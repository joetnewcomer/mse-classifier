question_id,title,body,tags
28230,Lower Central Series Problem: $D^i(G/N) = (ND^i(G))/N$,"Denote by $D^iG$ the $i$th term in the lower central series of G, i.e. $D^0G = \{1\}$, $D^i=[G, D^{i-1}G]$. The claim is that if $N$ is normal in $G$, then $D^i(G/N) = (ND^i(G)/N)$. I know we should proceed by induction, and we do thus: For the base case, $i=0$, we have: 
        $$ D^0(G/N) = G/N \mbox{ and } (ND^0G)/N = (NG)/N$$
        But from the second isomorphism theorem, $(NG)/N \cong G/(G\cap N) = G/N$, and we have equality. Now, assume that the claim holds for the $k$th term, and we will consider the $k+1$st term:
$\begin{eqnarray*}
	D^{k+1}(G/N) &=& \left[ G/N, D^k(G/N) \right] \\
	&=& [G/N, (ND^kG)/N] \\
	&=& \langle [x, y] \mid x \in G/N, y \in (ND^kG)/N \rangle \\
	&=& \langle xyx^{-1}y^{-1} \mid x \in G/N, y\in (ND^kG)/N \rangle \\
	&=& \langle xyx^{-1}y^{-1}N \mid x \in G, y\in ND^kG \rangle \\
	&=& \langle [x,y]N \mid x \in G, y\in ND^kG \rangle \\
	&=& [G, D^kG]N \\
	&\subseteq& (ND^{k+1}G)/N 
\end{eqnarray*}$ This gives one direction of inclusion. The other direction seems similar. Is this the right approach? I feel like I've bungled the chain of equalities. In particular, I'm pretty sure I just pulled the $ND^{k+1}G$ (necessary so that so that $N$ is normal in $ND^{k+1}G$) product out of thin air. Tips, advice, corrections?  (I'm a noob here, so be gentle :-P )","['group-theory', 'abstract-algebra']"
28231,Is the area of a circle ever an integer?,"Is the area of a circle ever an integer? I was trying to answer someone else's question on yahoo answers today and I got thumbs down from people on my answer and have come here to get a thorough proof on it because now I just must know! :) My assertion: Suppose we have two integers a and b. We can form a rational numbers out of each of these: $\frac{a}{1}$ and $\frac{b}{1}$. Now forming another rational by dividing them: $\frac{\frac{a}{1}}{\frac{b}{1}}$ = $\frac{a}{b}$. Now if we divide this by itself: $\frac{\frac{a}{b}}{\frac{a}{b}}$ = $\frac{ab}{ab}$ = 1. Therefore, we can conclude that given any rational number, we can always describe it using only integers thus always resulting in an integer number. However, even if our radius is $\sqrt{\frac{1}{\pi}}$ then we will have $\pi\sqrt{\frac{1}{\pi}}^2$ = $\frac{\pi}{\pi}$, by definition of area = $\pi r^2$. Now I think this the trickiest part. Does  $\frac{\pi}{\pi}$ = 1? Or can it only equal  $\frac{\pi}{\pi}$? How do we prove that  $\frac{\pi}{\pi} \neq$ 1? Or is my method sufficient at all? Thanks!","['irrational-numbers', 'number-theory']"
28236,"Partitioning polynomials in $\mathbb{Z}[x,y]$ by the primes they represent","Suppose you have a set $S\subset\mathbb{Z}[x,y].$ How can one efficiently partition the polynomials into sets such that the primes represented by the polynomials in any given set are identical?  For these purposes, ""efficient"" can be interpreted as ""subquadratic"", though I'm interested in practical as well as theoretical/worst-case. A special case of particular interest: binary quadratic forms $ax^2+bxy+cy^2.$ For any pair of polynomials, it's possible to check if the two are equivalent forms.  Of course this requires checking quadratically many pairs.  One practical speedup would be to first partition the polynomials by discriminant—in the case of binary quadratic forms, $b^2-4ac.$  This takes only (essentially) linear time, and results in speedup by a factor of $k$ if there are $k$ discriminants with roughly equal numbers of polynomials for each (time $n^2/k^2$ for each discriminant, $k$ discriminants).  Are there further invariants that can be used in similar fashion?","['prime-numbers', 'quadratic-forms', 'polynomials', 'number-theory']"
28238,Sums of prime powers,"You are given positive integers N, m, and k.  Is there a way to check if
$$\sum_{\stackrel{p\le N}{p\text{ prime}}}p^k\equiv0\pmod m$$
faster than computing the (modular) sum? For concreteness, you can assume $e^k<m<N.$ I don't know of a way, but it's not obvious to me that no method exists.  Fast ways to prove or refute the equivalence would be of interest.  You can assume that the particular instance of the problem is 'hard', that is, the modulus is not close enough to N so that Rosser-type bounds on the sum would rule it out. With $k=0$ this is just asking if $m|\pi(N)$, so it is possible to compute the sum in time $O(N^{1/2+\varepsilon})$ using the Lagarias-Odlyzko method.  (Or more practically, one of the combinatorial $\pi(x)$ methods.)  For $k>0$ the sum is superlinear and so cannot be stored directly (without, e.g., modular reduction) but it's not clear whether a fast algorithm exists. You can think of the problem as ""Your friend, who has access to great computational resources, makes the claim (N, m, k). If her claim is true, can you prove it?  If her claim is false, can you refute it?"". Edit: I posted a related problem on cstheory, asking if there is a short proof or interactive proof that the sum is correct.","['prime-numbers', 'algorithms', 'number-theory']"
28240,Why does $L \cap (M + N) = (L \cap M) + (L \cap N) $ not hold for subspaces,"Let $L$, $M$, and $N$ are subspaces of a vector space. Prove that following is not necessarily true. $L \cap (M + N) = (L \cap M) + (L \cap N) $ This problem is given in 'Finite dimensional vector spaces' by Halmos. I was using 'if a vector belongs to L.H.S. then it must belong to R.H.S and vice versa' argument. Neither I can disprove it using this argument nor I could find a case where this is wrong!","['vector-spaces', 'linear-algebra']"
28243,Is there a proof that $\pi \times e$ is irrational?,"A little reading suggests: It is known that either $\pi + e$ or $\pi \times e$ is transcendental (or possibly both), but no proof is known that one of those two numbers in particular is transcendental. If we just want irrationality rather than transcendence, is a proof known? Can we prove $\pi+e$ is irrational?  Can we prove $\pi \times e$ is irrational?","['pi', 'irrational-numbers', 'number-theory']"
28246,Why are gauge integrals not more popular?,"A recent answer reminded me of the gauge integral , which you can read about here . It seems like the gauge integral is more general than the Lebesgue integral, e.g. if a function is Lebesgue integrable, it is gauge integrable. (EDIT - as Qiaochu Yuan points out, I should clarify this to mean that the set of Lebesgue integrable functions is a proper subset of gauge integrable functions. ) My question is this: What mathematical properties, if any, make the gauge integral (aka the Henstock–Kurzweil integral) less useful than the Lebesgue or Riemann integrals? I have just a cursory overview of the properties that make Lebesgue integration more useful than Riemann in certain situations and vice versa. I was wondering if any corresponding overview could be given for the gauge integral, since I don't quite have the background to tackle textbooks or articles on the subject.","['gauge-integral', 'integration', 'analysis']"
28247,Can every even integer be expressed as the difference of two primes?,"Can every even integer be expressed as the difference of two primes?
If so, is there any elementary proof?","['prime-numbers', 'number-theory']"
28254,what is wrong with this reasoning?,"14% of people are left handed, if we want to find the chances of a brother and a sister both being left handed, we might be tempted to multiply .14 by .14. What is wrong with this reasoning when trying to find out the probability of both of them being left handed?",['probability']
28256,Hard problem Relationship between CDH and Discrete Log,"In Number Theory,
Given the Diffie Hellman tuple (g a ,g b ,g ab ),
Will the given info be helpful in finding the discrete log of g ,i.e a or b? Edit: That is can we use the solution of a Computational Diffie Hellman Problem to solve a Discrete Log. It is known that the converse is true!","['cryptography', 'number-theory']"
28258,How to simplify trigonometric inequality?,$| 3 ^ { \tan ( \pi x ) } - 3 ^ { 1 - \tan ( \pi x ) } | \geq 2$,"['trigonometry', 'inequality']"
28268,Why don't these limits exist?,"Why don't these limits exist? $$\lim_{x\to 0}\frac1{x^2}$$ Aren't we here just approaching $x$? And, thus will not get $0$ and avoid the division on ""0""? And, what about this limit? $$\lim_{x\to 0}\frac{|x|}{x}$$","['calculus', 'limits']"
28281,Reducibility over $\mathbb{Z}_2$?,"I have seen that $x^{2}+x+1$ and $x^{4}+x+1$ are irreducible over $\mathbb{Z}_2$ and I thought a polynomial of the form $x^{2^m}+x+1$ for $m\ge3$ would be irreducible too. However using WolframAlpha, my hunch was wrong. It could be factored over $\mathbb{Z}_2$. WolframAlpha could only generate the factors for $m=3,\ldots, 13$ and so far, I observed that for odd $m$, my polynomial is divisible by $x^{2}+x+1$. I want to see how one can show that $x^{2^m}+x+1$ for $m\ge3$ is reducible.","['irreducible-polynomials', 'abstract-algebra', 'polynomials']"
28282,Perron-Frobenius Theorem and Graph Laplacians,"How can the Perron-Frobenius theorem be used to show that for a connected graph, there is a simple eigenvector that is (i) real and (ii) smallest in magnitude and (iii) has an associated eigenvector that is positive? The graph Laplacian is given as $L = D-A$, where $A$ is the non-negative adjacency matrix of the graph.  The Perron-Frobenius theorem allows us to state that $\rho(A) > 0$ and is a simple eigenvalue of $A$ $Ax = \rho(A)x$ with all elements of $x$ positive. The matrix $D$ is diagonal with positive elements.  It is well-known that for a connected graph, 0 is the smallest eigenvalue of $L$ and it is simple, and $x=\mathbb{1}$ (vector of all ones) is the associated positive eigenvector. I am confused mainly because $L$ is no longer a non-negative (or non-positive) matrix.  Any ideas?","['matrices', 'linear-algebra', 'graph-theory', 'graph-laplacian']"
28285,Is there any possibility to do divergent summation with $\sum_{k=1}^{\infty}\exp(\sqrt k) $?,"Self-studying some properties of the exponential-function I came to the question of ways to assign a value to the divergent sum $$s=\sum_{k=1}^{\infty}\exp(\sqrt k) $$ I have no idea how to attack this with standard methods (I do not know many). I tried a replacement using reversing order of summation when $s$ is expressed as double sum and introducing zeta at negative half-integer values. I wrote the double-sum as
$$ \begin{array} {rr} s &=& \sum_{k=1}^{\infty} \sum_{j=0}^{\infty} \frac{k^{j/2}}{j!}
  &=& \sum_{j=0}^{\infty} \frac{\sum_{k=1}^{\infty} k^{j/2}}{j!}  
  &=& \sum_{j=0}^{\infty} \frac{\zeta(-j/2)}{j!} 
\end{array}$$ With this Pari/GP gives me about $ s=-0.753717005339 $ . Moreover I'm curious whether I have to extend the index to $-2$ to get formally $$s = -1 + 0 + \sum_{k=0}^{\infty}\frac{\zeta(-k/2)}{k!}$$ where I've set $\frac{\zeta(0.5)}{(-1)!} = 0 $ and $\frac{\zeta(1)}{(-2)!} =\frac{(-1)!}{(-2)!} =-1 $
to arrive at $ s_1=-1.753717005339 $ But this is just a shot in the dark. I've tried with another trick which works in some circumstances to sum the alternating series first, and then add an alternating partial series etc, like
$$s=\sum_{k=1}^{\infty} (-1)^{k-1} \exp(\sqrt k) + 2*\sum_{k=1}^{\infty} (-1)^{k-1} \exp(\sqrt{ 2 k}) + 4*... $$ but this doesn't help either since all sums are positive and I get another divergent and monotonuously increasing sequence of partial sums. One of the problems is, that regular summations cannot sum divergent series if all summands are positive and also increase, so my standard tools fail here. Q: how else could I sum that series? [edit]: Things begin to complicate... I tried another approach and got a result with a suspicious integer difference. I look at the formal powerseries 
$$ g(x) = \exp(\sqrt{1+x}-1) = 1 + g_1 \frac{x}{1!}+ g_2 \frac{x^2}{2!}+ \ldots $$
and $$ \begin{array} {ll}  t&=&e*(g(0)+g(1)+g(2)+g(3)+...) \\\ &=& e*g(0) + e*(g(1)+g(2)+g(3)+\ldots) \\\ &=& e*g(0)+e*t_1 \end{array} $$ Then, by the same principle of reordering summation of the formal doubleseries we get another sum of zetas, but now at negative integer arguments
 $$ \begin{array} {ll} t_1 &=& g(1)+g(2)+\ldots \\\ &=& 1*\zeta(0)+g_1*\frac{\zeta(-1)}{1!} +g_2*\frac{\zeta(-2)}{2!}+\ldots \end{array} $$ if that reordering makes sense. Interestingly the value which I get by this is $t=1.246282994682$ where much interestingly $s=t-2$ . This does not yet confirm one value over the other. But to have just a simple integer-difference seems to tell, that in principle these paths of computation are not completely meaningless (?) [Edit2]: using Ramanujan-summation as shown in the wikipedia-link I arrive at the same latter value of about $1.2462$ which is again $s+2$. What puzzles me is, that I'm used to negative values for divergent sums of increasing positiv terms. Did I miss something in the Ramanujan-formula? I used the formula $$C(a) = \int_0^a  f(t) dt - \frac12 f(0) - \ldots $$ where I insert my $g(x)$ above for $f(x)$ using $a=0$ (and thus the integral-term being zero). [Edit3]: It seems, that the method at [edit1] is just the Ramanujan-method where the Bernoulli-numbers are translated to the respective zeta-values [Edit4]: I had to correct the sum-formula; the factorials had to be removed Then the wikipedia-formula reads $$C(a) = \int_0^a  f(t) dt + \sum_{k=0}^{\infty} \zeta(-k) \frac{f^{(k)}(0)}{k!} $$ Because we have a power series, the k'th derivative $f^{(k)}(0)=f_k*k! $ and we can replace this in the formula, cancelling the factorial. Furtherly I had used the function g(x), so  $$ t=e + e*\sum_{k=0}^{\infty} \zeta(-k) g_k  $$   should equal $s$ . Unfortunately, this is also a divergent sum, but can be Euler-/Borel-summed. Interestingly, the integral-term $  \int_a^b  f(t) dt $ gives just the mysterious number 2 : $$ e*\int_{-1}^0  g(t) dt = \int_{0}^1  \exp(\sqrt{t}) dt = 2 $$ according to wolfram-alpha . With this it seems I can use the much better summable (if not convergent) series
$$ s=\sum_{j=0}^{\infty} \frac{\zeta(-j/2)}{j!} $$ and determine that Ramanujan-summ 
$$ t = \int_{0}^1  \exp(\sqrt{t}) dt + s $$ [Edit5] It seems, that the possibility for computations is coherent for other exponents in the basic series. If I generalize 
$$ \begin{array} {rr} S_q &=& \sum_{k=1}^{\infty} \exp(k^q) \\ 
     g_q(x)  &=& \exp((1+x)^q-1) &=& \exp((1+x)^q)/e \\
     Ca_q &=& \int_0^1 \exp(x^q) 
 \end{array} $$
and $t_q$ and $s_q$ accordingly, then for some positive fractional q I get the following results.
$$ \small{
\begin{array} {rrrr}
 q&   t_q &                      Ca_q           & &  s_q           &  C_q(0) \\
 1.00000000000 & 1.13630512159 & 1.71828182846 &(= 1e - 1) & -0.581976706869 & 1.13630512286 \\
 0.500000000000 & 1.24628299466 & 2.00000000000  &(=- 0e + 2)& -0.753717005339 & 1.24628299491 \\
 0.333333333333 & 1.28422772983 & 2.15484548538  &(= 3e - 6)& -0.870617755549 & 1.28422772997 \\
 0.250000000000 & 1.30316006154 & 2.25374537233  &(=-8e + 4!) & -0.950585310784 & 1.30316006162 \\
 0.200000000000 & 1.31447347236 & 2.32268228066 &(=45e - 5!)& -1.00820880830 & 1.31447347240 \\
 0.166666666667 & 1.32198952281 & 2.37359728681 &(=-264e + 6!)& -1.05160776400 & 1.32198952284 \\
 0.142857142857 & 1.32734318867 & 2.41279179153&(=1855e - 7!) & -1.08544860285 & 1.32734318869 \\
 0.125000000000 & 1.33134949700 & 2.44392029544 &(=-14832e + 8!)& -1.11257079844 & 1.33134949702 \\
 0.111111111111 & 1.33445988876 & 2.46925379716 &(=1334978e - 9!)& -1.13479390840 & 1.33445988878 \\
 0.100000000000 & 1.33694450266 & 2.49028031297 &(=-A240(10)e + 10!)& -1.15333581032 & 1.33694450267 \\
 0.0909090909091 & 1.33897484256 & 2.50801667035  &(=A240(11)e - 11!)& -1.16904182779 & 1.33897484257 \\
 0.0833333333333 & 1.34066501173 & 2.52318189730 &(=-A240(12)e + 12!)& -1.18251688557 & 1.34066501173
 \end{array}  }
$$
where $t_q$ in the second column is the assumed sum computed by the method $ t_q = Ca_q + s_q $ .    The $A240(k)$-entries are also found in the sequence A000240 in OEIS beginning at $k=1$. The last column is the same result computed by the Ramanujan sum $C(0)$ as denoted in the wikipedia-article (and my translation into the $g_q()$-function). That terms are always a diverging sequence of partial sums, so their Euler-sum is documented here for comparision of accuracy. A plot of $q$ and $t_q$ looks like a nearly linear (negative) relation. It is still open , which value ($t_q$ or $s_q$) should be taken as final sum. Note that using $q=1$ we should get $ S_1 = e^1 + e^2 + e^3 + ... = \frac{e}{1-e} \approx -1.58197670687 $ where only $s_q$ is in the near (misses by 1). The $t_q$ value for $q=1$ however seems obscure; the correct value would be $ S_1 = t_q - e = \frac{e}{1-e} $ . Here I do not know what this tells us?",['sequences-and-series']
28286,General Introduction to Functional and other Mathematic Notations,"I've been a programmer for a good while now. Fairly experienced at a bit of math as far as coming up with algorithms and such but I am far far behind on understanding quite a deal of notation. Here and there I run into an issue where someone will notify me that I've reinvented some piece of calculus, trig or some other fields. Occasionally this makes for some interesting code and all, but I've begun to think that I could very often avoid this by being able to read and write standard notation more fluently. When it comes to this area, I'm honestly a complete newb. Are there any good introductions or resources that can help get me on a clear path to understanding? I have some concept on simple functions, but not much. Tendency in study has been that I'll find myself too deep in something too complicated too quickly and forget everything. For instance, to borrow from another open bounty at this time, I cannot read the following: $$\sum_{n=-\infty}^\infty J_n(x) J_{n+m}(x) = \delta(m)$$ My mind is stuck in code, help me out of my cave! :)","['functions', 'online-resources', 'soft-question', 'notation']"
28305,"If f is surjective and g is injective, what is $f\circ g$ and $g\circ f$?","Say I have $f=x^2$ (surjective) and $g=e^x$ (injective), what would $f\circ g$ and $g\circ f$ be? (injective or surjective?) Both $f$ and $g : \mathbb{R} \to \mathbb{R}$ . I've graphed these out using Maple but I don't know how to write the proof, please help me!",['functions']
28317,How to prove the following about a group G?,"How does one prove that: for all $a\in G$, where $G$ is a group (not necessarily abelian) $a^{|G|} = 1_G$.",['group-theory']
28321,Continuity of a function that maps a point to the closest point on a compact convex set,"Let $K$ be a nonempty compact convex subset of $\mathbb R^n$ and let $f$ be the function that maps $x \in \mathbb R^n$ to the unique closest point $y \in K$ with respect to the $\ell_2$ norm. I want to prove that $f$ is continuous, but I can't seem to figure out how. My thoughts: Suppose $x_n \to x$ in $\mathbb R^n$. Let $y_n = f(x_n)$ and let $y = f(x)$. By the compactness of $K$, there is a convergent subsequence $(y_{k_n})$ that converges to some $y' \in K$. If $y \ne y'$, then $\|x-y\| < \|x-y'\|$. Furthermore, any point $z \ne y$ on the line segment joining $y,y'$ also satisfies $\|x-y\|<\|x-z\|$. I don't know where to go from here. Any tips?",['analysis']
28329,Nice proofs of $\zeta(4) = \frac{\pi^4}{90}$?,"I know some nice ways to prove that $\zeta(2) = \sum_{n=1}^{\infty} \frac{1}{n^2} = \pi^2/6$.  For example, see Robin Chapman's list or the answers to the question "" Different methods to compute $\sum_{n=1}^{\infty} \frac{1}{n^2}$ ?"" Are there any nice ways to prove that $$\zeta(4) = \sum_{n=1}^{\infty} \frac{1}{n^4} = \frac{\pi^4}{90}?$$ I already know some proofs that give all values of $\zeta(n)$ for positive even integers $n$ (like #7 on Robin Chapman's list or Qiaochu Yuan's answer in the linked question).  I'm not so much interested in those kinds of proofs as I am those that are specifically for $\zeta(4)$. I would be particularly interested in a proof that isn't an adaption of one that $\zeta(2) = \pi^2/6$.","['sequences-and-series', 'calculus', 'riemann-zeta', 'real-analysis', 'complex-analysis']"
28332,Is Lagrange's theorem the most basic result in finite group theory?,"Motivated by this question , can one prove that the order of an element in a finite group divides the order of the group without using Lagrange's theorem? (Or, equivalently, that the order of the group is an exponent for every element in the group?) The simplest proof I can think of uses the coset proof of Lagrange's theorem in disguise and goes like this: take $a \in G$ and consider the map $f\colon G \to G$ given by $f(x)=ax$. Consider now the orbits of $f$, that is, the sets $\mathcal{O}(x)=\{ x, f(x), f(f(x)), \dots \}$. Now all orbits have the same number of elements and $|\mathcal{O}(e)| = o(a)$. Hence $o(a)$ divides $|G|$. This proof has perhaps some pedagogical value in introductory courses because it can be generalized in a natural way to non-cyclic subgroups by introducing cosets, leading to the canonical proof of Lagrange's theorem. Has anyone seen a different approach to this result that avoids using Lagrange's theorem? Or is Lagrange's theorem really the most basic result in finite group theory?","['education', 'finite-groups', 'group-theory', 'abstract-algebra']"
28341,Number of ascending chains in a lattice,"Let $A = \{1,\ldots,n\}^2$, for some $n \in \mathbb{N}$. We define a partial order on $A$ by $(a,b) \leq (c,d)$ when $a \leq c$ and $b \leq d$. What is the number of ascending non-degenerate (all points are different) chains of length $k$, for relevant $k$. Help please... This is not a homework assignment, but just a question of interest.",['combinatorics']
28343,Notation for the set created from the combination or permutation of a set,"For a set $S$ with $n$ elements, the notation for a combination $\binom{n}{k}$, or $C(n, k)$, indicates the number of combinations of $k$ elements from $S$, but how does one indicate the actual set created from combinations of $k$ elements from $S$? That is, $\binom{n}{k}$ is the size of the set I'd like to represent. Likewise, how would one indicate the actual set of items created from the permutations of $k$ elements, rather than the size of that set?","['notation', 'combinatorics']"
28348,Proof of $\lim_{n\to \infty} \sqrt[n]{n}=1$,"Thomson et al. provide a proof that $\lim_{n\rightarrow \infty} \sqrt[n]{n}=1$ in this book (page 73) . It has to do with using an inequality that relies on the binomial theorem: I have an alternative proof that I know (from elsewhere) as follows. Proof . \begin{align}
\lim_{n\rightarrow \infty} \frac{ \log n}{n} = 0
\end{align} Then using this, I can instead prove: \begin{align}
\lim_{n\rightarrow \infty} \sqrt[n]{n} &= \lim_{n\rightarrow \infty} \exp{\frac{ \log n}{n}} \newline
& = \exp{0} \newline
& = 1
\end{align} On the one hand, it seems like a valid proof to me. On the other hand, I know I should be careful with infinite sequences. The step I'm most unsure of is: \begin{align}
\lim_{n\rightarrow \infty} \sqrt[n]{n} = \lim_{n\rightarrow \infty} \exp{\frac{ \log n}{n}}
\end{align} I know such an identity would hold for bounded $n$ but I'm not sure I can use this identity when $n\rightarrow \infty$ . Question: If I am correct, then would there be any cases where I would be wrong? Specifically, given any sequence $x_n$ , can I always assume: \begin{align}
\lim_{n\rightarrow \infty} x_n = \lim_{n\rightarrow \infty} \exp(\log x_n)
\end{align} Or are there sequences that invalidate that identity? (Edited to expand the last question)
given any sequence $x_n$ , can I always assume: \begin{align}
\lim_{n\rightarrow \infty} x_n &=  \exp(\log \lim_{n\rightarrow \infty} x_n) \newline
&=  \exp(\lim_{n\rightarrow \infty} \log x_n) \newline
&=  \lim_{n\rightarrow \infty} \exp( \log x_n)
\end{align} Or are there sequences that invalidate any of the above identities? (Edited to repurpose this question).
Please also feel free to add different proofs of $\lim_{n\rightarrow \infty} \sqrt[n]{n}=1$ .","['radicals', 'sequences-and-series', 'real-analysis', 'limits']"
28352,Prove that the Ky Fan norm satisfies the triangle inequality,How can one simply see that Ky Fan $k$ -norm satisfies the triangle inequality? (The Ky Fan $k$ -norm of a matrix is the sum of the $k$ largest singular values of the matrix),"['eigenvalues-eigenvectors', 'matrices', 'normed-spaces', 'linear-algebra', 'functional-analysis']"
28353,Different definitions for submanifolds,"I'm trying to better understand the concept of differentiable submanifold . However, it looks like many different definitions are adopted by various authors and so I'm trying to keep myself in sync by proving them equivalent. Now I'm stuck with the following two. Let $M$ denote a $n$-differentiable manifold and let $M' \subset M$: consider $M'$ equipped with the subspace topology. Also let $n' < n$ be an integer. I ) We say that $M'$ is a $n'$- submanifold of $M$ if it is locally a slice of coordinate system, i.e. for all $p'\in M'$ there exists a coordinate system $(U, x^1 \ldots x^n)$ for $M$ s.t. $$U \cap M'=\{ p \in M\mid x^{n'+1}(p)=\ldots=x^{n}(p)=0\}.$$ If this is the case $(U \cap M', x^1 \ldots x^{n'})$ is a local chart on $M'$ and the collection of such charts forms a differentiable atlas on it. II ) We say that $M'$ is a $n'$- submanifold of $M$ if for all $p'\in M'$ there exist an open neighborhood $U_{p'}$ of $p'$ in $M$ and a differentiable mapping $\tilde{F}_{p'} \colon U_{p'}\to \mathbb{R}^{n'}$ s.t.: i) The mapping $F_{p'}=\tilde{F}_{p'}|_{U_{p'} \cap M'}$ is one-one onto an open set $V$ of $\mathbb{R}^{n'}$; ii) The inverse mapping $F_{p'}^{-1}\colon V \to M$ is differentiable. If this is the case $(U_{p'}\cap M', F_{p'})$ is a local chart on $M'$ and the collection of such charts forms a differentiable atlas on it. The difficult part is proving that II $\Rightarrow$ I , that is, given a collection of $(U_{p'}\cap M', F_{p'})$ use them to show that $M'$ is locally a slice of some coordinate system. How do you build a coordinate system like that? Edit: Answer The following is based on Warner's Foundations of differentiable manifolds and Lie groups , Proposition 1.35. Let $M, M', p', U_{p'}, \tilde{F}_{p'}$ as in II and put $\tilde{F}_{p'}=(y^1\ldots y^{n'})$. Since $F_{p'}$ has a differentiable inverse, the functions $y^1 \ldots y^{n'}$ must be independent at $p'$ and so they form part of a local chart $(W, y=(y^1\ldots y^n))$, where $W$ is an open neighborhood of $p'$ in the big manifold $M$. With no loss of generality let us assume that $y(p')=(0\ldots 0)$. Now there is no need for the slice $\{p\in W \mid y^{n'+1}(p)=\ldots=y^{n}(p)=0\}$ to agree with $M'$. So we need to tweak this coordinate system a little. Define a mapping $Pr\colon W \to W \cap M'$ by setting $$Pr(p)=(y^1\ldots y^{n'})^{-1} (y^1(p) \ldots y^{n'}(p), 0 \ldots 0).$$ This mapping is best understood in coordinates: $Pr(p)$ is the unique point of $W\cap M'$ whose first $n'$ coordinates agree with the first $n'$ coordinates of $p$. It is clear that this mapping is differentiable (remember hypothesis (ii) above). Define functions $$z^i=
\begin{cases} 
y^i & i=1\ldots n' \\
y^i-y^i \circ Pr & i=n'+1 \ldots n 
\end{cases};$$ those functions are independent at $p'$ and so they form a coordinate system in an open neighborhood $V$ of it. We have $\{p \in V \mid z^{n'+1}(p)=\ldots =z^n(p)=0\}=M' \cap V$: we have thus proven that $M'$ agrees locally with a slice of some coordinate system of $M$, that is, $M'$ verifies I . ////","['differential-topology', 'differential-geometry']"
28355,$2^x - a$ touches $\log_2(x)$,"I was playing around with the functions $2^x$ and $\log_2(x)$. As they are the inversions of each other, I thought there was a simple number $a$ for which $2^x - a$ touches $\log_2(x)$. Using trial-and-error, for $a = 2$ looked like the functions just touched each other, but on closer inspection they did cross each other: at $x = 1$ and at approximately $x = 1.04759$. Zoomed in: Is there an exact solution to $a$ for which $2^x - a$ touches $\log_2(x)$? With ""touches"" I mean that they just touch each other, like a tangent does to a function.","['exponentiation', 'logarithms', 'calculus']"
28363,Elementary question about Cayley Hamilton theorem and Zariski topology,"A question about a proof of the Cayley-Hamilton theorem using Zariski topology. ""The set $C$ of all matrices of size $n \times n$ (over an algebraically closed field $k$ ) with distinct eigenvalues is dense in the Zariski topology"". Can we argue as follows? Since non-empty open sets in the Zariski topology are dense in $k^{n}$ then we are done if we can show the complement of $C$ , i.e the set of all matrices of size $n \times n$ with repeated eigenvalues is open in the Zariski topology. Now to each matrix $B$ of size $n \times n$ compute its characteristic polynomial $p_{B}$ and associate to this polynomial its discriminant $D(p_{B})$ . Now define a map: $f: \mathbb{A}^{n^{2}} \rightarrow \mathbb{A}^{1}$ given by $f(B)=D(p_{B})$ where where $\mathbb{A}^{n}$ denotes the $n$ -affine space. I'm identifying here $\mathbb{A}^{n^{2}}$ with the set of all matrices $n \times n$ over an algebraically closed field $k$ . Here is my question. How do we know the map $f$ is continuous with respect the Zariski topology?  If we can show it is continuous aren't we done? because we can take $\{0\}$ this is closed in $\mathbb{A}^{1}$ because it is finite, so by continuity of $f$ , $f^{-1}(\{0\})$ is closed in $\mathbb{A}^{n^{2}}$ but this preimage is exactly the set of all matrices with repeated eigenvalues.",['algebraic-geometry']
28365,Continuous transformations of a triangle bound on $S_1$,"Suppose we take the circle $S_1$ and three points on this circle, which defines a triangle. By moving the points continuously on $S_1$, we obtain a continuous transformation of the triangle. I was wondering what is the structure of this group of transformations ?","['lie-groups', 'group-theory', 'abstract-algebra']"
28368,How to graph equation,"So the problem is to find all points $(x,y)$ on the real plane such that $f(x,y) = \cos^2(x+t) + 2\sin(x+t)\cos(y) - \frac{(\cos y - 1)^2}{2} - \sin(x) \lt .5$ for all real $t$. I'm not sure where to start with this, I don't think I fully understand the equation... how can the result be in terms of $f(x,y)$ when $t$ is also essentially a variable? shouldn't this be a 3 dimensional plot?","['trigonometry', 'inequality', 'graphing-functions']"
28376,Incremental calculation of inverse of a matrix,"Does there exist a fast way to calculate the inverse of an $N \times N$ matrix, if we know the inverse of the $(N-1) \times (N-1)$ sub-matrix? For example, if $A$ is a $1000 \times 1000$ invertible matrix for which the inverse is known, and $B$ is a $1001 \times 1001$ matrix obtained by adding a new row and column to $A$, what is the best approach for calculating inverse of $B$?","['matrices', 'linear-algebra', 'computer-science', 'numerical-methods']"
28379,Are dualizing modules stable under localization,"Let $(R,m,k)$ be a (noetherian) regular local ring of depth=dimension $d$, and let $D$ be a dualizing module for $R$ (say, the injective envelope of $R/m$). Then is $D_p$ dualizing for $R_p$ for any prime $p$ of $R$ (more generally, if $R$ is Gorenstein and $p$ is a prime such that $R_p$ is also Gorenstein)?  If it is true, could I have a reference for a proof? Bump!","['commutative-algebra', 'algebraic-geometry']"
28382,What kind of completeness is the completeness of $\mathbb{R}$?,"As opposed to the algebraic completion of $\mathbb{Q}$, which yields the algebraic numbers, we can say that $\mathbb{R}$ is complete in the sense that every non-empty subset of $\mathbb{R}$ bounded by above has a supremum. So, it isn't algebraically complete, but is it topologically or metrically complete? What would be the right word to describe its completeness? Thanks.","['general-topology', 'terminology', 'real-analysis']"
28389,Archimedean property,"I've been studying the axiomatic definition of the real numbers, and there's one thing I'm not entirely sure about. I think I've understood that the Archimedean axiom is added in order to discard ordered complete fields containing infinitesimals like the hyperreal numbers. Additionally, this property clearly cannot be derived solely from the axioms of ordered field and completeness, since $^*\mathbb{R}$ and $\mathbb{R}$ are two complete ordered fields, two models of the axioms, one of them Archimedean and the other non-Archimedean. Are these ideas correct? Thanks.",['real-analysis']
28390,Is any transposition a product of simple transpositions?,"Is any transposition a product of simple transpositions? If yes, how can you prove this?","['group-theory', 'abstract-algebra']"
28393,Why does Cantor's diagonal argument yield uncomputable numbers?,"As everyone knows, the set of real numbers is uncountable. The most ubiquitous proof of this fact uses Cantor's diagonal argument . However, I was surprised to learn about a gap in my perception of the real numbers: A computable number is a real number that can be computed to within any desired precision by a finite, terminating algorithm. Turns out that the set of computable numbers is countable . My mind is effectively blown at this point. So I'm trying to reconcile this with Cantor's diagonal argument. Wikipedia has this to say: ""...Cantor's diagonal argument cannot be used to produce uncountably many computable reals; at best, the reals formed from this method will be uncomputable."" So much for background information. Say I have a list of real numbers $.a_{1n}a_{2n}a_{3n}\ldots$ for $n\geq 1$. Why do we get more than just computable numbers if we select digits different from the diagonal digits $a_{ii}$? I.e. if I make a number $.b_1b_2b_3\ldots$ where $b_i\neq a_{ii}$, why is this number not always computable? The main issue I'm having is that it seems like I'm ""computing"" the digits $b_i$ in some sense. Is the problem that I have a choice for each digit? Or is there some other subtlety that I'm missing?","['set-theory', 'real-analysis']"
28395,Is it faster to multiply a matrix by its transpose than ordinary matrix multiplication?,"I'm writing a program that multiples a matrix by its transpose, and was trying to find efficiency hacks I could exploit considering that the two matrices being multiplied are related. Any ideas?","['matrices', 'algorithms']"
28413,"Given two basis sets for a finite Hilbert space, does an unbiased vector exist?","Let $\{A_n\}$ and $\{B_n\}$ be two bases for an $N$-dimensional Hilbert space . Does there exist a unit vector $V$ such that: $$(V\cdot A_j)\;(A_j\cdot V) = (V\cdot B_j)\;(B_j\cdot V) = 1/N\;\;\; \ \text{for all} \ 1\le j\le N?$$ Notes and application: That the $\{A_n\}$ and $\{B_n\}$ are bases means that $$(A_j\cdot A_k) =\left\{\begin{array}{cl}
1&\;\text{if }j=k,\\
0&\;\text{otherwise}.\end{array}\right.$$ In the physics notation, one might write $V\cdot A_j = \langle V\,|\,A_j\rangle$. In quantum mechanics, $P_{jk} = |\langle A_j|B_k\rangle|^2$ is the ""transition probability"" between the states $A_j$ and $B_k$. ""Unbiased"" means that there is no preference in the transition probabilities. A subject much studied in quantum information theory is ""mutually unbiased bases"" or MUBs . Two mutually unbiased bases satisfy $|\langle A_j|B_k\rangle|^2 = 1/N\;\;$ for all $j,k$. If it is true that the vector $V$ always exists, then one can multiply the rows and columns of any unitary matrix by complex phases so as to obtain a unitary matrix where each row and column individually sums to one . If true, then $U(n)$ can be written as follows: $$U(n) = \exp(i\alpha)
\begin{pmatrix}1&0&0&0...\\0&e^{i\beta_1}&0&0...\\0&0&e^{i\beta_2}&0...\end{pmatrix}
M
\begin{pmatrix}1&0&0&0...\\0&e^{i\gamma_1}&0&0...\\0&0&e^{i\gamma_2}&0...\end{pmatrix}$$
where the Greek letters give complex phases and where $M$ is a ""magic"" unitary matrix, that is, $M$ has all rows and columns individually sum to 1. And $M$ can be written as $M=\exp(im)$ where $m$ is Hermitian and has all rows and columns sum to 0. What's significant about this is that the $m$ form a Lie algebra. Thus unitary matrices can be thought of as complex phases, plus a Lie algebra. This is a new decomposition of unitary matrices. Since $m$ is Hermitian and has all rows and columns sum to 0, it is equivalent to an $(n-1)\times(n-1)$ Hermitian matrix with no restriction on the row and column sums. And this shows that $U(n)$ is equivalent to complex phases added to an object (the $M$ matrices) that is equivalent to $U(n-1)$. This gives a recursive definition of unitary matrices entirely in terms of complex phases.","['vector-spaces', 'hilbert-spaces', 'probability']"
28415,A double series yielding Riemann's $\zeta$,"Can you give me some hints to prove equality: $$\sum_{m,n=1}^{\infty} \frac1{(m^2+n^2)^2} =\zeta (2)\ G-\zeta(4)=\frac{\pi^2}{6}\ G-\frac{\pi^4}{90}$$ where $\zeta (t):= \sum\limits_{n=1}^{+\infty} \frac{1}{n^t}$ is the Riemann zeta function and $G := \sum\limits_{n=0}^{\infty} \frac{(-1)^{n}}{(2n+1)^2} \approx 0.915 965 594$ is Catalan's constant ? I tried with some reverse engineering , but I wasn't able to solve the problem at all. Even a good reference may be useful. Thanks a lot in advance, guys.","['sequences-and-series', 'riemann-zeta', 'catalans-constant']"
28417,Bound on the dimension of $L(D)$ for a compact Riemann Surface,"this is homework, but after banging my head against the wall for a day, I feel justified asking for a hint. Let $X$ a compact Riemann Surface, $D,E \in Div(X)$ divisors on $X$ with $degE\geq 0$. Show that $dimL(D+E) \leq dimL(D) + deg(E)$. I think if I can show that for $E = 1x$, $dim(D+1x) \leq DimL(D) + 1$, then this follows by induction, but I don't even know how to show this. Ideas? Please note that this class is rather elementary, so I am seeking a rather elementary answer. Edit: Based off the hint, let $f_1$ and $f_2$ linearly independent in $L(D+x)$ and let the degree of $x$ in $D$ be given by $k$.  Then in local coordinates on a neighborhood of $x$ we can write $$f_1(z) = a/(z-x)^{k+1} + h(z)$$ and $$f_2(z) = b/(z-x)^{k+1} + g(z)$$ for $h,g\in L(D)$ and $a,b\in \mathbb{C}$.  Observe that for any values of $a$ and $b$ there are coefficients $\alpha, \beta \in \mathbb{C}$ both not zero such that $\alpha f_1 +\beta f_2 \in L(D)$ (this requires enumerating a couple cases and showing we can get rid of the order $k+1$ pole) so at least one of the two is in $L(D)$.  But then the dimension of $L(D+x)$ is at most one more than $L(D)$ since we have shown there is no two lin. indep. functions in $L(D+x)$ that are both not in $L(D)$. To show $dimL(D+E) \leq dimL(D) + deg(E)$ for any positive $E$ we simply use induction. I can also prove this using the same rough argument about the local laurent expansion using the other hint, but I will add that later.  It should be exact because we can map $f(z) = a/(z-x)^{k+1} + h(z)$ to $a$ and the kernel will be $h\in L(D)$.","['riemann-surfaces', 'complex-analysis']"
28425,How to compute the first eigenvalue of Laplace operator in an ellipse?,"Let $\mathcal{E}$ be an ellipse in the $\mathbb{R}^2$ plane with center in $o=(0,0)$, given focal distance $c\geq 0$ and given area $A>0$. It is a fact that the eigenvalue problem for the Laplace operator with homogeneous Dirichlet boundary condition , i.e.: $$\begin{cases} u_{xx}+u_{yy}=-\lambda u, &\text{in } \mathcal{E}, \\ u=0, &\text{on } \partial \mathcal{E}, \end{cases} $$ has solutions for infinite positive values of $\lambda$: these values are called eigenvalues of the Laplace operator in $\mathcal{E}$ ; in particular, there exists an eigenvalue $\lambda_1(c)$ which is the smallest one: $\lambda_1(c)$ is called the first eigenvalue of the Laplace operator and it has some nice properties (e.g. it is simple , for the eigenspace associated to $\lambda_1(c)$ is one dimensional). Now, if $\mathcal{E}$ is a circle (this can happen iff $c=0$) it is well known that $\lambda_1(0)=\frac{\pi}{A}\ j_{0,1}^2$, where $j_{0,1}\approx 2.40483$ is the first zero of the Bessel function $\text{J}_0(x)$. The questions I'm interested in are the following: What happens to $\lambda_1(c)$ if $\mathcal{E}$ is a ""true"" ellipse (i.e. if $c>
0$)? Can it be evaluated explicitly (in terms of some special functions)? And how different values of $c$ bias the value of $\lambda_1(c)$ around $0$? It is known that $\lambda_1(c)\geq \lambda_1(0)$, with equality iff $\mathcal{E}$ is a circle (i.e., iff $c=0$; this is the famous Faber-Krahn inequality ), but it also seems quite obvious that $\lambda_1(c)$ has to exhibit a sort of continuity in $0$: in fact one expects that $\lim \limits_ {c\to 0^+} \lambda_1(c) = \lambda_1(0)$... Now, I did some researches on the net.
In the case $c>0$, one can introduce the elliptic coordinates $(\mu ,\nu)$: $$\begin{cases} x=c\cosh \mu \cos \nu, \\ y=c\sinh \mu \sin \nu ,\end{cases} $$ so that equation $u_{xx}+u_{yy}=-\lambda u$ transforms into: $$u_{\mu\mu} +u_{\nu \nu} =-c^2 \lambda (\sinh^2 \mu +\sin^2 \nu) u $$ which is harder to solve with separation of variables than the equation for the circle; neverthless separation of variables applies and yields a couple of so-called Mathieu's differential equations , which are a sort of ugly counterpart of Bessel's differential equation... But then I cannot figure out how to compute $\lambda_1(c)$ (neither for fixed $c$ nor for varying $c$)! Do I have to use some tables (like the ones in Abramowitz & Stegun, §20 )?
And, in the positive case, how they can be used? If you have any reference it could be worth reading, please feel free to suggest. Thanks in advance for your help.","['ordinary-differential-equations', 'eigenvalues-eigenvectors', 'partial-differential-equations']"
28443,Differentiability and decay of magnitude of fourier series coefficients,I want to know the answer/references for the question on decay of Fourier series coefficients and the differentiability of a function. Does the magitude of fourier series coefficients {$a_k$} of a differentiable function in $L^2 (\mathbb{R})$ (or in any suitable space) decay as fast as or faster than $k^{-1}$. I want to know if there any such theorem ? Also about the converse statement. ?,"['fourier-series', 'real-analysis']"
28453,Does $\sum_{n=1}^\infty (\frac{1}{n}-1)^{n^2}$ converge?,"I am trying to decide if $$\sum_{n=1}^\infty \left(\frac{1}{n}-1\right)^{n^2}$$ converges. By the alternating series test, as far as I can see, the series converges. This is also true by the root test. In both cases I assume that $$\left|\left(\frac{1}{n}-1\right)^{n^2}\right| = \left(1-\frac{1}{n}\right)^{n^2}$$ and I can't see anything wrong with that. What makes me unsure is that Wolfram Alpha says that the sum does not converge. Wolfram Alpha uses the limit test, which I am not able to complete:
$$\lim_{n\to\infty} a_n = \lim_{n\to\infty}\left(\frac{1}{n}-1\right)^{n^2} = \lim_{n\to\infty} e^{n^2 \ln{\frac{1-n}{n}}}$$
The problem is the logarithm which is not defined for any $n$, and I am not aware of another way to compute that limit. So does this series converge? Edit: When I ask Wolfram Alpha to evaluate the sum, it says that the seires do not converge. But it also says that ""computation timed out"". Maybe this could be the reason for why it's wrong.",['sequences-and-series']
28460,Why is the identity map never equal to the product of an odd number of reflections?,"Suppose I have an some plane and an identity mapping on the points of the plane. I see that the identity can be expressed as a product of an even number of reflections, since any reflection has itself as its own inverse. But why is it impossible to ever express the identity as the product of an odd number of reflections? Thanks.","['geometry', 'transformational-geometry']"
28476,Finding the limit of $\frac {n}{\sqrt[n]{n!}}$,"I'm trying to find 
$$\lim_{n\to\infty}\frac{n}{\sqrt[n]{n!}} .$$ I tried couple of methods: Stolz, Squeeze, D'Alambert Thanks! Edit: I can't use Stirling.","['factorial', 'radicals', 'calculus', 'limits']"
28496,Techniques for forming square factorizations,"Say you have the polynomial
$$ x^4 + 2 + x^{-4} $$ Looking at it, you see you can do
$$\begin{align*}
x^4 + 1 + 1 + x^{-4} & =x^2( x^2 + x^{-2} ) + x^{-2}( x^2 + x^{-2} )\\
&= \left( x^2 + x^{-2} \right)^2.
\end{align*}$$
Another one is
$$\begin{align*}
 x^2 + \frac{1}{2} + \frac{1}{16x^2} &=
 x^2 + \frac{1}{4} + \frac{1}{4} + \frac{1}{16x^2} \\
&=x^2\left( 1 + \frac{1}{4x^2} \right) + \frac{1}{4}\left( 1 + \frac{1}{4x^2} \right)\\
&=\left( x^2 + \frac{1}{4}\right) \left( 1 + \frac{1}{4x^2} \right)\\
 (x^2) \left( 1 + \frac{1}{4x^2} \right)^2.
\end{align*}$$ So the question is, I've been doing this by ""inspection"" - are there any techniques for recognizing when this type of factorization is possible or how to do more easily?","['factoring', 'algebra-precalculus']"
28498,Question regarding positive-definite matrices,"Let $A, B$ be positive-definite matrices and $Q$ a unitary matrix, furthermore suppose $A=BQ$ . Prove or disprove: $A=B$ . I'm having a hard time figuring out where to begin. Thanks.",['linear-algebra']
28503,How to find intersection of two lines in 3D?,"Given two lines joining A,B and C, D in 3D how do I figure out if they intersect, where they intersect and the ratio along AB at which the intersection happens? I can quite hapilly work out the equation for the lines in different forms. I'm guessing that you need to change them to parametric form, equate the equations and do some algebra manipulation","['geometry', 'linear-algebra']"
28511,Number of roots of $x^a-1=0$ with $a \in \mathbb{C}$,"It is well known that $x^2-1=0$ has two roots in $\mathbb{C}$, namely $\pm 1$. In general $x^n-1=0$ has exactly $n$ roots in $\mathbb{C}$. But what happens when $n$ is non integer (rational or real or even complex)? For example how many roots does $x^{1.9}-1=0$ have (counting multiplicity)? Intuitively I suspect that for adequately small $\epsilon$, $x^{1+\epsilon}-1=0$ has one complex root while $x^{2-\epsilon}-1=0$ (for some other $\epsilon$) will have 2 roots and more I guess that these roots will be close to $\pm 1$ respectively. Note that multiplicity of a root $\rho$ of a (non-polynomial) function $f$ is defined as the largest integer $k$ (if exists) such that: \begin{align*}
\lim_{x \rightarrow \rho} \frac{|f(x)|}{|x-\rho|^k} < \infty 
\end{align*} Update 1: I understand that my claim regarding the number of roots in $\mathbb{C}$ is not correct since $x^2=1$ has two complex roots but $x^{2.1}=1$ has a lot.  My question now is whether the following holds: Claim 1: There is an $\delta \in \mathbb{R}$ such that for all $\epsilon \in \Re$ with $|\epsilon|<\delta$ it holds that $x^{2+\epsilon}=1$ has two real roots (as many as the initial one). Note that this claim is only about the number of real roots of the equation. Some simulations on MATLAB show that this might be true. Additionally, the simulations show that the real roots of the perturbed equation are close to the roots of the unperturbed. This claim, if it holds, can easily be extended to cater for equations with more exponents. Update 2: Consider for example the equation $x^{1.5}=1$. This has solutions $\rho_i=\exp\left(4k\pi i/3\right)=\cos(4k\pi/3)+i \sin(4k\pi/3)$ with $k\in\mathbb{Z}$. What is the multiplicity of each root??? According to the definition, it should be $1$, so I think it would be good when saying that the solutions of $x^a=1$ are $\exp(2k\pi i /a)$ to restrict $k$ properly so that $2k\pi / a \in [0,2\pi)$.","['roots', 'complex-analysis', 'polynomials']"
28523,"Given $n$ distinct elements, how many Young Tableaux can you make?","Given $n$ distinct elements, how many Young Tableaux can one make?","['young-tableaux', 'combinatorics']"
28534,Variance of $\overline{X}_n^2$,"Here is a problem a have got in my homework. Given a set of $X_1, ... X_n \sim F$ i.i.d values find the variance of $T_n = \overline{X}_n^2$ where $\overline{X}_n = \frac{\sum_i{X_i}}{n}$. I actualy have an answer for this problem: $V(T_n) = \frac{4 \mu^2 \alpha_2}{n} + \frac{4 \mu \alpha_3}{n^2} + \frac{\alpha_4}{n^3}$ where $\mu = E(X_1)$ and $\alpha_k = \int \left| x - \mu \right|^k dF(x)$. But I can't figure out how it was obtained. Here is what I got so far:
$V(\overline{X}_n^2) = E\left[\overline{X}_n^4\right] - \left[E(\overline{X}_n^2)\right]^2 = E\left[\overline{X}_n^4\right] - \left[V(\overline{X}_n) + \left(E(\overline{X}_n)\right)^2\right]^2$ where 
$E(\overline{X}_n) = \mu$, 
$V(\overline{X}_n) = \frac{\alpha_2}{n}$
so $E(\overline{X}_n^2) = \mu^2 + \frac{\alpha_2}{n}$
the question is what $E(\overline{X}_n^4)$ equals to. If you have any thought about that problem, hint or solution, please, tell me.",['statistics']
28540,prove that $\lim_{x\to\infty} \pi(x)/x=0$,"I think I might have asked this question before, but I can't find it on the site, so I sincerely apologize if I am making a duplicate. But anyway, I have been working on this proof for several weeks and am stumped. If $\pi(x)$ is the number of primes less than or equal to $x$, prove that
  $$\lim_{x\to\infty}\frac{\pi(x)}{x} = 0.$$ I have this: So far I know that prime numbers can only be (if greater than $k$ for $p \pmod{k}$: $1 \pmod{2}$. $1,2 \pmod{3} \Rightarrow$ upper bound of $\frac{\pi(x)}{x}$ is $\frac{2}{3}$. $1,3 \pmod {4}$. $1,2,3,4 \pmod{5}$. $1,5 \pmod{6}\Rightarrow$ upper bound of $\pi(x)/x$ is $\frac{1}{3}$. $1,2,3,4,5,6 \pmod{7}$. $1,3,5,7\pmod{8}$. $1,2,4,5,7,8\pmod{9}$. Any number prime $p \pmod{k}$ can only have a remainders that are relatively prime to $k$, as a number would not be prime if it could be expressed as a composite plus a factor of that composite. And I know that these possible remainders demonstrate a fraction of the possible numbers that can be prime, given that in any range of numbers there must be at least one that satisfies each possible remainder $\pmod{k}$. ... But I'm not sure what I can conclude from this. I think that I need to find a way to express a number $N$ with respect to a prime $p$ such that $p \pmod N$ has a constant number of possible values, $K$. Then as $N$ increases, $K/N \to 0$. But otherwise I'm really stumped where to go. I have considered the following: multiplying all prime numbers less than an arbitrary value and modding by that, so there are no relative primes less than a certain value except 1. But the problem with this is once you reach a certain value there can be a multiple of this as $2p_1p_2\cdots p_n$. So I don't think that works. Any help would be much appreciated! Also, this is a first-semester number theory class, so I don't have much math knowledge to work with. I've done calc A,B,C, linear algebra A, and this number theory class.","['prime-numbers', 'limits', 'number-theory']"
28543,Sequence that approaches integers,I'm referring to an answer posted on Math Overflow (see the post by fedja on https://mathoverflow.net/questions/59115/a-set-for-which-it-is-hard-to-determine-whether-or-not-it-is-countable ) The question is whether the set of real numbers $a > 1$ so that for $K > 0$ the distance between $K a^n$ and its nearest integer approaches $0$ for $n \to \infty$ is countable. The integers are obviously in that set. However I couldn't come up with a proof that for all other reals the limit does not exist.,"['real-analysis', 'limits']"
28556,Convergence of a series of complex numbers that are dense on the unit circle,"Let me introduce my problem: Let $C \subset \mathbb{C}$ be the unit circle of the complex plane and $Z=\left\{ z_n \right\}_{n \in \mathbb{N}} \subset C$ be a dense subset of the unit circle meaning that $\bar{Z}=C$ or otherwise put that for all $c \in C$ there is a subsequence $\left\{z_{n_{k}}\right\}_{k \in \mathbb{N}}$ of $Z$ such that $z_{n_{k}} \xrightarrow{k} c$. I want to know whether the following series converges: \begin{align*}
\sum_{j\in\mathbb{N}}z_n
\end{align*} For every $z_j$ on the unit circle there is it's anti-diametric $\hat{z_j}=-z_j$ and for all $\varepsilon>0$ we can find an index $\hat{j}\in\mathbb{N}$ so that $|\hat{z_j}-z_{\hat{j}}|<\varepsilon\Leftrightarrow	 |z_j+z_{\hat{j}}|<\varepsilon$. If we group all members of the sequence this way (pairwise for a given $\varepsilon$) then the sum can be written in the following form: \begin{align*}
\sum_{j\in\mathbb{N}}z_n=\left(z_1+z_{\hat{1}}\right)+
\left(z_{k_2}+z_{\hat{k_2}}\right)+\ldots
\end{align*} Then by the triangular inequality: \begin{align*}
\sum_{j\in\mathbb{N}}z_n \le
|\sum_{j\in\mathbb{N}}z_n| \le
\left|z_1+z_{\hat{1}}\right|+
\left|z_{k_2}+z_{\hat{k_2}}\right|+\ldots \le
\varepsilon + \varepsilon + \ldots
\end{align*} So this way I don't prove that the series converges. Is there some other way to prove it or it doesn't hold at all? (Anyway I think it was not a good idea to use the absolute value there...). And a second question on that: If $\left\{a_n\right\}_{n\in \mathbb{N}}$ is a real sequence such that $\sum_{j\in\mathbb{N}}a_n$ converges then $\sum_{j\in\mathbb{N}}a_nz_n$ converges (following the same procedure described above). Can we somehow loosen the conditions on $\left\{a_n\right\}_{n\in \mathbb{N}}$ ? Are there weaker conditions on the sequence $a_n$ so that the series will converge? Update 1: Does this series converge: \begin{align*}
\sum_{n\in\mathbb{N}}e^{2\pi\vartheta\alpha}
\end{align*} with $\alpha\in \mathbb{R} - \mathbb{Q}$ ?","['complex-numbers', 'convergence-divergence', 'sequences-and-series', 'complex-analysis']"
28558,What do $\pi$ and $e$ stand for in the normal distribution formula?,"I'm a beginner in mathematics and there is one thing that I've been wondering about recently. The formula for the normal distribution is: $$f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\displaystyle{\frac{(x-\mu)^2}{2\sigma^2}}},$$ However, what are $e$ and $\pi$ doing there? $\pi$ is about circles and the ratio to its diameter, for example. $e$ is mostly about exponential functions, specifically about the fact that $\frac{\mathrm{d}}{\mathrm{d}x} e^x = e^x$. It is my firm conviction that proofs and articles are available, but could someone perhaps  shed some light on this and please explain in a more 'informal' language what they stand for here? I'm very curious to know as those numbers have very different meanings as far as I'm concerned.","['pi', 'normal-distribution', 'probability-distributions', 'probability']"
28562,"Solution to the ""near-Gaussian"" integral $\int_{0}^{\infty} e^{- \Lambda \sqrt{(z^2+a)^2+b^2}}\mathrm{d}z$","In the course of my research I have come across the following integral: $\int_{0}^{\infty}  e^{- \Lambda \sqrt{(z^2+a)^2+b^2}}\mathrm{d}z$. This initially looks like it should be solvable by some suitable change of variable which will allow you to get it into a gaussian form. Unfortunately after trying for awhile I cannot find one. The constants $a$ and $b$ are combinations of parameters $s \in (0,\infty)$, $x \in [0,\infty)$: $a = s^2-x^2$ and $b = 2sx$. So the integral can be rewritten as: $\int_{0}^{\infty}  e^{- \Lambda \sqrt{z^4 +Az^2 +B}}\mathrm{d}z$, with $A = 2(s^2-x^2)$ and $B = s^4 + x^4 + 2s^2x^2$. Any help with a solution would be much appreciated. Edit: I forgot to mention that the $s = kL$ where $L$ is a fixed value and I will eventually take a limit in which $k \rightarrow 0$, so there are opportunities for series expansions. I have tried the obvious by expanding the square root in powers of $k$, but there are then convergence issues in the region $|z-x| < k$. A closed form solution is looking less and less likely as I try all the tricks I know and scour Gradshteyn, so a first term in $k$ (Edit: I originally said in $a$, that was a mistake) would also be much appreciated.","['definite-integrals', 'improper-integrals', 'integration']"
28568,Bijection between an open and a closed interval,"Recently, I answered to this problem: Given $a<b\in \mathbb{R}$ , find explicitly a bijection $f(x)$ from $]a,b[$ to $[a,b]$ . using an ""iterative construction"" (see below the rule). My question is: is it possible to solve the problem finding a less exotic function? I mean: I know such a bijection cannot be monotone, nor globally continuous; but my $f(x)$ has a lot of jumps... Hence, can one do without so many discontinuities? W.l.o.g. assume $a=-1$ and $b=1$ (the general case can be handled by translation and rescaling).
Let: ( 1 ) $X_0:=]-1,-\frac{1}{2}] \cup [\frac{1}{2} ,1[$ , and ( 2 ) $f_0(x):=\begin{cases}
    -x-\frac{3}{2} &\text{, if } -1<x\leq -\frac{1}{2} \\ -x+\frac{3}{2} &\text{,
    if } \frac{1}{2}\leq
    x<1\\ 0 &\text{, otherwise} \end{cases}$ , so that the graph of $f_0(x)$ is made of two segments (parallel to the line $y=x$ ) and one segment laying on the $x$ axis; then define by induction: ( 3 ) $X_{n+1}:=\frac{1}{2} X_n$ , and ( 4 ) $f_{n+1}(x):= \frac{1}{2} f_n(2 x)$ for $n\in \mathbb{N}$ (hence $X_n=\frac{1}{2^n} X_0$ and $f_n=\frac{1}{2^n} f_0(2^n x)$ ). Then the function $f:]-1,1[\to \mathbb{R}$ : ( 5 ) $f(x):=\sum_{n=0}^{+\infty} f_n(x)$ is a bijection from $]-1,1[$ to $[-1,1]$ . Proof : i . First of all, note that $\{ X_n\}_{n\in \mathbb{N}}$ is a pairwise disjoint covering of $]-1,1[\setminus \{ 0\}$ . Moreover the range of each $f_n(x)$ is $f_n(]-1,1[)=[-\frac{1}{2^n}, -\frac{1}{2^{n+1}}[\cup \{ 0\} \cup ]\frac{1}{2^{n+1}}, \frac{1}{2^n}]$ . ii . Let $x\in ]-1,1[$ . If $x=0$ , then $f(x)=0$ by ( 5 ). If $x\neq 0$ , then there exists only one $\nu\in \mathbb{N}$ s.t. $x\in X_\nu$ , hence $f(x)=f_\nu (x)$ . Therefore $f(x)$ is well defined . iii . By i and ii , $f(x)\lesseqgtr 0$ for $x\lesseqgtr 0$ and the range of $f(x)$ is: $f(]-1,1[)=\bigcup_{n\in \mathbb{N}} f(]-1,1[) =[-1,1]$ , therefore $f(x)$ is surjective. iv . On the other hand, if $x\neq y \in ]-1,1[$ , then: if there exists $\nu \in \mathbb{N}$ s.t. $x,y\in X_\nu$ , then $f(x)=f_\nu (x)\neq f_\nu (y)=f(y)$ (for $f_\nu (x)$ restrited to $X_\nu$ is injective); if $x\in X_\nu$ and $y\in X_\mu$ , then $f(x)=f_\nu (x)\neq f_\mu(y)=f(y)$ (for the restriction of $f_\nu (x)$ to $X_\nu$ and of $f_\mu(x)$ to $X_\mu$ have disjoint ranges); finally if $x=0\neq y$ , then $f(x)=0\neq f(y)$ (because of ii ).
Therefore $f(x)$ is injective, hence a bijection between $]-1,1[$ and $[-1,1]$ . $\square$","['calculus', 'elementary-set-theory']"
28594,Complex conjugate of $z$ without knowing $z=x+i y$,"Is it possible to determine (and if so, how) the complex conjugate $\bar{z}$ of $z$, if you don't already know that $z = x + i y$? I think you can use $\log(z)$ to get the angle, and therefore the ratio of $y$ and $x$. But how do you get $|z|$, the radius? How then to get $r$ (so that $x = {\rm Re}(z) = r \cos(\log(z))$ and $y = {\rm Im}(z) = r \sin(\log(z))$)? (this is related to How to express in closed form? , namely you can compute Re and Im using the conjugate, but then how do you reduce the conjugate itself fully to elementary functions (if at all))","['complex-numbers', 'complex-analysis']"
28599,Testing convergence of $\sum\limits_{n=2}^{\infty} \frac{\cos{\log{n}}}{n \cdot \log{n}}$,"Does the series:  $$\sum\limits_{n=2}^{\infty} \frac{\cos(\log{n})}{n \cdot \log{n}}$$ converge or diverge? I know that $|\cos(\log{n})| \leq 1$, but I really cannot apply it here. Any ideas on how to attack this problem","['real-analysis', 'analysis']"
28612,Mistake in Dugundji chapter IX section 11 example 3?,"A family of pseudometrics defined on a set gives rise to a uniform structure on that set. Moreover (up to uniform equivalence, anyway) every uniform structure arises this way. Let $A$ and $B$ be families of pseudometrics defined on sets $X$ and $Y$ respectively. There ought to be a way to characterize the uniform continuity of maps $X$ to $Y$ directly in terms of $A$ and $B$ and I thought I knew the correct way to do this but, when I scanned through the relevant sections in Dugundji's Topology to confirm my suspicions, I came across: ""$f: X \to Y$ is uniformly continuous if for each $\beta \in B$ and each $\epsilon > 0$, there exists an $\alpha \in A$ and a $\delta > 0$ such that if $\alpha(x,x') < \delta$, then $\beta(f(x),f(x')) < \epsilon$."" This seems stronger than uniform continuity to me. When I tried to work out the right condition I found that one might, given an $\epsilon > 0$ and a $\beta \in B$, only be able to find a $\delta>0$ and finitely many pseudometrics $\alpha_1,\ldots,\alpha_n \in A$ such that $(\alpha_i(x,x') < \delta \ \ \forall i) \Rightarrow \beta(f(x),f(x')) < \epsilon$. Thoughts? Edit: I don't think there's much more one can say in response to this question. If $\mathscr{D}$ is a family of pseudometrics on $X$, one can safely replace $\mathscr{D}$ with the family $\mathscr{D}^+$  consisting of all pseudometrics of the form $(x,y) \mapsto \max_{d \in \mathscr{F}} d(x,y)$ where  $\mathscr{F}$ is some finite subset of $\mathscr{D}$ without inducing a finer uniform structure on $X$. As remarked by Theo Buehler in the comments, if we assume, with no loss of generality so far as the uniform structure on $X$ is concerned, that my $A = A^+$ then Dugundji's definition of uniform continuity is equivalent to the clumsier one. In summary, there is a small inaccuracy in Dugundji which can be easily corrected by the addition of a single superscript $+$ to make explicit an assumption that the author (rather harmlessly I might add) probably considered implicit. I would call the matter settled. If anyone disagrees, feel free to say so, but you will do so too late to save my hapless copy of Dugundji - which has already been permanently defaced!",['general-topology']
28619,question on second mean value theorem for integration,"I am wondering two different forms of the second mean value theorem for integration. For the one in wikipedia , I also wonder where I can find a proof. The form I read from another reference is that:
$G:[a,b]\to \mathbb{R}$ is a monotonic function and $\phi : [a, b] \to \mathbb{R}$ is an integrable function, then there exists a number $x$ in $[a, b]$ such that $$\int_a^b {G(t)\phi(t)}dt=G(a)\int_a^x{\phi(t)dt}+G(b)\int_x^b{\phi(t)dt}.$$ Note the difference in where $x$ lies and whether to use the one-side limit for $G(a)$ and $G(b)$. To me, I think whether $G$ is right continuous at $a$ or left continuous at $b$ should not matter the integral $$\int_a^b {G(t)\phi(t)}dt$$, but clearly $G(a)$ vs. $G(a+)$ can be quite different. I am wondering if anyone can give me a proof that the two are equivalent. Thanks.","['integration', 'analysis']"
28645,What are the properties of $\Re f(x)$ for an analytical function $f$ if $\Im f(x)\ge 0 \forall x\in\mathbb R_0^+$?,"Background: In Electrodynamics, the scalar permittivity $\epsilon(\omega)$ relates the Electric displacement field $\vec D$ to the electric field $\vec E$ as $\vec D=\epsilon\vec E$ when assuming a linear, isotropic medium. Causality requires that in time-space the Fourier transform $\tilde\epsilon(t)$ must vanish for $t<0$ (i.e. the future cannot influence $\vec D$), resulting in $\epsilon(\omega)$ being analytic and that the Kramers-Kronig relation (basically using the Hilbert transform ) can be used to relate the real and imaginary parts of $\epsilon$. The imaginary part describes absorption and must thus not be negative 1 , does this put any additional restraints on $\Re \epsilon$? So in summary: For $\epsilon(\omega)$ analytical (because the Fourier transform $\tilde\epsilon(t)$ vanishes for $t<0$) and $\forall\omega>0:\Im\epsilon(\omega)\ge0$, what are properties of $\Re\epsilon(\omega)$ for $\omega>0$? 1) or positive, depending on convention as in whether the time dependence is $e^{+i\omega t}$ or $e^{-i\omega t}$ edit also, since $\vec E$ and $\vec D$ are real valued in time-space, $\epsilon(-\omega)=\epsilon(\omega)^*$",['complex-analysis']
28646,Good introductory books on homological algebra,"Which books would you recommend, for self-studying homological algebra, to a beginning graduate (or advanced undergraduate) student who has background in ring theory, modules, basic commutative algebra (some of Atiyah & Macdonald's book) and some (basic) field theory? I would especially like to hear your opinions on the following books: A Course On Homological Algebra / P. J Hilton and U. Stambach Introduction to Homological Algebra / Szen-Tsen Hu Notes on Homological Algebra / Rotman But other recommendations will also be appreciated.","['abstract-algebra', 'homological-algebra', 'big-list', 'reference-request', 'learning']"
28650,Coefficients of characteristic polynomial of a matrix,"For a given $n \times n$-matrix $A$, and $J\subseteq\{1,...,n\}$ let us denote by $A[J]$ its principal minor formed by the columns and rows with indices from $J$. If the characteristic polynomial of $A$ is $x^n+a_{n-1}x^{n-1}+\cdots+a_1x+a_0$, then why $$a_k=(-1)^{n-k}\sum_{|J|=n-k}A[J],$$
that is, why is each coefficient the sum of the appropriately sized principal minors of $A$?","['matrices', 'linear-algebra', 'characteristic-polynomial', 'determinant']"
28654,Spectrum of the operator,Let $T$ be an operator on Hilbert space. Define $\sigma(T)=\lbrace \lambda\in \mathbb{C} | \lambda I - T~\textrm{is not invertible}\rbrace$. How can I prove that $\sigma(T^n)=\lbrace \lambda^n|\lambda\in \sigma(T)\rbrace$?,['functional-analysis']
28666,Surjective and Unbounded functions,"Every surjective function from $\mathbb{R}$ to $\mathbb{R}$ is unbounded. Every unbounded function from $\mathbb{R}$ to $\mathbb{R}$ is surjective. Is it possible for either of these statements to be false? I have a feeling there is some counterexample that I am missing but I cannot figure it out. My understanding is that if a function is unbounded then for all $M\in\mathbb{R}$ there is an $x$ such that $|f(x)| \gt M$. And the definition of surjective is that for all $b \in Y$, there exists an $x \in X$ such that $f(x) = b$. Clearly if we have some $M$ in the image of this function there is an $x$ that exists such that $f(x) = M$ by the definition of surjective. I dont know if I am thinking of this correctly, intuition needed. Thanks.",['functions']
28670,Operator whose spectrum is given compact set,"Let $A\subset \mathbb{C}$ be a compact subset. Since $A$ is compact and metric space, it is separable, say $\overline{\lbrace a_n\rbrace_{n=1}^\infty}=A$. Let $\mathcal{l}^2(\mathbb{Z})$ be the Hilbert space consisting of $L^2$-summable sequences and $\lbrace e_n\rbrace_{n=1}^\infty$ be the canonical basis of $\mathcal{l}^2(\mathbb{Z})$. Define an operator $T\colon\mathcal{l}^2(\mathbb{Z})\to\mathcal{l}^2(\mathbb{Z})$ by sending $e_n$ to $a_ne_n$. I want to prove that $A=\sigma(T)$, where $\sigma(T)$ is the spectrum of $T$. What I can prove is that $A=\overline{\lbrace a_n\rbrace_{n=1}^\infty}\subset \sigma(T)$ because each $a_n$ is an eigenvalue of $T$ and $\sigma(T)$ is closed. How can I prove the other inclusion, namely $\sigma(T)\subset A$?",['functional-analysis']
28686,Final topology of $\mathbb R^\infty$ with respect to $\mathbb R^n$/ weak topology,"I'm stuck on this example in Boto v. Querenburgs ""Mengentheoretische Topologie"" and I would really appreciate some insight from our more topologically savvy friends on here. =) Let $I$ be an ordered set, and let $(X_j, \mathcal T_j)_{j \in I}$ be a family of topological spaces, such that for $j<k$, $j,k \in I$ we have: $$X_j \subset X_k, \quad \mathcal T_j = \mathcal T_k|X_j$$ i.e. the topology on $X_j$ is induced by the injection $i_{jk}: X_j \hookrightarrow X_k$ from the topology on $X_k$. On $X = \bigcup_{j\in I} X_j$ let $\mathcal T \; $  be the final topology with respect to $(i_j: X_j \hookrightarrow X)_{j\in I}$; This is called the weak topology on $X$. Example: Let $X_n = \mathbb R^n$, and let $X = \mathbb R^\infty$.
Then a sequence $(x_k = (x_{k1}, x_{k2}, \dots ))_{k\in \mathbb N}$ converges to $x = (x_1, x_2, \dots )$ iff for any fixed $n$ the sequence $(x_{kn})_{k \in \mathbb N}$ converges to $x_n$. Now I don't see why the last statement should be true. First off: To get a feel for this new kind of topology, I tried comparing it to other topologies on $\mathbb R^\infty$ known to me (and I think in the following already I must be making a mistake...) Suppose $U = \prod_{n \in \mathbb N} U_n$ is open in the box topology on $\mathbb R^\infty$, i.e. $U_n \subset \mathbb R$ is open for all $n$. Then I think $U$ is also open in the weak topology: (I suppose $\mathbb R^j$ should be identified with $\mathbb R^j \times 0 \times 0 \times \dots \subset \mathbb R^\infty$, right?) But then $i_j^{-1}(U) = \emptyset$ if $0 \notin U_n$ for some $n>j$ and $i_j^{-1}(U) = U_1 \times \dots \times U_j$ otherwise. Both of which are open in $\mathbb R^j$, thus $U$ should be open in the final topology w.r.t. the inclusions $i_j$. Now consider the sequence $$x_j = \underset{\text{j-th component}}{(0, \dots, 0,\underbrace{1}, 0, 0, \dots)}$$ Clearly $x_j$ converges to $(0, 0,\dots)$ componentwise, but $x_j$ does not converge in the box topology, hence neither in the finer topology introduced in the example (the weak topology). So where is the above argument wrong? What am I not understanding correctly about this topology? Many, many thanks in advance for any useful comments and answers. Regards, S.L.",['general-topology']
28690,"Which is the ""proper"" definition of a geodesic curve?","I'm taking a course on differential geometry, and up until now I'd always thought that the definition of a geodesic is (loosely speaking) a curve on a surface with the minimal length between its endpoints. My professor, taking his lead from do Carmo, however, defines it as any curve whose geodesic curvature $\kappa_g=0$ . We showed that this is equivalent to satisfying the following pair of nonlinear ordinary differential equations: $$(\boldsymbol{E}u' + \boldsymbol{F}v')' = \frac12(\boldsymbol{E}_u(u')^2 + 2\boldsymbol{F}_uu'v' + \boldsymbol{G}_u(v')^2)$$ $$(\boldsymbol{F}u' + \boldsymbol{G}v')' = \frac12(\boldsymbol{E}_v(u')^2 + 2\boldsymbol{F}_vu'v' + \boldsymbol{G}_v(v')^2)$$ We then went through an incredibly painful calculation on the length of the family of curves $\gamma_\lambda$ to show that geodesics (i.e, those curves satisfying the geodesic equations above) are critical points of the functional $$\displaystyle\mathcal{L}(\lambda) = \int_a^b{\left\|\frac{d\gamma_\lambda}{dt}\right\| dt},$$ which is the length of the curve. Therefore, according to my professor's (and the textbook's) definition, geodesics are not necessarily length-minimizing, just critical points of $\mathcal{L}$ . Therefore, on a sphere, two non-antipodal points have two geodesics: the obvious length-minimizing one, and the other one going the long way around the sphere (which is, in this case, a saddle point of $\mathcal{L}$ ). This is not just an oversight on my professor's part, he explicitly brought attention to this fact. My question is, what are the advantages and disadvantages of these two conflicting definitions? I still see the length-minimizing one almost everywhere. On a related note, the fact that a geodesic is only a critical point, not necessarily a minimum, leaves open the possibility of a geodesic actually being the longest path between two points. Are there any situations where this is actually possible? It seems you could always perturb a curve slightly to stay within the image of a chart while still increasing its length infinitesimally. Are there some weird spaces where this is not the case?","['differential-geometry', 'definition']"
28707,Applying Mean Value Theorem to formula,"As I understand it, the mean value theorem is where $${f}'(c)=\frac{f(b)-f(a)}{b-a}$$ if $f$ is continuous on the open interval (a, b) and differentiable on the closed interval [a,b]. A problem in the current homework set on WebAssign has me confused.  Given $f(x)=x^{7}$ on the closed interval   [0, 1], determine whether the MVT can be applied to the closed interval [a,b]. Since $f(x)= x^{7}$ has a similar profile to a cubic function graph, and it is differentiable to ${f}'(x)= 7x^{6}$, it passes two criteria for the MVT. Now, solving the MVT formula: $${f}'(x)=\frac{f(b)-f(a)}{b-a} \Rightarrow \frac{[1^{7}]-[0^{7}]}{1-0} \Rightarrow \frac{1-0}{1-0} \Rightarrow \frac{1}{1}= 1$$ Now, I need to find a number $c$ between 0 and 1 that f'(c)=1.  However, the only whole number possiblities from the [0, 1] interval produce 
$${f}'(0)= 7(0)^{6}= 0 \neq 1$$ 
$${f}'(1)= 7(1)^{6}= 7 \neq 1$$ Am I missing something here?  The question has two parts: identify whether the MVT is applicable, and find the numbers $c$ that fit the theorem on the interval.  The closest number for $c$ that I've found that works is 0.724, which gives a value of 1.00815, but it doesn't match 1 perfectly.","['calculus', 'analysis']"
28709,Sample sizes for an infinite population,"I've poked about in some other questions , and I'm no sure how to deal with my problem and my knowledge of statistics has atrophied. Particularly that I'm trying to choose a sample size for a population that I don't know the size of (potentially infinite, but it could be 10,000's or 100,000's or more). How do I choose a sample size that will give me a meaningful answer. Is it reasonable just to plug in a very large number, and see what comes out - does it approach a limit? My real world problem is this: I have two computer systems (Able and Baker). My user community believes Able is faster than Baker. I can run a simple test on both, and see how long it takes to run one each. However, there are inconsistencies in performance (probably do to the network, which will have spikes in activity and I unfortunately can't removed from the test). Baker will be running for years into the future, so I have no idea how many transactions will run in it over its lifetime. Assuming the performance issues caused by the network are random, how many tests do I have to run each on Able and Baker to to be 90% confident that Able is faster than Baker? Perhaps I'm asking the wrong question? Should I just be finding the average of a 100 tests on Able and 100 tests on Baker and compare? Can I make than number 100 smaller (to say like 20)","['statistics', 'probability']"
28713,What is the root linear coefficient theorem?,"MathWorld gives the root linear coefficient theorem as The sum of the reciprocals of roots of an equation equals the negative coefficient of the linear term in the Maclaurin series. The theorem appears to me to be false as stated.  For example, the equation $e^x = 0$ has no roots, yet (taking the Maclaurin series of $e^x$) the root linear coefficient theorem claims that the sum of the reciprocals of these nonexistent roots would be $-1$. Is MathWorld missing some hypotheses?  Or is there something happening in the complex plane that I'm not aware of?  The MathWorld entry also says to see Vieta's formulas , but those are for polynomials and not Maclaurin series. The only real information I could find from a Google search on ""root linear coefficient theorem"" was this statement (from Robert Israel of UBC): This won't work in general for non-polynomials (e.g. try it for
  $p(x) exp(x)$.  For a rational function such that $0$ is neither a root nor
  a pole, you want to take the sum of the reciprocals of the roots minus the
  sum of the reciprocals of the poles (again counting multiplicity). O.K., so it won't work for non-polynomials, and for rational functions you have to include the poles. But then why is MathWorld applying it to $\sin z/z$ in this ""proof"" that $\zeta(2) = \sum_{n=1}^{\infty} \frac{1}{n^2} = \pi^2/6$ ?  (Start near eq. (18).) The value $\zeta(2)$ can also be found simply using the root linear coefficient theorem. Consider the equation $\sin z=0$ and expand $\sin$ in a Maclaurin series
  $$\sin z = z- \frac{z^3}{3!}+\frac{z^5}{5!}+ \ldots =0$$
  $$0	=	1-\frac{z^2}{3!}+\frac{z^4}{5!}+ \ldots$$
  $$	=	1-\frac{w}{3!}+\frac{w^2}{5!}+ \ldots,$$ where $w=z^2$. But the zeros of $\sin z$ occur at $z=\pi, 2\pi, 3\pi, \ldots$, or $w=\pi^2, (2\pi)^2, \ldots$.  Therefore, the sum of the [reciprocals of the] roots equals the [negative of the] coefficient of the leading term
  $$\frac{1}{\pi^2}+\frac{1}{(2\pi)^2}+\frac{1}{(3\pi)^2}+ \ldots =\frac{1}{3!}=\frac{1}{6},$$ which can be rearranged to yield
  $$\zeta(2)=\frac{\pi^2}{6}.$$ (This is where I ran across the root linear coefficient theorem in the first place.) Could someone enlighten me with respect to these questions: Is MathWorld just wrong? Am I missing something here? What is the correct statement of the root linear coefficient theorem?","['sequences-and-series', 'real-analysis', 'analysis']"
28714,analytic functions from square to unit disk,"Let $f$ be an analytic function from $\{z; -1 < \Re(z) < 1, -1 < \Im(z) < 1\}$ to $\{z; |z| < 1\}$. If $f(0)=0$ and $f$ is one-one and onto, should $f(i\ z)=i\ f(z)$ for each $z$? I tried to show that $f(i\ z)-i\ f(z)$ is a constant, but it seems that I could not use  Liouville Theorem. Thank you very much.",['complex-analysis']
28715,Wreath product and solvability,"A paper I'm reading claims that the smallest class of monoids which contains $\mathbb{Z}$ and is closed under finite direct product and block product only contains solvable monoids.  I think that a proof that solvability of groups is closed under wreath product would be of great help to understand why this is true.  Would anyone know where I can find such a proof? In the ""converse direction"", I would be really interested in reading a proof of the following fact: Any solvable group is in the variety generated by a wreath product of cyclics (taken from Barrington and Thérien, Non-uniform automata over groups (1987) ).","['wreath-product', 'reference-request', 'group-theory', 'monoid']"
28716,Number of Permutations in a Bin Packing Problem,"I'm having a discussion with a co-worker over the number of permutations in a bin packing problems as follows. There are two bins each of which can hold 6 cu ft.  A package can be from 1 - 6 cu feet, there can be from 1 - 12 packages.  How many permutations are possible? It's been a great many years since either of us have done any formal math but it seems to me the problem space isn't all that large due to the constraints, though the problem is NP complete.  We found a few web pages talking about different approaches to bin packing but nothing really on how to determine number of possible permutations.","['packing-problem', 'combinatorics']"
28719,How to decompose displaced Hermite-Gauss function into higher order HGs?,"The Hermite-Gauss functions appear commonly in physics.  These functions are formed from the product of a Hermite polynomial and a Gaussian: $$ u_n(x) = \left(\frac{2}{\pi w_0^2}\right)^{1/4} \frac{1}{\sqrt{n! 2^n}} H_n\left(\frac{\sqrt{2}x}{w_0}\right)\exp\left\{-\left(\frac{x}{w_0}\right)^2\right\}$$ and are orthonormal: $$ \int_{-\infty}^{\infty} u_n(x) u_m(x) dx = \delta_{n,m}$$ In a paper ( 2004 J. Opt. B 6 495 ) I found the following identity, which gives the decomposition of a displaced mode $u_0(x-a)$ in terms of a series over high-order Hermite-Gauss functions $u_n(x)$ : $$ \int_{-\infty}^{\infty} u_0(x - a) u_n(x) dx 
= \frac{a^n}{w_0^n \sqrt{n!}} \exp\left\{ -\frac{a^2}{2 w_0^2}\right\} $$ How is this derived? (In addition to deriving it by hand, I would like to know how to coax Mathematica into giving it.) EDIT: Here is an animation showing the decomposition of a displaced Gaussian into higher-order Hermite-Gauss functions (modes):","['special-functions', 'sequences-and-series']"
28720,Tempered distribution concentrated in a lower dimensional manifold,"Question: What can you conclude about a tempered distribution $G\ \in\ S'(R^n)$ that is concentrated in some k-dimensional manifold $M\ \subset\ R^n$ (for k < n)?  More specifically, is there a result analogous to the following n=1 result? $n=1$ result (hope I remember it correctly): Let $\ S(R)\ $ be the set of Schwartz functions ($C^\infty$ functions $f:\ R\ \to\ C\ $ s.t. $\ f^{(n)}$ goes to 0 at infinity faster than any inverse power of x (for n=0, 1, ...)).  Let $\ S'(R)\ $ be the set of tempered distributions.  $G\ \in\ S'(R)$ is said to be concentrated in a set $A\ \subset\ R\ $ iff $\forall\ \phi\ \in\ S(R)$ that vanishes on some open set $B\ \supset\ A\ $, $G(\phi)\ =\ 0$. Suppose $\ G\ $ is concentrated in {$\ x\ $}, for some $x\ \in\ R$.  Then $\exists\ c_0,\ ...\ c_L\ \in\ C\ $ s.t. $\ G\ $ = $\sum_{j=0}^L\ c_j\ \delta_x^{(j)}$. [where $\delta_x^{(j)}\ (\phi)\ \equiv\ (-1)^j\ \phi^{(j)}(x)\ $]","['distribution-theory', 'functional-analysis']"
28727,Dual of a dual cone,"Any hint on how to prove the following please: Let $K$ be a convex cone, and $K^*$ its dual cone. Prove that $K^{**}$ is the closure of $K$. Thanks!","['topological-vector-spaces', 'convex-analysis', 'functional-analysis']"
28751,Proof of upper-tail inequality for standard normal distribution,"$X \sim \mathcal{N}(0,1)$, then to show that for $x > 0$,
$$
\mathbb{P}(X>x) \leq \frac{\exp(-x^2/2)}{x \sqrt{2 \pi}} \>.
$$","['statistics', 'probability-distributions', 'inequality', 'faq']"
28773,How to calculate the eigenvector corresponding to zero eigenvalue,"How can the eigenvector corresponding to zero eigenvalue be found out? I was trying with the following simple matrix in Matlab: $$A=\left[\begin{array}{ccc}1 & -2 & 3 \\ 2 & -3 & 4 \\ 3 & -4 & 5 \end{array}\right] \; .$$ In matlab computations, the matrix seemed nearly singular with one of the eigenvalues very close to zero (3e-15). That means the usual shifted inverse power methods for finding out the unit eigenvector corresponding to an eigenvalue won't work. But Matlab returns an eigenvector corresponding to 0. How? Basically, I would like to develop a program to compute this eigenvector given any singular matrix. What algorithm should I use? Edit: (1) Edited to reflect that the 'nearly singular' comment was corresponding to Matlab calculation.
(2) Edited to specify the actual question.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
28779,Minimum variance unbiased estimator for scale parameter of a certain gamma distribution,"Let $X_1, X_2, ..., X_n$ be a random sample from a distribution with p.d.f., $$f(x;\theta)=\theta^2xe^{-x\theta} ; 0<x<\infty, \theta>0$$ Obtain minimum variance unbiased estimator of $\theta$ and examine whether it is attained? MY WORK: Using MLE i have found the estimator for $\theta=\frac{2}{\bar{x}}$ Or as $$X\sim \operatorname{Gamma}(2, \theta)$$ So $E(X)=2\theta$ , $E(\frac{X}{2})=\theta$ so can I take $\frac {X}{2}$ as unbiased estimator of $\theta$ .
I'm stuck and confused need some help. Thank u.","['parameter-estimation', 'statistics', 'expected-value', 'probability-distributions', 'statistical-inference']"
28788,Proof of $f = g \in L^1_{loc}$ if $f$ and $g$ act equally on $C_c^\infty$,"Let $f$ and $g$ be locally integrable, say on $R^n$ (for arbitrary open domains, just extend trivially). Suppose $\forall \phi \in C_c^\infty : \int f \phi dx = \int g \phi dx$. Let $K = supp(\phi)$. If $f,g \in L^2(K)$, we see by Hilbert space theory $f = g$ almost everywhere, as the $C_c^\infty(K)$ is dense in $L^2(K)$. So the theorem holds for $f,g \in L^2_{loc}$. But $L^\infty_{loc} \subset L^2_{loc}$ is dense in $L^1_{loc}$ (in the respective topology), hence we have $f = g$ almost everywhere even for $L^1_{loc}$. I haven't seen this proof in literature, and I wonder whether there is a gap. If that is the case, do you know a better proof?",['functional-analysis']
28802,How to express $(1+x+x^2+\cdots+x^m)^n$ as a power series?,Is it possible to express $(1+x+x^2+\cdots+x^m)^n$ as a power series?,"['power-series', 'real-analysis']"
28813,How to improve linear interpolation in 3D,"in one physics problem, there is a cube. A computationally expensive function can be calculated inside the cube. But one needs to do the calculation faster and to know for a given point inside the cube, an approxmated value, which depends on the 8 vertices. For that I tried linear interpolation in 3D and it works more or less. Now I woule like to try the same idea but with parabolic, polynomic or other better interpolation option (in terms of accuracy), always in 3D. What do you suggest? PS: Of course, for doing more than linear interpolation you need more points. Forgot to say that this cube is surrounded by lots of other cubes of the same dimensions, where the function has also been calculated.","['geometry', 'calculus', 'physics', 'polynomials']"
28821,"Divergence of Gradient of the Unit Normal, and Curvature Equation","The curvature equation for implicit functions, level sets is usually given in two forms: one is the divergence of the gradient of the unit normal: $\kappa = \bigtriangledown \cdot \frac{\bigtriangledown \phi}{|\bigtriangledown \phi|}$ and the other is $\kappa = \frac{\phi_{xx}\phi_y^2 - 2\phi_x\phi_y\phi_{xy} + \phi_{yy}\phi_x^2}{(\phi_x^2+\phi_y^2)^{3/2}}$ How do we derive the second equation from the first?","['multivariable-calculus', 'curvature', 'calculus', 'differential-geometry']"
28825,Decomposition of $\Bbb R^n$ as union of countable disjoint closed balls and a null set,"This is a problem in Frank Jones's Lebesgue integration on Euclidean space (p.57), $$\mathbb{R}^n = N \cup \bigcup_{k=1}^\infty \overline{B}_k$$ where $\lambda(N)=0$, and the closed balls are disjoint. could any one give some hints?","['general-topology', 'measure-theory', 'real-analysis']"
28830,"Does $\sum{\frac{\sin{(nx)}}{n}}$ converge uniformly for all $x$ in $[0,2\pi]$","This question arises because of a problem I was doing (Bartle 3rd edition, section 9.4 problem 3). It was like this. Given $a_n$ a decreasing sequence of positive numbers and suppose that $$\sum_{n=0}^{\infty}{a_n \sin{(nx)}}$$ Converge uniformly (It doesn't specify the domain, so I guess is for every x). Prove that $n a_n \to 0$. Clearly $\frac{1}{n}$ fits the description of $a_n$, and $n \frac{1}{n} \to 1 \neq 0$, so this would prove that there is a mistake in the problem if $\sum{\frac{\sin{(nx)}}{n}}$ converge uniformly for all $x$. So my question is if $\sum{\frac{\sin{(nx)}}{n}}$ converge uniformly for every $x$. (I know that the series converge uniformly for every x in $[\delta, 2\pi - \delta]$, for $0 < \delta <2\pi$ by using the Dirichlet criterion.)","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
28852,Bounded denominators for modular forms,"I recently saw a conjecture that a modular form is a congruence modular form if and only if it has bounded denominators. I wonder if one direction or the other is already known to be true? EDIT: For completeness, here is the answer I received at Math Overflow when I asked a while back. https://mathoverflow.net/questions/59498/bounded-denominators-for-modular-forms","['modular-forms', 'number-theory']"
28858,Is an intersection of two splitting fields a splitting field?,"Let $F$ be a field, and let $K_1$, $K_2$ be two splitting fields over $F$ (Suppose they are contained in a larger field $K$). Is $K_1\cap K_2$ necessarily a splitting field over $F$? The statement is true if $K_1$ and $K_2$ are finite extensions of $F$, however I'm not sure how to prove (or disprove) the statement in the general case. Thanks.","['abstract-algebra', 'field-theory']"
28867,compact symplectic manifolds,Why there is no compact symplectic submanifold with dimension greater than 2 in $\mathbb{R}^{2n}$ ?,"['geometry', 'symplectic-geometry', 'differential-geometry']"
28879,Step in Proof of Lemma in Narkiewicz _Elementary and Analytic Theory of Algebraic Numbers_,"I was looking at the proof of Lemma 2.17 in Narkiewicz Elementary and Analytic Theory of Algebraic Numbers but don't understand a step. Let $p$ be a rational prime, $a$ be an algebraic integer of degree $n$, $K = \mathbb{Q}(a)$, and $R_K$ be the ring of integers of $K$.  Assume the minimal polynomial of $a$ is Eisenstein with respect to $p$. It is asserted that if $p$ divides $[R_K:\mathbb{Z}[a]]$ (the index of $a$ in $R_K$), then there exists $\xi$ in $R_K$ of the form
$$
\xi = (b_0 + b_1 a + \cdots + b_{n-1}a^{n-1})/p
$$
with the $b_i$'s integers not all divisble by $p$. I don't see why this assertion is true.  Can someone please help?","['algebraic-number-theory', 'number-theory']"
28884,Prove that $f(x)=e^x$ is Riemann integrable using Riemann sums,Does anyone know how to prove that $f(x)=e^x$ is Riemann integrable using right or left hand Riemann sums?,"['riemann-sum', 'integration', 'real-analysis']"
28886,powerset total order,"Suppose that $S$ is a well-ordered set; how can we prove that the following is a total order on the power set of $S$?
$$A\prec B\Longleftrightarrow \min(A\triangle B)\in A.$$",['elementary-set-theory']
28893,Hecke operators on modular forms,"Would you please explain the importance of Hecke operators on modular forms?  I am studying modular forms mostly on my own and I have a pretty good understanding up to Hecke operators.  So, I just wonder why we care about them.","['modular-forms', 'number-theory']"
28905,Expected time to roll all $1$ through $6$ on a die,"What is the average number of times it would it take to roll a fair $6$ -sided die and get all numbers on the die?  The order in which the numbers appear does not matter. I had this questions explained to me by a professor (not math professor), but it was not clear in the explanation.  We were given the answer $(1-(\frac56)^n)^6 = .5$ or $n = 12.152$ Can someone please explain this to me, possibly with a link to a general topic?","['dice', 'coupon-collector', 'probability']"
28925,Explicit formula for space curves,"I've been looking a bit into differential geometry and have gotten stuck on a question: Given a function $f,$ is there a way to find the explicit space curve which has $f$ as both it's curvature and torsion? I've been able to find a formula for a plane curve with curvature $k(s),$ but extending to what seems to be the next simplest case (curvature = torsion) has been difficult. Any hints on how to proceed?",['differential-geometry']
28930,another balls and bins question,"I've seen many variations of this problem but I can't find a good, thorough explanation on how to solve it. I'm not just looking for a solution, but a step-by-step explanation on how to derive the solution. So the problem at hand is: You have m balls and n bins. Consider throwing each ball into a bin uniformly and at random. What is the expected number of bins that are empty, in terms of m and n? What is the expected number of bins that contain exactly 1 ball, in terms of m and n? How would I approach solving this problem? Thanks!",['probability']
28948,How is it that this shape can converge to what looks like a triangle but has a different perimeter?,"I had this strange notion some time ago, and I recently wrote a blog post about it , as a mere curiosity. I don't really consider it a ""serious"" mathematical question; but out of interest, I wondered if someone on this site could shed some light on what principle might be underlying the idea. Basically, I envisioned a ""pseudo-triangle"" consisting of two straight edges and one jagged ""edge"" (not really an edge , since it's jagged, but I'm calling it that anyway): The above shape has 4 steps, its area is 10, and its perimeter is 16. Now let's increase the number of steps to 8: This shape has an area of 9 and a perimeter of 16. Now, without me having to write out a formal proof, I think it's pretty clear that as the number of steps increases, the area will approach 8 while the perimeter will remain constant at 16. And the resulting shape will look like this: Ultimately, there's nothing really ""mysterious"" about this; the shape above is not a triangle, and so it shouldn't be surprising that it doesn't have quite the same properties as a triangle. However, it does approach the same area as an analogous triangle; and, more to the point, it just seems odd . Is there a concept in mathematics that describes this phenomenon (for lack of a better word)? That is, the effect of some kind of mathematical entity (e.g., a shape) converging to what resembles another entity but differs from it in a critically important and counter-intuitive way (in this case, having a completely different perimeter)? If it seems that I'm having trouble articulating this question, that's because I am. But hopefully someone out there can see what I'm getting at and shed some light on the issue for me.","['geometry', 'approximation', 'infinity']"
28956,Solvable subgroups of $S_p$ of order divisible by $p$,"This question is from Dummit and Foote's Abstract Algebra, page 638, question 20. It gives a nice paragraph of hints that basically guides one through the problem, but I'm very stuck at a crucial junction. Any useful hint is much appreciated. I have detailed what I know and what I do not know, but if you just want the tl;dr, just read the question, which is the following sentence. ""Let $p$ be a prime. Show that any solvable subgroup of $S_p$ of order divisible by $p$ is contained in the normalizer of a Sylow $p$-subgroup of $S_p$. [...] Hint: Let $G \leq S_p$ be a solvable subgroup of order divisible by $p$. Then $G$ contains a $p$-cycle, hence is transitive on $\{1, \ldots, p\}$. Let $H < G$ be the stabilizer in $G$ of the element $1$, so $H$ has index $p$ in $G$. Show that $H$ contains no nontrivial normal subgroups of $G$ (note the conjugates of $H$ are the stabilizers of the other points). Let $G^{(n-1)}$ be the last nontrivial subgroup in the derived series for $G$. Show that $H \cap G^{(n-1)} = 1$ and conclude that $\lvert G^{(n-1)}\rvert = p$, so that the Sylow $p$-subgroup of $G$ (which is also a Sylow $p$-subgroup of $S_p$) is normal in $G$."" Here are the things I do know: $H$ has an order that divides $(p-1)!$ since it has index $p$ in $G$, and $G$ has order $pu$ for some $u$ not divisible by $p$. Everything up to and excluding the part where I am asked to prove that $H \cap G^{(n-1)} = 1$. I know how to prove the next part where I'm asked to prove that $|G^{(n-1)}| = p$ provided I know how to do that previous part! I know that $\lvert S_p \rvert = p!$, so any Sylow $p$-subgroup of $S_p$ has size $p^1 = p$, since no other factors of $p!$ can contain $p$ as a prime factor. Now here are the things I do not know: I am terribly stuck at the step where I have to show $H \cap G^{(n-1)} = 1$. I tried showing that this is normal, so I can use the result immediately preceding to conclude that it is trivial. But I'm having major problems. I may just be missing something extremely obvious. Even if I can do that part, the next part asks us to conclude that this Sylow $p$-subgroup is normal in $G$, which I can't immediately see how to derive. I'm assuming ``this Sylow $p$-subgroup'' is referring to the size $p$ subgroup $G^{(n-1)}$---it has the right size to be a Sylow $p$-subgroup.","['galois-theory', 'group-theory', 'abstract-algebra']"
28994,Simple asymptotic function,"(I have seen this question but it is too complicated for my needs, and my math skills are not good enough to convert the answer.) I am writing a game and I need a way to increase the armor of the character in a meaningful way: I want the increase in armor to mean a decrease in damage taken (meaning an increase in damage absorbed), approaching but never reaching 100% absorption. In other words, I need a simple, polynomial function f(x) so that $$\lim\limits_{x \to \infty} f(x) = 1$$ (x will never be less than zero.) Of course, the question has trivial answers, like f(x) = 0.9; I need a non-trivial one, preferably one where f(x) grows faster at first and then ""slows down"". [Edit] Removed the polynomial requirement... duh! [Edit] I found something stupidly simple... $$x / (x + 5)$$ This is close enough to my requirements. Unfortunately, I have absolutely no idea how to allocate the ""solution"" checkmark, so I'll pick the responder with less points, and add a +1 to the other. I hope it won't create problems.","['functions', 'polynomials']"
