question_id,title,body,tags
1538455,How many different ways can I get up a flight (of stairs) with 11 steps?,"You can climb either $1$ or $2$ stairs at a time, at any given time. How many ways can you get up $11$ stairs? I've tried using different cases to solve this. So I did: Case 1 : All $1$ steps --> $11  $steps --> number of combinations = $1$ Case 2 : $9 $one steps, $1$ two step --> number of combinations = $\binom{n}{2} $?? Case 3 : $7$ one steps, $2$ two steps --> number of combinations? I don't understand how to proceed further. Is there any easier way to do this?",['combinatorics']
1538539,$a$ is a stationary point of a scalar field $f$ whose Hessian at $a$ has two opposite sign diagonal entries. Is $a$ a saddle point?,"Let $S$ be some subset of $\mathbb R^n$ , $f:S \to \mathbb R$ is a function such that for some $a \in S$ , there is an open ball $B(a)\subseteq S$ such that $f$ has all second order partial derivatives (continuous) in $B(a)$ , $\nabla f(a)=O $ and the Hessian of $f$ at $a$ has at least  two opposite sign diagonal entries . Then how to prove that $a$ is a saddle point of $f$ ?","['hessian-matrix', 'partial-derivative', 'multivariable-calculus']"
1538543,"The line $\frac{x+6}{5}=\frac{y+10}{3}=\frac{z+14}{8}$ is the hypotenuse of an isosceles right angled triangle whose opposite vertex is $(7,2,4)$","The line $\dfrac{x+6}{5}=\dfrac{y+10}{3}=\dfrac{z+14}{8}$ is the hypotenuse of an isosceles right angled triangle whose opposite vertex is $(7,2,4)$.Find the equation of the remaining sides. My Attempt: Let the right angled triangle be $ABC$,right angled at $B(7,2,4).$The remaining two sides $AB$ and $BC$ of the right angled triangle will pass through the vertex $B(7,2,4)$. Let the equation of  $AB$ be $\dfrac{x-7}{a_1}=\dfrac{y-2}{b_1}=\dfrac{z-4}{c_1}$ and the equation of $BC$ be $\dfrac{x-7}{a_2}=\dfrac{y-2}{b_2}=\dfrac{z-4}{c_2}$ As $AB$ and $BC$ are perpendicular to each other. So $a_1a_2+b_1b_2+c_1c_2=0.....(1)$ Also as the triangle is a isosceles right triangle, so angle between $AC$ and 
$BC$ will be same as the angle between $CA$ and $BA$.  Let it be $\theta$. So $\cos\theta=\dfrac{5a_1+3b_1+8c_1}{\sqrt{5^2+3^2+8^2}\sqrt{a_1^2+b_1^2+c_1^2}}=\dfrac{5a_2+3b_2+8c_2}{\sqrt{5^2+3^2+8^2}\sqrt{a_2^2+b_2^2+c_2^2}}$ Squaring both sides we get $\dfrac{(5a_1+3b_1+8c_1)^2}{a_1^2+b_1^2+c_1^2}=\dfrac{(5a_2+3b_2+8c_2)^2}{a_2^2+b_2^2+c_2^2}.............(2)$ But I am stuck here.I don't know how to find $a_1,b_1,c_1,a_2,b_2$ and $c_2$. Please help me. Thanks.","['3d', 'geometry', 'analytic-geometry']"
1538561,Vector bundles on $M/G$,"Let $M$ be an algebraic variety with an action of algebraic group $G$, and $V$ be a linear representation of $G$. Then one can consider the set $E = (M \times V) / G$. If there is a quotient space $M/G$, the one gets the $G$-equivariant morphism $E \to M/G$. When is $E$ a vector bundle over $M/G$ and is the structure of vector bundle on it unique?",['algebraic-geometry']
1538563,Basic question: Global sections of structure sheaf is a field,"$X$ is projective and reduced over a field $k$ (not necessarily algebraically closed). Why is $H^0(X,\mathcal{O}_X)$ a field? Are there any good lecture notes on this (valuative criteria, properness, projectiveness, completeness)? I really don't have time to go through EGA/SGA.","['algebraic-geometry', 'reference-request', 'vector-bundles', 'sheaf-theory']"
1538590,Algebraic solutions of a differential equation.,"Given a differential equation $y' = (1/x)(y^2 + y^3)$. My question is how does one go about finding the solutions of this differential equation which are algebraic over the field $\Bbb{C}(x)$,if any. Notation- $\Bbb{C}(x)$ is the quotient field of $\Bbb{C}[x]$.","['galois-theory', 'differential-algebra', 'ordinary-differential-equations']"
1538605,Finding matrix such that it has a given kernel.,"Find matrix $A$ over $\Bbb Z_3$ such that $\ker A = \left\langle\begin{pmatrix}
  1\\
  2\\
  0\\
  1\\
  2\\
  \end{pmatrix},\begin{pmatrix}
  1\\
  1\\
  1\\
  1\\
  1\\
  \end{pmatrix},\begin{pmatrix}
  1\\
  0\\
  2\\
  1\\
  0\\
  \end{pmatrix}\right\rangle$ . I am confused by this problem. I guess I am not sure what the task is.
I know how to calculate $\ker A$ for a matrix but what is this telling me? $\ker A$ means $Ax = 0$ but how do you proceed when you have the set of solutions like this instead of the matrix? Thank you.","['finite-fields', 'linear-algebra', 'matrices']"
1538641,Proving two matrices are equal,A friend and I are having some trouble with a linear algebra problem: Let $A$ and $B$ be square matrices with dimensions $n\times n$ Prove or disprove: If $A^2=B^2$ then $A=B$ or $A=-B$ It seems to be true but the rest of my class insists it's false - I can't find an example where this isn't the case - can someone shed some light on this? Thanks!,"['linear-algebra', 'matrices']"
1538682,How do I evaluate the following definite integral: $\int^1_0\frac{x^2\ln x}{\sqrt{1-x^2}}dx$?,"$$\int^1_0\frac{x^2\ln x}{\sqrt{1-x^2}}dx$$
I tried using by parts but it didn't help. Also none of the properties of definite integral helps.","['calculus', 'definite-integrals', 'integration']"
1538687,Solving a Nonlinear ODE,"Does this problem have a unique solution in $[t_0,t_1]$? $$ \ddot x(t)=\alpha(1-t)\cos(x(t))$$ 
$$x(t_0)=0$$
$$ \dot x(t_1)=0$$ Thanks!","['boundary-value-problem', 'ordinary-differential-equations']"
1538747,Sequential continuity between metric and topological space,"I'm trying to prove that a map between a metric and topological space is continuous at x iff for every converging sequence in the materic space, the map of the sequence converges in the topological space. I was able to prove the forward case without too much trouble, but I'm having trouble proving that converging sequences imply continuity. I've assumed for contradiction that the map is not continuous and then invoked the definition of continuity to say there is an open neighborhood of x whose preimage is closed, but I'm having trouble piecing together a contradiction on convergence from this.","['analysis', 'general-topology']"
1538764,Visualizing linear transformations on vector fields,"I'm trying to figure out what it means to apply a linear transformation to a vector field geometrically.  So I start with the easiest geometrically interesting transformation: a rotation. Using StreamPlot in WolframAlpha I see that applying the transformation $T(x,y) = (-y,x) = \pmatrix{\cos(90^\circ) & -\sin(90^\circ) \\ \sin(90^\circ) & \cos(90^\circ)}\pmatrix{x \\ y}$ yields exactly what I'd expect: circular stream lines: However when I try a different angle, say $\pi / 6$, then I have $T(x,y)=\left(\frac{\sqrt{3}}{2}x-\frac12 y, \frac12 x + \frac{\sqrt{3}}{2}y\right)$.  But the picture no longer looks like circles, but spirals : Clearly something's wrong with my interpretation here.  Why do the stream lines look the way they do?  How can I imagine linear transformations being applied to vector fields?","['visualization', 'vectors', 'vector-analysis', 'multivariable-calculus']"
1538788,2-torsion points in a curve with genus 2,"Let X be a genus 2 curve with affine equation y^2 = f(x), where f is a polynomial of degree 6. Write $P_1, ..., P_6$ for the points on X(C) with y=0. Then why every $P_i-P_j$ is a 2-torsion points in Jacobian $Pic^0(X)$ and they are distinct? (Since there are 16 2-torsion points, we find all of them.) My professor says one can prove that $P_i-P_j$ is a 2-torsion points by some argument involving divisor, and he also mentions one can prove $P_i-P_j$ are distinct by using the fact that a genus 2 curve has one degree-2 map to $\mathbb P^1$. I just have no idea, so I am not able to say more. Could any one help me?","['elliptic-curves', 'algebraic-geometry', 'arithmetic-geometry']"
1538801,"Show that if $f$ is continuous on [0,1], then: $\int_0^\frac\pi 2 f(\sin x)dx=\int_0^\frac\pi 2 f(\cos x)dx= \frac12\int_0^\pi f(\sin x)dx$","Also part of the problem: Show that:
$$\int_0^{n\pi} f(\cos^2 x)dx=n\int_0^{\pi} f(\cos^2 x)dx$$ It may be important to note that I have taken a few semester of calculus prior to this, and that this problem was brought up in my math analysis course. Additionally, my class has only taught as far as Riemannian integrals. My work:
A) For the first part of this problem ($\int_0^\frac\pi 2 f(\sin x)dx=\int_0^\frac\pi 2 f(\cos x)= \frac12\int_0^\pi f(\sin x)$ ), I intuitively know that the areas under the curve will be equal to each other because the values at the endpoints will be the same, provided that $f(\sin x)=\sin x$ and $f(\cos x)=\cos x$. However, I have two dilemmas: 1) The fact that the situation deals with a function of $\sin x$, not $\sin x$ itself. To give an example, $f(a)$ could be equal to $a^2 + 8a^{-1} + \csc a^3$ and I feel like this completely flaws my logic (note that the above function was just an example to show how arbitrary the function is). In the grand scheme of things, I don't believe this will prove to be too much of an issue, I just don't know how I can prove that it won't be an issue 2) I am unaware of how to definitively prove that the area under each curve will be the same.  Suppose $f(a)= a$ for the sake of argument, then the value $f(x)$ at each of the endpoints will be the same, but this does not tell anything about the areas under the curve B) I believe that I understand the second part of the problem. Because $x^2$ will never be negative, the graph of $f(x)$ will either always be negative or always be positive. Therefore, the value of the integral is entirely dependent on $n$. I am primarily concerned with the two dilemmas in the first part of the problem, but any additional assistance is always welcome!","['analysis', 'calculus', 'integration']"
1538855,"How discontinuous does a $[a,b] \to (c,d)$ bijection have to be?","I know that bijection from $[a,b]$ to $(c,d)$ can't be continuous, but I'm wondering if such a function could exist if it was discontinuous at just countable points, and if this isn't possible, why?",['real-analysis']
1538863,Matrix functions of a non-diagonalizable matrix,"Let $A$ be the following $3 \times 3$ matrix: $$
A =
\begin{pmatrix}
1 & 1 & 0 \\
0 & 1 & 0 \\
0 & 0 & -1 \\
\end{pmatrix}
$$ I'm supposed to calculate $A^n$, where $n \in \Bbb R$, $\exp(tA)$ and $\sin(\pi A)$. Obviously $A$ is not diagonalizable. Since we haven't had anything about Jordan decomposition in the lecture, I'm not sure how to solve this. The eigenvalues $\lambda_1 = -1 , \lambda_{2,3} = 1$ can be read off. I tried to expand the two eigenvectors into a orthonormal basis, i.e.: $$
\mathbf{x}_{\lambda_1} =
\begin{pmatrix}
0 \\
0 \\
1 \\
\end{pmatrix} \qquad
\mathbf{x}_{\lambda_2} =
\begin{pmatrix}
1 \\
0 \\
0 \\
\end{pmatrix} \qquad
\mathbf{x}_3 =
\begin{pmatrix}
0 \\
1 \\
0 \\
\end{pmatrix}
$$ But I'm rather unsure how to continue. I suspect that $$
A^n =
\begin{pmatrix}
1 & n & 0 \\
0 & 1 & 0 \\
0 & 0 & (-1)^n \\
\end{pmatrix} \qquad \text{for} \qquad n \in \Bbb N_0,
$$ But how to expand this to $n \in \Bbb R$? In general, how can I solve such a problem of matrix functions, if I've not heard anything about Jordan decomposition? EDIT: Thanks for your help. I could show that the above mentioned matrix for $A^n$ is correct even for $n \in \Bbb Z$. The two other functions are straightforward then. If someone has an idea or hint about $A^n$ for $n \notin \Bbb Z$, i would appreciate it.","['jordan-normal-form', 'linear-algebra', 'matrices']"
1538901,Is there any group with self-normalizing Sylow $p$-subgroup?,"Let $G$ be a finite group and assume that $G$ is not a $p$-group. I am looking for an example that for every Sylow subgroup $P$ of $G$, $$N_G(P)=P$$. I have doubt whether such groups exist.","['group-theory', 'finite-groups']"
1538920,Every separable Banach space is isomorphic to $\ell_1/A$ for some closed $A\subset \ell_1$,"How to prove the following mind-blowing fact? Let $X$ be a separable Banach space and let $\ell_1$ be the space of all absolutely summable scalar sequences. Then there exists such closed subspace $A\subset \ell_1$ that factor space $\ell_1/A$ and $X$ are isomorphic as normed spaces. Edit: So what, this is like a classification up to isomorphism of all separable Banach spaces? Each separable Banach space corresponds to some closed subspace of $\ell_1$?","['convergence-divergence', 'banach-spaces', 'functional-analysis', 'normed-spaces']"
1538976,Confusion about Differentiability with partial derivatives,"Theorem: Let $A ⊂ R^n$ be open and $f: A ⊂ R^n → R^m$.  Suppose $f = (f_1,...,f_m)$.  If each of the partials  $\frac{∂f_j}{∂x_i}$ exists and is continuous on $A$, then $f$ is differentiable on A. Use the Theorem to show that $f(x,y)$ defined by $f(x,y) = \frac{xy}{\sqrt{x^2+y^2}}$, $(x,y)≠(0,0)$ and $f(x,y)=0, (x,y)=(0,0)$ is differentiable at $(0,0)$ So I first found $\frac{∂f}{∂x}$ = $\frac{xy(2x^2+2y^2-x^2y)}{(x^2+y^2)\sqrt{x^2+y^2}}$ but that is not continuous at $(0,0)$.  So I'm not sure how I can prove $f$ is differentiable with this theorem.","['partial-derivative', 'analysis', 'continuity', 'derivatives']"
1538979,Computing the Lie derivative of a metric,"Suppose $g$ is a Riemannian metric on a manifold, and $X$ is a smooth vector field. Show that
$$(\mathcal{L}_Xg)_{ij} = \nabla_iX_j + \nabla_jX_i$$ I've been able to obtain that $$(\mathcal{L}_Xg)(\frac{\partial}{\partial x^i},\frac{\partial}{\partial x^j} ) = g(\nabla_{\frac{\partial}{\partial x^i}}X, \frac{\partial}{\partial x^j}) + g(\frac{\partial}{\partial x^i}, \nabla_{\frac{\partial}{\partial x^j}}X)$$ but when I expand this in local coordinates I get a bunch of pesky $g_{ij}$ terms that I can't make disappear. It also seems somewhat odd to me that the Lie derivative of a metric yields an answer that is a sum of derivatives of component functions of $X$. This makes it seem like the Lie Derivative of a metric is not dependent on the metric. Maybe I have misunderstood the author's notation, but I would like to see an explicit computation from my step to the final answer, as most sources I've found seem to gloss over it.","['differential-geometry', 'riemannian-geometry']"
1538985,Finding zeta function of an elliptic curve [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Let $p \equiv 3 \pmod 4$ be a prime, and $E/F_{p^r}$ be
  the elliptic curve given by $y^2 = x^3 − x$ . Find the zeta-function of $E/F_p$ and use it to determine $|E(F_{p^r} )|$ for all r>0.","['elliptic-curves', 'zeta-functions', 'number-theory', 'finite-fields']"
1539020,Why do complex eigenvalues/eigenvectors cause rotation?,"I am trying to understand the intuition behind eigenvalues/eigenvectors through the lens of repeated matrix multiplication: Given a $2\times2$ matrix $M$ and $2D$ vector $v$, multiplying $v$ repeatedly 
with $M$ causes the result ($M^n v$) to gravitate towards one of the eigenspaces of $M$ because: $$M^n v = M^n(\alpha x_1 + \beta x_2) = (\alpha \lambda_1^n x_1 + \beta \lambda_2^n x_2)$$ where $x_1$ and $x_2$ are eigenvectors of $M$ and $\lambda_1$ and $\lambda_2$ the corresponding eigenvalues. As $n$ gets larger $M^n v$ will gravitate towards either $\alpha \lambda_1^n x_1$ or $\beta \lambda_2^n x_2$, whichever has the dominant eigenvalue. assuming: $v = \alpha x_1 + \beta x_2$ So the above is a way to connect the abstract concept of eigenvalue/eigenvector to something concrete: what happens when you apply a matrix over and over to a vector. However, the intuition breaks down for me with complex eigenvectors. I know repeated multiplication by a matrix with complex eigenvectors causes the result to either spiral outwards or inwards. Is there simple math such as above to see why? Edit: I know similar questions have been asked before, but I ask in the context of repeated matrix multiplication","['eigenvalues-eigenvectors', 'linear-algebra']"
1539023,"Prove that if $a_n$ contains no convergent subsequences, then |$a_n$| approaches infinity, as n approaches infinity.","I first approached the problem using contradiction. Suppose that |$a_n$| does not approach infinity. 
Case 1: The sequence will converge to some L, and thus be bounded. 
Case 2: The sequence will neither converge nor diverge, thus it will be bounded. (I'm having trouble explaining case 2) For both cases, we can use the Bolzano-Weiestrass Theorem, thus |$a_n$| has a convergent subsequence.
(How can I show that $a_n$ will also have a convergent subsequence?) This is a contradiction to the given statement, thus |$a_n$| will approach infinity. This was how I approached the problem, but there's a few problems with it. Please let me know if there is a better way or how I can improve mine. Thank you in advance! OR Again using contradiction, I can say that there exists an M > 0 for all N in the natural numbers, where there exists n > N such that we have |$a_n$| ≤ M. Let n = $a_ni$. Then |$a_ni$| ≤ M. Thus -M < $a_ni$ < M. This sequence is bounded, thus, by the Bolzano-Weiestrass theorem, it has convergent subsequences. CONTRADICTION","['sequences-and-series', 'convergence-divergence', 'real-analysis']"
1539051,"Proving an eliptic curve is cyclic, and determining it's order","I need a solution with an explanation for the following. Thanks! Let $E/F_q$ be an elliptic curve and let $P ∈ E(F_q)$ be a point a. if $n=ord(P)>1/2(q^{0.5}+1)^2$ prove that $E(F_q)$ is cyclic of order n b. if $n=ord(P)>1/m(q^{0.5}+1)^2$ for $m>1$, what can be said about $|E(F_q)|$?","['elliptic-curves', 'number-theory', 'group-theory', 'cyclic-groups']"
1539082,How to prove this infinite product identity?,"How can I prove the following identity?
$$\large\prod_{k=1}^\infty\frac1{1-2^{1-2k}}=\sum_{m=0}^\infty\left(2^{-\frac{m^2+m}{2}}\prod_{n=1}^\infty\frac{1-2^{-m-n}}{1-2^{-n}}\right)$$
Numerically both sides evaluate to
$$2.38423102903137172414989928867839723877...$$","['calculus', 'geometric-progressions', 'sequences-and-series', 'arithmetic-progressions', 'infinite-product']"
1539090,How would I construct a hyper-cube in .5 dimensions? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question As the title suggests, I want a hyper-cube in half of one dimension.  If you could provide an image, that would be superb.  I have no idea how I would do this; I can't connect hyper-cubes of a lower level to make this.  Help much appreciated.",['geometry']
1539109,The Light beam Problem.,"I am puzzled with a problem like this.  Suppose you have $N$ lighthouses, each of which has $360/N$ angle of light. Suppose they are arbitrarily allocated on totally flat endless earth (i.e. $R^2$). Can you adjust the lighthouses in a way, that there is no dark place left. You cannot change the places obviously, you can only rotate them.
First it sounds easy, but not really!","['geometry', 'calculus']"
1539116,How can this theorem about weakly measurable functions on $\sigma$-finite measure spaces be deduced from the finite measure space case?,"I am reading a theorem about measurability of vector-valued functions in a note on functional analysis: Theorem 3.6.1. If $X$ is a separable, metrizable locally convex space, $(\Omega, \Sigma, \mu)$ is a $\sigma$-finite measure space, and $f : \Omega \to X$ is weakly measurable, then $f$ is strongly measurable. The proof begins We can restrict ourselves to the case of finite measures. Could somebody explain how the general case (when $(\Omega,\Sigma,\mu)$ is ""$\sigma$-finite"") can be deduced from the ""finite"" case? For completeness, here are some definitions. Let $( \Omega, \Sigma, \mu )$ be a measure space, let $X$ be a Hausdorff locally convex space, and let $f : \Omega \to X$. We say that $f$ is measurable if $f^{-1} (G) \in \Sigma$ for every open set $G \subset X$. $f$ is weakly measurable if $\varphi \circ f$ is measurable for every $\varphi \in X^*$. $f$ is strongly measurable if there exist simple functions $f_n : \Omega \to X$ such that $f(\omega) = \lim_{n \to \infty} f_n(\omega)$ for $\mu$-almost every $\omega \in \Omega$. (A simple function is a measurable function which takes only finitely many values.) An image of proof, and surrounding definitions, can be seen here .","['locally-convex-spaces', 'measure-theory', 'real-analysis', 'functional-analysis', 'topological-vector-spaces']"
1539117,Prove that a polytope is closed,"Let the polytope defined by $$S:=co \left\{ x_1,x_2,...,x_k \right\}$$ where $x_1,x_2,...,x_k \in \mathbb{R^n}$ and $co \left \{... \right \}$ is the convex Hull. Prove that S i closed. I tried the following. I want to show that $S=cl(S)$ I've proved that for all set $S \subseteq cl(S)$. Now I want to prove that $cl(S)\subseteq S$. I know that $cl(S) = int(S) \cup bd(S)$ So, taking $x \in cl(S)$. If $x \in int(S)$ then its clear that $x \in S$. If $x \in bd(S)$ is not clear but intuitively the border is the convex combination between $x_i$ and $x_j$ (in pairs) and $i,j=1,2,...,k$. I don't know how to rite it formally and how to prove that my intuition about the border is actually $bd(S)$","['convex-optimization', 'convex-analysis', 'linear-algebra']"
1539126,Initial values problem with absolute value,"I've some doubts about initial values problems involving differential equation with absolute values. For example if I have a differential equation like $y'=|x+1|$ with initial condition $y(3)=-2$, since $3>-1$ I can trascurate the absolute value and solve $y'=x+1$, is it correct? But if the condition is for instance $y(-1)=2$ then I must consider the two different cases? That is, $y'=x+1$ if $x>-1$ and $y'=-x-1$ if $x<-1$ Is this the right way to solve this kind of problems?","['initial-value-problems', 'calculus', 'absolute-value', 'ordinary-differential-equations']"
1539151,Orthogonal similarity transformation,"Can someone please show me how to diagonalize a matrix such as the one below using an orthogonal similarity transformation?
$$
        \begin{bmatrix}
        2 & 1 & 1 \\
        1 & 2 & 1 \\
        1 & 1 & 2 \\
        \end{bmatrix}
$$ I have been looking everywhere online to find an example of orthogonal similarity transformations but I can't find any. Am I searching for the wrong thing? Is there another name for it, because similarity transformations seem awfully close to Jordan canonical form? Please help. Thank you in advance.","['linear-algebra', 'matrices']"
1539175,Polya's urn (martingale),"Suppose you have an urn containing one red ball and one green ball. You draw one at random; if the ball is red, put it back in the urn with an additional red ball , otherwise put it back and add a green ball . Repeat this procedure and let the random variable $X_n$ be the number of red balls in the urn after n draws.
Let $Y_n=\frac{1}{n+2}X_n$. Find $\mathbb{\mathbb{\textrm{E}}}\left(Y_{n}\right)$ and prove that $Y_n$ is a martingale with respect to $X_n$. MY ATTEMPT: We have $\mathbb{\mathbb{\textrm{E}}}\left(\left.X_{n+1}\right|X_{n}\right)=X_{n}+\dfrac{X_{n}}{n+2}=\dfrac{n+3}{n+2}X_{n}$, so $\mathbb{\mathbb{\textrm{E}}}\left(\left.Y_{n+1}\right|X_{n}\right)=\dfrac{1}{n+3}\mathbb{\mathbb{\textrm{E}}}\left(\left.X_{n+1}\right|X_{n}\right)=\dfrac{1}{n+3}\cdot\dfrac{n+3}{n+2}X_{n}=\dfrac{1}{n+2}\cdot X_{n}=Y_{n}$ It's ok? And, can you help me to find $\mathbb{\mathbb{\textrm{E}}}\left(Y_{n}\right)$?","['probability-theory', 'conditional-expectation', 'expectation', 'stochastic-processes', 'martingales']"
1539180,Hartshorne problem III.5.2(a),"Consider problem III.5.2(a) in Hartshorne's Algebraic Geometry : Let $X$ be a projective scheme over a field $k$, let $\mathcal O_X(1)$
  be a very ample invertible sheaf on $X$ over $k$, and let $\mathcal F$
  be a coherent sheaf on $X$. Show that there is a polynomial $P(z)\in
 \mathbb Q[z]$, such that $\chi(\mathcal F(n))=P(n)$ for all
  $n\in\mathbb Z$. We call $P$ the Hilbert polynomial of $\mathcal F$
  with respect to the sheaf $\mathcal O_X(1)$. [Hints: Use induction on
  dim Supp $\mathcal F$, general properties of numerical polynomials (I,
  7.3), and suitable exact sequences $$0\rightarrow \mathcal R \rightarrow \mathcal F(-1)\rightarrow
 \mathcal F \rightarrow \mathcal L \rightarrow 0.]$$ By III.2.10, we may suppose $X=\mathbb P^n_k$ for some $n$. I think the key difficulty here is describing an injective map $\alpha:\mathcal F(-1)\rightarrow \mathcal F$. For any map between these two sheaves, we get an exact sequence of the kind in the hint by taking the relevant quotient and kernel sheaves. If this map is injective, we get a short exact sequence, and we can use the additivity of the Euler characteristic on short exact sequences to say
$$\chi(\mathcal F) - \chi(\mathcal F(-1))=  \chi (\mathcal L).$$
Tensoring with $\mathcal O(n)$ gives
$$\chi(\mathcal F(n)) - \chi(\mathcal F(n-1))=  \chi (\mathcal L(n)).$$
So if $\chi(L(n))$ is eventually a polynomial, then $\mathcal F(n)$ is too, by I.7.3(b). If we construct $\alpha$ in such a way that $\mathcal L$ has support at least one dimension less than the support of $\mathcal F$, we're done by induction on the dimension of the support. (We also need to handle dimension $0$ separately, and I omit this discussion because it's not too hard.) So, let me say what I think $\alpha$ should be. Consider a global section $s$ of $O(1)$. Tensoring with $s$ gives a map $\mathcal F(-1)\rightarrow \mathcal F$. In some affine chart, this looks like multiplication by $s$, I think. Now we examine the stalks of the quotient sheaf. The first map, on the level of stalks, is an isomorphism when $s\mathcal F_p=\mathcal F_p$, which happens in particular when $s$ is a unit in the local ring $\mathcal O_{X,p}$, and this happens when $s_p \notin \mathfrak m_p$. Then the support of $\mathcal L$ is contained in the intersection of the support of $\mathcal F$ and $V(s)$, where we consider $s$ as a linear polynomial over $k$. So clearly the dimension of the support goes down by at least one, since hyperplanes have codimension $1$. It seems tricker to choose $s$ so that $\alpha$ is injective. By II.5.15, we know that every (quasi)coherent sheaf on projective space over a field is given as $\tilde M$ for some module $M$ over $k[x_i]$. We need $s$ to not be a zero-divisor. Recall that the set of zero-divisors is exactly the union of the associated primes, and that there are finitely many associated primes. But primes represent subvarieties, and these subvarieties might be impossible to avoid. For example, if a few hyperplanes are among the associate primes, then there’s no way we can choose $\alpha$ to be injective. Is this analysis correct? If so, it seems we need to analyze $\mathcal R$ more carefully and not just suppose it disappears. Could we say something like, its support lies on the union of the associated primes, which are all subvarieties of codimension at least 1, so we are finished by an argument similar to the one indicated above? Explicitly, we would have $$\chi(\mathcal F(n)) - \chi(\mathcal F(n-1))=  \chi (\mathcal L(n)) - \chi (\mathcal R(n)),$$
and then we can induct on dimension and apply I.7.3(b).","['algebraic-geometry', 'schemes', 'hilbert-polynomial']"
1539183,Number of Non-Abelian Groups of order 21,"My goal is to count the number of non-abelian groups of order 21, up to isomorphism. I also need to show their presentations. This is a homework assignment, so I would appreciate leads rather than answers as much as possible. However, since we have to do this for all groups up to order 60, it would be nice to hear approaches that work more generally. Here is the work that I have done so far, which may or may not be correct. Consider the possibilities for presentations $G=<a,b|a^7=b^3=1, bab^{-1}=a^i>$, where $i=\{1,2,3,4,5,6,7\}$. If $i=7$, then $a^7=1$, so $bab^{-1}=1$, so $ba=b$, implying that $a$ is the identity, a contradiction. If $i=1$, then $G$ is abelian, so that is not a possibility either. Let $H=<a>$ and $K=<b>$. H is the normal sylow 7-subgroup of $G$ and K is the sylow-3 subgroup of $G$. This is because $n_7\equiv{}1\pmod{7}$, and so $n_7$ must be 1. Observe that H and K also satisfy the 3 properties of semi-direct product. Let $\phi:K\rightarrow{}Aut(H)$ be a nontrivial homomorphism. The nontrivial homomorphisms are then $a\mapsto{a^2},a\mapsto{a^3},a\mapsto{a^4}, a\mapsto{a^5}, a\mapsto{a^6}$. The first homomorphism has order 3, the second homomorphism has order 6, the third has order 3, the fourth has order 6, the fifth has order 2. So, only the 1st and 3rd homomorphism are possible since they divide the order of the group. The others are not possible because that would imply an element has an order that does not divide the order of the group. The first has presentation $<a,b|a^7=b^3=1, bab^{-1}=a^2>$. The other has presentation $<a,b|a^7=b^3=1, bab^{-1}=a^4>$. I looked online and there is only one non-abelian group of order 21. How do I show that these two presentations result in the same group, or that one of these presentations is an impossibility?","['sylow-theory', 'group-theory', 'finite-groups']"
1539186,Find the limit of the vector as $~t~$ approaches $~0~$?,"Here's the vector: $$e^{-6t}~\vec i + \frac{t^2}{\sin^2t}~\vec j + \sin(6t)~\vec k$$ Don't I just take the limit as $t$ approaches $0$ from each individual component? As a result, I got $~\vec i + \vec j~$ , which was apparently incorrect.","['vectors', 'multivariable-calculus', 'limits']"
1539193,Integrating a second derivative,Admit that $f$ has a second derivative find the integer $m$. $$m\int_{0}^{1}xf''(2x)dx = \int_0^2xf''(x)dx$$ So I took $2x=u$ where $du/dx=2$ and I plugged in the integral getting $$\frac{m}{4}\int_{0}^{2}uf''(u)du =\frac{1}{4} \int_{0}^{2} uf''(\frac{u}{2})du$$ How do I proceed from here?,"['derivatives', 'substitution', 'integration']"
1539196,Defining maps from modules over different rings,"Let $R$ and $S$ be rings, $M$ be an $R$-module, $N$ be an $S$-module, and $\varphi:R\sqcup M\rightarrow S\sqcup N$ be a map satisfying: $\varphi\restriction_R:R\rightarrow S$ is a ring homomorphism $\varphi\restriction_M:M\rightarrow N$ is a group homomorphism $\varphi(am)=\varphi(a)\varphi(m)$ for all $a\in R, m\in M$ In the special case where $R=S$ and $\varphi\restriction_R$ is the identity map on R, we call $\varphi\restriction_M$ an $R$-module homomorphism. Is there something I am missing that makes $R$-module homomorphisms the only interesting example of such maps, or is this a worthy generalization? Could we define the category Mod of modules using these maps as the morphisms?","['abstract-algebra', 'category-theory', 'modules', 'ring-theory']"
1539215,Infinite closed subset of $S^1$ such that the squaring map is a bijection?,Is there an infinite closed subset $X$ of the unit circle in $\mathbb C$ such that the squaring map induces a bijection from $X$ to itself?,['analysis']
1539217,Power series method for differential equation $x^2y''+y=0$,"I tried to solve $(x^2)y''+y=0$ using power series, but I cannot get the general solution or the relation at least $$(x^2)y''+y=0 $$ $$ \sum_{n=2}^\infty c_n n(n-1) x^n + \sum_{n=0}^\infty c_n x^n$$ $$ \sum_{k=2}^\infty c_k k(k-1) x^k + \sum_{k=0}^\infty c_k x^k$$ $$ c_o+c_1+\sum_{k=2}^\infty c_k (k^2-k+1) x^k$$ From here $C_0=0$, $C_1=0$, $ C_k(k^2 -k+1)=0$. Is this right? How can I get a recurrence relation for coefficients or the general solution of the series?","['power-series', 'ordinary-differential-equations']"
1539257,The limit of a sequence of uniform bounded variation functions in $L_1$ is almost sure a bounded variation function,"Let  $\{f_n\} $be a sequence of functions on $[a,b] $ that $\sup V^b_a (f_n) \le C$, if $f_n \rightarrow f $ in $L_1$ ,Prove that $f $ equals to a bounded variation function almost every where. I really have no idea to solve this, is there any hint ? Thanks a lot.","['sequences-and-series', 'real-analysis', 'functional-analysis', 'bounded-variation']"
1539268,"Elementary Geometry Problems, which require Non-geometric Tools","In number theory, many problems are easy to state but difficult to solve within number theory. Are there Elementary (solved and unsolved) problems from Euclid's geometry, which are difficult to solve only by Euclid's axioms or the newest Hilbert's axioms on geometry? Had Euclid or Archimedes posed such propositions which they couldn't prove? (The most well known such questions are from Ruler and compass constructions, and doubling cube. I would like to see the problems, whose statements are like the propositions of Euclid, but whose proof requires non-geometry tools.)","['geometry', 'soft-question']"
1539271,"Probability of exactly two pairs share a birthday, and each pair shares different birthday","This isn't for homework, just a thought. Let's say there are $n$ people where $n \leq 365$ (I'm not entirely sure how to approach the problem if $n > 365$ and inquire about that down below). What is the probability that there are exactly two pairs with the same birthday, and each of the pairs have a different birthday (e.g. Alice and Bob share a birthday on June 8th, Charlotte and Dylan share a birthday on December 1st.), assuming that birthdays are evenly distributed and we pick a completely random sample of $n$ people. My attempt to solve is the following: The sample space is represented by the $365^n$ different combinations of birthdays for the $n$ people. The number of ways that exactly two pairs share a birthday, and the birthday each pair shares is different, is given by $n \choose 2$$(365)$$n - 2 \choose 2$$(364)(\frac{363!}{(363-(n-4))!})$ The explanation is that we first pick two individuals to have the same birthday, then another two individuals to have a different same birthday from the remaining 364 days, and then finally have rest of the $n-4$ individuals all have different birthdays. The solution is thus given by the numerator divided by the sample space (having trouble using latex format with the chooses, I apologize). A couple of questions: Is the above solution correct for $n < 365$? If I try to think about if $n > 365$ the combinatorics I use in the last part $\frac{363!}{(363-(n-4))!}$ doesn't make sense anymore, so I was thinking about how I could use a different approach. Someone hinted that I could try to calculate the conditional probability that there is exactly one pair that shares a birthday given that I remove a pair that shares a birthday. I'm envisioning the distribution as a bell curve of some sort, but am getting overwhelmed in the details of how to account for all the cases. I would appreciate any hints or pointers!","['birthday', 'probability']"
1539290,Is this a valid technique when calculating limits,"I recently came across the limit
\begin{equation}
\lim_{x \to 0} \frac{\sin(\tan^2 x)}{1 - \cos x}
\end{equation}
Now I know this limit can be evaluated using the half angle identity or by l'Hopital's rule but I recently tried a method that yielded the correct answer but I don't know if the method is always correct or if it's even mathematically valid. It goes as follows.
\begin{equation}
\lim_{x \to 0} \frac{\sin(\tan^2x)}{1 - \cos x} = \lim_{x \to 0} \frac{\sin(\sec^2 x - 1)}{1 - \cos x}
\end{equation}
at this point I realized I can't simply substitute $x = 0$. My intuition behind this was that although $\sec^2(0) = \sec(0)$, the functions grow at different rates, so when used in a ratio, the $\sec^2x$ answer would be greater than the $\sec x$ answer. So I made the substitution $\lim_{x \to 0} \sec x = \lim_{h \to 0} 1 + h$. This would change the limit to
\begin{align}
\lim_{h \to 0} \frac{\sin((1 + h)^2 - 1)}{1 - \frac{1}{1 + h}} &= \lim_{h \to 0} \frac{(1 + h)\sin(h^2 + 2h)}{h}\\
&= \lim_{h \to 0} \frac{(2 + h)(1 + h)\sin(h^2 + 2h)}{h^2 + 2h}\\
&= \lim_{h \to 0} (2 + h)(1 + h)\frac{\sin(h^2 + 2h)}{h^2 + 2h} = 2
\end{align}
So is this method vlid, or was I just lucky and it happend to work for this case but would fail for most others? I originally had $h$ as an infinitesimal when I first tried this.","['limits-without-lhopital', 'limits']"
1539302,Prove that the sum $a_1+a_2+....+a_n+b_1+b_2+...+b_n$ cannot equal to $0$,"We are given an $n \times n$ board, where $n$ is an odd number. In each cell
  of the board either $+1$ or $-1$ is written. Let $a_k$ and $b_k$
  denote the products of the numbers in the $k$-th row and the $k$-th
  column, respectively. Prove that the sum
  $a_1+a_2+\cdots+a_n+b_1+b_2+\cdots+b_n$ cannot equal to $0$ I started off with some examples: If its a $3 \times 3$ board, then: you can either have: five $-1$'s and four $1$'s five $1$'s and four $-1$'s three $1$'s and six $-1$'s three $-1$'s and six $1$'s two $-1$'s and seven $1$'s two $1$'s and seven $-1$'s one $1$'s and eight $-1$'s one $-1$'s and eight $1$'s regardless, the sum will never be $0$. but how would i prove that?","['number-theory', 'game-theory']"
1539321,Question based on chords of a circle,"Question: Given a circle and two points $P$ and $Q$ not neccessarily on that circle. Perpendiculars are drawn from points $P$ and $Q$ to the polar lines of the points $Q$ and $P$ respectively. Prove that the ratio of of lengths of those perpendiculars are equal to the ratio of distances of point $P$ and $Q$ from the centre of circle. Attempt: I solved this question by assuming the circle equation as $x^2+y^2=1$ Let $P$ be $(x_1,y_1)$ and $Q$ be $(x_2,y_2)$. Polar of $P$ is $$xx_1+yy_1-1=0$$
Polar of $Q$ is $$xx_2+yy_2-1=0$$ The perpendicular distance from $P$ to polar of $Q$ is $$\frac{x_1x_2+y_1y_2-1}{\sqrt{{x_2}^2+{y_2}^2}}$$
Similarly, perpendicular distance from $Q$ is $$\frac{x_1x_2+y_1y_2-1}{\sqrt{{x_1}^2+{y_1}^2}}$$
Ratio is $$\frac{\sqrt{{x_1}^2+{y_1}^2}}{\sqrt{{x_2}^2+{y_2}^2}}$$which is the ratio of distance from centre of circle $(0,0)$ to the points $P$ and $Q$. Is there any method to solve this using geometry ? It looks like a problem involving two similar triangles.","['geometry', 'circles']"
1539327,Can I show $\sum_{i=1}^n 1/{i^2} \le 2$ without calculus?,"I'm solving a number theory problem and it suffices to show that
$$\sum_{i=1}^n \frac {1}{i^2} \le 2$$
In fact, I only need
$$\sum_{d|n} \frac{1}{d^2} \le 2$$
Trying wolfram alpha suggests they are true but I don't know how to prove. A proof without calculus(which I think may be used) is preferable since I haven't learned it yet. Thank you for all helps:)","['calculus', 'contest-math', 'number-theory', 'elementary-number-theory', 'inequality']"
1539328,How to understand push-forward an exceptional divisor?,"Let X be a Gorenstein variety. And $f:Y\longrightarrow X$ is a resolution, Y is normal. And we have $K_Y=f^*K_X+\sum_{i}a_iE_i$, $E_i$ are exceptional divisors.
Then consider the push-forward of the line bundle $K_Y$ (since Y is Gorenstein, K_Y is locally free). $f_*K_Y=f_*f^*K_X+\sum_{i}a_if_*(E_i)=K_X+\sum_{i}a_if_*(E_i)$. My question is what is $\sum_{i}a_if_*(E_i)$ in Pic(X)? Is it zero? For example X is smooth and Y is blowup one point in X. Then what is $f_*{E}$ as a sheaf on X? As Remy pointed out, it is may not be a line bundle. Is there a general theorem about this issue?",['algebraic-geometry']
1539336,Dominated convergence theorem (computing limit),"I need to compute $\displaystyle\lim_{n \rightarrow \infty} \int \frac{\sin (x^n)}{x^2} \, dx$ using Dominated Convergence theorem. I have taken the function $g$ such that $|f_n| \leq g$ , where $f_n =\dfrac{\sin (x^n)}{x^2} $ to be $\dfrac{1}{x^2}$. I am not sure how to proceed forward. Do I need to find another function $f$ s.t. $f_n \rightarrow f $ almost everywhere. If not then what should be my approach?","['real-analysis', 'lebesgue-integral', 'measure-theory']"
1539340,Compactness of Set of Probability Measures,"I'm currently studying Information Theory from Csiszar and Korner, ""Information Theory: Coding theorems for Discrete Memoryless Sources"". There are several questions pertaining to the set of all probability measures on the underlying space. I figured if I prove the following lemma, it will make things easier: Let $\mathcal{X}$ be a finite set. Let $\mathcal{P}=\mathcal{P}(\mathcal{X})$ be the set of all probability measures that can be defined on $\mathcal{X}$. Under the total variation metric i.e. for any two measures $P,Q \in \mathcal{P}$
$$d_{TV}(P,Q) := \sum_{x \in \mathcal{X}}|P(x)-Q(x)|$$ Prove that $(\mathcal{P},d_{TV})$ is compact. I'm actually looking for a simple proof of this. For instance, I wanted to use the result that a metric space is compact iff it is complete and totally bounded. Completeness was easy as I could just use the completeness of $\mathbb{R}$ in a pointwise fashion and show the pointwise limit is a measure. Finiteness of $\mathcal{X}$ helps greatly here. So all that is left is Totally Boundedness. Unfortunately, while I did start by assuming an $\epsilon$-cover of $\mathcal{P}$, I could not find a way to pick finitely many that would cover the whole space. I'm sure that finiteness of $\mathcal{X}$ would help here as well. The other idea, in fact the property I wanted to use, was to show sequential compactness since this is equivalent to compactness. But even here I'm not sure how to go about things. Kindly help me in this regard in the form of subtle hints and tips. If I get it, I'll post my solution and credit the most helpful hint. Update: It turns out I could use the fact that $\mathcal{P}$ is convex. Since any measure is a convex combination of degenerate distributions... Could I use this I wonder?","['metric-spaces', 'probability-distributions', 'general-topology', 'measure-theory']"
1539358,How can one find $\mu$?,Let $X_n$ be iid random variables with $P(X_n=(-1)^kk)=\dfrac{C}{k^2\log k}$ for all $k\geq 2$. Here $C$ is just a constant so that the sum of probabilities is $1$. Find constant $\mu$ such that $S_n/n\to \mu$ in probability where $S_n=\sum_{k=1}^nX_k$. Here $E(X_n)=\infty$. I'm a bit lost after this. In general how does one find constants like this?,"['probability-theory', 'law-of-large-numbers', 'probability-limit-theorems', 'independence', 'convergence-divergence']"
1539381,All prime ideals are invertible $\Rightarrow$ Dedekind domain,"$\newcommand{\p}{\mathfrak{p}}$ $\newcommand{\a}{\mathfrak{a}}$
Let $A$ be a one-dimensional Noetherian domain.
I am thinking about this claim: If all prime ideals of $A$ are invertible, then $A$ is a Dedekind domain. Is that true? I tried to show a unique factorization into prime ideals.
Indeed, an integral domain is a Dedekind domain,
iff all nonzero ideals admit a unique prime factorization. To show this, I'm going to show following two lemmas.
If it is proved, we can prove a unique factorization
by the same way as a Dedekind domain (cf. Neukirch, Algebraic Number Theory ). Let $\a \neq 0$ be an ideal of $A$.
I proved the first lemma: There exists prime ideals $\p_1, \dots, \p_r$ such that
  $$
\a \supseteq \p_1\dots \p_r
$$ by the same way as a Dedekind domain,
because it is not used that $A$ is integrally closed. But I can't show the second lemma: $$\a\p^{-1} \supsetneq \a.$$ I found that to show the second lemma, it is sufficient to show that
$$ \bigcap_{n=1}^\infty \p^n = 0. \label{a}\tag{1}$$
We assume that it is proved.
If $\a\p^{-1} = \a$, $\a = \a\p$.
By induction, we get $\a = \a\p^n$ for $\forall n > 0$.
We use $\eqref{a}$, then we get $\a = 0$.
It is a contradiction. However, I can't prove $\eqref{a}$.","['ring-theory', 'commutative-algebra', 'ideals', 'dedekind-domain', 'abstract-algebra']"
1539416,Probability of each state less than or equal to $2^{-n}$ for each $n$?,"This relates to the hint to exercise 3.6.5 in Rosenthal's A First Look at Rigorous Probability Theory . ($\Omega, \mathscr{F}, P$) is a probability triple, where: $\Omega$ is countable (in this book, that also includes finite - cf. p. 200) $\mathscr{F} = 2^{\Omega}$ The hint says that ""for each $\omega \in \Omega$ and each $n \in \mathbb{N}$, we have $P(\{\omega\}) \le 1 / 2^n$."" But I must be interpreting something incorrectly, because the way I see it the hint isn't true: Let $\Omega$ be just $\{1, 2\}$, $\mathscr{F}$ the powerset, and let $P(\{1\}) = 1, P(\{2\} = 0$. Then $\Omega$ is finite and hence countable, but it is not true that for each $n \in \mathbb{N},  P(\{1\}) \le 1 / 2^n$. It in fact isn't true for any natural number $n$. And in fact for any countable set, if you just assign probabilities uniformly to a finite subset and 0 to everything else, there will always be some $n$ large enough to make the hint incorrect for those states having nonzero probability. The problem doesn't show up in the Errata I've found for the book, and it is assigned in several classes I've found, so I must be missing some implicit assumption. But neither I nor a friend with whom I'm working through the book can figure out what Rosenthal means here.",['probability-theory']
1539428,"If $f:[0,\infty) \to \mathbb{R}$ be a differentiable function with $f(0)=1$ . . . Show that $f'(x)\geq e^x$ for all $x>0$.","If $f:[0,\infty) \to \mathbb{R}$ be a differentiable function with $f(0)=1$ and $f'(x)\geq f(x)$ for all $x>0$. Show that $f'(x)\geq e^x$ for all $x>0$. Hint: Consider $g(x)=e^{-x}f(x)$. My main concern is what does $g(x)$ have to do with anything. I feel if I understood its relevance, then I could solve the problem. I'm just not sure how I can declare it's relevance to the problem at hand. Edit:
charlestoncrabb is correct on the proof, I'm just not certain of the relevance of $g(x)$","['real-analysis', 'derivatives']"
1539432,How to Prove $\oint ({\mathcal{\hat{r}}} \cdot \vec r') \mathrm{ d\vec l'} = -{\mathcal{\hat{r}}} \times \int \mathrm{d\vec a'}$?,$$\oint ({\mathcal{\hat{r}}} \cdot \vec r') \mathrm{ d\vec l'} = -{\mathcal{\hat{r}}} \times \int \mathrm{d\vec a'}$$ Here the integration in the LHS is around a certain loop and the $d\vec a'$ represents any surface enclosed by the loop.$\vec r' $ is the vector from origin to a point on the loop and $\mathcal{\hat{r}}$ is constant. I am unable to prove the integral.,"['vectors', 'vector-analysis', 'multivariable-calculus', 'integration']"
1539439,Given no of ways of selection for a game of mixed doubles find no of ways if selecting any 2 people,"If the number of ways of choosing 2 boys and 2 girls in a class for a game of mixed doubles is 1620, what is the number of ways of choosing 2 students from the class? My attempt : Let there be $m$ boys and $n$ girls. Number of ways of choosing 2 boys and 2 girls from them =$m \choose 2 $$ n \choose 2$. Now from each of these selections we can make 2 teams (If the boys are P & Q and the girls R & S, then the games will be P+R vs Q+S and P+S vs Q+R) Therefore $2$$m \choose 2 $$ n \choose 2$= $1620$ How can I find $m+n \choose 2$?",['combinatorics']
1539449,Is the following a Kuratowski closure operator?!,"Let $(X,\tau)$ be a cofinite topology, where $X$ is infinite. Then, for every $A\subseteq X$, we define a Kuratowski closure operator with:
$$cl(A)=\left\{ \begin{array}{cc} A; & A \; \text{finite}\\ X; & A\; \text{infinite} \end{array} \right.$$ I proved all of the Kuratowski closure axioms, but I don't know if my proof is correct. Any comments? $\boxed{(1) \; cl(\emptyset)=\emptyset}$ $$A \; \text{finite}\Rightarrow cl(A)=\emptyset\Rightarrow cl(\emptyset)=\emptyset $$ $\boxed{(2) \; A\subseteq B\Rightarrow cl(A)\subseteq cl(B)}$ $(i)\; A,B$ finite $\Rightarrow cl(A)=A,\; cl(B)=B$ 
$$A\subseteq B\Rightarrow cl(A)\subseteq cl(B)$$ $(ii)\; A,B$ infinite $\Rightarrow cl(A)=cl(B)=X$ $$A\subseteq B\Rightarrow A\cup X\subseteq B\cup X\Rightarrow X\subseteq X\Rightarrow cl(A)\subseteq cl(B)$$ $(iii)$ $A$ finite, $B$ infinite $\Rightarrow cl(A)=A,\; cl(B)=X$ $$ A\subseteq B \wedge A\subseteq X \Rightarrow A\subseteq B\cup X\Rightarrow A\subseteq X\Rightarrow cl(A)\subseteq cl(B)$$ $\boxed{(3)\; A\subseteq cl(A)}$ $(i)$ $A$ finite $\Rightarrow cl(A)=A  \Rightarrow A\subseteq cl(A)$ $(ii)$ $A$ infinite $\Rightarrow cl(A)=X$ $$A\subseteq X\Rightarrow A\subseteq cl(A)$$
$\boxed{(4)\; cl(A\cup B)=cl(A)\cup cl(B)}$ $(i)$ $A$ finite, $B$ infinite $\Rightarrow A\cup B$ infinite
$$cl(A\cup B)=X=A\cup X=cl(A)\cup cl(B)$$
$(ii)$ $A,B$ finite $\Rightarrow A\cup $ finite
$$cl(A\cup B)=A\cup B=cl(A) \cup cl(B)$$
$(iii)$ $A,B$ inifinite $\Rightarrow A\cup B$ inifite 
$$cl(A\cup B)=X=X\cup X=cl(A)\cup cl(B)$$ $\boxed{(5) \; cl(cl(A))=cl(A)}$ $(i)$ $A$ finite $\Rightarrow cl(A)=A$ $$cl(cl(A))=cl(A)$$
$(ii)$ $A$ infinite $\Rightarrow cl(A)=X$ $$cl(cl(A))=cl(X)\overset{X \; \text{infinte}}{=} X=cl(A)$$",['general-topology']
1539577,Is a Riemannian manifold with isometric coordinate charts flat?,"Suppose $M$ is a Riemannian Manifold such that each point has a coordinate chart into $\mathbb{R}^n$ that is an isometry, in the sense that the inner products are preserved. Does this imply that $M$ is locally flat in the sense that is vanishing Gaussian curvature? I really don't know much about differential geometry, but my impression is that this is Gauss' Theorema Egregium (or a corollary thereof), which is sometimes stated as 'Gaussian curvature is invariant under isometry'. Does this mean isometry in the sense that lenghts of paths are preserved (i.e. as metric spaces)? Or in the sense above that inner products are preserved? Or even more?Perhaps, does the coordinate chart need to be smoother than just smooth enough to formulate that it is an isometry? For example, the Wikipedia entry on Gaussian curvature gives a formula that contains second derivatives, so does the version of the Theorema that I cited above only hold for $C^2$ isometries?","['differential-geometry', 'riemannian-geometry', 'curvature']"
1539581,Limits and infinity in a succession,"Apologies for this rather basic question. I am preparing the entry exam for university without the help of a teacher and occasionally get stuck on seemingly simple things. I have been all over the internet and cannot find out how to solve this limit: \begin{align*} \quad \lim_{n \to \infty}\frac{3^n+2^n}{5^n+3}\\
 \end{align*} Does changing it to \begin{align*} \quad \lim_{n \to \infty}\frac{3^n}{5^n+3} + \lim_{n \to \infty}\frac{2^n}{5^n+3}\\
 \end{align*} would help in this case? Or can I do \begin{align*} \quad \lim_{n \to \infty}\frac{1+\frac{2^n}{3^n}}{1+\frac{3}{5^n}}\\
 \end{align*} I would be very, very grateful if anyone could take the time and show me step by step how this is done.","['infinity', 'limits']"
1539595,"For any affine open subset $U$ of an irreducible affine variety $X$, why $K(U)\cong K(X)$?","Here is a problem I met while reading Linear Algebraic Groups written by T. A. Springer. The following paragraph is on Page 16 of this book. Let $X$ be an irreducible variety. First assume that $X$ is affine. Then $K[X]$ is an integral domain. Let $K(X)$ be its quotient field. If $U=D(f)$ is a principal open subset of $X$, then $K[U]=K[X]_{f}$ from which it follows that the quotient field $K(U)$ is isomorphic to $K(X)$. And then it says that the same holds for any affine open subset $U$ by 1.3.6(ii).
(where 1.3.6(ii) is the fact that any open subset of affine variety $X$ is the union of some principal open sets.) I'm confused with the last sentence. Here is my proof. Proof. We write $U=\cup_{i=1}^{k}D(f_{i})$, where $f_{i}\in K[X]$ are distinct, since $U$ is an affine open subset of $X$. Notice that $D(f_{i})$ corresponds to $\{(x,1/f_{i}(x))~|~x\in D(f_{i})\}$. 
Then $U$ corresponds to $U'=\cup_{i=1}^{k}\{(x,1/f_{i}(x))~|~x\in D(f_{i})\}$. And $K[U]\cong K[X][T]/\cap_{i=1}^{k}(1-f_{i}T)$. For $f_i$ are different, $(1-f_{i}T, 1-f_{j}T)=1$, $\forall i\neq j$. Therefore $(1-f_{i}T)+(1-f_{j}T)=(1)$ and $K[X][T]/\cap_{i=1}^{k}(1-f_{i}T)\cong \prod_{i=1}^{k}K[X][T]/(1-f_{i}T)$. But $\prod_{i=1}^{k}K[X][T]/(1-f_{i}T)$ is not an integral domain. Hence $K[U]$ is not integral domain. How could $K(U)$ exist? Please tell me why, and where are my mistakes. Thanks!","['algebraic-geometry', 'proof-verification', 'commutative-algebra']"
1539604,Measurable set of real numbers with arbitrarily small periods,"I am trying to prove the following exercise (exercise 3, chapter 7 of Rudins Book ""Real and Complex Analysis""): Suppose that $ E $ is a measurable set of real numbers with arbitrarily small periods. Explicitly, this means that there are positive numbers $ p_i $, converging to $ 0 $ as $ i\rightarrow \infty $, so that 
  \begin{align*}
E + p_i = E \ \ (i = 1, 2, 3, . . . ).
\end{align*}
  Prove that then either $ E $ or its complement has measure $ 0 $. I have seen the following answer: Measure zero sets , 
but I tried it by my own and followed the hints Rudin give in his book. That is what I have: Given $ \alpha\in\mathbb{R}$, we define $F(x)=m(E\cap [\alpha, x])$, where $x>\alpha$. Then we get: 
  \begin{align*}
F(x+p_i)-F(x-p_i)
&=m(E\cap [\alpha, x+p_i])-m(E\cap [\alpha, x-p_i])\\
&=m((E\cap [\alpha, x+p_i])-p_i)-m((E\cap [\alpha, x-p_i])+p_i) \\
&=m(E\cap [\alpha-p_i, x)-m(E\cap [\alpha+p_i, x]) \\
&=m(E\cap [\alpha-p_i,\alpha+p_i]). 
\end{align*} 
   This implies that for every points $\alpha+p_i<x<y$, we get that
  \begin{align}
F(x+p_i)-F(x-p_i)=F(y+p_i)-F(y-p_i). 
\end{align} So the hint he gives now is to think about what does this imply for $F'(x)$ if $m(E) > 0$. I just have in mind that we could apply the Lebesgue differentiation theorem for $f=1_E$: \begin{align*}
\lim_{m(I)\rightarrow 0}\frac{m(E\cap I)}{m(I)}=1_E(x)
\end{align*} but this do not give enough information to conclude the density of $E$. Nevertheless, by having $m(E)>0$, we now that it must have some density point. I would appreciate any help!","['analysis', 'real-analysis', 'lebesgue-measure', 'measure-theory']"
1539605,Prove that if $A\ge B$ then $\left[ {\begin{array}{*{20}{c}} A & B \\ B & A \\ \end{array}} \right]\ge0$.,"Let $A$ and $B$ be $n \times n$ matrices, i.e., $A, B \in  M_n$. Also, $A \ge 0$, $B \ge 0$, and $A-B \ge 0$ which mean all these matrices are semi-positive-definite. Why does 
$\left[ {\begin{array}{*{20}{c}}
   A & B  \\
   B & A  \\
\end{array}} \right] \ge 0$?","['linear-algebra', 'matrices']"
1539606,Prove identity $1 + {n \choose 3} + {n \choose 6} + \cdots = \frac{1}{3}\left(2^n + 2\cos{\frac{n\pi}{3}}\right)$ without using complex numbers,"How to prove the following identity without using complex numbers (and de Moivre's formula)?
$$1 + {n \choose 3} + {n \choose 6} + {n \choose 9} + \cdots = \frac{1}{3}\left(2^n + 2\cos{\frac{n\pi}{3}}\right)$$","['binomial-theorem', 'binomial-coefficients', 'combinatorics']"
1539629,How did mathematicians decide on the axioms of linear algebra,"So we vector spaces, linear transformations, inner products etc all have their own axioms that they have to satisfy in order to be considered to be what they are. But how did we come to decide to include those axioms and not include others? For example, why does  this rule hold in inner product spaces $c\langle u,v\rangle=\langle cu,v\rangle$, when my intuition says that it should be $\langle cu,cv\rangle$? And how did we decide that it was  scalar multiplication and additive were sufficient criteria for something to be a linear map?",['linear-algebra']
1539640,"Finding critical points and determining local maxima and minima for $f(x,y)=-x^3+4xy-2y^2+1$","Finding critical points and determining local maxima and minima for $f(x,y)=-x^3+4xy-2y^2+1$ First I took the following derivatives: $f_x=-3x^2+4y$ $f_{xx}=-6x$ $f_y=4x-4y$ $f_{yy}=-4$ $f_{xy}=4$ I then set $f_x=0$ and $f_y=0$ and solved for the solution to the system of equations.  The answer I got is $x=\frac{4}{3}$ and $y=\frac{4}{3}$ I know I now have to classify my critical points to determine if they are local maxima or minima.  So using the following formula: $D(x,y)=f_{xx}(x,y)f_{yy}(x,y)-[f_{xy}(x,y)]^2$ I get: $-6x(-4)-(4)^2 = 24x-16$ For the next step I'm supposed to plug in $D(x,y)$ but I have no $y$ variable.  Any hints on where I'm going wrong here?","['optimization', 'calculus', 'multivariable-calculus']"
1539674,Leibniz test $\sum\limits_{n=1}^\infty \sin\left(\pi \sqrt{n^2+\alpha}\right)$,"I am given a series:
$$\sum\limits_{n=1}^\infty \sin\left(\pi \sqrt{n^2+\alpha}\right)$$
And in the description of the problem it is said that I must show by Leibniz test that it is convergent. How can I even get the $(-1)^n$ symbol out of the starting series?","['sequences-and-series', 'calculus', 'convergence-divergence']"
1539693,Why does a Poisson process hurt the prerequesites of the Kolmogorov-Chentsov theorem,"I have a question for you.
Obviously, by looking at the sample paths of a Poisson process with parameter $\lambda >0$, this process does not have a hölder-continuous version. But why? I have the feeling that the conditions for the Kolmogorov-Chentsov theorem are not hurt. This is part of my homework and it puzzles me the whole weekend already. A simple version of that theorem states: "" Let $X_t$ be a real-valued process. For every $T >0$ there exists $\alpha, \beta, C > 0$ with $E[|X_t - X_s|^\alpha] \leq C|t - s|^{1 + \beta}$ on $[0,T]$ Then there exists a version of $X_t$ with hölder-continuous paths."" Assuming $t > s$ and $\alpha \geq 1$, we can use Jensen and find $E[|X_t - X_s|^\alpha] \geq \lambda^\alpha (t - s)^\alpha$ which goes to zero, so the conditions are fulfilled (?). For $\alpha < 1$, I could calculate the fractional moments of the Poisson distribution via fractional Bell polynomials - but those are even negative, depending on $\lambda$ and $\alpha$. 
So they could be fulfilling the prerequisites for a given $\beta$ as well. Where am I wrong? I have to be somewhere, but I don't find out where.","['probability-theory', 'holder-spaces', 'continuity', 'stochastic-processes', 'poisson-process']"
1539695,How to prove that a nilpotent matrix is not invertible?,"Let $B_{n\times n}$ be a nilpotent matrix. How should I go around proving that $B$ is not invertible? I was thinking this: if $B*B = 0$ , then if I rank $B$ to echelon form, I will always have two or more rows that are the same, and then because $B$ is square, it is not possible to find another matrix $(B^{-1})$ that will transform $B$ to $I_{n}$ ... But I don't know how to write it formally.","['linear-algebra', 'matrices']"
1539702,Eddington's controversy simplified,"I have been given the following probability problem: A, B and C are three people, who each independently speak the truth one of three times. A denies that B declares that C is lying. What is the probability that C is telling the truth? This problem is similar to Eddington's controversy If A, B, C, D each speaks the truth 1 in 3 times (independently), and A affirms that B denies that C delcares that D is a liar, what’s the probability that D was speaking the truth? I believe that the answer to the Eddington's problem was $\frac{25}{71}$ as given by Eddington himself. However, the other solution (based on different initial assumptions) is $\frac{13}{41}$ . My question is, how are the above solutions worked out? If I understand the logic behind Eddington's problem, I hope I can solve my probability problem.",['probability']
1539736,"What is exactly meant by ""preserves the group operation""?","I'm new to the topic and I'm reading ""Contemporary Abstract Algebra"" by Gallian an this is how isomorphism is defined: ""An isomorphism $\phi$ from a group $G$ to a group $\overline{G}$ is a one-to-one mapping (or function) from $G$ onto $\overline{G}$ that preserves the group operation."" What is exactly meant by ""preserves the group operation""? The one of $G$?  $\overline{G}$?","['abstract-algebra', 'group-theory']"
1539750,$[z^n]$ notation,"I have the following formula: $[z^n]\frac{2+3z^2}{\sqrt{1-5z}}$ I'm not sure about the meaning of $[z^n]$. I don't have a definition for this in lecture notes, could someone clarify what exactly does it mean? I used to use this notation for equivalence class, but it does not make sense to me in this context.","['generating-functions', 'discrete-mathematics']"
1539767,The transformation of $\frac{\partial y}{\partial x}=\frac{Q}{P}$ to $\frac{dy}{Q}=\frac{dx}{P}$,"I'm studying a method used to solve PDE's and at one point in the argument we have the following: $$\frac{\partial y}{\partial x}=\frac{Q}{P}$$ which is then later re-written as $$\frac{dy}{Q}=\frac{dx}{P}$$ I sort of see how re-arranging fractions would make this true but I am unconvinced and something seems odd about the partials becoming ""not partial"". Can someone try to explain why this should be true?","['partial-differential-equations', 'partial-derivative', 'ordinary-differential-equations', 'derivatives']"
1539790,"Solving $X+Y\stackrel{d}{=}2Y$ with $X$ uniform on $[-1,1]$","I have problems with the following question: Let $X$ be the random variable such that $X\sim U[-1,1]$. Does there exist a random variable $Y$, independent to $X$, such that $X+Y\sim 2Y$? I thought that uniqueness of characteristic function would help. So, we ask if there exists a variable Y with characteristic function $\phi(t)$, such that $\frac{\sin(t)}{t}\phi(t)=\phi(2t)$.  (And, of course $\phi(0)=1)$ I would be thankful for help. Edit : Proof by contradiction. I will show that zeros of $\phi$ have $0$ as their accumulation point: Notice that if $t\in(-\pi,\pi)$ we have: if $\phi(2t)=0$ then $\phi(t)=0 (*) $. We just have to know if there exists any zero of $\phi$ in $(-\pi,\pi)$. $\phi(\pi)=\frac{2}{\pi}\phi(\frac{\pi}{2})$ and $\phi(-\pi)=\frac{-2}{\pi}\phi(\frac{-\pi}{2})$. So if $\phi(\frac{\pi}{2})\neq0$ and $\phi(-\frac{\pi}{2})\neq0$, then either $\phi(\pi)$ and $\phi(-\pi)$ or $\phi(\frac{\pi}{2})$ and $\phi(-\frac{\pi}{2})$ have opposite signs, so there exists zero of $\phi$ in $(-\pi,\pi)$. We know that $\phi(0)=1$, hence from $(*)$ there is a sequence of zeros of $\phi$ which converges to 0. Then, because $\phi$ is continuous $\phi(0)=0$. Is it correct?","['independence', 'characteristic-functions', 'probability', 'random-variables']"
1539797,Probability and exit polls,"I have a very simple probability question that I for some reason just can not solve. Question: Consider an election with two candidates, Candidate A and Candidate B. Every voter is invited to participate in an exit poll, where they are asked whom they voted for; some accept and some refuse. For a randomly selected voter, let A be the event that they voted for A, and W the event that they are willing to participate in the exit poll. Suppose that $P(W \mid A)=0,7$ but $P(W \mid A^C)=0,3$. In the exit poll, 60% of the respondents say they voted for A (assuming they are all honest), suggesting a comfortable victory for A. Find $P(A)$. Okay first we notice that $A,A^c$ obviously is a partition so we can use the total low of probability. getting
\begin{align*}
P(W) & = P(W\mid A) \cdot P(A)+P(W \mid A^c) \cdot P(A^c)\\
     & = P(W\mid A) \cdot P(A)+P(W \mid A^c)\cdot (1-P(A))\\
     & =0,7 \cdot P(A)+0,3\cdot (1-P(A))
\end{align*} Thus all I need is to find $P(W)$ and then solve for $P(A)$. However I have issue with finding $P(W)$. Any help?",['probability']
1539815,Reconstructing a function from its critical points and inflection points,"For my class I have sketched the following graph which depicts certain critical points and curvatures including one local maximum, minimum, two inflection points and a saddle point (which is an inflection point as well): I would like to draw this graph ( and the graphs of the first and second derivate as well ) in LaTeX but I need a possible corresponding function. At first I was considering to obtain such a function with the properties of the derivatives based on the critical points but that would be way too complicated with so many equations. Hence I was thinking about using a piecewise function (seems like two functions from $\mathcal{O}(x^2)$ and one from $\mathcal{O}(x^3)$ to mimick the behaviour from the graph) and glueing those pieces together such that the entire function is continuous. What would you do to reconstruct such a function for plotting purposes? EDIT There are no specific values $x$ and $f(x)$ so we're free to take values which make the reconstruction of the function as simple as possible as long as $f$ remains two times differentiable.","['continuity', 'real-analysis', 'functions', 'graphing-functions', 'derivatives']"
1539842,Convergence of series of positive terms: $\sum_{n=2}^{\infty}\frac{1}{{(\log n)}^{p}}$,"I have applied Cauchy condensation test for to test the convergence the series $\sum_{n=2}^{\infty}\frac{1}{{(\log n)}^{p}}$, where p is constant, I got $\frac{1}{{\log 2}^{p}}\sum_{k=1}^{\infty}\frac{2^{k}}{k^{p}}$ . I do not understand for which value of p such that  the original series is convergent. Also have used Cauchy integral test but did not solve the improper integral $\int_{2}^{\infty}
{\frac{1}{(\log{x})^{p}}}dx$. 
I do not understand the convergent or not, if it convergent what is the value of p will be.   Please some one help me. Thanks","['calculus', 'divergent-series', 'sequences-and-series', 'analysis', 'monotone-functions']"
1539851,Orthogonality of the degenerate eigenvectors of a real symmetric matrix,"It is relatively easy to show for a real symmetric matrix $ A $ that its eigenvectors belonging to distinct eigenvalues are orthogonal; it comes down to $(\lambda_i - \lambda_j) u_i^Tu_j=0$ and since eigenvalues are different; the eigenvectors have to be orthogonal. When the eigenvalues are equal, I know that we can pick eigenvectors which are orthogonal to eachother and to all other eigenvectors, enabling to build an orthogonal basis of eigenvectors which span $\mathbb {R^N} $ for a $ N \times N $ matrix. I try to show how one can pick orthogonal vectors for a shared eigenvalue $\lambda $. I tried to use the characteristic polynomial $ det (A - \lambda I_N)=0$ which has multiple roots at a shared eigenvalue $\lambda $. Assuming that $\lambda $ has multiplicity of $ m $ I tried to show then the matrix $ A - \lambda I_N $ has an $ m $ dimensional nullspace, spanned by $ m $ eigenvectors, but failed to reach any conclusions. How can we construct a proof of that?","['eigenvalues-eigenvectors', 'vectors', 'linear-algebra']"
1539882,Is there a general formula for $\sin( {p \over q} \pi)$?,"Virtually everyone knows the basic values of the unit circle, $\sin(\pi) = 0; \ \ \sin({\pi  \over 2}) = 1; \ \ \sin({\pi \over 3}) = {\sqrt{3} \over 2} \\$
And other values can be calculated through various identities, like $\sin({\pi \over 8}) =\frac{1}{2} \sqrt{2 - \sqrt{2}}\\$
Does there exist a general formula for $\sin({p\over q} \pi)$ for rational ${p \over q}$ as an algebraic number?","['geometry', 'algebraic-numbers', 'trigonometry']"
1540069,Can I write: $\lim \limits _{x \to x_0} (f(x) + g(x)) = \lim \limits _{x \to x_0} f(x) + \lim \limits _{x \to x_0} g(x)$?,"If $\lim \limits _{x \to x_0} (f(x) + g(x))$ exists, can I write: $\lim \limits _{x \to x_0} (f(x) + g(x)) = \lim \limits _{x \to x_0} f(x) + \lim \limits _{x \to x_0} g(x)$ ? I mean, to write this do I have to know that the other limits exist? Because they tell me that $\lim \limits _{x \to x_0} f(x)$ exists and I want to prove that $\lim \limits _{x \to x_0} g(x)$ also exists by writing: $$\lim \limits _{x \to x_0} (f(x) + g(x)) = \lim \limits _{x \to x_0} f(x) + \lim \limits _{x \to x_0} g(x)$$
$$\lim \limits _{x \to x_0} g(x) = \lim \limits _{x \to x_0} (f(x) + g(x)) - \lim \limits _{x \to x_0} f(x)$$
Then because the other limits exist, the theorem says that the limit of $g$ also exists... Is it correct to prove & write that way?","['calculus', 'limits', 'algebra-precalculus']"
1540115,Elementary Combinatorics... How many different shirts are being sold?,"A shirt sold in 6 colors, 5 sizes, striped or solid, and long
sleeve or short sleeve. -How many different shirts are being sold? -What if the black
and yellow shirts only come in short-sleeve and solid? For the first part, it seems that the answer is simply $6 \cdot 5 \cdot 2 \cdot 2 = 120$ different shirts. However, the second part is throwing me off.","['combinations', 'combinatorics', 'permutations']"
1540164,Is trace map well-defined for an endomorphism of free-module over $A[G]$?,"Given a commutative ring $A$ and a finite group $G$(not commutative), form $A[G]$. Given matrices $M,A,B\in M_n(A[G])$, with $AB=BA=I_n$. Is it true that $\sum_{i,j,k}a_{ij}m_{jk}b_{ki}=\sum_im_{ii}$ in $A[G]$? There's another try to give a definition: Write $M=\sum_{g\in G}gM_g$ with $M_g\in M_{n\times n}(A)$, define $Tr(M)=\sum Tr(M_g)[g]$, where $[g]=\sum_{\exists a, h=a^{-1}ga}{h}\in A[G]$, or $[g]$ is the sum of elements in $G$ in the same conjugacy class of $g$. Why does this definition work?","['abstract-algebra', 'group-theory', 'linear-algebra']"
1540201,Intuition for the valuative criterion for properness of morphisms?,"I've always been told that the intuition for the valuative criterion for properness is something like this: a morphism $X\rightarrow Y$ is proper if, given a map of a small disk $D$ into $Y$ and a lifting $\alpha$ of $D\setminus\{p\}$ to $X$ for some point $p\in D$, there exists a unique lifting of $D$ to $X$ extending $\alpha$. In the valuative criterion, we can think of the discrete valuation ring $R$ as representing a germ of the curve around a point, or $D$ in the above picture. Its field of fractions $K$ is the localization at its generic point. Questions: How can I think of $K$ geometrically as a ""punctured germ'' or ""punctured disk""? It seems that $K$ is actually a ""point'' of $D$, so that the criterion is saying something like, given a lift of the generic point of a small piece of a curve, we can lift to the entirety of the small piece. This makes less geometric sense to me, though. Perhaps one could view the generic point as a non-closed ""fuzzy"" thing whose closure includes the single closed point $\mathfrak m$ in the DVR and preserve the analogy that way. It seems reasonable to expect the valuative criterion to be able to prove the following: if $X$ and $Y$ are projective (and hence proper) curves, and $p\in X$ is a regular point, then any morphism $X\setminus \{p\}\rightarrow Y$ extends uniquely to a morphism $X\rightarrow Y$. We can interpret this in terms of extending a lift of a small punctured disk (the image of some small punctured disk around $p$ mapped to $Y$). Can the valuative criterion be used to prove this, and if so, how? I think something like the following works. We have morphisms
$$FF(\mathcal O_{X,p})\rightarrow Y \rightarrow \operatorname{Spec} \mathbb C$$
$$FF(\mathcal O_{X,p}) \rightarrow \mathcal O_{X,p}\rightarrow \operatorname{Spec} \mathbb C$$
that commute. The map $$FF(\mathcal O_{X,p})\rightarrow Y$$ is given by the restriction of the given map $X\rightarrow Y$ to the generic point, since $FF(\mathcal O_{X,p})$ is the function field for $X$ (right?). Then the valuative criterion produces a map $f:\mathcal O_{X,p}\rightarrow Y$. It seems like this map should be the desired extension, but I'm not sure how to say that precisely.","['algebraic-geometry', 'schemes']"
1540232,Product of generating functions,"Let $f(x) = \sum_{i=0}^\infty a_ix^i$ and $g(x) = \sum_{i=0}^\infty b_ix^i$ where $a_n = 1$ and $b_n = 2^n$ for all natural numbers $n$ What are the first three terms of the sequence generated by $f(x)g(x)$
  ? So I know that $f(x)$ will generate $\{1,1,1,1,1,.... \}$ and $g(x)$ will generate $\{1,2,4,8,16,32,64,....... \}$ The first term $c_0$ of the sequence $f(x)g(x)$will be $1 \times 1 = 1$ and the second term $c_1$ will be $a_0 \times b_1 + a_1 \times b_0 = 1 \times 2 + 1 \times 1 = 3$ and finally $c_2 = 1 \times 4 + 1 \times 2 + 1 \times 1 = 7$ Now what is the general formula for the sequence generated by
  $f(x)g(x)$, assume that it generates $\{c_0,c_1,c_2,c_3,..........\}$ If I calculates $c_3$ it would be easier to see that pattern, $c_3 = 8 + 4 + 2 + 1 = 15$ and so the sequence is $\{1,3,7,15,31,.................... \}$ It is basically $\{1,2^{2}-1,2^3-1,2^4-1,.... \}$ and so it is $\{1,a^2-1,a^3-1,a^4-1,.... \}$ where $a=2$, Is this general formula correct ? I mean what is the formula , I just know the pattern here. So is the formula just $$c_k = 2^k-1$$ where $k>1$ What function generates the sequence $\{c_0,c_1,c_2,..... \}$? Well I know that $\frac{1}{1-2x}$ generates the sequence $\{1,2,2^2,2^3,... \}$ and that $\frac{-1}{1-x}$ generates $\{-1,-1,-1,.... \}$ but adding these two functions will gives us the sequence $\{0,1,2^2-1,2^3-1 \}$ And what should I do to eliminate that zero, multiply by $x$ will add more zero, what should do I do eliminate one zero ?","['discrete-mathematics', 'generating-functions', 'combinatorics']"
1540267,Different solutions to the Hermite equation,"The Hermite differential equation is given as such $$ y'' - 2xy'+2\lambda y=0 $$ writing this in strum-liouville form you get $$-(\exp(-x^2)y')'= 2\exp(-x^2)\lambda y $$ However, in order for it to have real eigenvalues, according to strum-liouville theory, the differential operator, $$ Ly = \lambda y$$
must be self adjoint which implies that the solution must have compact support ( i.e. $ y\rightarrow 0 $ as $x \rightarrow \pm\infty $). However, we know that the solutions to the Hermite equation are the Hermite polynomials, which obviously are not compactly supported. So I'm confused. I was wondering if anyone could tell where I'm going wrong in my logic. Also I've seen solutions to the Hermite differential equation such as $ \exp(-x^2/2)H_n $ and $H_n$, where $H_n$ is the Hermite polynomial of order $n$. Basically, what's up with that?","['differential-operators', 'ordinary-differential-equations']"
1540271,A new approach to find value of $x^2+\frac{1}{x^2}$,"When I was teaching in a college class, I write this question on board. If we now $\bf{x+\dfrac{1}{x}=4}$ show the value of  $\bf{x^2+\dfrac{1}{x^2}=14}$ Some student asks me for a multi idea to show or prove that.
I tried these : $$ $$1 :$$\left(x+\frac{1}{x}\right)^2=4^2\\x^2+\frac{1}{x^2}+2x\times \frac{1}{x}=16\\x^2+\frac{1}{x^2}=16-2 $$
 2:solving quadratic equation ,and putting one of roots$$x+\frac{1}{x}=4\\\frac{x^2+1}{x}=4\\x^2+1=4x\\x^2-4x+1=0\\x=\frac{-b\pm \sqrt{b^2-4ac}}{2a}=\frac{-(-4)\pm \sqrt{(-4)^2-4(1)(+1)}}{2}=\\x=\frac{4\pm \sqrt{12}}{2}=2\pm \sqrt{3}\\x=2+\sqrt3 \to x^2=4+4\sqrt3+3=7+4\sqrt3\\x^2+\frac{1}{x^2}=7+4\sqrt3+\frac{1}{7+4\sqrt3}=\\7+4\sqrt3+\frac{1}{7+4\sqrt3}\cdot\frac{7-4\sqrt3}{7-4\sqrt3}=\\7+4\sqrt3+\frac{7-4\sqrt3}{49-16\cdot 3}=\\7+4\sqrt3+\frac{7-4\sqrt3}{1}=14$$
3: visual approach .assume side length of a square is $x+\frac{1}{x}=4$ now I am looking for new idea to proof.Any hint will be appreciated.(more visual proof - geometrical - trigonometrical - using complex numbers ...)","['education', 'alternative-proof', 'big-list', 'algebra-precalculus']"
1540277,conditional weak convergence almost surely and joint unconditional weak convergence,"Sorry for the confusing title! Consider random variables $\{X_n, Y_n:n\geq 1\}$, defined on the same probability space $(\Omega, \mathcal{A}, P)$. Suppose, (i) $X_n \stackrel{d}{\rightarrow} Z$, (ii) $Y_n\mid X_n \stackrel{d}{\rightarrow} Z$, almost surely $(P)$. This is the same random variable $Z$ as considered in (i). Assume $Z_1,Z_2$ are iid with the same d.f. as $Z$. Then, I need to show that, unconditionally, 
$$
(X_n, Y_n) \stackrel{d}{\rightarrow} (Z_1, Z_2).
$$
Also, will this be true if almost surely is replaced with in probability $(P)$ in part (ii) above. Any references, ideas will be highly appreciated. This is mentioned as a statement in page 475 of the book by Dasgupta (Asymp. Theory of Stat and Prob.).
Thanks!","['probability', 'statistics']"
1540324,In how many ways can two dozen identical robots be assigned to four assembly lines?,"In how many ways can two dozen identical robots be  assigned to four
  assembly lines with (a) at least three robots  assigned to each line? (b) at least three, but no more than nine assigned to each line ? Two dozen = 24, Now we use generating functions so for (a) we would have $(x^3+x^4+.........)^4$ but we can take $x^{12}$ as a common factor so we have $(x^3+x^4+.........)^4 = x^{12}(1+x + x^2 + ........)^4$ and we already know that $\frac{1}{1-x} = (1+x+x^2+......)$ and so $\frac{1}{(1-x)^4} = (1+x+x^2+.......)^4$ and so we have  $x^{12}(1+x + x^2 + ........)^4 = x^{12}(1-x)^{-4}$. Now want to find the coefficient of $x^{12}$ in $(1-x)^{-4}$  which is ${-4 \choose 12} = (-1)^{12} {4 + 12 -1 \choose 12} = {15 \choose 12}$ Now for (b) I get stuck. First we have $(x^3 + x^4 + ........ +x^9)^4$, now again we take $x^{12}$ as a common factor and so we have $x^{12}(1 + x + x^2 + .... + x^6)^4$ , and now I want to find the coefficient of $x^{12}$ in $(1 + x + x^2 + .... + x^6)^4$, But how do we do this ?","['discrete-mathematics', 'generating-functions', 'combinatorics']"
1540366,Find count of subsets which have at least one even number,"I have this set
$S = \{1, 2, 3, ..., 30\}$ a I have to find count of subsets of subset $S$ which have at least one even number. I solved it that I substracted from total count of subsets ($2^{30}$) that subsets which have only odd numbers. Like that: $2^{30}-\sum\limits_{i=0}^{15} {15\choose i}$ Is my solution correct?",['discrete-mathematics']
1540383,Entire functions with finite $L^1$ norm must be identically $0$,"Another question from Complex Variables: An Introduction by Berenstein and Gay. Show that an entire function has finite $L^1$ norm on $\mathbb{C}$ iff $f\equiv0$. Does this also hold true for $L^2, L^{\infty}$? So, the $L^{\infty}$ case I think just follows from Liouville's Theorem, but the others I'm not sure about. How should I approach these? My intuition would be to use a power series expansion at $0$ for $f$, but the work I've done on paper with this hasn't really gone anywhere fruitful. Edit: As discussed in the comments, there are two cases to consider wrt the behavior at $\infty$: if $f$ has a pole there, then $f$ must be a polynomial so it must have infinite norm. So we are reduced to the case where $f$ has an essential singularity at $\infty$.","['analysis', 'complex-analysis']"
1540423,Differentiating the inverse of a function with respect to a parameter,"The derivative of a function's inverse is well understood, and it is explained in full detail here . Say I have a function $\varphi_\varepsilon:\mathbb{R}\to\mathbb{R}$, where $\varepsilon$ is a parameter.  I also know that the function is smooth, invertible, and has smooth inverse.  This leads us to the question: do we have a representation for $\frac{\partial}{\partial\varepsilon}\varphi_\varepsilon^{-1}$ that is similar to the single variable case? Here is a post that already addresses this question, but it is quite old and doesn't have any significant responses.  I'm also more interested in the theoretical case than a concrete example.","['calculus', 'functions']"
1540445,"Given a tridiagonal, 10x10 matrix, how can I show that its largest eigenvalue is greater than 1?","EDIT: I have finished this problem -- if anyone has interest in solving this problem, too, please read up on Rayleigh Quotients, the Courant min-max principle, and the interlacing property that the two theorems imply -- in this order.  Have fun :-) Given a tri-diagonal, $10x10$ matrix A, I want to show that a) its largest eigenvalue $\lambda_{max}(A)>1$ b) the matrix has 9 negative eigenvalues the matrix is $$\left(\begin{matrix}1&-3&0&0&\cdots&0&0\\-3&-2&1&0&\cdots&0&0\\0&1&-2&1&\cdots&0&0\\0&0&1&-2&\cdots&0&0\\\vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\0&0&0&0&\cdots&-2&1\\0&0&0&0&\cdots&1&-2\end{matrix}\right)_{10\times10}$$ How can I get started on this problem?  What concepts are being tested here?  This is an old linear algebra exam question, dating back to 1994 :-) Thanks,","['linear-algebra', 'matrices']"
1540452,Discrete Calculus -- Summing $\sum _{k=1}^{n+1} \frac{k}{(n+1)^k (-k+n+1)!}$,"$$\sum _{k=1}^{n+1} \frac{k}{(n+1)^k (-k+n+1)!}$$ Mathematica gives that the answer is quite surprisingly the reciprocal of $n!$. The first way I thought of trying to prove this was by induction, but I couldn't find a way to easily prove the case for $n+2$ assuming $n+1$ was true. A second way I thought of was using the discrete analog of the FTIC. However, while $k$ and $(n+1)^k$ are readily integrable using this version, $(n-k+1)!$ is a bit trickier, and I am not sure how to convert this to something that can be applied to the discrete FTIC. Could generating functions possibly be used?","['summation', 'discrete-calculus', 'discrete-mathematics']"
1540523,Find the limit $\lim\limits_{x\to\infty} f(x)= \lim\limits_{x \to \infty} \left(\frac{x}{x+1}\right)^x$,"I need to find the following: $$\lim_{x\to\infty} f(x)= \lim_{x \to \infty}\left (\frac{x}{x+1} \right )^x$$ I know that this limit = $\frac{1}{e}$ from plugging it into a calculator, but I have to prove it without using the fact that: $$\lim_{x\to\infty} f(x)=\lim_{x \to \infty}\left (\frac{x}{x+k} \right )^x=\frac{1}{e^k}$$ I started by exponentiating: $$\lim_{x\to\infty} f(x)=\lim_{x \to \infty}e^{\ln \left (\frac{x}{x+1} \right )^x}$$ and from here I've dropped the exponent $x$ in front of the $\ln$, and from here I'm getting stuck. Should I separate the $\ln$ like this? $$\lim_{x\to\infty} f(x)=\lim_{x \to \infty}e^{x(\ln(x)-\ln(x+1))}$$ This doesn't seem to be leading me down the right path, but I'm not sure how else to do it. Is there a way to apply L'Hopital? If so, how?","['calculus', 'real-analysis', 'limits', 'exponential-function']"
1540546,Integration of Exponential,"I am trying to integrate this function $f(x)=e^{-c/x}$. $$\int_{a}^b e^{-c/x} dx \\$$ where $c$ is just a constant and $0<a<b$. But $u$ subsititution leads to me to an integration by parts which leads to another integration by parts that keeps going. Is there a closed form solution to this integral?? I appreciate any help. Thank you. Update: I derived this function from a conditional pdf. $f(y|x)=x^{-1}e^{-y/x}$ and $f(x)=x$ on $[0,\sqrt{2}]$. By using Bayes Theorem you get a joint pdf $f(x,y)=e^{-y/x}$. Now using the joint pdf I am trying to solve for partial pdf $f_y(y)$. In the problem above I generalize it to $[a,b]$ and $y=c$.","['statistics', 'integration']"
1540557,Why are these three integrals all $0$?,"I have the following three triple integrals: $$\iiint_S x \sigma \mathrm{d} V$$
$$\iiint_S y \sigma \mathrm{d} V$$
$$\iiint_S z \sigma \mathrm{d} V$$ where $\sigma = k \left(1 - (\rho / a)^3 \right)$, $\rho$ is the distance from the origin in spherical coordinates, and $S$ represents a sphere at the origin with radius $a$. I can easily compute all three integrals to be $0$. However, I'm asked to make an argument based on the symmetry of the sphere, rather than actually calculating the integrals. I could, for example, substitute $x = \rho \cos \theta \sin \phi$ to calculate the first integral as 0, but what specifically about the symmetry of the sphere is causing this to be true?","['calculus', 'multivariable-calculus', 'integration']"
1540559,Why is the zero set of $T$ equal to the zero set of the ideal generated by $T$?,"I don't understand the last part of the first paragraph Clearly, if $\mathfrak{a}$ is the ideal... common zeros of the finite set of polynomials $f_1,\ldots,f_r$. I don't quite understand how an ideal generated by a set implies that their zero sets are equal. Also, I don't see why an ideal has finitely many generators if the ring is noetherian.","['abstract-algebra', 'algebraic-geometry']"
1540572,Upper bound of $a_{n+1}=a_n + \frac{1}{a_n}$ [duplicate],"This question already has answers here : Closed form for the sequence defined by $a_0=1$ and $a_{n+1} = a_n + a_n^{-1}$ (6 answers) Closed 7 years ago . How can I prove: If $$a_0=\alpha>0\quad and\quad a_{n+1}=a_n + \frac{1}{a_n}$$, then $$a_n^2<\alpha^2+2n+\frac{1}{\alpha^2}+\frac{1}{2}ln\left ( \frac{2n}{\alpha^2}+1 \right )$$
? I'll really appreciate your help. Thanks.",['sequences-and-series']
1540586,"Unit sphere in $L^p([0,1])$ is not compact.","I am studying $L^p$ spaces and I would like a proof why the unit sphere in $L^p([0,1])$ is not compact. I know that unit sphere is not compact in infinite dimensional spaces, but I think there is an elementary proof, tailored to this example. I would appreciate your help.","['lp-spaces', 'functional-analysis']"
1540594,"Determining matrix $A$ and $B$, rectangular matrix","Let $A$ be a $3\times 2$ matrix and $B$ be a $2\times 3$ be matrices satisfying $$AB=\begin{pmatrix} 8 & 2 & -2\\ 2 & 5 & 4\\ -2 & 4 & 5\end{pmatrix}$$
Calculate $BA$. How would you go for this problem? Do we start by noticing the matrix is symmetric? Any hints/ideas? Thanks","['linear-algebra', 'matrices']"
1540600,"If $T$ injective or $T$ surjective, what is the composition $T^\ast T$? (where $T^\ast$ denotes adjoint of linear map $T$)","Let $T:V \to W$ be a linear transformation between inner product spaces. Then $T^\ast: W \to V$ denotes the linear transformation with the property that for every $v \in V$ and $w \in W$, $$\langle T(v),w \rangle = \langle v, T^\ast(w) \rangle.$$ We call $T^\ast$ the adjoint of $T:V \to W$. $\cdot$ If $T$ is injective is $T^\ast T$ injective (or possibly a bijection)? $\cdot$ If $T$ is surjective is $T T^\ast$ surjective (or a bijection)? How can we prove this? Any pointers in the right direction appreciated.",['linear-algebra']
1540602,"A 4 × 4 grid of squares is filled in, with each of the 16 squares colored either black or white...","A 4 × 4 grid is filled in, with each of the 16 squares colored either black or white. Two colorings are regarded as identical if one can be converted to each other by performing any combination of flipping, rotating, or swapping the two colors (flipping all the black squares to white and vice versa). How many non-identical colorings are there? I've figured out the number of invariances for each individual transformation but the combinations are a little confusing. Is there an easier way of solving this than just looking at each combination?",['combinatorics']
