question_id,title,body,tags
349435,Proofs of $\cos(x+y) = \cos x\cos y - \sin x \sin y$,"Define $\sin x $ and $\cos x$ via their infinite series:
$$
\sin x = \sum_n (-1)^{n}\frac{x^{2n+1}}{(2n+1)!}, \qquad
\cos x = \sum_n (-1)^n \frac{x^{2n}}{(2n)!}.
$$
Is there a short, clever proof that $\cos(x+y) = \cos x \cos y - \sin x \sin y$ for all real $x,y$?  I can prove it using product series, or by showing that both sides (with $y$ fixed) are solutions of $f''(x) = -f(x)$, $f(0) = \cos y$, $f'(0) = - \sin y$. Does anyone know other (preferably slick!) proofs?","['trigonometry', 'real-analysis']"
349450,What are fair point values for Zombie dice?,"Described below is a modified version of Zombie dice ( http://www.sjgames.com/dice/zombiedice/ ) which the kids and I play. As in the original game, the idea is to sequentially roll sets of 3 specialty dice (described below and in the link above) until you either voluntarily stop rolling or bust. There are green, yellow an red dice whose faces show: Green: 3 brains, 1 shotgun blasts, 2 footsteps Yellow: 2 brains, 2 shogun blasts, 2 footsteps Red: 1 brain, 3 shotgun blats, 1 footsteps After each roll, you accumulate either brains (you ate your victim's brains) or shotgun blasts (victim shot you); footsteps are neutral (victim ran away). If you choose to stop rolling, you get 1 point for each accumulated brain. You bust when you accumulate 3 shotgun blasts and receive no points in that game. Instead of picking the dice blindly from a bag, as called for in the original version rules, we let the players pick which 3 dice to roll of any color available. Obviously, nobody in his right mind would roll anything other than the green dice, since they have the most brains and least shotgun blasts. We modified the rules by somewhat arbitrarily awarding 1 point for each green die, 2 points for a yellow die and 5 points for a red die. So, the riskier the dice you select to roll, the more points you stand to get. This introduces a nice risk/reward element to the game. Here is where you come in. I don't know whether our 1:2:5 point ratio is the fairest, that is, the one that balances the risk/reward of each die color. So: What should be the fair point value of each color die? I don't know whether one can calculate the desired values. Naturally, I could do a simulation by rolling, say, 1,000 games with each color dice and tallying the average number of brains accumulated right before the bust for each color; then, I would derive a factor by which to the yellow and red dice that equates the average outomes of the three colors. Also, I could but now don't have the tools (e.g., a BASIC interpreter) to write a simulation program, or the time to manually do the simulation. What say you is the right green:yellow:red ratio? BK asked: ""For one's turn must the same 3 dice be rolled each time or may one switch back and forth?"" LB says: No, you can switch dice. After each roll (except if you bust, of course) you: Keep the brains. Keep the shotguns. Return the footsteps to the dice cache. Pick any 3 dice from the dice cache, if you want to roll again, and roll. Note that as a game progresses and players accumulate brains and shotguns--depleting the dice cache--there will be times when a player's dice choice is limited by the dice then remaining in the cache. However, this does not happen often (we actually use 2 sets of Zombie dice and may even buy a couple more so there will always be plenty to pick from). Also, when there are fewer than 3 dice left in the cache, we replenish it by writing down on a Post-it the number of brains each player has and returning back to the cache their brain dice (could also do it for the shotguns be don't). So I think reasonable to disregard the dice depletion for our purposes. Dr. Tim Chow suggested I ask y'all. http://www.bgonline.org/forums/webbbs_config.pl?noframes;read=139865 I hope you find this problem interesting enough to give it a shot. Thanks in advance for taking the time to read this message and for hopefully figuring out the answer to the problem.","['dice', 'probability']"
349474,What are the rules for factorial manipulation?,"I know that $$(k+1)! - 1 + (k+1)(k+1)! = (k+2)! - 1$$ thanks to wolframalpha, but I don't understand the steps for simplification, and I can't seem to find any rules about factorial manipulations on google.  Can someone explain this please?","['factorial', 'algebra-precalculus']"
349476,Did I calculate this (simple) integral correctly?,"Given the contour $C$: we are asked to calculate $\displaystyle\frac{1}{2\pi i}\oint \frac{ze^{z^2-4z}}{z^2-1}dz$. I wrote it as such: $$\frac{1}{2}\left(\frac{1}{2\pi i}\oint \frac{ze^{z^2-4z}}{z-1}dz+\frac{1}{2\pi i}\oint \frac{ze^{z^2-4z}}{z+1}dz\right)$$ and got that it equals $$\frac{1}{2}N(C,1)e^{-3}-\frac{1}{2}N(C,-1)e^5=e^{-3}+e^{5}$$ Does this look correct? I'm a little shaky on whether I got the indexes right, and some of my friends got that it should equal $0.5(e^{-3}+e^{5})$ instead.","['complex-integration', 'complex-analysis']"
349482,"Is $f(x,y) = ( \frac{x}{x^2+y^2},\frac{2y}{x^2+y^2} )$ injective?","I came across this function in a context in which I need to know if it is injective. The function is $f:\mathbb{R}^2\backslash\{(0,0)\} \longrightarrow \mathbb{R}^2\backslash\{(0,0)\}$ and defined by $$f(x,y) = \Biggl( \frac{x}{x^2+y^2},\frac{2y}{x^2+y^2} \Biggl).$$ I guess it is injective. I have failed to find counterexamples, but I couldn't prove that it is injective. Maybe I should use some result, but I couldn't find any that seemed useful. Hints or answers are much appreciated.",['multivariable-calculus']
349483,Best estimate for random values,"Due to work related issues I can't discuss the exact question I want to ask, but I thought of a silly little example that conveys the same idea. Lets say the number of candy that comes in a package is a random variable with mean $\mu$ and a standard deviation $s$, after about 2 months of data gathering we've got about 100000 measurements and a pretty good estimate of $\mu$ and $s$. Lets say that said candy comes in 5 flavours that are NOT identically distributed (we know the mean and standard deviation for each flavor, lets call them $\mu_1$ through $\mu_5$ and $s_1$ trough $s_5$). Lets say that next month we will get a new batch (several packages) of candy from our supplier and we would like to estimate the amount of candy we will get for each flavour. Is there a better way than simply assuming that we'll get ""around"" the mean for each flavour taking into account that the amount of candy we'll get is around $\mu$? I have access to all the measurements made, so if anything is needed (higher order moments, other relevant data, etc.) I can compute it and update the question as needed. Cheers and thanks!","['statistics', 'estimation', 'random']"
349486,Riemann-Stieltjes integrability criterion,"I am currently reading through chapter 11 of Rudin's Principles of Mathematical Analysis, and I'm trying to solve problem 7: Find a necessary and sufficient condition that $f \in \mathfrak R(\alpha)$ on $[a,b]$. [the class of Rienmann-Stieltjes integrable functions, with integrator $\alpha$] Hint: Consider Example 11.6(b) and Theorem 11.33 . In example 11.6(b) Rudin defines an additive set function on
intervals according to a monotonically increasing function $\alpha$: $$\mu((a,b))=\alpha(b^- )-\alpha(a^+)\\
   \mu((a,b])=\alpha(b^+)-\alpha(a^+)\\
   \mu([a,b))=\alpha(b^-)-\alpha(a^-) \\
   \mu([a,b])=\alpha(b^+)-\alpha(a^-) $$ and states that it can be extended to a countably-additive set
function over a richer sigma-algebra. In Theorem 11.33 he proves that any Rieamann integrable function is Lebesgue integrable (dm) and that their values coincide. He also proves the criterion for Riemann integrability - continuity almost everywhere (dm). The method of the proof relies on Darboux sums. I'd greatly appreciate any help. EDIT: This is my attempt at the solution. Please tell me what do you think about it. First of all we extend $\alpha:[a,b] \to \mathbb R$ to a monotonically increasing function over $\mathbb R$, as follows: for $x<a$, $\alpha(x):=\alpha(a)$ and for $x>b$, $\alpha(x):=\alpha(b)$. We now can use example 11.6(b) to get a measure $\mu_\alpha$ over a sigma-algebra of subsets of $\mathbb R$, and we will immediately restrict it back to the interval $[a,b]$. I will try to prove that $f \in \mathfrak R(\alpha) \Leftrightarrow$ $f$ is continuous a.e. ($d \mu_\alpha$) Suppose $f$ is bounded. By definition 6.1 and theorem 6.4 there is a sequence $\{P_k \}$, of partitions of $[a,b]$, such that $P_{k+1}$ is a refinement of $P_k$, such that the distance between adjacent points of $P_k$ is less than $\frac{1}{k}$, and such that: $$\lim_{k \to \infty} L(P_k,f,\alpha)=\underline{\int}_a^b f d\alpha, \, \lim_{k \to \infty} U(P_k,f,\alpha)= \overline{\int}_a^b f d\alpha $$ Furthermore, since $\alpha$ is monotonic, it has only countably many points of discontinuity, so we can take the points of the partitions to be points where $\alpha$ is continuous. If $P_k=\{x_0,x_1,\ldots,x_n\}$ with $x_0=a,x_n=b$, define the functions $L_k,U_k:[a,b] \to \mathbb R$ according to: $$L_k(x)=m_1,U_k(x)=M_1$$ for $a \leq x \leq x_1$ and $$L_k(x)=m_i,U_k(x)=M_i $$ for $x_{i-1} < x \leq x_i,2 \leq i \leq n$. Notice that: $$\int_{[a,b]} L_k d\mu_\alpha=L(P_k,f,\alpha), \, \int_{[a,b]} U_k d\mu_\alpha=U(P_k,f,\alpha)$$ due to the continuity of $\alpha$ at the points of the partitions $\{ P_k \}$. We also have $$L_1(x) \leq L_2(x) \leq \ldots \leq f(x) \leq \ldots \leq U_2(x) \leq U_1(x) $$ for all $x \in [a,b]$, since $P_{k+1}$ refines $P_k$. We therefore have the existence of $$L(x):=\lim_{k \to \infty} L_k(x),U(x):= \lim_{k \to \infty} U_k(x) $$ and $L,U$ are bounded and measurable on $[a,b]$, $L(x) \leq f(x) \leq U(x)$ and $$\int_{[a,b]} L d\mu_\alpha=\underline{\int}_a^b f d\alpha, \, \int_{[a,b]} U d\mu_\alpha=\overline{\int}_a^b f d\alpha $$ thanks to Lebesgue's monotone convergence theorem. So far, nothing has been assumed on $f$, except that $f$ is a bounded real function on $[a,b]$. Note that $f \in \mathfrak R(\alpha)$ if and only if its lower and upper integrals coincide, hence if and only if $$\int_{[a,b]} L d\mu_\alpha=\int_{[a,b]} U d\mu_\alpha $$. Since $L \leq U$, this happens if and only if $L(x)=U(x)$ a.e. ($d\mu_\alpha$). In that case $f$ equals to a measurable function a.e. and therefore is measurable itself [because $\mu_\alpha$ is complete?]. Furthermore, if $x$ belongs to no $P_k$, it is quite easy to see that $L(x)=U(x)$ if and only $f$ is continuous at $x$. Since $\cup_k P_k$ is a countable set of continuity points of $\alpha$ it has $\mu_\alpha$-measure zero. So that $L=U$ a.e. if and only if $f$ is continuous a.e. QED","['integration', 'measure-theory', 'real-analysis', 'analysis', 'lebesgue-integral']"
349495,How do I prove: $\cos (\theta + 90^\circ) \equiv - \sin \theta $ [duplicate],"This question already has answers here : Proving $\sin (x)=\cos (90^\circ-x)$ [closed] (7 answers) Closed 5 years ago . How do I go about proving this?
I know one method is: $\eqalign{
   \cos (90^\circ + \theta ) &\equiv \cos90^\circ \cos\theta  - \sin90^\circ \sin\theta   \cr 
  &  \equiv (0)(\cos\theta ) - (1)(\sin \theta )  \cr 
  &  \equiv  - \sin \theta  \cr} $ I'd appreciate others, particularly ones that will allow me to visualize this identity on the unit circle. Thanks alot.","['trigonometry', 'algebra-precalculus']"
349522,Calculate the limit $\lim \limits_{n \to \infty} |\sin(\pi \sqrt{n^2+n+1})|$,Calculate $$\lim \limits_{n \to \infty} |\sin(\pi \sqrt{n^2+n+1})|$$,"['radicals', 'trigonometry', 'real-analysis', 'limits']"
349537,Does weak convergence of two independent sequences of random processes imply weak convergence of the couple sequence?,"I consider sequences of random processes in the Skorohod space. Let $F_n$ and $G_n$ converge weakly to F and G, respectively, in $D[-\infty,\infty]$ endowed with the supnorm. I suppose that this implies that $(F_n,G_n)$ converges weakly to $(F,G)$ in $D[-\infty,\infty]^2$ with the $\max\{\|\|,\|\|\}$ norm. 
My attempts:
Using the portmanteau lemma I tried to check that $\liminf_{n\to\infty} P((X_n,G_n)\in U)\geq P((F,G)\in U)$ for all U open in $D[-\infty,\infty]^2$. Let first U be a product of open sets in $D[-\infty,\infty]$, $U=U_1\times U_2$:
$$
\liminf_{n\to\infty}P((F_n,G_n)\in U)=\liminf_{n\to\infty}P(F_n\in U1)P(G_n\in U2)\geq P(F\in U1)P(G\in U2)=P((F,G)\in U)
$$
(I applied the portmanteau lemma on the componentwise convergence and used the independence of the processes for each n and of the limit processes).
For general U and disjoint unions of product sets with $\bigcup{U_{i,1}\times U_{i,2}}\subset U$, we have:
$$
\liminf_{n\to\infty}P((F_n,G_n)\in U)\geq\liminf_{n\to\infty}P((F_n,G_n)\in \bigcup{U_{i,1}\times U_{i,2}})\geq \liminf\sum P((F_n,G_n)\in U_{i,1}\times U_{i,2})\geq \sum P((F,G)\in U_{i,1}\times U_{i,2})=P((F,G)\in \bigcup U_{i,1}\times U_{i,2})
$$
hence
$$
\liminf_{n\to\infty}P((F_n,G_n)\in U)\geq \sup P((F,G)\in \bigcup U_{i,1}\times U_{i,2})
$$
where the sup goes over disjoint unions of product sets that are subsets of U.
I assume that this last term is equal to $P((F,G)\in U)$. I know that $D[-\infty,\infty]^2$ is not separable, however I still have hope for that to be true, as we are allowed to take product sets not only of balls, but of general open sets in $D[-\infty,\infty]$ which might damp the lack of seperability. 
Any ideas? Or am I simply wrong?","['statistics', 'stochastic-processes', 'weak-convergence', 'probability-theory']"
349548,Solve $\frac{1}{2x}+\frac{1}{2}\left(\frac{1}{2x}+\cdots\right)$,"If $$\displaystyle \frac{1}{2x}+\frac{1}{2}\left(\frac{1}{2x}+ \frac{1}{2}\left(\frac{1}{2x} +\cdots\right) \right) = y$$ then what is $x$? I was thinking of expanding the brackets and trying to notice a pattern but as it effectively goes to infinity. I don't think I can expand it properly, can I?","['summation', 'algebra-precalculus']"
349578,Why is this function smooth?,"Let $f: \mathbb{R}^n\rightarrow \mathbb{R}$ be the following function,
$$f(x)=\begin{cases}
\operatorname{e}^{-\tfrac{1}{1-\|x\|^2}} & \text{if }\|x\|<1,\\\\
0 & \text{otherwise}.
\end{cases}$$
How can I show that $f$ is smooth?","['derivatives', 'real-analysis', 'analysis']"
349585,Norm of a tensor product of operators,"I have two Hilbert spaces $H_1$ and $H_2$ which are subspaces of a bigger Hilbert space $H$ .
I also have two bounded linear functions $T_1:H_1\rightarrow H$ and $T_2:H_2\rightarrow H$ . I define the tensor product space $F=H_1\otimes H_2$ , and a linear function on it $T=(T_1\otimes T_2)$ . The vector space $F$ has the induced inner product from the Hilbert spaces: $$\langle\phi_1\otimes \psi_1, \phi_2 \otimes \psi_2\rangle = \langle\phi_1,\phi_2\rangle\langle\psi_1,\psi_2\rangle$$ and therefore an induced norm. I want to show that $\|T\| =\|T_1\| \cdot\|T_2\|$ , but I'm stuck since I cant show that $\|T\| \leq \|T_1\| \cdot\|T_2\|$ (the other inequality I've already shown).
Can anyone help?",['functional-analysis']
349601,How do I formalize this probability exercise?,"Exercise : Suppose that whether or not it rains on a given day depends on the weather conditions of the previous day. If it rains today, then it will rain tomorrow with probability $0.7$; if it doesn't rain today, then it will rain tomorrow with probability $0.4$. Given that it rained today, compute the probability that it will rain the day after tomorrow. An informal solution : there are two different ""ways"" in which it can rain the day after tomorrow. It either (A) rains tomorrow and then rains the day after tomorrow or (B) it doesn't rain tomorrow and then rains the day after tomorrow. Since these two possibilities are disjoint (i.e., they cannot be realized at the same time), it follows that the probability that it will rain the day after tomorrow is given by the sum of the probabilities that each of these two will happen: $$P(A\cup B) = P(A) + P(B) = (0.7)(0.7) + (0.3)(0.4) = 0.61$$ The problem : I have tried to formalize this solution by determining the probability space we're working with and formally writing exactly what the assumptions we are making are. I've been able to do this with other execises, but apparently this one isn't so straight-forward. One of my attempts was to put everything in terms of conditional probabilities, but that would force me to translate the assumptions of the exercise in a not-so-natural way: My try (conditional probabilities) : We can think of the sample space as $\Omega = \{f:\mathbb{Z}\to \{0, 1\}\}$. For all $n\in\mathbb{Z}$ the $n$-th number (i.e., $f(n)$) corresponds to the weather conditions on the $n$-th day (the $0$-th day is today, the first is tomorrow, the $-1$-th is yesterday, and so on): if it's zero, that means it didn't/won't rain that day; if it's one, that means it did/will rain that day. There's some unknown probability measure $P:\mathcal{P}(\Omega)\to\mathbb{R}$. Then $(\Omega, \mathcal{P}(\Omega), P)$ is a probability space. If for each $n\in\mathbb{Z}$, $C_n$ is the event ""it rained or will rain on the $n$-th day"", then: $$P(C_2|C_0) = P(C_2\cap C_1|C_0) + P(C_2\cap C_1^C|C_0) = P(C_1|C_0)P(C_2|C_1\cap C_0) + P(C_1^C|C_0)P(C_2|C_1^C\cap C_0) =^{(!?)} (0.7)(0.7) + (0.3)(0.4) = 0.61$$ Note that in the second to last equality we must assume that $P(C_2|C_1\cap C_0) = 0.7$ and $P(C_2|C_1^C\cap C_0) = 0.4$, but I think this wouldn't be true to the information we were given, which is more like $P(C_{n+1}|C_n) = 0.7$ and $P(C_{n+1}|C_n^C) = 0.4$ for all $n\in\mathbb{Z}$. Can anybody see a more faithful formalization for this exercise and its solution?","['probability-theory', 'probability']"
349612,"Integrating $\int_0^\infty \sin(1/x^2) \, \operatorname{d}\!x$","How would one compute the following improper integral: $$\int_0^\infty \sin\left(\frac{1}{x^2}\right) \, \operatorname{d}\!x$$ without any knowledge of Fresnel equations? I was thinking of using the comparison theorem since $\sin x$ is never greater than 1. However, I can't find a function always greater than 1 between 0 and infinity such that its integral from 0 to infinity converges. Thanks.","['improper-integrals', 'integration', 'contour-integration']"
349641,"If $f:[a,b]\to \mathbb{R}$ is continuous and nonnegative and $\int_a^b{f}=0$, then $f(x)=0$ for all $x\in [a,b]$","Suppose that a function $f:[a,b]\to\mathbb{R}$ is continuous and nonnegative. Prove that if $\int_a^b{f}=0$, then $f(x)=0$ for all $x\in [a,b]$. I've been trying to prove it using the extreme value theorem, continuity and the upper and lower sums but can't come up with something tight enough. More specifically, I've been trying to relate $|f(x)-f(t)|<\epsilon$ to the sum of $M_k-m_k(x_k-x_{k-1})$","['real-analysis', 'analysis']"
349666,Prove that $\lim \limits_{n \to \infty} n^2 \int_{0}^{\frac{1}{n}} x^{x+1} dx = \dfrac{1}{2} $,Prove that $$\lim \limits_{n \to \infty} n^2 \int_{0}^{\frac{1}{n}} x^{x+1} dx = \dfrac{1}{2} $$,"['integration', 'real-analysis', 'limits']"
349674,"If $a\mid b$ and $b\mid a$, then $a = b$ or $a = -b$. Is the converse true?","I was able to prove the original statement, but I'm stuck on the converse. If $a = b$ or $a = -b$, then $a\mid b$ and $b\mid a$. This holds true for $a = b = 1$, but I'm not sure how to proceed. I mean, it seems to be true.","['elementary-number-theory', 'divisibility', 'discrete-mathematics']"
349680,Why is the particular solution of $y'' - 4y' +3y = e^t$ not in the form of $Ae^t$,"The particular solution $Y_p(t)$ of this problem is actually in the form of $Ae^tt$, but  isn't it supposed to be $Ae^t$ ? Since there is no homogenous root = 0, why do we need to multiply $t$.",['ordinary-differential-equations']
349709,Proving a Problem has a Closed Form Solution,I have been working on how deduce the radius of a circle based only on knowing the length of a chord within the circle and the area of the segment the chord creates. This restricts the radius to only one possibility but I can't seem to find a closed form solution for finding the radius using the given information.  I am not interested in the answer to the question but I am interested in how one would go about proving whether or not this problem and others like it  have a closed form solution.  What field should I be looking in to or papers should I be reading in order to work on proving whether or not this problem and others like it have a closed form solution or not?,"['geometry', 'closed-form', 'algebra-precalculus', 'abstract-algebra']"
349721,Square root of Positive Definite Matrix,Let $A$ be an $n\times n$ positive definite matrix. Show that there exists a unique positive definite matrix $B$ such that $B^2=A$. I do know the existence. But what about the uniqueness? Would you help me out? Thank you.,"['matrices', 'linear-algebra', 'diagonalization']"
349738,Prove $\operatorname{rank}A^TA=\operatorname{rank}A$ for any $A\in M_{m \times n}$,"How can I prove $\operatorname{rank}A^TA=\operatorname{rank}A$ for any $A\in M_{m \times n}$ ? This is an exercise in my textbook associated with orthogonal projections and Gram-Schmidt process, but I am unsure how they are relevant.","['matrices', 'linear-algebra', 'matrix-rank', 'transpose']"
349749,Visualizing a Calabi Yau,"I would like to understand how I can visualize the quintic threefold 
$$ z_1^5 + z_2^5 + z_3^5 + z_4^5 +z_5^5 - 5\psi z_1z_2z_3z_4z_5 = 0$$ For a similar problem, Hanson proposes the following: These images show equivalent renderings of a 2D cross-section of the
  6D manifold embedded in CP4 described in string theory calculations by
  the homogeneous equation in five complex variables:  $$ z_1^5 + z_2^5 + z_3^5 + z_4^5 +z_5^5 = 0$$ 
  The surface is computed by assuming that some pair of
  complex inhomogenous variables, say $z_3/z_5$ and $z_4/z_5$, are constant
  (thus defining a 2-manifold slice of the 6-manifold), normalizing the
  resulting inhomogeneous equations a second time, and plotting the
  solutions to $z_1^5 + z_2^5 = 1$  The resulting surface is embedded in 4D
  and projected to 3D using Mathematica (left image) Let me at least take Hanson's quintic, and try to understand. I first put the equation in inhomogenous form, assuming $z_5 \neq 0$:
$$ (z_1/z_5)^5 + (z_2/z_5)^5 + (z_3/z_5)^5 + (z_4/z_5)^5 + 1 = 0$$ 
then $z_3/z_5$ and $z_4/z_5$, are constant and I'll assume equal to $1$. So:
$$ (z_1/z_5)^5 + (z_2/z_5)^5 + 3 = 0$$ 
then normalizing the resulting inhomogeneous equations a second time, I guess this just means that we let $z_5=1$ :
$$ z_1^5 + z_2^5 + 3 = 0$$ and plotting the
  solutions to $z_1^5 + z_2^5 = 1$ I guess he just had different values for $z_3/z_5$ and $z_4/z_5$ - right? Or did I misunderstand ? The resulting surface is embedded in 4D and projected to 3D what does that projection mean ? I just randomly set one of my 4D components (say, I set the imaginary component of $z_2$ to $\alpha$) ? Is-there something more fancy, or is-there something I misunderstood earlier in my reasoning ? Addendum Even doing so, this would result in two algebraic equations to solve (one for the real part, one for the imaginary part) : why would this define a surface embedded in 3D rather than a curve ? Thanks!","['algebraic-geometry', '3d', 'visualization']"
349773,Sequential allocation of $n$ balls into $n$ urns,"Assume that there are $n$ balls (numbered from $1$ to $n$) and $n$ urns (numbered from $1$ to $n$). At the beginning no ball is placed in any urn. At $t=1$, each ball is randomly put into an urn (no restriction on how many balls an urn can contain, each ball can be placed into one urn for example) Check each urn and if there is more than one ball, randomly choose one of the balls and keep it in the urn and remove all the other balls. (do this for each urn) At $t=2$, take the balls removed from some urn at $t=1$ and again randomly place into an urn (except the urn that the ball was removed from at $t=1$, say ball 1 was removed from urn 1, then ball 1 can be thrown at urns 2,3,...,n; same for other balls). Again, check each urn and if there is an urn that contains more than one ball and if there was no ball placed to that urn at $t=1$ choose one of them randomly and remove others. If there was a ball placed into that urn at $t=1$ remove all the new balls placed at $t=2$ from that urn. At $t=k$, take the balls removed from some urn at $t=(k-1)$ and again randomly place into an urn ( except the urn that the ball was removed from at $t=1,...,(k-1)$). Again, check each urn and if there is an urn that contains more than one ball, choose one of them randomly if there was no ball placed to that urn at $t=1,\ldots,(k-1)$. If there was a ball placed into that urn at $t=1,\ldots,(k-1)$ remove all the new balls placed at $t=k$ from that urn. Continue in this manner and stop when each urn has only one ball. Although it should be clear, just to emphasize, if a ball is chosen to be placed into an urn at the end of $t=k$, it remains in that urn afterwards, that is, it can not be removed in the later stages. Also, a ball can not be thrown into an urn it was removed in earlier stages. What is the probability that a certain ball, say Ball 1, is placed into some urn at exactly $t=k$ for each $k=1,\ldots,n$? Any suggestions for the solution or even references on similar problems would be appreciated. The answer for $t=1$ is easy: 
For example, consider Ball 1, and assume it is thrown into Urn 1 at $t=1$ and let $j$ be the number of balls that are placed into urn 1 at $t=1$ among the remaining $n-1$ balls. Then, probability that ball 1 is placed into urn 1 is: $$
\sum_{j=0}^{n-1}\binom{n-1}{j}\left( \frac{1}{n}\right) ^{j}\left( \frac{n-1}{n%
}\right) ^{n-j-1}\left( \frac{1}{j+1%
}\right)
$$","['probability', 'combinatorics']"
349793,How to prove $\lim_{n \to \infty} \cos \frac {\pi}{2^2}\cos \frac {\pi}{2^3}\cos \frac {\pi}{2^4}......\cos \frac {\pi}{2^n}=\frac {2}{\pi}$,"I came across the following problem that says: prove that $$\lim_{n \to \infty} \cos \dfrac {\pi}{2^2}\cos \dfrac {\pi}{2^3}\cos \dfrac {\pi}{2^4}......\cos \dfrac {\pi}{2^n}=\dfrac {2}{\pi}$$. My Attempt:  Let $$P=\lim_{n \to \infty} [\cos \dfrac {\pi}{2^2}\cos \dfrac {\pi}{2^3}\cos \dfrac {\pi}{2^4}......\cos \dfrac {\pi}{2^n}] \implies \log P=\lim_{n \to \infty} \sum_{r=2}^{n}\log (\cos \dfrac {\pi}{2^r})$$. Now,I am stuck and not sure which way to go. Can  someone point me in the right direction?  Thanks in advance for your time.","['real-analysis', 'limits']"
349802,A proof on infimum property,"Suppose that $A_1$ and $A_2$ are nonempty sets with $A_2 \subset A_1$ of real numbers that are bounded below. I want to show that $\inf A_1 \leq \inf A_2$ I managed to do the opposite, that is $\inf A_2 \leq \inf A_1$ and not sure what went wrong in my proof Let $x \in A_2$ , then because $A_2$ is bounded below there exists a number $y$ such that $y \leq x$ for all $x \in A_2$ $A_2$ is nonempty, so by the greatest lower bound property that there exists a number $y^*$ such that $y \leq y^* \leq x$ Now let $x \in A_2 \subset A_1$ , then since $A_1$ is bounded below we have $y \leq x$ for each $x \in A_1$ . By the greaest lower bound property, there exists a number $z^*$ such that $y \leq z^* \leq x$ , but recall $y^* \in A_1$ is an lower bound for some $x$ , so we must have $y^* \leq z^* \implies \inf A_2 \leq \inf A_1$ My motivation for proving this come from proving that if $P \subset Q$ , then $L(f,P) \leq L(f,Q)$","['elementary-set-theory', 'real-analysis']"
349806,Equality of integrals,this is q.2 of ahlfors p. 241: Show that $$\int_{-1}^{1}\frac{dt}{\sqrt {(1-t^2)(1-k^2t^2)}}=\int_{1}^{\frac{1}{k}}\frac{dt}{\sqrt {(t^2-1)(1-k^2t^2)}}$$ if and only if $k=(\sqrt{2}-1)^2$ . Thank you.,['calculus']
349814,Understanding a famous proof by Jitsuro Nagura,"I am going step by step through a proof by Jitsuro Nagura which can be found here Nagura shows: $\frac{\Gamma'}{\Gamma}(x) - \frac{\Gamma'}{\Gamma}(\frac{x+n-1}{n}) = \int_0^\infty\frac{1}{1-e^{-t}}(e^{-\frac{x+n-1}{n}t} - e^{-xt})dt > 0 (x > 1)$ Then he states: $\frac{1}{n}\log\Gamma(x) - \log\Gamma(\frac{x+n-1}{n})$ is an increasing function when $x \ge 1$ . I am not clear how this follows.  I am not clear where $\frac{1}{n}$ follows from.  If someone could explain how the conclusion follows, I would greatly appreciate it. Thanks, -Larry","['gamma-function', 'elementary-number-theory', 'number-theory']"
349826,Counterexample: $G \times K \cong H \times K \implies G \cong H$,"I am having a hard time finding a counterexample for the statement:
$G \times K \cong H \times K \implies G \cong H$ I think this should be true for abelian, finite groups. But is this true in general? What would be a counterexample? Any hints appreciated! 
Thanks","['examples-counterexamples', 'group-theory', 'abstract-algebra']"
349834,What topological structures have exactly one base?,"for homework What topological structures have exactly one base? I think that: $\{\emptyset,X\}$ his basis is $\{\emptyset,X\}$ is this ok?  I am not sure, could please provide me another example and why?",['general-topology']
349839,Case of equality in Markov's inequality,"Find an example where Markov's inequality is tight in the following sense: For each positive integer $a$ , find a non-negative random variable $X$ such that $P(X\ge a)=E(X)/a$ . How to do this problem, I am really confused. Also, what is the definition of Markov's inequality?","['probability-theory', 'inequality']"
349855,Does $G\times K\cong H\times K$ imply $G\cong H$?,Let $G\times K$ be a finite group. Suppoose $G\times K\cong H\times K$. Is this sufficient to imply $G\cong H$?,"['finite-groups', 'group-theory']"
349873,Reflections in regular polygons,"I was thinking about regular polygons and paths beginning at a vertex such that whenever the path hits a side, it has a mirror reflection (angle of incidence equalling the angle of reflection) and continues on, undergoing a mirror reflection whenever it hits a side until it hits a vertex and the path ends. If the polygon is a unit square, $ABCD$, let the path begin at $A$. WLOG, let the first side it hits be  $BC$ and let $E$ be the point of intersection. I figured out that if $BE$ is $\frac{a}{b}$, where $\frac{a}{b}$ is rational and $a,b$ are co-prime, then the path will terminate. I realized that within the cartesian plane, the path described is the same as the path traveled from $(0,0)$ to $(a,b)$ so I can actually figure out the number of reflections during the path, the length of the path and the vertex where it ends (by labeling the lattice points based on reflections of the unit square). Similarly, I realized I can do the same if the polygon is a unit equilateral triangle, $ABC$. Let $A$ (the origin) be the initial starting point and $E$ is the point on $BC$ that the path initially hits, where $BE$ is $\frac{a}{b}$.
I can have a tessellation of the plane with unit equilateral triangles and we can consider a large equilateral triangle, $AB'C'$ of side $a+b$. Then the path described is that same as the path from $A$ to $X$, where $X$ is on $B'C'$ such that $B'X$ is $a$. Again, we can ascertain the length of the path, the number of reflections and the vertex where it ends. My question is how would one approach this problem for a regular pentagon or heptagon, or any regular polygon that you cannot tessellate the plane with. In the case of the hexagon, I know that I can tesselate the plane with hexagons but am unsure of how to describe the path in terms of a straight line in terms of $a$ and $b$ and unsure of how to determine the final vertex since different reflections produce different vertices (for example, suppose we reflect the hexagon over $BC$ and over $CD$. Then the image of $B$ is the same as the image of $D$). If anyone knows any other interesting observations, properties or problems (open or closed) about this topic, I'd like to hear about it. Thanks!",['geometry']
349885,Ideals of the algebra of all bounded linear operators on $\ell_p \oplus \ell_q$,Let $\mathcal{L}(X)$ be the algebra of all bounded linear operators from $X$ to $X$ for Banach space $X$. I need to show that $\mathcal{L}(\ell_p \oplus \ell_q)$ for $p \neq q$ contains at least two nontrivial closed two-sided ideals.,"['lp-spaces', 'ideals', 'functional-analysis', 'banach-spaces']"
349889,Algebraic Properties of Residues in Complex Analysis,"I'm interested in how residue at a point operation complies with algebraic operations: $$\underset{z_0}{\operatorname{Res}}(f + g) = \, ?$$ $$\underset{z_0}{\operatorname{Res}}(f g) = \, ?$$ my guess is that $$\underset{z_0}{\operatorname{Res}}(f + g) = \underset{z_0}{\operatorname{Res}} f + \underset{z_0}{\operatorname{Res}} g$$ whereas nothing can be said about multiplication. If that's true, what about $$\underset{z_0}{\operatorname{Res}} \sum_{n=0}^\infty f_n = \, ?$$ Can I pull the residue operator under the summation sign? Probably there might be some algebraic properties involving compositions of elementary functions.","['residue-calculus', 'complex-analysis']"
349902,Injectivity and Surjectivity of the Exponential Function,Why is the exponential function injective but not surjective?,['real-analysis']
349907,Cross Product Intuition,"I know the cross product between a vector $a$ and a vector $b$ is just a vector whose magnitude is the product of magnitude of $b$ times the magnitude of the perpendicular component of $a$ in relation to $b$.This arises in many applications like in calculating the torque and the magnetic force. The magnitude of this vectors definies how perpendicular $a$ and $b$ are ... The more perpendicular, the higher the magnitude.This fact implies that, in order for it to be a measure of perpendicularity, we need the magnitude of $a \times b$ to be $\lvert a \rvert \lvert b \rvert \sin(\theta)$ and that should be a no-brainer. It turns out that measuring the ""perpendicularity"" is the same as measuring the area between the paralelogram formed by the two vectors, the more perpendicularity, higher the area that is formed. Concluding, I fully understand the reasoning between why the magnitude of the cross product is the way it is. But i want to keep building my intuition on Cross Product and I'm kinda stuck with two problems: 1- What is the reason (other than the fact that the magnetic force is vector perpendicular to both $v$ and $b$, and that the normal vector to a plane is a vector perpendicular to two vectors in the plane, for example) that this measure of perpendicularity ($\lvert a \rvert \lvert b \rvert \sin(\theta)$) was attributed to the magnitude of a vector? Why wasn't the cross product defined as just this magnitude? Was the orthogonal vector just some convenient form of killing two birds with a stone (getting both the measure of perpendicularity and getting the normal vector to the plane spanned by $a$ and $b$)? 2 - Is there any intuition that the components of cross product $a \times b$ are: $ \langle(a_y b_z - a_z b_y), (a_z b_x - a_x b_z), (a_x b_y - a_y b_x) \rangle$? I'm saying intuition because I know the proof that the only vector (well one of the two possibles) who holds magnitude $\lvert a \rvert \lvert b \rvert \sin(\theta)$ and is perpendicular to both $a$ and $b$ should have this components.","['vector-spaces', 'geometry', 'analytic-geometry']"
349910,Is the Lebesgue integral of a continuous function necessarily continuous?,"Suppose that $f:\mathbb R \rightarrow [0,\infty]$ is measurable and that $\int_{\mathbb R}f \, dx<\infty$. (a) Prove that $F(x)=\int^x_{-\infty}f(y) \, dy$ is a continuous function. (b) Is $F$ necessarily uniformly continuous? Justify your answer. I've managed to get the first part by considering a sequence of $\{z_n\}\subset (-\infty,x]$ with $z_n\rightarrow z$. Then setting $f_n=f_{\chi(-\infty,z_n]}$ and using the Dominated Convergence Theorem, I get sequentially continuity and hence continuity. How do I go about trying to prove (b)? I'm guessing that the answer is no. I was trying to come up with a sequence of continuous functions that eventually has a discontinuity, but I don't know if this is possible? My other thoughts were along the lines making defining $f(y)$ such that $F(x)=x^2$ and we know already that $x^2$ is not uniformly continuous. Can that work?",['measure-theory']
349919,Rational Curves,"I have a set of small questions about rational curves. A rational curve is a curve birationally equivalent to $\mathbb{P}^1$. But I've also seen it said that ""$X$ contains a rational curve"" when there is a nonconstant (rational?) morphism $f$ from $\mathbb{P}^1$ to $X$. Does this mean that the image of $f$ is a rational curve? If so, why is that true? Are there easy conditions that $f$ must satisfy for its image to be isomorphic to $\mathbb{P}^1$?",['algebraic-geometry']
349924,Function mapping combinations to natural numbers,"I am looking for a function $f$ mapping combinations (from any finite set) to natural numbers. The hard part is that the function should have the following features: The function should be injective (I'm not looking for a hashing function). Let $g(c_1, c_2)$ be a function that takes two combinations $c_1$ and $c_2$ and returns 1 if $c_1 > c_2$, 0 if $c_1 = c_2$, -1 otherwise according to a certain total order in the set of combinations. If $g(c_1, c_2) = 1$, then $f(c_1) > f(c_2)$ should hold, if $g(c_1, c_2) = 0$ then $f(c_1) = f(c_2)$ and if $g(c_1, c_2) = -1$ then $f(c_1) < f(c_2)$. If $g(c_2, c_1) = 1$ and it doesn't exist any $c$ for which $g(c, c_1) = 1$ and $g(c, c_2) = -1$, then $f(c_2) - f(c_1) = 1$. I am a computer programmer. I haven't got a strong mathematical background (as you could deduct from my inexact formalism), so I just cannot figure out myself how to build such a function. In order to be more clear, I'll make an example. $A = \{a_1, a_2, a_3\}$ $C = \{\{a_1, a_2\}, \{a_1, a_3\}, \{a_2, a_3\}\}$ $f(\{a_1, a_2\}) = 0$ $f(\{a_1, a_3\}) = 1$ $f(\{a_2, a_3\}) = 2$ Both the $f(x)$ function and its inverse should be ""easy"" to compute. The ""trivial"" solution of creating a reference map by enumerating all the combinations is not an option. I'm not looking for a ready-to-implement solution that you just provide me - I would create my own function or search for one online and/or in the literature (if I just knew where and how to search). Thank you in advance for your help.",['combinatorics']
349940,"If $x \neq 0,y \neq 0,$ then $x^2+xy+y^2$ is .....","I came across the following problem that says: If $x \neq 0,y \neq 0,$ then $x^2+xy+y^2$ is 1.Always positive 2.Always negative 3.zero 4.Sometimes  positive and sometimes negative. I have to determine which of the aforementioned options is right. Now since $x \neq 0,y \neq 0$, so $ x^2+xy+y^2=(x-y)^2+3xy > 0$,if $x,y$ are of  same sign. But if $x,y$ are of different sign,I am not sure about the conclusion. Can  someone point me in the right direction?  Thanks in advance for your time.",['algebra-precalculus']
349957,Geometric meaning of completion and localization,"Let $R$ be a commutative ring with unit, $I$ an ideal of $R$ and consider the following three constructions. The localization $R_I$ of $R$ at $I$ (i.e. the localization of $R$ at the multiplicative system $R\setminus I$) gives a morphism
$$
f_1:\operatorname{Spec}(R_I)\to \operatorname{Spec}(R)=:X
$$ The completion $\widehat{R}_I$ of $R$ at $I$ gives a morphism
$$
f_2:\operatorname{Spec}(\widehat{R}_I)\to X
$$ For the special case $I=(a)$, the localization $R_a$ (i.e. the localization of $R$ at the multiplicative system $\{1,a,a^2,\ldots\}$) gives a morphism
$$
f_3:\operatorname{Spec}(R_a)\to X
$$ My question is: What is the geometric meaning of all three constructions and how are they related? This is what I ''know'' already or describes at least the style of answer I would appreciate. As remarked in the comments, $I$ has to be a prime ideal. $R\to R_I$ is injective iff $R\setminus I$ contains no zero divisors which is the case if $I$ is a prime ideal. The scheme $\operatorname{Spec}(R_I)$ is the intersection of all the neightbourhoods of $I$ in $X$. This is a little contra-intuitive for me since the last statement sounds like ''$f_1$ is injective'' but the $\operatorname{Spec}$-operator should turn 'injective'' and ''surjective'' around somehow (I know this is literally not true but I only want to get a feeling like ''is contained'', ''is bigger'', ''is smaller'', etc.). $\operatorname{Spec}(R_a)$ is somehow the opposite of $\operatorname{Spec}(R_{(a)})$ (= the intersection of all the neightbourhoods of $(a)$ in $X$) because $\operatorname{Spec}(R_a)$ seems to be something like the union of all the open sets of $X$ not containing the point $(a)$. $R\to\widehat{R}_I$ is injective iff $\cap I^n=(0)$ and this holds very often (e.g. for $R$ noetherian and either an integral domain or a local ring). Hence (this is probably false intuition as remarked before), $f_2$ should be something like a ''projection'' (from something ''big'' into something ''small''). But what is geometrically the difference between localization and completion. I don't have a geometric idea of completion at all. As remarked by Qiaochu Yuan in the comments below, one should not think of $\operatorname{Spec}$ as injective-surjective switching.","['commutative-algebra', 'algebraic-geometry']"
349968,What exactly is an $R$-algebra?,"I've looked up numerous definitions, and all of them talk of a new operator that is added to the $R$-module that is the $R$-algebra. One definition says An $R$-algebra, where $R$ is a commutative ring, is a ring with identity together with a ring homomorphism $f\colon R \to A$ such that the subring $f(R)$ of $A$ is contained within the center of $A$."" I don't see how the fact that an $R$-algebra is an $R$-module with a bilinear operator follows from this definition. 
Thanks in advance.","['ring-theory', 'abstract-algebra']"
350001,Show $g(\mathbf{x}) \leq h(\mathbf{x})$ implies $\int g(\mathbf{x})\mathrm{d}\mathbf{x} \leq \int h(\mathbf{x})\mathrm{d}\mathbf{x}$,"Suppose I have $g$ and $h$ from $\mathbb{R}^p\to\mathbb{R}$ such that for all $\mathbf{x}$, $g(\mathbf{x}) \leq h(\mathbf{x})$. I want to prove that the integral over all $\mathbb{R}^p$ of $g$ is less than or equal to that of $h$ (given that the integral over all $\mathbb{R}^p$ of $h$ is finite). In the 1 dimensional case I could write the infinite integral as a limit of a definite integral and prove that the fact holds for the definite integral over $[a,b]$. How would I go about proving this for the general case above? I only have a basic understanding of multivariable calculus.","['multivariable-calculus', 'measure-theory', 'integration']"
350002,Total variation norm in $\mathbb{R}^n$ [duplicate],"This question already has answers here : Difference between two measures (2 answers) Closed 11 years ago . Let's consider total variation norm ρ( , ) on $(\mathbb{R}^n, \mathcal{B}(\mathbb{R}^n)),$ where $\mathcal{B}(\mathbb{R}^n)$ is a Borel $\sigma$-algebra. Is it true that for probabiblity measures $P$ and $Q$
$$ρ(P,Q):=\sup_{A∈\mathcal{B}(\mathbb{R}^n)}|P(A)−Q(A)|=\sup_{I=I_1\times\dots\times I_n}|P(I)−Q(I)|?$$ Here $I_k=(a_k, b_k].$ If it is, why? Thanks in advance!","['measure-theory', 'probability']"
350007,On similar matrices and polynomial matrices,"Let $A,B,P\in M_n(F)$. Suppose that $A$ and $B$ are similar, thus $A=P^{-1}BP$. If $p(x)=a_0+\ldots+a_nx^n$, and $T:V\to V$ be a linear transformation. Defining $$p(T)=a_0I+\ldots+a_nIT^n$$ How to prove that $$p(A)=P^{-1}p(B)P$$ Thank you very much for any help.","['matrices', 'linear-algebra', 'polynomials']"
350011,Hard proof concerning the periodicity of trigonometrical functions. Is that a challenge or just trivial,"i want to know if exist or if you can develop or give me ideas of a proof to show that the least number for which sine is periodic is $2\pi$
$$\neg \{\exists n\in \mathbb{R} \wedge n < 2\pi:  \sin(x)=\sin(x+n)\}$$
$$\neg \{\exists n\in \mathbb{R} \wedge n < 2\pi:  \cos(x)=\sin(x+n)\}$$ Is not enough to proof it by definition of fundamental period, i am wondering for a proof that avoids definitions of certain properties (i am not avoiding properties, just definitions, in order to show that from the inner core of geometry and logic). Can we build trigonometry without the definition of fundamental period? We are allowed to use ALL THE THEORY we know about, analysis, logic, model theory, geometry, combinatorics, even topology, if you want, we just may try to avoid if it`s possible the definition of the periodicity. If that is a just a definition then.... I am not taking out the rest of the axioms of geometry, i am just trying to figure out wether or not the periodicity of trigonometrical functions is an axiom; or you can use any axiom, property, theorem that do not depends on that fact to proof it. Off course, we could not use Fourier series because that theory depends mainly on the periodicity of those functions, if we go further, i think that the sine function depends integrally on the existence of a least bound of periodicity. Thank you very much","['geometry', 'foundations', 'logic', 'trigonometry', 'alternative-proof']"
350022,Hilbert space and its dual,"I have an elliptic equation in the form $$-\Delta u + u =F(u).$$ For any $\phi \in C^{\infty}_{0}$ we rewrite the elliptic equation in weak form $$\int \limits_{\mathbb{R}^n}\left(-\Delta u + u\right)\phi dx=\int \limits_{\mathbb{R}^n} F \phi dx.$$ Then, thanks to the definitions of $L^{2}$ and $H^{1}$ norms we obtain $$\left\|u\right\|_{H^{1}}\left\|\phi\right\|_{L^{2}}\leq \left\|F\right\|_{L^{2}}\left\|\phi\right\|_{L^{2}} \\ \left\|u\right\|_{H^{1}}\leq \left\|F\right\|_{L^{2}}.$$
Here, I want to understand the relationship between $H^1$ and its dual space $H^*$. Is it possible to see $\left\|u\right\|_{H^{1}}\leq \left\|u\right\|_{H^{*}}$ and/or $\left\|F\right\|_{L^{2}}\leq \left\|u\right\|_{H^{*}}$? P.S.:I saw a similiar question in: Hilbert dual space (inequality and reflexivity) , but I couldn't understand well.","['functional-analysis', 'partial-differential-equations']"
350028,Block diagonal matrix diagonalizable,"I am trying to prove that: The matrix $C = \left(\begin{smallmatrix}A& 0\\0 & B\end{smallmatrix}\right)$ is diagonalizable, if only if $A$ and $B$ are diagonalizable. If $A\in GL(\mathbb{C}^n)$ and $B\in GL(\mathbb{C}^m)$ are diagonalizable, then is easy to check the $C\in GL(\mathbb{C}^{n+m})$ is diagonalizable. But if I suppose that $C$ is diagonalizable, then exists $S = [S_1, S_2, \ldots, S_{n+m}]$ , $S_i\in\mathbb{C}^{m+n}$ , such that $S^{-1}CS = \mbox{diag}(\lambda_i)$ . Now $CS_i = \lambda_iS_i$ , and  if $S_i = \left(\begin{smallmatrix}x_i\\y_i\end{smallmatrix}\right)$ , $x_i\in\mathbb{C}^n$ and $y_i\in\mathbb{C}^m$ , then $$Ax_i = \lambda_ix_i\quad\mbox{ and }\quad By_i = \lambda_iy_i.$$ So, if I can justify that $\{x_1,\ldots,x_{n+m}\}$ have exactly $n$ linear independent vectors and $\{y_1,\ldots,y_{n+m}\}$ have $m$ linear independent vectors, I will prove that $A$ and $B$ are diagonalizables, but I don't know how to prove that? Please, anyone have an idea? Thanks in advance.","['matrices', 'linear-algebra', 'block-matrices', 'diagonalization']"
350034,Inverse of Identity plus Volterra operator,"consider the following operator or $L_2(0,1)$,
$(Pw)(x)=w(x)+\int_0^x K(x,y)w(y)dy+\int_x^1 K(y,x)w(y)dy$, where the integral kernel is a polynomial. I am trying to construct the inverse of this operator, I can construct inverses of the operators where the integral kernel is just a function of $y$, but I don't know how to proceed for the operator $P$. Note that the operator $P$ is self-adjoint. Any help would be most helpful, thanks.","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
350035,Evaluating $\int_0^{\infty}\frac{e^{-x}}{1+x^2}dx$,"I'm trying to evaluate $$\int_0^{\infty}\dfrac{e^{-x}}{1+x^2}dx$$
By making the substitution $x=\tan\theta$,  $$\int_0^{\infty}\dfrac{e^{-x}}{1+x^2}dx=\int_0^{\frac \pi 2}\exp(-\tan\theta)d\theta$$ So it converges to something less than $\frac \pi 2$. Is there any way to  find the exact value, using only elementary methods?","['improper-integrals', 'calculus', 'integration']"
350041,Simple random sample without replacement,"I have a data file from which I wish to create a uniformly distributed simple random sample, without replacement. Will the following algorithm give me an unbiased result? 1 Set T = total number of records in the file.
2 Set S = number of samples required.
3 For each record in the file, in order:
  i    Set X = a random uniformly distributed number between 0 and 1.
  ii.  If X < S/T, select the record and decrement S.
  iii. Decrement T.","['statistics', 'random', 'algorithms']"
350042,Arrangement of zeroes and ones,"I'll be grateful for any ideas (or even solutions!) for the following task. I really want to know how to solve it. Let $M$ be an arbitrary positive integer which represents the length of line constructed of $0$ and $1$ symbols. Let's call $M$-$N$-line a line of $M$ symbols in which there are exactly $N$ ($1 \leq N \leq M$) ones (all other elements are zeroes). Also the number $L$ is given such that $1 \leq L \leq N$. The task is to calculate the number of all $M$-$N$-lines in which there is a group of exactly $L$ consecutive ones and no group of more than $L$ consecutive ones. For example if $M = 6$, $N = 4$, $L = 2$ then there are $6$ such $M$-$N$-lines: $$1-1-0-0-1-1$$ $$1-1-0-1-0-1$$ $$1-1-0-1-1-0$$ $$0-1-1-0-1-1$$ $$1-0-1-0-1-1$$ $$1-0-1-1-0-1$$ Thanks in advance!",['combinatorics']
350043,The intersection of a normal subgroup and Sylow $p$-subgroup,"Let $G$ be a group and $P\in Syl_p(G)$ , $H$ is normal in $G$ . I want to show that $P\cap H\in Syl_p(H)$ . So I let $P_0\in Syl_p(H)$ . $P\cap H$ is a $p$ subgroup of $H$ , so by Sylow 2nd Theorem, $P\cap H \leq P_0$ . And by Sylow's 2nd and 3rd theorem, I get that there exists $g\in G$ such that $P_0 \leq gPg^{-1}$ . I think I want to prove that $P_0 \leq P\cap H$ next in order to conclude that $P_0=P\cap H$ but got stuck at this part.","['sylow-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
350047,Let $R$ be a finite commutative ring. Show that an ideal is maximal if and only if it is prime.,Let $R$ be a finite commutative ring. Show that an ideal is maximal if and only if it is prime. My attempt: Let $I$ be an ideal of $R$. Then we have $I$ is maximal $\Leftrightarrow$ $R/I$ is a finite field $\Leftrightarrow$ $R/I$ is a finite integral domain $\Leftrightarrow$ $I$ is a prime ideal. Is my proof valid ?,"['ring-theory', 'ideals', 'finite-rings', 'abstract-algebra']"
350066,Finiteness of groups preserving a symmetric positive definite bilinear form,"This question arises from reading the note Hodge cycles on abelian varieties by P. Deligne (notes by J.S. Milne).  Suppose we are given a group $G$ (for example,  either a fundamental group $\pi_1(S, s_0)$ or a Galois group $Gal(k/k_0)$) acting on a finite dimensional $\mathbb{Q}$-vectors space.   It seems to me that the author concludes that the action factors through a finite subgroup once it is known there is a symmetric  positive definite $\mathbb{Q}$-valued bilinear form on $V$.  Of course, this is note true in general (Take $V=\mathbb{Q}^2$ with the standard inner product, for example.)  So I am wondering what is the missing link in my understanding of the proofs.  The proofs in question are Theorem 2.15 and (iii) of Propositin 2.9(b).   Why does the action factors through finite subgroups in those proofs?","['linear-algebra', 'group-theory', 'algebraic-geometry']"
350099,Exercise Functional Analysis,"Let $\mathcal{F}$ be the set of all functions $f: \mathbb{R} \rightarrow \mathbb{R}$. Consider an operator $\mathcal{O}: \mathcal{F} \rightarrow \mathcal{F}$ such that: $\mathcal{O}( f_1 + f_2) = \mathcal{O}(f_1) + \mathcal{O}(f_2) \ \text{for all } f_1, f_2 \in \mathcal{F}$; $\mathcal{O}( f_1 \cdot f_2) = \mathcal{O}(f_1) \cdot f_2 + \mathcal{O}(f_2)\cdot f_1 \ \text{for all } f_1, f_2 \in \mathcal{F}$; $\mathcal{O}( \mathbb{1}) = \mathbb{0} $. Question.
Find all operators satisfying the above properties. Notation.
The sum $f := f_1 + f_2$ is defined as $f(x) := f_1(x) + f_2(x)$ for all $x \in \mathbb{R}$. The product $f := f_1 \cdot f_2$ is defined as $f(x) := f_1(x) f_2(x)$ for all $x \in \mathbb{R}$. $\mathbb{1}$ denotes the constant function $f(x) = 1$ for all $x \in \mathbb{R}$. $\mathbb{0}$ denotes the constant function $f(x) = 0$ for all $x \in \mathbb{R}$. Comments.
Trivially, $\mathcal{O}(f) := \mathbb{0}$ satisfies the properties. Also the derivative, i.e. $\mathcal{O}(f) := df/dx$ does, whenever $\mathcal{F}$ is the set of differentiable functions. I am not able to prove if those are the only ones, even for this particular $\mathcal{F}$.","['functional-analysis', 'functions']"
350110,The pattern of bitstrings of square numbers,"Here is a picture of ""square numbers"" from mathworld website. A plot of the first few square numbers represented as a sequence of binary bits is shown above. The top portion shows $1^2$ to $255^2$ , and the bottom shows the next 510 values. (Black is for ""one"" bit, and while is for ""zero"" bit) I want to learn more about this pattern. However, there is no further explanation about the pattern of this plot from the website. Is there any known result about this pattern ?",['number-theory']
350125,Multiplicities of conjugate roots,"If a real polynomial of degree n has a complex root, then it is clear that its conjugate is also a root. But how to verify that the multiplicities of the conjugated roots are equal?","['functions', 'real-analysis']"
350130,Doubt about the Domain of the chart on a Manifold,"I have a doubt about the domain of the chart on a manifold. Suppose $M$ is a smooth manifold and that $(U, \varphi)$ is a chart on $M$, then $\varphi : U \to \mathbb{R}^n$ has $U$ as it's domain. That's fine to me. My doubt has to do with the comparison of this to the case of regular surfaces in $\mathbb{R}^3$. In that case, the surface $S$ is a subset of $\mathbb{R}^3$ and so, if $(V, \psi)$ is a chart on $S$, then I know that $\psi$ takes points in $\mathbb{R}^3$ and takes to $\mathbb{R}^2$. In other, words, I know that I can write: $$(u,v)=\psi(x_1,x_2,x_3)$$ And so, I know many things, for instance, I know that to build the chart I'll need to find one expression of $x_1, x_2,x_3$ which gives $(u,v)$ respecting the properties required. On general Manifolds, however, I feel a little confused. I mean, the manifold isn't inside another higher dimensional ambient space, so, if $(U, \varphi)$ is a chart, I would have: $$(x^1, \dots, x^n) = \varphi(\text{what goes here ?})$$ And the $\text{what goes here ?}$ is because if I plug there some $m$-tuple of numbers, I'm supposing that $M$ is a subset of $\mathbb{R}^m$ and that supposition shouldn't be necessary. I've read for instance, that to find charts for the $n$-sphere, we can consider it as a subset of $\mathbb{R}^{n+1}$, but that isn't really necessary. My point is, I know that elements of the codomain of a map of a chart will be $n$-tuples of numbers, that's fine, I know how to work with such objects. But how will be the elements of the domain, if we do not express the manifold as a subset of a higher dimensional ambient space? I think I've made clear my point. If I've failed to explain my doubt, please ask and I'll try to explain better. Thanks very much in advance! EDIT: The definition of Manifold I'm working with is the definition as presented by Manfredo Do Carmo: A smooth manifold of dimension $n$ is a set $M$ with a family of bijective maps $\varphi_\alpha : U_\alpha \to M$ from open sets $U_\alpha\subset \mathbb{R}^n$ to $M$ such that: $\bigcup_\alpha\varphi_\alpha(U_\alpha)=M$ For each pair $\alpha, \beta$ with $\varphi_\alpha(U_\alpha)\cap\varphi_\beta(U_\beta)=W\neq\emptyset$ we have $\varphi_\alpha^{-1}(W)$, $\varphi_\beta^{-1}(W)$ open in $\mathbb{R}^n$ and $\varphi_\beta^{-1}\circ\varphi_\alpha$, $\varphi_\alpha^{-1}\circ\varphi_\beta$ are differentiable. The family $\left\{U_\alpha, \varphi_\alpha\right\}$ is maximum with respect to conditions 1 and 2. The only point is that on my text above, I've decided to change the direction of the maps, but the definition is yet that one.","['manifolds', 'differential-geometry']"
350131,Is the universal covering surface orientable?,"Let $M$ be a smooth, say also closed (compact and without boundary) surface. Is it true that its universal covering surface is orientable?","['surfaces', 'covering-spaces', 'differential-geometry']"
350143,Definition of Unipotent in Positive Characteristic,"Let $G$ be an affine algebraic group over an algebraically closed field $k$ whose characteristic is $p>0$.  Can $\mathcal{U}(G)$, the set of unipotent elements of $G$, be characterized as all elements $g\in G$ such that $g^{p^t}=1$ for some $t\in\mathbb{N}$?  If not, what is $\mathcal{U}(G)$?  If so, what are equivalent definitions of $\mathcal{U}(G)$ and why are they equivalent? I'm just trying to grow in my understanding of the definition of unipotence.  Thanks for your help!","['algebraic-geometry', 'algebraic-groups', 'group-theory', 'definition']"
350152,The continuity of the rational maps in the zariski topology,"How can one show that the a rational map $f:V\rightarrow W$ is Zariski-continuous? ($V$ and $W$ are affine varieties, i.e. irreducible closed algebraic sets.)",['algebraic-geometry']
350158,General solution for the Eikonal equation $| \nabla u|^2=1$,"Does there exist a formula for the general solution of the Eikonal equation? $| \nabla u|^2=1$. I'm looking for something similar to ""the general solution of $\dfrac{\partial u}{\partial x}(x,y)=0$ is $u=\varphi(y)$, for an arbitrary function $\varphi$"". That is, the formula should include one arbitrary function. Thank you","['partial-differential-equations', 'analysis']"
350160,Approximations of the incomplete elliptic integral of the second kind,"For a calculation I am working on I need to determine the arc length $l$ of a part of an ellipse in terms of the major axis $2a$, the minor axis $2b$ and the angle $\phi$. I know that this is a classical problem which results in an incomplete elliptic integral of the second kind:
$$\tag{1} l=a E\left(\phi \left|\sqrt{1-\frac{b^2}{a^2}}\right.\right)  $$ What I would like to know is whether an algebraic approximation to this equation is known which is applicable with good accuracy in the range $1 < \frac{a}{b} < 3$? I would want to use this approximation to determine $l=f(\phi)$. Of course, I could do a Taylor series around $a=b$ but that is fairly inaccurate unless you use a significant number of terms. What I would love to have is an equation akin to the beautiful approximation due to Ramanujan (1914) for the complete elliptic integral of the second kind:
$$\tag{2} \frac{1}{4} \pi  (a+b) \left(\frac{3 (a-b)^2}{(a+b)^2 \left(\sqrt{4-\frac{3 (a-b)^2}{(a+b)^2}}+10\right)}+1\right)$$","['special-functions', 'integration', 'elliptic-integrals', 'approximation', 'numerical-methods']"
350172,"Number of permutations $\langle a_1,\ldots,a_n\rangle$ of $\{ 1,\ldots ,n \}$ with $a_{i+1} - a_i \ne 1$","Prove that for $n>0$ , the number of permutations $\langle a_1,\ldots,a_n\rangle$ of the set $\{ 1,\ldots ,n \}$ , where $a_{i+1} - a_i  \ne 1$ for $ i = 1, \ldots, n-1$ is equal to: $$D_n + (n-1)D_{n-2} +(-1)^{n-1},$$ where $D_n$ is the number of $n$ -permutations with no fixed points. I have tried to cope with this using inclusion-exclusion rule: $$A_i = (n-1)(n-2)! = (n-1)!$$ and so on. But for bigger products it is much more complicated. Any hints?","['discrete-mathematics', 'combinatorics']"
350180,"If $b\mid ca$, then $b\mid a$. Is this true?","My proof: We want to show $b\mid a$ i.e. $a = bn$ for some integer $n$. Since $b\mid ca$, $ca = bm$ for some integer $m$. Substituting for $a$ gives us $c(bn) = bm \Rightarrow b(cn) = bm\dots$ After that I get stuck. I get the feeling that this may be false.","['logic', 'elementary-number-theory', 'discrete-mathematics']"
350188,Square root is operator monotone,"This is a fact I've used a lot, but how would one actually prove this statement? Paraphrased: given two positive operators $X, Y \geq 0$, how can you show that $X^2 \leq Y^2 \Rightarrow X \leq Y$ (or that $X \leq Y \Rightarrow \sqrt X \leq \sqrt Y$, but I feel like the first version would be easier to work with)? Note: $X$ and $Y$ don't have to commute , so $X^2 - Y^2$ is not necessarily $(X+Y)(X-Y)$.","['operator-theory', 'linear-algebra', 'functional-analysis', 'c-star-algebras']"
350196,Bound for analytic function from unit disk into punctured unit disk,Suppose $f$ is analytic in the unit disk $D$ and satisfies $0<|f(z)|<1$. Show that $|f(z)|\leq|f(0)|^{\frac{1-|z|}{1+|z|}}$ for all $z\in D$. I tried to work with $\log|f|$. It seems that $\log|f|$ is harmonic but I couldn't get estimates.,"['harmonic-functions', 'analyticity', 'complex-analysis']"
350197,A point is in the boundary of $E$ if and only if it belongs to the closure of both $E$ and its complement.,"Let $E$ be a subset of a metric space $(S,d)$.
Prove that: A point is in the boundary of $E$ if and only if it belongs to the closure of both $E$ and its complement. Here is what I thought: I'm first trying to understand what I need to prove. The boundary of $E$ is the set $E^- -E ^{\circ}$. It a point belongs to both $E^-$ and $(S-E)^-$, then it belongs to $E^- \cap (S-E)^-$. Therefore I think I need to prove that: $$E^- -E ^{\circ}=E^- \cap (S-E)^-$$ And now I'm not sure if there any set theory rules I could use. Intuitive I would say that I need to prove: $S-E ^\circ =(S-E)^-$. Is this correct ? And I can kind of feel that this last statement is right, but I can't prove this rigoursly. Could anybody help me how I can prove this statement more rigourisly ?","['metric-spaces', 'real-analysis']"
350231,Determining the Existence of Global Minimum/Maximum,"Determine whether the function defined as $$f(x,y,z)=x+y+z$$ has a maximum or a minimum value on the set $xy+yz=1$, $xz+yz=4$, $x>0$, $y>0$, $z>0$. It is clear to me that it does have a minimum value as we have that  $f>{0}$; and calculations reveal that; $$f(\sqrt{3},2-\sqrt{3},2)=4$$ is a minimum value. Now, I suspect $f$ does not have a maximum value but I'm unsure how to properly show this.","['optimization', 'multivariable-calculus']"
350239,Sum polynomial and derivative,"How to prove that if polynomial $W(x)$ has $n$ real roots then
$\forall a \in \mathbb{R}$ $a W(x)+W'(x)$ has more than $n-1$ roots I have no idea how to solve. Please some hint.","['derivatives', 'real-analysis', 'polynomials']"
350240,"Proving reflexivity, symmetry and transitivity,..., on a relation on words","The relation R ,$uRv$ is defined iif a word u is the suffix of a word v. u is a suffix of v if there exist another word w such that $v = wu $ I have to verify the 6 following relations. Reflexive : Yes because $wu = wu$ Symmetric : No because $v = wu$     , $u \ne wu$ Transitive : Yes , example : u=""to"", v=""potato""   and  u2=""otato"", v=""potato""  and uRu2 Asymmetric : No, v = wu, v $\ne$ u , except if w is an empty word Antisymmetric : No. ex: ""to"" R ""potato"" but ""to"" $\ne$ ""potato"" Irreflexive : No. ex: $wu = wu$. Can you help me for those that are incorrect","['relations', 'discrete-mathematics']"
350252,Show that $N$ is a normal subgroup in $G$ when $N$ is the intersection of normal subgroups in $G$,"QUESTION : Let $G$ be a group, let $X$ be a set, and let $H$ be a subgroup of $G$ . Let $$N = \bigcap_{g\in G} gHg^{-1}$$ Show that $N$ is a normal subgroup of $G$ cointained in $H$ . MY ATTEMPT : I began by asking myself precisely what $\bigcap_{g\in G} gHg^{-1}$ means. I concluded that it must mean that if $g_1, g_2, g_3, ... , g_n \in G$ then $N$ might just be $$ g_1H{g_1}^{-1} \cap g_2H{g_2}^{-1} \cap g_3H{g_3}^{-1} \cap ... g_nH{g_n}^{-1}$$ which I figured is actually just $H$ because that's the only element that all those elements have in common. Therefore I figured that $N=H$ . Now my problem comes in showing that $H$ is a normal subgroup of $G$ . I've never been good at that.","['finite-groups', 'group-theory', 'abstract-algebra', 'normal-subgroups']"
350276,$f_n$ uniformly converge to $f$ and $g_n$ uniformly converge to $g$ then $f_n \cdot g_n$ uniformly converge to $f\cdot g$,"Please help me check, if $f_n$ uniformly converge to $f$ and $g_n$ uniformly converge to $g$ then $f_n + g_n$ uniformly converge to $f+g$ $f_n$ uniformly converge to $f$ and $g_n$ uniformly converge to $g$ then $f_n \cdot g_n$ uniformly converge to $f\cdot g$ What I've done: I Guess that first statement is true, second is false. I've tried to calculate directly from definition, nothing seems correct.","['uniform-convergence', 'convergence-divergence', 'real-analysis', 'analysis']"
350281,What is a good gentle introduction to the Virasoro algebra and its application in theoretical physics?,"I am looking for an as gentle and pedagogical as possible introduction that explains the Virasoro algebra and its applications in theoretical physics; finally I am interested in its application in string theory. The short explanations in the physics books I am reading are not enough to make me feel comfortable about the Virasoro algebra so I need to read some more ... I prefer shorter than whole book references which are optimally freely accessible, but if this does not work other things are welcome too. I know a little bit about Lie algebras and conformal transformations, but the central extension issue confuses me. What I am looking for could be something at the level of these BRST lecture notes I could mostly follow.","['mathematical-physics', 'reference-request', 'string-theory', 'group-theory']"
350309,"Domain, Range, and Relation","Show that if R is a relation, then $\cup\cup R =(\operatorname{dom}R)\cup(\operatorname{ran}R)$. First, I don't know what $\cup\cup R$ means where $R$ is a relation. I want to know what is the membership relation on $R$. Please help me.","['relations', 'logic', 'elementary-set-theory']"
350320,Partial Fraction Decomposition,"I am really stuck on how to do this. It is a step I need to do for an inductive proof. I have $$\frac{1}{n(n-1)} $$ Do I set it up like this: $\frac{ A}{n} + \frac{B}{n-1}$       ?
$$1= A(n-1) + B(n)$$
  How do I solve for $A$ and $B$","['algebra-precalculus', 'partial-fractions']"
350337,How to move from a right semigroup action to a left semigroup action?,"Let $S$ be a semigroup and $X$ any set. Define a left action of $S$ on $X$ to be a map $\sigma: S \times X \rightarrow X$ with the property that $(st)x = s(tx)$, where we define $gx = \sigma(g,x)$ for all $g \in G$, $x \in X$. Similarly, a right action of $S$ on $X$ is a map $\tau: X \times S \rightarrow X$ with the property $x(st) = (xs)t$, where $xg = \tau(x,g)$ for all $g \in G$, $x \in X$. Is there a natural bijection between left and right actions of $S$? Does a left action induce in some natural way a right action? Basically, if I have proven something for every left action of a particular semigroup, is there a shortcut to prove it for every right action as well?","['semigroups', 'abstract-algebra']"
350351,Consider a bipartite graph and Deduce that there exist infinitely many bipartite graphs,"Consider a bipartite graph $G=(X \cup Y, E)$ with both sides of equal size; we let $n$ denote $|X|=|Y|$ We are also given an integer $d\ge 3$ and we wish each vertex in $X$ to be adjacent to at most $d$ neighbors in $Y$ . For any, it is easy to construct arbitrarily large bipartite graphs with this property. It is not as easy to make a graph which also has the following expansion properties: $P_1$ : for each $S \subseteq X$ with $|X|\le\dfrac{n}{3d}$ we have $|N(S)|\ge\dfrac{|S|d}4$ $P_2$ : for each $S \subseteq X$ with $\dfrac{n}{3d} < |S|\le\dfrac{n}2$ we have $|N(S)|\ge |S| + \dfrac{n}{3d}$ Consider the following experiment. For each $v\in X$ , choose $d$ vertices in $Y$ independently at random, and make these vertices adjacent to $v$ . Let $G'$ be the resulting random graph. Prove that (if $n$ is sufficiently large with respect to $d$ ), then with probability greater than $0.75$ , Property $P_1$ holds for $G'$ . Deduce that there exist infinitely many bipartite graphs with these expansion properties.","['statistics', 'discrete-mathematics', 'probability', 'probability-theory']"
350354,Generating function for the solutions of equation $ 2x_1 + 4x_2 = n$,"Let's denote $h_n$ as the number of soulutions of the following equation: $$ 2x_1 + 4x_2 = n$$ where $x_i \in \mathbb N$. Find generating function of the sequence $h_n$ and calculate $h_{2000}$. I've found the generating function: $$\frac{1}{1-x^2}\cdot \frac{1}{1-x^4},$$
but I don't know how to expand it now. Any ideas?","['generating-functions', 'combinatorics']"
350379,"Finitely generated abelian groups: If $G \times K$ is isomorphic to $H \times K$, then $G$ is isomorphic to $H$.","Let $G,H,K$ be finitely generated abelian groups.  If $G \times  K$ is isomorphic to $H \times K$, then $G$ is isomorphic to $H$. What I have thought is that fundamental theorem of abelian groups can be used, but I don't know how to do next.  Please help me.","['group-theory', 'abstract-algebra', 'abelian-groups']"
350383,Formal Proof that area of a rectangle is $ab$,I tried to prove that the area of a rectangle is $ab$ given side lengths $a$ and $b$. The best I can do is the assume the area of a $1\times1$ square is $1$. Then not the number of $1\times1$ squares that fit in an $a\times b$ rectangle is $ab$. Therefore area is $a\cdot b$. This does not seem rigorous however.,"['geometry', 'euclidean-geometry']"
350418,Evaluating $\lim\limits_{x\rightarrow0}\frac{e^{-1/x^2}}{x}$,"Today in my analysis class, we were preparing for the final and this question came up: Evaluate $$\lim_{x\to0}\frac{e^{-1/x^2}}{x}$$ We tried taking the $\log$, using L'Hopitals and some other tricks but couldn't figure it out. I thought maybe viewing this limits as a sequence in the following way might help; $$\lim_{x\rightarrow0}\frac{e^{-1/x^2}}{x} = \lim_{n\rightarrow \infty}\frac{e^{-n^2}}{1/n} = \lim_{n\rightarrow \infty}\frac{n}{e^{n^2}}$$ But from them I'm not sure. Thank you.","['real-analysis', 'limits']"
350419,How to develop a function if you know the limits?,"I know some properties of a function, but I don't know the function itself. Is there a general way of discovering the function? For example, I know that: $$\lim_{ x\to \infty } f(x) = 1, \qquad \lim_{ x\to 1 } f(x) = 2, \qquad f(60) = 1.5.$$ I also know that $f'(x)$ is always negative (sloping downwards). How might I go about finding out what $f(x)$ is?","['functions', 'limits']"
350452,Need help showing the supremum of a function exists.,"I was wondering if anyone knows a technique for proving that this function has a supremum less than infinity for $x \in \mathbb{R}$ ,$x \in [-1,1]$ (I am very certain that it does). The function is, for a fixed $y \in (1,\infty)$, $$f(x)=\frac{||x+1|^y-|x|^y-1|}{|x|^{y-1}+|x|}.$$ I've tried lots of methods, like taking the derivative (a huge mess), and stringing together a chain of $\leq$'s, which doesn't seem to work. Is there an easy way to show this? Thanks! I did not know what tag to put this under, so feel free to tag it appropriately if you know a better one.","['inequality', 'functions', 'limits']"
350453,Combinatorial Proof of Binomial-type Identity,"I'm looking to find a combinatorial proof for the following: Fix a positive integer $n$ and a non-negative integer $k$ . Show that $$\sum a_1\dots a_k={n+k-1\choose 2k-1}$$ where the sum ranges over all $k$ -tuples $\left(a_1,\ldots,a_k\right)$ of integers satisfying $a_1+\dots +a_k=n$ with $a_i\ge 0$ $\forall i\in [k]$ . Here, $\left[k\right]$ denotes the set $\left\{1,2,\ldots,k\right\}$ . I guess I've sort of been looking at the right side with a modified ""stars and bars"" type mindset.  I'll write down $n+k-1$ stars and then circle $2k-1$ of them.  I'll sweep from left to right, putting stars in a bucket, and when I get to the second circle I put a line through it to start a new bucket.  I continue putting things in that bucket passing the next circled star, and then drawing a line through the one after that.  This should give me $k$ buckets with $a_i$ things in each one (and with the $\sum a_i=n$ since we crossed out every second circled star). Is this the right bijection in some sense?  I understand what I did but I'm not sure if I understand why what I did is right (if it is).  Namely, what's the inverse procedure and what is the left side actually counting?","['combinatorial-proofs', 'binomial-coefficients', 'combinatorics']"
350466,Prove that $A \mathop \triangle C \subseteq (A \mathop \triangle B)\cup (B \mathop \triangle C)$,"Suppose A, B, and C are sets, prove that $A \mathop \triangle C \subseteq (A \mathop \triangle B)\cup (B \mathop \triangle C)$ I'm just wondering if this proof is ok, or if I'm overlooking something, thanks! Proof. Suppose $x \in A \mathop \triangle C$. If $x \in A \mathop \triangle B$, then clearly $x \in (A \mathop \triangle B) \cup (B \mathop \triangle C)$, so we will consider the case when $x \notin A \mathop \triangle B$. Suppose $x \notin A \mathop \triangle B$. This means that $x \in A \leftrightarrow x \in B$. Since $x \in A \mathop \triangle C$, either $x \in A \mathop \backslash C$ or $x \in C \mathop \backslash A$. We will consider both cases. Case 1: $x \in A \mathop \backslash C$. So $x \in A$ and $x \notin C$. Since $x \in A$ and $x \in A \leftrightarrow x \in B$, it follows that $x \in B$. Then since $x \notin C$, $x \in B \mathop \backslash C$, so $x \in B \mathop \triangle C$. Hence, $x \in (A \mathop \triangle B)\cup (B \mathop \triangle C)$ Case 2: $x \in C \mathop \backslash A$. So $x \in C$ and $x \notin A$. Then since $x \notin A$ and $x \in A \leftrightarrow x \in B$, it follows that $x \notin B$. Thus, $x \in C \mathop \backslash B$, so $x \in B \mathop \triangle C$, and hence, $x \in (A \mathop \triangle B)\cup (B \mathop \triangle C)$. Edit: Also, I would be interested to see any alternative methods of proving this.","['proof-writing', 'elementary-set-theory']"
350469,How to define addition through multiplication?,"One might define multiplication $\bullet$ on $\mathbb Z$ as follows: $\bullet: \mathbb Z\times \mathbb N\ni (a,b) \mapsto a+\cdots+a\in \mathbb Z$ where we add $b$ times. But suppose we are in a universe where we can only multiply. How would one define addtion, or could one even define it? Silly approach 1: $\log(e^ae^b)=\log(e^{a+b})=a+b$, but this assumes existence of $\log$ and $e$ and is rather unsatisfying. Approach 2: If we could find a formula for $a+1$ (where $a\in \mathbb N$), then we could successively extend this notion to get an addition function $+:\mathbb N\times\mathbb N\to \mathbb N$. But we can only define $a+1$ through multiplication and the only given parameter is $a$, so $a+1$ is be a product of $a$, hence $a\mid (a+1)$. But this is impossible for $a>1$. So it seems we cannot define an addition function using only multiplication, which is again unsatisfying. Does anybody have an idea whether this is at all possible? What if we could use a (possibly infinite) product of real numbers to define $a+1$?","['arithmetic', 'number-theory']"
350470,Can the matrix $A=\begin{bmatrix} 0 & 1\\ 3 & 3 \end{bmatrix}$ be diagonalized over $\mathbb{Z}_5$?,"Im stuck on finding eigenvalues that are in the field please help. Given matrix:
$$
A=  \left[\begin{matrix}
0 & 1\\
3 & 3
\end{matrix}\right]
$$ whose entries are from $\mathbb{Z}_5 = \{0, 1, 2, 3, 4\}$, find, if possible, matrices $P$ and $D$ over $\mathbb{Z}_5$ such that $P^{−1} AP = D$. I have found the characteristic polynomial: $x^2-3x-3=0$
Since its over $\mathbb{Z}_5$, $x^2-3x-3=x^2+2x+2=0$. But from there I'm not sure how to find the eigenvalues, once I get the eigenvalues that are in the field it will be easy to find the eigenvectors and create the matrix $P$.","['matrices', 'linear-algebra']"
350473,"Proof By Counterexample, pigeonhole","This is from a discrete math homework question. I really don't know where to begin, except that I understand the concept of a proof by counterexample, just not how to get to it. In the statement of the pigeonhole, we argued that $$\left\lfloor\frac{n-1}m\right\rfloor+1=\left\lceil\frac{n}m\right\rceil\;.$$ Prove that this is generally not true.",['discrete-mathematics']
350514,Compact formula for $\sum_k k!$ [duplicate],"This question already has answers here : $\sum k! = 1! +2! +3! + \cdots + n!$ ,is there a generic formula for this? (4 answers) Closed 11 years ago . Is there any compact formula for: $$\sum_{k=0}^n k!$$ I've tried to find it using one method for summation, but I was able to receive only compact formula for $\sum_k k! \cdot k = (n+1)!-1$ I've typed it into wolfram, but answer is also pretty complicated .","['factorial', 'summation', 'combinatorics']"
350553,Largest eigenvalue of a symmetric positive definite matrix with rank-one updates,"I have a $n \times n$ symmetric positive definite matrix $A$ which I will repeatedly update using two consecutive rank-one updates of the form $A' = A + e_j u^T +u e_j^T$ where $\{e_i: 1 \leq i \leq n\}$ is the standard basis. I also compute the updates to $A^{-1}$ using Sherman-Morrison. Due to the nature of the updates, the matrix $A'$ is guaranteed to be non-singular and positive definite. I would like to keep track of the largest and smallest eigenvalue of the matrix. Since I have the inverse, a method for calculating the largest (or smallest) eigenvalue would suffice. I know I can calculate the eigendecomposition of $A$ and update it in $O(n^2)$ but I was wondering if there was a more efficient method seeing as I only care about one particular eigenvalue (and not at all about the eigenvectors). A lower bound on the eigenvalue, might also be helpful, but it would have to be tight. Gershgorin discs seem too loose. Finally, if I do have to go via the eigendecomposition route, any pointers to what algorithms are used in practice for computational efficiency and numerical stability?","['matrices', 'linear-algebra']"
350580,Does the series $\sum_{n=1}^\infty$ ${\sqrt{n+1}-\sqrt{n}}\over n$ converge or diverge?,Does this series converge or diverge? $$\sum_{n=1}^\infty\frac{\sqrt{n+1}-\sqrt{n}}{n}$$ I tried the comparsion test with $\sum_{n=1}^\infty$ $1 \over n$ but this does not help. I also tried to simplify the series to $\sum_{n=1}^\infty \frac{1}{n (\sqrt{n+1}+\sqrt{n}{}{}{})}$ but this become harder.,"['convergence-divergence', 'sequences-and-series', 'analysis']"
350606,Shape of zero set of homogeneous polynomial,"Let $f$ be a homogeneous polynomial in $d$ variables of degree $n$ over the real numbers. What does its zero set $V(f)$ look like? Is it a ""hypersurface""? Is it connected in the metric topology of $\mathbb{R}^d$?",['algebraic-geometry']
350618,$f(x^2) = 2f(x)$ and $f(x)$ continuous,"I ran into a problem recently where I obtained the following constraint on a function.
$$f(x^2) = 2f(x) \,\,\,\, \forall x \geq 0$$
and the function $f(x)$ is continuous. Can we conclude that $f(x)$ is of following form?
$$f(x) = \begin{cases} a\log(x) & \text{for } x \geq 1\\ 0 & \text{for  }x \in [0,1]\end{cases} \tag{$\star$}$$
where $a \in \mathbb{R}$. It is easy to conclude for $x \in [0,1)$ it should be zero, since $f(0) = 0$ and $f(x) = \dfrac{f(x^{2^n})}{2^n}$. Now letting $n \to \infty$, thanks to continuity, we can conclude that $f(x) = 0$ for $x \in [0,1)$. But how do I show $(\star)$ for $x \geq 1$? If not under what further constraints, will I be able to conclude ($\star$)? This is similar to the Cauchy functional equation $f(xy) = f(x) + f(y)$, but with $y=x$.","['calculus', 'functional-equations']"
350659,Showing Heron's Formula Works for All Triangles,"we got this question in class and I am having a lot of trouble understanding how to go about it! Question: Show that if Heron's formula is true for every triangle in which one of the sidelengths equals to 1, then it is true for every triangle. My approach currently:
So I basically said that given a triangle with one side length equal to 1, the other two sides can be of any other measurement provided that their sum is greater than 1.  Such a set of triangles can generate all triangles since we can multiply any real number to all three sides, which gives a scalar of such triangles.  Since Heron's formula works for the most basic set of triangles, then for scalars of such triangles, Heron's formula works as well.",['geometry']
350665,$l_1$ equipped with the sup norm is NOT a Banach Space,"Prove that $l_1 = \{ x = (x_k)_{k\in\mathbb{N}}\subset \mathbb{R};\ \sum_{k\in\mathbb{N}}\ |x_k| < +\infty \}$ equipped with the norm
$\| x\| = \mathrm{sup}_{k\in\mathbb{N}} |x_k|$ is NOT a Banach Space. I've tried to solve it considering the sequence
$x_n = (\frac{1}{k^{1 + 1/n}}),\ \forall n \in \mathbb{N}$ Since $\sum_{k\in\mathbb{N}}\frac{1}{k^{1 + 1/n}} < +\infty$ (because $1+1/n > 1$), $(x_n)_{n\in\mathbb{N}}$ is a sequence in $l_1$. We also have that $x_n \longrightarrow (1/k)_{k\in\mathbb{N}},$ as $n\longrightarrow +\infty$, and this one is not in $l_1$. I would like to prove that $(x_n)_{n\in\mathbb{N}}$ is a Cauchy sequence, but I don't have a clue how to do it.","['normed-spaces', 'functional-analysis', 'banach-spaces']"
350675,Prove $(n^5-n)$ is divisible by 5 by induction.,"So I started with a base case $n = 1$. This yields $5|0$, which is true since zero is divisible by any non zero number. I let $n = k >= 1$ and let $5|A = (k^5-k)$. Now I want to show $5|B = [(k+1)^5-(k+1)]$ is true.... After that I get lost. I was given a supplement that provides a similar example, but that confuses me as well. Here it is if anyone wants to take a look at it: Prove that for all n elements of N, $27|(10n + 18n - 1)$. Proof: 
We use the method of mathematical induction. For $n = 1$, $10^1+18*1-1 = 27$. 
Since $27|27$, the statement is correct in this case. Let $n = k = 1$ and let $27|A = 10k + 18k - 1$. We wish to show that $27|B = 10k+1 + 18(k + 1) - 1 = 10k+1 + 18k + 17$. Consider $C = B - 10A$ ***I don't understand why A is multiplied by 10.
$= (10k+1 + 18k + 17) - (10k+1 + 180k - 10)$ $= -162k + 27
= 27(-6k + 1)$. Then $27|C$, and $B = 10A+C$. Since $27|A$ (inductive hypothesis) and $27|C$, then
$B$ is the sum of two addends each divisible by $27$. By Theorem 1 (iii), $27|B$, and
the proof is complete.","['induction', 'discrete-mathematics']"
350679,We break a unit length rod into two pieces at a uniformly chosen point. Find the expected length of the smaller piece,"We break a unit length rod into two pieces at a uniformly chosen point. Find the
expected length of the smaller piece","['probability-theory', 'uniform-distribution']"
