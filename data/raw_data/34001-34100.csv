question_id,title,body,tags
324136,Showing a model does not have a particular substructure and understanding satisfaction relations.,"Out of Winfried Just and Martin Weese's Set theory book: Show that the model $\mathfrak B=\langle \Bbb Z, +, \le, 0 \rangle$ does not have any substructure whose universe is $\{-1,0,1\}$. In a previous example he showed that there is such a substructure for $\mathfrak B$ with multiplication instead of addition. However, I do not see how changing the function breaks the identity embedding. My guess is that it has to do with {-1,0,1} not being closed under addition but I am unsure how to formalize this. Something like $i(1+1)\neq i(1)+i(1)$ since $1+1\notin \{-1,0,1\}$ where $i$ is the identity function is my attempt but this is clearly lacking. Also on a somewhat related note, I'm not quite sure I understand the following property of satisfaction relations under a valuation s $\mathfrak U \vDash_s \exists v_i\phi$ iff there exists a valuation $s^*$ such that $\mathfrak U \vDash_s^* \phi$ and $s(k)=s^*(k)$ for all $k\neq i$ How I understand this property is that a bounded variable's formula is true under the valuation $s$ as long as the formula can be satisfied under a valuation for all of the free variables of $\phi$ in $\mathfrak U$. Is this interpretation correct?","['elementary-set-theory', 'model-theory']"
324148,Finding the extreme values of a function,Hello everyone how would I find the extreme values of the following function. $f(x)=\cos^2(x)$  within $0 \leq x \leq 2\pi$ I got the derivative as $f'(x)=-2\sin(x)\cos(x)=0$ I know that $\sin^{-1}(0)=0$ and $\cos^{-1}(0)=\pi/2$ But I am not sure if this is correct as the graph seems to go in a cycle so would there be critical points?,"['calculus', 'derivatives']"
324150,Expected rank of a random binary matrix?,"Recently a friend stumbled across this question: Let $M$ be a random $n \times n$ matrix with entries in $\{0,1\}$ (both zero and one has probability $p = q = \frac{1}{2}$). What is its expected rank? My intuition is that it would be something of order $\frac{n}{\log n}$, similarly to coupon collector's problem , but I could not produce anything more specific. Unfortunately my linear algebra skills are, to put it mildly, rusty. Is this a know problem? If the exact calculation is hard, are there any simple arguments regarding the order when $n$ tends to infinity? I would greatly appreciate any hints, proofs, references, or any other help. Edit: The original question was phrased in terms of field $\mathbb{F}_2$, however, the approach for $\mathbb{R}$ would be great as well, that is I would consider it a full answer (especially if simpler).","['matrix-rank', 'matrices', 'random-matrices', 'reference-request', 'probability']"
324178,Counting symmetric unitary matrices with elements of equal magnitude,"Let $X$ be an $n\times n$ symmetric unitary matrix with elements of equal magnitude and the elements of the first row (and the first column, of course) are $1/\sqrt{n}$, i.e. $X_{j,k} = e^{i \phi_{j,k}}/\sqrt{n}$ with $\phi_{j,k}=\phi_{k,j} \in \mathbb{R}$ and $\phi_{1,k}=0$.
Prove (or disprove) that such matrix is unique up to permutations. The background here is to get understanding of the set of bases in $\mathbb{C}^n$ with coordinates differ by phase factors only. The orthogonality relation $(v_j, v_k) = n^{-1}\sum_l \exp(i(\phi_{j,l}-\phi_{k,l})) = 0$ for $j \ne k$ is invariant with respect to $\phi_{j,k} \to \phi_{j,k}+\omega_j + \omega_k$. This would be great if the set could be obtained from a particular choice $$X_{j,k} = \frac{1}{\sqrt{n}}\exp\left(\frac{2\pi i}{n} (j-1)(k-1)\right)$$ by permutations and the symmetry transformation. The statement seems plausible since the matrix $X$ is determined by $n(n-1)/2$ phases with $n(n-1)/2$ constraints imposed by orthogonality relations. The proof, however, is lacking. I would greatly appreciate help in a form of proof/disproof or a strong hint.","['matrices', 'linear-algebra']"
324227,Convergence of $\sum_{n=1}^{\infty}\frac{1}{n}\sin\left(\frac{1}{n}\right)$,"Showing convergence is easy, since for $x\geq 0$ we have $\sin x\leq x$ so: $$0\leq\sum_{n=1}^{\infty}\frac{1}{n}\sin\left(\frac{1}{n}\right)\leq \sum_{n=1}^{\infty}\frac{1}{n^2}$$ I was wondering if it might have a closed form? Finding one is beyond me, but I am sure that the people on here will have ideas.",['sequences-and-series']
324234,Book Searching in Complex Analysis,"I'm searching for a problem book in complex analysis published by MIR. It was recommended by my professor (when I asked for a Demidovich equivalent in the field), but he did not remember the exact name (possibly "" Ejercicios de Analise Complexa "" - Exercises in Complex Analysis) nor the author. He said the book was quite difficult, it don't have applications and he mentioned a particular and hard problem involving a construction of a Riemannian surface. Edit: The problem of the construction of a Riemannian surface has a infinity product of functions.","['reference-request', 'complex-analysis']"
324238,Orientation on finite dimensional vector spaces over finite fields.,"For finite-dimensional $\mathbb R$-vector spaces, we define an orientation to be an equivalence class of ordered bases, where $B_1 \sim B_2$ iff the change of basis matrix $A$ taking $B_{1}$ to $B_{2}$ has positive determinant. Then there are two equivalence classes, one which we call, ""positive"" and the other we call, ""negative"". I wanted to know if any work has been done to extend this to finite-dimensional vector spaces over finite fields. My idea was to do everything as above, but replace the condition $\det A>0$ with $\det A$ is a quadratic residue. This should split the bases into two equivalence classes just as above. I played around with these and noticed some interesting things. For example let $q=p^{f}$ and $\mathbb F_{q}$ be an $\mathbb F_{p}$ vector space. Unlike the case for $\mathbb R$, if $q \not\equiv 3 \pmod 4$ then switching any two vectors in your basis doesn't change the equivalence class, because the determinant of the corresponding change of basis matrix is $-1$, which is a quadratic residue in this case. Has any work been done on this, or are there any other definitions or related concepts that might be of interest?","['vector-spaces', 'number-theory', 'finite-fields', 'abstract-algebra', 'differential-topology']"
324241,"Number of 6-digit passwords, starting with even or ending with odd digit","My problem is A password consists of six digits, each in $\{0,\ldots,9\}$
  How many passwords start with an even digit or end with an odd digit? the answer is $750,000.$ I would like to know how exactly do you get $750,000$ as the answer?","['discrete-mathematics', 'combinatorics']"
324249,Can the Basel problem be solved by Leibniz today?,"It is well known that Leibniz derived the series
$$\begin{align}
\frac{\pi}{4}&=\sum_{i=0}^\infty \frac{(-1)^i}{2i+1},\tag{1}
\end{align}$$
but apparently he did not prove that
$$\begin{align}
\frac{\pi^2}{6}&=\sum_{i=1}^\infty \frac{1}{i^2}.\tag{2}
\end{align}$$
Euler did, in 1741 (unfortunately, after the demise of Leibniz). Note that this was also before the time of Fourier. My question: do we now have the tools to prove (2) using solely (1) as the definition of $\pi$? Any positive/negative results would be much appreciated. Thanks! Clarification : I am not looking for a full-fledged rigorous proof of (1)$\Rightarrow$(2). An estimate that (2) should hold, given (1), would qualify as an answer.","['riemann-zeta', 'sequences-and-series', 'number-theory', 'combinatorics']"
324253,Are there real world applications of finite group theory?,"I would like to know whether there are examples where finite group theory can be directly applied to solve real world problems outside of mathematics.  (Sufficiently applied mathematics such as cryptography, coding theory, or statistics still count.) Let me clarify: I am not interested in applications of elementary group theory which happen to involve finite groups (e.g. cyclic/dihedral/easy groups as molecular symmetries).  I am interested in applications of topics specifically coming from finite group theory as a discipline, like one might see in Isaacs , Huppert , or Robinson . ""The Schur multiplier has order $2640,$ so we should point the laser that way."" ""Is this computer system secure?""  ""No - Frobenius kernels are nilpotent."" I'm aware of this MO post , but many of the applications listed there are inside mathematics or fall in the ""applications of easy groups"" category.  It is entirely possible that what I'm looking for doesn't exist, and that finite group theory is still an untouchable, pure subject, like number theory in the days of G. H. Hardy.  But perhaps not.  Does anyone know of any applications of the higher level stuff?","['applications', 'abstract-algebra', 'finite-groups', 'big-list', 'group-theory']"
324304,"Showing that if $fg=gf$ and $fh=hf$, then $gh=hg$, where $f$, $g$, and $h$ are affine functions","Given real numbers $a$ and $b$ ($a \ne 0$), let $f_{a,b}$ be the function $\mathbb{R} \to \mathbb{R}$ defined by $x \mapsto ax+b$.  The set of such functions is a permutation group on $\mathbb{R}$, under function composition. Let $f,g,h, \in G$, where $f$ is not the identity.  If $f$ commutes with both $g$ and $h$, show that $g$ and $h$ commute with each other. (Problem from I.M. Isaacs) I think I have proved this, but I'd like to be sure. Let $f(x)=ax+b$, $g(x)=cx+d$, and $h(x)=mx+n$.  We have the following: $$f(g(x))=acx+ad+b,\quad g(f(x))=acx+bc+d$$ For these two functions to be equal, therefore, we must have that $ad+b=bc+d$.  Am I correct in thinking that this further implies that $a,c=1$? If so, then by essentially the same argument we also obtain $a,m=1$, and so $c,m=1$, which would imply that $gh=hg$ (since $g(h(x))=cmx+cn+d$ and $h(g(x))=cmx+md+n$). Is this an effective proof?  It's clear that, for example in the first case, $a,c=1$ implies $ad+b=bc+d$, but it's not completely clear to me that $ad+b=bc+d$ necessarily implies $a,c=1$. Thanks.","['affine-geometry', 'linear-algebra', 'group-theory']"
324314,A twist on a classic high school problem,"$$\text{""Toss a fair coin, if heads: stop; if tails: toss again.""}$$ Not a particularly fun game, but a classic probability exercise nonetheless; the probability of this process ending is easily shown to be $1:$ $$\frac{1}{2}+\frac{1}{4}+\frac{1}{8}+\cdots =1$$ This made me wonder, what happens if instead of two outcomes, we have three ? In better terms, suppose we randomly generate a number from $\{0,1,2\}$ (each pick is equiprobable); if $0:$ stop, if $1:$ pick again, if $2:$ pick twice $($even if the first pick is $0)$. In the last case, sum the results of both picks, giving us the number of picks required for the next round. Here is an example of such a game: $$\text{start}\to(1)\to(2)\to (1,2)\to (0,2,1)\to (0,1,0)\to (0)\to\text{end}$$ (the numbers in brackets represent the outcomes of each pick) Again, the probability that this process will end is $1$ (justification below). Upon finding this, I was a tad puzzled. Surely this probability cannot be $1$ if the number of possible outcomes is large enough? It turns out that it fails to give $1$ at the next integer. Indeed, if we randomly generate from $\{0,1,2,3\}$, same rules as previous, with the added ""if $3:$ pick thrice "", the probability that the process will end stoops down to $\sqrt{2}-1$. $$\star$$ I was interested in finding an expression which gives us this probability in terms of the largest integer in the initial set (only looking at sets of the form $\{0,1,\cdots \,n\}$ for now); I believe I have found a polynomial whose solutions give the desired probability. There are several issues that I have not managed to solve: the aforementioned polynomial has two distinct roots in $[0,1]$: one is $1$ (when the set is $\{0,1\}$ (coin toss case) or $\{0,1,2\}$, the roots are not distinct). I am almost certain that the desired probability is the lower root. However, I have not found a decent way of supporting this claim. I would like some criticism on my working; I have never studied degree level maths, and even less taken a course in probability, so I may well have abused of some notation and made some assumptions which I shouldn't be allowed to make. Feel free to critise whatever you feel necessary! $$\textbf{Problem}$$ Let $\Omega$ be a set of $\alpha\geq 2$ consecutive integers with smallest element $0:\;\Omega=\{0,1,\cdots\,\alpha-1\}$ Process: Randomly and independently generate elements of $\Omega$ $r_n$ times. If the sum of the results is $r_{n+1}=0$ the process ends. If the sum of the results is $r_{n+1}\geq 1$, randomly and independently generate elements of $\Omega\;r_{n+1}$ times, etc. The process begins with $r_1=1$. What is the probability of this process ending? $$\textbf{Attempted solution}$$ $\phi:$ end of process
, $r_n:$ number of picks required at stage $n$ Notice that for $n>1:$ $$
\left\{ 
  \begin{array}{l l}
   p(\phi|r_n=0)=0 &\\
    p(\phi|r_n=1)=p(\phi|r_1)=p(\phi) & \; (r_n=1\;\text{returns us to the initial conditions})
  \end{array} \right.$$ For $r_n\geq 1$ the event $(\phi|r_n)$ is equivalent to: $$\left(\bigcap_{k=1}^{r_n}\phi|i_k\right)$$ where $(i_k)$ requires a single independent pick i.e. $(i_k)\Leftrightarrow (r_1)$ Therefore we may write for $n>1,r_n\geq 1:$ $$p(\phi|r_n)=p\left(\bigcap_{k=1}^{r_n}\phi|i_k\right)=\prod_{k=1}^{r_n}p(\phi|i_k)=p(\phi|r_1)^{r_n}=p(\phi)^{r_n}$$ Additionally, since all results are equipossible, $p(r_n=k\in\Omega)=\dfrac{1}{\alpha}$ The law of total probability gives: $$\begin{align*}p(\phi)&=p(\phi|r_n=1)\\&=\sum_{k=0}^{\alpha-1}p(r_{n+1}=k)p(\phi|r_{n+1}=k)\\&=\frac{1}{\alpha}\sum_{k=0}^{\alpha-1}p(\phi|r_{n+1}=k)\\&=\frac{1}{\alpha}\sum_{k=0}^{\alpha-1}p(\phi)^k\end{align*}$$ For clarity, denote $\lambda$ the desired probability $p(\phi)$. We are left to solve: $$\lambda =\frac{1}{\alpha}\sum_{k=0}^{\alpha-1}\lambda^k\Rightarrow\alpha\lambda =\sum_{k=0}^{\alpha-1}\lambda^k$$
$$\Rightarrow\lambda^{\alpha}-\alpha\lambda^2+\alpha\lambda-1 =0$$ Notice that for $\alpha=2$ this reduces to $(\lambda-1)^2=0\Rightarrow \lambda=1$ which agrees with the coin toss scenario, and $\alpha=3$ gives $(\lambda-1)^3=0\Rightarrow\lambda=1$ which is why my initial twist on the problem also has probability $1$. By Descartes' rule of signs this polynomial has exactly three positive roots. It is easy to show that the these roots lie in $[0,1]$. In fact, two of them are $1$, and the other is $<1$ when $\alpha\geq 4$. This is why, for $\alpha=4$, I believe the probability is the lower solution: $$(\lambda-1)^2(\lambda^2+2\lambda-1)=0\Rightarrow\lambda=\sqrt{2}-1\;\;\text{if}\;\;\lambda\neq 1$$ We can observe that this other solution approaches $0$ when $\alpha\to\infty$ which agrees with intuition. If what I have done so far is correct, and my intuition is correct, how can I justify that the solution is the smallest positive solution to $\lambda^{\alpha}-\alpha\lambda^2+\alpha\lambda-1 =0?$ $$\star$$ Many thanks to anyone who put the effort into reading this through. If those who answer wish to include any probability theory that is beyond the basic tools that I have used, I would be very grateful is you could explicitly name the tools you use, so that I can study them to fully understand your answers.","['probability-theory', 'probability']"
324316,How does one prove probability integral transform? [duplicate],"This question already has an answer here : Intuition behind Probability Integral Transformation (1 answer) Closed 3 years ago . How does one prove probability integral transform? So when $Y = F_X(X)$ where $X$ has a continuous distribution for which the cumulative distribution function is $F_X$, why does $Y$ have a uniform distribution? And what would Y's relationship with $\text{uniform}(0,1)$ distribution?","['statistics', 'probability-theory']"
324324,Help! I have proven that the Area of a $1\times 1$ Square is $0$,"Let the square $S$ be the set of points $(x,y) \in [0,1]^2$ Let $R \subset S = S \cap \mathbb{Q}^2$, that is, the ""rational pairs"" in the square. To each of these points $r_i \in $ R, we can associate a small square $s_i$ of area $\epsilon / 2^i$, centered at $r_i$. Now the collection $\{s_i\}$ must cover $S$ because if any region of $S$ is uncovered, then that region contains a rational pair that is uncovered which is a contradiction. So since we covered $S$ with a buch of small squares $s_i$, then $\text{area}(S) \le \sum \text{area}(s_i) = \epsilon$ Since $\epsilon$ was arbitrary, the area of a square is $0$! So what went wrong here?",['measure-theory']
324336,Prove that there are no convex functions on compact manifolds,"This one seems intuitively obvious to me but I don't know how to prove it.  Suppose you have a compact manifold $M$ with a function $f$ defined on it.  Given two points $x$ and $y$ on the manifold, let $\gamma_{xy}: [0,1]\rightarrow M$ be the geodesic between $x$ and $y$.  Then we say a function is convex if, $\forall x, y\in M, \lambda \in [0,1],\,\,\,\, f(\gamma_{xy}(\lambda)) \le (1-\lambda)f(x) + \lambda f(y)$ I can't think of any function on a compact manifold for which this is actually true, and I suspect that there are no convex functions on compact manifolds.  Can anyone point me to the relevant proof?","['convex-analysis', 'differential-geometry', 'compact-manifolds']"
324338,A divergent sequence whose average sequence converges,"Can we find a sequence $\{a_n\}$ such that $\lim_{n\to\infty}a_n=\infty$, but
$$\lim_{n\to\infty}\frac{1}{n}\sum_{i=1}^n a_i=a<\infty?$$
Does the sequence $\{\ln(\ln(n))\}$ satisfy this condition? If yes, how can we show that? Thank you!","['limits', 'sequences-and-series', 'analysis']"
324340,Induced de Rham map is a ring map,The de Rham Theorem states that for a smooth manifold $M$ the cochain map $R: \Omega^*(M) \to C^*(M;\mathbb{R})$ from differential forms to singular real cochains defined by $R(\omega)(\sigma)= \int_{\sigma}\omega$ induces an vector space isomorphism in cohomology. How can one prove that the induced map $R^*: H^*_{dR}(M) \rightarrow H^*(M;\mathbb{R})$ takes the wedge product to the cup product?,"['algebraic-topology', 'differential-geometry']"
324346,Derivatives of Logarithmic Functions.,"I've been working through my practice problems and came across one that has stumped me. $$y = (3x^{2}+2)^{ln x}$$ The answer to this is: $$\frac{dy}{dx} = (3x^{2}+2)^{lnx} (\frac{1}{x}ln(3x^{2}+2)+\frac{6xlnx}{3x^{2}+2})$$ What I'm coming up with is: $$\frac{dy}{dx} = (3x^{2}+2)^{lnx} (\frac{1}{x}ln(3x^{2}+2)+\frac{6x}{3x^{2}+2})$$ What I'm not understanding is where the $\frac{6xlnx}{3x^{2}+2}$ comes from, if anyone could explain this I'd really appreciate it.","['calculus', 'derivatives']"
324351,Simplifying covariance matrices in distributions,"In the multivariate Gaussian distribution, it is required that the covariance matrix be positive semidefinite. I have read that a positive semidefinite matrix $\Sigma$ can be written as $LL^{T}$. I have also seen that $\Sigma=(C^{T}C)^{-1}$ where $C$ is positive definite (is this true?). However, I'm entirely sure why this is true. I want to know what facts do we know about positive semidefinite matrices that can be used in order to manipulate a multivariate Gaussian or similar distributions. For example, in a Gaussian distribution: $$f(x)=\exp{\{-\frac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu)\}}$$ we can use $\Sigma^{-1}=C^{T}C$ (although I'm not entirely certain this is correct). Therefore, a change of variable $y = C (x-\mu)$  can be used to write $f(x)$ as: $$f(x)=\exp{\{-\frac{1}{2}y^{T}y\}}$$ Another example could be using $\Sigma^{-1} = \sum_{i=1}^{D} \frac{1}{\lambda_{i}}u_{i}u_{i}^{T}$ where $u_{i}$ are the eigenvectors of $\Sigma$ and $\lambda_{i}$ its eigenvalues. This expression also can be used to simplify $f(x)$. What other representations are there for $\Sigma^{-1}$? Or what is the correct procedure in the examples I described above? UPDATE: A third example could be simply taking $\Sigma^{-1} = \Sigma^{-\frac{1}{2} T}\Sigma^{-\frac{1}{2}}$ (because $\Sigma$ is symmetric) and change variables with $y = \Sigma^{-1/2}(x-\mu)$. Initiallly I had written a fourth option with $\Sigma$ as $G^{T}DG$ with $G$ as a orthogonal matrix and $D$ as an diagonal matrix containing $\Sigma$'s eigenvalues. I think that's wrong and the correct decomposition should be $\Sigma=G\Lambda G^{T}$, however this still produces issues because a change of variable $y=G^{T}(x-\mu)$ leads to a differential volume in the following form: $$dy_{1}dy_{2}...dy_{n} = |G^{T}|dx_{1}dx_{2}...dx_{n}$$ but the determinant of $G$ might be 1 or -1, which is not good. Thanks!","['statistics', 'matrices', 'normal-distribution', 'probability-distributions']"
324361,Compositum of fields with trivial intersection,"Let $E/F$ be a finite extension. Let $L,K$ be two intermediate fields with $L\cap K = F$, and also $$[L : F]  [K:F] = [E:F].$$ Must it hold that the compositum $LK$ equals $E$? If we assume that $E/F$ and $K/F$ are Galois, then this follows from basic Galois theory. Namely, since $K/F$ is Galois we have $$\mathrm{Gal}(E/F) = \mathrm{Gal}(E/K\cap L) = \mathrm{Gal}(E/K)\mathrm{Gal}(E/L)$$ and $$\mathrm{Gal}(E/KL) = \mathrm{Gal}(E/K) \cap \mathrm{Gal}(E/L).$$ We have $$|\mathrm{Gal}(E/K)\mathrm{Gal}(E/L)| =  \frac{|\mathrm{Gal}(E/K)||\mathrm{Gal}(E/L)|}{| \mathrm{Gal}(E/K) \cap \mathrm{Gal}(E/L)|}.$$ Therefore we must have $$|\mathrm{Gal}(E/KL)| = \frac{|\mathrm{Gal}(E/K)||\mathrm{Gal}(E/L)|}{|\mathrm{Gal}(E/K)\mathrm{Gal}(E/L)| }= \frac{[E : K][E : L]}{[E: F]} = 1.$$ However, I am not sure whether this is still true if either $E$ or $K$ is not assumed Galois over $F$. Does anyone have any ideas?","['galois-theory', 'abstract-algebra', 'field-theory']"
324370,Questions about distribution-free statistic,"If I understand correctly, a statistic $T$ is said to be distribution free, if the distribution of $T(X)$ doesn't depend on the distribution of $X$. Examples are Kolmogorov-Smirnov test statistic . To prove $T$ is distribution free, is it equvalent to showing that $T(F^{-1}(U)) = T(U)$, for a random variable $X$ with an arbitrary cdf $F$, and a uniform random variable $U$ over $(0,1)$? Are distribution free statistics always nonparametric statistics?","['statistics', 'probability']"
324372,How to find the central angle of a circle?,"My book states the following: Likewise, we can take a circular cone with base radius $r$ and slant height $l$ , cut it along the dashed line in Figure 2: and flatten it to form a sector of a circle with radius $l$ and central angle $ \theta = \frac{2\pi r}{l} $ . Why does $ \theta = \frac{2\pi r}{l} $ ?","['geometry', 'circles']"
324398,Prove that $G \cong\mathrm{Inn}(G)$ if and only if $Z(G)$ is trivial,"Claim : Let $G$ be a group. Prove that $G \cong\mathrm{Inn}(G)$ if and only if $Z(G)$ is trivial. Could anyone offer a hint on proving this claim just using simple properties of group isomorphisms? (i.e., not using the fact that the quotient group $G / Z(G)$ is isomorphic to the group of inner automorphisms of $G$.) EDIT: It turns out that this Claim is false as stated. There are several counterexamples, several of which are provided in answers below, for the case of G being infinite. However, the claim holds for finite groups.","['group-theory', 'abstract-algebra']"
324402,"Does ""indeterminate"" mean ""divergent""?","Just learning about series and someone tried to tell me that when doing the alternating series test, if the limit is indeterminate , it means it is divergent , and I wanted to know what exactly the difference between these terms is.  English is not my native language.","['sequences-and-series', 'calculus', 'terminology']"
324410,probability of this event happening,"Play $(n+1)t$ rounds of the same coin-tossing game and the coin is fair ($n$ is a fixed natural number). Please help me find the following probability: $P$(the number of rounds of tossing that show head is no less than $t$ after all the tossing is done, and at any time point during, the number of coin landing head is no less than $1/n$ of that of tail). If possible, please also show that when $t \to \infty$, this probability becomes/does not become $0$. What I think: If n=1, it is similar to the Catalan number. In this more general case, I can calculate the probability of the number of head landings being x after all the tossing, with x between 0 and (n+1)t. Aggregate this on the interval [t,(n+1)t] can get the probability without the restriction of 'at any time point during ... no less than 1/n of that of tail'. Basically I followed the approach used in here . Between page 473 & 475 (theorem 12.1 till 12.3). But I do not know how to deal with the restriction, neither do I know how to evaluate the limit of this probability.","['probability-theory', 'random-walk', 'probability-limit-theorems']"
324413,How to understand $\log{f(z)}$?,"For example, let $\Omega$ be the region $Re(z)>1$ which is simply connected, and let $f(z)=z^9$. I want to find an explicit formula for $\log{f(z)}$ such that $\log{f(z)}$ is holomorphic on $\Omega$ and that $\log{f(z)}$ coincides with $\log{x^9}$ for all real $x>1$. Here is how I did it: Since $f$ is holomorphic and nonvanishing on $\Omega$, there is a holomorphic function $g(z)$ on $\Omega$ such that $e^{g(z)}=f(z)=z^9$ and that $g(x)=9\log{x}$ for real $x>1$. Similarly, there is a holomorphic function $h(z)$ on $\Omega$ such that $e^{h(z)}=z$ and that $h(x)=\log{x}$ for real $x>1$. Since for all real $x>1$ we have $g(x)-9h(x)=0$, we can say that $g(z)-9h(z)=0$ on $\Omega$. On the other hand, we can write $h(z)=\log{|z|}+i\arg{z}$ on $\Omega$ where $\arg{z}\in(-\pi,\pi)$. Thus, since $g(z)=9h(z)$ on $\Omega$, we have $g(z)=9\log{|z|}+9i\arg{z}$ where $\arg{z}\in (-\pi,\pi)$. Is my argument correct or not? If it is, then how can I see the formula for $g(z)$ directly? Moreover, if $f(z)$ is not as simple as a polynomial, how can I give the formula for $\log{f(z)}$ such that $\log{f(z)}$ is holomorphic? Thank you very much.",['complex-analysis']
324422,Dimensions of a box of maximum volume inside an ellipsoid,"Finding the dimensions of the maximum volume box inside the ellipsoid. I assume that the volume of a box, $V(x,y,z) = xyz$ (they did not give this to me, but this is the volume of a box right?) Ellipsoid: $$\frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} = 1$$ and I use Lagrange multipliers to find an incorrect  answer, I end up getting $$x = \frac{\sqrt{a}}{\sqrt{3}}$$
$$y = \frac{\sqrt{b}}{\sqrt{3}}$$
$$z = \frac{\sqrt{c}}{\sqrt{3}}$$ the hint they give me is that $$\text{Max volume} = \frac{8abc}{3\sqrt{3}}$$ Could someone tell me where I am doing this wrong?","['optimization', 'multivariable-calculus', 'calculus', 'volume', 'real-analysis']"
324426,Finding $ \prod_{n=1}^{999}\sin\left(\frac{n \pi}{1999}\right)$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I would appreciate if somebody could help me with the following problem. How can we find the product $$ \prod_{n=1}^{999}\sin\left(\frac{n \pi}{1999}\right)$$","['trigonometry', 'products']"
324427,How to find the multiplicity of eigenvalues?,"I don't understand how to find the multiplicity for an eigenvalue. To be honest, I am not sure what the books means by multiplicity. For instance, finding the multiplicty of each eigenvalue for the given matrix:
$$\begin{bmatrix}1 & 4\\2 & 3\end{bmatrix}$$ I found the eigenvalues of this matrix are -1 and 5, but what are the multiplicities of these?","['linear-algebra', 'eigenvalues-eigenvectors']"
324433,In abelian groups: Is $[G:2G]\leq 2$?,"Let $G$ be an abelian group. Is it true that $[G:2G]\leq 2$? Sometimes it can be $1$ (say, when $G=\mathbb{Z}_3$), but it seems never to be more than $2$.",['group-theory']
324438,"What is the fastest (most reliable) way to calculate the Frenet frame, curvature and torsion, given r(t)?","Vector calculus, just learned about the Frenet frame and curvature and torsion. Naturally, we have to calculate a lot of these on homework and exams. However, the formulas that we are given for getting curvature, torsion, frame are computationally intensive and usually requires a whole bunch of different calculations (differentiate twice, take a cross product and two absolute values just for $\kappa$ and $\tau$). Being unreliable as a biological computer, I am fairly error prone. It feels like there should be easier and more direct ways of getting these formulae. We have: $\mathrm T=\frac{\mathrm r^\prime}{|r^\prime|}$, $\mathrm B=\frac{\mathrm{r'(\mathit t)\times r''(\mathit t)}}{|\mathrm{r'(\mathit t)\times r''(\mathit t)}|}$, $\mathrm{N=B\times T}$, $\kappa =\frac{|\mathrm{r'(\mathit t)\times r''(\mathit t)}|}{\mathrm |r'(t)|^3}$, $\tau=\frac{(\mathrm{r'(\mathit t)\times r''(\mathit t)})\cdot \mathrm r'''(t)}{|\mathrm{r'(\mathit t)\times r''(\mathit t)}|^2}$
and the Frenet-Serret formulas. I am not sure what strategy I should go for - calculate the unit tangent, differentiate a whole bunch, and take absolute values (go straight for Frennet-Serret) or should I try the given formulas since I have a function with respect to t and not arc length? Is there some other better faster way to do this?",['multivariable-calculus']
324444,Power series infinity at every point of boundary,Is there an example of a power series $f(z)=\sum_{k=0}^\infty a_kz^k$ with radius of convergence $0<R<\infty$ so that $\sum_{k=0}^\infty a_kw^k=\infty$ for all $w$ with $|w|=R$ Thank you kindly.,"['complex-analysis', 'real-analysis', 'analysis']"
324452,$x\mapsto f(x^{1/p})$ is smooth if and only if $f^{(n)}(0)=0$ whenever $p\nmid n$,"This is a slight generalization of something I got stuck on when trying to do Problem 2-5 from Introduction to Smooth Manifolds by John M. Lee (which uses the case $p=3$). Let $p\ge 1$ be an integer, let $f:\mathbb{R}\to\mathbb{R}$ be a smooth function, and define $g(x)=f(x^{1/p})$. Then $g$ is smooth if and only if $f^{(n)}(0)=0$ whenever $n$ is not divisible by $p$ and $n\ge 1$. (Here smooth means that $f^{(n)}$ exists on $\mathbb{R}$ for all $n\ge 0$.) This is obvious if $f$ is analytic. But I'm not sure whether this is true for general smooth $f$.","['calculus', 'real-analysis']"
324483,Linear Transformations mapping four points,"Problem: Show that any four distinct points can be carried by a linear transformation to positions $1, -1, k, -k$, where the value of $k$ depends on the points. How many solutions are there, and how are they related? Attempt at a solution: So I know that given any three points $z_2, z_3, z_4$ I can find a linear transformation that carries these points to some other points $w_2, w_3, w_4$ this can be done since the ratio is preserved; that is $$(w, w_2, w_3, w_4)=(z, z_2, z_3,z_4).---(1)$$ So, in our case we have $w_2=-1, w_3=k$ and $w_4=-k$, and we want this transformation to be such that it will also take $z_1$ to $1$. After performing the necessary algebraic steps in $(1)$ I found $$w(z)=\frac{(1+k)(z-z_3)(z_2-z_4)+(1-k)(z-z_4)(z_2-z_3)}{(1-k)(z-z_4)(z_2-z_3)-(1+k)(z-z_3)(z_2-z_4)}k$$ This transformation takes the $z_2$ to $-1$, $z_3$ to $k$ and $z_4$ to $-k.$ So now, do I just force the transformation so that $w(z_1)=1$? I am not sure how the whole $k$ being dependent on the points we choose is coming into play? Any hints?? Thanks!",['complex-analysis']
324484,A Recurrence Relation Involving a Square Root,"Consider the recurrence relation: $a_{n+1} = \sqrt{a_n^2 -k},$ where $k>0$, $n\in\{0,1,n:a_n^2\geq k\}$, and $a_0>0$ is known. Is it possible to obtain an expression for $a_n$ in terms of $n$?","['generating-functions', 'recurrence-relations', 'sequences-and-series', 'recursion']"
324488,Infinite Series :$ \sum_{n=0}^\infty \frac{\Gamma \left(n+\frac{1}{2} \right)\psi \left(n+\frac{1}{2} \right)}{n! \left(n+\frac{3}{2}\right)^2}$,Prove that: $$\sum_{n=0}^\infty \frac{\Gamma \left(n+\frac{1}{2} \right)\psi \left(n+\frac{1}{2} \right)}{n! \left(n+\frac{3}{2}\right)^2} = \frac{-\pi^{\frac{3}{2}}}{12}\left( \pi^2+6\gamma(1-2\log 2)-12\log 2\right)$$ where $\gamma$ is Euler-Mascheroni Constant and $\psi(z)$ is the Digamma Function.,"['special-functions', 'sequences-and-series']"
324496,Binary expansions,"This question is about an example in an article of Dekking and Mendez France: For an integer $n$ let $s(n)$ be the number of ones in the binary expansion,
so that $s(2k)=s(k)$ and $s(2k+1)=s(2k)+1$, $\alpha \in (0,1/2)$ is fixed, $x = 2\pi i \alpha$ and $$ z_n= \sum_{k=0}^{n-1} \exp(xs(k)).$$
The authors claim that for all $n,m \in\mathbb N$ the following can be shown by induction:
$$ z_n=z_m \text{ and } z_{n+1}=z_{m+1} \Longrightarrow n=m.$$
I see this if $n,m$ have the same parity: One has 
$\exp(xs(n))=\exp(xs(m))$ and if $n,m$ are both odd  this gives $\exp(xs(n-1))=\exp(xs(m-1))$ which rather
quickly implies $z_{n-1}=z_{m-1}$. If $n,m$ are both even one can use the identity
$$z_{2n}=(1+e^x)z_n$$ (each term $e^{xs(k)}$ for $k\in \lbrace n,\ldots,2n-1\rbrace$ corresponds to a term $e^{xs(j)}$ with $0\le j \le n-1$ such that
$s(k)=s(j)+1$) to obtain $z_{n/2}=z_{m/2}$ and $z_{n/2-1}=z_{m/2-1}$. However, I do not see how to proceed if $n$ and $m$ have different parity.",['sequences-and-series']
324502,"Elementary Set theory: Consider any three arbitrary sets A, B, and C.","Consider any three arbitrary sets $A$ , $B$ and $C$ . Show that $C \cap A = C \cap B$ and $C \cup A = C \cup B$ , then $A = B$ . Show that if $A − B = B − A$ , then $A = B$ . Show that if $A\cap B = A\cap C = B \cap C$ and $A\cup B \cup C = U$ , then $A\oplus B \oplus C = U$ . My attempts: My logic behind it is that I can prove this by showing that $A$ is a subset of $B$ and $B$ is a subset of $A$ : $x \in  C\cap A$ implying $x  \in A$ and $x  \in  C$ . But now, i get a little confused about the other side. I can't just say $x  \in  C\cap  B$ . But if you look at the $C \cup  A = C \cup  B$ , you can say that since $x \in  A$ , would that imply $x \in  B$ . I went about it the same way as 1, trying to state that $A$ is a subset of $B$ and $B$ is a subset of $A$ . Changing $A-B$ to $A  \cap\lnot B $ , but that means $x \in  A$ , and $x \in \lnot B$ . Can $x$ be an element of $B$ and $\lnot B$ ?",['elementary-set-theory']
324527,Do these equations create a helix wrapped into a torus?,"I don't have any graphing software capable of plotting this, but it makes sense to me. First a circle: $$
x = r\cos\theta \\
y = r\sin\theta
$$ Then a sine wave wrapped into a circle: $$
x = (r+\cos\theta)\cos\theta\\
y = (r+\sin\theta)\sin\theta
$$ And finally, add in the z-coordinate: $$
z = \sin\theta
$$ Is this correct? If not, what's wrong with it? $$
x = (r+\cos\theta)\cos\theta = r\cos\theta + \cos^2\theta\\
y = (r+\sin\theta)\sin\theta = r\sin\theta + \sin^2\theta\\
z = \sin\theta
$$","['locus', 'geometry', 'functions']"
324538,Separable Hilbert space have a countable orthonormal basis,"I want to show that every an infinite-dimensional separable (contains countable dense set) Hilbert space has a countable orthonormal basis. I know that every orthogonal set in a separable Hilbert space is countable, it is help me with the proof?","['hilbert-spaces', 'functional-analysis']"
324540,Find $x\in \mathbb{Z}$ such that $54x^3+1$ is a cube,"Find $x\in \mathbb{Z}$ such that $54x^3+1$ is a cube. I found $x=0$, any others ?","['diophantine-equations', 'elliptic-curves', 'number-theory']"
324542,Why are there $736$ matrices $M\in \mathcal M_2(\mathbb{Z}_{26})$ for which it holds that $M=M^{-1}$?,"I'm currently trying to introduce myself to cryptography. I'm reading about the Hill Cipher currently in the book Applied Abstract Algebra. The Hill Cipher uses an invertible matrix $M$ for encryption and the inverse matrix $M^{-1}$ for decryption. The book recommends to use a matrix $M$ for which it holds that $M=M^{-1}$, since we then have the same key for encryption and decryption. In the book, they use a $2 \times 2$ matrix $M$ over $\mathbb{Z}_{26}$ as example, and state that for there are 736 $2 \times 2$ matrices for which it hold that $M=M^{-1}$. I'm trying to pick up on as much as possible when reading things, since I find it counter-productive for learning to skip something, when you don't get the theory behind it.
Can someone enlighten to me, as to why it is that there are 736 possible $2 \times 2$ $M=M^{-1}$ matrices and how to find them?","['matrices', 'linear-algebra', 'modular-arithmetic', 'cryptography']"
324549,How to prove that $\lim\limits_{n\to\infty} \frac{n!}{n^2}$ diverges to infinity?,"$\lim\limits_{n\to\infty} \dfrac{n!}{n^2} \rightarrow \lim\limits_{n\to\infty}\dfrac{\left(n-1\right)!}{n}$ I can understand that this will go to infinity because the numerator grows faster. I am trying to apply L'Hôpital's rule to this; however, have not been able to figure out how to take the derivative of $\left(n-1\right)!$ So how does one take the derivative of a factorial?","['factorial', 'calculus', 'derivatives', 'limits']"
324554,How does Thurston's geometrisation conjecture imply Poincaré's conjecture?,"I ran into the geometrisation conjecture a few days ago, and I started wondering how to prove Poincaré's conjecture. Let $M$ be a compact, simply connected, $3$-manifold. Clearly it is irreducible since it is simply connected. How would show that the whole $M$ carries a spherical geometry ? Have a nice day, Selim","['low-dimensional-topology', 'geometric-topology', 'differential-geometry', 'algebraic-topology', 'differential-topology']"
324555,A transitive relation $R$ such that $R\circ R\neq R$?,"Find an example of a set $A$ and a transitive relation $R$ on $A$ such that $R\circ R\neq R$. $R\circ R$ is the relation such that $(a,c)\in R\circ R$ when $(a,b) \in R$ and $(b,c) \in R$. I know this, but I don't understand how that can not equal $R$.","['relations', 'discrete-mathematics']"
324561,"What is $\text{Col}(\kappa,\lambda)$ in set theory","I saw somewhere thing like this: $\text{Col}(\kappa,\lambda)$. What is this?","['notation', 'forcing', 'elementary-set-theory']"
324589,Detecting whether a point is above or below a slope,Is there a simple test to know if a point is above or below a line in 2 dimensional vector domain?,"['analytic-geometry', 'geometry', 'linear-algebra']"
324597,Solve $x^{2k}+(x-2)^{2k}=2k$ with $k\in \mathbb N$ and $x\in\mathbb{R}^+$,"Solve $x^{2k}+(x-2)^{2k}=2k$  with $k\in \mathbb N$ and $x\in\mathbb{R}^+$. I have no idea how to solve this, I just can find one solution, $x=k=1$.",['number-theory']
324598,A Simons' type inequality,"I have a problem with the inequality (5) in the article 'Estimates for stable minimal surfaces in three dimensional manifolds' of R.Schoen. As the author suggests this inequality comes from 'well known' equations of the article 'Curvature estimates for minimal hypersurfaces' of Schoen-Simom-Yau. I use [S] to denote the first article and [SSY] for the second one. Now i think that the only usefull inequality in [SSY] for proving (5) of [S] is the inequality (1.27) that can be rewritten in the following form: $\Delta |A|^2 \geq 2|\nabla A|^2-c(1+|A|^2)^2 $ where $ c$ depends only on curvatures of $ N$. This inequality holds for every point in $ M $. In [SSY] the authors restict the study on points of $ M $ where the second fundamental form is non vanishing, but for the inequality above this restriction is clearly not necessary. All things made in [SSY] below (1.27) are restricted to $ |A| \neq 0 $, so they are not useful for proving (5) of [S] that it holds globally on $ M $. Thank you","['riemannian-geometry', 'manifolds', 'differential-geometry']"
324606,"If a group scheme $G$ operates on another scheme $X$, how do you define orbits?","In my specific case, $G=\mathrm{Spec}(k[M])$ is an algebraic torus acting on a toric variety $X_\Sigma$ corresponding to a fan $\Sigma$ when $k$ is not necessarily algebraically closed (or maybe even $k=\mathbb{Z}$). I see how one still can define the distinguished points $x_\sigma$, but how would the $G$-orbit of $x_\sigma$ be defined? My problem is that my working definition of orbits uses points. Of course, I can consider $T$-valued points for any $T$ and get orbits of those, but how do they fit together?","['algebraic-geometry', 'algebraic-groups', 'toric-geometry']"
324620,Order of profinite groups,"So as we know, if $G$ is a profinite group, then the order of $G$ is defined to be
$|G| = \textrm{lcm}(\{G/N\})$
where $N$ runs over all normal subgroups of finite index of $G$. (see here) Question : Let $K$ be a finite group and $G=K^\alpha$ the direct product of copies of $K$ where $\alpha$ is a cardinal number. What should the order of $\widehat{G}$ be? I think it should be $|K|^{2^\alpha}$ but then I do not know how to figure out.",['group-theory']
324622,Counting ways to arrange envelopes by inclusion (from Stanley's Enumerative Combinatorics),"This is a question from supplement( Bijective proof problems ) to the Stanley's Enumerative Combinatorics. The question statement goes like this. ""In how many ways can $n$ square envelopes of different sizes can be arranged by inclusion. For instance, with $6$ envelopes $A, B, C, D, E, F$( listed in decreasing order of their sizes), one way of arranging them would be $F \in C \in B$, $E \in B, D \in A$, where $I \in J$ means envelope $I$ is placed in envelope $J$"". I could not come up with a bijection( had no clue ). I tried in to write a recurrence relation as following. let, $F_n$ = Total number of arrangements possible with $n$ envelopes.
Assume $F_0 = 1$. $$F_n = F_{n-1} + \binom{n-1}{1} F_{n-2} + \binom{n-1}{2} F_{n-3} + \binom{n-1}{3} F_{n-4} +\cdots + \binom{n-1}{n-1} F_0$$ The thought process was, smallest envelope can be grouped with no other envelope($F_{n-1}$ term) or with one other letter($\binom{n-1}{1}F_{n-1}$ term) or with $2$ other letters .... $n-1$ other letters. my notion of grouping is inclusion. Letters $i, j, k$ are grouped means the smallest letter is included in second smallest, second smallest letter is included in the third smallest etc. So, given a set of $k$ letters we include them in one another( we can do it in only one way ). Grouping smallest letter with $i$ other chosen letters$\binom{n}{i}$, we're left with $n-i-1$ letters to arrange. Hence the term $F_{n-i-1}$. Is my reasoning correct? If yes, please help with a bijective proof too.","['permutations', 'combinatorics']"
324637,integrate $\int_{\frac{\pi}{4}}^{\frac{\pi}{2}}{\ln{(\ln{\tan{x}})}dx} $,"Evaluate this integrate
$$\int_{\frac{\pi}{4}}^{\frac{\pi}{2}}{\ln{(\ln{\tan{x}})}dx} $$ My friend tian_275461 proposed this integrate,but I have no idea about it.",['calculus']
324647,Integrate $\int_{0}^{1}{x^{-x}(1-x)^{x-1}\sin{\pi x}dx}$,"Evaluate integral
$$\int_{0}^{1}{x^{-x}(1-x)^{x-1}\sin{\pi x}dx}$$
Well,I think we have
$$\int_{0}^{1}{x^{-x}(1-x)^{x-1}\sin{\pi x}dx}=\frac{\pi}{e}$$ and $$\int_{0}^{1}{x^{x}(1-x)^{1-x}\sin{\pi x}dx}=\frac{e\pi}{24}$$ With such nice result of these integral,why isn't worth to evaluate it? I found a solution about the second one,but I wonder it will work for the first one Note
$$ S=\int_{0}^{1}{\sin{\pi x}x^{x}(1-x)^{1-x}dx}-\int_{0}^{1}{(1-x)e^{(i\pi+\ln{x}-\ln{(1-x)})x}dx} $$
Let $t=\ln{x}-\ln{(1-x)}$,$x=\frac{e^{t}}{1+e^{t}}$
Thus
\begin{align}
S&=\int_{-\infty}^{+\infty}{\frac{1}{e^{t}+1}e^{(i\pi+t)\frac{e^{t}}{1+e^t}}\frac{e^{t}}{(1+e^{t})^{2}}dt}\\  
&=\int_{-\infty+i\pi}^{-\infty-i\pi}{e^{\frac{te^{t}}{e^{t}-1} } \frac{e^{t}}{(e^{t}-1)^{3}}dt}
\end{align}
Due to
$$ f(z)=e^{\frac{te^{t}}{e^{t}-1} } \frac{e^{t}}{(e^{t}-1)^{3}},\qquad D=\{Z\in C|-\pi\leq Im(z) \leq \pi\}$$
Therefore
$res(f,0)=-\frac{e}{24}$when $z=0$
with $ \zeta_{R}=\gamma_{R}+o_{R}+\tau_{R}$
$$\oint_{\zeta_{R}}{f(z)dz}=-2\pi i\cdot res(f,0)=\frac{2i\pi e}{24}$$
because
$$ \{z_{n}\}\subset D,\qquad |z_{n}|\rightarrow\infty $$
Therefore
$$ 2S=2\lim_{R\rightarrow \infty}\int_{\gamma_{R}}{f(z)dz} $$
gives
$$ \int_{0}^{1}{\sin{\pi x}x^{x}(1-x)^{1-x}dx}=Im(S)=\frac{e\pi}{24} $$ My friend tian_275461 told me he use a simliar method to deal with the first one to obtain the result $\frac{\pi}{e}$,but I am not figure it out.",['calculus']
324650,Convergence/Divergence of infinite product,"General condition: $(P_n)_{n\in\mathbb{N}}$ is a sequence of non-zero real numbers.
If $\prod_{n=0}^\infty P_n$ exists in reals and is non-zero , then call this infinite product convergent. Otherwise divergent. I have proven that: If all $(P_n)_{n\in\mathbb{N}}$ are positive, then its convergence is equivalent to convergence of $\sum_{n = 0}^\infty \log(P_n)$. If further $(P_n)_{n\in\mathbb{N}}$ are further greater or equal to 1, then the convergence of the product is equivalent to the convergence of $\sum_{n = 0}^\infty (P_n-1)$ Now I am looking for two examples where a)  $(P_n)_{n\in\mathbb{N}}$ are reals. $\sum_{n = 0}^\infty (P_n-1)$ converges but $\prod_{n=0}^\infty P_n$ diverges b) $(P_n)_{n\in\mathbb{N}}$ are reals. $\prod_{n=0}^\infty P_n$ converges but $\sum_{n = 0}^\infty (P_n-1)$ diverges I have spent a long time on this but failed to find any. I guess it requires complex analysis technique? (Which I don't know) Please help me out. Thank you.","['sequences-and-series', 'infinite-product', 'real-analysis', 'analysis']"
324667,Automorphism group any bounded domain of $\mathbb{C}$,"So far the automorphism group I have calculated for known domain is a Lie Group,so  Automorphism group any bounded domain of $\mathbb{C}$ is a lie group?","['complex-geometry', 'lie-groups', 'complex-analysis']"
324674,"Help me derive Ampere's law from Biot-Savart, magnetostatic case ... how do I use $\nabla\cdot\vec{J} = 0$?","I was trying to derive $\nabla \times \vec{B}\left(\vec{r}\right) = \mu_0 \vec{J}\left(\vec{r}\right)$ from:
$$
\vec{B} \left( \vec{r} \right) = 
   \frac{\mu_0}{4\pi}
      \iiint_{V_s} 
          \frac{\vec{J}\left(\vec{r}_s\right)}{\left|\vec{r}-\vec{r}_s\right|^3} 
          \times \left(\vec{r}-\vec{r}_s\right) 
      \space dV\left(\vec{r}_s\right)
$$
So I first substitute $\nabla\frac{1}{|\vec{r}-\vec{a}|} = -\frac{\vec{r}-\vec{a}}{|\vec{r}-\vec{a}|^3}$ and get:
$$
\vec{B} \left( \vec{r} \right) = 
   -\frac{\mu_0}{4\pi}
      \iiint_{V_s}
          \vec{J}\left(\vec{r}_s\right)
          \times 
          \nabla_{\vec{r}} 
          \frac{1}{\left|\vec{r}-\vec{r}_s\right|} 
      \space dV\left(\vec{r}_s\right)
$$
Which, because $\vec{J}\left(\vec{r}_s\right)$ doesn't depend on $\vec{r}$, is equal to:
$$
\vec{B} \left( \vec{r} \right) = 
   \frac{\mu_0}{4\pi}
      \iiint_{V_s}
          \nabla_{\vec{r}}
          \times  
          \frac{\vec{J}\left(\vec{r}_s\right)}{\left|\vec{r}-\vec{r}_s\right|} 
      \space dV\left(\vec{r}_s\right)
$$
Now if I take the curl of both side, I get:
$$
\nabla_{\vec{r}} \times \vec{B} \left( \vec{r} \right) = 
   \frac{\mu_0}{4\pi}
      \iiint_{V_s}
          \nabla_{\vec{r}} \times
          \left(
          \nabla_{\vec{r}}
          \times 
          \frac{\vec{J}\left(\vec{r}_s\right)}{\left|\vec{r}-\vec{r}_s\right|}
          \right)
      \space dV\left(\vec{r}_s\right)
$$
Which is:
$$
   \frac{\mu_0}{4\pi}
      \iiint_{V_s}
          \left(         
           \nabla_{\vec{r}}\left(\nabla_{\vec{r}} \cdot \frac{\vec{J}\left(\vec{r}_s\right)}{\left|\vec{r}-\vec{r}_s\right|} \right)
           -  {\nabla^2}_{\vec{r}} \frac{\vec{J}\left(\vec{r}_s\right)}{\left|\vec{r}-\vec{r}_s\right|}
          \right)
      \space dV\left(\vec{r}_s\right)
$$
Which, because $\vec{J}\left(\vec{r}_s\right)$ doesn't depend on $\vec{r}$, is:
$$
   \frac{\mu_0}{4\pi}
      \iiint_{V_s}
          \left(
          \nabla_{\vec{r}}
            \left(
              \vec{J}\left(\vec{r}_s\right) \cdot \nabla_{\vec{r}} \frac {1} {\left|\vec{r}-\vec{r}_s\right|}
            \right)
          + \vec{J}\left(\vec{r}_s\right) \space 4\pi \delta^3 \left(\vec{r}-\vec{r}_s\right)
          \right)
      \space dV\left(\vec{r}_s\right)
$$
Which is:
$$
   \left[
   \frac{\mu_0}{4\pi}
      \iiint_{V_s}
          \nabla_{\vec{r}}
            \left(
              \vec{J}\left(\vec{r}_s\right) \cdot \nabla_{\vec{r}} \frac {1} {\left|\vec{r}-\vec{r}_s\right|}
            \right)
      \space dV\left(\vec{r}_s\right)
    \right]
   \Large{ + \space\mu_0 \vec{J}\left(\vec{r}\right)}
$$
Which is:
$$
    \frac{\mu_0}{4\pi}
    \left[ 
      \nabla_{\vec{r}}
      \iiint_{V_s}
            \left(
              \vec{J}\left(\vec{r}_s\right) \cdot \nabla_{\vec{r}} \frac {1} {\left|\vec{r}-\vec{r}_s\right|}
            \right)
      \space dV\left(\vec{r}_s\right)
      \right]
      \Large{+ \space\mu_0 \vec{J}\left(\vec{r}\right)}
$$
Now my question is, given $\nabla \cdot \vec{J}\left(\vec{r}_s\right) = 0$, how can I show that $ \nabla \iiint_{V_s}
            \left(
              \vec{J}\left(\vec{r}_s\right) \cdot \nabla \frac {1} {\left|\vec{r}-\vec{r}_s\right|}
            \right)
      \space dV\left(\vec{r}_s\right) $ reduces to zero? Which expression reduces to $\nabla \cdot \vec{J}\left(\vec{r}_s\right)$, and how? What is the applicable identity? Attempt So to attack the integral $ \iiint_{V_s} \left( \vec{J}\left(\vec{r}_s\right) \cdot \nabla \frac {1} {\left|\vec{r}-\vec{r}_s\right|} \right) \space dV\left(\vec{r}_s\right) $, I first switch the variable over which the gradient is taken from $\vec{r}$ to $\vec{r}_s$:
$$
\nabla_{\vec{r}_s}\frac {1} {\left|\vec{r}-\vec{r}_s\right|} = -\nabla_{\vec{r}}\frac {1} {\left|\vec{r}-\vec{r}_s\right|}
$$
My integral, therefore, becomes:
$$
 -\iiint_{V_s} \left( \vec{J}\left(\vec{r}_s\right) \cdot \nabla_{\vec{r}_s} \frac {1} {\left|\vec{r}-\vec{r}_s\right|} \right) \space dV\left(\vec{r}_s\right) 
$$
Which is, doing a vector integration by parts:
$$
 \iiint_{V_s} \frac {\nabla_{\vec{r}_s} \cdot \vec{J}\left(\vec{r}_s\right)} {\left|\vec{r}-\vec{r}_s\right|}  dV\left(\vec{r}_s\right) -
 \oint_{\partial V_s}
 \frac {\vec{J}\left(\vec{r}_s\right)} {\left|\vec{r}-\vec{r}_s\right|} 
 \cdot d\vec{S}\left(\vec{r}_s\right)
$$
The first term is zero because we know that $\nabla\cdot\vec{J}=0$. I am guessing that the second term also zero because, by definition, there is no current density outside of $V_s$. (This is correct, as confirmed by the answer below)","['multivariable-calculus', 'vector-analysis']"
324677,Uniform Convergence of integrals,"If a sequence of functions $f_n$ are uniformly convergent in a given interval $[a,b]$ to a function $f$, are all riemann integrable, then the integral $$\int ^b_af_ndx\rightarrow\int^b_afdx$$ and $f$ is riemann integrable. but is the convergence uniform? More precisely, is it true that $\forall \epsilon >0, \exists N:\forall n>N$,
$$\left| \int ^b_af_ndx-\int^b_afdx\right|<\epsilon$$ How would I prove it? Or is it obvious?","['calculus', 'real-analysis', 'analysis']"
324681,"If all the signs are negative in an $(a + b + c)^2$ bracket, can I just make them all positive?","I have to do the expansion $$(-y - z - x^2 - y^2 - z^2)^2$$ Can I say that this is $$(y + z + x^2 + y^2 + z^2)^2$$ as all the signs are the same inside the brackets and so multiplying two negatives together will always give me a positive? Or if I wanted to show it algebraically, I could do $$(-y - z - x^2 - y^2 - z^2)^2 = [(-1)(y + z + x^2 + y^2 +z^2)]^2$$
$$ = (-1)^2(y + z + x^2 + y^2 +z^2)^2 = (y + z + x^2 + y^2 +z^2)^2$$ EDIT: Ok, lets say just one of those terms in that bracket was positive, could I still do the $(-1)$ trick and make just one term negative and so its easier to work out, or would I need to leave it as it is and expand it?",['algebra-precalculus']
324690,$\mathbb{R}^S$ for finite and countable set $S$,"For a finite and countable set $S$, what does $\mathbb{R}^S$ mean? It seems like it should mean something similar to the power set but I can't think of what this is. Also, I couldn't figure out how to search for an answer to this question!",['elementary-set-theory']
324712,Disproving a claim about path-connected Hausdorff spaces which are an infinite union of an ascending chain of compact subsets,"I am trying to disprove the following: Let $X$ be a path-connected Hausdorff space which has a sequence of compact subsets $$K_1\subseteq K_2\subseteq K_3\subseteq \cdots$$ such that $X=\bigcup_{n\geq 1} K_n$. Assume a subset $C$ is closed if and only if $C\cap K_n$ is compact for all $n$. Claim : Every compact subset $C\subseteq X$ is contained in $K_n$ for some $n$. Question : Is this false? I believed $X=[0,1]$ with $K_n=[0,1-\frac{1}{n+1}]$ was a counterexample, but it's not. Any thoughts? Note : this is not homework, at least not mine anyway. I found it while looking through old topology problem sheets.",['general-topology']
324740,Fermat's 'proof' of his Last Theorem,"The definition of a unique factorisation domain came up in my rings lecture about a week ago, and my lecturer mentioned that Fermat's 'proof' of his Last Theorem probably relied on the (false) assumption that all subrings of $\mathbb{C}$ are unique factorisation domains. Does anyone know what this 'proof' would have looked like?","['soft-question', 'number-theory']"
324748,Optimization problem (in linear algebra course!),"Let $a_1, a_2, \ldots, a_n$ be real numbers such that $a_1 + \cdots + a_n = 0$ and $a_1^2 + \cdots +a_n^2 = 1$.  What is the maximum value of $a_1a_2 + a_2a_3 + \cdots + a_{n - 1}a_n  + a_na_1$? I'd like to emphasize that this was found in a random linear algebra exercise sheet so one might expect that there exists a clever solution based on matrix manipulation... Personally I tried to conceive the problem geometrically and analytically. Notably $n=1$ has no meaning, $n=2$ gives $-1$, $n=3$ gives $-1/2$. This did not reveal much about the general case except for the fact that Lagrangian (system of partial derivatives and all that jazz) seems to imply that ANY combination satisfying the constraints gives the same value (value I'm trying to maximize) - but this needs some further checking. Back to the linear algebra I see traces of matrices, but I need to somewhat simply express $A$ and $B$ (see below) in terms of one another before anything useful can be done... $$A = \operatorname{diag}(a_1,a_2,\ldots,a_{n-1},a_n);$$
$$B = \operatorname{diag}(a_2,a_3,\ldots,a_{n-1},a_n,a_1);$$ P.S. The problem was originally taken from this very forum but it's quite and old post and I don't seem to be able to leave a comment there.","['optimization', 'linear-algebra']"
324759,"Given the product of a unitary matrix and an orthogonal matrix, can it be easily inverted _without_ knowing these factors?","Given the product $M$ of a unitary matrix $U$ (i.e. $U^\dagger U=1$) and an orthogonal matrix $O$ (i.e. $O^TO=1$), can it be easily inverted without knowing $U$ and $O$? Sure enough, if $M=UO$, then $M^{-1}=O^TU^\dagger$. But assuming you only know that $M$ is composed in such a way, but not how $U$ and $O$ actually look, does there still exist a simple formula for $M^{-1}$?","['matrices', 'linear-algebra', 'inverse']"
324769,"Results of the multivariate function $f(x,y) = 3x^2 - 2xy + y^3 $","I was asked to derive 2 experessions for this multivariate function $$
f(x,y) = 3x^2 -2xy+y^3
$$ The first is $\large{\frac{f(x+h,y) - f(x,y)}{h}}$ and the other is $\large{\frac{f(x,y+k) - f(x,y)}{k}}$ The working is as follows: $$
\begin{align*}
\frac{f(x+h,y) - f(x,y)}{h} &= \frac{3(x+h)^2 - 2y(x+h) + y^3 -(3x^2-2xy+y^3)}{h}
\\&= \frac{3(x+h)^2 - 3x^2 -2y(x+h) + 2xy}{h}
\\&=\frac{3(x+h+x)(x+h-x) - 2y(h)}{h}
\\&=\frac{3(x+h+x)(x+h-x) - 2y(h)}{h}
\\&= 3(2x+h) -2y
\end{align*}
$$ and $$
\begin{align*}
\frac{f(x,y+k) - f(x,y)}{k} &= \frac{3x^2 - 2x(y+k) + (y+k)^3-(3x^2-2xy+y^3)}{k}
\\&= \frac{-2x(y+k) +(y+k)^3 + 2xy-y^3}{k}
\\&=\frac{2x(-y-k+y) + (y+k)^3 - y^3}{k}
\\&=\frac{-2xk + (y+k-y)[(y+k)^2 + y(y+k) + y^2]}{k}
\\&=\frac{-2xk + k[(y+k)^2 + y(y+k) + y^2]}{k}
\\&= -2x + (y+k)^2 + y(y+k) + y^2
\end{align*}
$$
Are the calculations correct? UPDATE Thanks to the community, I have verified the answer. For completeness, I shall continue to derive the partial derivatives using the above answers. $$
\begin{align*}
\frac{\partial f}{\partial x}(x,y)=\lim_{h\to0}\frac{f(x+h,y)-f(x,y)}{h}
&= \lim_{h \to 0}3(2x+h) - 2y
\\&= 6x + 2y
\end{align*}
$$ and $$
\begin{align*}
\frac{\partial f}{\partial y}(x,y)=\lim_{k\to0}\frac{f(x,y+k)-f(x,y)}{k}
&= \lim_{k \to 0} -2x + (y+k)^2 + y(y+k) + y^2
\\&= -2x + y^2 + y^2 + y^2
\\&= -2x + 3y^2
\end{align*}
$$","['multivariable-calculus', 'calculus']"
324777,Do eigenfunctions of elliptic operator form basis of $H^k(M)$?,"We know that the eigenfunctions of the Laplacian on a compact manifold $M$ form a countable basis of $H^1(M)$. If $L$ is a $2k$-order elliptic operator, do the eigenfunctions of $L$ form a basis for $H^k(M)$? References/more detail would be appreciated. Thanks.","['riemannian-geometry', 'functional-analysis', 'partial-differential-equations']"
324790,A problem on sequentially compact and countably compact,"Recently I came across a problem as follows ""I know that sequentially compact implies countably compact. But can anybody tell me please that the converse is true or false.""","['general-topology', 'compactness']"
324798,How to choose the starting row when computing the reduced row echelon form?,"I'm having hell of a time going around solving matrices to reduced row echelon form. My main issue is which row to start simplifying values and based on what? I have this example so again, the questions are: 1.Which row to start simplifying values? 2.Based on what criteria? Our professor solved it in the class with no fractions but I could not do it. Even though  I know the 3 operations performed on matrices","['matrices', 'linear-algebra']"
324808,I don't understand the definition of completion of a $\sigma$-algebra,"I am preparing for the test there is a question that I dont understand: suppose that $(\Omega,\mathscr F,P)$ is the probability space where $\Omega:=\{1,2,...,6\}$, $\mathscr F:=\sigma(\{2,4,6\},\{1,3,5\})$, $P(\{2,4,6\})=0$. What is the $P$-completion of $\mathscr F$?","['probability-theory', 'measure-theory']"
324832,complex proof not sure,"There's this problem in my homework, I did it, but somehow it just doesn't seem right. I wonder where the problem is... Please help me :) Show that $\int_\gamma z^n dz=0$ for any closed smooth $\gamma$ and any integer $n\neq -1$. [If $n$ is negative, assume that $\gamma$ does not pass through the origin, since otherwise the integral is not defined.] $\rightarrow$  Sol.
Let $z=\gamma(t)$, $dz=\gamma'(t)dt$, $a\leq t\leq b$, $\gamma(a)=\gamma(b)$. Then:
\begin{align*}
&\int_\gamma z^n dz\\
=&\int_a^b\gamma(t)^n\gamma'(t)dt\\
=&\int_{\gamma(a)}^{\gamma(b)} z^n dz\\
=&\frac{z^{n+1}}{n+1}\bigg|_{\gamma(a)}^{\gamma(b)}\\
=&0\\
\end{align*} What could the problem be? Thank you!",['complex-analysis']
324833,"With $xy+yz+zx=-1$, proving: $x^2+2y^2+2z^2 .....$","Assuming $xy+yz+zx=-1$, prove that : $$x^2+2y^2+2z^2 \geq \frac{1+\sqrt{17}}{2}$$","['inequality', 'calculus', 'real-analysis']"
324842,Nets and compactness in topological spaces.,"I am reading Kelley’s book on general topology. There are a few statements on nets there (chapter 2), but the characterization of compact sets in the language of nets is not given. How should we prove the following Theorem: A topological space X is compact iff every net has a convergent subnet.","['general-topology', 'convergence-divergence', 'compactness', 'nets']"
324866,Facts about Abelian Groups and group order.,"I look for some theorems which tell us about the relation between the property of being abelian for groups and the order of the group. I think these theorems are provided in a second course of group theory or more advanced courses.  At this stage, however, I'm interested in knowing some of these theorems without the details of proofs of this theorems. I hope that you can give me some of these theorems! Thanks.","['finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
324878,Commuting Skew-symmetric Nilpotent 4x4 Matrices,"Suppose $A$ and $B$ are nonzero, commuting, skew-symmetric, nilpotent matrices in $M_4(k)$, $k$ a field (char $k\ne 2$).  Must $A=\lambda B$ for some $\lambda\in k$?  I have shown that this is true for $3\times 3$ matrices, and I believe it should also be true for $4\times 4$ matrices. Thanks in advance to anyone willing to help me with this fairly dry question.",['linear-algebra']
324886,On Groups of Order 315 with a unique sylow 3-subgroup .,"in Dummit and Foote , an exercise asked me to prove that , if $G$ is a group of order $315$ , $G$ has a normal sylow $3$ -subgroup then , $G$ is abelian . this is exercise number $27$ , section $5$ , chapter $4$ my method on proving this is showing that $ |G| = |Z(G)|$ as follows i showed that $|Z(G)|$ $\in$ $\{ 9 , 63 , 45 , 315 \} $ and  showed that $ |Z(G)|$ is not $63 , 45$ or $9$ so it must be $315 $ but i showed this under two conditions, first condition:
if $X$ is the set of all elements of $G$ of order $5$ , $H$ is the subgroup generated by $X$ then $|H|$ is not $315$ second condition: also , if $Y$ is the set of all elements of $G$ of order $7$ , $N$ is the subgroup generated by $Y$ then $|N|$ is not $315$ so , if those two conditions are true then my method of proving works . but i don't know how to prove those conditions . any help ?","['abelian-groups', 'abstract-algebra', 'sylow-theory', 'finite-groups', 'group-theory']"
324901,"Does $\sum_{n=1}^\infty n^{-1-|\sin n|^a}$ converge for some $a\in(0,1)$?","The divergence of the series $\sum_{n=1}^\infty n^{-1-|\sin n|}$ is proved here . An inmediate consequence is that if $a\ge1$ then $\sum_{n=1}^\infty n^{-1-|\sin n|^a}$ also diverges. My question is: is there some $a\in(0,1)$ such that
$$
\sum_{n=1}^\infty \frac{1}{n^{1+|\sin n|^a}}<\infty?
$$
I have tried to adapt the proof given in the above link, but I have been unable to do it.  On the other hand, it can be adapted to prove that
$$
\sum_{n=1}^\infty \frac{1}{n^{1+b|\sin n|}}=\infty\quad\forall b>0.
$$","['convergence-divergence', 'sequences-and-series']"
324908,What is the shortest line around two equally sized circles called?,"Like the outline of a rectangle with semi-circular ends. Is there a formula to describe it(like $x^2 + y^2 = r^2$ describes a circle)? I'm sure I could Google it if I knew a name for this shape - surely something this simple must have a name? The circles can be separate, touching, intersecting or co-incident(one circle). They will always be the same size I need to be able to determine the co-ordinates of the intersection of the shape and a straight line at any given angle to the horizontal from the centre of the shape to the edge. say $r=radius$ and $d=$distance between centres For a specified $r$ and $d$ and $\angle$ from any point$(x, y)$ on the edge to midway between the centres to the horizontal. I need to find $(x, y)$ Apologies for my non-mathematical statement of the problem.
I was good at maths $20$ years ago!",['geometry']
324913,Order of the smallest group containing all groups of order $n$ as subgroups.,Let $n\in \Bbb N$ be fixed and $m\in \Bbb N$ be the least number such that there exists a group of order $m$ in which all groups of order $n$ can be (isomorphically) embedded. Can we deduce $n!=m$?,"['asymptotics', 'finite-groups', 'group-theory', 'abstract-algebra']"
324969,Manifolds and Charts,"I have a very silly and basic question about finding charts for a manifold. The point is: I'm self learning differential geometry, however, I didn't find the answer for this in the book nor on the web. I've once asked about how to find charts, but now my point is another: is how to represent the elements of a manifold before start creating the charts. First, I'm using Do Carmo's definition of manifold: A smooth manifold of dimension $n$ is a set $M$ with a family of bijective maps $\varphi_\alpha : U_\alpha \to M$ from open sets $U_\alpha\subset \mathbb{R}^n$ to $M$ such that: $\bigcup_\alpha\varphi_\alpha(U_\alpha)=M$ For each pair $\alpha, \beta$ with $\varphi_\alpha(U_\alpha)\cap\varphi_\beta(U_\beta)=W\neq\emptyset$ we have $\varphi_\alpha^{-1}(W)$, $\varphi_\beta^{-1}(W)$ open in $\mathbb{R}^n$ and $\varphi_\beta^{-1}\circ\varphi_\alpha$, $\varphi_\alpha^{-1}\circ\varphi_\beta$ are differentiable. The family $\left\{U_\alpha, \varphi_\alpha\right\}$ is maximum with respect to conditions 1 and 2. Amongst all definitions of smooth manifold, this one was the one I prefered to work with. My point here is: we make this definition in order to avoid the need to consider manifolds as subsets of some euclidean space. In other words, we want to deal with them without making reference to some ambient space. My problem with this is to find the charts. I have to construct bijective functions from $\mathbb{R}^n$ to $M$, and so my doubt is: how I describe the elements of $M$? The classical example of finding charts for the sphere $S^n$ assumes that the sphere is defined as a subset of $\mathbb{R}^{n+1}$, so we know that if $p \in S^n$ then there are $n$ real numbers $p^i$ such that $p = \left(p^1 ,\cdots, p^n\right)$ that simply satisfy some conditions. Then it becomes easier to find the charts because first of all we know how to describe the elements of the set. Second, because we can use the ambient space, so we can use stereographic projections, which depends on the ambient space. But in general, we don't want to use one ambient space. So, if I was asked for instance to find the charts for the sphere without the ambient space, what should I do? Well, now if $p \in S^n$, I cannot say that $p$ is one $n$-tuple of numbers, and I cannot also use things from outside $S^n$ like the planes and lines used in stereographic projections. I'm confused with all of that. In understand the theorems, the proofs, the use of transition charts to ensure differentiability, and so on. My only problem is to find the charts, I feel I'm in need of examples, but I haven't found many. Do Carmo's examples deal just with surfaces, and he always presents them as subsets of $\mathbb{R}^3$. Can someone explain those points or point me some references? Sorry for such a silly and basic question. And also sorry for the long text, I just didn't find a way to make it smaller.","['manifolds', 'differential-geometry']"
324972,Existence of minimizing geodesic in each fixed-end-point homotopy class in a complete manifold?,"This is intuitively clear, but I cannot solve this homework problem: 1) Let $(M,g)$ be a complete Riemannian manifold, let $c:[0,1]\to M$ be a continuous curve in $M$ such that $c(0)=p, c(1)=q$. Then prove that in the fixed-end-point homotopy class of $c$, there is a geodesic $\gamma$, i.e. there exists a geodesic $\gamma$ so that $\gamma$ is homotopic to $c$ with homotopy keeping the end points $p,q$ fixed. 2) My question: Assuming the above is true, is that geodesic $\gamma$ in the answer necessarily minimizing as well? I feel it should be. I was thinking of using Hopf-Rinow theorem stating that geodesically complete is the same as metrically complete and starting with the contrary. But I got stuck.","['riemannian-geometry', 'algebraic-topology', 'differential-geometry']"
324975,"If $P$ is the intersection of the altitudes of a tetrahedron $ABCD$ and $r$ is the circumradius, then $PA^2+PB^2+PC^2+PD^2=4r^2$","Prove that, if $P$ is the intersection of the altitudes of a tetrahedron $ABCD$ and $r$ is the circumradius, then $$PA^2+PB^2+PC^2+PD^2=4r^2$$","['geometry', '3d', 'coordinate-systems', 'solid-geometry']"
324980,"Partial Derivative of $f(x,y) =\ln(x^{2} + y^{2}) + \sqrt{x^{2}\cdot y^{3}}$","$$f(x,y) = \ln(x^{2} + y^{2}) + \sqrt{x^{2}\cdot y^{3}}$$
What is the value of $f_{x}\left ( 0,1 \right )$ and $f_{y}\left ( 0,1 \right )$?
I tried but I found the denominator as zero.","['multivariable-calculus', 'partial-derivative']"
324984,Finding solution in naturals to $a^b=b^a$ with the help of $f(x)=\frac{\ln(x)}{x}$,"As the title said, I'm trying to find solution in naturals numbers to $a^b=b^a$ with the help of the function $f(x)=\large\frac{\ln(x)}{x}$. I've been reading some solutions of that problem posted in math forums, and still don't know how to deduce, the obvious solutions, $(2,4)$ and $(4,2).$ Thank you very much!",['calculus']
324995,6 point lying on a common circle,"$Z$ is an interior point of segment $XY$. Three semicircles are drawn over segments $XY$, $XZ$ and $ZY$ on the same side. The midpoints of the arcs are $M1$, $M2$ and $M3$ respectively. A circle tangent to these semicircles is internally tangent to the semicircle centered at $M1$. Let their point of tangency be $T$. Show that the midpoint of segment $XY$ and the points $Z$, $M1$, $M2$, $M3$ and $T$ all lie on a common circle. So far I've tried using coordinates and equations such as if $X=(0,0)$, $XZ=a$ and $YZ=b$ then $Z=(a,0)$, $Y=(a+b,0)$, $M=(\frac{a+b}{2},0)$, $M_1=(\frac{a+b}{2},\frac{a+b}{2})$, $M_2=(a,a)$, $M_3=(a+\frac{b}{2},\frac{b}{2})$ and after that applying the Equation of the Circle, but it seems pretty hard going in parts. Any other ideas? Or should I continue this?","['geometry', 'circles', 'euclidean-geometry']"
325004,Total length of pieces after splitting,"If I consider the number line from $0$ to $n$ and cut it into $x$ pieces, it is well known that there is at least one stretch of length at least $n/x$. My question is what is the minimum total length of all the pieces of length at least $y$. For example, if I split the line into three pieces and set $y = \frac{n}{3}$ then by making one piece fractionally greater than $\frac{n}{3}$ and the other two smaller, we can make the total length fractionally greater than $\frac{n}{3}$. If we set $y=\frac{n}{4}$ keeping $x=3$ then the minimum total length seems to be just over  $\frac{n}{2}$.  From this one can guess an answer of $n-(x-1)y$. Is this the correct answer and how can one prove it?","['discrete-mathematics', 'recreational-mathematics', 'combinatorics']"
325009,Rudin Real And Complex Definition 2.16,"I'm having some difficulties in the remark Rudin makes in definition 2.16, when he says that , if we consider the situation described in theorem 2.14(Riesz representation theorem), if $E$ is in the $\sigma$-algebra and has $\sigma$-finite measure then $E$ is inner regular. I don't understand why this is true. And i think it's key to prove theorem 2.18 item (b), so the trouble is really to prove theorem 2.18. Sorry for my bad english.","['measure-theory', 'real-analysis']"
325020,Prove that a set of matrices is a subspace,"I'm self studying linear algebra and now I'm starting with proofs and so on. I found this exercise and this is the way I prove it. I think it's correct but I'm not sure I mean, what do you think? Is the set of matrices 
    $
\begin{pmatrix}
x && x+y \\
x-y && y
\end{pmatrix}
$ where $x, y \in R $ a subspace of $M_{2\times 2}$ I know that for the set to be a subspace it needs to be closed under vector addition and under scalar multiplication. So: Given $M_1, M_2 \in M_{2\times 2}, x,y, \in R$. Then $M_1 + M_2$ will be: $$\begin{align}
\begin{pmatrix}
x_1 && x_1+y_1\\
x_1-y_1 && y_1
\end{pmatrix}
&+
\begin{pmatrix}
x_2 && x_2+y_2\\
x_2-y_2 && y_2
\end{pmatrix}
=
\\&
\begin{pmatrix}
(x_1 + x_2) && (x_1+x_2)+(y_1+y_2)\\
(x_1+x_2)-(y_1+y2) && (y_1 + y_2)
\end{pmatrix}
\end{align}$$ Which has the same structure so it's closed under vector addition. Now, Given $M \in M_{2\times 2}, x,y,r \in R$. Then $rM_1$ will be: $$
r\begin{pmatrix}
x && x+y\\
x-y && y
\end{pmatrix}
=
\begin{pmatrix}
rx && r(x+y)\\
r(x-y) && ry
\end{pmatrix}
$$ Which, given that $x,y,r \in R$ is also closed under vector multiplication. So yes. The set is a subspace of $M_{2\times 2}$",['linear-algebra']
325059,Polynomial root (using contraction mapping principle),"I am asked to provide an iterative algorithm which would lead to finding a real root of this polynomial: $$6x^5-x^3+6x-6=0$$
It is required to rely on the contraction mapping principle and Banach fixed-point theorem . At the moment I think I can rewrite $$f(x) = \sqrt[5]{x^3/6-x+1}$$
and try to prove that in a complete metric space $\langle \, \mathbb{R}, d \, \rangle$ I have a contraction mapping $f:\mathbb{R} \rightarrow \mathbb{R}$ and consequently a unique fixed-point is my solution. I already see it's going to be messy (contraction mapping proof part) and the idea of it makes me sick... Besides those 6'es in the initial polynomial temps to rewrite $$ x = \sqrt[3]{6} \sqrt[3]{x^5+x-1}$$ but I see no good coming out of it. Since I'm very new to functional analysis and metric spaces I decided to ask you for suggestions about the most suave way to do it. The final answer (fixed point) will be $x \approx 0.78$ so I'd love to get the contraction mapping over $[0;1]$, $[-1;1]$, $[0;2]$, $[-2;2]$ or something like that which would be easy to prove (contractility that is) without calculator... But I can't find it!","['metric-spaces', 'functional-analysis']"
325060,A bounded sequence whose sequence of averages does not converge,"Can we find a bounded sequence $\{a_n\}$ such that the sequence of its averages, say, sequence $\{b_n\}$, where 
$$b_n=\frac{1}{n}\sum_{i=1}^n a_i,$$
does not converge?",['analysis']
325069,Problem with the Pythagorean theorem [duplicate],"This question already has answers here : The staircase paradox, or why $\pi\ne4$ (23 answers) Vector path length of a hypotenuse (4 answers) Closed 11 years ago . The Pythagorean theorem has already been proved and it is a basic fact of math. It always works, and there are proofs of it. But I have found a problem. Say you want to get from point A to point B . Here is a way to do it, where red is vertical movement and grey is horizontal movement. Now say you split the path up like this. Note that it is the same length, as you can see from the color of the lines: You can continue to do this... (note that the path still continues to stay the same length): And if you continue forever, the path will become diagonal. But now there's a problem. This is contradicting the Pythagorean theorem: I know the Pythagorean theorem is true and proven, so what is wrong with this series of steps that I went through?","['geometry', 'triangles', 'fake-proofs']"
325073,"How do extension fields implement $>, <$ comparisons?","I'm taking an abstract algebra course, and we just hit extension fields - for example, you define $\sqrt{2}$ by starting with the field $\mathbb{Q}$ and defining $\sqrt{2}$ as a solution to the irreducible (over $\mathbb{Q}$) polynomial $x^2 - 2$. This is unintuitive to me, because I know something additional about $\sqrt{2}$: intuitively I want to be able to make statements like $1 < \sqrt{2} < 2$, but I'm not sure how $<$ is even defined when $\sqrt{2}$ is fabricated like so. So, my question: using the extension-field definition of $\sqrt{2}$, what additional construction allows us to make comparisons such as $1 < \sqrt{2} < 2$?  And why do these constructions not allow us to make comparisons on $i$, which is similarly defined via extension fields (since $1 < i < 2$ is a nonsensical statement)?","['ordered-fields', 'extension-field', 'abstract-algebra']"
325080,Map that satisfies $f(\lambda x) = \lambda f(x)$ but not $f(x+y) = f(x)+f(y)$,"Could you give me example of maps $f:\mathbb R \to \mathbb R$ that satisfy
$$ f(\lambda x) = \lambda f(x) \quad \forall x,\lambda \in \mathbb R $$
but not
$ f(x+y) = f(x)+f(y) $? Thanks in advance.","['real-analysis', 'functional-equations']"
325082,Is the inverse of a symmetric matrix also symmetric?,"Let $A$ be a symmetric invertible matrix, $A^T=A$, $A^{-1}A = A A^{-1} = I$ Can it be shown that $A^{-1}$ is also symmetric? I seem to remember a proof similar to this from my linear algebra class, but it has been a long time, and I can't find it in my text book.","['symmetric-matrices', 'matrices', 'linear-algebra', 'inverse']"
325091,What is the probability for a monkey writing Shakespeare? [duplicate],"This question already has answers here : Given an infinite number of monkeys and an infinite amount of time, would one of them write Hamlet? (13 answers) Closed 11 years ago . The article clearly describes the idea but does not the state the probability. What is the probability? Can this problem be extended to audio, graphics and video for instance what is the probability that a random outcome is a certain song, a certain photo or a certain movie?","['statistics', 'probability']"
325096,"Find $\iint xy(x^2 + y^2)^{1/2} \, \mathrm dA$","$$\iint xy(x^2 + y^2)^{1/2}\,  \mathrm dA$$ where the region is square $[0,1] \times [0,1]$ removing its intersection with the circle of radius 1 at origin. i got $\displaystyle{\frac{2^{7/2}-7}{30}}$ as my final answer? Anyone disagree?","['multivariable-calculus', 'calculus']"
325110,Continuity of Monotone Functions,"Let f be a monotone function on the open interval (a,b). Then f is continuous except possibly at a countable number of points in (a,b). Assume f is increasing. Furthermore, assume (a,b) is bounded and f is increasing on the closed interval [a,b]. Otherwise, express (a,b) as the union of an ascending sequence of open, bounded intervals, the closures of which are contained in (a,b), and take the union of the discontinuities in each of this countable collection of intervals. I was a little confused about the last sentence, because I wasn't sure of what ""closure"" meant. This is how my textbook defines it, For a set E of real number, a real number x is called a point of point of closure of E provided every open interval that contians x also contains a point in E. The collection of points of closure of E is called the closure of E and denoted by $\bar{E}$...It is clear that we always have $E \subseteq \bar{E}$. I'm not sure if I understood this theorem correctly, because...from what I understand the (a,b) needs to be included in the closures (since $E \subseteq \bar{E}$ ) of the ascending sequences, right? But it says the opposite (""closures of which are contained in (a,b)). So could anybody try the clarify this for me? Thanks in advance",['real-analysis']
325127,"Given distinct positive integers $a, b, c$ and $2^a\cdot2^b\cdot2^c =64$, what is $2^a+2^b+2^c$?","Suppose that $a,b$ and $c$ are distinct positive integers and $2^a\cdot2^b\cdot2^c =64$ . Find $2^a+2^b+2^c$ . This is so far my work: I got $2^a\cdot2^b\cdot2^c=2^6$ then $abc=6$ is this so far in the right track?","['exponentiation', 'algebra-precalculus']"
325141,Probability that n points on a circle are in one semicircle,"Choose n points randomly from a circle, how to calculate the probability that all the points are in one semicircle? Any hint is appreciated.","['geometric-probability', 'probability']"
325146,"$\int_C ( 2 xz \, \vec {\mathbf i} + x^2z \, \vec {\mathbf j}+ x^2y \, \vec {\mathbf k}) \mathrm d \, \vec {\mathbf r}$ : Line Integral","Evaluate $\int_C \vec {\mathbf F} \mathrm d \, \vec {\mathbf r}$ , where $\vec {\mathbf F} (x,y,z) = 2 xz \, \vec {\mathbf i} + x^2z \, \vec {\mathbf j}+ x^2y \, \vec {\mathbf k}$ , and C is the path from (0 , 1 , 2) to (1 , 2, 3) that consists of three line segments parallel to the x    -axis, y-axis, and z-axis, in this order. Ill try it in a few moments",['multivariable-calculus']
325169,Solving for the triangle's perimeter,"Would like some help with solving for the grey triangle's perimeter. It is assumed that the grey triangle is equilateral. My attempt: Let $x =$ side of grey triangle
Let $h =$ height of grey triangle
Let $y =$ height of rectangle
Let $x =$ length of rectangle Area of triangle $= \sqrt{150^2 - 120^2} \cdot 120 \cdot 2 = 21600$ $90(120) = (h+y) \cdot 120$ $h + y = 90$","['geometry', 'triangles']"
