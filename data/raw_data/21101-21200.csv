question_id,title,body,tags
178814,Understanding why the roots of homogeneous difference equation must be eigenvalues,"There is some obvious relationship between the root solutions to a homogeneous difference equation (as a recurrence relation) and eigenvalues which I'm trying to see. I have read over the wiki article 3.2, 3.4 and the eigenvalues ($\lambda$ ) are hinted at as the roots, but I'm still not sure why these must be eigenvalues of some matrix, say $A_0$, and what the meaning of $A_0$ may be. It seems that to solve a homogeneous linear difference equation we find the ""characteristic polynomial"" by simply factoring one difference equation. However, typically to find the ""characteristic polynomial"" I would solve the characteristic equation for some matrix, $A_0 = \begin{pmatrix} 1 & 0 & 0\\ 
0 & -2 & 0  \\ 
0 & 0 & 3  \\  
\end{pmatrix}$ $(A_0 - \lambda I)\mathbf x = \mathbf 0$, then solve for the determinant equal to $0$, and then solve for each $\lambda$ e.g. $ \det(A_0 - \lambda I)  = 0$ $(1 - \lambda)(2 + \lambda)(3 - \lambda) = 0$ Now suppose this also happens to be a solution to some linear difference equation, and so here the characteristic polynomial is $\lambda^3 - 2\lambda^2 - 5\lambda + 6 = 0$, and the difference equation is. 
$y_{k+3} - 2y_{k+2} - 5y_{k+1} + 6y_k = 0 $. Then, for example, $\lambda = 3$ is a solution for all k. Now, given we have found this solution to this difference equation, how can we explain some special relationship to $A_0$, other than $\lambda = 3$ happens to be an eigenvalue of $A_0$? Is there any meaning to make of $A_0$? (cf. 4.8, Linear Algebra 4th, D. Lay )","['linear-algebra', 'eigenvalues-eigenvectors', 'recurrence-relations']"
178828,show that $x_n$ converges and find the limit,"Let $\left\{ x_n \right\}_{n\geq0}$ be a sequence of real numbers such that $$x_{n+1}=\lambda x_n+(1-\lambda)x_{n-1},\ n\geq 1,$$for some $0<\lambda<1$ (a) Show that $x_n=x_0+(x_1-x_0)\sum_{k=0}^{n-1}(\lambda -1)^k$ (b) Hence, or otherwise, show that $x_n$ converges and find the limit. Note that $x_{n+1}=\lambda x_n+(1-\lambda)x_{n-1}$$$=>x_{n+1}-x_n=(\lambda-1)(x_n-x_{n-1})=\cdots=(\lambda-1)^n(x_1-x_0),\forall n$$ Hence we get $x_n-x_0=(x_n-x_{n-1})+(x_{n-1}-x_{n-2})+\cdots+(x_1-x_0)=(\lambda-1)^{n-1}(x_1-x_0)+(\lambda-1)^{n-2}(x_1-x_0)+\cdots+(x_1-x_0)=(x_1-x_0)\sum_{k=0}^{n-1}(\lambda -1)^k.$ Help me in convergence part.","['convergence-divergence', 'sequences-and-series']"
178830,Cross-product technique to find the eigenspaces of a $3\times 3$ matrix,"$1)$ For each distinct real eigenvalue $\lambda$ of a $3 \times 3$ matrix $A$, it turns out that the cross product of the transpose of any two linearly independent rows of $A-\lambda I$ gives a corresponding eigenvector (and thus easily the corresponding eigenspace, since in this case the eigenspace is an eigenline). But why does this method work? $2)$ I think the above may be generalisable to any $3\times 3$ matrix with only real eigenvalues: Substitute an eigenvalue of $A$ into $A-\lambda I$. Then take the cross products of the transpose of any two pairs of rows of $A-\lambda I$. Only two possibilities exist: $(a)$ If only one is nonzero, that gives a corresponding eigenvector and hence easily the eigenspace. ($b$)If both are zero, then the eigenspace is the plane orthogonal to any row of $A-\lambda I$. Is this generalisation valid, and if so, why does the method work? $3)$ How about for the final case whereby $2$ complex eigenvalues exist??","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
178833,Karatsuba Multiplication,Karatsuba's equation to reduce the amount of time it takes in brute force multiplication is as follows (I believe this is a divide-and-conquer algorithm): $$ x y = 10^n(ac) + 10^{n/2}(ad + bc) + bd $$ My question is this. Where did the $10^{n/2}$ and $10^n$ come from? Thanks,"['recursive-algorithms', 'arithmetic', 'discrete-mathematics', 'algorithms']"
178837,What is the chance of an event happening a set number of times or more after a number of trials?,"Assuming every trial is independent from all the others and the probability of a successful run is the same every trial, how can you determine the chance of a successful trial a set number of times or more? For example, You run 20 independent trials and the chance of a ""successful"" independent trial each time is 60%. how would you determine the chance of 3 or more""successful"" trials?",['statistics']
178843,Eisenstein Series and cusps of $\Gamma_{1}(N)$,"Let $q = e^{2\pi i\tau}$, $\operatorname{Im}\tau > 0$ and let $$G(\tau) = 1 - 24\sum_{n = 1}^{\infty}\frac{nq^{n}}{1 - q^{n}}$$ be the weight 2 Eisenstein series for $\Gamma(1)$. Consider the inequivalent cusps of $\Gamma_{1}(N)$. For each cusp, there is an Eisenstein series of weight 2 associated to this cusp. How does one relate this Eisenstein series to a linear combination of $G(k\tau)$'s (for some integers $k$)? In particular, the case I am considering is when $N = 7$. The inequivalent cusps are $0$, $2/7$, $1/3$, $3/7$, $1/2$, and $\infty$. Consider the cusp $2/7$ and denote by $E_{2/7}$ the associated Eisenstein series. I would like to write $E_{2/7}$ as a finite sum of $G(k\tau)$ for some integers $k$. One of the first issues I'm having is how would I know the $q$-expansions of Eisenstein series of $E_{2/7}$ (which is related to the issue that I can't seem to find a good reference for the definition of a weight 2 Eisenstein series associated to a cusp)? Second, would finding the desired linear combination of $G(k\tau)$'s be just an exercise in matching up finitely many coefficients in the $q$-expansion?","['sequences-and-series', 'modular-forms', 'number-theory']"
178851,Classifing groups of order 56: problems with the semidirect product,"While I was doing an exercise about the classification of groups of order 56, I had some problems concerning the semidirect product. Let $G$ a group of order 56 and let us suppose that the 7-Sylow is normal (let's call it $H$). Then we want to construct the non abelian group whose 2-Sylow $S$ is $S \cong \mathbb Z_8$. First of all, we have to determine the homomorphism $\phi \colon \mathbb Z_8 \to \text{Aut}(\mathbb Z_7)$. 
It is known that $\text{Aut}(\mathbb Z_7) \cong \mathbb Z_6$ and the isomorphism is given by
$$
\begin{split}
& \mathbb Z_6 \to \text{Aut}(\mathbb Z_7) \\
& a \mapsto \psi_a \colon \mathbb Z_7 \ni n \mapsto an \in \mathbb Z_7
\end{split}
$$ So we can start by finding the homomorphism $\mathbb Z_8 \to \mathbb Z_6$. There are exacly $(6,8)=2$ such homomorphism. Who are they? Simply the one who sends everything to $0$ and the multiplication by $3$ (which is the only element in $\mathbb Z_6$ whose order - 2 - divides 8). In multiplicative terms, they are the homomorphism which sends everything to $1$ and the homomorphism which sends $n \mapsto 6^n=(-1)^n$. So, by composition, we have the two homomorphism 
$$
\begin{split}
\phi_1 \colon & \mathbb Z_8 \to \text{Aut}(\mathbb Z_7)\\
& n \mapsto \text{id}
\end{split}
$$
and
$$
\begin{split}
\phi_2 \colon & \mathbb Z_8 \to \text{Aut}(\mathbb Z_7)\\
& n \mapsto \psi_n \colon \mathbb Z_7 \ni x \mapsto 6^nx = (-1)^nx \in \mathbb Z_7 
\end{split}
$$ Am I right? Now, if we take $\phi_1$ we simply get the direct product. What if we take $\phi_2$? For sake of simplicity, let's assume additive notation (this is stupid, I know but it has helped me somehow to understand). If I'm not wrong, we obtain that $H \rtimes_{\phi_2} \mathbb Z_8$ is the set $H \times \mathbb Z_8$ with the operation given by 
$$
(a,b) + (c,d) = (a+(-1)^bc,b+d)
$$ Now if I do $(0,k)+(h,0)-(0,k) = ((-1)^k h, 0) = \phi_k(h)$ which is exactly what I want. Now I must pass to the much more confortable multiplicative notation: so let's $C_7=\langle s \rangle$ and $C_8=\langle r \rangle$ be the cyclic groups of order 7 and 8. Then we define the automorphisms 
$$
\begin{split}
\phi_n \colon & C_7 \to C_7 \\
& x \mapsto x^{(-1)^n}
\end{split}
$$
and the homomorphism 
$$
\begin{split}
\psi \colon & C_8 \to \text{Aut}(C_7) \\
& n \mapsto \phi_n
\end{split}
$$ In other words, we can simply say that $\psi$ is the homomorphism which sends the generator $r$ to the inversion $x^{-1}$. Am I right so far? Well, now $C_7 \rtimes_{\psi} C_8$ is the set $C_7 \times C_8$ with the operation given by 
$$
(a,b)(c,d) = (ac^{(-1)^b},bd)
$$ I do again the calculation $(1,k)(h,1)(1,k)^{-1}=(h^{(-1)^k},1) = \phi_k(h)$ which is exactly what I want (also according to ineff's answer). Are there any mistakes? 
May I ask one more question? Who is this mysterious group I've built up? Is it isomorphic to some other (simpler) group? How can I do to write down a presentation? I thank you in advance for your kind help.","['finite-groups', 'group-theory', 'abstract-algebra']"
178854,Is every nilpotent linear group triangularizable?,"Is it true that every finitely generated nilpotent group of matrices over $\mathbb C$ is conjugated to a subgroup of the upper triangular group? If yes, what is a reference for that?","['linear-algebra', 'group-theory', 'abstract-algebra']"
178864,Area of a polygon [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: How quickly we forget - basic trig. Calculate the area of a polygon Calculate area of a figure based on vertices I saw a formula in a book,
$$\mathrm{area}=\frac{1}{2}\left|\sum_{i}(x_iy_{i-1}-x_{i-1}y_i)\right|.$$
Where $x_iy_i$ are the vertices of the polygon. Since it was an exercise in the book (no proof) I would very much like to see a proof, or maybe an outline? I can't come up with anything. This is no homework, I just got very curious and wanted to know.",['geometry']
178865,“locally” operator in “locally path-connected space”,"For any property p of topological spaces, p implies locally p. topospaces.subwiki.org. Locally operator Locally path-connected space … This property is obtained by applying
  the locally operator to the property: path-connected space topospaces.subwiki.org. Locally path-connected space This space is obviously path-connected, but it is not locally
  path-connected math.stackexchange.com This seems like a contradiction.",['general-topology']
178871,Is $\sin\left(\frac{\pi}{2}\sin\left(\frac{\pi}{2}\cdots\sin x\cdots\right)\right)=\frac4{\pi}\sum\limits_{k=0}^\infty\frac{\sin(2k+1)x}{2k+1}$?,"We can see intuitively that
$$
f(x)=\sin\left(\frac{\pi}{2}\sin\left(\frac{\pi}{2}\sin\left(\frac{\pi}{2}\cdots\sin{x}\cdots\right)\right)\right)
$$
is the square wave with period $2\pi$ and has the value $0$ at the jumps, i.e
$$
f(x)=
\begin{cases}
0 & \text{if } \frac{x}{\pi}\in\mathbb{Z}\\
\mathrm{sign}(\sin{x}) & \text{otherwise}
\end{cases}
$$
Look at this graph of $x$ and $\sin{\frac{\pi}{2}x}$ to see why : But $f(x)$ is then also exactly equal to the Fourier series of the square wave with period $2\pi$ since Dirichlet conditions assure that the series converges to $0$ (the midpoint) at the jumps as do $f(x)$. Hence we might be able to show that, 
$$
\sin\left(\frac{\pi}{2}\sin\left(\frac{\pi}{2}\sin\left(\frac{\pi}{2}\cdots\sin{x}\cdots\right)\right)\right)=\frac{4}{\pi}\sum_{k=0}^{\infty}\frac{\sin{(2k+1)x}}{2k+1}
$$ Does anyone have an idea of how to prove this directly? Are there other Fourier series that are equal to a recursive formula of trigonometric functions? Restated, the problem is to show that if
$$
f_0(x)=\sin{x},\quad\text{and}\quad f_n(x)=\sin{\left(\frac{\pi}{2}f_{n-1}(x)\right)}
$$
then,
$$
\lim_{n\to\infty}{f_n(x)}=\frac{4}{\pi}\sum_{k=0}^{\infty}\frac{\sin{(2k+1)x}}{2k+1}
$$","['fourier-series', 'recurrence-relations', 'sequences-and-series']"
178877,"Eigenvalues, singular values, and the angles between eigenvectors","Suppose the $n \times n$ matrix $A$ has eigenvalues $\lambda_1, \ldots, \lambda_n$ and singular values $\sigma_1, \ldots, \sigma_n$. It seems plausible that by comparing the singular values and eigenvalues we gets some sort of information about eigenvectors. Consider: a. The singular values are equal to the absolute values of eigenvalues if and only if the matrix is normal, i.e., the eigenvectors are orthogonal (see http://en.wikipedia.org/wiki/Normal_matrix , item 11 of the ""Equivalent definitions"" section ). b. Suppose we have two distinct eigenvalues $\lambda_1, \lambda_2$ with eigenvectors $v_1, v_2$. Suppose, hypothetically, we let $v_1$ approach $v_2$, while keeping all the other eigenvalues and eigenvectors the same. Then the largest singular value approaches infinity. This follows since $\sigma_{\rm max} = ||A||_2$ and $A$ maps the vector $v_1 - v_2$, which approaches $0$, to $\lambda_1 v_1 - \lambda_2 v_2$, which does not approach $0$. It seems reasonable to guess that the ``more equal'' $|\lambda_1|, \ldots, |\lambda_n|$ and $\sigma_1, \ldots, \sigma_n$ are, the more the eigenvectors look like an orthogonal collection.  So naturally my question is whether there is a formal statement to this effect.",['linear-algebra']
178880,Local solutions of a Diophantine equation,"I am trying to prove that the equation
$$3x^3 + 4y^3 +5z^3 \equiv 0 \pmod{p}$$
has a non-trivial solution for all primes $p$.
I am sure that this is a standard exercise, and I have done the easy parts: treating $p=2, 3, 5$ as special cases (very simple), and then for $p\geq 7$, those for which $p \equiv 2 \pmod{3}$ is also straightforward, as everything is a cubic residue $\pmod{p}$, but I am having a mental block about the remaining cases where $p \equiv 1 \pmod{3}$ and only $(p-1)/3$ of the integers $\pmod{p}$ are cubic residues. I was hoping to be able to show that the original equation has non-trivial solutions in $\mathbb{Q}_p$, and that this might be an easy first step towards the $p$-adic case. Any pointers, or references to a proof (I am sure there must be some in the literature) would be most gratefully received.","['diophantine-equations', 'p-adic-number-theory', 'number-theory']"
178881,Example of a meromorphic function in $\mathbb{C}$ but not in $\mathbb{C}_{\infty}$,"I need to produce an example of a meromorphic function on $\mathbb{C}$ but not meromorphic on the Riemann sphere $\mathbb{C}_{\infty}$.
Will this work: $f(z)=e^z-1/z$?
Other examples are welcome. Thank you.",['complex-analysis']
178888,A Hölder norm bound that I need help with,"Define the seminorm on the space $S=[0,1]\times[0,T]$
$$[u]_{\alpha} = \sup\frac{|u(x, t) - u(y,s)|}{(|x-y|^2 + |t-s|)^{\frac{\alpha}{2}}}.$$
Define the norms on the same space
$$\lVert u \rVert_{C^{0, \alpha}} = \lVert u \rVert_{C^0} + [u]_{\alpha}$$
and
$$\lVert u \rVert_{C^{2, \alpha}} = \lVert u \rVert_{C^0} +\lVert u_x \rVert_{C^0}+\lVert u_{xx} \rVert_{C^0}+\lVert u_t \rVert_{C^0}+ [u_{xx}]_{\alpha} + [u_t]_{\alpha}.$$ I want to show that $[u_x]_\alpha \leq C\lVert u \rVert_{C^{2, \alpha}}$ where $C$ doesn't depend on $u_{xt}$. Does anyone have any hints how to do this? I tried using the MVT but that gives me a $u_{xt}$ which I can't bound above. Or is there something I can do with $u_{xt}$? Alternatively, is there anything I can do (as in bound above) with
$$\sup\frac{|u_x(x, t) - u_x(x,s)|}{|t-s|^{\frac{\alpha}{2}}}?$$ I can't seem to avoid getting a mixed derivative $u_{xt}$ here. Thanks for any help. ADDED: $u$ solves the equation
$$u_t = a_1u_{xx} + b_1u_x + c_1u + (f_1 + a_2v_{xx} + b_2v_x + c_2v)$$
where $v$ solves $$v_t = a_3v_{xx} + b_3v_x + c_3v + f_3$$ and the $a_i$, etc, are functions of $(x,t)$ in $C^{0, \alpha}$.","['holder-spaces', 'functional-analysis']"
178896,"Proof: $X\ge 0, r>0\Rightarrow E(X^r)=r\int_0^{\infty}x^{r-1}P(X>x)dx$","As the title states, the problem at hand is proving the following: $X\ge 0, r>0\Rightarrow E(X^r)=r\int_0^{\infty}x^{r-1}P(X>x)dx$ Attempt/thoughts on a solution I am guessing this is an application of Fubini's Theorem, but wouldn't that require writing $P(X>x)$ as an expectation? If so, how is this accomplished? Thoughts and help are appreciated.","['probability-theory', 'expected-value', 'probability']"
178898,"Characteristic functions of random variables (Poisson, Gamma, etc.)","My self-study in measure and probability theory as finally brought me to the subject of characteristic functions, and I have not handled these in the past with any rigor at all, so all of this is somewhat daunting. Problem: To find explicitly the characteristic function for each of these situations: $X$~Poisson$(\lambda)$ $Y$~Gamma$(\alpha,\beta)$ $Z$~$U_1+U_2+...+U_n$ where each $U_n$ is ~Uniform(-1,1) (additionally, can this example be used in Levy's inversion formula if $n\ge 2$ to have a completely real-valued integral? Work/attempts at solution For $X$: $\phi_X(t)=E[e^{itX}]=\sum[e^{it}]^xe^{-\lambda}\frac1{x!}\lambda^x=e^{-\lambda}\sum_{x=0}^{\infty}\frac{(\lambda e^{it})^x}{x!}=e^{-\lambda}e^{\lambda e^{it}}=e^{\lambda e^{it-1}}$ I'm not completely sure on this, but it seems reasonable. I am pretty stuck on the gamma distribution and am largely clueless on the sum of uniform RVs part.","['probability-theory', 'characteristic-functions', 'random-variables']"
178905,Combinations of characteristic functions: $\alpha\phi_1+(1-\alpha)\phi_2$,"Suppose we are given two characteristic functions: $\phi_1,\phi_2$ and I want to take a weighted average of them as below: $\alpha\phi_1+(1-\alpha)\phi_2$ for any $\alpha\in [0,1]$ Can it be proven that the result is also a characteristic function? If so, I am guessing this result could extend to any number of combinations $\alpha_i$ as long as $\sum_i\alpha_i=1$ Secondly, if $\phi$ is again a characteristic function, then $\mathfrak{R}e\phi(t)=\frac12(\phi(t)+\phi(-t))$ is also a characteristic function. I don't even know how to begin attempting this proof as I am not sure what the $\mathfrak{R}$ represents. Lastly, regarding the symmetry of characteristic functions, $\phi$ is symmetric about zero iff it is real-valued iff the corresponding distribution is symmetric about zero. Once again, my lack of familiarity with the complex plane leaves me in the dark here. Why can a complex-valued function not be symmetric about zero?","['probability-theory', 'measure-theory', 'probability-distributions', 'characteristic-functions']"
178921,Space of Complex Measures is Banach (proof?),"How can we prove that the space of Complex Measures is Complete? with the norm of Total Variation.
I have stuck on the last part of the proof where I have to prove that the limit function of a Cauchy sequence of measures has the properties of Complex measures. We are using the norm of total variation :$$\lVert \mu\rVert = \lvert \mu \rvert(X)$$","['measure-theory', 'functional-analysis', 'real-analysis', 'banach-spaces']"
178926,"What does the following notation mean: $\Bbb Q[x,y]$?","I came across this notation while at this MathOverflow thread and I could not find its meaning. It makes the biggest sense that $f(x,y) \in \Bbb Q[x,y] $ represents any continuous function on the interval $[x,y] \in \Bbb Q$ and thus $\Bbb Q[x,y]$ is a set of such functions.
However, I am not sure.","['notation', 'functions']"
178938,A Marcinkiewicz approach,"The problem was to prove the following that the operator $$Tf(x)=\int_{\mathbb{R}^N}\frac{f(y)}{|x-y|^\alpha}dy$$ Is continuous from $$L^1 \to \ L_\mathrm{Weak}^{p}$$ where $0<\alpha<N$ and $p=(N-\alpha)^{-1}$. I tried to use the Lorentz Space $$M^{q,\nu}(R^N)=L_\mathrm{Weak}^{\frac{p}{1-\nu}}(R^N)$$ but it didn't helped much.","['operator-theory', 'functional-analysis', 'analysis']"
178950,Showing that a set of trigonometric functions is linearly independent over $\mathbb{R}$,"I would like to determine under what conditions on $k$ the set $$ \begin{align}
A = &\{1,\cos(t),\sin(t), \\
&\quad \cos(t(1+k)),\sin(t(1+k)),\cos(t(1−k)),\sin(t(1−k)), \\
&\quad \cos(t(1+2k)),\sin(t(1+2k)),\cos(t(1−2k)),\sin(t(1−2k))\},
\end{align}$$
is linearly independent, where $k$ is some arbitrary real number. As motivation, I know that the set defined by $$
\{1, \cos wt, \sin wt\}, \quad w = 1, \dots, n
$$ is linearly independent on $\mathbb{R}$, which one generally proves by computing the Wronskian.  I thought that I could extend this result to the set in question, but I haven't found a proper way to do so.  My intuition tells me that $A$ will be linearly dependent when the arguments of the trig functions coincide, which will depend on the value of $k$. Though, I'm at a loss for proving this is true.  Computing the Wronskian for this set required an inordinate amount of time-- I stopped running the calculation after a day.  Is there perhaps a way to reduce the set in question so that the Wronskian becomes manageable? I'm interested in any suggestions/alternative methods for proving linear independence that could help my situation.  Note that I'd like to have a result that holds for any $m = 0, \dots, n,$ where $n \in \mathbb{Z}$ if possible. Thanks for your time. EDIT :  The set originally defined in the first instance of this post was incorrectly cited.  My sincere apologies.","['vector-spaces', 'linear-algebra']"
178964,Proof of infinitude of primes using the irrationality of π,"According to the section Proof using the irrationality of $\pi$ of the Wikipedia article on Euclid's theorem, Euler proved that: $$\frac{\pi}{4}=\frac34\cdot\frac54\cdot\frac78\cdot\frac{11}{12}\cdot\frac{13}{12}\cdots$$ where ""each denominator is the multiple of four nearest to the numerator"".
Can someone please explain this formula? I see it, but cannot believe it.","['prime-numbers', 'pi', 'number-theory']"
178971,Prove that the first positive root of the solution to the Lane-Emden equation increases steadily with $n$.,"Let $\lambda$ be the first positive value for which $y=0$ where $y(x)$ satisfy the following differential equation
$$
y''+\frac{2}{x}y'+y^n=0,\qquad\text{where }n\in\mathbb{R},\ y(0)=1,\text{ and }\ y'(0)=0.
$$
This equation is known as the Lane-Emden equation and has analytic solutions for $n=0,1,5$. For $n=0$, 
$$
y(x)=1-\frac{x^2}{6}\Rightarrow\lambda=\sqrt{6}
$$ For $n=1$, 
$$
y(x)=\frac{\sin{x}}{x}\Rightarrow\lambda=\pi
$$ And for $n = 5$, 
$$
y(x)=\frac{1}{\sqrt{1+\frac{x^2}{3}}}\Rightarrow\lambda=\infty
$$ We want to show that $\lambda$ increases steadily as $n$ goes from $0$ to $5$. We can verify numerically that it is indeed true but it has not yet been proved analytically.",['ordinary-differential-equations']
179000,Bézier approximation of archimedes spiral?,"As part of an iOS app I’m making, I want to draw a decent approximation of an Archimedes spiral . The drawing library I’m using ( CGPath in Quartz 2D , which is C-based) supports arcs as well as cubic and quadratic Bézier curves. What is a good method of approximating an Archimedes spiral using either of these path types? For example the wikipedia exemplar image says it was “drawn as a series of minimum-error Bézier segments.” How would one generate such segments? My math background takes me through Calculus III plus some stuff I picked up from a classical mechanics class, but it’s been a couple of years so I’m rusty. What I have so far: For a spiral r = a + b $\theta$, I used the information from this page to find that the cartesian slope at any point (r, $\theta$) is equal to $$\frac{dy}{dx}=\frac{b\sin\theta\space+\space(a + b\theta)\cos\theta}{b\cos\theta\space-\space(a + b\theta)\sin\theta}$$ From here, I could use point-slope to find the equation of a tangent line at any point, but how do I go about finding the proper lengths of the handles (i.e. the positions of the middle two points) for the curve? Or would an approximation with circular arc segments be better/easier/faster? If I can’t figure it out, I’ll just use a static image in the app, but it occurs to me that I don’t even know of a way to generate a high-quality image of an Archimedes spiral! The Spiral tool in Illustrator, for example, does only logarithmic spirals.","['geometry', 'plane-curves', 'polar-coordinates', 'bezier-curve', 'spline']"
179015,A question about probability,"I have met a interesting question: If today rains, the probability that tomorrow rains is $0.6.$ If today doesn't rain, the probability that tomorrow rains is $0.2.$ Given Tuesday rained, what's the probability that Monday rained? I have no idea how to solve this. If I make the question a bit more complicated:
Given Tuesday rain, what's the probability that the Sunday just before rained?",['probability']
179025,Compute $\lim_{x\to\infty} \frac{{(x!)}^{\frac{1}{x}-1} (x\Gamma(x+1) \psi^{(0)}(x+1)-x! \log(x!))}{x^2}$,"What's the strategy one may use when facing a limit like this one? I think it's more important to know the possible ways to go than the answer itself. It's a problem that came to my mind again when I was working on a different problem. $$\lim_{x\to\infty} \frac{{(x!)}^{\frac{1}{x}-1} (x\Gamma(x+1) \psi^{(0)}(x+1)-x! \log(x!))}{x^2}$$ Any suggestion, hint are very welcome.","['special-functions', 'calculus', 'real-analysis', 'limits']"
179041,Characterization of Rational Normal Curve,"Given a curve $C\subset P^n$ in projective space such that any $n+1$ points on $C$ are linearly independent. I've heard from multiple people that this implies that $C$ is a rational normal curve, some people said that one needs that $C$ is rational for that. I would like to know what precisely is true and how I can prove it, google is not my friend here... Thanks for your help!","['algebraic-geometry', 'algebraic-curves']"
179050,application of the maximum modulus theorem,"Let $f$ be holomorphic on the unit disc and continuous on the unit circle. Suppose there is an $M \in \mathbb{R}$ such that $|f(z)| \leq M$ on the unit circle and let $\alpha_1, \alpha_2, ..., \alpha_n$ be zeros of $f$ in the unit disc listed according to multiplicity. Show that $|f(z)| \leq M \frac{|z-\alpha_1| \cdots |z- \alpha_n|}{|1-z \overline{\alpha_1}| \cdots |1-z \overline{\alpha_n}|}$. Why can't I apply the Maximum Modulus theorem to $f$ directly? Is there something I am missing?",['complex-analysis']
179058,To show that a given process is Gaussian,"Suppose I have given a Brownian Motion $W$, this is a Gaussian process, and I define: $$B_s:=W_{t-s}-W_t$$ for $0\le s\le t$. Clearly this random variable has expectation zero. For the covariance function I did this: $$Cov(W_{t-s}-W_s,W_{t-r}-W_r) = (t-s)\wedge(t-r) - ((t-s)\wedge r)-((t-s)\wedge s) +(r\wedge s)$$ The first term is equal $r\vee s$. But how can I simplify the second and third one to get a covariance function $s\wedge r$? The last point which is to show is that $B_s$ is a Gaussian process. So let $t_0,\dots,t_n$ be given time points. I have to show that $(B_{s_0},\dots,B_{s_n})$ is multivariate normal distributed, that is equivalent to $$\sum_{i=0}^n a_i B_{s_i}$$ should be normal distributed for any scalars $a_i$. My idea was: Write $(B_{s_0},\dots,B_{s_n})$ as $(B_{s_0}-B_0,\dots,B_{s_n}-B_{t_{s-1}})$ using a linear transformation $\phi$ which is a $(n+1)$ matrix. Then the above equation leads to $$\sum_{i=0}^n a_i (W_{t-s_i}-W_{t})-a_i(W_{t-s_{i-1}}-W_{t})=\sum_{i=0}^na_i(W_{k_i}-W_{k_{i-1}})+\sum_{i=0}^n b_iW_t$$ where $k_i:=t-s_i$ and $b_i:=-2a_i$ and $W_{k_{-1}}:=W_0=0$ Am I correct that the first sum is normal distributed, since the increment are independent and they are also independent to $\sum_{i=0}^nb_i W_t$ hence the whole thing is normal distributed. Therefore $(B_{s_0},\dots,B_{s_n})$ is multivariate normal distributed, since this remains true under linear transformations. Are my thoughts correct? hulik","['probability-theory', 'brownian-motion']"
179067,Prove that: $\lim_{n\to\infty} f(n+1) - f(n) = \lim_{x\to\infty} (f(x))' $,"I conjecture that in some specific conditions a differentiating function gives the following equality:
$$\lim_{n\to\infty} f(n+1) - f(n) = \lim_{x\to\infty} (f(x))' $$ However, I'm not sure yet what exactly those conditions are in order to precisely know where I may apply this rule or not. If you wanna take a look over my posted problem here you'll immediately notice that this rule applies for that case. I really appreciate if you help me clarify this.","['calculus', 'real-analysis', 'limits']"
179088,showing a function defined from an integral is entire,"Let $f$ be a continuous complex-valued function on the unit interval. For any complex number $z$, define $F(z)=\int _0 ^1 f(t) e^{zt} dt$. How do I show that $F$ is entire?",['complex-analysis']
179117,the measure of a set..,"$C(n)$  is defined as the set that remains after removing from $[0, 1]$ an open interval of length 1/n centered at 1/2, then an open interval of length $1/n^2$ from the center of each of the two remaining intervals, then open intervals of length $1/n^3$ from the centers of each of the remaining $4=2^2$ intervals, and so on. How would I show that the measure of $C(n)$ is $\frac{n-3}{n-2}$? Any hints greatly appreciated: By drawing out examples for small n, I would think that the measure is 0 since we are continuously removing open intervals and keeping the endpoints. I also see that C(3) = 0 since C(3) is the Cantor set.","['measure-theory', 'real-analysis']"
179129,How to integrate $\frac{1}{\sqrt{1+x^2}}$ using substitution?,How you integrate $\frac{1}{\sqrt{1+x^2}}$ using following substitution? $1+x^2=t$ $\Rightarrow$ $x=\sqrt{t-1} \Rightarrow dx = \frac{dt}{2\sqrt{t-1}}dt$... Now I'm stuck. I don't know how to proceed using substitution rule.,"['substitution', 'integration', 'indefinite-integrals']"
179143,Convex Polyhedron: How many corners maximum?,"How many corners can a $n$-dimensinal convex polyhedron have at tops? Is it the same as the number of corners a $n$-dimensional simplex has? EDIT:
By polyhedron $P$, I mean, that for some matrix $A \in \mathbb{R}^{m,n}$, $P = \{ x\in \mathbb{R}^n \mid A x \leq b\}$ where $Ax \leq b$ is meant as $a_i^T x \leq b$.
An alternative charakterization would be $P = \cap_{H \text{ is hyperplane}} H_{+}$, where $H_{+}$ is the half-room $\{x \in \mathbb{R}^n \mid \langle x, u \rangle \geq b\}$.
ADDED convex","['geometry', 'polytopes', 'combinatorics']"
179153,Shifting a function is continuous,"I'm slightly puzzled by the following: if $g(t)$ is a function in $L^q(X)$ then we can show that $g(t-x)$ is continuous function of $t$, i.e. for $\varepsilon > 0$ we can find $\delta$ such that $d(x,y)<\delta$ implies $\|g(t-x) - g(t-y)\|_q < \varepsilon$. But $g$ is not necessarily continuous. Is this result stating something like $g$ is continuous with respect to norm $\|\cdot\|_q$? Because if $\tau_x$ is translation by $x$ then $g(t-x) = g \circ \tau_x$ is not necessarily continuous. When continuous I mean in topology on $X$ (e.g. $X \to \mathbb R$). Does this sort of continuity have a name?","['measure-theory', 'harmonic-analysis', 'real-analysis', 'banach-spaces', 'locally-compact-groups']"
179156,Understanding a theorem concerning Sobolev spaces,"I have two doubts in the proof of the theorem below. If you want the detaIls can be found here . Theorem A Let $q$ a given real number $q>p$. Let $u \in W^{1,p}$ be a solution to (E2). Assume  that (H1) holds. Then there exists $\varepsilon_0>0, \varepsilon_0(q)$, such that if (H2) holds for some $0 < \varepsilon < \varepsilon_0$, then $u \in W^{1,q}$. Given $q>p$ we study  when $g\equiv M(| \nabla u|) \in L^{q/p}$ by standards arguments of measure theory, $g \in L^{q/p}$ if \begin{equation} 
\sum_{k=1}^{\infty} A^{kq/p}w_g(A^{k}\lambda_0)< \infty, \tag{1}
\end{equation}
where $w_g$ is the distribution function of g. Now take $A,\delta$ and the corresponding $\varepsilon>0$ given by lemma 1.3; by lemma 1.2 we obtain that $w_g(A\lambda_0) \le \delta w_g(\lambda_0) $ and by recurrence $w_g(A^k\lambda_0) \le \delta^k w_g( \lambda_0)$. (My Ask)Then the candidate to $\varepsilon_0(q)$ is $\varepsilon=\varepsilon(\delta)$ given by lemma 1.3. But what fixed $0<\delta<1$? To apply the lemma 1.2 we need that i) $w_g(A \lambda_0)< \delta|Q´|$ where $w_g(t) = |\{x \in Q':|g(x)|>t\}|$ and $Q'$ is such that we hope obtain $g \in L^{q/p}$ in $Q'$ and ii) below, but by lemma 1.3 ii)holds only to dyadic cubes $Q_k \subset \overline{Q_k} \subset \dfrac{1}{4}Q$ from $Q$. To answer this, I think that is because we want to obtain local results, then we can consider $Q'$ such that the dyadic cubes $Q_k \subset \overline{Q_k} \subset \dfrac{1}{4}Q$ be also dyadic cubes from $Q'$. Am I right here?. Then by (1)
implies that
$$ \sum_{k=1}^{\infty} A^{kq/p}w_g(A^{k}\lambda_0) \le w_g(\lambda_0)\sum_{k=1}^{\infty} A^{kq/p} \delta^k.$$
We need that $\delta A^{q/p}<1$. If $M(|\nabla u|^p)\in L^{q/p}$ a fortiori $\nabla u \in L^q$. 2. (Ask) We need $\delta <<1$ to obtain $\delta A^{q/p}<1$, but $\delta$ satisfies $ w_g(A\lambda_0) < \delta |Q´|$. Is not clear for me that we can choose $Q',\lambda_0$ that we can find $\delta$ such that $\delta A^{q/p}<1$ and $w_g(A\lambda_0) < \delta |Q´|$. Lemma 1.2: Let $Q$ be a bounded cube in $\mathbb{R}^{N}$. Assume that $A$ and $B$ are measurable sets, $A \subset B \subset Q$, and that there exists a $\delta>0$ such that i) $|A| < \delta|Q|$ and ii) for each $Q_k$ dyadic cube obtained from $Q$ such that $|A \cap Q_k|> \delta_k$, its predecessor $\tilde{Q}_k \subset B$. Then $|A|< \delta|B|$. Lemma 1.3 Assume (H1) holds. Let $u \in W^{1,p}$ be a solutin to (E2) in $Q$. Denote by $A = \max(2^{N},2^{p+1}B\}$ with $B$ as in (H1). Then for $0<\delta<1$ fixed, there exist an $\varepsilon= \varepsilon(\delta)>0$ such that if hjypothesis (H2) holds for such $\varepsilon$, and $Q_k \subset \overline{Q_k} \subset \dfrac{1}{4}Q$ satisfies
  \begin{equation} 
|Q_k \cap \{x :M(\nabla u|^{p}) < A \lambda| > \delta |Q_k|,
\end{equation}
  the predecessor $\overline{Q}_k$ satisfies $\overline{Q}_k \subset \{x:M(|\nabla u|^{p}) > A \lambda\}.$ Remark: $A$ does not depend on $Q$.","['sobolev-spaces', 'measure-theory', 'partial-differential-equations']"
179158,How to introduce stress tensor on manifolds?,"I want to understand the type of stress tensor $\mathbf{P}$ in classical physics. Usually in physics it is said that the force $\text d \boldsymbol F$ (vector) acting on an infinitesimal area $\text d \boldsymbol s$ (vector) equals $\text d \boldsymbol F = \mathbf{P} \cdot \text d \boldsymbol s$ where $\cdot$ is a ""scalar product"". How can it be rigourised? I guess directed area can be $\star s$ where $s$ is a 2-form, but can I avoid using $\star$ by employing the volume form for example? The force should be 1-form. How is the power of surface forces is written? Usually it is given by $$\frac{dA}{dt} = \int_S \boldsymbol v \cdot \text d \boldsymbol F$$ $\boldsymbol v$ being the speed of the surface of the deformed body. What would be the corresponding local form, that is the power density of surface forces? UPDATE 1 If it helps, I found a whole appendix ""The Classical Cauchy Stress Tensor and Equations of Motion"" in the book ""The Geometry of Physics: An Introduction"" by Theodore Frankel. Particularly it says The Cauchy stress should be a vector-valued pseudo-$(n - 1)$-form. However currently I don't know what does it mean. Further development in the book is rather obscure and I'm afraid of that ""pseudo"". If a thing called ""pseudo-something"" I would prefer it stated as ""actual another thing"". UPDATE 2 Stress tensor can also be viewed as a (molecular) flux of momentum. Then the equation for balance of momentum would be the Newton's second law. Probably this approach would be more fruitful, analogues can be made with the flux of density.","['physics', 'differential-geometry', 'manifolds', 'tensors', 'classical-mechanics']"
179162,Inclusion-exclusion principle problems,"I've got huge problems with inclusion-exclusion principle. I know the formula, but always don't know how to use it, how to denote all the things. Hope it will pass when I do some excercises. I stuck with these two: How many are $8$ -digit numbers (without $0$ at any position) that don't have subsequence $121$ ? Find the number of permutations of the set: $\left\{1,2,3,4,5,6,7\right\}$ , that don't have four consecutive elements in ascending order. And here are my propositions for solutions: On the whole, there are $9^8$ numbers this kind. Let think about numbers that have at least one subsequence: $121$ . We choose place for first $1$ of this subsequence. There are six possibilities. After choosing place for $1$ we set $21$ after this digit, and the rest of digits are with no restrictions. So we have $6\cdot 9^5$ numbers with at least one subsequence $121$ , so numbers without this subsequence are $9^8-6\cdot 9^5$ . Is that correct? Let $X$ be a set of all permutations of a given set. $|X|=7!$ . Let $A_i$ be a set of permutations that have numbers: $i, \ i+1, \ i+2, \ i+3$ consecutive in ascending order. In other words they have subsequence of this form. Hence $|A_i|=4\cdot 3!$ , because we choose one of $4$ places for $i$ and the rest $3$ of digits are with no restrictions. Another observation is that for $i_1<...<i_k$ we have $\displaystyle |A_{i_1}\cap ... \cap A_{i_k} |=(3-i_k+i_1) \cdot (3-i_k+i_1)!$ which is that simple only because the set is $\left\{1,2,3,4,5,6,7 \right\}$ . $A_{i_1}\cap ... \cap A_{i_k}$ is a set of permutations that have subsequence: $i_1,...,i_k,...,i_{k+3}$ so we choose place for $i_1$ , set this subsequence starting from this place and permuting the rest of digits. By the way I'm wondering if it was possible to solve this problem in general, I mean if the set was of the form $\left\{1,..,n \right\}$ for any natural number $n$ ? Back to problem. Now, what I want to count is, by exclusion-inclusion principle, this sum: $\displaystyle \sum_{k=0}^{4}(-1)^kS_k$ , where $\displaystyle S_k=\sum_{i_1<...<i_k\le 4}|A_{i_1}\cap ... \cap A_{i_k}|$ , and $S_0=|X|$ . The last observation: $A_{i_1}\cap ... \cap A_{i_k}=A_{i_1}\cap A_{i_k}$ (which again wouldn't be so easy in general unfortunately) and let's do it: $$\sum_{k=0}^{4}(-1)^kS_k=|X|-|A_1|-|A_2|-|A_3|-|A_4|+|A_1\cap A_2|+|A_1\cap A_3|+|A_1\cap A_4|+|A_2\cap A_3|+|A_2\cap A_4|+|A_3\cap A_4|-|A_1\cap A_2\cap A_3|-|A_1\cap A_2\cap A_4|-|A_1\cap A_3\cap A_4|-|A_2\cap A_3\cap A_4|+|A_1\cap A_2\cap A_3\cap A_4|=\\=|X|-|A_1|-|A_2|-|A_3|-|A_4|+|A_1\cap A_2| + |A_2 \cap A_3|+|A_3\cap A_4|= \\ =7!-4\cdot 4\cdot 3! + 3\cdot 2\cdot 2!=4956$$ Is that correct? I'm afraid not :-( While waiting for answer I'll write a program that counts these permutations and check if it is a good answer. I would be very grateful for any help, answering my questions, any advices and hints about this type of problems. I really want to finally understand this principle. Regards","['inclusion-exclusion', 'combinatorics']"
179181,Cauchy's Integral Theorem,"I am trying to understand Cauchy's Integral Theorem which states $$
\int_\gamma f(z)\,dz = 0.
$$ If function $f(z)$ is holomorphic (has no singularities) within the area contained by the contour $\gamma$. I understand the proof comes from Green's theorem, but I don't understand conceptually why this is true. What exactly does the complex contour integral measure? It's not area, is it?",['complex-analysis']
179199,Why does this function converges almost everywhere and not pointwise?,"I am working on the following question. I believe I am almost done, but I still have a hole in my solution: Let $\{r_k\}_{k=1}^{\infty}$, a counting of $\mathbb{Q}$. For every $k \in \mathbb{N}$, let: $$ f_k(x):= \begin{cases}  (x - r_k)^{-1/2} &\text{ if } r_k < x \leq r_k + 1 \\   0 &\text{ else } \end{cases} $$ Prove that $\sum_{k = 1}^{\infty} 2^{-k}f_k$ converges almost
   everywhere on $\mathbb{R}$ to an integrable function, $f$, such that
   for every interval $(a, b)$, and every M,  $$ m((a,b) \cap \{x:f(x) \geq M\}) > 0. $$ My question is why does $\sum_{k = 1}^{\infty} 2^{-k}f_k$ converges to $f$ almost everywhere and not simply pointwise? This is what I have so far: $\frac{1}{\sqrt{x}}$ is integrable, hence $f$ is integrable (because its integral on $(0,1)$ equals 2, and $f$'s integral on $\mathbb{R}$ is $2 \times \sum_{k = 1}^{\infty} 2^{-k} < \infty$ by monotone convergence). For every $(a, b)$ there's a $k$ such that $r_k \in (a,b)$, and there is a $\delta$ such that for every $x \in (0, \delta)$, $\frac{1}{\sqrt{x}} > M\times 2^{-k}$ and from this follows the second claim.","['measure-theory', 'real-analysis']"
179205,Evaluate $\lim\limits_{n\to \infty}\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{6n}$,Show that $$\lim_{n\to \infty}\left(\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{6n}\right)=\log 6$$ Here I need to use the definition of integral but I  faced problem in range . Please help.,"['integration', 'limits']"
179221,Roots of a cubic mod prime,"For which primes $p$ is there a root to the equation $x^3+x^2-2x-1$ mod $p$? I have no idea where to start, any help is appreciated! Thank you",['number-theory']
179224,How to show x and y are equal?,"I'm working on a proof to show that f: $\mathbb{R} \to \mathbb{R}$ for an $f$ defined as $f(x) = x^3 - 6x^2 + 12x - 7$ is injective. Here is the general outline of the proof as I have it right now: Proof: For a function to be injective, whenever $x,y \in A$ and $x\neq y$, then $f(x) \neq f(y)$, i.e., where $A$, $B$ are finite sets, every two elements of $A$ must have distinct images in $B$, which also implies that there must be at least as many elements in $B$ as in $A$ such that the cardinality of $A$ is less than or equals the cardinality of $B$. We shall prove the contra-positive: If $\exists$ $f(x) = f(y)$, then $x=y.$ Let $x^3 - 6x^2 + 12x - 7 = y^3 - 6y^2 + 12y - 7$. Then by addition and some algebra, we get $x(x^2 - 6x + 12) = y(y^2 - 6y + 12)$ This feels dumb to ask but how do I continue to finally get the result that $x = y$?","['algebra-precalculus', 'functions']"
179249,Compute the limit of $\sqrt{1-a}\sum\limits_{n=0}^{+\infty} a^{n^2}$ when $a\to1^-$,"I need some suggestions, hints for the limit when $a \to 1^{-}$ of $$\sqrt{\,1 - a\,}\,\sum_{n = 0}^{\infty}a^{n^{2}}.$$","['calculus', 'real-analysis', 'limits']"
179255,Evaluate the triple integral.,"Evaluate the triple integral of $x=y^2$  over the region bounded by $z=x$, $z=0$ and $x=1$  My order of integration was $dx\:dy\:dz$. I want to calculate the volume of this surface. I solved it for $dz\:dy\:dx$ and it was: $$V=\int_0^1\int_{-\sqrt{x}}^{\sqrt{x}}\int_{0}^{x}\:dz\:dy\:dx$$ And for $dz\:dx\:dy$ would be this: $$V=\int_{-1}^{1}\int_{y^2}^{1}\int_{0}^{x}dz\:dx\:dy$$ I tried to solve it and the result is this: $$V=\int_{0}^{1}\int_{-\sqrt{x}}^{\sqrt{x}}\int_{z}^{1}dx\:dy\:dz + \int_{0}^{1}\int_{-\frac{1}{2}}^{\frac{1}{2}}\int_{y^2}^{1}dx\:dy\:dz$$ But i think its wrong please advice me the best solution . I wanted to post the  shape of this surface in 3-dimensional region but I couldn't because I am new user.","['multivariable-calculus', 'integration']"
179257,Questions on fractional Laplacian graph spectra,"Both the signed ($D-A$) and unsigned ($D+A$) Laplacian are of interest in spectral graph theory, see eg Cvetkovic: Bibliography on the signless Laplacian eigenvalues: first one hundred references . Considering the spectral function $D+\rho A$ over the interval $\rho \in [-1,1]$ rather than just the extreme values $\rho={-1,1}$, results in the curves $\lambda_i(\rho)$. For example, the following fractional spectra are are shown as point interpolations (as opposed to curve following, as in bifurcation theory) corresponding to some random Bernoulli graphs with increasing connectivity: These experimental results raise basic questions: If graphs are $M$-cospectral on $\rho = {-1,1}$ are they cospectral for $\rho \in [-1,1]$? Are there no intersections of $\lambda_i(\rho)$ outside $\rho \in [-1,1]$? Does $\lim_{\lambda_i \to \infty}\frac{d\lambda_i}{d\rho} = const?$ What's the combinatorial interpretation of intersections in $\rho \in [-1,1]$? Feel free to add your own conjectures.","['matrices', 'spectral-graph-theory', 'graph-theory', 'graph-laplacian']"
179277,Pell type equation: $x^2-py^2=a$,"Let $p=4k+1$ be a prime number such that $p=a^2+b^2$, where $a$ is an odd integer.Prove that the equation $$x^2-py^2=a$$ has at least a solution in $\mathbb{Z}$.","['algebraic-number-theory', 'number-theory']"
179282,How $f^{2}=g^{6}-1$ implies $f$ and $g$ are constant?,"From Harvard qualification exam, 1990. Let $f,g$ be two entire holomorphic functions satisfy the property $$f(z)^{2}=g(z)^{6}-1,\forall z\in \mathbb{C}$$ Prove that $f,g$ are constant functions. Would this be the same if $f,g$ are allowed to be meromorphic functions? The problem comes with a hint that I should think about the algebraic curve $$y^{2}=x^{6}-1$$but I do not see how they are related. I know this curve is hyperellipitic (from Riemann-Hurwitz or simply the wiki article). But how this help?(this curve should be of genus 2). Taking a short look at the entire function article also seems to be no help. Is the author implying $f,g$ is not best to be treated by classical Riemann Surface applications (as opposed to algebraic geometry ones)?","['riemann-surfaces', 'complex-analysis']"
179285,Boundary of $L^1$ space,"Is there any rigorous or heuristic notion of boundary of $L^1$ that is studied? I mean something loosely like the collection of functions or distributions defined by $$\left\{f\notin L^1: f_n\to f\quad\text{a.e.}\quad \text{as} \quad n\to \infty \quad \text{where} \quad f_n\in L^1\right\}$$ And what kind of characterizations or properties of this ""surface"" are known? Edit: Changed to pointwise convergence.","['functional-analysis', 'real-analysis', 'banach-spaces']"
179294,"Prove $\cos^2 x \,\sin^3 x=\frac{1}{16}(2 \sin x + \sin 3x - \sin 5x)$","How would I prove the following? $$\cos^2 x \,\sin^3 x=\frac{1}{16}(2 \sin x + \sin 3x - \sin 5x)$$ I do not know how to do do the problem I do know $\sin(3x)$ can be $\sin(2x+x)$ and such yet I am not sure how to commence.",['trigonometry']
179309,Unconfounded assumption,"In the notation of the unconfounded assumption, does 
$$\left(Y(0),Y(1)\right)\perp W \mid X $$ mean $$ f(Y(0),Y(1), W\mid X)=f(Y(0),Y(1)\mid X)\cdot f(W\mid X)$$
? I can prove that the second line if the set of random variables $(Y(0),Y(1))$ is
independent of $W$ given $X$:
$$f(Y(0),Y(1), W\mid X)=f(Y(0),Y(1)\mid W,X)\cdot f(W|X)$$
by the conditioning rule. Since $f((Y(0),Y(1)|W,X)$ does not depend on $W$ by the assumption stated, the result is
obtained. But every signle paper omits this discussion. I am studying this treatment effect literature by myself, so I need to understabd this fundamental assumption based on my econometrics knowledge.",['statistics']
179324,A group of order $120$ cannot be simple,"We know that: Theorem: If a simple group $G$ has a proper subgroup $H$ such that $[G:H]=n$ then $G\hookrightarrow A_n$. This fact can help us to prove that any group $G$ of order $120$ is not simple . In fact, since $n_5(G)=6$ then $[G:N_G(P)]=6$ where $P\in Syl_5(G)$ and so $A_6$ has a subgroup of order $120$ which is impossible. My question is: Can we prove that $G$ of order $120$ is not simple without employing the theorem? Thanks.","['sylow-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
179325,"Hadamard Product Represented as ""Simpler"" Operations","Given matrices $A$ and $B$, the Hadamard product $A\circ B$ is given by $(A\circ B)_{ij}=A_{ij}\cdot B_{ij}$ (if you ask an ordinary middle schooler, this would be the ""most natural"" definition of matrix multiplication, haha.) Does anyone know if it is possible to represent $A\circ B$ as a combination of other widely used matrix operations, such as addition, multiplication, taking determinant and taking inverse?","['hadamard-product', 'linear-algebra']"
179329,Random walk and its expectation,"Let $S_n=X_1+X_2+...+X_n$, where $X_i=1$ with probability $p$ and $X_i=-1$ with probability $q=1-p$, for all $i$ and independently of each other. Assume that $S_0=0$ and $0<p<\frac{1}{2}$. Show $$E\left(\sup\limits_{0\le k\le n}S_k\right) \le \frac{p}{q-p}$$ I would like to know how to prove it.","['random-walk', 'probability']"
179331,What is the Birch and Swinnerton-Dyer Conjecture?,"This is probably a really silly question, but I was wondering if someone could explain the Birch and Swinnerton-Dyer conjecture to me in a simple way. I've read a lot about it, but cannot understand it. Maybe posting here will help. What I do understand is the concept of ranks on an elliptic curve; for ever point that generates an infinite number of points on the elliptic curve, it contributes 1 to the rank. Further, I know that Mordell proved that every elliptic curve must have a finite rank. Finally, with regards to BSD, I understand that the conjecture says that the ""analytic"" way of computing the rank is the same as the ""algebraic"" way of computing the rank. But what I cannot seem to understand is what exactly is the analytic way of computing the rank, or the algebraic way. If anyone wants to help me out, that would be much appreciated! Thanks!","['analytic-number-theory', 'elliptic-curves', 'number-theory']"
179339,Group with an automorphism of order 2 (Jacobson BA1),"I am having trouble with Exercise 11, Section 1.10 of Basic Algebra 1 by Nathan Jacobson (pub. Freeman & Co. 1985).  The statement to prove is: Let $G$ be a finite group and $\phi$ an automorphism of $G$.  Let $$ I = \{ g \in G : \phi g = g^{-1} \} $$ If $|I| > {3\over4} |G|$ , $G$ is abelian. If $|I| = {3\over4} |G|$ , $G$ has an abelian subgroup of index 2. I'm trying to attack item 2 first, thinking there will be a way from 2 to 1, but I am not even at a point where that matters. Facts I can see: $\phi^2 = id_G$ , because the set of elements fixed by $\phi^2$ is a subgroup containing $I$. Since $|G|$ is even (working on item 2!) , so must be the order of $K$ where $$ K = \{ k \in G : \phi k = k \} $$ because we can partition $G$ into classes $\pi_k = \{ k, \phi k \}$ of size either 2 or 1, and $K$ is the union of all the singleton classes. Hence, $K$ contains an element $i$ of order 2, so $ \phi i = \phi i^{-1} = i^{-1} $ , i.e. $$ 1 \neq i \in K \cap I $$ That's already some nice information, but I still have no clue where to look for the abelian subgroup :-(","['finite-groups', 'combinatorics']"
179340,Show that $\overline{U\cap \overline{A}}=\overline{U\cap A}.$,Show that: For every open set $U$ in a topological space $X$ and every $A\subset X$ we have $$\overline{U\cap \overline{A}}=\overline{U\cap A}.$$ The simple and new proof is welcome. Thanks for any help.,['general-topology']
179353,Effective Upper Bound for the Number of Prime Divisors,"Let $\omega(n) = \sum_{p \mid n} 1$. Robin proves for $n > 2$,
\begin{align}
\omega(n) < \frac{\log n}{\log \log n} + 1.4573 \frac{\log n}{(\log \log n)^{2}}.
\end{align}
Is there a similar tight effective upper bound for $\Omega(n) = \sum_{p \mid n} \text{ord}_{p}(n)$ or at least an upper bound in terms of $\omega(n)$?","['analytic-number-theory', 'reference-request', 'number-theory']"
179357,Probability that a man will hit the target,"The question is A man can hit a target once in $4$ shots. If he fires 4 shots in succession, what is the probability that he will hit his target? Here is how I am solving it: Since the probability of man hitting the target is $\frac{1}{4}$ so for four consecutive shots it will be $(\frac{1}{4})^4 = \frac{1}{256}$ which is wrong. Now the book takes a different approach and finds the probability that he will not hit the target in one shot = $1 - \frac{1}{4} = \frac{3}{4}$ therefor the probability he will not hit the target in 4 shots is  $(\frac{3}{4})^4$ and thus , the probability that he will hit the target at least in one of the four shots is 1- $(\frac{3}{4})^4$ Although I understand the books approach - I wanted to know why my approach is wrong ? doesnt it also calculate the probability of hitting the target in 4 shots",['probability']
179360,"Reference request for examples of probabilistic heuristics, help put some examples in a broader context.","I was thinking about how probability is used in heuristic arguments, an example being the argument that there are an infinite number of twin primes: the probability that $n$ is the first of two twin primes is about $\frac{1}{(\log n)^2}$, and $\prod{(1-\frac{1}{(\log n)^2}}) \rightarrow 0$, so the probability that there are an infinite number of twin primes is $1$.  (Another example provided by @joriki is the heuristic for the Collatz conjecture.)  I then wondered if there are any heuristic arguments yielding probabilities strictly between $0$ and $1$ and I considered this example predicate: $A(x,n)$ := ""the $n^{th}$ bit of the binary expansion of $x$ is $1$"". Given certain assumptions there is a sense in which $A(\pi, n)$ is ""true with probability $\frac{1}{2}$"".  Now this isn't a very useful notion, since it is either true or not, and we can find out by computing the $n^{th}$ bit of $\pi$, although perhaps there is some utility if $n$ is very large.  However it is a second-class sort of heuristic because it only gives a hint to an answer we could find definitively with more work.  But next I thought of this example: $B(x,n)$ := ""the binary expansion of $x$ starting from offset $n$, when interpreted as an Iota program, halts"". In a similar way we can lazily argue that $B(\pi, n)$ is ""true with probability $\Omega_{\mathrm{Iota}}$ "".  But in this case, under similar assumptions, there are values of $n$ for which $B(\pi, n)$ is not even decidable: we can construct a Gödel-sentence in our working theory, write an Iota program which searches for its proof, find that program in the binary expansion of $\pi$, and then construct $B(\pi, n)$ using its offset $n$.  For that reason, it seems to be a first-class sort of heuristic (despite giving us a probability strictly between $0$ and $1$), in the same league as those that give us almost-certain conclusions to open problems. One of the unstated assumptions (along with the 2-normality of $\pi$ and such) is that there is no ""conspiracy"" between the bits of $\pi$ and the semantics of Iota.  It is equally believable that no such conspiracy exists between $\pi$ and $e$, or between $e$ and Iota, or amongst all three.  And since the probability of the conjunction of independent events is equal to the product of their respective probabilities, it is just as reasonable to say that $B(\pi,n) \wedge B(e,n)$ is ""true with probability $\Omega_{\mathrm{Iota}}^2$"".  On the other hand, the same doesn't apply to $B(\pi,n) \wedge B(\pi,n+1)$: since the programs substantially overlap we should expect some correlation in their halting status and therefore a different ""truth probability"" for the conjunction. So here are my questions: Are there other (hopefully more natural) examples of problems (open or not) with simple heuristic arguments suggesting a particular probability of truth (other than $0$ or $1$)?  Are my (admittedly vague) arguments above at least vaguely correct or are there major mistakes and conceptual problems?  What is a good way of describing the dependencies between different heuristics?  Can the idea of quantum probability amplitude be applied here?  What are some other examples of heuristics that are not independent (e.g. two statements that are both heuristically true but contradict each other)?  Any references to related topics that might help me further develop or discard this idea?  I have read overviews of fuzzy logic and probabilistic logic but I don't know how to apply either here.","['probability-theory', 'logic', 'reference-request', 'soft-question']"
179361,Can you prove why consecutive diagonal intersection points show decreasing fractions inside a rectangle?,"When I was in third grade, I was playing with rectangles and diagonal lines, and discovered something very interesting with fractions.  I've shown several math teachers and professors over the years, and never got an answer.  Just a few, ""Wow, that's neat!"" Draw a rectangle.  Draw a line from the top left corner to the bottom right corner.  Then draw a line from the top right corner to the bottom left corner.  The intersection obviously becomes 1/2 units of the rectangle's width. Now draw a line from the last intersection to the bottom line of the rectangle, and then from that point to the top right corner of the rectangle.  The new intersection becomes 1/3 units of the rectangle's width. Keep doing this and the denominator of the fraction increases by one each time to infinite.  Why does this happen?  I don't know how to prove why this happens, but it would be interesting if someone could.  Can you?  I never became a mathematician to prove it, but if it's easy, please forgive my mathematical ignorance.  I tried this several years ago with AutoCAD and it does in fact work out.","['analytic-geometry', 'geometry', 'fractions']"
179367,Canonical Isomorphism Between $\mathbf{V}$ and $(\mathbf{V}^*)^*$,"For the finite-dimensional case, we have a canonical isomorphism between $\mathbf{V}$, a vector space with the usual addition and scalar multiplication, and $(\mathbf{V}^*)^*$, the ""dual of the dual of $\mathbf{V}$."" This canonical isomorphism means that the isomorphism is always the same, independent of additional choices. We can define a map $I : \mathbf{V} \to (\mathbf{V}^*)^*$ by $$x \mapsto I(x) \in (\mathbf{V}^*)^* \ \text{ where } \ I(x)(f) = f(x) \ \text{for any } \  f \in \mathbf{V}^*$$ My Question: what can go wrong in the infinite-dimensional case? The notes I am studying remark that if $\mathbf{V}$ is finite-dimensional, then $I$ is an isomorphism, but in the infinite-dimensional case we can go wrong? How?","['vector-spaces', 'linear-algebra']"
179389,Product of Polynomials,"If $p$ is a polynomial of degree $n$ and $q$ is a polynomial of degree $m$, then their product $p \cdot q$ is given by:
  $$ (p \cdot q)(x) = \sum_{i = 0}^{n + m} \left ( \sum_{k = 0}^i p_k q_{i - k} \right ) x^i $$
where $p_i$ and $q_i$ denote the $i$th coefficient of $p$ and $q$, respectively. I am having trouble proving that $p \cdot q$ is, indeed, subject to this identity. I have attempted to prove the identity by induction on the degree of one of the polynomials, but am having trouble completing the proof. My trouble arises when I distribute sums in the inductive step of the proof. I assume the proof is relatively simple, and I am overlooking something simple. I would appreciate some help in this regard. Here, the polynomials are real-valued.","['algebra-precalculus', 'polynomials']"
179398,why is $0=0$ not possible?,"Hi one of my friend showed me one proof, i.e., $2^2 - 2^2 = 10 - 10$ $(2+2) (2-2) = 5 (2-2)$ dividing both sides by $(2-2)$ $(2 + 2) = 5$ I know this is wrong in first line as both LHS and RHS goes to $0$ and you cannot directly make an equation $0=0$ because $\frac{0}{0} \neq 1$ ,
but I cannot explain this. Can anyone give a perfect reason why we cannot compare $0=0$ ? Or, is there any other reason for this to be wrong?","['algebra-precalculus', 'fake-proofs']"
179424,What is an example of a vector field that is not left-invariant?,"Let $G$ be a Lie group, $L_g$ the left-translation on this group with differential $d L_g$. A vector field $X$ on $G$ is called left-invariant if $$ X \circ L_g = d L_g \circ X \quad \forall g \in G$$ i.e. $$ X_{gh} = (d L_g)_h (X_h) \quad \forall g,h \in G. $$ Now, this definition seems so natural to me that I cannot come up with a non-trivial counterexample for a vector field that is $\textit{not}$ left-invariant. In my mind, pushing forward on the tangent space is basically always the same as the group action... Could you provide me with such a counterexample that helps understand the notion of left-invariance?","['lie-algebras', 'lie-groups', 'differential-geometry', 'vector-fields']"
179452,Enumerate certain special configurations - combinatorics.,"Consider the vertices of a regular n-gon, numbered 1 through n. (Only the vertices, not the sides).
A ""configuration"" means some of these vertices are joined by edges. A ""good"" configuration is one with the following properties: 1) There is at least one edge. 2) There can be multiple edges from a single vertex. 3) If A and B are joined by an edge, then the degree of A equals the degree of B. 4) No two edges must intersect each other, except possibly at the endpoints. 5) The degree of each vertex is at most k. (where $0\leq k \leq n$ ) Find f(n, k), the number of good configurations. For example, f(3, 2) = 4 and f(n, 0) = 0.","['recurrence-relations', 'combinatorics']"
179453,Area Bounded by Polar Curves,"I am answering sample exams for my Calculus class and my attention was caught by the following item. Set-up the definite integral or sum of definite integrals equal to the area of the region above the polar axis, inside the limaçon $r = 3 + 2 \sin \theta$ and outside the lemniscate $r^2 = 32 \cos 2\theta$ given that the two curves intersect at $(4,\frac{\pi}{6})$. At first, I thought that the area is given by $$\dfrac{1}{2} \int_{\frac{\pi}{6}}^{\frac{5\pi}{6}}{[(3 + 2\sin \theta)^2 - (32 \cos 2\theta)] \mathrm{d}\theta}$$ but I know that the area of the lemniscate is tricky so I may have given a smaller area. My question is this: How do you know the limits of integration for lemniscates? (I know that the limits of integration for the area of the lemniscate alone is from $-\frac{\pi}{4}$ to $\frac{\pi}{4}$, but how about for small portions of the curve?) I'll appreciate any help. Thank you so much.","['polar-coordinates', 'calculus']"
179456,Does $\int_{0}^{\infty} \cos (x^2) dx$ diverge absolutely?,"I believe it does, but i would like some help formulating a proof.","['improper-integrals', 'convergence-divergence', 'integration', 'limits']"
179478,Evaluating the line integral of $F=\frac{-y}{x^2+y^2}i+\frac{x}{x^2+y^2}j$ along $0 \le t \le 2\pi $,"Recently, I had an exam and in that I was asked to evaluate the line integral of the function $$F=\frac{-y}{x^2+y^2}i+\frac{x}{x^2+y^2}j$$ alongside the unit circle, $0 \le t \le 2\pi $ . Moreover, it was asked if this integral could be carried out with using Green's Theorem or not and why? For the first, I did the following: $$\oint_C F\cdot dr=\int_0^{2\pi}F\big (\cos(t),\sin(t)\big)\cdot\big(-\sin(t),\cos(t)\big)dt$$ which is $2\pi$. But always I have problem with above theorem and I do know I didn't pass this part of question correctly. May I ask to help me? Thank you.","['multivariable-calculus', 'integration']"
179479,Really stuck on strategy for this fundamental theorem of algebra type problem.,"I am at a loss at how to approach this problem. It doesn't make sense to me to solve without finding the roots. I couldn't find the roots without a calculator anyway, but you're not meant to. Show that if the roots of the equation: $5x^3-x^2-2x+3=0$ are a,b and c then: $\frac{1}{a}+\frac{1}{b}+\frac{1}{c}=2/3$ $a^2+b^2+c^2=\frac{21}{25}$ $a^3+b^3+c^3=-\frac{194}{125}$","['algebra-precalculus', 'polynomials']"
179492,one-dimensional random walk,"Consider a one-dimensional random walk whose steps are $+2$ and $-1$ with probabilities $p$ and $1-p$ respectively, starting from $0$ and in the interval {$-n$, $n$}. The walk ends at $-n$ or $n$ or $n+1$. Let $m$ be the number of integers ""jumped"" during the walk. Is there a limit for the ratio $\frac{m}{2n+1}$ for $n \rightarrow \infty$? Three examples to clarify: 1) n=15 p= 1/2
 Steps = {-1, 2, -1, 2, -1, 2, -1, 2, -1, -1, 2, 2, -1, -1, 2, 2, 2, 2, -1, \
-1, 2, -1, -1, 2, -1, 2, -1, -1, 2, 2} Positions = {0, -1, 1, 0, 2, 1, 3, 2, 4, 3, 2, 4, 6, 5, 4, 6, 8, 10, 12, 11, 10, \
12, 11, 10, 12, 11, 13, 12, 11, 13, 15} Missed (jumped) positions =  {-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, 7, 9, 14} m = 17;  r = m/(2 n +1) = 0.548387 2) n= 15 p=1/2
 Steps = {2, 2, 2, 2, -1, -1, 2, 2, 2, -1, -1, -1, -1, 2, 2, -1, -1, -1, 2, \
-1, 2, -1, -1, 2, 2, 2} Positions = {0, 2, 4, 6, 8, 7, 6, 8, 10, 12, 11, 10, 9, 8, 10, 12, 11, 10, 9, 11, \
10, 12, 11, 10, 12, 14, 16} Missed positions =  {-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 1, 3, 5, 13, 15} m =20;  r = m/(2 n +1) = 0.645161 3) n=20 p=1/2
 Steps = {-1, 2, -1, 2, 2, 2, -1, -1, -1, -1, -1, -1, 2, -1, 2, 2, 2, -1, 2, \
-1, 2, -1, -1, -1, -1, -1, 2, -1, -1, -1, 2, -1, -1, -1, 2, -1, 2, \
-1, 2, 2, -1, -1, -1, -1, -1, -1, -1, 2, 2, -1, -1, 2, 2, -1, 2, -1, \
2, 2, 2, -1, 2, 2, 2, 2} Positions = {0, -1, 1, 0, 2, 4, 6, 5, 4, 3, 2, 1, 0, 2, 1, 3, 5, 7, 6, 8, 7, 9, \
8, 7, 6, 5, 4, 6, 5, 4, 3, 5, 4, 3, 2, 4, 3, 5, 4, 6, 8, 7, 6, 5, 4, \
3, 2, 1, 3, 5, 4, 3, 5, 7, 6, 8, 7, 9, 11, 13, 12, 14, 16, 18, 20} Missed positions =  {-20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, \
-6, -5, -4, -3, -2, 10, 15, 17, 19} m =20;  r = m/(2 n +1) = 0.560976 A simulation with the range {-2000,2000}, iterated 1000 times provides r as 0.572958. The question is: Is there a limit for n -> Infinity based on: (n, p, base steps {-1,2}) ?","['stochastic-processes', 'random-walk', 'probability']"
179499,"Klenke's proof for ""Kernel via a consistent family of kernels""","I'm trying to understand a proof in Achim Klenke's textbook Probability Theory: A Comprehensive Course (Springer, 2008). The proof in question is the one for Theorem 14.42, ""Kernel via a consistent family of kernels"" (pp. 289-290). The proof proceeds in two steps: (1) Show existence of $\kappa$ using Kolmogorov's extension theorem, (2) Show that $\kappa$ is a probability transition kernel. I'm concerned with the first step. In order to use Kolmogorov's extension theorem, a family of finite dimensional distributions $\left(P_J : J\subset I \space \mathrm{finite},\space 0\in J\right)$ is defined and shown to be consistent. According to Klenke, Kolmogorov's extension theorem then yields a probability measure from $\left(E,\mathcal B\left(E\right)\right)$ to $\left(E^I,\mathcal B\left(E\right)^{\otimes I}\right)$ . However in my opinion, due to the condition $0\in J$ Kolmogorov's theorem yields a probability measure from $\left(E,\mathcal B\left(E\right)\right)$ to $\left(E^H,\mathcal B\left(E\right)^{\otimes H}\right)$ where $H = I\setminus\left\{0\right\}$.",['probability-theory']
179505,"Finite dimensional function space ""different"" from $\mathbb{R}^n$ generically","If you pick a random vector in $\mathbb{R}^n$ with some fixed basis, there is no special relationship between components. The relationship between the $1^{st}$ component and the $5^{th}$ component is the same as the relationship between the $82^{nd}$ component and the $1001^{th}$ component. On the other hand, if the space $\mathbb{R}^n$ is viewed as a discretization of a function space (eg, n nodal values for a piecewise linear basis of hat functions), then there is a special relationship between components based on nearness in the underlying domain. If 2 nodes are close in physical space, then the basis vectors corresponding to those nodes are more highly related in the function space. So, somehow $\mathbb{R}^n$ as a function space has more structure and is different than $\mathbb{R}^n$ generically. What is this difference and how can it be made precise? My thoughts so far are as follows: this seems similar to the ideas of function space regularity (the more regular the space, the more nearby points are ""related"" to each other). However I don't think this is the whole picture since one could also imagine defining additional structure on the function space over nodes in a n-node graph $\{f:G\rightarrow\mathbb{R}\}$, where there is no notion of continuity, differentiability, etc.","['graph-theory', 'linear-algebra', 'functional-analysis']"
179507,Proof of a Proposition on Partitions and Equivalence Classes,"I stumbled upon a seemingly rudimentary proposition that I am having trouble writing out a proof for. The proposition goes something like, Proposition: If $\{A_i|i\in I\}$ is a partition of $\mathcal A$, then there is an equivalence relation on $\mathcal A$ whose
    equivalence clases are precisely the sets $A_i, i \in I$. Where $I$ is some indexing set. How do I prove the statement ? I can't even decide on a good place to start.","['relations', 'elementary-set-theory', 'set-partition']"
179512,Finite $G$ with involutory automorphism $\alpha$ with no nontrivial fixed points. Proving properties of $\alpha$.,"The question at hand is: Let G be a finite group and $\alpha$ an involutory automorphism of G, which doesn't fixate any element aside from the trivial one. 1) Prove that $ g \mapsto g^{-1}g^{\alpha} $ is an injection 2) Prove that $\alpha$ maps every element to its inverse 3) Prove that G is abelian I think I've found 1). I assume $ g_1^{-1}g_1^{\alpha} = g_2^{-1}g_2^{\alpha} $ and from this I get $ (g_2g_1^{-1})^\alpha = g_2g_1^{-1} $ , so $g_2 = g_1$ (is this correct?) For 2) I'm sort of stumped though, not sure how to start proving that, so any help please?","['involutions', 'finite-groups', 'group-theory']"
179518,Number of Quadrilaterals with given sides and area?,"How many non-congruent quadrilaterals are there if we specify the sides to be a, b, c, d and specify its area A?","['general-topology', 'geometry']"
179520,Showing the sum of orthogonal projections with orthogonal ranges is also an orthogonal projection,"Show that if $P$ and $Q$ are two orthogonal projections with orthogonal ranges, then $P+Q$ is also an orthogonal projection. First I need to show $(P+Q)^\ast = P+Q$. I am thinking that since
\begin{align*}
((P+Q)^\ast f , g) & = (f,(P+Q)g) \\
 & = (f,Pg) + (f,Qg) \\
 & = (P^\ast f,g) + (Q^\ast f,g) \\
 & = (Pf,g) + (Qf,g) \\
 & = ((P+Q)f,g),
\end{align*}
we get $(P+Q)^\ast=P+Q$. I am not sure if what I am thinking is right since I assumed that $(P+Q)f=Pf+Qf$ is true  for any bounded linear operator $P$, $Q$. For $(P+Q)^2=P+Q$, I use
$$(P+Q)^2= P^2 + Q^2 + PQ +QP,$$
but I cant show $PQ=0$ and $QP=0$. Anyone can help me? Thanks.","['hilbert-spaces', 'functional-analysis']"
179529,What are some examples of vector spaces that aren't graded?,"From wikipedia : a vector space $V$ is graded if it decomposes into direct sum $ \oplus_{n \geq 0} V_n$ of vector spaces $V_n$. So as far as I understand things, any vector space with a countable basis is graded:  Let $V$ be a vector space over a field $k$ with basis $\{v_n\}_{n\in\mathbb{N}}$, then $V = \oplus_{n\geq 0} k\cdot v_n$.  Then the only vector spaces that I can think of that aren't obviously graded are things like $C(X)$, the space of continuous functions on some manifold $X$ Is this correct? are there any more? or do I not understand something? Thanks","['vector-spaces', 'ring-theory', 'linear-algebra']"
179534,The expected payoff of a dice game,"There's a question in my Olympiad questions book which I can't seem to solve: You have the option to throw a die up to three times.  You will earn
the face value of the die.  You have the option to stop after each
throw and walk away with the money earned. The earnings are not additive. What is the expected payoff of this game? I found a solution here but I don't understand it.","['dice', 'probability']"
179562,"Is it possible to 'approximate' compact, convex sets in $\ell^2$ by the Hilbert cube","Define $H=\{(x_n)_n\in\ell^2:|x_n|\le \frac1n, n\in\mathbf N\}\subset\ell^2$. This set is known as the Hilbert cube and it is well-known that $H$ is compact, convex and non-empty. Let $\overline{\mathrm{conv}}(C)$ denote the closure of the convex hull of a subset $C\subset\ell^2$. Suppose $S$ is a non-empty, compact, convex subset of $\ell^2$, is it possible to write$$S=\overline{\mathrm{conv}}\left(\bigcup_{n=1}^\infty[ S\cap(n\cdot H)]\right),$$ where (for $n\in\mathbf N$ fixed) $n\cdot H=\{n\cdot x:x\in H\}$. I think it is possible (since the Hilbert cube keeps getting 'thinner' in each coordinate), but I do not know how to prove it.","['convex-analysis', 'hilbert-spaces', 'functional-analysis', 'compactness']"
179583,Incremental approach of calculating the Singular Value Decomposition,"I have a fairly large array, a billion or so by 500,000 array. I need to calculate the singular value decomposition of this array. The problem is that my computer RAM will not be able to handle the whole matrix at once. I need an incremental approach of calculating the SVD. This would mean that I could take one or a couple or a couple hundred/thousand (not too much though) rows of data at one time, do what I need to do with those numbers, and then throw them away so that I can address memory toward getting the rest of the data. People have posted a couple of papers on similar issues such as http://www.bradblock.com/Incremental_singular_value_decomposition_of_uncertain_data_with_missing_values.pdf and http://www.jofcis.com/publishedpapers/2012_8_8_3207_3214.pdf . I am wondering if anyone has done any previous research or has any suggestions on how should go on approaching this? I really do need the FASTEST approach, without losing too much accuracy in the data.","['numerical-linear-algebra', 'matrices', 'linear-algebra']"
179585,Point set topology,"Some time back, I tried reading Rudin's Principles of Mathematical Analysis and I found no trouble with the introductory chapter. In chapter II I encountered point set topology. The number of theorems packed into some pages kind of overwhelmed me. I got stuck there as I felt I did not fully understand everything geometrically. I thought topology was supposed to be geometric. So, I request you to suggest something in this regard. I am contemplating learning some basic point set topology from elsewhere (I don't know where from) and I am wondering if this is the solution to my problem. (Yes, as a preparation for analysis. Even some good notes would be nice or perhaps a great book) Any help is appreciated. PS : I hate compromising rigor.","['general-topology', 'reference-request']"
179597,sum alternating series inequality,"I am stuck on proving the inequality in $LHS:=\sum_{k=1}^{\infty}(-\lambda)^k\prod_{i=1}^k \left(1+\frac{\alpha}{n+i}\right)\geq \sum_{k=1}^{\infty}(-\lambda)^k\left(1+\frac{\alpha}{n}\right)^k=\frac{-\lambda(\alpha+n)}{n+\lambda(\alpha+n)}:=RHS$ where $\lambda, \alpha, n\geq 0$, and $\lambda\left(1+\frac{\alpha}{n}\right)<1$ which ensures convergence of RHS. If necessary, one may assume $2\alpha$ is an integer. Obviously, LHS=RHS if $\alpha=0$ or $n\rightarrow\infty$. Numerical evaluations indicate (no proof): The inequality is valid, also if $n$ at the right hand side is replaced by $n+\frac{1}{2}$ The difference LHS-RHS increases monotonically in $a$ and decreases monotonically in $n$ Background (no need to read this): If $S$ is a Gamma distribution with shape $\alpha$ and scale $\lambda$, and $n$ an even integer, then $LHS = \frac{1}{x_n}\sum_{k=n+1}^{\infty}x_k$ where $x_k = \frac{E[(-S)^k]}{k!} = \frac{(-\lambda)^k\Gamma(\alpha+k)}{k!\Gamma(\alpha)} $. Thus, LHS is the scaled remainder when $\sum_{k=0}^{\infty}x_k=E[\exp(-S)]=\frac{\alpha\lambda}{(1+\lambda)^{\alpha+1}}$ is truncated after $n$ terms.","['inequality', 'gamma-function', 'sequences-and-series']"
179604,When is the geometric multiplicity of an eigenvalue smaller than its algebraic multiplicity?,"I was kinda crushed to discover that two different matrices  with different properties can actually share the same characteristic polynomial ($-\lambda^3-3\lambda^2+4$): $A=\begin{pmatrix}
1 &  2& 2\\ 
-3 &-5  &-3 \\ 
 3& 3 & 1
\end{pmatrix} , B=\begin{pmatrix}
2 & 4& 3\\ 
-4 &-6  &-3 \\ 
 3& 3 & 1
\end{pmatrix}$ $A$ has an eigenline and an eigenplane (and thus an eigenbasis), whereas $B$ has two eigenlines (so no eigenbasis). The repeated eigenvalue -2 of B corresponds to an eigenspace with basis {(-1,1,0)}. When is the geometric multiplicity of an eigenvalue smaller than its algebraic multiplicity (as in case B)? Are there general conditions to look for? Thanks!","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
179623,Calculating: $\lim_{n\to \infty}\int_0^\sqrt{n} {(1-\frac{x^2}{n})^n}dx$ [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Prove: $\lim\limits_{n \to \infty} \int_{0}^{\sqrt n}(1-\frac{x^2}{n})^ndx=\int_{0}^{\infty} e^{-x^2}dx$ I need some help calculating the above limit. What i have observed so far is that: For all x the limit of the sequence inside the integral as n tends to infinity is $e^{-x^2}$ I can use Dini's theorem to show that: $f_n(x) = {(1-\frac{x^2}{n})^n}$ uniformly converges to $e^{-x^2}$ Consequently i can use the theorem regarding ""the integral of the limit is the limit of integrals"" for the function sequence $f_n(x)$ and it's limit function $f(x) = e^{-x^2}$ All this is well and good, but i would be ignoring the fact that the interval integrated upon is [0,$\sqrt{n}$], and so also affected by the limit. What should i do to resolve this?","['improper-integrals', 'convergence-divergence', 'sequences-and-series', 'integration', 'limits']"
179625,Surjective and injective functions,"So let's say that we have some function $f:  \mathbb{A} \rightarrow \mathbb{B} $ Is it possible to have some function such that not all elements of A map to some value in B? Like for example, in these pictures for various surjective and injective functions: Would it be possible to have some function that has elements in A that don't map to any values of B? Like in example 1, just have the 3 in A without mapping to the element in B?","['functions', 'analysis']"
179639,"easy ""show this is a subset"" question","I am having a hard time showing this simple relation. Here, all the letters below are in $\mathbb{N} \cup \{0\}$.
$$A = \{(a,b) : a + 2b \leq n+2\}$$
$$B = \{(a,c+1) : a + 2c \leq n\}$$ How to show that $B \subset A$? This is something I got from a sum over the above indices. I wanted a lower bound on the sum (which is where $B$ came in). Obviously I set $b = c+1$ in $A$ to get $B$ but how to show that it's a subset? Thanks",['elementary-set-theory']
179641,"Proving inequality $\left( \frac {x} {y}\right) ^{x}\left( \frac {1-x} {1-y}\right) ^{1-x}\geqslant 1$ for $x, y\in (0, 1)$","Let $x,y\in \left( 0;1\right).$ I want to prove that $$\left( \dfrac {x} {y}\right) ^{x}\left( \dfrac {1-x} {1-y}\right) ^{1-x}\geqslant 1$$","['inequality', 'algebra-precalculus']"
179652,Zariski Open Sets are Dense?,"Is it true that any nonempty open set is dense in the Zariski topology on $\mathbb{A}^n$ ? I'm pretty sure it is, but I can't think of a proof! Could someone possibly point me in the right direction? Many thanks! Note: I am not asking about the Euclidean topology at all!","['general-topology', 'algebraic-geometry']"
179684,Generators of a cyclic group,"In a paper there is a lemma: Let $G= \langle a,b \rangle$ be a finite cyclic group. Then $G=\langle ab^n \rangle$ for some integer $n$. The proof is omitted because it's ""straightforward"" but I'm not able to proof it. How does this work?","['cyclic-groups', 'group-theory']"
179692,Set notation: subtracting elements with given cardinality from the powerset,"I have a set $S = \{1,2,\ldots,n\}$ of $n$ elements and I denote with $P(S)$ the powerset of $S$. Which is a correct and accepted notation to say that the set $Z$ is composed by all the elements in $P(S)$ with the exception of all the subsets of cardinality $h$? Example: if $S=\{1,2,3\}$ then $P(S) = \{\emptyset, \{1\},\{2\},\{3\},\{1,2\},\{1,3\},\{2,3\},\{1,2,3\}\}$. If $h = 1$, then it should be $Z = \{\emptyset, \{1,2\},\{1,3\},\{2,3\},\{1,2,3\}\}=P(S)\setminus\{\{1\},\{2\},\{3\}\}$. How can it be expressed in a formal and concise way, for any value of $n$ and $h$? Thanks","['notation', 'elementary-set-theory']"
179713,Find the domain of $f(x)=\frac{3x+1}{\sqrt{x^2+x-2}}$,"Find the domain of $f(x)=\dfrac{3x+1}{\sqrt{x^2+x-2}}$ This is my work so far:
$$\dfrac{3x+1}{\sqrt{x^2+x-2}}\cdot \sqrt{\dfrac{x^2+x-2}{x^2+x-2}}$$
$$\dfrac{(3x+1)(\sqrt{x^2+x-2})}{x^2+x-2}$$
$(3x+1)(\sqrt{x^2+x-2})$ = $\alpha$ (Just because it's too much to type)
$$\dfrac{\alpha}{\left[\dfrac{-1\pm \sqrt{1-4(1)(-2)}}{2}\right]}$$
$$\dfrac{\alpha}{\left[\dfrac{-1\pm \sqrt{9}}{2}\right]}$$
$$\dfrac{\alpha}{\left[\left(\dfrac{-1+3}{2}\right)\left(\dfrac{-1-3}{2}\right)\right]}$$
$$\dfrac{\alpha}{(1)(-2)}$$
Now, I checked on WolframAlpha and the domain is $x\in \mathbb R: x\lt -2$ or $x\gt 1$
But my question is, what do I do with the top of the problem? Or does it just not matter at all.",['algebra-precalculus']
179717,Uniform convergence of polynomial with degree less than N+1,"In the space of polynomials with degree less than $N+1$: $\operatorname{span}\{ 1,x,\ldots,x^N\}$ defined on $[a,b]$, if a  sequence has a uniform convergent limit(under maximum norm in continuous function space). 1) Is the limit a polynomial? 2) Is the limit polynomial's degree less than $N+1$? 3) Do the coeffcients of polynomial sequence converge?","['real-analysis', 'analysis']"
179734,Basic help with sigma algebras and borel sets,"In non-rigorous, intuitive terms, can someone briefly define: (i) a measurable set (ii) a borel set (iii) a sigma algebra (iv) a borel sigma algebra Im studying these concepts independently in preparation for a course in the fall and want to make sure I have a functional intuitive idea before learning them rigorously.  Im not looking for references to textbooks, or textbook definitions, just a quick intuitive description from someone who is familiar.",['measure-theory']
179735,Finding the sum of series; sum of squares,Is there any way to find the sum of the below series ? $$\underbrace{10^2 + 14^2 + 18^2 +\cdots}_{41\text{ terms}}$$ I got asked this question in a competitive exam.,"['summation', 'sequences-and-series', 'number-theory']"
179778,Solve $\cos^{n}x-\sin^{n}x=1$ with $n\in \mathbb{N}$.,"Solve $\cos^{n}x-\sin^{n}x=1$ with $n\in \mathbb{N}$ I have no idea how to deal with this crazy question. One idea came into my mine is factorization, but I can't go on... Can anyone help me please? Thank you.","['trigonometry', 'algebra-precalculus']"
179786,Stone-Weierstrass theorem proof (Rudin),I am reading Rudin's proof (3rd edition) and am wondering what substitution is made to make it true that $P_n(x)=$ the integral from $-x$ to $1-x$ is equal to the same function integrated from -1 to 1. He says there's a substitution but I haven't found the right one. Thanks a lot,['real-analysis']
179787,Compute the series : $\sum_{n=1}^{\infty} \frac{4^n n!}{(2n)!}$,"How would you compute the following series? I'm interested in some easy approaches that would allow me to work it out.
$$\sum_{n=1}^{\infty} \frac{4^n n!}{(2n)!}$$","['sequences-and-series', 'calculus', 'real-analysis']"
179798,The greatest possible geometric multiplicity of an eigenvalue,"Wikipedia claims that "" Given an n×n matrix A.... both algebraic and geometric multiplicity are integers between (including) 1 and n. "" But how can the geometric multiplicity possibly be n? Since $(A-\lambda I)$ is a square matrix (as opposed to a matrix with more columns than rows), each of A's eigenspaces $Nul (A-\lambda I)$  has at most $(n-1)$ dimensions, isn't it? I.e. The geometric multiplicity of an eigenvalue must be a number between between $1$ and $(n-1)$, right?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
