question_id,title,body,tags
2798951,trigonometric limit with integral: $\lim_{\alpha\to 0}\int^{\alpha}_{0}\frac{dx}{\sqrt{\cos x -\cos \alpha}}$,"I've got following limit to calulate: $$\lim_{\alpha\to 0}\int^{\alpha}_{0}\frac{dx}{\sqrt{\cos x -\cos \alpha}}$$ Is there any way to bound it by some ""more convenient"" limit?","['real-analysis', 'limits', 'trigonometry', 'integration', 'definite-integrals']"
2798953,Minimum Variance Unbiased Estimator for exponential distribution cases,"Exercises : Let $X_1, \dots, X_n$ be a random sample from the exponential distribution with unknown parameter $\theta >0$ . i) Find a sufficient and complete statistic function $T$ for $\theta$ . ii) With the help of the theorem Rao-Blackwell, find a Minimum Variance Unbiased Estimator for $1/\theta$ and $1/\theta^2$ . iii) Find $\mathbb{E}(1/T^k), \; k \in \{1,2,\dots,n-1\}$ . Attempt : i) The pdf of our sample is given by : $$f(x;\theta) = \begin{cases} \theta e^{-\theta x}, \; x \geq 0 \\ 0, \; x < 0 \end{cases}$$ Thus, in a simple expression : $$f(x;\theta) = \theta e^{-\theta x}\mathbb{I}_{[0,+\infty]}(x)$$ Note that the expression is of the form $c(\theta)e^{q(\theta)t(x)}h(x)$ , thus it belongs in the Exponential Family of Distributions with $c(\theta) = \theta$ , $q(\theta) = -\theta$ , $t(x) = x$ and $h(x) = \mathbb{I}_{[0,+\infty]}(x)$ . Thus, the function $T := T(X) = \sum_{1}^n t(x_i) = \sum_1^nx_i$ is a sufficient and complete statistic function for $\theta$ . ii) It is $\mathbb{E}[X] = 1/\theta$ . Moreover : $$\mathbb{E}(T) = \sum_{i=1}^n\mathbb{E}[X_i]=n\frac{1}{\theta} \implies \mathbb{E}\bigg(\frac{T}{n}\bigg)=\frac{1}{\theta}$$ Thus, the function $T^*(X) = \frac{1}{n}\sum_{1}^n x_i$ is a MVUE for $1/\theta$ as a function of only the sufficient and complete statistic function $T$ . How to continue on finding in a similar way a MVUE for $1/\theta^2$ ? iii) Being asked to calculate : $$\mathbb{E}\bigg\{\bigg(\sum_{i=1}^n x_i \bigg)^{-k}\bigg\}$$ I don't know how to proceed with this one though . Any help, tips or thorough solution would be much appreciated.","['statistical-inference', 'probability-theory', 'probability-distributions', 'statistics', 'probability']"
2798955,Integral $\int_1^3 \frac{\log x}{x^2+3}dx$,"I stumbled upon this integral $$I=\int_1^3 \frac{\log x}{x^2+3}dx$$ Since the answer given by Wolfram-Alpha is $I=\frac{\pi \log 3}{12\sqrt3}$ I tried to work near the bounds of the integral because as a indefinite integral it will involve some polylogarythms which I want to avoid. But not a single substitution 
like $x=\frac{1}{y}$ or $x-2=u$ gave any better look to this integral. And when integrated by parts I feel like it got worse. Could you perhaps help me on this?","['integration', 'definite-integrals', 'calculus']"
2798959,Explicit bijection between $\Bbb R$ and permutations of $\Bbb N$,"The set of permutations of the natural numbers has the cardinality of the continuum. I've got injections in both directions, no problem. The Schröder–Bernstein theorem tells us that this implies the existence of a bijection. I'm wondering if it's possible to construct one explicitly. (In what follows, I'm using the convention that $0\not\in\Bbb N$. This obviously doesn't change anything, cardinality-wise.) For $\Bbb R\to S_\Bbb N$, we note that every real number is the limit of some rearrangement of the alternating harmonic series. If $\alpha\in\Bbb R$, we start with positive terms: $1+\frac13+\frac15+\cdots$, until we obtain a partial sum greater than $\alpha$. We then add negative terms until our partial sum is less than $\alpha$, then we switch back to the positive terms, starting with the first unused one, etc. In this way, we construct a series, and if we take the absolute values of the reciprocals of the terms of it, we have a permutation of $\Bbb N$. This mapping is not onto , because many permutations of the series converge to $\alpha$ - all we have to do is ""overshoot"" at some point, and then continue converging to $\alpha$ as usual. (More trivially, we only get permutations with $\sigma(1)=1$ using this particular construction.) In the other direction, if we have a permutation $\sigma\in S_\Bbb N$, we can write the continued fraction $[\sigma(1);\sigma(2),\sigma(3),\ldots]$. This actually injects $S_\Bbb N$ into $\Bbb R\setminus\Bbb Q$, because non-terminating continued fractions represent irrational numbers. Thus, this mapping is not onto; it is not even onto the irrationals.For example, no permutation of $\Bbb N$ maps in this way to any quadratic irrational, or to $e$, or to any other irrational whose c.f. expansion has repeated terms. So, those injections are fun and all, but finding an explicit bijection seems hard. Clearly, a bijection between $S_\Bbb N$ and any interval would suffice, because there are standard, elementary ways to construct bijections between $\Bbb R$ and any interval. I have Googled in vain for a solution, and I don't believe this question is a duplicate. I will be happy for a hint or a full solution, or an explanation of why such an explicit construction is impossible. Full disclosure: someone online claimed that this is ""not hard"", but refused to explain how, other than mentioning the Cauchy sequence construction of the reals. I don't see how that's useful, and I think he's mistaken or bluffing. I'm not too proud to admit I'm stumped. :/","['permutations', 'elementary-set-theory']"
2798976,Is this space $S^3$?,"I learned here that if we glue two copies of the solid tori together along their boundary, we get $S^3$. What happens if the gluing map is more complicated? In particular, recall that each $A \in \mathrm{GL}_2(\mathbb{Z})$ gives a homeomorphism $T^2 \rightarrow T^2$. Suppose we glue two solid tori along this map, would we still get $S^3$? If not, what would we get? Can its homotopy or homology groups be computed?","['algebraic-topology', 'general-topology', 'fundamental-groups', 'homology-cohomology']"
2799106,Iterations of the radical of an integer,"We denote for an integer $n>1$ its square-free kernel as $$\operatorname{rad}(n)=\prod_{\substack{p\mid n\\p\text{ prime}}}p,\tag{0}$$
with the definition $\operatorname{rad}(1)=1$. You can see this definition and the properties of this arithmetic function from the Wikipedia Radical of an integer . Then I wondered about a variant of two problems showed in last paragraphs of section B 41 of Guy's book [1]. Definition. For each fixed integer $n\geq 1$, I consider the arithmetic function $$f(n)=f^1(n):=\operatorname{rad}(n)+1,\tag{1}$$
and we create the iterated $$f^{k+1}=f(f^{k}(n))\tag{2}$$
until $f^{T}(n)$ reaches a prime number, here thus $T=T(n)$ is a function depending on $n$ (that is the number of steps in our iteration that we need to wait until the sequence of iterated $f^{k}(n)$ reaches a prime number 
for the first time). We can call stopping time to the arithmetic function $T(n)$ (defined thus for integers $n\geq 1$ and taking positive values). Example 1. Let $n=1$, then in a step the sequence of iterations reaches a prime number since $f(1)=f^1(1)=\operatorname{rad}(1)+1=1+1=2$ is a prime number. The same argument works with the composite number $n=8$, because $f(8)=f^1(8)=\operatorname{rad}(8)+1=2+1=3$ a prime number. Thus in our table $T(1)=1$ iteration, and also in this example we've seen that the corresponding  sequence defined for the integer $8$ has stopping time $T(8)=1$. Example 2. We work about the calculation of $T(33)$. We iterate while the result is a composite integer. Here $\operatorname{rad}(33)=33$, thus $f(33)=34$ and since $34=2\cdot 17$ is also square-free then $f^2(33)=f(f(33))=34+1=35$. Again our last iterated, that is $35=5\cdot 7$ has no repeated prime factors, thus we write $f^3(33)=f(35)=36$. Finally $f^4(33)=\operatorname{rad}(36)+1=6+1=7$ that results a prime number. Thus we conclude that $T(33)=4$. Computational fact. I did few experiments/calculations and seems that the arithmetic function $T(n)$ is erratic, thus it makes sense to study averages of consecutive values of this stopping time. Question. I would like to know if it is possible to deduce a tighter upper bound for $$\frac{1}{N}\sum_{1\leq n\leq N}T(n)\tag{3}$$
  as $N$ grows (if you are able to provide an elaborated statement about the asymptotic behaviour of $(3)$ as $N\to\infty$ feel free to do it). Many thanks. Final remarks. My motivation was to propose a similar variant of the mentioned problems in Guy's book, now for other interesting arithmetic function $\operatorname{rad}(n)$. I've no idea about a strategy to attack the problem to get idea about the size of the average means of the $T(n)$. References: [1]  Richard K. Guy, Unsolved Problems in Number Theory , Volume I, Second Edition, Springer (1994).","['analytic-number-theory', 'asymptotics', 'recursion', 'prime-numbers', 'sequences-and-series']"
2799146,Evaluate the limit with exponents using L'Hôpital's rule or series expansion,"Evaluate the limit$$\lim_{x\to 0}\dfrac{\left(\frac{a^x+b^x}{2}\right)^{\frac{1}{x}}
-\sqrt{ab}}{x}$$ It is known that $a>0,b>0$ My Attempt: I could only fathom that  $$\lim_{x\to 0}\left(\frac{a^x+b^x}{2}\right)^{\frac{1}{x}}=\sqrt{ab}$$","['calculus', 'limits']"
2799148,"If $f$ is uniformly continuous and integrable, then $\lim_{x\to \infty }f(x)=0$.","Let $f$ an integrable function (i.e. $L^1(\mathbb R)$). Suppose $f$ is uniformly continuous. Prove that $$\lim_{|x|\to \infty }f(x)=0.$$ If suppose first that $\ell:=\lim_{|x|\to \infty }f(x)$ exist. By contradiction, I suppose $\ell\neq 0$, and suppose WLOG that $\ell>0$. Using continuity, there is $M>0$ such that $f(x)>\frac{\ell}{2}$ for all $x\geq M$. Therefore, $$\int_{\mathbb R} f(x)dx=\int_{|x|>M}f(x)+\int_{[-M,M]}f(x)\geq \frac{\ell}{2}\int_{|x|>M}dx+C=+\infty ,$$
what contradict $f$ integrable. Q1) Is it correct ? Q2) How can I do if I don't suppose that $\lim_{|x|\to \infty }f(x)$ exist ?","['real-analysis', 'integration', 'lebesgue-integral']"
2799168,"What is the genus of compact Riemann surface: $\Sigma =\{[X,Y,Z]\in \mathbb{C}P^2: Z^2=XY\}.$","What is the genus of compact Riemann surface: $$\Sigma =\{[X,Y,Z]\in \mathbb{C}P^2: Z^2=XY\}.$$ I try to use the Riemann-Herwitz Formula $f: \Sigma \rightarrow \mathbb{S},$
we have $$2g(\Sigma)-2=B_{p}(f)-2\deg(f),$$
where $g(\cdot)$ means the genus and $B_{p}(f)$ is the branch number of $f$ at point $p$. I know how to calculate the genus of $\Sigma=\{[X,Y,Z]\in \mathbb{C}P^2: X+Y+Z=0\}$, but how to get the genus of a nonlinear polynomial $\Sigma =\{[X,Y,Z]\in \mathbb{C}P^2: Z^2=XY\}?$","['algebraic-curves', 'riemann-surfaces', 'algebraic-geometry', 'geometry']"
2799181,"Is there a way to express the set-theoretic limit in terms of topology, filters or ultrafilters?","The way limits are defined in Set Theory (lim sup = lim inf or limits of indicator functions) looks at odds compared to general definitions in term of topology, filters or ultrafilters. Ref: https://en.wikipedia.org/wiki/Set-theoretic_limit . Is there a way to express it similarly to general topological limits? Or the other way around (limits of sequence of real numbers considered as Dedekind cuts actually coincide with Set-theoretic limits)?","['general-topology', 'elementary-set-theory', 'limits']"
2799212,"Counterexample: If $\sum_{n=1}^{\infty}a_n=1$ and each $a_n\geq 0,$ then $\lim\limits_{n\to}na_n=0$","I'm studying for an exam and I ran into these problems. I'm having a feeling that this is not true. Hence, I don't need to prove. I need to just provide a counterexample. However, the appropriate example is not just coming. Any help? Prove or give a counterexample: If $\sum_{n=1}^{\infty}a_n=1$ and each $a_n\geq 0,$ then $\lim\limits_{n\to\infty}na_n=0$ If $a_n\geq 0$ and $\sum_{n=1}^{\infty}a_n$ converges, then $\lim\limits_{n\to\infty}na_n=0$","['real-analysis', 'sequences-and-series', 'analysis', 'limits']"
2799273,What are necessary and sufficient conditions for a supremum to be a limit point?,"A question in similar spirit has already been asked here , but was wrongly accepted. Consider the case $A = \{0, 1, 2\} \subset \mathbb{R}$, this has $\sup(A) = 2$, but $2$ is not a limit point of $A$. Note that the answer to this question could be sensitive to the definition of limit, so I give the definition from (Croom 1989):
Let $(X,T)$ be a topological space and $A \subset X$, a point $x \in A$ is called a limit point of A if every open set containing $x$ contains a point of $A$ distinct from A. A sufficient condition would be that the supremum does not lays in $A$, e.g. $A = (0,1)$ has $\sup(A) = 1$ and $1$ is a limit point of $
A$.
But it is not a necesary condition (consider $[ 0, 1 ]$). Can we say that the supremum is either a maximum or a limit point?","['general-topology', 'supremum-and-infimum', 'limits']"
2799301,Holomorphic function which is zero at every lattice point,"Suppose that $f:\mathbb C \to \mathbb C$ is holomorphic and not identically zero, and that $f$ has a zero at every lattice point (point with integer coordinates) except for $(0,0)$. Show that there is a constant $c>0$ such that $|F(z_i)|>e^{c|z_i|^2}$ for a sequence $z_1,z_2,\ldots$ of complex numbers tending to infinity. If we take the supremum of $F$ over each circle of radius $R$, this should give a correct sequence (taking $R=1,2,\ldots$). I am not sure how to come up with a lower bound though.",['complex-analysis']
2799323,"Prove that for a family of $100n$ subsets of a $[n]$ such that each subset has size $m$, there exists two whose intersection is at least $m^2/10n$.","Let $A_1, \ldots, A_k$ be subsets of $\{1, \ldots, n\}$ such that $|A_i| = m$ for each $i = 1,\ldots,k$ and $k>100n$. Prove that there exists two distinct sets $A_i, A_j$ such that $|A_i\cap A_j| \geq \frac{m^2}{10n}.$ I found this problem in the book Introduction to Theoretical Computer Science by Boaz Barak. Here's my attempt:
Suppose for contradiction that every pair of subsets satisfies $|A_i\cap A_j| < \frac{m^2}{10n}$. Then
$$\sum_{1\leq i < j \leq k}|A_i\cap A_j| < {k\choose 2}\frac{m^2}{10n}.$$
It's also known from the principle of inclusion-exclusion that 
$$\left|\bigcup_{i=1}^k A_i\right| \geq \sum_{i=1}^k|A_i| - \sum_{1\leq i < j \leq k}|A_i\cap A_j|.$$
Then
$$n\geq \left|\bigcup_{i=1}^k A_i\right| \geq \sum_{i=1}^k|A_i| - \sum_{1\leq i < j \leq k}|A_i\cap A_j| \geq km - {k\choose 2}\frac{m^2}{10n}$$
$$n^2 + {k\choose 2}\frac{m^2}{10n}\geq km.$$
I'm not sure how to proceed from here since it's pretty clear that the left side is bigger than the right side for large $n, m, k$ since it has a higher degree.
Thanks in advance for any help.","['pigeonhole-principle', 'combinatorics', 'inequality']"
2799325,Self-adjoint operator with increasing sequence of eigenvalues,"The spectral theorem says that if $A$ is a self-adjoint operator on a Hilbert space $H$ with compact inverse, then the eigenvectors of $A$ form a complete orthonormal basis of $H$. Furthermore each eigenvalue is real and $|\lambda_n|\to\infty$ as $n\to\infty$. Now let us slightly change the conditions of the theorem. Let $A$ be a self-adjoint operator with increasing sequence of eigenvalues $0<\lambda_1<\lambda_2<...$ Is it true that the eigenvectors of $A$ form a complete orthonormal basis of $H$?","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'adjoint-operators']"
2799393,Laplace Equation on Rectangle & Fourier Series,"I am trying to solve the Laplace Equation on the rectangle. Namely, I trying to solve the following PDE problem: Solve the equation $\Delta u = 0$ on the rectangle $R = \{(x, y): 0\leq x \leq a, \hspace{2mm} 0\leq y \leq b\}$ subject to $u(x,0) = f(x)$, $u(x, b) = 0$, $u(0, y) = 0$ and $u(a, y) = 0$. I have separated variables and used the first three boundary conditions to obtain $$u(x, y) = \sum_{n= 1}^{\infty} c_n \sin\left(\frac{n\pi x}{a}\right)\sinh\left(\frac{n\pi (b-y)}{a}\right)$$ Now it is the final boundary condition that seems strange. I am reading how it has been dealt with Olver's introduction book to PDEs. His argument goes as follows: We want $$u(x, 0) =:f(x) =  \sum_{n= 1}^{\infty} c_n \sinh\left(\frac{n\pi b}{a}\right)\sin\left(\frac{n\pi x}{a}\right)$$ and this looks like the fourier sine series for $f(x)$. So let $$b_n = \frac{2}{a} \int_0^a f(x) \sin\left(\frac{n\pi x}{a}\right)dx$$ then $c_n = \frac{b_n}{\sinh\left(\frac{n\pi b}{a}\right)}$. But the issue I have here is that does the fact that $f$ has a fourier sine series not assume/imply that the function $f$ is odd? How is this possible - was the choice of $f$ not arbitrary? So the PDE problem could have been posed with a specific function for $f$ where $f$ is instead even and then this does not make sense anymore?","['harmonic-functions', 'fourier-series', 'fourier-analysis', 'partial-differential-equations', 'ordinary-differential-equations']"
2799441,Extreme value theory - proof this is a poisson point process,"Let $(X_n)_{n \geq 1}$ be an i.i.d sequence of real valued RVs with continous distribution function f and $M_n:=\max \{X_1,...,X_n \}$. Let $U_n:=\inf \{ k \in \mathbb{N} | X_k>X_{U_{n-1}} \}$ be the n-th ""record time"" (with $U_0=1$) Define (simple) point processes $N_n:= \sum_{k \geq 1} \delta_{U_k/n}$.(with delta being the dirac measure) Are these $N_n$ poisson point processes? If so, what is their intensity measure. So far I've shown that for disjoint sets $(A_k)$ $(N_n(A_k))$ are independent for all n, but im still missing the distribution property","['stochastic-processes', 'extreme-value-theorem', 'probability-theory', 'poisson-process', 'probability']"
2799480,Are integral curves of a vector field $X$ such that $\nabla_X X = 0$ geodesics?,"Let $(M,g)$ be a riemannian manifold, $X$ a vector field of $M$ and $\gamma \colon M \to \mathbb{R}$ an integral curve of $X$ that is $\gamma'(t) = X(\gamma(t))$. Assume also that the Levi-Civita connection $\nabla_X X = 0$ where Are the integral curves of a $X$ geodesics? I believe is true. A curve $\gamma$ of $M$ is a geodesic if and only if the covariant derivative $\nabla_{\gamma'(t)}\gamma'(t) = 0$. But since $\gamma$ is an integral curve of $X$, just plugging $X(\gamma(t))$ in the connection and using the hypothesis that $\nabla_X X = 0$ gives the result. Is this correct?","['smooth-manifolds', 'vector-fields', 'ordinary-differential-equations', 'riemannian-geometry']"
2799488,"Independent of $\sigma(X_{1})$ implies measurable with respect to $\sigma(X_{2},X_{3},\dots)$?","Suppose $(\Omega,\mathcal{F},\mathbb{P})$ is a probability space supporting iid random variables $\{X_{n}\}_{n \in \mathbb{N}}$.  Moreover, assume $\mathcal{F} = \sigma(X_{1},X_{2},\dots)$.  If $Y$ is a $\mathcal{F}$-measurable random variable and it is independent of $\sigma(X_{1})$, can we say that $Y$ is $\sigma(X_{2},X_{3},\dots)$-measurable?","['independence', 'probability-theory']"
2799491,Showing that a number is prime if norm is prime,"Suppose that $\alpha\in\mathbb{Z}[i]$, and $N(\alpha)=\alpha .\bar{\alpha} =p$ (norm), a prime in $\mathbb{Z}$. Then show that
  $\alpha$ is a prime in $\mathbb{Z}[i]$. My attempt: Let $\alpha|ab$ for some $a,b\in\mathbb{Z}[i]$ and if we assume that,  $\alpha\not| b$ and $\alpha\not| a$ then $N(\alpha)\not|N(a)$ and $N(\alpha)\not|N(b)$ (I showed this using the fact that $\mathbb{Z}[i]$ is a euclidean domain). But this is a contradiction as $\alpha|ab\Rightarrow N(\alpha)|N(a)N(b)\Rightarrow N(\alpha)|N(a)$ or $N(\alpha)|N(a)$. Is the approach correct? Can anyone suggest some alternatives? Thank You.","['number-theory', 'ring-theory']"
2799500,Tensor product of ultrafilters corresponds to iterated limit,"I will use letters such as $p$, $q$ for filters (or ultrafilters). I want to ask about correspondence between iterated limit and $p\otimes q$-limit, but let me start by mentioning the relevant definitions and notation.
$\require{begingroup}\begingroup\newcommand{\Flim}[2]{\lim\limits_{#1\to#2}}$ Tensor product. Let $p$ be a filter on a set $X$, $q$ be a filter on a set $Y$. Then the system
$$\{A\subseteq X\times Y; \{x; \{y; (x,y)\in A\}\in q\}\in p\}$$
is a filter on $X\times Y$. This filter is called tensor product or Fubini product of the filters $p$ and $q$ and denoted by $p\otimes q$. If we denote $A_x=\{y; (x,y)\in A\}$ the $x$-cut of the set $A$, then we can say more briefly
$$A\in p\otimes q \Leftrightarrow \{x; A_x\in q\}\in p.$$
For people who are used to work with filter quantifiers 1 this can also be expressed as
\begin{align*}
A\in p\otimes q
&\Leftrightarrow (\forall_p x) A_x\in q \\
&\Leftrightarrow (\forall_p x) (\forall_q y) (x,y)\in A \\
\end{align*} It can be shown that if both $p$ and $q$ are ultrafilters , so is $p\otimes q$. Limit along a filter. If $p$ is a filter on $X$, $T$ is a topological space and $f\colon X\to T$, then we say that $\ell$ is $p$-limit of $f$ and write
$$\Flim xp f(x)=\ell$$
if for every neighborhood $U$ of $\ell$ the preimage $f^{-1}[U]$ belongs to $p$, i.e.,
$$f^{-1}[U]=\{x\in X; f(x)\in U\}\in p.$$
This notion generalizes various types of limits. Some links to further references are given below. 2 For the sake of simplicity, we will always assume that $T$ is Hausdorff, which gives us uniqueness of the $p$-limit. An important property is that if $p$ is an ultrafilter and $T$ is compact, then the $p$-limit exists. Correspondence. Let $f\colon X\times Y\to T$, where $T$ is a compact Hausdorff topological space. Then for any two ultrafilters $p$ on $X$ and $q$ on $Y$, we have
$$\Flim xp \Flim yq f(x,y) = \Flim{(x,y)}{p\otimes q} f(x,y)$$
in the sense the limit on the one side of the above equality exists, then so does the other one and the limits are equal to each other. In fact, the above property characterizes the tensor product of ultrafilters. (In the sense that there exists unique ultrafilter on $X\times Y$ with the above properties. To see this it suffices to take $T=\{0,1\}$ with discrete topology and notice that $\Flim xp \chi_A(x)=1$ iff $A\in p$, so if we know limits of indicator functions, this uniquely determines the filter.) If we only require $p$ and $q$ to be filters, then the existence of the iterated limit implies the existence of $p\otimes q$-limit. (But not conversely.) For this implication we can also omit the assumption that $T$ is compact. When I searched for some references for this fact, I was able to find some places mentioning that
$$p\otimes q = \Flim{(x,y)}{p\otimes q} (x,y)$$
for any $p\in\beta X$, $q\in\beta Y$; where we consider $X$, $Y$ endowed with the discrete topology and the ultrafilters are viewed as points of the Stone-Čech compactification . I found this claim for example as Lemma 11.2 in Hindman-Strauss: Algebra in the Stone-Čech Compactification (2nd edition). (The proof is left to the reader as an exercise.) This is a special case of the above result if $f = e_X\times e_Y \colon X\times Y \to \beta X\times\beta Y$ is product of embeddings into the corresponding compactifications. Maybe also the above result can be deduced from this, although I do not see an immediate way to show this. Questions. I am interested both in references for this result and in a proof. (I have included my own proof as an answer, if there are alternative proofs or if my proof can be simplified, I'd be glad to learn about that.) It would also be nice to know whether some assumptions can be omitted. (But I do not think that it's possible to go too far beyond for what I have already mentioned - that in one direction you only need filters rather than ultrafilters and also the compactness assumption can be omitted.)
$\endgroup$ 1 See also this question and references there: References on filter quantifiers . 2 For some references related to limit along filter (or filterbase) see Where has this common generalization of nets and filters been written down? or Basic facts about ultrafilters and convergence of a sequence along an ultrafilter .","['general-topology', 'set-theory', 'convergence-divergence', 'filters']"
2799513,"The Chicken McNuggets Problem, as it relates to ideals and Grobner bases in algebraic geometry [closed]","Closed. This question is off-topic . It is not currently accepting answers. Closed 6 years ago . This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. This question is not about mathematics, within the scope defined in the help center . Improve this question I am studying a course in algebraic geometry. I was given an introduction to the Chicken McNuggets problem, and I've been asked to discuss it within the algebraic geometry principals of ideals and Grobner bases. I am asking for some references and books so I could understand this problem and write on it. I would like some help, please.",['algebraic-geometry']
2799528,"Expected value of $\sin(X)$, where $X$ is a Cantor random variable","Let $X$ be a random variable with Cantor distribution . Find $\mathbb{E} \sin(X)$. I thought about representing $$X = \sum \frac{X_i}{3^i}$$ where $X_{i} \in \{0, 2\}$, but I guess it's not easy to compute the sine of a sum of random variables. Maybe it's better to compute via the definition? Any hints?","['probability-theory', 'expectation']"
2799541,On Kelvin-Stokes proof without differential forms,"I was reading a proof of the Kelvin-Stokes theorem (without differential forms) and the first step was defining a Jordan curve $\gamma:[a,b]\rightarrow\mathbb{R}^2$ and a surface $\psi:D\rightarrow\mathbb{R}^3$ where $D$ is the interior of the curve (i.e. the compact portion of $\mathbb{R}^2$). The surface is $S:=\psi(D)$ and the surface boundary is defined $\Gamma(t)=\psi(\gamma(t))$. 
Then, by definition of line integral we have
\begin{align*}
\oint_{\partial S=\Gamma}\vec{F}\cdot\vec{d\vec{\Gamma}} & = \int\limits_{a}^b\big\langle(F\circ\Gamma(t))|\frac{d\Gamma}{dt}(t) \big\rangle dt
\\ & = \int\limits_{a}^b \big\langle(F\circ\Gamma(t))|\frac{d(\psi\circ\gamma)}{dt}(t) \big\rangle dt
\\ & = \int\limits_{a}^b \big\langle(F\circ\Gamma(t))|(J_\psi)_{\gamma(t)}\cdot\frac{d\gamma}{dt}(t) \big\rangle dt
\end{align*}
Where $J_\psi$ is the Jacobian matrix of $\psi$. 
I'm not sure what $(J_\psi)_{\gamma(t)}$ means though, or why it can be used here. Also, the next few lines of the proof are \begin{align*}
\big\langle(F\circ\Gamma(t))|(J_\psi)_{\gamma(t)}\cdot\frac{d\gamma}{dt}(t) \big\rangle &  = \big\langle(F\circ\Gamma(t))|(J_\psi)_{\gamma(t)}|\frac{d\gamma}{dt}(t) \big\rangle\
\\ & = \big\langle(^tF\circ\Gamma(t))\cdot(J_\psi)_{\gamma(t)}|\frac{d\gamma}{dt}(t) \big\rangle
\end{align*} I'm wondering why the ""|"" symbol is moving around in the interior product, and also what the superscript $t$ in $(^tF)$ means.","['multivariable-calculus', 'stokes-theorem', 'proof-explanation']"
2799553,Prove that only units of $\Bbb Z[\sqrt d] $ are $\pm 1$.,"Let $d(\in \Bbb Z)<-1$ such that $d$ is not divisible  by the square of a prime.
  Prove that only units of $\Bbb Z[\sqrt d] $  are $\pm 1$. $$a+b\sqrt d \text{ is a unit }\implies (a+b\sqrt d)(c+e\sqrt d)=1\implies (a^2-db^2)(c^2-de^2)=1\implies a^2-db^2=\pm 1\implies a+b\sqrt d=\pm1\implies a+b\sqrt d \text{ is a unit}$$ Where did we use that $d$ is not divisible  by the square of a prime. Is my proof wrong?","['number-theory', 'abstract-algebra', 'algebraic-number-theory']"
2799556,Understanding the $\mathrm{d}x$ in integrals,"The integral is usually introduced as an extension of the Riemann sum, i.e. $$
\lim_{n\to\infty}\sum_{i=0}^n f(x_i)\,\Delta x_i = \int_a^b f(x)\,\mathrm{d}x
$$ with the usual explanation that $\sum \to \int$ (finite sum to infinite sum) and $\Delta x \to \mathrm{d}x$ (finite element to infitesimal element). This is a nice intuitive explanation, but it doesn't explain what $\mathrm{d}x$ is. Attempting to read the definition of a differential gives a very broad and general definition that does not seem to be immediately applicable to integrals. However, these $\mathrm{d}$-things appear in different settings as well, such as probability theory 
$$
\int_{\mathbb{R}} \mathrm{d}F(x)
$$
and differential equations (and variable substitution)
$$
\frac{\mathrm{d}y}{\mathrm{d}x} = x
\iff \mathrm{d}y = x\,\mathrm{d}x
\iff \int\mathrm{d}y = \int x\,\mathrm{d}x
$$
with no apparent connection to the original $\Delta x$. This may be confusing, and does only appear to complicate things unnecessarily. It would also seem possible to define all these concepts without this $\mathrm{d}$-thing:
$$
\lim_{n\to\infty}\sum_{i=0}^n f(x_i)\,\Delta x_i = {\Large\mathcal{I}}_a^b f(x)
\\ {\Large\mathcal{I}}_a^b F'(x)
\\ \frac{\mathrm{d}y}{\mathrm{d}x} = x \iff {\Large\mathcal{I}}y' = {\Large\mathcal{I}}x
$$ So what is the purpose of the $\mathrm{d}$-things? Is it just a historical artefact, or is it possible to assign some intuition and purposeful meaning to $\mathrm{d}x$ without appealing to too abstract concepts in differential geometry? Maybe a simplified version that's easily explained and applicable to integrals. It seems clear that in some cases this cannot be remedied by making an alternative integration function ${\Large\mathcal{I}}$, as there are fields where $\mathrm{d}x$ does appear to have some meaning:
$$
\int_{\partial\Omega}\omega = \int_\Omega \mathrm{d}\omega
$$
(unless this is just deceivingly similar notation to normal integration.) So how can one motivate the usage of $\mathrm{d}$ that is accessible when one first encounters integrals, but does not cause confusion when encountering it later? I.e. are there any intuitions besides $\Delta x\to \mathrm{d}x$ that gives insight into the interpretation of $\mathrm{d}x$?","['integration', 'differential-forms']"
2799563,Vector Laplacian on Manifolds,"I'm trying to understand some basics of calculus on a surface (i.e. a 2-manifold in $\mathbb{R}^3$ ), without having much knowledge in differential geometry (so from an engineer's perspective). I am not able to get much about how the vector Laplacian on surfaces is defined. There was a similar question here , but the answer there seems to be above my pay grade. Let's say we have a (sufficiently smooth) surface $S \subset \mathbb{R}^3$ , and (sufficiently smooth) functions $u: S \rightarrow \mathbb{R}$ , $\vec{v}: S \rightarrow \mathbb{R}^3$ . Then, from a lay-man's perspective, for the projection operator(which removes the normal component) $P = \mathbf{I} - \mathbf{n}\mathbf{n}^T$ , the surface derivatives can be defined as \begin{align}
\nabla_S u &= P\nabla u = \text{(say) } \left( \begin{array}{c} D_1u \\ D_2 u \\ D_3 u \\ \end{array}\right) \\
\nabla_S \cdot \vec{v} &= P\nabla \cdot \vec{v} = D_1v_1 + D_2v_2 + D_3v_3\\
\Delta_S u &= \nabla_S \cdot \nabla_S u = D_1D_1u + D_2D_2u + D_3 D_3u
\end{align} There seem to be multiple definitions for the Laplacian of a vector field Wiki Page . Two specific ones are what I am trying to understand. The Bochner Laplaican, and the Hodge Laplacian (since those are the ones used in the context I need). There is also a third one here (starting after equation 1.1, till equation 1.3) that has me a bit confused. Can any of them be understood in a way similar to the surface gradient/surface divergence/Laplace beltrami of a scalar field written above? Is any of them simply a component wise Laplace-Beltrami operator? \begin{equation}
\left( \begin{array}{c} 
\Delta_S v_1 \\ \Delta_S v_2 \\ \Delta_S v_3 \\ \end{array}\right)?
\end{equation} Another way to look at this is to ask if we can define a Vector Laplacian on a 2-manifold in 3-space without going in to the differential geometry formalism. i.e. using cartesian coordinates only.","['differential-topology', 'calculus', 'manifolds', 'differential-geometry', 'surfaces']"
2799567,How to prove that if $AB = A + B$ then $\frac{\lambda}{\lambda - 1}$ is an eigenvalue for $A$?,"I'm struggling with a problem in linear algebra where I have to prove that: Given $AB = A + B$ and $ 1 \notin \sigma (A) \cup \sigma(B)$ where $\sigma$ represent the spectrum of a Matrix and $\lambda \in \sigma(B)$ then the quotient :  $\frac{\lambda}{\lambda - 1}$ is an eigenvalue for A (  $\frac{\lambda}{\lambda - 1} \in \sigma(A)$ ) I have proved before this that A is invertible iff B is invertible, it has also asked me to prove that : $$\prod\limits_{\lambda_i \in \sigma(A)}(\lambda_i - 1)  \prod\limits_{\lambda_i \in \sigma(B)}(\lambda_i - 1) = 1$$ But I couldn't find a way to do it, how can I prove both questions ?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2799575,Counting pairs of multisets with prescribed discrepancy,"It has been explained here many times that $n$ indistinguishable sweets can be distributed to $r$ children in ${n+r-1\choose r-1}$ ways. Given two such allocations (multisets) $x=(x_i)_{1\leq i\leq r}$ and $y=(y_i)_{1\leq i\leq r}$  we can look at their discrepancy $$\sum_{i=1}^r|x_i-y_i|=:2d\geq0$$
(an even number). The question is: How many pairs $(x,y)$ of multisets of cardinality $n$ over the set $[r]$ are there, having given discrepancy $2d>0$? This question (in a somewhat different disguise) has been asked here a few days ago, but unfortunately got  closed before anybody had time to come up with a hint, let alone a full solution. I'm convinced this is a novel and challenging problem, off the standard stars and bars route. Therefore I dare to post it again, this time with the added context of sweets $\ldots$",['combinatorics']
2799576,Integral results in difference of means $\pi(\frac{a+b}{2} - \sqrt{ab})$ [duplicate],"This question already has answers here : Can we prove AM-GM Inequality using these integrals? (3 answers) Closed 2 years ago . $$\int_a^b \left\{ \left(1-\frac{a}{r}\right)\left(\frac{b}{r}-1\right)\right\}^{1/2}dr = \pi\left(\frac{a+b}{2} - \sqrt{ab}\right)$$ What an interesting integral! What strikes me is that the result involves the difference of the arithmetic and geometric mean. Is there an innate geometric explanation that corresponds to this result? And can we generalize this integral to, say, the mean of three or more items? Some background on where I saw it and how to solve it. This arises in calculating the action variable $I$ for the Kepler problem (Hamiltonian $H=\frac{p_r^2}{2m}+\frac{p_\phi^2}{2mr}-\frac{k}{r}$ ). The $a,b$ are the minimal and maximal $r$ from the origin set at the focus of an ellipse (i.e. the perihelion/aphelion). See David Tong's Classical Dynamics notes $\S$ 4.5.4. I was able to solve the integral by using the third Euler substitution, letting $$\left\{ \left(1-\frac{a}{r}\right)\left(\frac{b}{r}-1\right)\right\}^{1/2}=\frac{1}{r}\sqrt{-(r-a)(r-b)}=\frac{1}{r}(r-a)t$$ giving $r=\frac{b+at^2}{1+t^2}$ and $$2(b-a)\left\{\int_{t(r_2)=0}^{t(r_1)=\infty}\frac{t^2}{(1+t^2)^2}dt - \int_{t(r_2)=0}^{t(r_1)=\infty}\frac{\frac{a}{b}t^2}{(1+t^2)(1+\frac{a}{b}t^2)}dt\right\}$$ $$=\pi\left(\frac{b-a}{2}\right) + \pi\left(a-\sqrt{ab}\right)=\pi\left(\frac{a+b}{2} - \sqrt{ab}\right).$$","['means', 'mathematical-physics', 'integration', 'definite-integrals', 'conic-sections']"
2799580,"Integrability of supremum of continuous, integrable functions over compact space","Consider a function $f: \mathbb{R}^d \times \mathbb{R}^k \to \mathbb{R}_+$, such that $(\theta, x) \mapsto f(\theta, x)$ is continuous, and $x \mapsto f(\theta, x)$ is Lebesgue integrable for every $\theta \in \mathbf{R}^d$. Let now $\Theta \subseteq \mathbf{R}^d$ be compact. I am trying to prove that the supremum function $g(x) := \sup_{\theta \in \Theta} f(\theta, x)$ is Lebesgue integrable as well. Anyone that can help? Many thanks in advance.","['integration', 'probability', 'measure-theory']"
2799627,Convergence of series with integral inside,"$\sum_{n=1}^\infty (-1)^{n+1} \int_{n}^{n^2}\frac{dx}{x^6+1}$ First time i see integral inside the series. Need to just prove convergence, so i don't think there is a need to integrate and count it all. Is there any fast methods to work with it?","['integration', 'sequences-and-series', 'convergence-divergence']"
2799661,Definition of a Lie group representation of a Hilbert Space,"Let $G$ be a real Lie group, and $V$ a Hilbert space.  Wikipedia defines a unitary representation of $G$ on $V$ to be a homomorphism of $G$ into the group of unitary operators of $V$ such that for each $v \in V$, the map $g \mapsto \pi(g)v$ is continuous, where $V$ is given its norm topology. On the other hand, many places for example here (page 23, proposition 5.5(2)) seem to define a Hilbert space representation as one for which the product mapping $G \times V \rightarrow V, (g,v) \mapsto \pi(g)v$ is continuous. Are these inequivalent definitions?  Or does each $g \mapsto \pi(g)v$ being continuous imply the continuity of $(g,v) \mapsto \pi(g)v$?  Maybe by some application of the uniform boundedness principle.","['functional-analysis', 'hilbert-spaces', 'lie-groups']"
2799732,"Number of ways to represent $100$ as a sum of $1, 5, 10, 25$","In how many ways can you represent $100$ as a sum using only these numbers: $1, 5, 10, 25$ if the order does not matter? What if the order did matter? My solution: Let the power of $x$ denote our current sum. We need to take any number of ones, fives, tens and twenty-fives as we need, just to get the exponent of $x$ to be $100.$ The generating function will be:
$$f(x) = (x^0 + x^1 + x^2 + \dots)(x^0 + x^5 + x^{10} + \dots)(x^0+x^{10}+x^{20} +\dots)(x^0 + x^{25}+x^{50}+ \dots) = \frac{1}{(1-x)(1-x^5)(1-x^{10})(1-x^{25})}$$
We need to take the coefficient at $x^{100}$, which is $242$. Now, if the order did matter, then we would have to consider sequences instead of multisets, and so the generating function would be
$$g(x) =\sum_n(x+x^5+x^{10}+x^{25})^n$$
And now the coefficient would be $
8 577 828 731 901$. Well, there is a slight difference between these numbers and so - my question is - is my method of solving this correct? If so, I guess that this enormous numbers derives from very large factorials.","['generating-functions', 'combinatorics', 'analytic-combinatorics']"
2799739,Limit involving Series and Greatest Integer Function,"If $[$.$]$ denotes the greatest integer function, then find the value of $\lim_{n \to \infty} \frac{[x] + [2x] + [3x] + … + [nx]}{n^2}$ What I did was, I wrote each greatest integer function $[x]$ as $x - \{x\}$, where $\{.\}$ is the fractional part. Hence, you get $\lim_{n \to \infty} \frac{\frac{n(n+1)}{2}(x-\{x\})}{n^2}$ The limit should then evaluate to $\frac{x-\{x\}}{2}$ But the answer given is $\frac{x}{2}$. What am I missing here?","['limits', 'fractional-part', 'limits-without-lhopital', 'sequences-and-series', 'ceiling-and-floor-functions']"
2799765,Correspondance between finite index subgroups of $\mathbb{Z}^{2}$ and regular coverings of the Torus,"Suppose we let $G = \mathbb{Z}^{2} = \left<x,y \mid xyx^{-1}y^{-1}\right>$ for $x = (1,0)$, and $y=(0,1)$. Then for a given index $n \in \mathbb{Z}$, we can find all index $n$ subgroups of $G$ by considering all lattices $\left<{(r,0),(p,q)}\right>_{\mathbb{Z}}$ for $r\cdot q = n$, and $0\leq p < r$. This comes from the smith normal form of a finitely generated-submodule of a free module (considering abelian groups as $\mathbb{Z}$-modules). For example, consider the index 4 subgroups, we get a subgroup for every combination $(r,p,q)$ such that $r,p,q \in \mathbb{Z}_{\geq 0}$, $r\cdot q = n$ and $0 \leq p < r$. This gives the subgroups: \begin{align*}
& \Lambda_{1} = \left<{(4,0),(0,1)}\right>_{\mathbb{Z}} && \Lambda_{2} = \left<{(4,0),(1,1)}\right>_{\mathbb{Z}} && \Lambda_{3} = \left<{(4,0),(2,1)}\right>_{\mathbb{Z}} & \\
& \Lambda_{4} = \left<{(4,0),(3,1)}\right>_{\mathbb{Z}} && \Lambda_{5} = \left<{(2,0),(0,2)}\right>_{\mathbb{Z}} && \Lambda_{6} = \left<{(2,0),(1,2)}\right>_{\mathbb{Z}}
\end{align*} Then since $G$ is abelian, every subgroup of $G$ is normal, and since $G$ is the fundamental group of the space $X$ (i.e the Torus) gained by attaching the 2-cell along the loop $xyx^{-1}y^{-1}$ to $B_{2}$ (the bouquet of two circles), there is a one to one correspondence between the index $n$ subgroups of $G$ and regular $n$-degree coverings of $X$. A nice way to visualise the coverings corresponding to $\Lambda_{i}$, is to construct a surjective group homomorphisms $\phi_{i} : G \rightarrow H_{i}$, for $H_{i}$ an appropriate group of order 4, such that $\operatorname{ker}(\phi_{i}) = \Lambda_{i}$. In our case it's quite simple to see that the following work for $\Lambda_{i}$, $1\leq i \leq 5$, but I can't seem to find such a map for $\Lambda_{6}$. \begin{align*}
& \phi_{1}: G \rightarrow C_{4} = \left< \xi \mid \xi^{4}=1 \right> && (1,0) \mapsto \xi && (0,1) \mapsto 1 & \\
& \phi_{2}: G \rightarrow C_{4} = \left< \xi \mid \xi^{4}=1 \right> && (1,0) \mapsto \xi && (0,1) \mapsto \xi^{3} & \\
& \phi_{3}: G \rightarrow C_{4} = \left< \xi \mid \xi^{4}=1 \right> && (1,0) \mapsto \xi && (0,1) \mapsto \xi^{2} & \\
& \phi_{4}: G \rightarrow C_{4} = \left< \xi \mid \xi^{4}=1 \right> && (1,0) \mapsto \xi && (0,1) \mapsto \xi & \\
& \phi_{5}: G \rightarrow C_{2}\times C_{2} = \left<\eta \mid \eta^{2}\right> \times \left< \kappa \mid \kappa^{2}\right> && (1,0) \mapsto (\eta,0)  && (0,1) \mapsto (0,\kappa) & \\
\end{align*} Since, from here, it is relatively trivial (since there is a low number of generators of low order) to produce the corresponding coverings of the torus, if I could find the map for $\Lambda_{6}$, I would have classified all 6 (up to covering transformation) regular degree 4 coverings of the torus. Could anyone help here?","['algebraic-topology', 'general-topology', 'covering-spaces', 'group-theory']"
2799788,Find the marginal probability density function,"The random vector $[\,X \,\,\, Y \,]'$ has probability density function $f_{X,Y} (x,y) = ke^{-2x^2-3xy-\frac{9}{2}y^2}$, where $k$ is some constant Find $k.$ Find the marginal probability density functions of $X$ and $Y.$ I know for it to be a valid pdf its integral from negative to positive infinity must be equal to one, and that it must be greater than $0$ for all $x.$ But for starters I'm not sure on the integration.","['statistics', 'density-function']"
2799823,Is there any construction of real numbers that does not use a quotient space in the process?,I am working on an isomorphism (in terms of order and operations) from the power set of integers to R. I would like to know if anyone knows of any construction of the real numbers that uses such a simple set to provide it with the structure of the real number system. Thanks!,"['order-theory', 'real-numbers', 'analysis']"
2799829,Function which satisfies $f(x-f(x))=f(x)-1$,"While trying to solve a particular problem, I got stuck trying to find an unknown function $f(x)$ , $f : \Bbb{R}\to\Bbb{R}$ whose only known property is that it satisfies the following equation: $$f(x-f(x))=f(x)-1$$ Is there a way to determine if the above equation has a unique solution? If $f(x)$ is indeed unique, but its explicit form cannot be determined, is there a way to find its value at some arbitrary point $f(a_0)$?","['real-analysis', 'functional-equations']"
2799860,Do there exist any integer solutions for $y=\log_2(1+3^x)$?,"I was working on this problem and came to a standstill. I'm not exactly sure how to go about this problem, to find if any integer pairs of $(x,y)$ satisfy this equation. Any guidance would be appreciated! $$
y=\log_2(1+3^x)
$$","['logarithms', 'algebraic-number-theory', 'discrete-logarithms', 'number-theory', 'integers']"
2799872,Inner circle of torus of revolution is calibrated,"I'm working on the following problem from Lee's ""Introduction to Smooth Manifolds"": Let $D \subseteq \mathbb R^3$ be the surface obtained by revolving the circle $(r-2)^2 + z^2 = 1$ around the z-axis, with the induced Riemannian metric from $\mathbb R^3$, and let $C \subseteq D$ be the “inner circle” defined by $C = \{(x,y,z) : z=0, \, x^2 + y^2 = 1\}$. Show that $C$ is calibrated, and therefore is the shortest curve in its homology class. In this case, a calibration of a Riemannian manifold $M$ is a closed $p$-form $\omega$ on $M$ so that $\omega(v_1, \ldots, v_p) \leq 1$ for every orthonormal set $\{v_1, \ldots, v_p\}$, and a Riemannian submanifold $S \subseteq M$ is calibrated if there is a calibration $\omega$ so that $\iota_S^*\omega$ is the induced Riemannian volume form on $S$. So I need to find a 1-form $\omega \in \Omega^1(D)$ for which $\omega(v) \leq 1$ for every unit tangent vector $v\in TD$, and $\iota_C^* \omega$ is the induced Riemannian volume form on $C$. Let $F(\theta, t) = \big((2t+\cos t)\cos\theta, (2+\cos t)\sin\theta, \sin t\big)$; then $F : [0,2\pi]^2 \to \mathbb R^2$ parametrizes $D$. My original thought was to let $\omega$ be the 1-form $(\overline F_\theta)^\flat$, i.e. $(\overline F_\theta)^\flat(v) = g_D (v, \overline F_\theta)$ for every $v \in TD$, where $g_D$ is the induced Riemannian metric on $D$ and $\overline F_\theta = F_\theta / |F_\theta|$ is the normalization of the tangent vector $F_\theta$. It seems clear to me in this case that $\iota^*_C \omega$ is the induced volume form on $C$, and that $\omega(v) \leq 1$ for unit tangent vectors $v$. However, I have two concerns: I'm not sure how to show $\omega = (\overline F_\theta)^\flat$ is closed, and if I could show the above, why would a similar argument not apply to the outer circle of $D$, which is clearly not minimizing in its homology class? I would appreciate any thoughts or clarifications.","['homology-cohomology', 'riemannian-geometry', 'differential-forms', 'differential-geometry', 'calibrated-geometry']"
2799884,Importance of $\sigma$-finiteness for Uniqueness of Measure $dm_f = f dm$,"Background Given a measure $m : X \rightarrow [0,+\infty]$ and a measurable function $f : X \rightarrow [0,+\infty]$, we can define a new measure by integrating $f$ as below: $$
m_f(E) = \int_E f \, dm
$$ I'm not aware of a name for $m_f$, hence the awkward title.  My question arises from Exercise #1.2.2 of Tao, ""Epsilon of Room, Vol. I"" , which states the following: EOR #1.2.2: Let $m$ be $\sigma$-finite.  Given two functions $f,g : X \rightarrow [0,+\infty]$, show that $m_f = m_g$ if and only if $f = g$ for $m$-almost every $x$.  Give and example to show that this uniqueness statement can fail if $m$ is not $\sigma$-finite. I am trying to better understand the importance of the $\sigma$-finiteness condition.  For reference, here is my proof of the statement. Proof The $\impliedby$ direction is easy and true even when $X$ is not $\sigma$-finite.  For the $\implies$ direction, we prove the contrapositive. Let $\mu(X) < +\infty$ and suppose $f$ is not almost-everywhere equal to $g$, that is, $f \neq g$ on a set $E$ of positive but possibly infinite measure. Without loss of generality, we can take $f > g$ on $E$ since the sets $E \cap 1_{f > g}$ and $E \cap 1_{f < g}$ cannot both be null.  This condition prevents $g$ from being infinite on $E$. Moreover, we may assume $\mu(E) < +\infty$ is finite because each infinite-measure set in a sigma-finite space necessarily has a subset of positive measure.  This ensures $m_g(E) < +\infty$. Then, $m_f(E) = \int_E f \, dm > \int_E g \, dm  = m_g(E)$, where it is possible for $m_f(E) = +\infty$ but $m_g(E)$ must be finite. Counterexample Let $X = \{ a \}$ be a singleton set and $\mu : \{ \emptyset, X \} \rightarrow [0,+\infty]$ be the measure which assigns $\mu(\emptyset) = 0$ and $\mu(X) = +\infty$.  Clearly $X$ is not $\sigma$-finite.  Let $f(a) = 1$ and $g(a) = 2$.  Then $m_f(X) = m_g(X) = +\infty$, but $f \neq g$. Questions What is stopping uniqueness from being true when $X$ is not $\sigma$-finite? Like the counterexample suggests, we run into problems when $f$ and $g$ only disagree on sets of infinite measure, because then it is possible that $m_f(E) = m_g(E) = +\infty$.  Is this the only problematic case? For which classes of functions is $m_f$ unique even when $X$ is not $\sigma$-finite? What if we restrict $g$ to be integrable?  Then for any $E$, we have $m_g(E) < \int_X g dm < +\infty$.  This could be too strong an assumption though since integrable functions have $\sigma$-finite support.","['radon-nikodym', 'real-analysis', 'measure-theory']"
2799906,Class of integrals: $I(a)=\int_0^\infty \frac{dx}{e^x+ax}$,"I'm investigating integrals in the form
$$I(a):=\int_0^\infty \frac{dx}{e^x+ax}$$
So far, I haven't been able to find any special values other than $I(0)=1$, and I've only managed to evaluate these similar indefinite integrals:
$$\int \frac{x-1}{e^x+ax}dx=-\frac{\ln(1+axe^{-x})}{a}+C$$
$$\int \frac{xdx}{e^x+x+1}=-\ln(1+e^{-x}(x+1))+C$$
I've also found the following series representation for $I(a)$:
$$I(a)=\sum_{n=0}^\infty \frac{(-a)^n n!}{(n+1)^{n+1}}$$
...which looks remarkably similar to the Maclaurin series for the Lambert-W function. QUESTION: Can anyone find any non-trivial special values of this integral? I find this unlikely because of the weird series representation of $I(a)$, so if this isn't feasible, can anyone find any interesting properties or functional/differential equations for $I(a)$? UPDATE: I've managed to show that
$$\lim_{a\to\infty }\frac{aI(a)}{\ln(a)}=1$$","['functional-equations', 'improper-integrals', 'integration', 'definite-integrals', 'recreational-mathematics']"
2799926,"Fourier transform, tangent and cotangent bundles","I'm familiar with the notion of Fourier transform in the context of $\mathbb{R}^n$ and more generally, locally compact abelian groups. However recently I came across the Fourier transform acting as follows: $M$ is a compact manifold, $x \in M$ and $T_xM,T^*_xM$ are tangent and cotangent spaces at $x$. Also $E$ is a given vector bundle over $M$. Then the Fourier transform should act $\mathcal{F}_x:\Gamma^{\infty}(T_xM,T_xM \times E_x) \to \Gamma^{\infty}(T^*_xM,T_xM \times E_x)$ Any idea how such Fourier transform should be defined? Here $T_xM \times E_x$ should be viewed as a trivial vector bundle over $T_xM$ with fiber $E_x$. However I suspect that $\mathcal{F}_x$ should be defined somehow consistently when $x$ varies.","['tangent-bundle', 'fourier-analysis', 'differential-geometry', 'fourier-transform']"
2799937,"In the connected component of $\{z \in \mathbb{C} : |p(z)| \le 1\}$, $p$ must vanish at least once. [duplicate]","This question already has an answer here : Does every connected component of $\{z : |P(z)|<1 \}$ contain a zero? (1 answer) Closed 6 years ago . If $p$ is a non-constant polynomial, and. $G$ is an open connected component of $\{z \in \mathbb{C} : |p(z)| \le 1\}$, then $p$ has at least one zero in $G$ My thoughts so far.  Suppose that $p$ is nonzero in $G$.  By the minimum modulus principle, $p(z)$ then achieves its minimum (say $m$) on the boundary of $G$.  From here, I either want to show that $G$ cannot be connected, or maybe that $p$ must be constant, and hence we have a contradiction?  Any thoughts?",['complex-analysis']
2799950,"On the integral $\int_{0}^{1/2}\frac{\text{Li}_3(1-z)}{\sqrt{z(1-z)}}\,dz$","This questions is related to my previous one . I am interested in a explicit evaluation in terms of Euler sums for
  $$ \int_{0}^{\pi/4}\text{Li}_3(\cos^2\theta)\,d\theta = \frac{1}{2}\int_{0}^{1/2}\frac{\text{Li}_3(1-z)}{\sqrt{z(1-z)}}\,dz.$$ It is not difficult to show that
$$ \int_{0}^{\color{red}{1}}\frac{\text{Li}_3(1-z)}{\sqrt{z(1-z)}}\,dz =-\frac{\pi^3}{3}\log(2)+\frac{4\pi}{3}\log^3(2)+2\pi\zeta(3)\tag{A}$$
but I have not managed to make a wise use of the trilogarithm functional identities for computing
$$ \int_{0}^{1/2}\frac{\text{Li}_3(z)}{\sqrt{z(1-z)}}\,dz\stackrel{\text{IBP}}{\longrightarrow}\int_{0}^{\pi/4}\theta\cot(\theta)\text{Li}_2(\sin^2\theta)\,d\theta \quad\text{or}\quad\int_{0}^{1/2}\frac{\text{Li}_3(z)-\text{Li}_3(1-z)}{\sqrt{z(1-z)}}\,dz ,$$
which would have solved the problem. One might need substantial extensions of the result about $\mathcal{I}(a,b)$ proved here by nospoon . I am expecting the integral above to be related with Euler sums with (total) weight five. Maybe the shifted-Fourier-Chebyshev expansion of $\text{Li}_3(x)$ over $(0,1)$ is already known in the literature, but I have not been able to find it.","['reference-request', 'hypergeometric-function', 'integration', 'special-functions', 'polylogarithm']"
2799960,Why is the domain of $x^x$ positive real numbers?,"(What is this function called, is it an exponential function?) Plot of $x^x$ I plotted this function and found that only positive part of it is shown. Also while computing derivative of this function we take log which also implies that $x$ has been taken to have only positive values. But I can take individual negative numbers and easily find its value like $(-2)^{-2}=1/4.$ (This is not true for negative fractions though) What causes this discrepancy?","['exponential-function', 'functions', 'graphing-functions']"
2799978,"exponential rv's, gamma distribution","Let $X_1, X_2, X_3, \dots$ be independent exponential random variables with parameter $\lambda$. Let $Y = \max\{r : X_1 + X_2 + \cdots + X_r \le 1\}$. Prove that $Y$ is Poisson distributed with parameter $\lambda$. My attempt: $$P(Y=k)=P(X_1 + X_2 + \cdots + X_{k+1} \ge 1) \cdot P(X_1 + X_2 + \cdots + X_k \le1)$$ Now define $T_n=\sum_{i=1}^n X_i$. Since $X_i$ are exponentially distributed it follows that $T_n \sim \Gamma(n, \lambda) $ with pdf  $$f_{T_n}(x)=\frac{\lambda^nx^{n-1}e^{-\lambda x}}{(n-1)!}.$$ So $$P(Y=k) = \left( 1-\int_0^1 \frac{\lambda^{k+1}x^{k}e^{-\lambda x}}{k!}\right) \cdot \left(\int_0^1 \frac{\lambda^k x^{k-1}e^{-\lambda x}}{(k-1)!} \right)$$ Now obviously those integrals can't be computed to obtain the answear. Can anyone please help me abd tell me what's wrong with my solution?","['probability-theory', 'probability', 'random-variables', 'probability-distributions']"
2800011,Using the Well-Ordering Principle to prove that all integers less than $2^{m+1}$ can be represented by $m$ bits.,"Actually, the problem statement I am working with doesn't specify it's about binary numbers at all, and the problem reads as such: You are given a series of envelopes, respectively containing $1,2,4,...,2^m$ dollars. Define Property $m$ :  For any nonnegative integer less than $2^{m+1}$ , there is a selection of envelopes whose constants add up to exactly that number of dollars. Use the Well Ordering Principle (WOP) to prove that Property $m$ holds for all nonnegative integers m . Hint : Consider two cases: first, when the target number of dollars is less than $2^m$ and second, when the target is at least $2^m$ . Which, well, reads to me like coded language for computer science people that any integer less than $2^{m+1}$ can be represented by an $m$ -bit binary number. So I take the provided hint under advisement and demonstrate the case that we are targeting at least $2^m$ dollars, which is easy: If the target dollar amount is at least $2^m$ , then assume there is an $m_0$ such that there is no combination of envelopes that add to $2^{m_0}$ , and that $m_0$ is the smallest number with this property via the Well-Ordering Principle. Since $m_0$ is the smallest number for which this applies, there is a combination of envelopes that adds $2^{m_0-1}$ = $2^{m_0}/2$ , which can be achieved with a single envelope. However, since $m_0$ is less than $m+1$ by hypothesis, there is also an envelope twice as large as $2^{m_0-1}$ , which is equal to $2^{m_0}$ . Therefore, $2^{m_0}$ is representable by a combination of envelopes (and, in fact a single envelope). I attempt to show the case where the target number of dollars is less than $2^m$ by sub-cases but I'm getting stuck. Say, for the sake of contradiction, there is some number $n_0$ that cannot be represented by a combination of envelopes, and that this number is the smallest possible counterexample by the Well Ordering Principle. $n_0=1$ can be represented, so $n_0>1$ . $n_0-1$ can then be represented with the following polynomial: $n-1=\sum_{i=0}^{m}2^i a_i$ , where $a_i$ is either $0$ or $1$ . If $n-1$ is even: $n-1 = 2^{m}a_m + 2^{m-1}a_{m-1} + ... + 2^2a_2 + 2a_1 + a_0$ Which, if $a_0 = 0$ , is an even number on the right hand side. But then, adding $1$ to both sides: $n = 2^{m}a_m + 2^{m-1}a_{m-1} + ... + 2^2a_2 + 2a_1 + 1$ Which demonstrates that $n$ can be represented as a combination of envelopes. I think this is sound so far, but I'm having trouble with the case where $n-1$ is odd. My computer science brain just wants to say it works like a ripple carry adder but I can't think of how to express that argument mathematically. Or perhaps there's a more elegant way to express the argument in the first place that I'm not seeing.","['binary', 'proof-writing', 'well-orders', 'discrete-mathematics']"
2800013,"In a proof by contradiction, what if both the proposition and its negation lead to contradictions? [duplicate]","This question already has answers here : Are proofs by contradiction really logical? (14 answers) Closed 6 years ago . I'm learning math. I've recently thought more about the proof by contradiction technique, and I have a question that I would like cleared up. Let me set the stage. Suppose I am trying to prove a theorem. Theorem: If A and $\neg$B, then $\neg$C. Proof (contradiction): Let us suppose that A is true and $\neg$B is true. Let us assume that C is true ($\neg$C is false). [blah blah blah] From this, we arrive at a contradiction because we see that B is true ($\neg$B is false), but we know that $\neg$B is true (because we assumed it to be true). Thus, since assuming that C is true lead us to a contradiction, it must be the case that C is false ($\neg$C is true). QED. My issue with this : why is it that C leading to a contradiction must mean that $\neg$C is true? What if $\neg$C also leads to a contradiction? In that case, doesn't a proof by contradiction not prove anything? Why can we be sure that C leading to a contradiction must mean that $\neg$C doesn't lead to a contradiction? I'm sorry if this question has already been asked. I searched for a bit before asking to see if anyone had this same specific question, but most results just asked why a proof by contradiction works in general without any clear question.","['logic', 'discrete-mathematics']"
2800021,Probability of Following Winning Player,"Let's say we're playing a game with a total of $n$ people. In each round of the game, two random players $A$ and $B$ are selected. One of $A$ or $B$ is randomly chosen to be the winner, and the other the loser. Without loss of generality, let us assume $A$ wins. Then, $B$ is eliminated from the pool of $n$ contestants, and denoted as a 'follower' of $A$. Furthermore, any previous followers of $B$ also become followers of $A$. $A$ is re-entered into the pool of contestants, and this process is repeated until one person is left and wins the game. Clearly, this last person remaining will have everyone following him. My question is: what is the probability that a player $X$, randomly selected at the beginning of the game, ends up following the overall winner $Y$, before $Y$ wins? I'll say any player is definitionally following themselves at the beginning of the game, to formalize the problem. I think the answer is $\frac{1}{2}$ by symmetry, but this also seems somewhat counter-intuitive. If you're curious, the above question is motivated by the game Fortnite; when another player kills you, you can then watch them play. If another player kills the player who killed you, you then watch the new winner play.","['induction', 'probability']"
2800022,"cross product not associative, outer product associative","The cross product is not associative. If $i=(1,0,0)$, $j=(0,1,0)$ and
$k=(0,0,1)$, then 
\begin{eqnarray}
 i \times (i \times j) = i \times k = -j \\
 (i \times i) \times j = 0
\end{eqnarray} However in Geometric Algebra, if $e_1=(1,0,0)$, $e_2=(0,1,0)$ and
$e_3=(0,0,1)$ then 
\begin{eqnarray}
  e_1 \wedge (e_1 \wedge e_2) = (e_1 \wedge e_1 ) \wedge e_2 = 0
\end{eqnarray} According to D. Hestenes, New Foundations for Classical Mechanics
(equation 3.13)
\begin{eqnarray}
   a \times b = -i a \wedge b  \quad, i=\sqrt{-1} 
\end{eqnarray} So, where is the flaw here? Except for a complex scalar both definitions in $\mathbb{R}^3$ are the same. But.....one is associative and the other is not? Thanks.","['clifford-algebras', 'linear-algebra']"
2800023,Prove using calculus or otherwise the following inequality,"Prove that$$ \frac {2}{\pi -2}\ \le\ \frac {\sin x-x\cos x}{x-\sin x}\ <\ 2$$where $$x\in\left(0,\frac{\pi}{2}\right]$$ My Attempt:$$ f'(x)=\frac{ x\sin x(x-\sin x)-(1-\cos x)(\sin x-x\cos x)}{(x-\sin x)^2}=\frac{ x^2\sin x-(1-\cos x)x-\sin x(1-\cos x)}{(x-\sin x)^2}$$ After this not able to get breakthrough.","['algebra-precalculus', 'monotone-functions', 'calculus']"
2800035,Sufficient statistics for beta-binomial distribution,"The beta-binomial pmf is $$f_X(x) = {n \choose x}{B(x+\alpha, n-x+\beta)\over B(\alpha, \beta)}$$ where $B$ is the beta function. The numerator is the issue here when trying to separate data from parameters. I tried using $$B(x+\alpha, n-x+\beta) \propto \Gamma(y+\alpha)\Gamma(n-x+\beta)$$ and the fact that $x$ is discrete but that led me to a polynomial where parameters and data are still intertwined through the exponents and coefficients. Is this solvable at all?","['special-functions', 'statistics', 'gamma-function', 'beta-function']"
2800038,The numbers don't add up in this Venn diagram?,I'm trying to draw a Venn diagram to make sense of the overlapping 3 pairs of brightly colored and stripped socks but the numbers don't add up to the 10 pairs given in the question? How can there be 10 pairs of socks?,['statistics']
2800107,Prove $A$ and $B$ are equivalent if and only if $\text{rank}(A) =\text{rank}(B)$,"Knowing that $A$ is equivalent to $B$ if there exists an invertible $m\times m$ matrix $P$ and an invertible $n\times n$ matrix $Q$ such that $PAQ = B$ , how can I prove that $A$ and $B$ are equivalent iff $\text{rank}(A) =\text{rank}(B)$ ? I've managed to solve the forward direction of the iff and am confident it is correct: Suppose $A$ and $B$ are equivalent. Then, $PAQ = B$ . Knowing this, we can assume $$
\text{rank}(PAQ) \leq \text{rank}(A) = \text{rank}(P^{-1} B Q^{-1}) \leq \text{rank}(B)
$$ As $\text{rank}(PAQ) = \text{rank}(B)$ , all inequalities must be equalities, so $\text{rank}(A) =\text{rank}(B)$ . I am not sure how to prove this statement in the reverse direction. I think that the invertible matrix theorem could be useful for this problem","['matrices', 'matrix-rank', 'equivalence-relations', 'linear-algebra']"
2800110,Evaluate $\lim\limits \frac{x-\sin\sin\cdots\sin x}{x^3}.$ [duplicate],"This question already has answers here : Evaluating limit (iterated sine function) (4 answers) Closed 5 years ago . Problem Evaluate $$\lim\limits_{x \to 0} \frac{x-\sin\sin\cdots\sin x}{x^3},$$where $\sin\sin\cdots\sin x$ denotes n-fold composite sine function. Solution Consider applying Taylor's Formula with 3-order at $x=0$. We may obtain $$f_n(x)=\sin\sin\cdots\sin x=x-\frac{n}{6}x^3+\mathcal{O}(x^3).\tag{*}$$ To prove this, we can apply the mathematical induction. Let $n=1,$ then $$f(x)=\sin x=x-\frac{1}{6}x^3+\mathcal{O}(x^3),$$  It's true and shows that $(*)$ holds for $n=1$. Assume that $(*)$ holds for $n=k$. Then $$\begin{align*}f_{k+1}(x)&=\sin(f_k(x))\\&=x-\frac{k}{6}x^3+\mathcal{O}(x^3)-\frac{1}{6}\left(x-\frac{k}{6}x^3+\mathcal{O}(x^3)\right)^3+\mathcal{O}(x^3)\\&=x-\frac{k+1}{6}x^3+\mathcal{O}(x^3)\end{align*}.$$ This shows that $(*)$ holds for $n=k+1$. As a result, $(*)$ holds for all $n=1,2,\cdots.$
Now,let's go back to deal with the problem. $$\lim\limits_{x \to 0} \frac{x-\sin\sin\cdots\sin x}{x^3}=\lim\limits_{x \to 0} \dfrac{x-\left(x-\dfrac{n}{6}x^3+\mathcal{O}(x^3)\right)}{x^3}=\frac{n}{6}.$$ Please correct me if I'm wrong. Hope to see other solutions. Thanks.","['taylor-expansion', 'proof-verification', 'limits']"
2800113,number of edges in a transitive closure of a random directed graph,"First two definition: (A) Random Directed Graph: Suppose we have a random $DAG(n, p)$. Here is how it's generated: Put n distinct nodes on a line, and connect each node in the $i$th order to any node after that; This would form a complete directed graph with $n$ nodes. Sample each edge with probability $p$. The resulting graph will be directed, and acyclic. (B) Transitive Closure: Transitive closure of a graph $\text{closure}(G)$ is the result of connecting all the node pairs $i-j$ (via a direct edge $i \rightarrow j$) such that there is a path connecting $i$ to $j$. The question is: what is the expected number of edges in $\text{closure}(DAG(n, p))$?","['graph-theory', 'random-graphs', 'probability']"
2800162,Rearrangement inequality and minimal value of $\frac{\sin^3x}{\cos x} +\frac{\cos^3x}{\sin x}$,"For $x \in \left(0, \dfrac{\pi}{2}\right)$, is the minimum value of $\dfrac{\sin^3x}{\cos x} +\dfrac{\cos^3x}{\sin x} = 1$? So considering ($\dfrac{1}{\cos x}$, $\dfrac{1}{\sin x}$) and ($\sin^3x$, $\cos^3x$), is it right to use the rearrangement inequality and conclude that $\dfrac{\sin^3x}{\cos x} +\dfrac{\cos^3x}{\sin x}$ is more than or equal to $\dfrac{\sin^3x}{\sin x} +\dfrac{\cos^3x}{\cos x}$ which is equal to $1$? Thanks.","['inequality', 'trigonometry', 'cauchy-schwarz-inequality', 'rearrangement-inequality', 'maxima-minima']"
2800167,Matrix Inverse is a Uniformly Continuous function for Uniformly Positive Definite matrices?,"Definition 1: A collection of $k\times k$ positive semidefinite matrices $\{A_n\}$ is said to be uniformly positive definite if for some $\eta > 0$, $det(A_n) > \eta$. Definition 2: A function $f$ is uniformly continuous on $B$ if for any $\epsilon > 0$, there exists a $\delta > 0$ such that for $x, y \in B$, $d(x,y) < \delta$ implies $d(f(x),f(y)) < \epsilon$. I need to prove that the matrix inverse is a uniformly continuous function for uniformly positive definite matrices, using the sup-metric, $d(M, N) = \max_{ij}|m_{ij} - n_{ij}| = ||M - N||_{\infty}$. The statement is clearly true for scalars $\{a_n\}$, in that if we have $a_n > \eta > 0$ for all $n$, then have $m = \eta^{-1}$ larger than any other value of the function. For any $\epsilon >0$, let $\epsilon^* = \min(\epsilon, m/2)$. We take a $\delta$ such that $0 < \delta < (m - \epsilon^*)^{-1}$, and for that $\delta$ we have $|x - y| < \delta$ implies $|x^{-1} - y^{-1}| < \epsilon$. However, I do not now how to generalize this proof to matrices. Any hint?","['matrices', 'positive-definite', 'positive-semidefinite', 'uniform-continuity']"
2800183,Visual representation of the domain and range of a function?,"An excerpt in the book ""College Algebra by Michael Sullivan is that: When the graph of a function is given, its domain may be viewed as the shadow created by the graph on the x- axis by vertical beams of light. Its range can be viewed as the shadow created by the graph on the y-axis by horizontal beams of light. I did't get it and i also sought in google to get some idea but i can't find one.
Can anyone help me to understand it maybe with some graphics. Thanks.","['functions', 'graphing-functions']"
2800198,Proving the universal mapping property for polynomial rings,"I am studying from Patrick Morandi's Field and Galois Theory , and I am stuck on Problem 6 from Section 1 (on page 13). Verify the following universal mapping property for polynomial rings: Let $A$ be a ring containing a field $F$ . If $a_1,\dotsc,a_n \in A$ , show that there is a unique ring homomorphism $\varphi \colon F[x_1,\dotsc,x_n] \to A$ with $\varphi(x_i) = a_i$ for each $i$ . Moreover, suppose that $B$ is a ring containing $F$ , together with a function $f \colon \{ x_1,\dotsc,x_n \} \to B$ , satisfying the following property: For any ring $A$ containing $F$ and elements $a_1,\dotsc,a_n \in A$ , there is a unique ring homomorphism $\varphi \colon B \to A$ with $\varphi(f(x_i)) = a_i$ . Show that $B$ is isomorphic to $F[x_1,\dotsc,x_n]$ . The list of errata for the book says that we must assume that all the rings are commutative and the ring homomorphisms are $F$ -homomorphisms (that is, they are ring homomorphisms that fix $F$ ). I have proved the first part as follows: let $\mathbf{a} = (a_1,\dotsc,a_n)$ . The evaluation map $\operatorname{ev}_\mathbf{a} \colon F[x_1,\dotsc,x_n] \to A$ given by $\operatorname{ev}_\mathbf{a}(f) = f(a_1,\dots,a_n)$ is an $F$ -homomorphism with $\operatorname{ev}_\mathbf{a}(x_i) = a_i$ for each $i$ . Moreover, if $\varphi$ is any $F$ -homomorphism from $F[x_1,\dotsc,x_n]$ to $A$ with $\varphi(x_i) = a_i$ , then we must necessarily have that $$
\begin{align}
\varphi\left( \sum_{k_1,\dotsc,k_n} c_{k_1,\dotsc,k_n} x_1^{k_1} \dotsm x_n^{k_n} \right) &= \sum_{k_1,\dotsc,k_n} c_{k_1,\dotsc,k_n} \varphi(x_1)^{k_1} \dotsm \varphi(x_n)^{k_n}\\
&= \sum_{k_1,\dotsc,k_n} c_{k_1,\dotsc,k_n} a_1^{k_1} \dotsm a_n^{k_n}\\
&= \operatorname{ev}_\mathbf{a}\left( \sum_{k_1,\dotsc,k_n} c_{k_1,\dotsc,k_n} x_1^{k_1} \dotsm x_n^{k_n} \right).
\end{align}
$$ Thus, the existence and uniqueness of $\varphi$ has been established. I am stuck in proving the second part. From the previous result, we have a unique $F$ -homomorphism $\Phi \colon F[x_1,\dotsc,x_n] \to B$ given by
evaluation at $(f(x_1),\dotsc,f(x_n))$ , and my intuition is that this is the required isomorphism. But I am not able to make much progress. To show that $\Phi$ is injective, the idea I have in mind is as follows: given $0 \neq g \in \ker(\Phi)$ , choose the ring $A$ and elements $a_1,\dotsc,a_n$ in such a way that $g(a_1,\dotsc,a_n) \neq 0$ , thereby arriving at a contradiction. To show that $\Phi$ is surjective, my intuition is that the uniqueness of the map $\varphi$ should play a role, since we will have used only the existence in showing injectivity. Am I on the right track? I haven't been able to convert these thoughts into a proof yet, and I would really appreciate some hints. Thanks in advance!","['abstract-algebra', 'polynomials', 'field-theory', 'universal-property']"
2800218,An integral related to the pdf of the non-central chi-squared distribution,"Problem Statement I was attempting to produce a direct derivation of the pdf of the non-central chi-square distribution and came across the following integral, which I will denote as $g_{n-1}(x_n, \mathbf{\mu}^{(n)})$. \begin{align}
\int_{(0,1)^{n-1}}\left(\ \prod^{n-1}_{k=1}\frac{x_k^{k/2-1}}{\sqrt{1-x_k}}\ \right)\left(\ \prod^n_{k=1}\cosh\left(\mu_k\sqrt{x_n}\sqrt{\ (1-x_{k-1})\prod^{n-k}_{j=1}x_{n-j}}\right)\ \right)\ dx_1dx_2\cdots dx_{n-1}
\end{align} Here $x_n>0$, $x_0:=0$ and $\mathbb{R}^n\ni\mu^{(n)}:=(\mu_1,\mu_2,\cdots,\mu_n)$. Thus far, I have succeeded in showing that if $f_n$ is the (Lebesgue) pdf of a random variable having a non-central chi-square distribution with $n$ degrees of freedom and non-centrality parameter $\delta_n:=\sum^n_{k=1}\mu_k^2$, then $$f_n(x_n, \delta_n)=\frac{e^{(-\delta_n+x_n)/2}}{(2\pi)^{n/2}}x_n^{n/2-1}g_{n-1}(x_n,\mu^{(n)})\tag{1}$$ and I am interested to know how one might complete the proof to show that $$f_n(x_n,\delta_n)=\frac{e^{(-\delta_n+x_n)/2}}{2}\left(\frac{x_n}{\delta_n}\right)^{n/4-1/2}I_{n/2-1}\left(\sqrt{\delta_nx_n}\right)\tag{2}$$ with $I_\nu$ being the modified Bessel function of the first kind. If one takes the following for granted: (*) Claim: The value of $g_{n-1}(x_n,\mu^{(n)})$ depends only on $x_n$ and $\delta_n$. then finding the value of $g_{n-1}(x_n,\mu^{(n)})$ would be a rather easy task as one could simply take $\mu_1=\sqrt{\delta_n}, \mu_2=\cdots=\mu_n=0$ without loss of generality and the integral simplifies to \begin{align}
g_{n-1}(x_n, \mu^{(n)})
&=\int_{(0,1)^{n-1}}\left(\ \prod^{n-1}_{k=1}\frac{x_k^{k/2-1}}{\sqrt{1-x_k}}\ \right)\cosh\left(\sqrt{\delta_n x_n}\sqrt{x_1\cdots x_{n-1}}\right)\ dx_1\cdots dx_{n-1}\\
&=\int_{(0,1)^{n-1}}\sum^\infty_{j=0}\frac{\left(\left(\sqrt{\delta_n x_n}\right)^2\right)^j}{(2j)!}\left(\ \prod^{n-1}_{k=1}\frac{x_k^{j+k/2-1}}{\sqrt{1-x_k}}\ \right)\ dx_1\cdots dx_{n-1}\\
&=\sum^\infty_{j=0}\frac{\left(\left(\sqrt{\delta_n x_n}\right)^2\right)^j}{(2j)!}\int_{(0,1)^{n-1}}\left(\ \prod^{n-1}_{k=1}\frac{x_k^{j+k/2-1}}{\sqrt{1-x_k}}\ \right)\ dx_1\cdots dx_{n-1}\\
&=\sum^\infty_{j=0}\frac{\left(\left(\sqrt{\delta_n x_n}\right)^2\right)^j}{(2j)!}\left(\ \prod^{n-1}_{k=1}\int^1_0\frac{x_k^{j+k/2-1}}{\sqrt{1-x_k}}\ dx_k\ \right)\\
&=\sum^\infty_{j=0}\frac{\left(\left(\sqrt{\delta_n x_n}\right)^2\right)^j}{(2j)!}\left(\ \prod^{n-1}_{k=1}\frac{\Gamma\left(j+\frac{k}{2}\right)\Gamma\left(\frac{1}{2}\right)}{\Gamma\left(j+\frac{k+1}{2}\right)} \right)\\
&=\sum^\infty_{j=0}\frac{\left(\left(\sqrt{\delta_n x_n}\right)^2\right)^j}{(2j)!}\left(\frac{\Gamma\left(j+\frac{1}{2}\right)}{\Gamma\left(j+\frac{n}{2}\right)}\cdot \pi^{(n-1)/2}\right)\\
&=\sum^\infty_{j=0}\frac{\left(\left(\sqrt{\delta_n x_n}\right)^2\right)^j}{(2j)!}\left(\frac{(2j)!}{4^jj!\Gamma\left(j+\frac{n}{2}\right)}\cdot \pi^{n/2}\right)\\
&=\pi^{n/2}\sum^\infty_{j=0}\frac{\left(\frac{\left(\sqrt{\delta_n x_n}\right)^2}{4}\right)^j}{j!\Gamma\left(j+\frac{n}{2}\right)}=\pi^{n/2}\left(\frac{2}{\sqrt{\delta_n x_n}}\right)^{n/2-1}I_{n/2-1}\left(\sqrt{\delta_n x_n}\right)\\
&=\frac{(2\pi)^{n/2}}{2(\delta_nx_n)^{n/4-1/2}}I_{n/2-1}\left(\sqrt{\delta_n x_n}\right)
\end{align}
which proves $(2)$ after substituting this into equation $(1)$. Hence, here are my two questions: $\text{a)}$ How might one rigorously justify the claim (*) above? I am most likely missing something but the veracity of the claim is not immediately obvious to me. $\text{b)}$ How might one evalaute the integral $g_{n-1}$ without exploiting the claim? Solution to Question b) for $n=2$ If $n=2$, we have $$g_1(x_2, \mu^{(2)})=\int^1_0\frac{\cosh(\mu_1\sqrt{x_2}\sqrt{x_1})\cosh(\mu_2\sqrt{x_2}\sqrt{1-x_1})}{\sqrt{x_1(1-x_1)}}\ dx_1$$ Let $(a,b)=(\mu_1\sqrt{x_2}, \mu_2\sqrt{x_2})$ and $2\omega=b+ia$. With the substitution $x_1=\sin^2\theta$ and then $z=e^{i\theta}$, we get \begin{align}
g_1(x_2, \mu^{(2)})
&=\int^\frac{\pi}{2}_02\cosh(a\sin{\theta})\cosh(b\cos\theta)\ d\theta\\
&=\frac{1}{2}\int^{2\pi}_0\cosh(a\sin{\theta})\cosh(b\cos\theta)\ d\theta\\
&=\frac{1}{2}\int_{|z|=1}\cosh\left(a\cdot\frac{z-z^{-1}}{2i}\right)\cosh\left(b\cdot\frac{z+z^{-1}}{2}\right)\frac{dz}{iz}\\
&=\frac{1}{4}\int_{|z|=1}\left[\cosh\left(\bar{\omega}z+\omega z^{-1}\right)+\cosh\left(\omega z+\bar{\omega}z^{-1}\right)\right]\frac{dz}{iz}
\end{align} Now deform the contour along the essential singularity $z=0$ to obtain \begin{align}
\int_{|z|=1}\cosh\left(\bar{\omega}z+\omega z^{-1}\right)\frac{dz}{iz}
&=\lim_{\epsilon\to 0^+}\int^{2\pi}_0\cosh\left(\bar{\omega}\epsilon e^{i\theta}+\omega\epsilon^{-1}e^{-i\theta}\right)\ d\theta\\
&=\lim_{\epsilon\to 0^+}\int^{2\pi}_0\sum^\infty_{k=0}\frac{1}{(2k)!}\sum^{2k}_{j=0}\binom{2k}{j}\bar{\omega}^{2k-j}\omega^j(\epsilon e^{i\theta})^{2k-2j}\ d\theta\\
&=\lim_{\epsilon\to 0^+}\sum^\infty_{k=0}\frac{1}{(2k)!}\sum^{2k}_{j=0}\binom{2k}{j}\bar{\omega}^{2k-j}\omega^j\int^{2\pi}_0(\epsilon e^{i\theta})^{2k-2j}\ d\theta\\
&=\lim_{\epsilon\to 0^+}\sum^\infty_{k=0}\frac{1}{(2k)!}\sum^{2k}_{j=0}\binom{2k}{j}\bar{\omega}^{2k-j}\omega^j(2\pi\mathbf{1}_{\{k\}}(j))\\
&=\sum^\infty_{k=0}\frac{1}{(2k)!}\binom{2k}{k}|\omega|^{2k}\cdot 2\pi\\
&=\sum^\infty_{k=0}\frac{\left(|\omega|^2\right)^k}{k!\Gamma(k+1)}\cdot 2\pi\\
&=2\pi I_0(2|\omega|)
\end{align} Repeating the same argument, we clearly also have $$\int_{|z|=1}\cosh\left({\omega}z+\bar{\omega} z^{-1}\right)\frac{dz}{iz}=\int_{|z|=1}\cosh\left(\bar{\omega}z+\omega z^{-1}\right)\frac{dz}{iz}=2\pi I_0(2|\omega|)$$ and therefore, $$g_1(x_2, \mu^{(2)})=\pi I_0(2|\omega|)=\pi I_0\left(2.\sqrt{\frac{a^2+b^2}{4}}\right)=\pi I_0\left(\sqrt{x_2(\mu_1^2+\mu_2^2)}\right)=\pi I_0\left(\sqrt{\delta_2 x_2}\right)$$ Brief Derivation of Equation (1) In case anyone is interested, this is the sequence of transformations I used to arrive at equation $(1)$. Let $X_k$, $k=1,\cdots,n$, be independent random variables each distributed as $N(\mu_k,1)$. First, it is trivial to show that each $X_k^2$ has Lebesgue pdf $\frac{1}{\sqrt{2\pi x}}e^{-(x+\mu_k^2)/2}\cosh\left(\mu_k\sqrt{x}\right)\mathbf{1}_{(0,\infty)}(x)$. Integrating the joint density of $(X_1^2,\cdots,X_{n-1}^2, X_1^2+\cdots+X_n^2)$ gives us, for $x_n>0$, \begin{align}
\small{f_n(x_n,\delta_n)}
&\small{=\frac{e^{-(x_n+\delta_n)/2}}{(2\pi)^{n/2}}\int_{\mathbb{R}^{n-1}}\frac{\prod^{n-1}_{k=1}\cosh\left(\mu_k\sqrt{x_k-S_{n-1}\mathbf{1}_{\{n\}}(k)}\right)\mathbf{1}_{(0,\infty)}(x_k-S_{n-1}\mathbf{1}_{\{n\}}(k))}{\sqrt{x_1\cdots x_{n-1}(x_n-S_{n-1})}}\ dx_1\cdots dx_{n-1}}\\
&\small{=\frac{e^{-(x_n+\delta_n)/2}}{(2\pi)^{n/2}}\int^{x_n}_0\int^{x_{n-1}}_0\cdots\int^{x_2}_0\prod^{n}_{k=1}\frac{\cosh\left(\mu_k\sqrt{x_k-x_{k-1}}\right)}{\sqrt{x_k-x_{k-1}}}}\ dx_1\ dx_2\cdots dx_{n-1}\tag{i}\\
&\small{=\frac{e^{(-\delta_n+x_n)/2}}{(2\pi)^{n/2}}x_n^{n/2-1}g_{n-1}(x_n,\mu^{(n)})}\tag{ii}
\end{align} where $x_0:=0$ and $S_{n-1}:=\sum^{n-1}_{k=1}x_k$. Explanation: $\text{(i)}$: Apply the transformation $(x_1,x_2,\cdots,x_{n-1})\mapsto (x_1, x_2-x_1,\cdots,x_{n-1}-x_{n-2})$. The determinant of the Jacobian for this transformation is $1$. $\text{(ii)}$: Apply the transformation $(x_1,x_2,\cdots,x_{n-1})\mapsto \left(\prod^n_{k=1}x_k, \prod^n_{k=2}x_k,\cdots, \prod^n_{k=n-1}x_k\right)$. The Jacobian for this transformation is an upper triangular matrix with diagonal elements $\prod^n_{k=2}x_k, \prod^n_{k=3}x_k,\cdots, \prod^n_{k=n}x_k$ and its determinant is thus $\prod^n_{k=2}x_k^{k-1}$. Further simplification gives us the stated result.","['probability-distributions', 'multivariable-calculus', 'complex-analysis', 'integration', 'definite-integrals']"
2800238,find value integral $\int_{1}^{2}f(x)dx$,"For a function $f(x)$ determined and continuous with $\forall x\in $ $\Bbb R\setminus\left\{ 0 \right\}$  such that $$x^{2}f^{2}(x)+(2x-1)f(x)=xf'(x)-1$$ and $f(1)=-2$ Find 
$$\int_{1}^{2} f(x)dx $$ I write: 
$$(xf(x)+1)^{2}=(xf(x)+1)'$$ But I do not know how to proceed","['real-analysis', 'integration', 'ordinary-differential-equations']"
2800246,Find the derivative of $h(x) = 1/x^2$ by definition,"Can someone please explain the process of finding the derivative $h'(x)$ of 
$h(x) = \dfrac{1}{x^2} $ using the delta ($\Delta$) notation. What I managed: $h '(x) \displaystyle = \lim _{\Delta x\rightarrow 0} \frac{h(x+\Delta x)- h(x)}{\Delta x}$ $h '(x) \displaystyle = \lim _{\Delta x\rightarrow 0} \frac{1/(x+\Delta x)^2 - 1/x^2}{\Delta x}$ $h '(x) \displaystyle = \lim _{\Delta x\rightarrow 0} \frac{x^2-(x+\Delta x)^2}{(x+\Delta x)^2x^2\Delta x}$ And after this point, I do not know how to proceed. The next steps have been given as: $h '(x) \displaystyle  = \lim _{\Delta x\rightarrow 0} \frac{-2x\Delta x - (\Delta x)^2}{(x+\Delta x)^2x^2\Delta x}$ $h '(x) \displaystyle  = \lim _{\Delta x\rightarrow 0} \frac{-2x - \Delta x}{(x+\Delta x)^2x^2}$ With the answer being $h'(x) = -\dfrac{2}{x^{3}}$ Can someone please explain the process between steps 3 and 4?","['derivatives', 'calculus', 'limits']"
2800269,Show $A(x) = \int_{0}^{x}f(t)dt$ is convex if $f(x)$ is increasing.,"Not using $f'(x) = A''(x)$, and that $A''(x) >0$ means convex, Show $A(x) = \int_{0}^{x}f(t)dt$ is convex if $f(x)$ is increasing. This is from Apostol Calculus Vol. 1, Theorem 2.9 Pg. 122 . My try is given For a function to be convex in $[a,b]$ we need $\forall \alpha \in (0,1)$ $$f(\alpha b + (1-\alpha) a) < (\alpha) f(b) + (1-\alpha) f(a)$$ Using this, we need to show $A(\alpha x) < \alpha A(x)$ Now $A(\alpha x) = \int_0^{\alpha x} f(t) dt = \alpha \int _{0}^{x} f(\alpha t) dt < \alpha \int_{0}^{x} f(t) dt = \alpha A(x)$ because $t > \alpha t \implies f(t) > f(\alpha t)$. Is this proof alright, and how can I write it more properly. I am self learning calculus and will then proceed to real analysis.","['calculus', 'functions']"
2800348,"Showing that the $n$-th positive integer that is not a perfect square is $n+\{\sqrt{n}\}$, where $\{\}$ is the ""closest integer"" function","Answering a question on sequences which asks to show If $a_n$ denotes the $n$-th positive integer that is not a perfect square, then 
  $$a_n = n + \{ \sqrt n \}$$ 
  where $\{ x \}$ is the closest integer to the real number $x$. I argued as follows: Given a positive integer $n$,  there is some positive integer $m$ such that $$m^2 - m + 1 \le n \le m^2 + m$$ and hence $$\sqrt { m^2 - m + 1 } \le\sqrt n\le\sqrt{ m^2 + m }$$ Since $$m -\frac12 < \sqrt{ m^2-m+1 }\,,\,\,\text{and}\;\; \sqrt{m^2 + m} < m + \frac12$$ then $$m - \frac12 < \sqrt n < m + 1/2$$ 
hence  $\sqrt n = m$. By this, 
$$m^2 + 1 \le n + \sqrt n  \le m^2 +2m$$ 
and no integer from $m^2 + 1$ to $m^2 + 2m$, inclusive, is a perfect square. Now: Is the first step (defining the $m$-based interval where $n$ lies) valid? Thanks in advance :)","['sequences-and-series', 'discrete-mathematics']"
2800359,How to solve this differential equation numerically in Python?,"I am trying to solve a differential equation in Python:
    $$y'' + 2\frac{y'}{x} + (1 - \frac{e^{-x}}{x} - \frac{l(l+1)}{x^2})y = 0$$
I have initial conditions at $x=0$ as:
    $$y(0) = a$$
    $$y'(0) = b$$
$a$ and $b$ are some known constants and they will be constrained by $l$. I tried using Euler forward method but solution was unstable. I tried Runge-Kutta 2nd order method but again the solution was unstable. What method should I use so that I will get a stable solution?","['numerical-methods', 'ordinary-differential-equations', 'python']"
2800425,"Converting parametric $x = \sec \theta + \tan \theta$, $y = \csc\theta + \cot\theta$ to Cartesian form","This question comes from Solomon C4 Paper K, Question 7b. Consider the parametric equations: $$\begin{align}
x &= \sec(\theta) + \tan(\theta) \\
y &= \csc(\theta) + \cot(\theta)
\end{align}$$ I would like to express them in Cartesian form. To check my answer, I have used the Desmos Graphing Calculator to draw the graph of the parametric equations ($-\pi<\theta<\pi$): Firstly I find: $$\begin{align}
x+\frac{1}{x} &= 2\sec(\theta) \\[4pt]
y+\frac{1}{y} &= 2\csc(\theta)
\end{align}$$ Dividing the first equation by the second: $$\frac{x+\dfrac{1}{x}}{y+\dfrac{1}{y}}=\tan(\theta)$$ Using both the original parametric equation for $x$ and the one found allows me to simplify to: $$y+\frac{1}{y} = \frac{2\left(x+\dfrac{1}{x}\right)}{x-\dfrac{1}{x}}$$ At that point, I decide to check with Desmos again: This graph seems to include the one found from the parametric equations, but with an extra negative reciprocal curve. At this point, I check the mark scheme for the question, and find that it simplifies to: $$\begin{align}
\cos(\theta)&=\frac{2x}{x^2+1} \\[4pt]
\sin(\theta)&=\frac{2y}{y^2+1}
\end{align}$$ It then uses the identity: $\sin^2A+\cos^2A=1$ to form the following Cartesian equation: $$\frac{4y^2}{(y^2+1)^2}+\frac{4x^2}{(x^2+1)^2}=1$$ Plugging that into Desmos returns: This graph once again includes the original one, but with even more extra reciprocal curves. I think this is because of the squares in the identity used. I then decide to muck around with various reciprocal equations until I find one that matches the first graph. I find: $$y=\frac{2}{x-1}+1$$ At this point, I am very confused. How (if it is possible) can I get from my parametric equations to that final Cartesian equation? Where (if I am going wrong) am I (and the mark scheme) going wrong with the first two attempts? Do the first two Cartesian equations have solutions that are not solutions for the parametric equations?","['parametric', 'trigonometry', 'graphing-functions']"
2800484,Must a matrix of which all conjugates have zero diagonal be zero?,"Let $A$ be an $n \times n$ real matrix with the following property: All the conjugates of $A$ have only zeros on the diagonal. Does $A=0$? (By conjugates, I mean all the matrices similar to it, over $\mathbb{R}$, that is I require the conjugating matrix to be real). Of course, if $A$ is diagonalizable, then clearly it must be zero. The only idea I have is to use the Jordan form for real matrices , but after some thought I am not sure this is a good approach.","['matrices', 'matrix-equations', 'matrix-calculus', 'linear-algebra']"
2800514,Intuition for warped product manifold.,"I am reading about wave equations in manifold and encountered the term warped product manifold . More specifically, in my case it is defined as follows, $$N:=[0,\phi^*)  \times_g \mathbb S^{k-1}$$
  where $\phi^* \in \Bbb R\cup\{+\infty\}$ and $g:\Bbb R\to\Bbb R$ is an odd smooth function such that $g(0)=0, g'(0)=1$. On $N$ we have the ''polar'' coordinates $(\phi,\chi) \in [0,\phi^*)\times \mathbb S^{k-1}$. In these coordinates the metric of $N$ takes the form 
  $$
d\phi^2 + g^2(\phi)d\chi^2
$$
  where $d\chi^2$ is the standard metric of $\mathbb S^{k-1}\hookrightarrow \Bbb R^k$. How should I think of $N$ is this case? More importantly, what is a warped product manifold in general? Any help is very appreciated.","['semi-riemannian-geometry', 'riemannian-geometry', 'general-relativity', 'partial-differential-equations', 'differential-geometry']"
2800554,Can we express $\pi$ in terms of $\sum_{n=1}^\infty\frac1{n^2}$?,Since $$\sum_{n=1}^{\infty} \frac{1}{n^2}=\frac{\pi^2}{6}$$ can we now express $\pi$ in terms of this series by multiplying by $6$ and taking the square root? If not why is this not true? I was wondering since I had an exam question that required to write $\pi$ in terms of some infinite sum. I did it exactly like this and got 0 points. So I thought maybe I'm doing something wrong by manipulating it this way,"['real-analysis', 'summation', 'sequences-and-series', 'pi']"
2800580,Norm compatibility of ideals and ideles,"Let $L|K$ be a finite separable extension of global fields, $\mathbb{I}$ the idele group and $\mathcal{I}$ the group of fractional ideals. We have a surjective homomorphism from $\mathbb{I}\to\mathcal{I}$ given by 
$a\mapsto\prod\mathfrak{p}^{v_{\mathfrak{p}}(a)}$. The idele norm between 
$\mathbb{I}_{L}$ and $\mathbb{I}_{K}$ is given by $N_{L|K}(b_{w})=(a_v)$ where each $a_{v}$ is given by $a_{v}:=\prod_{w|v}N_{{L_{w}|K_{v}}}(b_{w})$. The ideal norm is given by $\mathfrak{P}\mapsto \mathfrak{p}^{f(\mathfrak{P}|\mathfrak{p})}$ and is extended linearly. Why is the diagram
$\require{AMScd}$
\begin{CD}
\mathbb{I}_{L} @>>> \mathcal{I}_{L}\\
@V{N_{L|K}}VV @V{N_{L|K}}VV \\
\mathbb{I}_{K} @>>> \mathcal{I}_{L};
\end{CD}
commutative?","['number-theory', 'class-field-theory', 'algebraic-number-theory']"
2800584,Minor Detail in the Proof of the Spectral Radius Formula,"Theorem : Let $A$ be a Banach Algebra then for $x\in A$ the spectral radius $r(x)$ of $x$ satisfies $$r(x)=\lim_{n\rightarrow\infty}\|x^n\|^\frac{1}{n}.$$ The proofs that I have seen of this (I have mostly been using Murphy: C* algebras and operator theory, and a few sets of online lecture notes which follow his book) show that if $\lambda\in\mathbb{C}$ satisfies $r(x)<|\lambda^{-1}|$ then $\limsup_{n\rightarrow\infty}\|x^n\|^\frac{1}{n}\leq|\lambda^{-1}|$, in fact I am quite happy with showing this inequality. However what I don't understand is why we then can conclude that $\limsup_{n\rightarrow\infty}\|x^n\|^\frac{1}{n}\leq r(x)$, I mean it must be really trivial because everybody just concludes it without a second thought, but I just can't for the life of me see how it follows. Can anybody help me? I'm sorry that it's probably a very silly question.","['functional-analysis', 'spectral-theory', 'banach-algebras']"
2800586,Uniqueness in Bernstein's theorem of calculus of variations,"I'm working through Gelfand and Fomin's book on calculus of variations. One of the book's exercises is to prove the uniqueness portion of a result called ""Bernstein's theorem"" on solutions to equations of the form $y'' = F(x, y, y')$. The book states the theorem thus: If the functions $F$, $F_y$, and $F_{y'}$ are continuous at every finite point $(x, y)$ for every finite $y$, and if a constant $k > 0$ and functions $$\alpha = \alpha(x, y) \geq 0, \qquad \beta = \beta(x, y) \geq 0$$ (which are bounded in every finite region of the plane) can be found such that $$F_y(x, y, y') > k, \quad |F(x, y, y')| < \alpha y'^2 + \beta,$$ then one and only one integral curve satisfying $y'' = F(x, y, y')$ passes through any two points $(a, A)$ and $(b, B)$ with different abscissas ($a \neq b$). (Subscripts on $F$ mean partial derivatives.) The hint for the exercise is: Let $\Delta(x) = \varphi_2(x) - \varphi_1(x)$, where $\varphi_1(x)$ and $\varphi_2(x)$ are two solutions of $y'' = F(x, y, y')$, write an expression for $\Delta''$ and use the condition $F_y(x, y, y') > k$. Following the hint, I got the expression $$\Delta''(x) = F(x, \varphi_2(x), \varphi'_2(x)) - F(x, \varphi_1(x), \varphi_1'(x)).$$ I thought that I could use the condition on $F_y$ to get some sort of lower bound on the magnitude of the RHS of this equation, and then try to turn that into some sort of proof that $\Delta(a)$ and $\Delta(b)$ cannot both be zero. But because $\varphi_1'(x) \neq \varphi_2'(x)$, I don't know what I can conclude about $ F(x, \varphi_2(x), \varphi'_2(x)) - F(x, \varphi_1(x), \varphi_1'(x))$ unless I also know something about $F_{y'}$ as well as $F_y$, and the theorem imposes only a very weak hypothesis, continuity, on $F_{y'}$.","['functional-analysis', 'calculus-of-variations']"
2800600,Extended $3$square problem,"We know about the famous 3-square problem. Draw three adjacent squares with same size and any two adjacent square has a common side. This looks like a rectangle. Name all of the vertices of square in anti clock wise from $A$ to $H$. Join $HB$, $HC$, and $HD$.
  Prove that
  $$\angle{ABH}+\angle{ACH}+\angle{ADH}=90^\circ$$ Visual proof of 3-square problem. In this figure we can find three congruence right-angled triangles which are in yellowish-green color and their hands are in ratio $2:1$ and we can see two isosceles right angled triangle. Orange colored angle symbol denote half right angle (i.e,$45^\circ$). In square $ABGH$, $HB$ is the diagonal of square. By using the property of diagonal of square we get, $\angle{ABH}=45^\circ$. We also know that $\angle{ABH}+\angle{ACH}+\angle{ADH}=90^\circ$. From above two equations, we get $\angle{ACH}+\angle{ADH}=45^\circ$. $\square$ Now, for my question: Let $n$ be the number of squares. Is it possible, for $n$-squares, for the sum of all angles which lies below each line to became $180^\circ$?","['trigonometry', 'triangles', 'geometry']"
2800612,"For $0 < x < \pi/2 $, prove that $x + \frac{x^{3}}{3} <\tan x $","I proved as follows: Let $f(x) = \tan x -  x - \frac{x^{3}}{3}.$ Then $f '(x) = \sec^{2}x - 1 - x^{2}$ and $f''(x) = 2\sec^{2}x\tan x-x > \tan x - x,$ since $\\tan x > x,$ $f''(x) > 0$ so $f'(x)$ is increasing. Since $f '(0) = 0,$ $f '(x) > 0$ for all $x \in (0, \frac{\pi}{2}).$ So $f(x)$ is increasing. since $f(0) = 0,$ $f(x) > 0$ for all $x \in (0, \frac{\pi}{2}).$ But my proof seems complex. Is there any simpler way to prove this?","['derivatives', 'inequality']"
2800627,Hypothesis testing - Experiment with replacement,"Exercise : A box contains 4 balls out of which $\theta$ are white and $4-\theta$ are black. Suppose that you want to check the null hypothesis $H_0 : \theta =2$ against the alternative $H_1 : \theta \neq 2$ . You draw 2 balls with replacement from the box and if they are both of the same color you reject the null hypothesis. i) Calculate the confidence level $a$ of the test above. ii) If the box contains 3 white balls, calculate the probability of the type two error for the test above. Question : First of all doea the last phrase means that you draw one ball first and then replace it and draw a second one too? Can someone please clarify me the test mentioned? Generally, I know that : $$a = \mathbb{P}(reject H_0 | H_0 true)$$ How would I express this probability though ? Obviously due to replacement he events are independent and then the probability of drawing 2 of the same color is : $$\mathbb{P}(2black) = \mathbb{P}(black)\cdot  \mathbb{P}(black) = \frac{(4- \theta)^2}{16}$$ $$\mathbb{P}(2white) = \mathbb{P}(white) \cdot  \mathbb{P}(white) = \frac{\theta^2}{16}$$ Also the type II error is : $$P(accept H_0 | H_1 true)$$ Can someone help me formulate the expression for $a$ ? I would really appreciate a thorough explanation.","['statistics', 'probability', 'hypothesis-testing', 'probability-distributions']"
2800636,Why $Dom(f)$ needs to be open for $Df(a)$ to work?,M. Spivak in Calculus on Manifolds defined differentiability as: $f:\mathbb R^n\to\mathbb R^m$ is differentiable at $a\in\mathbb R^n$ if there exists a linear transformation $\lambda:\mathbb R^n\to\mathbb R^m$ such that $$\lim_{h\to0}\dfrac{|f(a+h)-f(a)-\lambda(h)|}{|h|}=0$$ $\lambda$ is denoted by $Df(a)$ which is called the derivative of $f$ at $a.$ He made the following remark regarding the above definition: The definition of $Df(a)$ could be made if $f$ were defined only in some open set containing $a.$ Here is the problem I am facing. Why the domain of $f$ needs to be open for the definition to work?,['multivariable-calculus']
2800674,Evaluate $\lim\limits_{x\to 0 } \frac{ e^{\frac{\ln(1+ax)}{x}} - e^{\frac{a\ln(1+x)}{x}}}{x}$.,"Problem Evaluate
$$\lim_{x\to 0 } \frac{ e^{\frac{\ln(1+ax)}{x}} - e^{\frac{a\ln(1+x)}{x}}}{x}.$$ Solution For  convenience, denote $u(x)=\dfrac{\ln(1+ax)}{x}$ and $v(x)=\dfrac{a\ln(1+x)}{x}.$ Notice that $u(x),v(x) \to a$ as $x \to 0.$Hence,
\begin{align*}
\lim_{x\to 0 } \frac{ e^{\frac{\ln(1+ax)}{x}} - e^{\frac{a\ln(1+x)}{x}}}{x}&=\lim_{x\to 0 } \frac{e^{v(x)}(e^{u(x)-v(x)}-1)}{x}\\&=\lim_{x \to 0}\left(e^{v(x)}\cdot\frac{e^{u(x)-v(x)}-1}{u(x)-v(x)}\cdot \frac{u(x)-v(x)}{x}\right)\\&=\lim_{x \to 0}e^{v(x)}\cdot\lim_{x \to 0}\frac{e^{u(x)-v(x)}-1}{u(x)-v(x)}\cdot \lim_{x \to 0}\frac{u(x)-v(x)}{x}\\&=e^a \cdot 1 \cdot\lim_{x \to 0}\frac{\ln(1+ax)-a\ln(1+x)}{x^2}\\&=e^a \cdot\lim_{x \to 0}\dfrac{ax-\dfrac{1}{2}a^2x^2+\mathcal{O}(x^2)-a\left(x-\dfrac{1}{2}x^2+\mathcal{O}(x^2)\right)}{x^2}\\&=e^a \cdot\lim_{x \to 0}\dfrac{-\dfrac{1}{2}a^2x^2+\dfrac{1}{2}ax^2+\mathcal{O}(x^2)}{x^2}\\&=\frac{1}{2}e^a(a-a^2). \end{align*} Please correct me if I'm wrong! Hope to see other solutions.","['solution-verification', 'limits']"
2800692,Find $x^5+x^{-5}$ given the value of $x^2+x^{-2}$.,"Find $x^5+\dfrac1{x^5}$ in its simplest form given that $x^2+\dfrac1{x^2}=a$ for $a,x>0$. Attempt: We write $$x^2+\frac1{x^2}=a\implies x^4-ax^2+1=0\implies x^5=ax^3-x$$ and $$\frac1{x^2}=a-x^2\implies \frac1{x^4}=a^2-2ax^2+x^4\implies \frac1{x^5}=\frac{a^2}x-2ax+x^3$$ so $$\begin{align}x^5+\frac1{x^5}&=(1+a)x^3-(1+2a)x+a^2\cdot\frac1x\\&=(1+a)x^3-(1+2a)x+a^2(ax-x^3)\\&=(1+a-a^2)x^3-(1+2a-a^3)x\\\implies x^5+\frac1{x^5}&=(a^2-a-1)x(a+1-x^2)\end{align}$$ But is this in its simplest form?","['algebra-precalculus', 'radicals']"
2800710,Prove $\lim_{n \to \infty}\frac{\ln (n+1)}{(n+1)(\ln^2 (n+1)-\ln^2 n)}=\frac{1}{2}$,"Problem Prove $$\lim_{n \to \infty}\frac{\ln (n+1)}{(n+1)[\ln^2 (n+1)-\ln^2 n]}=\frac{1}{2},$$ where $n=1,2,\cdots.$ My Proof Consider the function $f(x)=\ln^2 x.$ Notice that $f'(x)=2\cdot \dfrac{\ln x}{x}.$ By Lagrange's Mean Value Theorem, we have $$\ln^2(n+1)-\ln^2 n=f(n+1)-f(n)=f'(\xi)(n+1-n)=f'(\xi)=2\cdot \frac{\ln \xi}{\xi},$$ where $n<\xi<n+1.$ Moreover, consider another function $g(x)=\dfrac{\ln x}{x}.$ Since $g'(x)=\dfrac{1-\ln x}{x^2}<0$ holds for all $x>e,$ hence $g(n+1)<g(\xi)<g(n)$ holds for every sufficiently large $n.$ Therefore, $$\frac{1}{2} \leftarrow\frac{1}{2}\cdot\dfrac{g(n+1)}{g(n)}<\dfrac{\ln (n+1)}{(n+1)[\ln^2 (n+1)-\ln^2 n]}=\frac{1}{2}\cdot\dfrac{g(n+1)}{g(\xi)}<\frac{1}{2}\cdot\dfrac{g(n+1)}{g(n+1)}=\frac{1}{2}.$$ Thus, by Squeeze Theorem, we have that the limit we want equals $\dfrac{1}{2}.$ Am I right? The proof above is not natural to me. Any other proof ?",['limits']
2800738,Operator norm in Hilbert space [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let $\mathcal{B}(F)$ the algebra of all bounded linear operators on an infinite-dimensional complex Hilbert space $F$. If $A\in \mathcal{B}(F)$, why $(\|A^n\|^{1/n})_n$ is a decreasing sequence?","['matrices', 'functional-analysis']"
2800753,Intuition for semistable points on a $G$-variety.,"I'm reading some lecture notes on the relationship between GIT quotients and symplectic reduction, and came across the definition of a semistable point. For completeness, I will re-write it below: Let $G$ be a complex reductive algebraic group and $(X,\mathcal{O}_X(1))$ a polarized $G$-variety. If we form the ring $$R(X) = \bigoplus_{d\geq 0} H^0(X,\mathcal{O}_X(d)),$$ the action on $X$ induces an action on $R(X)$, so we have the (sub)ring of invariants $R(X)^G$. Then a point $x\in X$ is called semistable if $s(x) \neq 0$ for some $s\in R(X)^G_{>0}$. I frankly do not have any intuition for this definition. I found this question but the discussion there wasn't particularly helpful. Is there a Hartshorne-level way of thinking about this that lends some intuition for why this is a desirable property (or even why its called semistable)?","['geometric-invariant-theory', 'algebraic-geometry']"
2800760,Why every localizable measure space is semifinite measure space?,"Let $(X,\mathcal{E},\mu)$ be a measure space. We recall the following two definitions: $(X,\mu)$ is called semifinite measure space if for each $E \in \mathcal{E}$ with $\mu(E) = \infty$ , there exists $F \subset E$ and $F \in \mathcal{E}$ and $0 < \mu(F) < \infty$. $(X,\mu)$ is called localizable measure space if it can be 
  partitioned into a (possibly uncountable) family of measurable subsets $X_{\lambda}$ such that (i) $\mu(X_{\lambda})< \infty$ for all $\lambda$. (ii) a subset $A\subseteq X$ is measurable if and only if $A\cap X_{\lambda}$ is measurable for all $\lambda$. (iii) $\mu(A) =\sum_{\lambda}\mu(A\cap X_{\lambda})$ for every measurable $A\subseteq X$. For more details about localizable measure space one can see here . Why every localizable measure space is semifinite measure space?","['measure-theory', 'elementary-set-theory']"
2800781,A problem on Measure preserving dynamical system,"Let us consider a measure preserving dynamical system $(X,\mathscr{B},\mu,T)$, where $X$ is a compact metric space, $\mathscr{B}$ is a $\sigma$- algebra which contains the Borel $\sigma$-algebra on $X$ and $T:X\rightarrow X$ is continuous. Then for some fixed $\:f:X\rightarrow \mathbb{R}$ continuous, can we say that  $$\mathbb E_\mu(f|T^{-1}\mathcal B)=0 \implies f = 0$$ [ This question came up in my mind when studying the proof of Proposition 3.4 from 'Recurrence in Ergodic Theory and Combinatorial Number Theory' by Harry Furstenberg. ] Thanks in advance for any help.","['dynamical-systems', 'ergodic-theory', 'measure-theory']"
2800782,Finding the probability that an ace is found in every pile when a deck of cards is split into 4,"I'm trying to answer this question and you are supposed to use the multiplication rule to solve it: A deck of 52 playing cards is randomly divided into four piles of 13 cards each. Compute the probability that each pile has exactly 1 ace. I started off by defining following 4 events: $A_{1}, A_{2}, A_{3}$ and $A_{4}$ where $A_{i}$ denotes the event that exactly one ace is found in the i$^{th}$ pile - so to find the probability I need to find the probability of the intersection of all these events which is where I can use the multiplication rule. The multiplication rule says that $$\mathbb{P}(A_{1} \cap A_{2} \cap A_{3} \cap A_{4})= \mathbb{P}(A_{1}) \mathbb{P}(A_{2}|A_{1}) \mathbb{P}(A_{3}|A_{2} \cap A_{1}) \mathbb{P}(A_{4}|A_{3} \cap A_{2} \cap A_{1})$$ to find each of the probabilities on the RHS I looked compared the possible combinations allowed for each situation: The number of possible card combinations such that $A_{1}$ holds is $\binom{48}{12}$ and the total number of possible card combinations for the first pile is $\binom{52}{13}$. It then follows that $$\mathbb{P}(A_{1})= \frac{\binom{48}{12}}{\binom{52}{13}}=\frac{1406}{4165}$$ When moving on to the second pile, it follows that we now have 39 cards remaining so in order for the pile 2 to have exactly one ace, it leads to $\binom{36}{12}$ possible combinations out of the $\binom{39}{13}$ total number of combinations and so we get that
$$\mathbb{P}(A_{2}|A_{1}) = \frac{\binom{36}{12}} {\binom{39}{13}} =\frac{225}{703}$$. Continuing on in this way I got that $$\mathbb{P}(A_{3}|A_{2} \cap A_{1}) = \frac{\binom{24}{12}}{\binom{26}{13}}=\frac{13}{50}$$ and by the way I have defined my events, it means that 
$$\mathbb{P}(A_{4}|A_{3} \cap A_{2} \cap A_{1}) = 1$$ so by the multiplication rule I get that $$\mathbb{P}(A_{1} \cap A_{2} \cap A_{3} \cap A_{4}) = \frac{1406}{4165} \frac{225}{703} \frac{13}{50} \approx 0.0281$$ However the answer I am given says it should be $\approx 0.105$. Can anyone help me to see where I have gone wrong? Would it perhaps be that defining the events differently lead to different probabilities? Thanks!","['problem-solving', 'probability']"
2800822,Does there exist a series with property $n\sum_{k=0}^{\infty} u_{nk}=1$?,"Shortly, the idea is to find such series which admits ""lazy"" calculation: instead of computing all the terms, it would be enough to calculate its even terms (the case with $n=2$), and then multiply result by $2$; or calculate third of its terms (the case with $n=3$), and then multiply result by $3$; etc. It seems that we can construct such series for finite set of values $n$ (say, for $n\in\{1,2,4,8\}$ or $n \in \{1,2,3,4\}$). So, my Question is: does there exist a series 
$$\sum_{k=0}^{\infty} u_{k}=1,$$
such that for each $n\in\mathbb{N}$:
$$n\sum_{k=0}^{\infty} u_{nk}=1. \quad (?) \tag{1}$$",['sequences-and-series']
2800845,find intermediate points on small circle of a sphere,"What I know/have: A sphere S with radius $r_0=1$ centered in Cartesian space at $c_0=(0,0,0)$ Three points on the sphere $S$: $p_1$, $p_2$, and $p_3$ A plane $P$ through the points $p_1$, $p_2$, and $p_3$ A circle $C$, which is produced by intersecting plane $P$ with sphere $S$. All points $p_1$, $p_2$, and $p_3$ are on the circle $C$ The arc $A$ when going from $p_1$ over circle $C$ to $p_3$ has the interesting property that at fraction $0.5$ of its total distance, we find $p_2$ Hence, at fraction $0$ of the total distance of arc $A$ we find $p_1$, and at fraction $1$ of the total distance of arc $A$ we find $p_3$ What I want: A point $p_4$ in Cartesian space ($x$,$y$,$z$ with respect to origin $c_0$), which lies on the arc $A$ at an arbitrary fraction $X$ of the total distance that arc $A$ spans from $p_1$ to $p_3$ From a computational perspective this would mean: input coordinates of 3 points and a fraction output coordinates of 1 point Unfortunately all the steps in between are a black box to me in terms of the mathematical/computational steps involved and I would appreciate a solution ... or help with finding the solution myself. Visualization of the Problem The visualization was drawn by hand using geogebra so please just assume the assumptions above hold true (although it might look different in the visualization) Previous research: The Great Circle is the circle that comes from intersecting a sphere and a plane that contains the origin of the sphere as a point There are computations for finding intermediate points along the Great Circle Distance in Ed William's Aviation Formulary In my case, the plane does NOT contain the origin of the sphere but three other points on the sphere What I am looking for are intermediate points on a ""Small Circle Distance"" Appendix (not required for answering the question) - Real-Life application: When measuring EEG data, there is a conventional set of rules how to place electrodes (white buttons in image below) on the scalp of a human. Usually this is measured with a measuring tape but of course we can also model the human head by a geometrical sphere and compute the relative electrode positions on that sphere (based only on rules and the initial, arbitrary placement of one electrode ... no measurements involved then). Looking at figure B of the image above, and relating to this question, let's assume I know the positions $F7$, $F8$, and $Fz$. Knowing the rules, $F3$ and $F4$ will lie at fractions on the contour connecting $F7$ and $F8$ through $Fz$.","['spheres', '3d', 'trigonometry', 'geometry']"
2800851,Show that differential map $df : TM \to \mathbb{R}$ of a smooth map $f: M \to \mathbb{R}$ is smooth.,"I'm trying to prove that for any smooth map $f: M \to \mathbb{R}$ on a manifold $M$ to the real numbers, the map $df : TM \to \mathbb{R}$ from the tangent bundle $TM$ to the real numbers given by $df(v) = v(f)$ is smooth. I was told that I need to show that every component of $df$ is smooth, using a coordinate map of the tangent bundle $TM$ (with respect to a chart on $M$ and the natural projection map from $TM$ to $M$). I'm pretty sure that I need to show that $df$ is smooth with respect to any given smooth vector field on $M$. My plan was to show that the composition of the inverse of a chart of $TM$ and $df$ is a smooth diffeomorphism, as one proves that any vector field can be written as a linear combination of smooth functions and the partial derivitive of the components of a chart. But I'm having a hard time trying to write out each components explicitly. I would love some helps!! P.S. I'm new here, and I apologive that I don't know how to write mathematical symbols as in LaTeX when asking a question.","['tangent-bundle', 'smooth-manifolds', 'differential-geometry']"
2800873,Presentation of the holomorph of $\mathbb Z/5 \mathbb Z$,"When I look up the presentation of the holomorph of $\mathbb Z/5 \mathbb Z$ it reads like the following:
$\left\langle a,b \mid a^5 = 1, b^4 = 1, bab^{-1} = a^2\right\rangle$ See https://groupprops.subwiki.org/wiki/General_affine_group:GA(1,5) The automorphisms of $N := \mathbb Z/5 \mathbb Z$ are as follows $Aut(N) = \{\iota, \psi, \psi^2, \psi^3\}$ 
where $\psi: \mathbb Z/5 \mathbb Z \to \mathbb Z/5 \mathbb Z$ via $x \mapsto 3\cdot x$ and $\iota: \mathbb Z/5 \mathbb Z \to \mathbb Z/5 \mathbb Z$ via $x \mapsto x$. This means in detail: $\psi(x) = 3\cdot x$ $\psi^2(x) = -x$ $\psi^3(x) = 2\cdot x$ $\psi^4(x) = x$ Define the holomorph of $N$ as $G := N \rtimes Aut(N)$ via $(g_1, \eta_1)\star (g_2, \eta_2) := (g_1 + \eta_1(g_2), \eta_1\circ\eta_2)$.
Note $(0,\iota)$ is the identity element in $G$. Define (possible) generators $x := (1,\iota)$ and $y := (0, \psi)$ of $G$. $x^2 = (1,\iota)\star (1,\iota) = (1 + \iota(1),\iota\circ\iota) = (1 + 1,\iota\circ\iota) = (2,\iota)$ $x^3 = (1+2,\iota) = (3,\iota)$ $x^4 = (4,\iota)$ $x^5 = (0,\iota)$ $y^2 = (0, \psi) \star (0, \psi) = (0 + \psi(0), \psi\circ\psi) = (0+0,\psi^2) = (0,\psi^2)$ $y^3 = (0, \psi^3)$ $y^4 = (0, \psi^4) = (0,\iota)$ $y\star x \star y^{-1} = (0, \psi)\star (1,\iota) \star (0, \psi^3) = (0+\psi(1),\psi) \star (0, \psi^3) = (3,\psi) \star (0, \psi^3) = (3+\psi(0),\psi^4) = (3,\iota)= x^3$ So, everything works out except for $y\star x \star y^{-1} =x^3$ instead of $y\star x \star y^{-1} = x^2$ as in the presentation given above. Questions : Did I make an error? (I apologize if it is obvious to you.) Are the presentations $\left\langle a,b \mid a^5 = 1, b^4 = 1, bab^{-1} = a^2\right\rangle$ and $\left\langle a,b \mid a^5 = 1, b^4 = 1, bab^{-1} = a^3\right\rangle$ equivalent? If so, is there an easy argument? Thank you for your thoughts!","['combinatorial-group-theory', 'group-presentation', 'group-theory', 'holomorph', 'semidirect-product']"
2800874,Squares in the sequence $ a3^n+b$,"Let $a \in \mathbb{N}, b \in \mathbb{Z}$.  Define $n$ to be the largest nonnegative integer such that the sequence $ \{a_1, a_2, \ldots, a_n \}$ consists entirely of squares of natural numbers, where $a_n := a3^n+b$?  For which values of $a,b$ does $n$ achieve a maximum value? I managed to prove that the sequence is finite for any given $a,b$, but I have not gone further than this.  I would be happy with any hint. Thank you","['number-theory', 'square-numbers', 'sequences-and-series']"
2800907,Conformal mapping between disk and the complement of a spiral,The Riemann mapping theorem guarantees the existence of a biholomorphic mapping between the unit disk and the complement in the complex plane of an (archimedean or logarithmic) spiral ... is it known an explicit formula for such a map? Anyone knows something about such functions and can provide me any reference? Thanks in advance,"['complex-analysis', 'conformal-geometry']"
2800910,What is the conditional probability distribution for who wrote this particular exam?,"A small course has 3 students, $B$, $C$ and $D$. Based on the previous
  testscores of these students we know that $B$ usually scores $80$%
  correct on the exam questions, $C$ scores $60$% and $D$ scores $40$%.
  The anonymous test that is now corrected has $4$ correct answers out
  of $8$. What is the conditional probability distribution for who took
  this particular exam? This just doesn't want to work. I know Baye's theorem is of use here and possibly the Law of total probability. Let $B=1, \ C=2$ and $D=3.$ Now also let $A_i, \ i=1,2,3$ be the event that person $A_i$ took the test and $X= \ $number of correctly answered question on the test. We are thus looking for $$P(A_i|X=4)=\frac{P(X=4|A_i)P(A_i)}{P(X=4)}.$$ This did not make anything simpler. The only thing I now in the RHS is that $P(A_i)=1/3.$","['probability-theory', 'probability']"
2800931,Hole inside cube with tetrahedrons at corners?,"Given is a unit cube with a tetrahedron at each corner, as shown here for one corner out of the $8$ : It is noticed that the tetrahedrons are not disjoint. Because I cannot look through the cube, I have great difficulty imagining whether there is a hole left inside or not. If there is a hole, what then is the shape of that hole? And what then is the volume of that hole? The volume of one tetrahedron is $1/6$ . This would make a total of $\,8/6\,$ if they were disjoint, but - as I've said - they are not. Apart from the facts some sort of proof would be nice.","['solid-geometry', 'geometry']"
2801008,Is there a naive proof that $x - \frac{x^3}{3!} + \frac{x^5}{5!} - \ldots$ has period $2\pi$?,"I recently visited the far away land of Polynomia.  The mathematicians in Polynomia are quite sophisticated algebraists: they know a lot about polynomials and their associated machinery - rings, fields, algebraic geometry, etc.  But they aren't very good at analysis; they don't know much about differential equations and don't like sophisticated estimates.  They're pretty good with the theory of power series because it involves taking limits of polynomials (which they love), and so they've managed to figure out at least some complex analysis. In my recent visit I got into a discussion about the power series $$f(x) = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \ldots$$ They knew how to prove that this power series converges everywhere on the complex plane, but they were astonished when I told them that $f$ is periodic with period $2\pi$.  (They are aware that the polynomial equation $x^2 + y^2 = 1$ defines a curve in $\mathbb{R}^2$, and they define $2\pi$ to be its arclength.)  You see, since they don't really like differential equations they don't know about functions like $\sin x$, $e^x$, etc. So the Polynomians were pretty incredulous about my claim and they demanded that I prove it.  The proofs I know rely heavily on methods like path integrals of transcendental functions, and their eyes just glazed over.  They're looking for some property of the partial sums of $f$ which, in the limit, guarantees that $f$ is periodic with period $2 \pi$.  Circles are almost certainly going to have to enter into it and I can probably convince to accept path integrals of polynomials along a circle, but the more algebraic the argument the better.  Can anyone help?","['sequences-and-series', 'calculus']"
2801013,Fibered product of schemes and global section functor,"Let $X$ and $Y$ be two $k$-schemes ($k$ is a field  ).Suppose that  $\Gamma(Y,\mathcal{O}_Y) =k$. Is the true that $$\Gamma(X \times_{spec(k)}Y, \mathcal{O}_{X \times_{spec(k)}Y}) = \Gamma(X,\mathcal{O}_X) \otimes_{k}  \Gamma(Y,\mathcal{O}_Y) $$ PS: The categorical argument claiming that global section functor preserves colimits is incorrect as explained in one of the answers. In general the above statement is false.","['schemes', 'abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
2801014,Problem similar to Stieltjes moment problem where $m_n=E[X^n e^{-X}]$,"Suppose that we are given the following sequence of moments:
\begin{align}
m_n=E[X^n e^{-X}], \, n=0,1 \dots 
\end{align}
where $X \ge 0$ (non-negative random variable). Can we show that this sequence of (moments modified by an exponential function) uniquely determines the distribution of $X$. This problem reminds of both the  Stieltjes moment problem and the uniqueness of Laplace transform (except things are discrete here).",['probability-theory']
2801028,Is there a neat way to write the parameterization of this tennis-ball-seam-like curve on the sphere?,"I have been experimenting with drawing curves on the surface of a sphere (of radius 1). In order for it to lie on the sphere, every point $(x,y,z)$ must satisfy:
$$
\begin{equation} \tag{1} \label{Eq1}
x^2 + y^2 + z^2 = 1
\end{equation}
$$
I became interested in drawing something vaguely resembling the seam on a tennis ball: My first guess was to try (for some parameter $\theta$ between $0$ and $2\pi$), $x(\theta)=cos(\theta)$ and $y(\theta)=sin(\theta)$, before I realised that's obviously just a circle and from $(\ref{Eq1})$ we get $z(\theta)=0$ (oops). So instead, I replaced $sin(\theta)$ with a triangular wave: Then, using $(\ref{Eq1})$, I know $z(\theta)$ must satisfy: $$
\begin{equation} \tag{2} \label{Eq2}
z(\theta) = \pm\sqrt{1 - x^2(\theta) - y^2(\theta)}
\end{equation}
$$ If I just take the positive solution for all $\theta$, then my curve is discontinuous. However, if I alternate + and - (or vice versa) for each of the four quadrants, then I get a nice smooth curve like I want: However, I can't figure out if there's a neat equation for describing my $z(\theta)$. It doesn't look so complicated in the graph below. Can someone tell me if there's a neat way of describing it (as some function of $\theta$)? Sorry for the long question and many thanks for your help!","['spheres', 'curves', 'geometry']"
2801062,Is the fixed point at the origin of this dynamical system asymptotically stable?,"I am given a dynamical system $$\dot x = f(x,y)= x - (1+\theta(x))x^3-y \\ \dot y =g(x,y)= y - 3x^2y + x$$ where $\theta(x)$ is a step function which is equal to $1$ when $x \geq 0$ and $0$ when $x<0$. Now I am asked to prove whether or not the fixed point at the origin is asymptotically stable. My thinking so far is as follows. 1) I know that when $x<|\sqrt{\frac{2}{3}}|$ that there can not exist a periodic orbit due to Bendixson's criterion 2) I have found that $\nabla \cdot \pmatrix{f(x,y) \\ g(x,y)} = 2$ when $x<0$ and $\nabla \cdot \pmatrix{f(x,y) \\ g(x,y)} = 2-3x^2$ when $x \geq 0$ 3) I know that if there exists a strict Liapounov function around the fixed point then the fixed point is asymptotically stable 4) Not sure if this is relevant but Poincare bendixson states that if there exists a non empty closed and bounded omega limit set then there is either a fixed point or a periodic orbit. Now I know that there can't be a periodic orbit so there must be a fixed point What I think I need to do I think I need to find a strict Liapounov function which will then allow me to state the fixed point is asymptotically stable. How I am going to find this function is still up in the air, but maybe it's something to do with the fact that the orbital derviative $$\frac{dV}{dt} = \int_{\phi(t,D)} d^nx(\nabla \cdot \pmatrix{f(x,y) \\ g(x,y)})$$ where $\phi(t,D)$ is the region obtained by evolving all the points in a set $D$.","['self-learning', 'dynamical-systems', 'lyapunov-functions', 'general-topology', 'ordinary-differential-equations']"
