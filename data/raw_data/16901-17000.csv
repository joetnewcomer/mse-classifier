question_id,title,body,tags
138243,How to prove $\cosh(x) \ge 1$ without the $\cosh^2x-\sinh^2x=1$ identity,"I think it's pretty easy question, maybe even dumb one, but still I can't find a nice way to solve it. How do you prove that $\forall x . \cosh(x) \ge 1$ , without using the identity: $\cosh^2x-\sinh^2x=1$, and not without using derivatives. the defenition of $\cosh(x)$ is: $\frac{e^x+e^{-x} }{2}$ I already proved that using the identity, but I'm just wondering if there is another way.
sadly, I couldn't find a proof using the search engine, even though that is a very basic question. would appreciate your help!","['inequality', 'trigonometry', 'algebra-precalculus']"
138252,"Expected value of $\ln X$ if $X$ is $\Gamma(a,b)$ distributed.","I'm new here and hope you can help. It's really late here in South Africa, maybe my mind just doesn't want to function now!  But I need to figure out how to get a closed form expression hopefully for $E(\ln X)$  and even $E(\ln (X^2))$  if $X$ is $\Gamma(a,b)$ distributed.
Any help would be greatly appreciated!! Scrofungulus","['statistics', 'special-functions', 'probability']"
138267,Gradient of $A \mapsto \operatorname{trace} (A B A' C)$,"Given three matrices $A$ , $B$ and $C$ such that $ABA^T C$ is a square matrix, the derivative of the trace with respect to $A$ is: $$
\nabla_A \operatorname{trace}( ABA^{T}C )  = CAB + C^T AB^T
$$ There is a proof here, page 4 (PDF file) . However, I was not able to understand the second line of the proof. it says something like this: $$
\nabla_A \operatorname{trace}( ABA^T C )=
\nabla_\bullet \operatorname{trace}(f(\bullet)A^{T}C) + \nabla_\bullet \operatorname{trace}(f(A) \bullet^T C)
$$ Where $f(A) = AB$ I tried searching the proof or any hint using google, but I couldn't fine anything. Could anyone please help me with this second line. I cannot sleep. I am obsessed with this proof.","['trace', 'matrices', 'matrix-calculus', 'derivatives', 'scalar-fields']"
138268,Rewriting automorphism of matrix algebra in terms of automorphisms of the underlying ring?,"I've used the following idea as a black box for some time now, but it occurred to me I don't fully understand why it's true. Suppose $A=M_n(R)$ is the algebra of square matrices over some division ring $R$. Then for any $\phi\in\operatorname{Aut}(A)$, we can actually write $\phi$ as the composition of an automorphism induced by an automorphism $\psi$ of $R$ and the conjugation by some unit of $A$. 
More explicitly, for $\psi\in\operatorname{Aut}(R)$, this induces an automorphism $\tilde{\psi}$ of $A$ by applying $\psi$ to each of the entries in the matrix, for example,
$$
M=\begin{pmatrix}
a_{11} & a_{12}\\ a_{21} & a_{22}
\end{pmatrix}
\mapsto
\tilde{\psi}(M)\begin{pmatrix}
\psi(a_{11}) & \psi(a_{12})\\ \psi(a_{21}) & \psi(a_{22})
\end{pmatrix}
$$
and then we can conjugate by an invertible matrix in $A$, say $N$, to get $N\tilde{\psi}(M)N^{-1}$. I don't think the order of applying $\tilde{\psi}$ or conjugating matters, since if I conjugate first, then I could apply a different $\tilde{\psi}$. So the composition would be something like $\phi=\varphi_N\circ\tilde{\psi}$ where $\varphi_N$ is the conjugation by $N$ map. My question is, why can any automorphism $\phi$ of $A$ actually be decomposed in this way?","['abstract-algebra', 'matrices', 'linear-algebra', 'reference-request', 'modules']"
138284,Differential equation with gaussian noise,"The equation has the following form: $$x'' + w^2 x=n$$ $w=1$, $x(0)=1$, $n$ is Gaussian noise with mean $0$ and standard deviation of $1$. Without the Gaussian noise, i can easily solve the equation numerically by using ODE45 in matlab.The problem is, how can i deal with this equation when the Gaussian noise is taken into consideration?","['stochastic-processes', 'ordinary-differential-equations']"
138290,Finding $E\left[\frac{\sum_{i=1}^n X_i^2}{(\sum_{i=1}^n X_i)^2}\right]$ of a sample of gamma random variables,"Suppose $X_1,\ldots,X_n$ is a random sample from the $\Gamma(k,\lambda)$ distribution where $\lambda$
is unknown and $k$ is a positive integer and known. How can I find $$E\left[\frac{\sum_{i=1}^n X_i^2}{(\sum_{i=1}^n X_i)^2}\right] \>?$$","['statistics', 'probability']"
138295,eigenvalues of the subtraction of a PSD matrix and a rank 1 matrix,"Let $A$ be a positive semi-definite matrix, and let $C$ be a rank 1 matrix. Prove that $A-C$ has at most one negative eigenvalue. PS: It's easy to show that if $A$ and $C$ commute, then the statement is true, but most of the time they do not commute.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
138299,Name of function: $\sum_{i=0}^N(N-i)$,I'm sure this is a really simple question but I have a series and I'm sure it has a name but my math is rusty and I'm not sure what it is. $$ \sum_{i=0}^{N} (N - i)$$ I have an algorithm which has execution time characterized by this function and I'm wondering what to call it.,"['summation', 'terminology', 'functions']"
138310,Show that $2\tan^{-1}(2) = \pi - \cos^{-1}(\frac{3}{5})$,"Show that $2\tan^{-1}(2) = \pi - \cos^{-1}(\frac{3}{5})$ So, taking $\tan$ of both sides I get: LHS $=\frac{2\tan(\tan^{-1}(2))}{1 - \tan^2(\tan^{-1}(2))} = -\frac{4}{3}$ and RHS $= \tan(\pi - \cos^{-1}(\frac{3}{5})) = ~...$ I wasn't sure how to treat the RHS given the $\pi$ term. If it were just $\cos^{-1}(\frac{3}{5})$ I guess I would try to manipulate $\sin^2(\theta) + \cos^2(\theta) = 1$ to try and find something appropriate for substitution; however, I am not sure where to even start with the given $\theta$.",['trigonometry']
138313,How to reach $k\cdot 2^{k+2}$ from $(2k)\cdot 2^{k+1}$?,I was trying to figure out the step between these two equal expression: $$(2k)\cdot 2^{k+1} = k\cdot 2^{k+2}$$,['algebra-precalculus']
138327,Combinatorial argument for $\sum_{k=0}^n k^2 \binom{n}{k} = n(n+1)2^{n-2}$,"Can you please give a combinatorial argument for the argument below? $$\sum_{k=0}^n k^2 \binom{n}{k} = n(n+1)2^{n-2}$$ From RHS, I drew the following argument: There are $n+1$ people. In how many ways, can we pick $n-1$ people and divide them into $2$ distinct committees say $C_1$ and $C_2$. I cannot get the same argument from LHS. Can you help me?","['binomial-coefficients', 'combinatorics']"
138355,Logistic Sigmoid Function with a vector input,"For a statistical learning problem (classification), I have the data set $\{ (x_i,y_i) \}_{i=1}^n$ with $x_i \in \mathbb{R}^2$ being the input data and $y_i \in \{0,1\}$ the possible classes. The data is used to compute the log-likelihood for the data, in that equation I have to compute the logistic sigmoid function $$\sigma(x_i) = \frac{1}{e^{-x_i} + 1}$$ My problem is: The input data of $x$ is a matrix $X \in \mathbb{R}^{n \times 2}$, now I am confused how I can compute the $\sigma(x_i)$ for a certain value, since one value of the matrix is a tuple, respectively a vector, one row of this matrix. Any hints on how to approach this problem and compute my $\sigma(x_i)$? My matrix looks like that: $$\begin{pmatrix}
1.55545  & -1.00055\\
-1.24155 & 1.58778\\
1.28068  & -1.0224\\
\vdots   & \vdots\\
-1.68505 & 0.290898\\
1.73686  & 0.793386\\ 
\end{pmatrix}$$ Hence $x_1 = (1.55545, -1.00055)$, but what is then: $$\sigma(1.55545, -1.00055) = \frac{1}{e^{????} + 1}$$ The only thing I have found is the Vector exponential which claims that it can be computed by: $$exp(v) = 1 \cosh(|v|) + \frac{v}{|v|} \sinh(|v|)$$","['statistics', 'matrices', 'machine-learning']"
138360,Universal property of initial topology,"I'm learning some category theory and I thought I had understood universal objects but maybe I have not because I cannot write down the definition of initial topology in terms of categories. My understanding of universal objects so far: I thought universal objects are either initial or terminal objects in a comma category $(O \downarrow F)$ where $O$ is a selection functor $\textbf{1} \to O \in C$ and $F$ is a forgetful functor into $C$. In the example of a free group, $F: \textbf{Group} \to \textbf{Set}$ and $O$ is the set that generates the free group. The objects in this category are pairs $(f, G)$ where $f$ is a (set-theoretic) map from $S \to G$. Now I would like to do the same for the initial topology but I'm struggling to see what the objects are and also what $F$ should be. $O$ is probably going to be $X$, the space we would endow with the topology. So we probably want $F$ to be a functor $\textbf{Top} \to \textbf{Set}$. The objects are probably $(f,Y)$ where $f$ is a map $X \to Y$ (or $Y \to X$?) such that there exists a continuous map $f^\prime$ with $F(f^\prime) = f$. Is this right? If not: what are the objects? And is the initial topology an initial or a terminal object? Edit I think what I wrote above is wrong: I get one commutative diagram for each $Y_i$ in the family with respect to which the initial topology is defined. This means that the objects are $(g_i, Z)$ where $g_i : Z \to Y_i$ and the comma category would be $(Y_i, F)$. Is this right? The diagram for $(Y_i \downarrow F)$ would look like this: X --(f_i)--> Y_i
              ^
              | 
              |
            (g_i) 
              |
              |
              Z Then the question is whether the unique continuous map $\varphi$ is $Z \to X$ or $X \to Z$.","['general-topology', 'category-theory']"
138363,Show triangulations can be transformed into each other by edge flip.,"Let $\Delta_1$ and $\Delta_2$ be two triangulations of the same point set $P_n$. Show that they can be transformed into each other by edge flips. To define an edge flip, let $pqrs$ be vertices (in clockwise order) of a quadrilateral. If $pr$ is an edge in the triangulation, then $pr$ can be flipped into $qs$. For convex polygon case, it is easy to show there exists a sequence of edge flip that will increase the number of common edges of two different triangulations. But I am stuck in the general case. Any hint?","['graph-theory', 'discrete-mathematics']"
138366,How much algebra is there in Noncommutative Geometry?,"My Professor of Homological Algebra got me into some Hochschild (co)homology and then suggested to continue with formally smooth algebras, noncommutative differential forms and so forth. Now, my personal interest has always been algebra, especially noncommutative (ring and module theory, category theory, some homological algebra). Moreover, my studies have been concerned almost exclusively with such subjects. Hence, I am very bad at calculus, differential geometry etc. I do have the basics, though. I know it's recommendable to have a decent knowledge in most of the subjects, but I got far enough in algebra not needing very much knowledge of calculus, say. What I want to ask you is the following:
Assuming that I got on the way to noncommutative geometry (so it seems to me...), how much algebra is there in? As I said, I really want a career in noncommutative algebra and it would be pretty unpleasant to get involved intensively in a subject which is not my cup of tea. So far, so good, I am enjoying the subject and it interests me in a personal way (not just for school), but I am only at the beginning, I have met only the most basics. I read that Connes somehow started the subject of NG wanting to extend differential geometry for arbitrary (noncommutative) rings, but would you say the current research work in NG, cyclic homology and the like is algebra at its finest or does it have deep and links with something else (what?)? OR am I getting this wrong and there are some other paths ahead, starting from noncommutative differential forms, formally smooth algebras, Hochschild (co)homology and the like? Thank you.","['soft-question', 'noncommutative-geometry', 'abstract-algebra']"
138369,Inscrutable proof in Humphrey's book on Lie algebras and representations,"This is a question pertaining to Humphrey's Introduction to Lie Algebras and Representation Theory Is there an explanation of the lemma in §4.3-Cartan's Criterion ? I understand the proof given there but I fail to understand how anybody could have ever devised it or had the guts to prove such a strange statement... Lemma : Let $k$ be an algebraically closed field of characteristic $0$. Let $V$ be a finite dimensional vector space over $k$, and $A\subset B\subset \mathrm{End}(V)$ two subspaces. Let $M$ be the set of endomorphisms $x$ of $V$ such that $[x,B]\subset A$. Suppose $x\in M$ is such that $\forall y\in M, \mathrm{Tr}(xy)=0$. Then, $x$ is nilpotent. The proof uses the diagonalisable$+$nilpotent decomposition, and goes on to show that all eigenvalues of $x$ are $=0$ by showing that the $\mathbb{Q}$ subspace of $k$ they generate has only the $0$ linear functional. Added: (t.b.) here's the page from Google books for those without access:","['linear-algebra', 'lie-algebras']"
138382,The roots of $t^5+1$,"Just a quick question, how do we go about finding the roots of $t^5 +1$? I can see that since $t^5=-1$ that an obvious root is $\sqrt[5]{-1}$. I am assuming that since there is a $-1$ involved, some of the factors will be complex?
Any help would be welcome.","['complex-numbers', 'algebra-precalculus', 'roots', 'polynomials']"
138406,sum of series involving coth using complex analysis,"I am self-studying complex analysis, so I am a rookie. I ran across an interesting series I am trying to evaluate using CA. Show that $$\sum_{n=1}^{\infty}\frac{\coth(\pi n)}{n^{7}}=\frac{19{\pi}^{7}}{56700}$$ I began by considering $$\oint_{C_{N}}\frac{\pi \cot(\pi z)\coth(\pi z)}{z^{7}}$$ $$=\oint_{C_{N}}\frac{\pi \cos(\pi z)\cosh(\pi z)}{z^{7}\sin(\pi z)\sinh(\pi z)}$$ Where $C_{N}$ is the square centered at the origin with vertices $$(N+1/2)(-1+i), \;\ (N+1/2)(1+i), \;\ (N+1/2)(-1-i), \;\ (N+1/2)(1-i)$$ The poles are located at $$z=0 (\text{order }9), \;\ z=\pm 1, \;\ \pm 2,\ldots, \;\ z=\pm i, \;\ \pm 2i,\ldots$$ So, using the series for the respective trig functions, I get: $$\frac{\pi \cos(\pi z)\cosh(\pi z)}{z^{7}\sin(\pi z)\sinh(\pi z)}$$ $$=\pi \frac{\left(1-\frac{(\pi z)^{2}}{2!}+\frac{(\pi z)^{4}}{4!}-\cdots\right)\left(1+\frac{(\pi z)^{2}}{2!}+\frac{(\pi z)^{4}}{4!}+\cdots\right)}{z^{7}\left({\pi}z-\frac{(\pi z)^{3}}{3!}+\frac{(\pi z)^{5}}{5!}-\cdots \right)\left({\pi}z+\frac{(\pi z)^{3}}{3!}+\frac{(\pi z)^{5}}{5!}+\cdots\right)}$$ $$=\pi \frac{\left(1-\frac{(\pi z)^{4}}{6}+\cdots \right)}{z^{7}(\pi z)^{2}\left(1-\frac{(\pi z)^{4}}{90}+\cdots \right)}$$ Which leads to a residue at z=0 of $\frac{-7{\pi}^{7}}{4050}$, since this is the coefficient of the 1/z term. The residue at $z=n$ is $\lim_{z\to n}\frac{(z-n)}{\sin(\pi z)}\cdot \frac{\pi \cos(\pi z)\coth(\pi z)}{z^{7}}=\frac{\coth(\pi n)}{n^{7}}$ The residue at $z=ni$ is $\lim_{z\to ni}\frac{(z-ni)}{\sinh(\pi z)}\cdot \frac{\pi cot(\pi z)cosh(\pi z)}{z^{7}}=\frac{coth(\pi n)}{n^{7}}$ Now, here is where I am hung up.  Where does the $\frac{19}{56700}$ come from?. There is apparently an error I am making or something I should do I am unaware of. So, by residue theorem, I should get something like: $$\oint_{C_{N}}\frac{\pi \cot(\pi z)\coth(\pi z)}{z^{7}}dz=\frac{-7{\pi}^{7}}{4050}+\text{something}\sum_{n=1}^{N}\frac{\coth(\pi n)}{n^{7}}$$. What I am doing wrong or overlooking?. I do not know how to obtain the $\frac{19}{56700}$.  In order to get $\frac{19}{56700}$, the $\text{something}$ would have to be $\frac{98}{19}$. I could understand it being $4\sum_{n=1}^{\infty}\frac{coth(\pi n)}{n^{7}}$. Of course, this would result in $\frac{7{\pi}^{7}}{16200}$.  Help is greatly appreciated. Thanks very much.","['trigonometry', 'sequences-and-series', 'complex-analysis']"
138452,Nilpotent group and exponent,"If $G$ is a (possibly infinite) nilpotent group generated by elements of bounded order, does it follow that $G$ has finite exponent?","['group-theory', 'abstract-algebra']"
138455,How to figure of the Laplace transform for $\log x$?,"I was looking at a table of common Laplace transforms of functions when I came across the transform for $\log x$.  Apparently, the transform is as follows: $$\mathcal{L} \left\{ \log x\right\}=-\frac{1}{s}\left(\log s + \gamma\right)$$ where $\gamma$ is Euler's Constant. Clearly, because $\gamma$ is present, the integral $$\mathcal{L} \left\{ \log x\right\}=\int_{0}^{\infty} e^{-st}\log t dt$$ must be turned into a sum at some point.  This integral as well looks very similar to $$\Gamma'(1)=\int_{0}^{\infty} e^{-t}\log t dt=-\gamma$$ How should $\mathcal{L} \left\{ \log x\right\}$ be solved? Here is my attempt: Letting $u=st \Rightarrow t =\frac{1}{s}u \Rightarrow dt = \frac{du}{s}$ so we have $$
\mathcal{L} \left\{ \log x\right\}=\int_{0}^{\infty} e^{-st}\log t \, dt=
\frac{1}{s} \int_{0}^{\infty} e^{-u}\log (\frac{1}{s}u)du =
\frac{1}{s} (\int_{0}^{\infty} e^{-u}\log u\, du -\log s\int_{0}^{\infty} e^{-u}\, du)=\frac{1}{s}(\log s-\gamma)
$$ I must have made a mistake here but cannot find it.","['laplace-transform', 'logarithms', 'transformation', 'integration']"
138459,"Kendall notation's ""General distribution"", what does that mean?","The first and second parameters for the Kendall's notation may have a G value, which stands for General distribution , see here . But what does that mean? What is a general distribution ?","['probability-theory', 'markov-chains', 'markov-process', 'probability']"
138469,Calculating limits of a function of 2 or 3 variables,"I have to calculate these two limits, and have no idea where to start from.
Your guidance for how should I start working with it can help me a lot. 1) $\lim\limits_{(x,y,z)\rightarrow (0,0,0)} (1+xyz)^{(x^2+y^2+z^2)^{-1}}$ 2)$\lim\limits_{(x,y)\rightarrow (0,0)} \dfrac{4y^2+3xy^2+2x^2}{x^2+2y^2}$ Thanks in advance.",['limits']
138498,Derivative of $x^{x^{\cdot^{\cdot}}}$?,"The infinite tetration is defined as
$$f(x)=x^{x^{\cdot^{\cdot}}}$$ This function is defined for $e^{-e} \leq x \leq e^{e-1}$. (Wikipedia image) Can one determine the derivative of this function?","['exponentiation', 'tetration', 'derivatives']"
138514,"""Unsolvable"" Equations","I was just playing around with some equations the other day and losing interest I started writing down what were mostly ""random"" equations at first. But, I realized that there's something special about them, they don't have solutions! At least, as far as I could tell. On the surface it seems there should be solutions to them, seeing they look simple; at any rate, couldn't we just ""define"" objects which would satisfy these equations? Similar to what was done when complex numbers were introduced? I can't say; anywho, here is a sample of what I have: $$
\tag{1} \sqrt{ix} = -1, \sqrt{ix} = -i, \sqrt{x} = -1 - i, \\ \sqrt{ix} = -1 - i, \sqrt{-ix} = -1 - i, \sqrt{-ix} = i - 1, \\ \sqrt{-ix} = -i
$$ What do you think? Can we get any solutions? Can we define solutions? Thanks in advance. EDIT: I have to mention that I'm looking for solutions that would ""force"" the LHS of the equations to equal the RHS. I'm not an expert so I'm not sure if this is the right question to ask, but that's why I have it here :)","['complex-analysis', 'real-analysis']"
138519,Proving a function is constant,"Let $f$ be an analytic function such that $f(z)$ is an element of $\mathbb R$ for all $z$ element of $\mathbb C$. Prove $f$ is constant. Here's what I have done - $f(z) = c + i0$, where $c$ is an element of $\mathbb R$ So i have component functions $u(x,y) = c$, 
$v(x,y) = 0$ The partial derivative $u_x = 0$ and the partial derivative $v_x = 0$ The derivative, $f'(z)$ = $u_x +i v_x$, so I have $f'(z) = 0$ As $f'(z) = 0$ the function must be constant. Does that seem right? One thing that I noticed when looking at question is that if $f(z)$ is an element of $\mathbb R$ then it is automatically constant...isn't that correct? But I would expect they are looking for more than that in an exam situation...",['complex-analysis']
138520,Showing a series is a solution to a differential equation,"I am attempting to show that the series $y(x)\sum_{n=0}^{\infty} a_{n}x^n$ is a solution to the differential equation $(1-x)^2y''-2y=0$ provided that $(n+2)a_{n+2}-2na_{n+1}+(n-2)a_n=0$ So i have:
$$y=\sum_{n=0}^{\infty} a_{n}x^n$$
$$y'=\sum_{n=0}^{\infty}na_{n}x^{n-1}$$
$$y''=\sum_{n=0}^{\infty}a_{n}n(n-1)x^{n-2}$$ then substituting these into the differential equation I get: $$(1-2x+x^2)\sum_{n=0}^{\infty}n(n-1)a_{n}x^{n-2}-2\sum_{n=0}^{\infty} a_{n}x^n=0$$ $$\sum_{n=0}^{\infty}n(n-1)a_{n}x^{n-2}-2\sum_{n=0}^{\infty}n(n-1)a_{n}x^{n-1}+\sum_{n=0}^{\infty}n(n-1)a_{n}x^{n}-2\sum_{n=0}^{\infty} a_{n}x^n=0$$ relabeling the indexes: $$\sum_{n=-2}^{\infty}(n+2)(n+1)a_{n+2}x^{n}-2\sum_{n=-1}^{\infty}n(n+1)a_{n+1}x^{n}+\sum_{n=0}^{\infty}n(n-1)a_{n}x^{n}-2\sum_{n=0}^{\infty} a_{n}x^n=0$$ and then cancelling the $n=-2$ and $n=-1$ terms: $$\sum_{n=0}^{\infty}(n+2)(n+1)a_{n+2}x^{n}-2\sum_{n=0}^{\infty}n(n+1)a_{n+1}x^{n}+\sum_{n=0}^{\infty}n(n-1)a_{n}x^{n}-2\sum_{n=0}^{\infty} a_{n}x^n=0$$ but this doesn't give me what I want (I don't think) as I have $n^2$ terms as I would need $(n^2+3n+2)a_{n+2}-(2n^2+n)a_{n+1}+(n^2-n-2)a_{n}=0$ I'm not sure where I have gone wrong? Thanks very much for any help",['ordinary-differential-equations']
138530,At which points is this function differentiable/analytic?,At which points (if any) is this function differentiable? At which points is it analytic? $f(x+iy) = x^2 + iy^2$ I applied the Cauchy Riemann equations and got the result that $y=-x$. So then am I correct to say that the function is only differentiable on the line $y=-x$ and is analytic nowhere as it is not differentiable at every point in any small disc centred on the line?,['complex-analysis']
138541,Left inverse implies right inverse in a finite ring,"Let $R$ be a finite ring with identity $1$ , and assume $\exists x,y\in R$ such that $ xy=1$ . How can I show it implies $yx=1$ ?","['ring-theory', 'finite-rings', 'abstract-algebra']"
138548,When do weak and original topology coincide?,"Let $X$ be a topological vector space with topology $T$. When is the weak topology on $X$ the same as $T$? Of course we always have $T_{weak} \subset T$ by definition but when is $T \subset T_{weak}$? Assume that $X$ is any topological space, not necessarily normed.","['general-topology', 'topological-vector-spaces', 'functional-analysis']"
138556,Probability and Axiom of Choice,"I'm not a logician, so I apologize if what follows translates to nonsense. I would like to try to define a different theory of random choice. I hesitate to call it probability theory because I do not expect it to follow the usual rules of probability. I will however refer to it as a warped theory of probability. For the sake of simplicity take $\mathbb{Z}$ or $[-\infty,\infty]$. It is an easy fact that one CANNOT define a discrete uniform distribution on either of these spaces in the usual sense. One of two things necessarly goes wrong: normalization or countable additivity. However, according to the axiom of choice, I can pick an element of $\mathbb{Z}$ or $[-\infty,\infty]$. Even though these sets are well ordered, I would still like to use the axiom of choice as explained below. In fact, if I have infinitely many copies of $\mathbb{Z}$ or $[-\infty,\infty]$ then I can pick elements from each copy turning it into a product space. Since there is no real recipe for how the axiom of choice picks elements, I would like to think that if I want to define a ""uniform"" distribution on $\mathbb{Z}$ or $[-\infty,\infty]$, then I would invoke the axiom of choice to generate an element. Can any of this be formalized into a useful theory? In short, I would like to pick an element of each set with the underlying notion that I have no preference to the choice I make. I'm invoking the axiom of choice as a means to do so. That is, I am defining the notion of a uniform distribution through the process of saying ""by the axiom of choice I can pick an element."" Literally, I am thinking of the axiom of choice as a black box into which I feed an arbitrary collection of sets from which it spits out picked elements. Of course this would not be in line with usual probability. In particular there would be huge issues with sets such as $[-1,1]$ and $[-\infty,\infty]$ where in the usual theory of probability I CAN define a uniform distribution on $[-1,1]$ but cannot on the latter, even though the two sets have a bijection. I am not sure how to reconcile this. My experience with the axiom of choice has been mostly in proofs that say, involve some collection of equivalence classes so I can pick representatives from each one. The point is in this case I don't care which representatives I pick. So if I were to suddenly care, is there some warped notion of probability that one can invoke to make ""inferences?""","['probability-theory', 'logic', 'philosophy', 'probability']"
138562,Is the union of two manifolds a manifold?,"Suppose I have $M$ and $N$, two $k$-manifolds in $\mathbb{R}^n$. Is it true that $M\cup N$ is also a manifold? What is a sufficient condition for positive answer?","['manifolds', 'differential-geometry']"
138571,Why is Hodge more difficult than Tate?,"There are strong connections between the Hodge and the Tate conjectures, mainly at the level of similarities and analogies. To quote from an answer of Matthew Emerton on MathOverflow : ""[...] we also have a natural abelian (in fact Tannakian) category in play: in the complex case, the category of pure Hodge structures, and [when the field of definition $K$ is finitely generated over its prime subfield], the category of $\ell$ -adic representations of $G_K$ (the absolute Galois group of $K$ ) (for some prime $\ell$ , prime to the characteristic of $K$ in the case when $K$ is a finite field). Now taking cohomology gives a functor from the category of smooth projective varieties to this latter category (via Hodge theory in the complex case, and the theory of étale cohomology in the other cases). The Hodge conjecture (in the complex case) and the Tate conjecture (in the other cases) then says that this functor is fully faithful. Moreover, it is known that the Hodge conjecture for CM abelian varieties over $\mathbb{C}$ implies the Tate conjecture over finite fields (this was proven by J. Milne), and that the Tate conjecture for abelian varieties over finitely generated fields implies the Hodge conjecture over $\mathbb{C}$ (this was proven by P. Deligne I. Piatetski-Shapiro - see anon's answer) (see this workshop summary ). However, I remember that during a seminar at my university, someone said that the Hodge conjecture is expected to be more difficult to solve than the Tate conjecture. Also, the Hodge conjecture (H), unlike the Tate conjecture (T), is part of the Millenium problems, which could suggest that H is more difficult/deeper that T. My question is thus the following: are there any reason why H should be more difficult than T ?","['arithmetic-geometry', 'algebraic-geometry', 'open-problem', 'hodge-theory']"
138578,Newtonian potential of a rotationally-invariant function,"Lately I read up in the wikipedia article about the Newtonian potential , that for any compactly supported continuous function $f: \mathbb{R}^d \rightarrow \mathbb{R}$ that is rotationally invariant (for simplicity I assume $d>2$) outside of the support of $f$ whe have the equality $$f*\Gamma(x) =\lambda \Gamma(x),\quad \lambda=\int_{\mathbb{R}^d} f(y)\,dy.$$ where $$\Gamma(x) = \frac{1}{d(2-d)\omega_d} | x | ^{2-d} $$ and $\omega_d$ is the volume of the unit $d$-ball. I like the statement and tried to show it but had no success, therefore I looked up the mentioned references in the wikipedia article, but in both books I could not find the theorem. Can anyone provide a proof or better a reference containing a basic proof?","['convolution', 'ordinary-differential-equations', 'orthogonal-polynomials', 'reference-request', 'analysis']"
138584,Multiplication of Taylor series - expanding $2x\sin(x)$,"I'm working on a problem for university Calculus 2. We're talking about Taylor series right now and I need to approximate an integral using one of a function that I think it should be easy to produce a series for, but I'm not 100% sure. This is the function: $$f(x) = 2x\sin(x)$$ I know the expansion for $\sin(x)$ , which is in a reference table in the book. To give the first few terms it looks like this: $$x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \;\cdots$$ I'm pretty sure I can just multiply the whole polynomial by $2x$ , giving: $$2x^2 - \frac{2x^4}{3!} + \frac{2x^6}{5!} - \frac{2x^8}{7!} + \;\cdots$$ What's odd is that I can't find any examples quite like this in either of the textbooks or on the internet... which makes me wonder if this isn't actually a valid manipulation. Additionally, I can't seem to get an answer that matches this from Wolfram Alpha. I could work out the Taylor series by hand, but the derivatives of the function start getting a bit ugly (by which I mean long), so I think I'm supposed to manipulate a known series since this should be an easy problem. So, am I doing this right or am I on the wrong track?","['calculus', 'taylor-expansion']"
138589,Intuition and derivation of the geometric mean,"I've run through a bunch of searches, especially here on SO, but I simply couldn't find something that answers a question that has been on my mind lately. How was the geometric mean derived? What is the intuition behind it. Most simply use the final equation as a justification for its existence. The $n$-th root of the product of all elements equation really doesn't do it justice. Could someone elaborate on how and why is it interesting?",['algebra-precalculus']
138612,Number of pairs satisfying $2\alpha + 3 \beta =k$,"How can I prove the following: Let $\mathbb{W}$ denote the set of non-negative integers. Then what is the cardinality of the set $$\bigl\{ (\alpha,\beta) \in \mathbb{W} \times \mathbb{W} \ | \ 2\alpha + 3\beta =k \bigr\}$$ I think it’s $\left\lfloor\frac{k}{6}\right\rfloor$ if $k \equiv 1 \ (\text{mod} \: 6)$ and $\left\lfloor\frac{k}{6}\right\rfloor + 1$ if $k \not\equiv 1 \ (\text{mod} \ 6)$. But I am having trouble doing this. Can anyone provide me an answer, or thoughts on how to go about a solution.",['number-theory']
138615,How to get a geometric morphism out of a section? (And general pedagogy on classifying toposes),"Let $\mathcal{E}$ and $\mathcal{F}$ be toposes, $X$ an object of $\mathcal{E}$ and $p: \mathcal{E}/X \rightarrow \mathcal{E}$ the canonical geometric morphism (whose inverse image part is pullback along $p: X \rightarrow 1$.) I am trying to figure out the correspondence between geometric morphisms $\mathcal{F} \rightarrow \mathcal{E}/X$ over $\mathcal{E}$ and ""global sections"" $1 \rightarrow f^*(X)$. More precisely, I am looking to establish $$\text{Hom}_{\textbf{Topoi}/ \mathcal{E}} ( f: \mathcal{F} \rightarrow \mathcal{E}, \mathcal{E}/X) \cong \text{Hom}_{\mathcal{F}} (1, f^{*} (X))$$ Given a geometric morphism $g$ it is easy to get a section. One simply sends $g$ to the section $$g^* (\Delta) : 1 \rightarrow g^*(\pi_2 : X \times X \rightarrow X) = g^* \circ p^* (X) = f^*(X) $$ where $\pi_2$ is the standard projection and $\Delta$ the diagonal map $X \rightarrow X \times X$. (The idea is that $\Delta$ is the universal section, classifying the identity $\mathcal{E}/X = \mathcal{E}/X$.) I'm having some difficulty figuring out the converse. Given a section $s : 1 \rightarrow f^*(X)$ we do get a geometric morphism $\mathcal{F} \rightarrow \mathcal{F}/f^*(X)$ and I can see that this ought to be 'sendable' to $\mathcal{E}/X$ but cannot figure out a nice way to do this via a geometric morphism (the wall I keep hitting is that the unit map $\eta_X : X \rightarrow f_* f^*(X)$ induces a geometric morphism in the 'wrong' direction.) So I guess my first question is: How does one get the right-to-left correspondence, i.e. from sections to geometric morphisms in this case? In general, I am also interested to hear how one should generally think of these classifying problems (finding classifying topoi for given structures.) I am new to the game and every case I encounter seems to me now devoid of a general principle of attack. In some cases it seems much easier to go from 'points'/'individual structures' to geometric morphisms. For example, in geometric cases, a point immediately gives the stalk/skyscraper adjunction and hence a geometric morphism. In other cases, like the one above, where the universal structure is clear, it is much easier to go from geometric morphism to a 'point'/'structure'. So my second question is this: Is there a good standard way to think/attack such problems? Should one always try and figure out the universal structure first? Should one think geometrically? Any suggestions will be greatly appreciated... (NOTE: I understand that the second question is not very precise, but neither am I looking for very precise answers.) Finally, a bonus question: is the correspondence in the problem above (the first equation) a kind of adjunction between functors $\textbf{Topoi}/\mathcal{E} \overset{\leftarrow}{\rightarrow} \mathcal{F}$ (where $\mathcal{F}$ lies over $\mathcal{E}$.) Can one view this as some sort of adjunction in this manner? I suspect not, but I'd like to know if this is a fact made more elegant from a 2-categorical perspective...","['category-theory', 'algebraic-geometry', 'topos-theory', 'abstract-algebra']"
138620,$\epsilon$- dense subsets,"Let be $M$  a compact metric space, and let $\{x_n\}$ be a dense subsequence in $M$. We say that a set $\Lambda=\{y_1,\ldots,y_n\}$  is $\epsilon$-dense  when every ball 
of radius $\epsilon$ contains a point of $\Lambda$. I want to prove that for every $\epsilon$ there exists $N\in\mathbb{N}$ such that $\{x_1,\ldots,x_N\}$ is $\epsilon$- dense. I'm trying to do this by contradiction. I'm trying to argue that it does not exist then $\{x_n\}$ is not dense. But I'm having trouble with it.","['general-topology', 'metric-spaces', 'real-analysis']"
138641,Find the smallest $k\in \mathbb{Z}$ such that $f(x)=x^2-3x+k$ and $g(x)=x-2$ do not intersect.,"$$ \large{ \text{Here are some instructions from the original question: } \ \\ } $$ $$ \large{ k \in \mathbb{Z} \ \ \land \\ f(x)=x^{2}-3x+k \ \ \land \ \ g(x)=x-2 \ \\ \text{And, there is NO any intersection point between $f(x)$ and $g(x)$. } \ \\ k_{(min) \, }= \;? } \ \\ $$ $$ \large{ \text{Here is just an example graph which I've drawn after seeing the answer: } \ \\ }   $$ I've tried this so far: $$ \large{ f(x) \ne g(x) \; \land \; f(x)-g(x)\lt{0} \leftrightarrow \Delta \lt{0} \; \\ \Delta=x^{2}-4x+k+2 \; ... \\ } $$ The answer lies just behind that $\Delta$ but, unfortunately, I couldn't able to further the solution anymore...and, I need your help from here, so, please, show me how to do that. Thank you very much... PS: Finally, I understand it now... :) Thank you so much for your all help!... A very big hint: $ \large{ \Delta= \Big(b \Big)^{2}- \Bigg(4 \times \Big( a \Big) \times \Big( c \Big) \Bigg) \ (1) \\ } $ Now, I'm furthering my solution using that* equation *(1): $$ \large{ (-4)^{2}- \Big( 4 \times (1) \times (k+2) \Big) = \Delta \ \\ 
4^{2}- \Big( 4 (k+2) \Big)= 16-(4k+8)= \Delta \ \\ 
\Delta \lt{0} \iff 16-4k-8 \lt{0} \iff 8-4k \lt{0} \ \\ } $$
$$ \text{Here comes a simple method to reach the answer: } \ \\
\large{ 8-4k=0 \ \\ 4k=8 \ \\ k=2 } \ \\ \text{but,} \ \ k_{min} \ \text{ equals just one of these } \ \mathbb{R^{+}} \ \text{and} \ \mathbb{Z^{+}} \ \text{numbers} : \ (2, \, {+}\infty ) \ \\
\text{So, } \ \large{ k_{min}=3 } $$","['conic-sections', 'algebra-precalculus', 'functions']"
138657,Squaring an arbitrary summation?,"I'm trying to find a recurrence relation for the coefficients for the Maclaurin series for $\tan(x)$ by substituting $y=\sum_{k=0}^{\infty}C_{2k+1}x^{2k+1}$ into the differential equation $y'=1+y^2$. This is because $\tan(x)$ is the solution to the initial value problem for the aforementioned DE with the initial condition $y(0)=0$; this is also where the form $\sum_{k=0}^{\infty}C_{2k+1}x^{2k+1}$ comes from (the fact that $\tan(x)$ is an odd function and that $y(0)=0$ which implies $C_0=0$). But I have no clue how to work ""around"" the expression $y^2=\big(\sum_{n=1}^{\infty}C_{2k+1}x^{2k+1}\big)^2$. How can I find a recurrence relation with an infinite squared summation? Any help is appreciated, thank you.","['power-series', 'ordinary-differential-equations', 'sequences-and-series']"
138664,"How to integrate $\int e^{-t^{2}} \space \, \mathrm dt $ using introductory calculus methods","Earlier today I stumbled across this when I was doing some practice questions for a physics course: $$\int e^{-t^2} \space \, \mathrm dt $$ To expand, the limits of integration were something like $1$ and $4$ (it was just a velocity function that needed to be integrated to find distance - it was not a known integral like $\int_0^\infty e^{-t^2} \space\, \mathrm dt$ .) Based on Wolfram|Alpha , it appears it cannot be expressed in elementary terms (i.e. it involves the error function.) Note that the questions involved the use of a calculator, so I was able to integrate the function using a CAS with ease, but I am wondering how to do it by hand. Thus, I was wondering if there was possibly a way to evaluate the integral using elementary methods from a calculus one or two course (read: no complex analysis). I thought there may perhaps be an elementary solution (I don't know what kind of algorithm Wolfram uses to evaluate integrals - I have seen them evaluate easy integrals in a lot of steps before.)","['calculus', 'integration', 'indefinite-integrals']"
138668,Convergence of Series w/ factorial,"I'm working on a convergence problem that's giving me trouble. I'll list the steps I've made so far. Given the following series determine if it is convergent or divergent:
$$\sum_{n=1}^{\infty}\frac{n!\cdot x^n}{n^n}, \text{where } x > 0.$$ When I first saw this problem I thought to use the root test so I attempted to preform the following calculation: 
$$\lim_{n\to\infty} \sqrt[n]{\left| \frac{n!\cdot x^n}{n^n} \right|}.$$ But here is where I'm not sure how to move forward. I'm basically unsure if we can distribute the $\frac{1}{n}$ exponent to $n!$ to generate something like this ${(n!)}^{1/n} \cdot x$ as the numerator (which would go to $x$ as $n \longrightarrow \infty$).",['sequences-and-series']
138671,$L^{2}$ functions,"Let $f(x)$ be a continuous function for all $x\in \mathbb R$, such that $f\in L^{2}(\mathbb R)$ (i.e., $\int_{-\infty}^{\infty}|f(x)|^{2}dx<\infty$), and define $$f_{o}(x):=\sup_{|x-y|\leq 1}|f(y)|$$ How to prove that $f_{o}\in L^{2}(\mathbb R)$, and $\|f_{o}\|_{L^{2}}\leq A\|f\|_{L^{2}}$, for some constant $A>0$? My progress is the follwoing, so correct me if I'm wrong, and advise me if I'm missing something: We can construct a function $g\in S(\mathbb R)$ (Schwartz class) with $\hat{g}=1$, so $\hat{f}=\hat{f}\hat{g}$, hence $f=f*g$ (convolution), then $$f_{o}(x)\leq (|f|*g_{o})(x)$$ 
which implies that $\|f_{o}\|_{L^{2}}\leq \|(|f|*g_{o})\|_{L^{2}}\leq \|f\|_{L^{2}} \|g_{o}\|_{L^{1}}$.","['hilbert-spaces', 'functional-analysis']"
138694,Laplace-Beltrami operator for curves,"I'm CS major and have used discrete Laplace-Beltrami operator for 2D-manifold (surface meshes). I'm wondering if it is possible to define Laplace-Beltrami operator for 1D-manifold. If this is possible, I will try to discretize it for polylines. Any help is appreciated.","['riemannian-geometry', 'differential-geometry']"
138700,Showing two field extensions are the same,"Consider the finite extension $F/K$, [$F:K$]=15. Suppose for some $\gamma\in F$, $F=K(\gamma)$. I want to show that $F=K(\gamma^{2}+1)$. Since the extension is finite, in particular it is algebraic. Therefore I think as long as I show that both $\gamma$ and $\gamma^{2} +1$ satisfy the same minimal polynomial the conclusion will follow. Is this correct? Also, I do not see the significance that the degree of the extension is playing, I would appreciate a hint about this as well.","['abstract-algebra', 'field-theory']"
138712,Application of the First Moment Method to Random Graphs,"I've been trying for a few days to figure out a proof of part $(iii)$ of Lemma 2.1 of this paper , on page 4, and I could definitely use some help. You don't need to understand any of the rest of the paper to understand what lemma 2.1 is saying, it's purely about a few properties of random graphs. Could anyone explain how such a proof (just of part $(iii)$) might go? As far as I know, the ""first moment method"" is simply the observation that $\mathbb{P}(X>0) \leq \mathbb{E}(X)$. We can condition this on ""vertices $v$, $w$ are at distances at most $i$ from each other"" but I can't really get anywhere with it. I guess the expected number of length-$i$ paths between 2 fixed vertices is $(n-2)(n-3)\ldots(n-i)p^i \sim d^i/n = n^{i\alpha - 1}$. Conditioning on $d(v,w)\leq i$ (which is obviously not the same as necessarily having a path of length $i$ between the 2 vertices, although I think the probabilities of these events become arbitrarily close), I'm not sure how we pull out a $2/(1-i\alpha)$ out of the details. I think we can use part $(i)$ of the lemma to get out probabilities that a vertex is at distance at most $i$ from another, and probabilities that a vertex is at distance exactly $i$ from another (both approximately $d^i/n$). After that I tried extending the first moment method to the statement $\mathbb{P}(X>\frac{2}{1-i\alpha}) \leq \frac{1-i\alpha}{2} \mathbb{E}(X)$ but again, I'm unclear where to go from here. I'd be really appreciative of a proof of this part of the lemma - it looks to be fairly simple, so I'm not sure what I'm missing. Alternatively, if anyone has a reference which happens to prove this result then I would be more than happy to locate that, but I've looked through numerous books on random graphs and spent a lot of time searching online to no avail. Thank you for your help - Sam","['graph-theory', 'probability']"
138715,"Showing that the dual space of bilinear maps $V \times W \to \mathbb{R}$ satisfies the tensor product property, for finite dimensional vector spaces.","Let $U,V$ and $W$ be finite dimensional vector spaces, and define $B$ to be the vector space of all bilinear maps $V \times W \to \mathbb{R}$. Given a bilinear map $\alpha : V \times W \rightarrow U$, define $\tilde{\alpha}: B^* \rightarrow U^{**}$ by $\alpha(\psi)(\sigma) = \psi (\sigma \circ \alpha)$. Define a map $\pi : V \times W \rightarrow B^*$ by $\pi(v,w) (f:V \times W \rightarrow  \mathbb{R}) = f(v,w).$ $\mathbf{CORRECTION:}$ $B$ should be the space of bilinear maps $V \times W \to \mathbb{R}$, not $V \times W \to U$ as previously stated. In order to show that $B^*$ satifies the universal property of the tensor product, I have to show that given a map $\alpha : V \times W \rightarrow U$, then there is a unique $\tilde{\alpha} : B^* \rightarrow U^{**}$ such that $\Theta \circ \tilde{\alpha} \circ \pi = \alpha$, where $\Theta:U^{**} \to U$ is the canonical isomorphism. It is quite clear that $\tilde{\alpha}$ defined above satisfies this property, but I am having trouble proving uniqueness. I would like to show that given $f:B^* \to U^{**}$ such that $\Theta\circ f \circ \pi = \alpha$, then $f= \tilde{\alpha}$, however I am getting nowhere. Any help would be appreciated, thank you.","['vector-spaces', 'tensor-products', 'linear-algebra']"
138753,Variance of the Empirical CDF,"Suppose $X_1,X_2,\ldots$ are $m$-dependent random variables. Let $F_i$ be the cdf of $X_i$. Let $F_n(x, \omega)$ be the empirical cdf of $X_1,\ldots,X_n$. What will be the variance of $F_n(x, \omega)$?",['probability-theory']
138786,Lowenheim-Skolem theorem confusion,"This Wikipedia entry on the Löwenheim–Skolem theorem says: In mathematical logic, the Löwenheim–Skolem theorem, named for Leopold Löwenheim and Thoralf Skolem, states that if a countable first-order theory has an infinite model, then for every infinite cardinal number κ it has a model of size κ. What does the ""size"" of a model referring to (or mean)?
Edit: If it is referring to the cardinality of a model (set), how do you get the cardinality of one model (-> It's synonymous with interpretation, right?)? What is inside the model, then? I mean, it seems sensical to define a model of a language, as a language has some constant numbers and objects, but defining a model of a single object - a number - seems nonsensical to me. What is inside the model of an infinite number? Thanks.","['elementary-set-theory', 'model-theory']"
138792,Cardinality: does $|A^B|=|2^B|$ if $|A| \le |2^B|$?,"Taking finite powers of a countably infinite set still yields a countable set:
$$|\mathbb{N}|=|\mathbb{N}^k|.$$ It's also known that countable powers of the continuum still have the same cardinality as the continuum:
$$|2^\mathbb{N}|=|\mathbb{R}|=|\mathbb{R}^k|=|\mathbb{R}^\mathbb{N}|.$$ Furthermore, taking the next highest ordinal to the power of the continuum doesn't seem to change it. (at least according to wikipedia ) Denote $X:=2^\mathbb{R}$, then
$$|2^\mathbb{R}|=|X|=|X^k|=|X^\mathbb{N}|=|X^\mathbb{R}|$$ See a pattern? It seems that when taking one set to the power of another set, it doesn't really matter how big the exponent is so long as it is smaller than the base. Or thinking about it in terms of the other variable, if the exponent isn't too big then you might as well replace the base by 2. Ie.,
$$|A| \le |2^B| \Rightarrow |A^B|=|2^B|.$$ Is there a way in which this pattern can be stated and proved rigorously, or is it just a coincidence?","['cardinals', 'elementary-set-theory']"
138799,holomorphic function is real analytic?,"$f$ is a holomorphic function on $\mathbb C^n$. If we regard $f$ as a function $F$ from $\mathbb R^{2n} \to \mathbb R^2$, is it necessarily that $F$ is real analytic?","['complex-analysis', 'several-complex-variables', 'real-analysis']"
138800,How to prove the holonomy group is preserved under Ricci flow?,"I've heard that on a Kähler manifold $(M,g_0)$, if you evolve the metric $g$ by Ricci flow $\partial g_{ij}(t)/\partial t=-2R_{ij}$, and $g(0)=g_0$, then you always have $g(t)$ is a Kähler metric on $M$. All the references I saw refer this fact to that the holonomy group of $(M,g(t))$ is preserved under Ricci flow, but I don't know how to prove it.","['ricci-flow', 'riemannian-geometry', 'differential-geometry', 'kahler-manifolds']"
138812,Difference between axiomatization and model,"As I study through set theory, I find the definition of axiomatization and models somewhat confusing. The question is what is the difference between axiomatization and model? Thanks.","['elementary-set-theory', 'model-theory']"
138827,Taylor Series of Products,Here's a taylor series problem I've been working on. I'll list a few steps to the problem and tell you guys where I'm getting stuck. Thanks in advance for the help. So my questions builds off the fact that $ e^x = \sum_{n=0}^{\infty}\frac{x^n}{n!}$ and we are asked to find the taylor series of the following function: $f(x) = (2x-3)\cdot e^{5x}$ around a = 0 So I first decided to calculate the taylor series for $e^{5x}$ by generating a few terms and noticing the pattern. I then found the following series to represent $e^{5x}$ $ e^{5x} = \sum_{n=0}^{\infty}\frac{5^n}{n!} \cdot x^n$ Next I know I must multiply this series by (2x-3) somehow so I begin like this: $(2x-3) \cdot \sum_{n=0}^{\infty}\frac{5^n}{n!} \cdot x^n$ $\sum_{n=0}^{\infty}\frac{(2x-3)5^n}{n!} \cdot x^n$ My problem with this answer is that it's not in the correct form for a taylor series and must be in the form: $\sum b_n \cdot x^n$ Does anyone know the type of manipulations I must do to convert my result to the correct form?,"['sequences-and-series', 'taylor-expansion']"
138842,Proof of Osborn's Rule,"Osborn's Rule is described here on MathWorld . Firstly, am I right that only signs of terms in the form $\sin^{4n+2} \theta$ , $n \in \mathbb{Z^+}$ have their signs switched (i.e. terms like $\sin^4 \theta$ simply become $\sinh^4 \phi$ )? Secondly, I haven't been able to find a proof of Osborn's Rule anywhere - does anyone know of one? My attempt was to have $\theta=i\phi$ in the trigonometric equation, so that $\cos \theta=\cosh \phi$ and $\sin \theta=i \sinh \phi$ . However, the presence of $i$ in the latter seems problematic e.g. if the original trigonometric equation contains both even and odd powers of $\sin \theta$ then we will end up with both real and imaginary terms.","['trigonometry', 'complex-numbers']"
138861,Is there a fundamental misunderstanding here or have I made an algebraic slip?,"Is there a fundamental misunderstanding here or have I made an algebraic slip? I have a Riemannian metric of the form $ds^2={du^2+dv^2\over 1-u^2-v^2}$ on an open disc and I want to prove that radial curve $(r(t), 0)$ is a geodesic. I wrote the metric in polar form -- $ds^2={dr^2+r^2d\theta^2\over 1-r^2}$,
so the coefficients of the first fundamental form are $E={1\over 1-r^2}, F=0, G={r^2\over 1-r^2}$. So the geodesic equations become ${d\over dt} (E\dot{r})={1\over 2}{\partial \over \partial r} (E\dot{r}^2)$ and (another equation which works). I can always reparametrise $r(t)$ so that it has unit speed. And I get $2r\over (1-r^2)^2$= $r\over (1-r^2)^2$, which is clearly wrong! Why is there an extra factor of 2? Thank you. ADDED: Perhaps it would be helpful for me to point out that
generally, for a Riemannian metric of the form $Edu^2+2Fdudv+Gdv^2$ and geodesic $g(t)=(a(t),b(t))$, the Euler Lagrange equations are ${d\over dt} (E\dot{a}+F\dot{b})={1\over 2} (E_u\dot{a}^2+2F_u\dot{a}\dot{b}+G_u\dot{b}^2)$ and ${d\over dt} (F\dot{a}+G\dot{b})={1\over 2} (E_v\dot{a}^2+2F_v\dot{a}\dot{b}+G_v\dot{b}^2)$ where $\dot{a}={d\over dt}a,\,\,\,E_u={\partial\over\partial u}E$ and so on. EUREKA! Ooh, I think I know what the bug is, The geodesic has constant speed, but the inner product here is not simply the Euclidean one which is what I assumed when I set $\dot{r}=1$! I think it works fine now. :) -- I write it here because I can't post it as an answer...","['calculus-of-variations', 'differential-geometry']"
138865,How do I determine the number of odd integers in a range?,"Say I have a range of integers, [1..100]. How do I determine the number of odd integers in that range? Does it make a difference if the beginning and end numbers are [odd .. odd], [even .. odd], [even .. even]?",['combinatorics']
138882,The intersection of distinct maximal ideals is not prime.,"Let $P,Q$ be distinct maximal ideals of a ring $R$. Prove that $P\cap Q$ is not prime. I am not sure how to prove this.  The only facts that I can think of applying are the definitions, $R/M$ is a field iff $M$ is max, and $R/P$ is an ID iff $P$ is prime. Any suggestions would be appreciated.","['ring-theory', 'abstract-algebra']"
138899,Number of surjections from one set to another,"I'm having trouble on this question: Let $f(n,r)$ be the number of surjections from a set $A$ having $n$ elements to a set $B$ having $r$ elements. Show that $$f(n,r)=r\Big(f(n-1,r-1)+f(n-1,r)\Big)\;.$$ Here is my idea about how to start: Partition each set, $A$ and $B$, such that the top partition consists of $n-1$ or $r-1$ elements (for $A$ and $B$ respectively) and the bottom partitions consists of one element each. Then there are $f(n-1,r-1)$ surjections from the top partition of $A$ onto the top partition of $B$. There are $f(n-1,r)$ surjections from the top partition of $A$ to all of $B$. Now consider the whole of $A$ (i.e. $(n-1)+1$ elements). The total number of surjections is: ((total number of surjections from top partition of $A$ onto all of $B$) + (extra surjections due to extra element of $A$)) permuted to account for all combinations But how do you calculate the extra surjections due to the extra element of $A$ and the correct number of permutations? Thank you.","['elementary-set-theory', 'combinatorics']"
138910,The definition of a directional derivative,"We're given that for $e \in \mathbb{R}^2$ the directional derivative of $u$ in the direction of $e$ is, 
$$\frac{\partial u}{\partial e}(x,t):= \lim_{h \to 0}\frac{u((x,t) + he) - u(x,t)}{h} = \frac{d}{dh}u((x,t) + he)|_{h=0}$$ and don't understand how they managed to jump from the 'middle' to the 'last' equation in this directional derivative definition. Could someone break this down for me? Cheers!","['derivatives', 'partial-differential-equations']"
138916,Questions on limits of the sequence $a_{n}=\frac{(-1)^{n}n+1}{n}$,"Given $a_{n}=\frac{(-1)^{n}n+1}{n}$, compute 
  $$\lim\limits{\inf(a_{n})}$$
  $$\lim\limits{\sup(a_{n})}$$ 
  $$\inf\{a_{n}\}$$
  $${\sup(a_{n})}$$ My attempt:
I tried taking different values ​​for the sequence and reached the following results:
$$\lim\limits{\inf(a_{n})}=1$$
$$\lim\limits{\sup(a_{n})}=-1$$ 
$$\inf\{a_{n}\}=3/2$$
$${\sup(a_{n})}=-1$$ The teacher told me to do it more formally, anyone can help me please?","['sequences-and-series', 'real-analysis', 'limsup-and-liminf']"
138919,Advection diffusion equation,"The advection diffusion equation is the partial differential equation $$\frac{\partial C}{\partial t} = D\frac{\partial^2 C}{\partial x^2} - v \frac{\partial C}{\partial x}$$ with the boundary conditions $$\lim_{x \to \pm \infty} C(x,t)=0$$ and initial condition $$C(x,0)=f(x).$$ How can I transform the advection diffusion equation into a linear diffusion equation by introducing new variables $x^\ast=x-vt$ and $t^\ast=t$? Thanks for any answer.","['ordinary-differential-equations', 'partial-differential-equations']"
138922,Why morphism between curves is finite?,"If $X$ is a complete nonsingular curve over $k$, $Y$ is any curve over $k$, $f: X \to Y$ is a morphism not map to a point (so $f(X)=Y$), then $f$ is a finite morphism. This is the assertion prove in Hartshorne Chapter2, Prop6.8. But the proof is a little sketchy at the point of the inverse image of an affine set is also affine. I quote it here: ...Let $V=\rm{Spec}B$ be any open affine subset of $Y$. Let $A$ be the integral closure of $B$ in $K(X)$. Then $A$ is a finite $B$-module, and Spec$A$ is isomorphic to an open subset $U$ of $X$. Clearly $U=f^{-1}(V)$... Can anyone explain why ""Spec$A$ is isomorphic to an open subset $U$ of $X$. Clearly $U=f^{-1}(V)$""?",['algebraic-geometry']
138925,Factoring $ac$ to factor $ax^2+bx+c$,"I was watching a first-year high-school-algebra student struggle with factoring quadratics last night. Given a quadratic $ax^2+bx+c$ (I'll give you the exact example in a moment), her method — presumably her teacher's — was as follows: find the factors of $ac$, and see which pair add up to $b$. It seems to me that multiplying $a$ by $c$ is needless work. True, it's $ac$ whose factors sum to $b$. But when writing out the factors as (say) $(a_1x+c_1)(a_2x+c_2)$, one's actually working with not the factors of $ac$ but rather the $c_i$ and the $a_i$, factors of, respectively, $c$ and $a$. So my question is: Is there any advantage to working with $ac$ — finding its factors, seeing which ones sum to $b$ — and, if so, what is that advantage? Here's the example she was working, so you get a better under standing of what I mean. The problem was (or amounted to) $9x^2-47x+60=0$. This poor girl found $9\cdot60$ and started examining its factors to see which sum to $47$. Eventually, she hit upon the answer, $20\cdot27$, and put them in her parentheses as $(9x-20)(x-3)$ (somehow divining that the $27$ was to be split up as $9\cdot3$, and the $9$ as $9\cdot1$; I'm not sure how she hit upon that). My method would have been instead to consider $(9x-c_1)(x-c_2)$ or $(3x-c_1)(3x-c_2)$. (I'd reject the latter because $3\nmid47$, but I wouldn't expect that of my high schooler. So consider both possibilities.) Then find factors of $60$ that possibly fit in one of those pairs of parentheses, and hit upon $3\cdot20$. Again, what if anything is the advantage to factoring $ac$? (The advantage, if any, may be pedagogic.)","['factoring', 'education', 'algebra-precalculus', 'polynomials']"
138975,Eigenvalues of the 1D laplacian with mixed boundary conditions,"I am trying to find the eigenvalues and eigenvectors of the Laplacian with mixed boundary conditions on $[0,L]$: More precisely: $$X''(x) = \lambda X(x)$$ with $X'(0)=0$ and $X(L)=a$. I know how to do it with pure Dirichlet or pure Neumann, but not for this mixture. Could you help me or point me to the right reference ? Thanks folk Just found part of the answer here: http://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors_of_the_second_derivative#Mixed_Dirichlet-Neumann_boundary_conditions but I am not sure how to relate it to parameter $a$ in the question. any help welcome","['ordinary-differential-equations', 'spectral-theory']"
138992,Equation with trigonometry,"To solve $\sin^3x+\cos^3x=1$ So I just thought of a solution like: Let $\sin x=t$. Then we have:
$$t^3+(1-t^2) \sqrt{1-t^2} =1 \\ (1-t^2) \sqrt{1-t^2} =1-t^3 \\ (1-t^2)^3=(1-t^3)^2 \\ (1-t)^3(1+t)^3=(1-t)^2(1+t+t^2)^2 \\ (1-t)^2\left[ (1-t)(1+t)^3-(1+t+t^2)^2 \right]=0$$ Which is followed by $\sin x=0$ or $\sin x=1$. However, this solution seems very easy to make a silly mistake in (with all the squares and cubes of differences and sums). Is there any easier solution to this?",['trigonometry']
139011,Product of Transitive Systems,"Let be $M$ a topological space, and $f: M\to M$ a dynamical system, i.e, a continuous map between from $M$ to $M$. We say that a  dynamical system,  $f:M\to M$ is topologically  transitive when, exists 
$x\in M$ such that,  $Orb(x)=\{x,f(x),\ldots, f^n(x),\ldots\}$ is dense in $M.$ There is a problem in the book of Brin Stuck, An introduction to Dynamical Systems, 
 that makes  the following question:
Is the product of two topologically transitive (minimal, topologically mixing) systems topologically transitive (minimal, topologically mixing)? I already know that for minimal systems the answer is no, And as for mixing systems, the answer is yes. But I have no intuition for the case of topologically transitive systems, so my question is: Is the product of two topologically transitive maps, topologically transitive?","['general-topology', 'dynamical-systems', 'metric-spaces']"
139015,Neighborhood Base (the definition),"In Steven G. Krantz' A Guide To Topology , a countable neighborhood base is defined: Let $(X,U)$ be a topological space.  We say that a point $x\in X$ has a countable neighborhood base at $x$ if there is a countable collection $\{U_{j}^{x}\}_{j=1}^{\infty}$ of open subsets of $X$ such that every neighborhood $W$ of $x$ contains some $U_{j}^{x}$. Here is a link . Now, to define a neighborhood base at $x$, the obvious thing to do would be to simply drop the countable requirement, and replace $\{U_{j}^{x}\}_{j=1}^{\infty}$ with some collection $\{U_{\alpha}^{x}\}_{\alpha\in J}$ with index set $J$. My question:  (and I've seen this same definition in other books)  Why do we not require that each $U_{\alpha}^{x}$ contain the point $x$?  My intuitive idea of what a neighborhood base ought to be completely falls apart without this requirement.  All examples of neighborhood bases seem to satisfy this.  Is it a consequence of the definition? Is there a better way to think about neighborhood bases?",['general-topology']
139025,Solve trigonometric equation $\tan\theta + \sec\theta =2\cos \theta$,"$$\tan\theta + \sec\theta =2\cos \theta,\quad 0\le \theta\le 2\pi$$Find all the possible solutions for the equations. Multiply both sides by $\sec\theta - \tan \theta$.
$$\implies (\tan\theta + \sec\theta)(\sec\theta - \tan\theta) = (\sec\theta -\tan\theta)2\cos \theta$$
$$\implies 1 = 2 -2\sin \theta$$ $$\implies \sin \theta=\frac12 \implies \theta = \arcsin\frac12$$Such a solution gets me two solutions $\frac{\pi}6$ and $\frac{5\pi}6$. But when I Wolfram it, I am supposed to get one more solution i.e $\frac{3\pi}2$, but at $\frac{3\pi}2$ $\tan \theta$ and $\sec\theta$ aren't defined.","['trigonometry', 'algebra-precalculus']"
139039,Show that $\mathbb{Q}^+/\mathbb{Z}^+$ cannot be decomposed into the direct sum of cyclic groups.,"$\newcommand{\ZZ}{{\mathbb{Z}}}
\newcommand{\QQ}{{\mathbb{Q}}}
\newcommand{\FF}{{\mathbb{F}}}
\newcommand{\PP}{{\mathbb{P}}}
\newcommand{\RR}{{\mathbb{R}}}
\newcommand{\CC}{{\mathbb{C}}}
\newcommand{\ra}{{\rightarrow}}
\newcommand{\eps}{{\epsilon}}$ Show that the quotient group $\QQ^+/\ZZ^+$ cannot be decomposed into the direct sum of cyclic groups. What I had was: Suppose $\QQ^+/\ZZ^+$ decomposed into the direct sum of cyclic groups $\bigoplus H_i$.  Patently $\QQ^+/\ZZ^+$ is not cyclic because if $r>0$ were the generator, then $r/2$, which is rational, would not be included. Thus we know if it were to decompose it must decompose into at least two proper nontrivial subgroups and any two groups must intersect trivially. Let $H_k$ be the cyclic subgroup in the decomposition that is generated by $\frac{a}{b}$ where $a,b \in \ZZ$ and $gcd(a,b)=1$. In fact, if $a\neq1$ then it must be contained in the direct sum $\bigoplus_{i\neq k} H_i$  which contains $\frac1b$ and thus it would contain $\frac{a}{b}$. Thus we know that all subgroups $H_i$ must be generated by an element of the form $\frac1b$.  Now say a subgroup $H_k$ is generated by $\frac1b$, then it is contained in the direct sum $\bigoplus_{i\neq k} H_i$ because in $\bigoplus_{i\neq k} H_i$ must be $\frac1{b^2}$ since  $\bigoplus H_i = \QQ^+/\ZZ^+$. Thus we can return to the original argument, for an arbitrary cyclic subgroup in the decomposition of $\QQ^+/\ZZ^+$, it is generated by some positive element $r$, and we know there is a smaller element $r/2 \in  \QQ^+/\ZZ^+$  that this element will not generate. This smaller element thus is generated by the direct sum of all the other subgroups in the decomposition, and the sum of $r/2+r/2=r$ so that original cyclic subgroup cannot be in the direct sum decomposition. A contradiction! Thus $\QQ^+/\ZZ^+$ cannot be decomposed into the direct sum of cyclic groups. However, I'm not sure this works. Please help!","['group-theory', 'abstract-algebra']"
139052,Calculate $\sum_{i=1}^{[\frac{\sqrt n}{2}]}{n\choose i}$,"It is known that $\sum_{i=1}^n {n \choose i}=2^n$. I am wondering what would be the sum if we change the upper limit to $\sqrt n/2$, i. e. How to calculate$$\sum_{i=1}^{[\frac{\sqrt n}{2}]}{n \choose i}?$$","['statistics', 'sequences-and-series', 'binomial-coefficients', 'combinatorics']"
139054,Commutativity between diagonal and unitary matrices?,"Quick questions: if you have a diagonal matrix $A$ and a unitary matrix $B$. Do $A$ and $B$ commute? if $A$ and $B$ are positive definite matrices. if $a$ is an eigenvalue of $A$ and $b$ is an eigenvalue of $B$, does it follow that $a+b$ is an eigenvalue of $A+B$?","['matrices', 'linear-algebra']"
139071,How does one calculate the expected number of coin flips for this game to last?,"A biased coin yields heads with probability $\frac{1}{3}$ and tails with probability $\frac{2}{3}$. Adam and Bob use this coin to play a game, in which I flip the coin twice. If both flips are tails, Adam wins. If the flips differ, then Bob wins. Otherwise, this process is immediately repeated. How many flips are expected in a game (until either player wins)?",['probability']
139074,Continuity question on topological product space,"Let $\left\{X_a \right\}_{a \in I}$ be an indexed family of topological spaces. Consider their topological product $X=\prod_{a \in I} X_a$. Let $I'$ be a finite subset of $I$ and define $X' =\prod_{a \in I'} X_a$. Let $y$ be a point of $X$. Define an embedding $j:X' \rightarrow X$ by $j(x')(a)=x'(a)$ if $a \in I'$ and $j(x')(a)=y(a)$ if $a \in I-I'$, where $x' \in X'$. Let $p_a : X \rightarrow X_a$ be the projection on the $a$ factor $x \mapsto x(a)$. I read the statement ""j is continuous, since all maps $p_a j$ are continuous"". I can see that $p_a j$ is continuous for any $a \in I$. But why does this continuity imply the continuity of $j$?","['general-topology', 'product-space']"
139080,With probability $o(1)$,"I am not sure how to read little/big O expressions in probability theory: What does a statement like ""with probability $1-o(1)$"" mean?
Does it mean with high probability?","['asymptotics', 'probability']"
139101,Can height of a curb be determined by the angles of scratches on the perimeter of a wheel that struck a curb?,"With any level of certainty, can the angles of scratches on the outermost edge of a wheel of known diameter be used to calculate the height of a curb, which the wheel struck at low velocity? The wheel didn't strike the curb head on, but rather scraped against the curb while approaching (So, imagine rolling forwards or backwards beside the curb and then attacking it at an angle less than perpendicular). It comes to mind that the type of curb is unknown, but suspected to be either semi-circular or perpendicular to the ground.",['trigonometry']
139102,Translating FOL from English?,"I have searched for answers/help, but I am not able to find specifics. I am on a ""FOL for Dummies"" level, I really have no clue what I'm doing. Edit: I understand most of the symbols (∀x, the backwards E meaning there exists), I just don't know how to tie them together conclusively. I understand (barely) truth tables. Very basic knowledge of the information. Having trouble with first order translations. Assume the universe is all human beings. (a). Some citizens are unhappy in countries ruled by dictators. (b). No college dean is greedy. Attempt: For this, I have ∀x (x is a college dean -> ~(x is greedy)), but I don't think that is what I am looking for. (c). All freshmen that drink regularly never make A's. Attempt: x= Freshman, P(x)=drinking, z=Making A's. (∀xP(x)) -> ~Z AND Consider the following formulas: (a). [(∀xPx) v (∀xRx)] -> ∀x(Px v Rx) and (b). [∀x(Px v Rx)] -> [(∀xPx) v (∀xRx)] Which one is true in any model? Give a model where the other one is false.","['logic', 'boolean-algebra', 'discrete-mathematics']"
139108,Explicit example of a toric flip,"I am looking for a toy example of a flip between toric projective 3-folds. More precisely, I would like to see their defining fans (or polytopes). Does anyone know where I can find something like this?","['algebraic-geometry', 'toric-geometry']"
139110,What is the Lie algebra of the ``indefinite orthogonal group''?,"For $p,q \geq 0$ and $n=p+q\geq 1$, give $\mathbb{R}^n$ the indefinite inner product (written as a matrix)
$$ \begin{pmatrix} I_p & \\ & -I_q \end{pmatrix}, $$
where $I_m$ is the $m \times m$ identity matrix.  For example, if $\{e_i\}$ is a basis of $\mathbb{R}^n$ and $X = X^i e_i,$ then
$$ |X|^2 = (X^1)^2 + \cdots + (X^p)^2 - (X^{p+1})^2 - \cdots - (X^{p+q})^2.$$ Let $\mathrm{O}(p,q,\mathbb{R})$ be the Lie group of all linear transformations $T : \mathbb{R}^n \rightarrow \mathbb{R}^n$ that preserve this indefinite inner product. What is the Lie algebra of $\mathrm{O}(p,q,\mathbb{R})$?  Does it admit a ``nice'' description when $p$ and $q$ are both positive?","['matrices', 'linear-algebra', 'lie-algebras', 'lie-groups']"
139135,Application of pythagoras theorems (circles on sides of a right triangle),One circle is constructed on each side of a right triangle. The center of each circle is the midpoint of the side and the side forms a diameter of the circle. The area of the triangle is $24$ square units. Find the total area of the regions of the two smaller circles that lie outside the largest circle.,['geometry']
139151,How do calculators handle $\pi$?,"When the calculator displays the digits of $\pi$, how does it arrive at that answer? Also, at what digit does the approximation of $\pi$ stop at?","['pi', 'algebra-precalculus', 'calculator']"
139152,"Is there an easy formula for $\operatorname{Tor}_i^{\mathbb{Z}/(p^n)}(\mathbb{Z}/(p),\mathbb{Z}/(p))$?","I've been following some old slides from the Spring 2010 Algebra Seminar at UWaterloo. I now know that 
$$
\operatorname{Ext}_{\mathbb{Z}/(p^n)}^i(\mathbb{Z}/(p),\mathbb{Z}/(p))\cong\mathbb{Z}/(p)
$$
for all $i\geq 0$ when $n>1$. Otherwise, when $n=1$, every $\operatorname{Ext}$ group vanishes for $i\geq 1$. However the Tor groups aren't addressed as closely in the examples, so I would like to know about the other side/left side of the coin. Is there a simple formula or characterization of $\operatorname{Tor}_i^{\mathbb{Z}/(p^n)}(\mathbb{Z}/(p),\mathbb{Z}/(p))$ for $i\geq 0$ for $n$ arbitrary?","['derived-functors', 'homological-algebra', 'abstract-algebra']"
139159,The length of maximum subsequence in a random sequence,"I'm doing my homework and really stuck with one problem. I have a random sequence of 1 and 0 of length $n$. Let's $m$ the maximum lenght of subsequence consisting only of 1. For example for the sequence 0011010 $m=2$ So task is to prove that $$P\left\{\frac{\log_2{n}}{2} < m < 2\log_2{n}\right\} \to 1\text{ as }n \to \infty$$ I've proved the second part ($P\{m < 2\log_2{n}\} \to 1$ as $n \to \infty$), however, I can't prove the first one ($P\left\{\frac{\log_2{n}}{2} < m\right\} \to 1$ as $n \to \infty$). Can you get me some ideas about how can I do this? Thank you. Maybe it will be helpful. The second part I've proved with combinatorial method. Let's estimate $P\{m \ge k\}$. This means that we have at least subsequence with length $k$. So let's make sequence like this 11111XXXXX Here we have $k$ of 1 and $n-k$ arbitrary values. We can fill this XXXXX in $2^{n-k}$ ways. Also we can place the beginning of the sequence in $n-k+1$ ways. E.g. XX11111XXX There are $2^{n-k}(n-k+1)$ ways (and some of them we calculeted twice or more). All there are $2^{n}$ ways. So $$P\{m \ge k\} \le 2^{-k}(n-k+1)$$ And $$P\{m \ge 2\log_2{n}\} \le \frac{n-2\log_2{n}+1}{n^2} \to 0\text{ as }n \to \infty$$",['probability-theory']
139170,Resolution of singularities (small resolution),"Consider the following complex (complete intersection) variety,
$$ f_1: x_0^2 + x_1^2 + x_2^2 + x_3^2 = 4x_4x_5,$$
$$ f_2: x_4^4 + x_5^4 = 2x_0x_1x_2x_3,$$
in $\mathbb{P}^5$. This is the first example in Chapter 5 of Christian Meyer's Modular Calabi-Yau Threefolds , and in computing their Euler characteristic he has the following two lines,
$$ \chi(X) = -176 + 32 + 12\cdot 9 = -36,$$
and letting $\tilde{X}$ be a small resolution of $X$,
$$ \chi(\tilde{X}) = -36 + 32 + 12(4-1) = 32.$$ This is my first pass at resolution of singularities, though I think I've been able to explain everything except the $(4-1)$ at the very end, and I'm not entirely sure how that comes in to play. To start, one has that $X$ without its singularities has Euler characteristic $-176$ by a couple adjunctions. Then one can find the singularities fairly easily, and we have 32 nodes (orbit of $(1:1:1:1:1:1)$ under the symmetries of the curve) and 12 type $(2,2,4,4)$ singularities (orbit of $(1:i:0:0:0:0)$ under the same symmetries). Given a node is a type $(2,2,2,2)$ singularity, it's easy to see the Milnor numbers for the nodes are 1 and for the higher singularities, the Milnor numbers are 9. This explains the first equation completely. Now taking a small resolution of $X$ at each of the nodes simply adds one to the Euler characteristic, for each node, as a $\mathbb{P}^1$ adds two, and removing the node itself subtracts one. Now we take a small resolution of each $(2,2,4,4)$ singularity, so as before, the Milnor number of each singularity is 9, and we add an exceptional $\mathbb{P}^1$ in place of each node, so... this gives $12(2-9) = -84...$ of a change to the Euler characteristic? I don't see how to get $12(4-1)$.. Because of the 4 I figured maybe we could think about each small resolution as a blow up followed by a blow down, since every blow up adds a $\mathbb{P}^1\times\mathbb{P}^1$ which is 4-dimensional, but I haven't found any way to simply get $(4-1)$. I'm guessing I'm just fudging up something silly, so hopefully someone can easily remedy the confusion. I would also happy if anyone could recommend any good references to the related material. Meyer's book is very nice! However the $\sim$ 1.5 page treatment of resolution of singularities gives me the impression I was supposed to have seen it before. Thanks!","['algebraic-geometry', 'reference-request']"
139172,Trigonometric identities --- working on both sides of the equation at once,"When solving trigonometric identities, you aren't allowed to work on both sides of the equation at once. The reason for this is that if you do arrive at a valid conclusion, it doesn't provide the validity of the initial equation - it just proves that if the initial equation is true, you can arrive at a valid equation. I have a number of questions about this: 1) Why can't adding or subtracting to both sides by allowed? Regardless of the relation between the sides ($=$,$<$,$>$,$≤$ or $≥$), adding and subtracting doesn't change the relation. Unlike dividing or multiplying by a negative number (which inverses the sign), adding or subtracting doesn't change the sign. 2) If you do work on both sides, and you do arrive at a valid equation (i.e. the Pythagorean identity), can't you prove the initial equation by working backwards? Through this reasoning if you reach a valid equation by working on both sides, the initial equation is valid. For example:
Let $x$ represent a trigonometric identity you are checking the validity of. Let $y$ represent a proven identity such as the Pythagorean identity. Let's you say you do the following: i) Divide both sides of $x$ by $a$ ii) Multiply both sides of $x$ by $b$ iii) Add $c$ to both sides of $x$ iiii) You arrive at equation $y$ My math teacher would argue this doesn't prove the validity of $x$ - it simply proves that if $x$ is true, you can arrive at $y$. However, if you start at $y$, and do the above steps backward (Subtract $c$, divide by $b$ and multiply by $a$) won't you arrive at $x$? Therefore if you do arrive at $y$ through working on both sides of $x$, shouldn't $x$ be valid since you can arrive at $x$ by working backwards starting at $y$? 3) Some trigonometric identities are extremely complicated and take a while to solve. How do you tell the difference between you not being able to find the proof and when the equation is not true? Because it would be a waste of time trying to find the proof of an trigonometric identity that is invalid.",['trigonometry']
139180,Example questions for bias/consistent estimators.,"Now, I know how to do this particular one, but I was wondering if anyone had a place to get questions similar to this? I've tried googling, but have not come up with anything. Consider the regression model: $y=Bx + u$, where $\mathbb{E}(u)=0$, $\mathbb{Var}(u)=\sigma^2$. Is the following estimator an asymptotically unbiased estimator for $B$? $$ 
  \mathbb{E}(B) = \frac{\mathbb{Var}(n u)}{\sigma^2 n}
$$ Many thanks.",['statistics']
139183,Differentiating Definite Integral,I think $\frac{d}{dx} \int f(x) dx = f(x)$ right? So $\frac{d}{dx} \int^b_a f(x) dx = [f(x)]^b_a = f(a)-f(b)$? But why when: $$f(x) = \int^{x^3}_{x^2} \sqrt{7+2e^{3t-3}}$$ then $$f'(x) = \color{red}{(x^3)'}\sqrt{7+2e^{3x-3}} - \color{red}{(x^2)'}\sqrt{7+2e^{3x-3}}$$ Where did the $(x^3)'$ and $(x^2)'$ come from?,"['leibniz-integral-rule', 'integration', 'derivatives']"
139189,Evaluating 'combinatorial' sum,"Help me please to calculate the following sum. I have seen such kind of formulas in the papers related to combinatorics, specifically 'trees'. I am curious how to calculate or approximate this sum:
Let $n \in N$, $q\geq 2$
$$
\sum_{m=-n}^n m^q {n \choose (m+n)/2}=\Gamma(n+1)\sum_{m=-n}^nm^q\frac{1}{\Gamma(n/2-m/2+1)\Gamma(n/2+m/2+1)}
$$","['sequences-and-series', 'statistics', 'trees', 'binomial-coefficients', 'combinatorics']"
139195,Show that a star-like region is simply connected.,"A set S is called star-like if there exists a point $\alpha\in S$ such that the line segment connecting $\alpha$ and z is contained in S for all $z\in S$. Show that a star-like region is simply connected. My answer Show that
$γ:γ(t)=tz+(1−t)α, t≥1$ is contained in the complement for any z in the complement Let $\gamma$ represents the portion of the ray from $\alpha$ through z to $\infty$, starting at z. Thus, if z is in the complement of S, so is all of $\gamma$. For, if any $z_{1}\in \gamma$ belonged to S, so would the entire segment connecting $\alpha$ and $z_{1}$, including z. Could anyone help to formalize the answer?",['general-topology']
139215,orientation preserving map,"Let $f:X\rightarrow Y$ be a diffeomorphism between connected oriented manifolds. $f$ is orientation-preserving at $p\in X$ if the induced map $df_{p}:T_{p}X\rightarrow T_{f(p)}Y$ is orientation-preserving; similarly $f$ is orientation-reversing at $p$ if the derivative is orientation-reversing. Why must $f$ be either orientation-preserving everywhere or orientation-reversing everywhere? I think it is true that the sets of points where $p$ is orientation-preserving and orientation-reversing are both open (which implies the result), but I can't prove this.","['differential-topology', 'differential-geometry']"
139221,What are the vertices of a regular tetrahedron embeded in a sphere of radius R,"Imagine you had a sphere of radius R centered at the origin.  What are the coordinates of the vertices of the regular tetrahedron which is circumscribed by the sphere?  One of the vertices of the tetrahedron is (0,0,R) and one of the vertices lies in the z,x plane.","['geometry', 'polyhedra']"
139234,Hypersurface becomes an hyperplane after embedding,"Let $X$ be an hypersurface of degree $k$ in $\mathbb{P}^{n}$, why the equation defining $X$ becomes linear in the Veronese coordinates? More precisely I want to understand the last paragraph of the following link: https://www.encyclopediaofmath.org/index.php/Veronese_mapping",['algebraic-geometry']
139235,"Proving an identity using reciprocal, quotient, or Pythagorean identities.","I've been trying to prove this for a while, to no avail. I am only allowed to use pythagorean, quotient, and reciprocal identities:
$$\frac{\tan \theta}{1 + \cos \theta} = \sec \theta \csc\theta(1-\cos \theta)$$
I've tried converting $\tan \theta$ to $\frac{\sin \theta}{\cos \theta}$ and such, but could only get it simplified down to $\frac{\tan \theta}{\cos \theta + 1}$ on the LHS. As for the right, I tried a common denominator and ended up with $$\frac{1-\cos \theta}{\cos \theta \sin \theta}$$ but couldn't see how I could go further from there.",['trigonometry']
139242,Singular jacobian matrix?,"I have a series of questions, in various degrees of befuddled muddledness (and they are related to my previous questions: this and this ) First question: how do I do a change of variable if the determinant of the jacobian is singular? The setting for this question is as follows: I have one $n$-dimensional standard gaussian random variable $u \sim N(0,I)$ and a fixed $v \in \mathbb{R}^n$. Then I define the random variable
$$z = u - \frac{u^Tv}{v^Tv}v$$
and I'd like to derive a density for $z$. So the Jacobian:
$$\frac{dz}{du} = I - \frac{vv^T}{v^Tv}$$
which turns out to be singular and so $|\frac{dz}{du}|=0$. Does this mean trying to do a change of variable is fundamentally wrong here? Or is there a way to do this? Second question: Aside from the Jacobian, I'm not sure how to change a standard normal distribution on $u$ to a distribution on $z$. So if the density on $u$ is
$$\frac{1}{\sqrt{2\pi}}\exp(-u^Tu/2)$$
is there an inverse function $z^{-1}$ such that $z^{-1}(z) = u$? Then (I think)
$$\frac{1}{\sqrt{2\pi}}\exp(-u^Tu/2) du = \frac{1}{\sqrt{2\pi}}\exp(-z^{-T}z^{-1}/2) \left|\frac{dz}{du}\right| du$$
So, is there such a $z^{-1}$? And if there is, what is it? Third question: ultimately, I'm trying to answer this question . Am I going about this the right way by asking the two questions above? (The person who replied to my question there says something about Haar measure which I'd never heard of before so it's not enlightening to me as a proof.)","['multivariable-calculus', 'probability-distributions']"
139246,The set $\{g^2 | g \in G\}$ in a group $G$,"Let $G$ be a group. Prove or disprove that $H =\{g^2 | g \in G\}$ is a subgroup of $G$. I tried testing the permutations of $A_4$, however squaring each cycle yielded a cycle in $A_4$ so I'm lacking a counter-example (if there is one). In a nutshell I'm looking for a subgroup such that when you square the permutation cycle, it yields a cycle not in that subgroup. Or, I could be way off base and figure out that there isn't a counter-example and I need to prove that indeed $H$ is a subgroup of $G$.","['group-theory', 'abstract-algebra']"
139264,Monotonic function only has jump discontinuities,"I'm trying to show that a monotone function on a closed interval can only contain jump discontinuities. Could someone give me a hint as to how I should begin? I am not sure how to start this problem. Edit : Let $f$ be a increasing function. Then if $x \leq y, f(x) \leq f(y)$.",['real-analysis']
139272,Determine convergence of $\sum_{n=1}^{\infty} (\cos{\frac{2}{n}}-\cos{\frac{4}{n}})$,"Determine convergence of $$\sum_{n=1}^{\infty} \left(\cos{\frac{2}{n}}-\cos{\frac{4}{n}}\right)$$ In the answer, it says $$\cos{\frac{2}{n}}-\cos{\frac{4}{n}} = 2\sin{\frac{3}{n}}\sin{\frac{1}{n}} \le 2\cdot \frac{3}{n} \cdot \frac{1}{n} = \frac{6}{n^2}$$ But how do I get the above trig substitution? I guess removing the fractions, I will get $\cos{x}-\cos{2x}=2\sin{(2x-1)}\sin{(x-1)}$ ... probably this is wrong, but how do I get that?","['trigonometry', 'sequences-and-series']"
139284,Examples of not completely bounded maps,"Let $\phi:\mathcal{A}\longrightarrow\mathcal{B}$ be a bounded map between $C^*$ algebras. $\phi$ is said to be completely bounded if the natural extension map
\begin{eqnarray}
\phi_n:M_n(\mathcal{A})&\longrightarrow & M_n(\mathcal{B})\\
((a_{i,j}))&\longmapsto & ((\phi(a_{ij}))
\end{eqnarray}
is also bounded for all $n$. ($M_n(\mathcal{A})$ denotes $n\times n$ matrices whose entries are elements of $\mathcal{A}$.) This bound defines a norm as well which is known as completely bounded norm on the the set of maps. The standard example of a 'not' completely bounded bounded map  is transpose. I could not construct any other example which does not involve transpose. Unfortunately I could not locate any other example from the literature. Please help.","['operator-theory', 'operator-algebras', 'functional-analysis', 'operator-spaces']"
139298,Proof of Proposition 5.11 of David Cox's Primes of form $x^2+ny^2$?,"I'm just beginning to read the paper Finding Eisenstein Elements in Cyclic Number Fields of Odd Prime Degree .* On the third page, in Lemma 2, the author references Proposition 5.11 of David Cox's Primes of the form $x^2+ny^2$ , (John Wiley and Sons, New York, 1989), which is apparently found on page 102. It deals with inert primes. Unfortunately, I don't have access to this book, and it is checked out at my local library for another 3 weeks. Could someone with access perhaps provide the proof of the proposition in question? I'd be very grateful. *For some reason the link I copy from my browser doesn't seem to work as a link. Googling brings up the paper as the first result though.","['reference-request', 'number-theory']"
139304,A question about solving multiple integral,"What i wanna ask is that how do you tackle the problem oif multiple integral when you are not able to draw the diagram?Also how you would determine the order of integrand. For instance, what is the volume bounded by the surface $x^3+xyz^2, x^3y^2+z^y, z+y+2x=10$ Those function are just creat without any try, so may be it is not solvable, but what i want to say is if we face the function which cannot really draw it, how would you deal with it.","['multivariable-calculus', 'calculus', 'analysis']"
