question_id,title,body,tags
2767023,Diagram of the tangent vector at a point along a curve on a manifold in generalized coordinate system,"The interpretation of vectors as partial derivatives of the position vector and dual vectors as stacks is visually very appealing. I understand that in the book Gravitation by Misner the passage from one leave of the stack of a covector is made even more intuitive by pretending to be associated to some sort of sound effect (""bongs of bell""). Incredibly, though, I couldn't find any good diagrams of how this would work out to visualize the coordinates of a tangent vector $\vec v$ (in red below) to a point $P$ (central point below) on a manifold $M$ (in turquoise), where $P$ is located through the positional vector $\vec R = x^1(y_1,y_2,y_3)\vec e_1+x^2(y_1,y_2,y_3)\vec e_2+x^3(y_1,y_2,y_3)\vec e_3$ on a generalized curvilinear coordinate system. The vector $\vec v$ is NOT intended to belong to a vector field. It is a velocity vector tangent to the parameterized curve $f.$ Just dweling on one of the curvilinear coordinates in which only the $y_2$ component is allowed to change (in magenta) - $\vec R(c_1, y_2, c_3)$ - and with the stack (covector) represented as the orthogonal layers (also in magenta), I imagine that at point $P$ the tangent vector to a curve $f$ (in red) would be projected on one of the basis vectors, $\frac{\partial \vec R}{\partial y_2}\in T_pM$ (in black) as on the image to the left below. In the event that there is vector field (or scalar field?) defined on the manifold, the number of layers of the covector (1-form) pierced by the projected vector $\vec v$ on $\frac{\partial \vec R}{\partial y_2},$ if read-out directly on the stack (covector $\mathrm dy_2 \in T^*_pM$) as portrayed in the diagram (right side picture) it would amount to $2$ - i.e. the projection onto the black curvilinear coordinate basis vector pierces through exactly $2$ layers. This 1-forms underpin the integration along the curve. Is it correct to say that to introduce the 1-form (covector) a vector field on the manifold (or possibly a scalar field) needs to be defined (not drawn on the diagram)? Is it true that there is no role for 1-forms if all that was needed is to calculate the arc length of the curve $f$ on these generalized curvilinear coordinates, which would instead call for concepts like Lamé coefficients ? The question remains unanswered, likely due to the imprecisions in its formulation. However I tend to think that the correct answer is likely (I look forward to confirmation or corrections): In the case of integration to get the arc length, and since the differential distances, i.e. $dS= \sqrt{1 +\left(\frac{\partial \vec R}{\partial y_i}\right)^2}\mathrm dy,$ are 1-forms, the graphic correct (with recent modifications): the velocity vector $\vec v$ along the integration curve $f$ at point $P$ is part of the tangent space. The component along the curvilinear coordinate $\vec R(c_1,y_2,c_3)$ would give rise to the black vector - i.e. the projection of the vector $\vec v$ with its magnitude given by the number of magenta layers pierced orthogonal to the coordinate $\vec R(c_1,y_2,c_3)$. If there was a scalar or vector field defined on the manifold there would be a gradient or a field vector at point $P.$ The integration along the curve $f$ would implicitly involve for the tangent vector $\vec v$ to the curve $f$ at point $P$ to be dotted with that field vector as in any other point along the curve: $$\int_C \vec F \cdot \mathrm d\vec R =\int_a^b \vec F(\vec R(y_1(t),y_2(t),y_3(t))\cdot \vec R'(y_1(t),y_2(t),y_3(t))\mathrm dt.$$","['multivariable-calculus', 'differential-forms', 'differential-geometry', 'differential-topology']"
2767025,"Prove the coefficients of $\prod_{k=2}^{n+1}(1-x^{a_k})$ are $0$, $1$, or $-1$ where $(a_k)$ are Fibonacci numbers.","Given $a_1 =1,a_2=1, a_{n+2}=a_{n+1}+a_n$ , prove that for $n\geq 2$ , all coefficients of polynomial $$A(x)=\prod_{k=2}^{n+1}(1-x^{a_{k}})$$ are $0$ , $1$ , or $-1$ . I tried induction. I don't think it works. The hypothesis will be too weak. I think if we want to prove it by induction, we need to prove a stronger proposition, but I can't find it.","['fibonacci-numbers', 'polynomials', 'sequences-and-series']"
2767052,Is the Torricelli/Fermat point unique?,"In a triangle with all angles less than 120 degrees can there be two such points? I am wondering because in the geometry game Euclidea it gives two ""v-stars"" for this problem (theta 8.6). This usually means that there are two solutions possible. I found one solution, basically by constructing equilateral triangles on the sides and connecting their external vertices. However I am confused what the second solution is supposed to be.",['geometry']
2767077,General solution to a first-order partial differential equation,"$$
\begin{cases}
\displaystyle u(x+u)\frac {\partial 𝑢}{\partial 𝑥} - y(y+u)\frac {\partial 𝑢}{\partial 𝑦}  = 0 \\
u=\sqrt y ,x =1
\end{cases}
$$ my idea: Can we solve by the method : 
$$\frac {𝑑x}{u(𝑥+u )} =  \frac{𝑑y}{-y(𝑦 +u)}$$","['ordinary-differential-equations', 'partial-differential-equations']"
2767098,UMP level $\alpha$ test with distribution $f(x\mid\lambda) = \lambda x^{-2}$,"Suppose we have a random sample from the distribution $f(x\mid\lambda) = \lambda x^{-2}$ with $x > \lambda$. I want to find a UMP level $\alpha$ test for the hypothesis test $H_0: \lambda = \lambda_0$ and $H_1: \lambda = \lambda_1$, where $\lambda_1 > \lambda_0$. I believe $\prod_{i=1}^n x_i$ is a sufficient statistic for $\lambda$, but I don't know what to do from here. Any hints/general strategies would be great.","['statistics', 'statistical-inference']"
2767100,"How many lattice paths are there from $(0,0)$ to $(2n,2n)$ that avoids odd points","How many lattice paths are there from $(0,0)$ to $(2n,2n)$ that do not go through one of the points $(2i-1,2i-1)$ for $i=1,\dots,n$? My idea is to count the number of total lattice paths one can take from $(0,0)$ to $(2n,2n)$. There are ${4n \choose 2n}$ such paths. Then subtract the number of paths that are not valid. In counting these, I reasoned that we must avoid the ""odd points"" inside the grid with height and width of $2n$. I counted the number of paths that take these of points to be ${4 \choose 2}^{n-1}{2 \choose 1}{2 \choose 1}$ with the reasoning that from $(0,0)$ to $(1,1)$, there are ${2 \choose 1}$ paths, similarly for $(2n-1,2n-1)$ to $(2n,2n)$. Now, there are a total of $n-1$ ""odd points"" we consider and the number of paths from say $(1,1)$ to $(3,3)$ is ${4 \choose 2}$, we consider $n-1$ such scenarios. But in comparing my result, it is wrong, I seem to be undercounting the number of invalid paths that I need to subtract from the total paths. Edit: The result is expected to be the Catalan numbers of the form $C_{2n+1}$. Edit 2: I've reworked the problem to make the first couple of terms match $C_{2n+1}$, by removing from the total number of lattice paths the invalid paths (a sum of all the possible cases by which we choose how many and which odd points our invalid path has gone through). It seems to be some recursive function, any ideas how to express this recursively?","['combinatorics', 'recursion', 'discrete-mathematics']"
2767118,"Non-self-intersecting ""Robot Walks""","Question 208 on Project Euler describes walks of ""robots"" the move in parts of a circular arc: A [ $5$ -]robot moves in a series of one-fifth circular arcs (72°), with a free choice of a clockwise or an anticlockwise arc for each step, but no turning on the spot. Let an $n$ -robot be a robot that moves in $1/n$ of a circular arc. Let an $(i, j)$ -path be a path that consists of $i$ clockwise steps, followed by $j$ anticlockwise steps, followed by $i$ clockwise steps, and so on. The following picture shows $(i,j)$ -paths for all $0 < i < j < 5$ of a $5$ -robot. In order, these are: a $(1, 2)$ -path, $(1, 3)$ -path, $(1, 4)$ -path, $(2, 3)$ -path, $(2, 4)$ -path, and a $(3, 4)$ -path. It is clear from the picture that the $(1, 2)$ -path, $(2, 3)$ -path, and $(3,4)$ -path are non-self-intersecting. If you want to play around for yourself, you can do so on this web app . In particular, you can change the n=5 and w=1,4 in the URL to whatever value of $n>2$ that you want. Data Here's some data for $(i,j)$ -paths for an $n$ -robot with $3 \leq n \leq 12$ and $1 \leq i < j < n$ . Question In general, is there a combinatorial rule that will determine whether an $(i, j)$ -path is non-self-intersecting for an $n$ -robot? If so, does it predict how many intersections there will be? Conjecture Suppose that $i < j < n$ . Then an $(i,j)$ -path is non-self-intersecting if and only if $(j-i) \mid n$ and $6j < 5n$ .","['discrete-geometry', 'combinatorics', 'recreational-mathematics']"
2767149,soft question - differential geometry and topology book recommendations,"I just need a few book recommendations for studying on my own.
I know the basics (trig, calc, etc.) and on my free time, I studied multivariable and vector calculus, in addition to differential equations. 
I am now trying to go into the fields of differential geometry/manifolds/topology, etc.
Can you guys recommend me some books on my level? If you need me to tell you further what I already studied, please comment.
Thanks in advance.","['reference-request', 'reference-works', 'differential-geometry', 'soft-question']"
2767152,"Let $X_M^c$ be the space of vector fields on a manifold $M$ with compact support. Prove that $X_M^c=[X_M^c,X_M^c]$","Let $X_M^c$ be the space of vector fields on a manifold $M$ with compact support. Prove that $X_M^c=[X_M^c,X_M^c]$. Proving that $[X_M^c,X_M^c]\subset X_M^c$ is relatively simple. However, I have not been able to prove $X_M^c\subset [X_M^c,X_M^c]$. Any clues?",['differential-geometry']
2767201,Making a regular tetrahedron out of concrete,"I'm trying to make the following tetrahedron made of concrete just for fun: Each edge is a beam with a triangular cross section.
I imagine the easiest way is to make 6 identical truncated triangular prisms and glue them. Identical because I would need to make only one mold. The problem I'm having is figuring out the angles to make the mold. Currently I have the following equilateral triangle prism I made just for testing: Equilateral because it could be rotated to whatever edge it would be placed, but I tried recreating it on Autocad and the pieces wouldn't fit together. What I want is to find out what are the angles I need at the end of each prism and build a wooden piece to put into the mold to make the final piece.","['platonic-solids', 'angle', 'solid-geometry', 'geometry', '3d']"
2767202,Probability that if three balls numbered from 1-20 are selected without replacement that at least one will be numbered at least 17,"I'm a new user here. I am currently self-learning probability theory (long journey ahead). I was wondering as to why my answer is not correct. I have listed the question below. Three balls are to be randomly selected without replacement from an urn containing 20 balls numbered 1 through 20. If we bet that at least one of the balls that are drawn has a number as large as or larger than 17, what is the probability that we win the bet? My solution: $ {{ 4 \choose 1}{ 19 \choose 2} \over { 20 \choose 3}}  $ Reason: ${ 4 \choose 1}$ is of choosing either 17, 18, 19, or 20. ${ 19 \choose 2}$ once a urn is chosen which is either 17,18, 19 ,20. There are 19 balls left and the value does not matter.","['combinatorics', 'probability']"
2767254,"Prove that $(C^1[0,1], \|\cdot\|)$ is not a Banach space","Given the normed space $C^1[0,1]$ of differentiable functions with continuous derivatives on $[0,1]$ . The norm is defined as $$\|x\| = \max_{[0,1]} |x(t)|$$ I'd like to prove that the given normed space is not a Banach space. In the attempt of solving this problem, I have thought about the possibility to construct a Cauchy sequence in the space which doesn't converge in the space. However until now I haven't got any idea. Then I proceeded to think about constructing an equivalent norm to the given one where the space can be easily proven to be not a Banach space. However, I have got nothing either. Now I'm stuck without a clue. Please give me a hint to a correct direction. Any help is greatly appreciated.","['functional-analysis', 'normed-spaces', 'real-analysis', 'banach-spaces']"
2767260,Where did I go wrong when solving this system of differential equations?,"We have been given two differential equation, $$
\begin{alignat}{1}
\frac{dy}{dx}&=2y+z,\\
\frac{dz}{dx}&=3z.
\end{alignat}
$$ I need to solve this differential equation simultaneously. My approach From the first differential equation, on integrating with respect to x: $$y = y^2+zy.$$ Putting this equation of $y$ into the second differential equation yields: $$\frac{dz}{dx}=3y^2+3zy,$$ which is a linear differential equation with respect to $x$. Now, it can be solved as usual, and after solving my answer turned out to be: $$(z+y)e^{-3yx}=C$$ Now, this answer does not match with any of the following four solutions that were provided: $(z+y)e^{3x}=C$ $(z+3y)e^{-3x}=C$ $(y-z)e^{3x}=C$ $(z+3y)e^{3x}=C$ What did I do wrong?",['ordinary-differential-equations']
2767291,Evaluate$\int_0^\infty \frac{\log(x)^2}{(1+x)^2}dx$,"Trying to evaluate the integral
$$\int_0^\infty \frac{\log(x)^2}{(1+x)^2}dx$$ or equivalently $$\int_{-\infty}^\infty e^x\frac{x^2}{(1+e^x)^2}dx$$
The answer should be $\frac{\pi^2}{3}$ Looks like we can use residue theorem, but the integration path does not seem to be easy to choose","['complex-analysis', 'analysis']"
2767303,How does the Chern number relate to the Gauss-Bonnet theorem?,"I am a physicist so I am sorry if my question is not rigorous enough. We use the concept of a topological invariant named Chern number, and it is an integer. I have seen people relating it to the Euler characteristic.
They say that it has to do with the generalization of the Gauss-Bonnet theorem, namely the Gauss-Bonnet-Chern theorem although I can't see exactly how. How can one go from the Gauss-Bonnet-Chern theorem, if we apply it to a 2D manifold, to the classic Gauss-Bonnet theorem?","['differential-geometry', 'differential-topology']"
2767317,Leibniz rule with balls,"Let's say I have an integral: $$\int_{B_{t}} f(t,x) \mathrm{d}x$$ where $B_t$ is the ball of radius $t$ . And I would like to apply the Leibniz rule to compute the derivative of this. How would I do it? I know that the formula goes something like this: $$\frac{d}{dt}\int_{B_{t}} f(t,x) \mathrm{d}x = \int_{B_t} \frac{d}{dt}f(t,x) \mathrm{d}x + \int_{\partial B_t}g(t,x) \mathrm{d}S$$ I know that $g$ is supposed to have something to do with the velocity of the boundary (I saw this term used when discussing the Reynolds transport theorem). What does this mean exactly? How can I compute it for the case of the unit ball?","['derivatives', 'leibniz-integral-rule', 'multivariable-calculus', 'definite-integrals', 'vector-analysis']"
2767318,Flatness of a statistical manifold with Fisher information metric,"Let $\mathcal{M} = \{p_\theta := p(\cdot | \theta), \theta \in \Theta\}$ be a statistical manifold with Fisher information metric: $$g_{{jk}}(\theta )=\operatorname {E} \left[\left({\frac {\partial }{\partial \theta _{i}}}\log p(X;\theta )\right)\left({\frac {\partial }{\partial \theta _{j}}}\log p(X;\theta )\right) \right].$$ The Wikipedia article on the topic derives the metric form Euclidean metric by changing variables. I can understand the procedure but I have questions related to the flatness of $\mathcal{M}$. In Amari's book; ""Information Geometry and its application"", it is said that such manifold is flat  (dually flat actually) so 1- Is the above derivation enough to conclude that the manifold is flat (I mean the fact that the metric is derived from the Euclidean metric)? 2- Is there a straightforward way to show that the curvature is 0 everywhere?","['fisher-information', 'information-geometry', 'differential-geometry']"
2767338,Finite Calculus on undefinded values -- Concrete Mathematics,"I have been reading Concrete Mathematics by Donald Knuth.  Upon reading chapter 2 on page 29, I came across the following sum : $H_n=1+\frac{1}{2}+\frac{1}{3}+...+\frac{1}{n}=$$\sum_{k=1}^n \frac{1}{k}$. From this I deduce that $H_n$ is defined for any integer $\geq 1$. However, on page 56, we have the following:
$\sum_{}^{} xH_x \delta x = \frac{x^{\underline2}}{2}H_x - \frac{x^{\underline2}}{4} + C$ and that $\sum_{0}^{n-1} kH_k = \sum_{0}^{n} xH_x \delta x =\frac{n^{\underline2}}{2}(H_n - \frac{1}{2})$. That is, $\frac{x^{\underline2}}{2}H_x - \frac{x^{\underline2}}{4} + C \bigg|_{0}^{n} = \frac{n^{\underline2}}{2}(H_n - \frac{1}{2})$. But this last line requires us to compute $(\frac{n^{\underline2}}{2}H_n - \frac{n^{\underline2}}{4} + C) - (\frac{0^{\underline2}}{2}H_0 - \frac{0^{\underline2}}{4} + C)$. But $H_0$ is not defined.  So how can we correctly compute this last line?","['calculus', 'discrete-mathematics']"
2767511,Square board game with overlapping square sub-parts,"Two players, A and B play a game on a board with $NxN$ squares. Player A populates all squares with numbers from 1 to $N^2$ in a completely random way. Here is an example for a 5x5 board: Player B does not see the board but can ask player A to tell him the content of any square part of the board. Two such square parts (with red and green frame) are shown here: Player A has to report numbers in the requested square part but he does not have to report them in any particular order. For example, for the red part of the board he could respond with: 23, 21, 12, 4, 14, 10, 5, 22, 25. And for the green part he could reply with: 15, 21, 11, 1. How many questions player B has to ask before he is able to fully reconstruct the content of the board? Obviously he can do it by asking for a content of every single 1x1 square of the board. So in the worst case he does not have to ask more than $N^2-1$ questions. But with a better strategy that number can be greatly reduced.","['combinatorics', 'chessboard']"
2767570,The shortest distance from a point to the graph of the function,"To compute the distance from the point (5,5) to the graph of xy=4. I choose an arbitrary point (u,v) on the graph of $xy=4$.
 I get $d(u,v)=\sqrt{(u-5)^2+(v-5)^2}$ again $(u,v)$ satisfies equation of hyperbola so that $uv=4$. Now what shall i do next?",['multivariable-calculus']
2767578,"Let $X_1, X_2, \dots,X_n$ independent random variables.","Let $X_1, X_2, \dots,X_n$ independent random variables such that for $1\le i \le n$ the distribution of $X_i$ is $$\mathbb{P}(X_i=2^i)=\frac{1}{2^i}, \space \space \mathbb{P}(X_i=1)=\frac{1}{2}-\frac{1}{2^{i+1}}, \space \space\mathbb{P}(X_i=-1)=\frac{1}{2}-\frac{1}{2^{i+1}}$$ For $1\le i \le n$ , we'll define the event $A_i = \{X_i\ne2^i\}$ and the random variable $Y_i=X_i\cdot \mathbb{1}_{A_i}$ . (a) Prove: For all $i$ : $\mathbb{E}Y_i=0$ (b) For $1\le k \le n$ , we'll define the event $B_k$ that there exists $k\le i \le n$ , such that: $X_i\ne Y_i$ . Prove the following inequality: $$\mathbb{P}(B_k)\le\frac{1}{2^{k-1}}$$ My try: (a) $Y_i$ takes the values $0, 1$ or $-1$ : $\mathbb{E}Y_i=\mathbb{P}(Y_i=1)\cdot1+\mathbb{P}(Y_i=-1)\cdot(-1)+\mathbb{P}(Y_i=0)\cdot0$ Since: $\mathbb{P}(Y_i=1)=\mathbb{P}(X_i=1)\cdot\mathbb{P}(\mathbb{1}_{A_i}=1)=\mathbb{P}(X_i=-1)\cdot\mathbb{P}(\mathbb{1}_{A_i}=1)=\mathbb{P}(Y_i=-1)$ Then, the result above is 0. Can anyone validate that proof? (b) I'm struggling a bit with the definitions. How is that possible that $X_i=Y_i$ as $Y_i$ takes the values: $0, 1$ or $-1$ and $X_i$ takes $2^i, 1$ or $-1$ , so they would never be equal. I hope you could help me get the definitions straight.","['expectation', 'probability-theory', 'probability-distributions', 'probability', 'random-variables']"
2767579,Simple commutative algebra localisation problem that I just can't seem to see,"Let $B$ be a noetherian integral domain and consider the polynomial ring $B[t]$. Let $\mathfrak{p}$ be a prime ideal in $B[t]$ of height $1$ such that $\mathfrak{p} \cap B = (0)$. Show that $B[t]_{\mathfrak{p}}$ is just $K[t]_{\mathfrak{m}}$ where $K$ is the field of fractions of $B$ and $\mathfrak{m}$ is some maximal ideal of $K[t]$. Note this isn't a homework problem, it's actually a step in a proof in Hartshorne that I got stuck on, showing that the preimage of the generic point under the fibered product is a regular codimension $1$ point. For reference it's Proposition II.6.6. It seems like this should be straight forward, but I'm having trouble making it rigourous. We have $B[t]_{\mathfrak{p}}$, and since $\mathfrak{p}$ doesn't contain any non-zero element in $B$, then $B[t]_{\mathfrak{p}}$ must at least contain $K[t]$. If $B$ was a UFD then it would be easy, since we could say that $\mathfrak{p}$ is principal. But say $\mathfrak{p}$ is generated by $\{ f_{1}, f_{2}, \ldots , f_{r}  \}$. I can ""see"" intuitively that the result should be $K[t]_{\langle f_{1}, \ldots, f_{r}\rangle}$, and of course $\langle f_{1}, \ldots, f_{r} \rangle$ would be principal in $K[t]$. But I can't seem to be able to make this rigorous, which is worrying to me because I feel like this should be extremely straight forward. Any advice?","['localization', 'maximal-and-prime-ideals', 'algebraic-geometry', 'commutative-algebra']"
2767660,Find $\lim_{n\to\infty}P_n$ where $P_n =\big (1+\frac{1}{a_1}\big)\big(1+\frac{1}{a_2}\big)\big(1+\frac{1}{a_3}\big)\cdots\big(1+\frac{1}{a_n}\big)$ [duplicate],"This question already has answers here : How I find limit of $P_n$ (3 answers) Closed 12 months ago . Let $a_1=1$ and $a_n=n(a_{n-1}+1)$ for $n=2,3,\ldots$ Find $$\lim_{n\to\infty}P_n\\ P_n = \left(1+\frac{1}{a_1}\right)\left(1+\frac{1}{a_2}\right)\left(1+\frac{1}{a_3}\right)\cdots\left(1+\frac{1}{a_n}\right); \ n=1,2,\ldots$$ My approach: $$ P_n = \left(\frac{a_1+1}{a_1}\right)\left(\frac{a_2+1}{a_2}\right)\cdots\left(\frac{a_n+1}{a_n}\right)$$ or $$P_n = \left(\frac{a_2}{2a_1}\right)\left(\frac{a_3}{3a_2}\right)\left(\frac{a_4}{4a_3}\right)\cdots\left(\frac{a_{n+1}}{(n+1)a_n}\right)$$ or $$P_n = \left(\frac{a_{n+1}}{a_1(n+1)!}\right)$$ or $$\lim_{n\to\infty} P_n =\lim_{n\to\infty} \left(\frac{a_{n+1}}{(n+1)!}\right)$$ How to find $\lim_\limits{n\to\infty}a_{n+1}$? I am stuck here.","['infinite-product', 'limits', 'sequences-and-series', 'convergence-divergence', 'power-series']"
2767665,A problem about matrix eigenvalues: the eigenvalues of $A_n$ are all positive and no more than $3+2\sqrt 2$,"Today I was asked by a friend to have a look over a linear algebra problem, which is quite easy at a first glance: For $n\in\mathbb N$, put $$A_n=\left[\begin{matrix}1 &\frac{1}{2} &\frac{1}{3} &\cdots &\frac{1}{n}\\
\frac{1}{2} &\frac{1}{2} &\frac{1}{3} &\cdots &\frac{1}{n}\\
\frac{1}{3} &\frac{1}{3} &\frac{1}{3} &\cdots &\frac{1}{n}\\
\vdots& & &\ddots & \vdots\\
\frac{1}{n}& \frac{1}{n}& \frac{1}{n}& \cdots &\frac{1}{n}\end{matrix}\right].$$ Then the eigenvalues of $A_n$ are all positive and no more than $3+2\sqrt2$. To the positivity of eigenvalues, we may consider the matrix $P=\left[\begin{smallmatrix} 1 \\ -1 & 1\\ & \ddots&  \ddots \\& & & 1\\& & & -1 &1\end{smallmatrix}\right]$ and it follows that $P^\top AP=\left[\begin{smallmatrix} 1/2 \\ & 1/6& &\ast \\ & &\ddots\\ & &  & 1/(n-1)n\\ & O& & & 1/n\end{smallmatrix}\right]$. Now the problem is, the wierd bound $3+2\sqrt 2$ cannot be seen. Diagonalizing this real symmetric matrix does not seem to work because it usually needs the eigenvalues beforehand. I thought about Gerschgorin disk but unfortunately it does no help here. So I would like to ask for some ideas about this problem, and any help is appreciated.","['eigenvalues-eigenvectors', 'linear-algebra']"
2767678,"We have two coins, A and B. For each toss of coin A, the probability of getting head is 1/2...","We have two coins, A and B. For each toss of coin A, the probability of getting head is 1/2 and for each toss of coin B, the probability of getting Heads is 1/3. All tosses of the same coin are independent. We select a coin at random and toss it till we get a head. The probability of selecting coin A is ¼ and coin B is 3/4. What is the expected number of tosses to get the first heads? The above problem is taken from the website https://www.analyticsvidhya.com/blog/2017/04/40-questions-on-probability-for-all-aspiring-data-scientists/ question 11 My solution is either 1/(1/4*1/2 + 3/4*1/3)=8/3, including the success toss, or 5/3, not including the success toss. My understanding is that it is geometric distribution question. But the solution provided is 2.75, with the following explanation:
""If coin A is selected then the number of times the coin would be tossed for a guaranteed Heads is 2, similarly, for coin B it is 3. Thus the number of times would be
Tosses = 2 * (1/4)[probability of selecting coin A] + 3*(3/4)[probability of selecting coin B] = 2.75"" Is the solution provided incorrect? Or am I missing something?","['probability', 'expected-value']"
2767702,Data analysis over geometric distribution sample with R (statistics pack),"Problem : The following observations are the number of tries $21$ football players had to make until they succeeded in scoring a penalty kick. Consider that all players have equal skills. $$3 \quad 2 \quad 1 \quad 3 \quad 2 \quad 1 \quad 1 \quad 2 \quad 3 \quad 4 \quad 2 \quad 2 \quad 2 \quad 5 \quad 3 \quad 4 \quad 1 \quad 2 \quad 5 \quad 2 \quad 3$$ (i) Find analytically the Maximum Likelihood Estimator of the success rate of each player regarding the penalty kicks. (ii) Find graphically the Maximum Likelihood Estimator of the success rateo f each player regarding the penalty kicks, with the help of $\mathbf{R}$ (statistics pack-language) Attempt : (ii) One can easily see that the case of the specific problem leads to the conclusion that the observations follow the Geometric Distribution as it follows exactly by its definition (the number of trials $x$ needed until the first success). Thus, the Maximum Likelihood Estimator can be found us (Loglikelihood) : Let $X_1, X_2, \dots, X_n$ with p.d.f. $f(x;p)=(1-p)^{x_1}p, \; x=1,2,\dots$ .The likelihood function is given by :
  $$L\left(p \right)={\left(1-p \right)}^{{x}_{1}-1}p {\left(1-p \right)}^{{x}_{2}-1}p...{\left(1-p \right)}^{{x}_{n}-1}p ={p}^{n}{\left(1-p \right)}^{\sum_{1}^{n}{x}_{i}-n}$$
  By applying the natural logarithm, we get :
  $$\ln L\left(p \right)= n\ln{p}+\left(\sum_{1}^{n}{x}_{i}-n \right)\ln{\left(1-p \right)}$$
  Following differentiation and equaling to zero, we yield :
  $$\frac{d\left[\ln L\left(p \right)\right]}{dp}=\frac{n}{p} -\frac{\left(\sum_{1}^{n}{x}_{i}-n \right)}{\left(1-p \right)}=0 \Rightarrow p=\frac{n}{\left(\sum_{1}^{n}{x}_{i} \right)}$$
  which means that the Maximum Likelihood Estimator (Loglikelihood as we applied the logarithm) is :
  $$P = \frac{n}{\left(\sum_{1}^{n}{x}_{i} \right)} =  \frac{1}{\bar{X}}$$ With the help of the statistics pack $\mathbf{R}$, we can write a short function to compute any Geometric Distribution Loglikelihood we'd like : which when we execute for a given vector $\mathbf{trials}$ with the given observations, it returns the wanted result. Question : My question is about part (ii) though, as I am completely at loss on how to proceed on estimating-calculating the Maximum Likelihood Estimator graphically with $\mathbf{R}$, especially since this is a case of a discrete distribution. I would really appreciate any hint or thorough explanation on how to proceed with it.","['statistics', 'computational-mathematics', 'data-analysis', 'probability-distributions']"
2767765,"Lorenzini's ""Invitation to arithmetic geometry"", 1st exercise","I'm reading Dino Lorenzini's book ""An invitation to Arithmetic Geometry"" and the very first exercise is the following Ex. 1 Let $d\in \Bbb{Q}\backslash\Bbb{Z}.$ Show that $\Bbb{Z}[\sqrt{d}]$ is not a finitely generated abelian group. Since this is the first exercise and judging by the fact that the other exercises are quite easy, I assume that I am missing something. This is my guess and I would be happy if someone can check it or provide me with a solution. $\color{red}{\textrm{EDIT: The solution below fails because of the following WRONG assumption that I silently used: If }G,H\textrm{ are finitely generated abelian groups and }H\subsetneq G\textrm{ then }rank(H)<rank(G)\textrm{ (take }G=\Bbb{Z}, H=2\Bbb{Z}) \textrm{ to arrive at a contradiction.}}$ Solution(?) Supposing that it is finitely generated, it must be a free abelian group of finite rank (since there are no elements of finite order in it). Therefore, $\Bbb{Z}[\sqrt{d}]=\Bbb{Z}^n$ for some $n$. I will show that it contains free abelian groups of arbitrarily large ranks, which is a contradiction. Consider the elements $d, d^2, d^3,...$ and the subgroups $I_1=\langle d\rangle$, $I_2=\langle d,d^2\rangle$,..., $I_n=\langle d,\dots,d^n\rangle$. $I_1$ is free abelian of rank $1$ with $\{d\}$ as basis. Similarly $\{d,d^2\}$ is a basis for $I_2$. I can show that $d^3\notin I_2$ and this will give me that $I_2\subsetneq I_3$. This will mean that $rank (I_3)>rank(I_2)=2$ as I want. Notice here that $\{d,d^2,d^3\}$ are not linearly independent i.e. they do not form a basis of $I_3$. This puzzles me but I don't think it matters, since I am only interested in proving that the sequence
  $$I_1\subsetneq I_2\subsetneq ...\subsetneq I_n\subsetneq ...$$
  is non-constant. Indeed, let me show why $d^4$ cannot be written as
  $$\lambda_1 d+\lambda_2 d^2+\lambda_3 d^3$$
  for $\lambda_1, \lambda_2,\lambda_3\in\Bbb{Z}$. Writting $d=p/q$ yields
  $$\frac{p^2}{q^2}=\lambda_1\frac{\sqrt{p}}{\sqrt{q}}+\lambda_2\frac{p}{q}+\lambda_3\frac{p}{q}\frac{\sqrt{p}}{\sqrt{q}}$$
  which can be rewritten as $$\frac{\sqrt{p}}{\sqrt{q}}\left(\lambda_1+\lambda_3\frac{p}{q}\right)=\frac{p}{q}\left(\frac{p}{q}-\lambda_2\right)$$
  Now if $\left(\lambda_1+\lambda_3\frac{p}{q}\right)=0$ then $\frac{p}{q}=\lambda_2\in\Bbb{Z}$ (contradiction) hence
  $$\frac{\sqrt{p}}{\sqrt{q}}=\frac{\frac{p}{q}\left(\frac{p}{q}-\lambda_2\right)}{\left(\lambda_1+\lambda_3\frac{p}{q}\right)}\in\Bbb{Q}$$
  which is a contradiction too. Similarly it can be proven that $d^{i+1}\notin I_i$, which means that $rank(I_{i+1})>rank(I_i)$ yielding the desired result. I understand this is way too awkward to be correct... Thanks a lot for any help!","['abstract-algebra', 'algebraic-number-theory', 'group-theory', 'proof-verification']"
2767799,How to derive this continued fraction formula of $\ln(2)$?,"On wiki page Naturel logarithhm of 2, other representations section it lists
$$\ln\,2=\cfrac 1{1+\cfrac 1{2+\cfrac 1{3+\cfrac 2{2+\cfrac 2{5+\cfrac 3{2+\cfrac 3{7+\cfrac 4{2+\cfrac 4{9+\cdots}}}}}}}}}$$ How to derive this? I checked Euler's continued fraction formula page but still couldn't figure out how the $a_i$ and $b_i$ are derived. A math stackexchange answer mentioned
$$\;\left[\matrix {n_k\\d_k}\right]=\left[\matrix {n_{k-1}\;n_{k-2}\\d_{k-1}\;d_{k-2}}\right]\left[\matrix {b_k\\a_k}\right],\quad\left[\matrix {n_1\\d_1}\right]=\left[\matrix {b_0\,b_1+a_1\\b_1}\right]=\left[\matrix {1\\1}\right],\;\left[\matrix {n_0\\d_0}\right]=\left[\matrix {b_0\\1}\right]=\left[\matrix {0\\1}\right]$$
but didn't explain where this is from.","['real-analysis', 'continued-fractions']"
2767801,$f(x)$ such that $f(x)*f(f(x)+\frac{1}{x})=1$ and $f(x) > - \frac{1}{x}$ $ \forall$ $ x > 0$ and $f(x)$ is an injective function,"I don't even know where to begin in solving this functional equation. I got this in a multiple choice question exam and was able to solve it by substituting all of the given options into the equation. The one that worked is $$f(x) = \frac{1 -\sqrt 5}{2x}$$ I can't even prove that this is a unique solution. However, I was able to show that $f(1)=\frac{1-\sqrt 5}{2}$","['functional-analysis', 'functions', 'functional-equations']"
2767806,"Does ""local on the target"" mean the same thing as ""local on the base""?","In Vakil's book (Foundation of Algebraic Geometry), I learned the definition of a type of morphism of schemes being local on the target: A class of morphisms of schemes is called local on the target if (a) if $\pi:X\rightarrow Y$ is in the class then for any open set $V$
  of $Y$, the restricted morphism $\pi ^{-1} (V)\rightarrow V$ is in the
  class. (b) for a morphism $\pi:X\rightarrow Y$, if there is an open cover
  {$V_i$} of $Y$ for which each restricted morphism $\pi ^{-1}(V)\rightarrow V$ is in the class, then $\pi$ is in the class. In the other book (Algebraic Geometry and Arithmetic curve Qing Liu), I learned a similar definition. A property P of morphisms of schemes $\pi:X\rightarrow Y$ is said to
  be local on the base if the following assertions are equivalent: (i) $\pi$ verifies P. (ii) for any $y\in Y$, there exists an affine neighborhood $V$ of $y$
  such that the restricted morphism $\pi ^{-1} (V)\rightarrow V$ verfies
  P. It's obvious that ""local on the target"" implies ""local on the base"", but do we have another direction?","['schemes', 'algebraic-geometry']"
2767839,How do you interpret a product of transpositions? [duplicate],"This question already has answers here : How to write permutations as product of disjoint cycles and transpositions (3 answers) Closed 6 years ago . I'm trying to understand why the product of transpositions for a specific permutation is not unique. Intuitively, it somewhat makes sense to me since I can get the answer but I don't actually know why it works. The example I am particularly confused over is:
say I have a permutation which in cycle notation is of the form: (1,2,3,4) Then I have been given two examples of transpositions that work: 1) (1,4)(1,3)(1,2) 2) (2,3)(1,3)(3,5)(3,4)(4,5) Is it like you treat each transposition as a bijection that belongs to (in this case) S5 (or for any N>5) and so you consider the product of transpositions as a composition of all these bijections - which is why you start from the right and work your way backwards bracket by bracket and you stop once that number doesn't appear anymore? Is this also the case for a product of permutations? Thanks!","['permutations', 'abstract-algebra', 'functions']"
2767873,Why is the square root of Cholesky decomposition equal to the lower triangular matrix?,"I came across this as I was learning unscented Kalman filters. Suppose I have a symmetric and positive definite matrix $P$ . I want to take its square root. After I perform the Cholesky decomposition of $P$ , I get $LL^T$ . One of the resources (inaccessible on the web) I am using says that when you take the square root of $LL^T$ , you get the lower triangular matrix $L$ . That's why I don't understand. My understanding was that matrix $Y$ is a square root of $X$ if the matrix product $YY$ is equal to $X$ . But what seems to be acceptable is that matrix Y can be a square root of X even when the matrix product $Y^TY$ is equal to $X$ .","['numerical-linear-algebra', 'cholesky-decomposition', 'matrices', 'matrix-decomposition', 'linear-algebra']"
2767884,Extrema of implicit functions - one point - two values?!,"I am given this expression:
$$x^2+y^2+z^2-2x-2y-2z+2 = 0$$
And I need to find the extrema of the function 
$$z = z(x,y)$$
I did it in the following way: Differentiate the expression with respect to $x$ and solve for $\frac{dz}{dx}$ Differentiate with respect to $y$ and solve for $\frac{dz}{dy}$ Find all tuples $(x, y ,z)$ such that $\frac{dz}{dx} = \frac{dz}{dy} = 0$ given that both partial derivatives are continuous and exist. Now, I got two points: $(1, 1, 0) $ and $(1, 1, 2)$ both of them turn out to be an extremum, but - to be honest - I do not know what is happening - why does this function have two outputs for one input? Could you explain this to me in as simple terms as possible?","['multivariable-calculus', 'calculus']"
2767887,"Let $\sigma \in\operatorname{Aut}(K)$ have infinite order and $F = \mathcal{F}(\sigma)$. Show that if $K/F$ is algebraic, then $K$ is normal over $F$.","Let $K$ be a field, and suppose that $\sigma \in\operatorname{Aut}(K)$ has infinite order. Let $F$ be the fixed field of $\sigma$ . If $K/F$ is algebraic, show that $K$ is normal over $F$ . I have to use Definition. If $K$ is a field extension of $F$ , then $K$ is normal over $F$ if $K$ is splitting field of a set of polynomials over $F$ Criteria for normality: Proposition. If $K$ is algebraic over $F$ , then the following statements are equivalent: The field $K$ is normal over $F$ 2. If $M$ is an algebraic closure of $K$ and if $\tau: K \to M$ is an $F$ -homomorphism, then $\tau(K)=K$ .
3. If $F \subset L \subset K \subset N$ are fields and if $\sigma: L \to N$ is an $F$ -homomorphism, then $\sigma(L) \subset K$ , and there is a $\tau \in\operatorname{Gal}(K/F)$ with $\tau|_{L} = \sigma$ 4. For any irreducible $f(x) \in F[x]$ , if $f$ has a root in $K$ , then $f$ splits over $K$ . I'm not sure what to do, I'm trying to use the statement 2. We know that $\mathcal{F}(\sigma) = F$ , so $\sigma(F) = F$ . Let $M$ be an algebraic closure of $K$ . We know that $\sigma$ is an $F$ -automorphism, in particular, $\sigma$ is an $F$ -homomorphism... $\sigma: K \to M$ would not it be a $F$ -homomorphism? Seems very simple, I imagine I'm not seeing something, because I didn't use the hypothesis $\sigma$ has infinite order. Thanks for the help!","['abstract-algebra', 'galois-theory', 'extension-field', 'field-theory']"
2767897,Evaluate $\int_{0}^{\pi} \log \left(m^2-2m\cos x+1\right)\: dx$ [duplicate],"This question already has answers here : Computing $\int_{0}^{\pi}\ln\left(1-2a\cos x+a^2\right) \, dx$ (7 answers) Closed 3 years ago . Evaluate $$\int_{0}^{\pi} \log \left(m^2-2m\cos x+1\right)\: dx$$ My Try: I let $$f(m)=\int_{0}^{\pi} \log \left(m^2-2m\cos x+1\right)\: dx$$ Differentiating w.r.t $m$ both sides we get $$f'(m)=2\int_{0}^{\pi}\frac{(m- \cos x)dx}{(m-\cos x)^2+\sin^2x}=2\int_{0}^{\pi}\frac{(m+ \cos x)dx}{(m+\cos x)^2+\sin^2x}$$ we get $$f'(m)=2\int_{0}^{\pi}\frac{m \csc^2 x+\csc x \cot x}{(m\csc x+\cot x)^2+1}$$ How to proceed now?","['definite-integrals', 'integration', 'trigonometry', 'calculus']"
2768002,Geometric Proof of Perron-Frobenius II,"The following is proved in these lecture notes. Let $A$ be an $n\times n$ real matrix with all entries positive.
Then $A$ has a unique positive eigenvector (up to positve scaling), and the eigenvalue of $A$ corresponding to this eigenvector is greater than every other real eigenvalue in absolute value. By a positive vector we mean a vector all of whose entries are positive. (I am alluding the statement made alongside ""Perron-Frobenius Theorem"" in the link provided. What I have stated is not quite what is stated in the PDF). The proof given goes as follows. Let $X$ be the set of all the points $(x_1, \ldots, x_n)\in\mathbf R^n$ such that each $x_i\geq 0$ , and $\sum x_i^2=1$ .
Define $T:X\to X$ as $Tv=Av/\|Av\|_2$ .
Then $T$ is a contraction (I haven't yet verified this but this seems intuitively reasonable).
Therefore, by Banach Fixed Point theorem, there is a unique vector $v\in X$ which is fixed by $T$ .
Thus $v$ is an eigenvector of $A$ and say $Av=\lambda v$ . Now let $\mu$ be any other real eigenvalue of $A$ , and let $w=(w_1, \ldots, w_n)$ be a corresponding eigenvector.
At least one entry of $w$ is negative.
Write $|w|$ to denote the vector whose $i$ -th entry is $|w_i|$ . Here is the statement I am unable to understand Then $A(|w|)$ has smaller length than $\lambda L$ , where $L$ is the length of $w$ . Can somebody explain why is this true? It seems what is really used here is that $\|Au\|\leq \lambda \|u\|_2$ for each $u\in X$ , but I don't see why is this true. A related discussion is here .","['eigenvalues-eigenvectors', 'matrices', 'positive-matrices', 'fixed-point-theorems', 'linear-algebra']"
2768011,Wronskian zero and linear dependence,"Let $y''(x)+p(x)y'(x)+q(x)y(x)=0$ such that $p(x),q(x)$ are continuous. Let $y_1(x),y_2(x)$ be two solutions of the equation. Suppose that $y_1(x),y_2(x)$ both attain a maximum at a point $x_0$. Prove that $y_1,y_2$ are linearly dependent. Is it possible to say that $y_1'(x_0)=y_2'(x_0)=0$ and then, using Abel's formula, we get that $W[y_1,y_2,x]\equiv 0$ and so $y_1,y_2$ are linearly dependent? Moreover, in general can we say that if $p,q$ are continuous and $W[y_1,y_2,x]\equiv 0$ then the solutions $y_1,y_2$ are dependent? Edit: $W[y_1,y_2,x]=y_1(x)y_2'(x)-y_2(x)y_1'(x)\equiv 0$, so define $f(x)=\frac{y_2(x)}{y_1(x)}$. Then $f'(x)=\frac{y_1(x)y_2'(x)-y_2(x)y_1'(x)}{(y_1(x))^2}\equiv 0$. So $\exists c\in\mathbb{R}: f(x)\equiv c$ and finally $\exists c\in\mathbb{R}: y_2(x)\equiv c\cdot y_1(x)$. But, for this we need $y_1(x)\neq 0$.",['ordinary-differential-equations']
2768072,How do I combine two trigonometric waveforms that have the same $\omega t$ but different $\phi$,"I am working on an applied math assignment of mine and there's this problem on waveform combination that is kinda tricky. My lecturer did a problem similar to this as an example. However, the example he did was simple as it only had the angular frequency and no phase shift. Here is the problem: The current flowing in an AC circuit is defined by the following trigonometric waveform: $$i=\cos(3t-1)-2\sin(3t+4)$$ He wants us to combine those two waveforms into a simpler trigonometric waveform of the form $$i=\sin(\omega t+\phi) \quad\text{with}\quad \phi\geq 0$$ Here's my working: using the identities $cos(A-B)=cos(A)cos(B)+sin(A)sin(B)$ and $sin(A+B)=sin(A)cos(B)+cos(A)sin(B)$ $$cos(3t)cos(-1)+sin(3t)sin(-1)-2[sin(3t)cos(-1)+cos(3t)sin(-1)]$$ $$0.5403023059cos(3t)-0.8414709848sin(3t)-2[0.5403023059sin(3t)-0.8414709848cos(3t)]$$ $$0.5403023059cos(3t)+1.68294197cos(3t)-0.8414709848sin(3t)-1.080604612sin(3t)$$ $$2.223244275cos(3t)-1.922075597sin(3t)$$ Using $Asin(\omega t + \phi)$ : $$A[sin(\omega t)cos(\phi)+cos(\omega t)sin(\phi)]$$ $$Asin(\omega t)cos(\phi)+Acos(\omega t)sin(\phi)$$ Equate coefficients: $$2.223244275=Acos(\phi) eq1$$ $$(2.223244275)^2 = A^2sin^2(\phi) eq2$$ $$-1.922075597=Acos(\phi) eq3$$ $$(-1.922075597)^2=A^2cos^2(\phi) eq4$$ Now add eq2 and eq4: $$(2.223244275)^2 + (-1.922075597)^2 = A^2cos^2(\phi)+A^2sin^2(\phi)$$ $$(2.223244275)^2 + (-1.922075597)^2 = A^2(cos^2(\phi)+sin^2(\phi))$$ $$(2.223244275)^2 + (-1.922075597)^2 = A^2$$ $$A=\sqrt{(2.223244275)^2+(-1.922075597)^2}$$ $$A=2.938909612$$ Now divide eq3 and eq1: $$\frac{2.223244275}{-1.922075597}=\frac{Acos(\phi)}{Asin(\phi)}$$ $$\frac{2.223244275}{-1.922075597}=tan(\phi)$$ $$\phi = tan^-1 (\frac{2.223244275}{-1.922075597})$$ $$\phi = -0.8579234358 rads$$ Note that it is not in the domain so: $$-0.8579234358 rads + 2\pi rads = 5.425261871 rads$$ $$\therefore \phi = 5.425261871 rads$$ So: The simplified combined waveform is $2.938909612sin(3t+5.425261871)$ . That is the simplified form I came up with. However, the simplified form does not match with the original equation when graphed: You can see clearly that it is out of phase with the original equation. What am I doing wrong? Is my approach correct? Please help!",['trigonometry']
2768073,Subsequence construction for lebesgue inequality,"$(A_{n})_{n}$ are $\lambda$ _lebesgue measurable sets in $[0,1]$ such that $\limsup\lambda(A_{n})=1$ . I have to prove that for every $a\in (0,1)$ there exists a subsequence $(A_{n_{k}})_{k}$ of $(A_{n})_{n}$ such that $\lambda(\cap_{k}A_{n_{k}})>a$ . Any idea on how to prove this ?? I found that we have to construct $(A_{n_{k}})_{k}$ such that $\lambda([0,1]\setminus A_{n_{k}})<(1-a)/2^{k}$ But how we construct such subsequence and where does $\lambda([0,1]\setminus A_{n_{k}})<(1-a)/2^{k}$ helps us in order to prove $\lambda(\cap_{k}A_{n_{k}})>a$ ?","['lebesgue-measure', 'measure-theory']"
2768081,Does there exist a measurable function with a specific property?,"Does there exist such a measurable function $f$ from $[0 ; 1]$ to $\mathbb{R}$ (under Lebesgue measure) such that for  $\forall x \in \mathbb{R}$ $\int_0^1 \frac{dt}{|f(t) - x|}$ is always finite?
(The integral in this question is a Lebesgue integral) I failed to construct any examples, but I have not found any way to prove that such functions do not exist either. Any help will be appreciated.","['measurable-functions', 'lebesgue-measure', 'integration', 'lebesgue-integral', 'measure-theory']"
2768088,Garden with mushrooms,"A farmer cultivates mushrooms in his garden. A greedy neighbor wants to pick some but the farmer is trying to block him. The garden has the form of a 8x6 grid. Rows 1 to 8 from the front to the back and columns A to F from left to right. The mushrooms are planted in the 8th row (6 mushrooms). The farmer is initially standing at the block E7, right in front of the mushrooms and can move at any of his direct surrounding 8 blocks (including those behind him, where the mushrooms are planted). 
The neighbor initially stands at block F1 and is trying to reach the mushrooms by walking at any of his directly surrounding blocks (including those situated diagonally in relation to his position). Once the neighbor reaches the farmer, he hits him and can then reach the mushrooms, but if the farmer reaches the neighbor, he hits him also, and he has to back out. The neighbor moves first and then they alternate turns. Will he manage to get at least one mushroom, or the farmer will block him? 
To summarize, the ""game"" ends in any of the 3 cases: The farmer reaches the neighbor (walks on his square). In this case, the neighbor has to leave and go home. The neighbor reaches the farmer, even once (walks on his square). Then the farmer has to admit he lost, and let him get the mushrooms! The neighbor reaches one (any) mushroom before the farmer manages to stop him. Describe some of the optimal moves for each of them, using the grid coordinates. I tried to set the neighbor ""chase"" the farmer by trying to be on the same column with him but can't find a general pattern. FYI I found this in an Ukrainian magazine at the Kiev airport - I hope I translated everything correctly!",['combinatorics']
2768097,Almost sure convergence of a certain sequence of random variables,"Let $(X_n)_{n\geq 1}$ be i.i.d. random variables with uniform distribution on the interval $(0,1)$. I need to prove that the following sequence of random variables $(Y_n)_n$ defined by: $$Y_n = \frac{X_1^2+\dots+X_n^2}{X_1+\dots+X_n}$$ converges almost surely, and then compute $$\lim_{n\to\infty} \mathbb{E}(Y_n)$$ It does not seem to be a very difficult problem, but I am stuck. Thanks a lot!","['law-of-large-numbers', 'probability-theory', 'convergence-divergence', 'sequences-and-series', 'random-variables']"
2768105,The group $\mathbb{Z}^n/A\mathbb{Z}^n$ is finite iff the determinant of A is nonzero,"Let $n\geq 1$ and $A$ be an $n\times n$ integral matrix with columns $c_1,\ldots, c_n\in\mathbb{Z}^n$. Write $A\mathbb{Z}^n$ as the set of all integral linear combinations of the columns of A, i.e., 
$$A\mathbb{Z}^n=\{x_1c_1+\cdots+x_nc_n: x_1, \ldots, x_n\in\mathbb{Z}\}. $$
The problem is to prove that the group $G=\mathbb{Z}^n/A\mathbb{Z}^n$ is a finite group if and only if $\det(A)\neq0$, and moreover that in the case $\det(A)\neq0$, the order of $G$ is precisely $|\det(A)|$. The case when $\det(A)$ is a unit ($\pm1$) is somewhat trivial. But how about other nonzero values for $\det(A)$? I tried to define a homomorphism  $f:\mathbb{Z}^n\to\mathbb{Z}^n, x\mapsto Ax$ for $x\in\mathbb{Z}^n$, and observed that $G$ is the quotient $\mathbb{Z}^n/\operatorname{im}(f)$. How can we proceed? Thanks.","['matrices', 'abstract-algebra', 'group-theory']"
2768119,Is Algebraic Number Theory still an active research field?,"I've took an introductory course on Algebraic Number Theory during my Master's, which I really enjoyed. Now that I'm beginning to think about my PhD area, I wonder if I shouldn't go for something in that direction. However, as in practically all courses I've taken, I was too busy trying to understand definitions and theorems, having little time left (or not enough knowledge) to understand the historical development or the research perspectives on the subject. Is Algebraic Number Theory still an active area of research? I ask this because almost everything I read or hear about number theory from recent years seems to involve analytic methods (harmonic analysis, probability, ergodic theory etc.), which are not really my cup of tea. Since I'm a more algebra-driven guy (meaning I'm instinctly attracted to things like Commutative Algebra, Algebraic Geometry, Galois Theory and, of course, Algebraic Number Theory), I wish there were still active lines of research in Number Theory using actual algebraic methods, at least for the most part. I know this question is rather vague, but that's how well I'm able to articulate it right now, so any advice, insights, reading suggestions etc. would be greatly appreciated.","['number-theory', 'algebraic-number-theory', 'soft-question', 'research']"
2768222,"Let $f\in L^2(0,\infty)$ and let $(Tf)(s)=\frac1s\int_0^sf(t)dt$. Find the adjoint, $T^*$.","Problem: Let $f\in L^2(0,\infty)$ and let $(Tf)(s)=\frac1s\int_0^sf(t)dt$. Find the adjoint, $T^*$. Attempt: I know that problems like these should be very simple, but oftentimes I find them very difficult, to my shame. I understand that the adjoint in this case is defined as being the $T^*:L^2(0,\infty)\to L^2(0,\infty)$ where, for all $f,g\in L^2(0,\infty)$, $$\langle Tf,g\rangle=\langle f,T^*g\rangle$$ I understand the method one usually employs; namely to start from the left hand side and via manipulation (in this case, of the integrals) to get the inner product of $f$ with something else. In this case though, I don't really understand what is going on with regards to the order of integration changing and how, exactly, the limits thereof change as well. I have been told it is to do with Fubini's theorem, but it's not something I have really grappled with, and had exposure to before. I have had a look at some examples like this one here involving the same inner product, but I am thrown more than usual by the $1/s$ factor. Could somebody use the above problem to elucidate what is going on, and how the machinations behind these manipulations really work?","['hilbert-spaces', 'lebesgue-measure', 'operator-theory', 'functional-analysis', 'integration']"
2768243,Proof verification: An asymptotic & geodesic curve is a straight line.,"I am trying to prove that a curve $C\subset S$ is both an asymptotic curve and a geodesic if and only if $C$ is a (segment of) a straight line. $\Rightarrow$ NTS: If $C$ is both asymptotic and a geodesic, then it is a straight line. By definition asymptotic curves have normal curvature of zero. Hence $k_n = 0$. The relationship of normal, geodesic, and space curvature of $C$ gives: $(k_n)^2 + (k_g)^2=k^2$. Hence $\mid k_g \mid = k.$ A curve is geodesic if and only if $k_g = 0$ at each point of the curve. So $k=0$. Since $k=\vert \alpha ''(x) \vert \equiv 0$, then by integration $\alpha(s) = cs + d$, so the curve is a (segment of) a straight line. $\Leftarrow$ NTS: If $C$ is a straight line, then it is both an asymptotic curve and a geodesic. If $C$ is a straight line, the curvature of $C$ is zero, $k=0$, but from the relation $(k_n)^2+(k_g)^2=k^2$, $(k_n)^2 \geq 0$, and $(k_g)^2 \geq 0$, so $k_n$ and $k_g$ must both be zero. $\therefore$ $C \subset S$ is asymptotic and geodesic curve if and only if $C$ is a (segment of) a straight line. Is this correct? Thanks [Edited]","['differential-geometry', 'curvature']"
2768252,pulling a pair of balls from a box with a simple twist,"I'm stuck on this question, and I don't know how to solve it. In a box there are $3$ balls, numbered 1, 2 and 3. We randomly pull $2$ balls out of it, and we write the lower number on the higher number, and then return them to the box.. so for instance if (2,3) were pulled, we return (2,2). We repeat the process until all of the balls in the box are marked 1. If we get the same number twice, we just put them back to the box without doing anything. a) If after the first pull, there is at least one ball with the number 2 on it, what are the odds that the process will end after only one additional ball pulling? b) What are the odds that the process will be over after exactly two pulls? My attempt: a) To end the task as needed, we need something like this: we pull (1,3), we return (1,1) - the ball with 2 is left in the box - then we pull it out along with 1, i.e (1,2) and we retrieve (1, 1) as needed. so the probability should be $\frac{1}{3} \cdot \frac{2}{3}$ 2) Because we are not limited to having just 2 inside after the first pull, we can repeat the process with pulling (1,2) returning (1,1), then pulling (1,3) and returning (1,1) as needed. Since it's the same process, it seems to be the same calculation times 2, i.e: $2 \cdot \frac{1}{3} \cdot \frac{2}{3}$ Is this calculation correct or should I use a different kind of calculation/ formula?","['probability', 'discrete-mathematics']"
2768257,Sheaf Theory for Complex Analysis,"I've recently been reading Complex Analysis in One Variable by Narasimhan and Nievergelt. I've done enough work in complex analysis prior that I find the majority of the text quite understandable and beautiful; however, I was pleasantly shocked when I began reading the section entitled ""The sheaf of germs of holomorphic functions"" . After re-reading through the section a number of times, I have found I can formally follow the argument, but lack any intuition for the definitions or the mechanics. Unfortunately, my passion for analysis has meant the majority of my studies have been directed away from Algebra, and so I've only taken an introductory level course to Group Theory and Ring Theory. Nevertheless, I strongly desire to become more familiar with sheaf theoretic techniques in complex analysis. I could of course simply wait until I have taken more courses in Algebra to become acquainted with it enough to grasp Category Theory at an intuitive level and then begin chipping away at a Sheaf Theory text. However, I am presently only in my first year of college, and I don't wish to be forced to wait a few years until Grad School to appreciate basic applications of Sheaf Theory. As such, I am wondering if there is a more optimized route to learn the very basic Sheaf Theory I might need to appreciate it's applications to Analysis, and in particular single variable Complex Analysis. I imagine I will not need a complete understanding of modern Sheaf Theory to merely understand its applications to my field. As such, I am wondering what the minimally required topics are that I should study in order to build up some basic intitution for the uses of Sheaf Theory in N&N's text. Edit: Per the suggestions below, I have checked out copies of Gunning's and Forster's texts on Riemann Surfaces. My initial reaction to both texts has been quite positive; in particular I have found Gunning's text fantastic in that it provides the definition of a sheaf as soon as possible. I look forward to reading through the texts as I find time! However, I remain completely open to other perspectives on how to best attack the necessary Sheaf theory, and so other answers are welcome!","['abstract-algebra', 'complex-analysis', 'sheaf-theory', 'analysis']"
2768263,Is $f(x)=x^2-4x$ injective and surjective? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question If $f: A\to \mathbb{R}$ be such that $f(x) = x^2 - 4x$, where $A = \{x ∈ \mathbb{R}: x \ge 2\}$. How do I determine if the following function is injective or surjective and has an inverse? Here's my attempt:
domain: $\mathrm{dom} (f) = [2,\infty)$, co-domain: $(-\infty,\infty) = \mathbb R$. Let $a, b \in  A$. Then
\begin{align}
f (a) = f(b) &\Rightarrow a^2 - 4a = b^2  - 4b \\
&\Rightarrow a^2 - b^2 - 4a + 4b = 0 \\
&\Rightarrow(a + b)(a - b) - 4(a - b) = 0 \\
&\Rightarrow(a - b)(b - 4) = 0 \\
&\Rightarrow a - b = 0 \text{ or }a + b -4 = 0 \\
&\Rightarrow a = b \text{ or }a + b = 4.
\end{align}
Therefore, f is injective.
Then I become stuck.","['elementary-set-theory', 'functions']"
2768278,Metric trace of third derivative,"Let $(M,\langle \cdot, \cdot\rangle)$ be a Riemannian manifold, and $\varphi: M\to \Bbb R$ be a smooth map. Denoting the gradient of $\varphi$ by $\nabla \varphi$ and the covariant Hessian by $\nabla^2\varphi$ (that is, $\nabla^2\varphi(X,Y) = \langle \nabla_X(\nabla\varphi), Y\rangle$), I would like to compute the metric trace $${\rm tr}_{\langle \cdot,\cdot\rangle}\big((X,Y)\mapsto \nabla^2\varphi(\nabla_X(\nabla\varphi), Y)\big).$$I'm a bit stumped. I tried to do it in coordinates using $({\rm d}x^i)^\sharp = g^{ij}\partial_j$ but I couldn't simplify anything. Help?","['tensors', 'riemannian-geometry', 'differential-geometry']"
2768289,Constructing the Monster,"I am trying to write ~12 page paper on the construction of the Monster group.
I have been thinking about this for a few weeks now, but every paper I read is a few levels ahead of my expertise with group theory, as I have only taken an introductory course to the subject (Abstract Algebra I).
What are the core concepts that must be understood to be able to go through the construction of the monster?","['abstract-algebra', 'group-theory']"
2768304,What is the one dimensional analog of the Gauss-Bonnet theorem and the Euler characteristic?,"The Gauss-Bonnet theorem has to do with surfaces. Its generalization has to do with $2n$ ($n$ being an integer) manifilolds. Is there an analog in one dimension with closed curves? If there exists one such analog, then what is the geometrical interpretation of the analog of the Euler characteristic?","['differential-forms', 'differential-geometry', 'differential-topology']"
2768369,"$ n $ different variances, same mean, what is the maximum-likelihood estimator of $ \mu $?","Observations $ X_1, X_2,\ldots,X_n$ are drawn from normal populations with the same mean $ \mu $ but with different variances $ \sigma_1^2, \sigma_2^2,\ldots, \sigma_n^2 $. Is it possible to estimate all the parameters? If we assume that the $ \sigma_i^2 $ are known, what is the maximum-likelihood estimator of $ \mu $? My attempt: The likelihood function is
$$ L(x_1,\ldots,x_n; \mu, \sigma_1,\ldots, \sigma_n) = \frac 1 {(2\pi)^{n/2}} \prod_{i=1}^n \dfrac 1 {\sigma_i} e^{-\sum_{i=1}^n \dfrac{(x_i-\mu)^2}{2\sigma_i^2} }$$ Then we take the natural logarithm. We derive with respect to $ \sigma_i$  and we equate these derivatives to zero. We obtain $$ -\frac 1 {\sigma_i} + \frac{(x_i-\mu)^2}{\sigma_i^3} = 0 $$ From here we get that $$ \widehat{\sigma_i} = X_i - \mu$$ Is this correct? Analogously for the other question but now we derive with respect to $ \mu $.","['maximum-likelihood', 'statistics', 'estimation']"
2768372,Factorising polynomials in to their irreducible factors over GF(2),"A skill I'm trying to learn/understand is how to do this manually. I've noticed as a predecessor to a lot of my discrete maths example questions we are asked to obtain the irreducible factorisation of things like $$x^{15}-1, x^{18}-1, x^{20}-1 \in\mathbb{F_2[x]}.$$ What approach should one take generally when trying to do something like this? I've tried practising with smaller ones which are easier to do but I can't really see a general technique. For $x^{18}-1=(x^9-1)^2=(x^3-1)^2(x^6+x^3+1)^2=(x-1)^2(x^2+x+1)^2(x^6+x^3+1)^2$
This one I mostly understand, aside from the $x^6$ factor, how could you know this was an irreducible polynomial in this field which out memorising them all? Or is that the technique.. Then, for $x^{15}-1$ I am told to assume that the primitive quartic polynomials in $\mathbb{F}_2[x]$ are $x^4+x+1$ and $x^4+x^3+1$. I can check on wolfram alpha that the factorisation looks like: 
$x^{15}-1=(x+1)(x^2+x+1)(x^4+x+1)(x^4+x^3+1)(x^4+x^3+x^2+x+1)$ Now my hint suggested there are only $2$ quartic polynomials but this makes use of $3$...unless the $3$rd one is not primitive? And also, how could one find this factorisation easily by hand? The one above I could attempt trial and error to find the irreducible polynomial of degree $6$ perhaps but for this one that seems a bit strange. Any advice is greatly appreciated.","['irreducible-polynomials', 'finite-fields', 'discrete-mathematics']"
2768384,Solving the Differential Equation $u'=u^{1-k}$ by separation of variables.,"I have the differential equation $u'=u^{1-k}$, and am supposed to solve it by separation of variables. As an attempted solution, I have $u^{k-1}du=dt$, and therefore $\frac{u^k}{k}=t+c$, and therefore $u=(kt)^\frac{1}{k}+c$. With $u(0)=1$, this is $u=(kt)^\frac{1}{k}+1$. Is this the correct solution, and also, for what values of $k<0$ does $u$ ""blow up"".",['ordinary-differential-equations']
2768402,Make sense of taking 'differential' on both sides of a matrix equation,"This is related to a question I posted. Here is the statement for the question In control theory, the discrete Lyapunov equation is defined as
    \begin{align*}
A^T X A + Q  = X,
\end{align*} 
    where $A \in \mathcal{M}(n \times n; \mathbb R)$ and $Q \in \mathbb {S}_{++}$ ( positive definite matrices). There is a theorem stating if the spectral radius of $A$ satisfies $\rho(A) < 1$ and for fixed $Q > 0$, there exists a unique $X \in \mathbb {S}_{++}$ which solves above equation.
    Let $D = \{A \in \mathcal{M}(n \times n; \mathbb R): \rho(A) < 1\}$ and fix $Q$. Suppose we define some scalar valued function $f$ over $X$ which are solutions of Lyapunov equation over $D$. To make it more concrete, let us define this scalar valued function to be $f(X) = \text{tr}(X)$. This function can be also viewed as a function $g$ over $D$, i.e., it is a composition
    \begin{align*}
g \colon A \xrightarrow{h} X \xrightarrow{f} \text{tr}(X).
\end{align*}
     Now I would like to differentiate $g$ with respect to $A$. There are some very good answers to this question. The answers posted by @greg and @lynn are very interesting. But in the answers, they kind of freely take 'differential' of both sides and applying product rule $$dA^T X A + A^T d X A + A^T X dA = dX.$$ I am a little uncomfortable with using the symbols $dX, dA$ before assigning some mathematical meaning. I know we can intuitively think them as infinitesimal change in the entries. But I would like to know some rigorous way to understand it.
 The only place I know they have a meaning is in differential geometry, i.e., differential forms. In this situation, how do we make sense of this step?","['matrix-equations', 'differential', 'differential-forms', 'differential-geometry', 'analysis']"
2768437,First isomorphism theorem for Banach Spaces,"I am dealing with the following exercise: Let $E$, $F$ be Banach Spaces and $T:E\to F$ a continuous and surjective linear function. Define $\widehat{T}:E/\ker T\to F$ as $\widehat{T}([x])=T(x)$. Prove that $\widehat{T}$ is an isomorphism such that $\left \|T\right \|=\left \|\widehat{T}\right \|$. First of all, since $T$ is continuous then $\ker T$ is closed, so $E/\ker T$ is a Banach space (because $E$ is a Banach Space). Take $Q:E\to E/\ker T$ the projection. Therefore $\widehat{T}\circ Q=T$, so $\widehat{T}$ is a continuous linear function which is bijective. By the open mapping theorem, it is also an homeomorphism. Moreover, $\left \|T\right \|=\left \|\widehat{T}\circ Q\right \|\leq \left \|\widehat{T}\right \|\left \|Q\right \|\leq\left \|\widehat{T}\right \|$ since $\left \|Q\right \|\leq 1$. The only thing I need to prove in order to finish the exercise is the other inequality: $\left \|\widehat{T}\right \|\leq \left \|T\right \|$. I do not know how to achieve it. How would you solve this last step?","['functional-analysis', 'normed-spaces', 'banach-spaces', 'continuity']"
2768522,Number of terms in a Polynomial Expansion,"For a binomial $(a + b)^n$, the number of terms is n + 1. For a trinomial $(a + b + c)^n$, the number of terms is $\frac{(n+1)(n+2)}{(2)}$. For a multinomial $(a + b + c +d)^n$, the number of terms is $\frac{(n+1)(n+2)(n+3)}{(6)}$. I'm guessing that for $(a + b + c + d + e)^n$, the number of terms formula would include $(n+1)(n+2)(n+3)(n+4)$ on the numerator but I don't know what should be its denominator. Question: What is the number of terms for $(a + b + c + d + e)^n$? Do we have a general formula for the number of terms of a polynomial expansion? What if the given is $(a^2 + a + b)^n$, can I still use the formula $\frac{(n+1)(n+2)}{(2)}$.when 2 terms in the expansion has the same variable? What if the given is $(a + b + Constant)^n$, would the constant affect the number of terms?",['algebra-precalculus']
2768528,From concavity to second derivative,"Let $f(x)$ be continuous and differentiable on $\mathbb{R}$. I want to show that if $f(x)$ is concave, then $f''(x)\le0$ $\forall\space x\in\mathbb{R}$ Proof: Let $x,y$ be fixed in $\mathbb{R}$ such that $y>x$ Without loss of generality, since $f$ is concave, then $f'(x)\ge\cfrac{f(y)-f(x)}{y-x}$ by the calculus criterion. By the mean value theorem, $\exists\space c\in[x,y]$ such that $f'(c)=\cfrac{f(y)-f(x)}{y-x}$ So I now have: $f'(x)\ge f'(c)$ Since $x$ was arbitrarily chosen, then we have shown $a\ge b\implies f'(b)\ge f'(a)$ Since $y>x$, then we have $f'(x)\ge f'(y)$ and this is true for all $x,y\in\mathbb{R}$ So $f''(x)\le 0$ Is my approach correct?","['derivatives', 'calculus']"
2768574,Decide whether or not there exists $f(f(x))=5x-\lfloor 5x\rfloor$,"Decide whether or not there exists  $f;[0,1)\to [0,1)$ such 
  $$f(f(x))=5x-\lfloor 5x\rfloor=\{5x\}$$ Today I suddenly thought of an interesting question, but I have not found any function of symbolic conditions so far.","['functions', 'functional-equations']"
2768626,How to solve the integration [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How to find $$ \frac{\int_0^{\pi}x^3\log(\sin x)\,dx}{\int_0^{\pi} x^2 \log(\sqrt{2} \sin x)\,dx} $$ I couldn’t resolve it by using integration by parts.",['integration']
2768635,About multiplication operators on fractional Sobolev space,"Let $\Gamma$ be a regular boundary of a $C^{k,1}$ domain $\Omega$ and  $H^s(\Gamma)$, $s\in(0,1)$, denote the fractional Sobolev space on $\Gamma$. Suppose I define a multiplication operator $M_\phi:H^s(\Gamma)\to H^s(\Gamma)$ where $M_\phi v=\phi v$. What should be the minimal regularity of $v$ for the map to be continuous? I am thinking that $v$ being Lipschitz (i.e., $v \in C^{0,1}(\Gamma)$) is enough for $M_\phi$ to be continuous. Can someone please give me a reference or study that deals with this kind of problem. Thanks! Edit I am only interested on the case when the map $H^\frac12(\Gamma) \to H^\frac12(\Gamma)$ is continuous. More precisely, I want to know whether the following statement is true. Let $\Omega \subset \mathbb{R}^2$ be a bounded Lipschitz domain and $\Gamma$ be a non-empty subset of $\Omega$. Then, the map $v \mapsto \phi v$ is continuous in $H^\frac12(\Gamma)$ for any $v \in H^\frac12(\Gamma)$ and $\phi \in C^{0,1}(\Gamma)$. I tried to argue the validity of the above statement as follows. By McShane-Whitney extension theorem, we know that we can find a $\tilde{\phi} \in C^{0,1}(\bar{\Omega})$ such that $\tilde{\phi}|_{\Gamma} = \phi$. Then, using [Grisvard, Elliptic Problems in Nonsmooth Domains, Theorem 1.4.1.1, p. 21] and [McLean, Strongly Elliptic Systems and Boundary Integral Equations, Theorem 3.37, p. 102], we have that $v \mapsto \phi v$ a continuous linear map in $H^\frac12(\Gamma)$. Can someone confirm if my argument is correct?","['functional-analysis', 'fractional-sobolev-spaces']"
2768637,Gaussian integral over a wedge of the complex plane,"I'm trying to evaluate, if it is possible, a Gaussian integral over a wedge of the complex plane $$
I = \int_W d^2z \,e^{-|z|^2 + z^*a + za^*}, 
$$
($d^2z = \frac{dz\,dz^*}{2} = dx\,dy = r\,dr\,d\phi$)
where $W=\{z\mid -\theta \le \arg(z) \le \theta\}$, with $\theta < \pi/2$. In other words, the integral can also be written $$
I = \int_{-\theta}^\theta d\phi \int_0^\infty dr \,r e^{-r^2 + e^{-i\phi}r a + e^{i\phi}ra^*}. 
$$ In the case where $W$ is instead the entire complex plane, the answer is well known and equal to $I=\pi e^{|a|^2}$. Attempt at solution I made an attempt using Green's theorem to turn $I$ into a contour integral, and I was hoping to continue with Cauchy's integral formula from there, but got stuck due to a non-analytic function in the contour integral. I'm not sure if this is a good path forward, but I'll show you what I did. My complex integration knowledge is rusty so be aware of mistakes. First, assume that we have a complex function $f(z)$ that can be written $f(z) = f(z,z^*) = \partial_{z^*} F(z,z^*)$. Then Green's theorem gives $$
\int_W d^2 z\, f(z) = \int_W \frac{dz \, dz^*}{2} \partial_z^* F(z,z^*) = \int_W dx\,dy\, (\partial_x + i\partial_y)F = \frac{1}{2} \int_{\partial W} F \,dy - iF\,dx \\ = -\frac{i}{2} \int_{\partial W} F(z)\,dz,
$$
where the last integral is a counter-clockwise contour integral over the boundary $\partial W$ of $W$. Here I used that $\partial_z^* = (\partial_x + i\partial_y)/2$ and Green's theorem $\int_S dx\,dy\,(\partial_x L + \partial_y M) = \int_{\partial S} M \,dx - L \,dy$. Returning to the integral $I$ above we have $f(z) = e^{-|z|^2 + z^*a + za^*} = \partial_{z^*} F(z,z^*)$ with $$
F(z,z^*) = \frac{e^{-|z|^2 + z^*a + za^*}}{a-z} = \frac{f(z)}{a-z}.
$$ Now, it is tempting at this stage to use Cauchy's integral formula $\int_{\partial W} dz \,\frac{g(z)}{z-a} = 2\pi i g(a)$ for holomorphic (i.e. analytic) $g(z)$. However this does not work because $f(z)$ above is not holomorphic due to the $|z|^2$ and $z^*$ terms in the exponent. Writing out the contour integral over the wedge $\partial W$ explicitly we have $$
\int_{\partial W} F(z) \, dz
= \int_{\partial W} dz \,\frac{e^{-|z|^2 + z^*a + za^*}}{a-z} \\
= \int_{0}^\infty dr \,\frac{e^{-r^2 + r \left(e^{-i\theta} a + e^{i\theta} a^*\right)}}{a-e^{-i\theta}r}
+ \int_\infty^0 dr\, \frac{e^{-r^2 + r \left(e^{i\theta} a + e^{-i\theta} a^*\right)}}{a-e^{i\theta}r}
+ 0
$$
Here I have divided the contour into three parts. One where $\arg(z) = -\theta$, one where $\arg(z) = \theta$, and the ""arc"" out at infinity which vanishes due to the $-|z|^2$ term in the exponent. I wasn't able to make any further progress on the integrals over $r$ above. Perhaps there is a way to evaluate them directly, or perhaps one can come up with an analytic function $g(z)$ that is equal to $f(z)$ on the contour and use Cauchy's integral formula?","['gaussian-integral', 'greens-theorem', 'complex-integration', 'cauchy-integral-formula', 'complex-analysis']"
2768645,Proper direct image and extension by zero,"I was reading about the proper direct image functor, which can be defined in a general setting as follows. Let $X$ and $Y$ be topological spaces and let $f:X\rightarrow Y$ be a continuous map. Let $\mathcal{F}$ be a sheaf of abelian groups on $X$. For a section $\sigma$ of $\mathcal{F}$ the support of $\sigma$ is defined to be the closure of $\{x\mid \sigma_x\neq 0\}$. The proper direct image $f_!\mathcal{F}$ is then defined to be the sheaf on $Y$ with
$$
f_!\mathcal{F}(V):=\left\{\sigma\in \mathcal{F}\left(f^{-1}(V)\right) \ \middle| \ \text{$f|_{\mathrm{supp}(\sigma)}: \mathrm{supp}(\sigma)\rightarrow V$ is proper} \right\}.
$$ Now consider the case where the map $f$ is an open embedding $U\rightarrow X$ and $\mathcal{F}$ is a sheaf of abelian groups on $U$. I have seen in many different texts stating the fact that in this case $f_!$ coincide with what is called ""extension by zero"", which is equivalent to saying that 
$$
\left(f_!\mathcal{F}\right)_x=\left\{\begin{array}{ll}
\mathcal{F}_x & \text{if $x\in U$},\\
0 & \text{otherwise}.
\end{array}\right.
$$
I haven't been able to find any proof of such statement. While the first case ($x\in U$) is pretty obvious, I have not been able to prove the second case ($x\notin U$). Just for the reference, while I was doing a search on the internet, I also came across this post on mathstackexchange from 2 years ago on the exact same topic, which has not been answered: Prove extension by zero is a special case of lower shriek? Here are my questions: Is the statement correctly stated? Did I miss any topological conditions (such as locally compact or Hausdorff) on the spaces $X$ that would otherwise make the statement correct? How to prove this statement? I feel like if the statement is correct, then one should be able to prove it just using point-set topology since we are stating all definitions in topological terms.","['general-topology', 'sheaf-theory']"
2768679,Does $\sum\limits_{n=1}^{\infty}\frac{\cos^{2}(n+1)}{n}$ converge?,"The original question, given to my Calculus II recitation class, was: Determine if the series $$\sum\limits_{n=1}^{\infty}\frac{(-1)^{n}\cos^{2}(n+1)}{n}$$ converges absolutely, conditionally, or diverges. I can kind of see a comparison with the alternating harmonic series here, but making that formal is tough. With the absolute series $\sum\limits_{n=1}^{\infty} \frac{\cos^{2}(n+1)}{n}$ , I'm not sure what test to apply. What I've Tried: No tests (in the classical Calc II curriculum) work. I've tried expanding $\cos^{2}(n+1)$ into a power series within the series in question, but I'm not really sure where to go from there. My intuition tells me this series will diverge, since it seems ""close"" to the harmonic series; but $\cos(x)$ is less than $1$ infinitely often.","['real-analysis', 'trigonometry', 'sequences-and-series', 'calculus']"
2768704,Is there an algorithm to solve all soluble group word problems?,"What I mean is, is there an algorithm that given any finitely presented group with soluble word problem can solve the word problem on that group?","['group-theory', 'group-presentation']"
2768762,Does weak convergence in a Sobolev space implies uniform convergence?,"Let $\Omega$ be a nice open, bounded domain in $\mathbb{R}^n$. (e.g suppose $\bar \Omega$ is a smooth manifold with boundary). Let $f_n \in W^{1,p}(\Omega),p>n$ and suppose that $f_n \rightharpoonup f$ in $W^{1,p}(\Omega)$. Question: Is it true that $f_n$ converges uniformly to $f$? (Since $p>n$ the $f_n$ are continuous, so this is well-defined). I know two things: If $f_n$ converges uniformly to some function $g$, then $g=f$ . There is always a subsequence of $f_n $ which converges uniformly to $f$. Indeed, any weakly convergent sequence is bounded in $W^{1,p}$, hence by the Rellich-Kondrachov theorem it has a subsequence which converges in $C(\Omega)$. By point $(1)$ the limit must be $f$. So, the question is can we can conclude directly that the original sequence was uniformly convergent, without passing to a subsequence. (This is the case when we have strong Sobolev convergence, by the way).","['real-analysis', 'uniform-convergence', 'functional-analysis', 'weak-convergence', 'sobolev-spaces']"
2768775,Cant understand how chain rule works,"Let $w(x,y)$ be a function of class $C^2$ in the variables $x$ and $y$, and let $x=u+v$, $y=u-v$, show that: \begin{align} \frac{\partial^2 w}{\partial u \partial v} = \frac{\partial^2 f}{\partial x^2} -  \frac{\partial^2 f}{\partial y^2}\end{align} My attempt: What we are looking for is $\frac{\partial}{\partial u}(\frac{\partial w}{\partial v})$, so, by the chain rule: $$\frac{\partial w}{\partial v} = \frac{\partial f}{\partial x}\frac{\partial x}{\partial v} + \frac{\partial f}{\partial y}\frac{\partial y}{\partial v} = \frac{\partial f}{\partial x} - \frac{\partial f}{\partial y}$$ and similarly for $\frac{\partial w}{\partial u}$. Now, what we need is: $$\frac{\partial}{\partial u}(\frac{\partial w}{\partial v}) = \frac{\partial}{\partial u}(\frac{\partial f}{\partial x} - \frac{\partial f}{\partial y}) = \frac{\partial}{\partial u}(\frac{\partial f}{\partial x}) - \frac{\partial}{\partial u}(\frac{\partial f}{\partial y})$$ But I can’t seem to grasp what $\frac{\partial}{\partial u}(\frac{\partial f}{\partial x})$ is or how am I supposed to apply the chain rule again in this case.","['multivariable-calculus', 'chain-rule']"
2768782,A limit involving $\cos x$ and $x^2$,The question is finding the value of $L = \lim_{x \to 0}\frac{1 - \cos x \cos 2x \cos 3x}{x^2}$ if it exists . I've found the answer using taylor's formula but I'm looking for other solutions maybe using trigonometric identities .,"['trigonometry', 'calculus', 'limits']"
2768817,How to correctly Min-Cut this network?,"I'm trying to understand the right procedure for making cuts in max-flow min-cut problems. In this network here https://i.sstatic.net/SornO.png with the dashed cut through the middle, when working out the capacity of this cut, you would not include the capacity 9 of the $v_3$ to $v_2$ edge, because it is going backwards towards S (though, if you would count the -4 if you were working out how much actual flow you were interrupting). This I understand. But, I was told that if you were to make a cut say across edges $(v_3,t), (v_4,v_3), (v_2, v_4)$ you in fact don't count the capacity - and I think not even the flow, though please correct me if I'm wrong - of edge $(v_4, v_3)$ - why? How am I supposed to know which edges that I cut across to exclude from the calculations? Is it because, if I were to cut all 3 of those edges, because all the edges supplying $v_4$ have been cut (namely $(v_2,v_4)$ ) then all edges leaving v4 are now defacto 'empty'? If I'm right, then if I were to make a cut along $(s, v_2), (v_2,v_1)$ and $(v_1,v_3)$ then I wouldn't count $(v_2,v_1)$, since all edges supplying $v_2$ are already, so any capacity potentially leaving $v_2$ is already accounted for with another cut? Is this right - if not, what's the understanding behind this/procedure to follow? Thanks very much, indeed! Edit for future readers: it was the insightful comments supporting the accepted answer that brought it together for me, so check those out for the full explanation.","['network-flow', 'optimization', 'discrete-mathematics']"
2768840,Square Roots of a Matrix: Diagonalisable Solutions.,"I am trying to solve the following problem, Find all diagonalisable matrices $B$ such that $$B^2 = \left(\begin{matrix}
    3    & 1 \\
    -2       & 0 
\end{matrix}\right)$$ I diagonalised the matrix on the RHS, so we can write $$B^2 = \left(\begin{matrix}
    1    & 1 \\
    -1     & -2 
\end{matrix}\right) \left(\begin{matrix}
    2    & 0 \\
    0       & 1 
\end{matrix}\right) \left(\begin{matrix}
    2    & 1 \\
    -1       & 1 
\end{matrix}\right) $$ We know $B$ is diagonalisable, so we can write $$P_1 D_1^2 P_1^{-1} = \left(\begin{matrix}
    1    & 1 \\
    -1     & -2 
\end{matrix}\right) \left(\begin{matrix}
    2    & 0 \\
    0       & 1 
\end{matrix}\right) \left(\begin{matrix}
    2    & 1 \\
    -1       & 1 
\end{matrix}\right) $$ So, I found the following four solutions, all involving $P_1 = P$, with $$
D_1 = \left(\begin{matrix}
    \pm \sqrt{2}    & 0 \\
    0       & \pm 1 
\end{matrix}\right)$$ My question is, are there any more solutions? How can we be sure that there are/aren't more solutions? I think that if matrix diagonalisation is unique, then these should be the only solutions. Is this a valid idea? Edit: I found out that diagonalisation is unique up to permutations of the order of eigenvalues and eigenvectors. This implies switching the columns in $P_1$ and in $D_1$ are also valid solutions, but when $B$ is expanded, the same solutions arise as presented above.","['matrices', 'diagonalization', 'linear-algebra']"
2768877,estimation of the rest of Taylor expansion for holomorphic function,"let $f$ be a holomorphic function on $D=\mathbb{D}(0,1)$ Let $f(z)=\sum \frac{f^{(n)}(0)}{n!}z^n$ be its Taylor expansion. If I use the Taylor McLaurin inequality: $||f(z) - f(0) +f'(0)z|| \le Mz^2/2 $ where $M=Sup ||f''(z')||$ for $z' \in D(0,z)$? Is it still valid for holomorphic function like in real analysis? Thank you for your help.","['complex-analysis', 'taylor-expansion']"
2768904,Solve differential equation $(1+x^2) \frac{dy}{dx} - 2xy = x$,"Solve differential equation $$(1+x^2) \frac{dy}{dx} - 2xy = x$$ I simplified it to $$\frac{1}{1+2y} dy = \frac{x}{1+x^2} dx$$ $$ \int \frac{1}{1+2y} dy =\int \frac{x}{1+x^2} dx $$ $$\frac{1}{2} \int \frac{2}{1+2y} dy = \frac{1}{2} \int \frac{2x}{1+x^2} dx$$ $$\frac{1}{2} \ln | 1 + 2y | = \frac{1}{2} \ln | 1+x^2 | + C $$ From here, I got stuck. I have to remove y from here to solve it. The answer in the textbook gave $ y= (k(1+x^2) - 1)/{2}$ I believe $k$ is the integration constant. How do I remove the $\ln$ from both sides?","['logarithms', 'ordinary-differential-equations', 'calculus']"
2768912,Solve $\operatorname{cotan}(z) = 2 + i$,"As the title says, I have to solve: $\operatorname{cotan}(z) = 2 + i$ I have gotten this far: $$\tan(z) = \frac{1}{2+i} = \frac{2}{5} - \frac{1}{5}i$$ I thought, maybe writing $z=x+iy$ would work. I found the following online (via complex exponential):
$$\tan(x+iy) = \frac{\sin(2x)+i\sinh(2y)}{\cosh(2y)+\cos(2x)}.$$ But equating the real and imaginary parts does not really give me something I can work with (or is it just rough work?).
Any hints or tips would be appreciated!","['trigonometry', 'complex-numbers']"
2768930,$f(a) = 0 \implies (x-a) \mid f(x)$? (polynomial zeros imply factors),"Hopefully this is a foolish question with a simple answer. I've seen it said that, for polynomial $f(x)$ $$
f(a)=0 \iff (x-a) \mid f(x)
$$ I can see the implication from factor to zero: $(x-a) \mid f(x) \implies f(a)=0$, because anything multiplied by zero is zero, and if $x=a$, then $(x-a) = 0$. But I'm not sure of the converse: $f(a) = 0 \implies (x-a) \mid f(x)$. If $f(a)=0$, is the only way it can be zero is if it includes a factor $(x-a)$? How can we be sure there isn't some other circumstance that could make it zero? I guess I'm looking for a proof. Hopefully it is a foolish question and simple answer!","['algebra-precalculus', 'polynomials']"
2768988,Finding area of related triangle and circle,"Let's say $AM$ and $AN$ are tangent lines to a circle centered at $O$. $L$ is a point on arc $MN$. Line $ML$ and $NL$ intersect with the line passing $A$ parallel to $MN$, at $P$ and $Q$. If $\angle POQ=45°$, prove that the area of circle $O$ is $2\pi$ times the area of $\triangle OPQ$. I have discovered that points $ALMQ$ are concyclic, as well as points $ALNP$, but I cannot connect them with the asked area. I believe the problem can be solved using power of a point.","['trigonometry', 'geometry']"
2768994,Differentiable at a point with positive derivative implies increasing in neighborhood of point?,"Let $\,f: \mathbb{R} \rightarrow\mathbb{R}$ be some function st $f(0)=0$ and $f'(0) > 0$. Is it the case that $f$ must be increasing in some neightborhood of zero? If $f$ is differentiable in some neighborhood of $0$ then the answer is trivial with the MVT, however all we have is differentiability at a point. I don't think the premise holds, take for example $f(x) = \begin{cases} \sin(x) & \text{, $x\in\mathbb{Q}$} \\ x & \text{, $x \notin \mathbb{Q}$} \end{cases}
$ The function seems to be differentiable near $0$ with derivative $1$ but is neither increasing nor decreasing near $0$. Is this correct? Would you have anymore counterexamples?","['derivatives', 'analysis']"
2769014,"Showing a function is in Holder space for some $a \in (0,1] $","Hi Im stuck on this exercise :  for which $a \in (0,1]$ is $f(x)=x^{2}\sin(\frac{1}{x^{3}})$  in $C^{a}((0,1])$ This is my attempt so far : $|f(x)| \leq x^{2} $ $|f'(x)| = 2x\sin(1/x^{3})-\frac{3}{x^{2}}\cos(1/x^{3}) \leq 2x+ \frac{3}{x^{2}} $ Then for $ 0<y<x \leq 1$ we have $|f(x)-f(y)| \leq x^{2} +y^{2} \leq 2x^{2}$ I would like now to get this in terms of $|x-y|$ and then use the mean value theorem to find $a$ for which $f(x)$ is in $C^{a}((0,1])$.","['functional-analysis', 'functional-inequalities', 'holder-spaces']"
2769042,Is this function $f$ continous?,"Let $f:\mathbb{R}^2\to\mathbb R$ with 
$$
f(x,y)=\begin{cases}\frac{x^2}{||(x,y)||}&\text{for }(x,y)\neq(0,0)\\ 0&\text{for }(x,y)=(0,0)\end{cases}
$$
The norm is not further specified. As every norm is continuous and $||(x,y)||=0$ iff $(x,y)=(0,0)$, we have that $f$ is continuous for every $(x,y)\neq (0,0)$(as $x^2$ is obviously continuous). (0,0) gives me more troubles as I don't know how to handle the unspecified norm. I know that all norms over $\mathbb R^2$ are equivalent, so there may be a way to convert this problem into a version using the classical Euclidean norm.","['continuity', 'real-analysis', 'functions']"
2769102,Limit of divided differences.,"I'm trying to show that the limit of Newton's interpolation formula as $x_i\to x_0$ ( $i=1,\ldots,n$ ) gives the Taylor's formula (knowing that $f\in \mathcal{C}^{n+1}[x_0-\delta,x_0+\delta]$ ) $$T(x)=f(x_0)+f'(x_0)(x-x_0)+\ldots+\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n+\frac{f^{(n+1)}(\xi)}{(n+1)!}(x-x_0)^{n+1}$$ The Newton's interpolation formula is $$P_n(x)=f(x_0)+f(x_0,x_1)(x-x_0)+\ldots+f(x_0,\ldots,x_n)(x-x_0)\ldots (x-x_{n-1})$$ So basically I must show that $$\lim_{(x_1,\ldots,x_n)\to(x_0,\ldots,x_0)}P_n(x)=T(x)$$ $f(x_0,\ldots,x_k)$ is defined as $$f(x_0,\ldots,x_k)=\frac{f(x_1,\ldots,x_k)-f(x_0,\ldots,x_{k-1})}{x_k-x_0}$$ From that definition it's easy to show that $$\lim_{(x_1,\ldots,x_n)\to(x_0,\ldots,x_0)}f(x_0,x_1)=\lim_{(x_1,\ldots,x_n)\to(x_0,\ldots,x_0)}\frac{f(x_1)-f(x_0)}{x_1-x_0}\overset{def}{=}f'(x_0)$$ But I get stuck when I have to find the limit of $f(x_0,x_1,x_2)$ . $$\lim_{(x_1,\ldots,x_n)\to(x_0,\ldots,x_0)}f(x_0,x_1,x_2)=\lim_{(x_1,\ldots,x_n)\to(x_0,\ldots,x_0)}\frac{f(x_1,x_2)-f(x_0,x_1)}{x_2-x_0}=???=\frac{1}{2}f''(x_0)$$ So my question is what should I do at $(???)$ ? I'm guessing that if I get this step figured out, finding the limit of $f(x_0,\ldots,x_{n-1})$ is analogous?","['numerical-methods', 'real-analysis', 'analysis', 'interpolation']"
2769147,Stirling Numbers $ \sum_{j= m}^{n-r} \binom{n}j {j \brace m} {n-j\brace r} = \binom{m} {m+r} {n\brace m+r} $ Combinatorical Proof or Algebraic,"$$\sum_{j= m}^{n-r} \binom{j}n {j \brace m} {n-j\brace r} = \binom{m} {m+r} {n\brace m+r}$$ I am trying to proof some identies from concrete mathmatics page 265. But i cant get nowhere. No clues where to start, I have found a proof involving Euler's Formula for Stirling Number. The Books gives them: Like here there are not event a hint how to show it. 
update: 
Well there is a clue in other book: both sides counting pair $(P_1,P_2)$ with $P_1 (k+r)$ partitions of $\{1,\ldots,n\}$ $P_2$ subfamily of $k$-blocks of $P_1,\ldots$ what ever this means","['stirling-numbers', 'combinatorics']"
2769166,Which convex functions are characterized as the supremum of linear functions?,A convex function $f$ can be represented as the supremum of all the affine functions that are dominated by $f$. Is there a simple characterization of those convex functions $g$ that can be represented as the supremum of all the linear functions that are dominated by $g$?,"['functional-analysis', 'convex-analysis']"
2769169,"Brouwer Fixed Point, Jordan Curve, Hairy Ball and Borsuk-Ulam theorems - Characterization of topology of Euclidean spaces","At wikipedia article about Brouwer fixed-point theorem , in the second paragraph, one can read the following: In its original field, this result is one of the key theorems characterizing the topology of Euclidean spaces, along with the Jordan curve theorem, the hairy ball theorem and the Borsuk–Ulam theorem. My question is: in what sense does these four theorems characterize the Euclidean space? Is there a theorem that says: ""If a space $X$ fulfils the criteria of those four theorems, then $X\simeq A\subseteq \mathbb{R}^n$ "" or something along the lines? Wikipedia has a citation at that point, namely ""See page 15 of: D. Leborgne Calcul différentiel et géométrie"". Sadly, I don't speak French. An English source or a translation would be apprieciated.","['algebraic-topology', 'general-topology']"
2769238,Proof of uncountability of irrationals without using completeness of real numbers,"I am studying countable sets and every proof of uncountability of real numbers uses completeness property? I know completeness is required to define irrtionals and real numbers, but if one considers irrational numbers or assigning a Dedekind cut of rational numbers to each irrational number or calling irrational numbers as gaps between rational numbers, can it be proved that those gaps are uncountable? Using nested interval theorem or decimal representation and other such proofs use completeness inherently. It is my understanding that completeness talks about ordering of elements, and countability is about cardinality of set","['real-analysis', 'elementary-set-theory']"
2769297,$f(x+1)=f(x)$ almost everywhere,"Let $f:\mathbb{R}\to\mathbb{C}$ be a function such that $f(x+1)=f(x)$ almost everywhere. I want to prove that exists a function $F$ such that $F(x+1)=F(x)$ always holds and $F(x)=f(x)$ almost everywhere. I think the intuition here is simple: let $x_0$ be a real number, if every $x\in x_0\mathbb{Z}$ satisfies $f(x+1)=f(x)$, then we define $F(x)=f(x)$. If there are a couple exceptions, we fix them and keep going for every $x_0\in \mathbb{R}$. However I am failling to formalize this. Let $A=\{x\in\mathbb{R} : f(x+1)\neq f(x)\}$. Since $\mathbb{R}\setminus A$ is dense, for every $x\in\mathbb{R}$ there is a sequence in $\mathbb{R}\setminus A$ that converges to $x$. Then maybe we could define $F(x)$ as
$$\lim_{n\to\infty}f(x_n).$$ I am lost.","['real-analysis', 'lebesgue-measure']"
2769298,"Compute the PDF of $X$ if $(X,Y)$ is uniformly distributed over the unit disk","Let $X,Y$ be random variables and $(X,Y)$ is uniformly distributed
  over the unit disk. Find the density function $f_X$. Well, it is given that $f(x,y) = \frac{1}{\pi}$ if $(x,y) \in S^1$ and $0$ elsewhere. Hence, $$f_X(x) = \int_{-\infty}^{+\infty}f(x,y)dy = \int_{-1}^1 \pi^{-1}dy  = 2 \pi^{-1}$$ for $x \in [-1,1]$ and $0$ elsewhere. But, this seems wrong, as it isn't a density function. Where is my mistake?","['density-function', 'probability-theory', 'probability-distributions', 'marginal-distribution', 'uniform-distribution']"
2769357,"Exam with $12$ yes/no questions (half yes, half no) and $8$ correct needed to pass, is it better to answer randomly or answer exactly 6 times yes?","In an exam with $12$ yes/no questions with $8$ correct needed to pass, is it better to answer randomly or answer exactly $6$ times yes and 6 times no, given that the answer 'yes' is correct for exactly $6$ questions? I have calculated the probability of passing by guessing randomly and it is $$\sum_{k=8}^{12} {{12}\choose{k}}0.5^k0.5^{n-k}=0.194$$ Now given that the answer 'yes' is right exactly $6$ times, is it better to guess 'yes' and 'no' $6$ times each? My idea is that it can be modelled by drawing balls without replacement. The balls we draw are the correct answers to the questions. Looking at the first question, we still know that there are $6$ yes and no's that are correct. The chance that a yes is right is $\frac{6}{12}$ and the chance that a no is right is also $\frac{6}{12}$ . Of course the probability in the next question depends on what the first right answer was. If yes was right, yes will be right with a probability of $5/11$ and a no is right with the chance $6/11$ .  If no was right, the probabilities would change places. Now that we have to make the choice $12$ times and make the distinction which one was right, we get $2^{12}$ paths total. We cannot know what the correct answers to the previous questions were. So we are drawing $12$ balls at once, but from what urn? It cannot contain $24$ balls with $12$ yes and $12$ no's. Is this model even correct? Is there a more elegant way to approach that? I am asking for hints, not solutions, as I'm feeling stuck. Thank you. Edit : After giving @David K's answer more thought, I noticed that the question can be described by the hypergeometric distribution , which yields the desired result.","['combinatorics', 'probability']"
2769361,Prove that $\tan^{-1}(1/n)+\tan^{-1}(2/n)+\cdots+\tan^{-1}(n/n)$ increases as $n$ increases,"Let 
  $$f(n)=\tan^{-1}\left(\frac{1}{n}\right)+\tan^{-1}\left(\frac{2}{n}\right)+\tan^{-1}\left(\frac{3}{n}\right)+ \cdots +\tan^{-1}\left(\frac{n}{n}\right)$$
  where $n\in\mathbb{N}$. Prove that $f(n)$ increases as $n$ increases. I first tried to create telescopic sum, but it seems that it is impossible to do so. I tried to find all $n$ such that
 $f(n+1)-f(n)≥0$,
 this would give me terms like
 $\tan^{-1}(r/n) -\tan^{-1}(r/n+1)$ ,
which I would simplify using the formula for inverse tangents' sum and difference, but this made it worse. I used a graphing calculator to find that: as
$ x→∞,f(n)→∞$ and hence $f$ doesn't converge. Then i tried to approximate 
$f(n);f(n+1)$ 
as linear functions such that
 $f(n)<k(n)$ and $f(n+1)>q(n+1)$,
such that $q(n+1)≥k(n)$ but I could not find any.","['trigonometry', 'inverse-function', 'trigonometric-series', 'graphing-functions']"
2769377,Stable limit cycle,"For a system of two differential equations, the eigenvalues determine the stability of the system. When the eigenvalues are positive, the system is unstable. In case of complex eigenvalues, the system is unstable when the real parts of the eigenvalues are positive. In the latter case, how do we mathematically show that the system enters a stable limit cycle when the fixed point is unstable? Considering the following non-linear system, Bier et al.'s model of yeast glycolysis \begin{align} \frac{dA}{dt} &= 2k_1GA - \frac{k_pA}{A+K_m}\\\\ \frac{dG}{dt} &= V_{in}-k_1GA\end{align} where $G$ refers to glucose and $A$ refers to ATP. The values of the parameters are $V_{in}=0.36$, $k_1=0.02$, and $k_p=6$. When $K_m=13$, the following behavior is observed ref. From the Jacobian of the matrix, the eigenvalues at the fixed point are $0.0040 + 0.1132i$ and $0.0040 - 0.1132i$. Here, the real parts of both eigenvalues are positive and we observe that the phase portrait shows a limit cycle. I would like to understand how complex eigenvalues with positive real parts are mathematically related to limit cycles. Any help would be much appreciated","['stability-in-odes', 'chemistry', 'ordinary-differential-equations', 'dynamical-systems']"
2769402,Necessary and sufficient condition for two complete norms to be equivalent,"Let $E$ be a normed vector space with two complete norms $\left \|\cdot \right \|_1$ and $\left \|\cdot \right \|_2$ . Prove that those norms are equivalent if and only if every Cauchy sequence with respect to one norm is also Cauchy with respect to the other. We only have to prove that $\text{id}:\left (E,\left \|\cdot \right \|_1\right )\to \left (E,\left \|\cdot \right \|_2\right )$ is continuous. Since both spaces are Banach, the open mapping theorem will guarantee that $\text{id}$ is a homeomorphism, and therefore the norms will be equivalent. So, I thought of closed graph. Suppose that there is a sequence $x_n$ which tends to $x$ in $\left \|\cdot \right \|_1$ , and $x_n=\text{id}(x_n)$ tends to $y$ in $\left \|\cdot \right \|_2$ . We want $y=\text{id}(x)=x$ . But this is not true in general: Banach space with respect to two norms must be Banach wrt the sum of the norms? Presumably the problem is that the example given previously does not satisfy the strong statement: ""for every Cauchy sequence with respect to one norm, is also Cauchy with respect to the other"". There is a suggestion: If $(a_n)_n\subset \mathbb{R}$ tends to $0$ , then there exists another sequence $(\varepsilon_n)_n\subset \mathbb{R}_{>0}$ such that $\varepsilon_n\to +\infty$ but $\varepsilon_na_n\to 0$ . But I cannot see how to make use of it. How would you solve the exercise? EDIT : This post has been marked as a duplicate, but I think that in an unfair way. The question equivalence of two definitions of norm equivalence: ""$|\cdot|_1=|\cdot|_2^\alpha$"" vs. ""being a Cauchy sequence is the same for both norms"" makes use of a knowledge that is more advanced with respect to the simpler knowledge that I am using here. I did not understand what they were talking about because I do not know anything about p-adic Analysis. Moreover, they use definitions of norm-equivalence that I am not familiarized with. This is an exercise given on a more basic subject, and our professors are no way interested on a solution like the one given in that post (providing that it really solves my problem, which I cannot assert since I do not understand it).","['functional-analysis', 'normed-spaces', 'banach-spaces', 'continuity']"
2769409,Inverse of doubly stochastic matrix $M$ is doubly stochastic iff $M$ is a permution matrix,"In a very short remark, my syllabus states that if $M\in\Omega_n$ (i.e. the set of doubly stochastic matrices) and $M$ is invertible, that $M^{-1}\in\Omega_n$ if and only if $M$ is a permutation matrix. I'm having trouble to see why this is so obvious. By definition of a doubly stochastic matrix, $Me=e$ and $e^TM=e^T$, and thus $M^{-1}Me=M^{-1}e=e$, and similarly $e^TM^{-1}=e^T$. But of course, we do not know that all matrix elements are non-negative, and by trying a few examples it indeed turns out that (for all matrices I tried), doubly stochastic matrices which are not permutation matrices do not have non-negative inverses. For the given remark, I'm trying to prove the equivalence. The reverse implication is easy: $S_n$ is a group, and $h:S_n\to GL_n(\mathbb{R}):\sigma\mapsto\Pi_{\sigma}$ is a group homomorphism, and it follows directly that the inverse of a permutation matrix will also be a permutation matrix. However, I don't see how to prove the forward implication. Any help is much appreciated!","['abstract-algebra', 'linear-algebra']"
2769433,Cardinality of Cauchy Sequences in Natural Numbers.,"Consider the set $S$ consisting of all cauchy sequences $\{a_n\}_{n \in \mathbb{N}}$ with $ a_n \in \mathbb{N}$ for all $n$. Is the set $S$ countable? Justify your Answer. Attempt Cauchy $\rightarrow$ Convergent.Let sequence $\{ a_n \}$ converge to $N$ Thus for any $\epsilon >0$ there exist $N_0 \in \mathbb{N}$ such that $|a_n-N|$ for all $n>N_0$.         (DEFINITION 1) Choose $\epsilon=0.001$
Because any two natural numbers differ by atleast $1$ We must have all $a_n=N$ for all $n>N_0$. Define
$D_{K}=\{$Sequences where $N_0=K \}$  (REFER DEFINITION 1 for $N_0$ $S=D_1 \cup D_2....... \cup D_K......$ Further note that each set $D_K$ where $N_0=K$ has cardinality$ \mathbb{N} \times \mathbb{N} \times \mathbb{N} ...... \times \mathbb{N} $ No. Of $\mathbb{N} $ is K+1. Each set $D_K$ is countable because its product of finitely many $\mathbb{N} $. Hence countable sum of countable set is countable hence S is countable.","['real-analysis', 'cauchy-sequences', 'elementary-set-theory', 'proof-verification']"
2769447,Solve this integral using Residue Theorem,"I am trying to find $$\int_{0}^{\infty} {\frac{\ln(x)}{(x+1)^3}}dx$$ Using the residue formula. I am mainly having a hard time finding a contour that works, since we must include the pole of order three at $x=-1$. I have tried a partial, indented circle that goes from $\theta = 0$ to $4\pi/3$ and a $3/4$ circle as well, but in both cases, if $\gamma_3(t) = te^{i\theta}, t \in (R,0)$ for a fixed $\theta$ in the third quadrant, we are left with the real part of the integral, as well as a complex integral that is just as difficult to solve. The residue I calculated is: $$res_{-1}f(z) = \lim_{z \rightarrow -1}\frac{1}{3!} \frac{d^2}{dz^2} (z+1)^3 \frac{\ln{z}}{(1+z)^3}$$ $$=\frac{1}{2}* \frac{-1}{-1^2} = \frac{-1}{2}$$ So that means the entire complex integral should be $2\pi i* \frac{-1}{2} = -\pi i$... I had another idea for a contour that catches the pole: we have $$\gamma_1(t) = t, t \in (\epsilon, R)$$
$$\gamma_2(t) = Re^{it}, t\in (0, \pi/2)$$
$$\gamma_3(t) = e^{it} -1, t \in (\pi, 2\pi - \epsilon)$$
$$\gamma_4(t) = $$ the little tiny circle to complete the contour. But this one, for $\gamma_3$ gives us a weird integral: $$\int_{\pi}^{2\pi - \epsilon}\frac{\ln{e^{it} - 1}}{(e^{it} - 1 +1)^3}(ie^{it})$$ Which looks a little better, but I'm not sure how to hande the log function in this case, and it doesn't look promising. Any help would be appreciated.","['complex-analysis', 'definite-integrals', 'residue-calculus']"
2769481,Ideal class defined in terms of linear fractional ideal is chern class?,"Let $O$ be a number ring(i.e. dedekind ring). Let $M$ be a finitely generated torsion free and non-zero module over $O$. $M$ can be embedded into a vector space over $Frac(O)=K$. There $M$ is a submodule of some $O$ free module contained in $V$. Fix any free module $F\subset V$. We call $M$ an $O$ lattice if $F$ is of full rank. Define $[F:M]$ as the following. Consider a place $p$ of $O$. Let $O_p$ be completion of $O$ at $p$ and $K_p$ be the corresponding field completion of $K$ at $p$. Then there is automorphism $l_p\in Aut_{K_p}(V\otimes_KK_p)$ s.t. $l_p(F\otimes_OO_p)=M\otimes_OO_p$. Then define $[F\otimes_OO_p:M\otimes_OO_p]=p^{e}O_p\subset O_p$. Since there are only finitely many places $F$ is distinct from $M$, let $[F:M]=\prod_{i<\infty}p_i^{e_i}O$ where $p_i$ runs through only finitely many places s.t. $[F\otimes_OO_p:M\otimes_OO_p]\neq O_p$. This defines a fractional ideal in $O$. Let $c(M)=[F:M]$ for a choice of free module $F$ containing $M$ s.t. $F\otimes_OK=V=M\otimes_OK$. First $c(M)$ is independent of choice of $F$. Then one also have $c(M_1\oplus M_2)=c(M_1)c(M_2)$. $\textbf{Q:}$ It seems that $C(M_1\oplus M_2)=c(M_1)c(M_2)$ defines a chern class. Note that if $M=F$ free module, then $c(F)=1\in Cl(O)$ where $Cl(O)$ is class group of $O$. The only question is naturality here. Do I have a chern class functor defined here? This is just my thought when I saw the formula on Pg 95 Thm 13 of Taylor Frohlich Algebraic Number Theory.","['number-theory', 'abstract-algebra', 'algebraic-topology', 'algebraic-geometry']"
2769562,Is this bounded uniformly on $H^{-2}(\mathbb{T})$?,"Let be $u(x,t) = e^{it\partial_x^2}u_0$ be the linear solution of
\begin{align*}
i\partial_t u +  \partial_x^2 u &= 0\\
 u(x,0) &= u_0
\end{align*}
so i would like to know if we have $u_0 \in L^2(\mathbb{T})$, $\varepsilon >0$ and if we define $u_\varepsilon = \dfrac{e^{i\varepsilon \partial_x^2}u_0 - u_0}{\varepsilon}$. It is $u_\varepsilon $ bounded uniformly on $H^{-2}(\mathbb{T})$ in $\varepsilon \to  0$ . $\mathbb{T}$ is the one dimension torus. Hope u can help me. Thank you in advance","['functional-analysis', 'sobolev-spaces', 'analysis']"
2769619,Finding bounds to apply Dominated Convergence,"i was filling some gaps on a proof my teacher made in class, to compute
$$\int_0^\infty \frac{\sin x}{x} \, \mathrm{d}x.$$
The first he made was saying that this integral is equal to
$$\lim_{\varepsilon \to 0^+} \int_0^\infty \frac{\varepsilon \sin x}{e^{\varepsilon x}-1} \, \mathrm{d}x,$$
and he said ""okay, you can check that at home"". I tried to apply Dominated Convergence Theorem in
$$\lim_{\varepsilon \to 0^+} \int_0^\infty \frac{\sin x}{x}-\frac{\varepsilon \sin x}{e^{\varepsilon x}-1} \, \mathrm{d}x,$$
and show that it's zero, because I already know that $\frac{\sin x}{x}$ is not Lebesgue-integrable. So, I tried to bound the function inside the integral sign, but I'm not getting very sharp bounds (essentialy, I tried to apply MVT a couple times and get
$$\frac{\sin x}{x}\xi e^{-\tau},$$
with $0<\tau<\xi<\varepsilon x$, but then I take absolute value and get something like $\varepsilon$). Do you have any idea/hint to bound this with an integrable function? Edit : As Delta-u pointed out, my approach can't work. Do you have any idea to prove the equality?",['measure-theory']
2769672,Evaluating a Path Integral in the Complex Plane,"I am preparing for a final tomorrow and working through an old exam question that I got incorrect and since I cannot find an online contour integral calculator I was wondering if my (new) solution is correct. The question is Consider the contour $C$ given by $$ z(t)=\begin{cases}
e^{it} & t \in [0,\pi] \\
1 + 2e^{it} & t \in [\pi, 2 \pi]
\end{cases}. $$
  Evaluate the path integral $$\int_{C} \frac{(z + 1)^2}{z} \, dz .$$ For the first part of the contour, we may simplyify the integrand: 
$$
\frac{(z+1)^2}{z} \cdot \frac{\overline{z}}{\overline{z}} = \frac{(z + 1)^2 \cdot \overline{z}}{|z|^2}
$$
and we get 
$$
\begin{eqnarray*}
\int_{0}^\pi (e^{it} + 1)^2\cdot (e^{-it}) \cdot (i e^{it}) \, dt & = & i \cdot \int_{0}^\pi (e^{it} + 1)^2 \, dt \\
& = & i \left[ \frac{e^{2it}}{2i} + \frac{2e^{it}}{i} + t\right]_{t = 0}^{t = \pi} \\
& = & \pi i - 4. 
\end{eqnarray*}
$$
For the second part of the contour, we have 
$$
\int_{\pi}^{2 \pi} \frac{(2 + 2e^{it})^2}{1 + 2e^{it}} \cdot 2ie^{it} \, dt.
$$
If we let $u = 1 + 2e^{it}$, then $du = 2i e^{it}\,dt$ and the integral becomes 
$$
\int_{-1}^3 \frac{(1 + u)^2}{u} \, du = \left[ \ln(u) + 2u + \frac{u^2}{2} \right]_{u = -1}^{u =3} = \ln(3) + 8.
$$
So then 
$$
\int_{C} \frac{(z + 1)^2}{z} \, dz= \ln(3) + 4 + i \pi.
$$ Is this correct?","['complex-analysis', 'contour-integration']"
2769706,Integrating $\int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{\log\left( x^2 + 2 x \sin(\theta) + 1 \right)}{x + 2 \sin(\theta)} d\theta$,"Let $x>0$. I've encountered the following integral:
$$
I(x) \ = \ \int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{\log\left( x^2 + 2 x \sin(\theta) + 1 \right)}{x + 2 \sin(\theta)} d\theta
$$ Is there a way to integrate this? I've been looking through Gradshteyn and Ryzhik, and I have found some similar integrals but nothing that looks exactly like this. Maybe through a contour integration? If there is no way to integrate this, is it possible to derive asymptotics for the above $I(x)$ in the limit $x \to \infty$?","['asymptotics', 'integration', 'definite-integrals']"
2771591,Degrees of freedom for a matrix,"What does it mean for a matrix to have degrees of freedom? How does the degrees of freedom relate to constraints on what those values could be in the context of an optimization problem? I'm specifically confused about the last paragraph in this screenshot, but a more general explanation would be much appreciated.",['linear-algebra']
2771617,How would I obtain the square root of this multinomial?,"I was doing some problems from a book I found on finding the square root of a polynomial expression. I came across this problem: $$\frac{a^4}{64}+\frac{a^3}{8}-a+1$$ I utilised the method outlined here , and obtained the following result $$\frac{a^4}{64}+\frac{a^3}{8}-a+1)\frac{a^2}{8} + \frac{a}{2}$$
$$\frac{a^2}{4} + \frac{a}{2} )\frac{a^3}{8} - a + 1$$
$$\frac{a^2}{4} + a + 1) -\frac{a^2}{4} - a + 1$$
$$\frac{a^2}{4} + a + 1 ) -2$$ I know that I didn't format it well, but, basically, when I used the method they suggested, I had a remainder at the end. I don't know whether I did something wrong or whether the polynomial is a perfect swuare.","['algebra-precalculus', 'polynomials']"
