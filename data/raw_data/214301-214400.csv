question_id,title,body,tags
4342310,Evaluate $\int_{\pi}^{\infty}\left(x^{2}-\sin\left(x\right)-1\right)^{-1}dx=?$,It's an integral which seems simple but I confess I cannot evaluate this : $$\int_{\pi}^{\infty}\left(x^{2}-\sin\left(x\right)-1\right)^{-1}dx=?$$ I can evaluate another integral where I start from : $$\int_{\pi}^{\infty}\left(x^{2}-x-1\right)^{-1}dx=\frac{2\coth^{-1}\left(\frac{2\pi-1}{\sqrt{5}}\right)}{\sqrt{5}}$$ Show the convergence is not hard using bound for $\sin(x)$ . Question : Can we hope to find a closed form ? Thanks .,"['trigonometry', 'improper-integrals', 'closed-form']"
4342315,Totally geodesic submanifolds and conformal class of metrics,"Suppose I have a riemannian manifold $(N,g^1)$ and a submanifold $i:M\hookrightarrow N$ . Furthermore, assume that $M$ is totally geodesic with respect to $N$ , therefore the second fundamental form vanishes. Now consider another riemannian metric $g^2$ on $N$ such that $g^2=e^{2f}g^1$ for a smooth function $f$ . Now I was wondering if with respect to the metric $g^2$ will $M$ also be totally geodesic with respect to $N$ . I belive the answer is yes but I wanted to make sure my proof was correct. The goal is to check that the second fundamental form associated with $g^2$ vanishes. We will have $B^2(X,Y)=\tilde \nabla ^2_{\tilde X}\tilde Y- \nabla ^2_X Y$ . But since we are in the same conformal class we know that , from this answer Levi-Civita connection between conformal metrics , $$\tilde \nabla^2_{\tilde X}\tilde Y=\tilde \nabla^1_{\tilde X}\tilde Y+\tilde X(f)\tilde Y+\tilde Y(f)\tilde X- g^1(\tilde X,\tilde Y)grad(f)$$ and we get an analogous result for $\nabla^2_{X}Y$ . Therefore using the fact that $\tilde \nabla^1_{\tilde X}\tilde Y- \nabla^1_{X}Y=0$ and that $\tilde X,\tilde Y$ are extensions of $X$ and $Y$ we get that $B^2$ will vanishe, and hence $(M,i^*(g^2))$ is totally geodesic with respect to $(N,g^2)$ . What do you think about this proof? Any insight is appreciated, thanks in advance.","['solution-verification', 'riemannian-geometry', 'differential-geometry']"
4342318,Riemann surface with transition functions of the form $z \mapsto az+b$,"Let $\Sigma$ be a closed Riemann surface and let $\{U_\alpha,\phi_\alpha:U_\alpha\rightarrow\mathbb C\}$ be a family of holomorphic coordinate charts. If the transition maps $$\Phi_{\alpha\beta}:\phi_\alpha(U_\alpha\cap U_\beta)\rightarrow\phi_\beta(U_\alpha\cap U_\beta)$$ are of the form $z\mapsto az+b$ where $a,b$ are complex numbers (of course determined by the charts $U_\alpha$ and $U_\beta$ ). Show that $\Sigma$ must be a genus one Riemann surface. I can prove that $\Sigma$ must not be genus zero because a holomorphic developing map $F:\hat\Sigma\rightarrow \mathbb C$ can be well-defined using the data of the coordinate charts, where $\hat\Sigma$ is the universal covering of $\Sigma$ . The surface $\Sigma$ must not be genus zero since there are no nonconstant holomorphic functions on compact Riemann surfaces. I know this problem can be solved by introducing flat connections in differential geometry, and is related to a famous open problem (Chern's conjecture), but I believe there is a more elementary solution using theory of Riemann surfaces. Thanks for any help!","['complex-geometry', 'riemann-surfaces', 'differential-geometry']"
4342341,Extreme value distribution- member of the exponential family?,"I am asked to prove whether or not the following distribution (extreme value distribution) is part of the exponential family: $$ f_Y(y;\mu,\phi)=\frac{1}{\phi}\exp[-\frac{y-\mu}{\phi}+\exp(-\frac{y-\mu}{\phi})]$$ My definition of the exponential family is the following: I have tried rewriting the density function and obtained: $$f_Y(y;\mu,\phi)=\exp \left[\log\frac{1}{\phi}-\frac{y}{\phi}+\frac{\mu}{\phi}-\exp\left(\frac{-y+\mu}{\phi}\right)\right]$$ However, at this point I am stuck. How do I get the density function into the form of the exponential family distribution from this point? Any help would be very much appreciated!","['statistics', 'probability-distributions', 'exponential-distribution', 'probability-theory', 'density-function']"
4342347,Separation Axioms: is it true that $T_4 \Rightarrow T_3 \Rightarrow T_2 \Rightarrow T_1 \Rightarrow T_0$?,"I am thoroughly confused by the separation axioms in topology. My lectures, online resources, and books all seem to say different things. Online I read that $T_4 \Rightarrow T_3 \Rightarrow T_2 \Rightarrow T_1 \Rightarrow T_0$ , the proofs make sense to me and I don't see how this could be wrong. I am reading the book Topology: An Introduction, by Stefan Waldmann. Given the chain of implications from before as fact, several things he says in the book confuse me: Let $(M, \mathcal{M})$ be a topological space. he says that $(M, \mathcal{M})$ is regular if it is $T_1$ and $T_3$ . But $T_3 \Rightarrow T_2 \Rightarrow T_1$ , so why have the condition that it is $T_1$ and what is the difference between a regular space and a $T_3$ space? $(M, \mathcal{M})$ is normal if it is $T_1$ and $T_4$ . Again, why have $T_1$ in the definition and what is the difference between normal and $T_4$ ? He says a metric space is normal and hence $T_1, T_2, T_3, T_4$ . Why did he not include $T_0$ in this list? Further, the Wikipedia article ""Separation Axiom"" adds a whole new level of confusion. There it is implied that normal and regular spaces are not necessarily $T_0$ . So is $T_4 \Rightarrow T_3 \Rightarrow T_2 \Rightarrow T_1 \Rightarrow T_0$ even true? If not, why not? Here are the definitions of the axioms as I learned them in my lecture and the book: Let $(M, \mathcal{M})$ be a topological space. The space $M$ is called a $T_0$ -space if for each two different points $p \neq q$ in $M$ we find an open subset which contains only one of them. The space $M$ is called a $T_1$ -space if for each two different points $p \neq q$ in $M$ we find open subsets $O_1$ and $O_2$ with $p \in O_1$ and $q \in O_2$ but $p \not\in O_2$ and $q \not\in O_1$ . The space $M$ is called a $T_2$ -space or a Hausdorff space if for each two different points $p \neq q$ in $M$ we find disjoint open subsets $O_1$ and $O_2$ with $p \in O_1$ and $q \in O_2$ . The space $M$ is called a $T_3$ -space if for every closed subset $A \subset M$ and every $p \in M \backslash A$ there are disjoint open subsets $O_1$ and $O_2$ with $A \subset O_1$ and $p \in O_2$ . The space $M$ is called a $T_4$ -space if for two disjoint closed subsets $A_1, A_2 \subset M$ there are disjoint open subsets $O_1$ and $O_2$ with $A_1 \subset O_1$ and $A_2 \subset O_2$ .","['general-topology', 'separation-axioms']"
4342349,Area expressions in terms of its dimensions,"(This question is about area, but the same thing fully applies to volume) Whenever I was finding an area of a shape / geometric figure - triangle, square, circle, ellipse etc - I always had this understanding that if I express the final result in terms of 1D components of that shape, it must always result in a degree 2 polynomial . The best example here would be a triangle since there are a lot of ways to get its area: $$S=\frac{1}{2}ab\cdot sinA = \frac{1}{2}ah = \sqrt{s(s-a)(a-b)(a-c)}$$ All of them are degree 2 polynomials in the end, even if the components aren't exactly ""degree 1 things"" - like Heron's formula is a product of 4 ""degree 1/2"" components, yet in the end it sums up to 2. Also, standard trigonometric functions are all ""degree 0"" because by definition any such function is just a quotient of two sides of a right triangle, so has ""degree 0"" I'm asking this because of a ""counter example"" I recently encountered. That one is the area of a shape in its polar form defined by: $$r=\theta , 0\le\theta\le2\pi$$ That shape will have its area equal to $\frac{1}{6}{\theta}^{3}|_0^{2\pi}=\frac{4}{3}{\pi}^3$ (thanks bprp!). Now I'm not concerned about the last expression featuring ${\pi}^3$ - it's just a constant. But the integral from which that is derived definitely results in a cubic, not a quadratic form in terms of $\theta$ I know I'm very loose here with defining things - I'm not a mathematician, it's just about my intuition. Perhaps, this is the reason I'm having this question in the first place. And the question is this : Are there cases when a 2D shape will not have its area to be a quadratic polynomial in terms of its 1D components? What can be counted as ""proper"" 1D components of a 2D shape? Do polar coordinates have some differences (like the one above)?","['area', 'geometry']"
4342365,Probability of receiving gifts on time,"Alex plans to order a birthday gift for his friend from an online retailer. However, the birthday coincides with the festival season during which there is a huge demand for buying online goods and hence deliveries are often delayed. He estimates that the probability of receiving the gift, in time, from the retailers A, B, C and D would be 0.6, 0.8, 0.9 and 0.5 respectively. Playing safe, he orders from all four retailers simultaneously. What would be the probability that his friend would receive the gift in time? My solution:- If we even get 1 gift on time, the task would be done, so I thought of finding 1-P(No gift on time) P(No gift on time)=P(A)*P(Not on time | A) + P(B)*P(Not on time | B) + P(C)*P(Not on time | C) + P(D)*P(Not on time | D) Choosing any of gifts among A,B,C,D are equally likely therefore P(A)=P(B)=P(C)=P(D)=1/4 P(No gift on time) = 1/4 * (0.4 + 0.2 + 0.1 + 0.5) = 0.3 Therefore P(At least 1 gift on time)= 1-0.3 = 0.7 but the answer is given as 0.996 , what mistake am I making ? Update :- I have understood that P(A)=P(B)=P(C)=P(D)=1 as it is certain that alex has ordered the gifts from all these retailers, but my question now is why is the following notation wrong ? P(No gift on time)=P(A)*P(Not on time | A) + P(B)*P(Not on time | B) + P(C)*P(Not on time | C) + P(D)*P(Not on time | D) A= event of ordering gift from retailer A P(Not on time | A) = Probability of gift not arriving on time given that it was ordered from retailer A",['probability']
4342409,Characterization of the isomorphic semidirect products,"Let $A$ and $G$ be two finite abelian groups and let $\alpha$ , $\beta:G\rightarrow{\rm Aut}(A)$ . Suppose that $\alpha (G)$ and $\beta (G)$ are conjugate subgroups of ${\rm Aut}(A)$ . Are the semidirect products $A\rtimes _{\alpha }G$ and $A\rtimes _{\beta }G$ isomorphic? I know that this is true for a finite cyclic group $G$ but I don't what to do if $G$ is a finite non-cyclic Abelian group. I think the answer is usually no, so I will be thankful if someone provides me a counterexample. Thank you in advance.","['abelian-groups', 'group-theory', 'semidirect-product', 'finite-groups']"
4342429,Function of $x$ which diverges for $x\to c$ while derivative converges to a constant,"Is there a function $f(x)$ of one real variable and a constant $c$ with the following two properties: $\lim_{x\to c} f'(x)$ converges to some finite value $\lim_{x\to c} f(x) = \infty$ With $\lim_{x\to\infty}$ , I could take $f'(x) = \frac{x}{x+1}$ . For the limes going to constant $c$ , I tried a trival replacement using $f'(x) = \frac{1/(x-c)}{1/(x-c) + 1}$ , but then end up with $f$ not being divergent.","['limits', 'calculus']"
4342440,How to prove this process to be a martingale?,Suppose we have $(X_n)$ a sequence of real positive random variables in $\mathcal L^2$ that is $\mathcal F_n$ mesurable Let: $S_n=X_1+\dots+X_n$ with $S_0=0$ $A_n=\sigma_1^2+\dots+\sigma_n^2$ with $A_0=0$ $V_n=S_n^2-A_n$ Given that $\mathbb E[X_n |\mathcal F_{n-1}]=0$ and $\mathbb E[X_n^2|F_{n-1}]=\sigma_n^2$ Show that $(S_n)$ and $(V_n)$ are martingales. My problem: I proved that $(S_n)$ is a martingale simply using the fact that $\mathbb E[X_n |\mathcal F_{n-1}]=0$ but I don't know how am I going to prove that $(V_n)$ is a martingale since the calculation gets complicated if I try to pull out the $X_n^2$ from $S_n^2$ to use the second property.,"['conditional-expectation', 'stochastic-processes', 'martingales', 'probability-theory', 'probability']"
4342467,Family of sets with $|F_i| \equiv 2\pmod 3$ and $|F_i \cap F_j| \equiv 0 \pmod 3$,"Let $p$ be a prime. By considering the incidence vectors of subsets $F_1,\ldots,F_m$ of $\{1,2,\ldots,n\}$ , such that $|F_i| = a \not\equiv 0 \pmod p$ and $|F_i \cap F_j| \equiv 0 \pmod p$ for all $1\leq i<j \leq m$ , we can show $m\leq n$ (the vectors are linearly independent).
For $p=2$ this bound is achievable by the singletons $\{\{1\},\{2\},\ldots,\{n\}\}$ , same for $p=3$ with $a=1$ . But what about $p=3$ with $a=2$ ? Is there an example of size $n$ (or perhaps $n - c$ for some ""small"" constant $c$ )?. Observing such examples could help towards ideas of how to improve the bound $m\leq n$ where possible.","['finite-fields', 'extremal-combinatorics', 'linear-algebra', 'combinatorics', 'algebraic-combinatorics']"
4342525,Trigonometric elimination possibly related to hypocycloids,"This is the question, which has been previously asked on Math.SE. Eliminate $\theta$ from the system of equations. $$x\sin\theta-y\cos\theta=-\sin4\theta$$ $$x\cos\theta+y\sin\theta=\frac52-\frac32\cos4\theta$$ I encountered this problem while browsing through some trigonometric elimination problems. At the first glance, I thought that this is definitely from the famliy of problems such as: Eliminate $\theta$ from $$x\sin\theta-y\cos\theta=\cos2\theta$$ $$x\cos\theta+y\sin\theta=2\sin2\theta$$ where the eliminant (usually) gives evolute of a hypocycloid etc. For instance, the elimination of the second problem is $(x-y)^{2/3}+(x+y)^{2/3}=2$ which is the envelope of normals to the astroid $x^{2/3}+y^{2/3}=1$ . So I first decided to play with geogebra graphing tool. Solving for $x$ and $y$ we get, $$x=\frac52\cos\theta-\frac12\cos\theta\cos4\theta-\cos3\theta$$ $$y=\frac52\sin\theta-\frac12\sin\theta\cos4\theta-\sin3\theta$$ The plot looks like this: I then tried some other functions and I noted that the locus of point $A$ (in the figure) lies on (approximately), $$\color{blue}{[(x-y)^{1/3}+(x+y)^{1/3}]^2=4}$$ $$\color{#F80}{[(y-x)^{1/3}+(x+y)^{1/3}]^2=4}$$ Thus, the curve, $$\left(\left((x-y)^{1/3}+(x+y)^{1/3}\right)^2-4\right)\cdot\left(\left((y-x)^{1/3}+(y+x)^{1/3}\right)^2-4\right)=0$$ seems to be doing a very good job, but the matter is it is not bounded. With this clue, could you please help me to end this solution?","['trigonometry', 'algebra-precalculus', 'geometry']"
4342540,Can one integral can give more than one answer one with natural log and other with tan inverse,"question is $$\int\frac{1}{\sin^6(x) + \cos^6(x)}\,dx$$ My method : $$\sin^6\left(x\right)+\cos^6\left(x\right)$$ $$=\left(\sin^2\left(x\right)+\cos^2\left(x\right)\right)\left(\sin^4\left(x\right)-\cos^2\left(x\right)\sin^2\left(x\right)+\cos^4\left(x\right)\right)$$ $$=1-3\cos^2\left(x\right)\sin^2\left(x\right)$$ so integration is $$\int\dfrac{1}{1-3\cos^2\left(x\right)\sin^2\left(x\right)}\,dx$$ divide numerator and denominator by $$cos^2x$$ $$\int\dfrac{\sec^2\left(x\right)}{\sec^2\left(x\right)-3\tan^2\left(x\right)} \, dx$$ Now put $$t=\tan x$$ So $$dt = \sec^2x\,dx$$ So $$\int\dfrac{t}{1-2t^2} \, dt$$ $$=\frac{1}{2\sqrt{2}}\ln\left(\left|\frac{\sqrt{2}\tan x+1}{\sqrt{2}\tan x-1}\right|\right)$$ But answer is $$\arctan\left(\tan\left(x\right)-\cot\left(x\right)\right)$$ So can there be two answers of different forms of same integration?
Thanks!","['integration', 'trigonometry', 'substitution']"
4342553,Calculate residue of pole with order 5,"I am trying to evaluate the residue of $\frac{(z^6-1)^2}{z^5(2z^4-5z^2+2)}$ at z=0. Is there a way to do this without having to do the long derivative calculation? I know we have the formula $Res(f,0)=\lim_{z\to0}\frac{1}{(5-1)!}\frac{\mathrm{d}^{5-1}f}{\mathrm{d}z^{5-1}}z^5f(z)$ . But finding the 5th derivative of this function would take a long time and be pretty messy. My first try was to find the residues at the other poles and at infinity since all the residues must sum to zero, but when I tried to do this the residue at infinity ended up being the same as the residue at zero. I've also considered finding the Laurent expansion but the Partial Fraction Decomposition is also long.","['complex-analysis', 'residue-calculus']"
4342560,Chern connection and Levi Civita connection on Kahler manifold,"I'm reading Voisin's book on complex geometry. A theorem states on Kahler manifold, Chern connection and Levi Civita connection coincide on (1,0). But I feel difficult to formalize it rigorously. Let $X$ be a Kahler manifold. Let $TX$ be its holomorphic tangent bundle and $T_{\mathbb R}X$ be its real tangent bundle. Then, in my opinion, (1,0) part of chern connection is a map: $$
\nabla^{1,0}: \Gamma(X,TX)\rightarrow \Gamma(\Omega^{1,0}_X\otimes_{\mathbb C}TX)
$$ and Levi Civita connection is a map: $$
\nabla_{LC}: \Gamma(X,T_{\mathbb R}X)\rightarrow \Gamma(X,T^*_\mathbb RX\otimes_{\mathbb R}T_\mathbb RX)
$$ My question: (1) How to identify $T_{\mathbb R}X$ with $TX$ and $\Omega_X^{1,0}$ with $T^*X$ ? (2) Why $\Omega^{1,0}_X\otimes_{\mathbb C}TX = T^*_\mathbb RX\otimes_{\mathbb R}T_\mathbb RX$ ? It seems weird because one is $\mathbb R$ -tensor but another is $\mathbb C$ -tensor. Thank you in advance!","['complex-geometry', 'riemannian-geometry', 'differential-geometry']"
4342569,Understanding Analysis by Abott (Prerequisites) [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 6 months ago . Improve this question I just bought „Understanding Analysis“ by Stephan Abott. I am a CS Student who already passed his math lectures in Germany but I want a better understanding since I memorized a lot.
I want to build a deep understanding and intuition. My goal is to self study math. „Understanding Analysis“ is a introduction to rigerous analysis, so basically proof based calculus right? So would a calculus book before working through „Understanding Analysis“ beneficial to get an intuition?
Or does „Understanding Analysis“ cover the same stuff as an Calculus book?","['intuition', 'calculus', 'analysis', 'real-analysis']"
4342576,Bound the derivative at zero of an analytic function with $f(0.5) = 0$,"The following is a problem from the UW-Madison complex analysis qualifying exam. Let $f:\mathbb{D}\to\mathbb{D}$ be analytic, where $\mathbb{D}=\{z : |z| < 1\}$ . Assume that $f(\frac{1}{2}) = 0$ . Show that $|f'(0)| \leq \frac{25}{32}$ . Using the Schwartz-Pick (S-P) lemma, we can say $$|f(0)|= \left|\frac{f(1/2)-f(0)}{1-\overline{f(1/2)}f(0)}\right| \leq \left|\frac{1/2-0}{1-\overline{\frac{1}{2}}0}\right| = 1/2.$$ Not sure if this will help. There is a first part to this qual problem: Show that $|f'(0)| \leq 1-|f(0)|^2.$ It is a simple consequence of S-P lemma for $z=0$ .",['complex-analysis']
4342612,"What does finding a ""free local ring"" have to do with finding the spectrum of a ring?","In Tierney's 1976 paper On the Spectrum of a Ringed Topos (which you can find here ) at the top of section 2 we read Let $A$ be a commutative ring in [a topos] $\mathbf{E}$ . We look at the problem of finding the spectrum of $A$ as the problem of finding a free local ring on $A$ . That is, we try to find a universal homomorphism $\gamma : A \to L(A)$ , where $L(A)$ is a local ring. Then a page later That is, we are looking for a right adjoint to the forgetful functor $LR\text{-top} \to R\text{-top}$ . When such an adjoint exists, it is characterized up to unique local equivalence, and we call it $\text{Spec}(\mathbf{E},A)$ , the spectrum of $(\mathbf{E},A)$ . Here $R\text{-top}$ is the category of topoi with a distinguished ring, and $LR\text{-top}$ is the category of topoi with a distinguished local ring. You can find more details about the exact morphisms in the paper, but they're what you expect. Tierney then spends some time describing historical constructions, before finally proposing a new construction, introducing a technique where we build a free ring (since this theory is algebraic), then introduce a (grothendieck) topology whose sheaves respect the additional geometric axioms of a local ring. I mention this mainly because I found it instructive, but it's not particularly relevant. Now, it's clear that this is a good notion of ""spectrum"", since Tierney proves (on written page 207) the $\mathbf{E}$ -points of $\text{Spec}(\mathbf{E},A)$ ... correspond $1$ - $1$ to the primes of $A$ . (NB: ""primes"" in this paper are what we would classically call complements of prime ideals. This is to avoid some technical issues with double negation that I don't fully understand) The question, then: Obviously this idea of ""free"" local rings does lead us to a good notion of spectrum. But it's entirely opaque to me why we would consider it at all. Maybe this is my weakness in algebraic geometry showing? Regardless: What is the motivation for looking at ""free"" local rings? And what does this have to do with the construction of the spectrum of a ring? I would prefer answers which give concrete examples if possible. Thanks in advance ^_^","['category-theory', 'algebraic-geometry', 'intuition', 'local-rings', 'topos-theory']"
4342621,Question on Egorov's Theorem: How do you find such $E_{\epsilon}$ sets?,"Egorov's Theorem is as follows: Let $X$ be a finite measure space.  If $f_n\rightarrow f$ pointwise a.e., then for all $\epsilon>0$ , there exists $E_{\epsilon}\subset X$ such that $m(E_{\epsilon})<\epsilon$ and $f_n\rightarrow f$ uniformly on $X\setminus E_\epsilon$ . I don't have a specific problem in front of me, but suppose we had a problem where we were given some hypothesis, and we had to find such a $E_\epsilon$ .  Is there a standard method to find such a set?  Could you maybe provide some examples?  I (believe I) understand the proof of Egorov's theorem, but I am having a hard time actually finding such sets, rather than just claiming such sets exist.  One last question: since $X$ is a finite measure space, then we can use $f_n\rightarrow f$ in measure in the original claim, correct?  Thank you!!","['measure-theory', 'pointwise-convergence', 'real-analysis']"
4342627,Critique my proof of: $A \times (B \cap C) = (A \times B) \cap (A \times C)$,"Critique my proof on correctness, structure, etc. Proof. Suppose $p = (x,y)$ is an arbitrary element. ( $\subseteq$ )
Let $p \in A \times (B \cap C)$ . By definition of cartesian product, $x \in A$ and $y \in B \cap C$ . Thus, $y \in B$ , $y \in C$ and $p \in (A \times B)$ , $p \in (A \times C)$ . By definition of $(A \times B) \cap (A \times C)$ , $\ p \in (A \times B) \cap (A \times C)$ and because $p$ is arbitrary, we can say that $A \times (B \cap C) \subseteq (A \times B) \cap (A \times C)$ . ( $\supseteq$ )
Let $p \in (A \times B) \cap (A \times C)$ . Thus, $p \in (A \times B)$ and $p \in (A \times C)$ . By definition of cartestian product, $x \in A$ and $y \in B$ , $y \in C$ . By definition of $A \times (B \cap C)$ , $\ p \in A \times (B \cap C)$ and because $p$ is arbitrary, we can say that $(A \times B) \cap (A \times C) \subseteq A \times (B \cap C)$ . $\therefore$ $A \times (B \cap C) \subseteq (A \times B) \cap (A \times C)$ and $(A \times B) \cap (A \times C) \subseteq A \times (B \cap C)$ , so $A \times (B \cap C) = (A \times B) \cap (A \times C)$ .","['elementary-set-theory', 'proof-writing', 'solution-verification']"
4342733,L'Hôpital's rule in topological vector spaces,"Let $E$ be a (separated) topological vector space over $\mathbb{R}$ , $f\colon [0,1]\to E$ continuous. Assume that for every $t \in (0,1)$ we have a derivative $$f'(t) = \lim_{h\to 0} \frac{f(t+h)- f(h)}{h}$$ Moreover, assume that there exists the limit $\lim_{t \to 0_{+}} f'(t)$ Is it true that $$\lim_{h\to 0_{+}} \frac{f(h)-f(0)}{h}=\lim_{t \to 0_{+}} f'(t) $$ ? Notes: This is true for $E$ finite dimensional topological vector space ( since it's isomorphic to $\mathbb{R}^n$ , and we can work component-wise, using Lagrange intermediate value theorem). If $E$ is arbitrary, we can still conclude $$ \frac{f(h) - f(0)}{h} \to \lim_{t\to 0} f'(t)$$ weakly. If $f'$ has a continuous extension to $[0,1]$ , and $E$ is locally convex and complete ( say a Banach space) then we have $$f(h) - f(0) = \int_{0}^h f'(t) dt = h \cdot \int_{0}^1 f'(h t) d t$$ so again we get the desired equality. It may be that the equality ( L'Hospital rule ) is not true if $E$ is not locally convex. It may have to do with the fact that the average of a sequence convergent to $0$ may not converge to $0$ . Or it may not work in the general form even for locally convex spaces, or even Banach spaces. $\bf{Added:}$ I think it will work for locally convex spaces.  We use a bit of compactness too.  But I haven't written down details. Anyways, maybe it's a very basic fact, for which references are available. $\bf{Added:}$ The following lemma is useful, and not hard to prove (use the compactness of $[a,b]$ ): Let $[a,b]$ an interval, $f\colon [a,b]\to E$ , with a derivative at every point. Let $U$ be an open convex set such that $f'(t) \in U$ for all $t \in [a,b]$ . Then $$\frac{f(b)-f(a)}{b-a} \in U$$ $\bf{Added:}$ Another lemma : Let $[a,b]$ an interval, $f\colon [a,b]\to E$ , with a derivative at every point except a finite set $A$ .  Let $U$ be an open convex set such that $f'(t) \in U$ for all $t \in [a,b]\backslash A$ . Then $$\frac{f(b)-f(a)}{b-a} \in \bar U$$ ( similar to Dieudonne lemma here... perhaps it's also valid with the proper modifications). Note: this will take care of the case $E$ locally convex. $\bf{Added:}$ It turns out that the statement is related to the mean value theorem ""inequality"", as seen from the previous lemma. What I have learned and is somehow related is that the inequality might not be true if the topological vector space $E$ does not have any linear functionals $\ne 0$ . There exist functions $f\colon [0,1]\to E$ , $f'(t) = 0$ for all $t \in [0,1]$ , but $f$ not constant. See "" functions with $0$ derivative"". $\bf{Added:}$ This is the example of Rolewicz of a nonconstant function with $0$ derivative from $[0,1]$ to $L^p[0,1]$ ( $0<p<1$ ). Take $f(t) = \chi_{[0,t]}$ (!). Following this idea, here is an example of a continuous function $f\colon [0,1] \to L^p[0,1]$ such that $f'(t) = 0$ for all $t \in (0,1]$ , but $\frac{f(h)-f(0)}{h}$ does not converge to $0$ as $h\to 0_{+}$ . Just take $$f(t) = \chi_{[0, t^p]}$$ This provides a counterexample. $\bf{Added:}$ Now that we know it may not work for spaces what are not locally convex, let's see what more can be said. With the same methods we can show: if $f\colon [0,1]\to E$ , $g\colon [0,1] \to \mathbb{R}$ continuous functions, with derivatives on $(0,1]$ , and moreover: $E$ is locally convex and $g$ is monotonous around $0$ (I cannot avoid this extra hypothesis for general l.c. $E$ ), and moreover $\lim_{t\to 0_{+}} \frac{f'(t)}{g'(t)}$ exists then $$\lim_{t\to 0_{+}} \frac {f(t)-f(0)}{g(t)-g(0)} = \lim_{t\to 0_+} \frac{f'(t)}{g'(t)}$$","['differential', 'topological-vector-spaces', 'analysis', 'calculus', 'convex-analysis']"
4342737,"If you throw a dice 5 times, what is the expected value of the square of the median?","My question: If you throw a dice 5 times, what is the expected value of the square of the median of the 5 results? A slightly modified question would be: If you throw a dice 5 times, what is the expected value of the median? The answer would be 3.5 by symmetry. For the square, it seems to be that symmetry does not hold anymore. Is there a ""smart"" way to solve this problem? If there isn't a smart way to solve the problem, if there a smart way to estimate the answer?","['expected-value', 'dice', 'symmetry', 'probability']"
4342741,"I've clicked XKCD's ""random"" button k times and I've already seen all of them. What's the expected number of XKCD's I've seen?","This seems like a modification of the coupon collector's problem which can be stated as follows: There are $n$ coupons total to collect. Given that the past $k$ coupons seen I've already collected (coupons are collected with replacement), what's the expected number of coupon's I've collected so far? I'm also unsure if this problem depends on an underlying prior probability distribution on the number of coupons I've collected; if it does, can this be solved with an arbitrary distribution? One additional part to this question: let's say after the $k$ th one I collect a new coupon; what would the expected number of coupon's I've collected be then?","['bayesian', 'expected-value', 'coupon-collector', 'balls-in-bins', 'probability']"
4342742,"Power Rule Derivatives, $f(x) = x^n, f'(x) = nx^{n-1}.$ Why can $n <0?$","I was watching and reading some online articles, and stubbled upon the power rule when dealing with derivatives. It states $f(x) = x^n$ , $n ≠ 0$ then $f'(x) = nx^{n-1}$ I saw some proofs on this but no one addressed the reason why $n ≠ 0$ . So I tested it out. $f(x) = x^0 = 1$ thus, $f'(x) = 0 \times x^{0-1} = 0$ So I now saw why $n ≠ 0$ , however knowing this, it sparked another question into my mind. What happens when $n$ is negative? Once again I tested this out, $f(x) = x^{-1}$ $f'(x) = -1 \times x^{-1 - 1}$ if you look at the last line you, a question appears, if $x = 0$ then, $f'(x) = -1 \times \frac{1}{0^2}$ Dividing by zero is undefined, thus shouldnt the power rule be not defined for $x = 0$ for values $n < 0$ . (This problem also applies for the case where $n = 0$ ) Can anyone give a explanation for all this stuff? Thx!",['derivatives']
4342758,"What is the probability of throwing all the even numbers with a dice, before you throw any odd number? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I came across this question via a friend, and I am still thinking about it. So we need to throw all even numbers before we throw any odd number. The first throw can be even or odd, that is simple. However, after that, we can throw the same even number, another even number or an odd number. This infinite loop of possibly throwing the same even number an infinite number of times, gets me confused in finding the answer. Could someone help me with finding the answer, using possibly recursion techniques? Kind regards,
Clayton44","['dice', 'probability']"
4342768,Example of atoms with respect to $ \mu$,"I was reading the document ATOMICITY RELATED TO NON-ADDITIVE
INTEGRABILITY and came across this example about atoms relative to a measure: Let $T$ be a countable set, $\mathscr{A} = \{A\subseteq T\colon A \text{ is finite or } A^c \text{ is finite} \}$ and $\mu: \mathscr{A}\to [0,\infty)$ definided for every $A\in \mathscr{A}$ by $$
\mu (A)=\left\{\begin{array}{ll}
0, & \text { if } A \text { is finite } \\
1, & \text { if } A^{c} \text { is finite. }
\end{array}\right.
$$ Then every set $A\in \mathscr{A}$ , such that $A^c$ is finite, is an atom with respect of $\mu$ . But I can't see how it is concluded that every set $A\in \mathscr{A}$ , such that $A^c$ is finite, is an atom with respect of $\mu$ , can someone help me?","['measure-theory', 'probability-theory']"
4342777,"$\int_0^1 fg\geq 0$ for every non negative, continuous $g$ implies $f\geq 0$ a.e.","I'm trying to solve the following problem. Let $f$ be an integrable function in $(0,1)$ . Suppose that $$\int_0^1fg\geq0$$ for any non negative, continuous $g:(0,1)\to\mathbb{R}$ . Prove that $f\geq0$ a.e. in $(0,1)$ . I'm a little unsure on what it is that I must prove in order to conclude that $f\geq0$ . I tried to show that $\int_0^1f^2\geq0$ but I couldn't get very far. I'm seeking hints on how to solve this. Thanks.","['integration', 'measure-theory', 'lebesgue-integral', 'real-analysis', 'continuity']"
4342844,Frattini subgroup of a cyclic group which is not a p group for some prime p,"What can you say about the frattini subgroup of a finite cyclic group which is not a p-group? I am just wandering do I need to check for each individual case or is there any general result for the same. As we know that, in a finite case frattini subgroup is the set of all non-generators of the group. Does this help? I would like to know a general way for seeing the frattini subgroup of finite cyclic group which is not a p-group.","['group-theory', 'cyclic-groups']"
4342869,"What is the maximum amount of ""shore"" tiles in a rectangular grid that has only ""water"" and ""land"" tiles?","I'm not a mathematician or anything of the like, so please forgive me if I'm not using the correct terminology for something. The problem is as follows: Given a rectangular grid that has $m*n$ tiles, where $m$ is the amount of rows and $n$ is the amount of columns in the grid, and knowing that: $1 \leq m \leq 100$ $1 \leq n \leq 100$ Every tile is classified as either water or land The grid can have any amount of water tiles ranging from $0$ to $m*n$ A shore tile is defined as any land tile that has at least 1 of its 4 (or 3 on the edges, or 2 on the corners) adjacent tiles as a water tile What is the maximum amount of shore tiles a grid can have (I'll call it $R$ )? I started working on this by first trying to solve for very small grids and go up from there, so, for a 1x1 grid, $R = 0$ , since there can't be any adjacent tile to that single tile. W: water tile L: land tile $s$ : amount of shore tiles Then, for 1x2 grids: WW WL LL $s=0$ $s=1$ $s=0$ So, for 1x2 (and 2x1) grids, $R = 1$ For 1x3 grids: WWW WWL $s=0$ $s=1$ (ignoring some other possibilities with 1 L, because I'm interested in the maximum value, and $s$ can't be higher than the amount of L in the grid) WLL LWL LLL $s=1$ $s=2$ $s=0$ So, for 1x3 (and 3x1) grids, $R = 2$ (...) For 2x3 grids: WWW WWW WWW WWL WWW WLL WWW LLL WWL LLL LWL LWL WLL LLL LWL LLL LLL LLL $s$ =0 $s$ =1 $s$ =2 $s$ =3 $s$ =3 $s$ =4 $s$ =2 $s$ =3 $s$ =0 (with only 2 rows or columns, $s \leq 3*\text{amount of W's}$ , and reaching the maximum has been confirmed to be possible here) So, for 2x3 (and 3x2) grids, $R = 4$ |m \ n|1|2|3|4|5|6|
|-----|-|-|-|-|-|-|
|  1  |0|1|2|2|3|4|
|  2  |1|2|4|?|?|?|
|  3  |2|4|?|?|?|?|
|  4  |2|?|?|?|?|?|
|  5  |3|?|?|?|?|?|
|  6  |4|?|?|?|?|?| So, up until now $$R = m*n - 1 - \lfloor m*n/4 \rfloor$$ But this is likely not a general formula (right?). Is there a known general solution for mxn grids? And if so, is there an easier way for getting to it than what I'm doing? Edit: reduced amount of examples, tried to fix the table at the end. Edit 2: since it seems like the preview and the actual table don't match, I'll leave the table preformatted for now.",['geometry']
4342873,Calculating the contour integral: $\int_{|z-z_0|=r}\frac{1}{\bar{z}}dz$,"I'm trying to find out what the following contour integral equals to: $$\int_{|z-z_0|=r}\frac{1}{\bar{z}}dz$$ given that $z_0$ is a point in the complex plane, where $|z_0|\neq r >0$ .
Due to the fact that the function is not holomorphic, I'm not able to apply any theorems that require this condition. If I parametrize the contour, I get: $$i\int_0^{2\pi}\frac{re^{2it}}{\bar{z_0}e^{it}+r}dt$$ When $z_0=0$ , the answer is trivial. However, I have difficulty calculating this integral when $z_0$ is any other point. I would appreciate some help.","['complex-analysis', 'complex-integration']"
4342893,Minimum value of $a^2 \cot (10^ \circ)+b^2\cot (70^ \circ)+c^2\cot (130^ \circ)$,"Let $a,b,c$ be real numbers such that $a+b+c=3$ , then find minimum value of $$a^2 \cot (10^ \circ)+b^2\cot (70^ \circ)+c^2\cot (130^ \circ)$$ I have solved many such question using A.M.-G.M. inequality but since $\cot (130^ \circ)$ is negative, hence it cannot be applied here. I also have a result in mind which is $$\cot (60 ^\circ-\theta)\cot (\theta)\cot (60 ^\circ+\theta)=\cot (3\theta)$$ and in this question if we write $
\cot(130^\circ)=-\cot (50^\circ)$ , then above mentioned result can be applied on $\cot (10^ \circ),\cot (70^ \circ),\cot (50^ \circ)$ but I am not able to put everything together and reach the final answer which is given as $\sqrt{27}$ . Any help or hint would be appreciated.","['trigonometry', 'inequality']"
4342917,Is there a model of $Th(\frac{\mathbb{R}}{\mathbb{Z}})$ which is a periodic group?,"Let $L := (+,-,0)$ be the language of abelian groups and let $T = Th(\frac{\mathbb{R}}{\mathbb{Z}})$ . Is there a model of $T$ which is periodic, i.e. every member of the domain has finite order. In model theoretic terms this can be restated as: Is there a model of $T$ which omits the partial type $P(x) = \{nx\neq 0 | n \in \mathbb{N}_0\} \cup T$ ? Since $T$ is complete this is iff $P$ is non-principal. I'm not really sure how I'm supposed to show that $P$ is non-principal in this case ( or in general). Any hints/ideas? Many thanks.","['group-theory', 'logic', 'model-theory']"
4342924,A question about analytic continuation,"Let $\Omega = \{z: \frac{1}{2} < |z| < 2\}$ . For $n = 1,2,3, ...$ let $X_n$ be the set of all $f \in H(\Omega)$ that are nth derivatives of some $g \in H(\Omega)$ . [In other words, $X_n$ is the range of the differential operator $D^n$ with domain $H(\Omega)$ .] (a) Show that $f \in X_1$ if and only if $\int_\gamma f(z) dz = 0$ , where $\gamma$ is the positively oriented unit circle. (b) Show that $f \in X_n$ for every n if and only if $f$ extends to a holomorphic function in $D(0; 2)$ . For (a) $f \in X_1$ that $\int_\gamma f(z) dz = 0$ is easy get from Cauchy Theorem, but I cannot figure out the converse part. Maybe I can define a $F(z) = \int_{[a,z]}f$ Show that F is analytic in $\Omega$ and $F'=f$ But I totally have no idea about the (b), any relation between the analytic continuous and existence of f.",['complex-analysis']
4342938,Subwords of the Thue-Morse Sequence,"In addition to Complexity of Thue-Morse Sequence , I have the following question: Has anyone found a characterization for subwords of Thue–Morse sequence? I.e., for a given binary word, can I (easily for some definition of easy) decide whether it is a subword of the Thue–Morse sequence or not?
Any references (in addition to Brlek and de Luca–Varricchio) are very welcome!","['combinatorics-on-words', 'combinatorics']"
4342988,Question on baby Rudin examples 10.12,"I have two questions: $(a)$ . Fix $a > 0$ and $b > 0$ and define $\gamma(t) = (a\cos(t),b\sin(t))$ where $(0\leq t \leq 2\pi)$ . So that $\gamma$ is a closed curve in $R^2$ . (Its range is an ellipse.) Then $$\int_\gamma x dy = \int_0^{2\pi} ab \cos^2(t)dt = \pi ab \tag{1}$$ $(b)$ . Let $D$ be the $3$ -call defined by $0 \leq r \leq 1$ , $0 \leq \theta \leq \pi$ and $0 \leq \varphi \leq 2\pi$ . Define $\phi ( r,\theta,\varphi ) = (x,y,z)$ , where $x = r\sin\theta \cos\varphi$ , $y = r\sin\theta \sin\varphi$ , $z = r\cos\theta$ Then $$
J_\phi (r,\theta,\varphi) = \frac{\partial(x,y,z)}{\partial(r,\theta,\varphi)} =  r^2\sin\theta.
$$ Hence $$
\int_{\phi} dx \land dy \land dz = \int_D J_\phi\ \color{red}{dr\,d\theta\, d\varphi} = \frac{4\pi}{3}. \tag{2}
$$ I don't understand how do we get $(1)$ and $(2)$ . (in the $(2)$ I also don't understand why is $\int_D J_{\phi}$ equal of $\frac{4\pi}{3}$ ). Any help would be appreciated.","['integration', 'multivariable-calculus', 'differential-forms', 'real-analysis']"
4342990,On the space of Carleson measures,"Consider the space $X=\mathcal{CM}(\mathbb{D})$ of finite Borel measures on $\mathbb{D}$ whose total variation is a Carleson measure. It is easy to see that this space is a vector space. Moreover, given $\mu\in X$ we can define $\|\mu\|:=B(|\mu|)$ , where $$B(|\mu|):=
\sup_{z_0\in \mathbb{D}}\int_{\mathbb{D}}\frac{1-|z_0|^2}{|1-\overline{z}_0z|^2}\text{d}|\mu|(z)$$ with this norm equipped, the space is a Banach space. Now, Carleson measures are important for many different reasons, so it is normal to try and study the banach space properties of this space. However, I have not been able to find any reference on this problem. in brief, my question is:
What is known about the Banach space properties of this space? Any reference is welcome.","['measure-theory', 'functional-analysis', 'reference-request']"
4342996,Hoeffding type inequality for bounding deviation of a sequence,"I'm am trying to work out an Hoeffding type inequality for upper bounding $$\mathbb{P} \left\{ \bigcap_{n=1}^N \{S_n - \mathbb{E}[S_n] \geq nt\} \right\} $$ where $S_n = \sum_{i=1}^n X_i$ , $X_k$ are iid (note that $S_{n+1}$ and $S_n$ are dependent). We can assume that $X_k$ has bounded support for applying Hoeffding inequality but I can't figure out how to do it. My approach was to consider the complement of the event and to try and use union bound but that's too weak and I end up with a trivial upper bound greater than $1$ .","['inequality', 'probability-theory', 'probability']"
4343045,How to calculate the radius of the curved side of a triangle?,"In this image, only having these dimensions, is it possible to calculate the radius of the circle (of the arc of the line AB)? The centre of the circle is in the same X position as the line AC, but its Y position is unknown, How can I do it? Sorry if it's a duplicate question, I could not find how to do this,","['triangles', 'circles', 'geometry']"
4343048,Why is the following statement true about symmetric differences of Subsets?,"Let $X$ be a non-empty set. Then, for a finite amount of subsets $A_1, A_2, ...,A_m \in X$ we define $S := A_1 \Delta A_2 \Delta ...  \Delta A_m$ as the symmetric difference of all $A_k$ with $ k \in I:= [1,...,m]$ Then:
A point $x\in X$ is element of S, when x is element of an odd index number k of $A_k$ So, when the Quantity of Indices $ k \in {1,...,m} $ with $ x\in A_k$ is odd. why is this statement true? I mean x can be in the intersection of 3 subsets of $X$ and wouldn't be in the symmetric difference. Is there something I am not noticing?","['elementary-set-theory', 'combinatorics']"
4343053,Is my example of a function which isn't mesurable on the completions of the sigma algebras correct?,"I have the following Problem: We take $(\Omega_1,A_1,\mu_1), (\Omega_1,A_1,\mu_1)$ be mesure spaces and $f: \Omega_1 \rightarrow \Omega_2$ be a mesurable map. The question is if the map $f$ is always $A_1^*, A_2^*$ mesurable where $A_i^*$ are the completions of the sigma algebras? I have worked out the following solution but I'm not really sure if this works. I take $\Omega_1=\Omega_2=\mathbb{N}$ , $A_1=A_2=\{\emptyset, \mathbb{N}\}$ and $f(x)=x$ be the identity. Furthermore we take $\mu_1(X)=|X|$ if $X$ is finite and otherwise $\infty$ and $\mu_2(X)=0$ . We remark that these are indeed measures and f is mesurable on these sigma algebras. But now I get thet $A_2^*=P(\mathbb{N})$ and $A_1^*=\{\emptyset,\mathbb{N}\}$ . Since $\{1\}\in A_2^*$ we have $$f^{-1}(\{1\})=\{1\} \notin A_1^*$$ which shows that f is not mesurable on the completitions. But does this work? Sorry there are some guys who voted my question, does this mean to you also that it works or is it only because you liked the question?","['measure-theory', 'solution-verification', 'measurable-functions']"
4343100,"Proving that if $(X_t)_{t\geq0}$ and $(Y_t)_{t \geq0}$ are continuous and have the same marginal distributions, then $P_\mathbb{X}=P_\mathbb{Y}$.","Let $(X_t)_{t\geq0}$ and $(Y_t)_{t \geq0}$ denote two continuous stochastic processes on a probability space $(\Omega, \mathcal{F}, P)$ and let $C$ denote space of continuous functions from $[0,\infty)$ to $\mathbb{R}$ . Let $\pi_x\colon C \rightarrow \mathbb{R}$ given by $\pi_x(f)=f(x)$ and equip $C$ with the sigma algebra $\mathcal{E} = \sigma(\{\pi_x : x\geq 0\})$ . Consider the now the $\mathcal{F}$ - $\mathcal{E} $ -measurable mappings $\mathbb{X}, \mathbb{Y} \colon \Omega \rightarrow C$ given by $$
\omega \mapsto X_{(\cdot)}(\omega) \quad \text{and} \quad \omega \mapsto Y_{(\cdot)}(\omega).
$$ I want to prove that if $(X_t)_{t\geq0}$ and $(Y_t)_{t \geq0}$ have the same marginal distributions, then $P_\mathbb{X}=P_\mathbb{Y}$ . My progress: Supposing that $(X_t)_{t\geq0}$ and $(Y_t)_{t \geq0}$ have the same marginal distributions, then for $t_1,\dots, t_n, A_1,\dots,A_n$ $$
P(X_{t_1}\in A_{1},\dots, X_{t_n} \in A_{n})=P(Y_{t_1}\in A_{1},\dots, Y_{t_n} \in A_{n})
$$ by definition. So working from this, we get that $$
\bigcap_{k=1}^n \{X_{t_k} \in A_k\} = \bigcap_{k=1}^n \{\pi_{t_k} \circ\mathbb{X} \in A_k\} = \bigcap_{k=1}^n \{\mathbb{X} \in \pi_{t_k}^{-1}(A_k)\} = \{\mathbb{X} \in \bigcap_{k=1}^n \pi_{t_k}^{-1}(A_k) \}
$$ but this is where I become stuck. We want to show $P(\mathbb{X} \in B) =P(\mathbb{Y} \in B) $ where $B \in \mathcal{B}$ , an intersection stable generator set of $\mathcal{E}$ . So the question is if $$
\{\bigcap_{k=1}^n \pi_{t_k}^{-1}(A_k) \colon n \in \mathbb{N}, t_1,\dots,t_n \in \mathbb{R}, A_1,\dots, A_n \in \mathcal{B}(\mathbb{R}) \}
$$ is an intersection stable generating set of $\mathcal{E}$ .
Can anyone help me? Am I on the right track?
Also my textbook claims this is only true if the processes are continuous but I can't seem to find anywhere where I would use this continuity...","['stochastic-processes', 'measure-theory', 'probability-theory']"
4343113,When is the splitting field of $x^n-a$ abelian?,"Let $K$ be a number field and $a \in K^\times$ an element that is not an $n$ -th power.  Is it true that the splitting field of $x^n-a$ is abelian if and only if $\zeta_n \in K$ ? I know one direction is true: if $\zeta_n \in K$ , then $K(\sqrt[n]{a})$ is the splitting field, hence every automorphism is determined by the image $\sqrt[n]{a} \mapsto \zeta_n^k \sqrt[n]{a} $ . Therefore $G$ is a subgroup of $\mathbb{Z}/n\mathbb{Z}$ . The opposite direction is harder.
In this case, I would love to say that the extension $K(\sqrt[n]{a})$ is not normal (thus, corresponding to a non-abelian subgroup of $G$ ). If it were normal, it would contain all roots of the minimal polynomial of $\sqrt[n]{a}$ , in particular some $\zeta_n^r\sqrt[n]{a}$ and their quotient $\zeta_n^r$ . If $n=p$ is prime, this provides a contradiction, since the dregee of $K(\zeta_p)/K$ is prime to $p$ , which is the degree of $K(\sqrt[n]{a})/K$ . In the general case two problems arise: if $r$ is not prime to $n$ , then $\zeta_n^r$ is allowed to be in $K$ and $K(\sqrt[n]{a})$ might be a splitting field! if $r$ is prime to $n$ (or, say, we decide we contempt ourselves with the case of $n$ prime) we conclude that $K(\sqrt[n]{a})$ is the splitting field of $x^n-a$ , but I am not sure how to exclude the possibility Any idea?","['field-theory', 'number-theory', 'galois-theory', 'kummer-theory']"
4343130,"How ""same"" are two isomorphic groups?","From what I understand about isomorphisms is that two isomorphic groups are the same groups. They may have different names for the same elements and the operation. But the point is that the groups are same since their elements combine the same way. So if $G \cong G'$ then every group property about $G$ also holds for $G'$ , am I correct? Now my question is— Can I interchange $G$ and $G'$ whenever and wherever I want? I thought the answer was obviously yes but... now I'm not sure. For example: $\mathbb{Z} \cong \mathbb{2Z}$ so shouldn't $\mathbb{Z}/\mathbb{Z} = \mathbb{Z}/\mathbb{2Z}$ under the group operation $(a+H) + (b +H) = (a+b) + H$ ? where $H$ is either $\mathbb{Z}$ or $\mathbb{2Z}$ since both are the same groups. But that's clearly not the case as $\mathbb{Z}/\mathbb{Z} = \{0\}$ but $\mathbb{Z}/\mathbb{2Z}=\{0,1\}$ So where does one draw the line between two isomorphic groups? How ""same"" are two isomorphic groups? I'm very confused.","['group-theory', 'group-isomorphism']"
4343144,"Critique my proof of: Suppose $A$, $B$, $C$, and $D$ are sets. Prove that $(A \times B) \cup (C \times D) \subseteq (A \cup C) \times (B \cup D)$.","Critique my proof on correctness, structure, etc. Proof. Let $p = (x,y) \in (A \times B) \cup (C \times D)$ . Thus, $(x, y) \in (A \times B)$ or $(x, y) \in (C \times D)$ . Case #1 Suppose $(x, y) \in (A \times B)$ . By definition of cartesian product, $x \in A$ and $y \in B$ . It follows that $x \in (A \cup C)$ and $y \in (B \cup D)$ by definition of union. Case #2 Suppose $(x, y) \in (C \times D)$ . By definition of cartesian product, $x \in C$ and $y \in D$ . It follows that $x \in A \cup C$ and $y \in C \cup D$ by definition of union. $\therefore$ Because $(x, y)$ is an arbitrary element of $(A \times B) \cup (C \times D)$ , $(A \times B) \cup (C \times D) \subseteq (A \cup C) \times (B \cup D)$ .","['elementary-set-theory', 'proof-writing', 'solution-verification']"
4343153,Conditional distribution function for two standard normal variables,"Let $U,V$ have a bivariate normal distribution with joint density $f_{u,v}(u,v)=\frac{1}{2\pi\sqrt{1-\rho^2}}\exp\left(-\frac{u^2+v^2-2\rho uv}{2(1-\rho^2)}\right)$ where $\rho\in(-1,1)$ is the correlation coefficient. I want to show that the conditional distribution of $U$ given $V=v$ is distributed as $N(\rho v,1-\rho^2)$ for all $v\in\mathbb{R}$ . We are allowed to assume $U,V$ are $N(0,1)$ variables. My attempt: By definition of the conditional density function we have $f_{u|v}(u|v)=\frac{f_{u,v}(u,v)}{f_v(v)}=\frac{\frac{1}{2\pi\sqrt{1-\rho^2}}\exp(-\frac{u^2+v^2-2\rho uv}{2(1-\rho^2)})}{\frac{1}{\sqrt{2\pi}}\exp(-\frac{v^2}{2})}$ $$=\frac{1}{\sqrt{1-\rho^2}}\exp\left(-\frac{(\rho v)^2+u^2-2\rho uv}{2(1-\rho^2)}\right)$$ I know I basically need to show this is the density function of a $N(\rho v,1-\rho^2)$ variable, but I am having problems with this - if we read off the mean and variance we should have $2\sigma^2=2(1-\rho^2)$ and so $\sigma^2=1-\rho^2$ , and the mean is $\rho v$ . But in the very first part before the exponent, surely we should have $\frac{1}{\sigma\sqrt{2\pi}}$ ? As the current form for my solution is incompatible with this. Any help would be really useful.","['statistics', 'solution-verification', 'probability-theory', 'probability']"
4343186,"Elementary proof that $\sum_{j=1}^{n} \prod_{k \neq j} \frac{1}{1+(a_j - a_k + i)^2} \in \mathbb{R}$ for $a_1, \dots, a_n \in \mathbb{R}$ distinct","By a straightforward contour integral, one can show that for $a_1, \dots, a_n \in \mathbb{R}$ distinct, we have $$\frac{1}{\pi} \int_{-\infty}^{\infty} \prod_{j=1}^{n} \frac{1}{1+(x-a_j)^2} \, dx = \sum_{j=1}^{n} \prod_{k \neq j} \frac{1}{1+(a_j - a_k  + i)^2}$$ and therefore the latter sum is real-valued. Is there an elementary (or at least purely algebraic) way to show this, without using complex analysis?","['complex-analysis', 'abstract-algebra', 'complex-numbers']"
4343215,"If sequences $A$ and $B$ satisfy $A,B=B,A$ then $A$ and $B$ are concatenations of the same sequence","If $A$ and $B$ are finite sequences and $A,B=B,A$ (where the comma denotes the concatenation of sequences), then both $A$ and $B$ are repetitions of some sequence $C$ . Let $A=\left(a_i\right)_{i=1}^m$ and $B=\left(b_i\right)_{i=1}^n$ , then the condition $$A,B=B,A$$ is equivalent to $$a_1,\ldots, a_m, b_1,\ldots,b_n=b_1,\ldots, b_n, a_1,\ldots, a_m .$$ If $m=n$ then we obtain $A=B$ , in which case we can just take $C=A$ . On the other hand, if $m<n$ , then we obtain $b_i=a_i$ for $i\le m$ and $b_{m+k}=b_k$ for $1\le k \le n-m.$ At this point, we have some $b$ 's which have two constraints (if $i\le \min(m, n-m)$ then $b_i=a_i=b_{n-i}$ ) and I am unsure of how to identify the sequence $C$ .","['discrete-mathematics', 'sequences-and-series']"
4343249,Why is my reasoning incorrect - probability?,"In a variant of Russian Roulette, where you put 2 bullets in 2 adjacent chambers, like that: Image credit: Brilliant.org Now, first person shoots and survives, you are the second.
The question is: In which scenario are you more likely to survive: You spin the barrel again, assuming a random spin(each chamber has equal probability). Shot, without spinning. I have tried solving it like that:
Even though I have gotten the correct result I was reasoning incorrectly
I have calculated the probability of 1-st scenario and got 1/3(2 possible ways of killing, 6 barrels), this gives the chance of dying if spin. Then the probability of 2nd scenario, here I got the wrong result. P(dying in second scenario) = P(1st surviving)*P(you being hit) = $$ \frac{4}{6} * \frac25 = \frac4{15}$$ Which is approximately 0.27. Not to forget I have also thought that this answer gives the P(dying), but I need P(dying given 1st survived). So, I thought that I need to calculate how big is the chance of this specific outcome of 2nd dying if first survived. To do that I divided it by 2/3 - because that was the probability of the first one surviving. Also, I don't really know why we are dividing, probability by probability. But the correct answer is 0.25. Reasoning like that: There are 4 ways to get the specific result, and only 1 way this could happen.","['problem-solving', 'probability-theory', 'probability']"
4343295,Solutions for $A^2=B$,Show that there exists a neighborhood $U$ of $I$ in $\mbox{Mat}(2 \times 2)$ such that for all $B\in U$ there are at least two solutions in $\mbox{Mat}(2 \times 2)$ for the equation $A^2 = B$ . I have this question for homework and I would be happy to get a hint.  I think it uses the implicit function theorem.,"['matrices', 'calculus', 'matrix-calculus', 'implicit-function-theorem', 'matrix-equations']"
4343308,Construction of derivative as ratio of determinants related to simultaneous system of implicit functions,This is Example C in section 1.1 from Advanced Calculus (2nd ed) by David Widder. $$\begin{cases} v + \log u = xy \\ u + \log v = x - y \end{cases}$$ $$\begin{cases} \frac{1}{u} \frac{\partial u}{\partial x} + \frac{\partial v}{\partial x} = y \\ \frac{1}{v} \frac{\partial v}{\partial x} + \frac{\partial u}{\partial x} = 1 \end{cases}$$ $$\frac{\partial u}{\partial v} = \frac{\begin{vmatrix} yu & u \\ v & 1 \end{vmatrix}}{\begin{vmatrix} 1 & u \\ v & 1 \end{vmatrix}} = \frac{u(y-v)}{1-uv}$$ How does the author come up with the ratio of determinants in the third equation?,"['systems-of-equations', 'determinant', 'multivariable-calculus', 'implicit-differentiation', 'partial-derivative']"
4343315,Why does the GroupNames.org table of transitive groups omit $S_6$ and $S_7$?,"Obviously $S_n$ s are all transitive. But GroupNames.org's ""Transitive groups of degree up to 31"" table seems not to include $S_6$ , $S_7$ . Tell me why. (And I also don't figure out reason why $C_{23}\rtimes C_{22}$ is not in the table..?) Sorry if I make elementary mistakes.","['symmetric-groups', 'group-theory']"
4343318,When is the smallest point on a hull a convex combination of the smallest vertices?,"Let $x_1, \dots, x_n\in\mathbb{R}^d$ be a finite set of points and denote the convex hull by $H$ . Assume that $0\not\in H$ and also that each $x_i$ is an extreme point, meaning that it cannot be expressed as a convex combination of the remaining points. Consider the smallest element in the hull $$x^* := \arg\min_{x \in H} |x|^2$$ By Caratheodory's theorem, $x^*$ can be expressed as a convex combination of $d$ of the points $x_1, \dots, x_n$ . Is it true that $x^*$ is a convex combination of the $d$ smallest points ? While this seems like a plausible hypothesis, the answer is no. For example, consider $x_1=(2,0), x_2=(0,1)$ and $x_3=(2/5+\epsilon,4/5+\epsilon)$ . It's easy to see that $x^*=(2/5,4/5)$ , but $x^*$ cannot be written as a convex combination of $x_2$ and $x_3$ . However in this counterexample, the points are nearly co-linear. So it seems possible that the statement could be true assuming that the points are sufficiently ""generic."" So I will reformulate the original question: Is there a sufficient condition which implies that $x^*$ is a convex combination of the $d$ smallest points? If not, is it at least true with high probability under reasonable sampling assumptions?","['euclidean-geometry', 'convex-hulls', 'convex-geometry', 'geometry', 'convex-analysis']"
4343335,Bounds on Gaussian process posterior variance.,"This is in the context of Gaussian process models where, the posterior variance (given observations at $X = \{x_1, \ldots, x_n\}$ ) has the following form $\sigma_n^2(x)=k(x,x) - \mathbf{k}(X, x)^T \mathbf{K}_n^{-1} \mathbf{k}(X, x)$ , where $k(\cdot, \cdot)$ is a positive definite covariance kernel, $\mathbf{k}(X, x)$ is the vector $[k(x_1, x), \ldots, k(x_n, x)]$ , and $\mathbf{K}$ is an $n\times n$ postive definite matrix defined as $\mathbf{K}_{ij} = k(x_i, x_j)$ . Are there any existing works that discuss the rate of convergence of $\sigma_n^2(x)$ as $n \rightarrow \infty$ or some sort of an upper bound, e.g., (for a finite $n$ ) $\sigma_n^2(x) \leq \mathcal{O} ( \frac{1}{log(n)} )$ ?","['linear-algebra', 'analysis', 'asymptotics']"
4343353,"Closed-form for $\sum_{n=1}^{\infty} \left(m n \, \text{arccoth} \, (m n) - 1\right)$","I'm looking for a closed-form for the following sum: $$\sum_{n=1}^{\infty} \left(m n \, \text{arccoth} \, (m n) - 1\right)$$ for $|m|>1.$ In a previous question of mine, the following similar sum was determined: $$\sum_{n=1}^{\infty} (-1)^n \left(m n \, \text{arccoth} \, (m n) - 1\right)=\frac{1}{2}+\frac{1}{2} \log \left|\cot\left(\frac{\pi}{2m}\right)\right|+\frac{m}{2\pi} \left(\frac{1}{2}\text{Cl}_2\left(\frac{2\pi}{m}\right)-2\text{Cl}_2\left(\frac{\pi}{m}\right)\right)$$ for $|m|>1,$ where $\text{Cl}_2$ is the Clausen function of order 2. I determined the following closed-forms for example as mentioned in that question: $$\sum_{n=1}^{\infty} \left( 4n \, \text{arccoth} \, (4n)-1\right) = \frac{1}{2} - \frac{G}{\pi}- \frac{1}{4} \ln (2)$$ $$\sum_{n=1}^{\infty} \left(6n \, \text{arccoth} \, (6n) - 1\right) = \frac{1}{2} - \frac{3}{2\pi} \, \text{Cl}_2 \left( \frac{\pi}{3}\right)$$ $$\sum_{n=1}^{\infty} \left( 8n \, \text{arccoth} \, (8n) - 1\right) = \frac{1}{2} - \frac{2}{\pi} \, \text{Cl}_2 \, \left(\frac{\pi}{4}\right) - \frac{1}{4} \ln (2-\sqrt{2})$$ I suspect a similar method to that used by @skbmoore involving the Barnes G function might be applicable. Any help would be much appreciated. Here is my attempt: $$S(m) := \sum_{n=1}^{\infty} \left(m n \, \text{arccoth} \, (m n) - 1\right) = \frac{m}{2} \log \left( \prod_{n=1}^{\infty} \frac{1}{e} \left(\frac{1+1/(m n)}{1-1/(m n)}\right)^{n}\right)\\ = \frac{1}{2} + \frac{m}{2} \zeta' \left(-1,1-\frac{1}{m}\right)-\frac{m}{2}\zeta' \left(-1,1+\frac{1}{m}\right)+\frac{1}{2} \zeta' \left(0,1-\frac{1}{m}\right)+\frac{1}{2} \zeta' \left(0,1+\frac{1}{m}\right) \\ =\frac{1}{2} + \frac{m}{2} \left(\zeta' \left(-1,1-\frac{1}{m}\right)-\zeta' \left(-1,1+\frac{1}{m}\right)\right) \\+ \frac{1}{2} \ln\left( \Gamma \left(1-\frac{1}{m}\right)\Gamma \left(1+\frac{1}{m}\right)\right) - \frac{1}{2}\ln (2\pi) \\=\frac{1}{2} + \frac{m}{2} \left(\zeta' \left(-1,1-\frac{1}{m}\right)-\zeta' \left(-1,1+\frac{1}{m}\right)\right) + \frac{1}{2} \ln\left( \frac{\pi}{m} \csc \left(\frac{\pi}{m}\right)\right) - \frac{1}{2}\ln (2\pi)$$ However, I would like to write the solution in terms of the Clausen function if possible, like in the alternating sum, but I cannot see how to do that.","['special-functions', 'analysis', 'real-analysis', 'calculus', 'sequences-and-series']"
4343366,Proof of a closed-form of $\prod_{n=1}^{\infty} \frac{1}{e} \left(1+\frac{1}{3n}\right)^{3n+1/2}$,"I'm looking for a proof of the following equality: $$\prod_{n=1}^{\infty} \frac{1}{e} \left(1+\frac{1}{3n}\right)^{3n+1/2}=\sqrt{\frac{\Gamma\left(\frac{1}{3}\right)}{2\pi}}\frac{3^{13/24} \exp \left[1+\frac{2\pi^2-3\psi_1 \left(\frac{1}{3}\right)}{12\pi \sqrt{3}} \right]}{A^4}$$ Where $\psi_1$ is the trigamma function, and $A$ is the Glaisher-Kinkelin constant. This product is the last entry of this Wolfram Mathworld page. The product is stated to have been found by Gosper, however, his proof is not listed in the references. I have checked the OEIS entry of its decimal expansion also, however, the closed-form is not referenced there either. Assuming, Gosper refers to Bill Gosper, nothing about this product is stated on his Wikipedia page either.","['integration', 'analysis', 'calculus', 'sequences-and-series', 'infinite-product']"
4343393,Why a 'collection' of sets and not a 'set' of sets in sigma-algebra,"All the sources I've checked speak of 'a collection', say $\mathcal{F}$ , of sets from some set $X$ , and then go on to write things like: If $F\in\mathcal{F}$ then $F^c\in F$ , and so on. Is it just convention in measure theory to speak of collections of sets instead of sets of sets and to use $\in$ instead of $\subset$ when referring to members in the collection, OR, is there something more fundamental about collections that I'm missing?","['measure-theory', 'terminology']"
4343397,What is the difference between a two sample t-test and a paired t-test?,"I have the following question from AP statistics: Two friends were curious if it was faster to use the drive-thru or order at the counter at their favorite fast food restaurant. For 555 different visits, one of them ordered at the counter while the other used the drive-thru (determined by a coin toss). Each person ordered the same meal at every visit. They want to test if these results suggest a significant difference in the average time between ordering at the counter and ordering in the drive-thru. Assume that the necessary conditions for inference were met. Which of these is the most appropriate test and alternative hypothesis? A) Paired t-test with alternative hypothesis: $\mu_{counter} - \mu_{drive-thru} > 0$ B) Paired t-test with alternative hypothesis: $\mu_{counter} - \mu_{drive-thru} \neq 0$ C) Two-sample t-test with alternative hypothesis: $\mu_{counter} > \mu_{drive-thru}$ D) Two-sample t-test with alternative hypothesis: $\mu_{counter} \neq \mu_{drive-thru}$ E) Two-sample t-test with alternative hypothesis: $\mu_{counter} < \mu_{drive-thru}$ It is easy to exclude A, C, E and I am just struggling with whether it should be a two-sample t-test or a paired t-test. I know the difference between them is that a two-sample t-test gets data from two different group and paired t-test gets data from one group. The correct answer for this question is B which means this is a paired t-test, but this question states that 'one of them ordered at the counter while the other used the drive-thru."" Isn't that considered as two groups and this should be considered as two-sample t-test? Also, what is the more clear difference between a two-sample t test and a paired t-test? I am very confused with that. Thanks for any responses! *Sorry for the bad format, I don't really know how to type those symbols.",['statistics']
4343453,Why is coin tossing combination *without* repetition?,"As per the title, for a traditional statistics question like: Find the probability of landing 7 heads in 10 throws of fair coin, P(head) = 0.5 No problems with this being a combination (as opposed to a permutation), but I cannot convince myself why it's the WITHOUT repetition sub category of combinations. Thus allowing one to use the Binomial Distribution via nCr. As opposed to using the n+r-1Cr distribution for WITH repetition. What exactly does ""without repetition"" physically mean in this real life example?","['permutations', 'statistics', 'combinatorics', 'combinations']"
4343484,Solution of simultaneous equations to get desired value,"Let $a,b,c,d \in R$ and $$a \sec (200 ^\circ)-c \tan(200 ^\circ)=d$$ $$b \sec(200 ^\circ)+d \tan (200 ^\circ)=c$$ If $\dfrac{a^2+b^2+c^2+d^2}{ac-bd}=\lambda \csc(200 ^ \circ)$ , then find the value of $\lambda$ . I found values of $\sec(200 ^\circ)$ and $\tan(200 ^\circ)$ in terms of $a,b,c,d$ which are $\sec(200 ^\circ)=\dfrac{c^2+d^2}{ad+bc}$ and $\tan(200 ^\circ)=\dfrac{ac-bd}{ad+bc}$ and which ultimately yielded $\csc(200 ^\circ)=\dfrac{c^2+d^2}{ac-bd}$ but I cannot proceed further. How should I bring $a^2+b^2$ into picture and ultimately find $\lambda$ .","['algebra-precalculus', 'systems-of-equations', 'trigonometry']"
4343500,What does it mean to be in the same probability space?,"Sometimes I see the expression ""two random variables are defined on the same probability space $(\Omega,F,P)$ "", and I'm curious what it means to be in the same probability space. Does it mean the same as being in the same sample space $(\Omega)$ ? For example, let's say I have an object flying along the x-axis, and I pin one point as the x-coordinate, however, the flying object can be anywhere on the y-axis and on the z-axis. So two probability distributions are defined as [ $g(y) dy$ ] and [ $h(z) dz$ ]. And $\int_{-\infty}^\infty g(y)\,dy = 1$ $\int_{-\infty}^\infty h(z)\,dz = 1$ Are the random variables $Y$ and $Z$ defined on the same probability space $(\Omega,F,P)$ ? (It seems like they are in a different sample space..)","['probability-theory', 'random-variables']"
4343542,Understanding / learning how to work with quotient spaces,"When I try to work with quotient spaces in topology, I find myself stuck and confused. I always find that the definition of a quotient space: $$ \tau_{X / \sim}  = \{ V \subseteq X /\sim \, \mid q^{-1}(V) \ \text{is open on} \, X \}$$ Is not really comfortable to use. The definition and the map look so ""clumsy"", I feel like it's difficult to find open or closed sets in such a space. I also had the same problem with product space, but I eventually figured it out by understanding how neighborhoods behave in such spaces. However, in quotient spaces, we don't even have a basis to work with! I think I am missing something crucial with how to work with such spaces. If anybody has a source, or perhaps tips/tricks on how to work with quotient spaces, It'll really help. Thanks to all who respond!","['general-topology', 'quotient-spaces']"
4343566,"Question on $(2, 1+\sqrt{-5})$ as a submodule of $\mathbb{Z}[\sqrt{-5}]$.","Let $R$ be the ring $\mathbb{Z}[\sqrt{-5}]$ and $I$ the ideal generated by $2$ and $1+\sqrt{-5}$ , $I=(2, 1+\sqrt{-5})$ . Show that $I$ is not R-module isomorphic to $R$ but $I\bigoplus I$ is R-module isomorphic to $R^2$ . My attempt thus far: It can be shown that $I$ is not principal, and thus not generated by a single element. Since $R$ is generated by $1$ , if there were an isomorphism $\phi: R \rightarrow I$ , $\phi(1)$ must generate $I$ . By contradiction, $I$ cannot be isomorphic to $R$ . However, I am unable to prove the second part of the question. I see that $R^2$ has rank 2, so if we can find a basis for $I\bigoplus I$ , say $(x,y)$ , then there is a direct isomorphism $\phi: R^2 \rightarrow I \bigoplus I$ , $\phi(1,0)=x$ , $\phi(0,1)=y$ . However, it's not immediately obvious to me what I should take as the basis for $I\bigoplus I$ ; is there a nonconstructive way of showing the two modules are isomorphic?","['free-modules', 'modules', 'ring-theory', 'abstract-algebra', 'ideals']"
4343571,Linear Model and Posterior distribution,"Consider the following linear model: $$
\mathbf{y} = A \mathbf{x} + \sigma\mathbf{z},
$$ where $\mathbf{x} \in \{0,1\}^n$ is an unknown signal, to be recovered; $A \in \mathbb{R}^{m \times n}$ is a (known) linear measurement matrix; $\sigma > 0$ ; and $\mathbf{z} \in \mathbb{R}^{m}$ is i.i.d.
Gaussian noise: $z_1,\dots,z_m \overset{\text{i.i.d.}}{\sim} \mathcal{N}(0,1)$ . Assume a sparse binary prior for $\mathbf{x}$ . Specifically, let $k$ be the expected sparsity and denote $\rho = \frac{k}{n}$ . The coordinates of $\mathbf{x}$ are assumed i.i.d. Bernoulli random variables: $$
x_1,\dots,x_n \overset{\text{i.i.d.}}{\sim} \text{Bernoulli}(\rho).
$$ I want to determine the posterior distribution $$
\mathbb{P}(\mathbf{x} \mid \mathbf{y}) . 
$$ My attempt was to use Bayes theorem, i.e., $$
\mathbb{P}(\mathbf{x} \mid \mathbf{y}) = \frac{\mathbb{P}(\mathbf{y} \mid \mathbf{x}) \cdot \mathbb{P}(\mathbf{x})}{\mathbb{P}(\mathbf{y})}.
$$ Now $\mathbb{P}(\mathbf{x})$ is given by $$
\Pi_{i=1}^n \rho^{x_i}(1 - \rho)^{1-x_i}
$$ I'm having trouble determining the $\mathbb{P}(\mathbf{y} \mid \mathbf{x})$ and $\mathbb{P}(\mathbf{y})$ . I would be very grateful for any help.","['statistics', 'bayesian']"
4343590,Alternative cartesian equation for epicycloid (quatrefoil),"In the problem : Eliminate $\theta$ from the system of equations. $$x\sin\theta-y\cos\theta=-\sin4\theta$$ $$x\cos\theta+y\sin\theta=\frac52-\frac32\cos4\theta$$ it is stated in a previous answer that the resultant is $$x^{10}+5 x^8 y^2+10 x^6 x^4 + 10 x^4 y^6+5 x^2 y^8+y^{10}-705 x^8+12180 x^6 y^2 -24230 x^4 y^4+12180 x^2 y^6-705 y^8+122560 x^6-112320 x^4 y^2 -112320 x^2 y^4 +122560 y^6+599040 x^4-1361920 x^2 y^2 +599040 y^4+327680 x^2+327680 y^2-1048576=0$$ (generated via Mathematica ) which ultimately turned out to be $$\boldsymbol{(x+y)^{2/5}+(x-y)^{2/5}=2}$$ that was accomplished by the parametrization, $$x=\cos(\theta)\,(5-4\cos^4(\theta)),$$ $$y=\sin(\theta)\,(5-4\sin^4(\theta)).$$ That represents the cartesian equation of the evolute of an astroid .(?) With the victory over that problem (thanks to @Claude Leibovici), I was attracted by another similar problem: Eliminate $\theta$ from $4x=5\cos\theta -\cos 5\theta$ and $4y=5\sin\theta -\sin 5\theta$ , where the answer is the equation of an epicycloid . In that question, one can find that $$x=\cos^3(\theta)\,(5-4\cos^2(\theta))$$ $$y=\sin^3(\theta)\,(5-4\sin^2(\theta))$$ which seems almost similar to the aforementioned approach. Also as mentioned in one answer, the eliminant is $$-81 - 45 x^2 + 365 x^4 - 15 x^6 - 480 x^8 + 256 x^{10} - 45 y^2 - 2395 x^2 y^2 - 45 x^4 y^2 - 1920 x^6 y^2 + 1280 x^8 y^2 + 365 y^4 - 45 x^2 y^4 - 2880 x^4 y^4 + 2560 x^6 y^4 - 15 y^6 - 1920 x^2 y^6 + 2560 x^4 y^6 - 480 y^8 + 1280 x^2 y^8 + 256 y^{10}=0$$ (generated via Wolfram|Alpha ) So because of the similarity, there may be a neat solution as before. I tried plugging some possible equations in Wolfram|Alpha and Desmos graphing calculator, seeking for a hint. Yet, I haven't found the exit. Question . Can there be a nice equation for this curve? If it helps, here's a table showing the coefficients of each term of each polynomial (for the ease of comparison). $(x+y)^{2/5}+(x-y)^{2/5}=2$ unknown $x^{10},y^{10}$ 1 256 $x^8,y^8$ -705 -480 $x^6,y^6$ 122560 -15 $x^4,y^4$ 599040 365 $x^2,y^2$ 327680 -45 $x^8y^2,x^2y^8$ 5 1280 $x^6y^4,x^4y^6$ 10 2560 $x^6y^2,x^2y^6$ 12108 -1920 $x^4y^2,x^2y^4$ -112320 -45 $x^2y^2$ -1361920 -2395 $x^4y^4$ -24230 -2880 constant -1048576 -81 Curves: The red curve is the hypocycloid and the other is the epicycloid. The symmetry of these curves is probably implying that they have well formed equations too.","['graphing-functions', 'geometry', 'trigonometry', 'cycloid', 'algebra-precalculus']"
4343596,"if $f: \Omega \to \mathbb{C} \setminus \{0\}$ is holomorphic and $\Omega$ is simply connected, show there is a holomorphic function $g^2 = f$.","I am making exercises to prepare for my exam and came across this one Suppose $\Omega$ is simply connected and $f: \Omega \to \mathbb{C} \setminus \{0\}$ is holomorphic. Show that there is a holomorphic function $g: \Omega \to \mathbb{C}$ such that $$g^2 = f.$$ [ $g$ is a holomorphic branch of the square root of $f$ , and we can write $g$ as $g = f^{1/2}$ . I am a bit stuck on how I am supposed to solve this question. I thought that branches are connected to the complex logarithm, also the theorems in my book that use that $\Omega$ is simply connected use the complex logarithm aswell. But I am not sure on how I could use the logarithm or the exponentials in this question since I want to get the square root of the function.","['complex-analysis', 'analysis', 'logarithms']"
4343603,"$\int_a^bf'=f(b)-f(a)$ if $f'$ is integrable, but not continuous?","Let $a<b$ and $f:(a,b)\to\mathbb R$ be differentiable (i.e. $f'$ exists, but is NOT necessarily continuous). Assuming that $f'$ is Lebesgue integrable , does it still hold that $$\int_a^bf'=f(b)-f(a)?\tag1$$ The claim is clearly true when $f'$ is continuous, since then $(1)$ is simply the second fundamental theorem of calculus. I wasn't able to come up with a couterexample, but I didn't found a reference of the claim either.","['lebesgue-integral', 'analysis', 'real-analysis', 'calculus', 'derivatives']"
4343635,Relationship between the holonomy pseudogroup and holonomy homomorphism (foliation),"First, let me state some basics mainly coming from Introduction to foliations and Lie groupoids written by I. Moerdijk and J. Mrcun. A codimension $q$ foliation $\mathcal{F}$ on a smooth n-manifold $M$ is given by the following data:
An open cover $\mathcal{U}:=\left\{U_{i}\right\}_{i \in I}$ of $\mathrm{M}$ . A $q$ -dimensional smooth manifold $T_{0}$ . For each $U_{i} \in \mathcal{U}$ a submersion $f_{i}: U_{i} \rightarrow T_{0}$ with connected fibers (these fibers are called plaques). For all intersections $U_{i} \cap U_{j} \neq \emptyset$ a local diffeomorphism $\gamma_{i j}$ of $T_{0}$ such that $f_{j}=\gamma_{i j} \circ f_{i}.$ We call $T=\coprod_{U_{i} \in \mathcal{U}} f_{i}\left(U_{i}\right)$ the transverse manifold of $\mathcal{F} .$ The local diffeomorphisms $\gamma_{i j}$ generate a pseudogroup $\Gamma$ of transformations on $T$ (called the holonomy pseudogroup ). The space of leaves $M / \mathcal{F}$ of the foliation $\mathcal{F}$ can be identified with $T / \Gamma$ . Also, for a transversal section $S$ at $x\in L$ one obtains the map $$
\mathrm{hol}^{S}=\mathrm{hol}^{S, S}: \pi_{1}(L, x) \longrightarrow \operatorname{Diff}_{x}(S)
$$ which is a group homomorphism to obtain a homomorphism of groups
hol: $\pi_{1}(L, x) \longrightarrow \operatorname{Diff}_{0}\left(\mathbb{R}^{q}\right)$ which is called the holonomy homomorphism of $L$ , and is determined uniquely up to a coniugation in $\operatorname{Diff}_{0}\left(\mathbb{R}^{q}\right)$ . The motivation for me to compare these two concepts coming from the following statement, (the above book page 26, paragraph -2): For a given foliation $\mathcal{F}$ on $M$ , a Riemannian structure on the normal bundle of $\mathcal{F}$ determines a transverse metric (i.e., $\mathcal{F}$ is Riemann) if and only if this structure is holonomy invariant. One half of this is stated in the following proposition, the other half in Remark $2.7$ (2). And the following proposition should imply the necessariness: Proposition $2.5$ Let $(\mathcal{F}, g)$ be a Riemannian foliation of $M$ . Let $L$ be a leaf of $\mathcal{F}, \alpha$ a path in $L$ , and let $T$ and $S$ be transversal sections of $\mathcal{F}$ with $\alpha(0) \in T$ and $\alpha(1) \in S$ . Then $$
\mathrm{hol}^{S, T}(\alpha):(T, \alpha(0)) \longrightarrow(S, \alpha(1))
$$ As  the authors claimed, the other direction can be proved by Remark 2.7 (2) as follows: Let $\mathcal{F}$ be a foliation of $M$ given by a Haefliger cocycle $\left(U_{i}, s_{i}, \gamma_{i j}\right)$ . If each submersion $s_{i}: U_{i} \rightarrow s_{i}\left(U_{i}\right)$ has connected fibres, then any transverse metric on $(M, \mathcal{F})$ induces a Riemannian metric on $s_{i}\left(U_{i}\right)$ , for any $i$ , such that the diffeomorphisms $\gamma_{i j}$ are isometries. Conversely, if each $s_{i}\left(U_{i}\right)$ is a Riemannian manifold and if each $\gamma_{i j}$ is an isometry, then the pull-back of the Riemannian structure on $s_{i}\left(U_{i}\right)$ along $s_{i}$ gives a transverse metric on $\left(U_{i},\left.\mathcal{F}\right|_{U_{i}}\right)$ , and these transverse metrics amalgamate to a transverse metric on $(M, \mathcal{F})$ . However, I can't see how this happen. So my questions are listed as follows: I think Remark 2.7 (2) is saying $$\mathcal{F} \text{ is Riemann}\iff \text{ transverse manifold } T \text{ has a } \Gamma\text{-invariant Riemannian metric,}$$ am I right? If I understand incorrect for the above question, how can the authors used Remark 2.7 (2) to imply the other direction? Why we call the name holonomy pseudogroup? What is the relationship between the holonomy pseudogroup and holonomy homomorphism, also,  holonomy-invariant and holonomy pseudogroup-invariant?","['foliations', 'fundamental-groups', 'differential-topology', 'algebraic-topology', 'differential-geometry']"
4343638,Integral-sum conversion in the proof that the $\chi^2$ statistic tends to the $\chi^2$ distribution,"I cite the derivation on Wikipedia, here . The focus of that section of the article is to show that the $\chi_p^2$ statistic is asymptotically equivalent to the $\chi^2$ distribution. Let $n$ be the number of observations, $m$ the number of cells and $p_i$ the probability of an observation (according to the null hypothesis of the supposed underlying distribution) falling in the $i$ th cell, $1\le i\le m$ . Let $\{k_i\}$ denote the configuration where $k_i$ occurences are observed in the $i$ th cell. Let $\chi^2_p(\{k_i\},\{p_i\})$ denote the test statistic, and let $\chi^2_p(\{p_i\})$ denote its distribution. For any arbitrary real $T$ , assuming that observations are multinomially distributed by the supposed underlying distribution: $$P(\chi^2_p(\{p_i\})\gt T)=\sum_{\{k_i\}:\chi^2_p(\{k_i\},\{p_i\})\gt T}\frac{n!}{k_1!\cdots k_m!}\prod_{i=1}^mp_i^{k_i}$$ As $n\to\infty$ , one may use Stirling's approximation for the factorial: $$P(\chi^2_p(\{p_i\})\gt T)\sim\sqrt{\frac{2\pi n}{\prod_{i=1}^m2\pi k_i}}\sum_{\{k_i\}:\chi^2_p(\{k_i\},\{p_i\})\gt T}\prod_{i=1}^m\left(\frac{n p_i}{k_i}\right)^{k_i}$$ With the substitution $x_i=\frac{k_i-np_i}{\sqrt{n}},\,1\le i\le m-1$ and noting that $k_m=np_m-\sqrt{n}\sum_{i=1}^{m-1}x_i$ , one finds: $$\begin{align}P(\chi^2_p(\{p_i\})\gt T)&\sim\sqrt{\frac{2\pi n}{\prod_{i=1}^m2\pi k_i}}\sum_{\{x_i\}:\chi^2_p(\{x_i\sqrt{n}+np_i\},\{p_i\})\gt T}\\&\left\{\left(1-\frac{\sum_{i=1}^{m-1}x_i}{p_m\sqrt{n}}\right)^{-(np_m-\sqrt{n}\sum_{i=1}^mx_i)}\prod_{i=1}^{m-1}\left(1+\frac{x_i}{p_i\sqrt{n}}\right)^{-(np_i+x_i\sqrt{n})}\right\}\end{align}$$ Ugly as this is so far, I have no problems. However, as $n\to\infty$ , Wikipedia pass from the above sum to an $(m-1)$ dimensional integral over the $x_i$ , with everything unchanged save for an extra (mystifying) factor of: $$\prod_{i=1}^{m-1}\left(\sqrt{n}\,\mathrm{d}x_i\right)$$ $$\begin{align}P(\chi^2_p(\{p_i\})\gt T)\sim\sqrt{\frac{2\pi n}{\prod_{i=1}^m2\pi k_i}}\color{red}{\int_{\chi^2_p(\{x_i\sqrt{n}+np_i\},\{p_i\})\gt T}}\hspace{100pt}\\\left\{\left(1-\frac{\sum_{i=1}^{m-1}x_i}{p_m\sqrt{n}}\right)^{-(np_m-\sqrt{n}\sum_{i=1}^mx_i)}\prod_{i=1}^{m-1}\left(1+\frac{x_i}{p_i\sqrt{n}}\right)^{-(np_i+x_i\sqrt{n})}\right\}\color{red}{\left\{\prod_{i=1}^{m-1}\sqrt{n}\,\mathrm{d}x_i\right\}}\end{align}$$ This step I don't understand. That extra factor suggests that $\mathrm{d}x_i\sim\frac{1}{\sqrt{n}}$ , but how can this be formalised? Or is it that, under the null hypothesis, $k_i-np_i\approx0$ as $n\to\infty$ ? In passing from a sum over discrete variables to a continuous integral, work must be done and the article's authors have not provided it. If anyone could help me see how the above sum transforms to an $m-1$ dimensional Riemann sum, with limiting difference $\sqrt{n}\mathrm{d}x_i$ , that would be greatly appreciated. I understand that we can change our perspective and view the $x_i$ as a free ranging variable. I guess I just don't get the meaning of the symbol $\mathrm{d}x_i$ in this context.","['integration', 'statistics', 'chi-squared', 'solution-verification', 'riemann-sum']"
4343658,Can the following sum of random variables be normally distributed?,"Consider $ N_{1},N_{2} $ independent random variables which both distribute normally, both with zero expectation (and maybe different variance). Let $ \theta\sim U[0,2\pi] $ be uniformly distributed random variable, which is independent of $N_1$ and $N_2$ .
Define: $$ \begin{cases}
X=N_{1}\sin\left(\theta\right)\\
Y=N_{2}\cos\left(\theta\right)
\end{cases} $$ Next, define: $$ Z=X+Y\overset{\text{i.e}}{=}N_{1}\sin\left(\theta\right)+N_{2}\cos\left(\theta\right) $$ Does $Z$ distributes normally? I'd really appreciate a clarification - is it correct or wrong? I think that its wrong, and I have wrote a proof, but I feel like something's wrong with it and its actually correct.
Anyway, here's what I have done: My work: It is easy to note that $Z$ has zero expectation, and if we will asssume it has a gaussian distribution, say $ \mathcal{N}\left(0,\sigma^{2}\right) $ , then it would have to hold the following moments well known equation: $$ \mathbb{E}\left[Z^{n}\right]=\begin{cases}
1\cdot3\cdot5\cdot....\cdot\left(n-1\right)\cdot\sigma^{n} & n\thinspace\thinspace\text{even}\\
0 & n\thinspace\thinspace\text{odd}
\end{cases} $$ Now, say $ \mathbb{E}\left[N_{1}^{2}\right]:=\sigma_{1}^{2},\thinspace\thinspace\thinspace\thinspace\mathbb{E}\left[N_{2}^{2}\right]=\sigma_{2}^{2} $ Then $ \mathbb{E}\left[X^{2}\right]=\mathbb{E}\left[N_{1}^{2}\right]\mathbb{E}\left[\sin^{2}\theta\right]=\frac{1}{2}\sigma_{1}^{2} $ And $ \mathbb{E}\left[Y^{2}\right]=\mathbb{E}\left[N_{2}^{2}\right]\mathbb{E}\left[\cos^{2}\theta\right]=\frac{1}{2}\sigma_{2}^{2} $ . Also, since $N_1$ follows the moments equation I wrote, we have $ \mathbb{E}\left[X^{4}\right]=\underset{3\sigma_{1}^{2}}{\underbrace{\mathbb{E}\left[N_{1}^{4}\right]}}\underset{\frac{3}{8}}{\underbrace{\mathbb{E}\left[\sin^{4}\theta\right]}}=\frac{3}{8}\cdot3\sigma_{1}^{2}$ And in the same way: $ \mathbb{E}\left[Y^{4}\right]=\frac{3}{8}\cdot3\sigma_{2}^{2} $ . Next, note that $ \mathbb{E}\left[XY\right]=\mathbb{E}\left[N_{1}\right]\mathbb{E}\left[N_{2}\right]\mathbb{E}\left[\sin\theta\cos\theta\right]=0 $ . Next, note that $ Z^{2}=X^{2}+Y^{2}+2XY $ And thus $ \mathbb{E}\left[Z^{2}\right]=\frac{1}{2}\left(\sigma_{1}^{2}+\sigma_{2}^{2}\right) $ . Since $Z$ holds the moments equation we must have $ \mathbb{E}\left[Z^{4}\right]=\frac{3}{4}\left(\sigma_{1}^{2}+\sigma_{2}^{2}\right)^{2} $ But note that: $ Z^{4}=X^{4}+Y^{4}+2X^{2}Y^{2}+4\left(X^{2}+Y^{2}\right)XY+4X^{2}Y^{2} $ And $ \mathbb{E}\left[4\left(X^{2}+Y^{2}\right)XY\right]=4\mathbb{E}\left[X^{3}Y\right]+4\mathbb{E}\left[Y^{3}X\right]=4\mathbb{E}\left[X^{3}\right]\mathbb{E}\left[Y\right]+4\mathbb{E}\left[Y^{3}\right]\mathbb{E}\left[X\right]=0 $ So that $$ \mathbb{E}\left[Z^{4}\right]=\mathbb{E}\left[X^{4}\right]+\mathbb{E}\left[Y^{4}\right]+2\mathbb{E}\left[X^{2}\right]\mathbb{E}\left[Y^{2}\right]+4\mathbb{E}\left[X^{2}\right]\mathbb{E}\left[Y^{2}\right] $$ $$ =3\cdot\frac{3}{8}\sigma_{1}^{2}+3\cdot\frac{3}{8}\sigma_{2}^{2}+2\cdot\frac{1}{2}\cdot\frac{1}{2}\sigma_{1}^{2}\sigma_{2}^{2}+4\cdot\frac{1}{2}\cdot\frac{1}{2}\sigma_{1}^{2}\sigma_{2}^{2} $$ $$ =\frac{9}{8}\sigma_{1}^{2}+\frac{9}{8}\sigma_{2}^{2}+\frac{3}{2}\sigma_{1}^{2}\sigma_{2}^{2}=\frac{3}{4}\left(\frac{3}{2}\sigma_{1}^{4}+2\sigma_{1}^{2}\sigma_{2}^{2}+\frac{3}{2}\sigma_{2}^{4}\right) $$ Which does not seem equal to $ \frac{3}{4}\left(\sigma_{1}^{2}+\sigma_{2}^{2}\right)^{2} $ . What is wrong with what I have done? Any help would be appreciated. Thanks in advace.",['probability-theory']
4343703,Understanding confidence intervals and percentiles,"An experimenter publishing in the
Annals of Botany investigated whether the stem diameters of the dicot sunflower would change depending on
whether the plant was left to sway freely in the wind
or was artificially supported. Suppose that the unsupported stem diameters at the base of a particular
species of sunflower plant have a normal distribution
with an average diameter of $35$ millimeters (mm) and a
standard deviation of $3$ mm a. What is the probability that a sunflower plant will
have a basal diameter of more than $40$ mm? b. If two sunflower plants are randomly selected, what
is the probability that both plants will have a basal
diameter of more than $40$ mm? c. Within what limits would you expect the basal
diameters to lie, with probability $.95$ ? d. What diameter represents the $90$ th percentile of the
distribution of diameters? $\mathbf{\text{MY ATTEMPT:}}$ a-) $P(X >40)=P(Z>1.66)=0.0475$ b-) for this part , i tried to use the formula for selection more than one elements such that $$P\bigg(Z > \frac{40-35}{3 / \sqrt{2}}\bigg)=P\bigg(Z > \frac{5}{2.12132}\bigg) =P\bigg(Z >2.357\bigg)=0.00921$$ However , the answer is $0.00226$ and it has such a solution : $$P(Z>1.66) \times P(Z>1.66)=(0.0475)^2 $$ Why didn't my formula work ? I always use it to find normal dist. probabilities when we choose more than one object. c-) I could not do this with mathematical formula , the only way i could do is to seach for values to satisfy this condition in z table , so i am looking for a nice answer for it. By the way , the given answer is $29.12$ to $40.88$ d-) I have never solved a percentile problem , answer says that $P(Z \geq -z) =0.9$ and answr is $38.84$ . I could not understand why they used ""-z"" insteaf of ""+z"" and why we used $""\geq""$ instead of $>$ . Thanks in advance..","['statistics', 'probability-distributions', 'normal-distribution', 'probability-theory', 'probability']"
4343723,Infinite (co)-homology,"Lately, I've been wondering if it was possible to define singular homology also with infinite-dimensional simplices.
For example we could define an infinite dimensional simplex as: $$\Delta_{\infty}:=\left\{\mathbf{x}\in [0,1]^{\mathbb{N}}:\ \sum_{i\in \mathbb{N}}x_i=1\right\}$$ (We could also impose $x_i=0$ almost everywhere). $\Delta_{\infty}$ is a topological space equipped with the topology induced by the product topology of $[0,1]^{\mathbb{N}}$ . Now given a topological space $X$ , we could define: $$ S_{\infty}(X):=\{\sigma:\Delta_{\infty}\to X : \ \sigma \ \text{is continous}\} $$ Normally the boundary operator is defined as: $$\partial \sigma=\sigma\circ d_0 -\sigma\circ d_1+...(-)^n\sigma\circ d_n$$ Where $d_i$ embeds the $n-1$ -simplex into the $n$ -simplex by adding a $0$ in $i$ -th coordinate. If the simplex is infinite dimensional, adding a zero simply embeds $\Delta_{\infty}$ in itself.
So maybe(given a ring $R$ ) we could define a boundary operator $\partial_{\infty}$ : $$ 0 \to RS_{\infty}(X) \xrightarrow{\partial_{\infty}} RS_{\infty}(X) \xrightarrow{\partial_{\infty}} RS_{\infty}(X)  \to 0$$ Such that $\partial_{\infty}\circ \partial_{\infty}=0$ . And we could define: $$H_{\infty}(X):=\frac{\ker(\partial_{\infty})}{\text{im}(\partial_{\infty})}$$ The problem is that if the simplex is infinite dimensional, there are infinite $d_i$ so the alternating sum becomes infinite and meaningless(Moreover I don't know if this construction can be translated into a functor $\mathbf{Top}\to \mathbf{Mod}_R$ , so that homeomorphic topological spaces have isomorphic infinite homologies). Have you ever heard of a construction similar(even remotely) to this one? Is it a stupid idea? (One could also approach this idea with cellular homology, by attaching also infinite dimensional disks to a CW-complex, but sincerely I didn't thought about this long enough). Thank you in advance.","['general-topology', 'homology-cohomology', 'algebraic-topology']"
4343724,Does a bounded function converge if its derivative tends to zero?,Suppose we have function $f:\Bbb R^+\to\Bbb R$ that is bounded $|f(t)|<M$ and differentiable such that $\lim\limits_{t\to\infty}f'(t) = 0$ . Does this imply that $f(t)$ converges?,"['derivatives', 'real-analysis']"
4343741,Polynomial with icosahedral symmetry,"I am interested in polynomials with icosahedral symmetry. https://arxiv.org/pdf/1308.0955.pdf says that $$
p(v,w)=v^{11}w+11v^6w^6-vw^{11}
$$ has icosahedral symmetry. Each term is homogeneous of degree $12$ . Moreover, within each term the power of $v$ and the power of $w$ are congruent mod $ 5 $ . That implies $ p $ is invariant under the following generator of the binary icosahedral subgroup of $ SU_2 $ $$
\begin{bmatrix}
e^{\frac{2\pi i}{5}} & 0\\
0 & e^{-\frac{2\pi i}{5}} 
\end{bmatrix}=
\begin{bmatrix}
\zeta_5 & 0\\
0 & \overline{\zeta_5}
\end{bmatrix}
$$ In other words, the symmetry \begin{align*}
v \mapsto \zeta_5 v \\
w \mapsto \overline{\zeta_5} w
\end{align*} fixes $ p $ . Apparently $ p $ is also invariant under $$
\begin{bmatrix}
-\zeta_5+\overline{\zeta_5} & \zeta_5^2-\overline{\zeta_5}^2\\
\zeta_5^2-\overline{\zeta_5}^2 & \zeta_5-\overline{\zeta_5} 
\end{bmatrix}
$$ and these two matrices generate the entire 120 element binary icosahedral subgroup $ 2I \cong SL_2(\mathbb{F}_5) $ of $ SU_2 $ . Are there any lower degree polynomials in two complex variables $ v,w $ with icosahedral symmetry? How about polynomials in three real variables $ x,y,z $ that are invariant with respect to the icosahedral subgroup $ I \cong A_5 \cong PSL_2(\mathbb{F}_5) $ of $ SO_3(\mathbb{R})$ ?","['finite-groups', 'matrices', 'abstract-algebra', 'polynomials', 'group-theory']"
4343748,Where's my mistake in my attempt at showing that the squared sum of normally distributed variables is a $\chi^2$ distribution?,"$\newcommand{\N}{\mathcal{N}}\newcommand{\d}{\,\mathrm{d}}$ I am trying to understand how the sum of squares of standard normal variables is a $\chi^2$ distribution. Note that I am not a student of probability theory, but am rather trying to make sense of some things in a formal manner from a background of analysis. As I understand it: $$X\sim\N(0,1)\iff p(X\in I\subset\Bbb R)=\frac{1}{\sqrt{2\pi}}\int_I\exp\left(-\frac{1}{2}x^2\right)\d x$$ Allegedly, if $X_1,X_2,\cdots,X_n\sim\N(0,1)$ , then: $$\sum_{i=1}^nX_i^2\sim\chi_n^2$$ Where: $$X\sim\chi^2_n\iff p(X\in I\subset\Bbb R^+)=\frac{1}{2^{n/2}\Gamma(n/2)}\int_Ix^{n/2-1}\exp(-x/2)\d x$$ I will try (and fail!) to show this. The squares of these $X_i$ will lie in $\Bbb R^+$ . I will proceed by induction. For $n=1$ , we find that $X_1^2\in I\iff X_1\in\pm\sqrt{I}$ , so I can make the substitution $x=u^2$ to retrieve the normal pdf of $X_1$ . I believe it is a theorem that if two measures agree on all intervals in $\Bbb R$ , they agree on all Borel sets - is this true? What's the name of this theorem if it is? I cannot recall, but I think I read this somewhere. Anyway, w.l.o.g (hopefully!) take $I=(a^2,b^2)\subset\Bbb R^+$ : $$\begin{align}p(X_1^2\in I)&=\int_{a^2}^{b^2}\mathrm{pdf}_{X_1^2}(x)\d x=\frac{1}{2}\left(\int_a^b2x\cdot\mathrm{pdf}_{X_1}(x)\d x+\int_{-b}^{-a}2x\cdot\mathrm{pdf}_{X_1}(x)\d x\right)\\&=\frac{1}{\sqrt{2\pi}}\left(\int_a^b x\exp(-\frac{1}{2}x^2)\d x+\int_{-b}^{-a}x\exp(-\frac{1}{2}x^2)\d x\right)\\&=\frac{1}{\sqrt{2\pi}}\left(\int_{a^2}^{b^2}\sqrt{u}\cdot\exp(-\frac{1}{2}u)(\frac{1}{2}u^{-1/2}\d u)-\int_{b^2}^{a^2}\sqrt{u}\cdot\exp(-\frac{1}{2}u)(\frac{1}{2}u^{-1/2}\d u)\right)\\&=\frac{1}{\sqrt{2\pi}}\int_{a^2}^{b^2}\exp(-\frac{1}{2}u)\d u\end{align}$$ But this is not consistent with the assertion that $X_1^2\sim\chi^2_1$ , since the integral is missing a $u^{-1/2}$ term. I have two questions: What's my mistake in the analysis of the case $n=1$ ? To put my mind at rest, to show that the two distributions are the same over all Borel sets in $\Bbb R$ , is it really sufficient to show equivalence over intervals? Many thanks.","['integration', 'measure-theory', 'probability-distributions', 'chi-squared', 'probability-theory']"
4343762,Spurious solution to differential equation?,"I have the differential equation $$ \frac{d}{dx}y = 2\sqrt{y} $$ which starts at $x=0$ with $y=0$ . Wolfram Alpha says the solution is $y=x^2$ . I can see that when I insert this into the original equation. But I don't understand two things here. Shouldn't $y=0$ also be a solution? But maybe that is only a Wolfram Alpha issue as it displays only one solution? I don't understand how $y=x^2$ can ""actually happen"" in reality. With that I mean using a solver. Because when $y=0$ then also $2\sqrt{y} = 0$ and so $y$ should not ever change at all. I can confirm this with Matlab: y0=0;
ode45(@(t,y)(2*sqrt(y)),0:0.01:10,y0); The code produces: So this is obviously the $y=0$ solution. Is the $y=x^2$ some kind of spurious solution that doesn't ""exist"" in reality? If so how can we know when a solution is ""bad""? Or if it does exist how can we get a solver to produce this output?","['initial-value-problems', 'numerical-methods', 'ordinary-differential-equations', 'dynamical-systems']"
4343802,Is the unbiased test always uniformly most powerful? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I know that the uniformly most powerful test is always unbiased, if it exists, but is the unbiased test always UMP?","['statistics', 'probability', 'hypothesis-testing']"
4343821,Lipschitz inequality with Rademacher variable,"Suppose $(\epsilon_i)_{i = 1}^n$ are IID Rademacher variables. And we have another series of rv.s $(X_i)_{i = 1}^n$ independent with $(\epsilon_i)_{i = 1}^n$ with a Lipschitz function $|f(x, z_1) - f(x, z_2)| < L(x) |z_1 - z_2|$ . What I want to do is to bound the expectation: $$
    \mathrm{E} \bigg| \sum_{i = 1}^n \epsilon_i \big( f(X_i, z_1) - f(X_i, z_2) \big) \bigg|.
$$ First, I simply use the fact $ \big( f(X_i, z_1) - f(X_i, z_2) \big) \leq L(X_i) |z_1 - z_2|$ to give the upper bound $|z_1 - z_2| \cdot \mathrm{E} \bigg| \sum_{i = 1}^n \epsilon_i L(X_i)\bigg|$ . But later I found that this may not be held since $\epsilon_i$ can be either positive or negative. So I wonder if there exist some constant $C$ such that $$
    \mathrm{E} \bigg| \sum_{i = 1}^n \epsilon_i \big( f(X_i, z_1) - f(X_i, z_2) \big) \bigg| \leq C \cdot |z_1 - z_2| \cdot \mathrm{E} \bigg| \sum_{i = 1}^n \epsilon_i L(X_i)\bigg|
$$","['statistics', 'probability-distributions', 'probability', 'inequality']"
4343829,How to find the expectation of this random variable,"Assume $\theta \sim U[0,1]$ . Fix $x\in \mathbb{R}$ and consider the following random variable: $ g_{x}\left(\theta\right)=\begin{cases}
2-|x| & |x|\leq\theta\\
0 & \text{else}
\end{cases} $ How can I calculate the expectation of $ \mathbb{E}\left[g_{x}\left(\theta\right)\right] $ ? Im not sure how to start. The answer should be $$ \begin{cases}
1.5-2|x|+0.5x^{2} & |x|\leq1\\
0 & \text{else}
\end{cases} $$ And I'm not sure how or why. Thanks in advance, any help would be appreciated.",['probability-theory']
4343832,How do you measure the 'explained variance' of arbitrary linear embeddings?,"Question Elaboration: When I say 'linear embeddings' I mean a lower-dimensional representation of variables resulting from an arbitrary linear transformation. And when I say 'explained variance' I mean in the sense that 'explained variance' is measured for PCA's principal components. Context of Confusion: I realized I'm confused about exactly what this means because while on the surface the idea of 'explained variance' from lower-dimensional encodings makes sense. I've come to wonder if rigorously speaking it is at all possible for anything but a model to 'explain variance' of original variables (i.e. R^2 measure) ... Attempt 1 to draw connection to PCA: For example This website says that total variance for PCA is sum of individual variances of the PCA variables, and then explained variance for each PC is portion of that total variance present in a PC. I don't see how this could generalize to arbitrary lower dimensional representations because you could just scale some of the lower dimensional variables arbitrarily and change which represent more of the variance no? Attempt 2 to draw connection to PCA: I've also seen on numerous websites (e.g. here ) that the explained variance for a PCA variable is the corresponding eigen-value but I'm not sure what the analogue to arbitrary lower-dimensional linear representations would be...","['statistics', 'variance', 'principal-component-analysis']"
4343869,What is this vector notation called?,"I am asking here because I believe this is an issue with my understanding of mathematical notation, and not an issue with a physics misunderstanding although there is heavy physics context here. I am writing a physics simulator, and right now I am working on simulating elastic collisions between spheres of equal mass (mass of 1 unit makes much of the math work out nicely). I found this fantastic writeup https://physics.stackexchange.com/questions/107648/what-are-the-general-solutions-to-a-hard-sphere-collision which has gotten me most of the way there. If the spheres collide head on my simulation works but when they collide at an angle, the result shows energy was not conserved (energy lost). I feel I must be misunderstanding the notation. The portion in question is the calculation of the impulse vector. Specifically this (copied from the link): $$
J=2 \hat{j}\frac{\hat{j} \bullet R'}{\frac1{M_a} + \frac1{M_b}}
$$ Where R' is $$
R'=V_{a1}-V_{b1}
$$ and j is the direction of the impulse (a unit vector through the COM of each sphere) Considering that I have equal masses of 1 this equation should reduce to: $$
J = \hat{j}\left( {\hat{j} \bullet R'}\right)
$$ I assume the quantity is a dot product of R' and the unit vector j. If I have two spheres traveling toward each other such that they will collide at a 45 degree angle there is clearly something wrong here. If spheres A / B have velocities (say A is centered on the X-axis and B starts a bit above it, such that they collide at an angle) $$
V_a = \begin{bmatrix} 5 \\ 0 \\ 0 \end{bmatrix}
V_b = \begin{bmatrix} -5 \\ 0 \\ 0 \end{bmatrix}
$$ My calculation for the direction of impulse is fine but I find $$
\hat{j} = \begin{bmatrix} -\frac{1}{\sqrt{2}} \\ -\frac{1}{\sqrt{2}} \\ 0 \end{bmatrix}
$$ $$
R' = \begin{bmatrix} 10 \\ 0 \\ 0 \end{bmatrix}
$$ Which (here must be my misunderstanding) would mean $$
J = \begin{bmatrix} -\frac{10}{\sqrt{2}} \\ 0 \\ 0 \end{bmatrix}
$$ This is clearly wrong, there needs to be a vertical component to the impulse vector. I assume the write-up is correct and I'm misunderstanding the notation, what is the correct way to interpret this? edit: The correct vector for reference is $$
J = \begin{bmatrix} -5 \\ -5 \\ 0 \end{bmatrix}
$$ Which causes the spheres to change direction by 90 deg and continue on as expected. Final edit for posterity: In my final implementation I actually had to use the absolute value of the dot product. If it's negative, it flips the direction of the impulse and yields incorrect results. I am not sure if this is a mistake in the formula, or an artifact of my implementation. Either way it is working correctly now.","['matrices', 'notation', 'vectors']"
4343880,Double integral with absolute value solution verification,"I would like to know if my way to solve the following integral is correct: Let $I=\frac{1}{4}\int\int_Te^{x^2/4+y^2}(4-x^2-4y^2)dxdy$ , with $T=\{(x,y)\in \mathbb{R^2}:0\leq x\leq 2y,\ \ x^2+4y^2 \leq 4 \}$ . I made the following substitution, $\begin{cases}x=2rcos(\theta)\\\ y=rsin(\theta)\end{cases}$ , so that $dxdy=2rdrd\theta$ , $T=\{(r,\theta): 0\leq cos(\theta) \leq sin(\theta), \ \ r^2\leq 1 \}=\{(r,\theta): \theta \in [\pi/4,\pi/2], \ \ r\in[0,1] \}$ , thus we can say $I=\frac{1}{4}\int_{\pi/4}^{\pi/2}\int_0^1e^{r^2}(4-4r^2)2rdrd\theta=\frac{\pi}{2}\int_0^1e^{r^2}(r-r^3)dr=\frac{\pi}{2}(\frac{e-2}{2})$ . Is my reasoning correct?","['integration', 'calculus', 'solution-verification', 'analysis']"
4343890,Constructing the Haar measure of the $n$-dimensional Torus,"Let $\mathbb{T}^n:=\mathbb{R}^n/\mathbb{Z}^n$ be the quotient of the group $(\mathbb{R}^n,+)$ by the subgroup $(\mathbb{Z}^n,+)$ . I'm trying to construct the Haar measure of $\mathbb{T}^n$ . I constructed a measure which is finite and Radon. However I don't how to prove that the measure I constructed is translation invariant. Below I'll sketch the construction. Firstly suppose that $\lambda$ is the Lebesgue measure of $\mathbb{R}^n$ and that $\mathfrak{B}$ is the Borel $\sigma$ -algebra of the unit cube $[0,1]^n$ with the subspace topology of $\mathbb{R}^n$ . Define $\pi :[0,1]^n\to \mathbb{T}^n$ by $\pi (x):=x+\mathbb{Z}^n$ . We can define a metric $d_{\mathbb{T}^n}$ in $\mathbb{T}^n$ such that $\pi$ is continuous (see here ). Let $\mathfrak{B}_{\mathbb{T}^n}$ be the Borel measure of $\mathbb{T}^n$ induced by the topology induced by the metric $d_{\mathbb{T}^n}$ ; Let $\pi _\star (\lambda |_{\mathfrak{B}}) :\pi_\star\mathfrak{B}\to\overline {\mathbb{R}} $ be the pushforward measure of the restriction $\lambda|_{\mathfrak{B}} $ . It's easy to show that $\mathfrak{B}_{\mathbb{T}^n}\subseteq\pi_\star\mathfrak{B} $ since $\pi$ is continuous. Define $\vartheta :\mathfrak{B}_{\mathbb{T}^n}\to \overline{\mathbb{R}}$ by $\vartheta (B):=\pi _\star (\lambda |_{\mathfrak{B}}) (B)$ . We can show that $\vartheta :\mathfrak{B}_{\mathbb{T}^n}\to \overline{\mathbb{R}}$ is a probability measure of $\mathbb{T}^n$ and it's also a Radon measure. My question is: how can I show that $\vartheta $ is translation invariant? I did almost nothing worth mentioning. I think it's important to observe that the restriction $\pi |_{[0,1)^n}:[0,1)^n\to\mathbb{T}^n$ is bijective. With the property of pushforward measure we can show that, given any $B\in\mathfrak{B}_{\mathbb{T}^n}$ and $a\in\mathbb{T}^n$ , we have $$\vartheta(B+a)=\int _{\mathbb{T}^n}\mathbf{1}_{B+a}d\vartheta=\int _{[0,1]^n}\mathbf{1}_{B+a}(\pi (x))d\lambda (x)\,\,\color{red}{(1)} $$ Above $\mathbf{1}_{B+a}$ is the indicator function of $B+a$ . If there's an $\alpha\in[0,1]^n$ such that $\mathbf{1}_{B+a}(\pi (x))=\mathbf{1}_{\pi^{-1}(B)+\alpha}(x)$ for all $x\in [0,1]^n$ , then we can use $(1)$ to prove that $\vartheta (B+a)=\lambda (\pi ^{-1}(B)+\alpha )=\lambda (\pi^{-1}(B))=\vartheta(B)$ . However I wasn't able to prove that there's such $\alpha\in[0,1]^n$ . If anyone knows an easier way to construct the Haar measure of the $n$ -dimensional Torus please tell me. Thank you for your attention!","['measure-theory', 'lebesgue-measure', 'borel-measures', 'haar-measure', 'borel-sets']"
4343891,Average number of days to see all possible cards,"My father and I go to the restaurant everyday, and each one of us needs to grab a card, which has a number from 1 to 600. I thought about registering every new card we see in a list, and a question arose: ""How many days, on average, would we need to see every possible card?"" Each card has an equal probability of being chosen The two cards my father and I get are different So far, I reasoned that the minimum number is 300, if it were the case that everyday we got different cards. In addition, it gets ever more harder to reach the final number of cards. When the list of seen cards is almost complete, it is more likely that we are going to draw a card that has already been seen before, and not a new one. I coded 1000 simulations in python and this is the graph of the number of days expected to reach $n$ cards on average: which is compatible with my reasoning, and results in an average of 2088 days for us to see each one of the 600 cards.
But I would like to see a non-brute force way to derive such value.","['expected-value', 'coupon-collector', 'probability']"
4343920,In how many different ways can two teams of five players each be formed?,"Precalculus textbook problem (self-study): Ten people wish to play in a basketball game. In how many different ways can two teams of five players each be formed? Textbook section title : Distinguishable Permutations and Combinations Textbook solution in back of book : $C(10,5) = 252$ . My solution : $252/2 = 126$ . My reasoning : $C(10,5) = 252$ gives the number of five-person teams that can be formed, but that's double how many ways you can pick two teams because once one team is picked, the other is decided. For example , suppose I have four people, A,B,C, and D.  If I ask how many different ways can two teams of two players each be formed from these four people the answer is three, not six: Two teams: AB and CD Two teams: AC and BD Two teams: AD and BC Yes, there are six different teams, but only three ways to pick two teams. Question : Am I nuts?","['combinations', 'combinatorics']"
4343934,Is the multivector derivative invariant under a change of coordinates?,"The multivector derivative $\partial _X \equiv e^I \partial_I \equiv \partial_{\langle X \rangle_0} + e^1\partial_{X_1} + e^2 \partial_{X_2}+\dots + e^{1,2,3} \partial_{X_{1,2,3}}$ with respect to some multivector variable is defined as the linear combination of all of the basis k-vectors with the components being the partial derivative operators with respect to the variable’s components. My question is if the operator would give the same results if you changed the coordinates, or in other words, if the following statement is true: $\partial_{X}\equiv e^I \partial_I \equiv \partial_{\langle X \rangle_0} + e^1\partial_{X_1} + e^2 \partial_{X_2}+\dots + e^{1,2,3} \partial_{X_{1,2,3}} = \partial_{\langle X \rangle_0}+ e’^1\partial_{X’_1} + e’^2 \partial_{X’_2}+\dots + e’^{1,2,3} \partial_{X’_{1,2,3}}$","['geometric-algebras', 'derivatives', 'clifford-algebras']"
4343936,Wrong answers to simple trigonometry questions,"I am solving the following questions from here I gave the following answers to the questions and are marked as wrong: A plane ascends at a 40° angle. When it reaches an altitude of one hundred feet, how much ground distance has it covered? To solve, use
the trigonometric chart. Round the answer to the nearest tenth. Options: $64.3$ ft, $76.6$ ft, $80.1$ ft, $119.2$ ft My answer: $76.6$ ft. Reasoning: It is $100\cdot\cos 40º$ A 20 ft. beam leans against a wall. The beam reaches the wall 13.9 ft. above the ground. What is the measure of the angle formed by the
beam and the ground? Options: $44º, 35º, 55º, 46º$ My answer: $46º$ . Reasoning: $\sin \theta = \frac{13.9}{20} = 0.695$ and $\cos 46º \approx 0.695$ They were marked as wrong. What am I messing up here?","['algebra-precalculus', 'trigonometry', 'recreational-mathematics']"
4343945,Confusion concerning Lemma 1.12 in Wiles's proof of Fermat's Last Theorem,"Let $k$ be a finite field of characteristic $p\neq 2$ (in fact, one only needs to consider the case $p\in\{3,5\}$ ), let $\Sigma$ be a finite set of primes containing $\infty$ and $p$ , and $$\rho_{0}:{\rm Gal}(\mathbb{Q}_{\Sigma}/\mathbb{Q})\rightarrow {\rm GL}_{2}(k)$$ an absolutely irreducible representation, meaning $\rho_{0}\otimes\overline{k}$ cannot be written as the direct sum of two one-dimensional subrepresentations, where $\mathbb{Q}_{\Sigma}$ is the largest Galois extension of $\mathbb{Q}$ unramified outside the primes in $\Sigma$ . Assume that if $\tau\in\operatorname{Gal}(\mathbb{Q}_{\Sigma}/\mathbb{Q})$ is complex conjugation, then $\det(\rho_{0}(\tau))=-1$ .
Then $\rho$ induces a projective representation $$\tilde{\rho}_{0}:\operatorname{Gal}(\mathbb{Q}_{\Sigma}/\mathbb{Q})\longrightarrow\operatorname{PGL}_{2}(k).$$ Assume this projective representation has dihedral image, meaning $$\operatorname{image}(\tilde{\rho}_{0})\cong\left<s,r\mid s^{2}=r^{m}=(sr)^{2}=1\right>$$ for some $m\in\mathbb{N}$ , and assume further that $\rho_{0}|_{\mathbb{Q}(\sqrt{(-1)^{\frac{p-1}{2}}p})}$ is absolutely irreducible. The action of $\operatorname{Gal}(\mathbb{Q}_{\Sigma}/\mathbb{Q})$ on $k^{2}$ induces an action on $V_{\lambda}=\operatorname{Hom}(k^{2},k^{2})$ , namely by conjugation. (What that $\lambda$ stands for is of no significance here.) Since $p\neq 2$ , one has a direct sum of $k[\operatorname{Gal}(\mathbb{Q}_{\Sigma}/\mathbb{Q})]$ -modules $$V_{\lambda}=W_{\lambda}\oplus k\text{,}$$ where $W_{\lambda}$ denotes the space of $\operatorname{trace}$ - $0$ matrices and $k$ is the space of scalar multiplications. Let $K_{1}$ be the splitting field of $\rho_{0}$ (i.e. $\operatorname{Gal}(\mathbb{Q}_{\Sigma}/K_{1})=\operatorname{ker}(\rho_{0})$ ), and $$G:=\operatorname{Gal}(K_{1}/\mathbb{Q})=\operatorname{Gal}(\mathbb{Q}_{\Sigma}/\mathbb{Q})/\operatorname{ker}(\rho_{0})=\operatorname{image}(\rho_{0}).$$ Since $\overline{\rho}_{0}$ has dihedral image, $\rho_{0}\otimes\overline{k}=\operatorname{Ind}_{H}^{G}(\chi)$ for some character $\chi$ . Question : Wiles now makes the following claims. (1.) Under the above conditions, $W_{\lambda}\otimes\overline{k}=\delta\otimes\operatorname{Ind}_{H}^{G}(\chi/\chi')$ where $\chi'$ is the quadratic twist of $\chi$ by any element of $G\setminus H$ and $\delta$ is the quadratic character $G\longrightarrow G/H$ (what does that even mean - $W_{\lambda}\otimes\overline{k}$ decomposes as a quadratic character + something else?) (2.) since $M(\zeta_{p^{n}})$ is Abelian over $\mathbb{Q}$ , where $\mathbb{Q}\subseteq M\subseteq K_{1}$ such that $G/H=\operatorname{Gal}(M/\mathbb{Q})$ , one always finds for any $n\in\mathbb{N}$ an $x\in\operatorname{Gal}(\overline{\mathbb{Q}}/\mathbb{Q})$ which fixes $\mathbb{Q}(\zeta_{p^{n}})$ and $\tilde{\rho}_{0}(x)\neq 1$ as long as $m\neq 2$ (i.e. $\operatorname{image}(\rho_{0})\neq\mathbb{Z}/2\times\mathbb{Z}/2$ ). Why is that the case? Maybe I'm not seeing the wood for all the trees here, but who knows. EDIT : Also, should it not be $\operatorname{Gal}(\mathbb{Q}_{\Sigma}/\mathbb{Q})$ instead of $\operatorname{Gal}(\overline{\mathbb{Q}}/\mathbb{Q})$ ?","['galois-representations', 'proof-explanation', 'representation-theory', 'galois-theory', 'linear-algebra']"
4343967,Tail probability bound on the expected value of measurable function of a random variable,"I was reading Allan gut's graduate probability book and came across this problem, Let $X$ be a non-negative random variable and $g$ be a non-negative, strictly increasing, differentiable function. Then, $ Eg(X) < \infty \iff \sum_{n=1}^{\infty}g'(n)\textbf{P}(\textbf{X}>n) <\infty$ . I am stuck and any help will be appreciated.","['probability-theory', 'probability']"
4343973,"Use the Lagrange multiplier method to find the shortest distance from $(1, 1, 1)$ to $2x + y - z = 5$","This is my working so far: let $$f=d^2=(x-1)^2+(y-1)^2+(z-1)^2$$ $$g=2x+y-z-5$$ $$\psi=f+\lambda g$$ from this we can make simultaneous equations: $$\psi_x=2(x-1)+2\lambda =0$$ $$\psi_y=2(y-1)+\lambda =0$$ $$\psi_z=2(z-1)-\lambda =0$$ $$2x+y-z=5$$ solving these gives: $$x=\frac 65,\,y=\frac {11}{10},\,z=\frac 9{10}$$ so then to calculate the shortest distance we would do the following: $$d=\sqrt{\left(x-\frac6{5}\right)^2+\left(y-\frac{11}{10}\right)^2+\left(z-\frac{9}{10}^2\right)}=\frac{\sqrt6}{10}$$ but the answer given is $$\frac{\sqrt6}{2}$$","['multivariable-calculus', 'lagrange-multiplier']"
4344009,"Prove that $\sin nx\le n\sin x$, by Induction","I have to prove that $\sin nx\le n\sin x,\ \forall n\in\mathbb{N},\ 0\le x\le \pi/2$ , using Mathematical Induction.
The problem arises during the inductive step. What I've done so far, is $$\sin(k+1)x=\sin(kx+x)=\sin kx\cos x + \sin x\cos kx.$$ Since $\cos x\le1,\ \forall x\in[0, \pi/2]$ , we have that $\sin kx\cos x\le\sin kx\le k\sin x\ \text{(by the inductive hypothesis)}$ , obtaining $$\sin(k+1)x\le k\sin x +\sin x\cos kx.$$ I need to prove that the last term is $\le\sin x$ , but I'm not sure that what I've done until now is correct, since $\sin$ and $\cos$ are nonnegative for $x$ , but not for $kx$ . If the statement to prove had the modulus, it would be easier to be proven.","['inequality', 'induction', 'trigonometry', 'solution-verification', 'algebra-precalculus']"
4344042,Changing order of integration in triple integral,"Change the order of integration in the triple integral $$\int_0^1 \int_0^x \int_0^y f(x,y,z) \,dz ~dy~dx$$ to $dz~dx~dy$ Attempt: Here, since $z$ remains in the same place I think it is enough to consider only what happens in the $xy$ plane. So the bounds will become $0 \leq y \leq 1$ , $y \leq x \leq 1$ and $0 \leq z \leq y$ . However, my intuition tells me that this is not correct since if we change the order of $x$ and $y$ then this will affect $z$ as well. So is my intuition correct? If yes then how can I approach this problem?","['integration', 'multivariable-calculus', 'calculus']"
4344045,"Find the smallest $n$ for which there are real $a_{1}, a_{2}, \ldots,a_{n}$","Find the smallest $n$ for which there are real $a_{1}, a_{2}, \ldots,a_{n}$ such that $$\left\{\begin{array}{l} a_{1}+a_{2}+\ldots+a_{n}>0 \\a_{1}^{3}+a_{2}^{3}+\ldots+a_{n}^{3}<0 \\a_{1}^{5}+a_{2}^{5}+\ldots+a_{n}^{5}>0 \end{array}\right.$$ I don't have a solution, but I suspect $n_{\min}=5$ is optimal. I think so mainly because I could not find anything by brute force for either $4$ or $3$ . There are quite a few solutions for $n=5$ , for example: $$a_{1}=1, a_{2}=-0.88, a_{3}=-0.88, a_{4}=0.5, a_{5}=0.5$$ $$a_{1}=-8, a_{2}=-7, a_{3}=3, a_{4}=4, a_{5}=9$$ It is also not difficult to prove by contradiction that $n_{\min}>2$ .","['algebra-precalculus', 'systems-of-equations', 'inequality']"
4344083,How to show that the integral inequality holds for vector-valued functions. [duplicate],"This question already has an answer here : Inequality involving the integral of vector valued function (1 answer) Closed 2 years ago . If I define the integral for $\int_a^b\textbf{F}(t)dt$ as $(\int_a^b F_1(t)dt, \int_a^bF_2(t)dt,\ldots, \int_a^bF_n(t)dt )$ . How do I then show that $$\left|\int_a^b\textbf{F}(t)dt \right|\le\int_a^b\left|\textbf{F}(t) \right|dt?$$ If we write out the inequality we have $$\sqrt{\left(\int_a^b F_1(t)dt\right)^2+\left(\int_a^bF_2(t)dt\right)^2+\cdots+ \left(\int_a^bF_n(t)dt\right)^2 }\le\int_a^b\sqrt{F_1(t)^2+F_2(t)^2+\cdots+F_n(t)^2}dt.$$ attempt: If I use Jenssen's inequality I get for the left side: $$\sqrt{\left(\int_a^b F_1(t)dt\right)^2+\left(\int_a^bF_2(t)dt\right)^2+\cdots+ \left(\int_a^bF_n(t)dt\right)^2 }\le\sqrt{\int_a^b F_1^2(t)dt+\int_a^bF_2^2(t)dt+\cdots+ \int_a^bF_n^2(t)dt }\\=\sqrt{\sum\limits_{i=1}^n\int_a^bF_i^2(t)dt}=\sqrt{\int_a^b\sum\limits_{i=1}^nF_i^2(t)dt}.$$ The problem I have now is that the square root function is concave, so if I use Jenssen again, I get the opposite inequality as the one I need. Any idea on how to solve this?","['integration', 'measure-theory', 'real-analysis', 'calculus', 'inequality']"
4344088,"Closed form solution method for infinite sum (but not ""by inspection"")","I have a series whose terms are defined by the recurrence relation $$T_n = \alpha \ \left(1+\frac{\mu}{n}\right)\ T_{n-1}$$ with $T_0=1$ So $$T_n=\alpha^n\prod_{k=1}^n \left(1+\frac{\mu}{k}\right)\tag{1}\label{eq1}$$ $\alpha$ and $\mu$ are real constants with $0\le\alpha\lt1$ and $\mu\ge 0$ .  I want the sum $$S(\alpha,\mu)=\sum_{n=0}^\infty T_n$$ Now, I know that when $\mu=0$ , $$S(\alpha,0)=\frac{1}{1-\alpha}$$ Here's the funny thing... I was playing around in Excel with actual numbers and stumbled upon the general solution: $$S(\alpha,\mu)=\left(\frac{1}{1-\alpha}\right)^{1+\mu}$$ Does anyone know any general techniques that would have led me to this expression? Here's another funny thing... if I expand the solution in a Taylor series around $\alpha=0$ , I get $$S(\alpha,\mu)=1+(1+\mu)\alpha+\frac12(1+\mu)(2+\mu)\alpha^2+\frac16(1+\mu)(2+\mu)(3+\mu)\alpha^3+\ldots$$ Each term in the Taylor series is $$\frac{\alpha^n}{n!}\prod_{k=1}^n(k+\mu)=\alpha^n\prod_{k=1}^n\frac{k+\mu}{k}
=\alpha^n\prod_{k=1}^n\left(1+\frac{\mu}{k}\right)$$ which is of course $T_n$ as defined in $\eqref{eq1}$ I suppose if I were really good, I might have recognized the Taylor series expansion in the first place, but I'm not that good. :)  So does anyone know a better method by which I could have arrived at the answer?","['power-series', 'sequences-and-series']"
4344139,Having trouble with proving this binomial identity. I have taken it as far as I can go.,"I have broken down this equation into factorials, but I'm unsure of where to go from here. This may not even be the right approach to solve this binomial transform. Any help would be appreciated. Binomial transform identity : \begin{align*}
&\sum_{k=0}^n(-1)^{n-k}{n\choose k}{n+jk\choose jk}=j^n\\
&\sum_{k=0}^n(-1)^{n-k}\frac{(jk+1)(jk+2)\dots(jk+n)}{(n-k)!\,k!}=j^n
\end{align*}","['binomial-coefficients', 'combinatorics', 'binomial-theorem', 'discrete-mathematics']"
4344158,"For an arbitrary continuous $\mathbb{R}\to\mathbb{R}$, how to show that a certain Borel set is contained in the set of finite differentiability?","I am working on a more detailed version of a proof that has appeared on Math Stack before. Requests for a proof of the following theorem have been posted several times, but I am asking about the specific strategy suggested in (1) below. Theorem. Let $f$ be any real-valued, continuous function with domain $\mathbb{R}$ . Then $\Delta(f) := \{x\in \mathbb{R}: f'(x) \in \mathbb{R}\}$ is Borel measurable. In other words, the set of points of finite differentiability belongs to the sigma-algebra generated by the closed sets. I am trying to flesh out the proof given in (1) Show that $\Delta(f)$ is a $F_{\sigma\delta}$ -set , where it is suggested that $\Delta(f)$ is exactly $$S\,=\,\bigcap_{k=1}^{\infty} \;\bigcup_{n=1}^{\infty} \;\; \bigcap_{0 < |\eta| < \frac{1}{n}} \;\; \bigcap_{0 < |\delta| < \frac{1}{n}} \; \left\{x:\;\; \left| \frac{f(x + \eta) - f(x)}{\eta} \; - \;  \frac{f(x + \delta) - f(x)}{\delta} \right| \; \leq \frac{1}{k}\right\}.$$ I have showed that $\Delta(f)$ is a subset of the above set; I outline the reasoning below. For any fixed and non-zero $\eta$ and $\delta$ , the function $$x \mapsto \left| \frac{f(x + \eta) - f(x)}{\eta} \; - \;  \frac{f(x + \delta) - f(x)}{\delta} \right|$$ is continuous, so that the set $\{x: \cdots\}$ appearing above is closed, being a continuous pre-image of a closed set. So if $S=\Delta(f)$ the theorem is proved. What I am stuck on is showing $S\subset \Delta(f)$ . Set $S$ doesn't ""know"" about the value of the derivative, which is why I think it is harder. It seems (from looking at other approaches posted) that we need to pass to the rationals ( maybe something like this: https://math.stackexchange.com/a/1395360 ), or build a Cauchy sequence, or a sequence of nested compacts. It makes me wonder, more generally, about sufficient conditions for differentiability at $x_0$ that do not involve pre-knowledge of $f'(x_0)$ . What is a good way to rigorously show the inclusion $S\subset \Delta(f)\,$ ? Sketch of proof that $\Delta(f)\subset S$ : Let $x \in \Delta(f)$ , and let $k\geqslant 1$ be fixed. Let $\epsilon = 1/k>0.$ Let $t=f'(x)$ . $\exists n\geqslant 1,$ $$\left| \frac{f(x + \eta) - f(x)}{\eta} -t \right| \; \leqslant \; \frac{\epsilon}{2} \;\text{ whenever }\; 0 \lt |\eta|\lt \frac1n.$$ From here it is just a matter of applying the triangle inequality: $$\left| \frac{f(x + \eta) - f(x)}{\eta} -  \frac{f(x + \delta) - f(x)}{\delta} \right|  $$ $$\leqslant \left| \frac{f(x + \eta) - f(x)}{\eta} - t\right| + \left| \frac{f(x + \delta) - f(x)}{\delta} -t \right|  \leqslant \epsilon=\frac{1}{k}.$$","['borel-sets', 'continuity', 'derivatives', 'real-analysis']"
4344181,Show $\mathbb{E}_1\big[S_n\textbf{1}_{\{T_{\text{hit zero}} > n\}}\big] \not\to 0$ for SSRW.,"Suppose we have a simple symmetric random walk starting at $1$ , and define $$T_{\text{hit zero}} = \min\{n\geq 1 : S_n = 0\}.$$ I was trying to argue that $$\star =\mathbb{E}_1\big[S_n\textbf{1}_{\{T_{\text{hit zero}} > n\}}\big] \not\to 0$$ as $n\to\infty$ . I can think of it with using the FKG inequality, as the expectation can be lower bounded by $$ \star \geq \sqrt{n} \; \mathbb{P}_1( \{S_n \geq \sqrt n\}\cap \{T_{\text{hit zero}}>n\}).$$ Both events are increasing (if we flip any of the steps from a $-1$ to $1$ , they are more likely to happen), and so we get $$\star\geq \sqrt n \; \mathbb{P}_1\{S_n \geq \sqrt n\} \mathbb{P}_1\{T_{\text{hit zero}}>n\} \geq \sqrt n C_1 \frac{C_2}{\sqrt n} > \epsilon.$$ Is there an easy to to show this claim without FKG inequality?","['martingales', 'stopping-times', 'probability-theory']"
4344247,Restriction of vector bundle to norm 1 is a covering map,"Given a mainfold $M$ , the vector bundle \begin{equation*}
\pi:\wedge^k T^*M = \sqcup_{p \in M} \wedge^k T_p^*M \rightarrow M
\end{equation*} has the property that its section are exactly the $k$ -forms on $M$ .
We assume that $M$ is connected and has dimension $m$ . I have already proven that the vector bundle $\wedge^m T^*M$ has rank 1.
Then we endow every fiber of the total space $\wedge^m T^*M$ with an inner product varying smoothly (i.e. for any two smooth sections, their inner product is a smooth function on $M$ ). Then $M'$ is the submanifold of $\wedge^m T^*M$ consisting of the vectors with norm 1. I need to show that \begin{equation*}
\pi|_{M'}:M' \rightarrow M
\end{equation*} is a smooth covering map. I have already proven that this map is both smooth and surjective.
This means that I only need to prove that each point of $M$ has a neighborhood $U$ such that $\pi|_{M'}$ maps each connected component of $\pi|_{M'}^{-1}(U)$ diffeomorphically onto U. Can anyone tell me how to do this or where to start?","['diffeomorphism', 'vector-bundles', 'covering-spaces', 'manifolds', 'differential-geometry']"
4344261,How many ways to deal with the integral $\int \frac{d x}{\sqrt{1+x}-\sqrt{1-x}}$?,"I tackle the integral by rationalization on the integrand first. $$
\frac{1}{\sqrt{1+x}-\sqrt{1-x}}=\frac{\sqrt{1+x}+\sqrt{1-x}}{2 x}
$$ Then splitting into two simpler integrals yields $$
\int \frac{d x}{\sqrt{1+x}-\sqrt{1-x}}=\frac{1}{2}\left [\underbrace{\int\frac{\sqrt{1+x}}{x}}_{J} d x+\underbrace{\int\frac{\sqrt{1-x}}{x} d x}_{K}\right]
$$ To deal with $J$ , we use rationalization instead of substitution. $$
\begin{aligned}
J &=\int \frac{\sqrt{1+x}}{x} d x \\
&=\int \frac{1+x}{x \sqrt{1+x}} d x \\
&=2 \int\left(\frac{1}{x}+1\right) d(\sqrt{1+x}) \\
&=2 \int \frac{d(\sqrt{1+x})}{x}+2 \sqrt{1+x} \\
&=2 \int \frac{d(\sqrt{1+x})}{(\sqrt{1+x})^{2}-1}+2 \sqrt{1+x} \\
&=\ln \left|\frac{\sqrt{1+x}-1}{\sqrt{1+x}+1} \right| +2 \sqrt{1+x}+C_{1}
\end{aligned}
$$ $\text {Replacing } x \text { by } -x \text { yields }$ $$
\begin{array}{l} \\
\displaystyle K=\int \frac{\sqrt{1-x}}{-x}(-d x)=\ln \left|\frac{\sqrt{1-x}-1}{\sqrt{1-x}+1}\right|+2 \sqrt{1-x}+C_{2}
\end{array}
$$ Now we can conclude that $$
I=\sqrt{1+x}+\sqrt{1-x}+\frac{1}{2}\left(\ln \left|\frac{\sqrt{1+x}-1}{\sqrt{1+x}+1}\right|+\ln \left|\frac{\sqrt{1-x}-1}{\sqrt{1-x}+1}\right|\right)+C
$$ My question is whether there are  any simpler methods such as integration by parts , trigonometric substitution, etc… Please help if you have. Thank you for your attention.","['integration', 'indefinite-integrals', 'calculus', 'radicals']"
4344274,"A counter example to ""Banachness""","We know that if $V_2$ is a Banach Space then $\mathcal{L}(V_1,V_2)$ is also a Banach space, but can we state the converse? That is, does $\mathcal{L}(V_1,V_2)$ being a Banach Space implies that $V_2$ is a Banach Space (if $V_1\neq \{0\}$ )? I think the answer is no but im no sure. I'm trying to find a counter example: Consider a Cauchy sequence $(A_n)_{n\in\mathbb{N}}\in\mathcal{L}(\mathbb{R}, \mathbb{Q})$ . We know that $\mathbb{Q}$ isn't Banach cause we can make a rational sequence converge to a irrational number. But considering a Cauchy sequence $(x_n)_{n\in\mathbb{N}}\in\mathbb{R}$ since $\mathbb{R}$ is complete we know that there exists a $x\in\mathbb{R}$ such that $$||x_n-x||<\epsilon$$ Since for each $n\in\mathbb{N}$ , $A_n$ is bounded (hence continuous) we have $$||A_n(x_n)-A_n(x)||<\epsilon$$ And here is where i'm stuck because i cannot conclude that exists $A$ such that $$||A_n-A||<\epsilon$$","['banach-spaces', 'operator-theory', 'functional-analysis']"
