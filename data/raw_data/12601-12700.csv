question_id,title,body,tags
98801,Probability distribution function that does not have a density function,What is an example of the probability distribution function that does not have a density function?,['probability']
98805,How many solutions has $z^\pi = 1$?,"I know that for $z \in \mathbb C$ and some natural $n\geq 1$, the equation $z^n = 1$ has exactly $n$ solutions. But what if I say $n$ need not be natural, e.g. 
$$ z^\pi = 1.$$ I mean the equation can't have 3.14-something solutions, can't it?","['complex-numbers', 'algebra-precalculus', 'roots', 'polynomials']"
98808,"put 4 red, blue and green triangles in a row","How many ways are there to put 4 red, 4 blue and 4 green triangles in a row so that no blue triangles would lie next to each other. I got an answer, there are 126*56=7056 combinations. Could you check please, if the answer is right/wrong?",['combinatorics']
98819,finding values of $a$ for which the limit exists,"I've been banging my head all day long over this question, would apprecate some help :) $$f(x) = \frac{1}{x^2-1} - \frac{a}{x^3-1},\qquad a\in\mathbb{R}.$$
  For which values of $a$ does $\lim\limits_{x \to 1} f( x)$ exist? Also it was requested to use only the $\epsilon$-$\delta$ definition.","['calculus', 'functions', 'limits']"
98821,Expository articles on Analysis and Probability theory,"When I come across a notion from algebra or number theory which I don't know I usually check Keith Conrad's page to see if he has written something about it. Key features of his articles are a very clear exposition and carefully worked-out, well-chosen examples. Furthermore, he explains why the definitions are the way the are (why do we require a subring of a unital ring to have the same multiplicative identy as the original ring?). I am now looking for articles of similar style and quality explaining the basic notions of analysis (both real and complex analysis) and probability theory (so they should be aimed at undergraduate students). More specifically, I mean the notions (and central theorems) you would expect to learn in any undergraduate course on the subject at a German university. The content descriptions of the courses in the following document might give you an idea of what that means: mathematics.uni-bonn.de/study/master/files/MA_QualTest.pdf The courses are: Analysis I & II (page 2), Analysis III (page 3), Introduction to complex analysis (p. 4), Introduction to Probability & Stochastik Processes (both p. 6). I tried to find something using google and the only thing I found is http://www.mtts.org.in/expository-articles . There are articles on theorems from analysis on that site, but they focus on proofs and do not contain enough motivation for definitions or interesting examples (as far as I checked, I did not read them all). The articles should not be too dense (to give you an idea of what that means: They should not be as dense and short as the articles in the Princeton Companion). Note that I am looking for articles which are available freely online. I am aware of the related question Elementary Papers at ArXiv , however, I ask for articles explaining ideas and notions from analysis and probability theory only and do not require the articles to be posted on the arxiv.","['probability-theory', 'big-list', 'soft-question', 'real-analysis', 'complex-analysis']"
98825,Continuity in weak convergence implies continuity in norm convergence,"Let $X$ and $Y$ be norm spaces, and let $T:X\to Y$ be a linear transformation which is continuous under weak convergence. That is, if $\forall x^\star\in X^\star:x^\star x_n\to x^\star x $ then $\forall y^\star \in Y^\star:y^\star Tx_n \to y^\star Tx$. Prove that $T$ is continuous under norm convergence. That is, if $\|x_n\|\to\|x\|$ then $\|Tx_n\|\to\|Tx\|$. Any hints would be most welcomed. TIA,
Shai",['functional-analysis']
98828,Monotone convergence to a fixpoint in a Banach space,"Let $\mathscr X$ be a complete separable metric space and $\mathbb B$ be the Banach space of all real-valued bounded measurable functions on $\mathscr X$. The partial order on this space is introduced by 
$$
f\leq g \text{ iff }f(x)\leq g(x)\text{ for all }x\in \mathscr X.
$$
The operator $\mathscr A:\mathbb B\to\mathbb B$ is called monotone if $f\leq g$ implies $\mathscr Af\leq \mathscr Ag$, such operator is not necessary linear. Let us consider the function $f_0\in \mathbb B$ such that $\mathscr Af_0\geq f_0$ and construct the sequence $f_{n+1} = \mathscr A f_n$. Clearly, for any fixed $x\in \mathscr X$ the limit $\lim\limits_{n}f_n(x)$ exists (though it may be infinite) and the convergence is monotone. Let us assume that for any $x\in\mathscr X$ the limit is finite and denote it by $f(x)$. Is it true that
$$
f = \mathscr Af\quad?
$$","['functional-analysis', 'banach-spaces']"
98831,Continuity and Joint Continuity,"Consider a function $f(x,y):[0,1] \times [0,1] \rightarrow R.$ What is the difference between $f$ continuous in each argument and jointly continuous?",['real-analysis']
98879,Holomorphic and Harmonic functions,"I'm studying holomorphic functions in my Complex Analysis class and have encountered the following problem: Let $U,V$ be open subsets of $\mathbb{C}$ and $f$ be a holomorphic function on $U$ with range in $V$ and let $\phi : V \longrightarrow \mathbb{R}$ be harmonic. Prove that the composite function $g(z)= \phi (f(z))$ is harmonic on $U$. Thoughts: I think we may need to make use of the fact that the real and imaginary parts of holomorphic functions are harmonic respectively. I've come across the term 'harmonic conjugate' whilst working through the notes and feel this may also be involved. A proof that uses reasonably elementary properties of complex analysis would be highly appreciated. Regards as always, MM.","['general-topology', 'functions', 'complex-analysis']"
98880,Finding the Value of a Trigonometric Function,"I am trying to solve a homework problem that has to do with deciding which of two trigonometric functions is greater. This would be simple to do with a calculator, but the instructions explicitly say not to, so I've hit a wall. For example, I have to decide whether $\sin 30^{\circ}$ or $\tan 30^{\circ}$ is greater, but I do not understand how to do this. I know that  $\sin$ is $y/r$ and $\tan$ is $y/x$, but the only thing I can think of is that $\sin$ would have to be smaller because r is always larger than x . However, when the situation becomes  $\cos 26^{\circ}$ or $\cos 27^{\circ}$, I can only guess that  $\cos 27^{\circ}$ would be larger because, as $\theta$ comes closer to terminating at 90 degrees, y becomes larger and x becomes smaller, but that really doesn't help too much. Am I doing any of this correctly in terms of logic? I am not sure I understand the concept very well - my class's lessons are usually finished in ten to fifteen minutes... Thanks for any and all help.",['trigonometry']
98898,Combinations/Permutations Count Paths Through Grid,"I am curious about a situation in permutations/combinations. This question stems from a challenge site (project euler, problem 15) and research found on this exchange and elsewhere. The question involves finding a path through a 20 x 20 grid from one corner to another. This question has been generally addressed previously here: Counting number of moves on a grid But I am curious about the solution and was hoping to understand it further. The use of the algorithms for combinations and permutations makes sense to me. This problem can be though of by simplifying it to the fact there will always be 40 total moves, 20 of which will be down and 20 of which will be right to reach a valid end point. The solution involves using the algorithm for combinations, i.e. 40C20. Reading the responses it has been stated that order does not matter and as such this is a combination. However, traditionally I would think this would call for a permutation because although starting as (0,0) and going Right-Down or Down-Right both gets you to (1,1) they do so using different paths and I would think would need to be counted as unique. However, this does not appear to be the case. If thought of in terms of strings such as RRRRDDDD... for the series of moves, does not each unique position of an R and a D matter? Thanks for any help, I like to understand the concepts behind a problems solution before I move on, any additional explanation would be much appreciated.","['project-euler', 'combinatorics']"
98902,"Evaluating $\int\sin^3t \, dt$","I have this integral: $$\int\sin^3t \, dt$$ I have tried partial integration with $\sin t \cdot \sin^2t$, but then I get another integral to evaluate which needs partial integration: $$\dots \int \cos^2t \cdot \sin t \, dt \dots$$ Which gives me another integral that needs partial integration and so on. I get stuck in a partial integration loop. How should I evaluate this?","['trigonometry', 'calculus', 'integration']"
98907,Differentiability of Moreau-Yosida approximation.,"I want to show that if $X$ is a reflexive Banach space with norm of class $\mathcal{C}^1$ and $f\colon X\to\mathbb{R}\cup \{+\infty\}$ is convex and lower semicontinuous, then $f_{\lambda}$ is differentiable of class $\mathcal{C}^1$. (where $f_{\lambda}:X\to\mathbb{R}\cup \{+\infty\}$ is the Moreau-Yosida approximation: $$f_\lambda(x)=\inf_{y\in X} \left\{ f(y)+\frac{1}{2\lambda}|x-y|^2\right\})$$ Maybe, this result could be useful:
If $g\colon X\to\mathbb{R}$ is convex and differentiable in every point then $g\in\mathcal{C}^1(X)$. Many thanks in advance.","['convex-analysis', 'approximation', 'functional-analysis', 'banach-spaces']"
98916,How is a singular continuous measure defined?,"On a measurable space, how is a measure being singular continuous relative to another defined? I searched on the internet and in some books to no avail and it mostly appears in a special case - the Lebesgue measure space $\mathbb{R}$. Do you know if singular continuous measures can be generalized to a
more general measure space than Lebesgue measure space $\mathbb{R}$?
In particular, can it be defined on any measure space, as hinted by
the Wiki article I linked below? The purpose of knowing the answers to previous questions is that I would like to know to
what extent the decomposition of a singular measure into a discrete
measure and a singular continuous measure still exist, all wrt a refrence measure? Thanks and regards! PS : In case you may wonder, I encounter this concept from Wikipedia (feel it somehow sloppy though): Given $μ$ and $ν$ two σ-finite signed measures on a measurable space
  $(Ω,Σ)$, there exist two $σ$-finite signed measures $ν_0$ and $ν_1$
  such that: $\nu=\nu_0+\nu_1\,$ $\nu_0\ll\mu$ (that is, $ν_0$ is absolutely continuous with respect to $μ$) $\nu_1\perp\mu$ (that is, $ν_1$ and $μ$ are singular). The decomposition of the singular part can refined: $$
     \, \nu = \nu_{\mathrm{cont}} + \nu_{\mathrm{sing}} + \nu_{\mathrm{pp}} $$ where $\nu_{\mathrm{cont}}$ is the absolutely continuous part $\nu_{\mathrm{sing}}$ is the singular continuous part $\nu_{\mathrm{pp}}$ is the pure point part (a discrete measure).","['measure-theory', 'singular-measures', 'reference-request', 'real-analysis']"
98923,Open Sets of $\mathbb{R}^1$ and axiom of choice,"In the proof of 'Every open set in $\mathbb{R}^1$ is a countable union of disjoint open intervals', we need to pick one rational representative from each of the intervals hence establish the countability. This seems to depend on the axiom of choice. Thus I wonder does this property of $\mathbb{R}$ is equivalent to the axiom of choice, that is, is there any construction such that this property is not true once we abandon the axiom of choice? Thanks!","['logic', 'real-analysis', 'axiom-of-choice']"
98936,On atomic and atomless subsets,"In a measure space, let's call a measurable subset atomless wrt the measure, if it does not have an atomic subset . In particular a measurable subset with zero measure is atomless. There may be measurable subsets that are neither atomic nor atomless, for instance, the union of atomic subset(s) and atomless subset(s) with positive measure(s). I was wondering if the converse is true, i.e. if a measurable subset
is neither atomic nor atomless, then must it be the union of atomic
subset(s) and atomless subset(s) with positive measure(s)? I think the previous question is equivalent to whether any measurable subset
can be partitioned into atomic subset(s) and atomless subset(s)? Thanks and regards!",['measure-theory']
98965,Significance of  $\sigma$-finite measures,"From Wikipedia : The class of $\sigma$-finite measures has some very convenient properties;
  $\sigma$-finiteness can be compared in this respect to separability of
  topological spaces. Some theorems in analysis require σ-finiteness as
  a hypothesis. For example, both the Radon–Nikodym theorem and Fubini's
  theorem are invalid without an assumption of $\sigma$-finiteness (or
  something similar) on the measures involved. Though measures which are not σ-finite are sometimes regarded as
  pathological, ... I was wondering what makes  $\sigma$-finite measures so natural to mathematicians ( they often think of them in the first place when it comes to measures , while I as a layman don't have that instinct), well-behaved (as opposite to ""pathological"") and important (appearing in conditions in many theorems such as Radon-Nikodym, Lebesgue decomposition and Fubini's Theorems)? In what sense/respect, can $\sigma$-finiteness be compared to separability of topological spaces? For example, are most or all properties true for finite measures also true for $\sigma$-finite measures, but not for general infinite measures? If yes, why is that? Are all above because of equivalence of $\sigma$-finite measures to probability measures ? If yes, how is it the reason? Thanks and regards!","['general-topology', 'measure-theory', 'intuition']"
98973,List applications of sets & relations in science/business/tech that a highschooler can understand,"What are some applications of sets & relations in science/business/tech that a highschooler can understand? To kindle a young mind, what examples can be given?","['big-list', 'examples-counterexamples', 'elementary-set-theory']"
98981,How to win at roulette?,"I know that the answer to my attention-grabbing question is : ""You can't win at roulette, it's a negative Expected Value game"". Yes, you're right, long term speaking . Let's imagine a medium-short term situation (just an after-dinner at the casinò) where there will be <100 bets. What's the best strategy to use to win some money? I imagine a hypothetical formula that considers our ""money target"" and percentage of success as inversely proportional (the more we want to win the less likely we are going to succeed). What do you think? Are those ""red-black double if lose"" systems useful?",['probability']
98990,Can one deduce Liouville's theorem (in complex analysis) from the non-emptiness of spectra in complex Banach algebras?,"As you probably know, the classical proof of the non-emptiness of the spectrum for an element $x$ in a general Banach algebra over $\mathbb{C}$ can be proven quite easily using Liouville's theorem in complex analysis: every bounded, entire function $\mathbb{C} \to \mathbb{C}$ is constant. As these two theorems seem closely related and are certainly strong and non-trivial (for instance, both of them easily imply the fundamental theorem of algebra), I wonder if it is also possible to deduce Liouville's theorem from the non-emptiness of spectra for elements in complex Banach algebras. I guess one would like to to apply the Gelfand-Mazur theorem (which is a simple corollary of the above non-emptiness) to the Banach algebra of bounded, entire functions on $\mathbb{C}$ but showing that this is a division algebra is basically the same as showing that it is equal to $\mathbb{C}$ to begin with.","['banach-algebras', 'complex-analysis']"
98996,Continuous map between spheres [duplicate],"This question already has an answer here : Closed 11 years ago . Possible Duplicate: Continuous map $\mathbb{S}^n\to \mathbb{S}^m$ Why is every continuous function $f:\mathbb{S}^n\to\mathbb{S}^m,$ for $n<m$ homotopic to a constant map? Thanks.",['general-topology']
98998,Why $x<\tan{x}$ while $0<x<\frac{\pi}{2}$?,"In proof of $\displaystyle\lim_{x\rightarrow0}\frac{\sin{x}}{x}=1$ is assumed that $\sin{x}\leq{x}\leq\tan{x}$ while $0<x<\frac{\pi}{2}$. First comparison is clear, arc length must be greater than sine value, but how about $x\leq\tan{x}$, why tangent is longer than arc?","['trigonometry', 'inequality', 'limits']"
99009,Proof: Tangent space of the general linear group is the set of all squared matrices,"Let us assume we have the following definition of a tangent space: Definition of smooth path Let $X\subset\mathbb{R}^n$. Let $I$ be a real interval.
 \begin{equation}
P \text{ is a smooth path in } X \quad:\Leftrightarrow\quad P:I\rightarrow X \text{ is a differentiable function}~.
 \end{equation} Definition: Tangent vector
 at the identity Let $P$ be a smooth path with $P(0) = \mathtt{I}$.
 \begin{equation}
t \text{ is the tangent vector of } P \text{ at the idenity}
\quad:\Leftrightarrow\quad t=\frac{\partial}{\partial x}P(x)|_{x=0}
 \end{equation}
Moreover, we call $t$ a tangent vector 
of a space $X$, if a path $P:I\rightarrow X$ exists such that $t$ is  tangent vector of a $P$. Definition: Tangent space We call the space of all tangent vectors (at the identity), the tangent space (at the identity). Using these definitions, (how) can we show that the tangent space of all invertible matrices $GL(n)$ is indeed the space of all $n\times n$ matrices? (I'd like to rely mainly on these definitions and do not use the notion of the 
exponential map if possible...)","['matrices', 'lie-groups', 'differential-geometry']"
99015,Counting ordered tuples with an additional condition,"Let $a_1 \le a_2 \le ... \le a_n$ be positive integers. I'm looking for a closed formula of  the number $f(a_1,...,a_n)$ of all (ordered) tuples $(x_1,...,x_n)$ of positive integers statisfying 
$$x_1 + ... + x_i \le a_i\quad\quad(i=1,...,n).$$
$f$ has the recursion $f(a_1,...,a_n) = \sum_{k=1}^{a_1}f(a_2-k,...,a_n-k)$ that also yields the sum expression 
$$f(a_1,...,a_n) = \sum_{x_1=1}^{a_1}\sum_{x_2=1}^{a_2-x_1}...\sum_{x_n=1}^{a_n-x_1-...-x_{n-1}}1$$
The only case I know of is for $a_1=...=a_n$ when one obtains $\binom{a_n}{n}$ what is also an upper bound for $f(a_1,...,a_n)$. Edit: Using the transformation $y_i = x_1 + ... + x_i$ one finds that the searched $f$ equals the number of ordered tuples $1 \le y_1 < y_2 < ... < y_n \le a_n$, satisfying the additional condition $y_i \le a_i$ for all $i$. It's classical that the number of ordered tuples $1 \le y_1 <...<y_n \le a$ equals the number of k-element subsets of $\lbrace 1,...,a\}$ which is $\binom{a}{n}$. Perhaps it's possible to extend one of the solutions for this classical formula to my problem ?",['combinatorics']
99016,Proof that $e=\sum\limits_{k=0}^{+\infty}\frac{1}{k!}$,How can it be proved that the Euler constant equals the limit of the sum of all $\frac{1}{k!}$ when $k$ goes from $0$ to $+\infty$ ?,"['exponential-function', 'limits']"
99025,What is the expectation of $ X^2$ where $ X$ is distributed normally?,"I know that if $X$ were distributed as a standard normal, then $X^2$ would be distributed as chi-squared , and hence have expectation $1$, but I'm not sure about for a general normal. Thanks","['statistics', 'normal-distribution']"
99029,Probability of choosing the correct stick out of a hundred. Challenge from reality show.,"So I was watching the amazing race last night and they had a mission in which the
contestants had to eat from a bin with 100 popsicles where only one of those popsicles had a writing on its stick containing the clue. Immediately I thought well of course choosing the correct stick is 1 in a 100. So taking the correct stick on the first try probability is $\frac{1}{100}$.
Then on the second attempt it should be  $\frac{1}{99}$ and so on. 
Multiplying these results give a huge number and so it seems that the more times you try the probability of getting the correct stick decreases. while it seems that the more times you try it more probable for you to get the correct stick. So how do you calculate the probability of getting the correct one first try? 
the second? What about last? I mean the probability of trying 100 times to get the correct stick? Thanks.",['probability']
99042,Finding a generator of $(\mathbb Z/p\mathbb{Z})^*$,"Is there a method for finding a primitive element (generator) of $(\mathbb Z/p\mathbb{Z})^*$, where $p$ is a prime number?","['finite-groups', 'group-theory', 'number-theory']"
99052,The $\omega$ function that proves that a function is differentiable at a point $a$,"I'll start by listing a definition: ""The function $f$ is differentiable in a $\in$ $D^0$ if there is a number $A_a \in R$ and a function $\omega_a$ continuous and null in $a$ so that, for any $x \in D$ we have: $$f(x)-f(a)=A_a(x-a)+\omega_a(x)(x-a)$$ where $\lim_{a\to\infty}\omega_a(x)=\omega_a(a)=0$ Immediately we see that $A_a=f'(a)$"" Now, I've found an example but I don't see very well how it's related to the formula above. The problem asks to prove that for a=1 $f$ is not differentiable in $(0,0)$ and for $a>1 \ f$ is differentiable in the origin. $$f(x,y)=\frac{x^2y}{\sqrt{x^2+y^2}}, \ x^2+y^2\not=0$$
$$f(x,y)=0, \ x^2+y^2=0$$ $$f(x,y)=\frac{\partial f}{\partial x}(0,0)(x-0)+\frac{\partial f}{\partial y}(0,0)(y-0)+\omega(x,y)\sqrt{x^2+y^2}$$ I guess the last row applies the formula listed in the definition (right?). But in the last part in the definition formula says $\omega_a(x)(x-a)$, shouldn't then be?
$$f(x,y)=\frac{\partial f}{\partial x}(0,0)(x-0)+\frac{\partial f}{\partial y}(0,0)(y-0)+\omega(x,y)(x-0)$$","['calculus', 'derivatives']"
99056,Limit $\frac{0}{0}$ which tends to $\frac{\pi}{2}$,"I'm trying to evaluate the following limit:
$$\lim_{x\rightarrow\pi/2}\frac{\cos(x)}{(1-\sin(x))^{2/3}}$$
The limit has the form $\frac{0}{0}$, I've tried using L'Hopital's rule but I can't resolve it.
Any idea?",['calculus']
99082,"How can I compare two averages of imperfect measurements, with their std. deviations?","I have a process by which I measure the times it take to do something, (run some code), and this time varies, a lot. I'm trying to optimize this code, making small changes that sometimes have small impacts on performance, and I want to try and see whether the change actually made a difference or not (And if so, how much of a difference) What i'm doing right now is I run one code 10 times, time each of them, and take an average and a standard deviation. I do the same for the second code. And then... That's where I'm stuck. How can I compare two averages and their standard deviations, to know which one is greater and how greater, or to know they are actually the same (because the difference is not statistically significant) 2 examples: 1) Avg: 13577       Std Dev:    114 Avg: 13929       Std Dev:    220 2) Avg: 24759       Std Dev:    34 Avg:    24196       Std Dev:    110 The first case are two runs of the same code, so whatever I do to compare should tell me those two are just as fast. The second case are two runs of different codes, one of which had a ""feature"" disabled, which does make it a bit faster, I just don't know how much. How can I know whether one test was faster than the other? How can I know how much faster/slower? I'm doing 10 runs, ""just because"". How would I know if 10 runs is too little to know, and I need to have more runs per test? (or in other words, I believe, how do I know if my deviation is too big and I need to lower it?) UPDATE : Turns out my question is an exact duplicate of this: https://stats.stackexchange.com/questions/16018/how-can-i-determine-if-theres-a-statistically-significant-difference-between-tw","['statistics', 'standard-deviation', 'average']"
99083,What is $f(x)$ divided by $(x-a)$?,"This is an exercise from Spivak's Calculus: Prove that for any polynomial function $f$, and any number $a$, there is a polynomial function $g$, and a number $b$, such that $f(x)=(x-a)g(x)+b$ for all $x$. (The idea is simply to divide $(x-a)$ into $f(x)$ by long division, until a constant remainder is left. [. . .] A formal proof is possible by induction on the degree of $f$. I did an adaptation of this question and decided to figure out precisely what $g(x)$ and $b$ are. Here is what I ended up with: First, presume $f$ takes the form:
$$f_n(x)=\sum_{u=0}^{n}c_ux^u$$ Then:
$$f_n(x)=(x-a)\sum_{q=1}^{n}\sum_{z=q}^{n}a^{z-q}c_zx^{q-1}+\sum_{z=0}^{n}a^zc_z$$ I've had a really hard time figuring out a clean and nice way to show this is true. But, I'm pretty sure it's accurate. I can't quite show the extensive work in deriving this because it's a lot of synthetic division and long division, then noticing patterns among the remainders and the quotients. My manipulations of double sums are not that great, so I'd appreciate if anyone could either 1) show that I'm wrong (which is very possible) or 2) show how this is right, in a preferably elegant way. One method is thus: Assuming that $b=\sum_{z=0}^{n}a^zc_z$, then $g(x)$ could be derived by 'basic' algebra:
$$\sum_{u=0}^{n}c_ux^u=(x-a)g(x)+\sum_{z=0}^{n}a^zc_z \Rightarrow g(x)=\frac{\sum_{u=0}^{n}c_ux^u-a^{u}c_u}{(x-a)}$$
$$g(x)=\frac{\sum_{u=0}^{n}c_u(x^u-a^u)}{(x-a)}$$
$$\frac{x^u-a^u}{(x-a)}=\sum_{k=1}^{u}a^{u-k}x^{k-1}$$
$$\therefore g(x)=\sum_{u=0}^{n}\sum_{k=1}^{u}a^{u-k}c_ux^{k-1}$$ This seems to contradict what I just wrote, but it brings up another question:
Is $$\sum_{u=0}^{n}\sum_{k=1}^{u}a^{u-k}c_ux^{k-1}=\sum_{q=1}^{n}\sum_{z=q}^{n}a^{z-q}c_zx^{q-1}\text{?}$$ I think it is, and I can show that thus: First, change the right hand side: $\sum_{k=1}^{n}\sum_{u=k}^{n}a^{u-k}c_ux^{k-1}$. Then, make the substitution $e_{u,k}=a^{u-k}c_ux^{k-1}$ So, you have: $$\sum_{u=0}^{n}\sum_{k=1}^{u}e_{u,k}=\sum_{k=1}^{0}e_{0,k}+\sum_{k=1}^{1}e_{1,k}+\sum_{k=1}^{2}e_{2,k}+\dots+\sum_{k=1}^{n-2}e_{(n-2),k}+\sum_{k=1}^{n-1}e_{(n-1),k}+\sum_{k=1}^{n}e_{n,k}$$
$$\sum_{u=0}^{n}\sum_{k=1}^{u}e_{u,k}=\sum_{k=1}^{n}e_{n,k}+\sum_{k=1}^{n-1}e_{(n-1),k}+\sum_{k=1}^{n-2}e_{(n-2),k}+\dots+\sum_{k=1}^{2}e_{2,k}+\sum_{k=1}^{1}e_{1,k}+\sum_{k=1}^{0}e_{0,k}$$ Each sum can be modified thusly: $$\sum_{k=1}^{n-j}e_{(n-j),k}=\sum_{k=(1+j)}^{n}e_{(n-j),(k-j)}$$ So, by inspection, the two sums are equivalent. I guess what my question now amounts to is thus: Are there any methods I'm simply not using that I could be using? And am I incorrect in any of my methods and statements above? Feel free to use a completely different approach to solve this, I'd like to see other approaches. P.S. If you would like, feel free to provide a proof of the original problem by induction.","['sequences-and-series', 'algebra-precalculus', 'polynomials']"
99084,Locally compact topological group is Normal,"How can I prove directly that a locally compact topological group G is normal? 
I have done this by showing that every locally compact topological group is strongly Paracompact. But I could not prove it directly.","['general-topology', 'topological-groups']"
99086,How do you prove that $\ell_p$ is not isomorphic to $\ell_q$?,"I guess that for all  $1\le p,q<\infty $, such that $p\ne q$ , the spaces $\ell_p$ and $\ell_q$ are not isomorphic, but how do you prove this?","['lp-spaces', 'functional-analysis', 'banach-spaces']"
99097,Is a limit a variable or a constant? Is a limit an exact value or approximate value?,"My question: Is a limit a variable or a constant? Is a limit an exact value or approximate value? My current understanding of the limit is that it is a constant based on applications related to physics such as terminal velocity.  Also, I believe that since a limit can possibly be infinity, that limits are not exact values.  Please tell me how I can understand this better.  Thanks.","['calculus', 'limits']"
99112,Outline and Goals of a One-Year Calculus Sequence,"Our department is considering restructuring our traditional three semester calculus sequence so that the calculus requirement for our majors is satisfied in two semesters. Does your department offer such a two
  semester sequence and, if so, could
  you provide a rough outline of topics
  covered and/or textbooks used? What
  are your department's learning goals
  for this sequence? If your department
  does not offer such a sequence, has it
  been considered? We are particularly interested in responses from faculty at small liberal arts colleges. Addendum: It has been suggested that we consider, for the first semester, accelerating the Calculus I (differentiation) part of the course by reviewing for a week and then proceeding with Calculus II (integration) at the usual pace. The second semester is then dedicated to multivariable calculus. If your institution has tried this, feedback on this would be helpful. Note: We intend to offer the abridged sequence only for mathematics majors (or perhaps mathematics and physics majors).","['education', 'calculus']"
99126,Conjugacy classes of a $p$-group,"This is a problem from Preliminary Exam - Spring 1984, UC Berkeley For a $p$-group of order $p^4 $, assume the center of $G$ has order $p^2 $.
  Determine the number of conjugacy classes of $G$. What I have tried: each element of the center constitutes a conjugacy class; the other conjugacy classes have order a power of $p$; their sum is $ \ p^{4} - p^{2}$.","['finite-groups', 'group-theory', 'p-groups']"
99158,Rudin Principles Theorem 2.40: Every k-cell is compact.,"In the proof $I$ is a $k$-cell whose coordinates are bounded by $a_{j}\le x_{j}\le b_{j}$ where $1\le j\le k$. From the proof: Put $c_{j}=(a_{j}+b_{j})/2$.
The intervals $[a_{j},c_{j}]$ and $[c_{j},b_{j}]$ then determine
$2^{k}$ $k$-cells $Q_{i}$ whose union is $I$.
What does each of the $Q_{i}$ look like?",['real-analysis']
99175,Solutions to the matrix equation $\mathbf{AB-BA=I}$ over general fields,"Some days ago, I was thinking on a problem, which states that $$AB-BA=I$$ does not have a solution in $M_{n\times n}(\mathbb R)$ and $M_{n\times n}(\mathbb C)$ . (Here $M_{n\times n}(\mathbb F)$ denotes the set of all $n\times n$ matrices with entries from the field $\mathbb F$ and $I$ is the identity matrix.) Although I couldn't solve the problem, I came up with this problem: Does there exist a field $\mathbb F$ for which that equation $AB-BA=I$ has a solution in $M_{n\times n}(\mathbb F)$ ? I'd really appreciate your help.","['matrix-equations', 'matrices', 'linear-algebra', 'field-theory']"
99206,Discontinuous linear functional,"I'm trying to find a discontinuous linear functional into $\mathbb{R}$ as a prep question for a test. I know that I need an infinite-dimensional Vector Space. Since $\ell_2$ is infinite-dimensional, there must exist a linear functional from $\ell_2$ into $\mathbb{R}$. However, I'm having trouble actually coming up with it. I believe I'm supposed to find an unbounded function (although I'm not sure why an unbounded function is necessarily not continuous; some light in that regard would be appreciated too), so I thought of using the vectors $e^i$, which have all entries equal to zero, except for the $i$-th one. Then, you can define $f(e^i)=i$.  That'd be unbounded, but I'm not sure if it'd be linear, and even if it is, I'm not sure how to define it for all the other vectors in $\ell_2$. A friend mentioned that at some point the question of whether the set $E=\{e^i:i\in\mathbb{Z}^+\}$ is a basis would come up, but I'm not sure what a basis has to do with continuity of $f$. I'm just learning this topic for the first time, so bear with me please. The space of sequences that are eventually zero (suggested by a few people) turned out to be exactly what I needed.  It also helped to cement the notions of Hamel basis, not continuous, etc.","['examples-counterexamples', 'functional-analysis', 'real-analysis']"
99221,Does $n^{\log n}$ or $(\log n)^n$ grow faster?,"Which grows faster? $n^{\log n}$ or $(\log n)^n$ and how can we prove this? This was presented as a ""challenge question"" for students to try ahead of the next class meeting. Any help would be appreciated!","['asymptotics', 'limits']"
99236,Is the general linear group generated by elementary matrices?,"(Cfr. Wikipedia for the definition of Elementary matrix). Have a look at the following excerpt of Jacobson's Basic algebra vol.I, 2nd edition, pag.186. There exist PID in which not every invertible matrix is a product of elementary ones. An example of this type is given in a paper by P.M.Cohn, On the structure of the $\text{GL}_2$ of a ring , Institut des Hautes Etudes Scientifiques, #30 (1966), pp 5 - 54. This leaves me puzzled. Take an invertible matrix $A$ over a PID. Then $A$ has a Smith normal form , that is, up to elementary row and columns operations it is equivalent to something like this $$\begin{bmatrix} d_1 & && \\ & d_2 &&\\ &&\ddots&\\ &&&d_n\end{bmatrix}.$$ In particular $\det A= d_1\ldots d_n u$ for some unit element $u$ . But $\det A$ needs be unit, so all of $d_i$ 's are units, which means that up to some other elementary row operation $A$ is equivalent to the identity matrix. It seems to me that we have just proven that $A$ is the product of elementary matrices, which is false as of Jacobson's claim. There must be an error somewhere, but where? Thank you.","['matrices', 'group-theory', 'abstract-algebra']"
99265,Approximate $\int_{0}^{\infty} \frac{\text{d} x}{1 + x^4}$,"Now, I have been given this integral. And need to approximate it. My first idea was to use a Taylor series, but this series explodes, as x reaches infinity. Does anyone know how to approximate improper integrals, (and this one in particular)? I know I can use contour-integration to evaluate it exact, but I want to estimate it.
Someone mentioned something about a Taylor expansion at infinity, but alas I have not learned about this. $$ \int_{0}^{\infty} \frac{\text{d} x}{1 + x^4} $$","['approximation', 'integration']"
99274,Conjugacy classes in group extensions,Consider a normal subgroup $N$ of a finite group $G$. How are the conjugacy classes of $G$ related to $G/N$ and $N$?,"['group-extensions', 'finite-groups', 'group-theory']"
99293,Category-theoretic limit related to topological limit?,"Is there any connection between category-theoretic term 'limit' (=universal cone) over diagram, and topological term 'limit point' of a sequence, function, net...? To be more precise, is there a category-theoretic setting of some non-trivial topological space such that these different concepts of term 'limit' somehow relate? This question came to me after I saw ( http://www.youtube.com/watch?v=be7rx29eMr4 ) a surprising fact that generalised metric spaces can be seen as categories enriched over preorder $([0,\infty],\leq)$.","['general-topology', 'category-theory', 'limits-colimits', 'limits']"
99295,Geodesic on a plane,"I guess that each geodesic on a plane is a straight line. Is it right? What can I use to prove it?
I guess I have to use somehow Levi-Civita connection.","['manifolds', 'differential-geometry']"
99296,"Relationship between two random, normally distributed variables","I have two normally distributed random variables, X and Y. X has mean 66 and standard deviation 6. Y has mean 77 and standard deviation 7. The correlation between the random variables is given as 0.8. The task is to find the probability $$P(X > 0.7Y)$$ This is my attempt: Create the random variable $$D = 0.7Y - X$$ and calculate $$P(D < 0)$$ The variable D should also be normally distributed with these properties: $$\mu_D = 0.7 \times 77 - 66 = -12.1$$
$$\sigma^2_D = 0.7^2 \times 49 + 36 + 2 \times 0.7 \times -1 \times 0.8 \times 7 \times 6 = 12.97$$ Then, $$P(D < 0) = F_Z\left(\frac{0 + 12.11}{\sqrt{12.97}}\right) \approx F_Z(3.36)$$ But, this is not the answer I'm supposed to get (which is instead $$F_Z(1.17)$$ according to the textbook). Where am I going wrong?","['probability-distributions', 'probability']"
99299,Best Fitting Plane given a Set of Points,Nothing more to explain. I just don't know how to find the best fitting plane given a set of $N$ points in a $3D$ space. I then have to write the corresponding algorithm. Thank you ;),['linear-algebra']
99318,Estimation of $\mathbb{P}(X > t)$,"Let $X_1, \ldots, X_n \sim X$ be iid random variables. The goal is to find an estimator of $\theta = \mathbb{P}(X > t)$ for a given $t > 0$. 1) Show that $\hat{\theta}_1 = 1 - F_n(t)$ is an unbiased estimator of $\theta$ and find its MSE ($F_n$ is the empirical distribution function). 2) Let now $X_1, \ldots, X_n$ be exponential($\lambda$). Find the UMVUE of $\theta$. (Hint: $X_1$ and $X_1/\sum_{i=1}^n X_i$ are independent and the pdf of $X_1/\sum_{i=1}^n X_i$ is : $(n-1)(1-x)^{n-2} \mathbb{I}_{ x \in (0,1) }$) Some thoughts 1) If I'm not wrong: $$
\hat{\theta}_1 = 1 - F_n(t) = \frac{1}{n} \sum_{i=1}^{n} \mathbb{I}_{\{X_i > t \}}
$$ Therefore $n \hat{\theta}_1 \sim \mathrm{Binomial}(n, 1 - F_X(x))$ and then: $$
\mathbb{E}(\hat{\theta}_1) = \frac{1}{n}\mathbb{E}(n\hat{\theta}_1) = 1 - F_X(x) = \mathbb{P}(X > x) = \theta \qquad \mathrm{(unbiased)}
$$
$$
\mathrm{MSE}(\hat{\theta}_1) = \mathbb{V}(\hat{\theta}_1) = \frac{1}{n^2}\mathbb{V}(n\hat{\theta}_1) = \frac{\theta(1-\theta)}{n}
$$ 2) We know that $\hat{\theta}_1$ is an unbiased estimator of $\theta = e^{-t/ \lambda}$ and $S = \sum_{i=1}^n X_i$ is a complete sufficient statistic of $\lambda$. Therefore $U = \mathbb{E}(\hat{\theta}_1 \, | \, S)$ is the UMVUE of $\theta$. The problem is that I'm unable to ""compute"" $U$ or find an alternative solution. Edit: Alternative solution I think I've found an alternative (and rather tedious) solution which doesn't make use of the hint. I was trying to write it as a comment, but it was too long. Mr. Hardy's answer is clearer and better in any sense, so I apologize in advance. From Michael Hardy's answer: Notice that $W=\mathbb{I}_{\{X_1>t\}}$ is an unbiased estimator of
  $\theta$, so the Rao-Blackwell estimator is $\mathbb{E}(W\mid S)$. 
  Because of completeness, [...] all unbiased estimators
  based on the sufficient statistic $S$ will be the same. So we seek $\mathbb{E}(W\mid S) = > \Pr(X_1>t\mid S)$, and this must be equal to $\mathbb{E}(\hat{\theta}_1 \mid S)$. The conditional pdf of $X_1$ given $S = s$ is: $$f_{X_1 | S = s}(x) = \frac{f_{X_1,S}(x,s)}{f_S(s)} $$ We know that $S$ is a Gamma r.v. because it is the sum of $n$ Exponential r.v. :
$$f_S(s) = \frac{\lambda^{-n} s^{n-1} e^{-s/\lambda}}{(n-1)!} $$ The joint distribution can be rewritten as $f_{X_1,S}(x,s) = f_{X_1}(x)f_{S | X_1 = x}(s)$. It should also be noted that:
$$
\begin{align}
\mathbb{P}(S \leq s | X_1 = x) &= \mathbb{P} \left(\left. x + \sum_{i=2}^n X_i \leq s \; \right|\; X_1 = x \right) \\ &= \mathbb{P} \left(\left. \sum_{i=2}^n X_i \leq s -x \; \right|\; X_1 = x\right) \\ &= \mathbb{P} \left(\sum_{i=2}^n X_i \leq s -x\right) 
\end{align}
$$
Where $\sum_{i=2}^n X_i$ is a Gamma r.v.. Thus: $$
f_{S | X_1 = x}(s) = f_{\sum_{i=2}^n X_i}(s-x) = \frac{\lambda^{-(n-1)} (s-x)^{n-2}e^{-(s-x)/\lambda}}{(n-2)!}
$$ If $S = s$, then $0 \leq X_1 \leq s$. If we simplify it turns out that: $$
f_{X_1 | S = s}(x) = (n-1) \frac{(s-x)^{n-2}}{s^{n-1}} \,  \, \mathbb{I}_{\{0 \leq x \leq s\}}
$$ Finally: $$
\mathbb{P}(X_1 > t | S = s) = \int_{t=1}^S (n-1)\frac{(s-x)^{n-2}}{s^{n-1}} \, \mathrm{d}x = \frac{n-1}{s^{n-1}}\left[- \frac{(s-x)^{n-1}}{n-1} \right]^{s}_{t} = \left(1 - \frac{t}{s}\right)^{n-1}$$ Which is exactly the same thing.",['statistics']
99324,How to prove that $\lim \frac{1}{n} \sqrt[n]{(n+1)(n+2)... 2n} = \frac{4}{e}$,I'd like a hint to show that: $$\lim _{n\to\infty}\frac{1}{n} \sqrt[n]{(n+1)(n+2) \cdots 2n} = \frac{4}{e} .$$ Thanks.,"['factorial', 'radicals', 'calculus', 'limits']"
99333,$x$ conjugate to $y$ in a group $G$ is an equivalence relation on $G$,"This is a question from the free Harvard online abstract algebra lectures .  I'm posting my solutions here to get some feedback on them.  For a fuller explanation, see this post. This problem is from assignment 5. a) Prove that the relation $x$ conjugate to $y$ in a group $G$ is an equivalence relation on $G$ . b) Describe the elements $a$ whose conjugacy class (= equivalence class) consists of the element $a$ alone. a) Let $G$ be a group and $R$ be a relation on $G$ defined by $a\sim b$ if $a$ is conjugate to $b$ .  Then $a\sim b$ if there is a $g\in G$ such that $a = gbg^{-1}$ .  Let $a$ be an element of $G$ .  Then $a=eae^{-1}$ .  So $a\sim a$ and $R$ is reflexive.  Let $a$ and $b$ be elements of $G$ such that $a\sim b$ .  Then there is a $g\in G$ such that $a=gbg^{-1}$ .  Then $b=g^{-1}ag$ .  Since $g^{-1}\in G$ , $b\sim a$ .  Hence, $R$ is symmetric.  Let $a,b$ , and $c$ be elements of $G$ such that $a\sim b$ and $b\sim c$ . Then there are elements $g,g^\prime\in G$ such that $a=gbg^{-1}$ and $b=g^\prime cg^{\prime -1}$ .  Then $a=g(g^\prime c g^{\prime -1})g^{-1}=(gg^\prime)c(g^{\prime -1}g^{-1})=(gg^\prime)c(gg^\prime)^{-1}$ . Since $gg^\prime\in G$ , $a\sim c$ .  Hence $R$ is transitive.  Therefore $R$ is an equivalence relation on $G$ . b) Let $S$ be the set of elements of $G$ such that, for $s\in S$ , $s=gsg^{-1}$ for any $g\in G$ .  Then $sg=gs$ .  So $S$ is the set of elements that commute with every element of $G$ .  In other words, $S$ is the center of $G$ . Again, I welcome any critique of my reasoning and/or my style as well as alternative solutions to the problem. Thanks.","['group-theory', 'abstract-algebra']"
99339,Elementary problems with group theoretic solutions,"I am helping a friend develop a course in abstract algebra that is designed for high school students who have no knowledge of abstract algebra or any real exposure to formally rigorous mathematics. To motivate the study, we are seeking problems whose statement will be immediately accessible to the students, but whose solution is aided by basic tools of group theory. So my question is this: What are some interesting problems, whose statements are comprehensible to an average 9th or 10th grade high school student, but whose solutions are greatly aided by group theory? Here is the best type of example I have thought of so far for what we are looking for: How many distinct ways are there to 2-color the 8 vertices of a cube, with colorings only considered distinct up to rotation? The problem is very tricky by direct enumeration (how do you know when you're done?) but submits to a double-counting method based on the orbit-stabilizer theorem. This is perfect because the question is natural and kids could get started by direct enumeration; but the group theory really adds a lot of power. Also, the type of group theory needed is at the right level: Lagrange's theorem and its corollary the orbit-stabilizer theorem. These are significant pieces of theory but are realistic to get to in this setting. Problems solvable by computation in some specific group (e.g. can you get a line of people into an arbitrary order by switching them 2 at a time?) are also useful to us but will do less to motivate the theory. Meanwhile, problems involving heavier theory (e.g. Sylow theorems) will be hard to use because it is not realistic to plan on developing this theory in the (1-semester, and slow b/c for high school students) course. Can you help me brainstorm questions of this kind? Thanks so much. Update (1/16): These answers are helpful, and my friend may well use them. I am hoping for more though! Specifically, I am hoping for more problems that require (a small amount of) group theory and not just a calculation in some specific group, because the idea is to use the problems to motivate the theory. For example, the Futurama problem is adorable (and therefore great for HS students!), but seems to be pretty much a calculation in $S_n$. The mattress problem is a little more what I'm talking about here because the proffered solution involves concepts central to the theory like cyclic groups, and the theorem (grantedly a minor one but still a theorem ) that cyclic groups have at most one element of order 2. Ideally the solution to the problem involves invoking an important and not very hard theorem of group theory. Examples of the types of concepts and theorems I'd ideally like to see used: Subgroups, homomorphisms, normal subgroups, quotients Lagrange's theorem / the orbit-stabilizer theorem (this is the virtue of the cube-coloring enumeration problem) The first isomorphism theorem Basic facts about actions: the stabilizer is a subgroup; stabilizers of objects in the same orbit are conjugate; etc. Any more ideas folks? Thanks again.","['big-list', 'education', 'group-theory']"
99343,Is $(XY - 1)$ a maximal ideal in $k[[X]][Y]$?,"Is $(XY - 1)$ a maximal ideal in $k[[X]][Y]$, and if so, how can I see it? It is at least prime because the generator is irreducible, and by the same argument it is maximal among all principal ideals. But I haven't gotten further than that - Finding units in the quotient ring didn't turn out well, either.","['commutative-algebra', 'ideals', 'maximal-and-prime-ideals', 'abstract-algebra']"
99345,Show that if $x_n \to x$ then $\sqrt{x_n} \to \sqrt{x}$,"Show that if $x_n \to x$ then $\sqrt{x_n} \to \sqrt{x}$ I have been stuck on this for a while. I tried $$|\sqrt{x_n} - \sqrt{x}| = \frac{|x_n - x|}{|\sqrt{x_n} + \sqrt{x}|},$$ and then I at least can get the top to be as small as I want, so I have $$\frac{\epsilon}{|\sqrt{x+\epsilon} + \sqrt{x}|},$$ but I get stuck here at choosing the N, and I don't know if my first step in breaking down the absolute value is legitimate. Please help.","['radicals', 'sequences-and-series', 'real-analysis', 'limits']"
99351,Limit with a summation,"I'm getting crazy with the next limit:
$$\lim_{n\rightarrow\infty}\frac{\sum \limits_{k=1}^n(k·a_k)}{n^2}$$
The exercise also says that is known that: $$\lim_{n\rightarrow\infty}a_n = L$$ I suppose that I have to answer in function of ""$L$"", but I still can't see anything. Any ideas?","['sequences-and-series', 'calculus', 'limits']"
99369,Absolute value of Brownian motion,"I need to show that $$R_t=\frac{1}{|B_t|}$$ is bounded in $\mathcal{L^2}$ for $(t \ge 1)$, where $B_t$ is a 3-dimensional standard Brownian motion. I am trying to find a bound for $\mathbb{E}[\int_{t=1}^{\infty}R^2_t]$. Asymptotically $B_t^i$ is between $\sqrt{t}$ and $t$. I also know that $|B_t| \to \infty$, but the rate is not clear. Hints would be helpful.","['probability', 'brownian-motion']"
99376,Maximum triangle area,"I have a small problem. Consider I have a triangle. Which maximum area can it cover if two of his medians are 3 and 8?
I think I'll need to use derivative here, but firstly I need to find a function of an area which it covers. I actually tried to use some sorts of formulas but didn't succeed. Could anyone give me a hint at least?
Thanks","['geometry', 'triangles', 'derivatives']"
99383,Uniform convergence of series $\sum\limits_{n=2}^\infty\frac{\sin n x}{n\log n}$,Using Dirichlet series test I proved that the series $\displaystyle\sum\limits_{n=2}^\infty\frac{\sin n x}{n\log n}$ converges for all $x\in\mathbb{R}$. How to determine whether this series converges uniformly on $\mathbb{R}$?,"['convergence-divergence', 'sequences-and-series']"
99389,Drunkard's walk on the $n^{th}$ roots of unity.,"Fix an integer $n\geq 2$.  Suppose we start at the origin in the complex plane, and on each step we choose an $n^{th}$ root of unity at random, and go $1$ unit distance in that direction.  Let $X_N$ be distance from the origin after the $N^{th}$ step.  How well can we bound $E(X_N)$ from above? In my attempt to calculate this, I found the bound $\sqrt{N}$, but I have a feeling this could be wrong because the problem I am applying this to has instead $\sqrt{N\log N}$.  (This reasoning is based on the belief that the problem is likely optimal)  What I did was apply Cauchy Schwarz to get a sum with the norm squared, and then try to do some manipulations from there, relying on the fact that the sum of the vectors (not the distance) is zero by symmetry.","['stochastic-processes', 'markov-chains', 'probability', 'roots-of-unity']"
99392,Hardy's inequality again,"How can I prove that the constant in classical Hardy's inequality is optimal? $$\int_0^{\infty}\left(\frac{1}{x}\int_0^xf(s)ds\right)^p dx\leq \left(\frac{p}{p-1}\right)^p\int_0^{\infty}(f(x))^pdx,$$
where $f\geq0$ and $f\in L^p(0,\infty)$. This inequality fails for $p=1$ and $p=\infty$ ?","['inequality', 'analysis']"
99408,prove$\frac{  \sin a\vphantom{(}}{\sin b} +\frac{\cos a\vphantom{(}}{\cos b} = \frac{2\sin (a+b)}{\sin 2b}$,"I've got this far but don't understand where the $2$ on the numerator comes from:
$$\dfrac{\sin a \cos b + \cos a \sin b}{\sin b \cos b}\overset{?}{=}\dfrac{\sin(a+b)}{\sin 2b}$$",['trigonometry']
99411,Can someone explain this paragraph from Griffiths and Harris to me?,"(page 17) ...It follows that the projection (of tangent spaces, respectively real, complexified and holomorphic, at $p$ to a complex manifold $M$) $$T_{\mathbb{R},p}(M)\longrightarrow T_{\mathbb{C},p}(M)\longrightarrow T_{p}'(M) $$ is an $\mathbb{R}$-linear isomorphism. This last feature allows us to ""do geometry"" purely in the holomorphic tangent space. For example, let $z(t) = x(t) + iy(t)$, and the tangent to the arc may be taken either as $$x'(t)\frac{\partial}{\partial x}+ y'(t)\frac{\partial}{\partial y}$$ in $T_{\mathbb{R},p}(\mathbb{C})$ or $$z'(t)\frac{\partial}{\partial z}$$ in $T'(\mathbb{C})$ and these two correspond under the projection. What does the book mean by ""doing geometry""? I guess more basically, what properties precisely do $\mathbb{R}$-linear isomorphisms preserve that are fundamental to 'doing geometry'? I assume only angles?",['geometry']
99418,how to evaluate a definite integral (looks almost like nonintegral moments of a Gaussian),"I'd like to show the following equality (at least Mathematica claims it is an equality):
\begin{multline*}
\int_0^\infty x^p \exp(-(ax - b)^2)\, dx = \frac{1}{2} e^{-b^2} a^{-p-1} \left(\Gamma \left(\frac{p+1}{2}\right) \, _1F_1\left(\frac{p+1}{2};\frac{1}{2};b^2\right)+\
b p \Gamma \left(\frac{p}{2}\right) \, _1F_1\left(\frac{p}{2}+1;\frac{3}{2};b^2\right)\right)
\end{multline*}
Here $a,b>0$ and $p > 1$ (if it matters). This looks a lot like the expression given on Wikipedia for the uncentered moments of a Gaussian, except the integral is over $[0,\infty)$ rather than all of $\mathbb{R}.$ Any suggestions on how to proceed? I haven't been able to find this in any table of integrals.","['normal-distribution', 'special-functions', 'integration']"
99440,Switching order of supremum for doubly indexed sequence?,"Suppose you have a doubly indexed sequence of reals, $(\alpha_{ij})$. Why is
$$
\sup_i \;\sup_j\ \alpha_{ij}=\sup_j\;\sup_i\ \alpha_{ij}?
$$
I know one approach is to note $\alpha_{mn}\leq\sup_j\;\sup_i\alpha_{ij}$ for any $m$ and $n$. Why is this exactly? I don't really know what $\sup_j\sup_i\alpha_{ij}$ means. Does it mean first fix some $j$ and find the supremum of $\alpha_{ij}$ as $j$ remains fixed as $i$ runs over $\mathbb{N}$? And then after that, find the supremum of $\sup_i\alpha_{ij}$ as $j$ runs over $\mathbb{N}$? It's not clear how I would find $\sup_i\alpha_{ij}$ for fixed arbitrary $j$ first. Thanks.",['sequences-and-series']
99450,Question on order ideals,"On p. 80 of his General topology , John Kelley gives the following theorem: Let $X$ be a distributive lattice, and let $A \subseteq X$ be an ideal and $B\subseteq X$ a filter such that $A\cap B = \varnothing$.  Then there exist ideal $A'\supseteq A$ and filter $B'\supseteq B$ such that $A' \cap B' = \varnothing$ and $A' \cup B' = X$. [NB: Both in the theorem statement and below I've departed somewhat from the wording and terminology of Kelley's original.  In particular, Kelley uses the term dual ideal instead of filter .] In the proof of this theorem, Kelley considers the family $\cal{A}$ of all ideals in $X$ that contain $A$ and are disjoint from $B$, and proposes a maximal member of $\cal{A}$ (ordered by set inclusion) as a candidate for the ideal $A'$ claimed by the theorem.  (Kelley bases the existence of such maximal ideal $A'$ on the Hausdorff Maximal Principle, p. 32, or equivalently, the Axiom of Choice.) Then, in the next step of the proof, Kelley asserts that the smallest ideal that contains $A'$ and some arbitrary element $c \in X$ corresponds to the set $$
P = \{x:x\leq c \;\;\; \mathrm{or} \;\;\; x\leq c \vee y \;\; \mathrm{for} \; \mathrm{some} \; y \in A'\}
$$ True or not, this assertion confuses me because If $A' \neq \varnothing$, I don't see how $P$ could contain any element that is not already contained in the set $Q = \{x:x\leq c \vee y \;\; \mathrm{for} \; \mathrm{some} \; y \in A'\}$ (since $\forall u, v\in X\;[\;u \leq u \vee v\;]$, it follows from the transitivity of $\leq$ that $\forall y \in A'$, $ \{ x:x\leq c\} \subseteq \{ x : x \leq c \vee y \}$ ). The theorem is trivially true when $A = \varnothing$ and $B = X$ (both necessary for $A' = \varnothing$), which makes me doubt the idea that covering this trivial case is the sole reason for including the otherwise obfuscating ""$x \leq c$"" clause. Is the ""$x \leq c$"" clause less superfluous than it looks?","['general-topology', 'lattice-orders', 'order-theory']"
99463,Intersection of subgroups of orders 3 and 5 is the identity,"This is a question from the free Harvard online abstract algebra lectures .  I'm posting my solutions here to get some feedback on them.  For a fuller explanation, see this post. This problem is from assignment 5. Let $H, K$ be subgroups of a group $G$ of orders 3,5 respectively. Prove that $H\cap K=\{1\}$. The order of each element of $H$ must divide 3. Since the identity element is the only element with order 1, every other element in $H$ has order 3. Similar reasoning shows every nonidentity element of $K$ has order 5. Since $H$ and $K$ are both subgroups of $G$ they share the same identity element. Therefore, $H\cap K =\{1\}$. Again, I welcome any critique of my reasoning and/or my style as well as alternative solutions to the problem. Thanks.","['group-theory', 'abstract-algebra']"
99468,"Number of elements in a group of different orders, mod $n$, yields subgroup information?","The alternating group on five elements, $A_5$, has $1$ element order $1$, $15$ elements order $2$, $20$ elements order $3$, and $24$ elements order $5$. If I take these numbers mod some $n$, sometimes I get numbers of elements which correspond to a subgroup of $A_5$. To clarify, an example with $n=10$.
$\{1,15,20,24\}$ mod $10$ becomes $\{1,5,0,4\}$. $D_{10}$, the dihedral group of order $10$, has one element order $1$, $5$ elements order $2$, and $4$ elements of order $5$. $D_{10}$ is also a subgroup of $A_5$. This also happens for the other $n$ equal to the order of some subgroup of $A_5$. My question is, why does this happen? And what conditions are necessary for this to occur in other groups, since this doesn't occur for all groups.","['finite-groups', 'group-theory']"
99475,Calculating the percent of a person's life that a certain time takes up?,"A while ago I read an article on Cracked.com about why you wouldn't want to be immortal. Among many other reasons was that time would speed up for you after so many years and it would make every second seem fleeting. Relative to a year old, each day is a long time because it's a large portion of their life, but to someone who has lived 100 years, it's a very small fraction. How though, would you calculate what true percentage a certain amount of time is of someone's life? For example, what percent of a two-day-old's life is day one? Day two? I have no clue what to tag this, but I'm hoping someone who knows what this kind of mathematics is called can retag it.",['algebra-precalculus']
99484,Do you need real analysis to understand complex analysis?,"I'm debating whether I should take a course, in complex analysis (using Bak as a text).  I've already taken Munkres level topology and ""very light"" real analysis (proving the basic theorems about calculus) using the text Wade. The complex analysis course is supposedly difficult and will even cover the Prime Number Theorem in the end.  Do you think it's better to take Rudin level real analysis first?","['education', 'complex-analysis']"
99493,Derivation of the Riccati Differential Equation,"I am attempting to derive the Riccati Equation for linear-quadratic control. The original equation is: $-\partial V/\partial t = \min_{u(t)} \{x^TQx + u^TRu + \partial V^T/\partial x(Ax + Bu) \}$ $x \in \Re^n$, $u \in \Re^m$, $Q \in \Re^{n\times n}$, $R \in \Re^{m\times m}$, $A \in \Re^{n\times n}$, $B \in \Re^{n\times m}$. It can be shown that the minimal $u$ is $u^*=-\frac{1}{2}R^{-1}B^T\partial V/\partial x$; also, $V(x,t)$ can be shown to be quadratic in $x$, so it is of the form $V(x(t),t) = x(t)^{T}P(t)x(t)$, so $\partial V/\partial x = 2P(t)x(t)$. Thus $u^*(t) = -R^{-1}B^TP(t)x(t)$. We'd like to solve for $P$, which is symmetrical. Plugging into the original equation, I obtain $-\partial V/\partial t = -x^T\dot{P}x \equiv x^TQx + (-R^{-1}B^TPx)^TR(-R^{-1}B^TPx)+2x^TP(Ax+B[-R^{-1}B^TPx])$ Somehow this gets reduced to $-x^T\dot{P}x = x^T\{A^TP + PA + Q - PBR^{-1}B^TP\}x$ I cannot figure out the manipulation to get to the final equation. In particular, how is there both an $A^TP$ and $PA$ term in the final expression, when I distribute $2x^TP$ into $Ax+Bu^*$? Any insight would be helpful. Thanks.","['control-theory', 'linear-algebra', 'ordinary-differential-equations']"
99494,How can I show that this family of curves may be described by this differential equation?,"I have a homework problem in which I wish to show that the family of curves given by $$x^2 + y^2 = cx,$$ where $c$ is an abitrary constant may be described by the differential equation $$\frac{dy}{dx} = \frac{y^2-x^2}{2xy}.$$ I thought that I could use implicit differentiation to differentiate the original equation to get the second equation, but instead I get the equation $$\frac{c-2x}{2y}=\frac{dy}{dx}.$$ As you can see the derivative I get is not in the form of the equation that I am supposed to get. I do not see a way for my solution to even become similar to the proposed solution as one contains constants whereas the other does not. What is the correct procedure I should use to solve the problem?","['ordinary-differential-equations', 'calculus']"
99499,Fast $L^{1}$ Convergence implies almost uniform convergence,"$\sum_{n \in \mathbb{N}} \lVert f_{n}-f \rVert_{1} < \infty$ implies $f_{n}$ converges almost uniformly to $f$ , how to show this? EDIT: Egorov's theorem is available. I have been able to show pointwise a.e. convergence using Chebyshev and Borel-Cantelli, I am having trouble trying to pass to almost uniform convergence using the absolute summability condition...",['measure-theory']
99506,Binary expansion Unique,"I am trying to show that how the binary expansion of a given positive integer is unique. According to this link, http://www.math.fsu.edu/~pkirby/mad2104/SlideShow/s5_3.pdf , All I see is that I can recopy theorem 3-1's proof? Is this polished enough of an argument. Thanks","['elementary-number-theory', 'algebra-precalculus']"
99521,Convergence of the next series,"I'm trying to determine the convergence of this series:
$$\sum \limits_{n=1}^\infty\left(\frac12·\frac34·\frac56·...\frac{2n-3}{2n-2}·\frac{2n-1}{2n}\right)^a$$
I've tried using D'Alambert criteria for solving it. $$\lim_{n->\infty}\frac{(\frac12·\frac34·\frac56·...\frac{2n-3}{2n-2}·\frac{2n-1}{2n}\frac{2n}{2n+1})^a}{(\frac12·\frac34·\frac56·...\frac{2n-3}{2n-2}·\frac{2n-1}{2n})^a} =
 \lim_{n->\infty}\left(\frac{(\frac12·\frac34·\frac56·...\frac{2n-3}{2n-2}·\frac{2n-1}{2n}·\frac{2n}{2n+1})}{(\frac12·\frac34·\frac56·...\frac{2n-3}{2n-2}·\frac{2n-1}{2n})}\right)^a$$
Which becomes:
$$\lim_{n->\infty}\left(\frac{2n}{2n+1}\right)^a$$
But after that, the limit is 1, so its convergence is unknown.
Any idea?","['sequences-and-series', 'calculus', 'limits']"
99541,Solution of a differential equation that would be a generalized mean?,"I am trying to solve this differential equation on which I've been stuck for several days now. $$\frac{d X}{d t}=\frac{\int_{-\infty}^{\infty}\frac{\partial f}{\partial t}\frac{\partial f}{\partial x}dx}{\int_{-\infty}^{\infty}\left(\frac{\partial f}{\partial x}\right)^{2}dx} $$ where $f(x,t)$ is as smooth and integrable as you want it to be. Hey, I'm a physicist :) I have also the normalisation
$\int f(x,t)dx=\int f^{2}(x,t)dx=1 $ If for all $t$, $x_0(t)$ is a center of symmetry relative to x then $X(t)=x_0(t)$ is a solution of my equation. This lets me think that in the general, non-symmetric case, a solution of this equation might be related to a generalized mean of $f$. It does make sense when I do some simulations. Rewriting this in the Fourier plane using Parseval identities leads to interesting formulas but I can't interpret them either. I also tried to think of it as $L^2$ inner products without any result. That would be great if anyone had an idea on how to give some sense to this equation, particularily if a solution of it could be interpreted as a generalized mean of $f$. Or obviously to solve it if that proved to be possible. The original problem is actually in dimension $N$ with gradients instead of derivatives relative to $x$ but any idea in dimension $1$ would be extremely welcome. Thanks to whoever takes time considering this problem, Olivier","['partial-differential-equations', 'calculus', 'differential-geometry']"
99544,Why does every finite subgroup of $\mathrm{Aut}(F_n)$ acts on a graph of Euler characteristic $n-1$?,"My question is the following: In a paper I read that: Any finite subgroup of $\mathrm{Aut}(F_n)$ can be realised as agroup of baspoint-preserving isometries of a graph of Euler characteristic $1-n$.
Why is this fact true? Thanks for help.","['graph-theory', 'geometric-group-theory', 'group-theory', 'abstract-algebra']"
99558,Commutator of a particular group product,"Let $S \leq G$ and $N \lhd G$ two subgroups of $G$. Is the commutator $[SN,SN]$ equal to $[S,S]N$ ? The first is generated by commutators $[ax,by]$ (where $a,b\in S$ and $x,y \in N$), and each generator (after inserting $e$'s in the forms $cc^{-1}$ or $c^{-1}c$ in the product $(ax)^{-1}(by)^{-1}axby$ and using the fact that $N$ is normal) can be expressed as $[a,b]n$ for a suitable $n$. Is this correct?","['group-theory', 'abstract-algebra']"
99560,Generalization of variance to random vectors,"Let $X$ be a random variable. Then its variance (dispersion) is defined as $D(X)=E((X-E(X))^2)$. As I understand it, this is supposed to be a measure of how far off from the average we should expect to find the value of $X$. This would seem to suggest that the natural generalization of variance to the case where $X = (X_1,X_2,\ldots,X_n)$ is random vector, should be $D(X)=E((X-E(X))^T(X-E(X)))$. Here vectors are understood to be columns, as usual. This generalization would again, quite naturally, measure how far off from the average (expectation) we can expect to find the value of vector $X$. The usual generalization, however, is $D(X)=E((X-E(X))(X-E(X))^T)$, the variance-covariance matrix which, as I see it, measures the correlation of components. Why is this the preferred generalization? Is $E((X-E(X))^T(X-E(X)))$ also used and does it have a name? The variance-covariance matrix does seem to contain more information. Is this the main reason or is there something deeper going on here?","['statistics', 'terminology', 'probability-theory']"
99561,Construction of the global $\mathbf{Proj}$,"I have many questions about the very abstract concept of global $\mathbf{Proj}$. I am following Hartshorne's book Algebraic Geometry, where this concept is on II.7, page 160. Let $(X, \mathcal{O}_{X})$ be a noetherian scheme and $\mathcal{S} = \bigoplus_{d \geq 0} \mathcal{S_{d}}$ a quasi-coherent sheaf of $\mathcal{O}_{X}$-modules, which has a structure of a sheaf of graded $\mathcal{O}_{X}$-algebras. Assume that $\mathcal{S}_{0} = \mathcal{O}_{X}$, that $\mathcal{S}_{1}$ is a coherent $\mathcal{O}_{X}$-module and that $\mathcal{S}$ is locally generated by $\mathcal{S}_{1}$ as an $\mathcal{O}_{X}$-algebra. Why this implies $\mathcal{S}_{d}$ is coherent for all $d \geq 0$? For the construction of the global $\mathbf{Proj}$, for each affine subset $U = \mathrm{Spec} A$ of $X$, let $\mathcal{S}(U) = \Gamma(U, \mathcal{S}|_{U})$, which is a graded $A$-algebra. Then we have a natural morphism $\pi_{U}: \mathrm{Proj} \mathcal{S}(U) \rightarrow U$. Let $f \in A$ and $U_{f} = \mathrm{Spec} A_{f}$. Hartshorne says that since $\mathcal{S}$ is quasi-coherent we have $\mathrm{Proj} \mathcal{S}(U_{f}) \cong \pi_{U}^{-1}(U_{f})$. Why? I can not see that. In my opinion, the global $\mathbf{Proj}$ is a very abstract concept that I can not get any concrete example of blowing up. Do you know a book where I can find concrete examples? Thank you!",['algebraic-geometry']
99562,Complexification of Tangent Bundle,"I am currently reading a book where the author says that the tangent and cotangent bundles $TM$ and $T^*M$ of a manifold $M$ are complexified. I am not familiar with Complex Manifolds so looked it up on Wikipedia. Now I just would like to check whether my impression is correct that if $(x^1, \dots, x^n)$ is a local coordinate system and so $\frac{\partial}{\partial x^i} , i = 1, \dots n$ forms a basis for the corresponing local region in the tangent bundle then a vector $v$ in the complexified tangent space $T^C_pM$ at $p \in M$ can be written as
\begin{align}
v \,\otimes_\mathbb{R} \mathbb{C}  &= (\sum_j v^j \frac{\partial}{\partial x^j} \! |_p) \otimes _\mathbb{R} \mathbb{C} = (\sum_j v^j \frac{\partial}{\partial x^j} \! |_p) \otimes _\mathbb{R} (a + ib) \\
 &= \sum_j (av^j \frac{\partial}{\partial x^j} \! |_p \otimes 1 + bv^j \frac{\partial}{\partial x^j} \! |_p \otimes  i) \\
 &= (\, \sum_j av^j \frac{\partial}{\partial x^j} \! |_p ) \otimes 1 + (\, \sum_j bv^j \frac{\partial}{\partial x^j} \! |_p) \otimes  i \\
 &= av \otimes 1 + bv \otimes  i
\end{align} Is this description correct ? I am very new to tensor products so I hope I could use this as a way to check whether I actually understandt how extension of scalars work, thanks for any feedback!","['tensor-products', 'differential-geometry']"
99563,Necessary and sufficient conditions for $||f||_p = ||f||_q$ with $p \neq q$,"Let $0 < p < q \leq \infty$ and suppose $ E\subset \mathbb{R}^N$ with $m(E)=1$ (where $m$ is the Lebesgue measure). I am asked to find necessary and sufficient conditions for: 
$$ ( \int_E{|f|}^pdx)^{1/p} = (\int_E{|f|}^qdx)^{1/q}$$ 
I know how to prove that that LHS $\leq$ RHS, this is done with Jensen's inequality in its measure-theoretic form, considering the function $\phi(t)=t^{q/p}$, which is convex, because $p<q$. This is how it works: $$(\int_E{|f|^pdx})^{q/p}=\phi(\int_E{|f|^p}dx) \leq \int_E{\phi(|f|^p)dx}= \int_E{|f|^qdx }$$ I was guessing that the necessary and sufficient condition required in the excercize is that $f(x) = 0$ almost everywhere (EDIT as observed in the comments, the condition is also satisfied if $f$ is such that $|f|$ is constant a.e.), but I'm stuck trying to prove it. I tried manipulating the exponents, but nothing seems to work; maybe some result on the inverse implication in Jensen's inequality could help, but I can't find any. I hope someone can point me in the right direction, thanks in advance!","['measure-theory', 'real-analysis']"
99564,Symmetric-decreasing rearrangement of a function,"I'm studying section 3.3 of Analysis by Lieb and Loss, about symmetric-decreasing rearrangement of functions. Let $A\subset \mathbb{R}^n$ a Borel set of finite Lebesgue measure. They define
  $A^*$ to be the ball centered at 0 with the same measure that
  $A$. The symmetric-decreasing rearrangement of a measurable function $f:\mathbb{R}^n \to \mathbb{R}$ is then defined by $$f^*(x):=\int_0^{\infty} \chi_{\{|f|>t\}^*}(x)dt,$$ by comparison to the ""layercake"" representation of $f$, namely
  $$f(x)=\int_0^{\infty} \chi_{\{f>t\}}(x)dt.$$ They say that it is then an obvious property that $$\{x: f^*(x)>t\}=\{x: |f(x)|>t\}^* .$$ But I can't see why/how...","['symmetry', 'measure-theory', 'decreasing-rearrangements']"
99565,Simplest way to calculate the intersect area of two rectangles,"I have a problem where I have TWO NON-rotated rectangles (given as two point tuples {x1 x2 y1 y2}) and I like to calculate their intersect area. I have seen  more general answers to this question, e.g. more rectangles or even rotated ones, and I was wondering whether there is a much simpler solution as I only have two non-rotated rectangles. What I imagine should be achievable is an algorithm that only uses addition, subtraction and multiplication, possibly abs() as well. What certainly should not be used are min/max, equal, greater/smaller and so on, which would make the question obsolete. Thank you! EDIT 2: okay, it's become too easy using min/max or abs(). Can somebody show or disprove the case only using add/sub/mul? EDIT: let's relax it a little bit, only conditional expressions (e.g. if, case) are prohibited! PS: I have been thinking about it for a half hour, without success, maybe I am now too old for this :)",['geometry']
99587,Calculating $\prod (\omega^j - \omega^k)$ where $\omega^n=1$.,"Let $1, \omega, \dots, \omega^{n-1}$ be the roots of the equation $z^n-1=0$, so that the roots form a regular $n$-gon in the complex plane. I would like to calculate
$$ \prod_{j \ne k} (\omega^j - \omega^k)$$ where the product runs over all $j \ne k$ with $0 \le j,k < n$. My attempt so far Noting that if $k-j = d$ then $\omega^j - \omega^k = \omega^j(1-\omega^d)$, I can re-write the product as
$$ \prod_{d=1}^{\lfloor n/2 \rfloor} \omega^{n(n-1)/2}(1-\omega^d)^n$$ I thought this would be useful but it hasn't led me anywhere. Alternatively I could exploit the symmetry $\overline{1-\omega^d} = 1-\omega^{n-d}$ somehow, so that the terms in the product are of the form $|1-\omega^d|^2$. I tried this and ended up with a product which looked like
$$\prod_{j=0}^{n-1} |1 - \omega^j|^n $$ (with awkward multiplicative powers of $-1$ left out). This appears to be useful, but calculating it explicitly is proving harder than I'd have thought. The answer I'm expecting to find is something like $n^n$. My motivation for this comes from Galois theory. I'm trying to calculate the discriminant of the polynomial $X^n+pX+q$. I know that it must be of the form $ap^n+bq^{n-1}$ for some $a,b \in \mathbb{Z}$, and putting $p=0,q=-1$, the polynomial becomes $X^n-1$. This has roots $1, \omega, \dots, \omega^{n-1}$, so that $(-1)^{n-1}b$ is (a multiple of) the product you see above. An expression for $a$ can be found similarly by setting $p=-1,q=0$.","['galois-theory', 'complex-analysis', 'polynomials']"
99594,How to work with Connections,"I am currently reading a book which deals with complex manifolds. Since I am fairly new to the topic I don't know exactly the meaning of the followinig: Suppose we have a holomorphic vector bundle $V$ over the manifold $M$ with frames $s_\alpha$ over each trivialization $U_\alpha \subset M$ We can construct a Hermitian metric $h$ on $V$, and the author says this is given locally as $h_\alpha = (s_\alpha,s_\alpha) $. Then a connection 1 - form is defined locally by \begin{equation}
\omega_\alpha = \partial h_\alpha h_\alpha^{-1}
\end{equation} 
where 
\begin{equation}
d = \partial + \bar{\partial}
\end{equation}
and 
\begin{equation}
\partial(f) = \sum_j \frac{\partial f}{\partial z^j}dz^j
\end{equation}
(more generally $\partial \colon C^\infty(\Lambda^{p,q}) \to C^\infty(\Lambda^{p+1,q}) $. 
It is then shown in the book that these 1-forms patch together to form a connection $\triangledown_h$. Now comes the bit where I am struggeling with, to the extend that I can't read on without a bad feeling: From the definition, one should see that
\begin{align}
(\triangledown_h s_\alpha, s_\alpha) + (s_\alpha, \triangledown_h s_\alpha) &= \omega_\alpha h_\alpha + h_\alpha \omega^*_\alpha \\
 &=
\partial h _\alpha + \bar{\partial}h _\alpha = dh _\alpha
\end{align} I am afraind I don't know enough about connections yet, in particular I don't really understand how to get from the first expression to the second. If anyone could fill in a little more details into the lines above that would be very helpful!",['differential-geometry']
99602,"Limit of $\frac1{c^n}\iint_{[0,c]^n}\frac{f(x_1) +f(x_2) +\cdots+f(x_n)}{g(x_1) +g(x_2) +\cdots+g(x_n)}\,dx_1dx_2\cdots dx_n$ when $n\to\infty$","A. How do I prove the following sequence converges as $n$ goes to $\infty$ for any $c$, and how do I find the limit? $$
\begin{align} a_1 &=\frac{1}{c} \int _0^c\frac{x_1 }{1+x_1}\;dx_1 \\  \\
a_2 & =\frac{1}{c^2 } \int _0^c\int _0^c\frac{x_1 +x_2 }{2+x_1 +x_2 }\;dx_2\;dx_1  \\  \\
a_3 & =\frac{1}{c^3 } \int _0^c\int _0^c\int _0^c\frac{x_1 +x_2 +x_3 }{3+x_1 +x_2 +x_3 } \;dx_3\;dx_2\;dx_1 \end{align} 
$$ and so on for $a_n$ $\dots$ B. Similarly, with this, where $f$ and $g$ are not polynomials [I verified the convergence numerically]: $$
\begin{align} a_1 &=\frac{1}{c} \int _0^c\frac{f(x_1) }{g(x_1)}\;dx_1 \\  \\
a_2 & =\frac{1}{c^2 } \int _0^c\int _0^c\frac{f(x_1) +f(x_2) }{g(x_1) +g(x_2) }\;dx_2\;dx_1  \\  \\
a_3 & =\frac{1}{c^3 } \int _0^c\int _0^c\int _0^c\frac{f(x_1) +f(x_2) +f(x_3) }{g(x_1) +g(x_2) +g(x_3) } \;dx_3\;dx_2\;dx_1 \end{align} 
$$ and so on for $a_n$ $\dots$ (perhaps I need to include the very long definition of $f$ and $g$...?)","['law-of-large-numbers', 'integration']"
99605,Why study schemes?,"Why study schemes instead of only affine/projective varieties, given by zeros of polynomials in the affine/projective space? I mean, what is gained by introducing the concept of schemes? Thank you!",['algebraic-geometry']
99627,"if $m^2 = a^3 - b^3$, then $m$ is the sum of two squares.","(Please read ""Edit""s and see this .) How could I prove that : $$\text{If} \space m^2=a^3-b^3\text{ where}\space m,a,b\in\mathbb{N} \rightarrow \exists c,d \in\mathbb{N}\space \text{ such that}\space m=c^2+d^2 $$
thanks for helping Edit: I told the person who gave me this question it's wrong, and he corrected it like this:
$$\text{If} \space m^2=(a+1)^3-a^3\text{ where}\space m,a\in\mathbb{N} \rightarrow \exists c,d \in\mathbb{N}\space \text{ such that}\space m=c^2+d^2 $$
It's such an easy question and I already know the answer. Edit2: I though I know this question answer but after thinking I can't solve this, could any one help me to figure out how to solve this?(I hope it wasn't wrong like previous question, but if you think it's wrong please let me know,I need to solve this question for exam I wanna take from my students.) Edit 3: the second question wasn't wrong and has been answered at this link.",['number-theory']
99637,$K\subseteq \mathbb{R}^n$ is a compact space iff every continuous function in $K$ is bounded.,"I need to prove that $K\subseteq \mathbb{R}^n$ is a compact space iff every continuous function  in $K$ is bounded. One direction is obvious because of Weierstrass theorem. How can i prove the other direction?
I tried to assume the opposite but it didn't work for me. Thanks a lot.","['general-topology', 'compactness', 'real-analysis']"
99662,Derivative over variable vs. partial derivative over variable,"I was watching one of the Khan Academy videos on differential equations ("" Exact Equations Intuition 1 (proofy) "") and there's something that confused me. In the video, they use both the derivative of a function $\psi(x, y(x))$ with respect to $x$, $$\frac{d}{dx}\psi(x, y(x)),$$ as well as the partial derivative of the same function with respect to the same variable, $$\frac{\partial \psi}{\partial x}$$ (I think) I understand what a partial derivative of a function is (you consider its other arguments constants and you essentially turn it into a derivative of a single variable function), but I don't understand what a non-partial derivative with respect to one variable means. How is it different from a partial derivative?","['calculus', 'derivatives']"
99673,Proof of inequality (mollifier),"Let $J$ be a mollifier, e.g. a function in $J \in C^\infty(\mathbb R^n)$ with the properties $J\geq 0$ and $\int J(x) \mathrm dx=1$ and $J(x)=0$ for all $x$ with $|x|>1.$ Now define $J_\varepsilon (x):=\varepsilon ^{-n}J(\varepsilon ^{-1}x)$ and $$(J_\varepsilon \star u)(x)=\int_{\mathbb R^n}J_\varepsilon (x-y)u(y) \mathrm dy$$ (the symbol $\star$ denotes convolution). How does one prove, that for every function $u \in C^\infty_0(\mathbb R^n)$ (with compact support) the following inequality holds: $$\left \| u-J_\varepsilon  \star u \right \|_1 \leq  c \cdot \varepsilon \left \| u \right \|_{1,1}\quad ?$$ Here, $||u||_{1,1}=||u||_{L^1}+\sum_{j=1}^n||\partial_j u||_{L^1}$.",['functional-analysis']
99680,Domains of continuity,"I was playing around with the definition of uniform continuity, and realized that a nice application of it is the possibility to extend functions. For example, suppose we are given a uniformly continuous function $f:\mathbb{Q}\to\mathbb{R}$. By uniform continuity, it is easy to see that such a function extends (uniquely of course) to a continuous function $f:\mathbb{R}\to\mathbb{R}$. If we drop the uniform continuity assumption and demand only that $f$ to be continuous, this is no longer true, as easily demonstrated by $f(x) = \frac{1}{x-\pi}$ which is continuous on $\mathbb{Q}$ but cannot be extended to a continuous function on all of $\mathbb{R}$. Which brings me to my question: Is there a nice description of the sets $A\subseteq \mathbb{R}$ which have the following property: there is a function $f:A\to \mathbb{R}$ which is continuous, but for any $x \notin A$, $f$ cannot be extended to a continuous function on $A\cup \{x\}$ ? Certainly open sets have this property, because if $A$ is open and $B$ is its complement, then we may define $f:A\to \mathbb{R}$ by $f(x) = \frac{1}{dist(x,B)}$. Conversely, are all such sets open? Edit: per Robert Israel nice examples, it appear that not all such sets are open. I still wonder if there is a nice description of this sets?",['real-analysis']
99696,What is to median as first central moment is to mean?,"The question sounds like a riddle, but it isn't intended to be one. I've been thinking about the Cauchy Distribution which, famously doesn't have any central moments defined.  A very informal justification for this  is that as the angle approaches $\pm90^\circ$ from the origin, the value of the function tends quickly to infinity... hence, if we were to attempt to calculate the mean, its value would vary to $\pm\infty$ very, easily.  Essentially, rather than summarise the data-set as a whole, one would identify only whether or not your samples were biased very slightly to the positive or negative values. An obvious approach to establish an estimate of expected value would be to calculate the median - which would avoid the outlying data points overwhelming the summary.  This single scalar summary value - analogous to mean - then suggests a more reasonable estimate of 'expected' value in some circumstances.  Is it common to extend such analysis with measures analogous to variance, skew and kurtosis - to better describe the distribution?  If so, how are these concepts commonly defined? UPDATE: Many thanks for the pointer to MAD... that's definitely relevant.  While I wasn't clear about this previously, central moments appealed because they generated a progression of values each further refining the description of a normal distribution... and I really hoped to do something similar for systems where the empirical mean and standard deviation can't be trusted to give a meaningful summary.","['statistics', 'probability-distributions', 'probability']"
99719,What's the meaning of the transpose? [duplicate],"This question already has answers here : What is the geometric interpretation of the transpose? (5 answers) Closed 9 years ago . I don't understand the motivation of the transpose (or better yet, I haven't even seen one). It feels like just something pulled out of a hat. Thinking about it makes it seem  like a product of being able to write a matrix using either columns or rows 'first'. E.g., when we 'reflect down the diagonal' we are really keeping all the information of our old matrix, just changing rows to columns. This is much like how $f \text{  from} \{1,2,...,m-1,m\} \times \{1,2,...,n\} \text{ to some field } \mathbf{F}$ is an $m \times n$ matrix, ● if we switch the order of the product, so that we would define: $g \text{ is a map from } \{1,2,...,n\} \times \{1,2,...,m - 1, m\} \text{ to } \mathbf{F}$ ● but allow $f(i,j) = g(j,i)$. Then we somehow get a 'natural' map from the space of $m \times n$ matrices to $n \times m$ matrices. Is that what transpose is - a 'natural' map for those spaces? What do I even mean by natural here (serious question, I'm not being mysterious)? If I had to guess, it is a linear bijective map? Is that close enough? Moving away from this, does the transpose have any useful application in Euclidean geometry (other than orthogonal matrices being defined in terms of transposes?).","['matrices', 'linear-algebra']"
99737,Hopkins-Levitzki: an uncanny asymmetry?,"Not every left Noetherian ring is left Artinian . Take $\mathbb{Z}$ as a quick example. But: Hopkins-Levitzki theorem : a left Artinian ring is left Noetherian. I find this quite amazing. I find this asymmetry shocking. It just seems plain unreasonable that there are rings where every ascending chain of ideals stabilizes but not every descending chain stabilizes, and at the same time every ring with stabilizing descending chains has stabilizing ascending chains. I know asymmetries abound in ring/module theory, but this one strikes me as more elementary and uncanny. My question is: Why does this happen? Of course, this question is at an informal level; I'm not asking for a proof of the theorem. I just want to understand why one chain condition implies the other, but not the other way around. At first glance, it just seems so symmetrical, that I would have expected the conditions to be equivalent, or to have neither condition implying the other. My very naive first observation is that for noetherian rings, we have the characterization ""every ideal is finitely generated"", but for artinian rings there is not (that I know of) a simple analog, which is perhaps the first spark of an asymmetry...","['ring-theory', 'abstract-algebra']"
99745,Sum of infinite series and polynomial equation,"Let 
 $$a=\sum_{n=1}^\infty(1 \mod \phi^{-n})2^{n/3},$$
where $\phi = \frac{1 + \sqrt{5}}{2}$ is the golden ratio and $1 \mod x=1-x\lfloor x^{-1}\rfloor$. How can I prove that $a$ satisfies the equation $$2255 a^6 - 2340 a^5 - 3174 a^4 - 672 a^3 + 180 a^2 + 36 a - 36=0?$$",['sequences-and-series']
99753,Why is the Riemann integral only defined on compact sets?,"Every text I look at says a function must be bounded and be defined on a compact set before one can even think about the Riemann integral. Boundedness makes sense, otherwise the Darboux sums could be undefined. However, I don't see where it becomes important that the integral be taken over a compact set.","['integration', 'real-analysis']"
99756,Repeating digits in $\pi$,"As $\pi$ has infinite digits in its decimal expansion, one could argue that its digits will repeat after a finite number of digits. If so, it is a rational number. What's wrong with this argument?","['pi', 'infinity', 'number-theory']"
99788,"Prove\Refute: for every norm in $\mathbb{R}^n: \left \| x \right \|\leq \max (\left \| x+y \right \|,\left \| x-y \right \|)$","I need to prove or refute that for every norm in $\mathbb{R}^n$:$ \left \| x \right \|\leq \max (\left \| x+y \right \|,\left \| x-y \right \|)$. It's been quite a while since I studied Linear algebra 1. I tried to look for vectors $x$ and $y$ such that they will refute the claim, but I didn't find any, so I tried to prove the question by showing the explicit sum of each norm, and go on form that, but it didn't do either. (sorry if the question is too easy or silly) Any help? Thank you very much!",['linear-algebra']
99797,Understanding the Cosine Rule,"What is actually the Cosine rule? Can anyone explain it to me in way that I can understand it, explain in a simple way? that provide simple examples? (Only the Cosine rule) Thanks in advance. I tried googling online but most of it is full of complexity. Our school library is renovated.",['trigonometry']
