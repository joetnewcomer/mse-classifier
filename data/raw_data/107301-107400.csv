question_id,title,body,tags
1531967,Basic properties of free product amalgamation of groups,"I have some basic questions about properties of free product amalgamation of groups. Both can be phrased inside some fixed group $G$, which I am thinking of as having some very large infinite cardinality (but I don't think this is important). Given subgroups $A,B\leq G$, I will use $\langle AB\rangle$ to denote the subgroup of $G$ generated by $A\cup B$ (equivalently, by the set product $AB$). Given subgroups $A,B,C\leq G$, with $C\leq A\cap B$, I will use $A\ast_C B$ to denote the usual free product amalgamation of $A$ and $B$ over $C$ (as in this link ). Edit (re: Derek Holt's very good suggestion)
Given subgroups $A,B,C\leq G$, I will write $\langle ABC\rangle\cong\langle AC\rangle\ast_C\langle BC\rangle$ to mean that the identity map on $A\cup B\cup C$ generates an isomorphism between the two groups. Question #1 Fix subgroups $D\leq C\leq B\leq G$ and $A\leq G$. Consider the following statements. 1) $\langle AB\rangle \cong \langle AC\rangle \ast_C B$ and $\langle AC\rangle\cong\langle AD\rangle\ast_D C$ 2) $\langle AB\rangle \cong \langle AD\rangle\ast_D B$ What is the relationship between (1) and (2)? Are they equivalent? Question #2 Fix subgroups $A,A',B,C\leq G$, with $C\leq A\cap A'\cap B$. Assume: $\langle AB\rangle\cong A\ast_C B$, $\langle A'B\rangle\cong A'\ast_C B$, and there is an isomorphism $\phi:A\longrightarrow A'$ such that $\phi(c)=c$ for all $c\in C$. Define $\psi:\langle AB\rangle\longrightarrow\langle A'B\rangle$ such that $\psi$ extends $\phi$ and $\psi(b)=b$ for all $b\in B$. Is $\psi$ a well-defined isomorphism? I imagine that these problems are not difficult for someone used to this kind of thing; so helpful answers would also include references to sufficiently similar exercises in standard texts.","['abstract-algebra', 'group-theory', 'free-product', 'free-groups']"
1531977,Mistake in integration by parts,"The partial integration rule says: $\int f'g=fg-\int fg'$ . If I use the rule for $f'(x)=2x,g(x)=\frac{1}{x^2}$, I get that: \begin{align}\int\frac{1}{x^2}2x\,dx& =\frac{1}{x^2}x^2-\int\frac{-2}{x^3}x^2\,dx,\\
\int\frac{2}{x}\,dx& =1+\int\frac{2}{x}\,dx
\end{align}
and from this equation I get that $0=1$ Where did I make a mistake?","['calculus', 'integration']"
1531994,Lipschitz continuous one-to-one mapping from subset $K\subset\mathbb{R}^n$ of positive measure to $\mathbb{R}^{n-1}$,"Let $f:\mathbb{R}^n\to \mathbb{R}^{n-1}$ and $K\subseteq \mathbb{R}^n$ be a set of positive Lebesgue measure. What kind of regularity do we have to impose on $f$ (e.g., $C^1$, Lipschitz) to conclude that $f$ cannot be one-to-one on $K$? Continuity is (in general) not enough, as demonstrated here . On the other hand, a nonvanishing Jacobian on a subset of $K$ of positive measure allows us to construct a contradiction by the coarea formula. But what if we cannot assume anything about the Jacobian? Is, e.g., Lipschitz continuous sufficient to construct a contradiction? Or do there exist Lipschitz continuous examples of one-to-one mappings? Edit: This seems to have a connection to singularity theory. Unfortunately, things like Sard's Theorem also don't help as it only tells me something about singular values but I would need some information about the possible size of singular points of a one-to-one mapping.","['measure-theory', 'real-analysis', 'singularity-theory', 'geometric-measure-theory', 'dimension-theory-analysis']"
1532014,How to apply the definition of a derivative with a piecewise function?,"Given the function: $$f(x) = \begin{cases} x^2+1 & \text{if $x\ge0$} \\ x^2-1 & \text{if $x < 0$} \end{cases}$$ Question: are we justified to say that the derivative at $f(0)$ exists? If so, what is $f'(0)$? And how do we justify it? Of course I do realize that the function isn't continuous at $x=0$ but still since the slope near $x=0$ seems equal near $0+$ and $0-$ I wondered why we can't say that $f'(0)=0$ What I tried is this: $f_+'(0)=\lim\limits_{h \to 0+}\frac{(x+h)^2+1-(x^2+1)}{h}=\lim\limits_{h \to 0+}\frac{(0+h)^2+1-(0^2+1)}{h}=\lim\limits_{h \to 0+}\frac{h^2}{h}=h=0$
$f_-'(0)=\lim\limits_{h \to 0-}\frac{(x+h)^2+1-(x^2+1)}{h}=\lim\limits_{h \to 0-}\frac{(0+h)^2+1-(0^2+1)}{h}=\lim\limits_{h \to 0-}\frac{h^2}{h}=h=0$ My conclusion is that since both the right and left limit using the definition of the derivative exist and generate the same answer the limit exists such that $f'(0)=0$. Apparently this is not true, so what is my mistake?",['derivatives']
1532028,residue theorem with logarithmic function,"I have problem integrating function with logarithm.
Problems seems always to be branch cut of $\log$, but here it is different I think. I have task to integrate
$$\oint_{|z| = 1} \! dz \log\left(\frac{z - a}{z - b}\right)$$
given $|a| < 1$ and $|b| < 1$ First I think to check branch points of logarithm.
I write $$\log\left(\frac{z - a}{z - b}\right) = \log(z - a) - \log(z - b)$$
Going around $a$ in small circle I pick up term $2\pi i$, going around $b$ I pick up term $-2\pi i$, so going around both I pick up nothing.
So I make branch cut $a$ to $b$ and contour does not intersect. But now I get stuck! I try to find residue of integral at $a$ and $b$ but I cannot get series of at $a,b$, because logarithm always remains inside.
How I can evaluate such integrals?","['branch-cuts', 'complex-analysis', 'residue-calculus', 'logarithms']"
1532055,Is a linear factor more likely than a quadratic factor?,"I choose a reducible (over $\mathbb Z$) monic polynomial of degree four with integer coefficients,
at random. Is it more likely to have  a linear factor or a quadratic factor ? Formal version of the question : let $N>0$, and
$$B_N=\lbrace (a,b,c,d) \in [|-N,N|]^4 | X^4+aX^3+bX^2+cX+d \text{ is reducible},\rbrace$$ (so that $|B_N|$ has at most $(2N+1)^4$ elements ; in fact, it is known to have
$o(N^4)$ elements, and even $O(N^3)$ if I'm not mistaken). Let $$
\begin{array}{lcl}
B_{N,1} &=&\lbrace (a,b,c,d) \in B_N | X^4+aX^3+bX^2+cX+d \text{ has a linear factor}\rbrace, \\
B_{N,2}&=&\lbrace (a,b,c,d) \in B_N | X^4+aX^3+bX^2+cX+d \text{ has a quadratic factor}\rbrace,
\end{array}$$ (note that in $B_{N,2}$ the quadratic factor may itself be reducible ; also the intersection $B_{N,1}\cap B_{N,2}$ is nonempty) and $$
p_n=\frac{|B_{N,1}|}{|B_N|}, q_n=\frac{|B_{N,2}|}{|B_N|} 
$$ Is anything known about the asymptotic behaviour of $p_n,q_n$ and $\frac{p_n}{q_n}$ ?","['polynomials', 'probability']"
1532077,Is rank of vector bundle encoded in its Hilbert polynomial,"Let $\mathcal F$ be a vector bundle over a projective variety $(X, \mathcal O_X(1))$, and $P_\mathcal F(m)=\chi(X, \mathcal F(m))$ be its Hilbert polynomial. Then can I define from $P_\mathcal F$ the value of the rank $rk(\mathcal F)$?",['algebraic-geometry']
1532106,"Let $f:[0,\infty)\to \Bbb R$ be defined by $f(x)=\int_{0}^x \sin^2(t^2)\mathrm dt$. Show that $f$ is uniformly continuous","Let $f:[0,\infty)\to \Bbb R$ be defined by $$f(x)=\int_{0}^x \sin^2(t^2)\mathrm dt$$ Then Show that the function is uniformly continuous on $[0,1)$ and $(0,\infty)$ Attempt: Differentiating with respect to $x$ we get, $$f'(x)=\sin^2(x^2)$$ then $$|f'(x)|=|\sin^2(x^2)|\le1,\forall x\in(0,\infty)$$ this means that derivative of $f$ is bounded, hence f is uniformly continuous on given intervals. 
am I right? Also provide other methods to solve this. Thank you.","['continuity', 'uniform-continuity', 'real-analysis', 'integration']"
1532130,How to estimate $ \left(1 + \sqrt{2} + \sqrt{3} + \dots + \sqrt{n} \right) - \frac{2}{3} n \sqrt{n}$?,"How do I estimate the error for the sum of reciprocals of square roots.  From calculus we know that: $$ \int_0^n \sqrt{x} \, dx  = \frac{2}{3} x\sqrt{x} \;\;\Bigg|_{x=0}^{x=n} = \frac{2}{3}n\sqrt{n}$$ I forget the name - midpoint rule , trapezoid rule ?? - basically we want to approximate the integral as a Riemann sum.  How do we estimate the error? $$ \left(1 + \sqrt{2} + \sqrt{3} + \dots +  \sqrt{n} \right)  - \frac{2}{3} n \sqrt{n}$$ To give you a sense of how much we are losing on this approximation, let's   draw two pictures. We are losing all the gray stuff in our approximation, which is quite a lot!  I don't really care about the integral, what's important is the difference between all the stuff we are adding and square root of $n$. The yellow triangle has base $1$ and height $\sqrt{14} - \sqrt{13}$ so the area is: $$ A = \frac{1}{2} \times b \times h = \frac{1}{2} \times 1 \times (\sqrt{\color{#E0E070}{14}} - \sqrt{\color{#E0E070}{13}}) = \frac{1}{2}(\sqrt{n+1} - \sqrt{n}) \approx \frac{1}{4 \sqrt{n}}$$ This suggests the total of all errors is about $\propto \sqrt{\color{#D22}{n}}$ which is not a small amount.  Can anyone get the constant of proportionality? The Euler-Maclaurin machine does crank out such error estimates, but the square root function is not so strange. Can we derive such an estimate in this specific case using basic standard inequalities?","['calculus', 'real-analysis', 'numerical-methods']"
1532136,"Is there a group with countably many subgroups, but is not countable in ZF?","Inspired by this question , although I don't think it was the OP's intention, hence this separate question: Is there a group $G$ with countably many subgroups, but is a not a countable group itself in $\mathrm{ZF}$ ? In $\mathrm{ZFC}$ we can look at the cyclic subgroups of $G$ and ""estimate"" the number of elements in the group, to conclude that $G$ is countable. But this ends up not going through in $\mathrm{ZF}$ since a countable union of finite sets does not have to be countable, in particular it is known that a countable union of two-element sets does not have to be countable. So a possible way to construct such a uncountable group (although I am not saying this is a good way to go, I have no idea) is start with a collection $\{ A_i \mid i \in \mathbb{N} \}$ where $A_i$ are pairs, whose union is not a countable set and note that every torsion-free cyclic group has two natural generators, so conceivably there could be a torsion-free group with $A_i$ the natural generating set for a cyclic groups ("" $1,-1$ "" but we could not actually define such a function all $A_i$ without the axiom of choice). Then the constructions would have to make sure there are only countable many subgroups (this seems difficult and would take a lot of care) An interesting paper ""On the number of Russell's socks or $2+2+2+\cdots = ?$ "" 
by Horst Herrlich, Eleftherios Tachtsis discusses some of the ideas around countable unions of pairs.","['group-theory', 'set-theory', 'axiom-of-choice']"
1532154,Hecke characters and Conductors,"Motivation : Let $\ell$ be an odd prime. There is a conductor-preserving correspondence between primitive Dirichlet characters of order $\ell$ and cyclic, degree $\ell$ number fields $K/\mathbb{Q}$. The proof of this correspondence can be found in Chapter 3 of Washington's ``Introduction to Cyclotomic Fields"". Question : Let $k$ be a CM field. Is there a conductor-preserving correspondence between primitive Hecke characters of order $\ell$ and cyclic, degree $\ell$ extensions of $k$? I have tried to construct a proof of this correspondence for Hecke characters using global class field theory and the theory of complex multiplication, however, I am not totally confident with my answer. Any answers/references on the topic would be greatly appreciated.","['hecke-characters', 'number-theory']"
1532166,Visualizing a generator of $H^2(S^1 \times S^1)$,"Does anyone know of a good visualization for the generator of $H^2(S^1 \times S^1)$? (In any coefficients and any cohomology theory). I gather it might help to think of it as the product of the two angle forms, and I'm trying to make that more transparent for myself. My apologies if someone has asked this here before; I searched and found nothing.","['homology-cohomology', 'differential-geometry', 'algebraic-topology']"
1532168,"Proving the Commutative, Associative and Distributive laws of Sets","I have looked all over the web and can't find any elegant proofs for the commutative, associative and distributive laws of Sets: Commutative Law
$$A\cup B = B\cup A, \ A\cap B = B\cap A$$
Associative Law
$$A\cup (B\cup C) = (A\cup B)\cup C, \ A\cap (B\cap C) = (A\cap B)\cap C$$
Distributive Law
$$A\cap (B\cup C) = (A\cap B)\cup (A\cap C), A\cup (B\cap C) = (A\cup B)\cap (A\cup C) $$ How would these be proved in an elegant way? The question comes from Tom M Apostol Calculus Volume I book. He gives an example proof of the commutative law as follows. Let $X=A\cup B$, $Y=B\cup A$. To prove that $X=Y$ we prove that $X\subseteq Y$ and $Y\subseteq X$. Suppose that $x\in X$. Then $x$ is in at least one of $A$ or $B$. Hence, $x$ is in at least one of $B$ or $A$; so $x\in Y$. Thus, every element of $X$ is also in $Y$, so $X\subseteq Y$. Similary, we find that $Y\subseteq X$, so $X=Y$ He doesn't presuppose knowledge of truth tables. Can this proof be written in a more mathematical and concise way? How would I go about writing concise proofs for the other laws? I understand the logic, but I am new to mathematical language.",['elementary-set-theory']
1532206,Limit of random variables indipendent from a fixed sigma algebra.,"Let $(X_n)_{ n \in \mathbb{N}}$ be a sequence of random variables that converges (in probability) to a random variable $X$. Let's suppose that each $X_n$ is independent from a fixed sigma-algebra $F$, i.e. $\sigma(X_n)$ is independent from $F$ for each $n$. Is it always true that $X$ is independent from $F$? My apologies in advance: I am aware that this should be an easy question but I have not so much familiarity with the field of Probability and I am doing my best for improve. Any hint will be very welcome!
(I bet there's some property from measure theory that I am missing :)
Cheers","['probability-theory', 'random-variables', 'measure-theory']"
1532253,Mysterious Inverse Mellin transform using residue theorem,"The origin of this problem lies in the explanation of the evaluation of the series $\sum_{n\geq1}\frac{\cos(nx)}{n^2}=\frac{x^2}{4}-\frac{2\pi}{4}+\frac{\pi^2}{6}$ see this link ( Series $\sum_{n=1}^{\infty}\frac{\cos(nx)}{n^2}$ ) In the proposed solution a complex integral needs to be evaluated, which is a inverse mellin transform. This is done using the residue theorem. Let $Q(s)=-\Gamma(s-2)\zeta(s)\cos(\frac{\pi s}{2})$. The question is how to evaluate $\int_{\frac{5}{2}-i\infty}^{\frac{5}{2}+i\infty} Q(s)/x^s \, ds$ The author states that he integrates over the left plane, I suppose he uses a semi circle as a contour, which includes the 3 poles and if $R\rightarrow +\infty$ the integral over the arc vanishes and the part where $\operatorname{Re}(s)>\frac{5}{2}$ is covered. But how can I prove this? I tried to apply Jensens lemma which didn't work. What am I missing?","['gamma-function', 'mellin-transform', 'residue-calculus', 'zeta-functions', 'complex-analysis']"
1532260,Find the eigenvalues of the operator T.,"I have the following problem, ""Suppose that $X=\ell^1$ and define the operator $T\in B(X)$ as follows: $$Tx=\left(\frac12x_2,\frac13x_3,\frac14x_4,...\right)\,,\textit{where,}\,\,\, x=(x_1,x_2,x_3,...)$$ Find the eigenvalues of $T.$"" Here is my attempt so far: Let $\lambda$ be an eigenvalue of $T$, then, $$\implies\exists x\in \ell^1:Tx=\lambda x,\lambda\in\mathbb C$$
$$\implies\frac12x_2=\lambda x_1,\,\frac13x_3=\lambda x_2,\,\frac14x_4=\lambda x_3,...$$ We can write this in an equivalent manner as follows: $$\implies \frac12x_2=\lambda x_1,\,\frac13x_3=2!\lambda^2x_1,\,\frac14x_4=3!\lambda^3x_1,\,...\,,\frac1nx_n=(n-1)!\lambda^{n-1}x_1,\,...$$ For $n\in\mathbb N/\{1\}$. In order for the eigenvalue problem to be satisfied we require $x\ne1$, and so, if we have that $x_1=0\implies x=0$, which yields a contradiction. Thus, $x_1\neq0.$ This means that we then have, $$x=(x_1,\lambda x_1,2!\lambda^2x_1,...)$$ We must also ensure that $x\in X=\ell^1$, so we consider, $$x\in\ell^1\iff\sum_{k=1}^\infty|x_k|\lt \infty$$ $$\iff\sum_{k=1}^\infty|(k-1)!\lambda^{k-1}x_1|\lt \infty$$ $$\iff|x_1|\sum_{k=1}^\infty|(k-1)!\lambda^{k-1}|\lt \infty$$ And we know that $x_1\neq0$, so, $$\iff\sum_{k=1}^\infty|(k-1)!\lambda^{k-1}|\lt \infty$$ I am unsure how to move on from here. I had thought to argue along the lines that if $(k-1)!$ grows at a rate faster than the $\lambda^{k-1}$ tends to zero, then the sum will not be finite. I think I have to try and show that $|\lambda|\lt1$, but am not sure how to get rid of the $(k-1)!$ in the above. Is the aforementioned line of thought the right way to go about this? Cheers!","['eigenvalues-eigenvectors', 'real-analysis', 'functional-analysis', 'spectral-theory', 'operator-theory']"
1532275,Characterize kernels of monoid homomorphisms,"The kernel of a monoid homomorphism $f : M \to M'$ is the submonoid $\{m \in M : f(m)=1\}$. (This should not be confused with the kernel pair, which is often also named the kernel.) Question. Which submonoids $N$ of a given monoid $M$ arise as the kernel of a monoid homomorphism? (If necessary, let us assume that $M$ is commutative.) Here is a necessary condition: If $xy \in N$, then $x \in N \Leftrightarrow y \in N$.","['abstract-algebra', 'monoid']"
1532339,Prove $\lim_{n\rightarrow \infty} 2^n \sqrt{2-x_n}=\pi$ using the half angle identities.,"Given is the sequence $x_1=0,\; x_{n+1}=\sqrt{2+x_n}$. Prove: $$\lim_{n\rightarrow \infty} 2^n \sqrt{2-x_n}=\pi$$ Hint: Use the following formulas:
$$\cos\left(\frac{x}{2}\right)=\sqrt{\frac{1+\cos x}{2}}$$
$$\sin\left(\frac{x}{2}\right)=\sqrt{\frac{1-\cos x}{2}}$$ Any idea how to solve this problem?","['limits', 'real-analysis', 'trigonometry']"
1532358,"If the derivative of $f$ is never zero, then $f$ is one-to-one","This is an exercise from Abbott's second edition of Understanding Analysis. Let $f$ be differentiable on an interval $A$. Show that if $f'(x) \neq 0$ on $A$, show that $f$ is one-to-one on $A$. Provide an example to show that the converse statement need not be true. Is my solution (below) correct? Let $x_{1},x_{2} \in A $ such that $x_1 \neq x_2$. Since the function satisfies all the conditions of the mean value theorem, there exists $c \in (x_1,x_2)$ [without loss of generality we consider $x_1 < x_2$] such that $f(x_2) - f(x_1) = (x_2 -x_1) f'(c) \neq 0$ as it is given that $f'(x)$ is nonzero on $A$ and $x_1 \neq x_2$ is our assumption. Therefore $x_1 \neq x_2$ implies $f(x_1) \neq  f(x_2)$ for every $x_1,x_2 \in A$. Thus $f$ is one-to one on $A$. The converse may not be true. Consider $A=[-1,1)$ and $f(x)= x^3$. Therefore $f$ is injective on $A$. Again $f'(x)= 2x^2$. Therefore $f'(0)=0, 0 \in A$. So the converse need not be true.","['proof-verification', 'real-analysis', 'derivatives']"
1532390,Applying Kelly Criterion to profit/loss bet,"In a financial derivative trading situation, there are two outcomes to a bet (win/lose), but I don't necessarily lose my entire stake if I lose the bet, because I can buy my way out of the bet, taking a net loss. Nonetheless, I have to bet the entire stake in order to play. However, if I win the bet, I receive my stake plus a fraction as a gain. For example, let's say: my bankroll is \$100 if I win, I will gain 5% of my stake if I lose, I will lose 30% of my stake I expect to win 91% of the time What I want to determine is how much of my bankroll to put at stake. According the Wikipedia article, I should be using this formula: $$
f*=(\frac pa)-(\frac qb)
$$ where: p = probability of winning q = probability of losing ($\equiv 1-p$) a = amount of loss b = amount of gain f* = percentage of bankroll to bet However, when I do the math: $$
f*=(\frac{.91}{.3})-(\frac{.09}{.05})={3.0\overline3}-{1.8}={1.2\overline3}
$$ That's obviously very wrong. I'm expecting a number where $0 \leq f* \leq 1$. A colleague provided a function that he claims is a Kelly formula, and it gives values that I would expect, but I don't understand how he got the formula he uses. $$
k*=p-\frac q{(\frac ba)}
$$ The math works closer to what I would expect: $$
k*={0.91}-\frac {0.09}{(\frac {.05}{.3})}={0.91}-\frac {0.09}{.1\overline6}={0.91}-{.54}={.37}
$$ So I would put 37% of my bankroll at stake, which seems about right. What I don't understand is how my colleague's math works to the Kelly Criterion, or how I misapplied the formula from Wikipedia.","['probability', 'gambling']"
1532392,"What does $W_{1}$ and $(W_{1},W_{2})$ mean under the context of Brownian motion $W_{t}$?","As part of some practice questions for a course I'm taking, I was given the definition of a Brownian motion $W_{t}$ as 
a unique continous-time stochastic process satisfying: $W_{0}=0$ The function $t \rightarrow W_{t}$ is almost surely everywhere continous. The increments $W_{t_{1}} - W_{s_{1}}W_{t_{2}}-W_{s_{2}}$ are independent when $0 \leq s_{1} < t_{1} \leq s_{2}<t_{2}$ The increment $W_{t} - W_{s}$ has a $N(0, t-s)$ distribution for $0 \leq s < t$. This seems to make sense and I did some further research into Brownian motions, however then I was asked what the distribution of $W_{1}$ and $(W_{1},W_{2})$ would be. I don't really know what this means, as I don't know how to express either as any more than some function that is almost everywhere continuous.. it feels like my given definition isn't exactly enough to go off of...","['brownian-motion', 'statistics']"
1532417,Lebesgue measure vs Lebesgue-Stieltjes measure,"Reading advanced probability theory book I've come across Lebesgue-Stieltjes measure. Could someone explain what is the difference between it and ""standard"" Lebesgue measure on $\mathbb{R}$? Thank you.","['probability-theory', 'measure-theory']"
1532474,Expectation of supremum of a submartingale,"I have a probability space $(\mathbb{P}, \Omega, \mathcal{F})$ and in this space, I have a submartingale $(X_n)_n$ with the following two properties: $\inf_n X_n < 0$ $\mathbb{E}[X_0] \geq 0$ and I am supposed to show that $\mathbb{E}[\sup_n X_n] = \infty$. I am not very familiar with the language of probability but the main idea I am using is the fact that, the expectations form an increasing sequence: $\mathbb{E}[X_{n+1}] \geq \mathbb{E}[X_n]$. Since the infimum is a negative function we know that the set $\{ \omega \in \Omega : X_j(\omega) < 0\}$ has positive measure (probability) for some $j$. Otherwise, the countable union of these would have measure zero and almost surely our random variables would be positive which contradicts the first assumption in the hypothesis. So, let $j_1$ be the minimum natural number with this property. We know that expectations are increasing and before $j_1$, all random variables are almost surely positive. So, $X_{j_1}$ must compensate this ""going below zero"" by ""going up high somewhere else"" which means that the supremum of $X_{j_1}$ over all of $\Omega$, is strictly larger than supremum of earlier random variables. My goal is to somehow continue this process and reach that $\sup_n X_n$ is too big to have finite expectation. I can continue one more step: Since $X_{j_1}$ has non-negative expectation, it can not be negative everywhere. Therefore, it must be positive in a set of positive measure:$\mathbb{P}\{ \omega \in \Omega: X_{j_1}(w) > 0 \} > 0$. By the above argument, there is an $X_{j_2}$ such that there is a positive measure subset of this set where $X_{j_2}$ is negative. Can I continue doing this? Is it possible that first two random variables in my submartingale take care of the infimum condition and then the rest in the sequence are just constant? In particular, what is wrong with the following counterexample: $\Omega = [0,1]$, $X_n = 4$ (constant) for $n \geq 2$, $X_0 = -1$ on first half of the interval, $X_0 =1$ on the second half. Finally, $X_1 = 4$ on the first half and $X_1 = -1$ on the second. I satisfy that $X_0$ has zero (non-negative) expectation. And I satisfy that expectations increase. However, the supremum of these functions is constant 4. Then, the only problem should be that my example is not a submartingale. And this tells me that to solve my original problem, I should somehow use the submartingale property, with filtrations and everything, which I am not very comfortable with. (I also learned things like Doob's Inequality etc., but I can not see how that can be useful.) Should I change my point of view and try something else? I don't know how to attack this problem, other than the way I am used to from my measure theory class.","['probability-theory', 'martingales']"
1532481,Proof that correlation coefficient squared equals the coefficient of determination,"Hi I as the title says I'm looking at the proof that $r^2$ = $R^2$ in the case of simple linear regression, but I don't understand one part. There are different versions of the proof, but in most of them they do a step I don't understand. You may look at slide 9 here for instance. Particularly I don't understand how $(Y-\hat{Y})(\hat{Y}-\bar{Y}) = 0$. Could anyone please explain to me why that is? Thank you","['correlation', 'statistics', 'regression']"
1532485,"Algebraic topology, proving two spaces aren't homeomorphic","I need help on how to approach a problem of this kind, I'm given two topological spaces:
$$X=\mathbb{R}^2-\{(n,0)|n\in\mathbb{N}\}\text{ and }Y=\mathbb{R}^2-\{(\frac{1}{n},0)|n\in\mathbb{N}\}$$
I want to show that they're not the same but I have no clue where to start, one way could be showing that $\pi_1(X)\neq\pi_1(Y)$, but I don't know how to compute those groups.","['algebraic-topology', 'general-topology']"
1532507,Every sixth polynomial shares a factor of $(a^2-6)$,"I currently looking at the polynomials you get from the series expansion of 
$$
\frac{1-x^2}{1-ax+2x^2}=1+a x
 +(a^2-3) x^2
 +(a^3-5a) x^3
 +\underbrace{(a^4-7a^2+6)}_{(a-1)(a+1)(a^2-6)} x^4+\dots
$$ W|A helped here... What I found is that from $x^{4}$ onwards, every sixth polynomial shares a factor of $(a^2-6)$. How to prove that?",['sequences-and-series']
1532527,"If $\int_A f\,dm = 0$ for all $A$ having some fixed measure $C$, then $f = 0$ almost everywhere","Let $ f \in L^1[0,1]$. Assume that there is a constant C, with $0 < C < 1$, such that for every measurable set $A \subset [0,1] $ with $m(A)=C$, we have 
$ \int_{A} f dm = 0 $.  Prove that     $f = 0$ almost everywhere. I tried to do my contradiction but I could not get my head around it. Any hints or ideas are appreciated.","['measure-theory', 'almost-everywhere', 'real-analysis', 'analysis', 'lebesgue-integral']"
1532558,"$M$ orientable implies $H_{n-1}(M, \mathbb{Z})$ is free Abelian group. [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $M$ be a compact connected $n$-manifold without boundary, where $n \ge 2$. How do I see that if $M$ is orientable, then $H_{n-1}(M, \mathbb{Z})$ is a free Abelian group?","['homology-cohomology', 'abstract-algebra', 'manifolds', 'general-topology', 'algebraic-topology']"
1532580,Original proof of Ljunggren's equation,"The equation $$x^2=2y^4-1$$ was studied and solved by Ljunggren, who showed that $(1,1)$ and $(293,13)$ are the only integer solutions. However, his proof was very difficult and L. J. Mordell thought there must be an easier proof. Nowadays, this equation can be rewritten in Weierstrass form and solved by an algorithm for elliptic curves. However, I was wondering what the original proof really was. Here are some of the references on Wikipedia that I can't seem to be able to open. Draziotis, Konstantinos A. (2007), ""The Ljunggren equation revisited"", Colloquium Mathematicum 109 (1): 9–11, doi:10.4064/cm109-1-2, MR 2308822. Ljunggren, Wilhelm (1942), ""Zur Theorie der Gleichung x2 + 1 = Dy4"", Avh. Norske Vid. Akad. Oslo. I. 1942 (5): 27, MR 0016375. I have found a proof without the use of elliptic curves by Ray Steiner and Nikos Tzanakis, but the proof also requires some computational power, which Ljunggren didn't have access to. So if anyone knows a proof to this, it would be appreciated if you post it.","['elliptic-curves', 'number-theory', 'diophantine-equations', 'reference-request', 'algebraic-number-theory']"
1532597,Conformal mappings between open disk and half space,In which book / handout can I find an explicit description of a conformal mapping between the open ball and the upper half space in $n$ dimensions?,"['riemannian-geometry', 'differential-geometry', 'geometry', 'reference-request', 'mobius-transformation']"
1532602,rate of convergence central limit theorem,"Let $X_{1},X_{2,\ldots }$ be i.i.d. with finite second moment random variables. With mean $\mu$ and $\sigma^{2}$
Then the classical CLT states:
$\sqrt{n}(\overline{X_{n}}-\mu)$ convergences to $N(0,\sigma^{2})$ in distribution.
Therefore, statisticians usually claim that the convergence in probability, 
$\overline{X_{n}}$ to $\mu$, holds with the rate $\frac{1}{\sqrt{n}}$. My Questions are: Can someone give a detailed explanation of that fact?
Isn't it necessary, that the r.vs have finite third moment in order to be able to make statements about the rate of convergence? (Using Berry Esseen)","['probability-theory', 'probability', 'statistics']"
1532605,Show $R$ is right-Artinian but not left-Artinian,"Let $R$ be the subring of $M_2(\mathbb{R})$ defined by
$$R=\left\{\begin{pmatrix}a&b\\0&d\end{pmatrix}\mid a\in\mathbb{Q},b,d\in\mathbb{R}\right\}$$ Show that $R$ is right-Artinian but not left-Artinian. The ""obvious"" approach to show it is not left-Artinian is to find an $A\in R$ such that
$$RA\supset R(A^2)\supset R(A^3)\supset\dots$$ is an infinite decreasing chain of proper left submodules of $R$ (as a module over itself). However, after spending a lot of time in this endeavor I've come to the conclusion that no such element $A$ exists (I can post a proof if anybody is interested but it'd be long and not worth the time for me otherwise). Does anybody have an idea for another approach I can take to this? I have no idea what else submodules of $R$ would look like.","['abstract-algebra', 'noncommutative-algebra', 'ring-theory']"
1532628,"Isomorphism between $SL(2,\mathbb{Z}) \times \mathbb{Z_2}$ and $GL(2,\mathbb{Z})$","Since $SL(2,\mathbb{Z})=\{A\in M_{(2,2)}(\mathbb{Z})|\det(A)=1\}$ and $GL(2,\mathbb{Z})=\{A\in M_{(2,2)}(\mathbb{Z})|\det(A)=\pm1\}$, 
one can naturally guess there may exist an isomorphism between $SL(2,\mathbb{Z}) \times \mathbb{Z_2}$ and $GL(2,\mathbb{Z})$. In my text book, the author shows that $SL(2,\mathbb{Z})\cong \mathbb{Z_4}*_{\mathbb{Z_2}}\mathbb{Z_6} $ and $GL(2,\mathbb{Z})\cong (\mathbb{Z_4}*_{\mathbb{Z_2}}\mathbb{Z_6})\times \mathbb{Z_2}$. Hence there should be such an isomorphism. But I failed to construct a conscise isomorphism directly from $SL(2,\mathbb{Z}) \times \mathbb{Z_2}$ to $GL(2,\mathbb{Z})$. Is there a '(possibly) simple' isomorphism between them? Any help will be appreciated.","['group-theory', 'linear-groups', 'group-isomorphism']"
1532659,Bounded set in Riemannian manifold is relatively compact,"Suppose $\{x_n\}_{n=1}^{\infty}$ is a bounded sequence in a finite dimensional Riemannian manifold. Can I say that this set is relatively compact? In $R^n$, this is true by Bolzano-Weierstrass theorem. I cannot think of a way to transfer that argument to any finite dimensional Riemannian manifold.","['riemannian-geometry', 'differential-geometry', 'real-analysis', 'functional-analysis']"
1532668,"If $\{x,\{x,y\}\} = \{z, \{z,t\}\}$, then must it be $x = z$ and $y = t$?","If $\{x,\{x,y\}\} = \{z, \{z,t\}\}$, then must it be $x = z$ and $y = t$? Can you explain, or can you give hint?",['elementary-set-theory']
1532674,"Calculate the density function of $Y=\frac{1}{X}-X$ where $X\sim U[0,1]$","I know that :
$$f_X(x)=\cases{1 & $x\in [0,1]$\\0 & $x\notin[0,1]$}$$
Then:
$$P(Y\leq y)=P(\frac{1}{X}-X\leq y)=P(X\leq\frac{1}{2}(\sqrt{y^2+4}-y))$$ as $$\frac{1}{x}-x=y\rightarrow x\frac{1}{x}-xx=yx\rightarrow 1-x^2=yx\rightarrow 1-x^2-xy=0\rightarrow \cases{\frac{1}{2}(\sqrt{y^2+4}-y)\\\frac{1}{2}(-\sqrt{y^2+4}-y)}  $$ I assumed positive root only(dont know if it is right assumption). So I am stuck from now on. Any suggestions.","['probability-theory', 'probability-distributions', 'transformation']"
1532738,Logical Dependence of Induction on the Well-Ordering Principle,"I know from a Discrete Mathematics class in the spring that Mathematical Induction depends on the well-ordering principle for natural numbers. The explanation in my textbook (Rosen) did not give me the level of understanding I was hoping for. Could someone explain the equivalence of the well-ordering principle and the principle of mathematical induction? I am aware there are resources for proofs of this, but I am looking for a more ""intuitive"" explanation than a proof- proofs I can read on my own.","['logic', 'induction', 'discrete-mathematics', 'soft-question']"
1532743,Second order Taylor expansion of vector-valued function,"I am wondering what is the second order Taylor expansion of a vector-valued function $f(x):\mathbb{R}^M\rightarrow \mathbb{R}^N$. I know that the gradient of a vector-valued function is a Jacobian matrix $\nabla f(x)\in \mathbb{R}^{M\times N}$, and using this we have the first order Taylor expansion $f(x) = f(y)+\nabla f(y)^\top (x-y) + \text{higher order terms}$. My question is: what is the second-order expansion? It seems that the ""Hessian"" of $f(x)$ is a $M\times N \times M$ matrix (tensor).  Do I need some tensor operations to form the expansion?","['taylor-expansion', 'calculus', 'multivariable-calculus']"
1532786,average of maximal function is less than its infimum?,"Let M be the dyadic Hardy-Littlewood maximal operator. Prove the following: there is a constant $C$ such that for any $f$,
$$ 
\inf_{x\in I}Mf(x)\le C 2^k\inf_{x\in J} Mf(x)  $$ where $I$ and $J$ are dyadic intervals with $I\subset J$ and $2^k|I|=|J|$ for some positive integer $k$ (i.e. $I$ is the $k$-th generation of $J$). I noticed that this theorem follows from $$\frac{1}{|J|}\int_JMf\le C\inf_{x\in J}Mf(x). $$ This is an interesting phenomenon, but I am unable to prove it.","['harmonic-analysis', 'fourier-analysis', 'real-analysis', 'functional-analysis']"
1532798,"Let A be a square matrix of order $n$ such that $A^{2}= I$. Prove that if $1$ is the only eigenvalue of $A$, then $A = I$.",I have been trying to solve this for hours now and still have no idea. I have tried: a) substituting $\lambda = 1$ into $\lambda x - Ax = 0$. b) substituting $\lambda = 1$ into $\det(\lambda I-A)x = 0$. Both ways have proven ineffective. Any help would be appreciated.,"['linear-algebra', 'matrices']"
1532810,"Can an uncountable set be a ""chain""?","In the Wikipedia page about total orders, it's stated that a ""chain"" is a synonym for a totally ordered set. But this makes no sense to me, since ""chain"" seems to suggest countability, and yet the real numbers would be a chain because they are totally ordered by ""less than or equal to."" Am I missing something, or is it true that ""chain"" can refer to uncountable sets?","['elementary-set-theory', 'order-theory']"
1532849,Trace of hessian,"So this is a result used in Peter Topping's, Lectures on Ricci Flow . What is a quick of showing $$\text{tr}\nabla_{X,\cdot}^2h(\cdot,W)=-(\nabla\delta h)(X,W)$$ where $\delta A=-\text{tr}_{12}\nabla A$, is the divergence operator and $h=\partial_tg$.","['differential-geometry', 'riemannian-geometry']"
1532850,The intersection of all events in a sequence has probability $\lim \limits _{k \to \infty} P(A_k)$,"If a sequence $A_1, A_2, A_3, \dots$ of events is decreasing, show that the intersection of all events in the sequence has probability: $\lim \limits _{k \to \infty} P(A_k)$. I suck at proofs so I am lost. Any help would be appreciated :)","['probability-theory', 'elementary-set-theory', 'measure-theory']"
1532856,Is every Banach space densely embedded in a Hilbert space?,"Can every Banach space be densely embedded in a Hilbert space? This is clear if the Banach space is actually a Hilbert space, but much can you relax this? If the embedding exists, is the target Hilbert space unique?","['hilbert-spaces', 'banach-spaces', 'functional-analysis']"
1532875,I found only one critical point using Lagrange multipliers. Must it be a minimizer?,"I am trying to minimize $$V(x,y,z) = \frac {a^2b^2c^2}{6xyz}$$ subject to $$\frac {x^2}{a^2} + \frac{y^2}{b^2} + \frac {z^2}{c^2} = 1$$ and for $x,y,z>0$. I found one critical point; evaluating it gives a function value of $$V= \frac {\sqrt{3}}{2}|abc|$$ This agrees with the solution that I am looking at, but why does it have to be a minimum? Thanks,","['calculus', 'real-analysis', 'multivariable-calculus', 'optimization', 'lagrange-multiplier']"
1532881,Minkowski functional of a convex set is a convex function.,"Let $X$ be a real vector space, and $K$ be a convex set with $2$ properties:
$0\in K$ and $\forall x\in X, \exists t >0$ s.t. $x/t\in K$. Define the Minkowski functional of the set $K$ to be $p_K(x)=\inf \{t>0: x/t\in K \}$. Show that  $p_K(x)$ is convex. I have tried for some while using the definition of a convex function, but failed to prove this fact. Any idea on how to show it? Thanks!","['convex-analysis', 'functional-analysis']"
1532907,"Prove $E((X+Y)^p)\leq 2^p (E(X^p)+E(Y^p))$ for nonnegative random variables $X,Y$ and $p\ge0$ [duplicate]","This question already has an answer here : Classic $c_r$-inequality in $l_r$ space: $E(|X+Y|^r)\leq c_r[E(|X|^r)+E(|Y|^r)]$ (1 answer) Closed 3 years ago . Suppose $X \geq 0$ and $Y \geq 0$ are random variables and that $p\geq 0$ Prove
$$E((X+Y)^p)\leq 2^p (E(X^p)+E(Y^p))$$ Proof Since $(X+Y)^p \leq (2 \> \max\{X,Y\})^p=2^p \> \max \{X^p,Y^p\}\leq 2^p(X^p+Y^p)$ $ \implies E((X+Y)^p)\leq 2^p (E(X^p)+E(Y^p))$ If $p>1$ the factor $2^p$ may be replaced by $2^{p-1}$ If $0 \leq p \leq 1$ the factor $2^p$ can be replaced by $1$ Need help with part 2 and 3 any suggestions","['probability-theory', 'expectation', 'measure-theory']"
1532937,Why Is $x \ne y$ Not Transitive on the Set of All integers?,"I know this is a pretty simple question, but I'm just not getting the textbook... I'm taking a basic CS course and on one of the problems (not an assigned homework problem, just one I'm practicing on), it says that on the set of all integers, the relation $x \ne$ y is symmetric but not transitive where $(x,y) \in \Bbb R$. I understand why it's symmetric, but why is it not transitive? I'm thinking it has something to do with the definition of transitive including ALL $a,b,c \in A$, but I'm not sure. I understand transitive in the context of a finite set, but something about applying it to all integers is throwing me off.","['elementary-set-theory', 'relations']"
1532956,$\mathcal M(K)$ is an $\mathcal{l}_1-$sum of $L_1(\mu)$ spaces,"Let $K$ be a compact Hausdorff space. I want to show $\mathcal M(K)$ is an $\mathcal{l}_1$ -sum of $L_1(\mu)$ spaces, where $\mathcal M(K)$ is the dual of $C(K)$ . I have got the sketch of the proof but there are some small details that I don't know how to verify. First, by Zorn's Lemma, we can choose a maximal collection of mutually singular probability measures, say $(\mu_i)_{i\in I}$ and claim that $$\mathcal M(K) \cong \big(\oplus_{i\in I} L_1{(\mu_i)}\big)_{l_1}$$ For any $\nu \in \mathcal M(K)$ and $i \in I$ , by Lebesgue's decomposition theorem , there exists finite signed measures $\lambda_i$ and $\rho_i$ such that $\nu=\lambda_i + \rho_i$ , $\rho_i<<\mu_i $ and $\lambda_i \perp \mu_i$ . Let $f_i := \frac{d\rho_i}{d\mu_i}$ be the Radon–Nikodym derivative. Now my first question is: How to show that $(f_i)_{i\in I} \in \big(\oplus_{i\in I} L_1{(\mu_i)}\big)_{l_1}$ ? By the Radon–Nikodym theorem, each $f_i \in L_1(\mu_i)$ . But we need to show that the sum $\sum_{i\in I} \|f_i\|_1$ is finite. Do we actually have $\|v\|=\sum_{i\in I} \|f_i\|_1$ ? After showing this, we define the map $\phi:\mathcal M(K) \to \big(\oplus_{i\in I} L_1{(\mu_i)}\big)_{l_1}$ by $\nu \mapsto (f_i)_{i\in I}$ , which is an isometry. My second question is: How to verify that this map is surjective? Thank you in advance! (Sorry for the typos. I have corrected many of them.)","['banach-spaces', 'functional-analysis', 'measure-theory']"
1532968,Understanding the Normal Distribution?,"If a sample is normal with observations independent and identically distributed: $\mu|\sigma^2 \propto N(\beta \,,\,\sigma^2/\, n_0)$ How can I show that 
$\mu\,|\,x_1,x_2,....x_n\,,\,\sigma^2 \sim N(\frac {n\bar{x} + n_o\beta}{ n + n_o} \, , \frac {\sigma^2}{n + n_o})$ ? I have been trying to figure this out for days.  Originally I assumed both the mean and $x_1,....x_n$ were normally distributed and the the variance as chi squared distributed but I have don't know how to incorporate all three in a manner to get a normal distribution.","['probability-theory', 'normal-distribution', 'random-variables', 'statistics', 'standard-deviation']"
1532981,Modeling drunkeness over time,"So you have the function of drunkenness,$D(t)$, the amount of alcohol in your blood, for $t>0$, over time,$t$ in hours: $$D(t)=T-ct$$ $c$ being the arbitrary amount of alcohol your liver will process in 1 hour.  $T$ being the total amount of alcohol you have drunk at time t. So T does depend on t, but it still a totally arbitrary amount. As a piece wise function based on $T=c_nt$. $c_n=nc$ with n being some non negative number, representing the number of drinks of strength c had in 1 hours time: $$T= \begin{array}{cc}
  \{ & 
    \begin{array}{cc}
      t=1 & n_1c \\
      t=2 & n_2c \\
      ... \\
      t=n & n_nc
    \end{array}
\end{array}$$ So to find T for a certain time, t, $$T(t=n)=n_1c+n_2c...+...n_nc=(n_1+n_2+n_n)c$$ The number of drinks had each hour is totally arbitrary.  Now what I want to do is to compare this between different values of c.  Like comparing the same amount of drinking between a light beer (call it 1c) and a craft beer (2c). Is there a way to generalize this. For example: $$T= \begin{array}{cc}
  \{ & 
    \begin{array}{cc}
      t=1 & 2c \\
      t=2 & 1c \\
      t=3 & 3c
    \end{array}
\end{array}$$ $$T(t=3)=6c$$ So $$D(t=3)=3c$$ but if c=2c $$T(t=3)=12c$$ and $$D(t=3)=9c$$ So drunkenness is not a linear relationship related to the strength of alcohol you are drinking.","['analysis', 'real-analysis', 'functions']"
1533006,Faults in epsilon-delta proof?,"Above is the textbook proof that $\lim\limits_{x\to 3}\frac 1x=\frac 13$. I'm not sure if this is completely correct or not since I noticed that some of the implied inequalities doesn't hold $\forall~\epsilon\gt 0$. Take, for example, the inequality in the 4th line of the image : $$\frac 3{1+3\epsilon}\lt x\lt \frac 3{1-3\epsilon}$$ that is implied by the 3rd line. That inequality doesn't hold, for say $\epsilon=2\gt 0$, i.e., there is no real $x$ for when $\epsilon=2$ that satisfies that inequality. Also, I wonder why they took the $\min$ of $\delta_1$ and $\delta_2$ to be the $\delta$ since I think we should take the $\max$. This is because $-a\lt x\lt b\implies |x|\lt \max(a,b)~\forall~a,b\in\Bbb R$. I'm pretty much a beginner at rigorous stuff like this, so I might be completely wrong in my thinking. I look forward to helpful responses from the community. Thanks.","['limits', 'real-analysis', 'epsilon-delta']"
1533040,Normality of Sylow $p$-subgroup if all maximal subgroups have prime index,"This is exercise 1.C.7 in Isaacs, Finite Group Theory . I have a solution, but I am suspicious that there is something wrong with it, because I do not fully use one of the hypotheses. Let $G$ be a finite group in which every maximal subgroup has prime index, and let $p$ be the largest prime divisor of $|G|$. Show that a Sylow $p$-subgroup is normal. Hint: Otherwise, let $M$ be a maximal subgroup of $G$ containing $N_G(P)$, where $P \in Syl_p(G)$. Compare $n_P(M)$ and $n_P(G)$. I argue as suggested in the hint. Suppose that $P \in Syl_p(G)$ and $P$ is not normal. Then $N_G(P)$ is a proper subgroup of $G$, so it is contained in some maximal subgroup $M$. This gives us the containments $P \leq N_G(P) \leq M < G$. Note also that $P \in Syl_p(M)$. Since $|G:M|$ is prime and is not equal to $p$ (otherwise $|G:P|$ would be divisible by $p$), we have $|G:M| = q < p$ for some prime $q$. Now $n_p(G) = |G:N_G(P)|$ and $n_p(M) = |M:N_M(P)|$. But $N_M(P) = N_G(P) \cap M = N_G(P)$ since $N_G(P) \leq M$. Therefore, $n_p(M) = |M:N_G(P)|$. Summarizing, we have $n_p(G) = |G:N_G(P)| = |G:M|\,|M:N_G(P)| = q\,n_p(M)$. Taking this equation mod $p$ gives us $1 \equiv q$ mod $p$, since by Sylow's theorem both $n_p(G)$ and $n_p(M)$ are congruent to $1$ mod $p$. But $1 < q < p$, so we have a contradiction, and therefore $P$ must be normal after all. My concern is that I don't seem to require that $q$ is prime, only that it is any integer satisfying $1 < q < p$. So, it would seem that the hypothesis ""every maximal subgroup has prime index"" could be replaced with ""every maximal subgroup has index no larger than $p$"". But Isaacs is generally very economical with his hypotheses, so I suspect that there is a problem with my proof. Also, this answer seems much more brief/straightforward than usual for this book.","['sylow-theory', 'group-theory', 'proof-verification', 'finite-groups']"
1533052,Computations of Blow up,"Let $V=Z(y^5-x^3(x+1))$ be an irreducible variety in $\mathbb A^2$ . The partial derivatives of the equation $y^5-x^3(x+1)$ at the point $p=(0,0)$ are: $ \frac{{\partial f}}{{\partial x}}=-3x^2-4x^3$ , $ \frac{{\partial f}}{{\partial y}}=5y^4$ ,  then $\frac{{\partial f}}{{\partial x}} | _p=0=\frac{{\partial f}}{{\partial y}} | _p$ i.e. $p$ is a singular point. 1) The equations of the blowing-up at $p$ in $\mathbb A^2\times\mathbb P^1$ are $xu=yt$ together with the morphism restriction $\pi:\Pi\to\mathbb A^2$ where $\Pi$ are given by the equation $xu=yt$ in $\mathbb A^2\times\mathbb P^1$ . 2) In the affine chart $t=1$ , we have a) $y^5=x^3(x+1)$ b) $xu=y$ . Thus $Z(xu-y,y^5-x^3(x+1))=Z(y-xu,x)\cup Z(y-xu,x^2u^5-(x+1))$ , and the exceptional curve is $Z(y-xu,x)=E$ . Then $E\cap V_1=\emptyset$ with $V_1=Z(y-xu,x^2u^5-(x+1))$ Thus look at the chart affine $u=1$ 3) In the affine chart $u=1$ , we have a) $y^5=x^3(x+1)$ b) $x=yt$ In this case, $Z(xu-y,y^5-x^3(x+1))=Z(y,x-yt)\cup Z(y^2-t^3(yt+1),x-yt)$ and the exceptional curve is $E=Z(y,x-yt)$ . Then $E\cap V_2=\{(0,0,0)\}$ with $V_2=Z(y^2-t^3(yt+1),x-yt)$ Now calculate the matrix of partial derivatives of the equations of $V_2$ ; if $f=x-yt, g=y^2-t^3(yt+1)$ $\begin{bmatrix}{\frac{{\partial f}}{{\partial x}}=1}&{\frac{{\partial f}}{{\partial y}}=-t}&{\frac{{\partial f}}{{\partial t}}=-y}\\{\frac{{\partial f}}{{\partial x}}=0}&{\frac{{\partial f}}{{\partial y}}=2y-t^3}&{\frac{{\partial g}}{{\partial t}}=-4t^3y-3t^2} \end{bmatrix}|_{(0,0,0)}= \begin{bmatrix}{1}&{0}&{0}\\{0}&{0}&{0}\ \end{bmatrix}$ Then the variety $\widetilde{V}$ is singular in $\pi^{-1}(p)$ . Is correct? I have to do blowing up of the variety $V_2=Z(y^2-t^3(yt+1),x-yt)$ but now on $\mathbb A^3\times\mathbb P^2$ ? They could help me do this please.","['blowup', 'algebraic-geometry']"
1533068,What does ${50}\choose{4}$ mean in statistics?,I have a test tomorrow in statistics and was wondering what the following means? $$\binom{50}{4}$$ My professor along with most of my classmates have a calculator they can just plug that into. The professor never went into depth on what it means and how to figure it out with a normal ti-30. Thanks for your time.,"['combinations', 'statistics', 'elementary-number-theory', 'factorial', 'binomial-coefficients']"
1533071,Homology of hexagon,"My question has 4 parts, it is pretty long. Hence I would appreciate even the tiniest hint / comment regarding how to do this question. Thanks! Part 1) Compute $\pi_1(X)$. Part 2) Compute the integral homology $H_* (X;\mathbb{Z})$. Part 3) Compute the mod 2 homology $H_*(X;\mathbb{Z}/2\mathbb{Z})$. Part 4) Compute $H_*(X,\mathbb{Z}/p\mathbb{Z})$ for an odd prime $p$. Consider $X$, the quotient space of the hexagon with identification on its edges as follows. Part 1) Compute $\pi_1(X)$. My solution: $\pi_1(X)=\langle a,b,c\mid a^2b^2c^2\rangle$. Is that correct? I did it using van Kampen's Theorem. Part 2) Compute the integral homology $H_* (X;\mathbb{Z})$. My attempt: I managed to compute $H_0(X,\mathbb{Z})=\mathbb{Z}$, based on the following $\Delta$-complex. However, I am stuck with $H_1(X,\mathbb{Z})$. I calculated $\partial a=\partial b=\partial c=0$, hence concluded that $\ker \partial_1=\mathbb{Z}\oplus\mathbb{Z}\oplus\mathbb{Z}$.
Then, I calculuated $\partial_2 (S_1)=a+e-d$, ..., $\partial_2 (S_6)=h-g+b$, and concluded that $\text{Im}\ \partial_2 =\mathbb{Z}^{\oplus 6}$ which seems to be wrong.. Thanks a lot once again. Part 3) Compute the mod 2 homology $H_*(X;\mathbb{Z}/2\mathbb{Z})$. Part 4) Compute $H_*(X,\mathbb{Z}/p\mathbb{Z})$ for an odd prime $p$. I am totally stuck with parts 3 and 4.","['homology-cohomology', 'algebraic-topology', 'general-topology']"
1533077,Is there a borel set $A$ and a linear map $f$ such that $f(A)$ is not borel?,Is there a borel set $A\in\mathbb{R}^n$ and a linear map $f:\mathbb{R}^n\to\mathbb{R}^n$ that $f(A)$ is not borel set? I think there is but I can't find it.,"['real-analysis', 'descriptive-set-theory', 'measure-theory']"
1533096,"Villarceau Circles as loxodromic concurrent intersections among a plane, a sphere and a torus","A circular Clifford torus (radius at flat circle = h, section radius $ a , a<h $ )  is cut by a plane at an angle $ \cos \alpha = a/h \tag{1} $ centrally to the symmetry axis, the line of intersection is a Villarceau Circle. Show how, or by what Law or Theorem  the the Circle is a Loxodrome, i.e., makes a constant $$ \psi = \alpha \tag {2} $$ to torus meridians, that appears to be a situation of intersections as indicated here, agreeing with result from Colonel Schölcher mentioned in Wiki article of reference. Joachimsthal's theorem ( line of curvature of either surface cutting at same angle) does not seem to be of relevance here. I have checked it to be so by numerical calculation, and also that the Villarceau circle has curvature $ \kappa= 1/h \, \tag{3} $ Posted in SE Mathematica recently. I seek your help in being able to appreciate it more directly by analytical derivation. The loxodrome situation can be understood, hopefully around the new three common intersections. The Villarceau Circles are lines of concurrent intersection between three surfaces. Torus,Plane and Sphere. Image is uploaded. The sphere is not given in Wikipedia on the topic of Villarceau circles as being one of the generating intersection surfaces. Also I have not seen it anywhere else in this context.I am reporting this finding here. Plane $$ z = y \,\tan \alpha \tag{4} $$ Torus $$ (x,y,z) = ( ( h + a \cos u) \sin v ,( h + a \cos u) \cos v, a \sin u ) \tag{5} $$ where $ u $ is toroid latitude, $v$ longitude. A relation between $u,v$ of Torus surface  to obtain the Villarceau Circle intersection line that I obtain like spherical $$ (u,v) = ( \phi ,\theta) \tag{6} $$ $$ \sec \alpha = \frac{\sin u  \sin v }{\cos u - \cos v}  \tag{7} $$ The above result is obtained by assuming *constant $\alpha = \psi $ angles between Villarceau Circle and Torus meridian for Loxodrome *, so the question still remains. I have no access to the original article of Colonel Schölcher or the other references in: Villarceau Circles Wiki Sphere $$ (x,y,z)= (\cos u \sin v, \cos u \cos v \color {red} {+a } , \sin u) \tag{8} $$ where $ u $ is sphere latitude, $v$ longitude. Common Villarceau Circle intersection between Plane, Torus and sphere Any two surfaces intersect along the Villarceau Circle. $$ (x,y,z)= (\pm (a-h) \cos u , \sqrt{h^2-a^2} \sin u, a \sin u)  \tag9 $$ where $u$ is rotation angle starting from y-axis around torus center. Intersection of Torus-Plane are 1) Villarceau Circles. I have given here the new intersections 2) between Sphere-Torus touching at outer and inner radii of torus, as well as 3) Plane--Sphere (small circle of a sphere) are given by The motivation of this post was to draw a noticeable parallel of intersections on the one hand between sphere/ eccentric cylinder defining the Viviani curve and, on the other a torus/ eccentric sphere intersection curve in the same way defining Villarceau Circle now noticed here. Further, if $ \phi $ is meridional rotation around tube section and prime denotes differentiation with respect to arc length $s$ , the Villarceau circle possesses a very simple differential relation: $$ \boxed{\phi^{'} = \frac {\cos \psi}{h};\, \psi = \alpha, \,\psi^{'} (s)=0} \tag{10} $$ Arc length $$ s_{max} = 2 \pi h \tag{11} $$ Orthogonal projections are uploaded for a Villarceau Circle with dimensions $ h=5, a= 3. $ The projection of planar intersection is not  centered , but appears as an off-centred ellipse in 3D. The Villarceau Circle is shown in thick red contrasted: EDIT1: Another view where the rim of Villarceau Circle is swept about torus axis to generate the torus is shown below, unlike when torus is shown above conventionally as swept meridians:","['solid-geometry', 'differential-geometry']"
1533139,Is the long line completely uniformizable?,"The long line $L$ is uniformizable; in fact, as $L$ is a locally compact Hausdorff space we can explicitly write down a uniformity for it: If $\hat{L}$ is the one-point compactification of $L$, then $\hat{L}$ is compact Hausdorff, and so it has a natural uniformity that we can restrict to $L$. But this is not a complete uniformity; its completion is $\hat{L}$.  Is there a complete uniformity on $L$? One well-known result is that any paracompact Hausdorff space is completely uniformizable.  In particular, any manifold is completely uniformizable.  Does the same apply to spaces like $L$, or are they ""too noncompact"" to have a complete uniformity?","['uniform-spaces', 'general-topology', 'compactness']"
1533144,Proof that a matrix can be written as the product of a positive definite matrix and an orthogonal matrix,"How can I show that for a real invertible matrix $A$ with dimensions $n \times  n$ $A$ can be written: $A = B C$
where $B$ is a positive definite matrix and $C$ is an orthogonal matrix.","['linear-algebra', 'matrices']"
1533161,Describe all differentiable functions that follow these rules,Describe all differentiable functions that follow these rules: $$ f'(x) = f(x)^3 $$ and $$ f(0) = 2. $$ This came up in the scholarship exam today. I am clueless as to how you do this one.,"['calculus', 'ordinary-differential-equations']"
1533165,Which is the correct way to analyse balls drawn from an urn (with replacement),"4 balls are extracted at random - with replacement - from a urn with 3 white and 6 black balls. What is the probability that all extracted balls are 2 white and 2 black? Here is all my steps: If we use this method like in this video from 1:50 obtain: The probability that the ball extracted to be white is: $\frac{1}{3}\Rightarrow\left(\frac{1}{3}\right)^2$= probability that from 2 balls extracted, 2 are white; The probability that the ball extracted to be black is: $\frac{2}{3}\Rightarrow\left(\frac{2}{3}\right)\cdot\left(\frac{1}{3}\right)^2$= probability that from 3 balls extracted, 2 are white and 1 is black; $$\Rightarrow\left(\frac{1}{3}\right)^2\cdot\left(\frac{2}{3}\right)^2 = \text{probability that from 4 balls extracted 2 are white and 2 are black}$$ But if we use Bernoulli trial we obtain: $P={4\choose 2}\cdot\left(\frac{1}{3}\right)^2\cdot\left(\frac{2}{3}\right)^2$ Why if we use Bernoulli trial we have one more thing: ${4\choose 2}$? And which is correct from above?",['probability']
1533237,Spectrum of $\mathbb{Z}^\mathbb{N}$,"Is anything known about the spectrum of $\mathbb{Z}^{\mathbb{N}}$? Notice that the fiber of $\mathrm{Spec}(\mathbb{Z}^{\mathbb{N}}) \to \mathrm{Spec}(\mathbb{Z})$ at a non-zero prime ideal $(p)$ is the spectrum of $\mathbb{Z}^{\mathbb{N}}/(p) \cong \mathbb{F}_p^{\mathbb{N}}$, which corresponds$^1$ to the set of ultrafilters on $\mathbb{N}$. Thus we only have to look at the generic fiber, which is the spectrum of the $\mathbb{Q}$-algebra $\mathbb{Z}^{\mathbb{N}} \otimes_{\mathbb{Z}} \mathbb{Q}$. This is isomorphic to a subalgebra of $\mathbb{Q}^{\mathbb{N}}$ consisting of those sequences of rational numbers whose denominators are bounded (with respect to suitable (not any) representations as fractions). In particular, every ultrafilter on $\mathbb{N}$ induces a prime ideal of $\mathbb{Z}^{\mathbb{N}} \otimes_{\mathbb{Z}} \mathbb{Q}$, but not everyone arises like this. $^1$If $(F_i)_{i \in I}$ is family of fields, then there is a bijection between the (ultra)filters on $I$ and the (prime) ideals of $\prod_{i \in I} F_i$. It maps a filter $\mathcal{U}$  to the ideal $\{x \in \prod_{i \in I} F_i : \{i \in I : x_i = 0\} \in \mathcal{U}\}$.","['ring-theory', 'commutative-algebra', 'abstract-algebra', 'algebraic-geometry', 'maximal-and-prime-ideals']"
1533260,What's the difference between a null set and an empty set?,"From my notes, I understand that an empty set always has a null size (is this different from saying that it has a size = 0?). What are then examples of non-empty null sets? Thanks for your time. --- Edit: There seems to be some conceptual difference. Wikipedia also has 2 different articles (which I mostly don't understand :-) ) ( https://en.wikipedia.org/wiki/Null_set and https://en.wikipedia.org/wiki/Empty_set ).",['elementary-set-theory']
1533283,Pullback along the Frobenius morphism,"Let $X$ be a scheme over a finite field $\mathbb{F}_q$ and let $F : X \to X$ be the absolute Frobenius morphism. If $\mathcal{L}$ is an invertible $\mathcal{O}_X$-module, then $F^*(\mathcal{L}) \cong \mathcal{L}^{\otimes q}$ (naturally in $\mathcal{L}$). Is there also a general formula for $F^*(\mathcal{M})$ if $\mathcal{M}$ is a locally free $\mathcal{O}_X$-module of given rank $d$? In other words, I ask for a bundle representative  of the Adams operation $\psi^q$ on the $K$-theory of $X$. For example, when $q=2$, we have $\psi^2(x)=x^2-2 \lambda^2(x)$, and one could hope for a representation of $F^*(\mathcal{M})$ as the cokernel of some monomorphism $\Lambda^2(\mathcal{M}) \oplus \Lambda^2(\mathcal{M}) \to \mathcal{M} \otimes \mathcal{M}$, or as the kernel of some epimorphism $\mathcal{M} \otimes \mathcal{M} \to \Lambda^2(\mathcal{M}) \oplus \Lambda^2(\mathcal{M})$.","['vector-bundles', 'positive-characteristic', 'algebraic-k-theory', 'algebraic-geometry', 'quasicoherent-sheaves']"
1533321,Fisher information for a single sampling of an exponential distribution,"I am viewing an example of finding the Fisher information for a single sampling from an exponential distribution where: $$P(x|\theta) = \frac{1}{\theta}e^{-\frac{x}{\theta}}$$
The score $S$ is $S(x|\theta) = \frac{\partial}{\partial\theta}logP(x|\theta) = -\frac{1}{\theta} + \frac{x}{\theta^2}$.
Fisher information is the expectency of $S^2$ which is: $$E_x[S^2] = E_x\left[\frac{1}{\theta^2} - 2\frac{x}{\theta^3} + \frac{x^2}{\theta^4}\right]$$ I know this might sound strange, but I don't know how to calculate this expectation. Something is mixed for me here. I know that $$E[P(x)]=\int xp(x)dx$$ But I can't connect the two pieces of information. In the book, they got: $$E_x[S^2] = E_x\left[\frac{1}{\theta^2} - 2\frac{x}{\theta^3} + \frac{x}{\theta^4}] = \frac{1}{\theta^2} - 2\frac{\theta}{\theta^3} + \frac{2\theta^2}{\theta^4}\right] = \frac{1}{\theta^2}$$ But I can't see how they got that. Any information will be useful. Thanks.","['probability-theory', 'probability', 'statistics']"
1533375,SVD of concatenate matrices,"Let $X \in \mathbf{R}^{n\times m}$ be split into two sub matrices, $X = 
  \begin{bmatrix}
    X_0 \\
    X_1
  \end{bmatrix}
$, if $X_0 = U_0 \Sigma_0 V_0^T$ and $X_1 = U_1 \Sigma_1 V_1^T$ can we say anything about the SVD of $X$, or at least have a good starting point for an iterative method?","['svd', 'eigenvalues-eigenvectors', 'matrices']"
1533397,Minimizing fuel usage for small boat between given points,"I'm 12 years old and my I was getting bored this afternoon so my dad gave me this math problem (he said it was supposed to be hard, and that I should do some research to learn how to solve it). ""A small boat moving at $V$ km/h uses fuel at a rate given by the function $$q = 8 + \frac {V^2}{50}$$  where q is measured in litres/hour. Determine the speed of the boat at which the amount of fuel used for any given journey is the least."" I had no idea how to do it until i found some stuff on the internet about ""calculus"". I figured out that i might have to work out a formula for the total fuel consumed (fuel rate multiplied by time). But when i tried to do this, I found that I have created another variable (distance) when i was trying to write V in terms of d/t. I am really stuck, i feel like i have worked out how to do these types of problems, but this particular one I cannot solve. I dunno, would you guys maybe be able to solve it, or is it too high-level, maybe i should take it to my math teacher?",['calculus']
1533405,Computing $\lim_{x\to 0}\frac{1-cos(3x)}{5x^2}$ not using derivative,How can we compute the following limit not using derivative? $\lim_{x\to 0}\frac{1-\cos(3x)}{5x^2}$ I know $\lim_{x\to 0}\frac{\cos(x)-1}{x}=0$. But $\lim_{x\to 0}\frac{1-\cos(3x)}{5x^2}=\lim_{x\to 0}\frac{\cos(3x)-1}{3x}\frac{(-3)}{5x^2}=0.-\infty$,"['limits-without-lhopital', 'calculus', 'limits', 'trigonometry']"
1533407,An Algebraic Proof that $|y^3 - x^3| \ge |(y - x)|^3/4 $,"I can prove this using calculus, but not by simple algebra: can anyone help ? Calculus Proof :
Fix the separation of $x$ and $y$ so that $y = x + d$ with $d>0$ ($ \implies y > x \implies y^3 > x^3$) and now consider $ f(x) = y^3 - x^3 = (x+d)^3 - x^3$. $ f(x) = (x+d)^3 - x^3$ = $3x^2d + 3d^2x +d^3$ which is a quadratic in $x$ with a minimum given by $f`(x) = 0 = 6xd + 3d^2$ giving $x = - d/2$ and therefore $y = d/2$. This is not surprising considering the geometry: it says that for a fixed separation of $x$ and $y$, $y^3 - x^3$ is minimised when $x$ and $y$ are symetrically placed around the inflexion point of the cubic. So, $y^3 - x^3 = d^3/8 - (-d^3)/8 = d^3/4$ and since this is the minimum value it follows that for $x \in (-\infty, +\infty)$ and $y > x$ then $y^3 - x^3 \ge (y - x)^3/4 $, so that  $|y^3 - x^3| \ge |(y - x)|^3/4 $ whether $y > x$ or $y < x$ (and clearly this is true for $y = x$.) (The original interest in the inequality comes from this question: cauchy sequence on $\mathbb{R}$ )",['algebra-precalculus']
1533443,Convergence in the box topology,"A sequence in $R^{\omega}$ converges in the box topology iff it converges for each coordinate and is eventually constant in all but finitely many of the coordinates. I know for the direction $\Rightarrow$ we can use the fact that since $\pi_{\alpha}$ is continous so $\pi_{\alpha}(x_n) \rightarrow \pi_{\alpha}(x)$, but how can I show it is eventually constant in all but finitely many of the coordinates? And what about the other direction $\Leftarrow$?",['general-topology']
1533459,Is $\mathbb{R}^{\mathbb{R}}$ or $\mathbb{R}^{\mathbb{N}}$ separable?,"My guess is that they are but I can't find any information in my books. For $\mathbb{R}^{\mathbb{R}}$, Willard describes the basic open sets as all functions whose values are within $\epsilon_k$ on $(1,2,...,k,...,n)$-many fixed coordinates, and so it would seem that I can find a polynomial in any such given open set. For the latter ($\mathbb{R}^{\mathbb{N}}$) I am more unsure.","['separation-axioms', 'real-analysis', 'general-topology']"
1533502,Proving $n\sin(\frac{\pi}{n})<\pi<n\tan(\frac{\pi}{n})$ ; obtaining results from it.,"I was reading The Simpsons and the Mathematical Secrets when I encountered the story of $\pi$. It mentions how Archimedes devised a method to place a lower and upper bound on $\pi$ by bounding a circle of diameter $1$ inside a square and making a square in it. And I also read how the subsequent mathematicians made even more contributions by employing this technique and making polygons of 4 billion billion sides! I just tried to verify it for $4,6$ sides. Then I got the idea for $96$ sides. But I encountered this:
First, lets find the perimeter of the inner polygon. (inscribed). So first to find each side, we divide the polygon in triangles and make their altitudes/medians. (The polygon is regular , so triangle will be isosceles and base altitudes and medians will coincide). So each angle in the right triangle would be $\frac{2\pi}{2*96}=\frac{\pi}{96}$. Now we know that the hypotenuse of each triangle will be equal to radius $=\frac12$. So we get that each side of polygon will be double the side of the right triangles we divided. So we get that each side $=2*\frac{\sin{\frac{\pi}{96}}}{2}=\sin{\frac{\pi}{96}}$. And thus the perimeter is equal to $96\sin{\frac\pi{96}}$. Now at this point, two question arose in my mind: How did the mathematicians found the values of these sine expressions ($\sin{\frac\pi{96}}$)? ( Please don't tell me that series expansions were used because they give approximate results and that too is not necessary ) Can we generalize this to $n$ side polygons (Obviously, for $n\geq 3$ ) and get $n\sin\frac\pi{n}<\pi$? Now, quite intrigued, I proceeded forward and tried to find the perimeter of the bigger polygon. This time I got $96\tan\frac{\pi}{96}$ as the perimeter and thus got the inequality: $$\boxed{n\sin\frac\pi n<\pi<n\tan\frac\pi n}$$
Is it a valid result? Is it have a different, more algebraic proof? Now lets experiment with the inequality. (For $n$ is the no. of sides of a polygon) We get $\sin\frac\pi n<\frac\pi n$ and $\frac\pi n<\tan\frac\pi n$. We divide all sides by $n\sin\frac\pi n$, and square all sides, then subtract $1$ from all sides and again square root to get:
$$0<\sqrt{\frac{\pi^2}{n^2\sin^2\frac\pi n}-1}<\tan\frac\pi n$$ 
Are these of some use? Is this scribbling even correct? If someone can even tell if this has been used as a theorem or result or lemma etc before, it would be helpful.","['math-history', 'proof-verification', 'proof-writing', 'geometry', 'trigonometry']"
1533521,"Solve the diophanic equation $y^2 = x^4 -4x^3 + 6x^2 -2x +5$, where $x,y \in \mathbb{Z}$","Solve the diophanic equation $y^2 = x^4 -4x^3 + 6x^2 -2x +5$. Methods I know: 1) look modulo p for some prime p, when using this method I almost always conclude there are no solutions, so i don't think it is handy to use this in this particular case. 2) Combinations of factorization and estimation: factorize your specific function and Search for an upper bound. I used 2), and i get in a little bit of trouble. I tried factorize the right hand side, but did not come any further then: $y^2 - 10 = (x-5)(x^3 + x^2 - x - 3)$. I don't seem to get an upper bound here..... :(. Any hints on going to the right direction or on using a new method trying to solve this probelem? Kees",['number-theory']
1533577,"$U\subset [0,\infty)$ is open and unbounded $\Rightarrow \exists x$ such that $U\cap \{nx;n\in \mathbb N\}$ is infinite.","I want to show that: Let $U\subset [0,\infty)$ be open and unbounded. Show that there is a number $x\in (0,\infty)$ such that $U\cap \{nx;n\in \mathbb N\}$ is infinite. Because of $U$ is open, $U$ is a countable union of open intervals. if $U$ contain an interval $(a,\infty)$, we are done. But if all intervals which contain in $U$ was bounded, what we can do? can somebody give me a hint?","['metric-spaces', 'real-analysis', 'general-topology']"
1533614,integrate sin(x).,"OK. I have a doubt with this: I know $-\cos(x) + k =\int \sin x\,dx$ but doing
$\sin(x)=2\sin\frac{x}{2}\cos\frac{x}{2}$ I get $\int \sin x\,dx = \int 2\sin\frac{x}{2}\cos\frac{x}{2}\,dx $ if $ u = \sin \frac{x}{2}$ then $du = \cos \frac{x}{2} \frac{dx}{2}$ then $$\int \sin x\,dx = \int 2\sin \frac{x}{2}\cos \frac{x}{2}\, dx =4\int \sin \frac{x}{2} \cos\frac{x}{2}\frac{dx}{2}=4\int u\,du= 4\frac{u^2}{2}= 2u^2 = 2\sin^2\frac{x}{2}$$ then if $\theta = \frac{x}{2} \rightarrow \cos 2\theta =-2\sin^2(\theta)+k \rightarrow \frac{\cos(2\theta)}{2}=\cos^2 \theta -1+\frac{k}{2} $ if $k=0$, then $$\frac{\cos 2\theta}{2}=\cos^2 \theta-1.$$ Now, why isn't it a trigonometric identity? or Is it? Because I think that I found one.","['calculus', 'trigonometry']"
1533620,Basis elements of the uniform topology on $\mathbb R^{\omega}$,"I have been trying to understand the basis elements of the uniform topology on $\mathbb{R}^{\omega}$. For some time, I thought they would be: $B_\bar{p} (x,\epsilon) = \prod (x_i - \epsilon, x_i + \epsilon)$ if $\epsilon < 1$ However, after reading a bit online, I learned that this set is not even open in the uniform topology. The actual basis elements are: $B_\bar{p} (x,\epsilon) = \bigcup_{\delta < \epsilon} \prod (x_i - \delta, x_i + \delta)$  if $\epsilon < 1$ Why is this the case?",['general-topology']
1533647,$xf'(x) = αf(x)$. How to prove that $f(x) = cx^\alpha$?,"Let $f$ be a differentiable function such that $xf'(x) = \alpha f(x)$ for all $x > 0$. How do I show that $f(x) = cx^\alpha$ for some constant $c$? I have $f'(x) = \alpha f(x)/x$ , and I can see that $\alpha$ is the original power and $x$ is the denominator to make the power $(\alpha-1)$, as usual in differentiation, but I don't know how to show this mathematically.","['proof-explanation', 'proof-verification', 'proof-writing', 'derivatives']"
1533650,Is it necessary that if a limit exists at a point it should be also defined at that point?,"Say there exists a limit $\lim_{x \to x_0}f(x) = L$. Is it necessary that $f$ be defined at the point $x_0$ itself? Well, what I think of it is that it's OK to be undefined at that point because I guess that won't cease the limit of that function to exist there would it?","['random', 'calculus', 'limits']"
1533671,"What are the difference among entire, smooth, analytic and holomorphic in complex function?","In complex analysis, I know that they have similar meaning. However what are the difference among them? Especially for entire function, does entire function mean analytic function?","['complex-analysis', 'definition']"
1533676,Sum up a function series $f(1/9)+f(2/9)+\dots+f(26/9)$ for $f(x)=\frac{9^{x}}{9^{x}+27}$,"Given $f(x)=\dfrac{9^{x}}{9^{x}+27}$.
Find:
$$S=f\left(\frac{1}{9}\right)+f\left(\frac{2}{9}\right)+\dotsb+ f\left(\frac{26}{9}\right)$$
Teacher did not allow us to use calculator...Use sigma notation???","['summation', 'algebra-precalculus', 'functions']"
1533724,What is the Edgeworth Expansion of the binomial distribution?,"For a standardized binomial distributed random variable $\tilde B_n$ we have $$P(\tilde B_n\le x) = \Phi(x) + \frac {q-p}{6\sqrt{npq}}  (1-x^2) \phi(x) + \frac{R_1\left(np+x\sqrt{npq}\right)}{\sqrt{npq}}\phi(x) + O\left(\frac 1n\right)$$ with $R_1(x)=\lfloor x \rfloor -x +\frac 12$ [1] . Question: What is the Edgeworth Expension for $P( a \le \tilde B_n \le b)$? Is it true, that it is $$\begin{align}
P( a \le \tilde B_n \le b) &= 
 \Phi(b)-\Phi(a) + \frac {q-p}{6\sqrt{npq}}  (1-b^2) \phi(b) - \frac {q-p}{6\sqrt{npq}}  (1-a^2) \phi(a) \\
& + \frac{R_1\left(np+b\sqrt{npq}\right)}{\sqrt{npq}}\phi(b)-\frac{R_2\left(np+a\sqrt{npq}\right)}{\sqrt{npq}}\phi(a) + O\left(\frac 1n\right)
\end{align}$$ with $R_2(x)=\lceil x \rceil -x -\frac 12$ ?","['normal-distribution', 'statistics', 'asymptotics', 'probability', 'binomial-distribution']"
1533731,Sum of two families of uniform integrable random variables [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question Suppose $\{X_n\}$ and $\{Y_n\}$ are two families of u.i(uniform integrable) random variables defined on the same probability space. Is $\{X_n+Y_n\}$ u.i? Proof Given $$\mathbb{E}[|X_n|\,I_{|X_n|\geq K}]\leq \frac{\varepsilon}{4} ,\qquad \mathbb{E}[|Y_n|\,I_{|Y_n|\geq K}]\leq \frac{\varepsilon}{4}  $$ Since $|X_n+Y_n|\,I_{|X_n+Y_n|\geq 2K}\leq 2|Y_n|\,I_{|Y_n|\geq K}+2|X_n|\,I_{|X_n|\geq K}$ Then $$\mathbb{E}[|X_n+Y_n|\,I_{|X_n+Y_n|\geq 2K}]\leq\mathbb{E}[2|Y_n|\,I_{|Y_n|\geq K}+2|X_n|\,I_{|X_n|\geq K}]$$ $$=2\mathbb{E}[|Y_n|\,I_{|Y_n|\geq K}]+2\mathbb{E}[|X_n|\,I_{|X_n|\geq K}]\leq 2 \frac{\varepsilon} {4}+2 \frac{\varepsilon} {4}= \varepsilon$$ Thus $\{X_n+Y_n\}$ is ui.","['probability-theory', 'expectation', 'measure-theory']"
1533754,Is there a connection between duality in linear programming and duality in functional analysis?,"In linear programming we optimize a linear function which is constrained by linear inequalities or linear equalities. Under some conditions you can rewrite the problem to the dual problem, so that you can solve another linear programming problem to get your result. In functional analysis the dual of a vector space is the collection of linear functionals from the vector space. Are there any connections between this? Can we write the problems in some way so that they say the same thing? The only connection I have seen is that in functional analysis we have the hahn-banach theorem, which is a theorem about extensions of linear functionals, this is connected to the hahn-banach separation theorem, the separating hyperplane theorem, and this again is connected to farkas lemma, which is used in linear programming. Is there any more connections, or is it just coincidental that both use the word dual? Before I started reading functional analysis I thought the connection would be stronger, since we can prove the separating hyperplane theorem using functional analysis, and this theorem and farkas lemma were a big part of linear programming.","['linear-programming', 'functional-analysis']"
1533765,Solve $x-\lfloor x\rfloor= \frac{2}{\frac{1}{x} + \frac{1}{\lfloor x\rfloor}}$,"Could anyone advise me how to solve the following problem: Find all $x \in \mathbb{R}$ such that $x-\lfloor x\rfloor= \dfrac{2}{\dfrac{1}{x} + \dfrac{1}{\lfloor x\rfloor}},$ where $\lfloor *\rfloor$ denotes the greatest integer function. Here is my attempt: Clearly, $x \not \in \mathbb{Z}.$ $\dfrac{x}{\lfloor x \rfloor} - \dfrac{\lfloor x \rfloor}{x}= 2$ $ \implies x^2 -2x\lfloor x \rfloor - \lfloor x \rfloor ^2 = 0$ $\implies  x = (1 \pm \sqrt2 )\lfloor x \rfloor $ $\implies \{x\} = \pm\sqrt2 \lfloor x \rfloor$ Thank you.","['ceiling-and-floor-functions', 'algebra-precalculus']"
1533797,Prove existence,"Let $f$ be a continuous bounded function on the interval $(a, +\infty)$ such that $\lim_{x \to+\infty}f(x)$ does not exist. Prove that for any $t \in\mathbb R$ there is a sequence $x_{n} \to +\infty$ that $f(x_{n} + t) = f(x_{n})$ for all $n \in\mathbb N$.","['sequences-and-series', 'limits']"
1533824,Picture Justification of $\arccos(x) = \int_x^1 \frac{1}{\sqrt{1-t^2}}dt$,"Is there a quick shortcut way to write down that
$$\arccos(x) = \int_x^1 \frac{1}{\sqrt{1-t^2}}dt$$ just using the picture here ?
I know it can be computed with a computation using $\theta = \frac{s}{r}$ and 
$$\theta = \frac{s}{1} = \int_0^s ds' = \int_x^1 \sqrt{1+y'}dt = \int_x^1 \sqrt{1+\left(\frac{d}{dt}\sqrt{1-t^2}\right)^2}dt = ... = \int_x^1 \frac{1}{\sqrt{1-t^2}}dt$$
but it should be obvious without any calculation right? Don't see / forget how to justify it. The main issue is justifying the 
$$\frac{1}{\sqrt{1-t^2}}$$
term.","['calculus', 'trigonometry']"
1533904,Generating function for the number of surjections,"Let $S_k^n$ be the number of possible surjections from a set of $k$ elements to a set of $n$ elements. We have
$$\begin{align}
&S_0^0 = 1,\qquad\forall k>0: S_k^0 = 0,\\
&S_n^n = n!,\qquad\forall k<n: S_k^n = 0,\\
&\forall k>n>0: S_k^n = n(S_{k-1}^n + S_{k-1}^{n-1}).
\end{align}$$
The last relation can be seen as follows: let $\phi:\underline{k}\to\underline{n}$ be a surjection. Consider the subset $\underline{k-1}\subset\underline{k}$ consisting of the first $k-1$ elements $\{1,2,\ldots,k-1\}$. Then either the restriction of $\phi$ to $\underline{k-1}$ is a surjection, and $\phi(k)$ is any element of $\underline{n}$, or the restriction misses exactly one element among the $n$ elements of $\underline{n}$, and $k$ is mapped to this missed element. Representing the first terms in a grid, we have
$$\begin{array}{c|cccccc}
n\backslash k & 0 & 1 & 2 & 3 & 4 & 5 & 6\\
\hline
0 & 1 & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} \\
1 & \color{lightgray}{0} & 1 & 1 & 1 & 1 & 1 & 1\\
2 & \color{lightgray}{0} & \color{lightgray}{0} & 2 & 6 & 14 & 30 & 62\\
3 & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & 6 & 36 & 150 & 540\\
4 & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & 24 & 240 & 1560
\end{array}$$
If we extend $S_k^n$ to $n,k<0$ by setting it to zero everywhere, then the last relation is satisfied everywhere except at the point $(k,n) = (0,0)$. I am interested in the generating function of these numbers, that is
$$S(x,y) = \sum_{k,n\in\mathbb{Z}} S_k^nx^ky^n.$$
Using the relation above, we obtain
$$\begin{align}
S(x,y) = & 1 + \sum_{k,n\in\mathbb{Z}}n(S_{k-1}^n + S_{k-1}^{n-1})x^ky^n\\
= & 1 + xy\left(S(x,y) + (1+y)\frac{\partial S}{\partial y}(x,y)\right).
\end{align}$$
Moreover, we have the boundary conditions $S(x,0) = 1 = S(0,y)$. According to WolphramAlpha , this is solved by
$$S(x,y) = c(x)\left(\frac{y}{(y+1)^{x+1}}\right)^{\frac{1}{x}} + (y+1)^{-\frac{x+1}{x}}{}_2F_1\left(-\frac{1}{x},-\frac{1}{x};\frac{x-1}{x};-y\right).$$
(This was edited after an error in the original question was found by @MickA) Now, just by looking at the equation we know that this function will automatically satisfy the required boundary conditions. How can we fix the function $c(x)$? I am a bit at loss (also because I'm not familiar with hypergeometric functions at all). Also, is it possible derive a closed expression for $S_k^n$ from the resulting solution? Remark: I already know of the formula obtained by inclusion-exclusion principle:
$$S_k^n = \sum_{i = 0}^n(-1)^i\binom{n}{i}(n-i)^k$$
for $0\le n\le k$. I am curious to see if this alternative method works, if it gives exactly the same answer, and if it contains any additional information in general.","['hypergeometric-function', 'generating-functions', 'combinatorics']"
1533905,Find the error (cumulative function of abs.cont. random variable),"Let $X$ be an abs. cont. random variable. Then, for $k \in \mathbb{R}$, $prob(X \leqslant k \leqslant \alpha X)=prob (X\leqslant k)-prob(X\leqslant \frac{k}{\alpha})$. I cannot understeand why it doesn't hold $prob(X \leqslant k \leqslant \alpha X)=prob(X\geqslant \frac{k}{\alpha})-prob (X\leqslant k)=1-prob(X\leqslant \frac{k}{\alpha})-prob (X\leqslant k)$. Thansk. KB","['statistics', 'random-variables']"
1533911,Divergence $0$ everywhere implies Flux $0$?,"I was told this by a college mate, and I was pretty unsure as to why/if this is true. Consider the vectorfield $F=(1,1,1)$, it clearly has divergence $0$ at every point, but, picturing it in my head, I think the flux should not be $0$ for at least some surfaces (a plane normal to the vectors, for example). I'm saying this because of my intuition about these concepts: consider said vector field representing some liquid moving, then If I place a grid (plane said above) I clearly have some liquid flowing through it, thus the flux should not be 0... Where am I wrong?","['vectors', 'multivariable-calculus']"
1533918,Finding arc length parametrization of a parabola,"Suppose we have a parabola of equation $y = x^2$ in a given Cartesian coordinate system. An obvious parameterization of it is the system $x = t$, $y = t^2$, but there are infinite other possibilities, the system $x = t^2$, $y = t^4$ is just another possible one, for example. Although it is easy to find parameterizations, finding one of constant unit-speed is not (at least I can not find one after many tries). None of the examples above satisfy it for example (as we can verify by computing the magnitudes of the tangent vectors). I would like to know an example (are there more than one?) of parameterization by arc length of this parabola, and also how was it was found. Suggestion of books on the subject are also welcome.","['calculus', 'analytic-geometry', 'parametric', 'geometry', 'vectors']"
1534012,The orthogonality interval of a Sturm-Liouville problem,"Consider the Sturm-Liouville problem $(p(x)y)'+(q(x)+λ r(x))y =0$ . How to specify the interval (limits of integration) of orthogonality of eigenfunctions $y_m$ with respect to weight function $r$ (in the two cases: when the boundary conditions are given and the case in which there are no boundary conditions)? Do the limits of integration depend on $p$ ? If yes, how? For example, why are eigenfunctions orthogonal only on interval $(-\infty, \infty)$ for the Hermite equation but they are orthogonal on interval $(0, \infty)$ only for the Laguerre equation? Is there a relation between the interval of convergence and the interval on which orthogonality holds? If we know one of them can we deduce the other?",['ordinary-differential-equations']
1534120,Largest rectangle not touching any rock in a square field,"You want to build a rectangular house with a maximal area. You are offered a square field of area 1, on which you plan to build the house. The problem is, there are $n$ rocks scattered in unknown locations throughout the field. The rocks are unmovable, and you cannot build on rocks. What is the largest area of a rectangle that you can build, in the worst case? Formally: let $S_n$ be a set of $n$ points in the unit square. Define $\textrm{MaxArea}(S_n)$ as the maximum area of an axis-parallel rectangle in the unit square that does not contain, in its interior, any point in $S$. Define: $$\textrm{MinMaxArea}(n) = \inf_{S_n} (\textrm{MaxArea}(S_n))$$ where the infimum is on all possible sets $S_n$ of $n$ points. What are good bounds on $\textrm{MinMaxArea}(n)$? EXAMPLE: In the picture below, the unit square is scaled to a 100-by-100 square. There are $n=100$ rocks. Apparently, the largest possible rectangle that does not contain any rocks in its interior is a rectangle such as ABCD, whose area is $.06\times .58$, which is approximately $\frac{1}{4\sqrt{n}}$, so: $$\textrm{MinMaxArea}(n) \leq \frac{1}{4\sqrt{n}}$$ Is there another arrangement of rocks in which the largest rectangle is smaller?","['rectangles', 'geometry', 'discrete-geometry', 'discrete-optimization']"
1534124,"Drawing 2 marbles from a box with 3 red, 3 purple, 5 green, and 7 blue marbles.","A box contains 3 red, 3 purple, 5 green, and 7 blue marbles. 2 marbles are selected from the box without replacement. What is the probability that you choose both marbles to be red or both marbles to be purple. So far, I have figured out (I think): $$\text{ Probability of both red  }= \frac{3}{\binom{18}{2}} = \frac{3}{(\frac{18!}{2!16!})} = \frac{3}{153}$$ Is this correct?","['probability', 'discrete-mathematics']"
1534138,Minimizing $f(x)=A^{\frac{tx-1}{x-1}} \left( c^x \frac{\Gamma(0.5+x)}{\sqrt{\pi}} \right)^{\frac{1-t}{x-1}}$ subject to the constraint,"Let $f(r)$ be a function defined as follows 
\begin{align}
f(x)=A^{\frac{tx-1}{x-1}} \left( c^x \frac{\Gamma(0.5+x)}{\sqrt{\pi}} \right)^{\frac{1-t}{x-1}}
\end{align} where $0 < A,c$ and $ t\in (0,1)$.
I want to solve 
\begin{align}
\min_{\frac{1}{t}<x}  f(x)
\end{align} My approach: Let $g(x)=\ln(f(x))$ then both $g(x)$ and $f(x)$ have the same minimum where
\begin{align}
g(x)=\frac{tx-1}{x-1} \ln(A)+\frac{(1-t)x}{x-1} \ln(c)+\frac{1-t}{x-1} \ln \left(\Gamma(0.5+x) \right)-\frac{1-t}{2(x-1)}\ln(\pi)
\end{align} and 
\begin{align}
&g'(x)=\\
&=\frac{1-t}{(x-1)^2} \ln(A)-\frac{1-t}{(x-1)^2} \ln(c)+(1-t)\frac{(x-1)\psi^{(0)}(x+0.5)-\log(\Gamma(x+0.5))}{(x-1)^2}+\frac{1-t}{2(x-1)^2}\ln(\pi)\\
&=\frac{1-t}{(x-1)^2} \left(\ln \left( \frac{ \sqrt{\pi} A}{c\Gamma(x+0.5)} \right)+ (x-1)\psi^{(0)}(x+0.5)\right)
\end{align} where $\psi(x)$ is the so called digamma function. So, this means we have to focus on 
\begin{align}
h(x)=\ln \left( \frac{ \sqrt{\pi} A}{c\Gamma(x+0.5)} \right)+ (x-1)\psi^{(0)}(x+0.5)
\end{align} for $\frac{1}{t} <x$. But how to solve $h(x)=0$ or say for what $x$ is $h(x)>0$ ??? If this impossible to do then the approximated solution is also fine? I also feel that there might be a simpler approach with out using derivative. Thank you for any help.","['gamma-function', 'polygamma', 'digamma-function', 'optimization', 'derivatives']"
1534235,Exercises with solutions on Elementary Measure Theory,"Where can I find a nice collection of solved exercises on Elementary Measure Theory? (Rings, algebras, $\sigma$-algebras, Borel sets, measures, outer measures, Lebesgue measure, measurable functions, Borel functions, etc.)","['reference-request', 'measure-theory']"
1534244,Is the zero matrix in reduced row echelon form?,"Is this matrix in reduced row echelon form? 
$3\times3$ matrix is: 0 0 0  
0 0 0  
0 0 0 I can say for other matrices but this one without 1s confuses me. Are $1$s optional in reduced row echelon form? I think they aren't. What do you think?",['matrices']
1534251,How can you use Green's relations to learn about a monoid?,"Without having ever formally learned any real monoid theory, I was recently pointed to Green's relations by a friend. It sounds like they're quite useful, and I get the impression they might do what character tables do for representation theory. However, after looking over the article and playing around with a few interesting monoids, I'm still not totally sure what I can learn about the monoid with Green's relations. Let's take this monoid, which I find interesting, as the focus of this post: $$M=\langle c,k \mid c^2=1, k^2=k,kck = kckckck \rangle$$ Here's the egg-box diagram I came up with: $$\begin{matrix}\{1,c\}\\
&\{(ck)^2,(ck)^3\}&\{(ck)^2c,(ck)^3c\}\\
&\{(kc)^2k,kck\}&\{(kc)^2,(kc)^3\}\\
&&&\{ck\}&\{ckc\}\\
&&&\{k\}&\{kc\}\end{matrix}$$ I'll try to break down the other relations later, but I hope this is enough to begin with for now. How can I learn about this monoid using Green's relations?","['abstract-algebra', 'monoid']"
1534292,$P(X\in B)=1$ when $X_n$ converges in distribution to $X$ for open and closed $B$,"Suppose that $X_n \rightarrow X$ in distribution. If $B$ is a closed Borel subset of $\mathbb{R}$,
and $P(X_n \in B) = 1$ for all $n$, then (a) Prove that $P(X \in B) = 1$. (b) Show that, however, if $B$ is open subset of $R$, then (a) is false. For part (b), consider $B = (0,1)$, $X_n := \frac{1}{n+1}, n = 1,2,...$ and $X = 0$. Clearly $X_n \rightarrow X$ in distribution, $P(X_n \in B) = 1$ for all $n$ but $P(X \in B) = 0$. Thus (a) does not hold. Is this correct? For part (a) please give me some hints.","['probability-theory', 'weak-convergence', 'probability', 'probability-distributions']"
1534296,Are there any limit questions which are easier to solve using methods other than l'Hopital's Rule?,"Are there any limit questions which are easier to solve using methods other than l'Hopital's Rule? It seems like for every limit that results in an indeterminate form, you may as well use lHopital's Rule rather than any of the methods that are taught prior to the rule, such as factoring, rationalizing, trig limits, etc. EDIT: These are great answers, thanks!","['limits-without-lhopital', 'calculus', 'limits']"
