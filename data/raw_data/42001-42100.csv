question_id,title,body,tags
415247,Prove that the limit exist,"Let  $T : H \rightarrow H$ is a linear continuous unitary ($T^*=T^{-1}$) operator, $H$ is a Hilbert space (not necessary). Suppose that $\forall h \in H \Rightarrow Th=h$ $T_n$ - a sequence of linear operators $T_n \underset{n\rightarrow \infty}{\longrightarrow}  T$, $|| T_n - T||\rightarrow 0$. So the sequence $T_n$ tends to $T$ in the norm and we have $\forall h \in H \ \ || T_n h - T h|| \leq || T_n - T|| \ ||h||\rightarrow 0$. Can we prove that there exists a limit of the sum $S_n= \frac{1}{n}\left( T_1 h + T_1 T_2 h + \dots + T_1 \dots T_n h \right)$ where $n \rightarrow \infty$?","['operator-theory', 'functional-analysis']"
415269,How to prove that the implicit function theorem implies the inverse function theorem?,"I can prove the converse of it, but I cannot do this one. Here is the problem: Prove that the implicit function theorem implies the inverse function theorem.","['multivariable-calculus', 'functional-analysis', 'analysis']"
415280,Evaluting $\int_{1}^{2} \frac{\tan^{-1} x}{\tan^{-1} \frac {1}{x^2-3x+3}} \operatorname dx$,$$\int_{1}^{2} \frac{\tan^{-1} x}{\tan^{-1} \frac {1}{x^2-3x+3}} dx$$ My try:: $\displaystyle  \int_{1}^{2} \frac{\tan^{-1} x}{\tan^{-1} \frac {1}{x^2-3x+3}} dx = \int_{1}^{2}\frac{\tan^{-1}x}{\tan^{-1}(x-1)-\tan^{-1}(x-2)}dx$ Now How can i solve after that. plz help me Thanks,"['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
415284,Tietze–Urysohn's lemma in $\mathbb{R}^n$,"Let $F_1$ and $F_0$ be closed subsets in $\mathbb{R}^n$, $F_0\cap F_1=\varnothing$. How to build a $C^{\infty}$- function $f:\mathbb{R}^n\to \mathbb{R}$, such that $f|_{F_1}=1$, $f|_{F_0}=0$ and $0<f(x)<1$ for $x\notin F_1\cup F_2$? The only useful fact I know is Tietze–Urysohn's lemma, which states that only continuous function exists. Could you give me any hints?","['general-topology', 'manifolds', 'analysis']"
415286,A simple question on simplex,"Let $S \subset \mathbb{R}^n$ be a $n$-simplex. Let $a_0,\dots, a_n$ be the vertices of $S$. Define $L_i\subset \mathbb{R}^n$ be the hyperplane which touches $S$ at $a_i$ and parallel to the convex hull of $\{a_1,\dots,a_n\}\setminus \{a_i\}$. How can I see that he region $B$ bounded by $L_0,\dots,L_n$ is a simplex similar to $S$?",['geometry']
415287,Measure of $\{t:B_t\in E\}$ for some null set $E$.,"I am wondering if the following result can be found in any textbook or if you have a proof of it. When $E$ is a null set and $B_t$ is the Brownian motion, we have almost surely :
  $$\mathcal{L}^1\{t:B_t\in E\}=0.$$ Here, I denoted by $\mathcal{L}^1$ the $1$-dimensional Lebesgue measure.
This result is well known when $E=\{x\}$ is any singleton.","['probability-theory', 'stochastic-processes', 'measure-theory', 'brownian-motion']"
415296,Need help in integrating $\int_{0}^{2\pi}\int_{0}^{2\pi}\frac{\cos t-\sin s - \cos t \sin s}{\sqrt{3+2(\cos t - \sin s - \cos t \sin s)}^3}dtds$,This is not a homework problem. I was trying to use the Gaussian linking integral to compute the linking number of the Hopf link and I get stuck at: $$\int_{0}^{2\pi}\int_{0}^{2\pi}\frac{\cos t-\sin s - \cos t \sin s}{\sqrt{3+2(\cos t - \sin s - \cos t \sin s)}^3}dtds$$ Can anyone suggest some help?,"['multivariable-calculus', 'calculus', 'integration']"
415304,How to simplify $\frac{1-\frac{1-x}{1-2x}}{1-2\frac{1-x}{1-2x}}$?,"$$\frac{1-\frac{1-x}{1-2x}}{1-2\frac{1-x}{1-2x}}$$ I have been staring at it for ages and know that it simplifies to $x$, but have been unable to make any significant progress. I have tried doing $(\frac{1-x}{1-2x})(\frac{1+2x}{1+2x})$ but that doesn't help as it leaves $\frac{1+x-2x^2}{1-4x^2}$ any ideas?",['algebra-precalculus']
415327,Does this complex remain exact after I restrict the maps?,"$R$ is a commutative ring with unity. Assume you have two matrices $A:R^n\rightarrow R^m$ and $B:R^m\rightarrow R^n$ such that they form an exact complex in the obvious way, i.e., $$\cdots\rightarrow R^n\stackrel{A}\rightarrow R^m\stackrel{B}\rightarrow R^n\rightarrow\cdots.$$ Call $S$ the subring of $R$ generated by the entries of $A$ and $B$ (I mean $S=\mathbb{Z}/n\mathbb{Z}[a_{ij},b_{ij}]$, where $n$ is the characteristic of $R$), and restrict the matrices to the ring $S$. The restricted maps still form a complex. Is it exact? I'm pretty sure it is not, but I cannot find any counterexample. Any help?","['modules', 'matrices', 'ring-theory', 'commutative-algebra']"
415360,Angle between two lines on parametric surface,"I need to find what angle is between the lines $u=-v$ and $u=v$ on the surface:
$$r(u,v)=(u\cos(v), u\sin(v), 2v)$$
The only thing that comes to my mind is to put both line equations to the surface equation:
$$ \begin{align*}
r_1(v)&=(-v\cos(v),-v\sin(v), 2v)\\
r_2(v)&=(v\cos(v), v\sin(v), 2v)
\end{align*}$$
And then I need to find the angle between two curves at point $(0, 0, 0)$ because $u=0, v=0$. Am I thinking right? Thanks for every answer.",['differential-geometry']
415362,Change of variables for stochastic integral,"Let $H$ be a previsible locally bounded process, and let $X$ be a continuous local
  martingale. If $T$ is a stopping time and $X^T=(X_{t+T}-X_{T},t\geq 0) $ then 
  $$\int_T^{t+T}H_s.dX_s=\int_0^tH_{T+u}dX_u^{T}  $$ I'll be grateful for any help in details (step by step ). What i did : $$\int_T^{t+T}H_s.dX_s=\int_O^{t}H_{s+T}.dX_{s+T} $$
or we know that $$\int_0^{t}H_s.dX_s=\lim_{n\to \infty}\sum_{i=0}^{P_n-1 }H_{t^n_i}(X_{t^n_{i+1}}-X_{t^n_i}).$$
Best regards, Educ","['stochastic-integrals', 'integration']"
415364,Limit calculation using Riemann integral,"My task is to calculate limit: $$\lim_{n \rightarrow \infty} \sqrt[n^2]{ \frac{(n+1)^{n+1}(n+2)^{n+2}\cdots(n+n)^{n+n}}{n^{n+1}n^{n+2}\cdots n^{n+n}} }$$I denoted that limit as $a_n$. So:
$$\log a_n=\frac{1}{n^2} \left (  (n+1)\log \left (1+\frac{1}{n} \right )+\cdots+(n+n)\log \left (1+\frac{n}{n} \right )\right )=$$$$=\cdots=\frac{1}{n} \left ( \sum_{k=1}^n\log(1+\frac{k}{n})+\sum_{k=1}^n\frac{k}{n}\log(1+\frac{k}{n}) \right )$$ The only (quite crucial however) problem I've got is the term $\frac{1}{n}$ before the above. I know how to calculate parenthesis:$$ \lim_{n \rightarrow \infty}\left ( \sum_{k=1}^n\log(1+\frac{k}{n})+\sum_{k=1}^n\frac{k}{n}\log(1+\frac{k}{n}) \right )=$$$$\int_0^1\log(1+x)dx+\int_0^1x\log(1+x)dx=\cdots$$But I have no idea what $\frac{1}{n} $does. Any hints? Thanks in advance.","['integration', 'analysis']"
415376,Proving derived sets are closed,"I am following a proof of the statement The derived set(the set of accumulation points) $A'$ of an arbitrary
  subset $A$ of $\mathbb{R}^2$ is closed. in a book. It starts with Let $q$ be a limit point of $A'$. If it is proved that q $\in A'$, then the proof is done. Let $G_q$ be the open set containing $q$. Since $q$ is a limit point of $A'$,$G_q$ contains at least one point $r\in A'$ different from $q$. But  $G_q$ is an open set containing $r\in A'$; (Up to this I understood) hence $G_q$ contains infinitely many points of $A$ (How? I did not get this.) So there exist $a \in A$ such that $a \neq q,a \neq r$ and $a \in G_q$.
That is,each open set containing $q$ contains infinitely many points of $A$. Hence $q \in A'$. Can you help me out.",['general-topology']
415380,How to find the limit without L'Hospital?,"$$\lim_{x\rightarrow 1} \frac{x^m-1}{x^n-1}$$ I found this in a book (recommended by the professor) without solutions or hints. My problem is that I can't find definitions about this kind of problems and
I have no idea how to start, any kind of help would be great. So far I've been dealing with ""$\lim_{x\rightarrow ∞}$"" only.
Also without L'Hospital, because we haven't had this in lecture.","['calculus', 'limits']"
415382,A strictly positive operator is invertible,"Suppose that $H$ is an Hilbert space, and $T: H \to H$ is a self-adjoint strictly positive operator (i.e. $\langle Tx,x\rangle > 0$ for all $x \neq 0$). How do I show that this operator is invertible? For example, I want to show that $\langle Tx , x\rangle$ is bounded below by some positive constant (and then I am happy, I know the rest). Thank you,
Sasha","['c-star-algebras', 'linear-algebra', 'hilbert-spaces', 'operator-theory']"
415384,Domain of definition of a rational automorphism,"I am a bit confused about the following problem from Liu's book on Algebraic geometry.
Let $X= \mathbb{P}^1_\mathbb{Z}$ and let $f: X_\mathbb{Q} \rightarrow X_\mathbb{Q}$ be an automorphism corresponding to a matrix of $PGL_2 (\mathbb{Q})$. Determine the domain of definition of the rational map $X \rightarrow X$ induced by f. My question is: How does f induce a rational map? I thought that, by definition , a rational map is defined on an open set. Should I just ""clear the denominators"" ? Second - how do I determine the domain of definition? My intuition says defined everywhere, but I am probably wrong.",['algebraic-geometry']
415388,"Prove that $n! < n^n $ where n >1 and is an integer , why do some people say my solution is wrong?","Prove that $n! < n^n $ where n >1 and is an integer.
Lets skip the base case cause its trivial. Assume that:
$$ 
k! < k^k =
$$
Inductive step:
$$(k+1)! < (k+1)^{k+1} =$$
$$(k)!(k+1) < (k+1)^k (k+1) =$$
$$k! < (k+1)^k$$ why do some of my classmates say the way i solved it is wrong? am i really wrong?","['induction', 'calculus', 'discrete-mathematics']"
415399,Largest domain on which $z^{i}$ is analytic.,Can anyone help me with this question: What is the largest domain $D$ on which the function $f(z)=z^{i}$ is analytic?,"['analyticity', 'complex-analysis']"
415406,Sampling labeled items on a conveyor belts,"I have items on a moving conveyor belt. Every item has a label with a number that goes from $1$ to $N$; on the conveyor belt there are more than $N$ items. I have a camera above the items on the belt, the camera is in a fixed position; an example with $N=8$ (where * is the camera): *
...7 6 5 4 3 2 1 8 7 6 5 4 3 2 1 8 7 6 5 4 3 2...
------------------------------------------------- The camera knows when it can take a picture of the item because it is triggered by the presence of the item. The camera can't see the label on the items. It is assumed that the labels are ordered, there are no gaps, there are no duplicated labels in the wrong positions. For quality control purpose, the camera should take pictures of the items but it is not fast enough to take one picture for every item and so basically it can take the picture of one item, then skips the following $M$ items, then take the picture of one item, then skips the following $M$ items and so on; $M\gt0$ is a characteristic parameter of the camera in use. My goal is to find a sampling method in order to have pictures evenly distributed among the $N$ labels and to skip the least number of items. I have tried to solve the problem in this way: I compute a prime factorization of $N$; then I choose a prime $P$ that does not belong to the prime factorization of $N$ and $P\gt M+1$. Then the sampling goes in this way: the camera takes the picture of one item, then skips the following $P-1$ items, then takes the picture of one item, then skips the following $P-1$ items and so on. For example with $N=10$, $M=7$, my solution is $P=11$. I made some simulations of the above sampling method and it seems to meet my goal, but I would like to know whether it can be proved to be correct and/or optimized.","['statistics', 'applications', 'sampling', 'prime-numbers']"
415426,Prove that $T$ is an orthogonal projection,Let $T$ be a linear operator on a finite-dimensional inner product space $V$. Suppose that $T$ is a projection such that $\|T(x)\| \le \|x\|$ for $x \in V$. Prove that $T$ is an orthogonal projection. I can't understand well. The definition of orthogonal operator is $\|T(x)\| = \|x\|$. But why that $\|T(x)\| \le \|x\|$ for $x \in V$ means orthogonal projection?,"['linear-algebra', 'inner-products', 'operator-theory']"
415432,Why don't we include $\pm\infty$ in $\mathbb R$?,"Why don't we include $\pm\infty$ in $\mathbb R$? If we do so, many equations will got real solution (e.g. $2^x=0$), and $\mathbb R$ will be much more complete. Why don't we do so? Thank you.",['analysis']
415452,Understanding the proof for: $d(f^*\omega)\overset{!}{=}f^*(d\omega)$,"Consider this Proposition: Let $U\subset\mathbb{R}^n$ and $V\subset\mathbb{R}^n$ be open sets and $\phi:U\to V$ be differentiable. For all $k\in\mathbb{N}_0$ and $\omega\in \Lambda^k(V)$ it is true that $$d(\phi^*\omega)=\phi^*(d\omega)$$ I am trying to understand its prove. But there are some steps I do not understand. Here are the first lines of the Proof: At first let $f\in \mathcal{C}^\infty (V)$ be a differentialform of degree $0$. Then $\phi^*(f)=f\circ\phi$. Hence
\begin{eqnarray*}
d(\phi^*(f))
&=&d(f\circ\phi)\\
&=&\sum_{j=1}^{n}\frac{\partial(f\circ\phi)}{\partial x_j}dx_j\\
&\overset{?}{=}&\sum_{i,j}\frac{\partial f}{\partial y_i}\circ\phi(\frac{\partial (\phi_i)}{\partial x_j}dx_j)\\
&=&\sum_{i=1}^{m}\frac{\partial f\circ\phi}{\partial y_i}d\phi_i\\
\end{eqnarray*} I marked the position I don't understand with a question mark. What exactly happens here?","['manifolds', 'differential-geometry', 'analysis']"
415456,Finite surjective morphism to normal affine variety is open,"We have a finite surjective morphism  $\phi: X \to Y$ (it means that $k[X]$ is a finitely generated module over $\phi^*(k[Y])$), $Y$ is normal (it means that $k[Y]$ is normal). Why is it open in Zariski topology? (Image of open set is open?)","['commutative-algebra', 'algebraic-geometry']"
415467,How to solve the differential equation for the motion equation of a body in a gravitational field from one fixed source,"I want to develop the motion equation of a body in a classic gravitational field ($F=\frac{Gm_1m_2}{r^2}$). Starting by creating the lagrangian of a body under gravitational force, in polar coordinates. The speed in direction $\hat{r}$ is $\dot{r}$ and the speed in direction $\hat{\theta}$ is $r\dot{\theta}$. So the kinetic energy of the body is $K=\frac{m}{2}\left(\dot{r}^2+r^2\dot{\theta}^2\right)$ and the potential energy is $U=-\frac{GMm}{r}$. $M$ is the mass of the source generating the gravitational field (a star), and $m$ is the mass of the body (a planet). Creating the lagrangian we get: $$\mathcal{L}=K-U=\frac{m}{2}\left(\dot{r}^2+r^2\dot{\theta}^2\right)+\frac{GMm}{r}$$ Writing down the Euler–Lagrange equation ($\frac{{\partial}\mathcal{L}}{{\partial}q}=\frac{d}{dt}\left(\frac{{\partial}\mathcal{L}}{{\partial}\dot{q}}\right)$)we get
$$mr^2\ddot{\theta}=0$$
$$\dot{\theta}=\frac{p_{\theta}}{mr^2}$$ $p_\theta$ is the angular momentum which is conserved $$\theta=\frac{p_{\theta}}{mr^2}t+\theta_0$$ $$m\ddot{r}=mr\dot{\theta}^2-\frac{GMm}{r^2}$$ $$\ddot{r}=\frac{p_{\theta}^2}{m^2}r^{-3}-GMr^{-2}$$ How do I solve the differential equation?","['ordinary-differential-equations', 'physics']"
415477,The value of the $\lim_{n\rightarrow \infty}\frac{1}{n}\sum_{k=1}^{n}\frac{\sqrt[k]{k!}}{k}$,What is the value of  $$\lim_{n\rightarrow \infty}\frac{1}{n}\sum_{k=1}^{n}\frac{\sqrt[k]{k!}}{k}?$$,"['closed-form', 'limits']"
415483,Equivalent conditions for a measurable function,"I am reading Stein and Shakarchi volume 3 and on page 28 they give the definition of a Lebesgue  measurable (real - valued) function $f: \Bbb{R}^d \to \Bbb{R}$ to be on in which for any $a \in \Bbb{R}$, $f^{-1}(-\infty,a)$ is Lebesgue measurable. Now I am wondering it this is equivalent to the following conditions: $f$ is a Lebesgue measurable function if for any Lebesgue measurable set $E$, $f^{-1}(E)$ is Lebesgue measurable For almost every $a \in \Bbb{R}$, $f^{-1}\left((-\infty,a)\right)$ is Lebesgue measurable. My question is: Are these equivalent to the definition given in Stein and Shakarchi?",['measure-theory']
415491,Is this Euler-Mascheroni constant calculation from double integrals a true identity?,"A prime number is a number that is only divisible by itself and one, that is the number of divisors of a prime number is equal to $2$. One way to illustrate this is to plot a matrix such that if the column index (1,2,3,...) divides the row index (1,2,3,...) then a black square is drawn at that column and row index intersection, like this: As a matrix this has the definition in Mathematica: MatrixForm[Table[Table[If[Mod[n, k] == 0, 1, 0 ], {k, 1, 12}], {n, 1, 12}]] which gives the table below: $$\small \left(
\begin{array}{cccccccccccc}
 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & 1 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
 1 & 1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
 1 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
 1 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1
\end{array}
\right)$$ The number of divisors of n, also called tau, is the row sums of this matrix and starts: 1, 2, 2, 3, 2, 4, 2, 4, 3, 4, 2, 6 ... So at a row equal to a prime number there are only two black dots and the row sums in the above matrix are equal to 2. To find the ordinary generating function of the number of divisors of n we consider table $a$ times $b$, or row index times column index: MatrixForm[Table[Table[a*b, {b, 1, 12}], {a, 1, 12}]] $$\small \left(
\begin{array}{cccccccccccc}
 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\
 2 & 4 & 6 & 8 & 10 & 12 & 14 & 16 & 18 & 20 & 22 & 24 \\
 3 & 6 & 9 & 12 & 15 & 18 & 21 & 24 & 27 & 30 & 33 & 36 \\
 4 & 8 & 12 & 16 & 20 & 24 & 28 & 32 & 36 & 40 & 44 & 48 \\
 5 & 10 & 15 & 20 & 25 & 30 & 35 & 40 & 45 & 50 & 55 & 60 \\
 6 & 12 & 18 & 24 & 30 & 36 & 42 & 48 & 54 & 60 & 66 & 72 \\
 7 & 14 & 21 & 28 & 35 & 42 & 49 & 56 & 63 & 70 & 77 & 84 \\
 8 & 16 & 24 & 32 & 40 & 48 & 56 & 64 & 72 & 80 & 88 & 96 \\
 9 & 18 & 27 & 36 & 45 & 54 & 63 & 72 & 81 & 90 & 99 & 108 \\
 10 & 20 & 30 & 40 & 50 & 60 & 70 & 80 & 90 & 100 & 110 & 120 \\
 11 & 22 & 33 & 44 & 55 & 66 & 77 & 88 & 99 & 110 & 121 & 132 \\
 12 & 24 & 36 & 48 & 60 & 72 & 84 & 96 & 108 & 120 & 132 & 144
\end{array}
\right)$$ By stretching out this table in the downward direction we get this table: MatrixForm[Table[Table[If[Mod[a, b] == 0, a, 0], {b, 1, 12}], {a, 1, 12}]] $$\small \left(
\begin{array}{cccccccccccc}
 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 2 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 3 & 0 & 3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 4 & 4 & 0 & 4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 5 & 0 & 0 & 0 & 5 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 6 & 6 & 6 & 0 & 0 & 6 & 0 & 0 & 0 & 0 & 0 & 0 \\
 7 & 0 & 0 & 0 & 0 & 0 & 7 & 0 & 0 & 0 & 0 & 0 \\
 8 & 8 & 0 & 8 & 0 & 0 & 0 & 8 & 0 & 0 & 0 & 0 \\
 9 & 0 & 9 & 0 & 0 & 0 & 0 & 0 & 9 & 0 & 0 & 0 \\
 10 & 10 & 0 & 0 & 10 & 0 & 0 & 0 & 0 & 10 & 0 & 0 \\
 11 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 11 & 0 \\
 12 & 12 & 12 & 12 & 0 & 12 & 0 & 0 & 0 & 0 & 0 & 12
\end{array}
\right)$$ This looks very much like the divisorplot at the beginning.
To find the generating function for the number of divisors of $n$ we then introduce the variable $x$ like this: Clear[x]
MatrixForm[
 Table[Table[If[Mod[a, b] == 0, x^a, 0], {b, 1, 12}], {a, 1, 12}]] $$\small \left(
\begin{array}{cccccccccccc}
 x & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 x^2 & x^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 x^3 & 0 & x^3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 x^4 & x^4 & 0 & x^4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 x^5 & 0 & 0 & 0 & x^5 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 x^6 & x^6 & x^6 & 0 & 0 & x^6 & 0 & 0 & 0 & 0 & 0 & 0 \\
 x^7 & 0 & 0 & 0 & 0 & 0 & x^7 & 0 & 0 & 0 & 0 & 0 \\
 x^8 & x^8 & 0 & x^8 & 0 & 0 & 0 & x^8 & 0 & 0 & 0 & 0 \\
 x^9 & 0 & x^9 & 0 & 0 & 0 & 0 & 0 & x^9 & 0 & 0 & 0 \\
 x^{10} & x^{10} & 0 & 0 & x^{10} & 0 & 0 & 0 & 0 & x^{10} & 0 & 0 \\
 x^{11} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & x^{11} & 0 \\
 x^{12} & x^{12} & x^{12} & x^{12} & 0 & x^{12} & 0 & 0 & 0 & 0 & 0 & x^{12}
\end{array}
\right)$$ The generating function for the number of divisors of $n$ is then the infinite double sum which is the sum of the infinite matrix above: $$\sum\limits_{n=1}^{\infty} d(n)x^{n} = \sum\limits_{a=1}^{\infty} \sum\limits_{b=1}^{\infty} x^{a b}$$ 
$$= 1\, x^{1} + 2\, x^{2} +  2\, x^{3} +  3\, x^{4} +  2\, x^{5} +  4\, x^{6} +  2\, x^{7} +  4\, x^{8} +  3\, x^{9} +  4\, x^{10} + 2\, x^{11} +  6\, x^{12} +  ...$$ where $d(n)$ = the number of divisors of $n$ A sum $\sum$ is a sum of distances - usually under a function, while an integral $\int$ is a sum of areas under a function, and a double integral $\int \int$ is a sum of volumes and so on... Often in mathematics one wants to compare a sum to an integral, or at least so I have heard. In this case we have a double sum: $$\sum\limits_{a=1}^{\infty} \sum\limits_{b=1}^{\infty} x^{a b}$$ Considering the double integral instead we have: $$\int\limits_{a=1}^{\infty} \int\limits_{b=1}^{\infty} x^{a b}$$ As suggested by Chris's wise sister in the chat room about two weeks ago, the similar triple integral evaluates faster at $x=\frac{1}{e}$: According to Mathematica: Integrate[Integrate[1/Exp[1]^(a*b), {a, 1, Infinity}], {b, 1, Infinity}] the double integral then evaluates to: $$\int\limits_{a=1}^{\infty} \int\limits_{b=1}^{\infty} \frac{1}{e^{a b}}=-\text{Ei}(-1)$$ Or as Mathematica calls it, the exponential integral. Reading about the exponential integral in Wikipedia that passing a logarithm as argument to it one gets the logarithmic integral and remembering that the logarithmic integral has to do with the prime number theorem, I did some experimenting in Mathematica with the program: Monitor[MatrixForm[
  Table[Table[
    Integrate[
      Integrate[Exp[a*b], {a, k, Infinity}, 
       GenerateConditions -> False], {b, 0, n}, 
      GenerateConditions -> False] - 
     Integrate[
      Integrate[Exp[a*b], {a, 0, n}, GenerateConditions -> False], {b,
        k, Infinity}, GenerateConditions -> False], {n, 1, 4}], {k, 0,
     4}]], k] and came to the conclusion that for $n \gt 0$ and $k \geq 0$, this appears to be an identity: $$\gamma = \int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db-\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db$$ where $\gamma$ = Euler-Mascheroni constant , approximately equal to 0.57721566490153286060651209... My question is: Why is this identity true? I also noted that: For $k \lt 0$ and $n \lt 0$, it appears to be true that: $$\gamma = \Re(\int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db-\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db)$$ $$-\pi = \Im(\int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db-\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db)$$ But this is probably less interesting. As a starting point I believe it has something to do with the fact: -Integrate[Integrate[Exp[a*b], {a, 0, 1}, GenerateConditions -> False], {b, 0, 
   Infinity}, GenerateConditions -> False] $$\gamma = -\int_0^{\infty } \left(\int_0^1 e^{a b} \, da\right) \, db$$ and that it somehow can be separated out from both of the double integrals:
$$\int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db$$
$$\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db$$ depending on the values of $n$ and $k$ since: Monitor[MatrixForm[
  Table[Table[
    Integrate[
      Integrate[Exp[a*b], {a, k, Infinity}, 
       GenerateConditions -> False], {b, 0, n}, 
      GenerateConditions -> False] - 
     0*Integrate[
       Integrate[Exp[a*b], {a, 0, n}, 
        GenerateConditions -> False], {b, k, Infinity}, 
       GenerateConditions -> False], {n, 1, 4}], {k, 0, 4}]], k]
Monitor[MatrixForm[
  Table[Table[
    0*Integrate[
       Integrate[Exp[a*b], {a, k, Infinity}, 
        GenerateConditions -> False], {b, 0, n}, 
       GenerateConditions -> False] - 
     Integrate[
      Integrate[Exp[a*b], {a, 0, n}, GenerateConditions -> False], {b,
        k, Infinity}, GenerateConditions -> False], {n, 1, 4}], {k, 0,
     4}]], k] for $n \geq 1$ and $k \geq 0$ we have for the first double integral: $$\int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db$$ (for $n=1,2,3,4...$ and $k=0,1,2,3,4...$): $$\small \left(
\begin{array}{cccc}
 0 & -\log (2) & -\log (3) & -\log (4) \\
 \gamma -\text{Ei}(1) & \gamma -\text{Ei}(2) & \gamma -\text{Ei}(3) & \gamma -\text{Ei}(4) \\
 -\text{Ei}(2)+\gamma +\log (2) & -\text{Ei}(4)+\gamma +\log (2) & -\text{Ei}(6)+\gamma +\log (2) & -\text{Ei}(8)+\gamma +\log (2) \\
 -\text{Ei}(3)+\gamma +\log (3) & -\text{Ei}(6)+\gamma +\log (3) & -\text{Ei}(9)+\gamma +\log (3) & -\text{Ei}(12)+\gamma +\log (3) \\
 -\text{Ei}(4)+\gamma +\log (4) & -\text{Ei}(8)+\gamma +\log (4) & -\text{Ei}(12)+\gamma +\log (4) & -\text{Ei}(16)+\gamma +\log (4)
\end{array}
\right)$$ and for the second double integral: $$-\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db)$$ (for $n=1,2,3,4...$ and $k=0,1,2,3,4...$): $$\small \left(
\begin{array}{cccc}
 \gamma  & \gamma +\log (2) & \gamma +\log (3) & \gamma +\log (4) \\
 \text{Ei}(1) & \text{Ei}(2) & \text{Ei}(3) & \text{Ei}(4) \\
 \text{Ei}(2)-\log (2) & \text{Ei}(4)-\log (2) & \text{Ei}(6)-\log (2) & \text{Ei}(8)-\log (2) \\
 \text{Ei}(3)-\log (3) & \text{Ei}(6)-\log (3) & \text{Ei}(9)-\log (3) & \text{Ei}(12)-\log (3) \\
 \text{Ei}(4)-\log (4) & \text{Ei}(8)-\log (4) & \text{Ei}(12)-\log (4) & \text{Ei}(16)-\log (4)
\end{array}
\right)$$ I was not entirely clear in the use of integration indices $n$ and $k$. Usually $n$ is the row index and $k$ is the column index, while in the matrices above they have been permuted. Edit 10.6.2013: I should have used the 'PrincipalValue' command instead of the 'GenerateConditions' command, like this: t = 1;
Table[Integrate[
  Integrate[Exp[a*b] + 1/b/t, {a, 0, t}], {b, -Infinity, n}, 
  PrincipalValue -> True], {n, 1, 4}]
Table[Integrate[
  Integrate[Exp[a*b] + 1/b/t, {a, 0, t}], {b, -Infinity, Log[n]}, 
  PrincipalValue -> True], {n, 1, 4}] $$\text{Ei}(n \cdot t) = \int_{-\infty }^n \left(\int_0^t \left(e^{a b}+\frac{1}{b \cdot t}\right) \, da\right) \, db$$ And the relation from Wikipedia I wanted explore is:
$$\text{Ei}(\log (n)) = \text{li}(n)$$ Edit 11.6.2013: This allows us to write: X=5;
Monitor[Table[
  Integrate[
   Integrate[Exp[a*b] + n/b, {a, 0, 1/n}], {b, -Infinity, Log[X]}, 
   PrincipalValue -> True], {n, 1, 6}], n] $$\text{li}(X^{\frac{1}{n}}) = \int_{-\infty }^{\text{Log}[X]} \left(\int_0^{\frac{1}{n}} \left(e^{a b}+\frac{n}{b}\right) \, da\right) \, db$$ Which simplifies to: X = 5;
Monitor[Table[
  Integrate[E^(b/n)/b, {b, -Infinity, Log[X]}, 
   PrincipalValue -> True], {n, 1, 6}], n] $$\text{li}(X^{\frac{1}{n}}) = \int_{-\infty }^{\text{Log}[X]} \frac{e^{b/n}}{b} \, db$$","['multivariable-calculus', 'calculus', 'integration', 'number-theory', 'euler-mascheroni-constant']"
415511,about transpose of matrix,"Let $A$ be a real $n\times n$ matrix with $A^{T}=\alpha_{0}I+\alpha_{1}A$, where $\alpha_{0}$ and $\alpha_{1}$ are real numbers. Show that either $A^{T}=\pm A$ or $A=\lambda I$ for some real number $\lambda$.
Can someone give me hint?","['matrices', 'linear-algebra']"
415512,Is $S=\sum_{r=1}^\infty \tan^{-1}\frac{2r}{2+r^2+r^4}$ finite?,"Problem :
If  $$S=\sum_{r=1}^\infty \tan^{-1}\left(\frac{2r}{2+r^2+r^4}\right)$$ Then find S ?? Solution : I know that $\tan^{-1} x + \tan^{-1} y= \tan^{-1} \frac {x +y}  {1-xy} $ But I have no idea how to such complicated question with it.","['sequences-and-series', 'trigonometry', 'calculus']"
415513,How many sections of a vector bundle send a point outside a divisor?,"Let $\pi:E\to X$ be a holomorphic vector bundle on a complex algebraic variety $X$, and assume $E$ has nonzero global sections; fix a divisor $D\subset E$ and a point $P\in X$. I have the vague feeling that the following question has affirmative answer, but I am not able to prove it. Q .  Does the generic section $s\in H^0(X,E)$ satisfy
  $s(P)\notin D$? In other words: if we fix the point and the divisor, we should be able to send the point outside the divisor with ""almost all"" the sections. I just tried to reason in the opposite direction by showing that 
$$V:=\{s\in H^0(X,E)\,|\,s(P)\in D\}$$
is not the whole of $H^0(X,E)$. But how to compute $\dim V$, for instance? Thanks for any suggestions. Edit . Leu us assume, also (see comments below), that $E$ is base-point free and no fiber of $\pi$ is contained in a divisor.","['algebraic-geometry', 'vector-bundles']"
415535,Differential Equation : method of Constant variation,"I have to solve $y'' + 4y = 5\cos(2x)$. I solved first the homogenous equation and I find $y_H=C_1\cos(2x)+C_2\sin(2x)$. Then i can do two methods : 1) The undetermined coefficients: I find my particular solution $y_p =\frac{5}{4}x\sin(2x)$, which is the correct solution. 2) The constant variation: I suppose $y_p=C_1(x)\cos(2x) + C_2(x)\sin(2x)$, I compute $y_p'$ and $y_p''$ then I apply the method and now I find that $C_1(x)=-\frac{5}{16}\cos(4x)$ and $C_2(x)=\frac{1}{2}x + \frac{1}{8}\sin(4x)$. Then my $y_p$ is different. Can someone show me how to apply the constant variation step by step to this differential, because I really tried to see why I get a wrong result and I don't get it. EDIT : My work for method 2 : $y_p = C_1(x)cos(2x) + C_2(x)sin(2x)$ $y_p'=C_1'cos(2x)+C_2'sin(2x)-2C_1sin(2x)+2C_2cos(2x)$ I deliberately choose that $C_1'\cos(2x)+C_2'sin(2x)=0$ $y_p''=-2C_1'sin(2x)+2C_2'cos(2x)-4C_1cos(2x)-4C_2sin(2x)$ Then i get $C_1'\cos(2x)+C_2'sin(2x)=0$ and $-2C_1'sin(2x)+2C_2'cos(2x)=5cos(2x)$ which is a simple system. $C_1'=-5/2sin(2x)cos(2x)$ $C_2'=5/2cos(2x)^2$ I integrate and find $C_1=5/16cos(4x)$ and $C_2=5/4x + 5/16 sin(4x)$. Then i replace it in my particular solution which gives me $y_p=5/16cos(4x)cos(2x)+(5/4x + 5/16 sin(4x))sin(2x)$. Hope it's more clear. Thank you.","['ordinary-differential-equations', 'integration']"
415536,How do I solve such logarithm,"I understand that $\log_b n = x \iff b^x = n$ But all examples I see is with values that I naturally know how to calculate (like $2^x = 8, x=3$) What if I don't? For example, how do I solve for $x$ when: $$\log_{1.03} 2 = x\quad ?$$ $$\log_{8} 33 = x\quad ?$$","['logarithms', 'functions']"
415570,Limit of $\cos(x)/x$ as $x$ approaches $0$,"As the title says, I want to show that the limit of $$\lim_{x\to 0} \frac{\cos(x)}{x}$$ doesn't exist. Now for that I'd like to show in a formally correct way that $$\lim_{x\to 0^+} \frac{\cos(x)}{x} = +\infty$$ I'm sure this is right since $\displaystyle\lim_{x\to 0^+} \cos(x) = 1$ and $\displaystyle\lim_{x\to 0^+} x = 0$, but since $\displaystyle\lim_{x\to 0^+} x = 0$ I can't just say: $$\lim_{x\to 0^+} \frac{\cos(x)}{x} = \frac{1}{\displaystyle\lim_{x\to 0^+} x}$$ Things I tried: expand the fraction and use L'Hospital's rule (This didn't seem to yield results even though I tried quite a few things, should it? If it does, should it always work? It worked for similar problems) and going by the definition of the limit which didn't work for me either. I'm grateful for any hints for doing this problem and similar problems especially.","['calculus', 'limits']"
415594,Evaluating $\int_0^{2 \pi} \frac {\cos 2 \theta}{1 -2a \cos \theta +a^2}$,"In order to evaluate $\int_0^{2 \pi}  \frac {\cos 2 \theta}{1 -2a \cos \theta +a^2}$ we can define 
$$
f(z) := \frac 1 z \cdot \frac { (z^2+z^{-2})/2}{1-2a( \frac {z+z^{-1}} 2) +a^2}
$$ I have $0 < a <1$ which gives singular points in $0$ and $a$ which lie in the unit circle. I want to calculate the residues in those points to use the Residue-formula. How can I evaluate the residues here ?",['complex-analysis']
415600,"In Levenberg–Marquardt, is forcing the Hessian to be positive definite OK?","I am often doing parameter estimation using the Levenberg-Marquardt method, which involves solving the following linear system at each step: $$(H + \lambda I) \delta = r_{i}$$ where $H$ is a square Hessian matrix, $I$ is an identity matrix, $r_{i}$ is residual vector (at $i$ -th iteration), $\lambda$ is a damping factor, $\delta$ is improvement step to compute. The $\lambda$ value is decreased when the step improved solution (reduced objective value) and increased otherwise. The $\lambda$ parameter can allow solving ill-posed problems as it makes the Hessian positive definite. In most cases $H$ is positive definite by itself, but sometimes not. What to do in that case? Should I stop the iteration completely or increase lambda until $H$ becomes positive definite and solve the problem normally?","['optimization', 'linear-algebra', 'least-squares', 'numerical-optimization']"
415611,Proving when Gram's determinant is equal to zero [duplicate],"This question already has answers here : Proof: $\det\pmatrix{\langle v_i , v_j \rangle}\neq0$ $\iff \{v_1,\dots,v_n\}~\text{l.i.}$ (4 answers) Closed 11 years ago . Prove that Gram's determinant $G(x_1,\dots, x_n)=0$ if and only if
  $x_1, \dots, x_k$ are linearly dependent. So I know that $G(x_1,\dots, x_n)=\det \begin{vmatrix} \xi( x_1,x_1) & \xi( x_1,x_2) &\dots & \xi( x_1,x_n)\\
 \xi( x_2,x_1) & \xi( x_2,x_2) &\dots & \xi( x_2,x_n)\\
\vdots&\vdots&\ddots&\vdots\\
 \xi( x_n,x_1) & \xi( x_n,x_2) &\dots & \xi( x_n,x_n)\end{vmatrix}$ (where $\xi$ denotes an inner product) which means that if $G(x_1,\dots, x_n)=0$, then the determinant has to be equal to 0 as well. Why does it happen only with $x_1,\dots, x_k$ being linearly dependent, though?","['linear-algebra', 'inner-products', 'abstract-algebra']"
415650,Finding a counterexample; quotient maps and subspaces,"Let $X$ and $Y$ be two topological spaces and $p: X\to Y$ be a quotient map. If $A$ is a subspace of $X$, then the map $q:A\to p(A)$ obtained by restricting $p$ need not be a quotient map. Could you give me an example when $q$ is not a quotient map?",['general-topology']
415655,Adding small correction term to ODE solution,"Let $\mathbf{r}(t) = [x(t), y(t), z(t)]$ and $\mathbf{v}(t) = \frac{d}{dt}\mathbf{r}(t)$. I'm trying to solve
$$
\frac{d}{dt}\mathbf{v}=\frac{q}{m}(\mathbf{v}\times\mathbf{B}) \tag{1}
$$
where $q$ and $m$ are real constants and $\mathbf{B}(\mathbf{r})$ is an arbitrary vector field. Actually, $\mathbf{B}$ is a magnetic field and $(1)$ is the equation for the motion of a particle in such a field, but that isn't vitally important for the purposes of my question. If $\mathbf{B}$ is a constant,$\mathbf{B}_{0}$,  then we can find the exact solution of $(1)$ with initial conditions $\mathbf{r}_{\circ}$ and $\mathbf{v}_{\circ}$; call these solutions $\mathbf{r}_{0}$ and $\mathbf{v}_{0}$. However, $\mathbf{B}$ usually isn't a constant, it's usally a total mess, and $\mathbf{r}_{0}$ and $\mathbf{v}_{0}$ are poor approximations. In order to make the solutions a little bit better, one could consider expanding $\mathbf{B}$ about $\mathbf{r}_{\circ}$ to first order in $x, y$ and $z$, introducing the term $\mathbf{B}_{1}$, and then attempting to solve $(1)$. Even this is usually impractical, so I really only want the lowest order term of the solution. In short, my idea is to sub $\mathbf{B} = \mathbf{B}_{0} + \mathbf{B}_{1}$ and $\mathbf{v}=\mathbf{v}_{0}+\mathbf{v}_{1}$ into $(1)$, use the fact that $\mathbf{v}_{0}$ is known, and discard as much as possible to find a really low-order correction $\mathbf{v}_{1}$. The issue is that I'm not totally sure how to actually get that correction term, ie. what I'm allowed to throw away. The details are below; I would really appreciate it if someone could read it and tell me if what I did is valid and where I should go next. Derivation Consider a particle of mass $m$ and charge $q$ in an arbitrary magnetic field $\mathbf{B}$ at position $\mathbf{r}_{\circ}(t_{\circ})=[x_{\circ}, y_{\circ}, z_{\circ}]$ with velocity $\mathbf{v}_{\circ}(t_{\circ})=[v_{x{\circ}}, v_{y{\circ}}, v_{z{\circ}}]$. For $\mathbf{r}(t) = [x(t), y(t), z(t)]$ and $\mathbf{v}(t) = \dot{\mathbf{r}}(t)$, the particle's trajectory satisfies $(1)$. We may Taylor expand the magnetic field about $\mathbf{r}_{\circ}$ as follows:
\begin{equation}
\mathbf{B}(\mathbf{r})\approx \mathbf{B}(\mathbf{r}_{\circ}) + (\mathbf{r}- \mathbf{r}_{\circ})\cdot\nabla \mathbf{B}(\mathbf{r}_{\circ}) \tag{2}
\end{equation}
Where $\mathbf{r}\cdot\nabla\mathbf{B}(\mathbf{r}_{\circ}) = (x\partial_{x} + y\partial_{y} + z\partial_{z})\mathbf{B}(\mathbf{r})|_{\mathbf{r}=\mathbf{r}_{\circ}}$. Define $\mathbf{B}_{0}=\mathbf{B}(\mathbf{r}_{\circ})$ along with $\mathbf{B}_{1} = \mathbf{B}_{10} + \mathbf{B}_{11}= -\mathbf{r}_{\circ}\cdot\nabla \mathbf{B}(\mathbf{r}_{\circ}) + \mathbf{r}\cdot\nabla \mathbf{B}(\mathbf{r}_{\circ})$. Further separate $\mathbf{r}=\mathbf{r}_{0}+\mathbf{r}_{1}$ and $\mathbf{v}= \mathbf{v}_{0} + \mathbf{v}_{1}$, where $\mathbf{v}_{0}$ satisfies $(1)$ with field $\mathbf{B}_{0}$, the explicit solution of which is known since the field is simply a constant vector.
By subbing $\mathbf{v}$ and $\mathbf{B}$ into $(1)$ and canceling the known solution, we have
\begin{equation}
\frac{d}{dt} \mathbf{v}_{1} = \frac{q}{m}(\mathbf{v}_{0}\times\mathbf{B}_{1}) + \frac{q}{m}\left(\mathbf{v}_{1}\times(\mathbf{B}_{0}+\mathbf{B}_{1})\right) \tag{3}
\end{equation}
Then note that we must have $\mathbf{r}_{1}(0)=\mathbf{v}_{1}(0) = \mathbf{0}$ since $\mathbf{r}_{0}(0) = \mathbf{r}_{\circ}$ and $\mathbf{v}_{0}(0) = \mathbf{v}_{\circ}$, ie. the initial conditions are already taken care of. Therefore, the lowest order correction in time must be, for $\mathbf{y}=[\alpha, \beta, \gamma]$,  $\mathbf{r}_{1}=\mathbf{y}t^2 \implies \mathbf{v}_{1}=2\mathbf{y}t\implies \frac{d}{dt}\mathbf{v}_{1}=2\mathbf{y}$; by subbing these into $(3)$, we can solve for $\mathbf{y}$. The first-order solution discards all terms with $t^2$ dependence, and therefore we should set $\mathbf{r}_{1}\approx \mathbf{0}$. Also, applying this idea to $\mathbf{B}$, we have $\mathbf{B}_{11}=\mathbf{r}\cdot\nabla\mathbf{B}(\mathbf{r}_{\circ}) = (\mathbf{r}_{0} + \mathbf{r}_{1})\cdot\nabla\mathbf{B}(\mathbf{r}_{\circ}) \approx \mathbf{r}_{0} \cdot\nabla\mathbf{B}(\mathbf{r}_{\circ})\approx (\mathbf{r}_{\circ}+\mathbf{v}_{\circ}t) \cdot\nabla\mathbf{B}(\mathbf{r}_{\circ})$, so that $\mathbf{B}_{1} \approx t\mathbf{v}_{\circ}\cdot\nabla\mathbf{B}(\mathbf{r}_{\circ})$. Here's the issue. If we now sub everything into $(3)$, we have $\mathbf{B}_{1}\propto t$ and $\mathbf{v}_{1}\propto t$, so the left side is a constant and the ride side is $\propto t$ after discarding quadratic terms. How can you get a condition on $\mathbf{y}$ from that? Edit: There might be a simple fix. It seems like if I postulate a solution of the form $r_{1}=\mathbf{y}t^3$ rather than $r_{1}=\mathbf{y}t^2$, then this can work. In this case, the term in $(3)$ with $\mathbf{v}_{1}$ is still discarded, but now we have that the left side is $6\mathbf{y} t$. Writing $\mathbf{v}_{0}\approx\mathbf{v}_{\circ}$, we have a linear term on the right side that can be matched with this, giving
$$
\mathbf{y}= \frac{q}{6m}\mathbf{v}_{\circ}\times(\mathbf{v}_{\circ}\cdot\nabla)\mathbf{B}(\mathbf{r}_{\circ})
$$
I'd still like someone to confirm this logic though.","['electromagnetism', 'ordinary-differential-equations', 'physics']"
415672,Length of a curve given by an equation $ r(t)$,"Find the length of the space curve given by $$r(t) = 2t\,\mathbf{i} + 5\cos(t)\,\mathbf{j} + 5\sin(t)\,\mathbf{k}$$ over the interval $[0,2]$. I did this and I got the answer as 10.77 Did I get the right answer? please help me i'm not very good at this.",['multivariable-calculus']
415679,Pigeonhole principle for a triangle [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Consider a equilateral triangle of total area 1. Suppose 7 points are chosen inside. Show that some 3 points form a triangle of area $\leq\frac 14$.","['geometry', 'pigeonhole-principle']"
415688,"Is $f(x,y) = x^2y + x y^2$ (quasi-) concave or convex?","I should analyze whether the function $$f(x,y) = x^2y + x y^2 \text{ where }  x,y > 0$$ is (quasi-) concave or convex. Thus, as usual, I set up the Hessian as $$ D^2f(x,y) = \left( \begin{array}{cc}
2y & 2x + 2y \\
2x + 2y & 2x \\
 \end{array} \right)  $$ which, given the constraints $x,y > 0$, is indefinite. So I need the bordered Hessian: $$
H= \left( \begin{array}{ccc}
0 & 2xy + y^2 & x^2 + 2xy \\
2xy + y^2 & 2y & 2x + 2y \\
x^2 + 2xy & 2x+2y & 2x \end{array} \right) $$ and check its determinant to find out about its properties. I end up with $$ \det|H| = 2x(2x^3 + x^3 y - 2x^2 y + 4x^2 y^2 + 4 x y^3 + 2 y^4)$$ which, considering $x,y > 0$, looks quite positive to me, so $f$ would be quasiconcave.
But how can I prove that $\det|H| > 0$? Or is there any easier approach? Thanks!","['multivariable-calculus', 'convex-analysis']"
415690,Points on a sphere,"We draw n points, A, B, C, ... Z,  on the upper hemisphere of a sphere, and their n antipodal points on the lower hemisphere, a, b, c, ..., z. We draw the n(n-1)/2 great circles connecting each pair of points on the upper hemisphere, noting that every great circle through X also passes    through x. We now slice the sphere into two hemispheres by drawing an arbitrary great circle that does not pass through any of our points Each hemisphere must contain exactly one member from each of the sets 
{A, a}, {B, b}, {C, c}, ..., {Z, z}. We identify each hemisphere by the points it contains (something like AbcDEF); distances between the points are irrelevant. The question is, How many distinct hemispheres are possible for any given initial configuration of n points? The answer appears to be n(n-1)+2, but I can't prove it.","['geometry', 'graph-theory', 'combinatorics']"
415721,"How to determine the limit of $ f(x, y)=\frac{9xy}{x^2 + y^2}$?","Given $$f(x,y) = \frac{9xy}{x^2 + y^2},$$ determine the limit of $f(x,y)$ as $(x,y) \to (2,1)$.
The answer for this would be $\dfrac{18}{5}$ right?","['multivariable-calculus', 'limits']"
415738,"Finding the intregral $\int_{0}^{2\pi} (\cos x)^{2n}\,\mathrm dx$ by contour integration","How do I find $$\int_{0}^{2\pi} (\cos x)^{2n}\,\mathrm dx$$ using contour integration ? Should I turn it into an integral around the unit circle? Or should I integrate some other function with real part $(\cos x)^{2n}$. Not sure where to start, please help.","['integration', 'complex-analysis']"
415743,How can i solve this separable differential equation?,"Given Problem is to solve this separable differential equation: $$y^{\prime}=\frac{y}{4x-x^2}.$$ My approach : was to build the integral of y': $$\int y^{\prime} = \int \frac{y}{4x-x^2}dy = \frac{y^2}{2(4x-x^2)}.$$ But now i am stuck in differential equations, what whould be the next step? And what would the solution looks like? Or is this already the solution? I doubt that. P.S. edits were only made to improve language and latex","['ordinary-differential-equations', 'integration']"
415747,"If $\theta\in\mathbb{Q}$, is it true that $(\cos \theta + i \sin \theta)^\alpha = \cos(\alpha\theta) + i \sin(\alpha\theta)$?","Is the following true if $\theta\in\mathbb{Q}$?
$$(\cos \theta + i \sin \theta)^\alpha = \cos(\alpha\theta) + i \sin(\alpha\theta)$$
Is it true if $\alpha\in\mathbb{R}$? In each case, prove or give a counterexample, whichever is applicable. I am not able to guess except about the de Moivre's theorem.","['complex-numbers', 'complex-analysis', 'exponentiation']"
415759,"Is the image of a Borel subset of $[0,1]$ under a differentiable map still a Borel set?","Let $f:[0,1]\to[0,1]$ be a continuous function such that its derivative $f'$ exists on $(0,1)$. Inspired by a similar question of myself here , I want to ask: If $E\subset[0,1]$ is a Borel set, is $f(E)$ still a Borel set? Remark: It is known that $f$ maps sets of Lebesgue measure zero to sets of Lebesgue measure zero(for example, one may refer to this post ), so it follows easily that $f$ maps Lebesgue measurable sets to Lebesgue measurable sets. Even if $f$ is assumed to be $C^1$, the answer is unclear to me. As pointed by George Lowther in a comment in the same post , it is well known that for the natural projection $p:\mathbb R^2\to \mathbb R$, $p(x,y)=x$, which is clearly real analytic, the image of  a Borel set of $\mathbb R^2$ under $p$ may not be a Borel set in $\mathbb R$. More details can be found here . It follows that for a high dimensional analog of the question, i.e. for $f:[0,1]^n\to\mathbb R^m$, $n\ge 2$, even when $f$ is real analytic, the answer is negative . Any hint or suggestion is appreciated. Thanks in advance.",['real-analysis']
415765,Integration exercise: $ \int \frac{e^{5x}}{ (e^{2x} - e^x - 20) }dx$,"I have trouble integrating: $$ \int \frac{e^{5x}}{e^{2x} - e^x - 20} dx$$ With $t=e^x$, I've rewritten it as: $$\int \frac{t^5}{t^2 - t - 20} \frac{1}{t} dt$$ Then I tried integration by parts , but I am not any closer to the solution.",['integration']
415792,Proving that a set over a field is a vector space,"Given: $S$ is a nonempty set, $K$ is a field. Let $C(S, K)$ denote the set of all functions ${f}\in\ C(S,K)$ such that ${f}(s) = 0 $ for all but a finite number of elements of $S$ . Prove that $C(S, K)$ is a vector space. OK. I was thinking about using the simple additive axioms that define vector spaces. One of those is that there exist two elements such that $x$ (which is some vector) added to zero equals $x$ , or $x + 0 = x$ . Let $g(s)$ be an arbitrary function. $f + g = g$ when $f(s) = 0$ . In addition, if we assume $g(s)$ to be in the space $C(S,K)$ and $f + g = g$ then both vectors are in the space $C(S,K)$ and are closed under addition. Am I on the right track here? I feel like there's another step I need to have.","['vector-spaces', 'linear-algebra']"
415800,"describe the domain of a function $f(x, y)$","Describe the domain of the function $f(x,y) = \ln(7 - x - y)$. I have the answer narrowed down but I am not sure if it would be $\{(x,y) \mid y ≤ -x + 7\}$ or $\{(x,y) \mid y < -x + 7\}$ please help me.","['analytic-geometry', 'algebra-precalculus']"
415818,Product-to-sum formulas?,"My old pre-calculus book says:
$$\sin u\cos v=\frac{1}{2}[\sin (u+v)+\sin(u-v)]$$
and $$\cos u \sin v=\frac{1}{2}[\sin(u+v)-\sin(u-v)]$$ I don't understand why there is a difference, since multiplication is commutative. Can anyone help? Thanks!","['trigonometry', 'algebra-precalculus']"
415825,Group $G$ of order $p^2$: $\;G\cong \mathbb Z_{p^2}$ or $G\cong \mathbb Z_p \times \mathbb Z_p$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question If the order of $G$ is $p^2$ then how do I show that $G$ is isomorphic to $\mathbb Z_{p^2}$ or $\mathbb Z_p\times\mathbb Z_p$.","['finite-groups', 'group-theory', 'abstract-algebra']"
415833,Conceptual questions about cross product rules,I am studying cross products and I just cannot get my head around the materials. Can someone explain to me why... a) The cross product $\vec{a}\times \vec{b}$ is normal to $\vec{a}$ and $\vec{b}$. Where did this rule come from? b) $|\vec{a}\times \vec{b}| = |\vec{a}||\vec{b}| \sin\theta$ is area of a parallelogram c) $|\vec{a} \cdot (\vec{b} \times \vec{c})|$ is the volume of a parallelepiped. These rules look very strange to me. I just don't see how someone could have come up with them out of thin air. There has to be some reasoning and/or insight I'm missing.,"['linear-algebra', 'algebra-precalculus']"
415847,Galois group of $K(X)/K$,"Let $K$ be an infinite field, if $K(X)$ is the field of rational function I want to find the Galois group of the extension $K(X)/K$ . Lemma 1 : If $L$ is a field such that $K\subsetneq L\subseteq K(X)$ then $[K(X):L]$ is finite. Proof. It is easy to show that $X$ is algebraic over $L$ , so $K(X)/L$ is a finite extension. Lemma 2 : $\operatorname{Gal}(K(X)/K)$ contains only finite (proper) subgroups. Proof. Suppose that $H<G$ is infinite;  for the lemma 1 we have  that $[K(X):\operatorname{Fix}(H)]=n$ , and so $|\operatorname{Gal}(K(X)/\operatorname{Fix}(H))|\le n$ . But $\operatorname{Gal}(K(X)/\operatorname{Fix}(H))\supseteq H$ and this is a contraddiction. Now I know that the group $\operatorname{Gal}(K(X)/K)$ is a group with only finite subgroups, but I can't find other informations about its structure. Maybe this group depends strongly from the field $K$ . Thanks in advance.","['galois-theory', 'algebraic-geometry', 'group-theory']"
415879,Prove: $D_{8n} \not\cong D_{4n} \times Z_2$.,"Prove $D_{8n} \not\cong  D_{4n} \times Z_2$. My trial: I tried to show that $D_{16}$ is not isomorphic to $D_8 \times Z_2$ by making a contradiction as follows: Suppose $D_{4n}$ is isomorphic to $D_{2n} \times Z_2$, so $D_{8}$ is isomorphic to $D_{4} \times Z_2$. If $D_{16}$ is isomorphic to $D_{8} \times Z_2 $, then $D_{16}$ is isomorphic to $D_{4} \times Z_2 \times Z_2 $, but there is not Dihedral group of order $4$ so $D_4$ is not a group and so $D_{16}\not\cong D_8\times Z_2$, which gives us a contradiction. Hence, $D_{16}$ is not  isomorphic to $D_{8} \times Z_2$. I found a counterexample for the statement, so it's not true in general, or at least it's not true in this case. __ Does this proof make sense or is it mathematically wrong?","['dihedral-groups', 'finite-groups', 'group-theory', 'abstract-algebra']"
415891,How to determine the number of isomorphism types of groups of a given order?,"if $G$ is a group whose order is $n$ can we determine the number of isomorphism types for this number or not ? for instance, if $n=4$ we have 2 types, $Z_4$ and $Z_2 \times Z_2$ "" Klein 4-group"" for any number n, is a similar calculation possible ? in other words, let $P$ is a function from Natural numbers into natural numbers which for any number $n$ gives the number of possible structures for a group of order $n$ can we find a formula for this function in terms of $n$ and using operation like addition, multiplication, etc ?","['groups-enumeration', 'finite-groups', 'group-theory', 'abstract-algebra']"
415918,"""Rules of inference"" when the last premise is a conditional?","Another very basic Discrete Mathematics homework problem.  I don't want the answer as much as I want to understand the question: Problem 7 For each of the following sets of premises, what relevant conclusion(s) can be reached?  Explain which rules of inference are used. a) ""If I play hockey, then I am sore the next day"", ""I use the whirlpool if I am sore"", ""I did not use the whirlpool"" b) ""I am dreaming or hallucinating"", ""I am not dreaming"", ""If I am hallucinating, I see elephants smoking"" Okay, now my problem is with b, which ENDS with a conditional.  I'm pretty confident that I already got a) correct, so let's look at b): $p$: I am dreaming $q$: I am hallucinating $r$: I see elephants smoking According to the question, we have: $p$ V $q$ ~$p$ $q\rightarrow r$ The top two premises can be shortened to simply $q$ via ""disjunctive syllogism"": $q$ $q \rightarrow r$ So...which rule can you use to draw any conclusions from the above, and what is the conclusion? Using a truth table, if we look at the row where $q$ AND $q\rightarrow r$ are true, this means that $r$ must be true.  So...is the conclusion $r$?  But what rule is that?","['logic', 'propositional-calculus', 'discrete-mathematics']"
415928,Why is $X^4-16X^2+4$ irreducible in $\mathbb{Q}[X]$?,"Determine whether $X^4-16X^2+4$ is irreducible in $\mathbb{Q}[X]$. To solve this problem, I reasoned that since $X^4-16X^2+4$ has no rational roots hence irreducible. But there is a hint to this question that uses different approach: Try supposing it is reducible, then it must factor into a product of two monic quadratic polynomials with integer coefficients. Then show that it is impossible, then conclude the original polynomial is irreducible. My questions regarding the hints: 1. Why can't we just show that since $X^4-16X^2+4$ has no rational roots hence irreducible? 2. Why do we have to factorise into a product of two monic quadratic polynomials with integer coefficients? Why monic? And why can't we factorise into polynomial with degree 1 and 3? Also, lastly why the coefficients have to be integers? Thank you for any explanations! Edit: Thanks for all the answers. I saw that Second Gauss Lemma is used. But I only learned the first one in class. Which is: Let $R$ be a Unique Facorisation Domain. If $f,g\in\mathbb{R}[X]$ are primitive, then so too is their product $fg$. Is it inevitable to use Second Gauss Lemma? Is there any other way around?","['ring-theory', 'irreducible-polynomials', 'abstract-algebra']"
415966,"Is $ \pi $ definable in $(\Bbb R,0,1,+,×, <,\exp) $?","Is there a first-order formula $\phi(x) $ with exactly one free variable $ x $ in the language of ordered fields together with the unary function symbol $ \exp $ such that in the standard interpretation of this language in $\Bbb R $ (where $ \exp $ is interpreted as the exponential function $ x \mapsto e^x $), $\phi (x) $ holds iff $ x=\pi $? EDIT: As Levon pointed out, a negative answer to this problem would imply that $π$ and $e$ (and $e^e$, $(2e)^{3e^2}$, and so on) are algebraically independent over $\Bbb Q$, which is an unsolved problem. So, if you think that a definition of $\pi$ is impossible, I would be pleased if you could show something like, that it is possible to reduce $\phi$ to a formula which contains no terms involving bound variables inside exponential functions, which would reduce the problem more or less to a question on algebraical independece.
However because there are such intricate connections between exponential and trigonometric functions, I don't think that $\pi$ should be undefinable.","['first-order-logic', 'model-theory', 'real-analysis']"
415979,Are there prime lengths in triangle with all integer sides and heights?,"Suppose you have a triangle in which all sides and all heights are integer in length (i.e. triangle with sides 20, 25, 15 has heights 15, 12 and 20). Could it be that at least one of those numbers is prime? It is very easy to prove that if the numbers are all different then at most 3 of them could be prime. Suppose that $a$, $b$ and $c$ are sides and $h_{a}, h_{b}$ and $h_{c}$ are corresponding heights. Then double area of the triangle is $a h_{a} = b h_{b} = c h_{c}$. If there are 4 or more prime numbers then one equation would be product of two prime numbers (by pigeonhole principle), but by fundamental theorem of arithmetic there is only a single way to express the number as product of primes which contradicts the preposition that all numbers are different. This is fairly weak result, but result nonetheless. I dug a bit further and (according to Wolfram Mathworld ) the triangle which has all integer sides and integer area is called a Heronian triangle (all 'our' triangles are Heronian, but not all Heronian triangles are 'our'). At that page there is a generative formula which immediately$^{*}$ shows that none of sides can be prime, and quite obviously height opposing $c$ can't be prime. I haven't got far trying to prove that other two heights can't be prime either, but I've written a small script which iterates m, n and k up to 500 and yet to find any prime numbers (so far 270K triangles out of 61M triples I intend to iterate over, 54M to go). [*] On 'immediately':
Originally I claimed that sides can't be prime because they are products of integer numbers. In comments Steven Stadnicki raised the point that $m$ or $n$ (or both) can be equal to 1 which would lead to possibility of prime sides. I've shown that this is impossible to have prime side with that condition. Here is the copy of generative formulas from that page for reference: $a = n(m^{2}+k^{2})\\
b = m(n^{2}+k^{2})\\
c = (m+n)(mn-k^{2})\\
S = kmn(m+n)(mn-k^{2})\\
GCD(m,n,k) = 1; mn > k^{2} \ge m^{2}n/(2m+n); m \ge n \ge 1$ First we can easily see that both $m$ and $n$ can't be 1 (as $mn > k^{2}$), so only $n$ can be 1, and $m \ge 2$. I'm going to prove that if $n=1$ and $a$ is prime ($b$ is definitely composite) then $h_{a}$ is not integer, thus that triangle is not conforming.
Let $a = p$, where $p$ is prime and $n = 1$. Then $h_{a} = 2S/p = 2km(m+1)(m-k^{2})/p$. For $h_{a}$ to be integer there should be at least one factor in numerator which is divisible by $p$. Thus one of following should be true (where $q$ is a natural number): $\tag{a} 2=q(m^{2}+k^{2})$
$\tag{b} k=q(m^{2}+k^{2})$
$\tag{c} m=q(m^{2}+k^{2})$
$\tag{d} m+1=q(m^{2}+k^{2})$ 
$\tag{e} m-k^{2}=q(m^{2}+k^{2})$
As $m \ge 2$ it is obvious that (a) can't be true. The rest all lead to quadratic equations, which have no suitable integer solutions. For example let's take (e) and try to solve for $m$: $0 = qm^{2}-m+k^{2}(1+q)$, discriminant is $1-4qk^{2}(1+q)$ which is negative for any natural $q$ and $k$, thus there no such $m$. Similar results can be given for other equations, which means that there is no such number $p$ that $h_{a}$ is integer. Proof that $mn-k^{2}=1$ leads to non-integer $h_{a}$ is similar, thus $c$ can't be prime either.","['prime-numbers', 'geometry', 'triangles']"
415985,Given that $x = 4\sin \left( {2y + 6} \right)$ find dy/dx in terms of x,"My attempt: $\eqalign{
  & x = 4\sin \left( {2y + 6} \right)  \cr 
  & {{dx} \over {dy}} = \left( 2 \right)\left( 4 \right)\cos \left( {2y + 6} \right)  \cr 
  & {{dx} \over {dy}} = 8\cos \left( {2y + 6} \right)  \cr 
  & {{dy} \over {dx}} = {1 \over {8\cos \left( {2y + 6} \right)}} \cr} $ $\eqalign{
  & x = 4\sin \left( {2y + 6} \right)  \cr 
  & {{dx} \over {dy}} = \left( 2 \right)\left( 4 \right)\cos \left( {2y + 6} \right)  \cr 
  & {{dx} \over {dy}} = 8\cos \left( {2y + 6} \right)  \cr 
  & {{dy} \over {dx}} = {1 \over {8\cos \left( {2y + 6} \right)}}  \cr 
  & {\cos ^2}\left( {2y + 6} \right) + {\sin ^2}\left( {2y + 6} \right) = 1  \cr 
  & {\cos ^2}\left( {2y + 6} \right) + {\left( {{x \over 4}} \right)^2} = 1  \cr 
  & {\cos ^2}\left( {2y + 6} \right) = 1 - {{{x^2}} \over {16}}  \cr 
  & \cos \left( {2y + 6} \right) = \sqrt {{{16 - {x^2}} \over {16}}}   \cr 
  & \cos \left( {2y + 6} \right) = {{\sqrt {16 - {x^2}} } \over 4}  \cr 
  & {{dy} \over {dx}} = {1 \over {2\sqrt {16 - {x^2}} }} = 1 \cr} $ Okay I've got it right, but the official answer confuses me, it says: ${{dy} \over {dx}} = {1 \over {8cos\left( {\arcsin \left( {{x \over 4}} \right)} \right)}} = \left( {\left(  \pm  \right){1 \over {2\sqrt {\left( {16 - {x^2}} \right)} }}} \right)$ This is the part i'm struggling to get my head around, although I arrive at the same answer. Okay $\arcsin {x \over 4} = 2y + 6$ but how does the answer then go : $\left( {\left(  \pm  \right){1 \over {2\sqrt {\left( {16 - {x^2}} \right)} }}} \right)$ is there a shortcut or trick I overlooked? I think I need some sleep, thanks...","['trigonometry', 'implicit-differentiation', 'calculus', 'derivatives']"
415994,Is there a Dihedral group of order 4?,"If I use the notation $D_{2n}$, then does $D_4$ make sense? If I showed that a group $G$ is isomorphic to $H \times D_4$ where $H$ is a group, then is $G$ not a group? I am asking this because in my other question the answerer didn't directly address my question.","['group-theory', 'abstract-algebra']"
416004,How do we show that an ideal of polynomials is prime,"I'm trying to solve this exercise: To do so, I'm trying to prove that $(X_1^2+X_2^2+X_3^2)$ is a prime ideal. Suppose now $f,g\in \mathbb R[X_1,X_2,X_3]$ and $f\cdot g\in (X_1^2+X_2^2+X_3^2)$, i. e., $f\cdot g=h\cdot(X_1^2+X_2^2+X_3^2)$, with $h\in \mathbb R[X_1,X_2,X_3]$. Suppose $f\notin (X_1^2+X_2^2+X_3^2)$, then we have to prove that $g\in (X_1^2+X_2^2+X_3^2)$... I couldn't go further, I really need help. Thanks a lot","['abstract-algebra', 'polynomials']"
416005,Concrete Mathematics Iversonian Set Relation Clarification,"Sorry for asking a very dumb question, but in Concrete Mathematics(Graham,Knuth,Patashnik), chapter 2 section 4, Knuth talks about this formula called ""Rocky Road"". This is the formula to use when you want to interchange the order of summation of a double sum whose inner sum's range depends on the index variable of the outer sum, like this: \begin{equation}
\displaystyle\sum\limits_{j = 1}^{n}{\displaystyle\sum\limits_{k = j}^{n}{a_j,_k}}
\end{equation} The rocky road formula is as follows:
\begin{equation}
\displaystyle\sum\limits_{j \in J}^{}{\displaystyle\sum\limits_{k \in K(j)}} = \displaystyle\sum\limits_{k \in K'}{\displaystyle\sum\limits_{j \in J'(k)}}
\end{equation} With the requirement that the sets $J,K(j),K', \text{and} J'(k)$ be related in such a way that:
\begin{equation}
[j \in J][k \in K(j)] = [k \in K'][j \in J'(k)]
\end{equation} My understanding of this, is that the set $K'$ is basically the ""bounds"" that $k$ has, sort of like its restrictions. For the first sum I wrote, I would think that K' be the set {j,j+1,...,n} and since j starts at 1, K' is really just the set of the values $1 \rightarrow n$. However, I can't really figure out $J'(k)$ here , or even if my understanding of $K'$ is right. Can anyone give me some pointers or put me in the right track as to understanding this set relation? Thanks,","['set-theory', 'summation', 'discrete-mathematics']"
416021,What is computational group theory?,What is computational group theory? What is the difference between computational group theory and group theory? Is it an active area of the mathematical research currently? What are some of the most interesting results? What is the needed background to study it?,"['reference-request', 'group-theory', 'abstract-algebra', 'computational-algebra']"
416030,Conditional Expected Value and distribution question,"The distribution of loss due to fire damage to a warehouse is: $$
\begin{array}{r|l}
\text{Amount of Loss (X)} & \text{Probability}\\
\hline
0 & 0.900 \\
500 & 0.060  \\
1,000 & 0.030\\
10,000 & 0.008 \\
50,000 & 0.001\\
100,000 & 0.001 \\
\end{array}
$$ Given that a loss is greater than zero, calculate the expected amount of the loss. My approach is to apply the definition of expected value: $$E[X \mid X>0]=\sum\limits_{x_i}x_i \cdot p(x_i)=500 \cdot 0.060 + 1,000 \cdot 0.030 + \cdots + 100,000 \cdot 0.001=290$$ I am off by a factor of 10--The answer is 2,900.  I am following the definition of expected value, does anyone know why I am off by a factor of $1/10$? Should I be doing this instead??? $E[X \mid X>0] = \sum\limits_{x_i} (x_i \mid x_i > 0) \cdot \cfrac{\Pr[x_i \cap x_i>0]}{\Pr(x_i > 0)}$
Thanks.","['statistics', 'probability']"
416035,Support vs range of a random variable,Is there any difference between the two? I have not met any formal definition of the support of a random variable. I know that for the function $f$ the support is a closure of the set $\{y:\;y=f(x)\ne0\}$.,"['probability-theory', 'real-analysis']"
416040,How to apply De Morgan's law?,If for De Morgan's Laws $$( xy'+yz')' = (x'+y)(y'+z)$$ Then what if I add more terms to the expression ... $$(ab'+ac+a'c')' = (a'+b)(a'+c')(a+c)?$$,"['logic', 'propositional-calculus', 'boolean-algebra', 'discrete-mathematics']"
416044,Finding the closest point to the origin of $y=2\sqrt{\ln(x+3) }$,"Given $$y=2\sqrt{\ln(x+3) }$$
How do I determine a (x,y) pair satisfying the above relation which is the closest to the origin (0,0)?","['calculus', 'derivatives']"
416045,Every primitive matrix is irreducible?,"$A$ is reducible if there is some permutation matrix $P$ such that
$$ PAP^T = 
 \begin{bmatrix}
B & C \\ 
O & D \\
 \end{bmatrix}
$$ And, if $A^k > O$ for some k, then $A$ is called primitive. Then, how can I show that every primitive matrix is irreducible?",['matrices']
416046,How to show that the limit of compact operators in the operator norm topology is compact,"When I read the item of compact operator on Wikipedia, it said that Let $T_{n}, ~~n\in \mathbb{N}$ , be a sequence of compact operators from
  one Banach space to the other, and suppose that $T_n$ converges to $T$ with respect to the operator norm. Then $T$ is also compact. Can anyone give me a brief proof of this? Thanks in advance.","['compact-operators', 'functional-analysis']"
416049,Weak Law of Large Numbers proof,I want to know if there is a proof of the Weak Law of Large Numbers without using the Chebyshev's Inequality? please can anyone give me some references,"['probability-theory', 'reference-request', 'probability']"
416080,Index of maximal subgroups of $p$-solvable groups,"If $G$ is finite $p$-solvable group (every chief factor has order either a power $p$ or relatively prime to $p$) must every maximal subgroup have index either a power of $p$ or relatively prime to $p$? I've shown the maximal subgroups of $p$-power index behave like the maximal subgroups of solvable groups. A maximal subgroup of a finite solvable has prime power index, so it seems reasonable that the only other kind of maximal subgroup in a $p$-solvable group is one with prime-to-$p$ index. Surely this is true for simple $p$-solvable groups. I suspect a maximal subgroup of a $p$-solvable group either (a) have index a power of $p$ and cover all chief factors except exactly one $p$-chief factor which it avoids or (b) have index relatively prime to $p$ and cover all $p$-chief factors (but not necessarily cover or avoid the $p'$-chief factors). In case (b), I am interested if a maximal subgroup covers all but one $p'$-chief factor. I don't have much intuition here (what do maximal subgroups of $A_5 \wr A_5$ look like?).","['solvable-groups', 'finite-groups', 'group-theory', 'abstract-algebra']"
416083,Genus over finite fields,"Is there a way of computing the genus of a parametrized curve over a finite field?
For instance I am interested in the genus of the following space curve in the m-dimensional space over $F_{q^k}$ given parametrically as:
$(x, x^h, x^{h^2}, \dots , x^{h^{m-1}})$
Here h and m are some fixed constants, say. I basically work in theoretical computer science, more specifically in algebraic coding theory, so am not that familiar with advanced algebraic geometry, so I apologize in advance if the question is vague. Any help or references in this regard would be appreciated.","['finite-fields', 'algebraic-geometry', 'algebraic-curves']"
416088,Help with a trig-substitution integral,"I'm in the chapter of trigonometric substitution for integrating different functions. I'm having a bit of trouble even starting this homework question:
$$\int \frac{(x^2+3x+4)\,dx} {\sqrt{x^2-4x}}$$","['trigonometry', 'calculus', 'integration']"
416094,Evaluating an integral of unit step function?,"First we are given: $$\int_0^t H(s)\,ds=\left.\begin{cases} 0 & t<0\\ t & t>0\\ \end{cases}\right\}=tH(t).$$  Now I have attempted to do the following integral: $$\int_t^\infty [H(s-2)-H(s-3)]\,ds.$$  Now if $t<2$ then answer is $1$ because distance from $2$ to $3$ is $1$ with height $1$, or if $t>3$ answer is $0$.  But I am not sure how to give an answer in the form of the original definition of integration of unit step function.  I would guess that it would be $$\int_t^\infty [H(s-2)-H(s-3)] \, ds=(2-t)H(t-2)-(3-t)H(t-3).$$  I assume that $t<2$ and reasoning behind $2-t$ and $3-t$ is that to find area need distance from $t$ to $2$ and $t$ to $3$ then the times the height of each namely $H(t-2)$, $H(t-3)$.","['special-functions', 'integration']"
416098,Statistic question,"1) A student took a chemistry exam where the exam scores were mound-shaped with a mean score of 90 and a standard deviation of 64. She also took a statistics exam where the scores were mound-shaped, the mean score was 70 and the standard deviation was 16. If the student's grades were 102 on the chemistry exam and 77 on the statistics exam, then: a. the student did relatively better on the chemistry exam than on the statistics exam, compared to the other students in each class b. the student's scores on both exams are comparable, when accounting for the scores of the other students in the two classes c. it is impossible to say which of the student's exam scores indicates the better performance d. the student did relatively better on the statistics exam than on the chemistry exam, compared to the other students in the two classes e. the student did relatively the same on both exams The correct answer is D but I don't know why.",['statistics']
416099,Lasso - constraint form equivalent to penalty form,"We know that there are two definitions to describe lasso. Regression with constraint definition:
$$\min\limits_{\beta} \|y-X\beta\|^2, \sum\limits_{p}|\beta_p|\leq t, \exists t
$$
Regression with penalty definition:
$$\min\limits_{\beta} \|y-X\beta\|^2+\lambda\sum\limits_{p}|\beta_p|, \exists\lambda$$ But how to convince these two definition are equivalent for some $t$ and $\lambda$? I think Lagrange multipliers is the key to show the relationship between two definitions. However, I failed to work out it rigorously because I assume the properties of lasso ($\sum\limits_{p}|\beta_p|=t$) in regression with constraint definition. Does anyone can show me the complete and rigorous proof of these two definitions are equivalent for some $t$ and $\lambda$? Thank you very much if you can help. EDIT: According to the the comments below, I edited my question.","['optimization', 'regression', 'lagrange-multiplier', 'analysis']"
416122,"Is there a formula for this integral $I(a,b)=\int_0^1 t^{-3/2}(1-t)^{-1/2}\exp\left(-\frac{a^2}{t}-\frac{b^2}{1-t} \right)dt$","Is there a formula for the following integral?
$$I(a,b)=\int_0^1 t^{-3/2}(1-t)^{-1/2}\exp\left(-\frac{a^2}{t}-\frac{b^2}{1-t} \right)dt$$
where $a,b$ are non-zero real numbers.","['special-functions', 'improper-integrals', 'calculus', 'integration']"
416123,Why do we write second derivatives like $\frac{d^2x}{dt^2}$ [duplicate],"This question already has answers here : What is the use of, and intuition behind, writing $\frac{d^2}{dx^2}$ for the second derivative? (4 answers) Closed 11 years ago . Why do we write the second derivative of $x$ with respect to $t$ as $\frac{d^2x}{dt^2}$? It's never been explained to me, and I've never found a particularly good explanation. What's up with this weird derivative notation?","['notation', 'derivatives']"
416150,What is continuity correction in statistics,"Can someone please explain to me the idea behind continuity correction and when is it necessary to add or subtract $\dfrac{1}{2}$ from the desired number (how do we tell whether we need to add or subtract), how do we tell when we need to use continuity correction?",['statistics']
416157,Local Reparametrization of Surface using known Vector Field (Differential Geometry),"I need help with the following problem: ""Let $X$ be a vector field defined on surface $S$, and $p \in S$ such that $X(p) \neq 0$. Prove that there exists a local parametrization $\phi \colon U \to S$ with $U$ an open set of $\mathbb{R}^2$ such that $X|_{\phi(U)} = \phi_1$ where $\phi_1$ is the derivative of the parametrization with respect to it's first parameter."" I intuitively imagine I need to use the vector field in a creative way to satisfy the condition requiered. In a way I think I need something like $$
\phi(s,t)=\int_0^s \int_0^t X(s,t) ds dt
$$ But that doesn't really work.  I was wondering if anyone could guide me to the good parametrization so I can complete the rest...",['differential-geometry']
416169,Best upper bound on the number of divisors of $n$ that are larger than $N$.,"I am looking for the best upper bound on $$\sum_{\substack{d | n\\ d \geq N}} 1.$$ I know that
$$
d(n) = \sum_{\substack{d | n}} 1 \leq e^{O(\frac{\log n}{\log \log n})}.
$$ For my application, I need something like 
$$\sum_{\substack{d | n\\ d \geq N}} 1 \leq \frac{o(n^{\epsilon})}{\log N} \quad \forall \epsilon > 0.
$$ A reference where the bound can be found or a simple proof would be appreciated. Thanks. EDIT: Johan Andersson at mathoverflow has pointed out that the third display follows from the second. (Thanks.) I am still interested to learn what the best known bound is.","['analytic-number-theory', 'elementary-number-theory', 'number-theory']"
416179,"If $f:X\to Y$ is a one-to-one continuous mapping, and $Y$ is a $T_{2}$-space, then does $X$ too have to be a $T_{2}$-space?","Motivation: For any two points $y_{1},y_{2}\in Y$, there are disjoint open sets containing $y_{1}$ and $y_{2}$ separately, as $Y$ is a $T_{2}$-space. 
Say $f(x_{1})=y_{1}$ and $f(x_{2})=y_{2}$. Then, taking the inverses of the disjoint open sets, we get disjoint open sets containing $x_{1}$ and $x_{2}$ separately. Why the inverses of disjoint open sets are also disjoint is if there was one point in common between two open sets in $X$ and not in $Y$, then that point would mapped to two different points in $Y$, one in each disjoint set, which is impossible. Remember $f$ is one-to-one. Hence, as there are disjoint open sets for every $y_{i}$ and $y_{j}$, there are correponding open sets for every $x_{i}$ and $x_{j}$. Doesn't this make $X$ a Hausdorff space too?",['general-topology']
416185,Sperner's Lemma in infinite-dimensional spaces?,"I've been looking at Sperner's Lemma for a little while and have managed to come to grips with some of the combinatorial proofs. Some descriptions I have encountered claim to prove it for ""simplices"" and some for ""$n$-simplices"", and there didn't seem to be any particularly large differences between the proofs. On the other hand, it seems nontrivial to formulate Sperner's Lemma in infinite dimensions. It doesn't seem like there should be anything preventing us from defining simplices in arbitrary real infinite-dimensional topological vector spaces (RIDTVSs). But having little experience with them, I don't know how Sperner's Lemma would work there. In particular I know that closed balls in RIDTVSs are not compact, which could reasonably be hiding in the background of the combinatorial proofs. It certainly plays a role in the equivalent Brouwer's Fixed Point Theorem. Does anyone know of a formulation of Sperner's Lemma in RIDTVSs, or at least have a reference to an analytic proof in finite dimensions that might be illuminating?","['vector-spaces', 'combinatorics']"
416186,Differential manipulation,"Let $v \equiv F(y, z)$. The partial derivatives of $F$ are $$F_1 \equiv \frac{\partial F(y,z)}{\partial y} = \frac{H(v)}{H(y)},$$ $$F_2 \equiv \frac{\partial F(y,z)}{\partial z} = r\frac{H(v)}{H(z)},$$ where $H$ is an arbitrary function. This is taken from the book Probability Theory by E.T. Jaynes. The author goes on saying that the relation $ \mathrm{d}v = \mathrm{d}F(y, z) = F_1\mathrm{d}y + F_2\mathrm{d}z$ takes the form of 
$$\frac{\mathrm{d}v}{H(v)} = \frac{\mathrm{d}y}{H(y)} + r\frac{\mathrm{d}z}{H(z)}$$ or, on integration
$$w[F(y, z)] = w(v) = w(y)w^r(z),$$ where
$$w(x) \equiv exp\left\{\int^x \frac{\mathrm{d}x}{H(x)}\right\}.$$ I did undergraduate calculus; however, we didn't do this kind of differential manipulation (expansion of $\mathrm{d}v$) and I find it quite confusing. Is there a way to arrive at the same result using ""standard"" steps like integration by substitution etc.?","['multivariable-calculus', 'calculus', 'integration']"
416204,A question about the relationship between submodule and ideal,"It is stated in Wikipedia that if $I$ is an ideal of $R$, that is $I\triangleleft R$, then $_R I$ is a submodule of $_R R$. Here, I assume $R$ is commutative. Despite the notation, I mean ideal is the left and right ideal. But it can interpreted as left or right ideal only if necessary. The point of my question is not emphasising on left or right, I am just curious whether the statement works for the converse. Hopefully it is clear. But if there is something wrong in my interpretation, please kindly let me know. I would like to know whether the converse is true, but it is not stated in Wikipedia. That is for any submodule $_R N$ of $_R R$, then $N$ is an ideal of $R$? In other words, is it true that if $_R N\subseteq _R R$ then $N\triangleleft R$? If this is a well known useful property, then it should be stated, but I could not find in some books that I read and other sources. Is it something to proof or is it defined? If it is something to proof, could anyone give some ideas about the proof? Thanks!","['modules', 'ring-theory', 'abstract-algebra']"
416232,The second largest eigenvalue for Perron-Frobenius matrix,"The Perron-Frobenius theorem is about the largest eigenvalue and eigenvector of a non-negative (irreducible) matrix. My question: Is there any estimation of the difference between the first and second largest eigenvalues, say an upper or a lower bound? An general theory may be tough, so please feel free to add other conditions to limit our discussion.","['matrices', 'linear-algebra', 'graph-theory', 'markov-chains']"
416233,Analytic continuation of Riemann Zeta function.,I am reading about zeta function from book by Ingham. In that book the following theorem is given. I am unable to understand what does he mean by finite part of plane in the statement.,"['analytic-number-theory', 'riemann-zeta', 'complex-analysis']"
416241,Definition simply connected in $\Bbb C$,I recently saw a different definition for simply connected which I had never seen before. A connected subset $\Omega\subset\Bbb C$ is called simply connected if the boundary is the image of a simple closed curve. Is this equivalent to the usual definitions? Thanks,"['general-topology', 'complex-analysis', 'real-analysis']"
416254,Find $f(5)$ of a non-constant polynomial function $f(x)$,"Suppose $f(x)$ is a non-constant polynomial such that $f(x^ 3) − f(x ^ 3 − 2) = f( x )\cdot f(x) + 12$ for all $x$. Find $f(5)$? I find this problem on Quora just now, and I try to solve it but do not know where to start (every time I substitue a number  $a$ into the equation, I get three more unknown numbers). Would anyone give me any clue? Is there a general method to deal with this kind of problems?","['functions', 'polynomials']"
416255,Understading the idea behind Gradient vector fields..,"Example 3: Sketch the gradient vector field for $f(x,y) = x^2 + y^2$ as well as several contours for this function. The gradient of the vector field is 
$$
\nabla f(x,y)=2x\vec{i}+2y\vec{j}.
$$ But when i plot those 2 functions, I get a vector field that doesn't make sense. What does the Gradient vectors (the purple ones) tell me abouth the function?","['ordinary-differential-equations', 'calculus', 'vector-analysis']"
416265,Are two independent events $A$ and $B$ also conditionally independent given the event $C$?,"If we know that two events $A$ and $B$ are independent, can we say that $A$ and $B$ are also conditionally independent given an arbitrary event $C$? $$P(A\cap B) = P(A)P(B) \overset{?}{\Rightarrow} P(A\cap B|C) = P(A|C)P(B|C)$$",['probability']
416268,Bijection between multisets and directed animals?,"The number of directed animals (aka polyominoes) of size $n$ ( A005773 ) is enumerated by the generating function $$\frac{1}{2} \left(1+\sqrt\frac{{1+z}}{{1-3 z}}\right).$$ This
generating function also enumerates the number of $n$ -element multisets of $\{1,\ldots,n\}$ containing no pair of consecutive integers (e.g. $111, 113, 133, 222, 333$ for $n=3$ ). The first few numbers in the sequence are $$1, 1, 2, 5, 13, 35, 96, 267, 750, 2123, 6046, 17303, 49721.$$ Is there a good bijection between the two combinatorial classes? This question is now resolved in this paper .","['polyomino', 'generating-functions', 'multisets', 'combinatorics']"
416282,Weak and strong topology on infinite dimensional spaces,Is there a simple example to show that the weak and strong topology on an infinite-dimensional space do not need to coincide? I have several ideas using differences in the weak and strong convergence of probability measures (e.g. central limit theorem) but I'm looking for some $l^p$ example.,"['general-topology', 'normed-spaces', 'functional-analysis', 'probability-theory']"
416289,Derivative of this formula?,"I'm studying Solid State Electronics and at one point my book says:
$$\dfrac{\text{d}x_n}{\text{d}V_a}= \dfrac{1}{N_d} \left(\dfrac{\varepsilon_s}{2q(\frac{1}{N_a}+\frac{1}{N_d})(\phi_i -V_a)}\right)^{1/2}$$ where 
$$
\left\{\begin{align}
x_d &= x_n \left( 1+ \frac{N_d}{N_a} \right) \\ x_d &=\sqrt{ \frac{2\varepsilon}{q}\left(\frac{1}{N_a}+\frac{1}{N_d}\right)(\phi_i -V_a)}
\end{align}\right.
$$
So I tried calculating that derivative by ""hand"". I actually get the result of the book only, there's a minus sign that doesn't tally with what the books says. Is it me or is the book mistaken?",['derivatives']
416291,Can there be a repeated edge in a path?,"I was just brushing up on my discrete mathematics specifically graph theory and read the following definition of a walk in a graph ""A walk in a graph is an alternating sequence of vertices and edges from a start vertex to an end vertex where start and the end vertices are not necessarily distinct"" and after this I read up the definition of a path in a graph which says ""A path in a graph is a walk in the graph with no repeated vertices"" the point of confusion is that the definition for a path doesn't mention anything about the repetition of edges in a path, although the idea of repetition of edge in a path sounds absurd to me because that eventually means that I am taking the same road that I traversed previously and hence repeating the same destinations which are the vertices respectively. I am curious to know if there is any such case of a path where there is a repetitive edge but no repeated vertex. One more thing I would like to know is can there exists an ordering of edges in a graph such that the path from one vertex to another is infinite in short can there be an infinite path in a finite graph?","['graph-theory', 'discrete-mathematics']"
416293,"(18,9,8) self-dual quaternary codes vs S18","i am wondering about the form of S18. It is written that [18,9,8] self-dual quaternary codes is equivalent to S18.
there is a generator matrix of this quaternary code, ok, but how it can be equivalent to S18? S18 is the symmetric group. S_{18} maybe better.","['coding-theory', 'discrete-mathematics', 'finite-fields', 'linear-algebra', 'combinatorics']"
416299,How to deduce the uniform ellipticity condition from an integral condition,"Let $\Omega$ be a bounded open set, and let $A$ be a $N\times N$ symmetric matrix with entries in $L^\infty(\Omega, \mathbb{R})$, such that for some positive $\lambda$ and $\Lambda$ the following inequalities hold for every $u \in W^{1,2}_0(\Omega, \mathbb{R})$:
$$ 
\lambda \int \limits_\Omega \! | \nabla u(x) |^2 \, \mathrm{d}x \leq \int \limits_\Omega \! A(x) \nabla u(x) \cdot \nabla u(x) \, \mathrm{d} x \leq \Lambda \int \limits_\Omega \! | \nabla u(x) |^2 \, \mathrm{d}x
$$
Is there a way to deduce that $A$ satisfies the following pointwise inequalities
$$
\lambda | \xi |^2 \leq A(x) \xi \cdot \xi \leq \Lambda |\xi|^2
$$
for almost every $x \in \Omega$ and for all $\xi \in \mathbb{R}^N$? The first strategy I tried to adopt was to choose a function in $W^{1,2}_0(\Omega)$ whose gradient is essentially a fixed vector $\xi \in \mathbb{R}^N$. However, to choose it in such a way that it belongs to $W^{1,2}_0(\Omega)$ it must vanish near the boundary. Hence I chose
$$
u(x) := (\xi \cdot x ) \zeta(x)
$$
where $\zeta$ is a cutoff function such that $\zeta \equiv 1$ on $\omega \subset \subset \Omega$ and with support in $\Omega$. Maybe, if it is convenient, we can also control $|\nabla \zeta|$ when $\partial{\omega}$ is ""near"" $\partial{\Omega}$. But I don't see how to obtain the pointwise estimates from the intagral ones! Second strategy . I tried to argue by contradiction. Assume, for example, that the inequality
$$
\lambda |\xi|^2 \leq A(x) \xi \cdot \xi
$$
doesn't hold for almost every $x \in \Omega$ for some $\xi \in \mathbb{R}^N$. This means that the set
$$
\omega := \{ x \in \Omega \ | \ \lambda |\xi|^2 > A(x) \xi \cdot \xi \}
$$
has positive measure. If I was able to construct a function in $W^{1,2}_0(\Omega)$ whose gradient is $\xi$ on $\omega$ and $0$ in $\Omega \setminus \omega$, I would conclude integrating, contradictiong the first intregral inequality. Though such function cannot be constructed in that precise way, maybe I can argue as in the first strategy using suitable cutoff functions, but my tries failed. Any suggestions?","['inequality', 'partial-differential-equations', 'analysis']"
416306,Composition $R \circ R$ of a partial ordering $R$ with itself is again a partial ordering,If $R$ is a partial ordering then $R\circ R$ is a partial ordering. I cannot seem to prove this can anyone help ?,"['relations', 'elementary-set-theory', 'order-theory']"
