question_id,title,body,tags
3441821,"If $\sin^2x+\sin^2y<1 \forall x,y \in R$, then prove that $\sin^{-1}(\tan x\cdot\tan y)\in\left(-\dfrac{\pi}{2},\dfrac{\pi}{2}\right)$","If $\sin^2x+\sin^2y<1 \forall x,y \in R$ , then prove that $\sin^{-1}(\tan x\cdot\tan y)\in\left(-\dfrac{\pi}{2},\dfrac{\pi}{2}\right)$ My attempt is as follows:- $$f(x)=\tan x\tan y$$ $$f(x)=\dfrac{\sin x\sin y}{\cos x\cos y}\tag{1}$$ Let's find out upper bound of $f(x)$ , for that we need to find upper bound of $\sin x\sin y$ and lower bound of $\cos x\cos y$ $$\sin^2x+\sin^2y<1$$ $$(\sin x-\sin y)^2>=0$$ $$\sin^2x+\sin^2y-2\sin x\sin y>=0$$ $$\dfrac{\sin^2x+\sin^2y}{2}>=\sin x\sin y$$ $$\sin x\sin y<\dfrac{1}{2}\quad\forall x,y\tag{2}$$ $$(\cos x-\cos y)^2>=0$$ $$\cos^2x+\cos^2y-2\cos x\cos y>=0$$ $$1-\sin^2x+1-\sin^2y-2\cos x\cos y>=0$$ $$\dfrac{2-(\sin^2x+\sin^2y)}{2}>=\cos x\cos y$$ $$1-\dfrac{\sin^2x+\sin^2y}{2}>=\cos x\cos y$$ Now here I am stuck as I am not finding the way to calculate lower bound of $\cos x\cos y$",['trigonometry']
3441841,"Proof verification - If $a|bc$ and $(a,b) = 1$, then $a|c$ [duplicate]","This question already has answers here : $a|bc\!\!\iff\!\! a|(a,b)c\!\iff\!\!\frac{a}{(a,b)}\!\!\mid\! c\!\iff\!\!\frac{{\rm lcm}(a,b)}{b}\!\mid\! c\ $ [general Euclid's Lemma] (5 answers) Euclid's Lemma $\,(a,b)=1,\ a\mid bc\Rightarrow a\mid c\,$ in Bezout, gcd, ideal form (2 answers) If prime $p \mid ab$, then $p \mid a$ or $p \mid b\ $ [Euclid's Lemma] (4 answers) Closed 4 years ago . if $a|bc$ and $gcd(a,b) = 1$ , then $a|c$ We know that $b|bc$ also $a|bc$ and $(a,b)= 1 \rightarrow \big(ab=lcm(a,b\big)\big| bc$ so $a | c$ . Is this proof correct? Edit: I think assuming $lcm(a,b)=ab$ is too much so here is another elementary proof: $(a,b)=1\rightarrow \exists p,q \in Z \ni pa +qb = 1 \rightarrow pac + qbc = c $ now $a|ac$ and $a|bc$ so $a|c$","['elementary-set-theory', 'number-theory', 'combinatorics', 'elementary-number-theory']"
3441855,finite sum with combinatorics,I have two finite sum with combinatorics: $$f(n)=\sum_{k=0}^n (-1)^k 4^{n-k} \binom{2n-k+1}{k}$$ and $$g(n)=\sum_{k=0}^n (-1)^k 4^{n-k}\binom{2n-k}{k}$$ I tried several methods but have no clue how to derive that $f(n)=n+1$ and $g(n)=2n+1$ . Can anybody help me? Any hint is appreciated in advance!,"['summation', 'combinatorics', 'combinatorial-proofs', 'generating-functions']"
3441930,Binomial Probability Distribution Question,"Tom has $10$ crazy children. In honor of Christmas, he bought $7$ new toys for each one of them. The children destroy a new toy within one day with a $0.7$ probability. What is the chance that after one day at least 8 children destroyed at least 6 toys each ? Final Answer : $0.82$ I think the question is asking about Binomial Probability Distribution + little combinatorics. I don't know if that's right as well. Answer Attempt : I tried first calculating the probability that a child destroy at least $6$ toys , Let $X$ be random variable indicating that so : $P(6\leq X) = P(X=6)+P(X=7)=\binom{7}{6}(0.7)^6(0.3)^1 + \binom{7}{7}(0.7)^7(0.3)^0 = 0.3294$ $ P(X<6) = 1-P(6\leq X) = 0.6706$ Now we need at least $8$ children to destroy at least $6$ , Let $Y$ be the number of children that destroy at least $6$ toys so : $P(8 \leq Y) = P(Y=8)+P(Y=9)+P(Y=10) = $ $= \binom{10}{8}(0.3294)^8(0.6706)^2 + \binom{10}{9}(0.3294)^9(0.6706)^1 + \binom{10}{10}(0.3294)^{10}(0.6706)^0$ but I get really really small probability $(0.003)$","['combinations', 'probability-distributions', 'combinatorics', 'probability']"
3442053,Solve the equation $\cos^{-1}\frac{x^2-1}{x^2+1}+\tan^{-1}\frac{2x}{x^2-1}=\frac{2\pi}{3}$,"$\cos^{-1}\dfrac{x^2-1}{x^2+1}+\tan^{-1}\dfrac{2x}{x^2-1}=\dfrac{2\pi}{3}$ Let's first find the domain $$-1<=\dfrac{x^2-1}{x^2+1}<=1$$ $$\dfrac{x^2-1}{x^2+1}>=-1 \text { and } \dfrac{x^2-1}{x^2+1}<=1$$ $$\dfrac{x^2-1+x^2+1}{x^2+1}>=0 \text { and } \dfrac{x^2-1-x^2-1}{x^2+1}<=0$$ $$\dfrac{2x^2}{x^2+1}>=0 \text { and } \dfrac{-2}{1+x^2}<=0$$ $$x\in R$$ $$x^2-1\ne0$$ $$x\ne\pm1$$ $$\cos^{-1}\dfrac{x^2-1}{x^2+1}+\tan^{-1}\dfrac{2x}{x^2-1}=\dfrac{2\pi}{3}$$ $$\pi-\cos^{-1}\dfrac{1-x^2}{1+x^2}-\tan^{-1}\dfrac{2x}{1-x^2}=\dfrac{2\pi}{3}$$ $$\dfrac{\pi}{3}=\cos^{-1}\dfrac{1-x^2}{1+x^2}+\tan^{-1}\dfrac{2x}{1-x^2}$$ Substituting $x$ by $\tan\theta$ $$x=\tan\theta$$ $$\tan^{-1}x=\theta$$ $$\theta\in \left(-\dfrac{\pi}{2},\dfrac{\pi}{2}\right)-\{-\dfrac{\pi}{4},\dfrac{\pi}{4}\}$$ $$\dfrac{\pi}{3}=\cos^{-1}\dfrac{1-\tan^2\theta}{1+\tan^2\theta}+\tan^{-1}\dfrac{2\tan\theta}{1-\tan^2\theta}$$ $$\dfrac{\pi}{3}=\cos^{-1}(\cos2\theta)+\tan^{-1}(\tan2\theta)$$ $$2\theta\in(-\pi,\pi)-\{-\dfrac{\pi}{2},\dfrac{\pi}{2}\}$$ Now we break the range of $2\theta$ into various parts:- Case $1$ : $2\theta\in\left(-\pi,-\dfrac{\pi}{2}\right)$ , $\theta\in\left(-\dfrac{\pi}{2},-\dfrac{\pi}{4}\right)$ $$\dfrac{\pi}{3}=2\pi+2\theta+\pi+2\theta$$ $$-\dfrac{8\pi}{3}=4\theta$$ $$-\dfrac{2\pi}{3}=\theta$$ But it is not the range of $\theta$ we assumed Case $2$ : $2\theta\in\left(-\dfrac{\pi}{2},0\right]$ , $\theta\in\left(-\dfrac{\pi}{4},0\right]$ $$\dfrac{\pi}{3}=-2\theta+2\theta$$ $$\dfrac{\pi}{3}=0 \text { not possible }$$ Case $3$ : $2\theta\in\left(0,\dfrac{\pi}{2}\right)$ , $\theta\in\left(0,\dfrac{\pi}{4}\right)$ $$\dfrac{\pi}{3}=2\theta+2\theta$$ $$\dfrac{\pi}{12}=\theta$$ It is coming in the range of $\theta$ , so its a valid solution. $$\tan^{-1}x=\dfrac{\pi}{12}$$ $$x=\tan\dfrac{\pi}{12}$$ $$x=2-\sqrt{3}$$ Case $4$ : $2\theta\in\left(\dfrac{\pi}{2},\pi\right)$ , $\theta\in\left(\dfrac{\pi}{4},\dfrac{\pi}{2}\right)$ $$\dfrac{\pi}{3}=2\pi-2\theta+2\theta-\pi$$ $$\dfrac{\pi}{3}=\pi \text { not possible }$$ So only solution is $2-\sqrt{3}$ , but actual answer is $2-\sqrt{3}, \sqrt{3}$","['trigonometry', 'functions']"
3442126,A little game with rolling a fair dice,"You play the following game: you roll a fair dice then either you stop rolling and take the sum of the rolled numbers so far or you continue rolling the dice. Any time if a 1 is rolled you lose all your money, and has no option to continue the game. The strategy that you follow is that you wait until the cumulated price reaches a given level and then you stop. What should be this level in order to maximize the expected value of the prize? My answer is 20...is it correct?","['expected-value', 'optimization', 'dice', 'probability']"
3442150,Equivalent of a recursively defined sequence,Let $u_n$ the real sequence defined by $u_0=1$ and $$u_n=\frac{1}{n}\sum_{k=0}^{n-1} \frac{u_k}{n-k}.$$ The goal is to show that there exists $C>0$ such that $u_n \sim C/n^2$ . I am only able to prove that $u_n =O(\log(n)/n^2)$ . I tried to use an approached based on Cauchy product of power series but it failed.,"['sequences-and-series', 'asymptotics', 'real-analysis']"
3442161,My textbook says that $f(x)$ and $\sqrt{f(x)}$ have the same period. Why isn't this true for $\sin x$ and $\sin^2x$?,It says on my textbook that the period of $f(x)$ is the same as the period of $\sqrt{f(x)}$ . Then why isn't the period of $\sin x$ the same as $\sin^2x$ ? I don't know what I'm missing. Am I right in assuming that the square root of $\sin^2x$ is $\sin x$ ?,"['trigonometry', 'functions']"
3442166,Is $y'=y^2$ Lipschitz?,"I was given an example of the use of a function been Lipschitz to show that an ODE as a unique sloution $$
\begin{cases}
y'=y^2\\
y(0)=1\\
\end{cases}
$$ now the solution is $y=\frac{1}{x+1}$ but how could we check that the function is Lipschitz without solving the ODE? If we take $y=\frac{1}{x+1}$ and evaluate $y'=\frac{-1}{(x+1)^2}$ we can see that $|\frac{-1}{(x+1)^2}|=\frac{1}{(1+x)^2}\leq 1$","['lipschitz-functions', 'ordinary-differential-equations']"
3442208,Limit of the series $\lim_{n \to \infty} \frac{1}{n^2} \sum_{k=1}^{n-1} \csc\left(\frac{k\pi}{n}\right)$.,Does the following limit exist? $$\lim_{n \to \infty} \frac{1}{n^2} \sum_{k=1}^{n-1} \csc\left(\frac{k\pi}{n}\right)$$ I've computed the value for a few $n$ and it seems that the limit is zero. Any idea on how to prove this rigorously? The problem arises from electrostatics when computing the forces on point charges arranged in a ring.,"['limits', 'calculus', 'sequences-and-series', 'real-analysis']"
3442299,Bijection between sets,"Let $A= \{$ $F$ $|$ $F$ $:$ $\mathbb{R}$ $\rightarrow \mathbb{R}$ $\}$ . Prove that a bijection does not exist between $A$ $and$ $\mathbb{R}$ The idea I have is to show that a bijection between $A$ $and$ $P(\mathbb{R})$ exists. This is because if $A\sim$ $P(\mathbb{R})$ and since no bijection between $P(\mathbb{R})$ and $\mathbb{R}$ exists, then no bijection could exist between $A$ and $\mathbb{R}$ . However, im not sure what bijection to set up. What could I do? any hints? The idea I had was to set up a bijection $f: P(\mathbb{R}) \rightarrow A$ to be  defined as $f(A)=g_A$ where $g_A : \mathbb{R}\rightarrow A$ However, i'm not on the right track, as the map I attempted to construct is not well defined.","['elementary-set-theory', 'real-analysis']"
3442300,Decide whether a sequence converges or not,"There is a sequence $(a_{n})_n$ defined by relation: $a_{1} = 3 $ $2^{a_2} = 3^3$ $2^{2^{a_{3}}} = 3^{3^{3}}$ $2^{2^{2^{a_{4}}}} = 3^{3^{3^3}}$ Does $(a_{n})_n$ converge? So, I've tried to figure out what is an overall pattern for $(a_{n})_n$ . I did something like that: $a_1 = 3$ $2^{a_2} = 3^3$ $\log2^{a_2} = \log3^3$ $a_{2}\log2 = 3\log3$ $a_{2} = 3\frac{\log3}{\log2}$ But I don't know if it gets me anywhere, because I got $a_3 = \log(\frac{27}{2}\frac{\log3}{\log2})$ Have you got any idea?","['limits', 'convergence-divergence']"
3442333,When to use Pooled Variance?,"In the following examples, why is pooled variance used in the first video but not in the other? When do you use pooled variance? https://classroom.udacity.com/courses/ud257/lessons/4018018619/concepts/40043987120923 The last example in this page: https://newonlinecourses.science.psu.edu/stat414/node/306/","['experimental-mathematics', 'statistics', 'variance']"
3442337,Solving equation consisting of fractional part and greatest integer functions,"I don't understand how to go about solving $$[x]^2 = x+2\{x\}$$ where [.] and {.} denote the greatest integer and the fractional part function, respectively. I tried converting the entire equation in terms of the fractional part function, but couldn't figure out where to go from there. Also, can it be solved graphically?","['calculus', 'functions']"
3442360,What is difference between idempotent magma and unital magma?,"I don't understand well in what way idempotent element is wired to identity element in a magma context. idempotent: $x \cdot x = x$ identity element: $1 \cdot x = x = x \cdot 1$ For example subtraction has $0$ as a right identity since $x−0=x$ , but it doesn’t have a left identity. So is not a unital magma. An example of a unital magma that is neither a monoid nor a loop is given by this table but I want understand if this is or is not a idempotent semigroup $\begin{array}{c|rrrr}& 1 & a & b \\\hline {1} & 1 & a & b \\ {a} & a & 1 & a \\  {b} & b & b & a &  \end{array}$ I want understand with examples these differences an example of unital magma that is not a idempotent semigroup an example of unital magma that is not a idempotent magma an example of idempotent magma that is not an idempotent semigroup if every idempotent magma requires the identity element then is an idempotent element an identity element of itself ? I'm little confuse between idempotency and identity, I need some examples. For example, can you provide me a closed operation under some set $S$ but not associative nor commutative but with identity element ?","['magma', 'category-theory', 'idempotents', 'abstract-algebra', 'semigroups']"
3442364,Find the $\lim_{n\to\infty}\text{inf} \left(\frac {x_0^2}{ x_1}+\frac {x_1^2}{ x_2}+\cdots \frac {x_{n-1}^2}{ x_n}\right)$,"Here is my problem: If $(x_n)_{n\in\Bbb N}$ is non-increasing, $x_0=1$ and $\lim_{n\to\infty} x_n=0$ , does the following infimum exist? $$\inf_{(x_n)_{n\in\Bbb N}} \sum_{k\in\Bbb N}\frac{x_k^2}{x_{k+1}}$$ Here is the ""meat"" of my attempt: $$(a-2b)^2\geq 0$$ So we have, $$(x_i-2x_{i+1})^2\geq 0$$ $$\frac{x_i^2}{x_{i+1}} \geq 4(x_i-x_{i+1})$$ where $i=0,1,2,\cdots ,n$ $$\frac {x_0^2}{ x_1}+\frac {x_1^2}{ x_2}+\cdots \frac {x_{n-1}^2}{ x_n}\geq 4( x_0-x_1+x_1-x_2+\cdots + x_{n-1}-x_n)=4(1-x_n)$$ Finally we get, $$\lim_{n\to\infty}\text{inf} \left(\frac {x_0^2}{ x_1}+\frac {x_1^2}{ x_2}+\cdots \frac {x_{n-1}^2}{ x_n}\right) \geq \lim_{n\to\infty} 4(1-x_n)= 4$$ $$\lim_{n\to\infty}\text{inf} \left(\frac {x_0^2}{ x_1}+\frac {x_1^2}{ x_2}+\cdots \frac {x_{n-1}^2}{ x_n}\right)=4$$ Question 1: Is this solution correct? Question 2 : Is it possible to find a completely different method to solve this problem? I'm more interested in question 2. Is it possible to solve this problem with any pure calculus technique?","['contest-math', 'proof-verification', 'alternative-proof', 'calculus', 'limits']"
3442459,multivariate Ito isometry,"I wonder whether there exists a straightforward extension of the Ito isometry to multidimensional processes. In the one-dimensional case the Ito isometry can be written as $\mathbb{E}[ (\int_0^T X_t \; \mathrm{d}W_t)^2 ] = \mathbb{E}[ (\int_0^T X_t^2 \;\mathrm{d}_t) ]$ . If now $X_t$ is a vector of random variables instead, do I get something along these lines: $\mathbb{E}[ (\int_0^T X_t \; \mathrm{d}W_t) (\int_0^T X_t^\top \; \mathrm{d}W_t^\top) ] = \mathbb{E}[ (\int_0^T X_t X_t^\top \;\mathrm{d}_t) ]$ ????","['multivariable-calculus', 'stochastic-differential-equations', 'isometry', 'brownian-motion', 'stochastic-calculus']"
3442493,Geometric Numerical integration of a simple harmonic oscillator,"I have this 1D oscillator whose equations of motion is given by- $m \ddot{y}=-ky$ and when written is terms of conjugate variables $(p,q)$ in matrix form, we have $$\begin{bmatrix}\dot{q} \\ \dot{p}\end{bmatrix}=\underbrace{\begin{bmatrix}
0 & \frac{1}{m} \\ -k &0
\end{bmatrix}}_{A}\begin{bmatrix}q \\ p\end{bmatrix}$$ Now the author have presented three approaches (1) Explicit Euler : According to this form $x_{n+1}=x_n+h f(x_n)$ we have $$\begin{bmatrix}q_{n+1}\\ p_{n+1}\end{bmatrix}=\begin{bmatrix}1 & \frac{h}{m}\\-kh & 1 \end{bmatrix}\begin{bmatrix} q_n \\p_n \end{bmatrix}=\left(I+Ah \right)\begin{bmatrix}q_n \\p_n\end{bmatrix}$$ (2) Implicit Euler : with respect to the form $x_{n+1}=x_n+h f(x_{n+1})$ we have $$\begin{bmatrix}q_{n+1}\\ p_{n+1}\end{bmatrix}=\frac{1}{1+h^2\tfrac{k}{m}}\begin{bmatrix}1 & \frac{h}{m}\\-kh & 1 \end{bmatrix}\begin{bmatrix} q_n \\p_n \end{bmatrix}=\left(I-Ah \right)^{-1}\begin{bmatrix}q_n \\p_n\end{bmatrix}$$ (3) Symplectic Euler : The symplectic Euler VT $$\begin{bmatrix}q_{n+1}\\ p_{n+1}\end{bmatrix}=\begin{bmatrix}q_n+h \frac{p_{n+1}}{m} \\p_n-hkq_n \end{bmatrix}=\begin{bmatrix}1-h^2\frac{k}{m} & \frac{h}{m}\\-kh & 1 \end{bmatrix}\begin{bmatrix} q_n \\p_n \end{bmatrix}$$ and the symplectic Euler TV : $$\begin{bmatrix}q_{n+1}\\ p_{n+1}\end{bmatrix}=\begin{bmatrix}q_n+h \frac{p_{n}}{m} \\p_n-hkq_{n+1} \end{bmatrix}=\begin{bmatrix}1 & \frac{h}{m}\\-kh & 1-h^2\frac{k}{m} \end{bmatrix}\begin{bmatrix} q_n \\p_n \end{bmatrix}$$ All of these are okay so far, now the author claims for following differential equations-- $(1)~~\dot{q}=p+\frac{h}{2}q~,~\dot{p}=-q+\frac{h}{2}p~~(2)~~ \dot{q}=p-\frac{h}{2}q~,~\dot{p}=-q+\frac{h}{2}p$ $(3)~~\dot{q}=p-\frac{h}{2}q~,~\dot{p}=-q-\frac{h}{2}p ~~(4)~~\dot{q}=p+\frac{h}{2}q~,~\dot{p}=-q-\frac{h}{2}p$ with $k=m=1$ the exact solutions of (1) and (3) will follow the numerical solutions obtained by explicit and implicit euler methods, and solutions of (2) and (4) follows the results of symplectic euler methods. I'm not able to understand from where the differential equations are arising and how their exact solutions replicate the numerical euler solutions ?","['classical-mechanics', 'numerical-methods', 'control-theory', 'ordinary-differential-equations']"
3442566,"Irreducible representations of a semidirect product, proof in Serre","Let $H$ and $N$ be groups, where $N$ is abelian. Suppose that $H$ acts on $N$ by automorphisms, and consider the semidirect product $G=H\ltimes N$ . I am busy classifying all irreducible representations of $G$ , as in Section 8.2 by Serre. Since $H$ acts on $N$ , $H$ also acts on the character group $\widehat{N}$ by $(h\cdot\chi)(n)=\chi(\phi_{h^{-1}}(n))$ . Let $(\chi_i)_{1\leq i\leq k}$ be representatives of the orbits of the $H$ -action. For each $i$ , let $H_i$ denote the stabilizer subgroup of $\chi_i$ and define $G_i=H_i\ltimes N$ as a normal subgroup of $G$ . The function $\chi_i^\circ:G_i\to\mathbb{C}$ given by $\chi_i^\circ(h,n)=\chi_i(n)$ is a linear representation of $G_i$ since $H_i$ stabilizes $\chi_i$ . Now, let $\rho$ be any irreudcible representation of $H_i$ , and define $\tilde{\rho}$ to be the irreducible representation of $G_i$ given by $\rho\circ pr_{H_i}$ , where $Pr_{H_i}$ is the natural projection on $H_i$ . Then define the representation $\theta_{i,\rho}$ of $G$ by $\theta_{i,\rho}=\text{Ind}_{G_i}^G(\tilde{\rho}\otimes\chi_i^\circ)$ . By Mackey's irreducibility criterion, each $\theta_{i,\rho}$ is irreducible. Also, $$
\sum_{i=1}^k\sum_{\rho\in S_i}\dim(\theta_{i,\rho})^2=|G|,
$$ where $S_i$ is the set of isomorphism classes of irreducible representations of $H_i$ . To know that I have really classified all irreducible representations of $G$ , I need to prove that if $\theta_{i,\rho}\cong\theta_{i',\rho'}$ , then $i=i'$ and $\rho\cong\rho'$ . There is a proof of this in Serre (Proposition 25 $ii$ ), but I don't understand what is going on. Can anyone explain the proof in more detail? I also tried to come up with my own proof, but it seems to break down. I tried to use character theory. First, I followed Serre's argument to show that $i=i'$ . To show that $\rho$ and $\rho'$ are isomorphic, we show that their characters agree. Let $\chi_{\theta_{i,\rho}}$ and $\chi_{\theta_{i,\rho'}}$ denote the characters of $\theta_{i,\rho}$ and $\theta_{i,\rho'}$ . Since these are isomorphic, we know that $\chi_{\theta_{i,\rho}}=\chi_{\theta_{i,\rho'}}.$ Since $G_i$ is a normal subgroup of $G$ , we have that $$
\chi_{\theta_{i,\rho}}(h',n')=\frac{1}{|G_i|}\sum_{(h,n)\in G}\chi_i^\circ\big((h,n)^{-1}(h',n')(h,n)\big)\chi_{\tilde{\rho}}\big((h,n)^{-1}(h',n')(h,n)\big)=\frac{1}{|G_i|}\sum_{(h,n)\in G}\chi_i^\circ\big((h,n)^{-1}(h',n')(h,n)\big)\chi_{\rho}(hh'h^{-1})$$ and $$
\chi_{\theta_{i,\rho'}}(h',n')=\frac{1}{|G_i|}\sum_{(h,n)\in G}\chi_i^\circ\big((h,n)^{-1}(h',n')(h,n)\big)\chi_{\tilde{\rho}'}\big((h,n)^{-1}(h',n')(h,n)\big)=\frac{1}{|G_i|}\sum_{(h,n)\in G}\chi_i^\circ\big((h,n)^{-1}(h',n')(h,n)\big)\chi_{\rho'}(hh'h^{-1})
$$ I am stuck on what to do next, since I can't simply simplify $\chi_\rho(hh'h^{-1})=\chi_\rho(h')$ . Thanks in advance for the time","['semidirect-product', 'group-theory', 'group-isomorphism', 'representation-theory']"
3442609,2-Wasserstein distance between normal distribution and other distribution,"For 2-Wasserstein distance between two normal distributions, there is a nice closed-form formula . Now, I want to find the distance between a normal distribution $\mathcal{N}(\mu, \sigma^2)$ and, say, an exponential distribution $\exp(\lambda)$ . There's a formula to calculate the 2-Wasserstein distance between continuous one dimensional distributions. However, it involves integral over the inverse CDF of a random variable, which cannot be computed for normal distribution. If I follow the definition of Wasserstein distance, then the problem is about maximizing $E[XY]$ , for which I have no clue about how to solve. I want to ask: is there a way to compute 2-Wasserstein distance between normal distribution and other continuous random variable, say something from exponential family? Is it possible to generalize the computation to high-dimensional distributions? Any suggestion is appreciated. Thanks!","['statistics', 'probability-distributions', 'optimal-transport', 'probability']"
3442620,Matrix Differentiation of Generative Neural Network,"I wish to construct a neural network (restricted Boltzmann Machine) with network parameter set $\Omega$ that will minimise the cost function, \begin{equation}
\mathcal{C}(\Omega) = -\text{Tr}\big[A\log(B_\Omega)\big] 
\end{equation} where $B_\Omega$ is a Hermitian, postive semi-definite matrix generated by the neural network, and $A$ is a fixed Hermitian, postive semi-definite matrix. Due to the $\log(\cdot)$ , this appears very tricky. How do I take derivates of this cost function with respect to an arbitrary parameter $\Omega_i$ of the network? Is this out of reach analytically and perhaps automatic differentiation is a better approach?","['optimization', 'matrix-calculus', 'derivatives', 'neural-networks']"
3442634,The cup product of etale cohomology,"This is written in Fu Lei's ""Etale cohomology theory"", p362. Let $X$ be a scheme, $A$ a ring, $\mathscr{F,G}$ a sheaf of $A$ -modules on $X$ , $\mathscr{C^\bullet(F), C^\bullet(G)}$ be Godement resolutions, and let $\mathscr{C^\bullet(F)} \otimes_A \mathscr{C^\bullet(G)} \to \mathscr{I}^\bullet$ be a quasi-isomorphism.
Suppose that $\mathbb{R}^+\Gamma$ has finite cohomological dimension. Then we have a canonical map $\mathbb{R}\Gamma(X, \mathscr{F}) \otimes_A^{\mathbb{L}^-} \mathbb{R}\Gamma(X, \mathscr{G}) \to \mathbb{R}\Gamma(X, \mathscr{F} \otimes_A \mathscr{G})$ as follows: $$
\mathbb{R}\Gamma(X, \mathscr{F}) \otimes_A^{\mathbb{L}^-} \mathbb{R}\Gamma(X, \mathscr{G}) \cong \Gamma(X, \mathscr{C^\bullet(F)}) \otimes_A^{\mathbb{L}^-} \Gamma(X, \mathscr{C^\bullet}(G)) \\
\to \Gamma(X, \mathscr{C^\bullet(F)}) \otimes_A \Gamma(X, \mathscr{C^\bullet}(G)) \\
\to \Gamma(X, \mathscr{C^\bullet(F)} \otimes_A\mathscr{C^\bullet}(G)) \\
\to \Gamma(X, \mathscr{I^\bullet}) \cong \mathbb{R}\Gamma(X, \mathscr{F} \otimes_A \mathscr{G}).
$$ Why does this induce $H^i(X, \mathscr{F}) \otimes_A H^j(X, \mathscr{G}) \to H^{i+j}(X, \mathscr{F} \otimes_A \mathscr{G})$ ? To say $H^n(\mathbb{R}\Gamma(X, \mathscr{F}) \otimes_A^{\mathbb{L}^-} \mathbb{R}\Gamma(X, \mathscr{G})) \cong \oplus_{i+j=n} H^i(X, \mathscr{F}) \otimes_A H^j(X, \mathscr{G})$ , $\mathscr{F,G}$ have to satisfy some additional conditions.
But the author says this map is defined in general. Thank you very much!","['etale-cohomology', 'homological-algebra', 'derived-categories', 'algebraic-geometry', 'homology-cohomology']"
3442650,"Prove that if $f(x) = \frac{\sqrt{x} - \sqrt{a}}{x-a}$, then $f$ has a limit at a.","Prove that if $f(x) = \frac{\sqrt{x} - \sqrt{a}}{x-a}$ , then $f$ has a limit at a. I have written a very basic level proof here: Given $\epsilon > 0$ , we want $\delta > 0$ such that $|(\frac{1}{\sqrt{x} + \sqrt{a}}) - (\frac{1}{2\sqrt{a}})| < \epsilon$ whenever $0<|x - a|<\delta$ . So for $\delta = g(\epsilon)$ , $0<|x - a|<\delta \implies |(\frac{1}{\sqrt{x} + \sqrt{a}}) - (\frac{1}{2\sqrt{a}})| < \epsilon$ . I tried and failed to find a way to represent delta in terms of epsilon. Saying, $\delta = g(\epsilon)$ , is wrong. I saw some examples where they set $\delta=1$ and the used the $min$ function. I tried this but was not successful. Edit: I need to find an answer using the epsilon-delta form. just solving for the limit is not sufficient. Anyone have any tips?","['limits', 'epsilon-delta', 'real-analysis']"
3442726,The spectrum of the Volterra operator is $\{0\}$,"I'm asked to prove that the spectrum of the Volterra operator $$V(f(x))= \int_0^x f(y)dy$$ given by $$ \sigma (V)= \{ \lambda \in \mathbb{C} | V-\lambda1 \text{ is not invertible} \}$$ contains only zero.
This needs to be done by first showing that $0 \in \sigma (V)$ and then that all other complex numbers cannot belong to the spectrum. I don't see how to prove either one of those steps so any hints would really help.","['operator-theory', 'functional-analysis']"
3442837,Show that every locally compact Hausdorff space is regular.,"I have read through answers on this site and they all seem to rely on using the one-point compactification to prove that locally compact Hausdorff spaces are in fact completely regular. I would like to instead prove it more directly from the definition, using this lemma: Let $X$ be a Hausdorff space. Then $X$ is locally compact iff for any given $x\in X$ and a neighborhood $U$ of $x$ , there is a neighborhood $V$ of $x$ such that $\overline V$ is compact and $\overline V\subset U$ . Now, we must show that given $x\in X$ and $A$ closed in $X$ with $x\notin A$ , that there exist disjoint neighborhoods $U$ and $V$ that contain $x$ and $A$ , respectively. I am not sure how to proceed. I know that compact sets in a Hausdorff space are closed, and that seems important in the proof, but I don't know how to use that fact. Any hints would be appreciated.","['general-topology', 'compactness']"
3442861,Find $\lim\limits_{n \to \infty} \sqrt[3]{n^3+2n^2+1}-\sqrt[3]{n^3-1}$.,"I have to find the limit: $$\lim\limits_{n \to \infty} \sqrt[3]{n^3+2n^2+1}-\sqrt[3]{n^3-1}$$ I tried multiplying with the conjugate of the formula: $$(a-b)(a^2+ab+b^2)=a^3-b^3$$ So I got: $$\lim\limits_{n \to \infty} \dfrac{n^3+2n^2+1-n^3+1}{\sqrt[3]{(n^3+2n^2+1)^2} + \sqrt[3]{(n^3+2n^2+1)(n^3-1)} + \sqrt[3]{(n^3-1)^2}}$$ $$\lim\limits_{n \to \infty} \dfrac{2n^2+2}{\sqrt[3]{n^6+4n^5+4n^4+2n^3+4n^2+1} + \sqrt[3]{n^6+2n^5-2n^2-1} + \sqrt[3]{n^6-2n^3+1}}$$ And I saw that we can factor $n^2$ in the denominator and if we do the same in the numerator, we'd get that the limit is equal to $2$ . The problem is that my textbook claims that this limit is actually $\dfrac{2}{3}$ . I don't see why should I have a $3$ in the denominator since the coefficient of $n^2$ would be $1$ if I would carry out the factoring to detail. So, what did I do wrong?","['limits', 'calculus']"
3442896,Why is the fiber product $X \times_s S$ isomorphic to $X$ itself?,"This might be a silly question but I am new to do this and would be appreciated for your help. Suppose $X$ is an $S$ -scheme, say we have structure morphisms $f:X \rightarrow S$ and $\text{Id}:S\rightarrow S$ . Why is $X \times_s S \cong X$ ? The definition of fibered product I am using is:
A triple $(Z,p,q)$ where $h:Z \rightarrow S$ is an $S$ -scheme and morphisms of $S$ -schemes $p:Z\rightarrow X$ and $q:Z\rightarrow Y$ is called a fiber product if for every $S$ -scheme $T$ , a mapping of sets $$\text{Hom}_S(T,Z)\rightarrow \text{Hom}_S(T,X) \times \text{Hom}_S(T,Y)$$ is bijective. So in this case I need to show $$\text{Hom}_S(T,X)\rightarrow \text{Hom}_S(T,X) \times \text{Hom}_S(T,S)$$ is a bijection, but why is this true?","['algebraic-geometry', 'schemes']"
3442915,"Limit of Product of Monomials, Specifically $\prod_{i=1}^{n}(x+i)$","If $$p_n(x)=\prod_{i=1}^{n}(x+i)$$ then what is the order of the power of $x$ (with respect to $n$ ) with the greatest coefficient for the following polynomial? $$\lim_{n \to \infty} p_n(x)$$ I plugged in some small values of $n$ and saw that the desired power tends to hang within the smaller powers of $x$ (for example, $p_4(x)=x^4 + 10 x^3 + 35 x^2 + 50 x + 24$ , so the power of $x$ with the greatest coefficient is $1$ ), but I don't know enough about infinite polynomials to make any sort of generalization. Also, I know that the power goes to infinity as $n$ goes to infinity, what I want to know is the order of the power relative to $n$ - is it $\sqrt{n}$ ? $\ln(n)$ ? $n^{\frac{1}{e}}$ ? That sort of thing.","['infinite-product', 'limits', 'polynomials']"
3442952,Representing a unit speed curve on a general surface in terms of its Frenet Frame,"This question grew out of a research project in which I am an active participant, a project which curiously enough requires a hefty dose of the theory of curves and surfaces in $\Bbb R^3$ . I needn't go into more detail here. One of my colleagues in said endeavor noticed that a previous answer of mine, given in response to a question by Helen Waters, presented results which were very illuminating to his own work.  The question to which I  refer is: Representing a unit speed curve on a sphere in terms of its Frenet Frame . In point of fact, similar questions have been posed more than once here on math.stackexchange.com; but this particular one became the object of my colleague's attention, discovered by googling around. In the course of our work it became clear that a generalization of this question and its answer is also of significant importance to us.  I pose the generalized question here, and present my answer below. A unit speed curve $\alpha(s)$ , where $s$ as usual denotes arc-length, which lies on a sphere of radius $r$ centered at a point $c \in \Bbb R^3$ satisfies an equation of the form $(\alpha(s) - c) \cdot (\alpha(s) - c) = r^2; \tag 1$ if we differentiate this equation with respect to $s$ and recall that the unit tangent vector $T(s)$ to $\alpha(s)$ is given by $T(s) = \dot \alpha(s), \tag 2$ we obtain $T(s) \cdot (\alpha(s) - c) = 0; \tag 3$ successive differentiation of this formula with respect to $s$ yields the results of the answer to the cited question; the engaged reader my consult it to see the details. As indicated in the title, I seek here to broaden the result given in the above link to more general, not-necessarily spherical surfaces.  To this end we note that, just as a patch on the sphere of radius $r$ centered at $c \in \Bbb R^3$ may be represented as as a $2$ -parameter vector function $\mathbf r(u, v) \in \Bbb R^3$ such that $(\mathbf r(u, v) - c) \cdot (\mathbf r(u, v) - c) = r^2, \tag 4$ so a general surface patch $\mathcal S$ in $\Bbb R^3$ may be represented by a vector function $\mathbf r(u, v)$ , but sans the constraint (4).  When (4) no longer applies, we may consider the role of $\delta(s)$ , where $\delta^2(s) = \mathbf r(u(s), v(s)) \cdot \mathbf r(u(s), v(s)) = \alpha(s) \cdot \alpha(s) \tag 5$ is the squared magnitude of $\mathbf r(s)$ , i.e., $\delta(s)$ is the distance of $\alpha(s)$ from the coordinate origin $O$ ; here $(u(s), v(s))$ is the path $\alpha(s)$ takes in terms of the patch coordinates $u$ and $v$ . Seen from this point of view, what I wish to ask becomes: The Question: Given a surface patch $\mathcal S$ specified by a vector function $\mathbf r(u, v)$ of two parameters $u$ and $v$ , and a unit speed curve $\alpha(s)$ with differentiable non-vanishing curvature and non-vanishing torsion in $\mathcal S$ , express $\alpha(s) = \mathbf r(u(s), v(s)) \tag 6$ in terms of the Frenet Frame of $\alpha(s)$ and the function $\delta(s)$ .","['curves', 'surfaces', 'differential-geometry']"
3442964,Find the kernel and range of the linear operator $Kf(x) = \int_0^1 \sin \pi (x-y) f(y)dy$,"The question is the following Find the kernel and range of the linear operator $K : C([0,1]) \to C([0,1])$ defined by $$
Kf(x) = \int_0^1 \sin (\pi (x-y)) f(y)dy
$$ For the kernel, I tried to solve $$
Kf(x) = \int_0^1 \sin (\pi x) \cos(\pi y)f(y)dy - \int_0^1\sin (\pi y) \cos(\pi x)f(y)dy = 0
$$ and I can't proceed further. And I have no idea how to find the range. Any hint or help is appreciated!","['functional-analysis', 'real-analysis']"
3443071,Stability without Lyapunov methods,"I've been having some problems trying to solve a problem which appears in the book im following, so any help would be really appreciated. Defn. A fixed point $x_{0}$ is asymptotically stable if it is stable and (1) if there is a neighborhood $U$ , s.t. $x_{0} \in U$ and $|\phi(t,x)-x_{0} | \rightarrow 0$ as $t \rightarrow \infty$ . Problem. let $\dot x = x - y - x(x^{2}+y^{2}) + \frac{xy}{\sqrt{x^{2}+y^{2}}}$ and $\dot y = x + y - y(x^{2}+y^{2}) - \frac{x^{2}}{\sqrt{x^{2}+y^{2}}}$ . I have to show that $(1,0)$ is not stable even though it satisfies (1) . My solution . First, I change the cartesian coord. to polar coordinates. Then our new system is $\dot r = r-r^{3}$ and $\dot \theta = 2sin^{2}(\theta/2)$ . The point we're studying stays the same after the transformation, $(r,\theta)=(1,0)$ . Now, my problems begin, I tried to apply the linearization theorem and we got that our Jacobian Matrix will be \begin{bmatrix}1-3r^{2}&0\\0&2sin(\theta/2)cos(\theta/2)\end{bmatrix} and evaluating $(1,0)$ \begin{bmatrix}-2&0\\0&0\end{bmatrix} then its eigenvalues are $\lambda_{1,2}=-2,0$ and this implies that this is no good por my analysis cause we can say nothing ( right? ). And if we could say that it is unstable by this analysis, I havent been able to prove that (1) holds. The other way I think we could prove this is by definition directly, but since I couldn't find the flow for the ODE I cant try the definitions. So if you guys could help me with it I'd more than glad. Thanks so much in advance, I really appreciate it. <3","['ordinary-differential-equations', 'stability-in-odes', 'calculus', 'stability-theory', 'dynamical-systems']"
3443076,What graph with 7 vertices that doesn't contain $K_3$ as subgraph has the maximal number of edges?,"is there graph with vertices 7 that not contain $K_3$ as subgraph and have biggest edge? is this question trying to ask to remove all triangle in K7 graph? for this problem , is this possible to solve like this $\frac{7.6}{2}-\frac{3.2}{2}=18 edges$ but ofourse it contain triangle(?) here is the possible graph that i can think of.. edit: i think once again that, biggest one is bipartite graph, such as $K_{3,4}$ with 12 edges and 7 vertices .(?)","['graph-theory', 'discrete-mathematics']"
3443082,Find all positive integral solutions of $\tan^{-1}x+\cos^{-1}\frac{y}{\sqrt{y^2+1}}=\sin^{-1}\frac{3}{\sqrt{10}}$,"Find all the positive integral solutions of, $\tan^{-1}x+\cos^{-1}\dfrac{y}{\sqrt{y^2+1}}=\sin^{-1}\dfrac{3}{\sqrt{10}}$ Assuming $x\ge1,y\ge1$ as we have to find positive integral solutions of $(x,y)$ $$\tan^{-1}x=\tan^{-1}3-\tan^{-1}\dfrac{1}{y}$$ As $3>0$ and $\dfrac{1}{y}>0$ $$\tan^{-1}x=\tan^{-1}\left(\dfrac{3-\dfrac{1}{y}}{1+\dfrac{3}{y}}\right)$$ $$\tan^{-1}x=\tan^{-1}\dfrac{3y-1}{y+3}$$ $$x=\dfrac{3y-1}{y+3}$$ $y+3\in[4,\infty)$ as $y\ge1$ , $3y-1\in [2,\infty)$ as $y\ge1$ For $x$ to be positive integer, $3y-1$ should be multiple of $y+3$ $$3y-1=m(y+3) \text { where } m\in Z^{+}$$ $$3y-my=3m-1$$ $$(3-m)y=3m-1$$ Here R.H.S is positive, so L.H.S should also be positive. So $3-m>0$ , hence $m<3$ So possible values of $m$ are { $1$ , $2$ }. For $m=1$ , $$3y-1=y+3$$ $$2y=4$$ $$y=2$$ $$x=\dfrac{3\cdot2-1}{2+3}$$ $$x=1$$ For $m=2$ , $$3y-1=2(y+3)$$ $$3y-1=2y+6$$ $$y=7$$ $$x=\dfrac{3\cdot7-1}{7+3}$$ $$x=\dfrac{20}{10}$$ $$x=2$$ Is there some other nicer way to solve this problem.",['trigonometry']
3443092,For which $n$ can the plane with $n$ points removed be equipped with a Lie group structure?,"Let $X=\mathbb{R}^2-\{p_1, p_2,..., p_n\}$ , then if $n=0$ then clearly $X=\mathbb{R}^2$ is a Lie group under addition. If $n=1$ , then $X=\mathbb{R}^2-\{p_1\}$ is isomorphic to $\mathbb{C}\setminus\{0\}$ which has a Lie group structure under multiplication. But I don't know how to proceed in the case in which $n>1$ . I have thought of using that the tangent bundle of a Lie group is trivial but I don't know how to do this. I would appreciate any help or suggestions. Thank you.","['lie-algebras', 'vector-bundles', 'abstract-algebra', 'lie-groups', 'differential-geometry']"
3443094,"If $\lim_{x\to 0}\frac{ae^x-b}{x}=2$ the find $a,b$","If $$\lim_{x\to 0}\frac{ae^x-b}{x}=2$$ the find $a,b$ $$
\lim_{x\to 0}\frac{ae^x-b}{x}=\lim_{x\to 0}\frac{a(e^x-1)+a-b}{x}=\lim_{x\to 0}\frac{a(e^x-1)}{x}+\lim_{x\to 0}\frac{a-b}{x}=\boxed{a+\lim_{x\to 0}\frac{a-b}{x}=2}\\
\lim_{x\to 0}\frac{a-b}{x} \text{ must be finite}\implies \boxed{a=b}\\
$$ Now I think I am stuck, how do I proceed ?","['limits', 'exponential-function']"
3443114,Where am I going wrong in calculating the projection of a vector onto a subspace?,"I am currently working my way through Poole's Linear Algebra, 4th Edition , and I am hitting a bit of a wall in regards to a particular example in the chapter on least squares solutions. The line $y=a+bx$ that ""best fits"" the data points $(1,2)$ , $(2,2)$ , and $(3,4)$ can be related to the (inconsistent) system of linear equations $$a+b=2$$ $$a+2b=2$$ $$a+3b=4$$ with matrix representation $$A\mathbf{x}=\begin{bmatrix}1&1\\1&2\\1&3\\\end{bmatrix}\begin{bmatrix}a\\b\\\end{bmatrix}=\begin{bmatrix}2\\2\\4\\\end{bmatrix}=\mathbf{b}$$ Using the least squares theorem, Poole shows that the least squares solution of the system is $$\overline{\mathbf{x}}=\left(A^T A \right)^{-1} A^T \mathbf{b}=\left(\begin{bmatrix}3&6\\6&14\\\end{bmatrix}\right)^{-1}\begin{bmatrix}8\\18\\\end{bmatrix}=\begin{bmatrix}\frac{7}{3}&-1\\-1&\frac{1}{2}\\\end{bmatrix}\begin{bmatrix}8\\18\\\end{bmatrix}=\begin{bmatrix}
\frac{2}{3}\\1\\\end{bmatrix}$$ so that the desired line has the equation $y=a+bx=\frac{2}{3} +x$ . The components of the vector $\overline{\mathbf{x}}$ can also be interpreted as the coefficients of the columns of $A$ in the linear combination of the columns of $A$ that produces the projection of $\mathbf{b}$ onto the column space of $A$ [which the Best Approximation Theorem identifies as the best approximation to $\mathbf{b}$ in the subspace $\mathrm{col}(A)$ ]. In other words, the projection of $\mathbf{b}$ onto $\mathrm{col}(A)$ can be found from the coefficients of $\overline{\mathbf{x}}$ by $$\mathrm{proj}_{\mathrm{col}(A)}(\mathbf{b})=\frac{2}{3}\begin{bmatrix}1\\1\\1\\\end{bmatrix}+1\begin{bmatrix}1\\2\\3\\\end{bmatrix}=\begin{bmatrix}\frac{5}{3}\\\frac{8}{3}\\\frac{11}{3}\\\end{bmatrix}$$ But when I try to calculate $\mathrm{proj}_{\mathrm{col}(A)}(\mathbf{b})$ directly [taking $\mathbf{a}_{1}$ and $\mathbf{a}_{2}$ to be the first and second columns of $A$ , respectively], I get $$\mathrm{proj}_{\mathrm{col}(A)}(\mathbf{b})=\left(\frac{\mathbf{a}_{1}\cdot\mathbf{b}}{\mathbf{a}_{1}\cdot\mathbf{a}_{1}}\right)\mathbf{a}_{1}+\left(\frac{\mathbf{a}_{2}\cdot\mathbf{b}}{\mathbf{a}_{2}\cdot\mathbf{a}_{2}}\right)\mathbf{a}_{2}=\left(\frac{\begin{bmatrix}1\\1\\1\\\end{bmatrix}\cdot\begin{bmatrix}2\\2\\4\\\end{bmatrix}}{\begin{bmatrix}1\\1\\1\\\end{bmatrix}\cdot\begin{bmatrix}1\\1\\1\\\end{bmatrix}}\right)\begin{bmatrix}1\\1\\1\\\end{bmatrix}+\left(\frac{\begin{bmatrix}1\\2\\3\\\end{bmatrix}\cdot\begin{bmatrix}2\\2\\4\\\end{bmatrix}}{\begin{bmatrix}1\\2\\3\\\end{bmatrix}\cdot\begin{bmatrix}1\\2\\3\\\end{bmatrix}}\right)\begin{bmatrix}1\\2\\3\\\end{bmatrix}$$ $$=\frac{8}{3}\begin{bmatrix}1\\1\\1\\\end{bmatrix}+\frac{18}{14}\begin{bmatrix}1\\2\\3\\\end{bmatrix}=\begin{bmatrix}\frac{8}{3}\\\frac{8}{3}\\\frac{8}{3}\\\end{bmatrix}+\begin{bmatrix}\frac{9}{7}\\\frac{18}{7}\\\frac{27}{7}\\\end{bmatrix}=\begin{bmatrix}\frac{83}{21}\\\frac{110}{21}\\\frac{137}{21}\\\end{bmatrix}$$ I am quite confident that my calculation is incorrect, for a number of reasons. For example, when I take the component of $\mathbf{b}$ orthogonal to $\mathrm{col}(A)$ $$\mathrm{perp}_{\mathrm{col}(A)}(\mathbf{b})=\mathbf{b}-\mathrm{proj}_{\mathrm{col}(A)}(\mathbf{b})=\begin{bmatrix}2\\2\\4\\\end{bmatrix}-\begin{bmatrix}\frac{83}{21}\\\frac{110}{21}\\\frac{137}{21}\\\end{bmatrix}=\begin{bmatrix}-\frac{41}{21}\\-\frac{68}{21}\\-\frac{53}{21}\\\end{bmatrix}$$ I get a vector that is not perpendicular to either $\mathbf{a}_{1}$ or $\mathbf{a}_{2}$ , indicating that this vector is not in the orthogonal complement of $\mathrm{col}(A)$ . Can somebody help me identify where I'm going wrong in my attempt to calculate the projection of $\mathbf{b}$ onto $\mathrm{col}(A)$ ?","['projection', 'vectors', 'orthogonality', 'least-squares', 'linear-algebra']"
3443141,distinct eigenvalues of adjacency matrix imply abelian automorphism group,"I'm trying to understand if my proof of the statement in the title is correct. I am in doubt since my argument implies a stronger conclusion. Here is my reasoning: Let $A$ be the adjacency matrix of a graph $G$ with the mentioned properties. The automorphism group of G is isomorphic to the group of permutation matrices That satisfy $\sigma A\sigma^t = A$ . Since $A$ is symmetric, then by the spectral theorem it is unitarily diagonalizable, i.e, $A = UDU^t$ for some unitary matrix $U$ . Then $$ \sigma UDU^t \sigma = UDU$$ $$ U^t \sigma U D U^t \sigma^t U = U^tUDU^tU = D.$$ since $U$ is unitary, $U^t (\sigma U)$ is also some permutation matrix. But since all entries of $diag(D)$ are distinct, it must be that $U^t\sigma U = I$ . This means that the automorphism group is {1}. I appreciate any help, thanks!","['graph-theory', 'group-theory', 'linear-algebra']"
3443146,composite of exponential function,"Use the definition that $\exp(x) = \sum^{\infty}_{n=0}\frac{x^n}{n!}$ , show that $\exp\left(\sum^{\infty}_{n=1}\frac{t^n}{n} \right) = \frac{1}{1-t}$ $\forall t \in (-1,1)$ . (I cannot use integrals in this question). My attempt: $$
\exp\left(\sum^{\infty}_{n=1}\frac{t^n}{n} \right) = \exp(t)\exp(t^2/2)\exp(t^3/3)\cdots = \sum^{\infty}_{n=0}\frac{t^n}{n!} + \sum^{\infty}_{n=0}\frac{t^{2n}}{2n!} \cdots
$$ Not sure how to combine the sum to get a geometric series. Any idea?","['sequences-and-series', 'exponential-function', 'real-analysis']"
3443147,Sum of Scaled Harmonic Numbers,"I came across the following identity: $$
\frac{1}{n}\sum_{j=1}^{n}\sum_{k=j}^{n}\frac{1}{k}=1.
$$ However, I do not know how to prove it except verify it by numerical calculations.
Does any one know how to prove it or give me some hints? Thanks very much.","['harmonic-numbers', 'summation', 'sequences-and-series']"
3443163,Counterexample around Dini's Theorem,"""Give an example of an increasing sequence $(f_n)$ of bounded continuous functions from $(0,1]$ to $\mathbb{R}$ which converge pointwise but not uniformly to a bounded continuous function $f$ and explain why Dini's Theorem does not apply in this case"" So clearly Dini's Theorem does not apply, as $(0,1]$ is not a closed interval (or compact metric space), but I can't figure out an example. My first thought is $f_n(x)=\frac{1}{x^n}$ , but this does not converge pointwise to a bounded continuous function, as $x=1$ is in the interval My second thought is $f_n(x)=x^\frac{1}{n}$ . This is clearly an increasing sequence of bounded continuous functions (I think?) I believe this converges pointwise to $f(x)=1$ for all $x\in (0,1]$ , but I'm struggling to then show why this doesn't converge uniformly to $f(x)=1$ How would I do this? Or is then an easier/better example I could use?","['pointwise-convergence', 'functional-analysis', 'uniform-convergence', 'metric-spaces']"
3443183,Challenging Sum: compute $\sum_{n=1}^\infty\frac{H_n}{2n+1}\left(\zeta(3)-H_n^{(3)}\right)$,"How to prove $$\sum_{n=1}^\infty\frac{H_n}{2n+1}\left(\zeta(3)-H_n^{(3)}\right)=\frac74\zeta(2)\zeta(3)-\frac{279}{16}\zeta(5)+\frac43\ln^3(2)\zeta(2)-7\ln^2(2)\zeta(3)\\+\frac{53}4\ln(2)\zeta(4)-\frac2{15}\ln^5(2)+16\operatorname{Li}_5\left(\frac12\right)$$ where $H_n^{(q)}=\sum_{k=1}^n\frac{1}{k^q}$ is the generalized harmonic number, $\operatorname{Li}_a(x)=\sum_{k=1}^\infty\frac{x^k}{k^a}$ is the polylogarithmic function and $\zeta$ is the Riemann zeta function. This problem was proposed by Cornel and no solution has been submitted yet. I managed to convert it to a double integral but it seems tough to crack. Here is what I did: Using the integral representation of the polygamma function: $$\int_0^1\frac{x^n\ln^a(x)}{1-x}dx=-\psi^{(a)}(n+1)=(-1)^a a!\left(\zeta(a+1)-H_n^{(a+1)}\right)$$ With $a=2$ we have $$\zeta(3)-H_n^{(3)}=\frac12\int_0^1\frac{x^n\ln^2(x)}{1-x}dx\overset{x=y^2}{=}4\int_0^1\frac{y^{2n+1}\ln^2(y)}{1-y^2}dy$$ multiply both sides by $\frac{H_n}{2n+1}$ then sum up we get $$\sum_{n=1}^\infty\frac{H_n}{2n+1}\left(\zeta(3)-H_n^{(3)}\right)=4\int_0^1\frac{\ln^2(y)}{1-y^2}\left(\sum_{n=1}^\infty\frac{y^{2n+1}H_n}{2n+1}\right)dy$$ we have $$\sum_{n=1}^\infty \frac{y^{2n+1}H_n}{2n+1}=-\int_0^y\frac{\ln(1-x^2)}{1-x^2}dx$$ which follows from integrating $\sum_{n=1}^\infty x^{2n}H_n=-\frac{\ln(1-x^2)}{1-x^2}$ from $x=0$ to $x=y$ . so $$\sum_{n=1}^\infty\frac{H_n}{2n+1}\left(\zeta(3)-H_n^{(3)}\right)=-4\int_0^1\int_0^y\frac{\ln^2(y)\ln(1-x^2)}{(1-y^2)(1-x^2)}dxdy$$ $$=-4\int_0^1\frac{\ln(1-x^2)}{1-x^2}\left(\int_x^1\frac{\ln^2(y)}{1-y^2}dy\right)dx$$ For the inner integral, Mathematica gives $$\int_x^1\frac{\ln^2(y)}{1-y^2}dy\\=\operatorname{Li}_3(-x)-\operatorname{Li}_3(x)-\ln(x)\operatorname{Li}_2(-x)+\ln(x)\operatorname{Li}_2(x)-\ln^2(x)\tanh^{-1}(x)+\frac74\zeta(3)$$ and the integral turned out very complicated. So any good idea how to approach the harmonic series or the integral? Thank you.","['integration', 'harmonic-numbers', 'calculus', 'polylogarithm', 'sequences-and-series']"
3443235,Is this very weird function continuous?,"I read about Conway's base 13 function and felt encouraged to procrastinate on my homework and play around with functions that involve binary expansions. This one function $K$ I came across caught my attention. Let $t \in (0,1)$ . Taking the binary expansion, we can write $t= \sum_{n=1}^\infty \frac{a_n}{2^n}$ , where $a_n \in \{0,1\}$ and $(a_n)$ cannot have an endless tail of 1's (i.e. for any $N \in \mathbb{N}$ with $a_N=1$ , there exists some $n \geq N$ with $a_n =0$ ). This makes the binary expansion unique for any $x \in (0,1)$ . We can create 2 numbers from this: $x= \sum_{n=1}^\infty \frac{a_{2n-1}}{2^n}$ and $y= \sum_{n=1}^\infty \frac{a_{2n}}{2^n}$ . We say $K(t)=(x,y)$ . In other words, we convert $t$ to binary format (e.g. $0.3141... \rightarrow 0.0101...$ ), and put all the odd-indexed digits in the binary expansion of $x$ , and even-indexed digits in the binary expansion of $y$ . Then you convert $x,y$ back to decimal format. Plotting the path, we have: This looks like a space-filling curve! Neat. It oddly looks similar to the Hilbert Curve . My question is if this function is continuous , since it zig-zags so much about the rational numbers. Just for funzies, when I add $x$ and $y$ , I can create a new function $k(x):=x+y$ . Doing so, I get this neat looking graph:","['continuity', 'recreational-mathematics', 'real-analysis']"
3443370,Why is a Lattice called so?,"Why is a Lattice called so? In my mind, I relate a Lattice to the picture of Lattice seen usually in chemistry.. like that of a salt, in 3-d space.. or just balls stacked in a plane on top of each other. And I read the definition of a Lattice as a Poset in which every pair of elements have a least upper bound(join) and greatest lower bound(meet). Although, this definition seems to be related somehow to the above view, I couldn't figure out how. Can you help in seeing the relation between that picture of lattice and the definition? Or is it just speculative thinking and no relation exists?","['lattice-orders', 'discrete-mathematics', 'terminology']"
3443408,If one angle of two triangles and the two medians to the two sides forming this angle are equal are the two triangles congruent?,"If one angle of two triangles and the two medians to the two sides forming this angle are equal, will the two triangles be congruent? For example, in triangles $ABC$ and $A'B'C'$ , we have angle $A = A'$ and medians $BD = B'D'$ and $CE = C'E'$ . I have tried with Geogebra and indeed they are congruent. I used the fact that the 3 medians intersect at a point that has a distance of $\frac{1}{3}$ of its length from the origin vertex. By keeping one median fixed, I rotated the second one around the intersecting point and indeed there are two points which ""see"" the side $BC$ by a given angle, both of them resulting to the same triangles. How do I solve it geometrically? Let's name the intersection point of the 3 medians $O$ . I started by assuming that $BC \neq B'C'$ , then since the other two sides of the small triangles (formed by the $\frac{2}{3}$ of the medians) are equal, then angle $BOC \neq B'O'C'$ . Then also angles $DOE \neq D'O'E'$ , so, segment $DE \neq D'E'$ . But I don't know how to go further. Many thanks!","['euclidean-geometry', 'triangles', 'geometry']"
3443441,Prove that f(2000x)=2000f(x),"Given function $f:\mathbb{R}\rightarrow \mathbb{R}$ such that $f(x+y+2xy)=f(x)+f(y)+2f(xy)$ . Prove that $f(2000x)=2000f(x)$ . Letting $x=y=1$ yields $f(4)=4f(1)$ , which means that $f(n)=nf(1)$ . But I cannot prove this by induction. 
And is it possible to prove that this function is monotonous and additive? If so, then the function is linear and the work must be much easier.","['functional-equations', 'functions']"
3443467,How to Show $\int_n^{n+1}(\frac{1}{n^s}-\frac{1}{x^s})dx$ is Analytic,"I found in a note that $F_n(s)=\int_n^{n+1}(\frac{1}{n^s}-\frac{1}{x^s})dx$ ,  then $F_n(s)$ is analytic in $\mathbb{C}$ for every $n \in \mathbb{N}$ . Now, from the definition of analytic function found in Wikipedia (click here) , I am having trouble to see how $F_n(s)$ is analytic, specially, the integral is defined by the variable $x$ , but we are dealing with complex plan and complex number $s= \sigma +it.$ I request to explain and show  elaborately why $F_n(s)$ is analytic. Thanks.","['number-theory', 'analysis', 'real-analysis', 'complex-analysis', 'analytic-number-theory']"
3443499,Can we approximate harmonic functions with harmonic functions with non-vanishing differential?,"Let $\mathbb{D}^2$ be the closed $2$ -dimensional unit disk, and let $g:\mathbb{D}^2 \to \mathbb{R}$ be a non-constant harmonic function (in particular smooth up to the boundary). Does there exist a sequence of smooth harmonic functions $g_n$ on $\mathbb{D}^2 $ , such that $g_n \to g$ in $W^{1,2}$ and $dg_n \neq 0$ everywhere on $ \text{int}(\mathbb{D}^2)$ ? Since we can add additive constants to the $g_n$ , we can arrange $\int_{\mathbb D^2} g_n=\int_{\mathbb D^2} g$ , so the $W^{1,2}$ convergence of the $g_n$ is essentially equivalent to $dg_n \to dg$ in $L^2$ . (via Poincare inequality). Thinking on $dg$ as a vector field, I think that we can always approximate it with a non-zero vector field in $L^2$ . However, the only procedure I know for doing that does not produce approximating vector fields which are gradients of harmonic functions (or gradients of anything, really).","['harmonic-functions', 'real-analysis', 'partial-differential-equations', 'differential-topology', 'differential-geometry']"
3443678,Does $\sum\limits_{n=1}^\infty\frac{a_{n+1}-a_n}{b_{n+1}-b_n}<\infty$ imply $\sum\limits_{n=1}^\infty\frac{a_n}{b_n}<\infty?$,Let $(a_n)_{n\geq 1}$ and $(b_n)_{n\geq 1}$ be sequnces of positive numbers such that $a_n\to 0$ and $b_n\to 0$ as $n\to\infty$ . Then it is known that if $(b_n)_{n\geq 1}$ is strictly monotone and $$\lim\limits_{n\to\infty}\frac{a_{n+1}-a_n}{b_{n+1}-b_n}=0$$ then $$\lim\limits_{n\to\infty}\frac{a_n}{b_n}=0.$$ If we additionally have that $$\sum\limits_{n=1}^\infty\frac{a_{n+1}-a_n}{b_{n+1}-b_n}<\infty$$ does it then follow that $$\sum\limits_{n=1}^\infty\frac{a_n}{b_n}<\infty?$$,"['convergence-divergence', 'sequences-and-series']"
3443764,"If $\mathbb E[e^{\xi X}]=e^{\frac{\xi^2}{2}}$ for all $\xi >0$ does $X\sim \mathcal N(0,1)$?","I know that if $$\mathbb E[e^{\xi X}]=e^{\frac{\xi^2}{2}}$$ for all $\xi\in\mathbb R$ , then $X\sim \mathcal N(0,1)$ . Now, if $$\mathbb E[e^{\xi X}]=e^{\frac{\xi^2}{2}}$$ for all $\xi >0$ does $X\sim \mathcal N(0,1)$ as well ? I really can't find a counter example, and I know that to have $X\sim Y$ we need that $\mathbb E[e^{tX}]=\mathbb E[e^{tY}]$ for all $|t|\leq t_0$ for some $t_0>0$ . So, I'm not so sure if $\mathbb E[e^{\xi X}]=e^{\frac{\xi^2}{2}}$ for all $\xi>0$ is enough to have $X\sim N(0,1)$ . Any idea ?",['probability']
3443808,"Why is Furch's ""knotted hole ball"" not shellable?","I'm trying to work through the example below, but I need some explanation as to why K' is not shellable. If we try to shell it, where would we get stuck?. Here are some relevant definitions.","['discrete-geometry', 'proof-explanation', 'geometric-topology', 'knot-theory', 'general-topology']"
3443844,Homeomorphisms between infinite-dimensional Banach spaces and their spheres,"As I know Cz. Bessaga has proved that an infinite-dimensional Banach space is homeomorphic to its unit sphere.
Unfortunately I do not have his book but I want to know is this theorem true without dependence from that the space is separable or not, and it is real or complex. That is, is it true that: a real separable infinite-dimensional Banach space is homeomorphic to its sphere; a complex separable infinite-dimensional Banach space is homeomorphic to its sphere; a real non-separable infinite-dimensional Banach space is homeomorphic to its sphere; a complex non-separable infinite-dimensional Banach space is homeomorphic to its sphere?","['banach-spaces', 'analysis', 'hilbert-spaces', 'functional-analysis', 'general-topology']"
3443910,"Integrability of $\sin \frac1x$ on $[0,1]$ using Darboux sums","Prove that $f:[0,1] \rightarrow\mathbb{R}:f(x)= \left \{\begin {array}{ll}
\sin \frac1x &, \textrm{if}~      x\in(0,1]\\
0 &, \textrm{if}~~x =0
\end{array}
\right.~~$ is Riemann integrable using Darboux sums. Attempt. The proof that I am aware of uses the classic result that extends integrability from every $[a,1]$ to $[0,1]$ (if $f$ is bounded on $[0,1]$ and integrable on $[a,1]$ for all $a\in (0,1)$ , then $f$ is integrable on $[0,1]$ ). I am interested in a proof that uses Darboux sums, especialy: $$U(f,P_n)-L(f,P_n) \to 0$$ for a specific sequence $(P_n)$ of partitions of $[0,1]$ . So far I haven't found one that does the job. Note : the fact that such a partition exists neither means that we are looking for a good looking one, nor that it could be written in a closed form. Thanks in advance.","['integration', 'riemann-sum', 'analysis', 'real-analysis']"
3444058,Conditional Expectation of a Poisson Variable on an Exponential Variable,"The question is as follows: Consider two independent Poisson processes $N^{(1)}(t), t\geq 0$ and $N^{(2)}(t), t\geq 0$ .
Let $T = \inf\{t:N_t^{(1)} > 0\}$ be the time of the first point in the process, and let $X = N^{(2)}(T^{(1)}_1)$ be the number of points in the second process that occur before the first point in the first process. What are $\mathbb{E}(X\mid T)$ and $\mathbb{E}(X^2\mid T)$ ? The definition of condition expectation is that for random variables $X, Y$ , $\mathbb{E}(X\mid Y)$ is a $\sigma(Y)$ -measurable random variable with $$\int_G\mathbb{E}(X\mid Y) \, d\mathbb{P} = \int_G X \, d\mathbb{P} \quad \text{for all } G \in \sigma (Y)$$ Regarding the problem, it is clear that given $T = t$ , $X \sim \operatorname{Poisson}(t\lambda)$ , where $\lambda$ is the rate of the second process, which means we that expectation and variance are both $t\lambda$ and the desired conditional expectations follow. However, these are numbers , not random variables , so I this isn't actually a solution. When we are conditioning on a discrete random variable, the approach above suffices, because the $\sigma$ -algebra $\sigma (Y)$ is a countable union of preimages, so we have the countable series $\mathbb{E}(X\mid Y) = \sum_y \mathbb{E}(X\mid Y = y)\mathbb{1}_{Y = y}$ , and then considering each $\omega \in \Omega$ the result follows. However, $T$ in the question is a continuous random variable, so in particular its support is uncountable, so this trick does not work. I really have no idea how to proceed beyond this, and any help would be much appreciated.","['conditional-expectation', 'measure-theory', 'probability-theory', 'poisson-process']"
3444059,How does one compute this double integral?,"$$\int_0^2\int_0^{y^3} x^5(2-x^{1/3})^{-1} \, dx \, dy$$ I've tried change of variables, which didn't seem to help much. I've also tried u-substitution and that didn't help. What I noticed is that there is $x=y^3$ so $y=x^{1/3}$ , but I wasn't sure how to use that fact besides change of variables.","['integration', 'multivariable-calculus']"
3444107,Is the set of ALL strictly decreasing functions from $\mathbb{Q }$ to $\mathbb{Q }$ countable?,"I want to show that the set (call it $B$ ) of all strictly decreasing functions [ $f: \mathbb{Q} \rightarrow \mathbb{Q}$ such that x $<$ y implies f(x) > f(y)] is not bijective to the natural numbers N. That is, there exists no bijection  from $B$ to N. My guess: Since there are not strictly decreasing functions in N (due to positive values), wouldn't that imply that $B$ is not countable? How can I go about from here?","['elementary-set-theory', 'functions']"
3444112,Find $\lim_{n \to \infty} \prod_{k=1}^{n} \frac{(k+1)^2}{k(k+2)}$,"I have to find the following limit: $$\lim\limits_{n \to \infty} {\displaystyle \prod_{k=1}^{n} \dfrac{(k+1)^2}{k(k+2)}}$$ This is what I tried: $$\lim\limits_{n \to \infty} {\displaystyle \prod_{k=1}^{n} \dfrac{(k+1)^2}{k(k+2)}} = 
\lim\limits_{n \to \infty} {\displaystyle \prod_{k=1}^{n} \dfrac{k^2+2k+1}{k^2+2k}} = 
\lim\limits_{n \to \infty} {\displaystyle \prod_{k=1}^{n} \bigg(\dfrac{k^2+2k}{k^2+2k}} + \dfrac{1}{k^2+2k} \bigg ) = $$ $$ = \lim\limits_{n \to \infty} {\displaystyle \prod_{k=1}^{n} \bigg(1 } + \dfrac{1}{k^2+2k} \bigg ) = 
\lim\limits_{n \to \infty} {\displaystyle \prod_{k=1}^{n} 1 }  + \lim\limits_{n \to \infty} {\displaystyle \prod_{k=1}^{n} \dfrac{1}{k^2+2k} }$$ Now, $\lim\limits_{n \to \infty} {\displaystyle \prod_{k=1}^{n} 1 } = 1$ and: $\lim\limits_{n \to \infty} {\displaystyle \prod_{k=1}^{n} \dfrac{1}{k^2+2k} } = 0$ I think the above equals $0$ , since this is a product and the limit of the last term of the product is $0$ , so the whole thing would be $0$ , but I am not exactly sure if my intuition is right. So that means: $$\lim\limits_{n \to \infty} {\displaystyle \prod_{k=1}^{n} \dfrac{(k+1)^2}{k(k+2)}} = \lim\limits_{n \to \infty} {\displaystyle \prod_{k=1}^{n} 1 }  + \lim\limits_{n \to \infty} {\displaystyle \prod_{k=1}^{n} \dfrac{1}{k^2+2k} } = 1 + 0 = 1$$ The problem I have is that my textbook claims that the correct answer is $2$ , not $1$ . So I did something wrong, however, I can't spot my mistake/mistakes.","['infinite-product', 'limits', 'calculus']"
3444132,What are the Euler characteristics of fractals?,"I have been led to believe that all shapes, surfaces and polyhedra have Euler characteristics. Does this apply to fractals as well?
If so, is this linked in any way to fractal dimensions?
How would such an Euler characteristic be calculated?
If fractals do not have an Euler characteristic, why is that the case?","['general-topology', 'surfaces', 'fractals']"
3444176,Are these two intervals order-isomorphic?,"Suppose $A (\text{unit}):= [0,1] \subset \mathbb{R}$ and $B:=[0,1] \cup [2,3]\, \cup...  \subset \mathbb{R}$ . I am trying to show $A$ and $B$ might not be order isomorphic under the ordering of $<_\mathbb{R}$ on $\mathbb{R}$ I don't think A and B are order isomorphic under the condition $<_\mathbb{R}$ since they seem to not be equinumerous to one another. Such that there is not a bijection $A$ to $B$ that exists. Originally, I thought $f:\mathbb{R} \rightarrow \mathbb{R}: \tan(x)$ on the interval ( $-\pi/2$ , $\pi/2$ ) would be a bijective function, but scaling the interval accordingly to find this alternating union of distinct intervals in $B$ brought some issues. Any suggestions on how to move on from here?","['elementary-set-theory', 'functions']"
3444211,CFG where the number of 0s is the same as the number of 1s and there is exactly one 2.,"So to create a CFG where the number of 0s and 1s are the same, I have: $$ S \rightarrow SS \ |  \ 0S1 \ |  \ 1S0 \ | \  \epsilon $$ However, I don't know how to inject one single 2 to create the CFG that the number of 0s is the same as the number of 1s and there is exactly one 2. Any help is appreciated! Thanks!","['formal-languages', 'context-free-grammar', 'discrete-mathematics']"
3444230,Is there a 1-1 function $f: \mathbb{N} \rightarrow A$?,"Assume $g: A \rightarrow A $ is a 1-1 but not onto function. What does that tell us about an injective function $f$ from $\mathbb{N}$ to $A$ ? In this case, $A$ would have to be an infinite set since if the set were finite, such a $g$ could not exist. It seems as though such a 1-1 function $f$ exists, but any suggestions on how to proceed from here to show that there is one?","['elementary-set-theory', 'functions']"
3444256,Projection of algebraic set on hyperplane is closed,"Suppose that $X$ is an algebraic set of $\mathbb{P}^n$ . We defined the projection $\pi$ as follows: Let $P$ be a point in $\mathbb{P}^n$ and $H$ a hyperplane of $\mathbb{P}^n$ such that $P \notin \mathbb{P}^n$ . We project every point $Q \neq P$ $\in \mathbb{P}^n$ , the line $\overline{PQ}$ will cut $H$ at a point $\pi(Q)$ . We would like to prove that $\pi(X)$ with $X$ an algebraic set is closed, but we're stuck with our reasoning. This is what we already thought about: For a random point $Q \in X$ there is a line $PQ$ between $Q$ and $P$ . We can write that $PQ =Z(f_1,...,f_{n-1})$ with $f_1,...,f_{n-1}$ irreducible polynomials. We also know that we can write $H = Z(g)$ with $g$ an irreducible polynomial. Here we are stuck. We have a feeling that we can do something with resultants but we don't know what or how. Hopefully someone can help us.",['algebraic-geometry']
3444274,Expected time to fuse a $D_{10}$ dragon,"I play a game called DragonSky merge and idle (or something like this). The basic premise of the early game is that dragons will spawn, and will be fused in pairs. You continue to fuse these until you have a level $10$ dragon. Let me be precise. Let $\{D_1,D_2,\dots, D_{10}\}$ denote the set of types of dragons. Then, the following occurs: Every $.9$ seconds a dragon will spawn of type $D_1$ with probability $.8$ , and of type $D_2$ with probability $.2$ . For each $i\in\Bbb N$ such that $1\leq i\leq 8$ , two dragons of type $D_i$ will be fused to form a dragon of type $D_{i+1}$ with probability $P_1=.85$ or a dragon of type $D_{i+2}$ with probability $P_2=.15$ . For $i=9$ , they will always fuse to a dragon of type $D_{10}$ . This merging will occur until there is no pair of dragons of the same type. These two steps will continuously repeat. As a small example of $6$ time steps, let us denote a collection of $k$ dragons of type $D_i$ by $d_{i}^1,\dots,d_i^k$ (of course, after fusion $k\in\{0,1\}$ ). Then we could have the following sequence of sets of dragons, where $\overset{1}{\to}$ means rule $1$ was applied (a dragon spawned), and $\overset{2}{\to}$ means rule $2$ was applied (a pair of dragons was fused). $$\emptyset\overset{1}{\to}\{d_1^1\}\overset{1}{\to}\{d_1^1,d_1^2\}\overset{2}{\to}\{d_2^1\}\overset{1}{\to}\{d_2^1,d_2^2\}\overset{2}{\to}\{d_3^1\}\overset{1}{\to}\{d_2^1,d_3^1\}\overset{1}{\to}\{d_1^1,d_2^1,d_3^1\}\overset{1}{\to}\{d_1^1,d_1^2,d_2^1,d_3^1\}\overset{2}{\to}\{d_2^1,d_2^2,d_3^1\}\overset{2}{\to}\{d_3^1,d_3^2\}\overset{2}{\to}\{d_4^1\},$$ (This sequence might fully exhibit the behaviour I describe, noting that there are two steps where a $D_2$ was spawned, and $4$ where a $D_1$ was spawned.) I am trying to determine the number of seconds it takes on average to form a dragon of type $D_{10}$ assuming that we initially start with no dragons. I have very little experience with probability theory, so my first approach was to simplify this by taking $P_1=1$ and $P_2=0$ , but what I compute is definitely not correct. My approach there was to consider: $$E_n = \{(x,y)\mid x+y=n, x+2y\geq 2^{10}, x,y\in\Bbb Z_{\geq 0}\},$$ where $(x,y)\in E_n$ corresponds to a valid sequence of $n$ spawns that yields a $D_{10}$ dragon, such that there were $x$ spawns of $D_1$ and $y$ spawns of $D_2$ . Then I thought I would only need to take $$S_n=\sum_{(x,y)\in E_n}(.2)^i,$$ for the probability that we have a $D_{10}$ in precisely $n$ steps, and I am then looking for $k$ such that $$\sum_{i=1}^k S_i\approx .5.$$ This led me to make a mistake (after many calculations), and also doesn't deal with the proper fusion rates. A second thought I had would be to set this up in terms of Markov chains, where we simply enumerate all possible sequences $(n_1^t,\dots,n_{10}^t)$ of numbers of dragons $n_i^t$ of type $D_i$ at time step $t$ , and edges corresponding to merging and spawning, but I had trouble setting this up precisely, and even doing so, it seemed that I (personally) can't calculate the resulting probability . Can someone help me solve this problem?","['recreational-mathematics', 'probability']"
3444279,"Prove that if $R$ and $S$ are rings, $\theta : R \to S$ is an isomorphism, and $e$ is a unity of $R$, then $\theta (e)$ is a unity of $S$","Prove that if $R$ and $S$ are rings, $\theta : R \to S$ is an isomorphism, and $e$ is a unity of $R$ , then $\theta (e)$ is a unity of $S$ So if $\theta : R \to S$ is an isomorphism, that means that they essentially have the same structure. From my understanding, a unity is an element that has a multiplicative inverse in R. So $e$ is the inverse in R and we have to prove the same for S. Not sure where to go from here","['ring-theory', 'group-theory', 'abstract-algebra', 'group-isomorphism']"
3444281,prove derivative of dot product of A(u) and B(u) with respect to u.,"Suppose $\vec{A}$ and $\vec{B}$ are differentiable  functions of a scalar u. Prove: $\Large \frac{d}{du}(\vec{A} \cdot \vec{B}) = \vec{A} \cdot \frac{d\vec{B}}{du} + \frac{d\vec{A}}{du} \cdot \vec{B}$ ok so i start with definition of derivative: $\Large \frac{df(x)}{dx} = \lim \limits_{\Delta x \to \infty} \frac{f(x+\Delta x) - f(x)}{\Delta x}$ and apply it to the dot product of $\vec{A}$ and $\vec{B}$ : $\Large \frac{d}{du} (\vec{A} \cdot \vec{B}) = \lim \limits_{\Delta u \to \infty} \frac{(\vec{A}+\Delta\vec{A}) \cdot (\vec{B}+\Delta\vec{B}) -\vec{A}\cdot\vec{B}}{\Delta u}$ appying ""foil"" method to expand dot produt in numerator: $\Large \frac{d}{du} (\vec{A} \cdot \vec{B}) = \lim \limits_{\Delta u \to \infty} \frac{\vec{A}\cdot\Delta B ~+~ \Delta \vec{A} \cdot \vec{B} ~+~ \Delta A \cdot \Delta B}{\Delta u}$ $\Large \frac{d}{du} (\vec{A} \cdot \vec{B}) = \lim \limits_{\Delta u \to \infty} \frac{\vec{A}\cdot\Delta B}{\Delta u} + \lim \limits_{\Delta u \to \infty} \frac{\Delta \vec{A} \cdot \vec{B}}{\Delta u} + \lim \limits_{\Delta u \to \infty} \frac{\Delta A \cdot \Delta B}{\Delta u}$ $\Large \frac{d}{du} (\vec{A} \cdot \vec{B}) = \vec{A} \cdot \frac{d\vec{B}}{du} + \frac{d\vec{A}}{du} \cdot \vec{B}  + \lim \limits_{\Delta u \to \infty} \frac{\Delta A \cdot \Delta B}{\Delta u}$ now for the part that I don't understand..why does this piece goto zero: $\Large \lim \limits_{\Delta u \to \infty} \frac{\Delta A \cdot \Delta B}{\Delta u} = 0?$","['limits', 'calculus', 'vector-analysis']"
3444283,Permutation 6 letter password lowercase and digits?,"I got this question from a past exam paper. I know there is a typo I think it is anyway where it says six letter passwords Question How many six letter passwords can be formed from a scheme where only lower case   letters or digits are allowed, with no repetition and a password may not start with a digit? Now because there is 26 letters and 10 digits the total is 36 characters. But the password can not start with a digit so here was my solution 26*35*34 ...... As 26 letters can be picked for the first character and as there is no repetition that leaves 35 as a letter was entered in for the first character. Is this the right way of approaching this problem, also is the a faster way of doing this on the calculator like using ! or P??","['permutations', 'combinatorics']"
3444325,Which of the following statements describe the sum $S_n = {\sum\limits_{k=2}^{n} \frac{k^2-2}{k!}}$ correctly?,"I have the sum: $$S_n =  {\displaystyle \sum_{k=2}^{n} \dfrac{k^2-2}{k!}}$$ with $n \ge 2$ . I am asked to choose which one of the following statements describe the sum accurately (only one option is right): A. $S_n < 3$ B. $S_n > 3$ C. $S_n = e$ D. $S_n < 0$ E. $S_n = e - \dfrac{1}{2}$ I can see that answer D is clearly out, but I don't know how to choose the right answer from A , B , C , E . I tried completing the square into something like: $$S_n =  {\displaystyle \sum_{k=2}^{n} \dfrac{k^2-2}{k!}} =$$ $$={\displaystyle \sum_{k=2}^{n} \dfrac{k^2+2k+1-2k-1-2}{k!}} $$ $$={\displaystyle \sum_{k=2}^{n} \dfrac{(k+1)^2-(2k+3)}{k!}}  $$ $$={\displaystyle \sum_{k=2}^{n} \dfrac{(k+1)^2} {k!}} - {\displaystyle \sum_{k=2}^{n} \dfrac{2k+3}{k!}}  $$ $$={\displaystyle \sum_{k=2}^{n} \dfrac{(k+1)^2}{k!}} - 2{\displaystyle \sum_{k=2}^{n} \dfrac{1}{(k-1)!}} - 3{\displaystyle \sum_{k=2}^{n} \dfrac{1}{k!}}$$ And I got stuck here. I don't think completing the square helps me all that much in this problem.","['algebra-precalculus', 'summation']"
3444338,Finding 'glitch' primes,"Consider numbers of the form $$
p=\underbrace{b\,\cdots\, b}_{n\,b\text{'s}}\,a\,\underbrace{b\,\cdots\, b}_{n\,b\text{'s}},
$$ where $0\leq a\leq 9$ and $1\leq b\leq 9$ . In other words, $$
p=(a - b)10^n +\frac{b}{9}(10^{2 n - 1} - 1).
$$ For example, $121,44344$ and $9990999$ are numbers of this form. Given $a$ and $b$ , for which values of $n$ is $p$ prime? Clearly, $p$ can only be prime if $b\in\{1,3,7,9\}$ . What else can we say? Letting $m=2n+1$ be the integer length of $p$ , and just for fun, here are some of the values of $(a,b)$ and $m$ for which $p$ is a prime number (up to numbers of integer length $1000$ ) \begin{matrix}
a&b&m\\
0    &   1  &    \{  3     \}\\
1    &   1  &    \{ 9, 23, 317, 1031      \}\\
2    &   1  &    \{       \}\\
3    &   1  &    \{ 3, 5, 39, 195      \}\\
4    &   1  &    \{ 5, 7, 65, 91      \}\\
5    &   1  &    \{   3, 15, 91, 231, 1363    \}\\
6    &   1  &    \{  21, 29, 81, 119, 321, 825, 1121     \}\\
7    &   1  &    \{ 7, 67, 623      \}\\
8    &   1  &    \{ 3 , 9, 13, 15, 769, 1333, 1351     \}\\
9    &   1  &    \{  3, 9, 53, 375, 453, 1749     \}\\
0    &   3  &    \{       \}\\
1    &   3  &    \{  3, 7, 15, 123, 181, 185, 539, 597, 643, 743, 1553     \}\\
2    &   3  &    \{       \}\\
4    &   3  &    \{       \}\\
5    &   3  &    \{ 3, 5, 35, 159, 237, 325, 355, 371, 481, 1649      \}\\
6    &   3  &    \{       \}\\
7    &   3  &    \{   3, 7, 15, 23, 27, 35, 59, 63, 67, 155, 1867    \}\\
8    &   3  &    \{  3, 15, 171, 189, 547, 713     \}\\
9    &   3  &    \{       \}\\
0    &   7  &    \{       \}\\
1    &   7  &    \{  233     \}\\
2    &   7  &    \{3, 7, 15, 21, 25, 961, 1899       \}\\
3    &   7  &    \{ 5      \}\\
4    &   7  &    \{   5, 7, 13, 47, 73, 139, 1123, 1447    \}\\
5    &   7  &    \{ 3, 15, 27, 117, 259, 507      \}\\
6    &   7  &    \{ 9, 11, 17, 23      \}\\
8    &   7  &    \{  3, 7, 79, 109, 337, 481     \}\\
9    &   7  &    \{  3, 5, 17, 39, 41, 425, 561, 1775     \}\\
0    &   9  &    \{       \}\\
1    &   9  &    \{ 3, 11, 27, 87, 339, 363      \}\\
2    &   9  &    \{  3, 17, 19, 705, 1061, 1395     \}\\
3    &   9  &    \{       \}\\
4    &   9  &    \{  29, 45, 73, 209     \}\\
5    &   9  &    \{ 177, 225, 397, 1245      \}\\
6    &   9  &    \{       \}\\
7    &   9  &    \{ 237      \}\\
8    &   9  &    \{  53, 757     \}
\end{matrix} For example, for $a=4$ and $b=7$ , $7777774777777$ is prime. Naturally such answer entirely depends on the given pair $(a,b)$ , but I wonder if something can be said about specific cases. For example, for which cases does $m$ take infinitely many values? PS - If these type of primes are known, please suggest me a better name than the title.","['number-theory', 'prime-factorization', 'prime-numbers']"
3444380,Solve Exponential Equation with square,Solve equality with square $2^{2x}=7\cdot 2^{x+\sqrt{x-1}}+8\cdot 2^{2\sqrt{x-1}}$ $x-1\ge0 \\\sqrt{x-1}=t\ge0\Rightarrow x-1=t^2\Rightarrow x=t^2+1\\2^{2(t^2+1)}=7\cdot2^{t^2+1+t}+2^{3+2t}$ It looks very complicated and I don't know how to move it. Is there a better way to approach this task?,['algebra-precalculus']
3444390,error of Taylor series for $\ln x$,"Find the Taylor Polynomials for $f(x)=\ln x$ about $a=1$ and give error estimates. Below is what I've done. There may be some mistakes. Let $f(x) = \ln x$ . Then $f(1) = 0$ . $f'(x) = \dfrac{1}{x}$ so $f'(1) = 1$ . $f''(x) = -\dfrac{1}{x^2},$ so $f''(1) = -1$ . $f^{(3)}(x) = \dfrac{2}{x^3}$ so $f^{(3)}(1) = 2$ . From this, we see that $f^{(n)}(1)$ , where $n>0,$ has value $(-1)^{n-1}(n-1)!$ . Hence the Taylor polynomials $P_{n,1}(x)$ for $f(x)$ about $a=1$ are given by $\displaystyle\sum_{i=1}^n (-1)^{i-1}\dfrac{(x-1)^i}{i}$ . By Taylor's Theorem, we have that $f(x) - P_{n,1}(x)=\dfrac{f^{(n+1)}(x_0)}{(n+1)!}(x-1)^{n+1},$ where $1\leq x_0 \leq x$ . Hence since $|f^{(n+1)}(x_0)|=|(-1)^n\dfrac{n!}{(x_0)^{n+1}}|=\dfrac{n!}{(x_0)^{n+1}}, n\in\mathbb{N}$ is a decreasing function, for $x_0\geq1$ , it has a maximum of $n!$ at $x_0=1$ . Thus, the absolute value of the error is given by $\dfrac{n!}{(n+1)!}|(x-1)|^{n+1}=\dfrac{|(x-1)|^{n+1}}{n+1}.$ Edit: I guess this could also be shown using the fact that the error for an alternating series is smaller than the next term and has the same sign.","['calculus', 'taylor-expansion']"
3444433,Why is the solution to $\dot x = \sin x$ written in $t = ... $ form?,"I'm a high school senior currently taking AP Calculus AB. I'm trying to learn a little about dynamical systems in my free time (yes, I know the pre-requisites are supposed to be multi-variable calculus and linear algebra, but I was eager!) Basically, I'm starting Strogatz's Nonlinear Dynamics and Chaos and came across the equation $\dot x = \sin x$ , which I presume means the same thing as $x'(t)=\sin(x(t))$ since my understanding is that $x$ is a function of $t$ . The separation of variables seems pretty straightforward -- you get $t = -\ln|\csc x + \cot x| + C$ . I agree with Strogatz on that much. But then I wondered -- wasn't a solution to a differential equation supposed to be a function $x(t)$ , not a variable $t$ ? What the heck does it even mean to have a solution expressed as $t = ...$ ? Indeed, when I told Wolfram Alpha to solve $x'(t) = \sin(x(t))$ , it returned $x(t) = 2\cot^{-1}(e^{c_1 - t})$ -- quite different from the solution given above, although I have no idea how Wolfram Alpha got it or how their process differred from Strogatz's. Below is an image of the Strogatz page in question (section 2.1). Having not understood why solving for $t$ was useful, I am of course completely (even more) lost at the part where he says $x = x_0$ and does some stuff with initial conditions or whatever. Basically, isn't the point of solving a differential equation generally to find the function $x(t)$ that satisfies it? So why isn't Strogatz doing that here, and what else is it that he's doing instead?","['nonlinear-system', 'calculus', 'ordinary-differential-equations', 'dynamical-systems']"
3444438,Under what assumptions will $M \unlhd G$? ($M$ maximal),"Let $G$ be a finite group (non-trivial), and let $M$ be a maximal subgroup of $G$ . My question is, what criterion on $M$ would allow us to deduce that $M \unlhd G $ ? (I mean, will $M \unlhd G$ hold when $M$ is cyclic? Abelian? Nilpotent? Metanilpotent? Solvable? None of the above?) I know already that if we assume $G$ is nilpotent, every maximal subgroup will be normal, hence our particular $M$ is normal. But if we assume nothing about $G$ (other than that it is finite), I don't know what will happen. Note: Although I would be willing to accept an answer for the finite case alone, I would also be interested to know if the result would be different for $|G|= \infty$ .","['maximal-subgroup', 'finite-groups', 'normal-subgroups', 'abstract-algebra', 'group-theory']"
3444446,"Counting: A distributed network of 10 servers, 40 different movies will be stored on network","How many ways are there to select where the movies will be stored if there is no restriction on the number of movies stored at each server? Answer: $10$ ^ $40$ Comparing this problem to problems like how many different passwords are there of length $6$ using letters only. The letters are constant and never need refilling, and you always have $26$ possibilities per slot => (26^6) total outcomes. However I thought that the $40$ movies are finite, and storing some would decrease the overall count each time you store them, something like a permutation/factorial. Why can I store the movies as if they refill/are constant? 2. How many ways are there to select where the movies will be stored if the same number of movies are stored at each server? Answer: $40! / (4!)$ ^ $10$ I am lost as to why factorials were used and what they represent. Now treating the movies as a finite resource compared to problem #1. Also confusing where the $4!$ in the denominator came from. Can someone explain the reasoning?","['discrete-mathematics', 'combinatorics', 'probability']"
3444491,The speed of a.s. convergence in SLLN,"Let $X_1, X_2, \ldots\sim \mathcal{N}(0, 1)$ be i.i.d, and $S_n = X_1 + X_2 + \cdots + X_n$ . The strong law of large numbers states that $\frac{S_n}{n} \to 0$ almost surely. Fix $\epsilon > 0$ . Define an integer valued random variable $$N = \sup\{n: |\frac{S_n}{n}| > \epsilon\}$$ i.e the ""last time the deviation is large"". By SLLN, $N$ is finite almost surely. What is its distribution (it will depend on $\epsilon$ )?","['probability-distributions', 'probability-theory']"
3444555,Show all maximal chains in a power set of a set,"Suppose the set $S$ , partially ordered by $\subseteq$ respectively , is $S=\{x,y,z\}$ . Show all maximal chains in the power set of S. 1st Attempt : I wrote out the power set of S ( $P(S)$ ) as such $P(S)=\{\emptyset,\{x\},\{y\},\{z\},\{x,y\},\{x,z\},\{y,z\},\{x,y,z\}\}$ . I think the maximal chain(s) would just be $\{x,y,z\}$ (or $S$ itself) given the definition of a maximal chain. 2nd Attempt :However, this brought me to confusion on $\{\emptyset, x\}$ , $\{ \emptyset, y\}$ , and so forth on being maximal chains as well despite not being explicitly stated in the power set. Any suggestions on how to move forward?","['elementary-set-theory', 'order-theory']"
3444560,Can $\dot x = \sin x$ be equivalently written as $x'(t) = \sin(x(t))$?,"Somewhat related to a question I asked earlier. Basically, can we write $\dot x = \sin x$ as, equivalently, $x'(t) = \sin(x(t))$ ? Do those two equations have the same meaning, or is there some difference? I'm trying to make sure I understand whether $x$ is a function of time, and, if so, how that affects the way we can write the differential equation. And also, can $x$ be considered a variable here, or only a function? I find variables a bit more intuitive as, technically speaking, functions cannot ""change""; their dependent variable (the ""value"" of the function?) changes, right?","['notation', 'calculus', 'derivatives', 'ordinary-differential-equations']"
3444580,What is unknown about the sphere $S^2$?,"The standard sphere $S^2$ is (arguably) the simplest symmetrical geometric object. We can view $S^2$ as a smooth manifold in the category of smooth manifolds, or a Riemann sphere $\mathbb{P}^1$ in the category of complex manifolds, or  a genus zero curve (which is also often called a line) in the category of complex algebraic varieties. We can ask different questions about $S^2$ depending on the category we put it into. For example, we can ask whether there is a nowhere vanishing vector field on $S^2$ , how many complex structures there are on $S^2$ , or what the Gromov-Witten invariants of $\mathbb{P}^1$ are. All these questions have been answered. What is unknown about $S^2$ ? If we replace $S^2$ by $S^6$ , then we don't know if there is a complex structure on $S^6$ . Although $S^2$ is a simpler object, I guess there should still be open problems involving $S^2$ . In other words, I'm asking what we know we don't know about $S^2$ .","['open-problem', 'complex-geometry', 'algebraic-geometry', 'smooth-manifolds']"
3444602,Genus of $y^4=x^{14}+x$?,"I want to calculate the genus of the algebraic curve $y^4=x^{14}+x$ by Riemann-Hurwitz formula. I know there are $42$ branch numbers over all finite points by the discriminant of the curve. But i don't know how to calculate the branch number of infinity, because infinity is a singular point. I want to know how to resolve the singularities of infinity. What's more, how can i use puiseux series to distinct the regular points, branch points and singular points? Someone help please? Thanks.","['algebraic-curves', 'riemann-surfaces', 'algebraic-geometry']"
3444603,prove/disprove: the functions $f_n(x)=\cos(x+n)+\ln\left(1+\frac{\sin^2(n^nx)}{\sqrt{n+2}}\right)$ are uniformly equicontinuous,"Prove/Disprove that the sequence of functions $(f_n)$ from $\Bbb R$ to $\Bbb R$ defined by $$f_n(x)=\cos(x+n)+\ln\left(1+\frac{\sin^2(n^nx)}{\sqrt{n+2}}\right)$$ are uniformly equicontinuous. That is, prove/disprove that for all $\epsilon>0$ there is a $\delta>0$ such that $$|x-t|<\delta, n\in\Bbb N\Rightarrow |f_n(x)-f_n(t)|<\epsilon.$$ Thoughts/Context. It is my gut feeling that $f_n$ are uniformly equicontinuous. I have a not-very-rigorous ""proof"" of this. For $n\in\Bbb N$ and $x\in\Bbb R$ , $\sin^2(n^n x)$ is between $0$ and $1$ , so $$0\le \frac{\sin^2(n^nx)}{\sqrt{n+2}}\le \frac{1}{\sqrt{n+2}}<1.$$ Then from the squeeze theorem $a_n(x)=\frac{\sin^2(n^nx)}{\sqrt{n+2}}\to 0$ as $n\to\infty$ , regardless of the value of $x$ . Hence $\ln(1+a_n(x))\to0$ as $n\to \infty$ as well. So for large $n$ , $f_n$ is practically $\cos(x+n)$ . I know that the set of functions $$\mathcal{E}=\left\{f\in C^1(\Bbb R,\Bbb R): |f'(x)|\le1\right\}$$ is uniformly equicontinuous. Thus the subset $$\{\cos(x+n):n\in\Bbb N\}\subset \mathcal{E}$$ is also uniformly equicontinuous. Of course this does not necessarily imply that functions that behave like $\cos(x+n)$ (in the aforementioned way that $f_n$ does) are also uniformly equicontinuous. Unfortunately, $\{f_n(x):n\in\Bbb N\}$ does not seem to be a subset of $\mathcal{E}$ , so I can't really take the easy way out here. Is there some way to rigorize my argument, or is there a better way to go about things? Thanks.","['continuity', 'equicontinuity', 'functional-analysis', 'real-analysis']"
3444714,Is finite verbal subgroup equivalent to finite index of marginal subgroup?,"There is a well known fact: If $G$ is a finitely generated group. Then $|G’| < \infty$ iff $[G:Z(G)]<\infty$ . Suppose $\mathfrak{U}$ is a group variety. Let’s denote the corresponding verbal subgroup as a $V_{\mathfrak{U}}(G)$ and the corresponding marginal subgroup as $M_{\mathfrak{U}}(G)$ . Note, that for the variety of all abelian groups $\mathfrak{A}$ (defined for the word $[x, y]$ ) we have $V_{\mathfrak{A}}(G) = G’$ and $M_{\mathfrak{A}}(G) = Z(G)$ . My question is: Can the aforementioned statement be generalized to the following one: If $G$ is a finitely generated group and $\mathfrak{U}$ is a variety, defined by one word. Then $|V_{\mathfrak{U}}(G)| < \infty$ iff $[G:M_{\mathfrak{U}}(G)]<\infty$ . ?","['universal-algebra', 'infinite-groups', 'verbal-subgroups', 'finitely-generated', 'group-theory']"
3444739,Probability terminology: determining events based on random variable evaluations,"I am reading a paper right now on a constructive proof for the Lovasz Local Lemma and I want to sanity check my understanding on some of their terminology that is unfamiliar to myself. I will include a passage that illustrates what I'm concerned with: So the first piece of terminology here I want to make sure I understand is first the discussion about the events $A$ determined by values of some subset of random variables $S$ of $\mathcal{P}$ . My understanding can be expressed with an example. Suppose we have a probability space $\Omega = \lbrace \omega_1, \omega_2, \omega_3, \omega_4 \rbrace$ . Further, define our set of random variables $\mathcal{P} = \lbrace X_1, X_2 \rbrace$ where we define the two random variables to be \begin{align}
X_1(\omega) &= \begin{cases} 2 & \text{if } \omega \in \lbrace \omega_1, \omega_2 \rbrace \\
1 & \text{if } \omega \in \lbrace \omega_3 \rbrace \\
0 & \text{otherwise}
\end{cases} \\
X_2(\omega) &= \begin{cases} 1 & \text{if } \omega \in \lbrace \omega_2 \rbrace \\
0 & \text{otherwise}
\end{cases}
\end{align} Now my suspicion is an event $A$ is determined by some set of random variables $\lbrace X_1, X_2 \rbrace$ by making $A$ equal to the intersection of the events that make $X_1$ and $X_2$ output some values. So for example, if $X_1 = 2$ and $X_2 = 1$ , we would say the event $A$ determined by the values of these two random variables is $A = \lbrace \omega_1, \omega_2 \rbrace \cap \lbrace \omega_2 \rbrace = \lbrace \omega_2 \rbrace$ . It is also appears that within this example, $\lbrace X_2 \rbrace \subset \mathcal{P}$ is a minimal subset needed to determine $A$ , so it seems that $\text{vbl}(A) = \lbrace X_2 \rbrace$ . Is all of this correct so far? Also, I just want to make sure I understand their use of ""evaluating"" a random variable. Is an evaluation of a random variable really just choosing a value for it? So if I choose $X_1 = 1$ , that's an evaluation of the random variable $X_1$ ? If so, it seems the passage is saying that an evaluation of a set $S$ of random variables violates $A$ if we have some evaluation for the random variables and this evaluation determines some event $\mathcal{E}$ such that $\mathcal{E} \subseteq A$ , since this determined event should imply that $A$ should happen. Does this seem reasonable? If so, I do not think I understand why they claim there's a unique minimal subset that determines $A$ . Seems to me there need not be a unique minimal subset but that there could be multiple subsets that achieve the smallest cardinality possible that can determine $A$ with an appropriate evaluation. Thus, I suspect I am understanding their terminology incorrectly. Any help one can provide to help me understand the terminology and few concepts would be great.","['probability', 'terminology']"
3444763,Dividing a polygon into 6 equal regions,"You are given a convex polygon, ie all its internal angles are less than 180 degrees. Prove that you can always draw three straight lines through a specific point inside this polygon, such that they divide it into 6 equal (by area) regions? Bonus questions: Can you prove that this can be achieved for non-convex polygons too? This time the point may not lie inside the polygon. Does this result extend to 4 lines dividing a convex polygon into 8 equal regions? This question was inspired by the hard problem in the recent TopCoder Open Algorithm final, written by Michal Forisek (misof).",['geometry']
3444855,Evaluating $\lim_{x\to0}{\frac{\sqrt[3]{\cos{4x}}-\sqrt[3]{\cos{5x}}}{1-\cos{3x}}}$ without L'Hopital's rule,"I'm currently struggling with this task: $$\lim_{x\to0}{\frac{\sqrt[3]{\cos{4x}}-\sqrt[3]{\cos{5x}}}{1-\cos{3x}}}$$ By now I have only come up with the idea to use the formula of sum of cubes, so, the numerator would become $\cos{4x}-\cos{5x}$ and the denominator would be $3(1-\cos{3x})$ : $$\frac{\sqrt[3]{\cos{4x}}-\sqrt[3]{\cos{5x}}}{1-\cos{3x}} = \frac{(\sqrt[3]{\cos{4x}}-\sqrt[3]{\cos{5x}})*(\sqrt[3]{cos^2{4x}} + \sqrt[3]{\cos{4x}}*\sqrt[3]{\cos{4x}} + \sqrt[3]{\cos^2{5x}})}{(1-\cos{3x})*(\sqrt[3]{cos^2{4x}} + \sqrt[3]{\cos{4x}}*\sqrt[3]{\cos{4x}} + \sqrt[3]{\cos^2{5x}})} = \frac{\cos{4x}-\cos{5x}}{3(1-\cos{3x})}$$ In this expression it looks like $\cos{4x}-\cos{5x}$ and $(1-\cos{3x})$ increase with the same speed (if I can say it this way) and the limit is likely to be $\frac{1}{3}$ . Still I have no idea how to prove that without using L'Hopital's rule which is prohibited by the task.","['limits-without-lhopital', 'real-analysis', 'calculus', 'limits', 'trigonometry']"
3444869,Proving a series converges if and only if an expectation is finite [duplicate],"This question already has an answer here : Show that $\sum_{n=1}^{\infty}X_n<\infty$ almost surely if and only if $\sum_{n=1}^{\infty}\mathbb E[\frac{X_n}{1+X_n}]<\infty$. (1 answer) Closed 4 years ago . I'm struggling with a probability theory question that asks me to show a series converges almost surely if and only if an expectation is finite. Does anyone know how I can solve this problem? Let $X_{1}, X_{2}, \ldots$ be independent random variables all taking
  non-negative values. Prove that the series $\sum_{i=1}^{\infty} X_i$ converges almost surely if and only if $$\sum_{i=1}^{\infty}E\left(\frac{X_i}{1 + X_i}\right) < \infty$$ I don't know if it helps, but the book I am studying from teaches the three series and two series theorems in this chapter.  I don't know if there might be some way to cleverly apply that here with this expectation, but I have not been able to do so.","['measure-theory', 'expected-value', 'convergence-divergence', 'probability-theory', 'probability']"
3444972,What allows us to use the Heaviside operator like a variable?,"We were taught to use the Heaviside operator $D: \dfrac{d}{dx}$ to solve an ODE, for example, Consider $y'' + 3y' +2y = e^{-2x}$ $$\implies (D^2 + 3D + 2)y = e^{-2x}$$ $$\implies y = \dfrac{1}{D^2 + 3D + 2} e^{-2x}$$ $$\implies y = \dfrac{1}{(D+1)(D+2)} e^{-2x}$$ Now we substitute $-2$ in place of $D$ , in this case the denominator becomes zero, so we differentiate the denominator with respect to $D$ as if it's a variable and multiply $^*$ a factor $x$ . $$ y = \dfrac{x}{(D+1)+(D+2)} e^{-2x}$$ And then do the substitution $$\implies y = -xe^{-2x}$$ How is this possible, how are we able to treat an operator $\dfrac{d}{dx}$ like a variable? What does differentiate with respect to $D$ even mean? $*:$ I also don't understand why we multiply $x$ in the numerator Reference: https://www.youtube.com/playlist?list=PLEC88901EBADDD980","['ordinary-differential-equations', 'operator-theory', 'calculus', 'partial-differential-equations', 'derivatives']"
3444979,A problem from Analysis On Manifold by Munkres,"Let $A$ and $B$ be rectangles in $R^n$ and $R$ ,respectively.Let $S$ be a set contained in $A\times B$ .For each $y\in B$ ,let $$S_y=\{x|x\in A\ \text{and}\ (x,y)\in S\}.$$ We call $S_y$ a cross-section of $S$ .Show that if $S$ is rectifiable ,and if $S_y$ is rectifiable for each $y\in B$ ,then $$v(S)=\int_{y\in B}v(S_y)$$ According to this book,I should give a explanation of some words . Let $S$ be a bounded set in $R^n$ .If the constant function 1 is Riemann integrable over $S$ ,we say that $S$ is rectifiable and we define the ( $n$ -dimensional) volume of $S$ by the equation $$v(S)=\int_{S}1.$$ I have sloved this problem with @Matematleta help,but I find another question in zorich's Analysis(11.4.3.(2)) which can be seen,to some extent, as a inverse proposition of the above problem. If $S_y$ is rectifiable for each $y\in B$ ,and if $v(S_y)$ is integrable over $B$ .Can we assert that in this case the set $S$ is rectifiable ? I think the answer is affirmative,but I have no idea how to prove it.Any help will be thanked.","['integration', 'analysis', 'real-analysis']"
3445032,Find the value of $\int_{-\infty}^{\infty} \frac{e^{-x^2}}{1+x^2} dx$ . [duplicate],"This question already has answers here : Methods to solve $\int_{0}^{\infty} \frac{e^{-x^2}}{x^2 + 1}\:dx$ (3 answers) Closed last year . Find the value of $\int_{-\infty}^{\infty} \frac{e^{-x^2}}{1+x^2} dx$ My attempt First, I know the existence of this integral since $$ \mid \int_{-a}^{a} \frac{e^{-x^2}}{1+x^2} dx \mid \;\; \leq\;\;  \mid \int_{-a}^{a} \frac{1}{1+x^2} dx \mid$$ Next, let $R >0 $ be an arbitrary and $\gamma_1(t) = -R(1-t) + Rt , \;\; 0 \leq t \leq1$ and $\gamma_2(t)= Re^{i\pi (t-1)}, \;\; 1 \leq t \leq 2 $ . So, take $f(z) = \frac{e^{-z^2}}{1+z^2}$ . I tried to find the value or upper bound of norm of $$\int_{\gamma_2} \frac{e^{-z^2}}{1+z^2} dz$$ . However, $$ \lvert\int_{\gamma_2} \frac{e^{-z^2}}{1+z^2} dz\rvert \leq  \frac{\text{max}\lvert e^{-z^2}\rvert}{R^2-1}\pi R = \frac{e^{R^2}}{R^2-1}\pi R $$ So, I can't proceed this. May I ask you how to solve this?","['complex-analysis', 'complex-integration']"
3445037,Deducing information based on common denominators between unknown fractions.,"I'm trying to answer a 3-part question from the ""Art of Problem Sovling: Introduction to Algebra"" book. The problem is outlined as: Fiona, George and Henry each think of a different fraction. The simplest common denominator between Fiona's and George's fraction is $10ab^{2}$ . The simplest common denominator between George's and Henry's fraction is $20a^{3}b^{2}$ . The simplest common denominator between Fiona's and Henry's fraction is $4a^{3}b$ The questions are: (a)Whose fraction has the highest power of $b$ ? What is the power? (b)Whose fraction has the largest constant? (Assuming all constants are positive) (c)What is the simplest common denominator between all 3 fractions. Here's how I attempted to answer this. (a) It's George because all the common denominators between George and the other two result in more $b$ 's being factored out. I assume the power is $b^{2}$ but I'm not too sure, because Henry's and Fiona's $b$ power could be preventing from further factoring George's fraction. (b)
My guess is either George or Henry, but which one of the two I'm not sure. (c) $LCM(10,4,20) = 20 \therefore 20ab$ I'd appreaciate if someone could clear this up in most explanative manner.",['algebra-precalculus']
3445057,"Number of shortest paths on a grid from $(0,0)$ to $(m,n)$ that don't go through (odd,odd) except perhaps $(m,n)$","I know that without restrictions there are $\binom{m+n}{n}$ such ways and i guess i should look at the number of paths that go through (odd,odd) but it seems to me that there are too many situations to check, is there a smart way to do this.
Also i found this How many lattice paths are there from $(0,0)$ to $(2n,2n)$ that avoids odd points this only avoids points on $(2i-1,2i-1)$ where for example $(1,3)$ is allowed.","['combinatorics', 'discrete-mathematics']"
3445062,"$f,g$ analytic on $I\subset \mathbb{R}$. If exist $a\in I$ such that $f=g$ and $f^{(n)}=g^{(n)}$then we have $f(x)=g(x)$ for every $x \in I$.","Problem Let $f,g$ analytic on an open interval $I\subset \mathbb{R}$ . If exist
some $a\in I$ such that $f(a)=g(a)$ and $f^{(n)}(a)=g^{(n)}(a)$ for
all $n \in \mathbb{N}$ then we have $f(x)=g(x)$ for every $x \in I$ . Show this is no longer true if you just suppose $f,g$ class $C^\infty
> $ Well, my idea is just write these series and show that if all terms are the same, these functions well be the same as well. But my main problem is understanding this fundamental difference between analytic or $ C^\infty $ . The core of this problem is being able to write the series of these functions?","['analytic-functions', 'analyticity', 'real-analysis']"
3445065,Evaluate $\lim\limits_{n \to \infty}\sum\limits_{k=1}^{n}\frac{\sqrt[k]{k}}{\sqrt{n^2+n-nk}}$,"$$\lim_{n \to
 \infty}\sum_{k=1}^{n}\frac{\sqrt[k]{k}}{\sqrt{n^2+n-nk}}$$ How to consider it?",['limits']
3445066,Dimension of affine variety mod $p$ can only increase,"Let $X$ be an affine variety defined by polynomials over $\mathbb{Z}$ .
Reducing the polynomials modulo $p$ , we obtain a variety $X_p$ defined over the finite field $\mathbb{F}_p$ . Is it true that the dimension of $X_p$ is larger or equal to the dimension of $X$ ? Note: It seems likely to me that the dimension stays the same for all but finitely many primes $p$ , and this answers says that it is the case for projective varieties. My question is different: I'm asking about affine varieties, I'm asking about all primes, and I'm only asking for an inequality. EDIT : To make the second part of the question explicit: In addition, is it also true that $\dim X_p=\dim X$ for all but finitely many primes $p$ ?",['algebraic-geometry']
3445132,Solving $\tan 2x=1+2\sin 4x$,Solve: $$\tan 2x=1+2\sin 4x$$ My work: $$\left(\frac{\sin2x}{\cos2x}\right)(1+2\cos2x)(1-2\cos2x)=1$$ $$\frac{(\sin2x+\sin4x)(\sin2x-\sin4x)}{\cos2x}=1$$ $$\frac{-6\sin x \sin2x}{\cos2x}=1$$ $$\tan2x+\csc6x=0$$ How to proceed after this?,['trigonometry']
3445169,"Is there a short, elementary way to show $\cos(x+y)=\cos x\cos y-\sin x\sin y$ for any angles $x$ and $y$?","In High School, the above mentioned formula is often proved assuming that $x,y$ are acute angles and using some more or less 'brilliant' geometrical construction. And after that, books 'forget' the assumption about the angles and apply the identity to whatever angles. There is a trivial, long and tedious proof by cases, with all combinations of the possible quadrants where $x$ and $y$ can lie. Is there a shorter way to extend the formula for whatever angles? The proof must be suitable for High School, that is, no Taylor series or Euler's formula. I don't think that this is a duplicate of the proposed question, because the first answer considers only acute angles and the second uses Euler's formula.","['trigonometry', 'education']"
3445203,A normal distribution question is this the correct way of going about it?,"A study of data collected at a company manufacturing flashlight
  batteries shows that a batch of 8000 batteries have a mean life of 250
  minutes with a standard deviation of 20 minutes. Assuming a Normal
  Distribution, estimate: (i) How many batteries will fail before 220 minutes? This is my answer to this question does it look correct or are there any improvements I can make? Batch: 8000
Mean: 250 minutes 
SD: 20 minutes

(250-220)/20 = 1.5

Z-score of 1.5 = .4332

(.5-.4332)8000 = 534.4 will fail after 220 minutes","['statistics', 'probability-distributions', 'normal-distribution', 'probability']"
3445257,Interesting identity $\sum_{A\subseteq X\\B\subseteq X}|A\cap B|=n4^{n-1}$,"Let $X = \{1,2,\dots,n\}$ . Prove that the following identity holds: $$\sum_{A,B\subseteq X}|A\cap B|=n4^{n-1}$$ I noticed by using Inclusion-Exclusion formula that $$
\begin{aligned}
\sum_{A\subseteq X\\B\subseteq X}|A\cap B|
&=\sum_{A\subseteq X\\B\subseteq X}|A|+\sum_{A\subseteq X\\B\subseteq X}|B|-\sum_{A\subseteq X\\B\subseteq X}|A\cup B|\\
&=\sum_{A\subseteq X}|A|2^{n}+\sum_{B\subseteq X}|B|2^{n}-\sum_{A\subseteq X\\B\subseteq X}|A\cup B|\\
&=2^n\sum_{A\subseteq X}|A|+2^{n}\sum_{B\subseteq X}|B|-\sum_{A\subseteq X\\B\subseteq X}|A\cup B|\\
&=2^{n+1}\sum_{k=1}^nk\binom{n}{k}-\sum_{A\subseteq X\\B\subseteq X}|A\cup B|
\end{aligned}
$$ By using identity $\sum_{k=1}^nk\binom{n}{k}=n2^{n-1}$ , we get: $$
\sum_{A\subseteq X\\B\subseteq X}|A\cap B|=n4^{n}-\sum_{A\subseteq X\\B\subseteq X}|A\cup B|$$ But now i am stuck.","['probabilistic-method', 'inclusion-exclusion', 'combinatorics', 'discrete-mathematics', 'elementary-set-theory']"
3445298,Question from Exercise $1.8$ in Karatzas and Shreve. Representation of a filtration.,"This is Exercise $1.8$ from Karatzas and Shreve. Let $X$ be a process whose sample paths are RCLL a.s., and let $A$ be the event that $X$ is continuous on $[0,t_0)$ . Show that $A$ can fail to be in $\mathscr{F}^X_{t_0}$ . This is part of the solution given in the text. We first construct an example with $A \notin \mathscr{F}_{t_0}^X$ . The collection of sets of the form $\{(X_{t_1},X_{t_2},\dots)\in B\}$ , where $ B \in \mathscr{B}(\mathbb{R}^d) \otimes \mathscr{B}(\mathbb{R}^d) \otimes \cdots $ and $0\le t_1 < t_2 < \cdots \le t_0,$ forms a $\sigma$ -field and each such set is in $\mathscr{F}_{t_0}^X$ . Indeed, every set in $\mathscr{F}_{t_0}^X$ has such a representation. Choose $\Omega = [0,2), \mathscr{F}= \mathscr{B}([0,2))$ , and $P(F) = \operatorname{meas}(F \cap [0,1]);$ $F \in \mathscr{F}$ , where meas stands for ""Lebesgue measure."" For $\omega \in [0,1]$ , define $X_t(\omega)=0,$ $\forall t \ge 0;$ for $\omega \in (1,2),$ define $X_t(\omega)=0$ if $t \neq \omega$ , $X_\omega(\omega)=1$ . Choose $t_0=2.$ If $A \in \mathscr{F}_{t_0}^X$ , then for some $B \in \mathscr{B}(\mathbb{R}^d) \otimes \mathscr{B}(\mathbb{R}^d) \otimes \cdots $ and some sequence $t_k \in [0,2]$ , we have $A = \{(X_{t_1},X_{t_2},\dots)\in B\}.$ Choose $\bar{t} \in (1,2)$ , $\bar{t} \notin \{t_1, t_2, \dots\}.$ Since $\omega = \bar{t} $ is not in $A$ and $X_{t_k}(\bar{t})=0, k=1,2, \dots, $ we see that $(0,0,\dots) \notin B$ . But $X_{t_k}(\omega)=0,$ $k=1,2, \dots,$ for all $\omega \in [0,1]$ ; we conclude that $[0,1] \cap A = \phi$ , which contradicts the definition of $A$ and the construction of $X$ . I am not convinced by the bolded statement. How do we show that every set in a filtration is of the given form?","['stochastic-processes', 'measure-theory', 'stochastic-calculus', 'real-analysis']"
3445309,Understanding a statement in a paragraph in Royden (4^th edition) on pg.136,"The paragraph is given below: My question is:
Why this statement ""Since complements of sets of measure zero are dense in $\mathbb{R}$ "" is correct? could anyone explain this for me please?","['measure-theory', 'proof-writing', 'analysis', 'real-analysis']"
3445335,Stuck on a probability law problem,"I'm currently trying to solve a problem, I completed the first question but I am stuck at the second one, here is the problem: One person roll a die until the result is a $1$ , a second person toss a coin until he gets $3$ tails. How many tries are they going to make on average. $X$ = number of die rolls $Y$ = number of time we toss a coin $X$ follows a geometric law with parameter $1/6$ , $E(X) = 6$ and $V(X) = 30$ . $Y$ follows a negative binomial law with $n = 3$ and $p = 1/2,$ $E(Y) = 3/(1/2) = 6$ and $V(Y) = n(1-p)/p^2 = 6.$ What is the probability that they both stop at the same time $(p(X = Y)).$ I found $p(X=Y) =  \sum_{k=3}^\infty p(X=k, Y=k) $ so the same sum with $p(X=k)p(Y=k)$ since they are independent. Then $p(X=k)p(Y=k)  = (5/6)^{k-1} \cdot\frac16 \begin{pmatrix} k-1 \\ 2 \\ \end{pmatrix} 
 \left(\frac12\right)^{k-3}\left(\frac12\right)^3$ But now i don't know how to compute it so i can get the value of that probability? Any help would be very appreciated. Thanks","['summation', 'combinatorics', 'probability']"
3445371,Riemann sum of $\int_1^2 {1\over x^2} dx$.,"I've spent quite a time solving the following problem: Evaluate using Riemann's sum: $$
I = \int_1^2{1\over x^2} dx
$$ I was first trying the following approach, which didn't work since the summation seems undoable to me: $$
\Delta x = {1\over n}\\
I = \lim_{n\to\infty}\sum_{k=1}^nf\left(1+{k\over n}\right)\Delta x \\
= \lim_{n\to\infty}\sum_{k=1}^n{n^2\over (k+n)^2} {1\over n} \\
= \lim_{n\to\infty}\sum_{k=1}^n{n\over (k+n)^2}
$$ Wolfram evaluates this sum in terms of digamma function which is too advanced. Several hours has passed before I decided to reconsider the point to choose in each partition. Let: $$
\Delta x = {1\over n}\\
x_k = 1 + {k\over n}\\
\begin{align}
I &= \lim_{n\to\infty}\sum_{k=1}^nf\left(\sqrt{x_k x_{k-1}}\right)\Delta x \\
&= \lim_{n\to\infty}\sum_{k=1}^n{1 \over x_k x_{k-1}}\Delta x \\
&= \lim_{n\to\infty}\sum_{k=1}^n{1 \over \left(1+{k\over n}\right)\left(1+{k-1\over n}\right)}\Delta x \\
&= \lim_{n\to\infty}\sum_{k=1}^n{n^2 \over (n+k)(n+k-1)}{1\over n}\\
&=\lim_{n\to\infty}\sum_{k=1}^n{n \over (n+k)(n+k-1)} \\
&=\lim_{n\to\infty}\sum_{k=1}^n\left({n \over (n+k-1)} - {n \over (n+k)}\right)\\
&= {n\over n} - {n\over 2n}\\
&= \boxed{{1\over 2}}
\end{align}
$$ This sum telescopes nicely. Now I'm wondering whether the first approach is even doable. I've met some other questions but the first one lists a hint I don't really understand and the second one is closed as a duplicate. What would be the way to finish the initial approach? In the first approach, the problem is actually reduced to finding the limit which I couldn't handle. Also is there some intuition in choosing the ""right"" points in the partitions?","['limits', 'calculus', 'riemann-sum', 'real-analysis']"
3445401,Proving that there exists only one non-negative eigenfuction for the following operator.,"Fix some constants $a>1$ , $\sigma>0$ and consider $x_- = -\sigma/(\alpha-1)$ , $x_+ = \sigma/(\alpha - 1)$ , and $M=[x_-,x_+]$ .  Consider the Banach space $V = \left(\mathcal C^0 (M),|\cdot |_{\infty}\right)$ where $$\mathcal C^0(M) = \{f:M\to\mathbb R;\ f\ \text{is a continuous function}\}, $$ and $$\left|f\right|_\infty = \sup_{x\in M}\left|f(x)\right|. $$ Defining the linear operator \begin{align*}
T:V&\to V\\
f&\mapsto\left(x\mapsto \frac{1}{2\sigma} \int_{\frac{1}{\alpha}\left(x-\sigma\right)}^{\frac{1}{\alpha}\left(x+\sigma\right)} f(y)\ \text d y\right),
\end{align*} it is ''easy to see'' that $T$ is a continous and compact operator, moreover $r(T)>0$ (where $r(T)$ is the spectral radius of $T$ ). Defining convex cone $K:= \mathcal C^0_+(M) = \{f\in V;\ f(x)\geq 0, \forall\ x\in M\}$ , and noticing that $T(K)\subset K$ and $K-K= V$ , by Krein-Rutman theorem there exists an eigenfunction $g\in K$ , such that $$T(g) = r(T)g. $$ My Question: Is it possible to show that $g$ is the unique eigenfunction of $T$ lying in the cone $K$ ? Comment: I think that the only non-negative eigenfunction of $T$ is the constant function $1$ .","['eigenfunctions', 'linear-algebra', 'functional-analysis', 'real-analysis']"
