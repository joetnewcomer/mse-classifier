question_id,title,body,tags
434432,"Calculating the limit $\lim\limits_{a\to0} \int_0^2 {1 \over ax^4+2}\,\mathrm dx$","I have some trouble calculating this integral: $$\lim_{a\to 0} \int_0^2 {1 \over ax^4+2}\,\mathrm dx$$ Got something divided by zero all of the time. Thanks in advance for any assistance!","['definite-integrals', 'calculus', 'integration', 'limits']"
434443,How can I prove $\nabla \cdot \color{green}{(\mathbf{F} {\times} \mathbf{G})} $ with Einstein Summation Notation?,"Source: Stewart. Calculus: Early Transcendentals (6 edn 2007) . p. 1068. §16.5, Exercise #27. $\nabla \cdot \color{green}{(\mathbf{F} {\times} \mathbf{G})} = \partial_h\color{green}{\epsilon_{hij}F_iG_j}$ $ = \epsilon_{hij}\partial_h[F_iG_j]$ $ = \color{purple}{\epsilon_{hij}G_j\partial_hF_i} \color{red}{+} \epsilon_{hij}F_i\partial_hG_j $ $\color{purple}{1. \text{How do I determine whether } \epsilon_{hij}G_j\partial_hF_i =   \mathbf{G} \times \nabla \mathbf{F} \text{ or } \mathbf{G} \cdot (\nabla \times \mathbf{F}) ?}$ $\color{darkred}{\text{3. The answer shows a negative sign $-$, not +. What did I miss?}}$ I read this . My guess One answer to my question 1 is that the divergence of a vector field, ie $\nabla \mathbf{F}$ , is always a scalar. So taking its cross product is nonsensical. This is why $ \color{purple}{ \mathbf{G} \times \nabla \mathbf{F} } $ is wrong. First Attempt Recanted due to celtschk's Answer: I tried to compute $\operatorname{div}(\mathbf{F} \times \mathbf{G})$ by considering the $j$ th component term in the sum of the divergence operator: $\color{red}{[}\nabla \cdot \color{green}{(\mathbf{F} {\times} \mathbf{G})}\color{red}{]}_\color{red}{\LARGE{j}} = \partial_\color{red}{\LARGE{j}}{\epsilon_{hi\color{red}{\LARGE{j}}}}F_{\huge{\color{green}{i}}}G_{\huge{\color{green}{i}}} = \color{green}{\epsilon_{hi\color{red}{\LARGE{j}}}}\partial_\color{red}{\LARGE{j}}[F_{\huge{\color{green}{i}}}G_{\huge{\color{green}{i}}}] = \color{purple}{\epsilon_{hi\color{red}{\LARGE{j}}}G_i\partial_\color{red}{\LARGE{j}}F_i} \color{brown}{+} \color{gray}{\epsilon_{hi\color{red}{\LARGE{j}}}F_i\partial_\color{red}{\LARGE{j}}G_i} $ Supplement due to Muphrid and celtschk: $1.1.$ Without geometric calculus or wedge products or any more advanced topics, how can I  divine to move $G_h$ to the front, as Muphrid did? $3.1.$ In $\color{purple}{F_i\partial_hG_j}$ , the order of the subscripts is $\color{purple}{(i, h, j)}$ But in $\epsilon_{hij}$ , the order is $(h, i, j)$ . Thus, I must rotate $(h, i, j)$ to obtain $\color{purple}{(i, h, j)},$ by swapping $\color{purple}{h}$ and $\color{purple}{i}$ once $\Longrightarrow \epsilon_{hij} = -\epsilon_{\color{purple}{ihj}} $ . This yields the required answer. Must [the order of the subscripts of the components] = [the order of the subscripts in the Levi-Civita symbol]? Why does this work? Supplement due to Muphrid's Comment on July 17th: $3.2.$ How can I divine to pull $G_j$ to the front, and NOT the back? You did: $\color{purple}{\epsilon_{hij}G_j\partial_hF_i} = \color{purple}{(\epsilon_{hij}\partial_hF_i)G_j} = \color{purple}{G_j\epsilon_{\color{magenta}{jhi}}\partial_hF_i = \mathbf{G} \cdot (\nabla \times \mathbf{F})}. $ I would've computed: $\color{purple}{\epsilon_{hij}G_j\partial_hF_i} = \color{purple}{(\epsilon_{hij}\partial_hF_i)G_j = (\nabla \times \mathbf{F}) \cdot \mathbf{G}. \text{ But this is wrong! }}$ Supplement due to celtschk & Muphrid's Comments on July 22nd From celtschk: It is also not strictly required that the order of indices maps the order in the vector expression. However it helps to do that because it's less error prone... From Muphrid: Yes, the order of indices in the Levi-Civita matters... $3.3. $ Don't these two comments contradict? Must [the order of the subscripts of the components] = [the order of the subscripts in the Levi-Civita symbol] ? $3.4.$ Ought the order for both match? Why or why not?","['multivariable-calculus', 'derivatives']"
434453,"Find the density function of $Y=e^Z$ where $Z \sim N(\mu, \sigma^2)$","Find the density function of $Y=e^Z$  ,where $Z \sim N(\mu, \sigma^2)$ This is called the lognormal density , Since $\log Y$ is normally distributed.",['statistics']
434460,"How can I proved, that $\left\{\sqrt{\tfrac{2}{\pi}}\sin(kx):k\in\mathbb{N}\right\}$ is an orthonormal basis of $L^2[0,\pi]$?","I want to prove that $S = \left\{\sqrt{\tfrac{2}{\pi}}\sin(kx):k\in\mathbb{N}\right\}$ forms an orthonormal basis of $L^2[0,\pi]$. I may use the fact, that $B = \left\{\sqrt{\tfrac{2}{\pi}}\sin(2kx):k\in\mathbb{N}\right\} \cup \left\{\sqrt{\tfrac{2}{\pi}}\cos(2kx):k\in\mathbb{N}\right\} \cup \{ \tfrac 1 \pi \}$ is an orthonormal basis for $L^2[0,\pi]$. To show, that $S$ is an orthonormal system is easy. But I have problems to show, that the span of $S$ is dense in $L^2[0,\pi]$. I could already show that $\left\|\tfrac1\pi\right\|^2 = \sum_{k=1}^\infty \left|\langle\tfrac 1\pi,\sqrt{\tfrac{2}{\pi}}\sin(kx)\rangle\right|^2$. Does this imply that $\tfrac1\pi$ is in the closure of the span of $S$? So am I right that the only think left to show for me is $\left\|\cos(2mx)\right\|^2 = \sum_{k=1}^\infty \left|\langle\cos(2mx),\sqrt{\tfrac{2}{\pi}}\sin(kx)\rangle\right|^2$? (which I couldn't do so far) My idea is to prove that $B$ is in the closure of the span of S and thus the span of $S$ dense in $L^2[0,\pi]$ (because the span of $B$ is dense in $L^2[0,\pi]$).","['fourier-series', 'orthonormal', 'functional-analysis']"
434481,Computing a contraction of an exceptional divisor.,"For a few days, I have been working on the following problem, from Qing Liu's book: Let $\mathcal{O_K}$ be a discrete valuation ring with uniformizing parameter t and residue characteristic $\neq 2,3$. Let $X = Proj \mathcal{O}_K[u,v,w] /(u^2w+v^3+t^6w^3)$. Determine the minimal desingularization of X. I have been able to desingularize X by blowing it up first at $(t,u,v)$ to obtain $\widetilde{X}$and then, calling the additional coordinates in the blow-up by $(x_1,x_2,x_3)$, blowing $\widetilde{X}$ up at $(t,x_2,x_3)$ and then normalizing the corresponding scheme one gets. Let  us call this scheme, obtained from two blow-ups and normalizing for $Z$, and the scheme we get from blowing up twice for $Y$. I then got that:
$$Z = Proj \widetilde{X}[v_1,v_2,v_3]/(v_1x_2-tv_2,v_1x_3-tv_3,v_2x_3-v_3x_2,v_1v_2^2+v_3^3+v_1^3)$$
and
$$\widetilde{X} = Proj X[x_1,x_2,x_3]/(x_1u-tx_2,x_1v-tx_3w,x_2^2w+x_3^2v+t^4x_1^2).$$
However, I might have made a mistake , but I believe Z to be regular. Now, one can check that there is an exceptional E divisor in $Z_k$, in $Z$ has defining equations $$(t,u,v,v_1,v_3).$$ I want to contract this E, so I should find an ample effective cartier divisor D such that $\mathcal{O}_Z(D)$ is generated by global sections, $\mathcal{O}_Z(D)_{Z_K}$ (restriction to the generic fiber) is ample, $Supp D \cap E = \emptyset$ and for any other curve on $Z$, the restriction of $\mathcal{O}_Z(D)$ to it is ample. Now, I get that we should look for such a divisor in the generic fiber, and I believe that I might have found a candidate, namely $D=(v_3+v_1,v_2)$. I also believe that by Riemann-Rochlike theorems, $3D$ should be ample and generated by global sections. However, here is my problem: I want to see, in concrete, how I can calculate the contraction morphism AND the resulting scheme one gets. I just don't want to wave my hands and say that we contract, I would like to do one calculation in all detail, just to know how it works. But when I have been trying to do this, I get hopefully stuck, and I end up getting nowhere. Since my computational powers fail me, I would be more than thankful for someone taking their time and actually showing me how this calculation is done. Thank you for your time. Update: I believe that the normalization can be wrong, but I am not sure.","['arithmetic-geometry', 'algebraic-geometry', 'surfaces']"
434544,Is the intersection of an arbitrary collection of semirings a semiring?,"A semiring (of sets) is a nonempty class $\mathcal{P}$ of subsets of the whole space $X$ that is closed under intersections and is such that any difference of two sets in $\mathcal{P}$ can be expressed as a finite disjoint union of sets in $\mathcal{P}$. Motivation for this question: for any class $\mathcal{E}$ of subsets of the whole space $X$, does there exist a unique smallest semiring containing $\mathcal{E}$? In other words, does there exist such a thing as the semiring generated by $\mathcal{E}$? I believe the answer is ""no,"" but I don't really have a good reason why. The actual question: Normally, to prove the existence of rings (or fields, I'll just stick to rings for simplicity) generated by a set $\mathcal{E}$, we first show that the intersection of an arbitrary collection of rings is again a ring. My hunch is that this result does not hold for semirings, and is the reason why there (possibly) does not exist such a thing as a semiring generated by $\mathcal{E}$. Let $\mathcal{P}_{\gamma}$ be a semiring for every $\gamma$ in some index set $\Gamma$. Define $\mathcal{P} = \cap \{\mathcal{P}_{\gamma}: \gamma \in \Gamma\}$. Then if $E, F \in \mathcal{P}$, we have that $E,F \in \mathcal{P}_{\gamma}$ for every $\gamma$. Then by the definition of semiring for each $\gamma$ there exists a disjoint collection of sets $\{E_{n_{\gamma}}\} \in \mathcal{P}_{\gamma}$ such that $E-F = \cup E_{n_{\gamma}}$ (for each $\gamma$ this sequence may be different). But for some reason I'm having trouble seeing why I can't take this disjoint sequence $\{E_{n_{\gamma}}\}$ to be common across $\gamma$. If I can, then it follows that an intersection of an arbitrary collection of semirings is a semiring, and then it follows that generated semirings exist. But I'm becoming convinced that they don't exist. Can anyone point out where I'm tripping up?","['measure-theory', 'real-analysis']"
434553,What does $f: A \times A \to A$ mean?,What does $f: A \times A \to A$ mean? Can you give some examples please?,"['notation', 'functions']"
434562,curl(fF) with Einstein Summation Notation,"I considered the $k$th component of $\text{curl $f\mathbf{F}$}$. $f$ is a scalar field and $\mathbf{F}$ a vector field. $\color{green}{[}\nabla \times (fF)\color{green}{]} _{\LARGE{\color{green}{k}}} = \epsilon_{ij\LARGE{\color{green}{k}}}\partial_i(f\mathbf{F})_j $ $= \epsilon_{ij\LARGE{\color{green}{k}}}\partial_i(fF_j) \qquad \qquad \qquad \qquad (\text{since $\mathbf{(F)}_j :=$ the $j$th component of $\mathbf{F} = F_j$})$ $= \epsilon_{ij\LARGE{\color{green}{k}}}(F_j\partial_if + f\partial_iF_j) \qquad \qquad  (\text{since $f$ scalar})$ $= \underbrace{\epsilon_{ij\LARGE{\color{green}{k}}}F_j\partial_if}_{\Large{\bigstar}} + f\underbrace{{\epsilon_{ij\LARGE{\color{green}{k}}}\partial_iF_j}}_{\LARGE{\color{green}{[}\nabla \times \mathbf{F}\color{green}{]}_{\LARGE{\color{green}{k}}}}} $ Hereafter, I refer only to the term with the star underneath.  Since [$\color{#007FFF}{F_j}$ corresponding to $\color{#007FFF}{\mathbf{F}}$] appears before [$\color{#FF00FF}{\partial_if}$ corresponding to $\color{#FF00FF}{\nabla f}$], thus ${\epsilon_{ij\LARGE{\color{green}{k}}}\color{#007FFF}{F_j}\color{#FF00FF}{\partial_if}} = {\color{green}{[}\color{#007FFF}{\mathbf{F}} \times \color{#FF00FF}{\nabla f}\color{green}{]} _{\LARGE{\color{green}{k}}}}$. But the answer states $\color{green}{[}\nabla f \times \mathbf{F}\color{green}{]} _{\LARGE{\color{green}{k}}}$. What went wrong? $\large{\text{Supplement to Andrew D's response :}}$ Here's my understanding of your answer : In ${\epsilon_{ij\LARGE{\color{green}{k}}}F_j\partial_if}, \; {(i, j, \LARGE{\color{green}{k}})}$ (in the subscript of the Levi-Civita symbol) denotes the order of the components. So the $i$th component must appear first, and the $j$th component second. However, since $(i, j, k) = \color{brown}{(j, k, i)}$, therefore  $\epsilon_{ijk} = \epsilon_{\color{brown}{\LARGE{jki}}}$. $\color{brown}{\text{Now, $j$ precedes $i$, so wouldn't this result in the wrong order of the components?}}$ $\large{\text{2nd Supplement to Andrew D's Comment beneath his Answer :}}$ $\color{#3EB489}{\text{The variable in the permutation succeeding the variable that's not summed}}$ corresponds to the first component to appear. Here, $k$ denotes the component being analysed so is not summed. Since I am looking at $\color{brown}{(j, k, i)}$, $\color{#3EB489}{i}$ succeeds $k$ so the $\color{#3EB489}{i}$th component is the first. Therefore, ${\epsilon_{ijk}F_j\color{#3EB489}{\partial_{\LARGE{i}}}f}$ = ${\epsilon_{\color{brown}{\LARGE{jki}}}\color{#3EB489}{\partial_{\LARGE{i}}}F_jf} = \color{green}{[}\color{#3EB489}{\nabla f} \times \mathbf{F}\color{green}{]} _{\LARGE{\color{green}{k}}} $ However, this appears to discord with Steven Stadnicki's 2nd comment, according to which: $ {\epsilon_{\color{brown}{\LARGE{jki}}}F_j\partial_if} = {\color{green}{[}\mathbf{F} \times \nabla f\color{green}{]} _{\LARGE{\color{green}{k}}}}$?",['multivariable-calculus']
434569,Hilbert space on line bundle,"Suppose that $L$ is a complex line bundle on a manifold $M$ with measure $\mu$, How can we prove, $L^2(M,L,\mu)$ is Hilbert space?","['geometry', 'differential-geometry', 'fiber-bundles', 'algebraic-geometry', 'hilbert-spaces']"
434571,Roulette betting system probability,"The Fibonacci is a popular Roulette betting system that is based on a naturally occurring mathematical sequence. The sequence itself is cumulative. In other words, the next number is equal to the sum of the two previous ones. So the first 12 numbers in the sequence are: 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144 How this system works is: You progress through the sequence on losing bets and return towards the start with winning bets. Each time you lose, you move on to the next number in the sequence. Each time you win, you step back two numbers. I was wondering, if I were to use £10 as my initial bet betting on red and black only on the American Roulette wheel (with the double zeros), what are the chances of winning once in a series of 12 bets? That is, what are my chances of winning at least £10 in the total sum of money that I need to put in for the whole series of 12 bets: £10, £10, £20, £30, £50, £80, £130, £210, £340, £550, £890, £1440 Note that this is different than the Martingale system in that once you win a bet, you don't start over at the beginning of the sequence (£10 initial bet). Instead, you step back two numbers.","['fibonacci-numbers', 'probability']"
434580,Confusion on Derived Sets and the $n$-the Derived Set,"I want to solve the following exercise 1.3.C. from page 27 of R. Engelking: General Topology. For every positive integer $n$ the $n$ -th derived set $A^{(n)}$ of a subset $A$ of a topological space $X$ is defined inductively by the formulas: $$
 A^{(1)} = A^d \quad \textrm{and} \quad A^{(n)} = (A^{(n-1)})^d.
$$ (a) Give an example of a set of real numbers that has three consecutive derived sets distinct from each other. (b) Give an example of a set of real numbers that has infinitely many derived sets distinct from each other. The definition is $$
  A^d := \{ x \in X \mid x \in \overline{A \setminus \{ x \}} \}.
$$ I am confused, cause the set $A^d$ ist closed, i.e. $\overline{A^d} = A^d$ . And closed means it already contains all its limit points, so how can then $(A^d)^d$ be different from $A^d$ ?","['general-topology', 'analysis']"
434587,Matrix determinant $\neq 0$,"I have problem with this task: Given a square matrix $A = [a_{ij}]^n_{i,j=1} \in M_{n \times n}(\mathbb{R})$ and $t \geq 0$ satisfies conditions: $\forall i \neq j : a_{ij} = t,$ $\forall i : a_{ii} > t$. How to prove that $\det A \neq 0$ ? I have tried with brute force, but it isn't a good way to solve it.","['matrices', 'linear-algebra']"
434609,Problem with the proof that $\zeta(s)$ has no zeros for $\mathrm{Re}(s) = 1$,"Almost every proof I read says that If $\zeta(s)$ has a zero of order $\mu$ in $1 + ai$ ($\mu \geq 0$) then
  $$\lim_{\epsilon \to 0}\; \epsilon \frac{\zeta'(1+\epsilon +ai)}{\zeta(1+\epsilon +ai)} = \mu $$ without spending a word to explain it. Why is this so obvious? Thank you!","['complex-analysis', 'number-theory']"
434621,Can I identify the distribution of a random variable given a related distribution function?,"Let $X_1$, $X_2$ be i.i.d random variables. Suppose we know the distribution function of $X:=|X_1-X_2| =\max\{X_1,X_2\} - \min\{X_1,X_2\}$. Can we find the distribution of $X_1$? I realize that to have any hope of identification we must fix the support of these random variables since $|X_1-X_2| = |(X_1+C)-(X_2+C)|$ for any constant $C$. Considering first absolutely continuous random variables, with supports of the type $[a,b]$, or open ended intervals such as $[0,infinity)$, are there conditions under which the distribution of $X_1$ can be determined uniquely? Thanks.","['probability-theory', 'probability-distributions']"
434625,What's $\sum_{n \ge 0} q^{n^2}$?,"Is there a relatively simple way of calculating the sum of the series $$\sum_{n=0}^\infty q^{n^2}, \quad |q|<1 ?$$","['sequences-and-series', 'summation', 'calculus', 'real-analysis']"
434643,non empty set with empty interior is countable at most,"A is non empty set of R and set of interior points of A is empty. Then A is countable at most. How to (dis)prove it? Empty interior for non-empty set implies that A consist of isolated points. I cannot imagine uncountable (i.e. infinite) set of isolated points, that's why I tend to think that the statement is true. Could you help me to prove?","['general-topology', 'calculus']"
434676,Cyclic vectors of an irreducible representation of a C*-algebra,"Let $\mathcal{A}$ be a C*-algebra and $(H,\pi)$ an irreducible representation of $\mathcal{A}$. I want to prove the statement:  all $\xi \in H$ are cyclic or $\pi(\mathcal{A})=\{0\}$ and $H=\mathbb{C}$. How can one approach this problem? Suppose there is a $\hat{\xi}\in H$ that is not cyclic, then $\{a\hat\xi:a\in \pi(\mathcal{A})\}$ is not dense in H, i.e. $\{a\hat\xi:a\in \pi(\mathcal{A})\}^{\perp}\neq \{0\}$. From here on, I don't know how to conclude that $\pi(\mathcal{A})=\{0\}$ and $H=\mathbb{C}$.","['c-star-algebras', 'operator-algebras', 'representation-theory', 'functional-analysis']"
434685,Do equivalent norms preserve dual spaces?,"Suppose that $X^*$ is the dual space of a normed space $X$. If we renorm the space $X^*$ with a new norm equivalent to the first one, is this new normed space the dual of $X$ as well?
(I think it suffices to prove that a functional $f$ is continuous with a norm1 if and only if it is continuous with norm2 where norm1 and norm2 are two equivalent norms. This seems to be obvious!). Thanks for the help.","['normed-spaces', 'functional-analysis']"
434687,Equivalence between Ext and Hom,"This is a question from Homology by Saunders Mac Lane. This is problem 5 page 76. I've been struggling to solve this problem for like more than a day, but still nothing valuable comes across my mind yet. Problem For $p$ prime, and $C$ an Abelian group such that $pC = 0$ , prove that: $$\mbox{Ext}_\mathbb{Z}(C; G) \cong \mbox{Hom}(C; G/pG)$$ I've made a couple of attempts, but all of them fail. Firstly, I try to find some connections between the elements in $\mbox{Ext}_\mathbb{Z}(C; G)$ , and the elements in $\mbox{Hom}(C; G/pG)$ . The elements of $\mbox{Ext}_\mathbb{Z}(C; G)$ is a short exact sequence of Abelian groups $0 \to G \to W \to C \to 0$ , with $W$ varies. So given this exact sequence, how can I manage to find a homomorphism from $C$ to $G/pG$ ? And vice versa, given a homomorphism, how can I deduce a short exact sequence? Secondly, I try to make use of the fact that $pC = 0$ . Although I know that $C$ can only be some group of orders $p^k$ , can I deduce that $C = \bigoplus\mathbb{Z}_p$ , or is it $C = \prod\mathbb{Z}_p$ ? That's all I have in mind till now. :( Is there some other way that to look at this problem? Thanks very much, And have a good day, :* Edit (July, 03) I've managed to prove the problem for the simpliest case, i.e, for $C = \mathbb{Z}_p$ , i.e, to prove: $$\mbox{Ext}_\mathbb{Z}(\mathbb{Z}_p; G) \cong \mbox{Hom}(\mathbb{Z}_p; G/pG)$$ I hope someone can have a quick look over the proof. Consider the short exact sequence: $$0 \to p\mathbb{Z} \to \mathbb{Z} \to \mathbb{Z}_p \to 0$$ Apply $\mbox{Ext}^n(-; G)$ to the above ses (? is this the right way to say it) , gives the long one: $$0 \to \mbox{Hom}(\mathbb{Z}_p; G) \to \mbox{Hom}(\mathbb{Z}; G) \xrightarrow{\chi} \mbox{Hom}(p\mathbb{Z}; G) \xrightarrow{\sigma} \mbox{Ext}(\mathbb{Z}_p; G) \to \mbox{Ext}(\mathbb{Z}; G) = 0$$ Hence $\sigma$ is epic, we'll have: $\mbox{Hom}(p\mathbb{Z}; G)/\mbox{Im} \chi \cong \mbox{Ext}(\mathbb{Z}_p; G)$ . Notice that a group homomorphism $f$ from $\mathbb{Z}$ to $G$ is completely determined if we know $f(1)$ , similarly any $g: p\mathbb{Z} \to G$ will be determined by $g(p)$ . So, in fact, we'll have $\mbox{Im}(\chi) = \left\{ f: p\mathbb{Z} \to G \middle| f(p) \in pG\right \}$ . And hence, 2 classes of $f$ , and $g$ in $\mbox{Hom}(p\mathbb{Z}; G)/\mbox{Im}$ will be congruent iff $f - g \in \mbox{Hom}(p\mathbb{Z}, pG)$ . So: $\mbox{Hom}(p\mathbb{Z}; G)/\mbox{Im} \chi \cong \mbox{Hom}(p\mathbb{Z}; G/pG) \cong \mbox{Hom}(\mathbb{Z}; G/pG)$ , since $\mathbb{Z} \cong p\mathbb{Z}$ as Abelian groups. And moreover, one should notice that, for every $f \in \mbox{Hom}(\mathbb{Z}; G/pG)$ , and for every $m, n \in \mathbb{Z}$ , such that $(m - n) \vdots p$ , then $f(m) = f(n)$ . Which, in turns means that, $\mbox{Hom}(\mathbb{Z}; G/pG) \cong \mbox{Hom}(\mathbb{Z}_p; G/pG)$ . Hence, it's done. And I've found this pdf http://www.math.wichita.edu/~pparker/classes/handout/torext.pdf , which says that: $$\mbox{Ext}\left( \bigoplus A_i; B\right) \cong \prod \mbox{Ext}\left( A_i; B\right)$$ So if it's true that $pC = 0 \Leftrightarrow C = \bigoplus \mathbb{Z}_p$ , if so, then everything should be pretty clear. Questions So some of my concerns left are: ""Apply $\mbox{Ext}^n (-; G)$ to..."" is this the right way to say it? Does the proof I gave for $\mbox{Ext}_\mathbb{Z}(\mathbb{Z}_p; G) \cong \mbox{Hom}(\mathbb{Z}_p; G/pG)$ look correct? Can it be shortened? I know that $\mbox{Ext}\left( \bigoplus A_i; B\right) \cong \prod \mbox{Ext}\left( A_i; B\right)$ , but is it also true that $\mbox{Ext}\left( \prod A_i; B\right) \cong \bigoplus \mbox{Ext}\left( A_i; B\right)$ ? Can you guys guide me to some article, or some book, or website that have a proof to that? Or, can you guys just give me some hints on proving them? Is it true that $pC = 0 \Leftrightarrow \left[ \begin{array}{l} C = \oplus\mathbb{Z}_p \\ C = \prod \mathbb{Z}_p \end{array} \right.$ ? Thank you very much,","['exact-sequence', 'derived-functors', 'abstract-algebra', 'homological-algebra', 'modules']"
434706,Sufficient condition for a *-homomorphism between C*-algebras being isometric,"Let $\mathcal{A},\mathcal{B}$ be two unital C*-algebras and consider a *-homomorphism $\pi: \mathcal{A} \rightarrow \mathcal{B}$. I know that in general $\pi$ is contractive, i.e. $\vert\vert \pi(A) \vert\vert \leq \vert\vert A \vert\vert, \forall A\in \mathcal{A}$. I want to show that under the additional assumption that $\pi(A)>0, \forall A>0$ one has equality, i.e. $\pi$ is an isometry: $\vert\vert \pi(A) \vert\vert = \vert\vert A \vert\vert, \forall A\in \mathcal{A}$ The crucial step in establishing the previous inequality lies in the fact that $\forall A\in\mathcal{A}$ $$r(\pi(AA^*)) \leq r(AA^*),$$ where $r$ denotes the spectral radius, respectively. Since $AA^*$ is positive, I sense that the additional condition enters at this point, but I can't finish the proof. Am I on the wrong foot? Help is highly appreciated!","['c-star-algebras', 'operator-algebras', 'functional-analysis']"
434720,Convex hull of orthogonal matrices,Where can I find the proof of the fact that the convex hull of the set of orthogonal matrices is the set of matrices with norm not greater than one? It is easy to show that a convex combination of orthogonal matrices has norm (I mean the norm as operators) not larger than $1$. The reverse seems quite tricky...,"['convex-analysis', 'matrices', 'orthogonal-matrices', 'spectral-norm', 'convex-hulls']"
434721,$\lim (a_n - a_{n-1}) = 0$ for convergent $a_n$,"If $a_n$ is convergent and sequence $b_n = a_n - a_{n-1}$, then $\lim b_n = 0$ It's true because $\lim b_n = \lim (a_n - a_{n-1}) = \lim a_n - \lim a_{n-1} = 0$. The last limits are equal due to convergence of $a_n$. Is it correct proof?",['sequences-and-series']
434737,"Given that the first child draws $10\$$ from his envelope, what is the probability that the second child has an envelope that contains a 20$ note?","Three children each receive an envelope from their grandparents. It is known that each envelope contains three banknotes and that in the three envelopes together there are two $5\$$ notes, four $10\$$ notes and three $20\$$ notes. The first child opens his envelope and the first note that he draws from it is a $10\$$ bill. What is now the probability that the second child has a $20$$ note in his envelope? I have difficulty thinking about this question as it seems very complex. My intuition tells me that probably conditional probabilities are involved and maybe even Bayes' rule. However, besides that, I have no clue where to start. Could anyone please help?","['statistics', 'probability']"
434742,Finding $\lim\limits_{x\to0}x^2\ln (x)$ without L'Hospital,"I am preparing a resit for calculus and I encountered a limit problem. The problem is the following: $\lim\limits_{x\to0}x^2\ln (x)$ I am not allowed to use L'Hospital. Please help me, I am stuck for almost an hour now.","['calculus', 'limits']"
434765,Trig substitution $\int x^3 \sqrt{1-x^2} dx$,$$\int x^3 \sqrt{1-x^2} dx$$ $x = \sin \theta $ $dx = \cos \theta d \theta$ $$\int \sin^3 \theta d \theta$$ $$\int (1 - \cos^2 \theta) \sin \theta  d \theta$$ $u = \cos  \theta$ $du = -\sin\theta d \theta$ $$-\int u^2 du$$ $$\frac{-u^3}{3} $$ $$\frac{\cos^3 \theta}{3}$$ With the triangle trick I get: $$\frac{-\sqrt{1-x^2}^3}{3}$$ This is wrong but I am not sure where I went wrong.,['calculus']
434769,How and what to teach on a first year elementary number theory course?,"In the late 80’s and early 90’s there was the idea of ‘calculus reform’ and some emphasis and syllabus changed. The order of doing things in calculus also changed with the advantage of technology. 
Similarly in linear algebra there was a linear algebra curriculum study group which produced some really good ways of teaching linear algebra and also highlighted curriculum changes. This was produced in the January 1993 College Mathematics Journal.
Has any similar work been covered in number theory. I am looking for what are the important topics to cover and any work or research on the teaching of number theory.","['education', 'elementary-number-theory', 'discrete-mathematics']"
434787,Matsunaga's Method for solving $x^2+y^2=p$,"In his history of number theory, Dickson mentions an 18th century algorithm due to Matsunago [Sic --- he means, presumably, Matsunaga Ryohitsu a.k.a. Matsunaga Yoshisuke] for finding two numbers whose squares sum to a given integer $p$.  Dickson's source Mikami can be found describing the Matsunaga method in entry 15 on page 233 here: http://quod.lib.umich.edu/u/umhistmath/ACD4271.0008.001/244?rgn=full+text;view=pdf Quoting: ``To solve the equation $x^2+y^2=k$, let $\tfrac{1}{2}k$ be $=r^2+R$, where $r^2$ is the greatest square contained in $k$.  Form the quantities $$ a_1 = 2r-1 \quad a_2 = a_1 - 2 \quad a_3 = a_2 -2 \ldots $$
$$ b_1 = 2r+1 \quad b_2 = b_1 + 2 \quad b_3 = b_2 + 2 \ldots $$ and from $2R=A$ successively subtract $b_1$, $b_2$, $\ldots$.  When these subtractions are impossible, successively add $a_1$, $a_2$, $\ldots$ and carry out the subtractions.  If we come at last to a remainder that vanishes, let the values of $a$ and $b$ employed in the last place be $a'$ and $b'$.  Then $x = \tfrac{1}{2}(a'+1)$ and $y = \tfrac{1}{2}(b'-1)$ is a solution required."" I have a lot of questions about this, but I'll start with:
Can you make this work?  I've tried several different interpretations of the instructions but have been unable to make it work to produce the representations $5 = 1^2 + 2^2$, $10 = 1^2 + 3^2$, $13 = 2^2 + 3^2$, $17 = 4^2 + 1^2$, $41 = 4^2 + 5^2$, ... in a reliable manner.  I desire a systematic way to follow these instructions that produces each of these representations (and others, if possible!).  Or perhaps this does not work for all $k$ (i.e., the remainder 0 is not reached).  But an exposition of how it works when it does work would be appreciated. Incidentally, the wording differs slightly from that given by Dickson.  I doubt he would include this result as stated if it didn't hold some merit.  Perhaps his rewording of the instructions (p.229 of volume 2 of his ""Number Theory"") was clarifying exactly how the algorithm was to be performed?","['math-history', 'number-theory']"
434789,"That Brownian Motion's increments are gaussian is ""not surprising""?","In section 1 of chapter 1 of Continuous Martingales and Brownian Motion , the authors claim that the fact that the increments of of Brownian motion are gaussian random
  variables ""is not surprising in view of the central-limit theorem"". Why do they put a hyphen between 'central' and 'limit'? Just kidding, my real question is: What do they mean by this? My understanding of the CLT is limited to, ""the averages of same-size samples from any distribution converges in distribution to a gaussian distribution"" (and please correct me if that's wrong), but I don't see how that applies here.","['probability-theory', 'probability-limit-theorems', 'probability-distributions', 'brownian-motion']"
434798,Difference between two definitions of Manifold,"I've been studying Differential Geometry on Spivak's Differential Geometry book. Since Spivak just works with notions of metric spaces and analysis, I'm doing fine. The point is that Spivak presents the following definition of a manifold: A manifold $M$ is a metric space such that for every $p \in M$ there's some neighbourhood $V$ of $p$ and some integer $n \geq 0$ such that $V$ is homeomorphic to $\Bbb R^n$ Now, there's another definition, usually given in texts that assume the reader knows general topology, and the definition is: A manifold $M$ is a topological space such that: $M$ is Hausdorff; $M$ has a countable basis for its topology; $M$ is locally Euclidean. For now I'm happy with Spivak's definition because I've not seen general topology yet, but I'm curious with one thing: these two definitions are equivalent? In other words, every topological space with those three properties is metrizable, so that it can be put in terms of the first definition? Is there any other way in which these definitions can be said to be equivalent? Thanks very much in advance for the help.","['general-topology', 'manifolds']"
434823,Quadratic equation which has rational roots,"If the following quadratic equation 
  $$qx^2+(p+q)x+bp=0$$
  always has rational roots for any non-zero integers $p$ and $q$ what will be the value of $b$? My book's solution says the value of $b$ will be $0$ or $1$. If we consider the  discriminant of the equation,
$$D=(p+q)^2-4bqp =  p^2+2q(1-2b)p+q^2$$ 
then $D$ should be a perfect square of a rational number for the equation having rational roots. so the value of b should be 0 0r 1 for given conditions (p and q are non-zero integers and the equation always has rational roots) But I am not sure whether  we can conclude the discriminant $D=p^2+2q(1-2b)p+q^2$ is a perfect square of a rational number if only if b is 0 or 1. I can see if b is 0 or 1, then $D$ will be $(p+q)^2$ or $(p-q)^2$. So $D$ will be a perfect square of a rational number. But I can't figure out the other case: If $D$ is a perfect square of a rational number for any non-zero integer p and q
, then the value of b will be 0 or 1. EDIT 1 : b is rational number.",['algebra-precalculus']
434837,Integration trig substitution $\int \frac{dx}{x\sqrt{x^2 + 16}}$,$$\int \frac{dx}{x\sqrt{x^2 + 16}}$$ With some magic I get down to $$\frac{1}{4} \int\frac{1}{\sin\theta} d\theta$$ Now is where I am lost. How do I do this? I tried integration by parts but it doesn't work.,"['calculus', 'integration']"
434838,Primes as quotients,"I ask this question based on a comment of David Speyer in another question . What primes are of the form
$$
\frac{p^2-1}{q^2-1}
$$
where $p$ and $q$ are prime? The first prime not apparently of this form is 17. The Diophantine equation
$$
p^2-17q^2+16=0
$$
has solutions following a linear recurrence relation which has no primes in the first 1000 terms (only $(\pm1, 1)$ seeds may contain primes). But perhaps there is a better way to go about this?","['prime-numbers', 'diophantine-equations', 'number-theory']"
434863,"Ultrafilter condition: If A is a subset of X, then either A or X \ A is an element of U","My confusion concerns ultrafilters on sets that are themselves power sets. If $X=\{\emptyset,\ \{1\},\ \{2\},\ \{3\},\ \{4\},\ \{1,2\},\ \{1,3\},\ \{1,4\},\ \{2,3\},\ \{2,4\},\ \{3,4\},\ \{1,2,3\},\ \{1,2,4\},\ \{1,3,4\},\ \{2,3,4\},\ \{1,2,3,4\}\ \}$ and the upset $\{1\}=U=\{\ \{1\},\ \{1,2\},\ \{1,3\},\ \{1,4\},\ \{1,2,3\},\ \{1,2,4\},\ \{1,3,4\},\ \{1,2,3,4\}\ \}$ is supposedly a principal ultrafilter (for visual delineation see https://en.wikipedia.org/wiki/Filter_%28mathematics%29 ), then how do I satisfy the criteria that ""If $A$ is a subset of $X$, then either $A$ or $X\setminus A$ is an element of $U$""? For example, could I let $A=\{\emptyset,\{2\}\}$ such that $A\notin U$, but $X\setminus A\notin U$ because $\{2,3,4\}\in X\setminus A,\{2,3,4\}\notin U$? My understanding of the distinction between an element and a subset is unrefined, particularly with regard to power sets.","['filters', 'elementary-set-theory']"
434868,"$I=(3,x^2+1)$ be an ideal of $\mathbb{Z}[x]$. Then $I$ is a proper ideal of $\mathbb{Z}[x]$","This is from an old exam. Here is the problem. Let $I=(3,x^2+1)$ be an ideal of $\mathbb{Z}[x]$. Then $I$ is a proper ideal of $Z[x]$ How does one go about showing that this is a proper ideal. Should I consider $Z[x]/I$ and then show that it is neither $Z[x]$ nor $0$ thus showing that $I$ must be a proper ideal or is there some other easier way to proceed? My attempt: Since $I=\{ 3p(x)+(x^2+1)q(x): p(x), q(x) \in Z[x] \} $ we know that the constant term of $f(0)$ of any element $f(x) \in I$ must be of the form $3n+m$ for $m,n \in \mathbb{Z}$. Does this help me in anyway?. Am I making this too complicated than it should be? Can you kindly help? Thank you in advance for your answers.","['ring-theory', 'ideals', 'abstract-algebra']"
434891,"Physical meaning of ""probability density""","Is there some way of describing the co-domain of probability density functions? Does it relate in some way to something physically meaningful? I was given that question today - and I was at a loss. Density for me, is the co-domain of pdfs - a scalar dimension with values from zero to infinity. For instance, I fit a normal distribution to a probability vector on N values (a probability mass function). This vector contains normalised values of the actual frequency counts in a histogram with N bins. The normalisation is done by dividing each frequency count by the discrete integral ""area"" of the pmf - so that the pmf values sum to 1. The pmfs now seems to be scaled similarly to the estimated pdfs. Is probability density a measure of probability? I am sure that the necessary definitions must be hidden somewhere deep down in the guts of measure theory - which is why I have included that as a tag.","['probability-theory', 'measure-theory', 'probability-distributions']"
434899,"Differential equation two solutions, how so?","I tried to solve $7x^3y'=4*\sqrt{y}$ with $y(1)=1$ now I thought that Picard Lindelöf would tell me that there is a (at least in a local area for x=1) unique solution unfortunately I found two: 
$y(x)=(-\frac{1}{7x^2}+\frac{8}{7})^2, y(x)=(-\frac{1}{7x^2}-\frac{6}{7})^2$. Can somebody explain to me why this is the case here?","['ordinary-differential-equations', 'calculus', 'real-analysis']"
434932,What does $X \subsetneqq Y$ mean,"What does $X \subsetneqq Y$ mean? I cannot find it on Google, I suppose this means, it is a subset and at the same time it is not the same. I.e. it could be simply written as $\subset$. Pardon my ignorance.","['notation', 'elementary-set-theory']"
434933,Proving $\sum_{n=-\infty}^\infty e^{-\pi n^2} = \frac{\sqrt[4] \pi}{\Gamma\left(\frac 3 4\right)}$,"Wikipedia informs me that $$S = \vartheta(0;i)=\sum_{n=-\infty}^\infty e^{-\pi n^2} = \frac{\sqrt[4] \pi}{\Gamma\left(\frac 3 4\right)}$$ I tried considering $f(x,n) = e^{-x n^2}$ so that its Mellin transform becomes $\mathcal{M}_x(f)=n^{-2z} \Gamma(z)$ so inverting and summing $$\frac{1}{2}(S-1)=\sum_{n=1}^\infty f(\pi,n)=\sum_{n=1}^\infty \frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}n^{-2z} \Gamma(z)\pi^{-z}\,dz = \frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\zeta(2z) \Gamma(z) \pi^{-z}\,dz$$ However, this last integral (whose integrand has poles at $z=0,\frac{1}{2}$ with respective residues of $-\frac 1 2$ and $\frac 1 2$) is hard to evaluate due to the behavior of the function as $\Re(z)\to \pm\infty$ which makes a classic infinite contour over the entire left/right plane impossible. How does one go about evaluating this sum?","['sequences-and-series', 'integration', 'summation', 'complex-analysis', 'contour-integration']"
434934,How to find what point a wave is reflected off,"If a wave is reflected off a surface, the angle of reflection is equal to the angle of incidence.  But, how can we use this to find the actual path of the incident and reflected waves if we only know the positions of the wave origin and observer? It seems clear that the reflection will occur in the plane normal to the reflective surface and including the origin and observer.  We can then look at this problem in two dimensions: (I've drawn the reflection off a horizontal line because my actual application involves a blast wave reflected off the ground in order to simulate the mach stem effect in a game.  The blast wave also reaches the observer directly, but the mach stem effect is concerned with the constructive interference between this and the reflected wave.) We know point O (the wave origin) and point P (the observer.)  We know that R (the reflection point) lies on the ground line somewhere between where O and P project to the ground, but we don't know where.  We also don't know theta although we do know it's the same on both sides. I'm sure this is a relatively simple trigonometry problem but I'm terrible at seeing these things.  Any ideas?","['trigonometry', 'reflection']"
434959,Motivation for/history of Jacobi's triple product identity,"I'm taking a short number theory course this summer. The first topic we covered was Jacobi's triple product identity . I still have no sense of why this is important, how it arises, how it might have been discovered, etc. The proof we studied is a bit on the clever side for my taste, giving me no sense of how said proof might have been discovered. Can anyone help?","['motivation', 'q-series', 'sequences-and-series', 'math-history']"
434975,Stuck on an 'advanced logarithm problem': $2 \log_2 x - \log_2 (x - \tfrac1 2) = \log_3 3$,"I'm stuck on solving what my textbook calls an ""advanced logarithm problem"". Basically, it's a logarithmic equation with logarithms of different bases on either side. My exercise looks like this: $$2 \log_2 x - \log_2 (x - \tfrac1 2) = \log_3 3$$ To start off, I used the power rule to simplify the first term to get this: $$\log_2 x^2 - \log_2 (x - \tfrac1 2) = \log_3 3$$ Then I used the quotient rule to get this: $$\frac {x^2} {x - \frac 1 2}  = \log_3 3$$ Then I turned the logarithmic equation into an exponential equation to get this: $$3^{\frac {x^2} {x - \frac 1 2}} = 3$$ Now, however, I'm unsure of how to proceed. The textbook has neither explained to me how to simplify such complex exponents nor do such exponents have any precedence. I'm therefore assuming that I went wrong somewhere previously in solving the problem, but as far as I can tell I did everything by the book. Did I go wrong? And if not, am I really supposed to simplify that exponent?","['logarithms', 'algebra-precalculus']"
434992,"How can one simplify $¬(¬∃x, P(x)) $ and $\neg(\neg\forall x,P(x))$?","What I've learned so far: $\lnot$($\forall$$x$, P($x$)) $=$ $\exists$$x$, $\lnot$P($x$) $\lnot$($\exists$$x$, P($x$)) $=$ $\forall$$x$, $\lnot$P($x$) So far so good (I hope!) But what about negating a negative ""for all"" or ""there exists"": $\lnot$($\lnot$$\forall$$x$, P($x$)) $=$ ??? $\lnot$($\lnot$$\exists$$x$, P($x$)) $=$ ??? One of the problems says, for example: Let F(x, y) be the statement ""x can fool y.""  Write ""Nobody can fool themselves"" with quantifiers, negate it, and then write the negation in English: My answer: Quantifiers: $\lnot$$\exists$$x$ $F(x, x)$ Negation: $\exists$$x$ $F(x, x)$ English: Someone can fool themselves. I feel that this is right, but I want to be sure: when you negate an entire statement that already has a negative quantifier, that quantifier simply loses the ""not,"" and DOESN'T become the opposite quantifier?","['logic', 'quantifiers', 'discrete-mathematics', 'predicate-logic']"
434995,Possibilities for $[KL:F]$ when $[K:F]=[L:F]$ is prime,"Suppose $K/F$ and $L/F$ are extensions of $F$ (contained in some common field) of degree $p$, where $p$ is prime. Standard arguments show that $[KL:F]$ must be in $\{p,2p,\ldots,p^2\}$. But are all these multiples attained for every $p$? I.e. for all primes $p$ and for all integers $1\leq r\leq p$, do there exist $K$, $L$, and $F$ as above with $[KL:F]=rp$? Stating this in terms of Galois theory (using the fact that every prime-degree extension is separable), does there exist a group $G$ with index-$p$ subgroups $H_1,H_2$ of $G$ such that $|G:H_1\cap H_2|=rp$? Edit (I'm not sure whether this should be in an answer or not): It's straightforward to show that if $KL/F$ is Galois, so that $G$ is its Galois group, then either $r=p$ or $(r,p-1)\neq 1$: Assume $r\neq p$. By Sylow's theorems, $n_p:=\text{number of Sylow }p\text{-groups}$ is congruent to $1$ mod $p$ and divides $r$. But $r<p$, so $n_p=1$. Thus, there's a unique (and therefore normal) Sylow $p$-subgroup $P\cong Z_p$. So, $G= P\rtimes H_1=P\rtimes H_2$. If $(r,p-1)=1$, then there's no nontrivial homomorphism from either $H_1$ or $H_2$ to $\operatorname{Aut}(Z_p)\cong Z_{p-1}$, and so the semidirect products are in fact direct. But then (since $r\neq p$) $H_1$ and $H_2$ are normal Hall subgroups of the same order and therefore equal, which can only happen if $r=1$. Thus, $r=p$ or $(r,p-1)\neq 1$. So, to solve the general problem when $(r,p-1)=1$, we can't make the simplifying assumption that $H_1$ and $H_2$ have trivial intersection, i.e. that $KL/F$ is Galois.","['galois-theory', 'finite-groups', 'group-theory', 'field-theory']"
435002,how to compare $\sin(19^{2013}) $ and $\cos(19^{2013})$,"how to compare $ \sin(19^{2013})$  and $\cos (19^{2013})$ or even find their value range with  normal calculator? I can take $2\pi k= 19^{2013} \to \ln(k)= 2013 \ln(19)- \ln(2 \pi)=5925.32 \to k= 2.089 \times 10^{5925}$, but it useless.(I can get final answer with WolframAlpha but it is not allowed.) Any hint? thanks!","['algebra-precalculus', 'numerical-methods']"
435011,Finding the interval for increase of the function $y =x^2e^{-x}$,"Problem : Find the interval in which the function $y =x^2e^{-x}$ is increasing . My approach : We can take first derivative to the find the increase or decrease of function ie. $y'=2xe^{-x}-x^2e^{-x}$ finding the critical point by putting y'=0 $ \Rightarrow xe^{-x}(2-x)=0$ $\Rightarrow x =0, x =2$ are the critical point ( please clarify here) Now if we take second derivative at these critical points : $y'' = x^2e^{-x}-4xe^{-x}+2e^{-x}$ ; If we put x =0 then we get  2 ( which is positive ) that means at 0 function attains minimum values.... please help me to find the interval in which it increases...As the function attains minimum value at 0, I think from 0 onwards it start increasing.. but unable to locate the interval ....","['calculus', 'derivatives', 'functions']"
435025,Sum of terms in a composition cycle,"Let $f, g$ be linear functions. Define $S(x)$ as $any$ composition sequence of $f$ and $g$ like $S(x) = (f\circ g\circ g\circ f\circ f\circ g)(x)$ Let $s$ as the fixed point of $S$ then a cycle is determined $s \to_g g(s) \to_f (f\circ g)(s) \to_f (f\circ f\circ g)(s) \to_g (g\circ f\circ f\circ g)(s) \to_g (g\circ g\circ f\circ f\circ g)(s) \to_f s (again)$ Call $Sum_g(S)$ the sum of the terms of the cycle such that $g$ function is applied to this term. In this example $Sum_g(S) = s + (f\circ f\circ g)(s) + (g\circ f\circ f\circ g)(s)$ Define $T(x)$ as the reversed composition sequence $T(x) = (g\circ f\circ f\circ g\circ g\circ f)(x)$ Call $t$ the fixed point of $T$ In this example $Sum_g(T) = (f)(t) + (g\circ f)(t) + (f\circ f\circ g\circ g\circ f)(t)$ Prove that $Sum_g(S) = Sum_g(T)$ $f(x) = 3x-2$ and $g(x)=2x+1$ $S(x) = (f\circ g\circ g\circ f\circ f\circ g)(x) = 216 x + 19$ and $s = -19/215$ $T(x) = (g\circ f\circ f\circ g\circ g\circ f)(x) = 216 x - 105$ and $t = 21/43$ $Sum_g(S) = s + (f\circ f\circ g)(s) + (g\circ f\circ f\circ g)(s) = -19/215 -127/215 -39/215 = -37/43$ $Sum_g(T) = (f)(t) + (g\circ f)(t) + (f\circ f\circ g\circ g\circ f)(t) = -23/43 -3/43-11/43 = -37/43$ A visual approach $f(x) = 3x-2$ (or any linear function) $g(x)=x/5+1$ (or any other linear function) Then $ \color{red}{215/98 \to_g} \color{blue}{141/98 \to_f 227/98 \to_f} \color{red}{485/98 \to_g 195/98 \to_g} \color{blue}{137/98 \to_f} 215/98 (again)$ Obs: $215/98$ is the fixed point of $(f\circ g\circ g\circ f\circ f\circ g)(x)$ The reversed cycle is $ 177/98 \color{red}{_g\leftarrow 395/98} \color{blue}{_f\leftarrow 197/98 _f\leftarrow 131/98} \color{red}{_g\leftarrow 165/98 _g\leftarrow 335/98} \color{blue}{_f\leftarrow 177/98} (again)$ Obs: $177/98$ is the fixed point of $(g\circ f\circ f\circ g\circ g\circ f)(x)$ why this happens? $ \color{red}{215/98 + 485/98 + 195/98 = 395/98 + 165/98 + 335/98}$ $\color{blue}{141/98 + 227/98 + 137/98 = 197/98 + 131/98 + 177/98} $","['sequences-and-series', 'algebra-precalculus', 'functions', 'function-and-relation-composition', 'summation']"
435029,Understanding Bertini's theorem,"Let's suppose that I am given a pencil generated by the vector fields $X$ and $Y$ in $\mathbb{C}^2$, $\{ Z_\lambda \}_{\lambda\in\mathbb{P}^1}$, that is, 
$$
Z_\lambda = X + \lambda Y
$$ Assume that $X$ and $Y$ are non-singular except in the origin $(0,0)$. By Bertini's Theorem, does this mean that for a generic $\lambda \neq 0,\infty $, the generic element of the pencil $Z_\lambda$ is non-singular except in the origin? If not, can someone please explain me what I am missing?",['algebraic-geometry']
435050,Is $\mathbb{N}$ infinite?,"Intuitively the answer is yes. According to the definition, a set $A$ is infinite if there is no bijection between $A$ and some natural number. Now, I don't know the problem of my reasoning. Accordingly the funcion $f:\mathbb{N}\longrightarrow 0$ is a bijection (Because $f\subseteq \mathbb{N}\times 0=\emptyset$ and then it's vacuously true that $\forall a\in \mathbb{N}\forall b\in \emptyset((a,b)\in f \wedge(a,c)\in f\Longrightarrow b=c)$. Also, if I wanted to prove that indeed $\mathbb{N}$ is infinite, the only option I see is by making a proof by induction. In such a case then my statement should be false. I don't know... Edit : The approach to prove that there is a biyection is the same way as to proove that it's a function: It's injective: It's vacously true that $\forall a\in \mathbb{N}\forall b\in \emptyset((a,b)\in f \wedge(c,b)\in f\Longrightarrow a=c)$. It's surjective: It's vacuously true that $\forall a\in \emptyset \exists b((a,b)\in f)$. Now I know my problems are in my understanding of the meaning of ""vacously"". It would be very nice if you guys could tell me the mistakes in it and also in my definitions.",['elementary-set-theory']
435060,Volume of n-dimensional solid w/ n-1 dimensional simplex as a base,"Background On an old MathForm discussion site I came across a very interesting method, which can find the center of mass of an n-dimensional solid, with an n-1 dimensional unit simplex as a base. To ground this problem a 3D version of such a solid looks like the following: Where the base is just a triangle with each side = 1 and the ""vertical"" sides stand orthogonal to the base. In Mathematica code the method as presented looks like this: h = {3, 4, 2};  (* heights at right angles to the base simplex *)
n = Length[h];

A = Transpose[Prepend[#, 03]&/@CholeskyDecomposition[(IdentityMatrix[n - 1] + 1)/2]];

((h/Total[h] + 1)/(1 + n)) . A For some further insight into this, the matrix ""A"" used in the dot product calculation looks like this: One of the contributors to the old site described this approach as, ""finding moments e.g. averaging a coordinate over the object (which is what you do, in effect, to find the center of mass)."" The guy who came up with this appears to have found a formulation that does exactly that, and avoiding integration.  It has a couple of distinct advantages over other methods: being very fast to calculate (at least in Mathematica) and it can handle any number of dimensions. Questions I need a similar fast method to calculate the volume of precisely these kinds of n-dimensional solids. The approach to finding the center of mass seems promising, but I'm not familiar enough with the ideas behind it to work it all out by myself.  I keep taking the pieces of this approach apart trying to understand it more clearly, but can't think of a way through it. Breaking down the problem into more manageable parts might help.  Wikipedia shows a formula to calculate the volume of a regular n dimensional simplex with unit side length as: This leaves figuring out how to calculate the orthogonal ""cap"". The Cholesky decomposition approach does seem promising.  I wondered if anyone had some insight into how to apply this (or an equally speedy) approach to calculating the volumes of such solids? Additional information that might lead to a simpler solution: Some discussion around the original MathForum question suggested that one could calculate  the volume of the kinds of solids described above by taking the hyperarea of the base and multiplying it by the average of the heights. Wolfram Alpha provides a formula for calculating the ""hyper-surface area"" of a simplex: As I only need this for a unit simplex (all sides = 1), I think this simplifies to: Symbolically, in Mathematica code, for n=3 with a base simplex of n-1 dimensions  it looks like this: hyperarea[n_] := Sqrt[(2^(1 - n) *n)] *(n + 1) * 1^(n - 1) / (n-1)! 

heights = {h1, h2, h3};
hyperarea[n]* Mean@heights Plug in some simple values for the heights: heights = {1, 2, 3};
n = Length[heights];
N[hyperarea[n]* Mean@heights]

3.4641 BUT, this does not seem to work correctly. Take a simple example of this kind of solid, a prism with equilateral triangle for the base and top and all edges = 1.  Its volume should equal: (1^2) * Sqrt[3]/4 * 1 = 0.433013 But when I use the hyperarea approach with heights {1, 1, 1}, I get 1.73205. Any thoughts and guidance on what I've missed appreciated. Apologies for all the edits.",['geometry']
435079,"the value of $\lim\limits_{n\rightarrow\infty}n^2\left(\int_0^1\left(1+x^n\right)^\frac{1}{n} \, dx-1\right)$","This is exercise from my lecturer, for IMC preparation. I haven't found any idea. Find the value of $$\lim_{n\rightarrow\infty}n^2\left(\int_0^1 \left(1+x^n\right)^\frac{1}{n} \, dx-1\right)$$ Thank you","['definite-integrals', 'calculus', 'real-analysis', 'limits']"
435107,Prove the equation: $\frac{2}{\pi} \int_0^\infty \frac{\cos kr - ak \sin kr}{k^2a^2 +1} \ldots $,"Prove the following equation: \begin{equation}
\frac{2}{\pi} \int_0^\infty \frac{\cos kr - ak \sin kr}{k^2a^2 +1} \left (\int_0^\infty \cos kr' \left [u(r')-au'(r') \right] dr' \right ) dk =u(r) .
\end{equation}
where $u,u' \in L^1(\mathbb{R}^+)$ and $a,r >0$. I have found the following not rigorous proof. By reversing the order of integration (this is the not rigorous part) one obtains:
$$
\ldots = \frac{2}{\pi}  \int_0^\infty \left ( \int_0^\infty \frac{\cos kr\cos kr' - ak \sin kr \cos kr'}{k^2a^2 +1} dk \right ) [u(r')-au'(r') ] dr';
$$
By using the Werner formulas, the integral in $dk$ becomes:
\begin{align*}
&  \int_0^\infty \frac{\cos k(r + r') + \cos k(r - r') - ak \sin k(r+r') - ak \sin k(r-r')}{2(k^2a^2 +1)} dk.
\end{align*}
Given the following integrals:
$$
\int_0^\infty \frac{\cos kx}{a^2 k^2 +1} dk = \frac{\pi}{2} \frac{e^{-|x/a|}}{a}; \; \; 
\int_0^\infty \frac{ak \sin kx}{a^2 k^2 +1} dk = \frac{\pi}{2} \frac{\text{sgn}(x)e^{-|x/a|}}{a};
$$
the complete formula becomes:
\begin{align*}
&\ldots = \int_0^\infty \Theta(r'-r) \frac{e^{-(r'-r)/a}}{a}[u(r')-au'(r') ] dr' = \\
& - \int_r^\infty \partial_{r'}[ e^{-(r'-r)/a}u(r') ]dr'= - e^{-(r'-r)/a}u(r')  \Big |_{r'=r}^\infty = u(r).
\end{align*} I think that reversing the order of integration is not allowed, because the conditions for Fubini are not satisfied. In fact, probably: \begin{equation}
\int_0^\infty \left |\frac{\cos kr\cos kr' - ak \sin kr \cos kr'}{k^2a^2 +1} \right | dk = \infty.
\end{equation} Can somebody give a rigorous proof of the equation?","['fourier-analysis', 'calculus', 'integration']"
435119,"If $q$ is prime, then $w=(1+q+q^2)/3$ is a composite integer iff $w$ has a prime divisor less than $\sqrt{w}$ and congruent to $1$ modulo $6$","I have a question regarding prime numbers. Specifically, I wonder if the following is true: If $q$ is a prime and $w=(1+q+q^2)/3$ is an integer, then $w$ is composite iff $w$ has a prime divisor less than $\sqrt{w}$ and congruent to $1$ modulo $6$. Edit: The problem appears in this paper.","['prime-numbers', 'prime-factorization', 'number-theory']"
435123,Polynomials and Trig,"Question: The equation $x^{2}-x+1=0$ has roots $\alpha$ and $\beta$.
Show that $\alpha ^{n}+\beta ^{n}=2\cos\frac{n\pi }{3}$ for $n=1, 2, 3...$ Attempt: $x^{2}=x-1 \Rightarrow x^{n}=x^{n-1}-x^{n-2}$ for $n=3, 4, 5...$ $\therefore \alpha^{n}=\alpha^{n-1}-\alpha^{n-2}$ $\therefore \alpha ^{n}+\beta ^{n}=\alpha ^{n-1}+\beta ^{n-1}-\alpha ^{n-2}-\beta ^{n-2}$ I don't see how I could link this with cosine. Could you please go beyond answering the question and proving that $\alpha ^{n}+\beta ^{n}=2\cos\frac{n\pi }{3}$ and explain the question to me why this relation between the roots and trig happen? The question can probably be done by induction but is there another way? Thank you!","['trigonometry', 'roots', 'polynomials']"
435133,How find the value $\sum\limits_{k=1}^{\infty}(C_{3k}^k)^{-1}$,"find the value 
$$\sum_{k=1}^{\infty}\dfrac{1}{C_{3k}^{k}}$$ and  long ago,I have see this and is easy
$$\sum_{k=1}^{\infty}\dfrac{1}{C_{2k}^{k}}$$ where 
$$C_{n}^{k}=\dfrac{n!}{(n-k)!k!}$$","['summation', 'sequences-and-series', 'binomial-coefficients']"
435143,Is this true? $f(g(x))=g(f(x))\iff f^{-1}(g^{-1}(x))=g^{-1}(f^{-1}(x))$.,"Is this true? Given $f,g\colon\mathbb R\to\mathbb R$ . $f(g(x))=g(f(x))\iff f^{-1}(g^{-1}(x))=g^{-1}(f^{-1}(x))$ . I met this problem when dealing with a coding method, but I'm really not familiar with functions. Please help. Thank you.",['functions']
435157,Understanding Dual Transformations and reasoning behind definition,"In Linear Algebra working with Dual space and dual transformations I've come along this very basic definition of the dual transformations: Suppose: $T^*$ is a dual transformations from $W^*\to V^*$ $T$ is a linear transformation from $V\to W$ $u$ is a linear functional which belongs to $W^*$ $v$ is a vector which belongs to $V$ Then the following applies:
     $$ (T^*u)(v)  = u(Tv) $$ Why is the dual transformation defined this way? (I know this is a very problematic question, but please any intuition will be very helpful)",['linear-algebra']
435202,Prove if there are 4 points in a unit circle then at least two are at distance less than or equal to $\sqrt2$,There is a unit circle and 4 points inside the circle. The problem is to prove at least two are at distance less than or equal to $\sqrt2$,"['geometry', 'combinatorics']"
435204,In how many ways can a group element in a finite group be written as a commutator?,"It seems there is a result by Frobenius that states that the number of ways an element $g$ of a finite group can be written as a commutator ($\phi(g) =  | \{(x,y) \in G \times G: g = [x,y]\}|$) is given by $\phi(g) = \sum_{\chi} \frac{|G| \chi(g)}{\chi(1)}$, where the sum is taken over all the irreducible characters of $G$. I can't find the original paper and am having trouble on proving this. I'm trying to make use of the class algebra constants, but it's of no use so far. Would anybody kindly provide some advice? Thank you!","['representation-theory', 'group-theory']"
435211,Why Euler angles cause gimbal lock?,"And here's another one about Euler angles. I want to ensure I'm understanding it right. I had a really hard time getting how and why gimbal lock is possible, because the most common explanation is ""loosing one degree of freedom"" or something like ""two axes are in the same plate"". Explanations like ""map from Euler angles is not a covering map for rotation space"" sounds good, but still doesn't reveal the reason. Then, I've read Wikipedia once again and saw this: ""Euler rotations are never expressed in terms of the external frame, or in terms of the co-moving rotated body frame, but in a mixture. They constitute a mixed axes of rotation system, where the first angle moves the line of nodes around the external axis z, the second rotates around the line of nodes and the third one is an intrinsic rotation around an axis fixed in the body that moves."" And then it hit me. When I was looking at all the pictures from all the articles and books, I saw something like this: And I thought, that Euler angles are based on co-moving frame  (so did a couple of my friends I asked, for that matter). But they are not! And from that moment everything seemed obvious! If one axes is global and two others are co-moving, then they can become aligned and we have a gimbal lock. So, here are my questions: Am I right at all, and this is the basic reason for gimbal lock in Euler angles? Will any rotation representation based on 3 orthogonal axes from one frame be gimbal-lock-free? Not only quaternions, but rotational matrices for example? WHY OH WHY did Euler used those, let's say, strange set of axes?! WHY OH WHY isn't it written in capsbold in every article about Euler angles, why all the pictures are so confusing?! Or maybe I'm the only one who didn't know that? P.S. I'm sorry for my bad English.","['geometry', 'rotations']"
435219,How do I transform $f(x)=\log(1+e^x)$ such that graph rotates $90^{\circ}$ on the $x$-$y$ axis,I am looking for a function $f(x)$ that is of a specific shape on the $x$-$y$ axis. I have a function $f(x)=\log(1+e^x)$ that has right shape. I want it rotated $90^\circ$ on $x$-$y$ axis. How can I get an $f(x)$ that is essentially a $90^\circ$ rotation of $f(x)=\log(1+e^x)$?,['functions']
435230,Limit point of an infinite set in a compact space,"I'm reading Kolmogorov's book on Real Analysis and I'm having problems understanding the proof of this theorem: If $T$ is a compact space, then any infinite subset of $T$ has at least one limit point. The proof goes like this:
Suppose $T$ contains an infinite set with no limit point. Then $T$ contains a countable set
$X=\{x_1,x_2,...\}$ with no limit point. But then the sets 
$ X_n=\{x_n,x_{n+1},... \} $ form a centered system of closed sets in $T$ (every finite intersection is nonempty) with an empty intersection, i.e. $T$ is not compact. My questions are: I don't understand why the sets $X_n$ are closed. If we take the interval $[0,1]$ with the usual topology and the sequence $x_n=1/n$, then the intersection of all the $X_n$ should be the empty set since it can't be a positive number because taking $n$ sufficiently large that number won't be in an infinite collection of the $X_n$ and neither can be zero since $0$ is not in any of the sets. Am I understanding the concept of intersection of an infinite collection of sets? Alternatively I have thought of this proof: assume that the theorem is false , then for every point in $T$ we can take a neighborhood containing at most a finite number of points of $X$, in this way we obtain a covering of $T$, extracting a finite subcovering, at least one of the neighborhoods must contain an infinite number of points of $X$, contradiction.","['general-topology', 'compactness']"
435234,$\mathbb{S}^2$ as a fibre bundle,"I know, by the Hopf fibration, that $\mathbb{S}^3$ is an $\mathbb{S}^1$-fibre bundle over $\mathbb{S}^2$. Can $\mathbb{S}^2$ be an $\mathbb{S}^1$-fibre bundle over some manifold $M$?","['differential-topology', 'fiber-bundles', 'manifolds', 'differential-geometry']"
435266,Locally exact differential in a disk is exact,"I'm reading through Ahlfors' Complex Analysis text for self study, and I found difficulty with a proof. In chapter 4 he defines a locally exact differential as a differential who is exact in some neighborhood of every point of its domain. In the proof of theorem 16 however, he claims that such differential is exact in every open disk contained in the region. I fail to see why is it so: Each point should have its own radius, and these can get very small (?). I can use the fact that a locally exact differential of class $C^1$ is closed and apply Poincare's lemma, but no differentiability assumptions were made in the statement of the theorem. Any help will be appriciated.","['differential-forms', 'complex-analysis']"
435274,Holomorphic function with bounded real part,"Suppose that $f(z)$ is holomorphic over $|z| \leq R$, for some positive $R$, and that $f(0)=0$. Further, suppose that $Re(f(z)) \leq C$ for all $|z| \leq R$. How do we show that $|f(z)| \leq \dfrac{2Cr}{R-r}$ for all $|z| \leq r$, for any $0 < r < R$? Any help or hint would be greatly appreciated. Thanks!",['complex-analysis']
435285,Isomorphic varieties,"I just want to see if my approach for this problem is fine: Show $W=\mathbb{P}^1 \times \mathbb{P}^1$ is not isomorphic to $W'=\mathbb{P}^2.$ Well $V= \{ [0:1] \} \times \mathbb{P}^1, V' = \{ [1:0] \} \times \mathbb{P}^1$ are closed subvarieties of $W$ each isomorphic to $\mathbb{P}^1$ so each of dimension $1.$ So $W$ has two dimension 1 closed subvarieties that don't intersect, while $W'$ does not (any two projective plane curves intersect) and thus they are not isomorphic. Edit: Isomorphic as varieties.",['algebraic-geometry']
435296,Harmonic function on an annulus,"I have stumbled across the following fact in complex analysis and I was trying to prove it, but didn't get anywhere: Let $R=\{r<|z|<R\}\subset\mathbb{C}$ where $0<r<R<\infty$ be an annulus in the complex plane and $u$ a harmonic function on $R$. Then there exists a constant $C\in\mathbb{R}$ and a holomorphic function $f$ on $R$ such that
$$u(z)=\mathrm{Re}f(z)+C\log|z|$$ The problem arises because $R$ is not simply connected (on simply connected domains this is clearly true for $C=0$ by the CR equations). I just don't see where that $\log$ should come from. Can somebody help me and provide an easy proof? Any potentially useful approaches/hints are welcome.",['complex-analysis']
435299,where this series converges,"Given the series $$\sum_{j=0}^{\infty}\frac{1}{6j^2-5j+1}$$
I am completely stuck and do not  understand the answer from my book which is $\pi^2/36-1$. I need explanation and different approach how this result is gained. Thanks","['convergence-divergence', 'sequences-and-series']"
435304,How do I show that this curve has a nonsingular model of genus 1?,"Let $C$ be the projective closure of $Z(f) \subset \mathbf{A}^2$ where $f$ is an irreducible polynomial of degree 4 in $x$ and degree 2 in $y$, so $C = Z(f^*) \subset \mathbf{P}^2$ where $f^*$ is the homogenization of $f$.
For a particular example, let $f = x^4y - 2x^3y^2 + 6x^3y - 6x^2y^2 - 4x^3 + 12x^2y - 4xy^2 - 12x^2 + 12xy - 8x + 4y$. (I have a family of these, all of a particular form.) Using MAGMA I find that this curve has a nonsingular model of genus 1: > R<x,y,z> := ProjectiveSpace(Rationals(),2);
> C:= Curve(R, x^4*y - 2*x^3*y^2 + 6*x^3*y*z - 4*x^3*z^2 - 6*x^2*y^2*z + 12*x^2*y*z^2 - 12*x^2*z^3 - 4*x*y^2*z^2 + 12*x*y*z^3 - 8*x*z^4 + 4*y*z^4);
> Degree(C);
5
> Genus(C);
1
> P0:= C![-2,0,1];
> E, phi:=EllipticCurve(C,P0);
> E;
Elliptic Curve defined by y^2 - 4*x*y = x^3 - 11*x^2 + 12*x over Rational Field How would one go about showing this by hand? I suspect that the algorithms used by MAGMA are not practical for this. Can we prove that the degree of the defining homogeneous polynomial of the nonsingular model is 3? In that case we would be done after an application of the genus-degree formula $g = (d-1)(d-2)/2$. Note that I'm not asking for a construction of the nonsingular model, just a proof of the fact that it has genus 1. This may or may not be helpful. Many thanks in advance. Note : The singular points of my example $C$ that I know of are $[\sqrt{2} : \sqrt{2} : 1]$ and $[-\sqrt{2} : -\sqrt{2} : 1]$, and I believe they are ordinary singularities (multiplicity 2, two distinct tangents). Note 2 : Actually, $[0 : 1 : 0]$ is also a singular point, but I don't know what kind. If it's ordinary with multiplicity 3, then we are done by the generalized genus-degree formula discussed in the comments below. But how do I prove that these are all the singularities?","['algebraic-geometry', 'elliptic-curves']"
435310,The golden ratio and a right triangle,Assume the square of the hypotenuse of a right triangle is equal to its perimeter and one of its legs  is  $1$ plus its inradius(the radius inside the circle inscribed inside the triangle.) Find an expression for the hypotenuse  $c$  in terms of the golden ratio.,"['geometry', 'trigonometry', 'algebra-precalculus']"
435313,"what is a ""dévissage"" argument?","In Serre's ""Local Fields"" (Chapter 2, section 2, proposition 3) he proves something about field extensions which he breaks into parts: first he dealt with the separable case, and then with the inseparable case. In between the two cases he writes ""a straightforward dévissage argument reduces one to the case of an inseparable extension. What is dévissage argument? I saw in wikipedia something with the same name.  Is there a connection? If it matters, the proposition statement is as follows: Let $K$ be a complete field with respect to a discrete valuation $\nu$ with valuation ring $A$, and let $L/K$ be a finite extension. Let $B$ be the integral closure of $A$. Then $B$ is a discrete valuation ring and is a free $A$-module of rank $[L:K]$; also, $L$ is complete in the topology defined by $B$. (So in this case the reduction really is easy, as one can break the extension into a separable part and an inseparable part. It is clear that if the statement holds for $L/E$ and for $E/K$ then it holds for $L/K$)","['algebraic-geometry', 'arithmetic-geometry', 'algebraic-number-theory', 'terminology', 'field-theory']"
435315,Riemann-Stieltjes integral (floor function),"Please, I am having problem with this function. $$ \int_{-1.2}^{3.9} xd[x] $$ Here is what I have done
$$\int_{-1.2}^{1}xd[x] + \int_{0.8}^{2}xd[x] + \int_{1.8}^{3}xd[x] + \int_{2.8}^{3.9}xd[x] $$ I don't know if I am on the right track, help.","['integration', 'real-analysis']"
435331,"Differential forms: The authors of a paper define $d(u\times du)$, but what is $u \times du$ supposed to mean?","I'm reading [1] recently and have another question about a remark in this paper. I tried to solve it myself (see below) but did not succeed. It could be just a notation problem. The Setup: Let $u \in H^1(\Omega,\mathbb{C})$ where $\Omega = [-\pi,\pi]^3 \subset \mathbb{R}^3$. In [1, Rmk.4.2] the authors denote by $Ju$ the 2-form \begin{equation} Ju \equiv \frac{1}{2} d(u \times du) = \sum_{1 \leq i < j \leq 3} (\partial_i u \times \partial_j u) dx_i \wedge dx_j. \end{equation} Furthermore they define \begin{equation} \zeta_1(x)= - x_2 dx_1 \wedge dx_2 - x_3 dx_1 \wedge dx_3. \end{equation} From this definition it follows that \begin{equation} \star \zeta_1 = -x_2 dx_3 + x_3 dx_2 \end{equation} which I checked. Here $\star$ denotes the Hodge-star-operator. I then calculated \begin{equation} d(\star \zeta) = -2dx_2 \wedge dx_3 \tag{G1}\end{equation} which I hope is correct. Now the authors state that \begin{equation} (u \times du) \wedge d(\star \zeta_1) = 2 \langle i \partial_1 u, u \rangle dx_1 \wedge \ldots \wedge dx_3 \tag{G2}  \end{equation} My Question: What is $u \times du$ supposed to be? My Attempt: I tried to find out myself, but I discovered the following difficulty: Let $\omega=\sum_{i=1}^3 \omega^i dx_i$ be the 1-Form $\omega=u \times du$. Then \begin{equation} \frac{1}{2} d\omega = \frac{1}{2} \sum_{1 \leq i< j \leq 3} \omega^i_{x_j} dx_j \wedge dx_i\stackrel{!}{=} Ju = \sum_{1\leq i < j\leq 3} (\partial_i u \times \partial_j u) dx_i \wedge dx_j.  \end{equation} This suggests that $\omega_{x_j}^i = -2 (\partial_i u \times \partial_j u)$. On the other hand because of $(G1)$ equation $(G2)$ becomes \begin{equation} \omega \wedge d(\star \zeta) = -2\omega^1dx_1 \wedge dx_2 \wedge dx_3 \stackrel{!}{=} 2 \langle i \partial_1 u, u \rangle dx_1 \wedge dx_2 \wedge dx_3, \end{equation} which suggests $\omega^1=-\langle i \partial_1 u, u \rangle$. So my question reduces to How are these two equations compatible? What is the $\times$ supposed to mean? [1] Béthuel, F., P. Gravejat und J. C. Saut: Travelling waves for the Gross-
Pitaevskii equation. II. Comm. Math. Phys., 285(2):567–651, 2009.","['ordinary-differential-equations', 'partial-differential-equations', 'differential-geometry']"
435339,four points in a square distance minimum,Suppose there are four points inside a unit square.The problem is to prove there is a pair of points with distance less than or equal to one.,"['geometry', 'combinatorics']"
435340,Sum of squares of binomial coefficients,"I came across the following sum in reference to this question $$\sum_{n=0}^{\infty} \frac{1}{2^{5 n}} \binom{2 n}{n}^2 = \frac{\sqrt{\pi}}{\Gamma \left( \frac{3}{4}\right)^2}$$ The sum on the left was generated from expanding the square root in the integrand of the following elliptic integral: $$K\left( \frac{1}{2}\right) = \int_0^{\pi/2} \frac{d\theta}{\sqrt{1-\frac12 \sin^2{\theta}}} $$ For the life of me, I cannot figure out how to evaluate this sum directly.  Mathematica has no problem in doing so.  Can someone point the way?","['sequences-and-series', 'calculus', 'binomial-coefficients']"
435356,"When solving an ODE using power series method, Why do we need to expand the solution around the singular point?","When solving a differential equation using series expansion method, if it has the following form : $$y''+\frac{p(x)}{x}y'+\frac{q(x)}{x^2}y=0$$ ; where $p$ and $q$ are analytic at $x_0$; if we want to find the solution in a series fprm expanded around $x_0$, it can't be solved using the regular method of series expansion and we must use Frobenius method to find the  series around $x_0$. Why do we need to expand around the singular point?  why we don't solve the equation by expanding $y$ around a regular, nonsingular point (I mean a point different than $x_0$) and without using Frobenius method ? Is it a matter of convergence of the solution series at the singularity point?","['power-series', 'ordinary-differential-equations']"
435372,Dual and completion of metric spaces,"Say we have a metric space $(M,d)$, and we want to complete it in the following sense: Definition : A completion of $(M,d)$ is a complete metric space $(\widetilde{M},d')$ together with a Lipschitz funcion $i:M\rightarrow\widetilde{M}$ such that for every other complete metric space $(N,\rho)$ together with a Lipschitz function $f:M\rightarrow N$, there exists an unique Lipschitz function $F:\widetilde{M}\rightarrow N$ such that $F\circ i=f$. This definition is adapted from the definition for uniform spaces ( wikipedia ). I changed the condition that the functions are uniformly continuous to Lipschitz so any two completions of a metric space would be ""equivalent"" as metric spaces, and not just be ""uniformly equivalent"". One could also suppose the functions are isometries, for example. (I think the better ""morfisms"" in the category of metric spaces are Lipschitz functions.) The usual completion of $M$ is defined to be (a quotient of) the set $\widetilde{M}$ of Cauchy sequences on $M$ with the (pseudo)metric $d'\left((x_n)_n,(y_n)_n\right)=\lim d(x_n,y_n)$ and the inclusion $i:x\in M\mapsto (x)_n\in\widetilde{M}$ (it's the same as the one given in wikipedia). However, suppose we are working with a normed (vector) space, let's say $(X,\Vert\cdot\Vert)$. The completion of $X$ (making the proper adaptations in the definition: that the functions are linear, etc...) can be very easily defined as the closure of $ev(X)$ as a subspace of $X''$, where $Y'$ denotes the dual of a normed space $Y$ with the operator norm, and $ev:X\rightarrow X''$ is the evaluation function: $ev(x)(f)=f(x)$ for every $x\in X$ and $f\in X'$. My question is: would we be able to make a similar construction for general metric spaces, that is, to find a nice definition of dual of a metric space for which the dual of it would be a complete metric space? If so, we could try to just define the completion of $M$ as the closure of $ev(M)$ in $dual(dual(M))$. In other words, I would like to find a kind of (nice) (algebraic, analytic, etc..) structure so the category of sets with that structure is dual to the category of metric spaces. The first possible ""dual"" of $(M,d)$ that comes to my mind is $C_b(M)$, the set of continuous bounded functions from $M$ to $\mathbb{R}$ with the $\infty$-norm. Problem is that this is a commutative, unital $C^*$-Algebra, and we know the natural dual of a commutative $C^*$-Algebra is a compact hausdorff topological space, not a metric space. (also, I guess a dual notion of metric space couls have many applications other than just making completions)","['category-theory', 'metric-spaces', 'duality-theorems', 'analysis']"
435383,"$p$ prime, $P = \left\{ \frac{m}{p^e} \middle| m, e\in \mathbb{Z} \right\}$. Prove that $\mbox{Ext}(P; \mathbb{Z}) \cong \mathbb{Z}^{(p)}/\mathbb{Z}$","I don't know why the book Homology by Saunders Mac Lane is wwaaayyy tttoooo hard to digest. :((( This is like the third time I read this book, but still not clear is everything, and to tell the truth, I cannot even see (or see little) connections between the exercises and the information provided in each lesson. It's exercise 7, on page 76 of the book. The current lesson is about The obstructions to the extension of homomorphisms . Ok, here's what it says: Problem Let $p$ be any prime, and define the set $P$ as follow: $P = \left\{ \frac{m}{p^e} \middle| m, e\in \mathbb{Z} \right\}$, clearly it's a subgroup of the additive Abelian group $\mathbb{Q}$. Let $\mathbb{Z}^{(p)}$ be the additive group of $p-$adic integers. Prove that: $$\mbox{Ext}(P; \mathbb{Z}) \cong \mathbb{Z}^{(p)}/\mathbb{Z}$$ Ok, I know some strategies when doing problems on Ext is to find a ses with projective, or injective modules, then just kind of applying $\mbox{Ext}(-; A)$, and $\mbox{Ext}(A; -)$ to arrive at the les, and work from there. Here's what I have tried, not much though. :( I've found the ses for $\mathbb{Z}^{(p)}$, i.e:
$$0 \to \mathbb{Z} \to \mathbb{Z}^{(p)} \to \mathbb{Z}^{(p)} / \mathbb{Z} \to 0$$ The problem is, if I work with that ses, then I have to apply $\mbox{Ext}(P; -)$ to the sequence. But there is no injective $\mathbb{Z}-$module there, so there's nothing that can make $\mbox{Ext}(P; \mbox{something injective}) = 0$. I also try to find a ses for $P$, but its definition confuses me. I know that every module $M$ can be embedded in $0 \to S \to F \to M \to 0$ for some projective $F$, but how should I use the definition of $P$ to find a 'good' ses like that? I think I'm not seeing something here, or maybe I'm going on the wrong track. So any hints would be great. :* Thank you very much, And have a good day,","['p-adic-number-theory', 'abelian-groups', 'abstract-algebra', 'homological-algebra', 'modules']"
435414,Questions about $B(H)$ and $B(H)/K(H)$ as Banach space,"I am trying to investigate the relation between Uniformly Convexity and existence of Schauder Basis for a Banach space. I read in a Handbook article  that $B(H)$ (the algebra of all bounded operators on a Hilbert space $H$) and $B(H)/K(H)$ (the Calkin algebra for the same Hilbert space) are both naturally occurring examples of space which fails the Approximation Property. I am wondering if we know: a) if the above algebras are separable Banach spaces; b) the convexity of them as Banach spaces (e.g. strictly convex, uniformly convex, ...?) I apologize if this is really trivial functional analysis problem. Thank you!","['operator-algebras', 'hilbert-spaces', 'functional-analysis', 'banach-spaces']"
435433,Proof of $A\cap(B\cup C) = (A\cap B)\cup(A\cap C)$,"I have to resit a calculus exam and for some reason set proofs were never my best friend... Anyway, on a practice exam I encountered the following proof: $$A\cap(B\cup C) = (A\cap B)\cup(A\cap C)$$ When I draw a Venn-diagram it seems quite obvious but I couldn't manage to write the proof down properly. If someone could help me, that'd be great!",['elementary-set-theory']
435439,"Question about Permutations, and the distinct differences","I have the following question regarding permutations of the sequence $(1,2,\cdots,n)$: For what values of $n$ does there exist a permutation $(x_1,x_2,\cdots,x_n)$ of $(1,2,\cdots,n)$, such that the differences $|x_k-k|$ for each $k\in\{1,2,\cdots,n\}$ are all distinct? I have shown that $n$ must not be congruent to 2 or 3 modulo 4. I have tried to construct a permutation for each value of $n$ congruent to 0 or 1 modulo 4, but I was not able to find a pattern, and as such I was unable to come up with a permutation for higher values of $n$. Is there a nice way of actually constructing the desired permutations, or are there yet more values of $n$ for which such a permutation does not exist?","['permutations', 'combinatorics']"
435462,solution of $y' = \exp \left(-\frac yx\right) + \frac yx$,"Could you help me to solve equation 
$$y' = \exp \left(-\frac yx\right) + \frac yx;\quad y(e) = 0$$ I know how to solve 1st order linear de like $y' = \exp \bigl(-\frac 1x\bigr) + \frac yx$ but here I have the dependent variable in the part that usually (in my practice) was free of it.",['ordinary-differential-equations']
435472,Is this function bounded? Next question about integral $\int_{\partial M} \frac{1}{||y-x||} n_y \cdot \nabla_y \frac1{||y-x||} dS_y$.,"Let $\partial M$ be $C^2$ closed surface in $\mathbb{R}^3$, $M$ is open. Show that 
   $$
f(x) = \frac{\int_{\partial M} \left| \frac{1}{||y-x||} n_y \cdot \nabla_y \frac{1}{||y-x||} \right| dS_y}{\left| \int_{\partial M}  \frac{1}{||y-x||} n_y \cdot \nabla_y \frac{1}{||y-x||}  dS_y\right|}
$$
  is bounded in $\overline{M}$ I already know few things about this kind of integral, I already had two questions about it here and here . But I still can't show that $f$ is bounded. $f$ is continuous in $M$. So if I show that 
$$
\lim_{x\rightarrow x_0} f(x) = 1
$$
for every $x_0 \in \partial M$. Than $f$ is continuous in $\overline{M}$ hence it is bounded. My idea of proving it is: Find $U(x)\subset \partial M$ that $\left( n_y \cdot \nabla_y \frac{1}{||y-x||} \right)  > 0$ for all $y\in U(x)$ and that
  $$
\frac{\int_{\partial M\setminus U(x)} \left| \frac{1}{||y-x||} n_y \cdot \nabla_y \frac{1}{||y-x||} \right| dS_y}{ \int_{U(x)}  \frac{1}{||y-x||} n_y \cdot \nabla_y \frac{1}{||y-x||}  dS_y} \rightarrow 0\qquad \text{as dist}(x,\partial M) \rightarrow 0
$$ If you show that map $U(x)$ exists than you can easily show the limit  $\lim_{x\rightarrow x_0 \in \partial M} f(x) = 1 $","['integration', 'surfaces', 'limits']"
435505,Do these union- and intersection-like operations have a name?,"I have two sets of pairs, e.g: $$A = \{ (a, 1), (b, 2), (c, 3) \}$$ $$B = \{ (b, 12), (c, 13), (d, 14) \}$$ I also have two operators which match the first element of pairs and return a pair of modified sets. This intersection-like operation $\cap'$ keeps only pairs that have a corresponding first element in the other set: $$ A \cap' B = ( \{ (b, 2), (c, 3) \}, \{ (b, 12), (c, 13) \} )$$ On the other hand, this union-like operation adds new pairs to each set, taking first elements from the other set and setting the second element to zero: $$ A \cup' B = ( \{ (a, 1), (b, 2), (c, 3), (d, 0) \}, \{ (a, 0), (b, 12), (c, 13), (d, 14) \} )$$ Are there names for these operations?","['terminology', 'elementary-set-theory']"
435509,How to solve the given initial-value problem?,"Solve the given problem which the input function $g(x)$ is discontinuous? $y''+4y = g(x)$, $y(0) = 1$, $y'(0) = 2$, where $$g(x) = \begin{cases} \sin x, & 0\leq x\leq\frac{\pi}{2}\\
0,& x>\frac{\pi}{2} \end{cases}$$ And the given answer is, $$y = \begin{cases} \cos 2x+\frac56\sin2x+\frac13\sin x, & 0\leq x\leq\frac{\pi}{2}\\
\frac23\cos 2x+\frac56\sin2x,& x>\frac{\pi}{2} \end{cases}$$",['ordinary-differential-equations']
435510,generic regularity of affine varieties,"Suppose that $V\subset {\mathbb C}^n$ is an affine subvariety of codimension $p$. How does one prove that $V$ is regular (i.e., is a smooth manifold) at its generic points? In view of the Jacobian test for regularity (which is just the implicit function theorem in this case), it suffices to show that there exist a point $x\in V$ and polynomials $f_1,...,f_p$ in the defining ideal $I$ of $V$ so that the derivatives $df_1,..., df_p$ are linearly independent at $x$. However, I do not see why such  point and polynomials would exist.","['commutative-algebra', 'algebraic-geometry']"
435513,"If $\sin a+\sin b=2$, then show that $\sin(a+b)=0$","If $\sin a+\sin b=2$, then show that $\sin(a+b)=0$. I have tried to solve this problem in the following way : \begin{align}&\sin a + \sin b=2 \\
\Rightarrow &2\sin\left(\frac{a+b}{2}\right)\cos\left(\frac{a-b}{2}\right)=2\\
\Rightarrow &\sin\left(\frac{a+b}{2}\right)\cos\left(\frac{a-b}{2}\right)=1
\end{align} What will be the next ?",['trigonometry']
435514,$A$ is a subset of $B$ if and only if $P(A) \subset P(B)$,"I had to prove the following for a trial calculus exam: $A\subset B$ if and only if $P(A) \subset P(B)$ where $P(A)$ is the set of all subsets of $A$. Can someone tell me if my approach is correct and please give the correct proof otherwise? $PROOF$: $\Big(\Longrightarrow\Big)$ assume $A\subset B$ is true. Then $\forall$ $a\in A$, $a\in B$ Then for $\forall$ A, the elements $a_1, a_2,$ ... , $a_n$ in A are also in B. Hence $P(A)\subset P(B)$ $\Big(\Longleftarrow\Big) $ assume $P(A) \subset P(B)$ is true. We prove this by contradiction so assume $A\not\subset B$ Then there is a set $A$ with an element $a$ in it, $a\notin$ B. Hence $P(A) \not\subset P(B)$ But we assumed $P(A) = P(B)$ is true. We reached a contradiction. Hence if $P(A) = P(B)$ then $A\subset B$. I proved it both sides now, please improve me if I did something wrong :-)","['elementary-set-theory', 'solution-verification']"
435522,Why does this sequence happen like this?,"The other day I sent my girlfriend this text <3 she sent me back <3<3<3 not to be one upped I responded with <3<3<3<3<3<3<3 this got very silly very quickly. After our ""<3"" battle was over I got to thinking about the pattern we were forming. Since we were doubling the number of hearts and adding one I thought the sequence would be something like 2^n + 1. BUT IT IS NOT. It is 2^n - 1 . Why is this?",['sequences-and-series']
435545,right continuous continuous function is measurable,"Let $f: S \times [0, \infty)\rightarrow \mathbb{R}$ satisfy $f(x, t)$ is continuous in $x$ for each $t$ and right continuous in $t$ for each $x \in S$.  Here $S$ is a metric space.  Why is $f$ Borel measurable? (In the joint sense)  I am vaguely familiar with the idea of proof I did a long time ago for if $S$ is instead a Euclidean space, and we have full continuity instead of only right.  Then one interpolated.  But you can't do that here anyway, since $S$ is not Euclidean, and nevermind the fact that you only have right continuity anyway.  I also tried to write $f$ as a limit of joint measurable functions using the right continuity, but failed.","['measure-theory', 'real-analysis', 'analysis']"
435561,Proof of the infinitude of primes by probabilistic methods.,I'm looking to see if there is proof of the infinitude of prime numbers using a probabilistic method. I am motivated by the answer of my question here . The answer is based on a relationship between independence of measurable sets and coprime integers . More precisely I am asking the following. QUESTION: Is there a proof of the infinitude of primes using the Lovász local lemma by any of several different versions of the lemma?,"['probability-theory', 'prime-numbers', 'number-theory']"
435565,Limit of sum with parameter [duplicate],"This question already has answers here : The limit of truncated sums of harmonic series, $\lim\limits_{k\to\infty}\sum_{n=k+1}^{2k}{\frac{1}{n}}$ (12 answers) Closed 10 years ago . $$\lim_{n \rightarrow \infty} \sum^n_{k=1} \frac {1} {k+n} = \ln 2$$ I'm supposed to find the limit and get the right part as an answer. I don't know what to do with it. Could someone explain?","['calculus', 'limits']"
435567,Why do we include deleted neighborhoods when defining limits?,"Very often, we define the limit of a function as $0 < |x -a|< \delta \implies |f(x) - L|< \epsilon$ . A lot of times we don't let $x$ equal $a$ , and the reason for this is clear in the case of discontinuity. However, the book I am reading also doesn't allow $x = a$ for continuous functions.","['definition', 'calculus', 'limits']"
435574,Convergence of binomial to normal,"Problem: Let $X_n \sim \operatorname{Bin}(n,p_n) $ where $p_n \xrightarrow{} 0$ and $np_n \xrightarrow{} \infty$. What I need to show is that $$\frac{X_n - np_n}{\sqrt{np_n}} \xrightarrow{d} N(0,1) \text{ as } n\xrightarrow{} \infty.$$ My thoughts: My first thought was to set 
$$Y_n=\frac{X_n - np_n}{\sqrt{np_n}}$$
and investigate $P(Y_n=k) = p_{X_n}(\sqrt{np_n}k + np_n) $ as $n$ goes to infinity, but this led to very messy calculations so I don't know if it is the right approach. My second attempt was with Central Limit Theorem, rewriting $X_n$ as a sum of Bernoulli random variables, $X_n = Z_1 + \dots + Z_n$, $Z_n \sim \operatorname{Be}(p_n)$. The expectation and variance of each $Z_i$ is dependent on $n$ in that case. Will that violate any assumptions in CLT? I prefer working out these kind of questions from definition rather than using a theorem and previous results, so if anyone can show me that I would be very grateful! Thanks.","['convergence-divergence', 'weak-convergence', 'probability-limit-theorems', 'normal-distribution', 'probability']"
435576,Algebraic Solutions to Systems of Polynomial Equations,"Given a system of rational polynomials in some number of variables with at least one real solution, I want to prove that there exists a solution that is a tuple of algebraic numbers. I feel like this should be easy to prove, but I can't determine how to.  Could anyone give me any help? I have spent a while thinking about this problem, and I can't think of any cases where it should be false.  However I have absolutely no idea how to begin to show that it is true, and I can't stop thinking about it.  Are there any simple properties of the algebraic numbers that would imply this? I don't want someone to prove it for me, I just need someone to point me in the direction of a proof, or show me how to find a counterexample if it is actually false (which would be very surprising and somewhat enlightening).  If anyone knows anything about this problem I would be thankful if they could give me a little bit of help.","['geometry', 'algebraic-geometry', 'polynomials']"
435588,Direct sum of orthogonal subspaces,"I'm working on the following problem set. Let $\mathcal{H}$ be a Hilbert space and $A$ and $B$ orthogonal subspaces of $\mathcal{H}$. Prove or disprove: 1) $A \oplus B$ is closed, then $A$ and $B$ are closed. 2) $A$ and $B$ are closed, then $A \oplus B$ is closed. I could prove 1) and if my proof is correct, it even holds if $\mathcal{H}$ is just an inner product space. Unfortunately, I can't manage to prove 2). Since $\mathcal{H}$ is by assumption a Hilbert space and I didn't use that fact to prove 1), I should probably use it here. It means that $A$ and $B$ are also complete. Given some convergent sequence in $A \oplus B$, I want to show that the limit is also in  $A \oplus B$. Here I'm stuck. I want to use the completeness of $A$ and $B$, but I don't see how to obtain suitable Cauchy sequences. Can anyone drop me a hint? Or is my approach all wrong?","['hilbert-spaces', 'functional-analysis']"
435592,Concave function properties,"Given a concave function $f(x)$, $\,f(x)$ decreases as $\,x\,$ increases. That is,  $\;f(x_1)\gt f(x_2)\,$ if $\,x_2\gt x_1$ For $\;f(x_1)+f(x_2)\;$ and $\;\large\left(\frac{f(x_1+x_2)}{2}\right)^2,\;$ which one is larger? For $\;(1-f(x_1))(1-f(x_2))\;$ and $\;1\large-\left(\frac{f(x_1+x_2)}{2}\right)^2,\;$ which one is larger? Is there any theorem to prove it? Thanks!","['geometry', 'functions']"
435596,Check my answer: Prove that every open set in $\Bbb R^n$ is a countable union of open intervals.,"I have a question. I have solved this but please can you check my solution? Thank you. If there are any mistakes or something is missing and so on, please tell me. This is important to me. Is this proof enough to get a successful grade on an exam? Btw, I underlined the question with pink a pencil.","['general-topology', 'proof-verification', 'real-analysis', 'analysis']"
435599,"two fixed points, same fractional iteration","Suppose a function f(z) has two fixed points, one repelling, and the other attracting.  Call the repelling fixed point f(-1)=-1, and the attracting fixed point f(+1)=+1.  I'm interested in functions where the fractional iterates are the same, developed from either fixed point. We can generate fractional iterates, $g_{-1}(z)=f^{oz}$ from the Schroeder function of f(z) developed around the fixed point of -1, and also from the fixed point of +1, $g_{+1}(z)=f^{oz}$.  For what functions ""f"" will the two fixed points agree on their fractional iterates, such that $g_{-1}(z)=g_{+1}(z+k)$, where ""k"" is a constant? The only case I can find that works is $f(z)=\frac{z+c}{1+cz}$, where $0<|c|<1$, and the inverse function is $f^{-1}(z)=\frac{z-c}{1-cz}$.  Then $g(z)=\tanh(z\tanh^{-1}(c))$, which is derived using the tangent angle sum equation.  Are there any other functions f with symmetrical fractional iterates from both fixed points, or is this function family of functions the only functions with symmetrical fractional iterates from both fixed points? I know of one other case, iterating z^2, involving a super-attracting fixed point of zero, and a repelling fixed point of 1.","['dynamical-systems', 'complex-dynamics', 'complex-analysis']"
435603,Socle of abelian divisible periodic group,"I'm trying to prove that the socle of a periodic divisible abelian group J is a proper subgroup of J. I know that J is direct sum of quasicyclic groups, say $$
J={\oplus}_{i\in I} P_i
$$ and that the socle of J is $$
Soc(J)={\oplus}_p J[p]
$$ Now, I'm wondering if it is true that $$J[p]={\oplus}_{i\in I} P_i[p]$$ and that $$Soc(J)={\oplus}_p\big({\oplus}_{i\in I}P_i[p]\big)
        ={\oplus}_{i\in I}\big({\oplus}_p P_i[p]\big)
$$ Thank you very much!","['socle', 'group-theory', 'abelian-groups', 'divisible-groups']"
435606,How to find the limit $\lim\limits_{m\to\infty}\frac{m^{m-2}}{(m-1)^{m-2}}$?,I am trying to evaluate the limit of this: $$\lim_{m\rightarrow \infty} \frac{m^{m-2}}{(m-1)^{m-2}}$$ That is just basic calculus I think but I forget those methods for finding the limit. I think the limit is just $e$. Anyone could prove that? Thanks! Fei,"['calculus', 'limits']"
