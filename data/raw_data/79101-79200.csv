question_id,title,body,tags
1015202,Prove that the exponential function is differentiable,"Imagine that you are writing a book on the foundations of analysis. You have already proved that for each $a > 1$ there is a unique function $f_a(x) = a^x$ satisfying the following: $f_a$ is an isomorphism of ordered groups between $(\mathbb{R},+)$ and $(\mathbb{R}_{+},\cdot)$; $f_a(1) = a$. It follows from the monotonicity and bijectivity of $f_a$ that it is continuous. Now you would like to prove that $f_a$ is differentiable. At this point, you don't know anything about integration, differential equations or power series. What is the simplest or most elegant way of doing this?","['education', 'exponential-function', 'real-analysis']"
1015212,Prove there cannot be an inner product which turns $l^p$ into an inner product space?,"For all $1\leq p < \infty, \mbox{ }p$ is not equal to 2, prove there cannot exist an inner product that turns $(X,\|\cdot \|_p)$ into an inner product space; that is, prove that there cannot be exist an inner product $\langle\cdot , \cdot\rangle:l^p \times l^p \rightarrow \mathbb{C}$ for which $\langle x,x\rangle=\|x\|_p^2$ for each $x=(a_k)_{k\geq 1}$. Thanks, any help will be appreciated, I am completely stuck.","['normed-spaces', 'inner-products', 'hilbert-spaces', 'functional-analysis']"
1015215,Standard Error of Sample Variance,"I have a time-series of values $X_1, X_2, \ldots, X_t$, for which I compute sample variance: $$\hat{\sigma}^2  = \operatorname{var}(X_1, \ldots, X_t)$$ (unabiased estimator using $\frac{1}{t-1})$. In a subsequent calculation, I would like to use to shrink this variance estimate in proportion to its precision. How can I empirically estimate the standard error of this variance estimate? In theory, the variance of sample variance (for normal distribution) is: $$\operatorname{var}(\hat{\sigma}^2) = \frac{2}{t - 1} (\sigma^2)^2 $$ where $\sigma^2$ is the true variance. For the purporse of this calculation, can I safely assume that $\hat{\sigma}^2 = \sigma^2$, and thus let: $$\operatorname{var}(\hat{\sigma}^2) = \frac{2}{t - 1} (\hat{\sigma}^2)^2 $$ be an estimate of the variance of the sample variance? Any help would be appreciated! Thanks!","['statistics', 'standard-deviation', 'covariance']"
1015216,Need clarification on this l'Hopital's rule solution,"I found a solution to this limit using l'hoptital's rule, but I don't get the third step.
$$\eqalign{ \lim_{x\to\infty} {\ln3x}-{\ln(x+1)}
&= \lim_{x\to\infty} \ln\frac{3x}{x+1} \\
&=\lim_{x\to\infty} \ln\frac{3}{1+1/x}\\
&=\ln3\\}$$ I'm not sure how what happened to get the third line. Can you explain?","['calculus', 'limits']"
1015219,Prove that stabilizer subgroups of G are conjugate to each other,"Suppose that a group $G$ acts on a set $X$. Show that if $x_1$ and $x_2$ in X are in
  the same $G$-orbit, then their stabilizer subgroups of $G$ are conjugate
  to each other. My proof: Assume $x_1 = g_1x$ and $x_2 = g_2 x$ for some $g_1, g_2 \in G$. Let $h \in G_{x_1}$. We claim that $g_2g_1^{-1}hg_1g_2^{-1}$ is in $G_{x_2}$, thus proving that the two stabilizer subgroups are conjugate to each other. Indeed, 
$$\begin{align}
x_1&=g_1x\\
g_2g_1^{-1}x_1&=g_2x\\
g_2g_1^{-1}hx_1&=g_2x\\
g_2g_1^{-1}hg_1x&=g_2x\\
(g_2g_1^{-1}hg_1g_2^{-1})x_2&=x_2\\
\end{align}$$ as desired. I think it is a bit messy. Can you please comment on my proof and leave your own proof so that I can learn in a better way? Thanks in advance.","['proof-verification', 'proof-writing', 'group-theory', 'abstract-algebra']"
1015228,A question about local convexity of the weak operator topology,"By definition, I know a locally convex space is a topological vector space whose topology is defined by a family of seminorms $\cal P$ such that 
$$\bigcap_{p\in{\cal P}}\{x\colon p(x)=0\}=\{0\}.$$ Also I can easily show that a locally convex space by above definition separates the points and conversely. So this two properties are equivalent. Now I want to show weak operator topology (WOT) is locally convex. By above definition, suppose for every $\xi , \eta \in H$, $p_{\xi,\eta}(x) =0 $, thus $|(x\xi,\eta)|=0$ for every $\xi,\eta$. Put $\eta=x\xi$ we have $\|x\xi\|=0$ for every $\xi$ and we can conclude $x=0$. My problem is to show WOT is locally convex using the equivalent property. Suppose $x,y\in B(H)$ and $p_{h,k}(x) = p_{h,k}(y)$ for every $h,k\in H$. We have $|(xh,k)|=|(yh,k)|$. There are $r_x,r_y$ with $|r_x|=|r_y|=1$ such that $|(xh,k)|=r_x(xh,k)$ and $|(yh,k)|=r_y(yh,k)$ and in the end we can see $r_x x=r_y y$. In this way I can not conclude wot topology separates the points. Please help me to understand it. Thanks in advance.","['operator-theory', 'operator-algebras', 'topological-vector-spaces', 'functional-analysis']"
1015231,Jacobian Matrix in dynamical systems,Can someone explain what exactly the Jacobian matrix is (specifically in its application to dynamical systems) and maybe give an example of how to compute it? It really confuses me...and I haven't been able to find any good resources online.,"['dynamical-systems', 'matrices']"
1015255,Why does the whole integral converge but not part of it? (Dilogs),"$\newcommand{\Li}{\operatorname{Li}}$Consider the integral: $$\int_0^1 \frac{(-\Li_2(x) - \Li_3(x) - x^2/8 + 3x - x\log(1-x) + \log(1-x))}{x^2} \, dx$$ This integral converges to $\sim 0.01$ But when taken separately, $$ \int_0^1 \frac{-\Li_2(x) - \Li_3(x)}{x^2} \, dx$$ this integral does not converge. What is going on here? I dont understand?","['special-functions', 'calculus', 'integration', 'real-analysis', 'analysis']"
1015270,Comparing weak and weak operator topology,"We can compare topologies on $B(H)$. For instance, Sot topology is stronger than wot topology or $\sigma-$ weak topology is equivalent to weak* topology. I would like to compare wot topology and weak topology. Please help me. Thanks so much.","['operator-theory', 'banach-algebras', 'functional-analysis']"
1015272,Is inclusion map not the same as identity?,"Wikipedia says $i$ is an inclusion means $i: A \to B$ with $A \subset B$ means $i(x) = x$ for each $x\in A$. But doesn't this mean $i(A) = A$, so this is actually identity?","['elementary-set-theory', 'functions']"
1015290,Sempifying an algebraic expression,"I have the following expressions:$$f_1=a_1^2+a_2^2+\cdots+a_n^2$$
$$f_0=(a_1x_1+a_2x_2+\cdots+a_nx_n)^2$$
$$x_1^2+x_2^2+\cdots+x_n^2=1$$
I need to show that:$$f_1-f_0\ge0$$
for all $x_i$. Assume that all not the $a_i$'s are zero.",['algebra-precalculus']
1015292,A basic measure theory question on Stochastic Process,"Let $(Ω, F, P)$ be a probability space, $T$ some index
set, and $(S, Σ)$ a measurable space. $X : T × Ω → S$ is a
stochastic process, so it is measurable map. Let $S^T$ be the collection of all functions
from $T$ into $S$. I don't understand why $Φ_X : Ω → S^T$, defined by $Φ_X(\omega)(t) = X_t(\omega)$ is a measurable map. Is Fubini's theorem of help here.","['probability-theory', 'stochastic-processes', 'measure-theory']"
1015345,Flipping coins probability of $6$ flips having more heads than $5$ flips.,"I have $6$ fair coins and you have $5$ fair coins. We both flip our own coins and observe the number of heads we each have. What is the probability that I have more heads than you? Not sure how to start this, any help please?","['discrete-mathematics', 'probability']"
1015373,"Leray-Hirsch Using Kunneth Formula from ""Differential form in Algebraic Topology"" by Bott and Tu",Kunneth Formula: Let M and F are manifolds. If M has a finite good cover then $H^n(M\times F)=\bigoplus _{p+q=n} H^p(M)\bigotimes H^q (F)$ Bott and tu says One can prove Leray-Hirsch theorem by the same argument for Kuneth. I dont see how does  Leray-Hirsch follows via similar argument as Kunneth-Formula. Can someone help? I saw a similar question Relating the Künneth Formula to the Leray-Hirsch Theorem here. But I guess that post doesn't answer my question.,"['fiber-bundles', 'algebraic-geometry', 'algebraic-topology', 'differential-geometry']"
1015379,C*-algebra generated by the symmetric on 3 elements,"I want compute $C^*(S_3)$ where $S_3$ is the symmetric group on $\{1,2,3\}$ and $C^*(S_3)$ is the (full) C*-algebra generated by $S_3$. My attempt:
Since $S_3$ is a finite group, $C^*(S_3)=C_c(S_3)$ and its dimension is equal to the group order. So, I was trying to representate this group C*-algebra in a algebra of the form $\oplus_{i=1}^nM_{d_i}$. Since $S_3$ has order $6$, there are only two possibilities: $C^*(S_3)=\oplus_{i=1}^6\mathbb{C}$ $C^*(S_3)=M_2(\mathbb{C})\oplus\mathbb{C}\oplus\mathbb{C}$ Can anyone help me identify which one is it?","['operator-algebras', 'matrices', 'permutations', 'c-star-algebras']"
1015385,Computing $ \int \frac{{x}~{\cos^{-1}(x)}}{\sqrt{1-{x^2}}}~\mathrm{d}x $.,"I've just begun to learn integration which makes me a little nervous! Here's a question I'm having a problem with. Also my first time trying to use LaTeX. I apologise for any discrepancies. Compute:
  $$ \int \frac{{x}~{\cos^{-1}(x)}}{\sqrt{1-{x^2}}}~\mathrm{d}x $$ Here's what I did: Substitute $ u = \cos^{-1}(x) $. So, $ -~\mathrm{d}u = \frac{1}{\sqrt{1-x^2}}~\mathrm{d}x$. Also, I think it's also correct (please correct me if not) that $ x = \cos(u) $. This could be my mistake. $$ = -\int u~\cos(u)~\mathrm{d}u $$ Using integration by parts for $ f(x) = u $, $ f'(x) = 1 $, $ g'(x) = \cos(u) $ and $ g(x) = \sin(u) $, $$ = -~(u~\sin(u) - \int \sin(u)~\mathrm{d}u) $$
$$ = -~u~\sin(u) - \cos(u) + C $$ Substituing back, $$ -~\cos^{-1}(x)~\sin(\cos^{-1}(x)) - \cos(\cos^{-1}(x)) + C $$ I understand integration by parts could've been applied directly in the very beginning. But my first instinct when I solved was this. Is it in any way incorrect? I appreciate your time.","['calculus', 'integration']"
1015394,epsilon-delta limit with multiple variables,"I am getting confused with this epsilon delta proof of the limit for this particular case. Prove that $\lim_{(x,y)\to(0,0)} (2x^2+3y^2)=0.$ if the limit is equal to zero, then for any given positive epsilon there exists some positive delta, such that $0$ so in this case i have $|2x^2+3y^2|$ I cannot seem to find the way to express delta in epsilon terms 
I feel like i need to find the relationship between the given function and the $\sqrt{x^2+y^2}$","['epsilon-delta', 'multivariable-calculus', 'real-analysis']"
1015396,"$f$ an analytic function on $\mathbb{C}$ which takes values in $\mathbb{C}\backslash(-\infty,0]$ implies constant","Let $f$ be an analytic function on $\mathbb{C}$ which takes values in $\mathbb{C}\backslash(-\infty,0]$, i.e. takes values in the complement of the nonpositive part of the real axis. Show that $f$ is constant. My first observation is that there is a branch of the square root defined on $\mathbb{C}\backslash(-\infty,0]$ which takes positive real values along the positive part of the real axis. But I am not sure what do from thereon out. Any help would be appreciated!","['self-learning', 'complex-analysis']"
1015418,Number of Necklaces of Beads in Two Colors,"I was reading this paper , and came across an equation which gives an expression for the number of necklaces of beads in two colors, with length n. $Z_n = \dfrac{1}{n} \displaystyle \sum \limits_{d \mid n} \phi \left( d \right) 2^{n/d}$ The author says that this equality is well known, and cites Golomb and Riordan as examples.  However, I do not have access to these cited works. I was curious, what is the proof of this equality?  Is it generalizable to necklaces with an arbitrary number of colors? Related Questions (that do not answer my question explicitly): Black and white beads on a circle Beads on the circle Number of restricted ways to two-color a necklace","['necklace-and-bracelets', 'combinatorics']"
1015425,Proof regarding Robin's inequality (RI).,"Let $\sigma$ be the divisor sum function, $\gamma$ the Euler-Mascheroni constant and $n>5040$. Robin showed that if the inequality$$\displaystyle \sigma(n)<e^{\gamma}n\log\log n$$ ever fails, it does infinitely often. It is quite intuitive that infinitely many of the counterexamples (if not all) would be superabundant , i.e. natural numbers $a$ such that $\displaystyle \frac{\sigma(a)}{a}>\frac{\sigma(b)}{b}$ for all $b<a$. 
My proof, which I'd like to have verified: Let $SA_k$ be the $k$-th superabundant number. Then assume, without loss of generality, $$
\left\{ 
\begin{array}{c}
\sigma(SA_k)<e^{\gamma}SA_k\log\log SA_k \\ 
\sigma(m)\ge e^{\gamma}m \log \log m \\ 
SA_l < SA_k<m<SA_{k+1}
 \ , \end{array}
\right. 
$$
where $SA_l$ is the largest superabundant counterexample.
So we must have $$\displaystyle \frac{\sigma(m)}{\sigma(SA_k)}>\frac{m \log\log m}{SA_k\log\log SA_k} \\ \ \ \ \ \ \ \frac{\sigma(m)}{m \log\log m} >\frac{\sigma(SA_k)}{SA_k\log\log SA_k}. \ \ \ \ \ \  (1)$$
But since $m$ is between two consecutive superabundant numbers, it is not superabundant itself, hence it is by definition $\displaystyle \frac{\sigma(m)}{m}\le\frac{\sigma(SA_k)}{SA_k}$. Given that $ \log\log m >\log\log SA_k$, we easily find $$\displaystyle \frac{\sigma(m)}{m \log\log m} <\frac{\sigma(SA_k)}{SA_k\log\log SA_k},$$ contradicting $(1)$. As a result, we have no counterexamples $> SA_l$, which is an absurdity. $ \ \ \ \ \ \ \ \ \ \  \square$ Any comment, suggestion for improvement or alternative proof would be highly appreciated.","['divisor-sum', 'inequality', 'proof-verification', 'number-theory']"
1015462,A strange integral: $\int_{-\infty}^{+\infty} {dx \over 1 + \left(x + \tan x\right)^2} = \pi.$,"While browsing on Integral and Series , I found a strange integral posted by @ Sangchul Lee . His post doesn't have a response for more than a month, so I decide to post it here. I hope he doesn't mind because the integral looks very interesting to me. I hope for you too. :-) $$\mbox{How does one prove}\quad
\int_{-\infty}^{\infty}
{{\rm d}x \over 1 + \left[\,x + \tan\left(\, x\,\right)\,\right]^{2}} = \pi\quad
{\large ?}
$$ Please don't ask me, I really have no idea how to prove it. I hope users here can find the answer to prove the integral. I'm also interested in knowing any references related to this integral. Thanks in advance.","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
1015483,Solving the Diff. Eq: $y''+9y=36x\cos(3x)$,"I'm stuck on this differential equation: $$y''+9y=36x\cos(3x), \quad  \text{with }y(0)=-3, y'(0)=4$$ I know the homogenous equation is: $y_H(x)=A\cos(3x)+B\sin(3x)$ Now to find the particular solution... I believe this next step is right. $$Z_P(x)=A(x)e^{3ix}$$ Then we find the second derivative. $$Z''_P(x)=A''(x)e^{3ix}+6iA''(x)e^{3ix}-9A(x)e^{3ix}$$ After plugging $Z_P$ and $Z''_P$ into the equation we arrive at $A''+6iA=36x$ Where do we go now?  I'm not sure what to do.","['ordinary-differential-equations', 'calculus']"
1015507,Find minima of the multivariable function $\frac{4}{x^2+y^2+1}+2 xy$,"$$f(x,y)=\frac{4}{x^2+y^2+1}+2 xy \\ \text{within the  domain: }1/5\leq x^2+y^2\leq 4$$ I am able to find the maximum of the function at $x^2+y^2=4$ by substituting x,y for $\cos(t)$ and $\sin(t)$ and I am able to start working for a solution in the lower boundary: $$ x=\frac{1}{\sqrt5}\cos(t), \  y=\frac{1}{\sqrt5}\sin(t) \\ 
\frac{4}{\frac{6}{5}}+\frac{2}{\sqrt5}(\cos(t)\sin(t))\\ 
\frac{df}{dt}=\frac{2}{\sqrt5}\cos(2t)=0\\
\tan(t)=1\\
x=\frac{1}{\sqrt5}\lvert\cos(\frac{\pi}{4})\rvert \ ,  \ \ y=\frac{1}{\sqrt5}\lvert\sin(\frac{\pi}{4})\rvert \\
x=\pm\frac{1}{\sqrt{10}},y=\pm\frac{1}{\sqrt{10}}$$ When i resubstitute this into the original function I get the wrong answer. $$f\left(\frac{1}{\sqrt{10}},\frac{1}{\sqrt{10}}\right)=\frac{4}{\frac{12}{10}}+\frac{2}{10}=53/15
$$",['multivariable-calculus']
1015571,Counterexamples in $R$-modules products and $R$-modules direct sums and $R$-homomorphisms (Exemplification),"Q: (Exemplification) Do examples family of $R$-modules like $\{M_i\} , \{N_i\}$  and $R$-modules like $M,N$ such that every of four  question in underline is true. (in other word for every question Do Examples separately (Exemplification) $${Q1: \operatorname{Hom}_R\left ( \prod M_{i} ,N\right )\not \cong_{\Bbb Z} \bigoplus_{i\in I} \operatorname{Hom}_R\left ( M_{i} ,N\right )}$$
  $${Q2: \operatorname{Hom}_R\left ( \prod M_{i} ,N\right )\not \cong_{\Bbb Z} \prod_{i\in I} Hom_R\left ( M_{i} ,N\right )}$$ $${Q3: \operatorname{Hom}_R\left ( M ,\bigoplus N_{i}\right )\not \cong_{\Bbb Z} \bigoplus_{i\in I} \operatorname{Hom}_R\left ( M ,N_{i}\right )}$$ $${Q4:\operatorname{Hom}_R\left ( M ,\bigoplus N_{i}\right )\not \cong_{\Bbb Z} \prod_{i\in I} \operatorname{Hom}_R\left ( M ,N_{i}\right )}$$ in other word this question is four separate question but similar(may be in one answer is existed for all) . i can't any answer for every case(Q1-Q4).
if you can help me or hint until to aid to solve them (or one) 
for this question we just $\Bbb Z_p, \Bbb Q, \Bbb R, \Bbb C$ $R$-modules. and I think we must work with  this $R$-modules. but is not work for example (for Q1 ): I let $M_i =\Bbb Z_{p_i} , N=\Bbb R$ then $\operatorname{Hom}_R(\prod \Bbb Z_{p_i}, \Bbb R)=\{ \phi \mid \phi : \prod \Bbb Z_{p_i} \rightarrow \Bbb R$ is $R$-homomorphism $\}$ $\operatorname{Hom}_R\left ( \prod M_{i} ,N\right )=\{ \phi \mid \phi : \prod M_{i} \rightarrow N$ is $R$-homomorphism $\}$ $\operatorname{Hom}_R\left (  M_{i} ,N\right )=\{ \phi \mid \phi :  M_{i} \rightarrow N$ is $R$-homomorphism $\}$ $\cong_{\Bbb Z}$ is $\Bbb Z$-isomorphism. $\bigoplus M$ in this statement means submodules of product. In other words it's product word such that ${""""""\bigoplus_{i\in I} M_i=\{ (a_i) \in \prod_{i \in I}M_i : a_i=0}$  for all $i \in I$ except finitely elements $\}""""""$ I cannot find the true notation for this operation in help center, so i define this operation under question and in $"""""","""""" $in fact $\bigoplus$ in this statement is not true and just is used for notation in this way definition.
I must be find for every i to iv statement, examples to show...","['modules', 'commutative-algebra', 'products', 'abstract-algebra']"
1015598,Filling the cells of a $\mathbb{N} \times\mathbb{N}$ grid,"My roommate proposed this question to me. ""Write a natural number into each cell of a $\mathbb{N} \times\mathbb{N}$ such that each number appears exactly once in every row and column."" I think I've been over-complicating things but I haven't been able to think of a solution. I thought perhaps it would have something to do with how we show that the rationals are countable or even deals with Cantor's Pairing Function. Any thoughts on the solution? They are much appreciated.",['elementary-set-theory']
1015610,Number of solutions for IVP $\frac{dy}{dx}=3y^{{2}/{3}}$,"Consider the initial value problem $\dfrac{dy}{dx}=3y^{{2}/{3}}$ with initial condition $y(0)=0$. How many solutions are there for this IVP? 1 2 3 4 infinitely many. Clearly, $f(x,y)=3y^{\dfrac{2}{3}}$ does not satisfy Lipschitz's condition &  so the solution of the IVP is not unique. Solving the equation with initial condition we get $y=x^{3}$. Again $y=0$ is the trivial solution. So I get two solutions.Are there any other solution(/s)? I want to know all the solutions & how we find their?",['ordinary-differential-equations']
1015639,Evaluating $\int_0^{\infty} \log(\sin^2(x))\left(1-x\operatorname{arccot}(x)\right) \ dx$,"One of the ways to compute the integral $$\int_0^{\infty} \log(\sin^2(x))\left(1-x\operatorname{arccot}(x)\right) \ dx=\frac{\pi}{4}\left(\operatorname{Li_3}(e^{-2})+2\operatorname{Li_2}(e^{-2})-2\log(2)-\zeta(3)\right)$$ is to make use of the series of $\log(\sin(x))$, but the result I got after doing that wasn't that friendly. Is it possible to find a neat way of evaluating the integral?","['definite-integrals', 'calculus', 'integration', 'real-analysis']"
1015651,Frobenius theorem for 2-plane fields on some open set in $\mathbb{R}^3$,"I need help with this two part question. I am rather confused by it. let $f(x, y, z)$, $g(x, y, z)$ be smooth on $U \subset \mathbb{R}^3$ with $f^2 + g^2 > 0$ on $U$. Define the differential form $$\omega = f(x, y, z)\,dx + g(x, y, z)\,dy$$ on $U$. Establish necessary and sufficient conditions on $f$, $g$ for the plane field defined by $\omega$ on $U$ to be integrable. Explain the condition you find geometrically. What do the integral surfaces look like? Let $a(z)$, $b(x)$, $c(y)$ be smooth functions on $U \subset \mathbb{R}^3$, not all vanishing. Repeat the first part for $$\omega = a(z)\,dx + b(x)\,dy + c(y)\,dz.$$ I understand that for the first part the necessary and sufficient condition for integrability is $\omega \wedge d\omega = 0$, and that the right thing to do for the second part is to forget about $U$ and assume that the functions are smooth on all of $\mathbb{R}^3$.","['multivariable-calculus', 'manifolds', 'differential-geometry']"
1015655,Identities of sets,"Let $U$ a set and $A,B$ subsets of $U$. I have to prove the following sentences: $A \cap A^c=\varnothing, \ \ \ \ A \cup A^c=U$ $(A^c)^c=A$ $(A \cap B)^c=A^c \cup B^c$ $(A \cup B)^c=A^c \cap B^c$ $A \setminus B=A \cap B^c$ That's what I have tried: $x \in A \cap A^c \leftrightarrow x \in A \wedge x \in A^c \leftrightarrow x \in A \wedge x \in U \setminus A \leftrightarrow x \in A \wedge(x \in U \wedge x \notin A) $, that is a contradiction. So, there is no $x$, such that $x \in A \cap A^c$, so we conclude that $A \cap A^c=\varnothing$. $x \in A \cup A^c \leftrightarrow x \in A \lor x \in A^c \leftrightarrow x \in A \lor x \in U \setminus A \leftrightarrow x \in A \lor (x \in U \wedge x \notin A) \leftrightarrow x \in U$. Therefore, $A \cup A^c=U$ $x \in (A^c)^c \leftrightarrow x \in U \setminus A^c \leftrightarrow x \in U \wedge x \notin A^c \leftrightarrow x \in U \wedge x \in  A \leftrightarrow x \in A$ So, we conclude that $(A^c)^c=A$. $x \in (A \cap B)^c \leftrightarrow x \in U \setminus A \cap B \leftrightarrow x \in U \wedge x \notin A \cap B$ How can we continue? EDIT : Could we prove maybe the sentences $4,5$ like that? $$x \in (A \cup B)^c \leftrightarrow x \in U \setminus (A \cup B) \leftrightarrow x \in U \wedge x \notin A \cup B \leftrightarrow x \in U \wedge x \notin A \wedge x \notin B \\ \leftrightarrow x \in U \wedge x \in A^c \wedge x \in B^c \leftrightarrow x \in U \wedge x \in A^c \cap B^c \leftrightarrow x \in A^c \cap B^c$$ $$x \in A \setminus B \leftrightarrow x \in A \wedge x \notin B \leftrightarrow x \in A \wedge x \in B^c \leftrightarrow x \in A \cap B^c$$",['elementary-set-theory']
1015685,Wolfram Alpha can't solve this integral analytically,"Wolfram Alpha isn't able to calculate this integral (I don't have mathematica, but I have Wolfram Pro). $$\int_{0}^{a} \frac{1}{\sqrt{(x-a)^2+(x-b)^2}} \ dx \ \ \ , \ b>a$$ This is for a physics problem. I'd appreciate either a solution or the knowledge that the integral is non-soluble (which would indicate that I need to find some symmetry that I haven't seen yet). Thanks!",['integration']
1015713,How to deal with negative exponents in modular arithmetic?,"So I think I understand how to calculate something like $(208\cdot 2^{-1})\mod 421$ using extended euclidean algorithm. But how would you calculate something like $(208\cdot2^{-21})\mod 421$? Thanks, this is basically for my cryptography class; I'm just trying to understand the ""big step, baby step"" algorithm.","['modular-arithmetic', 'exponentiation', 'cryptography', 'number-theory']"
1015714,"Find a subsheaf of a coherent sheaf, whose quotient is torsion sheaf.","Suppose $X$ is a variety, $\mathcal{F}$ is a coherent sheaf, its generic stalk has rank $r$. How to find an ideal sheaf $I$ such that a direct sum of $r$ copies of $I$ injects into $\mathcal{F}$ and $$0\to\oplus_r\mathcal{I}\to \mathcal{F}\to \mathcal{F}/\oplus_rI\to 0$$ the quotient sheaf vanishes on the generic stalk?",['algebraic-geometry']
1015723,Standard Error in OLS Regression,"Assuming I have the following linear regression set-up: $y_i = \alpha + x_i * \beta + \epsilon_i$ for $i = 1,2,..., n$. When I run the regession, I get a $\beta$ and $\alpha$ estimates, along with their standard errors. Let $\sigma_{\alpha}$ and $\sigma_{\beta}$ be the standard error of $\alpha$ and $\beta$ respectively. If I want to compute the standard error of the expression $\hat{\alpha} + x_i * {\hat\beta}$ for each value of $i$, would that be: $\sqrt{\sigma^2_{\alpha} + x^2_i * \sigma^2_{\beta}}$   ??? Any help would be appreciated! Thanks!","['statistics', 'regression', 'standard-deviation']"
1015741,Fuzzy statistics bibliography.,"Could someone recommend me fuzzy statistical literature? I have basic knowledge of probability theory and statistics, but this topic is totally new to me. Prefer books I can download, but any recommendations are welcome.","['statistics', 'reference-request']"
1015747,Example of ODE $x' = f(x)$ for $f : \mathbb{R}^3 \to \mathbb{R}^3$ such that solution is bounded but not periodic,"On the last page of these notes: http://www.cds.caltech.edu/archive/help/uploads/wiki/files/179/lecture5Bs.pdf the author says that ""for $n \geq 3$ trajectories may wander around a bounded region without settle down to a fixed point or a closed orbit.""  I've been trying to think of an IVP in which this scenario happens but can't come up with anything.  Is there some classic example someone can point me to? More specifically, could you give me an example of an ODE $x' = f(x)$ for some $f : \mathbb{R}^3 \to \mathbb{R}^3$ such that a solution is bounded but is neither an equilibrium nor a periodic orbit?",['ordinary-differential-equations']
1015751,Give a combinatorial argument,Give a combinatorial argument to show that $$\binom{6}{1} + 2 \binom{6}{2} + 3\binom{6}{3} + 4 \binom{6}{4} + 5 \binom{6}{5} + 6 \binom{6}{6} = 6\cdot2^5$$ Not quite where to starting proving this one. Thanks!,"['combinatorial-proofs', 'discrete-mathematics', 'combinatorics']"
1015772,Repeated projection of points onto lines,"Consider a point $P$ on the Euclidean plane, and lines $l_1,l_2,\ldots,l_n$. Project $P$ onto $l_1$. Then project the resulting point onto $l_2$. Then project the resulting point onto $l_3$, and so on, up to $l_n$. Then project the resulting point onto $l_1$ again, then $l_2$, ..., repeating the process. Will the set of projected points always be bounded? That is, does there always exist $r$ (possibly depending on $P,l_1,\ldots,l_n$) such that the resulting points always stay within the disk of radius $r$ centered at $P$?","['geometry', 'combinatorial-geometry', 'euclidean-geometry']"
1015786,"What are the ""right"" spaces for the Laplace transform","There are for example several canonical spaces to define the Fourier transform (i.e. Schwartz's space). Is there also a particularly suitable space to define the Laplace transform, so that the Laplace transform is at least bijective?","['integral-transforms', 'harmonic-analysis', 'real-analysis', 'analysis', 'functional-analysis']"
1015799,Linear Algebraic Group whose elements have finite order is finite,"Assume $k$ alg. closed field, with characteristic $0$. Let $G$ a linear algebraic group, whose elements have finite order, in symbols $$ \forall g \in G, \exists n \in \mathbb{N} \ \  \text{s.t. } g^n=e  $$ Prove that it is finite. My attempt At first I wanted to make use of the variety-version of this ""well known result"" . Algebraically closed field and characteristic $0$ doesn't imply that $k$ is uncountable (Thanks to Matt S for the observation) So I need to prove this (if possible) to use the result, which was given as an hint of the exercise. The countable family of closed would be $\{Z_i\}_{i \in \mathbb{N}}$ where $$ Z_i := \{ g \in G \mid g^i = e \}$$ obviously $G=\bigcup_i Z_i$ but I'm not able to prove (I hope it is true with these hypothesis) that $$ \forall i \in \mathbb{N} \ Z_i \neq G $$ using the fact that $G$ is an infinite group . Suppose we have proved that, we would have that $$ \bigcup_i Z_i \neq G$$ so exists an element in $G$ of infinite order, so an absurd and so $G$ cannot be infinite. So can someone help me filling the details of this proof (I've highlighted the two problematic steps) ? In particular, the second step is motivated by the fact that I have to find an absurd using infiniteness of the group, otherwise would be true. Maybe I've chosen the wrong family of closed, but anything else came to my mind Thanks in advance",['algebraic-geometry']
1015818,Find all integers n such that $\;\frac{n^2-9}{n^2-5n+4}$ is an integer.,"Find all integers such that $\;\dfrac{n^2-9}{n^2-5n+4}\;$ is an integer. I am really struggling to figure this out. I can tell that -3,3, and 5 are solutions but I don't know how to show that these are the only solutions or if they even are the only solutions.",['algebra-precalculus']
1015828,Curves with a common tangent line,"Question Find the point where the curves $$\tag 1y = x^3 -3x + 4$$ and $$\tag 2 y = 3x^2 - 3x$$ are tangent to each other, that is, have a common tangent line. My approach Let $x = a$ and $x = b$ be the points on curves $(1)$ and $(2)$, respectively, at which their slopes are equal and share a mutual tangent line. Now I will relate the $a$ and $b$ by equating the derivatives of $(1)$ at $a$ and $(2)$ at $b$, as follows $$3a^2 - 3 = 6b- 3 \Leftrightarrow b = \frac{a^2}{2}$$ Let $A$ be the point on curve $(1)$ and $B$ be the point on curve $(2)$ where the two curves share the mutual tangent, that is $$A(a, x^3 - 3x + 4)$$ and $$B(b, 3b^2 - 3b) = B\Big(\frac{a^2}{2}, \frac{3a^4 - 6a^2}{4}\Big)$$ Now, since I have two points on the tangent line, I can calculate the slope and equate it to the derivative of $(1)$ at $a$ as follows 
$$\frac{(x^3 - 3x + 4) - \Big(\frac{3a^4 - 6a^2}{4}\Big)}{a -  \frac{a^2}{2}} = 3a^2 - 3$$ Simplifying that equation I get the following, $$3a^4 -8a^3  - 12a^2 + 16 = 0$$ Now, I would solve for $a$ and then substitute the value of $a$ in to points $A$ and $B$ which would then be the points at which the two curves have a common tangent line. The problem is that I doubt I should be solving such an equation, and quite frankly, I don't have the tools to solve that equation, unless I'm missing something? Any suggestions?","['calculus', 'derivatives']"
1015830,Mathematical Induction Proof - Exponent with n in denominator,"Use mathematical induction to prove the following:
$$\frac{1}{2}+\frac{2}{2^2}+\frac{3}{2^3}+...+\frac{n}{2^n}=2-\frac{n+2}{2^n}; n ∈ N $$ I am having trouble figuring out how to solve this with an exponent in the denominator. $$2-\frac{n+2}{2^n}+\frac{n+1}{2^{n+1}} $$","['induction', 'discrete-mathematics', 'proof-writing']"
1015885,Eigenvalue of the Power of a Matrix [duplicate],"This question already has answers here : Eigenvalues and power of a matrix (3 answers) Closed 3 years ago . Let $A$ be an n×n matrix with eigenvalues $\lambda_1,\dots,\lambda_n$. Show that
$\lambda_1^k,\dots,\lambda_n^k$ are the eigenvalues of $A^k$. I don't know where to start.","['linear-algebra', 'eigenvalues-eigenvectors']"
1015963,Mean of a Cauchy Distribution,"Why is the mean of a Cauchy distribution undefined? Surely, it should be $0$ by symmetry? $$\int_{-\infty}^{\infty} {\frac{x}{\pi (1+x^2)}} dx =0?$$","['expectation', 'probability', 'integration']"
1015974,Borel subalgebras inside the grassmannian,"This is probably something standard and I just don't know where to look (so a reference would be just as appreciated as an answer), but... Let $\mathfrak{g}$ be a finite dimensional semisimple Lie algebra over a field $k$. People sometimes define the flag variety $\mathcal{B}$ to be the set of Borel subalgebras of $\mathfrak{g}$, and then endow $\mathcal{B}$ with the structure of a variety by regarding it as a subset of the grassmannian of $\dim(\mathfrak{b})$-dimensional subspaces of $\mathfrak{g}$, where $\mathfrak{b}$ is some fixed Borel subalgebra (for instance, see page 129 in section 3.1 of Chriss and Ginzburg's book Representation Theory and Complex Geometry ). Why is $\mathcal{B}$ a closed subset of the grassmannian?","['algebraic-geometry', 'representation-theory', 'lie-algebras', 'grassmannian']"
1015977,"A closed, bounded subset $A$ of $\Bbb Q$ and a continuous function $f : A → \Bbb R$ such that $f$ is not bounded","Find a closed, bounded subset $A$ of $\Bbb Q$ and a continuous function $f : A →\Bbb R$ such that $f$ is not bounded Note: $\Bbb Q$ is the set of all rationals. My Solution: $A=\{x:x\in\Bbb Q, 1\leq x\leq2\}$. Clearly $A$ is bounded below by $1$ and bounded above by $2$. Also $A$ is closed since it contains its limit points. Define $f : A →\Bbb R$ such that $f(x)=\frac1{x-1}$. $f(x)$ is not bounded at $x=1$ but I am unsure about its continuity at $x=1$. Does the right continuity at $x=1$ alone ensure the function is continuous? What is more important is the question that how does this not violate the theorem that the image of a compact set is compact under a continuous function. Since $A$ is compact (any open cover of $A$ has a finite subcover), the images of $A$ under $f$ must also form a compact set which implies that the image set is closed and bounded, contradiction.","['uniform-continuity', 'continuity', 'limits']"
1015993,"$d(x_n,y_n)$ converges to a limit when $x_n, y_n$ are Cauchy sequences","Let $(X,d)$ be a metric space and $x_n, y_n$ Cauchy sequences.  Is there a way to prove that $\lim\limits_{n \to \infty} d(x_n,y_n)$ exists without involving the completion of $X$?  Intuitively you have the $x_n$s, and the $y_n$s, each trapped in an open ball, so their distance cannot change wildly.  But it seems surprisingly difficult to prove that the given limit actually exists.","['general-topology', 'metric-spaces']"
1015994,Understanding Spherical coordinates on ellipses.,"I was given the following problem: $$\iiint\limits_D (4x^2+9y^2+36z^2)\,dV,$$ where $V$ is the interior of the ellipsoid
$$\frac{x^2}{9}+\frac{y^2}{4}+z^2=1.$$ The problem gives what the new coordinate system will be:
\begin{align}
x&=3\rho\sin\theta\cos\phi,\\
y&=2\rho\sin\theta\sin\phi,\\
z&=\rho\cos\theta.
\end{align} I don't really know why that would work. Let's take the ellipse on the $xy$ plane and polar coordinates:
$$\frac{x^2}{9}+\frac{y^2}{4}=1;~~~~~~~~~~~~x=3r\cos\theta,~~y=2r\sin\theta.$$
How do I know that for every $\theta$ I will end up with a point on the ellipse? Moreover, how do I know that with the change of variables given by the problem I will end up with a point on the ellipsoid? I appreciate your thoughts.","['multivariable-calculus', 'coordinate-systems', 'spherical-coordinates']"
1016008,Injectivity of sine on complex domain?,"So the problem is :
let $R$ be region $[{z\in \mathbb{C} : -\cfrac{\pi}{2}<Re(z)<\cfrac{\pi}{2}}]$. Show that sine function is injective in R. I could think about two starting points: i) we have $\sin(z) = \cfrac{e^{iz}-e^{-iz}}{2i}$. So if, say for $z_1,z_2 \in R$, $\sin(z_1)=\sin(z_2)$, then we have $e^{iz_1}-e^{-iz_1}=e^{iz_2}-e^{-iz_2}$ but I have no idea how to continue from this. Since region $R$ mentions real part of the complex number, I will need to refer to it at some point but I dont seem to find how. I tried to put $z_1$ and $z_2$ into the form $x+iy$ but it only seemed to complicate things. ii) So after above attempt, maybe I thought it was better to consider imaginary part and real part separately: $\sin(x+iy)=\sin(x) \cosh(y)+i\cos(x) \sinh(y)$ so I proceeded in exactly same way, but in the end I had to relate two equations arising from equating real/imaginary parts somehow, but that actually made attept too complicated. I have a feeling that it shouldn't be this hard... any hints are appreciated!",['complex-analysis']
1016014,Largest subset with no pair summing to power of two,"For positive integer $n$, define the set $A_n=\{0,1,\ldots,n\}$. What is the size of the largest subset of $A_n$ such that the sum of any two (not necessarily distinct) elements in it is not a power of $2$? So, a power of $2$ can never be chosen. For $n=3,4,5$, the set $\{0,3\}$ is the best possible, and for $n=6,7$ we can choose $\{0,3,6\}$ and $\{0,3,6,7\}$, respectively.","['extremal-combinatorics', 'elementary-number-theory', 'combinatorics']"
1016022,Question regarding the sequence definition of continuity.,"Here is an excerpt from Ross' Elementary Analysis (specifically the definition of continuity): ""The function $f$ is $\it \space continuous\space  at \space x_0$ if, for every sequence $(x_n)$ in $dom(f)$ converging to $x_0$, we have $lim_nf(x_n)=f(x_0)$.""
My question is the subscript in the limit needed?","['continuity', 'limits']"
1016028,"Proving that f is measurable if g is measurable where $g(x, y) = |f(x) - f(y)|$","I need help understanding the proof of this question. Basically it involves Fubini's theorem and I can't seem to get a grasp on the proof (and I am pretty sure this question uses techniques from the proof). The question is as follows: Assume $f:[0,1] \rightarrow \mathbb{R} $ is measurable and define $g: [0, 1]^2 \rightarrow \mathbb{R}$ by  $g(x, y) := |f(x) - f(y)|$. Prove that $f$ is integrable if and only if $g$ is integrable. Proof.
The slice of $g$, $g_x(y) = |f(x) - f(y)|$ is integrable iff $h(y) = f(x) - f(y)$ is integrable and $h(y)$ is integrable iff $f$ is integrable. $(*)$ Now, assume $g$ is integrable. If $g$ is integrable, then by Fubini's theorem, the slice $g_x$ is integrable for almost all $x$. If the slice is integrable then $(*)$ shows that $f$ is integrable. Now assume $f$ is integrable. Then again by $(*)$ $g_x$ is integrable $\forall x$. Also, $$\int f - |f(x) \leq \int |f(x) - f(y)| dy \leq |f(x)| + \int f \qquad (**)$$ Then the function $\alpha(x) = \int |f(x) - f(y)| dy$ is bounded and measurable and therefore integrable on $[0, 1]$. By Fubini we have $\int g = \int \int |f(x) - f(y)| dy dx = \int \alpha(x) dx$ hence $g$ is integrable. Now my question(s) are: How did $(*)$ come about? It seems intuitive to me to claim that but can someone explain to me why that is the case? In the forward direction (assuming f is true), how can the claim that $g_x$ be integrable hold for ALL x? And where is the $(**)$  coming from?","['measure-theory', 'lebesgue-measure']"
1016033,Bernoulli's inequality and an unexpected limit,"This question is inspired by What would happen to Bernoulli's inequality if $x<-1$? . Let $x_n=\min\{x\in{\bf R}:(1+x)^n\geq 1+nx\}$, where $n$ is natural and odd (my mistake in the first version, observed by @mfl). Is it true, that 
$$
\lim_{n\to\infty}x_n=-2?
$$
Numerical computations suggest the positive answer.","['inequality', 'real-analysis']"
1016049,Oscillation matrix whose $n-1$ power is totally positive,"Let $A$ be a $n\times n$ real matrix. If all the sub-determinant of $A$ is $\geq0$, then $A$ is called totally non-negative. If all the sub-determinant of $A$ is $>0$, then $A$ is called totally positive. If for a totally non-negative matrix $A$, there exists a positive integer $m$ such that $A^m$ is totally positive, then $A$ is called an oscillation matrix. Prove that if $A$ is an oscillation matrix, then $A^{n-1}$ is totally positive... I have no ideas...my god.",['matrices']
1016052,Number of length $8$ binary strings with no consecutive $0$'s,"How many $8$ bit strings are there with no consecutive $0$'s? I just sat an exam, and the only question I think I got wrong was the above(The decider for a high-distinction or a distinction :SSS) I took Number with consecutive $0$'s 1 zero $0$ 2 zeros $\frac{7!}{6!}$ 3 zeros above + $\frac{6!}{5!}$ 4 zeroes above + $\frac{5!}{4!}$ 5 zeros above + $\frac{4!}{3!}$ 6 zeroes above + $\frac{3!}{2!}$ 7 zeroes above + $\frac{2!}{1!}$ 8 zeroes above + $1$ $(7*7)+(6*6)+(5*5)+(4*4)+(3*3)+(2*2)+1=140$ and we have $2^8 - 140=116$ Is this correct?","['permutations', 'combinatorics']"
1016124,Union of all finite cyclic groups,"Let $C_n$ be the cyclic group of order $n$. I'm trying to investigate properties of $\bigcup_{n=1}^{\infty} C_n$ It seems obvious that this is a group, but I don't really know much else about it. Does this group have a name, and are there any references where properties of this group are described? Edit: The group operation here is given by thinking of the elements of $C_n$ as complex nth roots of unity. For any two elements $x \in C_n$ and $y \in C_m$, the product $xy \in C_{mn}$ is just given by complex multiplication.","['reference-request', 'cyclic-groups', 'group-theory']"
1016151,Probability that Ken and John set next to each other,"A group of ten people sits down, uniformly at random, around a table. Ken
  and John are part of this group. Determine the probability that Ken and John sit
  next to each other. There are $10!$ ways to arrange the seating for everyone, there are 10 possible ways for John and Ken to sit together. $$\operatorname{Pr}(J\ \&\ K ) = \frac{10}{10!} = \frac{1}{9!}$$ Am I correct?",['probability']
1016183,Determining $\frac{d^2\arcsin(2x)}{dx^2}$,I am hitting my head against a wall trying to understand how to differentiate this. $$f(x) = \frac{d^2\arcsin(2x)}{dx^2}$$ Can someone please hold my hand through this?  I understand that $\arcsin(2x) = \sin^{-1}(2x)$ . Is this implicit differentiation?,"['trigonometry', 'calculus', 'derivatives']"
1016186,Algorithm to compute fastest method of collecting $k$ re-spawning items which spawn at $n$ specified points,"Let $V = v_1, \dots, v_n$ be the locations the items can spawn at, and let $U = u_1, \dots, u_k$ be the current positions of the items. We will assume a new items spawns instantly every time we collect an item, so there are always $k$ items (Assume uniform distribution for spawn location). Let $w$ be the current position of the character. Then $S = (V, U, w)$ is the state of the game. Assume the character can move at a constant speed, so the time metric we care about is proportional to the distance between two points. Essentially I want a function $\text{bestItem}(S)$ that tells me which item in $U$ to go to first to maximize the number of items I collect per hour. This seems similar to shortest path on a clique with weighted edges, but it doesn't stop after one step. Or a traveling salesman problem where the traveling salesman doesn't know all the locations he needs to visit from the start. Is there a name for this problem? I am curious if it is already solved, and how good the greedy method of just always taking the nearest item is compared to the optimal method. Or the method of computing the shortest path through the points of $U$, and updating it after some number of spawns. Has anyone worked with this type of problem and point me at some reading material? My interest is inspired by video games which have mechanics like this. Thanks.","['graph-theory', 'discrete-mathematics', 'probability', 'algorithms']"
1016191,Rank Theorem proof,"Let $\phi: M \to N$ be an immersion from smooth manifold $M^m$ into $N^n$ ($\dim M = m$ and $\dim N = n$). Prove there exists smooth charts $(U,h)$ in $M$ with $p \in U$, $h(p) = 0$, and $(V,g)$ in $N$ with $\phi(p) \in V$, $g(\phi(p)) = 0$ such that the transition map $$g \circ \phi \circ h^{-1}(x_1, \dots, x_m) = (x_1, \dots, x_m, 0,\dots,0)$$ in a neighbourhood of $0$. Consider the case for $\phi: W \to \Bbb R^n$ is smooth with $W $ be open in $\Bbb R^m$ containing $0$ and $\phi(0) = 0$ and the Jacobian of $\phi$ is $J(\phi)_{m \times m} \neq 0$. Then use Inverse Function Theorem on $F : W \times \Bbb R^{n - m} \to \Bbb R^n$ where $$F(x_1, \dots, x_n) = (\phi_1(x_1 ,\dots, x_m),\dots, \phi_m(x_1 ,\dots, x_m),x_{m+1},\dots,x_n).$$ So I showed that $J(F) = \begin{bmatrix}
J(\phi) &0 \\ 
 0& I
\end{bmatrix}_{n \times n}$ is of course invertible, then Inverse Function Theorem says I have open set $0 \in L \subset W \times \Bbb R^{n -m}$ and $F(0) \in F(L) \subset \Bbb R^n$ where $F$ is a local diffeomoprhism. In this suggests I need to relate the given charts from the open sets I have shown here to finish off the transition map to show $$g \circ \phi \circ h^{-1}(x_1, \dots, x_m) = (x_1, \dots, x_m, 0,\dots,0)$$ If someone could help me glue everything together, it would be great.","['general-topology', 'manifolds', 'smooth-manifolds', 'differential-geometry']"
1016199,Recursive identity for elliptic lattice constants $\sum_{\lambda\in\Lambda\setminus0} \lambda^{-2k}$,"I am stuck on Exercise 3 in these notes . To keep this question self-contained: we have $\displaystyle\Lambda=\langle\omega_1,\omega_2\rangle=\omega_1\Bbb Z+\omega_2\Bbb Z\subset\Bbb C,$ $\displaystyle \wp(z)  =\frac{1}{z^2}+\sum_{\lambda\in\Lambda\setminus0}\left(\frac{1}{(z-\lambda)^2}-\frac{1}{\lambda^2}\right)=\frac{1}{z^2}+\sum_{k=2}^\infty(2k-1)G_{2k}z^{2k-2} ~~ (z\approx0), $ $\displaystyle G_k=\sum_{\lambda\in\Lambda\setminus0}\frac{1}{\lambda^k}, \quad G_{\rm odd}=0,$ $\dot{\wp}^2=4\wp^3-40G_4\wp-160G_6.$ (See the link for proof of $\wp$'s Taylor expansion and the differential equation.) I want to prove $$(n-3)(2n+1)(2n-1)G_{2n}=\sum_{\substack{k+l=n \\ k,l\ge2}} (2k-1)(2l-1)G_{2k}G_{2l}$$ for $n\ge4$. Multiplying both sides by $z^{2n}$ and summing should result in a differential equation that will surely yield an unwieldy equation involving $z,\wp,\wp^2,\dot{\wp},\ddot{\wp}$. I have no how to derive this from the known differential equation $(4)$, or if perhaps I should try a route other than generating functions and differential equations to prove the identity. Perhaps I should augment the generating function because the identity is only being proven for $n\ge4$?","['ordinary-differential-equations', 'elliptic-functions', 'modular-forms', 'recurrence-relations']"
1016201,"High School Advanced Functions: Clarifying log rules in a log equation - $\log(x^2) = 2$, Solve for x.","I got in an argument with my teacher for the possible solutions of x. From some sources i found that because x is squared, negative values should be possible; however, my teacher insists that:
$$
\log(x^2) = 2\log x
$$
and that they have to be interchangeable, no matter what was given originally. Therefore the negative solution (-10) would be extraneous.
Please help me understand which is correct! Thanks.","['logarithms', 'algebra-precalculus', 'functions']"
1016214,Every function from discrete metric space to another metric space is uniformly continuous,"My solution:It is fairly straightforward graphically but I just want to ensure if it is rigorous enough. Suppose $X$ is a discrete metric space and $f$ be any function from $X$ to $Y$ where $Y$ is any other metric space. Let $d_{x}$ and $d_{y}$ denote the metrics in metric spaces $X$ and $Y$ respectively. If $p,q\in X, p=q$, then $d_{x}(p,q)=0<\delta$ for any $\delta>0$.
If $p,q\in X, p\neq q$, then $d_{x}(p,q)=1$. Choosing $\delta=2$, we have $d_{y}(f(p),f(q))<\epsilon$, $\forall \epsilon>0$. So $\forall \epsilon>0,$ we have $\delta>2$, such that $d_{x}(p,q)<\delta$ implies $d_{y}(f(p),f(q))<\epsilon$. So, any function from a discrete metric space to any other metric space is uniformly continuous. Please suggest if it is correct and rigorous enough.","['uniform-continuity', 'continuity', 'limits']"
1016218,Verifying an Epsilon-Delta Limit,"I have to prove that  $$\lim_{x \to a} \frac{1}{\sqrt{x}}=\frac{1}{\sqrt{a}}$$ where x>0 and a>0. So given $\epsilon>0$, I let $\delta<a/2$. Then: $$|x-a|<\delta \\ -\delta<x-a<\delta \\ a-\delta<x<a+\delta \\ a/2<x<3a/2$$ So now $$|1/(\sqrt{x})-1/(\sqrt{a})| =|(\sqrt{a}-\sqrt{x})/(\sqrt{xa})|\\ =|(\sqrt{a}-\sqrt{x})(\sqrt{a}+\sqrt{x})/(\sqrt{xc}(\sqrt{a}+\sqrt{x}))| \\ =|(x-a)/(\sqrt{xa}(\sqrt{a}+\sqrt{x}))| \\ <|(x-a)/(\sqrt{xa}(\sqrt{a})| \\ <\delta/(\sqrt{a/2*a}\sqrt{a})\\ <2\delta/(a^{3/2})<\epsilon$$ so given any $\epsilon>0$, let $\delta<min(a/2, \epsilon*a^{3/2}/2)$ so now if $\delta<\epsilon*a^{3/2}/2<a/2$ $|1/(\sqrt{x})-1/(\sqrt{a})|<2\delta/(a^{3/2})<2\epsilon*a^{3/2}/(2a^{3/2})=\epsilon$, and now if $\delta<a/2<\epsilon*a^{3/2}/2$, then $|1/(\sqrt{x})-1/(\sqrt{a})|<2\delta/(a^{3/2})<2(a/2)/a^{3/2}<2\epsilon*a^{3/2}/(2a^{3/2})=\epsilon$ Does this proof work?  Thanks","['epsilon-delta', 'real-analysis']"
1016223,Closed Subspaces of Hilbert Spaces,"I read the following statements. But I do not know how to show it or any example to support it. Could anyone provide some explanation and examples, please? Thank you! The subspace $C^\infty$ functions inside $\mathcal L^2(\mathbb R)$ is not closed. The subspace of simple functions inside $\mathcal L^2(\mathbb R)$ is not closed. Polynomials inside $C^0$ is not closed. I can think of the following Not sure. In addition, how do we know that $C^\infty \subset \mathcal L^2(\mathbb R)$ in the first place, please? Consider a sequence of functions of the following form: $$f_n (x) := \frac{k}{n}\chi_{\left[\frac{k}{n}, \frac{k+1}{n}\right)}(x),$$ where $n \in \mathbb N$ and $k = 0, 1, \dots$. Each function $f_n$ is defined on $[0, 1)$ and is left continuous. This sequence converges in norm to $f=x\mathbb I_{[0, 1)}$ which is not a simple function. So the set of simple function is not closed. Is this a valid counter example, please? I know that polynomials are dense in continuous functions. But there are plenty of continuous functions which are not polynomials. Hence, it is true that polynomials are not closed. But any concrete example, please?","['self-learning', 'big-list', 'analysis', 'hilbert-spaces', 'functional-analysis']"
1016230,Geometric distribution with multiple successes,"Here's the question: ""A sales representative vows to keep knocking on doors until he makes two sales. Given that his probability of success is $u$, let $X$ = the number of doors he knocks on. Find the probability mass function of $X$"" My thought is that $x$ cannot be less than $2$, since he would have to knock on two doors to make two sales. I'm thinking the function would be $\displaystyle\binom{x}{2} (u^2)(1-u)^{x-2}.$ But when I go to find $E(x)$, that doesn't lend itself well to the geometric form I've learned to love. Am I on the right track at least? Thanks for any help.",['probability']
1016234,Need help in figuring out what I am doing wrong when solving for n..,"Here is the expression that I am trying to solve for n: $$ \frac{4}{16+n} = \frac{10}{16+n} \frac{10}{16+n}$$ I am doing the following: \begin{align}
\frac{4}{16+n} & = \frac{100}{(16 + n)^2} \\[8pt]
\frac{4}{16+n} & = \frac{100}{16^2 + 32n + n^2} \\[8pt]
\frac{4}{16+n} & = \frac{100}{256 + 32n + n^2} \\[8pt]
\frac{1}{16+n} & = \frac{100}{4(256 + 32n + n^2)} \\[8pt]
\frac{1}{16+n} & = \frac{20}{256 + 32n + n^2} \\[8pt]
16+n & = \frac{256 + 32n + n^2}{20} \\[8pt]
n & = \frac{256 + 32n + n^2 - 320}{20} \\[8pt]
n & = \frac{-64 + 32n + n^2}{20} \\[8pt]
20n & = -64 + 32n + n^2 \\[8pt]
20n -32n - n^2 & = -64 \\[8pt]
12n - n^2 & = -64 \\[8pt]
n(12 - n) & = -64
\end{align} Not sure what to do next now... Book says that n = 9 
Cannot get 9...
Where am I wrong? Thank you",['algebra-precalculus']
1016252,complex eigenvalues and invariant spaces,"I am currently reading Guillemin and Pollack's Differential Topology , and the following claim is made without proof: Given a linear isomorphism $E: \mathbb{R}^k \to \mathbb{R}^k$, with $k>2$ and such that $E$ can be represented by a matrix with real entries, $E$ has a one- or two-dimensional invariant space . I understand that the Fundamental Theorem of Algebra implies that $E$ has at least one real or complex eigenvalue; if it is real, then $E$ clearly has a one-dimensional fixed space. If it is complex, however, I don't see how there needs to be a two-dimensional invariant space. If $E$ has complex eigenvalue $a+bi$, then $a-bi$ must also be an eigenvalue (as $E$ contains real entries). These eigenvalues correspond to eigenvectors $v_1$ and $v_2$. I assume that the subspace spanned by $v_1$ and $v_2$ is the desired invariant space, but can't figure out how to prove it. Any help would be most appreciated.","['vector-spaces', 'linear-algebra', 'eigenvalues-eigenvectors']"
1016263,How to evaluate this improper integral?,"I got stuck when evaluating these two improper integrals:$$
\int_a^b\frac{dx}{\sqrt{(b-x)(x-a)}}
$$
and$$
\int_0^1\frac{dx}{\sqrt{x-x^3}}
$$
How to evaluate them? Thank you!","['improper-integrals', 'calculus', 'integration']"
1016286,$\{X_n\}$ are iid random variables with symmetric distribution,"Let $X_1,X_2,\ldots,X_n$ be iid random variables with symmetric distribution. Show that
  $$P\left(|X_1+X_2+\cdots+X_n|\ge \max_{1\le i\le n}|X_i|\right)\ge \frac12.$$ I was trying it for $n=2$. Let $I=P(|X+Y|\ge |X| \cap |X+Y| \ge |Y|)$. It is equivalent to
$$1-P(|X+Y|<|X| \cup |X+Y|<|Y|)=1-2P(|X+Y|<|X|)=1-2P(Y^2<-2XY)$$
Now $P(Y^2<-2XY)=P(Y^2<-2XY\mid XY\le 0)P(XY\le 0)=\frac12(P(Y^2<-2XY\mid XY\le 0)$.
But could not proceed further.","['probability-theory', 'probability', 'random-variables']"
1016317,Bounds on derivative of real positive coefficient polynomial satisfying certain properties,"While thinking about this question of Clin, I wanted to consider the polynomial: $P(z) = 1+x_1z+x_2z^2+\cdots+x_nz^n$ , satisfying: (I) $1\geq x_{1}\geq x_2\geq\cdots\geq x_{n}\geq0$ and $\sum\limits_{k=1}^{n}x_{k}=1$ . Then, $P(1) = 2$ and $P$ has no root (real or complex) inside the disc $|z| < 1$ , since, $\displaystyle (1-z)P(z) = 1+(x_1-1)z+(x_2-x_1)z+\cdots+(x_n-x_{n-1})z^n-x_nz^{n+1}$ , Now if $P$ has a root $z_0$ in the region $|z| < 1$ , then, $\displaystyle 1+(x_1-1)z_0+(x_2-x_1)z_0+\cdots+(x_n-x_{n-1})z_0^n - x_nz_0^{n+1} = 0 \implies \begin{align} 1 &\le |x_nz_0^{n+1}|+|(x_1-1)z_0|+|(x_2-x_1)z_0|+\cdots+|(x_n-x_{n-1})z_0^n| \\ &= x_n|z_0^{n+1}| + (1-x_1)|z_0| + \cdots + (x_{n-1}-x_n)|z_0^n| \\ &< x_n + (1-x_1)+\cdots + (x_{n-1}-x_n) = 1\end{align}$ leads to a contradiction! Hence, $P$ (polynomial of degree $n$ ) has no root in the region $|z| < 1$ flatly satisfies the conditions of Erdos-Lax Theorem , which states: $\displaystyle \max\limits_{|z| = 1}|P'(z)| \le \frac{n}{2}\max\limits_{|z| = 1}|P(z)|$ , and equality holds for polynomials of type $P(z) = \alpha+\beta z^n$ , where, $|\alpha| = |\beta|$ . Thus, $\displaystyle \sum\limits_{k=1}^{n} kx_k = P'(1) \le \frac{n}{2}P(1) = n$ . Of course this bound can be improved for $P$ satisfying (I) . Now my questions are: (1) What is the best constant $c_n$ , for polynomials satisfying (I) such that: $$\displaystyle \max\limits_{|z| = 1}|P'(z)| \le c_n\max\limits_{|z| = 1}|P(z)|$$ and (2) Does an upper bound exist for: $\displaystyle \max\limits_{|z| = 1} \lVert P\rVert_2^2 \, |P'(z)|$ and $\displaystyle \max\limits_{|z| = 1} (\lVert P\rVert_2^2-1) \, |P'(z)|$ where, $\lVert P\rVert_2 := \sqrt{1+|x_1|^2+\cdots+|x_n|^2}$ .","['inequality', 'complex-analysis', 'polynomials']"
1016322,What is the correct definition of Area?,"How is the area of a rectangle: length $\times$ breadth? We know that other areas can be derived from it.  Also, the area under curves uses the area of rectangles as a basis.","['geometry', 'rectangles', 'integration', 'area', 'lebesgue-integral']"
1016323,Does $\theta(n)$ = $1/x$ make any sense?,"So, I asked this question on a discrete structures exam today, which I apparently didn't give enough thought to: $f(x) = (5x^2 + 6x + 2)/(x^3 + 4x^2 +x)$ Find the correct theta notation for the function. So, I believe it is easy to create an upper bound around $1/x$ since we can show $f(x) \leq 2/x$ for sufficiently large $x$.  I don't know that a lower bound can exist since $C$ must be positive and would need to be zero for a proper $\Omega(n)$ lower bound. First, am I correct about the non-existence of a tight bound or am I missing something here? Second, is this the only reason this is a Mickey Mouse type question or what else am I missing here?  It seems like it could be possible for a particular algorithm to have a $1/x$ complexity.","['asymptotics', 'discrete-mathematics']"
1016355,"Prove $\langle a^s \rangle=\langle a^t \rangle \iff \gcd(n,s)=\gcd(n,t)$ [duplicate]","This question already has answers here : Prove that $\langle a^n \rangle \bigcap \langle a^k \rangle = \langle a^{lcm (n,k)} \rangle$ (3 answers) Closed 4 years ago . Problem Let $G$ be a cyclic group with $n$ elements and with $a$ as the generator let $b \in G$ and let $b=a^s$ . Then $b$ generates a cyclic subgroup of $H$ of $G$ containing $\dfrac{n}{d}$ elements, where $d=\gcd(n,s)$ . Also show that $\langle a^s \rangle=\langle a^t \rangle \iff \gcd(n,s)=\gcd(n,t)$ I could prove all the remaining parts of the problem but I can't figure out the way to prove the second part of the problem i.e. $\langle a^s \rangle=\langle a^t \rangle \impliedby \gcd(n,s)=\gcd(n,t)$ without using the concept of Isomorphism. The only things that can be used are, Definition of cyclic group The theorem that every cyclic group is abelian. The theorem that every subgroup of a cyclic group is cyclic. Any help will be appreciated.","['cyclic-groups', 'group-theory', 'abstract-algebra', 'gcd-and-lcm']"
1016358,Direction Field and Trajectories,"I am wondering how to draw a direction field and trajectories of a system of linear equations: $$ x'= \left[
  \begin{array}{ c c }
     4 & -2 \\
     8 & -4
  \end{array} \right] x
.$$ I remember how to do them for a equation from the first part of ODE where we would have $$y'=2x-y$$ but I do not really understand how to begin with the system in this form. Would it just be: $$  x'=4x_1 -2x_2 $$ $$ x'=8x_1-4x_2 $$ and we would just plot different values of $x_1$ and $x_2$?","['ordinary-differential-equations', 'systems-of-equations']"
1016370,Number of solutions of an IVP,"$\dfrac{dy}{dx}=60y^{\dfrac{2}{5}}$ ,$x\gt 0$ ,$y(0)=0$ has 1.a unique solution. 2.two solutions. 3.no solution. 4.infinite number of solutions. Here f(x,y)=$60y^{\dfrac{2}{5}}$ does not satisfy Lipschitz's condition, so I can't give any conclusion about the uniqueness of the solution. how can I get all possible solutions?",['ordinary-differential-equations']
1016400,Show that $\frac{1-\cos2 \theta}{\sin2 \theta} = \tan \theta$,"I have to show that the left equation simplifies to $\tan\theta$ : Show that: $$\frac{1-\cos2 \theta}{\sin2 \theta} = \tan \theta$$ I do have prior knowledge that: $$\tan \theta = \frac{\sin\theta}{\cos \theta}$$ But I'm stuck from this point, I have tried a few rules, but none have seemed to work so far.",['trigonometry']
1016467,Mutual or pairwise independence needed? Variance of a sum.,"This is a simple question: Do we need mutual independence or only pairwise independence in order to state that $$\mathrm{Var}\left[\sum_{i=1}^n X_i\right] = \sum_{i=1}^n \mathrm{Var}\left[X_i\right]?$$ As I do not know what uncorrelated means (I know that this is the actual condition), I am not sure whether it is enough for each pair to be independent. Thanks for your help.","['random-variables', 'probability-theory', 'probability-distributions', 'probability', 'covariance']"
1016468,"Prove by induction the predicate (All n, n >= 1, any tree with n vertices has (n-1) edges).","I'm stuck on this problem, posting my progress so far below. I've looked at similar questions here and here , but neither seem to directly prove the predicate by induction, with a base case followed by the inductive step. Solution(?): Let P(n) be the predicate (All n, n >= 1, any tree with n vertices has (n-1) edges). Base case (n=1): P(1): (n=1, any tree with 1 vertice has 0 edges). A tree G is a connected graph with no cycles of length at least three. An edge E is a two-element subset of the set of all vertices V of G . In the base case, V contains one vertice. Thus there are zero two-element subsets of V , or zero edges, in G . Inductive Step: For every n>0, P(n) => P(n+1). For P(n+1), where n>0 in G , n+1 vertices will form exactly n edges. All vertices are of degree 1, which means there is exactly one less edge than vertice (one edge per vertice, excluding the root vertice). Thus, any tree with n vertices will have exactly n-1 edges. Assume P(n) is true. Then, we want to prove that the graph G , for P(n+1), has n edges. G contains no cycles of length at least three. Thus, G must contain only one region, meaning that the edges in G do not form any regions. This means that G must contain at least one leaf (vertex with degree of 1). Obtain a graph G' by removing one leaf from G . Because a leaf is a vertex of 1, by the definition of vertex degree, the leaf is connected to exactly one edge. Thus, removing the leaf will remove one vertex and one edge from G , to create G' . This means that for all n, n>=1, any tree with (n+1) vertices will have ((n+1)-1). or n, edges. We have proven that the case base P(1) is true, and assuming that P(n) is true, we see that the statement remains true for n => n+1. Thus, the predicate (All n, n >= 1, any tree with n vertices has (n-1) edges) is true by induction. Assume P(n) is true. Then, we want to prove that the graph G , for P(n+1), has n edges. G contains no cycles of length at least three. Thus, G must contain only one region, meaning that the edges in G do not form any regions. This means that G must contain at least one leaf (vertex with degree of 1). Remove a leaf l from G to obtain a tree G′ with n vertices. Then, G' has n−1 edges, by the inductive hypothesis. The addition of l to G′ produces a graph with n+1 vertices and n edges, since l has degree 1. P(1) is true, and for every n>0, P(n) => P(n+1). Thus, the predicate must be true. I'm not exactly sure how to proceed for the inductive step., or if I doing it correctly. Any hints, or confirmation that I'm going in the right direction would be greatly appreciated.","['graph-theory', 'induction', 'discrete-mathematics', 'proof-writing']"
1016494,Function for which it is unknown whether it is continuous,"Is there any function $f:\mathbb R\rightarrow \mathbb R$ for which at least some values are known but it is unknown whether $f$ is continuous or not? Edit: I am looking for examples from actual research, not functions explicitly constructed for that purpose.","['functions', 'continuity', 'real-analysis']"
1016504,How to apply Fubini's theorem in proof of Osgood's lemma,"In the proof of Osgood's lemma for seperate holomorphicity, at one step we get that $$f(z)=\frac{1}{(2\pi \iota)^n}\int_{|w_i-\zeta_i|=r_i}\sum_{v_1,v_2,\ldots,v_n}\frac{f(\zeta)z_1^{v_1}\ldots z_n^{v_n}}{\zeta_1^{v_1+1}\ldots \zeta_n^{v_n+1}}d\zeta_1\ldots d\zeta_n,$$  (call the integrand $g$) for $z\in{\triangle (w,r)}.$ After this step i am supposed to change the summation and integration. But i am not able to justify this change.\
MY ATTEMPT: I am taking space $X=\mathbb{C}^n$ with product measure=$\mu$ and $Y=\mathbb{N}^n$ with counting measure=$\nu$. For Fubini's theorem i need to show that $g$ is integrable i product measure $\mu \times \nu.$ Can anyone help me in proving this. Or is there any other method to see this.","['measure-theory', 'several-complex-variables', 'analysis', 'proof-writing', 'complex-analysis']"
1016551,Ideal contained in a finite union of prime ideals,"Let $I \subset R$ be an ideal and $P_i$  $(i=\{1,...,n\})$ prime ideals with $I\subseteq\bigcup_{i=1}^nP_i$. Prove that then $I$ is contained in one $P_i$. I don't know how to show this because I don't have any approach. So I am looking for something to start with or something like a sequence of tips (Since I know this is a large proof) Thanks in advance!","['ideals', 'abstract-algebra']"
1016558,In statistics what does mutually exclusive mean?,For homework a question related to Venn diagrams is 'Are the probabilities of having not used a spinner and not tossed a coin in the game mutually exclusive' Don't know what is meant by it so can't answer it with out your help,['statistics']
1016580,Solving a 2 independent variables (2nd degree) recurrence relation,"Changes to the recurrences and definition are changed! See here: $f(n, 1) = 2n^2 $ and $f (n, k) = 0$ for $k \geq 2n$ and for $k < 0$ and $f(n, 2n-1) = 1$ for all $n$. Question: Is it possible to solve the following recurrence? If so in what manner should I approach it? Conditions Let $f(n,k)$ be the 2-independent-variable function, where $f(n, 0) = 1$, $f(n, 1) = 2 n^2 $ and $f (n, k) = 0$ for $k \geq 2n$ and for $k < 0$ and $f(n, 2n-1) = 1$ for all $n$. All $n, k$ are positive integers. Solve the recurrence (giving either a generating function, hopefully also an explicit formula): $f(n,k) = f(n-1, k) + 2(2n-k) \cdot f(n-1, k-1) + (2n-k+1)(2n-k) \cdot f(n-1, k-2).$ I read the following link on gen. functions and tried to come up with something as follows: Multiplying throughout by $x^k$ and summing the RHS over $k\geq 0$, define the generating function $B_n(x) = \sum_{k\geq0} f(n,k)x^k$, with $n \geq 1, B_0(x) = 0$. Let the notation $[x^k]g(x)$ denote the $k^{\text{th}}$ coefficients of the function $g(x)$. Then if we do the above for the LHS too and equate both sides, we yield: $ B_n(x) = B_{n-1}(x) + \sum_{k\geq0} 2(2n-k) \cdot [x^k](xB_{n-1}(x)) + \sum_{k\geq0} (2n-k+1)(2n-k) \cdot [x^k](x^2 B_{n-1}(x)) $ where the notation $\sum_{k\geq0} 2(2n-k) \cdot [x^k](xB_{n-1}(x))$ means $2(2n-k)$ multiplied by the $k^{th}$ coefficient of the function $(xB_{n-1}(x))$. Notice this simplifies to: $  B_n(x) = B_{n-1}(x) + \sum_{k\geq0} 2(n-k) \cdot [x^{k-1}](B_{n-1}(x)) + \sum_{k\geq0} (n-k+1)(n-k) \cdot [x^{k-2}](B_{n-1}(x)) $ Is the above workings correct/logical? If it is, is there a way to simplify the $\sum_{k\geq0} (2n-k+1)(2n-k)$ expression (which is something multiply by the $k^{th}$ coefficient)? Any other ideas to go about solving this recurrence function? Thanks!","['generating-functions', 'closed-form', 'recurrence-relations', 'functions']"
1016582,Solve for x in tanx-2x=0,"I know homework questions are generally frowned upon here, but I've run into the following equation, which I've tried to solve and am having a genuinely hard time with: $$\tan(x)-2x=0,x\in(-\pi/2, \pi/2)$$ So far I've tried adding $2x$ to both sides and doing some manipulations, but I can't seem to isolate the $x$ (and I'm not even sure if that's what I have to do here). I guess in the worst case scenario I could always just graph $y=\tan(x)$ and $y=2x$ and see where they intersect, but surely there has to be a better way to do it?","['trigonometry', 'algebra-precalculus']"
1016593,What comes before precalculus [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 9 years ago . Improve this question I studied in Europe and followed mostly European academic ways. I'm tutoring a young person , and I will to know what math class comes before pre calculus. Because soon we will be starting some precalculus exercises","['calculus', 'algebra-precalculus']"
1016624,Distributions with finite number of moments,"Is it easy to provide an example of a distribution that has, say, finite moments of order one and two, but such that $\mathbb{E}[X^k]=\infty$ or does not exist for all $k>2$ (where $k$ is not necessarily an integer)? More generally, is there a way to construct a distribution with an arbitrary number of moments, in the sense that $\mathbb{E}[X^k]$ converges for $k \leq b$ and diverges or is non-existent for $k>b$? To emphasize: $b, k$ are real.","['probability-theory', 'probability-distributions']"
1016650,Did Einstein introduce anything new to mathematics? [duplicate],"This question already has an answer here : Did Albert Einstein contribute to math? (1 answer) Closed 9 years ago . Newton introduced calculus, so I am wondering, did Einstein introduce anything important to mathematics?","['notation', 'calculus', 'soft-question']"
1016709,Derivative of an exponential function,"I am trying to solve $$\frac{1}{e^{x}}$$ I first tried using the quotient rule, and ended up with: $$\frac{e^{x}}{(e^{x})^2}$$ That was not the right answer, so I took a look at wolfram, and wolfram rewrites $$\frac{1}{e^{x}}$$ as $$e^{-x}$$ And then apply the chain rule, but that is irrelevant to me right now. I am looking for someone to explain how $$\frac{1}{e^{x}} = e^{-x}$$ Any help would be great, I want to solve this but I need to understand what just happened.","['exponential-function', 'derivatives']"
1016741,Solving ODE $F(t)=A(t)F'(t) $,"How to solve 
  $F(t)=A(t)F'(t) ,F(0)= I\tag 1$ All are $3 \times 3$ matrices except variable t A(t) is given and has determinant $0$.  $A(t)=(I-tC_1)^{-1}t^3C_2 \tag 2$ I is a constant unit  rotation matrix means  I is unity matrix $C_1,C_2$ are constant skew symmetric matrices of  $0$ determinent $$C_1=\left( \begin{array}{ccc} 
   0 & -c_0 & b_0 \\
   c_0 & 0 & -a_0 \\
  -b_0 & a_0 & 0 \\
   \end{array} \right).$$
$$C_2=\left( \begin{array}{ccc} 
   0 & -(c_1-c_0) & (b_1-b_0) \\
   (c_1-c_0) & 0 & -(a_1-a_0) \\
   -(b_1-b_0) & (a_1-a_0) & 0 \\
   \end{array} \right).$$ NB: All entries of the matrices $C_1$, $C_2$ are constants,can't be altered","['ordinary-differential-equations', 'calculus', 'integration', 'matrices', 'linear-algebra']"
1016761,What happens if $|f|$ is constant in the boundary of the image,Let D be a domain and let $f$ be analytic on $D$ and continuous on $\overline{D}$. Suppose $|f|$ is constant on $\overline{D}-D$. So from this can we say that $f$ is constant in $D$? I suppose $f$ is constant but then again I do not know how to prove this. Any help will be appreciated. Thanks EDIT: D here is a bounded domain and f is not 0 anywhere in the domain,['complex-analysis']
1016764,Definition of the hessian as a bilinear functional on the tangent space,"In Milnor's Morse Theory, the Hessian of a smooth function $f : M \to \mathbb R$ defined on a manifold $M$ at a critical point $p$ is the bilinear functional on $T_p M$ defined as follows: $$f_{**}(v, w) = \tilde v_p(\tilde w(f))$$ where $\tilde v, \tilde w$ are vector fields that extend $v$ and $w$.
It is written that $\tilde w(f)$ denotes the directional derivative of $f$ in the direction $\tilde w$ and that $\tilde v_p$ is, of course, $v$. I am assuming that this means $\tilde w(f) = T_p(f)(w)$, but I do not know what it means to write $v(T_p(f)(w))$ it is claimed that $f_{**}$ is symmetric because $$\tilde v_p(\tilde w(f)) - \tilde w_p(\tilde v(f)) = [v, w]_p(f) = 0$$ since $p$ is critical.
If I am not mistaken, the argument used here is that since $p$ is critical, any directional derivative of $f$ at $p$ (e.g. $[v, w]_p(f)$) is zero, but wouldn't that also mean that $\tilde w(f) = \tilde v(f) = 0$? Hopefully, I am only mixing up notations. I would appreciate any comment.","['differential-topology', 'differential-geometry']"
1016789,"""Inverse"" Chain Rule","Green's Theorem, as we know, takes $\frac{\partial Q}{\partial x}$ and $\frac{\partial P}{\partial y}$. However, my functions $P$ and $Q$ aren't easily derived in $x$ and $y$ (actually I'm lazy) but are easily so in $r$ and $\theta$. How can I write those partials in terms of the easier ones? I looked online but didn't find much. It's like an ""inverse"" Chain Rule, since normally the Chain Rule is used to find $\frac{\partial P}{\partial r}$ and $\frac{\partial P}{\partial \theta}$ in terms of $\frac{\partial P}{\partial x}$ and $\frac{\partial P}{\partial y}$, but in this case I want the opposite. MY WORK: I gave it a shot and arrived at the following (note, $t$ is $\theta$): $$\frac{\partial Q}{\partial x}
= \frac{\frac{\partial Q}{\partial r}\frac{\partial y}{\partial t}-\frac{\partial Q}{\partial t}\frac{\partial y}{\partial r}}
{\frac{\partial x}{\partial r}\frac{\partial y}{\partial t}-\frac{\partial x}{\partial t}\frac{\partial y}{\partial r}}$$ This works for me, but is this correct? Can it be simplified further? Also, is this something common? EDIT: the equation above has been confirmed by @CameronBuie's answer; I applied the same thinking for the 3-dimensional case (that is, a scalar field $u(x,y,z)$ with the coordinate change $(x,y,z)=\mathbf r(r,s,t)$ and arrived at this -- I don't intend this to be useful (it's unwieldy) or correct (didn't check, but seems right), but I thought I might store it here: $$\frac{\partial u}{\partial z} =
\frac{
\left(
\frac{\partial x}{\partial t}\frac{\partial u}{\partial t}
-
\frac{\partial x}{\partial s}\frac{\partial u}{\partial r}
\right)
\left(
\frac{\partial x}{\partial r}\frac{\partial y}{\partial s}
-
\frac{\partial x}{\partial s}\frac{\partial y}{\partial r}
\right)
-
\left(
\frac{\partial x}{\partial r}\frac{\partial u}{\partial s}
-
\frac{\partial x}{\partial s}\frac{\partial u}{\partial r}
\right)
\left(
\frac{\partial x}{\partial t}\frac{\partial y}{\partial t}
-
\frac{\partial x}{\partial s}\frac{\partial y}{\partial r}
\right)
}{
\left(
\frac{\partial x}{\partial t}
\frac{\partial z}{\partial t}
-
\frac{\partial x}{\partial s}
\frac{\partial z}{\partial r}
\right)
\left(
\frac{\partial x}{\partial r}
\frac{\partial y}{\partial s}
-
\frac{\partial x}{\partial s}
\frac{\partial y}{\partial r}
\right)
-
\left(
\frac{\partial x}{\partial r}
\frac{\partial z}{\partial s}
-
\frac{\partial x}{\partial s}
\frac{\partial z}{\partial r}
\right)
\left(
\frac{\partial x}{\partial t}
\frac{\partial y}{\partial t}
-
\frac{\partial x}{\partial s}
\frac{\partial y}{\partial r}
\right)
}
$$ $\frac{\partial u}{\partial x}$ and $\frac{\partial u}{\partial y}$ can now be found solving the 2x2 system below (chain rules), or by finding a pattern on the formula above. $$\frac{\partial u}{\partial r}=\frac{\partial u}{\partial x}\frac{\partial x}{\partial r}+\frac{\partial u}{\partial y}\frac{\partial y}{\partial r}+\frac{\partial u}{\partial z}\frac{\partial z}{\partial r}$$
$$\frac{\partial u}{\partial s}=\frac{\partial u}{\partial x}\frac{\partial x}{\partial s}+\frac{\partial u}{\partial y}\frac{\partial y}{\partial s}+\frac{\partial u}{\partial z}\frac{\partial z}{\partial s}$$","['multivariable-calculus', 'partial-derivative']"
1016803,"Prob. 29, Chap. 2, in Baby Rudin, 3rd ed: Every open set in $\mathbb{R}$ is the union of at most countable collection of disjoint open intervals","Here is Prob. 29, Chap. 2, in the book Principles of Mathematical Analysis by  Walter Rudin, 3rd edition: Prove that every open set in $\mathbb{R}^1$ is the union of an at most countable collection of disjoint segments. How to give this proof? My effort: Let $E$ be a non-empty open subset of $\mathbb{R}^1$ , and let $p \in E$ . Then we can find a real number $\delta > 0$ such that $$(\, p-\delta \, , \, p+\delta \, ) \subset E.$$ Now we can find rational numbers $q_1$ , $q_2$ such that $$p-\delta < q_1 < p < q_2 < p+\delta.$$ So we have $$ \left( q_1, q_2 \right) \subset (\, p-\delta \, , \, p+\delta \, ) \subset E.$$ In this way, we can show that $$E = \cup (q_1, q_2),$$ and this union is of course that of a countable collection of segments. Now how to show that these intervals are disjoint? Is this line of reasoning going to lead to our desired conclusion?","['general-topology', 'elementary-set-theory', 'real-analysis', 'analysis', 'metric-spaces']"
1016805,Find $\lim\limits_{x \to \infty} 2x(\sqrt{x-1} - \sqrt{x+5})$,"$\lim\limits_{x \to \infty} 2x(\sqrt{x-1} - \sqrt{x+5})$ For what i've found the part in brackets is an indeterminate form. I've tried to multiply the bracket part by $\frac{\sqrt{x - 1} + \sqrt{x+5}}{\sqrt{x - 1} + \sqrt{x+5}}$ , then multiply the numerator by $2x$. I don't know what to do next.","['calculus', 'functions', 'limits']"
1016839,Bound the norm of the partial trace of an operator on a Hilbert space,"Let $H=H_1 \otimes H_2$ a composite Hilbert space and let $A, B$ bounded linear operators on $H$, and we can assume they are trace class. Let $A_2$ we denote the operator on $H_2$ obtained by taking the partial trace on $H_1$, i.e. $A_2 = \mathrm{tr}_1 (A) \in B(H_2)$. Assume that we know there is some $\varepsilon > 0$ so that $$ ||A-B||_{B(H)} < \varepsilon. $$ Can we deduce a similar bound for $$ ||A_2 - B_2 ||_{B(H_2)} ? $$ Notes :
1) The finite dimensional case $\dim (H_1) = n_1$, $\dim (H_2) = n_2$, $\dim (H) = n$ all finite would be fine (but if you have a hint or source for an answer in the general case I'd appreciate!). 2) (My approach) Choose the Frobenius (or Hilbert-Schmidt) norm, $$ ||A||_{B(H)} = \sqrt{\mathrm{tr}(A^\dagger A)}$$ and let $C=A-B$. We know that $ ||I_1 \otimes C_2 ||_{B(H)} = ||I_1||_{B(H_1)} ||C_2||_{B(H_2)}$ (cf. Reed Simon Vol. 1 page 299), then 
$$
\begin{array}{rcl}
||C_2||_{B(H_2)} &=& \frac{1}{\sqrt{n_1}} ||I_1 \otimes C_2||_{B(H)} \\
&=& \frac{1}{\sqrt{n_1}} ||C - (I_1 \otimes C_2) - C ||_{B(H)} \\
&\leq& \frac{\varepsilon}{\sqrt{n_1}} + \frac{1}{\sqrt{n_1}} ||C - (I_1 \otimes C_2)||_{B(H)} 
\end{array}
$$
and expect to bound the term on the right by $\alpha ||C||_{B(H)}$. To see what is going on I put
$$
C = C^{(1)}_1 \otimes C^{(2)}_1 + C^{(1)}_2 \otimes C^{(2)}_2 
$$
(taking enough terms of these form should be fine to represent an arbitrary $C$). A calculation gives
$$
||C - (I_1 \otimes C_2)||_{B(H)} = ||(C^{(1)}_1 - (\mathrm{tr} C^{(1)}_1) I_1)\otimes C_1^{(2)} + (C^{(1)}_2 - (\mathrm{tr} C^{(1)}_2) I_1)\otimes C_2^{(2)}||_{B(H)}
$$
how close this is to $||C||_{B(H)}$?","['linear-algebra', 'hilbert-spaces', 'functional-analysis']"
1016863,How to prove that $ \lim_{u \downarrow 1} (u-1) \zeta(u) =1 $?,"I would like to prove that $$ \lim_{u \downarrow 1} (u-1) \zeta(u) =1 \quad .$$ However, I am not sure which form of the Riemann-zeta function I ought to pick in order to compute this limit. I guessed I could use Hasse's definition: $$ \zeta(u) = \frac{1}{u-1} \sum_{n=0}^{\infty} \frac{1}{n+1} \sum_{k=0}^{\infty} (-1)^{k} \binom{n}{k}(k+1)^{1-u} \quad , $$ which would lead to $$ \lim_{u \downarrow 1} (u-1) \zeta(u) = \sum_{n=0}^{\infty} \frac{1}{n+1} \sum_{k=0}^{\infty} (-1)^{k} \binom{n}{k}  $$ (right?). But how do I prove this double series is equal to $1$? Or should I use another definition/form of Riemann's zeta function to compute this limit?","['analytic-number-theory', 'sequences-and-series', 'riemann-zeta', 'analysis']"
1016884,Word problem - set up linear equation,"Four friends, Andrew, Bob, Chris and David, all have different heights. The sum of their heights is 670 cm.
Andrew is 8cm taller than Chris and Bob is 4cm shorter than David.
The sum of the heights of the tallest and shortest of the friends is 2cm more than the sum of the heights of the other two.
Find the height of each friend.","['linear-algebra', 'algebra-precalculus']"
1016898,Exercise on Rudin about $R^2$ measurable,"I'm thinking about exercise 9 on Rudin's Real and Complex Analysis chapter 8: $E$ is dense in $\mathbb{R}^1$ and $f$ is a real function on $\mathbb{R}^2$ such that: (a) $f_x$ is Lebesgue measurable for each $x\in E$; (b) $f^y$ is continuous for almost all $y\in \mathbb{R}^1$. Prove that $f$ is $\mathbb{R}^2$ Lebesgue measurable. My idea is to construct a sequence $\{f_n\}_n$ to approach $f$ just like the exercise above, but fail. Who can give some hints for this problem? Any suggestion is appreciated. Thank all of you!","['measure-theory', 'lebesgue-measure', 'real-analysis']"
1016920,Bayesian Shrinkage Factor,"Vasicek(1973), referenced in this paper (See bottom of page 16) explains a method of shrinking individual betas $\beta^{TS}$ toward a cross-sectional mean $\beta^{XS}$ as follows: for each time $t$, the shrinkage $\beta$ for stock $i$ is defined as; $\beta_i^{shrink} = w_i * \beta_i^{TS} + (1 - w_i) * \beta^{XS}$ The shrinkage weight is defined as: $w_i = 1 - \frac{\sigma_{i,TS}^2}{\sigma_{i,TS}^2 + \sigma_{XS}^2}$ where  $\sigma_{i,TS}^2$ is the variance of the individual beta, and where $\sigma^2_{XS}$ is the variance of the cross-sectional variance of betas (dispersion of betas in the cross-section). I would like to extend this methodology as follows: Imagine now I have standard deviation estimates, instead of beta estimates, that I would like to shrink. I have individual standard deviation values $s_i^{TS}$ and a cross-sectional standard deviation value $s^{XS}$ at each time $t$. I would like to do the following: $s^2_{i,shrink} = w_i * s^2_{i, TS} + (1 - w_i) * s^2_{XS}$ How can best define the shrinkage weight $w_i$ in this case? Thanks!","['statistics', 'standard-deviation', 'bayesian']"
