question_id,title,body,tags
1761059,Singular point of $f(z)$ also a singular point of $1/f(z)$ and $f^{2}(z)$,"Suppose $z_{0} \in \mathbb{C}$ is an isolated singular point of the function $f$ of a given type (removable, pole of order $N$, essential). I need to show that $z_{0}$ is an isolated singular point of $g(z) = 1/f(z)$ (here, additionally, assume that $f(z)$ has no zeros in some deleted neighborhood of $z_{0}$). $h(z) = f^{2}(z)$ and find its type in each case. I've been struggling with this problem for a couple of days - I tried using the neighborhood definition of an isolated singular point with $\delta$'s, but that wasn't getting me anywhere. Could somebody please walk me through this problem? I'm extremely confused to the point of tearing my hair out. Maybe just a full solution for 1. and a hint for 2.? Thanks.","['complex-analysis', 'singularity', 'complex-numbers']"
1761068,Is it possible for $R \oplus M$ and $R \oplus N$ to be isomorphic to each other if $M$ and $N$ are not isomorphic?,"Suppose $M$ and $N$ are non-isomorphic $R$-modules (where $R$ is a commutative ring with a unit element).Can we conclude that $R \oplus M \not\simeq  R \oplus N$ ? If not in this most general setup, is there an affirmative answer in some special circumstances ? Motivation : I am reading Proposition 9(1.4) in Dale Husemoller's book 'Fibre Bundles' which reads : If $u,v : \theta^1 \to \xi^k$ are two monomorphisms of the trivial line bundle over $B$ into $\xi^k$ (a k-dimensional vector bundle over $B$) , such that $n \leq ck-2$, then coker $u$ and coker $v$ are isomorphic over $B$. Using the fact that short exact sequences of finite dimensional vector bundles over a paracompact space split,  and replacing vector bundles over $B$ by $R$-modules, I get the question that I am asking here. Essentially I am just trying to see if the theorem about vector bundles can be generalized to an arbitrary abelian category.","['algebraic-topology', 'abstract-algebra', 'fiber-bundles', 'abelian-categories']"
1761130,"finding sup and inf of $\{\frac{n+1}{n}, n\in \mathbb{N}\}$","Please just don't present a proof, see my reasoning below I need to find the sup and inf of this set: $$A = \{\frac{n+1}{n}, n\in \mathbb{N}\} = \{2, \frac{3}{2}, \frac{4}{3}, \frac{5}{4}, \cdots\}$$ Well, we can see that: $$\frac{n+1}{n} = 1+\frac{1}{n} > 1$$ Therefore, $1$ is a lower bound for $A$, however I still need to show that it's the greatest lower bound of $A$. Suppose that $1+\frac{1}{n}>c>1$, then $\frac{1}{n}>c-1\implies \frac{1}{c-1}>n\implies$ c has to be $>1$, which is not a problem :c. Now, for the sup, we have: $$\frac{n+1}{n} = 1+\frac{1}{n}\le 2$$ because if $n>1$ then $\frac{1}{n}<1$ then $1+\frac{1}{n}<1+1=2$. So, $2$ is the upper bound of $A$, but I still have to show that $2$ is the lowest upper bound of $A$. I've read that if $a\in A$ and $a$ is an upper bound, then $a$ is the sup ( how do I prove it? ). But suppose that I didn't knew this theorem, then I would have to prove that there is no $c$ such that $$1+\frac{1}{n}<c<2$$ and such that $c\ge a, \forall a\in A$. Oh, wait, I might have been able to prove the question above: suppose $c\ge A, \forall a\in A$, with $c\in A$. Then if there exists another $b$ such that $c>b\ge a$, i can see that this $b$ is greater than every member of $A$, but not $c$, therefore there isn't such $c$ that is both greater than every member of $A$ and in the middle of $c$ and $a$.","['general-topology', 'real-analysis', 'real-numbers', 'elementary-set-theory']"
1761148,Extension of real analytic function to a complex analytic function,"I just learned that real analytic functions (by real analytic, I mean functions $f: \mathbb{R} \to \mathbb{R}$ which admit a local Taylor series expansion around any point $p \in \mathbb{R}$) cannot be extended to complex entire function always. I believe functions with this extension property are called real entire functions in some books, and a function which is real analytic, but not real entire is $f(x) = \frac{1}{1 + x^2}$. Clearly, with this example, the problem with any extension happens around $\pm i$. See also this MSE post. My question is, do real analytic functions admit extensions to a complex analytic function even locally? That is, given a real analytic function $f : \mathbb{R} \to \mathbb{R}$, can we find a complex analytic function $g : \Omega \to C$, such that $g|_\mathbb{R} = f$, and $\Omega$ contains a strip $\mathbb{R} \times (-\varepsilon, \varepsilon)$ around the real axis?","['complex-analysis', 'real-analysis', 'analytic-functions', 'reference-request']"
1761196,How many divisors does $111...1$ have?,"Let $A=\underbrace{11..1}_{2010}$ . How many divisors does $111...1$ have? Original problem: Prove that $τ(A)>50$ (or $τ(A)<50$ ) My work so far: If $\tau(A) -$ the number of divisors of $A$ and $A=p_1^{\alpha_1}\cdotp_2^{\alpha_2}\cdot...\cdot p_n^{\alpha_n}$ , then $\tau(A)=(\alpha_1+1)(\alpha_2+1)\cdot...\cdot(\alpha_n+1)$ If $a=\underbrace{11..1}_{k}$ and $b=\underbrace{11..1}_{l}$ and $l|k$ then $b|a$ $2010=2\cdot 3\cdot5\cdot67$ . Then $\tau(A)\ge 2^4=16$","['number-theory', 'elementary-number-theory']"
1761198,proof on trace trick,"I wanted to find the maximum likelihood estimator for $\mathbf{\Sigma}$ in the multivariate gaussian. I was anticipating the solution would be a bit involved and messy, if not 'brute-forced', but I was surprised to find an elegant and clever shortcut known as the trace trick. For a vector $\mathbf{x}$ and a matrix $\mathbf{A}$, $\mathbf{x}^T\mathbf{Ax} = tr (\mathbf{x}^T\mathbf{Ax}) = tr (\mathbf{xx}^T\mathbf{A}) = tr (\mathbf{Axx}^T)$. I am not sure how this can be true. Any insight/rough sketch of proof would be great.",['linear-algebra']
1761199,Continuity of functional calculus,"Let $\mathcal{A}$ be an unital C*-Algebra. $a,b$ be normal elements in $\mathcal{A}$. $X\subset \Bbb C$ is a compact subset. $f:X\rightarrow \Bbb C$ is continuous.  I need to show that for all $\epsilon >0$ there exists $\delta>0$ such that $||f(a)-f(b)||<\epsilon$ whenever $||a-b||<\delta$ with $\sigma (a), \sigma (b)\subset X$. I have no clue on how to attack the problem as I know to define $f(a)$ by considering $C^*(a)$. Now that I have to work with both $f(a)$ and $f(b)$ I cannot use gelfand transformation directly. I tried to look at the definition of $f(a)$ and tried to write the map $f:\mathcal{A} \rightarrow \mathcal{A}$ explicitly that is giving all the identifications a name. But it got complicated and I could not work. Can you show me a way?","['c-star-algebras', 'operator-theory', 'functional-analysis', 'spectral-theory', 'operator-algebras']"
1761200,Evaluating $\int_{0}^{3} \sqrt{1+x}\: dx$ using Limit of a Sum approach,Evaluate $\int_{0}^{3} \sqrt{1+x}\: dx$ using Limit of a Sum approach. Using the formula $$\int_{a}^{b} f(x)\:dx=(b-a) \times \lim_{n \to \infty} \frac{1}{n} \times \sum_{k=1}^{n}f\left(a+\frac{(b-a)k}{n}\right)$$ we have $$I=\int_{0}^{3} f(x)\:dx=(3-0) \times \lim_{n \to \infty} \frac{1}{n} \times \sum_{k=1}^{n}f\left(0+\frac{(3-0)k}{n}\right)=3 \lim_{n \to \infty} \frac{1}{n}\sum_{k=1}^{n}f\left(\frac{3k}{n}\right)$$ So $$I=3\lim_{n \to \infty} \frac{1}{n}\sum_{k=1}^{n} \sqrt{1+\frac{3k}{n}}$$ Now if we expand the summation we get limits of the form $$\lim_{n \to \infty} \frac{1}{n}\sqrt{1+\frac{3}{n}}+\lim_{n \to \infty} \frac{1}{n}\sqrt{1+\frac{6}{n}}+\lim_{n \to \infty} \frac{1}{n}\sqrt{1+\frac{9}{n}}+\cdots+\lim_{n \to \infty} \frac{1}{n}\sqrt{1+\frac{3n}{n}}$$ But each limit is clearly zero and hence $I=0$.  I know the answer is wrong but what is my mistake?,"['algebra-precalculus', 'definite-integrals']"
1761245,Showing that this is a martingale.(4.13 in Øksendals SDE),"This is an exercise from Øksendals stochastic differential equations, where I get stuck. It is exercise number 4.13.(I simplified the notation a bit.) I have that X is an Itô-process where: $dX_T=u(\omega,t)dt+dB_t$, $t \in [0,T]$, and I assume u is bounded. I define the Itô-process Z, where: $dZ_t = -u_t dB_t -\frac{1}{2}u_t^2dt$, $Z_0 = 0$ I am supposed to show that $X_te^{Z_t}$ is a
  $\mathcal{F}_t$-martingale, $\mathcal{F}_t$ is the filtration generated by the Brownian
  motion. Using Itô formula for the multidimensional case(I omit all the algebra) I get that: $d(X_te^{Z_t})=[e^{Z_t}(1-X_tu_t)]dB_t$. Hence $X_te^{Z_t}=X_0+\int_0^te^{Z_t}(1-X_tu_t)dB_t$. From the theory of the construction of the Itô process I know that this is a martingale if:
$E[\int_0^t(e^{Z_t}\{1-u_tX_t\})^2dt]<\infty$. But how do I show this? What I am able to get is: $|Z_t| \leq K+ |\int_0^tu_TdB_t|$, so since u is bounded we know that  $|\int_0^tu_tdB_t|\in L_2(\omega \times [0,T])$. So $Z_t \in L_2(\Omega \times [0,T])$. And by the boundedness of u it also follows that $(1-u_tX_t)\in L_2(\Omega \times [0,T])$. But how do I show that $e^{Z_t} \in L_2(\omega \times [0,T])$, and $e^{Z_t}u_tX_t \in L_2(\omega \times [0,T])$? The $L_2$ vector-space isnt closed under multiplication, and we can not just take the exponential and expect to still be there? Any hints?","['stochastic-processes', 'probability-theory', 'stochastic-integrals', 'stochastic-analysis', 'stochastic-calculus']"
1761290,True or False: there is a space $X$ such that $S^1$ is homeomorphic to $X\times X$,"I had an exam this morning, one of the questions asked about the truth of the statement There is a space $X$ such that $S^1$ is homeomorphic to $X\times X$. I said that this was false and this was my reasoning... was I correct? (Note, an earlier part of the question asked me to prove $\pi_1(Y\times Z)=\pi_1(Y)\times\pi_1(Z)$, I took this as a hint.) Suppose for the sake of contradiction that such an $X$ exists. Then $\Bbb{Z}\cong G\times G$ where $G\cong\pi_1(X)$. Let $\Phi$ be the isomorphism. Let $\Phi(1)=(g_1,g_2)\in G\times G$. Then at least one of $g_1,g_2$ is nonzero, since $\Phi(0)=(0,0)$ (the identity on $G\times G$, and $\Phi$ is injective). Without loss of generality $g_1\ne 0$. Then which element $n\in\Bbb{Z}$ has $\Phi(n)=(kg_1,0)$? Since $$kg_1=\underbrace{g_1+\dots +g_1}_k\in G,$$
and $\Phi$ is surjective, such an $n$ should exist. But this is not possible since $\Phi(n)=(kg_1,0)$ implies (since $\Phi$ is a homomorphism) that $kg_1=ng_1$ and $ng_2=0$, and since $k$ was arbitrary and this need not hold if $k\ne 0$.","['algebraic-topology', 'general-topology']"
1761318,A walk on the chessboard with conditions!,"A 16 step path is to go from (-4,-4) to (4,4) with each step increasing in either the x-coordinate or the y-coordinate by 1. How many such paths stay outside or on the boundary of the square $-3<x<3,\ -3<y<3$ at each step? (Background) I am a 12th grader and I know about dots and dashes and Pascal's triangle.","['random-walk', 'combinatorics']"
1761322,Why this set is dense in $C_0(\mathbb{R})$?,"Let $C_0=\{f~|~ f:\mathbb{R}\to\mathbb{R}, \textrm{$f$ is continuous},\lim\limits_{\vert x\vert \to\infty}f(x)=0\}$ $A=\{f~|~f(x)=p(x)e^{-x^2}, \textrm{$p(x)$ is polynomials}\}$ Why $A$ is dense in $C_0$? The topology induced by the supremum metric $d(f,g)=\sup\limits_{x\in\mathbb{R}}|f(x)-g(x)|$.","['general-topology', 'real-analysis', 'functional-analysis']"
1761364,Getting better at proofs,"So, I don't like proofs. To me building a proof feels like constructing a steel trap out of arguments to make true what you're trying to assert. Oftentimes the proof in the book is something that I get if I study, but hard to come up with on my own.  In other words I can't make steel traps, but I feel fine buying them from others. How does one acquire the ability to create steel traps with fluency and ease?  Are there any particular reference books that you found helped you really get how to construct a proof fluently?  Or is it just practice?",['soft-question']
1761366,"Can we apply an Itō formula to find an expression for $f(t,X_t)$, if $f$ is taking values in a Hilbert space?","Let $U$ and $H$ be separable Hilbert spaces $Q\in\mathfrak L(U)$ be nonnegative and symmetric with finite trace $U_0:=Q^{1/2}U$ $(\Omega,\mathcal A,\operatorname P)$ be a probability space $(W_t)_{t\ge 0}$ be a $Q$-Wiener process on $(\Omega,\mathcal A,\operatorname P)$ $X_0$ be a $H$-valued random variable on $(\Omega,\mathcal A,\operatorname P)$ $v:[0,\infty)\times H\to H$ be continuously Fréchet differentiable with respect to the first argument and twice continuously Fréchet differentiable with respect to the second argument $\xi:\Omega\times[0,\infty)\times H\to\operatorname{HS}(U_0,H)$ suitable for the following Assuming that $$X_t=X_0+\int_0^tv_s(X_s)\;{\rm d}s+\int_0^t\xi_s(X_s)\;{\rm d}W_s\;\;\;\text{for }t>0\;,\tag 1$$ I would like to use an Itō-like formula to find an expression for $$Y_t:=v_t(X_t)\;\;\;\text{for }t\ge 0\;.\tag 2$$ However, the Itō formula (see Da Prato, Theorem 4.32 ) for $(1)$ can only be used to find an expression for $f_t(X_t)$, if $f$ is a continuously partially Fréchet differentiable mapping $[0,\infty)\times H\to\color{red}{\mathbb R}$. Since I want to derive a SPDE for $Y$, I'm unsure what I need to do. Maybe we can do the following: Let $(e_n)_{n\in\mathbb N}$ be an orthonormal basis of $H$ and $$v^{(n)}_t(x):=\langle v_t(x),e_n\rangle_H\;\;\;\text{for }n\in\mathbb N\;.$$ Then, each $v^{(n)}$ is continuously partially Fréchet differentiable and we can apply the Itō formula to find an expression for $$Y^{(n)}_t:=v_t^{(n)}(X_t)\;\;\;\text{for }t\ge 0\;.$$ Is this a good idea? We should be able to obtain $(2)$ by $$Y=\sum_{n\in\mathbb N}Y^{(n)}e_n\;.$$ Later, I'm interested in numerically obtaining $Y$. EDIT : By the referenced version of the Itō formula, we obtain \begin{equation}
\begin{split}
\langle v(t,X_t),e_n\rangle_H&=\langle v(0,X_0),e_n\rangle_H+\int_0^t\langle{\rm D}u(s,X_s)(\xi_s(X_s){\rm d}W_s),e_n\rangle_H\\
&+\int_0^t\langle\frac{\partial u}{\partial t}(s,X_s),e_n\rangle_H+\langle{\rm D}u(s,X_s)(u_s(X_s)),e_n\rangle_H\\
&+\frac 12\operatorname{tr}\langle{\rm D}^2u(s,X_s)\left(\tilde\xi_s(X_s)\tilde\xi_s^\ast(X_s)\right),e_n\rangle_H{\rm d}s
\end{split}\tag 3
\end{equation} where $\tilde\xi:=\xi Q^{1/2}$. I've got two questions: Can we write the infinite system of equations $(3)$ as one equation, as it is possible in the case $H=\mathbb R^d$ and $e_n=n\text{-th standard basis vector}$? It seems like that's the case, cause almost all terms are simply projections to the $n$-th basis vector, but I don't know how I need to deal with the trace term. In my real application, I have another known expression for $v(t,X_t)$. Thus, my SPDE would be obtained by equating the SPDE of the question with that other expression. Now the question is: I want to solve that SPDE numerically. Is there any recommended method for such a type of equation? [I should note that I will consider something like $H=[L^2(\mathcal V)]^3$ or $H=[H_0^1(\mathcal V)]^3$ for some bounded domain $\mathcal V\subseteq\mathbb R^3$].","['stochastic-processes', 'partial-differential-equations', 'probability-theory', 'stochastic-analysis', 'numerical-methods']"
1761470,Numerical solution of an ODE system of equations using RK4,"I have given an assignment to find the solution to the ODE system of equations as follow: $$\begin{cases} x_1' = x_1 + x_2 \\ x_2' = -3x_1 -10x_2 + x_2 ^2\end{cases}$$ With initial conditions: $x_1(0) = 1, \quad x_2(0)=10$ on interval $[0,10]$ The above system of questions differs in two aspects from the normal questions of my textbook so I am confused and don't know how to program the algorithm in Matlab: It has two intermingled equations. In contrary to textbook samples which has only one in form of: $x'=f(t,x)$ $x_1'$ and $x_2'$ don't have any $t$ variable! which makes me even more confused. I appreciate it if you elaborate  on the above two points. Thanks. ------------------------------------------Part2----------------------------------------- Ok with above clarifications I started to program in Matlab, after running my code, $x_1(t)$ and $x_2(t)$ seems to change (probably becomes unstable) after changing the step number which changes h respectively. Here is the code: function [sol_x1, sol_x2] = rk4 (m)
    a = 0;      % interval = [a, b] = [0, 10]
    b = 10;
    h = (b-a) / m; % m is  number of steps

    Sx1 = zeros (1,m+1);      % Solutions will be saved here
    Sx2 = zeros (1,m+1);

    Sx1(1) = 1;    % initial values
    Sx2(1) = 10;

    for j = 1:m
        x1 = Sx1(j);
        x2 = Sx2(j);

        fprintf('x1 = %i, x2 = %i \n', x1, x2);

        x1_k1 = h * f1(x1, x2);
        x2_k1 = h * f2(x1, x2);

        x1_k2 = h * f1(x1 + x1_k1/2, x2 + x2_k1/2);
        x2_k2 = h * f2(x1 + x1_k1/2, x2 + x2_k1/2);

        x1_k3 = h * f1(x1 + x1_k2/2, x2 + x2_k2/2);
        x2_k3 = h * f2(x1 + x1_k2/2, x2 + x2_k2/2);

        x1_k4 = h * f1(x1 + x1_k3, x2 + x2_k3);
        x2_k4 = h * f2(x1 + x1_k3, x2 + x2_k3);


        next_x1 = x1 + (x1_k1 + (2 * x1_k2) + (2 * x1_k3) + x1_k4) / 6;
        next_x2 = x2 + (x2_k1 + (2 * x2_k2) + (2 * x2_k3) + x2_k4) / 6;

        % no need for t = t + h because x1 and x2 do not depend on t

        %Save the solutions
        fprintf('%i\n', h);
        %display(h)
        Sx1(j+1) = next_x1;
        Sx2(j+1) = next_x2;
    end    

    sol_x1 = Sx1;
    sol_x2 = Sx2;
end

function [y] = f1 (x1, x2) 
    y = x1 + x2;
end

function [y] = f2 (x1, x2) 
    y = (-3 * x1) + (-10 * x2) + (x2 ^ 2);
end Am I on right path? $x1(t)$ and $x2(t)$ shoots up to very large numbers pretty quickly. I think something is wrong with my algorithm implementation.","['numerical-methods', 'ordinary-differential-equations', 'runge-kutta-methods']"
1761497,How draw a sample of distant points from a set of binary numbers,"I am working on a computer program where I need to sample a set of say $k$ elements from a set of binary numbers ranging from $0$ to $2^n-1$, for some integer $n$. For various reasons, I want the elements of my sample to be as distant from each other as possible, for example in the Hamming sense. When computing such distances, the elements are to be regarded as bit sequences of length $n$. As an example, say that $n=3$. Then our binary numbers are $000, 001, 010, 011, 100, 101, 110, 111$. Suppose we want to make a sample of $k = 3$ elements. In this case, a good sample would be $000, 011, 110$, as the Hamming distance between any pair of elements in the sample is $2$. Is there a way to accomplish this? I am not necessarily looking for the optimal solution, but rather for something which is relatively easy to implement. A random algorithm which produces a sample of expected size $k$ would probably also be fine.","['binary', 'discrete-mathematics']"
1761501,"With the exception of $\mathbb{Z}$, every infinite abelian group contains a subgroup isomorphic to $\mathbb{Z}^2$?","With the exception of $\mathbb{Z}$, every infinite abelian group
  contains a subgroup isomorphic to $\mathbb{Z}^2$. Is this statement true? I don't have much experience working with non-finite groups so any advice would be appreciated, thanks!","['abstract-algebra', 'group-theory']"
1761538,"Suppose $f$ is a mapping between a normed space and a Hilbert space with ONB $(e_n)_n$, what's the second derivative of $\langle f,e_n\rangle$?","Let $E$ be a normed space $(H,\langle\;\cdot\;,\;\cdot\;\rangle)$ be a Hilbert space $f:E\to H$ be Fréchet differentiable $(e_n)_{n\in\mathbb N}$ be an orthonormal basis of $H$ and $$f_n:=\langle f,e_n\rangle\;\;\;\text{for }n\in\mathbb N$$ How can we compute the second Fréchet derivative ${\rm D^2}f_n:E\to\mathfrak L(E,\mathfrak L(E,H))$ of $f_n$?$^1$ Let $$L_n:=\langle\;\cdot\;,e_n\rangle\;\;\;\text{for }n\in\mathbb N\;.$$ Then, since each $L_n$ is an element of $\mathfrak L(H,\mathbb R)$$^1$, $${\rm D}L_n(u)=L_n\;\;\;\text{for all }u\in H\text{ and }n\in\mathbb N$$ and hence $${\rm D}f_n(x)={\rm D}(L_n\circ f)(x)={\rm D}L_n(f(x))\circ{\rm D}f(x)=L_n\circ{\rm D}f(x)=\langle{\rm D}f(x),e_n\rangle$$ by the chain rule, for all $x\in E$ and $n\in\mathbb N$. So, I guess that $${\rm D^2}f_n(x)={\rm D}({\rm D}f_n)(x)={\rm D}(L_n\circ{\rm D}f)(x)={\rm D}L_n({\rm D}f(x))\circ {\rm D^2}f(x)=L_n\circ{\rm D^2}f(x)=\langle{\rm D^2}f(x),e_n\rangle\;,$$ again by the chain rule, for all $x\in E$ and $n\in\mathbb N$. But I'm unsure whether I made a mistake or not. $^1$ Let $\mathfrak L(A,B)$ be the space of bounded, linear operators from $A$ to $B$.","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'derivatives']"
1761554,"Do non-second-countable spaces have ""small"" non-second-countable subspaces?","If $X$ is any space which is not second-countable, can one find a subspace $Y \subseteq X$ with $|Y| \leq \aleph_1$ which is also not second-countable? (Recall that a topological space $X$ is second-countable if it has a countable base.) Note that if we require $|Y| \leq \aleph_0$ there are obvious counterexamples. For example, take $X$ to be the ordinal space $\omega_1$ . Since $X$ has uncountably many isolated points, it is not second-countable, but every countable subspace is second-countable. Looking through the non-second-countable spaces in π-base seems to suggest this is possible, but perhaps the spaces listed there are ""too nice"".",['general-topology']
1761557,"Prove: $\frac{a+c}{b+d}$ lies between $\frac{a}{b}$ and $\frac{c}{d}$ (for positive $a$, $b$, $c$, $d$)","I am looking for proof that, if you take any two different fractions and add the numerators together then the denominators together, the answer will always be a fraction that lies between the two original fractions. Would be grateful for any suggestions!",['algebra-precalculus']
1761575,How do I go about solving this?,"I have tried substitution, but it is not working for me.
$$
\int_0^\pi \frac{dx}{\sqrt{(n^2+1)}+\sin(x)+n\cos(x)}=\int_0^\pi \frac{n dx}{\sqrt{(n^2+1)}+n\sin(x)+\cos(x)}=2
$$ General form of this integral is
$$
\int_0^\pi \frac{dx}{\sqrt{(n^2+m^2)}+m\sin(x)+n\cos(x)}=\frac{2}{m}
$$",['integration']
1761598,Why is a PDE a submanifold (and not just a subset)?,"I struggle a bit with understanding the idea behind the definition of a PDE on a fibred manifold. Let $\pi: E \to M$ be a smooth locally trivial fibre bundle.
In Gromovs words a partial differential relation of order $k$ is a subset of the $k$th jet bundle $J^k(E)$. Usually one defines a  partial differential equation of order $k$ to be a closed submanifold of the $k$th jet bundle $J^k(E)$. This last definition  brings in some kind of regularity condition. I do not really understand why one wants/needs this regularity. What is the advantage of asking a PDE to be a submanifold in lieu of beeing merely a subset of $J^k(E)$? Let me explain a bit further: 
(First, remark that this is somehow a follow up for my earlier question: Why is a differential equation a submanifold of a jet bundle? ) Often a partial differntial relation comes from a differential operator. Let $\rho: H \to M$ be another fibred manifold. A differential operator of order $k$ is a map $D_f: \Gamma_{loc}(\pi) \to \Gamma_{loc}(\rho)$ between local sections, for which there exists a bundle morphism $f: J^k(E) \to H$ such that for every local section $\phi \in \Gamma_{loc}(\pi)$ the equality $D_f (\phi) (p) = f(j^k_p \phi)$ holds for all $p$ in the domain of $\phi$. Now the preimage of a given section $\eta$ of $\rho$ under $f$ is clearly a partial differential relation, but for it to be a partial differntial equation we need to ask $df$ to have constant rank. This previous paragraph is a bit opposed to my naiv interpretation of a PDE in $R^n$ to be an arbitrary equation in the indpendent variable, the funtion itself and it's partial derivatives. Just in the sense of wikipedia: A partial differential equation looks like $F(x_1, \dots, x_n, u(x), \frac{\partial u}{\partial x_1}, \dots ) = 0$ for an arbitrary function $F$ (with image, say, in $R$).
Now, if we are looking for functions $u: R^n \to R^m$ we can set $E = R^n \times R^m$ with $\pi$ beeing the projection on the first factor and $H = R^n \times R$. $F$ is a bundle map, that implicitly also defines a differential operator $D_F$. So in the stricter sense of beeing a submanifold, $F$ defines only a partial differential equation, if it hat constant rank, otherwise it is ""merely"" a partial differential relation. Edit: Example : Why is such a thing as $\frac{\partial u}{\partial x} \frac{\partial u}{\partial y} = 0$ not a pde (in the narrower sense)? In this case $(E, M, \pi) = (R^2 \times R, R^2, pr_2)$ with coordinates $(x_1, x_2, y)$. The first jet bundle $J^1(E)$ has coordinates $(x_1, x_2, y, p_1, p_2)$. The partial differential relation $S = \lbrace (x_1, x_2, y, p_1, p_2) \, | \, p_1 p_2 = 0 \rbrace$ describes the equation I started with and is clearly not a smooth submanifold. Why is this gap between the naiv real analysis point of view and the somewhat more elaboratet differential geometric point of view? Last I'm curious if there is a nice way to see, that a specific relation is in deed a partial differential equation. For example the equality $\Phi^* g = g$ specifying local diffeomorphisms that are isometries with respect to a pseudo-Riemannian metric $g$ is often said to be a partial differential equation, without giving an argument. And in parts I agree: this really feels like a partial differential equation. But to show that it defines in deed a submanifold needs some works, as can be seen in my earlier question Why is $\phi^* g = g$ a PDE for a pseudo-Riemannian metric $g$ on a manifold? , which got a very nice answer. Other examples that are often said to be defined by partial differential equations are locally defined affine maps with respect to an arbitrary connection $\nabla$ in $TM$ or locally defined diffeomorphisms that preserve a given tensor field $T$ or even those affine diffeomorphisms that in addtion preserve a given tensor field. Maybe it would be helpful to see an argument in coordinates in one of this cases, to see how this intuitivly obvious statements can be made rigorous. Edit : To start with the ""coorinate argument"" I asked for in the last paragraph, set $E=M \times M$ and $\pi$ the projection to the first factor and we can restrict ourselfes to the open submanifold of $J^1(E)$, consisting of 1-jets of local diffeomorphisms. Note that for $(x,U)$ a chart arount $p$ and $(y, V)$ a chart arount $f(p)$, a chart arount $j^1_p f$ is given by $\phi_{xy}: j^1_q g \to (x(q), y(g(q)), d(y \circ g \circ x^{-1})_{x(q)}) \in x(U) \times y(V) \times GL(\Bbb R^n)$. Remark, that for $\phi_{xy}(j^1_q g) = (\xi, \eta, A)$ and $\Phi (\mu) := A(\mu) + \eta - A(\xi)$ the function $y^{-1} \circ \Phi \circ x$ (restricted to a suitable subset) is a representative of the equivalence class $j^1_q g$. Now we can pullback the connection $\nabla$ and/or the tensorfield $T$ to give connections/tensor fields $\nabla^x, \nabla^y, T^x, T^y$ on $x(U)$, $y(v)$ via $x^{-1}, y^{-1}$ respectively. The property to preserve the connection/tensor field spells out in coordinates as
\begin{align*}
F(\xi, \eta, A) &= (\Phi^* T^y)_{\xi} - T^x_{\xi} = 0 \\
G(\xi, \eta, A) &= (\Phi^* \nabla^y)_{\xi} - \nabla^x_{\xi} = 0
\end{align*} (The first term of $F$ resp. $G$ depends only on $\eta$ and $A$, whereas the second term depends only on $\xi$.) This can be translatet into equations for the components of $T^x$ and $T^y$ resp. the Christoffel symbols of $\nabla^x, \nabla^y$ with respect to the standard coordniate frame of $\Bbb R^n$. So far so good. But now I need to proove, that the rank of the differentials of $F, G, (F,G)$ respectively is constant for solutions and moreover does neither depend on the choice of chart, nor of the domain/image of the local solution $g$. Any hints, how to do this in any of this cases? Edit 2: As Hubert Goldschmidt points out in his 1967 article Integrability criteria for systems of nonlinear partial differential equations , it suffices that the bundle morphism defining a differential operator has locally constant rank. That means in the above discussion, it suffices to show, that $F$ etc. have constant rank for all pairs of charts $((x,U),(y,V))$. Second he points out, that there are PDEs (necessaryly nonlinear), that can't be written in such a way. But I doubt, that the above examples are of this kind.","['jet-bundles', 'fiber-bundles', 'differential-geometry', 'partial-differential-equations']"
1761628,Linear Algebra with functions,"Basically my question is - How to check for linear independence between functions ?! Let the group $\mathcal{F}(\mathbb{R},\mathbb{R})$
  Be a group of real valued fnctions. i.e $\mathcal{F}(\mathbb{R},\mathbb{R})=\left\{ f:\mathbb{R}\rightarrow\mathbb{R}\right\} $ Let 3 functions $f_{1},f_{2},f_{3}$
  be given such that $\forall x\in\mathbb{R}\,\,\,f_{1}=e^{x},\,\,f_{2}=e^{2x},\,\,f_{3}=e^{3x}$ $W=sp(f_{1},f_{2},f_{3})$
  what is $dim(W)$
 ? How to approach this question ? (from a linear algebra perspective) I know that $\forall x\in\mathbb{R}\,\,\,W=\alpha e^{x}+\beta e^{2x}+\gamma e^{3x}$ And to get the dimension I need to find the base of $W$ so I need to check whether the following holds true : $\forall x\in\mathbb{R}\,\,\alpha e^{x}+\beta e^{2x}+\gamma e^{3x}=0\,\Leftrightarrow\,\alpha,\beta,\gamma=0$ However when $x=0$
  I get $\alpha+\beta+\gamma=0$
  which leads to infinite amount of solutions. How to approach this question ?","['functional-analysis', 'linear-algebra', 'calculus', 'vector-spaces']"
1761637,A question about the definition of $p$-adic pseudo-measure.,"Let $\mathfrak B$ be a profinite abelian group and let $\Lambda(\mathfrak B)$ be defined as the inverse limit $\varprojlim \mathbb Z_p[\mathfrak B/ \mathcal H]$ where the inverse limit is taken with respect to all the open normal subgroups $\mathcal H$ of $\mathfrak B$.
In the book Cyclotomic fields and zeta values , it is said that an element of $\Lambda(\mathfrak B)$ defines a $p$-adic integral measure on $\mathfrak B$. I think it is fairly intuitive why an element of $\Lambda(\mathfrak B)$ should define such a measure, since a measure is basically a way of assigning numbers ($p$-adic in this case) to open subgroups of $\Lambda(\mathfrak B)$ and their cosets in such a way that they are disjoint additive. If the image of an element $\lambda \in \Lambda(\mathfrak B)$ under the projection to $\mathbb Z_p[\mathfrak B/\mathcal H]$ is written as $\sum\limits_{x \in \mathfrak B/\mathcal H} c_{\mathcal H}(x)x$, then we can think of this notation to mean that $\lambda$ assigns the $p$-adic integer $c_{\mathcal H}(x)$ to the coset $x$, and the inverse limit condition gives disjoint additivity. Next, the author defines what is called a $\textit{pseudo-measure}$. An element $\lambda$ in the total ring of fractions of $\Lambda(\mathfrak B)$ (localisation outside all zero-divisors) is said to a pseudo-measure if we have $$(g-1)\lambda \in \Lambda(\mathfrak B)$$ for all $g \in \mathfrak B$. I didn't understand why this definition makes sense or how it is motivated, i.e., how this definition accounts for the pole of the zeta function. Kindly help. Thank you!!","['algebraic-number-theory', 'measure-theory', 'p-adic-number-theory']"
1761647,One-sided limit in topology,Can we define One-sided limit in topology ? I think our space must be order set (Partially ordered set) . is it true?,['general-topology']
1761660,"Value of $a$ such that range contains the interval $[0,1]$","Find the number of integral values of $a$ in the interval $[0,100]$ so that the range of the function $y= \frac{x+a}{x^2-1}$, $x\in R$ contains the interval $[0,1]$? After rearranging  $y= \frac{x+a}{x^2-1}$, we get $yx^2-x-(y+a)$
As $x \in R$, hence
$Discriminant \geq0$ which gives $1+4y(y+a)\geq0$ Could someone hint me as how to proceed from here?","['algebra-precalculus', 'functions', 'quadratics']"
1761719,Converting ratio of cosines to tangent or cotangent,"Given the function: $f : [-\frac{\pi}{2},\frac{\pi}{2}] \to \mathbb{R}$ $f(x) = \frac{\cos{x}}{\cos{(x-a)}}$ for some $a \in \mathbb{R}$ Is it possible to convert it to some kind of translated / otherwise transformed $\tan{x}$ or $\cot{x}$? I have plotted it for some values of $a$ and it looks like the above should be possible but I am at a loss when looking for the actual formula.",['trigonometry']
1761749,"reference for ""wonderful compactification""",I am trying to learn about the wonderful compactification for (adjoint) semi-simple groups. Are there any good references that sketch out the full construction other than here: http://arxiv.org/abs/0801.0456 ? (and the original De Concini Procesi papers) Thank you!,"['algebraic-groups', 'algebraic-geometry']"
1761757,"Linear algebra for modern differential geometry( and other types of modern geometry, like analytic, complex and algebraic)","I wish to study real and complex analysis(for example, Pugh ""Real Mathematical Analysis"" and Cartan ""Elementary theory of analytic functions of one and several complex variables"") and modern differential and riemannian geometry(for example, Jeffrey Lee ""Manifolds and differential geometry""). I would like to chose a book on theoretical linear algebra to cover prerequisites for these. That is, I don't need a linear algebra for applications in science. I don't need it for its own sake or history of mathematics. I want to study modern geometry and analysis - real and complex analysis, analysis on manifolds, differential geometry, riemannian geometry, complex algebraic and analytic geometry. I came across a few books on my search, but I'm not sure if they are the best option for my goals. Axler ""Linear Algebra Done Right"" - this book seems to have a different goal in mind. It avoid determinants as well as works only over $\mathbb{R}$ and $\mathbb{C}$. Do you need linear algebra over an arbitrary field $F$ for study of smooth manifolds? Roman ""Advanced Linear Algebra"". Isn't it an overkill for my goals? What do you think of this book? Any other recommendations will be considered, of course. I would prefer modern books over likes of Hoffman-Kunze or Halmos, but if you know any old gems, feel free to tell.","['complex-geometry', 'reference-request', 'book-recommendation', 'differential-geometry', 'linear-algebra']"
1761769,Number of $\mathbb{F}_q$-rational points on a smooth variety,"From the proof of Weil's conjectures it follows that
$|q^k - \# X(\mathbb{F}_{q^k})| = O(q^{k(n - \frac{1}{2})})$, where
$X$ is a smooth variety over $\mathbb{F}_q$ and $n = \dim X$ (see for example http://www-math.mit.edu/~poonen/papers/Qpoints.pdf ). How the constant in $O(\ldots)$ can be estimated? Every estimation  (even very rough) is interesting.","['finite-fields', 'algebraic-geometry']"
1761801,Proving that the tangent to a convex function is always below the function [duplicate],"This question already has answers here : Tangent line of a convex function (4 answers) Closed 4 years ago . Consider a real-valued convex function $f$ defined on an open interval $(a,b) \subset \mathbb{R}$ . Let $x,y \in (a,b)$ .  I want to prove that \begin{equation}
f((1-\lambda)x + \lambda y) \leq (1-\lambda)f(x) + \lambda f(y) , \lambda \in [0,1]\implies f(y) + f'(y)(x-y) \leq f(x)
\end{equation} No other assumptions (regarding the second derivatives) is allowed. 
While both facts are really obvious and clear, I am unable to prove this without making additional assumptions.","['real-analysis', 'convex-analysis', 'functions']"
1761808,What is known about the space of measure-preserving transformations?,"I started reading about measure-preserving transformations, the ergodic theorems and mixing, but I was also wondering what is known about the space of measure-preserving transformations. The books that I have on ergodic theory (P. Walters, K. Petersen) don't really address that, and I've only seen one reference to the Halmos book, where he supposedly defines a metric on this space. But is this, for example, a Banach space? I would assume it's not, but I'd like to hear more on it and where I could get some information on this.","['ergodic-theory', 'measure-theory', 'transformation']"
1761825,Example of a bounded space which is not totally bounded,"I was trying to find an example of a bounded metric space which is not totally bounded. The only example I could come up whith was the natural numbers with the discrete metric. However, like any other example with the discrete metric, I find this one artificial (not to say disappointing), so I was wondering if there is any non-trivial example of this. (by non-trivial I mean not envolving the discrete metric or, if possible, envolving non discrete sets)","['general-topology', 'metric-spaces']"
1761834,Ricci flow on compact surfaces flows the metric conformally,"The (normalized) Ricci flow on compact surfaces is given by 
$$\frac{\partial}{\partial t}g_{ij}=(r-R)g_{ij}\text{ ,}$$
and in the beginning of Hamilton's paper on the topic he points out that since the rate of change of the metric is, pointwise, a multiple of the metric, the metric is flowed within its conformal class. That is, if the initial metric is $g_0$, the metric at later times would be something like
$$g(t)=\varphi g_0$$
where $\varphi$ is some scalar function. Intuitively, this explanation makes sense, but is there a rigorous way of showing this? For an ODE of the form $f'(x)=h(x)f(x)$ we would expect the answer to be $f_0$ scaled by some exponential. Is the reasoning similar in this case? Since the scalar curvature $R$ depends implicitly on the changing metric $g(t)$, I expect this would complicate things.","['ricci-flow', 'differential-geometry']"
1761843,Can a separable isogeny of elliptic curves have an inseparable dual?,"Let $\phi: E_1\to E_2$ be an isogeny of elliptic curves over a field $K$ of characteristic $p>0$. Suppose that $\phi$ is separable and let $\hat{\phi}: E_2\to E_1$ denote the dual isogeny. Then $\hat{\phi}$ satisfies several nice properties. Two of these that I am interested in are: $\deg\hat{\phi} = \deg\phi$; $\hat\phi\circ\phi = [\deg\phi]$ on $E_1$ and $\phi\circ\hat\phi = [\deg\phi]$ on $E_2$. Note that if $\deg\phi$ is divisible by $p$ then both compositions $\hat\phi\circ\phi$ and $\phi\circ\hat\phi$ are inseparable. But is it possible for $\phi$ to be separable while $\hat\phi$ is inseparable ? Or, by the above remark, can $\phi$ be separable whilst having degree divisible by the characteristic $p$? These properties, plus others in Silverman's book, don't tell me how the inseparability degrees of an isogeny and its dual are related. My intuition (and hope!) is that these two things are impossible, but I am wary of strange counterexamples in characteristic $p$.","['positive-characteristic', 'elliptic-curves', 'algebraic-geometry']"
1761884,Give necessary and sufficient conditions so the sum of random variables converges almost surely,"$\{X_k\}_{k}$ are independent random variables on the probability space $(\Omega, \mathcal F, P)$ and $X_k$ has gamma density $f_k(x)$ where $f_k(x)=\dfrac{x^{a_x-1}e^{-x}}{\Gamma(a_k)}$ where $x,a_k >0$. Give necessary and sufficient conditions so $\sum_{k=1}^{\infty}X_k(\omega) < \infty$ almost surely. I would like some hints on this I'm kind of stuck on this now. Here is what I have so far. Define $X(\omega):=\sum_{k=1}^{\infty}X_k(\omega)$. Since $X_k$ follows a gamma distribution then this means that $P(X_k<0) = 0$ so that $P(X_k \ge 0)=1$ then one sufficient condition would be that for every $\omega \in [X \ge 0],\;\;E(X)=E(\sum_{k=1}^{\infty}X_k)= \sum_{k=1}^{\infty}E(X_k) =\sum_{k=1}^{\infty}a_k  <  \infty$ because that would imply that $P(X=\infty)=0$ but I don't think that this condition is necessary. Also it would be necessary that $X_k(\omega) \rightarrow 0$ as $k \rightarrow \infty$ but that is not sufficient.","['gamma-distribution', 'probability-theory', 'convergence-divergence']"
1761894,"Which properties characterize $\sin, \cos$?","I know a few properties of $\sin$ and $\cos$, for example: $\sin^2+\cos^2=1$ $\sin (a+b) = \sin a\cos b+\cos a\sin b$. $\cos (a+b) = \cos a\cos b-\sin a\sin b$. $\sin (x+\delta) = \sin x$ for some real $\delta$. $\cos (x+\delta) = \cos x$ for the same real $\delta$. Obviously, the list is incomplete. My question is: Which set of properties characterize $\sin$ and $\cos$ (i.e, if $s,s',c,c'$ satisfy the properties, then $s=s', c=c'$) ? I'm looking for a set of such properties that doesn't reference differentiability, continuity, or the number $\pi$. E: I've given up on the requirement of not assuming continuity (although, if someone does get a proof without assuming it, that person will get a nice bounty $:$-$)$ ), however, I still don't want differentiability or $\pi$ in this characterization. Just to be clear, I'm looking for a proof of something like The continuous solutions to $f^2+g^2=1$, $f(a+b)=f(a)g(b)+g(a)f(b)$ and $g(a+b)=g(a)g(b)-f(a)f(b)$ are unique.","['real-analysis', 'trigonometry']"
1761922,Evaluation of $ \int_0^\infty\frac{x^{1/3}\log x}{x^2+1}\ dx $,"The following is an exercisein complex analysis: Use contour integrals with $-\pi/2<\operatorname{arg} z<3\pi/2$ to compute
  $$
I:=\int_0^\infty\frac{x^{1/3}\log x}{x^2+1}\ dx.
$$ I don't see why the branch $-\pi/2<\operatorname{arg} z<3\pi/2$ would work. Let
$$
f(z)=\frac{z^{1/3}\log z}{z^2+1}.
$$
Denote $\Gamma_r={re^{it}:0\leq t\leq \pi}$. One can then consider a contour consisting of $\Gamma_R$, $\Gamma_r$, and $[-R,-r]\cup[r,R]$. The integral along $[r,R]$ will give $I$. But without symmetries, how could one deal with the integral along $[-R,-r]$?","['complex-analysis', 'calculus']"
1761962,Show that $\cot \frac{\pi}{2m}\cot \frac{2\pi}{2m}\cot \frac{3\pi}{2m}...\cot \frac{(m-1)\pi}{2m}=1$,"Prove: $$\cot \frac{\pi}{2m}\cot \frac{2\pi}{2m}\cot \frac{3\pi}{2m}...\cot \frac{(m-1)\pi}{2m}=1$$ This is a roots of unity problem. I managed to show a similar example for $\cos$ by the following: $z^m-1=0$ with roots $1,e^{2\pi /m},...,e^{2(m-1)\pi /m}$ Put the roots into a polynomial with linear factors: $(z-1)(z-e^{2\pi /m})...(e^{2(m-1)\pi /m})=z^m-1$ and divide by $z-1$ to get: $$(z-e^{2\pi /m})...(e^{2(m-1)\pi /m})=1+z+...+z^{m-1}$$ Evaluation at $z=1$ with some complex conjugation (I multiply 2 conjugated equations) yields the result. I'll be happy to expand on my current work if required. Edit: Thought I'd add a similar $\sin$ summation","['complex-analysis', 'roots-of-unity', 'complex-numbers']"
1761966,Can we abuse traffic patterns to get home earlier?,"I had a heated discussion with my co-worker today, and was wondering if someone here could shed some light on this situation. The post is a bit lengthy, but I wanted to put all my intuition down in writing so you all only need to help as minimally as possible. I live in a town called Mathelia, and every day I commute from my workplace at $x=0$ to my house at $x=1$. I've been starting my commute home at $t=0$, and this gets me home at $t=2$, since there's quite a bit of traffic. My friend told me that the traffic lulls down over time, and if I were to leave after $t=0$, I might be able to commute a less amount of time. He's right, in fact, and if I leave at $t=1$, I end up at home at roughly $t=2.5$, saving $0.5$ time from my commute. Theorem: I will never be able to arrive home before $t=2$. Proof: Let's say that I arrive home at some time $t<2$. Then, at some point I would have coincided in position and time with the ""ghost car"" that left exactly at $t=0$. Since the position and time are the same, the time remaining for the rest of the journey must be the same, and thus I must arrive home at $t=2$. My question is this: is it possible to leave at a time $t>0$ and still arrive home at $t=2$? I make the following assumptions. Let's assume we have some traffic function $f(x,t) > 0$ which gives us the traffic $f$ (in miles/hour ; $f$ really tells us the speed we can travel, with high $f$ being low traffic and vice versa) at every point $0 \leq x \leq 1$ and $0 \leq t$. We assume that $f$ is continuous and differentiable everywhere in this region. My first thought was that if we allow $f(x,t) = 0$ for some $x$ and $t$, we could let $f(x,t) = 0$ for $t \leq 1$, and then have the $t > 1$ portion complete continuity and differentiability. This would mean that I would go literally nowhere for the first hour, at which point leaving at $t=1$ would make me coincident with the ""ghost car"" immediately. But since $f(x,t) > 0$, I don't know how to approach this problem. I think there's something weird going on, because if we know that $f(x_1, t_1) = c$, this value of $c$ tells us which ""path"" we take on the surface $f$. If $c$ is large, we then have small increases in $t$ with large increases in $x$; if $c$ is small, we then have small increases in $x$ with large increases in $t$. This makes me feel like the entire system can be described by just one parameter: $t_0$, or when you start the journey. I reason that everything from there should be deterministic: you know $x_0 = 0$ and $t_0$, so you know the initial value of $f$. Depending on $f$, the values for $x$ and $t$ change ($f$ will tell you the local value of $\frac{dx}{dt}$, I think), and you can work out a new value for $f$. So, the question is are there multiple paths that intersect the state $x=1, t=2$? I think there's maybe a system of ODEs I can write, but I don't know how to translate ""given $f$, is there a path where $t_0 > 0 \text{ and } (x = 1, t = 2) \text{ is part of the solution curve}$"" into actual mathematics. This is about when I actually left work for my commute home, and I typed this up. UPDATE After thinking about this some more, I think what I'm modeling looks something like: $$\frac{dx}{dt} = f(x,t), x(t_0)=0$$ As long as we know $f$ and $t_0$, we should be able to find the curve $x(t)$ which gives us our position at any time $t$. Then we need to find $t_f$ such that $x(t_f) = 1$. The question then becomes: can we find multiple $t_0$ such that $t_f = 2$? Maybe someone well-versed can answer if this is ever possible, or how we might choose $f$ such that this is possible. UPDATE #$2$ Let me make my question much more explicit without the background information. I have a function $f(x,t)$ which gives you the speed you're allowed to travel at a position $x$ and a time $t$ ($0 \leq x \leq 1$, $0 \leq t$). We know the following: If you leave at $t = 0$ from $x = 0$, you will arrive at $x = 1$ at $t = 2$. If you leave at $t = \delta$ from $x = 0$, you will never be able to arrive before $t = 2$. The second bullet indicates that there might be some $\delta$ which allows you to arrive exactly at $t = 2$. My question is how, given $f(x,t)$, can we determine whether or not such a $\delta$ exists? Might it be true that for no $f(x,t)$ is this satisfied?","['ordinary-differential-equations', 'mathematical-modeling']"
1762006,"$|f| $ is Lebesgue integrable , does it implies $f$ is also? [duplicate]",This question already has answers here : Proving $f$ is Lebesgue integrable iff $|f|$ is Lebesgue integrable. (2 answers) Closed 8 years ago . If $ f $ is Lebesgue integrable then $|f|$ is Lebesgue integrable but does the converse of the result is also true?,"['lebesgue-integral', 'measure-theory']"
1762009,simple proof for principle of pigeons,I must prove the principle of pigeons but the proofs I find in the internet are too complex. Here's what I can use: Definition $$I_n = \{p\in \mathbb{N}; p\le n\}$$ The principle of the pigeons states that if $m>n$ then there can't exist an injective function $I_n\to I_m$. I've proven before that if there is a bijection from $I_n$ to $I_m$ then $n=m$ but I'm unable to prove it for just an injection. Could you guys help me?,"['pigeonhole-principle', 'algebra-precalculus', 'elementary-set-theory', 'general-topology', 'metric-spaces']"
1762023,"$\mu(X) \lt \infty$. Then $f_k \to f$ in measure iff for any subsequence $k_l$, there is a subsequence $k_{l_n}$ such that $f_{k_{l_n}}\to f$ a.e.","Let $\mu(X) \lt \infty$. Then $f_k \to f$ in measure iff for any subsequence $k_l$, there is a subsequence $k_{l_n}$ such that $f_{k_{l_n}}\to f$ a.e. I can show the only if part by using the theorem that if $f_k \to f$ in measure then there is a subsequence converging to $f$ a.e. However, I can't show the other part. I'm trying to use the finiteness of the measure, but I am out of ideas. How can I show this? I would greatly appreciate any help.","['real-analysis', 'functional-analysis', 'measure-theory', 'convergence-divergence', 'analysis']"
1762024,Commutativity of a ring from idempotents. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question In a ring $R$ with unity, every element can be written as product of finitely many idempotents. Can one show that the ring is commutative?","['abstract-algebra', 'ring-theory', 'idempotents', 'commutative-algebra']"
1762036,Why can't you count up to aleph null?,"Recently I learned about the infinite cardinal $\aleph_0$, and stumbled upon a seeming contradiction. Here are my assumptions based on what I learned: $\aleph_0$ is the cardinality of the natural numbers $\aleph_0$ is larger than all finite numbers, and thus cannot be reached simply by counting up from 1. But then I started wondering: the cardinality of the set $\{1\}$ is $1$, the cardinality of the set $\{1, 2\}$ is $2$, the cardinality of the set $\{1, 2, 3\}$ is 3, and so on. So I drew the conclusion that the cardinality of the set $\{1, 2, \ldots n\}$ is $n$. Based on this conclusion, if the cardinality of the natural numbers is $\aleph_0$, then the set of natural numbers could be denoted as $\{1, 2, \ldots \aleph_0\}$. But such a set implies that $\aleph_0$ can be reached by counting up from $1$, which contradicts my assumption #2 above. This question has been bugging me for a while now... I'm not sure where I've made a mistake in my reasoning or if I have even used the correct mathematical terms/question title/tags to describe it, but I'd sure appreciate your help.","['cardinals', 'elementary-set-theory']"
1762068,Surface integral of function over intersection between plane and unit sphere,"I've been asked to compute the integral of $f(x, y, z)= 1 - x^2 - y^2 - z^2$ over the surface of the plane $x + y + z = t$ cut off by the sphere $x^2 + y^2 + z^2 = 1$ for $t \leq \sqrt3$ and prove it is equal to $\frac{\pi}{18}(3-t^2)^2$. A hint is provided to introduce a new coordinate system $(x_1, y_1, z_1)$ where $z_1$ is normal to the plane and use polar coordinates in the $x_1 y_1$ plane to parametrize the surface as a circle. I started to do this, letting $z_1 = \frac{1}{\sqrt3}(1,1,1)$, choosing $x_1 = \frac{1}{\sqrt2}(1, 0, 1)$ since it is orthogonal to $z_1$, and letting $y_1 = (\frac{-1}{\sqrt6},\sqrt\frac{2}{3}, \frac{-1}{\sqrt6})$ (their cross product). Then I tried to take the surface integral:
$$
\int\int_S{f(x_1,y_1,z_1) dS}=\int\int_S(1-x_1^2-y_1^2-(t-x_1-y_1)^2)dS
$$ Then by the polar parametrization $g(r, \theta)=(r\cos\theta, r\sin\theta, t-r\cos\theta-r\sin\theta)$, this becomes
$$\int_0^{2\pi}{\int_0^1{(1-2r^2-t^2+2rt(\sin\theta+\cos\theta)-2r^2\sin\theta\cos\theta)\sqrt3r}dr}d\theta$$ This integral does not evaluate to anything resembling what I'm supposed to prove it does. Where am I going wrong? I feel it has something to do with switching coordinate systems, but I'm not exactly sure where I've made my mistake.","['surface-integrals', 'multivariable-calculus', 'spheres', 'integration', 'parametrization']"
1762073,Two tower problem,"Suppose that we have two towers of equal height $N$ , each tower consisting of $N$ coins piled on top of each other. Now suppose we have a machine or whatever that takes a coin from one of the towers and move it to the other one. That is, a coin can be moved from tower $A$ to tower $B$ with $50\%$ probability or from $B$ to $A$ with $50\%$ probability. The question is: How many such moves on average will it take before the height of either tower $A$ or tower $B$ i zero? It can be transformed into an equivalent problem, where a machine prints $0$ or $1$ with equal probability and we want to find the average length of the sequence before there are $N$ more $0$ 's than $1$ 's or the other way around. I think I have solved it, though I'm not sure my though process is correct. The solution is: Let $f(n)$ be the average number of steps, where $n$ is the height of the towers. Now, suppose we double the height of each tower and we want to find $f(2n)$ . By definition, the average number of steps required before either tower $A$ or $B$ have height $n$ is $f(n)$ . From here, there is an equal probability that we either go back to the starting position or that the tower becomes empty. So: $$f(2n) = f(n) + 0.5[f(n) + f(2n)] + 0.5f(n)$$ Solving for $f(2n)$ we get: $$f(2n) = 4f(n)$$ Hence, $f(n)$ must take the form $f(n)=cn^2$ , where $c$ is a constant. Since $f(1) = 1 \Rightarrow c=1$ , the solution is: $f(n) = n^2$ .",['probability']
1762074,Evaluation of an integral associated with integral kernel of resolvent of Laplacian,"I came across evaluating the following sort of integral when I was considering the integral kernel for resolvent of Laplacian $(I-\Delta)^{-1}$:
$$
K(x)=\int_0^{\infty}\frac{\exp(-t-\frac{|x|^2}{4t})}{t^{\frac{n}{2}}}dt
$$ However, what I did know is that in the 1-dimensional case, i.e. $n=1$, the operator $(1-\partial_x^2)^{-1}$ has an integral kernel representation of the form:
$$
(1-\partial_x^2)^{-1}f=\int_{-\infty}^{\infty}\frac{1}{2}e^{-|x-y|}f(y)dy
$$
i.e. the integral kernel is$$
K(x)=\frac{1}{2}e^{-|x|}
$$ My question is, how can one evaluate the first integral for the case $n=1$ to obtain exactly the integral kernel in the third equation?","['functional-analysis', 'laplacian', 'integration', 'fourier-analysis']"
1762101,Right Triangle's Proof,"A right triangle has all three sides integer lengths. One side has length 12. What are the possibilities for the lengths of the other two sides? Give a proof to show that you have found all possibilities. EDIT: I figured out that there are a total of 4 combinations for a side with length 12. $$a^2= c^2 -b^2$$ factoring the right side gives $$a^2 = (c+b)(c-b)$$ so from there I just looked for values of c and b which would make the equation true. And I got: $(37,35), (13,5), (15,9), (20,16)$. My only problem now is proving that these are all the possibilities. I have an intuition as to why that's true but I don't know how to go about a full proof. I'm guessing I need to make use of the fact that all sides are to be integer lengths and that $12$ itself cannot be equal to $c$. I know that if I were to try values for values for $b$ and $c$ whose absolute value difference is greater than 8, then the equation would not hold true. Ex: $(37,35)$ has a difference of $2$ and works. $(13,5)$ has a difference of $8$ and works. $(15,9)$ has a difference of $6$ and works. $(20,16)$ has a difference of $4$ and woks. But if I were to pick any pair with an absolute difference greater than 8 it would not work. Can I just prove this is true with a couple of examples? Or do I need a full generic proof ? If so, how would I go about it?",['geometry']
1762147,Why do we study real numbers?,"I apologize if this is a somewhat naive question, but is there any particular reason mathematicians disproportionately study the field $\mathbb{R}$ and its subsets (as opposed to any other algebraic structure)? Is this because $\mathbb{R}$ is ""objectively"" more interesting in that studying it allows one to gain deep insights into mathematics, or is it sort of ""arbitrary"" in the sense that we are inclined to study $\mathbb{R}$ due to historical reasons, real-world applications and because human beings have a strong natural intuition of real numbers? Edit: Note that I am not asking why $\mathbb{Q}$ is insufficient as a number system; this has been asked and answered on this site and elsewhere. Rather, why, in a more deep sense, are $\mathbb{N} \subset \mathbb{Z} \subset \mathbb{Q} \subset \mathbb{R}$ so crucial to mathematics? Would we be able to construct a meaningful study of mathematics with absolutely no reference to these sets, or are they fundamentally imperative?","['real-analysis', 'soft-question']"
1762184,Solution of functional equation $f(x+y)=f(x)+f(y)+y\sqrt{f(x)}$,"If $x,y\in \mathbb{R}$ and $f(x+y)=f(x)+f(y)+y\sqrt{f(x)}$ and $f'(0)=0\;,$ Then $f(x)$ is $\bf{My\; Try::}$ Using $$f'(x) = \lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h} = \lim_{h\rightarrow 0}\frac{f(x)+f(h)+h\sqrt{f(x)}-f(x)}{h}$$ Now Put $x=y=0$ in  $$f(x+y)=f(x)+f(y)+y\sqrt{f(x)}\;,$$ We get $f(0)=0$ So we get $f(0)=0$ So $$f'(x) = \sqrt{f(x)}+\lim_{h\rightarrow 0}\frac{f(h)}{h}=\sqrt{f(x)}$$ So $$\int\frac{f'(x)}{\sqrt{f(x)}}dx = 1\int dx\Rightarrow 2\sqrt{f(x)}=x+c$$ Now Put $x=\;,$ We get $c=0$ So we get $2\sqrt{f(x)}=x\Rightarrow 4f(x)=x^2\Rightarrow \displaystyle f(x)=\frac{x^2}{4}$ Can we solve it some short way, If yes then please explain here, Thanks","['calculus', 'functional-equations']"
1762213,Is there a fundamental theorem of algebra for matrices?,"The fundamental theorem of algebra says we can do this ($z\in\mathbb{C}$ of course) $$\sum_{k=0}^n a_kz^k= a_n\prod_{k=1}^n (z-\omega_k)=0$$ for some set $\{\omega_k \in\mathbb{C}\}_{k=1,2,\ldots , n}$. Is there a similar answer for square matrices with complex entries (i.e. for linear operators $A_k:\mathbb{C}^n \to\mathbb{C}^n,\,\,(k=0,1,2,\ldots, n))$? That is, can we do such a factorization $$\sum_{k=0}^n A_kz^k= A_n\prod_{k=1}^n (z\mathbb{1}-\Omega_k)=0$$ where $\mathbb{1}$ is the identity operator and $\Omega_k : \mathbb{C}^n\to\mathbb{C}^n$ are linear operators? Certainly we're restricted here by the non-commutativity of matrices in general, so the order of this decomposition would matter. But, maybe there are some types of matrices that admit commutative ""root"" matrices? Sorry if my notation is awkward, and also if the answer to this is considered common knowledge.","['abstract-algebra', 'linear-algebra']"
1762225,How many times $n$ must you play a game in which you have a $1/N$ chance of winning to have a better than 50% chance of winning at least once,"I am having difficulty approaching the above problem, and would like a hint. I tried doing an inclusion exclusion argument: Let $A_{i}$ be winning the game on the i'th try, then by inclusion exclusion we have, for winning at least 1 game in n tries:
$$P\left(\bigcup_{i=1}^{n}A_i\right)=\frac{n}{N}-{n\choose 2}\frac{1}{N^2}+{n\choose 3}\frac{1}{N^2}+.....\pm \frac{1}{N^{n}}
$$
unless I am missing something, I don't see how I could evaluate numerically the probability without knowing the value of $N$
edit: We have spent a fair amount of time on stirling's formula, so maybe this would be a way to at least make sense of the choose function portion?",['probability']
1762229,Proving Fatou type lemma,"Let $f_1, f_2, \cdots$ and $f$ be nonnegative lebesgue integrable functions on $\mathbb{R}$ such that $$\lim_{n \to \infty}\int_{-\infty}^y f_n(x)dx = \int_{-\infty}^y f(x)dx   \; \; \text{ for each $y \in \mathbb{R}$}$$ and $$\lim_{n \to \infty}\int_{-\infty}^{\infty} f_n(x)dx = \int_{-\infty}^{\infty} f(x)dx $$ Then I want to prove that $ \liminf_{n \to \infty} \int_{U}f_n(x)dx  \geq \int_{U}f(x)dx\:$ for any open set $U$ of $\mathbb{R}.$ I think this can done by proving $\lim_{n \to \infty}f_n(x) = f(x) $ and then using Fatou's lemma. But I am not able to prove $\lim_{n \to \infty}f_n(x) = f(x) $ . Thank you in advance.","['lebesgue-measure', 'integration', 'lebesgue-integral', 'measure-theory']"
1762239,"$\lim x_n = a$, $\lim \frac{x_n}{y_n}=b$ then $\lim y_n = \frac{a}{b}$","I must prove: $\lim x_n = a$, $\lim \frac{x_n}{y_n}=b$ then $\lim y_n = \frac{a}{b}$ Well, I know that $$\lim x_n = a \implies |x_n-a|<\epsilon$$ $$\lim \frac{x_n}{y_n} = b \implies |\frac{x_n}{y_n}-b|<\epsilon$$ I need to use these inequalities to somehow arrive at: $$|y_n-\frac{a}{b}|<\epsilon_0$$ But I cannot see any obvious algebraic relation between those absolute values. ANy helps?","['algebra-precalculus', 'sequences-and-series', 'calculus', 'limits']"
1762262,"What exactly is an ""analytic function""?","This is for real analysis so I'm not worried about complex analytic functions. The definition in my book just says: ""A function f(x) which is represented by a power series with a positive radius of convergence is said to be 'real analytic at the origin', or simply 'analytic'."" To me it seems like this definition ends prematurely. Like when I was reading it I expected there to be an ""if"" and then a list of qualifications. I guess I just don't really understand the rationale behind creating this definition in the first place. What would even be the point of representing a function by a power series that didn't have a positive radius of convergence? If the power series doesn't converge for any values of x, it's not really representative of anything , right? I feel like this is actually obvious and I'm just overthinking it, but is this definition literally just giving a name to functions that can be represented as power series that actually converge for x values in some radius? There was an exercise earlier in the chapter before analytic functions were defined that asked us to find an infinite power series which represented a function; was that function analytic as well? Thanks in advance and sorry if this is a silly question.",['real-analysis']
1762268,Function is continuous if graph is compact.,"Let $X$ be a Hausdorff space and let $f:X\to \mathbb{R}$. If grapph of $f$ is compact we have to show that $f$ is continuous. Since every closed subset of a Hausdorff space is closed, therefore grapph of $f$  is closed. WE know that if $f:X\to Y$ and $Y$ is compact, then graph of $f$ is clsed implies $f$ is continuous. But here $\mathbb R$ is not compact. Please help!","['continuity', 'general-topology', 'compactness']"
1762274,How to solve for the expectation of the Ito Integral: $\int_0^4 B_t^2 dB_t$?,"I would like to find the expectation of the Ito Integral: $\int_0^4 B_t^2 dB_t$. My strategy is to use Ito's general formula with: $$
f(t, B_t) = f(0,0) + \int_0^t \frac{df}{dx}(s, B_s) dB_s + \int_0^t \frac{df}{dt}(s, B_s) ds + \frac{1}{2}\int_0^t \frac{d^2f}{dx^2}(s, B_s) ds
$$ Then, my candidate function is $f(t, B_t) = \frac{B_t^3}{3}$. However, the problem I am having is in the derivative $\frac{df}{dt}(s, B_s)$. Since I want to have my integration go up to $4$, then I necessarily have: $$
\int_0^4 \frac{df}{d4}(s, B_s) ds = \int_0^4 \frac{\frac{B_t^3}{3}}{d4} ds
$$ I know that there is probably a bad/stupid mistake here, and that I should just take the derivative with respect to $s$, but I cannot figure out why exactly we are having the $dt$ MATCH the upper limit of the integral, $t$. Can anyone shed some light here? Thanks!","['stochastic-processes', 'probability-theory', 'stochastic-calculus', 'stochastic-integrals']"
1762278,Prove that the product of two invertible matrices also invertible,"I am working on a homework problem, but I am lacking some understanding. 
Here is the problem: Let $A$ and $B$ be invertible $n \times n$ matrices with $\det(A) = 3$ and $\det(B) = 4$. I know that the product matrix of two invertible matrices must be invertible as well, but I am not sure how to prove that. I am trying to show it through the product of determinants if possible.","['matrices', 'linear-algebra', 'determinant']"
1762319,How do I prove that $\lim_{z\to i} z^2=-1$?,"How do I prove the following limit using the limit definition? $$\lim_{z\to i} z^2=-1$$
Using the limit definition
  $$|z^2+1|<\epsilon, \;\text{whenever} 0<|z-i|<\delta$$
so I factor out to get that 
  $$|z^2+1|=|z+i||z-i|<\epsilon$$
 which means that if I am able to bound 
  $$|z+i|<K \tag{1}$$
then I can say that 
  $$|z-i||z+i|<K|z-i|<\epsilon \tag{2}$$
 and from there I could proceed to proving the limit, the only problem is that I do not know how to go from $(1)$ to $(2)$ using complex numbers. How could I prove this limit?","['complex-analysis', 'limits']"
1762337,Proof of an inequality in $\mathbb{C}$,"Let $z\in \mathbb{C}, n \geq 2$. Show this complex inequality
$$|z^n-1|^2\le |z-1|^2\left(1+|z|^2+\dfrac{2}{n-1}\Re{(z)}\right)^{n-1}$$ For $n=2$ the inequality is easy to prove: 
$$|z^2-1|^2\le |z-1|^2\left(1+|z|^2+2\Re{(z)}\right)$$
$$\Longleftrightarrow |z+1|^2\le 1+|z|^2+2\Re{(z)}$$
$$\Longleftrightarrow z+\overline{z}\le 2\Re{(z)}$$
which is in fact an equality, thus is exact. for $n=3$.
$$\Longleftrightarrow |z^2+z+1|^2\le (1+|z|^2+\Re{(z)})^2$$
$$\Longleftrightarrow(z^2+z+1)(\overline {z^2}+\overline{z}+1)\le |z|^4+2|z|^2+1+\Re^2{z}+2\Re{(z)}+2|z|^2\cdot\Re{(z)}$$
$$\Longleftrightarrow |z|^4+|z|^2+|z|^2(z+\overline{z})+1+(z+\overline{z})+(z^2+(\overline{z})^2)\le |z|^4+2|z|^2+1+\Re^2{z}+2\Re{(z)}+2|z|^2\cdot\Re{(z)}$$
$$\Longleftrightarrow |z|^2+(\Re{(z)})^2\ge z^2+(\overline{z})^2=(z+\overline{z})^2-2|z|^2$$
$$\Longleftrightarrow 3|z|^2\ge 3(\Re{(z)})^2$$
It is clear Is it true for a general $n$?","['complex-analysis', 'inequality']"
1762401,Does rationality of $\cosh(nx)$ and $\cosh((n+1)x)$ imply rationality of $\cosh(x)$?,"Suppose that $x\in\mathbb{R}^+$ and $n\in \mathbb{N}$. If $\cosh(nx)$ and $\cosh((n+1)x)$ are rational, can we show that $\cosh(x)$ is rational too? I guess the following equalities should be useful: $$\begin{eqnarray}
\cosh(x) &=& \cosh((n+1)x−xn)\\
&=& \cosh((n+1)n).\cosh(nx) − \sinh((n+1)x).\sinh(nx)\\
&=& \cosh((n+1)n).\cosh(nx) − \sqrt{\cosh^2((n+1)x) − 1}.\sqrt{\cosh^2(nx) − 1}.
\end{eqnarray}$$","['trigonometry', 'calculus', 'elementary-number-theory']"
1762404,"A possible norm on a subspace of $C^\infty([0,1])$?","My question is related to this one : Take the vector space of infinitely differentiable functions on $[0,1]$. The standard norm of $C^k([0,1])$ is just the $\ell^1$-norm of the vector $(\|f\|_\infty, \|f'\|_\infty,\ldots,\|f^{(k)}\|_\infty)$, but of course this idea cannot be further pursued to define a norm on $C^\infty([0,1])$. However, what if one would consider the space
$$
\{f\in C^\infty([0,1]):(\|f^{(n)}\|_\infty)_{n\in\mathbb N}\in \ell^p \}
$$
for $p\in [1,\infty]$? This space is certainly small - in particular, it contains neither the exponential function, nor $\sin$ and $\cos$ - but at least it does contain the polynomials and it seems to be a Banach space - in fact even a Banach lattice algebra. Does this space appear in applications (PDEs?)? Has anybody ever studied its functional analytical properties and if this is not the case, what are this space's obvious drawbacks?","['functional-analysis', 'real-analysis', 'banach-spaces']"
1762433,Should a metric always map into $\mathbf{R}$?,"Typically you see the definition of a metric as a function which maps $X\times X\to\mathbf{R},$ but does this always have to be the case? Motivating example: When you complete $\mathbf{Q}$ with the Archimedean metric you think of it as mapping into $\mathbf{R},$ but if you were to choose the $p$-adic metric instead it can only take values in $\{0\}\cup p^\mathbf{Z}$. These are elements of $\mathbf{Q}_p$ as well as $\mathbf{R}.$ The difference is then that either your metric maps into an ordered field or one where you can't define any ordering (but you still know that the distances can have different values). Does not mapping a metric into $\mathbf{R}$ always lead to problems? And are the issues of the example above avoidable?","['metric-spaces', 'analysis']"
1762435,How to evaluate $\int_0^\infty \frac{e^{-x}+x-1}{x(e^{2x}-e^{-2x})}dx$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question We are unable to verify this this equality $$
4\int\limits_0^\infty \frac{e^{-x}+x-1}{x\left(e^{2x}-e^{-2x}\right)}\;\mathrm{d}x=\gamma+\ln\frac{16\pi^2}{\Gamma^4\left(\frac{1}{4}\right)}\;.
$$ where $\gamma$ is Euler's constant which is approximately $0.5772156\dots$, and $\Gamma(n)$ is the gamma function and the particular value for $\Gamma\left(\frac{1}{4}\right)=3.625690\dots$.","['integration', 'definite-integrals', 'calculus']"
1762444,Sum over fourth power of the sine,"I am considering the sum
$$
A_m = \sum_{j=0}^m \sin^4\left(\frac{j}{m}\cdot\frac{\pi}{2}\right).
$$
I think that for $m>1$ it holds
$$
A_m = \frac{3m+4}{8},
$$
but I can't really get to it.","['summation', 'trigonometry']"
1762456,Construction using a straight edge only,"Given a circle, its diameter and a point on the circle, find a procedure to construct a line perpendicular to the diameter using only a straight edge. The perpendicular must pass through the given point. I can do this if another point outside the circle is given, but my question is the degenerate case when that point lies on the circle. Any help will be appreciated. Thanks.","['circles', 'geometric-construction', 'geometry']"
1762501,Monotone sequence of orthogonal projections on a complex Hilbert space,"Suppose $P_n$ is a monotone sequence of orthogonal projections on a complex Hilbert space $\mathcal{H}$, i.e. $V_n= Im(P_n)$ is a decreasing or increasing sequence of subspaces and $P_n^\star=P_n$ and $P_n^2=P_n$ for all $n$. I want to prove that the sequence $\Vert P_n z \Vert$ is monotone for all $z\in \mathcal{H}$, but I can't quite see where to start. Somehow the $V_n$ being monotone should play into it, but I can't see how, since I can't find any obvious relations between elements of $V_n$ and $V_{n+1}$.","['functional-analysis', 'spectral-theory', 'hilbert-spaces']"
1762537,Why is the determinant of the 0x0 matrix equal 1? [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question I don't understand why the determinant of the 0x0 matrix equals 1.,"['matrices', 'determinant']"
1762538,Time-and-Work and Motorcycle Tyres,"A problem about motorcycle tyres, related to Time-and-Work or rate-of-work methods. This is not a homework question, nor, as far as I know, a contest question. It is intended as a challenge for Year 10/11 or 15/16-year olds, but should require no knowledge of calculus. Readers will no doubt be familiar with the type of rate-of-work problem, often seen at elementary school, which goes like this: Alice can paint an $X$ metre-long fence in $A$ hours if she works on her own. Bob can paint the same fence in $B$ hours if he works on his own. If they work together, starting at opposite ends, how long will it take them to paint the fence? Solution : Every hour Alice will paint $\frac{X}{A}$ metres of fencing, and likewise Bob will paint $\frac{X}{B}$ metres. Together, without interference, they will paint $\frac{X}{A}+\frac{X}{B}$ metres and therefore the hours they take complete the job is $$\frac{X}{\frac{X}{A}+\frac{X}{B}}=\frac{1}{\frac{1}{A}+\frac{1}{B}}=\frac{AB}{A+B}$$ So far so good. But the following three-part question is not quite so obvious. QUESTION : A motorcycle’s wheels wear out tyres at constant, but different, rates. A tyre fitted to the front wheel will wear out after $F$ miles, and a tyre fitted to the back wheel will wear out after $B$ miles. a)  By swapping the tyres between front and back wheels, what is the maximum distance the owner can travel on just two tyres? When should she swap the tyres? b)  What is the maximum distance she can travel if she also has a spare tyre? When should she swap the tyres around? c)  The owner decides to fit a side-car to her motorcycle, and a tyre fitted to the side-car will wear out after $S$ miles. What is the maximum distance she can travel on the three tyres? When should she swap the tyres around? We assume, no doubt, that all the tyres are identical and all are brand new to start with, and that all tyres will be worn out by the time she has driven the maximum distance. In part a) we assume that the tyres are swapped just once, and that there will be two change-overs in parts b) and c). My Approach a)  Let the maximum distance be $D$ and let the distance travelled to the swap-over time be $x$. Let $r$ be the depth of rubber on each tyre, measured in mm.
For each mile travelled, the back wheel loses $\frac{r}{B}$ mm of rubber. Therefore in travelling a distance $x$, the loss of rubber on this tyre is $\frac{rx}{B}$.
At the point of swap-over, the remaining rubber on this tyre is $r-\frac{rx}{B}$ and this tyre will be fitted to the front wheel to travel the remaining distance $D-x$.
When fitted to the front wheel, the loss of rubber for every mile is $$\frac{r}{F}=\frac{r-\frac{rx}{B}}{D-x}.$$ Rearranging this equation gives $$x=\frac{B(D-F)}{B-F}.$$ Since $x>0$, we have that either $B<D<F$ or $F<D<B$, which makes sense since we would expect the maximum journey to be less than $\max(B,F)$. We can now write down the equivalent expression if we consider the front tyre in exactly the same way, and then equate the different expressions for $x.$ Thus we have: $$\frac{B(D-F)}{B-F}=\frac{F(D-B)}{F-B}.$$ We can rearrange this and get an uncannily familiar-looking expression: $$D=\frac{2}{\frac{1}{F}+\frac{1}{B}}$$ When this is substituted back to get $x$, we get: $$x=\frac {1}{\frac{1}{F}+\frac{1}{B}}$$ Obviously this is exactly the same type of expression obtained in the Alice & Bob rate-of-work problem. And this is what suggests to me that there must be an easier and more intuitive method to obtain the result. Furthermore I don’t think it would be easy to apply my method to parts b) and c), so there must be an easier way. Can anyone give me a hint? I think I’m missing something obvious.","['algebra-precalculus', 'recreational-mathematics', 'word-problem', 'puzzle']"
1762559,"Regularity, Dirichlet form","I have a question about Dirichlet form. Let $\Omega$ be an Euclidean domain of $\mathbb{R}^{N}$ and 
$X=\bar{\Omega}$. The measure $m$ on the Borel 
$\sigma$ algebra $\mathcal{B}(X)$ is given by $m(A)=\lambda(A \cap \Omega)$ for all $A \in \mathcal{B}(X)$ with $\lambda $ the Lebesgue measure. It follows that $L^{2}(\Omega)=L^{2}(X,\mathcal{B}(X),m)$. We define a Dirichlet form on $L^{2}(\Omega)$ by 
\begin{equation*}
\mathcal{E}(f,g)=\int_{\Omega}\left(\nabla f,\nabla g \right)\,dx,\quad f,g \in \widetilde{H}^{1}(\Omega),
\end{equation*}
where $\widetilde{H}^{1}(\Omega)=\text{closure of }H^{1}(\Omega)\cap C_{c}(\bar{\Omega}) \text{ in } H^{1}(\Omega)$. $C_{c}(\bar{\Omega})$ denotes all continuous reak valued function on $\bar{\Omega}$ with support and $H^{1}(\Omega) \cap C_{c}(\bar{\Omega})=\left\{ f \left| \right._{\Omega} \in H^{1}(\Omega) : f \in C_{c}(\bar{\Omega}) \right\}$. Question I want to check the following assertion: \begin{align*}
&(1) \quad \widetilde{H}^{1}(\Omega) \cap C_{c}(\bar{\Omega}) \text{ is dense in } C_{c}(\bar{\Omega}) \text{ w.r.t. sup norm}.
\end{align*} My attempt (1): It is enough to show that for all $ f \in C_{c}(\bar{\Omega})$, $\epsilon>0$, there exists $g \in H_{1}(\Omega) \cap C_{c}(\bar{\Omega})$ such that $\|f-g\|<\epsilon$, where $\|\cdot\|$ is sup norm. Take $f \in C_{c}(\bar{\Omega})$. By Tietze extension theorem, we can find $F \in C_{c}(\mathbb{R}^{n})$ such that $F=f$ on $\bar{\Omega}$. Define $F_{\delta}=\int_{\mathbb{R}^{n}}j_{\delta}(x-y)F(y)\,dy$, where $j_{\delta}$ is standard mollifier. Then $F_{\delta } \to f$ uniformly on $\text{supp} [f]$ and $F_{\delta} \in C_{c}^{\infty}(\mathbb{R}^{n})$. But I don't know how to prove $F_{\delta} \left|_{\Omega} \right. \in H_{1}(\Omega) \cap C_{c}(\bar{\Omega})$. Please tell me how to prove (2). Thank you in advance.","['functional-analysis', 'real-analysis', 'stochastic-calculus']"
1762563,If $A$ is normal and upper triangular then it is diagonal,"Let $A$ be a normal matrix in Mat$_{n\times n}(\mathbb C)$, if $A$ is upper triangular then it is diagonal (Normal means $AA^*=A^*A$, where $A^*$ is the conjugate transpose of $A$) If I consider the diagonal of $AA^*$,  let denote $(a_{ij})=A$ and $(â_{ij})_{i,j}=AA^*$ then, since $AA^*=A^*A$ $â_{ii}=\sum\limits_{k=1}^na_{ik}\overline{a}_{ik}=\sum\limits_{k=1}^n\overline{a_{ki}}{a}_{ki}$ $\implies\sum\limits_{k=1}^n|a_{ik}|^2=\sum\limits_{k=1}^n|a_{ki}|^2$. If I take $i=n$ then it follows that $a_{in}=0, \forall 1\le i\le n-1$ and continuing in this manner the upper diagonal entries are zero, Is this correct ? Can I show it in another way, because in a previous exercise I had to show that ''If A is normal and nilpotent then $A=0$'' so using this can I decompose $A$ into diagonal and nilpotent matrix, then show that the nilpotent part is zero ?","['matrices', 'linear-algebra']"
1762594,Functions with rational image of algebraic elements,"Does there exist a non constant continuous fonction $f:\mathbb{R}\rightarrow\mathbb{R}$ such that for any real algebraic number $x$, $f(x)$ is rational? Thank you for your answers!","['real-analysis', 'functions']"
1762608,Integrating a probability density function that only depends on the norm,"I have a probability density function $f$ on $\mathbb{R}^3$ which only depends on the norm of a vector (that is, it takes the same value for $x,y$ if their length is equal). Let me call a region of $\mathbb{R^3}$ a cone if it is closed under multiplying by a nonnegative number (the intersection of some half spaces through the origin for example). Now it seems intuitively obvious that for a cone $S$ the number $\int_Sf$ is equal to the relative area of its intersection with the unit sphere (compared to the surface area of the unit sphere). Is there an elegant way to show this?","['probability', 'measure-theory']"
1762616,"Prove the following statement by proving its contrapositive: if $r$ is irrational, then ${ r }^{ \frac { 1 }{ 5 } }$ is irrational","Just a disclaimer before I proceed with my question and the proof I wrote up: I know that this question has been asked before, for example here , but I am more interested in being critiqued on how I wrote the proof and its completeness.
In addition, I am having trouble seeing how it proves what I first set out to prove. Theorem: if $r$ is irrational, then ${ r }^{ \frac { 1 }{ 5 }  }$ is irrational Proof: We prove the contrapositive: if ${ r }^{ \frac { 1 }{ 5 }  }$ is rational, then $r$ is rational 1) Assume that ${ r }^{ \frac { 1 }{ 5 }  }$ is rational, then there exists $a,b\in\mathbb{Z}$ such that: ${ r }^{ \frac { 1 }{ 5 }  }=\frac { a }{ b }$ where $a,b$ are coprime and $b\neq 0$ 2) Therefore, ${ r }=\frac { a^{ 5 } }{ b^{ 5 } } $ 3) If $a,b\in\mathbb{Z}$, then $a^5,b^5\in\mathbb{Z}$ as well. 4) Therefore $r\in\mathbb{Q}$ Q.E.D. When it comes to proving that the square root of $2$ is irrational, I can quickly see and understand why $\sqrt { 2 } $ is indeed irrational. However, with this proof, I don't understand how this actually proves the theorem I set out to prove. Does proving it by using the contrapositive just make it that much simpler? Or did I miss some vital steps in my proof? Please feel free to give me constructive criticism about my proof writing techniques as well.","['proof-verification', 'discrete-mathematics']"
1762643,Prove that $\tan20^°\tan40^°\tan60^°\tan80^°=3$,"Prove that $\tan20^°\tan40^°\tan60^°\tan80^°=3$ \begin{align}
\tan20^°\tan40^°\tan60^°\tan80^°&=\frac{\sin20^°\sin40^°\sin60^°\sin80^°}{\cos20^°\cos40^°\cos60^°\cos80^°} \\
&=\frac{2^4(\sin20^°\sin40^°\sin60^°\sin80^°)^2}{\sin 160^°}
\end{align} I am stuck here.",['trigonometry']
1762665,Can the boy escape the teacher for a regular $n$-gon?,"This is related to Prove that the boy cannot escape the teacher Suppose there is a boy in the center of a regular $n$-gon. The teacher is on the edge of the $n$-gon (but cannot leave the edge) and wants to capture the boy. At the beginning he is on a vertex. The teacher is $v(n)$ times faster than the boy. Which is the maximum $v(n)$ such that the boy can escape? (By escaping means he reaches the edge of the $n$-gon and the teacher is not there) From the linked question we know $3 \le v(4) < 6$, and for $n= \infty$ (a circle) then I know a strategy such that $v(\infty) = \pi + 1$ suffice; I don't know if this is optimal. I also put convergence in the tags because my wild hypothesis is that the maximum $v(n)$ will converge to some value and it would be interesting to know which one! Any cool way to solve this?","['analytic-geometry', 'curves', 'convergence-divergence', 'geometry']"
1762693,You have to estimate $\binom{63}{19}$ in $2$ minutes to save your life.,"This is from the lecture notes in this course of discrete mathematics I am following. The professor is writing about how fast binomial coefficients grow. So, suppose you had 2 minutes to save your life and had to estimate, up to a factor of $100$, the value of, say, $\binom{63}{19}$. How would you do it? I will leave this (hopefully intriguing!) question hanging and maybe come back to the topic of efficiently estimating binomial coefficients later. Any ideas/hints on how to do it?","['combinatorics', 'binomial-coefficients', 'discrete-mathematics']"
1762710,An integral related with the Riemann $\zeta$ function,"I have to prove that:
$$
\forall s>1,\qquad\int_0^\infty \sum_{k=1}^{\infty}\frac{1}{(k^s+1)^x+k^s}dx=\zeta(s).
$$ I how do I find the closed form for this sum? $$
\sum_{k=1}^{\infty}\frac{1}{(k^s+1)^x+k^s}
$$","['integration', 'riemann-zeta']"
1762720,Gradient Chain Rule: Applying Gradient in the case of a Series of Matrix operations (Neural Net Gradient Calculation),"I have the following situation: I need to calculate the gradient of the Error of a CNN a few layers deep by hand.  Starting with the Error function, The $\operatorname{Error}[readoutX]= -\sum_i \sum_j {actualX_{ij} * \operatorname{log}(readoutX_{ij})}$ So, letting $actualX = \mathbf{a}$ and $readoutX = \mathbf{x}$, I need to take the gradient of the Error function. The error function written out more fully, is: $$
\begin{align}
\operatorname[X] &= -\sum_i \sum_j a_{ij} * \operatorname{log}(x_{ij})\\
\mathbf{x} &= \operatorname{softmax}(\mathbf{B}\bullet \mathbf{A})\\
\mathbf{B} &= \mathbf{C} \bullet \mathbf{B}\\
\end{align}
$$ $\text{ Where the actual dimensions of }\mathbf{A},\mathbf{B}, \text{ and }\mathbf{C} \text{ are } (1024,10), (1568,1024),(?,1568) \text{ respectively (}? = \text{number of images in batch}), \text{ and the softmax is defined as: }$
$$\sigma(\mathbf{x})_j = \frac{e^{x_j}}{\sum_{k=1}^{|\mathbf{x}|} e^{x_k}} \text{ for } j = 1,\ldots,|\mathbf{x}|
$$ $\text{ with the partial derivative with respect to element }x_j:$ $$
\frac{\partial{\sigma(x)_i}}{\partial{x_j}} = \sigma(x)_i (\Delta_{ij} - \sigma(x)_j)
$$ Next, I start to write the gradient: $$
\nabla\operatorname{Error}[\mathbf{x}] = \sum_i \sum_j {- \frac{\partial{(a_{ij} * \operatorname{log}(x_{ij}))}}{\partial{x_{ij}}}}
= \sum_i\sum_j -a_{ij}\frac{\partial{\operatorname{log}(x_{ij})}}{\partial{x_{ij}}}
= \sum_i\sum_j -a_{ij}\frac{1}{x_{ij}}\frac{\partial{x_{ij}}}{\partial{u}}
$$ And I am stuck at: $\frac{\partial{x_{ij}}}{\partial{u}}$. I know that $\frac{\partial{x_{ij}}}{\partial{u}}$ should be a gradient, but I don't know how to implement it (I can just write the $\nabla$ in place of the partial and call it correct...but I have no idea if that is right...), and even after reading the Wikipedia article, I am not sure which chain rule applies here (or even if the first part of my gradient is correct).   In the past, I've done this using matrix derivatives, but it seems like the summation breaks that down... So, how do I write this first step...and transition to the next gradient (and then on to $\mathbf{C}$)...","['matrices', 'neural-networks', 'matrix-calculus', 'vector-analysis']"
1762733,Evaluation of $\lim_{x\rightarrow 0}\left(\frac{16^x+9^x}{2}\right)^{\frac{1}{x}}$,"Evaluation of $\displaystyle \lim_{x\rightarrow 0}\left(\frac{16^x+9^x}{2}\right)^{\frac{1}{x}}$ $\bf{My\; Try::}$ I am Using above question using Sandwich Theorem So Using $\bf{A.M\geq G.M\;,}$ We get $$\frac{16^x+9^x}{2}\geq (16^x\cdot 9^x)^{\frac{1}{2}}\Rightarrow \lim_{x\rightarrow 0}\left(\frac{16^x+9^x}{2}\right)^{\frac{1}{x}}\geq \lim_{x\rightarrow 0}(16^x\cdot 9^x)^{\frac{1}{2x}}=12$$ But I did not Understand How can I Calculate it for Upper bond, Help me Thanks",['limits']
1762737,Stochastic domination,"Suppose we have two probability measures on a space $X$, $\mu$ and $\nu$, such that $\nu$ stochastically dominates $\mu$, i.e.there exist a coupling of $\mu$ and $\nu$ on the product space $X \times X$, call it $\xi$, such that $\xi$'s respective marginals are $\mu$ and $\nu$ and $\xi[(x_1,x_2) : x_1 \leq x_2] = 1$. My question is :
is it true that the product measure $\bigotimes_{k \in \mathbb{N}}\nu_k$ on $\prod_{k \in \mathbb{N}}X$ with marginals $\nu_k \sim \nu$ will stochastically dominate  $\bigotimes_{k \in \mathbb{N}}\mu_k$ on $\prod_{k \in \mathbb{N}}X$ given that $\nu_k$ dominates $\mu_k$ on $X$ for every $k$ ?","['stochastic-processes', 'probability-theory', 'measure-theory']"
1762758,Calculate the limit $\lim_{n \to \infty}\frac{ \ln(n)^{(\ln n)}}{n!}$,I wonder what the limit $\lim_{n \to \infty}\frac{ \ln n^{\ln n}}{n!}$ would be equal to. It is well known that the factorial function grow faster than an exponential but slower than $n^n$. But how about a combination of $\ln $ (natural logarithm) and exponential? I guess the answer is $0$ since for $e$ the value is quite small. If I show that the logarithm of the expressions tends to $-\infty$ then I would be done.  Using laws of logarithm I can write $(\ln n)^2-\ln(n)!=(\ln n)^2(1-\frac{\ln(n!)}{(\ln n)^2})$. Now I need to know the limit of $\frac{\ln(n!)}{(\ln n)^2}$. Any suggestions?,"['real-analysis', 'calculus', 'limits']"
1762759,"$R$ be a commutative ring with unity such that every surjective ring homomorphism $f:R\to R$ is injective, then is $R$ Noetherian?","Let $R$ be a commutative ring with unity such that every surjective ring homomorphism $f:R\to R$ is injective, then is $R$ a Noetherian ring ?","['abstract-algebra', 'ring-theory', 'noetherian', 'ideals']"
1762799,Does it make sense to compare sets (polygons) with different dimensions?,"In the context of integer programming, I am considering 3 different linear models for a given problem. The goal is to determine which formulation is the tightest, that is, the one that gives the least fractional solution when omitting integrity constraints. Let $X$ , $Y$ and $Z$ be the polytopes defined by each of these formulations, without integrity constraints, and let $z_1, z_2, z_3$ denote the optimal values of the formulations over $X,Y,Z$ , respectively. Assume we are dealing with a minimization problem. I have managed to prove that $$
z_1 \ge z_2 \ge z_3
$$ in other words, the formulation over polytope $X$ is the tightest. From there, do the following inclusions hold (or make any sense) ? : $$
X\subseteq Y \subseteq Z
$$ My guess is that if the same number of variables is used for each formulation, then yes. But if these numbers are different, I am not sure the polytopes are ""comparable"" (my wording may be incorrect), and perhaps it makes no sense to use the symbol $\subseteq$ .","['integer-programming', 'polygons', 'optimization', 'polyhedra', 'discrete-mathematics']"
1762811,Straight Edge - Only Geometric Construction,"Given a circle, its diameter and a given point on the diameter, find a procedure to construct a line perpendicular to the diameter using only a straight edge. The perpendicular must pass through the given point. This question is a follow up to my previous question where the point was lying on the circle.Apparently, similar constructions cannot be made in this problem. This question discusses the case when the point lies outside the circle. Any help will be appreciated. Thanks.","['circles', 'geometric-construction', 'geometry']"
1762829,How many straight lines can be made between 10 points such that 4 of them are colinear?,"So i know how to get the answer. We just have to find $C(10,2)$ and subtract $C(4,2)$ and add 1. We are basically counting all the points between co-linear points as 1. So the question is why we are doing that. Lets consider 4 points to be $A,B,C,D$ and the lines that could be made from them are $AB,BC,CD,DA,AC,BD$. Clearly these lines are different from each other unless it is specified that distance between them are equal. So Why we are counting all of them as 1 ? This makes no sense to me.","['permutations', 'combinatorics', 'combinations', 'geometry']"
1762835,Deduce that $f=0 \operatorname{a.e.}$,"Let $f:[a,b]\to \mathbb R$ be a measurable function .Then Prove that if $\int _c ^d f(x)\operatorname {dx}=0$ for all $a\le c
<d\le b$ then $f=0 \operatorname{a.e.}$ My try :
Let $A=\{x:f(x)\neq 0\}$ .Define $A^+=\{x:f(x)>0\} $ and $A^{-}=\{x:f(x)<0\}$ We consider only the set $A^+=\{x:f(x)>0\} $ for $A^-$ we consider $-f$.
Surely $A^{+}$ is a measurable set., How should I proceed from here? Please give some hints","['lebesgue-measure', 'lebesgue-integral', 'measure-theory']"
1762837,What is the domain of the successor function?,"Before defining the natural numbers, how do you define the successor function? $S(x)=x\cup\{x\}$ is a function on _ into _? In two textbooks I've seen, the authors introduce the function (before the naturals) by saying ""for every set $x$, we define the successor $S(x)$..."". But doesn't that imply that the domain of $S$ contains all sets? Kinda funny that ""what is the domain of the successor function?"" is a title that does not meet this website's standards. (I guess if you click submit enough times...)",['elementary-set-theory']
1762849,Can you determine the length of a curve by the lengths of its projections onto planes?,"If $\,\Gamma \subset \mathbb R^n$ is $1$–rectifiable, then its Hausdorff measure is equal to its integral geometric measure. That is, 
$$\displaystyle\mathcal H^1\left(\Gamma\right) = \int_{G\left({1,\mathbb R}^n\right)} \int_K \operatorname{Card}\left(\left\lbrace {y \in \Pi_K}^{-1}\left(\left\lbrace x\right\rbrace \right)\right\rbrace \right)\, {d\hspace{0.125ex}\mathcal H}^1\left(x\right)\, d \hspace{0.125ex}\Theta_{{1,\mathbb R}^n}\left(K\right),$$
where $\operatorname{Card}(S)$ means the number of points in ${S,\Pi}_K$ denotes orthogonal projection onto ${K,\mathcal H}^1$ denotes the one–dimensional Hausdorff measure, $G\left({1,\mathbb R}^n\right)$ denotes the Grassmanian of unoriented lines through the origin in $\mathbb R^n$, and $\Theta_{{1,\mathbb R}^n}$ is the unique (up to suitable constant) finite Borel measure on $G\left({1,\mathbb R}^n\right)$ which is invariant under the action of the orthogonal group. I would like to know if the following is true:
$$\displaystyle\mathcal H^1\left(\Gamma\right) = \int_{G\left({2,\mathbb R}^n\right)} \int_V \operatorname{Card}\left(\left\lbrace {y \in \Pi_V}^{-1}\left(\left\lbrace x\right\rbrace \right)\right\rbrace \right)\, {d\hspace{0.125ex}\mathcal H}^1\left(x\right)\, d \hspace{0.125ex}\Theta_{{2,\mathbb R}^n}\left(K\right),$$ The more general question where the numbers $1$ and $2$ are replaced by $j$ and $k$ with $j<k<n$ is also of interest.","['geometric-measure-theory', 'differential-geometry']"
1762898,How does the posterior of a dirac prior look like?,"Edit for the Moderators: Should this question migrate to stats.stackexchange? I have a very basic question concerning updating from a prior to a posterior in bayesian statistics. Setting: I enter in a casino and I have a degenerate prior over an american roulette wheel, say $\delta_{\{0\}}$. The outcome of the first roll I witness is not $0$. [Notation: $\delta_{\{0\}}$ denotes the dirac measure associated with the belief that the roulette is unfair and completely bias towards $0$] Questions: How do I update my degenerate prior? Is my posterior the uniform over $\{ 0, 1 , \dots , 36 \}$?. What kind of prior is it? To what kind of posterior does it lead? [I assume there are some technical names for these things, that I am unaware of] Of course the questions come from the fact that it is not possible to update anything with such a prior, if the hard evidence I can obtain does not support it. Any feedback is most welcome. Thank you for your time.","['bayesian', 'probability-theory', 'statistics', 'dirac-delta']"
1762963,Painting the plane red and blue: Is it possible for each unit circumference to contain exactly $n$ blue points?,"I recently stumbled upon the following problem: Consider the plane: You may color each point either red or blue.
  Is there a way to color it such that each unit circumference (centred anywhere) contains exactly one blue point? And two? I solved it relatively easy: the ""one"" case has no solution, and the ""two"" case is solved placing the blue points in a set of parallel lines, at a distance of two from their neighbours. Of course I couldn't resist the temptation to consider the $n$ case: For $n$ even, the solution is easily extended considering lines at a distance of $4/n$. My question is: any help for the odd $n$ case? If there is any justice in the world, there should be no solution, but I honestly don't know where to start. EDIT: I have had this idea: if I have a solution for an $m$ case, and another for the $n$ case, such that they do not intersect (that is, whenever a point is blue in a solution it is not in the other) then simply superimposing the solutions yields a valid $m+n$ solution. It also stands to reason that if a $k$ solution exists, and contains an $m$ solution, then removing it yields a $k-m$ solution. So all that I need to prove is that an odd $k$ solution must contain a $k-1$ solution, and therefore also a $1$ solution, which I have shown cannot exist, and therefore also the generic odd solution cannot exist. For reference: I know geometry up to the basics of manifolds, analysis up to (but not including) Lebesgue measure and integration, and some group theory. Here is the proof for the $n = 1$ case:
Obviously, there must be at least one blue point: otherwise any circumference would contain no blue points and break the condition.
Consider the circle centred in that blue point: it must have one blue point. We therefore have two blue points at a distance of 1, therefore there is a circle that contains both, and violates the condition.
Thus, there cannot be a successful configuration of blue points, QED. I also have this other proof:
Take one blue point.
Consider all circles containing that point.
Those circles cannot have any other blue point, because they must have exactly one.
All those circles cover a disc of radius 2 centered in the blue point, and said disc cannot contain any other blue points.
Therefore the circle centered in the blue point contains no blue points and breaks the condition, QED.","['puzzle', 'geometry']"
1763014,Function that is second differential continuous,"Let $f:[0,1]\rightarrow\mathbb{R}$ be a function whose second derivative $f''(x)$ is continuous on $[0,1]$. Suppose that f(0)=f(1)=0 and that $|f''(x)|<1$ for any $x\in [0,1]$. Then $$|f'(\frac{1}{2})|\leq\frac{1}{4}.$$ I tried to use mean value theorem to prove it, but I found no place to use condition of second derivative and I cannot prove this.","['derivatives', 'real-analysis', 'continuity', 'analysis']"
1763087,"How to calculate Probability of ""Ranking""?","I took a course with other 10 students. After the final exam, the professor reported statistical result of scores to us:
1. The range of score: 46~98;
2. The average score: 73.3;
3 The S.D of score: 14.3;
I got 81, without any further information, how do I know the probabilities for me to be ranked in the 2nd place or the last 2nd place? If you happen to find the similar question to this on other sites with a reasonable answer, I'd like to know. Or if you can incorporate your own code in whatever language, I'll appreciate your answer very much!","['statistics', 'probability']"
1763146,Fundamental Group and DeRahm Cohomology from Group of Covering Transformations,"Old qual problem here, test tomorrow in topology and we barely got to DeRahm Cohomology so I'm not sure how to do this. Let $G$ be the group of transformations of $\mathbb{R}^3$ generated by
  \begin{align} A(x,y,z)&=(x+1,y,z)\\
B(x,y,z)&=(x,y+1,z)\\
C(x,y,z)&=(x+y,y,z+1). \end{align} Assume that $M=\mathbb{R}^3/G$ is a
  three-manifold. a. Determine $\pi_1(M)$ up to isomorphism by giving a presentation
  with generators and relations. ( note the relations will involve only
  commutators of generators) b. Determine $H_{DR}^1(M)$ up to isomorphism and give closed one-forms
  whose cohomology classes are a basis of $H_{DR}^1(M)$. Here's all I've got: We know that $G$ acts properly discontinuously on $\mathbb{R}^3$ so $\pi_1(M)=G$, but I'm not sure how to write $G$. When we have $G$, we know that $H_{DR}^1(X)=Hom(H_1(X),\mathbb{R})$ where $H_1(X)$ is $\pi_1(X)$ abelianized. I'm also not sure how to find the 1-forms giving a basis. Thank you.","['algebraic-topology', 'general-topology', 'differential-geometry', 'homology-cohomology']"
1763167,"Precalculus/Trigonometric Functions of Sine, Cosine, and Tangent with given parameters?","for my precalculus class I was given an assignment for extra credit however it is some material that I have yet to cover or learn as far as sine, cosine, and tangent go. Below is the prompt that I was given: If sin α = 3/13 where 0 < α < π/2 and cos β = -2/9 where π < β < 3π/2 , determine the following: sin(α - β) cos(β - α) tan(2β) cos(4β) cot(α + β) I am not quite sure of the first step to take on these. I wasn't able to find much online either due to my search terms or what not. I hate to upload such a blank question however I am at a loss for how to approach these questions...","['algebra-precalculus', 'trigonometry']"
1763168,How to prove $\lim_{a \to + \infty}a^q \int_{a}^{+\infty}\frac{\sin(x)dx}{x^p}=0$ when $p>q>0$,"I know a similar problem in demidovich's problem set #2357 about proving $$\lim_{x \to 0^+}x^a\int_{x}^1 \frac{f(t)}{t^{a+1}}dt$$it proves by dividing the integral into two parts and used two inequality to prove it less than some $\epsilon$. But the method does not apply. My other attempts discovered $\sin(x)$ is not arbitrary and cannot be casually changed to some constant even on some intervals. After Taylor expansion of $sin(x)$ is applied, the limit is still hard to calculate since it is a sum of an infinite series of improper integrals.","['improper-integrals', 'analysis']"
1763201,Closed-Form solution for system of simple nonlinear equations,"I am interested in analytical solutions for a system of nonlinear equations. Motivation : The source of the question is a very convinient method to create random matrices with special properties . Mathematica can give me solutions up to certain sizes of the linear system, but I would like to have it for arbitrary size N. I can also use numerical algorithms (which I am doing at the moment), but for N in the order of $N\approx10.000$, they are quite slow. System of nonlinear equations : $$
(w_i \cdot \sum_{j=1}^N w_j) - w_i^2 = d_i
$$
for $i=1...N$, and $w$ and $d$ are vectors with $N$ dimensions, and $w_i$ and $d_i$ is the $i$-th component of the vector. Both $d_i$ and $w_i \in \mathbb{R_+}$. I am providing the vector $d$ (i.e. N real non-negative numbers), and want to solve for $w_i$. Is there a way to solve this system analytically for arbitrary N? Edit : For clarification, if N=3 we have the following system of equations: $$
w_1 \cdot (w_2 + w_3) = d_1 \\
w_2 \cdot (w_1 + w_3) = d_2 \\
w_3 \cdot (w_1 + w_2) = d_3
$$ with $w_i, d_i \in \mathbb{R}$. For a given vector $d=(d_1,d_2,d_3)$, I want to get $w=(w_1,w_2,w_3)$. Edit2: I think I see a way how it could be solved, but I'm not certain: Let's set $c=\sum_{j=1}^N w_j$, which is the sum of all weights. What we have now: $$c \cdot w_i - w_i^2 = d_i \\
w_i^2 - c \cdot w_i + d_i = 0
$$
which has two solutions: $$w_{i_{1,2}} = \frac{c}{2} \pm \sqrt{ \left(\frac{c}{2}\right)^2 - d_i}
$$
and the normalisation constant $c$ can be calculated by the sum of all weights: $$\sum_{j=1}^N w_j = \sum_{j=1}^N \left(\frac{c}{2} \pm \sqrt{ \left(\frac{c}{2}\right)^2 - d_j} \right) = c
$$ Is this correct? Do you know an analytical solution for c?","['nonlinear-system', 'analysis']"
1763222,How to show that $f(x) = x \arctan \left(x \sin^{2} \left(\frac{1}{x}\right)\right)$ is strictly increasing for $x \geq 1$?,"I am trying to prove that $f(x) = x \arctan \left(x \sin^{2} \left(\frac{1}{x}\right)\right)$ is a strictly increasing function for $x \geq 1$. I try to do this by showing that $f'(x)>0$ for all $x \geq 1$. We have $$f'(x)= \arctan(x \sin^{2} \frac{1}{x}) + \frac{x}{1+x^{2} \sin^{4} \frac{1}{x}} \left(\frac{-2\cos\frac{1}{x} \sin \frac {1}{x}}{x} + \sin^{2} \frac{1}{x}\right),$$
so it's not clear if this quantity is positive.
Now I can show that $x \arctan \left(\frac{1}{x}\right)$ is strictly increasing (by computing its derivative and using simple trig inequalities to show that it is positive), and that $$x \sin^{2} \left(\frac{1}{x}\right)- \frac{1}{x}>0$$ So my aim is somehow to compare $f(x)$ with $x\arctan \frac{1}{x}$ and use the above inequality to prove that $f'(x)>0$. But now I am stuck. Any suggestions as to how to proceed? Or any other approach to the problem would be appreciated!","['real-analysis', 'trigonometry', 'functions']"
1763228,Parallelization of a Sphere gives Division Algebra,"Is there an elementary proof of the fact, that a parallelization of $S^n$ can turn $\mathbb{R}^{n+1}$ into a division algebra? My guess was something like this: Let $v_1(x),\dots, v_{n}(x)$ denote the sections of my parallelization. I'm assuming that these are pairwise orthogonal. Now $v_1((1,0,\dots,0)),\dots, v_{n}((1,0,\dots,0))$together with $(1,0,\dots,0)$ defines a basis for $\mathbb{R}^{n+1}$. I would like to define multiplication $v_i((1,0,\dots,0))\times x$ as applying the rotation by 90° in the plane spanned by $v_i(x)$ and $x$ and multiplication by $(1,0,\dots,0)$ as the identity. The next step would be to extend this linearly. But this doesn't work since my parallelization is not invariant under the right things for this to be correct. PS: With an elementary proof I mean, that it does not involve Milnor and Kervaires result.","['algebraic-topology', 'geometric-topology', 'general-topology', 'division-algebras']"
