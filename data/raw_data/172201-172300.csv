question_id,title,body,tags
3057995,Relation induced topology,"For an ordered space $X$ there is the term of ordered topology generated by sets of the form: $l(x)=\{ y\in X: y<x\} $ and $r(x)=\{ y\in X: y>x\} $ I was wondering if someone had encountered somewhere and can give a reference of reading materials on an a topology induced by relation. More precisely, for a set $X$ and a binary relation $R$ on $X$ , I would call the $R$ -induced topology as the topology generated by sets of the form: $l_R(x)=\{ y\in X: (y,x)\in R \} $ and $r_R(x)=\{ y\in X: (x,y)\in R\} $","['general-topology', 'relations', 'reference-request']"
3057997,"Isomorphism between two spaces, one of them is a Banach Space.","Let $E$ be a Banach space. And $X$ be normed vector space. If we have an isomorphism between $E$ and $X$ . can we prove then that $X$ is also a Banach space ? (In other words, does isomorphism conserves the Banach structure ? )","['general-topology', 'functional-analysis']"
3058059,If $\sum_{n=1}^{\infty} \sum_{k=1}^{\infty} f_{n}(k) = \infty$ then $\sum_{k=1}^{\infty} \sum_{n=1}^{\infty} f_{n}(k) = \infty$.,"Suppose $\{f_{n}\}_{n=1}^{\infty}$ be functions such that $f_{n} : \Bbb{N} \rightarrow \Bbb{R}^{+}$ for each $n$ . I was trying to prove - If $\sum_{n=1}^{\infty} \sum_{k=1}^{\infty} f_{n}(k) = \infty$ then $\sum_{k=1}^{\infty} \sum_{n=1}^{\infty} f_{n}(k) = \infty$ . I can see that both the double summation series are  equal by expanding the double summation.But I am trying to prove it ? any other thoughts? Hm, as the order of summation are changed, is Uniform convergence likely to play any role here?","['calculus', 'functions', 'convergence-divergence', 'summation']"
3058069,Integral for the New Year $2019$!,"Does the following transition between $2018$ and $2019$ hold true? $$\large\bbox[10pt,#000,border:5px solid green]{\color{#58A}{\color{#A0A}\int_{\color{#0F5}{-\infty}}^{\color{#0F5}{+\infty}} \frac{\color{yellow}\sin\left(\color{#0AF}x\color{violet}-\frac{\color{tomato}{2018}}{\color{#0AF}x}\right)}{\color{#0AF}x\color{violet}+\frac{\color{aqua}1}{\color{#0AF}x}} \color{#A0A}{\mathrm d}\color{#0AF}x\color{aqua}=\frac{\color{magenta}\pi}{\color{magenta}e^{\color{red}{2019}}}}}$$ $$\large\color{red}{\text{Happy new year!}}$$ I must say that I got lucky arriving at this integral. Earlier this year I have encountered the following integral: $$\int_0^\infty \frac{\sqrt{x^4+3x^2+1}\cos\left[x-\frac{1}{x} +\arctan\left(x+\frac{1}{x}\right)\right]}{x(x^2+1)^2}dx=\frac34\cdot \frac{\pi}{e^2}$$ Which at the first sight looks quite scary, but after some manipulations it breaks up into two integrals, one of which is: $$\int_{-\infty}^\infty \frac{\sin\left(x-\frac{1}{x}\right)}{x+\frac{1}{x}}dx$$ And while trying to solve it I also noticed a pattern on an integral of this type. Also today when I saw this combinatorics problem I tried to make something similar and remembered about the older integral. $\ddot \smile$ If you have other integral of the same type feel free to add!","['integration', 'recreational-mathematics', 'definite-integrals']"
3058076,Does Cauchy's theorem's hold if we only assume boundedness?,"Let $f$ be a function $\mathbb  C \to \mathbb C$ . I am not assuming $f$ is analytic on $\mathbb C$ , so Cauchy-Goursat does not apply. Suppose $\gamma$ is a simple closed contour, and suppose that the region $D = {\rm int}(\gamma) \cup \gamma$ can be approximated arbitrarily by little squares of arbitrarily small size. I would like to know whether $\oint_\gamma f = 0$ , under the assumption that $f$ is continuous and bounded on $D$ . I believe the answer is yes. Since the integral around $\gamma$ is equivalent to adding up the integrals from all the small squares, it is sufficient to show that the integral around the small squares approaches zero, which trivially follows from the Cauchy ML-inequality if $f$ is bounded on $D$ . Is this correct? So there is no need to assume analyticity if a continuous function is bounded?",['complex-analysis']
3058077,Number of relations on a set of $n$ elements [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question http://mathonline.wikidot.com/the-number-of-distinct-relations-on-a-finite-set From the link above I'm having trouble understanding how from $n^2$ ordered pairs which are either true or false there are a total of $ {2^{n^2}} $ , would it not be $2n$ ? Also, can someone explain the subset part of the definition, say I have a set $\{a,b,c\}$ , would that mean $\{(a,b), (b,a), (c,c)\}$ is also a relation? Or is are the subsets only the pairs of elements of $\{a,b,c\}$ ?","['elementary-set-theory', 'relations', 'combinatorics', 'discrete-mathematics']"
3058082,If $A$ is a symmetric matrix. Then all the eigenvalues of $A^2$ are nonnegative,"For the answer, we can get support from two claims: Claim 1: If $A$ is real and symmetric, then it has real eigenvalues. Proof here Claim 2: If $\lambda$ is an eigenvalue of $A$ , then $\lambda^2$ is an Eigenvalue of $A^2$ . Proof here So by those two claims we can say that if $\lambda$ is an eigenvalue of $A$ , then the corresponding eigenvalue $\lambda^2$ of $A^2$ is nonnegative. But my problem is how can we guarantee that it will cover all the possible eigenvalues of $A^2$ ?","['linear-algebra', 'eigenvalues-eigenvectors']"
3058099,Conditional probability- what is wrong with my understanding,"From Ostaszewski, 2007: An insurance policy covers two employees of a company. The policy will reimburse no more than one loss per employee per year. It reimburses the full amount of the loss up to a company wide maximum of $8000$ . The probability of an employee incurring a loss is $40$ %, and is independent of the other employee's losses. The amount of each loss is uniformly distributed on $(1000, 5000)$ . Given that one of the employees has incurred a loss in excess of $2000$ , determine the probability that losses will exceed reimbursements. The way to solve this is to make a square with vertices $(1000,1000), (5000,1000), (5000,5000),$ and $(1000,5000)$ . Then, to find the condition that one of the employees incurred $\text {loss} >2000$ , one must find the area that goes from $2000$ to $5000$ on one of the axes, and from $1000$ to $5000$ on the other, for a total area of $3000\cdot 4000$ in the denominator. The probability that losses exceed reimbursement is $P(X+Y>8000)$ , so the area is the triangle with vertices $(3000,5000), (5000,5000),$ and $(5000,3000)$ , and so the numerator will be ${1\over2}\cdot 2000^2$ . What is confusing me is how to account for fact that the probability of an employee incurring a loss is $40$ %. I would have thought that the total probability of at least one employee incurring a loss is $.40\cdot.60 +.60\cdot.40 + .40\cdot.40$ , and the probability that both employees incur a loss (which is necessary for losses to exceed reimbursements) is $.40 \cdot .40$ , and therefore the solution should be $$.40 \cdot .40\cdot {1\over2} \cdot 2000^2 \over (.40\cdot.60 +.60\cdot.40 + .40\cdot.40)\cdot 3000 \cdot 4000$$ However the solution says to just do: $$.40\cdot {1\over2} \cdot 2000^2 \over 3000 \cdot 4000$$ What is wrong with how I wanted to do it?","['statistics', 'probability']"
3058108,Iterated function 'periodicity',"Note: $f^n$ denotes the iteration of composition, e.g. $f^3(x)=(f\circ f\circ f)(x)$ I've noticed that particular functions have a certain property where for some number $n$ the iterations of the function cycle through a set of values so that $f^{m+n}(x)=f^m(x)$ for all $m\in\mathbb{N}$ . For example, if $f(x)=1-\frac{1}{x}$ : $$f^1(x)=1-\frac{1}{x}$$ $$f^2(x)=1-\frac{1}{1-\frac{1}{x}}=\frac{1}{1-x}$$ $$f^3(x)=1-\frac{1}{1-\frac{1}{1-\frac{1}{x}}}=x$$ $$f^4(x)=1-\frac{1}{x}$$ So the cycle has a  period of $n=3$ . Is there a name for this property, and where can I find more information? Also, are there any cases where the 'period' $n$ varies as a function of the iterate $m$ ? Edit: As others have pointed to in the comments, the property I am describing can be stated succinctly by $F^n(X)=X$ * for some $n$ , and can apply to functions as well as operators on functions. Since this extends rather naturally to integer $n$ , idempotence and involution would be examples with periods $1$ and $2$ , respectively. If matrix multiplication is used to represent the composition of functions, then the property in question applies to any $M$ such that $M^n=\pm I$ for some $n$ . As Will Jagy pointed out, in the example $f(x)=1-\frac{1}{x}$ , $M^3=-I$ is given by the Moebius transformation $f(x)=\frac{x-1}{x+0}$ . Given how incredibly general this property is and the number of things to which it applies there is absolutely no way that I am the first person to notice it. There has to be a book or a paper somewhere, right? *In retrospect, this should have been apparent given that $f^{m+n}=f^m\implies f^n=f^0$ ""Corollary""? If $$\frac{d^nf(x)}{dx^n}=f(x)$$ for some $n\in\mathbb{Z},n\neq0$ , then $$\frac{d^{mn}f(x)}{dx^{mn}}=f(x)$$ and $$\int^{m(n-1)}f(x)\ dx^{m(n-1)}=f(x)$$ for all $m\in\mathbb{Z}$","['abstract-algebra', 'polynomials', 'function-and-relation-composition']"
3058119,Side length of a regular tetrahedron given the radius of the sphere tangent to its edges,"I am working on a physics project where we have to build a container to protect a glass ornament when dropped from a high place. My design involves building a tetrahedron out of straws and putting the glass ornament inside of it.  I'm not sure what length to cut each side of the straw tetrahedron. I did some measurements and I estimated the radius of the sphere to be about 1.3. The tetrahedron has no ""walls"" where the ornament will touch at a single point. It is simply an empty frame made out of regular McDonald's straws, and the ornament will protrude out of each side a little bit, thus there are no faces, only edges . How can I find the best side length?","['geometry', '3d']"
3058135,chebyshev's inequality - Question,"I had a question in my exam and they asked to prove that
prove that: $$3(1+a^2+a^4)\geq(1+a+a^2)^2$$ for all $a\in\mathbb R$ . Now , I solved it , but the problem is that in the answer they wrote this:
using Chebyshev inequality: $$(1+a+a^2)^2=(1·1+a·1+a^2·1)^2≤(1+a^2+a^4)·(1+1+1)=3(1+a^2+a^4).$$ And so I tried searching the web for this inequality but all it found was the Chebyshev's inequality for probabillity.
can someone please send me link regarding this inequality or just write it here? Thank you.","['rearrangement-inequality', 'algebra-precalculus', 'symmetric-polynomials', 'inequality']"
3058140,How is the missing digit calculated?,"Recently I watched a video by Arthur Benjamin: https://youtu.be/e4PTvXtz4GM?t=337 I was curious how we solved this part of his show, and would like to know. Essentially at this point of the video, he asks three audience members to take the number $576$ and multiply it by a $4$ digit number. Thus the resulting product is a $6$ or $7$ digit number. Then he asks each of the members to call out all 5 of their 6, or 6 of their 7 digits, and he will find the missing digit. The first person calls: $8,0,9,3,8$ , and Arthur guesses $8$ as the digit he leaves out. The second person calls: $4,7,2,5,8,4$ , and Arthur guesses $6$ . The third person calls: $9,4,4,5,4,4$ , and Arthur guesses $6$ . My question is, how exactly he knew this. Firstly, I realize that adding each of the digits together in the product yields $36$ , regardless of it being a $6$ or $7$ digit number. So then I assume that he just added all their digits and subtracted from $36$ to get their missing digit. If this is the case, where did the number $36$ come from? I don't think this is fully true, as something like $231\times 4412 = 1019172$ , which has digits sum up to $21$ . I don't have any previous experience is number theory (if I need to know this to understand why it works)","['number-theory', 'elementary-number-theory']"
3058146,Finding the common face of clinging soap bubbles using trigonometric functions of angles,"I am trying to help my daughter with a problem from Stewart's Precalculus book.This problem comes right after law of sines. When two bubbles cling together in midair, their common surface is part of a sphere whose center D lies on the line passing through the centers of the bubbles (please refer to the figure below) also angles ACB and ACD each have measure 60 degrees Show that the radius r of the common surface is given by r = ab / (b - a) Find the radius of the common face if the radii of the bubbles are 3cm and 4cm I could do the second one but after using law of cosines to find length of the segment AB in triangle CBA. That came out as Then I used law of sines in triangle ABC to find angle CAB = 73.897 degrees Angle CAD = 180 - angle CAB = 106.1 degrees
angle CDA = 180 - 106.1 - 60 = 13.897 degrees Then I used law of sines in triangle CAD to find the value of r But I couldn't make any headway for the first one. Also it seems to me that I don't need law of cosines to solve this problem. Any help will be appreciated.
Thanks","['algebra-precalculus', 'trigonometry']"
3058158,limsup of continuous function is measurable.,"I want to show that if $F$ is continuous on $[a,b]$ then $$\limsup_{h \rightarrow0, h>0} \frac{F(x+h)-F(x)}{h}$$ is measurable. By the definition of $\limsup$ we can write \begin{align}
&\limsup_{h \rightarrow0, h>0} \frac{F(x+h)-F(x)}{h}\\
&=\lim_{\delta\rightarrow 0}\left(\sup_{0<h<\delta} \ \frac{F(x+h)-F(x)}{h}\right)\\
&=\lim_{n\rightarrow \infty}\left(\sup_{0<h<\frac{1}{n}} \ \frac{F(x+h)-F(x)}{h}\right).
\end{align} If we show $\sup_{0<h<\frac{1}{n}} \ \frac{F(x+h)-F(x)}{h}$ is measurable then we can use the fact that limit of a countable sequence of measurable functions is also measurable. I want to show that $$\sup_{0<h<\delta}\frac{F(x+h)-F(x)}{h}=\sup_{0<h<\delta,h \in \mathbb{Q}}\frac{F(x+h)-F(x)}{h}$$ It suffices to show that $$\sup_{0<h<\delta,h \in \mathbb{Q}}\frac{F(x+h)-F(x)}{h}\geq \sup_{0<h<\delta}\frac{F(x+h)-F(x)}{h}$$ . Given $\epsilon>0$ , there exists $0<h_0<\delta$ such that $$\frac{F(x+h_0)-F(x)}{h_0}>\sup_{0<h<\delta}\frac{F(x+h)-F(x)}{h}-\epsilon$$ Let's fix $x$ . Since $\frac{F(x+h)-F(x)}{h}$ is a continuous function with variable $h$ , there exists a rational $0<q<\delta$ close enough to $h_0$ such that $$\left|\frac{F(x+q)-F(x)}{q}-\frac{F(x+h_0)-F(x)}{h_0}\right|<\epsilon$$ Therefore, $$\frac{F(x+q)-F(x)}{q}>\sup_{0<h<\delta}\frac{F(x+h)-F(x)}{h}-2\epsilon$$ Since $\epsilon$ is arbitrary, $$\sup_{0<h<\delta,h \in \mathbb{Q}}\frac{F(x+h)-F(x)}{h}\geq \sup_{0<h<\delta}\frac{F(x+h)-F(x)}{h}$$","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
3058169,Verfying partial derivatives for an ODE,"Let $\phi(t,x)$ : $[\mathbb{R}$ x $\mathbb{R^N}] \rightarrow \mathbb{R^N}$ have the following properties: for any $t\in\mathbb{R}$ and $x\in\mathbb{R^N}$ , $\phi(t,x)$ is differentiable in both arguments and has a differentiable inverse. For any $s\in\mathbb{R}$ , $\phi(t+s,x)=\phi(t,\phi(s,x))$ . Define T(t,x) = $\dfrac{\partial\phi(t,x)}{\partial{x}}$ and $f(x)=\dfrac{\partial\phi(t,x)}{\partial{t}}\big|_{t=0}$ . Show that $\phi(t,x)$ and $T(t,x)$ satisfy: a. $\dfrac{\partial\phi(t,x)}{\partial{t}} = f(\phi(t,x))$ b. $\dfrac{\partial{T(t,x)}}{\partial{t}} = Df(\phi(t,x))\hspace{0.5mm}T(t,x)$ where $Df$ is the Jacobian of f. Here is my proposed solution. For the first part, I need to show that $\dfrac{\partial\phi(t,x)}{\partial{t}} = f(\phi(t,x))$ . Starting from the LHS, \begin{equation}
\begin{split}
\dfrac{\partial\phi(t,x)}{\partial{t}}  & = \dfrac{\partial\phi(t+0,x)}{\partial{t}}  \\
 & = \dfrac{\partial\phi(t,\phi(0,x))}{\partial{t}} \\
 & = \dfrac{\partial\phi(t,\phi(t,x))}{\partial{t}}\big|_{t=0} \\
 & = f(\phi(t,x)) 
\end{split}
\end{equation} I think that the second to last equality is justified since $\phi(t,x)$ is evaluated at $t=0$ . Although, I'm not sure if I have overlooked something and made a mistake. For the second part, I need to show that $\dfrac{\partial{T(t,x)}}{\partial{t}} = Df(\phi(t,x))\hspace{0.5mm}T(t,x)$ . Starting from the LHS, \begin{equation}
\begin{split}
\dfrac{\partial{T(t,x)}}{\partial{t}} & = \dfrac{\partial\phi(t,x)}{\partial{x}\hspace{0.5mm}\partial{t}}  \\
 & = \dfrac{f(\phi(t,x))}{\partial{x}} \\
 & = D{f(\phi(t,x))}\hspace{0.5mm}\dfrac{\partial\phi(t,x)}{\partial{x}} \\
 & = D{f(\phi(t,x))}\hspace{0.5mm}T(t,x)
\end{split}
\end{equation} As $\phi\in{C^1}$ , the Jacobian is defined by the third equality. Is this approach correct? Please let me know if there are any better alternatives.","['partial-derivative', 'ordinary-differential-equations']"
3058192,Showing $\sum_{k=1}^{nm} \frac{1}{k} \approx \sum_{k=1}^{n} \frac{1}{k} + \sum_{k=1}^{m} \frac{1}{k}$,"Since $\log(nm) = \log(n) + \log(m)$ , and $\sum_{k=1}^n \frac{1}{k} \approx \log n$ for large $n$ , we would expect that $$\sum_{k=1}^{nm} \frac{1}{k} \approx \sum_{k=1}^{n} \frac{1}{k} + \sum_{k=1}^{m} \frac{1}{k}$$ when $n,m$ are large. I'm wondering if this approximation can be demonstrated through discrete means. That is to say, manipulations of rational fractions and/or elementary number-theoretical considerations, without using the $\log n$ approximation.","['harmonic-numbers', 'sequences-and-series']"
3058241,Integral of a function with compact support,I am reading a book with the following statement Since $g$ has compact support $$\sum_{i=1}^d \int_{\mathbb{R}^d} \frac{\partial (fF_i g)}{x_i} dx = 0$$ where $\frac{dx}{dt} = F(x)$ with $x\in \mathbb{R}^d$ $g: \mathbb{R}^d \rightarrow \mathbb{R}$ is continuously differentiable with compact support $f: \mathbb{R}^d \rightarrow \mathbb{R}$ The compact support means that if it is zero outside of a compact set. How can we say the sum of integral is zero?,"['integration', 'derivatives', 'partial-derivative']"
3058246,Probability of covering all vertices of a square,"Let $~A_1 = (0,0), ~~A_2 = (1,0),~~ A_3 = (1,1)~$ and $~A_4 = (0,1)~$ be the four vertices of a square. A particle starts from the point $~A_1~$ at time $~0~$ and moves either to $~A_2~$ or to $~A_4~$ with equal probability. Similarly, in each of the subsequent steps, it randomly chooses one of its adjacent vertices and moves there. Let $~T~$ be the minimum number of steps required to cover all four vertices. 
The probability $~P(T = 4)~$ is $(A) ~~~~0$ $(B) ~~~~\frac{1}{16}$ $(C) ~~~~\frac{1}{8}$ $(D) ~~~~\frac{1}{4}$ I am getting it as $~\frac{3}{4}~$ but answer is $~\frac{1}{8}~$ please help!",['probability']
3058273,Compute $\int_{0}^{+\infty} \frac{\sin x}{\sqrt{x}}\ dx$ using Gamma function,"I want to compute $$\int_{0}^{+\infty} \frac{\sin x}{\sqrt{x}}\ dx$$ using Gamma function. I know that by change of variable, $y=\sqrt{x}$ , one gets $$\int_{0}^{+\infty} \frac{\sin x}{\sqrt{x}}\ dx=2\int_{0}^{+\infty}\sin y^2\ dy=\frac{\sqrt{2\pi}}{2}$$ by Fresnel's integral. I try it by considering this: $$\int_{0}^{+\infty}x^{-\frac{1}{2}}e^{ix}\ dx$$ It converges for both real and imaginary part using Dirichlet test, and $0$ is not a problem here. Let the square root take the pricipal branch where $\sqrt{1}=1$ . Let $y=-ix$ , then $$\int_{0}^{+\infty}x^{-\frac{1}{2}}e^{ix}\ dx=\sqrt{i}\int_{0}^{-i\infty}y^{-\frac{1}{2}}e^{-y}\ dy=(\frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i)\Gamma(\frac{1}{2})=\frac{\sqrt{2\pi}}{2} + \frac{\sqrt{2\pi}}{2}i$$ And it coincides with the final answer! My problem is, suppose $L$ is a ray starting from $0$ and has an angle $\phi$ with the $x$ -axis, and let $\phi\in(0,2\pi)$ .
I want to argue that (maybe it is incorrect though) $$\Gamma(z)=\int_{L}t^{z-1}e^{-t}\ dt$$ I firstly know that it converges when $\Re(z)>0$ . Choose a contour like sector, let $L_1=\{z=x+iy:y=0, r<x<R\}$ , $L_2=\{z=Re^{i\theta}:0<\theta<\phi\}$ , $L_3=\{z=xe^{i\phi}:r<x<R\}$ and $L_4=\{z=re^{i\theta}:0<\theta<\phi\}$ , where $r<R$ and the contour is counterclockwise. By Cauchy theorem we have the contour integral should be $0$ .
Easy to see that (let $z=x+iy$ ) $$
\lim_{r\to0+, R\to+\infty}\int_{L_1}t^{z-1}e^{-t}\ dt=\Gamma(z)
$$ $$
|\int_{L_4}t^{z-1}e^{-t}\ dt|=|\int_{\phi}^{0} e^{-re^{i\theta}} (re^{i\theta})^{z-1}ire^{i\theta}\ d\theta| \leq \int_{0}^{\phi} e^{-r\cos\theta} |r^{z}e^{i\theta(z-1)}|\ d\theta=\int_{0}^{\phi} e^{-r\cos\theta} r^{x}e^{-\theta y}\ d\theta \to 0, r \to 0+
$$ But when considering $L_2$ : $$
|\int_{L_2}t^{z-1}e^{-t}\ dt|\leq\int_{0}^{\phi} e^{-R\cos\theta} R^{x}e^{-\theta y}\ d\theta
$$ when for example, $\frac{3\pi}{2}>\phi>\frac{\pi}{2}$ , we have $\cos\theta<0$ and I failed to prove the above integral goes to zero when $R\to +\infty$ . Is my usage of Gamma function to compute the original integral a coincidence to get the correct result, or there is a way to prove my argument? Thank you so much!","['complex-analysis', 'gamma-function']"
3058278,Concerning this sum $\sum_{n=0}^{\infty}\frac{1}{4n+1}\left[\frac{1}{4^n}{2n \choose n}\right]^2=\frac{\Gamma^4\left(\frac{1}{4}\right)}{16\pi^2}$,"I was looking at this paper and saw this nice sum in section [12] of the paper, $$\sum_{n=0}^{\infty}\frac{1}{4n+1}\left[\frac{1}{4^n}{2n \choose n}\right]^2=\frac{\Gamma^4\left(\frac{1}{4}\right)}{16\pi^2}\tag1$$ out of curiosity I conjectured the following two sums $$\begin{align*}
\sum_{n=0}^{\infty}\frac{(-1)^n}{(2n-1)^2}\left[\frac{1}{4^n}{2n \choose n}\right]^2&=\frac{4\sqrt{2\pi}}{\Gamma^2\left(\frac{1}{4}\right)}\tag2\\
\sum_{n=0}^{\infty}(-1)^n\frac{n^2}{(2n-1)^2}\left[\frac{1}{4^n}{2n \choose n}\right]^2&=-\frac{\Gamma^2\left(\frac{1}{4}\right)}{8\pi\sqrt{2\pi}}\tag3
\end{align*}$$ I am unable to prove them. How do we go about to prove these two sums?",['sequences-and-series']
3058387,Empirical error proof Runge-Kutta algorithm when not knowing exact solution,"I'm implementing a RK solver for calculating the solution to the Lorenz system: \begin{equation}
\begin{cases}
x'(t) = \sigma(y-x) \\
y'(t) = rx-y-z \\
z'(t) = xy-bz
\end{cases}
\end{equation} The implemented RK method is of order 3 with some random Butcher tableau (but satisfies the conditions neccesary for it to have global error of order $\mathcal{O}(h^k)$ , for $k$ the order of the method and local truncation error of $\mathcal{O}(h^{k+1})$ ). One of the questions I'm being asked is to prove empirically that my implemented RK achieves these orders of error. My first attempt was to estimate the local error ( $\delta_L$ ) as: $$\delta_L(t_n) = x_n(t_n)-x_n(t_n-1)$$ Where $x_n$ is the numerical solution of $x$ and $t_n$ is the time step. Following this approach, I get a very oscillatory error, ranging from $-2.5$ to 2.5 with mean $0.0012$ , suggesting that the way I calculate the error must not be appropiate.","['runge-kutta-methods', 'numerical-methods', 'ordinary-differential-equations']"
3058413,What are the minor and major arcs in the Circle method (Hardy & Littlewood)?,"I was wondering if somebody would be so kind as to graphically show what are the minor and major arcs in the Circle method? In this example , extract below, I've attempted a simple diagram to show what is going on but it is clearly incomplete (I've now edited it to reflect comments). Extract problem: given $k \in \mathbb{N}$ , determine the number of possible representations of n $\in$ N as a sum of exactly $k$ natural numbers. Please correct the diagram below and show the major and minor arcs.","['complex-analysis', 'number-theory', 'analytic-number-theory']"
3058424,"Why does the function $ f(x) = x, x \in (0, 1) $ not have maximum or minimum values? Why do we not use limits?","My textbook says that this function does not have a maximum value because for any $ x $ I choose to be a point of maximum or point of minimum, we can always choose some other $ x $ right next to it such that $ f(x) $ is smaller or greater (as we require). The same reasoning is given in this question here on Math SE. My question is, why don't we use limits here and say that the maximum value is just 1, and that the minimum value is just 0. In other words, we know that: $$ \lim_{x \to 1^+}\ x = 1 \quad \text{ and } \quad \lim_{x \to 0^-}\ x = 0 $$ In that case, aren't the extremum values technically just 1 and 0? Is there a specific reason why we use limits elsewhere in math but not in this particular case?","['limits', 'maxima-minima', 'derivatives']"
3058425,Do all projections matrices take this form?,"Do all projection matrices take the form $P = A{(A^TA)}^{-1}A^T$ ? If so, can you help me derive it and explain it intuitively?","['matrices', 'projective-geometry', 'linear-algebra']"
3058442,Rectangles in a $n \times n$ grid and the sum of the first $n$ cubes: a geometric connection?,"My aim is to find the number of rectangles (squares included) in a $n \times n$ grid. It is easy to get that result with combinations. The usual answer to this problem is given by $$\binom{n+1}{2}^2$$ which makes sense, just select two parallel lines from the $n+1$ vertical lines and another two from horizontal ones. Intriguingly, this is the same as the sum of the first $n$ cubes: that is $$1^3 + 2^3 + 3^3 + ... +n^3 = \binom{n+1}{2}^2$$ Are these two problems (the number of rectangles and the sum of cubes) and their results interrelated? Is there some sort of geometric connection between the two, and, if so, what is it?","['alternative-proof', 'combinations', 'combinatorics']"
3058455,"Infinite cyclic cover corresponding to non-zero cohomology class $\alpha \in H^1(x,\mathbb Z)$","I want to understand the following sentence: Let X a compact (complex) manifold which has a non-zero cohomology class $\alpha \in H^1(X,\mathbb Z)$ . Let $\pi: \bar X\to X$ be the corresponding infinite cyclic covering. What does this mean? It seems that an infinite cyclic covering is a cover with fiber $\mathbb Z$ . But why does such a covering exist, and how is it related to the cohomology class?","['complex-geometry', 'geometry', 'covering-spaces', 'algebraic-topology', 'differential-geometry']"
3058457,If $[F(x)]^{100} = \int_{0}^{x} (F(t))^{100} \frac{dt}{1+\sin t}$ then find $F(x)$,"If $[F(x)]^{100} = \int_{0}^{x} (F(t))^{100} \frac{dt}{1+\sin t}$ then find $F(x)$ . My attempt Differentiating both sides, $$100[F(x)]^{99} \frac{d F(x)}{dx} = \frac{F(x)^{100}}{1 + \sin x}$$ then $$\frac{d F(x)}{F(x)} = \frac{dx}{100(1+\sin x)}$$ and $$\int \frac{d F(x)}{F(x)} = \int \frac{dx}{100(1+\sin x)}$$ $$\log F(x) = -1/(50+50 \tan (x/2))$$ Hence $$F(x) = \exp(-1/(50+50\tan (x/2))$$ But, I am not getting my answer right. Where did I go wrong?","['integration', 'calculus']"
3058464,Definition of the weak derivative involving the mean curvature,"Source: https://homepages.warwick.ac.uk/staff/C.M.Elliott/DziEll13a.pdf Definition 2.11 of the weak derivative: A function $f \in L^1(\Gamma)$ has the weak derivative $v_i=D_if \in L^1(\Gamma)$ , $i \in \{1,...,n+1\}$ , if for every function $\phi \in C^1_0(\Gamma)$ we have the relation $$\int_\Gamma f D_i\phi \,dA =- \int_\Gamma\phi v_i \,dA+ \int_\Gamma f\phi H\ n_id\,A$$ where $\Gamma$ is a hypersurface in $\mathbb R^{n+1}$ and $H$ is its mean curvature. Question : I am familiar with the ""standard"" definition of the weak derivative ( https://en.wikipedia.org/wiki/Weak_derivative ). How are these two different defintions to be reconciled and what role does the mean curvature get into the equation? Some explanation/interpretation would be much appreciated.","['curvature', 'weak-derivatives', 'ordinary-differential-equations', 'differential-geometry']"
3058485,A question about the Residue of $h=fg$,"Let $f$ and $g$ be two functions (not necessarily analytic) of the complex
variable $z$ such that for some $\varepsilon >0$ : 1) $f$ is continuous on $0<\left\vert z\right\vert <\varepsilon $ 2) $g$ is continuous on $\left\vert z\right\vert <\varepsilon $ and $%
g\left( 0\right) \neq 0$ 3) $h=fg$ is analytic on $0<\left\vert z\right\vert <\varepsilon .$ Do we have \begin{equation*}
Res\left( h,0\right) =\frac{g\left( 0\right) }{2\pi i}\oint_{\left\vert
z\right\vert =\frac{\varepsilon }{2}}f\left( z\right) dz
\end{equation*} Or perhaps some other equation ? Thank you !","['integration', 'complex-analysis', 'contour-integration', 'functional-analysis', 'residue-calculus']"
3058500,Analytic continuation of harmonic series,"Is there an accepted analytic continuation of $\sum_{n=1}^m \frac{1}{n}$ ? Even a continuation to positive reals would be of interested, though negative and complex arguments would also be interesting. I don't have a specific application in mind, but I'd very much like to understand how / if such a continuation could be accomplished. I've Googled but haven't come up with anything meaningful - perhaps because it's not possible? ADDENDUM @Noble below suggests $\frac{\Gamma'(x)}{\Gamma(x)}$ . But this produces the following mismatched plots: Can anyone explain?","['harmonic-numbers', 'harmonic-functions', 'analytic-continuation', 'sequences-and-series']"
3058514,Modeling a yes/no event,"I was wondering what kind of distribution applies to a variable that can have one of two outcomes (say yes or no) but the probability of any of these outcomes is completely random and cannot he determined ? Example: I am stopping 10,000 people on the street and asking them: are you happy today. Thank you !",['statistics']
3058522,prove or disprove (K ∩ L) × (M ∩ N) = (K × M) ∩ (L × N);,"I have a bad understanding of the Cartesian product and having trouble doing this: We are given $(K ∩ L) × (M ∩ N) = (K × M) ∩ (L × N)$ ;
how to prove it or disprove it? This is what i am thinking: Let $x ∈ (K∩L)×(M∩N)$ . then $x=(x_1,x_2)$ , where $x_1∈(K∩L) ∧ x_2∈(M∩N)$ . By definition of intersection $x_1∈K ∧ x_1∈L ∧ x_2∈M ∧ x_2∈N$ as $x_1∈K ∧ x_2∈M$ , then $x = (x_1,x_2) ∈K×M$ . as $x_1∈L ∧ x_2∈N$ , then $x = (x_1,x_2) ∈L×N$ . as $x∈K×M ∧ x∈L×N$ , then $x∈(K × M) ∩ (L × N)$ let's prove this the other way let $x ∈ (K × M) ∩ (L × N)$ by definition of intersection $x∈K×M ∧ x∈L×N$ . $x ∈K×M$ which means that $x_1∈K ∧ x_2∈M$ . $x ∈L×N$ which means that $x_1∈L ∧ x_2∈N$ . by definition of intersection $x_1∈(K∩L)$ . by definition of intersection $x_2∈(M∩N)$ . which means $x=(x_1, x_2)∈(K∩L)×(M∩N)$ . Is it all correct? or is it all wrong?","['elementary-set-theory', 'proof-writing']"
3058544,Finding element of order in the symmetric group,"What is the proper and technical way to find if there exists an element in the symmetric group $S_n$ ( Wikipedia article on symmetric groups. ). I do know how to disprove if there does not exists such elements, but how should I find the element which does exists of this order? For example, in the $S_{12}$ , there is not such element of order $13$ because The only elements of order $13$ in $S_n$ are unions of disjoint $13$ -cycles, since $13$ is prime. This would require $S_{12}$ to contain at least $13$ symbols, which it does not. But I think that there is an element of order $35$ in $S_{12}$ . How should I find it? EDIT : I do understand that I have to find a $7$ -cycle and a $5$ -cycle, but how?","['permutations', 'group-theory']"
3058597,Find all irreducible characters of a matrix group on finite field $\mathbb F_5$,"Find all irreducible characters of matrix group $G =\left\{ \left( \begin{array}{cc}
a & b \\0 & a^{-1}\end{array} \right)|\,\,\, a,b \in\mathbb F_5, a\not=0 \right\}$ . The former question is to find irreducible characters of subgroup of $G$ $H =\left\{ \left( \begin{array}{cc}
a & 0 \\0 & a^{-1}\end{array} \right)|\, a\in\mathbb F_5^{\times}  \right\}$ and $N =\left\{ \left( \begin{array}{cc}
1 & b \\0 & 1 \end{array} \right)|\, b\in\mathbb F_5 \right\}$ and I can work it out. But situation of $G$ is much complicated than I thought.","['group-theory', 'abstract-algebra', 'representation-theory', 'characters']"
3058626,"$f(x)$ is continuous at $x=\alpha$ ,$g(x)$ is discontinuous at $x=a$ but $g(f(x))$ is continuous at $x=\alpha$","Suppose $f,g:\mathbb{R} \rightarrow \mathbb{R}$ are such that $f(x)$ is continuous at $x=\alpha$ and $f(\alpha)=a$ and $g(x)$ is discontinuous at $x=a$ , but $g\big(f(x)\big)$ is continuous at $x=\alpha$ .  Also, $f(x),g(x)$ are non-constant functions.  Then, can it be said that $x=\alpha$ is an extremum of $f$ and $x=a$ is an extremum of $g$ ? I have tried to construct examples of functions, but never could figure out a rigorous proof
For example take the function $f(x)=x^2$ which is continuous at $0$ , $g(x)=[x]$ which is discontinuous at $0$ , but $g\big(f(x)\big)$ is continuous at $0$ .","['analysis', 'function-and-relation-composition', 'real-analysis', 'continuity', 'calculus']"
3058670,Open balls in $\mathbb{R}^d$ are Jordan Measurable,"I'm trying to solve the following question from Terrence Tao's An Introduction to Measure Theory. Show that an open Euclidean
  ball $B(x, r) := \{y \in \mathbb{R}^d
: |y − x| < r\}$ in $\mathbb{R}^d$ is Jordan measurable, with Jordan
  measure $c_d r^d$ for some constant $c_d > 0$ depending only on $d$ . Is there an elementary way to approach this problem?",['real-analysis']
3058677,Irreducible polynomials of degree greater than 4 over finite fields,"I want to build a field with $p^{n}$ elements. I know that this can be done by finding a irreducible (on $Z_{p}$ ) polynomial f of degree n and the result would be the $Z_{p}$ /f.
 My question is finding this irreducible polynomial. I know that if it has degree $\leq$ 3, then it's irreducible iff it has no roots. But what if I want to construct a field with 81 = $3^{4}$ elements? How can I find an irreducible polynomial of degree 4?","['irreducible-polynomials', 'number-theory', 'finite-fields', 'polynomials']"
3058679,Integral $\int_0^\infty \frac{\ln x}{(\pi^2+\ln^2 x)(1+x)^2} \frac{dx}{\sqrt x}$,"I have stumbled upon the following integral: $$I=\int_0^\infty \frac{\ln x}{(\pi^2+\ln^2 x)(1+x)^2} \frac{dx}{\sqrt x}=-\frac{\pi}{24}$$ Although I could solve it, I am not quite comfortable with the way I did it. But first I will show the way. We can substitute $\ln x \rightarrow t\ $ which gives: $$I=\int_{-\infty}^\infty \frac{t}{\pi^2+t^2}\frac{e^{\frac{t}{2}}}{(1+e^t)^2}dt\overset{t=-x}=\int_{-\infty}^\infty \frac{-x}{\pi^2+x^2}\frac{e^{-\frac{x}{2}}}{(1+e^{-x})^2}dx$$ Also adding the two integral from above and simplify some of it yields: $$2I= \int_{-\infty}^\infty \frac{x}{\pi^2+x^2}\left(\frac{e^{\frac{x}{2}}}{(1+e^x)^2}-\frac{e^{-\frac{x}{2}}}{(1+e^{-x})^2}\right)dx$$ $$\Rightarrow I=-\frac{1}{4} \int_{-\infty}^\infty \frac{x}{\pi^2+x^2}\frac{\sinh \left(\frac{x}{2}\right)}{\cosh ^2\left(\frac{x}{2}\right)}dx$$ And now a round of IBP gives: $$I=\frac12 \int_{-\infty}^\infty \left(\frac{x^2-\pi^2}{(x^2+\pi^2)^2}\right)\left(\frac{1}{\cosh \left(\frac{x}{2}\right)}\right)dx$$ Using the Plancherel theorem the integral simplifies to: $$I=\int_0^\infty \left(\sqrt{\frac{\pi}{2}}x\left(-e^{-\pi x}\right)\right)\left(\sqrt{2\pi}\frac{1}{\cosh(\pi x)}\right)dx\overset{\pi x\rightarrow x}=-\frac{1}{\pi}\int_0^\infty \frac{x}{\cosh( x)}e^{- x}dx$$ We also have the following Laplace tranform for: $$f(t)=\frac{t}{\cosh( t)}\rightarrow F(s)=\frac18\left(\psi_1\left(\frac{s+1}{4}\right)-\psi_1\left(\frac{s+3}{4}\right)\right)$$ Where $\displaystyle{\psi_1(z)=\sum_{n=0}^\infty \frac{1}{(z+n)^2}}\,$ is the trigamma function . $$\Rightarrow I=-\frac{1}{\pi}F(s=1)=-\frac{1}{\pi}\cdot \frac18\left(\psi_1\left(\frac{1}{2}\right)-\psi_1 (1)\right)=-\frac{1}{\pi}\cdot \frac18\left(\frac{\pi^2}{2}-\frac{\pi^2}{6}\right)=-\frac{\pi}{24}$$ Have I done anything wrong, or can it be improved?
I have to admit that I mostly used wolfram when applying Plancherel theorem  and Laplace transform which I'm not comfortable with, but I didn't find an alternative method myself. For this question I would like to see a different proof that doesn't rely on that theorem. Probably not needed, but I should mention that my contour integration knowledge is pretty low. Also maybe there is a conexion with this integral , but I didn't find any.","['integration', 'alternative-proof', 'definite-integrals']"
3058707,Bounded function of compact normal operator on Hilbert space is normal,"Let $H$ be a Hilbert space and consider a compact normal linear operator $A:H \to H$ . Moreover, let $f$ be a bounded function on the spectrum $\sigma(A)$ of $A$ and consider the operator $f(A)$ in the sense of functional calculus.
I want to show that $f(A)$ is also a normal operator. I know that a bounded linear operator $B:H \to H$ is normal if and only if $$ ||Bx||=||B^\star x|| \quad \forall x \in H,$$ which might be useful in this context.","['operator-theory', 'spectral-theory', 'functional-analysis', 'functional-calculus']"
3058787,Find a first integral of an ODE system,"I have the system $$ \left\{\begin{aligned}
\dot x & = 2xy \\
\dot y & = x+y^2 \\
\end{aligned}\right. $$ and I need to find a first integral $H$ of the system. This is easy if the equation $$\left( x + y^2 \right) {\rm d} x - 2 x y \, {\rm d} y = 0$$ is exact, i.e., if the divergence of the field is $0$ . In this case, the divergence is $4y$ so I need to find an integrating factor $\mu(x,y) $ , but I don't know how to do it, because it doesn't work if I use that $\mu$ is just a function of $x$ or $y$ . Any help is welcome!","['integrating-factor', 'vector-fields', 'ordinary-differential-equations']"
3058806,Linear order of the quotient generated from Vitali relation implies non-measurability of subset of reals,"Vitali relation, $a,b\in\Bbb R;\ a\sim b\iff a-b\in\Bbb Q$ , is used to prove that there exists a non-measurable set of reals: we look at $A=\Bbb R/\sim$ , from each $a\in A$ we take $b_a\in a$ , then $\bigcup_{a\in A}\{b_a\}$ is the desired set. This construction require choice function for the power set of $\Bbb R$ , and without some kind of axiom of choice there is no guarantee such function exists(it can be seen by, for example, Solovay's model). I remember reading the following: In $\sf ZF$ , $\Bbb R/\sim$ has a linear order implies the existence of of non-measurable subset of the reals. This fact will also imply that compactness implies non-measurable set of reals, so my question is: what proof is there for the above theorem?","['axiom-of-choice', 'measure-theory', 'lebesgue-measure', 'set-theory']"
3058840,Real n-by-n Matrices...,"Let $M_n(\mathbb{R})$ denote the vector space of real $n\times n$ matrics, and let $A \in M_n(\mathbb{R})$ . Part (a) of this question says: Suppose $B \in M_n(\mathbb{R})$ such that $AB = I_n$ (the $n \times n$ identity matrix. If $C \in M_n(\mathbb{R})$ such that $CA = 0$ , then prove $C = 0$ . I have already proven part (a). Part (b) asks: Assume there exists a least positive integer $m$ such that $t_0I + t_1A + \dots + t_mA^m = 0$ for some $t_0, \dots, t_m \in \mathbb{R}$ with $t_m \neq 0$ . Also, suppose that $AB = I_n$ for some $B \in M_n(\mathbb{R})$ .Prove that $t_0 \neq 0$ . (Hint: Use the result from part (a)). My idea is to use induction on $m$ . That is, suppose $$t_0I = 0.$$ But this implies that $t_0 = 0$ since $I$ is the identity. But we could see this as \begin{align*}
t_0I &= 0
\\
t_0AB &= 0
\\
t_0CAB &= 0
\\
t_0C &= 0.
\end{align*} But I don't think this is the right approach. So I have a few questions: (i) Is this the correct approach? (ii) How do I use the result from part (a) properly? (iii) What's a good resource for these types of questions? The book that I am using is ""Linear Algebra Done Right by Sheldon Axler"". I am studying for my linear algebra comp in a few weeks so any help is appreciated!","['matrices', 'linear-algebra', 'vector-spaces']"
3058856,"Why do the properties of determinants (used to calculate determinants from multiple matrices) apply not only to rows, but to columns as well?","A set of rules in my textbook is as follows: a. If $A$ has a zero row (column), then $\det A = 0$ b. If $B$ is obtained by interchanging two rows (columns) of $A$ , then $\det B = -\det A$ c. If $A$ has two identical rows (columns), then $\det A = 0$ d. If $B$ is obtained by multiplying a row (column) of $A$ by $k$ , then $\det B = k\cdot\det A$ e. If $A$ , $B$ , and $C$ are identical except that the $i$ -th row (column) of $C$ is the sum of the $i$ -th rows (columns) of $A$ and $B$ , then $\det C = \det B + \det A$ f. If $B$ is obtained by adding a multiple of one row (column) of $A$ to another row (column), then $\det B = \det A$ I don't understand why ""column"" is in parentheses after every instance of row. Is that the same as saying, for example with clause a: ""if $A$ has a zero row or a zero column, then $\det A = 0$ ""? As in, it's saying that column and row can be used interchangably in the statement, as the statement holds true either way? If the above interpretation is correct, then how? Why would these statements that apply to rows also apply to columns. The only situation I could see it applying is if the matrix is symmetrical, but the question doesn't specify that, it only says that the matrix is square. Any help is appreciated.","['matrices', 'determinant', 'linear-algebra']"
3058878,Problem of rooms,A rectangle is divided into some smaller rectangles.Each two adjacent rectangles share a door which connects them.Prove that we can start from one of the small rectangles and pass them all without crossing a rectangle more than once.,"['graph-theory', 'recreational-mathematics', 'problem-solving', 'discrete-mathematics']"
3058880,Convert in a Sturm-Liouville form $y''+R(x)y'+(Q(x)+\lambda p(x))y=0$,"Convert in a Sturm-Liouville form $$y''+R(x)y'+(Q(x)+\lambda P(x))y=0\tag1$$ My attempt: The form of Sturm-Liouville is: $$\frac{d}{dx}[r(x) \frac{dy}{dx}]+(q(x)+\lambda p(x))y=0\tag2$$ For obtain this, we need multiply for $\mu(x)$ the ODE $(1)$ . This result in: $$\mu y''+\mu R(x)y'+(\mu Q(x)+\lambda \mu P(x))y=0 \tag3$$ I need rewrite the first term of $(3)$ . Here, i'm stuck. I don't have a clear idea of how rewrite and then proceed for solve the exercise. Can someone help me?","['sturm-liouville', 'ordinary-differential-equations']"
3058883,Every $\mathbb{Z}/6\mathbb{Z}$-module is projective,"I have to prove that every $\mathbb{Z}/6\mathbb{Z}$ -module is projective. I've found already this question Prove that every $\mathbb{Z}/6\mathbb{Z}$ -module is projective and injective. Find a $\mathbb{Z}/4\mathbb{Z}$ -module that is neither. but I haven't defined what does it mean to be Artinian or semisimple: the proof should be based just on the equivalent definitions of projective modules (exactness of the covariant Hom functor, being a direct summand of a free module, lifting property and split sequences ending in the module). My idea is to use the fact that $\mathbb{Z}/6\mathbb{Z} \cong \mathbb{Z}/2\mathbb{Z} \bigoplus \mathbb{Z}/3\mathbb{Z}$ , these two submodules are projective and they are fields, hence all $\mathbb{Z}/2\mathbb{Z}$ and $\mathbb{Z}/3\mathbb{Z}$ -modules are free. But I don't know if taken any $\mathbb{Z}/6\mathbb{Z}$ -module I can ""decompose"" it in a sum of a $\mathbb{Z}/2\mathbb{Z}$ -module and a $\mathbb{Z}/3\mathbb{Z}$ -module.","['projective-module', 'abstract-algebra', 'modules']"
3058888,Kendall's Tau of bivariate normal,"Prove Kendall's tau of a bivariate normal is given by $$\rho_\tau (X_1,X_2)=\frac{2}{\pi}\arcsin\rho$$ I can derive the bivariate normal as $$F(x_1,x_2)=\frac{1}{2\pi\sqrt{1-\rho^2}}e^{-\frac{1}{2}x_1\Sigma^{-1}x_2}$$ where, for simplicity, I am assuming $X_1$ and $X_2$ have mean $0$ .  I also am aware that the formula for Kendall's tau involves an integral over some domain involving $X_1$ , $X_2$ , and $\rho$ , multiplied by $4$ . So it seems like all the pieces are there; the integral should result in the answer, if only the integral over the exponential term w.r.t. $X_1$ and $X_2$ were $1$ .  But this is not the case, so I am stuck.","['integration', 'correlation', 'statistics', 'probability']"
3058891,"Definitions of ""linearly normal"" variety","I wish I understood the explanation of linear normality on Wikipedia a bit better, and it seems there's actually a mistake at one point. The variety $V$ in its projective embedding is projectively normal if its homogeneous coordinate ring $R$ is integrally closed. This condition implies that $V$ is a normal variety, but not conversely: the property of projective normality is not independent of the projective embedding, as is shown by the example of a rational quartic curve in three dimensions.  Another equivalent condition is in terms of the linear system of divisors on $V$ cut out by the tautological line bundle $L$ on projective space, and its d th powers for d = 1, 2, 3, ...; when $V$ is non-singular, it is projectively normal if and only if each such linear system is a complete linear system. I have no intuition for what it means for the homogenous coordinate ring to be integrally closed. I also don't have any intuition for this ""complete linear system"" condition. That would be okay if I were sure I understood this: In a more geometric way one can think of $L$ as the Serre twist sheaf $O(1)$ on projective space, and use it to twist the structure sheaf $O_V$ k times, for any k . Then $V$ is called k -normal if the global sections of $O(k)$ map surjectively to those of $O_V(k)$ for a given k . This is great except for one issue.  Isn't $O(1)$ the sheaf of sections of the dual of the tautological line bundle?  Yet here Wikipedia seems to be claiming it's the sheaf of sections of $L$ , which in the previous passage it claimed was the tautological line bundle! I think this is just a mistake on their part.  I think they should say sections of $L^*$ give the Serre twist sheaf $O(1)$ .  I'd like to correct this if it's wrong... but I don't understand the previous passage well enough to know if they wanted the tautological line bundle or its dual back there. Anyway, going on: If $V$ is 1-normal it is called linearly normal , and projective normality is the condition that $V$ is k -normal for all k ≥ 1. Is this way of stating projective normality only true for normal varieties, or for all varieties? This Math Stackexchange answer says it's only true for normal varieties. Linear normality may be said geometrically: $V$ as projective variety cannot be obtained by an isomorphic linear projection from a projective space of higher dimension, except in the trivial way of lying in a proper linear subspace. This sounds nice and geometrical, but I don't quite understand it.   What's a ""linear projection from a projective space of a higher dimension""?   A linear projection from a vector space of higher dimension to one of lower dimension has a nontrivial kernel so it doesn't give a regular map between their projective spaces: I've been meaning to ask what sort of map we call this partially defined map.   (A rational map I guess?)   But I guess sometimes it maps a subvariety of the higher-dimensional projective space isomorphically to a subvariety of the lower-dimensional one?   Is that the idea?",['algebraic-geometry']
3058939,Twin Prime Formula,"I have a function involving polynomials and the centre of the Binomial Triangle and I'd like to prove that the function produces a positive integer infinitely many times. I don't have any interest in what values the integers take so much, merely that they exist. The function I have is: $$f(n) = \dfrac{15n^5+23n^4-20n^3-56n^2-48n-16}{n^3(n+1)(n+2)^4}\begin{pmatrix}2n \\ n \end{pmatrix} + 4\dfrac{3n^2+6n+4}{n^3 (n+2)^3}$$ The only method I have thought of is that I could try to prove that $\sin\left(\pi f(n)\right)$ has an infinte number of roots. But that feels like kicking the can down the road as I don't know how to do that either! Thank you for any and all help. Ben Using partial fractions I get: $$f(n) = \frac{\left( 4n^3+28n^2+84n+76 \right) \begin{pmatrix} 2n \\ n \end{pmatrix} - 2n-4}{(n+2)^4} - \frac{\begin{pmatrix} 2n \\ n \end{pmatrix} - 2}{n^3} - \frac{4\begin{pmatrix} 2n \\ n \end{pmatrix}}{n+1} $$ From here I can find conditions for each fraction separately. $\frac{\begin{pmatrix} 2n \\ n \end{pmatrix} - 2}{n^3} \in \mathbb{N} \implies n \text{ is prime > 3   (I found this on A000984)}$ $\frac{4\begin{pmatrix} 2n \\ n \end{pmatrix}}{n+1} \in \mathbb{N} \implies n \in \mathbb{N} \text{  (Always true)}$ $$f(n) = \frac{\left( 4n^3+28n^2+84n+76 \right) \begin{pmatrix} 2n \\ n \end{pmatrix} - 2n-4}{(n+2)^4} - \color{Blue}{\frac{\begin{pmatrix} 2n \\ n \end{pmatrix} - 2}{n^3} - \frac{4\begin{pmatrix} 2n \\ n \end{pmatrix}}{n+1}} $$ This leaves the final condition: $\frac{\left( 4n^3+28n^2+84n+76 \right) \begin{pmatrix} 2n \\ n \end{pmatrix} - 2n-4}{(n+2)^4} \in \mathbb{N} \\ \implies \left( 4n^3+28n^2+84n+76 \right) \begin{pmatrix} 2n \\ n \end{pmatrix} \equiv 2n+4\pmod{n^4+8n^3+24n^2+32n+16}$ This seems to hold true when $n+2$ is a prime. So if this function outputs an infinite number of integers, the twin-prime conjecture should be true.
If $n$ is the lower of a pair of twin primes, then $f(n)$ is an integer.","['number-theory', 'twin-primes', 'integers', 'factorial']"
3058952,Using a gamblers race to approximate $\pi$,"Imagine two wealthy gamblers start tossing their own separate fair coins, winning 1\$ on heads and losing 1\$ on tails. Both start at 0\$ and have infinite bank balances. Both of them want to get to k\$. What is the probability that they will both reach their targets on the same toss? Based on this question we see that the answers to all such questions take the form $A+\frac{B}{\pi}$ . Here, we're strictly focusing on draws. First, we know that the stopping time (probability he'll reach his target first time on toss $2t+k$ ) for any one gambler is given by: $$a_k(t) = \frac{k}{k+t}\frac{{2t+k-1 \choose t}}{2^{2t+k}}$$ Now, the probability of an overall draw is simply the probability both will reach their target on toss $2t+k$ , summed over all possible values of $t$ . $$D_k = \sum\limits_{t=0}^{\infty} \left(\frac{k}{k+t}\frac{{2t+k-1 \choose t}}{2^{2t+k}}\right)^2$$ Mathematica can't find a nice closed form expression for the summation above (if you can, I'll be very impressed indeed). However, plugging various values of $k$ in we find that the answer always takes the form: $$D_k = \frac{E_k}{F_k \pi} - G_k$$ Where $E_k$ , $F_k$ and $G_k$ are all integers. Plugging the first few values of $G_k$ (calculated using Mathematica) into OEIS, I got the sequence A002002 . This means that: $$G_k = \sum\limits_{l=0}^{k-1} {k \choose l+1} {k+l \choose l}$$ However, I haven't been able to find corresponding expressions for $E_k$ and $F_k$ . Can anyone help with this? We can use it to get an expression for $\pi$ since $D_{\infty} = 0$ Here are the first few expressions for $D_k$ . $$D_1 = \frac{4}{\pi}-1$$ $$D_2 = \frac{16}{\pi}-5$$ $$D_3 = \frac{236}{3 \pi}-25$$ $$D_4 = \frac{1216}{3 \pi} - 129$$ $$D_5 = \frac{32092}{15 \pi} - 681$$ $$D_6 = \frac{172144}{15 \pi} - 3653$$ $$D_7 = \frac{1307924}{21 \pi} - 19825$$ $$D_8 = \frac{7161088}{21 \pi} - 108545$$ $$D_9 = \frac{592194476}{315 \pi} - 598417$$ $$D_{10} = \frac{3282949168}{315 \pi} - 3317445$$ $$D_{11} = \frac{40221561524}{693 \pi} - 18474633$$ $$D_{12} = \frac{224841634624}{693 \pi} - 103274625$$ Unfortunately, Mathematica gives up providing nice expressions in terms of $\pi$ , $D_{13}$ onwards. The idea is courtesy /u/boyobo on this reddit thread .","['summation', 'binomial-coefficients', 'pi', 'combinatorics', 'probability']"
3058990,"$[0, 1]\setminus \mathbb Q$ can't be exhausted by Jordan sets","We wish to show that $[0, 1]\setminus \mathbb Q$ can't be exhausted by Jordan sets. What I mean by this is that there's no nested sequence of Jordan sets $J_1 \subseteq J_2 \subseteq \dots$ such that $\bigcup_{k=1}^{\infty}J_k = [0,1]\setminus\mathbb Q$ Jordan in this sense means Jordan Measurable (boundary is negligible) Sadly, the fact that the boundary of the union is a subset of the union of the boundaries is only true for finite union, else this would be piece of cake. How would you tackle this? It may be related to improper integration","['general-topology', 'improper-integrals', 'measure-theory']"
3058993,Finding the monotonicity of simple sequence - how to?,"I'm trying to find the monotonicity (whether it's increasing, decreasing or non-existeng) of such simple sequence: $$a_{n} = \sqrt[n]{2^n+3^n}$$ $$\frac{a_{n}}{a_{n+1}}=\frac{\sqrt[n]{2^n+3^n}}{\sqrt[n+1]{2^{n+1}+3^{n+1}}}$$ I have dealt with such exercises before without problems. This one I have no idea how to proceed further. Help is appreciated, thanks.","['limits', 'sequences-and-series', 'real-analysis']"
3059020,Integral with two different answers using real and complex analysis,"The integral is $$\int_0^{2\pi}\frac{\mathrm dÎ¸}{2-\cosÎ¸}.$$ Just to skip time, the answer of the indefinite integral is $\dfrac2{\sqrt{3}}\tan^{-1}\left(\sqrt3\tan\left(\dfracÎ¸2\right)\right)$ . Evaluating it from $0$ to $ 2 \pi$ yields $$\frac2{\sqrt3}\tan^{-1}(\sqrt3 \tanĎ€)-\frac2{\sqrt3}\tan^{-1}(\sqrt3 \tan0)=0-0=0.$$ But using complex analysis, the integral is transformed into $$2i\int_C\frac{\mathrm dz}{z^2-4z+1}=2i\int_C\frac{\mathrm dz}{(z-2+\sqrt3)(z-2-\sqrt3)},$$ where $C$ is the boundary of the circle $|z|=1$ . Then by Cauchy's integral formula, since $z=2-\sqrt3$ is inside the domain of the region bounded by $C$ , then: $$2i\int_C\frac{\mathrm dz}{(z-2+\sqrt3)(z-2-\sqrt3)}=2Ď€i\frac{2i}{2-\sqrt3-2-\sqrt3}=2Ď€i\frac{2i}{-2\sqrt3}=\frac{2Ď€}{\sqrt3}.$$ Using real analysis I get $0$ , using complex analysis I get $\dfrac{2Ď€}{\sqrt3}$ . What is wrong?","['complex-analysis', 'definite-integrals', 'cauchy-integral-formula']"
3059024,"For any positive integer $n>3$, there exists at least $1$ integer $k$ such that $n+k$ and $n-k$ are primes.","How to prove the following conjecture: For any positive integer $n>3$ , there exists at least $1$ integer $k$ such that $n+k$ and $n-k$ are both primes. Any hint, idea or reference would be greatly appreciated!","['number-theory', 'prime-gaps', 'prime-numbers']"
3059035,Is the differential forms perspective on $dx$ incompatible with the technique of implicit differentiation?,"Suppose $$x^2 + y^2 = 5^2.$$ We're trying to find $dy/dx$ at $(3,4).$ Applying $d$ to both sides: $$2x dx + 2y dy = 0$$ Or in other words: $$2x dx + 2y dy = 0dx + 0dy$$ Since the covectors $dx_p$ and $dy_p$ form a basis for the cotangent space at any $p \in \mathbb{R}^2$ , hence $2x = 0$ and $2y = 0.$ Hence $x = 0$ and $y = 0$ . Ergo $0^2 + 0^2 = 5^2$ , a contradiction. Question. Does this mean that the differential forms perspective on $dx$ is incompatible with the technique of implicit differentiation? If not, why not? If so, what definition of $dx$ can be used to avoid this issue?","['calculus', 'implicit-differentiation', 'differential-topology', 'differential-forms', 'differential-geometry']"
3059081,Prove that there are no integer solutions to this equation,"I would like to know if it is possible to prove that there are no integer solutions to: $3n(4x^3-n^3)=y^2$ , where $x$ , $y$ and $n$ are all positive integers and $x>n$ . I have no idea how to start, so any comments are welcome. Thank you and regards,
Marcos.","['number-theory', 'diophantine-equations']"
3059090,Finding the area of an isosceles right triangle given its hypotenuse,"I was doing a problem in which I was told the lengths of all sides of an isosceles triangle and asked to find the area. I solved the problem by dividing the isosceles triangle into two equal triangles to find the height which I used in the area formula for the original triangle. Looking at the answer, my method resulted in the correct value but, it seems I could have used the legs of the isosceles triangle (both 8) as the base and height and skipped finding the height. Why does that shortcut work?
The question is below: If the hypotenuse of an isosceles right triangle is $8 \sqrt 2$ , what is the area of the triangle? (A) 18 (B) 24 (C) 32 (D) 48 (E) 64","['triangles', 'geometry']"
3059108,Let $\{a_n\}$ be a sequence of positive numbers and $b_{n} = \frac{a_{n}}{(a_{1}+...+a_{n})^{2}}$. Prove $\sum_{n=1}^{\infty}b_{n}$ converges.,"Let $\{a_n\}_{n=1}^{\infty}$ be a sequence of positive numbers and let $b_{n} = \frac{a_{n}}{(a_{1}+...+a_{n})^{2}}$ for n $\in\mathbb{N}$ . Prove that $\sum_{n=1}^{\infty}b_{n}$ is a convergent series. 
I'm stuck on how to start this problem. I've considered the limit comparison test, but it hasn't worked out for me. I know I can assume $\{a_{n}\}$ and $\{b_{n}\}$ are positive, so maybe I need to show $\{b_{n}\}$ has an upper bound and apply the positive series test. Any help is appreciated. Thank you!","['calculus', 'sequences-and-series', 'real-analysis']"
3059124,Suppose $\sum_{n=1}^{\infty}\sqrt{{a_{n}}/{n}}$ is convergent. Prove that $\sum_{n=1}^{\infty}a_{n}$ is also convergent.,"Let $\{a_{n}\}$ be a decreasing sequence of non-negative real numbers. Suppose $\sum_{n=1}^{\infty}\sqrt{\frac{a_{n}}{n}}$ is convergent. Prove that $\sum_{n=1}^{\infty}a_{n}$ is also convergent.
My thought is to use the direct comparison test but I think I'm struggling with showing that $a_{n}\leq\sqrt{\frac{a_{n}}{n}}$ $\forall$ n $\in\mathbb{N}$ .
Any help would be great. Thank you!","['calculus', 'convergence-divergence', 'real-analysis']"
3059139,Solutions of $2^a+5^b=c^2$,"I tried to solve this question using this way: $a$ must be even, because if it's odd the equation have no solution. Let $a=2n$ , so \begin{align*}
2^{2n}+5^b &= c^2 \\
(2^n)^2+5^b &= c^2 \\
5^b &= c^2-(2^n)^2 \\
5^b &= (c-2^n)(c+2^n)
\end{align*} Only one of $c-2^n$ and $c+2^n$ can be divided by 5, $c-2^n \neq c+2^n$ , so $c-2^n=1$ and $c+2^n=5^b$ .
From this equations, I got $1+2^{n+1}=5^b$ .
But I don't know how to continue.","['number-theory', 'square-numbers', 'diophantine-equations']"
3059145,Prove This Function is Finite Almost Everywhere,"Let $F$ be a closed subset of $[0,1]$ of positive Lebesgue measure. Let $\delta(x)$ be defined as $\delta(x) = \operatorname{dist}(x, F)$ . Consider $$M(x) = \int_{0}^{1}\frac{\delta(y)}{|x -y|^2} \, dy$$ Prove that for almost every point $x \in F$ , $M(x) < \infty$ . My thoughts so far are the following : We wish to show that $M \in L^{1}(F)$ , which is more than sufficient to complete the proof. Thus, consider $$\int_{F} \int_{0}^{1}\frac{\delta(y)}{|x -y|^2} \, dy \,dx$$ From here, I would like to proceed by using Fubini Theorem to switch the order of integration to $$\int_{0}^{1}\int_{F} \frac{\delta(y)}{|x -y|^2} \, dx \,dy$$ From here, I am not really sure what to do.","['measure-theory', 'lebesgue-measure']"
3059150,Open linear subspace of a Hilbert space.,"Does there exist any open linear (vector) subspace of a Hilbert space? I could not think of any example. Actually, I was reading the book by Simmons, there almost in every theorem it assumed that ""If M is a closed linear subspace"".It seemed natural to me to think about subspaces which are not closed. I have an got an example which is not closed:
Take the Hilbert space H = L^[0,1], with L^2 norm and the subspace set of all polynomials , it is not closed because it's closure is H and not open can be found here Set of all polynomials on [0, 1/2] is not open in C[0, 1/2] . Then I asked myself an example of  to think of an open set. But I could lead myself nowhere, as I am not familiar with infinite dimensional vector space. Not closed does not necessarily mean open.",['functional-analysis']
3059204,"Set Theory: Union over sets satisfying criterion, rigorous definition?","I'm trying come to a rigorous understanding of certain types of set unions. For purposes of this question I'm comfortable with set unions written as $$
\mathcal{A} = \bigcup A = \{x:\exists_a(x\in a \wedge a\in A)\}
$$ but I am not comfortable with unions expressed using other types of notations.. I am trying to understand Munkres Lemma 13.1 concerning a characterization for the basis ( $\mathcal{B}$ ) of a topology*. In fact, I am stuck at the same point as the asker in this question: Proof of Lemma 13.1 in Munkres . We are considering an open set $U$ and the proof has a step which says for each $x$ in $U$ we know there is a set $B_x$ satisfying $x\in B_x\subset U$ and $B_x \in \mathcal{B}$ . I understand and agree with this statement. The next statement is the problem. That statement says that thus $$
U = \bigcup_{x\in U}B_x
$$ Let Intuitively I very much understand this statement. We've found a $B_x$ for each $x$ and we combine together all of the $B_x$ that we found. Let $$
C = \bigcup_{x\in U}B_x
$$ Clearly each $x$ in $U$ will be in this collection so $U\subset C$ and clearly each element of this collection is a subset of $U$ so $C\subset U$ so clearly $C=U$ . My problem is understanding what is the rigorous definition of the set $C$ in terms of the definition for infinitary unions I have given above. That is, is there some set $b$ such that I can write $$
C = \bigcup b
$$ Where $b$ somehow captures the notion of having one set $B_x\subset U$ inside of it for each $x$ in $U$ ? How would I construct the set $b$ formally? It seems like it is something like constructing a choice function? (something I'm not really familiar with..) edit:
Just a few notes to explain along what lines I am thinking about the problem. It seems like I want something like $$
f:U \rightarrow \mathcal{B}
$$ with $x \in f(x) \subset U$ . Then I would want $b$ to be the range of $f$ which is guaranteed to be a set by the axiom schema of replacement. The problems are 1) I don't know exactly how to construct the function $f$ and 2) I'm not sure if this is an overkill solution to the issue I am describing when there is in fact a much more straightforward definition.. *However my question doesn't really have to do with this particular proof but rather a general notion about set unions so I don't want to get bogged down in the details of this particular proof.","['elementary-set-theory', 'general-topology']"
3059225,"Why doesn't the definition ""$p$ is called 'prime' if $p\mid ab\implies p\mid a\,\text{ or }\,p\mid b$"" hold up when we square numbers?","So, I've been given the actual definition of a prime for the first time, as opposed to the definition of an irreducible which I was previously taught (as is customary), it goes as follows: An element $p$ of a ring $R$ is called ""prime"" if $a,b\in R$ and $p|ab\rightarrow p|a$ or $p|b$ $4^2 = 16$ . So inversely $4|16$ . Now let's look at all the combinations of two integers $a,b\in R$ where $ab = 16$ and whether $p|a$ or $p|b$ : $1 * 16$ ( $4|16$ ) $2 * 8$ ( $4|8$ ) $4 * 4$ ( $4|4$ ) By my logic, $4$ is prime. However, as we all know $4 = 2^2$ . But $2$ is not a unit so $4$ is an irreducible. Since the ring of integers is an integral domain $4$ must, therefore, be prime as well. Why does this happen? Edit Thanks for your help everyone. I understand your answers logically and experimentally but not really conceptually. The reason this definition works (from my perspective) because your saying that A number is prime if it necessary to represent its multiples in
  factorisations. Whereby factorisations, I mean $8 = 2^3, 6 = 2*3$ and relevantly $16 = 2^4$ . The answer I had kind-of expected from this question (and was going to include in my original query until I forgot) was that more generally if there exists the product of any amount of numbers that is equivalent to $ab$ and for each of those numbers $n$ , $n$ suffices $p|n$ then $p$ is composite. This makes much more sense to me logically. In the case of $16$ you saying that you don't need $4$ to express $16$ since you can instead use $2*2*2*2$ or $2^4$ to represent the same thing. For this reason, $4$ is composite. By this logic, you don't need to prove it for every multiple of 4, only 1. Have I completely confused myself? Can someone provide a counter-example? Also, could you provide an explanation of why my logic doesn't work? Edit 2 Yes everyone, the correct definition of includes checking the factors of every $ab$ such $p|ab$ . However, as @Vincent and I showed in our respective answers (the former much better) the definition I used is equivalent to the definition everyone else is using in integral domains. I highly suggest you read @Vincent answer as he makes this very clear. Regardless, I'm not accepting any answer that simply says that my definition is wrong when it is actually equivalent.","['examples-counterexamples', 'ring-theory', 'abstract-algebra', 'group-theory', 'prime-numbers']"
3059270,Find all functions satisfying $f(x+1)=\frac{f(x)-5}{f(x)-3}$,Find all functions satisfying $$f(x+1)=\frac{f(x)-5}{f(x)-3}$$ My try: We have $$f(x+1)=1-\frac{2}{f(x)-3}$$ Letting $g(x) =f(x+1)-3$ We get $$g(x+1)=-2-\frac{2}{g(x)}$$ Any clue here?,"['periodic-functions', 'functional-equations', 'algebra-precalculus', 'functions']"
3059328,Proving $(A \cup B) \backslash (A \cap B) = (A \cup C) \backslash (A \cap C) \implies B = C$,Indirect proof. Assume that $B \neq C$ . Therefore I assume without loss of generality  that $\exists x (x \in B \land x \notin C)$ . This leaves us with two possible cases: $x \in A$ . But then $x \notin (A \cup B) \backslash (A \cap B)$ and $x \in (A \cup C) \backslash (A \cap C)$ which contradicts the given equality. $x \notin A$ . But then $x \in (A \cup B) \backslash (A \cap B)$ and $x \notin (A \cup C) \backslash (A \cap C)$ which contradicts the given equality as well. Therefore $B = C$ . Is this proof complete and correct?,"['elementary-set-theory', 'discrete-mathematics']"
3059342,How can I prove the asymptotic equipartition property (AEP) for an identically distributed markov chain?,"$ $ Hi, everyone. I am recently reading the lecture note of EE376a : Information Theory course from Stanford University. This note introduces that we can prove the Asymptotic Equipartition Property (or the Shannon-McMillan-Breiman Theorem) for the case that the given stochastic process $\left\{ X_n \right\}$ is a time-invariant discrete-time Markov chain with a finite state space $\mathcal{X}$ such that every $X_n$ is identically distributed over $\mathcal{X}$ with the distributuion $p$ . The following is the statement. : $$-\frac{1}{n} \log p(X_1, \cdots, X_n) \rightarrow H(X_2|X_1)$$ in probability as $n \rightarrow \infty$ . The note introduces the proof of this statement by using Weak Law of Large Numbers for weak dependency. : Let $\{ Y_n \}$ be a sequence of identically distributed random variables such that $$\lim_{n \rightarrow \infty} \frac{1}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} Cov[Y_i, Y_j] = 0.$$ Then, $\frac{1}{n} \sum_{i=1}^{n} Y_i \rightarrow \mathbb{E}[Y_1]$ in probability as $n \rightarrow \infty$ . Thus, we let $Y_k := \log p(X_k |X_{k-1})$ for $k \geq 2$ and $Y_1 := \log p(X_1)$ . Therefore, it suffices to verify that $$\lim_{n \rightarrow \infty} \frac{1}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} Cov[Y_i, Y_j] = 0 \ \cdots (\star)$$ and the statement comes from the WLLN for weak dependency. Now, here is my question. How can I prove the part $(\star)$ ? Please, share some good ideas for this problem.","['statistics', 'probability', 'information-theory']"
3059400,"Approximating left continuous process $(L_t)_{0 \leq t \leq T}$ uniformly on $[0,T]$ by step functions on the Dyadics","The question is closely related to optional quadratic variation. If I have a left-continuous adapted stochastic process $(L_t)_{0 \leq t \leq T}$ with $L_0 = 0$ on the probability space $(\Omega, \mathcal{F},P)$ , is it possible to approximate it uniformly on $[0,T]$ on the dyadics by step functions, i.e. if $D_n=2^{-n} T \mathbb{N} \cap [0,T]$ is the set of all $n$ -th dyadic points, do I have the following convergence $$
\sup_{t \in [0,T]}\left|L_t(\omega) - \sum_{t_i \in D_n}L_{t_i}(\omega) 1_{((t_i,t_i+1]]}(t, \omega)\right| \rightarrow 0, \text{ for } n \rightarrow \infty
$$ for almost every $\omega \in \Omega$ ? The function $1_{((t_i,t_{i+1}]]}$ denotes the left half open stochastic interval. Thanks a lot in advance!","['stochastic-analysis', 'stochastic-calculus', 'stochastic-processes', 'probability-theory', 'probability']"
3059403,Computing the differential of a certain smooth map,"Let $M \subseteq \mathbb{R}^k$ be an embedded submanifold of $\mathbb{R}^k$ , with dim $M=n$ . Let $v$ be in $\mathbb{S}^{k-1}$ , and let $P_v:\mathbb{R}^k\to(\mathbb{R}v)^{\bot}$ defined by $P_v(x)=x-<x,v>v$ where $<x,v>=x^1v^1+\dots+x^kv^k$ is the Euclidean dot product and $(\mathbb{R}v)^{\bot}$ is the vector space of the vectors in $\mathbb{R}^k$ orthogonal to $v$ . We know that $(\mathbb{R}v)^{\bot}$ has dimension $k-1$ as a real vector space, so it is isomorphic to $\mathbb{R}^{k-1}$ . Question 1) If I want to consider $(\mathbb{R}v)^{\bot}$ as a smooth manifold, I can choose an isomorphism between $(\mathbb{R}v)^{\bot}$ and $\mathbb{R}^{k-1}$ and declare this to be a diffeomorphism, right? Or, better, is there a canonical identification between $(\mathbb{R}v)^{\bot}$ and $\mathbb{R}^{k-1}$ ? Now, (assuming the answer to Question 1 is affirmative), I have that $P_v:\mathbb{R}^k\to(\mathbb{R}v)^{\bot}\simeq \mathbb{R}^{k-1}$ is a map between two smooth manifolds. Question 2) How can I show that this map is smooth? Do I have to calculate it in local coordinates? So do I have to explictly choose an isomorphism between $(\mathbb{R}v)^{\bot}$ and $\mathbb{R}^{k-1}$ and then calculate the map in local coordinates? Let $\Phi_v:M\to (\mathbb{R}v)^{\bot}$ be $P_v\circ \iota_M$ with $\iota_M$ the inclusion map of $M$ in $\mathbb{R}^k$ . So, since $P_v$ is smooth, then also $\Phi_v$ is smooth. Let $p\in M$ and $X\in T_pM$ . Then $d(\iota_M)_p(X)=\sum_iw^i \partial_i|_p\in T_p\mathbb{R}^k$ for some $w\in \mathbb{R}^k$ . My notes say that $$d(\Phi_v)_p(X)=\sum_iP_v(w)^i\partial_i|_p$$ Question 3) How can I prove the above equation? How should I imagine $T_{\Phi_v(p)}((\mathbb{R}v)^{\bot})$ ? Who is a (canonical) basis for $T_{\Phi_v(p)}((\mathbb{R}v)^{\bot})$ ? All I can see is that $$d(\Phi_v)_p(X)=d(P_v)_p(\sum_iw^i\partial_i|_p)=\sum_iw^id(P_v)_p(\partial_i|_p)$$ where the last $=$ is by the linearity of the differential. Please use simple language since I'm a beginner in this subject, do full calculation if needed, and also, if you think I lack some knowledge of some topic of smooth manifold theory (useful to better understand your answer to my question), please let me know.","['multivariable-calculus', 'smooth-functions', 'smooth-manifolds', 'differential-geometry']"
3059417,Sequential compactness and filters,"I'm trying to work with the many equivalent definitions of compactness for a topological space $X$ ; in particular, Every (proper) filter on $X$ has a (proper) convergent refinement. I'll be referring to this property as filter-compactness for convenience, and also because it looks very much like sequential compactness. *Edit to include some other definitions here: A filter on $X$ is said to be proper if it does not have the empty set as a member. Let $X$ be a set and let $\mathcal{F}$ be a filter on $X$ . If $\mathcal{G}$ is another filter on $X$ such that $\mathcal{F}$ is a subset of $\mathcal{G}$ , then $\mathcal{G}$ is said to be a refinement of $\mathcal{F}$ . A filter $\mathcal{F}$ on a topological space $X$ is convergent if there exists $x \in X$ such that $\mathcal{F}$ refines the neighbourhood filter $N_x$ of $x$ , which is defined by $$ N_x = \{\, A \subseteq X \mid A \text{ contains an open neighbourhood of $x$ in $X$}\, \} $$ It is clear to me that filter-compactness and sequential compactness are equivalent for metric spaces because both are equivalent to open-set compactness. However, I'm hoping for a direct proof, since the two definitions seem so similar. Here's what I've managed: Let $X$ be a metric space and suppose that $X$ is filter-compact. Let $(x_n)_{n \in \mathbb{N}}$ be a sequence in $X$ , and let $\mathcal{F}$ denote the elementary filter associated with $(x_n)_{n \in \mathbb{N}}$ , which is defined by $$\mathcal{F} = \{\, A \subseteq X \mid A \text{ contains all but finitely many of the } x_n\, \}.$$ Since $X$ is filter-compact, there is a convergent refinement $\mathcal{G}$ of $\mathcal{F}$ . It'd be good if $\mathcal{G}$ were the elementary filter associated with some subsequence. But that doesn't seem to be true in general, considering refinements can be very large. I'm not able to get anything for the converse either. Following notation used in Eric's answer: Replace the sets $A_n \in \mathcal{G}$ by their closures in $X$ . There exists $r > 0$ such that the open ball $B(x, r)$ is a subset of $A$ . Since $d(A_n) \to 0$ , we have $d(\bigcap_{k=1}^n A_k) \to 0$ as well. Thus there exists $N \in \mathbb{N}$ such that $d(\bigcap_{k=1}^N A_k) < r/2 < r \le d(A)$ . The set $B := \bigcap_{k=1}^N A_k$ is closed in $X$ and the tail sequence $(x_n)_{n \ge N}$ is contained in $B$ , so the limit point $x$ belongs to $B$ . It follows from $d(B) < r$ that we have $B \subseteq A$ . Finally, since $B$ is a member of $\mathcal{G}$ , we have $A \in \mathcal{G}$ also. This suggests that $\mathcal{G}$ is convergent (to $x$ ), a contradiction.","['filters', 'general-topology', 'compactness']"
3059464,What is the relation between these two functions? Are they isomorphic?,"Suppose I have an infinite sequence $a_{i}\in A$ , and two functions, $\Theta:\mathbb{N}\rightarrow \mathbb{N}$ , and $\vartheta: a_{i}\mapsto a_{j}$ , so that $\forall (i\geq 1):\{ \vartheta(a_{i})=a_{(\Theta(i))} \}$ .  Clearly, $\vartheta$ is operating on the indexes of a sequence (i.e., $\mathbb{N}$ ) in exactly the same way that $\Theta$ is operating on $\mathbb{N}$ .  Do we say that $\vartheta$ and $\Theta$ are ""isomorphic""?  ""homomorphic""?  What term(s) do we use to describe the relationship between $\vartheta$ and $\Theta$ ?","['definition', 'functions', 'sequences-and-series']"
3059488,How to solve this 4th order ODE with polynomial coefficients?,"Write the general solution 
  for $ (x^2) y'''' + (3x^2-2x)y''' + (3x^2-4x+2)y'' +(x^2-2x+2)y' 
 = 0 $ I tried to guess a solution and use the fact that i can decrease the ODE to less power ( to $y'''$ ) by using the Wronskian. I guessed that $ e^{-x} $ is a solution. Is it the way we solve this kind of equations? It's a homework question so i guess (i / you) can solve it. Euler ODE doesn't work here . Can you help me with the solutions i got 4 solutions : ( after solving Euler equation and moving to $ v''' $ . $y'(x) = \{ e^{-x}  ,~  \frac{x^3}{3}e^{-x} ,~ \frac{x^2}{2}e^{-x}   \}$ or any linear combination of those, uniqueness theorem doesn't apply here near $x=0$",['ordinary-differential-equations']
3059518,"Prove that Gramian matrix is Invertible iff $(v_1,...,v_k) $ is linearly independent","Prove that Gramian matrix is Invertible iff $(v_1,...,v_k)  $ is linearly independent $G=G(v_1,...,v_k) = [\left\langle v_i,v_j\right\rangle ]_{i,j=1}^k $ I have great idea to calculate $\det G$ and show that if $(v_1,...,v_k)  $ is linearly independent then $\det G \neq0$ and vice versa. Plan sounds good (?) but how to calculate $\det$ of this? \begin{vmatrix} \langle v_1,v_1\rangle & \langle v_1,v_2\rangle &\dots & \langle v_1,v_n\rangle\\
 \langle v_2,v_1\rangle & \langle v_2,v_2\rangle &\dots & \langle v_2,v_n\rangle\\
\vdots&\vdots&\ddots&\vdots\\
 \langle v_n,v_1\rangle & \langle v_n,v_2\rangle &\dots & \langle v_n,v_n\rangle\end{vmatrix} .
Probably I should use some scalar product propeties but it isn't clear for me how can I do that.","['matrices', 'inner-products', 'linear-algebra']"
3059544,"$X_1,..,X_n$ i.i.d random variable and discrete, local limit theorem","Let $X_1,..., X_n$ be i.i.d discrete random variables which take their value in $\mathbb{Z}$ with a non trivial and finite support. Let $S_n = X_1+...+ X_n$ Prove the existence of $ 0 < C_1 < C_2 < \infty$ such that for all $ n \geq 1$ : $$ C_1/\sqrt{n} \leq \sup_{k \in \mathbb{Z}} \mathbb{P}(S_n = k) \leq C_2/\sqrt{n}$$ I know that this can be proved using the central limit theorem yet we didn’t see this theorem in class so this exercise can be solved without using CLT. So far here are my thoughts : The fact that it’s $\sqrt{n}$ comes from the fact that the standard deviation of $S_n$ is $\theta \sqrt{n}$ .
Hence one possible strategy is to study the random variable : $\frac{S_n- \mu}{\theta/\sqrt{n}}$ . Yet from now on I dind’t manage finding an upper bound on the probability. For example using Markov inequality I get that : $$\mathbb{P}( \mid \frac{S_n}{n} -\mu \mid \geq \theta/\sqrt{n}) \leq \frac{1}{n}$$ The problem is that it doesn’t help since I can’t say anything when $\mid S_n/n -\mu \mid \leq \theta/\sqrt{n}$ . Thank you !","['probability-limit-theorems', 'probability-theory', 'probability']"
3059555,Whether the induced map in de Rham cohomology is injective,"Let $M, N$ be smooth manifolds, and let $f: M \rightarrow N$ be a surjective submersion, i.e. a surjective smooth map such that the differential $f_{*}$ is also surjective. I have shown that for all $k \geq 0$ , the pullback map of $k$ -forms $$ f^{*} : \Omega^{k}(N) \rightarrow \Omega^{k} (M)$$ is injective. However, the problem now asks me whether the induced map on de Rham cohomology $$  H_{dR}^k (N) \rightarrow H_{dR}^k (M) : [\omega] \mapsto [f^{*} \omega] $$ is also injective ? I was trying to prove this. I took $[\omega] \in H_{dR}^{k} (N)$ and assumed $[f^{*} \omega] = [0]$ . This means $f^{*} \omega \sim 0$ or $$ f^{*} \omega = d \tau $$ for some $(k-1)$ form $\tau$ on $M$ . I want to conclude from this somehow that $[\omega ] = [0]$ or $\omega = d \sigma$ for some $(k-1)$ form $\sigma$ on $N$ . But I'm not sure if the statement is even true. I tried to find a counter example, but couldn't. Any help is appreciated!","['homology-cohomology', 'differential-forms', 'differential-geometry']"
3059565,How to calculate a (possible) chance from a zero-incidence sample?,"This is probably a very simple problem, but I want to make sure I have a correct understanding. I have a sample of $500$ events, in which a complication $C$ didn't occur. How do I calculate a reasonably correct chance for $C$ ?
Would that be just $<1/500$ ? My intuition is that it would be a bit higher, as there is a sampling effect.
Obviously, it is impossible to calculate the chance exactly, but does something like some kind of confidence interval exist for these types of observations? Much obliged, Joris",['probability']
3059617,Questions about Aleph-Aleph-Null,"Note: I apologize in advance for not using proper notation on some of these values, but this is literally my first post on this site and I do not know how to display these values correctly. I recently was looking up facts about different cardinalities of infinity for a book idea, when I found a post made several years ago about $ℵ_{ℵ_0}$ If the infinite cardinals aleph-null, aleph-two, etc. continue indefinitely, is there any meaning in the idea of aleph-aleph-null? In this post people are talk about the difference between cardinal numbers and how $ℵ_{ℵ_0}$ should instead be $ℵ_ω$ . The responses to the post then go on to talk about $ℵ_{ω+1}$ , $ℵ_{ω+2}$ , and so on. Anyways, my understanding of the different values of ℵ was that they corresponded to the cardinalities of infinite sets, with $ℵ_0$ being the cardinality of the set of all natural numbers, and that if set X has cardinality of $ℵ_a$ , then the cardinality of the powerset of X would be $ℵ_{a+1}$ . With this in mind, I always imagined that if a set Y had cardinality $ℵ_0$ , and you found its powerset, and then you found the powerset of that set, and then you found the powerset of THAT set, and repeated the process infinitely you would get a set with cardinality $ℵ_{ℵ_0}$ . So, I guess my question is, in the discussion linked above, when people are talking about $ℵ_{ω+1}$ , how is that possible? Because if you take a powerset an infinite number of times, taking one more powerset is still just an infinite number of times, isn't it? I hope I worded this question in a way that people will understand, and thanks in advance into any insight you can give me about all this.","['elementary-set-theory', 'cardinals']"
3059656,"Does alternating group $A_5$ is a subgroup of $GL(4,\mathbb Z)$?","Does alternating group $A_5$ is a subgroup of $GL(4,\mathbb Z)$ ? I know $A_5$ has a 4-dimensional complex representation. But how to prove $A_5$ is a subgroup or not of $GL(4, \mathbb Z)$ ? In case $GL(4, \mathbb Z)$ has a subgroup isomorphic to $A_5$ ,  then I would like to know corresponding generators of that subgroup? I want to know how many subgroups are there in $GL(4, \Bbb Z)$ isomorphic to $A_5$ . Is there a unique one? Thank you so much in advance.","['group-theory', 'representation-theory']"
3059667,Existence of MLE,"I have a problem with MLE's definition: Casella Berger in Statistical Inference and Nitis Mukhopadhyay in Probability and Statistics said that MLE for a parameter $\theta\in\Theta$ is respectively $\arg\sup_{\theta\in\Theta}\{L(\theta\mid x)\}$ or $\arg\max_{\theta\in\Theta}\{L(\theta\mid x)\}$ . But this estimator is a supremum or a maximum? If it is a supremum why we don't call it supremum likelihood estimator? Conversely if it is a maximum, the likelihood function must be continuous and the parametric space must be compact (sufficient condition for the existence of maximum) What is the truth or the minimal condition for the existence of MLE?","['statistical-inference', 'statistics', 'estimation', 'maximum-likelihood', 'probability']"
3059678,"Proving that $\lim_{n\to\infty}(\int_{a}^{b}f(x)^ndx)^{1/n} = \max_{x\in [a,b]}f(x)$ [duplicate]","This question already has answers here : Finding $\lim\limits_{n \rightarrow \infty}\left(\int_0^1(f(x))^n\,\mathrm dx\right)^\frac{1}{n}$ for continuous $f:[0,1]\to[0,\infty)$ [duplicate] (2 answers) Closed 5 years ago . I'm trying to prove the following statement: $$\lim_{n\to\infty}\left(\int_{a}^{b}f(x)^ndx\right)^{1/n} = \max_{x\in [a,b]}f(x)$$ where $[a,b] \subset \mathbb{R} $ and $f$ is non-negative and continuous. I've tried to prove it in a similar way that we prove that $\displaystyle\lim_{n\to\infty}(a^n+b^n)^{1/n} = b$ if $b>a$ . However, I'm stuck in the end with an iterated limit of the form $\displaystyle\lim_{n\to\infty} \lim_{\epsilon\to 0 } \left(\epsilon^{1/n}\max_{x\in [a,b]}f(x)\right)$ . Is this last expression equal to $\displaystyle\max_{x\in [a,b]}f(x)$ ? If not, could anyone please give me a hint as to how to go about this proof?","['integration', 'limits', 'calculus', 'real-analysis']"
3059684,Norms on Tensor Product of $C^*$- algebras,Suppose $A$ and $B$ are two $C^*$ -algebras. On the algebraic tensor product $A\otimes B$ we can define the maximal and minimal tensor norms which makes $A\otimes B$ a $C^*$ - algebra. what are other possible norms which one define on algebraic tensor product of $C^*-$ algebras to make it again a $C^*$ -algebra? The books I have seen only discusses these two norms while they do discuss many norms on tensor product of operator spaces.Why so?,"['tensor-products', 'c-star-algebras', 'operator-theory', 'functional-analysis']"
3059714,How does one evaluate the multiplication $f(2)\cdot f(3)\cdot f(4)\cdots f(15)$ by formulating?,Suppose $$f : \mathbb{Z}^+ \rightarrow \mathbb{R}$$ $$f(x) = 1-\dfrac{1}{x^2}$$ How does one evaluate the multiplication $\prod_{i=2}^{15} f(i)=f(2)\cdot f(3)\cdot f(4)\cdots f(15)$ ? Here I have to see the trick that directly yields the calculation. How come that we write this using $\Pi$ (product) notation ? I'll be glad to hear your dear thoughts.,"['functions', 'products']"
3059744,Generalizing $\sum_{n=1}^{\infty}\frac{H_n{2n \choose n}}{2^{2n}(2n-1)}=2$,"I was looking at this paper on section [17], $$\sum_{n=1}^{\infty}\frac{H_n{2n \choose n}}{2^{2n}(2n-1)}=2\tag1$$ Let generalize $(1)$ $$\sum_{n=1}^{\infty}\frac{H_n{2n \choose n}}{2^{2n}(2n-1)(2n-3)(2n-5)\cdots [2n-(2k+1)]}\tag2$$ Where $k\ge 0$ I conjectured the closed form for $(2)$ to be $$\sum_{n=1}^{\infty}\frac{H_n{2n \choose n}}{2^{2n}(2n-1)(2n-3)\cdots [2n-(2k+1)]}=\frac{2(-1)^k}{(2k+1)!!(2k+1)}\tag3$$ Here are a first few values of $k=1,2$ and $3$ $$\begin{align}
\sum_{n=1}^{\infty}\frac{H_n{2n \choose n}}{2^{2n}(2n-1)(2n-3)}&=-\frac{2}{9}\tag4\\
\sum_{n=1}^{\infty}\frac{H_n{2n \choose n}}{2^{2n}(2n-1)(2n-3)(2n-5)}&=\frac{2}{75}\tag5\\
\sum_{n=1}^{\infty}\frac{H_n{2n \choose n}}{2^{2n}(2n-1)(2n-3)(2n-5)(2n-7)}&=-\frac{2}{735}\tag6
\end{align}$$ How do we go about to prove this conjecture $(3)?$","['harmonic-numbers', 'closed-form', 'sequences-and-series']"
3059745,Squeezing function defined over infinite range down to finite,"Abstract What I'm generally trying to do is to squeeze the first derivative of the sigmoid function defined over infinite range into finite. I.e. $$f(x)=\frac{1}{1+e^{-x}}$$ This function is heavily used as an activation function for neural networks. It's integral has close relation to another relu activation function which is also heavily used with neural networks: $$\int{f(x)}{dx}=ln(1+e^{-x})-ln(e^{-x})$$ It's derivative is useful in modeling and is similar to normal distribution pdf function: $$\frac{d}{dx}f(x)=\frac{e^{-x}}{(1+e^{-x})^{2}}=df(x)$$ It is also simple to evaluate for computer, it's derivative is expressed in terms of function itself. But $df(x)$ is defined over infinite range which makes it unsuitable for some modeling tasks where the range should be finite. Taking into account the fact that the most of the values close to zero are located outside [-10..10] range, this is shown by the following equation: $$\int_{-\infty}^{\infty}{df(x)}{dx}-\int_{-10}^{10}{df(x)}{dx}=1-\frac{e^{10}-e^{-10}}{(1+e^{10})(1+e^{-10})}=0.00009079573740486882...$$ That means that all of the values outside [-10..10] would introduce minor effect to the shape of function when it's range is squeezed from infinite to finite. So how do we squeeze the range? It can be done through the use of $arctanh(x)$ : That goes as an argument to $df$ function. So when approaching +/-1 arctanh would asymptotically approach +/- $\infty$ thus when used as an argument it will map the argument range from infinite to finite: $$df(arctanh(x))=\frac{\sqrt{1-x^2}}{(1+\frac{\sqrt{1-x^2}}{x+1})^2(x+1)}$$ while the function doesn't even look similar to what was originally intended it is easy to get the shape close through a factor before arctanh(x): $$df(arctanh(x)*6)$$ yields to: thus getting the final equation equal to: $$df(n*arctanh(x))=\frac{(1-x^2)^{\frac n2}}{(1+\frac{(1-x^{2})^{\frac n2}}{(x+1)^n})^2(x+1)^n}=F(x,n).$$ It's interesting to see how $4*F(x,\pi)$ is similar to $\frac{sin(x\pi+\frac{\pi}{2})}{2}+\frac 12$ : Which could essentially serve as yet another way to approximate sine. Problem While playing with $F(x,n)$ I've noticed that it's hard to find values of $n$ that suffice some condition, for instance I want to find $n$ such that it best approximates $\frac{sin(x\pi+\frac{\pi}{2})}{2}+\frac 12$ . Let's define an error function of an approximation: $$err(x, n) = (4·df(n·arctanh(x))-\frac 12·sin(x\pi+\frac{\pi}{2})-\frac 12)^2$$ or $$err(x, n) = (\frac{(1-x^2)^{\frac n2}}{(1+\frac{(1-x^{2})^{\frac n2}}{(x+1)^n})^2(x+1)^n}-(\frac{sin(x\pi+\frac{\pi}{2})}{2}+\frac 12))^2.$$ Then we would need to find $n$ such that: $$\frac{d}{dn}\int_{-1}^{1}{err(x, n)}{dx}=0.$$ Please note that $n$ is real here This is where things start getting messy, an integral over $F(x, n)$ doesn't seem to have an analytical (closed) form nor it is clear how to approach differentiation of such integral due to different integration and differentiation variables. I don't understand how to differentiate such anintegral, so thought it would be better to ask here? Thank you in advance!","['integration', 'optimization', 'derivatives']"
3059753,Generalizing Heron's Formula for Cyclic $n$-gons,"Consider the following extension of Heron's Formula.
For a cyclic $n$ -gon $C$ with side lengths $x_1, x_2, \dots, x_n$ and semi-perimeter $P = \frac{1}{2} \left( x_1 + x_2 + \dots + x_n\right)$ define: $$ M = \sqrt{P^{4-n} (P-x_1)(P-x_2) \dots (P-x_n)} $$ After some experimentation in GeoGebra, it turns out that $M$ is pretty close (but not equal) to the usual area for cyclic $n$ -gons. This suggests that $M$ is less than a constant multiple of area $A$ . Does anyone have an idea of how to prove this? To get a sense of what might happen, for regular $n$ -gons $R_n$ it turns out that: $\displaystyle \lim_{n \rightarrow \infty} M(R_n)/A(R_n) = \pi/e$ . Observe that $M$ is a homogeneous function $M(\lambda C) = \lambda^2 M(C)$ . Area is also homogenous in the same degree $A(\lambda C) = \lambda^2 A(C)$ . Thus, $M/A$ is scale invariant. We can pick a scale to work. Can anyone show that $M$ is bounded on cyclic polygons of area one?","['euclidean-geometry', 'inequality', 'geometric-inequalities', 'geometry']"
3059769,"Let$~${$ f_1 , f_2 , .. , f_n$} be functions lineary indepenedante in $ I$ Prove that every Subset ...","Let $~$ { $ f_1 , f_2 , .. , f_n$ } be functions lineary indepenedante in $ I$ Prove that every Subset of the group is also lineary independante in $ I $ ( interval). how do i prove such claim with differential equations ? say with the wronsekian . here is my prof ( might not be right ) : lets suppose that there exist subset such that without the loss of generality { $ f_1 , f_2 , .. , f_k$ } , $k<n$ dependant. so $ \sum_i^k \alpha_i^*f_i = 0$ such that $\alpha_1^* ,\alpha_2^*,\alpha_3^*,...,\alpha_k^* $ not all $0$ ,suppose at least $\alpha_1^* \not= 0$ . so there exist $\alpha_1^* ,\alpha_2^*,\alpha_3^*,...,\alpha_k^*,0,0,0,0,...,0 $ not all $0$ such that : $ \sum_1^n \alpha_if_i = \sum_1^k \alpha_i^*f_i + 0f_{k+1}+0f_{k+2}+...+0f_{n} = 0$ so its lineary dependant but we know that its not. QED","['functional-analysis', 'ordinary-differential-equations']"
3059796,If $A=A^2$ is then $A^T A = A$?,"I know that for a matrix $A$ : If $A^TA = A$ then $A=A^2$ but is it if and only if ? I mean: is this true that ""If $A=A^2$ then $A^TA = A$ ""?","['matrices', 'transpose', 'linear-algebra', 'symmetric-matrices']"
3059797,Computing the stable manifold for a fixed point,"Compute the stable manifold of $(0,0)$ for the system $$\dot{x}=x-y^3$$ $$\dot{y}=-y$$ Here in my proposed solution My first step isn't necessary for the solution. Although, it is helpful in seeing whether or not the x-axis and y-axis are stable. The Jacobian is $J(x,y)=\begin{pmatrix} \frac{\partial{f}}{\partial{x}} & \frac{\partial{f}}{\partial{y}} \\ \frac{\partial{g}}{\partial{x}} & \frac{\partial{g}}{\partial{y}} \end{pmatrix}=\begin{pmatrix} 1 & -3y^2 \\ 0 & -1 \end{pmatrix}$ . Therefore, $\begin{pmatrix} \frac{dx}{dt} \\ \frac{dy}{dt}  \end{pmatrix}=J(x_0,y_0)\begin{pmatrix} x-x_0 \\ y-y_0  \end{pmatrix}=\begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix}=\begin{pmatrix} x \\ -y \end{pmatrix}$ . So, the x-axis is unstable while the y-axis is stable. To compute the stable manifold, we need to apply the stable manifold theorem. By the definition of $\dot{x}$ and $\dot{y}$ , $$\frac{dy}{dx}=\frac{-y}{x-y^3}$$ Therefore, $$ydx + (x-y^3)dy=0$$ We can now apply the theory of integrating factors which states that $M(x,y)dx
+N(x,y)dy= 0$ . We are given that $M(x,y)=y$ and $N(x,y)=x-y^3$ . If we follow the first example in this pdf , we see that the equations are exact since $$M_y(x,y)=1=N_x(x,y)$$ So, we will therefore find a general solution such that $f(x,y)=C$ . Hence, $$f = \int Mdx + g(y)= \int ydx + g(y)= xy + g(y)$$ But, we know that $$f_y=N=x-y^3=x+g'(y)$$ which implies that $$g'(y)=-y^3$$ and so $$g(y) = \int -y^3dy =\frac{-y^4}{4}+C$$ Hence, $$f(x,y)=xy+\frac{-y^4}{4}=C$$ is the general solution. To avoid singularities in the orbits of $y(x)$ which pass through $(0,0)$ , we should set $C=0$ . Then, $$xy=\frac{y^4}{4}$$ $$4x=y^3$$ $$\sqrt[3]{4x}=y$$ Therefore, $y(x)=\sqrt[3]{4x}$ is the stable manifold. I'm not sure if there is a shorter approach to compute the stable manifold. The solution inside this question doesn't appear to work for this problem. Is this approach correct? Please let me know if there are any better alternatives.","['manifolds', 'proof-verification', 'ordinary-differential-equations']"
3059854,Simple algebra manipulation?,I am currently reading through this guide http://www.math.ucsd.edu/~ebender/CombText/ch-10.pdf on generating functions and I can't figure out how on page three he went from this formula to the next $$\frac{1}{(1-y) - xy} = \frac{(\frac{1}{1-y})}{1 - \frac{xy}{1-y}}$$ It's got me stumped.,"['algebra-precalculus', 'combinatorics']"
3059860,Invert a $4 \times 4$ matrix with a given structure?,"When tryig to fit $f(x,y) = a+bx+cy+dxy$ to the values of four points, we will have to invert following matrix. (Let us assume that $x_i,y_i$ are chosen suitably such that it is regular.) We could obviously solve this with any method (LU etc), but does the special structure of this matrix maybe allow for a compact representation of its inverse? I thought there might be a way because this matrix looks similar to a Vandermonde matrix (but it is obviously not the same), which do sometimes have inverses that are particularly easy to compute. $$M=\begin{bmatrix}
1 & x_1 & y_1 & x_1 y_1\\
1 & x_2 & y_2 & x_2 y_2\\
1 & x_3 & y_3 & x_3 y_3\\
1 & x_4 & y_4 & x_4 y_4\end{bmatrix}$$","['matrices', 'linear-algebra', 'inverse', 'matrix-decomposition']"
3059906,Find the $\frac mn$ if $T=\sin 5°+\sin10°+\sin 15°+\cdots+\sin175°=\tan \frac mn$,"It's really embarrassing to be able to doesn't solve this simple-looking trigonometry question. $$T=\sin(5^\circ) +\sin(10^\circ) + \sin(15^\circ)  + \cdots +\sin(175^\circ) =\tan \frac mn$$ Find the $\frac mn=?$ , where $m$ and $n$ are positive integer numbers. Attepmts: $$T=2\Big(\sin(5°)+\sin(10°) + \cdots + \sin(85°)\Big) + 1 = 2\Big((\sin(5°) + \cos(5°))+(\sin(10°)+ \cos(10°))+\cdots + (\sin(40°)+\cos(40°))\Big)+1 = 2\Big(\sqrt 2((\sin50°+\sin55°)+\cdots+\sin(80°))\Big)+1.$$ and then I can not see an any way...","['contest-math', 'algebra-precalculus', 'trigonometry', 'summation']"
3059949,Can't figure out this triangle geometry problem,"I have the following triangle: The following information about it are given: ABCD is a trapezoid (AB || DC) EF || DC Q is the intersection of AC, DB, PN, & EF Prove that EQ = QF. Since I don't have any numerical values, I tried solving it by various triangular relation identities via similarities and Thales's theorem. The only way to create a relation between EQ and QF that I could think of was this: $$\bigtriangleup \text{APM} \sim \bigtriangleup \text{EPQ} \text{ and } \bigtriangleup \text{PMB} \sim \bigtriangleup \text{PQF}$$ $$\begin{cases} \frac{AM}{EQ} = \frac{PM}{PQ} \\
\frac{MB}{QF} = \frac{PM}{PQ} \end{cases}$$ I've then tried to swap around the redundant lengths to try and get to the desired equation, but because I lack direction and methodology I get lost and frustrated.  I feel like I'm just doing guesswork. How can I solve this particular problem, and how do I tackle problems of this kind more effectively?","['euclidean-geometry', 'geometric-transformation', 'geometry']"
3059975,Generalized Circumcenter: minimizing the range of distances from a point to the vertices of a polygon,"It is well known that the circumcenter of a polygon exists if and only if the polygon is cyclic. I would like to extend the definition of a circumcenter for noncyclic polygons. Let us define $c(A)$ as the range of the lengths of the distances from $A$ to the vertices of the polygon; that is, the longest minus shortest distance from $A$ to the vertices of the polygon.   The range is chosen as a simple measure of spread. If there exists an $A_0$ such that $0 \leq c(A_0) < c(A)$ for all $A$ not equal to $A_0$ , and $A_0$ is not equivalently at infinity, then this $A_0$ is defined to be the generalized circumcenter of the polygon. Note that this generalization follows from the fact that the distances from the circumcenter to the vertices of a cyclic polygon are equal to each other. Does the generalized circumcenter exist for all n-gons?","['euclidean-geometry', 'statistics', 'geometry']"
3059993,$\underset{x\rightarrow\infty}{\lim}\frac{f(x)}{x}=0$ Implies $\underset{x\rightarrow\infty}{f'(x)}=0$ [duplicate],"This question already has answers here : Proving that $\lim\limits_{x\to\infty}f'(x) = 0$ when $\lim\limits_{x\to\infty}f(x)$ and $\lim\limits_{x\to\infty}f'(x)$ exist (6 answers) Closed 5 years ago . Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be a continuously differentiable function such that $\underset{x\rightarrow\infty}{\lim}\frac{f(x)}{x}=0$ and suppose $\underset{x\rightarrow\infty}{f'(x)}$ exists. Then Prove that $\underset{x\rightarrow\infty}{f'(x)}=0$ I can see that if we apply L'hoptal's theorem directly to $\frac{f(x)}{x}$ then we can get the answer. But is it possible to do so without knowing the value of $\underset{x\rightarrow\infty}{f(x)}$ On the similar problem: found here , they have given the existence of $\lim_{x\rightarrow\infty} f(x)$ . But in this particular problem they haven't","['calculus', 'analysis', 'real-analysis']"
3060040,Why is $\cos \sqrt z$ entire but $\sin \sqrt{z}$ isn't?,"I've been trying to formulate a way of comparing these two functions, in order to find out why the function $\sin \sqrt z$ is not entire, but I couldn't find a good way of doing that. What I tried so far: I wrote the series of both functions: \begin{align}\cos(\sqrt{z})&=\sum_{n=0}^\infty \frac{(-1)^nz^n}{(2n)!}\\
\sin(\sqrt{z})&=\sum_{n=0}^\infty \frac{(-1)^nz^n\cdot\sqrt{z}}{(2n+1)!}\end{align} The $e$ version: \begin{align}\cos(\sqrt{z})&=\frac{e^{i\sqrt{z}}+e^{-i\sqrt{z}}}{2}\\
\sin(\sqrt{z})&=\frac{e^{i\sqrt{z}}-e^{-i\sqrt{z}}}{2i} ,\end{align} but they didn't help me on solving the problem. How could I progress from here? I could not find a way of writing Cauchy-Riemann equations for $\cos$ or $\sin$ .","['complex-analysis', 'entire-functions', 'power-series']"
3060045,"How does this equation always work? $\sqrt{x \times (x+2)+1} = x + 1$ for non-negative $x$, and $=|x|-1$ for negative $x$","When I was playing with new calculator's functions, somehow I managed to get a formula, which works with all real numbers (negative number have a slight change). I had asked my teacher about it, but never figured out why it works: Non-Negative: $$\forall x \in \Bbb R_0^+: \sqrt{x \times (x+2)+1} = x + 1$$ Negative: $$\forall x \in \Bbb R^-: \sqrt{x \times (x+2)+1} = |x| - 1$$",['algebra-precalculus']
3060064,Does this property characterize abelian groups?,"Let $G$ be a group. Suppose there exists an integer $k>1$ and a non-identity permutation $\pi \in S_k$ such that for all $x_1, x_2 \cdots x_k \neq \mathbf{1} \in G$ we have that $x_1x_2x_3 \cdots x_k = x_{\pi(1)}x_{\pi(2)}x_{\pi(3)} \cdots x_{\pi(k)}$ . Must $G$ be abelian? This question is motivated by this . I've attempted to use Andrés technique in the linked post again here, but to no avail. I've also attempted to look at classical non-abelian groups like $S_3$ and $GL_n(\mathbf{C})$ for counterexamples but also to no avail. If this is false, is it possible that there's some conditions on the permutation $\pi$ which makes this true? Because, again looking over the linked post, it is clear that some permutations force abelianness.","['permutations', 'group-theory', 'abstract-algebra']"
3060101,"Proof that for any function $f:A\to B$ there exists a set $C$ and two functions $g:A\to C,h:C\to B$ not equal to $f$ such that $f=h\circ g$?","Proof that for any function $f:A\to B$ there exists a set $C$ and two functions $g:A\to C,h:C\to B$ not equal to $f$ such that $f=h\circ g$ ? I really have no clue how to tackle this problem. I have strong evidence to conclude this is true, but I don't know how to prove it. I think this may be solved using category theory, knowing if in the category Set , for any morphism $f:A\longrightarrow B$ , there are two morphisms such that their composition equals $f$ . The axioms for category tells the opposite, that for any two morphism there exists their composition morphism, but is it true the other way around in this context? And if this is not true, what condition does $f$ need to have in order to not have this property?","['functions', 'category-theory']"
3060106,"How to show that $\gcd(a_1,a_2,\cdots,a_k) = 1$ implies that there exist a non-negative solution to $\sum_{i=1}^{n}a_ix_i = n$ for large $n.$","I was reading about the Coin-problem and I am unable to fully understand the following argument: On the other hand, whenever the GCD equals 1, the set of integers that cannot be expressed as a conical combination of $\{ a_1, a_2, …, a_n \}$ is bounded according to Schur's theorem, and therefore the Frobenius number exists. Here the author is arguing for the existence of a non-negative solution to the linear Diophantine equation (LDE) $$\sum_{i=1}^{k}a_ix_i =n \text{}$$ for large enough $n.$ Now I tried to understand the proof of the Schur theorem here enter link description here (Page 98), but I am not sure that I understand it fully. In particular, I don't understand why the generating function associated with the sequence $h_n$ that counts the number of solutions to the LDE is $$H(x)= \prod_{i=1}^{k}\left(\frac{1}{1-x^{a_i}}\right).$$ Once we have $H(x)$ we can deduce that $$h_n\sim \frac{n^{k−1}}{(k − 1)!a_1a_2 ··· a_k}$$ as $n\to \infty.$ How does this exactly show that for large enough $n,$ $h_n>0?$ Is it because the $\frac{n^{k−1}}{(k − 1)!a_1a_2 ··· a_k}>0?$","['number-theory', 'additive-combinatorics', 'combinatorics', 'generating-functions', 'formal-power-series']"
3060125,"Defining the Cosine Function from First Principles, intuitively","Throughout most of my mathematics education, the cosine function has been defined formally either using its series expansion, as $\mathfrak{Re}(\exp i\theta)$ , or as the unique solution to $y+y''=0$ with $y(0)=1$ and $y'(0) = 0$ . Although these definitions make the mathematics more convenient, I've always been interested to see what it would be like to try to formalise it directly with the geometric intuition from the unit circle, assuming only the notion of distance (i.e. that we have a complete metric space with metric $d\colon\mathbb R^2 \times \mathbb R^2 \to \mathbb R$ ). Since, by geometric intuition, we have that the cosine function is the $x$ -coordinate obtained by walking along the unit circle, my idea was to take  a line segment from the point $(1,0)$ to another point on the circle such that the distance is $\theta$ , and split it into two line segments whose sum of lengths is also $\theta$ . We then split into 3 line segments, and so on, in a limiting manner, 
in such a way that the sum of lengths is always $\theta$ , as illustrated below with $\theta = 2\pi/5$ . [Desmos link] When this procedure converges, the $x$ - and $y$ -coordinates of the limiting point should be the cosine and sine of $\theta$ respectively. The problem is I can't find an easy way to express the $n$ th coordinate of this procedure (assuming we are splitting the line into $n-1$ segments) so that I can take the limit. I was going to try and do things the other way round, that is, define $\cos^{-1}\colon [-1,1] \to [0,\pi]$ by approaching the circle from below and finding the length. I did manage to do this, and got that \begin{align*}
    \cos^{-1}(x)  &= \sum_{k=1}^\infty d\left[\left(\frac{(k-1)x}{n}, \sqrt{1-\left(\frac{(k-1)x}{n}\right)^2}\right), \left(\frac{kx}{n}, \sqrt{1-\left(\frac{kx}{n}\right)^2}\right)\right]\\[4pt]
                  &= \sum_{k=1}^\infty \sqrt{2
   \left(1-\sqrt{1-\frac{(k-1)^2
   x^2}{n^2}}
   \sqrt{1-\frac{k^2
   x^2}{n^2}}\right)-\frac{2
   k(k-1)  x^2}{n^2}},
\end{align*} and I suppose one can extrapolate from here to obtain the $\cos$ and $\sin$ functions and extend them appropriately. But it feels like the other way, that is, finding that limiting point, should be possible. I appreciate any assistance with this.","['trigonometry', 'geometry', 'real-analysis']"
