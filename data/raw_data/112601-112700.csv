question_id,title,body,tags
1633326,What's so special about hyperbolic curves?,"This is really a two-part question, but I would be happy to get an answer for either bit. By a hyperbolic curve as defined by e.g. Szamuely in Galois Groups and Fundamental Groups (p.137) I mean an open subcurve $U$ of an integral proper normal curve $X$ over a field $K$ such that $2g-2+n>0$ where $g$ is the genus of the base change $X_\bar{K}$ $n$ is the number of closed points in $X_\bar{K}\backslash U_\bar{K}$. Many theorems/conjectures in anabelian geometry involve hyperbolic curves - for example, the section conjecture states that the rational points $U(K)$ on a hyperbolic curve $U$ correspond bijectively to (conjugacy classes of) sections of $\rho$ in the exact sequence of étale fundamental groups $1\rightarrow \pi_1 (U_\bar{K}) \rightarrow \pi_1 (U)\xrightarrow{\rho}G_K \rightarrow 1$ where $G_K$ is the absolute Galois group of $K$. Now, amongst all hyperbolic curves I have seen many particular references to the curve $U = \mathbb{P}_{\mathbb{Q}}^1 \backslash \left\{0,1,\infty\right\}$. Indeed, in his Notes on Etale Cohomology (p.30), J.S. Milne says that $\pi_1 (U)$ is arguably the most interesting object in mathematics. I know that in part this is because it ought to give us insight into the absolute Galois group of the rationals, but the particular choice of removed points seems quite mysterious to me. So my questions are: Where does the interest in hyperbolic curves come from? Why is $= \mathbb{P}_{\mathbb{Q}}^1 \backslash \left\{0,1,\infty\right\}$ of particular interest?","['number-theory', 'arithmetic-geometry', 'algebraic-curves', 'algebraic-geometry']"
1633354,Why can quotient groups only be defined for subgroups?,"I know that for the operation on cosets to be well-defined one requires normality. But why is it a requirement (with $G / N$) that $N$ be a subgroup or even a subset of $G$? Surely all that is required is that $N$ is a normal subgroup of a group $S$ (say), of which $G$ is a subgroup of. In which case $G / N \le S/N$.",['group-theory']
1633411,"Show, with the definition, that $\lim_\limits{ (x,y) \to (0,0)} x\sin\frac{1}{y} + y\sin\frac{1}{x}$ exist","Show, with the definition, that $\lim_\limits{ (x,y) \to (0,0)} x\sin\frac{1}{y} + y\sin\frac{1}{x} $ exist; $(x,y) \in \mathbb{R^2}-\{(0,0)\}$. I think the limit is zero because for $||(x,y)|| < \delta$, $$||x\sin\frac{1}{y} + y\sin\frac{1}{x}|| \leq ||(x,y)|| \cdot||(\sin\frac{1}{y},\sin\frac{1}{x})|| \leq \sqrt{2} ||(x,y)||< \sqrt{2}\delta.$$ 
It is sufficient to define that $\sqrt{2}\delta = \epsilon$ I am not certain of what I did so far. Is there anyone who can give me a hint to solve the problem?","['multivariable-calculus', 'epsilon-delta', 'limits']"
1633417,Find $\lim\limits_{n\to\infty}\sum\limits_{k=1}^{n}\frac{2k-1}{2^k}$ [duplicate],This question already has answers here : What is the sum of $\sum\limits_{i=1}^{n}ip^i$? (4 answers) Why $\sum_{k=1}^{\infty} \frac{k}{2^k} = 2$? [duplicate] (12 answers) Closed 8 years ago . What is the method finding the closed form of $\displaystyle\sum_{k=1}^{n}\frac{2k-1}{2^k}$?,"['sequences-and-series', 'calculus', 'limits']"
1633453,Why do people all the time exploiting almost sure properties of a stochastic process as if they were sure properties?,"All the time, I see people working with a given Brownian motion $(B_t)_{t\ge 0}$ on a fixed probability space $(\Omega,\mathcal A,\operatorname P)$ and suddenly exploiting its almost sure properties as if they were sure properties. Yeah, I know we can find a $\operatorname P$-null set $N\subseteq\Omega$ such that these properties hold surely on $\tilde\Omega:=\Omega\setminus N$ and hence coud replace $(\Omega,\mathcal A,\operatorname P)$ by $(\tilde\Omega,\left.\mathcal A\right|_{\tilde\Omega},\left.\operatorname P\right|_{\tilde\Omega})$. As a second option, we can modify $X_t$ on $N$ for any $t\ge 0$ such that these properties hold surely on $\Omega$. However, either we need to modify the probability space or the Brownian motion. But that's a weird and unusual practice in mathematics. If we can't prove the desired result, then we just modify our objects such that we can prove them. Carry the world as you like it . Shouldn't we better state (in a theorem) that there exists $B$ and $(\Omega,\mathcal A,\operatorname P)$ such that ... instead of fixing $B$ and $(\Omega,\mathcal A,\operatorname P)$ (at a global space)? And that's just an example. In probability theory, we do things like that all the time. Why is it legitimate?","['stochastic-processes', 'brownian-motion', 'probability-theory', 'measure-theory']"
1633463,Step size in Euler's forward method,"I came across the following question. Kindly let me know if there is any generic solution to this type of question. $$
\frac{d^2 y}{dt^2} + 3 \frac{dy}{dt} + 2y = f(t)
$$ Where $f(t)$ is an impulse function. What is a suitable step size for Euler forward difference method. 2 1.5 1 0.2","['numerical-methods', 'ordinary-differential-equations']"
1633504,Is the square root function norm continuous?,"Let $\{a_n\}$ be a  sequence of positive operators in $B(H)$. What about the following implication, True or false? $$||a_n-a||\to 0\Longrightarrow ||a_n^{\frac{1}{2}}-a^{\frac{1}{2}}||\to0$$","['functional-analysis', 'c-star-algebras']"
1633517,Is the matrix filled with the areas of pairwise intersections of disks in a plane always positive semidefinite?,"Consider disks $s_1, \cdots, s_n$ in the plane and let $a_{ij}$ be the area of $s_i\cap s_j$. Is it true that for any real numbers $x_1,\cdots, x_n$ we have 
$$ \sum_{i,j=1}^n x_ix_j a_{ij} \geq 0$$ Equivalent formulation: one can put $a_{ij}$ into a matrix $A$ and ask whether it is positive semidefinite. For $n=2$ this is true since 
$$a_{12}^2\le \min(a_{11},a_{22})^2 \le a_{11}a_{22} $$","['positive-definite', 'bilinear-form', 'geometry', 'area', 'linear-algebra']"
1633554,derivative of a projection matrix,"The projection onto a parametrised vector $v(\lambda)$ is $P_v = \frac{vv^{T}}{v^{T}v}.$ Its complement is $$P = I-\frac{vv^T}{v^{T}v}.$$ I've got an expression containing this complementary projection and I need its derivative. How do I calculate $$\frac{\partial P(v(\lambda))}{\partial \lambda} \text{ ?}$$ I started with $$\cfrac{\partial P(v(\lambda))}{\partial \lambda} = \cfrac{\partial P(v(\lambda))}{\partial v} \cfrac{\partial v(\lambda))}{\partial \lambda}$$ where only the expression $\cfrac{\partial vv^{T}}{\partial v}$ I can't handle. How can I find this derivative of a matrix with respect to a vector, or the original derivative with respect to the scalar parameter $\lambda$?","['derivatives', 'differential-geometry', 'linear-algebra']"
1633560,What's the arc length of an implicit function?,"While an explicit function $y(x)$'s arc length $s$ is easily obtained as $$s = \int \sqrt{1+|y'(x)|^2}\,dx,$$ is there any formula for implicit functions given by $f(x,y) = 0$? One can use the implicit differentiation $y'(x) = -\frac{\partial_y f}{\partial_x f}$ to obtain $$s = \int\sqrt{1 + |\partial_y f / \partial_x f|^2}\,dx,$$ but that still requires (locally) solving for $y(x)$. Is there any formulation that does not require this, e.g. another implicit equation involving $s$? Thoughts so far: One could rewrite $s$ as $$s = \int |\nabla f|\, |\partial_x f|dx,$$ or symmetrize to $$s = \int |\nabla f|\, \underbrace{(|\partial_x f|dx + |\partial_y f|dy)}_{(*)}/2$$ where $(*)$ might be strongly related to $|df|$ I guess (though it's not identical due to the $|\cdot|$), but then?","['real-analysis', 'integration', 'implicit-function-theorem', 'implicit-differentiation']"
1633563,"What dihedral subgroups occur in the affine general linear group $AGL(2,3)$","I am interested in the subgroup structure of the affine general linear group $AGL(2,3)$, in particular I want to know if they could have dihedral subgroups other then $D_3$ and $D_4$, i.e. the ones of order $6$ and $8$ (and $C_2 \times C_2$ if you consider it as a dihedral group). This group could be described as the group of matrices over $\mathbb F_3$ (the finite field containing three elements) of the form
$$
 A = \begin{pmatrix} e & 0 & 0 \\ a_1 & a_2 & a_3 \\ b_1 & b_2 & b_3 \end{pmatrix} 
$$
with $e, a_1, a_2, a_3, b_1, b_2, b_3 \in \mathbb F_3$ and $\operatorname{det}(A) = 1$. This group also appears as the automorphism group of the group of order $27$ and exponent $3$, see this post where it is described slightly different . So has this group any subgroups which are dihedral groups other then $D_3$ and $D_4$?","['finite-groups', 'abstract-algebra', 'group-theory', 'gap']"
1633597,What does y=y(x) mean?,"In many diciplines that utlizes mathematics, we often see the equation $$y=y(x)$$ where $y$ might be other replaced by whichever letter that makes the most sense in context. My question is what does $y$ mean in this case. I think that $y$ means both a function, since $y(x)$, but also a variable whose value is equall to the output of function $y$. Is that correct?",['functions']
1633602,"If $\{x_n\}$ satisfies that $x_{n+1} - x_n$ goes to $0$, is $\{x_n\}$ a Cauchy sequence? [duplicate]","This question already has answers here : Why doesn't $d(x_n,x_{n+1})\rightarrow 0$ as $n\rightarrow\infty$ imply ${x_n}$ is Cauchy? (5 answers) Closed 3 years ago . Since the definition of Cauchy sequence is: Understanding the definition of Cauchy sequence , I noticed we need an absolute value for $a_m-a_n$ in the definition so the statement would be false. But I can't find such a couterexample. Maybe it is true?","['examples-counterexamples', 'cauchy-sequences', 'sequences-and-series']"
1633619,Can you find the maximum or minimum of an equation without calculus? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Without using calculus is it possible to find provably and exactly the maximum value
or the minimum value of a quadratic equation $$ y:=ax^2+bx+c $$ (and also without completing the square)? I'd love to know the answer.",['analysis']
1633626,Integral with trigonometric function,"I have a problem with this integral $$\int_\ \frac{\sin 2x }{  \sqrt{4-\cos^2 x}} \, dx$$ We can transform it to $$\int_\ \frac{2\sin x \cos x }{  \sqrt{4-\cos^2 x}} \, dx$$ Using substitution $u^2 = 4 - \cos^2 x $ we get $$\int_\ \frac{2u }{\ u } \, du$$ And it gives bad result. Can you point when did i make the mistake ?",['integration']
1633640,"Show with the definition that the function $f:\mathbb{R^3} \to \mathbb{R^2}$ defined as $f(x,y,z) = (x^2-y^2+z, 4|xy|)$ is continuous","Show with the definition that the function $f:\mathbb{R^3} \to
 \mathbb{R^2}$ defined as $f(x,y,z) = (x^2-y^2+z, 4|xy|)$ is
  continuous. Let $\alpha=(x,y,z), \alpha_0=(x_0,y_0,z_0)\in \mathbb{R^3}$ For $\delta > 0$, $||\alpha - \alpha_0||< \delta$ $ \implies$ $$||f(\alpha)- f(\alpha_0)||$$ $$=||((x^2 - x_0^2)-(y^2-y_0^2)+(z-z_0), 4(|xy|-|x_0y_0|))||$$ Can I use the Cauchy-Scharwz inequality and use an equivalent norm, i.e. $||\cdot||_\infty$ How can I continue to cleverly develop this equality? Is there an inequality I can use to simplify or I have to develop the right side of the equality? I know I have to factorized the first few terms $(x^2 - x_0^2)$ and $(y^2-y_0^2)$ with $4(|xy|-|x_0y_0|)$","['multivariable-calculus', 'real-analysis', 'continuity']"
1633667,Modular Arithmetic - summing from 1 to a prime,"Apologises for the vague title; I couldn't think of anything better to call it. I'm currently working on the following question: Consider the equation $\sum_{i=1}^{5} \frac{1}{i} = \frac{X}{5Y}$.  Without making explicit calculations on the left hand side, show that $X \equiv Y$ modulo $125$. I'm unsure how to approach this really.  I've noted that $125 = 5^3$ of course, but I don't know how significant that will be.  I've tried some simple things like multiplying by $5! \cdot s$ to try and eliminate all denominators, but that doesn't seem to be of any use to me? Can anyone give a nudge in the right direction for me?  Thanks in advance!","['number-theory', 'modular-arithmetic']"
1633704,Calculating the length of the paper on a toilet paper roll,"Fun with Math time. My mom gave me a roll of toilet paper to put it in the bathroom, and looking at it I immediately wondered about this: is it possible, through very simple math, to calculate (with small error) the total paper length of a toilet roll? Writing down some math, I came to this study, which I share with you because there are some questions I have in mind, and because as someone rightly said: for every problem there always are at least 3 solutions. I started by outlining the problem in a geometrical way, namely looking only at the essential: the roll from above, identifying the salient parameters: Parameters $r = $ radius of internal circle, namely the paper tube circle; $R = $ radius of the whole paper roll; $b = R - r = $ ""partial"" radius, namely the difference of two radii as stated. First Point I treated the whole problem in the discrete way. [See the end of this question for more details about what does it mean] Calculation In a discrete way, the problem asks for the total length of the rolled paper, so the easiest way is to treat the problem by thinking about the length as the sum of the whole circumferences starting by radius $r$ and ending with radius $R$.
But how many circumferences are there? Here is one of the main points, and then I thought about introducing a new essential parameter, namely the thickness of a single sheet. Notice that it's important to have to do with measurable quantities. Calling $h$ the thickness of a single sheet, and knowing $b$ we can give an estimate of how many sheets $N$ are rolled: $$N = \frac{R - r}{h} = \frac{b}{h}$$ Having to compute a sum, the total length $L$ is then: $$L = 2\pi r + 2\pi (r + h) + 2\pi (r + 2h) + \cdots + 2\pi R$$ or better: $$L = 2\pi (r + 0h) + 2\pi (r + h) + 2\pi (r + 2h) + \cdots + 2\pi (r + Nh)$$ In which obviously $2\pi (r + 0h) = 2\pi r$ and $2\pi(r + Nh) = 2\pi R$.
Writing it as a sum (and calculating it) we get: $$
\begin{align}
L = \sum_{k = 0}^N\ 2\pi(r + kh) & = 2\pi r + 2\pi R + \sum_{k = 1}^{N-1}\ 2\pi(r + kh)
\\\\
& = 2\pi r + 2\pi R + 2\pi \sum_{k = 1}^{N-1} r + 2\pi h \sum_{k = 1}^{N-1} k
\\\\
& = 2\pi r + 2\pi R + 2\pi r(N-1) + 2\pi h\left(\frac{1}{2}N(N-1)\right)
\\\\
& = 2\pi r N + 2\pi R + \pi hN^2 - \pi h N
\end{align}
$$ Using now: $N = \frac{b}{h}$; $R = b - a$ and $a = R - b$ (because $R$ is easily measurable), we arrive after little algebra to $$\boxed{L = 4\pi b + 2\pi R\left(\frac{b}{h} - 1\right) - \pi b\left(1 + \frac{b}{h}\right)}$$ Small Example: $h = 0.1$ mm; $R = 75$ mm; $b = 50$ mm thence $L = 157$ meters which might fit. Final Questions: 1) Could it be a good approximation? 2) What about the $\gamma$ factor? Namely the paper compression factor? 3) Could exist a similar calculation via integration over a spiral path? Because actually it's what it is: a spiral. Thank you so much for the time spent for this maybe tedious maybe boring maybe funny question!","['summation', 'integration', 'calculus', 'recreational-mathematics']"
1633790,What is the order when doing $x^{y^z}$ and why?,"Does $x^{y^z}$ equal $x^{(y^z)}$? If so, why? Why not simply apply the order of the operation from left to right? Meaning $x^{y^z}$ equals $(x^y)^z$? I always get confused with this and I don't understand the underlying rule. Any help would be appreciated!","['algebra-precalculus', 'exponentiation']"
1633850,This sigma to binom?,Can you please show me how to get from the left side to the right side? $$\sum\limits_{k=0}^{20}\binom{50}{k}\binom{50}{20-k} = \binom{100}{20}$$,"['combinatorics', 'discrete-mathematics']"
1633895,affine variety definition,"I had this very elementary question which baffles me. Most introductions to the topic define an affine variety as a subset of affine space that is the zero-locus of a set of polynomials. Now, $X:=\mathbb{A}\setminus\{0\}$ does not satisfy this property. Yet I see in many places that it is treated as an affine variety (e.g. on Wikipedia) because it is isomorphic (not biregular, but birational, I guess) to the zero-locus of one variety that does satisfy the above definition (the zero-locus of $\langle xy-1\rangle$ on $\mathbb{A}^2$). Now, there's a circularity problem here, since for two objects to be isomorphic they must first be in the same category, and, according to our original definition, the first object $X$ is not an object in the category of affine varieties (over the given field, say $\mathbb{C}$). I assume there's some reference with a definition that captures this silly issue and gives a broader definition that pleases me, but I can't find it. The question then is: what should such a definition of an affine variety (in a classical sense, that is, avoiding schemes and the like) be? I mean a definition that includes the $X$ above (and similar other objects) as an affine variety.","['algebraic-groups', 'algebraic-geometry']"
1633901,"Formula for the simple sequence 1, 2, 2, 3, 3, 4, 4, 5, 5, ...","Given $n\in\mathbb{N}$, I need to get just enough more than half of it. For example (you can think this is : number of games $\rightarrow$ minimum turns to win) $$ 1 \rightarrow 1 $$
$$ 2 \rightarrow 2 $$
$$ 3 \rightarrow 2 $$
$$ 4 \rightarrow 3 $$
$$ 5 \rightarrow 3 $$
$$ 6 \rightarrow 4 $$
$$ 7 \rightarrow 4 $$
$$ \vdots $$
$$ 2i \rightarrow i+1 $$
$$ 2i+1 \rightarrow i+1 $$
$$ \vdots $$ Is it possible to create a simple formula without piecewise it into odd and even? Sorry for my bad English.",['sequences-and-series']
1633987,Directional derivative understanding,"[Beginning multivariable question.] I have just been introduced to a theorem that says $$D_uf(x)=\nabla f(x)\cdot u.$$ So in the two-dimensional case, $$\nabla f(x,y)= \langle f_x(x,y),f_y(x,y)\rangle \cdot \langle a,b\rangle$$ I don't really understand this. It seems to me that $f_x$ could be 0 and $f_y$ could be 0, there could still be a nonzero derivative in the direction halfway between the $x$ and $y$ axes. My intuition is that such a situation would violate the theorem -- so I must be misunderstanding something. Where am I going wrong?","['multivariable-calculus', 'derivatives']"
1634034,"Prove that $\lim_n \int_{\Bbb R} \frac{\sin(n^2 x^5)}{n^2 x^4} \chi_{(0,n]} d\lambda(x) = 0$","Prove that: $$\lim_n \int_{\Bbb R} \frac{\sin(n^2 x^5)}{n^2 x^4} \chi_{(0,n]} d\lambda(x) = 0$$ I am self-learning these stuff, and I would like to check whether I did things right. Here's my work: Call $f_n(x)$ the integrand. We have: $$\left| f_n(x) \right| = \left| \frac{\sin(n^2 x^5)}{n^2 x^4}\chi_{(0,1]} + \frac{\sin(n^2 x^5)}{n^2 x^4}\chi_{(1,n]}\right| \le \frac{n^2 x^5}{n^2x^4} \chi_{(0,1]} + \frac{1}{n^2 x^4} \chi_{(1,n]} \\ \le x \chi_{(0,1]} + \frac1{x^4} \chi_{(1,n]} \le x \chi_{[0,1]} + \frac{1}{x^4}\chi_{[1,\infty)} := g(x)$$ for all $n \ge 1$ and $x \in \Bbb R$ . Note that $(f_n)$ is a sequence of measurable functions, and it converges pointwise to $0$ . The function $x \mapsto x$ is Riemann-integrable on $[0,1]$ , hence it is Lebesgue-integrable and the integrals coincide. Also, $x \mapsto 1/x^4$ is Riemann-integrable on every compact $[1,a]$ , with $a > 1$ , and its $\int_1^{\infty}$ is absolutely convergent, hence it is Lebesgue integrable and the integrals coincide. Then, $$\int_{\Bbb R} g d\lambda = \int_0^1 x dx + \int_1^{\infty} \frac{dx}{x^4} < \infty$$ Hence $g \in L^1$ . Therefore, by LDCT, $$\lim_n \int_{\Bbb R} f_n d\lambda = \int_{\Bbb R} \lim_n f_n d\lambda = 0$$","['integration', 'lebesgue-integral', 'proof-verification']"
1634066,open equivalence relation and closed graph of it,"I need to prove that if $\sim$ is an open equivalence relation on a topological
space S and $R = \{(x,y)\in S\times S : x\sim y\}$ is a close subset of $S\times S$ then $\Delta = \{(x,x)\in S\times S\}$ is a close subset of $S\times S$. 
I tried to apply ideas from the theory and exercises with similar requests, like that the quotient map is an open map but failed to solve that.",['general-topology']
1634073,Simplifying division of integrals,"The $\overline{x}$ coordinate of the center of mass of a plane region is calculated as $$
\overline{x} = \frac{M_y}{M} = \frac{\int_a^b xf(x) \, \textrm{d}x}{\int_a^b f(x) \, \textrm{d}x}
$$ And the $\overline{y}$ coordinate as $$
\overline{y} = \frac{M_x}{M} = \frac{\frac{1}{2} \int_a^b [f(x)]^2 \, \textrm{d}x}{\int_a^b f(x) \, \textrm{d}x}
$$ Is it possible to simplify the division of two integrals so that the above coordinates look something like this where I assume the values outside the integrals remain that way: $$
\overline{x} = \int_a^b g(x) \, \textrm{d}x \\
\overline{y} = \frac{1}{2} \int_a^b h(x) \, \textrm{d}x
$$ If this really depends on the function, let $f(x) = x^2$ for fun.","['integration', 'calculus']"
1634106,Cech cohomology commuting with colimits? (Non noetherian confusion.),"Suppose that $X$ is a quasicompact, separated $A$-scheme, and $I$ is some directed poset. Suppose that $F_i$ is a system of sheaves on $X$ over $I$. I am having difficulties proving the claim that $H^i(X, \operatorname{colim} F_j) = \operatorname{colim} H^i(X, F_j)$. (An exercise in Ravi chapter 18.) Does one need $X$ to be locally Noetherian? Mainly, the confusion is that because $X$ if is not locally Noetherian, there are conceivably affine opens in some chosen cover were the $\operatorname{colim} (F_i(U)) \not = (\operatorname{colim} F_i)(U)$. If I could commute these, I know how to finish this, because ""filtered colimits commute with cohomology."" (The Cech complex for the $\operatorname{colim} F_i$ is the colimit of the Cech complexes of $F_i$, so the cohomology for the Cech complex for $colim F_i$ is the colimit of the cohomology for the Cech complexes of $F_i$.) I don't think I especially care about non Noetherian things right now, but I feel that I should know how to fix this. Edit: I think this is probably actually very simple, and I am just getting characteristically confused: For the open affine $U$ sets in the covering, I think probably $colim (F_i(U)) = (colim F_i)(U)$. This should be because any cover of $U$ can be refined to a finite cover, and for some abstract nonsense reason filtered colimits commute with finite products ( https://mathoverflow.net/questions/57099/why-do-filtered-colimits-commute-with-finite-limits ) It's not completely clear to me how to write that out. Is it  the case if $X$ is quasi-compact, then $\Gamma(X, \operatorname{colim} F_i) = \operatorname{colim} \Gamma(X,F_i)$? ** Edit: So here is the confusing thing: Suppose that $U_a$ is some cover of $U$ (quasi compact), and $U_i$ is some finite subcover. Let $F$ be a presheaf, and suppose the exactness of (1) $0 \to F(U) \to \Pi F(U_i) \to \Pi F(U_{i,i'})$. (In the previous set up, this exactness would come from the colimit commuting with finite products.) Then does it follow that (2) $0 \to F(U) \to \Pi F(U_a) \to \Pi F(U_{a, a'})$ is exact? (Which would tell us that the colimit presheaf is already a sheaf.) The map $F(U) \to \Pi F(U_a)$ is clearly still injective (because $\Pi F(U_i)$ injects in $\Pi F(U_a)$). What seems unclear is this: if $f_a$ is in the kernel at the second slot, from the data of the $f_i$ (and the $U_{ij}$) we get an $f \in F(U)$ with the property that $f|_{U_i} = f_i$. However, this $f$ only has $f|_{U_a \cap U_i} = f_a|_{U_a \cap U_i}$, for the cover $U_{ia}$ of $U_a$. But $F$ is not known to be separated, so it is not clear that then $f|_{U_a} = f_a$. If $U_a$ is quasi-compact, then we can use that $I$ is filtered to get that the canonical map $\operatorname{colim} (F_i(U_a) ) \to ( \operatorname{colim}  F_i) (U_a)$ is injective, i.e. the colimit presheaf is already ""separated"" over $U_a$. From this $f|_{U_a \cap U_i} = f_a|_{U_a \cap U_i}$ implies that $f|_{U_a} = f_a$, hence (2) is exact. So here is where we need the space to be Noetherian in order to conclude. I'm confused. (Final edit): If it is known that all finite covers of $U$ give exact sequences (which would be true in the filtered colimit situation), then one can apply the method of adding $U_a$ back to the finite cover to obtain that $f|_{U_a} = f_a$. The second bolded question should be true (provided the limits are filtered.) So I think Noetherianity is not necessary, because all of the covers used in computing Cech cohomology are quasi compact, so their sections are the colimits of the sections. I will try to write this out.","['sheaf-theory', 'sheaf-cohomology', 'algebraic-geometry']"
1634110,Are there prime gaps of every size?,"Is it true that for every even natural number $k$ there exists some $n \in \mathbb{N}$ such that $g_n = p_{n+1} - p_n = k$? I don't know how to approach the problem at all, and in fact I don't even know enough about prime gaps to even form a conjecture as to the answer. I feel like the answer is ""yes"", but only because that would be ""nicer"" than having some even integers never appear in sequence of prime gaps. I hope it's not an unsolved problem! Edit: My question is distinct from Polignac's Conjecture, since I ask if there is at least one prime gap, instead of infinitely many prime gaps, for every size.","['number-theory', 'prime-numbers']"
1634112,Probability function over infinite set,"Hmm, I was just talking to a friend of mine...and I said that Personally I would like to define the discrete probability function to be $ |event|\over |sample space|$ Then I gave an example about rolling a fair die P(outcome is even)=$|2,4,6| \over |1,2,3,4,5,6|$ which is 50%, and my friend asked me if it worked with infinite discrete set...without thinking too much I said...of course, if the numerator is all even positive integers and the denominator is all positive integers , then I know the probability is going to be 50% but later, when I tried to prove it mathematically...I failed, since I know that set of even positive integers and all positive integers have the same cardinality...the one to one mapping is just times two so...my function should return me 1? I know this is not making sense...can someone help me...I think somehow I confused myself :(","['probability', 'elementary-set-theory']"
1634113,Davenport's Q-method (Finding an orientation matching a set of point samples),"I have an initial set of 3D positions that form a shape.  After letting them move independently, my goal is to find the best rotation of the original configuration to try to match the current state.  This is for a soft body physics simulation, the idea being that if I can construct an optimal 'rigid' frame for the deformed shape then I can apply a shape matching constraint that removes deformation without introducing energy. Existing solutions tend to find the optimal linear transformation representing the deformation, and then use various methods to decompose the matrix into rotation and scale/shear components.  However, I found the orientations provided by such methods tended to not be very stable.  After significant searching I discovered that my problem was identical to a problem solved by NASA to determine satellite orientations.  When I implemented their solution my simulation was remarkably stable.  I want to gain a better understanding of why it works. Details of Davenport's Q-method are here .  Somehow, after taking a bunch of outer, cross and dot products of the original and deformed samples, jamming them into a symmetric 4x4 matrix, and then computing the eigenbasis for that matrix, the eigenvector corresponding to the largest eigenvalue can be reinterpreted as a quaternion that is the best orientation to use.  The author of the linked paper claims this result is easy to prove, but I guess easy is relative.  Can anyone walk me through why this works?","['eigenvalues-eigenvectors', 'rotations', 'quaternions', 'physics', 'linear-algebra']"
1634133,Cartesian Product of a Union and an Intersection,"I am given the Cartesian Product of an equation: $(A \cap C) \times (B \cup A)$ As being $\{(5,1),(5,4),(6,1),(6,4)\}$ And the sets: $B=\{1,9,4\}$ and $C=\{5,6,7,8\}$ And so I figure that $(A \cap C)=\{5,6\}$ and $(B \cup A)=\{1,4\}$ But regardless of the elements of the set $A$, surely $(B \cup A)$ must contain all three elements of $B$ and thusly $(B \cup A) \neq \{1,4\}$? I am supposed to give an example of the set $A$ with the maximum cardinality, but given my understanding of set notation this is not possible, is it?",['elementary-set-theory']
1634148,Solving differential equation describing motion in a pendulum,"I've been looking at Simple Harmonic Motion in particularly the period of a pendulum. This may seem like physics but my question is tailored towards mathematics. The differential equation is: $${{d^2\theta}\over dt^2}+\sin\theta=0$$ Using the small angle approximation it is found that $T={2\pi}\sqrt{L\over g}$. Is it possible to solve the differential equation without using the small angle approximation? If so, what is the actual period of a pendulum?","['ordinary-differential-equations', 'mathematical-physics']"
1634206,"If $a+b=8$ and $ab+c+d = 23$ and $ad+bc=28$ and $cd=12\;,$ Then $abcd$","If $a+b=8$ and $ab+c+d = 23$ and $ad+bc=28$ and $cd=12\;,$ Then value of $(1)\;\; a+b+c+d=$ $(2)\;\; ab+bc+cd+da = $ $(3)\;\; abcd=$ My attempt: Let $x=a\;,b$ be the roots of $(x-a)(x-b)=0$ and $x=c\;,d$ be the roots of $(x-c)(x-d)=0.$ So, $(x-a)(x-b)(x-c)(x-d)=\left[x^2-(a+b)x+ab\right]\cdot \left[x^2-(c+d)x+cd\right]=0.$ Thus, $$\left[x^2-8x+ab\right]\cdot \left[x^2-(c+d)x+12\right]=0.$$ Where do I go from here? Any help would be much appreciated.",['algebra-precalculus']
1634207,${2\pi \over 3} = 2u + \sin {2u}$ (intersections of circles),"So, I was browsing the internet today, when I saw an interesting problem: Two circles, each with radii of one, are intersecting. If the area enclosed by the intersection of the two circles is equal to the area of the remaining part of one of the circles, how far apart are the circles? After working for an hour on the problem, it came down to being able to solve the following problem:
$${2\pi \over 3} = 2u + \sin 2u$$ As far as I know, there is no practical way to express the exact solution for $u$, but am I wrong? Is there a way to solve the problem that I originally presented?","['trigonometry', 'geometry']"
1634222,How to prove this series about Fibonacci number: $\sum_{n=1}^{\infty }\frac{F_{n}}{2^{n}}=2$? [duplicate],"This question already has answers here : Infinite Series: Fibonacci/ $2^n$ [duplicate] (3 answers) Closed 8 years ago . How to prove this series result: $$\sum_{n=1}^{\infty }\frac{F_{n}}{2^{n}}=2$$ where $F_{1}=1,~F_{2}=1,~F_n=F_{n-1}+F_{n-2},~~n\geq 3$. I have no idea where to start.","['fibonacci-numbers', 'sequences-and-series', 'calculus', 'closed-form', 'power-series']"
1634226,cardinality of a basis for a topology,Suppose X is a space of cardinality $\le \kappa$. I would like to claim that any topology on X has a basis of cardinality $\le \kappa$. Intuitively it's true since even the discrete topology has such basis but i can't prove or find a counter-example... Thanks!,"['general-topology', 'elementary-set-theory']"
1634228,How to evaluate $\lim\limits_{x\to 0+}\frac 1x \left(\frac 1{\tan^{-1}x}-\frac 1x\right)$?,How to evaluate $\lim_{x\to 0+}\dfrac 1x \Big(\dfrac 1{\tan^{-1}x}-\dfrac 1x\Big)$ ? I used L'Hospital's rule but with no success.,"['derivatives', 'real-analysis', 'limits']"
1634250,Solve limit with Lagrange theorem,"I tried to solve this limit:
$$ \lim_{x \to +\infty} x^2\left(e^{\frac{1}{x+1}}-e^{\frac{1}{x}}\right) $$ Instead of solving it with Taylor series (using $u = 1/x$), I noticed that the difference within the parenthesis is the $\Delta f$ of the function $e^{\frac{1}{x}}$. $\lim\limits_{x \to +\infty} x^2 * \Delta\left(e^{1/x}\right) = $ The Lagrange theorem says that $\Delta f = D\left[f\right] * \Delta x$, so $=\lim\limits_{x \to +\infty} x^2 * \left( D\left[e^{1/x}\right]_{x_0} * \Delta x\right), x_0 \in \left(x, x+1\right)$ $$ x_0=x+r(x)$$ 
  $$ 0<r(x)<1 $$ $=\lim\limits_{x \to +\infty} x^2 * \left( e^{\frac{1}{x+r(x)}} * \left(-\frac{1}{\left(x+r(x)\right)^2}\right)\right) $ $=\lim\limits_{x \to +\infty} -\frac{1}{\left(x+r(x)\right)^2} * x^2 * e^{\frac{1}{x+r(x)}}$ $\approx \lim\limits_{x \to +\infty} -\frac{1}{x^2} * x^2 * e^{\frac{1}{x}} $ $=\lim\limits_{x \to +\infty} -1 * e^{\frac{1}{x}} = -1$ Is it correct to proceed in this way? EDIT: Using approximations is not a very elegant solution. I might be more precise using the Squeeze theorem (I'll think the solution, then I'll post it) Instead of using the approximation, we consider these three functions: $f(x) = x^2 * e^{\frac{1}{x+1}} * \frac{1}{(x+1)^2}$ $h(x) = x^2 * e^{\frac{1}{x+r(x)}} * \frac{1}{(x+r(x))^2}$ $g(x) = x^2 * e^{\frac{1}{x}} * \frac{1}{x^2}$ Obviously, $f(x) \le h(x) \le g(x)$ for $x > 0$ and $r(x) \in (0, 1)$. $\lim\limits_{x \to +\infty} f(x) = \lim\limits_{x \to +\infty} x^2 * e^{\frac{1}{x+1}} * \frac{1}{(x+1)^2} = 1$ (It is 1 and not -1 just because I left the minus sign out of the limit) $\lim\limits_{x \to +\infty} g(x) = \lim\limits_{x \to +\infty} x^2 * e^{\frac{1}{x}} * \frac{1}{x^2} = 1$ So $\lim\limits_{x \to +\infty} h(x) = 1 \rightarrow \lim\limits_{x \to +\infty} -h(x) = \lim\limits_{x \to +\infty} x^2\left(e^{\frac{1}{x+1}}-e^{\frac{1}{x}}\right) = -1$ Here's how the f (the red function) and g (the blue function) look like:",['limits']
1634265,"How to evaluate $\int_{0}^{\pi }\theta \ln\tan\frac{\theta }{2} \, \mathrm{d}\theta$","I have some trouble in how to evaluate this integral:
$$
\int_{0}^{\pi}\theta\ln\left(\tan\left(\theta \over 2\right)\right)
\,\mathrm{d}\theta
$$
I think it maybe has another form
$$
\int_{0}^{\pi}\theta\ln\left(\tan\left(\theta \over 2\right)\right)
\,\mathrm{d}\theta
=
\sum_{n=1}^{\infty}{1 \over n^{2}}
\left[\psi\left(n + {1 \over 2}\right) - \psi\left(1 \over 2\right)\right]
$$","['improper-integrals', 'integration', 'sequences-and-series', 'calculus']"
1634276,"Some questions about S.Roman, ""Advanced Linear Algebra""","Question for those who have studied Roman's book ""Advanced Linear Algebra"".
How self-contained is this book. Can I study determinants directly from this in context of exterior algebra and tensor products? How much one can understand if he didn't have a previous course in Linear Algebra. I want to study linear algebra but I want to do it properly with focus in abstract algebra. That is, I want the book to talk about modules, tensor products, exterior algebras. I tried Blyth's ""Module theory - an approach to linear algebra"" and Winitzki's ""Linear Algebra via Exterior Products"", but it didn't work out very well. Not beause the material was too hard, but because I simply don't like the style. It's not fully rigorous.
Now I hope I can learn something from Roman's book.","['reference-request', 'modules', 'book-recommendation', 'linear-algebra']"
1634281,Solve $3x(1-x^2)y^2\frac{dy}{dx}+(2x^2-1)y^3=ax^3$,"I am solving this linear Differential equation which can be easily solve by using the formulas for the Bernoulli's Equations I have solved till 
$$\frac{dy}{dx}+\frac{(2x^2-1)y^3}{3x(1-x^2)y^2}=\frac{ax^3}{3x(1-x^2)y^2}$$
$$y^2\frac{dy}{dx}+\frac{(2x^2-1)y^3}{3x(1-x^2)}=\frac{ax^3}{3x(1-x^2)}$$
Substituting $y^3=t$
so the equation will be
$$\frac{1}{3}\frac{dt}{dx}+\frac{(2x^2-1)t}{3x(1-x^2)}=\frac{ax^3}{3x(1-x^2)}$$
after this the integrating factor is $$\frac{1}{x\sqrt{1-x^2}}$$
But I am unable to solve it forward.","['ordinary-differential-equations', 'calculus']"
1634307,Maximum of a sum of random variables,"Let $X_1, \dots, X_n$ be independent and identically distributed random variables with $E(X_i) = 0$ and $$S_k = \sum_{i \leq k} X_i$$ What is the probability distribution of $M_2 = \max \{ X_1, X_1+X_2 \}$? We can suppose $X_i$ have normal distribution ; we have to note that $X_1$ and $X_1 + X_2$ are not independent, that's why all my attempts of computing $P(S \leq t)$ failed. What is the probability distribution of
  $M_3 =\max \{ X_1, X_1+X_2, X_1+X_2+X_3 \}$, and, more generally, of $M_n = \max\limits_{k \le n} {S_k}$ ?","['normal-distribution', 'independence', 'probability-theory', 'probability-distributions', 'random-variables']"
1634343,summation of a binomial expression that doesn't start from 0,"I have the following expression: $$
\sum_{k=9}^{17}\binom{17}{k}
$$
and I need to show that it's equal to:
$$
2^{16}
$$
now I know that if 'k' was starting from zero and not from 9 , like this:
$$
\sum_{k=0}^{17}\binom{17}{k}
$$
then there is this identity that says it's equal to:
$$
2^{17}
$$
But Because the summation starts from 9 I don't know what to do..
can you help please?
thank you","['binomial-coefficients', 'discrete-mathematics']"
1634354,"Prob. 9 (c), Sec. 18 in Munkres' TOPOLOGY, 2nd ed: Continuity of a map deduced from its restrictions to closed subsets of the domain","Here's Prob. 9, Sec. 18 in Topology by James R. Munkres, 2nd edition: Let $\{ A_\alpha \}$ be a collection of subsets of $X$; let $X = \bigcup_\alpha A_\alpha$. Let $f \colon X \to Y$: suppose that $f | A_\alpha$ is continuous for each $\alpha$. (a) Show that if the collection $\{A_\alpha \}$ is finite and each set $A_\alpha$ is closed, then $f$ is continuous. [ I have managed to show this! ] (b) Find an example where the collection $\{ A_\alpha \}$ is countable and each $A_\alpha$is closed, but $f$ is not continuous. [Example found easily!] (c) An indexed family of sets $\{ A_\alpha \}$ is said to be locally finite if each point $x$ of $X$ has a nieghborhood that intersects $A_\alpha$ for only finitely many values of $\alpha$. Show that if the family $\{ A_\alpha \}$ is locally finite and each $A_\alpha$ is closed, then $f$ is continuous. It is part (c) that stumps me. My Attempt at Part (c): Let $B$ be a closed set in $Y$. We need to show that $f^{-} (B)$ is closed in $X$. Let $A \colon= f^{-1}(B)$. Then 
  $$A = \bigcup_\alpha \left( f | A_\alpha \right)^{-1} (B).$$
  Now since $f | A_\alpha$ is continuous for each $\alpha$, each set $\left( f | A_\alpha \right)^{-1} (B)$ is closed in $A_\alpha$ and hence is closed in $X$. Suppose that $x \in X - A$. Then $x$ has a neighborhood $U$ (i.e. an open set $U$ containing $x$) that intersects only finitely many of the sets in the collection $\{A_\alpha \}$. Let $\alpha_1, \ldots, \alpha_n$ be the values of the indices $\alpha$ for which $U$ intersects the sets $A_\alpha$. Since $x \not\in A$, therefore $x \not\in \left( f | A_\alpha \right)^{-1} (B)$ for any $\alpha$. So $\left( f|A_\alpha \right) (x) \not\in B$ for any $\alpha$. But as $X = \bigcup_\alpha A_\alpha$, so $x \in A_\alpha$ for some $\alpha$, and so $f(x) = \left( f|A_\alpha \right) (x) $ for some $\alpha$. But $x$ can only belong to one of the sets $A_{\alpha_1}, \ldots, A_{\alpha_n}$. So $f(x) = \left( f | A_{\alpha_i} \right) (x)$ for some $i \in \{ i , \ldots, n\}$. Thus we can conclude that $f(x) \not\in B$. Let $S_i \colon= \left( f | A_{\alpha_i} \right)^{-1} (B)$. Then $x \not\in S_i$ for any $i$. Since the sets $\left( f | A_{\alpha_i} \right)^{-1} (B)$ are closed in $X$, we can conclude that, for each $i$, the point $x$ has a neighborhood $U_i$ such that $U_i \cap S_i = \emptyset$. Let $V \colon= U \cap U_1 \cap \ldots \cap U_n$. Then $V$ is a neighborhood of $x$ and if $v \in V$, then $v \in U$ so that $v \in A_{\alpha_i}$ only for some $i = 1, \ldots, n$ and $v \in U_i$ so that $v \not\in S_i$ for any $i = 1, \ldots, n$. Also then $v \not\in A_\alpha$ for any $\alpha \neq \alpha_1, \ldots, \alpha_n$. Is my reasoning so far correct? How to show from here  that $v \not\in A$? P.S.: My Attempt at Part (c) Contd.: Now if this $v$ were to lie in $A$, then $v$ would have to lie in some set $\left( f | A_\alpha \right)^{-1}(B)$ for some $\alpha$. But as each set $\left( f | A_\alpha \right)^{-1}(B)$ is contained in $A_\alpha$ and as $v$ cannot be in any set $A_\alpha$ for any $\alpha$ different from one of the $\alpha_i$, so we can conclude that if $v$ were to lie in $A$, then $v$ would have to be in one of the sets $\left( f | A_{\alpha_i} \right)^{-1}(B) = S_i$ for some $i = 1, \ldots, n$. But as $v$ is in $U_i$ and $U_i \cap S_i = \emptyset$ for each $i$, so $v$ cannot be in $S_i$ for any $i$. Thus $v$ cannot be in $A$, which implies that $v \in X-A$, showing that the open set $U \cap U_1 \cap \cdots \cap U_n \subset X-A$. And $x \in U \cap U_1 \cap \cdots \cap U_n$ also. Thus every point $x \in X-A$ has a neighborhood disjoint from $A$, which implies that set $X-A$ is open and hence $A$ is closed, as required. Is my proof correct now? Or, is there any problem in it?",['general-topology']
1634375,Choosing a substitution to evaluate $\int \frac{x+3}{\sqrt{x+2}}dx$,"Is there any other value you can assign to the substitution variable to solve this integral? $$\int \frac{x+3}{\sqrt{x+2}}dx$$ Substituting $u = x + 2$:
$$du = dx; u +1 = x+3 ,$$
and we get this new integral that we can then split into two different ones:
$$\int \frac{u + 1}{\sqrt{u}}du = \int \frac{u}{\sqrt{u}}du + \int \frac{1}{\sqrt{u}}du .$$ We can substitute again $s = \sqrt u$ and get two immediate integrals: $$s = \sqrt{u}; \quad ds = \frac{1}{2\sqrt{u}}du; \quad 2s^2 =u .$$ Substituting back $u$ to $s$ and $x$ to $u$ we get this result,
$$s^2 + \ln{\left | \sqrt{u} \right |} = u + \ln{\left | \sqrt{u} \right |} = x+2+\ln{\left | \sqrt{x+2} \right |},$$ which doesn't look quite to be right. What am I doing wrong? I'm pretty unsure about the second substitution, $2s^2 = u$. Is it correct?","['indefinite-integrals', 'substitution', 'integration', 'calculus']"
1634411,why adding or subtracting linear equations finds their intersection point?,"I was trying to understand the logic behind linear algebra but got stuck at this point. Why does adding or subtracting two linear equations with one another result in their intersection point ? After searching i came across a method which goes like this . Lets say we have two equations x+y=5 and 2x+y=8. Now they do this 
y=5-x
y=8-2x
and then 5-x=8-2x and then find the value of x. I understood the logic behind this method. But what about the other method where they just subtract those equations , and find x value first and then find y value . What is going on there ? What is the logic behind it ?",['linear-algebra']
1634436,$\sigma$-field generated by the continuity sets of a measure,"Let $\mu$ be a probability measure on the Borel subsets of a topological space $X$ (a compact metric space if necessary). A Borel set $B$ is a $\mu$-continuity set if $\mu(\partial B)=0$, where $\partial B$ is the boundary of $B$. Is the $\sigma$-field generated by the continuity sets of $\mu$ equal to the Borel $\sigma$-field?","['probability-theory', 'measure-theory']"
1634437,Lie groups pre-requisites and reference,"What are the minimum pre-requisites in analysis (differential geometry) required to study Lie-groups? And for that material, what are some good references? I have done basic courses in Metric spaces, Topology, Complex analysis etc. and Linear Algebra and Functional analysis. I also have some knowledge of Curves and surfaces  ( $\mathbb{R^3}$ ). I have to do a reading in Lie groups and, perhaps, later continue with its representation theory. Though it is (probably?) an algebraic study, I would still like to know the role played by Lie groups and algebras in Geometry too. Ideally I would prefer to have a brief but sufficiently rigorous introduction in Differential geometry so that I may continue with the study of Lie groups without hindrance. For that if there is a reference recommendation then I would be really thankful.If there exist some lecture notes serving this purpose,then that would be great too.) Thanks in advance!","['reference-request', 'differential-geometry', 'lie-groups']"
1634479,Fubini's Theorem and expectation of random variables,"I have a question regarding the application of the Fubini's Theorem to the expectation of the product of two random variables. Let $X,Y$ be two random variables defined on the probability space $(\Omega, \mathcal{F},\mathbb{P})$, $X:\Omega\rightarrow \mathbb{R}$, $Y:\Omega\rightarrow \mathbb{R}$. Assume $E(XY)$ exists. (case 1) : Suppose $X,Y$ continuous with pdf $f^{X,Y}$ and $\int_{\mathbb{R}\times\mathbb{R}} |xy\text{ } f^{X,Y}(x,y)|\text{ }d(x,y)<\infty$. Then 
$$
E(XY):=\int_{\mathbb{R}\times\mathbb{R}} xy\text{ } f^{X,Y}(x,y)\text{ }d(x,y)\underbrace{=}_{\text{Fubini}}\int_{\mathbb{R}}\int_{\mathbb{R}}xy\text{ } f^{X,Y}(x,y)\text{ }dx dy
$$ Question : can we generalise case 1 to the case in which $X,Y$ could be both discrete, both continuous or mixed? My attempt : Let $P^{X,Y}$ be the probability distribution induced by $X,Y$ on the probability space $(\mathbb{R}^2,\mathcal{B}(\mathbb{R}^2))$, where $\mathcal{B}(\mathbb{R}^2)$ is the Borel $\sigma$-algebra on $\mathbb{R}^2$ . In other words, $P^{X,Y}$ is the measure on the product space $(\mathbb{R}^2,\mathcal{B}(\mathbb{R}^2))$. Then,
$$
E(XY):=\int_{\mathbb{R}\times\mathbb{R}} xy \text{ }dP^{X,Y}(x,y)
$$ Assume $\int_{\mathbb{R}\times\mathbb{R}} |xy| \text{ }dP^{X,Y}(x,y)<\infty$. At this point how can I apply the Fubini's Theorem? Is $P^{X,Y}(x,y)$ a product measure on $(\mathbb{R}^2,\mathcal{B}(\mathbb{R}^2))$ My intuition is that $P^{X,Y}(x,y)$ is a product measure only if $X$ and $Y$ are independent. Maybe I could use the fact that $P^{X,Y}=P^{X|Y}\times P^Y$? I'm confused on this point and any hint would be really appreciated.","['expectation', 'riemann-integration', 'integration', 'lebesgue-integral', 'measure-theory']"
1634488,How could we define the factorial of a matrix?,"Suppose I have a square matrix $\mathsf{A}$ with $\det \mathsf{A}\neq 0$. How could we define the following operation? $$\mathsf{A}!$$ Maybe we could make some simple example, admitted it makes any sense, with $$\mathsf{A} =
\left(\begin{matrix}
1 & 3 \\ 
2 & 1 
\end{matrix}
\right)
$$","['matrices', 'matrix-calculus', 'operator-theory', 'factorial', 'linear-algebra']"
1634503,"$\overline\phi: M/IM \to N/IN$ is surjective, then $\phi$ is surjective.","Let $I$ be a nilpotent ideal in a commutative ring $R$, let $M$ and $N$ be $R$-modules and let $\phi : M \to N$ be an $R$-module homomorphism. Show that if the induced map $\overline\phi: M/IM \to N/IN$ is surjective, then $\phi$ is surjective. I have proceeded in this way    $\overline\phi: M/IM \to N/IN \Rightarrow \hat \phi:(M/IM)^n=M^n/(IM)^n \to (N/IN)^n=N^n/(IN)^n$ is surjective. Now from here how do I conclude the claim? OR Do I have to show that $M/I^nM \to N/I^nN$ is surjective? I am completely stuck here. Need help.","['abstract-algebra', 'ring-theory', 'modules', 'commutative-algebra']"
1634505,Example of a self-adjoint bounded operator on a Hilbert space with empty point spectrum,"I want to find a self-adjoint bounded operator on a Hilbert space with empty point spectrum i.e. $$ T = T^* ~\text{but}~ \sigma_p(T)= \emptyset $$ Some definitions and results of the lecture: (On a Hilbert space $X$ and let $T \in \mathscr{L}(X)$ i.e. a bounded linear operator on $X$ ) $T=T^* \Leftrightarrow \sigma(T) \subset \mathbb{R} $ $TT^* = T^* T \Rightarrow \sigma_r(T)=\emptyset$ i.e. the residual spectrum is empty $\sigma(T)=\sigma_r(T) \cup \sigma_p \cup \sigma_c(T)$ disjoint unions If the space is finite then $\sigma_p(T)=\sigma(T)$ $\sigma(T)$ is non-empty So, I have a self-adjoint operator i.e the residual spectrum is empty and I also want the point spectrum to be empty i.e. I want to achieve $\sigma(T)=\sigma_c(T)$ i.e $$ \{\lambda \in \mathbb{C} ~|~ (\lambda I - T) ~\text{not invertible} \}=$$ $$\{\lambda \in \mathbb{C} ~|~ \ker(\lambda I - T)=\emptyset ~\text{ and }~ \text{ran}(\lambda I - T) \neq \overline{\text{ran}(\lambda I - T)}=X \}$$ Additionally the space has to be infinite since otherwise $\sigma(T)=\sigma_p(T)$ . Does someone have such an example for me? And please explain why this example works in this way. This spectral theory is new for me.","['functional-analysis', 'spectral-theory', 'operator-theory', 'hilbert-spaces']"
1634516,The significance of failure of uniqueness in differential equations,"The nonlinear ODE: $y'(t)=y(t)^{1/2}$ with initial condition $y(0)=1$ has two solutions.  Non-uniqueness is not surprising because of the failure of Lipschitz continuity in the $y$ term.  While this is formally true, what if any, is the practical significance of the failure of uniqueness of solutions?  For example, if this ODE (or a similar PDE) modelled some biological or physical phenomenon, would non-uniqueness mean anything? Edit: Thanks for the responses so far!  I found a passage in Fung and Tong's Classical and Computational Solid Mechanics in Chapter 21 on page 849 which reads: One of the distinct characteristics of nonlinear problems is that the
  solution may not be unique. In the nonuniqueness, there lies much of
  nature’s secret. Examples in solid mechanics are the buckling of thin
  shells, self-equilibrating residual stresses and strains,
  three-dimensional solutions in bodies with apparently two-dimensional
  boundary conditions, and many problems in plasticity. I am not so familiar with these models: perhaps someone wiser than myself might have some specific insight?","['intuition', 'ordinary-differential-equations']"
1634520,Helmholtz theorem,"I have been told that the Helmholtz decomposition theorem says that every smooth vector field $\boldsymbol{F}$ [where I am not sure what precise assumptions are needed on $\boldsymbol{F}$] on an opportune
  region $V\subset\mathbb{R}^3$ [satisfying certain conditions for whose precisation I would be very grateful to any answerer] can be expressed as $$  \boldsymbol{F}(\boldsymbol{x})=-\nabla\left[\int_{V}\frac{\nabla'\cdot \boldsymbol{F}(\boldsymbol{x}')}{4\pi\|\boldsymbol{x}-\boldsymbol{x}'\|}dV'-\oint_{\partial V}\frac{\boldsymbol{F}(\boldsymbol{x}')\cdot\hat{\boldsymbol{n}}(\boldsymbol{x}')}{4\pi\|\boldsymbol{x}-\boldsymbol{x}'\|}dS'\right]$$ $$+\nabla\times\left[\int_{V}\frac{\nabla'\times \boldsymbol{F}(\boldsymbol{x}')}{4\pi\|\boldsymbol{x}-\boldsymbol{x}'\|}dV'+\oint_{\partial V}\frac{\boldsymbol{F}(\boldsymbol{x}')\times\hat{\boldsymbol{n}}(\boldsymbol{x}')}{4\pi\|\boldsymbol{x}-\boldsymbol{x}'\|}dS'\right]$$[where I suppose that the $\int_V$ integrals are intended as limits of Riemann integrals or Lebesgue integrals]. I think I have been able to prove it ( below ), interpretating the integrals as Lebesgue integrals with $dV'=d\mu'$ where $\mu'$ is the usual tridimensional Lebesgue measure, for a compactly supported $\boldsymbol{F}\in C^2(\mathbb{R}^3)$ with $\boldsymbol{x}\in \mathring{V}$ and $V$ satisfying the hypothesis of Gauss's divergence theorem. Nevertheless, I am also interested in proofs of it under less strict assumptions on $\boldsymbol{F}$. What are the usual assumptions -I am particularly interested in the assumptions done in physics- on $\boldsymbol{F}$ and how can the theorem proved in that case? I heartily thank any answerer. I think that it would be interesting to generalise it to some space containing $C_c^2(\mathbb{R}^3)$ whose functions have ""smoothness"" properties usually considered true in physics, where the Helmholtz decomposition is much used, but I am not able to find such a space and prove the desired generalisation.","['vector-fields', 'real-analysis', 'multivariable-calculus', 'lebesgue-integral', 'vector-analysis']"
1634530,Evaluating $\int^{\pi}_0\arctan\left(\frac{p\sin x}{1-p\cos x}\right)\sin(nx) dx$ by differentiation under integral?,"I saw that $$
\int^{\pi}_{0}\arctan \left(\frac{p \sin x}{1-p \cos x}\right) \sin(nx) dx=\frac{\pi}{2n} p^n  
$$
for $$p^2 <1$$ I tried to prove using differentiation under integral but got stuck at this step $$
I^{\prime} (p)=\int^{\pi}_{0} \frac{\sin x \sin (nx)}{1+p^2-2p \cos x}dx 
$$ What to do next?","['integration', 'definite-integrals', 'calculus']"
1634565,Is there a closed form for these polynomials?,"Let $P_0(x)=1, P_{-1}(x)=0$ and define via recursion $P_{n+1}(x)=xP_{n}(x)-P_{n-1}(x)$. The first few polynomials are $$ P_0(x)= 1\\
P_1(x) = x \\
P_2(x) = x^2-1 \\
P_3(x)= x^3 -2 x\\
P_4(x) = x^4 - 3 x^2 +1 \\
P_5(x) = x^5 - 4 x^3 +3 x$$ It appears the polynomials are always the form: $$P_n(x)=\sum_{k=0}^{\lfloor n/2\rfloor+1} (-1)^k\ \ f(n,k)\ x^{n-2k}$$ Where for example one can calculate $$f(n,0)=1 \\ f(n,1)=n-1 \\ f(n,2)=\frac{(n-2)(n-3)}{2}$$ Is there a closed form for these polynomials? Aside from that I am specifically interested in whether or not $\sum_{n=0}^\infty |P_n(x)|^2$ diverges for every $x \in \mathbb{C}$.","['real-analysis', 'polynomials', 'closed-form']"
1634606,How can we prove that the generalized stochastic process induced by a real-valued Brownian motion is Gaussian?,"Let $(B_t)_{t\ge 0}$ be a real-valued Brownian motion on a probability space $(\Omega,\mathcal A,\operatorname P)$, $\lambda$ be the Lebesgue measure on $[0,\infty)$ and $$\langle W,\phi\rangle:=\int\phi(t)B_t\;{\rm d}\lambda\;\;\;\text{for }\phi\in\mathcal D:=C_c^\infty([0,\infty))\;.$$ We can prove that the expectation $$\operatorname E[W](\phi):=\operatorname E\left[\langle W,\phi\rangle\right]\;\;\;\text{for }\phi\in\mathcal D$$ of $W$ is $0$ and the the covariance $$\rho[W](\phi,\psi):=\operatorname E\left[\langle W,\phi\rangle\langle W,\psi\rangle\right]\;\;\;\text{for all }\phi,\psi\in\mathcal D$$ of $W$ is $$\int\int\min(s,t)\phi(s)\psi(t)\;{\rm d}\lambda(s)\;{\rm d}\lambda(t)\;.$$ Now I want to prove, that $W$ is Gaussian , i.e. $$\alpha_1\langle W,\phi_1\rangle+\cdots+\alpha_n\langle W,\phi_n\rangle\text{ is normally distributed}$$ for all (linearly independent$^\ast$) $\phi_1,\ldots,\phi_n\in\mathcal D$ and $\alpha\in\mathbb R^n$. Unfortunately, I've no idea how we can do that. [$^\ast$ I've found different notions of being Gaussian for a generalized stochastic process. Some of them state that $\phi_1,\ldots,\phi_n$ need to be linearly independent while the others omit this assumption.]","['functional-analysis', 'brownian-motion', 'stochastic-analysis', 'stochastic-processes']"
1634645,"If $ A=\frac{1}{2\sqrt{1}}+\frac{1}{3\sqrt{2}}+\frac{1}{4\sqrt{3}}+.........+\frac{1}{100\sqrt{99}}\;,$ Then $\lfloor A \rfloor =$","If $\displaystyle A=\frac{1}{2\sqrt{1}}+\frac{1}{3\sqrt{2}}+\frac{1}{4\sqrt{3}}+.........+\frac{1}{100\sqrt{99}}\;,$ Then $\lfloor A \rfloor =$ Where $\lfloor x \rfloor$ represent floor function of $x$ . $\bf{My\; Try:}$ For lower bound $$\sum^{99}_{k=1}\frac{1}{(k+1)\sqrt{k}}>\sum^{99}_{k=1}\frac{1}{(k+1)k}=\sum^{99}_{k=1}\left[\frac{1}{k}-\frac{1}{k+1}\right]=1-\frac{1}{99}$$ Now I didn't understand how can I solve it, any help? Thanks",['sequences-and-series']
1634684,A good pictorial explanation of separation of variables?,"I'm teaching ordinary differential equations for the first time, and I would like to give a compelling visual explanation of why it makes sense to ""multiply by $dx$"" and integrate when you want to solve a separable equation like $\frac{dy}{dx} g(y) = f(x)$. Roughly what came to mind: one can use the tangent slope of a solution to the equation to give two congruent right triangles with ""adjacent"" and ""opposite"" side lengths $(\Delta x, \Delta y)$ (approximately) and $(g(y), f(x))$.  Using the fact that these are similar triangles, we see that cross multiplying yields $g(y)\,\Delta y = f(x) \,\Delta x$ (really approximately), and these are approximations of the areas represented by $\int g(y) \,dy$ and $\int g(x) \,dx$. Question: Are there other visual explanations for the method of separation of variables?  Perhaps one that can make a more direct connection with areas and/or are more precise?","['visualization', 'ordinary-differential-equations']"
1634713,Example of operator with spectrum equal to $\mathbb{C}$?,"In my Functional Analysis course, we proved that for a (possibly unbounded) operator $T$ that is densely defined, closed, and symmetric, exactly one of the following four occurs: $\sigma(T) = \mathbb C$; $\sigma(T) = \{\lambda \in \mathbb C \mid \Im \lambda \geq 0\}$; $\sigma(T) = \{\lambda \in \mathbb C \mid \Im \lambda \leq 0\}$; $\sigma(T) \subset \mathbb R$. Now, 4 is easy; this is true for selfadjoint operators. I'm having a hard time coming up with an example for option 1; can you guys help me?","['functional-analysis', 'spectral-theory', 'operator-theory']"
1634718,"What is $\bigcap_{n \in \mathbb{N}} \left(0, {1\over n}\right)$?","What is$$\bigcap_{n \in \mathbb{N}} \left(0, {1\over n}\right)?$$I suspect it is the empty set, and we would see this by using the Archimedean property of $\mathbb{R}$ or something like that, but I have no idea on how to prove it. Can anybody help me? Thanks in advance!","['real-analysis', 'sequences-and-series']"
1634725,Non-infinite geometric sum; does not start at 0 or 1,"It's bee a long time since I've worked with sums and series, so even simple examples like this one are giving me trouble: $\sum_{i=4}^N \left(5\right)^i$ Can I get some guidance on series like this? I'm finding different methods online but not sure which to use. I know that starting at a non-zero number also changes things. My original thought was to do (sum from 0 to N of 5^i) - (sum from 0 to 3 of 5^i) but I'm not sure that's right.","['summation', 'sequences-and-series', 'geometric-series']"
1634750,Associativity of symmetric difference of sets,"By $A\oplus B$ we denote the symmectric difference of two sets. The definition is $A\oplus B =(A\setminus B) \cup (B\setminus A)$. Now I hope to show that $A\oplus (B\oplus C) = (A\oplus B)\oplus C$. I remember that there's an elegant proof, but I forget its detail. (The first step is to show $A\oplus (A\oplus B) = B$, and maybe applying this formula, we can obtain associativity.)",['elementary-set-theory']
1634755,How do I prove that sin is not defined implicitly by an algebraic equation?,"How do I prove that sin is not defined implicitly by an algebraic equation? In essence, there does not exist rational functions $f_0,\ldots,f_{n-1}$ that satisfies
$$\sin^n(x)+f_{n-1}(x)\sin^{n-1}(x)+\cdots+f_0(x)=0$$","['real-analysis', 'trigonometry']"
1634778,Trace of the $k$-th Exterior Power of a Linear Operator,"Let $V$ be an $n$ dimensional vector space over a field $F$ and $T$ be a linear operator over $V$ . Assume that the characteristic of $F$ is not $2$ . Definition. Consider the map $f_1:V^n\to \Lambda^n V$ as $$f(v_1, \ldots, v_n)= \sum_{i=1}^n v_1\wedge \cdots \wedge v_{i-1}\wedge Tv_i\wedge v_{i+1} \wedge \cdots \wedge v_n$$ This is an alternating multilinear map and thus it induces a unique linear map $\Lambda^n V\to \Lambda^n V$ . Since $\dim(\Lambda^n V)=1$ , this linear map is multiplication by a constant which we call the trace of $T$ . The above is standard and it naturally calls for the following generalization before which we discuss a notation. Given an $n$ tuple $(v_1, \ldots, v_n)$ of vectors in $V$ and an increasing $k$ -tuple $I=(i_1, \ldots , i_k)$ of integers between $1$ and $n$ , write $v_{I, j}$ to denote $Tv_j$ if $j$ appears in $I$ and simply $v_j$ if $j$ does not appear in $I$ . Further write $v_I$ to denote $v_{I, 1}\wedge \cdots \wedge v_{I, n}$ . Definition. Let $f_k:V^n\to \Lambda^n V$ be defined as $$f_k(v_1, \ldots, v_n)= \sum_{I \text{ an increasing }k\text{-tuple}}v_I$$ Then $f_k$ is an alternating multilinear map and this induces a unique linear map $\Lambda^n V\to \Lambda^n V$ . Again, this linear map is multiplication by a constant which we call the $k$ -th trace of $T$ and denote it as $\text{trace}_k(T)$ . From this post I have am convinced that the following is true Statement. $\text{trace}_k(T)= \text{trace}(\Lambda^k T)$ . I am unable to prove this.","['trace', 'exterior-algebra', 'linear-algebra', 'multilinear-algebra']"
1634834,Why doesn't this infinite exponential growth go beyond 2.5?,"My calculus book says that with: 
$$a=x^{x^{x^{.^{.^{.}}}}}$$
(exponent tower goes on forever), then:
$$x=a^\frac{1}{a}$$ I tried it out with $a=3$ so $x=3^\frac{1}{3}$ and then ran a python program to test it. I did: $$(3^\frac{1}{3})^{(3^\frac{1}{3})^{(3^\frac{1}{3})^{.^{.^{.}}}}}$$ Between 500 runs and 10.000 runs the answer stayed: 2.4780526802882967 Maybe I don't appreciate enough what infinity means, but why isn't it closer to $3$ after 10.000 runs? Is the answer $x=a^\frac{1}{a}$ really correct? Will this really finally be 3 if it would run infinitely? For reference, this was the little python program: x=3**(1/3)
y=x
for i in range(0,100000):
    y=x**y
    print(y)","['exponential-function', 'calculus']"
1634847,"Elementary Set Theory: Ordinals, Well Orderings and Isomorphisms","I need to show that for any countable ordinal $\alpha$ there is a set A $\subseteq \mathbb{Q}$ such that (A, <) is isomorphic to ($\alpha, \in$).  To do it I am supposed to show the following stronger statement by induction on ordinals $\alpha$ < $\omega_{1}$:  Let P($\alpha$) be the statement ""For every interval (a, b) with rational endpoints, there is an A $\subseteq$ (a,b) such that (A, <) is isomorphic to ($\alpha, \in$)."" I think that the purpose of breaking $\mathbb{Q}$ into intervals (a,b) is to make $\mathbb{Q}$ a countable set, but I don't see the significance of doing this or how it would make the proof easier.  I feel like I need to define a well-ordered set in (a,b) but I don't know how to do this since if a and b are both negative then there is no least element, so no well-ordering. I believe that I am supposed to be using transfinite induction? But I don't know how P($\alpha$) implies P(S($\alpha$)) for S($\alpha$) successor of $\alpha$. Any help would be greatly appreciated... thanks in advance.","['elementary-set-theory', 'ordinals']"
1634848,Associativity of tensor product over various rings,"From Atiyah-MacDonald: Exercise 2.15. Let $A$, $B$ be rings, let $M$ be an $A$-module, $P$ a $B$-module and $N$ an $(A,B)$-bimodule (that is, $N$ is simultaneously an $A$-module and a $B$-module and the two structures are compatible in the sense that $a(xb) = (ax)b$ for all $a \in A$, $b \in B$, $x \in N$). Then $M \otimes_A N$ is naturally a $B$-module, $N \otimes_B P$ an $A$-module, and we have
  $$
 (M \otimes_A N) \otimes_B P \cong M \otimes_A (N \otimes_B P).
$$ Source Do they mean the isomorphism to be one of abelian groups? Or of modules over one of the rings somehow?","['abstract-algebra', 'tensor-products', 'commutative-algebra']"
1634849,Inverse (finite group) isomorphism of a certain form exists,"I have been working on something in group theory for a long time and I have one problem that I cannot solve. I have reduced that problem to a conjecture. It takes some work to set it up, but I don't thinks it's that hard to understand. Let $\mathcal G$ be the finite abelian group
$\sum_\limits{i=1}^A \mathbb Z/a_i \mathbb Z.$ We represent an element 
$\bar{\mathbf x} \in \mathcal G$
as a column vector
$\begin{bmatrix}
  \overline{x_1} &
  \overline{x_2} &
  \overline{x_3} &
  \cdots &
  \overline{x_A}
\end{bmatrix}^\text T$
where
$\mathbf x =
\begin{bmatrix}
  x_1 &
  x_2 &
  x_3 &
  \cdots &
  x_A
\end{bmatrix}^\text T \in \mathbb Z^{A \times 1}$ Define
$D_a = \operatorname{diag}(a_1, a_2, a_3, \dots, a_A)$.
Then, for any two
$\overline{\mathbf x}, \overline{\mathbf y} \in \mathcal G, \,$
$\overline{\mathbf x} = \overline{\mathbf y}$ if and only if there exists a
$\mathbf u \in \mathbb Z^{A \times 1}$
such that
$\mathbf x = \mathbf y + D_a \mathbf u$. Let $\mathcal H$ be a nontrivial subgroup of $\mathcal G$ which can be expressed as an internal direct sum of cycles, 
$$\mathcal H =
  \bigoplus_{j=1}^B \langle \, \overline{\mathbf s_j} \, \rangle.$$
For $j=1 .. B,$ let
$\operatorname{ord}(\, \overline{\mathbf s_j} \,) = b_j$. Let $S =
\begin{bmatrix}
  \mathbf s_1 &
  \mathbf s_2 &
  \mathbf s_3 &
  \cdots &
  \mathbf s_B
\end{bmatrix} \in \mathbb Z^{A \times B}$
be the matrix formed by the column vectors
$\{\mathbf s_j\}_{j=1}^B$ Define
$D_b = \operatorname{diag}(b_1, b_2, b_3, \dots, b_B)$. Then there exists a matrix
$\widetilde S \in \mathbb Z^{A \times B}$ such that 
$$ S D_b = D_a \widetilde S $$
This is true because each $b_j$ is the smallest positive integer such that, for every $i$, there exists an integer $\tilde s_{ij}$ such that
$b s_{ij} = \tilde s_{ij} a_i \equiv 0 \pmod{a_i}.$ Finally, we get to Conjecture: The matrix
$\begin{bmatrix} \widetilde S \\ -D_b \end{bmatrix}$
has an integer left inverse. This is equivalent to saying that the rows of $\widetilde S$ span $\prod_{j=1}^B \mathbb Z_{b_j}$. It is easy to show that the elements in each column of
$\begin{bmatrix} \widetilde S \\ -D_b \end{bmatrix}$
are relatively prime. But I can't see how to take the next step and create an integer left inverse. Context: The mapping
$f : \prod_{j=1}^B \mathbb Z_{b_j} \to \mathcal H$
defined by
$f(\bar{\mathbf x}) = \overline{S \mathbf x}$
is an (additive group) isomorphism. So there must exists an isomorphism
$\, f^{-1} : \mathcal H \to \prod_{j=1}^B \mathbb Z_{b_j}$ It would be nice if there were a matrix
$T \in \mathbb Z^{B \times A}$
such that 
$f^{-1}(\bar{\mathbf y}) = \overline{T \mathbf y}$,
but this only happens some times. If my conjecture were true, then we would always have 
$T = D_b \widetilde T D_a^{-1} \in \mathbb Q^{B \times A}$
where, for some
$U \in \mathbb Z^{B \times B} $, 
$$\begin{bmatrix} \widetilde T & U \end{bmatrix}
\begin{bmatrix} \widetilde S \\ -D_b \end{bmatrix} = I$$ I tried for a long time to find a counter example with no success, but I also can't prove that
$\begin{bmatrix}
    \widetilde S \\
    -D_b \\
 \end{bmatrix}$
always has a left inverse. NOTES: The expression 
$ S D_b = D_a \widetilde S $
is just the matrix way of expressing that
for $j = 1..B, \operatorname{ord}\mathbf s_j = b_j$ What the function
$F:\mathbb Z^B \to \mathcal H$
defined by 
$F(\bar{\mathbf x}) 
  = \overline{S x}
  = \sum_{j=1}^B x_j \mathbf{\bar s}_j$
is doing is pretty obvious. The problem is that the function is ""too big"" in the sense that any $x_j$ can be replaced by
$x_j + nb_j \; (n \in \mathbb Z)$
without altering the image of 
$\bar{\mathbf x}.$
That periodic redundancy is encapsulated in the function
$f : \prod_{j=1}^B \mathbb Z_{b_j} \to \mathcal H$
defined by
$f(\bar{\mathbf x}) = \overline{S \mathbf x}$.
Here is how you prove that this function is well-defined.
\begin{align}
  \bar{\mathbf x} = \bar{\mathbf y}
  &\implies x = y + D_b u \; (u \in \mathbb Z^{B \times 1})\\
  &\implies Sx = Sy + S D_b u\\
  &\implies Sx = Sy + D_a (\widetilde S u)\\
  &\implies f(\bar{\mathbf x}) = f(\bar{\mathbf y})\\
\end{align} So $f$ is a well-defined isomorphism. Hence there is also an inverse isomorphism 
$f^{-1}:\mathcal H \to \prod_{j=1}^B \mathbb Z_{b_j}$.
Let's assume that there is a rational matrix
$T \in \mathbb Q^{B \times A}$
such that
$f^{-1}(\bar{\mathbf y}) =\overline{Ty}.$
We will show that $f^{-1}$ is well-defined if there exists an integer matrix
$\widetilde T \in \mathbb Z^{B \times A}$ such that
$T D_a = D_b \widetilde T$. \begin{align}
  \bar{\mathbf y} = \bar{\mathbf z}
  &\implies y = z + D_a u \; (u \in \mathbb Z^{A \times 1})\\
  &\implies Ty = Tz + T D_a u\\
  &\implies Ty = Tz + D_b (\widetilde T u)\\
  &\implies f^{-1}(\bar{\mathbf y}) = f^{-1}(\bar{\mathbf z})\\
\end{align} We also need to ensure that, for $j = 1..B$,
$f^{-1}(f(\bar{\mathbf e}_j)) = f^{-1}(\bar{\mathbf s}_j) 
 = \bar{\mathbf e}_j.$
This can all be compressed into
$f^{-1}(f(\overline{I_B})) = \overline{I_B}$. \begin{align}
  f^{-1}(f(\overline{I_B})) &= \overline{I_B} \\
  f^{-1}(\overline S) &= \overline{I_B} \\
  \overline{TS} &= \overline{I_B} \\
  TS &= I_B + D_b U \; (U \in \mathbb Z^{B \times B})\\
  (D_b \widetilde T D_a^{-1})(D_a \widetilde S D_b^{-1}) &= I_B + D_b U \\
  D_b \widetilde T \widetilde S D_b^{-1} &= I_B + D_b U \\
  \widetilde T \widetilde S &= I_B + U D_b \\
  \widetilde T \widetilde S - U D_b &= I_B \\
  \begin{bmatrix} \widetilde T & U \end{bmatrix}
  \begin{bmatrix} \widetilde S \\ -D_b \end{bmatrix} &= I_B
\end{align}","['group-theory', 'linear-algebra']"
1634884,Arzela-Ascoli for $\mathbb R^n$ from the case of $\mathbb R$?,"In class, we proved the Arzela-Ascoli theorem for $\mathbb R$. The lecturer said it's also true for $\mathbb R^n$, and this version is deducible from $\mathbb R$. I tried to do this but failed. How does one infer this generalization? For the record, the theorem I mean is: Theorem. Let $X$ be a compact metric space. Then a subset of $C(X,\mathbb R)$ is compact iff it's closed, equicontinuous, and totally bounded.","['functional-analysis', 'general-topology', 'analysis']"
1634898,"In $\lim(x,y)\to(0,0)$ why can I change to $(x^2,x)$?","When we have a multivariable function  and we want to see if the function is continuous at a point, normally the origin, we sometimes ""change"" $(x,y)\to(0,0)$ to expressions like $(x^2,x)\to(0,0)$ to make it work. For example, for the function:
$f(x)=\begin{cases}\frac{yx^2}{(x^4+y^2)}&  \text{if } (x,y)\neq (0,0)\\
0& \text{if } (x,y)=(0,0)\end{cases}$ In order to see the discontinuity we can consider $(x,xm)\to(0,0)$ and we get $0$. But if we change to $(x,x^2)\to(0,0)$, the limit becomes $1/2$. Why can we choose those curves? Also, for a different function, could I choose $(1/x,x)\to(0,0)$. I know the limit of $1/x$ as $x$ goes to zero does not exist, therefore I am unsure.","['multivariable-calculus', 'limits']"
1634905,How to calculate the volume of an arbitrary pyramid without calculus?,"I've been reading about the intuition behind calculating the volume of a pyramid by dividing the unit cube into 6 equal pyramids with lines from the center of the cube and it makes sense since all pyramids are the exact copies of each other and I'm curious how this intuition expands to rectangular prisms. Once we know the formula to calculate the volume of a pyramid we can actually see that lines from the center of the prism indeed divides the shape into 6 pyramids with equal volumes, but without knowing the formula is it possible to somehow say that? Same question goes for other pyramids with unequal side lengths. How can you say that pyramids with same base and height have equal volumes without knowing the formula? I'm specifically asking for a primitive method without the use of calculus or other advanced methods because I've been curious about whether or not Egyptians had a way to show it or they just got lucky, or maybe they were only interested with pyramids cut from the unit cube and not the others?",['geometry']
1634984,A thief and a policeman,"A policeman desperately tries to catch a thief that is $a$ meters away. The thief has the constant velocity $v$ , and the policeman has the constant velocity $k\cdot v$ , with $k > 1$ . The policeman starts at $(0, 0)$ and the thief at $(0, a)$ . The thief never changes its direction (not a very smart thief) and always runs straight to the right. The policeman is a bit smarter and always looks directly at the thief while running. At $(a, a)$ , the thief is caught. For illustration, see this image: Find $k$ . I found a solution (numerical approximation) but the answer is very unexpected :) I used Excel and the method of small steps. For a very small step and about $10^6$ iterations, I got the first six digits of the golden ratio. I want to find a proof but I have no clue at all.","['ordinary-differential-equations', 'calculus', 'vector-analysis']"
1634991,"Which of the $43,380$ possible nets for a dodecahedron is the narrowest?","I want to fit multiple regular dodecahedron nets on to an infinitely long roll of paper. I want this to result in the largest possible dodecahedrons, for a roll of a given width. My hunch is that the longer and narrower the net, the larger the dodecahedron I can produce; proving this one way or the other might be an interesting side-exercise. My main question for now is simply: for a given size of pentagon, which of the $43,380$ possible nets for a regular dodecahedron fits into the narrowest rectangle?","['solid-geometry', 'platonic-solids', 'geometry']"
1634999,Why the set of pure state ‎is ‎weak* ‎compact?,"Let ‎$‎‎A$ ‎be a‎ ‎C*-algebra‎. ‎
‎$‎S(A)‎$ ‎is ‎the ‎set ‎of ‎state ‎on ‎‎$‎‎A$ and $‎‎PS(A)$ ‎is ‎the ‎set ‎of ‎pure ‎state ‎on ‎‎$‎‎A$. ‎
‎
I ‎know ‎that ‎if ‎‎$‎‎A$ ‎is ‎unital ‎then ‎‎$‎‎S(A)$ ‎is ‎weak* ‎compat.‎ ‎I know that  extreme points of $S(A)$ is $PS(A)$ I ‎want ‎to ‎prove ‎‎$‎‎PS(A)$ ‎is ‎weak* ‎compact.so I‎ ‎should ‎show ‎that ‎‎$‎‎PS(A)$ ‎is ‎weak* ‎closed.(when $A$ is unital) ‎
Q: ‎‎My question is:""  Why $‎PS(A)‎$ ‎is ‎weak* ‎compact?‎"" 
"" Is the extreme point of compact set compact?
""","['functional-analysis', 'c-star-algebras', 'von-neumann-algebras', 'banach-algebras']"
1635012,A result of equation $y^2+1=x^p$ where $p$ is odd prime.,"Example 2.4.4 page 23 of the book ""Problems of algebraic number theory"" by R. Murty is about solving equation  $y^2+1=x^p$ where $p$ is odd prime and $x,y\in \mathbb{Z}$. Solving this example lead to two sum over some factorials which a special case of those is as follow:
$$\sum_{k=0}^{m}\frac{k^m}{k!(m-k)!}(-1)^{m-k}=1$$
I was interested to a small solution way to this.","['combinatorics', 'sequences-and-series']"
1635013,Product spaces and open sets,"I have a proposition I have been pondering that I need help with. Let $(X,d_{X})$ and $(Y,d_{Y})$ be metric spaces. Recall that the product space $(X\times Y, d_{1})$ is also a metric space with the metric $d_{1}: (X\times Y)\times(X\times Y) \to \mathbb{R}$ defined as
$$ d_{1}((x_{1},y_{1}),(x_{2},y_{2})) = d_{X}(x_{1},x_{2}) + d_{Y}(y_{1},y_{2}) $$
Show that (a) If $A, B$ are subsets of $X,Y$, respectively, and $A\times B$ is an open subset of $X\times Y$, then $A$ and $B$ are open in $X$ and $Y$, respectively. My start: Let $A \subset X$, $B \subset Y$, and let $A\times B$ be an open subset open in $X\times Y$. Since $A\times B$ is open, then $A\times B = \text{Int}(A\times B)$. I'm stuck in how to proceed. (b) If both $(X,d_{X})$ and $(Y,d_{Y})$ are separable, then $(X\times Y, d_{1})$ is also separable. Suppose that both $(X,d_{X})$ and $(Y,d_{Y})$ are separable. Then, there exists some countable dense subset in each of $X$ and $Y$, say $A$ and $B$, respectively. We claim that $A \times B$ is a countable dense subset of $X\times Y$. To show that $A\times B$ is dense, let $C$ be an open set in $X\times Y$. Again, I am stuck in how to proceed. Any clues, tips, or insights?","['functional-analysis', 'real-analysis', 'metric-spaces']"
1635028,fourier transform for pde equation,"I was solving the pde using fourier transform: $u_{tt}-u_{xx}+m^2u=0$ with initial values $u(0,x)=f(x)$ and $u_t(0,x)=g(x)$. I have received the answer $$U(t,k)=Ae^{-it \sqrt {k^2+m^2}}+Be^{it \sqrt {k^2+m^2}}$$
where $A, B, m$ are constants, and $U(t,k)$ is the Fourier transform of $u(t,x)$.
Now I have problems with turning $U$ to $u$. I tried to do it directly, calculating the integral for inverse fourier, but I got stuck since the integral contains $e^{it \sqrt{k^2+m^2}+ikx}dk$ and $f(x)$, $g(x)$ a bit different from that. Can someone help me, please? Any hints are welcome! Thank you!","['integration', 'fourier-analysis', 'partial-differential-equations']"
1635034,$\frac {\partial}{\partial t}T$ vs $\frac d{dt} T$.,"Suppose we have a function $T_1=F(x,y,t)$. Now suppose that $x=g(t),y=h(t)$, so we have a new $T_2=F(x(t),y(t),t)$, so then we have that $\frac \partial{\partial t} T_2=F_t$ and $\frac d{dt}T_2=F_x x_t+F_yy_t+F_t$. My question is, if we let $x,y$ and $t$ be independant variables, does the symbol $\frac d{dt}T_1$ (if we use the same idea as before, we should have that $\frac d{dt}T_1=\frac {\partial}{\partial t}T_1$, is this true?) have any meaning?","['multivariable-calculus', 'partial-derivative', 'notation', 'derivatives']"
1635060,Prove that there exist a sylow subgroup of $G$ which is fixed by $\alpha$.,"Let $G$ be a finite group and $\alpha\in Aut(G)$ such that $\alpha$ restricted to any sylow subgroup of $G$ equals the restriction of some inner automorphism of $G$ and $(o(\alpha),o(G))=1$, then is it true that there exist a sylow subgroup of $G$ which is fixed by $\alpha$. I think this is true, but could not think of proper reasoning. Thanks in advance for any help.","['abstract-algebra', 'group-theory']"
1635062,Rudin's definition on measurable function,"In the definition of measurable function in Rudin's book, he defines measurable function from a measurable space $X$ to a topological space $Y$ as the inverse image of every open set in the range space is measurable in the domain space, the definition is equivalent to the common definition of measurable function when $Y$ is equipped with borel set ( the smallest $\sigma-$ algebra containing open sets). However, if the $\sigma-$ algebra containing open sets on $Y$ is bigger than Borel set, then this definition gives a broader range of measurable function, can anyone tell me why Rudin defines like that?",['real-analysis']
1635088,Evaluating $\lim_{n\to\infty}{n\left(\ln(n+2)-\ln n\right)}$,I am trying to find$$\lim_{n\to\infty}{n\left(\ln(n+2)-\ln n\right)}$$ But I can't figure out any good way to solve this. Is there a special theorem or method to solve such limits?,"['logarithms', 'limits']"
1635114,Prove that $f(n) = 3n^5 + 5n^3 + 7n$ is divisible by 15 for every integer $n$,"So far I have only been able to complete the base case for which I got the following: $$f(n) = 3n^5 + 5n^3 + 7n$$ $$f(n) = 3(1)^5 = 5(1)^3 + 7(1)$$ $$f(n) = 3 + 5 + 7$$ $$15/15 = 1$$ From here I got a bit confused with the inductive step in terms of number manipulation, a hint that my professor gave me was $f(-n) = -f(n)$. Any further help is appreciated.","['number-theory', 'induction', 'discrete-mathematics']"
1635136,Full classes in Kelley's book,"In Kelley's ""General topology"" (in the ""Appendix"") the full classes $X$ are defined as those with the property
$$
\forall A\in X\quad A\subseteq X.
$$
In the Russian translation it is added that this is equivalent to the property that the relation $\in$ is transitive on $X$:
$$
\forall A,B,C\in X\quad A\in B\in C \ \Rightarrow\ A\in C.
$$
I think there must be an easy trick for proving this equivalence, but I don't see it. Can anybody help me?",['elementary-set-theory']
1635191,Saturation of a multiplicatively closed subset,"Exercise 3.7 of Atiyah-MacDonald asks the reader: if $A$ is a commutative ring and $\mathfrak{a} \triangleleft A$ an ideal, find the saturation of $1 + \mathfrak{a}$. Previously we have shown that the saturation of a multiplicatively closed subset $S$ is the complement of the union of prime ideals not meeting $S$. Are they just looking for the fact that the saturation is the complement of the union of all $\mathfrak{p}$ prime such that $\mathfrak{p} + \mathfrak{a} \neq R$? Or is there more to say?","['abstract-algebra', 'ideals', 'commutative-algebra']"
1635192,Eigenvector and eigenvalue for exponential matrix,"$X$ is a matrix. Let $v$ be an eigenvector of $X$ with corresponding eigenvalue $a$. Show that $v$ is also an eigenvector of $e^{X}$ with eigenvalue $e^{a}$ If $X$ is diagonalizable, then we can start writing out terms using Taylor expansion of $e^{X}$ but I can't seem to get anywhere. Thanks for the help Edit: Corrected question to read ' Let $v$ be an eigenvector of $X$' instead of ' Let $v$ be an eigenvector of $e^X$'.","['eigenvalues-eigenvectors', 'matrices', 'abstract-algebra', 'exponential-function', 'diagonalization']"
1635242,Stability of limit cycle associated with a homogenous linear quation,"Study the stability of the limit cycle r=1 for the system given in polar coordinates by the equations  $\dot{r}=(r^2−1)(2x−1), \dot{\phi}=1$, where $x=r\cos \phi$. I've been trying to solve this problem by estimating the return function, but haven't made any progress.
Can anyone give me some hints?","['homogeneous-equation', 'ordinary-differential-equations']"
1635250,What are numerical methods of evaluating $P(1 < Z \leq 2)$ for standard normal Z?,"Let $Z \sim Norm(0, 1)$ and denote its PDF and CDF by $\phi$ and $\Phi$ respectively. Then, theoretically, $P(1 < Z \leq 2) = \Phi(2) - \Phi(1).$ However $\Phi$ cannot be expressed in closed form, so some sort of computational method is required to obtain a numerical answer. The traditional method has been to consult tables of of $\Phi$ such as the five place table available online from NIST online, or similar tables available in many textbooks on probability and statistics to obtain $P(1 < Z \leq 2) = 0.47725 - 0.34134 = 0.13591.$
Nowadays, many software packages give such answers. For example, using R one obtains. diff(pnorm(c(1,2)))
  ##  0.1359051 in which pnorm (with default second and third parameters) is a function for computing $\Phi.$ This R function is based on numerical integration. In the initial answer below, our purpose is to illustrate several computational and Monte Carlo methods that have been used to make CDF tables or to program software for finding intervals associated with normal distributions, and a few other commonly occurring distributions. Mostly, our focus is on widely applicable methods that are also useful for practical problems involving a variety continuous distributions. Additional answers illustrating different practical approaches are welcome.","['statistics', 'simulation', 'probability']"
1635281,Convergence of $\sum_{n=1}^\infty\left(\sqrt[n]{2}-1\right)$,"I'm trying to determine whether $$\sum_{n=1}^\infty \left ( \sqrt[n]{2}-1\right )$$ converges or diverges.  Ratio, root, nth term, etc tests are either inconclusive or too difficult to simplify.  I feel like there must be something I can bound this series by but I can't think what. In this question the answerer very smartly (I have no idea how he/ she thought to do that) used the fact that $(1+\frac 1n)^n \le e \le 3$ to bound $\sqrt[n]{3} -1$ by $\frac 1n$ but that only worked because $3\ge e$.  So even though that question looks very similar I don't think I can apply that idea here. Edit: This is in the section before power/ Taylor series so I don't think I'm allowed to use that.","['sequences-and-series', 'calculus']"
1635332,Show that $\hat{\theta}$ is an unbiased estimator of $\theta$,"Let $f(x, \theta) = \frac{1}{\theta} x^{\frac{1-\theta}{\theta}}$, where $0 < x < 1$ and $\theta > 0$. Let $X_1, \dots, X_n$ be iid with density $f$. Taking the log likelihood, I found
$$ l(\theta) = -n\ln{\theta} + \frac{1-\theta}{\theta}\sum_{i=1}^n{\ln{X_i}}  $$
$$ l'(\theta) = -\frac{n}{\theta} - \frac{1}{\theta^2}\sum{\ln{X_i}}$$ Setting $l'(\theta) = 0$ yields the MLE of $$\hat{\theta} = -\frac{1}{n}\sum{\ln(X_i)}$$ But I don't know how to show that $E(\hat{\theta}) = \theta$, i.e. it's an unbiased estimator. I tried taking the estimate of both sides as follows: $$ E(\hat{\theta}) = -\frac{1}{n}\sum{\ln{E(X_i)}} = -\frac{1}{n}\sum{\ln{\frac{1}{1 + \theta}}} = \ln(1 + \theta)$$
where I found $E(X_i)$ as follows: $$ E(X) = \int_0^1{x f(x, \theta) dx} = \frac{1}{\theta}\int_0^1{x^{1/\theta}} = \frac{1}{1 + \theta} x^{\frac{1 + \theta} {\theta}}{\huge\rvert}_0^1 = \frac{1}{1 + \theta}$$ Okay, thanks to @CommongerG for pointing out my mistake in his answer. We have 
$$E(\hat{\theta}) = -\frac{1}{n}\sum{E(\ln{X})} = -E(\ln{X})$$
So I need to show $E(\ln{X}) = -\theta$. Well, $$ E(\ln{X}) = \int_0^1{\ln{x} f(x, \theta) dx} = \theta^{-1}\int_0^1{x^{\frac{1-\theta}{\theta}}\ln{x}dx}$$ Thank you @MlleM for pointing out my calculus error. I finally got the desired result. Letting $u = \ln{x}$ and $dv = \theta^{-1}x^{\frac{1-\theta}{\theta}} dx$, we have $du = \frac{dx}{x}$ and $v = x^{\frac{1}{\theta}}$. Then this solves as: $$ E(\ln{X}) = x^{\frac{1}{\theta}}\ln(x){\large\rvert}_0^1 - \int_0^1{x^{\frac{1}{\theta}}dx}{\huge\rvert}_0^1 = 0 - \theta x^{\frac{1}{\theta}} {\huge\rvert}_0^1 = - \theta$$","['maximum-likelihood', 'statistics', 'log-likelihood', 'proof-verification']"
1635347,What lies beyond the Möbius transform?,"Consider the matrix $\pmatrix{a & b \\ c & d} ^n$ This is isomorphic to the $n$ th iteration of the Möbius transform $\frac{a z + b}{c z + d}$ when the determinant is nonzero. So I wonder what is the analogue isomorphism from a power of a $3 \times 3$ matrix to the iteration of an analytic function ? I prefer to stay on the complex plane, so I am not so intrested in iterating functions defined for noncomplex numbers or more than 2 dimensions.","['matrices', 'mobius-transformation']"
1635402,Probability of every ball occurring in multiple independent random samples,"An urn contains 5 distinct numbered balls. You choose 2 without replacement. You then reset the urn and choose another 2 without replacement. Do this one more time. Now you have three random samples of size 2. What is the probability that all of the numbered balls appear at least once in your 3 random samples of size 2? My thinking of a way to approach this is through complements. Finding the probability one of the balls is missing, two, and three. Then subtracting all of these scenarios from one. Is this a solid approach? Here is the work: P(all numbered balls appear at least once) = 1 - P(at least one ball is missing) P(at least one ball is missing) = P(one ball missing) + P(two balls are missing) + P(three balls are missing) I found the probabilities of one ball, two balls, and three balls missing to be the following: P(one ball missing) = $$\left(1*{4 \choose 2}/{5 \choose2}\right)^2$$ P(two balls missing) = $$\left(1*{3 \choose 2}/{5 \choose2}\right)^2$$ P(three ball missing) = $$\left(1*{2 \choose 2}/{5 \choose2}\right)^2$$ This is because the first time you can choose any three balls, in the one ball missing case, you can only choose two balls from four when there are five possible balls. You can choose either the two that are original or any combination with a different arbitrary two but one must be left out. This is true for both random samples following the first. Any thoughts?","['probability', 'polya-urn-model', 'random-variables']"
1635406,Locally square integrable (local) martingales,"I'm reading Protter and sometimes he says ""locally square integrable martingale"", and sometimes he says ""locally square integrable local martingale"", and I wonder if these two are the same. Protter's definition is a property holds locally for $X$ if there are $T_n$ increasing to $\infty$ such that $X^{T_n}1_{T_n>0}$ has the property. Then a local martingale is an adapted cadlag $X$ which is locally a martingale. Protter also proves that a cadlag $X$ which is locally a local martingale is a local martingale. Now I try to parse ""locally square integrable local martingale"". If $X$ is such that it is locally a square integrable local martingale, in particular $X$ is locally a local martingale, and hence is a local martingale. Thus the question reduces to is ""(locally square integrable) + (local martginale) = locally (square integrable martingale)""? I think they are the same because if $T_n$ makes $X^{T_n}1_{T_n>0}$ a martingale, and $S_n$ makes $X^{S_n}1_{S_n>0}$ square integrable, then $T_n \wedge S_n$ should make $X^{T_n \wedge S_n}1_{T_n \wedge S_n > 0}$ a square integrable martingale. Is this line of reasoning correct or am I missing something?","['stochastic-processes', 'local-martingales', 'probability-theory', 'martingales', 'stochastic-analysis']"
1635411,Integral of a trig function divided by the square root of a polynomial: $\int_a^b\frac{\sin x}{\sqrt{(x-a)(b-x)}}dx$?,I was trying to help some physics students with an integral on their homework and they've presented me with something that has me stumped. The integral they are working on is: $$\int_a^b\frac{\sin x}{\sqrt{(x-a)(b-x)}}dx$$ They're definitely going to need a change of variable but any changes to simplify the bottom portion will greatly complicate the top. Any suggestions on how to tackle such a beast?,"['radicals', 'definite-integrals', 'integration', 'trigonometry']"
1635412,Integral of $x^2 e^{-x^2}$,"Like the title says, I'm trying to find $$\int_0^r x^2 e^{-x^2}\,dx$$ Where $r$ is some finite value. I've done one step using integration by parts with $u=x^2$ and $dv=e^{-x^2}dx$, which has left me with $$\left.x^2 \int_0^x e^{-t^2}\,dt\,\right|_0^r - \int_0^r 2x \int_0^x e^{-t^2}\,dt\,dx$$ and more questions than answers. I'm aware that the integrals in $t$ are a scaling of the error function, and don't have a representation in elementary functions. For the second term in this I think I should try another integration by parts, but then I would need the integral of the error function, and am not sure how to get that either. Am I going about this the right way? What do I do next?","['exponential-function', 'integration', 'definite-integrals', 'error-function']"
1635438,Could I do this to an infinite series?,If a had two series like so: $$\lim_{n\rightarrow \infty} \sum^{n}_{i=1} i + \sum^{\infty}_{k=1} k $$ Is it logical for me to say: $$\lim_{n\rightarrow \infty} \sum^{n}_{i=1} i = \sum^{\infty}_{i=1} i $$ Therefore: $$\lim_{n\rightarrow \infty} \sum^{n}_{i=1} i + \sum^{\infty}_{k=1} k $$ $$=$$ $$ \sum^{\infty}_{k=1} k + \sum^{\infty}_{k=1} k $$ $$=$$ $$ \sum^{\infty}_{k=1} 2k$$ Is this wrong?,"['sequences-and-series', 'limits']"
1635471,Is $f(x) = \frac{5x^2}{1+x^2}$ bounded?,"Show that $$f(x) = \frac{5x^2}{1+x^2}$$ is a bounded function? I know that if $x=0$ the function is undefined, but how can you prove that it is bounded? Help is much appreciated!","['algebra-precalculus', 'functions']"
1635481,Prove $|P(0)|\leq 2n+1$,"Let $P(x)$ be a polynomial with degree $\leq n$ and $|P(x)|\leq\frac{1}{\sqrt{x}}$ for $x\in(0,1]$. Prove that $|P(0)|\leq 2n+1$. The idea should be that if $|P(0)|$ is too large, then the polynomial cannot change values fast enough to avoid intersecting the curve $ \pm 1/\sqrt{x}$, but I don't see how to formalize this.","['algebra-precalculus', 'approximation-theory', 'polynomials', 'calculus']"
1635486,"What is sample variance of sample variance, and what is theoretical sampling distribution?","I am trying to work some things in R and I am having trouble understanding some of the instructions. I generated $1000$ samples of size $5$ from the standard normal distribution, and I calculated the mean of the sample variance of these. Now I want to know what the sample variance of my sample of sample variances is. But I am not sure I understand really what this means, nor how to implement this in R. Further, I am asked to overlay the histogram I generated from my sample with a histogram of the theoretical density of the sampling distribution. What does this mean? Ie, what is meant by the theoretical density of the sampling distribution of the sample variance. I know all my samples are coming from standard normal, where $\sigma^{2}=1$ and I know that if $X_{N}=X_{1}+...+X_{1000}$ would be $N(0,\frac{\sigma^{2}}{1000})$, is this at all what is being referred to? I will appreciate any help and advice. Thank you","['statistics', 'probability', 'computer-algebra-systems']"
1635490,Characterize units in formal power series $R[[x]]$ [duplicate],"This question already has answers here : If $a_0\in R$ is a unit, then  $\sum_{k=0}^{\infty}a_k x^k$ is a unit in $R[[x]]$ (3 answers) Closed 8 years ago . Suppose $R$ is a commutative ring with unity. Define $R[[x]]$ as ""formal power series in the variable $x$ with coefficients from $R$"". These are the infinite sums of the form 
$
    \sum_{n=0}^\infty a_ix^i,  a_i\in R.
$ Is there any way to characterize all of the units in this ring $R[[x]]$?","['abstract-algebra', 'ring-theory']"
