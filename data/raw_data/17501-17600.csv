question_id,title,body,tags
143785,A solution to a system of homogeneous polynomials in three variables,"If one has (say) five degree $3$ homogeneous polynomials $f_1,f_2,f_3,f_4,f_5$ in three variables $x,y,z$, and $f_j(x_0,y_0,z_0)=0$ for all $j$ for some fixed $(x_0,y_0,z_0)$, can we conclude that there must be some relationship between some of these polynomials? In short, is there something linear algebraic that one can exploit to show that this can't happen given certain conditions on these $f_j$? Obviously given any specific set of these guys we can use ""back substitution"" in order to determine whether they can have simultaneous zeros, but I would love to know if algebraic geometry and friends can offer a more general approach.","['linear-algebra', 'algebraic-geometry']"
143790,Vanishing of higher cohomology,"If $M$ is a manifold of dimension $n$, does singular cohomology $H^i(M, \mathbb{C})$ vanish when $i > n$ ? If $M$ is an algebraic variety over $\mathbb{C}$, equipped with ordinary topology, can one say something about the vanishing of higer singular cohomology?","['algebraic-geometry', 'algebraic-topology']"
143796,Number of $\sigma$  -Algebra on the finite set,Let $X$ is a nonempty set with $m$ members . How many $\sigma$ -algebra can we make on this set?,"['measure-theory', 'elementary-set-theory', 'real-analysis']"
143801,Average sine of an angle between two rays in a cone,"I'm looking for an average value of sine of an angle between two rays, lying within a cone with a certain angle. Given a cone with an aperture of ${2\chi}$ and two rays lying within the cone. The rays can be represented as vectors in a spherical coordinate system: $$
{\vec{e_1}=\lbrace1,\phi_1,\theta_1 \rbrace},{\vec{e_2}=\lbrace1,\phi_2,\theta_2 \rbrace}
$$ where ${\phi_1,\phi_2\in[0,2\pi], \theta_1,\theta_2\in[0,\chi]}$ (assuming the axis of the cone is aligned with the z axis). The distribution of every angle is uniform. It is needed to find the average value of the sine of the angle between the rays (vectors). We can get an answer by simply integrating the sine within a needed area:
$$
{{\frac{1}{4\pi^2\chi^2}}\int\limits_{0}^{\chi}\int\limits_{0}^{\chi}\int\limits_{0}^{2\pi}\int\limits_{0}^{2\pi}\sin(\vec{e_1},\vec{e_2})d\phi_1\phi_2\theta_1d\theta_2}
$$ We can get cosine of an angle between the vectors using the dot product: $${\cos(\vec{e_1},\vec{e_2})=\frac{(\vec{e_1},\vec{e_2})}{|\vec{e_1}||\vec{e_2}|}}=\sin\theta_{1}\sin\theta_{2}\cos\left(\phi_{1}-\phi_{2}\right)+\cos\theta_{1}\cos\theta_{2}$$ Using this an average value of cosine can be easily got: $$
{{\frac{1}{4\pi^2\chi^2}}\int\limits_{0}^{\chi}\int\limits_{0}^{\chi}\int\limits_{0}^{2\pi}\int\limits_{0}^{2\pi}\cos(\vec{e_1},\vec{e_2})d\phi_1\phi_2\theta_1d\theta_2=\frac{\sin^2\chi}{\chi^2}}
$$ But I didn't have much luck trying to get the average value of sine. I can't solve this: $$
{{\frac{1}{4\pi^2\chi^2}}\int\limits_{0}^{\chi}\int\limits_{0}^{\chi}\int\limits_{0}^{2\pi}\int\limits_{0}^{2\pi}\sqrt{1-\left(\sin\theta_{1}\sin\theta_{2}\cos\left(\phi_{1}-\phi_{2}\right)+\cos\theta_{1}\cos\theta_{2}\right)^{2}}d\phi_1\phi_2\theta_1d\theta_2}
$$ Using the Monte-Carlo simulation I got this curve: Any help would be appreciated!","['geometry', 'uniform-distribution', 'integration', 'average', 'trigonometry']"
143807,History behind Exact Sequences.,I am very much interested in listening to the history behind the exact sequence. We know that the exact sequence is sequence of objects with morphisms such that image of one morphism equals to the kernel of the next one. But how did the whole idea start ? . What is the motivation behind considering the image and kernel equality and linking groups ? . How did the exact sequences come into play ?. I want to hear some on some of the above things. Thank you.,"['homological-algebra', 'math-history', 'motivation', 'abstract-algebra']"
143826,Names of higher-order derivatives,"Specific derivatives have specific names. First order is often called tangency/velocity, second order is curvature/acceleration. I've also come across words like Jerk, Yank, Jounce, Jolt, Surge and Lurch for 3rd and 4th order derivatives. Is there a widely agreed list of names for these? How many orders have specific names? In this case, I'm dealing with NURBs curves, so the ""tangency"" and ""curvature"" related words are to be preferred over ""velocity"" and ""acceleration"" words.","['terminology', 'derivatives']"
143827,How to calculate distance between point and object in 3d space,"I have object in 3d space created from points $P_i(x, y, z)$ from which I can create triangles, and I need to calulate distance from point X to this object. I try to take 3 points from smallest distance and calulate height of tetrahedron created from this 3 points and X , but this will be not the distance from the object. So my question is how to calculate this distance.","['analytic-geometry', 'geometry', '3d']"
143828,Question about a property certain algebraic extensions $E/K$ (not necessarily separable) have.,"A few days ago I found this question here on math.stackexchange, which gave a sufficient criterion for a separable, algebraic extension $E/K$ to be an algebraic closure of $K$. However it was claimed by KCd, in a comment below the question I'm referring to, that we can drop the separability condition on the extension and still get the same result My question is: how does the proof work in the non-separable case? Put precisely: Let $E/K$ be an algebraic extension such that every non-constant polynomial in $K[X]$ has a root in $E$, then $E$ is the (up to isomorphism) algebraic closure of $K$. It is pretty clear to me that Makotos proof in the separable case (which can be found on the page the link above is leading to) won't work for the case of a non-separable extension (e.g. because the primitive element theorem may fail). I had some ideas of working with the separable closure but didn't try much, because I didn't see a real perspective in my approach. In other words, I'm stuck. Lastly an apology: I refrained from asking KCd this question directly because it might be of common interest. Regards","['abstract-algebra', 'field-theory']"
143837,Intuition for the Poisson kernel,"The derivation of the Poisson kernel for a disc seems to involve a trick, and I don't really understand how one would come up with it. Let $f$ be a holomorphic function on a disc $D_{R_0}$ centered at the origin and of radius $R_0$. We are aiming for some sort of integral representation of $f$ with a real-valued kernel, which ends up to be $$f(z) = \frac{1}{2\pi}\int_0^{2\pi} f(Re^{i\varphi}) \text{Re}\left(\frac{Re^{\varphi} + z}{Re^{i\varphi} - z}\right) \; d\varphi$$ So the trick used is to write $$f(z) = \frac{1}{2\pi i} \int_{D_{R_0}} f(\zeta)/(\zeta-z) - f(\zeta)/(\zeta-R^2/\bar{z}) \; d\zeta$$ I'm not sure how one would come up with adding $f(\zeta)/(\zeta-R^2/\bar{z})$, except for the fact that it magically seems to work. I've tried working backwards, but it really hasn't given me any new insight into the problem.","['integration', 'complex-analysis']"
143838,Convergence in probability in relation to large sample variance,"I have a (possibly simple) question: If a sequence of scalar random variables, $\{ X_T \}_{T=1}^{\infty}$, convergences in probability to a constant $c$, does that imply that the variance of $X_T$ converges to $0$? In other words, if one has an estimator $\hat{\beta}_T$ of a true parameter value $\beta_0$ with $Var(\hat{\beta}_T)$ converging to a non-zero constant, can this estimator be a consistent estimator of $\beta_0$? Thanks in advance.",['probability-theory']
143856,Is every killed Markov process still a Markov process?,"Suppose we've got $X=(X(t))_{t\geq 0}$. $X$ is a strong Markov process with respect to filtration $\mathcal{F}_t$, taking values in some subset of $\mathbb{R}$. We take $\tau$ - a stopping time w.r.t $\mathcal{F}_t$ and we kill $X$ in $\tau$ obtaining new process $Y$ which is given by $$
Y(t)=\left\{
\begin{array}{ll}
 X(t), & \textrm{ for }  t<\tau\\
 \Delta, & \textrm{ for } t\geq \tau
\end{array}
\right..
$$
where $\Delta$ is an isolated point. We can then ask if $Y$ is still strong Markov process. There are a lot examples when it is (e.g. when $\tau$ is terminal time) however I am interested in an example when it isn't . I've got simple examples when killing destroys some other properties (e.g time-homogenity) but Markov property seems not so easy to eliminate. I would be very thankful for any ideas.","['probability-theory', 'stochastic-processes', 'markov-process']"
143857,"$C[0,1]$ is NOT a Banach Space w.r.t $\|\cdot\|_2$","I'm trying to find a cauchy sequence in $C[0,1]$ that converges under $\|\cdot\|_2$ to a limit which isn't continuous. Any ideas?","['hilbert-spaces', 'functional-analysis', 'banach-spaces']"
143872,"Computing the trace and determinant of $A+B$, given eigenvalues of $A$ and an expression for $B$","Let $A$ be $4\times 4$ matrix with real entries such that $-1$, $1$, $2$, and $-2$ are its eigenvalues. If $B = A^4 - 5A^2+5I$, where $I$ denotes $4\times 4$ identity matrix, then what would be determinant and trace of matrix $A+B$?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'determinant']"
143873,Iterated Root Mean Square-Arithmetic Mean,"Can I find iterated Root Mean Square-Arithmetic Mean as a function of Arithmetic-geometric mean (AGM) with some transformations if it is possible? if not possible, what is the closed form of it as known functions ? $$AGM=M(x,y)=\frac{\pi}{4}\frac{x+y}{K(\frac{x-y}{x+y})}$$ where $K(m)$ is the complete elliptic integral of the first kind: $$K(m)=\int_{0}^{\frac{\pi}{2}} \frac{dx}{\sqrt{1-m^2\sin^2(x)}}$$ Iterative Root-Mean Square-Arithmetic Mean calculation: $$r_1=\sqrt{\frac{r_0^2+a_0^2}{2}}$$ $$a_1=\frac{r_0+a_0}{2}$$ $$r_{n+1}=\sqrt{\frac{r_n^2+a_n^2}{2}}$$ $$a_{n+1}=\frac{r_n+a_n}{2}$$ Root Mean Square-Arithmetic Mean of $(r_0,a_0)=RMSAM(r_0,a_0)=\lim\limits_{n\to \infty} r_{n}=\lim\limits_{n\to \infty} a_{n}$ Thanks a lot for answers","['special-functions', 'sequences-and-series', 'functions']"
143876,Remove every (k+1) th remaining element in kth pass of natural numbers,"In the natural numbers series, we've to remove every 2nd element in the 1st pass. Then in the remaining elements, remove every 3rd element in the second pass. Then at Kth pass, remove every (k+1)th element from the remaining elements. The series will go like this 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, ... After 1st pass(after removing every 2nd element), 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, ... After 2nd pass,(after removing every 3rd element), 1, 3, 7, 9, 13, 15, 19, 21, 25, 27, ... After 3rd pass,(after removing every 4th element), 1, 3, 7, 13, 15, 19, 25, 27, ... So, after infinity pass, it will become 1, 3, 7, 13, 19, 27, 39, 49, 63, 79, ... This series is also called Flavius-Josephus sieve. The solution for this, to find the 6th element in the series: do 6^2 = 36 go down to a multiple of 5 giving 35 then down to a multiple of 4 = 32 then down to a multiple of 3 = 30 then down to a multiple of 2 = 28 then down to a multiple of 1 = 27 and so the 6th lucky number is 27. Though it works, I'm not understanding how the solution works ? A C program for this is, int calc(int n)
{
   if (n == 1) return 1;
   return calc_rec(n*n, n-1);
}

int calc_rec(int nu, int level)
{
   int tmp;
   if (level == 1) return (nu-1);
   tmp = nu % level;
   return calc_rec(nu - (tmp ? tmp : level), level-1);
} The link explaining this http://oeis.org/A000960","['algorithms', 'number-theory']"
143884,Quantile of Chi-squared = inverse Quantile of inverse Chi-squared distribution?,"I used to think that the following held true: If $Y\sim \chi^2$, then $\frac{1}{Y}\sim \operatorname{inv}\chi^2$, the inverse $\chi^2$-distribution. Let $\chi^2_\alpha$ denote the $\alpha$-quantile of $Y$, then $\frac{1}{\chi^2_\alpha}$ is the $\alpha$-quantile of $\frac{1}{Y}$, meaning $$P\left(Y\leq \chi^2_\alpha\right)=P\left(\frac{1}{Y}\leq\frac{1}{\chi^2_\alpha}\right)=\alpha.$$ Now I figured out that this cannot be true, right? But what is the relationship between the two quantiles then? (Or is it true after all?)","['statistics', 'probability-distributions']"
143893,"$\|\cdot\|_1 \leq \|\cdot\|_2 \leq \|\cdot\|_{\infty}$ for functions in $C([0,1])$?","Why does the following hold for continuous functions on $[0,1]$? $\|\cdot\|_1 \leq \|\cdot\|_2 \leq \|\cdot\|_{\infty}$","['normed-spaces', 'hilbert-spaces', 'functional-analysis', 'banach-spaces']"
143895,How can I prove $\ e^n=\sum_{k=0}^\infty\frac{n^k}{k!}$,"Given 
$$
e=\sum\limits_{k=0}^\infty\frac{1}{k!}
$$
How can I prove 
$$
e^n=\sum\limits_{k=0}^\infty\frac{n^k}{k!}
$$ Can anyone please demostrate the $n=2$ case? Thanks!",['sequences-and-series']
143896,maps with connected fibers,"Let $\pi: X \to S$ be a morphism of schemes. I will say $\pi$ is ""pseudoconnected"" if $\mathcal{O}_S \to \pi_* \mathcal{O}_X$ is an isomorphism (this is not standard language). If $\pi$ is proper with connected fibers, can we deduce that $\pi$ is pseudoconnected? I think this follows from Zariski's main theorem (the version that says a proper morphism is a pseudoconnected morphism followed by a finite morphism) but I am squeamish because Hartshorne doesn't explicitly say this (even for projective morphisms). What if instead $\pi$ is proper with geometrically connected fibers?",['algebraic-geometry']
143897,Wrapping curves,"Let's say we have a parametric $3\mathrm{d}$ curve $C$. How to ""wrap"" a helix around it? For a helix $(\sin(t),\cos(t),t)$, how to ""replace"" the $z$ axis with curve $C$?",['geometry']
143914,inequality in a differential equation,"Let $u:\mathbb{R}\to\mathbb{R}^3$ where $u(t)=(u_1(t),u_2(t), u_3(t))$ be a function that satisfies $$\frac{d}{dt}|u(t)|^2+|u|^2\le 1,\tag{1}$$where $|\cdot|$ is the Euclidean norm. According to Temam 's book paragraph 2.2 on page 32 number (2.10), inequality (1) implies $$|u(t)|^2\le|u(0)|^2\exp(-t)+1-\exp(-t),\tag{2}$$but I do not understand why (1) implies (2).","['dynamical-systems', 'ordinary-differential-equations', 'analysis']"
143927,Is $\left(\sum\limits_{k=1}^\infty \frac{x_k}{j+k}\right)_{j\geq 1}\in\ell_2$ true if $(x_k)_{k\geq 1}\in\ell_2$,"Let $(x_k)_{k\geq 1}\in\ell_2$. Consider $\left(\sum\limits_{k=1}^\infty \dfrac{x_k}{j+k}\right)_{j\geq 1}$. Now my question is that whether $\left(\sum\limits_{k=1}^{\infty}\frac{x_k}{j+k}\right)_{j\geq 1}$ belongs to $\ell_2$ or not. The following is an idea, but I am not sure whether it's right. Let $\varphi(t)=i(\pi-t)$ be a $2\pi$-period function. Then it's easy to see that $\widehat\varphi(n)=\frac{1}{n}$ for every nonzero $n\in\mathbb Z$ and $\widehat \varphi(0)=0$. Then we obtain
 $$\sum\limits_{1\leq j,k\leq N}\frac{a_jb_k}{j+k}=\frac{1}{2\pi} \int_0^{2\pi}\left(\sum\limits_{j=1}^N a_j e^{-ijt}\right)\left(\sum\limits_{k=1}^Nb_ke^{-ikt}\right)\varphi(t)dt$$
 where $(a_1,\cdots,a_N),(b_1,\cdots,b_N)\in\mathbb C^N$.Then by Cauchy-Schwarz inequality, we have $$\left|\sum\limits_{1\leq j,k\leq N}\frac{a_jb_k}{j+k}\right|\leq\|\varphi\|_{\infty}\left|\left(\sum\limits_{j=1}^N|a_j|^2\right)^{1/2}\left(\sum\limits_{k=1}^N|b_k|^2\right)^{1/2}\right|.$$
Now for any $x,y\in \ell_2$, we have $$\left|\langle u(x),y\rangle\right|\leq \|\varphi\|_{\infty}\|x\|_2\|y\|_2$$
where $u(x)=(\sum\limits_{k=1}^{\infty}\frac{x_k}{j+k})_{j\geq 1}$. Note that $\langle u(x),y\rangle$ exists, since $\lim\limits_{N\to\infty}\sum\limits_{1\leq j,k\leq N}\frac{|x_j||y_j|}{j+k}$ exists. Then $\langle u(x),\cdot\rangle$ is a linear functional on $\ell_2$ for fixed $x\in\ell_2$. By Riesz representation theorem, there exists $z\in \ell_2$ such that $\langle u(x),y\rangle=\langle z,y\rangle$ for all $y\in\ell_2$. Hence $z=u(x)$, i.e. $u(x)=z\in\ell_2$. Maybe I have made some mistakes in the proof. And anyone know some other proofs? Thank you for you help.",['functional-analysis']
143932,"Calculate point, given x, y, angle, and distance","Excuse my ignorance and use of incorrect terms, but... I have x and y coordinates, and the angle that the entity is facing on a 2D plane.  I want to find the correct point, say 5 units in front of the point I have. Examples: If my entity is at 0, 0 and is facing east (0 degrees), my point would be 5, 0.

If my entity is at 0, 0 and is facing north (90 degrees), my point would be 0, 5.

If my entity is at 0, 0 and is facing north-east (45 degrees), my point would be ???. I can't even figure it out in my head, let alone figure out the formula I need.  I assume I need trigonometry, but I'm old and haven't used it since 1997.","['geometry', 'trigonometry']"
143939,Strassen Multiplication?,"How are the values of the 7 new matrices derived? I'm referring to the values that reduce matrix multiplication to 7 multiplications per level: $M_1 = \left(A_{1,1} + A_{2,2}\right)\left(B_{1,1} + B_{2,2}\right)$ ... $M_7 = \left(A_{1,2} - A_{2,2}\right)\left(B_{2,1} + B_{2,2}\right)$ Could someone show how these values were arrived at?",['matrices']
143954,isolated non-normal surface singularity,"I am looking for an isolated non-normal singularity on an algebraic surface. One obvious example occurs to me: the union of two $2$-dimensional affine subspaces of $\mathbb{A}^4$ which meet in a point. But this seems like ""cheating."" Can someone provide an irreducible example?","['algebraic-geometry', 'surfaces']"
143963,"Calculus on Manifolds (Spivak), problem 2-41(a)","Let $f:\mathbb{R}\times\mathbb{R}\to\mathbb{R}$ be differentiable. For each $x \in \mathbb{R}$ define $g_x:\mathbb{R}\to\mathbb{R}$ by $g_x(y) = f(x,y)$. Suppose that for each $x$ there is a unique $y$ with $g_x'(y) = 0$; let $c(x)$ be this $y$. (a) If $D_{2,2}(x,y) \neq 0$ for all $(x,y)$, show that $c$ is differentiable and $c'(x) = -\dfrac{D_{2,1}f(x,y)}{D_{2,2}f(x,y)}$. Hint : $g_x'(y) = 0$ can be written $D_2f(x,y) = 0$. I looked at the solution for this problem and it basically seems to go like this: Apply the implicit function theorem to obtain a differentiable local solution to $D_2f(x,y) = 0$ at each $(x, c(x))$. Since there is only one $c(x)$ for which $D_2f(x,c(x)) = 0$ at each $x$, each of these local solutions must agree with $c$. Therefore, by gluing together all these local solutions, we get an everywhere differentiable function identical to $c$. Since we know $c$ is a differentiable function, we can differentiate the relation $D_2f(x,c(x)) = 0$ using the chain rule (Theorem 2-9), which immediately gives the desired result. I understand everything in this solution except for the following: before we can apply the implicit function theorem to $D_2f(x,y) = 0$, we need $D_2f$ to be continuously differentiable, and the problem statement doesn't seem to permit that assumption. How is this resolved?",['multivariable-calculus']
143981,intrinsic and geometric definition of blow-up,"Suppose I am given an algebraic variety $X$ and a (closed) point $x \in X$. I know of two descriptions of the blow-up of $X$ at $x$. One is intrinsic but not geometric: if $\mathcal{I}_x$ denotes the ideal sheaf of $x$ then we can define the blow-up to be $\text{Proj} \ \mathcal{O}_X \oplus \mathcal{I}_x \oplus \mathcal{I}_x^2 \oplus \cdots$. The other, which works only when $X$ is quasi-projective, is geometric but not intrinsic: one chooses an embedding $X \to \mathbb{P}^n$, defines the blow-up of $\mathbb{P}^n$ at a point explicitly in coordinates, and then takes the proper transform (or whatever the terminology is) of $X$. I hope there is a construction which is both intrinsic and geometric (it may be nothing but a repackaging of the $\text{Proj}$ definition). Here is a starting point to indicate what I'm looking for. Suppose $x \in X$ is a nonsingular point for simplicity, so the tangent space $T_xX$ is well-behaved. As I understand it, the blow-up is set-theoretically $X \setminus \{ x \} \sqcup \mathbb{P}(T_xX)$, but obviously this is not a disjoint union in the sense of varieties. How does one make this into a variety?","['algebraic-geometry', 'projective-geometry', 'definition']"
143982,Proof of identity $\ln \left|\frac{\sin x}{\cos x - 1}\right| = \ln \left|\frac{\cos x + 1}{\sin x}\right|$,"How do you prove this identity:
$$\ln \left|\frac{\sin x}{\cos x - 1}\right| = \ln \left|\frac{\cos x + 1}{\sin x}\right|$$ Mathematica says it's true, but if I try to simplify both sides, I wind up with
$$ \sin^2 x = \cos^2 x - 1$$
which ain't right.","['trigonometry', 'algebra-precalculus']"
143986,Is there a simple expression for universal quantification without vacuous truth?,"I'm working on a software problem and trying to describe it in symbolic logic so that I can get my head around it. I have $isnt(n) := \mathbf{F} \neq \emptyset \wedge \forall f \in \mathbf{F} : P(n,f)  $ Basically, I'm checking n against all elements in F , unless F is empty. Is there a way to simplify this so as to have no conjunctions (or disjunctions) outside of the quantifiers","['logic', 'elementary-set-theory']"
143988,How to prove the Closed map lemma,"The closed map lemma says that if $f : X \to Y$ is a continuous function, $X$ is compact and $Y$ is Hausdorff, then $f$ is a closed map. How can I prove this ? Here is my attempt so far: Suppose for contradiction that $f$ is not a closed map. Then there exists a closed subset $V$ of $X$ whose image $f(X)$ is not closed in $Y$. This means that there exists a convergent sequence $(w_n)_{n \in \mathbb{N}}$ in $f(V)$ whose limit is not contained in $f(V)$. Now by compactness of $X$, we know the inverse image $f^{-1}((w_n)_{n \in \mathbb{N}})$ of the sequence contains a limit point, denote it by $z$, which lies in $V$ (as $V$ is closed). But then, by continuity of $f$, we also know that $f(z)$ must be a limit point of the sequence $(w_n)_{n \in \mathbb{N}}$. By the fact that the latter converges, we deduce that this limit point must be the unique limit. Thus we have \begin{equation}
 V \ni z \mapsto f(z) \notin f(V)
\end{equation} which is a contradiction. Here is my question: Where does the Hausdorff condition for $Y$ enter the proof ? Since it is not mentioned in my above attempt I must have a mistake somehwhere .. what did I miss ? Many thanks for your help !!",['general-topology']
143995,Is always true that: $ v(\cup_{n=1}^{\infty} A_n) \leq \sum\limits_{n=1}^{\infty} v(A_n)$?,"Let $v : \mathcal {P}(\mathbb R) \to [0,\infty]$ a set-function such that $\displaystyle{ v(F \cup E) \leq v(E) + v(F)  \quad \forall E,F \subset \mathbb R}$. Is always true that: $ \displaystyle{ v\left(\bigcup_{n=1}^{\infty} A_n\right) \leq \sum_{n=1}^{\infty} v(A_n)}$ ? I think this is not but I can't find a counterexample. Any help? Thank's in advance!",['measure-theory']
144007,Irreducible component of fibre product of schemes,"I have some questions about algebraic geometry which might be elementary and boring (sorry). Let $R$ be a ring - say, an integral domain which is Noetherian. Let $X$ and $Y$ be $R$-varieties - that is, integral separated schemes of finite type over $R$. Let $f: X \to Y$ be a dominant morphism of $R$-varieties. Let $\beta: Y' \to Y$ be a proper, birational morphism. I believe that the fibre product $X \times_Y Y'$ can be reducible but does anyone know a simple example of this phenomenon? Is it true that the fibre product $X \times_Y Y'$ has a unique irreducible component $X'$ which dominates $Y'$? If the answer to the previous question is yes, is it true that the composition $X' \to X \times_Y Y' \to X$ is birational?",['algebraic-geometry']
144016,"Notationally, what is the difference between $\Pr(X = x)$ and $P(X = x)$? When should I use each?","I'm talking specifically about probability theory. I was reading some stuff about probabilistic graphical models, and they kept switching the notation in this book, but I couldn't discern the difference by context. One possible hypothesis is that they are subtly different, e.g., $P$ is a probability measure, while $\Pr$ is an unnormalized probability measure (or something; I really have no idea).","['probability-theory', 'probability', 'notation']"
144018,Power rule for the limits of convergent sequences,"The ""Power Rule"" for null sequences states that If a null sequence of non-negative terms is raised to a positive
  power, the resulting sequence is also a null sequence. Ok, can this rule be generalised to the following? If a sequence of non-negative terms that converges to the limit $l$ is
  raised to a positive power $p$, the resulting sequence converges to
  the limit $l^p$.","['convergence-divergence', 'sequences-and-series', 'real-analysis', 'limits']"
144037,"$T :\mathbb {R^7}\rightarrow \mathbb {R^7} $ is defined by $T(x_1,x_2,\ldots x_6,x_7) = (x_7,x_6,\ldots x_2,x_1)$ pick out the true statements.","Consider the linear  transformations $T :\mathbb {R^7}\rightarrow \mathbb {R^7} $ defined by $T(x_1,x_2,\ldots x_6,x_7) = (x_7,x_6,\ldots x_2,x_1)$. Which of the following statements are true. 1-  $\det T = 1$ 2 - There is a basis of $\mathbb {R^7}$ with respect to which $T$ is a diagonal matrix, 3- $T^7=I$ 4- The smallest $n$ such that $T^n = I$ is even. What i have done so for is I have tried for $T :\mathbb {R^2}\rightarrow \mathbb {R^2} $
 and found that all the statments are true. Can i generalize my conclusion to $\mathbb {R^7} $. Do i need to find $7\times 7$  matrix? Is there any other approach?","['matrices', 'linear-algebra']"
144063,Change of variables to a desirable form,"Suppose we have smooth function $\varphi: \mathbb{R}^n \to \mathbb{R}$ and let $x_0 \in \mathbb{R}^n$ be a non-degenerate critical point. That is,
$$\begin{equation}
\varphi'(x_0) = \nabla \varphi(x_0) = 0, \quad \text{and} \quad \text{det }(\varphi''(x_0)) \neq 0
\end{equation}$$
where $\varphi ''(x)$ stands for the Hessian matrix of second partial derivatives. Suppose that $(r,n-r)$ is the signature of $\varphi '' (x_0)$ (this means that the number of postive and negative eigenvalues is $r$ and $n - r$ respectively). I am currently trying to understand a proof for the Morse Lemma, in which it is taken for granted that I see the following statement as trivial: Given the above assumptions, after a translation and a linear change of coordinates, we may assume that $x_0 = 0$ and that
$$\begin{equation}
\varphi(x) = \frac{1}{2}(x^2_1 + \cdots + x_r^2 - x^2_{r + 1} - \cdots - x_n^2) + \mathcal{O}(|x|^3) \quad x \to 0
\end{equation} $$ Why is this so? I understand that the translation $y(x) = x - x_0$ gives me the result that $y(x_0) = 0$. Then I think I need to apply a linear transformation that somehow involves the Hessian $\varphi^''(x_0)$, but I need to diagonalize and rescale it, that is I need to transform to a basis of its eigenvectors that are scaled by the inverses of the eigenvalues, so that I get the $\pm \frac{1}{2}$ - coefficients. Then I think I need to use Taylor's expansion? I can use the fact that the gradient at $x_0$ is zero. But then I would still need the value $\varphi(0)$ in the above equation$\ldots$ here I guess the text I am using might have a typo. If I could get some feedback on whether the above rough reasoning goes into the right direction that would be a huge help! Many thanks!","['differential-geometry', 'multivariable-calculus', 'calculus', 'real-analysis']"
144066,Let $\alpha$ and $\beta$ be two distinct eigenvalues of $A$ then $ A^3 = \frac{\alpha^3-\beta^3}{\alpha-\beta}A-\alpha\beta(\alpha+\beta)I$?,Let $\alpha$ and $\beta$ be two distinct eigenvalues of a $2\times2$ matrix $A$. Then which of the following statements must be true. 1 - $A^n$ is not a scalar multiple of identity matrix for any positive positive integer $n$. 2 - $ A^3 = \dfrac{\alpha^3-\beta^3}{\alpha-\beta}A-\alpha\beta(\alpha+\beta)I$ For the statement 1 I picked up a diagonal matrix with diagonal entries 1 and -1 whose square comes out to be identity matrix. Thus statement may be false. But for the second statement i am not able to figure out a way to start. This  probably may be easy but I am not able to get this. Please post a small hint so that I may proceed further.,"['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
144078,Number of combinatorial progressions,"A $k$-term combinatorial progression of order $2$ is defined as a set of positive integers $A=\{x_1<x_2<\cdots x_k\}$ such that the set $\{x_{i+1}-x_i:1\le i\le k-1\}$ has cardinality at most $2$. My question is given a positive integer $N$, how many $k$-term combinatorial progressions of order $2$ will exist in $\{1,2\cdots N\}$? If not a closed formula can a reasonable upper bound for this number be deduced? For example if we replace the term combinatorial progression with arithmetic progression then a reasonable upper bound is $N^2/k^2$. Any help or ideas please. Thanks.","['sequences-and-series', 'combinatorics']"
144079,Passing from induction to $\infty$,"Somehow, the operation of passing to the limit after I have shown that something is true by induction for each natural number $n$ troubles me each time. I know there are instances where one cannot deduce a statement is true for $\infty$ if it holds for each $n \in \mathbb{N}$, and sometimes one can. Here is one instance where I am not sure whether my argument is solid: Suppose $X$ is a Banach space with norm $\| \cdot \|$. I would like to show that the triangle inequality for finite linear combinations extends to series.
So, by induction and by properties of the norm we have $$\begin{equation}
\bigg\|\sum^n_{k = 1} a_k \bigg\| \;\;\leq \;\;\sum_{k = 1}^n \|a_k\|
\end{equation}$$ holds for each natural number $n$. I would now argue that I can immediately pass to the limit and deduce directly that $$\begin{equation}
\bigg\|\sum^\infty_{k = 1} a_k\bigg\| \;\;\leq \;\;\sum_{k = 1}^\infty \|a_k\|
\end{equation}
$$ because of a property of sequences of real numbers, which says that if $(c_n)_{n \in \mathbb{N}}$ and $(d_n)_{n \in \mathbb{N}}$ are sequences of real numbers such that \begin{equation}
0 \leq c_n \ \leq d_n \quad \text{ for all } n \in \mathbb{N}.
\end{equation} Then it follows that \begin{equation}
\lim_{n \to \infty} c_n \leq \lim_{n \to \infty} d_n
\end{equation} (I can use this by taking $c_n = \| \sum_{k = 1}^n a_k \|$ and $d_n = \sum_{k = 1}^n \|a_k\|$) Is this reasoning correct ? I am not sure .. For example, one of the issues I have with my argument is the following: When I replace $n$ by $\infty$ in the expression $\|\sum_{k = 1}^n a_k \|$ then I might make a statement that is ill-defined, because $\|\sum_{k = 1}^\infty a_k \|$ might not exist, whereas the expression $\sum_{k = 1}^\infty \|a_k\|$ always has a value in $[0,\infty]$ (since $s_n = \sum_{k = 1}^n \|a_k\|$ is a sequence that is monotone). Is this an issue? Or is the statement $\|\sum_{k = 1}^\infty a_k \| \leq \sum_{k = 1}^\infty \|a_k\|$ simply vacuously true in this case? If it is an issue, how can I rectify the argument?","['normed-spaces', 'sequences-and-series', 'real-analysis']"
144089,Stalk of a point in the intersection of two irreducible components of a Noetherian scheme,"If we have a Noetherian scheme $X$, is it true that for any point $p$ that is in two irreducible components of $X$, then the stalk of $X$ at $p$ is not an integral domain?","['algebraic-geometry', 'schemes']"
144104,Do the notions of weak and weak* convergence coincide for $\ell^1(\mathbb{N})$?,"As my friends and I were studying for our real analysis final exam yesterday, we were playing with various examples and found ourselves asking this question: The space $\ell^1(\mathbb{N})$ is the dual of $c_0(\mathbb{N})$ , and the dual of $\ell^1(\mathbb{N})$ is $\ell^\infty(\mathbb{N})$ . Is it possible to have a sequence $\{b_n\}\in\ell^1(\mathbb{N})$ converge to $b\in\ell^1(\mathbb{N})$ weakly*, but not weakly? We knew that the weak and weak* topologies agree on a reflexive space, and because $\ell^1(\mathbb{N})$ is non-reflexive, we were wondering whether the weak and weak* topologies would agree. Parsing the definitions, this is just asking whether there is a sequence $\{b_n\}\in\ell^1(\mathbb{N})$ such that, for any $r\in c_0(\mathbb{N})$ , we have $$\sum_{k=1}^\infty (b_n)_kr_k\to\sum_{k=1}^\infty b_kr_k\quad \text{ as }n\to\infty,$$ but for some $s\in \ell^\infty(\mathbb{N})$ , $$\sum_{k=1}^\infty (b_n)_ks_k\nrightarrow\sum_{k=1}^\infty b_ks_k\quad \text{ as }n\to\infty.$$ WLOG, we can let take $b=0$ (just subtract $b$ from all the $b_n$ ), so this becomes: Is there a sequence $\{b_n\}\in\ell^1(\mathbb{N})$ such that, for any $r\in c_0(\mathbb{N})$ , we have $$\sum_{k=1}^\infty (b_n)_kr_k\to 0\quad \text{ as }n\to\infty,$$ but for some $s\in \ell^\infty(\mathbb{N})$ , $$\sum_{k=1}^\infty (b_n)_ks_k\nrightarrow 0\quad \text{ as }n\to\infty ?$$ We weren't able to come up with any examples, but of course that doesn't mean there aren't any. Also, just to double-check, were we correct in assuming that it would suffice to check whether weak and weak* convergence of sequences agreed in order to determine whether the weak and weak* topologies agreed?","['topological-vector-spaces', 'sequences-and-series', 'functional-analysis']"
144133,Finding dimension of a vector space,"Let $H_n$ be the space of all $n\times n$ matrices $A = (a_{i,j})$ with entries in $\mathbb{R}$ satisfying $a_{i,j} = a_{r,s}$ whenever $i+j = r+s$ $(i, j , r , s = 1, 2, \ldots, n)$. What would be dimension of $H_n$ as a vector space over $\mathbb{R}$? i have options for the dimension 1 -  $n^2$ 2-   $n^2-n+1$ 3 - $2n+1$ 4- $2n-1$ I am finding difficulty in identifying the matrix $A$ .
thanks for support","['matrices', 'linear-algebra']"
144148,Determinant of symmetric matrix with the main diagonal elements zero,"How to prove that the determinant of a symmetric matrix with the main diagonal elements zero and all other elements positive is not zero (i.e., that the matrix is invertible)? EDIT: OP indicates in a comment that the entries above the diagonal are to be distinct.",['matrices']
144150,"How to write the set of all natural numbers, that can be divided by two?","I would like to write as a mathematical expression such sentence:
x is the set of all natural numbers that can be divided by 2 without the remainder. $\{x \in \mathbb N: What \ here? \} $ Thanks in advance,
Regards,
Misery","['notation', 'elementary-set-theory']"
144162,Is the total variation function uniform continuous or continuous?,"I have been doing some excercises on total variation when the following questions came up to my mind: (1) Let $f$ be continuous on the interval $[0,1]$ and be of bounded variation. Is it true that its total vatiation function $TV(f_{[0,x]})$ is uniformly continuous? i.e. Is it true that for $\forall\space\epsilon>0$, $\exists\space\delta>0$, such that for arbitrary interval $[a,b]$ with $|b-a|<\delta$, we have $TV(f_{[a,b]})<\epsilon$? (2) Alternatively, if it is not uniformly continuous, can I say that for $\forall\space{}x\in[0,1]\text{ and } \forall\space\epsilon>0$ , $\exists\space\text{ nondegenerate interval }I \text{ such that }x\in{}I\text{ and } TV(f_{I})<\epsilon$? Thank you!","['bounded-variation', 'continuity', 'real-analysis']"
144177,Why is this ideal projective but not free?,"Let $R=\mathbb{Z}[\sqrt{-5}]$ and $I=(2,1+\sqrt{-5})$. How can I prove that $I$ is projective but not free?","['ring-theory', 'projective-module', 'abstract-algebra', 'modules', 'commutative-algebra']"
144181,"Exercise in David Cox ""Toric Varieties""","I want to do an exercise in the book Toric Varieties (by David Cox) Exercise 3.3.5. Let $\overline{\phi}:N \rightarrow N'$ be a surjective $\mathbb{Z}$ -linear mapping and let $\widehat{\sigma}$ and $\sigma'$ be cones in $N_{\mathbb{R}}$ and $N'_{\mathbb{R}}$ respectively with the property that $\overline{\phi}_{\mathbb{R}}$ maps $\widehat{\sigma}$ bijectively onto $\sigma'$ . Prove that $\overline{\phi}$ has a splitting $\overline{\nu}:N' \rightarrow N$ such that $\overline{\nu}$ maps $\sigma'$ to $\widehat{\sigma}$ . My approach: we consider the following exact sequence of lattices: $0 \longrightarrow N_0 = ker(\overline{\phi})\longrightarrow N \xrightarrow{ \ \overline{\phi } \ } N' \longrightarrow 0$ Because $N'$ is free over $\mathbb{Z}$ , the exact sequence above splits exact. That is, there exists $\overline{\nu} : N' \rightarrow N$ such that $\overline{\phi} \circ \overline{\nu} = id_{N'}$ . That is, I want find $\overline{\nu}$ such that $\overline{\nu}(\sigma') \subseteq \widehat{\sigma}$ . Recall that the existence of $\overline{\nu}$ is not unique: Because $\overline{\phi}$ is onto, if $N' \simeq \mathbb{Z}^r$ , then $e_j = \overline{\phi}(u_j)$ with $u_j \in N$ for each $j \in \lbrace 1,2,\dots,r \rbrace$ . Since $N'$ is free with $\mathbb{Z}$ -basis $\lbrace e_1,\dots,e_r\rbrace$ , for fixed $\lbrace u_j \rbrace$ we can define $\overline{\nu}$ by extending $e_j \longmapsto u_j$ . Now, let us consider the case of that $\widehat{\sigma}$ is a strongli convex rational polyhedral cone, i.e., we can write $\widehat{\sigma} = \lbrace\widehat{v_1},\dots,\widehat{v_k} \rbrace$ , where $\widehat{v_1},\dots,\widehat{v_k}\in N \subseteq N_{\mathbb{R}}$ and $\widehat{v_1},\dots,\widehat{v_k}$ are linearly independent over $\mathbb{R}$ . Note that for each $\widehat{v_i}$ , $\widehat{v_i} = \sum_{j=1}^r a_{ij}e_j$ with $a_{ij} \in \mathbb{R}$ for $ i =1,\dots,k$ and $j = 1,\dots,r$ . Now, $e_j = \overline{\phi}(\widehat{w_j})$ for each j. We hope $\overline{\nu}(\sum_{j=1}^r a_{ij}e_j) = \widehat{v_i}$ . My main question: (1) What shall I do in next step? (2) Where should I use the hypothesis that $\overline{\phi}_{\mathbb{R}}$ maps $\widehat{\sigma}$ bijectively onto $\sigma'$ ? (3) Is this statement always true for any arbitrary cone?","['algebraic-geometry', 'toric-geometry']"
144186,Set of all injective functions $A\to A$,"If $A$ is denumerable, is the set of all injective functions $A\to A$ equipotent with $2^A$? I have proved $\aleph_0^{\aleph_0} = 2^{\aleph_0}$.",['elementary-set-theory']
144190,Factoring a number $p^a q^b$ knowing its totient,"We are given: $n=p^aq^b$ and $\phi(n)$, where $p,q$ are prime numbers. I have to calculate the $a,b,p,q$, possibly using computer for some calculations, but the method is supposed to be symbolically valid and proper. I know that $\phi(n)=p^{a-1}q^{b-1}(p-1)(q-1)$, but I dont know what can I deduct from this.","['discrete-mathematics', 'number-theory', 'totient-function', 'prime-numbers', 'factoring']"
144202,tangent space at some point of a quasi-projective variety,In order to define the tangent space to a quasi-projective variety $V$ (i.e a locally closed closed subset of $\mathbb{P}^n$ considered with Zariski topology induced from $\mathbb{P}^n$) at a point $p$ we must think of $V$  as an open  subset in a closed sub variety $W$ of some fixed projective space. Could any one explain me with a simple example that how the tangent space is at some point of a Quasi Proj.Variety?,['algebraic-geometry']
144209,Let $A$ be real symmetric $n\times n$ matrix whose only eigenvalues are 0 and 1. Pick out the true statements.,Let $A$ be real symmetric $n\times n$ matrix whose only eigenvalues are $0$ and $1$. Let the dimension of the null space of $A-I$ be $m$. Pick out the true statements. The characteristic  polynomial of $A$ is $(\lambda-1)^m(\lambda)^{m-n}$. $A^k = A^{k+1}$ The rank of $A$ is $m$. This is what I did: I found geometric multiplicity corresponding to eigenvalue value $0$ to be $n-m$(using symmetric matrix is diagonalizable ) while geometric multiplicity of  eigenvalue value 1 is $m$(that is given) .so the characteristic polynomial of $A$ should be $(\lambda-1)^m(\lambda)^{n-m}$. While I am not sure about other two statements. Any kind of help is highly appreciated. Thanks.,"['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
144225,Problem on analytic function.,"Let $f(z)$ be analytic function on $D = \{z\in C : |z-1|<1\}$ such that $f(1) = 1$. If $f(z) = f(z^2)$ for all $z\in D$. Then which of the following statement is not correct. 1-$f(z) = [f(z)]^2$ for all $z\in D$ 2- $f(z/2)$ = $\frac{1}{2}[f(z)]$ for all $z\in D$ 3- $f(z) = [f(z)]^3$ for all $z\in D$ 4- $f'(1) = 0$ I am fully stucked on this problem. 
I need help. Thanks",['complex-analysis']
144228,"Why we need to add the notion of ""separated"" to the notion of variety?","In most case, the definition of a variety over a field $k$ at least requires that being ""of finite type""  and being ""separated"". It has no question for me that being of finite type, since we always like finite. I donot know the reason why we require being ""separated"" to a variety? There is a reason since a scheme over a field $k$ being separated will have the property that the intersection of two affine open sets is still affine open set. Are there any other acceptant reasons? Thanks a lot.",['algebraic-geometry']
144241,"Continuous $f\colon [0,1]\to \mathbb{R}$ all of whose nonempty fibers are countably infinite?","I have been told it is possible to construct a continuous function $f\colon [0,1]\to \mathbb{R}$ such that $f^{-1}(x)$ is either empty or has cardinality $\aleph_0$ for every $x\in \mathbb{R}$. I've thought about this for a while but can't seem to cook up an example. Does anyone know such a construction?","['general-topology', 'real-analysis']"
144256,Sum from $0$ to $n$ of $ n \choose i $? [duplicate],This question already has answers here : Closed 12 years ago . Possible Duplicate: Algebraic Proof that $\sum\limits_{i=0}^n \binom{n}{i}=2^n$ Evaluation $\sum\limits_{k=0}^n \binom{n}{k}$ Is there a simple proof for this equality: $$\sum_0^n  {n \choose i}  = 2^n$$ thanks and sorry I forgot the basics,"['binomial-coefficients', 'combinatorics']"
144270,"Words of Length $n$ over the Alphabet $\{1,2,3\}$ with Certain Restrictions","Let $w(n)$ denote the number of words of length $n$ over the alphabet $\{1,2,3\}$ with the restrictions that in a word the parity of $1$s be even and the parity of $2$s odd. I have written out the possible words for some small values of $n$, hoping to see a relationship which would lead to a recurrence relation, but so far this has not helped. Trying to count the $w(n)$ by considering a general word $a_1a_2...a_n$ and counting possibilites for $a_i$ also doesn't seem to be a tractable solutions because of the dependency between the $a_i$. Any suggestions? I am not looking for an answer to this problem, only for suggestions as to how one approaches a problem of this kind or for hints. Following Ross Millikan's suggestion: Define the functions $OO(n),OE(n),EO(n),EE(n)$, where the first digit represents the parity of $1$ and the second the parity of $2$. Then clearly $$w(n)=OO(n)+OE(n)+EO(n)+EE(n).$$ Furthermore, $w(n)=3^n$ since each of the $n$ letters has three possible values. Now, one can define the function $s:OE(n)\rightarrow EO(n)$ by having it switch $1$ with $2$ and $2$ with $1$. Since this map is bijective, we have $OE(n)=EO(n)$. We can now derive a recurrence for $EO(n)$. An element of $EO(n)$ can be constructed from an element of $OO(n-1)$ by adjoining a $1$, from an element of $EE(n-1)$ by adjoining a $2$ and from $EO(n-1)$ by adjoining a $3$, which gives the recurrence $$EO(n)=OO(n-1)+EO(n-1)+EE(n-1).$$ Using the relationship between our four functions and the symmetry between $EO(n)$ and $OE(n)$ we see that
\begin{align*}
EO(n)&=w(n-1)-OE(n-1)\\
&=3^{n-1}-EO(n-1).
\end{align*}
A closed form for this recurrence can be obtain by using the formula from this question by setting $b=-1,c=1$ and $d=3$, which gives $$EO(n)=\frac{3^n-(-1)^n}{4}.$$",['combinatorics']
144280,A uniform continuous function which is not Hölder continuous,"Can someone give me an example of a function $f: I\to \mathbb R$ which is uniform continuous but not Hölder continuous (for any $\alpha$)? Here $I$ is an interval. If $I$ is closed and bounded then we are essentially assuming that $f$ is merely continuous. By saying that $f$ is not Hölder continuous for any $\alpha$, I mean for all $\alpha >0$, $$\sup_{x,y\in I, x\neq y} \frac{|f(x) - f(y)|}{|x-y|^\alpha} = \infty.$$ That is, I need to find a function $f$ so that for all $\alpha$ and $M>0$, there are $x, y\in I$ so that $$ \frac{|f(x) - f(y)|}{|x-y|^\alpha} \ge M.$$ I know that $f(x) = x^\alpha$ are $\alpha$-Hölder continuous. Thus, in some sense, I am looking for $f$ which are worst than the functions $x^\alpha$ for all $\alpha >0$.","['continuity', 'holder-spaces', 'real-analysis']"
144329,Prove that there is an unique $z$ s.t. $f(z) = z$ where $z$ is a complex number,"Let $f$ be analytic on the closed unit disk centered at the origin and $|f(z)| < 1$ for $|z| = 1$. Show that $f$ has exactly one fixed point inside the open unit disk. That is, there exists a unique number $z_0$ with $|z_0| < 1$ such that $f(z_0) = z_0$.
We must prove 1 there exists at least on solution, 2 there is at most one solution. 
1) Having problems with at least one solution.
2)By definition a is a fixed point if f(a) = a. Assume that f has more then one fixed point a,b and that a","['general-topology', 'complex-numbers', 'complex-analysis']"
144331,Maximal Value of Integral,"Calculate the maximal value of $\int_{-1}^1g(x)x^3 \, \mathrm{d}x$, where $g$ is subject to the conditions $\int_{-1}^1g(x)\, \mathrm{d}x = 0;\;\;\;\;\;\;\;$     $\int_{-1}^1g(x)x^2\, \mathrm{d}x = 0;\;\;\;\;\;\;\;\;\;$     $\int_{-1}^1|g(x)|^2\, \mathrm{d}x = 1.$ I should mention that $g\in C[-1,1]$ with real scalars, and usual inner product. Just looking for the actual answer!","['normed-spaces', 'hilbert-spaces', 'functional-analysis']"
144334,"Are there infinitely many primes of the form $n^2 - d$, for any $d$ not a square?","Clearly, for $d$ a square number, there is at most one prime of the form $n^2 - d$, since $n^2-d=(n+\sqrt d)(n-\sqrt d)$. What about when $d$ is not a square number?",['number-theory']
144344,Proof concerning compactly generated spaces,"I lately looked up the definition of being a compactly generated space on Wikipedia : Definition: A topological space $X$ is compactly generated if it satisfies the following condition:
  A subspace $A$ is closed in $X$ if and only if $A \cap K$ is closed in
  $K$ for all compact subspaces $K \subset X$. In the second sentence it says: ""Equivalently, one can replace closed with open in this definition"".
I tried to show that this is actually equivalent, but I did not succeed. Bascially you have: $A$ open $\iff$ $(X\backslash A)$ closed $\iff \forall K $ compact: $K \cap (X\backslash A)$ closed What one would need is pulling the set difference out, namely: $\forall K $ compact: $K \cap (X\backslash A)$ closed $\iff \forall K $ compact: $X\backslash(K \cap A) $ closed $\iff \forall K $ compact: $K \cap A$ open. But is the first equivalence true? I could not find a justification for it, probably I am not seeing a simple argument here.",['general-topology']
144361,"To prove $f(x)\rightarrow \infty$ with a ""home made"" strategy","My goal is to prove that: $\displaystyle\sum\limits_{n=1}^\infty \frac{1}{n^{x}} \rightarrow \infty$ for all $ x\rightarrow 1^+$ In order to show this statement I show that no matter how big you choose $N\in \mathbb{R}$, you can always find a $\delta >0$ so $\displaystyle\sum\limits_{n=1}^\infty \frac{1}{n^{x}} = 1+\frac{1}{2^{x}}+\cdots+0>N$ when $x\in \left]1,1+\delta\right[$ My idea is to use some kind of ""induction"". First/the start : N = 1.25 If we look at the case where $N = 1.25$ I conclude that i can just choose $\delta = 1$ so the following statement is true: $\displaystyle\sum\limits_{n=1}^\infty \frac{1}{n^{x}} = 1+\frac{1}{2^{x}}+\cdots+0> 1.25$ for all $x\in \left]1,2\right[$ The ""induction""-step I now assume that the following statement is true for an $N$: There exists a $\delta>0$ so $\displaystyle\sum\limits_{n=1}^\infty \frac{1}{n^{x}} = 1+\frac{1}{2^{x}}+\cdots+0>N$ for all $x\in \left]1,1+\delta\right[$ Now I multiply the above equation with $x$ ($x$ is greater than $1$) $\displaystyle x+\frac{x}{2^{x}}+\frac{x}{3^{x}}+\cdots +0>xN$ for all $x\in \left]1,1+\delta\right[$ Then I do some magic and get from the above: $\displaystyle 1+\frac{x}{2^{x}}+\frac{x}{3^{x}}+\cdots+0>xN-x+1$ for all $x\in \left]1,1+\delta\right[$ I now see that following is true: $xN-x+1 > N$ Because I dont need to go below $N=1.25$ and can therefore do the following calculations: $xN-x+1 = x(N-1)+1> N \Leftrightarrow \\
x(N-1)>N-1 \Leftrightarrow \\
x>1$ From all this I can finally conclude that: $\displaystyle 1+\frac{x}{2^{x}}+\frac{x}{3^{x}}+\cdots+0>xN-x+1>N$ for all $x\in \left]1,1+\delta\right[$ I now write the above as: $1+\dfrac{1}{2^{x-\frac{\ln(x)}{\ln(2)}}}+\dfrac{1}{3^{x-\frac{\ln(x)}{\ln(3)}}}+\cdots+0>xN-x+1>N$ for all $x\in \left]1,1+\delta\right[$ Because I can use the following true statement: $\dfrac{1}{x} = a^{-\frac{\ln(x)}{\ln(a)}}$ From the above I can get a new statement: $1+\dfrac{1}{2^{x-\frac{\ln(x)}{\ln(2)}}}+\dfrac{1}{3^{x-\frac{\ln(x)}{\ln(2)}}}+\cdots+0>xN-x+1>N$ for all $x\in \left]1,1+\delta\right[$ I substitue $y = x-\frac{\ln(x)}{\ln(2)}$ and get: $1+\dfrac{1}{2^{y}}+\dfrac{1}{3^{y}}+\cdots+0>xN-x+1>N$ This is true for all $y\in \left]1,1+\delta_{1}\right[$ where $\delta_{1}>0$
It is true, because: for $1+\delta>x>1$ I can get $2x-2>\ln(x) \Leftrightarrow x-1>\dfrac{\ln(x)}{2} \implies y=x-\dfrac{\ln(x)}{2}>1$ and because $x$ is limited by $1+\delta$ I can find a new smaller $\delta_{2}>0$ so $1+\dfrac{1}{2^{y}}+\dfrac{1}{3^{y}}+\cdots+0>xN-x+1>N$ is true for all $y\in \left]1,1+\delta_{2}\right[$ Finally Now I'm done. If I choose a $N\in \mathbb{R}$ I can go iteratively from 1.25 to a value above $N$. My question My question is very simple. I know it's long (and ""ugly""), but does it looks right? The strategy is ""homemade"", so I'm a bit insecure.","['sequences-and-series', 'real-analysis', 'analysis']"
144368,projective cubic,"I have some difficulties to prove that the image of the function $f:\,\mathbb P^1\longrightarrow\mathbb P^3$ such that
$$(u,v)\longmapsto (u^3,\,u^2v,\,uv^2,\,v^3)$$
is the algebraic projective set 
$$V(XT-YZ,\, Y^2-XZ,\,Z^2-YT)$$
Clearly I have problem to prove that the algebraic projective set is contained in the image of $f$. In particular ""solving brutally"" the polynomial system I'm losing my mind in calculations, so I hope that there is a simpler method.","['algebraic-geometry', 'algebraic-curves', 'projective-geometry']"
144390,What kind of graph would $|x-h| + |y-k| = 1$ give?,"I know that $(x - h)^2 + (y - k)^2 = 1$ is a circle, but what would the graph look like for     $|x-h| + |y-k| = 1$ and why would it look like that?","['algebra-precalculus', 'graphing-functions']"
144396,Show velocity of a particle during its flight at time $t$,"I'm completely stuck, I think I have to use Newton's second law but I have no idea where to start, any help would be appreciated! At time $t=0$ a particle of unit mass is projected vertically upward with velocity $v_0$ against gravity, and the resistance of the air to the particle's motion is $k$ times its velocity. Show that during its flight the velocity $v$ of the particle at time $t$ is: $$v = \left(v_{0} + \frac{g}{k}\right)  e^{-kt} - \frac{g}{k}$$ Deduce that the particle reaches its greatest height when $$t = \frac{1}{k} \ln\left({1+\frac{kv_{0}}{g}}\right)$$ and that the height reached is $$ \frac{v_{0}}{k} - \frac{g}{k^2} \ln{\left(1 + \frac{kv_{0}}{g}\right)}$$ Thanks!","['classical-mechanics', 'ordinary-differential-equations', 'integration']"
144400,Where do I start with self learning linear algebra [duplicate],"This question already has answers here : Prerequisites/Books for A First Course in Linear Algebra (6 answers) Closed last year . I'm a physics major and I'd probably go with mathematical/theoretical physics path. Where do I start with self learning linear algebra? I'm good with proofs but I'm not comfortable with learning math without intuition or motivation behind the axioms. Still, I hate math without rigor (cookbook engineer math). I'm looking for an intro book for linear algebra. Thanks. May be my first exposure to pure math excluding intro to proofs.","['linear-algebra', 'reference-request']"
144405,Confused about Hypercohomology terminology and meaning,"check this: Given a sheaf complex $F^\bullet$, let's say I want to compute the hypercohomology of this complex, if we consider the bicomplex of sheaves $C^\bullet(F^\bullet) = (C^p(F^q))\quad (p,q\in\mathbb{Z})$, where $C^\bullet(F^q)$ is the Godement resolution of the sheaf $F^q$. The hypercohomology of $F^\bullet$ is the cohomology of the complex $K^\bullet(X) = tot(C^\bullet(F^\bullet)(X))$. If we use spectral sequences to compute the hypercohomology I have two spectral sequences, let's look at the first spectral sequence {$'E^{p,q}_r$}, this sequence converges to the final term $'E^{p,q}_\infty$ right? This term is at the same time $'E^{p,q}_\infty = Gr^p_C \: \mathbb{H}^{p + q}(K^\bullet(X)) = C^{p+1}(\mathbb{H}^{p + q}(K^\bullet(X)))/C^p(\mathbb{H}^{p + q}(K^\bullet(X)))$ right? This is commonly expressed as $'E^{p,q}_2 = H^p(X,H^q(F^\bullet)) \Rightarrow \mathbb{H}^{p + q}(K^\bullet(X))$, and the second spectral sequence {$''E^{p,q}_r$} also converges to this. Ok my questions now are: 1 - Some authors simply say that these spectral sequences converge to the hypercohomology $\mathbb{H}^{p + q}(K^\bullet(X))$, why do they say that if the spectral sequences clearly converge to $Gr^p_F \: \mathbb{H}^{p + q}(K^\bullet(X)) = C^{p+1}(\mathbb{H}^{p + q}(K^\bullet(X)))/C^p(\mathbb{H}^{p + q}(K^\bullet(X)))$? Or where am I wrong? 2 - Let's say I have succesfully computed ALL the terms in the two spectral sequences, what do I gain from obtaining $Gr^p_F \: \mathbb{H}^{p + q}(K^\bullet(X)) = C^{p+1}(\mathbb{H}^{p + q}(K^\bullet(X)))/C^p(\mathbb{H}^{p + q}(K^\bullet(X)))$? What is that telling me?, like what if $Gr^p_F \: \mathbb{H}^{p + q}(K^\bullet(X)) = 0$ for some $p$, and $q$? What can I get from knowing that $C^{p+1}(\mathbb{H}^{p + q}(K^\bullet(X)))/C^p(\mathbb{H}^{p + q}(K^\bullet(X)))$ is $0$? How can I use that to compute $\mathbb{H}^{p + q}(K^\bullet(X))$, which is actually what I'm looking for? I know it's dumb and am missing something but I can't see it, can anybody please help me understand this, thanks.","['sheaf-theory', 'general-topology', 'algebraic-topology', 'homological-algebra', 'spectral-sequences']"
144410,Nilpotent groups are solvable,"I know this should be obvious but somehow I can't seem to figure it out and it annoys me!
My definition of nilpotent groups is the following:
A group $G$ is nilpotent if every subgroup of $G$ is subnormal in $G$, or equivalently if $U<N_G(U)$ for all $U<G$. And my definition of solvable groups is that a group $G$ is solvable if $U'\neq U$ for all subgroups $1\neq U \le G$, where $U'$ is the commutator subgroup of $U$.
My question is then: why are nilpotent groups solvable?","['nilpotent-groups', 'solvable-groups', 'group-theory']"
144424,Rubik’s Cube Not a Group?,"I read online that although the $3 \times 3 \times 3$ is a great example of a mathematical group, larger cubes aren’t groups at all. How can that be true? There is obviously an identity and it is closed, so that must mean that some moves aren’t invertible. But this seems unlikely to me.","['rubiks-cube', 'recreational-mathematics', 'group-theory']"
144429,How to show that the collection of Borel-measurable functions from $\mathbb{R}$ to $\mathbb{R}$ is the smallest one with these properties?,"Consider collections $ \mathcal{V} $ of functions from $ \mathbb{R} $ to $\mathbb{R} $ satisfying the following conditions: (a) $ \mathcal{V} $ is a vector space (b) $ \mathcal{V} $ contains the continuous functions (c) If $ (f_{n})_{n} $ is an increasing sequence of nonnegative functions in $ \mathcal{V} $ and if $ \lim_{n \rightarrow \infty} f_{n}(t) $ exists and is finite for all $ t \in \mathbb{R} $ , then $ \lim_{n\rightarrow \infty} f_{n}(t) \in \mathcal{V} $ . Show that the collection $ \mathcal{V}_{0} $ consisting of the Borel-measurable functions is the smallest such collection of functions. (Hint: define $\mathcal{A}= \{ A \subseteq \mathbb{R}: \chi_{a} \in \mathcal{V} \}$ . Show that $ \mathcal{A} $ contains the interval $ (-\infty,a) $ , and then contains the Borel sets). $\chi_{A} :$ characteristic function of $A$ . $\chi_{A}(x)=1$ if $x \in A $ , $\chi_{A}(x)=0$ if $x \notin A, $ I need to find or prove the existence of a sequence of positive continuous functions, increasing to converge to $ \chi_ {A} $ , then I could use the basic theorem of measure theory to put all the functions borel measurable in the set. Any help is appreciated, I try with step functions but dont result.","['measure-theory', 'real-analysis']"
144430,"To prove $f(x)\to\infty$ with an ""Oresme"" strategy","My goal is to prove that: $\displaystyle\sum\limits_{n=1}^\infty \frac{1}{n^{x}} \rightarrow \infty$ when $ x\rightarrow 1^+$ My first approach (which failed) is here: To prove $f(x)\rightarrow \infty$ with a ""home made"" strategy I think the confusing part is the ""$x\rightarrow 1^+$"". I have now argued for the statement, but I haven't used the direction to $1$. I begin with $s_{N}(x) = \displaystyle\sum\limits_{n=1}^N \frac{1}{n^{x}}$ and write $s_{2^{n}}(x)$ as: $\begin{equation*}
\begin{split}
s_{2^{n}}(x) &= 1 \\ 
& + \frac{1}{2^{x}}\\
& + \frac{1}{3^{x}} + \frac{1}{4^{x}} \\ \\ \\
& \dots \\ 
& + \frac{1}{(2^{nx-x}+1)^x} + \frac{1}{(2^{xn-x}+2)^x}+ \ldots + \frac{1}{2^{nx}}
\end{split}
\end{equation*}$ From this I can deduce that there are $n+1$ lines and every line has a number of terms of the form $2^{k-1}$ and ends with a term on the form $\frac{1}{2^{kx}}$ (where all the other terms are greater than this, because $x \rightarrow 1^+$). The sum of a line (including the first line) is therefore greater than or equal $2^{k-1}\frac{1}{2^{kx}}$ which is equal to $\frac{1}{2}$ when $x\rightarrow 1^+$ (the first line is $1$) Finally I get: $\frac{1}{2} \cdot (n+1) \leq s_{2^{n}}(x)$ And when $n\rightarrow \infty$ then $s_{2^{n}}(x)\rightarrow \infty$ And I'm done. Question Well. My suspicion is that I have forgotten something, because I havn't used the direction $x\rightarrow 1^+$. Is this a valid proof?","['sequences-and-series', 'analysis']"
144433,Can the output of a mathematical function be another mathematical function?,"Apologies if this is actually mathematical gibberish. I'm very familiar with mathematical functions at a simple level. A function relates a set of inputs to a set of outputs. What I'm trying to denote is a function, G, which, when given a set F and a true/false value, $\delta$, returns another function which has $n$ as a free variable. For reference, 'match' is another function that matches $n$ and $f$ according to some algorithm. $$ \mathrm{G}(F,\delta) \equiv (F=\varnothing  \vee  ( \delta \veebar \exists f \in F: \mathrm{match}(n,f))) $$ My concern with the expression above is that $n$ pops out of nowhere. What I'd like to get to is $$ A(n) \equiv G(F_A,\bot)$$ and $$ B(n) \equiv G(F_B,\top)$$ So, I guess my question is: does that notation make sense? Or are there more standard forms of expressing these ideas?","['notation', 'elementary-set-theory', 'functions']"
144440,Lebesgue Integral Questions,"I'd like to show some properties of the Lebesgue integral. I'd like to show that if $f$ is a simple function which is zero almost everywhere, then the Lebesgue integral $\int f(x) dx = 0$. Similarly, I'd like to show this is also true for a measurable function $f$ which is zero almost everywhere. I'm working through a real analysis textbook on my own, and I'm not quite sure what to do about this ""almost everywhere."" Do I have to consider separately a set of measure zero? Thank you as always. Attempt for simple function: If $f$ is a simple function that is zero almost everywhere, then $f = \sum_{i=1}^{n}a_{i}\chi_{E_i} = 0$. Then, for each $i$, either $a_i = 0$ or else $m(E_i)= 0$. By definition, $\int f(x) = \sum_{i=1}^{n}a_{1}m(E_i)$. This summation is the sum of zeros. Thus,  $\int f(x) = 0$ as desired. Attempt for measurable function: Assume $f$ is a non-negative measurable function that is zero almost everywhere. By definition, $\int f(x) dx = \lim_{n \to \infty}\int f_n(x) dx$ where $\{f_n\}$ is a sequence of increasing, non-negative, simple functions that are all less than $f$. Since $f$ is zero almost everywhere, then each non-negative, simple $f_n$ must also be zero almost everywhere. Now, from above, we know that for each $n \in \mathbb{N}$,  $\int f_n(x) dx = 0$. Then, $\int f(x) dx = \lim_{n \to \infty} 0 = 0$. Thus, $\int f(x) dx = 0$. Now, for the general case... We can write any measurable function $f$ in terms of its positive and negative parts. So, $f(x) = f^+(x) - f^-(x)$. Both $f^+(x)$ and $f^-(x)$ are non-negative. Now if $f$ is zero almost everywhere, then both $f^+(x)$ and $f^-(x)$ are non-negative and zero almost everywhere. Then, by above, $\int f^+(x) dx= \int f^-(x) dx= 0$ And by definition, $\int f(x) dx = \int f^+(x) dx - \int f^-(x) dx$. So, $\int f(x) dx = 0 - 0 = 0$ as desired.",['real-analysis']
144449,Differentiability of Norms,"I am looking at for which point(s) in $\mathbb{R}^n$ and $p\geq 1$ such that the map $\mathbb{R}^n\rightarrow\mathbb{R}$  given by $x\mapsto ||x||_p=(|x_1|^p+\cdots+|x_n|^p)^{\frac{1}{p}}$ is differentiable. Intuitively, it is not hard to ""guess"" the answer to be for all $p$, the map is not differentiable at origin. for $p=1$, the map is not differentiable everywhere, except for the axis. for $p>1$, the map is differentiable everywhere except at the origin. I come up with these answers by checking continuity of partial derivatives, which is pretty tedious. However, I was even asked to verify these by definition. I am wondering whether there is a very neat and insightful way to see this.",['real-analysis']
144462,Covector field on the sphere $S^2$ vanishing?,"Covector field on the sphere $S^2$ vanishing? There exists a smooth vector field $X$ on $S^2$ that vanishes at exactly one point, for example at the north pole. My idea is the following: Let $\beta:=\{Y_1:=X, Y_2, Y_3\}$ be a basis for $\mathbb{R}^3$. Now, take $\beta^*:=\{\phi^1,\phi^2,\phi^3\}$, the dual basis of $\beta$.",['differential-geometry']
144464,Bolzano Weierstrass theorem in a finite dimensional normed space,"The problem may have a very simple answer, but it is confusing me a bit now. Let $(\mathbf{V},\lVert\cdot\rVert)$ be a finite dimensional normed vector space. A subset $\mathbf{U}$ of $\mathbf{V}$ is said to be bounded, if there is a real $M$ such that for any member $u$ of $\mathbf{U}$, we have: $\lVert u\rVert\lt M$. . Also, convergence of a sequence in $\mathbf{V}$ is defined with respect to the metric $\lVert\cdot\rVert$. Is it true that every bounded sequence of vectors in $\mathbf{V}$ admits a convergent subsequence? If not, please give a counterexample with $\mathbf{V}$ finite dimensional.",['linear-algebra']
144488,Is the set of singular matrices ever a differentiable manifold?,I can see that invertible matrices are a differentiable manifold however I don't know how to show that something is not a differentiable manifold so easily. Is it ever the case that singular matrices form a differentiable manifold?,['differential-geometry']
144496,Finding the number of analytic functions which vanish only on a given set.,"Let $S = \{0\}\cup \{\frac{1}{4n+7} : n =1,2\ldots\}$. How to find the number of analytic functions which vanish only on $S$? Options are a: $\infty$ b: $0$ c: $1$ d: $2$",['complex-analysis']
144499,Probability of Heads in a coin,"I was wondering, if you flip a fair coin $5$ times, whether you can calculate the probability of getting at least one head is calculated like this: You can do the complement of getting at least one head which is TTTTT: $\dfrac1{2^5} =\dfrac1{32}$ Then you do $$1-\frac1{32}= \frac{31}{32}\;,$$ so that's the possibility of getting at least one head after a flip? Thanks!",['probability']
144501,What exactly is a tensor product?,"This is a beginner's question on what exactly is a tensor product, in laymen's term, for a beginner who has just learned basic group theory and basic ring theory. I do understand from wikipedia that in some cases, the tensor product is an outer product, which takes two vectors, say $\textbf{u}$ and $\textbf{v}$, and outputs a matrix $\textbf{uv}^T$. ($\textbf{u}$ being a $m\times 1$ column vector and $\textbf{v}$ being a $n\times 1$ column vector) How about more general cases of tensor products, e.g. in the context of quantum groups? Sincere thanks.","['tensor-products', 'quantum-groups', 'abstract-algebra']"
144510,Analytical method for root finding,"Is there an analytical method to find the roots of the following equation? $$y = -\frac{1}{2}{x}^{2}-\cos(x)+1.1$$ I'm sorry for the trivial question, I'm new at math! :)","['trigonometry', 'algebra-precalculus', 'roots']"
144512,"Solutions to $z^3 - (b+6) z^2 + 8 b^2 z - 7+b^2 = 0, b\in \mathbb R, z \in \mathbb C$","$z_1 = 1+i$ is a given solution. I guess what I have to find is $z_2$ and $z_3$ in $(z - (1 + i))(z - z_2)(z-z_3) = z^3 - (b+6) z^2 + 8 b^2 z - 7+b^2$. I tried to divide the polynomial by $(z - (1 + i))$, but that didn’t seem to work because of the $b$. According to the Complex conjugate root theorem $z_2 = \overline{z_1} = 1 - i$ is a solution too and somebody mentioned that it’s a hint that all coefficients are real. But I still don’t know how to proceed. What am I missing?","['complex-numbers', 'algebra-precalculus', 'polynomials']"
144518,What exactly is an $R$-module?,"From Wikipedia : ""If $R$ is commutative, then left $R$-modules are the same as right $R$-modules and are simply called $R$-modules."" The definition of left $R$-module: $M$ is a left $R$-module if $M$ is an abelian group and $R$ a ring acting on $M$ such that (i) $r(m_1 + m_2) = rm_1 + rm_2$ (ii) $(r_1 + r_2 ) m = r_1 m + r_2 m$ (iii) $1m = m$ (iv) $r_1 (r_2m) = (r_1 r_2) m$ I don't understand what commutativity of $R$ has to do with the module being left and right. If $R$ is commutative it means that $r_1 r_2 = r_2 r_1$. Now how does it follow from that that $rm = mr$? $M$ is not a subset of $R$, it could be anything so how does commutativity of $R$ make elements of $M$ and $R$ commute, too?","['modules', 'abstract-algebra']"
144539,Limit inferior of the quotient of two consecutive primes,"I have recently read an article about the prime number theorem, in which Mathematicians Erdos and Selberg had claimed that proving $\lim \frac{p_n}{p_{n+1}}=1$, where $p_k$ is the $k$th prime, is a very helpful step towards proving the prime number theorem, although I don't know how, primarily because I have not gone through the proof of the theorem even once. Anyway, I was trying to prove the result $\lim \frac{p_n}{p_{n+1}}=1$ by really elementary methods, as is always my habit, and quite recently I learned of a theorem that the sum of the reciprocals of the primes diverges (I am only a beginner). The idea that suddenly struck me is that this theorem implies $\limsup\frac{p_n}{p_{n+1}}=1$, by a simple application of the ratio test and the fact that $\frac{p_n}{p_{n+1}} < 1$ for all $n$. So, is there any simple way to show that $\liminf\frac{p_n}{p_{n+1}}=1$ or at least $\ge1$, so that the result is proved? Another beautiful result that came to me, follows from the theorem on divergence of $\sum\frac{1}{p}$, that given any $h > 1$ there are infinitely many $n$ such that $p_n < h^n$. Are there any other results with really simple proofs (easy to understand even for beginners like me) having deep consequences in the theory of the distribution of primes? I'd really like to hear them!","['prime-numbers', 'analytic-number-theory', 'number-theory']"
144544,Does the 'closure of the interior' equal the 'interior of the closure'?,"My answer is no because, $\mathbb{Q}^o = \emptyset$ and so $\overline{(\mathbb{Q}^o)} = \emptyset$ but $\overline{\mathbb{Q}} = \mathbb{R}$ and so $\big(\overline{\mathbb{Q}}\,\big)^o = \mathbb{R}$. Is my example correct?",['general-topology']
144545,Weird integral with cylinders,"I have this weird integral to find. I am actually trying to find the volume that is described by these two equations. $$x^2+y^2=4$$ and $$x^2+z^2=4$$ for $$x\geq0, y\geq0, z\geq0$$ It is a weird object that has the plane $z=y$ as a divider for the two cylinders. My problems is that I can't find the integration limits. I can't even draw this thing properly.","['multivariable-calculus', 'integration']"
144554,Find the equation of a line which is perpendicular to a given vector and passing through a known point,"There is given a vector $2 \vec i + \vec j - 3 \vec k$ and now I want to find the equation of a line that is perpendicular to the given vector and passing through a known point $(1,1,1)$. How can I solve this?","['linear-algebra', 'vector-analysis']"
144559,If $f(x + y) = f(x) + f(y)$ showing that $f(cx) = cf(x)$ holds for rational $c$,"For $f:\mathbb{R}^n \to \mathbb{R}^m$, if $f(x + y) = f(x) + f(y)$ for then for rational $c$, how would you show that $f(cx) = cf(x)$ holds? I tried that for $c = \frac{a}{b}$, $a,b \in \mathbb{Z}$ clearly 
$$
f\left(\frac{a}{b}x\right) = f\left(\frac{x}{b}+\dots+\frac{x}{b}\right) = af\left(\frac{x}{b}\right)
$$
but I can't seem to finish it, any help?","['functional-equations', 'analysis']"
144572,permutations of a multiset having symbols with fixed multiplicity,"Let $N$ be a multiset of $n$ distinct objects having the same multiplicity $k$. For instance, $N=\{a,\,a,\,b,\,b\}$ where $n=2$ and $k=2$. I was looking for the problem of counting the number of all the permutations of all the non-empty subsets of $N$. For the N in the above example, there are 18 permutations of the subsets of N $$
a,b,\;\;
aa,ab,ba,bb,\;\;
aab,aba,abb,baa,bab,bba,\;\;
aabb,abab,abba,baab,baba,bbaa$$ Till now I've ended up just with an upper bound of that number, by using the following idea.
Compute all of the permutations of $N$ of length $nk$ (ignore subsets) with the basic formula
$$
perm(N;nk)=\frac{(nk)!}{\underbrace{(k!)(k!)...(k!)}_{n \; times}}
$$ Then, just take all the $nk$-prefixes of all the objects in $perm(N;nk)$. That gives
$$
nk\frac{(nk)!}{(k!)^{n}}
$$ However since this method counts twice a prefix shared by two $nk$-permutations (e.g. $ab$), I end up with a coarse upper bound. For $N$ in the example, $24$ ($>18$). I was wondering if I can find a closed formula that computes exactly the desired number ?","['permutations', 'multisets', 'combinatorics']"
144587,are fibres of a flat bijective map reduced?,"Let $f: X \to Y$ be a flat map of algebraic varieties or of complex analytic spaces which is bijective on closed points (or just bijective in the secnond case). Suppose  both $X$ and $Y$ are reduced. Is it true that $f$ has reduced fibres? If it is true, I would be most grateful for a reference.","['algebraic-geometry', 'reference-request', 'complex-geometry']"
144589,Determining the Smith Normal Form,"Consider the integral matrix $$R = \left(\begin{matrix} 2 & 4 & 6 & -8 \\ 1 & 3 & 2 & -1 \\ 1 & 1 & 4 & -1 \\ 1 & 1 & 2 & 5 \end{matrix}\right).$$ Determine the structure of the abelian group given by generators and relations. $$A_r = \{a_1, a_2, a_3, a_4 | R \circ \vec{a} = 0\}$$ I know you have to row/column reduce the matrix however am unsure what to do next.","['matrices', 'smith-normal-form', 'abelian-groups']"
144599,Initial-boundary value problem for PDE,"I need a little help with solving IBVP for hyperbolic and parabolic equations like these:
$$
hyperbolic: 
\left\{\begin{matrix}
\frac{\partial^2u}{\partial t^2}=\frac{\partial^2 u}{\partial x^2}+1\\
u(0,t) =u(1, t) =0\\
u(x,0) = 0\\
u_t(x,0)=x
\end{matrix}\right.
\\parabolic: 
\left\{\begin{matrix}
3\frac{\partial u}{\partial t}=4\frac{\partial^2 u}{\partial x^2}\\
u(0,t) =u(5, t) =0\\
u(x,0) = x
\end{matrix}\right.
$$
Don't even know where to start. I'm not actually asking for full solution, but would appreciate it if you could give me direction. Links to tutorials and examples are also highly welcomed. Update: Second equation looks like 1 dimensional heat conduction equation: $u_t = c^2u_{xx}$ with $c=\frac{2\sqrt{3}}{3}$. Ok, for the second one method of separation of variables could be applied. We assume that $u$ can be written as a product of single variable functions of each independent variable, $u(x, t) = X (x)T (t)$. Substituting this guess into the heat equation, we find that $XT′ =c^2X′′T$. Dividing both sides by $c^2$ and $u = XT$, we then get $\frac{1}{c^2}\frac{T'}{T} = \frac{X''}{X} = \lambda$. This leads to two equations: $$
T′ =c^2\lambda T\\
X'' = \lambda X
$$
giving $$
T(t) = Ae^{c^2λt}\\
X(x) = c_1e^{\sqrt{\lambda}x} + c_2e^{\sqrt{-\lambda}x}$$
The aim is to force our product solutions to satisfy both the boundary conditions and initial conditions. Is it possible to use this method for the first equation?","['ordinary-differential-equations', 'partial-differential-equations']"
144606,Finite measures are $\sigma$-finite,How I can show that every finite measure can be regarded as a $\sigma$-finite measure but not conversely in general?,['measure-theory']
144611,What operations is a metric closed under?,"Suppose $X$ is a set with a metric $d: X \times X \rightarrow \mathbb{R}$. What ""operations"" on $d$ will yield a metric in return? By this I mean a wide variety of things. For example, what functions $g: \mathbb{R} \rightarrow \mathbb{R}$ will make $g \circ d$ into a metric, for example $g \circ d = \sqrt{d}$. Or what functions of metrics will yield metrics in return, for example $d_1 + d_2$, where $d_1$ and $d_2$ are distinct metrics on $X$. I'm looking for a list of such operations, and counterexamples of ones which plausibly seem like they could define a metric but do not.","['general-topology', 'metric-spaces', 'real-analysis']"
144637,One sided limit of an increasing function defined on an open interval,"Let $f:(a,b)\to \mathbb{R}$ be a strictly increasing function. Does the limit $\lim_{x\to a^+}f(x)$ necessarily exist and is a real number or $-\infty$?  If so, is it true that $\ell=\lim_{x\to a}f(x)\le f(x) \ \ \forall x\in (a,b)$? Please provide proofs.","['functions', 'limits']"
144678,"""Hartog's Lemma"" for locally free sheaves on a Noetherian normal scheme","Exercise 14.1.I of Ravi Vakil's notes is the following: Show that locally free sheaves on Noetherian normal schemes satisfy ""Hartog's Lemma"": sections defined away from a set of codimension at least 2 extend over the set. With his ""Algebraic Hartog's Lemma"" (For a Noetherian normal ring R, the intersection (in the field of fractions) of $R_p$ where $p$ ranges over all codimension one primes is R), I can show the statement for free sheaves. But how does one extend this to locally free sheaves?","['algebraic-geometry', 'schemes']"
144686,Conjugacy classes in $A_n$.,"Suppose $n$ is a non negative integer $\geq 4$ and $\sigma\in S_n$ a permutation. Conjugacy classes in $S_n$ are completley determined by the cycle structure of $\sigma$. If we let the alternating group $A_n$.act on $S_n$ by conjugation, the orbits coincide with the conjugacy classes in $S_n$ except for those (even) permutations whose cycle structure is composed of even cycles (which corresponds to cycles of uneven length) of distinct order (fixed points are treated as cycles of length $1$.) See http://groupprops.subwiki.org/wiki/Splitting_criterion_for_conjugacy_classes_in_the_alternating_group For instance a $3$-cycle in $A_4$ has cycle structure $[3,1]$ which fits the bill, and a $5$-cycle in $A_5$ or $A_6$ works too, since the cycle structure is $[5]$ and $[5,1]$ respectively. On the other hand, a $3$-cycle in $A_5$ will does not satisfy the criteria as it has cycle structure $[3,1,1]$ with two fixed points. In this case, the conjugacy class of $\sigma$ inside $S_n$ splits in $2$ orbits of the conjugation action of $A_n$, and if $\tau$ is any odd permutation, for instance $(12)$, then we have $$\mathrm{Conj}_{S_n}(\sigma)=\mathcal{O}(\sigma)\coprod\mathcal{O}(\tau\sigma\tau^{-1})$$ My question is How can we differentiate between the two orbits? Does it have geometric meaning? I can see that this information can be useful when looking at representations of the alternating groups, since there are as many irreducible representations as conjugacy classes. As for some geometric interpretation, I ask because there is one for the three cycles in $A_4$. If $S_4$ is understood as the group of symmetries of a regular tetrahedron, then $A_4$ is the subgroup of direct symmetries, and a $3$-cycle corresponds to a rotation of angle $\frac{2\pi}{3}$ or $\frac{4\pi}{3}$ with axis passing through one of the vertices. Conjugacy classes inside $A_n$ preserve the angle, and that's how we can tell them apart. In this case the computations are so simple we don't really need this picture, but I think it is a nice way to understand the fact $3$-cycles in are not all conjugate inside $A_4$...","['permutations', 'group-theory']"
144693,Showing $\sum _{k=1} 1/k^2 = \pi^2/6$ [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Different methods to compute $\sum\limits_{n=1}^\infty \frac{1}{n^2}$ Does $\sum\limits_{k=1}^n 1 / k ^ 2$ converge when $n\rightarrow\infty$? I read my book of EDP, and there appears the next serie
$$\sum _{k=1} \dfrac{1}{k^2} = \dfrac{\pi^2}{6}$$
And, also, we prove that this series is equal $\frac{\pi^2}{6}$ for methods od analysis of Fourier, but... Do you know other proof, any more simple or beautiful?",['sequences-and-series']
144696,Smallest number with a given number of factors,"From my rather rudimentary explorations of this fascinating problem, I believe it to be a layered and rewarding subject for investigation. My question, essentially, is: How do you find the smallest number with a given number of factors? Indeed, as quickly becomes apparent, a distinction is called for between exactly a given number of factors and at least a given number of factors; as such, approaches considering both will be appreciated. It's a fairly standard result in number theory that the number of distinct factors (including $1$ and itself) of some number $N$, where $$
N = p_1^{a}\cdot\ p_2^{b}\cdot\ p_3^{c} \cdots  
$$
($p_1$, $p_2$, $p_3\ldots$ being distinct primes) is 
$$
(a+1)(b+1)(c+1)\cdots
$$ Thus, stated mathematically, the question appears to resolve into finding, or rather, finding a method of finding, this:
$$
\min\{N = 2^{a}\cdot\ 3^{b}\cdot\ 5^{c} \cdots \space| \space (a+1)(b+1)(c+1)\cdots = n \}
$$ or, as the case may be, this:
$$
\min\{N = 2^{a}\cdot\ 3^{b}\cdot\ 5^{c} \cdots \space| \space (a+1)(b+1)(c+1)\cdots \geq n \}
$$
($n$ being the given number of factors). My crude, trial-and-error approach so far has been factorising $n$ into $n = n_1\cdot n_2\cdot n_3\cdots \space$  and then assigning $a = n_1 - 1,\space b = n_2 - 1,\space c = n_3 - 1,\space \ldots \space$ to get $N$, my only defence being that I tried to factorise sensibly and perceive some sort of pattern or rule at play. I have been unable to obtain anything beyond some common-sense tricks and techniques, though some of them seemed tantalisingly concrete. I think it's a beautiful problem, and I'm looking for a way of solving it using a clever, universal algorithm. I'd greatly appreciate a comprehensive solution.","['factoring', 'divisibility', 'number-theory']"
144697,Multiset Combination in Combinatorics,"I want to buy a $k$-combination of doughnuts, where $k$ is any amount less than or equal to the total doughnuts available. At the bakery there are $n$ different types of doughnuts but there are restricted amount left for each type of doughnut. For example, In this case, the total doughnuts available is 
4 + 2 + 3 + 2 + 7 + 2 + 8 = 28
and n = 7

 Doughnut type       Amount left
    1                     4  
    2                     2
    3                     3  
    4                     2
    5                     7  
    6                     2
    7                     8  
                        =====
                         28 Let's assume I want to buy a combination of $10$ doughnuts but I cannot have more than, for example $7$ of type $5$ doughnut and I can't have more than $3$ of type $3$ doughnuts.
How many combination of $10$ doughnuts can I have altogether?","['arithmetic-combinatorics', 'multisets', 'combinatorics']"
