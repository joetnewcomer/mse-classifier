question_id,title,body,tags
426427,Density function as derivative (Self-study),"I'm trying to do the Society of Actuaries' example problems.  I am having trouble with no. 62, which says: A random variable $X$ has CDF
  $$ F(x) = 
\begin{cases} 0 & \text{for $x < 1$} \\
              \frac{x^2 - 2x + 2}{2} & \text{for $1 \leq x < 2$} \\
              1 & \text{for $x \geq 2$}
\end{cases}
$$
  Compute the variance of $X$. I understand the basic steps for computing the variance: Transform the CDF into a density $f$, by differentiating. Compute the expectation $E(X)$ by integrating $x f(x)$ Compute the expectation $E(X^2)$ by integrating $x^2 f(x)$ Compute the variance $V(X) = E(X^2) - E(X)^2$. The problem I'm having is that the density I compute does not match up with the one in the solutions page.  In particular, I get $$f(x) = \begin{cases} x - 1 & \text{for $1 \leq x < 2$}\\
                       0     & \text{otherwise}
\end{cases}
$$ whereas they get $$ 
f(x) = 
\begin{cases} \frac{1}{2} & \text{for $x = 1$} \\
              x - 1       & \text{for $1 \leq x < 2$}\\
              0           & \text{otherwise}
\end{cases}
$$ Where is that $\frac{1}{2}$ coming from? Edit:  I corrected the CDF, and now the derivative (if not the density) is correct.","['calculus', 'probability']"
426441,Simplifing formulas using tensor notation,"Im trying to symplify formulas like: 
$$\operatorname{div}(\operatorname{rot}\vec{F}),\qquad \operatorname{rot}(\operatorname{rot}\vec{F}) $$ or something more strange like: $$\operatorname{rot}(\vec{r}\operatorname{div}(r^4\operatorname{grad}(r^4)))$$ To do this I want to use the tensor notation and by this I mean using the Einstein convention, Levi-Civita symbol, Kronecker delta and all that. The problem is that I don't understand the rules and what its allowed and what not. As an example: $$\operatorname{div}(f( r)\cdot \textbf r)= \partial_i(f( r)\cdot \textbf r)_i = \partial_i(f( r)\cdot x_i)= \partial _if(r)x_i+f(r)\partial_ix_i= f'(r)\frac{x_i}{r}x_i+3f(r)=rf'(r)+3f(r) $$ Any help on how to do this kind of problems or where I can find useful examples? I'm working in flat space. Thanks!","['notation', 'multivariable-calculus', 'tensors']"
426453,Sequences are Cauchy depending on the norm?,"Assume that we have two Banach spaces $B_1, B_2$ with their underlying sets being identical. Is it possible that a Cauchy sequence in one of the spaces would fail to be Cauchy in the other? I am assuming that it is possible since the Cauchy test directly depends on the norm. However, this seems kind of unnatural, will someone please clarify.","['metric-spaces', 'general-topology', 'normed-spaces', 'hilbert-spaces', 'banach-spaces']"
426454,Prove that $\dfrac{(n^2)!}{(n!)^n}$ is an integer for every $n \in \mathbb{N}$,"Prove that $\dfrac{(n^2)!}{(n!)^n}$ is an integer for every $n \in \mathbb{N}$ I know that there are tools in Number theory to proves the required but I want to use the tool that says that if you can prove that an expression solves a combinatorial problem then it represents an integer for every $n \in \mathbb{N}$ My solution is, assume we are given $n^2$ beads, $n$ beads in every color of $n$ colors, and we want to place them in a row ($(n^2)!$)
now since we have $n$ groups of colors and every group has $n$ beads in it, we need to cancel the inner sort of each of the groups, which gives us $(n!)^n$ for all the possible inner sorts of the beads. Will that proof work? What are its flaws?","['divisibility', 'discrete-mathematics', 'binomial-coefficients', 'combinatorics']"
426468,The concept of ordinals,"I am trying to understand this concept and have some difficulties. For example, can I say that $\alpha$ is the cardinality of $\{1,2,3,...\}=\Bbb N$? And if so, what is $\alpha +1$? I guess it is not the cardinality of $\Bbb N \cup \{\sqrt2\}$ (for example)?","['ordinals', 'elementary-set-theory']"
426482,Framed Cobordism Classes of links in $\mathbb R^3$,"We know that every link in $S^3$ is framed cobordant to the unknot with some framing. The idea is to study smooth homotopy classes of maps from $S^3$ to $S^2$. Actually in the title I have given $\mathbb R^3$ but any knot in $S^3$ can be isotoped to miss a point $p$ on $S^3$ and hence lie in $\mathbb R^3\cong S^3-p$ The framing given below is one where the frame twists once as it goes one round along the knot, i.e., framing given by $1\in\pi_1(SO(2))$ Does the disjoint union of $n$ (mutually unlinked) unknots with framing $1\in SO(2)$ represent the unknot with framing $n\in\pi_1(SO(2))$? Somehow I find it difficult to picture whether this is true or not. The only way I can perhaps argue is that in the framed cobordism classes of links form a group and the addition in the group is just the unlinked disjoint union. Is this true? If false, is there any other way to represent the class of the unknot with framing with $n\in\pi_1(SO(2))$, by a link which has framing with one twist ($1\in SO(2)$) on each knot in the link?","['knot-theory', 'homotopy-theory', 'differential-geometry']"
426485,"If the difference of cubes of two consecutive integers is a square, then the square can be written as the sum of squares of two different integers.","How can i prove the statement that if the difference of cubes of two consecutive integers is an integral power of 2, then the integer with power 2 can be written as the sum of squares of two different integers. For example: $$8^3 - 7^3 = 13^2 = 12^2 + 5^2$$ Any help appreciated. Thanks.",['number-theory']
426486,Inequality with square root and squaring each side of the inequality,"My book says if I take $\sqrt{x^2 + y^2} \lt 1,\;$ and it says if I ""square each side of the inequality"" the result will give the inequality $\;x^2 + y^2\lt 1,\;$ but I don't understand the concept. If you find the square root of $5^2$ isn't that $5$? Then isn't the square root of $\,x^2 + y^2\,$ equal to $\,x + y\;?$ Am I thinking about this correctly or am I mistaken somehow?","['inequality', 'algebra-precalculus']"
426487,Why is every positive linear map between $C^*$-algebras bounded?,We know that every positive linear functional on a $C^*$-algebra is bounded. How can we prove every positive linear map between $C^*$-algebras is bounded?,"['c-star-algebras', 'operator-algebras', 'functional-analysis']"
426503,Bijection between $\mathbb{R}\times\mathbb{R}$ and $\mathbb{R}$ [duplicate],"This question already has answers here : Examples of bijective map from $\mathbb{R}^3\rightarrow \mathbb{R}$ (2 answers) Cardinality of $\mathbb{R}$ and $\mathbb{R}^2$ (2 answers) Closed 11 years ago . It must be posted somewhere, but I can't find it. I've been working on it for a while too without getting anywhere. Does there exist a bijection between $\mathbb{R}\times\mathbb{R}$ and $\mathbb{R}$? Is it possible to give an explicit bijection? NOTE : This question is not a duplicate of the link suggested. Please see comments for further detail.",['elementary-set-theory']
426516,How to use double angle identities to find $\sin x$ and $\cos x$ from $\sin 2x $?,"If $\sin 2x =\frac{5}{13}$ and $0^\circ < x < 45^\circ$ , find $\sin x$ and $\cos x$ . The answers should be $\frac{\sqrt{26}}{26}$ and $\frac{5\sqrt{26}}{26}$ Ideas The idea is to  use double angle identities. One such identity is $\sin 2x=2\sin x\cos x$ . It's easy to use it to find $\sin 2x$ from known $\sin x$ and $\cos x$ . But here it's the other way around.",['trigonometry']
426523,$\sqrt{x + \sqrt{2x -1}} + \sqrt{x- \sqrt{2x-1}} = A $,"I am puzzling over the following problem, which involves an equation of the form: $$\sqrt{x + \sqrt{2x -1}} + \sqrt{x- \sqrt{2x-1}} = A $$ The problem involves finding real values of x corresponding to 
A = $ \sqrt{2}$, A = 1, and A = 2, where the roots must be of non-negative real numbers. So far, I have found that A = $\sqrt{2}$ when x = 1: $$\sqrt{1 + \sqrt{2(1) -1}} + \sqrt{x- \sqrt{2(1)-1}} = \sqrt{1 + 1} + \sqrt{1 - 1} = \sqrt{2}   $$ But it is not so obvious to me how to go about obtaining values of x when A = 1, or A = 2, for example. And how can I be certain that I have found all values of x, if there is more than one? And how can I be absolutely sure that there is only one solution? And if we think about it the other way around- in general, for which values of A are there solutions? Some thoughts on any of the above would be much appreciated!","['arithmetic', 'algebra-precalculus']"
426530,How to solve $u'' + k u + \epsilon u^3 = 0$?,"I am looking at the project of my ODE class, there is one problem saying we have to solve $u'' + k u + \epsilon u^3 = 0$. The problem gives us some values of $k$, $\epsilon$ and says you should experiment with different initial values with Euler's method. I have solved the equation using Euler's method. But now I am confused, how can I know I get the right solution, in previous exercises the book gave the answer for the function and we can compare it with the Euler answer, the project page says nothing about the answer. I tried letting $u = e^{rt}$ like in the class to get the characteristics equation if both constants are 1:
$$
r^2 + r + e^{2rt}=0
$$
but I can't solve this. Thanks alot. The initial values are $u(0)=0$, $u'(0)=1$, and $k=\epsilon =1$.",['ordinary-differential-equations']
426569,Maximum of a trigonometric function without derivatives,I know that I can find the maximum of this function by using derivatives but is there an other way of finding the maximum that does not involve derivatives? Maybe use a well-known inequality or identity? $f(x)=\sin(2x)+2\sin(x)$,['trigonometry']
426575,Big Rudin 1.40: Open Set is a countable union of closed disks?,"Reading through Big Rudin, I have come across the following statement in the proof of Theorem 1.40: Let $S \subset \mathbb{C}$ be a closed set [in the topology induced by
  the complex modulus]. Let 
  $\Delta = \{z \in \mathbb{C}: |z-\alpha|\leq \epsilon\}$ be a closed disc about the point 
  $z \in \mathbb{C}-S$. Then $\mathbb{C}-S$ is given by a countable union of
  closed discs $\Delta$. An (arbitrary) open set is the union of a countable number of closed sets? This seems like an error to me, but I can find no mention of it online. For what its worth, the proof seems to work if we take $\Delta$ to be an open disc, as the standard topology on $\mathbb{C}$ is second-countable. Edit: Does Anyone know of a good errata for the book? The only ones making themselves known are for Baby Rudin.","['general-topology', 'metric-spaces', 'complex-analysis', 'analysis']"
426576,How do you formally prove that a function in several variable is really a function,"Let say for example that we define $f:\mathbb{R}^{3}\longrightarrow \mathbb{R}^{3}$ such that $f(x,y,z)=(y^{2},xz,xy^{2})$. My informal argument would be just that there is only one object  that can be defined having three real numbers, but I'm just saying this intuitively. How do you prove it formally?","['multivariable-calculus', 'elementary-set-theory']"
426590,"about weak convergence in $L^{2}(0,T;H)$","I am trying to do an exercise and if the  affirmation below is true, my exercise is done . This is the affirmation : Affirmation :  Let $H$ a Hilbert space and suppose $u_k$ converges weakly to $u$ in  $L^{2}(0,T;H)$. Suppose that $\operatorname{ess sup}_{ 0 \leq t \leq T} \ || u_k (t)|| \leq C$.
Then $u_k(t) $ converges weakly to $u(t)$ for every $t$. I am trying  to do, but nothing...  . Someone can give me  a hint ? (please dont give me a complete answer , just a hint ^^ ) thanks in advance ^^","['weak-convergence', 'measure-theory', 'partial-differential-equations', 'hilbert-spaces', 'functional-analysis']"
426629,Making exponent of $a^x$ object of the function,"Is it possible to make a variable the subject of a formula when it is an exponent in the equation? For example: $$y=a^x\quad a\;\text{is constant}$$ For example, let the constant $a = 5.$ $$
\begin{array}{c|l}
\text{x} & \text{y} \\
\hline
1 & 5 \\
2 & 25 \\
3 & 125 \\
4 & 652 \\
5 & 3125 \\
\end{array}
$$ I cannot find the relation between x and y. The constant is making the equation a bit complicated. Appreciate if someone can help me here.","['algebra-precalculus', 'functions']"
426631,Greatest integer $n$ where $n \lt (\sqrt5 +\sqrt7)^6$,"I'm really not sure how to do this. I factored out a power of $3$ and squared so that I have $2^3 (6+\sqrt{35})^3 \gt n$ , and I know that if I can prove that $12^3-1 \le (6+\sqrt{35})^3 \lt 12^3$ I am basically done, but I don't know how to do that. Any help is appreciated. Thanks!","['elementary-number-theory', 'inequality', 'algebra-precalculus', 'number-theory']"
426640,$k$-cells: Why $a_i < b_i$ instead of $a_i \le b_i$,"In Rudin, The Principles of Mathematical Analysis , there is the following definition: Definition: If $a_i < b_i$ for $i=1,2,...,k$, the set of all points, $ \boldsymbol{x} = ( x_1, x_2, ..., x_k )$ in $ \mathbb{R} ^ k $ whose coordinates satisfy the inequalities $ a_i \le x_i \le b_i$ $( 1 \le i \le k )$ is called a $k$-cell. The examples that are provided give a $1$-cell as an interval and a $2$-cell as a rectangle. What I am trying to figure out is why the definition is given this particular way. In particular, why the definition is not phrased the same way, with the exception that $a_i \le b_i$. Upon consideration, the only difference between the two situations is what may arise in a particular $k$-cell. For example, consider a $3$-cell. This would provide the set of all $\boldsymbol{x} = (x_1, x_2, x_3)$ where each $a_i \le x_i \le b_i$. Such a characterization gives a cuboid. However, by allowing for the possibility that $a_i = b_i$, we allow for the possibility that at least one $x_i$ is fixed in the set. Thus in the $3$-cell case we would be allowed to have cuboids, planes, lines, and points. Thus the restriction $a_i \le b_i$ seems to be more flexible. Thus my question is, why is the more restrictive $a_i < b_i$ used rather than $a_i \le b_i$.","['general-topology', 'metric-spaces', 'real-analysis']"
426649,"For any three vectors $x,y,z\in\mathbb{R}^d$, we have $ \|y-z\|\cdot\|x\|\leq\|x-y\|\cdot\|z\|+\|z-x\|\cdot\|y\|$","Does anyone know a proof of the following problem? Problem: Show that for any three vectors ${\bf x}, {\bf y}, {\bf z}\in \mathbb{R}^d$ the following holds,
$$ \|{\bf y} - {\bf z}\|\cdot \|{\bf x}\| \leq \|{\bf x} - {\bf y}\|\cdot \|{\bf z}\| + \|{\bf z} - {\bf x}\|\cdot\|{\bf y}\|.$$ All of the norms are Euclidean 2-norm.","['geometry', 'normed-spaces', 'linear-algebra']"
426653,Gradient flow of harmonic function is measure preserving?,"Let $M$ be a manifold with $Ric \ge  - \left( {n - 1} \right)$ and $f:{B_R}\left( p \right) \to R$ is a lipschitz and harmonic function. In a paper, it says ""As the gradient flow ${\Phi _t}$ of $f$ is measure preserving."" Gradient flow of harmonic function is measure preserving? Suppose $U$ is a subset of $M$, $V = {\Phi _t}\left( U \right)$.$$Vol\left( V \right) = \int_V {1dx}  = \int_U {Jacobi\left( {y = {\Phi _t}\left( x \right)} \right)} dy $$$Jacobi\left( {y = {\Phi _t}\left( U \right)} \right) = 1$? I don't know how to compute.","['geometry', 'differential-geometry', 'analysis']"
426658,What is the difference between a ball and a neighbourhood?,"I am presently reading chapter two of Rudin, Principles of Mathematical Analysis (ed. 3). He provides the following definitions: Definition: If $\boldsymbol{x} \in \mathbb{R} ^ k$ and $r > 0$, the open ball $B$ with center at $\boldsymbol{x}$ and radius $r$ is defined to be the set of all $\boldsymbol{y} \in \mathbb{R} ^ k$ such that $| \boldsymbol{y} - \boldsymbol{x} | < r.$ Definition: A neighbourhood of a point $p$ is a set $N_r(p)$ consist of all points $q$ such that $d(p,q) < r$. The number $r$ is called the radius of $N_r(p)$. What I have been attempting to figure out is what the difference between these two definitions are. Ilya, in the following question provides the following description - ""The neighborhood of a point $x\in \Bbb R$ is any subset $N_x\subseteq \Bbb R$  which contains some ball $B(x,r)$ around the point $x$. Note that in general one does not ask neighborhood to be open sets, but it depends on the author of a textbook you have in hands."" In Kaplansky, Set Theory and Metric Spaces he presents an example where by setting the distrance function $d(p,q) = |a-b|$ then we obtain a metric space. Then combining this statement and the part of Ilya's answer that a neighbourhood contains some ball, a ball is like a special case of a neighbourhood. The following two theorems seem to give support for this case: Theorem $27$ from Kaplansky: Any open ball in a metric space is an open set. Theorem $2.19$ from Rudin: Every neighbourhood is an open set. So essentially they are both open sets, however, the neighbourhood has a more general distance function. I would appreciate some clarification on this matter.","['general-topology', 'metric-spaces']"
426659,When is gradient flow an isometry?,"$M$ is a Riemannian manifold,$f$ is a function on $M$. Under what conditions is the gradient flow $F(t)$ of $f$ an isometry for $t>0$?","['geometry', 'analysis']"
426672,Showing that a transformation $T:\mathbb R^3 \to \mathbb R^2$ is linear,"OK, I am trying to prove the following transformation is linear, and find the basis for $\ker(T)$ and Im$(T)$ (also denoted in our textbook by $N(T)$ and $R(T)$ ). Then we're suposed to find the nullity and rank of $T$. $T: \Bbb{R}^3 \rightarrow \Bbb{R}^2$ defined by  $T(a_1, a_2, a_3) = (a_1-a_2, 2a_3)$ We want to see that the transformation preserved addition and scalar multiplication. So I define vector $a$ as $(a_1, a_2, a_3)$ and $b$ as $(b_1, b_2, b_3)$. So the first question is whether $T((a_1+b_1, a_2+b_2, a_3+b_3)$ = $T((a_1-a_2), 2a_3) + T(b_1-b_2, 2b_3)$ and when I plug in vectors $a+b$ to the transformation I get: $((a_1+b_1)-(a_2+b_2), 2(a_3+b_3))$ which works. So addition is preserved. The next question is whether it preserves scalar multiplication, or if $T(ca+b) = cT(a) + T(b)$ and as it happens:
 $T(ca_1+b_1, ca_2+b_2, ca_3+b_3) = ((ca_1+b_1-ca_2+b_2), 2(ca_3+b_3))$ and then if we break up the vectors we find that we get $(ca_1-ca_2, 2ca_3)+(b_1-b_2, 2ba_3)$ so the transformation is linear. To find the kernel we look for the set of vectors for which $T(a_1,a_2,a_3) = 0$. 
That happens whenever $a_1 = a_2$ and $a_3 = 0$ But that is where I get stuck because the definition of a kernel doesn't seem to fit. What is the basis for the kernel in this case? If a kernel is a set of vectors then this is making little or no sense to me from the get-go. Because I am not sure what the basis would be if the set of vectors are all those where $a_1 = a_2$ unless it's something like $(a_1, a_2, 0)$. And the dimension of the kernel is 2, I wold think intuitively, but I want to better understand why that is so I can get through the rest of the problem.","['vector-spaces', 'linear-algebra', 'transformation']"
426687,Prove that $A$ has Lebesgue measure $0$.,"Suppose $G$ is a connected open set of $\mathbb{C}^n$. Prove that: (1). If $f \in$ PSH(G) and $f \not \equiv \infty$ then
$A=\{z \in G: f(z)=-\infty\}$ has Lebesgue measure $0$. (2). If $f \in \mathcal{H}(G,F)=\{f: G \to F,~ \text{f is holomorphic function}\}$ and $f \not \equiv 0$ (not heterogeneous $0$) then $A=\{z \in G: f(z)=-\infty\}$ has Lebesgue measure $0$. Any help (or hint or another solution) would be greatly appreciated. Thanks.","['measure-theory', 'several-complex-variables', 'complex-analysis']"
426708,Does the product of positive definite matrices have a positive trace,"Let $ A_{1}, A_{2}, \ldots, A_{m}$ be a real symmetric semi-positive  definite matrices,  I want to know whether $ tr (A_{1} \cdot A_{2} \cdots A_{m} ) \geq 0$ ? When $m=2$, it seems a rather standard problem and has a ""yes"" answer.","['matrices', 'linear-algebra']"
426711,Motivation for Jordan Canonical Form,"I took linear algebra and understood the proof that linear operators on a vector space over an algebraically closed field have a Jordan Canonical Form. Why should I care about this theorem? I understand that it can be useful in doing some computations, but it seems that these computations are quite rare. Indeed, I am not puzzled by diagonalization or triangularization at all. They both have practical and theoretical uses, but even more than that, they just seem like nice things to have. Can someone explain why Jordan Canonical Form is a ""nice thing to have""?","['jordan-normal-form', 'matrices', 'linear-algebra', 'soft-question']"
426713,$\lim_{x\rightarrow 0^+}x^x$,"How can I calculate $\lim_{x\rightarrow 0^+}x^x$? I can only write it in the form $e^{x\ln x}$. I would like to use L'Hospital rule somehow, but I can't write it in form of fractions.","['calculus', 'limits']"
426722,Proving principle of the Iterated Suprema,"Let $X$ and $Y$ be nonempty sets and let $h : X\times Y \to R$ have bounded range in $\mathbb{R}$. Let $F: X \to\mathbb{R}$ and $G : y \to \mathbb{R}$ be defined by $F(x):=\sup\{h(x,y) : y\in Y\}$, and $G(y) := \sup\{h(x,y) : x\in X\}$. Establish the Principle of the Iterated Suprema:
$\sup\{h(x,y) :x \in X, y \in Y\} = \sup\{F(x) : x \in X\} = \sup\{G(y) : y \in Y\}$. This proof is quite long but im having trouble with it. Here is what I have so far. Proof
Since $h(x,y)$ is bounded we know that $\sup\{h(x,y) :x \in X, y \in Y\}$ exists. Let $T=\sup\{h(x,y) :x \in X, y \in Y\}$. By definition we know that $T \geq h(x_0,y_0)$ for arbitrary
$x_0 \in X$ and $ y_0 \in Y$ Since $h(x_0,y_0) \in\{h(x,y) :x \in X, y \in Y\}$ and $h(x_0,y_0) \in \{h(x_0,y) : y \in Y\}$ Since $x_0$ and $y_0$ are arbitrary it follows that
T is a upper bound for $F(x_0)= \sup\{h(x_0,y) : y\in Y\}$. $\sup\{F(x) : x \in X\}$ exists since $F(x_0)$ was arbitrary. Thus $T \geq \sup\{F(x) : x \in X\}$ This is where I stopped at since I do not know if what I have done so far is correct and I am stuck proving $T \leq \sup\{F(x) : x \in X\}$ in order to show $T=\sup\{F(x) : x \in X\}$.",['analysis']
426753,"Substituting an equation into itself, why such erratic behavior?","Until now, I thought that substituting an equation into itself would $always$ yield $0=0$. What I mean by this is for example if I have $3x+4y=5$, If I substitute $y=\dfrac {5-3x}{4}$, I will eventually end up with $0=0$. However, consider the equation $\large{\sqrt {x+1}+\sqrt{x+2}=1}$ . If we multiply by the conjugate, we get $\dfrac {-1}{\sqrt{x+1}-\sqrt{x+2}}=1$, or $\large{\sqrt{x+2}-\sqrt{x+1}=1}$. Now we can set this equation equal to the original, so $\sqrt{x+2}-\sqrt{x+1}=\sqrt {x+1}+\sqrt{x+2}$ , and you get $0=2 \sqrt{x+1}$ which simplifies to $x=-1$ , which is actually a valid solution to the original! So how come I am not getting $0=0$ , but I am actaully getting useful information out of this? Is there something inherently wrong with this? Thanks.",['algebra-precalculus']
426758,"Which of these statements about biholomorphic functions $f \colon D(0, 1) → D(0, 1)$ is true?","$f \colon D(0, 1) → D(0, 1)$ is a biholomorphic function. a) $f$ must be constant b) $f$ must have a fixed point c) $f$ must be a rotation d) $f$ must fix the origin. Any such map looks like $e^{i\alpha}{(z-a)\over (1-\bar{a}z)}$ , $a\in D$ , $\alpha\in [0,2\pi]$ , so only c is correct option?",['complex-analysis']
426763,How does $\operatorname{Ric} \ge 0$ guarentee the Busemann function is regular in the splitting theorem?,"Cheeger-Gromoll's famous splitting theorem says If $(M,g)$ contains a line and $\operatorname{Ric} \ge 0$. Then $(M,g)$ is isometric to a product. I want to know how does $\operatorname{Ric} \ge 0$ guarentee that the Busemann function is regular, since it's regular then by Morse theory $M$ is homeomorphic to a product.","['riemannian-geometry', 'morse-theory', 'differential-geometry']"
426764,Theorem by Whitney,For $0<k<\infty$ and any $n$-dimensional $C^k$ manifold the maximal atlas contains a $C^\infty$ atlas on the same underlying set by a theorem due to Whitney. Could someone please point me to where I can find the theorem and a proof thereof?,"['manifolds', 'reference-request', 'differential-geometry']"
426777,An operator inequality,"I would be most thankful if you could help me prove the following operator inequality. Let $A$ be an arbitrary linear operator on a Hilbert space, satisfying
$$\left\|AA^{\ast} - A^{\ast}A\right\|\leq 2a$$
where $A^{\ast}$ is the Hermitian adjoint and $a>0$ is a constant. Let $\varepsilon$ be equal to either $+1$ or $-1$. Then show that 
$$2\sqrt{A^{\ast}A + aI} - \varepsilon\left(A + A^{\ast}\right) \geq 0$$ 
Thank you!","['operator-theory', 'inequality', 'functional-analysis']"
426793,Proof that $\frac{(\bar X-\mu)}{\sigma}$ and $\sum_{i=1}^n\frac{(X_i-\bar X)^2}{\sigma^2}$ are independent,"Let $X_i\sim N(\mu,\sigma^2)$ ; where$[i=1,2,\ldots,n]$ $Z_i\sim N(0,1)$ ; where$[i=1,2,\ldots,n]$ Proof that $\bar Z=\frac{(\bar X-\mu)}{\sigma}$ and $\sum_{i=1}^{n}(Z_i-\bar Z)^2=\sum_{i=1}^n\frac{(X_i-\bar X)^2}{\sigma^2}$
are independent, which implies $\bar X$ and $\sum_{i=1}^n(X_i-\bar X)^2$ are independent. MY ATTEMPT: I considered $n=2$, and $$M_{X_1+X_2}(t_1)=M_{X_1}(t_1)M_{X_2}(t_1)$$ $\ast$I did so for the proof but does the statement $X_i\sim N(\mu,\sigma^2)$ ; where$[i=1,2,\ldots,n]$ imply that $X_i's$ are independent? Moment Generating Function of $X_1+X_2$ and $X_1-X_2$  are
$$M_{X_1+X_2}(t_1)=e^{2\mu t_1+\sigma^2 t_1^2}$$
$$M_{X_1-X_2}(t_2)=e^{\sigma^2 t_2^2}$$
respectively. Also, $$M_{X_1+X_2,X_1-X_2}(t_1,t_2)=e^{2\mu t_1+\sigma^2 t_1^2}e^{\sigma^2 t_2^2}=M_{X_1+X_2}(t_1)M_{X_1-X_2}(t_2)$$ since the joint moment generating function factors into the product of the marginal moment generating functions, so $X_1+X_2$ and $X_1-X_2$  are independent which implies that: $\bullet$ Since $\bar Z=\frac{(\bar X-\mu)}{\sigma}$ is only a function of $X_1+X_2$ and $\sum_{i=1}^{2}(Z_i-\bar Z)^2=\sum_{i=1}^2\frac{(X_i-\bar X)^2}{\sigma^2}$ is only a function of $X_1-X_2$ ,so $\bar Z=\frac{(\bar X-\mu)}{\sigma}$ and $\sum_{i=1}^{n}(Z_i-\bar Z)^2=\sum_{i=1}^n\frac{(X_i-\bar X)^2}{\sigma^2}$
are independent. $\bullet$ Since $\bar X$ is only a function of $X_1+X_2$ and $S^2=\frac{1}{2-1}\sum_{i=1}^2(X_i-\bar X)^2$ is only a function of $X_1-X_2$ ,so Sample mean,$\bar X$ and sample variance,$S^2$ are independent. $\diamond\diamond\diamond$ We accept the above independence for any arbitrary $n$ . Is the procedure correct?","['statistics', 'statistical-inference', 'sampling', 'generating-functions', 'probability']"
426801,Positive homogeneous,"Question: A set $X\subset\mathbb{R}^n$ is called a cone in $\mathbb{R}^n$ if $x \in X$ implies $tx ∈ X$ for every $t\in\mathbb{R}_+$. Given a cone $X$ in $\mathbb{R}^n$, a function $f\colon X \to\mathbb{R}$ is said to be positive homogeneous of degree $k \in\mathbb{R}$ if $f(tx) = t^kf(x)$ for every $x \in X$ and every $t\in\mathbb{R}_{++}$. 1) Let $X$ be the interior of a cone in $\mathbb{R}^n$ and let $f\colon X \to\mathbb{R}$ be differentiable on $X$. Show that $f$ is positive homogeneous of degree $k$ iff  $kf(x) = Df(x)\cdot x$ for every $x ∈ X$.
(Notation: $Df(x)$ is derivative of $f$ at $x$ and $Df(x)\cdot x$ is (unitary) inner product of $Df(x)$ and $x$). 2) Let $X$ be the interior of a cone in $\mathbb{R}^n$ and let f: X $\to\mathbb{R}$ be differentiable on X. Show that, if f is positive homogeneous of degree k, then the partial derivative $D_if$ is homogeneous of degree $k-1$ for $i=1,...,n$ . Source: From the question paper of an exam conducted in 2005. my try : EDIT: It has been 2 days since I asked this question. Please, anybody, help me.. I got stuck in between.
First part:
Given: f(tx)=$t^k$f(x) I just realised $Df(x)$ is differentiation of $f(x)$ with respect to $x$ and not $t$. This means the following solution(my try) is completely wrong. But earlier also when I tried to solve it by differentiating it with respect to $x$ I was not getting anywhere. $\mathbf{Please\, help}$. differentiating wrt t $\implies$ $xDf(tx)=kt^{k-1}f(x)$ setting t=1 $\implies xDf(x)=kf(x)$ to prove: $<Df(x),x>=kf(x)$ LHS=$<(k/x)f(x) , x>$ =$k<f(x)/x  ,  x>$ Now I am stuck. Please help...","['multivariable-calculus', 'ordinary-differential-equations', 'functions', 'linear-algebra', 'real-analysis']"
426805,Surface integral of $2x+y+2z=16$,"Here's the question: Find the surface area of the part of the plane $2x+y+2z=16$ bounded by the surfaces $x=0$, $y=0$ and $x^2+y^2=64$. So, I know I have to parameterize the surface $S:\mathbf{x}=\mathbf{x}(u,v)$ and I currently have it parameterized as $\mathbf{x}(u,v)=(\sqrt{32}\cos{u},\sqrt{32}\sin{u},v)$ because we're dealing with a circle of radius $8$ in the first quadrant (octants 1 and 5). If my parameterization is correct, then 
$$\left\lVert\frac{\partial\mathbf{x}}{\partial u}\times \frac{\partial\mathbf{x}}{\partial u}\right\rVert=64.$$ I'm still confused about the bounds though. Obviously, $0\le u\le\pi/2$ but what about $v$? Help! Thank you :)","['definite-integrals', 'multivariable-calculus', 'integration', 'surfaces']"
426807,How does this vector addition work in geometry?,"I saw the accepted answer to the question: Finding a point along a line a certain distance away from another point! I am not getting how to use it actually to find the coordinates of the new point at a given distance. This is because I am confused between how to translate to/from the Cartesian system and the vector system.
So please explain me the following by walking through the solution suggested in that answer with the following example data. Suppose I have two points $(0,0)$ and $(1,1)$ and I want to find a point at a distance which is 3/5th of the total distance between the points (i.e. $\frac{3}{5}\sqrt{2})$ from the point $(0,0)$ and lies on the segment. How do I use the vectors mentioned in the solution given there to find the required coordinates? Edit:
Precisely speaking, What I do expect is the explanation of: What is vector $\mathbf v$ there if $(x_1,y_1) = (1,1)$ and $(x_0,y_0) = (0,0)$ What is the normalized vector $d\mathbf u$? How do I do the addition $(x_0,y_0) + d\mathbf u$?","['analytic-geometry', 'geometry', 'linear-algebra']"
426815,local isometry for riemannian manifolds is not transitive,"Let $(M_1,g_1)$ and $(M_2,g_2)$ be Riemannian manifolds of the same
dimension, and let $\phi: M_1 \to M_2$ be a smooth map.
We say that $\phi$ is a local
isometry if $g_2 (\phi_* X, \phi_* Y ) = g_1 (X, Y )$
for all $m \in M_1$ and $X, Y \in T_m M_1,$ where $\phi_* : T_m M_1 \to T_{\phi(m)} M_2$ is the
derivative of the map $\phi$ at $m.$ The relation of being locally isometric for Riemannian manifolds is not symmetric, it is of course reflexive: is it transitive?","['riemannian-geometry', 'differential-geometry']"
426817,A Challenging Integral $\int_0^{\frac{\pi}{2}}\log \left( x^2+\log^2(\cos x)\right)dx$,"I encountered a strange integral with a strange result. $$\int_0^{\frac{\pi}{2}}\log \left( x^2+\log^2(\cos x)\right)dx = \pi \log \left(\log (2) \right)$$ Believe it or not, the result agrees numerically. How can we prove this result? Please help me. I feel very curious to know how this can proved.","['definite-integrals', 'closed-form', 'integration', 'analysis']"
426818,"How to find solutions to this equality $\; \mathrm{x} = \mathrm{a^2x \, (1-x)\,(1-ax\,(1-x))}$","We have the following equality: $$ \mathrm{x} = \mathrm{a^2x \, (1-x)\,(1-ax\,(1-x))}$$ Some of the solutions I found: $\mathrm{x} = 0$ Also for $\mathrm{a}=0$, every $\mathrm{x}$ is a solution I believe I tried getting everything out of the brackets but that just gave a nasty equality which I couldn't solve. Let's take $-1 \leq \mathrm{a} \leq 1$. I was also wondering if there is a way of knowing how many solutions this equality has beforehand? Or do we just have to look at the cases $\mathrm{a} = 1$, $\mathrm{a} = -1$, $\mathrm{a} \neq 0$ and $\mathrm{a} = 0$ individually to find every solution (i.e. both of the bounds, and for a (not) equal to 0)?",['algebra-precalculus']
426822,If $A$ is a compact set then so is $A'$?,"Let $X$ be a metric space with a metric $d$ and let $A$ be a compact subset of $X$.
Show that $A'$ is compact where $A'$ is a derived set of $A$. I am done $A'$ is closed and bounded.
But we know that if a set is closed and bounded, then the set is not compact, generally.
So I try to prove by using the definition of compactness, but I can't.","['general-topology', 'metric-spaces', 'compactness']"
426824,how to prove a parametric relation to be a function,"For example lets suppose that I have given the functions $f:\mathbb{R}\longrightarrow \mathbb{R}$ and $g:\mathbb{R}\longrightarrow \mathbb{R}$. If my relation is $R=\{(x,(y,z))\in \mathbb{R}\times \mathbb{R}^{2}: y=f(x) \wedge z=g(x)\}$ How to prove formally (from a set theoretic stand point) that $R$ is a function. I have a try but I'm not convince: Let suppose to have $(x,(y,z))\in R$ and also $(x,(y',z'))\in R$. Then $y=f(x), z=g(x)$ and also $y'=f(x), z'=g(x)$ by definition. Then $y=y'$ and also $z=z'$. Therefore $(y,z)=(y',z')$. In a more general case if I have the functions $f_1, f_2,...,f_n:\mathbb{R}^m\longrightarrow \mathbb{R}$ and I define the function $f:\mathbb{R}^{m}\longrightarrow\mathbb{R}^{n}$ such that $f(x_{1},x_{2},...,x_{m})=(f_{1}(y),f_{2}(y),...,f_{n}(y))$ with $y=(x_1,x_2,...,x_m)$, how to justify that it is indeed a function? If my try is fine I suppose this can be done by induction. Any comment will be appreciated.","['multivariable-calculus', 'elementary-set-theory', 'functions']"
426830,Solve an equation with $e^{(x-2)}=e^{4}\cdot e^{\sqrt{x}}$,$$e^{(x-2)}=e^{4}e^\sqrt{x}$$ I know that $x = 9$ and I can show the calculations like this: $$e^{(x-2)} = e^{\sqrt{x}+4}$$ and now I need to get the $x$ to the right side but I dont know how.,"['exponentiation', 'exponential-function', 'algebra-precalculus']"
426837,A linear transformation which maps the unit sphere to itself.,"$A \colon\Bbb  R^3\to\Bbb R^3$ is a linear transformation which maps the unit sphere to itself.
Then $A$ is a) symmetric; b) orthogonal; c) positive definite; d) symmetric and positive definite. By the given condition my intuition says $\|Ax\|=\|x\|$  so $A$ will be orthogonal transformation. it may have negative eigenvalue so it will not be positive definite. Its characteristic polynomial will be of degree three and may have a complex root, so in that case it will not be symmetric as symm matricx has eigen value only realss. Thank you for help.","['matrices', 'linear-algebra']"
426858,"Construction(s) of new integral domains from ""old ones""","Given an integral domain $D$, there are several ways how to construct a new integral domain related to D. For example, one can consider a ring of polynomials/formal power series/formal Laurent series in one/two/infinite indeterminates, a localization $S^{-1}D$, where $S \subseteq D$ is some multiplicatively closed subset, etc. Note that all these constructions ""depend"" only on one domain, i.e. $D$. In the case of general rings, there is in a way much more possibilities: Since category of rings is both complete and co-complete, one can consider limits/colimits of arbitrary diagram in $\mathcal{Ring}$. In particular, it is possible to have products of arbitrary nonempty family of rings. This is, however, almost never an integral domain (i.e. if the family contains at least two rings). So the question is the following: Is there some universal construction, which, given two or more abstract integral domains, produces a new integral domain, related to the given ones? By abstract domains I mean that the construction does not assume some relation between the domains (i.e. one doesn't need to be, for example, subring of the other, so that the construction would produce some ring in between). By universal I mean that the construction does not assume much about the structure of the given domains except the fact that they are domains (for example, does not need them to be of the form $F[x], K[x]$ for some fields $F,K$). (In fact, if the ""initial"" rings were not domains and the resulting ring would be, such construction would interest me as well). Edit: An example I encountered is: Ultraproduct of collection of integral domains is again an integral domain. This construction satisfies the conditions universal and abstract as I described them, however, it can give a ""new"" domain only if we consider infinite collections of domains. Another interesting example is mentioned by Zhen Lin in comments.","['commutative-algebra', 'ring-theory', 'soft-question', 'abstract-algebra']"
426860,How The Jacobian of the transformation can be shown to not depend on $X_i$ or $\bar X $ and is equal to the constant $n$,"Transform the random variables, $X_i$, $i=1,2,\ldots,n$ to $$
\begin{align}
Y_1 & =\bar X \\
Y_2 & =X_2-\bar X \\
Y_3 & = X_3-\bar X \\
& {}\  \vdots \\
Y_n & =X_n-\bar X
\end{align}
$$ Find the Jacobian of transformation.","['multivariable-calculus', 'calculus']"
426868,Sketch all the continuous function use the intermediate value theorem,"Question: Sketch all the continuous functions $f:\mathbb{R}\rightarrow \mathbb{R}$ which satisfy
\begin{equation*}
(f(x))^2=(x-1)^2 (x-2)^2.
\end{equation*}
Justify your answers. I have found the eight possible continuous functions as follows:
\begin{align*}
f(x) & =(x-1)(x-2)\\
f(x) & =-(x-1)(x-2)\\
f(x) & =|x-1|(x-2)\\
f(x) & =-|x-1|(x-2)\\
f(x) & =(x-1)|x-2|\\
f(x) & =-(x-1)|x-2|\\
f(x) & =|x-1| |x-2|\\
f(x) & =-|x-1| |x-2|.
\end{align*}
and have got the conclusion of this question which has at most eight possible such functions, but how to proof the ""at most"" statement.","['continuity', 'functions']"
426878,What's correspondence between the model theoric and the set theoric kernel of homomorphism?,"A kernel of a mapping $h$ from $\mathfrak{A}$ to $\mathfrak{B}$, generally,  is an equivalence relation $\{(a,a') \in \mathfrak{A} \times \mathfrak{A} \mid  h(a)=h(a')\}$. However, in model theory, there is another version of definition of kernel of mappings. That is,
$\ker(h) \colon=\{\varphi(\bar a) \mid \models_{\mathfrak{B}}\varphi[h(\bar a)]\}$, in which $\bar a$ is a non-repetitive enumeration of $\mathrm{dom}(\mathfrak{A})$, $\varphi(\bar a)$ are all atomic sentences. Let's call the former one set theoric version, the later one model theoric version. My question: What's relationship between them? Are they equivalent to each other in some senses? Elaboration for the model theoric version The model theoric version I found was in exercise 1.5.4 in Hodges's Model Theory. This exercise mainly requires a proof of those assertion following are equivalent to each other: (a) $\mathrm{diag}^+(\mathfrak{A}) \subseteq T$ and $T$ is =-closed; (b) $T$ is the kernel of some homomorphism from $\mathfrak{A}$ into $\mathfrak{B}$; (c) $T$ is the kernel of some surjective homomorphism from $\mathfrak{A}$ into $\mathfrak{B}$; In which $T$ is a set of atomic sentences of $L(\bar a)$. Since I haven't found an explanation why he defined kernel in this way, I asked this question here.","['soft-question', 'model-theory', 'elementary-set-theory', 'functions']"
426903,Subgroups of order 8 in the quasidihedral group of order 16,"Why are there only $3$ subgroups of order $8$ in the quasidihedral group $QD_{16}$ of order $16$? (I am not interested in drawing the lattice of subgroups, but rather an argument convincing one that there can be only $3$ subgroups of order $8$).","['finite-groups', 'group-theory', 'abstract-algebra']"
426932,Why are Vandermonde matrices invertible?,"A Vandermonde-matrix is a matrix of this form: $$\begin{pmatrix}
 x_0^0 & \cdots & x_0^n \\
\vdots & \ddots & \vdots \\
 x_n^0 & \cdots & x_n^n
\end{pmatrix} \in \mathbb{R}^{(n+1) \times (n+1)}$$ . condition ☀ : $\forall i, j\in \{0, \dots, n\}: i\neq j \Rightarrow x_i \neq x_j$ Why are Vandermonde-matrices with ☀ always invertible? I have tried to find a short argument for that. I know some ways to show that in principle: rank is equal to dimension all lines / rows are linear independence determinant is not zero find inverse According to proofwiki , the determinant is $$\displaystyle V_n = \prod_{1 \le i < j \le n} \left({x_j - x_i}\right)$$ There are two proofs for this determinant, but I've wondered if there is a simpler way to show that such matrices are invertible.","['matrices', 'linear-algebra', 'polynomials']"
426934,Why are constructible sets a disjoint unions of locally closed sets,"Let $X$ be a noetherian scheme. The constructible sets are the smallest boolean algebra containing all of the open sets. It is easy to see that the constructible sets are exactly finite unions of locally closed sets. I have read several times that every constructible set is a finte disjoint union of locally closed sets. In all the examples I have seen this is indeed the case, but when I try to write down a proof of this fact I get stuck. Does anyone know why this is true? I suspect that this is a standard trick which I have not seen.",['algebraic-geometry']
426940,"How exact is the functor ""tensoring with a locally free sheaf""","Let $X$ be a variety over a field $k$, $\mathcal F$ a locally free $\mathcal O_X$-module. Has the functor on locally free sheaves 'tensoring with $\mathcal F$' any exactness property (is it right/left exact or not at all) ? If $\mathcal F$ is of rank $1$, it is known that this functor is exact. What happens for greater rank ?","['sheaf-theory', 'algebraic-geometry', 'exact-sequence']"
426941,"Precalculus (Functions) If $f(2x+\frac{y}{8}, 2x-\frac{y}{8}) = xy, $ then $f(m,n) +f(n,m)=0$ only when :","If $f(2x+\frac{y}{8}, 2x-\frac{y}{8}) = xy, $ then $f(m,n) +f(n,m)=0 $ Options are : (a) only when $m =n$ (b)  only when $m \neq n$ (c) only when $m =-n$ (d) for all $m$ and $n$ My approach : $x=0, y =0 \Rightarrow f(0 , 0) =0 ; $ By putting $x = 1, y = 1$  gives $f(\frac{17}{8}, \frac{15}{8})$ = 1 Is it the right way please suggest... thanks....","['algebra-precalculus', 'functions']"
426943,Set Relations Question,"I understand these laws when applied to certain situations but can't seem to understand how to apply it to these problems. I know that if Jon is Mike's cousin, then Mike is Jon's cousin and that is a Symmetric relation. I also know that if Jon is taller than Mike and Mike is taller than Maddie, then Jon is taller than Maddie and that is a Transitive relation. How do I make the step to these type problems using the same thought system? For each the following relations on the set of integers list all that apply
(Reflexive, Symmetric, Antisymmetric, or Transitive):

R1 = {(a, b) | a * b <1}","['relations', 'discrete-mathematics']"
426949,Completion along zero section of an elliptic curve.,"I am trying to understand the intuition that I should have about the formal group of an elliptic curve. Say that I have an elliptic curve $E\to \text{Spec} R$ for some ring $R$, with section $0\colon \text{Spec} R\to E$. My first question is: when I hear speaking about the ""completion of $E$ along $0$"", should I think that such a thing is the formal scheme whose underlying topological space is $0(\text{Spec} R)$ and whose sheaf of rings is the completion of $\mathcal O_E$ with respect to the ideal sheaf defining $0(\text{Spec} R)$ in E? And what is the relation of this object with the formal group of $E$?
My second question is: say that I have a nowhere vanishing differential $\omega \in H^0(E,\Omega_{E/R}^1)$. I somehow have this idea (but I can't understand how true is it) that completion along the zero section tells us about ""Taylor expansion"" of $\omega$. How does one formalize that?
Also, is the sheaf $\Omega_{E/R}^1$ always globally isomorphic to $\mathcal O_E$? or is it just invertible?
Thank you in advance if you're willing to help me!","['arithmetic-geometry', 'algebraic-geometry', 'elliptic-curves']"
426956,How Does A Precessing Sphere Precess?,"In particular, consider a perfectly spherical object or radius $r$, with a certain axis $L$ , and this axis titled relative to a vertical axis by some amount $\theta$. Say that it's ""wobbling"" in a stable, circular manner -- the axis $L$ is revolving around the vertical axis, but comes back to where it started after a revolution. In other words, the sphere looks like this one . My question is, how can I describe the motion of any point on that sphere (assuming it's a perfect sphere)? First, notice that if you look at the bottom-most point of Africa, it rotates in an ellipse counterclockwise. But, the North & South Poles as viewed from the top are rotating clockwise! But if you look at areas around the equator (the green areas of Africa), they seem to have an 8-shaped motion with the smaller circle being formed a the bottom. How can this be? I'm totally mystified. How can different points of the sphere rotate in different directions (and opposite directions, too) in that way? I also imagine that some points from behind the Earth in that video will be rotating clockwise at the same time as Africa is rotating counterclockwise. But then again, it seems like the motions change from upper to lower hemispheres, and the directions seem to be the same in the same hemisphere if you view it overhead. Is there a way for me to know how a certain point is moving? Or is this animation misleading me? This seems to me like a purely mathematical problem if we assume the ideal case.","['geometry', 'topological-vector-spaces', 'calculus', 'differential-geometry']"
426962,Ring and Subring with different Identities [duplicate],"This question already has answers here : Nontrivial subring with unity different from the whole ring? (7 answers) Closed 11 years ago . Is there an example of a ring $S$ with identity $1_S$ containing a non-trivial subring $R$ which itself has an identity $1_R$, but $1_R\neq 1_S$ (or equivalently $1_S\notin R$). I'd also like to know under what conditions the identities have to be equal. I know they must be equal if $S$ has no zero divisors, since for every $r\in R$ we have $(1_S-1_R)r=0$ In other words: Is the category of unital rings with identity-preserving morphisms a full subcategory of the category of rings (where morphism are only required to respect addition and multiplication)?","['ring-theory', 'examples-counterexamples', 'abstract-algebra']"
426972,A Differential operator.,"What are the fundamental solutions for the operator 
$$\mathcal D=a{\partial^2\over\partial x_1^2}+b{\partial^2\over\partial x_2^2}$$ 
on $\Bbb R^2 $ with standard cordinates $(x_1,x_2)$. Here $a,b\in \Bbb R$. Definition: A distribution $E\in  D'(R)$is called a fundamental solution of an differential operator $P(D)$ if $$P(D)E= \delta(x).$$ Here $$P(D)=\sum_{|\alpha|\le m} a_\alpha D^\alpha.$$ Differential operator in the above problem looks like a kind of generalization of Laplace operator. Actually, I don't know; is there any generalization of Laplace operator? But if we take $a,b=1$ then it is the Laplace operator and in this case, maybe we can show that $E=\frac1 {2\pi} log|x|, n=2$ is a fundamental solution... Thank you.","['ordinary-differential-equations', 'fourier-analysis', 'distribution-theory', 'partial-differential-equations']"
426979,"Complex integral, correct?","I am supposed to do the integral $$ \int_{\gamma_2} \frac{\sin(z)}{z+\frac{i}{2}} dz$$ where $\gamma_2:[-\pi, 3\pi] \rightarrow \mathbb{C}$ , $\gamma_2(t)=\exp(it)$ for $ t\in [-\pi,\pi]$, $\gamma_2(t)=(1+t-\pi)\exp(it)$ for $t\in [\pi,2\pi)$ and $\gamma_2(t)=(1+3\pi-t) \exp(it)$ for $t\in[2\pi,3\pi]$. My idea was to say that this is equal to $2 \cdot 2\pi i \sin(-\frac{i}{2})$. Since we have two loops and the rest is cauchy's integral formula, is this correct?","['calculus', 'complex-analysis', 'contour-integration']"
426981,Need help in proving that $\frac{\sin\theta - \cos\theta + 1}{\sin\theta + \cos\theta - 1} = \frac 1{\sec\theta - \tan\theta}$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question We need to prove that $$\dfrac{\sin\theta - \cos\theta + 1}{\sin\theta + \cos\theta - 1} = \frac 1{\sec\theta - \tan\theta}$$ I have tried and it gets confusing.",['trigonometry']
426983,Probability $P(A < B)$,"Given two independent and continuous random variables $A$ and $B$ with cumulative distributions $F_A$ and $F_B$, show that $$P(A<B) = \int_{-\infty}^{\infty} F_A(x)\, F'_B(x)\,dx.$$ Is this something obvious and available in text books ?","['statistics', 'probability-distributions', 'probability', 'probability-theory']"
426994,Positive definiteness of Fubini-Study metric,"Define the Fubini-Study metric
$$g_{i\overline{j}} = \frac{\delta_{i\overline{j}}(1+|\boldsymbol{z}|^2)-\overline{z}^jz^i}{(1+|\boldsymbol{z}|^2)^2} $$
for $i,j=1,\ldots,n$ and $z_i$ complex variables and $|\boldsymbol{z}|^2=\sum_{i=1}^n |z^i|^2.$ My GOAL is to show that, for every $k=1,\ldots,n,$
$$ \det \left( g_{i\overline{j}} \right)_{1 \leq i,\overline{j}\leq k} =  \frac{1+\sum_{i=k+1}^n |z^i|^2}{(1+|\boldsymbol{z}|^2)^{k+1}}.$$","['riemannian-geometry', 'linear-algebra', 'differential-geometry']"
426997,Analyticity of Laplace transform,"Let $f(x)$ be a bilateral Laplace transform of a measure $\mu$:
$$
f(x)=\int_{-\infty}^{+\infty} e^{-xt} d\mu(y).
$$
Suppose that $f(x)$ converges absolutely in $(a,b)$, and $(a,b)$ do not contain the origin.
It is always true that $f(x)$ is analytic in $(a,b)$? Or it is true just for finite measure $\mu$? Moreover, if the measure $\mu$ is finite, then $(a,b)$ must contain the origin? Thank you!","['measure-theory', 'laplace-transform', 'analyticity']"
427019,Proving that $\iint_S (\nabla \times F) \cdot \hat{n} dS =0$,"I have the following question: Prove that $$\iint_S (\nabla \times \vec{F}) \cdot \hat{n} dS =0$$  for any closed surface $S$ and twice differentiable vector field $\vec F:\mathbb{R^3} \to \mathbb{R^3} $ . I need to prove this using Stokes' theorem. The only thing I want to verify is whether or not for every closed surface $S$, we have:
 $$\iint_S (\nabla \times \vec{F}) \cdot \hat{n} dS =\int_C \vec F \cdot d\vec r$$ and the last term is trivially zero, because $C=\emptyset $ ($S$ is a closed surface). Is this correct? Thanks in advance",['multivariable-calculus']
427043,"Prove that $λ^∗(A×B)\geq λ^∗(A)λ^∗(B)$ for every pair of sets, $A \subseteq \mathbb{R}^n$ and $B \subseteq \mathbb{R}^m$","Prove that  $ \lambda^*(A\times B)\geq \lambda^*(A) \lambda^*(B)$ for every pair of sets, $A \subseteq\mathbb{R}^n$ and $B \subseteq\mathbb{R}^m$, where $\lambda^*$ denotes the Lebesgue Outer Measure and $\lambda$ the Lebesgue Measure. Given $\epsilon>0$, there is an open set $G$ such that $A\times B \subseteq G$  and  $ \lambda^*(A\times B) \geq \lambda(G) - \epsilon$. Then, naming $G_n$ the first $n$ coordinates of $G$, and $G_m$ the last $m$ coordinates of $G$,  $A \subseteq G_n$ and $B \subseteq{G_m}$,   $G_n$ and $G_m$ are open sets. Thus, $ \lambda(G_n)\geq \lambda^*(A)$ and $ \lambda(G_m) \geq \lambda^*(B)$. I want to conclude that  $\lambda(G) \geq \lambda (G_n\times G_m)$, but I don't see how. Ps: I have already proved: $\lambda(G_n\times G_m) =\lambda (G_n) \lambda (G_m)$.","['measure-theory', 'inequality', 'real-analysis']"
427052,Showing one point compactification is unique up to homeomorphism,"First for clarity I'll define things as I'm familiar with them: A compactification of a non-compact topological space $X$
is a compact topological space $Y$
such that $X$
can be densley embedded in $Y$
. In particular a compacitifaction is said to be a one-point compactification if $\left|Y\backslash X\right|=1$ The Alexandroff one-point compactification of a a topological space $\left(X,\mathcal{T}_{X}\right)$
is the set $X^{*}=X\cup\left\{ \infty\right\}$
for some element $\infty\notin X$
given the topology $$\mathcal{T}^{*}:=\mathcal{T}_{X}\cup\left\{ U\subseteq X^{*}\,|\,\infty\in U\,\wedge\, X\backslash U\,\mbox{is compact and closed in }\left(X,\mathcal{T}_{X}\right)\right\}$$ 
If $\left(X,\mathcal{T}_{X}\right)$
is a Hausdorff space one can omit the requirement that $X\backslash U$
is closed. It is easy to show that given two choices of elements $\infty_{1},\infty_{2}\notin X$
  the one-point compactifications $X\cup\left\{ \infty_{1}\right\}$ 
  and $X\cup\left\{ \infty_{2}\right\}$
  with the topology defined as that of the Alexandroff one-point compactification are homeomorphic. What I'm wondering is why isn't there another possible way to define the topology on $X^{*}$ 
  that would also yield a compactification (which is in particular not homeomorphic to the Alexandroff one-point topology) As far as I see it there are two approaches to answering this question: Show that any topology on $X^{*}$
that yields a compact space in which $X$
is dense is homeomorphic to $\mathcal{T}^{*}$. Show it's not possible to consturct any other topology on $X^{*}$  that results in a compactification. I'm quite interested in seeing the reasoning to both approaches if possible.
Thanks in advance!","['general-topology', 'compactification', 'compactness']"
427053,Monotone Decreasing Sequences of Functions: Is the Dominated Convergence Thm applicable?,"Reading through Rudin's Real and Complex Analysis, I came across the following exercise: Suppose $(f_n: X \to [0,\infty])$ is a monotone decreasing sequence of
  measurable functions such that $\lim\limits_{n \to \infty} f_n(x) =
 f(x)$ for all $x \in X$. Prove that if  $f_1 \in L^1(\mu)$, then $$\lim\limits_{n \to \infty}\int\limits_{X} f_n \, \mathrm{d}\mu =
 \int\limits_X f \, \mathrm{d}\mu.$$ It seems like this should be a trivial application of the Dominated Convergence Theorem, taking $f_1$ to be the dominating function. But it seems like an exercise would not be so trivial as to merit basically a one line proof. Is there a reason that DCT fails to be applicable here?","['lebesgue-integral', 'integration', 'real-analysis', 'analysis']"
427059,Lipschitz continuity and sup of derivative norm,"On this wikipedia page , it is stated: For a differentiable Lipschitz map $f : U \rightarrow R^m$ the inequality
  $\|Df\|_{\infty,U}\le K$ holds for the best Lipschitz constant of $f$, and
  it turns out to be an equality if the domain $U$ is convex. I have two questions about this statement. Question 1: does a best Lipschitz constant necessarily exists? Shouldn't be $K$ the $\inf$ of all Lipschitz constants? Question 2: do you know a proof of the wikipedia statement, or a reference where this is proved? 
I tried to prove it by using Taylor expansion with integral remainder (which seems to make sense with the convex assumption for equality), but it did not work... Thank you.","['multivariable-calculus', 'derivatives', 'analysis']"
427092,State-of-art of the Discrete Fourier Transform,"I would like to know what is the state-of-art in the research of the discrete Fourier transform. I have listed some questions to help answering, please add your own to make the list more comprehensive. 1) Is it possible to compute DFT faster than in $O(N\log N)$? Is there proofs for or against this? 2) For sparse inputs, I heard there is a faster than FFT algorithm now. Are there any other faster than FFT algorithms for some spesific input types? 3) Is it known how many additions and multiplications, respectively, is needed to compute the DFT for inputs of size $2^P$? Has a lower bound been proven (for either or both)? 4) What other improvements has been made during the past ten years or so? Proofs, explanations, and URLs to recent good papers are welcome. I know that I have several questions here, but I think it serves a good purpose. For someone who would like to enter the field, it is really difficult to find the correct things from the thousand's of publications and other materials in the internet.","['fourier-series', 'fourier-analysis', 'reference-request', 'soft-question', 'real-analysis']"
427116,Graphs of rational functions of sine and cosine,"What do graphs of rational functions of sine and cosine generally look like?  (A variety of different shapes, I know.  A classification or catalog of them might answer the question, or maybe a theoretical statement of some kind.) The domain can be regarded as a circle $[0,2\pi]$ by identifying the endpoints, and the codomain is the circle $\mathbb R\cup\{\infty\}$, the one-point compactification of the line.  Hence the graphs live on a torus .  The sine and cosine wind once around the torus the horizontal (domain) way and zero times around the vertical (codomain) way.  The tangent goes around once the horizontal way and twice the vertical way.  The secant and cosecant do as the sine and cosine do, but they're on the other half of the torus (and it is just half if you map the circle $\mathbb R\cup\{\infty\}$ to the ordinary Euclidean circle in a way that takes $0, 1, \infty, -1$ in that order to points differing by an arc of a quarter of the whole circle. So I looked at the graph of $\theta\mapsto\sec\theta+\csc\theta$.  I was a bit startled.  Superficially, it looked something like this: Between $0$ and $\pi/2$ it looks similar to $2\sqrt{2}\csc(2\theta)$, i.e. it came down from $+\infty$ and went back up; Between $\pi/2$ and $\pi$, it looks similar to one period of the tangent function, again of course with twice the frequency of the natural tangent function; Between $\pi$ and $3\pi/2$ it looks like the other lobe of the cosecant graph; Between $3\pi/2$ and $2\pi$ it looks like minus the tangent function, but again with twice the frequency. But the actual shape of those lobes resembling the secant graph is not identical to the shape of the actual secant graph.  And similarly with the tangent, although plotting the values of a tangent function having a zero at $3\pi/4$ against those of $\sec+\csc$ on that interval gives something remarkably close to a straight line, although visibly different from it. So its windings around the torus are thus: It goes once around in the horizontal direction, and a net zero times around in the vertical direction.  But in winding zero times around the circle $\mathbb R\cup\{\infty\}$, it starts and $\infty$, goes almost half way around in the negative direction, then goes in the positive direction almost two whole turns around the circle before turing around and heading back the other way.","['trigonometry', 'rational-functions']"
427120,Evaluate integral $ I_s(x) \leq \frac{C}{(\pi(1-2 \alpha s))^{d/2}}\exp\left(\frac{\alpha}{1-2 \alpha s }|x|^2\right) $,"For all $ x \in \mathbb{R}^n ,\hspace{5mm} 0  \leq s<t ,\hspace{5mm} t \in \mathbb{R}^+$ 
$$ I_s(x)=\int_{\mathbb{R}^n}\left|v\left(y \sqrt{2s}+x\right)\right|\exp(-|y|^2) \, \mathrm dy.  $$
How we can prove that $$ I_s(x) \leq  \frac{C}{(\pi(1-2 \alpha s))^{d/2}} \exp\left(\frac{\alpha}{1-2 \alpha s }|x|^2\right)  $$
if we have for all $ y \in \mathbb{R}^n ,|v(y) |<C\exp\bigl(\alpha |y|^2\bigr) $
such $C$ and $\alpha$ are constant $ ( C,\alpha > 0 ) $? What I did: Indeed, I think that the idea is to try to show 
$$ \int_{\mathbb{R}^n}C\exp(\alpha |y \sqrt{2s}+x|^2-|y|^2)dy \leq \frac{C}{(\pi(1-2 \alpha s))^{\frac{d}{2}}}\exp\left(\frac{\alpha}{1-2 \alpha s }|x|^2\right)(\text{Gaussian integral =1 } ).$$ in fact we have $$ I_s(x)=\int_{\mathbb{R}^n}\left|v\left(y \sqrt{2s}+x\right)\right|\exp(-|y|^2) \, \mathrm dy.  $$ 
or we know that  for all $ y \in \mathbb{R}^n ,|v(y) |<C\exp\bigl(\alpha |y|^2\bigr) $
then
$$
I_s(x) \leq \int_{\mathbb{R}^n}C\exp(\alpha |y \sqrt{2s}+x|^2-|y|^2)dy
  \leq \int_{\mathbb{R}^n}C\exp(|y|^2 2\alpha s+|x|^2-|y|^2)dy
\leq \int_{\mathbb{R}^n}C\exp(-(1-2\alpha s)|y|^2 +|x|^2)dy
$$
Let's make change variables by letting $ r=\sqrt{(1-2\alpha s)}y $ and $ dr=(1-2\alpha s)^{\frac{d}{2}} dy $
implies $$ I_s(x) \leq \int_{\mathbb{R}^n}\frac{C}{(1-2 \alpha s)^{\frac{d}{2}}} \exp(|x|^2)\exp(-|y|^2)dy$$ $$ I_s(x) \leq \frac{C}{(1-2 \alpha s)^{\frac{d}{2}}} \exp(|x|^2) \int_{\mathbb{R}^n}\exp(-|y|^2)dy$$ $$ I_s(x) \leq \frac{C}{(\pi (1-2 \alpha s))^{\frac{d}{2}}} \exp(|x|^2) \int_{\mathbb{R}^n}{\pi}^{\frac{-d}{2}} \exp(-|y|^2)dy$$ 
I'll be grateful for any help especially for detailed one Best regards, Educ .","['inequality', 'integration']"
427134,How to interpret the adjoint?,"Let $V \neq \{\mathbf{0}\}$ be a inner product space, and let $f:V \to V$ be a linear transformation on $V$. I understand the definition 1 of the adjoint of $f$ (denoted by $f^*$), but I can't say I really grok this other linear transformation $f^*$. For example, it is completely unexpected to me that to say that $f^* = f^{-1}$ is equivalent to saying that $f$ preserves all distances and angles (as defined by the inner product on $V$). It is even more surprising to me to learn that to say that $f^* = f$ is equivalent to saying that there exists an orthonormal basis for $V$ that consists entirely of eigenvectors of $f$. Now, I can follow the proofs of these theorems perfectly well, but the exercise gives me no insight into the nature of the adjoint . For example, I can visualize a linear transformation $f:V\to V$ whose eigenvectors are orthogonal and span the space, but this visualization tells me nothing about what $f^*$ should be like when this is the case, largely because I'm completely in the dark about the adjoint in general . Similarly, I can visualize a linear transformation $f:V\to V$ that preserves lengths and angles, but, again, and for the same reason, this visualization tells me nothing about what this implies for $f^*$. Is there (coordinate-free, representation-agnostic) way to interpret the adjoint that will make theorems like the ones mentioned above less surprising? 1 The adjoint of $f:V\to V$ is the unique linear transformation $f^*:V\to V$ (guaranteed to exist for every such linear transformation $f$) such that, for all $u, v \in V$, $$ \langle f(u), v\rangle  = \langle u, f^*(v)\rangle \,.$$","['inner-products', 'hilbert-spaces', 'linear-algebra', 'fourier-analysis']"
427139,"Probability, integers and reals (soft question)","Given a random integer, is the probability of correctly guessing what it is exactly zero? What if it would be a real number, rather than an integer? Does the fact that the set of all integers is countable and the set of real numbers is uncountable change the probability value?",['probability']
427150,Maclaurin Series for $\ln(x+\sqrt{1+x^2})$,"Is there a trick to finding the Maclaurin series for $f(x)=\ln(x+\sqrt{1+x^2})$ fast? Vaguely, I recall this being some sort of inverse hyperbolic function, but I'm not sure about which one, and what its derivatives are. This is a past exam question and I would like to know, should something similar appear again, if there is a quick method of finding this series without using inverse hyperbolic functions. The derivatives of this look absolutely painful to calculate, although easy at $x=0$, but I'm not sure if I could easily see a pattern for the $n$-th derivative at $0$.","['power-series', 'calculus']"
427163,Why is this composition of scheme morphisms proper?,"I am learning about proper morphisms from Liu's book. I have a question about the proof of the Lemma 3.17 on page 104. Let $A$ and $B$ be rings and suppose $\operatorname{Spec} B$ is proper over $A$. The lemma says that $B$ is finite over $A$. The proof begins by supposing that $B$ is singly generated over $A$, so that there is a surjective morphism $A[T]\rightarrow B$. We can consider $\operatorname{Spec} A[T]$ as an open subscheme of $\operatorname{Proj} A[T_1,T_2]$ by identifying it with the principal open set $D_+(T_2)$, setting $T=T_1/T_2$. We have the following composition of morphisms, where the first is a closed immersion and the second is an open immersion. $$\operatorname{Spec} B \rightarrow \operatorname{Spec} A[T] \rightarrow \operatorname{Proj} A[T_1,T_2]$$ Why is this proper? To justify this, the book quotes a result saying that if one has a proper composition of two morphisms $f\circ g$, and $f$ is separated, then $g$ is proper. But here, we know the first morphism is proper and we want to deduce the composition is proper. If we knew this was a closed immersion, I think we could compose it with a map to $\operatorname{Spec} A[T_1,T_2]$ and use the fact that projective morphisms are proper in conjunction with the result cited above. But it does not appear to be a closed immersion.","['schemes', 'abstract-algebra']"
427166,Number of distinct path in a graph with $n$ vertices,"Let $T = (V , E)$ be a tree with $|V | = n\geqslant 2$. How many distinct paths are there (as sub graphs) in $T$? I already have the answer to this question as $(n/2)$. The problem that I'm having is finding anything in the text that helps me to figure out how to arrive at this answer.","['graph-theory', 'discrete-mathematics', 'trees']"
427167,Combinations with 10 digits,"To find the number of $4$ digit combinations I can form with $10$ digits, without repeating any of the digits, I run the binomial coefficient of $10$ and $4$ and get $210$. A friend of mine suggested why not calculate all of the possible combinations you have with $10$ digits using only $4$, this means $10^4$, and divide it for all the possible combinations you can have with $4$ digits, which means $4^4$. The results would be $39.0625$ What is wrong with the approach of the my friend's answer?
Each $256$ combinations from the 10k possible combinations with the $10$ digits, is the results of  the combination of 4 digits. If I divide $10000$ by$ 256$ shouldn't I get the combinations without repeating any digits?",['combinatorics']
427170,Condition on monic second-order polynomials so that a commutative ring is an integral domain,"I am trying to prove this result: Let $A$ be a commutative ring different from $\{0\}$, $\mathbb{Z}/4\mathbb{Z}$ and $\mathbb{Z}/2\mathbb{Z}[X]/(X^2)$. Prove that if any monic polynomial of degree $2$ of $A[X]$ has at most two roots in $A$, then $A$ is an integral domain. I have tried to suppose that $A$ is not an integral domain, so that $\exists a,b\in A$ with $a,b\ne 0$ and $ab=0$. If $a\ne b$, the polynomial $X(X-a+b)$ has three different roots: $0,a-b,$ and $a$, which is absurd. However, if $a=b$ (so that $a^2=0$), I can't find a way to come to an absurdity. The polynomial $X^2$ has two different roots: $0$ and $a$, as well as any $xa$ for $x\in A$. An absurdity will occur if there exists $x\in A$ such that $xa\notin \{0,a\}$, and I can't see why just putting apart the three aforementioned rings ensures that it is the case.",['abstract-algebra']
427172,On the Constant Rank Theorem and the Frobenius Theorem for differential equations.,"Recently I was reading chapter $4$ (p. $60$ ) of The Implicit Function Theorem: History, Theorem, and Applications (By Steven George Krantz, Harold R. Parks) on proof's of the equivalence of the Implicit Function Theorem (finite-dimensional vector spaces) and the Picard Theorem  for ordinary differential equations . We know that the Implicit Function Theorem (finite-dimensional vector spaces) is a particular case of the Constant Rank Theorem. We also know that the Frobenius Theorem is a generalization of Picard's Theorem for ordinary differential equations. Based on these facts follow my question. The Constant Rank Theorem and the Frobenius Theorem for differential equations ( ODE's or/and PDE's) are equivalent? Is there any reference which provides a solution to this question? If the Frobenius theorem does not imply the Constant Rank Theorem there is some explanation for the negative? Conversely, if the Constant Rank Theorem does not imply the Frobenius theorem there is some explanation for the negative?","['ordinary-differential-equations', 'partial-differential-equations', 'real-analysis', 'analysis', 'implicit-function-theorem']"
427180,A question about the Hardy-Littlewood maximal function.,"Somebody can to help me in the following question? Let $f$ be measurable in $\mathbb{R}^n$ and different from zero in some set of positive measure. Show that there is a positive constant с such that $f^*(x) \geq c |x|^{-n}$ for $|x| \geq 1$ Note: $f^*(x)$ is the Hardy-Littlewood maximal function, i.e., $\displaystyle{f^*(x) = \sup_{r>0} \; \frac{1}{|B_{r}(x)|}\; \int_{B_{r}(x)} \;|f(y)|\;dy}.$","['measure-theory', 'real-analysis']"
427184,quick definition check: locally compact,"I have this statement in something I am reading: Let $S$ be a Borel subset of $\mathbb{R}^d$ that is locally compact in
  the relative topology. Does this mean that every point in $S$ has a compact neighbourhood in the subspace topology of $S$ relative to the usual topology of $\mathbb{R}^d$? Then it goes on saying We denote as $B_b(S)$ the linear space of all bounded Borel measurable
  function from $S$ to $\mathbb{R}$Banach space) with respect to the
  supremum norm for each $f\in B_b(S)$. I have typed every word from the book. Clearly, there is a typo here, does anyone have a guess what it could mean? More importantly, I was wondering why the local compactness condition imposed on $S$ is important.","['general-topology', 'measure-theory', 'functional-analysis']"
427192,"showing $f(x_1,x_2)=\sqrt[3]{x_1x_2}$ is differentiable","Given $f\colon\mathbb R^{>0}\times\mathbb R^{>0}\rightarrow\mathbb R, (x_1,x_2)\mapsto \sqrt[3]{x_1\cdot x_2}$ I want to prove that $f$ is differentiable. I know $f$ is partial differentiable and all partial derivatives are continuous, so $f$ is differentiable. But I am wondering if I could show it by the definition of differentiability. E.g. consider the point $1=(1,1)$. So there has to be a linear map $A$ such  that $\lim_{h\rightarrow0}\frac{f(1+h)-f(1)-Ah}{\|h\|}=0$ Let $h=(h_1,h_2)$. It's $A=(\frac13,\frac13)$ and so $\lim_{h\rightarrow0}\frac{\sqrt[3]{(1+h_1)(1+h_2)}-1-\frac13h_1-\frac13h_2}{\|h\|}=0$ ? I know how to show it using polar coordinates but is there any way by doing it without any big 'help functions/relations' etc.?","['calculus', 'derivatives', 'real-analysis', 'analysis']"
427194,"Conditional probability is not a probability measure, but it does satisfy each of the requisite axioms with probability 1.","I dont quite understand what the statement in the question means, which appears in this paragraph of a textbook I am reading. How can it not be a probability measure (not even almost surely) but satisfies each of the requisite axioms with probability 1? Why are the two things not the same?","['probability-theory', 'measure-theory']"
427195,Trigonometric near-identity,"The parametrized curve
$$
\left( \sec\theta+\csc\theta,\  2\sqrt{2}\csc(2\theta) \right), \qquad \frac{10}{100} \le\theta\le\frac{142}{100}
$$
looks to the naked eye like a straight line.  The $y$-intercept is not $0$ and the slope is a number that I haven't tried to make sense out of (yet).  (The factor $2\sqrt{2}$ was chosen only to make the minimum values of the two coordinates equal to each other.)  The best-fitting straight line gives all residuals less than $0.08$, quite small! Why?",['trigonometry']
427212,Do I need to present a formula in this proof?,"Well, I've been studying Rudin's Principles of Mathematical Analysis and then I've thought on the following exercise: Let $A, B$ be two countable sets, then $A\times B$ is countable. My idea to prove this was to arrange the elements of $A\times B$ in a sequence. Inded, I've used that argument of constructing the array: $$\begin{matrix}
(a_1,b_1) & (a_1,b_2) & (a_1,b_3) & (a_1,b_4) & \cdots \\ 
(a_2,b_1) & (a_2,b_2) & (a_2,b_3) & \cdots & \cdots \\ 
(a_3,b_1) & (a_3,b_2) &  \cdots  & \cdots & \cdots \\ 
 \vdots & \vdots & \vdots & \vdots &  \vdots\\ 
\end{matrix}$$ And then arrange the sequence $(a_1,b_1), (a_1,b_2), (a_2,b_1), (a_3,b_1), (a_2,b_2), (a_1,b_3)\dots$ with this I would be defining a sequence of distinct elements, in other words a bijection $f: \Bbb N \to A\times B$ showing that $A\times B$ is countable. I've then shown this to someone I know that studies set theory and he said that this proof wasn't good, it was needed to show explicitly the function $f$. Is this really necessary? Because the argument show that this must be a bijection: since $A$ is countable it's elements can be put into a sequence $(a_i)$ and the same for the elements of $B$ which would give a sequence $(b_i)$. Both sequences are of distinct terms. Now, on this arrangement, we have elements $(a_i, b_j)$, so all the pairs are distinct because the sequences $(a_i)$ and $(b_j)$ are of distinct elements. Is it necessary to find $f$? If that's the case, how could I find it? I didn't notice any obvious pattern into the sequence I've made.",['elementary-set-theory']
427222,"Given that $xyz=1$ , find $\frac{1}{1+x+xy}+\frac{1}{1+y+yz}+\frac{1}{1+z+xz}$?","I think I solved this problem, but I don't feel $100$ percent sure of my solution. We have: $xy=\large {\frac 1z}$ $xz=\large \frac 1y$ $yz=\large \frac 1x$ So let's substitute these into our sum: $\large  \frac{1}{1+x+\frac 1z}+\frac{1}{1+y+\frac 1x}+\frac{1}{1+z+\frac 1y}$ If we rewrite with a common denominator we get $\large \frac{z}{1+z+xz}+\frac {x}{1+x+xy}+\frac{y}{1+y+zy}$ If $\large \frac{1}{1+x+xy}+\frac{1}{1+y+yz}+\frac{1}{1+z+xz}=\frac {x}{1+x+xy} +\frac{y}{1+y+zy}+\frac{z}{1+z+xz}$ , $;$   then $(x, y, z)=1$ and we can compute that the sum is equal to $1$. The problem I have with this is that I found what $(x, y, z)$  $had$ to be, but I but I only had one weak restriction on the variables. Secondly, what are other way of doing this that I can learn from? Thanks.","['elementary-number-theory', 'algebra-precalculus']"
427236,Chain rule for functions of two variables,"Suppose that $f(x,y)$ is a function of two variables with $f_x(0,2) = 2$ and $f_y(0,2) = -1$. Using the chain rule compute the numerical value of $f_\theta(r\cos\theta,r\sin\theta) = 2$ at $r=2$, $\theta=\frac{\pi}{2}$. Any hints on how to do this question would be appreciated. Thanks in advance.",['multivariable-calculus']
427255,Does $\sum_{n=1}^{\infty} \frac{\sin(n)}{n}$ converge conditionally? [duplicate],"This question already has answers here : How to prove that $ \sum_{n \in \mathbb{N} } | \frac{\sin( n)}{n} | $ diverges? (3 answers) Closed 3 years ago . I think that the series $$\sum_{n=1}^{\infty} \dfrac{\sin(n)}{n}$$ converges conditionally, but I´m not able to prove it. Any suggestions ?","['convergence-divergence', 'sequences-and-series', 'analysis']"
427256,Prove that the additive inverse of an odd integer is an odd integer,"This is a homework problem, but I don't want the answer, just a little guidance: Prove that the additive inverse of an odd integer is an odd integer. When approaching a problem like this, how much is it safe to assume?  Is it safe to assume that ""the additive inverse of an integer is an integer?""  Or does that need to be proven first, before we can start talking about odds and evens? I have two ideas about how to approach this, and that is to either: 1) Use absolute value to negate the fact that something is negative so that the absolute values of something like $4$ and $-4$ are both $4$.  But is it safe to assume something like ""the absolute values of any integer positive or negative are equal?"" 2) Do something like subtract $2$ times a number to get the negative or positive:
e.g. the additive inverse of $4$ is $(4 - 2(4))$.  The additive inverse of $-4$ is $(-4 -(2(-4))$. Exactly where I would follow those ideas to, I'm not sure yet, but I'd like to at least know I'm on the right track and not completely going off in the wrong direction.","['discrete-mathematics', 'proof-writing']"
427257,Motivation behind Dedekind's cut set,"I want to know the motivation behind Dedekind's real number construction. The motivation of such properties of the cut sets is not clear to me. 
BTW, I am new to real analysis and just have started reading the first chapter of Rudin. what made Dedekind to thought of sets with some nice properties (what are the motivations behind such properties ? For example, why cut set should not have any greatest element ?). I read somewhere that initially Dedekind thought that any real number can be uniquely identified by rational numbers less than that. So, this was his starting point. From that the first and second property of cut set is understandable, but the third property (no greatest element) is not clear to me.","['intuition', 'real-analysis']"
427258,second and first derivative growth function,"I have a function I would like to take the first and second derivative from $$f(t)= a\left(1-\frac{1}{1+(b(t+i))^e+(c(t+i))^f+(d(t+i))^h)}\right)$$ I have taken the following steps $$u(t)={\left(\mathrm{b}\, \left(\mathrm{i} + t\right)\right)}^{\mathrm{e}} + {\left(\mathrm{c}\, \left(\mathrm{i} + t\right)\right)}^{\mathrm{f}} + {\left(\mathrm{d}\, \left(\mathrm{i} + t\right)\right)}^{\mathrm{h}} + 1$$ $f(t) = a (1-1/u(t))$
$f(t) = a ((u(t)-1)/u(t))$ for simplicity u(t) = u and f(t)=f f= a*(u-1)/u quotient rule
dy = d(u-1) df = a*((du*u-du*(u-1))/u^2) df = a * du/u^2 quotient rule d2f = a*((d2u*u^2-du*d(u^2))/u^4) Is the above reasoning correct? df= (a*(b*e*(b*(i + t))^(e - 1) + c*f*(c*(i + t))^(f - 1) + d*h*(d*(i + t))^(h - 1)))/((b*(i + t))^e + (c*(i + t))^f + (d*(i + t))^h + 1)^2 d2f=(a*((b^2*e*(e - 1) (b (i + t))^(e - 2) + c^2*f*(f - 1) (c (i + t))^(f - 2) + d^2*h*(h - 1) (d (i + t))^(h - 2)) ((b (i + t))^e + (c*(i + t))^f + (d*(i + t))^h + 1)^2 - (2*(b*e*(b*(i + t))^(e - 1) + c*f*(c*(i + t))^(f - 1) + d*h*(d*(i + t))^(h - 1))^2 + 2*(b^2*e*(e - 1) (b (i + t))^(e - 2) + c^2*f*(f - 1) (c (i + t))^(f - 2) + d^2*h*(h - 1) (d (i + t))^(h - 2)) ((b (i + t))^e + (c*(i + t))^f + (d*(i + t))^h + 1))*(b*e*(b*(i + t))^(e - 1) + c*f*(c*(i + t))^(f - 1) + d*h*(d*(i + t))^(h - 1))))/((b*(i + t))^e + (c*(i + t))^f + (d*(i + t))^h + 1)^4 $\dfrac{d}{dt} f(t) = \frac{a\, \left(b\, e\, {\left(b\, \left(i + t\right)\right)}^{e - 1} + c\, f\, {\left(c\, \left(i + t\right)\right)}^{f - 1} + d\, h\, {\left(d\, \left(i + t\right)\right)}^{h - 1}\right)}{{\left({\left(b\, \left(i + t\right)\right)}^e + {\left(c\, \left(i + t\right)\right)}^f + {\left(d\, \left(i + t\right)\right)}^h + 1\right)}^2}$ $\dfrac{d2}{d2t} f(t) =\frac{a\, \left(\left(b^2\, e\, \left(e - 1\right)\, {\left(b\, \left(i + t\right)\right)}^{e - 2} + c^2\, f\, \left(f - 1\right)\, {\left(c\, \left(i + t\right)\right)}^{f - 2} + d^2\, h\, \left(h - 1\right)\, {\left(d\, \left(i + t\right)\right)}^{h - 2}\right)\, {\left({\left(b\, \left(i + t\right)\right)}^e + {\left(c\, \left(i + t\right)\right)}^f + {\left(d\, \left(i + t\right)\right)}^h + 1\right)}^2 - \left(2\, {\left(b\, e\, {\left(b\, \left(i + t\right)\right)}^{e - 1} + c\, f\, {\left(c\, \left(i + t\right)\right)}^{f - 1} + d\, h\, {\left(d\, \left(i + t\right)\right)}^{h - 1}\right)}^2 + 2\, \left(b^2\, e\, \left(e - 1\right)\, {\left(b\, \left(i + t\right)\right)}^{e - 2} + c^2\, f\, \left(f - 1\right)\, {\left(c\, \left(i + t\right)\right)}^{f - 2} + d^2\, h\, \left(h - 1\right)\, {\left(d\, \left(i + t\right)\right)}^{h - 2}\right)\, \left({\left(b\, \left(i + t\right)\right)}^e + {\left(c\, \left(i + t\right)\right)}^f + {\left(d\, \left(i + t\right)\right)}^h + 1\right)\right)\, \left(b\, e\, {\left(b\, \left(i + t\right)\right)}^{e - 1} + c\, f\, {\left(c\, \left(i + t\right)\right)}^{f - 1} + d\, h\, {\left(d\, \left(i + t\right)\right)}^{h - 1}\right)\right)}{{\left({\left(b\, \left(i + t\right)\right)}^e + {\left(c\, \left(i + t\right)\right)}^f + {\left(d\, \left(i + t\right)\right)}^h + 1\right)}^4}$",['derivatives']
427263,"Sequence of irreducible polynomials in $K[X_{1},....,X_{n}]$ generates a prime ideal?","I was thinking about how a chain of irreducible polynomials in $K[X_1,\ldots,X_n]$, where $K$ is a field, behave with respect of being prime. What I mean is the folowing: If $\{f_1,\ldots,f_n\}$ is a sequence of irreducible polynomials in $K[X_1,\ldots,X_n]$, I know that the ideal generated by $(f_i)$ is prime for every $i = 1,\ldots,n$. But what I can have from the ideals of the form  $I_k = (f_1,f_2,\ldots,f_k)$? Are these ideals $I_k$ prime? I'm asking this because if this is true there is a very simple answer for my question here . Thank you for the help!!","['ring-theory', 'ideals', 'abstract-algebra']"
427265,"Pólya and Szegő, Part I, Ch. 4, 174.","The following is a problem proposed in Pólya and Szegő's book ""Problems and Theorems in Analysis"" Assume that $0<f(x)<x$ and $$f(x)=x-ax^k+bx^\ell+x^\ell \varepsilon(x),\,\;\;\;\lim_{x\to 0}\varepsilon(x)=0$$
  for $0<x<x_0$, where $1<k<\ell$ and $a,b$ positive. Put $$v_0=x,\;\; v_1=f(v_0),\;\;v_2=f(v_1),\ldots,\;\;\;v_n=f(v_{n-1}),\ldots$$
  Then we have for $n\to\infty$$$n^{\frac{1}{k-1}}v_n\to[(k-1)a]^{\frac{-1}{k-1}}$$ PROOF I will prove the better looking$$nv_n^{k-1}\to \frac{1}{a(k-1)}$$ To this end, first note that $v_n\to 0$, since $v_n$ decreases because of $0<f(x)<x$ and because of continuity at the origin, along with $f(0)=0$. Also note $f(x)/x\to 1$. Now, we have after some algebraic meddling that $$\frac{1}{{{x^{k - 1}}}} - \frac{1}{{f{{\left( x \right)}^{k - 1}}}} = \frac{{f{{\left( x \right)}^{k - 1}} - {x^{k - 1}}}}{{{x^{k - 1}}f{{\left( x \right)}^{k - 1}}}} = \frac{{f\left( x \right) - x}}{{{x^k}}}\frac{{f\left( x \right)}}{x}{\sum\limits_{m = 0}^{k - 2} {\left( {\frac{x}{{f\left( x \right)}}} \right)} ^m}$$ It follows that $$\mathop {\lim }\limits_{x \to 0} \left( {\frac{1}{{f{{\left( x \right)}^{k - 1}}}} - \frac{1}{{{x^{k - 1}}}}} \right) = a\left( {k - 1} \right)$$ Thus, since $v_n\to 0$, we must have $$\mathop {\lim }\limits_{n \to \infty } \left( {\frac{1}{{v_{n + 1}^{k - 1}}} - \frac{1}{{v_n^{k - 1}}}} \right) = a\left( {k - 1} \right)$$ Appealing to Cesàro's theorem, it follows that $$\mathop {\lim }\limits_{n \to \infty } \frac{1}{n}\left( {\sum\limits_{m = 0}^{n - 1} {\frac{1}{{v_{m + 1}^{k - 1}}} - \frac{1}{{v_m^{k - 1}}}} } \right) = \mathop {\lim }\limits_{n \to \infty } \frac{1}{n}\left( {\frac{1}{{v_n^{k - 1}}} - \frac{1}{{v_0^{k - 1}}}} \right) = a\left( {k - 1} \right)$$ Which is what we wanted to prove. $\blacktriangle$ DSC The above is inspired in this particular proof when $f(x)=\sin x$. Do you know any other proofs?","['alternative-proof', 'sequences-and-series', 'problem-solving']"
427277,"For a morphism of affine schemes, the inverse of an open affine subscheme is affine","This seems ridiculously simple, but it's eluding me. Suppose $f:X\rightarrow Y$ is a morphism of affine schemes. Let $V$ be an open affine subscheme of $Y$. Why is $f^{-1}(V)$ affine? I noted that $V$ is quasi-compact and wrote it as a finite union of principal open sets. Because the pullbacks of principal open sets are principal open sets, we can write $f^{-1}(V)$ as the union of such sets. But I'm not sure how to show this union is affine. I don't think this is the right way to go, because such unions are not affine in general. I'm particularly perplexed because this occurs as an exercise in the chapter on separated morphisms and base change in Liu. Of course, all affine schemes are separated, but I don't see the relevance of that here.","['affine-schemes', 'schemes', 'abstract-algebra']"
427294,Generalizing the Definition of Convexity,"The definition of convexity can be given as: Definition: Call a subset of $\mathbb{R} ^ k$, which will be denoted $E$, convex if given two elements of $E$, $\boldsymbol{x}$ and $\boldsymbol{y}$ and $0 < \lambda < 1$ the following holds:
$$ \lambda \boldsymbol{x} + (1 - \lambda ) \boldsymbol{y} \in E$$ What I have been wondering is whether this is limited to two elements of $E$. In other words, can this be generalized to $n$ elements of $E$ and still retain the same properties? Thus I propose the following definition: Definition: Call a subset of $\mathbb{R} ^ k$, which will be denoted $E$, ""generally convex"" if given $ \boldsymbol{x}_i \in E$, for $i = 1,2,...,n$ and the condition $\sum_{1=1}^n \lambda_i = 1$ the following holds:
$$ \sum_{i=1}^n \lambda_i \boldsymbol{x}_i  \in E $$ An open ball is an example of a convex set, and it is also the case that a ball is generally convex. Proof: Let $| \boldsymbol{x} _1 - \boldsymbol{x} |$, $| \boldsymbol{x} _2 - \boldsymbol{x} |$, $...$, $| \boldsymbol{x} _n - \boldsymbol{x} |$, be $n$ balls centred at $\boldsymbol{x}$ with radius $r$. Consider the following:
$ | \sum_{i=1} ^n \lambda_i \boldsymbol{x}_i - \boldsymbol{x} | $. This is also a ball of radius $r$. $$| \sum_{i=1} ^n \lambda_i \boldsymbol{x}_i - \boldsymbol{x} | = | \sum_{i=1} ^n \lambda_i (\boldsymbol{x}_i - \boldsymbol{x}) | $$ $$\le  \sum_{i=1} ^n |\lambda_i (\boldsymbol{x}_i - \boldsymbol{x}) |$$ $$< \sum_{i=1}^n \lambda_i r $$ $$=r$$ This, among other things, satisfies both the definition for convexity and general convexity. This leads me to the following conjecture: Conjecture: Consider a subset of $\mathbb{R} ^k$, $E$. $E$ is convex if and only if $E$ is generally convex. I am having difficulty proving whether or not my conjecture is true. My first thought was that given an element of $E$, it should be able to be expressed as a linear combination of other elements of $E$. And thus using this fact, expand the convexity definition to the general convexity one. The only difficulty with this is figuring out whether or not this can be done for every element of $E$. Online I have been able to find arguments that seem to support this for the case of vector-spaces, but nothing that states it for complex sets. Proof Sketch: Suppose that it is the case that any $\boldsymbol{x}_i \in E$ may be expressed as a linear combination of other elements in $E$. Then given $\lambda \boldsymbol{x}$ as presented in the definition of convexity, the $\boldsymbol{x}$ can be ""split"" into two new elements of $E$. This can be re-iterated until we have the $n$ elements needed for the general convexity definition. Conversely, we just need to ""combine"" $\mathbb{x}_i$'s in the general convexity definition until only the two remaining elements we desire remain. Thus this leads to my questions: How do I go about proving whether my conjecture is true or false (linear combinations or some other method)? Does this ""general convexity"" definition have any mathematical significance?","['general-topology', 'convex-analysis', 'real-analysis']"
427297,Continuous function $f:E\rightarrow F$ with closed graph in $E\times F$ implies $F$ compact,"Please can you help with this exercise. Let $F$ be a metric space such that for any metric space $E$, any mapping of $E$ into 
$F$ whose graph is closed in $E\times F$ is continuous. Show that $F$ is compact.","['general-topology', 'metric-spaces', 'compactness']"
427299,Relation Matrix,"Is my set of related pairs correct for this problem? $$\{(2,1), (2,2), (3,1), (3,2), (3,3), (4,1), (4,2), (4,3), (4,4)\}$$ Suppose that $\,A = \{1,2,3,4\}\,$ and $\,B = \{1, 2, 3\}.$ Let $R$ be the relation from $A$ to $B$ containing $(a,b)$ if $\,a \in A$ , $b \in B$ , and $\;a^2 \ge 2^b$ . What is the matrix representing $R$ ? (Assume the ordering of elements is the same as the increasing numerical order.)","['relations', 'matrices', 'discrete-mathematics']"
427315,Looking for an easy lightning introduction to Hilbert spaces and Banach spaces,"I'm co-organizing a reading seminar on Higson and Roe's Analytic K-homology . Most participants are graduate students and faculty, but there are a number of undergraduates who might like to participate, and who have never taken a course in functional analysis. They are strong students though, and they do have decent analysis, linear algebra, point-set topology, algebraic topology... Question: Could anyone here recommend a very soft, easy, hand-wavy reference I could recommend to these undergraduates, which covers and motivates basic definitions and results of Hilbert spaces, Banach spaces, Banach algebras, Gelfand transform,  and functional calculus? It doesn't need to be rigourous at all- it just needs to introduce and to motivate the main definitions and results so that they can ""black box"" the prerequisites and get something out of the reading seminar. They can do back and do things properly when they take a functional analysis course next year or so.","['banach-algebras', 'self-learning', 'operator-theory', 'reference-request', 'functional-analysis']"
