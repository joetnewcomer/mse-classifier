question_id,title,body,tags
1681341,Evaluate $\int_{-\infty}^{\infty}\frac{\sin x}{x}\mathop{}\! \mathrm dx$ [duplicate],"This question already has answers here : Integration of the cardinal sine (4 answers) Closed 8 years ago . I am trying to evaluate the following: $$\int_{-\infty}^{\infty}\frac{\sin(x)}{x}\, dx$$ My first approach was to find the antiderivative but I can't seem to express it as I have not yet learnt about $\text{Si}(x)$ . I then tried replacing the $\sin(x)$ with $(e^{ix}-e^{-ix})/(2i)$ but I just ended something even more complicated. Does making it go from $0$ to $\infty$ by multiplying by $2$ help? Please help me in evaluating this integral. By the way, I am familiar with substitution and integration by parts but not complex analysis or contour integration. However, if this question requires something I don't already know, I am willing to try and understand it. Thanks.","['integration', 'calculus']"
1681363,CDF of absolute value of difference in random variables,"Let $X$ and $Y$ be independent random variables, uniformly distributed in the interval $[0,1]$. Find the CDF and the PDF of $|X - Y|$? Attempt Let $Z = |X - Y|$, so for $z \geq 0$, the CDF $F_{Z}(z) = \mathbf{P}(Z \leq z) = \mathbf{P}(|X - Y| \leq z) = \mathbf{P}(-z \leq X - Y \leq z)$, which is where the algebra becomes confusing. Since they are independent, the joint pdf of $X$ & $Y$ is simply 1, as long as $(X,Y)$ belong to the unit square.
The solution suggests a plot the event of interest as a subset of the unit square and find its area. Any hints?",['probability']
1681374,rate of change of area of circle per second w.r.t. radius,"Find the rate of change of the area of a circle per second with
respect to its radius when radius=5cm. Source $A= \pi r^2$ ⇒ $\frac{{\rm d}A}{{\rm d}r} =2rπ$ So when $r=5$ cm, $\frac{{\rm d}A}{{\rm d}r}= 10 \pi$ cm But the answer is $10\pi$ cm $^2$ /sec. I don't understand how time comes into picture when we are only talking about radius and area? Why is ""per second"" even mentioned in the question?","['derivatives', 'calculus']"
1681393,Semisimplicity of the induced representation of an irreducible representation,"Let $G$ be an arbitrary group, $H$ be a subgroup of finite index $n$ and $k$ be an algebraically closed field of characteristic prime to $n$. Suppose that we have an irreducible representation
$$\rho: H\to \mathrm{GL}(V)$$
where $V$ is a finite-dimensional $k$-vector space. Is the induced representation $\mathrm{Ind}_H^G(\rho)$ semisimple? This will certainly be true if $H$ is finite of order prime to the characteristic, or if we are in characteristic $0$ and $G$ is compact. Can we get away with less in this case? If $\mathrm{Ind}_H^G(\rho)$ is not semisimple, does the situation change if we assume that $\rho$ is actually the restriction of some irreducible representation $\sigma: G\to\mathrm{GL}(V)$? Edit: Alternatively, would the situation change if we knew that $H$ was normal in $G$?","['representation-theory', 'abstract-algebra', 'group-theory']"
1681409,why $3 - \sin{x}$ is always positive?,"Hello I am currently learning integration and after integrating the function $\int \frac{\cos{x}}{3-\sin{x}}$ I end up with $-\ln{|3-\sin{x}|} + c$. However in the textbook it is stated that, since $3-\sin{x}$ can only take positive values, the answer is $-\ln{(3-\sin{x})} + c$. I know it is very basic question but I want to make sure I understand this correctly. Does the $3-\sin{x}$ take only positive values because $\sin{x}$ can
  output values between $-1$ and $1$, therefore the minimum $y$-value
  can be $2$? Please note that I do understand why integrating $\frac{1}{x} = \ln{x} + c$ for $x>0$","['logarithms', 'trigonometry', 'calculus']"
1681422,There exists strictly increasing $\{x_n\}$ that converges to $\sup E$,"I need to prove that, if $E \subseteq \mathbb{R}$ is a non-empty bounded set and $\sup E \not\in E$ then there exists a strictly increasing sequence $\{x_n\}$ that converges to $\sup E$ such that $x_n \in E$ for all $n \in \mathbb{N}$. I've been trying to find a clue in the textbook, but couldn't. I don't even know how to start the proof. Could someone please give a clue?","['real-analysis', 'analysis']"
1681434,Find the solutions of the diophantine equation $(x^2-y^2)(z^2-w^2)=2xyzw$,"Let $x,y,z,w$ be postive integers. Find all solutions of:
$$(x^2-y^2)(z^2-w^2)=2xyzw$$ This gives: 
$$\left(\dfrac{x}{y}-\dfrac{y}{x}\right)\left(\dfrac{z}{w}-\dfrac{w}{z}\right)=2$$ $$\left(p-\dfrac{1}{p}\right)\left(q-\dfrac{1}{q}\right)=2$$","['number-theory', 'diophantine-equations']"
1681440,"Measure theory problem involving metric density function $\rho(E, x)$","Working on the real line $(\mathbb{R})$, let $\mu : \mathscr{M} \rightarrow [0, +\infty]$ represent the Lebesgue measure ($\mathscr{M}$ is the set of measurable subsets of $\mathbb{R}$). For $E \in \mathscr{M}$ and $x \in \mathbb{R}$, we define $$\rho(E, x) = \lim_{\delta \to 0+} \frac{\mu(E \cap (x - \delta, x + \delta))}{2\delta},$$ if the limit exists. The above limit is called the metric density of $E$ at $x$. $(1)$ Given $E=(1,2)\cup(2,5]\cup\{6\}$, find the metric density of $E$ for all $x \in E$. $(2)$ Let $\alpha \in (0, 1)$. Construct a set $E\subset\mathbb{R}$ such that $\rho(E, 0) = \alpha$. My work and thoughts: $(1)$ Since $x$ can be any real number, the intersection $E \cap (x - \delta, x + \delta)$ can be empty. Also, if $(x - \delta, x + \delta) \subset E$, as $\delta \rightarrow 0+$ the intersection $E \cap (x - \delta, x + \delta) = x$. In either case the measure equals zero. Is this correct? For $(2)$ I have no idea.","['real-analysis', 'lebesgue-measure', 'measure-theory', 'proof-verification']"
1681455,Technical challenge: Limit of von-Mises distribution approximates normal. How to take the limit?,"Background: In psychophysics or the study of ant navigation it's important to represent random variables on a circle. The most popular distribution for doing so is the von-Mises distribution (the wrapped Gaussian is too messy to work with). This is the von-Mises distribution for a random variable on a circle, $\theta \in [-\pi,\pi)$:
\begin{align} 
p(\theta;\mu,\kappa) = \frac{e^{\kappa cos(\theta - \mu)}}{\int_{-\pi}^\pi e^{\kappa cos(\theta)} \text{d}\theta} = \frac{e^{\kappa cos(\theta - \mu)}}{2 I_0(\kappa)}  ,
\end{align}
where $\kappa$ is the concentration parameter (have the inverse variance $\kappa \sim \sigma^{-2}$ in mind), $\mu$ the mean and the normalisation can be expressed in terms of the modified Bessel function of the first kind, $I_0(\kappa)$. Problem statement: Wikipedia ( https://en.wikipedia.org/wiki/Von_Mises_distribution ) claims that
\begin{align} 
\lim_{\kappa \rightarrow \infty} p(\theta;\mu,\kappa) = \text{Normal}(\theta; \mu, \kappa^{-1/2}).
\end{align} (The limit is not a rigorous mathematical limit but more a physicist-way of saying: expand the expression and throw higher-order terms away).
It makes sense: If the distribution is highly concentrated, we can forget about the circularity and just approximate the von-Mises as normal. Mathematically it makes intuitive sense, too. The argument of the exponential ranges between $\pm \kappa$, being 0 always at $\theta = \pm \pi/2$. At the same time, the normalisation constant grows large such that the whole distribution is essentially divided by a very large number and tends to zero everywhere except around it's mode. Around the mode, the cosine can be approximated by $\cos(\epsilon) = 1- \epsilon^2/2$, yielding a nice normal distribution. Despite this, I find it incredibly hard to show this! Can anyone help me with this technical challenge? My (unsuccessful) approach: I've tried to use Taylor expansion for the cosine and the following series representations ( http://mhtlab.uwaterloo.ca/courses/me755/web_chap4.pdf ) of the Bessel function for large $\kappa$:
\begin{align}
I_0(\kappa) = \sum_{n}^\infty \frac{(\kappa/2)^{2n}}{n!\Gamma(n+1)} \approx \frac{e^\kappa}{\sqrt{2\pi \kappa}}(1 + \frac{1}{8\kappa} + \mathcal{O}(\kappa^{-2})),
\end{align}
however, it didn't get me anywhere. Does anyone have any ideas how to attack this problem? Any help is much appreciated!","['bessel-functions', 'taylor-expansion', 'normal-distribution', 'limits', 'approximation']"
1681461,Fit 2600 equally spaced points on concentric circles,"My friend is working on an art project where she wants to draw 2600 dots on a circular table, symbolising the 2600 deaths of the conflict in east Ukraine. She approached me to solve this, but I've run out of ideas. The points must be placed in rings, where the space between the rings is equal to the space between the dots in the rings. At the centre of the table should be the zeroth ring which is a single dot. The table is 1.1 metres in diameter, however use a diameter value of 1 metre to leave a margin around the edge of the table. How many rings should there be, how many dots should there be in each ring and what is the value of the spacing for both the space between the dots and the space between the rings? (There may be multiple solutions.) An exact solution is preferable but approximate solutions are also accepted.","['circles', 'packing-problem', 'geometry']"
1681490,Lower semi-continuity of one dimensional Hausdorff measure under Hausdorff convergence,"Let $\mathcal H^1$ be the one-dimensional Hausdorff measure on $
\mathbb R^n$, and let $d_H$ be the Hausdorff metric on compact subsets of $\mathbb R^n$. If $K_n$ is connected for all $n \in \mathbb N$, and $d(K_n,K) \to 0$, I would like to know if 
$$\mathcal H^1 (K) \leq \liminf\limits_{n \to \infty} \mathcal H^1(K_n).$$ If $K_n$ is not connected, this is not true. One can take $K_n = \bigcup\limits_{i=0}^{2^n-1} [{i \over 2^n}, {i + 1/2 \over 2^n}]$. Then $\mathcal H^1(K_n) = 1/2$, but $K_n \to [0,1]$. Also, for $\mathcal H^k$, $k$ an integer greater than one, this fails spectacularly. See this picture from Frank Morgan's book: The thing that I am trying to prove is used implicitly in Peter Jones's paper on the analyst's traveling salesman problem, I believe.","['real-analysis', 'metric-spaces', 'metric-geometry', 'analysis']"
1681515,Linear convergence of sequences of inverse functions,"Let $f, f_n: \mathbb{R}^m \rightarrow \mathbb{R}^m$ such that $f^{-1}, f_n^{-1}$ exist and are globally Lipschitz continuous for all $n$ (same constant $L$). Assume that $f_n := f + \frac{1}{n} Id$. Then $\left( f_n \right)^{-1} \rightarrow f^{-1}$ uniformly on every compact set. Prove or disprove that $\left\| \left( f_n \right)^{-1} - \left( f \right)^{-1}\right\| \leq \frac{c}{n}$, for some $c>0$. Comments: $\left( f_n \right)^{-1} \rightarrow f^{-1}$ follows from the Lipschitz continuity property, see: Convergence of sequences of inverse functions . However, that does not exploit the fact that $\left( f_n \right)^{-1} = \left( f + \frac{1}{n} Id \right)^{-1}$. Attempt: If we take $x = \left( f + \frac{1}{n}Id \right) (y) = f(y) + \frac{1}{n} y$, then 
$\left\| \left( f + \frac{1}{n}Id \right)^{-1}(x) - f^{-1}(x)  \right\| = 
\left\| y - f^{-1}\left( f(y) + \frac{1}{n} y \right)  \right\| = 
\left\| f^{-1}\left( f(y) \right) - f^{-1}\left( f(y) + \frac{1}{n} y \right)  \right\| \leq L \left\| f(y)  - f(y) + \frac{1}{n} y \right\| = L \left\|  \frac{1}{n} y \right\| = \frac{L}{n} \left\| y \right\|$. So the statement holds if $\left\| y \right\|$ is bounded, i.e. if the domain of $f$ is bounded. Otherwise it seems the statement may be false.","['real-analysis', 'limits', 'inverse-function', 'functional-analysis', 'analysis']"
1681536,"Let T be a tree with t edges and G a graph. Prove that if |E(G)| ≥ t · |V (G)|, then T is a subgraph of G.","I tried to prove it by induction on t. Obviously true when t=1 and 2. Suppose true when t=k, then when tree T has t=k+1, we could remove a leaf x from T and thus go back to case t=k, but I have no idea how to extend that to a tree isomorphic to T . There are similar questions which restrict on degree of vertices of G , I also tried to use $$\sum_{v\in G}{d(v)}=2|E(G)|$$ but did not find a way. (e.g. Trees that are isomorphic to a subgraph of a graph G. )","['graph-theory', 'discrete-mathematics']"
1681542,Two definitions of Hilbert series/Hilbert function in algebraic geometry,"In classical algebraic geometry, suppose $I$ is a reduced homogeneous ideal in $k[x_0,\cdots,x_n]$, where $k$ is algebraically closed field, then $I$ cuts out a projective variety $X$, whose Hilbert function is defined by
\begin{equation}
\phi(m)=\text{dim}_k~ (k[x_0,\cdots,x_n]/I)_m
\end{equation}
where $()_m$ means the $m$-th homogeneous part of the quotient ring. When $m$ is large, there exists a polynomial $p_X$ such that 
\begin{equation}
\phi(m)=p_X(m)
\end{equation}
$p_X$ is the Hilbert polynomial. However in the scheme world, from section 18.6 of Ravi Vakil's book, the Hilbert function for a projective scheme $X \hookrightarrow \mathbb{P}^n$ is defined by
\begin{equation}
\phi(m)=h^0(X,\mathcal{O}(m))
\end{equation} 
When $m$ is large, there exists a polynomial $p_X$ such that 
\begin{equation}
\phi(m)=\chi(X,\mathcal{O}(m))=p_X(m)
\end{equation}
Are the two definitions of Hilbert functions the same? I guess there are issues with reducedness, could anyone give an overall explanation?","['hilbert-polynomial', 'algebraic-geometry']"
1681588,Homotopic maps have homotopy equivalent mapping cones,"Let $f,g:X\to Y$ be maps of spaces such that $f\simeq g$. Is it true that the mapping cones $\operatorname{cone}(f)$ and $\operatorname{cone}(g)$ are homotopy equivalent? Can we write down an explicit homotopy equivalence? It ought not to be too hard to get a map $\operatorname{cone}(f)\to \operatorname{cone}(g)$ from the existence of a homotopy $H:X\times I\to Y$, but I haven't been able to find a sensible candidate, despite trying for quite a while.",['general-topology']
1681591,Does $0 < x < 0$ imply $x =0$?,"In Real Analysis class, a professor told us 4 claims: let x be a real number, then: 1) $0\leq x \leq 0$ implies $x = 0$ 2) $0 \leq x < 0$ implies $x = 0$ 3) $0 < x \leq 0$ implies $x = 0$ 4) $0 < x < 0$ implies $x = 0$ Of course, claim #1 comes from the fact that the reals are totally ordered by the $\leq$ relation, and when you think about it from the perspective of the trichotomy property, it makes sense, because claim #1 says: $0 \leq x$, and, $x \leq 0$, and then, the only number which satisfies both propositions, is $x = 0$. But I am not sure I understand the reason behind claims #2, #3 and #4. Let's analyze claim #2: It starts saying $0 \leq x$, that means that x is a number greater than or equal to $0$, but then it says $x < 0$, therefore x is less than zero. I think no number can satisfy both propositions, as it would contradict the trichotomy property, because x is less than $0$ AND greater than or equal to $0$. Same thing with claim #4, since $0 < x < 0$ means: $x > 0$ AND $x < 0$, and no real number satisfy both propositions at the same time. Therefore, saying $x = 0$ is the same as saying $x = 1$, or $2$, or $42$ (this is because the antecedent if always false). Am I missing something? My professor then told us that these were axioms, but I think that axioms should not contradict well established properties (like the trichotomy property) or, at the very least, make some sense. Are claims #2 to #4  well accepted and used ""axioms"" in real analysis?","['real-analysis', 'real-numbers', 'logic']"
1681597,"On the theorem ""$3$ is everywhere""","In this Numberphile video it is stated that ""almost all natural numbers have the digit $3$ in their decimal representation"", and a proof of this fact is proposed.
A sketch of the proof follows: Denote by $D_3$ the set of natural numbers having a digit $3$ in their decimal representation. For all $n \ge 1$, denote by
$$f(n) = | D_3 \cap \{ 1, \dots , n\} |$$
it is proved that for all $n$
$$f(10^n) = 10^n- 9^n $$
holds (and this is quite clear), hence
$$\lim_{n \to + \infty} \frac{f(10^n)}{10^n} = 1$$
and this concludes the proof in the video. Now, this proof is clear and evident to me, but I think that it is incomplete, since we should prove that $$\lim_{n \to + \infty} \frac{f(n)}{n} = 1$$ while this is not proved in the video. So my question is: how to prove this? EDIT: Obviously, if the limit exists, then it is equal to $1$: so I am asking how to show that the last limit actually exists.","['number-theory', 'combinatorics', 'recreational-mathematics', 'asymptotics']"
1681617,How to solve $ u'(t)=(u(t))^2-5u(t)+6 $ rigorously?,"I have the following homework question: Show that the Cauchy problem:
$$
u'(t)=(u(t))^2-5u(t)+6
$$
for $t\in[0,\infty[$ and with $u(0)=u_0$ has a global solution for $u_0≤3$ and a maximal, non-global solution for $u_0>3$. In the solution, they proceed as follows:
$$
\frac{du(t)}{dt}=(u(t))^2-5u(t)+6\implies \frac{du(t)}{(u(t))^2-5u(t)+6}=dt \implies \int \frac{du(t)}{(u(t))^2-5u(t)+6}=\int dt \implies \log\left(\frac{u(t)-3}{u(t)-2}\right)=t+C
$$
And they deduce the solutions for $u$ from there. I'm a bit surprised by this approach, because as I'm studying maths (and not physics) this seems a bit vague… Why can we divide by $(u(t))^2-5u(t)+6$ even though it could be $0$? How to obtain the constant solutions $u\equiv 2$ and $u\equiv 3$ because they don't seem to be covered by this approach? If somebody could provide an approach without this kind of uncertainty, i would be very grateful.","['real-analysis', 'ordinary-differential-equations', 'calculus']"
1681666,Can a conformal map be turned into an isometry?,"Let $f: (M, g) \to (M, g)$ be a conformal diffeomorphism of the riemannian manifold $(M, g)$, with $$ g(f(p))(Df(p) \cdot v_1, Df(p) \cdot v_2) = \mu^2(p) g(p)(v_1, v_2), \quad \forall p \in M, \, \forall v_1, v_2 \in T_p M, $$ for a certain function $\mu \in C^{\infty}(M)$. Is it possible to conformally change the metric of $M$ so as to $f$ become an isometry? Explicitly, does there exist a metric $\tilde{g} = \alpha g$ in $M$ such that $$\tilde{g}(f(p))(Df(p) \cdot v_1, Df(p) \cdot v_2) = \tilde{g}(p)(v_1, v_2), \quad \forall p \in M, \, \forall v_1, v_2 \in T_p M \, \text{ ?}$$ Plugging $\tilde{g} = \alpha g$ in the above equation, we obtain that $\alpha$ must satisfy $$ \alpha(p) = \mu^2(p) \alpha(f(p)), \quad \forall p \in M. $$ Can we continue?","['conformal-geometry', 'riemannian-geometry', 'differential-geometry', 'functional-equations']"
1681667,Theorem about implicit solutions of differential equations?,"I have a theorem in my book (in the context of separation of variables method) which I don't fully understand: Suppose $g=g(x)$ is continuous on $(a, b)$ and $h=h(y)$ is continuous on $(c, d)$. Let $G$ be an antiderivative of $g$ on $(a, b)$ and let $H$ be an antiderivative of $h$ on $(c, d)$. Let $x_0$ be an arbitrary point in $(a, b)$, and let $y_0$ be an arbitrary point in $(c, d)$ such that $h(y_0) \not = 0$, and define
  $$
c=H(y_0)-G(x_0) \label{1}\tag{1}
$$
  Then there's a function $y=y(x)$ defined on some open interval $(a_1, b_1)$, where $a \le a_1 \lt x_0 \lt b_1 \le b$, such that $y(x_0)=y_0$ and 
  $$
H(y)=G(x)+c \label{2}\tag{2}
$$ 
  for $a_1<x<b_1$. Therefore $y$ is a solution of the initial value problem 
  \begin{align}
h(y)y'&=g(x), \\
 y(x_0) &=y_0 \label{3}\tag{3}
\end{align}
  It is convenient to say that $\eqref{2}$ with arbitrary $c$ is an implicit solution of $h(y)y'=g(x)$. If $c$ satisfies $\eqref{1}$ we'll say that $\eqref{2}$ is an implicit solution of the initial value problem $\eqref{3}$. However, keep in mind that for some choices of $c$ there may or may not be any differentiable functions that satisfy $\eqref{2}$. I don't think I really understand what this theorem is saying. My understanding of the theorem goes like this: If you have any function $g$ differentialbe somewhere and any function $h$ differentiable somewhere , then you can transform $H$ into $G$ plus a constant simply by plugging in an appropriate $y(x)$ in to $H$, which implies that you can transform any function into any other function by choosing an appropriate input. This seems wrong, so I think my interpretation is not correct here. I don't even see why this theorem is really needed. The book has been solving separation of variables problems since before this theorem by finding $H(y)$ and $G(x)$ such that $H'(y)=h(y)$ and $G'(x)=g(x)$. This is my first DE class so please try to keep the answers at an appropriate level.","['implicit-differentiation', 'ordinary-differential-equations', 'calculus']"
1681687,${d^2y}\over {dt^2}$ rather than ${dy}\over {dt}$ - what does it change$?$,"I have the problem ""Find a positive value of $k$ for which $y = \sin(kt)$ satisfies $\frac{d^2y}{dt^2} + 9y = 0.$ Any example I can find for solving this equation either just uses $y'$ or has a typical $\frac{dy}{dt}$ So what exactly would be changed by doing this$?$","['ordinary-differential-equations', 'calculus']"
1681699,Is this histogram considered bimodal?,"Is this histogram bimodal? Because when I google what a bimodal histogram looks like, I keep getting images that say histograms like these are considered bimodal. Isn't it unimodal because the highest peak is the only mode? Am I misunderstanding something?","['descriptive-statistics', 'statistics', 'data-analysis', 'visualization']"
1681753,On a remarkable system of fourth powers using $x^4+y^4+(x+y)^4=2z^4$,"The problem is to find four integers $a,b,c,d$ such that, $$a^4+b^4+(a+b)^4=2{x_1}^4\\a^4+c^4+(a+c)^4=2{x_2}^4\\a^4+d^4+(a+d)^4=2{\color{blue}{x_3}}^4\\b^4+c^4+(b+c)^4=2{x_4}^4\\b^4+d^4+(b+d)^4=2{x_5}^4\\c^4+d^4+(c+d)^4=2{x_6}^4$$ As W. Jagy pointed out, the form $x^4+y^4+(x+y)^4 = 2z^4$ appear in the context of triangles with integer sides and one $120^\circ$ angle. PM 2Ring discovered that, remarkably, the quadruple, $$a,b,c,d = 195, 264, 325, 440$$ yields five integer $x_i$ (except $x_3$). I found that, using an elliptic curve , it can be showed there are infinitely many non-zero integer triples with $\gcd(a,b,c)=1$ such that three $x_i$ are integers. Q: However, are there infinitely many quadruples with $\gcd(a,b,c,d)=1$ such that at least five of the $x_i$ are integers?","['diophantine-equations', 'number-theory', 'elliptic-curves', 'triangles', 'quadratic-forms']"
1681772,"Elementary question about the limit $\big( 1 - \frac 1 {\sqrt n}\big )^n$, $n\to\infty$.","When calculating the limit $L=\big( 1 - \frac 1 {\sqrt n}\big)^n$, $n\to\infty$, what allows me to do the following: $$
L=\lim \left(\left(1-\frac {1}{\sqrt n}\right)^\sqrt{n} \right)^\sqrt{n}
$$ As the term inside the outer parenthesis goes to $e^{-1}$, we have $L=\lim e^{-\sqrt n}=0$ . It's like we're distributing the parenthesis somehow: $$\lim \left(\left(1-\frac {1}{\sqrt n}\right)^\sqrt{n} \right)^\sqrt{n}=\lim \left(\lim\left (1-\frac {1}{\sqrt n}\right)^\sqrt{n} \right)^\sqrt{n}=\lim e^{-\sqrt n}$$ The question is: Why can we do this? Which property are we using?","['calculus', 'limits']"
1681782,"Prove $\lim_{(x,y)\rightarrow(0,0)} \sqrt{(x − y)} \ln |x + y| = 0$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I am asked to prove that the limit of this multivariable function is equal to zero. I used the squeeze theorem to say that the limit is greater than 0 and less than x+y, by taking the limit of those we get that it is between zero and zero thus making it = to 0.",['multivariable-calculus']
1681822,How to solve the differential equation $\frac {dP}{dt} = \frac {1}{2} (P-200)$ when we are given that $p=200$ when $t=0$?,"The title pretty much describes the question. Posting this on behalf of a friend. He says he knows how to apply the integrating factors method, but can't figure out how to solve this. Here's my working: $$\frac {dP}{dt} = \frac {1}{2} (P-200)$$ $$ \int \frac {1}{P-200} dP = \int \frac {1}{2} dt $$ $$ ln(P-200) = \frac {1}{2} t + c $$ where $c$ is the constant of integration. Now, if we substitute the values of $p$ and $t$ in the equation, we would get $$c = ln(0)$$ This is where I'm stuck. This is a JEE past paper question. I would really appreciate it if someone could tell me where my friend and I are going wrong. Thanks!","['logarithms', 'integration', 'ordinary-differential-equations', 'calculus']"
1681836,How to generalize the determinant as function,"Hi I was asked to show that for any vector space $V$ over a field $\mathbb{F}$ of arbitrary dimension $n$ that if we fix some basis $\beta=\{w_1,\ldots,w_n\}$ that there is a unique function $D_\beta : V \times \cdots \times V \to \mathbb{F}$ that will satisfy the three properties, $D_\beta(v_1,\ldots,v_n)=0$ if some $v_i=v_j, i \neq j$ $D_\beta$ is linear in each factor and $D_\beta(w_1,\ldots,w_n)=1$ Moreover, I want to be able to prove some things using this. For example that Applying D to some vectors v will be the same as taking the determinant of the coordinate representation of those v, that applying D and getting something non zero to a set of vectors implys those vectors are not a basis, etc. I know that in the case of two dimensional, we can do this by using the idea that the determinant gives the area of a parallelepiped, etc. And if we define the function to be that that satisfies the above properties then it can be easily shown to be unique. But in cases when it is not dim 2, since I dont have a general formula for the n vectors , how can this be done? Is it safe to assume that such a function exists and then just show it is unique, or must it be shown that even such a function exists at all? And say we could just define the function that satisfies those properties. Then how would we show it is unique, etc? Is it possible to maybe do this problem using matrices? Ie, we can define the determinant on the nxn matrices as our inputs, and somehow use that to prove things? I have not learned about things called alternating maps.
I am still trying to do this , using advice in answers, is this how it should be approached? Define a mapping $f: L(V^{n}, \mathbb{F}) \to \mathbb{F}$ by $f \to f(e_1,...,e_n)$, or should it be as $f \to f(x_1,...x_n)$? Then $f$ is injective as if $f_{1}(e_1,...,e_n)=f_{2}(e_1,...,e_n)$ then would this imply they are equal as how a function acts on a basis completely determines it? I a just really confused. and then If I could show that it is subjective and thus an isomorphism I could say choose that unique f which is the one that gives $f(x_1,\ldots,x_n)=0$ and claim this is the function $D_\beta$ I wanted. But I am having lots of trouble putting it all together. I still dont understand. It seems like the top answer is getting many vote, but I dont understand it. This is only a first course in linear algebra by the way, so I do not know about many advanced results.
Maybe the answer could rely on sgn function and permutations. Then I could have a general formula
I dont know how in some of the answers we can just simply say suppose D is alternating etc, when this is one of the things I want to prove. That is what is also confusing me. I dont know what we can even start with. Or if we must start from scratch completely.
Looking for advice. If this cannot be done so easily, I would also be happy to see that if we assume such a function does exist, then at least prove it is unique. Without just saying the determinant is that function and the determinant is unique. Thank you","['determinant', 'linear-algebra', 'vector-spaces']"
1681851,Any countable free group is embeddable into a free group of rank $2$,"I have found this proof of the fact that any countable free group is embedable in a free group of rank $2$ (see the last page, Proposition 2). But isn't this proof incorrect? First off, it says $w=b^{-i_1}a^{\epsilon_1}b^{i_1}\dots$. Shouldnt it be $w=b^{-\epsilon_1 i_1}a^{\epsilon_1}b^{\epsilon_1  i_1}\dots$? Or are they somehow equivalent. Second, it says $a^{\epsilon_j}$ and $a^{\epsilon_{j+1}}$ are present in the literal and so $w$ cannot collapse to $1$. But that is not true...it even says that $i_j$ may equal $i_{j+1}$, and if so then we must collapse $a^{\epsilon_j}a^{\epsilon_{j+1}}$ as $a^{\epsilon_j+\epsilon_{j+1}}$, and so clearly these two literals are not present in $w$ in this case, and so how then do we know that after perhaps collapsing it some more we do not get the exponent of this to equal $0$?","['group-theory', 'free-groups']"
1681856,Irreducibility of $(1+x)^{2^s}+(1-x)^{2^s}$,"Let $n=2^s$ with $s \geq 1$. Is the polynomial
$$(1+x)^n+(1-x)^n \in \mathbb{Q}[x]$$
irreducible? I have checked this for some values of $s$ and it seems to be true. Notice that we can also write it as $2 \sum_{k \geq 0} \binom{n}{2k} x^{2k}$. I have already found an irreducible factorization with substituted cyclotomic polynomials if $n$ is odd. The even case leads to the case of $n=2^s$.","['irreducible-polynomials', 'abstract-algebra', 'ring-theory', 'polynomials']"
1681872,How to solve a triple integral with a circle not centered at origin?,"My task is this: Use cylinder coordinates to calculate:$$\iiint\limits_{A}z\sqrt{x^2 + y^2}dA, \enspace A = \left\{(x,y,z):x^2 + (y - 1)^2 \leq 1,\: 0 \leq z \leq 2\right\}.$$ My works so far is this; Switching to cylindrical coordinates we get:$$A = \left\{(r,\theta,z):0\leq r\leq 1,\: 0\leq \theta \leq 2\pi,\: 0\leq z \leq 2\right\}.$$
Now my book tells me that if you want the center in another point $(a,b,c)$, you should use the substitution: $$x = a + r\cos(\theta),\: y = b + r\sin(\theta),\: z = c + z.$$ With this in mind we change to cylindrical and add the bounderies (don't forget the jacobian).$$\int\limits_{0}^{2\pi}\int\limits_{0}^{1}\int\limits_{0}^{2}zr\sqrt{r^2\cos^2(\theta) + (1 + r\sin(\theta))^2}dz\:dr\:d\theta \:=\:2\int\limits_{0}^{2\pi}\int\limits_{0}^{1} r\sqrt{r^2\cos^2(\theta) + (1 + r\sin(\theta))^2}dr \:d\theta.$$ Now this is the part where i get stuck, if i did my calculations right teh expression under the root becomes $r^2 + 1 + 2r\sin(\theta).$ I'm not sure where to go from here so any tips and tricks would be appreciated. I would very much like to see how this is done with this substitution, but alternative solution that leads me to the right answer would also be of great value. Finally, don't show me the calculations down to the answer as i would like to do that myself. Thanks in advance!","['multivariable-calculus', 'integration']"
1681886,Rolling $n$ $k$-sided dice and discarding the lowest $m$ of them.,"In this question I will use the notation $\Bbb{E}(n,k,m)$ to refer to the expected average of rolling $n$ $k$-sided dice and discarding the lowest $m$ of them. The most trivial response happens when $m = 0$, in which case we discard no dice and we arrive at the result: $$\Bbb{E}(n,k,0) = \frac{k}{2} + \frac{1}{2}$$ When $m = 1$, I considered a sample case to give some intuition for this problem. Looking at the case of $\Bbb{E}(2, 6, 1)$, I found the following pattern. There are one $1$s, three $2$s, five $3$s, etc. The sum of these outcomes is: $$\sum_{i=1}^{6} i(2i-1)$$ In general, the expected outcome for $\Bbb{E}(2,k,1)$ is: $$\frac{\sum_{i=1}^{k} i(2i-1)}{k^2} = \frac{\sum_{i=1}^{k} 2i^2 - \sum_{i=1}^{k} i}{k^2} = \frac{\frac{2k(k+1)(2k+1)}{6} - \frac{k(k+1)}{2}}{k^2} = \frac{2}{3}k + \frac{1}{2} - \frac{1}{6k}$$ Now I want to consider $\Bbb{E}(3,k,2)$. In the previous case each value $i$ occurred $2i - 1$ number of times. Where did $2i - 1$ come from? It looks like the frequency of occurrence is the difference of consecutive squares. $$i^2 - (i-1)^2 = 2i - 1$$ This seems intuitive based on the image I provided. We can reason that in the case of $n = 3$, the frequency of occurrence will be the difference of consecutive cubes . $$i^3 - (i-1)^3 = 3i^2 - 3i + 1$$ The expected outcome of $\Bbb{E}(3,k,2)$ is messy, so I'll just write the initial expression and the simplified expression. $$\frac{\sum_{i=1}^{k} i(3i^2-3i+1)}{k^3} = \frac{3}{4}k + \frac{1}{2} - \frac{1}{4k}$$ Let's finally look at the case of $\Bbb{E}(n,k,n-1)$. Based on the previous results, I conjecture that it looks like: $$\frac{\sum_{i=1}^{k} i(i^n - (i-1)^n))}{k^n} = \frac{n}{n+1}k + \frac{1}{2} - \mathcal{O}(\frac{1}{k})$$ My two questions are this: Is my conjecture for $\Bbb{E}(n,k,n-1)$ correct, and if so, how can I prove this? What happens when $m \ne n-1$? How can I adjust my analysis to account for discarding dice such that I leave not just the maximum value?","['combinatorics', 'dice']"
1681899,A class that does not coincide with the class of all sets,"This must be trivial, so my apologies to specialists in logic. I am trying to study the Morse-Kelley theory, and this is a continuation of my previous question here . Suppose $X$ is a class, that does not coincide with the class $V$ of all sets:
$$
X\ne V.
$$
Is it possible that this automatically means that there exists a subset $Y\subseteq X$ which is not an element of $X$?",['elementary-set-theory']
1681939,Is the cycle space of a planar bicubic graph an algebraic variety?,"Let $A$ be the adjacency matrix of a planar bicubic graph on $n$ vertices, consisting of faces with $4$ and $6$ edges only. Let $X$ be a matrix of variables $x_{kl}\in \{0,1\}$. We set up a matrix $Z(X)=X\odot A$, where $\odot$ is the Hadamard product . If the $x_{kl}$ are chosen appropriately, $Z(X)$ may represent a cycle, and therefore $Z(X)$ has at least one eigenvalue of $2$. Does the set of solutions $\det(Z(X)-2I)=0$, that is related/corresponds to the cycle space, represent an (Reply to monstrous moonshine comments: not necessarily irreducible) algebraic variety ?","['graph-theory', 'algebraic-geometry']"
1681960,PDF of sum of independent exponential r.v.s of different parameter values,"If we have N independent exponential random variables of different parameter values: $x_1$ ~ exp($m_1$), $x_2$ ~ exp($m_2$), ..., $x_N$ ~ exp($m_N$) Is there a closed form (and SIMPLE) answer for the pdf of the sum of those random variables, i.e., the pdf of $\sum_{i=1}^{N} {x_i}$? If not, is there an approximation (with a reference if available) where this pdf is approximated using another known pdf? Thanks","['statistics', 'probability', 'probability-distributions']"
1681975,The value of $\sum_{k=0}^\infty k^n x^k$ [duplicate],"This question already has answers here : Summation of series $\sum_{n=1}^\infty \frac{n^a}{b^n}$? (4 answers) Closed 8 years ago . Any known conclusions for $\sum_{k=0}^\infty k^n x^k$ where $n$ is a nonnegative integer and $0<x<1$? If $n=0$, the sum is simply $\frac{1}{1-x}$. If $n=1$, the sum can be computed as shown in this post For general $n$, it seems the method by taking derivative is
extremely complicated though I believe the sum would have a
finite value because $x^k$ decreases faster than $k^n$ increases.","['summation', 'sequences-and-series']"
1681980,Good idea to find below sum,this is the question. Purpose is to find sum of $$f\left(\frac{1}{14}\right)+f\left(\frac{2}{14}\right)+f\left(\frac{3}{14}\right)+...+f\left(\frac{13}{14}\right)$$for function $$f(x)=\frac{4^x}{4^x+2}$$Is there a nice method to find $f\left(\frac{1}{14}\right)+f\left(\frac{2}{14}\right)+f\left(\frac{3}{14}\right)+...+f\left(\frac{13}{14}\right)$ ?,"['sequences-and-series', 'functions']"
1681996,Probability of completing a self-avoiding chessboard tour,"Someone asked a question about self-avoiding random walks, and it made me think of the following: Consider a piece that starts at a corner of an ordinary $8 \times 8$ chessboard.  At each turn, it moves one step, either up, down, left, or right, with equal probability, except that it must stay on the board, of course, and it must not return to a square previously visited. Clarification.  On any given step, if the piece has $n$ available moves (excluding those that would put the piece on a previously
  visited square), it chooses randomly and uniformly from those $n$
  moves.  Example: Starting from a corner, at first move, $n = 2$, and
  either move is chosen with probability $1/2$.  Next move, $n = 2$
  also, because it cannot return to the corner, and so either of the two
  other moves are chosen with probability $1/2$.  On the third move, if
  it is on the edge, $n = 2$, while if it is off the edge, $n = 3$.  And
  so on. It is possible for the piece to be deadlocked at some point prior to completing a tour of the chessboard.  For instance, if it starts at lower left, and moves up, right, right, down, left, it is now stuck. What is the probability that it completes the tour?  Is there a method that answers this question besides exhaustive enumeration?  What about $n \times n$ chessboards for $n \geq 3$?  (The problem is trivial for $n = 1$ or $2$.) Analysis for $n = 3$, as another clarification: Let the chessboard be labelled $(1, 1)$ through $(3, 3)$, and the
  piece starts at $(1, 1)$.  Without loss of generality, the piece moves
  to $(2, 1)$.  Then: With probability $1/2$, the piece moves to the center square $(2, 2)$ on its second move.  From there, only one move permits completion
  of the tour—the move to $(1, 2)$—and in that case, the tour is
  guaranteed to complete.  This move is chosen with probability $1/3$. With probability $1/2$, the piece moves to $(3, 1)$ on its second move.  It is then forced to move to $(3, 2)$. With probability $1/2$, it then moves to $(3, 3)$ on its fourth
  move and is guaranteed to complete the tour. Otherwise, also with probability $1/2$, it moves to the center
  square $(2, 2)$ on its fourth move.  From there, it moves to $(1, 2)$
  with probability $1/2$ (and is then guaranteed to complete the tour),
  or to $(2, 3)$ also with probability $1/2$ (and is then unable to
  complete the tour). Thus, the probability of completing the tour on a $3 \times 3$ board
  is $$ p_3 = \frac{1}{2} \times \frac{1}{3}
     + \frac{1}{2} \times \left( \frac{1}{2} + \frac{1}{2} \times \frac{1}{2} \right)
     = \frac{1}{6} + \frac{3}{8} = \frac{13}{24} $$ Update. An exhaustive enumeration in floating point yielded the following: For $n = 8, p_n = 0.000006751027716$","['stochastic-processes', 'chessboard', 'random-walk', 'probability', 'combinatorics']"
1682003,When does contractible space of almost complex structures taming a given symplectic form $\omega$ contain an integrable compatible one?,"Given a symplectic form $\omega$ on a compact symplectic manifold $X$, we know there is a contractible homotopy class $\mathcal{J}_{\omega}$ of almost complex structures that tame $\omega$.  A subset of these is also compatible with $\omega$, in that $\omega(\cdot, J\cdot \cdot)$ defines a Riemannian metric on the manifold.  How do know, other than things like odd Betti numbers being even, if $\omega$ has an integrable member $J_{\omega, int}$ of $\mathcal{J}_{\omega}$, so that $(X,\omega, J_{\omega, int}, \omega(\cdot, J_{\omega, int}\cdot \cdot))$ is a Kaehler manifold?","['symplectic-geometry', 'almost-complex', 'kahler-manifolds', 'general-topology', 'differential-geometry']"
1682012,Why is $(\mathbf{v} \cdot \nabla)\mathbf{v} = (\nabla \times \mathbf{v}) \times \mathbf{v} + \nabla (\frac{1}{2} \mathbf{v}^2)$?,"The Convective Derivative or Material Derivative is usually written as $\frac{D}{Dt}=\frac{\partial}{\partial t} + \mathbf{v} \cdot \nabla$.  According to MathWorld , this equation, multiplied with ${\bf{v}}$ equals:
$$
    \frac{D \mathbf{v}}{Dt} = \frac{\partial \mathbf{v}}{\partial t} + (\nabla \times \mathbf{v}) \times \mathbf{v} + \nabla (\frac{1}{2} \mathbf{v}^2)
$$ Clearly, it must hold that; $$
    (\mathbf{v} \cdot \nabla)\mathbf{v} = (\nabla \times \mathbf{v}) \times \mathbf{v} + \nabla (\frac{1}{2} \mathbf{v}^2)
$$ However, I do not spot why this is true. What is the (trivial) identity that I am missing?","['multivariable-calculus', 'fluid-dynamics']"
1682049,Picture of elliptic curve double covers Rieman sphere,"For simplicity, let us assume we live in the field $\mathbb{C}$. Then all elliptic curves are hyperelliptic, so they admit a double cover of $\mathbb{P}^1$ branched over four points, whose preimage are the four 2-torsion points in the elliptic curve. So does any one know how to visualize this double cover of a torus over a sphere topologically? Like how to construct a simplicial ""complex"" structure of the torus and sphere and the double cover maps $n$-simplex $0\leq n \leq2$ in the torus to $n$-simplex in the sphere. Does the following simplex structure gives a double cover? The British national flag is a simplicial structure of a torus, its left half (right picture) with corresponding edges identified gives a sphere, similarly for the other half. a,b,c and d are four ramification points in the torus.","['algebraic-topology', 'algebraic-curves', 'complex-geometry', 'algebraic-geometry']"
1682057,"Why might Dieudonne have been ""begging the question"" by appealing to second-order Peano Axioms?","Following a comment by Peter Smith , I've been reading A. R. D. Mathias's paper The Ignorance of Bourbaki . Parts of the paper are above my head, but I understand it well enough for my own amateurish purposes - apart from one sentence. The context is a quotation from Dieudonne's A Panorama of Pure Mathematics (1982): The first axiomatic treatments (Dedekind-Peano arithmetic, Hilbert Euclid geometry) dealt with univalent theories , i.e. theories which are entirely determined by their complete system of axioms, unlike the theory of groups. Mathias's commentary on this passage ends with the following sentence, which baffles me: In saying that Peano arithmetic is univalent, Bourbaki probably has in mind some second-order characterisation of the standard model of arithmetic,
  which is, of course, to beg the question. I can only imagine that he means that even the second-order axioms cannot stand on their own, because any such version of the Peano Axioms has two hidden prerequisites: Reference to a particular (but unmentioned) version of set theory. Reference to a ""standard model of arithmetic"", whose existence and uniqueness is silently taken for granted (thus ""begging the question"" in a simpler sense than item 1). But neither of these ideas is really clear to me, nor do I have any idea whether the author is alluding to either of them, both of them, or neither. (When one is confused, it is hard to explain the precise way in which one is confused!) If the meaning of the quoted sentence is not obvious to others, I'll consider asking the author himself about it via e-mail, but I'm marginally less nervous about posting a question here - and perhaps an answer to the question here will also interest others. The paper is about Bourbaki's blind spot in relation to developments in logic since 1929. As my own blind spots are incomparably more severe than any of Bourbaki's, it is entirely possible that I will fail to understand a perfectly good explanation of the meaning of the above sentence! But I will be well enough satisfied by an answer that reduces my current bafflement, by one sentence in an otherwise intelligible paper, to a more familiar perplexity about mathematics itself.","['philosophy', 'foundations', 'logic', 'elementary-set-theory', 'peano-axioms']"
1682066,Why does $\frac{1}{1-z}=-\sum_{n=0}^{\infty} \frac{1}{z^n}$ if $|z|>1$,Why does $$\frac{1}{1-z}=-\sum_{n=0}^{\infty} \frac{1}{z^n}$$ if $|z|>1$ I know the case for $|z|<1$ and if $|z|>1 \implies |1/z|<1$ so $$\frac{1}{1-\frac{1}{z}}=\sum_{n=0}^{\infty} \frac{1}{z^n}$$ but I'm not seeing where the negative sign is coming from?,"['complex-analysis', 'taylor-expansion', 'power-series']"
1682082,Why is $\mathcal M(\mathcal C) \subset \sigma (\mathcal C)$?,"There should be an error in my logical reasoning but I can't figure out. Every metric space is a topological space. So it can be understood that: metric space $\subset$ topological space. Every $\sigma$-algebra is a monotone class. The same spirit applies, it can be understood that: $\sigma$-algebra $\subset$ monotone class. But if we define monotone class generated by $\mathcal C$ by $\mathcal M(\mathcal C):=\bigcap\limits_{\mathcal M \text{ monotone class, } \mathcal C \subset \mathcal M} \mathcal M$ and $\sigma$-algebra generated by $\mathcal C$ by $\sigma(\mathcal C):=\bigcap\limits_{\mathcal T \sigma\text{-algebra, } \mathcal C \subset \mathcal T} \mathcal T$. Why is $\mathcal M(\mathcal C) \subset \sigma (\mathcal C)$?",['measure-theory']
1682096,differential equation y''=1/y^m,"I'm interested in knowing the asymptotics of solutions to the nonlinear ordinary differential equation
\begin{equation*}
    \begin{array}{ll}
        y''=1/y^m\tag{*}\\
        y(0)=a>0, \text{ and }y'(0)=0.
    \end{array}
\end{equation*} When $m=3$ $(*)$ has a closed form solution $y=\frac{1}{a}\sqrt{a^4+x^2}$, and $y$ is asymptotic to $\frac{1}{a}|x|$.  I have been trying to deduce for which $m$ $(*)$ has a solution which is asymptotically linear (as for $m=3$), and also the constants $c,b$ depending on $m,a$ such that $y$ is asymptotic to $c|x|+b$. So far I've begun by turning the second order ODE into a first order equation.  This follows from letting $z=\frac{dy}{dx}$ and noticing that $(*)$ is equivalent to $z \frac{dz}{dy}=y'' = 1/y^m$, and solving for $z=\frac{dy}{dx}$ to get
\begin{equation}
(y')^2=\frac{2}{1-m} y^{1-m}+C.
\end{equation} Then we can evaluate $C$ using the initial condition and get for $x\geq 0$ and $y\geq a$
\begin{equation}
y' = \left( \frac{2}{m-1} \left(\frac{1}{a^{m-1}} - \frac{1}{y^{m-1}}\right)\right)^{1/2}.
\end{equation} $y$ is a convex function because $y''=1/y^m \geq 1/a^m$, so in particular it is unbounded, so letting $y\to \infty$ in the above expression gives 
\begin{equation}
\lim_{x\to \infty} y'(x) = \left(\frac{2}{(m-1)a^{m-1}}\right)^{1/2} :=c.
\end{equation} This step required that $m>1$, so that's the first constraint on $m$.  If $y$ is asymptotic to anything, it will be of the form $y=c|x|+b$ for some constant $b$.  Since $0\leq y' \leq c$ it follows that $y$ is bounded above by $c|x|+a$, but it's not clear to me that $y$ is necessarily bounded below by a linear function $c|x|+b$ for some $b$.  I've tried get asymptotic bounds on the integral \begin{equation}
\int_a^y \left( \frac{2}{m-1} \left(\frac{1}{a^{m-1}} - \frac{1}{t^{m-1}}\right)\right)^{1/2} \,dt
\end{equation} as $y\to \infty$, but I haven't had much success.  If anyone has any suggestions for how to prove the solution $y$ is bounded below by $c|x|+b$ for some $b$ I'd be very grateful. Update: I haven't proved this yet, but I've made progress by showing that $y$ cannot be asymptotic to $cx-ln(x)$.  This would mean that there exists $\alpha>\beta>0$ such that as $x\to \infty$
\begin{equation}
cx-\alpha\, ln(x) \leq y(x) \leq cx-\beta \,ln(x).
\end{equation}
Because $f$ is convex this implies a bound on the derivative.
\begin{equation}
c-\frac{\alpha}{x} \leq y'(x) \leq c-\frac{\beta}{x}.
\end{equation}
And then you can show from $(*)$ that $y'''<0$ so $y'$ is concave and this implies a bound on the second derivative.
\begin{equation}
\frac{\alpha}{x^2} \leq y''(x) \leq \frac{\beta}{x^2}.
\end{equation} Then if $m>2$ we get the following inequality for large enough $x$: \begin{equation}
\frac{1}{y^m} \leq \frac{1}{(cx-ln(x))^m} < \frac{\alpha}{x^2} \leq y''.
\end{equation} This provides us with a contradiction so if $m>2$ then $y$ cannot be asymptotic to $cx-ln(x)$.  But this is only one example, and doesn't stop $y$ from being some other sublinear function.  One could probably prove a similar thing for $y$ asymptotic to $cx-ln(ln(x))$, but this method will never completely prove that $y$ is asymptotically linear.",['ordinary-differential-equations']
1682119,Verify my proof of $\lim_{x\to \infty} [f(x)+g(x)]= L+M$.,"I am supposed to prove that $\lim_{x\to \infty} [f(x)+g(x)]= L+M$. Starting to realize I don't really understand the formal definition of a limit, although I do understand the general concept. Anyhow, so far I have: Given $\epsilon>0$, $\exists R_f,R_g$ s.t. $|f(x)-L|<\epsilon/2$ $\forall x>R_f$ and $|g(x)-M|<\epsilon/2$  $\forall x>R_g$ Choose $R>\max\{R_f,R_g\}$. (Do we want max, min, neither?) Suppose $x>R$. Then $x>R_f$ and $x>R_g$ whenever $|f(x)-L|<\epsilon/2$ and $|g(x)-M|<\epsilon/2$. Then $\left\vert\big(f(x)+g(x)\big)-(L+M)\right\vert$ = $\left\vert\big(f(x)-L\big)+\big(g(x)-M\big)\right\vert$ $\le$ $|f(x)-L|+|g(x)-M|$ This implies $|f(x)-L|+|g(x)-M|$ < $\epsilon/2 + \epsilon/2$ < $\epsilon$ QED. Am I headed in the right direction?","['proof-verification', 'epsilon-delta', 'calculus', 'limits']"
1682120,Books and sources concerning $G$-spaces,"A $G$-space is (generally) a topological space $X$ equipped with a continuous action by a topological group $G$. I mean generally because, I've never studied before $G$-spaces and after I read a couple of papers involving them, I've been looking for the exact definition on the internet but there are different conditions like: $G$ is just a group; the action is not necessarily continuous; $X$ is Hausdorff (I think this is because the author of the document was working with Hausdorff spaces). So my request is regarding for books concerning the definition of a $G$-space in the most generally sense and, why not, the precedence of its nature.","['reference-request', 'general-topology', 'topological-groups']"
1682145,Equation demonstration,"Let $\delta f \equiv \frac{\Delta f}{f}$ show that: $$\matrix{\delta(xy) &=& \delta x + \delta y\\
\delta(x/y) &=& \delta x - \delta y\\
\delta(x+y) &=& \frac{x}{x+y}{\delta x} + \frac{y}{x+y}{\delta y}}$$ Using floating point arithmetics, I am trying to demonstrate those formulas. For the first formula, I have tried something like this: I know that $f(xy)= f(x)f(y)$ $$\Delta f \approx \sum_{i=1}^n\Delta x_i \frac{\partial f}{\partial x}$$ But I got stuck even at the first equation. Any guidance, example or help would be appreciated.","['functional-analysis', 'numerical-methods', 'floating-point', 'analysis']"
1682155,Differentiability of Fourier Series,"The following Fourier Series is continuous (by M-test)
$$ \sum_{n=1}^{\infty}{\frac{\sin{n^n x}}{n^n}}$$ Is it differentiable anywhere, and if so where? http://kryakin.org/at/hardy_1916_W.pdf covers similar things, but I didn't really understand it.","['derivatives', 'fourier-series', 'sequences-and-series']"
1682156,Nose picking probability,"A questionnaire is carried out to find the percentage of men that pick
  their nose. Since most men are embarrassed to answer this questions,
  they are told to do the following. Secretly roll a dice. If the number
  is 1 always say I do not pick my nose regardless of what the truth is,
  if the number is 2 always say I pick my nose regardless of what the
  truth is, if the number is 3, 4, 5 or 6 then tell the actual truth.
  This way, it is not possible to ever be sure which men pick their nose
  or not. If we assume that 2/3 of men answered I pick my nose, what is
  the probability that a man picks their nose? If instead we assume that
  fraction of men that pick their nose is 3/4, what is the probability
  that a man picks his nose given that he answered I do pick my nose. So far I have that (for part a). $P(t|y) = \frac{P(y|t)\cdot P(t)}{P(y)}$ where $y=$ yes they pick nose. $t = $ telling the truth... However, I can't find $P(y|t)$ Thanks.","['probability', 'discrete-mathematics']"
1682167,Bayesian Statistics: Finding Sufficient Statistic for Uniform Distribution,"The example: let $y_1,\dots,y_n \overset{\text{i.i.d.}}\sim U([0,\theta])$, where $\theta >0$ is unknown. Find a sufficient statistic for $\theta$. Solution attempt: $$g(y_1,\dots,y_n) = c\quad \text{(constant)}$$ $$P(y_i\mid\theta) = \frac{1}{\theta}\quad \text{ for } 0<y_i<\theta$$ $$P(y_1,\dots,y_n\mid\theta) = \prod_{i=1}^n P(y_i\mid\theta) = \frac{1}{\theta^n}\quad\text{ for } 0<y_1,\dots,y_n<\theta$$ Now this is where I got stuck. I have seen this post about Sufficient Statistic but I am still stuck. Could somebody help me find a sufficient statistic for this problem? (I think maybe taking the average or the maximum value of $y_i$s might work but not sure how to do the next step)","['bayesian', 'statistics']"
1682239,Curvature and topology,"I am studying Riemannian Geometry and I came across various Theorems which give conditions on the topology of a manifold given conditions on curvature, and vice-versa.
Just to mention a few of them: Gauss-Bonnet (the version I know works only for surfaces), Hadamard (about negative sectional curvature), Bonnet-Myers (lower bound on Ricci curvature implies compactness), Preissman's theorem on compact manifolds with negative sectional curvature... Unfortunately, I fail to see the ""big picture"". In particular, I am interested in the following questions: Is there a general heuristic by which I can encompass many of these assertions? In particular, to me it's hard to memorize things just as a bunch of facts. Would it be possible to make a list, as concise and at the same time as complete as possible, about the mutual interaction of curvature and topology? I would appreciate your help.","['big-list', 'general-topology', 'riemannian-geometry', 'curvature']"
1682252,Expected Waiting Time: memoryless property,"Smith is waiting for his two friends Lee and Yang to visit his house. The time until Lee arrives is Exp( $\lambda_1$ ) and the time until Yang arrives is Exp( $\lambda_2$ ). After arrival, Lee stays an amount of time that is Exp( $\mu_1$ ), whereas Yang stays an amount of time that is Exp( $\mu_2$ ). All four random variables are independent. What is the expected time of the first departure? Hint: Let X be the time of the first departure, and write X=F+Y where F is the time of the first arrival and Y is the additional amount of time until the first departure. Compute E(Y) by conditioning on who arrived first. Attempt: Denote S=Lee's arrive time; U=Lee's stay time; T=Yang's arrive time; V=Yang's stay time. $E\{first arrival\}=E[X]=E[\min(S,T)]=\frac 1{\lambda_1+\lambda_2}$ After that, everything refreshes , then the additional waiting time is again: $E[A]=E[\min(U,V)]=\frac 1{\mu_1+\mu_2}$ . Therefore, total time of expected first departure = $\frac 1{\mu_1+\mu_2}+\frac 1{\lambda_1+\lambda_2}$ . Which is wrong","['probability-theory', 'probability']"
1682261,"If $A$ is the generator of $(P_t)$, then $A+f$ is the generator of $(P_t^f)$","Let $X=(X_t)_{t\geq0}$ be a Markov process on a state space $\Gamma$ (a Hausdorff topological vector space), let $A$ be the infinitesimal generator of $X$ and let $\mathcal C(\Gamma)$ the space of continuous functions on $\Gamma$. Then for each continuous function $f \in \mathcal C(\Gamma)$ the operator $A+f$ is the infinitesimal generator of the semigroup $(P_t^f)_{t\geq0}$ defined by
\begin{equation*}
P_t^f g(x) = \mathbb E_x\left[\mathrm \exp\left\{\int_0^t f(X_s) ds\right\} g(X_t) \right], \qquad g \in \mathcal C(\Gamma), x \in \Gamma,
\end{equation*}
where $\mathbb E_x$ denotes the expectation with respect to the process $X$ starting in $x \in \Gamma$. In other words: Show \begin{equation*}
\lim_{t\rightarrow0} \frac{1}{t} \left( \mathbb E_x\left[\mathrm \exp\left\{\int_0^t f(X_s) ds\right\} g(X_t) \right] - g(x) \right)
= Ag(x)  + f(x) g(x).\tag1
\end{equation*} In a proof I'm studying I found this stated as a known fact about Markov processes, but I couldn't find any suitable reference and my knowledge about continuous Markov processes is limited. My question : Why and under which assumptions about $X$ and $\Gamma$ is (1) true? (In the case I encountered it, $\Gamma$ is actually finite.) On a further note, does the semigroup $(P_t^f)$ bear any deeper meaning? The definition first seemed quite arbitrary to me, but the fact that this statement should be generally known makes it seem like there's more to it than I realise...","['stochastic-processes', 'probability-theory', 'markov-chains', 'markov-process', 'lebesgue-integral']"
1682284,Uniqueness of the derivative operator,"Let $\mathcal{D}(\mathbb{R})$ be the set of all functions $f:\mathbb{R}\to\mathbb{R}$ which are differentiable at all points, and let $\mathcal{F}(\mathbb{R})$ be the set of all functions $f:\mathbb{R}\to\mathbb{R}$. Let's denote by $D$ the derivative operator, i.e. $$D:\mathcal{D}(\mathbb{R})\to\mathcal{F}(\mathbb{R})$$ is such that $$D(f)=f^{\prime}$$ It's clear that $\mathcal{F}(\mathbb{R})$ is a real vector space and that $\mathcal{D}(\mathbb{R})$ is a subspace of it. We also know that $D$ is linear and that it obeys the product rule $$D(f\cdot g)=f\cdot D(g)+g\cdot D(f)$$ The question is: is $D$ the only such linear transformation, i.e., the only linear transformation that obeys product rule? Of course, the $0$ operator and any real multiple of $D$, $\alpha\cdot D$ are trivial examples. But I'm interested in non-trivial examples.","['derivatives', 'real-analysis', 'linear-algebra', 'calculus']"
1682315,Determine all the roots of the equation given by $z^2(1-z^2)=16.$,"For my third year Complex variable  course, the question is Determine all the roots of the equation given by
  $$z^2(1-z^2)=16.$$ My attempt: 
Let $z^2 = x$ $x(1-x) = 16$ $x-x^2 = 16$ $x^2-x-16 = 0$ $x = \frac{1 \pm \sqrt{1 -4(16)}}{2}$ $x = \frac{1 \pm \sqrt{-63}}{2}$ $x = \frac{1 \pm i\sqrt{63}}{2}$ $z^2 = \frac{1 \pm i\sqrt{63}}{2}$ Am I correct so far? BTW the question is worth $5$ marks.","['complex-analysis', 'roots', 'complex-numbers']"
1682319,Infinitely many prime divisors of $f(a)$ [duplicate],"This question already has an answer here : Infiniteness of the set of primes such $f$ have root $\bmod p$ [duplicate] (1 answer) Closed 5 years ago . Let $f(x)\in \mathbb{Z}[x]$ be a non constant polynomial with integer coefficients. Show that as $a$ varies over the integers, the set of divisors of $f(a)$ includes infinitely many primes. To be frank, I have no idea where to start... Trivial case is when constant term of $f(x)$ is zero. In case of $f(x)=x(a_nx^n+\cdots+a_1)$ we have $p$ divides $f(p)$ for all primes $p$ ... Other than this i have no idea... Please give only hints..","['abstract-algebra', 'polynomials', 'prime-numbers']"
1682362,Extension by zero not Quasi-coherent.,"Hartshorne's Example 5.2.3 in Chapter 2 states that if $X$ is an integral scheme, and $U$ is an open subscheme with $i:U \rightarrow X$ the inclusion, then if $V$ is any open affine not contained in $U$, $i_{!}(\mathcal{O}_U) \mid_{V}$ will have no sections over $V$. But it will have non-zero stalks, and so cannot come from a module on $V$ and so is not be quasi-coherent. I get everything but for the fact that the extension by zero will have no sections over $V$. My main problem is that Hartshorne states that $i_{!}(\mathcal{O}_U)$ is the sheaf associated to the presheaf $$P(W) \mapsto \begin{cases}\mathcal{O}_U(W) &:\text{if } W \subseteq U \\
0 &: \text{otherwise}. \end{cases}$$ So a section over $V$ would be a map $s$ from $V$ to the disjoint union of the stalks of $P$ at points in $V$ subject to the compatibility condition. I am having trouble showing that this map vanishes for all $p$. Clearly $s$ must vanish on $V-U$. For $p$ in $U \cap V$, then there must be some $W \subseteq V$ and $g \in P(W)$ so that $s(q)=g_q$ for all $q \in W$. And now no ideas spring to mind. Ideally I'd like $W$ to intersect with $V - U$ and then get that this section must vanish on a neighborhood of $p$, but I can't seem to get this to work out. The problem is that $V-U$ is closed in $V$, and $W$ is open in $V$, so they need not intersect. I can get that $W$ and $U$ intersect, but that isn't really helpful. Any tips?","['sheaf-theory', 'algebraic-geometry']"
1682368,Double pendulum probability distribution,Double Pendulum has a very beautiful stochastic trajectory. Is there any way to calculate the distribution of probability of finding the end of pendulum at each point? Link to formulations .,"['stochastic-processes', 'probability', 'dynamical-systems', 'probability-distributions']"
1682370,Measurability of a stopped random variable.,"Assume that you have a stochastic process $\{X_t\}$ on the probaiblity space $(\Omega, \mathcal{F},P)$ , equip this space with a filtration( $\{\mathcal{F}_t\}$ ). Suppose you have a random variable $T: \Omega\rightarrow [0, \infty]$ , where the set $T^{-1}(-\infty,t]\in \mathcal{F}_t$ , then $T$ is called a stopping time. I have two questions regarding this subject. It is stated that it can be shown that if $X_t$ is cadlag, then it can be shown that $X_T$ is $\mathcal{F}_T$ -measurable. But what does this mean? That $X_T^{-1}(B)\in \mathcal{F}_T$ ? The problem is that $T$ is a function of $\omega$ . If I look at $X_T^{-1}(B)$ , I get those $\omega$ 's, such that $X_{T(\omega)}(\omega) \in B$ . Now, all these $\omega$ 's together is a subset of $\Omega$ , but what does it mean that they are contained in $\mathcal{F}_T$ ? I mean $\mathcal{F}_T$ depends on $\omega$ aswell? My second question is this: If we forget cadlag etc. Can it be shown that $X_T$ is just a random variable? The problem is showing measurability, that is, that $X_T^{-1}(B) \in \mathcal{F}$ ? Does this require a lot of work? Or maybe it can not be done? I've tried, but got nowhere.","['stochastic-processes', 'probability-theory']"
1682385,Whether a nondegenerate skew-symmetric matrix is congruent to the matrix $\begin{bmatrix} 0 & I_{\ell} \\ -I_{\ell} & 0 \end{bmatrix}$,"Let $A$ be a nondegenerate skew-symmetric matrix over complex field $\mathbb{C}$. Is there an invertible matrix $P$ such that 
\begin{align*}
P^{T}AP=\begin{bmatrix}
0 & I_{\ell} \\
-I_{\ell} & 0 
\end{bmatrix},
\end{align*}
where $P^{T}$ is the transpose of $P$, $I_{\ell}$ is the $\ell$ by $\ell$ identity matrix? If $A$ is an $n \times n$ nondegenerate skew-symmetric matrix over complex field $\mathbb{C}$, then $n$ is even. Since $\mathrm{det}(A)=\mathrm{det}(-A^{T})=(-1)^{n}\mathrm{det}(A)$.","['matrices', 'linear-algebra']"
1682412,"Proving a function $\mathbb{Z}_m \to \mathbb{Z}_m,\ [a] \mapsto [a^2 + 3a + 1]$ is well defined","Prove that $\operatorname{poly}\colon \mathbb{Z}_m \to \mathbb{Z}_m$ given by $\operatorname{poly}\colon [a] \mapsto [a^2 + 3a + 1]$ is well defined. This is what I have so far, working in (mod m) i.e. if $a' \equiv a$ then $a'^2+3a'+1 \equiv a^2 + 3a + 1$. ( need to prove) Since $a' \equiv a$, there exists $d$ such that $dm = a' -a$ Not sure where to go from here, any tips?","['equivalence-relations', 'polynomials', 'modular-arithmetic', 'discrete-mathematics']"
1682416,Question on Type I and Type II Errors for a Test of Binomial $p$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question A random variable $Y$ representing the number of successes can be modeled by a binomial distribution with parameters $n=250$ and $p,$ whose value is unknown. A significance test is performed, based on a sample value $Y,$ to test the hypothesis $p=0.6$ against the alternative hypothesis $p>0.6.$ The probability of Type I error is $0.05.$ a. Find the critical region for $Y$. b. Find the probability of making a Type II error in the case when in actual fact $p=0.675.$","['statistics', 'hypothesis-testing']"
1682446,Is every Closed set a Perfect set?,"From 'baby' Rudin. I've seen that a set is closed iff it contains all of its limit points. In Rudin, $(d)$  says if every limit point of E is a point of E, then $E$ is closed. He also says $(h)$: $E$ is perfect if $E$ is closed and if every point of $E$ is a limit point of $E$. But Closed $\implies$ contains all of its limit points. So, is every closed set a perfect set?","['general-topology', 'real-analysis', 'definition']"
1682462,How to solve this equation with error functions?,"I'd like to solve the following equation for $S$, in terms of $p, x,$ and $\sigma$: $$
p = \int_0^x\sqrt{\frac{2}{\pi}} \frac{e^{\frac{-(S-\mu)^2}{2\sigma^2}}}{\mathrm{erf}\left(\frac{S}{\sqrt{2}\sigma}\right)- \mathrm{erf}\left(\frac{S-1}{\sqrt{2}\sigma}\right)} d\mu
$$ Solving the integral as Mhenni suggested yields:
$$
p = \frac{\frac{\sqrt{2}}{2}\left(\mathrm{erf}\left(\frac{S-x}{\sqrt{2}\sigma}\right) - \mathrm{erf}\left(\frac{S}{\sqrt{2}\sigma}\right) \right)}{{\mathrm{erf}\left(\frac{S}{\sqrt{2}\sigma}\right)- \mathrm{erf}\left(\frac{S-1}{\sqrt{2}\sigma}\right)}}
$$ The problem now is dealing with the $S$'s inside the error functions. I know there's an inverse error function ($\mathrm{erf}^{-1}$), but I don't see how this is ultimately solvable for $S$. Is this possible? Thanks for any help!","['statistics', 'integration']"
1682469,ZF without regularity and well orderings,"Briefly, my question is this: Is the following true? $ZF - Regularity \models \varphi $ where $\varphi$ is the formula in the language of set theory defined as ""For all sets $A$ and $B$, if there exists a well-ordering on $A$ and a well ordering on $B$, then there exists a well-ordering on $A^B$"", where $A^B$ is the set of all functions from $B$ into $A$. Clearly this statement holds in ZFC, but does it hold for ZF, even without regularity attached? My main concern is with the question above, so the acceptance of an answer is going to be based solely on the above question. However, if you can point me to a reference about the following harder question, then that would be appreciated: How many axioms can we take away from ZFC and yet $\varphi$ still hold? More precisely, what is the smallest subset $\Gamma \subseteq ZFC$ such that $\Gamma \models \varphi$? Where should I look to find information regarding this ""minimalist"" type of questions? A good reference textbook on model theory is all I have in mind. Thank you very much in advance!","['first-order-logic', 'elementary-set-theory']"
1682479,Set of diameter $\le 1$ contained in set of constant width $1$,"I'm reading the paper Minimal universal covers in $E^n$ by H.G. Eggleston and they state that every set $A\subseteq{\bf R}^2$ of diameter at most $1$ (the diameter of $A$ is defined as $\sup_{x,y\in A}|x-y|$ ) is contained in a set which has width $1$ along any direction.  I can't see how the proof of this should work, though. EDIT: Maybe the proof is something along the lines of constructing a thing that has width $1$ along any rational direction, then it should has width $1$ along all directions.  For this, it should suffice to show that for any $A$ of diameter $\le 1$ you can add a translate $I$ of the unit interval (embedded into ${\bf R}^2$ ) such that $A\cup I$ has diameter $1$ .  Then you are able to add an infinite amount of intervals at different angles without the diameter exceeding $1$ .","['discrete-geometry', 'convex-geometry', 'metric-geometry', 'geometry']"
1682487,Prove a sequence is a Cauchy and thus convergent,"Suppose that $0<\alpha<1$ and that $\{ x_n\}$ is a sequence which satisfies $$|x_{n+1}-x_n| \le \alpha^n$$ $$n= 1,2,....$$ Prove that $\{x_n\}$ is a Cauchy sequence and thus converges. Give an example of a sequence $\{ y_n\}$ s.t $y_n \to \infty $ but $$|y_{n+1}-y_n| \to 0$$ as $n \to \infty$ So here's my take so far, in order to understand from the beginning the definition of Cauchy is $\{v_n\}_n$ is a Cauchy sequence if for all $\varepsilon>0$ there exists $N\in \Bbb N$ such that for all natural numbers $n,m\geq N$ : $|v_n-v_m|<\varepsilon$ . and I said if $n > m$ $$|x_n-x_m| \le |x_n-x_{n-1}|+|x_{n-1}-x_{n-2}|....+|x_{m+1}-x_m|$$ $$\le \alpha^{n-1}+\alpha^{n-2}+.............+\alpha^{m}$$ $$= 1-\frac{\alpha^{n-m}}{1-\alpha}$$ but from here I'm not quite convinced how I could process further... Could i get some help?","['real-analysis', 'cauchy-sequences', 'sequences-and-series']"
1682488,Number of integer solutions to the equation $x_1+x_2+x_3+x_4=100$,"$x_1+x_2+x_3+x_4 = 100$ with $1 \le x_1\le10$ $2\le x_2\le15$ $x_3\ge5$ $0\le x_4\le10$ Apparently this is the same as $y_1 + y_2 + y_3 + y_4 = 92$ with $y_1 \le 9$ $y_2 \le13$ $y_4 \le10$ I understand the $3$ conditions, but what has happened to $x_3$? 
I can see that it has been subtracted but what has happened to the conditions?","['inclusion-exclusion', 'combinatorics', 'discrete-mathematics']"
1682495,Is there a proof for L'Hôpital's Rule for limits approaching infinity?,"L'Hopital's Rule states that: For two differentiable functions $f$ and $g$, where $g'(x)\neq 0$, such that $$\lim_{x\to a} f(x)=0$$ $$\lim_{x\to a} g(x)=0$$ We can say that: $$\lim_{x\to a} {f(x)\over g(x)}= \lim_{x\to a} {f'(x)\over g'(x)}\\ $$ NOTE: If you already know the proof and don't want to read all this, skip all the way down to $\blacksquare_{1.1}$ PROOF 1.1: Let $f$ and $g$ be continuous functions on $[a,b]$ and differentiable on $(a,b)$. Also, assume $g'(x)\neq 0$ on $(a,b)$ and $g(b)\neq g(a).\\$ Proposition 1.1.1: There exists some point $c$ within the open interval $(a,b)$ such that: ${f'(c)\over g'(c)} = {{f(b) - f(a)}\over {g(b) - g(a)}}$ Proof 1.1.1 $\quad \triangleright$ Let $$\space h(x)= f(x)-f(a) - {{f(b) - f(a)}\over {g(b) - g(a)}}\cdot (g(x)-g (a))\\$$ By simply substituting values we can clearly see that $h(a)=h(b)=0$. 
Now because $f(a)$, $f(b)$, $g(a)$ and $g(b)$ are constants, we can therefore say that much like $f$ and $g$,  $h$ is also continuous on $[a,b]$ and differentiable on $(a,b).\\$ If we differentiate  $h$ w.r.t. $x$, we get the following: $$h'(x) = f'(x) - g'(x)\cdot {{f(b) - f(a)}\over {g(b) - g(a)}}\\$$ Using Rolle's Theorem (which I porpusely won't prove as the question is long enough as it is) we can say that there exists a $c$ in $(a,b)$ such that $h'(c)=0$ Thus we can say that $0 = f'(c) - g'(c)\cdot {{f(b) - f(a)}\over {g(b) - g(a)}} $ Hence showing us that ${f'(c)\over g'(c)} = {{f(b) - f(a)}\over {g(b) - g(a)}}$ $$\blacksquare_{1.1.1}$$ $\triangleleft \\$ Remember that $\lim_{x\to a} f(x)= \lim_{x\to a} g(x)=0$. Where $a$ is finite. We also said $g(x)\neq 0$. Therefore we'll Let $L:= \lim_{x\to a} {f'(x)\over g'(x)} \\$ We're also going to define the functions $F$ and $G$. $F(x) = f(x) \Longrightarrow x\neq a$
$F(x) = 0 \Longrightarrow x = a$ Similarly $G(x) = g(x) \Longrightarrow x\neq a$
$G(x) = 0 \Longrightarrow x = a$ Because $F$ and $G$ are defined at $x=a$, they are continuous at $a$. (Unlike $f$ and $g$) This means that for $x>a$, the functions  $F$ and $G$ are differentiable on the open interval  $(a,x)$ and continuous on the closed interval $[a,x]. \\$ Using what we showed in Proof 1.1.1 ,  we can state the following equality to be true: $${F'(c)\over G'(c)} = {{F(x) - F(a)}\over {G(x) - G(a)}}$$ Due to the fact that $F(a)=0$ and $G(a)=0$, we can thus say $${F'(c)\over G'(c)} = {{F(x)}\over {G(x)}}$$ Now since $c$ is within the interval $(a,x)$, we can say $a<c<x$. This means that $x\rightarrow {a^+} \Longrightarrow c\rightarrow {a^+}$ Therefore because $F$ and $G$ are simply the functions $f$ and $g$ respectively where $x=a$ is defined. It's correct for us to then say $$\lim_{x\to a^+} {f(x)\over g(x)} = \lim_{x\to a^+} {F(x)\over G(x)} = \lim_{c\to a^+} {F'(c)\over G'(c)} $$ Also $$\lim_{c\to a^+} {F'(c)\over G'(c)} = \lim_{c\to a^+} {f'(c)\over g'(c)}\\$$ If we notice... $$L:=\lim_{c\to a^+} {f'(c)\over g'(c)}= \lim_{x\to a^+} {f'(x)\over g'(x)}$$ Hence showing us that $$\lim_{x\to a} {f(x)\over g(x)}= \lim_{x\to a} {f'(x)\over g'(x)} $$ $$\blacksquare_{1.1}\\$$ Isn't this only true when $\lim_{x\to a} {f(x)\over g(x)}={0\over 0}$? How would you prove $\lim_{x\to a} {f(x)\over g(x)}= \lim_{x\to a} {f'(x)\over g'(x)} $ for limits such as: $\lim_{x\to a} {f(x)\over g(x)}={\pm\infty\over \pm\infty}$?","['calculus', 'limits']"
1682496,Positively invariant neightbourhood using Lyapunov function,"Given the following system of nonlinear ODEs, $$x_1'=-x_1-x_2$$ $$x_2'=2x_1-x_2^3$$ I need to use the quadratic Lyapunov function $$V(x) = x^TQx$$ where $Q$ is a positive definite matrix such that $$A^TQ+QA=-I$$ and where $A=Df(0,0)$ , to find a neighbourhood $U$ around the origin, as large as possible, such that $U$ is positively invariant and all solutions starting in $U$ tend to the origin as $t\to\infty$ . I've carefully examined the course notes and the book by Perko ( Dynamical Systems and Differential Equations ), but couldn't find a clue how to do this problem. I'd appreciate it very much if someone could please explain: How is this neighbourhood found? How is $V$ related to all this?","['real-analysis', 'dynamical-systems', 'lyapunov-functions', 'set-invariance', 'ordinary-differential-equations']"
1682502,Does the following series $\sum_{k=2}^{\infty}{\frac{k-1}{k^2\ln k}}$ diverge?,"I encountered the infinite series $S=\sum_{k=2}^{\infty}{\frac{k-1}{k^2\ln k}}$ . I have to show whether it converges or diverges. I split it into two other sums as follows: $$\sum_{k=2}^{\infty}{\frac{k-1}{k^2\ln k}}
=\sum_{k=2}^{\infty}{\frac{1}{k\ln k}}-\sum_{k=2}^{\infty}{\frac{1}{k^2 \ln k}}.$$ I used integral test and found that the first one on RHS converges. Then, since the second one on the RHS is less than the first one on the specified interval, it should also converge. But when I used a calculator and calculated the series using more and more terms each time, it actually got bigger and bigger. Is there anything wrong with my argument?","['sequences-and-series', 'convergence-divergence']"
1682510,Let z and w are two complex number.,Let z and w are two complex number. Prove that $$\left|\frac{z-w}{1-z ̅w}\right| =1 \text{ if } |z|=1 \text{ but } w \neq z$$,"['algebra-precalculus', 'complex-numbers']"
1682523,Are similar circles really a thing?,"I'm a fifteen year old who is currently studying circle geometry (if that is the appropriate term) and our teacher stated that concentric circles are similar. I thought about this, and it doesn't make sense to me. The reason is because of proportionality. For example, similar triangles are similar because they have the same angles and they have proportional sides. However, circles can not be compared for angles, so that's out (as they all have the same 360 degree angle at the center) and the only factor is their size, which is directly influenced by their radius. If the radius is the only variable involved in a triangle like this, how can a circle be NOT proportional to another circle? If a case of that existed, there would be meaning (at least from my current perspective) to the term ""similar circle."" Help and critique on my logic is requested, and an explanation as to the term ""similar circle.""","['circles', 'geometry']"
1682542,2009 Benelux Math Olympiad (BxMO) number theory problem,"The following problem is taken from the first Benelux Mathematical Olympiad which occurred in 2009. Let $n$ be a positive integer and let $k$ be an odd positive integer. Moreover, let $a$, $b$ and $c$ be integers (not necessarily positive) satisfying the equation $$a^n+kb=b^n+kc=c^n+ka.$$ Prove that $a=b=c$. I tried to analyze some congruences module $k$, $a$, $b$ and $c$, but it seems that these relations will not help sufficiently. Also, I did not found a solution for this problem. You can access all the other problems from other years at the BxMo site .","['number-theory', 'contest-math', 'congruences']"
1682598,"Prove that if X, Y, Z independent, then X + Y and Z are independent","Is it possible to prove that if $X, Y, Z$ independent, then $X + Y$ and $Z$ are independent? Is it even true? Intuitively it seems true but I am unsure.","['probability-theory', 'probability']"
1682645,"Quadratic equation with one root in $[0,1]$ and other root in $[1,\infty]$","Find the values of $a$ for which $x^2-ax+2=0$ has one root in $[0,1]$ and other root in $[1,\infty]$. The twoo rots are $$\frac{a\pm\sqrt{a^2-8}}{2}$$ The smaller root should be less than $1$. So $$a-\sqrt{a^2-8}\le 2$$
$$a-2\le\sqrt{a^2-8}$$
$$a^2+4-4a\le a^2-8$$
$$a\ge 3$$ How will I find the upper bound for $a$? And what is the general approach to solve such problems where the roots are constrained between two values?","['algebra-precalculus', 'quadratics']"
1682648,Problem of determinant when $A^{-1}+B^{-1}=(A+B)^{-1}$,"I have two $4\times 4$ real matrices $A$ and $B$, and it is known that $A^{-1}+B^{-1}=(A+B)^{-1}$ ($A$, $B$ and $A+B$ are invertible). How can I prove that $\det (A)=\det (B)$?","['matrices', 'linear-algebra', 'determinant']"
1682651,Situations in which interchanging the order of integration fail.,"Suppose that our underlying space is $\Bbb R^2$ and $f:\Bbb R^2\to \Bbb R$, for concreteness. It is not hard to artificially construct such a function $f$ such that 
$$
\int_Y\int_X f(x,y)dxdy\ne \int_X\int_Y f(x,y)dydx
$$
,i.e. the interchanging of the order of integration in not applicable. Note that Fubini's Theorem implies that any $f$ with the above property is not absolutely integrable on $\Bbb R^2$. Although we, the mathematicians, are quite cautious about this matter, it seems to me that many physicists don't really pay much attention to the problem at all. I was trying to convinced my physicist friend that this is a serious matter but failed. The function I gave as an example seem too ad hoc for him. I want a more real-life example. Is there any $f:\Bbb R^2\to \Bbb R$ that arises naturally from a physical situation such that the interchanging the order of integration fail? I want the function $f$ to be in a classical sense i.e. not a distribution or any generalized function.","['real-analysis', 'physics', 'functions', 'integration', 'soft-question']"
1682689,What does this set theory term mean: $x\in \bigcup_{k=1}^{\infty}\bigcap_{n=k}^{\infty}A_{n}.$?,"I have a question for an assignment that involves this term. $$x\in \bigcup_{k=1}^{\infty}\bigcap_{n=k}^{\infty}A_{n}.$$ I have a faint idea of what it means, but perhaps someone can tell me if I am wrong. first im considering the intersection sign by itself, assuming that n=k=1 at first, meaning a family of sets A1...A(inf) all joined by intersection such that its only true (ie. not the null set) if there is some common element in all the sets. then i do the same thing but starting with n=k=2 so that you have an identical family of sets with the exception of it not including A1. again X must be in all the sets. then repeat so you have an infinite family of families of sets, all one set smaller than the last. and take the union of all of them. I'm having trouble though seeing what the point of the union is, It makes sense if the union and intersection signs were switched because then they both impose a condition, but having them this way, the union doesn't seem to do anything, or rule anything out? if there is something obvious that I'm missing Id greatly appreciate your help.","['limsup-and-liminf', 'elementary-set-theory']"
1682727,A question in the proof of $C(X)$ is not a dual space of a Banach space.,"Let $X$ be a non-singleton compact connected space.I want to show that $C_{\mathbb{R}}(X)$ is not the  dual space of a Banach space,$\mathbb{R}$ is real number field. I already know that, extreme points of $Ball(C_{\mathbb{R}}(X))$ are $\{f\equiv 1, f\equiv -1\}$. Then by Krein-Milman theorem, $Ball(C_{\mathbb{R}}(X))$ = weak*-closure of convex conbination set of $\{f\equiv 1, f\equiv -1\}$ = weak* closure of $\{f\equiv a : a\in[-1,1]\}$. How can I conclude that $X$ is a singleton from above? Any help would be appreciated!","['functional-analysis', 'normed-spaces', 'banach-spaces']"
1682734,Book Recommendation for Linear Algebra using analysis.,"Today in my Analysis class my teacher proved that (real)symmetric bilinear forms (in an inner-product space) are orthogonally diagonalizable using compactness, differentiablity of innerproducts and other concepts of analysis and then he proceeded to prove that the k'th largest eigenvalue can be derived by 
$$\min_{W\subset V,\dim W=k} \max_{x\in W , \|x\|=1} \langle Ax,x\rangle$$
where the bilinear form is $B(x,y)=\langle Ax,y\rangle$. Can anyone suggest me some books which have these kind of ""analysis"" flavoured linear algebra?","['reference-request', 'real-analysis', 'book-recommendation', 'linear-algebra']"
1682760,"Change of variable in $\varphi(s) = t$, effect in $\mathbb{d} W_t$","If I have the stochastic integral $$
\int_0^T f(t)\,\mathbb{d} W_t
$$ and perform the change of variables $t = \varphi(s)$ , how will $\mathbb{d} W_t$ transform (where the integration is taken in the Itô's sense and $W_t$ is a Wiener process)? PS: for deterministic integrals $$
\int_{\varphi(a)}^{\varphi(b)} f(t)\,\mathbb{d}t = \int_a^b f(\varphi(s))\varphi'(s)\, \mathbb{d}t
$$","['integration', 'stochastic-integrals', 'stochastic-analysis', 'brownian-motion', 'stochastic-calculus']"
1682789,Norm operators bounded below implies almost uniform lower bound,"I have a hard time proving (or disproving) the following statement about continuous linear operators: $$(\exists c>0:\forall j:\|T_j\|\geq c)\Rightarrow(\exists\delta>0:\forall n:\exists x\in X:\forall 1\leq j\leq n:|T_jx|\geq\delta)$$ where $T_j$ is a sequence of continuous linear functionals on a Banach space $X$, so $T_j:X\to\mathbb{R}$. Does anybody have any thoughts on this? Thank you in advance!","['banach-spaces', 'normed-spaces', 'functional-analysis', 'continuity', 'sequences-and-series']"
1682800,Maximal dimension of a vector space of square matrices in which every nonzero matrix is invertible,"I'm interested in the maximal dimension of a subspace $V\leq\mathbb R^{n\times n}$ in which every nonzero matrix is invertible. Odd $n$: For odd $n$ the maximum is $1$: if $A$ and $B$ would be linearly independent, then $\det(xA+B)$ is an odd polynomial of degree $\leq n$ with leading coefficient $\det A\neq0$, so it has a real root $x$; hence $0\neq xA+B$ is not invertible. Even $n$: For $n$ even the maximum can be no larger than $n$: if $A_1,\ldots,A_{n+1}$ would be linearly independent, then the first row of every nontrivial linear combination must be nonzero, meaning that the first rows of $A_1,\ldots,A_{n+1}$ are linearly independent, contradicting $\dim\mathbb R^n=n$. For $n=2$ the maximum is $2$, as $\begin{vmatrix}a&-b\\b&a\end{vmatrix}=a^2+b^2\neq0$ for $a,b$ not both zero. For $n=4$ the maximum is $4$, as
$$\begin{vmatrix}-a&b&c&d\\ b&a&-d&c\\ c&d&a&-b\\ d&-c&b&a\end{vmatrix}=-(a^2+b^2+c^2+d^2)^2.$$ Questions: For $n$ even, is the maximal dimension always $n$? Do similar such matrices exist with determinant $\pm\,(a_1^2+\cdots+a_n^2)^{n/2}$? This is an attempt to generalize problem $3$ of the PUMA 2016 .","['matrices', 'determinant', 'contest-math', 'linear-algebra', 'vector-spaces']"
1682811,Identify recursive languages?,"Consider the following languages. $L_1 = \{<M> \mid M \text{ takes at least 2016 steps on some input}\}$, $L_2 = \{<M> \mid  M \text{ takes at least 2016 steps on all inputs}\}$ and $L_3 = \{<M> \mid M \text{ accepts } ε\}$, where for each Turing machine $M, <M>$ denotes a specific encoding of $M$.
Which one of the following is TRUE? $L_1$ is recursive and $L_2, L_3$ are not recursive $L_2$ is recursive
    and $L_1, L_3$ are not recursive $L_1, L_2$ are recursive and $L_3$ is not
        recursive $L_1, L_2, L_3$ are recursive My attempt : Official answer is given option $(3)$. $L_3$  is not recursive as it asks if $L(M)$ contains $\varepsilon$ which is a non-trivial property of r.e. languages and hence undecidable as per Rice's theorem. Can you explain in formal way, please? How we prove that $L_1, L_2$ are recursive languages?","['formal-grammar', 'formal-languages', 'automata', 'discrete-mathematics']"
1682828,"Spectral radius of ""almost"" regular graph ?!","The answer to this question could be trivial. The Graph Let $G$ be graph formed of two $d$-regular connected components. That is, $G= H_1\cup H_2$, where $H_1$, and $H_2$ are $d$-regular and disjoint. Let $x\in H_1$ and $y\in H_2$. Let $G'= G+xy$, then $G'$ is connected graph. My question is: Question: What is the largest positive  eigenvalue of $G'$  ? Or $\lambda_1 (G') = ??$ Ideas: -It is obvious that $\lambda_1 (G) = d$ with multiplicity 2 ( since it is formed of 2 $d$-regular connected components). But I have no idea how to estimate $\lambda_1$ when a single  edge is added between $H_1$, and $H_2$. -The interlacing theorem could help in commutating  bound for the maximal eigenvalue. Any idea will be useful!","['combinatorics', 'graph-theory', 'algebraic-graph-theory', 'spectral-graph-theory']"
1682838,Is limit of function -1/0 ok?,"A quick question, i'm determining the limit of this function: $$\lim_{x→1}\frac{x^2 - 2x}{x^2 -2x +1}$$ When I divide numerator and denominator by $x^2$ and fill in $1$, I get $-1/0$. This is an illegal form right? Or does it indicate it is going to $∞$ or $-∞$?","['calculus', 'limits']"
1682853,"Integral solutions $(a,b,c)$ for $a^\pi + b^\pi = c^\pi$","We know that $a^n + b^n = c^n$ does not have a solution if $n > 2$ and $a,b,c,n \in \mathbb{N}$, but what if $n \in \mathbb{R}$? Do we have any statement for that? I was thinking about this but could not find any immediate counter examples. Specifically, can $a^\pi + b^\pi = c^\pi$ for $a,b,c \in \mathbb{N}$? I found this . It has a existential proof that $\exists \ n \in \mathbb{R}$ for any $(a,b,c)$ The question remains open for $n = \pi$. This question is just for fun to see if we can some up with some simple proof :)","['number-theory', 'diophantine-equations']"
1682883,Differentiation Calculus: $\tan^{-1} \text{Problem}$,"Well, Today at Math Revision exam I have to answer for $\frac{dy}{dx}$ Question:$$ y= \arctan\frac{{2x}}{{1+x^2}}$$ I got the answer $$ \frac{2}{1+(\frac{2x}{1+x})^2}\frac{cos(2\tan^{-1}x)}{1+x^2}$$ i think this not correct. I have to know the right solution with steps.","['derivatives', 'real-analysis', 'calculus']"
1682917,In a random selection of three pairs among $6$ people what is the probability that each girl will be matched with her boyfriend?,"There are $6$ people, $3$ boys and $3$ girls. Each boy is in a relationship with one girl. Three pairs are randomly drawn. What is the probability that these three pairs will be the actual couples? My reasoning was $$
P =  \frac{3}{\binom{6}{2}} \times \frac{2}{\binom{4}{2}} \times \frac{1}{\binom{2}{2}}$$ But this does not give me the answer a professor has given me. I'd appreciate some hints or new ways of approaching the problem.","['combinatorics', 'probability']"
1682928,Something wrong with this do carmo exercise (1.3.3)?,"I think I have found an unreported errata to this problem. Here is my attempt to solve the problem. Differential Geometry of Curves and Surfaces - Chapter 1 Section 3 Exercise 3 And here is the errata I can found online. In particular, I believe the errata should include $ \alpha'(t) = (0, 2a) $ when $ t \to \pm \infty $, not $ \alpha'(t) = (2a, 0) $ Can anyone confirm my finding? What should I do to get this included in the errata?",['differential-geometry']
1682962,Equivalent definitions of a root system.,"For studying root systems many authors start from a vector space $V$ over $\mathbb{R}$ with a positive definite scalar product $(\cdot,\cdot)$, in which a reflection $\sigma_\alpha$ is a linear application that fixes the hyperplane $H_\alpha$ and send $\alpha$ to its opposite. In formulas
\begin{gather}
\sigma_\alpha(\beta)=\beta- <\beta,\alpha>\alpha
\end{gather}
where $<\beta,\alpha>=$$2(\alpha,\beta)\over (\alpha,\alpha) $. Then a root system is defined as a subset $R$ of $V$ such that $\langle R \rangle =V$, $R$ finite and $0 \notin R$ $\mathbb{R}\{ \alpha\} \cap R=\{\pm \alpha \}$ if $\alpha \in R$ for every $\alpha, \beta \in R$, $R$ is invariant under $\sigma_\alpha$ and $<\beta,\alpha>$ is an integer. This is a quite strong structure, but all the properties envolved arise naturally in the form of the weights $\mu \in H^*$, where $H$ is the Cartan subalgebra of a complex Lie algebra $L$ (we are considering the adjoint representation). Then we can consider on $H^*$ the dual of the Killing form, that is again symmetric and positive definite. In this environment, we can restrict to $V_\mathbb{Q}$, the $\mathbb{Q}$-span of the non zero weights in $H^*$, (indeed one can prove that the dual of the killing form take rational values, see the chapter ""Integrality Properties"" of ""Introduction of Lie Algebras and Representation theory"", Humphreys) then consider $V=V_\mathbb{Q} \otimes_\mathbb{Q} \mathbb{R}$ and check that these are a root system in $V$. For proving the characterization of semisimple lie algebras, this can be a start point. Nevethless, some authors need to weak slightly the definition of a root system, starting from a vector space $V$ on $\mathbb{R}$ (without scalar product) and define a root system $R$ as a subset of $V$ such that $R$ is finite, generates $V$ and $0 \notin R$ $\alpha \in R \implies$$ \alpha \over 2$$ \notin R$ for each $\alpha, \beta \in R$ there is $\alpha^\vee \in V^*$ with $\alpha^\vee (\alpha)=2$ and $\alpha^\vee(\beta) \in \mathbb{Z}$ and $s_{\alpha^\vee,\alpha}(R) \subseteq R$ Where for $\lambda \in V^*, w \in V$ $s_{\lambda,v}(w)=w-\lambda(w)v$. Then, considerd $G$ the finite subgroup of $GL(V)$ that preserves $R$ and $(\cdot,\cdot)$ a generic positive definite scalar product, we define
\begin{gather}
(\alpha,\beta)'=\sum_{g\in G}(g\alpha,g\beta)
\end{gather}
After realizing that $(\cdot,\cdot)'$ is a positive definite scalar product by which $G$ acts by isometries, we can prove that $\alpha^\vee$ is uniquely determined by $\alpha$ $\alpha^\vee(\lambda)=2\frac{(\alpha,\lambda)'}{(\alpha,\alpha)'}$ Here the identifications: $\alpha^\vee$ is the element $h_\alpha$ such that $x_\alpha,y_\alpha,[x_\alpha,y_\alpha]=h_\alpha$ are the usual generators of a copy of $sl_2$ and $\alpha^\vee(\lambda)=\lambda(h_\alpha)$ after $H^{**}=H$. My first question: what is the relation between $(\cdot,\cdot)'$ and the dual of the Killing form? My guess is that they differ from a scalar, but I cant prove it directly. My second question: the second approach has the property that make easier to prove that the non zero weights of a Lie algebra via the adjoint representation are a root system, indeed we can avoid the use of the ""orthogonality relations"", but we need more work to return to the stronger situation of the first definition. So what is the real advantage of the second way?","['abstract-algebra', 'modules', 'root-systems', 'lie-algebras']"
1682964,Confidence intervals without the knowing the distribution of the data,"I am given the data set containing the values 12.09, 11.18, 9.97, 10.5,0 9.92, 9.97, 11.84, 10.93, 10.70. I am asked to construct a 90% confidence interval for the mean but I am not told the distribution. I am told to use the software package R in order to justify any assumptions I make. Even once I have plotted this data in R though I am not seeing a clear distribution and thus cannot construct the confidence interval. Can anyone help? I have also found the sample mean to be 10.78889 and the standard deviation to be 0.8029702.","['statistics', 'confidence-interval']"
1682969,A Nonhomogenous Poisson Process Question - Harry's Stressful Life,"Due to stress of coping with business, Harry begins to experience migraine headaches of random severities. Headaches are instantaneous and has zero duration. The times when headaches occur follow a Poisson process of rate λ. Headache severities are independent of times of occurrences and are i.i.d. random variables with common exponential distribution given by:
$$
\mathbb{P}[H \le x] = 1 − e^{-x}, \quad x > 0
$$
Harry decides to commit himself to the hospital if a headache of severity greater than $c > 0$ occurs in the time period $[0, t]$. Compute the probability that Harry does not commit himself in $[0, t]$. I think that probability of not committing is $\mathbb{P}[H(t)=0]$ $\mathbb{P}[H(t)=0]$ should be equal to $e^{-λt \mathbb{P}[H_s]}$ where $H_s$ is the occurrence probability of a severe headache. But how can I calculate $\mathbb{P}[H_s]$? Should I find $\mathbb{P}[H_s>t] = e^{-tm}$ ??","['stochastic-processes', 'poisson-process', 'statistics', 'exponential-distribution', 'poisson-distribution']"
1682972,"What is the relationship, if any, between maximal domains of $f$ and $f'(x)$?","(Edited question after some Calculus review) Let $D$ be the maximal domain of function $f$. Let $D^d$ be the largest subset of $D$ where $f'(x)$ is defined. Maximal domain of $f(x) = \ln(x)$ is $D_1 = (0, \infty)$ Its derivative $f'(x) = \frac{1}{x}$ is defined on $D_1$ Maximal domain of $f(x) = \sqrt{x}$ is $D_2 = [0, \infty)$ While $f' = \frac{1}{2\sqrt{x}}$ is not defined on $D_2$, it is defined on $D_2^d := (0, \infty)$ $D_2$ and $D_2^d$ differ only by one value. Maximal domain of $f(x) = |x|$ is $D_3 = \mathbb R$ While $f' = \frac{|x|}{x}$ is not defined on $D_3$, it is defined on $D_3^d := \mathbb R \setminus \{0\}$ $D_3$ and $D_3^d$ differ only by one value. Maximal domain of $f(x) =  \lfloor x \rfloor$ is $D_4 = \mathbb R$ While $f'$ is not defined on $D_4$, it is defined on $D_4^d := \mathbb R \setminus \mathbb Z$ $D_4$ and $D_4^d$ differ only by countably many values. It seems that $D$ and $D^d$ differ by only a set of Lebesgue measure zero. However, the Weierstrass function disproves that conjecture. So what kind of conditions of $f$ are sufficient or necessary to have such a relationship between $D$ and $D^d$?","['lebesgue-measure', 'functions', 'functional-analysis', 'domain-theory', 'measure-theory']"
1682977,How do you integrate $(x+2)\ln(x-3)$?,"I got $$\left(\frac {x^2}{2} +2x\right)\ln(x-3)-\left(\frac {x^2}{4}-\frac {7x}{2} -\frac {21}{2}\right)\ln(2x-6)$$ as my answer... Not sure If I got it right. Please correct me, thank you!","['indefinite-integrals', 'integration', 'calculus']"
1682983,"If a measure only assumes values 0 or 1, is it a Dirac's delta?","Let $\mu$ be a probability measure on a metric space $M$ (with the Borel $\sigma$-algebra). If $\mu(A)\in \{0,1\}$ for all measurable set $A\subset M$, then: Is it true that $\mu$ is a Dirac measure? I think the answer should be negative, but I do not know of a counterexample. There is an answer here for the general case where we don't know anything about the topology (metrizable in our case). There you can see also that the result holds for all Polish spaces.","['general-topology', 'measure-theory']"
1682985,Calculate the sum $x+y+z$,"If positive real numbers $x,y,z$ satisfying the conditions
$$x^2+xy+y^2=25, y^2+yz+z^2=49, z^2+zx+x^2=64$$ 
then calculate the sum $x+y+z.$ My attempt: By subtracting equalities are obtained $$(z-x)(x+y+z)=24, (x-y)(x+y+z)=15.$$ And here I stopped.    )-:",['algebra-precalculus']
1683035,Angle of rotation based on direction cosines,"I have a question which is bothering me for days! Suppose that we have a fixed frame $XYZ$ and a moving frame $xyz$ in 3D. The moving frame is orthonormal and is defined based on the fixed one using 9 direction cosines. For instance, the unit vector $x$ is $(l_1,m_1,n_1)$ where $l_1$, $m_1$ and $n_1$ are the cosines of the angles between $x$ and $X$, $Y$ and $Z$ respectively. Similarly, we have $y=(l_2,m_2,n_2)$ and $z=(l_3,m_3,n_3)$ which are also unit vectors. My question is: At first the moving frame $xyz$ coincides $XYZ$. Then it rotates arbitrary to form a frame with known direction cosines. How can I calculate the angle of rotation of the moving frame around its $z$ axis based on the 9 direction cosines. In other words, how much the $x$-axis rotates around the $z$-axis? Thanks a lot for saving me!","['coordinate-systems', 'rotations', 'geometry']"
1683038,If $a+b+c = 0$ then the quadratic equation $3ax^{2}+2bx +c=0$ has atleast one root in _________?,"If $a+b+c = 0$ then the quadratic equation $3ax^{2}+2bx +c=0$ has atleast one root in _________? Rolle's theorem states that if $f(a) = f(b)$ then there exists  a $p \in [a,b]$ such that : $f'(p) = \frac{f(b)-f(a)}{b-a} = 0$ So we have $f'(p) = 6ap + 2b \implies$ $p = \frac{-b}{3a}$ How to proceed next ?","['algebra-precalculus', 'quadratics', 'polynomials', 'derivatives']"
