question_id,title,body,tags
2206379,5x5 board Bingo Question,"There is a game which I play, it is like bingo. It starts with a 5x5. Lets say horizontally it goes ABCDE from left to right and vertically it goes 12345 from bottom to top.
I have 2 random generators which will generate a letter and a number giving me a box to cross. So for example A2.
Suppose I the generators don't generate a box that has been generated before, what is the probability that after the Nth amount of random generations, I get a bingo horizontally or vertically. I would like to also know the probability of the Nth generation to be a bingo.","['probability-limit-theorems', 'probability-theory', 'computational-mathematics', 'probability']"
2206434,"Non-abelian groups that are ""closest"" to being abelian [duplicate]","This question already has an answer here : Prove: if $a,b\in G$ commute with probability $>5/8$, then $G$ is abelian (1 answer) Closed 7 years ago . Given a finite, non-abelian group $G$ of order $n$, how close can $G$ be to being abelian? More formally, define the following density measure: $$d(G) = \frac{\#\{(a, b) \mid a, b \in G, ab = ba\}}{n^2}$$ The question is, then, are there known upper bounds for $d(G)$? I suppose lower bounds might also be interesting. A naive lower bound for $d(G)$ would be $\frac{2n-1}{n^2}$, since the commutator is trivial whenever $a = b$ or $a = e_G$ -- is this tight (in whatever sense you see fit, e.g. asymptotically)?",['abstract-algebra']
2206466,Construct series,"Are there two non-negative, monotone sequences ${\{a_n\}}$ and ${\{b_n\}}$, s.t. $\sum{a_n}$ and $\sum{b_n}$ diverge, but $\sum{min{(a_n,b_n)}}$ converges? I guess that the convergence speed must be carefully controlled, but I couldn't find such sequences. Thanks in advance for any help.",['real-analysis']
2206491,Infinite sum of $cot^{-1}$ series.,"If $$\sum_{n=1}^\infty cot^{-1}\left(2 + \frac{n(n+1)}{2}\right)=tan^{-1}a$$, then 'a' is equal to
(A) 1
(B) 2
(C) 3
(D) 4 My aproach in such question is to break orignal function into difference of two functions using identies $cot^{-1}(\frac{xy+1}{x-y}) = cot^{-1}x - cot^{-1}y$ In this $n^{2} + n + 4$ cannot be changed to xy+1 Is there any other way of doing it ?","['trigonometry', 'sequences-and-series']"
2206500,Why have the Mathematicians defined the boundedness in Functional Analysis so much different from that in Calculus?,"Let us consider $R$ with the norm $||x||=|x| $ for the whole discussion. Now the identity mapping $I$ from $R$ to $R$ is unbounded in Calculus but in Functional Analysis treating the same identity mapping $I$ as a linear transformation from the vector space $R$ to the vector space $R$, it becomes bounded. Why have the Mathematicians defined the boundedness in Functional Analysis so much different from that in Calculus?","['functional-analysis', 'calculus', 'functions']"
2206548,Existence of a continuous surjective map from the surface of a sphere to a circle?,"Does there exist a continuous surjective mapping  $f : S^2 \to S^1$ ? Intuitively, I think not, because every time in my head I try to demonstrate such a mapping, I always end up with a ""tearing"" in $S^2$. But I'm not sure how to prove that there doesn't exist such a mapping. The first approach I thought of follows something like this outline: Pick a path $\gamma$ in $S^1$ that is not homotopic to the constant path. Artificially ""lift it"" to a path in $S^2$ (in some similar manner to how you life paths to covering spaces) Show that the lifted path is homotopic to the constant path, and hence the initial path is homotopic to the constant path. Contradiction! It doesn't seem like this way is fruitful however, since it isn't apparent how to ""artificially lift the path"" since $f$ isn't given as a covering map. I feel like this comes down to a more basic fact however, and so I attempted to make the problem easier by generalising: If $X$ is simply connected and $f : X \to Y$ is a continuous surjective map, then $Y$ is simply connected because that seemed to be at the core of my thinking. But I couldn't prove this either, and I couldn't find mention of a theorem like this in my textbook.","['algebraic-topology', 'general-topology', 'continuity']"
2206550,General Solution of Euler's Equation,"Find the general solution to the Euler's Equation: $$
x^2\frac{d^2y}{dx^2}+2x\frac{dy}{dx}-6y=0
$$
using change of independent variable given by transformation:
$$
x = e^z
$$ Any help would be greatly appreciated.Thanks :)",['ordinary-differential-equations']
2206575,Union of connected sets which have pairwisely nonempty intersections,"If connected subsets have non-empty intersections pairwisely, how can I show that their union is connected? Formally, let $E_\alpha$ be connected for every $\alpha \in I$ , and suppose that $E_\alpha \cap E_{\beta} \neq \emptyset$ for every distinct pair of indices $\alpha$ and $\beta$ in $I$ . How can I show that $\displaystyle\bigcup_{\alpha \in I}E_\alpha$ is connected? There are similar questions to this theorem, they say the whole intersection $\displaystyle\bigcap_{\alpha \in I}E_\alpha$ is non-empty or say the same assumption as above but starts the proof with taking an element from $\displaystyle\bigcap_{\alpha \in I}E_\alpha$ when we have $E_\alpha \cap E_{\beta} \neq \emptyset$ .  I think that we can not pick an element from $\displaystyle\bigcap_{\alpha \in I}E_\alpha$ . Consider for example that $E_1 = \{1,2 \}, $ E_2 = {1,3 }, $E_3 = \{2,3 \} $ where $X = \{1,2,3\}$ with the coarsest topology.","['general-topology', 'connectedness']"
2206605,Find $\displaystyle\lim_{x\to\infty}x - \sqrt{x+1}\sqrt{x+2}$ using squeeze theorem,"Find $$\lim_{x\to\infty}x - \sqrt{x+1}\sqrt{x+2}$$ using squeeze theorem Tried using binomial expansion, but have no idea on how to continue.",['limits']
2206642,"Find $q$ such that $[q[qn]]+1=[q^2n]$ for $n=1,2,\dotsc$","Find $q>0$ such that 
  $$[q[qn]]+1=[q^2n],\qquad n=1,2,\dotsc$$ 
  where $[x]$ is the integer-valued function. In fact, if $q=\frac{\sqrt{5}+1}2$, then $q^2-q=1$, so we can verify $$[q[qn]]+1=[q^2n],\qquad n=1,2,\dotsc$$
and I believe $q=\frac{\sqrt{5}+1}2$ is the only solution of the equation. Now I have only proved $1.6125\leq q\leq 1.6190$, it still has a long way to go!","['golden-ratio', 'algebra-precalculus', 'number-theory', 'elementary-number-theory', 'ceiling-and-floor-functions']"
2206822,Finding a square root of a power series in terms of another power series,"I want to find a square root of a power series in the following way: Let $$A(x)=a_0+a_1x+\cdots=\sum_{j\ge 0}a_jx^j\qquad \mathrm{and}\qquad B(x)=b_0+b_1x+\ldots=\sum_{i\ge 0}b_ix^i$$ such that $a_0>0$ and $b_0>0$ and $A=B^2$ . How can I express the coefficients $a_j$ in terms of $b_i$ ? I used the Cauchy product to get $a_j=\sum_{k=0}^jb_kb_{j-k}$ , but have no idea how to continue. Can someone help me out with finding a recursive relation between $a_j$ and $b_i$ with initial value for the sequence $(b_i)$ ?","['power-series', 'sequences-and-series', 'analysis']"
2206825,"If $A=\{f,l,o,w\}$ and $B=\{f,l,o,o,w\}$, then are A and B equal sets?","If $A=\{f,l,o,w\}$ and $B=\{f,l,o,o,w\}$, are set $A$ and set $B$ equal? I saw this example in my book. But what I had learnt is that two sets are said to be equal if they have same elements. Here, set $A$ and $B$ have same elements but their cardinal numbers are not same. In this case are $A$ and $B$ called equal?",['elementary-set-theory']
2206839,Prove that the sum of the medians of a triangle is greater than the semiperimeter,Prove that the sum of the medians of a triangle is greater than the semiperimeter I tried working backwards. That is I presumed that $$AF + BE + DC > \frac{AB + BC + AC}{2}$$ is true. Then I came up with $AD + BF + EC < AF + BE + DC$ at the end.,"['geometric-inequalities', 'triangles', 'geometry']"
2206841,Solving the diffusion equation in a ball with Neumann BC,"I was hoping to ask for finding $\lambda_n$ in the following problem, I need to jog my memory as to how to solve these using fourier series. I am only interested in $\lambda_n$ as these terms will represent my decay rates. Suppose we have a ball, radius $r_0$, with the diffusion equation
$$\frac{\partial c(r,t)}{\partial t} = 
\frac{D}{r^2} 
\frac{\partial }{\partial r}
\left(
r^2
\frac{\partial }{\partial r}
c(r,t)
\right),
\quad r\in[0,r_0],t\geq 0$$ with neumann boundary conditions
$$
D\frac{\partial c}{\partial r} = -pc
,\quad \text{on}\ \ r=r_0
$$ with initial conditions
$$c(r,0)=
\begin{cases}
c_0 & r\in[0,R] \\
0 & r\in(R,r_0]
\end{cases}$$ where $D,p>0$. If we let
$$c = R(r)T(t)$$ then we find 
$$
\frac{1}{D}\frac{T'}{T} = 
\frac{\partial^2 R}{\partial r^2}
+
\frac{2}{r}\frac{\partial^2 R}{\partial r^2} = -\lambda^2
$$ Therefore
$T(t)=\exp(-D \lambda^2 t)$. I'm interested in describing the half-life of this system by examining the decay rates of the series solution to it.","['ordinary-differential-equations', 'partial-differential-equations']"
2206847,Artin-Wedderburn decomposition of $\mathbb{F}_2[S_5]/J$,"If $p$ is a prime that divides the order of a finite group $G$ and $k$ is the field with $p$ elements then we can form the group algebra $kG$ and quotient out by the Jacobson radical $J$ to obtain a semisimple artinian algebra $kG/J$ which is therefore a direct sum of matrix rings of the form $M_{n_i}(D_i)$ where $D_i$ is a finite extension of $k$. I'm interested in calculating the numbers $n_i$ and $d_i = \dim_k(D_i)$ for particular cases. The problem I'm trying to solve now is to compute those numbers in the case of $k=\mathbb{F}_2$ and $G=S_5$. Trying to do as in Artin-Wedderburn decomposition of a particular group ring (where the case $\mathbb{F}_5 S_3$ is considered) does not help very much because $|S_5|=120$ is quite big. Also, I thought those numbers would appear in the Atlas page of $S_5$ (representations in characteristic 2) http://brauer.maths.qmul.ac.uk/Atlas/v3/alt/A5/ but I'm quite sure they don't, or at least not in the way I would expect. Do you have any hint? To summarize, my question is: let $J$ be the Jacobson radical of $\mathbb{F}_2 S_5$, how do you compute the Artin-Wedderburn decomposition of the artinian semisimple algebra $\mathbb{F}_2 S_5/J$? That is, how do you compute the numbers that I called $n_i$ and $d_i$ above? Any good reference about this would be of great help. Thank you!","['representation-theory', 'ring-theory', 'group-theory']"
2206873,"Prove that for $n\geq3$, $n^3\geq3n+5$","Prove that for $n\geq3$,$$n^3\geq3n+5$$ My try: Let $f(x)=x^3-3x-5$. Clearly $x=1$ and $x=-1$ are critical points where $x=1$ is the local minima so the function $f(x)$ is an increasing function for $x>1$ and the result follows. Please check and if possible provide another way to solve like induction. Thank you.",['discrete-mathematics']
2206880,I need help finding the solution about $z=0$ of the following differential equation.,"The differential equation is $$\frac{d^2g}{dz^2}-\frac{l(l+1)}{z(z-1)}g=0.$$ After using the Frobenius method I have gotten to indicial roots $r=1,0$. The recursion formula for $r=0$ is $$n(n+1)c_{n+1} = [n(n-1)-l(l+1)]c_n.$$ And for $r = 1$ the recursion is $$(n+1)(n+2)c_{n+1}=[k(k+1)-l(l+1)]c_n.$$ Now my problem is that I cannot obtain the first independent solution whose first few terms are $$u_0=z, u_1=z(1-z), u_2=z(z-1)(2z-1), \dots,$$ where $$g_1(z)=\sum_{n=0}^{\infty}c_n^l u_l(z).$$ I will be very grateful to anyone that can explain how to obtain the above solution.","['ordinary-differential-equations', 'mathematical-physics', 'general-relativity']"
2206906,Unique map of Universal covering space,"Any help on the following question will be great. Question : Given a map $f: (X,x) \rightarrow (Y,y)$ of connected and locally simply connected spaces, show that it induces a unique map of universal covering spaces $\hat{f}: (\hat{X},\hat{x}) \rightarrow (\hat{Y},\hat{y})$ such that the diagram below commutes. $$\begin{equation*}\begin{array}{ccl}
(\hat{X},\hat{x})&\stackrel{\hat{f}}{\longrightarrow}& (\hat{Y},\hat{y})\\
\!\!\!\!\!\!\!\!{\scriptstyle p}\downarrow& &\downarrow{\scriptstyle q}\\
\!\!\!\!(X,x) &\stackrel{f}{\longrightarrow}& (Y,y)
\end{array}\qquad\qquad\end{equation*}$$ Thanks.","['algebraic-topology', 'general-topology', 'covering-spaces', 'homotopy-theory']"
2206936,Position $f(x) = x^3$ by inputting $2$ variables,"Before we start, I'm not sure if this question belongs here. The question is all about mathematics, however the math behind this question came from a problem I had in web design. But since it's about math I am going to put it here. I'm currently diving into parallax effects on the web. Parallax scrolling is a technique in computer graphics and web design, where background images move by the camera slower than foreground images, creating an illusion of depth in a 2D scene and adding to the immersion.
  ~ wikipedia In addition to just the foreground and background moving at a different pace moving elements in a different direction also has a parallax ish effect. ~ me Basically I want to create a little container (could be an image, or any block level element) and move it across the screen horizontally as the user scrolls. This can be done with JavaScript but how is not really the point of this question. The effect should be scalable across all viewports. Meaning that the hight and the width of the element that the element is moving across should not matter. When the user has scrolled half of the height of the screen the ""moving element"" should be in the exact center. Since the user will have scrolled half of the screen the element will be vertically already. We're only worried about horizontally right now. I've thought about this question for a while and came up with a pretty good idea of how. Take the hight and the width of the element you want the ""moving element"" to move across. For example a screen that is $1000\text{px}$ tall and $600\text{px}$ wide. Divide the width by the height. For example ($600\text{px} / 1000\text{px} = 3/5 = 0.6$) Take the amount of pixels the user scrolled and multiply it by the number we just created. For example ($500\text{px} \times 0.6 = 300\text{px}$). As you can see this is the exact center. Move the element across the screen by the amount of pixels just calculated. This calculation works fine even for every screen size, however it's linear. Meaning that the element will move at the same speed across the screen all the time. Let me show you what I mean. Let' draw out a screen size.... (Let's say $1000 \times 500$) Calculate two points for this graph -> screen factor: $(500 / 1000) = 0.5$ The first point is going to be easy. Let's say we scrolled exactly 
  $0\text{px}$ -> $(0.5 \times 0) = 0$ The ""Moving element"" will not have moved at all. For the second element we'll take the center. Just for convenience. The vertical center is at $500\text{px}$ -> $(0.5 \times 500) = 250\text{px}$ (Exactly the horizontal center) Put the results in a graph and draw a line through the points. (Consider the orange line) In the graph above you can see that whenever the user scrolls down the ""moving element"" will follow the line (the values on the horizontal-axis). My question I really hope I described all that well enough to understand. Now on to my question... What I want to create is a moving element that would go faster on the edge of the screen and slow down a bit in the middle. If we were to draw that out in the same way we just did (Creating a graph where we can take the amount of pixels scrolled and see where the element should be positioned horizontally) it would look like the blue line in the previous image . As you can see in this graph the ""moving element"" wouldn't be moving all that much in the middle of the graph. (I over did it a bit in my drawing but you get the general idea.) What I need is a mathematical function that takes three parameters (Screen height, width and the amount of pixels scrolled) and returns the horizontal position of the ""moving element"". My idea: My idea was to position the element in the dead center of the page and then to move it left and right (translations using css and JavaScript) based on how far there has been scrolled. The graph would look something like this: The (Hand drawn) graph above would be true for a screen that's $1000\times600\text{px}$ since the ""moving element"" translates $-300\text{px}$ when no scrolling has been done and $300\text{px}$ when $100\%$ has been scrolled. However I have no idea on how to create a mathematical function that would be true for every screen size. Edit from one of my comments down below: To be clear: the user controls the position of the object by scrolling down the page. I want to take the amount of pixels that the user has scrolled down and input that number into a function. This function will then calculate the exact position at which the object should be relative to it's original position (0;0). So if the user has scrolled 0px the position should be (-0.5 * Pagewidth; 0). If the user has scrolled halfway it should be (0;0) and if it's at the end it should be (0.5 * Pagewidth; 0) The function should ""slow down"" towards the center of the page. I really hope I explained myself well enough and I really hope somebody can help me out here. Keep in mind that I am no expert in maths at all.","['functions', 'graphing-functions']"
2206957,Digital roots of even numbers whose abundance is of the specific form,Let $n$ be an even number . Let $k$ denotes the abundance of $n$ and $dr(n)$ denotes a digital root of $n$ . I have noticed the following pattern : $\bullet$ If $k$ is of the form $18t+16$ then $dr(n)=1$ in almost all cases . $\bullet$ If $k$ is of the form $18t+10$ then $dr(n)=4$ in almost all cases . $\bullet$ If $k$ is of the form $18t+4$ then $dr(n)=7$ in almost all cases . where $t \in \mathbb{Z}$ . Here you can try it for yourself . How to explain this phenomenon ?,"['number-theory', 'pattern-recognition', 'elementary-number-theory']"
2206991,Grothendieck lemma for weakly compact sets,"Does anyone have a reference for the following result? I need to know the proof but I can't find it anywhere. Lemma (Grothendieck, for weakly compact sets). Let $X$ be a Banach space, and $K \subset X$. If $K$ is weakly closed and bounded, and for all $\varepsilon >0$ there exists a weakly compact set $K_\varepsilon$ such that $K \subset K_\varepsilon + \varepsilon B_X$, then $K$ is weakly compact.","['functional-analysis', 'banach-spaces', 'analysis']"
2207066,Showing that $\sum_{k=0}^{n}(-1)^k{n\choose k}{1\over k+1}\sum_{j=0}^{k}{H_{j+1}\over j+1}={1\over (n+1)^3}$,"Consider this double sums $(1)$ $$\sum_{k=0}^{n}(-1)^k{n\choose k}{1\over k+1}\sum_{j=0}^{k}{H_{j+1}\over j+1}={1\over (n+1)^3}\tag1$$
  Where $H_n$ is the n-th harmonic An attempt: Rewrite $(1)$ as $$\sum_{k=0}^{n}(-1)^k{n\choose k}{1\over k+1}\left(H_1+{H_2\over 2}+{H_3\over 3}+\cdots+{H_{k+1}\over k+1}\right)\tag2$$ Recall $$\sum_{k=0}^{n}(-1)^k{n\choose k}{1\over k+1}={1\over n+1}\tag3$$ Not sure how to continue","['harmonic-numbers', 'sequences-and-series']"
2207078,Can a matrix be invertible but not diagonalizable? [duplicate],"This question already has an answer here : If matrix A is invertible, is it diagonalizable as well? (1 answer) Closed 7 years ago . While reading a chapter on diagonalizable matrices, I found myself wondering: Can a matrix $A \in \mathbb R^{n \times n}$ be invertible but not diagonalizable? My quick Google search did not return a clear answer.","['eigenvalues-eigenvectors', 'diagonalization', 'linear-algebra']"
2207082,Factorizing an 8×8 unitary matrix into tensor product of three 2×2 unitaries,"I am an undergraduate physics student currently in the final stages of a BSc project. I am trying to decompose an $8 \times 8$ unitary matrix into a tensor product of three $2 \times 2$ unitaries. This is in the context of quantum information where we need to rotate measurement operators for a 3 qubit system but are limited to performing local (ie $2 \times 2$) unitary rotations. Concretely, the problem we have is as follows: We have an 'unphysical' unitary rotation $U_{8 \times 8}^{unphysical}$ that needs to be performed. It is unphysical as it is not a product of single qubit ($2 \times 2$) unitary matrices. So we have tried to numerically (in python) generate $$U_{8 \times 8}^{physical} = U_{2 \times 2}^{(1)} \otimes U_{2 \times 2}^{(2)} \otimes U_{2 \times 2}^{(3)}$$ 
where we guess the $4 \times 3$ (since $k = 1,2,3$) parameters $\theta^{(k)}, \phi^{(k)}_1, \phi^{(k)}_2, \phi^{(k)}$ in the single qubit unitaries $$U_{2 \times 2}^{(k)} = e^{i \phi^{(k)}} \left( \begin{array}{cc}
		e^{i \phi^{(k)}_1} \cos(\theta^{(k)})& e^{i \phi^{(k)}_2} \sin(\theta^{(k)})\\
		-e^{-i \phi^{(k)}_2}\sin(\theta^{(k)}) & e^{-i \phi^{(k)}_1} \cos(\theta^{(k)})\\
	\end{array} \right)$$
I have a suspicion that it may not be possible to obtain a factorization that produces $U_{8 \times 8}^{physical} = U_{8 \times 8}^{unphysical}$ but I would like to get as close as possible. Our current cost function is simply the Frobenius norm of of $U_{8 \times 8}^{physical} - U_{8 \times 8}^{unphysical}$ where every time the solver guesses the parameters, the cost function builds the corresponding single qubit unitaries, tensors (kronecker products) them together as in the construction above and calculates this 'distance'. The black box solver (scipy.optimize.minimize) stops after a suspiciously short number of iterations (we have used it throughout the project and it has been robust) and finishes with the cost function being about 2 or 3, which is clearly not good enough. We can either come up with a better cost function and be able to decompose $U_{8 \times 8}^{unphysical}$ numerically, or there may be a mathematical theorem/construct that can help us do this analytically. I am happy to provide more detail on the context or clarify the problem we have. Thank you, Alex","['matrices', 'kronecker-product', 'numerical-linear-algebra', 'quantum-information']"
2207098,Is the function $\sin x$ a transformation of $\cos x$?,"In my study of functions I've briefly learnt about transformation of functions wherein we can reflect, stretch , translate or compress a base function (informally) by adding out multiplying a constant to the variable or function itself. Suddenly the graph of trigonometric functions clicked my mind ( ... which I haven't studied in detail ) and I wondered whether function $\sin x$ is a transformation of funcion $\cos x$. Algebraically $ \ sin^2 x + cos^2 x = 1 $ which shows a relation between the two functions and may be they could be transformed to each other. But here as I don't have a thorough understanding of transformation I don't know whether squaring a function also yields a transformation. Though I am a bit unsure about it algebraically, geometrically I am firm about my question. This is so because if the cosine function is shifted towards right,  it can certainly be transformed to sine function what I feel intuitively. I may be wrong but these two aspects ( geometric and algebraic) are pestering me to ask  this question . Please help and thanks.","['algebra-precalculus', 'trigonometry', 'transformation', 'functions']"
2207111,Eigendecomposition - Optimization of quadratic expressions,"I am reading Deep Learning (page 44) : The eigendecomposition of a real symmetric matrix can also be used to optimize quadratic expressions of the form $f(\mathbf x) = \mathbf {x^T  Ax}$ subject to $\|\mathbf x\|_2 = 1$ . Whenever $\mathbf x$ is equal to an eigenvector of $\mathbf A$ , $f$ takes on the value of the corresponding eigenvalue. The maximum value of $f$ within the constraint region is the maximum eigenvalue and its minimum value within the constraint region is the minimum eigenvalue. The first part is clear to me, I can derive it with: $$\mathbf {Ax} = \mathbf {\lambda x}$$ $$f(\mathbf x) = \mathbf {x^T  Ax}$$ $$\Rightarrow f(\mathbf x) = \mathbf {x^T  \lambda x}$$ $$\Rightarrow f(\mathbf x) = \lambda$$ since $\|x\|_2 = 1$ . However, I cannot understand why the maximum and the minimum value of $f$ correspond to the relative eigenvalues.","['eigenvalues-eigenvectors', 'functions']"
2207122,The Unit Sphere $S^{n-1}$ is Path-Connected,"I am trying to understand Munkres' proof that $S^{n-1}$ is path-connected. Below is a snippet from the book. It's clear to me that $g$ is surjective; and I concur with him with him when he says it is rather easy to show the continuous image of a path-coonected space is path-connected. What is giving me trouble is showing that $g$ is continuous. I tried showing that $g : \mathbb{R}^n_0 \rightarrow \mathbb{R}^n_0$ is continuous, which would entail that the restriction to $f(\mathbb{R}^n_0) = S^{n-1}$ is continuous. This didn't seem to lead anywhere though. If I am not mistaken, a basis element of $\mathbb{R}^n_0$ is $\prod (a_i,b_i)$, where each interval $(a_i,b_i)$ does not contain $0$. The preimage under $f$ is $$f^{-1}\left(\prod (a_i,b_i)\right) = \left\{x \in \mathbb{R}^n_0 ~|~ \frac{x}{||x||} \in \prod (a_i, b_i) \right\} = \left\{x \in \mathbb{R}^n_0 ~|~ x \in \prod (||x||a_i,||x||b_i) \right\}$$ which I can't really make sense of; I can't determine exactly what this set looks like. EDIT: Following the unanamious suggestion, I will attempt to prove that the norm is a continuous function. Note that the norm on $\mathbb{R}^n$ induces the standard euclidean metric on $\mathbb{R}^n$, which in turn induces the standard topology. In a previous exercise, it was shown that the metric is continuous with respect to the topology it induces. With a little thought, we can see that $||x|| = d(x,0)$ and is nothing more than the restriction of a continuous function (i.e., the metric) to $\mathbb{R}^n \times \{0\}^n$, which means the norm is continuous. Having the zero vector, which is a crucial to the above proof, this proof generalizes to all normed vector spaces. I'll have to think about the case in which the normed space isn't a vector space, but I think this gets the job done. Now, in the previous chapter of munkres, I am told that if $f,g : X \rightarrow \mathbb{R}$ are continuous functions and $g(x) \neq 0$ for any $x \in X$, then $f/g : X \rightarrow \mathbb{R}$ is continuous. Clearly, then, the function defined in the picture is continuous.",['general-topology']
2207183,Calculating the limit of $\frac{\cos(x)-1}{x}$ as $x \rightarrow 0$,"Show that the $\lim \limits_{x \to 0}\frac{\cos(x)-1}{x}=0$ My attempt $$\begin{align}
\lim \limits_{x \to 0}\frac{\cos(x)-1}{x}*\frac{\cos(x)+1}{\cos(x)+1}&=\lim \limits_{x \to 0}\frac{1-\cos^2(x)}{x(1+\cos(x))}\\\\
&=\lim \limits_{x \to 0}\frac{\sin^2(x)}{x(1+\cos(x))}\\\\
&=\lim \limits_{x \to 0}\frac{\sin(x)}{x}*\frac{\sin(x)}{1+\cos(x)}\\\\
&=1*\frac{0}{2}\\\\
&=0
\end{align}$$ $$QED$$ Since $\lim \limits_{x \to 0}\frac{\sin(x)}{x}=1$ by the sandwich theorem. i know this is correct however i would like it if anyone could show me the natural argument of using power series instead. Recall the definition of the cosine function by the power series: $$\sum_{n=0}^\infty\frac{(-1)^n}{(2n)!}x^{2n}, \forall x \in \mathbb R$$ Also can anyone show me how to show that the radius of convergence of the cosine power series is $$\infty$$","['real-analysis', 'limits-without-lhopital', 'limits']"
2207198,Lesson in an induction problem,"I'm trying to do this problem but I'm having a basic misunderstanding that just needs some clarification. Consider the proposition that $P(n) = n^2 + 5n + 1$ is even. Prove $P(k) \to P(k+1)$ $\forall k \in \mathbb N$. For which values is this actually true? What is the moral here? This problem is meant to tell you a moral problem of induction. I'm aware that $P(n)$ is odd for all integers (I think), so I can't think of where to start on this. This is in regard to induction specifically even if the problem doesn't implicitly state it.","['induction', 'discrete-mathematics']"
2207260,Asymptotics of a function,I have to find the asymptotics of the following integral $$\int^1_0 \frac{\sin(x)}{x(1+x)^n} dx$$ as $n\to\infty$. I know I am supposed to use the lebesgue dominated convergence theorem and create a sequence $b_n$ and aim for $\lim_{n\to\infty} a_n/b_n =1$ but I can't seem to get my head round it. Any help I would be very much grateful for,"['lebesgue-integral', 'asymptotics', 'measure-theory', 'lebesgue-measure']"
2207278,Cylinder Gaussian Curvature,"The question is as follows.  Imagine we have two closed geodesics on a surface, where these two geodesics bound a cylinder together and the geodesics are diffeomorphic to circles.  Can the cylinder have $K>0$ everywhere or $K<0$ everywhere?  Here $K$ is Gaussian Curvature. What's confusing me about this question is that a cylinder has Gaussian Curvature of $K=0$ everywhere, so wouldn't the answer to both questions be no?  But then I don't get the point of the question with the geodesics. Thank you in advance","['differential-geometry', 'geodesic']"
2207285,"Second homotopy group of real Grassmannians $\textrm{Gr}(n,m)$, special case $n=m=2$ not clear.","I have been considering real Grassmanians
$$\textrm{Gr}(n,m)=O(n+m)/O(n)\times O(m)$$
appearing in certain condensed matter physics context (space of real flat-band Hamiltonians $Q(k)$ with $n$ occupied and $m$ unoccupied bands, the reality comes from commutation with antiunitary time-reversal squaring to $1$), and I am interested in their second homotopy group. If I understand correctly, this can be derived from the exact sequence ( https://en.wikipedia.org/wiki/Fibration#Long_exact_sequence_of_homotopy_groups ) 
$$\pi_2[O(n+m)]\to\pi_2[\textrm{Gr}(n,m)]\to \pi_1[O(n)\times O(m)]\to\pi_1[O(n+m)].$$ The result depends on the choice of $n$ and $m$. If I didn't do any mistake, one can order all the results into a neat table:
$$\begin{array}{c||c|c|c}
        & n=1        & n=2                        & n \geq 3  \\ \hline
m=1     & 1          & \mathbb{Z}                 & 1         \\
m=2     & \mathbb{Z} & \mathbb{Z}\times\mathbb{Z} & \mathbb{Z}\\
m\geq 3 & 1          & \mathbb{Z}                 & \mathbb{Z}_2
 \end{array}$$
where $1$ is the trivial one-element group. I think I do understand most of these entries. The $\color{blue}{\textrm{blue}}$ ones in here
$$\begin{array}{c||c|c|c}
        & n=1        & n=2                        & n \geq 3  \\ \hline
m=1     & 1          & \color{blue}{\mathbb{Z}}                & 1         \\
m=2     & \color{blue}{\mathbb{Z}} & \mathbb{Z}\times\mathbb{Z} & \mathbb{Z}\\
m\geq 3 & 1          & \mathbb{Z}                 & \mathbb{Z}_2
 \end{array}$$
come from the fact that
$$\textrm{Gr}(1,2)\cong \textrm{Gr}(2,1) \cong \mathbb{R}P^2$$
is the space of lines through $0$ in 3D, and topologically it looks like a half-sphere. One can obviously wrap $S^2$ around it an integer number of times, thus the second homotopy group are integers. For the $\color{LimeGreen}{\textrm{green}}$ entries here
$$\begin{array}{c||c|c|c}
        & n=1        & n=2                        & n \geq 3  \\ \hline
m=1     & 1          & \mathbb{Z}                 & 1         \\
m=2     & \mathbb{Z} & \color{LimeGreen}{\mathbb{Z}}\times\mathbb{Z} & \color{LimeGreen}{\mathbb{Z}}\\
m\geq 3 & 1          & \color{LimeGreen}{\mathbb{Z}}                 & \color{LimeGreen}{\mathbb{Z}_2}
 \end{array}$$
I also know an explanation, although only in physics terms: On the $S^2$ one defines a ""north pole"" $\mathrm{N}$ and a ""south pole"" $\textrm{S}$, and chooses a set of paths $\gamma(\theta)$ ($\theta \in[0,\pi]$) such that $\gamma(\theta)$ depends continuously on $\theta$, $\gamma(0) = \textrm{N}$ and $\gamma(\pi) = \textrm{S}$ are just single points, and for $0<\theta<\pi: \textrm{N},\textrm{S}\notin \gamma(\theta)$. Analogy with parallels on a globe might be helpful. Obviously $\cup_\theta \gamma(\theta)=S^2$. The physics interpretation has to do with a Wilson loop operator (I think this corresponds to parallel transport in mathematics -- not 100% sure though) on a closed path $\gamma$
$$W(\gamma) = \overline{\prod_{k\in\gamma}} P_k = \overline{\exp}\left[-\int_\gamma \mathcal{A}(k)\right]$$
where $P_k = \sum_{a=\textrm{occ}} u_{k,a}^{\phantom{\top}} u_{k,a}^\top$ is the projector onto the occupied (negative eigenvalue) or alternatively unoccupied (positive eigenvalue) eigenvectors of the Hamilotnian $Q(k)$ at $k$, the horizontal bar ""$\,\overline{\phantom{\exp}}\,$"" indicates path ordering, $\mathcal{A}$ is the (Wilczek-Zee-)Berry connection, and the points $k$ lie along $\gamma$ (a proper limit with number of points $N\to\infty$ is assumed). Now the interpretation of the $\color{LimeGreen}{\textrm{green}}$ homotopy groups: It can be shown that $W(\gamma)$ is a gauge invariant $O(n)$ or $O(m)$ matrix (depending on whether one focuses on positive or negative eigenvalues). We choose the smaller one, i.e. $O(\min\{n,m\})$. We now look at the continuous function $W(\gamma(\theta))\equiv W(\theta)$. Because of the conditions listed above, $W(0) = W(\pi)$ is just the unit matrix $1\in SO(\min\{n,m\})$, and we trace some closed path in $SO(\min\{n,m\})$ for intermediate values of $\theta$. Thus we constructed a topological invariant related to $\pi_1 [SO(\min\{n,m\})]$ which is well-understood to be $\mathbb{Z}$ for $SO(2)$, and $\mathbb{Z}_2$ for all larger arguments. This gives the $\color{LimeGreen}{\textrm{green}}$ entries. But there is one more non-trivial entry, the $\color{red}{\textrm{red}}$ one
$$\begin{array}{c||c|c|c}
        & n=1        & n=2                        & n \geq 3  \\ \hline
m=1     & 1          & \mathbb{Z}                 & 1         \\
m=2     & \mathbb{Z} & \mathbb{Z}\color{red}{\times\mathbb{Z}} & \mathbb{Z}\\
m\geq 3 & 1          & \mathbb{Z}                 & \mathbb{Z}_2
 \end{array}$$
that I have no clue about. I was wondering if anyone has some insight into or even suitable visualization of $\textrm{Gr}(2,2)$ to help me get over this last one. Does any one of you have an idea what's the meaning of that $\mathbb{Z}\times\mathbb{Z}$? Or perhaps some accessible reference into the topology of real Grassmannians? I would appreciate any hint.","['homotopy-theory', 'exact-sequence', 'grassmannian', 'algebraic-topology', 'general-topology']"
2207295,Differences between symmetries and isometries,"throughout the following question, whenever I'm wrong please correct me! Recently I came across the notions of symmetry and isometry. Though, there is something obscure (definitely in my head) concerning the distinction of those two things. For instance, let's say that $\Sigma \subset \mathbb{R}^{n},$ is an arbitrary geometric object (I'm looking for the general point view of the notion of symmetries and isometries, hence am going to assume that at the moment no further structure has been assumed on this object). Then the group of symmetries of $\Sigma$, is 
$$Symm(\Sigma)= \{ \sigma \in Isom(\mathbb{R}^n) \thinspace | \thinspace \sigma(\Sigma) = \Sigma \},$$
whilst isometries of $\mathbb{R}^n$ are defined as usually, being distance-preserving maps $\sigma : \mathbb{R}^n \rightarrow \mathbb{R}^n,$ which turn out to be continuous , one -to- one and onto (hence homeomorphisms of the underlying topological structure induced by the metric). Now, let's say that a geometric figure $\Sigma \subset \mathbb{R}^{n},$ is given on its own again and someone asks, "" What's the group of isomotries and symmetries of $\Sigma$? "".  Then there are two possibilities: $\Sigma$, inherits the metric by $\mathbb{R}^n,$ as a subspace. $\Sigma$, becomes a metric space with some other metric and we examine it by forgetting any ambient space. Now, for the first one, I think the symmetries and isometries coincide, right (if no, a counterexample suffices)? It's just another name for the same map $\sigma: \Sigma \rightarrow \Sigma$ which preserves distances. But what happens for the second case? For instance, for the last question I have in my mind the distinctive case $\Sigma= \mathbb{S}^{n-1},$ the $(n-1)$-dimensional sphere which naturally inherits a metric by $\mathbb{R}^n$, but it can be equipped with another metric too, hence the isometries change in those two cases since different type of measurment is being applied each time. What happens if moreover we assume some differentiable structure and someone asks for the isomotries/symmetries of Riemmanian manifolds instead of subsets of $\mathbb{R}^n$? What about the symmetries and isometries in that case? Thank you, I hope haven't done something wrong, because is my first post! If yes, do let me know.","['isometry', 'abstract-algebra', 'symmetry', 'group-theory']"
2207296,Can I apply L'Hôpital to $\lim_{x \to \infty} \frac{x+\ln x}{x-\ln x}$?,"Can I apply L'Hôpital to this limit: 
$$\lim_{x \to \infty} \frac{x+\ln x}{x-\ln x}?$$
I am not sure if I can because I learnt that I use L'Hôpital only if we have $\frac{0}{0}$ or $\frac{\infty}{\infty}$ and here $x-\ln x$ is $\infty-\infty$ and x tends to infinity.","['calculus', 'limits']"
2207315,Is my proof complete/valid?,"I can't help but think that my proof is missing something. I'm pretty sure I understand how to prove it, I just don't know if I expressed it correctly in words. As I am teaching myself, I would appreciate a second opinion. Is it fine as it is, or is there something I should improve? Prove that for arbitrarily chosen sets A, B, and C that
$$ (A-C) - (B - C) \subseteq A - B$$ 
My proof: Let $x \in (A-C) - (B-C)$. That means that $x \in A$ and $x \not\in (B-C)$ which implies $x \not\in B$. Therefore, we can conclude that $(A-C)-(B-C) \subseteq (A-B)$.","['elementary-set-theory', 'proof-verification']"
2207328,"Neutral element in $\hom_C(A, B)$","Let $C$ be an abelian category. Assuming that $\hom_C(A,B)$ has an abelian group structure, prove that the zero map $0_{AB}:A\to B$ is the neutral element of this group. I know that the group operation can be defined as $f+g:=\nabla_B\circ(f\oplus g)\circ \Delta_A$ for every $f, g\in\hom_C(A, B)$, where $\oplus$ is the biproduct, $\Delta_X:X\to X\oplus X$ is the diagonal map and $\nabla_X:X\oplus X\to X$ is the codiagonal map. Defining $\varphi:=(f\oplus 0_{AB})\circ \Delta_A$, I've shown that $\pi_1\circ\varphi=f$ and that $\pi_2\circ\varphi=0_{AB}$ (where $\pi_1$, $\pi_2$ are the natural projections), which intuitively means that $f+0_{AB}=\nabla_B\circ \varphi=f$, but I don't know how to formalize this. How do I show this formaly?","['category-theory', 'abstract-algebra', 'abelian-categories', 'commutative-algebra']"
2207329,Is there any algebraic structure in the set of all continuous pdf's in $\mathbb{R}^n$ under some operation?,"It is possible to define an algebraic structure to the set of all continuous probability densities under certain operation ? Example: Let $D = \{f(x_1,...,x_n) \mbox{ | } \int f(x_1,...,x_n)dx_1,...,dx_n = 1 \}$ This set posses any algebraic structure under certain operations such as multiplication, division, composition or any other special operation ? I'm just curious about this.","['abstract-algebra', 'probability-theory', 'statistics', 'probability-distributions']"
2207330,What is the probability that two random vectors in $\mathbb{Z}_n^k$ have dot product $z$?,"In particular, I'm considering the set $S(n, k, z) = \{(x, y) \in (\mathbb{Z}_n^k)^2 \mid \langle x, y \rangle = z\}$ which contains, for any $n, k, z$ each pair of vectors $(x, y) \in (\mathbb{Z}_n^k)^2$ which has the property that $\sum_{i \in [n]} x_i y_i = z$. I want to know how much smaller this set is than $(\mathbb{Z}_n^k)^2$ itself, which I state mathematically using the following two functions: $f(n, k, z) = |S(n, k, z)|$ $\rho(n, k, z) = \frac{f(n, k, z)}{n^{2k}}$ It's not a priori clear how to compute these functions, but I've done a little prepping of $f$ with a question on mathoverflow as well as some simply recurrence expansion which I did myself. I believe its clear that we can partition each $S(n, k, z)$ into sets which each have unique first components $x_1, y_1$: $S(n, k, z) = \oplus_{(x_1^*, y_1^*) \in \mathbb{Z}^2}\{ (x, y) \in (\mathbb{Z}^k)^2 \mid x_1 = x_1^*, y_1 = y_1^*, \langle x, y\rangle = z \}$ Writing the concatenation of $a, b$ as $a.b$, it is clear that we can also write: $S(n, k, z) = \oplus_{(x_1^*, y_1^*) \in \mathbb{Z}^2} \{ (x_1^*.x, y_1^*.y) \mid x, y \in \mathbb{Z}^k, \langle x_1^*.x, y_1^*.y \rangle = \langle x, y \rangle = z - x_1^*y_1^* \}$ and then I think its clear that: $f(n, k, z) = \sum_{(x_1, y_1) \in \mathbb{Z}_n^2} f(n, k - 1, z - x_1y_1)$ Using the fact that $ax\equiv b (\text{mod }n)$ has $(a, n)$ solutions if $(a, n) \mid (b, n)$ and none otherwise, we can see easily that: $f(n, 1, z) = \sum_{y \in \mathbb{Z} :(y, n) \mid (z, n)} (y, n)$ Using the fact that $|\{ y \in \mathbb{Z}_n \mid (y, n) = d \}| = \varphi(\frac{n}{d})$, we can further see that: $f(n, 1, z) = \sum_{d \in \mathbb{Z_m}:d|(z, m)} d \varphi(\frac{n}{d})$ We can further simplify this for primes: $f(p, 1, z) = \sum_{d \in \mathbb{Z}_p:d|(z, p)} d \varphi(\frac{p}{d})$ clearly $(z, p) = 1$ or $p$, the latter case being if $z = 0$. Let's deal with that case: $f(p, 1, 0) = \varphi(p) + p \varphi(\frac{p}{p}) = p + p(1 - \frac{1}{p}) = 2p - 1$ and in the other case we only have the term $\varphi(p)$, as the $p$ divisor is gone because $0 < z < p, z \neq p \Rightarrow (z, p) = 1$, so we can write $f(p, 1, z \neq 0) = \varphi(p) = p(1 - \frac{1}{p}) = p - 1$ This is great but I still can't really do much to simplify the initial recurrence and I feel like this function $f$ is going to be quite difficult to compute for most $n$. I'm looking for help simplifying $f$ for higher $k$ and for special cases of $n, z$, particularly $z = 0$, as that's an interesting case for algorithm design.","['modules', 'number-theory', 'combinatorics', 'modular-arithmetic', 'discrete-mathematics']"
2207369,"Reference for Universal covering of $Sp(2n,\mathbb{R})$?","Does anyone know any reference that treat $Sp(2n,\mathbb{R})$ detailedly? For $Sp(2n,\mathbb{R})$, I mean the subgroup of $GL(2n,\mathbb{R})$ that preserves the standard symplectic form $\sum_{i=0}^n dx_i \wedge dy_i$ on $\mathbb{R}^{2n}$. The Wikipedia or nLab pages state that $\pi_1 (Sp(2n,\mathbb{R}))\cong \mathbb{Z}$ without a proof. I guess this probably follows from some fibration but I cannot find reference for it. Also, does anyone know if there's a concrete geometric construction of the universal covering $\widetilde{Sp(2n,\mathbb{R})}$? Thank you.","['manifolds', 'symplectic-geometry', 'algebraic-topology', 'differential-geometry', 'lie-groups']"
2207389,"How to explain why Integration by parts apparently ""fails"" in the case of $\int \frac{f'(x)}{f(x)}dx$ without resorting to definite integrals?","Integrating by parts the following integral $$I=\int \frac{f'(x)}{f(x)}dx$$ gives us $$\begin{align*}
I&=\int \frac{f'(x)}{f(x)}\,dx\\
&=\int\frac1{f(x)}f'(x)\,dx\\
&=\frac1{f(x)}f(x)-\int\left(\frac1{f(x)}\right)'f(x)\,dx\\
&=1+\int \frac{f'(x)}{f(x)}\,dx,
\end{align*}
$$
so
$$I=1+I\implies0=1,$$ which seems like a contradiction but is in reality a mistake as we can see by being somewhat more rigorous: $$
\begin{align*}
I&=\int_{a}^x \frac{f'(t)}{f(t)}\,dt\\
&=\int_{a}^x\frac1{f(t)}f'(t)\,dt\\
&=\left[\frac1{f(t)}f(t)\right]_a^x-\int_{a}^x\left(\frac1{f(t)}\right)'f(t)\,dt,
\end{align*}$$
so $I=I.$ How do I explain this to a student-of economics for what it's worth-who has not still learned about definite Integrals? (I suspect I could insert some constant on the upper part of the ""failed"" relations but I am not sure where or how to properly explain it. I also understand that in a couple of lessons we will talk about definitive integrals but what can I say now-That indefinite integrals are in reality a form of definite ones? )","['integration', 'integration-by-parts', 'education', 'calculus']"
2207405,"Evaluate $\int_0^\infty {\rm Tr}\left( {\bf A}^{-1} (x \,{\bf A}+{\bf I})^{-1} -\frac{1}{2+x} {\bf I} \right) dx$","I would like to evaluate the following integral. \begin{align}
\int_0^\infty {\rm Tr}\left( {\bf A}^{-1} (x \,{\bf A}+{\bf I})^{-1} -\frac{1}{2+x} {\bf I} \right) dx
\end{align}
where ${\bf A} \in \mathbb{R}^{n \times n}$ is a real positive definte matrix and ${\bf I}\in \mathbb{R}^{n \times n}$  is an identity. Unfortunately, my matrix calculus is very weak.  So, any reference where I can look up this would also be great. For the scalar case, the integral is equal to \begin{align}
\int_0^\infty  \frac{\frac{1}{a}}{ax+1}-\frac{1}{2+x} dx=\log(2)-\log(a).
\end{align} Thanks.","['multivariable-calculus', 'matrix-calculus', 'linear-algebra', 'calculus']"
2207441,What is the smallest number of 3-element subsets of a set of n elements where any element must be included with every other element at least one time?,"We have a set of n elements, and we need to find the lowest number of subsets with 3 elements where every element must be included with every other element, in at least one subset. For example, if our set was {1,2,3,4}, our subsets would be {1,2,3} {2,3,4} {1,2,4} and the number would be 3. Can we generalise this for a set consisting of n elements? Thanks in advance.","['combinatorics', 'elementary-set-theory']"
2207442,Evaluation of a trace - how does it depend on the inner product being used?,"Let's say that I am looking at the space of matrices $M_{n\times n}(\mathbb{R})$. If I have some linear function $F : M_{n\times n}(\mathbb{R}) \to M_{n\times n}(\mathbb{R})$, then I can take it's ""trace"" by taking a basis $\{ E_{ab} \}_{a,b=1}^{n} \subset M_{n\times n}(\mathbb{R})$ and evaluating the following:
$$
\mathrm{Tr}(F) = \sum_{a,b=1}^{n} \left< E_{ab}, F(E_{ab}) \right>\ \ \ =?\ \ \  \sum_{a,b=1}^{n} \mathrm{Tr}\left[ F(E_{ab})^{T}E_{ab}\right]
$$ I'm assuming that the inner product on $M_{n\times n}(\mathbb{R})$ I should be using is $ \left< A,B \right> = \mathrm{Tr}(B^{T}A)$. But here's my question: obviously $ \left< A,B \right>_{\prime} = \frac{\pi}{1789} \mathrm{Tr}(A^{T}B)$ is a valid inner product as well! But this different choice of inner product would change the value of $\mathrm{Tr}(F)$! I would have liked to think that $\mathrm{Tr}(F)$ is invariant under the choice of our inner product for some reason...since this is not the case,  is the trace of a function like $F$ defined in terms the inner product $\left< A,B \right> = \mathrm{Tr}(B^{T}A)$? What's going on here?","['matrices', 'trace', 'linear-algebra', 'inner-products']"
2207448,Expectation and variance of the Pareto distribution,"Given the distribution funciton of the r.v. $X$ for $\alpha, \beta >0$ $$ F(x) = 1-\Big( \frac{\beta}{\beta +x}\Big)^{\alpha} $$ for $x \geq 0$ and $0$ elsewhere What is the expectation and variance of $X$ for those values of parameters, where it is defined? Furthermore, how can one estimate the parameters $(\alpha, \beta)$ with given data using the method of moments? My idea was to first of all calculate the density, i.e. $$f(x) = \frac{\alpha \beta^{\alpha}}{(\beta + x)^{\alpha+1}}$$ for $x \geq 0$ . Then $$E[X] = \alpha \beta^{\alpha}\int_0^{\infty}\frac{x}{(\beta + x)^{\alpha+1}} dx$$ How can I proceed now?","['expectation', 'probability-theory', 'variance', 'probability', 'random-variables']"
2207460,Adjoint of inverse map is the inverse of adjoint map?,"Let  $E,F$ be Banach normed spaces and $S,T \in L(E,F)$.Denote adjoint of  $T$ as $T^* .$ Prove that  if $   T^{-1}$ exist and $T(E)=F $, then $(T^{-1})^* = (T^*)^{-1}. $ Actually, I could not proceed beyond writing definition of adjoint map.",['functional-analysis']
2207484,Why global sections of Sheaf Hom is Hom?,"We know, that $\mathbf{Hom}(\mathcal{F},\mathcal{G})$ is abelian group of all morphisms between $\mathcal{O}_X$-modules $\mathcal{F}$ and $\mathcal{G}$, and $\mathcal{Hom}(\mathcal{F},\mathcal{G})$ is sheaf, which section $\mathcal{Hom}(\mathcal{F},\mathcal{G})(U)$ is $\mathcal{O}_X(U)$-module of all morphisms between module $\mathcal{F}(U)$ and module $\mathcal{G}(U)$. So, for me statement $\Gamma(\mathcal{Hom}(\mathcal{F},\mathcal{G}))=\mathbf{Hom}(\mathcal{F},\mathcal{G})$ sounds like ""every morphism between two $\mathcal{O}_X$-modules uniquely determined by morphism between global sections of them"". It can't be true, right? So, where is mistake?","['sheaf-theory', 'algebraic-geometry']"
2207511,"The number of lattice paths from $(0, 0)$ to $(7, 7)$","What is the number of lattice paths of length $14$ from the point $(0, 0)$ to the point $(7, 7)$ such that they pass through the point $(4, 4)$ and don't pass the line $y = x$? Note: each step is right on the grid, or up on the grid. I am thinking about using the Inclusion–exclusion principle, but I just don't know how to implement it here!","['combinatorics', 'discrete-mathematics']"
2207552,Does the distributional derivative of the Dirac Comb have the same properties as a single Dirac Delta?,"A single Dirac delta has a distributional derivative $\delta'$ defined in the sense that
$$
\int_{-\infty}^{\infty} \textrm{d}x \, \delta'(x) \, \phi(x) = -\int_{-\infty}^{\infty} \textrm{d}x \, \delta(x) \, \phi'(x) \, .
$$
I understand this comes from the integral of the total derivative of $\delta(x) \, \phi(x)$ vanishing,
$$
\int_{-\infty}^{\infty} \textrm{d}x \, \frac{\textrm{d}}{\textrm{d} x} \big( \delta(x) \, \phi(x) \big) = \delta(x) \, \phi(x) \, \big|_{-\infty}^{\infty} = 0 \, ,
$$
which means the product rule for differentation gives the above expression defining $\delta'$. If we instead consider the Dirac comb
$$
\mathrm{III}(t) = \sum_{k=-\infty}^{\infty} \, \delta(x - kT) \, ,
$$
which is periodic with period $T$, is the same total derivative trick valid -
$$
\int_{-\infty}^{\infty} \textrm{d}x \, \frac{\textrm{d}}{\textrm{d} x} \big( \textrm{III}(x) \, \phi(x) \big) = 0 \, ?
$$
Allowing us to define the distributional derivative of the Dirac comb analogously to the Dirac delta
$$
\int_{-\infty}^{\infty} \textrm{d}x \, \textrm{III}'(x) \, \phi(x) = -\int_{-\infty}^{\infty} \textrm{d}x \, \textrm{III}(x) \, \phi'(x) \, .
$$","['derivatives', 'dirac-delta', 'distribution-theory', 'fourier-series']"
2207568,"Does the notion of ""rotation"" depend on a choice of metric?","Consider the statement : The Euclidean metric on $\mathbb{R}^n$ is rotationally invariant. I interpret this to mean (is this interpretation correct?): The Euclidean metric on $\mathbb{R}^n$ is invariant under the action of the orthogonal group $O(n)$. However, the orthogonal group $O(n)$ is defined in terms of the Euclidean metric (as the group of all self-maps $\mathbb{R}^n \to \mathbb{R}^n$ which preserve Euclidean distance and fix the origin). This suggests that we are implicitly using the following definition of ""rotation"": Rotations are the set of all (orientation-preserving) isometries of $\mathbb{R}^n$ which fix the origin. Question: Why is the first claim ""the Euclidean metric on $\mathbb{R}^n$ is rotationally invariant"" noteworthy/not trivial if we are implicitly using this definition/notion of rotation? (I.e., of course the metric is preserved by a group of isometries.) When we define ""rotations"", how are we not implicitly choosing a preferred metric on $\mathbb{R}^n$? /Question Clarifying example: In contrast, The taxicab metric on $\mathbb{R}^n$ is not rotationally invariant. In other words, The taxicab metric on $\mathbb{R}^n$ is not invariant under the action of $O(n)$. But what if we consider, instead of $O(n)$, what I will call $T(n)$ (""taxicab orthogonal group"") of all self-maps $\mathbb{R}^n \to \mathbb{R}^n$ which preserve taxicab distance and fix the origin? It seems fairly clear that we have: The taxicab metric on $\mathbb{R}^n$ is invariant under $T(n)$. or in other words The taxicab metric on $\mathbb{R}^n$ is ""taxicab-rotationally invariant"". Note: This is a very dumb question, so if you have any suggestions for how it could be improved, or if it should just be deleted, please say so (nicely).","['real-analysis', 'rotations', 'euclidean-geometry', 'geometry', 'metric-spaces']"
2207572,Diameter of a graph consisting of Hamilton cycles,"Imagine an undirected graph $G = (V,E)$ with $|V| = n$ nodes. Its unweighted edges $E$ are the union of $h$ random Hamiltonian cycles through all nodes, each generated iid uniformly at random from the set of all Hamiltonian cycles. What is the expected diameter $D$ of $G$? The case $h=1$ is trivial and not interesting. Clearly, $D$ grows strictly monotonically with $n$ as well as with $h^{-1}$. However, I'm not sure of the exact relationship of these variables. I suspect a relationship along the lines of $D = O(\log(n)/h)$.","['graph-theory', 'random-graphs', 'hamiltonian-path', 'discrete-mathematics']"
2207606,Blockwise cofactor matrix identity,"Wikipedia gives an identity for blockwise inversion, assuming the appropriate inverses exist: $$\begin{bmatrix}\mathbf{A} & \mathbf{B} \\ \mathbf{C} & \mathbf{D}\end{bmatrix}^{-1} = \begin{bmatrix} \mathbf{A}^{-1}+\mathbf{A}^{-1}\mathbf{B}(\mathbf{D}-\mathbf{CA}^{-1}\mathbf{B})^{-1}\mathbf{CA}^{-1} & -\mathbf{A}^{-1}\mathbf{B}(\mathbf{D}-\mathbf{CA}^{-1}\mathbf{B})^{-1} \\ -(\mathbf{D}-\mathbf{CA}^{-1}\mathbf{B})^{-1}\mathbf{CA}^{-1} & (\mathbf{D}-\mathbf{CA}^{-1}\mathbf{B})^{-1} \end{bmatrix}$$ Is there a corresponding general formula for the matrix of cofactors: $$\operatorname{adj}^T\begin{bmatrix}\mathbf{A} & \mathbf{B} \\ \mathbf{C} & \mathbf{D}\end{bmatrix}$$
for when $\mathbf{A}^{-1}$ or $(\mathbf{D}-\mathbf{C}\mathbf{A}^{-1}\mathbf{B})^{-1}$ do not necessarily exist? Is there at least one for bordered matrices, i.e. $\mathbf{D} \in \mathbb{C}^{1\times 1}$?","['matrices', 'reference-request', 'matrix-decomposition', 'pseudoinverse', 'linear-algebra']"
2207608,Proof for Derivative of Dot Product,"In Taylor's Classical Mechanics , one of the problems is as follows: (1.9) If $\vec{r}$ and $\vec{s}$ are vectors that depend on time, prove that the product rule for differentiating products applies to $\vec{r}$ $\cdot$ $\vec{s}$, that is, that: $\frac{d}{dt}(\vec{r}$ $\cdot$ $\vec{s}) = \vec{r}$ $\cdot$ $\frac{d\vec{s}}{dt} + \vec{s}$ $\cdot$ $\frac{d\vec{r}}{dt}$ I'm not totally certain that my solution is correct, so if people could give me a hand in checking my work, I'd really appreciate it! $\vec{r}$ $\cdot$ $\vec{s} = r_xs_x + r_ys_y$ $\frac{d}{dt}(r_xs_x+r_ys_y) = \frac{d}{dt}(r_xs_x) + \frac{d}{dt}(r_ys_y)$ $\frac{d}{dt}(\vec{r}$ $\cdot$ $\vec{s}) = (r_x\frac{d}{dt}s_x + r_y\frac{d}{dt}s_y) + (s_x\frac{d}{dt}r_x + s_y\frac{d}{dt}r_y)$ $\frac{d}{dt}(\vec{r}$ $\cdot$ $\vec{s}) = (r_x+r_y)\frac{d}{dt}(s_x+s_y)+(s_x+s_y)\frac{d}{dt}(r_x+r_y)$ $\frac{d}{dt}(\vec{r}$ $\cdot$ $\vec{s}) = \vec{r}$ $\cdot$ $\frac{d\vec{s}}{dt} + \vec{s}$ $\cdot$ $\frac{d\vec{r}}{dt}$","['vectors', 'calculus']"
2207632,book recommendation for real analysis,"During the next quarter at uni, I'll be taking a course in real analysis and since I prefer studying with an additional text I thought I'd come here to look for some book recommendations. My background: I'm comfortable with linear algebra and single variable calculus, but shakey on multivariable calculus. I did have a slight introduction in to geometry. For linear algebra I found the common recommendation of Hoffman & Kunze to be very helpful (although the abstractness came as a bit of a kicker at first). For Single variable calculus I used the book Calculus by Adams and Essex, which I found frustrating to work with, because it often left me guessing at what they were trying to do or why they were doing it. I also felt that they exercised a certain lack of rigour. (Which may be due to the subject which would make it hard to derive from axioms.) Details: Though it would be a complementary text, I'd prefer one which will still hold value as a work of reference at a later point in my studies. I've heard that Rudin's Principles of mathematical analysis is one of the better textst out there, but also read several comments discouraging Rudin's book as a first introduction to real analysis, hence my quest to gather more information and maybe get some more personalised recommendations. The course: The mandatory course literature will consist of lecture notes, but 4 texts are suggested as recommended reading. T.M. Apostol, Mathematical analysis. Addison-Wesley (1974) J. Dieudonné, Foundations of Modern Analysis. Academic Press (1960) A. van Rooij, Analyse voor Beginners.Epsilon Uitgaven, no. 6 (2003) R.S. Strichartz, The way of analysis (1995) Thanks in advance!","['reference-request', 'real-analysis', 'book-recommendation']"
2207642,Is my proof logically sound?,"Prove that for arbitrary sets A, B, and C that
$$ A \subseteq B \implies (A \cap C) \subseteq (A \cap B). $$ My Proof Assume $A \subseteq B$. From this assumption we get  $x \in A \implies x \in B$. If we assume that $x \in (A \cap C)$ then $x \in A$ and $x \in C$. From our assumption, it follows that  $x \in B$. Since $x \in A$ and $x \in B$ we can conclude that $A \subseteq B \implies (A \cap C) \subseteq (A \cap B)$.","['elementary-set-theory', 'proof-verification']"
2207665,Projecting an angle from one plane to another plane.,"Consider I have two intersecting planes with an angle ($\theta$). I have two intersecting vectors ($\vec a$ and $\vec b$) on one of the planes that make an angle ($\gamma$). If I project these two vectors onto the other plane, what the projected angle ($\alpha$) between the projected vectors ($\vec a \prime$ and $\vec b \prime$) would be (as a function of the other angles)? To make it simple, consider: Vectors intersect on the hinge of the two planes. Vectors are symmetric to the perpendicular line to the hinge. Regards,","['plane-geometry', 'projective-space', 'geometry', 'vectors', 'vector-spaces']"
2207675,proving cartesian product is distributive over unions and intersections [duplicate],"This question already has answers here : elementary set theory (cartesian product and symmetric difference proof) (2 answers) Closed 7 years ago . I had to prove this: Let $A$, $B$, and $C$ be sets. Then, $A \times (B \Delta C) = (A \times B) \Delta (A \times C)$. By the definition of symmetric difference, we know that
$$B \Delta C= (B \Delta C) \cup (C \Delta B).$$
So, we can expand the LHS of this theorem to get 
$$A \times ( (B \Delta C) \cup (C \Delta B) ).$$
Therefore,
\begin{align}
A \times (B \Delta C) &= A \times ( (B \Delta C) \cup (C \Delta B) ) \\
&= (A \times (B \Delta C)) \cup (A \times (C \Delta B)) \\
&= ((A \times B) \Delta (A \times C)) \cup ((A \times C) \Delta (A \times B)) \\
&= (A \times B) \Delta (A \times C).
\end{align}
So, the LHS = RHS. But I'm not sure how to show that cartesian products are actually distributive over unions and intersections?","['proof-verification', 'elementary-set-theory', 'discrete-mathematics']"
2207682,Proof of $0x=0$,"I don't feel like I proved much here, all my life I took for granted that $0x=0$ was obvious but I really never even thought of questioning why that is so.
I want to get ahead and learn the basics of Analysis before taking a course on it so I am looking to get basic facts right before moving on to the good stuff. Thus, to see if I understand the concept of a field $-$I will call it $F-$ it was suggested to me that I try producing a convincing proof, based on what I know, of the presumably obvious fact that
$$0x=0$$ I start by noting that there exists a ""$0$ element"" in $F$ such that for all $x \in F$, $0+x=x$. $$\begin{align}
(0+x)x&=0x+xx\\
(0+x)x-xx & = 0x \\
0x+xx-xx & = 0x\\
\end{align}$$ I want to get rid of both $xx$ terms using axioms I know. The simplest for me is to use the distributive law $x(a+b)=xa+xb$ along with the property that there is an ""inverse"" element in $F$ for all elements of $F$ such that their sum is $x+(-x)=0$. I get the following result:
$$\begin{align}
0x+((x)(x))-((x)(x))&=0x\\
0x+((x)(x))+((x)(-x))&=0x\\
0x+x(x+(-x))&=0x\\
x(0+0)&=0x\\
x(0+0)-0x&=0\\
x((0+0)-0)&=0\\
\therefore \; 0x&=0 \tag*{$\blacksquare$} \\
\end{align}$$ I don't know why but this result does not feel satisfying to me at all and anything I tried so far either ended up this way or lead me to a circular reasoning tailspin. Is this acceptable and/or what would be a better way to prove that $0x=0$?","['real-numbers', 'elementary-set-theory', 'proof-verification']"
2207706,Strogatz 3.3.1d: when is adiabatic elimination allowable?,"I worked through much of 3.3.1 (Laser Threshold) in Strogatz's Nonlinear Dynamics and Chaos, but I'm struggling to understand the adiabatic elimination he does and when it's allowable. We have a system modeling a laser where $n$ is the number of photons in the laser and $N$ is the number of excited atoms. The equations are: $$\dot n= GnN-kn$$
$$\dot N= -GnN-fN+p$$ where $G$, $k$, $f$, and $p$ are various control parameters. To convert it from a one-dimensional system, we make the 'quasi-static' approximation $\dot N \approx 0$, which Strogatz says represents ""$N$ relaxing more rapidly than $n$"". This approximation is the part I'm confused about: a) If $\dot N\approx0$, do we assume that $N$ is constant? Or are these different assumptions? How can $\dot N\approx0$ be true when $\dot N$ has the constant, non-zero $p$ term? b) In the 4th part of the question, we are asked to find the range of parameters for which this approximation is acceptable. I tried the 'dimensionless' groups approach from earlier in the book, but that led to a dead-end. Is there a good introduction to when adiabatic elimination is allowed that isn't in the context of complex Quantum Mechanics?","['approximation-theory', 'ordinary-differential-equations', 'nonlinear-system']"
2207734,$\lim\limits_{n \to \infty} \frac{a_n}{b_n}=l$ ; Prove $\sum\limits_{k=1}^\infty a_k$ converges iff $\sum\limits_{k=1}^\infty b_k$ converges.,"Written, in Ex.8 Ch.9.1 of the book Advanced Calculus by P. M. Fitzpatrick : Suppose that $\sum\limits_{k=1}^\infty a_k$ and $\sum\limits_{k=1}^\infty b_k$ are series of positive numbers such that $$\lim_{n \to \infty} \frac{a_n}{b_n}=l \ \ \ \text{and} \ l>0.$$ Prove that the series $\sum\limits_{k=1}^\infty a_k$ converges iff the series $\sum\limits_{k=1}^\infty b_k$ converges. Am I correct by the following (sketch of) proof? : 1- For a given $\epsilon_1$ there is $N_1$ such that $\left|\frac{a_n}{b_n} - l\right| < \epsilon_1$ for all $n \ge N_1$. 2- Since the series $\sum\limits_{k=1}^\infty a_k$ converges, for a given $\epsilon_2$ there is $N_2$ such that $\left|b_{n+1}+\dots+b_{n+k}\right|< \epsilon_1$ for all $n \ge N_2$ any for all natural numbers $k$. 3- Define $N = \max {\{N_1,N_2}\}$. 4- From Step (1), $a_{n+k} < (\epsilon_1+l) b_{n+k}$ for all $n \ge N$ any for all natural numbers $k$. [Also, $a_i$'s and $b_i$'s are all positive]. Thus $a_{n+1}+\dots+a_{n+k} < (\epsilon_1+l) (b_{n+1}+\dots+b_{n+k})< \epsilon_3$. Then the convergence of the series $\sum\limits_{k=1}^\infty b_k$ implies the convergence of the series $\sum\limits_{k=1}^\infty a_k$. 5- For the reverse implication, we use the fact that $\lim\limits_{n \to \infty}\frac{a_n}{b_n}=l \iff \lim\limits_{n \to \infty}\frac{b_n}{a_n}= \frac{1}{l}= l' >0$ and repeat the process this time for a and b exchanged. 6- The Quotient Property For Sequences hold for a nonzero limit in the denominator, but since the limit in the numerator also is zero so we may use the The Quotient Property For Sequences. Thanks.","['real-analysis', 'sequences-and-series', 'solution-verification', 'limits']"
2207737,Finding the dimension of a vector space over different fields?,"We were given this question for my linear algebra module: We view $\Bbb C ^2$ as a vector space over $\Bbb C $,$\Bbb R$ and $\Bbb Q$. Let
$$\mathbf x_1 := \begin{pmatrix} i \\ 0 \end{pmatrix},
\mathbf x_2 := \begin{pmatrix} \sqrt 2 \\ \sqrt 5 \end{pmatrix},
\mathbf x_3 := \begin{pmatrix} 0 \\ 1 \end{pmatrix},
\mathbf x_4 := \begin{pmatrix} i\sqrt 3 \\ \sqrt 3 \end{pmatrix},
\mathbf x_5 := \begin{pmatrix} 1 \\ 3 \end{pmatrix}  \in \Bbb C ^2 $$ Find dim$_F$(Span$_F$($ \mathbf x_1,\mathbf x_2,\mathbf x_3,\mathbf x_4,\mathbf x_5 $)) for F=$\Bbb C $,$\Bbb R$ and $\Bbb Q$. So I have found that for F=$\Bbb C $, the dimension is 2, but I'm struggling with the other fields. Whats been confusing me is say I want to find a basis for Span$_F$($ \mathbf x_1,\mathbf x_2,\mathbf x_3,\mathbf x_4,\mathbf x_5 $) over $\Bbb R$. If I want to apply Gaussian elimination to obtain the minimal spanning set, which scalars am I allowed to used say when scaling the rows when applying row ops. Do the scalars always have to the field elements, say in this case just $\Bbb R $? Sorry if this seems trivial but couldn't really find any good sources online and lecturer didn't cover it in lectures. Thanks a lot!","['gaussian-elimination', 'linear-algebra']"
2207745,VI Arnold ODE: Need help coming to grips with early notation in the book (phase velocity),"This seems to be a somewhat common theme among users on here trying to start reading Arnold's ODE book. I have found a few similar questions but none have sufficiently answered my problems. Specifically I am having a hard time understanding the phase velocity, $v(x) = \dot{x} = \frac{d}{dt}|_{t=0}g^tx$. According to this post, Arnold's ODE computation of phase velocity , it is suggested that in the notation of $g^tx$, $x$ is considered a constant or equal to the initial value $x_0$. But how do I then reconcile this fact with the expression $\dot{x}=\frac{d}{dt}|_{t=0}g^tx$? In my simple world $\dot{x}=\frac{d}{dt}g^tx$ would make a lot more sense. I find this alteration to be especially fitting considering the examples put forth later, e.g. draw the integral curves of $v(x) = \dot{x} = -kx$. What am I missing here? Help would be greatly appreciated as I am reading this in my spare time and have no access to feedback other than from sources such as this site. Thank you! Edit by request: I have the Richard A. Silverman translated edition and the definition is found in subsection 1.4 on Vector Fields in Sec. 1 Phase Spaces and Phase Flows on page 7.","['classical-mechanics', 'ordinary-differential-equations', 'mathematical-physics']"
2207782,How to prove that sub-level set of spectral radius function is not convex,"Let $A \in \mathbb{R}^{n \times n}$ and $\rho(A)=\{|\lambda|_\max : \lambda \text{ is an eigen-value of } A\}$. I am trying to prove that the set 
\begin{align*}
B_\alpha=\{A: \rho(A) < \alpha \}
\end{align*}
need not be a convex set in general (for any $\alpha>0$). Can anyone provide a useful hint about how to proceed?","['matrices', 'convex-analysis']"
2207827,Exponential of the Laplacian operator as diffusion equation,"Let $u$ be a function on a domain $\Omega$ with some fixed boundary condition. I have recently seen a notation $e^{\tau \Delta}u$ as meaning the the time evolution of $u$ by diffusion for a time $\tau$. I'm curious where this notation comes from, and more generally, what is meant by a function of a differential operator.","['functional-calculus', 'semigroup-of-operators', 'notation', 'functional-analysis', 'differential-operators']"
2207834,One line solution with projective geometry,"I am trying to solve the following problem Let $A,B,C,D$ be four points in the plane.Let lines $AC$ and $BD$ meet at $P$ , lines
$AB$ and $CD$ meet at $Q$, and lines $BC$ and $DA$ meet at $R$. Let line through $P$ parallel to $QR$ meet lines $AB$ and $CD$ at $X$ and $Z$. Show that $P$ is the midpoint of $XZ$. There is a hint from the author that it can be solved in one line using projective geometry and specifically perspectivity at $Q$. I can't find this one liner does anyone have any ideas?","['geometric-transformation', 'projective-geometry', 'geometry']"
2207846,"If $\sqrt{n}(\widehat{\theta}_{n}-\theta) \to N(0, \frac{1}{I_1(\theta)})$, what does $\sqrt{n}(\widehat{\theta}_{kn}-\theta)$ converge to?","Suppose that $$
\sqrt{n}\left(\widehat{\theta}_{n}-\theta\right) \overset{D}\to N\left(0, \frac{1}{I_1(\theta)}\right)
$$ From this, is it true that: $$
\sqrt{n}\left(\widehat{\theta}_{kn}-\theta\right) \overset{D}\to N\left(0, \frac{1}{I_1(\theta)}\right)
$$ where $k \in \mathbb{N}$? In other words, my sequence is further ahead in the second equation.","['statistics', 'probability']"
2207863,Proving a Binomial Summation with Induction $\sum_{k=0}^n(-1)^k \binom nk^2$ [duplicate],"This question already has answers here : find $\sum_{k=0}^{t}(-1)^k\binom{t}{k}^2$ for odd t then for even t (2 answers) Closed 7 years ago . I'm attempting to prove that $$\sum_{k=0}^n(-1)^k{n \choose k}^2=\begin{cases}0&\text{if $n$ is odd}\\(-1)^m{2m \choose m}&\text{if $n$ = 2m}\end{cases}$$
via induction. Here's what I have so far: Base Case (odd): $n=1$ $$\sum_{k=0}^1(-1)^k{1 \choose k}^2=0$$
Base Case (even): $n=2$ $$\sum_{k=0}^2(-1)^k{2 \choose k}^2=-2$$
Hypothesis: $n=l$ $$\sum_{k=0}^l(-1)^k{l \choose k}^2=\begin{cases}0&\text{if $n$ is odd}\\(-1)^m{2m \choose m}&\text{if $n$ = 2m}\end{cases}$$
Inductive Step: $n=l+1$ $$\sum_{k=0}^{l+1}(-1)^k{l+1 \choose k}^2$$
I know that the goal is to get this sum into terms of the hypothesis plus the $(l+1)^{th}$ term, but I'm not sure how. I've tried manipulating various identities, but so far I'm not coming up with anything workable. Thanks in advance for any help.","['binomial-theorem', 'binomial-coefficients', 'induction', 'combinatorics', 'summation']"
2207868,Binomial Distribution and the Moment Generating Function,"Please consider the problem and the answer below. The problem is from a
text book on statistics. I believe that my answer is correct but it seems
to easy so I am concerned that it is wrong. Is it wrong? Thanks, Bob Problem: If $Y$ has a binomial distribution with $n$ trials and the probability of
success $p$, show that the moment generating function for $Y$ is:
\begin{eqnarray}
m(t) &=& (pe^t+q)^n
\end{eqnarray}
where $q = 1 - p$. Answer: The moment generating function is defined to be $m(t) = E(e^{ty})$. This
gives us the following:
\begin{eqnarray*}
m(t) &=& E(e^{ty}) \\
m(t) &=& \sum_{i = 0}^{n} { {n \choose i} p^i q^{n-i} e^{ti} } \\
\end{eqnarray*}
Now, I apply the binomial theorem to equation 1 and get:
\begin{eqnarray*}
m(t) &=& \sum_{i = 0}^{n} { {n \choose i} p^i q^{n-i} e^{ti} } \\
\end{eqnarray*}
Q.E.D.","['statistics', 'probability']"
2207965,sphere bundles isomorphic to vector bundle.,"Bredon claims that sphere bundles in certain cases are isomorphic to vector bundles. For example he says just replace $S^{n-1}$ with $R^n$. But for example the circle and the plane are not even isomorphic. How can we talk about bundle isomorphism when even the fibers are not isomorphic? ""A disk or sphere bundle gives rise to a vector bundle with the orthogonal group as the structure group just by replacing the fiber $D^n$ or $S^{n-1}$ with $R^n$ and using the same change of coordinate function"". We cannot just ""replace"" the fibers with something not isomorphic can we?","['algebraic-topology', 'fiber-bundles', 'vector-bundles', 'differential-geometry']"
2207994,proof Intermediate Value Theorem,"Intermediate Value Theorem The idea of the proof is to look for the first point at which the graph of f crosses the axis.
Let X = {x ∈ [a, b] | f (y) ≤ 0 for all y ∈ [a, x]}. Then X is non-empty since a ∈ X and X ⊆ [a, b] so it is bounded. Hence by the Completeness Axiom, X has a least upper bound α (say).
We claim that f (α) = 0. how can be written it formal?","['real-analysis', 'limits', 'calculus', 'convergence-divergence', 'analysis']"
2208004,"proving $\cos (A+B)>0$, if given angles $A$ and $B$","If $\displaystyle A=3\sin^{-1}\left(\frac{6}{11}\right)$ and $\displaystyle B = 3\cos^{-1}\left(\frac{4}{9}\right),$ then proving $\cos (A+B)>0$ Attempt: $$ 3\sin^{-1}\left(\frac{1}{2}\right)<3\sin^{-1}\left(\frac{6}{11}\right)<3\sin^{-1}\left(\frac{\sqrt{3}}{2}\right)\Rightarrow \frac{\pi}{2}<A<\pi$$ same way $$\displaystyle 3\cos^{-1}\left(0\right)<3\cos^{-1}\left(\frac{4}{9}\right)<3\cos^{-1}\left(\frac{1}{2}\right)\Rightarrow \frac{\pi}{2}<B<\frac{3\pi}{2}$$ so $$\pi<A+B<\frac{5\pi}{2}$$ could some help me how to prove $\cos (A+B)>0,$ thanks",['trigonometry']
2208017,"Is it true that for any compact Riemannian manifold, the sectional curvature is bounded?","My attempt at a proof of this statement goes something like this: Let $(M,g)$ be a Riemannian $n$-manifold, then consider the vector bundle $\mathrm{T}M\oplus\mathrm{T}M$, then sectional curvature defines a function $K:\mathcal{U}\to\mathbb{R}$ which is defined on an open subset $\mathcal{U}\subset\mathrm{T}M\oplus\mathrm{T}M$ and is continuous, since it is smooth in coordinates. Note that we can define a $\operatorname{Gr}_2\mathbb{R}^n$-bundle on $M$ by considering a quotient topology on $\mathcal{U}$ in which we identify $(v_1,v_2)\in\mathrm{T}_xM\oplus\mathrm{T}_xM$ with $(w_1,w_2)\in\mathrm{T}_xM\oplus\mathrm{T}_xM$ precisely when they cut out the same plane in $\mathrm{T}_xM$. If we define the resulting quotient space to be $\mathcal{V}$, then we obtain a continuous map $K:\mathcal{V}\to\mathbb{R}$ and $\mathcal{V}$ is compact, so that sectional curvature is bounded. However, I was talking to another student recently, and he claimed with great confidence that the sectional curvature on compact Riemannian manifolds need not be bounded, which makes me wonder if my (sketch of a) proof is incorrect.","['riemannian-geometry', 'differential-geometry', 'curvature']"
2208067,Example of a symplectic manifold with given properties,"Is there an example of a simply-connected, compact, symplectic manifold $(M,\omega)$ such that $\omega|_{\pi_2(M)}=0$ (in the sense that $\int_{S^2} \sigma^* \omega=0$ for any smooth map $\sigma: S^2 \to M$)? Preferably with $\pi_2(M)$ being free. This question is motivated due to the usual hypotheses made on $(M,\omega)$ in order for the related action functional to be well-defined.","['symplectic-geometry', 'differential-geometry', 'differential-topology']"
2208106,"If a linear map $T$ has a $k$-dimensional invariant subspace, does it admit an $n-k$ invariant subspace?","Let $V$ be an $n$ -dimensional real vector space, and let $1<k<n-1$ be fixed. Let $T: V\to V$ be a linear map, and suppose that there exists a $k$ -dimensional $T$ invariant subspace of $V$ . Does there exist an $(n-k)$ $T$ -invariant subspace of $V$ ? The smallest possible dimensions where a counter-example might be  is when $k=2,n=5$ . Two comments: By duality, $T$ has a $k$ -dimensional invariant subspace if and only if the dual map $T^*:V^* \to V^*$ has an $n-k$ -dimensional invariant subspace. (If $U$ is $T$ -invariant, then the subspace of $V^*$ whose restriction to $U$ is zero is $T^*$ -invariant). I excluded the cases $k=1$ and $k=n-1$ , since I know that the answer is positive for those. Indeed, since the characteristic polynomials of $T$ and $T^{*}$ are identical, we have $$T \, \text{  has an eigenvector  if and only if } \, T^{*} \, \text{  has an eigenvector } \tag{1}.$$ By the previous comment, we also have $$T \, \text{  has an eigenvector  if and only if } \, T^{*} \, \text{  has a co-dimension one invariant subspace } \tag{2}.$$ Combining $(1)$ and $(2)$ , we conclude that $T^*$ has an eigenvector  if and only if $T^*$ has a co-dimension one invariant subspace. Since any map is the dual of its dual, this holds for any endomorphism $T$ .","['linear-algebra', 'linear-transformations', 'invariant-subspace']"
2208117,"If $\tau(\sum P_i) =\infty$, can we find a sequence of projections $\{Q_n\}$ from $\{P_i\}$ such that $\tau(\sum Q_n) =\infty$?","Let ${P_i}$ be a family of mutually orthogonal projections of a semifinite von Neumann algebra $M$ and $\tau$ be the semifinite faithful normal trace on $M$. If $\tau(\sum P_i) =\infty$, can we find a sequence of projections $\{Q_n\}$ from $\{P_i\}$ such that $\tau(\sum Q_n) =\infty$? My idea is: Without loss of generality, we may assume that $\tau(P_i)<\infty$ for every $i$.
Define $\alpha_i := \tau(\sum_{j\le i} P_j)$. Then, since $\tau$ is normal, we have $\sup_i\alpha_i = \sup_i\tau(\sum_{j\le i} P_j)=\tau( \sup_i \sum_{j\le i} P_j) =\tau( \sum P_j) =\infty  $. 
Since $\tau(P_i) >0$ for every $i$ ($\tau$ is faithful), the elements in $\{\alpha_i <\infty\}$ are distinct and therefore $\{\alpha_i <\infty\}$ consists of countably many elements. But I don't know how to show the supremum of $\{\alpha_i <\infty\}$ is infty.","['functional-analysis', 'operator-algebras', 'operator-theory', 'von-neumann-algebras']"
2208129,Evaluating $\lim\limits_{b\to\infty}b\int_0^1\cos(b x) \cosh^{-1}(\frac{1}{x})dx$,"I came across this limit while integrating Bessel functions:
$$\lim_{b\to\infty}b\int_0^1\cos(b x) \cosh^{-1}(\frac{1}{x})dx$$ This integral does not have any standard value I know of for fixed $b$. Graphing it numerically, it appears to converge to $\pi/2$ as $b\to\infty$ (albeit slowly). Does anyone have any ideas for evaluating such an integral/limit?","['hyperbolic-functions', 'limits', 'improper-integrals', 'integration', 'definite-integrals']"
2208167,Show that B is a nonsingular matrix (not that obvious).,"How would you proceed if you were asked in an interview to show that B is a nonsingular matrix (in an elegant way)? $$B= \begin{pmatrix} 1& 1.25& −0.50& 0.15\\ 0.15& 2& 1.25& −1.50\\ −0.45& 0.25& 3& 1.25\\ 0.25& −0.15& 0.25& 4\\ \end{pmatrix}$$ In my opinion, taking the time to compute the determinant of this $4\times4$ matrix during the interview would not be appreciated by the interviewer.","['matrices', 'matrix-rank', 'linear-algebra']"
2208182,Probability Interview Question - Brain teaser,"Player A has a thirty-sided and Player B has a twenty-sided die. They both roll the dies and whoever gets the higher roll wins. If they roll the same amount Player B wins. What is the probability that Player B win? So I have
$$1 - \left(\frac{1}{3}+\frac{1}{2}\cdot\frac{2}{3}-\frac{1}{30}\right) = \frac{11}{30}.$$
There is $100\%$ chance of winning when A roll from 20 - 30 but for the rest $2/3$ there is only $50\%$ chance of winning, in addition, there is $1/30$ of chance that player A could roll the same number as B
The answer for this question should be $0.35$, I am not sure where I did wrong. I just figured maybe I should do this instead $1 - (\frac{1}{3}+(\frac{1}{2}-\frac{1}{30})\cdot\frac{2}{3}) = \frac{16}{45}$ is this right ?",['probability']
2208183,How to find the coefficient of $x^2y^3z^6$ in the expression $(x^2+y+z)^{10}$?,"How can find the coefficient of $x^2y^3z^6$  in the expression $(x^2+y+z)^{10}$? I know this involves the binomial theorem, but I can't figure out how to solve it.","['combinatorics', 'binomial-theorem', 'discrete-mathematics']"
2208222,Simplifying an integral by changing the order of integration,"Question: Consider a triple integral of the following form
\begin{equation}
\int_{x=0}^1 \int_{y=0}^{1} \int_{z=0}^{1} f(x,y,z)dzdydx.
\end{equation}
Because of the specific $f(\cdot,\cdot,\cdot)$ function I am dealing with, I would like to convert the above integral into the following form
\begin{equation}
\int_{x=0}^1 \int_{y=0}^{x} \int_{z=0}^{y} g(x,y,z)dzdydx,
\end{equation}
where $g(\cdot,\cdot,\cdot)$ is an appropriately defined function. This form is easier to work with because the integrands are nicely ordered as $x\ge y \ge z.$ Example: I am able to do a similar trick for a double integral. Consider 
\begin{equation}
\int_{x=0}^1 \int_{y=0}^{1} f(x,y)dydx.
\end{equation}
This integral is equivalent to the sum of two integrals:
\begin{equation}
\int_{x=0}^1 \int_{y=0}^{1} f(x,y)dydx=\int_{x=0}^1 \int_{y=0}^{x} f(x,y)dydx+\int_{x=0}^1 \int_{y=x}^{1} f(x,y)dydx.
\end{equation}
By changing the order of the integration in the last integral above, we obtain
\begin{equation}
\int_{x=0}^1 \int_{y=x}^{1} f(x,y)dydx = \int_{y=0}^1 \int_{x=0}^{y} f(x,y)dxdy.
\end{equation}
Renaming $x$ as $y$ and vice-versa on the integral in the right hand side, we obtain
\begin{equation}
\int_{x=0}^1 \int_{y=0}^{x} h(x,y)dydx
\end{equation}
for an appropriate $h(x,y).$
Thus, the original integral is given as
\begin{align}
\int_{x=0}^1 \int_{y=0}^{1} f(x,y)dydx &=\int_{x=0}^1 \int_{y=0}^{x} f(x,y)dydx+\int_{x=0}^1 \int_{y=0}^{x} h(x,y)dydx\\ &= \int_{x=0}^1 \int_{y=0}^{x} \left[ f(x,y)+h(x,y) \right] dydx.
\end{align}",['integration']
2208273,How to find the 'real' jordan canonical form of a matrix,"Given that the the Jordan normal form of a matrix is, $J=\begin{bmatrix}2&1&0&0\\0&2&0&0\\0&0&1-i&0\\0&0&0&1+i\end{bmatrix}$ How do you find the 'real' canonical form of the matrix?","['matrices', 'jordan-normal-form', 'linear-algebra']"
2208274,Suppose that $\sum a_n$ converges and that $a_n \neq 0$ for all $n \in \mathbb N $. Prove that $\sum \frac{1}{a_n}$ diverges.,Suppose that $\sum a_n$ converges and that $a_n \neq 0$ for all $n \in \mathbb N $. Prove that $\sum \frac{1}{a_n}$ diverges. My attempt let the series $\sum a_n$ converge to a. Therefore $\lim_{n\to\infty} S_n = a$ Yeah. I have never tackled a similar question to this. Could anyone help me get started?,['sequences-and-series']
2208287,Is the set of all conformal structures on $\mathbb{R}^n$ a manifold? Does it have a name?,"Question: Is the set of all conformal structures on $\mathbb{R}^n$ a manifold? Does it have a name? A pointer to a reference will suffice. Definition: A conformal structure on $\mathbb{R}^n$ is an equivalence class of inner products, with two inner products $f,g$ equivalent, $f \sim g$, if and only $f = \lambda g$ for some $\lambda >0$. In other words, it is an inner product ""up to positive scaling"". We need to specify an inner product to determine whether a set of vectors is orthonormal, but we only need to specify a conformal structure to determine whether a set of vectors is orthogonal. An inner product determines a notion of both length and angle, but a conformal structure only determines a notion of angle, not of length. This is analogous to how a norm only determines a notion of length, but not of angle -- in fact, it makes sense to think of a conformal structure as ""an inner product minus a choice of norm"". Attempt: Consider the following fact (cf. p. 201, Linear Algebra via Exterior Products ): If $\{ e_1, \dots, e_n\}$ is an arbitrary basis in $V$, then there exists an inner product with respect to which $\{e_1, \dots, e_n \}$ is an orthonormal basis. Thus, start with the non-compact $n$-Stiefel manifold , the set of all bases on $\mathbb{R}^n$. By the above fact, each element corresponds to an inner product (the inner product which makes the basis orthonormal). So we can impose an equivalence relation on the non-compact $n$-Stiefel manifold , saying that two bases are equivalent if and only if they are orthonormal with respect to the same inner product. Since the equivalence classes of this equivalence relation are (I imagine) diffeomorphic to the compact $n$-Stiefel manifold , this might be a homogeneous space . Now to get from this space (the space of all inner products) to the space of all conformal structures on $\mathbb{R}^n$ is simple -- we just quotient by the equivalence relation which says that two inner products are equivalent if and only if they are the same up to positive scaling, i.e. if and only if they belong to the same conformal structure . Since this is the same thing (I think) as quotienting by the action of $\mathbb{R}^{+}$, which is a Lie group, then, if the space of all inner products was a homogeneous space , the final space, the space of all conformal structures on $\mathbb{R}^n$, will also be a homogeneous space . Since homogeneous spaces are manifolds, and the space of all conformal structures on $\mathbb{R}^n$ might be a homogeneous space , then it might be a manifold. Obviously this says nothing about what the name of such a structure might be, except perhaps that is related to Stiefel manifolds via the actions of multiple Lie groups.","['reference-request', 'terminology', 'homogeneous-spaces', 'stiefel-manifolds', 'differential-geometry']"
2208289,Prove there exists $t>0$ such that $\cos(t) < 0$.,"I want to prove that there exists a positive real number $t$ such that $\cos(t)$ is negative. Here's what I know $$\cos(x) := \sum_{n=0}^\infty{x^{2n}(-1)^n\over(2n)!}, \;\;(x\in\mathbb R)$$ $${d\over dx}\cos(x) = -\sin(x)$$ $$\cos\left({\pi\over2}\right) = 0, \;\; \cos(0) = 1,$$ $$\sin\left({\pi\over2}\right) = 1, \;\; \sin(0) = 0.$$ I should also specify : The only thing I know about ${\pi\over2}$ is that it is the smallest positive number such that $\cos(\cdot)$ vanishes. Here's what I tried so far: Since ${d\over dx}\cos(x) = -\sin(x)$ for all $x\in\mathbb R$, we use the fact that $\sin(\pi/2) = 1$ to give us $$\left.{d\over dx}\cos\left(x\right)\right|_{x = {\pi\over2}} = -\sin\left({\pi\over2}\right) = -1.$$ So $\cos(x)$ is decreasing at $x={\pi\over2}$. Using the fact that $\sin(\cdot)$ and $\cos(\cdot)$ are continuous (since differentiable $\implies$ continuous), we know that ( and here's where I'm not sure ) there exists $\epsilon > 0 $ such that $\cos\left({\pi\over2} + \epsilon\right) < 0$. Call $t = {\pi\over2} + \epsilon > 0$. This completes the proof. Is there enough justification to make this claim? Since $\sin(\cdot)$ is continuous on $\mathbb R$, for some $\epsilon > 0$ we have $\left.{d\over dx}\cos(x + \epsilon)\right|_{x={\pi\over2}} = -\sin({\pi\over2}+\epsilon) < 0$. Hence $\cos(\cdot)$ is still decreasing at ${\pi\over2} + \epsilon$, and since $\cos({\pi\over2})=0$, it must be that $\cos(t) = \cos({\pi\over2}+\epsilon) < 0 $.","['derivatives', 'real-analysis', 'trigonometric-series', 'proof-verification']"
2208294,"Why does limit $\lim_{(x,y) \to (0,0)}\frac{2x}{x^2+x+y^2}$ not exist?","I don't understand how this limit doesn't exist. \begin{align*} 
\lim_{(x,y) \to (0,0)}\dfrac{2x}{x^2+x+y^2}&= \lim_{r \to 0}\dfrac{2r\cos\theta}{r^2\cos^2\theta+r\cos\theta+r^2\sin^2\theta}\\
&=\lim_{r \to 0}\dfrac{2r\cos\theta}{r^2+r\cos\theta}\\
&=\lim_{r \to 0}\dfrac{2\cos\theta}{r+\cos\theta} \\
&= 2
\end{align*} I find that limit goes to $2$. But by WolframAlpha , limit does not exist. How does that work ? Thanks in advance.","['multivariable-calculus', 'calculus', 'limits']"
2208313,Is the derivative of a function bigger or equal to $e^x$ will always be bigger or equal to the function ?!,"It seems to be the case, but i don't have a proof. Given the function $f$ such that $f(x) \geq e^x$, is it true that $f'(x) \geq f(x)$?! I was experimenting with wolfram and it appears that $\frac{f'(x)}{f(x)} \geq 1$ whenever $f$ is bigger or equal to $\exp(x)$. Note : as suggested in the comments, i meant that for all positive $x$ which means that $f(x) \geq e^x \space \forall x$ such that $x\ge 0$.","['derivatives', 'inequality', 'functional-inequalities', 'functions']"
2208348,stein equation proof,"This time I want to prove the stein equation for the 1D gaussian version which is stated below: A random variable X follows the standard normal distribution (i.e x ~ N(0,1))
  if and only E[f'(x) - xf(x) ]= 0     for all smooth function f
      where f'(x) means the derivative of f The proof for the left to the right direction is straightforward. The question is about the converse proof. Following is my proof and I am stuck in some weird conclusion. Please check where the error is. First, denote the distribution of x by p(x) i.e x~ p 1) let $f'(x) - xf(x) = g(x) - E_q[g(x)]$ for some function g(x) and some arbitrary distribution q 2) f can be obtained with a 1d differential equation by multiplying $e^{(-x^2/2)}$ to the both side when f has a proper zero-boundary condition. Then $f(x) = e^{x^2/2}\int_{-\infty}^x(g(t) - E_q[g(t)])e^{-t^2/2}dt$ That is, I can get the proper function f when g(x) is given. 3) let $g(x) = 1(x<=x_0)$ where 1 means the indicator Then, by the condition we have $0 = E_p[f'(x) - xf(x)] = E_p[ g(x) - E_q[g(x)] ] = E_p[g(x)] - E_q[g(x)] = p(x<=x_0) - q(x<=x_0)$ 4) Finally, we get $p(x) = q(x)$ because for any $x_0,  p(x<=x_0) = q(x<=x_0)$ satisfies. Then the conclusion is that the distribution of p is equivalent to any arbitrary distribution, not standard normal distribution.","['probability-theory', 'probability', 'operator-theory', 'normal-distribution']"
2208385,Why $x^{p^n}-x+1$ is irreducible in ${\mathbb{F}_p}$ only when $n=1$ or $n=p=2$,"I have a question, I think it concerns with field theory. Why the polynomial $$x^{p^n}-x+1$$ is irreducible over ${\mathbb{F}_p}$ only when $n=1$ or $n=p=2$ ? Thanks in advance. It bothers me for several days.","['finite-fields', 'abstract-algebra', 'irreducible-polynomials', 'polynomials']"
2208391,Is there a ring isomorphism between $M_n(D)$ and $M_m(D)$ where $n\neq m$ and $D$ is a division ring?,"Is there a ring isomorphism between $M_n(D)$ and $M_m(D)$ where $n\neq m$ and $D$ is a division ring? I know that this is impossible if we talk about left $D$-vector space homomorphisms (because of dimension over $D$ must be the same).
What if we think about just a ring isomorphism?","['abstract-algebra', 'ring-theory', 'linear-algebra']"
2208428,Local center manifold,"Consider the system
$$
x'=x^2, \quad  y'=y
$$
and find the local center manifold of the equilibrium $(0,0)$. The linearization matrix is
$$
A=\begin{pmatrix}0 & 0\\0 & 1\end{pmatrix},
$$
hence the eigenvalues are $\lambda_1=0$ and $\lambda_2=1$. The center space is spanned by the eigenvector belonging to $\lambda_1$, say $v=(1,0)$. Hence the $x$-axis should be the center space. But what is the center manifold? Since the center manifold $W_c$ should be tangent to the x-axis in point (0,0), my idea would be to write
$$
W_c=\left\{(x,y): y=h(x)\right\}, \text{with }h(0)=0, h'(0)=0
$$ and then to make some ansatz like second order approximation: $$
h(x)=ax²+O(\lvert x\rvert³).
$$ Do we then get that $h(x)=0$ is a second order approximation of $W_c$, i.e. $W_c$ is the x-axis?","['manifolds', 'ordinary-differential-equations', 'dynamical-systems']"
2208429,Exact norm of matrix exponential,"It seems that there is no way of computing $$ \lVert e^{tA}\lVert $$ for an arbitrary real square matrix $A$ and any matrix norm $\lVert\cdot\lVert$, in terms of $t \in \mathbb{R}$ and $\lVert A \lVert$, i.e. $$f:(t,\lVert A \lVert ) \mapsto \lVert e^{tA}\lVert$$ without explicitly performing the matrix exponential (exactly or approximately). Is that right? Because so far I could only find upper-bound estimates. If this problem in its full generality is not solved, can anyone say something about its solvability? For my particular case it would suffice to restrict to the case $$A=A^\mathrm{T}, \quad \mathrm{tr}(A) = 0$$
meaning $\left(e^A\right)^\mathrm{T} = e^A$ and $\det(e^A) = 1$. Thanks for any suggestions. edit: since it is very unlikely that such an $f$ exists, I think the requirement should be eased to
$$f:(t, A  ) \mapsto  \lVert e^{tA} \lVert$$
just somehow circumventing exponentiation.","['matrices', 'normed-spaces', 'matrix-calculus', 'matrix-exponential', 'linear-algebra']"
2208443,Find derivative of Taylor series,"How would one differentiate a function in this form? $$f(x) = f(a)+{\frac {f'(a)}{1!}}(x-a)+{\frac {f''(a)}{2!}}(x-a)^{2}+{\frac {f'''(a)}{3!}}(x-a)^{3}$$ I'm sorry if this is something obvious, I'm not great with maths. I tried searching for the answer with no luck.","['derivatives', 'taylor-expansion']"
2208465,Is $\displaystyle\lim_{x\rightarrow y}\dfrac{\cos x-\cos y}{x^2-y^2}$ equal to $-\dfrac 12$ or just $-\dfrac{\sin y}{2y}$,"Question:
$$\lim_{x\rightarrow y}\dfrac{\cos x-\cos y}{x^2-y^2}=?$$
Here is my try:
\begin{align}\lim_{x\rightarrow y}\dfrac{\cos x-\cos y}{x^2-y^2}&=\lim_{x\rightarrow y}\dfrac{-2 \sin (\frac 12(x+y))\sin (\frac{1}{2}(x-y))}{(x+y)(x-y)}\\
&=-\dfrac{2 \sin y}{2y}\dfrac 12\\
&=-\dfrac{\sin y}{2y}\end{align} My question: Is $-\dfrac{\sin y}{2y}$ the final answer or can it be calculated further as $-\dfrac12$? I also try different route:
Let $p=x-y$ so $x=p+y$ and $p\rightarrow 0$ as $x \rightarrow y$. Hence, \begin{align}\lim_{x\rightarrow y}\dfrac{\cos x-\cos y}{x^2-y^2}&=\lim_{p\rightarrow 0}\dfrac{\cos (p+y)-\cos y}{p^2+2py+y^2-y^2}\\\\
&=\lim_{p\rightarrow 0}\dfrac{-2 \sin (\frac{1}{2}(p+2y))\sin (\frac{1}{2}p)}{p(p+2y)}\\\\
&=\lim_{p\rightarrow 0}\dfrac{-2 \sin (\frac{1}{2}(p+2y))}{(p+2y)} \dfrac{\sin (\frac{1}{2}p)}{p}\\\\
&=-\dfrac{2\sin y}{2y} \dfrac{1}{2}\\\\
&=-\dfrac{\sin y}{2y}\end{align} Okay, so that left me with the same result. What is the correct final answer, $-\dfrac{\sin y}{2y}$ or $-\dfrac 12$? Thanks","['limits-without-lhopital', 'limits']"
2208468,Self-intersection removal in offset curves,"When you compute offset curves (also called parallel curves ), by offsetting a fixed distance along the normals to a given curve, the resulting curve self-intersects when the offset distance exceeds the radius of curvature (see below). I am looking for a practical way to detect and remove the inner ""pockets"" that appear. The output should be a continuous curve with the self-intersection replaced by a corner point. My curves are actually cubic arcs, but I work with flattening and discrete points, so one can see the curve as a smooth polyline. In a variant of the question, the offset is also varying along the curve. Update : There is a straightforward way to detect the cusps: they arise where the radius of curvature equals the offset distance. In the discrete setting, the osculating circle can be approximated by the circumscribing circle of three consecutive vertices. In the figure, you see offset vertices, which are in red when the estimated curvature is smaller than the offset. This principle allows to find evidence of self-intersections. I suspect that the ""ladder"" formed by the initial polyline and the corresponding offsetted points can help find the intersection efficiently.","['computational-geometry', 'geometry']"
2208489,The Miller-Rabin Test clarification,"I'm teaching myself cryptography but have realised that it has a lot of number theory as a part of it, one area which I'm a bit confused over is the Miller-Rabin test and how to use it in questions. A question which I have come across is: Prove that $ n^2=4 \space mod \space p $ if $p$ {is an odd prime?} then there are two solutions $ n = \pm2 $ if $ p $ is an odd prime Find an example of p where $n^2 = 9 \space mod \space p$ has one solution for $n \space mod \space p$ the part in curly brackets is missing from the question I am assuming that this is a mistake and what is inside the brackets should, in fact, be there. Any help with this question would be extremely helpful and really appreciated! EDIT: Forgot to add in this line: The Miller-Rabin Test uses the fact that the only two solutions to the equation $n^2=1 \space mod \space p$ are $ n=\pm1 $ if $p$ is an odd prime","['number-theory', 'cryptography', 'prime-numbers']"
2208502,Neighbours in a circle with similar interests,"I've tried this problem (from British FST $2011$) for a long time, with an induction and swapping approach, but nothing has worked. Any ideas please? Problem: There is a conference attended by $512$ mathematicians, who have been assigned to share $256$ twin rooms. Each is interested in some subset of the following nine subjects: algebraic topology, Banach spaces, combinatorics, differential manifolds, Euclidean geometry, fluid dynamics, group theory, harmonic analysis and inequalities. Every mathematician has a distinct set of interests (so, in particular, one is interested in nothing, and one in everything). Show that, at the conference dinner, they can be sat in one big circle such that everyone is sat next to his roommate, and such that, if two people are sat next to one another who are not roommates, then they have sets of interests which are identical except for one subject.",['combinatorics']
2208530,"Proof that ${2x\over 2x-1}={A(x)\over A(x-1)}$ for every integer $x\ge2$, where $A(x)=\sum\limits_{n=0}^\infty\prod\limits_{k=0}^n\frac{x-k}{x+k}$","Let $x\ge2$ denote an integer. Consider:
  $$A=1+{x-1\over x+1}+{(x-1)(x-2)\over (x+1)(x+2)}+{(x-1)(x-2)(x-3)\over (x+1)(x+2)(x+3)}+\cdots\tag1$$
  and 
  $$B=1+{x-2\over x}+{(x-2)(x-3)\over x(x+1)}+{(x-2)(x-3)(x-4)\over x(x+1)(x+2)}+\cdots\tag2$$
  How does one show that $${2x\over 2x-1}={A\over B}\ ?$$ An attempt: consider $(x)^n=x(x+1)\cdots(x+n-1)$ and $(x)_n=x(x-1)\cdots(x-(n-1))$. One can re-write $(1)$ as
$$A=x+{(x)_2\over (x)^2}+{(x)_3\over (x)^3}+{(x)_4\over (x)^4}+\cdots\tag3$$
and $(2)$ as
$$x+x(x-1)B=x+(x)_2+{(x)_3\over x}+{(x)_4\over (x)^2}+{(x)_5\over (x)^3}+\cdots\tag4$$
but I am not sure how to continue.","['products', 'sequences-and-series']"
2208532,Category theoretic proof that $\mathbb{N}$ is infinite,"I have been going through the proof of Theorem 9.4 in ""Sets for Mathematics"" by Lawvere and Rosebrugh, which proves that $1+\mathbb{N} \cong \mathbb{N}$, but I am a little confused over how to prove from that, that the successor map $\sigma:\mathbb{N} \rightarrow \mathbb{N}$ is not surjective, which is the exercise 9.15. I know from corollary 9.6 in the book that $\sigma: \mathbb{N} \to \mathbb{N}$ is injective since the predecessor map $p$ is a retraction for $\sigma$. The definition of infinite is that of Dedekind, i.e. a set $X$ is infinite if there exists an $s:X \to X$ which is injective but not surjective. Now, I though about using proof by contradiction, so that I suppose that $\sigma$ surjective, and get a contradiction from the fact that $\sigma$ surjective implies that $\sigma(n)=0$ for some $n$, but the proof of theorem 9.4 doesn't immediately suggest any relevant angle of attack on the problem. In the proof of 9.4, one proves that $1+\mathbb{N} \cong \mathbb{N}$ by constructing an inverse $g:\mathbb{N} \to 1 + \mathbb{N}$ to the unique $f:1+\mathbb{N} \to \mathbb{N}$ via recursion. $g$ can be shown to satisfy: $$ g(0) = i_\ast$$
$$ g(n+1)=i_\mathbb{N}(n)$$ Where $i_\ast:1 \to 1+\mathbb{N}$ and $i_\mathbb{N}:\mathbb{N} \to 1+\mathbb{N}$ are the injections into $1 + \mathbb{N}$. $1$ denotes the terminal object in the category of sets, and $\mathbb{N}$ is a natural numbers object in the category of sets. All morphisms in the category are supposed to be total functions. Many thanks in advance!","['category-theory', 'elementary-set-theory']"
2208568,Finding two points B and C such that the perimeter of triangle ABC is minimal,"Given an acute angle XOY and an interior point A. Find a point B on the side OX and a point C on the side OY such that the perimeter of the triangle ABC is minimal.
  Hint: Introduce points symmetric to A with respect to the sides of the angle. I found this problem in Kiselev's Geometry: Planimetry. I do not know what a minimum perimeter looks like or how it appears in algebraic form.","['euclidean-geometry', 'triangles', 'geometry']"
2208575,Solve the differential equation $\frac{dy}{dx} - xy=1$,Solve the differential equation $\frac{dy}{dx} - xy=1$ given $y(0)=1$ The given differential equation is a first order linear differential equation of the form $\frac{dy}{dx} + Py=Q$ The integrating factor is $$e^{\int Pdx}=e^{-\int xdx}=e^{-\frac{x^2}{2}}$$ Solution is $$ye^{-\frac{x^2}{2}}=\int e^{-\frac{x^2}{2}}dx + c$$ But how do I integrate the second term?,"['ordinary-differential-equations', 'calculus']"
2208577,Find all meromorphic functions $f: C \to C$ s.t. $|f(z)|=1$ wherever $|z|=1$,"Problem. Find all meromorphic functions $f: C \to C$ s.t. $|f(z)|=1$ wherever $|z|=1$ . $f(z)$ should be like $f=g(z)/h(z)$ , where $g(z)$ , $h(z)$ are holomorphic functions. I know that if $f(z)$ is also meromorphic at infinity, then it is easy to conclude that $f(z) = g(z)/h(z)$ , where $g(z)$ , $h(z)$ are polynomials. But now this condition is not satisfied, so I was stuck. Thanks for opinion.","['complex-analysis', 'meromorphic-functions']"
