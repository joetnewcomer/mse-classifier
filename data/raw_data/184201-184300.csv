question_id,title,body,tags
3381730,Some basic doubts about partial differentiation - PART II,"This is a continuation of Some basic doubts about partial differentiation . Doubt #3 : : Let us say that we have $f=f(x_1,x_2,....,x_n)$ where $x_i \in R$ . Is the following equation always true ? $$df=\frac {\partial f}{\partial x_1}dx_1+....+\frac {\partial f}{\partial x_n}dx_n$$ Doubt #4 : : Let $h=h(x,y,z)$ where $z$ itself is a function of the independent variables $x$ and $y$ , i.e., $z=z(x,y)$ . Which of the following equations is true ? $$ dh=\frac{\partial h}{\partial x}dx + \frac{\partial h}{\partial y}dy + \frac{\partial h}{\partial z}dz\,\,\,\,(1)$$ $$dh=\frac{\partial h}{\partial x}dx + \frac{\partial h}{\partial y}dy  \,\,\,\,(2)$$ I wrote Equation $(1)$ thinking that $h$ depends on $x, y$ and $z$ . I wrote Equation $(2)$ thinking that because $z$ can be expressed in terms of $x$ and $y$ , $h(x,y,z)$ is basically a function of only $x$ and $y$ . But I can not decide which of these two equations is actually correct. $\frac {\partial h}{\partial z}$ means differentiating $h$ wrt $z$ while holding $x$ and $y$ constant. But if $x$ and $y$ are constant, doesn't that mean that $z=z(x,y)$ is also a constant ? Does $\frac {\partial h}{\partial z}$ even mean anything here ? NOTE : As you can clearly see by the nature of my doubts, I am just a beginner in multivariable calculus. So please answer in simple terms. Thanks in advance :-).","['partial-derivative', 'multivariable-calculus', 'calculus', 'derivatives']"
3381733,Has this series for $\ln(2)$ been discovered yet?,"$$\ln(2)=\frac{1}{2}+\frac{1}{4}-\frac{1}{5}+\frac{1}{6}-\frac{1}{9}+\frac{1}{10}-\frac{1}{11}+\frac{1}{12}-\frac{1}{13}+...$$ This is something I came up with and was intrigued, and no this isn't random; there's a pattern to this. Since you guys are asking for a relation, here it is; $$\ln(2)=1+\sum_{n=1}^∞ \frac{(-1)^{S_n-1}}{S_n-1} $$ Where $S_n$ is the $n$ -th number that is not a perfect power ( A007916 , and $S_1$ is $2$ ). Proof to this is also somewhat easy to derive.","['number-theory', 'logarithms', 'math-history', 'sequences-and-series']"
3381785,How many odd coefficients will there be when expanding $(x^2+x+1)^{33}$,"How many odd coefficients will there be when expanding $(x^2+x+1)^{33}$ This question seems hard to me because of the $x^2$ . I tested it out on wolfram alpha and I got $6$ odd coefficients (coefficients of $x^0 \text{, } x^1 \text{, }x^2 \text{, } x^{64} \text{, } x^{65} \text{, } x^{66}$ ). I tried to use logic to see the different ways of getting $x^n$ but I am unable to keep track as we can go all the way to $x^{66}$ . Is there any simple and algebraic way to prove it. Thank you anyways.",['algebra-precalculus']
3381786,Derivation with polar coordinate [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Let $f(x)$ be a defined function $\mathbb{R}^2$ using polar coordinate by $\frac{r^6}{(\log(r))^3}(1+\cos(\theta))$ when $r>1$ . Please help me to calculate $\partial_x^{\alpha}f(x)$ for all $x\in\mathbb{R}^2$ and all $\alpha\in\mathbb{N}^2$ with $1\le |\alpha|\le 3$ . Merci de m'aider","['calculus', 'derivatives', 'polar-coordinates', 'partial-differential-equations']"
3381795,What's the difference between deciding if a mathematical statement is true VS proving it?,"Isn't a statement only true if you can prove it? Edit: To elaborate, when reading about foundations of math, there seems to be concepts of completeness and decidability that seems to suggest they are proving and deciding if true are different...","['elementary-set-theory', 'logic']"
3381799,Counting Problem: How to distribute 20 donuts to 6 kids where you have 4 types of donuts (No restriction on type or number of donuts),"The difficulty in this question is the fact that there are 4 types of donuts. If there was just one type of donut then the question is relatively simple using either bars and stars or generating functions. But when you introduce types of donuts, it gets a bit confusing (for me at least): To pick 20 donuts of which there are 4 types is equivalent to the number of integer solutions to $$n_a+n_b+n_c+n_d = 20, n_i \geq 0$$ For each selection, we now need to distribute the 4 types of donuts to every kid (clearly each kid is distinct). So this is equivalent to the number of integer solutions of $$k_1+k_2+k_3+k_4+k_5+k_6 = n, n\in \{n_a,n_b,n_c,n_d\}$$ Obviously, solving this exhaustively isn't feasible (i.e. for every solution of 1. get number of ways of doing 2. and sum). Is there any combinatorics trick I'm not seeing. Studying for an exam.",['combinatorics']
3381801,Expectation as product measure,"I am reading a result that for a nonnegative random variable $X$ on $(\Omega, \mathcal{F}, P)$ , $EX = (P \times  \lambda)\{(\omega,x): 0 \leq x \leq X(\omega)\}$ , where $\lambda$ is the Lebesgue measure. What is the intuition behind this?","['product-space', 'lebesgue-measure', 'probability-theory']"
3381815,Weierstrass elliptic functions and ordinary differential equations,"I am studying Elliptic functions for a University project with a particular focus on Weierstrass's theory. For the past few weeks I have been studying various basic properties of the $\wp$ function (the majority of the Elliptic functions section in Whittaker and Watson). Finally, I have come to the point were I want to choose a particular topic. Ideally, I don't want my paper to become just a list of standard theorems that can already be found in the standard references so I have been trying to find something interesting and challenging. In searching for a project idea, I found that according to wikipedia : ""Genus one solutions of ordinary differential equations can be written in terms of Weierstrass's elliptic functions"" This sounds very attractive to me but I have been unable to find references to unpack exactly what is meant. Does a genus 1 ODE mean one whose associated curve is genus 1? If any one could explain the above statement and provide some references to further pursue this strain of knowledge I would be very grateful. Thanks","['elliptic-curves', 'ordinary-differential-equations', 'reference-request', 'elliptic-functions', 'modular-forms']"
3381823,Domain and form of a composition,"I'm trying to do the following composition: $f:y=\frac{s+1}{s-1}$$,$ $g:y=\sqrt{s}$ My solution: $Dg\circ f = (-\infty;-1] \cup(1;\infty) $ $g\circ f: y= \sqrt{\frac{s+1}{s-1}}$ Is my solution correct? Thanks!","['calculus', 'functions']"
3381824,What is integration of $\csc (\pi \sqrt y )$,"I have given an O.D.E $$\frac{dy}{dt}=\sin(\pi\sqrt y)$$ We can solve this by doing $$\frac{1}{\sin(\pi\sqrt y) }\;dy=dt$$ and then integrating each side $$\int\frac{1}{\sin(\pi\sqrt y) }\;dy=\int dt$$ $$\int \csc(\pi\sqrt y)\;dy= \int dt$$ after that i put $\pi\sqrt y=z$ , $\;$ I am getting eqaution like $$\frac{2}{\pi^{2}}\int {\csc(z).z}=\int dt$$ further this i am not able to solve I applied the method of integration by parts but not getting anywhere Please help Thnkyou","['integration', 'ordinary-differential-equations', 'real-analysis']"
3381835,"Show that $\log_7 (n)$ is either an integer or irrational, where n is a positive integer.","I'm self-studying and a beginner in proofs and here's my take. Let x be the logarithm of 7 to base n where n is an integer.
Then $7^x = n$ . If n is an integer, then x should be any nonnegative integer, that is $ x \geq 0$ . Thus $\log_7 (n)$ is an integer. Is this enough for the integer part? I'm certain that this does not answer the irrational part. Also when it says on the question '..either an integer or irrational', does the 'integer' mean that it includes negative integers? Thanks a lot!","['elementary-number-theory', 'proof-verification', 'discrete-mathematics', 'logarithms']"
3381871,"How can a ""proper"" function have a vertical slope?","Plotting the function $f(x)=x^{1/3}$ defined for any real number $x$ gives us: Since $f$ is a function, for any given $x$ value it maps to a single y value (and not more than one $y$ value, because that would mean it's not a function as it fails the vertical line test).
This function also has a vertical tangent at $x=0$ . My question is: how can we have a function that also has a vertical tangent? To get a vertical tangent we need 2 vertical points, which means that we are not working with a ""proper"" function as it has multiple y values mapping to a single $x$ . How is it possible for a ""proper"" function to have a vertical tangent? As I understand, in the graph I pasted we cannot take the derivative of x=0 because the slope is vertical, hence we cannot see the instantaneous rate of change of x to y as the y value is not a value (or many values, which ever way you want to look at it). How is it possible to have a perfectly vertical slope on a function? In this case I can imagine a very steep curve at 0.... but vertical?!? I can't wrap my mind around it. How can we get a vertical slope on a non vertical function?","['tangent-line', 'graphing-functions', 'calculus', 'functions', 'derivatives']"
3381889,Congruence of angles axiom,"In my geometry book, the following statement is provided as axiom of congruence. Let $ABC$ and $A'B'C'$ be two triangles. If $AB \equiv A'B'$ , $AC \equiv A'C'$ and $ \angle BAC \equiv B'A'C'$ then $ \angle ABC \equiv A'B'C'$ I honestly have no idea where this comes from. Note that we use this axiom to prove $SSS$ , $ASA$ and $SAS$ . Could someone provide intuition for something like this? It has to be obvious if it's used as an axiom.. right? I'm having trouble memorising something like that and using it to prove things. Not to mention the order here is extremely important. EDIT:
As an extra note in the book it says, if we change it to $AC \equiv A'C'$ , $ AB \equiv A'B'$ and $\angle CAB = \angle C'A'B'$ then $\angle ACB \equiv \angle A'C'B'$","['congruences-geometry', 'geometry', 'axioms']"
3381911,"Show that if $Z_{n}-X_{n}$ converges weakly to $0$ and $Z_{n}$ converges weakly to $Z$, then $X_{n}$ converges weakly to $Z$.","This post is about my extended thought after I did the (depending on the editions) Exercise 2.2.10 or Exercise 2.2.13 of Durrett . The exercise itself states as follow: Let $\{X_{n}\}_{n=1}^{\infty}$ , $\{Y_{n}\}_{n=1}^{\infty}$ , $X$ be random variables on $(\Omega,\mathcal{F})$ and $c\in\mathbb{R}$ be such that $X_{n}\Rightarrow X$ and $Y_{n}\Rightarrow c$ . Show that Deduce that $X_{n}+Y_{n}\Rightarrow X+c$ . Then, he commented that If $X_{n}\Rightarrow Z$ and $Z_{n}-X_{n}\Rightarrow 0$ , then $Z_{n}\Rightarrow Z.$ I proved this exercise and convinced myself of this comment, since if $X_{n}\Rightarrow Z$ , and $Z_{n}-X_{n}\Rightarrow 0$ . Then by the exercise, it follows immediately that $$Z_{n}=X_{n}+(Z_{n}-X_{n})\Rightarrow Z+0=Z.$$ However, I am thinking about if this is sufficient and necessary, i.e. If $Z_{n}-X_{n}\Rightarrow 0$ , then $Z_{n}\Rightarrow Z$ if and only if $X_{n}\Rightarrow Z.$ The comment in Durret is about $(\Leftarrow)$ , but I don't know how to show the converse. If we want to use the same techniques, we will have $$Z_{n}+(Z_{n}-X_{n})\Rightarrow Z,$$ but not the RHS cannot give us $X_{n}$ . Therefore, I think this breaks down the question to whether $Z_{n}-X_{n}\Rightarrow 0$ implying $X_{n}-Z_{n}\Rightarrow 0$ is true. I tried to show it but I failed. Any idea? By the way, $(\Rightarrow)$ is weak convergence.","['convergence-divergence', 'probability-distributions', 'probability-theory', 'weak-convergence']"
3381919,How to verify whether function is surjective or injective,I'm trying to learn how to verify whether a certain function is surjective / injective. $g:\mathbb{R}\rightarrow \mathbb{R}$ $g(x)= 2x^5 +9$ How would I do so? Thanks,"['calculus', 'functions']"
3381951,"For finite sets (groups) are order, size, cardinality and power the same thing?","In section IB3.5, beginning on page 186 of The Fundamentals of Mathematics, Volume 1 , the terms order and power of a finite group are used. In the first part of the book the power of a finite group is said to be its cardinality which, for a finite set is the whole number of elements in the set.  That is what I like to call the size of the set.  I'm not sure what to make of the order of a subgroup of a finite group $\mathfrak{G}$ is always a factor of the order of $\mathfrak{G}$ . I believe it simply means the number of elements in a subgroup of $\mathfrak{G}$ will always divide evenly into the number of elements in $\mathfrak{G}$ . At this point we apparently have index, size, order, power and cardinality used to indicate the number of elements in a set under specific condition. Am I correct in understanding that power and order mean the same thing in this context, and that thing is the number of elements in the set?","['elementary-set-theory', 'group-theory', 'definition', 'permutations']"
3381956,prove that ${3^{3n}} + 3^{2n} + 3^{n } + 1$ is divided by $4$. by induction,I tried to take the 3 out but it is not helping me much.,"['elementary-number-theory', 'induction', 'discrete-mathematics']"
3382002,Find the distribution of $X|Y =k$ given the distribution of $Y|X =x$,"Good night, I'm trying to find the p.d.f of $Y$ and $X|Y=k$ , and $\mathbb E (X|Y=k)$ in the following exercise: Could you please verify if my attempt is correct or contains logical mistakes? Thank you so much for your help! My attempt: First, we have $$\begin{aligned} & \int_0^1 {n \choose k}  x^k (1-x)^{n-k}  \, \mathrm{d}x &&= {n \choose k} \int_0^1  x^{(k+1)-1} (1-x)^{(n-k+1)-1}  \, \mathrm{d}x \\ &= {n \choose k} B(k+1,n-k+1) &&= \frac{n!}{(n-k)!k!} \frac{k!(n-k)!}{(n+1)!} \\ &= \frac{1}{n+1} \end{aligned}$$ and $$\begin{aligned} & \int_0^1 {n \choose k} x^{k+1} (1-x)^{n-k}  \, \mathrm{d}x &&= {n \choose k} \int_0^1  x^{(k+2)-1} (1-x)^{(n-k+1)-1}  \, \mathrm{d}x \\ &= {n \choose k} B(k+2,n-k+1) &&= \frac{n!}{(n-k)!k!} \frac{(k+1)!(n-k)!}{(n+2)!} \\ &= \frac{k+1}{(n+2)(n+1)} \end{aligned}$$ We have $X \sim \mathcal U([0,1])$ and $(Y|X=x) \sim \mathcal B(n,x)$ . Then $f_{Y|X} (k|x) = {n \choose k} x^k (1-x)^{n-k}$ and so $$\begin{aligned} f_Y (k) &= \int_{\mathbb R} f_{Y|X} (k|x) f_X (x) \, \mathrm{d}x  &&= \int_{\mathbb R} {n \choose k} x^k (1-x)^{n-k} \frac{1}{1-0} \textbf{1}_{[0,1]} (x) \, \mathrm{d}x \\&= \int_0^1 {n \choose k} x^k (1-x)^{n-k}  \, \mathrm{d}x  &&=  \frac{1}{n+1} \end{aligned}$$ As such, $Y$ is uniformly distributed discrete random variable with $\operatorname{supp} (Y)= \{0,\ldots,n\}$ . We have $$\begin{aligned} f_{X|Y} (x,k) &= \frac{f_{Y|X} (k|x) f_X(x)}{f_Y (k)} \\ &= \frac{{n \choose k} x^k (1-x)^{n-k} \frac{1}{1-0} \textbf{1}_{[0,1]} (x)}{\frac{1}{n+1}}\\ &= (n+1) {n \choose k} x^k (1-x)^{n-k} \textbf{1}_{[0,1]} (x) \end{aligned}$$ As such, $$\begin{aligned} \mathbb E (X|Y=k) &= \int_\mathbb R x f_{X|Y} (x,k)  \, \mathrm{d}x \\ &= \int_\mathbb R x (n+1) {n \choose k} x^k (1-x)^{n-k} \textbf{1}_{[0,1]} (x)  \, \mathrm{d}x \\ &= (n+1)  \int_0^1 {n \choose k} x^{k+1} (1-x)^{n-k} \, \mathrm{d}x \\ &= (n+1) \frac{k+1}{(n+2)(n+1)} = \frac{k+1}{n+2}\end{aligned}$$","['conditional-probability', 'proof-verification', 'probability-theory', 'probability-distributions']"
3382078,Do either of $c\cdot I_n-A$ or $A-c\cdot I_n$ have a name?,"Let $A$ be an $n\times n$ matrix and let $c$ be a scalar. The matrices $c\cdot I_n-A$ and $A-c\cdot I_n$ are used to say interesting things about $A$ . Do either of $c\cdot I_n-A$ and $A-c\cdot I_n$ have a name? It seems like calling $A-c\cdot I_n$ something like the ""shift of $A$ by a factor of $c$ "" makes sense, but ""shift matrices"" usually refer to binary matrices whose only nonzero entries are either on the superdiagonal or subdiagonal. I suppose it's also worth asking if either of $c\cdot I-T$ or $T-c\cdot I$ have a name if $T:V\to V$ is a linear endomorphism of a vector space $V$ and $I:V\to V$ is the identity.","['matrices', 'notation', 'linear-algebra', 'terminology']"
3382083,Group presentations and isomorphism?,"I am reading Dummit and Foote, and they have only introduced group presentations very informally, so I am worried about the technicalities. I have to prove that the subgroup of $SL_2(\mathbb{F}_3)$ generated by $$A = \begin{bmatrix}
0 & -1\\
1 & 0
\end{bmatrix}
\hspace{2cm}
B = \begin{bmatrix}
1 & 1\\
1 & -1
\end{bmatrix}
$$ is isomorphic to $Q_8$ . I know that one presentation of $Q_8$ is $$Q_8 = \langle -1, i, j, k|(-1)^2=1, i^2=j^2=k^2=ijk=-1 \rangle.$$ Now, if we identify $A$ with $i$ , $B$ with $j$ , $AB$ with $k$ , and $-1$ with $-I$ (where $I$ is the identity matrix, and I can prove that both $I$ and $-I$ are in my subgroup of matrices), then my matrices satisfy the same relations as the ones in my group presentation for $Q_8$ . My question is, am I done? Is this enough to show that the two groups are isomorphic? Or is there something I am missing?","['group-presentation', 'group-theory', 'abstract-algebra', 'group-isomorphism']"
3382139,Covariance inequality and strong mixing,"In this post I conclude that, for a error process $\{\epsilon_t\}$ , $\mid Cov(\epsilon_t,\epsilon_l)\mid \leq C \alpha(\mid t-l \mid)^{1/p}$ , for some constant $C$ (given conditions on the boundeness of integrals).
Now, my question is why the following statement is true: Let $\{\epsilon_t\}$ be $\alpha$ -mixing (or strongly mixing). If $\mid t-k\mid>M$ for $k\in\{a,b,c\}$ , then $\mid Cov(\epsilon_t,\epsilon_a\epsilon_b\epsilon_c)\mid\leq C'\alpha(M)^{1/p}$ for some constant $C'$ ? I don't know if there always exists an $k\in\{a,b,c\}:\mid Cov(\epsilon_t,\epsilon_a\epsilon_b\epsilon_c)\mid\leq \mid Cov(\epsilon_t,\epsilon_k)\mid$ , because then I could use $\mid Cov(\epsilon_t,\epsilon_k)\mid \leq C \alpha(\mid t-k\mid)^{1/p}\leq C \alpha(M)^{1/p}$ , since the dependence coefficient $\alpha$ is nonincreasing. On the other hand $\alpha (\sigma(\epsilon_t),\sigma(\epsilon_k:k=a,b,c))\geq \alpha(\sigma(\epsilon_t),\sigma(\epsilon_k))$ for each $k\in\{a,b,c\}$ , looking at the definition. I know this question is quite specific (stochastic process), but I would appreciate any help. Thanks!","['stochastic-processes', 'self-learning', 'probability-theory']"
3382140,"Say $E_1,...E_n\subset\{1,2,...,k\}= K$, each $|E_i|=4$ and each $j\in K$ appear in at most $3$ sets $E_i$.","Say $E_1,...E_n\subset\{1,2,...,k\}= K$ , each $|E_i|=4$ and each $j\in K$ appear in at most $3$ sets $E_i$ . We choose from each $E_i$ one number. Prove that we can do that so that a set of all choosen numbers has not more than ${3k\over 7}$ members. This was my try but the bound I get is not good and also I'm not even sure if it is correct. We choose at random from each $E_i$ independently a number with a probability $p=1/4$ (so we can chose the same number more then once) and name this number $c_i$ . Let $M$ be a set of choosen numbers and let $X=|M|$ . If $X_i$ is indicator random variable for a number $i\in K$ then $$E(X) = E(X_1)+...+E(X_k)$$ Say $i$ is in a sets $E_1,...E_{d_i}$ , where $d_i\leq 3$ , then \begin{eqnarray}E(X_i) &=& P(X_i=1) \\
&=& P(\{i=c_1\}\cup ...\cup \{i=c_{d_i}\})\\
&=&1-P(\{i\ne c_1\}\cap ...\cap \{i\ne c_{d_i}\})\\
&=&1-P(i\ne c_1)\dots P(i\ne c_{d_i})\\
&=&1-\Big({3\over 4}\Big)^{d_i}\\
\end{eqnarray} So we have $$E(X)= k-\sum _{i=1}^k\Big({3\over 4}\Big)^{d_i}\leq k-k\Big({3\over 4}\Big)^3$$ So $E(X) \leq {37k\over 64}$ which is not good enough. Anyone solve this one with a probabilistic method gets bounty 500pt .","['discrete-optimization', 'probabilistic-method', 'combinatorics', 'extremal-combinatorics']"
3382156,Real Analysis Topology Problem,"Here is a problem I have been working on for the past 2 weeks, but to no avail: Suppose that $\mathcal{F}$ is a family of open sets in $\mathbb{R}$ , with the following property: for every open set $A\subset \mathbb{R}$ such that $\mathbb{Z}\subset A$ , there exists $F\in\mathcal{F}$ such that $\mathbb{Z}\subset F\subset A$ . Show that $\mathcal{F}$ must be an uncountable family. Here the open sets are just the open sets in the metric space $(\mathbb{R},d$ ), where $d(x,y)=|x-y|$ is the Euclidean metric.","['general-topology', 'real-analysis']"
3382183,Sum of two sequences bounded in probability,"I have two sequences of random variables which are bounded in probability, denoted as $X_n=\mathcal{O}_p(\sqrt{n})$ and $Y_n=\mathcal{O}_p(\lVert\theta\rVert)$ , where $\lVert\theta\lVert=\sum_{i=1}^n\theta_i^2$ with $\theta_i \in \mathbb R$ . I would like to show that $X_n+Y_n$ = $\mathcal{O}_p(\sqrt{n+\lVert\theta\rVert^2})$ . Typically, when adding 'big O' terms, the dominant one would be all that remains. However, since $\lVert\theta\rVert$ depends on the sample size $n$ , it is not clear in this case which term dominates. The definition of bounded in probability tells us that $X_n=\mathcal{O}_p(a_n)$ if for all $\varepsilon>0$ there exists a constant $M_\varepsilon>0$ and an integer $N_\varepsilon>0$ such that $$P\left(\biggr\lvert\frac{X_n}{a_n}\biggr\lvert\geq M_\varepsilon\right)\leq\varepsilon \text{ for all } n\geq N_\varepsilon$$ Here is what I have tried to show so far. I am mostly having issues with stating the right conditions. We have that for all $\varepsilon>0$ , there exists $M_1>0$ and $N_1>0$ s.t. $P\left(\biggr\lvert\frac{X_n}{\sqrt{n}}\biggr\lvert\geq M_1\right)\leq\varepsilon \text{ for all } n\geq N_1$ . Similarly, for all $\varepsilon>0$ , there exists $M_2>0$ and $N_2>0$ s.t. $P\left(\biggr\lvert\frac{Y_n}{\sqrt{\lVert\theta\rVert^2}}\biggr\lvert\geq M_2\right)\leq\varepsilon \text{ for all } n\geq N_2$ . Note that $\{|X_n+Y_n|>M\} \subset \{|X_n|\geq M/2\}\cup \{|Y_n|\geq M/2\}$ and hence $P(|X_n|+|Y_n|>M)\leq P(|X_n|\geq M/2)+P(|Y_n|\geq M/2).$ Then we can write \begin{align}
P\left(\biggr\lvert\frac{X_n+Y_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert> M\right)&\leq P\left(\biggr\lvert\frac{X_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert+\biggr\lvert\frac{Y_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert> M\right)\\
&\leq P\left(\biggr\lvert\frac{X_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert> \frac{M}{2}\right)+P\left(\biggr\lvert\frac{Y_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert> \frac{M}{2}\right)\\
&\leq P\left(\biggr\lvert\frac{X_n}{\sqrt{n}}\biggr\lvert> \frac{M}{2}\right)+P\left(\biggr\lvert\frac{Y_n}{\sqrt{\lVert\theta\rVert^2}}\biggr\lvert> \frac{M}{2}\right)
\end{align} I would like to say that the last part $\leq \frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon \text{ for all } n \geq N$ , but I'm not sure what conditions I need on $M$ , $N$ , and $\varepsilon$ to make this true. It has been a while since I've done a real analysis course and I am not very familiar with asymptotics. I would appreciate any help!","['inequality', 'asymptotics', 'probability', 'random-variables']"
3382227,Proof writing: looking for help in precisely expressing an idea I have about combinations of pairs of distinct residue classes,"I am working on an idea which I would call ""pairs of distinct residue classes for a given set of distinct primes"" which is an attempt to count the number of possible combinations of residue classes in a given context. Here is the set that I am trying to define below: $C_{P_{p_1,\dots,p_m}}(y,n)$ While it is quite clear in my head, expressing in precise terms has proven to be quite difficult for me. Below is my attempt. I would greatly appreciate any questions or comments.  :-) Let $y, p, n$ be integers with $p$ prime. Let $c_{p,i,j}(y)$ be a boolean function that is true if $y \not\equiv i \pmod p$ and $y \not\equiv j \pmod p$ . Let $P_{p_1, \dots, p_m}$ be a set of triplets $\{p_1, i_1, j_1\}, \{p_2, i_2, j_2\}, \dots, \{p_m, i_m, j_m\}$ where each $p_k$ is distinct and each $i_k \not\equiv j_k \pmod {p_k}$ Let $C_{P_{p_1,\dots,p_m}}(y,n)$ be a boolean function that is true if there exists $t$ such that $y \le t < y+n$ and for each triplet $\{p_k, i_k, j_k\}$ in $P_{p_1, \dots, p_m}$ , it follows that $c_{p_k,i_k,j_k}(t)$ is true. My interest here is counting the number of distinct values of $P_{p_1, \dots, p_m}$ where $C_{P_{p_1,\dots,p_m}}(y,n)$ is false. For example, for $P_{5,7,11}$ : if $n=1$ , there are 7500 distinct set of triplets where $C_{P_{5,7,1}}$ is false. if $n=2$ , there are 4530 distinct sets of triplets where it is false. if $n \ge 11$ , there is no set of triplets where $C_{P_{5,7,1}}$ is false. It appears to me that the number is the same regardless of $y$ .  This is the question that I am interested in exploring. Edit: Based on comments from antkam, I realized that my definition was not correct. I have updated the definition of $c_{p,i,j}(y,n)$ to only be $c_{p,i,j}(y)$ and to be true when the value is not congruent to either $i$ or $j$ . I have also updated the definition of $C_{P_{p_1,\dots,p_m}}(y,n)$ . With these changes, I believe that my examples hold.","['proof-writing', 'combinatorics', 'modular-arithmetic']"
3382249,Closed unit ball of an infinite-dimensional Banach space is not compact,"I have a few questions about the following proof taken from https://math.berkeley.edu/~sarason/Class_Webpages/solutions_202B_assign11.pdf . Prove that the closed unit ball of an infinite-dimensional Banach space is not compact. Proof . Let $B$ be an infinite-dimensional Banach space. Choose any unit vector $x_1\in B$ , and let $A_1$ be the subspace spanned by $x_1$ . In the quotient space $B/A_1$ , choose a coset of norm $\frac{1}{2}$ and then a representative $x_2$ of that coset of norm at most 1. Then $\|x_2−x_1\| \geq \frac{1}{2}$ . Let $A_2$ be the subspace spanned by $x_1$ and $x_2$ ,and note that $A_2$ is closed. In the quotient space $B/A_2$ , choose a coset of norm $\frac{1}{2}$ and then a representative $x_3$ of that coset of norm at most 1. Then $\|x_3−x_2\| \geq \frac{1}{2}$ and $\|x_3−x_1 \| \geq \frac{1}{2}$ . Continuing in this way, we obtain a sequence $\{x_n\}$ of vectors in the closed unit ball of $B$ such that $\|x_m−x_n\| \geq \frac{1}{2}$ whenever $m\neq n$ . The sequence $\{x_n\}$ then has no convergent subsequences, implying that the closed unit ball in $B$ is not compact. My questions are: 1) How do we know that a coset with a norm $\frac{1}{2}$ exists in $B/A_1$ ? 2) Why does the closedness of $A_2$ matter? 3) Why does it matter if $B$ is a Banach space?",['functional-analysis']
3382253,How to learn without looking at solutions? (real analysis),"I have 2 weeks to do real analysis HW set, I work on them everyday, but many questions I spend hours on and cannot figure out. In the end, I google them (and feel horrible), read the proofs, and think there was no way I could've come up with that proof. I know I need to not google solutions to learn, but I can't learn without googling solutions. What to do? Or at what point is googling ok? And in an ideal world I'd spend all the time in the world on a question, but reality is my hours are limited in college. I literally count the hours I have each day, and spend them accordingly, and at some point not googling a solution is simply shooting myself in the foot for other classes.","['advice', 'real-analysis']"
3382301,Prove that $\det A$ does not exceed $1$,"Let $A =(a_{ij}) ∈  M_n(\Bbb R)$ be a matrix with nonnegative entries such that the sum of the entries in each row does not exceed $1$ . Prove that $|\det A|$ does not exceed $1$ too. This is one of my exercise,I tried to induction,but i'm stuck. 
Help me please! Thanks","['matrices', 'determinant', 'linear-algebra']"
3382341,Central Limit Theorem: $ \mathbb{E}\left|\frac{1}{N} \sum_{i=1}^{N} X_i - \mu\right| = O\left(\frac{1}{\sqrt{N}}\right)$,"I am self-studying the High Dimensional Probability book by Roman Vershynin and came across this problem: Let $X_1, X_2, \dots$ be a sequence of i.i.d random variables with mean $\mu$ and finite variance. Show that $$ \mathbb{E}\left|\frac{1}{N} \sum_{i=1}^{N} X_i - \mu\right| = O\left(\frac{1}{\sqrt{N}}\right)$$ as $N \rightarrow \infty$ I feel I need to use central limit theorem somehow but not sure how to deal with absolute value","['expected-value', 'central-limit-theorem', 'probability-theory']"
3382344,Why the Fubini theorem fail??,"Let $f(x,y)=\dfrac{x^2-y^2}{(x^2+y^2)^2}$ prove: $$\int_0^1\left(\int_0^1f(x,y)dy\right)dx=\frac{\pi}{4}\tag1$$ $$\int_0^1\left(\int_0^1f(x,y)dx\right)dy=\frac{-\pi}{4}\tag2$$ Why the Fubini theorem fail?? My attempt: For $(1)$ we have: $$\int_0^1\left(\int_0^1f(x,y)dy\right)dx=\int\int\frac{\partial}{\partial y}\left(\frac{y}{x^2+y^2}\right)=\int \frac{y}{x^2+y^2}\bigg|_{y = 0}^{y = 1}dx=\int\frac{1}{x^2+1}dx= \\ =\arctan(x)\bigg|_0^1=\frac{\pi}{4}$$ For $(2)$ we have: $$\int_0^1\left(\int_0^1f(x,y)dx\right)dy=\int\int\frac{\partial}{\partial x}\left(\frac{-x}{x^2+y^2}\right)dxdy=-\int_0^1\frac{1}{1+y^2}dy=-\frac{\pi}{4}$$ I don't have very clear why Fubini Theorem fail. Can someone help me? https://en.wikipedia.org/wiki/Fubini%27s_theorem (Fubini-Tonelli Theorem)",['measure-theory']
3382362,"Given any 2 curves, can we prove the existence of a common normal?","One suggestion would be to say the every two curves will have a distance of closest approach, and this distance will be normal to both of them, but this is either:
1)what we are actually trying to prove
2) inherently wrong in the sense, there maybe 2 curves who don't have a common normal so their distance of closest approach wouldn't be normal to them.","['algebraic-curves', 'curves', 'tangent-line', 'calculus', 'derivatives']"
3382393,How to compute the indefinite integral of $1/(1+x^2)$,"The manipulation of logarithms in $(*)$ doesn't hold over the complex numbers. I'm not deleting it, as the answers I got, and the rest of my post make no sense without it, but I also don't want to confuse anyone who may also be new to complex logarithms. I know the integral upto addition of a constant is $\tan^{-1}(x).$ And, in fact it's not hard to show. However, I'm curious about the case where you start from $1/(1+x^2),$ and without knowing $d/dx\tan^{-1}(x)=1/(1+x^2)$ solving $$\int \frac{1}{1+x^2}.$$ Let us work modulo constants, so we need not write them. Then $$\int\frac{1}{1+x^2}=\int\left(\frac{1}{2i(x-i)}-\frac{1}{2i(x+i)}\right)$$ $$=\frac{1}{2i}\left(\ln(x-i)-\ln(x+i)\right)=\frac{\ln\left(\frac{x-i}{x+i}\right)}{2i}.\text{ }(*)$$ It should be clear now that our result is purely real, as $|(x-i)/(x+i)|=1.$ Moreover, it is clear that $$\ln\left(\frac{x-i}{x+i}\right)=i\cdot\text{argument}\left(\frac{x-i}{x+i}\right).$$ Now, I know that $$\frac{x-i}{x+i}=\frac{(x-i)^2}{{x^2+1}}=\frac{x^2-1}{{x^2+1}}-\frac{2xi}{{x^2+1}}.$$ This tells us $$\tan\left(\text{argument}\left(\frac{x-i}{x+i}\right)\right)=-\frac{2x}{x^2-1}.$$ So we can deduce that $$\int\frac{1}{1+x^2}=\frac{1}{2}\tan^{-1}\left(-\frac{2x}{x^2-1}\right).$$ From here I'm not quite sure how to proceed though. How would one show that modulo constants $$\tan(x)^{-1}=\frac{1}{2}\tan^{-1}\left(\frac{-2x}{x^2-1}\right)?$$ I guess it is clear if you differentiate both, but that presumes we already had $\tan^{-1}(x)$ in mind.","['integration', 'indefinite-integrals', 'trigonometry']"
3382479,Pythagorean triplets which satisfy Euler's totient function,"Let $\varphi(x)$ be the Euler totient function and $a,b$ and $c$ be natural numbers. Question 1 : Are there infinitely many non-trivial solutions of $$
\varphi(a)^2 = \varphi(b)^2  + \varphi(c)^2  
$$ $$
\varphi(a^2) = \varphi(b^2)  + \varphi(c^2) 
$$ A trivial solution is one which is obtained multiplying a smaller solution with a constant natural number. The first few solutions are (1004, 802, 604)
(1012, 782, 644)
(1050, 840, 630)
(1056, 816, 672)
(1084, 866, 652)
(1100, 850, 700)
(1136, 904, 688)
(1144, 884, 728)
(1188, 918, 756)
(1200, 960, 720) Question 2 : Is there a triplet with at least one of the three numbers $a,b$ and $c$ odd? Related question : Pythagorean triples that “survive” Euler's totient function","['number-theory', 'divisibility', 'elementary-number-theory', 'prime-numbers']"
3382524,"Does $\lim_{(x,y) \to (0,0)} \frac{x y \sin^2 y}{x^2 y}$ exists?","$\displaystyle\lim_{(x,y) \to (0,0)} \frac{x y \sin^2 y}{x^2 y}$ Along $x =y$ , it becomes \begin{equation}
\lim_{(x,y) \to (0,0)}\frac{y^2 \sin^2 y}{y^3} = 0.
\end{equation} But along $x = y^3$ , \begin{equation}
\lim_{(x,y) \to (0,0)}\frac{y^4 \sin^2 y}{y^7} = \lim_{(x,y) \to (0,0)}\frac{ \sin^2 y}{y^3}.
\end{equation} The limit is undefined. This is what I thought, but using wolframalpha, it say the limit is $0$ . Where did I go wrong?","['multivariable-calculus', 'calculus']"
3382553,Integration by parts for fractional Ornstein-Uhlenbeck process,"I have encountered a problem in a paper called Volatility is rough by Jim Gatheral et al. A stationary fractional Ornstein–Uhlenbeck process ( $X_t$ ) is
defined as the stationary solution of the stochastic differential
equation $$dX_t = \nu dW^H_t− \alpha (X_t − m)dt$$ where $m ∈ \mathbb{R}$ and $\nu$ and $\alpha$ are positive parameters (see Cheridito et al. 2003). As for usual Ornstein–Uhlenbeck processes,
there is an explicit form for the solution which is given
by $$X_t = \nu \int^t_{−\infty}e^{−\alpha (t−s)}dW^H_t+ m  \qquad \quad (3.3) $$ Here, the stochastic integral with respect to fBm is simply a
pathwise Riemann–Stieltjes integral, see again Cheridito et al.
(2003). Proposition 3.1 Let $W_H$ be a fBm and $X^\alpha$ defined by (3.3)
for a given $\alpha > 0$ . As \alpha tends to zero, $$E\left[\sup_{t\in[0,T]}|X^\alpha_t− X^\alpha_0− \nu W^H_t|\right]\to 0$$ Then the proof goes like this: Starting from equation (3.3) and applying integration by parts, we get $$X^\alpha_t = \nu W^H_t −\int_t^{−\infty}\nu \alpha e^{−\alpha(t−s)}W^H_s ds + m$$ and some proofs that I know; it is just this part that I don't understand. So my question is: How do I even perform integration by parts for the fractional Ornstein-Uhlenbeck process in this proof. I don't see anyway how to obtain the answer by integration by parts. I'd appreciate if someone can answer or link me to somewhere that has methods/answers!","['stochastic-integrals', 'rough-path-theory', 'fractional-calculus', 'probability-theory', 'stochastic-calculus']"
3382560,Find the limit of sequence $a_{n+1} -a_{n}$,"Consider the sequence $a_{n}=\sqrt{n}+\sqrt[3]{n}+\cdots+ \sqrt[n]{n}.$ Find the limit of sequence $a_{n+1} -a_{n}.$ One of my attempts is to use the reciprocal of the Stolz-Cesaro lemma, which is true by imposing additional conditions. What is the valid solution?",['real-analysis']
3382643,"Given points $A$, $B$, $C$, $D$ in a straight line, find $O$ in the line such that $OA:OB=OC:OD$.","Given four points $A$ , $B$ , $C$ , $D$ in a straight line, find a point $O$ in the same straight line such that $OA:OB=OC:OD$ . I tried doing this by drawing a ray through $A$ and drawing lines through $B$ , $C$ , and $D$ parallel to each other. That way we get three triangles. I do not know what to do from here. Am I going in the right direction? And if no, provide a hint. Thanks",['geometry']
3382651,Boolean Algebra: How does $\bar A\bar BC+\bar A\bar C\bar D+A\bar CD+\bar AB\bar C$ become $\bar A\bar BC + \bar A\bar C\bar D+A\bar CD+B\bar CD$?,"I'm trying to understand one of the steps taken during the process of getting a cnf in Boolean algebra but I just cant understand what is happening here. $$\bar A \bar B C + \bar A \bar C \bar D +  A \bar C  D + \bar A  B  \bar C$$ $$\bar A \bar B C + \bar A \bar C \bar D +  A \bar C  D + B  \bar C D$$ It seems like they just exchange the !A for D , but I cannot understand which of the Boolean algebra laws they used. Could someone help me understand it ?","['boolean-algebra', 'propositional-calculus', 'logic', 'discrete-mathematics', 'disjunctive-normal-form']"
3382661,Verify whether a function is injective,"I'm trying to learn how to verify whether a function is injective. This is my function: $g=e^{1-y^2}-1$ How should I proceed in veryfing whether it is injective or not? In my lecture, we verified using the definition by checking whether the function is always increasing or decreasing (we started with only some part of a function and continued to add the rest of the function while always verifying whether $f(x_1)<f(x_2)$ for all $x_1<x_2$ ). However, with this function, the approach seems too difficult to do. Is there any way to verify whether it is injective or not? Thanks","['calculus', 'functions']"
3382683,The existence of a square!,"My question is the following: There exists an homeomorphism from a Moebius band to a subset of $\mathbb{R}^3$ such that $\partial M$ is mapped in a continuous closed simple curve of $\mathbb{R}^3$ contained in a plane? I've done this question because I would to prove the following interesting property: I think that this problem is well known, but I don't understand how to prove it. Let $\gamma=(\gamma_1,\gamma_2)$ be a continuous closed simple curve of $\mathbb{R}^2$ , so $\gamma:[0,1]\to \mathbb{R}^2$ is injective in $(0,1)$ , $\gamma(0)=\gamma(1)$ and it's a continuous function. The question is if there exists $4$ points $A,B,C,D$ on this curve for which the polygon $ABCD$ results to be a square. I guess is possible to prove a weaker thesis in a simple way, substituting the existence of a square with the existence of a rectangle. We know that $ABCD$ would be a rectangle if and only if $AB\cap CD=\{M\}$ where $M$ is the middle point of $AB$ and $CD$ , and $AB\cong CD$ . 
Now we can interpret this property in this way: We define the following map $F:[0,1]\times [0,1]\to \mathbb{R}^3$ that maps each couple $(a,b)$ to $F(a,b):=\left(\frac{\gamma_1(a)+\gamma_1(b)}{2},\frac{\gamma_2(a)+\gamma_2(b)}{2}, ||\gamma(a)\gamma(b)||\right)$ This map associate to each couple of points $A$ and $B$ on the curve $\gamma$ , their middle point $M$ and the distance between them. We can observe that this map is continuous and it holds the following property: $F(0,b)=F(1,b)$ ; $F(a,0)=F(a,1)$ ; $F(a,b)=F(b,a)$ ; $F(a,a)=(\gamma(a),0)$ ; We define the following equivalence relation $\sim$ on $[0,1]\times [0,1]$ : for each $(a,b), (a',b')$ we say $a\sim b \iff (a,b)=(a',b')$ or $b=b'$ , $a=0,a'=1$ or $a=a'$ , $b=0,b'=1$ or $a=b'$ , $b=a'$ It's easy to check that $[0,1]\times[0,1]/\sim$ is the Moebius band $M$ and it's boundary is the image with respect the projection map of the diagonal $\Delta:=\{(a,a): a\in [0,1]\}$ . Now we observe that the map $F$ with that $4$ property induces a natural map $F^\sim : M\to \mathbb{R}^3$ defined in the following way: $F^\sim([(a,b)]):=F(a,b)$ Is clear that $F^\sim$ is a continuous map. Moreover we have $F^\sim([(a,a)])=(\gamma(a),0)\in \gamma([0,1])\times \{0\}$ , thus the boundary of the Moebius band $M$ is mapped by $F^\sim$ in a simple closed continuous curve of $\mathbb{R}^3$ contained in the plane $\{z=0\}$ . We observe that the existence of the rectangle $ABCD$ on the curve $\gamma$ is equivalent to say that the map $F^\sim$ is not injective. Arguing by contradiction, if $F^\sim$ would be injective, then $F^\sim: M\to F^\sim(M)\subseteq \mathbb{R}^3$ would be an homeomorphism because $M$ is compact and $\mathbb{R}^3$ is Housdorff, that means $F^\sim$ is also a closed map. Now the question is: There exists an homeomorphism from $M$ to a subset of $\mathbb{R}^3$ such that $\partial M$ is mapped in a continuous closed simple curve of $\mathbb{R}^3$ contained in a plane? I think that the answer is no, but I don't understand how to prove it.","['knot-theory', 'algebraic-topology', 'differential-geometry']"
3382688,Can the result of $\sum\limits_{n=1}^{\infty}\dfrac{1}{3^n-2^n}$ be expressed as a closed form?,"Notice that, for any $a>b>0$ and $n=1,2,\cdots$ , it holds that \begin{align*}
a^n-b^n&=(a-b)(a^{n-1}+a^{n-2}b+\cdots+ab^{n-2}+b^{n-1})\\
&\geq (a-b)(b^{n-1}+b^{n-2}b+\cdots+bb^{n-2}+b^{n-1})\\
&=n(a-b)b^{n-1}\\
&\geq(a-b)b^{n-1}.
\end{align*} Thus $$\frac{1}{3^n-2^n}\leq\frac{1}{2^{n-1}}.$$ Since $\sum\limits_{n=1}^{\infty}\dfrac{1}{2^{n-1}}$ is convergent,by the comparison test, $\sum\limits_{n=1}^{\infty}\dfrac{1}{3^n-2^n}$ is also convergent. But where does it converge to? WA gives a numerical approximation: $$\sum_{n=1}^{\infty}\frac{1}{3^n-2^n}\approx 1.27498.$$ I wonder whether it can be a closed form or not.",['sequences-and-series']
3382766,Mahalanobis distance invariant,"Is the Mahalanobis distance invariant with respect to arbitrary non-singular linear transformations? I mean if $C$ an arbitrary regular $(p × p)$ -matrix and $b$ in $R$ arbitrary and $ \tilde{x}_n= C\,x_n +b$ , is it then true that $d\left(x_n,x_m\right)=d\left(\tilde{x}_n,\tilde{x}_m\right)$ . And if so, why?",['statistics']
3382804,"What does ""Random Rotation Matrix"" really mean? How to generate it?","I got the term from this paper[1] and I don't understand what it means. It said the ""Random Rotation Matrix"" can be generated following ""Haar Distribution""[2]. I only know the output is a matrix which contains random number but has a property which is the ""Rotation"" itself but I don't know what the ""Rotation"" means. I don't know what it means with the Haar distribution too. Then I read the paper[2] about a method for generating this ""Random Rotation Matrix""[1] which is suggested by the first paper[1] and it seems so mathematical that it's hard for me to understand it. I research through the internet, books, and papers then I still don't understand what does ""Rotation Matrix"" mean and how to generate it because of those sources like telling different things. So my question is: What does ""Rotation Matrix""[1] really mean? How does it look like? Can you give me an example of it? What is ""Rotation Center""[1]? Maybe it's coordinate in the matrix where it becomes the centre point of the rotation? What is ""Haar Distribution""[1]? I only know about uniform or normal distribution lol. Is it related to ""Haar Measure""? Are there other good sources which discuss generating this ""Random Rotation Matrix""[1]? Are there tips and trick to understanding those really hard and very mathematical paper to know how to generate this ""Random Rotation Matrix""[1]? [1]: K. Chen and L. Liu. A random rotation perturbation approach to privacy preserving data classification. Technical Report, 2005. [2]: STEWART, G. The efficient generation of random orthogonal matrices with an application to condition estimation. SIAM Journal on Numerical Analysis 17
(1980). Disclaimer: I'm a computer science student who doesn't good at math. So I need an answer which more understandable by engineer and of course it needs to be codeable. Sorry if the scope of this question is too wide or doesn't specific. Maybe the answer doesn't need to be the solution, I mean it can be just another sources which I can learn to answer my questions.","['matrices', 'random', 'rotations']"
3382863,Division by $dx$ in multi-variable calculus ....,"I am stuck on this doubt : Suppose $f=f(x,y,z).$ Hence, $ df= \frac {\partial f}{\partial x}dx + \frac { \partial f}{\partial y}dy + \frac {\partial f}{\partial z}dz.$ Then, is the following equation correct : $$\frac {df}{dx}=\frac {\partial f}{\partial x}+\frac {\partial f}{\partial y}\frac{dy}{dx} + \frac {\partial f}{\partial z}\frac{dz}{dx} \,\,\,\,(*)$$ The reasoning used in obtaining $(*)$ is : ""dividing"" the whole equation by $dx$ . Normally, the $\large \frac {d}{dx}$ operator is used in single variable calculus where only single-variable functions are differentiated wrt $x$ . But it does look a bit awkward (at least to me) when used in multi-variable calculus. Do the expressions $\large \frac {df}{dx}$ , $\large \frac {dy}{dx}$ and $\large \frac {dz}{dx}$ even make any sense when used like this ? I know that ""division"" by $\partial x$ can cause problems in multi-variable calculus. But what about ""division"" by $dx$ . It works fine in single-variable calculus. If $\large \frac {df}{dx}$ makes any sense, then does it mean the ""total"" rate of change of $f$ wrt $x$ if $y$ and $z$ are allowed to change ? Summary : (1) Is division by $dx$ allowed in multi-variable calculus? (2) What does $\frac {df(x,y,z)}{dx}$ mean if answer to (1) is ""yes"" ? Does it mean anything if the answer to $(1)$ is ""no"" ?","['partial-derivative', 'multivariable-calculus', 'calculus', 'derivatives']"
3383014,History of the Cauchy matrix,"Cauchy matrix $C$ is defined by $$C_{i,j}=\frac{1}{a_i + b_j}$$ where $a_i$ and $b_j$ are any numbers so long $a_i + b_j \neq 0$ . Why did Cauchy introduce this matrix? Did he use it in the context of another problem or application?","['matrices', 'math-history', 'cauchy-matrices']"
3383089,Books or Materials on $n$-dimensional Lebesgue-Stieltjes Measure,"I am looking for a book dealing with $n$ -dimensional Lebesgue-Stieltjes Measure, especially dealing with its construction and its extension to Borel $\sigma$ -algebra on $R^d$ rigorously. For example, to show the extension to the Borel $\sigma$ -algebra exists, we need to show that the set function, defined on the semialgebra consisting of all left-open and right-closed rectangles, is finitely additive and countably subadditive. Many books mention this result but left it as an exercise as they state that it is the same case as 1-dimensional. However, I think the case on $n$ -dimensional is much more complex. So I want a book that deals with such problems in a clear, complete and rigorous way, without referring to any exercise. The books can be either in classical real analysis or regarding probability theory or stochastic calculus. Thanks a lot in advanced!","['measure-theory', 'stieltjes-integral', 'probability-theory', 'stochastic-calculus']"
3383119,Trying to convert 34.2111 (decimal) to binary in a faster way,"I tried this before here Convert 34.2111 (decimal) to binary and now I am trying again in a different way. When you have to convert base a to b where b is a^n you know that n digits of the number in base a = 1 digit in base b. In this case 10 isn't a power of 2 so at best you get $10 = 2^3+2^1$ What this means is that each digit of the given number in base 10 corresponds to 3 digits plus.... something? in base 2. I did a correspondence table: $$0_{10} = 0_2\\
1_{10} = 001_2 \\
2_{10} = 010_2 \\
3_{10} = 011_2 \\
4_{10} = 100_2 \\
5_{10} = 101_2 \\
6_{10} = 110_2 \\
7_{10} = 111_2 \\
8_{10} = 1000_2 = 111_2+1_2 \\
9_{10} = 1001_2 = 111_2+10_2$$ When I solve exercises like this base b is usually a power of a so I don't ""add"" anything. I write the correspondences up until n+1 digits (exclusive). If this was base 8 instead of decimal I'd only need to write the correspondences until 111_2. When solving this I noticed that the 3 (from the 34) doesn't correspond to 011_2 or 0011_2 but instead to 011_2+1_2=100_2 (because I do this as if I am solving for base 8 and then I add as if I am solving for base 2... because 10 = 2^3+2^1). So basically... 2 to the power that gives you the number closest to 10 (which is 8) and then add what's missing, which is either 0, 1 or 2 (decimal). Using this I get: $$3 = 011_2 + 01_2 = 0100_2 \\
4 = 0100_2 + 00_2 = 0100_2 \\
34 = 0100 0000_2 + 0000 0100_2 = 0100 0100_2$$ Only... the answer is 100010 (I'm only counting the integer part to keep it simple). If I try to solve the decimal part I get: $$2 = 0010_2 + 00_2 = 0010 \\
1 = 0001_2 + 01_2 = 0010 \\
2111 = 0010 0010 0010 0010$$ And this is... wrong. I know that each unit/digit of that number in decimal is $0111 + 10 = 1001_2$ in binary because what you do is use a power of 2 and then add what's left.. when b is a power of two you don't have to add anything because there's nothing missing. Here it's trickier... if $10 = 2^3+2^1 = 2(2^2+1)$ then maybe a different way of doing this is solving the given digit in base 8, add a zero to the left and then add the excess (mod) to the closest power of 2... in the case of 3 it's one or 01_2 because the closest power is 2... TL;DR I am trying to find a faster way of converting this than the one in the given link. I know it works but it's too messy. I am trying to apply the method I use for a -> b where b is a power of a but this time with non powers of a. Can anyone help me develop ""my"" method so I can apply it to these cases too?",['discrete-mathematics']
3383122,What is the intuition behind a low-rank covariance matrix?,"Let $X, Y$ be random vectors.  Let $K = \text{Cov}(X,Y) = E[XY^T] - E[X]E[Y]^T$ be the covariance matrix of $X$ and $Y$ .  Assume $K$ is low rank. I'm trying to come up with simple intuitive examples about what having a low rank covariance matrix means but I'm having trouble.  I understand that a low rank matrix means most of the column vectors are linearly dependent on other column vectors, and I understand that the covariance matrix shows the variance relationships between each random variable.  But from here I'm having trouble coming up with an intuitive explanation or example of where this would be useful.","['matrices', 'matrix-rank', 'covariance', 'intuition']"
3383268,"Is mapping generators to generators, and then extending, a well-defined homomorphism?","I was trying to define a homomorphism between some finite groups and I had the following idea. Suppose that $G = \langle a, b\rangle $ , and $H = \langle x, y\rangle$ . We define $\varphi:G \to H$ by $\varphi(a)=x,$ $\varphi(b)=y$ , and for an arbitrary element of $G$ , $g_1^{\epsilon_1}g_2^{\epsilon_2} \cdots g_n^{\epsilon_n}$ (where each $g_i$ is either $a$ or $b$ , and each $\epsilon_i$ is either $1$ or $-1$ ), then $\varphi(g_1^{\epsilon_1}g_2^{\epsilon_2} \cdots g_n^{\epsilon_n}) = \varphi(g_1)^{\epsilon_1} \varphi(g_2)^{\epsilon_2} \cdots \varphi(g_n)^{\epsilon_n}$ . If this is well-defined, then this is obviously a homomorphism. However, I do not know if this is well defined. I suspect not.","['group-homomorphism', 'group-theory', 'abstract-algebra']"
3383306,Partitions of $64$ with summands less than $12$,"How many ways are there to write $64$ as a sum of $10$ natural numbers (without $0$ ) such that each number is $\le 12$ (here, the order of these natural numbers doesn‘t matter)? My first idea would be to fill up to any sum between $52$ and $63$ using only $9$ numbers. Afterwards, the tenth number is fixed. However, I don‘t know how to count the fill-up and there might be duplicate counts. (This is problem #15 from Arnold‘s Problems for children from 5 to 15 , so I don‘t expect that a solution involves complex results about partitions.)","['integer-partitions', 'combinatorics']"
3383342,How many integers are there that are not divisible by any prime larger than 20 and not divisible by the square of any prime?,"I tackled the problem in the following way but i'm not sure if i'm correct. I need the count of the numbers that have in their prime factorization only primes p such that $p \lt 20$ and those numbers can't be more than once in the prime factorization (right?) So, the amount of numbers that can be expressed this way are all the subsets of the set $\{2,3,5,7,11,13,17,19\} = 2^8$ . Correct me if I'm wrong.","['number-theory', 'divisibility', 'prime-factorization', 'prime-numbers']"
3383344,About polynomial harmonic functions,"I am really struggling to solve the following, I don't even know how to start. I would appreciate if anyone could give me some help. Let $m$ be a positive integer and $u : \mathbb{R}^{n} \rightarrow
 \mathbb{R}$ be a harmonic function. If $u(x) = O(\left|x \right|^m)$ when $\left|x \right| \to \infty$ , show that $u$ is polynomial of
  degree at most $m$ . Thanks in advance for any help.","['harmonic-functions', 'harmonic-analysis', 'analysis', 'polynomials', 'partial-differential-equations']"
3383361,Expected Time Until Absorption for Discrete Finite State Markov Chain,"The Problem: Consider a discrete time Markov chain with states $0,1,...,N$ whose matrix has elements $$ P_{ij} =   \left\{
\begin{array}{ll}
      \mu_i,                 & j = i - 1; \\
      \lambda_i,             & j = i + 1, \hspace{5mm} i,j = 0,1,...,N;  \\
      1 - \lambda_i - \mu_i, & j = i;             \\
      0						 & |j - i| > 1.      \\
\end{array} 
\right. $$ Suppose that $\mu_0 = \lambda_0 = \mu_N = 0$ , and all other $\mu_i$ 's and $\lambda_i$ 's are positive, and that the initial state of the process is $k$ . Determine the expected time until absorption. My Progress: So, I know that if we define $\rho_0 = 1$ and $$ \rho_i = \frac{\mu_1 \mu_2 \cdots \mu_i}{\lambda_1 \lambda_2 \cdots \lambda_i}, $$ then $$ \Pr\{\text{absorption at $0$} \} = 1 - \Pr\{\text{absorption at $N$} \} = \frac{\sum_{i=k}^{N-1}\rho_i}{\sum_{i=0}^{N-1}\rho_i} .  $$ However, my thinking is as follows: If we collect the transient states into the set $T = \{1, 2, ..., N-1\}$ , then the expected time until absorption is simply the mean time the process spends in $T$ . Now, I know that, for $i,j \in T$ , if $s_{ij}$ denotes the number of time periods that the process is in $j$ given that it starts in state $i$ , we have the following formula: $$ s_{ij} = \delta_{ij} + \sum_{k=1}^{N-1}P_{ik}s_{kj}. $$ But I assume that I am supposed to use my knowledge of the above probabilities of absorption at $0$ or $N$ (perhaps in some kind of conditioning argument) to determine the desired time. Whatever the case, both approaches have sent me down different rabbit holes, neither of which has proven very fruitful.","['stochastic-processes', 'markov-chains', 'probability']"
3383372,sup-norm bound by second derivative,"If $f\in C[0,1]$ , twice differentiable function, and $f(0)=0=f(1),$ then $$ \sup_{x\in[0,1]} |f(x)| \leq \frac{1}{8} \sup_{x\in[0,1]} |f''(x)|.$$ I am not able to get the constant ${1}/{8}$ , here is my try: For any $x\in[0,1]$ , $$ |f(x)| = |f(x)-f(0)| \leq \int_0^x \int_0^t |f''(y)| \,dy\,dt \leq \sup_{x\in[0,1]} |f''(x)| \int_0^x t\,dt \leq \frac{1}{2} \sup_{x\in[0,1]} |f''(x)|. $$ Thanks for any help regarding this!","['derivatives', 'functional-analysis', 'analysis']"
3383517,How to simplify complex conjugates and moduli,"I have a few questions regarding conjugates and moduli 1.) If $z=x+bi$ , how would I simplify $\overline{z+a}$ or $\overline{z+i}$ Also, how would I simplify something like $\overline{2\overline{z}+5}$ . 2.) Would $\overline{2} = 2$ ? In addition, would $\overline{3i}=-3i$ ? 3.) For the modulus, I have no idea how to simplify $|3z-i|$ , or $|z+2|$ . Thank you so much!","['complex-analysis', 'complex-numbers']"
3383539,Regular Functions and Coordinate Rings,"When I first learned algebraic geometry a few years back, I was taught that for an affine variety $X \subset \mathbb{A}^n$ , a function $f$ was regular at a point $p$ if there existed a neighbourhood of $p$ where one could express $f=\frac{g}{h}$ , $g,h \in \mathbb{F}[x_1 , \dots , x_n]$ , $h \neq 0$ . The ring of all functions that were regular at every point on $X$ was just called, plainly, the ring of regular functions , denoted $\mathcal{O}(X)$ , and by a nice proof, it emerges that this was in fact isomorphic to the coordinate ring of $X$ , $\mathcal{O}(X) \cong A(X)$ . Something about this all always kind of bothered me. While I appreciated the usefulness of isomorphism, and I could abstractly understand every step of the proof (which was the one in Hartshorne's book, for the record), I could just never understand how the proof could ever have come about, as in, who would ever have guessed that these rings of ""fractions of polynomials"" would be something isomorphic to the coordinate rings? Why would you even begin to investigate that? Where was the link where, so to speak, you could see that, ""Oh, clearly, there's clearly correspondence between functions $f(x) + I(X)$ and functions that can be expressed $\frac{g}{h}$ "" to provide motivation for the definition of a regular function, and then the proof in question. And so, basically, that's my question: what's the clear, initial observation between the relationship of functions $f(x) + I(X) \in A(X)$ and functions that can be expressed $\frac{g}{h}$ , $g,h \in \mathbb{F}[x_1, \dots , x_n]$ . If the question is a bit too fuzzy, please let me know, and I shall try to clarify.","['affine-varieties', 'algebraic-geometry']"
3383575,Proving Laplace expansion using exterior algebra,"Let $A = (a_{ij})$ be an $n\times n$ matrix with entries in a ring $R$ , $M$ a free $R$ -module of rank $n$ with an ordered basis $(e_i)_{i \leq n}$ and $\phi\colon M\to M$ is an endomorphism which $A$ represents (such that $\phi(e_j) = \sum_{i = 1}^n a_{ij}e_i$ fop all $j$ ). Then $\bigwedge^n M$ has rank $1$ with a basis $\{e_1\wedge ... \wedge e_n\}$ and there is a unique scalar $r \in R$ such that $$\left(\bigwedge^n \phi\right)(e_1\wedge ... \wedge e_n) = \phi(e_1)\wedge ... \wedge \phi(e_n) = r(e_1\wedge ... \wedge e_n).$$ This scalar is precisely the determinant $\det(A)$ of $A$ . It can be easily shown that the value of $\det(A)$ doesn't depend on the choice of $M$ . I take this as the definition of a determinant. From this other definitions can be deduced as theorems, including the formula $$\det(A) = \sum_{\sigma \in S_n}\mathrm{sgn}(\sigma)a_{\sigma(1)1}...a_{\sigma(n)n}.$$ I understand that there is a shorter proof of the Laplace expansion of a determinant using the definition of a determinant in question. However, a book I consulted has a serious gap in the proof. I will state what I want to prove: Let $A = (a_{ij})$ be an $n\times n$ matrix with entries in a commutative ring $R$ . Denote by $A_{ij}$ the $(n-1)\times(n-1)$ matrix obtained from $A$ by deleting the $i$ -th row and the $j$ -th column of $A$ . Then, for all $i$ , $$\det(A) = \sum_{j = 1}^n (-1)^{i + j} a_{ij}\det(A_{ij}).$$","['determinant', 'abstract-algebra', 'linear-algebra', 'modules']"
3383598,"Use Koszul complex to show an ideal in $k[x,y,z]$ is contained into another ideal","Let $R=k[x,y,z]$ be a polynomial ring and $f,g,h\in k[x,y,z]_d$ be degree $d$ elements such that $f,g,h$ are homogeneous polynomials of degree $d$ and form a regular sequence. Find the necessary and sufficient condition for $$(x^{2d-1},x^{2d-2}y,\dots,y^{2d-1})=(x,y)^{2d-1}\subset (f,g,h)$$ in terms of the generators $f,g,h$ . The hint is to use Koszul complex, and I know since $f,g,h$ is a regular sequence the Koszul complex gives a minimal free resolution of $R/(f,g,h)$ . But I don't see how resolution plays role in this problem. This question rises when I study determinantal ideals and determinantal varieties, a possible reference is 'Algebraic Geometry' by Harris. Update: I am able to find the minimal resolutions of $R/(f,g,h)$ and $R/(x,y)^{2d-1}$ if they are correct: $0\to R[-3d]\to R[-2d]^3\to R[-d]^3\to R\to R/(f,g,h)\to 0$ $0\to R[-2d]^{2d-1}\stackrel{\phi}\to R[-2d+1]^{2d}\to R\to R/(x,y)^{2d-1}\to 0$ Here $\phi$ is a $2d\times (2d-1)$ matrix with entries $a_{i,i}=-y$ , $a_{j+1,j}=x$ for every $i,j$ , and $0$ for other entries. So what does $(x,y)^{2d-1}\subset (f,g,h)$ tell us about the relationships of these minimal free resolutions?","['homological-algebra', 'algebraic-geometry', 'commutative-algebra']"
3383605,Modelling a horizontal mass damper using differential equations,"I am trying to solve this second-order differential equation: $y'' + y'+ y + (y')^2 =0$ I was able to solve the equation $y'' + y'+ y $ , by substituting $y$ as $Ae^{kt}$ . 
But now I have this new term $(y')^2$ . Note: This equation represents the simplified equation of forces on a horizontal mass damper.","['calculus', 'derivatives', 'mathematical-modeling', 'ordinary-differential-equations']"
3383686,On affine morphism and Picard group,"Let $X,Y$ be Noetherian schemes and $f: X \to Y$ is an affine morphism ( $f^{-1}(U)$ is affine for every affine open $U \subseteq Y$ ). Is it true that $H^1 ( X, \mathcal O_X^{\times}) \cong H^1 ( Y, f_* (\mathcal O_X^{\times})) $ ? If this is not true in general, what if we also assume $f$ is proper (i.e. $f$ is finite) morphism ?","['algebraic-geometry', 'sheaf-cohomology', 'schemes', 'sheaf-theory']"
3383687,"If $f \colon \mathbb{R}^n \rightarrow \mathbb{R}$ is differentiable and vanishing, it has $0$ gradient somewhere.","I'm interested in ideas for improving and fixing the proof I wrote for the following theorem: Let $f \colon \mathbb{R}^n \to \mathbb{R} $ be differentiable, and $ \lim_{\| x \| \to \infty} f(x) = 0 $ . Then $\nabla f(x) = 0 $ for some $x \in \mathbb{R}^n$ . Here's the idea of the proof. First, since $f$ is differentiable, it is continuous. As $ \lim_{\| x \| \to \infty} f(x) = 0 $ , $\forall \varepsilon > 0, \exists r \in \mathbb{R} : |f(x) - 0| < \varepsilon$ whenever $\| x \| > r$ . If we choose $D = \{x \in \mathbb{R}^n : \| x \| \leq r \}$ , we can use the theorem that states that all continuous functions are bounded inside closed sets. In other words, there's a supremum of $|f(x)|$ in $D$ . Then we just look at the cases: if $f(x) = 0$ , so its gradient is always 0 and we're done. If $f$ varies in the set $D$ , there exist $a,b \in D$ such that $f(a) \neq f(b)$ , ie. $\exists \varepsilon_2 > 0$ so $| f(a) - f(b) | > \varepsilon_2 $ . If we choose $\varepsilon_2 > \varepsilon$ , $|f(x)|$ attains greater values in $D$ than outside it, and if we choose $c$ to be a point such that $$f(c) = \sup{\{f(x) : x \in D\}}$$ Then $|f(x)| \leq |f(c)|\quad \forall x \in D$ and as $f$ is differentiable, $\nabla f(c) = 0$ . There are more than a few issues I have with the formulation of the proof. First, "" $f$ attains greater values in $D$ than outside it"" seems a little ambiguous. Then the choosing of $c$ in a convenient way after having talked about it at such length... Additionally, I'd like to use the definition of differentiability that states that if $f$ is differentiable, it can be represented as $$f(x_0+h) = f(x_0) + Df(x_0)h + \varepsilon(h)\| h \|,\quad h \in \mathbb{R}^n $$ where $\varepsilon(h)\| h \| \to 0$ as $\| h \| \to 0$ , and where $Df(x)$ is the gradient in this case, or the Jacobian in a more general case. I'm almost certain you could bound the gradient $Df(c)$ to $0$ somehow using that definition, because it gives you a semi-explicit expression, instead of the verbal hand-waving I'm facing. There might've also been a method much simpler than this, but I couldn't exactly employ the mean value theorem easily here with the whole open domain. Maybe using the $D$ I defined there would've worked.","['multivariable-calculus', 'derivatives', 'vector-analysis']"
3383735,Linearity property of the Poisson distribution-- is it unique?,"The family of Poisson distributions (parametrised by its mean) has an interesting 'linearity' property: $$\mathrm{Poisson}(x) + \mathrm{Poisson(y)} \sim \mathrm{Poisson(x+y)}$$ ...meaning that the sum of two independent random variables drawn from poisson distributions with means $x$ and $y$ is itself distributed as a Poisson variable, with mean $(x+y)$ . Do any other probability distribution families have the same property? Are there similar distribution families $D(a)$ on other binary operations $\odot$ ? $$\text{i.e.} \qquad D(a) \odot D(b) \sim D(a \odot b)$$","['probability-distributions', 'probability-theory', 'poisson-distribution']"
3383736,"Prove there are distinct $x_1,\,x_2,\cdots,\,x_n$ such that $ \sum_{i=1}^n\frac{p_i}{f'(x_i)}=\sum_{i=1}^n p_i. $","Suppose $f(x)$ is differentiable on $[0,\,1]$ , $f(0)=0$ , $f(1)=1$ and $p_1,\,p_2,\cdots,\,p_n$ are $n$ positive real numbers. Prove there are distinct $x_1,\,x_2,\cdots,\,x_n$ such that $$
\sum_{i=1}^n\frac{p_i}{f'(x_i)}=\sum_{i=1}^n p_i.
$$ I can only prove some special cases. 
Let $p=\sum_{i=1}^n p_i$ . It suffice to prove that $\sum_{i=1}^n\frac{p_i}{pf'(x_i)}=1$ . A proper choose is $f'(x_i)=\frac{np_i}{p}$ . From Darboux theorem, if $f'$ is large enough, these values can attain.",['analysis']
3383769,What even *are* elliptic functions?,"I am just beginning to learn about elliptic functions. Wikipedia defines an elliptic function as a function which is meromorphic on $\Bbb C$ , and for which there exist two non-zero complex numbers $\omega_1$ and $\omega_2$ , with $\frac{\omega_1}{\omega_2}\not\in \Bbb R$ , which satisfy $$f(z)=f(z+\omega_1)=f(z+\omega_2).$$ That's all fine and dandy, but what does this have to do with an ellipse? I sort of know (but not really) about the Jacobi elliptic functions. I am told by the internet that the Jacobi elliptic functions can be defined as inverses of elliptic integrals, which relate to the arc lengths of ellipses. But other than that, I have no idea how elliptic functions relate to ellipses. I have looked at several sources, like this , this , and this . From what I can understand, any elliptic function can be expressed in terms of the Jacobi elliptic functions and Weierstrass elliptic functions, but I have yet to understand why that is true. Perhaps it has something to do with what ODE's elliptic functions satisfy? I do not know. I would really appreciate some help and/or a good source on the introduction to the study of elliptic functions in the context of elliptic integrals, because I do work best with integrals. Thanks!","['special-functions', 'complex-analysis', 'analytic-number-theory', 'elliptic-functions', 'elliptic-integrals']"
3383865,Prove that $\left ( 1+\frac{n^{\frac{1}{n}}}{n} \right )^\frac{1}{n}+\left ( 1-\frac{n^{\frac{1}{n}}}{n} \right )^\frac{1}{n}<2$,"Prove that $$\left ( 1+\frac{n^{\frac{1}{n}}}{n} \right )^\frac{1}{n}+\left ( 1-\frac{n^{\frac{1}{n}}}{n} \right )^\frac{1}{n}<2 \tag{1} $$ $\forall$ $n \gt 1$ I tried using Induction: For the Base Step $n=2$ we have: $$x=\sqrt{1+\frac{1}{\sqrt{2}}}+\sqrt{1-\frac{1}{\sqrt{2}}}$$ Then we get: $$x^2=2+\sqrt{2}\lt 4$$ So $x \lt 2$ Now Let $P(n)$ is True, We shall need to prove $P(n+1)$ is also True We have $P(n+1)$ as: $$\left ( 1+\frac{(n+1)^{\frac{1}{n+1}}}{n+1} \right )^\frac{1}{n+1}+\left ( 1-\frac{(n+1)^{\frac{1}{n+1}}}{n+1} \right )^\frac{1}{n+1}$$ Now i tried to use the fact that: $$f(x)=x^{\frac{1}{x}}$$ is a Monotone Decreasing $\forall x \ge e$ Hence $\forall n \ge 3$ we have: $$(n+1)^{\frac{1}{n+1}} \lt n^{\frac{1}{n}} \tag{2}$$ and also $$\frac{1}{n+1} \lt \frac{1}{n} \tag{3}$$ Multiplying $(2),(3)$ We get: $$1+\frac{(n+1)^{\frac{1}{n+1}}}{n+1}\lt  1+\frac{n^{\frac{1}{n}}}{n}$$ Can we proceed from here?","['inequality', 'jensen-inequality', 'monotone-functions', 'algebra-precalculus', 'exponential-function']"
3383873,To prove sum of A.P is greater than G.P,"Consider an Arithmetic Progression(A.P) with the first term $a$ , the commom difference $d$ and a Geometric Progression(G.P) with first term again as $a$ but common ratio $r$ such that $a,d,r>0$ and both these progressions have same number of terms and their last terms are also equal. Show that the sum of all the terms of A.P is greater than the sum of all the terms of the G.P. My Attempt: The terms between first and last terms are the $(n-2)$ Arithmetic Means(A.M's) or the Geometric Means(G.M's). Can it be proved that each of the A.M's is greater than the corresponding G.M's.","['arithmetic-progressions', 'geometric-progressions', 'sequences-and-series']"
3383902,Finding design matrix $X$ in the linear model,"$y=Xb+e$ is a (General) linear model with $n=p=3$ . Given that $b_3$ is non estimable, and $b_1+ 2b_2 + 2b_3$ is estimable. How can I find an $X$ which is consistent with the above? I think I have a partial solution to it but I do not understand the methodology of solving it. My questions 1) How can we show/prove that $\lambda_1\notin  C(X^T)$ but $\lambda_2 \in  C(X^T)$ ? and lastly, 2) How does the design matrix $X$ looks and why ? So I know $$b = \begin{bmatrix}
b_1\\ 
b_2\\
b_3
\end{bmatrix}$$ Now since $b_3$ is non estimable : $b_3 = λ_1^T b$ $\lambda_1 = \begin{bmatrix}
0\\ 
0\\
1
\end{bmatrix}$ and $\lambda_1\notin C(X^T)$ (the column space of $X^T$ ). and since $b_1 +2b_2 + 2b_3$ is estimable then $$b_1 +2b_2 + 2b_3 = \lambda_2^T b$$ $\lambda_2 = \begin{bmatrix}
1\\ 
2\\
2
\end{bmatrix}$ and $\lambda_2$ is  in $C(X^T)$ . We know probably that $X$ is not full column rank. I was thinking to use $X^T b = \lambda_1$ , $X^T b = \lambda_2 $ to find $X$ matrix but I am not sure how to proceed.","['statistics', 'systems-of-equations', 'matrices', 'linear-algebra', 'linear-regression']"
3383981,Finding the maximum area of a quadrilateral when three points are given,"I am working on problems in the chapter ""Applications of Derivatives"". I encountered the following problem: Question: Four points A,B,C, and D lie in that order on the parabola $y=ax^2+bx+c$ . The coordinates of A,B, and D are $(-2,3)$ , $(-1,1)$ , and $(2,7)$ respectively. The coordinates of C for which the area of the quadrilateral ABCL is maximum is: (A) $(1/2,7/4)$ (B) $(1/2,-7/4)$ (C) $(-1/2,7/4)$ (D) $(-1/2,-7/4)$ [Correct Answer : Option (A)] My Approach: Introduction: I found the equation of the parabola using the given coordinates. Then computed the area of the quadrilateral by considering an arbitrary value for point C. Then I found the coordinates of C by maximizing the value of A by using the concept of maxima. What I am looking for is an alternate proof or a property which relates the coordinates of third vertex of a quadrilateral when three points are fixed under certain constraints, to maximize the area. We have been given the coordinates A $(-2,3)$ ,B $(-1,1)$ and D $(2,7)$ . Since these points lie on the given parabola $y=ax^2+bx+c$ , on substituting the coordinates of A,B and D we get the following linear equations in variables $a,b,$ and $c$ : $4a-2b+c=3$ $a-b+c=1$ $4a+2b+c=7$ On solving these three equations, I got $a=1,b=1,$ and $c=1$ . So the equation of the parabola is $y=x^2+x+1$ . In the following graph, the points A,B and D are fixed, whereas point C is a variable point on the parabola. We need to find the coordinates of point C such that the area of the quadrilateral is maximum. In coordinate geometry, I came across the following formula to compute the area of a $n$ sided polygon when the coordinates are given: Area A $= \frac 1 2 \left( \left| {\begin{array}{cc}x_1 & x_2 \\y_1 & y_2 \\ \end{array} } \right|+\left| {\begin{array}{cc}x_2 & x_3 \\y_2 & y_3 \\ \end{array} } \right|+\left| {\begin{array}{cc}x_3 & x_4 \\y_3 & y_4 \\ \end{array} } \right|+ \dots +\left| {\begin{array}{cc}x_{n-1} & x_n \\y_{n-1} & y_n \\ \end{array} } \right|+\left| {\begin{array}{cc}x_n & x_1 \\y_n & y_1 \\ \end{array} } \right| \right)$ where $(x_1,y_1),(x_2,y_2),(x_3,y_3),\dots ,(x_{n-1},y_{n-1}),(x_n,y_n)$ are coordinates of the $n$ vertices of the $n$ sided polygon taken in order. Here |.| denotes determinant of the matrix. Now in the given question we are supposed to find the maximum area of a quadrilateral (4 sided polygon). So using the above formula, we get the following: Area A $= \frac 1 2 \left( \left| {\begin{array}{cc}x_1 & x_2 \\y_1 & y_2 \\ \end{array} } \right|+\left| {\begin{array}{cc}x_2 & x_3 \\y_2 & y_3 \\ \end{array} } \right|+\left| {\begin{array}{cc}x_3 & x_4 \\y_3 & y_4 \\ \end{array} } \right|+\left| {\begin{array}{cc}x_4 & x_1 \\y_4 & y_1 \\ \end{array} } \right|  \right)$ where where $(x_1,y_1),(x_2,y_2),(x_3,y_3),$ and $(x_4,y_4)$ are the coordinates of points A,B,C, and D respectively. Now let the $x$ -coordinate of point C be $h$ . So its $y$ -coordinate (from the equation of parabola) is $h^2+h+1$ . So coordinates of point C be represented as $(h^2+h+1)$ . After substituting the values of the coordinates in the equation for area, I obtained the following equation: Area A $=\frac 1 2 -3h^2+3h+18$ Area A attains the maximum value at $h=1/2$ . Hence the coordinates of point C is $(1/2,7/4)$ - option (A). My answer is correct. Doubt: Is there any other formal way of solving this problem? Is there any property for choosing the fourth vertex of the quadrilateral when three vertices are given, in order to get the maximum area under given constraints? Thank you in advance.","['alternative-proof', 'calculus', 'area', 'geometry']"
3383996,Homology in real closed fields,"I'm studing on ""Real Algebraic Geometry"" by Bochnak-Coste-Roy and in Chapter 11 I found a very interesting characterization of the Euler-Poincaré characteristic of real algebraic sets over a general real closed field. Now I'm a bit confused about the involved definition of homology, since in this book it is not defined. In particular I'm intereted in solving the following issues: In this setting the homology, with rational coefficients, is defined by mappings from affine simplices in $\mathbb{R^n}$ , as usual, or in the affine space over the real closed field where the algebraic set is defined? In $\mathbb{R^n}$ I know that the simplicial homology of a finite simplicial complex and the singular homology of its realization do coincide, the proof can be found in ""Elements of Algebraic Topology"" by Munkres. In ""Real Algebraic Geometry"" they seem to apply this result also in a general real closed field without any comment, is there any reference where I can find the generalization of the previous result? I think it must work but, for instance, somewhere in the proof it may be used the compactness of simplices in $\mathbb{R^n}$ that is false in real closed fields in general. Thus, I am interested in understanding whether the proof of the previous result can be generalized or it needs another aproach. I am really grateful to anyone would give an answer to my doubts.","['algebraic-geometry', 'homology-cohomology', 'algebraic-topology', 'real-algebraic-geometry']"
3384013,How many natural number between $100$ and $1000$ exist which can be expressed as sum of 10 different primes.,"How many natural number between $100$ and $1000$ exist which can be expressed as sum of 10 different primes. For example , we can write $129$ as : $$129 = 2+3+5+7+11+13+17+19+23+29$$ What would be the best way to solve this ? We could use modular arithmetic to reduce the number of test expression , but is there a more efficient way ?","['modular-arithmetic', 'number-theory', 'elementary-number-theory', 'algebra-precalculus', 'prime-numbers']"
3384037,In how many ways can Candice share $13$ KitKats and $14$ Twixes with her younger brothers?,"I'm trying to solve the following problem: After a round of ""trick or treating"", Candice has 13 Kit Kats and 14 Twixes in her pillow case. Her mother asks her to share some (but not necessarily all) of the loot with her three younger brothers. (A) How many different ways can she do this? (B) How many different ways can she do this if she gives at least one of each type of bar to each of her brothers? I have taken two approaches to part A, neither of which have been successful. Firstly I considered there being 13 stars, 14 circles and 3 bars and solving for 30C3.  Then I considered doing 16C3 + 17C3 but this didn't work either.  The second bit completely stumps me as I'm unable to solve the first part correctly. Thank you.","['combinations', 'combinatorics']"
3384074,"If two functions are mirror images of each other about the line $y=x$, are they inverses of each other?","I know that for a function $f$ there exists an inverse $f^{-1}$ when $f$ is one-one and onto in its domain. I also know that a function $f$ and its inverse $f^{-1}$ are mirror images about the line $y=x$ . Now, can we say that when two functions which are exactly mirror images about the line $y=x$ , are inverses of each other? Or in other words is the converse of the statement "" Function and its inverse are mirror images of each other about the line $y=x$ "" is always true? If it is not always true, kindly give me circumstances when the converse fails. Edit: From this Quora answer, it is said that two functions having the same graph need not necessarily be equal. Then how can we conclude that the graph mirror imaged about the line $y=x$ is definitely its inverse?","['functions', 'inverse', 'inverse-function']"
3384078,Additivity in algebraic K-theory --- what does it truly mean?,"--- Question --- I have seen several definitions of 'additivity' in algebraic K-theory. In all cases, I can more or less see that there is something additive going on. But I have difficulty seeing how they intertwine. My question is: could someone explain in dummy language how these notions are related? --- Definitions --- Philosophical additivity. Algebraic K-theory is additive in the sense that it should convert short exact sequences into direct sums in some universal way. This is most easily seen in the definition of $K_0$ of a ring: a short exact sequence $0 \to M' \to M \to M''\to 0$ gets converted into a relation $M = M' \oplus M''$ in $K_0(R)$ . Additivity à la Waldhausen. Waldhausen has given an explicit additivity theorem for K-theory. He has several equivalent formulation, but to me the most lucid one is the following. If we have a cofibration sequence $F' \to F \to F''$ of functors $\mathcal{C} \to \mathcal{D}$ , then $F' + F''$ and $F$ should be homotopic maps of spectra $K(\mathcal{C}) \to K(\mathcal{D})$ .[1] Additivity à la Blumberg et al. Regarded as a functor $\mathsf{Cat}_{\text{stable}} \to \mathsf{Spectra}$ , algebraic K-theory should send split-exact sequences of stable $\infty$ -categories to cofibre sequences of spectra.[2] --- Why I care --- I've heard that algebraic K-theory is somehow a 'universal' additive functor,  as found in the paper by Blumberg et al., and the idea of a universal property of K-theory greatly entices me. --- Sources --- [1] : Waldhausen's Algebraic K-theory of spaces [2] : Blumberg, Gepner, and Tabuada's A universal characterization of higher algebraic K-theory","['algebraic-k-theory', 'higher-category-theory', 'algebraic-geometry', 'homotopy-theory', 'stable-homotopy-theory']"
3384084,Finding Perfect numbers which are sum of consecutive prime number.,"Find all Perfect numbers which are sum of consecutive prime number.
For ex . we can write $28$ as : $$28 = 2+3+5+7+11$$ Are there any more examples possible ? If yes , what is the general condition to find such numbers ?","['summation', 'perfect-numbers', 'number-theory', 'elementary-number-theory', 'prime-numbers']"
3384096,Charts on projective space,"I am trying to solve an exercise about building an atlas for the projective space. For completeness, we work with the projective space as: $\mathbb{RP}^n=\{L\subset\mathbb{R}^{n+1}|L\text{ 1-dimensional subspace of } \mathbb{R}^{n+1}\}$ We endorse $\mathbb{RP}^n$ with the topology induced by the distance: $d(L,L')\colon = \text{inf}||x-x'||$ , where $x\in L\cap S^n$ , $x'\in L'\cap S^n$ . I.e., the distance is computed at the intersection between the lines in the projective space and the unit sphere $S^n$ . Now let's define our atlas on $\mathbb{RP}^n$ . Let $L\in\mathbb{RP}^n$ and let $H\subset\mathbb{R}^{n+1}$ be a 1-codimensional linear subspace (hyperplane) such that $L\cap H = \{0\}$ (hence $\mathbb{R}^{n+1}=L\oplus H$ ). Let the open sets be: $$U_{L,H}\colon =\{\Lambda\in\mathbb{RP}^n|\Lambda\cap H = \{0\}\}$$ And the coordinate maps: \begin{align}
\varphi_{L,H}\colon U_{L,H}&\longrightarrow \text{Hom}(L,H)\cong \mathbb{R}^{n}\\
\Lambda &\longmapsto \psi\colon L \rightarrow H
\end{align} with $\psi$ defined by the condition that $\Lambda=\{(l,\psi(l))|l\in L\}$ , i.e. $\Lambda$ being the graph of $\psi$ . I have to prove that 1) $U_{L,H}$ are open sets. 2) $(U_{L,H},\varphi_{L,H})$ is a chart. 3) $\{(U_{L,H},\varphi_{L,H})\}_{L,H}$ is an atlas on $\mathbb{RP}^n$ . So far, I think I have managed only 1). How can I prove 2) and 3)? I am currently stuck on showing that $\varphi_{L,H}$ is a homeomorphism, i.e., continuous with continuous inverse. Thanks a lot for your help.","['general-topology', 'smooth-manifolds', 'projective-space']"
3384148,How can I prove mathematically the reflection matrix has only the eigenvalues 1 or -1?,"Specifically where S is a subspace of $R^n$ . $P_S$ is the orthogonal projection onto $S$ . and the reflection matrix $ M = I - 2P_S$ I understand a similar proof where the eigenvalues of the projection matrix is either 0 or 1. Now trying to get the intuition for the reflection matrix (M) case. This is the proof for projection matrices that I have seen: $$Px = 
\lambda x $$ $$P^2 = P$$ $$P^2x = \lambda x$$ $$P(Px) = \lambda x$$ $$\lambda^2x = \lambda x$$ $$\lambda(\lambda -1)x = 0$$","['reflection', 'proof-writing', 'linear-algebra', 'eigenvalues-eigenvectors']"
3384150,Evaluate the sum : $\frac{1}{1+x_{1}}+\frac{1}{1+x_{2}}+\frac{1}{1+x_{3}}+...+\frac{1}{1+x_{n}}$,"Question : Let the real  number $x≥1$ : $x_{1}=x$ and $x_{n+1}=x_{n}(1+x_{n})$ for $n=1,2,3...$ Then find the sum : $S=\displaystyle \sum_{k=1}^{n}\frac{1}{1+x_{k}}$ My try : Note that : $\frac{1}{1+x_{1}}=\frac{1}{x_{1}}-\frac{1}{x_{2}}$ Also : $\frac{1}{1+x_{k}}=\frac{1}{x_{k}}-\frac{1}{x_{k+1}}$ So if we take sum rights-left  we get : $S=\frac{1}{x_{1}}-\frac{1}{x_{k+1}}$ I need see other method ? And it's possible to find the term of $x_{n}$ ?","['calculus', 'summation', 'sequences-and-series']"
3384177,Every prime occurs as the least quadratic nonresidue,"It is not difficult to check that the least quadratic nonresidue modulo prime $p$ cannot be a composite number, see, for example: Quadratic nonresidues mod p . It is quite natural to ask the opposite question: Is every prime the least quadratic non-residue modulo some $p$ ? In the other words, if we are given a prime $q$ , is there $p$ such that $q$ is a quadratic nonresidue modulo $p$ and, at the same time, all numbers $1,2,\dots,q-1$ are quadratic residues modulo $p$ ? I think I have a proof which I outlined in my answer below. However, the proof uses Dirichlet's theorem on arithmetic progressions , which is rather non-elementary result. I was wondering whether there is a more straightforward solution. I will also include link to the sequence A000229 in OEIS, which is described as: ""a(n) is the least number m such that the n-th prime is the least quadratic nonresidue modulo m.""","['number-theory', 'quadratic-residues', 'prime-numbers']"
3384214,Move integral inside logarithm,"I want to simplify the integral $$I=\int_y \log \left( \int_x f(y) \delta(x-y) dx \right)dy,$$ where $x$ , $y$ are real numbers, $f$ is a ""nice"" real fuction of real argument (eg. exp) and $\delta$ stands for Dirac Delta function. My idea is to somehow rescale the measure $dy$ by a function $g(x,y)$ such that $$I=\log \left(\int_y \int_x f(y) \delta(x-y) g(x,y) dx dy\right).$$ The question is how to find such a function $g(x,y)$ that would enable to use the sampling property of Dirac Delta function to simplify the integral $I$ .","['integration', 'measure-theory', 'dirac-delta', 'logarithms']"
3384241,Volume integration,"Let $$D = \left\{(x,y,z)\in\mathbb{R}^{3}\mid x\ge0,0\le y\le x, x^2+y^2\le {16}, 0\le z\le {5}\right\}.$$ I want to integrate $$\displaystyle\iiint\limits_{D}\left({-4\,z+y^2+x^2}\right)\,\mathrm{d}V $$ We can see that $x^2+y^2=r^2$ so $r^2=16$ . $r\to[0,16]$ and $\theta\to[0,2\pi]$ and $z \to[0,5]$ And then integration $$\int_0^{2\pi}\int_0^5\int_0^{16}(-4z+y^2+x^2)\,dV= \int_0^{2\pi}\int_0^5\int_0^{16}(-4z+r^2)\,drdzd\theta=\frac{36160\pi}{3}$$ That is wrong answer and I don't know where I have done mistake.","['integration', 'multivariable-calculus', 'calculus', 'multiple-integral']"
3384259,"Show that $(z+1)^8-z^8=0$ has roots $z=-\frac12$, $z=-\frac12(1\pm i\cot(k\pi/8))$; and follow-up questions","(a) Show that the equation $(z+1)^8-z^8=0$ has roots $z=-\frac12$ , $-\frac12\left(1\pm i\cot\frac{k\pi}{8}\right)$ , where $k=1,2,3$ . (b) Hence show that $$(z+1)^8-z^8=\tfrac18(2z+1)(2z^2+2z+1)\left(4z^2+4z+\csc^2\tfrac{\pi}{8}\right)\left(4z^2+4z+\csc^2\tfrac{3\pi}{8}\right)$$ (c) By making a suitable substitution into this identity, deduce that $$\cos^{16}\theta - \sin^{16}\theta = \tfrac1{16}\cos 2\theta(\cos^22\theta+1)\left(\cos^22\theta+\cot^2\tfrac{\pi}{8}\right)\left(\cos^22\theta+\cot^2\tfrac{3\pi}{8}\right) $$ original problem image How do you reformat the polynomial to reach the answer required? I have tried to turn the LHS into $[(z+1)/z]^8 = 0$ and solve the roots of unity, but I keep getting $\operatorname{cis}(2k\pi/8)$ instead of $k\pi/8$ which is required. Thanks in advance","['trigonometry', 'roots', 'polynomials']"
3384280,Solution of a limit of a sequence $\frac{\sqrt{4n^2+1}-2n}{\sqrt{n^2-1}-n}$,"I'm trying to solve the limit of this sequence without the use an upper bound o asymptotic methods: $$\lim_{n\longrightarrow\infty}\frac{\sqrt{4n^2+1}-2n}{\sqrt{n^2-1}-n}=\left(\frac{\infty-\infty}{\infty-\infty}\right)$$ Here there are my differents methods: assuming $f(n)=\sqrt{4n^2+1}, \,$$\ g(n)=2n$ , $h(n)=\sqrt{n^2-1}$ , $\ \psi(n)= n$ $$f(n)-g(n)=\frac{\dfrac{1}{g(n)}-\dfrac{1}{f(n)}}{\dfrac{1}{f(n)\cdot g(n)}}, \quad h(n)-\psi(n)=\frac{\dfrac{1}{\psi(n)}-\dfrac{1}{h(n)}}{\dfrac{1}{h(n)\cdot \psi(n)}}$$ I always have an undetermined form. I've done some rationalizations: $$\lim_{n\longrightarrow\infty}\frac{\sqrt{4n^2+1}-2n}{\sqrt{n^2-1}-n}=\lim_{n\longrightarrow\infty}\frac{\sqrt{4n^2+1}-2n}{\sqrt{n^2-1}-n}\cdot \frac{\sqrt{4n^2+1}+2n}{\sqrt{4n^2+1}+2n}$$ where to the numerator I find $1$ and to the denominator an undetermined form. Similar situation considering $$\lim_{n\longrightarrow\infty}\frac{\sqrt{4n^2+1}-2n}{\sqrt{n^2-1}-n}=\lim_{n\longrightarrow\infty}\frac{\sqrt{4n^2+1}-2n}{\sqrt{n^2-1}-n}\cdot \frac{\sqrt{n^2-1}+n}{\sqrt{n^2-1}+n}$$ $$\frac{\sqrt{4n^2+1}-2n}{\sqrt{n^2-1}-n}=\frac{n\left(\sqrt{4+\dfrac{1}{n^2}}-2\right)}{n\left(\sqrt{1-\dfrac{1}{n^2}}-1\right)}\rightsquigarrow \left(\frac{0}{0}\right)$$ At the moment I am not able to think about other possible simple solutions.","['limits', 'calculus', 'sequences-and-series']"
3384306,"$P$ is a point inside triangle $ABC$ such that $\angle PBC=30°,\angle PBA=8°$ and $\angle PAB=\angle PAC=22°$. Find $\angle APC$, in degrees.","$P$ is a point inside triangle $ABC$ such that $\angle PBC=30°,\angle PBA=8°$ and $\angle PAB=\angle PAC=22°$ . Find $\angle APC$ , in degrees. If you continue the $AP$ so that it meets $BC$ at $D$ you get that angle $DBP$ = $BPD$ therefore triangle $BDP$ is isosceles but I don’t know what to do next, hints and solutions would be appreciated Taken from the 2009 IWYMIC","['contest-math', 'euclidean-geometry', 'geometry']"
3384346,"Seeking reference for ""prome"" example (showing unique factorization isn't obvious)","The Fundamental Theorem of Arithmetic says that every positive integer can be expressed uniquely as a product of primes. Although this theorem is famous and has been known for a long time, it is not trivial, and is not as simple to prove as the fact that every positive integer can be written in at least one way as a product of primes. There's a cute example that I think does a good job of explaining to students (and to experienced mathematicians, for that matter) why the Fundamental Theorem of Arithmetic isn't obvious. I saw it somewhere when I was an undergraduate, but I can't remember where. That example is: Suppose our number system consists of all even positive integers, and we call such a number ""prome"" if it cannot be written as a product of two smaller numbers in the set. Then: 2 is prome 4 is not prome (4 = 2*2) 6 is prome (because 1*6 and 2*3 are not factorizations into even integers) 8 is not prome (8 = 2*4) 10 is prome (because 1*10 and 2*5 are not factorizations into even integers) 12 is not prome (12 = 2*6) We can then notice that 36 can be written as a product of ""promes"" in two different ways: 2*18 and 6*6. My question is: Where did I see this argument? I believe I may have read it in a textbook in the library of my undergraduate institution, which would make it no later than 1995. (The word ""prome"" was used in the document I read; it's not my paraphrase.)","['number-theory', 'elementary-number-theory', 'reference-request']"
3384442,How do I create a probability distribution for the number of games people play in this scenario?,"From a population of individuals the following statistics are reported: 20% play league of legends (event L) 45% play dota (event D) 30% play halo (event H) 15% play league of legends and dota 20% play dota and halo 10% play league of legends and halo 5%  play all games mentioned. Consider a randomly selected gamer from this population. Let Y= the number of games they play. Find a probability distribution for Y. I don't see how I'd find any p values here. I'm not told how to find when Y=1, 2 or 3 since they're all combined? I was thinking I could do $P(Y\geq 1)$ , $P(Y\geq 2)$ , $P(Y=3)$ but I'm not sure if that would answer the question.","['statistics', 'probability-distributions', 'probability']"
3384449,Smooth function $y$ that satisfies $dy|_p=w$ for covector $w$.,"If $M$ is a smooth manifold, $w\in T^*_pM$ , then is it possible to find a smooth function $y:M\to \mathbb{R}$ such that $dy|_p=w$ . If it is, is there an easy way to give $y$ explicitly? I have just learned about covectors and I am not really understanding them overly well.","['differential-topology', 'co-tangent-space', 'differential-geometry']"
3384535,Possible draws in which exactly one player gets exactly one 8,"The card deck has 30 cards in three different colors. Cards of each color are numbered 1 to 10. Each player draws 4 cards. The order in which cards are drawn to players' hands is not important. The question is in how many possible draws exist in which exactly one player receives exactly one card which has the number 8 on it. 
I thought that there are 2 players, for each player 3 options to draw the 8, $27 \choose 3$ for the three other cards for that player and another $24 \choose 4$ cards for the other player.
This totals to 186,486,300 which is not the correct answer. Any guidance would be appreciated.",['probability']
3384549,Finding $\sin 0.01$ to a first-order approximation (in the sense of a Taylor series expansion around $0$),"I am trying to understand what I need to calculate here exactly: To a first-order approximation (in the sense of a Taylor series expansion around 0), what is $\sin 0.01$ ? If I understood it correctly, I have to calculate the first order Taylor series for the function $f(x) = sin(x)$ where $x = 0.01$ . I get the following: $$f(x) = \sin(a) + \cos(x)(x-a)$$ and if I plug in $x = 0$ and $a = 0.01$ I just get $0.01$ as the answer again.","['approximation', 'trigonometry', 'taylor-expansion']"
3384570,How many bit strings of length 8 have a weight of 5 start with 101 OR end with 11.,"I'm very close to solving this problem but finding the final answer is proving problematic. A: 101x xxxx  = 32 strings starting with 101 
B: xxxx xx11  = 64 strings ending with 11 
C: 101x xx11  = 8 strings with both of these. The number of strings with weight five is equal to 56. It is also important to note the number of strings starting with 101 with weight five is equal to 10
and the number of strings ending in 11 with weight five is equal to 20. Therefore I thought the answer would've been 22 i.e. sum of 10 + 20 minus the strings common to both given this is an or problem.","['combinatorics', 'discrete-mathematics']"
3384589,Maximizing chance that randomly drawn numbers fill a row or column,"This is just a problem I have thought of. Let us say we have a square matrix of dimension $n$ with possible entries $1, 2, 3,..., n^2$ and we can freely distribute the entries in the matrix, each one has to be used exactly once. The numbers then are drawn without replacement. The probability that number $k$ is drawn is $0 \leq P(k) \leq 1$ with $\sum_{k=1}^{n^2}P(k)=1$ Now, we know the probabilities of the draws before we fill in our matrix. Let us say we sorted them such that $0 \leq p_1 \leq p_2 \leq ... \leq p_{n^2}$ . We want to cheat and optimally distribute the numbers in order to minimize the expected number of draws until we cross out a whole row or column. Is this a known problem? Is there an optimal strategy on how to distribute the probabilities $p_i$ in our matrix to minimize the expected number of draws until we cross out a whole row or column, and what is one such strategy? I was thinking of determining the expected value of number of draws to get a certain number (then determine expected draws to get whole rows and columns and minimize those), but I do not think I can define it only given the $P(k)$ , I would need to define how they change after each draw. I was thinking that it is reasonable to remodel the probabilities after each draw for nonzero $P(k)$ . 
Let us call $D$ the set of already drawn numbers. Then for $k \notin D$ with $P(k)\neq 0$ we do $$P'(k)=\frac{P(k)}{1-\sum_{ d \in D}P(d)}$$ But it sounds horribly complex! Then again, it shouldn't matter, because if we have some remaining nonzero probabilities, their new probabilities are in the same order, that is if $P(k) \geq P(l)$ and both were not drawn, then $P'(k) \geq P'(l)$ .","['puzzle', 'probability', 'maximum-likelihood']"
3384605,Proof that sets are equal,"I want to prove that $(A\setminus B)\setminus(A \setminus C)=(A  \cap C)\setminus B $ , so  I did this: $ x \in (A \setminus B)\setminus(A \setminus C) \iff $ $ (x \in A \setminus B)  \wedge   (x \notin A \setminus C)    \iff  $ $ (x \in A \wedge x \notin B) \wedge (x \notin A \vee x \in C)   \iff   $ $ (x \in A \wedge x \notin B \wedge x \notin A)  \vee (x \in A \wedge x \notin B \wedge x \in C)   \iff $ (Now,  the statement in the first bracket is always false, so the truth value of the whole disjunction  in the line above depends only on the second bracket) $x \in A \wedge x \notin B \wedge x \in C   \iff $ $ x \in  (A  \cap C) \setminus B $ Is the method correct? Thanks in advance.","['elementary-set-theory', 'proof-verification']"
3384617,Intersection/union of measurable and nonmeasurable sets,"Given a (Lebesgue) measurable set $A$ and a nonmeasurable set $B$ , when is $A \cap B$ measurable? Nonmeasurable? I think I know a case where the intersection turns out to be nonmeasurable (it involves the Cantor-Lebesgue function). I assume there are trivial cases (e.g. intersecting two disjoint sets), but I'm curious about more general results. Also, what about the union of measurable and nonmeasurable sets? I apologize in advance if this is a duplicate; I looked around MSE for a bit so to my knowledge it is not.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
3384619,Geometric Distribution - Coin Flip [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question You have a coin with unknown probability p of coming up heads. You wish to generate a random variable which takes the values 0 and 1, each with probability 1/2. Assume 0 < p < 1. You adopt the following procedure. You start by flipping the coin twice. If both flips produce the same side of the coin, you start again. If the result of the first flip is different from the result of the second flip, you report the result of the first flip and you are finished (this is a trick originally due to John von Neumann). (a) Show that, in this case, the probability of reporting heads is 1/2. (b) What is the expected number of flips you must make before you report a result? I don't know how to start, any help would be appreciated!!!","['statistics', 'probability']"
3384642,Example of a fact about divisors on a surfare,"Could you please give me a nice example of the following fact?
Let $X$ be an algebraic surface, let $D$ be a divisor on it and let $C$ be a curve not included in the support of $D$ . Then $$
\dim \frac{ \mathcal{L}(D)}{\mathcal{L}(D-C)} \leq D \cdot C +1
$$ where on the right hand side we have the intersection multiplicity. I have tried this cases but I was not able to figure them out: a line (as $D$ ) and a smooth conic/cubic (as $C$ ) on a plane. Is it also possible to give some examples of this on quadric surfaces? Thanks in advance!","['divisors-algebraic-geometry', 'algebraic-geometry', 'projective-geometry', 'arithmetic-geometry']"
3384688,"To use Mean Value Theorem to prove $f(x)=\tan(x)$ increases over $(-\pi/2,\pi/2)$, don't we need $f(\pm\pi/2)$? Yet these values are undefined.","Prove with the Mean Value Theorem that the function $\tan(x)$ increases in the interval $(\frac{-\pi}{2}, \frac{\pi}{2})$ . My problem is that to use the Mean Value Theorem you need $f(\frac{\pi}{2})$ and $f(\frac{-\pi}{2})$ but in those values it's undefined. I asked if I could use a smaller interval but I was told I must to use $(\frac{-\pi}{2}, \frac{\pi}{2})$ . Thanks for reading.","['monotone-functions', 'calculus', 'trigonometry']"
3384689,What is wrong with this proof of Cartan's second equation?,"Let $(M,g)$ be a Riemannian manifold and $\nabla$ a metric compatible connection. Let $\{e_a\}$ be a local orthonormal basis of vector fields on some open set $U\subset M$ . We define the connection $1$ -forms $\omega^a_b$ by $$\nabla_X e_b = \omega^a_b(X)e_a.$$ Let $\operatorname{Rm}$ be the Riemann tensor defined by $$\operatorname{Rm}(X,Y)Z=\nabla_X\nabla_YZ-\nabla_Y\nabla_XZ-\nabla_{[X,Y]}Z.$$ One defines the curvature $2$ -forms $\Omega^a_b$ by $$\frac{1}{2}\operatorname{Rm}(X,Y)e_b=\Omega^a_b(X,Y)e_a.$$ I want to prove Cartan's second equation $$\Omega^a_b=d\omega^a_b-\omega_b^c\wedge \omega_c^a.$$ I just computed $\operatorname{Rm}(X,Y)e_b$ using the connecton $1$ -forms: $$\operatorname{Rm}(X,Y)e_b = \nabla_X\nabla_Y e_b - \nabla_Y \nabla_X e_b - \nabla_{[X,Y]}e_b\\
=\nabla_X\left[\omega^a_b(Y)e_a\right]-\nabla_Y\left[\omega^a_b(X)e_a\right]-\omega^a_b([X,Y])e_a\\
=X(\omega^a_b(Y))e_a+\omega^a_b(Y)\nabla_X e_a-Y(\omega^a_b(X))e_a-\omega^a_b(X)\nabla_Y e_a-\omega^a_b([X,Y])e_a.$$ Now we know that $$d\omega^a_b(X,Y)=X(\omega^a_b(Y))-Y(\omega^a_b(X))-\omega^a_b([X,Y]),$$ hence the above evaluates to $$\operatorname{Rm}(X,Y)e_b = d\omega^a_b(X,Y)e_a + \omega^a_b(Y)\omega^c_a(X)e_c-\omega^a_b(X)\omega^c_a(Y)e_c\\
=d\omega^a_b(X,Y)e_a-2 \omega^a_b\wedge \omega_a^c(X,Y) e_c.$$ Now this last equation gives, upon using the definition of the curvature $2$ -forms $$\Omega^a_b = \dfrac{1}{2}d\omega^a_b - \omega_b^c\wedge \omega_c^a.$$ So there is this $1/2$ factor wrong in front of $d\omega^a_b$ . I have already read my computations again a few times but did not spot what I'm doing wrong. So what is wrong with my approach? Why I'm getting this $1/2$ in front of $d\omega^a_b$ ?","['curvature', 'proof-verification', 'riemannian-geometry', 'differential-geometry']"
3384690,Adjoints to $f^\ast: \mathscr P(L)\to \mathscr P(K)$,"An exercise from Leinster: Here is my attempt. Let $\hat f:\mathscr P(K)\to\mathscr P(L)$ be the function given by $\hat f(T)=\{y\in L:y=f(x)\text{ for some }x\in T\}$ . Note that $\hat f$ is order preserving. We find left and right adjoints below. (1.) Let's find a right adjoint. This must be an order preserving function $G:\mathscr P(K)\to \mathscr P(L)$ such that $$\mathscr P(K)(f^\ast(l),k)\cong\mathscr P(L)(l,G(k)).$$ This means the following: $$f^\ast(l)\subseteq k \text{ iff } l\subseteq G(k)$$ or $$\{x\in K: f(x)\in l\}\subseteq k \text{ iff } l\subseteq G(k)$$ If $G=\hat f$ , then the above holds. (2.) Let's find a left adjoint. This is an order preserving function $F:\mathscr P(K)\to\mathscr P(L)$ such that $$\mathscr P(L)(F(k),l)\cong \mathscr P(K)(k, f^\ast(l))$$ i.e. $$F(k)\subseteq l\text{ iff } k\subseteq \{x\in K: f(x)\in l\}$$ And again we can take $F=\hat f$ . Are the above arguments correct? Do I also need to verify the naturality conditions below in each case? I'm asking because they state that two arrows are equal, but in a poset category any two arrows between same objects are automatically equal.","['logic', 'category-theory', 'order-theory', 'elementary-set-theory', 'adjoint-functors']"
3384694,Functions Agreeing on Zariski Dense Sets,"Let $X$ be an affine variety and $U\subset X$ Zariski open, Then, $U$ is dense in $X$ (i.e., the smallest set containing $U$ which is also the zero locus of a set of polynomials is $X$ ). Let $\varphi_1$ and $\varphi_2$ be continuous and agreeing on $U$ . Does it follow that $\varphi_1$ and $\varphi_2$ agree on $X$ ? I'm trying to build intuition about how Zariski density is related to Euclidean density w.r.t. mappings.","['zariski-topology', 'general-topology', 'algebraic-geometry']"
3384706,Show that $(M_n(R))[X]\cong M_n(R[X])$,"Let R be a ring, show that $(M_n(R))[x]\cong M_n(R[x])$ . Given a matrix $A\in M_n(R[X])$ , $(A)_{ij}=\sum_0^nb_k^{ij}x^k$ (where $b_k^{ij}$ is the  coefficent of the k'th power on the polynomial). If I define $A_k\in M_n(R)$ such that $(A_k)_{ij}=b_k^{ij}$ , and let $n>0$ such that we define $(X^n)_{ij}=\begin{cases}0&\text{if } i\neq j\\x^n&\text{if }i=j \end{cases}$ . Then $(A_kX^k)_{ij}=\sum_{r=0}^n(A_k)_{ir}(X^k)_{rj}=\sum_{r=0}^nb_k^{ir}(X^k)_{rj}=b_k^{ij}x^k$ . Therefore $(A)_{ij}=\sum_{k=0}^n(A_kX^k)_{ij}$ which implies $A=\sum_{k=0}^nA_kX^k$ .(In the case $k=0$ $A_0$ is well defined so there's not trouble there) I have two questions: 1) how do I show that the $X^k$ I defined is the one in the expansion of a polynomial in $(M_n(R))[x]$ . 2) If the above holds is this injection well defined? I can't seem to prove it. Edit: as the comment below says, $R$ may not contain a multiplicative identity.","['matrices', 'ring-theory', 'polynomial-rings']"
3384744,Is random homomorphism from free product of $k$ copies of $\mathbb Z_2$ to orthogonal group $O(3)$ injective?,"Consider the group $G = \ast_{i=1}^k \mathbb Z_2 = \langle (g_i)_{i=1}^k : g_i^2 = 1 \rangle$ . Suppose we define a homomorphism $\phi$ from $G$ to $O(3)$ by setting $\phi(g_i)$ to the reflection in a randomly chosen plane $H_i = \{x\in\mathbb R^3 : x\cdot \hat v_i = 0\}$ , where the unit vectors $\hat v_i$ are iid and uniformly distributed over the sphere. Can we show that $\phi$ is injective almost surely? Someone else has written some code (for a programming competition) that relies on that assumption , but they did not describe a proof, and while the assumption seems intuitively obvious to me, I have been unable to produce a formal proof. I'm also curious whether this is true in $O(2)$ or in higher dimensions. [edit: It's false for $O(2)$ when $k > 2$ . The identities at https://en.wikipedia.org/wiki/Rotations_and_reflections_in_two_dimensions imply any such $\phi$ will have $(g_1g_2g_3)^2$ in the kernel regardless of $\hat v_1,\hat v_2,\hat v_3$ .]","['reflection', 'orthogonal-matrices', 'free-product', 'group-theory', 'random-variables']"
