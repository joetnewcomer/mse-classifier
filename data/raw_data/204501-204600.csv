question_id,title,body,tags
4052469,Negative moments of Marchenko-Pastur law,"Let $Z \sim \mu_\lambda$ be a the Marchenko-Pastur law with parameter $\lambda \in (0,\infty)$ , and let $k$ be a negative integer Question. Is there an analytic formula the $k$ th moment for $m_k(\lambda) = \mathbb E[Z^k]$ ? Note. I'm particularly inteteresting in $m_{-1}(\lambda)$ and $m_{-2}(\lambda)$ . Motivation $m_k(\lambda)$ is the trace of the pseudo-inverse of the $k$ th power a Wishart random matrix (inverse covariance matrix in gaussian iid random design). Application: generalization error of least-squares regression Consider a distribution $P$ on $\mathbb R^d \times \mathbb R$ defined by $(x,y) \sim P$ iff $x \sim N(0,(1/d)I_d)$ and $y|x \sim N(w_\star^\top x,\sigma^2)$ , where $w_\star \in \mathbb R^d$ and $\sigma \ge 0$ are fixed by unknown. Thus a point drawn from $P$ is of the form $(x,y)$ where $y=xw_\star+\eta$ , with $\eta \sim N(0,\sigma^2)$ . Let $\mathcal D_n := \{(x_1,y_1),\ldots,(x_n,y_n)\} \sim P^n$ be an iid sample from $P$ .
Consider the problem of estimating $w_\star$ from the data $\mathcal D_n$ . For $n < d$ , $XX^\top$ is invertible w.p $1$ and the least-squares solution is given by $\hat{w} = X^\top(XX^\top)^{-1}y=P_X w_\star + X(XX^\top)^{-1}\varepsilon$ , where $X$ is the $n \times d$ matrix with $i$ th row $x_i$ , $P_X := X^\top (XX^\top)^{-1} X$ is the orthogonal projection matrix onto the row space of $X$ , $\epsilon$ is a column vector in $\mathbb R^n$ with iid components from $N(0,\sigma^2 I)$ , and $y = Xw_\star+\varepsilon$ . For any $w \in \mathbb R^d$ , let $f_w:\mathbb R^d \to \mathbb R$ be the linear function $f_w(x):=w_\star^\top x$ . Thus, the generalization error of the model $f_{\hat{w}}$ is given by $$
\begin{split}
E_g &:= \mathbb E_{x}\mathbb E_\varepsilon[(w_\star^\top P_X x + \varepsilon^\top (XX^\top)^{-1} Xx - w_\star^\top x)^2]\\
&= (1/d)\|(I-P_X)w_\star\|^2+(\sigma^2/d)\mbox{tr}((XX^\top)^{-1}).
\end{split}
$$ Noise only model. For simplicity, assume $w_\star = 0$ . Then, in the limit when $n,d \to \infty$ with $n/d \to \lambda \in [0,1)$ , we have $$
E_g = \sigma^2\frac{1}{d}\mbox{tr}((XX^\top)^{-1}) \to \sigma^2 m_{-1}(\lambda),\,X\text{-a.s}.
$$ Thanks to the accepted answer, we conclude that $E_g \to \dfrac{\sigma^2}{1-\lambda}$ , $X$ -a.s.","['random-matrices', 'statistics', 'probability']"
4052473,Two circles inscribed in a semicircle,"Two circles are inscribed in a semi circle. Given the areas of the shaded triangles, what's the radius of the semicircle?
(Note there's a similar but different question here )",['geometry']
4052491,Probability for dummies,"I am the least mathematical person around, so apologies if this question is really dumb, but I'm trying to improve! I've been reading loads of examples everywhere but I'm having a hard time applying the logic/rules of probability to new problems. Let's say you have to win three out of three rounds of a game in order to win a prize. It is a single player game. The probability of a boy winning a round is $.25$ , and the probability of a girl winning a round is .4. Winning one round doesn't influence the result of the next round. So if I haven't misunderstood, the probability of a girl winning a prize is $.4 \cdot .4 \cdot .4 = 0.064$ and the probability of a boy winning a prize is $.25 \cdot .25 \cdot .25 = 0.016$ Now, this is where I'm stuck. What's the overall probability of a person winning a prize if $50\%$ of the players are girls and $50\%$ of the players are boys? Is it just $.016 + 0.064 = 0.08$ ? Or should I be dividing by $2$ here somewhere given that it's $50$ percent boys and $50$ percent girls. Thanks in advance for your help.",['probability']
4052520,Singular points on cubic curves,"I am trying to prove the following claim: Let $K$ be a field and let $f \in K[x]$ be a monic cubic polynomial. Define the cubic curve $C: y^2 = f(x)$ . If $C$ has a singularity $(a, b)$ , then $b = 0$ and $a$ is a solution to $f(x) = 0$ . I feel like I have a proof, but I'm not sure if it is correct because I feel that it is too simple. Proof. Write $f(x) = x^3 + ax^2 + bx + c$ where $a, b, c \in K$ and consider the polynomial $P(x, y) = y^2 - f(x)$ which defines the curve $C$ . Suppose $(p, q)$ is a singularity of $C$ . Then this implies that $$
\frac{\partial P}{\partial y}(p, q) = 2q = 2 \sqrt{f(p)} = 0.
$$ It thus follows that $q = 0$ and $f(p) = 0$ . $\, \, \blacksquare$ Would you agree that this is a proof? If not, can you point out where the error is? Thanks in advance.","['cubics', 'algebraic-geometry', 'solution-verification', 'elliptic-curves']"
4052527,What's the cardinality of the infinity introduced in Riemann sphere model? [duplicate],"This question already has answers here : Is $\lim\limits_{n\rightarrow\infty} n$ comparable to $\aleph_0$? (3 answers) Can the extended real number $+\infty$ be compared to transfinite numbers such as $\aleph_0$? (2 answers) $\infty$ and $-\infty$ are to $\aleph_0$ / $\beth_0$ as ""what"" is to $\beth_1$? (2 answers) Closed 3 years ago . In the Riemann sphere model, people extend the complex plane with a point at infinity: $\mathbb {C} \cup \{\infty \}$ and claim this expression: $\frac{1}{0}=\infty$ . I'm confused with what is this $\infty$ . Is it a member of $\{\aleph_n\}$ numbers?
When we study infinities, we usually discuss cardinality. Does this $\infty$ corresponds to something's cardinality?","['cardinals', 'real-analysis', 'complex-analysis', 'infinity', 'elementary-set-theory']"
4052536,Bounds on triple integral (Cartesian),"I want to setup a triple integral for the volume of the surface in the ordering $dy \hspace{1mm} dx \hspace{1mm} dz$ : So far I have that for $0\leq z \leq 1, 0 \leq y \leq x$ and for $1 \leq z \leq 2, 0 \leq y \leq \sqrt{2-z}$ . I'm having trouble setting up bounds for $x$ . It looks from the projection like $0 \leq x \leq 1$ for both integrals, but it doesn't give me the right value for volume (should be $\frac{11}{12}$ based on the other differential orderings.)",['multivariable-calculus']
4052553,Why are pull backs always defined for 1 forms but not push forwards?,"So I know that given a differentiable function $\mathcal{F}: \mathcal{M} \rightarrow \mathcal{N}$ , we can define the push forward map: $$
\mathcal{F}_*: T_p(\mathcal{M}) \rightarrow T_{\mathcal{F}(p)}(\mathcal{N})
$$ However, the pull back map for vectors would require the inverse function $\mathcal{F}^{-1}$ which may not necessarily exist and this is why we cannot define a pull back for vector fields. Now coming to forms, I do not understand why the pull back is always defined while the push forward is not? That is, given that I know $\langle \omega, v \rangle$ , shouldn't I be able to define $\langle \mathcal{F}_* (\omega), \mathcal{F}_*(v)\rangle$ ? Why is this not possible?","['pullback', 'differential-forms', 'differential-geometry']"
4052659,Equivalent definitions of Borel $\sigma$-algebra,"I am reading Christopher Heil's Introduction to Real Analysis and there I found the following definition of the Borel $\sigma$ -algebra. First denote $\mathcal{E}$ as a collection of subsets of $X$ . Then the $\sigma$ -algebra generated by $\mathcal{E}$ , $\Sigma(\mathcal{E})$ , is the smallest one containing $\mathcal{E}$ . That is $$
\Sigma(\mathcal{E}) = \cap \left\{{\Sigma : \textrm{$\Sigma$ is a $\sigma$-algebra on $X$ and $\mathcal{E} \subseteq \Sigma$}}\right\}
$$ Now let $\mathcal{U} = \left\{{U \subseteq X : \textrm{$U$ is open}}\right\}$ be the collection of all open subsets of $X$ . Then the Borel $\sigma$ -algebra on $X$ is $\Sigma(\mathcal{U})$ . Moreover, the Borel sets are the members of $\Sigma(\mathcal{U})$ . On the other hand, the Wikipedia page of Borel sets says that Borel sets are the ones that can be written as countable combination of unions, intersections and complements of open sets, and that the Borel $\sigma$ -algebra is the $\sigma$ -algebra containing the Borel sets. My question is the following: How can we conclude that the first definition implies that any member of $\Sigma(\mathcal{U})$ can be written as countable combination of unions, intersections and complements of open sets? EDIT: From my understanding we can state something like this. Define the following four functions acting on $\mathcal{P}(X) \times \mathcal{P}(X) \rightarrow \mathcal{P}(X)$ : $$
\begin{align}
s(A,B) &= A \cup B \\
d(A,B) &= A \cap B \\
c(A,B) &= X - A \\
i(A,B) &= A
\end{align}
$$ Then for any Borel set $B$ there exists a sequence of open sets $\left\{{U_k}\right\}_{k \in \mathbb{N}}, U_k \in \mathcal{U}$ and a sequence of functions $\left\{{f_k}\right\}_{k \in \mathbb{N}}, f_k \in \left\{{s,d,c,i}\right\}$ such that (if that even makes sense) $$
B = \cdots f_3(f_2(f_1(U_1,U_2),U_3),U_4) \cdots
$$ My question is how the intersection definition of the Borel $\sigma$ -algebra implies the aforementioned representation of Borel sets.","['general-topology', 'measure-theory', 'analysis']"
4052679,"For which rational coefficients is $a+b\alpha+c\alpha^2+d\alpha^3+e\alpha^4$ constructible, where $\alpha=3^{1/5}$?","Let be $\alpha=3^{1/5}$ , and be $\gamma$ the number $$
\gamma=a+b\alpha+c\alpha^2+d\alpha^3+e\alpha^4
$$ with $a,b,c,d,e \in \mathbb{Q}$ . For which $a,b,c,d,e \in \mathbb{Q}$ is $\gamma$ constructible? I know the field of constructible numbers is closed by square roots and the Wantzel theorem for constructibility, but I didn't get anywhere. Any hint?","['field-theory', 'number-theory', 'galois-theory', 'geometric-construction']"
4052728,Proving that there is a path in set.,"Given that $\underline Y$ is a subspace of $\underline ℝ^2$ and defined as follows: $$I = [0,1]$$ $$X = (\{1\} × I) ∪ \left(I × \left(\{0\} \cup\left\{ \frac{1}{n} \,\Bigg\vert\, n \in \Bbb N \right\}\right)\right)$$ $$Y = X \setminus \{ (0.5, 0) \}$$ How can one prove that there is no path from $(0,0)$ to $(1,0)$ using sequences? To show the contradiction I started by assuming that such a map exists: $$f: \underline{I} \rightarrow \underline Y \ \text{continuous map}$$ $$f(0) = (0,0),\ \ f(1) = (1,0)$$ If $f$ is continuous, then it must hold that $f^{-1}[\ [0,0.5)\times \{0\} ] = A$ is a closed set. So $A$ contains its maximum $m$ . From here on I'm not sure how to proceed. I wanted to somehow show that there is a sequence that due to $m$ being in $A$ cannot converge to $f(m) = (x,0)$ .",['general-topology']
4052732,Property of a covariant derivative of a vector field along a curve,"I am studying the covariant derivative of a vector field $X$ along a curve $\gamma$ ( $\nabla_{\dot \gamma}X:=\frac{\nabla X}{dt}$ ) and I have read the following property: $$\nabla_{\dot \gamma}X=\Big(\frac{d \xi^k}{dt}+\Gamma_{ij}^k\frac{dx^i}{dt}\xi^j\Big)\frac{\partial}{\partial_k}$$ In order to prove this above I have thought that if $X=\xi^j \frac{\partial}{\partial x^j}$ and $\dot \gamma= \frac{dx^i}{dt} \frac{\partial}{\partial x^i}$ , we have that:
since $\nabla X=\Big(\frac{\partial \xi^k}{\partial x^j}+\Gamma_{ji}^k\xi^j\Big)\frac{\partial}{\partial_k}$ we obtain: $$\nabla_{\dot \gamma}X=\nabla_{\frac{dx^i}{dt}\frac{\partial}{\partial x^i}}(\xi^j \frac{\partial}{\partial x^j})=\frac{dx^i}{dt}\Big(\nabla_{\frac{\partial}{\partial x^k}}(\xi^j \frac{\partial}{\partial x^j})\Big)=\frac{dx^i}{dt}\Big(\xi^j\nabla_{\frac{\partial}{\partial x^i}}( \frac{\partial}{\partial x^j})\Big)+\frac{dx^i}{dt}\Big(\xi^j\frac{\partial}{\partial x^i}\Big)\frac{\partial}{\partial x^j}=\Big(\frac{dx^i}{dt}\xi^j\Gamma_{ij}^k\frac{\partial}{\partial x^k}+\color{red}{\frac{dx^i}{dt}(\frac{\partial}{\partial x^i})}\frac{\partial}{\partial x^j}\Big)=\Big(\frac{dx^i}{dt}\xi^j\Gamma_{ij}^k\frac{\partial}{\partial x^k}+\color{red}{\frac{d\xi^j}{dt}}\frac{\partial}{\partial x^j}\Big)=\Big(\frac{dx^i}{dt}\xi^j\Gamma_{ij}^k+{\frac{d\xi^k}{dt}}\Big)\frac{\partial}{\partial x^k}$$ where the last equality is obtained considering the index $j$ in the second term as $k$ . $\textbf{My question:}$ do you think that the passages that I have done are correct? In particular it is valid the equality that involves the red quantities (I am not sure that is mathematically rigorous)?","['vector-fields', 'derivatives', 'differential-geometry']"
4052754,"Two random variables $X,Y$ such that $X+Y$ has the same distribution as $X$","Let $X$ and $Y$ be two almost surely finite real-valued random variables which are not necessarily independent. Assume that $X$ is non-negative and $Y$ has a finite, positive mean. Is it possible that $X+Y$ has the same distribution as $X$ ? Note that this is trivial if $\mathbb E(X) < \infty$ , so we can restrict attention to the case when $\mathbb E(X) = \infty$ . It is also easy to prove using characteristic functions if $X$ and $Y$ are independent, but I am interested in the case when they are not independent.","['probability-theory', 'probability']"
4052763,"Counting the number of 2-cycles, 3-cycles and 4-cycles in $S_4$","I know that in $S_4$ there are five different cycle types: double transpositions, 2-cycles, 3-cycles, 4-cycles and 1-cycle (i.e. identity). My question is, does there exist a combinatorial formula or similar for counting the number of, for example, the number of 3-cycles in $S_4$ ?","['finite-groups', 'abstract-algebra', 'combinatorics', 'symmetric-groups', 'group-theory']"
4052765,Does every convex planar set contain a centrally symmetric subset with at least $2/3$ its area?,"Let $S$ be a bounded convex subset of the plane of unit area. Can we guarantee the existence of a centrally-symmetric subset $C⊆ S$ of area $2/3$ ? If $S$ is any triangle, this bound is tight, attained by a hexagon whose vertices are $1/3$ of the way across each side: I suspect the triangle is the unique worst case for this problem, but didn't see a great way to prove it - perhaps there is some other convex shape which only has a centrally symmetric subset of area at most $0.6$ or something, though I would be quite surprised. It's easy to find a $C$ with at least half the area of $S$ , because every convex set contains a rectangle of at least half its area (see e.g. this MO thread for references). How much can we improve this lower bound? In the event of a positive resolution, I am curious whether one can find such a subset only using hexagonal $C$ . I imagine this question is discussed somewhere in the literature; if so, pointers to relevant papers or extensions to higher dimensions would be welcome.","['convex-geometry', 'symmetry', 'geometry', 'reference-request']"
4052771,Statistics question in cosmology,"The following are the approximate parameters for the Benchmark model in cosmology: $H_0 = 73.8 km s^{-1} Mpc^{-1})$ , $\Omega_{m,0} = 0.266$ , and $\Omega_{\Lambda,0} = 0.734$ . Given that we know $H_0$ very precisely to this value in a flat universe (meaning neglecting the negligible contribution from radiation, $\Omega_{m,0} + \Omega_{\Lambda,0} = 1$ ) with $\Omega_{\Lambda,0}$ being an unknown value very close to the given number, if we want to make a measurement of $\Omega_{\Lambda,0}$ with an accuracy of 5%, what is the maximum percent error we can tolerate on our measurement of luminosity distance at z = 0.5, 1.0, and 1.5? Extra note: luminosity distance can be approximated as $$d_L \approx \frac{c}{H_0} z (1 + \frac{1 - q_0}{2} z)$$ Where $$q_0 = \frac{1}{2} \Omega_{m,0} - \Omega_{\Lambda,0}$$ Due to covid, I've been unable to take the statistical physics course that was part of my plan, so it has been since the mid 2000's since I've had a stats course. There are a bunch of follow-up questions, but I'm hoping once I grasp the approach to this one I will be able to do them myself.",['statistics']
4052786,Is there a generalization of orientation?,"The orientation of the wedge product of two vectors has two possibilities (positive or negative). We sometimes imagine that this corresponds to the “handedness.” When we generalize this to higher dimensional wedges, the orientation still has two possibilities. Is there any way to have a generalization of orientation which has more than two possibilities? That is, $w \wedge u$ can be positive or negative, with $u \wedge w$ having the opposite orientation. But might $u \wedge w \wedge \ y$ have three possible orientations? Or perhaps $3!$ or $3!/[(3-1)! 1!]$ signed orientations? Of course, this would no longer mean the same thing as the previous definition of orientation, but it intuitively seems like there might be multiple ways to “orient” higher dimensional objects...","['geometry', 'exterior-algebra']"
4052831,Maxima of combined cosine function,"I'm new to these kinds of functions but I'm interested in mathematical proofs.  Take this function: $f(x) = 1 - \cos(a x) + \cos(b x)$ I assume this can often have no period, so how do you find the maximum and minimum possible values? For example, if $a = 0$ , then the range of possible values is $[-1, 1]$ , and if $b = 0$ , then the range is $[1, 3]$ .  Unless both equal zero, then $f(x) = 1$ . So the maximum possible range for $f(x)$ is $[-1, 3]$ .  But I think with certain values of $a$ and $b$ that this range can be more narrow, just like with $a = 0$ or $b = 0$ . If $f(x)$ is aperiodic, is the maximum range $[-1, 3]$ and can this be proven? Can the possible range be proven to be more narrow in certain circumstances and how would this be proven?","['algebra-precalculus', 'functions', 'trigonometry']"
4052872,Prove a graph is not planar with angles,"In graph theory, I remember the first time proving $K_5$ is non-planar, and I thought it was pretty slick to use Euler's Theorem and some other results to prove this. However, in the back of my mind, I thought there could be another way of doing this that involved angles, vectors, or a constructive argument. There are a lot of results in geometry involving triangulation and other spatial theorems, and I would be curious if there was a way to do it this way. Has anyone seen or able to prove a particular graph is non-planar by using angles, vectors, or a constructive argument?","['graph-theory', 'geometry', 'planar-graphs']"
4052910,Intuition of Algebraic Partition of Unity,"In Vakil's Rising Sea (Nov. 18, 2017 Draft) on p. 130 - 131, he gives a proof that his definition of the structure sheaf on affine schemes indeed defines a sheaf. He coins this proof an argument by ""partition of unity"" . In fact, he writes that the name is due to Serre. (In Vakil's book it appears again, e.g. on p. 161 and p. 203.) My questions are: Why is this called partition of unity? Does it - or in which way does it - resemble the topological/analytical partition of unity? Does anyone have a reference where Serre said this? For those who do not have Vakil's argument in front of their eyes, let me sketch it. Definition. Let $A$ be a ring and we define $\mathcal{O}_{\operatorname{Spec}{A}}(D(f)) = A_f$ with the obvious restriction map. Claim. Suppose $\operatorname{Spec}{A} = \bigcup_{i=1}^n D(f_i)$ for this argument. We want to show that this satisfies the base gluability property. Proof. Let $\frac{a_i}{f_i^{\ell_i}} \in A_{f_i}$ be elements which agree on overlaps $A_{f_i f_j}$ . After some algebraic manipulations (please trust me on this or you may read it in Vakil's book), we can rewrite $\frac{a_i}{f_i^{\ell_i}} = \frac{b_i}{h_i}$ with overlap condition being $h_j b_i = h_i b_j$ and $\operatorname{Spec}{A} = \bigcup_{i=1}^n D(h_i)$ . The latter implies $1 = \sum_{i=1}^n r_i h_i$ for some $r_i \in A$ . The key step is to define $$r = \sum_{i=1}^n r_i b_i.$$ This is an element in $A$ and restricts to $\frac{b_i}{h_i}$ since the overlap condition gives $$ rh_j = \sum_{i=1}^n r_i b_i h_j = \sum_{i=1}^n r_i h_i b_j = b_j. $$ This leaves me with one last question: What motivates the definition of $r = \sum_{i=1}^n r_i b_i$ ?","['motivation', 'algebraic-geometry', 'abstract-algebra', 'intuition', 'sheaf-theory']"
4052938,Calculate the limit $\lim\limits_{n \to \infty}\left(\frac{1}{\sqrt[3]{(8n^{3}+2)}^{2}}+\cdots+\frac{1}{\sqrt[3]{(8n^{3}+6n^{2})}^{2}}\right)$,I have to calculate the limit $$\lim_{n \to \infty}\left(\frac{1}{\sqrt[3]{(8n^{3}+2)}^{2}}+\frac{1}{\sqrt[3]{(8n^{3}+4)}^{2}}+\frac{1}{\sqrt[3]{(8n^{3}+6)}^{2}}+\cdots+\frac{1}{\sqrt[3]{(8n^{3}+6n^{2}-2)}^{2}}+\frac{1}{\sqrt[3]{(8n^{3}+6n^{2})}^{2}}\right)$$ I tried to use Sandwich Theorem like this $$\frac{3n^{2}}{\sqrt[3]{(8n^{3}+6n^{2})}^{2}} \leq \Bigg(\frac{1}{\sqrt[3]{(8n^{3}+2)}^{2}}+\frac{1}{\sqrt[3]{(8n^{3}+4)}^{2}}+\cdots+\frac{1}{\sqrt[3]{(8n^{3}+6n^{2}-2)}^{2}}+\frac{1}{\sqrt[3]{(8n^{3}+6n^{2})}^{2}}\Bigg) \leq \frac{3n^{2}}{\sqrt[3]{(8n^{3}+2)}^{2}}$$ And for result I got that limit is $\frac{3}{4}$ Is this correct?,['limits']
4052970,Study the monotonicity of the following function? No derivatives/graphing,"The function is the following: $f(x) = x^{21} + 3x + 1$ I have to study the monotonicity without graphing (as I don't know how to graph higher than mx+b at the moment) and without derivatives (as I haven't learnt them). Intuitively it is strictly increasing, according to Desmos graphing it is strictly increasing (so I was correct I guess). My approach would be with the ""rate of monotonicity"" as we call it here: We take two variables $x_1 \ne x_2$ . We proceed by doing $R(x_1,x_2) = (f(x_1) - f(x_2)/(x_1-x_2)$ If my calculations are correct, $R(x_1,x_2) = (x_1^{21}-x_2^{21})/(x_1-x_2) + 3$ I just have to prove this $R(x_1, x_2)$ is strictly greater than $0$ . Any advice?","['functions', 'monotone-functions']"
4052994,smooth vector fields over the 2-sphere is not a free module,"I keep seeing that the hairy ball theorem implies that smooth vector fields over $S^2$ are not a free module is implied by the hairy ball theorem; I don't understand how. How do I fill in the gaps? The hairy ball theorem tells us that we cannot have a smooth nonvanishing vector field over $S^2$ . For contradiction, assume that $\mathfrak X(S^2)$ is a free module over the ring $C^\infty (S^2)$ . Thus, $\mathfrak X(S^2) \simeq \oplus_i C^\infty(S^2)$ , since a free module is isomorphic to a direct sum of copies the ring. I am unsure how to continue. I have some ideas: First, see that we need at least two copies of $C^\infty(S^2)$ , because the sphere locally looks like $\mathbb R^2$ . If we have exactly two basis vector fields $V_1, V_2$ , then these must both vanish at points $p_1$ , $p_2$ by the hairy ball theorem. Consider the neighbourhood of $p_1$ : since $v_1$ vanishes, we have only one vector field $V_2$ which is not sufficient to locally span $\mathbb R^2$ . If we have three vector fields, we can have $V_{1, 2, 3}$ vanish at distinct $p_{1 2, 3}$ thereby leaving two vector fields even when one of them vanishes. However, now we can pick a point where none of $V_{1, 2, 3}$ vanish. (Why does such a point exist?). At this point, locally, we have three degrees of freedom $V_{1, 2, 3}$ , but the vector space looks like $\mathbb R^2$ so they cannot be linearly independent. Unfortunately, as is obvious from the above, I have no idea how to make this rigorous. I would appreciate whether this proof is repairable, and if now, how does one actually prove that smooth vector fields over $S^2$ are not  free module?","['differential-topology', 'modules', 'differential-geometry']"
4053004,Intuition: expected value formula of a continuous random variable and Riemann sums,"In my introductory probability class the expected value was given just by definition as $$E[X] = \int_{-\infty}^{+\infty} xf(x) dx$$ with $f(x)$ representing the probability density function of the distribution. But I was thinking about a way to correlate the idea in the discrete case with the one in the continuous case as follows (consider that I haven't studied measure theory yet) : Form a partition of a interval $[a,b]$ so that $a=x_0 < x_1 < ... < x_n = b$ then we write the Riemann sum $$\sum_{i=0}^{n-1} (x_{i+1}-x_{i}) x^* f(x^*)$$ with every $x^* \in [x_{i},x_{i+1}]$ . But now since $(x_{i+1}-x_{i}) f(x^*) \approx P(x_i<x<x_{i+1})$ and this approximation will improve more the points are close, we have something like the discrete case because $$\sum_{i=0}^{n-1} (x_{i+1}-x_{i}) x^* f(x^*) \approx \sum_{i=0}^{n-1} x^*P(x_i<x<x_{i+1}) $$ More the points of the partition increase more a single point $x^*$ becomes the ''right'' value to multiply with $P(x_i<x<x_{i+1}) $ to obtain the expected value , and it's known that the left hand side becomes $\int_{a}^{b} xf(x) dx$ , then letting $a \rightarrow -\infty$ and $b \rightarrow +\infty$ we are done. I think the main problem with this reasoning is the interpretation of $x^*$ to become eventually the ''right'' value. Do you consider this reasoning a valid intuition for the expected value?Thanks in advance","['expected-value', 'intuition', 'probability-theory', 'probability']"
4053007,Why do algebraic curves have to involve polynomials?,"I.e. , why, when we talk about an algebraic curve $f(x, y) = 0$ , do we assume that $f(x,y)$ is a polynomial? Surely the analysis of a curve like $|\cos(z)|^2 = 1$ is not beyond the reach of mathematics -- let alone modern mathematics.  But results like Bézout's Theorem require the curves in question to be polynomial.  Is it that the extension to general analytic functions is too hard? Or, on the other hand, is it too easy ( e.g , do results for more general $f(x,y)$ follow easily from results for polynomial $f(x,y)$ )?","['complex-analysis', 'curves', 'algebraic-geometry', 'algebraic-curves']"
4053047,Convolving the relation $o(x)$,"I'll get right to the point.  For sequences $\{a_n\}$ and $\{b_n\}$ in $\mathbf C$ , let $c_n = \sum_{d \mid n} a_db_{n/d}$ . Set $A(x) = \sum_{n \leq x} a_n$ , $B(x) = \sum_{n \leq x} b_n$ , and $C(x) = \sum_{n \leq x} c_n$ . If $A(x) = o(x)$ and $B(x) = o(x)$ , must it be true that $C(x) = o(x)$ , or is there a (simple) counterexample? And if there is a counterexample, is the conclusion valid if we also assume $A(x)$ or $B(x)$ is $O_\delta(x^{1-\delta})$ for some $\delta$ in $(0,1)$ but introduce no further assumptions? This question came up when editing some course notes. When proving various relations are equivalent to the prime number theorem, the proof that $\sum_{n \leq x} \mu(n) = o(x)$ implies $\psi(x) \sim x$ appears to be basically the same everywhere I have looked and I'd prefer if there were a different argument. In the standard proof (whose basic structure goes back to Landau (see Section 1)), you reduce the problem to checking that $$
\sum_{dd' \leq x} \mu(d)(\log(d') - \tau(d') + 2\gamma) = o(x),
$$ where $\tau(n) = \sum_{d \mid n} d$ and $\gamma$ is Euler's constant. The proof of this $o(x)$ estimate uses the following three properties: $\sum_{n \leq x} \mu(n) = o(x)$ , $\sum_{n \leq x} (\log(n) - \tau(n) + 2\gamma) = O(\sqrt{x})$ , $|\mu(n)| \leq 1$ for all $a$ . Abstracting what makes the proof work, we can say for my question at the start that $A(x) = o(x)$ and $B(x) = o(x)$ implies $C(x) = o(x)$ if we add the conditions that $\{a_n\}$ is bounded (think $a_n = \mu(n)$ ) and $B(x) = O_\delta(x^{1-\delta})$ for some $\delta$ in $(0,1)$ (think $b_n = \log(n) - \tau(n) + 2\gamma$ and $\delta = 1/2$ ). I would prefer a proof of $C(x) = o(x)$ that is more symmetric in the assumptions on $\{a_n\}$ and $\{b_n\}$ while still being applicable to the intended example above ( $a_n = \mu(n)$ and $b_n = \log n - \tau(n) + 2\gamma$ ). I have not seen a result of the form "" $A(x) = o(x)$ and $B(x) = o(x)$ implies $C(x) = o(x)$ "" anywhere, so I suspect it might not be true, but I have not seen (or created) a counterexample either.","['number-theory', 'mobius-function', 'asymptotics']"
4053051,Why are abelian groups of interest? What is their usefulness?,"I am reading about Abelian groups So apparently it is a set, with an associative binary operation, and identity element, an inverse operation and the binary operation must also be symmetric. But it is not clear to me how they are useful. Trying to find why they are important it seems they arise as ""additive structures"" in various systems but this is too abstract for me. Could someone give some less formal/more practical application or usages showing what is important about abelian groups (layman's terms basically)?","['motivation', 'group-theory', 'abstract-algebra', 'abelian-groups']"
4053054,Show $\mu_*$ is a measure,"Suppose $\mu$ is a finitely additive set function on Borel $\sigma$ algebra on $\mathbb R$ with $\mu(\mathbb R)<\infty$ . Define $\mu_*(A)=\sup \{\mu(K)|K\subset A,K$ compact $\}$ . Show that $\mu_*$ is a measure on Borel sets. I cannot even show $\mu_*$ is finitely additive. More specifically, I need help in the following direction. If A,B are disjoint Borel then $\mu_*(A\cup B)\leq \mu_*(A)+\mu_*(B)$ . The issue is, if I take any compact K subset of $A\cup B$ then I cannot split K to get compact sets K1 and K2 subsets of A and B respectively.","['measure-theory', 'real-analysis']"
4053126,Consistency in Statistical Decision Theory,"Let $(\mathcal X,\mathcal F,\mathcal P)$ be a statistical model with $\mathcal P = \{P_\theta : \theta\in\Theta\}$ . A decision rule is a measurable function $\delta:(\mathcal X, \mathcal F)\rightarrow(\mathcal A,\mathcal G)$ . Examples for such decision rules include parameter estimates, or hypothesis tests. This question is concerned with certain properties of decision rules. Definition. A decision rule is said to be unbiased iff $$\mathbb E_{P_\theta}[L(\vartheta, \delta)]\geq\mathbb E_{P_\theta}[L(\theta, \delta)]$$ for each $\theta,\vartheta\in\Theta$ . Assuming a certain loss function $L:(\mathcal A\times\mathcal A, \mathcal G\otimes\mathcal G)\rightarrow(\mathbb R,\mathcal B)$ , this yields the familar concepts for unbiasedness of an estimator and unbiasedness of a hypothesis test: Theorem 1. Assume the $L_2$ loss $L(t,a) = \Vert t - a\Vert_2$ , and $\tau:\Theta\rightarrow\mathcal A$ . Then $\delta$ is unbiased iff $\mathbb E_{P_\theta}[\delta] = \tau(\theta)$ for all $\theta\in\Theta$ , provided that $\mathbb E_{P_\theta}[\Vert\delta\Vert^2_2] < \infty$ , and $\mathbb E_{P_\theta}[\delta]\in\tau(\Theta)$ . Theorem 2. Assume the $0$ - $1$ -loss $L(t,a) = \ell_0 a\mathsf 1_{\Theta_0}(t) + \ell_1(1-a)\mathsf 1_{\Theta_1}(t)$ , where $\ell_0,\ell_1>0$ , $\Theta = \Theta_1\cup\Theta_0$ with $\Theta_1\cap\Theta_0=\emptyset$ , and $\mathsf 1$ is the usual indicator function. Then $\delta$ is unbiased iff $\mathbb E_{P_\theta}[\delta]\leq\alpha$ for all $\theta\in\Theta_0$ , and $\mathbb E_{P_\theta}[\delta]\geq \alpha$ for all $\theta\in\Theta_1$ , where $\alpha = \frac{\ell_1}{\ell_0+\ell_1}$ . Another important concept in testing and estimation theory is consistency: A sequence of estimtors $\delta_n$ is said to be consistent (for $\tau(\theta)$ ) iff $P_\theta(\Vert\delta_n - \tau(\theta)\Vert\geq\epsilon)$ converges to zero for each $\theta\in\Theta$ . Similarily, a sequence of tests $\delta_n$ is said to be consistent iff $\sup_{n\in\mathbb N}\mathbb E_{P_\theta}[\delta_n]\leq\alpha$ for all $\theta\in\Theta_0$ , and $\mathbb E_{P_\theta}[\delta_n]$ converges to $1$ for all $\theta\in\Theta$ . The concepts are clearly related: for estimators, consistency states that the risk converges to zero in probability. For tests it states that the type I error is bounded, while the probability of a type II error converges to zero. It is thus natural to think about generalizations in the decision theory setup stated above. However, I was not able to do so. Is it even possible?","['decision-theory', 'statistics', 'probability-theory']"
4053152,Help required with limit,"In finding the asymptotic value of a certain  quantity I ended up with the following: $$f(n)=(n-1)B_{1/2}(n,n+2)$$ $$g(n)=(n+1)B_{1/2}(n+2,n)$$ $$ h(n)=4^n \left( f(n)-g(n)\right)$$ Numerical simulations lead me to believe that  h(n) approaches 1 as n approaches infinity.However ,i am not able to prove it analytically Can somebody kindly help me with the evaluation of $ \lim_{n \to \infty} h(n)$ ? If somebody could also plug it in Mathematica, I would be highly obliged. Thanks for any help in advance. P.S. : In the above the notation $B_z(a,b)$ stands for the incomplete beta function defined by: $$B_z(a,b)=\int\limits_0^z u^{a-1}(1-u)^{b-1} \mathrm{d}u.$$",['integration']
4053156,"How to interpret ""let"" in mathematics?","Before explaining my issue, I wanted to first explain what things do make sense to me. So, statements (used at the beginning of proofs) like ""Suppose $x$ is an integer"" or ""Assume $x$ is an integer"" make sense to me. The way I read them is like: ""Let's just pretend that the symbol $x$ happens to represent an integer"". Statement (also used in proofs) like ""Let $x$ be 3"" or ""Let $x$ equal 3"" also make sense to me. The way I read them is like: ""Let's just temporarily name 3 with the symbol $x$ . My issue comes with statements like ""Let $x$ be an integer"" or ""Let $x$ $\in$ $\mathbb{Z}$ "". I really do not know how I should intuitively interpret such a statement. I can't interpret it in the same way as like ""Let $x$ be 3"" because there is not a specific object being assigned like 3. Should I interpret it like how I interpret ""Suppose $x$ is an integer""? EDIT: So, from what I gathered from the responses, I think I understand now how I should think of ""Let $x$ be an integer"". I could think of it as ""Assume a newly created symbol x happens to represent an integer"". However, this can cause issues as then ""Let $x$ be an element of the empty set"" is also completely valid. Instead, I should not think of ""Let $x$ be an integer"" as an assumption, but an assignment/declaration, just like ""Let $x$ be 3"". One tangible way to think about this is to imagine myself assigning the newly created symbol $x$ to an integer chosen in secret by a friend. With this mindset, $x$ is not assumed to be an integer - it is an integer. It is just unknown to me what integer it is. I hope this made sense to anybody with similar questions. If anyone thinks I have made an incorrect finding, please feel free to correct me.","['article-writing', 'proof-writing', 'soft-question', 'discrete-mathematics']"
4053197,Evaluating an adelic integral,"I am reading Arthur's notes on the trace formula, and I would like to understand why sometimes the integral appearing there diverge. The example he gives is the following: $G=GL(2)$ , $P_0$ the standard parabolic of upper triangular matrices, and $\gamma$ the matrix $\pmatrix{1&1\\1&1}$ . He then considers the integral $$\int_{G_\gamma(\mathbb A) \backslash P_0(\mathbb A)} \int_{P_0(\mathbb A) \backslash G(\mathbb A)} f(k^{-1}p^{-1}\gamma p k) dp dk$$ Here $dp = |a|^{-1} da db du$ is a left Haar measure if $p = \pmatrix{a & u \\ & b}$ (I also do not understand how the left Haar measure takes this form). Now he claims that this integral reduces to a constant times $$\prod_{p} (1-p^{-1})^{-1} \int_{P_0(\mathbb A) \backslash G(\mathbb A)} \int_{\mathbb A} f(k^{-1}\pmatrix{1& u \\ & 1} k) du dk$$ I do not understands these computations. I tried to write explicitly the variable in $f$ , making the $u$ disappear (yet it is still in Arthur's expression). Also, I tried to cut the adelic integral in product of local integrals to see the factor $(1-p^{-1})^{-1}$ (I think it should come from $|a|^{-1}$ ), but I only end up with $$\int_{G_\gamma(\mathbb A) \backslash P_0(\mathbb A)} \int_{P_0(\mathbb A) \backslash G(\mathbb A)} f(k^{-1}\pmatrix{1 & a/b \\ & 1} k) |a|^{-1} da db du dk$$ I would like to understand how to obtain his statement, e.g. if there are standard tricks to compute such integrals.","['integration', 'number-theory', 'adeles']"
4053209,Why do these two equivalent equations have different implicit differentiations?,"Using implicit differentiation, we have that the derivative of $4x^2y-3/y=0$ is $$\frac{dy}{dx} = -\frac{8xy^3}{4x^2y^2+3}.$$ But, if we multiply both sides of the original equation by y, we have the following equation $4x^2y^2-3=0$ which is seemingly equivalent for $y≠0$ . Taking the derivative of this new function yields $-y/x$ What is causing the difference here. Is it a rule of implicit differentiation or because the $0$ in the original equation that allows us to rewrite it in such a form? I am new to implicit differentiation and any help is appreciated.","['calculus', 'implicit-differentiation', 'derivatives']"
4053273,Does there exist a differentiable function from $\mathbb R^3$ to $\mathbb R$ whose zeros are a line?,"Suppose we are given a line in $\mathbb R^3$ .  Is there a differentiable function, $f$ , from $\mathbb R^3$ to $\mathbb R$ such that the solutions to $f(\vec{x})=0$ are precisely the points on the line? I would like to be able to describe a line using the zeros of a single function rather than using a parametrization. EDIT: I deleted a false claim about not being able to use a polynomial.","['multivariable-calculus', 'roots', 'geometry']"
4053298,Does $\pi:\mathbb{S}^2 \to \mathbb{R}P^2$ have a smooth right inverse?,"Let $\pi: \mathbb S^2 \to \mathbb {RP}^2$ be the projection map. I understand $\pi$ is smooth. Ideally I should use the tangent space, but this only tells me for $x \in \mathbb{S}^2$ that $$\pi_{*,x}:T_x \mathbb{S}^2 \to T_{\pi(x)} \mathbb{R}P^2 $$ is an isomorphism, but I dont know how to use this to construct an inverse for $\pi$ . Edit: Im sorry,The original question was too long for the title, here is a more precise statement Let $\pi$ be the projection map $\pi:\mathbb{S}^2 \to \mathbb{R}P^2$ , does there exist $s: \mathbb{R}P^2 \to \mathbb{S}^2$ such that $\pi \circ s = \text{id}_{\mathbb{R}P^2}$ ?","['smooth-functions', 'smooth-manifolds', 'differential-geometry']"
4053308,Slowpoke and Doubles probability -- does it converge as the numbers of laps increases?,"I posted this on puzzling stack exchange three months ago and it was immediately closed as off-topic, for being a ""fairly straightforward probability calculation"". I have the solution to the problem, which I do not give here in case you might want to solve it yourself. My two questions for this forum are: 1) is this indeed an interesting problem to solve and not ""fairly straightforward"", and 2) how can I prove that the answer for the probability of N laps converges over time (i.e. as N increases)? (This second part I have been unable to solve.) === Here is the original post: === I created this dice and paper game for my kids years ago, and at the same time gave myself an interesting puzzle. This game is a horse race between two horses: Slowpoke and Doubles. With a sheet of lined writing paper, draw vertical lines to make six columns down the paper. The first five columns belong to Slowpoke, and the sixth column belongs to Doubles. Each row across the paper represents one lap around a racetrack. Before the race starts, decide on the number of laps that will be run. You can then have fun predicting which horse will win the race. To begin the race, roll a pair of dice. If you roll a double -- (1,1), (2,2), (3,3), (4,4), (5,5), or (6,6) -- then draw an X in Doubles' column in the first lap. Doubles has just completed the first lap! If you roll anything other than doubles, then draw an X in Slowpoke's first column in the first lap. Slowpoke has made it one fifth of the way around the track. Keep rolling the dice. Each time a doubles comes up, Doubles completes another lap. Each time anything else comes up, Slowpoke advances across the current lap, left to write. Draw an X in the next free column. It will take five non-doubles rolls for Slowpoke to complete the lap. In this way, roll after roll, one or the other horse advances with another X, until finally, one of the two horses completes their last lap and wins! My puzzle for you is: Is one of the two horses favored to win the race? If so, what is the probability that a given horse wins a race of N laps? Enjoy! === UPDATE: @user2661923 I found solving the probability for Doubles is easier than for Slowpoke. It follows a simple pattern. (I'm using spoiler blocks in case others find it interesting to solve on their own.) For one lap: $$ \frac {6^4 + (6^3\cdot 5) + (6^2\cdot 5^2) + (6\cdot 5^3) + 5^4} {6^5} $$ For two laps: $$ \frac {6^9 + (6^8\cdot 5) + (6^7\cdot 5^2) + (6^6\cdot 5^3) + (6^5\cdot 5^4) + (6^4\cdot 5^5) + (6^3\cdot 5^6) + (6^2\cdot 5^7) + (6\cdot 5^8) + 5^9} {6^{11}} $$ For n laps: $$ \sum_{k=0}^{5n - 1} \frac{5^k\cdot 6^{(5n - 1) - k}} {6^{6n - 1}} $$ Which simplifies to: $$ \sum_{k=0}^{5n - 1} \frac{5^k} {6^{k + n}} $$ This last equation I would like to prove continually approaches, but never reaches, 1/2.","['probability-limit-theorems', 'central-limit-theorem', 'probability-theory', 'probability']"
4053331,If $f$ is a function such that $f(f(x))=x^{2}-1$ determine the function $f(f(f(f(x))))$,"I have tried $f(f(f(f(x))))=f\left(f\left(x^{2}-1\right)\right)$ . Since we know that $f(f(x))=x^{2}-1$ , we have $$
\begin{aligned}
f\left(f\left(x^{2}-1\right)\right) &=\left(x^{2}-1\right)^{2}-1 \\
&= x^{4}-2 x^{2}+1-1 \\
&=x^{4}-2 x^{2}.
\end{aligned}
$$ But something doesn't feel right, is there any other way to solve this?","['real-numbers', 'algebra-precalculus', 'functions', 'solution-verification']"
4053380,"Bounded random variables $X,Y$ satisfying $\mathbb{E}(X^mY^n) = \mathbb{E}(X^m)\mathbb{E}(Y^n)$ for every $m, n\in\mathbb{N}$ are independent","Suppose $X, Y$ are bounded random variables and we have that for every $m, n$ positive integers, $\mathbb{E}[X^mY^n] = \mathbb{E}[X^m]\mathbb{E}[Y^n]$ . Then show that $X, Y$ are independent. I have some idea of how this is supposed to go: Using linearity, etc, $\mathbb{E}[f(X)g(Y)]$ = $\mathbb{E}[f(X)]\mathbb{E}[g(Y)]$ for all polynomials $f, g$ . After this we use limit theorems to extend this across all measurable functions, and thus characteristic functions, which will let us conclude that for every measurable set $A, B$ , we have that $\mathbb{E}[1_{X \in A}\cdot 1_{Y \in B}] = \mathbb{E}[1_{X \in A}\cdot 1_{Y\in B}]$ which reduces to $P(X \in A, Y \in B) = P(X \in A)P(Y \in B)$ which gives independence. But all the limit identities and how to use them has never been natural to me, so I wanted to verify and ask for help for the details. First, for continuous functions $f, g$ , we use the Stone-Weierstrass theorem to get polynomials sequences $f_n, g_n$ that converge uniformly to $f, g$ on the bounded interval that $X, Y$ belong to. Then $\mathbb{E}[f_n(X)] \rightarrow \mathbb{E}[f(X)]$ , and similar for $Y, g$ . Which theorem exactly are we using here for this convergence (assuming I'm not doing something completely wrong of course); dominated convergence theorem? Once we get this, we also then demonstrate that $\mathbb{E}[f_n(X)g_n(Y)] \rightarrow \mathbb{E}[f(X)g(Y)]$ which requires showing $f_ng_n \rightarrow fg$ , but this just levarages standard analysis techniques and uses the uniform convergence, am I correct? Next we want to extend this to all measurable functions $f, g$ . For this we use the idea that there are sequences $f_n, g_n$ that will converge a.e pointwise to $f, g$ . Is this enough to conclude that $\mathbb{E}[f_n(X)] \rightarrow \mathbb{E}[f(X)]$ , and similar for $Y, g$ ? It seems we need stronger assumptions here. I'm not entirely sure how valid this last step is and would appreciate some detail.","['measure-theory', 'probability-limit-theorems', 'probability']"
4053462,Top homology of pure algebraic variety,"Given a pure-dimensional complex projective variety X, it is well-known that its top homology $H_{top}(X,\mathbb{Z})$ is freely generated by fundamental cycles of its irreducible components. What is the standard reference for this fact? (i.e. book, page number)","['algebraic-geometry', 'algebraic-topology', 'reference-request']"
4053489,Determinant of a sum of square matrices,"Let $$A=\begin{bmatrix}0&1&0&\cdots 0\\
0&0&1&\cdots 0\\
\vdots\\
0&0&0&\cdots 1 \\
1&1&1&\cdots1
 \end{bmatrix}_{n\times n}$$ i.e. it has ones above the main diagonal except for the last row and the last row has all ones. I am trying to find $\det(A+A^2+\cdots+A^t)$ for $t\leq n $ $\tag{1}$ I have checked that for a few $n$ , $\det(A)=\det(A^2)=\cdots=\pm 1$ . But I am not sure how to prove that. Also determinant of sum of matrices is not equal to sum of determinant of those matrices, so I'm not sure how to find $(1)$ ? Any ideas? **EDIT:**I realize that it is hard to find exact value of $(1)$ and so an upper bound for $(1)$ is also useful to me.","['matrices', 'linear-algebra']"
4053530,Lower Semi-Continuous Functions Arising from Plane Flows,"If $X$ is a Hausdorff space, by a flow I mean a continuous surjection $F: X \times \mathbb{R} \rightarrow X$ such that $F(x, s + t) = F(F(x,s), t)$ for all $x \in X$ and $s, t \in \mathbb{R}$ .  If $x$ is periodic (or fixed) under $F$ , then let $p_F(x)$ denote the minimal non-negative time such that $F(x, p_F(x)) = x$ .  Otherwise, write $p_F(x) = \infty$ . In other words, $p_F(x)$ is the length of the period of $x$ , and is infinite when $x$ is not periodic. Then by a continuity argument you can show that the function $p_F(x)$ is lower semi-continuous from $X$ into $[0, \infty]$ ; especially, if $x_n \rightarrow x$ and $ 0 < p_F(x) = r < \infty$ , then every finite accumulation point of $\lbrace p_F(x_n) \rbrace$ is a positive integer multiple of $r$ , as necessary due to the continuity of F. What lsc functions $f: \mathbb{R}^2 \rightarrow \mathbb{R}$ arise as $p_F$ for some plane flow $F$ ? It's not all of them: For example, if $f$ is constantly $1$ except at a single point, where it takes the value $\frac{1}{2}$ .  By the above argument, any jump discontinuity must be an integer multiple of the lower limit value, but the previous example shows that this is not sufficient.  Note that in the plane any non-periodic orbit of a flow is homeomorphic to $\mathbb{R}$ , providing another 'obvious' constraint. What are some other properties that might be sufficient to allow an associated flow?","['general-topology', 'semicontinuous-functions', 'plane-geometry', 'dynamical-systems']"
4053576,Intuition: Why do we divide by $\sqrt{n}$ instead of $n$ in the Central Limit Theorem?,"The law of large numbers for example is very straightforward to understand. You sum up the random variables, and divide them by their number. You take the almost sure limit of the arithmetic mean and end up with the expectation. What's not to love? Now for the Central Limit Theorem (CLT) we consider convergence in distribution so I realize the logic is different. Let me state a simple version for reference: Let $(X_n)_{n \in \mathbb{N}}$ be a sequence of i.i.d. random variables with $E[X_1]=0$ and > $Var(X_1) = \sigma^2$ where $0< \sigma <\infty$ . Then we have that $$ G_n := \frac{1}{\sqrt{n \sigma^2}} \sum_{k = 1}^{n} X_k  \overset{d}{\longrightarrow} G$$ where $G \sim N(0,1)$ I have seen more than one proof for the CLT but they are quite technical. For a long time I brushed this issue aside but it is repeating itself in several other theorems I encountered (e.g. Donsker's theorem for partial sum processes) so by now I really want to understand. Is there an intuition as to where the square root is coming from?","['statistics', 'central-limit-theorem', 'probability-theory']"
4053634,Book Recommendations for Stochastic Analysis Preliminaries,"I would like to ask for references that may help me in tackling some of the advanced stochastic analysis books. I am interested in a variety of different areas, namely (1) Malliavin Calculus, (2) Stochastic Differential Geometry, (3) Stochastic Differential Equations, and these are in order of interest. So, I would like to know what books I can read to better comprehend the standard literature in those areas. You can suppose I have a background in real analysis from Folland, probability theory from Williams, stochastic calculus from LeGall/Kuo (which is more or less the first 3 chapters of Karatzas & Shreve, i.e. elementary stochastics knowledge). Now, from the research I have done by myself, I concluded that for (1) I would simply need to go through a text in functional analysis. Something on the lines of ""Sobolev Spaces"" by Adams or Brezis' ""Functional Analysis, Sobolev Spaces and Partial Differential Equations"". Is that all that I should read before tackling the standard texts like Nualart? Now, for (2), I concluded that I would simply require a deeper understanding of riemannian geometry. A text like Lee's ""Riemannian Geometry"" would suffice. Am I safe in assuming this? Given that I remember very little differential geometry, can I 'skim' over manifold theory and riemannian manifolds instead of rigorously tackling the classic differential geometry texts, considering that I do not want to spend/focus my time on differential geometry and would very much like to focus on pure probability theory. For (3), from what I can tell it is an extremely wide area. If so, what would you recommend as solid foundation for tackling the basic texts in the area? Would the same books in (1) suffice? Thank you for your time.","['stochastic-analysis', 'book-recommendation', 'functional-analysis', 'stochastic-calculus', 'malliavin-calculus']"
4053640,Inequality for perimeter of Minkowski sum?,"This following is a small part of a rather large problem that has been bugging me. Let $\Omega$ be any bounded open set in $\mathbb{R}^{2}$ of finite perimeter. Is it necessarily true that $$\mathcal{H}^{1}(\partial (\Omega + B_{\delta})) \leq \mathcal{H}^{1}(\partial \Omega)+\mathcal{H}^{1}(\partial B_{\delta}) = \mathcal{H}^{1}(\partial \Omega)+2\pi\delta?$$ Here $\mathcal{H}^{1}$ is the Hausdorff measure, $B_{\delta}$ is the ball of radius $\delta$ and $ \Omega + B_{\delta}$ is the Minkowski sum of $\Omega$ and $B_{\delta}$ . Here $\partial \Omega$ denotes the topological boundary of $\Omega$ . The question is motivated by the a note somewhere that we have equality if $\Omega$ is convex. I can't seem to construct a counter example but nor a proof.","['measure-theory', 'geometric-measure-theory']"
4053643,Showing a convolution of a $f\in C_c(\mathbb{R}^n)$ with $g\in L^p_{loc}(\mathbb{R}^n)$s continuous,"I am trying to use Lebesgue's dominated convergence theorem to show that if $f\in C_c(\mathbb{R}^k)$ and $g\in L_{loc}^{1}(\mathbb{R}^k)$ then we will have that $f* g\in C(\mathbb{R}^k)$ . Now my idea was to take a sequence $x_n\rightarrow x$ and show that $(f*g)(x_n)\rightarrow (f*g)(x)$ . We have that $(f*g)(x_n)=\int_{\mathbb{R}^n}f(x_n-y)g(y)\,dy$ and $(f*g)(x)=\int_{\mathbb{R}^n}f(x-y)g(y)\,dy$ , and so we want to see that $\lim_{n\rightarrow \infty}\int_{\mathbb{R}^n}f(x_n-y)g(y)\,dy=\int_{\mathbb{R}^n}f(x-y)g(y)\,dy$ , and so the idea would be to apply the dominated convergence theorem to $h_n(y):=f(x_n-y)g(y)$ and $h(y):=f(x-y)g(y)$ Now Using the fact $f$ has compact support and is continuous, I was able to prove that $f(x_n-y)\rightarrow f(x-y)$ uniformly. First we check that we have that $f(x_n-y)\rightarrow f(x-y)$ uniformly. Since the function $f$ is continuous we have that for every fixed $y$ , $f(x_n-y)\rightarrow f(x-y)$ , and around each point we can find a neighborhood $V_y$ such that if $y'\in V_y$ , $|f(x_n-y')-f(x_n-y)|<\epsilon_y/3$ and $|f(x-y')-f(x-y)|<\epsilon_y/3$ . Now since $f(x_n-y)\rightarrow f(x-y)$ there exists $N_y\in \mathbb{N}$ such that for every $n>N_y$ we will have that $|f(x_n-y)-f(x-y)|<\epsilon_y/3$ . Using the triangle inequality we see that for every $y'\in V_y$ we have that $|f(x_n-y)-f(x-y)|<\epsilon_y$ for every $n>N_y$ . Now since the support of $f$ is compact , we can take a finite subcovering of this covering by open sets $\{V_y\}$ and choose $N:=\max N_y$ and $\epsilon:=\min \epsilon_y$ , so that for every $z\in K:=supp f$ and $n>N$ we have that $|f(x_n-z)-f(x-z)|<\epsilon$ . Since the choice of $\epsilon$ was arbitrary we get that $f(x_n-y)\rightarrow f(x-y)$ uniformly. Now I am not sure this can give me that $h_n\rightarrow h$ almost everywhere.And also we would need the fact that there exists an $h'\in L^1(\mathbb{R}^n)$ such that $|h_n(x)|\leq |h'(x)|$ almost everywhere in $\mathbb{R}^n$ for every $n$ , but this seems to be a bit hard since I only know that $g\in L_\text{loc}^1(\mathbb{R}^n)$ . Does anyone have any suggestions ? Thanks in advance. Attempt at solving this difficulties : Since $x_n\rightarrow x$ we can find an $N$ such that $x_n\in K$ for every $n\geq N$ , where $K$ is a compact set and so since $f$ has compact support we will have that $h_n$ will have it's support inside a compact set $K'$ for every $n$ greater than $N$ . And so know we can use the hypothesis that $g\in L_{loc}^1(\mathbb{R}^n)$ to get that there exists $M>0$ such that $|g(y)|\leq M$ for every $y\in K'$ , and so we can get that $h_n\rightarrow h$ since $|f(x_n-y)g(y)-f(x-y)g(y)|\leq |f(x_n-y)-f(x-y)||M|$ for every $x\in \mathbb{R}^n$ , and that $|h_n|\leq M'$ for every $n$ since $f$ has compact support. What do you guys think ? I would appreciate some input just to see if I made any mistake or not.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'convolution', 'real-analysis']"
4053671,Question about a statement involving system of linear equations and rank of matrix.,"the statement is: let $A\in \mathbb{R}^{m\times n}$ ,   if for every $c\in \mathbb{R}^m$ there exists a solution for $Ax=c$ , then $\operatorname{rank}(A)=m$ . Now I can understand that this is a true statement, since if $\operatorname{rank}(A)<m$ we can get no solution for the equation. What I wanted to ask if the given information was for every $c\in \mathbb{R}^m$ there exists a unique solution, could I infer that the matrix is square? ( $m = n$ ). This is coming from the idea that if $Ax=c\:$ has a unique solution, then $\operatorname{rank}(A) = n$ , so if it has a solution for every $c$ that means $\operatorname{rank}(A) = m $ and so $m=n$ . I would appreciate any feedback and would love to know if there's more interesting stuff to infer from the given information.","['matrices', 'matrix-rank', 'systems-of-equations', 'linear-algebra']"
4053720,How do I evaluate $\int_{1/3}^3 \frac{\arctan x}{x^2 - x + 1} \; dx$?,"I need to calculate the following definite integral: $$\int_{1/3}^3 \frac{\arctan x}{x^2 - x + 1} \; dx.$$ The only thing that I've found is: $$\int_{1/3}^3 \frac{\arctan x}{x^2 - x + 1} \; dx = \int_{1/3}^3 \frac{\arctan \frac{1}{x}}{x^2 - x + 1} \; dx,$$ but it doesn't seem useful.",['calculus']
4053758,Gini index different expressions,"Let $X$ be a non-negative random variable with positive finite expectation.
The Lorenzcurve $L_X$ is defined by $$ L_X(u) = \frac{\int_0^u F_X^{-1}(y) dy}{E(X)}, \quad 0 \leq u \leq 1,$$ where $$
F_X^{-1}(y) = \begin{cases}
\sup\{x : F_X(x) \leq y\}, \quad 0 \leq y < 1 \\
\sup\{x : F_X(x) \leq y\}, \quad y = 1
\end{cases}
$$ is the right continuous inverse distribution function of the random variable X.
The Gini-Index $G$ is defined by $G = 1 - 2\int_0^1 L_X(u) du$ . I've stepped across the following equation $$ G = \frac{E(X_{2:2}) - E( X_{1:2} )}{E(X_{2:2}) + E(X_{1:2})}, $$ where $X_{1:2} < X_{2:2}$ are the order statistics of a random sample of size 2 drawn from X. Is this a true statement for any random variable X? If so, why? In addition, I have calculated the Gini-Index in the case of $X \sim \exp(\lambda)$ for both expressions above and came to the same result, but I do fail to see any justification for the general case.","['order-statistics', 'probability-theory', 'probability']"
4053830,Geometric Algebras,"As far as I can tell there are several extensions of linear algebra which can be used to do geometry on $\mathbb{R}^n.$ There are: the Clifford Algebra, the Grassman Algebra, the Exterior Algebra, Geometric Algebra, Hamilton Algebra, ""Tensor Algebra"" (not really sure if this is an algebra - but you can use tensor to do a lot of the preceding stuff I believe), differential geometry/forms, and perhaps others. Edit: It seems like there is also pre-Lie algebras (and maybe just Lie algebras in general?) as well. It's not hard for me to go to Wikipedia and look at the definition of each, but this isn't very helpful. So how are each of these defined, what are the related concepts, and how do they all fit in together? Are there any that I have missed? Thanks.","['differential-geometry', 'tensors', 'geometry', 'exterior-algebra', 'clifford-algebras']"
4053870,Do falling factorials form a Schauder basis for formal power series in some topology?,"We usually talk about $F[[x]]$ , the set of formal power series with coefficients in $F$ , as a topological ring.  But we can also view it as a topological vector space over $F$ where $F$ is endowed with the discrete topology.  And viewed in this way, $\{x^n:n\in\mathbb{N}\}$ is a Schauder basis for $F[[x]]$ . Now in contrast, $\{(x)_n:n\in\mathbb{N}\}$ , where $(x)_n$ denotes the falling factorial, is not a Schauder basis for $F[[x]]$ .  That’s because if $\Sigma_na_n(x)_n$ never converges in the standard topology on $F[[x]]$ if infinitely many of the $a_n$ ’s are nonzero.  But my question is, does there exist some alternate topology on $F[[x]]$ which makes $\{(x)_n:n\in\mathbb{N}\}$ a Schauder basis for $F[[x]]$ as a topological vector space over $F$ endowed with the discrete topology?","['topological-vector-spaces', 'combinatorics', 'discrete-mathematics', 'generating-functions', 'formal-power-series']"
4053928,"Is this a circular proof of Pythagorean Theorem? If not, are there better ones? [duplicate]","This question already has answers here : Different proofs of the Pythagorean theorem? (14 answers) Closed 3 years ago . I found this proof of Pythagorean Theorem from  what 3Blue1Brown shows in his Lockdown math lecture  "" Trigonometry Fundamentals "": In the following right triangle, project $\cos\alpha$ and $\sin\alpha$ back to the hypotenuse of length $1$ , they become $\cos^2\alpha$ and $\sin^2\alpha$ : $\to\cos^2\alpha+\sin^2\alpha =1 $ . I thought this is what a simple, visual, and elegant proof!  My questions: Is it a circular proof, why? If not, are there better ones? I want clarity about whether or not this proof is circular.  The argument only depends on the definition of the sine and cosine functions and nothing more (please correct me if I am wrong).  This is why I love it.  Many other geometry solutions involve more than three shapes.","['algebra-precalculus', 'soft-question', 'trigonometry']"
4054024,Summing $\sum_{k=1}^n \binom{2n-2k}{n-k}\frac{H_{2k} - 2H_{k}}{2n-2k-1} \binom{2k}{k}$,"The sum in the question has a nice closed-form: $$
\sum_{k = 1}^{n}\binom{2n - 2k}{n - k}
\frac{H_{2k} - 2H_{k}}{2n-2k-1}\binom{2k}{k} =
\frac{1}{n}\left[4^{n} - 3\binom{2n-1}{n}\right],$$ where $H_k$ is the harmonic number $H_n = \sum_{k=1}^n 1/k.$ My proof is excruciating: It involved the specialization of a two-variable generating function ( $x$ and $y$ take different functions of $t$ ) so that I could use an identity that seems to have no mere
mortal-constructed proof ( a variant of the WZ method was used, I believe ). In the process of the proof, I noticed that the expression in big parentheses on the RHS is a sequence of integers, and I searched the OEIS to find $A213119$ . As logarithms are involved, it was a matter of talking the arguments into the logarithm to find that my generating function was indeed equal to implied by the right hand side of the equation. I seek a simpler, more direct proof. A contributor wanted to know where the identity originated.  It originated as an attempt to prove the very pretty $$
\sum_{k = 1}^{n}\binom{n}{k}^{2}H_{k} =
\binom{2n}{n}\left(\,{2H_{n} - H_{2n}}\,\right)
$$ It may be impossible not to use this in any attempted proof, but hopefully, the specialization of a two-variable generating function can be avoided.","['summation', 'binomial-coefficients', 'closed-form', 'sequences-and-series']"
4054043,Principal Value of a divergent integral over $\mathfrak{R}$,"I am trying to solve/prove this Principal Value integral $$ \mathscr{P}\int_{-\infty}^{+\infty}\dfrac{x^2\cdot \sin\left(x\right)}{x-a}{\rm{d}}x=\  -\ i\pi a^2\cdot\cos\left(a\right)\ ,$$ where $a$ takes a finite value. The way I try to prove this is by noticing there pole is a first order pole at $x=a$ , then by calculating the Residue at this value I find that $$ \mathscr{P}\int_{-\infty}^{+\infty}\dfrac{x^2\cdot \sin\left(x\right)}{x-a}{\rm{d}}x =-i\pi \cdot Res\left(\dfrac{x^2\cdot \sin\left(x\right)}{x-a},a\right)= $$ $$ =-i\pi\cdot\lim_{x\rightarrow a}\left(x^2 \cdot \sin\left(x\right)\right) = -i\pi a^2 \cdot {\sin(a)}\ ,$$ which of course is not correct. Hence, does anyone knows what I am doing wrong, and if yes could please explain it to me? NOTE: Just to mention that i end up to this question because a made use of Green's function for quantum many-body system. So if anyone have a clue about this they might be able to help. Thanks in advance. *******   EDIT: I tried to keep it short, but the truth is that I need to prove this $$-\dfrac{1}{a^3} \mathscr{P}\int_{-\infty}^{+\infty}\dfrac{x^3\cdot F(x)}{x-a}\dfrac{{\rm{d}}x}{2\pi} = G(a)\ ,$$ where $$ F(x) = \frac{3}{2}\left[(1-y)\cdot \frac{\sin(x)}{x} + (1-3y)\cdot\left( \frac{cos(x)}{{x^2}} - \frac{sin(x)}{x^3}\right) \right]$$ and $$ G(a) = \frac{3}{4}\left[-(1-y)\cdot \frac{\cos(a)}{a} + (1-3y)\cdot\left( \frac{sin(a)}{{a^2}} + \frac{cos(a)}{a^3}\right) \right],$$ where $y=const$ . Thanks again for the effort.","['complex-analysis', 'greens-function', 'cauchy-principal-value', 'real-analysis']"
4054062,Continuity of function in $\mathbb{R}^2$,"Where should I start if I want to study the continuity of a function in $\mathbb{R}^2$ ?
Like this one: $$f(x,y)=  
\begin{cases} 
      \frac{x^2y}{x^2+\sqrt{y}} & \quad\text{if } y>0,\\
      0 & \quad\text{otherwise.}\\
   \end{cases}
$$ I think $f$ is continuous except at $(0,0)$ , so I have to take the limit to see if it's continuous, right? But I'm confused about the piecewise function, which would be $0$ at that point... Could someone help me?","['continuity', 'multivariable-calculus']"
4054072,Martingale in Cox Model,"Can someone help me to show that $$
\hat{A}(t, \beta_0) = \sum_{i=1}^{n} \int_0^t\frac{1}{\sum_{j}^n Y_j(s) e^{X_i^T \beta_0}} dN_i(s)
$$ is a martingale. The setup is the Cox proportional hazard model in a semiparametric manner. This is what I got so far: $$
\sum_{i=1}^{n} \int_0^t\frac{1}{\sum_{j}^n Y_j(s) e^{X_i^T \beta_0}} dN_i(s) = \sum_{i=1}^{n} \int_0^t\frac{1}{\sum_{j}^n Y_j(s) e^{X_i^T \beta_0}} (dM_i(s|X) + d\Lambda_i(s|X) )
$$ $$
= \sum_{i=1}^{n} \int_0^t\frac{1}{\sum_{j}^n Y_j(s) e^{X_i^T \beta_0}} (dM_i(s|X) + d \int_0^s Y_i(u) \alpha_0 e^{X_i^T \beta_0} du   )
$$ $$
=\sum_{i=1}^{n} \int_0^t\frac{1}{\sum_{j}^n Y_j(s) e^{X_i^T \beta_0}} dM_i(s|X) + \int_0^t\frac{1}{\sum_{j}^n Y_j(s) e^{X_i^T \beta_0}} \sum_{i=1}^{n} Y_i(s) e^{X_i^T \beta} \alpha_0(s)ds
$$ $$
=\sum_{i=1}^{n} \int_0^t\frac{1}{\sum_{j}^n Y_j(s) e^{X_i^T \beta_0}} dM_i(s|X) + \int_0^t \alpha_0(s)ds
$$","['stochastic-processes', 'statistics', 'probability-theory', 'martingales']"
4054081,How many ways to seat $n$ couples so that each husband's neighbors can only be his wife or another gentleman?,"How to seat $n$ couples (husbands and wives) in a line so that each husband's neighbors can only be his wife or another gentleman?  I.e. his neighbor cannot be another woman that's not his wife. There is a classical similar problem: In how many ways can n couples (husband and wife) be arranged on a bench so no wife would sit next to her husband? But it's a bit different. In this case the husband can only be sitting with either his wife or another gentleman. Can the inclusion-exclusion principle still be applied on this problem? I can't think of a way.. [edit] through programmatical iteration, I found that the solution is http://oeis.org/A096121 . But there isn't a proof to it. It's not hard to show that the rook problem is equivalent to this problem -- one column is the wives and the other column is the husbands. The sequence of the locations of the rook is how you arrange the husbands and wives. But I wonder how do you prove the recurrence formula $a_{n+1} = n(n+1)(a_n + a_{n-1})$ ? Another formula in OEIS was given as $a_n = 2 \cdot n! \cdot b_n$ where $b_{n+1} = n b_n + b_{n-1}$ . $b_n$ is defined in http://oeis.org/A102038 This formula seems a bit more approachable. If we know the solution where the rook starts in one column, we multiply it by 2 so we get the solution where the rook in either column. $n!$ is just the permutation of all the cells in one column. We can interpret the $2 \cdot n!$ part but not sure about the rest!","['contest-math', 'combinatorics', 'recurrence-relations', 'recursion']"
4054130,"Prove that $\forall x,y, \, \, x^2+y^2+1 \geq xy+x+y$","Prove that $\forall x,y\in \mathbb{R}$ the inequality $x^2+y^2+1 \geq xy+x+y$ holds. Attempt First attempt: I was trying see the geometric meaning, but I´m fall. Second attempt: Consider the equivalent inequality given by $x^2+y^2\geq (x+1)(y+1)$ and then compare $\frac{x}{y}+\frac{y}{x} \geq 2 $ and the equality $(1+\frac{1}{x}) (1+\frac{1}{y})\leq 2$ unfortunelly not is true the last inequality and hence I can´t conclude our first inequality. Third attempt:comparing $x^2+y^2$ and $(\sqrt{x}+\sqrt{y})^2$ but unfortunelly I don´t get bound the term $2\sqrt{xy}$ with $xy$ . Any hint or advice of how I should think the problem was very useful.","['real-numbers', 'inequality', 'multivariable-calculus', 'calculus', 'algebra-precalculus']"
4054136,What is the derivative of the derivative?,"If we consider the derivative as a function from a function space to function space, then does it make sense to talk about the derivative of the derivative? In particular, if we consider $$D:C^\infty[\mathbb{R}]\to C^\infty[\mathbb{R}]$$ and arbitrary smooth function $f\in C^\infty[\mathbb{R}]$ , then can we reasonably ask if there is some other function on smooth real functions given by the following? $$\frac{d}{df}[Df]$$ I've tried to do this myself with limits, where we take an arbitrary smooth function $u$ that approaches the constant function of $0$ . In particular, I found that $$\lim_{u\to 0}\frac{D(f+u)-D(f)}{u}=\lim_{u\to 0}\frac{f'+u'-f'}{u}=\lim_{u\to 0}\frac{u'}{u}.$$ But I'm not sure if that approaches any particular value independent of $u$ 's path toward $0$ . However, plugging in $u = 0$ does indeed result in an indeterminant form, which leads me to suspect that there is a way of solving this. Instinctually, I think that this value should be $1$ both due to $D$ being considered linear, and applying L'Hopital's rule infinitely many times would result in $$\lim_{u\to 0}\frac{u'}{u} = \lim_{u\to 0}\lim_{n\to\infty}\frac{u^{(n+1)}}{u^{(n)}}=\lim_{u\to 0}\lim_{n\to\infty}\frac{u^{(n)}}{u^{(n)}}=\lim_{u\to 0}\lim_{n\to\infty}1=1$$ But this does not seem particularly rigorous. Does my question even make sense and if it is, is there a rigorous way of finding the solution? Edit: To add to the confusion, if we treat deriving with respect to a function as we do in $\mathbb{R}$ , we find that $$ \frac{d}{df}[Df] = \frac{df'}{dx}\frac{dx}{df}=\frac{f''}{f'}$$ Which I'm pretty sure is not quite the same as differentiating with respect to the function itself, but I don't fully understand why it would be different.","['smooth-functions', 'limits', 'derivatives', 'functional-analysis']"
4054170,Linearized ordinary differential equation for Hydraulic Mill,"The hydraulic mill is consists of two main part; servo valve and hydraulic cylinder. We will consider flow-control servo valve. The dynamics of the servo valve is \begin{equation} 
\label{1}\tag{1} Q_s=C_Q\pi dx\sqrt{\frac{2}{\rho}(P_s-P_1)}           
\end{equation} Here, $Q_s$ =supply flow, $C_Q$ =flow coefficient, $\rho$ =oil density, $x$ =servo-valve displacement, $P_s$ =supply pressure, $P_1$ =output pressure of the valve. The equation for the flow of oil to the hydraulic cylinder, \begin{equation} 
\label{2}\tag{2}Q_s=a\dot{y}+\frac{V_1}{\beta}\dot{P_1}
\end{equation} Here, $a$ =area of the cylinder, $y$ =hydraulic piston displacement, $V_1$ =volume of the primary side of the cylinder, $\beta$ =bulk modulus of the oil, $P_1$ =cylinder pressure on primary side. Schematic: Hydraulic servo system Equation \eqref{1} needs to be linearized for both input-flow & output-flow to the cylinder according to valve displacement $x$ . Help me find the ODE for rate of change in cylinder Pressure $\dot{P_1}$ and $\dot{P_2}$ .","['linearization', 'ordinary-differential-equations', 'fluid-dynamics']"
4054184,Why does a Reuleaux triangle appear when drilling a hole with a knife,"As the season commands, I was blowing out eggs for the kindergarten. In order to have large holes at both ends of the egg I first poke a small hole with a pin and then enlarge the said hole with a pointy knife (by rotating said knife in the hole in the hope of creating a round hole). To my surprise, enlarging the hole in such a fashion ended up giving me (in 7 out of 8 tries) a shape which rather looks like a Reuleaux triangle than a circle. Now it's obvious that the resulting shape should have constant width. But my [first and vague] question is: are there reasons not to get a circle? (and is the phenomenon confirmed?) In some sense a ""Reuleaux triangle""-like shape is more probable since it has a much smaller symmetry group (so if the medium is not uniform, it might be a more ""optimal"" solution [to some optimisation problem]). So my [hopefully more precise] question is: Question: What is a good model for this ""drilling process"" which could explain a ""Reuleaux triangle""-like shape? Just for details (but I doubt it matters) the knife was only sharp one side and both sides of the knife touch the edge of the hole at all times while the drilling occurs.","['optimization', 'recreational-mathematics', 'geometry', 'curves']"
4054244,What is $\frac{1}{2+\frac{1}{x}}$ equal to when $x=0$?,"$$\frac{1}{2+\frac{1}{x}}$$ What's the output of this function when $x=0$ ? I tried graphing it on Desmos and it shows a curve passing through the origin so the output must be equal to zero, however I don't get how it reached this result. The only way it could have reached it is maybe by changing the equation a little bit: $$\frac{1\cdot x}{(2+\frac{1}{x})\cdot x}$$ (where $x\neq0$ ) $$\frac{x}{2x+{1}}$$ However since we stated in the first step that $x$ can't be equal to zero we can't make it equal to zero again and solve with the simplified version we've just arrived at: at $x=0$ , $$\frac{0}{0+{1}}=0$$ $\rightarrow$ so this is wrong How did Desmos then arrive at the answer?","['calculus', 'algebra-precalculus']"
4054271,"$\lim_{(x,y)\to(0,0)} \frac{xy}{x-y}$","I was trying to calculate the following limit: $$\lim_{(x,y)\to(0,0)} \frac{xy}{x-y}$$ I used polar coordinates: $x=r\cos\theta$ and $y=r\sin\theta$ .
But this gives me: $$\lim_{r\to 0} \frac{r\cos\theta\cdot r\sin\theta}{r\cos\theta-r\sin\theta}=\lim_{r \to 0} r\frac{\cos\theta\sin\theta}{\cos\theta-\sin\theta}=0$$ But Wolfram Alpha says that this limit does not exist. What is the problem in what I did? Is it because of the fact that if $\theta = \frac{\pi}{4}$ I am dividing by $0$ ? (My guess is that it is in fact the problem and by applying L'Hôpital's rule I will find out the limit does not exist.)","['limits', 'multivariable-calculus', 'fake-proofs', 'real-analysis']"
4054295,Two rings with the same multiplicative structure but non-isomorphic underlying Abelian groups,"I am giving a series of lectures where I introduce some undergraduates to basic ideas from category theory. One of the things I would like to show them is how category theory could be used to make precise some of the intuitive ideas they have been exposed to (e.g., what ""natural"" means when we speak about the natural isomorphism of a finite dimensional vector space with its double dual, what ""universal"" really means when we speak of a universal construction, etc.). One of the subtleties I would like to illustrate with explicit examples is the difference between ""property"" and ""structure"". I would really like to show them that ""being a preadditive category"" (by preadditive here I just mean $Ab$ -enriched category, I do not assume existence of a $0$ -object) is not a property, so it does not make sense to give me an abstract category and ask me if it is preadditive or not (I can ask whether it can be made into a preadditive category, but even in that case the preadditive structure may not be unique). To illustrate this, I would like to find some minimal example of two different $Ab$ -enrichments of the same abstract category. A good way to do that seems that of finding two (unitary and associative) rings $(R,+,.)$ and $(S,+',*)$ , such that $(R,.)\cong (S,*)$ as monoids (i.e., as one-object categories) but $(R,+)\not\cong (S,+')$ as Abelian groups. Do you have some easy example of two rings with the properties described above?","['category-theory', 'enriched-category-theory', 'ring-theory', 'abstract-algebra', 'additive-categories']"
4054303,Modelling with Higher-order DEs,"I would like to know if there are any models that make use of higher-order (5th, 6th and so on...) linear differential equations. The highest that I know is the Euler-Bernoulli beam equation. Do you know any? Or how to model with higher-order ones? Thanks","['mathematical-modeling', 'ordinary-differential-equations']"
4054383,$\langle a\rangle \simeq \langle b \rangle$ if and only if $a$ and $b$ have the same index and period,"If $a$ and $b$ are elements of finite order in the same or in different semigroups, the $\langle a\rangle  \simeq \langle b \rangle$ if and only if $a$ and $b$ have the same index and period. $\Leftarrow]$ we have: $\langle a\rangle=\{a, a^2, \dots, a^m, a^{m+1}, \dots, a^{m+r-1}\}$ and $\langle b\rangle =\{b, b^2, \dots , b^m, b^{m+1}, \dots, b^{m+r-1}\}$ where $m$ is the index and $r$ is the period of $a$ and $b$ , which by hypothesis is the same. Let's consider the function $f: \langle a \rangle \to \langle b \rangle$ by $f(a^{i})= b^{i}$ it is easy to verify that $f$ is an isomorphism. I have trouble showing that if $\langle a \rangle$ and $\langle b \rangle$ are isomorphic then  the index and period of $ a$ are equal to the indexes and period of $b$ .
I think that if we assume that they are not true, it may contradict the minimality of the period and the index, but I do not know if it is true, any suggestions? thanks","['topological-semigroups', 'group-theory', 'abstract-algebra', 'semigroups']"
4054404,Is there a way to generalize the connected sets in $\mathbb{R}^2$?,"How do I generalize the connected sets in $\mathbb{R}^2$ if there is a way. I know how connected sets in $\mathbb{R}$ look like, so is there a way to say something about the connected sets in $\mathbb{R}^2$ ?","['connectedness', 'analysis', 'real-analysis']"
4054425,"Is Spivak wrong about this counterexample? $f$ integrable on $[-1,1]$, $F=\int_{-1}^xf$, $f$ differentiable at $0$, but $F'$ not continuous at $0$","Let $f$ be Riemann integrable on $[a,b]$ , let $c\in(a,b)$ , and let $F(x)=\int_a^xf$ for $x\in[a,b]$ . Exercise 3b in Chapter 14 of Spivak's Calculus (3rd edition) asks to give a proof or provide a counterexample of this statement: If $f$ is differentiable at $c$ , then $F'$ is continuous at $c$ . In his solutions manual, Spivak claims to give a counterexample. His function is $f:[-1,1]\to\mathbb{R}$ defined by $$f(x)=\begin{cases}0&x=0\\1&x\in\left\{-1,1\right\}\\\frac{1}{n^2}&\frac{1}{n}\leq |x|<\frac{1}{n-1}, n\geq2\end{cases}$$ Observe that $f$ has jump discontinuities at points of the form $1/n$ for nonzero integers $n$ and is continuous everywhere else. Now certainly $f$ is Riemann integrable on $[-1,1]$ (because its sets of discontinuities is countable, thus measure zero). Moreover $f$ is indeed differentiable at $0$ . But I don't think $F'$ is discontinuous at $0$ . On the contrary, here is my proof that $F'$ is continuous at $0$ . First, since $f$ is differentiable at $0$ , $f$ is continuous at $0$ ; it follows by the fundamental theorem that $F'$ exists at $0$ and that $F'(0)=f(0)$ . We know $f(0)=0$ , so $F'(0)=0$ . It remains to show that $\lim_{x\to0}F'(x)=0$ . Now this is a little delicate because, as Spivak points out, $F'$ is not even defined at $1/n$ for $n$ a nonzero integer. But that doesn't prevent us from calculating the limit of $F'$ . The limit simply must be taken through the domain of $F'$ . Indeed, given $\epsilon>0$ , take $N$ such that $\frac{1}{N^2}<\epsilon$ , and pick $\delta=\frac{1}{N}$ . Then if $0<|x|<\delta$ and $x$ is in the domain of $F'$ , it follows that $|F'(x)|\leq\frac{1}{(N+1)^2}<\frac{1}{N^2}<\epsilon$ . Therefore it is indeed true that $$\lim_{x\to0}F'(x)=F'(0)$$ so $F'$ is continuous at $0$ . What's going on here? Is this just a matter of one's definition of the limit of a function on a set that isn't an interval? Spivak seems to think ""If $\lim_{x\to c}g(x)$ exists then $g$ is defined on a deleted interval around $c$ .""","['limits', 'calculus', 'real-analysis']"
4054432,Definition of set containment,"Let $X$ and $Y$ be sets. Does "" $X$ contains $Y$ "" mean $Y \subseteq X$ or $Y\in X$ , or is it ambiguous?","['elementary-set-theory', 'terminology']"
4054466,Do functions with vertical asymptotes necessarily have infinite derivatives for all degrees?,"Suppose I have a function $f(x)$ where $f:\mathbb R^n\to\mathbb R$ . First take $n = 1$ . Now suppose that there exists a point $\bar x$ where the $d$ th derivative $f^d(\bar x)$ is defined and is finite for some $d \geq 1$ . Does this necessarily imply that $f(\bar x)$ is defined and is finite, or is it possible that it is undefined or infinite? (The example I am trying to construct is something like: $f(0) = 0$ , $\lim_{x\to 1} f(x) = +\infty$ . (So it is defined, it just isn't finite.) We can also assume that $f(x) \geq 0$ for $0 \leq x < 1$ , to help at least with the $d=1$ case. Now $f^d(x)$ is defined and finite for all $x < 1$ . But, is it necessary that $f^d(x)\overset{x\to 1}{\to} +\infty$ for all $d$ as well?) Now suppose $n > 1$ , and suppose $\mathcal C\subset \mathbb R^n$ is a closed connected set.
I know that for some $\bar x\in \mathcal C$ , $f(\bar x) = 0$ , and I also know that for all $x\in \mathcal C$ ,  for some $u$ , $u^T\nabla f(x) u$ is finite. Does this necessarily mean that $f(x)$ is finite for all $x\in \mathcal C$ ? This seems like a basic result, but I'm fearful of potential counterexamples. Edit : the more that I think about it, the more I think that it is true in $n = 1$ , but can't be true in $n > 1$ . For $n = 1$ , it seems like if $f(x)$ is finite-valued for all $x \in [0,1)$ , then the only way that $\lim_{x\to 1}f(x) = +\infty$ is if all its derivatives go to $+\infty$ at $x\to 1$ . For $n > 1$ , the simple counterexample of $$
\nabla^2 f(x) = \left[\begin{matrix} 1 & 0 \\ 0 & 1/(1-x_2) \end{matrix}\right]
$$ seems to satisfy the bill.","['calculus', 'derivatives', 'real-analysis']"
4054482,"On ""the Hessian is the Jacobian of the gradient""","According to Wikipedia , The Hessian matrix of a function $f$ is the Jacobian matrix of the gradient of the function $f$ ; that is: $H(f(x)) = J(\nabla f(x))$ . Suppose $f : \Bbb R^m \to \Bbb  R^n,x \mapsto f(x)$ and $f \in C^2 (\Bbb  R^m)$ . Here, I regard points in $\Bbb R^m, \Bbb R^n$ as column vectors, therefore $f$ sends column vectors to column vectors. When $n=1$ , we can define $\nabla f: \Bbb R^m \to (\Bbb R^m)^t,x\mapsto\nabla f(x)$ , which sends column vectors to row vectors. I  use $(\Bbb R^m)^t$ to denote row vector space, which is just a random notation. We do have a good definition for functions that sends column vectors to column vectors, but what can we say about functions that sends column vectors to row vectors? I discovered that if I manipulate $\nabla f(x)$ as a column vector, then I know how to calculate, and my calculation agree with Wiki. But I don't think we can ""manipulate $\nabla f(x)$ as a column vector"".","['jacobian', 'multivariable-calculus', 'definition', 'vector-analysis', 'hessian-matrix']"
4054495,Implications of $\text{Spin}(3)\times \text{Spin}(3) \cong \text{Spin}(4)$,"I recently learned that $\text{Spin}(3)\times \text{Spin}(3) \cong \text{Spin}(4)$ , and find it intriguing: it seems like the sort of thing that would have lots of interesting consequences. What are the implications of this isomorphism? I'd be interested in connections between this and any other area of math (or physics!).","['exceptional-isomorphisms', 'group-theory', 'lie-groups']"
4054502,How do you solve the following integral?,"How do you solve the following integral $$\int_0^{2\pi}\sqrt{\frac{5}{4} + \cos(t)} \, dt.$$ It has been a while since I have done integration and I think somehow I could multpily by the conjugate but I am unsure.  Any assistance would be appreciated. This problem is part of a larger problem to find the length of the cardiod. $$r(\theta)=\frac{1}{2}+\cos(\theta).$$ This integral is the length integral and I originally just found a numerical approximation but after reviewing my problem my teacher said there is a nice way to antidifferentiate but I was unsure how to go about that.","['integration', 'calculus']"
4054515,Leap year probability,"A year in the 2020s (i.e., from 2020 to 2029 inclusive) is selected uniformly at random, a month
is selected uniformly at random from that year, and a day of the month is selected uniformly at
random from that month. (a) What is the (exact) probability that the day is the 29th of February?
->I use 3/10 * 1/12 * 1/29 [not very sure] (b) Given that the day is the 29th, what is the probability that the month is February?
For this one, I know I should use Baye's rule, but cannot proceed further. Is anyone willing to help?","['statistics', 'combinatorics', 'probability']"
4054531,Travelling (soliton) Wave solution to 1D GPE equation,"I have a non-dimensional version of the Gross-Pitaevskii equation: $$ 2i \frac{\partial \psi}{\partial t} = - \frac{\partial^2\psi}{\partial x^2} + \left|\psi \right|^2\psi -\psi, $$ where $\psi(x,t)$ is the wave-function for a BEC. My aim is to find a travelling wave solution. I suspect this solution is of the form: $$\psi(x,t) = f(x-ut)\,e^{-i\mu t}  ,$$ where $\mu, u$ are constants ( $u$ is the speed).
From reading around online (specifically, the book ""A Primer on Quantum Fluids""), I think the final solution for $\psi(x,t)$ is of the general form: $$ \psi(x,t) = \tanh\left( (x-ct)\,+i\frac{u}{c} \right)\,e^{-i\mu t}. $$ I have tried to substitute my form of the solution into it to find $f$ , and so far I am at the current stage: $$ \frac{\partial^2f}{\partial x^2} - i\,2u\frac{\partial f}{\partial x} -f^3 +(1+2\mu)f = 0,$$ but after carrying on with this and applying some basic differential equation solver techniques, it doesn't seem to get me to the right place. It is also possible that I have made mistakes leading up to this point, and I'm not too sure whether that's the case or where to go from here. This particular solution is for dark solitons. I also need to find bright soliton solutions but this should proceed in a similar manner. Any help would be greatly appreciated!","['quantum-mechanics', 'ordinary-differential-equations', 'wave-equation', 'partial-differential-equations', 'nonlinear-system']"
4054557,Finding equilibrium point from a differential equation [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I have the differential equation of a system as given below, $$ m\frac{d^2H}{dt^2} = mg-k\frac{I^2}{H^2} $$ How do I find the equilibrium points of this?","['calculus', 'derivatives', 'ordinary-differential-equations']"
4054573,"Let {$r_n$} be an enumeration of all rationals in [0, 1]. Show that {$r_n$} is not convergent.","Let { $r_n$ } be an enumeration of all rationals in [0, 1]. Show that { $r_n$ } is not convergent. My approach
Let $r_n$ be the sequence.It can't be monotone . Thus there exists monotonic subsequnces (both increasing and decreasing) in it.Also it is bounded.
Thus it has two limit points.","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
4054590,Ant walking cube,"This is a modification of the ant crossing to the opposite diagonal problem: An ant traverse from a cube vertex and does so on the edge. It has equal probability to choose all the edge including the original one. What is the expected number of edge it will traverse before returning to the original vertex? My intuition is: there are 8 vertices, so if the ant just walking non-stop randomly to infinity, it would spend 1/8 of the time hitting each vertex. So intuitively, my answer is the average edge it would walk between each visit to the original vertex is 8 edges. But I don't know how to set it up in mathematically rigorous way.","['expected-value', 'probability-theory']"
4054606,How can I prove that $\frac{\sin\theta+ \tan\theta}{2}> \theta$ when $0 < \theta < \frac{\pi}{2}$ [duplicate],"This question already has answers here : Is there a geometrical method to prove $x<\frac{\sin x +\tan x}{2}$? (10 answers) Closed 3 years ago . I don’t know how to do it without calculus, could someone help ? How do I prove it geometrically and/or algebraically ? EDIT: $0 < \theta < \frac{\pi}{2}$ My teacher never explained it. Someone tried explaining it to me with calculus, but I would appreciate a different explanation.",['trigonometry']
4054610,Computation with Gaussian measures on Hilbert spaces,"What follows is based on the paper https://arxiv.org/abs/1509.02093v2 , specifically section 1.2 about Gibbs measures. The setup is the following: Let $\mu$ be the Gaussian measure on $H^s(\mathbb{T}^2)$ ( $s<0$ , and $H^s$ are Sobolev spaces defined in the usual sense of Fourier multipliers) defined by $$
d\mu = \exp\left(-\frac{1}{2} \int |u|^2 + |\nabla u|^2 dx \right) du $$ In the paper, Oh and Thomann show that you can compute the covariance operator associated to this measure explicitly ( $C = (1 - \Delta)^{-1+s}$ ), but they then claim that $\mu$ is only a probability measure on $H^s(\mathbb{T}^2)$ when $s < 0$ , as "" $\mu(L^2(\mathbb{T}^2)) = 0$ "". How does one go about showing this equality, and why does this show failure of $\mu$ to be a probability measure?","['hilbert-spaces', 'measure-theory', 'lebesgue-measure', 'functional-analysis']"
4054651,Venn diagram shading,"I am having trouble figuring out what the shaded region represents. The closest I've reached was $(X \oplus Y) \cup Z$ , but that ends up including $X \cap Y \cap Z$ , so that doesn't work. Any help would be appreciated.","['elementary-set-theory', 'discrete-mathematics']"
4054671,Euler product over a finite subset of composite numbers,"The product $$\prod_{p\text{ prime}}\frac{p^n}{p^n-1}=\zeta(n)$$ is well-known. This works over primes, and only over the entire set of them. Is any similar expression known for composites? For a finite subset of them? e.g. $$\prod_{c\text{ composite, c}=c_{i}}^{c=c_{j}}\frac{c^n}{c^n-1}=f(m)$$ for some $f$ . This is generic. If such an expression is not known, is anything known for the case $i=1$ and $n=1$ ? If not, then for $i=n=1$ and $j=\infty$ ? If that is also not known, is anything known on $\lim \inf f(m)$ or $\lim \sup f(m)$ ?","['analytic-number-theory', 'number-theory', 'infinite-product']"
4054680,Number of distinct right triangles formed by connecting vertices of a unit cube,"Suppose we have a unit cube in ${\mathbb{R}^3}.$ We want to count the total number of distinct right triangles formed by connecting vertices of the unit cube. I can see that the total number of right triangles simply on a face of the cube will be $4$ and since there are $6$ faces we have $4 \times 6 = 24$ right triangles on the faces alone. Of course there are others across the cube's diagonals. I think the total will be $48$ , due a symmetry across the diagonals, but am not entirely sure of my reasoning here, so I may be wrong. If someone could elucidate or provide a better/more rigorous answer it would be appreciated.","['combinatorics', 'geometry']"
4054750,Derivative of $E\left(\int_t^T S_udu|\mathcal{F}_t\right)$,"Calculate the derivarive of $E\left(\int_t^T S_udu|\mathcal{F}_t\right)$ in function of $t$ $$\frac{d}{dt}E\left(\int_t^T S_udu|\mathcal{F}_t\right)$$ where $S_t$ is a stochastic process( I try to avoid specifying its form). My attempt: We have $$E\left(\int_t^T S_udu|\mathcal{F}_t\right) = \int_t^T E\left(S_u|\mathcal{F}_t\right)du$$ then $$\frac{d}{dt}E\left(\int_t^T S_udu|\mathcal{F}_t\right) = \frac{d}{dt}\left(\int_t^T E\left(S_u|\mathcal{F}_t\right)du\right) $$ But after that, I don't know how to calculate $\frac{d}{dt}\left(\int_t^T E\left(S_u|\mathcal{F}_{\color{red}{t}}\right)du\right) $ because of the subscript in red color.","['stochastic-integrals', 'stochastic-analysis', 'derivatives', 'stochastic-calculus']"
4054769,Markov chain exercise 1,"I have the transition matrix $$P= \begin{pmatrix}
1 & 0 & 0\\
0 & 0 & 1\\
\frac14 & \frac14 & \frac12
\end{pmatrix}$$ and I have to determine the period of each state, compute $f_{2,2}{(n)}$ for each $n\geq 1$ and compute $p_2(X_n=3)$ I think $f_{2,2}{(n)} = p_{(2,3)}p_{(3,2)}=1·\frac14=\frac14$ but I am not sure
and the last part I have $p_i(X_n=j)=p_{i,j}{(n)}$ but I don't know how to do it thank you","['risk-assessment', 'statistics', 'markov-chains', 'stochastic-processes', 'probability-theory']"
4054831,Can you project unto closed subspaces of normed spaces that are not necessarily pre-Hilbert?,"I'm working through some notes for my signal processing class and they introduce the whole notion of pre-Hilbert spaces (inner product spaces) essentially only in order to be able to project elements onto closed subspaces. My question is: suppose $V$ is a general normed space (not necessarily derived from an inner product) and $U \subset V$ is a complete subset, can we not use the same proof to show that $\forall v \in V, \exists u \in U$ such that $||u-v||$ is minimal? In that case, the only thing the inner product does is to make the projection orthogonal, right?",['functional-analysis']
4054989,"Solve the system of equations: $32y+32x^3=6x+17$, $16z+32y^3=6y+9$, $8x+32z^3=6z+5$ where $x,y,z\in \mathbb{R}$","Solve the system of equations: $$\begin{cases} 32y+32x^3=6x+17 \\16z+32y^3=6y+9 \\8x+32z^3=6z+5 \end{cases}$$ where $x,y,z\in \mathbb{R}$ (Bulgaria 1960) I attempted to solve this question as follows: $32y+32x^3=6x+17$ $y=-x^3+\frac{6x}{32}+\frac{17}{32}$ $y-\frac{1}{2}=-x^3+\frac{3x}{16}+\frac{17}{32}-\frac{1}{2}$ Here it started getting very complex, and hence I don't think it can be solved this way. After this I tried doing something similar with the other two equations, but once again it was ending up way too complex. It is obvious that the solution is $x=y=z=\frac{1}{2}$ , but I can't manage to prove it. Could you please explain to me how to solve this question?","['contest-math', 'real-numbers', 'systems-of-equations', 'linear-algebra', 'algebra-precalculus']"
4055022,Bijective function in a commutative diagram,"Let $X,Y, Z$ be sets and $p_x:Z\rightarrow X$ and $p_y:Z \rightarrow Y$ so that for every Triple $(M, f_x, f_y)$ exactly one function $g:M\rightarrow Z$ exists, which makes following diagram commutative (Commutative $\Leftrightarrow f_x=g\circ p_x$ and $f_y=g\circ p_y$ ). Show that for $(M, f_x, f_y)=(X\times Y, \pi_x, \pi_y)$ , the received function $g:X\times Y \rightarrow Z$ is a Bijection. $\pi_x(x,y) = x$ and $\pi_y(x,y) = y$ My attempt: Since the diagram is commutative, it follows... $$x = \pi_x(x,y) = (p_x \circ g)(x,y) \Rightarrow x = (p_x \circ g)(x,y)$$ $$y = \pi_y(x,y) = (p_y \circ g)(x,y) \Rightarrow y = (p_y \circ g)(x,y)$$ So I think in order to get the desired values, $g$ must be... $$g(x,y) = (p_x^{-1} \circ \pi_x)(x) \cap (p_y^{-1}\circ \pi_y)(y)$$ I'm unsure what to do next. I could also say... $$ g^{-1}(x,y) = (\pi_x^{-1}\circ p_x)(x) \cap (\pi_y^{-1}\circ p_y)(y)$$ But since I don't know if the functions $\pi, p$ themselves are bijective, I cannot conclude that $g^{-1}$ exists I'd like to have some tips on how to proceed.","['abstract-algebra', 'commutative-algebra']"
4055102,Handbook of functional analysis for geometry,"Is there a book or document that could be used as a handbook so I don't have to go through how the space of distributions is constructed and the main theorems in every geometry book? I do no want to profundise on the topic, but it feels really bad when, for example, a book on compact Riemann Surfaces is about to prove some finite dimensionality and invokes an out of nowhere theorem about compact operators on Hilbert spaces, or when studying the Hodge theorem a very ad hoc definition of the spaces of distributions and elliptic operators is presented, because if I find myself trying to prove a similar reult, I will need to know if those tools in functional analysis can be useful. Also, I find that most of the functional analysis books don't cover the whole topic. Much of them restrict themselves to Banach spaces, for example, skip Hilbert spaces or omit distributions etc. while the ones that cover the whole topic are too long for me. I know that there are some short texts that gather the basics of functional analysis, but I don't want that, I'm looking for a document showing the deep theorems, that skips most of the proofs, but focuses on how to use the results, and I would also like to have a section on distributions and Frechet spaces for the study of holomorphic functions. This is very specific, but anything close to what I am asking is accepted.","['reference-request', 'complex-geometry', 'functional-analysis', 'differential-geometry']"
4055120,Definition of Clifford Algebras,"I'm currently studying algebras, and in particular Clifford Algebras. Primarily I've been looking at this paper , and on page 7 and 8 the definition of a Clifford Algebra is given. I have a broad understanding of tensor algebras, but I'm struggling to understand the definition of Clifford algebra by the quotient algebra $T(V)$ with the ideal $I_q$ where $$I_q = < v \otimes v + q(x)1_{T(V)}>$$ In particular, it isn't clear to me why $I_q$ is a proper ideal, or how to interpret its elements, and further the elements of $T(V)/I_q$ . I know this might be a lot of questions all in one, but any insights would be greatly appreciated!","['clifford-algebras', 'abstract-algebra', 'tensors']"
4055197,Structure of vector bundles over $(\mathbb P^1)^r$,"Fix an algebraically closed field $k$ of characteristic zero. I would like to know a classification of all vector bundles on $(\mathbb P_k^1)^r$ , or at least of semistable vector bundles. A theorem of Grothendieck states that a vector bundle $E$ of rank $m$ on $\mathbb P^1$ decomposes as a direct sum of line bundles: $E \cong \mathcal O(a_1) \oplus \dots \oplus \mathcal O(a_r)$ . Let $X$ be the $r$ -fold fibre product of $\mathbb P^1$ 's. We know (Hartshorne III Ex 12.6) that $\operatorname{Pic}(X) = \mathbb Z^r$ , so every line bundle on $X$ is of the form $\pi_1^*\mathcal O_{\mathbb P^1}(a_1) \otimes \cdots \otimes \pi_r^*\mathcal O_{\mathbb P^1}(a_r)$ , with $\pi_i$ the projection maps. For $r=2$ , we can find vector bundles of rank $2$ by computing $\operatorname{Ext}^1(\pi_i^*\mathcal O_{\mathbb P^1}(a_i), \pi_j^*\mathcal O_{\mathbb P^1}(a_j))$ , which is non-trivial if $a_i \leq -2$ and $a_j \geq 0$ or if $a_i \geq 0$ and $a_j \leq -2$ . Does every rank $2$ vector bundle on $(\mathbb P^1)^2$ arise as such an extension? What about vector bundles of rank $2$ on $(\mathbb P^1)^r$ for $r> 2$ ? What about bundles of higher rank?
What do vector bundles corresponding to non-trivial extensions look like in terms of transition functions? By the Harder-Narasimhan filtration, every vector bundle on a projective scheme arises as an iterated extension of semistable vector bundles.
Of the line bundles which arise as direct sums of tensor products of pullbacks of line bundles on $\mathbb P^1$ as above, it is not hard to show that the only semistable such are those of the form $\bigoplus_{i=1}^m (\pi_1^*\mathcal O_{\mathbb P^1}(a_1) \otimes \cdots \otimes \pi_r^*\mathcal O_{\mathbb P^1}(a_r))$ . Are there any other semistable vector bundles on $X$ ?","['homological-algebra', 'algebraic-geometry', 'projective-space', 'sheaf-theory']"
4055233,A result of Chebychev and an $\epsilon$ away from Bertrand's postulate,"I came across the following result in a number theory book. In proving a result of Chebychev that there exist positive constants $x_0$ , $c_1$ and $c_2$ such that $$ c_1 \frac{x}{\log x} \le \pi(x) \le c_2\frac{x}{\log x}$$ for all $x>x_0$ , the following bounds on $\psi(x)$ were used $$ x\log 2 + O(\log x) \le \psi(x) \le 2x\log 2 + O(\log^2(x))$$ together with the result that $$\frac{\psi(x)}{x} = \frac{\pi(x)\log x}{x} + o(1)$$ The author says that for any $c_1 < \log 2$ and any $c_2 > 2\log 2$ the theorem holds. In an attempt to fill the details, I did the following: starting from $$ x\log 2 + O(\log x) \le \psi(x) \le 2x\log 2 + O(\log^2(x)),$$ divide through by $x$ to obtain $$\log 2 + o(1) \le \frac{\psi(x)}{x} \le 2\log2 + o(1)$$ Now, replace $\frac{\psi(x)}{x}$ with $\frac{\pi(x)\log x}{x} + o(1)$ so that $$\log 2 + o(1) \le \frac{\pi(x)\log x}{x} + o(1) \le 2\log2 + o(1)$$ Here's a step I'm not sure of and need clarification: can the little $o$ term in the middle be subtracted across the board to get $$\log 2 + o(1) \le \frac{\pi(x)\log x}{x}\le 2\log2 + o(1)$$ $$\frac{x}{\log x}(\log 2 + o(1)) \le \pi(x) \le \frac{x}{\log x}(2\log2 + o(1))$$ and hence for any $c_1 < \log2, c_2 > 2\log 2$ the theorem follows? Secondly, the author says that since $\frac{2\log 2}{\log 2}=2,$ a corollary of this result is that for every $\epsilon > 0$ , there exists a prime number in the interval $[x, (2+\epsilon)x]$ for all $x > x_0(\epsilon)$ . I do not see this immediately. How can this be verified?","['analytic-number-theory', 'number-theory', 'asymptotics', 'prime-numbers']"
4055292,Binomial identity involving central binomial coefficient,"I came across this nice binomial identity $${‎‎\sum}_{k=0}^{2n} \frac{(-1)^k {2n \choose k} {2k \choose k}}{n+k \choose k} = 1$$ This is equivalent to the hypergeometric function ${}_2 F_1(-2n, 1/2; n+1; 4)$ . I am having a hard time trying to prove this. Can someone help me with a hint to prove this?","['calculus', 'binomial-coefficients', 'combinatorics', 'hypergeometric-function']"
4055329,Functions satisfying $f^2+g^2=1$,"I am asked to prove that if $f,g$ are differentiable functions and $f^2(x)+g^2(x)=1$ $\forall x$ , then there exists a differentiable function $\theta$ so that $f(x)=\cos(\theta(x))$ and $g(x)=\sin(\theta(x))$ , $\forall x$ . The proof can't use complex numbers. I'm suggested to use $\theta' = fg'-gf'$ , but I haven't been able to make any considerable progress.","['functions', 'derivatives', 'geometry']"
4055400,Lambda Calculus Question: If for some λ-terms M and N we have Mx =β Nx. Does it necessarily imply that M =β N?,"I have a homework question that I can't figure out. Hope someone can help. Assume that for some $\lambda$ -terms $M$ and $N$ we have $Mx =_\beta  Nx$ . Does it necessarily imply that $M =_\beta N$ ?
Here $=_\beta$ stands for $\beta$ -equivalent. It is in the paragraph on the Church-Rosser property Intuitively I would say the answer is yes, but I'm not sure how to show this.","['lambda-calculus', 'computability', 'discrete-mathematics', 'computer-science']"
4055465,Claiming that $\int_c^\infty I(y)dy = \int_a^\infty J(x)dx$,"Claim: Let a real-valued function $f(x,y)$ be definied on $D = [a,+\infty)\times [c,+\infty)$ . If $I(y) = \int_a^\infty f(x,y)dx$ and $J(x) = \int_c^\infty f(x,y)dy$ are continuous and at least one of the following $$\int_c^\infty I(y)dy = \int_c^\infty dy \int_a^\infty f(x,y)dx \\ \int_a^\infty J(x)dx = \int_a^\infty dx \int_c^\infty f(x,y)dy$$ improper integrals conveverges, then so does the other and $$\int_c^\infty I(y)dy = \int_a^\infty J(x)dx$$ I haven't found anything very related to this theorem in my textbooks. I was thinking of taking two arbitrary sequences $(a_n)$ and $(c_n)$ such that $a_n \to +\infty$ and $c_n \to +\infty$ and defining $$I_n(y) = \int_a^{a_n} f(x,y) dy$$ and $$J_n(x) = \int_c^{c_n} f(x,y)dy$$ Then, obviously $I_n(y)_\rightarrow^\rightarrow I(y)$ and $J_n(x)_\rightarrow^\rightarrow J(x)$ . However, it seems I cannot go any further. I wonder if after the definition of the functional sequence above, one could use the ready results from that section.","['integration', 'improper-integrals', 'real-analysis', 'calculus', 'sequences-and-series']"
4055466,Proving $\sum_{n=1}^m\sin^2\left(n\frac\pi{m}\right)=\frac{m}2$ for $m\geq 2$ by induction,"$$\sum_{n=1}^m \sin^2\left(n\frac{\pi}{m}\right) = \frac{m}{2}$$ for all $m\ge2$ positive integers I'm doing a maths problem that involves proving by mathematical induction the sum of a sigma. I find it hard because the highest term is included in the sigma so it changes the actual sigma. If anyone can help me, please respond it would be very useful!! Even just the smallest help will go a long way : ) Here is the Desmos link to show you this is true. But I want to prove it using induction. Thanks.","['trigonometry', 'induction', 'sequences-and-series']"
4055467,Side of a square attached to two triangles,"Solve for $l$ I tried to solve this for $l$ with trigonometry, but I stopped at $l^2+4-2l\cdot \cos(x)=16, l^2 + 4 +2l\cdot \sin(x)=25$ , where $x$ is the angle of the left triangle between 4 and $l$ .
So I've tried with Heron's, and got stuck with some square roots... According to WolframAlpha, the answer must be something around 3.71374 Any ideas? ------SOLVED---------- Okay, so, thanks to Narasimham I've seen that I took cosine formula wrong, and thanks to cosmo5 I've been able to solve it, here's the solution: Start with cosine formula \begin{matrix}
5^2 & = & l^2+4-2\cdot2\cdot l\cdot \cos(270^\circ - \alpha))\\ 
4^2 & = & l^2+4-2\cdot2\cdot l \cdot \cos(\alpha)
\end{matrix} Rearrange teh two equation \begin{matrix}
441-42l^2+l^4 & = &16l^2\cdot\sin^2(\alpha))\\ 
144-24l^2+l^4 & = &16l^2 \cdot \cos^2(\alpha)
\end{matrix} find this quadratic formula \begin{matrix}
585-66l^2+2l^4=16l^2
\end{matrix} and then found this solutions \begin{matrix}
+\sqrt{\dfrac{41+\sqrt{511}}{2}}\\ 
+\sqrt{\dfrac{41-\sqrt{511}}{2}}\\
-\sqrt{\dfrac{41+\sqrt{511}}{2}}\\
-\sqrt{\dfrac{41-\sqrt{511}}{2}}
\end{matrix} Then, discart the negative ones \begin{matrix}
\sqrt{\dfrac{41+\sqrt{511}}{2}}\\ 
\sqrt{\dfrac{41-\sqrt{511}}{2}}
\end{matrix}","['trigonometry', 'triangles']"
4055557,Equivariant line bundle-divisor correspondence?,"In reading about equivariant bundles, I've become a bit confused about how the usual line bundle-divisor correspondence $c_1:\text{Pic}(X)\xrightarrow{\cong}A^1(X)$ works in the equivariant setting. Let $X$ be a smooth complex variety with $G$ -action, and let $\mathcal L$ denote a $G$ -equivariant line bundle. I've read that there is an equivariant first Chern class $c_1^G$ defined by $$
c_1^G(\mathcal L)=c_1(EG\times_G\mathcal L)\in H^2(EG\times_GX)=H^2_G(X)
$$ which classifies equivariant line bundles, and am wondering if this leads to a concrete equivalence between equivariant line bundles on $X$ and some equivariant version of the Weil class group (with effective divisors replaced by $G$ -invariant divisors). For instance, in my current reading I came across an example (slightly simplified) where $\mu_n\cong\mathbb Z/n\mathbb Z$ acts on $\mathbb C$ by multiplication by roots of unity, and an equivariant line bundle $\mathcal L$ is defined on $\mathbb C$ by writing $\mathcal L=O(p)$ where $p$ is the origin (the point fixed under the action). How can I understand the action of $\mu_n$ on this line bundle?","['equivariant-maps', 'vector-bundles', 'algebraic-geometry']"
4055613,Open maps of spaces vs open maps of locales,"A continuous function between topological spaces $f:X\to Y$ is called open, if $f[U]\in\mathcal{O}(Y)$ for all $U\in\mathcal{O}(X)$ . A morphism of locales $f:X\to Y$ is called open, if the associated morphism of frames $f^*:\mathcal{O}(Y)\to\mathcal{O}(X)$ has a monotone left adjoint $f_!$ which satisfies the Frobenius condition $f_!(U)\wedge V\leq f_!(U\wedge f^*(V))$ for all $U\in\mathcal{O}(X)$ and $V\in\mathcal{O}(Y)$ . It is easy to see that every continuous $f$ that is open in the topological sense is also open in the localic sense, but the converse is false in general. For example,  the maps $1\to\nabla(2)$ and $\mathsf{cofin}(\mathbb{N})\to\mathsf{sobrify}(\mathsf{cofin}(\mathbb{N}))$ are open in the localic, but not in the topological sense, since they're not surjective, but the induced locale-morphisms are iso. These two examples involve non-sober spaces, so the natural thing to ask is: Do the two notions coincide for sober spaces? Or more generally, does the canonical functor from locales to spaces preserve open maps? Or are there other criteria for when the two notions coincide? For example, I think I have convinced myself that continuous maps that are open in the localic sense are open in the topological sense whenever the codomain is $T_1$ .","['general-topology', 'locales', 'category-theory']"
4055691,Number of pieces produced by cutting a folded ribbon,"A piece of ribbon 1 metre long is folded in half so that the two ends are on top of each other. This doubled piece of ribbon is then folded in half again. The folded piece of ribbon is then cut  right through its midway point (see my drawing below). This produces 5 pieces of ribbon of lengths: $\frac{1}{8},\frac{1}{4},\frac{1}{4}, \frac{1}{4}, \frac{1}{8}$ . My question is what happens after $n$ folds? Trying a few more examples has led me to guess that after $n$ folds: there are $2^n + 1$ pieces of ribbon, with two strands of length $\frac{1}{2^{n+1}}$ and the rest of length $\frac{1}{2^{n}}$ . I am having difficulty creating a convincing proof of this. I came across this problem on an Oxford University Thinking Skills Admissions test ( Question 38, page 23 ). If this is a well known problem, I would also be interested in a source to read about the question in more detail.","['recreational-mathematics', 'combinatorics']"
4055727,"$V(x,xy)=V(x)$ but also $V(x,xy)=V(xy)$?","In $\operatorname{Spec}k[x,y]$ , we have $$V(x,xy)=V(x)$$ but if we expand the LHS we also get \begin{align}
V(x,xy)&=V(x) \cap V(xy)\\
&=V(x) \cap (V(x) \cup V(y))\\
&=(V(x) \cap V(x))\cup (V(x) \cap V(y))\\
&=V(x) \cup V(xy)\\
&=V(xy).
\end{align} $V(x)$ corresponds to the $y$ -axis, but $V(xy)$ corresponds to the union of the $x$ and $y$ axes. What is going on here?","['intuition', 'algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
