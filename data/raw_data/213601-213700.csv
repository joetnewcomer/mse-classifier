question_id,title,body,tags
4321742,"Spivak Calculus, Ch. 5 Limits: Understanding the mathematical logic underlying conclusion of proof of uniqueness of limit of function","In Spivak's Calculus, Ch. 5 on Limits, there is the following theorem about the uniqueness of a limit of a function near a point: A function cannot approach two different limits near $a$ . In other
words, if $f$ approaches $l$ near $a$ , and $f$ approaches $m$ near $a$ , then $l=m$ Here is the proof: ""f approaches $l$ near $a$ "" $$\forall \epsilon>0\ \exists\delta_1>0, |x-a|<\delta_1\implies |f(x)-l|<\epsilon$$ ""f approaches $m$ near $a$ "" $$\forall \epsilon>0\ \exists\delta_2>0, |x-a|<\delta_2\implies |f(x)-m|<\epsilon$$ $\delta=min(\delta_1, \delta_2)$ $$\implies \forall \epsilon>0\ \exists\delta>0, |x-a|<\delta\implies |f(x)-m|<\epsilon,|f(x)-l|<\epsilon\tag{1}$$ Assume $m\neq l$ Choose $\epsilon=\frac{|m-l|}{2}$ . $$|x-a|<\delta \implies |f(x)-m|<\frac{|m-l|}{2}, |f(x)-l|<\frac{|m-l|}{2}$$ \begin{align*}
|m-l|&=|m-f(x)+f(x)-l|\\
     &\leq |m-f(x)|+|f(x)-l|\\
     &< \frac{|m-l|}{2}+\frac{|m-l|}{2}\\
     &= |m-l|
\end{align*} Therefore, with this reasoning we've reached the conclusion that $|m-l|<|m-l|$ , which is a contradiction. I am fine with the proof itself. My questions are about the actual logic that allows me to conclude that the proof was successful. Questions: When we say the conclusion is a contradiction, what is it contradicting? The fact that a number is smaller than itself? So here some basic axiom of numbers is being contradicted? More importantly, what is the exact statement that because of our conclusion, is now shown to be false? I believe it is the statement $(1)$ above. What is the negation of statement $(1)$ exactly? In general terms I believe it is ""we found an $\epsilon$ for which there is no $\delta$ such that $|x-a|<\delta\implies|f(x)-m|<\epsilon,|f(x)-l|<\epsilon$ "". Reformulating this statement: $$\exists\epsilon>0\ \text{such that}\ \nexists \delta>0\ \text{such that}\ |x-a|<\delta\implies |f(x)-m|<\epsilon,|f(x)-l|<\epsilon$$ Is this the correct conclusion? Ie, the negation of $(1)$ , which is true? Finally, as an extra if anyone can give their two cents: I haven't studied mathematical logic, but I think it would be a good idea, though I am not sure what to study (propositional logic?). What does one study so that questions of the type I am asking above aren't an issue anymore?","['limits', 'calculus', 'limits-without-lhopital']"
4321765,Why the answer for double integral is coming as zero?,"I am trying to evaluate $$\iint_{R} x+y \:d A$$ , where $R$ is the region formed by the vertices $$(0,0),(5,0),\left(\frac{5}{2}, \frac{5}{2}\right) \text { and }\left(\frac{5}{2},-\frac{5}{2}\right)$$ . My try:
Here is the picture of the region which has two triangular regions. Let the top traingle is $R1$ and bottom triangle is $R2$ We have $$\iint _{R}(x+y)dA=\iint_{R1}(x+y)dA+\iint_{R2}(x+y)dA$$ Now we have: $$\iint_{R1}(x+y)dA=\int_{x=0}^{5}\int_{y=x}^{5-x}(x+y)dydx=\frac{-125}{6}$$ Also $$\iint_{R2}(x+y)dA=\int_{x=0}^{5}\int_{y=-x}^{x-5}(x+y)dydx=\frac{125}{6}$$ Adding both i am getting zero. But that is not the answer. What's wrong in this approach?","['multivariable-calculus', 'multiple-integral', 'definite-integrals']"
4321776,Understanding where does the second (stochastic) attractor of the system come from.,"I am currently reading a paper , studying the population dynamics in 3-dimensional Lotka-Volterra model with the following interaction change descriptive system: $$
\begin{equation}
    \begin{cases}
        \dot x = ax - 0.06x^2-\Large\frac{xy}{x+10}\normalsize,\\
        \dot y = -y + \Large\frac{2xy}{x+10}\normalsize-\Large\frac{0.405\cdot yz}{y+10}\normalsize,\\
        \dot z = 0.038z^2 -\Large\frac{z^2}{y+20}\normalsize.\\
    \end{cases}
\end{equation}\tag{1}
$$ Where $a$ is the variable parameter, for different values of which the model's behavior is studied. In the paper, authors claim, that the respective non-degenerate (biologically meaningfull if $a > 0.9158$ ) equlibria for $(1)$ is $M_3(\bar x_3, \bar y_3, \bar z_3)$ , where $\bar x_3 = \frac{a}{0.12}-5+\frac{\sqrt{(a+0.6)^2-1.52}}{0.12},~\bar y_3 = 6.31579,~\bar z_3 = -40.3 + 80.6\frac{\bar x_3}{\bar x_3 + 10}.$ Now, the problem is that further in the paper, authors consider a case, when $(1)$ posesses coexisting limit-1 cycle (red) and two-band chaotic attractor (blue). But the case is, I understnad what the red curve is, that is just basically the set of solutions of the system $(1)$ , plotted not against the time variable, but against each other $(x(t),y(t),z(t))$ . I even managed to get the ""red"" curve by myself, by solving $(1)$ for $a=1.803$ in python, using scipy.integrate.odeint : But then, I completely fail to understand, where does the ""blue"" attractor come from, and there is no any further information in the paper  about where it comes from as well, rather the blue attractor is just called ""attractor of a Feigenbaum's tree"". If anyone would be so kind to explain me, where the ""blue"" attractor here comes from, that would be great! Thank you in advance!","['basins-of-attraction', 'stability-in-odes', 'bifurcation', 'ordinary-differential-equations']"
4321794,Calculate $\int_0^{2\pi} \tan \frac{\theta}8 d\theta $ using complex analysis,"Professor gave me the problem that calculates below real integral using complex analysis. $$\int_0^{2\pi} \tan \frac{\theta}8 d\theta $$ Actually this integral can easily be calculated just substituting $t=\cos\frac{\theta}8$ , but the professor requested me to calculate this integral using complex analysis. As far as I know, if we want to calculate a real integral that consists of trigonometric functions, we can substitute $z=e^{i\theta}$ then $\cos\theta=\dfrac{z+\frac 1z}2$ and $\sin\theta=\dfrac{z-\frac 1 z}{2i}$ where the contour is the unit circle. But $\frac \theta 8$ holds me back. How can I treat this? I tried to substitute $z^{1/8}=e^{i\theta/8}$ , but still challenging.","['complex-analysis', 'trigonometric-integrals', 'line-integrals', 'definite-integrals']"
4321815,Smooth homotopy and a theorem in Lee's book,"Suppose that $M,N$ are smooth manifolds without boundary and $F: N \rightarrow M$ is a continuous map, then we know that $F$ is homotopic to a smooth map ( Th6.26 , Lee's Smooth Manifolds),i.e there is a continuous map $G: [0,1]\times N \rightarrow M$ such that $G(0, \cdot) = F$ and $G(1, \cdot)$ is smooth. My question is : Can we choose $G$ so that $G$ is smooth in $(0,1]\times N$ ? Why I came up with this small (and trivial?) question? : I has been learning Lee's book for fun by trying to prove each Theorems in his book by myself. Then for this Theorem, I obtained the existence of such $G$ so I wanted to check if it is really right to make sure that I understand correctly most of concepts related to Smooth Manifolds. Thank you for your time.","['homotopy-theory', 'smooth-manifolds', 'differential-geometry']"
4321898,Problem in defining a trigonometric equation (ellipse),"I have an updated problem of my question from: Problem in defining a trigonometric equation @David K gave me a very nice solution here. But now the problem is that since I do not have a circle but a ellipse the radius r is not perpendicular to the straight line with slope $\alpha$ anymore.
So I somehow don't know how to get to a solution because I think something is missing. Given: $r_f$ $\tau$ major axis $b$ slope $\alpha$ of straight line $x_\phi$ , $y_\phi$ Target: Find value of minor axis $a$ with given values I can solve this for a circle with radius r (see link from my last question) and I then thought maybe it is possible to transform the circle to a ellipse but since $a$ is unknown this seem not to work... Here what I tried so far but I'm unable to continue because I cannot define $\beta$ . (1) $x_1=x_\phi-y_\phi cot(\tau)$ (2) $\delta = \frac{\pi}{2}-\tau$ (3) $\frac{x_1}{sin(\delta+\beta)}=\frac{r}{sin(\tau)}$ Putting (1) and (2) in (3) gives me: --> $r=\frac{sin(\tau) (x_\phi-y_\phi cot(\tau))}{sin(\frac{\pi}{2}-\tau+\beta)}$ with unkown $\beta$ (4) $x_2=x_\phi+y_\phi tan(\beta)$ (5) $\Psi = \frac{\pi}{2}-\beta$ (6) $\frac{r_f+a}{sin(\Psi)}=\frac{x_2}{sin(\delta+\beta)}$ Putting (4), (5) and (2) in (6) gives me: $a=(\frac{x(\phi)+y(\phi)tan(\beta)}{sin(\frac{\pi}{2}-\tau+\beta)}-\frac{r_f}{sin(\frac{\pi}{2}-\beta)})sin(\frac{\pi}{2}-\beta)$ but still $\beta$ and $x_\phi$ is unknown... Also I think $b$ can help me to find a solution for $a$ , since b is known but I don't know how I can use $b$ . // edit 2021-12-07:
What about if $x_\phi$ , $y_\phi$ is unkown? // edit 2021-12-08:
After discussion with @Intelligenti pauca: Line with slope $\alpha$ and y-intersection $t$ is given (fix) minor axis $a$ and point of tangency $x_\phi$ , $y_\phi$ need to be found. Best regards
mk3","['trigonometry', 'calculus', 'conic-sections', 'geometry']"
4321899,"How to prove that a certain block matrix is positive semi definite, which depends on a undetermined submatrix","How should I proof the following matrix $$M = \begin{pmatrix}
Z-A^TZA & -A^TZB\\
-B^TZA & -B^TZB
\end{pmatrix},$$ to be positive semidefinite? The matrices $A\in \mathbb{R}^{n\times n}$ and $ B\in \mathbb{R}^{n\times m} $ are known. The matrix $Z\in R^{n\times n}$ is unknown and the actual goal is to construct the matrix $Z$ such that $M$ is positive semi-definite. I have tried the following things: constructing $Z$ as a diagonal matrix and by using a symbolic programming library (sympy) I found the expressions for the eigenvalues of $M$ . Here I found out that for this specific $Z$ , the eigenvalues will be indefinite (larger or smaller than zero) using theories off Schur Complement : Wikipedia Link . For example, in order for the third option of the link to be true; $Z-A^TZA \succ 0$ and $ -B^TZB-(-B^TZA)^T(Z-A^TZA)^{-1}(-A^TZB) \succeq 0$ , $(-B^TZA)^T= -A^TZB$ -> $Z$ should be symmetric. I think I could write this all out to be a larger Linear Matrix Inequality (LMI) and try to solve using python for example. However, I'm not sure if that is true and if this is the correct approach as this would take some time to implement this in a python code. Do you have any suggestions or feedback for a different approach? (My mathematical knowledge is not so great as I come from a mechanical/control engineering background. Furthermore, this is my first question on a stack website. I apologize for any trivial mistakes I made) EDIT: Extra info regarding the matrices $A$ , $B$ ; they are so-called state-space matrices which are part of a Linear Time-Invariant(LTI) dynamical model Wikipedia . The standard form is $x_{k+1}=Ax_k + Bu$ where $x \in \mathbb{R}^n$ represents the state of the system and $u \in \mathbb{R}^m$ is the input to this dynamical model. The matrix $A$ is the mapping of the current state of the system to the next state (in time) and $B$ represents the mapping of the input to the next state (in time).
These state-space matrices ( $A, B$ ) are thus known as they represent the dynamics of a system. However, they have no special mathematical properties.","['schur-complement', 'linear-matrix-inequality', 'positive-semidefinite', 'matrices', 'linear-algebra']"
4321976,Applying Zorn's lemma on a set of all sets.,"Let $U$ be the set of all sets. Define a partial ordering on $U$ by inclusion: $A \leq B$ iff $A \subseteq B$ for $A, B \in U$ .
Consider a chain $C$ of $U$ under this partial ordering: $$
C : A_1 ≤ A_2 ≤ A_3 ≤ \cdots
$$ Define $B = \bigcup_{i\geq1}A_i$ .
Clearly, $B \in U$ and it is an upper
bound of the chain $C$ . Hence, Zorn’s Lemma implies that $U$ has a maximal element, say $M$ .
The argument is clearly wrong since $M$ is not a maximal element: $$
M \subsetneq \{M, \{M\}\} \in U.
$$ I can't identify which step in the argument is wrong and why.",['discrete-mathematics']
4321977,"Line of circles and star made of circles, are they homeomorphic?",How can I determine if this two figures are homeomorphic? I'm guessing they're not homeomorphic. I have tried using cut points but from what I understand both figures have the same number of cut points. I can see that in the first picture the circle in the center is connected to the four other circles while in the second image every circle is connected at most to two other circles. Would this help to prove that they're not homeomorphic?,['general-topology']
4321978,Pure states on commutative C* algebra are exactly the characters - elementary proof,"I'm trying to come up with an 'elementary proof' that if $A$ is a commutative $C^*$ algebra, then the pure states of $A$ are exactly its characters. I have already come up with a proof which uses properties of the GNS representation in order to show this. One can also identify the algebra with $C(X)$ and it's probably easier to prove this on this specific algebra.
But I was wondering if the is a more 'algebraic' proof which uses relatively elementary results and does not require much more than the basic definitions and properties of pure states. I can show by simple arguments that all characters are pure states. But I'm having difficulty with the other direction - showing that in the unital and commutative case, pure states must be multiplicative. Does anyone have an idea? Thanks in advance.","['c-star-algebras', 'banach-algebras', 'functional-analysis']"
4321986,Milnor fundamental theorem of algebra : proof that $f: S^2 \rightarrow S^2$ is smooth,"In the book of J.Milnor : ""Topology from the differentiable viewpoint"", in the chapter 1, p.8, he prooves the Fundamental Theorem of Algebra : Every complex polynomial $p: \mathbb{C} \rightarrow \mathbb{C}$ , not constant ( $k > 0$ ), $$ 
  p(z) = \sum_{k=0}^{N} a_z z^{k}, \quad a_z \in \mathbb{C} \quad 
$$ has at least one zero in $\mathbb{C}$ . To proove that, because $\mathbb{C}$ is not compact, he identifies the complex plane $\mathbb{C}$ with the Riemann sphere $S^2$ via the bijection $h_{+}$ and $h_{-}$ that are the stereographic projection of the north pole and south pole on the plane $\mathbb{R}^2 \times \{0\}$ . This allows us to extend $p: \mathbb{C} \rightarrow \mathbb{C}$ to $\hat{p}: \mathbb{C} \cup \{+\infty\} \rightarrow \mathbb{C} \cup \{+\infty\}$ and define an application, $$
  f: S^2 \rightarrow S^2
$$ where, $$
  f(u, v, w) = 
\begin{cases}
  h_{+}^{-1} \circ p \circ h_{+}(u,v,w), &\quad (u,v,w) \neq (0, 0, 1) \\
  (0, 0, 1), &\quad (u,v,w) = (0, 0, 1)
\end{cases}
$$ Now, Milnor claims that $f$ is smooth . Seeing that f is smooth in $S^2 \setminus \{(0, 0, 1)\}$ is easy but for the north pole (0, 0, 1) I am not sure to understand the proof. We define, $$
Q(z) := h_{-} \circ f \circ (h_{-}(z))^{-1}
$$ After some algebra, we can see that $Q(z)$ is a quotient of polynomial and that it is defined in $z = 0$ so that $Q(z)$ is smooth in $z = 0$ . So then $f \circ (h_{-}(0))^{-1} = f(0, 0, 1)$ is smooth at $(0, 0, 1)$ by composition with smooth functions $h_{-}$ and $h_{-}^{-1}$ ?","['smooth-functions', 'smooth-manifolds', 'complex-analysis', 'differential-topology', 'differential-geometry']"
4321987,Chern classes and sums of line bundles,"Let $E$ be a complex vector bundle of rank $r$ and suppose we can write $E = \oplus_{i=1}^r L_i$ where $L_i$ are line bundles. I have read here (and think I more or less understand why) that the total chern class of $E$ can be written in this case as: $$c(E) = \prod_{i=1}^r(1+c_1(L_i))$$ My question: is there any similar simple expression for $c_1(E)$ ? In particular, is it true that in this case I can write $c_1(E) = \sum_{i=1}^r c_1(L_i)$ ? Thanks in advance!","['complex-manifolds', 'algebraic-geometry', 'characteristic-classes']"
4321999,Proof explanation about why $\liminf_{n}X_{n}$ is a random variable,"Definition 1: $ X: \varOmega \to \varOmega' $ is called a measurable map from $ (\varOmega ,\mathcal{F}) \to (\varOmega' , \mathcal{F}') $ if for all $ A'\in\mathcal{F}' \implies X^{-1}(A') \in\mathcal{F} $ where $ \mathcal{F},\mathcal{F}' $ is  a sigma-algebra over $ \varOmega ,\varOmega'$ respectively Definition 2: A random variable on a probability space $(\varOmega , \mathcal{F} ,\mathbb P )$ is a measurable function $X : (\varOmega,\mathcal{F}) \to (\mathbb R, \mathcal{B})$ The question is: Assume that $(X_{n})_{n} $ is a sequence of random variables. I need to prove that $\liminf_{n}X_{n}$ is a random variable Since $ \mathcal{B}=\sigma((-\infty,t]:t\in\mathbb{R}) $ its enough to show that for any $ t \in \mathbb{R} $ $\liminf_{n}X_{n} \leq t $ is an event My professor solved that like that: Let $W = \liminf_{n}X_{n}$ . Note that for any $t \in \mathbb R$ , $$\left\{W > t \right\} = \{\exists n, \forall k\ge n , X_{k}>t\} = \bigcup_{n}\bigcap_{k\geq n}\{X_{k}>t\}=\liminf_{n}\{X_{n}>t\}$$ which is an event as  a countable union of a countable intersection of events.Thus $\left\{W \leq t\right\} = \left\{W > t\right\}^c$ is an event. So $W$ is measutable and thus a random variable. I don't understand the logic behind this, from the answer I can see that $$\left\{W \leq t\right\} = \bigcap_{n}\bigcup_{k\geq n}\left\{X_{k}\leq t\right\} = \limsup_{n}\left\{X_{n}\leq t \right\}$$ but the definition of $\liminf_{n}X_{n}$ is that $X_{n}$ will occur after some large enough $n$ onward. that is ,eventually all $X_{n}$ occur.
so if we say that $\left\{W > t\right\}$ its mean that after large enough $n$ we will have that for all $k \geq n$ $X_{k}>t$ so indeed $\left\{W > t\right\} = \liminf_{n}\left\{X_{n}>t\right\}$ but why can't I say the same with $\left\{W \leq t\right\}$ ? I mean why cant I use the same logic that after large enough $n$ we will have that for all $k \geq n$ $X_{k}\leq t$ so we will have that $\left\{W \leq t\right\} = \liminf_{n}\left\{X_{n}\leq t\right\}$ ? I saw the question here ( Prove that $ \liminf_{n}X_{n} $ is a random variable ) but this is not answering my question","['borel-sets', 'limsup-and-liminf', 'probability-theory', 'random-variables']"
4322004,"Does $f(a,b)$ being directly proportional to $a$ and $b$ separately imply that $f(a,b)$ is directly proportional to $ab?$","For example , in physics, if $$\text{F} \propto m_1m_2$$ and $$\text{F} \propto \frac{1}{r^2},$$ then $$\text{F} \propto (m_1m_2)\left(\frac{1}{r^2}\right)= \frac{m_1m_2}{r^2}.$$ This property (combining proportionality) intuitively makes sense, but I have never seen it formally written in a textbook. Could someone please rigorously prove this property (and fully specify its conditions?), or give a counterexample? P.S. I know that this question has been answered, including here , but I do not understand the explanations: e.g., I don’t understand how $k=f(C)$ or $k′=g(B).$","['algebra-precalculus', 'functions']"
4322038,Number of solution of ${\left( {\sin x - 1} \right)^3} + {\left( {\cos x - 1} \right)^3} + {\sin ^3}x = {\left( {2\sin x + \cos x - 2} \right)^3}$,"Number of solution of the equation ${\left( {\sin x - 1} \right)^3} + {\left( {\cos x - 1} \right)^3} + {\sin ^3}x = {\left( {2\sin x + \cos x - 2} \right)^3}$ in the interval $[0,2\pi]$ is equal to_____ My approach is as follow $a = \sin x - 1;b = \cos x - 1;c = \sin x$ ${a^3} + {b^3} + {c^3} = {\left( {a + b + c} \right)^3}$ $ \Rightarrow {a^3} + {b^3} + {c^3} = {\left( {a + b + c} \right)^3}$ ${\left( {a + b + c} \right)^3} = {a^3} + {b^3} + {c^3} + 6abc + 3ab\left( {a + b} \right) + 3bc\left( {b + c} \right) + 3ac\left( {a + c} \right)$ ${a^3} + {b^3} + {c^3} = {\left( {a + b + c} \right)^3} \Rightarrow 6abc + 3ab\left( {a + b} \right) + 3bc\left( {b + c} \right) + 3ac\left( {a + c} \right) = 0$ $ \Rightarrow 2abc + ab\left( {a + b} \right) + bc\left( {b + c} \right) + ac\left( {a + c} \right) = 0$ How do we approach from here",['trigonometry']
4322041,Limit of the sequence by recurrence of mean of the last two values.,"The sequence is defined by recurrence: $x_1=1$ , $x_2=2$ \begin{equation}
x_{n+1} = \frac{1}{2}(x_{n}+x_{n-1})
\end{equation} It is asked to calculate the limit.
I have seen that the sequence is bounded by 1 and 2.
On the other hand, I have seen that the sequence of the pairs, $x_{2n}$ , is decreasing and the sequence of the odd, $x_{2n-1}$ , is increasing. Therefore both are convergent.
I have seen that both limits are equal, therefore the original sequence is convergent with the same limit. But I won't be able to prove what the limit is.","['limits', 'recurrence-relations', 'sequences-and-series']"
4322098,Covering with sets of negligible boundary,"I am studying causality theory in Lorentzian length spaces, and I have a question about geometric measure theory in general (it will help me with a proof I am trying to finish): Suppose we have a Polish space $(X,d)$ , two compactly supported probability measures $\mu,\nu\in\mathscr{P}(X)$ and an optimal coupling $\boldsymbol{\pi}\in\mathscr{P}(X\times X)$ between them, i.e. the marginals of $\boldsymbol{\pi}$ are precisely $\mu$ and $\nu$ and it solves the problem $$\inf\bigg\{\sqrt{\int_{X\times X}d(x,y)^2\,\mathrm{d}\boldsymbol{\pi}(x,y)},\quad\boldsymbol{\pi}\text{ is a coupling between $\mu$ and $\nu$}\bigg\},$$ which is the usual $2$ -Wasserstein distance. In my context $S:=\text{supp }\mu\times\text{supp }\nu\subset A$ where $A$ is a particular open subset of $X$ . What I wanted to do is to take a finite covering of $S$ with rectangles of the form $B_\varepsilon(x_i)\times B_\varepsilon(y_i)$ where the $B_\varepsilon(z)$ are balls centered at $z\in X$ of radius $\varepsilon>0$ . Now the question: assume to have a locally finite Radon measure $\mathfrak{m}$ on $X$ . Is it then possible to consider a covering of $\text{supp }\boldsymbol{\pi}$ , say $\{B_i\}$ , with pairwise disjoint $B_i$ , each $B_i\in B_\varepsilon(x_i)\times B_\varepsilon(y_i)$ and such that $\boldsymbol{\mathfrak{m}(\partial B_i)=0}$ ? My doubt is about the $\mathfrak{m}$ -measure of the boundaries, altough in my context it is valid the Bishop-Gromov volume estimate (see Sturm's ""On the geometry of metric measure spaces II"", Proposition 2.3 a reference).","['measure-theory', 'metric-spaces', 'geometric-measure-theory', 'polish-spaces', 'wasserstein']"
4322159,Is the multiplier algebra $M(K(H)\otimes C(X))$ isomorphic to $M(K(H))\otimes C(X)$?,"In the survey article by Maes and Van Daele in the beginning of section 5, after Def. 5.1, the following claim is made (I will use different notation here, but wanted to give the reference nonetheless): Let $H$ be a Hilbert Space, $X$ be a compact hausdorff space and $K(H)$ denote the compact operators on H. Given any $C^\ast$ -algebra $A$ , we denote its multiplier algebra by $M(A)$ .
Then we can identify elements in $M(K(H)\otimes C(X)\otimes C(X))$ with strictly continuous functions from $X\times X$ to $B(H)$ . I have two questions regarding this: The way that I understand this is that we identify $C(X)\otimes C(X)$ with $C(X\times X)$ (which I'm fine with) and then, somehow, get that $M(K(H) \otimes C(X\times X)\simeq M(K(H))\otimes C(X\times X)$ . Why does that hold? Is it true in general that for any $C^\ast$ -algebra $A$ , we have $M(A\otimes C(X))\simeq M(A)\otimes C(X)$ ? Or is this something more specific about the compact operators? Am I correct in assuming that this is the intended route and we conclude the claim by identifying $M(K(H))$ with $B(H)$ (and $M(K(H))\otimes C(X)$ with the continuous functions from $X$ to $M(K(H))$ , but that is something that I at least know how to do)? I have read in several places that the multiplier algebra of $K(H)$ is $B(H)$ equipped with the $\sigma$ -stop $^\ast$ -topology. What is a good reference for that? From my understanding the multiplier algebra of a $C^\ast$ -algebra $A$ should again be a $C^\ast$ -algebra with respect to the norm $$\lVert \cdot\rVert_{M(A)} \colon = \sup_{a\in A} \max\{l_a(\cdot), r_a(\cdot)\},$$ where $l_a(x)\colon= \lVert xa\rVert\lVert a\rVert$ and $r_a(x)\colon=\lVert ax\rVert\lVert a\rVert$ . So what exactly do people mean when they say that we can identify $B(H)$ equipped with the  with the multiplier algebra of $K(H)$ ? They certainly cannot be isomorphic as $C^\ast$ -algebras, as that would imply equality of the two norms by uniqueness of norms that turn an algebra into a $C^\ast$ -algebra. What properties does this identification of $M(K(H))$ and $B(H)$ preserve? In what sense can they be identified? I'd be extraordinarily happy for any good reference on the topic that allows me to digest and understand what is going on in the Maes and Van Daele article. Thanks in advance!","['c-star-algebras', 'operator-theory', 'quantum-groups', 'functional-analysis']"
4322215,Application of Rolle's,"Suppose $q$ is a nonzero function of a real-variable such that $$u^2q''(u)+uq'(u)=u^2q(u)+q(u)$$ for all $u$ . Assume there exist $x,y$ such that $q(x)=q(y)=0$ . By Rolle's there exists $x<z<y$ such that $q'(z)=0$ . Plugging $z$ into the above equation is $$z^2q''(z)+zq'(z)=z^2q(z)+q(z)\iff z^2q''(z)=z^2q(z)+q(z).$$ And plugging $x,y$ in the equation is $$x^2q''(x)+xq'(x)=0\land y^2q''(y)+yq'(y)=0\implies xq''(x)+q(x)=0\land yq''(y)+q(y)=0.$$ I try to deduce contradiction from above but I don't know the next step. One strategy can be to show one of three equalities is actually is strict inequality. Another one can be to pursue second derivatives in the intervals $(x,z)$ and $(z,y)$ by mean value theorem. But none of these seem to show anything important. I would appreciate a hint.","['continuity', 'derivatives', 'ordinary-differential-equations']"
4322224,"Composition of $C^{k,\alpha}$ Holder Functions","Let $k,\ell \geq 0$ be integers and $\alpha,\beta \in [0,1]$ . Let $\Omega\subseteq \mathbb R^n$ be a closed set and set $f \in C^{k,\alpha}(\mathbb R;\mathbb R)$ and $g \in C^{\ell,\beta}(\Omega;\mathbb R)$ . I am wondering whether there are any citeable references which state the largest integer $h \geq 0$ and real number $\gamma \in [0,1]$ such that $f\circ g \in C^{h, \gamma}(\Omega;\mathbb R)$ . I am also interested in inequalities which upper bound $\|f \circ g\|_{C^{h,\gamma}(\Omega;\mathbb R)}$ in terms of $\|f\|_{C^{k,\alpha}(\mathbb R;\mathbb R)}$ and $\|g \|_{C^{\ell,\beta}(\Omega;\mathbb R)}$ . As mentioned in this post , when $k = \ell = 0$ ,   one may take $\gamma = \alpha\beta$ (and, of course, $h=0$ ). Furthermore, when $\alpha = \beta = 0$ , the chain rule would suggest that one may take $h = \min\{k,\ell\}$ and no better. Perhaps these results can be generalized to show that $f\circ g \in C^{\min\{k,\ell\},\alpha\beta}(\Omega;\mathbb R)$ . For example, if $n=k=\ell=1$ , then
for all $x,y \in \Omega \subseteq \mathbb R$ , $$
\begin{align*}
|(f \circ g)'(x) - (f \circ g)'(y)|
 &= |g'(x) f'(g(x)) - g'(y) f'(g(y))| \\
 &\leq  |g'(x) f'(g(x)) - g'(x) f'(g(y))| + |g'(x) f'(g(y)) - g'(x) f'(g(y))| \\
 &\lesssim  \|g\|_{C^{1,\beta}} \|f \|_{C^{1,\alpha}} |g(x) - g(y)|^\alpha + \| f\|_{C^{1,\alpha}} |g'(x)   - g'(y) | \\
 &\lesssim  \|g\|_{C^{1,\beta}}^{1+\alpha} \|f \|_{C^{1,\alpha}} |x - y|^{\alpha\beta} + \| f\|_{C^{1,\alpha}} \| g\|_{C^{1,\beta}} |x   - y |^\beta,
\end{align*}$$ suggesting that $f \circ g\in C^{1,\alpha\beta}(\Omega;\mathbb R)$ and $$\|f \circ g\|_{C^{1,\alpha\beta}} \lesssim 1+  \|g\|_{C^{1,\beta}}^{1+\alpha} \|f \|_{C^{1,\alpha}}.$$ Presumably this argument can be generalized, for instance using the Faa di Bruno formula (a similar suggestion was made in this post ). But I assume this has been done somewhere already. Does anyone know of a citeable reference containing such a result?","['holder-spaces', 'functional-analysis', 'real-analysis']"
4322232,Why is a bijection that preserves connectedness on $\mathbf{R}$ must be monotone?,"In one of the remarks for this highly upvoted unanswered question: Does there exist a bijection of $\mathbb{R}^n$ with itself such that the forward map is connected but the inverse is not? , the author points out in the post that a bijection that preserves connectedness on $\mathbf{R}$ must be monotone. Why is this true? I understand every single word in this statement, but I do not know how to prove it. To set up the notation, Let $f:\mathbf{R}\to\mathbf{R}$ be a bijection such that for any connected subset $A$ in $\mathbf{R}$ , the set $f(A)$ is also connected. How does one show that $f$ must be monotone? To get a feeling for what could go wrong if $f$ is not monotone, I consider the simple case when $f(x)=x^2$ . Obviously, $f(A)$ is connected for any connected set $A$ since $f$ is continuous; but it is not bijective. Other than this dumb example, I don't have any intuitions.","['connectedness', 'functions', 'monotone-functions']"
4322234,Complete statistic for beta distribution,"Let $X_1, ..., X_n$ identical independent variables that follows a beta distribution $\text{Beta}(\theta,1)$ Is $S = \sum_{i=1}^{n}X_i$ a complete statistic for $\theta$ ? I have proved that the sum is not a sufficient statistic for $\theta$ but I'm having a difficult time about completeness. If the statistic is not complete, then I need to find a function $g$ such that $E[g(S)] = 0 $ implies $g(S) = 0$ almost surely for every $\theta$ . Unfortunately I have not been able to find such function. I would really appreciate any hints or sugestions with this problem","['statistical-inference', 'statistics', 'estimation', 'probability-distributions', 'probability']"
4322248,"Measurability of $\sup_{[0,1]}X(t)$ with respect to continuity","Let $X\colon[0,1]\to\mathbb{R}$ be a stochastic process on some probability space $(\Omega, \mathcal{F}, P)$ . I was always told that $$
f(\omega)=\sup_{t\in[0,1]} X(t, \omega)
$$ is not always a measurable function. However, if $X$ is a.s. continuous (e.g., a Brownian motion), then it is measurable. My questions are of two folds: How to explictly show that $f\colon\Omega\to\mathbb{R}$ can be non-measurable? Do we have a concrete example to show this? Why does the continuity imply the measurability? People say that if $X$ is continuos, then $\sup_{t\in[0,1]} X(t, \omega) = \sup_{t\in[0,1]\cap\mathbb{Q}} X(t, \omega)$ , but why the latter is measurable (i.e., why the sup over a countable set gives measurable $f$ )? Related questions: Is the supremum of an almost surely continuous stochastic process measurable? This is similar to my question but does not really answers my 1 and 2. $f(x,y)$, continuous in $x$. Is $\sup_{x\in A}f(x,y)$ measurable? https://mathoverflow.net/questions/102258/when-is-the-infimum-of-an-arbitrary-family-of-measurable-functions-also-measurab","['measure-theory', 'stochastic-processes', 'functional-analysis', 'probability-theory', 'stochastic-calculus']"
4322252,Proving that Randers norm is a Minkowski norm,"I am struggling to follow the proof that the Randers norm is a Minkowski norm from ""Lectures on Finsler Geometry"" by Zhongmin Shen. A Minkowski norm on finite dimensional vector space $V$ is a function $F:V\to[0,\infty)$ which has the following properties: $F$ is $C^{\infty}$ on $V\setminus\{0\}$ $F(\gamma y) = \gamma F(y)$ , for all $\gamma>0$ and $y\in V$ For any $y\in V\setminus \{0\}$ , the symmetric bilinear form $g_y$ on $V$ is positive definite, where $$\mathbf{g}_y (u,v):= \frac{1}{2}\frac{\partial^2}{\partial s \partial t}\bigg[ F^2(y+su+tv)\bigg] \biggr\rvert_{s=t=0}$$ A Randers norm on $V$ is defined as $R(y):=\alpha(y)+\beta(y)$ where $\alpha$ is the Euclidean norm and $\beta$ is a linear form. I am confused about how to show that the Randers norm satisfies the Minkowski norm's third condition. I think my confusion stems from unfamiliarity with Einstein tensor notation. The text's proof proceeds by fixing a basis $\{\mathbf{b}_i\}_{i=1}^n$ for $V$ and computing $$g_{ij}:= \mathbf{g}_y (\mathbf{b}_i\mathbf{b}_j)=\frac{1}{2}[F^2]_{y^{i}y^{j}}(y)$$ to be $$g_{ij} = \frac{F}{\alpha}\left(a_{ij}-\frac{y_i}{\alpha}\frac{y_j}{\alpha}\right)+\left(\frac{y_i}{\alpha}+b_i\right)\left(\frac{y_i}{\alpha}+b_j\right)$$ Any attempt to walk through/clarify this step is appreciated. Also, insight into why $\Vert\beta\Vert<1$ ensures the above is positive definite is desired. I gathered from context that when the index is in the upper position, we have a row vector instead of a column vector, but I'm missing a lot on how to actually perform the computations.","['finsler-geometry', 'normed-spaces', 'metric-spaces', 'differential-geometry']"
4322292,Proofs with strong approximation theorem,"I am stuck on some proofs concerning strong approximation in Chapter 3.1 of Hida's book on modular forms. I have put in green the things that I do not understand. The set $gL\subset \mathbb{A}^\infty$ is a (free) module over $\widehat{\mathbb{Z}}$ . But why can we assume that its basis vectors are in $\mathbb{Q}^n$ ? I think that it has something to do with the identity $\mathbb{A}^\infty=\mathbb{Q}+\widehat{\mathbb{Z}}$ , but I do not see in what way? We have $s,g\in GL_n(\mathbb{A}^\infty)$ and $X\in GL_n(\mathbb{Q})$ (why again? this has to do with the previous proof). Then $s^{-1}g^{-1}X$ surely is in $SL_n(\mathbb{A}^\infty)$ , but why is it suddenly in $SL_n(\widehat{\mathbb{Z}})$ ? Any help is much appreciated.","['algebraic-number-theory', 'number-theory', 'profinite-groups', 'adeles', 'modular-forms']"
4322406,A formula for the second Chern class of the tensor product of a line bundle and vector bundle,"If possible I would like someone to prove or suggest a place to see the proof of this relation : $$c_2(V \otimes L)=c_2(V)+(r−1)c_1(V)c_1(L)+ {r \choose 2} c_1(L)^2$$ Here $L$ is the line bundle and $r$ is the rank of the vector bundle $V$ . The reference that is mentioned in the link is not freely available... What I need in reality is only to express this relation for the $r=2$ case, that is, to show that $c_2(V \otimes L)=c_2(V)+c_1(V)c_1(L)+ c_1(L)^2$ . I know the relation the relation $c_1(V \otimes L)=rc_1(L) + c_1(V)$ and that the total chern class satisfies $c(E)= 1 + c_1(E) +... +c_n(E)$ , and that $c(V \otimes L)=\prod_j (1 + c_1(L_j') + c_1(L))$ if we assume that $V= \oplus_{j=1}^r L_j'$ . However, this relations do not seem to suffice to prove what I want. Thanks in advance!","['vector-bundles', 'algebraic-geometry', 'manifolds', 'intersection-theory', 'characteristic-classes']"
4322508,Triviality of a tautological bundle,"I am trying to solve the following exercise. What I know: $\tau$ is a vector bundle of dimension $n$ over $\mathbb{R}P^n$ . The same is true for the trivial bundle $\mathbb{R}P^n \times \mathbb{R}^n$ . Then we find surjective smooth maps $$
\pi: \tau \to \mathbb{R}P^n \\
\tilde{\pi}:\mathbb{R}P^n \times \mathbb{R}^n \to \mathbb{R}P^n
$$ such that for each $[p] \in \mathbb{R}P^n$ the fibers $$
E_{[p]}=\pi^{-1}(\{[p]\})         \\
\tilde{E}_{[p]}=\pi^{-1}(\{[p]\})
$$ come with the structure of a k-dimensional real vector space. Moreover, we find open sets $U,\tilde{U}$ of $\mathbb{R}P^n$ and diffeomorphisms $$
\varphi: \pi^{-1}(U) \to U \times \mathbb{R}^k 
$$ $$
\tilde{\varphi}: \tilde{\pi}^{-1}(\tilde{U}) \to \tilde{U} \times \mathbb{R}^n 
$$ such that $$
\pi_n \circ \varphi=\pi \\
\tilde{\pi}_n \circ \tilde{\varphi}=\tilde{\pi} 
$$ where $$
\pi_n: U \times \mathbb{R}^n \to U, ([p],v) \mapsto [p] \\
\tilde{\pi}_n: \tilde{U} \times \mathbb{R}^n \to \tilde{U}, 
([p],v) \mapsto [p]. 
$$ In particular the maps $$
\pi_{\mathbb{R}^n} \circ \varphi_{E[p]}: E_{[p]} \to \mathbb{R}^n \tag{1}
$$ $$
\pi_{\mathbb{R}^n} \circ \tilde{\varphi_{E[p]}}: \tilde{E}_{[p]} \to \mathbb{R}^n \tag{2}
$$ are vector space isomorphisms. Now suppose the claim is true. Then there is a diffeomorphism $\phi: \tau \to \mathbb{R}P^n \times \mathbb{R}^n$ such that $\tilde{\pi} \circ \phi=\pi$ and for each $[p] \in \mathbb{R}P^n$ the map $\phi |_{E_{[p]}}: E_{[p]} \to \tilde{E}_{[p]}$ is a vector space isomorphism.
Then there is a section $f: \mathbb{R}P^n \to \tau, [p] \mapsto f_{[p]}$ that vanishes nowhere. But I am a bit at a loss about how to find a contradiction.",['differential-geometry']
4322511,Prove that the intersection have infinite elements,"I want to prove this theorem, and I made a proof but I want to know your opinion... Theorem: Let $A \subset \mathbb{R}$ , where $A\neq \emptyset$ , and $S=sup (A)$ . Prove that if $S\notin A$ , then $\forall \delta>0$ the set $A \cap (S-\delta,S)$ have infinite elements. My proof: First I'm going to prove that the intersection $A \cap (S-\delta,S) \neq \emptyset$ , let's proceed by contradiction... Suppose that $A \cap (S-\delta,S) = \emptyset$ then there exists an $\alpha \in (S-\delta,S)$ s.t $\alpha \notin A$ , then it satisfies that $a<\alpha<S, \forall a \in A$ , this is a CONTRADICTION, because $S$ is the smallest upper bound (by the fact is the sup) and I found a smaller upper bound... Then the intersection is non empty... Now I'm going to prove that $A \cap (S-\delta,S)$ have infinite elements proceeding by contradiction... Let's suppose that the intersection have a finite amount of elements, let's say $n$ , all this elements are going to be labeled with $a_i$ with $i=1,...,n$ ordered from the smallest to the biggest one like: $a_1<a_2<...<a_n$ , then it's clear that $a \leq a_n<S$ for all $a\in A$ , this means that $a_n$ is the smallest upper bound of A, then $a_n$ is the $sup(A)$ , and $a_n \in A$ , this is a CONTRADICTION to the fact that $S$ is the $sup(A)$ and that $S \notin A$ , then we get what we were looking for. This is my proof... What's your opinion?","['elementary-set-theory', 'calculus', 'supremum-and-infimum']"
4322520,Is there something wrong with this question concerning Groups,"We consider the group $G = SL(2, 3) $ i.e, the set of $2 \times2$ matrices with determinant 1 and addition and multiplication are performed modulo 3 even in the determinant formula. One can show that $|G| = 24$ a) Let $\alpha = \begin{pmatrix}
2 & 2\\
2 & 1
\end{pmatrix}$ show that $\alpha \in G$ and find its inverse $\alpha^{-1}$ . b) Let
H = { $ \begin{pmatrix}
a & b\\
0 & a
\end{pmatrix} $ where a, b $\in$ {0,1,2}, a $\neq 0$ }.
Show that H is a subgroup and find a familiar group that is Isomorphic to H. c) The subgroup H contains two elements of order 3. Find 8 elements of order 3 in G. HINT : H only contains upper triangular matrices; also use conjugation. It's trivial to show H $\leq$ G and I found it's Isomorphic to $D_{6}$ . It's the last part I have found issues in my understanding. I wrote out all the elements of H: $ \begin{pmatrix} 1 & 0\\ 0 & 1 \end{pmatrix}$ $ \begin{pmatrix} 2 & 0\\0 & 2 \end{pmatrix} $ $ \begin{pmatrix} 2 & 1\\0 & 2 \end{pmatrix} $ $ \begin{pmatrix} 2 & 2\\0 & 2 \end{pmatrix} $ $ \begin{pmatrix} 1 & 1\\0 & 1 \end{pmatrix} $ $ \begin{pmatrix} 1 & 2\\0 & 1 \end{pmatrix} $ Four of these have an order of 3. Not just two of them. Or is my understanding off?","['matrices', 'group-theory', 'finite-groups', 'inverse']"
4322543,entropy of skew product,"Let $Y$ be a compact abelian group and let $m$ be the haar measure.  Suppose that $f:X \to Y$ is measurable and let $T:X \to X$ be an invertible measure preserving transformation.  Show that the entropy of $\tau(x,y)=(T(x),y+f(x))$ is equal to $h(T)$ . I know that for skew products $(T(x),S_xy)$ the entropy is equal to $h(T)+h_T(S)$ where $h_T(S)$ is the fiber entropy.  Here $S_xy=y+f(x)$ .  My initial thought is to estimate the sizes of the partitions $\beta_1^n(x)=S_{x}^{-1} \beta \vee S_{x}^{-1}S_{Tx}^{-1} \vee \dots \vee S_{x}^{-1} \dots S_{T^{n-1}x}^{-1} \beta$ and show that it must be bounded by $Kn$ .  Then $h_T(\beta,S)=\lim_{n \to \infty} \frac{1}{n}\int_X H( \beta_0^n(x)) \to 0$ .","['measure-theory', 'ergodic-theory', 'real-analysis', 'probability', 'dynamical-systems']"
4322564,Components in the complement of compact subset in manifold,"Let $M$ be a (smooth) connected manifold and $K \subset M$ a compact subset. Then $M \setminus K$ consists of a number of components. Let $(U_j)_{j \in \mathcal J}$ be the collection of bounded components in $M \setminus K$, i.e, the components with compact closure in $M$. I wonder if its true that the set $U:=\bigcup_{j \in \mathcal J} U_j$ is again a bounded subset of $M$. Some thoughts I have made so far: It is clear that $M \setminus K$ may have an infinite, even uncountable number of bounded components, so one can't argue that $U$ is bounded because it is the finite union of bounded subsets. Also, the fact that $K$ is compact obviously plays a big role. I attempted to argue by contradiction: Suppose that $U$ was unbounded. Then $U$ cannot be contained in any compact connected subset of $M$. Somehow, I feel this should also imply that $K$ cannot be contained in any compact connected subset of $M$, which is a condradiction. But I am not sure how to make that last step.","['manifolds', 'general-topology']"
4322613,"Show $f:\mathbb{R}^2 \rightarrow \mathbb{R}^{2}, f(x,y) = (x-y, x^2-y^2)$ [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Show $f:\mathbb{R}^2 \rightarrow \mathbb{R}^{2}, f(x,y) = (x-y, x^2-y^2)$ is a bijection This is my try $f$ is injective if $$ (a,b) \neq (x,y) \rightarrow f(a,b) \neq f(x,y)$$ If $$f(x,y)=f(a,b) = a \qquad \forall a,b,x,y\in \mathbb{R}^{2}$$ Therefore is not injective For the surjective $f$ is surjective if $$Im(f)= \mathbb{R}^2 \quad \forall a, b \in \mathbb{R}^{2} \in (x,y) \in \mathbb{R}^{2}: (a,b) = f(x,y)$$ Please someone guide me to the correct solution.","['calculus', 'functions']"
4322633,Would this order of operations proposal be effective?,"Let ~ be a function from R2 to R.
Let x (~) y =  ~(x,y).
Let priority(P) be a function that maps functions (R2 to R) to integers.
Set P(+) = 1, P(*) = 2, P(^)=3 An expression that follows the order of operations is an expression that evaluates subexpressions with the highest priority before evaluating any other subexpression. An expression is well-ordered iff the expression follows the order of operations and
for each subexpressions that contain a function with a priority k, the subexpressions are evaluated from left to right. ie 4^3^2 = 262,144 contains an expression, 4^3^2, that follows the order of operations but is not well-ordered since 4^3^2 != (4^3)^2. I couldn't find a better standard than what I saw on Wikipedia. So I don't know if there is a better standard that already exists. I've seen too many memes on reddit of 6÷2(2+1) that I thought it'd be nice to have a reference against claims that 6÷2(2+1)=1.",['functions']
4322640,"Find $P(\max_{[0,h]}|W(s)|\geq x, W(h)\leq y$ where $W(t)$ is a standard Weiner process","I came across a question asking to prove $P(\max_{[0,h]}|W(s)+\mu s|\geq x)=o(h)$ . The question is easy, but I want to find the value.
The way I choose is by Girsanov's theorem $$P(\max_{[0,h]}|W(s)+\mu s|\geq x)=E(1_{(\max_{[0,h]}|W(s)|\geq x)} e^{\mu B(h)-\frac{1}{2}\mu^2 h}) \\
=\int_{y=-\infty}^\infty e^{\mu y-\frac{1}{2}\mu^2 h} dP(\max_{[0,h]}|W(s)|\geq x, B(h)\leq y)
$$ For $|y|\geq x$ , the probability can be found simply by reflection. But the $|y|\leq x$ , the probability seems quite hard to evaluate, to begin with, I choose to divide it. $$P(\max_{[0,h]}|W(s)|\geq x, B(h)\leq y) \\
=P(\max_{[0,h]}W(s)\geq x, B(h)\leq y)+P(\max_{[0,h]}-W(s)\geq x, B(h)\leq y)-
P(\max_{[0,h]}W(s)\geq x, \max_{[0,h]}-W(s)\geq x, B(h)\leq y)
$$ The first two term can still be found by reflection, while the third term can't. The reason for not applying reflection method is that I don't know which of the two cases $\max_{[0,h]}W(s)\geq x, \max_{[0,h]}-W(s)\geq x$ happens first. Actually evaluating $\frac{d}{dy}P(\max_{[0,h]}|W(s)|\geq x, B(h)\leq y)$ is enough for the calculate to continue. Thanks in advance.","['stochastic-processes', 'brownian-motion', 'probability-theory']"
4322650,Volume of a Riemannian manifold with a scaled metric,"I'm confused with the volume of an n-dimensional Riemannian manifold with a scaled metric. Specifically, let $M$ be a Riemannian manifold with Riemannian metric $g$ and its volume denoted by $vol_g(M)$ . If we endow $M$ with another metric $$\widetilde{g}=\lambda g,\qquad \text{here $\lambda$ is a positive smooth function on $M$}$$ then, how about the volume $vol_{\widetilde{g}}(M)$ of with respect to $\widetilde{g}$ ? I know that the volume form $$dv_{g}=\sqrt{\det\ g}\ dx^1\wedge\cdots \wedge dx^n .$$ So I guess that $$dv_{\widetilde{g}}=\lambda^{n/2}dv_{g}, $$ and therefore $$vol_{\widetilde{g}}(M)=\lambda^{n/2}vol_g(M) .$$ Do you think it is right? If not, how do we to calculate the volume $vol_{\widetilde{g}}(M)$ and figure out the relationship with $vol_g(M)$ ? Thanks in advance!","['conformal-geometry', 'riemannian-geometry', 'differential-geometry']"
4322756,"bounded variation functions on $[0,1]$ are always $L_2[0,1]$?","My question is $BV[0,1] \subset L_2[0,1]$ or not. My own answer (not sure correct): $f \in BV[0,1]$ implies that removing discontinuity, we have continuous function $\tilde{f}$ such that \begin{align*}
BV(f) = const + \int_{[0,1]} |\tilde{f}(x)|dx < \infty,
\end{align*} where the constant is from discontinuity. As discontinuities have Lesbesgue measure zero, it is sufficient to show $\tilde{f}$ is square integrable. But since $L_2[0,1] \subset L_1[0,1]$ , we can find some $\tilde{f}$ that is NOT square-integrable. Is it right?","['bounded-variation', 'lp-spaces', 'functional-analysis', 'real-analysis']"
4322822,Differential Equation to Model Temperature of Water,"Question The water in a hot-water tank cools at a rate which is proportional to $T − T_0$ , where $T$ is the temperature of the water in degrees celcius at time $t$ minutes and $T_0$ is the temperature
of the surrounding air in degrees celcius. When $T = 60$ , the water is cooling at $1$ celcius per minute. When
switched on, the heater supplies sufficient heat to raise the water temperature by $2$ degrees celcius
each minute (neglecting heat loss by cooling). If $T = 20$ when the heater is switched on
and $T_0$ = 20. Find the differential equation $\frac{dT}{dt}$ (Where both heating and cooling are taking place). So the temperature leaving the water is leaving at a rate of $\frac{dT_{out}}{dt}=k(T-T_0)$ for some constant $k$ . We can find $k$ by letting $T=60$ , $T_0=20$ and $\frac{dT_{out}}{dt}=-1$ . I assumed here that the air temperature is staying constant at $20$ as I'm thinking that is what the last scentence of the question implied but it is hard to tell. From this I found that $\frac{dT_{out}}{dt}=\frac{20-T}{40}$ It was given that $\frac{dT_{in}}{dt}=2$ so the overall temperature must be: $$\frac{dT}{dt}=\frac{dT_{in}}{dt}-\frac{dT_{out}}{dt}$$ $$\frac{dT}{dt}=\frac{60+T}{40}$$ However, the answer should be $\frac{dT}{dt}=\frac{100-T}{40}$ . Please let me know where I went wrong. Thanks.",['ordinary-differential-equations']
4322842,Simple proof about prime filters.,"Exercise. Let $F$ be an true filter in a set $X$ . Show that $F$ is an ultrafilter ( $\Leftrightarrow$ prime) iff a subset of $X$ intersects every set of $F$ then this same subset is in $F$ . UPDATE. My attempt. $(\Rightarrow)$ Suppose $F$ is an ultrafilter. Then, we have that $A,B \in F \Rightarrow A \cap B \in F$ and $A \in F, A \subseteq B \Rightarrow B \in F$ by definition of a filter. Let $S \subset X$ s.t. $S \cap A \neq \emptyset$ , $\forall A \in F$ . This guarantees that there is another filter $F'$ s.t. $F \subseteq F'$ and $S \in F'$ , but $F$ is maximal and thus $F=F'$ , meaning $S \in F$ , proving what's wanted. $(\Leftarrow)$ Suppose now that the second condition is verified for every subset $S$ of $X$ . By the same reasoning as before, we can guarantee that there exists a filter $F'$ s.t. $F \subseteq F'$ and $S \in F'$ . If we show that $F=F'$ we have that $F$ is maximal, and that's what we want. Let's assume that $F \neq F'$ , i.e., that there is a set $Z$ such that $Z \in F'$ and $Z \notin F$ . Then we have: $(X\backslash Z)\cup Z = X \in F$ ( $F$ is a filter). But this is equivalent to saying that $X\backslash Z \in F \vee Z \in F$ but $Z \notin F$ and thus $X \backslash Z \in F \Rightarrow X\backslash Z \in F'\Rightarrow Z \notin F'$ which is a contradiction. Thus $F=F'$ e so $F$ is maximal. Is this formulation right? I have some issues understanding this basic concepts about filters and some of my proofs go wrong because of it. Thanks for all the help in advance.","['elementary-set-theory', 'filters']"
4322875,Generalization the time elapsed in Poisson Process,"Suppose that people immigrate into a territory at a Poisson rate λ = 1 per day. What is the probability that the elapsed time between the fourth and the sixth arrival exceeds two days, and What is the expected arrival time of the tenth immigrant given that exactly two immigrants arrived before and including the fifth day? For the first part, I write $$ \begin {align}
&\mathbb P\{T_5 + T_6 >2\} 
\\
&= \mathbb P\{T_5>2\}\mathbb P\{T_6>0\}+\mathbb P\{T_5>0\}\mathbb P\{T_6>2\} + \mathbb P\{T_5 > 1 \} \mathbb P\{T_6 >1\} 
\\
&= e^{-2} + e^{-2} + 2e^{-1}
\end {align}
$$ And the second part, my approach is: $$
\begin {align}
& \mathbb E[S_{10} | S_{5}=2]
\\&= \mathbb E[S_{10} | S_5 = 2]\mathbb P\{S_5=2\}
\end {align}
$$ I know that $\mathbb P\{S_5 = 2\}$ is nothing but a poisson with mean 5. But I have no idea on obtaining $E[S_5 = 8]$ . I have taken reference on Poisson process. Time between two events. But this post is related to 2 event only but not 3, I wondering that can I generalize it as well.","['expected-value', 'stochastic-processes', 'poisson-process', 'probability-theory', 'probability']"
4322906,Probability of passing a T/F exam?,"There are $n$ questions in an examination ( $n \in \mathbb{N}$ ), and the answer to each question is True or False. You know that exactly $t$ of the answers are True ( $0 \le t \le n$ ), so you randomly answer $t$ questions as True and the rest as False. What is your probability of getting at least a $50\%$ score in the exam (in terms of $n$ and $t$ )? My attempt: WLOG assume you answer the first $t$ questions as True. Let there be $k$ questions out of the first $t$ of which the answer is True. Thus, out of the other $n-t$ questions where you replied False, $(n-t)-(t-k)=n-2t+k$ questions are really False. Thus, the fraction of correct answers for the whole examination is equal to $\frac{n-2t+2k}{n}$ . If this is at least $1/2$ , then $n+2k \ge 4t$ . However, I can't calculate the probability of this happening.","['random', 'probability']"
4322926,Torus is the only closed orientable surface regularly covered by punctured plane,"Let $\Sigma_g$ be the closed orientable surface of genus $g$ . There is no covering map $p\colon\Bbb R^2\backslash \mathbf 0\to \Sigma_g$ so that $p_*\pi_1(\Bbb R^2\backslash \mathbf 0)$ is a normal subgroup
of $\pi_1(\Sigma_g)$ when $g\geq 2$ . In other words, the fundamental group of any
closed orientable hyperbolic surface has no normal infinite cyclic subgroup. Attempt: Suppose, we have a normal covering $\Bbb R^2\backslash \mathbf 0\to \Sigma_g$ , where $g\geq 2$ . So, there is an infinite cyclic normal subgroup of $\pi_1(\Sigma_g)$ . In other words, we have non-trivial elements $a,b\in \pi_1(\Sigma_g)$ such that $bab^{-1}=a^n$ for some integer $n$ . Consider the subgroup $G$ of $\pi_1(\Sigma_g)$ generated by $a,b$ and let $X\to \Sigma_g$ be the covering corresponding to the subgroup $G$ of $\pi_1(\Sigma_g)$ . Note that $X$ is an orientable surface as $\Sigma_g$ is an orientable surface. Also, $\pi_1(X)=G$ . $\textbf{Case 1:}$ Let $X$ be compact. From classification theory $X\cong \Sigma_h$ for some $h\geq 0$ . So, the covering will be finite-fold, say $m$ -fold, and then $2-2h=\chi(X)=m\cdot \chi(\Sigma_g)=m(2-2g)$ , i.e., $1+m(g-1)=h$ , i.e. $h\geq 2$ . In other words, $\pi_1(\Sigma_h)=G$ is generated by two elements, in particular, $\Bbb Z^{2h}\cong \frac{G}{[G,G]}$ is also generated by two elements when $h\geq 2$ , a contradiction. So, this case is impossible. $\textbf{Case 2:}$ Let $X$ be non-compact. Hence, $\pi_1(X)=G$ is a free group. Also, from hypothesis, $G$ is generated by $a,b$ such that $bab^{-1}=a^n\implies a=(b^{-1}ab)^n$ . ........ Now, if I show that the problem can be started by assuming that $a$ is not a proper power of some element, then $a=(b^{-1}ab)^n$ gives $n=\pm 1$ . When $n=1$ we have $ab=ba$ , and in a free group, if two non-trivial elements commute, then they are powers of some common element, i.e., $a=b^{\pm 1}$ as $a$ is not a proper power of any element, and this ends up with giving that every element of $\pi_1(\Sigma_g)$ is a power of $a$ , impossible. But I don't know how to tackle the case $n=-1$ , also how to show the
problem can be started by assuming $a$ is not a proper power of any
element.","['geometric-topology', 'free-groups', 'covering-spaces', 'group-theory', 'algebraic-topology']"
4322932,A set of orthogonal circles passing through two points,"This is related to my previous problem: Relation between incentre of a triangle and a circle touching its two sides and circumcircle , where I have found an answer but stuck at the following fact. Given two orthogonal circles ( $c$ and $d$ ) draw a line passing through the centre of one circle $(O)$ and intersecting the other circle at points $A$ and $B$ . Any circle passing through $A$ and $B$ is orthogonal to $\odot O$ . I believe this is a well-known property (not known to me). Is there any specific theorem which states this? Or do you have a proof?","['euclidean-geometry', 'circles', 'geometry', 'plane-geometry']"
4322990,Differentiability of $f(|x|)$,"What are the rules for the differentiability of $f(|x|)$ ? In hindsight, and upon inspecting $\sin(|x|)$ and $\cos(|x|)$ , the only rule I can deduce is that $f(x)$ should not be zero at $x=0$ . But I couldn't get any polynomials for which my rule applies. So is $\cos(|x|)$ , the only possible function where $f(x)$ is differentiable at $x=0$ or are there any other polynomials too?","['trigonometry', 'derivatives', 'polynomials']"
4323003,"Maximum of $ F(f)=\int_0^1 |f(x)|^2\; dx-\left(\int_0^1 f(x)\; dx\right)^2 $ over a subset of continuous functions on $[0,1]$","Let $X$ be a subset of $C([0,1])$ with $$
X=\big\{f\in C([0,1]): 0\le f(x)\le x,\text{$f$ is a polynomial}\big\}
$$ where $C([0,1])$ denotes the space of continuous real-valued functions on $[0,1]$ . Define a nonlinear functional $F$ on $C([0,1])$ as $$
F(f)=\int_0^1 |f(x)|^2\; dx-\left(\int_0^1 f(x)\; dx\right)^2
$$ Can $F$ achieve a maximum in the set $X$ ? Remarks. If one restricts the set to the linear functions $f$ of the form $f(x)=kx$ with $0\le k\le 1$ , then this reduces to a min/max problem for values of $k$ : $$
F(f) = \int_0^1 (kx)^2\;dx-\left(\int_0^1kx\;dx\right)^2=\frac{k^2}{3}-\frac{k^2}{4} = \frac{k^2}{12}
$$ So the maximum is achieved at $f(x)=x$ for the restriction. One could also restrict the functions to be parabolas of the form $f(x)=kx^2$ with $k\in[0,1]$ , and get $$
F(f)=\frac{k^2}{5}-\frac{k^2}{9}=\frac{4k^2}{45},
$$ where the maximum is achieved at $f(x)=x^2$ . If one allows one more parameter and consider $f(x)=kx^m$ , then $$
F(f)=k^2\cdot \left(\frac{1}{2m+1}-\frac{1}{(m+1)^2}\right)=\frac{k^2m^2}{(2m+1)(m+1)^2}\;.
$$ Then one can study the maximum of $g(m)=\frac{m^2}{(2m+1)(m+1)^2}$ over positive integers $m$ . But this is far from analyzing all the polynomials in $X$ . Another observation is that the functional can be written as $F(f)=\|f\|_{L^2}^2-\|f\|_{L^1}^2$ . But this seems not helpful at all. This question was motivated by this unanswered question on the site. I was curious and attempted to solve that one but I didn't get anything. So I restrict the attention to the set of polynomials here.","['nonlinear-analysis', 'analysis', 'real-analysis', 'maxima-minima', 'optimization']"
4323010,A random walk martingale where $P(Y_n = \pm 1) = 0.5$ and $X_n = \sum_{j=1}^n a_j Y_j$ where $\{a_n\} \subset \mathbb{R}_+$ is non-increasing,"I pulled this question from an old set of lecture notes. It goes as follows: Suppose $Y_n$ are i.i.d random variables on a probability space $(\Omega, \mathcal{F}, P)$ such that $P(Y_n = \pm 1) = \frac{1}{2}$ and $X_n = \sum_{j=1}^n a_j Y_j$ where $\{a_n\} \subset \mathbb{R}_+$ is non-increasing (i.e. a positive real-valued non-increasing sequence). Show the following: a) If $\sum_{j=1}^\infty a_j < \infty$ , then there exists $X \in L^2$ such that $X_n \to X$ almost surely and in $L^2$ . b) Now suppose there exists a real-valued $X$ . Show that $\sum_{j=1}^\infty a_j < \infty$ and, hence there exists an $X \in L^2$ such that $X_n \to X$ (Hint: consider $e^{X_n}$ ). I understand how to do part a), mainly by showing that $X_n$ is a martingale with respect to the natural filtration $\mathcal{F}_n = \sigma(Y_1, Y_2, \ldots, Y_n)$ . Next, by showing $\text{sup}_{n \in N} E[X_n^2] < \infty$ , we get the result from one of the martingale convergence theorems. My problem is I don't understand what b) is asking for. The question wording to me is strange, and I'm not sure what it is asking me to solve. These old notes are prone to some big typos, so I thought I would see if anyone perhaps could see what was being asked here. If you have any thoughts/corrections, I would appreciate hearing them.","['martingales', 'measure-theory', 'probability-theory']"
4323068,A question about finite group acting on inputs and outputs of maps between vector spaces.,"I'm reading this paper and considering the following notations/definitions: Let $G$ be a finite group, $V,W$ finite dimensional vector spaces and consider two maps $\phi:V \rightarrow \mathbb{R}$ , $\Phi:V \rightarrow W$ . Now we define: $$\begin{align}
\psi(X) &:= \frac{1}{|G|}\sum_{g \in G}\phi(g^{-1} \cdot X) \\ \Psi(X) &:= \frac{1}{|G|}\sum_{g \in G}g \cdot \Phi(g^{-1} \cdot X),
\end{align}$$ where $\cdot$ denotes a group action, $X \subset V$ . First question : Why do we take the inverse of $g$ to act on the set $X$ ? As far as I'm concerned (but not 100% sure), this should be arbitrary, because if $x \mapsto gx$ is a left action, then $x \mapsto xg^{-1}$ is a right
action. if $x \mapsto xg$ is a right action, then $x \mapsto g^{-1}x$ is a left
action. So for example, I could modify the above definitions saying that $\phi(g \cdot X)$ is the left action, while $\phi(X\cdot g^{-1})$ would be the right one. Second Question : Given that we assume $g^{-1}$ for the left action, why do we need to take $g$ to act on the output $\Phi(\cdot)$ ?","['group-theory', 'group-actions', 'finite-groups', 'vector-spaces']"
4323094,"Understanding $\lim\limits_{m(B) \rightarrow 0, x \in B}$ (Lebesgue Differentiation)","My question concerns the following excerpt from section 3.1 (Differentiation of the Lebesgue Integral) of Stein and Shakarchi's Real Analysis : Suppose $f$ is integrable on $\mathbb{R}^d$ . Is it true that $$\lim\limits_{m(B) \rightarrow 0 \\ x \in B} \frac{1}{m(B)} \int_B f(y) \,dy = f(x), \quad \text{for a.e. } x?\label{1}\tag{$\ast$} $$ The limit is taken as the volume of open balls $B$ containing $x$ goes to $0$ . My question is: what is the precise meaning of $\lim\limits_{m(B) \rightarrow 0, \, x \in B}$ ? I am familiar with the following notions of limits: If $(a_n)_{n=1}^{\infty}$ is a sequence, then  "" $\lim\limits_{n \to \infty} a_n = a$ "" means: for each $\epsilon > 0$ , there exists some $N \in \mathbb{N}$ such that $|a_n - a| < \epsilon$ whenever $n \geq N$ . If $f: \mathbb{R}^d \rightarrow \mathbb{R}$ , then "" $\lim\limits_{x \rightarrow x_0} f(x) = y$ "" means: for each $\epsilon > 0$ , there is some $\delta > 0$ such that $|f(x) - y| < \epsilon$ whenever $\|x - x_0\| < \delta$ . But \eqref{1} does not seem to match either of the above notions of a limit. My best guess is that \eqref{1} means something like the following: $$\lim_{n \to \infty} \frac{1}{m(B_n)} \int_{B_n} f(y)\,dy = f(x) \quad \text{for a.e. } x$$ for every sequence of balls $\{B_n\}_{n=1}^{\infty}$ satisfying (1) $\lim\limits_{n \to \infty} m(B_n) = 0$ , and (2) $x \in B_n$ for all $n$ ...Is this correct?","['lebesgue-integral', 'analysis', 'real-analysis', 'calculus', 'derivatives']"
4323155,Finding an operator norm in Hilbert space,"Let H be Hilbert with an orthonormal basis $(e_n)_n$ . Let $(a_{ij})_{ij}$ , $i,j\geq 1
$ such that $$\sum_{i=1}^\infty \sum_{ j=1}^\infty a_{ij} ^2<\infty.$$ Show there exists a bounded linear operator $T:H\to H$ such that $(Te_j,e_i)=a_{ij}$ and compute the operator norm $\|T\|$ I have defined $$Tx=  \sum_{i=1}^\infty (x, e_i) T e_i=   \sum_{j=1}^\infty  \Big(\sum_{i=1}^\infty (T e_i, e_j) (x, e_i) \Big) e_j=  \sum_{j=1}^\infty  \Big(\sum_{i=1}^\infty a_{ij} (x, e_i) \Big) e_j$$ By Parseval and Cauchy-Schwarz inequality $$\|Tx\|^2=	\sum_{j=1}^\infty  \Big|\sum_{i=1}^\infty a_{ij} (x, e_i)\Big|^2\leq \big(\sum_{i=1}^\infty |(x, e_i)|^2 \big)\big( \sum_{j=1}^\infty \sum_{i=1}^\infty a^2_{ij}\big) = \|x\|^2 \big( \sum_{j=1}^\infty \sum_{i=1}^\infty a^2_{ij}\big). $$ From this it follows that $T$ is bounded and we have $$\|T\|\leq \Big( \sum_{j=1}^\infty \sum_{i=1}^\infty a^2_{ij}\Big)^{1/2}. $$ Is it possible to show that $$\|T\|\geq \Big( \sum_{j=1}^\infty \sum_{i=1}^\infty a^2_{ij}\Big)^{1/2}?$$ Or How to compute $\|T\|$ ?","['matrices', 'operator-theory', 'hilbert-spaces', 'functional-analysis']"
4323192,Show that $P(C)=P(A\cup B)P(C\mid A)-P(A\cap B)P(C'\mid A)$,"Let $A,B,$ and $C$ be events defined in the samplespace $S$ , where $(A\cup B\cup C)\cap D=\emptyset$ and $ D\neq\emptyset$ $C \subset (A\cup B)$ and $C\cap A\cap B = A\cap B$ $A\cap B\neq \emptyset$ and $A\cap C\neq \emptyset$ and $B\cap C\neq \emptyset$ $P(C\mid A)=P(C\mid B)$ Draw the events in a Venn Diagram. Explain why $D$ and $E=A\cup B\cup C$ are disjoint. I have scetched a Venn Diagram like so: Explanation: Since we are given that $(A\cup B\cup C)\cap D=\emptyset$ , we know that $D$ and $E$ are disjoint, since $D\cup E=\emptyset\Rightarrow D$ and $E$ are disjoint! Now comes the part I'm having trouble with: Show that $P(C)=P(A\cup B)P(C\mid A)-P(A\cap B)P(C'\mid A)$ I started off with \begin{align*}
  & P(A\cup B\cup C)=P(A)+P(B)+P(C)-P(A\cap B)-P(A\cap C)-P(B\cap C)+P(A\cap B\cap C) \\
  & P(C) = P(A\cup B\cup C)-P(A)-P(B)+P(A\cap B)+P(A\cap C)+P(B\cap C)-P(A\cap B\cap C) \\
  & P(C) = P(A\cup B\cup C)-P(A)-P(B)+P(A\cap B)+P(A\cap C)+P(B\cap C)-P(A\cap B) \\
\end{align*} (since we're given that $P(C\cap A\cap B) = P(A\cap B))$ ) \begin{align*}
& P(C) = P(A\cup B\cup C)-P(A)-P(B)+\(\cancel{P(A\cap B)}\)+P(A\cap C)+P(B\cap C)-\(\cancel{P(A\cap B)}\) \\
& P(C) = P(A\cup B\cup C)-P(A)-P(B)+P(A)+P(B)\\
& P(C) = P(A\cup B\cup C) \\
\end{align*} This is where I got stuck, then I thought I'd try something different: \begin{align*}
& P(C) = P(A\cup B\cup C)-P(A)-P(B)+P(A\cap B)+P(A\cap C)+P(B\cap C)-P(A\cap B) \\
& P(C) = P(A\cup B\cup C)-P(A)-P(B)+P(A\cap B)+P(A)+P(B)-P(A\cap B)\\
& P(C) = P(A\cup B\cup C)-P(A)-P(B)+P(A\cap B)+P(A\cup B) \\
\end{align*} But I got stuck here as well. I tried to look at this question, but I didn't understand how to apply it to this exercise. How do I prove this? All help is appreciated!","['statistics', 'solution-verification', 'probability']"
4323208,"Does order of integration matter, while integrating over a cone?","Suppose I want to find the center of mass of a cone, from its vertex. It is a right circular solid cone of radius $a$ . About the $z$ axis, the center of mass is given by : $$z_{com}=\frac{\int dm\,z}{\int dm}$$ In cylindrical coordinates, let $dm=rdrd\phi dz$ Moreover, we know that for a cone, we have the following relation : $$\frac{z}{r}=\frac{h}{a}$$ Hence, I can have $z=\frac{hr}{a}$ or $r=\frac{az}{h}$ . Normally this is how we do the integral : $$\frac{\int_{0}^{h}\int_{0}^{\frac{az}{h}}rdrzdz}{\int_{0}^{h}\int_{0}^{\frac{az}{h}}rdrdz} = \frac{3h}{4}$$ (I've ignored the integral over the angle and the density, since that cancels out) Here, $r$ ranges from $0$ to $\frac{az}{h}$ . Then we integrate over $z$ from $0$ to $h$ .
However, I could have first integrated over $z$ and then integrated over $r$ - this should give me the same answer but it doesn't. In this case, $z$ should range from $\frac{hr}{a}$ , and then $r$ should range from $0$ to $a$ . Hence we would have : $$\frac{\int_{0}^{a}\int_{0}^{\frac{hr}{a}}zdz\,rdr}{\int_{0}^{a}\int_{0}^{\frac{hr}{a}}dz\,rdr} = \frac{3h}{8}$$ There is an extra factor of $1/2$ coming from somewhere. For some reason, the order of integration seems to matter here. However, how would one know which is the correct order, and why exactly does the order even matter ?","['integration', 'cylindrical-coordinates', 'definite-integrals', 'multivariable-calculus', 'multiple-integral']"
4323217,Non-trivial Examples of Surfaces of Voss,"Let $I$ and $J \subset \mathbb{R}$ be two intervals of the real line. A smooth parametrized immersed surface $\sigma: I\times J \rightarrow \mathbb{R}^3$ is called a surface of Voss if its coordinate curves satisfy the following conditions: They form a conjugate net (i.e. $\sigma_{uv} \in \textrm{span}\{\sigma_u, \sigma_v\}$ ), They are two one-parameter families of geodesics. I'm looking for non-trivial examples (non-developable surfaces) of this kind. I would be very much interested in a non-minimal example too. My Attempt: I know that there are ways of making them using their relation to a pseudospherical surface but all of them involve solving systems of PDEs and I wish to know if one has a ""relatively simple"" example of these surfaces.","['geodesic', 'surfaces', 'minimal-surfaces', 'examples-counterexamples', 'differential-geometry']"
4323260,What do you call a matrix of the form $\left(\begin{smallmatrix} a & -b \\ b & a \end{smallmatrix}\right)$?,"I'm reviewing a piece of python code that uses the term ""rotations"" for these matrices, but of course that's not quite accurate. What's a good, more accurate term of similar accessibility? Here are my candidates so far: scaling-and-rotation matrix : Clunky, but the best I've got right now. scaled rotation : Less clunky than the above. This term might sound like we're scaling the amount of rotation . conformal matrix : Technically correct, but far fewer people will understand the meaning compared to ""rotation matrix"". Also, it's a bit ingenuous since the term conformal prototypically refers to nonlinear maps that behave infinitesimally like these matrices. angle-preserving matrix : A more accessible form of conformal matrix . Less knowledgeable readers may be distracted trying to figure out which $2\times2$ matrices are angle-preserving. (Readers who understand the term conformal matrix will probably already know this.) [multiplication by a] complex number : Not as accessible as ""rotation"". Also a bit clunky since it identifies a complex number with its representation. sum of a scaling and antisymmetric matrix : Worst suggestion so far, especially since antisymmetric matrices don't show up anywhere in the code or code comments. Is there any standard, accessible term for such linear transformations? I'd also appreciate thoughts on whether I'm mistaken about how accessible and/or clunky the terms above are.","['matrices', 'linear-algebra', 'complex-numbers', 'terminology']"
4323291,Group of an Elliptic curve.,"In my algebraic geometry course I found the following problem: Let $E$ an elliptic curve over the field $\mathbb{F}_5$ given by the equation: $$y^2z=x^3+xz^2-z^3$$ Find the group asociated to $E$ . Doing some computations and with quadratic residues I found that $E$ has the following points: $$[0:1:0],[0:2:1],[0:3:1],[1:1:1],[1:4:1],[2:2:1],[2:3:1],[3:2:1],[3:3:1]$$ Thus the group asociated to $E$ has $9$ elements, so it must be either $C_9$ or $C_3\times C_3 $ . I thought that maybe we can compute the order of the elements to choose which of the groups is the solution, but it looks like a very long computational problem. My question is whether there is a more elegant solution avoiding all these computations or not. Thanks for your help :)","['group-theory', 'algebraic-geometry', 'elliptic-curves']"
4323371,How many four-digit positive integers are there that contain the digit $3$ and are divisible by $5$?,"How many four-digit positive integers are there that contain the digit $3$ and are divisible by $5$ ? The answer is: the  number of four-digit integers that are divisible by $5\;-\;$ the number of four-digit integers that are divisible by $5$ and not contain the digit $3$ So, $9\cdot10\cdot10\cdot2-8\cdot 9\cdot 9\cdot 2=1800-1296=504\tag{*}$ I know that, but when I tried to solve this problem with an other way I got a different result. Four digit integers : $\overline{xyzw}$ Suppose $\overline{xyzw}$ contain at least one digit equal $3$ So, $x = \{1, \ldots ,9\}, y = 3, z = \{0, \ldots, 9\}, w = \{0,5\}$ or $x = \{1, \ldots, 9\}, y = \{0, \ldots, 9\}, z = 3, w = \{0,5\}$ or $x = 3, y=\{0, \ldots, 9\}, z = \{0, \ldots, 9\}, w = \{0,5\}$ The number of all $\overline{xyzw}$ that must be divisible by $5$ and contain $3$ is: $9\cdot 10\cdot 2+9\cdot 10\cdot 2+10\cdot 10\cdot 2=180+180+200=560\tag{**}$ but (*) contradicts (**), so where is the mistake?","['algebra-precalculus', 'solution-verification', 'combinatorics']"
4323434,Duhamel's Principle Intuition,"I am trying to understand Duhamel's Principle by applying it to some simple problems.  I am thinking of $P(t)$ as expressing a bank account balance at time $t$ , to try to gain an intuition for Duhamel's Principle that doesn't depend on understanding physics. First I considered $P'(t) - \frac{1}{10}P(t) = \pi,\ P(0) = 0$ .  I started by solving $Q'(\tau) - \frac{1}{10}Q(\tau) = 0,\ Q(0) = \pi$ (swapping the forcing term and initial condition) and got the answer $Q(\tau) = \pi e^{\frac{1}{10}\tau}$ .  It appears that I can simply integrate this and produce the correct solution as $P(t) = \int_0^t \pi e^{\frac{1}{10}\tau} d\tau = 10\pi e^{\frac{1}{10}t} - 10\pi$ .  In English, this seems to say, ""To calculate the balance of a bank account starting with $\$0$ and continuously receiving deposits of $\$\pi$ per time unit, integrate between $0$ and $t$ the balance of a bank account starting with $\$\pi$ and continuously receiving deposits of $\$0$ per time unit.""  Of note is that both the real and hypothetical accounts have $10\%$ continuous compounding, but their time units are not necessarily the same ( $t$ and $\tau$ are presumably two forms of time). Since the above statement is not obvious, I decided to try a discrete version of the problem so I could then track the account balances at each time step.  To consider $P[n + 1] - \frac{1}{10}P[n] = \pi,\ P[0] = 0$ , I solved $Q[m + 1] - \frac{1}{10}Q[m] = 0,\ Q[0] = \pi$ .  The answer I got is $Q[m] = \frac{\pi}{10^m}$ , and inspired by the above integration, I took a summation from $0$ to $n$ to produce the solution $\displaystyle P[n] = \sum_{m = 0}^n \frac{\pi}{10^m} = \frac{\pi (10)^{n + 1} - \pi}{9(10)^n}$ .  However, I believe this is slightly incorrect and the solution should be $P[n] = \frac{\pi (10)^n - \pi}{9(10)^{n - 1}}$ . Can I use Duhamel's Principle to solve difference equations?  If so, what mistake have I made in the computations?  Is there a nice description of Duhamel's Principle in the context of this sort of bank account model (continuous or discrete)?","['ordinary-differential-equations', 'finance', 'recurrence-relations', 'solution-verification', 'intuition']"
4323462,Ratio of two positive functions,"Let $g(x)$ and $h(x)$ be two nonnegative functions over $[0,a]$ with $g(0)=h(0)=0$ , $$
g'(x)\leq h'(x),
$$ and $g(x)>0$ and $h(x)>0$ for $x\in(0,a)$ .
Let $$
f(x) = \frac{g(x)}{h(x)}
$$ over $(0,a)$ with $$
\lim_{x\to 0}f(x)=1.
$$ (An example is $g(x)=\sin 2x$ and $h(x)=2\sin x$ for $a=\frac{\pi}{2}$ .)
Is it true that $f(x)$ is non-increasing over $(0,a)$ (since $g(x)$ does not ""grow"" faster than $h(x)$ )?",['functions']
4323480,Showing there is a node in the graph with one and only one edge,"We have an undirected simple graph with $n$ vertices where for every pair of vertices $v_1,v_2$ , if $d(v_1)=d(v_2)$ then the set of neighbours of $v_1$ is disjoint from the set of neighbours of $v_2$ . Assuming the graph contains at least one edge, prove that there is a vertex of degree exactly $1$ in the graph. For example the following graph has vertices of degree exactly $1$ : While this problem concerns a graph, I feel like there is a way to apply pigeonhole theory to prove this.  Is this possible?","['graph-theory', 'pigeonhole-principle', 'combinatorics']"
4323512,How would you discover Stokes's theorem?,"Let $S$ be a smooth oriented surface in $\mathbb R^3$ with boundary $C$ , and let $f: \mathbb R^3 \to \mathbb R^3$ be a continuously differentiable vector field on $\mathbb R^3$ . Stokes's theorem states that $$
\int_C f \cdot dr = \int_S (\nabla \times f) \cdot dA.
$$ In other words, the line integral of $f$ over the curve $C$ is equal to the integral of the curl of $f$ over the surface $S$ .
Here the orientation of the boundary $C$ is induced by the orientation of $S$ . Question: How might somebody have derived or discovered this formula? Where does this formula come from? The goal is to provide an intuitive explanation of Stokes's theorem, rather than a rigorous proof. (I'll post an answer below.)","['multivariable-calculus', 'stokes-theorem']"
4323539,How to calculate this improper integral: $\int_0^{\infty}{\frac{1}{\theta}e^{\cos\theta}\sin(\sin\theta){d\theta}}$?,"Calculate the improper integral $$\displaystyle\int_0^{\infty}{\frac{1}{\theta}e^{\cos\theta}\sin(\sin\theta){d\theta}}$$ My try: We know that for any $a\in\mathbb{C}$ the integral $$\displaystyle\int_0^{\infty}e^{-ax^2}=\frac{1}{2}\sqrt{\frac{\pi}{a}}$$ Let $a=\cos\theta+i\sin\theta$ we know $$\displaystyle\int_0^{\infty}{e^{x^2\cos\theta}\sin(x^2\sin\theta){dx}}=\frac{\sqrt{\pi}}{2}\sin\frac{\theta}{2}$$ then $$\displaystyle\int_0^{\infty}{\frac{1}{\theta}e^{x^2\cos\theta}\sin(x^2\sin\theta){dx}}=\frac{\sqrt{\pi}}{2}\frac{\sin\frac{\theta}{2}}{\theta}$$ $$\displaystyle\int_0^{\infty}d\theta\displaystyle\int_0^{\infty}{\frac{1}{\theta}e^{x^2\cos\theta}\sin(x^2\sin\theta){dx}}=\displaystyle\int_0^{\infty}\frac{\sqrt{\pi}}{2}\frac{\sin\frac{\theta}{2}}{\theta}d\theta$$ Let $F(x)=\displaystyle\int_0^{\infty}{\frac{1}{\theta}e^{x^2\cos\theta}\sin(x^2\sin\theta){d\theta}}$ , then the result equals to $F(1)$ ,But I don't know what to do next.","['calculus', 'improper-integrals', 'analysis', 'real-analysis']"
4323578,"$\int_0^1 tf(2x-t)dt=\frac{1}{2}\arctan(x^2), f(1)=1$, find $\int_0^1 f(x)dx$. here $f$ is continuous.","$\int_0^1 tf(2x-t)dt=\frac{1}{2}\arctan(x^2),\ f(1)=1$ , find $\int_0^1 f(x)dx$ . here $f$ is continuous. By substituting $2x-t=s$ , and taking derivative, we have $2\int_{2x-1}^{2x}f(s)ds=2f(2x-1)+\frac{x}{1+x^4}$ . Let $x=1/2$ , we have $2\int_0^1 f(s)ds=2f(0)+x/(1+x^4)|_{x=1/2}$ . But we know just $f(1)=1$ , not $f(0)$ . How to pass across this obstacle? I strongly suspect it is a wrong problem, but could not find some counterexample.","['integration', 'calculus', 'definite-integrals']"
4323584,"Let $X$ be a compact Hausdorff space, then $A\subset X$ is compact $\iff$ A is closed","So I was trying to see if anyone could confirm the veracity of this statement. I've done the prove and I would like to know if I've done it right. This is a caracterization of the closed subsets inside a compact Hausdorff space (see demonstration). $\Rightarrow)$ To prove this implication I will only use that $X$ is Hausdorff, without using the fact that it is also compact. So, we are trying to see is that $X$ Hausdorff, let $A\subset X$ compact, then A is closed. To prove this statement we will see that $X\setminus A$ is open because all it's points are interior. So, let $x\in X\setminus A$ be any point, we need to find a neighbourhood $\mathcal{U}$ , such that $$x\in\mathcal{U}\subset X\setminus A$$ Let $a\in A$ and $x\in X\setminus A$ , as $X$ is Hausdorff, we can find two distinct neighbourhoods $\mathcal{U}_a$ and $\mathcal{V}_a$ such that $x\in \mathcal{U}_a$ , $a\in \mathcal{V}_a$ and $\mathcal{U}_a\cap\mathcal{V}_a=\emptyset$ . Doing this process for all points in $A$ , we get $$a\in \bigcup_{a\in A}\mathcal{V}_a:=\mathcal{V}\subset X, \hspace{4mm} x\in \bigcap_{a\in A}\mathcal{U}_a:=\mathcal{U}\subset X\setminus A$$ where $a\in \mathcal{V}$ , $x\in \mathcal{U}$ , and $\mathcal{V}\cap\mathcal{U}=\emptyset$ . Notice that $\mathcal{V}$ is open (because it is an arbitrary union of open sets), but we cannot garantee that $\mathcal{U}$ is open. Now, as $A$ is compact, there exists a finite subcover $\{\mathcal{V}_{a_{i}}\}_{i=1}^{n}$ such that $$a\in \bigcup_{i=1}^n\mathcal{V}_{a_i}:=\mathcal{V'}\subset X, \hspace{4mm} x\in \bigcap_{i=1}^{n}\mathcal{U}_{a_i}:=\mathcal{U'}\subset X\setminus A$$ So, we have constructed a neighbourhood $\mathcal{U'}$ such that $x\in \mathcal{U'}\subset X\setminus A$ . As all points in $X\setminus A$ are interior, this means that $X\setminus A$ is open so $A$ is closed. $\Leftarrow$ ) To prove this other implication I will only use the fact that $X$ is compact. So, we are trying to see that $X$ compact, let $A\subset X$ closed, then $A$ is compact. Let's starts by considering a cover of $A$ and see that it admits a finite subcover. $$\{\mathcal{W}_a\}_{a\in A}, \hspace{4mm} A\subset\bigcup_{a\in A}\mathcal{W}_a$$ which is open (because it is an arbitrary union of open sets). Now, observe that we can create a cover of $X$ just by adding one more open set. $$X\subset \bigcup_{a\in A}\mathcal{W}_a\cup(X\setminus A)$$ $X\setminus A$ is open because $A$ is closed. As $X$ is compact, we can find a finite subcover of $X$ , but the only way for $X$ to admit a finite subcover is that there exists a family of open sets $\{\mathcal{W}_{a_i}\}_{i=1}^{n}$ such that $$X\subset \bigcup_{i=1}^{n}\mathcal{W}_{a_i}\cup (X\setminus A)$$ But now, $\{\mathcal{W}_{a_i}\}_{i=1}^{n}$ is a finite subcover of open sets such that $A\subset \{\mathcal{W}_{a_i}\}_{i=1}^{n}$ $\hspace{7mm} \blacksquare$ So, as we saw, does this mean that inside a compact Hausdorff space $X$ , the closed and compact subsets are exactly the same?",['general-topology']
4323700,Does every compact set in a normed space with a non-trivial interior has 2 path connected points in the boundary?,"Let $k\subset\mathbb{R}^n$ be a compact space with $K^\circ \neq \emptyset$ . Are there necessarily $a,b\in\partial K$ such that $$[a,b]=\{a+t(b-a)\mid t\in[0,1]\}\subset K$$ This is a lemma I want to prove in order to use mean-value type theorems in a compact set. I would appreciate notes regarding my own proof attempt (which isn't formal enough I believe) as well as other proofs. Proof attempt: There exists a point $x\in K^\circ$ , so we can take $r=sup_r(\hat B _r(x)\subset K)$ and claim that $\partial K \cap\partial B_r(x)\neq\emptyset$ . Now we can take a point $a$ from this intersection and look at the interval $$[a,\infty)=\{a-t(x-a)\mid t\in[0,\infty]\}$$ Now we can take another supremum: $$s=sup_\alpha \{a+t(x-a)\mid t\in[0,\alpha]\}\subset K$$ Since $K$ is compact in a normed space it is bounded, so $s<\infty$ . It is also true that $s\geq2r$ . Because of that $s$ is well defined. We define $b=a-s(x-a)\in\partial K$ and we have $$a,b\in\partial K \ \ \ s.t \ \ \ [a,b]\subset K$$","['proof-writing', 'normed-spaces', 'multivariable-calculus', 'supremum-and-infimum', 'compactness']"
4323720,"Theorem 3.2, Chapter 1, of Hartshorne's Algebraic Geometry","This is regarding a question about Theorem 3.2 in Chapter I of Hartshorne's Algebraic Geometry. Let $Y \subset \mathbb{A}^n$ be an affine variety with affine coordinate ring $A(Y)$ . The final item (d) in the statement is (d) $K(Y)$ , the function field of $Y$ , is isomorphic to the quotient field of $A(Y)$ .... The argument is given as "" From (c) it follows that the quotient field of $A(Y)$ is isomorphic to the quotient field of $\mathcal{O}_P$ for every $P$ , and this is equal to $K(Y)$ , because every rational function is actually in some $\mathcal{O}_P$ ."" Could somebody explain this statement in detail? How is the quotient field of $\mathcal{O}_P$ isomorphic to $K(Y)$ , and how does this follow as explained in ""because every rational function is actually in some $\mathcal{O}_P$ . It is true that $\bigcup_{P \in Y} \mathcal{O}_P = K(Y)$ , but how does taking the quotient field of ONE $\mathcal{O}_P$ gives us $K(Y)$ ? Thanks for the help.","['affine-varieties', 'algebraic-geometry']"
4323748,Trouble understanding Blagouchine's extensions to the Malmsten integral,"$\newcommand{\d}{\,\mathrm{d}}$ The great work of Blagouchine massively generalises the Malmsten integral. I am actually familiar with contour integration, but he consistently introduces results from other papers that I am unfamiliar with, so it feels disingenuous to take notes on a proof I can't understand. I am interested in arriving at the following in a more ""simple"" manner: Let $a\ge0$ be real. Then: $$J(a)=\int_0^\infty\frac{\ln(x^2+a^2)}{\cosh(x)}\d x=2\pi\ln\left(\frac{\Gamma\left(\frac{3}{4}+\frac{a}{2\pi}\right)}{\Gamma\left(\frac{1}{4}+\frac{a}{2\pi}\right)}\right)+\pi\ln2\pi$$ As I mentioned, his derivation is not one that I am particularly keen to follow, but the similarity between this integral and Malmsten's integral made me hopeful one could be derived from the other. Malmsten's Integral: If $-\pi\lt\varphi\lt\pi$ , then: $$I(\varphi)=\int_1^\infty\frac{\ln(\ln(x))}{x^2+2\cdot\cos(\varphi)x+1}\d x=\frac{\pi}{2}\csc(\varphi)\ln\left((2\pi)^{\varphi/\pi}\frac{\Gamma\left(\frac{1}{2}+\frac{\varphi}{2\pi}\right)}{\Gamma\left(\frac{1}{2}-\frac{\varphi}{2\pi}\right)}\right)$$ This I have seen a good proof of and am satisfied with. Sadly I did not get very far with tackling $J$ : $$J(a)=2\int_0^\infty\frac{\ln(x^2+a^2)}{e^x+e^{-x}}\d x$$ Which under the transformation $x\mapsto e^x$ becomes: $$J(a)=2\int_1^\infty\frac{\ln(\ln^2(x)+a^2)}{x^2+1}\d x$$ Which is almost equal to $2\cdot I\left(\frac{\pi}{2}\right)$ . We want the term inside the logarithm to be simply $\ln(x)$ . For clarity, introduce $t$ a dummy variable. For $\ln^2(x)+a^2=\ln(t)$ , one gets $t=e^{a^2}x^{\ln(x)}$ , and $\d t=2e^{a^2}x^{\ln(x)}\frac{\ln(x)}{x}\d x$ , and an expression for $x$ in terms of $t$ too ugly to type. I do not see how to go any further. I also do not see how to reverse engineer Blagouchine's closed form into an expression involving $I$ and $a$ . It is similar to $I(\pi/2 + a)$ , but not close enough. Must I resign myself to researching his contour integration, or can this be done using Malmsten's integral as a first principle? If it can be done, I am not expecting the full proof, just an indication. Of course, if an answerer wants to derive it fully anyway for the joy of it, feel free!","['integration', 'improper-integrals', 'definite-integrals']"
4323761,"How to calculate $\int_{0}^{\infty} x^{-x} \,dx$?","I am trying to solve this improper integral: $\int_{0}^{\infty} x^{-x} \,dx$ . First I replace de infinity by a another variable $y$ , so: $\int_{0}^{y} x^{-x} \,dx = \int_{0}^{y} e^{\ln(x^{-x})}\,dx = \int_{0}^{y} e^{-x\ln(x)}\,dx = \int_{0}^{y} \sum_{n=0}^{\infty} \frac{(-x\ln(x))^{n}}{n!}\,dx = \sum_{n=0}^{\infty} \frac{(-1)^{n}}{n!} \int_{0}^{y} (x\ln(x))^n\, dx$ . Solving $\int (x\ln(x))^n\,dx$ : Substitute $u=\ln(x) \implies \int u^ne^{(n+1)n}\,du $ Substitute $v=u^{n+1} \implies \frac{1}{n+1}\int e^{(n+1)v^{\frac{1}{n+1}}}\,dv$ Substitute $w=(n+1)^{(n+1)}v  \implies \int e^{(n+1)v^{\frac{1}{n+1}}}\,dv = (n+1)^{-n-1}\int e^{w^{\frac{1}{n+1}}}\,dw$ $\int e^{w^{\frac{1}{n+1}}}\,dw = -(n+1)(-1)^n \operatorname{\Gamma}(n+1,-w^{\frac{1}{n+1}})$ Undo substitutions, $\int (x\ln(x))^n\,dx = \dfrac{\left(n+1\right)^{-n-1}\operatorname{\Gamma}\left(n+1,-\left(n+1\right)\ln\left(x\right)\right)}{\left(-1\right)^n}$ $\int_{0}^{y} (x\ln(x))^n\, dx  \implies \dfrac{\left(n+1\right)^{-n-1}\operatorname{\Gamma}\left(n+1,-\left(n+1\right)\ln\left(x\right)\right)}{\left(-1\right)^n}  \Big|_0^y$ , when $x=0$ , the incomplete gamma function will be evalueate between plus infinity and plus infinity so, $\int_{0}^{y} (x\ln(x))^n\, dx =  \dfrac{\left(n+1\right)^{-n-1}\operatorname{\Gamma}\left(n+1,-\left(n+1\right)\ln\left(y\right)\right)}{\left(-1\right)^n}$ $\sum_{n=0}^{\infty} \frac{(-1)^{n}}{n!} \int_{0}^{y} (x\ln(x))^n\, dx = \sum_{n=0}^{\infty} \frac{\operatorname{\Gamma}\left(n+1,-\left(n+1\right)\ln\left(y\right)\right)}{n!(n+1)^{n+1}} =   \sum_{n=1}^{\infty}\frac{Q\left(n,\ -n\ln\left(y\right)\right)}{n^n}$ . Where $Q$ is the normalized or regularized incomplete gamma function But what's happen when $y \to \infty$ ? The incomplete gamma function will be evaluated between zero and minus infinity, is it valid? Is there another way to find this value? Because de the improper integral converges.","['integration', 'improper-integrals', 'definite-integrals']"
4323765,How can i obtain general form of this integtral $\int_0^{\pi/4}\frac{x^3}{1+b\tan x}\ dx$,This is how i tried $$\int_0^{\pi/4}\frac{x^3}{1+b\tan x}\ dx$$ writing $\tan x=\frac{e^{ix}-e^{-ix}}{i(e^{ix}+e^{-ix})}$ $$i\int_0^{\pi/4}\frac{x^3(e^{ix}+e^{-ix})}{i(e^{ix}+e^{-ix})+b(e^{ix}-e^{-ix})}\ dx$$ substituting $e^{ix}=t;x=-i\ln t; dx=-\frac{i\ dt}{t}$ $$-\int_{1}^{e^{i\pi/4}}\frac{\ln^3t\left(t^2+1\right)}{i(t^2+1)+b(t^2-1)} dt$$ $$-\frac{1}{(i+b)}\int_{1}^{e^{i\pi/4}}\frac{\ln^3t\left(t^2+1\right)}{t^2+\frac{(i-b)}{(i+b)}} dt$$,"['integration', 'calculus', 'contour-integration', 'definite-integrals']"
4323851,Proving divisibility of a integer sequence,"A sequence of integers $f(n)$ has $f(0) =0$ and satisfies $f(n+2) = a f(n+1)+b f(n)$ for $n \geq 0$ , where $a,b \in \mathbb{Z}$ . For any
positive integer $k$ with $\operatorname{gcd}(k, b)=1$ , show that $f(n)$ is divisible by $k$ for infinitely many $n$ . Things I have tried so far: (Please correct me if I made any mistakes below, I am self learning :) Rewriting the given relation as $$f(n) = \frac{f(n+2) - a f(n+1)}{b}$$ Now for $f(n)$ to be divisible by $k$ it has to be that $f(n+1) - af(n+1) = mk$ for some $m \in \mathbb{Z}.$ which is equivalent to $f(n+2) \equiv a f(n+1) \operatorname{mod} k$ . Now since $f(n)$ is a integer sequence so $f(n+2) \equiv a f(n+1) \operatorname{mod} b$ but unsure how to proceed from here. Also $k$ does not divide $b$ so my only observations are $pk + qb = \operatorname{gcd}(k,b)$ or that $bx \equiv 1 \operatorname{mod} k$ has a solution for some unknown $x.$ Computing some terms to notice some pattern, however the only term common for the first few is $f(1)$ and no common structures that I can recognise. I fail to proceed, so any hints or tips would be great help. Thanks!","['elementary-number-theory', 'modular-arithmetic', 'discrete-mathematics']"
4323888,Finding $\limsup_{n\to\infty}\sqrt[n]{|a_n|}$ for a recursively defined sequence $(a_n)$ with $a_{n}=\frac13(a_{n-1}+a_{n-2}+a_{n-1}a_{n-2})$,"Question. Let $(a_n)$ be a complex sequence defined recursively: $$
a_0 = 0,\quad  a_1=1, \quad a_{n}=\frac13(a_{n-1}+a_{n-2}+a_{n-1}a_{n-2})\quad (n>1)
$$ What is $\displaystyle\limsup_{n\to\infty}\sqrt[n]{|a_n|}$ ? Remarks. This question is motivated by an unanswered question on the site that I am not able to solve. By the Cauchy-Hadamard theorem , the problem of finding the radius of convergence for the power series $f(z)=\sum_{n=0}^\infty a_nz^n$ reduces to the limit problem above. One can probably find some other way to figure out the radius of convergence, but I would like to focus on Cauchy-Hadamard and thus particularly the limit in the question. One straightforward attempt is to find a closed-form formula for the sequence so that one may able to apply asymptotic techniques to analyze $|a_n|^{1/n}$ . While there are systematic ways to handle the linear recurrence , I don't know how to handle this particular nonlinear case. The usual idea of ""linearizing the nonlinear problem"" seems not helpful here. With help of the short Python script, I plotted the sequence $(|a_n|^{1/n})$ . The result seems to suggest that the limit is $1$ .","['real-analysis', 'complex-analysis', 'sequences-and-series', 'power-series', 'limits']"
4323920,When is a local minimum a global minimum over a closed interval,"Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be  twice differentiable function. Suppose $a<c<b$ such that $f'(c)=0$ and $f''(c)>0$ . Then $c$ is a local minimum of $f$ . Does it follow that over $[a,b]$ , $c$ is also global minimum? It seems no. By EVT, there exists $y\in[a,b]$ such that $f(y)\leq f(x)$ for all $x\in[a,b]$ . Then $f(y)\leq f(c)$ . We also know that there exists $\delta>0$ such that for all $x\in(c-\delta,c+\delta)$ , $f(c)\leq f(x)$ . Since it's not necessary for $y$ to be in the interval $(c-\delta,c+\delta)$ , we may not have $f(c)\leq f(y)$ ; i.e. $f(c)$ is not necessarily a global min over $[a,b]$ . Is there anything we can say about the global minimum of $f$ over $[a,b]$ , once we find a local minimum in $(a,b)$ ?","['continuity', 'maxima-minima', 'derivatives', 'real-analysis']"
4323931,Number of points of an elliptic curve,"In my cryptography course I found the following problem: Find $|E(\mathbb{F}_{7^{100}})|$ where $E$ is given by $y^2=x^3+1$ . I know how to do it for small numbers, using quadratic residues, but this doesn't work with $7^{100}$ . My question is if there is a general method or algorithm that works in general and can be done by hand (no computer) or if there is a clever solution in this particular case. Many thanks.","['group-theory', 'elliptic-curves']"
4323992,How to approach this discrete graph question about Trees.,"A tree contains exactly one vertex of degree $d$ , for each $d\in\{3, 9, 10, 11, 12\}$ . Every other vertex
has degrees $1$ and $2$ . How many vertices have degree $1$ ? I've only tried manually drawing this tree and trying to figure it out that way, however this makes the drawing far too big to complete , I'm sure there are more efficient methods of finding the solution. Could someone please point me in the right direction!","['graph-theory', 'trees', 'discrete-mathematics']"
4324040,Differentiability on $\mathbb{R}^n$ under an equivalence relation.,"Let $f:\mathbb{R}^n \rightarrow \mathbb{R}^n$ be differentiable. Given an equivalence relation $\sim$ on $\mathbb{R}^n$ , is $f:\mathbb{R}^n/\sim \rightarrow \mathbb{R}^n/\sim$ also differentiable? The question that made me consider this is as follows: Given the 2-sphere $\mathbb{S}^2$ (as a manifold), consider the stereographic projection defined in the usual way, e.g. from the 'South pole' as \begin{align}
P_S:\mathbb{S}^2\setminus (0,0,-1) &\longrightarrow \mathbb{R}^2
\\ (x, y, z) &\longmapsto (\frac{x}{1+z}, \frac{y}{1+z}).
\end{align} With a similarly defined maps $P_N$ for the 'North pole', this gives us an atlas on $\mathbb{S}^2$ (they are smoothly compatible charts), and so we can talk about differentiability. Now define the equivalence relation for $x, x'\in \mathbb{S}^2$ \begin{align}
x\sim x' \iff x = -x.
\end{align} Now we can define \begin{align}
P_S':\mathbb{S}^2\setminus (0,0,-1)/\sim &\longrightarrow \mathbb{R}^2/\sim'
\\ [(x, y, z)] &\longmapsto [(\frac{x}{1+z}, \frac{y}{1+z})],
\end{align} where given $(\frac{x}{1+z}, \frac{y}{1+z}), a\in \mathbb{R}^2$ , define \begin{align}
(\frac{x}{1+z}, \frac{y}{1+z}) \sim' a \iff a = (-\frac{x}{1-z}, -\frac{y}{1-z}).
\end{align} Together with the analogous $P_N'$ (although I don't know if this is necessary any longer, since $(0,0,-1)\sim(0,0,1)$ ), this provides charts for $\mathbb{S}^2/\sim$ . Assuming there is a function $f\in C^{\infty}(\mathbb{S}^2)$ , then if $f(x) = f(-x) \forall x\in \mathbb{S}^2$ , then it seems to me that this function would be well defined on $\mathbb{S}^2/\sim$ . i.e. define $f'\in C^{\infty}(\mathbb{S}^2/\sim):[(x, y, z)] \mapsto f(x, y, z)$ . Is this correct? And if $f$ is differentiable on $\mathbb{S}^2$ , will it be differentiable on $\mathbb{S}^2/\sim$ ?","['real-numbers', 'continuity', 'calculus', 'derivatives']"
4324093,"How do 3 fractions having respectively $(a-x)^2$ , $(a+x)^2$ and $(a-x)$ as denominators add up to a fraction having $(a^2 - x^2)^2$ as denominator?","Source : Olry Terquem, Exercices de mathématiques élémentaires , $1842$ ( At Archive.org https://archive.org/details/exercicesdemath00terqgoog/page/n85/mode/1up ) I'm working on problem $35$ below, where appears  also the solution. My question is simply : is this solution correct, as far as the denominator is concerned? When I do $(a-x)^2(a+x)^2(a-x)$ , I get $ (a-x)(a-x)(a+x)(a+x)(a-x) $ $= (a-x)(a+x)(a-x)(a+x)(a-x)$ $= [(a-x)(a+x)] [(a-x)(a+x)](a-x)$ $= (a^2- x^2) ^2 (a-x)$ . Or, am I wrong?","['fractions', 'algebra-precalculus', 'soft-question', 'polynomials']"
4324174,Martingale constructed with Bernoulli random variables,"Let $U \sim U(0,1)$ and $V_1,V_2,...$ be a sequence of i.i.d $U(0,1)$ random variables  independent of $U$ . We define $X_k = 1$ if $V_k \le U$ else $X_k =0$ . If $\displaystyle S_n = \sum_{i=1}^{n} X_i$ , show that $M_n =\frac{S_n +1}{n+2}$ is a martingale with respect to the filtration $\mathcal{F}_n=\sigma(X_1,...,X_n)$ . My approach : Firstly, I calculated $E[X_{n+1}| \mathcal{F}_n]= P[V_{n+1} \le U | \mathcal{F}_n]=\frac{1}{2}$ Now, I start off with $E[M_{n+1}| \mathcal{F}_n]=E[\frac{S_{n}+X_{n+1}+1}{n+3} | \mathcal{F}_n]$ But that is not coming out to be $M_n$ . Where am I going wrong?","['probability-distributions', 'stochastic-processes', 'martingales', 'probability-theory', 'probability']"
4324177,Is it possible to determine the sign of the determinant of a matrix without knowing/using the formula for the determinant?,"I'm trying to build intuition for the orientation of a set of vectors independent of the well-known definition of the determinant . My intuition wants to go something like this: any set of vectors can be transformed into the standard basis by a sequence of elementary transformations: shears and positive rescalings should not change the sign of the set of vectors, swaps and negatives rescaling change the sign of the set of vectors. Let $v_1, \ldots, v_N \in \mathbb{R}^N$ . Let $V$ be the matrix whose columns equal $v_i$ . I would like to define a sign function which maps a square matrix $V$ to the set $\{-1, 0, +1\}$ . I'll give two candidates for a sign function which I'll call $S_1(V)$ and $S_2(V)$ . The hope is that $S_{1,2}(V) = \text{sgn}(\text{det}(V))$ , but I would like to establish this without relying on any well-known formulas for $\text{det}(V)$ such as $$
\text{det}(V) = \sum_{\sigma \in S_N} v_{1, \sigma(1)} \ldots v_{N, \sigma(N)} = \sum_{i_1, \ldots, i_N=1}^N \epsilon_{i_1\ldots i_N} v_{1, i_1}\ldots v_{N, i_N}\
$$ I define $S_{1,2}(V)$ as follows. If $V$ is not invertible then $S_{1,2}(V) = 0$ . If $V$ is invertible we proceed as follows.
There are three types of elementary matrices. $E^1_i(c)$ is the identity but with $c$ at the $(i,i)$ position instead of 1. $E^2_{ij}(c)$ is the identity but with $c$ at the $(i, j)$ position instead of 0. $E^3_{ij}$ swaps rows $i$ and $j$ . If $V$ is an elementary matrix then if $V=E_i^1(c)$ then let $S_{1,2}(V) = \text{sgn}(c)$ , if $V=E_{ij}^2(c)$ then $S_{1,2}(V)=+1$ , if $V=E_{ij}^3$ then $S_{1,2}(V)=-1$ If $V$ is invertible but not elementary my definitions for $S_1(V)$ and $S_2(V)$ differ. For $S_1(V)$ , if $V$ is invertible but not elementary then $V$ can be uniquely decomposed into elementary row matrices using a well-defined Gauss-Jordan elimination procedure: $$
V = E_1\ldots E_K
$$ In this case let $$
S_1(V) = S_1(E_1)\ldots S_1(E_K)
$$ For second candidate we define $S_2$ to have the property that $$
S_2(AB) = S_2(A)S_2(B)
$$ For $S_1$ it is clearly that $S_1(V)$ is a well-defined function for all matrices, but it is not clear to me how to prove $S_1(AB)=S_1(A)S_1(B)$ . For $S_2$ it is not clear to me how to prove such a function exists. For example, $V$ can be decomposed multiple different ways into elementary matrices. $$
V = E_{1,1}\ldots E_{1,k_1} = E_{2,1}\ldots E_{2, k_2}
$$ How to prove $$
S_2(E_{1,1})\ldots S_2(E_{1,k_1}) = S_2(E_{2,1})\ldots S_2(E_{2, k_2})?
$$ It is clear that if $S_2$ exists that $S_2(V) = S_1(V)$ and if we relax the constraint that we avoid explicit expersions for $\text{det}(V)$ , then it is clear that all of the above can be proven and $S_1(V)=S_2(V) = \text{sgn}(\text{det}(V))$ , but this is of course what I'm trying to avoid. So my questions are: How to show that $S_1(AB)$ satisfies $S_1(A)S_1(B)$ ? How to show that $S_2(V)$ exists? Is there another way to get at what I am seeking?","['matrices', 'signed-measures', 'determinant', 'linear-algebra']"
4324207,Using limits properties when proving using epsilon-delta definition.,"I want to prove $\lim\limits_{x \to 5} \sqrt{2x+6} = 4$ using the epsilon-delta definition. My intuition to proving this is to use the root rule and square both ends of the equation to end up with: $\lim\limits_{x \to 5} 2x+6 = 16$ I would then continue to prove the later limit as I would any other. Is this a valid way to approach this proof, or am I missing something?","['limits', 'calculus', 'proof-writing', 'epsilon-delta']"
4324219,Prove there exists $c\in\mathbb{C}$ such that $|c| \leq 1$ and $f(z)=ce^{z}$,"Let $(a_k)_{k\geq 0}$ be a real sequence such that $\lim_{k\rightarrow \infty} a_k =+\infty$ . Let $f:\mathbb{C}\rightarrow\mathbb{C}$ be a holomorphic function such that: $$\forall k \in \mathbb{N}, \forall n\in\mathbb{N},~~|f^{(n)}(a_k)|\leq e^{-a_k} $$ Prove there exists $c\in\mathbb{C}$ such that $|c| \leq 1$ and, $$\forall z \in\mathbb{C}, ~~f(z)=ce^{-z}$$ Do you have an idea about how to approach this problem?",['complex-analysis']
4324269,Existence and Uniqueness of the Cauchy Problem for General Competition Systems?,"I have the original system \begin{equation}
    \begin{array}{lcl}
      \dot u_{1} & = & A_{1}u_{1}(1 - u_{1} - a_{12}u_{2} - \dots - a_{1n}u_{n})  \\
        \dot u_{2} & = & A_{2}u_{2}(1 - a_{21}u_{1} - u_{2} - \dots - a_{2n}u_{n}) \\ 
        & \vdots & \\
        \dot u_{n} & = & A_{n}u_{n}(1 - a_{n1}u_{1} - \dots - a_{n(n-1)}u_{n-1} - u_{n}),
    \end{array}
\end{equation} which is a general n-dimensional competition system. We use the fact that $A_{i} = a_{ii}$ to write this system as \begin{equation}
    \dot u_{i} = \Phi_{i}(t; u_{1}, u_{2}, \dots, u_{n}),
\end{equation} where \begin{equation*}
\begin{array}{lcl}
    \Phi_{1} & = & u_{1}(a_{11} - a_{11}u_{1} - a_{11}a_{12}u_{2} - \dots - a_{11}a_{1n}u_{n}) \\
    \Phi_{2} & = & u_{2}(a_{22} - a_{22}a_{21}u_{1} - a_{22}u_{2} - \dots - a_{22}a_{2n}u_{n}) \\
    & \vdots & \\
    \Phi_{n} & = & u_{n}(a_{nn} - a_{nn}a_{n1}u_{1} - \dots - a_{nn}a_{n(n-1)}u_{n-1} - a_{nn}u_{n}).
\end{array}
\end{equation*} Here, the $a_{ij}$ 's are smooth, positive 1-periodic functions of t defined over $\mathbb{R}$ . Before I properly consider the periodic case, I need to consider properties of the time-averaged system (which, in this case, will be autonomous). We define this as \begin{equation}
    \dot w_{i} = \phi_{i}(w_{1}, w_{2}, \dots, w_{n}),
\end{equation} where \begin{equation*}
    \phi_{i}(w_{1}, w_{2}, \dots, w_{n}) = \int_{0}^{1} \Phi_{i}(w_{1}, w_{2}, \dots, w_{n}) \ dt.
\end{equation*} It follows that the system (7) can be written as \begin{equation}
    \dot w_{i} = w_{i}\bigg(\bar{a_{ii}}(1 - w_{i}) - \sum_{k \neq i} \bar{a_{ik}}w_{k}\bigg), \ \ \ i = 1, 2, \dots, n,
\end{equation} where \begin{equation*}
    \bar{a_{ij}} = \int_{0}^{1} a_{ij}(t) \ dt.
\end{equation*} Now, my goal is to prove that the Cauchy problem for this system $\dot w_{i}$ has a unique global solution whenever the initial data $w_{0} = (w_{0_{1}}, w_{0_{2}}, \dots, w_{0_{n}})$ satisfy $w_{0_{i}} \in \mathbb{R}_{+0} = \mathbb{R}_{+} \cup \{0\} \forall i \in [1,n].$ Unfortunately, I have not been able to find much information on conditions for the existence and uniqueness of nonlinear systems of ODEs, or at least for general n-dimensional competition systems like this one. How should I approach a proof for this? I'm a bit stuck.","['ordinary-differential-equations', 'dynamical-systems']"
4324425,Recursivley count triangulations of a convex polygon,"I am trying to find a recursive number of different triangulations of a convex polygon with $n$ vertices. After some searching I found that the number can be expressed using catalan numbers, this useless for me as I need a recursive expression. Any hints will be usefull :)","['triangulation', 'combinatorics', 'polygons']"
4324572,Calculate the determinant of the matrix under the condition $x \neq y$,"Calculate the determinant of the matrix: $$\left|\begin{array}{ccccc} a_{1} & x & x & \ldots & x \\ y & a_{2} & x & \ldots & x \\ y & y & a_{3} & \ldots & x \\ \ldots & \ldots & \ldots & \ldots & \ldots \\ y & y & y & \ldots & a_{n} \end{array}\right|.$$ Attempts and thoughts : One of my good ""colleagues"" noticed that if $D_n$ is the determinant of an $n×n$ matrix, then $$D_{n}=P_{n}-x y \sum_{i=0}^{n-2}(-1)^{i} P_{n-2-i} X_{i}.$$ Here $X_k$ is the sum of all products, $x^iy^j$ , where $i+j=k$ . $P_k$ is the sum of all possible products involving exactly $k$ distinct $a_i$ values. Manually counting the determinants, you can see a certain pattern: $$ \begin{aligned} &D_{0}=P_{0} \\ &D_{1}=P_{1} \\ &D_{2}=P_{2}-x y[P_{0} X_{0}] \\ &D_{3}=P_{3}-x y[P_{1} X_{0}-P_{0} X_{1}] \\ &D_{4}=P_{4}-x y[P_{2} X_{0}-P_{1} X_{1}+P_{0} X_{2}]. \end{aligned} $$ This is true up to $n=10$ . I did not check further. However, a better option appeared on the horizon, namely $\displaystyle\frac{x f(y)-y f(x)}{x-y}$ , where $f(z)=(a_{1}-z)(a_{2}-z) \ldots(a_{n}-z)$ . And verily, these two expressions agree with each other. Option $1$ is more complicated and requires additional calculations, while this formula is much simpler and fully satisfies the condition of the problem. Question : I can prove the second formula by the method of mathematical induction. It is not very difficult, much easier than deriving this formula. And here's the question. How do you derive this formula?","['matrices', 'determinant', 'linear-algebra']"
4324585,how to prove that this function is not injective,"I'm very new to proving that a function is injective, surjective, bijective, invertible etc.
So I'm supposed to prove that the function below is not injective. $$f(x) = \frac{(-1)^x (2x-1) +1}{4}$$ Where $f:\Bbb N\to\Bbb Z$ . Well, I tried to consider: $$f(a) = f(b)$$ Which gives: $$\frac{(-1)^a (2a-1) +1}{4} = \frac{(-1)^b (2b-1) +1}{4}$$ Then $$(-1)^a (2a-1) = (-1)^b (2b-1)$$ And using log base $-1$ : $$a(2a-1) = b(2b-1)$$ Annnd finally: $$2a^2 -a = 2b^2 -b$$ I know that if $a=0$ and $b=1/2$ they both get $0$ as the answer, but $b= 1/2$ isn't a natural number so I can't use that right? So I guess I'm stuck here. Is there a way to break it down further to show that $a\neq b$ ?",['functions']
4324630,Approximate any Borel subset $A \subseteq R^n$ with a compact $B \subseteq A$ such that $\mu(A) - \mu(B)$ is arbitrarily small.,"What kinds of distributions $\mu$ on $\mathbb R^n$ (seen as a measurable space, equipped with Borel $\sigma$ -algebra) have the property that every Borel subset can be approximated arbitrarily well (in terms of meausure deficit) by one of its compact subsets ? That is, such that For every $\epsilon>0$ and every Borel $A$ with $\mu(A)>0$ , there exists a compact set $B \subseteq A$ such that $\mu(B) \le \mu(A)$ and $\mu(B) \ge \mu(A) - \epsilon$ . My wild guess is that any $\mu$ which has density w.r.t Lebesgue measure on $\mathbb R^n$ should have this property, but I'm not quite sure.","['approximation', 'measure-theory', 'probability-theory', 'probability']"
4324644,Curl of a Lie bracket of two vector fields,"I am wondering if there is a nice (ideally coordinate free, something that holds in manifolds) identity of the form $\nabla \times [X,Y] = [\nabla \times X,Y] + [X, \nabla \times Y] + ...$ , and if this is not something that can exist is it at least possible to determine that if $X,Y$ are irrotational $\nabla \times X = \nabla \times Y = 0$ then we can conclude their Lie bracket is irrotational. I first tried in vain writing $\nabla \times = \star d$ and hoping I could get some very easy result out of exterior derivative identities but the Lie bracket completely brick walled any progress from this direction. Since that didn't work I calculated $(\nabla \times v)^i= \varepsilon^i_{jk} \frac{\partial}{\partial x^j}v^k$ and I started to get terms that did look like $X(\nabla \times Y^i)$ which seemed promising, but I also got a lot of horrible junk terms looking like $\varepsilon^i_{jk}\frac{\partial X^a}{\partial x^j}\frac{\partial}{\partial x^a}Y^k$ which I don't know how to nicely take out of index notation, since just taking the partial derivative of the components of the vector field $X$ and feeding it $Y$ doesn't seem like a very geometric quantity to have. Is there a better way of doing this, or is there some known identity someone has already found in a book that I can find?","['vector-fields', 'reference-request', 'vector-analysis', 'differential-forms', 'differential-geometry']"
4324675,Going from 30 to 100 in a coin flip game.,"The question is this: Say you're playing a coin flip game, where you start with 30 dollars.
If you flip heads, you win 1.
If you get tails, you lose 1.
You keep playing until you either run out of money or reach 100.
What is the probability that you will reach 100. The coin is fair. I have seen many questions about expected number steps, expected earnings and so on. However I am having trouble with this question because the game need not even end for certain (I think). In such situation, how would we either get a probability, or explain why it can’t be arrived at, if that is the case?","['random-walk', 'probability']"
4324678,"If the image of an operator is closed, is the image of the powers of the operator also closed?","Say $T$ is a bounded linear operator in a normed space that maps to itself (Banach or Hilbert space is fine). If the image $\text{Im}(T)$ is closed, then is it true that $\text{Im}(T^n)$ is closed? If not, what is a counterexample? I know there are some theorems for compact operators that make use of this, and it is true for compact, but I'm not sure if this is true in general.","['operator-theory', 'functional-analysis']"
4324680,"The $\big\{\{a,b\}\mid a\in A\wedge b\in B\big\}$ operator","Given two sets $A$ and $B$ we can define: $$
C=\big\{\{a,b\}\mid a\in A\wedge b\in B\big\}
$$ I was wondering if there a common name/definition for this kind of operator?","['elementary-set-theory', 'terminology']"
4324735,Solve this nonhomegenous ode $y''+4y = \cos(2x)$,"Solve the given nonhomogenous linear ODE by variation of parameters or undetermined coefficients $y'' + 4y = \cos(2x)$ . A general solution is $y_1 = \cos(2x), y_2 = \sin(2x)$ , and the Wronksin determinant is equal to 2. Plugging this into the equation for the method of variation of parameters, I get $$-\cos(2x)\int\frac{\sin(2x)\cos(2x)}{2}dx + \sin(2x)\int\frac{\cos^2(2x)}{2}dx$$ The integrals cancel out to $0$ . How can I approach this correctly with the method proposed?",['ordinary-differential-equations']
4324772,Are there any proof that show something about this language?,"Suppose we show any positive rational number with alphabet a string $S$ on $\{0,1,\#\}$ that $S=x_kx_{k-1}\dots x_1\#y_ky_{k-1}\dots y_1$ such that $x_i,y_i\in\{0,1\}$ show an rational number. How it's possible to show all rational numbers in interval $[\sqrt{2},\sqrt{7}]$ with context sensitive grammars? According to this link , I know rational numbers between an interval are countable, but how we can conclude that, we can show all rational numbers in interval $[\sqrt{2},\sqrt{7}]$ by a context senstive langyage?","['formal-languages', 'discrete-mathematics']"
4324786,What is $ \lim_{x \rightarrow 0}\left(\frac{1}{\ln\cos (x)}+\frac{2}{\sin ^{2}(x)}\right) $?,"The answer of the following limit: $$
\lim_{x \rightarrow 0}\left(\frac{1}{\ln \cos (x)}+\frac{2}{\sin ^{2}(x)}\right)
$$ is 1 by Wolfram Alpha. But I tried to find it and I got $2/3$ : My approach : $1)$ $
\ln(\cos x)=\ln\left(1-\frac{x^{2}}{2}+o\left(x^{3}\right)\right)=-\frac{x^{2}}{2}+o\left(x^{3}\right)
$ $2)$ $
\sin ^{2}(x)=\left(x-\frac{x^{3}}{3!}+o\left(x^{3}\right)\right)^{2}=x^{2}-\frac{x^{4}}{3}+o\left(x^{4}\right)
$ $3)$ $\begin{aligned} \frac{1}{-\frac{x^{2}}{2}+o\left(x^{3}\right)}+\frac{2}{x^{2}-\frac{x^{4}}{3}+o\left(x^{4}\right)}=\frac{-x^{2}+x^{2}-\frac{x^{4}}{3}+o\left(x^{3}\right)}{-\frac{x^{4}}{2}+o\left(x^{5}\right)}=\frac{-\frac{1}{3}+o\left(x^{3}\right)}{-\frac{1}{2}+o\left(x^{5}\right)} \end{aligned}$ $4)$ $\lim _{x \rightarrow 0} \frac{-\frac{1}{3}+o\left(x^{3}\right)}{-\frac{1}{2}+o\left(x^{5}\right)}=\frac{-\frac{1}{3}}{-\frac{1}{2}}=\frac{2}{3}$ So where is the mistake in my approach? Note: $o$ denotes the little-o notation Edit : I've understood where's my mistake is, but another question popped up reading the answers which is : does $o(1/x)$ tends to zero as x tends to zero?","['limits', 'limits-without-lhopital', 'taylor-expansion']"
4324849,Why the partial derivative for these two similar cases are done differently?,I was watching patrickJMT's derivates of logarithmic functions video and I got stuck understanding why these derivates are treated differently: $f(x) = \ln(g(x))$ derivative is $f'(x) = \frac{1 }{ g(x)} * g'(x)$ while the function $f(x) = log_a g(x)$ has the derivative $f'(x) = \frac{1 }{ g(x) \ln(a)}$ . Why do we not include the derivative of $g(x)$ as well to the case of log function? Reference,"['derivatives', 'logarithms']"
4324867,Formula for distance between Incenter and Orthocenter.,"On pg. 205 of Johnson's Advanced Euclidean Geometry, he gives three formulas, preparatory to a proof of Feuerbach's theorem. $$OI^2=R^2-2R\rho$$ $$IH^2=2\rho^2-2Rr$$ $$OH^2=R^2-4Rr$$ where $O$ is the circumcenter, $I$ the incenter, $H$ the orthocenter; $R$ the radius of the circumcircle, $\rho$ , that of the inscribed circle, and $r$ , the in-radius of the pedal triangle, the triangle formed by the feet of the altitudes. The first equation is the theorem of Euler. The third follows from the first, by applying it to the pedal triangle, whose incenter is $H$ , and circumcenter is $N$ , the midpoint of $HO$ . Is there a correspondingly simple proof of the second formula? A non-trigonometric solution is preferred.","['euclidean-geometry', 'triangles', 'geometry']"
4324882,Is a category a conglomerate?,"In the book The joy of cats , a category is defined as a tuple $(\mathcal O, \text{Hom}, \text{id}, \circ)$ , where $\mathcal O$ is a class, etc. So a category consists of a class and a few ""functions"" between classes. Since classes can't contain classes, this means that a category must be a conglomerate, right? And if we wanted to talk about a ""bigger category"" like the ""category"" of all categories, we would need some concept bigger than a conglomerate right? What concept would this be?","['elementary-set-theory', 'category-theory']"
4324888,Is a subgroup determined by where the generators are in its cosets?,"Let $G$ be a finitely generated infinite group and $H$ be a subgroup of finite index. In particular say $G=\langle x_1,x_2,...,x_n\rangle$ and $G:H=\{R_1,...,R_m\}$ . Does the distribution of the $x_i$ among the $R_j$ determine $H$ (up to reordering cosets)? For example if $G=\langle x_1,x_2,x_3\rangle$ and $H$ is such that $x_1, x_2\in R^H_1$ and $x_3\in R^H_2$ , then if $K\le G$ with $x_1,x_2\in R_1^K, x_3\in R_2^K$ , we must have $H=K$ ? Hopefully the intention is clear, but let me know in the comments if otherwise","['finitely-generated', 'group-theory', 'abstract-algebra', 'infinite-groups']"
4324896,Finding $\lim_{n\to\infty} \frac{z_{n}}{z_{n-1}}$ where $3z_{n}=z_{n-1}+z_{n-2}+z_{n-1}z_{n-2}$,"Question. Let $(z_n)$ be a real sequence such that $$
z_0 = 0,\quad  z_1=1, \quad 3z_{n}=z_{n-1}+z_{n-2}+z_{n-1}z_{n-2}\quad (n>1)\tag{1}
$$ Prove that the limit of the sequence $(b_n)$ with $b_n:=\frac{z_{n}}{z_{n-1}}$ exists. Observations. Diving by $z_{n-1}$ on both sides of (1), we get $$
b_n = f(b_{n-1})+z_{n-2}
$$ where $f(x)=\frac13(1+\frac1x)$ . An answer to this question shows that $\lim_{n\to 0}z_n = 0$ . One straightforward idea is to show that the sequence is Cauchy. By the triangle inequality $$
|b_n-b_m| = |f(b_{n-1})-f(b_{m-1})|+|z_{n-2}-z_{m-2}|\;.
$$ The second term on the right-hand side can be handled easily by Observation 2. But then one needs to estimate $|f(b_{n-1})-f(b_{m-1})|$ . One can find the derivative $f'(x)=\frac{-3}{x^2}$ , which seems not very much helpful here.","['limits', 'sequences-and-series', 'real-analysis']"
4324976,Hodge decomposition for complex manifold,"Let $X$ be a compact oriented Riemannian manifold. By Hodge decomposition, we can decompose $$\Omega^k(X)=\mathrm{im}(d)\oplus\mathrm{im}(d^*)\oplus\ker(\Delta).$$ Now, if further $X$ has a complex structure, I read on a book that $$\Omega^{p,q}(X)=\partial(\Omega^{p-1,q}(X))\oplus\partial^*(\Omega^{p+1,q}(X))\oplus\ker(\Delta_{\partial}),$$ or $$\Omega^{p,q}(X)=\bar\partial(\Omega^{p,q-1}(X))\oplus\bar\partial^*(\Omega^{p,q+1}(X))\oplus\ker(\Delta_{\bar\partial}).$$ My question is: given that I know the theorem for the real case and $d=\partial+\bar\partial$ , shouldn't the result be $$\Omega^{p,q}(X)=(\partial(\Omega^{p-1,q}(X))+\bar\partial(\Omega^{p,q-1}(X)))\oplus(\partial^*(\Omega^{p+1,q}(X))+\bar\partial^*(\Omega^{p,q+1}(X)))\oplus\ker(\Delta)?$$","['hodge-theory', 'complex-geometry', 'complex-manifolds', 'differential-geometry']"
4325002,Combi Problem - Proving Existence of a row,"The following problem comes from a Problem Set that concluded recently - Problem: $50$ girls and $50$ boys stand in line in some order. There is exactly one stretch of $30$ children next to each other with an equal number of boys and girls. Show that there is also a stretch of $70$ children in a row with an equal number of boys and girls. I've tried a couple of approaches and seem to be going nowhere. One approach I tried was applying the Pigeonhole Principle by defining the $71$ possible rows of $30$ children as pigeons, and another thing I attempted was considering the contrapositive, but nothing seems to work. I would appreciate any hints (not a full solution) towards solving this problem.","['contest-math', 'pigeonhole-principle', 'combinatorics', 'combinatorial-proofs']"
4325057,Cramer rao low bound of uniform distribution,"I was given a task to show empirically that the scattering holds up Cramer rao low bound. At first I had to calculate the estimator $ T' = E(2X_1\mid \max X_i)$ which is equal to $=\frac{n+1}{n} \max X_i$ Then I was need to run a sample in R with some parameters. Here is my code: theta = 5
n = 1000
error1 = c()
error2 = c()

for (i in 1:15){
  U = runif(n, min=0, max = 5)
  T_1 = 2*U[1]
  T_2 = ((n+1)/n)*max(U)
  error1 = c(error1, (T_1-theta)^2)
  error2 = c(error2, (T_2-theta)^2)
  
} Ok, now for Cramer rao low bound I have to calculate $\frac{1}{I(\theta)}$ but there is no Fisher information for $U\sim[0,\theta]$ So, how can I show empirically (in R) that Cramer rao low bound hold here?","['statistical-inference', 'statistics', 'uniform-distribution', 'estimation']"
4325061,How to verify chi-square random variables are sub-exponential variables?,"I just began to study statistics this term and I had some trouble understanding the derivation of sub-exponential variables. Let $Z \sim \mathcal{N}(0, 1), X = Z^2 \sim \chi^{2}_{1}$ . Now, I want to show this chi-square random variables are sub-exponential random variables based on the definition of sub-exponential, $$\mathbb{E}[\exp(\lambda(X - \mathbb{E}[x]))] = \mathbb{E}[\exp(\lambda(X - 1))] = \frac{e^{-\lambda}}{\sqrt{(1 - 2\lambda)}}, \forall \lambda < \frac{1}{2}.$$ The final step is to show $\frac{e^{-\lambda}}{\sqrt{(1 - 2\lambda)}} \leq e^{\frac{\nu^2 \lambda^2}{2}}$ and $|\lambda| < \frac{1}{\alpha}$ , where $\nu, \alpha > 0$ . But, I have a trouble to derive the final step, I see some lecture notes show that $\frac{e^{-\lambda}}{\sqrt{1 - 2\lambda}} \leq e^{2\lambda^2}$ , I cannot understand this step. Can anyone tell me how to derive such inequality? Thanks!","['chi-squared', 'statistics', 'probability-theory']"
4325128,A purely algebraic proof of a regular tetrahedron inequality,"One of the comments in Prove that inequality $AM \cdot AN + BM \cdot BN + CM \cdot CN \geq DM \cdot DN$ gives the suggestion for proving the inequality $$ \sqrt{(x-1)^2 + (y+1)^2 + (z+1)^2}\sqrt{(a-1)^2+(b+1)^2+(c+1)^2} $$ $$ + \sqrt{(x+1)^2 + (y-1)^2 + (z+1)^2}\sqrt{(a+1)^2+(b-1)^2+(c+1)^2} $$ $$ + \sqrt{(x+1)^2 + (y+1)^2 + (z-1)^2}\sqrt{(a+1)^2+(b+1)^2+(c-1)^2} $$ $$ \geq \sqrt{(x-1)^2 + (y-1)^2 + (z-1)^2}\sqrt{(a-1)^2+(b-1)^2+(c-1)^2} $$ for any real numbers $a,b,c,x,y,z$ . Question : Can anyone think of a nice algebraic way to do that? If you try to put the third product of square roots on the right, then square and have two products, then square again etc. the resulting inequality is with roughly 3800 terms (done with Wolfram Mathematica) and has a mixture of positive and negative terms (so it is not even clear why it holds). Crude applications of Cauchy-Schwarz also do not seem to work. Any help appreciated!","['3d', 'geometry', 'real-analysis', 'cauchy-schwarz-inequality', 'inequality']"
4325140,Robert didn’t sleep last night and now he is sitting for a multiple choice examination with ...,Robert didn’t sleep last night and now he is sitting for a multiple choice examination with 20 questions. He fills in the answers on the bubble sheet randomly without reading the question and each question has 5 possible answers. A.) What is the probability that Robert gets exactly 10 questions right? $P(X=10) = \binom{20}{10}\left( \frac15\right)^{10}\cdot \left(\frac45\right)^{10} = 0.002$ B.) What is the probability that Robert gets two or more questions right? $P(x \ge 2) = 1 - P(x<2) = 1 - [P(x=0) + P(x=1)] = 0.9308$ c.) What is the expected value and variance of the number of questions Roberts gets right? $E(x) = 20(1/5) = 4$ $Var(x) = 20(1/5)(4/5) = 16/5$ Does my thought process seem correct or does my work or my answers seem off somewhere?,"['statistics', 'solution-verification']"
