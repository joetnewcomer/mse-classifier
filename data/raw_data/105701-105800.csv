question_id,title,body,tags
1496567,Why is $n_1 \sqrt{2} +n_2 \sqrt{3} + n_3 \sqrt{5} + n_4 \sqrt{7} $ never zero? [duplicate],"This question already has answers here : The square roots of different primes are linearly independent over the field of rationals (3 answers) Closed 8 years ago . Here $n_i$ are integral numbers, and not all of them are zero. It is natural to conjecture that similar statement holds for even more prime numbers. Namely, $$ n_1 \sqrt{2} +n_2 \sqrt{3} + n_3 \sqrt{5} + n_4 \sqrt{7} + n_5 \sqrt{11} +n_6 \sqrt{13} $$ is never zero too. I am asking because this is used in some numerical algorithm in physics","['abstract-algebra', 'number-theory']"
1496611,Integral closure/normalization of the cuspidal cubic.,"This is a homework question from my Commutative Algebra class. Please correct me if I'm asking this question in a wrong way. Let $k$ be any field, and let $A=k[x,y]/(y^2-x^3)$. The question works towards the integral closure of $A$ in three steps. The first step is to show that the $k$-algebra homomorphism $\phi: A\to k[t]$ sending $x\to t^2$ and $y\to t^3$ is injective and has image $k[t^2,t^3]$, which I have done. The second step consists of showing that the integral closure of $k[t^2,t^3]$ equals $k[t]$, which I have done by showing that $k[t]$ is contained in $\overline{k[t^2,t^3]}$ and by noting that $k[t]$ is a UFD and thus integrally closed. The third part is: Deduce that the integral closure of $A$ is $A[y/x]$. What monic polynomial with coefficients in $A$ does $y/x$ satisfy? My own work: We can get the integral closure of $k[t^2,t^3]$ by adjoining the element $t=\frac{t^3}{t^2}$ (in its field of fractions $k(t)$) to $k[t^2,t^3]$. If we would ""extend"" the domain of the homomorphism $\phi$ to include the field of fractions of $A$ (I'm not sure if I am phrasing this correctly, but I hope it's clear what I mean), such that we can meaningfully speak of $\phi(y/x)=t^3/t^2$, then it would seem to makes sense that we get the integral closure of $A$ by adjoining $y/x$, but here lies exactly my problem: it doesn't make all that much sense to me. The isomorphism is between $k[t^2,t^3]$ and $A$ and not between their respective field of fractions, so how can we ""transport"" the element $t^3/t^2$ back to $A$ via using $\phi$, and simply conclude that $y/x$ should be adjoined to $A$ to form the integral closure? Is there something I'm missing here? If anybody can help, it would be greatly appreciated. It's the only question I haven't completed, so even though it's homework, I'm more interested in understanding what's going on here than the actual answer. Many thanks in advance.","['algebraic-geometry', 'commutative-algebra']"
1496629,Measure of Image of Linear Map between Different Dimensional Space,"If $L \in {\mathbb R}^{m \times n}$ ($m < n$) is a linear map from ${\mathbb R}^n$ onto ${\mathbb R}^m$ (onto means $L$ has full row rank). Given a compact set ${\mathcal A} \subset {\mathbb R}^n$ (compact set in Euclidean space is Lebesgue measurable), how to calculate the measure $\mu_{m}(L({\mathcal A}))$, where $\mu_{m}(\cdot)$ is the Lebesgue measure in ${\mathbb R}^m$?","['linear-transformations', 'measure-theory']"
1496688,Three lines are concurrent (or parallel) $\iff$ the determinant of its coordinates vanishes.,"I'm trying to prove the concurrency condition for three lines lying on a plane. This condition says that: Let 
  \begin{cases} ax + by + cz=0 \\ a'x – b'y + c'z=0 \\ a''x + b''y + c''z=0 \end{cases}
  be three lines (barycentric coordinates), with the cordinates of the lines not all equal. Prove that they are concurrent or parallel iff $$ \left| \begin{array}{ccc}
a & b & c \\
a' & b' & c' \\
a'' & b'' & c'' \end{array} \right| =0.
$$ My try: $$\left| \begin{array}{ccc}
a & b & c \\
a' & b' & c' \\
a'' & b'' & c'' \end{array} \right| =0 \iff \exists P=(x,y,z)\neq(0,0,0),$$ and we've found a common $P$ in those three lines, different of $(0,0,0)$ and with $(x,y)\neq (0,0)$, because it would follow that $P=(0,0,0)$. So the lines are concurrent. Is it correct? How I see that they're parallel?","['affine-geometry', 'determinant', 'barycentric-coordinates', 'geometry', 'linear-algebra']"
1496699,Limits- legal and illegal algebraic manipulation.,"I am doing probability and am using the strong law of large numbers to get after a bit of irrelevant extra algebra which I wont mention 
$\frac{\log(C_n)}{n} \rightarrow K$ where $C_i$ are a sequence of random variables, $K$ is some constant and $n$ can only take natural number values.
I want to do the following: $\Rightarrow$ $\log(C_n) \rightarrow nK$ $\Rightarrow$ $(C_n) \rightarrow e^{nK}$ This is definitely not allowed I know- but I'm trying to figure out how $C_n$ behaves and I don't know what to do??","['probability-theory', 'sequences-and-series', 'limits', 'law-of-large-numbers']"
1496708,Another way of counting probability,"A set $S = \{1, 2, \cdots, k\}$ is given. Two persons independently choose some numbers from this set. I want to count the probability that the cardinality of intersection of the chosen sets by both persons is exactly one. Each person has to choose at least one number. A person can choose a number which is already chosen by another person. A number is being chosen independently and uniformly at random from the set. My approach :
Fix one number from $1$ to $k$. Probability of both persons choosing that number is $\frac{1}{k^2}$. Remaining $k-1$ numbers can be chosen by either of both or by none of both. So, probability for that is $\left(1 - \frac{1}{k^2}\right)^{k-1}$. And that fixed number can be selected in ${k \choose 1}$ ways. So, probability of required event is: \begin{align}
P(E) = {k \choose 1} \frac{1}{k^2} \left(1 - \frac{1}{k^2}\right)^{k-1}
\end{align} My questions : Is this reasoning correct? Initially I started with counting all the possible ways of choosing numbers by each person. Can we count the required probability by counting ways technique? Is there any other way of counting the probability?","['probability', 'combinatorics']"
1496720,"""Regular polytopes"" in Minkowski spacetime","Is there an analogue of regular ""polytopes"" (hyperbolic honeycombs?) in the 4D Minkowski spacetime of special relativity, just as there are six regular polytopes in Euclidean 4D space? If so, what is their classification?","['polytopes', 'geometry']"
1496755,Radical of an infinite dimensional Lie Algebra,"I am studying Lie Algebras and I just encountered the notion of radical $R$ of a finite dimensional Lie algebra $L$ over a field $F$, the maximal solvable ideal. Since the dimension of $L$ is finite, every increasing chain of solvable ideals is bounded, then exists a maximal element, and since the sums of two maximal solvable ideals still remains solvable, the maximal solvable ideal above is unique (and then well defined).
Can we find some similar notions in the case $\dim_F (L)= \infty$?
In the construction above we have used that every chain of solvable ideals has an upper bound, that may be not true in the infinite dimensional case. For example, there is a way to build a Lie algebra with a series of ideals $0=I_0<I_1<I_2<\ldots$ in which $(I_{i+1})'= I_i$ (here $L'$ is the derivated algebra of $L$)?
If yes, this would means that the notion above of radical can't be extended, because $I=\bigcup_{j \ge 0}Ij$ would be not solvable.","['abstract-algebra', 'lie-algebras', 'ring-theory']"
1496856,How do you solve this limit involving definite integration?,"$$ \lim \limits_{r \to \infty} \frac {r^C \int_0^{\frac{\pi}{2}} x^r \sin(x)\, dx}{\int_0^{\frac{\pi}{2}} x^r \cos(x)\, dx} = L$$ Find the value of $\pi L - C$, given that $C\in\mathbb{R}$ and $L>0$. My approach: I tried to apply integration by parts to both the numerator and denominator to get a recurring relation, hoping to cancel something off, but to no avail. I'm not getting any other method to solve it, so any help will be appreciated.","['calculus', 'limits', 'definite-integrals', 'integration']"
1496875,Proof that the preimage of generated $\sigma$-algebra is the same as the generated $\sigma$-algebra of preimage.,"This question has also been asked here , but the answer there didn't help me. I am trying to prove that, given some measurable space $(X, \Sigma)$, if $G$ is a collection of subset of $X$ such that $\sigma(G) = \Sigma$, then
$$f^{-1}(\sigma(G)) = \sigma(f^{-1}(G)).$$
So far, I have been able to show that $\sigma(f^{-1}(G)) \subseteq f^{-1}(\sigma(G))$, but I am having trouble with the opposite inclusion. I have shown that $f^{-1}(G)$ is a $\sigma$-algebra, from which it follows that $f^{-1}(G) \subseteq \sigma(f^{-1}(G))$, but that's about all I have been able to show. How do I proceed from there? The answer in the other question suggests the following approach:
Prove that $f^{-1}(G) \in \sigma(f^{-1}(G))$, if $f^{-1}(A_i) \in \sigma(f^{-1}(G))$ for $i \in \mathbb{N}$ (i.e. a countable collection), then $f^{-1}(\bigcup_i A_i) \in \sigma(f^{-1}(G))$, and if $f^{-1}(A) \in \sigma(f^{-1}(G))$ then $f^{-1}(Y \setminus A) \in \sigma(f^{-1}(G))$. However, I am not sure how to actually prove this, and even then, I'm not sure how it follows from this that $f^{-1}(\sigma(G)) \subseteq \sigma(f^{-1}(G))$.","['elementary-set-theory', 'measure-theory']"
1496895,"Mean of values ${1 \over m} {\sum_{i=1}^m {s_i \over t_i}}$ vs. Value of sums ${\sum_{i=1}^m {s_i} \over \sum_{i=1}^m {t_i}}$, What is the relation?","Similar to: Average of products VS. product of averages I have $$
R = \{(s_1, t_1), (s_2, t_2), ..., (s_n, t_n)\}
$$ With the property that, for all pairs $(s_i, t_i)$, $0 \le s_i < t_i$. $$
\forall (s_i, t_i) : 0 \le s_i < t_i
$$ The value of one pair, $(s_i, t_i)$ is $s_i \over t_i$ I want to select an $m$ sized subset where $m < n$ that maximizes value. One way to compute the value of a subset $P \subseteq R$ is to take the mean of the values of the individual pairs: $$p(P) = {1 \over m} {\sum_{i=1}^m {s_i \over t_i}}$$ Another way is to compute the value of the summed individual elements from the pairs: $$q(P) = {\sum_{i=1}^m {s_i} \over \sum_{i=1}^m {t_i}}$$ Let $P'$ be the subset $P$ of size $m$ such that $p(P)$ is maximized.  (This is easy.  Select the $m$ elements of $R$ with highest value.) Let $Q'$ be the subset $Q$ of size $m$ such that $q(Q)$ is maximized. (I think this requires combinatorial search.) What is the relationship between $p(P')$ and $q(Q')$? Will $p(P') \le q(Q')$ always? Which is the truer maximum value?","['data-analysis', 'sequences-and-series', 'statistics']"
1496912,"Find $\lim\limits_{(x,y)\to(0,0)}\frac{e^{x^2+y^2}-x^2-y^2-1}{(x^2+y^2)^2}$","We have to calculate this limit of the multivariable function:
$$\lim\limits_{(x,y)\to(0,0)}\frac{e^{x^2+y^2}-x^2-y^2-1}{(x^2+y^2)^2}$$
By setting $z=x^2+y^2$ then $z\to 0$ when $(x,y)\to(0,0)$, so if we apply de l'Hopital's rule twice, we find that the limit is equal to $\frac{1}{2}$. Now, I'm trying to calculate it by using the Squeeze Theorem (I've tried by using the ε-δ definition, without a result). My thoughts so far: I have tried to use the inequality $(x^2+y^2)^2\geq 2x^2y^2$ in order to overcome the problem that the denominator=0 and after some algebraic manipulation I can't get a result. Another thing I've tried is to use polar coordinates, but it doesn't seem to give an inequality. What can I do? Thanks in advance!","['calculus', 'limits']"
1496931,How is $\sin x < x < \tan x$ the same as $x \cos x < \sin x < x$,How is $$\sin{x} < x < \tan{x} $$ the same as $$x \cos{x} < \sin{x} < x$$ when $x$ is $0 < x < \pi/2$?,"['algebra-precalculus', 'trigonometry']"
1496972,"Let $\left\{\Delta_1,\Delta_2,.....,\Delta_n\right\}$ be the set of all determinants of order 3 that can be made with the distinct real numbers","Let $\left\{\Delta_1,\Delta_2,.....,\Delta_n\right\}$ be the set of all determinants of order 3 that can be made with the distinct real numbers from the set $S=\left\{1,2,3,4,5,6,7,,8,9\right\}$.Then prove that $\sum_{i=1}^{n}\Delta_i=0$ I know that the total number of determinants that can be formed by using distinct real numbers from the given set is $9!$.But i dont know how to prove that their sum is zero.Please help me.Thanks","['determinant', 'linear-algebra']"
1496973,How many such ways to group 2n students?,"I don't understand something very simple at the beginning of the course in combinatorics. There are $2n$ students in class. They divide to couples to do homework. How many such options of dividing there is ? $$\frac{(2n)!}{2^n\cdot n!}$$ so $(2n)!$ are all the options, $n!$ is the different amount of ordering $n$ couples. Why and what is this $2^{n}$?",['combinatorics']
1497001,Connected components of a graph,"If we have a graph $G$ and $e$ is an edge in this graph. Now I want to
show that $G − e$ has at most one more connected component than $G$ . Now
if we remove one vertex  from $G$ , by how much can the number of
connected components can increase? I think we would have two cases if we remove an edge from a graph. (case 1) The graph is still connected, Meaning that every vertex has a path to every other vertex, in this case, The connected components are still the same. (Here the degree of the vertex is more than $1$ because the vertex is still connected to the graph , right ?) (case 2) The vertex has only this edge (Degree =1) and so the graph becomes disconnected, But I have a hard time arguing that it has at most one more connected component. Now, if we remove a vertex, this means that we remove all edges connected to this vertex, I did this for $k_3$ , $k_4$ to get sense of it, and still the connected components only increase by $1$ , is that true and how can I argue here?","['discrete-mathematics', 'graph-theory', 'connectedness', 'combinatorics']"
1497043,"Is there a function that's continuous and has all directional derivatives as a linear function of direction, but still fails to be differentiable?","There are many standard examples of functions $f:\mathbb{R}^2\to\mathbb{R}$ that possess all directional derivatives at a point and yet fail to differentiable or even continuous there. The most common counterexamples are not even continuous, e.g.
$$f(x,y)=\begin{cases}\frac{x^2y}{x^2+y^4}&(x,y)\neq(0,0)\\0&(x,y)=(0,0)\end{cases}$$
This example illustrates the easiest type of nondifferentiability given the existence of all directional derivatives, but I'm interested in more sophisticated pathologies -- how far we can go in improving the situation before we finally hit differentiability. The natural next step would be to impose continuity and yet still fail to achieve differentiability. A good example here is
$$f(x,y)=\sqrt[3]{x^2y}$$
This function is continuous at the origin, unlike the last example, and all its directional derivatives exist there, but it still fails to be differentiable. The easiest way to show this is to note that the partials are zero, but there are directional derivatives $D_u$ that are nonzero, so the directional derivative $D_u$ cannot be given by a linear function of the direction $u$ for all $u$. The problem is that the directional derivative isn't a linear function of the direction. The next step would be to ask for both continuity and all-directional-derivatives-exist-as-a-linear-function-of-direction and yet still fail to achieve differentiability. The example given in this answer is not continuous, so it shows only that the second condition alone doesn't imply differentiability. What if we impose continuity? I'm almost certain there is such a counterexample, but I can't think of one, nor could I find one in a quick glance at Courant, Apostol, or Munkres. Showing nondifferentiability here would be harder, since the standard arguments, discontinuity and the failure of the directional derivative operator to be linear, aren't available. Presumably the trick will be to have something go wrong along a nonlinear path even though everything goes right linearly.","['multivariable-calculus', 'real-analysis', 'examples-counterexamples']"
1497054,"Find necessary and sufficient conditions so that $(0,0)$ is stable.","Suppose we have the system
$$
\left(\begin{array}{c} \dot{x} \\ \dot{y} \end{array}\right) = \left(\begin{array}{c} f(x) + y \\ g(x) \end{array}\right).
$$
Here $f,g: \mathbb{R} \to \mathbb{R}$ are smooth analytic functions of $x$ such that
$$
\lim_{x\to 0} \frac{f(x)}{x^k}
$$
and
$$
\lim_{x\to 0} \frac{g(x)}{x^l}
$$
exists and are non-zero for some $k, l \geq 2$. What are necessary and sufficient conditions on $f$ and $g$ so that $(0, 0)$ is (asymptotically) stable? I have no idea where to start. I thought it has to do something with the signs of $f$ and $g$ near $0$, but the $y$ term causes a disturbance, and I don't know how to handle that, so to say.","['dynamical-systems', 'ordinary-differential-equations']"
1497061,Why do I see $\sqrt{\sin^2\theta}=\sin\theta$ in integration solutions?,"I am trying to integrate: $$\int x \sqrt{-x^2+6x-8} \ dx $$ After a substitution $x-3=\cos \ \theta$, I got that the integral written above is equal to: $$\int (\cos \ \theta +3)\sqrt{\sin^2 \ \theta}(-\sin \ \theta \ d\theta)$$ I see often in problem solutions on the internet, that you write $\sin \ \theta$ instead of the square root  above. After that step, integration is something I know how to do. My question is stated in the question topic. Why can we say that the square root is equivalent to $\sin$? Can't the $\sin$ be negative? Could you provide me with an explanation? Cheers.","['trigonometry', 'indefinite-integrals', 'integration']"
1497066,What is the smallest possible value of $\lfloor (a+b+c)/d\rfloor+\lfloor (a+b+d)/c\rfloor+\lfloor (a+d+c)/b\rfloor+\lfloor (d+b+c)/a\rfloor$?,"What is the smallest possible value of $$\left\lfloor\frac{a+b+c}{d}\right\rfloor+\left\lfloor\frac{a+b+d}{c}\right\rfloor+\left\lfloor\frac{a+d+c}{b}\right\rfloor+\left\lfloor\frac{d+b+c}{a}\right\rfloor$$ where $a,b,c,d>0$?","['contest-math', 'ceiling-and-floor-functions', 'algebra-precalculus']"
1497079,Relation between $SO(n)$ and rotations,"We often consider $SO(n)$ as the group of rotations in $\mathbb{R}^n$ in the sense that the usual action of $SO(n)$ on $\mathbb{R}^n$ by matrix multiplication can be interpreted as a rotation operation in $\mathbb{R}^n$. Although I've always used this fact, I never had an intuitive understanding of why is that. Basically, we know that the linear transformation associated to a matrix $A$ is inner product preserving if and only if $A\in O(n)$. In truth, if $A\in O(n)$ then we know that $AA^T = I$ and hence $$\langle Ax, Ay\rangle=\langle x, A^TA y\rangle = \langle x,y\rangle , \quad \forall x,y\in \mathbb{R}^n.$$ Furthermore, if $A$ is inner product preserving, then $A\in O(n)$. Then we have two possible choices, $\det(A) = +1$ and so $A\in SO(n)$ and $\det(A) = -1$ and $A\in O(n)\setminus SO(n)$. In that case, an element of $SO(n)$ is simply one inner product preserving linear transformation, that is, which doesn't change angles nor lengths, and which has determinant $+1$. Now, from this rigorous definition of the elements of $SO(n)$ how can one see that the elements of $SO(n)$ can be though of as rotation operators? Why rotation is related to the elements of that group and how can one arrive at the definition of $SO(n)$ in trying to define properly the group of rotations?","['lie-groups', 'geometry', 'group-theory', 'linear-algebra', 'intuition']"
1497092,Over the reals the intersection of the orthogonal and symplectic groups in even dimension is isomorphic to the unitary group in the half dimension.,"See the answer here . Over the reals the intersection of the orthogonal and symplectic groups in even dimension is isomorphic
  to the unitary group in the half dimension:$$ U(n) = O(2n, \mathbf{R}) \cap Sp(2n, \mathbf{R}).$$ To me, this is not so obvious. How do we see this without just saying ""oh, that's trivial, cite the ""2-out-of-3 property""?","['multilinear-algebra', 'abstract-algebra', 'group-theory', 'linear-algebra', 'symplectic-geometry']"
1497118,Computing Lyapunov Exponents,"Consider $\mathcal{T}=S^{1}\times D^{2}$, where $S^{1}=[0,1]\mod 1$ and $D^{2}=\{(x,y)\in\mathbb{R}^{2}|x^{2}+y^{2}\le 1\}$. Fix $\lambda\in(0,\frac{1}{2})$ and define the map $F:\mathcal{T}\to\mathcal{T}$ by $$F(\phi,x,y)=\left(2\phi,\lambda x+\frac{1}{2}\cos 2\pi\phi,\lambda y+\frac{1}{2}\sin 2\pi\phi\right)$$ Then define the Lyapunov exponent $\chi(x,v)$ by $$\chi(x,v)=\overline{\lim_{n\to\infty}}\frac{1}{n}\log\|df^{n}(x)v\|$$. So I wrtie $$\chi(\phi,x,y,v)=\overline{\lim_{n\to\infty}}\frac{1}{n}\log\|dF^{n}(\phi,x,y)v\|$$ The problem is that I calculate $\frac{\partial}{\partial y\partial x\partial\phi}F(\phi,x,y)=0$. I think that's the wrong way of going about it anyway. I also have that $F^{n}(\mathcal{T})\cap\{\phi=constant\}$ consists of $2^{n}$ disks of radius $\lambda^{n}$, but I need help with calculating $dF^{n}(\mathcal{T})$.","['ergodic-theory', 'ordinary-differential-equations', 'dynamical-systems', 'exponential-function', 'lyapunov-exponents']"
1497152,"Measure Theory: Prove that $\mu( \cap_{k \in \mathbb{N}}B_k)=1$ given $\mu(B_k)=\mu(B)=1$, $B_k \subset B$ for all $k \in \mathbb{N}$","Problem: For a measurable space $(\Omega, \mathcal{A}, \mu)$ with measure $\mu: \mathcal{A} \to [0, \infty]$ Let $B \in \mathcal{A}$ and $(B_k)_{k \in \mathbb{N}} \subset \mathcal{A}$ be a sequence such that $B_k \subset B$ for all $k \in \mathbb{N}$. Prove that if $\mu(B)=\mu(B_k)=1$ for all $k$ then $\mu( \cap_{k \in \mathbb{N}}B_k)=1$ My approach : It doesn't take much effort to show that $$ \mu \left(  \bigcap_{k \in \mathbb{N}} B_k\right) \leq 1 $$
Because certainly: $$\bigcap_{k \in \mathbb{N}} B_k \subset B_k \text{ for every } k \in \mathbb{N} \implies \mu \left(  \bigcap_{k \in \mathbb{N}} B_k\right) \leq \mu(B_k)=1 $$ because the measure $\mu$ is monotone. My problem is the less obvious inequality, namely $$  \mu \left(\bigcap_{k \in \mathbb{N}} B_k \right) \geq 1 $$ I haven't made use of the fact that $\mu(B)=1$ but I also don't believe that $$\bigcup_{k \in \mathbb{N}} B_k = B $$ is true. Any hints for the missing inequality? The problem at hand clearly being that $\cap_{k \in \mathbb{N}} B_k$ cannot easily be approximated from below, thus the only possible way might be to bring the strict inequality $$ \mu \left( \bigcap_{k \in \mathbb{N}} B_k \right)< 1 $$ to a contradiction.","['analysis', 'measure-theory']"
1497174,Does the amount of translation for depends on whether it goes before or after dilation?,"One question in my practice book, asks me to describe $y=f(-ax+b)$ based on y=f(x). According to the book, the order of transformation must be listed in this order: Reflection Dilation (scaling) Translation So the first step in describing is to factor out the scale factor and get $-a(x-\frac{b}{a})$. My question is, is the order my book gives used in the mathematical world and not just on the test I am taking. There are  two ways of looking at what the translation applied to the equation is. Before dilation happen, translation is b units to the right. But after it, translation is only b/a units to the right.","['graphing-functions', 'algebra-precalculus', 'functions']"
1497181,Definition of identity law in the laws of proposition,"I'm sure this is an easy one but I'm struggling. From my notes, there's this example on how to simplify a proposition using proposition laws: p $\lor$ (p$\land$  q) $\equiv$  (p $\land$ t) $\lor$ (p $\land$ q) identity law $\equiv$ p $\land$ (t $\lor$ q) distribution law $\equiv$ p $\land$ t identity law $\equiv$ p identity law I just can't get my head round how the identity law works. Reading up, I found that: p $\land$ T ≡ p p $\lor$ F ≡ p p $\lor$ T ≡ T domination law p $\land$ F ≡ F domination law However, I have been unable to find what T is. Does it stand for Truth and F false? If so, why does p AND T = p? What is the value of p? What is happening in the example then? Please could someone explain this to me I also included the domination law since it uses T and F again which is alien to me). Also, on the second line, how does 
p $\land$ (t $\lor$ q) $\equiv$ p $\land$ t. What happens to q? Thanks in advance","['logic', 'propositional-calculus', 'discrete-mathematics']"
1497189,Mutually exclusive countable subsets of a countable set,"This is part of a bigger problem I'm trying to prove, but my argument relies of the validity of the following idea. Note that when I say countable, I don't mean finite -- I mean countable infinity. Consider the set of natural numbers, $\mathbb{N}$. Now take a countable subset of them, call it $\mathsf{S}_1$. Then take a countable subset of $\mathbb{N}\setminus{\mathsf{S}_1}$ and call it $\mathsf{S}_2$. Then take a countable subset of $\mathbb{N}\setminus\{{\mathsf{S}_1}\cup{\mathsf{S}_2}\}$ and call it $\mathsf{S}_3$. Continue in this manner to construct $\mathsf{S}_i$'s such that ${\mathsf{S}_i}\cap{\mathsf{S}_j}=\emptyset$ for $i≠j$. My question is this: is it necessarily the case that eventually there will be finitely many $\mathsf{S}_i$'s with $\mathbb{N}\setminus\bigcup_{i}{\mathsf{S}_i}={P}$ where $P$ is either empty or finite? My guess is yes, but I'm not how to prove it or how to find a counterexample.",['elementary-set-theory']
1497200,Dirac delta - sifting,"We know
$\int_{-\infty}^\infty \delta(x-a)f(x) \, dx=f(a)  $ Is this still true for:
$\int_{-\infty}^\infty \delta(a-x)f(x) \, dx=f(a)  $ In general, can we call dirac delta even function?","['dirac-delta', 'integration']"
1497270,Prove $x^{4}-x+1=0$ has no solution,"I would like to prove that the following equation has no solution in $\mathbb{R}$
   $$x^{4}-x+1=0$$ my question : could we use  Intermediate Value Theorem to prove it otherways I'm interested in more ways of prove that has no solution in $\mathbb{R}$. without : i know that we can prove it by that way : $x=x^4+1\geq 1$ and $x^4-x+1=x^2(x^2-1)+x^2-x+1>0$","['analysis', 'calculus', 'real-analysis']"
1497275,An exercise about Lebesgue integrable functions & convergence,"Let $(\Omega ,F,\mu)$ a be a measure space & $\{f_n\}$ a  sequence of nonnegative Lebesgue integrable functions.
If $\{f_n\}$ converges in measure  to function $f $ & the integrals converges to $\int_\Omega f < \infty $, prove that  $\int_\Omega |f_n -f|\,d\mu$ converges to  $0$, when  $n $ goes to  infinity. It seems easy, but I didn't success. Help me please.","['lebesgue-integral', 'real-analysis', 'measure-theory', 'integration']"
1497294,How to find a sensible approximation of $R\dot{\theta}^2+\ddot{\theta}(R\theta-l)+g\cos\theta=0$,"The differential equation  $$R\dot{\theta}^2+\ddot{\theta}(R\theta-l)+g\cos\theta=0$$ is derived from considering a pendulum attached to the uppermost part of a disk. As in the picture above (but remember the string is attached to the intersection with the y-axis). Anyways, I was approximating this by considering small oscillations, as usual. To end up with something like $$\ddot{\theta}+\frac{R\dot{\theta}}{R\theta_0-l}+\frac{g\cos\theta_0}{R\theta_0-l}=0$$ But this has a complex solution, and a real valued log function, which doesn't seem like an oscillation at all or physically sound. The solution manual to my book approximates the equation as
$$\ddot{\epsilon}+\frac{g\sin\theta_0}{l-R\theta_0}\epsilon=\frac{g\cos\theta_0}{l-R\theta_0}$$
Where $\epsilon=\theta-\theta_0$. The equation doesn't make sense to me, especially the second term on the LHS. So I was wondering if you guys could help me. Perhaps give me a hint or two... Or perhaps tell me what the author of the solutions manual did? Thanks!","['physics', 'ordinary-differential-equations']"
1497328,"Nature of $G$ when $N$ is cyclic, normal subgroup of $G$ and $G/N$ is cyclic","Let $N$ be a normal subgroup of $G$ and both groups $N$ and $G/N$ are cyclic. I need to prove that $G$ is generated by at most two elements. To that effect, what sorts of things do we know about $G$ if $N$ is a subgroup of $G$ and $N$ and  $G/N$ are both cyclic? I know that all cyclic groups are abelian, so $N$ and $G/N$ must both be abelian as well. Does that necessarily mean that $G$ itself is abelian? Or cyclic? Really, I am having a lot of trouble proving that $G$ is generated by at most two elements, especially in the case where $G$ is generated by a single element (i.e., is cyclic) and showing that it is not possible for $G$ to be generated by more than two elements. Could somebody please provide me with insight into this? Thank you.","['abstract-algebra', 'group-theory', 'normal-subgroups', 'cyclic-groups']"
1497459,Can we extend the group action from subgroups?,"Let $G$ be a group and $H,K$ be subgroups of $G$ such that $G=<H,K>$. Suppose that $H,K$ acts on the set $S$. Is there any condition that which guarantees that action of $H,K$ is extended to action of $G$ ? What I mean can we define action of $G$ by the actions of $H,K$ ? Probably we need some compability conditions. What are they ?","['group-theory', 'group-actions']"
1497484,Show that multiplicative order mod p exists and that it divides (p-1),"Let $p$ be some odd prime.  Let $r$ be the smallest natural number such that $x^r \equiv 1 \pmod{p}$ for some $x \in \mathbb{F}_p^{\times}$. Prove that such an $r$ exists, and that it divides $(p-1)$. My thoughts: that it exists seems trivial.  The field is finite, so all elements must have some finite order?  Not sure how to state this rigorously though.  For $r \mid (p-1)$ I'm thinking Lagrange's theorem seems an obvious choice.  Guidance appreciated.","['group-theory', 'finite-groups', 'elementary-number-theory', 'finite-fields']"
1497491,Use Sylvestor's Criterion to classify the critical point?,"I am asked to find and classify the critical point of $g(x,y,z) = xy-x+2z-x^2-y^2-z^2$ I have calculated the derivative and found that the critical point is at $(-\frac23, -\frac13, 1)$ I have found the Hessian matrix = 
$$
\left[\matrix{-2 & 1 & 0\\1 &-2 & 0\\0 &0 &-2}\right]
$$ But when I calculate the leading principle minors, I get $-2$, $3$ and $-6$. Wolframalpha tells me that this point is a maximum, so I should be getting all negative values to make the matrix negative definite. Where am I going wrong?","['optimization', 'calculus', 'multivariable-calculus', 'matrices']"
1497528,Proving convergence by the comparison test,"I need to prove the convergence of the following series :
$$\sum_{n=1}^{\infty} \frac{1}{(3n-2)(3n+1)}$$ I suppose I need to find two series like
$$\sum_{n=1}^{\infty}(k_1a_n + k_2b_n) = \sum_{n=1}^{\infty} = k_1\sum_{n=1}^{\infty}a_n  + k_2\sum_{n=1}^{\infty}b_n$$ I thought that the series $a_n$ and $b_n$ can be the partial sums, so
$$\sum_{n=1}^{\infty} \frac{1}{(3n-2)(3n+1)} =  \frac{1}{3}\sum_{n=1}^{\infty} \frac{1}{(3n+1)} - \frac{1}{3}\sum_{n=1}^{\infty} \frac{1}{(3n-2)}$$ I know, by the comparison test, that if $a_n$ and $b_n$ converge, the main series will it too. But, how can I demonstrate that the series $a_n$ and $b_n$ converge?","['summation', 'real-analysis', 'sequences-and-series', 'analysis', 'convergence-divergence']"
1497540,Proving the inverse of a matrix as a polynomial of matrices,"Suppose $A$ is invertible $n\times n$ matrix. Show that $A^{-1}$ can be written as a polynomial of degree at most $n-1$, i.e. $$A^{-1} = c_{n-1}A^{n-1} + \dots + \ c_{1}A + c_{0}I$$ Are there any tips on how may this proof be approached?","['matrix-equations', 'linear-algebra', 'matrices']"
1497556,Is there a formula for the cosine of 1/5 of an angle?,"I'm trying to find a formula for $\cos \frac{x}{5} $ as follow. By the elementary trigonometric identity, $\cos 5x = 16\cos^5 x - 20\cos^3 x + 5\cos x$ By putting $x=  \frac{x}{5}$ , and using the change of variable $ y = \cos \frac{x}{5} $, we get the quintic equation $ 16y^5 - 20y^3 + 5y - \cos x = 0$. If we can solve this equation by radicals, then we can get a formula for $\cos \frac{x}{5} $ However, I can not see how we can resolve this equation. Is this a solvable quintic equation? If so, how can we solve it by radicals?",['trigonometry']
1497590,Ratio estimator in sampling,"Let the population $U=(1,2,3)$ . We want to estimate $R=\frac{\mu_y}{\mu_x}$ .Consider the estimators $$\hat{R_1}=\frac{\overline{y}}{\overline{x}},\hat{R_2}=\frac{\overline{y}}{\mu_x}$$ where $Y=(9,42,53)$ and $X=(1,4,5)$ . Find the distributions of the estimators and their bias. Consider the sample size $n=2$ Considering a simple random sample without replacement, we have that $S=[(1,2),(1,3),(2,3)]$ $$\begin{bmatrix}s:&12&13&23\\\hat{R_1}: &10.2&10.33&10.55\\ p:&1/3&1/3&1/3 \end{bmatrix}$$ Just to ilustrate, taking $s=(1,2)$ I did $$\frac{\overline{y}}{\overline{x}}=\frac{(\frac{9+42}{2})}{(\frac{1+4}{2})}=10.2$$ but solutions say that the distribution is $$\begin{bmatrix}s:&12&13&23\\\hat{R_1}: &0.098&0.097&0.095\\ p:&1/3&1/3&1/3 \end{bmatrix}$$ It is as if they had done $$\hat{R_1}=\frac{\overline{X}}{\overline{Y}}$$ Could anyone help me?","['estimation', 'statistics', 'sampling']"
1497595,"If $v$ is an eigenvalue of $e^{t A}$ for all $t \geq 0$, is it also an eigenvalue of $A$?","I'm currently writtng a proof and I wont use that, if $v$ is an eigenvector of $e^{tA}$ for all $t \geq 0$ where $A$ is some generating matrix, then $v$ is an eigenvector of $A$ itself. However, I found neither the proof nor a contradiction in available sources. The case of diagonalisable matrices is self-evident as  a popular computation approach utilises this fact. However, it is still unclear for me if  the same is true for non-diagonalisable matrices at least for the case of basic (non generalised) eigenvectors. Recalling Jordan structure  I think that all kinds of eigenvectors are preserved. But are there any better rigorous proof for this conjecture to make me totally confident? Can this fact be assumed as obvious?","['linear-algebra', 'matrices']"
1497615,Dense subspace of the space of functions vanishing at infinity,"How can I show that the space of smooth functions with compact support, $C^{\infty}_K$, is dense in the space of continuous functions vanishing at infinity equipped with the supremum norm, $(C_0,|| \cdot ||_{\infty})$ ? I already know that the space of continuous functions with compact support, $C^0_K$, is dense in $C_0$, so it suffices to show that $C^{\infty}_K$ is dense in $C^0_K$.","['analysis', 'real-analysis', 'functional-analysis', 'functions']"
1497637,How to evaluate the definite integral by the limit definition $\int_{-1}^1 x^3 dx$?,"Solve the definite integral by the limit definition: $$\int_{-1}^1 x^3 dx$$ The formula: $$\int_a^bf(x)dx= \lim_{n\rightarrow \infty} \sum_{i=1}^n f(c_i)\Delta x_i$$ Get the variables: $$\Delta x_i : \frac{b-a}{n} = \frac{1-(-1)}{n} = \frac{2}{n}$$ $$f(c_i) : a + i(\Delta x_i) = \left(-1+\frac{2i}{n}\right)$$ Now plug them into the formula I get: $$\lim_{n\rightarrow \infty} \sum_{i=1}^n \left(-1+\frac{2i}{n}\right)^3\left(\frac{2}{n}\right)$$ Take out the delta and distribute the cube: $$\lim_{n\rightarrow \infty} \left(\frac{2}{n}\right) \sum_{i=1}^n \left(-1+\frac{2i}{n}\right)^3 = \lim_{n\rightarrow \infty} \left(\frac{2}{n}\right) \sum_{i=1}^n \left(-1+\frac{8i^3}{n^3}\right) $$ Expand the summation and take out constants, and properties of Simga: $$\lim_{n\rightarrow \infty} \left(\frac{2}{n}\right) \left[- \sum_{i=1}^n 1+ \frac{8}{n^3} \sum_{i=1}^n i^3\right] = \lim_{n\rightarrow \infty} \left(\frac{2}{n}\right) \left[-n + \frac{8}{n^3}\left( \frac{n^2(n+1)^2}{4}\right)\right]$$ Distribute the $\frac{2}{n}$ and simplify: $$\lim_{n\rightarrow \infty}\left[-2 + \frac{16}{n^4}\left( \frac{n^2(n+1)^2}{4}\right)\right] = \lim_{n\rightarrow \infty}\left[-2 + \frac{4}{n^2}\left( \frac{n^2+2n+1}{1}\right)\right]$$ Distribute and simplify/cancel: $$\lim_{n\rightarrow \infty}\left[-2 + \frac{4n^2}{n^2} + \frac{8n}{n^2} + \frac{4}{n^4}\right] = \lim_{n\rightarrow \infty}\left[-2 + 4 + \frac{8}{n} + \frac{4}{n^4}\right] $$ I keep getting the limit is -2 (-2+4), but the book says it's 0. Where did I go wrong?","['calculus', 'limits', 'definite-integrals', 'integration']"
1497640,Proof of uniform continuity of with sequences of functions,"Let ${f_n}$ be a sequence of continuous functions such that $f_n \rightarrow f$ uniformly on $R$. Suppose that $x_n \rightarrow x_0$. Prove that $$\lim_{n\to\infty} f_n(x_n)=f(x_0)$$ I really don't know where to start on this, can someone help me prove this? Thank you!","['sequences-and-series', 'calculus', 'real-analysis', 'limits']"
1497662,How much do we really care about Riemann integration compared to Lebesgue integration?,"Let me ask right at the start: what is Riemann integration really used for ? As far as I'm aware, we use Lebesgue integration in: probability theory theory of PDE's Fourier transforms and really, anywhere I can think of where integration is used (perhaps in the form of Haar measure, as a generalization, although I'm sure this is vastly incomplete picture). Let me state a well known theorem: Let $f:[a,b]\to\mathbb R$ be bounded function. Then: (i) $f$ is Riemann-integrable if and only if $f$ is continuous almost everywhere on $[a,b]$ (with respect to Lebesgue measure). (ii) If $f$ is Riemann-integrable on $[a,b]$, then $f$ is Lebesgue-integrable and Riemann and Lebesgue integrals coincide. (I will try to be fair, we use this result and Riemann integration to calculate many Lebesgue integrals) From this we can conclude that Riemann-integrability is a stronger condition and we might naively conclude that it might behave better. However it does not; Riemann integral does not well behave under limits, while Lebesgue integral does: we have Lebesgue monotone and dominated convergence theorems. Furthermore, I'm not aware of any universal property of Riemann integration, while in contrast we have this result presented by Tom Leinster; it establishes Lebesgue integration as initial in appropriate category (category of Banach spaces with mean). Also, I'm familiar with Lebesgue-Stiltjes integral, greatly used for example in probability theory to define appropriate measures. I'm not so familiar with the concept or usage of Riemann-Stiltjes integral, and I'd greatly appreciate if someone could provide any comparison. As far as I can tell, the only accomplishment of Riemann integration is the Fundamental theorem of calculus (not to neglect it's importance). I'm very interested to know if there are more important results. To summarize the question: Where is Riemann integral used compared to Lebesgue integral (which seems much better behaved) and why do we care? Update: It seems that it is agreed upon that Riemann integration primarily serves didactical purpose in teaching introductionary courses in analysis as a stepping stone for Lebesgue integration in later courses when measure theory is introduced. Also, improper integrals were brought as an example of something Lebesgue integration doesn't handle well. However, in several answers and comments we have another notion - that of a gauge integral (Henstock–Kurzweil integral, (narrow) Denjoy integral, Luzin integral or Perron integral). This integral not only generalizes both Riemann and Lebesgue integration, but also has much more satisfactory Fundamental theorem of calculus: if a function is a.e. differentiable than it's differential is gauge-integrable and conversely function defined by gauge integral is a.e. differentiable (here almost everywhere means everywhere up to a countable set). Thank you for all the answers. This question should probably be altered to the following form (in more open-ended manner): What are pros and cons of different kinds of integrals, and when should we use one over the other?","['riemann-integration', 'real-analysis', 'lebesgue-integral', 'integration']"
1497667,Product $\sigma$-algebra in countable case (Proposition 1.3 in Folland),"In the real analysis, by Folland , p. 23: I know $\prod_{\alpha\in A}E_{\alpha}=\bigcap_{\alpha\in A}\pi_{\alpha}^{-1}(E_{\alpha})$. But I cannot figure out why the product $\sigma$-algebra in the countable case should be defined in $\bigcap_{\alpha\in A}\pi_{\alpha}^{-1}(E_{\alpha})$. And I have no idea of ""The result therefore follows from Lemma 1.1"". The following is the general definition of product $\sigma$-algebra (on p.22) (It does not say anything about the intersection): The following is the Lemma 1.1: I can understand this Lemma, however, what does this Lemma relate to that proposition?",['real-analysis']
1497695,Kolmogorov 0-1 law and terminal sigma algebra,I was wondering about the following: Assume $X : \Omega \rightarrow S$ is measurable w.r.t. a terminal sigma algebra on $\Omega$ and some sigma algebra on $S$. What are the requirements we have to put on $S$ such that $X$ is constant a.s. I know that it holds for $S= \mathbb{R}$ but what about more general sets $S$?,"['probability-theory', 'probability', 'stochastic-processes', 'measure-theory']"
1497740,Conditional Expectation and Interpretation of Projection of $Y$ Onto $X$ vs. $Y$ onto $L^{2}(\sigma(X))$,"Suppose $X,Y\in L^{2}(\Omega,\mathcal{F},\mathbb{P})$ are real-valued square-integrable random variables and that the joint density of $(X,Y)$ denoted by $f_{XY}(x,y)$ exists. Then as is well-known, the conditional expectation of $Y$ given $X$ can be computed explicitly by the following formula (where we have used $X(\omega)$ instead of $X=x$ to emphasize that the conditional expectation is a fully-fledged random variable that is merely $\sigma(X)$-measurable): $$\begin{align*}
(1)\;\;\;\;\mathbb{E}[Y|X](\omega)
&=\int_{-\infty}^{\infty}y\;f_{XY}(X(\omega),y)\;dy\;\Bigg/\;\int_{-\infty}^{\infty}f_{XY}(X(\omega),y)\;dy
\\&=\frac{1}{f_{X}(X(\omega))}\int_{-\infty}^{\infty}y\;f_{XY}(X(\omega),y)\;dy.
\end{align*}$$ It is straight-forward to prove that
$$||Y-\mathbb{E}[Y|X]||^{2}_{L^{2}(\mathcal{F})}=\inf_{Z\in L^{2}(\sigma(X))}||Y-Z||^{2}_{L^{2}(\mathcal{F})},$$
which in turn proves (because conditional expectation is linear) that
$$\mathbb{E}[Y|X]=\mathbb{proj}_{L^{2}(\sigma(X))}Y,$$
i.e. the conditional expectation operator is really a projection operator from $L^{2}(\mathcal{F})$ to the closed subspace $L^{2}(\sigma(X))$. When I first learned about this fact I was tempted to assert that given $X$ we have
\begin{align*}
(2)\;\;\;\;\mathbb{E}[Y|X](\omega)
&\stackrel{?}{=}\frac{(X,Y)_{L^{2}}}{||X||_{L^{2}}^{2}}X(\omega)
\\&=\frac{\mathbb{E}[XY]}{\mathbb{E}[X^{2}]}X(\omega)
\\&=X(\omega)\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}xy\;f_{XY}(x,y)\;dxdy\;\Bigg/\;\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}x^{2}f_{XY}(x,y)\;dxdy
\end{align*}
because in a Hilbert space this can be thought of as the orthogonal projection of $Y$ in the direction of $X$.  However, the conditional expectation is an orthogonal projection into the entire subspace $L^{2}(\sigma(X))$, and so the formula above only holds for one random variable, namely
$$X(\omega)=\mathbb{E}[Y|X](\omega),$$
which defeats the purpose of using this formulation as a computational device for $\mathbb{E}[Y|X](\omega)$.  Of particular note, if $\sigma(Z)=\sigma(X)$ (which implies $Z\in L^{2}(\sigma(X))$), then
$$\mathbb{E}[Y|X](\omega)=\mathbb{E}[Y|Z](\omega).$$ Still I wonder, even if clearly wrong, whether (2) is known to be useful in any way.  So I have a couple of questions: Given $X$, can we easily find an orthonormal basis $\{X_{n}\}_{n>0}$ that spans $L^{2}(\sigma(X))$?  By easily, I mean in terms of the marginal and joint distributions of $X$ and $Y$, without explicit reference to whatever the underlying sample space looks like.  If so, then in principle (2) could be made valid by summing the formula over each $X_{n}$.  Of course, I think this would likely destroy the original motivation of finding an explicit way to represent the conditional expectation using the intuition of orthogonal projections. Can we relate (1) to such an orthonormal set $\{X_{n}\}_{n>0}$?  In particular, show that it arises from the sum of orthogonal projections. Are there any useful applications of orthogonal projection onto a particular random variable $X$ (as opposed to orthogonal projection onto an entire subspace $L^{2}(\sigma(X))$ which is represented by the conditional expectation).","['probability-theory', 'probability', 'hilbert-spaces', 'real-analysis']"
1497777,"Comparison of different topologies on the ordered square $[0,1]\times[0,1]$","$\newcommand{\R}{\mathbb{R}}$
$\newcommand{\T}{\mathcal{T}}$ This is textbook problem in Munkres' Topology. I know there are plenty of solutions online, but none of them are exactly the same as mine. I would really appreciate if anyone can review my solution to this problem and point out any mistakes and stuff that can be improved. Problem: Let$I=[0,1]$. Compare the product topology on $I\times I$, the dictionary order topology on $I\times I$, and the topology $I\times I$ inherits as a subspace of $\R\times \R$ in the dictionary order topology. Attempt: Let $\T_{1}$ denote the product topology on $I\times I$, $\T_{2}$
the dictionary topology on $I\times I$, $\T_{3}$ the topology inherits
as a subspace of $\R\times\R$ in the dictionary topology and let
$\mathcal{B}_{1},\mathcal{B}_{2}$ and $\mathcal{B}_{3}$ denote the
corresponding set of basis. Note that for an arbitrary element $B\in\mathcal{B}_{2}$,
we have 
\begin{align}
B & =\left\langle \left(a,b\right),\left(c,d\right)\right\rangle \\
 & =\left\{ a\right\} \times(b,1]\cup\left(a,c\right)\times[0,1]\cup c\times[0,d)\\
 & =\left(\left\{ a\right\} \times\left(b,2\right)\cap I\times I\right)\cup\left(\left(a,c\right)\times\left(-1,2\right)\cap I\times I\right)\cup\left(\left\{ c\right\} \times\left(-1,d\right)\cap I\times I\right)\\
 & =\left\{ \left[\left\{ a\right\} \times\left(b,2\right)\right]\cup\left[\left(a,c\right)\cup\left(-1,2\right)\right]\cup\left[\left\{ c\right\} \times\left(-1,d\right)\right]\right\} \cap\left(I\times I\right)
\end{align}
and notice that $\left[\left\{ a\right\} \times\left(b,2\right)\right]\cup\left[\left(a,c\right)\cup\left(-1,2\right)\right]\cup\left[\left\{ c\right\} \times\left(-1,d\right)\right]$
is open in the dictionary order topology of $\R\times\R$. Therefore,
we have $B\in\mathcal{B}_{3}$, which implies $\mathcal{T}_{2}\subset\mathcal{T}_{3}.$
Furthermore, we claim that $\mathcal{T}_{3}$ in fact strictly finer
than $\T_{2}$. Let $A=\left\{ 1/2\right\} \times(1/2,1].$ Since
we can rewrite $A=\left[\left\{ 1/2\right\} \times\left(1/2,3/2\right)\right]\cap\left(I\times I\right)$,
$A\in\T_{3}.$ However, suppose $A\in\mathcal{T}_{2};$ then $\exists\left\{ B_{i}\right\} _{i\in I}\in\mathcal{B}_{2}$
such that $A=\cup_{i\in I}B_{i}$. Since $\left(1/2,1\right)\in A$,
$\exists B_{i}=\left\langle \left(a_{i},b_{i}\right),\left(c_{i},d_{i}\right)\right\rangle $
such that $\left(1/2,1\right)\in B_{i}$. Note that we have $a_{i}=c_{i}=1/2$
since otherwise we would have $\cup_{i}B_{i}\neq A$. But $\left(1/2,1\right)\in B_{i}$
implies $\left(1/2,a_{i}\right)\prec\left(1/2,1\right)\prec\left(1/2,d_{i}\right)$,
which in turn implies $1<d\leq1$, a contradiction. Therefore, $A\notin\T_{2}.$ Next, we claim that $\mathcal{T}_{1}\subset\T_{3}.$ Indeed, by Problem
17 (which says the $\R_d\times\R$ is equal to $\R\times\R$ in dictionary order), we have $\T_{3}=\left(\R_{d}\times\R\right)\cap I\times I\supset\left(\R\times\R\right)\cap I\times I=\T_{1}.$
We also have that $\T_{1}$ and $\T_{2}$ are incomparable. To see
this, we first note that $\left\{ 1/2\right\} \times\left(1/3,2/3\right)=\left\langle \left(1/2,1/3\right),\left(1/2,2/3\right)\right\rangle \in\T_{3}$.
However, any open set in $\T_{2}$ containing $\left\{ 1/2,1/2\right\} $
will contain $\left\{ 1/2+\varepsilon,1/2\right\} $ for some $\varepsilon>0$.
Thus $\T_{2}\nsubseteq\T_{1}$. For this other direction, we have
$I\times(0,1]=\left(-1\times2\right)\times(0,2)\cap I\times I$ which
is in $\T_{1}$ but not in $\T_{2}.$ Indeed, suppose $I\times(0,1]\in\T_{2},$
then $(0,1)\in\mathcal{B}_{i}$ for some $B_{i}=\left\langle (a_{i},b_{i}),(c_{i},d_{i})\right\rangle \in\mathcal{B}_{2},$
which implies $\left(0,1\right)\prec\left(c_{i},d_{i}\right)$, which
indicates $c_{i}>0$. Then we have $\left\langle \left(0,1\right),\left(c_{i},d_{i}\right)\right\rangle =\left[\left(0,c_{i}\right)\times\left[0,1\right]\right]\cup\left[\left\{ c_{i}\right\} \times[0,d_{i})\right]$
containing $\left(c_{i},0\right)$ which is not in $I\times(0,1].$
Hence, $\T_{2}$ and $\T_{1}$ are incomparable.","['proof-verification', 'general-topology']"
1497800,Inequality between 2 norm and 1 norm of a matrix,"When reading Golub's ""Matrix Computations"", I came across a series of norm inequalities. While I could prove a lot of them, this one has me stuck:
$$ \frac{1}{\sqrt{m}} ||A||_1 \le ||A||_2 \le \sqrt{n}||A||_1$$
where $A \in \mathbb{R}^{m\times n},$ $||A||_1 = \displaystyle \max_{j \in [1,n]} \sum_{i=1}^m |a_{ij}|$ and $||A||_2 = \max_{||x||=1}||Ax||_2$, where $||Ax||_2$ is the standard Euclidean norm of the vector $Ax$. I know that $||A||_2 = \max \sigma(A)$ (maximum singular value of $A$), in case that's useful. Help?","['normed-spaces', 'matrices']"
1497825,Why can't $p^p-(p-1)^{p-1}=n^2$ be a square?,"Let $p$ be a prime number. Show that $p^p-(p-1)^{p-1}$ can't be a square. In other words, there is no $n\in\mathbb{N}^{+}$ such that
$$p^p-(p-1)^{p-1}=n^2.$$","['contest-math', 'prime-numbers', 'number-theory', 'diophantine-equations', 'elementary-number-theory']"
1497894,How to compute the limit $\lim_{n \to \infty} \sqrt[n]{a_1^n + \cdots + a_m^n}$? [duplicate],"This question already has an answer here : The $ l^{\infty} $-norm is equal to the limit of the $ l^{p} $-norms. [duplicate] (1 answer) Closed 4 years ago . Let $a_1, \ldots, a_n > 0$. How to compute the limit $\lim_{n \to \infty} \sqrt[n]{a_1^n + \cdots + a_m^n}$? My solution: 
$$
\lim_{n \to \infty} \sqrt[n]{a_1^n + \cdots + a_m^n} \\
= \lim_{n \to \infty} (1 + a_1^n + \cdots + a_m^n - 1)^{1/n} \\
= \lim_{n \to \infty} \left( (1 + a_1^n + \cdots + a_m^n - 1)^{\frac{1}{a_1^n + \cdots + a_m^n - 1}} \right)^{ \frac{a_1^n + \cdots a_m^n-1}{n}}.
$$
But then we need to have the condition $a_1^n + \cdots + a_m^n - 1 \to 0$ ($n \to \infty$). Thank you very much.","['calculus', 'limits']"
1497944,A linear transform of a closed set is closed,"A linear transform of a closed set $E\subset \mathbb{R}^d \to \mathbb{R}^d$ is closed. I have seen a lot of similar questions here, but none of them exactly addresses the issue. Please if you find it duplicate make sure it is and comment about it. A set is closed if it's complement is open. A set $E\subset \mathbb{R}^d$ is open if for every $x\in E$ there exists $r>0$ with $B_r(x)\subset E$, where $B_r(x)$ is a ball centered at $x$ with radius $r$,","['transformation', 'real-analysis', 'general-topology', 'linear-transformations']"
1497991,Give an example of a nonabelian group in which a product of elements of finite order can have infinite order. [duplicate],"This question already has answers here : Example of a group where $o(a)$ and $o(b)$ are finite but $o(ab)$ is infinite [duplicate] (6 answers) Closed 8 years ago . So, I let a,b be elements in such a group. So |a|=n and |b|=m, n and m are finite. But |ab| needs to be infinite, but since |ab|=lcm(n,m), how can that be possible?","['abstract-algebra', 'group-theory', 'examples-counterexamples', 'abelian-groups']"
1498014,An Identity Involving Narayana Numbers,"Let $N(n,m)$ denote the Narayana number defined by $$N(n,m)=\frac{1}{n}{n\choose m}{n\choose m-1}.$$ Let $$A(n,k,\ell)=\sum_{\substack{i_0+i_1+\cdots+i_k=n\\ j_0+j_1+\cdots+j_k=\ell}}\,\prod_{t=0}^kN(i_t,j_t+1),$$ where the sum ranges over all compositions $(i_0,i_1,\ldots,i_k)$ of $n$ into exactly $k+1$ parts and all weak compositions $(j_0,j_1,\ldots,j_k)$ of $\ell$ into exactly $k+1$ parts. From numerical evidence, I have conjectured that $$A(n,k,\ell)=\frac{k+1}{n}{n\choose \ell}{n\choose \ell+k+1}.$$ This seems like a simple enough formula, but I am at a loss for how to prove it. Any help would be greatly appreciated.","['binomial-coefficients', 'combinatorics']"
1498023,Completeness of Probability Distribution as a Measure.,"Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a complete probability space
and $X:\Omega \to \mathbb{R}^n$ be a $\mathcal{F}$-measurable function, i.e., it is a random variable.
Then, in the book ""Bernt Øksendal, stochastic differential equations: an introduction with applications, Springer-Verlag, 2003,"" it is said that $X$ induces the probability space $(\mathbb{R}^n, \mathcal{B}, \mu_X)$, where $\mathcal{B}$ is the Borel $\sigma$-algebra on $\mathbb{R}^n$, 
and $\mu_X: \mathcal{B} \to [0, 1]$ is the probability measure called the distribution given by
\begin{equation}
   \mu_X(B) \doteq \mathbb{P}(X^{-1}(B)) 
\end{equation}
for any $B \in \mathcal{B}$. My question is that is $\mu_X$ a complete measure? Since $\mathbb{P}$ is assumed complete, I think $\mu_X$ would be also complete, but I stuck with its proof. Perhaps, one need to show that 
\begin{equation}
   \mu_X(B) = 0 \textrm{ and } C \subset B \;\; \Longrightarrow \;\; 
   C \in \mathcal{B},
\end{equation}
which obviously implies $\mu_X(C) = 0$ by monotonicy.","['stochastic-calculus', 'real-analysis', 'measure-theory']"
1498070,Rate of convergence of random series,"$X_1,X_2,\cdots$ are iid with $E(|X_i|^{p})<\infty$ for some real $p\ge 1$ and $E(X_i)=\mu$. I am trying to find the largest $\alpha>0$ such that $n^{\alpha}\left[\dfrac{S_n}{n}-\mu\right]\to 0$ almost surely. I am able to find $\alpha$ for $p$ even and show convergence in $\mathbb{L}^p$ and almost sure. Any hints on how I can proceed with this problem? Thanks!",['probability']
1498091,Show that $a = b = c = 0$ for $a\sqrt{2} + b = c\sqrt{3}$ is,"This is the following question: Suppose that $a, b, c$ are integers such that $a\sqrt{2} + b = c\sqrt{3}$ (i) By squaring both sides of the equation, show that $a = b = c = 0$ The answer says that you put the equation into the following form: if $ab \neq 0$ $\sqrt{2} = \frac{3c^2 − 2a^2 − b^2}{2ab}$ is rational — a contradiction and so a = 0 or b = 0. Why would $a$ or $b$ be 0? (I get that you cannot express an irrational number as the quotient of two rational numbers).","['irrational-numbers', 'algebra-precalculus']"
1498105,Peano existence theorem & Uniqueness of solutions to IVPs,"I have learned Peano existence theorem and Uniqueness of solutions to IVPs, but I don't understand what does that mean by $y'=f(x,y)$ , $y(x_0)=y_0$ has a solution in $(x_0-d,x_0+d)$ for some $d>0$ . What is this thm trying to show? How to understand its uniqueness? I have a hw question following: Prove that if $f$ is continuous on $\Bbb R× \Bbb  C$ and locally Lipschitz in the second argument, and if $x_0 \in \Bbb R$ , $y_0 \in \Bbb C$ , then there exists an interval $(a; b)$ containing $x_0$ such that the following holds. A solution to IVP $y' = f(x; y)$ and $ y(x_0) = y_0$ exists on $(a; b)$ , and if a solution $\tilde y$ to the IVP exists on some open interval $I$ containing $x_0$ , then $I\subset(a; b)$ and $\tilde y = y$ on $I$ . That is, (a; b) is the largest interval of existence and the solution is unique on it. (Hint: Show that if $F$ is the family of all couples (open interval containing $x_0$ ,
solution on it), then any two of these solutions coincide on the intersection of their intervals of definition. Conclude that then a solution can be defined on the union of these intervals (show it is an open interval) such that it coincides with each solution in F where the latter is defined.) I just don't understand how is the hint related to the thm. I know I have learned this part poorly, I really appreciate if you can let me understand the thm.","['real-analysis', 'ordinary-differential-equations']"
1498145,Homogeneous Littlewood-Paley decomposition,"I have a question concerning Littlewood-paley-theory. Suppose we have test functions $\psi_k$ supported in annuli $\{2^{k-1}\leq\vert\xi\vert\leq2^{k+1}\}$ such that $\sum_{k\in\mathbb{Z}}\psi_k(\xi)=1$ for $\xi\neq0$. Define the homogeneous Littlewood-Paley projections $P_k$ of a tempered distribution by $\widehat{P_ku}=\psi_k\hat u$. I'd like to show that the equality
$$ u=\sum_{k\in\mathbb{Z}}P_ku\qquad \text{in} \qquad \mathcal{S}'$$
holds true modulo a polynomial. Unfortunately I'm not able to show this. That's why I'm hoping for your help. Greets Lukas","['fourier-analysis', 'distribution-theory', 'real-analysis', 'littlewood-paley-theory', 'analysis']"
1498153,Bounded linear functional is necessarily continuous proof verification,"I want to prove that a bounded linear functional $f$, must be continuous. I have defined: $f$ is bounded means that $\exists c> 0, |f(x)|\leq c\|x\|, \quad \forall x\in X$ and continuous means that $x_n\to x \implies f(x_n)\to f(x)$. Proof: Let $f$ be bounded. Then $\exists c, |f(x)| \leq c\|x\|$ Then \begin{align}
&\lim_{n\to\infty} |f(x_n-x)|\leq \lim_{n\to\infty} c\|x_n-x\|\\
\implies& \lim_{n\to\infty} |f(x_n)-f(x)|\leq c\|x-x\|=0\\
\implies& \lim_{n\to\infty} f(x_n)=f(x)
\end{align} Is that all there is to it? I used linearity in the second line, but what if we removed the condition that $f$ is linear. Is a non-linear bounded functional $f$ necessarily continuous","['proof-verification', 'linear-algebra', 'functional-analysis']"
1498158,Word problems on Sets,"In an examination, $80$ students passed in maths, $70$ failed in maths, $90$ failed in science and $20$ failes in both subjects.
How many passed in science$?$
How many passed in both subjects$?$",['elementary-set-theory']
1498183,Integers with a divisor in a given interval,"Please bear with me, I have a notation question. In Kevin Ford's paper with the above title, the following statement occurs in Theorem T1, p. 369: If $2 ≤ y ≤ z ≤ x$, then
$$H(x, y, z) = x\left(1 + O\left(\frac{\log y}{\log z}\right)\right),$$
where $H(x, y, z)$ isthe number of
positive integers $n ≤ x$ with a divisor in $(y,z].$ Now since $$H(x,y,z)\leq x-1$$ clearly holds, is the $O$ notation to be taken with an implied negative constant? Does this equation actually say that
$$H(x,y,z) \geq x\left(1-c\frac{\log y}{\log z}\right)$$ for some universal constant $c$?","['asymptotics', 'number-theory', 'sieve-theory', 'analytic-number-theory']"
1498222,Radius of Convergence of Binomial Series,Why the following is true? $$\bigg|\lim_{n\rightarrow\infty}\frac{\alpha(\alpha-1)...(\alpha-n)}{(n+1)!}\frac{n!}{\alpha(\alpha-1)...(\alpha-n+1)}\bigg|=\lim_{n\rightarrow\infty}\frac{|\alpha-n|}{n+1}=1$$ This is found in this link .,"['analysis', 'sequences-and-series', 'calculus', 'limits']"
1498225,$f(x):=x^4+ax^3+\frac{3}{2}x^2+1$. For which constant $a$ the function $f$ will be convex on $\mathbb{R}$?,"$f(x)=x^4+ax^3+\frac{3}{2}x^2+1$ . For which constant $a$ the function $f$ will be convex on $\mathbb{R}$ ? The first derivative of the function will be: $4{x}^{3}+3a{x}^{2}+3x$ A function $f(x)$ is convex on an interval $ [a,b]$ if for any two points $ x_1$ and $x_2$ in $[a,b]$ and any $\lambda$ where $0<\lambda<1$ we have $f(\lambda x_{1}+(1-\lambda)x_{2})\le\lambda f(x_{1})+(1-\lambda)f(x_{2})$ How can I compute the value of a?","['derivatives', 'analysis', 'calculus', 'functions']"
1498233,Probability of a boring afternoon,"I am extremely bad in probabilities (as in so many other areas) and I fully understand that this question is off-topic and/or missing context (may I underline that this is not homework). Could you tell me how to compute the probability that, in a bridge tournament consisting in $n$ deals, it can happen that I never get more than $p$ points in my hand ? If needed, each player has $13$ cards in hand and the points are counted as ${Ace}=4$, $King=3$, $Queen=2$, $Jack=1$. This happened to me last week with $n=28$ and $p=8$ and this has been a very boring tournament for me (not for my opponents !). Thanks in advance.",['probability']
1498244,Second fundamental form and metrics,"Suppose $M$ and $N$ are orientable manifolds, $f: M \to N$ is a smooth embedding and $g$ is a Riemannian metric on $N$. When $M$ has codimension $1$ and $\vec{n}$ is a prefered unit normal section of $f$, the second fundamental form of $f$ with respect to $\vec{n}$ can be regarded as a section $II: M \to T^*M \otimes T^*M$ defined by $II_p(X,Y) = g_p(\nabla_X Y, \vec{n}_p)$. It is a quadratic form on each tangent space, and, when it is additionally positive definte, it defines a Riemannian metric on $M$. I wonder if there is a nice geometric illustration of the resulting metric on $M$ in this case. In particular, in how far does it differ from the pullback-metric $f^*(g)$ ?","['differential-geometry', 'riemannian-geometry', 'surfaces']"
1498245,There is more than one functor that fix objects in category of groups?,"I am trying to solve the following exercise: Find two functors $F_1,\ F_2: Grp \rightarrow Grp $ such that $F_i G = G $ for all $i=1,2$ and $G \in Grp$, where $Grp$ is the category of groups. Of course the identity functor can be chosen like one of this $F_i's$ but I cant find another. Thank's","['group-theory', 'category-theory']"
1498257,Formula for Nested Radicals,"I know that: $$\sqrt{2+\sqrt{2+\sqrt{2+...\sqrt{2}\; (upto\; n\; times)}}}=2\cos(2^{-n-1}\:\pi)$$ I was wondering whether such a formula exists for $$\sqrt{3+\sqrt{3+\sqrt{3+...\sqrt{3}\; (upto\; n\; times)}}}$$ or in general for,
$$\sqrt{k+\sqrt{k+\sqrt{k+...\sqrt{k}\; (upto\; n\; times)}}}$$ I've tried scaling the formula for 2 to get an approximate result. For example for the 6 case:
$$\sqrt{6+\sqrt{6+\sqrt{6+...\sqrt{6}\; (upto\; n\; times)}}}\approx\left(\frac{2\cos(2^{-n-1})-\sqrt2}{2-\sqrt2}\right)(3-\sqrt6)+\sqrt6$$",['algebra-precalculus']
1498291,In how many ways can 9 cars be parked so that there are never two red cars next to each other?,"Nine cars are parked in a row. Four of the cars are painted red and five are painted blue. In how many ways can the cars be parked so that there are never two red cars next to each other? I think I know how to solve this but I am not sure. First arranging the blue cars in line and specifying where the red ones could be parked. $$\color{red}X\color{blue}B\color{red}X\color{blue}B\color{red}X\color{blue}B\color{red}X\color{blue}B\color{red}X\color{blue}B\color{red}X$$ Where $\color{blue}B$ stands for a parked blue car and $\color{red}X$ for a potential red car parking spot. So we have 6 $X's$ (red cars) and 5 $B's$ (blue cars). Note all cars are considered to be the same. Then the answer is $C(6,4) = 15$?","['discrete-mathematics', 'combinatorics']"
1498307,How many group structures make $S^1$ a topological group?,Let $S^1$ be the subspace of $R^2$ given the usual topology. How many group structures make $S^1$ a topological group?,"['lie-groups', 'group-theory', 'locally-compact-groups', 'topological-groups']"
1498319,Prove an inequality using the Cauchy -Schwarz Inequality [duplicate],"This question already has answers here : Prove QM-AM inequality (5 answers) Closed 8 years ago . I want to prove that for all $n\in\mathbb{N}$ and $x_i\in\mathbb{R}$, we have
$$(x_1+\cdots+x_n)^2\leq n(x_1^2+\cdots+x_n^2).$$ At first I wanted to do a proof by induction, but it has turned out to be much more complicated than I imagined.  Now I'm thinking Cauchy-Schwarz, but I can't seem to write it in the correct form to get the result I need. Any hints or help would be much appreciated.  The Cauchy-Schwarz inequality as we are using it in my class is in vector form, i.e.,
$$|\langle u,v\rangle|\le\|u\| \|v\|.$$","['linear-algebra', 'inequality']"
1498329,In how many ways can 7 boys and 3 girls be arranged in a row so that the end positions are taken by the boys?,"In how many ways can 7 different boys and 3 different girls be arranged in a row so that the end positions are taken by the boys and no 2 girls are sat next to each other. I think I have an idea on how to solve this but my answer differs from the one in the solutions. First of all choose the boys for the end positions, $7*6$ but since there are 2 end positions we get $7*6*2$. The rest of the boys can be seated in $5!$ ways. Now consider the configuration $$BXBXBXBXBXBXB$$ Where $X$ is a potential position for a girl to sit. There are 6 such positions so for the girls its $\tbinom 63$ Putting it all together gives $$\tbinom 63 *5! *5 *4 *2$$ But the answer in the solutions is $3!*\tbinom 63$","['discrete-mathematics', 'combinatorics']"
1498394,Irreducible characters of the direct product of two groups,"I am studying representation and character theory because of my field of research. So, my question is not a homework. I want to solve a problem of the book ""character theory of finite groups"" by M. Isaacs. The problem is as follows: I know that if $A$ is an abelian group, then each character of $A$ in the field of complex numbers is linear. Also I know that if $G=H \times A$ then each irreducible character of $G$ can be written as $\phi \lambda$, where $\phi \in Irr(H)$ and $\lambda \in Irr(A)$. Using these facts, I tried to solve this problem but I could not find any useful ideas. I will be so grateful for your helpful answers and comments.","['representation-theory', 'group-theory', 'finite-groups']"
1498400,What is a counterexample to the converse of this corollary related to the Dominated Convergence Theorem?,"Based on Williams' Probability w/ Martingales: Let $(S, \Sigma, \mu)$ be a measure space. Dominated Convergence Theorem : Suppose $\{f_n\}_{n \in \mathbb{N}}$, $f$ are $\Sigma$-measurable $\forall n \in \mathbb{N}$
   s.t. $\lim_{n \to \infty} f_n(s) = f(s) \forall s \in S$ or a.e. in S
   and $\exists g \in \mathscr{L}^1 (S, \Sigma, \mu)$ s.t. $|f_n(s)| \le
 g(s) \forall s \in S$ (I guess: or a.e. in S). Then $\lim_{n \to
 \infty} \int_S |f_n - f| d\mu = 0$. The last sentence implies $$\lim_{n \to \infty} \int_S f_n d\mu = \int_S f d\mu$$ It is apparently false to say that $$\lim_{n \to \infty} \int_S f_n d\mu = \int_S f d\mu \to \lim_{n \to \infty} \int_S |f_n - f| d\mu = 0$$ Hence, we have things like Scheffé's Lemma Part (i) : Suppose nonnegative $\{f_n\}_{n \in \mathbb{N}}, f \in \mathscr{L}^1 (S, \Sigma, \mu)$ and $\lim_{n \to \infty} f_n(s)
 = f(s) \forall s \in S$ or a.e. in S. Then $\lim_{n \to \infty} \int_S |f_n - f| d\mu = 0$ iff $\lim_{n \to \infty} \int_S f_n d\mu = \int_S
 f d\mu$ So what is a counterexample saying that $\lim_{n \to \infty} \int_S f_n d\mu = \int_S f d\mu$ implies $\lim_{n \to \infty} \int_S |f_n - f| d\mu = 0$? Based on Scheffé's Lemma, I'm guessing a counterexample might have something to do with at least one of the functions not being integrable or something. Re an answer: $\int_{[-1,1]} |f_n-f|\mathrm d\lambda=2$? $$\int_{[-1,1]} |f_n-f|\mathrm d\lambda$$ $$ = \int_{[-1,1]} |f_n|\mathrm d\lambda$$ $$ = \int_{[-1,1]} |n1_{(0,1/n)} - n1_{(-1/n,0)}|\mathrm d\lambda$$ $$ \color{red}{=?} \int_{[-1,1]} |n1_{(0,1/n)}| + |n1_{(-1/n,0)}|\mathrm d\lambda$$ $$ = \int_{[-1,1]} n1_{(0,1/n)} \mathrm d\lambda + \int_{[-1,1]} n1_{(-1/n,0)}\mathrm d\lambda$$ $$ = 1 + 1 = 2$$","['probability-theory', 'measure-theory', 'real-analysis', 'integration', 'lebesgue-integral']"
1498403,Deriving properties of the t distribution,"Let X~$t_p$ Derive the Mean and Variance of X (EX and Var(X). Show that $\chi^2$~$F_{1,p}$. Show that X converges to N(0,1) I'm not so sure how to do part 1 since it involves Gamma distribution and I don't really know how to deal with the integral portion of the pdf. For part 2 I tried plugging in 1,p into the pdf but I'm getting something that is completely different from what's needed. For part 3 I used the Almost sure convergence theorem but I'm getting stuck at showing how the probability=1. I'd really need some help.  thanks.","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
1498412,Maximising shortest path passing through $n$ points inside a bounded region,"Source: I was programming a visualization for the Euclidean Travelling Salesman Problem when I stumbled on this problem. Question: Consider a bounded region in the Euclidean plane, in this case, we will consider the unit square $[0, 1]\times[0, 1]$. We will place $n$ points inside it. Next, we find the shortest path that passes through all $n$ points. Where do we place the $n$ points such that the length of this shortest path is maximised? Examples: For $n=2$, we have the longest path as a diagonal of the square, with length $\sqrt{2}$: For $n=3$, (credit to Fritz for spotting this error) we have this longest path part of the largest equilateral triangle in the square, of length $\frac{8}{\sqrt{6}+\sqrt{2}}$: Placing 4 points at the corners of the square will lead to this path, which I suspect is the longest, with length $3$: Some work: The maximum length path is $\omega(\sqrt{n})$. A construction: Arrange the $n$ points into a regular grid formation. Since the points are separated by a distance $\Theta\left(\frac{1}{\sqrt{n}}\right)$ and there are $n$ points, multiplying them gives the bound of $\omega(\sqrt{n})$ Placing the points at $\left(\frac{i}{\lceil\sqrt{n}\rceil}, \frac{j}{\lceil\sqrt{n}\rceil}\right)$ would give a closed-form lower bound for the upper bound of $\frac{n-1}{\lceil\sqrt{n}\rceil}$. Bounty Edit: I am interested in closed-form bounds for the upper bound (such as the lower bound of $\frac{n-1}{\lceil\sqrt{n}\rceil}$ as mentioned above). Other bounded regions (such as the unit circle) may be also interesting and will also be considered for the bounty.","['optimization', 'geometry']"
1498417,Christoffel symbols and Riemann curvature tensor of a left-invariant metric on a Lie group,"Let $G$ be a Lie group equipped with a left-invariant metric, with dimension n. One can write the local coordinates of $G$ as $\phi^a$, whereby $a=1,2..n$. From Milnor's 1976 paper ""Curvatures of Left Invariant Metrics on Lie Groups"" (equation 5.3) one is able to find the Levi-Civita connection in terms of Lie algebra elements. My question is, how does one extract the Christoffel symbols of the metric, as a function of the coordinates, $\phi^a$? Likewise, I would like to find an expression for the Riemann curvature tensor in terms of the coordinates $\phi^a$, as well.","['lie-groups', 'differential-geometry', 'lie-algebras']"
1498438,Deriving a statistic of the t distribution with 2 degrees of freedom,"Assume I have an independent $X_{1}, X_{2}, \ldots, X_{n}$ with $X_{i} \sim N(i,i^{2})$ and I want to find a statistic that has a t distribution with 2 degrees of freedom. How would I go about showing that?  I don't think t distribution is one that is related to the normal or the F, but I would like someone to help clarify the steps and methodology towards tackling problems like these.","['probability-theory', 'order-statistics', 'probability-distributions', 'statistics', 'probability']"
1498439,Finding $\lim_{n\to + \infty }(1+\frac{in}{n^2-1})^2$,"Finding $$\lim_{n\to + \infty }\left(1+\frac{in}{n^2-1}\right)^2$$ I am having troubles with complex limits, and if anyone knows a workbook with solutions online that I can find, it would be very appreciated. :)","['calculus', 'limits', 'complex-numbers', 'analysis', 'complex-analysis']"
1498442,Using Fatou's Lemmas in proving Scheffe's Lemma Part (ii),"Based on Williams' Probability w/ Martingales: Let $(S, \Sigma, \mu)$ be a measure space. Scheffe's Lemma Part (ii) : Suppose $\{f_n\}_{n \in \mathbb{N}}, f \in \mathscr{L}^1 (S, \Sigma, \mu)$ and $\lim_{n \to \infty} f_n(s) = f(s) \forall s \in S$ or a.e. in S. Then $$\lim_{n \to \infty} \int_S |f_n - f| d\mu = 0 \iff \lim_{n \to \infty} \int_S |f_n| d\mu = \int_S |f| d\mu$$ In proving Scheffe's Lemma, we could use Fatou's Lemmas to show that $$\lim_{n \to \infty} \int_S f_n^{+} d\mu = \int_S f^{+} d\mu$$ $$\lim_{n \to \infty} \int_S f_n^{-} d\mu = \int_S f^{-} d\mu$$ What I tried: Fatou's Lemmas for $f_n^{+}$ $$\int_S \limsup f_n^{+} d\mu \ge \limsup \int_S f_n^{+} d\mu \ge \liminf \int_S f_n^{+} d\mu \ge \int_S \liminf f_n^{+} d\mu$$ And that's about it. I have no idea if $$\lim_{n \to \infty} f_n^{+}(s) = f^{+}(s) \forall s \in S$$ or a.e. in S. Is $$\lim_{n \to \infty} \max(f_n, 0) = \max(\lim_{n \to \infty} f_n, 0)$$ ? I seem to recall from basic calculus that $$\lim_{x \to \infty} f(g(x)) = f(\lim_{x \to \infty} g(x))$$ if $f$ is continuous. Even if it was true, I'm not sure what I can use here. I don't think I can use monotone convergence theorem or dominated convergence theorem. Can I? How else can I approach this?","['probability-theory', 'measure-theory', 'real-analysis', 'integration', 'lebesgue-integral']"
1498457,"If A is a $m\times n$ matrix, and $\text{rank}(A)=1$, then $A^2 =\lambda A$ [duplicate]","This question already has answers here : If $A$ is rank-$1$, show that $A^2=cA$ for some scalar $c$ (4 answers) Closed 8 years ago . If $A$ is $m \times n$ matrix with rank$(A)= 1$. How do we show that 
 $$A^2 =\lambda A$$ 
for some $\lambda$? How do we show this?
All I could show is that if rank$(A)=1$ then rank$(A^2)=1.$ Am I heading in the right direction?","['matrix-rank', 'eigenvalues-eigenvectors', 'matrices']"
1498500,"$(2\pi)^{-n/2}\int_{\mathbb{R}^n} q(x)e^{-\Vert x \Vert^2/2}\,dx = \mbox{trace}(Q)$","Let $Q$ be a symmetric matrix and consider the quadratic form $q: \mathbb{R}^n \rightarrow \mathbb{R}$, $q(x) = \langle Qx, x \rangle$ Show that
$(2\pi)^{-n/2}\int_{\mathbb{R}^n} q(x)e^{-\Vert x \Vert^2/2}$dx = tr(Q) I tried to do this: We can write $Q = UDU^*$, where U is unitary and D = diag($\lambda_1, \dots, \lambda_n)$, $\lambda_i$ are the eigenvalues of $Q$.
Then, given x $\in \mathbb{R}^n$, $q(x) = \langle Qx, x \rangle =  \langle UDU^*x, x \rangle = \langle DU^*x, U^*x \rangle = \sum_{i = 0}^n \lambda_i|(U^*X)_i|^2$. So, $(2\pi)^{-n/2}\int_{\mathbb{R}^n} q(x)e^{-\Vert x \Vert/2}$dx $(2\pi)^{-n/2}\int_{\mathbb{R}^n} \sum_{i = 0}^n \lambda_i|(U^*X)_i|^2e^{-\Vert x \Vert/2}$dx I think we can use that $\Vert x\Vert^2 = \Vert U^*x \Vert^2$, since U is unitary. I do not know how to proceed anymore!","['random-matrices', 'complex-analysis', 'matrix-calculus']"
1498521,How to prove that $\frac{d\left(\tan^{-1}x\right)}{dx}=\frac{1}{1+x^2}$ directly using the definition.,How to prove that $\frac{d\left(\tan^{-1}x\right)}{dx} =\frac{1}{1+x^2}$ using the definition. I trying to prove some derivatives using fundamental theorems. But no idea of the proof $tan^{-1}x$,"['calculus', 'real-analysis', 'algebra-precalculus', 'derivatives']"
1498533,Direct Summand and Intersection Homology,"Let $X$ the projective cone of $C$, here $C$ a curve of genus $g$. We can compute its intersection cohomology : $IH^0(X) = \mathbb Q, IH^1(X) =  \mathbb{Q}^{2g}, IH^2(X) =  \mathbb 0, IH^3(X) =  \mathbb{Q}^{2g} , IH^4(X) =  \mathbb Q$. We have a resolution of singularity : $W:= \mathbb P^1 \times C \to X$ (blow-up at the vertex). We obtain that $H^i(W) = IH^i(X)$ for $i \neq 2$ and $H^2(W) = \mathbb{Q}^2$. Is there an geometric interpretation of this $\mathbb Q^2$ ? The decomposition theorem for perverse sheaves gives us that $IH^k(X)$ are direct summand of $H^k$ but I don't know how if there is an geometric interpretation of the other summand. Thanks in advance !","['algebraic-geometry', 'homology-cohomology', 'algebraic-topology', 'sheaf-cohomology']"
1498536,Proving that if $ab=e$ then $ba=e$,"Suppose that instead of the property $ab=ba=e$ a group G has the condition that for every element $a$ there exists an element $b$, such that $ab=e$. Prove that $ba=e$. Is the following a valid proof? Since $ab=e$ then under the condition of the group there exists an element $k$ such that $bk=e$ for some $k$ in the group. Now $bk=e$ so $abk=ae$ therefore $(ab)k=a$ and finally $ek=a$ and $k=a$. Is this a valid proof?","['abstract-algebra', 'group-theory']"
1498549,What is the limit of $\lim_{x\to\pi/2-}= (\tan {x})^{\cot{x}}$?,"$\lim_{x\to\pi/2-}= (\tan {x})^{\cot{x}}$ where $cot\alpha=\frac{1}{tg\alpha}$ I think that I should use the L'Hospital rule but the L'Hospital rule works only if 
 $\lim_{x\to c}f(x)=\lim_{x\to c}g(x)=0$or $+,- \infty$","['calculus', 'limits', 'functions']"
1498674,Finding an equation of a plane perpindicular to xy plane that intersects with a surface and has a directional derivate of zero at this point.,"I'm a bit new to 3D space and haven't had much practice with it. One question I'm working on says: A plane perpendicular to the x-y plane contains the point (3, 2, 2) on
  the paraboloid $36z=4x^2+9y^2$. The cross-section of the paraboloid
  created by this plane has slope 0 at this point. Find an equation of
  the plane. What I did was I solved for z explicitly, giving me: $z=\frac{4}{36}x^2 + \frac{9}{36}y^2$ Then I found the partials with respect to $x$ and $y$ giving me: $F_x = \frac{8}{36}x$ $F_y = \frac{18}{36}y$ Evaluating the partials at the point $(3,2,2)$ gives me: $F_x(3) = \frac{24}{34}$ $F_y(2) = 1$ Since it's given that the directional derivative at this point is zero, and that the plane is perpendicular to the x-y plane, I get the equation of the plane to be: $0=\frac{24}{34}(x-3) + (y-2)$ But the answer in the textbook says: $0=2(x-2)+3(y-2)$ Any help would be greatly appreciated. Thanks","['partial-derivative', 'multivariable-calculus']"
1498693,Finding the inverse function of $f(x)=\frac{3x+1}{2-7x}$,"Find the inverse function of:
$$f(x)=\frac{3x+1}{2-7x}$$
I did the question and when I checked my answer with the key it was wrong, can someone please show me how to properly do this problem? I followed all the steps and the answer I came up with was:
$$\frac{2x-1}{7x+3}$$
but the correct answer is supposed to be:
$$\frac{-(1-2x)}{7x-3}$$","['inverse', 'algebra-precalculus']"
1498701,Expository articles on Cayley Graphs?,"Does anyone know of any expository articles on Cayley graphs ? I have some background in both group theory and graph theory, and know a little bit of algebraic topology. In particular, I am hoping to find an expository article which explores the graph theory point of view for Cayley graphs, ideally something which starts from the basics, and then goes on to explain some open problems. Does anybody know if anything like this exists? Thank you in advance. EDIT: To be more specific, by ""graph theory"" point of view, I mean something which has as its primary focus the graph theoretic properties of Cayley graphs, such as what is known about hamiltonicity, etc. It would be nice to know what properties of Cayley graphs translate to interesting (deliberately vague) properties of groups.","['graph-theory', 'group-theory', 'cayley-graphs', 'reference-request', 'algebraic-graph-theory']"
1498718,Is $\arctan n$ always equal to $\arccos\sqrt{\frac{1}{n^2+1}}$?,"$$\arccos\sqrt\frac{1}{2}=\arctan 1$$
$$\arccos\sqrt\frac{1}{5}=\arctan 2$$
$$\arccos\sqrt\frac{1}{10}=\arctan 3$$
$$\arccos\sqrt\frac{1}{17}=\arctan 4$$
$$\arccos\sqrt\frac{1}{26}=\arctan 5$$
$$\arccos\sqrt\frac{1}{37}=\arctan 6$$
$$\arccos\sqrt\frac{1}{50}=\arctan 7$$ The answer is a sequence $n^2+1$ for the slope which is in the inverse of tangent. Digits that are whole numbers. Is there any explanation as to why this is true? Is it a well-known problem?","['sequences-and-series', 'trigonometry']"
1498729,"$S_n \in [-a,a]$ for some $a$ infinitely often","Suppose we have iid r.v.s $X_n \in \mathbb{R}$ with mean $0$ variance $\sigma^2$, I wonder is it true that we have $\exists a>0,$ 
$$P(S_n \in [-a,a] \text{ infinitely often} )=1,$$ where $S_n =\sum_{i=1}^n X_i$. In the case of integer valued $X_n$, the above is true by strong law of large numbers and Kesten-Spitzer-Whitman theorem. By Hewitt–Savage $0-1$ law, we know the above probability is $0$ or $1$. But it looks hard to me to determine if it is positive or not.","['probability-theory', 'random-walk']"
1498752,Expand in Taylor series $\frac{1}{1-\sin{x}}$,Expand in Taylor series $\frac{1}{1-\sin{x}}$ I have an idea that $\frac{1}{1-\sin{x}} = 1 + \sin {x} + \sin^2 {x} + \sin^3 {x} + \dots$ But I don't know what to do next. Every sine expands in infinity series... Can anybody help?,"['taylor-expansion', 'sequences-and-series', 'real-analysis']"
1498763,Find $\sum_{n=1}^\infty \frac{n^3}{n!}$.,"I have to find the sum of the following series:
 $$\sum\limits_{n=1}^\infty \frac{n^3}{n!}$$ I know how to prove the convergence of this series, but how do i find the sum. I can't use the properties of derivation or integration of the series, i have to do it using the definition that a series converges iff it's sequence of partial sum converges.","['sequences-and-series', 'real-analysis', 'exponential-function']"
1498784,More problem on van Aubel configuration associated with parallelogram and cyclic quadrilateral,"Problem 1: Let $ABCD$ be a parallelogram. Construct four squares on the sidelines $ABCD$. Let $NPMO$ be the Thebault’s square . Show that: 1-Centers of four circles $(NAP)$, $(PBM)$, $(MCO)$, $(OCN)$ is rhombus. 2-Intersection of four circles $(NAP)$ and $(PBM)$, $(PBM)$ and $(MCO)$, $(MCO)$ and $(OCN)$, $(OCN)$  and $(NAP)$  form a square. Problem 2: $ABCD$ be a parallelogram, construct for square on the sidelines of ABCD. Show that $OPMN$ be a rectangle. Problem 3: Let $A, B, C, D$ lie on a circle with center $(O)$. Construct four squares on the sidelines $ABCD$. Let $PMNQ$ be the van Aubel 's equidiagonal orthodiagonal quadrilateral . Show that: 1-Six circles $(QAP)$, $(PBM)$, $(MCN)$, $(NDQ)$, $(PON)$, $(MOQ)$ are concurrent be a point. 2-Centers of four circles $(QAP)$, $(PBM)$, $(MCN)$, $(NDQ)$ lie on a circle. 3-Center of four circles $(QOP)$, $(POM)$, $(MON)$, $(NOQ)$ lie on a circle.","['euclidean-geometry', 'geometry']"
1498799,"What shape do we get when we shear an ellipse? And more generally, do affine transformations always map conic sections to conic sections?","What shape do we get when we shear an ellipse? Is it another ellipse (or circle in special cases)? Or is it some other shape which isn’t a conic section? I was under the impression that applying any affine transformations to an ellipse would always yield an ellipse (or special ellipses like circles, line segments or points). Yet recently, I was doing an exercise in my Linear Algebra textbook, and in one of the answers it states that: “An ellipse has the form $Ax^2 + By^2 = C$ where $A ≠ B$.” Well clearly, I disagree with the condition A ≠ B for a start, as I implied above that I consider circles to be a subset of ellipses. Secondly, a rotated ellipse will not be of that form, either. This leads me to believe that this is a mistake in the book (the question/answers do not say that the ellipse has to have major and minor axis in the same orientation as the $x$/$y$ axes either). Is it, or am I missing something here? This textbook I’m using is the Further Maths HL textbook for IB, and although 1st edition, all of the content in all of the IB maths textbooks so far is very good, and the answers have always been (until now) trustworthy. This led me to a few other speculations as well… so in addition to my first question: What shape do we get when an ellipse is sheared? Could someone clarify these following ones too? When ellipses are affine transformed, is the image always an ellipse? When parabolas/hyperbolas are affine transformed, are the images always parabolas/hyperbolas? And hence, from the above 2 questions, does the affine transformation of a conic section always result in a conic section? The question in the book (although not necessarily relevant, as I am just challenging the statement above in the answers) is: Under what conditions does a linear transformation with matrix \begin{bmatrix}
a&b\\
c&d
\end{bmatrix} transform the unit circle into: a. an ellipse?
b. a circle?","['linear-algebra', 'conic-sections', 'linear-transformations']"
1498801,"Which of the constants A,B,C,D does T depend on?","Let $f(x)=cos(5x)+Acos(4x)+Bcos(3x)+Ccos(2x)+Dcos(x)+E$ and $T=f(0)-f(\pi/5)+f(2\pi/5)-f(3\pi/5)+..-f(9\pi/5)$.Then out of A,B,C,D which does T depend on? Hints please!
P.S:KVPY 2011 question","['contest-math', 'trigonometry']"
1498830,Direct sum of finitely-many non-abelian groups,"Consider two non-necessary-abelian groups $(A,\circ)$ and $(B,\circ)$. It seems that the notion of direct sum $(A,\circ) \oplus (B,\circ)$ is only used in the case that both groups are abelian, and in that case the direct sum coincides with the direct product. However, the direct sum of permutations is a common notion. More generally, the direct sum of matrices is well-defined, and thus one might define the direct sum of matrix groups. What is the problem with direct sums of non-abelian groups? What can we do when restricting to finite direct sums, perhaps of merely finite groups? EDIT: Considering the answer by MarcPaul and Qiaochu Yuan, I presume that the notion of direct sum of finitely many groups can be used, though it is not necessary natural to do so. Let $G_1$ and $G_2$ be groups, let $G = G_1 \oplus G_2 := G_1 \times G_2$ be the supposed direct sum.
We want this two satisfy the universal property as described by MarcPaul.
We note that $(g_1,g_2) = (g_1,e_2) (e_1,g_2)$ for any $(g_1,g_2) \in G_1 \times G_2$.
Let $H$ be any group, and let $f : G \rightarrow H$ be a group homomorphism.
Then we set $f_1 : G_1 \rightarrow H, \quad g_1 \mapsto (g_1,e_2)$
$f_2 : G_2 \rightarrow H, \quad g_2 \mapsto (e_1,g_2)$ and with that $f(g_1,g_2) = f(g_1,e_2) f(e_1,g_2) = f_1(g_1) f_2(g_2)$. In conclusion, if we are given $f : G \rightarrow H$ we can construct $f_i : G_i \rightarrow H$,
if we are given $f_i : G_i \rightarrow H$ we can construct $f : G \rightarrow H$,
and those constructions are inverse to each other.
The natural property holds.",['group-theory']
1498842,"If $D$ is a dense subset of a topological space, $X$, and $O$ is an open subset of of $X$, then prove $\it{O} \subseteq \overline{D \cap O}$.","If $D$ is a dense subset of a topological space, $X$, and $O$ is an open subset of of $X$, then prove $\it{O} \subseteq \overline{D \cap O}$. Here's a summary of what I've done/thought so far: First, I said let $x \in \it{O}$. Now we want to show that $x \in \overline{D \cap O}$. $D$ is given to be dense $\implies$ $\overline{D} = X \implies$ every neighborhood of every element of $X$ is a closure point of $D \implies$ every neighborhood of every element of $X$ intersects $D$. Also, $O$ is given to open $\implies$ $\forall x \in X, \ \exists$ a neighborhood, $N_x$, such that $N_x \subseteq O$. At this point, I was unsure of how to use these ideas to prove my result, so I looked at the possibility of proving this via a contradiction. In other words, suppose $\it{O} \not\subseteq \overline{D \cap O} \implies \exists x \in O$ such that $x \not\in \overline{D \cap O} \implies x \in (\overline{D \cap O})^c$. Now, I have proved a property that says $(\overline{A})^c = (A^{c})^o$. Using this result, I get $x \in [(D \cap O)^c]^o \implies x \in (D^c \cup O^c)^o$. I have tried to play with the above result, but am unable to get any traction.","['elementary-set-theory', 'general-topology']"
1498856,Is the function characterized by $f(\alpha x+(1-\alpha) y) \le f^{\alpha}(\alpha x)f^{1-\alpha}(y)$ convex?,"Is a non-negative function $f(x)$ convex ? If for $x  \ge y$ it satisfies for any $\alpha \in [0,1]$.
\begin{align}
f(\alpha x+(1-\alpha) y) \le f^{\alpha}(\alpha x)f^{1-\alpha}(y)  \ \text{       eq.1}
\end{align} This is very reminiscent of the log-convexity which is defined as \begin{align}
f(\alpha x+(1-\alpha) y) \le f^{\alpha}( x)f^{1-\alpha}(y).
\end{align} Extra Hypothesis we can add: There exist a log-convex function $g(x)$ such that $f(x) \le g(x)$ and such that
\begin{align} f(\alpha x+(1-\alpha) y)  \le
    g^\alpha(x)f^{1-\alpha}(y). \end{align} $f(x)$ is a decreasing function of $x$. A little back ground: I am trying to show that if $f$ satisfies eq.$1$ then it is continuous .  The property that came to my mind is that if $f$ is convex then it is continuos on the open set. The condition in eq.$1$ is very similar to log-convexity (recall log-convexity implies convexity) and the hope is that it implies convexity. Thank you for any help and suggestions, in advance.","['convex-analysis', 'functional-analysis']"
1498858,Possible permutations of elements within sets,"I'm trying to resolve a permutation problem. Say I have n apples, k bags and each bag has a c storage space. (Let's assume every bag has the same c storage), I need to know how many permutations are possible so that each apple is in a bag. If each bag had $c = 1$, $\frac{k!}{(k-n)!}$ would solve my problem. But c can vary and we don't care about the order within a bag. So if n = 3 k = 2 c = 3 (For this example, () are used to show a bag's size and [] the whole problem's context) $[(1,0,0)(1,1,0)]$ is the same as $[(0,1,0)(0,1,1)]$ since the bags have the same number of apples in them in both the examples. But $[(1,1,0)(1,0,0))$ is the different from $((0,1,0)(0,1,1))$  because : In example 1 : $|bag1|=2$ and $|bag2|=1$ In example 2 : $|bag1|=1$ and $|bag2|=2$. I'm thinking I might need to divide something or apply another combination somewhere, but I can't figure what to do next. Any hint would be appreciated!",['combinatorics']
