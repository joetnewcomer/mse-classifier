question_id,title,body,tags
954335,Present a combinatorial argument for the identiy $\sum^{n}_{k=1} k\binom{n}{k} = n\cdot 2^{n-1}$,"This is a question in my textbook that does not provide a solution. Any help on a solution? Consider the following identity: $\sum^{n}_{k=1} k\binom{n}{k} = n\cdot 2^{n-1}$ Present  a combinatorial argument for the identity by considering a set of $n$ people and determining,in two methods, the number of ways you can select a committee of any size and a chair personfor the committee (a) How many ways possible you can select a committee of size k and its chairperson?
(b) How many ways possible you can select a chairperson and the other committee members?","['statistics', 'combinations', 'probability', 'combinatorics']"
954360,"Compare $\int_0^1 f(x)\log f(x)\,dx$ and $\int_0^1f(s)\,ds\cdot\int_0^1\log f(t)\,dt$","The question: Given $f$ to be a positive, measurable function on $[0,1]$, which is larger, $\displaystyle\int_0^1 f(x)\log f(x)\,dx$ or $\displaystyle\left(\int_0^1f(s)\,ds\right)\left(\int_0^1\log f(t)\,dt\right)$? I know from testing with $f(x)=x$ that the first integral is, indeed, larger. Of course, this isn't a rigorous ""proof"" (if it can even be called that). I am unsure as to go about this. At first glance, it looks similar to a Holder's Inequality problem, but appears to go the wrong direction. If anyone has a hint/suggestion as to where to start, it would be much appreciated. Thanks in advance! EDIT:
I've now found examples which show equality and inequality the other direction. If I let $f(x)=\cases{c\text{ if }x\in[0,1/2)\newline1\text{ otherwise}}$, then the first integral is smaller if $0<c<1$, they are equal if $c=1$, and the second is smaller if $c>1$. The new question, is this a sufficient answer: The magnitude of the integral depends on the function $f$? RE-EDIT:
I forgot about the sign change of $\log c$ when $c<1$, so I either have the integrals being equal when $c=1$ or the second integral being larger for other values of $c$. I suppose my original question still remains.","['integration', 'real-analysis']"
954367,Isaac Newton did number theory?!,"I was reading Whiteside's article called ""Newton the Mathemtician"", where he says that Newton did Number Theory (e.g. inverstigating which numbers are expressible as a sum of two cubes). If this is true, can someone point me towards some papers of newton on number theory? If not, then do you know which book in the eight-volume Newton's mathematical papers I can find his number theory work? I'm very interested in this, it came as a huge surprise (perhaps it shouldn't have) to me that Newton even knew of number theory. Concrete questions: Where can I find Newton's number theoeretical work in Whiteside's ""Newton's Mathematical Papers"" volumes? What did Newton investigate in Number Theory, and what did he discover? Thanks! EDIT: Here is the extract from Whiteside's article where he talks about Newton doing NT:","['math-history', 'reference-request', 'number-theory']"
954419,Self learning game theory and probability,"I am teaching myself mathematics, my objective being a thorough understanding of game theory and probability. In particular, I want to be able to go through A Course in Game Theory by Osborne and Probability Theory by Jaynes. I understand I want to cover a lot of ground so I'm not expecting to learn it in less than a year or maybe even two. Still I'm fairly certain it's not impossible. However I would like to have a study plan more or less fleshed out just to know I'm on the right track. There were some other questions related to self learning math here but I couldn't find one like mine. I'd appreciate some feedback. Calc I + II: no book, I already know basic calculus Differential equations: MIT's OCW lectures Calc III: Stewart's Multivariable calculus Linear Algebra: Strang, Gilbert, Linear Algebra and Its Applications complemented with MIT's OCW lectures OR Linear Algebra Done Right Until here I am more or less certain on what I want to study, but I'm totally confused on what to learn next. Jayne's book states that you need to be familiar with applied mathematics. After reading about applied mathematics, I came up with this plan to be done after finishing what I mentioned earlier (in order of course, not all at the same time): Topology A: Munkres, part I. Real analysis: Still not sure about the material, probably Abbott or Rudin. Complex Analysis: No idea about the material Group Theory: Rotman, An Introduction to the Theory of Groups Topology B: Munkres, part II. And then finally,
Jayne's Probability Theory and game theory. Am I missing something here? Some of these books such as Rotman's are aimed at a graduate level, is it foolish to think I will understand them?","['probability-theory', 'self-learning', 'group-theory']"
954436,Does $X_n \xrightarrow{\text{in distr.}} X$ and $|X_n|\leq Y$ imply $|X|\leq Y$?,"We know that $$X_n \xrightarrow{\mathbb P} X \text{ and } |X_n|\leq Y \implies |X|\leq Y \text{ a.s.}$$ I was wondering if the same holds in case of convergence in distribution. So far, I've shown that $$X_n \xrightarrow{\text{in distr.}} X \text{ and } |X_n|\leq c \in \mathbb R \implies |X|\leq c \text{ a.s.}$$
So the question is if the following holds: $$X_n \xrightarrow{\text{in distr.}} X \text{ and } |X_n|\leq Y \implies |X|\leq Y \text{ a.s.}$$","['probability-theory', 'convergence-divergence', 'random-variables']"
954453,How to come up with One-To-One and Onto Examples,"I'm trying to come up with example functions that are $N \rightarrow N$ for each category: One-to-one but not onto. Onto but not one-to-one. Nether one-to-one nor onto. Both one-to-one and onto. Here's what I've got: $f(n) = 2n$, because it's a linear function. $f(n) = n-1$, This only works when n is $\geq$ 2, but I'm thinking that's good enough? $f(n) = 0$, maybe this is a stretch but because y is always outside of $N$ I'm sure this is neither one-to-one or onto. $f(n) = n$, here x=y which matches both definitions. So, I'm posting because I'm unsure of what I've got. Especially with 1 and 2. Here are the definitions I've got: Onto: For every $y \in Y$ at least one $x \in X$ such that $f(x) = y$ One-to-one: For any $y \in Y$ there is at MOST one $x$ such that $f(x) = y$ This means that in order for a function to be onto there can be an x with two y's but it's not required. If it doesn't, doesn't that automatically make it also one-to-one?","['discrete-mathematics', 'functions']"
954489,A room and a spider,"A room has the shape of a rectangular cuboid. The edges are 3, 4 and 5 metres. There is a spider in one of the corners. The spider now walks to the corner on the other end of the space diagonal using the shortest possible route. How much distance does the spider travel? I think the solution is $ \sqrt {5^2+4^2}+3$ metres, but I am unsure.",['discrete-mathematics']
954523,Bivariate distribution with normal conditions,"Define the joint pdf of $(X,Y)$ as: $$f(x,y)\propto \exp(-1/2[Ax^2y^2+x^2+y^2-2Bxy-2Cx-Dy]),$$ where $A,B,C,D$ are constants. Show that the distribution of $X\mid Y=y$ is normal with mean $\frac{By+C}{Ay^2+1}$ and variance $\frac{1}{Ay^2+1}$. Derive a corresponding result for the distribution of $Y\mid X=x$. Attempt: I tried to integrate the equation w.r.t. $x$ in order to find $X\mid Y=y$. However, I'm not sure if I am correct: $$\int_{-\infty}^{\infty}\exp(-1/2[Ax^2y^2+x^2+y^2-2Bxy-2Cx-Dy])\,dx$$ $$ =\left[\frac{\exp[-1/2[Ax^2y^2+x^2+y^2-2Bxy-2Cx-Dy]}{-Axy^2-1/2+By+C}\right]_{-\infty}^{\infty}$$ Whatever the value of the previous integration (call it ""Q""), then we would divide the original equation by ""Q"", i.e.: $$ \frac{f_{X,Y}(x,y)}{Q}$$ Which would give us $f_{X\mid Y=y}(X\mid Y=y)$. How do I go about evaluating $$ =\left[\frac{\exp[-1/2[Ax^2y^2+x^2+y^2-2Bxy-2Cx-Dy]}{-Axy^2-1/2+By+C}\right]_{-\infty}^{\infty}\text{ ?}$$","['conditional-probability', 'probability-theory', 'statistical-inference', 'probability-distributions', 'probability']"
954536,2nd order odes with non constant coeff.,I am trying to solve these two DE: $ y''+(2x)/(1+x^2)y'+1/(1+x^2)^2y=0 $ and $ xy''-y'-4x^3y=0 $ and I am looking for methods on how to find the solutions. Should I go with the series method or is there a simpler way?,['ordinary-differential-equations']
954558,Polar Coordinates in $\mathbb R^n$,"After proving Fubini-Tonelli theorem a formula on polar coordinates in $\mathbb R^n$ is given in my class as follows. Let $f$ be a real-valued integrable function on $\mathbb R^n$ and $S^{n-1}$ be the surface of $n$-dimensional unit ball with respect to Euclidean norm. Then define a new function $\tilde f(r, \omega) :\mathbb R^+ \times S^{n-1} \to \mathbb R$ by $$\tilde f(r, \omega) = f(r\omega).$$ In addition, let $E$ be a measurable subset of $\mathbb R^n$ and $r>0$. Define $E_r \subset S^{n-1}$ as $$E_r := \{\omega\in S^{n-1}:r\omega \in E\}.$$ Then finally the polar coordinate formula in $\mathbb R^n$ is as follows. $$
\int_E f(x) dx = \int_0^\infty \left( \int_{E_r} \tilde f(r, \omega)d\omega \right) r^{n-1} dr.
$$ I have the following questions about this formula. How is this formula related to the two-dimensional case? Recall in two dimensional case, we have $x=r\cos\theta$ and $y=r\sin\theta$ and $$\iint f(x, y) dxdy = \iint f(r\cos\theta, r\sin\theta) rdrd\theta.$$ Hence, the general formula is similar but still different, especially the ingegrad $\tilde f(r, \omega)$. How do I intepret this, please? How can $\mathbb R^n$ be written as $\mathbb R^+ \times S^{n-1} $? Comparing with the two dimensional situation, $r$ seems to be the same radius. However, the angle $\theta$ in $2$-d case is now replaced by $\omega \in S^{n-1}$. How can this be treated as angle like argument, please? Why and how do we define $\tilde f(r, \omega) = f(r\omega)$? How to interpret the definition of $E_r := \{\omega\in S^{n-1}:r\omega \in E\}$? Could anyone explain these to me, please? More detailed answers are appreciated since I know very little here. Thank you!","['multivariable-calculus', 'measure-theory', 'real-analysis', 'analysis', 'functional-analysis']"
954560,Solve $(\varepsilon-x)y=y'(-x+y^2-2x^2)$,"I need some help, I have this ODE but can't solve it for $y(x)$ , I try every method I know, but with no success,please, somebody can help me? $$(\varepsilon-x)y=y'(-x+y^2-2x^2)$$ Thanks.","['ordinary-differential-equations', 'calculus']"
954575,Proof that the order of any finite $p$-group is a power of $p$,What is the most concise proof that the order of any finite $p$-group is a power of $p$?,"['finite-groups', 'group-theory', 'abstract-algebra']"
954599,Generalization of the Glivenko-Cantelli Theorem,"The classic Glivenko-Cantelli Theorem states that
$$
\sup_{t}|F_{n}(t) - F(t)| \longrightarrow_{a.s.} 0
$$
where $F_{n}(t)$ is the empirical cdf. Looking at the proof of the theorem, it seems to me like it only uses the fact that
$F_{n}(x) \longrightarrow_{a.s.} F(x)$ for each fixed $x$, and that 
both $F_{n}(x)$ and $F(x)$ are monotonic with $0\leq F(x) \leq 1$
and $0 \leq F_{n}(x) \leq 1$. My first question is that if, in general, we have an estimated function $G_{n}(t)$
such that $G_{n}(t) \longrightarrow_{a.s.} G(t)$ for each fixed $t$ with 
$G(t)$ monotonic and $|G(t)| \leq K$, is it true that
$$
\sup_{t}|G_{n}(t) - G(t)| \longrightarrow_{a.s.} 0?
$$ Another question I have is if the above can be generalized to some extent.
That is, if, we have an estimated function $G_{n}(t)$
such that $G_{n}(t) \longrightarrow_{a.s.} G(t)$ for each fixed $t$ with 
$G(t)$ continuous and $|G(t)| \leq K$ for $t \in [a,b]$, is it true that
$$
\sup_{t \in [a,b]}|G_{n}(t) - G(t)| \longrightarrow_{a.s.} 0?
$$
where $a < b$ are finite numbers.","['statistics', 'probability', 'probability-theory']"
954614,Understanding Bernoulli's Inequality,"Here is the proof, I understand it for the most part, but have some specific questions to help me understand better. In the induction step: Line 2, we multiply $(1+x)$ to balance the comparison so we can utilize the induction hypothesis? Line 4, how are we able to add $(1+x)$ to balance the inequality, and then remove $kx^2$ freely? How do I know when I can add 'stuff' and remove 'stuff'?","['induction', 'algebra-precalculus']"
954626,Confused about Pochhammer contour?,"I know some theorems about complex analysis such as the argument principle. But I do not get the Pochhammer contour. I read about it on the wiki page of the beta function , but I do not understand a thing. Why this contour and not another ? Is it based on the argument principle ? Why is it an analytic continuation valid for all complex $a,b$ ? Does the winding number that is $0$ not imply the integral is $0$ as well ?? Im new to complex analysis, so please explain step by step. The wiki page does not explain much. Here it is anyway : http://en.wikipedia.org/wiki/Pochhammer_contour#Applications","['gamma-function', 'complex-analysis', 'contour-integration']"
954630,Differentiation under integral sign without DCT,"Suppose $f: \Omega \times I \subseteq \mathbb{R}^n \to \mathbb{R}$ is differentiable, where $\Omega$ is measurable and $I$ is an open interval. How do you show that if $\frac{\partial f}{\partial t}$ is uniformly continuous in $\Omega \times I$,  then $\frac{d}{dt} \int_{\Omega} f(x,t) dx = \int_{\Omega} \frac{\partial f}{\partial t}(x,t) dx$? You would surely have the left-hand side equal to $\lim_{\epsilon \to 0} \int_{\Omega} \frac{f(x,t+\epsilon)-f(x,t)}{\epsilon} dx$, so it suffices to show the limit commutes with the integral. If I could use the DCT, I'd just take any sequence $\epsilon_n$ going to $0$ and apply the theorem to the sequence $g_n = \frac{f(x,t+\epsilon_n)-f(x,t)}{\epsilon_n}$, which converges to $\frac{\partial f}{\partial t}$ (it shouldn't be difficult to bound the $g_n$). Does uniform continuity of $\frac{\partial f}{\partial t}$ imply uniform convergence of $(g_n)_{n \in \mathbb{N}}$? That's the actual issue. Is there a simple way to see this?","['integration', 'real-analysis']"
954639,"Aluffi, Exercise 2.12, regarding the cokernel in $\sf{Ring}$ of $\mathbb{Z} \hookrightarrow \mathbb{Q}$","I am working in Aluffi's Algebra: Chapter $0$ textbook, and Chapter 3, Exercise 2.12 asks one to determine the cokernel in $\sf{Ring}$ of the imbedding $i \colon \mathbb{Z} \hookrightarrow \mathbb{Q}$.  At the beginning of Chapter 3, Section 5, he hints that the answer is perhaps weird, when he says ""Also, cokernels do not behave as one would hope [in $\sf{Ring}$]"" and then references this exercise. Note that Aluffi assumes that all rings are unital and that ring homomorphisms send $1$ to $1$. Here's my question:  Is the statement ill-defined (or perhaps vacuous -- not exactly sure which description is more accurate)?  It appears to me that the setup of the cokernel in this situation requires that one start with a ring homomorphism $\varphi \colon \mathbb{Q} \to R$, where $R$ is some ring, satisfying $\varphi(i(n)) = 0$ for all $n \in \mathbb{Z}$, but then $\varphi(i(1)) = \varphi(1) = 0$ contradicting the existence of such a ring homomorphism $\varphi$ (assuming $R$ is not trivial). Am I missing something?  If I am right so far, then one quickly realizes that the same problem occurs for every ring homomorphism $\varphi \colon R \to S$.  If this is true, is it better to say that ""cokernels do not exist"" or that ""cokernels are not well-defined"" in $\sf{Ring}$?","['category-theory', 'abstract-algebra']"
954725,Why do the concepts of linear algebra apply to differential equations?,"A lot of the stuff we do to solve differential equations are taken word for word from linear algebra. The concept of linear independence, determinant of the Wronskian used to determine independence, adding a particular solution to the kernel to get the general solution - all this stuff that I'm used to applying on vectors seems to work with functions. Why?","['linear-algebra', 'ordinary-differential-equations']"
954726,Irrational solutions to some equations in two variables,"The next statement is a conjecture of mine, so I dont know if it's true (though quite sure): Let $x,y$ be irrational numbers such that $x^4+y^4=1$. Prove (or disprove) that $x^5+y^5$ is irrational or $x^6+y^6$ is irrational (or both of them are irrational). Edit: just to remove any doubt, my meaning is to prove that at least one of the numbers $x^5+y^5$ and $x^6+y^6$ has to be irrational.","['abstract-algebra', 'number-theory']"
954769,Real Analysis texts: Royden versus Stein & Shakarchi. Which is better? (and other suggestions welcome),"I am taking an introductory ""graduate"" analysis class and am comparing Analysis books that cover measure theory. I have had an ""advanced calculus"" class that covered the standard topics. I am having difficulty deciding what I want to buy. I am wondering how Royden's book compares to Stein and Shakarchi's. Which is better for a beginner? Which takes a more standard approach? Which is more motivated? Also other suggestions are welcome.","['measure-theory', 'reference-request', 'analysis']"
954785,Correlation between sleep hours and brain activity,"Say I am tracking my sleep for 1 week and these are the number of hours I sleep each night: (5, 6, 9, 4, 8, 9, 6) everyday that I track my sleep I am also taking a test that measures how well my brain is working these were my scores: (45, 23, 33, 48, 68, 19, 26) The higher the score the better. Given these numbers, I would like to find out the optimal number of hours I would have to sleep to score the highest on this test. For example, the answer could be X amount of hours would give me the best chance of scoring highest on this test. I would like to know how to find X. Any help that points me in the right direction would be incredibly appreciated!",['statistics']
954807,What Notation Do I Use To Fix Ambiguity Writing Chain Rule,I'm a calculus noob learning over the internet. I think the best way to ask my question is just to put up a little diagram I made in paint. Now this is my attempt to write the chain rule using d/dx notation: So my question is can I use d/dx notation and signify that I'm passing g(x) into the derivative of f(x) without ambiguity as to what I'm doing?,"['notation', 'calculus', 'derivatives']"
954816,"If L = lim_x→a f(x) exists, then |f(x)| → |L| as x → a .","Suppose that f is a real function. a) Prove that if $L = \lim_{x\to a} f(x)$ exists, then $|f(x)|\to |L|$ as $x \to a$ . Proof: Suppose that f is a real function. And suppose $L = lim_{x\to a} f(x)$ exists. Then by definition, this is true when given a real number $a$, in an open interval, then for every $\epsilon > 0$, there exists $\delta > 0 $ s.t $0 < | x - a| < \delta  $ implies $|f(x) - L| < epsilon$. Then by the triangle inequality $|f(x) - L| <= |f(x)| - |L| < \epsilon$. Thus $ \lim_{x\to a} |f(x)| = |L|$. Therefore $|f(x)| \to |L|$ as $x \to a$ Can anyone please help me? I am not sure if this is a correct way to prove it. 
Thank you.","['functions', 'real-analysis', 'limits']"
954843,Helices in Lorentz-Minkowski space $\Bbb L^3$.,"Context: Consider the Lorentz-Minkowski space $\Bbb L^3$, with the metric: $$ds^2 = dx^2 + dy^2 - dz^2$$ (which I'll denote just by $\langle \cdot, \cdot \rangle$) If $\alpha$ is spacelike and ${\bf N}(s)$ is lightlike for all $s \in I$, the Frenet equations are: $$\begin{pmatrix} {\bf T}' \\ {\bf N}' \\ {\bf B}' \end{pmatrix} = \begin{pmatrix} 0 & 1 & 0 \\ 0 & \tau & 0 \\ -1 & 0 & -\tau \end{pmatrix}\begin{pmatrix} {\bf T} \\ {\bf N} \\ {\bf B} \end{pmatrix}$$
where $\alpha$ is assumed parametrized by arc-length, the tangent is ${\bf T}(s) := \alpha'(s)$, the normal is ${\bf N}(s):= {\bf T}'(s)$ and the binormal ${\bf B}(s)$ is the only lightlike vector such that $\langle {\bf B}(s), {\bf T}(s) \rangle = 0$ and $\langle {\bf B}(s), {\bf N}(s)\rangle = 1$. The problem: Definition: A curve $\alpha: I \to \Bbb L^3$ is a $\bf T$-helix if exists a non-zero, constant vector $\bf v$ such that $\langle {\bf
 T}(s), {\bf v}\rangle$ is a constant $ c \in \Bbb R$. I'm trying to characterize all $\bf T$-helices in $\Bbb L^3$, and I'm having trouble in this last case: when $\alpha$ is spacelike and ${\bf N}(s)$ is lightlike for all $s \in I$. My strategy in all of the other cases was to simply suppose that $\alpha$ is a $\bf T$-helix, find some condition on the curvature (when it exists) and torsion, and then try to ""make my way back"". I'm failing here. Suppose $\alpha$ is a $\bf T$-helix. Then exists a constant non-zero vector $\bf v$, and a constant $c$ such that $\langle {\bf T}(s), {\bf v}\rangle = c$. Taking derivatives, we have $\langle {\bf N}(s), {\bf v}\rangle = 0$. If we differentiate this again, we conclude nothing, because in the end, we're just multiplying the last expression by $\tau(s)$. It is easy to check, by applying the Lorentzian inner product with $\bf T, N$ and $\bf B$, that: $${\bf v} =  \langle{\bf T}(s), {\bf v}\rangle {\bf T}(s) + \langle{\bf B}(s), {\bf v}\rangle {\bf N}(s) + \langle{\bf N}(s), {\bf v}\rangle {\bf B}(s)$$
So, in our situation, we have that: $${\bf v} = c {\bf T}(s) + \langle{\bf B}(s), {\bf v}\rangle {\bf N}(s)$$
Differentiating this, we get $0 = 0$, that is, nothing. Can someone help me out of this trap?","['semi-riemannian-geometry', 'frenet-frame', 'curves', 'differential-geometry']"
954849,"Why is $f(x)^{-1}$ used to denote the inverse of a function, and not its reciprocal?","Function notation says that any operations applied to a variable inside the parenthesis are applied to the variable before it enters the function, and anything applied to the function as a whole is applied to the entire function or to the result of the function.  So you could say that... If $f(x)=x^2$ ,
then $f(3x-2)=(3x-2)^2$ , and $3f(x)-3=3x^{2}-3$ . I understand that $f^{-1}(x)$ is used to denote the inverse of a function so... $$f^{-1}(x)=\pm\sqrt{x}.$$ But putting something to the $-1$ power gives you its reciprocal like... $$x^{-1}=\frac{x^{-1}}{1}=\frac{1}{x^1}= \frac{1}{can}$$ So would it not make sense that... $$f^{-1}(x)=\frac{1}{x^2}.$$ My question is why $f^{-1}(x)$ is considered the inverse of $f(x)$ ?  Was this notation chosen randomly, or is there some logical explanation for why it is that way?","['inverse', 'functions']"
954855,The derivative of something with respect to $3x+5$?,"If you take $(3x+5)^2$ and differentiate it with respect to $3x+5$ it's just $2(3x+5)$. Can someone explain to me how this would actually work out? I understand normal derivatives with respect to say, $x$, where at some point $x$, $f '(x)$ is the slope at that $x$ value. But how would this work out in this situation?","['calculus', 'derivatives']"
954920,"Is the space $B([a,b])$ separable?","Let $a$, $b$ be two real numbers such that $a < b$, and let $B([a,b])$ denote the metric space consisting of all (real or complex-valued) functions $x=x(t)$, $y=y(t)$ that are bounded on the closed interval $[a,b]$ with the metric $d$ defined as follows: 
$$ d(x,y) \colon= \sup_{a\leq t \leq b} \ |x(t) - y(t)|.$$ Then how to determine whether or not this space is separable? By definition, a metric space $X$ is said to be separable if it has a countable dense subset, that is, if there is a countable subset $M$ of $X$ such that $\bar{M} = X$.","['general-topology', 'real-analysis', 'analysis', 'metric-spaces', 'functional-analysis']"
954921,Lacking properties of the category of smooth manifolds,"According to Wikipedia ""the category of smooth manifolds with smooth maps lacks certain desirable properties""( http://en.wikipedia.org/wiki/Differentiable_manifold#Generalizations ). What are these desirable properties and why should a geometer care?","['soft-question', 'category-theory', 'differential-geometry']"
954968,Evaluate the Limit as it approaches 1/2,"$$\lim_{x\to \frac12} \frac{2x^2-x}{|x-1/2|}$$ Hi,
I'm just wondering If I answered this right. lim x-> 1/2^+= x(2x-1)/(x-1/2)
             = (2x-1)/-1/2
             =(2(1/2)-1)/-1/2
             =0 $$\begin{align}
\lim_{x\to 1/2^+}&= \frac{x(2x-1)}{x-1/2}\\
             &= \frac{2x-1}{-1/2}\\
             &=\frac{2(1/2)-1}{-1/2}\\
             &=0
\end{align}$$ lim x-> 1/2^-= x(2x-1)/-x+1/2
             =2x-1/-1+1/2
             =2x/1/2
             =2 Therefore lim x-> 1/2 DNE Is this correct? Thanks","['calculus', 'limits']"
955001,"What does it mean for a random variable to ""admit"" a distribution?","Can someone explain the word ""admit"" and explain what would happen if it does not admit a distribution?",['probability']
955052,What real life statistician's job look like?,"I have recently finished statistics course and would like to know if statisticians really do what we covered in the course (usual college level stat course material). The course made me interested in statstician's work. But I have questions, that are not answered in simple "" statistician's work description "". Does your job consist more of checking using t- and F-tests, etc.? Or is it closer to academic tyoe like trying to find the way to reduce bias, etc.? For example (dumb example), if you are testing accuracy of predictions are you considering going deep into assumptions made by the predictors (e.g. constant prices,etc.)? Basically, if you are statistician, could you please share with me (us, at stackexchange) your work routine (I mean things one would not see in typical ""statistician's work description"")?","['statistics', 'soft-question']"
955058,"Proof $\phi(r\cos\theta,r\sin\theta)=\theta$ is not Lipschitz.","Taking $S=\lbrace(x,y)\in\mathbf{R}^2:1<x^2+y^2<9\rbrace\backslash ( [0,\infty)\times\lbrace 0\rbrace),$ and defining $\phi:S\to\mathbf{R}$ as $\phi(r\cos\theta,r\sin\theta)=\theta$ for $1<r<3$ and $0<\theta<2\pi,$ how would I go about showing that $\phi$ is not Lipschitz? I have been given a comment that $\phi$ is a $C^\infty$-function and any partial derivative of $\phi$ will be bounded, but I'm not sure how to proceed. Please can someone explain or suggest a method of attack to this? I know I must show that there is no $K\in\mathbf{R}$ such that $|\phi(v)-\phi(u)|\leq K\|v-u\|$ for all $v,u\in S,$ but I don't know which theorems are useful here, and the result is not intuitive to me. Even just a name of a theorem to help would be great.","['multivariable-calculus', 'real-analysis']"
955066,Deriving $\frac{8}{\sqrt{x-2}}$,"I'm not sure how to derive this: $$\frac{8}{\sqrt{x-2}}$$ I tried $$8 \cdot \frac{1}{\sqrt{x-2}}$$ $$8 \cdot (\sqrt{x-2})^{-1}$$ Differentiating w.r.t. $x$, $$8 \cdot -1 \cdot (\sqrt{x-2})^{-2}$$ $$8 \cdot -1 \cdot \frac{1}{(\sqrt{x-2})^{2}}$$ $$\frac{-8}{(\sqrt{x-2})^{2}}$$ $$\frac{-8}{x-2}$$ But the answer is $$\frac{-4}{(x-2)\sqrt{x-2}}$$ What should I have done?","['calculus', 'derivatives']"
955108,Big-O Function for f(x),"I'm currently taking a Discrete Mathematics course which just started the chapter on The Growth of Functions . A ( very ) brief overview was given in lecture that covered the Big-O definition. Let $f$ and $g$ be functions from the set of integers or the set of real numbers to the set of real numbers. We say that $f(x)$ is $O(g(x))$ if there are constants $C$ and $k$ such that
  $$|f(x)| \le C|g(x)|$$
  whenever $x \gt k$ . $[$This is read as ""$f(x)$ is big-oh of $g(x)$.""$]$ And that is where the lecture left off. Then in the online homework tonight I was given the following problem. Find the best Big-O function for the function $f(n)=1+2+3+ \ldots +(n^2-1)+n^2$ Note: This chapter in the book is five pages long and covers Big-O Notation , The Growth of Combinations of Functions , and Big-Omega and Big-Theta Notation . There are four examples on those three subjects and 75 exercises with no listed answers (so they're fun to gaze at hopelessly). I searched the Google and looked at the Big Omega posts on the StackExchange sites but I was pressed for time and couldn't find what I was looking for. Anyway I'm not the best at this and I tried but can't seem to get it, so here it goes... Using the definition $$1+2+3+\ldots+(n^2-1)+n^2 \le n^2+n^2+\ldots+n^2$$
and since the number of summations of $n^2$ is equal to $n$ it would give you $n(n^2)$ which would be $n^3$? Thus making the following inequality correct
$$1+2+3+\ldots+(n^2-1)+n^2 \le n^2+n^2+\ldots+n^2=n^3$$ and finally
$$f(n)=1+2+3+\ldots+(n^2-1)+n^2 \;\;\text{is}\;\; O(n^3)$$ which came back as being incorrect. The answer turned out to be $n^4$ which I cannot figure out and I was hoping someone could shed some light?","['asymptotics', 'discrete-mathematics']"
955126,"Linear independence of the functions $1,\cos(x),\cos(2x)$","I want to show that the functions $1,\cos(x),\cos(2x)$ are linearly independent in $C[-\pi,\pi]$. I computed the Wronskian determinat of these functions but at the points $x=0,-\pi,\pi$ the obtained determinant vanishes. So, I couldn't obtained the required result. Can you me help me in showing that these are linearly dependent or linearly independent in $C[-\pi,\pi]$. Thanks in advance.","['linear-algebra', 'calculus', 'ordinary-differential-equations', 'analysis']"
955144,Use the law of logarithms to expand an expression,$$\log\sqrt [ 3 ]{ \frac { x+2 }{ x^{ 4 }(x^{ 2 }+4) }  } $$ How is this answer incorrect? $$\frac { 1 }{ 3 } [\log(x+2)-(4\log x+\log(x^ 2+4))]$$,['algebra-precalculus']
955151,Probability of random assignment to form pairs,"So the question goes: I have 100 individuals and 100 different buses, and I randomly assigned each individual to sit on a bus (each bus has equal probability of being selected). How many buses are expected to be empty at the end of assignment? What type of question is this? Does it have a particular name? Also - how does it differ from calculating how many pairs of people will be sitting on the same bus? E.g. 2 people on a bus = 1 pair, 3 people on a bus is 3 pairs.","['statistics', 'random', 'probability', 'random-variables']"
955162,"Can we find an $x, y : x < y$ and $x, y > 0$ and $\lfloor \frac{n}{x}\rfloor$ < $\lfloor \frac{n}{y}\rfloor$ for some integer $n > 0$?","I know there are no solutions when we have just the fraction without the floor, but how do we consider solutions when the floor is there?","['algebra-precalculus', 'number-theory', 'algorithms', 'combinatorics']"
955168,How to find the eigenvalues of tridiagonal Toeplitz matrix?,"Assume the tridiagonal matrix $T$ is in this form: $$
T = \begin{bmatrix}
a       & c        &              &              &   &\\
b       & a        & c            &              &   &\\
        & b        & a            & c            &   &\\
        &          &              &\ddots        &   &\\
        &          &              & b            & a & c\\
        &          &              &              & b & a\\
\end{bmatrix}
$$ we must show that its eigenvalues are of the form $$a + 2 \sqrt{bc} \, \cos \left( \frac{k \pi}{n+1} \right)$$ where $$a=qh^2−1, ~~ b=1- \frac{ph}{2}, ~~ c =1+\frac{ph}{2} , ~~q \leq 0.$$","['tridiagonal-matrices', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'toeplitz-matrices']"
955190,Find the value of $\sqrt{10\sqrt{10\sqrt{10...}}}$,"I found a question that asked to find the limiting value of $$10\sqrt{10\sqrt{10\sqrt{10\sqrt{10\sqrt{...}}}}}$$If you make the substitution $x=10\sqrt{10\sqrt{10\sqrt{10\sqrt{10\sqrt{...}}}}}$ it simplifies to $x=10\sqrt{x}$ which has solutions $x=0,100$. I don't understand how $x=0$ is a possible solution, I know that squaring equations can introduce new, invalid solutions to equations and so you should check the solutions in the original (unsquared) equation, but doing that here doesn't lead to any non-real solutions or contradictions. I was wondering if anyone knows how $x=0$ turns out as a valid solution, is there an algebaric or geometric interpretation? Or is it just a ""special case"" equation? A similar question says to find the limiting value of $\sqrt{6+5\sqrt{6+5\sqrt{6+5\sqrt{...}}}}$, and making a similar substituion for $x$ leads to
$$x=\sqrt{6+5x}$$
$$x^2=6+5x$$
which has solutions $x=-1,6$. In this case though, you could substitute $x=-1$ into the first equation, leading to the contradiction $-1=1$ so you could satisfactorily disclude it. Is there any similar reasoning for the first question? I know this might be a stupid question but I'm genuinely curious :)","['nested-radicals', 'infinite-product', 'radicals', 'proof-verification', 'limits']"
955294,"Prove that $ \int_0^{\pi} \frac{(\cos x)^2}{1 + \cos x \sin x} \,\mathrm{d}x =\int_0^{\pi} \frac{(\sin x)^2}{1 + \cos x \sin x} \,\mathrm{d}x $","In a related question the following integral was evaluated
$$ 
      \int_0^{\pi} \frac{(\cos x)^2}{1 + \cos x \sin x} \,\mathrm{d}x
     =\int_0^{\pi} \frac{\mathrm{d}x/2}{1 + \cos x \sin x} 
     =\int_0^{2\pi}  \frac{\mathrm{d}x/2}{2 + \sin x} \,\mathrm{d}x
     =\int_{-\infty}^\infty \frac{\mathrm{d}x/2}{1+x+x^2}
$$
I noticed something interesting, namely that
$$ 
\begin{align*}
        \int_0^{\pi} \frac{(\cos x)^2}{1 + \cos x \sin x} \,\mathrm{d}x
    & = \int_0^{\pi} \frac{(\sin x)^2}{1 + \cos x \sin x} \,\mathrm{d}x \\
    & = \int_0^{\pi} \frac{(\cos x)^2}{1 - \cos x \sin x} \,\mathrm{d}x
      = \int_0^{\pi} \frac{(\sin x)^2}{1 - \cos x \sin x} \,\mathrm{d}x
\end{align*}
$$
The same trivially holds if the upper limits are changed to $\pi/2$ as well ($x \mapsto \pi/2 -u$).
But I had problems proving the first equality. Does anyone have some quick hints?","['calculus', 'integration', 'definite-integrals', 'trigonometry', 'real-analysis']"
955295,Is $\operatorname{End}_K(V)$ self-opposite?,Let $V$ be a vector space over a field $K$. Is $\operatorname{End}_K(V)$ a self-opposite $K$-algebra?,"['ring-theory', 'linear-algebra']"
955371,Bound for $\sum_{k=1}^\infty\left(\frac{1}{2^k+k^2}\right)$,"I found for the series:
$$S=\sum_{k=1}^\infty\left(\dfrac{1}{2^k+k^2}\right)$$ a bound:
$$S\le\dfrac{\pi^2}{6+\pi^2}$$
which is in good agreement with the approximate value of $S$ calculated with Maple or Mathematica $(S=0.588239...)$, while the ratio: $\dfrac{\pi^2}{\pi^2+6}=0.621918...$ Is it possible to get a sharper bound for $S$? Thanks.","['inequality', 'sequences-and-series']"
955372,Does a set of positive outer measure contain a measurable subset of positive measure?,"Is it true or false that whenever $E \subseteq \mathbb{R}$ is such that $m^*(E) > 0$, where
$$
m^*(E) = \inf\left\{\sum_{n=1}^\infty|b_n - a_n|\, :\mid\, E \subseteq \bigcup_{n = 1}^\infty(a_n,b_n)\right\}
$$
there is some Borel set $B \subseteq E$ such that $m(B) > 0$?","['measure-theory', 'lebesgue-measure']"
955382,Spaces where all compact subsets are closed,"All compact subsets of a Hausdorff space are closed and there are T$_1$ spaces (also T$_1$ sober spaces) with non-closed compact subspaces. So I looking for something in between. Is there a characterization of the class of spaces where all compact subsets are closed? Or at least, is there a name for them?","['general-topology', 'compactness']"
955394,Compact subsets of $L^\infty$,"The Riesz Frechet Kolmogorov theorem gives a necessary and sufficient condition for a subset of $L^p(\Omega)$ spaces for $1\leq p<\infty$ and equipped with Lebesgue measure to be relatively compact for the Banach space topology. Is there any similar result known in case of $L^\infty$?
Thanks","['general-topology', 'compactness', 'lp-spaces']"
955403,Please explain the Sequential Characterization of Limits more clearly.,"Sequential Characterization of Limits (SCL) Let $a \in \mathbb{R}$, let $I$ be an open interval which contains $a$, and let $f$ be a real function defined everywhere on $I$ except possibly at $a$. Then $$ L = \lim\limits_{x\to a} f(x) $$ exists if and only if $f(x_n) \to L$ as $n \to \infty$ for every sequence $x_n \in I \backslash \{a\}$ which converges to $a$ as $n \to \infty$. What I know: I know from learning calculus that a limit doesn't have to exist at a point, but haven't found a proof for that statement. The formal definition of Limit of a sequence (barely).  I understand the concept, but still have trouble with properly writing the proofs. I understand the first part of the statement of SCL; however, the last part confuses me. The domain of $f(x_n)$ is the sequence $x_n$, and $f(x_n) \to L$ means (?) that every point in the domain of $f(x)$ approaches L.  Is SCL only for functions that have a single point in it's range?","['real-analysis', 'analysis']"
955449,Independent set of points in a square.,"Suppose I select points uniformly at random in $[0,1]^{2}$ and two points share an edge if their euclidean distance is less than $r$. Suppose I have $n$ points $v_{1},v_{2},...,v_{n}$ selected in this way, how could I compute the probability that they are all independent given that $1<m<n$ of them are? One way would be to cover the $m$ points with circles of radius $r$ and calculate the probability that the remaining $n-m$ points form an independent set in a region outside that covered by the circles, but you would need to know how much area is covered in the first place which seems difficult to calculate.","['statistics', 'geometry', 'probability', 'combinatorics']"
955450,How are inequalities from IMO built?,I notice that there are lots of apparently difficult inequalities in IMO. Are there some techniques to manipulate well-known inequalities in order to built a difficult exercise? What are the main problem-posing techniques about inequalities?,"['inequality', 'algebra-precalculus', 'contest-math']"
955463,Is every group a permutation group?,"I just read about permutation groups. Before going further this question came up in my mind. Isn't every group a permutation group? The definition says, ""one-to-one mappings of a set onto itself is called a permutation"".
We say the group has a binary operation which also is a one-to-one mapping onto itself. So, the question is, why do we need another name to the same thing?","['permutations', 'group-theory', 'abstract-algebra']"
955482,Sum of squares of maximal minors of a rectangular matrix with orthonormal rows,"A matrix $A$ has $m$ rows and $n$ columns, such that $m \leq n$. We know that each row of $A$ has norm $1$ (the norm of an element $x=(x_1,x_2,...,x_n) \in \mathbb{R}^n$ is $||x||=\sqrt{x_1^2+x_2^2+...+x_n^2}$) and any two rows are  orthogonal (if $y=(y_1,y_2,...,y_n) \in \mathbb{R}^n$ then $x$ and $y$ are orthogonal if their dot product is $0$, i.e. $x_1y_1+x_2y_2+\cdots+x_ny_n=0$. Is the sum of the squares of the minors of order $m$ of $A$ equal $1$? I have already asked this question before, but in a cheeky way, so nobody gave it a try. I think that this is true. What I did, was to find out that $A^tA=I_n$ and I know that the eigenvalues in case $m=n$ have absolute value 1 (they are not necessarily real). Observation: The matrix is not a square matrix. We have $A^tA=I_n$ but $^tAA=I_n$ is not equivalent to the first (if this relation holds, then $n\leq m$ which is not given).
Any ideas?","['eigenvalues-eigenvectors', 'orthogonality', 'matrices', 'linear-algebra', 'determinant']"
955509,Number of solutions of this trigonometric equation.,"Q. Find the number of solutions of the equation $\sin(x) + 2\sin(2x) - \sin(3x) = 3$, in the interval $x\in (0,\pi)$. I tried clubbing the $\sin(x)$ and $\sin(3x)$ terms together but got nothing. I also tried the $\sin(x)$ with $\sin(2x)$ and $\sin(2x)$ with $\sin(3x)$. How do i do it?",['trigonometry']
955527,Rank of euclidean distance matrix,"How do I prove that the rank of a euclidean distance matrix is $p+2$, where $p$ is the dimensionality of the points from which the matrix was created?","['matrices', 'linear-algebra']"
955538,"Confusion regarding almost sure events. If given infinite time, will a discrete-time gaussian process cover the entire real line?","This question really pertains to any discrete time continuous-valued, stationary stochastic process on the real line, but the Gaussian process will be adequate for this question. I have this confusion about zero-probability events. If we observe a discrete-time Gaussian process for any finite length of time, the probability that it will hit a particular real number is $0$. However, this does not imply that it is impossible for the process to take on this value, as impossible events are only a subset of zero-probability events. Now, instead of watching the process for a finite period of time, lets say that you are going to make a bet that at some time in the future, the Gaussian process will take a particular (real-number) value at least once. So here's my confusion: it seems that I can argue this both ways. I can say that since it is a zero probability event, there are an infinite number of other numbers it can visit, so its zero. On the other hand, with infinite time, the empirical CDF that results from the Gaussian process sample path will converge to the actual CDF of a Gaussian RV, so it converges to a distribution that has visited all points in the real line. Can someone provide some insight into which of the above is more accurate when $T=\infty$? As a related question: It seems that the continuous time, nonstationary version of this (Brownian Motion) is actually easier to think about, as the sample paths are continuous and hence must cover all values between its most extreme endpoints, which is asymptotically the entire real line.","['stochastic-processes', 'convergence-divergence', 'probability-theory', 'probability-distributions', 'probability']"
955542,Nestedradicals found in the solution of equation $x^{257}=1$,"I was looking for the exact solutions of $\cos\frac{2\pi}{257}$, it lead me to the following expressions. $A=-8\sqrt{514+18\sqrt{257}+12\sqrt{X}+4\sqrt{12593+561\sqrt{257}-98\sqrt{X}-400\sqrt{Y}}}-4\sqrt{514+18\sqrt{257}+12\sqrt{X}-4\sqrt{12593+561\sqrt{257}-98\sqrt{X}-400\sqrt{Y}}}-4\sqrt{514-18\sqrt{257}-12\sqrt{Y}+4\sqrt{12593-561\sqrt{257}-400\sqrt{X}+98\sqrt{Y}}}-4\sqrt{514+18\sqrt{257}-12\sqrt{X}+4\sqrt{12593+561\sqrt{257}+98\sqrt{X}+400\sqrt{Y}}}+\frac{1}{4}*[15+\sqrt{257}+2\sqrt{Y}+2\sqrt{257+15\sqrt{257}+16\sqrt{X}+14\sqrt{Y}}]*\sqrt{514-18\sqrt{257}+12\sqrt{Y}+4\sqrt{12593-561\sqrt{257}+400\sqrt{X}-98\sqrt{Y}}}$. with $X=\frac{257+\sqrt{257}}{2}$, $Y=\frac{257-\sqrt{257}}{2}$ Using numerical computation, I noticed that : $A=6\sqrt{514-18\sqrt{257}+12\sqrt{Y}+4\sqrt{12593-561\sqrt{257}+400\sqrt{X}-98\sqrt{Y}}}$ I did not succeed in doing the demonstration. Do you think it would be possible to demonstrate such a result? Thank you and good luck.","['radicals', 'nested-radicals', 'algebra-precalculus']"
955554,On the maximum number of polynomials in a certain subspace,"I've already asked this question on mathoverflow, but no one answered. So I put this problem also here. Sorry for that. Let $\mathbb F_q$ be a finite field  and let $e, k$ be positive integers with $k \leq e < q-1$. 
Define $T_e$ to be the set 
$$T_e:=\left\{p(x) \in \mathbb F_q[x] \;|\; \deg p =e \;, lc(p)=1, \; p(x)|x^{q-1}-1 \right\}. $$
I would like to find the value
$$ M(e,k,q):=\max\left\{ | W \cap T_e| \;\; | \; W \mbox{ is a subspace of } \mathbb F_q[x]_{\leq e}, \; \dim W=k+1\right\}. $$ I could determine exactly the value $ M(e,k,q) $ in three simple cases. When $e=k$ then we have 
$$M(e,e,q)= \binom{q-1}{e}.$$
In fact, since $e=k$, we can take $W=\mathbb F_q[x]_{\leq e}$ and so we obtain $W\cap T_e=T_e$. When $k=1$, we have
$$M(e,1,q)=q-e.$$ If $e=q-2$ then 
$$M(q-2, k, q) =k+1.$$ For the general case I conjecture that the maximum $M(e,k,q)$ is obtained by taking a polynomial $p(x)$ of degree $e-k$ that divides $x^{q-1}-1$ and choosing the subspace
$$ W= \langle p(x), xp(x), \ldots, x^kp(x) \rangle.$$
From this I would obtain the following conjecture. Conjecture: Let $q$ be a power of a prime, and let $e,k$ positive integers such that $ 0<k\leq e < q-1$. Then
$$ M(e,k,q) = \dbinom{q-1-e+k}{k}.$$ Could anyone help me to prove or disprove it? Thanks in advance.","['polynomials', 'finite-fields', 'linear-algebra', 'combinatorics']"
955587,A question regarding evaluating a function of a scheme,"I am learning about schemes reading Ravi Vakil's notes. On page 136, he says 
""For example, consider the scheme $\mathbb{A}_k^2 = Spec \ k[x,y]$, where $k$
is a field of characteristic not $2$. Then $(x^2 + y^2)/x(y^2-x^5)$ is a function 
away from the $y$-axis and the curve $y^2 - x^5$. Its value at $(2,4)$ (by which we mean
$[(x-2,y-4]$) is $(2^2 + 4^2) / (2(4^2-2^5))$, as
$$
(x^2 + y^2) / (x(y^2-x^5)) \equiv (2^2 + 4^2) / (2(4^2-2^5))
$$
in the residue field"". I understand that they are equal in the residue field, because I did
the calculations to verify it. But I really don't have an intuition or
idea why this happens (as why evaluating the point ""is"" considering it in
the residue field). I would greatly appreciate any explanation on this matter.
Thanks!","['algebraic-geometry', 'soft-question']"
955623,Coin pair betting paradox (NOT!),"If we throw two fair coins then there are 4 equally probable possibilities: HH, TT, HT, TH. Suppose we can't see the result, but we can check one of those two coins. (doesn't matter which one)
Suppose the checked one is H. Then we know that both of them cannot be TT. So there are now only 3 possibilities: HH, HT, TH. ******And here is my mistake****** Therefore, the probability that the other coin in the pair is T (when we know that one of them is H) is 2/3. Actually the probability is 1/2, because by checking one coin at random we remove only half of the cases in which they are different, so we are left with equal probabilities that both are same, and that they are different. So there is no paradox. Similarly, if we get T when we check one of those two coins, then the possibilities are: TT, HT, TH. So, in this case the probability that the other coin in the pair is H is 2/3. Let say that we have N such random pairs, and for each pair we check one coin and than place a bet on the state of the other. We would naturally always choose the opposite value for the other coin because, as demonstrated above, the probability that the other one will be opposite of the one we checked is always 2/3. However, if those N pairs are truly random, then for large N there will be about N/2 pairs with the coins of same value (TT or HH), and about N/2 pairs with the coins of opposite values (TH or HT). And since we are effectively always betting that the coins have the opposite values, then this implies that we would win about half of the time. How can that be? We are constantly betting on the results which have 2/3 probability, but we win only half of the times. What is wrong with my reasoning?",['probability']
955633,predicate quantifier,"a)There is a tree in the back yard. b)If the tree in the back yard is an elm or an oak, then the treasure
is in the kitchen and not  in the garage. c)If this house is made of bricks or the tree in the back yard is an
oak, then the treasure is  not in the kitchen. d)The tree in the back yard is an elm or the treasure is buried under
the mailbox. e)All houses are made of bricks. f)If the tree in the back yard is an oak, then the treasure is in the
garage. Hello, i am given the above problem to find where is the treasure hidden. and i have currently come up with the following premises: ∃x(Tx):There is a tree in the back yard. T(e):The tree in the back yard is an elm. T(o):The tree in the back yard is an oak. K(t):The treasure is in the kitchen. G(t):The treasure is in the garage. B(h)The house is made of bricks. ∀x(Bx):All houses are made of bricks. M(t):The treasure is buried under the mailbox ∃x(Tx) , a) T(e) v T(o) -> K(t) ^ ~G(t) , b) B(h) v T(o) -> ~K(t) , c) T(e) v M(t) , d) ∀x(Bx) , e) T(o) -> G(t) , f) B(h) ,5,universal instantiation B(h) v T(o) ,7,addition ~K(t) ,3,8,modus ponens T(e) v T(o) -> K(t) , 2,simplification ~(T(e) v T(o)) 10,9, modus ponens ~T(e) ^ ~ T(o) , 11,demorgan ~T(e) ,12,simplification M(t) , 4,13,Modus tollen","['logic', 'discrete-mathematics', 'first-order-logic', 'predicate-logic']"
955672,"ODEs of the form $a''= -f(b,t) b',\,\,\, b''=f(b,t) a'$","In the course of doing some physics I've encountered serveral systems of the form 
$$a''= -f(b,t) b'\\ b''=f(b,t) a'$$ where prime denotes derivative in $t$ and $f$ is maybe a polynomial or e.g. $\cos (a-t)$. I know that it's a non-linear system and I shouldn't expect exact soultions, but I would like to know what sort of methods I might use to obtain analytic approximations (I've successfully used Picard iteration in the linear case $f(t)$) and maybe some indication as to why they are hard to solve. I think but haven't proven that one gets chaotic dynamics even for simple $f$ like $\cos (b)$.",['ordinary-differential-equations']
955678,"Describe explicitly $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m)$.","Describe explicitly $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m) := \{\varphi:\mathbb{Z}_n \rightarrow \mathbb{Z}_m \mid \mathbb{Z}\text{-linear homomorphism}\}$ There is an answer to this question that says $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m) \cong \mathbb{Z}_{(n,m)}$ where $(n,m)=\gcd(n,m)$. But I am having some trouble seeing this. For the sake of an argument, suppose the above answer is true, that $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m) \cong \mathbb{Z}_{(n,m)}$. Suppose $n=4$ and $m=8$. Then $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_4, \mathbb{Z}_8) \cong \mathbb{Z}_4$. Now consider each of the following maps in $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_4, \mathbb{Z}_8)$: $\varphi_1(1)=1$ $\varphi_2(1)=2$ $\varphi_3(1)=3$ $\varphi_4(1)=4$ $\varphi_5(1)=5$ $\varphi_6(1)=6$ $\varphi_7(1)=7$ Are each of these maps not unique? If there are two that are identical, could you please explain which two and why? Thank you! My alternate answer is that $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m) \cong \mathbb{Z}_m$, since I think each $\varphi \in \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}_n, \mathbb{Z}_m)$ is uniquely determined by where it maps $\varphi(1) \in \mathbb{Z}_m$.","['ring-theory', 'abstract-algebra']"
955691,Estimate on the derivative at fixed point,"Let $D$ be a bounded domain and let $f$ be analytic function from $D$ into $D$. Show that if $z_{0}$ $\in D$ is a fixed point for $f$ , then $|f' (z_{0} )| \leq 1$. WHAT I WAS THINKING: To have a conformal mapping from $D$ to the unit disc & after composing it with $f$ ; I was thinking to use Pick's Lemma. So, can anyone tell me any conformal map from any bounded domain to the unit disc?? OR Is there any other way out to solve this problem??",['complex-analysis']
955693,Injective functions and sufficient statistics,"I'm trying to prove that for a random sample $X_1,\ldots,X_n$ that depends on $\theta$, if $T$ is a sufficient statistic for $\theta$, then so is $T'=f\circ T$, for any injective function $f$. My attempt: Since $f$ is injective, if we restrict the target space of $f$ to $\operatorname{range}(f)$, then we can consider $f$ as bijective. Now $T'\in \operatorname{range}(f)$ since $T'=f\circ T$, so $T=f^{-1}\circ T'$. Define $\phi'(u(\vec{x}),\theta)=\phi(f^{-1}\circ u(\vec{x}),\theta)$. Since $T$ is sufficient, we have that $f(\vec{x};\theta)=\phi(T(\vec{x};\theta))h(\vec{x})=\phi(f^{-1}\circ T'(\vec{x};\theta))h(\vec{x})=\phi'(T'(\vec{x};\theta))h(\vec{x})$. Hence, $T'$ is also sufficient. Does this look alright?",['statistics']
955702,How many to rearrange the letters of the word “MAMMAL”. What if all M’s must be together?,"I am trying to get my head around an idea but I can't seem to get it to work. Imagine you have the word ""MAMMAL"" Lets see I wanted to figure out how many ways I could rearrange the letters. Well that is easy. It is simply 6!/3!2! = 60 possibilities But what if I added a restriction to it such that all M's must be together. Then I could consider all M's as one letter and it would be 4!/2! = 12 possibilities. Again I understand that. But what if the restriction was there needs to be a minimum of 2 M's together at all times. If I were to do the same process as the previous example, I would combine 2 M's into one. Which then would become 5!/2! = 60. This seems to be a wrong answer because it is the same as my first calculation of finding all possibilities without any restrictions. Can anyone please explain to me as to how I need to approach the last problem of finding number of combinations where at least 2 M's are always together? Thanks!","['discrete-mathematics', 'combinations']"
955734,A tetrahedron inside another tetrahedron. Could the contained tetrahedron have a greater perimeter then the outside one? [duplicate],This question already has answers here : Can a tetrahedron lying completely inside another tetrahedron have a larger sum of edge lengths? (3 answers) Closed 6 years ago . Suppose you have a tetrahedron. It doesn't have to be regular. Now suppose you have another tetrahedron contained inside the first tetrahedron. Again do not assume it is regular and do not assume that both tetrahedrons are similar. Could it happen that the perimeter of the tetrahedron in the inside is larger then the tetrahedron on the outside? Whether it is or not prove it. Do a proof by contradiction. This one is tricky. I have been thinking about this problem for a long time now and do not see any way to come up with a reasonable solution. The help would be greatly appreciated!,"['geometry', 'platonic-solids']"
955760,Find the order of a subgroup of $S_5$ generated by two elements,"The Question I am trying to solve reads : Find the order of a subgroup of $S_5$ generated by the elements $s=(123)$ and $r=(12345)$. Is this group sovable ? Is it nilpotent ? I tried to compute a couple of terms but then I realized this subgroup is way large, and computing the elements one by one might not be a good idea (Is there another way to compute the order ?) My calculation shows : $r, r^2, r^3, r^4, rs, r^3s, sr $ are all $5-$cycles but there are elements like $r^2s=(14)(25)$ and also $r^4s=(354)$...It seems that all sorts of things can happen in this subgroup...I do not even know how to approach the solvability and nilpotency before I know what the subgroup is... I already appreciate your hints/ideas/answers","['symmetric-groups', 'group-theory', 'abstract-algebra']"
955814,Why do we use only 1/2 for continuity correction in case of approximating binomial random varable to a standard normal random variable?,"I have read about continuity correction in case of approximating a binomial random variable to a standard normal variable. But in all the examples , they only use 1/2 as a continuity correction factor.Let's take an example: Let X be the number of times that a fair coin, flipped 40 times,lands heads. Find the probability that X=20. 
X is a binomial random variable with mean 20 and variance 10. The actual answer is 12.54% Use the normal approximation for this question. \begin{align} 
Ans: P(X=20) = 
                P(19.5 <= X <= 20.5)                                 
             = P( \frac{19.5-20}{\sqrt(10)} < \frac{X-20}{\sqrt(10)} < \frac{20.5-20}{\sqrt(10)} )            
             = P(-0.16 < \frac{X-20}{\sqrt(10)}< 0.16)
             = fi(-0.16) - fi(0.16)  
             = 12.72 \%
\end{align} ; where fi is the distribution function of a normal random variable This is pretty close to the actual answer.. Now if I could have written \begin{align} 
  P(X=20) = 
                P(19.99 <= X <= 20.01)                                 
             = P( \frac{19.99-20}{\sqrt(10)} < \frac{X-20}{\sqrt(10)} < \frac{20.01-20}{\sqrt(10)} )            
             = P(-0.031 < \frac{X-20}{\sqrt(10)}< 0.031)
             = fi(0.031) - fi(-0.031)  
             = 2.4 \%
\end{align}
 I have brought the range very close to 20 instead of just using (19.5,20.5) . Why is the approximation in second case worst than that in first case ??","['probability-theory', 'normal-distribution', 'probability-distributions', 'probability']"
955872,Calculate the dimension of a space of operators,"This is a homework question. First, consider the ring of real polynomials in $n$ variables, $P_n=\mathbb{R}[x_1,\ldots,x_n]$ ($n\geq 2$), and let $S_n$ act on $P_n$ by automorphism (of algebra) by permutating the variables: $\sigma(x_i)=x_{\sigma(i)}$ For each $i=1,\ldots,n-1$, let $s_i$ be the transposition $(i\ i+1)$ (so $s_i(x_i)=x_{i+1}$ and $s_i(x_{i+1})=x_i$). Finally, for each $i$, consider the operator $\Delta_i:P_n\to P_n$ given by
$$\Delta_i(f)=\frac{f-s_i(f)}{x_i-x_{i+1}}$$ (a) Show that $\Delta_i$ is a linear operator on $P_n$ that satisfies the rule
  $$\Delta_i(fg)=\Delta_i(f)g+s_i(f)\Delta_i(g)$$
  (b) Let $D_n$ be the subalgebra generated by $Id_P,\Delta_1,\ldots,\Delta_{n-1}$. Calculate the dimension of $D_3$. This is what I have so far: It is easy to check that $\Delta_i$ is a well-defined operator and that the rule above is satisfied. Moreover, in the basis $\left\{x_1^{\alpha_1}\cdots x_n^{\alpha_n}\right\}$, we have the following (let's write $x(\alpha)=x_1^{\alpha_1}\cdots x_n^{\alpha_n}$ for $\alpha=(\alpha_1,\ldots,\alpha_n)$)
$$\Delta_i(x(\alpha))=x_1^{\alpha_1}\cdots x_{i-1}^{\alpha_{i-1}}x_i^{\min(\alpha_i,\alpha_{i+1})}x_{i+1}^{\min(\alpha_i,\alpha_{i+1})}\left(\sum_{k=0}^{|\alpha_i-\alpha_{i+1}|-1}x_i^kx_{i+1}^{|\alpha_i-\alpha_{i+1}|-1-k}\right)x_{i+1}^{\alpha_{i+2}}\cdots x_n^{\alpha_n}$$
(the sum is $0$ if $\alpha_i=\alpha_{i+1}$) The problem is finding the dimension of $D_3$. I checked that $\Delta_i^2=0$, so $D_3$ is generated (as a vector space) by $Id_P,\Delta_1,\Delta_1\Delta_2,\Delta_1\Delta_2\Delta_1,\ldots,\Delta_2,\Delta_2\Delta_1,\Delta_2\Delta_1\Delta_2,\ldots$, but I couldn`t find any other good relation between $\Delta_1$ and $\Delta_2$ so obtain an upper bound for the dimension of $D_3$ (which I'm guessing is finite).","['linear-algebra', 'dimensional-analysis', 'polynomials']"
955874,Cholesky factor when adding a row and column to already factorized matrix,"I have a positive deifnite, symmetrical, $N\times N$ real matrix $A$ which has 1's on the diagonal and all off-diagonal elements positive and $<1$. Let $A=LL^t$ be the Cholesky decomposition of $A$. Suppose now that I extend $A$ as follows:
$$\left( \begin{array}{cc} A & a \\ a^t & 1 \end{array} \right)$$
where $a$ is a $N\times1$ real vector with positive elements $<1$. Thus the extended matrix has the same structure as the original matrix $A$. I would like to prove that the Cholesky factor of the extended matrix has the form
$$\left( \begin{array}{cc} L & 0 \\ c^t & d \end{array} \right)$$
where $L$ is, again, the Cholesky factor of $A$, $c$ an appropriate $N\times 1$ real vector, and $d$ an appropriate scalar, positive or 0. By definition of Cholesky factor, the following should hold:
$$\left( \begin{array}{cc} A & a \\ a^t & 1 \end{array} \right) = \left( \begin{array}{cc} L & 0 \\ c^t & d \end{array} \right) \left( \begin{array}{cc} L^t & c \\ 0 & d \end{array} \right) = \left( \begin{array}{cc} LL^t & Lc \\ L^tc^t & c^t c + d^2 \end{array} \right)$$
where I just carried out the matrix product. This is promising, and means that we have to prove that we can choose $c$ and $d$ so that these two statements hold:
$$a=Lc$$
$$1=c^tc+d^2$$
The first is easy because $L$ is invertible:
$$c=L^{-1}a$$
Then second equation becomes
$$1=a^t(L^{-1})^tL^{-1}a+d^2$$
or
$$1=a^tA^{-1}a+d^2$$
or
$$d=\sqrt{1 - a^tA^{-1}a }$$
which gives a real $d$ so long as $a^t A^{-1} a<1$, but I am not sure one can prove this. If that helps, the entries of $A$ and inner products of unit vectors. I have not been able to find numerical counterexamples, but the elements of $a$ are not necessarily small and in the worst case its norm is close to $N$. Is there something about the norm of $A^{-1}$ or of $L^-1$ that can help me out here? Thanks,
Stefano","['matrix-decomposition', 'matrices', 'matrix-calculus', 'linear-algebra']"
955875,Why do we set $u_n=r^n$ to solve recurrence relations?,"This is something I have never found a convincing answer to; maybe I haven't looked in the right places. When solving a linear difference equation we usually put $u_n=r^n$, solve the resulting polynomial, and then use these to form a complete solution. This is how to get $F_n=\frac{1}{\sqrt{5}}(\phi^n-(-\phi)^{-n})$ from $F_{n+1}=F_n+F_{n-1}$ and $F_0=0, F_1=1$ for example. I can see that this works, but I don't understand where it comes from or why it does indeed give the full solution. I have read things about eigenfunctions and other things but they didn't explain the mechanics behind this very clearly. Could someone help me understand this?","['recurrence-relations', 'sequences-and-series']"
955888,What happens when the determinant of the Jacobian is zero?,"Let $f \colon \Bbb R^n \rightarrow \Bbb R^n$ be a continuously differentiable function. Let $f'(x)$ denote the Jacobian matrix of $f$ at the point $x \in \Bbb R^n$. I would like to show that if $f$ is one-to-one, then $\exists$ $a \in \Bbb R^n$ such that det$f'(a) \neq 0$. When $n=1$, this result is a consequence of the Mean Value Theorem. For larger $n$, I assume we will need some version of either the Inverse Function Theorem or the Implicit Function Theorem. Thank you for your thoughts!","['multivariable-calculus', 'calculus', 'real-analysis']"
955907,Discrete math. Finding a perfect square.,"The problem is: Find all natural numbers $n$ for which $2^n + 1$ is a perfect square? I am having a bit of trouble finding a generic way of finding these numbers. Of course the first obvious solution is $n = 3.$ For which we have $8 + 1 = 3^2.$
Anyone has any smart ideas?","['discrete-mathematics', 'square-numbers']"
955917,"Equivalence of two definitions of weak solution (from a book, I don't understand something!!!!)","Consider
$$y_t - \Delta y = f$$
$$y(0) = y_0$$
with zero boundary condition. Let $a(t,.,.)$ be the bilinear form associated to $-\Delta$. We have two definitions of weak solutions: We have $y \in L^2(0,T;H^{1}_0)$ with $y_t \in L^2(0,T;H^{-1})$ is a A-weak solution of problem (1) if
  $$\langle y_t(t), v \rangle + a(t,y(t),v) = \langle f(t), v \rangle$$
  for all $v \in H^1_0$ and almost all $t \in [0,T]$. and We have $y \in L^2(0,T;H^{1}_0)$ with $y_t \in L^2(0,T;H^{-1})$ is a B-weak solution of problem (1) if
  $$\int_0^T \langle y_t(t), v(t) \rangle + \int_0^T a(t,y(t),v(t)) = \int_0^T \langle f(t), v(t) \rangle$$
  for all $v \in L^2(0,T;H^1_0)$. The claim is that these two notions of solution are the same. For one side, the proof is like this. Let $y$ be an A-weak solution of (1). We shall show that
$$ \langle y_t(t), v(t) \rangle + a(t,y(t),v(t)) =  \langle f(t), v(t) \rangle \tag{1.61}$$
for all $v \in L^2(0,T;H^1_0)$ for a.a. $t$. This is because: So he proves (1.61) for all simple functions, and hence for the simple functions $v_k$ that converge to an arbitrary $v$,  and the null set does not depend on $v_k$. Then he passes to the limit $v_k(t) \to v(t)$ for a.e. $t$. So in the end the null set does depend on $v$ (as it must do). So why the whole fuss about getting rid of the null set and making it independent of $v_k$ in the first place? What gets messed up if he didn't do that?
(This is on page 43 of ""Optimization with PDE constraints"" by Hinze, Pinnau, Ulbrich.)","['sobolev-spaces', 'measure-theory', 'partial-differential-equations', 'functional-analysis', 'bochner-spaces']"
955941,Integral versus hypergeometric series: how to solve this?,"How can I resolve the following indefinite integral using hypergeometric series? $$
\int (x^3 + 1)^\frac{1}{3} \,dx
$$ Wolfram Alpha indicates that the series of Appell are used, but how to get to this result? Grateful!","['hypergeometric-function', 'integration', 'indefinite-integrals']"
955964,"Hidden Markov Model, transition probabilities which are modeled with an exponential distribution","I'm looking at implementing an algorithm described in a paper, but I'm having trouble understanding how the transition probabilities for a Hidden Markov Model are defined. In the first sections, I have segmented an image into a number of areas, each denoted as ""text"" or ""gap"". The algorithm then uses a HMM to refine these regions, and I'm stuck in the section of the paper that describes the parameters for the HMM. It starts out easy enough by defining two states (c 0 = text, c 1 = gap) and their initial probabilities π 0 , π 1 both being 0.5, but then the transition probabilities are described and there's something I'm missing. It goes: ""The transition probabilities are modeled by an exponential distribution with parameters m j , j ∈ {0,1}, the mean height of each region for the whole document image, as follows a jj (i) = P(s [h,h+H i ] = c j | s [h-H i-1 ,h] = c j ) = exp(-H i /m j ),     j ∈ {0,1} where H i denotes the height of the i-th area and s [h,h+H i ] the state of the region that starts at height h and extends up to h+H i . The transition probabilities of a 01 (i) and a 10 (i) result as the difference of a 00 (i) and a 11 (i) from 1, respectively."" From Papavassiliou, Stafylakis, Katsouros, Carayannis: ""Handwritten document image segmentation into text lines and words"" (Pattern Recognition 43 (2010) pp. 369-377) I can easily do the exp() calculations with the area data that I have, but I don't understand how this becomes a 2x2 matrix. As I understand the formula, the result is dependent on the two variables i (= area index), and j (= 1 or 0) but how do I select i / the area it describes? Update: Additionally, the regions are alternately text or gap; so the P() formula above should equal 0.0, as there are no two regions i, i-1 that have the same state. This would give a transition probabily matrix of: $\begin{bmatrix} 0.0 & 1.0 \\ 1.0 & 0.0 \end{bmatrix}$ It will always transition to the
opposite state at each point in time – which definitely does not seem useful. There's most likely something that I'm misunderstanding in the above, my theoretical grounding isn't very solid. Note: The transition probability matrix has to be 2 x 2 (it describes the probability of transition between states, including staying in the same state, so both dimensions are equal to the number of states).","['exponential-function', 'probability-theory', 'hidden-markov-models', 'bayesian-network', 'probability-distributions']"
955971,"Solve for $x$ when $\sin 2x = \cos x$ where $ x$ is in the domain $ [0, 2\pi]$","Quick question on trig (which I haven't dealt with in a long time): since $\sin 2x = 2\sin x\cos x $ $2\sin x\cos x = \cos x$ $2\sin x\cos x/\cos x = 1$ $\sin x = 1/2$ since $\sin x = 1/2$ in quadrants $1$ and $2$, $x = \pi/6$ and $x = 5\pi/6$ Is this correct? If not, hint please.","['trigonometry', 'calculus']"
955976,Find a space whose dual does not separate points,"I read about the fact that for a locally convex topological vector space $X$, its dual $X^*$ separates points, i.e. for any $x\neq y$ in $X$, $\exists f \in X^*$ such that $f(x)\neq f(y)$. Could you help me to find a non locally convex topological vector space such that its dual does not separate points? Thanks",['functional-analysis']
956003,Determining an explicit line bundle over surface,"The following is an  explicitly defined complex line bundle $E\to\Sigma$ over a closed surface: View $\Sigma$ as a subset of $\mathbb{R}^3$ and consider its Gauss map $n:\Sigma\to S^2$ given by (outward-pointing) unit normal vectors, $n(p)=(n_1(p),n_2(p),n_3(p))$. Given the Pauli matrices $\tau_1 =\bigl( \begin{smallmatrix}
0&i\\ i&0
\end{smallmatrix} \bigr)$ and $\tau_2=\bigl( \begin{smallmatrix}
0&-1\\ 1&0
\end{smallmatrix} \bigr)$ and $\tau_3=\bigl( \begin{smallmatrix}
i&0\\ 0&-i
\end{smallmatrix} \bigr)$, define $\tilde{n}:\Sigma\to M_2(\mathbb{C})$ by $p\mapsto \sum_{j=1}^3n_j(p)\tau_j$. Then $E$ is the subbundle of $\Sigma\times\mathbb{C}^2$ defined by $\lbrace (p,v)\;|\;\tilde{n}(p)v=iv\rbrace$. Is $E$ familiar, say $E\cong T\Sigma$ or $E\cong\underline{\mathbb{C}}$? This is an instance where brute force seems like the only way to approach these questions, as everything is written pointwise instead of being abstractly defined. But I don't have a brute force method at hand. [Edit] I think I can show that $c_1(E)=-1$ for $\Sigma=S^2$, so that it's neither $TS^2$ nor $S^2\times\mathbb{C}$.","['characteristic-classes', 'vector-bundles', 'differential-geometry']"
956025,"Let $X$ be a closed subset of a compact metric space $M$. Then, $X$ is compact.","Theorem : Let $X$ be a closed subset of a compact metric space $M$. Then, $X$ is compact. Query : Since, $M$ is compact, then there is a finite collection $F$ of open sets which covers $M$. Hence, $F$ should cover every subset of $M$, whether be it open or closed. Then, why does the problem define this property only for closed subsets of the compact metric? Thank you for your help.","['general-topology', 'elementary-set-theory', 'real-analysis']"
956061,Help figuring out what this textbook did.,"I was reading my classical mechanics textbook and this appeared in the chapter for oscillations. $$\dfrac{\mathrm d^2x}{\mathrm dt^2}+\omega_0^2x=0\tag{3.31}$$ We can obtain the equation for the phase path, however, by a simpler procedure, because Equation $3.31$ can be replaced by the pair of equations $$\dfrac{\mathrm dx}{\mathrm dt}=\dot x,\quad\dfrac{\mathrm d\dot x}{\mathrm dt}=-\omega_0^2x\tag{3.32}$$ How did the author do that replace the first equation with the second one? (The book is Classical Dynamics by Marion)",['ordinary-differential-equations']
956073,Studying for Abstract Algebra,"Abstract Algebra is actually the first proofs intensive course I am taking and its not a simple topic.  There are many definitions and theorems that I have to know right on the spot for a proof and i find that quite difficult to do.  It takes me quite a while to finish my problem sets but I know on an exam I don't have the luxury of time.  Can any of you provide some advice for doing well on the exams. I mean I have been reading definitions, going over notes and proving theorems already but how should I study or ask myself questions in a way that I can do well on my exams? My weakness, in particular, is in dissecting hard proofs and applying theorems on the spot. My first exam will be on Groups, subgroups, cyclic groups, cosets/lagrange and orbits/alternating groups.","['group-theory', 'abstract-algebra']"
956086,Naturality of the pullback connection,"I'm completely stuck proving the naturality of the pullback connection. The strategy suggested is a follows: We let $\phi: (M,g) \to (\tilde{M}, \tilde{g})$ be an isometry, with connections $\nabla$ and $\tilde{\nabla}$ respectively. Define the ""pullback connection"":
$(\phi^* \tilde{\nabla})_X Y=\phi_*^{-1} ( \tilde{\nabla}_{\phi_* X}(\phi_* Y)). $ Now show that it is symmetric and compatible with the metric, and hence agrees with the unique Riemannian connection on $M.$ I am completely stuck with showing metric compatibility. According to the definition of a symmetric connection, I need to show $(\phi^* \tilde{\nabla})_X \langle Y, Z \rangle= \phi_*^{-1} ( \tilde{\nabla}_{\phi_* X}(\phi_* \langle Y,Z \rangle)) = \langle\phi_*^{-1} (\tilde{\nabla}_{\phi_* X}(\phi_*  Y)),Z \rangle + \langle Y,\phi_*^{-1} (\tilde{\nabla}_{\phi_* X}(\phi_*  Z)) \rangle. $ I am willing to believe that this is just a matter of unwinding definitions. However, I don't even understand how $\phi_* \langle Y, Z \rangle$ should even be defined. Could anyone help get me started by perhaps doing the first few terms of the computation to show me how it should go? (or else guide me to somewhere in the literature where this is done?)","['differential-topology', 'riemannian-geometry', 'differential-geometry']"
956095,When does order of partial derivatives matter?,"I've taken multivariate calculus and am wondering if I can see a specific function where the order of taking the partial derivative matters. I've been told that there are some exceptions where $ \dfrac{\partial ^2 f}{\partial x \partial y} \ne \dfrac{\partial ^2 f}{\partial y \partial x} $, so I'm curious to see what this looks like. EDIT:
And why would this true?","['multivariable-calculus', 'partial-derivative']"
956110,Discrete Math -- Sets,"I am struggling with thinking about this. Any help would be great!! A medical research survey categorizes adults as follows: by gender (male or female) by age group (age groups are 18-25, 26-35, 36-50, 51+) by income (less than 30k/year, 30k-60k/year, more than 60k/year) for women only: by whether they have been pregnant (yes/no) for men only: by frequency of undergoing prostate exams (frequently, rarely, never). What minimum size of a set of adults will guarantee that there are two people in it with matching characteristics in all categories? You do not need to explain your answer.",['discrete-mathematics']
956200,Dirichlet Distribution - the underlying intuition.,"I'm not a math expert, but I need dealing with some math tools for natural language processing research. One of the most common tools is the Dirichlet distribution. I know that with a multinomial distribution I can estimate the probability of a vector of outcomes to happen given a vector of a priori probabilities. I've tried to understand the Dirichlet distribution comparing to the multinomial case, but I'm facing difficulties since most ""tutorials"" use too much formal jargon, which I don't have enough background knowledge to absorb. My guess is that Dirichlet distribution is a multinomial with more ""vectors"" of parameters, but I'm not sure if it's the real thing. Hopefully someone will be capable of bringing a proper answer according to my level of expertise in statistics (if there is any). Thank you in advance.","['statistics', 'intuition', 'multinomial-coefficients']"
956209,A property of homogeneous of degree p functions:,"Prove that if $f(x_1,...,x_n)$ is homogeneous of degree $p$, i.e; $f(tx)=t^pf(x)$. Then: $$(x_1 \frac { \partial}{\partial x_1} +...+x_n \frac { \partial}{\partial x_n})^mf(x_1,...,x_n)=p(p-1)(p-2)...(p-m+1)f(x_1,...,x_n)$$ I've tried using the multinomial theorem and doing some induction over $m$, however I haven't been able to prove it even for $m=2$. Is this approach right, or what would you do?","['homogeneous-equation', 'partial-derivative', 'derivatives', 'real-analysis']"
956254,Expressing a summation using matrix algebra,"Consider the $r \times n$ matrix 
$$\begin{pmatrix}
X_{11} & X_{12} & \cdots & X_{1n} \\
X_{21} & X_{22} & \cdots & X_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
X_{r1} & X_{r2} & \cdots & X_{rn}
\end{pmatrix}\text{.}$$
Define 
$$\begin{align*}
&\bar{X} = \dfrac{\sum\limits_{i=1}^{r}\sum\limits_{j=1}^{n}X_{ij}}{nr} \\
&\bar{X}_{i} = \dfrac{\sum\limits_{j=1}^{n}X_{ij}}{n}\text{.}
\end{align*}$$
I am interested in knowing if there is a possible way to write the summations
$$\begin{align*}
\hat{v}^{S} &= \sum\limits_{i=1}^{r}\sum\limits_{j=1}^{n}\left(X_{ij}-\bar{X}_{i}\right)^{2} \\
\hat{a}^{S} &= \sum\limits_{i=1}^{r}\left(\bar{X}_i - \bar{X}\right)^{2}
\end{align*}$$
in terms of matrix operations (anything one would learn in a first course in linear algebra, such as multiplication of matrices, inverses of matrices, determinants, eigenvalues, etc.). The reason why is because I have to memorize these formulas for the actuarial exam I will be taking soon, and I am not interested in memorizing summations if there is a way to express them in matrix form. There may not be an answer to what I seek, and I might just have to memorize these summations as is, but I thought I would ask in case there is. ETA : I did pass this exam (at least 93% scored) but am still interested in knowing if there is a solution to this problem.","['statistics', 'average', 'matrices', 'summation', 'actuarial-science']"
956257,Prove that $A = B$ if and only if $A \subseteq B$ and $B \subseteq A$,I want to prove that $A = B$ iff $A \subseteq B$ and $B \subseteq A$. I'm unsure of how to approach this problem. It seems really easy but I have no idea. Help would be greatly appreciated.,"['logic', 'elementary-set-theory']"
956273,How to show that if $X_n \downarrow 0$ then $P(X_n >\epsilon) \downarrow 0$,"My solution is as follows: If $X_n \downarrow 0$ then $\forall \epsilon > 0~ \exists N\ge n $ such that $X_n < \epsilon$. This means that $$I_{X_n \ge \epsilon} = I_{X_n = \epsilon} + I_{X_n > \epsilon} =0$$ Now if I take expectations, then $$P(X_n=e) +P(X_n > \epsilon) = 0$$ Since probabilities are non-negative, this means that $P(X_n > \epsilon) = 0$ and the proof is complete. I can't help but have the feeling it's somehow wrong. First it seems like I proved a much stronger condition and two, if $X_n$ is a continuous function that limits to a singularity, the probability of $X_n$ being greater than a certain number will never be actually 0. So where did I go wrong? Thanks. UPDATE Thanks to Mike's comments, I am trying the following: Define $E_n = \cup_{i \ge n}\{X_i > \epsilon\}$, the set of points $\omega \in \Omega$ for which the sequence $X_i(ω)$, for $i \ge n$, is above $\epsilon$ at least once. To show that $P(E_n) \downarrow 0$, I proceed as follows: $$P(E_n) = P(\omega \in \cup_{i \ge n}\{X_i > \epsilon\})$$ By the definition of pointwise convergence, I can claim that for each $\omega$, $\exists N \ge n  $ such that $X_i(\omega) < \epsilon$. Essentially I can always take an $N$ big enough to knock out any $\omega$ from $E_n$. Then given an $\epsilon$, I take such $N$, which means that for $i > N$, $$I_{X_i(\omega) > \epsilon} = 0 $$ Taking its expectation, I can say that $$P(E_n) = 0 $$ From here I'm not sure how to show that $P(E_n)$ is strictly greater than $P(X_n > \epsilon)$.","['statistics', 'probability', 'probability-theory']"
956278,Characterization of ideals of algebra of continuous functions on a compact space.,"I was reading this PlanetMath page on the connections between the topology on a compact Hausdorff topological space $X$ and the maximal ideals on the algebra of continuous functions $C(X)$ on $X$ ,
which basically states the following two results: Lemma. Let $I\subset C(X)$ be an ideal. Either $I=C(X)$ ,
or there exists $p\in X$ such that $f(p)=0$ for all $f\in I$ . Theorem. An ideal $I\subset C(X)$ is maximal if and only if  there exists $p\in X$ such that $$I=\{f\in C(X):f(p)=0\}.$$ This lead me to the following question: Question. Does there exist a correspondance between open sets in $X$ and the ideals of $C(X)$ (or a subclass of ideals)? Clearly,
every set of the form $$I_U=\{f\in C(X):f(U^c)=0\}$$ where $U\subset X$ is open is an ideal of $C(X)$ .
Is the converse true,
i.e.,
if one has an ideal $I\subset C(X)$ ,
does there exist an open set $U$ such that $I=I_U$ ? If one defines $$K=\bigcap_{f\in I}f^{-1}(0),$$ then it is easy to see that $I$ will be contained in an ideal of the form $I_U$ ,
where $U$ is the complement of the compact $K$ , but must it be equal? Or perhaps $I$ is not necessarily equal to $I_U$ , but $I_U$ is the closure of $I$ under the supremum norm $\|\cdot\|_{\infty}$ ?","['general-topology', 'commutative-algebra', 'abstract-algebra']"
956298,Group of Units in Cyclotomic Integers,"I'm trying to show that for any $p$-th root of unity $\zeta$, where $p$ is an odd prime, we have $\mathbb{Z}[\zeta]^{\times} = \left<\zeta\right>\mathbb{Z}[\zeta + \zeta^{-1}]^{\times}$. Obviously the $\left<\zeta\right>$ factor comes as a result of Dirichlet's unit theorem. However, I'm struggling to show that $\mathbb{Z}[\zeta + \zeta^{-1}]^\times$ is a free abelian group of rank $r + s - 1$, where $r$ is the number of real embeddings of $\mathbb{Z}[\zeta]$ and $s$ is the number of complex conjugate pairs of embeddings.","['algebraic-number-theory', 'number-theory']"
956315,What do limits of functions of the form $te^t$ have to do with l'Hopital's rule?,"I have an improper function that I have to integrate from some number to infinity. Once integration is done, the function is of the form $te^t$ .
What I'm wondering is what does this have to do with l'Hopital's rule? From reading my book, I see the following: We know that $e^t \to 0$ as $t \to -\infty$ , and by l'Hopital's rule we have $$\lim_{t\to-\infty} te^t = \lim_{t\to-\infty} \frac{t}{e^{-t}} = \lim_{t\to-\infty} \frac{1}{-e^{-t}} = \lim_{t\to-\infty} -e^t = 0.$$ I know what l'Hopital's rule is The limit of a quotient of functions is equal to the limit of the quotient of their derivatives. I don't understand what this has to do with the explanation above. Can somebody help me understand this please?","['improper-integrals', 'integration', 'limits']"
956322,Second year mathematics textbook recommendations.,"I am currently majoring in pure mathematics, and would like to purchase textbooks that would not only assist with content covered in the courses, but will serve as a great reference throughout my studies. Furthermore, if you believe that I will only ever use the textbook for the semester in which I am studying the subject, then please do not recommend it. Here are my second year mathematics courses: Several Variable Calculus Linear Algebra Theory of Statistics Mathematical Computing Fundamental Analysis and Abstract Algebra Theory and Application of Differential Equations Complex Analysis","['book-recommendation', 'abstract-algebra', 'linear-algebra', 'reference-request', 'analysis']"
956329,"Optimal strategy for picking cards: win a dollar for red, lose one for black, and stop at any time","Suppose I have four cards: two black, two red. I draw them one by one. Every time I draw a red card, I win a dollar, and every time I draw a black card, I lose a dollar. I can choose to stop at any time I want. What is the optimal strategy for choosing when to stop, and what is its expected value? I did this by brute force to get $2/3$, but I don't know if there is a more clever way out there.",['probability']
956335,Upper semicontinuity of fibre dimension on the target,This is Vakil 18.1.C. Suppose $\pi : X \to Y$ is a projective morphism where $Y$ is locally Noetherian (or more generally $\mathcal{O}_Y$ is coherent over itself). Show that $\{y \in Y : \dim \pi^{-1}(y) > k\}$ is a Zariski-closed subset of $Y$. He says this exercise is important to know how projective morphisms work so I ideally I should work it out for myself. But I am reading the chapter without having read a lot of the preceding chapters so I am finding it rather difficult. I would like some copious hints and directions. His suggestion seemed to me to be to find a hypersurface upstairs that could somehow collect the fibres into a closed subset. Then perhaps to push down this closed subset while claiming $\pi$ is a closed map. But I don't see how to this. Thanks.,['algebraic-geometry']
956371,How to evaluate the limit $\lim_{x\to 0} ((1+2x)^{1/3 }-1)/ x$ without using the l'Hospital's rule?,$$\lim_{x\to 0} \frac{(1+2x)^{\frac{1}{3}}-1}{x}.$$ Please do not use the l'hospital's rule as I am trying to solve this limit without using that rule... to no avail...,"['limits-without-lhopital', 'calculus', 'limits']"
956388,Show that any convex subset of $R^k$ is connected,I need to prove that any convex subset of $R^k$ is connected. I have seen the proof in Rudin's book and on numerous websites but they all use some prior results. I want to do it without using results where one establishes something for some other question and then uses the result to prove this.,['general-topology']
956415,Is $x^{1-\frac{1}{n}}+ (1-x)^{1-\frac{1}{n}}$ always irrational if $x$ is rational?,"Let $x$ be rational with $0<x<1$ and let $y$ be the rational defined by $y = 1 - x.$ Let $n$ be any natural number with $n>2.$ Then I want to prove that $$x^{(1-1/n)}+ y^{(1-1/n)}$$ will never be a rational. Here is my attempt: Let $x=\dfrac{a}{c}$ and  $y=\dfrac{b}{c}$ where $a,b$ are positive integers such that $a+b=c.$ Then it is equivalent to show that the following number is irrational,
$$a\Big(1+\frac{b}{a}\Big)^{1/n}+b\Big(1+\frac{a}{b}\Big)^{1/n},∀n\in\mathbb N\setminus\{1\}.$$
After this I was stuck. How can I continue? Hints are also welcome.","['radicals', 'rationality-testing', 'number-theory']"
956424,Diagonalization of restrictions of a diagonalizable linear operator,"I realized that I have some difficulties for prove this exercise. Let $T : V \rightarrow V$ be a linear operator on a finite dimensional vector space $V$ over a field $F$, and invariant subspaces $U,W \subset V$  such that $V = U \oplus W$. Show that if $T$ is diagonalizable then $T_{|U}, T_{|W}$ are  diagonalizable. Any help would be greatly appreciated. Thanks!",['linear-algebra']
956439,Uniqueness of projection in a Banach space,"Let $X$ be a Banach space, $M$ be a subspace of $X$ and $x \in X$ be any vector in $X$. Consider $\displaystyle \hat{x}_M=\arg \inf_{m\in M}\|x - m\|$. Under what conditions for $l_p$ norms $p = 1,...,\infty$ is $\hat{x}_M$ unique? Assume that solutions to this infimization problem exist. Note: Uniqueness may not be possible for all $l_p$ norms. I am aware about counter examples in $l_\infty$ but would like to know counter examples as well as restrictions under which uniqueness would prevail in other $l_p$ norms.","['convex-analysis', 'locally-convex-spaces', 'functional-analysis', 'banach-spaces']"
