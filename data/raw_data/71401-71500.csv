question_id,title,body,tags
874295,Product of Lebesgue and counting measures,"Let $\mathbb R$ be endowed with the standard Euclidean topology and let $\widetilde {\mathbb R}$ denote the line endowed with the discrete topology. Let $\mu$ and $\nu$ denote the Lebesgue and counting measures on these two spaces, respectively. Suppose that $E\in\mathscr B_{\mathbb R\times\widetilde{\mathbb R}}$ is a Borel-measurable set on the product space. For each $y\in\widetilde{\mathbb R}$, define $$E^y\equiv\{x\in\mathbb R\,|\,(x,y)\in E\}.$$ Assume also that $$G\equiv\{y\in\widetilde{\mathbb R}\,|\,\mu(E^y)>0\}$$
is a countable set and also that $$\sum_{y\in G}\mu(E^y)<\infty.$$ I am trying to prove the following: $$\boxed{(\mu\times\nu)(E)=\sum_{y\in G}\mu(E^y),}\tag{*}$$
where $$(\mu\times\nu)(E)\equiv\inf\left\{\sum_{k=1}^{\infty}\mu(A_k)\cdot \nu(B_k)\,\Bigg|\,E\subseteq\bigcup_{k=1}^{\infty}A_k\times B_k,\,A_k\in\mathscr B_{\mathbb R},\,B_k\subseteq\widetilde{\mathbb R}\,\forall k\right\}\tag{**}$$
is the product measure on $\mathscr B_{\mathbb R}\otimes\mathscr B_{\widetilde{\mathbb R}}=\mathscr B_{\mathbb R\times\widetilde{\mathbb R}}$. (Remark: I have already proved that these latter two $\sigma$-algebras coincide and also that $E^y\in\mathscr B_{\mathbb R}$ for any $y\in\widetilde{\mathbb R}$). Attempts: It is not difficult to show that $(\mu\times\nu)(E)\geq\sum_{y\in G}\mu(E^y)$, given that $$E=\bigcup_{y\in\widetilde{\mathbb R}}E^y\times\{y\}\tag{***}$$
and this union is disjoint. As for the other direction, note that $\{E^y\times\{y\}\}_{y\in\widetilde{\mathbb R}}$ cover $E$ according to $(***)$, so one could use the infimum property of the product measure $\mu\times\nu$ in $(**)$ to establish the desired inequality. The problem is that this union is uncountable (even though only countably many $y\in\widetilde{\mathbb R}$ have $m(E^y)>0$), so it may not be a suitable cover based on which $(**)$ could be made use of. Any hints/thoughts are appreciated. UPDATE #1: Possible counterexample: Let $E\equiv\{(x,x)\,|\,x\in[0,1]\}$. Clearly, $E^y=\{y\}$ if $y\in[0,1]$ and $\varnothing$ otherwise. It is clear also that $E\in\mathscr B_{\mathbb R}\otimes\mathscr B_{\widetilde{\mathbb R}}$. It follows that $G=\varnothing$ and the right-hand side of $(*)$ vanishes. However, it is well-known that $(\mu\times\nu)(E)=\infty$ whenever $\widetilde{\mathbb R}$ is endowed with the Borel $\sigma$-algebra and the counting measure . In the present setting, though, $\widetilde{\mathbb R}$ is endowed with the discrete topology and the corresponding $\sigma$-algebra $2^{\widetilde{\mathbb R}}$! Hence, there may still be some hope that the left-hand side of $(*)$ vanishes, too; to do this, one must cover $E$ with a countable union of rectangles of the form $(A_k,B_k)\in\mathscr B_{\mathbb R}\times 2^{\widetilde{\mathbb R}}$ the measures of whose products are small. To achieve the desired result, at least some of $B_k$'s must be non-Borel-measurable (say, cleverly chosen Vitali sets), in order to avoid the conclusion that $(\mu\times\nu)(E)=\infty$. Is such a choice of non-Borel sets possible, or is it the case that $(\mu\times\nu)(E)=\infty$ with the discrete topology, too? UPDATE #2: The result should be true. According to Bogachev (2007) (Example 7.14.65, pp. 154–155), the measure $$E\mapsto\sum_{y\in\widetilde{\mathbb R}}\mu\left(E^y\right)$$ coincides with $(\mu\times\nu)$, as defined above in $(*)$, but this result is mentioned only; no proof is provided. If this is true, then the possible counterexample is obviated, too, and the diagonal of $[0,1]\times[0,1]$ should have a vanishing product measure.","['measure-theory', 'lebesgue-measure', 'real-analysis']"
874317,Changing order of integration limits,"$$\int_{1}^{3} \int_{0}^y x+y-1 \, dx \, dy = 9$$ How would I change the order of integration here? Wouldn't this require two integrals? $$\int_{0}^{1} \int_{1}^3 x+y-1 \, dy \, dx + \int_{1}^{3} \int_{x}^3 x+y-1 \, dy \, dx = 9$$ Why does this integral below work? $$\int_{0}^{3} \int_{x}^3 x+y-1 \, dy \, dx = 9$$ Is this just a coincidence? I'm not sure how to plot this in 3D. Here's a graph of the xy plane and the boundaries of the region on it. This is how I visualized the region. Perhaps I did something wrong? I am finding the volume between the surface z = x + y and z = 1",['integration']
874324,"On the spectrum of a product in a Banach algebra, in specific case","Let $A$ be a Banach algebra, and suppose that $a,b\in A$ have spectra that satisfy: 
$\sigma(a) \subset U$, and $\sigma(b)\subset U$, 
where $U$ is the open right half-plane of complex numbers with positive real part. Is is true that $\sigma(ab)$ does not contain any element of the form $-r$ for $r\geq 0$ ? That's obviously the case when $a$ and $b$ commute, but I can't find a counterexample in the noncommutative case.","['banach-algebras', 'functional-analysis']"
874337,An Inequality with Prime Numbers,"Let $m\geq 8$ be an integer, and let $q$ be the smallest prime that is greater than $m$. Let $p$ be a prime that satisfies $q\leq p<q^2$, and let $p_0$ be the smallest prime such that $p_0q>p^2$. I would like to show that $(p_0-m)(q-m)\leq p^2-pm$. I have tried some small examples, and the left-hand side seems to be much less than the right-hand side. However, I cannot seem to find a way to prove the inequality in general. Any advice would be greatly appreciated. Thank you.","['prime-numbers', 'inequality', 'number-theory']"
874341,Bayesian linear regression cost function,"I am studying classification using linear regression . Now, I want to map it in Bayesian regression. Let talk about binary classification using linear regression again. Assume that I have a set $X=${$x_1,x_2...x_n$} and binary lable $y$={$0,1$}. Binary classification using linear regression task can embedded in to minimum loss function, where: $h(x)=ax+b$ is linear regression line. 
$$L=\sum(h(x)-y)^2$$
It is very clear fomular and discussed in lecture note . Now I want to map it in Bayesian rule. Bayesian rule can express:
$$\max(p(y=0;1\mid X,a,b))$$
We have: $$p(y=0;1\mid X,a,b)=p(X\mid y,a,b)\cdot P(X)$$
Hence, the loss function with Bayesian classification case are given
$$L_{Bayesian}=\sum(p(X\mid y=1,a,b)\cdot P(X)-p(X\mid y=0,a,b)\cdot P(X))$$
Is the Bayesian's loss fomular correct? Thank you so much.","['statistics', 'regression', 'linear-algebra', 'bayesian']"
874367,Proving a specific limit of integrals without using the Monotone Convergence Theorem,"I am trying to prove the follow exercise without using the Monotone Convergence Theorem. Let $(X, \mathfrak{M}, \mu)$ be a measure space. Suppose $f \geq 0$ is measurable. Prove that $$\lim_{n \rightarrow \infty} \int{f \wedge n} \> d\mu = \int{f} d\mu.$$ (Here, the author defines $f \wedge n (x) = \min\{f(x),n\}$ for each $n \in \mathbb{N}$.) $\textbf{Attempt at Solution:}$ Let $\epsilon > 0$ and let us suppose $ \int{f}  d\mu < \infty$. We note the following: $(1)$ $(f \wedge n)$ converges to $f$ pointwise (for each $x$ find an $N$ so large that $f(x) \leq N$), $(2)$ for each $n \in \mathbb{N}$, $f \wedge n \leq f$ for all $x \in X$, $(3)$ $(f \wedge n)$ is monotonically increasing and, therefore, $(\int{f \wedge n} \> d\mu)$ is monotonically increasing. Item $(2)$ imples $\int{f \wedge n} \> d\mu \leq \int{f} d\mu$ for each $n$. The value $\int{f} d\mu - \epsilon$ is not an upper bound for the set $\{ \int{\phi} \> d\mu : \phi \text{ is simple, measurable and } 0 \leq \phi \leq f\}$. Hence, there exists some simple, measurable function $\phi_{0}$ such that $\int{f} d\mu - \epsilon < \int{\phi_{0}} \> d\mu \leq \int{f} d\mu$. Suppose $\{y_{1}, \ldots, y_{n}\}$ is the range for $\phi_{0}$. Put $N=\max\{y_{1}, \ldots, y_{n}\}$. Then, $\phi_{0} \leq f \wedge n$ for $n > N$. Consequently, $n > N$ implies $$\int{f} d\mu - \epsilon < \int{\phi_{0}} \> d\mu \leq  \int{f \wedge n} \> d\mu \leq \int{f} d\mu <  \int{f} d\mu + \epsilon.$$ That is, $\lim_{n \rightarrow \infty} \int{f \wedge n} \> d\mu = \int{f} d\mu.$ If $ \int{f}  d\mu = \infty$, our desired results follows from Items (1) and (3).* Is the above solution attempt correct? Thank you. *I really want to be more explicit here. Let $M > 0$ be arbitrary. Assume $ \int{f}  d\mu = \infty$. By definition, $\int{f} \> d\mu = \sup \{ \int{\phi} \> d\mu : \phi \text{ is simple, measurable and } 0 \leq \phi \leq f\}$. So, there must exist some simple, measurable function, say $\phi_{M}$, such that $M < \int{\phi_{M}} \> d\mu$. As in the previous case, suppose $\{y_{1}, \ldots, y_{n}\}$ is the range for $\phi_{M}$. Put $N=\max\{y_{1}, \ldots, y_{n}\}$. Then, $\phi_{M} \leq f \wedge n$ for $n > N$. Consequently, $M < \int{f \wedge n} \> d\mu $ for $n > N$. Because $M$ was arbitrary, $\int{f \wedge n} \> d\mu \rightarrow \infty$ as $n \rightarrow \infty$.","['measure-theory', 'solution-verification']"
874389,Checking if the Hessian is the derivative of the gradient,"Suppose $f: \Bbb R^n \to \Bbb R$. I have a code that computes the gradient of $f$. I have another code that computes the Hessian of $f$ times a vector. Now I want to check if they are correct. Specifically, I am checking of the Hessian times vector is the directional derivative of the gradient. I have Hessian(x).v \approx (1/h) * (grad(x+h.v) - grad(x)) where h is a scalar. Define: fderror:= (Hessian.v - (1/h) * ( grad(x+h.v) - grad(x))))^T (Hessian.v - (1/h) * ( grad(x+h.v) - grad(x)))). For some reasons, as $h$ decreases, my $\text{fderror}$ increases and vice versa. And when $h$ is around 1e-10 , my $\text{fderror}$ is around 1e+00 . Is it due to floating point
or my Hessian-times-vector is not correct? I would greatly appreciate your help.","['floating-point', 'multivariable-calculus', 'numerical-methods', 'analysis', 'finite-differences']"
874390,Different Definitions Of The Sine Function,"I was hoping someone could give me a flow chart or high-level map connecting all of the definitions of the sine function, with some of the reasons why we care next to each. I've tried this but I'm not able to fill in the details to my satisfaction. Here are a few definitions I know, and it's clear how some are connected to each other. There is definitely many more I am missing. The first definition of $\sin\theta$ is usually as the angle determined in a right triangle by  $$\sin^{-1}:[-1,1]\to[0,2\pi] \ , \ \frac{\text{opp}}{\text{adj}}\mapsto \sin^{-1}\left(\frac{\text{opp}}{\text{adj}}\right)$$ Or to be the $y$-coordinate of a point on the unit circle. .
That is $$\sin:[0,2\pi]\to[-1,1] \ , \ \theta\mapsto \sin\theta$$ There is the continued fraction definition $$\sin:\mathbb{R}\to\mathbb{R} , \ , x\mapsto \sin x:=\dfrac{x}{1+\dfrac{x^2}{2\cdot 3-x^2+\dfrac{2\cdot 3x^2}{4\cdot 5-x^2+\dfrac{4\cdot 5x^2}{6\cdot 7-x^2+\ddots}}}}$$ There's also the power series definition $$\sin:\mathbb{R}\to\mathbb{R}\ , \ x\mapsto \sum_{n=0}^\infty\frac{(-1)^n}{(2n+1)!}x^{2n+1}$$ and the extension to $\mathbb{C}$ by power series $$\sin:\mathbb{C}\to\mathbb{C}\ , \ z\mapsto \sum_{n=0}^\infty\frac{(-1)^n}{(2n+1)!}z^{2n+1}$$ or Euler's formula $$\frac{e^{iz}-e^{-iz}}{2i}$$ or as the imaginary part divided by the modulus of a complex number.","['geometry', 'power-series', 'continued-fractions', 'exponential-function', 'trigonometry']"
874394,Software tools for medium-scale systems of polynomial equations,"I am attempting to find all real solutions of a system of 12 polynomial equations in 12 unknowns. The equations each have total degree 6 and contain up to 1700 terms. I am only interested in real solutions. The equations were derived as the gradients of a sum-of-squares cost function, which I am attempting to find all global optima of. I believe there are a finite number of real solutions but I have not confirmed this yet. I have floating point coefficients and I'm looking for numerical solutions (rather than symbolic solutions). Which software packages (and which functions specifically) are generally most promising to solve such a problem? I am aware of various functions in Maple, Matlab, and Mathematica that can solve systems of polynomial equations but there are a large number of options in each software package and I'm interested in advice on where I should be looking first for problems of this scale.","['algebraic-geometry', 'numerical-optimization']"
874404,Proof for Surjections,"I'm reading through Basic Algebra I (which I enjoy so far. Thoughts on this for self-studying?) and am having a difficult time proving surjection. I believe I understand the concept, but when it comes to the proof I'm not sure how I'm supposed to prove it. Is this an acceptable proof, or is it at least part of the final proof? $f$ and $g$ are surjective $\implies f \circ g$ surjective Known:
$$\forall y\in Y, \exists x \in X \mid y = f(x)$$
$$\forall z\in Z, \exists y \in Y \mid z = g(y)$$ Therefore:
$$\forall y\in Y \texttt{ and }\forall z\in Z, \exists x \in X \mid y = f(x), z = g(y) = g(f(x)) = (g \circ f)(x)$$ So I guess the final line should be: $$\forall z \in Z, \exists x \in X \mid z = (g \circ f)(x)$$ P.S. This is my first post here, so hopefully the style isn't too bad. EDIT: What if I included an extra set that includes the members of Y that exist for z = g(y)? $$A = \{ y \in Y \mid z = g(y)\}$$
$$\forall y_A \in A, z \in Z, \exists x \in X \mid y = f(x) \texttt{ and } z = g(y_A) = g(f(x))$$ $$\forall z \in Z, \exists x \in X \mid z = g(f(x))$$ (Perhaps I'm not explaining it right)","['functions', 'elementary-set-theory', 'abstract-algebra', 'function-and-relation-composition']"
874419,Is isomorphism not always unique?,"Given two isomorphic groups G and H, is it possible that two or more functions define their isomorphism? Also, is it possible that another group say, L is isomorphic to G but not to H?",['group-theory']
874431,A closed form of $\int_0^1\frac{\ln\ln\left({1}/{x}\right)}{x^2-x+1}\mathrm dx$,"This integral has been bugging me since yesterday: $$\int_0^1\frac{\ln\ln\left({1}/{x}\right)}{x^2-x+1}\mathrm dx$$ I've tried substitution $y={1}/{x}$ and $e^y={1}/{x}$, but those didn't help much. Wolfram Alpha gives me result: $-0.67172$. Could anyone here please help me to obtain the closed form of the integral preferably ( if possible ) with elementary ways (high school methods)? Any help would be greatly appreciated. Thank you.","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
874432,General solution of $\frac{\partial^2}{\partial t^2} x(t) + \omega^2 x(t) = 0$,"Consider $$\frac{\partial^2}{\partial t^2} x(t) + \omega^2 x(t) = 0$$ 1) Show that $\left(\frac{\partial x}{\partial t}\right)^2 + \omega^2 x^2$ is constant
in $t$, and 2) deduce that the general solution is $x(t) = a \cos \omega t + b \sin \omega t$ Differentiating $\left(\frac{\partial x}{\partial t}\right)^2 + \omega^2 x^2$ with respect to $t$ shows the first part, since
$$2 \frac{\partial x}{\partial t}\left(\frac{\partial^2 x}{\partial^2 t} + \omega^2 x\right) = 0$$
hence the derivative is $0$ and the function is constant. Now I want to deduce the second part, but am not sure how to use the first part to show this.",['ordinary-differential-equations']
874439,"Expectation of CDF of continuous random variable $X$, evaluated at $X$","Given the continuous random variable $X$ with cumulative distribution function $F_{X}$, find $E[F_{X}(X)]$. Attempt at solution: I understand that the expected value, $E[X]$, of a random variable, $X$, is $\int^{+\infty}_{-\infty} x f_{X}(x)\operatorname{d}x$, where $f_{X}$ is the probability density function. However, I'm a little thrown off by the wording of the question. Is $E[F_{X}(X)]$ the same thing as $E[X]$?",['probability']
874469,Symmetric matrix multiplication,"Let $A$ and $B$ be symmetric matrices.
Prove: $AB=BA$ $AB$ is a symmetric matrix As for 1. due to the axiom $(AB)^T=B^T A^T$ so $AB=BA$ As for 2. I did not find any axiom that can support the claim, but from test I found that it is true for symmetric matrices when the entries on the diagonal are equal.",['linear-algebra']
874481,Derivative of logistic loss function,"I am using logistic in classification task. The task equivalents with find $\omega, b$ to minimize loss function: That means we will take derivative of L with respect to $\omega$ and $b$ (assume y and X are known). Could you help me develop that derivation . Thank you so much","['regression', 'linear-algebra', 'discrete-mathematics', 'derivatives']"
874509,variation of a function over countable intervals,"Let $f$ be a function of bounded variation on $[0,1]$. Let $\{[a_n,b_n]\}_{n=1}^\infty$  such that $(a_n,b_n)$ are pairwise disjoint and $\cup_{n=1}^\infty [a_n,b_n]=[0,1]$. (for example, $[1/2, 1], [0,1/3], [1/3,1/3+1/3^2], \cdots$ ) Can we write $$
\operatorname{Var}_{[0,1]} f=\sum_{k=1}^\infty \operatorname{Var}_{[a_k,b_k]} f?
$$","['calculus', 'integration', 'measure-theory', 'real-analysis', 'analysis']"
874511,When do two integral superellipses have 'nice' intersections?,"A recent question posed the nonlinear system
\begin{cases}
3x^3+4y^3=7\\
4x^4+3y^4=16
\end{cases}
for real $(x,y)$ and asked for the sum $x+y$. As noted by commentary in the question, this regrettably seems analytically intractable: Resolving $x$, $y$ into separate equations gives two irreducible polynomials of degree 12, with no evidently soluble roots (the same holds for $x+y$). That situation suggested to me the following problem: What pairs of superellipses with integer coefficients have 'nice' intersections? The best case would be for there to be rational roots, but I'd be quite satisfied to see examples where the polynomials are reducible or the system is solvable. EDIT) Let me narrow the scope of this: Consider
\begin{cases}
3x^3+4y^3=a\\
4x^4+3y^4=b
\end{cases}
for positive integers $a,b$. Certainly one can construct cases in which there are integer/rational/radical solutions. But suppose someone gives me integer $a$ and $b$. 
What criteria could I apply to see whether any 'nice' solutions exist?","['algebraic-geometry', 'irreducible-polynomials', 'systems-of-equations', 'algebraic-curves']"
874522,Matrix notation of an ellipse.,"When I was reading a paper related to computer vision, I came across the following notation, where an ellipse is represented by the equation $\mathbf{x}^TM\mathbf{x} = 1$ , where the ellipse parameter M, is given by a $2\times2$ matrix where, $M = \begin{bmatrix}a & b\\
b & c
\end{bmatrix}$ I want to know firstly, how does this equation represent an ellipse, and further how does this ellipse gets normalized to a circle with the affine transformation, $\mathbf{x}' = M^{1/2}\mathbf{x}$ .","['symmetric-matrices', 'linear-algebra', 'conic-sections']"
874524,What do you call geometric patterns like this?,What do you call geometric patterns like this ?,['geometry']
874566,Euclidean space and Euclidean geometry,"If we have a Euclidean space $\mathbb{E}^2$, how can we define the Euclidean geometry,i.e. how to determine point,line,or some other things on it?",['geometry']
874571,Fermat pseudoprimes p to base 2 (AKA Sarrus or Poulet numbers) with special properties,"Are there any known Fermat pseudoprimes $p\;$ to base $2\;$ (Sarrus or Poulet numbers) with the properties
$q = (p-1)/2\;$ is prime and $p \equiv 0 \pmod 3?$ I was not able to find any example up to $p = 2^{31}-1.$ Is there an argument that they cannot exist? This question is related to Fast check of safe primes or Sophie Germain primes where I added the condition $p \not \equiv 0 \pmod 3?$","['elementary-number-theory', 'pseudoprimes', 'number-theory']"
874632,Base-points and invertible sheaves,"Once again I am confused after thinking too much about something I thought I already understood... Let $\mathcal{L}$ be an invertible sheaf on a smooth projective curve $X$ such that $\deg \mathcal{F} \geq 2g$. Denote by $\Gamma(\mathcal{L})$ the global sections of $\mathcal{L}$. Then it is known that $\Gamma(\mathcal{L})$ has no base-points. That is, there exists no point $P \in X$ such that all elements $f \in \Gamma(\mathcal{L})$ vanish simultaneously at $P$. The proof is something like this: If $P \in X$, one considers an invertible sheaf $\mathcal{L}(-P)$; it satisfies $\deg \mathcal{L}(-P) = \deg \mathcal{L} - 1$, and the global sections $\Gamma(\mathcal{L}(-P))$ are precisely the global sections of $\mathcal{L}$ which vanish at $P$. Then one can show (for example, by Serre duality) that $\dim \Gamma(\mathcal{L}) = \dim \Gamma(\mathcal{L}(-P)) - 1$. Now for my question, suppose that $\deg \mathcal{L} \geq 2g+1$. Let $P \in X$. According to the above, $\deg \mathcal{L}(-P) \geq 2g$, so $\Gamma(\mathcal{L}(-P))$ has no base points, but all global sections $\Gamma(\mathcal{L}(-P))$ vanish at $P$! Obviously I am making some mistake in what I've stated above. Could someone tell me what it is? Thanks in advance.","['algebraic-geometry', 'coherent-sheaves']"
874635,Integral $\int_{0}^{\pi/2} \arctan \left(2\tan^2 x\right) \mathrm{d}x$,"The following integral may seem easy to evaluate ... $$
\int_{0}^{\Large\frac{\pi}{2}} \arctan \left(2 \tan^2 x\right) \mathrm{d}x = \pi \arctan \left( \frac{1}{2} \right).
$$ Could you prove it?","['calculus', 'integration', 'definite-integrals', 'trigonometry', 'real-analysis']"
874708,Is there a golden pyramid?,"Is there a golden pyramid? Or pyramides? Would they have some interesting properties (related to let's say packing, etc.)? Golden rectangle is said to be the most aestheticaly pleasing among rectangles: This question mentions golden triangles: On the other hand, another question mentions golden parallelepiped: NOTE: Someone even used golden rectangle to construct this:","['geometry', 'golden-ratio']"
874714,Spectral theory,"I have absolutely no idea about Spectral theory and want to ask some fundamental questions. 1.) What does it mean that the resolvent of an operator is Hilbert-Schmidt? (Cause I saw a theorem that was like: The resolvent of our self-adjoint operator is Hilbert-Schmidt, hence all eigenvalues are purely discrete and the eigenfunctions are simple and form an orthonormal basis). I don't see how this Hilbert-Schmidt is related to any of the other things. 2.) Can we always represent the resolvent of a self-adjoint operator with a Hilbert-Schmidt integral operator and is the Hilbert Schmidt integral kernel the same as the Green's function? If anything is unclear, please let me know.","['operator-theory', 'spectral-theory', 'real-analysis', 'analysis', 'functional-analysis']"
874717,"$xf''(x) , xf', f \in L^{2}$ is $f' \in L^{1}$?","I am stuck on the following problem. I have a function $f$ such that $f$ is bounded on $(0,1)$, $xf'(x)$ is bounded on $(0,1)$, $f \in L^{2}(0,1)$, $xf' \in L^{2}(0,1)$, and $xf'' \in L^{2}(0,1)$. I wish to show that $f' \in L^{1}(0,1)$ or find a counter example that shows this to be untrue. So far, the only functions that I think could present possibly work as counter examples are functions for which $\lim\limits_{x \to 0^+} f(x)$ does not exist. But the common examples ($\sin(1/x)$ and $\sin(\ln(x))$) don't work. Thanks.","['measure-theory', 'calculus', 'lp-spaces']"
874730,Does an isotropic vector always exist for an indefinite quadratic forms?,"I have some problem reading some paper.
In that paper, the author proved that a quadratic form $Q$ has an isotropic vector(of course, nonzero) by showing $Q$ has both nonnegative and nonpositive values. Does an isotropic vector always exist for an indefinite quadratic forms? If true, why?","['quadratic-forms', 'linear-algebra']"
874731,$3 \times 3$ real matrix: relation with determinants,"$A$ is a $3 \times 3$ matrix with real entries such that $\operatorname{det}(A+I_3)=\operatorname{det}(A+2I_3)$.
Then is $2\operatorname{det}(A+I_3)+\operatorname{det}(A-I_3)+ 6   =3 \operatorname{det}A$? So, if the first holds, then does the second also hold? That $6$ in the sum makes it somehow ""different"".
Any idea / solution?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'determinant']"
874736,Use squeeze theorem to find the limit of a non-trigonometric (rational) function,Use the squeeze theorem to prove $$\lim_{x \to 0} \frac {2x^3}{x+1} =0$$ The only thing I can think of is that for all $x<0$  $f(x) $will be negative and positive for all $x>0$ $$\lim_{x \to 0}-x \le \frac {2x^3}{x+1} \le x$$ and then substitute $x$ proving $\lim_{x \to 0} -x = \lim f(x) = \lim x$. Is this valid or is there a better way?,"['calculus', 'limits']"
874748,derivatives of a vector of functions with respect to a vector,"Let $\vec W \in \mathbb R^3$. What is the general solution to: $$\frac{\partial}{\partial \vec{W}} \begin{pmatrix}
        f(\vec W) \\
        g(\vec W)
        \end{pmatrix}
$$ I think that in the case where $f$ and $g$ are linear I could rewrite:
$$\begin{pmatrix}
        f(\vec W) \\
        g(\vec W)
        \end{pmatrix}
=A\cdot \vec W
$$
for some suitable matrix $A$ and then this would break down to: $$\frac{\partial}{\partial \vec{W}}A\cdot \vec W=A
$$ Is this correct? So my question really aims for the general case, i.e. when $f$ and $g$ are not necessarily linear. It feels kind of wrong to take the derivatives along the rows given that $\vec W$ is a column-vector.","['multivariable-calculus', 'vector-analysis', 'derivatives', 'vectors']"
874755,Determined or not?,"the function $\dfrac {2x}{3x-\sqrt{x} }$ is not derterined for values of $x$ equale or samller than zero, though when I take the limit $ \lim_{x \to 0^+} \dfrac {2x}{3x-\sqrt{x} }$ the output is zero as though the function gets the value $(0,0)$ at that point, even though we know that's not the case....how come?","['calculus', 'algebra-precalculus', 'real-analysis', 'limits']"
874761,Realizing $\mathbb{Z}/n \mathbb{Z} \oplus \mathbb{Z}/n\mathbb{Z}$ as an isometry group,"Every finite group arises as the isometry group of a subspace of an euclidean space (Albertsona, Boutin, Realizing Finite Groups in Euclidean Space ). What are natural examples of spaces realizing the groups $\mathbb{Z}/n\mathbb{Z}$ $\mathbb{Z}/n \mathbb{Z} \oplus \mathbb{Z}/n\mathbb{Z}$ ? For $\mathbb{Z}/n\mathbb{Z}$ we may simply take a regular $n$-gon whose edges are extended in one consistent direction so that reflections are excluded. But this is not really a space which appears naturally. Also what about $\mathbb{Z}/n \mathbb{Z} \oplus \mathbb{Z}/n\mathbb{Z}$? The more examples, the better.","['symmetry', 'metric-spaces', 'group-theory']"
874770,Inequality - Find what value of $t$ satisfies: $ (t/24) - (t+1) + (3t/8) < (5/12) (t+1)$,Inequality - Find what value of $t$ satisfies:  $(t/24) - (t+1) + (3t/8) < (5/12) (t+1)$. Step 1: I multiplied both sides by $24$ and divided to get: $t-24(t+1)+9t < 10+24(t+1)$. Step 2: I multiplied $(t+1)$ on both sides with -24 and +24 and got: $t-24t+24+9t < 10+24t+24$. Step 3: Simplified this into: $-14t+24 < 34+24t$. Step 4: Added $14t-34$ on both sides. I was left with: $-10 < 38t$. Step 5: Divided both sides by $38$ gives: $-5/19 < t$. I also tried moving $(t+1)$ to one side so I got: $-(t+1)^2$. Where I got: $-24t^2-38t<34$. Then I divided by $-38$ where I also changed the sign: $-12/19t^2+t>-17/-19$. From this point I couldn't get just $(t)$ on one side because of that $t^2$. Both of them are incorrect. What did I do wrong?,"['inequality', 'algebra-precalculus']"
874783,Semi-norms in Functional Analysis,"I'm self-studying functional analysis. The following is from Rudin's ""Functional Analysis, 2nd edition"". It consists of parts from question 7 and 13 from the first chapter. I am not sure if my answers are correct, and would appreciate any hints/help. Thanks! 7) Let $X$ be the vector space of all complex functions on the unit interval $[0,1]$, topologized by the family of semi-norms \begin{equation}
p_x(f) = |f(x)|\,\,\,\,\,\, 0\leq x\leq 1
\end{equation} Show that there is a sequence $\{f_n\}$ in $X$ such that $\{f_n\}$ converges to $0$ as $n\rightarrow \infty$, but if $\{\gamma_n\}$ is any sequence of scalars such that $\gamma_n \rightarrow \infty$, then $\{\gamma_nf_n\}$ does not converge to $0$ (Hint: use the fact that the collection of all complex sequences converging to $0$ has the same cardinality as $[0,1]$.) 13) Let $C$ be the vector space of all complex continuous functions on $[0,1]$. Define \begin{equation}
d(f,g) = \int_0^1\frac{|f(x) - g(x)|}{1+|f(x) - g(x)|}dx
\end{equation} Let $(C,\sigma)$ be $C$ with the topology induced by this metric. Let $(C,\tau)$ be the topological vector space defined by the semi-norms \begin{equation}
p_x(f) = |f(x)|\,\,\,\,\,0\leq x\leq1
\end{equation} a) Prove that every $\tau$-bounded set in $C$ is also $\sigma$-bounded and that the identity map $id:(C,\tau)\rightarrow (C,\sigma)$ therefore carries bounded sets into bounded sets. b)Prove that $id:(C,\tau)\rightarrow (C,\sigma)$ is not continuous, although it is sequentially continuous. Hence $(C,\tau)$ is not metrizable. Show also directly that $(C,\tau)$ has no countable local base. Attempt: 7) Im really struggling with this one. I don't see where the cardinality of $[0,1]$ comes in. 13) a) Let $E$ be a $\tau$-bounded set in $C$. Using Theorem 1.37 from the book, we can say that in the $\tau$-topology, a set $E\subset C$ is bounded if and only if every $p_x(f)$ is bounded on $E$. i.e., for any $f\in E$, $|f(x)| < k_x$ for all $x\in [0,1]$, where $k_x$ is some positive real number dependent on $x$. If $g\in E$ then $d(g,0)<1$, because $|g(x)|<\infty$, from the above statement. Let $V_{\sigma} = \{g\in C : d(g,0) < 1\}$. Then, $tV_{\sigma} = \{f\in C : d(f,0)<t\}$. Therefore, if $h\in E$, then $h\in tV_{\sigma}$ for all $t\geq s$, for $s$ large enough, and so $E$ is also $\sigma$-bounded. b) If $\{f_n\}\rightarrow f$ in the $\tau$-topology, then $d(f_n,f)\rightarrow 0$, and so $id$ is sequentially continuous. To show $(C,\tau)$ does not have a countable base: Let $\mathcal{B}$ be the base constructed by the family of semi-norms. i.e., $\mathcal{B}$ is the collection of all finite intersections of sets $V(p_x,n) = \{f:p_x(f)<\frac{1}{n}\}$, $n$ a positive integer. For a real number $x$ and an integer $n$, a base element is given by: \begin{equation}
B_{x,n} = \{f\in C:|f(x)|<\frac{1}{n}\}
\end{equation} Because $[0,1]$ is uncountable, there is an uncountable number of base elements. We can therefore conclude that $id$ is not continuous (sequential continuity result, found in A6 in appendix of the book), and that $(C,\tau)$ is not metrizable.",['functional-analysis']
874844,Without Lebesgue,"Everyone knows following problem.
Let $f$ be positive function on $[0,1]$ and there exist $I = \int_{0}^{1}f(x)dx$. Prove that $I>0$. (recall that there are only two cases: $I=0$ or $I>0$. NOT $I<0$!!!!) My question is how to prove it without word ""Lebesgue""?? I'm interested in ""simple"" proof. Original proof. let $I=0$. Let $A_{n} = \{x: f(x) > \frac{1}{n}\}$. It is clear that Lebesgue measure of $A_{n}$ is 0. Let $A=\{x: f(x) > 0\}$. Than $A=A_{1} \cup A_{2} \cup ...$ and of course measure of A is 0. That means that f almost everywhere equals to 0. Contradiction with $f>0$.","['measure-theory', 'calculus', 'integration', 'lebesgue-measure']"
874873,Does this sequence consist of squares of integers?,"Question: let  sequence $\{x_{n}\}$ such $$x_{0}=0,x_{1}=1,x_{2}=0,x_{3}=1$$ and such
  $$x_{n+3}=\dfrac{(n^2+n+1)(n+1)}{n}x_{n+2}+(n^2+n+1)x_{n+1}-\dfrac{n+1}{n}x_{n}$$ show that:$ x_{n}$ are all square number? My idea: I have
$$x_{4}=3\cdot 2-2\cdot 1=4=2^2$$
$$x_{5}=\dfrac{21}{2}\cdot 4+(2^2+2+1)\cdot 1=49=7^2$$
and so on,but for all $n$,How prove it? Thank you","['recurrence-relations', 'sequences-and-series']"
874882,Measures which cannot be uniquely written as the sum of a purely atomic measure and a nonatomic measure,"Maharam's theorem says that every complete measure can be written as the sum of a purely atomic measure and a nonatomic measure. According to the paper ""Atomic and Nonatomic Measures"" by R.A. Johnson, this decomposition becomes unique if we require the measure to be $\sigma$-finite. However, Johnson claims that uniqueness may not hold if we drop the $\sigma$-finite hypothesis. Is this obvious? If not, would someone please direct me to a counterexample?",['measure-theory']
874895,How is $ \sum_{n=1}^{\infty}\left(\psi(\alpha n)-\log(\alpha n)+\frac{1}{2\alpha n}\right)$ when $\alpha$ is great?,"Let $\psi := \Gamma'/\Gamma$ denote the digamma function. Could you find, as $\alpha$ tends to $+\infty$, an equivalent term for the following series? $$
\sum_{n=1}^{\infty}  \left( \psi (\alpha n) - \log (\alpha n) + \frac{1}{2\alpha n} \right)
$$ Please I do have an answer, I'm curious about different approaches. Thanks.","['sequences-and-series', 'calculus', 'logarithms', 'asymptotics', 'polygamma']"
874913,norm of a singular integral operator,"My question is from Harmonic Analysis, about the study of singular kernels (in the Calderon Zygmund sense.) Suppose that a kernel $K$ is a singular kernel, extending to a bounded operator on $L^p$, for any $1\leq p<\infty$. On $L^2$ it is easy to compute the norm using Plancherel. But I am not sure how to compute the norm in general of this induced operator as a bounded operator from $L^1$ to $L^1_w$. The most common 'norm' I have seen (for instance in Stein) is that of $||\hat{K}||_{L^\infty} + C$, where the $\hat{K}$ denotes the distributional Fourier transform, and $C$ is the constant such that
$$|K(x)|\leq\frac{C}{|x|^n}$$
 I know that $K$ commutes with translations, but am wondering about general transformations. A norm I am interested in is the constant $A$ such that $$\int\limits_{\mathbb{R}^n\setminus B_{2\delta}(y)} |K(x-y)-K(x-\bar{y}) |dx\leq A$$
whenever $\bar{y}\in B_\delta(y)$, some $\delta>1$. How does one prove that, if $K$ satisfies the above decay and regularity estimates, and if $T$ is a general transformation matrix on $\mathbb{R}^n$, then $$\int\limits_{\mathbb{R}^n\setminus B_{2\delta}(y)} |K(T(x-y))-K(T(x-\bar{y})) ||\det(T)|dx\leq p(1+||T||||T^{-1}||)A?$$ 
where $p(x)$ is some $L^1_{loc}$ function? 
Any help would be appreciated.","['harmonic-analysis', 'singular-integrals', 'real-analysis', 'analysis', 'functional-analysis']"
874937,Transforming a latin square into a sudoku,"Can any $9\times 9$ - Latin Square be transformed into a sudoku by just exchanging rows and
 columns (it is allowed to mix row- and column-exchanges arbitarily and there is no limit for the number of the exchanges) ?","['latin-square', 'combinatorics']"
874960,How does one take limit along a path?,"So in multivariable calculus for a limit of a function to exist, the limits of the function along all possible paths must exist and equal the same value. But how does one calculate the limit along a given path? Say I have $f(x,y) = (x^3(y+1), x-y^2)$ (this is off the top of my head, so sorry if it doesn't work out well) and I want to know what the value of $\lim_{(x,y) \to (2,3)}$ is along the path $y= x^2 -1$ .  How would I calculate the limit? My guess is we'd need to parametrize the curve?  In that case, I guess we'd need some $\phi(t): [a,b] \subset \Bbb R \to \Bbb R^2$ .  So we'll let $t=x$ , then $\phi(t) = (t, t^2-1)$ .  Then would $\lim_{(x,y) \to (2,3)} f(x,y) = \lim_{t \to 2} f(\phi(t))$ .  I don't know for sure, bu it seems like we'd need something like the chain rule here -- that is can we just plug stuff in like this? Moreover, is $\frac {\partial f}{\partial x}$ the limit of the gradient in the x-direction?  If so, is there some notation that tells us what the limit of the gradient at a point is along some other given path (like $y=x^2 -1$ for instance)? I could be way off here.  I just realized that even though I know how to calculate partials and gradients and multiple integrals, I don't really understand the basics.","['multivariable-calculus', 'real-analysis', 'limits']"
874964,How to solve Absolute Value Inequality: |x-1| ≥ 3-x,"I am learning the topic of solving absolute value inequality question. I had mostly understood the steps in order to solve for an inequality. However, I'm still clueless of a step to solve the inequality below:
Which is: Why does $ 3-x \ge  0$? I notice that 3-x is clearly not inside a radical, so it shouldn't have that requirement. Am I right?","['inequality', 'absolute-value', 'algebra-precalculus']"
874971,Parametric formula for figure 8 mobius strip,"I'm making 3D prints with Mathematica, and am interested in a parametric formula for a mobius strip that is in the form of a figure 8, rather than simply a circle with a twist in it. Can someone help me with that?
Thanks Rick Russell","['general-topology', 'analytic-geometry']"
874978,A set of measure zero in a product space intersects almost every fiber in a set of measure zero,"Let $C\subset A\times B$ be a set of content zero. Let $A'\subset A$ be the set of all $x\in A$ such that $\{y\in B: (x,y)\in C\}$ is not of content zero. Show that $A'$ is a set of measure zero. I couldn't finish this problem, after a few steps I'm not sure what could I do next. This much I know: $C$ has content zero, then $\partial C$ has content zero ($\partial C$ denotes the boundary of $C$) which means that the characteristic function $\chi_c$ is integrable in $A\times B$. Then I applied Fubini's theorem to have $\displaystyle\int_{A\times B}\chi_C=\displaystyle\int_A\left(L\displaystyle\int_B \chi_C\; dy\right)dx=\displaystyle\int_A\left(U\displaystyle\int_B\chi_C\;dy\right)dx$ where $L$ and $U$ denote that those are the lower and upper integral. Now follows  $\displaystyle\int_A\left(L\displaystyle\int_B \chi_C\; dy-U\displaystyle\int_B\chi_C\;dy\right)dx=0$ which means that $\displaystyle\int_B \chi_C\;dy$ is integrable. Since $C$ is a set of content zero, is a set of measure zero. I know that if a bounded set $C$ is of measure zero and $\displaystyle\int_B\chi_c$ exists then $\displaystyle\int_B\chi_c=0$. Here I'm not sure how to go on, I'm considering taking a partition $P$ of $B$ and knowing that $\sup\{L(\chi_C,P): \text{P partition of B}\}=0$ is possible to take $P$ such that $U(f,P)=\sum_{S\in P} M_S(\chi_C)v(S)\leq\sum_{S\in P} v(S)<\epsilon$. But it doesn't seem okay... Any thoughts about it?.","['multivariable-calculus', 'integration', 'solution-verification']"
874982,"Relation between Sobolev Space $W^{1,\infty}$ and the Lipschitz class","I have a Sobolev space related question. In the book 'Measure theory and fine properties of functions' by Lawrence Evans and Ronald Gariepy. I know the result that states that for $f: \Omega \rightarrow \mathbb{R}$ . $f$ is locally Lipschitz in $\Omega$ if and only if $f \in W^{1,\infty}_{loc}(\Omega)$ . I recently saw that it was stated in a book 'Nonlinear partial differential equations with applications' by Roubicek, that $W^{1,\infty}(\Omega) = C^{0,1}(\Omega)$ . Can anyone confirm this stronger result and maybe recommend a book or text which provides a proof? Thanks a lot for any help.","['sobolev-spaces', 'measure-theory', 'holder-spaces', 'real-analysis', 'functional-analysis']"
874993,Line Integral Around a Triangle,"Let $R$ be the interior of the triangle with vertices $(0,0), (4,2),$ and $(0,2)$. Let $C$ be the boundary of $R$, oriented counterclockwise. Now evaluate the integral below. $$\int_C(y+e^\sqrt{x}) dx + (xe^{y^2}) dy$$ I know this has to be parametrized somehow, but I'm not sure where to start. Could someone show me how to set up the integral so it can be evaluated? Thanks.",['multivariable-calculus']
874999,Differentiation under the integral if and only if we have an $L^1$ dominator,"Let $f(x)\in L^2(\mathbb{R})$ and define $$g(t) = \int_\mathbb{R} f^2(x)\exp(-tx^2)dx$$ for $t\geq0$ . We want to show that $g(t)$ is continuously differentiable if and only if $xf(x)\in L^2(\mathbb{R})$ . If we have that $xf(x)\in L^2(\mathbb{R})$ then we can use the standard Lebesgue Dominated Convergence technique to show that $g(t)$ is differentiable, and that its derivative is continuous. I'm having trouble, however, showing that $g'(t)$ continuous means that $xf(x)\in L^2(\mathbb{R})$ . My attempt: It seems intuitive to me that if $g(t)$ is continuously differentiable, it's derivative must be defined by what we'd expect: $$g'(t) = \int_\mathbb{R} -x^2f^2(x)\exp(-tx^2)dx,$$ but I don't know how I would go about proving this. If we have this fact, then $g'(0)<\infty\Rightarrow xf(x)\in L^2(\mathbb{R})$ and we're done. Any thoughts?","['measure-theory', 'functional-analysis', 'real-analysis', 'analysis']"
875005,Question on Green's Theorem,"Consider the vector field $\textbf{f}(x,y)=(ye^{xy}+y^2\sqrt{x})\textbf{i}+(xe^{xy}+\frac{4}{3}yx^{\frac{3}{2}})\textbf{j}$. Use Green's Theorem to evaluate $\int_C\textbf{f} \dot d\textbf{r}$, where $C$ is the ellipse given by $(x-1)^2+\frac{y^2}{9}=1$, oriented counterclockwise. $\int_C\textbf{f} \dot d\textbf{r} = \int \int_R (\frac{\partial Q}{\partial x} -\frac{\partial P}{\partial y}) \ dx \ dy$ $=\int \int_R (xe^{xy}+ye^{xy}+2yx^\frac{1}{2})-(ye^{xy}+xe^{xy}+2\sqrt{x}y) \ dx \ dy$ $=\int \int_R 2y\sqrt{x}-2\sqrt{x}y \ dx \ dy$ What would the bounds be on the integral? I think I should parametrize to polar coordinates, but I'm not sure how to do that when the ellipse's center isn't the origin. Or would I just use $0\leq x \leq 2$ and $-\sqrt{9(1-(x-1)^2)} \leq y \leq  +\sqrt{9(1-(x-1)^2)}$ ? Thanks.","['multivariable-calculus', 'integration']"
875009,Classic Counting Problems,"Does anyone have some good, classic, counting problems? I want things that are interesting, as well as instructive- more than just compute the number of way to get a flush, etc. (Not that those aren't interesting, but students seem to get bored of that quickly.)","['education', 'big-list', 'combinatorics']"
875014,Evaluation of $ \int\frac{\sqrt{\sin x}}{\sqrt{\sin x}+\sqrt{\cos x}}dx$,"Evaluation of $\displaystyle \int\frac{\sqrt{\sin x}}{\sqrt{\sin x}+\sqrt{\cos x}}dx$ $\bf{My\; Try::}$ Given $\displaystyle \int\frac{\sqrt{\sin x}}{\sqrt{\sin x}+\sqrt{\cos x}}dx = \int \frac{\sqrt{\tan x}}{1+\sqrt{\tan x}}dx$ Now Let $\displaystyle \tan x = t^2\;,$ Then $\sec^2 xdx = 2tdt$ or $\displaystyle dx = \frac{2t}{1+t^4}dt$ So Integral is $\displaystyle \int\frac{t}{1+t}\cdot \frac{2t}{1+t^4}dt = 2\int\frac{t^2}{(1+t)\cdot  (1+t^4)}dt$ Now How can I solve after that Help me Thanks","['calculus', 'integration', 'indefinite-integrals']"
875016,Basic limit question to understand the methods,"I have a very basic question about proving limits with the epsilon-delta method. So i want to prove  $\lim _{x\to 0}\left(\frac{1}{1-2x}\right)\:=\:1$ . first, i write it like that: $\left|\frac{1}{1-2x}\:-\:1\right|\:$ = $\left|\frac{2x}{1-2x}\right|\:$  = $\frac{2\left|x\right|}{\left|1-2x\right|}\:$ and from here i stuck. I know that i need to get |x|< some expression of epsilon and stuff that will be actually my delta. What i need to do from here?","['epsilon-delta', 'calculus', 'limits']"
875022,how to find matrix from its exponential form,I know about the relation $$\frac{d}{dt}e^{At}=Ae^{At}$$ Is the only way to use it is to find the inverse of $e^{At}$ and then post-multiply on both sides? Is there a better approach?,['ordinary-differential-equations']
875032,Is the Axiom of Choice necessary to prove $\mathbb R \approx \mathcal P(\omega)$?,"I am self-studying Horst Herrlich, Axiom of Choice (Lecture Notes in Mathematics, Vol. 1876) , and I'm getting quite confused about cardinal arithmetic without AC. Here ( Which sets are well-orderable without Axiom of Choice? ) OP writes that $\mathbb R$ is not necessarily well-orderable in ZF. At the same time, it seems to me that $\mathcal P(\omega)$ is well-orderable in ZF (attempt of proof follows). Therefore, either my proof is wrong, either the answer to the original question is ""Yes"". Any help? Thanks. Claim ZF $\vdash$ ""$\mathcal P(\omega)$ is well-orderable"" Proof We know that $2=\{0,1\}$ is a cardinal number, therefore it is well-ordered w.r.t. ""$\in$"" (of course this could be manually checked
   too). Same holds for $\omega$. (I'll use ""$<$"" instead of ""$\in$"").
   Let's consider $2^\omega = \{f \mid f : \omega \to 2\}$. The relation
   defined by  $$f \prec g \iff \exists n \, [f(n) < g(n) \wedge \forall
 i\!\!<\!\!n \;\; f(i)=g(i)]$$ is a well-order on $2^\omega$ (and this
   is true in ZF). To conclude, just observe that ZF $\vdash 2^\omega
 \approx \mathcal P(\omega)$. Update: The proof is wrong, since the lexicographic order on $2^\omega$ is clearly not a well-order, as pointed out in Asaf Karagila's answer. Asaf claims also that ZF $\not\vdash$ ""$2^\omega$ is well-orderable"". But then, I have another question: in the book I cite above, there is the following proof (page 51): Now: If $2^\omega$ is not necessarily well-orderable, why is the author allowed to use $2^{\aleph_0}$ as a cardinal number? Or, equally, why is he allowed to talk about the cardinality of $\prod_{n \in \mathbb N} B_n$? Solution to update: It was just a matter of definitions. In the text I've studied these topics, cardinal numbers are defined as ordinals for which there is no bijection with smaller ordinals. Then, given a set $A$, $|A|$ is a cardinal number, therefore it is defined iff $A$ is well-orderable. On the contrary, in this book $|A|$ is intended as the equivalence class of $A$ under the equivalence relation $A \sim B \iff $ there exist a bijection $A \to B$. This way, $|A|$ is always well-defined.","['cardinals', 'elementary-set-theory', 'axiom-of-choice']"
875061,"A proof that if the product of spaces is Hausdorff, each of them is Hausdorff","Is my approach to this question right? Question: Prove that if $$\prod_{\alpha \in J} X_\alpha (\neq \emptyset) $$ is Hausdorff, each $X_\alpha$ is Hausdorff. Attempt to answer: It is enough to show that if there is a $X_i,i\in J$ that is not Hausdorff, then $$\prod_{\alpha \in J} X_\alpha$$ is not Hausdorff.
$$\prod_{\alpha \in J} X_\alpha$$ is homeomorphic to $$\prod_{\alpha \in J/\{i\}} X_\alpha \times X_i,i\in J $$ so it is sufficient to show that a product of two spaces is Hausdorff only if both are Hausdorff (which is easy). Am I right?",['general-topology']
875076,Evaluating $\int_{0}^{1}\cdots\int_{0}^{1}\bigl\{\frac{1}{x_{1}\cdots x_{n}}\bigr\}^{2}\:\mathrm{d}x_{1}\cdots\mathrm{d}x_{n}$,"Here is my source of inspiration for this question. I suggest to evaluate the following new one . $$
I_{n}:= \int_0^1 \! \cdots \! \int_0^1 
\left\{\frac{1}{x_1x_2  \cdots x_n}\right\}^{2} \:\mathrm{d}x_1\,\mathrm{d}\,x_2 \cdots \mathrm{d}x_n 
$$ where $\left\{x\right\}=x-\lfloor x\rfloor$ denotes the fractional part of $x$ throughout. (a) Could you prove the result below? $$
I_2= \int_0^1\!\!\int_0^1 
\left\{\frac{1}{x y}\right\}^2 \:\mathrm{d}x \,\mathrm{d}y = 1-\gamma+\dfrac{\gamma^2}{2}-\dfrac{\pi^2}{24}+\ln(2\pi)-\dfrac{\ln^2(2\pi)}{2}.
$$ where $\gamma$ denotes the Euler-Mascheroni constant. (b) Could you find a general formula for the multiple fractional integral $I_n$ ? Please, this is a challenge problem. Thanks.","['multivariable-calculus', 'calculus', 'integration', 'definite-integrals', 'euler-mascheroni-constant']"
875093,Area of spherical cap with integrals,"Given a sphere $S$ of fixed diameter $D$ (or radius $R=D/2$, it will be convenient to have both, I suppose), and a point $P$ on its surface, let's create a ball $B$ of variable radius $r$ with its centre in $P$. What I have been wondering was - what is the surface area $A(r)$ of the intersection of the sphere and the ball as a function of $r$? Recently I found a neat solution using the formula for the area of spherical cap - which it will be, after all, I just had to relate the missing variables for the formula to the ones I know, and I managed to get that $A=\pi r^2$ for $0 \leq r \leq D$ and I believe that to be correct (it might not necessarily be, I just was unable to find any limiting cases that would prove the formula wrong). However, my initial approach - the crux of the question - was different. I replaced B with a sphere $B'$ with the same parameters (i.e. centre in $P$ and variable radius $r$), attempted to find the perimeter of the intersection (circle) $p(r)$ and then let $A(r)=\int_{0}^{r}p(x) dx$ Finding that $$p(r)=2\pi \sqrt{r^2-\frac{r^4}{D^2}}$$ was simple, but the integration was not, and not knowing enough to reliably follow through with it, I asked Wolfram Alpha to do the heavy lifting, which gave me this:
$$\int p(x) dx = \frac{2\pi (x^2-1)\sqrt{x^2-x^4}}{3x}+c$$
(I assumed D=1 for simplicity to easier see the curve, perform sanity checks, and believing that I can always multiply the resulting area by $D^2$) The curve seemed plausible, I just had to compute the exact function $A(r)$ as defined above as a definite integral. Because the function wasn't defined at 0, I had to compute $$\lim_{x \to0^+}2\pi \sqrt{x^2-\frac{x^4}{D^2}}$$ which gave me a puzzling result - $2\pi/3$ for unit sphere. My question is - why this value? What was incorrect in this approach?","['multivariable-calculus', 'calculus', 'integration', 'differential-geometry']"
875111,correspondence between balls in compartments and integer vectors,"I'm doing a self-review of probability and working through Ross' Introduction to Probability. The question is (Ross, ch2 number 51): suppose $n$ balls are randomly distributed into $N$ compartments.  Find the probability that $m$ balls fall in the first compartment, assuming all $N^n$ arrangements are equally likely. I solved this two ways -- it's $$\frac{ \displaystyle{n \choose m} (N-1)^{n-m}}{ N^n }.$$  Easy enough.  You can also think of this as a bernoulli trial w/ prob $$p = \frac{1}{N}$$ so that $$P(k=m) = \displaystyle{n \choose m} p^m (1-p)^{n-m} = \displaystyle{ n \choose m } \frac{1}{N}^m \left(\frac{N-1}{N}\right)^{n-m}$$ and those are equal.  So my answer is probably right. My question is Ross also mentions a formula for the number of nonnegative integer solutions to 
$$x_1 + x_2 + \ldots + x_r = n;$$ there are 
$$\displaystyle{n+r-1 \choose r-1}$$
solutions.  So I feel like the answer to this problem should also be the number of solutions to 
$$x_2 + \ldots + x_N = n - m$$
 divided by the number of solutions to 
$$x_1 + \ldots + x_N = n,$$
ie
$$ \frac{\displaystyle{ n - m + (N-1) - 1 \choose (N-1) - 1}}{\displaystyle{n + N - 1 \choose N - 1}}  = \frac{\displaystyle{ n - m + N-2 \choose N-2}}{\displaystyle{n + N - 1 \choose N - 1}}   $$ but it's not -- I couldn't make this factory correctly, so I tried it with a random choice of numbers for $n,N,m$ and it's definitely not equal.  My question is why not?  There should be a correspondence between balls in compartments and the number of nonnegative vectors $x_1 + \ldots + x_N = n$, right?",['probability']
875145,Exactly How Does This Proof Mean That The Cosine Function Is Continuous,"The question is: Prove that cosine is a continuous function. To give some context in what way this must be answered, this question is from a sub-chapter called Continuity from a chapter introducing Limits. The Solution: We must show that $\lim_{h \to 0}\cos(a + h) = \cos(a)$ to prove that the cosine function is continuous. $\lim_{h \to 0}\cos(a + h) = \lim_{h \to 0}(\cos(a)\cos(h)-\sin(a)\sin(h)$ which after applying the limit laws $= \cos(a)(1) - \sin(a)(0) = \cos(a)$ Now how I understand how this shows that the cosine function is continuous, is that a can be any number and the cosine function is defined for any number a , thus the proof shows that the cosine function is continuous. But now why use $\cos(a+h)$? I feel slightly uncomfortable with the way I understand this proof as I feel it's almost too elaborate to show something that I have taken to be true without question. Could anybody explain to me in words how this proof shows that the cosine function is continuous?","['calculus', 'limits']"
875153,Finding $\binom{n}{0} + \binom{n}{3} + \binom{n}{6} + \ldots $,Help me to simplify:$$\binom{n}{0} + \binom{n}{3} + \binom{n}{6} + \ldots $$ I got a hunch that it will depend on whether $n$ is a multiple of $6$ and equals to $\frac{2^n+2}{3}$ when $n$ is a multiple of $6$.,"['summation', 'binomial-coefficients', 'combinatorics']"
875172,Can a convex polygon inside a square with edge length 1 have a perimeter > 4?,While featherbrainedly doodling the other day I noticed that it's probably impossible to draw a convex polygon with a greater perimeter then that of the square around it. Can someone find a counterexample or maybe even find a proof?,['geometry']
875181,Solving weak 2 body problem,"I tried to solve a physics problem about two body problem where the masses $M$ and $m$ are $M \gg m$.
The body $m$ is at radius $R$ from the mass $M$ and is falling down with initial speed $v(0) = 0$.
I need to calculate the time of falling. The point is not how can I solve it the problem (I have found a better way). I tried to find the solution it by solving the differential equation 
$$\ddot x(t) = \frac{k}{x(t)^2}$$
but had no success.
The way I tried is the following:
$$
\dot x \ddot x = \frac{k}{x^2} \dot x \\
\frac{1}{2} D[(\dot x)^2] = k \frac{\dot x}{x^2} \\
\int \frac{1}{2} D[(\dot x)^2]\ dt = k \int \frac{\dot x}{x^2}dt\\
\frac{1}{2}(\dot x)^2 = -k \frac{1}{x} + C \\
\dot x = \sqrt{-2k\frac{1}{x} + C}
$$ which doesn't seem correct to me. I want to solve it using clever tecniques (by clever I mean multiply or add a nice terms and make calculations almost instant). Could you suggest me something?","['ordinary-differential-equations', 'physics']"
875182,Uniformly bounded derivative implies uniform convergence,"Let $f_n$ be a sequence of differentiable functions on $[a, b] \subset \mathbb{R}$.
Suppose $\lim_{n \rightarrow \infty} f_n(x) = f(x)$ exists for all $x \in [a, b]$, and the derivatives $|f_n'(x)| < M$ are uniformly bounded over $n$ and $x$ Prove that $f_n$ converges to $f$ uniformly. The closest I can get is to try to adapt Arzela-Ascoli somehow, but it is not working.
I can conclude the existence of a subsequence that converges uniformly, but this doesn't guarantee the original sequence converges uniformly.",['real-analysis']
875195,Measuring sums of complex alternating series,"Suppose we have functions $$f(x) = \sqrt{x}, \space g(f) = \frac{df}{dx}+\frac{d^2f}{dx^2}+\frac{d^3f}{dx^3}\space ...$$ Applying function f(x) to g(f) we get:
$$g(f(x))=\frac{1}{2}x^{-\frac{1}{2}} - \frac{1}{4}x^{-\frac{3}{2}} + \frac{3}{8}x^{-\frac{5}{2}} - \frac{15}{16}x^{-\frac{7}{2}}$$ Is it possible to tell if it's converging? If it is, what is it converging to?","['summation', 'sequences-and-series', 'derivatives']"
875211,"How to scale ""probabilities"" to a given mean?","I have a set of scores $x_i$, $i=1,\ldots,N$ (mimicking probabilities, $0\le x_i\le 1$) and I want to transform them so that the result has a given mean $m$, while remaining in the interval $[0;1]$. IOW, I am looking for a reasonable (in particular, smooth and strictly increasing) function $f(x): [0;1]\mapsto [0;1]$ such that $f(0)=0$, $f(1)=1$. One transformation which makes sense to me is this: convert probabilities to odds: $o_i=\frac{1-x_i}{x_i}$ (new range is $[0;\infty]$) multiply the odds by a positive factor $\lambda$ convert the scaled odds back to probabilities: $y_i=\frac{1}{1+\lambda o_i}$ The question is : how do I find $\lambda$? Here is a recursive R function, which scales the odds by the ratio of the desired mean over the actual mean: set.mean <- function (p, m, eps=sqrt(.Machine$double.eps)) { # make mean of p equal to m
  m1 <- mean(p)
  if (abs(m-m1) < eps)
    return(p)
  set.mean(1/(1 + (m1/m) * (1/p - 1)), m, eps)
} It converges too slowly. I guess I can use the Newton's method for faster conversion, but I wonder if there is some brilliant trick which would solve my problem. PS. reasonable in this case means just that: I should be able to reason that it makes sense to transform probabilities this way :-)","['statistics', 'probability', 'numerical-methods']"
875227,What is the value of $ \int_{x}^{1} \arcsin \left( \frac{2t}{t^2+1} \right) \text{d}t $?,Is this result true? Wolfram doesn't seem to be able to evaluate the definite integral in the allowed time. $$ \int_{x}^{1} \arcsin \left( \dfrac{2t}{t^2+1} \right) \text{d}t = \dfrac{\pi}{2} - 2x\arctan x - \log(2) + \log(1+x^2) $$,"['trigonometry', 'integration']"
875310,Is there any difference between $P$ and $\Pr$ to represent probabilities?,"I have come across both $P(\dots)$ and $\Pr(\dots)$ being used to represent probabilities. Is there any difference in the meaning of these notations, or are they just different shorthands? I seem to come by $\Pr(\dots)$ more often in Bayesian probability contexts, though I wouldn't say that's a rule.","['notation', 'probability']"
875321,Step Connected if and only if Connected,"A space $X$ is step connected if given any open covering $\mathcal{U}$ of $X$ and any pair of points $p,q\in X$ there is a finite sequence $U_1,\ldots,U_n$ of sets belonging to $\mathcal{U}$ so that $p\in U_1$, $q\in U_n$ and $U_i\cap U_{i+1}\neq\emptyset$ for $1\leq j\leq n-1$. Prove that a space is step connected if and only if it is connected. So far I was able to prove that step connected implies connected by showing the negation, that disconnected implies not step connected.  Which was pretty straight forward by taking the open cover to be the partition of $X$ into open sets.  The other implication I am struggling with.  My first thought was to fix a $q\in X$ and let $A$ be the set of points such that this step sequence can be found.  Then showing $A$ is open, closed, and nonempty thus by $X$ being connected we would see that $A$ is all of $X$ and thus $X$ is step connected.  I was able to show that $A$ is open and nonempty, but cannot seem to show that $A$ is closed.  Any tips? Also this isn't for a homework assignment, I am trying to prepare for an upcoming qualifying exam.","['general-topology', 'connectedness']"
875367,"Prove that an expression is zero for all sets of distinct $a_1, \dotsc, a_n\in\mathbb{C}$","A while ago one of my professors gave the class a problem ""to think about when lying on the beach."" Well, I've been on the beach several times since then to no avail and my curiosity has finally outweighed my desire to solve this personally. The problem is this: Let $a_1, \dotsc, a_n\in\mathbb{C}$ be distinct. Prove that: \begin{equation}
\sum_{i=1}^n\prod_{j\neq i}\frac{1}{a_i - a_j} = 0
\end{equation} It's pretty easy, if tedious, to show this for a given $n$ but I'm unsure about how to generalise the result.","['complex-numbers', 'abstract-algebra']"
875385,Use a double integral in polar coordinates to find the area,"So the area is just an intersection of two circles Converting the two circles to polar coordinates, I get: $r(r-2\sin\theta)=0$, and $r(r-2\cos\theta)=0$ Ummm so $r =0$ and r = $2\sin\theta$ and r=$2\cos\theta$ ? are those the boundaries?","['multivariable-calculus', 'polar-coordinates', 'calculus', 'integration']"
875410,Convergence in a metric space,"Is it possible to define a metric on $\mathbb R$ such that $(1,0,1,0,...)$ converges on $(\mathbb R, d)$? I believe it is impossible. But how to show analytically? Any hint would be appreciated.","['metric-spaces', 'analysis']"
875422,Applications of Geometry to Computer Science,"How is differential geometry (or any type of theoretical math) being used in computer science?  Any research I have done on this topic leads me to some sort of applied math concept. I know that there are many pure mathematicians in physics (i.e. in string theory, studying Hamiltonionan mechanics, Quantum Field Theory and so on) and am wondering where the pure mathematicians in computer science fit in. Edit: I am looking for factual answers, something along the line of, Hamiltonian mechanics is to symplectic geometry, as computer graphics is to ... or Calabi-Yau manifolds are to string theory as Artificial Intelligence is to ... I want to know the pure math concepts being used in current computer science.","['applications', 'soft-question', 'computer-science', 'differential-geometry']"
875433,Dimension of the sum of three subspaces,"We know that $$\dim(U_1 + U_2) = \dim U_1 + \dim U_2 - \dim(U_1 \cap U_2)$$ if $U_1$ and $U_2$ are finite dimensional subspaces. For three finite dimensional subspaces prove or give a counterexample for the following: $$
\begin{align}
\dim(U_1 + U_2 + U_3) &= \dim U_1 + \dim U_2 + \dim U_3 \\
&- \dim(U_1 \cap U_2) - \dim(U_2 \cap U_3) - \dim(U_1 \cap U_2)\\
&+ \dim(U_1 \cap U_2 \cap U_3) 
\end{align}$$ Its basically the formula for the union of three sets. I think that this is false but the only reason I can think it would be is because the union of subspaces is rarely a subspace itself, even though it applies to sets, so it seems to me like this formula which works for sets shouldn't work for subsets because it would disrupt overlapping elements of $U_1 + U_2 + U_3$ and run into complications with the sum being closed under addition or something like that. Help much appreciated thank you!",['linear-algebra']
875447,Is there a group-theoretic proof of the Riemann rearrangement theorem?,"The analytic proofs of the Riemann rearrangement theorem are easy to understand but they don't explain why commutativity breaks down when you go from finite sums to infinite sums of real numbers. I suspect that this involves the action of the symmetric group on infinite sets vs finite sets of real numbers. But, so far I haven't come across a proof that only uses tools from Group Theory. Does such a proof exist?","['divergent-series', 'group-theory', 'symmetric-groups']"
875458,Drawing a triangle from medians,"Is it possible to draw a triangle, if the length of its medians $(m_1, m_2, m_3)$ are given only? Someone asked me this question, but I can not see it. Is it really possible? UPDATE Apart from the algebraic solution given by JimmyK4542 , can anyone give me a direct construction?  I mean, it should sound like: Draw a line segment sufficiently long. Cut the length of $m_1$ from it. Then $\ldots$","['geometry', 'geometric-construction']"
875465,Does every inner product space has an orthogonal basis?,"It is proved that every inner product space has a basis $W$, but I am not sure if every inner product space has an orthogonal basis? It is known that every inner space has a maximal orthogonal set $S$, so if I want to prove the conclusion, we need to show that if $w\in W$ is linearly independent to $S$, then we can construct a vector that is orthogonal to $\mbox{span}\{S\}$, which leads to contradiction, but it seems needs the condition that the space is complete. If not, can anyone give me a counterexample?",['real-analysis']
875483,Confused about this set representation and conclusions,"I'm pursuing Set Theory by Enderton and am having trouble understanding the following idea. Early in the book, the author constructs an ""informal view"" of sets, which he says he will refine further (fine by me). In it he asks us to imagine a bucket-like diagram, with each hierarchical layer representing a set. So the bottom-most layer is the set $V_0$ (which is the set of all ""atoms"" from which other sets will be constructed), the next one is $V_1$, and so on. He then defines a layer as $$ V_{\alpha+1} = V_{\alpha} \cup \mathcal P (V_{\alpha}) $$ which means that $V_0 \subseteq V_1 \subseteq V_2 \ldots $ Now comes the knockout punch: ""But even this infinite hierarchy does not include enough sets. For example, $\phi \in V_1$, $\{\phi\} \in V_2$, $\{\{\phi\}\} \in V_3$, etc., but we do not yet have the infinite set $\{\phi, \{\phi\}, \{\{\phi\}\}, \ldots\}$. To remedy this lack, we take the infinite union $V_{\omega} = V_0 \cup V_1 \cup V_2 \ldots$ and then let $V_{\omega+1} = V_{\omega} \cup \mathcal P(V_{\omega})$."" My objection is: whatever the set $V_0$ is, $\mathcal P(V_1)$ will have $\phi$ as its member, and then $\mathcal P(V_2)$ will have $\{\phi\}$, $\mathcal P(V_3)$ will have $\{\phi, \{\phi\}\}$, and so on. Eventually there has to be a set which contains $\{\phi, \{\phi\}, \{\{\phi\}\}, \ldots\}$. What, then, does the infinite union introduced above achieve? Also, the idea is later used to demonstrate that there is no set of all sets. Can someone show how this follows (I can add more details if needed)?","['self-learning', 'elementary-set-theory']"
875485,Finding Horizontal/Oblique Asymptote of $y=\frac{\sqrt{x}+1}{\sqrt{x}-1}$,"Is it correct to simply subsitute $\sqrt{x}$ with $x$ when finding horizontal or oblique asymptotes? The method works but I am not sure if it is formally sound enough to pass muster in an examination. How about a function of other fractional powers of $x$. If I had a function where $x$ always appeared as a seventh root: $\sqrt[7]{x}$, can I substitute $\sqrt[7]{x}$ with $x$ to find asymptotes? If so, in general, can I substitute $g(x)$ with $x$ to find the asymptotes of $f(g(x))$ if $\lim_{x \to \infty}g(x) = \infty$?","['asymptotics', 'algebra-precalculus', 'limits']"
875490,How do I find the domain of this function,"I would like to know which operations i have to do to get the domain of this function: 
$$y=\sqrt{\frac{1}{x}-1}$$ I have researched and the solution of the inequality $\frac{1}{x}-1 \geq 0$  is $$0<x \leq 1$$ Which are the steps to get this result?","['algebra-precalculus', 'functions']"
875543,$C(X)$ is separable when $X$ is compact,"Let $X$ be a compact space and let $\Bbb U =\{(U,V); U,V \mbox{ are open subsets of }X \mbox{ and }\mathrm{cl} U \subset V\} $. for $u=(U,V)$ in $\Bbb U$ , let $F_u:X\to [0,1]$ be a continuous function such that $f_u=1$ on $\mathrm{cl} U$ and $f_u=0$ on $X \setminus V$. Show a- the linear span of $\{f_u;u\in \Bbb U\}$ is dense in $C(X)$. b- If X is a metric space, then $C(X)$ is separable. c-If X is a $\sigma-$ compact metrizable locally compact space, then $C_0(X)$ is separable. My attempt: a- put $M=\{f_u; u\in \Bbb U\}$. suppose $\mu \in M^{\perp}$. thus  for every open subset $U$, $\mu(U)=0$. Also  $||\mu||=|\mu|(X) =0$ which shows that $M^{\perp}=0$. b- For every $n$, put $B_n=\{B(x,\frac{1}{n}) ; x\in X\}$. X is compact so there is a finite set $F_n\subset X$ such that  $\{B(x,\frac{1}{n}) ; x\in F_n\}$ is an open finite cover for X. put $F=\cup F_n$. I can show F is dense in X. put $u_x= (B(x,\frac{1}{n}), B(x,\frac{1}{n-1}))$ for every $x\in F.$ I want to show $M=\{f_{u_x}, x\in F\}$ is dense in $C(X)$. But I can not. c- $X=\cup X_n$ when every $X_n $ is compact.suppose $A_n$ is a countable dense set for  each $X_n$. put $A=\cup A_n$. clearly A is dense in X. Can I claim $C_0(X)=\cup C(X_n)$? 
so in this case $C_0(X)$ is separable. I do not know my proof in part (a) is correct or not. Also I have problem in parts b,c. Please help me. Thanks in advance.","['functional-analysis', 'banach-spaces']"
875569,simple geometry question- equation of cylinder,"A cylinder is $(x-a)^2+(y-a)^2=r^2$ with axis at $z$. I don't see where the '$z$' is in the equation. The book (calc 3) I'm using mentions the equation works for any $z$, but I don't see where the $z$ output is in the equation Here is the excerpt from the book, the only part referencing to the basic equation of the cylinder as I've read 1-2 chapters beyond this point (it is a 4 chapter vector calc text)",['geometry']
875570,"Is it possible to cover a $70\times70$ square with $24$ squares with side length $1,2,3\ldots24$?","Is it possible to cover a $70\times70$ square with $24$ squares with side length $1,2,3\ldots24$?",['combinatorics']
875637,Does a function that is twice weakly differentiable have a version that is classically differentiable?,"I have been wondering about the idea of functions that are weakly differentiable. My intuition tells me that the weak derivative allows one to differentiate functions that either have a removable discontinuity or have a kink. Functions with a jump that cannot be ""repaired"" are not weakly differentiable. Furthermore, it seems that if we take the weak derivative of a non-classically differentiable function $f$ with a kink at some point $x$, then the weak derivative will have a jump at $x$ since the limits of the classical derivative approaching $x$ from the left and the right will differ. It would therefore follow that the weak derivative of $f$ is not weakly differentiable. Is this idea correct? If so, does that imply that in order for the second weak derivative to exist, the function is equivalent to (in the Lebesgue sense) a classically differentiable function?","['calculus', 'functional-analysis', 'analysis']"
875662,"Suppose A has eigenvalues 1,2, 4.","a) What is the trace of  $A^2$
b) What is the determinant of $(A^{-1})^T$ I need someone to check my answers and correct me, am especially not sure about part a), help me me out; for a), I did--- Trace $A = 1+2+4 = 7$. So trace $A^2 = 14$ for b) $det(A^{-1})^T = 1/(1\times2\times4) = 1/8$","['vector-spaces', 'matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
875700,Local convexity of the topology of weak convergence of probability measures,"Let $X$ be a Polish or standard Borel space, and $\mathcal P(X)$ be the space of all Borel probability measures on $X$ endowed with the topology of weak convergence. I am thinking of using Choquet-Bishop-de Leeuw theorem which requires working on locally convex topological spaces. I thus wonder whether $\mathcal P(X)$ can be considered as a subspace of a locally convex topological space, or shall I instead work with compact subsets of $\mathcal P(X)$ in some norm topology?","['convex-analysis', 'measure-theory', 'probability-theory', 'locally-convex-spaces', 'functional-analysis']"
875709,Canonical connection on $CP^n$,"I have heard something along the lines of ""There is a canonical $U(1)$ connection on $CP^n$"" and I am trying to understand what that means. First I suppose that the sentence refers to a line bundle over $CP^n$, possibly the tautological line bundle. Second why is there a preferred connection?
I was thinking that $CP^n$ can be realised as the homogenous space $\frac{U(n+1)}{U(1)\times U(n)}$. Hence the Maurer-Cartan form on $U(n+1)$ descends to a unique $U(n+1)$-invariant connection form on $CP^n$ which however takes values in $U(1)\times U(n)$. I was thinking that one way to get a $U(1)$ connection would be to follow the prescription described in https://math.stackexchange.com/questions/875705/a-construction-on-principal-bundles . Namely one constructs the bundle $U(n+1) \times_{\rho} U(1)$ where the action $\rho: U(1)\times U(n) \rightarrow U(1)$ is simply projection onto the first factor followed ny $U(1)$ multiplication. Would such a construction work? Is there a simpler way of thinking of the canonical connection on the tautological (?) line bundle over $CP^n$?","['principal-bundles', 'differential-geometry', 'homogeneous-spaces', 'fiber-bundles', 'connections']"
875729,Decompose a real symmetric matrix,"Prove that, without using induction, A real symmetric matrix $A$ can be decomposed as $A = Q^T \Lambda Q$, where $Q$ is an orthogonal matrix and $\Lambda$ is a diagonal matrix with eigenvalues of $A$ as its diagonal elements. I can see that all eigenvalues of $A$ are real, and the corresponding eigenvectors are orthogonal, but I failed to see that when putting all (interesting) eigenvectors together, they form a basis of $\mathbb{R}^n$. Edit The reason I asked this question is to show that a real symmetric matrix is diagonalizable, so let's not use that fact for a while. Other than that, any undergraduate level linear algebra can be used. Edit 2 After reading Algebraic Pavel 's answer, I feel like ruling out Schur Decomposition as well, but I can't keep ruling out theorems, so...if a proof is too obvious, that's probably not what I am looking for, though, it maybe a technically correct answer. Thanks.",['linear-algebra']
875745,"A set of all rational numbers in $[0, 1]$?","I have a question that is giving me some minor grief: If $A$ is a closed set containing all rational numbers $r \in [0, 1]$, then show that $[0, 1] \subset A$. I don't really understand this question - surely that set of all values $[0, 1]$ contains infinitely more points that the set of rational numbers over the same interval? Am I missing something large? Thanks in advance.",['general-topology']
875764,Example of non continuous random variable with continuous CDF,"Can someone provide an example of $X$ being a non-continuous random variable with continuous cumulative distribution function? For instance: $X$ is discrete if it takes (at most) a countable number of values. $X$ is continuous (or absolutely continuous) if its law $P^X$ admits a density $f(x)$. Note: A random variable don't have to be necessarily discrete or continuous; just take a cumulative distribution function that is non-constant and continuous except in $0$.
Then $X$ is neither continuous nor discrete. I know that to ensure that $X$ is continuous, we need to ask $F_X \in C^1$, as $F_X \in C^0$ does not suffice. I would then like to see a non continuous random variable with continuous cdf","['probability-theory', 'probability-distributions', 'probability', 'random-variables']"
875818,Semidirect products as (amalgamated) free product,It is well known that $\mathbb{Z}\rtimes \mathbb{Z}_2$ is free product  $\mathbb{Z}_2 \star \mathbb{Z}_2$. Are there more examples of these kind?,"['examples-counterexamples', 'free-groups', 'group-theory', 'semidirect-product']"
875826,Double Angle Equations,"$\cos2x=\frac1{\sqrt2}$ is the original problem, and I have to solve for $x$. However, I'm not sure what to do after I substitute the double angle formulas for $\cos2x$. I know that $\frac1{\sqrt2}$ can be rationalized to $\frac{\sqrt2}{2}$.",['trigonometry']
875836,If $\vec r = x \hat i + y \hat j + z \hat k$ and $r =| \vec r |$ show that $curl [f(r) \vec r] = 0$,"I know that $\nabla \times f(r) \vec r = \nabla f(r) \times \vec r + f(r) \left ( \nabla \times \vec r \right )$. I figured that the rightmost expression is $0$. How do I prove that $\nabla f(r) \times \vec r = 0$ ? The actual question in the book is to evaluate the curl, and the answer key says that the answer is 0. I've already expanded the vector product but do not see how it becomes 0.",['multivariable-calculus']
875837,Almost pointwise inner automorphism of free products of groups.,"Let $A,B$ be groups, let $G = A\ast B$ be their free product and let $\phi \in \text{Aut}(G)$ be a automorphism of $G$. We say that $\phi$ is pointwise inner if $\phi(g) \sim_G g$ (there is $w \in G$ such that $\phi(g) = wgw^{-1}$) for every $g \in G$. It is not too difficult to show that if $\phi$ is pointwise inner then $\phi$ is actually inner.
However, what if we assume that $\phi(g) \sim_G g$ for all $g \in G$ such that $|g|=2$, where $|g|$ denotes the length of $g$? Can one then show that $\phi(g)\sim_G g$ for all $g\in G$ such that $|g|=1$?",['group-theory']
875840,How can I evaluate this indefinite integral? $\int\frac{dx}{1+x^8}$,How do I find $\displaystyle\int\dfrac{dx}{1+x^8}$? My friend asked me to find $\displaystyle\int\dfrac{dx}{1+x^{2n}}$ for a positive integer $n$. But looking up I am getting pretty noisy answer for a general value. I have seen that $\displaystyle\int\dfrac{dx}{1+x^6}$ can be broken into partial fractions because of the odd factor of $6$. So I am curious what is the algorithm to compute the integral for $n$ being a power of $2$.,"['calculus', 'integration', 'indefinite-integrals']"
875841,solving equation also involving unknown matrix in trace,"Given two real $m$ x $k$ matrices $A_1$ and $B_1$ and two $k$ x $k$ real matrices $A_2$ and $B_2$ I want to solve the following equation for $Q$. $Q$ is an orthogonal matrix, i.e. $Q^TQ=I$. $$\frac{tr(Q^TA_1^TB_1)}{tr(A_1^TA_1)} Q^TA_1^TB_1 + Q^TA_2^TB_2 = symmetric$$ The solution to a similar problem (without the trace expression) has e.g. been described by Schönemann (1966, p. 2) and goes like this. $$ 
Q^TA_1^TB_1 + Q^TA_2^TB_2 = symmetric \\
Q^T(\underbrace{A_1^TB_1 + A_2^TB_2}_{C}) = symmetric \\
Q^TC = C^TQ \\
C = QC^TQ \\
CC^T = QC^TQQ^TCQ^T = QC^TCQ^T
$$ With $CC^T$ and $C^TC$ being diagonizable and having the same latent roots, let $$ CC^T = WDW^T \text{and} C^TC = VDV^T \\
\text{with} \\
I = W^TW = WW^T = V^TV = VV^T$$ We get
$$ WDW^T = QVDV^TQ^T$$
and thus
$$W=QV \\
\text{and} \\ 
Q=WV^T$$ I tried work out an argument along the same lines but do not know how to do that with the trace expression which also contains $Q$. Any ideas? PS. I am a psychologist, no mathematician, so please bear with me ;) Schönemann, P. H. (1966). A generalized solution of the orthogonal procrustes problem. Psychometrika , 31 (1), 1–10. doi:10.1007/BF02289451","['trace', 'matrices', 'linear-algebra']"
875849,Why Trace and the main diagonal of a matrix are distinguished,"Let $A$ be a square $n \times n$ over a field (say $\mathbb{R}$ or $\mathbb{C}$). As we know, the main diagonal $(a_{1,1},...,a_{n,n})$ is important in linear algebra while the off-diagonal is far less important. The deep question is why? We try to test it using the trace, which lies heavily on the main diagonal of a matrix. Recall that the trace is defined as
$$ \operatorname{Tr}(A) := \sum_{i=1}^n a_{i,i} \ .$$
We know that it is a good operator, in the sense it is invariant under matrix conjugation (matrix similarity: $B = M A M^{-1} \Rightarrow \operatorname{Tr}(A) = \operatorname{Tr}(B)$). Let us look on the symmetry group $S_n$ of $n!$ permutations. Let us define a more general trace: let $\sigma \in S_n$ then
$$ \operatorname{Tr}_{\sigma}(A) := \sum_{i=1}^n a_{i,\sigma(i)} \ . $$
Note that $\operatorname{Tr}(A) = \operatorname{Tr}_{\operatorname{id}}(A)$
I checked on few examples that $\operatorname{Tr}_{\sigma}(A)$ is not generally invariant under matrix conjugation. The question is why? My thought is that it is due to the fact $\operatorname{Tr}(A) = \operatorname{Tr}_{\operatorname{id}}(A)$ and that $\operatorname{id} \in S_n$ is the unit element of the group $S_n$ and hence a distinguished element. However, I did not managed to show how this fact implies that the trace is invariant under matrix conjugation while $\sigma$-trace is generally not. What I did managed to show is that
$$ \operatorname{Tr}_{\sigma}(AB) \ne \operatorname{Tr}_{\sigma}(BA) $$
unless $\sigma = \operatorname{id}$. I think this implies that the $\sigma$-trace isn't invariant under conjugation (as $\operatorname{Tr}(MAM^{-1}) = \operatorname{Tr}(AM^{-1}M) = \operatorname{Tr}(A)$). I want to connect between the deep fact the the identity is the unit element of $S_n$ to the fact the only the $\sigma$-trace $\operatorname{Tr}_{\operatorname{id}}(A)$ is invariant under matrix conjugation.",['linear-algebra']
875861,How is partial time derivative $\frac{\partial}{\partial t}$ defined for vector flows?,"This question emerged when I was thinking about Liouville's theorem of classical mechanics. As far as I understand, the change of any function along the integral curves of Hamiltonian vector field is $$\frac{d \rho}{d t} = \{\rho, H \} = \mathcal L_X \rho $$ where $\{\,,\}$ is Poisson bracket, $X$ is a vector field associated with $dH$ and $\mathcal L$ is Lie derivative. I have the following understanding of $\frac{d f}{d t}$ --- as we move on the manifold $M$ with a speed $X$, the landscape ($f$ visioned as mountains on $M$) changes. The mountains are still, it us who is moving. On the other hand, in certain formulations of Liouville's theorem $\frac{\partial}{\partial t}$ is used: $$\frac{\partial \rho}{\partial t} = - \{\rho, H \} $$ (The question is about the definition of $\frac{\partial}{\partial t}$, not about the contents of Liouville's theorem). I am familiar with the notion of material derivative and partial time derivative from usual formulations of fluid dynamics, but I am not sure of their counterparts in differential geometry. What is partial time derivative $\frac{\partial}{\partial t}$ and how is it defined invariantly for functions, vector fields and differential forms? How is it related to $X$ and $\mathcal L_X$?","['lie-derivative', 'classical-mechanics', 'differential-geometry']"
875873,Prove: Square Matrix Can Be Written As A Sum Of A Symmetric And Skew-Symmetric Matrices,Let $C^{n \times n}$ be a square matrix. Prove that $$C=\frac{1}{2}(C+C^T)+\frac{1}{2}(C-C^T)$$ What I have manage so far is: a. Let $S$ be a Symmetric Matrix so $S=C+C^T$ b. Let $N$ be a Skew-Symmetric Matrix so $N=C-C^T$ Proof: $S^t=[C+C^T]^T=C^T+C=S$ $N^t=[C-C^T]^T=-C^T+C=-N$,['linear-algebra']
875885,Does the series $\sum_{i=0}^{\infty}\exp\{{-(m!)!}\}(D^m\phi)(0)$ converge for every $\phi \in C^\infty$?,"Does the series $$\sum_{m=0}^{\infty}\exp\{{-(m!)!}\}(D^m\phi)(0)$$
  converge for every $\phi \in C^\infty$? For analytic function $\phi$, we can show that the series converges by using Caushy-Schwartz inequality. But I believe in general that there is an example that the series diverges. Although we have a Taylor expansion
$$\phi(x)-\phi(0)=x\phi'(x)+...+\frac{x^n}{n!}\phi^{(n)}(x)+\int_0^x\frac{y^n}{n!}\phi^{(n)}(y)dy$$
it seems to be useless because we don't have any information of $\phi^{(n)}(y)$. How to make the growth of $\phi^{(n)}(0)$ fast?","['sequences-and-series', 'analysis']"
875901,Mean of this experiment,"Let the following experience : Let $x=n_0\in\mathbb{N}$. Each step, $x$ has a $1/2$ probability of increasing by one and a
  $1/2$ probability of decreasing by one. The goal is to determine the Mean of this experience for an
  infinite number of steps. If $x$ was varying over $\mathbb{Z}$ then it seems obvious to me that the Mean should be $n_0$. However, if we now limit $x$ to $\mathbb{N}$ (which implies that if $x$ is $0$ and is to decrease then it stays at $0$), what is the Mean of the experience ?",['statistics']
