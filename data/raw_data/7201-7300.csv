question_id,title,body,tags
54507,$|e^a-e^b| \leq |a-b|$ for complex numbers with non-positive real parts,"Came across this problem on an old qualifying exam: Let $a$ and $b$ be complex numbers whose real parts are negative or 0. Prove the inequality $|e^a-e^b| \leq |a-b|$. If $f(z)=e^z$ and $z=x+iy$, then $|f'(z)|=e^x\leq 1$ given that $x \leq 0$. I played around with the limit definition of the derivative, but wasn't able to get anywhere. Not sure what else to try; a hint would be very helpful!","['inequality', 'complex-analysis']"
54512,Forecasting based on advises from multiple advisers with various experiences(sample sizes),"I have a signal generator, which each second generates one of the letters 'a', 'b' or 'c'. I don't know anything else about this signal generator, but I suspect that there are some patterns to it. The signal generator is started at time 0. Given output of the signal from time 0 to time n, I need to forecast its output at time n+1. I suspect that there are some patterns to the signal, so I create a frequency table: For each sub-string(up to length 7) of the first n symbols of the signal generated data, I calculate three values: the number of occurrences of 'a','b', and 'c' after that sub-string. So, for example for sub-string ""abc""(if it exists in the data), I store: the number of cases when symbol 'a' comes after string ""abc"" the number of cases when symbol 'b' comes after string ""abc"" the number of cases when symbol 'c' comes after string ""abc"" Now that I have all these data, I have 7 predictions as to what the next symbol could be. If for example the last 7 characters of the signal are ""acbccba"", then: If I look just at the one-character frequency table, then I will have a certain prediction, which would look like:
""Since the last character of the string is 'a', and since coming directly after character 'a' there were 40 cases of letter 'a', 25 cases of letter 'b', and 130 cases of letter 'c', I predict that the next character will be letter 'c'"" Similarly for the last 2-letter(""ba""), 3-letter(""cba""), ... , 7-letter(""acbccba""). So in the end I have 7 predictions. The question is, how do I find which next character is actually the most probable for this signal generator? Different predictions are based on different sample sizes, so how do I combine them effectively?","['statistics', 'probability']"
54522,subgroup generated by two subgroups,"Let $A$ and $B$ be two subgroups of the same group $G$. let $$AB=\{ab\,|\, a\in A,\, b\in B \}$$
and 
$$\langle A,B\rangle$$ the subgroup generated by $A$ and $B$. Are $AB$ and $\langle A,B\rangle$ the same as sets? My guess is no since the element $aba\in \langle A,B\rangle$ but it is not in $AB$, but I guess when $A$ and $B$ commute: $AB=BA$ then this is true. is this correct?",['group-theory']
54526,Why is the Hessian of an irreducible polynomial not zero?,"Let $k$ be an algebraically closed field, $\operatorname{char}k=0$, $F$ be an irreducible homogeneous polynomial of degree$>1$ in $k[X,Y,Z]$, and $H=\det\left(\begin{array}{ccc}F_{xx}&F_{xy}&F_{xz}\\F_{yx}&F_{yy}&F_{yz}\\F_{zx}&F_{zy}&F_{zz}\end{array}\right)$. Make more clear, in this setting, that $H\neq 0$ is always true. Why is $H$ not 0?
  Is there a pure algebraic proof of this ? Thanks.","['commutative-algebra', 'algebraic-geometry', 'abstract-algebra']"
54534,Finding the set $\{z: e^z=-1\}$,"I want to find the set of $z$ 's such that $\{z: e^z=-1\}$ . Then this just mean that I have to solve $\cos(-iz)+i\sin(-iz)=-1$ which is equivalent to having $\cos(-iz)=-1$ and $\sin(-iz)=0$ Then I find that the set of solutions is such that $-iz=\pi + 2k\pi$ or in other words, $z=(1+2k)\pi i$ Should I also consider the possibility that $\sin(-iz)=i$ and $\cos(-iz)=0$ or is it irrelevant to take this possibility into account? I am not sure. Thx.","['complex-numbers', 'complex-analysis']"
54543,Is it possible for a cyclic additive group to have more than one generator?,"I'm trying to find an element $k$ that generates the cyclic additive group $\mathbb{Z}_{6}$. Since a group is cyclic, the entire group can be generated by a single element. I've tried adding $\langle1\rangle$ and $\langle5\rangle$ repeatedly in modulo $6$. And both $1$ and $5$ give me all the elements of $\mathbb{Z}_{6}$. So is it possible for a cyclic additive group to have more than one generator or am I doing something wrong?","['finite-groups', 'group-theory', 'abstract-algebra']"
54547,Which integers are the areas of squares with vertices in the 3d integer lattice?,"For which integers $n$ does there exist a square of area $n$ with vertices in the 3d integer lattice $\mathbb{Z}^3$? A sufficient condition is that $n$ is a square or the sum of two squares, and I have verified that the condition is also necessary when $n < 10^5$. Edit: This question was posed by James Tanton on Twitter. I thought it was very interesting, so I took the liberty of posting it here. Edit 2: I have extended the search to $n < 10^6$ without finding any counterexamples.",['number-theory']
54550,An inequality satisfied by the circumradius and inradius of a right triangle,"This should be trivial, but I am unable to show that $R \geq (1+\sqrt{2})r$ for a right triangle. Where $R$ is the circumradius and $r$ is the inradius of a right triangle.","['geometry', 'inequality', 'geometric-inequalities', 'triangles', 'circles']"
54554,Medial Limit of Mokobodzki (case of Banach Limit),"A classical Banach limit is very useful concept for me, but there is a problem with the integration and even with the measurability, this means for a sequence $(f_n)_{n\in \mathbb{N}}$ of measurable (eg borel) and uniformly bounded functions, the function $x \mapsto L((f_n(x))_{n\in\mathbb{N}})$ , where $L$ is Banach limit, is not measurable in general. I heard about a stronger concept of Banach limit of Mokobodzki called ""medial limit"", that exists, assuming the continuum hypothesis. This functional apparently has the same properties like Banach limit and additionally, which is important for me, commutes with integration in appropriate settings, this means it would preserve the measurability and satisfied condition $M((\int f_n(x)\mu(dx))_{n\in\mathbb{N}}))=\int M((f_n(x))_{n\in\mathbb{N}})\mu(dx)$ , with appropriate assumptions. Unfortunately, I found only a brief mention of this notion in the available literature. Could somebody explain to me this idea more precisely or point me to available literature on this subject?","['set-theory', 'measure-theory', 'cardinals', 'functional-analysis']"
54555,Why does a constructible set in a Noetherian topological space contain an open subset dense in its closure?,"In a Noetherian topological space, a constructible set is a finite union of locally closed sets. This is a conclusion on constructible sets: Every constructible set contains a dense open subset of its closure. Now neglect the Noetherian condition, and give $\mathbb{R}$ the usual topology. $\{0\}$ is closed, thus ""constructible"". The only open set contained in $\{0 \}$ is the empty set. It is certain that the empty set is not dense in the closure of $\{0 \}$ which is equal to $\{0 \}$. So, the Noetherian condition is necessary. But the result does not seem clear to me. Would you please give me a proof or a reference? Many thanks.",['general-topology']
54565,What is the relation between normal extension and separable extension?,"What is the relation between normal extension and separable extension? Let F be the algebraic extension of K, if F is a separable extension of K,if and only if F is a normal extension of K? is this correct?",['abstract-algebra']
54597,"$a,b,c>0 \text{ s.t. }a+b+c=1 \implies \sqrt{ab+c}+\sqrt{bc+a}+\sqrt{ca+b} \ge 1+ \sqrt{ab}+\sqrt{bc}+\sqrt{ca}$","How can we show that the assumption $a,b,c>0$ and $a+b+c=1$ implies $$\sqrt{ab+c}+\sqrt{bc+a}+\sqrt{ca+b} \ge 1+ \sqrt{ab}+\sqrt{bc}+\sqrt{ca}~?$$",['algebra-precalculus']
54603,Group Multiplication Table,"I'm currently trying to learn abstract algebra myself, and the following is a quote from the book I am using, ""A set of equations, involving only the generators and their inverses , is called a set of defining equations for $G$ if these equations completely determine the multiplication table of $G$."" Then the book proceeds to give an example: ""Let $G$ be the group $\{e, a, b, b^{2}, ab, ab^{2} \}$ whose generators $a$ and $b$ satisfy the equations $a^{2} = e$, $b^{3} = e$, and $ba = ab^{2}$."" And claims that the three equations determine the multiplication table of $G$. So I worked out the multiplication table and displayed it below. When they say, ""completely determine the multiplication table of $G$,"" does that mean the product of two elements can be simplified to another element? For example, $(ab^{2})(ab^{2}) = ab(ba)bb = ab(ab^{2})b^{2} = abab(b^{3}) = a(ba)b = a(ab^{2})b = aab^{3} = e.$ I also don't see how inverses are used in determining the multiplication table in this case. I've only used substitution in this case. Can someone explain why inverses might be important? How did the author know that only 3 equations were enough to determine the multiplication table? And why did he choose those equations? Also what is the significance of determining a multiplication table for elements of a group? Multiplication Table of G ___________________________________________
          |  e      a      b      b^2    ab     ab^2  |
  .-------+-------------------------------------------+
  |  e    |  e      a      b      b^2    ab     ab^2  |
  |  a    |  a      e      ab     ab^2   b      b^2   |
  |  b    |  b      ab^2   b^2    e      a      ab    |
  |  b^2  |  b^2    ab     e      b      ab^2   a     |
  |  ab   |  ab     b^2    ab^2   a      e      b     |
  |  ab^2 |  ab^2   b      a      ab     b^2    e     |
  '-------+-------------------------------------------'","['group-theory', 'abstract-algebra']"
54611,A relation $R$ such that $R\cup R^{-1}$ is not an equivalence relation,"I have a homework assignment to find a Relation $R$ over $A = \{1,2,3\}$
where $R\cup {{R}^{-1}}$ is not an equivalence relation (transitive, reflexive and symmetrical). $R$ must be Transitive and Reflexive (${{I}_{A}}\subseteq R$) Any clue anyone? 
I just am unable to find an example Thanks","['examples-counterexamples', 'elementary-set-theory']"
54627,Inequality involving sides of a triangle,"How can one show that for triangles of sides $a,b,c$ that $$\frac{a}{b+c}+\frac{b}{c+a}+\frac{c}{a+b} < 2$$ My proof is long winded, which is why I am posting the problem here. Step 1: let $a=x+y$, $b=y+z$, $c=x+z$, and let $x+y+z=1$ to get $\frac{1-x}{1+x}+\frac{1-y}{1+y}+\frac{1-z}{1+z}<2$ Step 2: consider the function $f(x)=\frac{1-x}{1+x}$, and note that it is convex on the interval (0,1), so the minimum of $\frac{1-x}{1+x}+\frac{1-y}{1+y}+\frac{1-z}{1+z}$ is reached when the function takes the extreme points. i.e. $x=y=0, z=1$. But going back to the fact that this is a triangle, we note that $x=y=0 \implies a=0$ which is not possible, so the inequality is strict.","['geometry', 'inequality']"
54635,Integer partition with fixed number of summands but without order,"For a fixed $n$ and $M$, I am interested in the number of unordered non-negative integer solutions to
$$\sum_{i = 1}^n a_i = M$$ Or, in other words, I am interested in the number of solutions with distinct numbers. For $n = 2$ and $M = 5$, I would consider solutions $(1,4)$ and $(4,1)$ equivalent, and choose the solution with $a_1 \ge a_2 \ge ... \ge a_n \ge 0$ as the representative of the class of equivalent solutions. I know how to obtain the number of total, ordered, solutions with the ""stars and bars"" method. But unfortunately, I cannot just divide the result by $n!$ since that would only work if all the $a_i$ are distinct.",['combinatorics']
54643,why not just 2 charts to make atlas for sphere?,"In http://en.wikipedia.org/wiki/Manifold_(mathematics)#Construction , it says that 6 charts can be used to make an atlas for a sphere. But the text shows that you have a chart for the northern hemisphere, and you can make a similar chart for the southern hemisphere. Hence, these two charts cover the entire sphere. What am I doing wrong?","['differential-topology', 'differential-geometry']"
54661,"Polynomial equations $p(A, B) = 0$ for matrices that ensure $AB = BA$","Let $k$ be a field with characteristic different from $2$, and $A$ and $B$ be $2 \times 2$ matrices with entries in $k$. Then we can prove, with a bit art, that $A^2 - 2AB + B^2 = O$ implies $AB = BA$, hence $(A - B)^2 = O$. It came to a surprise for me when I first succeeded in proving this, for this seemed quite nontrivial to me. I am curious if there is a similar or more general result for the polynomial equations of matrices that ensures commutativity. (Of course, we do not consider trivial cases such as the polynomial $p(X, Y) = XY - YX$ corresponding to commutator) p.s. This question is purely out of curiosity. I do not know even this kind of problem is worth considering, so you may regard this question as a recreational one.","['matrices', 'linear-algebra']"
54674,geometric meaning of a trigonometric identity,"It follows from the law of cosines that if $a,b,c$ are the lengths of the sides of a triangle with respective opposite angles $\alpha,\beta,\gamma$, then
$$
a^2+b^2+c^2 = 2ab\cos\gamma + 2ac\cos\beta + 2bc\cos\alpha.
$$ For a cyclic (i.e. inscribed in a circle) polygon, consider the angle ""opposite"" a side to be the angle between adjacent diagonals whose endpoints are those of that side (it doesn't matter which vertex of the polygon serves as the vertex of that angle because of the Inscribed Angle Theorem ).  Then for a cyclic quadrilateral with sides $a,b,c,d$ and opposite angles $\alpha,\beta,\gamma,\delta$, one can show that
$$
\begin{align}
a^2+b^2+c^2+d^2 = {} & 2ab\cos\gamma\cos\delta + 2ac\cos\beta\cos\delta + 2ad\cos\beta\cos\gamma \\
& {} +2bc\cos\alpha\cos\delta+2bd\cos\alpha\cos\gamma+2cd\cos\alpha\cos\beta \\
& {}-4\frac{abcd}{(\text{diameter})^2}
\end{align}
$$
And for a cyclic pentagon, with sides $a,b,c,d,e$ and respective opposite angles $\alpha,\beta,\gamma,\delta,\varepsilon$,
$$
\begin{align}
a^2 + \cdots + e^2 = {} & 2ab\cos\gamma\cos\delta\cos\varepsilon+\text{9 more terms} \\& {} - 4\frac{abcd}{(\text{diameter})^2}\cos\varepsilon+ \text{4 more terms}
\end{align}
$$
And for a cyclic $n$-gon with sides $a_i$ and opposite angles $\alpha_i$,
$$
\begin{align}
\sum_{i=1}^n a_i^2 = {} & \text{a sum of }\binom{n}{2}\text{ terms each with coefficient 2} \\
& {} - \text{a sum of }\binom{n}{4}\text{ terms each with coefficient 4} \\
& {} + \text{a sum of }\binom{n}{6}\text{ terms each with coefficient 6} \\
& {} - \cdots
\end{align}
$$
The number of terms depends on $n$ and the power of the diameter on the bottom is in each case what is needed to make the term homogeneous of degree $2$ in the side lengths (""dimensional correctness"" if you like physicists' language), and the alternation of signs continues. I showed this by induction.  It should work for infinitely many sides, too, by taking limits.  Each term would then have a product of infinitely many cosines. My question is: Is there some reasonable geometric interpretation of the sum of squares of sides of a polygon inscribed in a circle?","['trigonometry', 'euclidean-geometry']"
54679,Is there an infinite number of primes constructed as in Euclid's proof?,"In Euclid's proof that there are infinitely many primes, the number 
$p_1 p_2 ... p_n + 1$
is constructed and proved to be either a prime, or a product of primes greater than $p_n$. Trivially, we could also use the number $R_n=p_1 p_2 ... p_n - 1$ to prove the theorem, for n>2. Intuitively, as $n$ grows, the probability that $R_n$ is prime gets smaller. Is there a proof that $R_n$ is not prime for any $n$ greater than some integer $M$ ? Or conversely, that there is an infinite number of prime $R_n$ numbers? A possibly equivalent question:
Is there a prime number greater than $p_n$ and smaller than $R_n$ for any $n$ greater than some integer $M$ ?","['prime-numbers', 'infinity', 'number-theory']"
54682,What is $\sum\limits_{n=0}^{\infty} r^{an^2 + bn + c}$ ?  or: is $0.0100100010000100001...$ transcendental?,"The idea is a more convenient form for $N = 0.01001000100001000001...$ in base $r$, hopefully to show whether it is transcendental. Sorry for brevity.","['sequences-and-series', 'transcendental-numbers']"
54685,Can you write a non-piecewise equation that describes an arbitrary shape?,"This Batman equation thing got me thinking: for an arbitrary curve drawn on the Cartesian plane, can you write a corresponding equation which is not piecewise? What about closed shapes, a la the Batman symbol? I assume that there are limitations, such as that the curve would have to be differentiable and/or continuous everywhere, but is this possible for any random squiggle? Or is it not?","['geometry', 'plane-curves', 'algebra-precalculus', 'graphing-functions']"
54699,"Showing that Mg, the Mapping Class Group of the 1-Torus, is $SL(2,\mathbb Z)$","All: I am trying to figure out the mapping class groupof the torus ; more accurately, I am trying to show that it is equal to $SL(2,\mathbb Z)$ . The method: every homeomorphism h: $ T^2 \rightarrow T^2 $ gives rise to, aka, induces, an isomorphism g: $  \pi_1(T^2) \rightarrow  \pi_1(T^2)$ , and we use the fact that: i) $\pi_1 (T^2)=\mathbb Z\oplus\mathbb Z$ ii) Aut $ \mathbb Z\oplus\mathbb Z=SL(2,\mathbb Z)$ Now, if we can show that the homomorphism from [the group of homeomorphisms
of $T^2$ to itself ] to $SL(2,\mathbb Z)$ is an isomorphism,
      we are done. Now, it is not too hard (tho, I think not trivial) , to show that $SL(2,\mathbb Z)$ has a generating set with three elements ; the set of transvections (actually a set of four transvections that are generating set for the set of transvections ); the transvections are a generalization of shear maps in linear transformations $T: \mathbb R^n \rightarrow \mathbb R^m$ , as maps that add a multiple of a row to another row. A (generating) shear matrix has all diagonal entries $a_{ii}$ identically equal to one, and exactly one non-diagonal entry equal to +/-1
(general shear matrices have all $a_{ii}=1$ and exactly one off-diagonal term with any non-zero value). So to show the map is onto, I am trying to see that each of the elements of
the generating set are the image of some homeomorphism from the torus to itself, i.e., to show that there are automorphisms of the torus thad induce the basis shear maps, by examing the effect of the shear maps on a standard basis $\{(1,0),(0,1)\}$ of the torus, and trying to construct a self-homeo of the torus that would have the effect on homology described by the effect of the shear maps on the basis  . I was also thinking of using the fact that the mapping class group for $S_g$ is known to have a generating set of size $3g-1$ (best possible) , given by Dehn twists about the basis. I suspect these Dehn twists (about the basis elements) may induce mapsin homology describable as shear matrices. Does any know? I will try to complete this idea, but I would appreciate some comments on whether
  this approach makes sense. I would appreciate your comments/suggestions. Thanks.","['general-topology', 'geometry', 'mapping-class-group', 'algebraic-topology']"
54711,Group theory text [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Introductory Group theory textbook I am an Indian student currently in the eleventh grade.I haven't yet learned calculus(I am learning it ) but I would also like to study a bit of Abstract Algebra by myself.Here is the context :
  What I plan to do is to take the theorems for a particular chapter and then try to prove them myself.If I am unable to do so after trying for a long time or I have managed to prove them rigorously,only after that will I refer to the text.So, can someone please tell the name of a well-structured book which isn't quite haphazard with good,tough problems. Thank you.","['reference-request', 'group-theory']"
54713,Complex cosine and sine,"I would like to know what the mapping properties of the complex sine and cosine are. To start with one can say that $\sin(z)$ and $\cos(z)$ are conformal where their derivatives are nonzero, which means $\sin(z)$ preserves angles on $\mathbb{C}$ without $\frac{\pi}{2}+k\pi$ and $\cos(z)$ preserves angles on $\mathbb{C}$ without $\pi k$ for $\cos(z)$, with $k \in \mathbb{Z}$. What else can we say about these mappings? Thx.",['complex-analysis']
54719,Bounds on the gaps in a variant of polylog-smooth numbers.,"Sorry for the long intro. I think the explanation motivates the question and puts it in context. But if you want to skip the story, then just move on to the grey boxes; they should contain enough information to make out my question. This question is inspired by Sadeq Dousti's question on producing a factored integer from a small interval: Factoring some integer in the given interval . For convenience, I will assume that the problem is to produce a factored integer from the interval $[x-G; x]$, and our goal is to make $G = G(x)$ as small as possible. (Beware that Sadeq's version uses $N$ in place of my $x$, and fixes $G(x)$ concretely to be $O(\log x)$.) One can consider several candidate easily-stated algorithms for this problem, all of which work in the following general way. Let $S$ be a set of integers such that Given a number $N$, testing if $N$ is in $S$ can be done efficiently. Moreover, any $N \in S$ can also be factored in time $\mathrm{poly}(\log N)$. The gaps in $S$ are ""small"": for all sufficiently large $x > 0$,
  there exists $N \in S$, such that $x - G(x) \leq N \leq x$. (Hence my
  notation $G$.) Then the given problem can be solved for intervals of length $G(x)$: just search for an $S$-element in the interval and output its factorization. The whole problem then becomes how small can we make $G(x)$ to be . Here are some candidate sets: Powers of $2$. Primes. The set of numbers $N$ such that all prime divisors of $N$ are at most $\log^A(N)$ for some absolute constant $A < \infty$. I'll call these polylog-smooth numbers. (See the fineprint at the end of the question.) The set of numbers $N$ such that at most one of its prime divisors exceeds $\log^A(N)$ where $A$ is as before. I'll call these almost polylog-smooth numbers. Ok, enough with the names :-). All these examples satisfy the first requirement (testing+factoring) by design. (For instance, in the last case, divide out all small prime divisors of $N$ by brute force, and we will be left with either $1$ or a large prime number, and so we'll be in good shape.) The big question then is to analyze the gaps in these sets. The powers of two are very sparse. They have a gap $G(x) = O(x)$ and this is tight. The primes are suspected to have better gaps (see the Consequences of Riemann hypothesis and Cramér's conjecture ). In short, the gap  might be as small as $O(\log^2 x)$. On the other hand, the best unconditional bound is $O(x^{\theta})$ for $\theta < .53$. I do not have enough background to grok the question of gaps for the polylog-smooth numbers. Nevertheless, I found Andrew Granville's survey on smooth numbers ( Smooth numbers: Computational Number Theory and beyond ) says that even the average gap is around $x^{1/A}$. (I am quoting Theorem 1.14 from page 4/page 270 in the pdf I have linked to.) This might be quite bad compared to the conjectured gap for the primes example, but a great improvement over the powers of $2$. Now, what about the set of almost polylog-smooth numbers? They are denser than the primes, so it's definitely at least as small as $O(\log^2 x)$ conditionally and $O(x^{\theta})$ unconditionally. But taking a clue from the improvement we got in going from the powers of $2$ to the smooth-numbers, I believe that the actual gaps for the almost-smooth numbers should be even better than that of the primes. That is the motivation behind my question: What are the current best bounds on the gaps on the almost polylog-smooth numbers (conditionally and unconditionally)? Specifically, is it possible that $G = O(\log x)$ for this case? Any help? Fineprint that morally shouldn't matter. A number is $B$-smooth if its prime divisors are at most $B$. It seems to me that when people analyze properties of the smooth numbers $\leq x$, they usually set the smoothness parameter $B$ to be a function of $x$, like $B = \log^A x$. I defined a smooth number more ""intrinsically"" by setting $B = \log^A N$. I presume that this is just a technical issue, and none of the bounds will really change that much. If I am wrong, then please let me know. In any case, I see no reason why one definition is better for this application than the other.","['reference-request', 'algorithms', 'number-theory']"
54735,Restricted Three-Body Problem,"The movement of a spacecraft between Earth and the Moon is an example of the infamous Three Body Problem. It is said that a general analytical solution for TBP is not known because of the complexity of solving the effect of three bodies which all pull on each other while moving, a total of six interactions. Mathematician Richard Arenstorf while at NASA solved a special case of this problem, by simplifying the interactions to four, because, the effect of the spacecraft's gravity upon the motion of the vastly more massive Earth and Moon is practically non-existent. Arenstorf found a stable orbit for a spacecraft orbiting between the Earth and Moon, shaped like an '8' http://en.wikipedia.org/wiki/Richard_Arenstorf Was Arenstorf's solution purely analytical, or did he use numerical mechanisms? Is the '8' shape an optimal path, meaning the route on which the spacecraft would expand the least amount of energy? If yes, how was this requirement included in the derivation in mathematical form? If anyone has a clean derivation for this problem, that would be great, or any links to books, other papers, etc. Note: Apparently there was an earlier related mathoverflow question on this as well: https://mathoverflow.net/questions/52489/on-the-non-rigorous-calculations-of-the-trajectories-in-the-moon-landings Arenstorf's technical report is here http://hdl.handle.net/2060/19630005545 Regards,","['ordinary-differential-equations', 'calculus', 'classical-mechanics', 'reference-request', 'numerical-methods']"
54736,Isomorphism between group algebras,"I am starting to study group algebras and I am stuck on the following problem. The first part is easy, but I copy it in case it helps to prove the second part. This exercise is taken from Representations of groups by Lux and Pahlings. Suppose $K$ is a field with char $\neq 2$ containing a primitive $4$th root of unity $i$, and let $\langle g \rangle = C_4$. Put $$a = \frac{1+i}{2}g+\frac{1-i}{2}g^3 \in KC_4$$ and $$b = \frac{1-i}{2}g+\frac{1+i}{2}g^3 \in KC_4.$$ (a) Show that $\{1,g^2,a, b\} \subseteq KC_4$ is a subgroup of the unit group of $KC_4$ isomorphic to $V_4 \cong C_2 \times C_2$. (easy part) (b) Show that $KC_4 \cong KV_4$ as algebras over $K$. Here is my problem:
I can't find an isomorphism between $KC_4$ and $KV_4$. Actually, I don't understand a priori how they could be isomorphic since $C_4 \ncong V_4$ as groups. As a natural second question, - since I guess that there should actually exist an isomorphism after all - I wonder: are the hypotheses ""char$K\neq 2$ and there exists a primitive 4th root of unity in $K$"" necessary in order to obtain part (b)? I think my problem is partly conceptual: I don't really have any intuition on how to work with group algebras. Could you give me hints or help me to get a clearer view on this topic?","['finite-groups', 'representation-theory', 'abstract-algebra']"
54752,Sheaf cohomology: what is it and where can I learn it?,"As I understand it, sheaf cohomology is now an indispensable tool in algebraic geometry, but was originally developed to solve problems in algebraic topology . I have two questions about the matter. Question 1. What is sheaf cohomology? I have a vague idea that it has something to do with right derived functors, but this seems rather far removed from the (admittedly very little) cohomology of (co)chain complexes I do know. I would also like to know why sheaf cohomology appears to be so much more fundamental in algebraic geometry than algebraic topology—for instance, I will be taking second courses in algebraic geometry and topology this coming autumn, but sheaf cohomology only appears in the former, suggesting that perhaps sheaf cohomology is not as relevant in basic algebraic topology. (For example, is there an ‘intuitive’ reason why de Rham cohomology cannot be made to work for algebraic varieties?) Question 2. Are there any good introductions to sheaf cohomology in a general context ? I have tried reading Chapter III of Hartshorne, but very little is getting through, perhaps because I'm not yet comfortable with schemes. A different take—perhaps with an emphasis on manifolds, say—may prove more accessible to me, but since I also need to learn it in the context of algebraic geometry, it would be nice if there were a single text which introduces the theory with applications in both subjects.","['sheaf-theory', 'algebraic-geometry', 'algebraic-topology', 'reference-request', 'soft-question']"
54754,Proving that $(b_n) \to b$ implies $\left(\frac{1}{b_n}\right) \to \frac{1}{b}$,"In my textbook (S. Abbott. Understanding Analysis 1 ed. pp 47 Theorem 2.3.3.iv), the author proves $b_n \to b$ implies $\frac{1}{b_n} \to \frac{1}{b}$ the following way: $$\left|\frac{1}{b_n}-\frac{1}{b}\right|=\frac{|b-b_n|}{|b||b_n|}$$ therefore, since we can make the numerator as small as we like by definition, we just need to find a ""worst-case estimate"" for $\frac{1}{|b||b_n|}$ by considering $|b_n| \geq \lambda > 0$. He then argues that we need to look far into the sequence so that  the terms are closer to $b$ than to $0$. So, considering $\epsilon_0$=$|b|/2$, we can use $|b_n-b|<|b|/2$ for all $n \geq N_1$. Thus, $|b_n| \geq |b|/2$. Then we choose $N_2$ s.t. $n \geq N_2$ implies $|b_n-b|<\frac{\epsilon |b|^{2}}{2}$. Finally, if $N$ = max {$N_1, N_2$}, then $n \geq N$ implies 
$$\frac{|b-b_n|}{|b||b_n|}<\frac{\epsilon |b|^{2}}{2} \frac{1}{|b|\frac{|b|}{2}}=\epsilon.$$ 
What confuses me is why we need to pick elements closer to $b$ than to 0. What makes picking $\epsilon_0$=$|b|/3$ and $|b_n-b|<\frac{\epsilon |b|^{2}}{3}$ wrong for the proof? Thanks.",['real-analysis']
54757,What is the normal derivative of a PDE?,"Kreyszig's introduction of the normal derivative $u_n = \partial u / \partial n$ leaves me a bit puzzled as to what variable $n$ is if $u$ is a function of $x$ and $y$. The trailing example uses a condition for one of the boundaries specified as
$u_n = 6x$
and the solution steps deduces
$\dfrac {\partial u_{ij}} {\partial n} = \dfrac {\partial u_{ij}} {\partial y} = 6x$
out of thin air. So what exactly is the normal derivative? Is it simply an interpretation of a normal vector standing up from $u$ if it's treated as a surface, i.e. 
$\dfrac {\partial u_{ij}} {\partial n} = \dfrac {\partial u_{ij}} {\partial x} + \dfrac {\partial u_{ij}} {\partial y}$ 
?","['calculus', 'partial-differential-equations']"
54772,Probability on an infinite plane,"(I thought this is a popular problem, but sadly Google yields nothing.) Three points are chosen at random on an infinite plane. What is the probability that they are on a line? And a variant: the plane is discrete, that is, the point coordinates are both integers. How do I even approach this?","['geometry', 'probability', 'geometric-probability']"
54784,Uses of Chevalley-Warning,"In the recent IMC 2011, the last problem of the 1st day (no. 5, the hardest of that day) was as follows: We have $4n-1$ vectors in $F_2^{2n-1}$: $\{v_i\}_{i=1}^{4n-1}$. The problem asks :
Prove the existence of a subset $A \subseteq [4n-1], |A| = 2n$ such that $\sum_{i \in A} v_i = \vec{0}$. Is there a solution that uses the Chevalley-Warning theorem about divisibility of number of solutions by the field's characteristic? The statement of the problem seems as a ""xor"" analog of Erdos-Ginzburg-Ziv, that is usually proved by Chevally-Warning. My idea is to formulate homogeneous polynomial equations in $a_1,\cdots,a_{4n-1} \in F_2$: $P_j(\vec{a}) = (\sum a_i v_i)_j$ for $1 \le j \le 2n-1$.
Let $A(\vec{a}) = \{ i | a_i = 1\}$ and $g(\vec{a}) = |A(\vec{a})|$ (we want to choose $A = A(\vec{a})$ for a solution $a$ of the system). Ideas for completing the solution: We can also create $Q_{k}(\vec{a}) = $ Symmetric polynomial of degree $2^k$ = $a_1 \cdots a_{2^k} + \cdots$. We notice that $Q_k(a) = \binom{g(\vec{a})}{2^k}$. By Lucas's Theorem, mod 2 we have $\binom{m}{2^k} = $ k'th digit of $m$ in base-$2$. So we choose the equations $Q_k(a) = \binom{2n}{2^k}$ mod 2. The problem is that we get $\sum deg(Q_k) \ge 2n$ (sum over number of digits of $4n-1$). Also, $0$ is not a trivial solution. Another idea was to define the equations $R_i(a) = a_{2i-1} + a_{2i} - a_{2i+1} - a_{2i+2} = 0, 1 \le i \le 2n$. A solution implies that $a_{2i-1} + a_{2i}$ is constant. If it is $1$, we get that from each pair of even and odd vector, one is chosen - $2n$ vectors in total. But it has some holes. Another idea is to create equations that force $g(\vec{a}) = 0$ mod n, so $\vec{0}$ is a trivial solution, and another solution would imply that a $A$ exists of size $n, 2n$ or $3n$. A nice observation is that one of the vectors is (wlog) $\vec{0}$ (can be assumed since $2n$ is even, so replacing $v_i$ by $v_i - v_{1}$ is fine). If you have idea of how to use the theorem, and examples in general of its non-trivial uses - it would be welcome.","['arithmetic-combinatorics', 'linear-algebra', 'additive-combinatorics', 'algebraic-combinatorics', 'combinatorics']"
54791,"Elementary Probability Question: Conditional case, with AT LEAST clause","Q. An anti aircraft gun fires at a moving enemy plane with 4 successive shots. Probabilities of the shots S1, S2, S3 and S4 hitting the plane are 0.4, 0.3, 0.2, 0.1 respectively. (a) What is the probability that the gun is able to hit the plane? Correct Answer is: 0.6976 (b) What is the conditional probability that at least three shots are required to be shot? Correct Answer is: 0.1686 I am getting a wrong answer for b. Please help. My thoughts: (a) is dead easy. Drawing the sample spaces, there are four scenarios. Let H denote a hit and M denote a miss. The four scenarios are: 1: H 2. MH 3. MMH 4. MMMH Sum of the probabilities of these four cases turns out to be exactly 0.6976 (lots of small decimal multiplications!), so all is good. I've got the correct answer. For the second part, my approach is: There are two cases in our favor: Case 1: MMH (3 shots exactly) Case 2: MMMH (4 shots) Adding the probabilities for these two cases, I get 0.1176 as the answer. But this is wrong according the to solution index. What am I doing wrong? Also, can someone be kind enough to show me how to model the second part using Bayes theorem of conditional probability? In the form $P(>=3|S)$, i.e. the probability of at least 3 shots being used, knowing already that the plane was shot. In particular, I understand that $P(>=3|S) = P(>3 \cap S) / P(S)$. We have calculated $P(S)$ in part a. I don't know how to calculate the intersection in the numerator.","['probability-theory', 'probability']"
54806,How can I prove this expression not to be a characteristic function,"Let $\phi$ be a function of two real arguments defined as follows: $$ \phi\left(t_1, t_2\right) = \exp \left(-t_1^2-t_2^2 +i \frac{t_1}{3}\frac{ t_1^2-3 t_2^2 }{t_1^2+t_2^2} \right)$$ and whenever $t_1^2 + t_2^2 >0$ and $\phi(0,0)$ is defined to be $1$. How can I go about proving that this is not a characteristic function of a 2D random vector. This is function is known not to correspond to any 2D random measure, and is a special case of expression considered by D.J. Marcus in ""Non-stable laws with all projections stable"" (see first link in Google Scholar ). Notice that both $\phi(t_1, 0) = \exp( -t_1^2 + i t_1/3)$ and $\phi(0, t_2) = \exp(-t_2^2)$ are characteristic functions of normal variates. What techniques can be used to prove that $\phi$ corresponds to no probability measure on a plane ?","['probability-theory', 'probability-distributions']"
54807,boundary defining functions,"Suppose that $M$ is the interior of a compact manifold with boundary $\partial M$. I'm often faced with so called boundary defining functions - or just 'defining functions'. That are by definition  functions $f \in C^{\infty}(\overline{M})$ with the following properties: (i) $f(x) > 0 \ \forall x \in M$ (ii)$f(x) = 0 \Leftrightarrow x \in \partial M$ (iii) $df \neq 0 \ on \  \partial M$ I need to know what the third property does exactly mean. Often it also is just referred as ""has no zeroes on the boundary"", ""... has a non-vanishing differential there"" or ""has a non-degenerate differential there"". For me, the differential of a map $f: M \rightarrow N$ at a point p is a linear map 
$df_p : T_pM \rightarrow T_{f(p)}N$. Does property (iii) mean:
For $v \in T_pM$ with $df_p(v)=0 \Rightarrow v = 0$ (That would be the interpreation: For every point on the boundary, the differential has no other zero than the zero vector.) Or does it mean: The differential at the point p isn't the zero map, in other words: For every point p on the boundary $\exists v \in T_pM$ with $df_p(v) \neq 0$ Thank you for your help! Robin","['physics', 'differential-geometry']"
54815,Normal closure of a radical extension is radical,"I'm struggling to understand the proof that the normal closure of a radical extension of fields is also a radical extension, which is crucial since it allows us to work with radical and normal extensions (and thus, in characteristic 0, with radical Galois extensions). The proof I'm reading is lemma 4.17 in Rotman's Advanced Modern Algebra, pp. 211-212, which I attach at the end of this message. The definition Rotman uses is the following: an extension $F\subset F(u)$ is pure if there exists $m \geq 1$ such that $u^m\in F$. An extension $F\subset K$ is radical if there exists a tower (which I like to call radical tower ) $$F=K_0\subset K_1\subset \dots \subset K_t=K$$ such that $K_i\subset K_{i+1}$ is pure for all $i$. What I'm struggling to prove is: if $F\subset K$ is a radical extension, and $N$ is the normal closure of the extension, then $F\subset N$ is a radical extension. Since I find Rotman's proof confusing (and not convincing), I have rewritten the proof. It might seem longer in appearance, but the first part of the proof (the one that troubles me) was unsatisfying. Let $m_{\alpha,F}$ denote the minimal polynomial for an element $\alpha$ over $F$. What I ask is: 1) Is my rewriting of the proof correct? 2) Is this what's behind the argument of Rotman, or is there another, more simple way of reading it? Rotman's proof seems shorter, but I don't understand when he says ""it follows that $E=k(\sigma(u_1),\dots,\sigma(u_t):\sigma \in G)$"": what are those $u_i$? Here's my rewriting: Let $F\subset K$ be a radical extension. There exist $u_1,\dots,u_t$ such that $$F\subset F(u_1)\subset F(u_1,u_2)\subset \dots \subset F(u_1,\dots,u_t) = K$$ is a radical tower. Let $E$ be the normal closure of $F\subset K$. I claim that$$E=F\left(\\{\sigma(u_i): \sigma \in \text{Gal}^E_F, i=1,\dots,t\\}\right)$$ Indeed, $$E=\text{Split}_F\left(m_{u_1,F} \dots m_{u_t,F}\right)=F(\{\text{roots of }m_{u_1,F} \dots m_{u_t,F}\})$$ Since the Galois group of a polynomial acts transitively on its roots, $\{\text{roots of }m_{u_i,F}\}=\{\sigma(u_i):\sigma \in \text{Gal}_F(m_{u_i,F})\}$. Let us see that is also equals $\{\sigma(u_i):\sigma \in \text{Gal}^E_F\}$. $(\subset)$: We can extend every $\sigma\in \text{Gal}_F(m_{u_i,F})$ to $\tilde{\sigma}\in \text{Gal}_F^E$ by the theorem of extension of a polynomial to its splitting field, by taking the polynomial $m_{u_1,F} \dots m_{u_t,F}\in F[X]$. $(\supset)$: If $\sigma\in \text{Gal}^E_F$, then $\sigma$ restricts to an $F$-isomorphism $F(u_i)\to F(\sigma(u_i))$, then (corollary 1.9 p.236 of Hungerford)  $u_i$ and $\sigma(u_i)$ must be roots of the same irreducible polynomial in $F[X]$. This proves that $\sigma(u_i)$ is a root of $m_{u_i,F}$. Let $B_i=F\left(\{\sigma(u_j):1\leq j\leq i,\sigma \in\text{Gal}^E_F\}\right)$. What we just proved is that $E=B_t$. To see that $F\subset E= B_t$ es radical, we use induction on $t$, and this part of Rotman's proof is satisfying to me. Below is Rotman's proof.","['galois-theory', 'abstract-algebra', 'field-theory']"
54818,Construct matrix given eigenvalues and eigenvectors,"Given eigenvectors $v_1, v_2, \dots, v_n$ and eigenvalues $\lambda_1,\lambda_2,\dots,\lambda_n$, how do I construct a matrix whose eigenvectors and eigenvalues are $v$ and $\lambda$? The straightforward way of doing this is to encapsulate all $n^2$ constraints into a linear system and solve for each element of the matrix $M_i$. I.e., $$
\begin{bmatrix}
v_{11} & v_{12} & \dots & v_{1n} & 0 & 0 &\dots & 0 & \dots & 0 & 0 &\dots & 0 \\
0 & 0 &\dots & 0 & v_{11} & v_{12} & \dots & v_{1n} & \dots & 0 & 0 &\dots & 0\\
 & & & & &  & \vdots \\
0 & 0 &\dots & 0 & 0 & 0 &\dots & 0 & \dots & v_{n1} & v_{n2} & \dots & v_{nn}\\
\end{bmatrix}

\begin{bmatrix}
M_1 \\ M_2 \\ \vdots \\ M_{n^2}
\end{bmatrix}

= 

\begin{bmatrix}
\lambda_1 v_{11} \\ \lambda_1 v_{12} \\ \vdots \\\lambda_n v_{nn}
\end{bmatrix}
$$ Is there a more elegant way?","['linear-algebra', 'eigenvalues-eigenvectors']"
54822,"""Center-of-Mass"" of lattice polygons (generalization of Pick's theorem)","Call a polygon with integer coordinates (in the Euclidean plane) a 'lattice polygon'. Pick's Theorem allows you to efficiently compute the number of lattice points inside this polygon given just its set of vertices. Is there a similar method to efficiently compute the sum $$\sum_{(x,y)\in \mathcal{P}} x$$ where $\mathcal{P}$ is some lattice polygon? In other words, are there any methods to compute the ""center-of-mass"" of the set of lattice points belonging to the interior/boundary of a given lattice polygon? (By efficiently, I mean something on the order of the number of vertices of the polygon. Also, by triangulation it's clear that it suffices to answer this question for lattice triangles) EDIT: In case it was unclear, I am not trying to find the actual center of mass of the triangle - I want to find the center of mass of the set of lattice points inside the triangle (hence the above sum). EDIT 2: After working on this problem a bit more, I think I've arrived at a fairly simple method which seems to work and avoids the messy machinery of 3D-Ehrhart polynomials. The idea is (just as in Pick's theorem), since we can inscribe any triangle inside a rectangle, it suffices to compute the sum for rectangles and right triangles. Computing the sum for rectangles is easy; it's just something like $(y_2-y_1)(x_1+(x_1+1)+...+x_2)$. Because of symmetry, it's almost as simple for right triangles. Namely, the sum of x-coordinates in/on the boundary of any right triangle is just equal to ((sum of x-coordinates in the corresponding rectangle) + (sum of x-coordinates along the diagonal))/2. Hopefully this helps anyone who later has the same problem.","['integer-lattices', 'discrete-geometry', 'combinatorics']"
54836,How do you take the derivative with respect to a function?,"I'm trying to figure out how to take a derivative that looks like  $\displaystyle \frac{d}{d(\ln(a))}$, of a function $F(a)$, where $a = a(t)$.  In the paper I'm reading (where this appears), they give the following result in the case that $F(a) = \frac{\dot{a}}{a}$ (where the ""dot"" is a derivative with respect to $t$): $$\frac{d(1/F^2)}{d\ln(a)} = \frac{-2\dot{F}}{F^4},$$ but I can't see how they're getting this.  Any insight would be much appreciated.",['calculus']
54839,Good abstract algebra books for self study,"Last semester I picked up an algebra course at my university, which unfortunately was scheduled during my exams of my major (I'm a computer science major). So I had to self study the material, however, the self written syllabus was not self study friendly (good syllabus overall though). The course was split up into 3 parts, group theory, ring theory and field theory. As a computer science major we only had to study the first 2. Now that I passed the exam for this course I want to study the field theory part ( which covers Galois theory, etc). So, now I want to ask whether any of you know any good books on abstract algebra, which lift off at basic ring theory and continue to more advanced ring theory and to finite fields, Galois theory, ... Please keep in mind that I am not a math major, and that I would like books which are suited for self study (thus a lot of examples and intuition). Thanks in advance!","['self-learning', 'book-recommendation', 'reference-request', 'abstract-algebra']"
54843,How to prove that derivatives have the Intermediate Value Property,"I'm reading a book which gives this theorem without proof: If a and b are any two points in an interval on which ƒ is differentiable, then ƒ'
  takes on every value between ƒ'(a) and ƒ'(b). As far as I can say, the theorem means that the fact ƒ' is the derivative of another function ƒ on [a, b] implies that ƒ' is continuous on [a, b]. Is my understanding correct? Is there a name of this theorem that I can use to find a proof of it?",['real-analysis']
54845,Combinatorial Proof: $n! = 1+\sum\limits_{r=1}^{n-1}( r\cdot r!)$,"To show it is true $r\times r!$ can be algebraically decomposed as $(r+1)!-r!$ But I am trying to think of a combinatorial proof. If $S$ is the set of all permutations of $\{1,2,\cdots ,n\}$ then I need a definition for the mutually non overlapping subsets $S_r$ whose union is $S$. So I will have $|S|=\sum|S_r|$. I am unable to think of such a decomposition.",['combinatorics']
54846,Handshaking with no crossovers in minimum number of rounds: has this problem been studied?,"I've met a group of 9 colleagues (PhD students), and when we came to handshake it was complicated as always to handshake everyone and avoid cross overs. So one guy suggested (he was not serious about it) to study the problem of the minimum number of rounds for a circle of $n$ friends to handshake such that no crossovers occur. Of couse the minimum if we allow crossovers is $n-1$ rounds, because if we fix a person, then in each round he gets to shake hands with at most one other person. But there is a moment where the two guys next to him shake hands, and so he sits idle in that round. The natural question is if there is a formula for the least number of rounds needed in this case, or at least lower bound lower than the trivial bound where each person gets to shake hands with all others while everyone else stands still waiting for him to finish. I am not expecting a solution but rather hoping if this problem has been studied before. When I tried searching I ran into all sorts of homework problems like ""if 534345 handshakes happened then how many people were there"" ... I wasn't also sure of the search terms; I tried both ""crossovers"" and ""intersection"" but no avail. Edit: From the comments I realize that maybe more solid definition for the problem is needed. Here it goes: There is a set $P$ of $n$ people positioned at the vertices of a regular $n$-gon. The goal is that after the ""program"" terminates, every person should have shook hands with every other person exactly once.  By ""shaking hands"" we mean that two persons have a edge connecting them. The execution proceeds in rounds, such that at each round a person may be either ""shaking hands"" with another person, or doing nothing. A person $i$ who shook hands in some preceding round with a subset of people $J\subseteq (P-\{i\})$ will consider only the people he did not shake hands with yet $(P-(J\cup\{i\}))$ in the next round, by selecting one of them to shake hands with. The constraint is that at no round no two edges can intersect. The question is to determine the minimum number of rounds needed to solve this problem ? Also I would be interested in a special case where the edges are restricted to be ""straight lines"", rendering the constraint a little bit different from planar graph condition, to a more geometrical condition.",['combinatorics']
54860,Why study only rook polynomials?,"In introductory combinatorics, there is an emphasis on rook polynomials . But what is the significance of only considering rook polynomials? Why not consider ""knight polynomials"" or ""bishop polynomials?""","['soft-question', 'combinatorics']"
54866,Cantor space: example of an open set that's not closed?,"Very basic question: I can't get my head around the Cantor space . It has a basis of clopen sets. Finite unions of closed sets are closed, and unions of open sets are open, so a finite union of basis elements of a Cantor space is clopen. The only open sets in a Cantor space that are not closed, if there are any, are infinite unions of basis elements. An example of an open set that's not closed is ... what? Not a homework question; I managed to stump myself. Thanks for your help.","['general-topology', 'descriptive-set-theory', 'examples-counterexamples']"
54875,Math notation for location of the maximum,My question is about notation. I have maximum of the function $f(x)$. This can be expressed as $\max(f)$ How can I express in compact form that $x_0$ is the location of that maximum.,"['notation', 'optimization', 'functions']"
54879,using trigonometric functions to adjust values to be from -1 to 1,"I have some code which is projecting 3D points onto a 2D surface based on the user's viewpoint. The top graph shows the actual points that I get from my code. The y values seem to be correct, but the x values are off. The blue x values in the top graph should be more like the bottom graph (stretching from 1 to -1). I need to somehow take the blue x and orange y values from the top graph and get the desired x values that you see in the bottom graph. I don't know much about curve fitting. Does anyone know any combination of trigonometric functions that I can apply to the top values to get the desired x values in the bottom graph? . EDIT:
To get the x and y values requires a full page of code which takes x y z of a point, x y z of the camera, azimuth pitch roll of the camera and somehow churns out an x,y coordinate which is appropriate for displaying the point on the screen. I was hoping that just knowing the values of X and Y relative to each other would be enough to allow us to unsqueeze the x line. If it helps, I've uploaded a CSV file containing the points used to make this graph at: http://g42.org/temp/projectionXY.csv Those points represent calculations starting at -45 degrees horizontal and -45 degrees vertical and then progressing along the horizontal by 5 degree increments until it reaches +45. It then increments the vertical by 5 degrees and starts again. In other words, the camera is pointed down 45 degrees and left 45 degrees and then is moved along a horizontal path until it reaches right 45 degrees and then goes up 5 degrees and repeats. For what it's worth, here's the actual code. double ax = obj.p().x();
double ay = obj.p().y();
double az = obj.p().z();
double cx = northPole.x();
double cy = northPole.y();
double cz = northPole.z();

double pi180 = Math.PI / 180;

{
    // Adjust ax, ay, az to bring the point into the frame of reference of the fixed camera
    double ax2, ay2, az2;

    // Rotate the point clockwise around the z-axis by its longitude
    ax2 = ax * Math.cos(cam.lon()*pi180) + ay * Math.sin(cam.lon()*pi180);
    ay2 = -ax * Math.sin(cam.lon()*pi180) + ay * Math.cos(cam.lon()*pi180);
    ax = ax2;
    ay = ay2;

    // Rotate around y-axis by minus (90 - latitude)
    ax2 = ax * Math.cos((90-cam.lat())*pi180) - az * Math.sin((90-cam.lat())*pi180);
    az2 = ax * Math.sin((90-cam.lat())*pi180) + az * Math.cos((90-cam.lat())*pi180);
    ax = ax2;
    az = az2;           
}

double cosOx = Math.cos(pitch*pi180);
double sinOx = Math.sin(pitch*pi180);
double cosOy = Math.cos(roll*pi180);
double sinOy = Math.sin(roll*pi180);
double cosOz = Math.cos(azimuth*pi180);
double sinOz = Math.sin(azimuth*pi180);

double p1 = sinOz * ay + cosOz * ax;
double p2 = cosOz * ay - sinOz * ax;

double dz = cosOx * (cosOy * az + sinOy * p1) - sinOx * p2;
double dx =         (             cosOy * p1) - sinOy * az;
double dy = sinOx * (cosOy * az + sinOy * p1) + cosOx * p2;

double bx = -dx/dz;
double by = dy/dz; In the above code, bx is the ""x"" on the graph image. by is the ""y"" on the graph image. The dz value is only used to determine if the value is in front of or behind the viewer. If it's positive then it's in front. Other than that I don't use its value for anything. EDIT 2:
I figured out the solution empirically. Since dy was being calculated correctly I just played around with manipulations that were similar to dy until I got a result for dx which looked correct. The end result is that the source code above would have the following two lines change: double dx = sinOx * (-sinOy * az + cosOy * p1) + sinOx * p2;
double bx = -dx/dz - 1.086087667; Ideally I'd like to understand why this works, but honestly I'm just thrilled that I've finally got the projection code working like it's supposed to. If anyone has an alternate way of expressing the above change which doesn't require the ugly -1.086087667 there, I'd love to see it.",['trigonometry']
54887,Can $A^2+B^2+C^2-2AB-2AC-2BC$ be a perfect square?,"I have come upon the trivariate polynomial $A^2+B^2+C^2-2AB-2AC-2BC$ and want to factor it.  Because of the symmetry, I am wondering if it can be a perfect square or if there is some other nice factorization.","['factoring', 'algebra-precalculus', 'multivariate-polynomial', 'polynomials']"
54891,Bulgarian Solitaire: Number of root loops and which numbers have multiple root loops,"For an explanation of what Bulgarian Solitaire is, look here . I have worked out the full graphs for $1 \leq \text{number of cards} \leq 13$ in the past, and all of them had just one root loop...except for $8$ cards. In that case, there are two root loops, one of which is $(4,2,2) \to (3,3,1,1)$ (which is also the entire subgraph for that loop). So, here we have a loop of size $2$ and a loop of size $4$. Unlike my previous question, I have no good intuition as to why this is the case. Which numbers have multiple root loops? How many do they have?","['card-games', 'number-theory']"
54902,How to find all groups that have exactly 3 subgroups?,"How to find all groups that have exactly 3 subgroups? Any group must have identity and itself as subgroups, so we just need to find all the groups that only have one proper subgroup. I think that for a prime $p$ the group $\mathbb Z/p^2\mathbb Z$ has only one proper subgroup (for example, $\mathbb Z/4\mathbb Z$, $\mathbb Z/9\mathbb Z$). Are there any other possibilities?","['cyclic-groups', 'group-theory', 'abstract-algebra']"
54910,A detail about MCT application,"I  have a indirect question about Monotone Class Theorem (MCT), in its functional form. Here is a version which should be sufficiently general for my purpose. Functional Monotone Class Theorem : Let H a collection of real valued and bounded functions such that: - H is a vector space - H contains constants - If $f_n$ is an increasing sequence of real and bounded functions of H, admitting a limit $f$ that is a bounded real valued function, then $f$ belongs to H. Now let K be another collection of real bounded functions which is stable by multiplication, and such that $K \subset H$. Conclusion : Then H contains all real bounded functions that belongs to $\sigma(K)$ (the sigma algebra generated by K). The statement here is clear but I have a question about applications of it. Usually the collection K is built by considering a collection P over real valued functions satisfying some propetry and intersecting it with the collections of bounded functions. Then using MCT with a nice space H, you have your conclusion for $\sigma(K)$. My question is the follwing is there a general way or sufficient conditions to see if $\sigma(K)=\sigma(P)$. There is a trivial inclusion so the question is better stated as under what conditions does $\sigma(P) \subset \sigma(K)$ holds ? The motivation behind this question comes from the fact that when I see MCT used in proofs of theorems, it is often the case that the theorem's conclusion is stated for the unbounded real valued functions collection P rather than K (P+the bounded property). Best Regards",['measure-theory']
54915,Is there general formula for the exponential of a tridiagonal matrix?,"For an arbitrary tridiagonal matrix of the form $$ A = \begin{pmatrix} b_1 & c_1 & 0 & 0 & ... \\ a_2 & b_2 & c_2 & 0 & ... \\ 0 & a_3 & b_3 & c_3 & ... \\ \vdots &&\ddots&\ddots&\ddots\end{pmatrix} $$ is there a formula to calculate $\exp(A)$? Or at least for some special tridiagonal matrices? The special case I am most interested in is a $(2n+1)^2$ matrix with $b_k = i(k-n-1)$ and $c_k = (a_{2n+2-k})^*$, i.e. $$\begin{pmatrix} -in & c_1 & 0 & \\ c_{2n}^* & -i(n-1) & c_2 & \\ 0 & c_{2n-1}^* & -i(n-2) & \ddots \\ &&\ddots&\ddots \end{pmatrix}$$","['matrices', 'exponentiation', 'matrix-exponential', 'tridiagonal-matrices']"
54926,Under what circumstance will a covariance matrix be positive semi-definite rather than positive definite?,"I have a covariance matrix: $\operatorname{cov}(\mathbf{X}, \mathbf{X}) = \operatorname{E}[(\mathbf{X} - \operatorname{E}[\mathbf{X}])(\mathbf{X} - \operatorname{E}[\mathbf{X}])^T]$ According to Wikipedia , it should be a positive semi-definite matrix. Under what circumstances will it be positive semi-definite rather than positive definite? The reason I am asking is because I see that a common thing to do when implementing an Unscented Kalman Filter is to implement the square-root of the covariance matrix using the matlab command: sqrt_P = gamma * chol(P_a, 'lower') where gamma is a scaling factor and P_a is the state covariance matrix. I understand that for chol() to work, it needs to be positive definite: >> help chol
 CHOL   Cholesky factorization.
    CHOL(A) uses only the diagonal and upper triangle of A.
    The lower triangle is assumed to be the (complex conjugate)
    transpose of the upper triangle.  If A is positive definite, then
    R = CHOL(A) produces an upper triangular R so that R'*R = A.
    If A is not positive definite, an error message is printed. So, what are the dangers in assuming that it isn't positive semi-definite? Will it only be semi-definite when (for example) it is the zero matrix, or when there are fully correlated states? ADDENDUM: In the original post, there was a reference to ""if the states are fully correlated"".  This was rather fast and loose with the notation.  There is a discussion and an answer on it here .","['probability-theory', 'matrices', 'statistics', 'positive-semidefinite']"
54930,Projecting onto the diagonal given Banach spaces with unconditional bases,"Let E be a Banach space with a 1-unconditional basis $(e_n)$ (for example, $\ell^p$).  Then an operator T on E can be thought of as an infinite matrix, in the obvious way.  Clearly each scalar on the diagonal of this matrix is bounded by $\|T\|$.  By the unconditionality, it follows that if I have any diagonal matrix with uniformly bounded entries, this will define a bounded operator.  So we conclude that the projection taking the matrix of T to the diagonal matrix given by setting all off-diagonal terms zero, is a contraction. This is absolutely well-known for $\ell^p$ spaces say, and must be well-known in this more general setting, though I don't know a reference. Now suppose we have two Banach spaces E and F, both with 1-unconditional bases.  We can still think of operators as given by infinite matrices.  Is this procedure of projecting down to the diagonal still bounded?  What's hard is that we cannot expect, in general, the diagonal to be isomorphic to $\ell^\infty$ anymore.  So we need an indirect argument.  I think I can do this in an adhoc way for maps between $\ell^p$ and $\ell^q$; does anyone know a more systematic treatment, or any references?","['functional-analysis', 'banach-spaces']"
54934,What is the standard deviation of multiple correlated random variables subtracted from another random variable?,Wiki states that standard deviation of $X-Y$ is: $$\sigma_{x-y} = \sqrt { \sigma_x^2 + \sigma_y^2 - 2\rho\sigma_x\sigma_y }$$ I have a number (say 3) correlated random variables to be subtracted from another correlated random variable. All random variables have identical correlation $\rho$. Can I subtract each one in turn like this: $$\sigma_{x-1} = \sqrt { \sigma_x^2 + \sigma_1^2 - 2\rho\sigma_x\sigma_1 }$$ $$\sigma_{x-2} = \sqrt { \sigma_{x-1}^2 + \sigma_2^2 - 2\rho\sigma_{x-1}\sigma_2 }$$ $$\sigma_{x-3} = \sqrt { \sigma_{x-2}^2 + \sigma_3^2 - 2\rho\sigma_{x-2}\sigma_3 }$$ The application is determining carrier-to-interference ratio of multiple co-channel interferers in an environment where it can be assumed that each interferer has identical correlated variation.,"['statistics', 'correlation']"
54943,One-to-one correspondence of ideals in the quotient also extends to prime ideals?,"I'm beginning to learn some Grothendieck's algebraic geometry and I have a doubt about a property of commutative algebra. For a comm. ring $A$ and an ideal $I$ of $A$, does the one-to-one correspondence between ideals of the quotient $A/I$ and ideals of $A$ containing $I$ extends to a correspondence of prime ideals ? My guess would be no, because I never learned it and couldn't find it on internet. However, where is the mistake in : Let $I \leq J \leq A$ be an ideal. We have $J$ prime iff $A/J \cong (A/I) / (J/I)$ integral domain iff $\bar{J} \leq A/I$ prime. Also can someone provide a counter example if this is not true ? Thanks !","['ideals', 'maximal-and-prime-ideals', 'abstract-algebra']"
54946,"I need explanation for this solution for the proof. (Perfect square ends with 0,1,4,5,6,9)","Give a proof to the sentence: ""The final decimal digit of a perfect square is 0, 1, 4, 5, 6 or 9."" Solution:
A integer $n$ can be expressed as $10a+b$, where $a$ and $b$ are positive integers and $b$ is 0, 1, 2, 3, 4, 5, 6, 7, 8, or 9.
Here $a$ is the integer obtained by subtracting the final decimal digit of $n$ and dividing by 10. (so $a=(n-b)/10$)
Next note that $(10a + b)^2 = 100a^2+20ab+b^2=10(10a^2+2b)+b^2$ so the final decimal digit of $n^2$ is same as the final decimal digit of $b^2$. I understand until this point but not below: Furthermore, note that the final decimal digit of $b^2$ is the same as final decimal digit of $(10-b)^2 = 100 - 20ab + b^2$. (how did you get this equation?) consequently we cab reduce our proof to the consideration of fix cases. final digit of: 1) $n$ is 1 or 9 is 1 2) $n$ is 2 o 8 is 4 3) $n$ is 3 or 7 is 9 4) $n$ is 4 or 6 is 6 5) $n$ is 5 is 5 6) $n$ is 0 is 0 THANKS!","['discrete-mathematics', 'intuition']"
54953,Looking for an accessible explanation of Henstock–Kurzweil (gauge) integral,"I'm not completely new to analysis, but I'm an engineer -- very applied, not very theoretical -- looking into self-studying pure mathematics. I've recently stumbled upon Henstock–Kurzweil integrals; many internet articles state that it's a very intuitive idea, but I simply can't wrap my head around its intuitive meaning as successfully as I can do it for the Riemann integral. The Wikipedia article seems to be pretty well-written, but I probably need a simpler stated approach/definition, because I'm only starting to get into all of these things. Can someone give me their own explanation of what the Henstock-Kurzweil is, or perhaps a good resource?","['integration', 'gauge-integral', 'reference-request', 'real-analysis', 'analysis']"
54961,The number of partitions of $n$ into distinct parts equals the number of partitions of $n$ into odd parts,"This seems to be a common result. I've been trying to follow the bijective proof of it, which can be found easily online, but the explanations go over my head. It would be wonderful if you could give me an understandable explanation of the proof and let me know how I'd go about finding such a bijection.","['integer-partitions', 'combinatorics', 'number-theory']"
54964,Explanation for the assumption of the proof,$(x+y)^r < x^r + y^r$ whenever $x$ and $y$ are positive real numbers and $r$ is a real number with $0 < r < 1$. In the solution it says it is safe to assume that $x+y=1$. I don't see any reason why this is the case... Why is it safe to assume $x+y=1$? If so how does this help proving this statement? Thanks!,"['inequality', 'discrete-mathematics']"
54973,Injective Holomorphic Functions that are not Conformal?,"Is it possible for a holomorphic function on a connected domain to be conformal but not injective? Also, is it possible for a holomorphic function to be injective but not conformal?",['complex-analysis']
54977,"Approximating by smooth functions on $W^{1,p}_\mathrm{loc}$?","I'm a little bit confused about different ways of approximating by smooth functions, in particular, quasiconformal mappings. So if a map $\phi : R\to R'$ is $K$-quasiconformal map on a relatively compact set $R$, it is true that $\phi \in W^{1,2}(R)$. And I know that $\phi$ can be approximated in $W^{1,2}(R)$ by smooth functions in $C^\infty(R)$, meaning that $ \lim_{n->\infty}||\phi_n - \phi||_{W^{1,2}(R)} = ((|| \phi_n - \phi ||_{2})^2 + || D\phi_n - D\phi ||_{2})^2)^{1/2} = 0 $ But it seems like it's possible to find smooth functions $\phi_n$ that actually 1) $\phi_n\to\phi$ (pointwise, or possibly uniform?) 2)$||D\phi_n -D\phi||_2 \to 0$. So my question is, how is this possible? (i.e. What theorem?) The sequence I get from the approximation theorem in $W^{k,p}$ guarantees 2), but not the first one. I think I get a.e. uniform or a.e. convergence at best... Note: I'm not entirely sure what convergence 1) is. I'm looking at a proof given by Ahlfors that shows that q.c. maps send null sets to null sets in his ""Lectures on Quasiconformal Mappings."" For the purpose of the proof, the a.e. convergence is enough, but Ahlfors doesn't say ""a.e.,"" so I'm wondering if I'm missing something... EDIT: Here's a word-by-word quote, as requested by Willie Wong ""
THEOREM 3. Under a q.c. mapping the image area is an absolutely continuous set function. This means that null sets are mapped on null sets, and that the image area can always be represented by $$A(E) = \int\int_E J \, dx \, dy$$ PROOF. $\phi = u+iv$ can be approximated by $C^2$ functions $u_n+iv_n$ in the sense that $u_n \to u$, $v_n \to v$ and $\int\int |u_x - (u_n)_x|^2 \, dx \, dy \to 0$ $\int\int |v_x - (v_n)_x|^2 \, dx \, dy \to 0$ etc. Consider rectangles $R$ such that $u$ and $v$ are absolutely continuous on all side....
""","['functional-analysis', 'real-analysis']"
54984,understanding of a proof of the invariance of 3-D laplacian?,"I learned the proof of the fact that 3-D laplacian is invariant under all rigid motions in space in Strauss's Partial Differential Equations : Any rotation in three dimensions is given by
  $${\bf x'}=B{\bf x},$$
  where $B$ is an orthogonal matrix. The laplacian is
  $$\Delta u=\sum_{i=1}^3 u_{ii}=\sum_{i,j=1}^3\delta_{ij}u_{ij}$$
  where the subscripts on $u$ denote partial derivatives. Therefore,
  $$
\Delta u=\sum_{k,l}\Big(\sum_{i,j}b_{ki}\delta_{ij}b_{lj}\Big)u_{k'l'}
=\sum_{k,l}\delta_{kl}u_{k'l'}
=\sum_{k}u_{k'k'}.
$$ Added :
I believe the chain rule is needs here, but I don't see how it is applied here. Here is my question : How can I get the first equality, i.e.
$$\Delta u=\sum_{k,l}\Big(\sum_{i,j}b_{ki}\delta_{ij}b_{lj}\Big)u_{k'l'}?$$","['multivariable-calculus', 'linear-algebra', 'partial-differential-equations']"
55000,Is it true that every positive integer is the sum of 18 fourth powers of integers?,"Is it true that every positive integer is the sum of $18$ fourth powers of integers? Does this means every positive integer $n = x_1^4+x_2^4+\cdots+x_n^4$ for some positive integer $n=18$? 
Could you show me some example, I don't think I am understanding the question..( ex:
Explanation says $78$ can be written as a sum of $18$ fourth powers of integers, how? Can $1$ or $5$ be written as sum of $18$ fourth powers of integers?) Thanks!","['discrete-mathematics', 'number-theory']"
55004,basic question--reasoning on alternating harmonic series,"Can someone please tell me where this line of reasoning goes wrong? False proof for the convergence of the alternating harmonic series: Break the series $S = 1 - 1/2 + 1/3 - 1/4 + \dots$ into the following ""subseries"": $S_1=1 - 1/2 - 1/4 - 1/8 - \dots$ $S_3=1/3 - 1/6 - 1/12 - 1/24 - \dots$ $S_5=1/5 - 1/10 - 1/20 - 1/40 - \dots$ $S_7=1/7 - 1/14 - 1/28 - 1/56 - \dots$ etc. First, it seems that no term from the original series occurs in more than one subseries. If a term did occur in more than one, then we would have $z \cdot 2^i= y \cdot 2^j$, where $z$ and $y$ are odd. So $z \cdot 2^{i-j}=y$, and the only way this can happen is if $i=j$ and $z=y$. Second, it seems that every term from the original series can be found in one of the subseries. Take any integer $k$ and decompose it into $k=(2^i) \cdot z$, where $z$ is odd. Then the $k$th term of the original series can be found in the $i+1$ term of $S_z$. Therefore $S=S_1 + S_3 + S_5 + S_7 + \dots$, and all the $S_i=0$, so $S=0$.","['sequences-and-series', 'calculus']"
55010,"Are ""Streamlines"" Anything Like Level Curves?","Streamlines are found in complex space, and represent constant values that are tangent to the outgoing velocity vector. Level curves are found in real (perhaps complex, as well?) space, and represent constant values of a multivariate function. Is there any connection between them in general? In particular cases?",['complex-analysis']
55015,Smooth structure on the topological space,"Consider a topological space $X$. Lee in Introduction to Smooth Manifolds wrote that it is impossible to introduce a smooth structure on the topological manifold based only on topology (i.e. preservable my homeomorphisms) since the square and the circle are homeomorphic, but the square we don't want to be smooth. Anyway, when introducing topological/smooth manifolds one makes a strict connection with $\mathbb R^n$. It seems that we extremely need this space to introduce the notion of smoothness on other spaces, am I right? Namely, can we formulate the smoothness without talking about $\mathbb R^n$ at all? If yes, what is necessary to have: finite dimension? metrics? topology?","['general-topology', 'manifolds', 'differential-topology']"
55018,Fast PCA: how to compute and use the covariance of x,"I'm trying to understand the paper Fast principal component analysis using
fixed-point algorithm by Alok Sharma and Kuldip K. Paliwal (1151–1155) , and
especially what is said about $\Sigma_x$, the covariance of x. But before being specific, let me summarize how I understand the algorithm. The PCA finds a linear transformation matrix $\varphi$ of size $d \times h$
which is meant to reduce a set of $n$ d-dimensional feature vectors $x$ ($x \in
\mathbb{R}^d$) to a set of $n$ h-dimensional feature vectors $y$ ($y \in
\mathbb{R}^h$), with $h < d$. So given one feature vector $x$, we have $\varphi x \rightarrow y$, or: $\pmatrix{
    a_{1,1} & a_{1,2} & \cdots & a_{1,h} \\
    a_{2,1} & a_{2,2} & \cdots & a_{2,h} \\
    \vdots  & \vdots  & \ddots & \vdots  \\
    a_{d,1} & a_{d,2} & \cdots & a_{d,h}
}\pmatrix{
    x_{1}  \\
    x_{2}  \\
    \vdots \\
    x_{d}
} \rightarrow \pmatrix{
    y_{1}  \\
    y_{2}  \\
    \vdots \\
    y_{h}
}$ And we want to define the matrix $\varphi$. Let me quote the algorithm (Table 1): Choose $h$, the number of principal axes or eigenvectors required to estimate. Compute covariance $\Sigma_x$ and set $p \leftarrow 1$ Initialize eigenvector $\varphi_p$ of size $d \times 1$ e.g. randomly Update $\varphi_p$ as $\varphi_p \leftarrow \Sigma_x \varphi_p$ Do the Gram-Schmidt orthogonalization process [...] Normalize $\varphi_p$ by dividing it by its norm: $\varphi_p \leftarrow \varphi_p/||\varphi_p||$ If $\varphi_p$ has not converged, go back to step 3 Increment counter $p \leftarrow p + 1$ and go to step 2 until $p$ equals $h$ So basically, the orthogonalization process and the normalization are pretty
straightforward and simple to implement, same for the convergence.
Unfortunately, I'm having hard time trying to figure out the first steps: How am I supposed to compute the covariance $\Sigma_x$ given that $x$ is one
of the feature vector of the input? (BTW, is the described algorithm actually
only explaining the definition of $\Sigma$ for one single features vector of the
$n$ input vectors?) I was unable to understand how to apply the definition of the covariance
matrix to that case; is it possible to have a simple example of what it
takes in input, and what gets out? Now suppose I am able to compute the covariance $\Sigma_x$, what does step 2 and
3 means? $\varphi_p$ is supposed to be one column of the $d \times h$ matrix
$\varphi$, so what does the random initialization of $\varphi_p$ means and how to apply the transformation $\varphi_p \leftarrow \Sigma_x\varphi_p$ using
the previously computed covariance?","['matrices', 'linear-algebra', 'principal-component-analysis']"
55037,"Weierstrass M-test, and $\sum_{n=1}^\infty e^{-nx}x^n$","How can I use the Weierstrass M-test to show uniform convergence of $\sum_{n=1}^\infty e^{-nx}x^n$ on $[0,\infty )$? I can't find any bounding sequences. I've tried to analyse the convergence on a smaller interval, but this didn't turn out too.","['sequences-and-series', 'calculus', 'real-analysis']"
55052,Bounds on roots of polynomials,"What bound is there on the roots of a given polynomial, in terms of its degree and coefficients? Consider the polynomial $p(x) = 3x^7 – 5x^3 + 42$. Would you not agree, without doing any calculation, that one million ($10^6$) cannot be a root? It just wouldn’t be in accord with the smallness of the coefficients and the well-behavedness of polynomials. And yet I don’t recall ever having encountered anything in the literature that gave a bound on the absolute value of the roots of a polynomial in terms of the degree and coefficients of the polynomial, but I’m pretty sure such must exist, and that I simply missed it, and so I’m tagging this a a reference-request. By the way, during my post of a question, every time, it seems, there are stray graphics on the screen, as if from someone else's question or answer. Is this happening to anyone else?","['calculus', 'reference-request']"
55064,which is the best distance function?,"We all know there are distance functions, like Kullback Leibler distance , Bhattacharyya measure , Euclidean distance, Wasserstein distance, and so on.
Take a sample distance: $D=\sum\limits_n\left|P_n\left(\text{model}\right)-P_n\left(\text{sample}\right)\right|$. Specifically, if we have a model distribution (probability density function)$P\left(\text{model}\right)=[0.2,0.8]$, $n=2$, we want to calculate the distance between every sample distribution and this model distribution. If sample distribution is $P\left(\text{sample}1\right)=[0.3,0.7]$. Then $D=\left|0.3-0.2\right|+\left|0.7-0.8\right|=0.2$. But I do not think it is a good distance measure since I think $0.8$ and $0.7$ are more similar than $0.2$ and  $0.3$. What I mean is in model distribution, one component is 0.8, another is 0.2, same difference $a$ has more influence in 0.2 since 0.8 is quite big than 0.2. So the weight of components are different. How should I incorporate weight into distance equation? I try to make a equation , like $D=\sum\limits_n\frac{\left|P_n\left(\text{model}\right)-P_n\left(\text{sample}\right)\right|}{P_n\left(\text{model}\right)}$, But it seems to be  wrong.","['probability-distributions', 'discrete-mathematics']"
55065,who first defined a tangent to a circle as a line meeting it only once?,"From googling, it seems commonly believed that Euclid did this, but it seems nowhere in Euclid does he even state this property of a tangent line explicitly.  Rather Euclid gives 4 other equivalent properties,  that the line does not cross the circle, that it is perpendicular to the radius, that is a limit of secant lines, and that it makes an angle of zero with the circle, the first of which is his definition, the others being in Proposition III.16.  I am wondering where the ""meets only once"" definition got started.  I presume once it got going, and people stopped reading Euclid, (which seems to have occurred over 100 years ago), the currently popular definition took over.  Perhaps I should consult Legendre or Hadamard?  Thank you for any leads. Well I have found this definition in Hadamard's lessons in plane geometry.  Any earlier references? I have also found another equivalent characterization of a tangent by Euclid, Prop. (III.36-37):  A segment PX, from a point P outside a circle and meeting the circle at X, is tangent to the circle at X if and only if there exists another segment PB, meeting the circle first at A and then at B, such that (PA)(PB) = (PX)^2, [in terms either of equality squares of lengths of segments, or of equality of area of rectangles].","['geometry', 'math-history']"
55096,non time constructible functions [duplicate],"This question already has an answer here : Definition of time-constructible function (1 answer) Closed 2 years ago . A function $T: \mathbb N  \rightarrow \mathbb N$ is time
  constructible if $T(n) \geq n$    and there is a $TM$  $M$ that computes
  the function $x \mapsto \llcorner T(\vert x\vert) \lrcorner$ in time $T(n)$. ($\llcorner T(\vert x\vert) \lrcorner$ denotes the binary representation of
  the number $T(\vert x\vert)$.) Examples for time-constructible
  functions are $n$, $nlogn$, $n^2$, $2^n$. Time bounds that are not
  time constructible can lead to anomalous results. --Arora, Barak. This is the definition of time-constructible functions in Computational Complexity - A Modern Approach by Sanjeev Arora and Boaz Barak . It is hard to find valid examples of non-time-constructible functions. $f(n)=c$ is an example of a non-time-constructible function. What more (sophisticated) examples are out there?","['examples-counterexamples', 'algorithms', 'functions', 'computer-science', 'analysis-of-algorithms']"
55097,Finiteness of conditional expectation if expectation is finite,"I have $E(X) < \infty$. Under which conditions follows that $E(X|A)<\infty$ ? (A is an event of the form {$Y=y$} if it should matter) If I can use the formula $E(X|A)=\frac{E(X 1_A)}{P(A)}$ ($1_A$ the indicator function of the set A) then it would follow at least for $P(A)\neq0$, but I am not sure if this formula is applyable as I am working with the general definition (A random variable Y is called conditional expectation value and we write $Y=E(X|\mathcal{A})$ if Y is $\mathcal{A}$-measurable and for all $A \in \mathcal{A}$: $E(X1_A)=E(Y1_A)$. How can I assert that $E(X|A) <\infty$? (Or if my way seems valid, how can I deduce the formula from the general definition?)","['probability-theory', 'measure-theory']"
55107,Are simply connected open sets in $\mathbb{R}^2$ homeomorphic to an open ball?,Let $U$ be a simply connected open set in $\mathbb{R}^2$. Is it true that $U$ is homeomorphic to an open ball?,['general-topology']
55114,Are contractible open sets in $\mathbb{R}^n$ homeomorphic to $\mathbb R^n$?,Is it true that every contractible open subset of $\mathbb{R}^n$ is homeomorphic to $\mathbb{R}^n$?,['general-topology']
55117,Smoothness of harmonic functions,In the book on PDEs I'm reading there is a section on harmonic functions. To prove that these functions are in the class $C^\infty$ the author use standard mollifiers which I am not comfortable with. If there another proof of the $C^\infty(U)$ for the functions $u$ such that $\Delta u = 0$ on $U$?,"['partial-differential-equations', 'real-analysis']"
55119,On the equation $3x^3 + 4y^3 + 5z^3 = 0$,How can I show that the equation $$3x^3 + 4y^3 + 5z^3 = 0$$ has nonzero solutions modulo every integer but not in $\mathbb{Z}$?,"['diophantine-equations', 'number-theory']"
55120,Showing $\tan\frac{2\pi}{13}\tan\frac{5\pi}{13}\tan\frac{6\pi}{13}=\sqrt{65+18\sqrt{13}}$,"How can one show :
$$\tan\frac{2\pi}{13}\tan\frac{5\pi}{13}\tan\frac{6\pi}{13}=\sqrt{65+18\sqrt{13}}?$$","['radicals', 'trigonometry', 'polynomials']"
55136,General questions about level sets of polynomials of two variables,"Sorry if I'm being too general here, but here it goes.  I'm trying to find out more about levels sets of polynomials of two variables of degree $d$ $$ C = \{ (x,y) \ :  \sum_{1 \leq i + j \leq d} c_{i,j} x^i y^j = 1 \} $$ In particular, I want a feeling of what these curves ""look like"" for low $d$ ($d = 3,4,5...$), and also what kind of things can be computed ""exactly"" (probably need special functions),  for instance: When is $C$ made up of closed curve(s)? When is $C$ connected? What is the arc length of $C$? What is the curvature of $C$? Any tips, or paper references would be helpful too,  thanks!!","['algebraic-geometry', 'polynomials']"
55137,Is this a Delta Function? (and Delta as limit of Gaussian?),"I have a set of users that generate calls.  If I assign the same probability to each user, they have identical call generation probability which can be defined as $\delta$. These callers are chosen uniformly among the set of users. At the end of the generation process, the representation of the probability density function of the call rates should be a delta function (hence the shape is similar to a bell, isn't it?) The probability i assigned to each user is: 
$$p_u = \frac{\lambda}{\sum_{i \in N_u} \lambda}$$ where $\lambda = \frac{1}{N_u}$ and $N_u$ is the number of users. In this way they are equally partitioned between 0 and 1 and i can take a random number uniformly distributed in order to select a random user. My question is how can i demonstrate that this is really a Delta function? The information i wrote are enough to defined the Delta function (i don't know if it is possible to formalize the p.d.f.)? For example in figure we have 10000 that has the same generation probability: if I generate ca.  605000 calls the average is ca. 60.5 calls per user","['probability-theory', 'probability-distributions', 'probability']"
55138,Is a bijective local homeomorphism a global homeomorphism. What about diffeomorphisms?,"Is a bijective local homeomorphism a global homeomorphism? What about diffeomorphisms? I don't know if it's true this property, I'm not sure. If someone can prove it I would be very grateful, and if not I would welcome a counterexample because I can not think. Thank you very much. At worst, if not true, someone knows a sufficient condition to fulfill what I want? Thank you very much!","['general-topology', 'differential-geometry']"
55147,"Chord dividing circle , function","Two chords $PA$ and $PB$ divide circle into three parts. The angle $PAB$ is a root of $f(x)=0$. Find $f(x)$. Clearly , $PA$ and $PB$ divides circle into three parts means it divides it into $3$ parts of equal areas How can i find $f(x)$ then ? thanks","['geometry', 'roots', 'circles', 'functions']"
55152,Local minimum and maximum of the function,"Can anyone help me to solve the following question?
maximize and minimize the function $(10-x)(10-\sqrt{9^2-x^2})$ over $x\in[0,10]$
This is a high school question, so is there any simple trick help solve it? Thanks!","['optimization', 'algebra-precalculus']"
55154,References about the symmetric products of a stack,"I would like to know references about a construction of the symmetric product (or the moduli space of effective divisors) $X^{(d)}$ of a stack $X$. I am currently thinking about the following case: $X$ is a proper complex Deligne-Mumford stack. This means that the stack $X$ can be represented as a proper complex étale groupoid $Z_1 \rightrightarrows Z_0$ of complex dimension $1$. Because I think that the construction of the symmetric spaces of a stack might be elementary for algebraic geometers, I am looking for a construction of the symmetric spaces of the stack $X$. But I have not found any references yet. Similar settings are welcome.","['algebraic-geometry', 'reference-request']"
55165,Eigenvalues of the rank one matrix $uv^T$,"Suppose $A=uv^T$ where $u$ and $v$ are non-zero column vectors in ${\mathbb R}^n$, $n\geq 3$. $\lambda=0$ is an eigenvalue of $A$ since $A$ is not of full rank. $\lambda=v^Tu$ is also an eigenvalue of $A$ since
$$Au = (uv^T)u=u(v^Tu)=(v^Tu)u.$$ 
Here is my question: Are there any other eigenvalues of $A$? Added: Thanks to Didier's comment and anon's answer, $A$ can not have other eigenvalues than $0$ and $v^Tu$. I would like to update the question: Can $A$ be diagonalizable?","['eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'rank-1-matrices', 'diagonalization']"
55170,Is it possible for a function to be in $L^p$ for only one $p$?,"I'm wondering if it's possible for a function to be an $L^p$ space for only one value of $p \in [1,\infty)$ (on either a bounded domain or an unbounded domain). One can use interpolation to show that if a function is in two $L^p$ spaces, (e.g. $p_1$ and $p_2$,with $p_1 \leq p_2$ then it is in all $p_1\leq p \leq p_2$). Moreover, if we're on a bounded domain, we also have the relatively standard result that if $f \in L^{p_1}$ for some $p_1 \in [1,\infty)$, then it is in $L^p$ for every $p\leq p_1$ (which can be shown using Hölder's inequality). Thus, I think that the question can be reduced to unbounded domains if we consider the question for any $p>1$. Intuitively, a function on an unbounded domain is inside an $L^p$ space if it decrease quickly enough toward infinity. This makes it seem like we might be able to multiply the function by a slightly larger exponent. At the same time, doing this might cause the function to blow up near zero. That's not precise/rigorous at all though. So I'm wondering if it is possible to either construct an example or prove that this can't be true.","['examples-counterexamples', 'banach-spaces', 'measure-theory', 'real-analysis', 'functional-analysis']"
55181,countably infinite union of countably infinite sets is countable,"How do you prove that any collection of sets $\{X_n : n \in \mathbb{N}\}$ such that for every $n \in \mathbb{N}$ the set $X_n$ is equinumerous to the set of natural numbers, then the union of all these sets, $\bigcup_{i\in \mathbb{N}}$ $X_i$ is also equinumerous to the set of natural numbers? (By equinumerous I mean there exists a one-to-one and onto function $f:X_n \to \mathbb{N}$ .) Is this statement false as it stands?",['elementary-set-theory']
55190,Inner product and dot product,"If I am correct dot product is an example of inner product on coordinate space. I wonder if for an arbitrary inner product space with base field being $\mathbb{R}$ or $\mathbb{C}$, there always exists a coordinate system so that the inner product becomes the dot product in coordinate? What is the name of the topic regarding this question? Thanks and regards!","['linear-algebra', 'inner-products']"
55192,"What if the only eigenvectors of $A$ are multiples of $x=(1,0,0)^T$?","The question is from an exercise in Gilbert Strang's Linear Algebra and its Applications : Suppose the only eigenvectors of $A$ are multiples of $x=(1,0,0)$. True or false: (a) $A$ is not invertible. (b) $A$ has a repeated eigenvalue. (c) $A$ is not diagonalizable. (b) has to be true. Since if $A$ has different eigenvalues, then there will be linear independent eigenvectors. One example that I can come up with for which (a) and (c) are true is 
$$A=\left(
  \begin{array}{ccc}
     0&  1& 0 \\
     0& 0 & 1 \\
     0& 0 & 0 \\
  \end{array}
\right)$$ Here are my questions: Are there any counterexamples for (a) and (c)? What's the underlying picture of this problem?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
55196,Improper integral of piece-wise rational function,"I am looking to evaluate the following improper-integral $$ \int\nolimits_0^\infty \left( \frac{1}{ 1 + x^\alpha \vert v-1 \vert^\alpha} - \frac{1}{ 1 + x^\alpha \vert v+1 \vert^\alpha} \right) \frac{ d v}{v} $$ for some positive value of $x$ and $\alpha = 3$ in view of being able to generalize this to odd integers $\alpha = 2 n-1$. The answer for $\alpha=3$ is known to be $$ \frac{2 x^3 \log(1/x)}{1-x^6} + \frac{\pi x s_3}{ (x-c_3)^2 + s_3^2} + \frac{\pi x s_3}{ (x+c_3)^2 + s_3^2} $$ where $s_3 = \sin\left(\pi/3\right)$ and $c_3 = \cos\left(\pi/3\right)$. I am not able to reproduce this, and would appreciate help. Thank you","['improper-integrals', 'calculus', 'integration']"
55204,What are the cases of not using  (countable) induction?,"In countably infinite union of countably infinite sets is countable the proof has been given, but when as a student I attempted the question, I tried using induction ( later to found it to be wrong way of going about that problem) but the reasoning was quite simple. I.Union of 1,2 countable set is counatble ( obvious ) II.Suppose I is true up some n. III.For case n+1 we get union of all the sets up to n, which was true by II , so we get back to case of union of two countable sets which is true. I couldn't see any flows with the above, but it was wrong, I think it was due to the fact that proving something holds for all finite n, is not the same as proving it for the infinite case. My question is, why proving something for all finite n ( after all any nu,ber that can be picked is finite), is not same as proving the infinite case ? Is there any other example induction failing for infinite clause? Another question is : Is uncountable ( infinite of course :) union of countable ( finite or infinite) is countable? (The wrong induction method I used can't even be used for this one.) Thank you PS : Modified the title as it was sugeestive of induction failing, where is the case is it is being misused.","['logic', 'induction', 'elementary-set-theory']"
55253,A question in complex analysis about analytic function,"It's an exercise in the book complex analysis of Ahlfors,but I can't work it out.Can somebody give me some hints please.
Suppose that $f(z)$ is analytic and satisfies the condition$\left | f(z)^{2}-1 \right | <1$ in a region $\Omega$. Show that either $Ref(z)>0$ or $Ref(z)<0$ through-out $\Omega$.
Thank you.",['complex-analysis']
55258,Does every Poisson bracket on a commutative algebra come from a second-order deformation?,"Let $A$ be a commutative algebra over a field $k$ (of characteristic not equal to $2$ to be safe). Recall that $f : A \otimes A \to A$ is a Hochschild $2$-cocycle if it satisfies $$f(ab, c) + f(a, b) c = f(a, bc) + a f(b, c)$$ and recall that $\{ -, - \} : A \otimes A \to A$ is a Poisson bracket if it is a Lie bracket such that $\{ a, bc \} = \{ a, b \} c + b \{ a, c \}.$ Until recently I was pretty sure that if $f$ is a $2$-cocycle, then $f(a, b) - f(b, a)$ is a Poisson bracket (which only depends on the image of $f$ in $H^2(A, A)$). I can prove that $f(a, b) - f(b, a)$ is alternating and satisfies the Leibniz rule, but I can't prove the Jacobi identity and now I'm no longer sure it holds in general, although I don't know how to construct a counterexample. What's a counterexample to this statement? The correct statement seems to be that $f(a, b) - f(b, a)$ satisfies the Jacobi identity if the first-order deformation of $A$ $$a \star b = ab + \epsilon f(a, b)$$ defined by $f$ extends to a second-order deformation. Is this condition necessary? That is, Does every Poisson bracket on $A$ extend to a second-order deformation? I recall that there is a nice way of checking whether $f$ extends in this way involving $H^3(A, A)$, but I don't remember where I saw it or what it was. (Edit: it can be found in Gerstenhaber's original paper on the subject. I think the answer to the question ought to be ""no,"" but I don't know an explicit counterexample.) Also, is there a nice name for an alternating bilinear map on an algebra that satisfies the Leibniz rule but not the Jacobi identity? An alternating biderivation? A quasi-Poisson bracket?","['homology-cohomology', 'deformation-theory', 'abstract-algebra']"
55259,Did Zariski really define the Zariski topology on the prime spectrum of a ring?,"The question is not : “Did Zariski really define the Zariski topology?” It is:  “Did Zariski really define the Zariski topology on the prime spectrum of a ring ?” Here is the motivation. --- On page 80 of Grothendieck, Alexander, Éléments de géométrie algébrique (rédigés avec la collaboration de Jean Dieudonné) : I. Le langage des schémas . Publications Mathématiques de l'IHÉS , 4 (1960), p. 5-228, availablable here , one reads: L'introduction de cette topologie en géométrie algébrique est due à Zariski. Aussi est-elle souvent appelée la « topologie de Zariski » de $X$ . The introduction of this topology in algebraic geometry is due to Zariski. This is why it is often called the  “Zariski topology“ of $X$ . The set $X$ is of course the prime spectrum of a ring. EDIT. Theo Buehler has just posted a question inspired by Qiaochu's answer below. The title of Theo’s question is: Was Grothendieck familiar with Stone's work on Boolean algebras?","['commutative-algebra', 'algebraic-geometry', 'math-history', 'reference-request']"
55262,The automorphism group of a direct product of abelian groups is isomorphic to a matrix group,"Let $G=G_1 \times G_2 \times \cdots \times G_n$ where $G_i$ are abelian groups. Prove that Aut$G$ is isomorphic with the group of all invertible $n \times n$ matrices whose $(i,j)$ entries belong to Hom$(G_i,G_j)$, the usual matrix product being the group operation. Given the structure of abelian groups, it can be supposed that every $G_i$ is cyclic, infinite or of prime power order. As $G_i$ and $G_j$ are cyclic, it is not hard to determine the homomorphism group between the two. But how to combine all the homomorphism groups together to get a matrix group? Moreover, let $\phi = (\phi_{ij})_{n \times n}$ be an automorphism of $G$, why is its inverse $\phi' = \phi^{-1}$ also of the form $(\phi'_{ij})_{n \times n}$. What's the relation between $\phi_{ij}$ and $\phi'_{ij}$? I am trapped in this problem and I appreciate your help. Many thanks.",['group-theory']
55265,Convergence of variance and mean of weighted sums of random variables,"Let $c_n$ be a sequence of positive real numbers such that
$$\sum^{\infty}_{n=1}{c_n} = \infty, \qquad \sum^{\infty}_{n=1}{c_n^2} < \infty.$$
Let $X_n$ be a family of i.i.d random variables with $\mathbb{E}(X_n) = 0$ and $\sigma^2(X_n) = 1$ for each $n$, and define the random variable
$$X = \sum^{\infty}_{n=1}{c_n X_n}.$$
Is it true that
$$\mathbb{E}(X) = \sum^{\infty}_{n=1}{\mathbb{E}(c_n X_n)} = 0$$
and
$$\sigma^2(X) = \sum^{\infty}_{n=1}{\sigma^2(c_n X_n)} = \sum^{\infty}_{n=1}{c_n^2}?$$
If so, how does one prove this (and where is a source, if possible)? If not, what counterexamples exist?",['probability-theory']
55274,Ratio of angle divided by a line drawn in triangle?,If a line drawn from one point of a triangle divides opposite side in ratio $1:2$ then in what ratio angle is divided by line?,"['geometry', 'triangles']"
55277,An obscure explanation in Conway's Complex analysis,"I don't understand a paragraph in Conway's complex analysis at the beginning of Chapter VI page 128 (Maximum Modulus Theorem). He says: ""Note that in Theorem 1.2 we did not assume that $G$ is connected as in Theorem 1.1. Do you understand how Theorem 1.1 puts the finishing touches on the proof of Theorem 1.2? Or could the assumption of connectedness in Theorem 1.1 be dropped?"" For reference I included both theorems here:
1.1 Maximum Modulus Theorem, First Version. If $f$ is analytic in a region $G$ and $a$ is a point in $G$ with $|f(a)| \geq |f(z)|$ for all $z$ in $G$, then $f$ must be constant.
(it is proved with the open mapping theorem). 1.2 Maximum Modulus Theorem, Second Version. Let $G$ be a bounded open set in $\mathbb{C}$ and suppose $f$ is continuous on the closure of $G$ and analytic in $G$. Then the maximum is attained on $\partial G$. I was thinking that I understood the maximum modulus but since I can understand Conway's little paragraph I must be missing something important. If someone has the book, thanks for any help.",['complex-analysis']
