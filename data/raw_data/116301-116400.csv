question_id,title,body,tags
1710682,What's the higher dimensional generalization of arc length?,"Given a scalar field $f: \mathbb R^n \supseteq V \to S \subseteq \mathbb R, \vec x\mapsto f(\vec x)$, what is the $n$ dimensional hypersurface (or volume, however you want to call this submanifold of $S\times V$) of $\{(y,\vec x) \in S\times V \big|\ y=f(\vec x)\}$? The case $n=1$ leading to the arc-length of $f:[a,b]\to\mathbb R$, $\int_a^b\sqrt{1+|f'(x)|^2}\,dx$ is well-known, but what about $n>1$?","['surfaces', 'real-analysis', 'arc-length', 'analysis']"
1710730,Derivative is an alternating 1-tensor?,"I am reading through spivak, and he states, if $f: \mathbb{R^n} \to \mathbb{R}$ is differentiable, then $Df(p): \mathbb{R^n} \to \mathbb{R}$, and since this is linear, we have that $Df(p) \in \Lambda^1(\mathbb{R^n})$. I don't follow this exactly, I know that since it is linear, $Df(p) \in \mathcal{J}^1(\mathbb{R^n})$, but I don't see how it is alternating.","['multivariable-calculus', 'real-analysis', 'calculus', 'exterior-algebra']"
1710745,"Why is the direction of propagation of $y = \sin(kx - \omega t) \quad \omega , k \gt 0$ toward $+X$ axis?","I'm not sure if this question should be in Physics or here in Mathematics. Forgive me if it doesn't belong here. My book says that the wave $y = \sin(kx -\omega t)$ travels in $+X$ direction. I tried deriving the speed of propagation, and I am getting the direction to be towards $-X$ We have, $$\frac{\partial y}{\partial t} = -\omega \cos(kx - \omega t)$$ Also, $$\frac{\partial y}{\partial x} = k \cos(kx - \omega t)$$ Dividing, $$\frac{\partial x}{\partial t} = - \frac \omega k $$ This is speed of propagation of wave. Now I'm not sure if partial derivative of $x$ with $t$ gives speed of wave or not, but since the magnitude of speed is coming out to be $\frac \omega k$ which is the actual speed of a wave, I must be close. The Problem From my derivation, I get the speed of wave $= - \frac \omega k $, which means wave is travelling in $-X$ direction. My book says that the wave $y = \sin(kx - \omega t)$ travels in $+X$ direction with a speed of $\frac \omega k$. The wave $y = \sin(kx + \omega t)$ travels in $-X$ direction, which according to my calculation should go in $+X$ Why do I get the direction to be opposite? The magnitude of speed from my calculation is correct, but direction is coming out to be opposite.","['multivariable-calculus', 'wave-equation', 'derivatives']"
1710767,Spectrum of irrational number (exercise 3.13),"I'm trying to come up with a solution for exercise 3.13 from Concrete math. The exercise asks to prove that $Spec(\alpha)$ and $Spec(\beta)$ partition positive integers if and only if $\alpha$ and $\beta$ are irrational and $$1/\alpha + 1/\beta = 1$$ This mean that if condition is true, than following should hold: $$
\lfloor{n \alpha}\rfloor \neq \lfloor{m \frac{\alpha}{\alpha - 1}\rfloor},\quad \mid n, m \in \mathbb{N}
$$ for the case when $\alpha > 2$. This means that there exist no such combination of $m$ and $n$, such that previous condition is true. Let's replace floor functions with sums: $$
\sum_i [ i < n \alpha ] \neq \sum_i [i < m \frac{\alpha}{\alpha - 1}]
$$ Consider the case when $n\alpha > m \frac{\alpha}{\alpha - 1}$. Then left sum can be split as follows: $$
\sum_i [ i < n \alpha ] = \sum_i [i < m \frac{\alpha}{\alpha - 1}] + \sum_i [  m \frac{\alpha}{\alpha - 1} \leq i < n \alpha ]
$$ A sum with $m$ cancels out in each side of inequality, and the result is: $$
\sum_i [  m \frac{\alpha}{\alpha - 1} \leq i < n \alpha ] \neq 0
$$ In other words there exist no such combination of $n$ and $m$ such that the last sum is equal to 0. And I'm in stuck in here, because I do not see why. And if there exist such combination, then the same number can pop up in the spectra of $\alpha$ and $\beta$. I would appreciate, if you either explain me why the last sum can't be 0, or if you show me a mistake in my reasoning.","['integers', 'discrete-mathematics']"
1710770,Complex substitution allowed but changes result,"It is well known that
$$ I := \int_L \frac{1}{z} ~\text{d}z = 2 \pi i $$
where $L$ is the complex unit circle, parametrized by $\gamma(t) = e^{it}, 0 \leq t \leq 2 \pi$. However, using complex substitution, I obtain the following: by definition op complex line integrals, we have
$$ I = \int_{t = 0}^{t = 2\pi} \frac{1}{e^{it}} \cdot i e^{it} ~\text{d}t $$
Since $e^{it}$ is complex differentiable everywhere, and since $1/z$ is complex differentiable on the entire complex unit circle $L$, we can use complex substitution: $u = e^{it}$ and $\text{d}u = i e^{it} ~\text{d}t$, hence
$$ I = \int_{u = 1}^{u = 1} \frac{1}{u} ~\text{d}u = 0 $$
since the integral is from 1 to 1. Obviously, something went wrong. My teacher said that it was because both $1/z$ was not defined on the whole interior of $L$ (since $z = 0$ causes trouble) and because it's ""anti-derivative"" Log$(z)$ is not continuous on $L$ (it's not continuous on the negative real axis). If either $1/z$ was defined on the whole interior of $L$ or Log$(z)$ was continuous on $L$ itself, then the above would be true. For example,
$$ \int_L z^2 ~\text{d}z = 0 $$ However, if you are just given
$$ \int_{t = 0}^{t = 2\pi} \frac{1}{e^{it}} \cdot i e^{it} ~\text{d}t $$
Then you have no idea that this integral comes from some line integral over some line $L$. So my question is, what conditions have to be met in order to apply the equality
$$ \int_{t = a}^{t = b} f(\gamma(t)) \cdot \gamma'(t) ~\text{d}t = \int_{t = \gamma(a)}^{t = \gamma(b)} f(t) ~\text{d}t $$
for $\gamma : [a, b] \to M$, $f : D \to \mathbb{C}$ such that $M \subset D$, and why can't I write
$$ I = \int_{t = 0}^{t = 2\pi} \frac{1}{e^{it}} \cdot i e^{it} ~\text{d}t = \int_{u = 1}^{u = 1} \frac{1}{u} ~\text{d}u $$ My book on Complex Analysis simply says that $\gamma$ needs to be complex differentiable on $[a, b]$ (and $e^{it}$ is complex differentiable on $[0, 2 \pi]$) and that $f$ needs to be continuous on $M$ (and $1/z$ is continuous on $L$, the image of $e^{it}$). Either my book is wrong, or (most likely) I'm missing something.","['derivatives', 'line-integrals', 'substitution', 'continuity', 'complex-analysis']"
1710786,Why does L'Hopital's rule fail in calculating $\lim_{x \to \infty} \frac{x}{x+\sin(x)}$?,"$$\lim_{x \to \infty} \frac{x}{x+\sin(x)}$$ This is of the indeterminate form of type $\frac{\infty}{\infty}$, so we can apply l'Hopital's rule: $$\lim_{x\to\infty}\frac{x}{x+\sin(x)}=\lim_{x\to\infty}\frac{(x)'}{(x+\sin(x))'}=\lim_{x\to\infty}\frac{1}{1+\cos(x)}$$ This limit doesn't exist, but the initial limit clearly approaches $1$. Where am I wrong?","['calculus', 'limits']"
1710791,Describe all ring homomorphisms from $\mathbb{R}[T] \rightarrow \mathbb{R}[T]$,"One of the problems in a problem set I was given as homework in my Algebra course proposes the next problem: Describe all ring homomorphisms $\mathbb{R}[T] \rightarrow \mathbb{R}[T]$. Which of them are isomorphisms? I would like some suggestions towards the right direction, not the answer to the problem. This is what I've got so far: Given a ring homomorphism $f:\mathbb{R}[T] \rightarrow \mathbb{R}[T]$: Given an arbitrary polinomial $p(T) = a_{0} + a_{1}T + \ldots + a_nT^n$ we have that $f(p) = f(a_0) + f(a_1)f(T) + \ldots + f(a_n)f(T)^n$. So we get that $f$ is completely determined by the values it assumes on $\mathbb{R}$ and $f(T)$. So this problem may now be separated in two: Classifying all homomorphisms of the form $f:\mathbb{R} \rightarrow \mathbb{R}[T]$ Classifying all possible values $f(T)$ With respect to (1): Conjecture The only ring homomorphism is $f(x)=x$ (we put as a condition that f(1) = 1, on the definition the professor gave us, so that discards $f(x)=0$) I've shown by induction that $f(n) = n, ~\forall n\in\mathbb{N}$, then $f(m) = m, ~\forall m\in \mathbb{Z}$, then $f(q) = q, ~\forall q\in \mathbb{Q}$ but I
am having problems showing that $f(\alpha) = \alpha, ~\forall \alpha \in \mathbb{Q}'$ because I don't really know if $f(\alpha) \in \mathbb{R}$. If I knew that $f(\mathbb{R}) \subset \mathbb{R}$ then I could do something like $f(\alpha) = f(\sqrt{\alpha})^2 > 0$ if $\alpha > 0$. And this would help me prove that $f(\beta) = \beta$ for all irrationals too. The only problem is that, what happens if say, $f(\alpha) = T$. Then $>$ would make no sense. I think I solved this problem but I am not sure, maybe here is where you guys can help me a little. If we suppose that $f(\alpha)$ is a polynomial with degree $n$, we can then compute $f(\alpha^\frac{1}{n+1}) = f(\alpha)^\frac{1}{n+1}$ and that would be in $\mathbb{R}[T]$ only if the degree, $n$, of $f(\alpha)$ were $0$ thus proving that indeed $f(\alpha) \in \mathbb{R}$. Is there any mistake or an easier way? Or is there any usefull comment anyone wants to make that could help me out. Thanks in advance :)","['abstract-algebra', 'ring-theory', 'polynomials']"
1710799,Find the sum of the areas of regions $X$ and $Y$,"Right triangle $ABC$ is inscribed in a circle with $AC = 6$, $BC = 8$ and $AB=10$. $AC$ and $CB$ are semi-circles. Find the sum of the areas of regions $X$ and $Y$. This is not so obvious to me. I started off with the formula for area which is A=$\pi r^2$ and since each semi-circle, we are going to have divide A by $2$. However, how would I find $r^2$ or the radius? Any ideas would help.",['geometry']
1710832,"Weak-* bounded, closed convex set is compact?","Suppose $E$ is a Banach space, and $K\subseteq E^*$ is convex, and is closed and bounded with respect to weak-* topology. Is it true that $K$ is compact? If $E$ is reflexive, then this is the case, since weak boundedness implies norm boundedness, and it easily follows from Banach-Alaoglu theorem that $K$ is compact (even without convexity). I wonder what happens if we drop the reflexive condition. Any ideas? Thanks! As user1952009 pointed out, the preceding argument also works for non-reflexive Banach spaces, see Given a Banach space $X$, are weak$^*$ bounded subsets of the dual space $X '$ also strongly bounded (with respect to the usual norm in $X '$)? .","['functional-analysis', 'banach-spaces', 'weak-convergence']"
1710840,Pharmacokinetics differential equations; with equal absorption and elimination constants.,"There are three closely related questions for the single compartment model applied to oral dosing in pharmacokinetics: The time evolution of blood concentrations, $t=0$ to $t=\infty$, given one and only one dose to the stomach at $t=0$; and, The equilibrium state time evolution of blood concentrations in between doses, $t=0$ at the instant a dose is taken and $t=\tau$ at the instant the next dose is taken (which then sets $t=0$ again), assuming regularly spaced doses, given that enough time has passed to reach that equilibrium state ($t \to \infty$); and, The fuller time evolution of blood concentrations, $t=0$ to $t=\infty$, also assuming regularly spaced doses, and also given that the first dose starts at $t=0$ (each dose occurs at $t=n\tau$, where integer $n \ge 0$ and where $\tau$ is the dose interval.) In each of the above cases, there is an assumed single absorption rate ($k_a$) to model the transfer from the stomach (mouth/tongue, esophagus, stomach, and the rest of the gut) to the blood stream and another assumed single elimination rate ($k_e$) to model the removal from the blood stream. Let's call $A$ the amount of the dose remaining in the gut and awaiting absorption into the blood and $E$ the amount residing in the blood stream and awaiting elimination. (We'll avoid confounding issues about blood volume and concentration, effectiveness, etc.) The set up for case 1 above is simple:
\begin{equation}
dA = -k_a \cdot A \, dt \\
dE = k_a\cdot A \, dt - k_e \cdot E \, dt
\end{equation}
and I'm able to solve this when $k_a \ne k_e$ and when $k_a = k_e$. Just to dot the i, regarding case 1, here's the logic I've applied. (I apologize for doing the obvious here.) Assume that D is the single dose amount, which occurs at $t=0$. So the initial condition is $A_0 = D$. For the stomach:
\begin{equation}
dA = -k_a \cdot A \, dt, \,\,\,\text{where $A_0=D$} \\
\frac{dA}{A} = -k_a \, dt \\
\int \frac{dA}{A} = \int -k_a \, dt \\
ln(A_t) = -k_a \cdot t + C_0 \\
A_t = D \cdot e^{-k_a \cdot t}
\end{equation} For the blood:
\begin{equation}
dE = k_a\cdot A \, dt - k_e \cdot E \, dt, \,\,\,\text{where $E_0=0$} \\
dE = k_a\cdot D \cdot e^{-k_a \cdot t} \, dt - k_e \cdot E \, dt \\
\frac{dE}{dt} = k_a\cdot D \cdot e^{-k_a \cdot t} - k_e \cdot E \\
\frac{dE}{dt} + k_e \cdot E = k_a\cdot D \cdot e^{-k_a \cdot t} \\
\text{setting integrating factor $\mu=e^{\int k_e \, dt}=e^{k_e \cdot t}$}, then \\
E = \frac{1}{\mu} \int_0^t \mu \cdot k_a \cdot D \cdot e^{-k_a \cdot s} \, ds \\
E = D\cdot e^{-k_e \cdot t}\cdot k_a \int_0^t e^{\left(k_e-k_a\right) \cdot s} \, ds \\
\text{which resolves one of two ways,} \\
E_t = D \cdot k \cdot e^{-k_e \cdot t} \cdot t, \,\,\,\text{where $k = k_a = k_e$} \\
E_t = D \cdot \frac{k_a}{k_a - k_e} \cdot \left( e^{-k_e \cdot t} - e^{-k_a \cdot t} \right), \,\,\,\text{where $k_a \ne k_e$}
\end{equation} I get that far without difficulty. Per the above development, I've also found two related questions have already been asked and answered on stackexchange . These are the relatively clearly stated single compartment model, single dose, absorption rate equals elimination rate and the somewhat more confused question on the same single compartment model, single dose, absorption and elimination rates not necessarily the same . Unfortunately, neither of these address case 2 and case 3. Since I already understand case 1, those cases on stackexchange don't further my understanding at all. I'm particularly interested in developing case 3 above for the situation where $k_a = k_e$. (I have the book answer, but not solution method, when $k_a \ne k_e$, so if I had those solution steps I could probably intercede and find the other case.) I tap out approximately where I'm able to find the equilibrium equation over time for the stomach value, $A$, for case 2, but not the equilibrium equation for $E$ (though I know what it should be, again from stock answers I've already found.) I also understand there isn't a single approach, but actually several areas in mathematics which can be applied depending upon where my comfort level is at. For these purposes, assume ONE year of undergrad mathematics: basically MTH 251, 252, and 253. This means NO serious use of Laplace transforms (though a glancing familiarity with the idea), no familiarity with variations of parameters methods, and also very little experience with the application of matrix methods here (though I understand them as applied to solving combinations of finite linear equations.) I need help both with the setup and the solution process for case 3 but case 2 might be used to prepare for it or else as a check to see if it falls out of the solution for case 3 where $t \to \infty$. (Case 1, of course, should match up with case 3's equation where $0 \le t < \tau$.) I apologize in advance for any perceived lack of effort or clarity in posing this question. Please accept my assurance that I've spent dozens of hours testing my own skills and attempting to find an appropriate resource that I could learn from before posting here. I'm now at the point of hoping there is someone interested enough to help educate me about solving this case-3 problem. For those needing/wanting to dig into my motivation: This pharmacokinetics question actually develops because my daughter suffers from grand mal seizures and takes drugs to help manage them. This is my personal interest here and has nothing whatever to do with homework! (It's been several decades since my first year calculus coursework.) I've taken the time to read what I could over many days' worth of searches (and hand to paper work as well, of course) and still find that I'm out of my depth in being able to develop the solutions myself. That's frustrating because, while I can find some answers stated in tables for certain questions, I can't create my own solutions to related questions as I simply lack the insight either in properly forming the problems or else find I'm lacking the methods in solving them. It may help that I have found elsewhere (without knowing how it is achieved) that a solution for case 3, where $k_a \ne k_e$, is:
\begin{equation}
E_t = D \cdot \frac{k_a}{k_a - k_e} \cdot \left[ \left( \frac{1 - e^{-n \cdot k_e \cdot \tau}}{1 - e^{-k_e \cdot \tau}} \right) \cdot e^{-k_e \cdot t} - \left( \frac{1 - e^{-n \cdot k_a \cdot \tau}}{1 - e^{-k_a \cdot \tau}} \right) \cdot e^{-k_a \cdot t} \right]
\end{equation}
where $n$ is the number of doses. In the case where $n=1$, you can see how this nicely resolves into:
\begin{equation}
E_t = D \cdot \frac{k_a}{k_a - k_e} \cdot \left( e^{-k_e \cdot t} - e^{-k_a \cdot t} \right)
\end{equation}
which is the solution for case 1 where $k_a \ne k_e$ (but not where $k_a = k_e$, where it is instead $E_t = D \cdot t \cdot e^{-k \cdot t}$, where $k = k_a = k_e$) In the case where $n \to \infty$, you can see how this nicely resolves into:
\begin{equation}
E_t = D \cdot \frac{k_a}{k_a - k_e} \cdot \left[ \frac{e^{-k_e \cdot t}}{1 - e^{-k_e \cdot \tau}}  - \frac{e^{-k_a \cdot t}}{1 - e^{-k_a \cdot \tau}}  \right]
\end{equation}
which is the solution for case 2 where $k_a \ne k_e$ (but not where $k_a = k_e$.) Note that this case 3 situation (where I can't develop my own work, sadly) only works where $k_a \ne k_e$. I'd like to find the answer where $k_a = k_e$. But I'd also, of course, like to know how to solve it either way. Not just the answers, but the approach.","['ordinary-differential-equations', 'calculus']"
1710853,Group such that Aut(G) = H and Aut(H) = G,"So this question just popped into my mind: does there exist a group $G$ such that $Aut(G) = H$ and $Aut(H) = G$ and $H\not=G$. My intuition says no, but im not sure how to go about proving this. Can somebody find an example or knows how to prove such a statement?",['group-theory']
1710863,An example from Lang's Algebra about primary ideal,"On page 421 in Lang's Algebra, the author writes Let $R$ be a factorial ring with a prime element $t$. Let $A$ be the subring of polynomials $f(X)∈R[X]$ such that 
  $$f(X)=a_0 + a_1X + \dotsb $$ 
  with $a_1$ divisible by $t$. Let $P=(tX,X^2)$. Then $P$ is prime. My question is: why $P$ is prime?","['polynomials', 'abstract-algebra', 'unique-factorization-domains', 'commutative-algebra', 'ideals']"
1710875,How many n-th Order Partial Derivatives Exist for a Function of k Variables?,"Example: Let's say for example I have a function, $f$, of $2$ variables : $f(x,y)$ For this function there exits $2$ first-order partial derivatives namely: $f_x = \frac{\partial f}{\partial x}$ $f_y = \frac{\partial f}{\partial y}$ Then if we are to differentiate further we will find that there are $4$ computable second-order partial derivatives. $f_{xx} = \frac{\partial^2 f}{\partial x^2}$ $f_{xy} = \frac{\partial^2 f}{{\partial x} {\partial y}}$ $f_{yy} = \frac{\partial^2 f}{\partial y^2}$ $f_{yx} = \frac{\partial^2 f}{{\partial y} {\partial x}}$ However due to the Equality of Mixed Partials ( https://en.wikipedia.org/wiki/Symmetry_of_second_derivatives ), two of those second-order partial derivatives are equivalent, $f_{xy} = f_{yx}$, and thus we are left with $3$ second-order partial derivatives for a function of 2 variables. $f_{xx} = \frac{\partial^2 f}{\partial x^2}$ $f_{xy} = \frac{\partial^2 f}{{\partial x} {\partial y}} \Leftrightarrow	 f_{yx} = \frac{\partial^2 f}{{\partial y} {\partial x}}$ $f_{yy} = \frac{\partial^2 f}{\partial y^2}$ Question: Given a function of k variables: $f(x_1 , x_2,x_3,\dots,x_{k-1},x_k)$ Is there a formula to find the number of $n^{th}$-order partial derivatives, (where $n$ is the order of the partial derivative), for a function of $k$ variables? For example where $n=1$ (i.e. the first-order derivatives), there would be $k$ partial derivatives, just as in the example above, for a function of $2$ variables there exists $2$ first-order derivatives.","['real-analysis', 'partial-derivative', 'calculus', 'multivariable-calculus', 'combinatorics']"
1710894,"$\int x^x\,dx$ - What is it, and why? [duplicate]","This question already has answers here : Finding $\int x^xdx$ (8 answers) Closed 8 years ago . As a high school calculus student, I stumbled across the possibilities for:
$$\int x^x\,dx$$ 
My friends and I are currently stumped. My first idea was:
$$ \left(\frac{1}{x+1}\right) x^{x+1} $$
But I doubt it is this simple. I've read through multiple forums, and cannot find any solution or explanation! Please help shed some light on this mysterious intregral.","['integration', 'calculus']"
1710907,"Bijection from $[-1,1]\times[-1,1] \rightarrow \{(x,y) \in \mathbb{R}: \sqrt{x^2+y^2} \leq 1\}$","I am trying to find and prove a bijection from the square $[-1,1]\times[-1,1]$ to the unit circle. Given a point $(x,y)$ in the square, my function maps it to the point $(r, \theta)$ in the circle where $r = \frac{\sqrt{x^2+y^2}}{\sqrt{1+(y/x)^2}}$ and $\theta = \begin{cases} \arctan(\frac{y}{x}) &\mbox{if } x > 0 \\ 
\arctan(\frac{y}{x})+\pi & \mbox{if } x < 0 \\
\pi/2 & \mbox{if } x = 0\ \mbox{and}\ y > 0\\
-\pi/2 & \mbox{if } x = 0\ \mbox{and}\ y < 0 \end{cases}$ In other words, the angle of the point on the circle is the same as the 'angle' of the point on the square, and the radius is the 'radius' of the point on the square, scaled down to fit inside the circle. I'm trying to prove the injection, which means I need to prove that $f(a, b) = f(c, d) \implies a = c\ \mbox{and}\ b = d$ or $\frac{\sqrt{a^2+b^2}}{\sqrt{1+(b/a)^2}} = \frac{\sqrt{c^2+d^2}}{\sqrt{1+(d/c)^2}}\ \mbox{and}\ \arctan(b/a) = \arctan(d/c) \implies a = c\ \mbox{and}\ b = d$ How can I do this? Edit: I realize that my formula for $r$ is slightly incorrect, because when $|y| > |x|$ then the denominator is $\sqrt{1+(x/y)^2}$.","['real-analysis', 'discrete-mathematics']"
1710912,Relation between left and right eigenvectors corresponding to the same eigenvalue,"I have a general question on how the left eigenvectors and right eigenvectors of a matrix are related to each other. Background. It is easy to see that the characteristic polynomial of a $A$ and $A^\top$ are the same, hence the ""left"" and ""right"" eigenvalues of $A$ are the same. Is there any geometric reason on why this should happen? And moreover, why there should be any relations between the left and right eigenvectors corresponding to the same eigenvalue? To be more clear, I can prove the following: Observation. Let $A \in \mathbb{C}^{n\times n}$ have $n$ distinct eigenvalues. Then for an eigenvalue $\lambda$ and corresponding left eigenvector $u^\top$ and right eigenvector $v$, we have $u^\top v \neq 0$. Proof. Let $J$ be the Jordan canonical form of $A$. Since all the eigenvalues of $A$ are simple, $J$ is diagonal. Let $A = SJS^{-1}$ for some invertible matrix $S$. Observe that for an eigenvalue $\lambda$ there is an $1 \leq i \leq n$ such that the $i$-th column of $S$, $s^i$, is a right eigenvector of $A$ for the eigenvalue $\lambda$, and the $i$-th row of $S^{-1}$, ${s_i}^\top$, is a left eigenvector of $A$ for the eigenvalue $\lambda$. Since $S^{-1} S = I$ we have ${s_i}^\top s^i = 1$. This implies $u^\top v \neq 0$. Note that this need not be true in general. For example when there isn't a full set of eigenvectors, like in $$\begin{bmatrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ 0 & 0 & 0\end{bmatrix}.$$  So, I want to make a claim as following: Claim. If $\lambda$ is an eigenvalue of $A$ where its geometric multiplicity is equal to its algebraic multiplicity, then there are left and right eigenvectors of $A$ corresponding to $\lambda$, respectively $u^\top$ and $v$, such that $u^\top v \neq 0$. Note that the claim can't be true for all left and right eigenvectors, instead of there is . For example consider the identity matrix., So, my questions are: Questions. Is there any geometric reasons that eigenvalues of $A$ and $A^\top$ are equal? Is there any intuitive way to see why the observation above holds? Is the claim above true? -- Owen Biesel in their comment to this question mentions that left eigenvectors are perpendicular to hyperplanes that are preserved under left multiplication. In that sense, that would mean $u^\top$ and $v$ are perpendicular if $v$ is in the hyperplane perpendicular to $u^\top$. But I can't quite make a connection to prove what I want.","['eigenvalues-eigenvectors', 'linear-algebra', 'soft-question']"
1710927,Linear algebra problem from dummite & foote,"Let $V$ be a finite dimensional vector space over $\mathbb{Q}$ and suppose $T$ is a nonsingular linear transformation of $V$ such that $T^{-1} = T^2 + T$. Prove that the dimension of $V$ is divisible by $3$. If the dimension of $V$ is precisely $3$, prove that all such transformations $T$ are similar. So applying $T$ to both sides of the given equation gives us $T^3 + T^2 - I = 0$, hence the minimal polynomial $m(x)$ of $T$ divides $x^3 + x^2 + 1$. But this polynomial is irreducible over $\mathbb{Q}$ by the rational root test, hence $m(x) = x^3 + x^2 + 1$. The structure theorem for finitely-generated modules over PIDs tells that
$$(V,T) \cong \bigoplus_{i=1}^{t}\frac{\mathbb{Q}[x]}{(a_i(x))},$$
where $t \geq 1$ and $a_i(x) \mid a_{i+1}(x)$ and $a_t(x) = m(x)$. But since $m(x)$ is irreducible, we must have each $a_i(x) = m(x)$, therefore
$$(V,T) \cong \left(\frac{\mathbb{Q}[x]}{(f(x))}\right)^t.$$
Now the dimension of $V$ equals $3t$ and is thus divisible by $3$. But doesn't it then also follow that given a dimension $3t$, any two such transformations $T$ make $V$ isomorphic as a $\mathbb{Q}[x]$-module to the above, hence are similar? It seems true in general, not just for $\dim(V) = 3$. Thanks!",['linear-algebra']
1710939,"Geometric meaning of $\mathcal{F}_x \otimes_{\mathcal{O}_{X,x}} \kappa(x)$","Let $X$ be a noetherian scheme and let $\mathcal{F}$ be a coherent sheaf on $X$. Let $x \in X$ be a point, then what is the geometric meaning of the vector space $\mathcal{F}_x \otimes_{\mathcal{O}_{X,x}} \kappa(x)$? $\kappa(x)$ is the residue field  at the point $x$. If $\mathcal{F}$ is locally free (so it is the sections of a vector bundle), what is the geometric meaning of $\mathcal{F}_x \otimes_{\mathcal{O}_{X,x}} \kappa(x)$? What is the (geometric) difference with the stalk $\mathcal{F}_x$?",['algebraic-geometry']
1710975,How does opponent's flush affect odds of your full house?,"A cute probability intuition test: Let $f$ be the probability of being dealt a full house in a five-card poker hand, from a randomly shuffled standard deck.  ($f \approx 0.001468$). Now look at the case of two players being dealt hands, and player one shows that she has a flush.  Now what is the probability $f_2$ that the five cards dealt to player 2 is a full house? It seems clear that we will have $f_2 < f$ because if one player has a full house it must be a tiny bit more likely that the other has pairs and other clumps of the same rank, and a flush has none of those.  But to test your intuition, how small is that effect? Is $f_2$ more than 99% of $f$?  More than 95%?  More than 90%? or less than 90%? EDIT I had written $h$ for ""house"" in the first sentence.  Then I used $f$ for ""full"" later.",['combinatorics']
1711014,Divide an equilateral triangle into at least $100$ regions?,A piece of paper has the shape of an equilateral triangle. What is the minimum number of straight lines parallel to its sides that divide the triangle into at least $100$ regions? The answer said it is $16$. But. But. Don't know how to solve it. Thank you.,['geometry']
1711077,Can the inscribed angle theorem be generalized to solid angles in 3D? And beyond to n-dimensional space?,"The ""inscribed angle theorem"" is a common 2-dimensional plane geometry fact. It states that for a circle the angle formed between any two points on the circumference with the center is twice the angle formed by those two points with any other point on the circumference. I will not elaborate on a proof or further details here, but instead provide a link and image from the wikipedia page on this topic, where the basic theorem is proved. IMAGE: The inscribed angle θ is half of the central angle 2θ that subtends the same arc on the circle (magenta). Wikipedia Article on inscribed angle theorem My question is whether this simple 2D geometric concept can be adapted to solid angles in 3D? And perhaps beyond to n dimensions? The 2D case dealt with 3 points on the circumference of a circle (2 that defined the arc, and the 3rd point that formed the angle that was half the angle at the center). In 3D, imagine a sphere rather than a circle, and consider 4 points instead of 3. Let 3 of the 4 points form the base of a tetrahedron, then consider two distinct cases. In the first case the 4th point forms the tip of the tetrahedron. In the other case the center of the sphere defined by the 4 points forms the tip of the tetrahedron. In either case the base of the tetrahedron, and the associated spherical triangle on the surface of the sphere, is the same. However there are two different solid angles at the tip of the tetrahedron in each case -- one for when the tip is at the center of the sphere and the other when the tip is at the 4th point defining the sphere. Are these solid angles related (one being half of the other, or some other similar relation) as in the inscribed angle theorem in 2D? If they are related in some way, is this a common fact/theorem in solid geometry? Does it have a name like the ""inscribed angle theorem"" in 2D? What is the relation between these two solid angles? Is there a similar concept in 4D, or n-dimensional, space? (I am not even sure if there is a solid angle concept in arbitrary n-dimensional space.) If there is a concept of solid angles in higher dimensions is there a predictable relation between these two angles a set n-dimensional space?For example, a particular dimension like 10-dimensional space, then 11 points in that 10D space, is there a way to easily find the ""solid angle"" at the 11th point, and then use a fixed relation to know the ""solid angle"" at the center of the 10D hypersphere going out to the other 10 points on the surface of the hypersphere?","['solid-geometry', 'solid-angle', 'geometry']"
1711090,"Can we always find homotopy of two paths which lies ""between"" the paths?","Let $\gamma_0,\gamma_1:[0,1]\to\mathbb{R}^2$ be paths such that $\gamma_0(0)=\gamma_1(0)$ and $\gamma_0(1)=\gamma_1(1)$.  I wish to show that there is a homotopy $\Gamma:[0,1]\times[0,1]\to\mathbb{R}^2$ from $\gamma_0$ to $\gamma_1$ that satisfies the following: For all $(s,t)\in[0,1]\times[0,1]$, $\Gamma(s,t)$ is not in the unbounded face of $\gamma_0([0,1])\cup\gamma_1([0,1])$. PS: If the answer is no, are there additional restrictions which we could place on $\gamma_0$ and $\gamma_1$ which would allow this?  (Ex. rectifiable, differentiable, etc.)","['algebraic-topology', 'general-topology', 'real-algebraic-geometry', 'homotopy-theory']"
1711105,Trying to derive the Laurent Expansion of $\wp$ (Weierstrass Elliptic function),"I have the definition of the Weierstrass elliptical function $\wp$ as:
$$\wp(z)=\frac{1}{z^2}+\sum_{\omega\neq 0}\frac{1}{(z-\omega)^2}-\frac{1}{\omega^2}$$ Where $w=n\omega_1+m\omega_2$, for $\omega_1$ and $\omega_2$ the periods of $\wp$. Also I have the definition for the anti-derivative of $\wp$, $\zeta$. We have $\zeta'(z)=-\wp(z)$ with $$\zeta(z)=\frac{1}{z}+\sum_{\omega\neq0}\frac{1}{z-\omega}+\frac{1}{\omega}+\frac{z}{\omega^2}$$ In order to find the laurent expansion of $\wp$ I am trying to find the laurent expansion of $\zeta$ and then differentiating termwise as $\zeta$ and $\wp$ converge uniformly. Beginning: $$\frac{1}{z-\omega}=\frac{-1}{\omega(1-\frac{z}{\omega})}=\frac{-1}{\omega}\sum_{n=0}^{\infty}\frac{z^n}{w^n}$$ and so $$\frac{1}{z-\omega}+\frac{1}{\omega}+\frac{z}{\omega^2}=-\frac{z^2}{\omega^3}-\frac{z^3}{\omega^4}$$ And now I am stuck. In Ahlfors complex analysis text Chapter $7$, Section $3.3$ he observes that when we sum over all the periods the terms with odd powers of the periods are zero (equivalently the even powers of $z$). I can't follow this step. I know it must be true as $\zeta$ is an odd function. However why can we jump to this conclusion?","['complex-analysis', 'elliptic-functions']"
1711109,How to read the Jacobian (determinant) shorthand notation?,"Lets say we have a function $f : \mathbb{R}^3\rightarrow \mathbb{R}^3$ , as defined below, with its value being denoted as $(a, b, c)$ for convenient reference. $$f(x,y,z) = (x^2, y^2, z^2) = (a, b, c)$$ The Jacobian matrix of $f$ and subsequently the Jacobian determinant would then be written: $$
\begin{bmatrix}
a'\\ 
b'\\ 
c'
\end{bmatrix}
=
\begin{bmatrix}
\frac {\partial a}{\partial x} & \frac {\partial a}{\partial y} & \frac {\partial a}{\partial z}\\ 
\frac {\partial b}{\partial x} &\frac {\partial b}{\partial y} & \frac {\partial b}{\partial z}\\ 
\frac {\partial c}{\partial x} &\frac {\partial c}{\partial y} & \frac {\partial c}{\partial z}
\end{bmatrix}
=
\begin{bmatrix}
2x & 0 &0 \\ 
0 & 2y &0 \\ 
0 & 0 &2z 
\end{bmatrix}
$$ $$
\begin{vmatrix}
a'\\ 
b'\\ 
c'
\end{vmatrix}
=
\begin{vmatrix}
\frac {\partial a}{\partial x} & \frac {\partial a}{\partial y} & \frac {\partial a}{\partial z}\\ 
\frac {\partial b}{\partial x} &\frac {\partial b}{\partial y} & \frac {\partial b}{\partial z}\\ 
\frac {\partial c}{\partial x} &\frac {\partial c}{\partial y} & \frac {\partial c}{\partial z}
\end{vmatrix}
=
\begin{vmatrix}
2x & 0 &0 \\ 
0 & 2y &0 \\ 
0 & 0 &2z 
\end{vmatrix}
=
2x2y2z
$$ Ok sure, this makes sense. It's kind of just like normal calculus but expanding everything out into a matrix. Now I look at the shorthand notation for the Jacobian determinant: $$
\frac {\partial(a,b,c)}{\partial(x,y,z)} = 2x2y2z
$$ Where did this even come from? Why are there partials there. How does it convey the same amount of information? How do I even read this ""shorthand notation"". It just seems to have appeared out of nowhere. How do I read it, is there a common rule of thumb to follow? How did this arguably rather cryptic notation come about?","['multivariable-calculus', 'notation', 'terminology', 'jacobian']"
1711114,an open continuous image of a Baire space is a Baire space,"Let $(X,\tau)$ and $(Y,\tau_1)$ be topological spaces and $f:(X,\tau) \rightarrow (Y,\tau_1)$ be a continuous open mapping. If $(X,\tau)$ is a Baire space, prove that $(Y,\tau_1)$ is a Baire space. My Proof is that Let $\{X_n\}^\infty_{n=1}$ be a sequence of open dense sets in $X$. Since $X$ is a Baire space, $\bigcap_{n=1}^\infty X_n$ is dense. This implies $\left(\bigcap_{n=1}^\infty X_n\right) \cap U \ne \emptyset$ where $U$ is any open set in $X$. Let $x\in \left(\bigcap_{n=1}^\infty X_n\right) \cap U$, then It would $x$ should be in all $X_n$ and $U$; thus $f(x) \in \left(\bigcap_n^\infty f(X_n)\right)\cap f(U)$. $f(X_n)$ and $f(U)$ is open in $Y$ since $f$ is continuous open mapping function. This holds for all $x$ and $U$. Hence $Y$ is a Baire space. In this proof, I assume that $f(X_n)$ is an open dense set in $Y$. Can I do that? if so, why am I allowed to do this? If anything wrong, please correct me. Thanks","['descriptive-set-theory', 'general-topology', 'baire-category']"
1711134,Integration on product probability space w.r.t. a coupled measure,"Given two probability spaces $(X_1, \Omega_1, P_1)$ and $(X_2, \Omega_2, P_2)$, a coupling $P$ of $P_1$ and $P_2$ is a probability measure on $X_1\times X_2$ such that $P(A\times X_2) = P_1(A)$ and $P(X_1\times B)= P_2(B)$ for $A \in \Omega_1$ and $B \in \Omega_2$. If $f:X_1\to \mathbb{R}$ is an integrable function (i.e. $\int_{X_1} |f| dP_1 < +\infty$), then why is the following true? $$\int_{X_1} |f| dP_1 = \int_{X_1\times X_2} |f(x_0)| dP(x_0,x_1)$$ This follows directly from Fubini's theorem if $P$ is the product measure of $P_1$ and $P_2$; but why is it true for arbitrary couplings? Thanks.","['probability-theory', 'measure-theory']"
1711161,Ordinal Fractions,"Is any fraction $\,{x}\big/ {y}\,$ an ordinal number and if so, does ordinal  $\,1 = \big\lbrace0,\dots,y - 1\big/y\big\rbrace\,$ instead of $\,\left\lbrace0\right\rbrace\,$? ""If (X, <=) is a well ordered set with ordinal number x, then the set of all ordinals < x is order isomorphic to X. This provides the motivation to define an ordinal as the set of all ordinals less than itself. John von Neumann defined a set x to be an ordinal number iff If y is a member of x, then y is a proper subset of x. If y and z are members of x, then one of the following is true: y = z , y is a member of z, or z is a member of y. If y is a nonempty proper subset of x, then there exists a z member of x such that the y intersection z is empty."" ( http://mathworld.wolfram.com/OrdinalNumber.html )","['elementary-set-theory', 'ordinals']"
1711196,Find max of $f(x)=12x^2\int_0^1yf(y)dy+ 20x\int_0^1y^2f(y)dy+4x$,"Let $$f(x)=12x^2\int_0^1yf(y)dy+ 20x\int_0^1y^2f(y)dy+4x$$
  Find the maximum value of $f(x)$ I wrote the two integrals as $I_1$ and $I_2$ since they are constants and differentiated the equation and put it to $0$. Then I tried writing one integral in terms of the other. But I could not get the required answer. I am in 12th and it came in one of my tests.","['integration', 'calculus', 'functions']"
1711202,Suppose that in fact $9\%$ of the oranges on the truck do not meet the desired standard. What's the probability that the shipment will be rejected?,"I am tutoring a student in AP stats, and came across this question. And I have not been able to solve this problem and get a result that is one of the multiple choices. The closest I got to was B (which I think is the intended answer), but I feel like the answer choices are incorrect. Problem: When a truckload of oranges arrives at a packing plant, a random sample of 125 is selected and examined, The whole truckload will be rejected if more than $8\%$ of the sample is unsatisfactory. Suppose that in fact $9\%$ of the oranges on the truck do not meet the desired standard. What's the probability that the shipment will be rejected? A) $0.6966$ B) $0.3483$ C) $0.6517$ D) $0.7803$ E) $0.2197$","['statistics', 'probability']"
1711226,Intrinsic definition of differential k-form on smooth manifold,"Suppose I have a $k$-dimensional manifold embedded in $\mathbb{R}^n$. Munkres defines a $k$-form on $M$ as a a function $\omega$ that assigns an alternating tensor at each point $p \in M$ that acts on $k$-tuples of tangent vectors in $T_pM$. He says that, for simplicity, we will just work with $k$-forms that are defined on open sets (of $\mathbb{R}^n$) which contain $M$, as we can restrict this $k$-form to $M$. So if we have a $k$-form $\omega$ defined on an open set of $\mathbb{R}^n$, then we can write $\omega = \sum f_I dx^I$ where $I$ represents an ascending $k$-tuple of integers from the set $\{1, \dots, n\}$ and the $f_I$ are smooth functions. However, I would like to think (and I may be wrong here) that if we really want a $k$-form $\omega$ defined on just $M$, then because $\dim(M) = k$, we ought to be able to write $\omega = f dz^1 \wedge \cdots \wedge dz^k$, where the $z^i$ are standard coordinates on the tangent space at each point. Being able to write a form in that manner seems much more desirable to me. I was told however, that in general, the tangent spaces of the manifold will be in different directions, so I cannot just declare $z^i$ for $1 \leq i \leq k$ to be standard coordinates on the tangent space, for the $z^i$ will, in general, be different for each tangent space. This makes sense to me. However, this also bothers me because why should a $k$-form be dependent on the space that the manifold is embedded in? By writing $\omega = \sum f_I dx^I$ we are implicitly making reference to the ambient space. There ought to be an intrinsic way to define a $k$-form on a $k$-manifold. Also, since $\omega$ acts on $k$-tuples of tangent vectors, and the tangent space can be defined via derivations without reference to an ambient space, then $\omega$ ought to take on the same values, regardless of what space $M$ is embedded in. At least these properties seem reasonable to me. On the Wikipedia page, there is an intrinsic definition: https://en.wikipedia.org/wiki/Differential_form#Intrinsic_definitions But I don't know enough smooth manifold theory yet to understand that definition. My only workings with smooth manifold theory so far have come from Munkres and the first three chapters of Lee's ""Introduction to smooth manifolds"" (which covers smooth manifolds, smooth maps between smooth manifolds, tangent spacces). So I was hoping that someone would be able to explain it in an intelligible way to me. Also, please correct anything that I may have gotten wrong, and definitely correct me if my list of ""reasonable properties"" is wrong as well. Thanks.","['differential-forms', 'smooth-manifolds', 'differential-geometry', 'differential-topology']"
1711242,Probability of obtaining a heads on the coin before a 1 or 2 on the die?,"I came across this question recently and can't seem to find the correct approach.
Any help would be appreciated! An experiment consists of first tossing an unbiased coin and then rolling a fair die. If we perform this experiment successively, what is the probability of obtaining a heads on the coin before a $1$ or $2$ on the die? $\mathbb P(\textrm{Heads})=\frac12$ $\mathbb P(1,2)=\frac13$ If $A_i$ represents the event that a $1$ or a $2$ is rolled on the $i^{th}$ toss, then I have to find the following: $$\bigcup^{\infty}_{i=1}\mathbb P(A_i).$$ But I am  not sure how to find this and also incorporate the probability of landing on heads before this...
Am I approaching this correctly or should I be assigning random variables and working from there?","['probability', 'dice']"
1711256,Induction for divisibility: $3\mid 12^n -7^n -4^n -1$,"I must use mathematical induction to show that 
$a_{n} = 12^n −7^n −4^n −1$ is divisible by 3 for all positive integers n. Assume true for $n=k$ $a_{k} = 12^k -7^k -4^k -1$ Prove true for $n=k+1$ $a_{k} = 12^{k+1} -7^{k+1} -4^{k+1} -1$ $ = (12^k)(12) - (7^k)(7) - (4^k)(4) -1$ $ = (12^k)(12) - (7^k)(3+4) - (4^k)(3+1) -1$ I'm not really sure about the last step, as someone just told me to do it. Am I supposed to find the right addends to use and then distribute the exponent terms until I get a multiple of the original $a_{k}$? Because I can't get it to work out evenly, and the -1 at the end gives me trouble. Also, I know that $12^n$ is a multiple of three already, but I don't know how to implement that fact to my advantage. Can I prove that $7^{n}-4^{n}-1$ is also a multiple of three and go from there?","['discrete-mathematics', 'divisibility', 'induction', 'elementary-number-theory']"
1711278,"Find the Integral, $ I_{1,1I}=\int \frac{x\arcsin{x}}{c\arcsin{k}+\sqrt{1-x^2} + x\arcsin{x}}\mathrm{d}x $","$$
I:=\int\arcsin\left(c+\frac{\sqrt{1-x^2} + x\arcsin{x}}{\arcsin{k}}\right)\mathrm{d}x
$$
where $c$ and $k$ are constants with respect to $x$. Euler lets
$$
I=\int \ln{(iu+\sqrt{1-u^2})}\mathrm{d}x
$$
where $u:=c+\frac{\sqrt{1-x^2} + x\arcsin{x}}{\arcsin{k}}$.
$I$ is separable:
$$
I=\int\ln{(u)}\mathrm{d}x + \int\ln{(i+\sqrt{\frac{1}{u^2}-1})}\mathrm{d}x
$$
The first of the sum of integrals, $I_{1}$, is found by naming $u$:
$$
I_{1}=\int\ln{(c+\frac{\sqrt{1-x^2} + x\arcsin{x}}{\arcsin{k}})}\mathrm{d}x
$$
$$
=\int\ln{(c\arcsin{k}+\sqrt{1-x^2} + x\arcsin{x})}\mathrm{d}x-\int\ln{(\arcsin{k})}\mathrm{d}x
$$
Thus,
$$
I_{1,2}=-x\ln\arcsin{k}
$$
Per partes gives:
$$
I_{1,1}=x\ln{(u\arcsin{k})}-\int \frac{x\arcsin{x}}{c\arcsin{k}+\sqrt{1-x^2} + x\arcsin{x}}\mathrm{d}x
$$
Substitution provides
$$
I_{1,1I}=\int \frac{e^{2y}\tan{e^y}}{c\arcsin{k}\cos{e^y}+\cos^2{e^y} + e^y\sin{e^y}\cos{e^y}}\mathrm{d}y
$$
where $y:=\ln{\arcsin{x}}$. Substitution also provides
$$
I_{1,1I}=\int \frac{y\sin{y}\cos{y}}{c\arcsin{k}+\cos{y}+y\sin{y}}\mathrm{d}y
$$
where $y:=\arcsin{x}$. Where 
$$
J:= \int \frac{c\arcsin{k}}{c\arcsin{k}+\sqrt{1-x^2} + x\arcsin{x}}\mathrm{d}x
$$
and
$$
K:=\int \frac{\sqrt{1-x^2}}{c\arcsin{k}+\sqrt{1-x^2} + x\arcsin{x}}\mathrm{d}x,
$$
$$
I_{1,1I}+J+K = x
$$
I am trying to find $I_{1,1I}$, but my substitutions, per partes intgration, and additive integration techniques are not working.","['trigonometry', 'integration-by-parts', 'calculus', 'indefinite-integrals', 'integration']"
1711292,Sum of inverse of Fibonacci numbers,"If $F(n)$ is the nth Fibonacci number, How can I prove that:
$$\sum_{i=1}^{\infty} \frac{1}{F(i)}\approx 3.36\, .$$","['fibonacci-numbers', 'sequences-and-series', 'approximation']"
1711330,What is the opposite category of $\operatorname{Top}$?,"My question is rather imprecise and open to modification. I am not entirely sure what I am looking for but the question seemed interesting enough to ask: The opposite category of rings is the category of affine schemes. This is usually thought of as the category of spaces. Can we run the construction backwards for categories usually thought of as containing spaces? For instance, does $\operatorname{Top}^{\operatorname{op}}$ have a nice description as some ""algebraic"" category? Note that it does not seem easy to describe the opposite category of all schemes. Therefore, the above question might be asking too much. Perhaps the following is a more tractable (or not) question: Can we find an ""algebraic"" category $C$ such that we can embed $C^{\operatorname{op}}$ in $\operatorname{Top}$ such that every topological space can be covered by objects in $C^{\operatorname{op}}$? Perhaps one would like to replace this criterion of being covered by objects by a more robust notion in general. One can repeat the question for other categories of spaces like: Category of manifolds (perhaps closer to schemes than general topological spaces) Compactly generated spaces Simplicial Sets and so on. A perhaps interesting example is the category of finite sets, it's opposite category is the category of finite Boolean algebras.","['category-theory', 'general-topology', 'algebraic-geometry']"
1711332,Why are turns not used as the default angle measure?,"Why is $2\pi$ radians not replaced by $1$ turn in formulas? The majority of them would be simpler. If such a replacement was proposed earlier, why was it declined?","['plane-geometry', 'math-history', 'trigonometry', 'pi', 'geometry']"
1711377,"Find $f(x)$, when $\left[f''(x)\right]^2\cdot f(x)=\left[f'(x)\right]^3,\ \forall x\in[0,1]$","Let $f:[0,1]\to\mathbb{R}$ be a twice differentiable function with
  $f''(x)>0,\ \forall x\in[0,1]$, $f(0)=f'(0)=1$ and
  $\left[f''(x)\right]^2\cdot f(x)=\left[f'(x)\right]^3,\ \forall
 x\in[0,1]$. Find $f(x)$. I am not sure how I can manipulate the third equality to derive $f(x)$. Any hint?","['derivatives', 'integration', 'calculus', 'functions']"
1711383,Find $f'(1)$ if $f$ is continuous and such that $f (f (x))=1+x$ for every $x$,If $ f $ is a continuous function satisfying $f (f (x))=1+x$ find $f'(1)$. I just guessed $f (x)=x+1/2$.Any formal method for this sum ?,"['algebra-precalculus', 'calculus', 'functions']"
1711422,Why do isotropic spaces deserve their name?,"Wiki defines a quadratic form to be isotropic if it evaluates to zero at some vector. What does this have to do with isotropy in physics i.e uniformity in all directions? From my experience so far, mathematicians are very good at naming things, so what is the geometric justification for this definition?","['intuition', 'abstract-algebra', 'quadratic-forms', 'linear-algebra', 'definition']"
1711489,"Prove that $A_n = C_n$, the $n$th Catalan number.","Problem : For each $n \geq 0$ let $A_n$ be the number of sequences $a_1a_2...a_n$ of non-negative integers that satisfy $$0 \leq a_{i+1} \leq a_i + 1, \:\:\: i = 0,...,n-1, \:\:\: a_1 = 0$$ Prove that $A_n = C_n$ , the $n$ th Catalan number, for each $n \geq 0$ . Proof: $A_0 = C_0 = 1$ . It suffices to prove $$A_n = \sum_{m=1}^{n} A_{m-1}A_{n-m}$$ for each $n > 0$ . For each $m = 1,...,n-1$ , let $A(n,m)$ be the number of sequences $a_1...a_n$ of length $n$ for which $$a_{m+1} = 0, \:\:\: a_i > 0 \:\:\text{for}\:\: i = 2,...,m$$ And let $A(n,n)$ be the number of sequences of length $n$ for which $$a_i > 0 \:\:\text{for all}\:\: i = 2,...,n$$ Now $$A_n = \sum_{m=1}^{n} A(n,m)$$ So we are done if we can prove that $$A(n,m) = A_{m-1}A_{n-m} \:\:\text{for}\:\: m = 1,...,n$$ Here i am stuck.","['number-theory', 'discrete-mathematics', 'sequences-and-series', 'elementary-number-theory']"
1711531,Prove the following result for Hermitian and Skew-Hermitian matrix,"If $H$ be a Hermitian matrix, prove that $\det H$ is real number. If $S$ be a skew Hermitian matrix of order $n$, prove that (i). if $n$ be even, then $\det S$ is real number; (ii). if $n$ be odd, then $\det S$ is a purely imaginary number or zero. Attempt: 1. Let $H=P+iQ$ be a Hermitian matrix, where $P,Q$ are real matrices. Then $\bar{H}^t=H\implies P^t-iQ^t=P+iQ\implies P^t=P$ and $Q^t-Q$.  How can I show that $\det H$ is real?","['matrices', 'hermitian-matrices']"
1711535,"Finding an inverse of $f(x,y)=(e^x \cos y,e^x \sin y)$ on a neighborhood of a given point","Show that $f\left(x,y\right)=\left(e^{x}\cos y,e^{x}\sin y\right)$ is one-to-one around any point of $\mathbb{R}^{2}$. For the points $\left(0,\pi\right)$ and $\left(-1,\frac{\pi}{2}\right)$ find such neighborhoods and the suitable inverse function of $f$. This is actually the exact same question as: Inverse function theorem question - multivariable calculus But after being able to do all the steps given there I am a bit stuck on the last part. I have done pretty much the same process and calculations there to find that if $u=e^{x}\cos(y)$ and $v=e^{x}\sin(y)$ then $$x=\frac{1}{2}\ln\left(u^{2}+v^{2}\right)$$ and for any integer $k$ (and $\arccos$ defined from $[-1,1]$ to $[0,\pi]$ $$y=\pm\arccos\left(\frac{u}{\sqrt{u^{2}+v^{2}}}\right)+2\pi k$$ but I'm having troubles explicitly finding an inverse function and a neighborhood for the given points. e.g. for $(0,\pi)$ if I want to define the inverse function as $$g\left(u,v\right)=\left(\frac{1}{2}\ln\left(u^{2}+v^{2}\right),\arccos\left(\frac{u}{\sqrt{u^{2}+v^{2}}}\right)\right)$$ so that $g(f(0,\pi))=(0,\pi)$ I'm not sure how to find the neighborhood for which this actually holds (and prove it is true in that neighborhood). Edit: Actually still stuck on this.. Looking at the point given above $(0,\pi)$, any neighborhood of it will include numbers larger than $\pi$ for the second variable, which I won't be able to ""translate back"" with $g$, even if I add $2\pi$. i.e. if I check $(0,\frac{3\pi}{2})$ , then $$
g(f(0,\frac{3\pi}{2}))=g(\cos \frac{3\pi}{2},\sin \frac{3\pi}{2})=(0, \arccos (\cos \frac{3\pi}{2})) = (0, \frac{\pi}{2})
$$
Am I thinking about this wrong?","['multivariable-calculus', 'exponential-function', 'inverse-function', 'inverse-function-theorem']"
1711564,How to know wheter or not is possible to solve an equations explicitly,"On an assignment I got the following question: Characterize the this DE: $$\frac{1}{4x^2}(y')^2+\frac{x}{2}y'-y=0 $$ My suggested solution is: It is a first order, non-linear, ordinary differential equation. I am not sure whether it is implicit or explicit. In our textbook, an implicit differential equation is defined as: Implicit :  is not possible to express $y^{(n)}$ explicitly  as a function of $y^{(n-1)},...,y$. So, my question essentially comes down to: Is it possible to write quadratic equation in $y'$ in an explicit form. I know the solution formula but there is this $\pm$. Is this $\pm$ allowed in an explicit function? How do I know in general whether or not an implicit expression can be rearranged to yield an explicit function?","['ordinary-differential-equations', 'functions']"
1711586,Are these groups solvable?,"I am thinking  of Baumslag-Solitar groups of type $BS(1,m)=\langle a,b \mid bab^{-1} = a^m\rangle$ as a prototype. We can think of them as follows: Start with an infinite cyclic group $\langle a\rangle$, choose an injective endomorphism $a\mapsto a^m$, and add a generator $b$ which acts on $\langle a\rangle$ by this endomorphism. More generally, we can start with the trivial group, and finitely many times add a new generator which acts on the previous group by an injective endomorphism. Let's call this ""the generalized construction"". Examples of groups formed by the generalized construction:
$BS(1,m)$ or $\langle a,b,c \mid bab^{-1}=a^m, cac^{-1}=a^n, cbc^{-1}=ba^k\rangle$ Does the generalized construction always yield solvable groups? My guess: I guess the answer is ""yes"". My feeling is that those groups are repeated semidirect products of subgroups of $\mathbb{Q}$, and so they should be solvable.","['solvable-groups', 'group-presentation', 'group-theory', 'geometric-group-theory']"
1711621,Simplifying integral $\int_4^3 \sqrt{(x - 3)(4 - x)} dx$ by an easy approach,"So I have this Integral $$\int_4^3 \sqrt{(x - 3)(4 - x)} dx$$ I know I can easily evaluate it using the by first converting it into this form $$\int \sqrt{a^2 + x^2} dx$$ and then using the direct formula for this. But since this one's a definite integral and while evaluating it's getting very long and taking time to solve. Also the probability of committing a mistake is high. 
I was wondering if there's an easy approach to evaluate such integrals without doing this much maths. This question appeared in my exam for for just 2 marks and it took me a long time to solve.  I don't think this much calculation is justified for just 2 marks. Kindly help me with an easy approach.","['integration', 'definite-integrals', 'calculus']"
1711649,"How many data points are ""enough"" for linear regression?","I have data points $(x_t,y_t)$ generated from $y_t = a + b x_t + \epsilon$ where $\epsilon$ is gaussian error term with zero mean and unknown variance. I want to estimate coefficients $a$ and $b$ but their is some cost associated with generating more data points. So, how many number of data points to get a ""reasonable"" estimate of the coefficients? Can we quantify what is ""reasonable""?","['regression', 'statistics', 'regression-analysis', 'parameter-estimation']"
1711653,Max of sum of sinusoids with arbitrary frequencies,"Let's define: $f(t) = A_1 \cos(\omega_1t) + A_2 \cos(\omega_2t) $ I am interested in finding an expression for the peak of this function. It is not true in general that this peak will have the value: $max{f(t)} = \sqrt{A_1^2 + A_2^2 + 2A_1A_2}$ To find the value of max(f), I did the following manipulations: $\omega_2 = \omega_1 + \Delta \omega_1$ so I can express the second cosine as that of a sum of a single radian frequency: $f(t) = A_1 \cos(\omega_1t) + A_2 \cos (\omega_1 t + \Delta \omega t)$ and after a little algebra: $f(t) = [A_1 + A_2 \cos(\Delta \omega t)]\cos(\omega_1t) - A_2 \sin(\Delta \omega t) \sin(\omega_1t )$ I can then transform the sum of two isochronic $\sin$ and $\cos$ into a single $\cos$ with a certain amplitude and phase: $f(t) = \sqrt{A_1^2 A_2^2 + A_1 A_2 \cos(\Delta \omega t)} \; \cos \left[\omega_1t - \tan^{-1} \left( \frac{A_1 + A_2 \cos (\Delta \omega t)}{A_2 \sin(\Delta \omega t)} \right) \right]$ But that's about how far I can drive it: since a trig function of $\Delta \omega$ is present both in the amplitude and phase of the cosine, I am not sure how to proceed. For sure, it is not said that the maximum of the function will be that of the amplitude part. I find the straight approach of taking the derivative of f(t) and find its zero would be probably too cumbersome, however I would ask more experienced people what they think the best way to proceed would be.","['trigonometry', 'calculus']"
1711687,"$f$ differentiable with f(0)=0, 1 isn't eigenvalue of $f'(0)$. There's a neighborhood of 0 in wich $f(x)\neq x$.","Question: Let $f:\mathbb{R}^m\to \mathbb{R}^m$ be differentiable with $f(0)=0$. If $1$ isn't eigenvalue of $f'(0)$ then there is a neighborhood $V$ of $0$ in $\mathbb{R}^m$ such that $f(x)\neq x$ for all $x\in V\setminus\{0\}$. I tried three approaches: We know that $f'(0)x=\lim\limits_{t\to 0}\frac{f(tx)}{t}\neq x$. Also, $\lim\limits_{h\to 0}\frac{f(h)-f'(0)h}{||h||}=0$. And $f(x)=f'(0)x+r(x)$ where $\lim\limits_{x\to 0}\frac{r(x)}{||x||}=0.$ And there's the fact that $f'(0)x\neq x$, $\forall x\in V\setminus \{0\}$. But I don't know how to use theses facts here.","['multivariable-calculus', 'real-analysis', 'analysis']"
1711694,Intuition about the lack of a quadratic term in geometric expansions,"Let $(\Sigma,g)$ be a Riemannian 2-manifold and let $p\in\Sigma$. It turns out that the circumference $C(r)$ of a geodesic circle $S_r(p)$ of radius $r$ around $p$ satisfies
$$
C(r)=2\pi r-\frac{\pi}{3}Kr^3+O(r^4),
$$
where $K$ denotes the Gaussian curvature of $\Sigma$ in $p$. On the other hand, if $\gamma$ is a smooth arc length parametrized curve in $\Sigma$ with $\gamma(0)=p$, then the geodesic distance from $p$ to $\gamma(t)$ satisfies
$$
d(p,\gamma(t))=t-\frac{k_g^2}{24}t^3+O(t^4),
$$
where $k_g$ denotes the geodesic curvature of $\gamma$ in $p$. Now here's the question. Can somebody give me an intuitive reason why there are no quadratic terms in these expansions? At least for the second expansion I have a vague idea why this is plausible but maybe there is a neat explanation for this. Of course, the proofs of the statements ""explain"" somehow, that/why there are no quadratic terms but I'm really looking for some heuristics/an intuitive explanation.","['riemannian-geometry', 'differential-geometry', 'calculus']"
1711713,Hoffman-Wielandt Theorem Proof,"Exercise 3.3 of Izenman's Modern Multivariate Statistical Techniques : let $\mathbf{A}$, $\mathbf{B}$ be symmetric $J \times J$ matrices, with eigenvalues $\{\lambda_j(\mathbf{A})\}$ and $\{\lambda_j(\mathbf{B})\}$ respectively, arranged in descending order with respect to $j$ (so $\lambda_1$ is largest, $\lambda_J$ is the smallest for both matrices). Prove that $$\sum_{j=1}^{J}\left[\lambda_j(\mathbf{A}) - \lambda_j(\mathbf{B})\right]^2 \leq \text{tr}\{(\mathbf{A}-\mathbf{B})(\mathbf{A}-\mathbf{B})^{T}\}\text{.}$$
The hint says to use spectral decomposition, so
$$\begin{align*}
\mathbf{A} &= \sum_{j=1}^{J}\lambda_j(\mathbf{A})\mathbf{v}_j(\mathbf{A})\mathbf{v}^T_j(\mathbf{A}) \\
\mathbf{B} &= \sum_{j=1}^{J}\lambda_j(\mathbf{B})\mathbf{v}_j(\mathbf{B})\mathbf{v}^T_j(\mathbf{B})
\end{align*}$$
where the $\mathbf{v}_j(\cdot)$ denote the eigenvectors of the matrix $\cdot$ corresponding to $\lambda_j$. Then it says to express $$\text{tr}\{(\mathbf{A}-\mathbf{B})(\mathbf{A}-\mathbf{B})^{T}\}$$
in terms of the decomposition. I have
$$\mathbf{A}-\mathbf{B} = \sum_{j=1}^{J}[\lambda_j(\mathbf{A})\mathbf{v}_j(\mathbf{A})\mathbf{v}^T_j(\mathbf{A})-\lambda_j(\mathbf{B})\mathbf{v}_j(\mathbf{B})\mathbf{v}^T_j(\mathbf{B})] $$
and
$$(\mathbf{A}-\mathbf{B})^{T} = \mathbf{A}^{T}-\mathbf{B}^{T} = \sum_{j=1}^{J}[\lambda_j(\mathbf{A})\mathbf{v}^T_j(\mathbf{A})\mathbf{v}_j(\mathbf{A})-\lambda_j(\mathbf{B})\mathbf{v}^T_j(\mathbf{B})\mathbf{v}_j(\mathbf{B})]\tag{1}\text{.}$$
I suppose we could assume the vectors are normalized, so we get $\mathbf{v}^T_j(\mathbf{A})\mathbf{v}_j(\mathbf{A}) = \mathbf{v}^T_j(\mathbf{B})\mathbf{v}_j(\mathbf{B}) = 1$. But I'm not sure what else to do. Direct multiplication looks like a very messy approach (which would possibly involve induction on $J$), but I thought I'd ask here for suggestions.","['matrices', 'linear-algebra']"
1711720,Maximum length between two points,"There is given: $$f(x) = x^2$$
$$g(x) = x$$ A parallel line to the $x$-axis is put so there is two cut points between the line and the two functions. Find the biggest length of the line that connects the two functions. I tried the length between $(x, x)$  and $(x, x^2)$ but didn't work. EDIT: To explain it better, which orange line is bigger?","['calculus', 'functions']"
1711772,Cones of max-Spec,"Let $k$ be an algebraically closed field and $R=k\oplus R_1\oplus R_2\oplus \ldots$ be a graded commutative ring that's finitely generated by elements of positive degree. If $M$ is a finitely generated graded $R$-module then $$V(M):=\{\mathfrak{m}\in \text{max-Spec} R: M_\mathfrak{m}\neq 0\}\cup \{R_+\}.$$ I am reading this paper and they mention that $V(M)$ is a $k$-rational cone (I have slightly changed notation from their exposition,  but I hopefully have extracted the major ingredients).  Note that since $M$ is finitely generated, $$V(M)=\{\mathfrak{m}\in \text{max-Spec} R: \mathfrak{m}\supseteq \text{ann}_R M\}\cup \{R_+\}.$$ Now let $$\text{Supp}_R^+M:=\{\mathfrak{p}\in \text{Proj}R: M_{\mathfrak{p}}\neq 0\},$$then the authors say  this set determines and is determined by $V(M)$. I was wondering how this correspondence works. Thanks in advance. Edit: One thing to note is that Supp$_R^+M=V^+(M)$ where $$V^+(M):=\{\mathfrak{p}\in \text{Proj} R: \mathfrak{p}\supseteq \text{ann}_R M\}$$ since $M$ is finitely generated. Also, ann$_RM$ is a homogeneous ideal, since $M$ is a graded $R$-module. So I'm asking how is the following correspondence established?: $$(V(I)\cap \text{max-Spec}R)\cup\{R_+\}\leftrightarrow V^+(I),$$ where $I$ is a homogeneous ideal of $R$.","['modules', 'algebraic-geometry', 'graded-modules', 'graded-rings', 'commutative-algebra']"
1711778,Are there any other types of non-euclidean geometry?,"We have 2 non-euclidean geometries(ie. not satisfying the fifth postulate ) in hand. But can there be some other models of non-euclidean geometries different from the known two? In other words, do the other axioms of Euclid enforce the number of  lines parallel to a given line and passing through a given point to be 0,1 or $\infty$?","['noneuclidean-geometry', 'soft-question', 'geometry']"
1711787,"Twin Primes, their Arithmetic Means and some properties.","These are two problems which I have been trying to solve. The arithmetic mean of twin primes 5 and 7 is 6 which is a triangular number. Do there exist any other such twin primes? If they exist find a pair otherwise prove that there do not exist any other such twin primes. Let the smaller prime be $p$. The larger one is $p+2$. Their mean is $p+1$. Triangular numbers are of the form $\frac{n(n+1)}{2}$. So, $$\frac{p+p+2}{2} = \frac{n(n+1)}{2}$$ How do I proceed further? The arithmetic mean of twin primes 3 and 5 is 4 which is a perfect square. Do there exist any other such twin primes? If they exist find a pair otherwise prove that there do not exist any other such twin primes. I have made no progress in this one. Thanks.","['number-theory', 'twin-primes', 'prime-numbers', 'elementary-number-theory']"
1711790,Distance to origin of tangent plane to ellipsoid,"We have an $n$-dimensional ellipsoid described by: $$\frac{x_1^2}{a_1^2}+\dots+\frac{x_n^2}{a_n^2}=1$$ and we construct the hyperplane through any $x \in$ the ellipsoid which is tangent to the ellipsoid at $x$. Prove that $D(x)$, the distance from this hyperplane to the origin, is: $$D(x)=\frac{1}{\sqrt{\frac{x_1^2}{a_1^4}+\dots+\frac{x_n^2}{a_n^4}}}$$ I know that the plane tangent to the ellipsoid at a point on the ellipsoid we can call $y_0=(y_1,\dots,y_n)$ can be written as: $$\frac{x_1y_1}{a_1^2}+\dots+\frac{x_ny_n}{a_n^2}=1$$ I don't see how to get from this description of the tangent plane to an expression for the distance to the origin only in terms of $x$. How do we deal with the fact that the description is at a specific point? Edit: fixed the equation for D","['real-analysis', 'geometry']"
1711826,Kerr spacetime not symmetric?,"I always see a term $dt \, d \phi$ in the Kerr-spacetime . Now assuming this means $dt \otimes d \phi$ this means that the Kerr spacetime is NOT(!) symmetric which is somehow non-sense. So do physicists mean that $dt \, d\phi = dt \otimes d \phi + d\phi \otimes dt$ or am I missing anything?","['tensors', 'differential-geometry', 'general-relativity']"
1711839,differentiation problem,"If $x^{13}y^{7}=(x+y)^{20}$ , then $\frac{dy}{dx}$ directly doing it makes it very complicated so, I did this $\left(\frac{x}{y}\right)^{13}=\left(1+\frac{x}{y} \right)^{20}$. 
following are the options for solution
(a) $\frac{y^2}{x^2}$ (b)$\frac{x^2}{y^2}$ (c)$\frac{x}{y}$ (d)$\frac{y}{x}$
thanks for any hints.",['derivatives']
1711852,How do you find the value of $\sum_{r=0}^{44} \tan^2(2r+1)$?,Problem: Find the value of $$\sum_{r=0}^{44} \tan^2(2r+1)$$ Note: The angles here are in degrees. I don't know how to solve this question because trigonometric simplifications didn't get me anywhere. I think there was a method to solve this question using complex numbers which I no longer remember. Any hint/help will be appreciated.,"['contest-math', 'summation', 'complex-numbers', 'trigonometric-series']"
1711853,Pullback of a complex $ 1$-form,"Let $p = \operatorname{exp} : \mathbb{C} \to \mathbb{C}^*$ be a covering and $(U,z)$ a chart of $\mathbb{C}^*$ with $z = x + iy$. Let $\omega = dz/z$ be a one-form on $U$. Problem: Find the pullback $p^*\omega$. My try: We can write $p^* \frac{1}{z}dz = p^*\frac{1}{z} \, d(p^*z) = p^*\frac{1}{z} \, p^*(dz) = (\frac{1}{z} \circ p)(dz \circ p)$. I also tried making sens of $\frac{1}{z} \circ p (a)$ for some $a \in U$. Then we get
$$
\frac{1}{z} e^a = \frac{1}{x(e^a) + iy(e^a)}.
$$ I have no idea what makes sense to do or try. I have very little intuition for this.","['riemann-surfaces', 'complex-analysis', 'differential-geometry', 'differential-forms']"
1711918,An alternative to integration by trigonometric substitution?,"When I was a Calculus II student many (about 4800) moons ago, our professor taught us an alternative to trig sub.  For example, if we have
$$
  \int \frac{dx}{x^2\sqrt{x^2 - 9}},
$$
we would evaluate with trig sub by letting $x = 3\sec\theta$ and we'd get:
\begin{align}
  \int \frac{dx}{x^2\sqrt{x^2 - 9}} &= \int\frac{3\sec\theta\tan\theta \, d\theta}{9\sec^2\theta\sqrt{9\sec^2\theta - 9}}\\[0.3cm]
    &= \frac{1}{3}\int\frac{\tan\theta\,d\theta}{\sec\theta \cdot 3\tan\theta}\\[0.3cm]
    &= \frac{1}{9} \int \cos\theta \, d\theta\\[0.3cm]
    &= \frac{1}{9} \sin\theta + C\\[0.3cm]
    &= \frac{\sqrt{x^2-9}}{9x} + C
\end{align} The alternative method he showed us goes like this for this problem:
\begin{align}
  \int\frac{dx}{x^2\sqrt{x^2 - 9}} &= \int \frac{dx}{x^2\sqrt{x^2(1 - 9x^{-2})}}\\[0.3cm]
    &= \int\frac{dx}{x^3\sqrt{1 - 9x^{-2}}}\\[0.3cm]
    &= \int\frac{x^{-3} \, dx}{\sqrt{1 - 9x^{-2}}}
\end{align}
Yes, I know that technically $\sqrt{x^2} = |x|$.  But trig sub also comes with domain restrictions. Now let $u = 1 - 9x^{-2}$.  Then $du = 18x^{-3} \, dx$ and we have:
\begin{align}
\int\frac{x^{-3} \, dx}{\sqrt{1 - 9x^{-2}}} &= \frac{1}{18}\int\frac{du}{\sqrt{u}}\\[0.3cm]
    &= \frac{1}{18} \cdot 2\sqrt{u} + C\\[0.3cm]
    &= \frac{\sqrt{1 - 9x^{-2}}}{9} + C
\end{align} Same answer, different form.  My question has two parts, sort of (since an answer to #1 could point to an answer to #2). Does anyone know the history of this method? Is this method perfectly interchangeable with trig sub?  In other words, can an integral be done using this method iff it can also be done using trig sub? IIRC, which I may not because of all the moons, our professor said there's no ""general formula"" to get this to work.  You just kind of have to eyeball it and try it.  But I don't remember him saying whether or not it would work all the time. Thanks!","['substitution', 'integration', 'trigonometry', 'calculus']"
1711927,How to find dispersion relation for a system of linear ODEs,"I am trying to find the dispersion relation for a system of linear ODEs. I can do this for a single linear PDE, for example $$u_x = u_t$$
by substituting $u = Ae^{i(kx-wt)}$, here $w = w(k)$ where $k$ is the wavenumber. Then we get $$(ik) = -iw $$$$\Rightarrow w = -k$$ However , now I am trying to find the dispersion relation for a system of linear ODEs. For example $$\dot{u_n} =u_{n-1}+u_{n+1}$$ and $n = 1,2,3,...,2N$ when $u_0 = u_{2N}, u_1 = u_{2N+1}$ In the first example, $w$ was a function of a continuous variable $k$. But since there are no $x$ derivatives now, $w$ is a function of a discrete variable $w = w_k$. My question : what do I use to substitute into equation $(1)$ to find the dispersion relation. Would I use the same substitution as the first example? What's confusing me is that we have the term $u_{n-1}$ and I am not sure how we are meant to reflect that in the substitution. Thanks a lot.","['ordinary-differential-equations', 'systems-of-equations']"
1711935,"Let $S$ and $T$ be sets such that $|S|=|T|$, prove that $|P(S)|=|P(T)|$","Let $S$ and $T$ be sets such that $|S|=|T|$, prove that $|P(S)|=|P(T)|$ where $P$ denotes a power set. From the theorem: If $S$ is a finite set with $n$ elements, then the cardinality of $P(S)=2^n$ we can show that $|P(S)|=|P(T)|$ when $S$ and $T$ are finite. I'm not sure where to begin if $S$ and $T$ are infinite sets?","['cardinals', 'elementary-set-theory', 'proof-verification']"
1711952,"Is there an ""intrinsic"" difference between a plane and a cylinder?","Since the plane and the cylinder have zero Gaussian curvature, I'm wondering, is there an ""intrinsic"" way of telling one from the other? By ""intrinsic"" here I loosely mean a property that can be calculated and/or deduced by inhabitants of the manifold itself, without ""seeing"" it from a higher dimensional space.","['differential-geometry', 'soft-question']"
1711974,Why does the limit of this function not exist: $\lim_{x\to \infty} \frac{1}{1+\cos(x)}$,"In this question the asker mentions that the limit of this does not exist:
$$\lim_{x\to \infty} \frac{1}{1+\cos(x)}$$
Graphically I can see that the limit doesn't exist, but I'd like to know what the proof is. I'm also wondering if there is a general rule that can be applied to any limit to tell if the limit exists. Sorry if this question is a bit dumb, and thanks in advance for any answers.","['trigonometry', 'calculus', 'limits']"
1711979,"Problem about uniform continunity on $[0,\infty)$","The question is the following: $f(x)$ is uniformly continuous on $[0, \infty)$ and for any $x > 0$, $\lim\limits_{n\to \infty}f(x+n) = 0$, where $n \in \mathbb{Z}_{>0}$. Prove that $\lim\limits_{x\to \infty} f(x) = 0$. Hint: Divide $[0, 1]$ into small equal-length intervals I do not understand what this question means. What exactly it is asking to be proved? Wouldn't it be obvious that $\lim\limits_{x\to \infty} f(x) = 0$ since $\lim\limits_{n\to \infty}f(x+n) = 0$. Also, what is the meaning or help from the hint? Thanks for your help! I am so confused...","['uniform-continuity', 'real-analysis']"
1711988,Prove 1-Norm is a Norm,I am just curious how you would simply prove that a 1-norm is a norm. Step-by-step would be very helpful. Proofs are not my strong point. Thank you!,"['numerical-linear-algebra', 'matrices', 'normed-spaces', 'linear-algebra', 'vectors']"
1712013,"Is it really true that ""if a function is discontinuous, automatically, it's not differentiable""? [duplicate]","This question already has answers here : Why can a discontinuous function not be differentiable? (2 answers) Closed 8 years ago . I while back, my calculus teacher said something that I find very bothersome. I didn't have time to clarify, but he said: If a function is discontinuous, automatically, it's not differentiable. I find this bothersome because I can think of many discontinuous piecewise functions like this: $$f(x) =
\begin{cases}
x^2, & \text{$x≤3$} \\
x^2+3, & \text{$x>3$}
\end{cases}$$ Where $f'(x)$ would have two parts of the same function, and give:
$$\begin{align}
f'(x) = &&
\begin{cases}
2x, & \text{$x≤3$} \\
2x, & \text{$x>3$}
\end{cases} \\
= && 2x
\end{align}$$ So I'm wondering, what exactly is wrong with this? Is there something I'm missing about what it means to be ""continuous""? Or maybe, are there special rules for how to deal with the derivatives of piecewise functions, that I don't know about.","['continuity', 'ordinary-differential-equations', 'calculus']"
1712018,Pull back and intersection of divisors,"Let $X$ be a smooth projective variety over complex numbers. Let $Z$ be a smooth closed subscheme of $X$. Let $L$ be a very ample line bundle on $X$. Then $L|_Z=E$ is a very ample line bundle on $Z$. If $D,D'\in |E|$ are divisors on $Z$ such that $D\cap D'$ has codimension 2 in $Z$, can we say that $D$ and $D' $ come from divisors in $|L|$ on $X$ whose intersection has codimension 2?","['vector-bundles', 'algebraic-geometry']"
1712035,Is there a limit which characterizes twice differentiability?,"If $f$ is twice differentiable at $x=a$, then we have $$
f''(a) = \lim_{h \to 0} \frac{f(a+h)-2f(a)+f(a-h) }{h^2}
$$ However there are functions which are not twice differentiable for which this limit exists (for example, the signum function). Is there a limit definition for $f''(a)$ which exists iff $f$ is twice differentiable?","['derivatives', 'calculus']"
1712037,Let $p<q$ be distinct prime numbers and $G$ be a group with $|G|=pq$ [duplicate],"This question already has answers here : Nonabelian semidirect products of order $pq$? (3 answers) Closed 8 years ago . Let $p < q$ be distinct prime numbers and $G$ be a group with $|G| = pq$. Give an example of $p$, $q$ and $G$ such that $G$ is not isomorphic to $\mathbb{Z}_{pq}$. Now suppose that $p = 5$ and $q = 7$. Show that $G$ is isomorphic to $\mathbb{Z}_{35}$. I know we are learning about Sylow's Theorems and group actions, but those are very confusing to me, so I'm not sure how to implement them really.","['abstract-algebra', 'group-theory', 'group-isomorphism']"
1712116,"Subgroup generated by $1 - \sqrt{2}$, $2 - \sqrt{3}$, $\sqrt{3} - \sqrt{2}$","For a number field $K$, Dirichlet's unit theorem says that$$(O_K)^\times = \mathbb{Z}^{r - 1} \oplus (\text{a finite cyclic group}),$$where $r$ is the number of all infinite places of $K$. An infinite place of $K$ is either an embedding of $K$ (as a field) into $\mathbb{R}$ or the complex conjugacy class of an embedding of $K$ (as a field) into $\mathbb{C}$ with dense image. When $K = \mathbb{Q}(\sqrt{2}, \sqrt{3})$, how do I see that $1 - \sqrt{2}$, $2 - \sqrt{3}$, and $\sqrt{3} - \sqrt{2}$ generate a subgroup $\Gamma$ of $(O_K)^\times$ such that$$\Gamma \cong \mathbb{Z}^3 = \mathbb{Z}^{r - 1}?$$","['abstract-algebra', 'algebraic-number-theory', 'number-theory', 'group-theory', 'field-theory']"
1712127,Notion of co- and contravariance of vectors dependent on the convention used for the change of basis matrix?,"Upon reading a bit about general relativity I came across the notion of co- and contravariance of vectors. All sources I've found agree that vectors (or rather their coordinates) transform contravariantly while covectors (linear forms) transform covariantly. However, I have a feeling that this transformation behavior is only a consequence of what one defines to be a change of basis. Let me clarify this point. Let $V$ be a vector space and $B$ a basis for $V$. For each $v \in V$ we then have a coordinate representation $[v]_B$ of $v$ with respect to the basis $B$. If we now take another Basis of $V$, say $B'$, we can find a matrix $A$, such that $A[v]_B = [v]_{B'}$. That is $A$ converts a coordinate representation with respect to the ""old"" Basis $B$ to the corresponding representation of $v$ relative to $B'$. This matrix $A$ is what I consider to be the Change-of-Basis-matrix from $B$ to $B'$. Personally, I think this is the most ""natural"" way to define it. However, it's easy to see, that (by definition) the coordinates transform with $A$, i.e. we obtain the ""new"" from the ""old"" coordinates by multiplying with $A$. With this in mind I think it's just as good to call vectors covariant . Is my reasoning correct? Is the notion of co- and contravariance only dependent on the fact that (apparently) physicists define the Change-of-Basis-Matrix from $B$ to $B'$ the other way round, that is $A[v]_{B'} = [v]_B\iff [v]_{B'} = A^{-1}[v]_B$. I'm asking this question mainly because I cannot wrap my head around this convention. Not at all. Maybe anyone can clarify this a bit for me?","['differential-geometry', 'linear-algebra']"
1712177,"If a random variable is independent from the two components of a random vector, are the random vector and the random variable independent?","in my probability class I was asked this seemingly very tricky question dealing with random variables and vectors: Let $ X,Y,Z $ be random variables with PDFs (continuous) such that we know that Z and X are independent and the variables Z and Y are independent. We are asked to prove or disprove (give a counterexample) that the random vector $ (X,Y) $ and $ Z $ are independent. I have tried to prove it just with the basic identities and definitions but got nothing so maybe it is false and we must give a counterexample? I do not even know how to deal with this, so I really need the help. Thanks all helpers.","['independence', 'probability', 'random-variables']"
1712198,How to integrate $\int\limits_{0}^{\pi/2}\frac{dx}{\cos^3{x}+\sin^3{x}}$?,"I have$$\int\limits_{0}^{\pi/2}\frac{\text{d}x}{\cos^3{x}+\sin^3{x}}$$
Tangent half-angle substitution gives a fourth-degree polynomial in the denominator that is difficult to factor.","['integration', 'definite-integrals', 'calculus', 'closed-form']"
1712209,"Is $f(x,y) = \frac{x \sin(y^2)}{x^2+y^2}$ with $f(0,0) =0$ continuous?","I want to know whether the following function is continuous or not, but I have no idea how to do this. $$f(x,y)=\begin{cases}
\dfrac{x \sin(y^2)}{x^2+y^2}, &\text{if }(x,y)\neq (0,0)\\
0, &\text{if }(x,y)=(0,0)
\end{cases}$$","['multivariable-calculus', 'continuity']"
1712210,Is there a difference between $\sin^2(x)$ and $\sin(x)^2$?,"Is there a difference between these? Or are they the same? If they're the same, then why does $\sin^2(x)$ seem like its used more often?","['trigonometry', 'notation']"
1712216,Prove that $f( E^o)$ is an open set if $E$ is bounded,"I do not really understand how to proceed with this question; 
To prove a), do I need to show that every point in $f(E^0)$ is an interior point?
I would greatly appreciate any help in this regard","['general-topology', 'real-analysis', 'elementary-set-theory', 'vector-analysis']"
1712229,How to take the second derivative using multi variable chain rule?,"I am working on this question: Now I have the first part and found
$$\frac{\partial F}{\partial x} =
\frac{\partial f}{\partial u}+\frac{\partial f}{\partial v}\\
\frac{\partial F}{\partial y} =
\frac{\partial f}{\partial u}-\frac{\partial f}{\partial v}\\
\frac{\partial F}{\partial x}\frac{\partial F}{\partial y} =
\left(\frac{\partial f}{\partial u}\right)^2-\left(\frac{\partial f}{\partial v}\right)^2$$ as required. Yet I am stuck on the second part I know $$\frac{\partial ^2F}{\partial x \partial y}=\frac{\partial}{\partial x}\left(\frac{\partial F}{\partial y}\right)$$ but here is where I am not sure is this: $$\frac{\partial}{\partial x}\left(\frac{\partial F}{\partial u}-\frac{\partial F}{\partial v}\right)=\frac{\partial F}{\partial u}\frac{\partial u}{\partial x}-\frac{\partial F}{\partial v}\frac{\partial v}{\partial x}=\frac{\partial F}{\partial y}$$ However I think this might be wrong? Any help?",['multivariable-calculus']
1712263,"Radius of a largest circle inscribed under $y=\frac{1}{(1+x^2)^n}$, closed form","The curve $y=\frac{1}{1+x^2}$ has an obvious connection to circles, because it's the derivative of the arctangent function. Besides, if we inscribe a circle under it, its radius is exactly $R=\frac{1}{2}$ , so it takes exactly one fourth of the full area under the curve. Actually, I don't know an easy way to find $R$ even in this simple case. So, let's consider how I solve the more general problem. Find the largest circle fitting between the curve $y=y (x)$ and the line $y=0$ $$y(x)=\frac{1}{(1+x^2)^n}~~~~~~ n=1,2,3,\dots$$ The distance from the circle origin $(0,R)$ to the curve is the minimum of a function: $$s(x)=\sqrt{x^2+\left(R-\frac{1}{(1+x^2)^n} \right)^2}$$ $$s(x)'=0$$ The condition for the inscribed circle is $s(x)=R$ . Let's denote: $$t=1+x^2$$ Then from the above we obtain the system of equations: $$t^{2n+1}+2n~R~t^n-2n=0$$ $$t^{2n+1}-t^{2n}-2~R~t^n+1=0$$ This is how I got the solution for $n=1$ (using Mathematica). Other solutions do not have obvious closed forms. Here are the numerical roots I've got with Mathematica: $$R_2=0.4735710971151933$$ $$R_3=0.4401444298014721$$ $$R_4=0.41216506385826285$$ And so on. The questions I ask: Can there be closed forms for $R$ for $n \neq 1$ ? How to find them? Is there an easier way to find $R$ ? At least for some $n$ ? Edit The most simple equation for $t$ , as far as I can see, is: $$(n+1)~t^{2n+1}-n~t^{2n}-n=0$$ I think I might ask a separate question about this equation. It's easy to solve by Newton-Raphson, but can it have closed form solutions for any $n$ ?","['polynomials', 'optimization', 'systems-of-equations', 'geometry', 'lagrange-multiplier']"
1712276,"""Marginalizing out"" a parameter in a PDF","Say I have a variable $x$ whose PDF is a von Mises distribution with a single parameter, $\kappa$, that determines the distribution's concentration: $VM(x; \kappa)$. But suppose $\kappa$ itself is not fixed, but drawn from a Gamma distribution: $G(\kappa; \bar{\kappa}, \tau)$, where the mean is $\bar{\kappa}$ and the variance is $\bar{\kappa}\tau$. An author whose work I'm replicating has this to say about this situation: ""The predictions [for each $x$ value's probability] have to be averaged over all possible values of precision $\kappa$ (mathematically: we need to 'marginalize out $\kappa$').  We do this by discretizing the (gamma) distribution over $\kappa$ into 50 bins with equal probability masses, computing the model [von Mises] prediction at each bin center, and then averaging the predictions.  This solution is accurate as long as the number of bins is not too small (in the limit of an infinite amount of bins, the solution is equal to an analytical marginalization)"" (emphasis mine). I've read elsewhere that probabilities should be summed , not averaged, in marginalization.  Another confusion I have regards this author's statement that the average should be ""over all possible values of $\kappa$.""  This seems to imply that each possible value of $\kappa$ should be treated equally -- but then we're talking about a uniform distribution, not a Gamma one.  Clearly, the author was using language loosely. Can someone shed some light on this, maybe with language that is more precise?","['probability-theory', 'probability', 'density-function', 'probability-distributions']"
1712282,Cantor set minus endpoints homeomorphic to irrationals?,"$C=$ Cantor set $C_1=$ set of points in $C$ that are adjacent to removed intervals $C_2=C\setminus C_1$ (all of the ""non-endpoints"") QUESTION: Is $C_2$ homeomorphic to $\overline {\mathbb Q}$, the set of irrationals? I see no obvious reason why they would not be homeomorphic. Both are zero dimensional, nowhere locally compact, cardinality $2^\omega$, etc.","['general-topology', 'irrational-numbers', 'cantor-set']"
1712296,What is the probability that at least two of the $n^{\rm th}$ biggest elements of $\mathbf{A}$ share the same column?,"I have a random matrix $\mathbf{A}=\left[a_{ij}\right]$ for all $i,j\in\{1,\ldots,n\}$. Every entry $a_{ij}$ of the matrix $\mathbf{A}$ is generated randomly with exponential distribution. The $a_{ij}$ are i.i.d and have the same parameter $\lambda$. Now, for each row $i$ of $\mathbf{A}$, I select the argument of the maximum element. That is, $$x_i=\arg\max\limits_{j} a_{ij}.$$ Let $X_{ij}$ be the binary random variable that is equal $1$ if $x_i=j$, and $0$ otherwise. Also, let $X_j=\sum_{i=1}^nX_{ij}$. I am interested in calculating the probability that the $n^{\rm th}$ biggest elements of $\mathbf{A}$ belongs to different columns. Or, alternatively, the probability that at least two of the $n^{\rm th}$ biggest elements of $\mathbf{A}$ share the same column. That is, $$\Pr\left[X_j\ge 2\right],$$ for all $j\in\{1,\ldots,n\}$. How can I solve this problem? I will give an example to illustrate the problem: Let $n=3$ and $\mathbf{A}$ given by: $$\mathbf{A}=\begin{bmatrix}
1 & 3 & 6\\
9 & 7 & 10\\
11 & 5 & 8
\end{bmatrix}.$$ Now, given $\mathbf{A}$, I can calculate $\mathbf{X}=[X_{ij}]$ as:
$$\mathbf{A}=\begin{bmatrix}
0 & 0 & 1\\
0 & 0 & 1\\
1 & 0 & 0
\end{bmatrix},$$
since $x_1=3,x_2=3$ and $x_3=1$. Then, I get $X_1=1,X_2=0$ and $X_3=2$. The three biggest elements of $\mathbf{A}$ are $6,10$ and $11$ which are not in different columns because $X_3\ge 2$. Given $\mathbf{A}$, I would like to know the probability that the $n$ biggest elements of $\mathbf{A}$ are in different columns? When I tried to solve the problem I find that 
$$\Pr\left[X_{ij}=1\right]=\dfrac{1}{n}.$$ After my work, I find that
$$\Pr\left[X_j\ge 2\right]=1-\left(1-\dfrac{1}{n}\right)^{n-1}-\left(1-\dfrac{1}{n}\right)^{n},$$
which gives me the probability the the $n$ biggest elements of $\mathbf{A}$ are in different columns equals to:
$$\left(1-\dfrac{1}{n}\right)^{n-1}\left(2-\dfrac{1}{n}\right)\to\dfrac{2}{e}.$$ What is weird is that, in my calculation, I never used the fact that the $a_{ij}$ are exponential random variables.",['probability-theory']
1712304,Pull back of line bundles between projective schemes,"Suppose $\phi:S_\bullet \rightarrow R_\bullet$ is a morphism of graded rings that has degree $d$, i.e. $\phi$ maps $S_n$ to $R_{dn}$ for all $n$. Then $\phi$ induces a morphism
\begin{equation}
\Phi:\text{Proj}~R_\bullet \setminus V(\phi(S_+)) \rightarrow \text{Proj}~S_\bullet 
\end{equation} If $V(\phi(S_+))$ is empty then $\Phi$ would be a morphism between two projective schemes. If both $R_\bullet$ and $S_\bullet$ are finitely generated in degree $1$, then does the line bundle $\mathcal{O}_{\text{Proj}S_\bullet}(1)$ pulls back to $\mathcal{O}_{\text{Proj}R_\bullet}(d)$? If it is not true generally, is it true when $S_0=R_0=A$, i.e. they are both graded $A$-algebra? If it is still not true, what about we let $A=k$ is a field? edit: Suppose with some new conditions, $\mathcal{O}_{\text{Proj}S_\bullet}(1)$ pulls back to $\mathcal{O}_{\text{Proj}R_\bullet}(d)$, then the global sections of $\mathcal{O}_{\text{Proj}S_\bullet}(1)$ pulls back to the global sections of $\mathcal{O}_{\text{Proj}R_\bullet}(d)$, is this the same as the map $S_1 \rightarrow R_d$?",['algebraic-geometry']
1712330,Deriving the (un)familiar arc-cosine integral identity,"In his Theoretical Physics , Joos condescends the following expression as ""the familiar arc-cosine form"": $-\int \frac{1}{\sqrt{a+2 bx-hx^2}} \, dx=\frac{1}{\sqrt{h}}\arccos \left[\frac{b-hx}{\sqrt{a+b^2h}}\right]$ The only reason it is now ""familiar"" to me is that I have been staring at it for weeks, wondering how to derive it.  I can prove it to be valid by substituting the terms into the form I do know how to derive. $d\arccos (u)=-\frac{du}{\sqrt{1-u^2}}$ But that doesn't tell me how it was originally derived.  I strongly suspect there is some geometric development which would illuminate the meaning of the variables and terms in the form Joos provides. Any suggestions?","['integration', 'trigonometry']"
1712361,Question about joint cdf calculated by ratio of areas,"If a point $(X,Y)$ is equally likely to fall anywhere in a circle/triangle/square or whatever, is it true that the joint CDF of $X Y$ is the ratio of bounded area (bounded by $X\le x$,and $Y\le y$) and the total area (bounded by the range of $x$ and $y$)? Because I calculated the joint CDF using double integral of joint PDF and find it is the same as the ratio. Could someone explain the reason? And is it also true that if the joint PDF is a constant, then the CDF is just that ratio multiplied by that constant value?","['statistics', 'probability']"
1712363,"Prove that if $f$ is zero at two points, then it is zero over the interval between them","Suppose $f$ satisfies $f''(x) + f'(x)g(x) - f(x) = 0$ for some function $g$. Prove that if $f$ is zero at two points, then it is zero over the interval between them. Let's suppose that $f(a) = f(b) = 0$ where $a<b$. Then using Rolles theorem, we know that there exists a $c$ such that $f'(c) = 0$ on $[a,b]$. Therefore, $f''(c) = f(c)$. Then how do I show that $f(x)=0$ on $[a,b]$?","['derivatives', 'calculus']"
1712371,Analytic function on unit disk has finitely many zeros,"I am studying complex analysis from Theodore Gamelin's text and Exercise 1 of chapter IX.2 says that if $f$ is analytic inside the open unit disk and continuous on its boundary that satisfies $|f(z)| = 1$ for $|z| = 1$, then $f$ is a finite Blaschke product. Clearly, this would imply that $f$ has only finitely many zeros in the open unit disk. 
But the proof of it already assumes this fact. 
So my question is that is it trivial that such an $f$ has finitely many zeros in the open unit disk?","['analyticity', 'complex-analysis', 'blaschke-products', 'conformal-geometry']"
1712374,Show that every rotation in $\mathbb{R^3}$ can be written as the product of two rotations of order 2.,"Show that every rotation in  $\mathbb{R^3}$ can be written as the
  product of two rotations of order 2. Here's my attempt at a solution: We know that any rotation in  $\mathbb{R^3}$ can be represented as the product of two reflections. So we write our rotation as $R_1R_2$ where the $R_j$ are reflections in  $\mathbb{R^3}$. We would like to show that $R_1R_2$=$(R_aR_b)(R_cR_d)$=$R_aR_bR_cR_d$ where $R_aR_b$ and $R_cR_d$ are rotations of order 2 in $\mathbb{R^3}$.
I think I have shown that a rotation $R_1R_2$, which is the product of reflections in the planes $\Pi_1$ and $\Pi_2$ respectively, has order two if and only if $\Pi_1$ and $\Pi_2$ are perpendicular. Next I thought it sufficient to show that $R_1$=$R_aR_b$ (and similarly for $R_2$ with $R_c$ and $R_d$) and as $R_1$ and $R_2$ are just any reflections, I now attempt to show that any reflection can be written as the product of two reflections in perpendicular planes. The form of a reflection in the plane $x.n=d$ in $\mathbb{R^3}$ is given as $R(x)=x+2(d-x.n)n$. Suppose that we have $R_a$ and $R_b$ as reflections in the perpendicular planes (that is, the planes have perpendicular normals), $x.n_a=d_a$ and $x.n_b=d_b$ respectively. As $n_a.n_b=0$, we can show that $R_aR_b(x)= x+2(d_1+d_2)-(x.(n_1+n_2))(n_1+n_2)$ which is of the required form. So that for any reflection $R$ in $x.n=d$, we can set $n_1,n_2,d_1,d_2$ such that $d_1+d_2=d$ and $n_1+n_2=n$. First off, is this correct, have I shown what I was required to show? I was also wondering if there may be a nicer, perhaps geometric way of going about the question. Apologies if my attempt at a solution is difficult to follow, I have next to zero experience in writing formal solutions.","['rotations', 'affine-geometry', 'geometry', '3d', 'linear-algebra']"
1712375,Perimeter and area of a regular n-gon.,"A friend of mine asked me how to derive the area and perimeter of a regular $n$ -gon with a radius $r$ for a design project he is working on. I came up with this, but I want to make sure I didn't make any errors before giving it to him. First, I assumed that the $n$ -gon was inscribed in a circle of radius r centered at the origin, with the first vertex of the circle being at the point $(r,0)$ . The vertices of the $n$ -gon will divide the circle into $n$ equal sections. Because the total angle of a circle is $2\pi$ , then the angle between the $x$ -axis and the second vertex is $\frac{2\pi}{n}$ . Using trigonometry, the coordinates of this vertex are $\left(r\cos\left(\frac{2\pi}{n}\right), r\sin\left(\frac{2\pi}{n}\right)\right)$ . Now, the origin, the first vertex, and the second vertex form a triangle. The edge of this triangle which touches the circle in two places, using the distance formula, will have a length of $r\sqrt{\left(\cos\left(\frac{2\pi}{n}\right)-1\right)^2 + \left(\sin\left(\frac{2\pi}{n}\right)\right)^2}$ . Now, the $n$ -gon will be made up of $n$ of these triangles, and so the perimeter is: $nr\sqrt{\left(\cos\left(\frac{2\pi}{n}\right)-1\right)^2 + \left(\sin\left(\frac{2\pi}{n}\right)\right)^2}$ . Now, the triangle has a base of $r$ and a height of $r\sin(\frac{2\pi}{n})$ . There area of a triangle is half the product of its base and height, so the area of the triangle is $\frac{r^2\sin\left(\frac{2\pi}{n}\right)}{2}$ . Again, the $n$ -gon is made up of $n$ of these triangles, so its area is: $\frac{nr^2\sin\left(\frac{2\pi}{n}\right)}{2}$","['trigonometry', 'geometry']"
1712378,"Construction of the Itô-integral in Øksendals book, why is this sequence a Cauchy sequence.","A quick summary of the things regarding my question is this: You have a probability space $(\Omega, \mathcal{F},P)$ and a filtration $\{\mathcal{F}_t\}$. You have a $f(t,\omega): [0,\infty)\times\Omega \rightarrow \mathbb{R}$ satisfying. It is $\mathcal{B}\times\mathcal{F}$-measurable. $f(t,\omega)$ is $\mathcal{F}$-adapted. For two real numbers S,T $E[\int_S^Tf(t,\omega)^2dt]<\infty$. A function $\phi$ is elementary if it satisfies the above points and is of the form : $$\phi(t,\omega)=\Sigma_j e_j(\omega)\mathcal{X}_{[t_j,t_{j+1})}$$ Øksendal then shows that there is a sequence of elemntary functions $\phi_n$ such that $E[\int_S^T|f-\phi_n|^2dt]\rightarrow 0$. Then he defines the integral as the $L^2$ limit of $\int_S^T\phi_n(t,\omega)dB_t(\omega)$. He says that the limit exists in $L^2$ since this is a Cauchy sequence. He refers to the Itô-isometry which he has proved for elementary functions, using this I get myself trying to show that the limit is Cauchy in $L^2$ : $$E[(\int_S^T\phi_n(t,\omega)dB_t(\omega)-\int_S^T\phi_m(t,\omega)dB_t(\omega))^2]=E[(\int_S^T(\phi_n-\phi_m)(t,\omega)dB_t(\omega))^2]=E[\int_S^T(\phi_n-\phi_m)^2dt]$$ But I still can't see how this can get arbitrary small as $n,m$ get big enough. I tried writing $(\phi_n-\phi_m)^2=(\phi_n-f+f-\phi_m)$ and then multiplaying out using the elementary square rules, and then trying to use Hölder's-inequality. But I wasn't able to finish it. Can you please help me?","['stochastic-processes', 'real-analysis', 'probability-theory']"
1712384,Determining where the function $f(z) = \frac{y+ix}{x^2+y^2}$ is (complex-)differentiable,"Determine at what points the function
  $$f(z) = \frac{y+ix}{x^2+y^2}$$
  is differentiable, and write the formula for $f'(z)$ at those points. Should I let $u = y+ix$ and $v = x^2 + y^2$ and then use the Cauchy-Riemann equation?","['derivatives', 'complex-analysis']"
1712405,Why a sheaf is an object that permits to get global information from local one?,"Is there somebody who can explain/show me why a sheaf is something that can permit us to move from the local to the global? An explanation for the layman would be fine. Usually I tend to abhor them, but, being self-thaught and without any guidance, I think that kind of explanation could be a useful starting point to get what to look at during a first reading on the topic (they make something more salient). Thanks a lot.","['algebraic-geometry', 'category-theory', 'soft-question', 'algebraic-topology', 'general-topology']"
1712414,Classification of $O(2)$-bundles in terms of characteristic classes.,"It is well-known that $SO(2)$-principal bundles over a manifold $M$ are topologically characterized by their first Chern class. I was wondering what was the characterization of $O(2)$-bundles in terms of characteristic classes. I guess the first and second Setiefel-Whitney classes are necessary for the topological characterization of $O(2)$-bundles, but they can't be enough, because if $w_{1} = 0$ then one should recover the classification of $SO(2)$-bundles, which is given by the first Chern class and not by the second Stiefel-Whitney class. Thanks.","['fiber-bundles', 'differential-topology', 'algebraic-topology', 'general-topology', 'differential-geometry']"
1712422,Method of standardization of essay grades from a number of graders,"Basically, there is a group of us grading a few hundred essays. We divided the number up so each of us grade 50, assigning a score 0-100 given a rubric. However, there is still subjectivity in the rubric, so we would like to normalize the grades. By this I mean if I am grading hard and someone else is grading easy, we want the final grades to be in the middle for the sake of equality. Here was my initial thought: Each grader will assign grades to a sample of essays (n=50), and the population will be the combination of all of the samples (n=400). The ""normalized"" grade would be: Normalized grade = (original grade)+((population average) - (sample average)) Where the sample average is the average grade of whatever sample that specific essay was part of. This seemed a little rudimentary, but that is also what we are looking for. However, is this statistically appropriate? Would using z-scores be more appropriate? If so, how would that be used in this context, provided multiple samples? My concern with z-scores is that our scale and units are the same, some folks are just grading harder than others. Any thoughts are appreciated, thanks! Edit:
Another idea Normalized grade = (original grade)*((population mean)/(sample mean)) This produced similar but not the same results, resulting in round differences when rounded to a whole number. So... which method is the most appropriate for this application? Thanks again!","['statistics', 'standard-deviation']"
1712436,Zeros of analytic function accumulating to the boundary,"By $\mathbb D$ denote the open unit disc in $\mathbb C$. Suppose that $f : \overline{\mathbb D}\to\mathbb C$ is analytic on $\mathbb D$ and continuous on $\overline{\mathbb D}$. Assume now that there are infinitely many distinct points $z_n\in\mathbb D$ which accumulate to the boundary of $\mathbb D$ such that $f(z_n) = 0$ for all $n\in\mathbb N$. Does it then follow that $f\equiv 0$? The point is, we cannot make use of the usual identity theorem because the accumulation point of the zeros is not in $\mathbb D$. So, is there any ""improvement"" of that theorem covering the above case?","['complex-analysis', 'roots']"
1712469,Calculate Tangent Points to Circle,"Problem Given a circle with radius $r = 2$ and center $C = (4,2)$ and a point $P = (-1,2)$ outside the circle. How do I calculate the coordinates of two tangent points to the circle, given that the tangents both have to go through $P$? My (sad) try All I can think of is finding the equation for the circle, which is \begin{equation}
  (x-4)^{2} + (y-2)^{2} = 4.
\end{equation} I have no idea what to do next. (I don't even if finding the circle's equation is relevant.) Update After using Dhanush Krishna'a answer, I can (easily) find the two intersection points: \begin{equation}
  (x_{1,2}, y_{1,2}) = \frac{2}{5}(8, 5\pm\sqrt{21}).
\end{equation}",['geometry']
1712471,Insane dumb question alert: $\varnothing \cup A$ = $A$?,"I am learning $\sigma$ algebra in probability and I just couldn't shake off the feeling that 
$$\varnothing \cup A = A$$ is not true I know it sounds insane but let me explain Let $\mathcal{F}$ be the $\sigma$- algebra of a set $X$, then $\mathcal{F}$ satisfies: $\varnothing \in \mathcal{F}$, complement and closure properties. For example $\mathcal{F} = 2^X = \{\varnothing, x_1, x_2, \ldots\}$ Take $A\subset \mathcal{F}$, $\varnothing \notin A$, for example $A = \mathcal{F} \backslash \varnothing$ then isn't it true $\varnothing \cup A \neq A$? Confused!","['measure-theory', 'elementary-set-theory']"
1712481,Simplifying the integral $\int\frac{dx}{(3 + 2\sin x - \cos x)}$ by an easy approach,"$$I=\displaystyle\int\frac{dx}{(3 + 2\sin x - \cos x)}$$ If $$\tan\left(\frac{x}{2}\right)=u$$ or $$x=2\cdot\tan^{-1}(u)$$ Then, $$\sin{x}=\dfrac{2u}{1+u^2}$$ $$\cos{x}=\dfrac{1-u^2}{1+u^2}$$ $$dx=\dfrac{2}{1+u^2}$$ Substitute $$\tan\left(\dfrac{x}{2}\right)=u$$ Let us simplify the integrand before integrating $$\dfrac{1}{3+2\sin{x}-\cos{x}}$$ $$=\dfrac{1}{3+2\frac{2u}{1+u^2}-\frac{1-u^2}{1+u^2}}$$ $$=\dfrac{1}{3+\frac{4u-1+u^2}{1+u^2}}$$ $$=\dfrac{1}{\frac{4u-1+u^2+3+3u^2}{1+u^2}}$$ $$=\dfrac{1+u^2}{4u^2+4u+2}$$ $$=\dfrac{1+u^2}{(2u+1)^2+1}$$ $$I=\displaystyle\int\dfrac{1+u^2}{(2u+1)^2+1}\cdot\dfrac{2}{1+u^2}\ du$$ $$=\displaystyle\int\dfrac{1}{(2u+1)^2+1}\ 2\,du$$ Now, Take : $$v=2u+1$$ Therefore, $$dv=2\,du$$ $$I=\displaystyle\int\dfrac{1}{v^2+1}\ dv$$ $$I=\tan^{-1}(v)$$ Substitute everything back $$I=\tan^{-1}(2u+1)$$ $$I=\tan^{-1}\left(2\tan\left(\frac{x}{2}\right)+1\right)$$ $$\boxed{\displaystyle\int\frac{dx}{(3 + 2\sin x - \cos x)} = \tan^{-1}\left(2\tan\left(\frac{x}{2}\right)+1\right)+C}$$ I know that my approach is also not so difficult but still I think there must be an relatively easy approach to this integral. I have tried many different things using trigonometric identities but nothing seems to bring to the solution easily. Kindly help me out.","['integration', 'trigonometry', 'inverse-function', 'calculus']"
1712556,"If $a^{-1} b^2 a=b^3$ and $b^{-1}a^2 b=a^3$ with $a,b\in G$, $G$ a group, then $a=b=1$. [duplicate]","This question already has answers here : A Particular Two-Variable System in a Group (4 answers) Closed 8 years ago . I had this problem. Let $G$ be a group and $a,b\in G$ such that $a^{-1} b^2 a=b^3$ and $b^{-1}a^2 b=a^3$. Prove that $a=b=1$. Somehow I solved it, but it was a bit tedious (for example in some place I got to something like $b^3 =a^{-3}b^{-1}a^2a^{-3}b^{-1}a^2a^{-3}b^{-1}a^2=a^{-3}b^{-1}a^{-1}b^{-1}a^{-1}b^{-1}a^{2}$). I first proved that $b=a^{-2}ba^3$ (It's also true that $b=a^2ba^{-3}$) and then (Details not included) that $b^3=ab^6a^3$. Then (Details not included) that $b^3 a^3=a^{-1}b$, then $b^{-1}=a^4$ and from that $a^2=a^3$, from which $a=e$ (There are a lot of lines covering these details but there may be a mistake in these lines). It's the same to get $b=e$. So, is there any shorter, or less tedious way to prove it?","['abstract-algebra', 'group-theory']"
1712644,Can a increasing function from $\mathbb{R} \to \mathbb{R}$ be bounded?,A function $$f: \mathbb{R} \to \mathbb{R}$$ be increasing and yet be bounded?,['functions']
