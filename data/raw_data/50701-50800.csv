question_id,title,body,tags
521624,Conditional Independence and Mutual information,"I have a question concerning conditional independence. According to wikipedia (yes, maybe not the best source) two random variables are conditionally independent given a third if 
$$p(x,y|z) = p(x|z)p(y|z)\:\:\forall z.$$ However, I read a mutual information definition of conditional independence that said that two random variables are conditionally independent if 
$$I[X|Z:Y|Z] = \left\langle\left\langle\log \frac{p(x,y|z)}{p(x|z)p(y|z)}\right\rangle_{X,Y|Z}\right\rangle_Z = 0.$$ Now, I am not sure whether the two equations are equivalent. The first definitely implies the last. However, the last does not imply the first (or does it?), since there could be $z$ for which $p(x,y|z) \not= p(x|z)p(y|z)$ but the set of all $z$ for which that is true has measure zero. I guess the last equation means conditionally independence only almost surely (in terms of $z$) but not pointwise, but the first requires pointwise equality. Am I correct? If not, where is my mistake?","['probability-theory', 'information-theory', 'stochastic-calculus']"
521627,On the Hilbert function of projective schemes,"Let $X \subset \mathbb{P}^n$ be a projective subscheme (not necessarily reduced or irreducible). Denote by $I_X$ the ideal of $X$ i.e., $\Gamma_*(\mathcal{I}_X)$. There are two definitions of Hilbert functions that is used in the literature. One is the function $f(t)=\mbox{dim}(S/I_X)_t$, the $t$-graded part of the module where $S$ is the polynomial ring $k[X_0,...,X_n]$ and $t \in \mathbb{Z}$. The other definition is $f(t)=h^0(\mathcal{O}_X(t))$ for any integer $t$. Why are these two definitions compatible? I understand why they are the same for $t$ large enough.","['commutative-algebra', 'algebraic-geometry', 'projective-schemes']"
521658,The ring of convergent power series over $\mathbb C$ isn't noetherian,How can one prove that the ring of convergent everywhere power series in $\mathbb C[[z]]$ isn't Noetherian?,"['commutative-algebra', 'ring-theory', 'abstract-algebra']"
521675,"Is a rational-valued continuous function $f\colon[0,1]\to\mathbb{R}$ constant?","Let $f\colon[0,1]\to\mathbb{R}$ be continuous such that $f(x)\in\mathbb{Q}$ for any $x\in[0,1]$. Intuitively I feel that $f$ is constant, since $\mathbb{Q}$ is dense in $\mathbb{R}$. How can I formally write this down?","['continuity', 'real-analysis']"
521685,Integral $\int_0^\infty\frac{dx}{\frac{x^4-1}{x\cos(\pi\ln x)+1}+2x^2+2}$,"I need your help with this integral:
$$\int_0^\infty\frac{dx}{\frac{x^4-1}{x\cos(\pi\ln x)+1}+2\,x^2+2}.$$ I wasn't able to evaluate it in a closed form, although an approximate numerical evaluation suggested its value could be $\frac{\pi}{4}$.","['closed-form', 'integration', 'logarithms', 'trigonometry', 'conjectures']"
521690,Is connectedness $\implies $ local connectedness?,"Let $X$ be a connected topological space.
Then I wonder that $X $ can be locally connected or not.
I think the title of my question is NOT correct considering a Euclidean space like $\mathbb R^n$.
Do you think so?? Also, conversely, if $X$ is a locally connected, and if some conditions are given additionally, Can $X$ be a connected space?
I think the latter case may be possible (not certainly), but don't know the necessary condition although it is true. Please somebody tell me answers of them~~","['general-topology', 'connectedness']"
521691,Why is this defined even when divided by zero,"so I've got $$\dfrac{x^3-4x^2+3x}{x^2-1}$$ and want to calculate the asymptotes. There's one a $x=-1$ since the function is not defined there. But the function seems to be defined for $x=1$. How come? 
It should be undefined at $x=1$ since $f(1)=1^2-1 = 0$","['algebra-precalculus', 'functions']"
521756,The map $w=f(z)=\frac{i(1-z)}{1+z}$.,I am now studying complex analysis now. Now I want to find the image of right half plane $Re(z)>0$ under the linear transformation $w=f(z)=\frac{i(1-z)}{1+z}$.,['complex-analysis']
521775,Prove that x is rational,"Let $x$ be a real number with the properties that $x^3+x$ and $x^5+x$ are rational.
Prove that $x$ is rational. Denote $a=x^3+x$; $b=x^5+x$. We can multiply and add them together until we get the desired result. I also know some non-elementary proofs of this, but have you some nice elementary proofs? Thank you.","['algebra-precalculus', 'rational-numbers']"
521809,Is this implication true? [duplicate],"This question already has answers here : Give an example of a bounded, non-convergent real sequence $(a_n)$ s.t. $a_n-a_{n-1}\rightarrow 0$ [duplicate] (2 answers) Closed 10 years ago . Suppose that a real sequence $u_n$ is such that $$u_{n+1}-u_n \rightarrow0$$ That is not enough to prove that $u_n$ is convergent (take $u_n=ln(n)$) Now what if $u_n$ is bounded ? I guess it does converge, but how to prove this ? I tried to show that it had only one accumulation point...","['convergence-divergence', 'sequences-and-series']"
521830,An ergodic theorem on the circle,"Let $S^1$ be a circle (i.e. a closed $1$-dim. manifold) and let $F$ be a non-vanishing smooth vector field on $S^1$. Denote by $(t,x)   \mapsto \Phi_t^x$ the flow generated by $F$. I want to show that there exists an absolutely continuous probability measure $\pi$
with strictly positive density $\rho$ such that  for every bounded measurable function $f$ and every $x\in S^1$ $  \lim_{t\rightarrow \infty}    \frac{1}{t}\int_0^t  f(\Phi_s^x) ds   \ = \  \int_{S^1} f(x) \pi (dx) \ \ \  \ $   (*) From (*) it follows that $\pi$ is invariant, i.e. $\int_{S^1} f(\Phi_t^x) \pi(dx) \ = \ \int_{S^1} f(x) \pi(dx)$. I would also like to show that $\pi$ is the unique invariant measure. What I did until now: Denote by $\tau$ the time needed to return in $x$ when starting from $x$ and following the flow $\Phi$ and denote by $n_t$ the number of times $t\mapsto \Phi_t^x$ returned in $x$ up to time $t$. Observe that
$0<\tau<\text{const}$ and that both $\tau$ and $n_t$ are independent of $x$. Then
$    \frac{1}{t}\int_0^t  f(\Phi_s^x) ds   \ = \     \frac{n_t\tau}{t}  \  \frac{1}{n_t } \sum_{k=1}^{n_t}   \   \frac{1}{\tau}\int_0^{\tau} f(\Phi_s^x) ds   \  +   \   \frac{1}{t} \int_{n_t\tau}^t f(\Phi_s^x) ds   $ So using the boundedness of $f$ and of $t-n_t\tau$ and the fact that $\frac{n_t\tau}{t}\rightarrow 1$ I get for every $x\in S^1$ $ \frac{1}{t}\int_0^t  f(\Phi_s^x) ds   \rightarrow \     \frac{1}{\tau}\int_0^{\tau} f(\Phi_s^x) ds  $ with the right hand side in fact independent of $x$. Now I guess I should use some Riesz representation theorem for functionals to show existence of $\pi$ such that for every bounded measurable function $ \frac{1}{\tau}\int_0^{\tau} f(\Phi_s^x) ds    \   =   \   \int_{S^1} f(x) \pi (dx)  $ Can somebody hint to a precise reference or give some alternative (maybe more selfcontained) argument? I have no clue for the moment on how to show the existence of $\rho$ (or to find a counterexample if it is not true).","['dynamical-systems', 'ergodic-theory', 'measure-theory', 'ordinary-differential-equations']"
521867,"Family of connected sets, proving union is connected","I am having some trouble trying to prove the following statement:$$$$
Let $(X,d)$ be a metric space and $\mathcal A$ a family of connected sets in $X$ such that for every pair of subsets $A,B \in \mathcal A$ there exist $A_0$,...,$A_n \in \mathcal A$ that satisfy $A_0=A$, $A_n=B$ and $A_i \cap A_{i+1} \neq \emptyset$ for every i=0,...,n-1. Prove that $\bigcup_{A \in \mathcal A}A$ is connected.
$$$$I've tried to prove it by the absurd: Suppose the union is disconnected, then there exist $U$ and $V$ nonempty disjoint open sets such that $\bigcup_{A \in \mathcal A}A=U \cup V$. Then, there is $A \in \bigcup_{A \in \mathcal A}A$ : $A \subset V$ and $A \cap V=\emptyset$. The same argument applies for $B \in \bigcup_{A \in \mathcal A}A$ with $B \subset U$ ($A$ and $B$ both nonempty). By hypothesis, $A=A_0$ and $B=A_n$. In this part I got stuck. I know I have to use the fact that the intersection of $A_i$ and $A_{i+1}$ is nonempty and that all the sets in $\mathcal A$ are connected, but I don't know where to use that.","['connectedness', 'analysis']"
521898,Finding Revenue Function and Max Revenue,"Studying for a midterm. The demand function for a manufacture's product is $p=1000-\frac1{80} q$ Where $p$ is the
price (in dollars) per unit when $q$ units are demanded (per week) by consumers. Answer
the following questions. 1) Write the Revenue function $R(q)$ in terms of $q$. 2) Find the level of production that will maximize revenue. 3)Suppose there is a fixed cost of  $174500, to set up the manufacture and a producing cost of 125 dollars per unit. Find the break even quantities. First: To find the revenue function. I know that Revenue=$p*q$ so: $$R(q)=p*q$$ $$p=1000-\frac1{80}q$$ $$R(q)=(1000-\frac1{80}q)*q$$ $$=1000q-\frac1{80}q^2$$ I believe this is right. Now to find the level of production to maxime revenue we must find the first derivative of the revenue function. $$R'(q)=1000-2(\frac1{80}q)$$
$$2(\frac1{80}q)=1000$$
$$\frac1{80}q=500$$
$$q=40000$$
Input this into our demand function: $$p=1000-\frac1{80}40000$$
$$p=500$$ Now I don't know if this is right, please correct me if I'm wrong. Now I'm not sure how to find the break even quantities, I would appreciate help, at least to get me started. Cheers.","['finance', 'calculus', 'algebra-precalculus']"
521928,Show $e^{D}(f(x)) = f(x+1)$ where $D$ is the derivative operator,"I would appreciate help showing $e^{D}(f(x)) = f(x+1)$ Where $D$ is the linear operator $D: \mathbb{C}[x] \rightarrow \mathbb{C}[x]$ where (in the context where this statement arose) $x \in \mathbb{N}$; $f(x) \mapsto \frac{d}{dx} f(x)$ By the Taylor series expansion $e^{D} = \sum_{n=0}^{\infty} \frac{D^n}{n!}$ $(1)$ Then $e^{D} (f(x)) = f(x) + f'(x) + \frac{f''(x)}{2!} +\dots$ I would appreciate help showing that the above line $(1)$ is equal to $f(x +1)$ This is what I have tried, but it feels forced: for a Taylor series representation of $f(x +1)$ near $x$ I could write $f(x+1) = f(x) + f'(x)(x+1 - x) + \frac{f''(x)}{2!}(x+1 -x)^2 \dots$ This then is equal to the RHS of line $(1)$. Could this line of thinking be correct? Thanks very much.",['analysis']
521929,What did Newton and Leibniz actually discover?,Most popular sources credit Newton and Leibniz with the creation and the discovery of calculus. However there are many things that are normally regarded as a part of calculus (such as the notion of a limit with its $\epsilon$-$\delta$ definition) that seem to have been developed only much later (in this case in the late $18$th and early $19$th century). Hence the question - what is it that Newton and Leibniz discovered?,"['calculus', 'reference-request', 'math-history']"
521935,What is pluripotential theory?,"My tutor for electromagnetism showed me a problem about point charges in a disk and their equilibria. He referred me to a subject called ""pluripotential theory"". I googled it and I did not find what I was looking for at all! So my question is, what is pluripotential theory, what is it used for and are there any interesting and/or intuitive aspects/results of the field. EDIT: I might have been unclear with the phrasing of the question. I am not looking for an account of potentials of more than one point charge. I am aware that pluripotential theory is a field in it's own and this is what I am interested in learning about.","['several-complex-variables', 'complex-analysis']"
521936,Find a point $l$ in the closure of $A$ so that no sequence with values in $A$ converges to $l$. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question Find an example for this. You can choose which space to use. An example the professor gave had to do with the Box Topology, but I was wondering if there was an easier example. Thanks.",['general-topology']
521957,"Prove function (0, ∞) to (0, ∞) can't exist if $(f(x))^2>(f(x+y))((f(x)+y))$","So we're trying to prove that no function exists $f: (0,\infty) \rightarrow(0,\infty)$ such that $f(x)^2\ge f(x+y) (f(x)+y)\quad x,y\gt0$ I've tried to break it up into 3 cases to show if $x\gt y$ and  $x\lt y$ and $x= y$ to show that $f(x+y)\gt f(x)$, but doesn't that depend on the initial function? i.e $\frac{1}{x}\gt\frac{1}{x+y}$ not $\lt$ like I wanted to show. I'm just stumped at how to prove this for any function. We've tried to set it all up on one side and do the quadratic equation to try and chase down a numerical value to prove that $f(x+y)\gt f(x)$ so we could then say that $f(x+y)f(x)\gt f(x)f(x)$ which would imply that $f(x+y)f(x)\gt f(x)^2$ so our original function of $f(x)^2\ge((f(x+y))((f(x)+y))$ could be rewritten as $f(x)^2\ge((f(x))^2+f(x+y)y)$ which we know $f(x)^2 \lt f(x)^2 + y$ so we'd have a contradiction. But I can never seem to figure out how to write a formal proof of the ideas I have. If my idea was even a valid idea. Thanks ahead of time! Just had an idea to find some value such that it is always contradictory like choosing $y=x^2-x$, but then $y$ could have a negative value so I'm going to have to find a new y=, but that's the path I'm going now!","['multivariable-calculus', 'calculus', 'functions']"
521993,Integral $\int_1^\infty\operatorname{arccot}\left(1+\frac{2\pi}{\operatorname{arcoth}x-\operatorname{arccsc}x}\right)\frac{\mathrm dx}{\sqrt{x^2-1}}$,"Consider the following integral: $$\mathcal{I}=\int_1^\infty\operatorname{arccot}\left(1+\frac{2\,\pi}{\operatorname{arcoth}x\,-\,\operatorname{arccsc}x}\right)\frac{\mathrm dx}{\sqrt{x^2-1}}\,,$$ where $\operatorname{arccsc}$ is the inverse cosecant , $\operatorname{arccot}$ is the inverse cotangent and $\operatorname{arcoth}x$ is the inverse hyperbolic cotangent . Approximate numerical integration suggests a possible closed form: $$\mathcal{I}\stackrel?=\frac{\pi\,\ln\pi}4-\frac{3\,\pi\,\ln2}8.$$ I was not able to rigorously establish the equality, but the value is correct up to at least $900$ decimal digits. Is it the correct exact value of the integral $\,\mathcal{I}$ ?","['closed-form', 'hyperbolic-functions', 'integration', 'trigonometry', 'conjectures']"
521997,Characterizing the domain of definition of a rational map in terms of the function field homomorphism,"The following is an exercise in Liu (exercise 3.3.13(b), page 111): Let $f$ be a dominant rational map $X\dashrightarrow Y$ where $X$ and $Y$ are integral schemes of finite type over a locally Noetherian scheme $S$. Show that a point $x\in X$ lies in the domain of definition if and only if there is a point $y\in Y$ such that $\mathscr{O}_{Y,y}$ is dominated by $\mathscr{O}_{X,x}$ under the field extension $K(Y)\to K(X)$. This reduces in a straightforward way to a the affine case, where it becomes a statement in commutative algebra. The proof of that statement, as far as I can tell, is just as straightforward. The thing that has me worried is that I believe this holds with no Noetherianness condition on $S$ ($S$ can be an arbitrary scheme) and no finite type condition on $X$. Those conditions, of course, are pretty mild, so it's not surprising that Liu would include them anyways, but I want to make sure that I'm not missing a major obstruction. Here's my statement/idea of proof of that local case: Let $A$ and $B$ be $R$-algebras, with $A$ finite type, and suppose we have a homomorphism $f:A\to B_\beta$ for some $\beta\in B$. Then for any prime $\mathfrak p$ of B such that $f(A)\subseteq B_\beta \cap B_\mathfrak p$, there is $\beta'\notin \mathfrak p$ such that $f(A)\subseteq B_\beta\cap B_{\beta'}$. The proof is shorter than the statement. Choose $R$-generators $x_1,\dots,x_n$ for $A$. Then $f$ is given by $f(x_i) = f_i/\beta^n$. The condition $f(A)\subseteq B_\mathfrak p$ means that we have $t_i\notin\mathfrak p$ so that $t_if(x_i)\in B$. If we let $\beta'=\prod t_i$, then $f(A)\subseteq B_\mathfrak p$, Q.E.D. A note to relate this to global case: having an affine patch of $Y$ whose coordinate ring maps into the local ring is just as good as having a point whose local ring is dominated: we can just pull back the maximal ideal of the local ring, and then localize. Certainly knowing $A$ can be described by only finitely many relations on the $x_i$ comes only if $S$ is locally Noetherian, but is there any reason we benefit from that? And is there any reason why we would need some sort of finiteness conditions on $X$?","['algebraic-geometry', 'birational-geometry']"
522020,A discontinuous function such that $f(x + y) = f(x) + f(y)$ [duplicate],This question already has an answer here : Overview of basic facts about Cauchy functional equation (1 answer) Closed 10 years ago . Is it possible to construct a function $f \colon \mathbb{R} \to \mathbb{R}$ such that $$f(x + y) = f(x) + f(y)$$ and $f$ is not continuous?,"['continuity', 'real-analysis']"
522049,Maximum number of points on a sphere,"How can I calculate the maximum number of points that can be placed on the surface of a unit sphere, if any two points wont be closer than 1 unit?",['geometry']
522057,Delta-Epsilon Proofs,"I am trying to prove the following limits using the delta-epsilon method. Can you help me out? 1.$$ \lim_{(x,y)\to(2,3)}(3x^2y^2 + 4xy-12) = 120$$
2.$$ \lim_{(x,y)\to(0,0)}\frac{5x^2y}{x^2+y^2} = 0$$ How do I work this out with the upper and lower boundaries?",['multivariable-calculus']
522077,Complete and elementary proof that $(a^x - 1)/x $ converges as x goes to 0,"Anybody who has taken a calculus course knows that
$$\lim_{x \to 0} \frac{a^x - 1}{x}$$
exists for any positive real number $a$, simply because the limit is by definition the derivative of the function $a^x$ at $x = 0$.  However, for this argument to be non-circular one must have an independent technique for proving that $a^x$ is differentiable.  The standard approach involves the following two steps: 1) Calculate the derivative of $\log_a x$ by reducing it to the calculation of
$$\lim_{h \to 0} (1 + h)^{\frac{1}{h}}$$ 2) Apply the inverse function theorem. I find this unsatisfying for two reasons.  First, the inverse function theorem is not entirely trivial, even in one variable.  Second, the limit in step 1 is quite difficult; in books it is often calculated along the sequence $h = \frac{1}{n}$ where $n$ runs over the positive integers, but doing the full calculation seems to be quite a bit more difficult (if one hopes to avoid circular reasoning). So I would like a different argument which uses only the elementary theory of limits and whatever algebra is needed.  For instance, I would like to avoid logarithms if their use involves an appeal to the inverse function theorem.  Is this possible?","['calculus', 'limits']"
522085,Unique of eigenbasis of self-adjoint operator.,"Today I am reading an article: Eigenvalues and sums of Hermitian matrices there is an exercise copy from that article: Exercise 1 Suppose that the eigenvalues $\lambda_1(A)>\cdots>\lambda_n(A)$ of an $n\times n$ Hermitian matrix are distinct. Show that the associated eigenbasis $u_1(A),\cdots,u_n(A)$ is unique up to rotating each individual eigenvector $u_j(A)$ by a complex phase $e^{i\theta_j}$. In particular, the spectral projections $P_j(A):=u_j(A)^*u_j(A)$ are unique. what happens when there is eigenvalue multiplicity? Assume $A$ is the matrix of self-adjoint operator $\mathcal{A}$ under some property basis of $V_{\Bbb{C}}$. I don't know why eigenbasis $u_1(A),\cdots,u_n(A)$ is unique up to rotating. If we multiply a complex number $c_k \not=0$ respectively, then $c_1u_1(A),\cdots,c_nu_n(A)$ is also a basis of $V_{\Bbb{C}}$ consist of $\mathcal{A}$'s eigenvectors,under this basis, $\mathcal{A}$ correspond to a diagonal matrix consist of eigenvalues: $\text{diag}\{\lambda_1,\cdots,\lambda_n\}$. I think it is unique up to multiply a complex number $c_k$ respectively. what's wrong?","['matrices', 'linear-algebra']"
522131,Quotient spaces in linear algebra,"There's a statement in some notes I'm reading that goes like this: ""...$V/U$ is a 'simplified version' of $V$ where the elements of $U$ are ignored"" ($V$ and $U$ are vector spaces). I'm still trying to understand this idea: can someone shed some light on why we ignore $U$ in $V/U$?  I mean I understand that everything belonging to $U$ falls in the equivalence class $[0]$, but is that the sense in which we are ""ignoring"" $U$?  Is a quotient space a set of equivalence classes?  That is to say that, if we have equivalent affine subsets $v_1 + U = v_2 + U$, are $[v_1]$ and $[v_2]$ the same elements in $U/V$?  If this is the case, then aren't we ignoring certain elements of $V$ (like we would ignore $[v_2]$ in this case) because all equivalent affine subsets are redundancies and are therefore collapsed into one respective equivalence class?","['vector-spaces', 'equivalence-relations', 'linear-algebra', 'definition']"
522158,"Proving it doesn't exist a homeomorphism between $\mathbb R$ and $\mathbb R^n$, $n>1$.","I have to prove that for $n \ge 2$, there doesn't exist a homeomorphism between $\mathbb R$ and $\mathbb R^n$. Could anyone give me a hint on how could I prove this?","['metric-spaces', 'analysis']"
522163,How prove this analysis function $a\le\frac{1}{2}$,"let $$f(x)=\begin{cases}
x\sin{\dfrac{1}{x}}&x\neq 0\\
0&x=0
\end{cases}$$
  show that:there exsit $M>0,(x^2+y^2\neq 0)$ ,
  $$F(x,y)=\dfrac{f(x)-f(y)}{|x-y|^{a}}|\le M  \Longleftrightarrow a\le\dfrac{1}{2}$$ My try: (1)if $a\le\dfrac{1}{2}$, then
  $$\dfrac{f(x)-f(y)}{|x-y|^a}=\dfrac{x\sin{\frac{1}{x}}-y\sin{\frac{1}{y}}}{|x-y|^a}$$
  then How can prove
  $$|x\sin{\frac{1}{x}}-y\sin{\frac{1}{y}}|<M|x-y|^a,a\le\dfrac{1}{2}$$ By other hand : and if for any $x,y\in R$,and such $$ |x\sin{\frac{1}{x}}-y\sin{\frac{1}{y}}|<M|x-y|^a$$
  then How prove must $a\le\dfrac{1}{2}$? I think this is nice problem,Thank you By the way:when I deal this problem, I find this nice equality
$$|x\sin{\frac{1}{x}}-y\sin{\frac{1}{y}}|<2\sqrt{|x-y|}$$ But I can't prove  ,Thank you",['analysis']
522164,"The Probabilistic Method, Section 2.5. Unbalancing Lights","I am working through Alon's and Spencer's Probabilistic Method book. In Section 2.5, Unbalancing light, in the proof of Theorem 2.5.1, it is mentioned that $R_i$ has distribution $S_n$, the distribution of the sum of $n$ independent uniform $\{-1,1\}$ random variables, and so
$$
E[|S_n|]=\left(\sqrt{\frac{2}{\pi}}+o(1)\right)\sqrt{n},
$$
with asymptotics found by estimating $S_n$ by $\sqrt{n}N$, where $N$ is standard normal. It is easy to see from the CLT that if $S_n=\sum_{i=1}^n X_i$ with $X_i$ all i.i.d., $\mathcal{U}(\{-1,+1\})$, then $S_n/\sqrt{n}\to G\sim \mathcal{N}(0,1)$ in distribution. By the continuous mapping theorem, $|S_n|/\sqrt{n}\to |G|$, which is where the $\sqrt{2/\pi}$ comes from. However, how is
$$
|S_n|/\sqrt{n}\to |G|~\text{in distribution}
\qquad\Longrightarrow\qquad
E|S_n|/\sqrt{n}\to E|G|
$$
justified? It seems to me that the proof is incomplete, as integration to the limit would require for instance uniform integrability, but I have not been able to show it. Is it even the case? Is there any other way to prove this rigorously? Any hint or help much appreciated!","['probability-theory', 'weak-convergence', 'uniform-integrability']"
522172,A better proof for $\det(P) = \pm1$ if $P$ is an orthogonal matrix,"Looking for elementary proof for $\rm~det(\textbf{P})$ = $\pm 1$ if $P$ is an orthogonal matrix.  I prefer a proof without using determinant of transpose matrix. My First Proof, with $\det(\textbf{P}^{t}) = \det(\textbf{P})$ If $P$ is orthogonal matrix, $\textbf{P}^{t}=\textbf{P}^{-1}$ . So, $$\det(\textbf{P}^{t}\textbf{P})=\det(\textbf{I}) \implies \det(\textbf{P}^{t}\textbf{P}) = 1 \implies \det(\textbf{P}^{t}) \det(\textbf{P}) = 1$$ because $ \det(\textbf{P}^{t}) = \det(\textbf{P})$ . Therefore, $\det(\textbf{P}^{t})=\det(\textbf{P}) = \pm 1$ . My Second Proof,  without $\det(\textbf{P}^{t}) = \det(\textbf{P})$ Let $\lambda$ be an eigenvalue for orthogonal matrix $\textbf{P}$ . $$\textbf{P}\vec{v}=\lambda\vec{v},\quad\vec{v} \neq \vec{0}$$ $$\implies \rVert \textbf{P}\vec{v}\lVert = \lVert \lambda\vec{v} \lVert \implies \rVert \textbf{P}\vec{v} \lVert = \rvert \lambda \ \lvert \lVert \vec{v} \rVert = 1$$ because $\lVert \vec{v} \rVert = 1$ Therefore $\lvert \lambda \rvert = 1$ because $\textbf{P}$ is orthonormal matrix. $$\textbf{P} = \textbf{P}^{t}$$ Therefore $\textbf{P} = \textbf{U}^{t}\Lambda\textbf{U} $ $$\det(\textbf{U}^{t}\Lambda\textbf{U}) = \det(\textbf{U}^{t})\det(\Lambda)\det(\textbf{U})$$ $$\det(\textbf{U}^{t}\Lambda\textbf{U}) = \det(\textbf{U}^{t})\det(\textbf{U})\det(\Lambda)$$ $$\det(\textbf{U}^{t})\det(\textbf{U}) = 1 $$ (because $\textbf{U}$ is orthogonal matrix}) $$\det(\textbf{P}) = \det(\textbf{U}^{t}\Lambda\textbf{U}) = \det(\Lambda) = \prod_{i=1}^{n}\lambda_i = \pm 1 $$ $$\implies \det(\textbf{P}) = \pm 1$$","['matrices', 'linear-algebra', 'determinant']"
522186,Is there an elementary introduction to higher order functions?,"I am teaching a pre-calculus course (using the textbook by Michael Sullivan if it helps), and I realized that higher order functions seem to show up in with some frequency in pre-calculus and calculus. Since these students are particularly good (high school students taking college classes), I introduced this concept to them. Without being too rigorous, let me make some definitions. A first order function will be a function of the form, $f:A\to B$ such that $A$, and $B$ are (nice enough) subsets of $\mathbb{R}$. $\phantom{}$ An n-th order functions will be a function of the form, $f:A\to B$ such that either $A$ or $B$ are (perhaps sufficiently nice) sets of functions of order at most $n-1$. $\phantom{}$ The plethora of all the $n$-th order functions will be collectively known as higher order functions. The examples that they have seen are families of functions such as, $$a\mapsto (x\mapsto  f(ax))$$ $$r\mapsto (x\mapsto  x^r).$$ (in fact they have seen animations of these and others in mathematica in fact I used their experience with this program to help illustrate the concept). Some other examples that they have seen that are of the form $$PFun(\mathbb{R},\mathbb{R})\to PFun(\mathbb{R},\mathbb{R}),$$ where $PFun(\mathbb{R},\mathbb{R})$ is the set of partially defined functions on $\mathbb{R}$ (I made them partially defined so that I do not have to be too careful with the exact domain, as that can change from problem to problem), given by $$f\mapsto (x\mapsto f(x-a))\\f\mapsto (x\mapsto f(mx))\\f\mapsto (x\mapsto f(x)+b)\\f\mapsto (x\mapsto mf(x)),$$ as well as composites of these, so as to be able to talk about the affine transformations that we made to the graph. Another example of this is the difference quotient, $$(h,f)\mapsto \frac{f(x+h)-f(x)}{h},$$ and in calculus, they will also see the derivative. It seems that this notion is a fairly simple one, and one that will prove useful later in life as well as now. A student asked for a place to read about this, and I said that I did not know an appropriate place for this. I know that I can find some good treatments of this if I look up the lambda calculus or Cartesian closed categories, but I would not want them to learn the notions of category theory or the notation of the lambda calculus. I also know that this notion is described in books about programming languages like Haskell or LISP, but this seems like they would have to learn a certain amount of code to fully understand this. So my question: Is there a treatment of higher order functions that is not a computer science book  and is reasonably elementary (say at the level of elementary set theory)?","['reference-request', 'education', 'book-recommendation', 'elementary-set-theory']"
522227,Logarithm Problem : Find the number of real solutions of the equation $2\log_2\log_2x+\log_{\frac{1}{2}}\log_2(2\sqrt{2}x)=1$,"Find the number of real solutions of the equation $2\log_2\log_2x+\log_{\frac{1}{2}}\log_2(2\sqrt{2}x)=1$ My approach : Solution : Here right hand side is constant term so convert it into log of same base as L.H.S. therefore, $1$ can be written as $\log_2\log_24$ $\implies 2\log_2\log_2x+\log_{\frac{1}{2}}\log_2(2\sqrt{2}x)= \log_2\log_24$ $\implies \log_2\log_2x^2 -\log_{2}\log_2(2\sqrt{2}x)= \log_2\log_24$ $\implies \log_2 \frac{\log_2x^2}{\log_2(2\sqrt2x)}= \log_2\log_24$ $\implies \frac{\log_2x^2}{\log_2(2\sqrt2x)}= \log_24$ Please suggest whether is it the right approach... thanks...","['logarithms', 'algebra-precalculus']"
522270,Why left continuity does not hold in general for cumulative distribution functions?,"Definition: The c.d.f. $F$ of a random variable $X$ is a function defined for each real number $x$ as follows:$$F(x)=\Pr(X\leq x) \text{ for } -\infty<x<\infty$$ Let $$F(x^-)=\lim_{y\rightarrow x,\,y<x}F(y)$$ and $$F(x^+)=\lim_{y\rightarrow x,\,y>x}F(y)$$ Property of cumulative distribution function: A c.d.f. is always continuous from the right; that is , $F(x)=F(x^+)$ at every point $x$. Proof: Let $y_1>y_2>\dots$ be a sequence of numbers that are decreasing such that $$\lim_{n\rightarrow \infty}y_n=x.$$Then the event $\{X\leq x\}$ is the intersection of all the events $\{X\leq y_n\}$ for $n=1,2,\dots$ .Hence, $$F(x)=\Pr(X\leq x)=\lim_{n\rightarrow \infty} \Pr(X\leq y_n)=F(x^+).$$ Now I think the left inequality can also be proved in the similar way as: Let $y_1<y_2<\dots$ be a sequence of numbers that are increasing such that $$\lim_{n\rightarrow \infty}y_n=x.$$Then the event $\{X\leq x\}$ is the union of all the events $\{X\leq y_n\}$ for $n=1,2,\dots$ .Hence, $$F(x)=\Pr(X\leq x)=\lim_{n\rightarrow \infty}\Pr(X\leq y_n)=F(x^-).$$ Where am I wrong?","['probability-theory', 'probability-distributions']"
522273,"If a group $G$ has odd order, then the square function is injective.","Suppose $G$ has odd order, show the function $f:G\rightarrow G$ defined by $f(x)=x^2$ is injective. This proposition is easily provable if we assume $G$ is Abelian, but I don't know how to start this without the assumption of being Abelian.","['finite-groups', 'group-theory', 'abstract-algebra']"
522321,"Why, precisely, is $\{r \in \mathbb{Q}: - \sqrt{2} < r < \sqrt{2}\}$ clopen in $\mathbb{Q}$?","Just going over some old notes and I realized I always took this for granted without actually fleshing out exactly why it is true. The set of all r is closed in $\mathbb{Q}$, because the set of all r is just all of the rationals in that interval, and obviously contains all of its limits. If you take its complement, the irrational numbers between $- \sqrt{2}$ and $\sqrt{2}$, what precisely can we say about this to conclude that the original set is clopen? i.e. why precisely is the complement open? Thanks.",['general-topology']
522334,Solve differential equation $y'' = -a y +\frac by$,"I am trying to solve for y(t):
$$y'' =-ay + \frac by$$
I have tried a lot, but haven't succeeded so far. Actually I am not sure there is a 'nice' solution. Do any of you have ideas of how to solve this?",['ordinary-differential-equations']
522347,Determining the automorphism group of a disconnected graph,"There is this know formula for determining the automorphism group of a graph $G$: let the connected components of $G$ consist of $n_1$ copies of $G_1$, $\dots$, $n_r$ copies of $G_r$, where $G_1, \dots, G_r$ are pairwise non-isomorphic. Then $${\rm Aut}(G) = ({\rm Aut}(G_1) \wr S_{n_1}) \times \dots \times ({\rm Aut}(G_r) \wr S_{n_r}).$$ I know intuitively what the formula does, but I am not able to prove the formula formally, probably because I don't understand the definition of the wreath product properly. I would also appreciate if someone would describe the automorphism group of a graph which is a disjoint union of three paths of length one (or any other simple example). If you are aware of a text or a website, where this is explained, it would be nice if you gave me a link, I wasn't able to find anything. Thank you for your help!","['graph-theory', 'group-theory', 'algebraic-graph-theory']"
522359,Writing real invertible matrices as exponential of real matrices,Every invertible square matrix with complex entries can be written as the exponential of a complex matrix. I wish to ask if it is true that Every invertible real matrix with positive determinant can be written as the exponential of a real matrix. (We need +ve determinant condition because if $A=e^X$ then $\det A=e^{\operatorname{tr}(X)} > 0$.) If not is there a simple characterization of such real matrices (with +ve determinant) which are exponentials of other matrices ?,"['matrices', 'linear-algebra', 'abstract-algebra']"
522362,A sequence of random variables $(X_n)$ such that $\mathbb E(X_n)\to -\infty$ but $X_n\to +\infty$ a.s.,"Let $\xi_{1},\xi_{2},\dots$ be random variables (i.e  measurable functions) such that $\mathbb{P}(\xi_{n}=-3^{n})=2^{-n}$ and $\mathbb{P}(\xi_{n}=1)=1-2^{-n}$ Let $S_{n}=\displaystyle\sum_{j=1}^{n}\xi_{j}$.
  Prove that $\mathbb{E}[S_{n}]\to -\infty$ whereas $S_{n}\to \infty$ a.s Solution: so by the definition of expectation $\mathbb{E}[S_{n}]=-3^{n}2^{-n}+1(1-2^{-n})=-3^{n}2^{-n}+1-2^{-n}<1-(\frac{3}{2})^{n}$ but $\displaystyle\sum_{n=1}^{\infty}(\frac{3}{2})^{n}=\infty$ by d'Alembert convergence test so ${E}[S_{n}]=\to-\infty$ Just one question to this part: $S_{n}$ is defined as a finite sum of random variables whereas when we test convergence of the series we consider infinite sum.... Now for the second part I am unsure which Borel- Cantelli lemma has been used. By Borel-Cantelli $\xi_{n}=1$ a.s for all but for finitely many $n$. Hence a.s $S_{n}\to \infty$ How do we get the last result? Borel-Cantelli I: if $\displaystyle\sum_{n=1}^{\infty}\mu(E_{n})<\infty$ then $\mu(\displaystyle\limsup_{n}(E_{n}))=0$ where $E_{1},E_{2}....\in\mathcal{M}$ Borel-Cantelli II:Let $E_{1},E_{2}....\in\mathcal{M}$ be independent events,  if $\displaystyle\sum_{n=1}^{\infty}\mathbb{P}(E_{n})=\infty$ then $\mathbb{P}(\displaystyle\limsup_{n}(E_{n}))=1$ 
i. e infinitely many $E_{1},E_{2},,,$ will occur with prob =1.","['probability-theory', 'measure-theory', 'random-variables', 'expectation']"
522385,Determinant of a block upper triangular matrix [duplicate],"This question already has answers here : Determinant of a block lower triangular matrix (7 answers) Closed 10 years ago . How prove the following equality for a block matrix? $$\det\left[\begin{array}[cc]\\A&C\\
0&B\end{array}\right]=\det(A)\det(B)$$ I tried to use a proof by induction but I'm stuck. Is there a simpler method? Thanks for help.","['matrices', 'linear-algebra', 'block-matrices', 'determinant']"
522477,Functions satisfying $(b-a)f'(\tfrac{a+b}{2}) = f(b)- f(a)$,"Let $f$ be a differientable real function such that $$(b-a)f'(\tfrac{a+b}{2}) = f(b)- f(a)$$
for all reals $a,b$. Is $f$ polynomial of degree $\leq 2$ ?","['functions', 'real-analysis']"
522481,Evaluating the convolution using the convolution integral,"I am having trouble evaluating the convolution of two signals using the convolution integral.I want to find the convolution of two signals x and h where, $$
   x(t) = \begin{cases}
          e^{-at} & \text{$t > 0$} \\
          0 & \text{$t < 0$ } \\
         \end{cases}
$$
$$
   h(t) = \begin{cases}
          e^{-bt} & \text{$t > 0$} \\
          0 & \text{$t < 0$ } \\
         \end{cases}
$$ using the convolution integral $$ 
    y(t) = x(t)*h(t) = \int_{-\infty}^{\infty} h(\tau)x(t - \tau) d\tau
$$ Which will mean that:
$$
     h(\tau) = \begin{cases}
          e^{-b\tau} & \text{$\tau > 0$} \\
          0 & \text{$\tau < 0$ } \\
         \end{cases}
$$ $$
   x(t - \tau) = \begin{cases}
                  e^{-at}e^{a \tau} & \text{$t > \tau$} \\
                  0 & \text{$t < \tau$ } \\
         \end{cases}
$$ But how do I proceed from here? I don't know how to handle the $x(t - \tau)$ function which is non-zero only when $t > \tau$.","['convolution', 'integration']"
522516,Probability that coin will fall into a square,"So the exercise is this: We have and infinite chessboard and we have a coin. Every grid is of length and width $a$, whereas the coin has diameter $2 \cdot r<a$. We throw a coin into a chessboard and we want to know with what probability the coin will falll into the grid. So let $S_{1}$=area of green rectangle, $S_{2}=S_{1}+$ area of the red border.
So the probability in my opinion is 
$ P(a)= \frac{S_{1}}{S_{2}} $. Is this in any shape or form correct?","['geometry', 'probability', 'geometric-probability']"
522527,How much would it cost to try every possible burger combination?,"I was at a restaurant that allows you to build your own custom burger. I got bored and started to work out how many possible combinations of burger there could be. After figuring that out and sharing the number with a friend he wondered how much it would cost you if you were to order every possible combination. This is where I got stuck. Ignoring all the options that don't affect the price here's the basic menu: Choose either one (\$7.99) or two (\$9.48) patties. Choose from 7 cheeses \$0.89 each Choose from 10 hot toppings \$0.99 each Choose from 3 premium toppings \$1.49 each Choose from 4 cold toppings \$0.39 each I've been mulling it over in my head for a few days and I can't really figure out a good way to go about it. The best thing I've come up with so far is to pick a category and find out the total to try all combinations in that category using $\sum _{i=1}^m \binom{m}{i} c i$ where $c$ is the cost per item and $m$ is the total number of items to choose from. Then taking that and multiplying it by all the other possibilities created by the other categories. Please forgive me if I'm missing something obvious or screwed something up, my formal schooling doesn't extend much beyond algebra and that was a decade ago.",['combinatorics']
522532,Construction of moduli space with hands.,"I make this question because I'd like to have an explicit example of moduli space.
First of all, we consider $G=SL(2,\mathbb{C})$ and $X$ a compact Riemann surface with genus $2$. So we can build $M^2$: the moduli space of principal stable $SL(2)$-bundles on $X$. In order to do this, I cite this answer Principal stable $SL(2)$-bundles on a genus $2$ compact Riemann surface. , in order to have a model of principal $SL(2)$-bundle on $X$. Now, how can I build ''with hands'' the moduli space $M^2$?","['algebraic-geometry', 'moduli-space']"
522565,Can one define informational content of a mathematical expression?,"At least in physicist's thinking, information, vaguely, is something that allows one to select a subset from a set. Say, a system can be in states A and B, we have done a measurement on it (extracted information), then it is in either A or B. Now we are able to say, in which state among all the possible states is the system in. Now, consider numbers, say number e. One can write many digits to specify the boundaries of an interval to which e belongs. In fact, arbitrarily good precision can take arbitrarily large amount of information to specify the decimal representation of the number. Now, however, one can also write an expression for e, say $e = \sum_{n}\dfrac{1}{n!}$, and it seems like e is defined to an arbitrary precision straight away. That is to say, here we have something, for which we would have needed infinite amount of information. The question then: does this expression contain infinity of information/any information at all? Or, can information be defined at all for expressions? One might surely argue that given an expression, one still has to perform infinite number of evaluations to obtation a decimal expression of the number. But then a number of other questions would arrive: ""Is it evaluations of faculties and additions then that produce information?"", ""Is the information only about decimal representations of numbers, but not the numbers themselves?"", and perhaps many more.","['philosophy', 'entropy', 'soft-question', 'number-theory']"
522579,Where is $\operatorname{Log}(z^2-1)$ Analytic?,"$\newcommand{\Log}{\operatorname{Log}}$ The question stands as Where is the function $\Log(z^2-1)$ analytic , where $\Log$ stands for the principal complex logarithm. My understanding is that The domain of analyticity of any function $f(z) = \Log\left[g(z)\right]$ , where $g(z)$ is analytic, will be the set of points $z$ such that $g(z)$ is defined and $g(z)$ does not belong to the set $\left \{z = x + iy\ |\ −\infty < x \leq 0, y = 0\right \}$ . Following this definition it would imply that the function $f(z)$ is analytic everywhere in complex plane except for the points where $-\infty<\Re(z^2-1)\leq0$ and $\Im(z^2-1)=0$ . So I get $x^2-y^2-1\leq0$ and $2xy=0$ . Graphically it must be analytic everywhere except on the real x axis, the imaginary y-axis and in the region inside the hyperbola $x^2-y^2=1$ . The answers say Everywhere except $\{z\in\mathbb{R}:|z|\leq1\}\bigcup\{iy:y\in\mathbb{R}\}$ . Please help correct my understanding. Thank you in advance.","['analyticity', 'complex-analysis']"
522582,How many solutions of $ x+y+z+t = 7 $,"I have an equation: $ x+y+z+t = 7$. I want to know how many solutions does this equation have? $x,y,z$, and $t$ are positive integers. I have no idea how to solve this. Can you please help me to solve this question?","['number-theory', 'combinatorics']"
522595,Approximate the integral $\int_0^\pi \sin(x^3)\mathrm{d}x$ with a standard pocket calculator,"I came over the following integral $$
  \int_0^\pi \sin(x^3) \mathrm{d}x
$$ when a friend of mine tried to approximate it.
The most obvious way is to use Taylor's formula, and then turn the integral into a sum. Eg $$
\int_0^\pi \sin(x^3) \mathrm{d}x \approx \sum_{k=0}^N \frac{1}{2} \frac{(-1)^k \pi^{3k+2}}{(3k+2)(2k+1)!}
$$ The problem is the nominator increases much more rapidly than the denominator for the first 30 terms or so. Much faster than what a standard calculator can deal with.
This can be seen here https://i.sstatic.net/O8aX0.jpg By using the midpoint rule instead, the sum turns into $$
   \int_0^\pi \sin(x^3) \mathrm{d}x \approx \frac{\pi}{2}\sum_{k=0}^N f\left( \frac{\pi}{2} \frac{2k-1}{N}\right)
$$ Which converges to two decimal places in $36$ iterations, however to obtain a higher accuracy the convergence is slower than the Taylor series. As a final note I also tried using the substitution $u \mapsto u^3$ , but the series expansion did not improve. My question is as follows: What is the least terms needed to approximate the integral to $3$ digits accuracy under the restrictions of using a standard pocket calculator? To clearify the calculator does not have more than 8 digits accuracy, and can use sine and cosine. Oh, I also tried Simpsons that did not improve the convergence. Could Romberg, or Gaussian lead to faster convergence?","['definite-integrals', 'approximation', 'calculus', 'integration']"
522612,Is it possible to have a non-trivial homomorphism of some finite group into some infinite group?,"Let $G$ be a group of some finite order, and let $G^\prime$ be some group of infinite order. Then there is the trivial homomorphism of $G$ into $G^\prime$ which maps each element of $G$ into the identity element $e^\prime$ of $G^\prime$. Can we define any other homomorphism of $G$ into $G^\prime$? Why or why not?","['finite-groups', 'group-theory', 'abstract-algebra']"
522613,Exercise 6.9 in Rudin's RCA (Real and Complex Analysis),"The following is an exercise 6.9 in Rudin's Real and Complex Analysis: Suppose that $\{ g_n \}$ is a sequence of positive continuous functions on $I=[0,1]$, that $\mu$ is a positive Borel measure on $I$, and that (i) lim$_{n\to \infty}$ $g_n (x) = 0$ a.e. [m], (ii) $\int_I g_n dm = 1$ for all $n$, (iii) lim$_{n\to \infty}$ $\int_I fg_n dm = \int_I f d\mu$ for every $f\in C(I)$. Does it follow that $\mu \perp m$? I think that the answer is positive. $\{g_n\}$ seems to be something similar to good kernel. I tried to use Egoroff's theorem and then derive something useful, but couldn't. Would you please give me some help?","['real-analysis', 'analysis']"
522633,Geometric interpretation of the addition of linear equations in general form,"I have a very simple question: suppose I have two 2D linear equations in general form $$ a_1x + b_1y + c_1 = 0$$
$$ a_2x + b_2y + c_2 = 0$$ I'd like to know what's the (intuitive) geometric interpretation of their addition and subtraction $$ (a_1 + a_2)x + (b_1 + b_2)y + (c_1 + c_2) = 0$$
$$ (a_1 - a_2)x + (b_1 - b_2)y + (c_1 - c_2) = 0$$","['geometry', 'linear-algebra', 'intuition']"
522654,How to prove the space of orbits is a Hausdorff space,"Let $M$ be a connected smooth n-dimensional manifold and $G$ a lie group acting smoothly on $M$.
for $x\in M$, the orbit $G\cdot x=\{g(x)\mid g\in G\} $ is a sub-manifold of $M$ and if the action is proper, namely
the inverse image of every compact subset of $M\times M$ under the map 
$$ G\times M\rightarrow M\times M: (g,p)\mapsto(p,g(p))$$
is compact.
Please  prove  the space of  orbits is a Hausdorff space.\
Thanks in advance.","['general-topology', 'lie-groups']"
522656,Find $n$ such that the numerator of $1+\frac{1}2+\frac{1}3+\cdots+\frac{1}n$ is a square number,"Let $$a_n=1+\frac{1}2+\frac{1}3+\cdots+\frac{1}n=\frac{p_n}{q_n},$$ 
where $gcd(p_n,q_n)=1.$ $$\{a_n\}=\left\{1,\frac{3}{2},\frac{11}{6},\frac{25}{12},\frac{137}{60},\frac{49}{20},\frac{363}{140},\cdots\right\}$$ Hence $p_1=1,p_4=5^2,p_6=7^2,$ are there any other $n$ such that $\sqrt{p_n}\in\mathbb N$?",['number-theory']
522677,What is the probability of exactly two out of n persons sharing a birthday?,The classical Birthday problem asks for the probability of at least two out of $n$ people sharing the same birthday or sometimes for the least amount $n$ of people required such that with a probability of 50% at least two of them share their birthday. But what about the question how probable it is that also no more than two people share their birthday?,['probability']
522682,Prove that $\lfloor an \rfloor +\lfloor (1-a)n \rfloor = n-1 $,Given and irrational $a$ and a natural number $n$ prove that $\lfloor an \rfloor +\lfloor (1-a)n \rfloor  = n-1 $. Is this solution correct? $\lfloor an \rfloor +\lfloor (1-a)n  \rfloor = \lfloor an \rfloor +\lfloor n-na \rfloor   =$ (we take out $ n $ because it's an integer) $ \lfloor an \rfloor +n - \lfloor - an \rfloor =$ (because floor of a negative number is a negative of the ceiling of it's positive equivalent) $ \lfloor an \rfloor +n - \lceil an \rceil = n-1$,['discrete-mathematics']
522709,Evaluate $\lfloor \frac{x}{m} \rfloor + \lfloor \frac{x+1}{m} \rfloor + \dots + \lfloor \frac{x+m-1}{m} \rfloor $,"For any $x \in \mathbb{R}$  and $m \in \mathbb{N} $ evaluate $\lfloor \frac{x}{m}  \rfloor + \lfloor  \frac{x+1}{m} \rfloor  + \dots + \lfloor \frac{x+m-1}{m} \rfloor $. Well if $x=m$ then we obviously have $\lfloor \frac{x}{m}  \rfloor + \lfloor  \frac{x+1}{m} \rfloor  + \dots + \lfloor \frac{x+m-1}{m} \rfloor = 1 + 1 + \dots + 1=m$. If $x=-m$ then $\lfloor \frac{x}{m}  \rfloor + \lfloor  \frac{x+1}{m} \rfloor  + \dots + \lfloor \frac{x+m-1}{m} \rfloor=-m $. If $x=0$ then $\lfloor \frac{x}{m}  \rfloor + \lfloor  \frac{x+1}{m} \rfloor  + \dots + \lfloor \frac{x+m-1}{m} \rfloor=0 $. There are many such cases I can think of, but something tells me there might be an easier solution.",['discrete-mathematics']
522713,Explicitly realizing Riemann surfaces as a quotient of the upper-half plane,"Let $\Sigma_g$ be a Riemann surface of genus $g \ge 2$.  Then it is known that $\Sigma_g$ is (holomorphically) a quotient of the upper-half-plane (or unit disk) by a group $\Gamma$ of hyperbolic isometries.  Where can one find a nice explicit description of $\Gamma$? EDIT: Sorry for being vague.  Basically I just want to work out certain computations on Riemann surfaces and so am looking for nice, explicit groups of isometries of the upper half plane (so that I can compute equivariantly on the universal cover instead of on the surface).  I don't care about finding the group corresponding to a given holomorphic structure, but am just looking for nice ones to work with.","['differential-geometry', 'complex-geometry', 'riemann-surfaces', 'reference-request', 'complex-analysis']"
522728,Residue at infinity of $f(z)=z^3\cos\big(\frac{1}{z-2}\big)$,"I have trouble with the residue of: $f(z)=z^3\cos\left(\frac{1}{z-2}\right)$ at $z = \infty$ .
I tried to solve it at $z=0$ but it turns out that I was wrong while $z=0$ is not a pole.
I must solve it at $z=2$ but I'm stuck.
Any suggestion will be much appreciated.","['residue-calculus', 'infinity', 'complex-analysis']"
522730,17539 decimal to binary not getting the same result,"I'm trying to convert 17539 to binary. My math says its 110000010010001, but online calculators like this and this say it equals to 100010010000011. Who is making something wrong.","['discrete-mathematics', 'binary']"
522764,"Simplify $\frac{_3F_2\left(\frac{1}{2},\frac{3}{4},\frac{5}{4};1,\frac{3}{2};\frac{3}{4}\right)}{\Pi\left(\frac{1}{4}\big|\frac{1}{\sqrt{3}}\right)}$","Is it possible to simplify the ratio
$$\mathcal{E}=\frac{_3F_2\left(\frac{1}{2},\frac{3}{4},\frac{5}{4};\ 1,\frac{3}{2};\ \frac{3}{4}\right)}{\Pi\left(\frac{1}{4}\Big|\frac{1}{\sqrt{3}}\right)},$$
where $\Pi(n|k)$ is the complete elliptic integral of the third kind ? Its numeric value is approximately $\mathcal{E}\approx0.73510519389572273268...$, that looks like $\frac{4}{\pi\sqrt{3}}$.","['closed-form', 'calculus', 'conjectures', 'elliptic-integrals', 'hypergeometric-function']"
522769,Can someone explain curvature in simple terms,"I am studying differential geometry but am having a hard time picturing curvature. Can anyone explain it to me in simple terms, perhaps with any diagrams. As simple as possible!","['curvature', 'differential-geometry']"
522777,Connected subgroups of SU(2) and SU(3) [duplicate],"This question already has an answer here : Is every Lie subgroup of $SU(2)$ closed? (1 answer) Closed 3 years ago . I am reading Lie groups, Lie Algebras, and Representations: An Introduction (2nd edition) by Brian C. Hall and I am unable to do the problem 12 in chapter 5. It says Show that every connected Lie subgroup of SU(2) is closed. Show that this is not the case for SU(3). Also I am wondering if the Lie algebra of SU(2) has any two-dimensional subalgebras. Is there a systematic way of listing all the Lie subalgebras of the Lie algebras of SU(2) and SU(3) ? What about Lie subgroups ?","['topological-groups', 'lie-algebras', 'lie-groups', 'abstract-algebra']"
522794,Why does the sequence $\frac{1}{n}$ diverge?,"My math teacher said that it is not a Cauchy sequence thus it isn't convergent but divergent. It is bounded and its limit exists ($=0$). Now i am really confused. I thought that things started to get clearer and I then came across this one. She also said that $\frac{1}{n^2}$ is convergent.
I am not confusing the terms ""sequence"" with ""series"".
Thanks a lot.","['sequences-and-series', 'calculus']"
522807,Branch Cut and Argument Choice Subtlety,"Could someone give me an example of a contour integral of a simple complex function that requires a branch cut, and a choice of argument -- but for different parts of my contour, I make that argument choice differently. I'm trying to understand when/if this is acceptable... and a concrete example would really help me figure out another question I have posted. I'm interested in what I need to consider, and what restrictions I have. An example of what I mean: For example, say I'm integrating the function $z^\frac{1}{2}$ along the contour $H_1 \cup H_2 \cup H_3$ where $H_1$ is the line segment $1+i$ to $i$, $H_2$ is the semi circle with radius 1 from $i$ to $-i$, and $H_3$ is the line segment from $-i$ to $1-i$. The branch cut could be real axis $x \geq 0$. Then supposing I make the argument choice for my function different on $H_1$ and $H_3$.","['complex-analysis', 'contour-integration']"
522811,Existence of solution of singular ODE,"Suppose $f$ is a Lipschitz continuous function defined on $\mathbb{R}$ . How can one prove that the following ODE admits at least one solution. \begin{equation}
y'' + \frac{1}{x}y' + f(y) = 0
\end{equation} with $y(0) = y_0, y'(0) = 0$ .","['ordinary-differential-equations', 'initial-value-problems']"
522830,Product of Lebesgue-measurable sets in $\mathbb{R}$ and $\mathbb{R}^2$,"Let $M_1$ be the Lebesgue-measurable subsets of $\mathbb{R}$, and $M_2$ be the Lebesgue-measurable subsets of $\mathbb{R}^2$. Prove that $M_1\times M_1\neq M_2$, by considering a set $E\times\{0\}$, where $E\subseteq[0,1]$ and $E\not\in M_1$. The Lebesgue measurable sets in $\mathbb{R}^n$ are generated by finite unions of rectangles. If $E\not\in M_1$, then it looks like $E\times\{0\}$ is not in $M_2$, and it is not in $M_1\times M_1$ either. So I'm quite confused.","['measure-theory', 'real-analysis']"
522837,How to think about the change-of-coordinates matrix $P_{\mathcal{C}\leftarrow\mathcal{B}}$,"I've taken a linear algebra course in the past, but I feel my understanding of coordinate change is very superficial. For example this exercise (4.7.1 from Lay's ""Linear Algebra and its Applications"" 4. edition): Let $\mathcal{B}={\{ \bf{b_1,b_2} \}}$ and $\mathcal{C}={\{ \bf{c_1,c_2} \}}$ be bases for a vector space V, and suppose $\bf{b_1}=6\bf{c_1}-2\bf{c_2}$ and $\bf{b_2}=9\bf{c_1}-4\bf{c_2}$. a. Find the change-of-coordinates matric from $\mathcal{B}$ to $\mathcal{C}$. b. Find $[\bf{x}]_\mathcal{C} =-3\bf{b_1}+2\bf{b_2}$. I can solve a. because I remember that $P_{\mathcal{C}\leftarrow\mathcal{B}}=\bf{[[b_1]_\mathcal{C}\,\,[b_1]_\mathcal{C}]}$ and that $\bf{[b_1]_\mathcal{C}}$ is the 'weights on the linear combination of $\mathcal{C}$-vectors'. I can also solve b. because I remember that $[\bf{x}]_\mathcal{C}=P_{\mathcal{C}\leftarrow\mathcal{B}}[\bf{x}]_\mathcal{B} $ So I know how to apply the equations, but I feel that if I had a good mental model of what's going on here, it would be obvious that $\left(\begin{array}{rr}
6 & 9 \\
-2 & -4
\end{array}\right)$ is the matrix I'm looking for. In my own experience, usually, if I learn something well I can construct the formulas I don't remember from reasoning, but here I fail, so I've literally spent all day trying to think up some analogy that would let me do the abovementioned exercise without remembering the formulas, here's what I've come up with so far: $[\bf{x}]_\mathcal{B} $ is like a recipe for how much of the vectors of $\mathcal{B}$ you need to get to some point. So, how much of $\mathcal{C}$ do you need to get to $\bf{b_1}$? You need $\left[\begin{array}{rr}
6  \\
-2  
\end{array}\right]=[\bf{b_1}]_\mathcal{C}$. How much of $\mathcal{C}$ do you need to get to $\bf{b_2}$? You need $\left[\begin{array}{rr}
9  \\
-4  
\end{array}\right]=[\bf{b_2}]_\mathcal{C}$. Thus any ""$\mathcal{B}$-recipe"" $\left[\begin{array}{rr}
r_1  \\
r_2  
\end{array}\right]$ will in our case become a ""$\mathcal{C}$-recipe"" when we multiply it with 
  $\left(\begin{array}{rr}
6 & 9 \\
-2 & -4
\end{array}\right)$, because the result will tell us ""how much of $\mathcal{C}$ to get to $\bf{b_1}$ and $\bf{b_2}$, and then how much of these two to get to some new point"". But it's been 'how much to use of $\mathcal{C}$-vectors' all the way this time, so our result has to be some $[\bf{x}]_\mathcal{C}$. My question : What is a nice way to think about change between bases when neither is the standard one? Just looking for any way to think about this at any level of sophistication.","['linear-algebra', 'intuition']"
522848,Showing set not in $M\times M$ for Lebesgue measure,"Let $M$ be the Lebesgue-measurable subsets of $\mathbb{R}$. Suppose $E\subseteq [0,1]$ and $E\not\in M$. Then I want to show that $E\times\{0\}\not\in M\times M$, where $M\times M$ is the smallest $\sigma$-field generated by the sets $A\times B$ with $A,B\in M$. Well, the $\sigma$-field operations are countable unions, set difference, and complementation. Certainly $E\times\{0\}$ is not of the form $A\times B$ with $A,B\in M$, because $E\not\in M$. But how would I prove $E\times\{0\}\not\in M\times M$? I don't quite see how I could take into account the three operations mentioned above.","['measure-theory', 'real-analysis']"
522873,"If $a$ and $b$ commute in a $C^*$-algebra and $a$ is normal, then $f(a)$ and $b$ commute for any continuous $f$","I'm trying to find a way to demonstrate the following: Let $(A,*,\|\cdot\|)$ be a unital $C^*$-algebra. If $a,b\in A$ commute and $a\in A$ is normal (i.e. $a^*a=aa^*$), then for every continuous function $f:$Sp$(a)\to\mathbb{C}$, $f(a)$ and $b$ commute (where Sp$(a)$ denotes the spectrum of $a$ and $f(a)$ is given by functional calculus). So far, I've been trying to show that $\|f(a)b-bf(a)\|=0$ knowing that $ab=ba$ or, equivalently, $\|ab-ba\|=0$, but I've got nowhere with this. Any hint/suggestion would be greatly appreciated.","['c-star-algebras', 'functional-analysis', 'banach-spaces', 'functional-calculus']"
522890,"""Differential"" of a measure","Let $\mu$ be a finite measure on $\mathbb{R}$. What is the definition of the operator $d$ in the expression: $d\mu$. For example, I have an exercise where at one point: \begin{equation}
d\mu(x) = \frac{d x}{1+x^2}
\end{equation} I would said this a ""differential"" of $\mu$, but I can not find any definition of this kind on the Internet.","['lebesgue-integral', 'measure-theory']"
522901,Finding the smallest set on which a group acts faithfully,"Given a finite group $G$, how efficient can one make an algorithm to find the size of the smallest set $S$ such that $G$ is isomorphic to a group of permutations of the members of $S$?  And does the answer change if one requires the output to specify not only the cardinality of $S$ but the particular action of $G$ on $S$?  Might this be an NP-hard problem?  Or is it a trivial thing whose solution is known to everyone on earth except me?  Or somewhere in between?","['permutations', 'computational-complexity', 'group-theory', 'combinatorics']"
522907,Deconvolution of distribution of diffraction reflexes,"I'm a chemist stuck in a mathematical problem. Please bear with me as I'm trying to express myself in Math language. Let me explain in short terms the experimental method I'm using: X-ray diffraction . For this method, atoms in a solid can be viewed as ordered balls in space. X-rays, having similar wavelength as the distance between atoms, are diffracted by those balls and can be detected as diffraction fringes. The distance between the diffracting atoms (or planes of atoms, aka lattice distance) can then be calculated using Bragg's law We use the method to measure the symmetry of the atom ordering, their distances and placement in space. As chemists, we like to deduce so-called lattice parameters (the lengths of the smallest repeating unit of atoms in all three cartesian coordinates) from three or more characteristic atomic plane distances. In my case the repeating unit has the form of a cuboid. The measured diffraction fringes are equivalent to the points of the fourier transform of the spacing of the atoms in real space and describe the repetition of those atoms. They are linked to the cuboid edge lengths via: 1/d 2 = h 2 /a 2 + k 2 /b 2 + l 2 /c 2 h, k and l are discrete values, characteristic to the specific diffraction fringe, d is the measured lattice distance. Unfortunately, the cuboid is not stiff, but a, b and c have some distribution. As such I have measured an asymmetric distribution of the lattice distances d. I would like to find out how the cuboid edge lengths contribute to the measured distribution. I fitted a normal distribution to my experimental data for 1/d 2 , for which it is easy to deconvolute to get distributions of 1/a 2 and so on. This doesn't reflect my data correctly, though, since I observe an asymmetric distribution of 1/d 2 . Do you have an idea how to extract information of the distribution of a, b and c from those three distributions of lattice spacings? In a first approximation, these three edge lengths are independent variables.","['physics', 'statistics', 'chemistry', 'mathematical-physics', 'probability-distributions']"
522913,Are there other cases similar to Herglotz's integral $\int_0^1\frac{\ln\left(1+t^{4+\sqrt{15}}\right)}{1+t}\ \mathrm dt$?,"This post of Boris Bukh mentions amazing Gustav Herglotz's integral
$$\int_0^1\frac{\ln\left(1+t^{\,4\,+\,\sqrt{\vphantom{\large A}\,15\,}\,}\right)}{1+t}\ \mathrm dt=-\frac{\pi^2}{12}\left(\sqrt{15}-2\right)+\ln2\cdot\ln\left(\sqrt3+\sqrt5\right)+\ln\frac{1+\sqrt5}{2}\cdot\ln\left(2+\sqrt3\right). 
$$
I wonder if there are other irrational real algebraic exponents $\alpha$ such that the integral
$$
\int_{0}^{1}
\frac{\ln\left(1 + t^{\,{\large\alpha}}\right)}{1 + t}\,{\rm d}t
$$
has a closed-form representation? Is there a general formula giving results for such cases? Are there such algebraic $\alpha$ of degree $> 2$ ?","['closed-form', 'calculus', 'integration', 'definite-integrals', 'logarithms']"
522919,Calculation mistake in variation of length functional?,"This should be pretty simple to check if you know the basics of variational calculus. I feel like I am making an obvious mistake somewhere like not using chain rule somewhere. Let $g : \mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}$ be a smooth metric on some domain in $\mathbb{R}^n$, and let $\gamma : [0,1] \rightarrow \mathbb{R}^n$ be a smooth path in this domain. I'm trying to show that minimising the length functional
$$A(\gamma) = \int_0^1 \sqrt{g(\dot{\gamma},\dot{\gamma})} dt$$
is equivalent to minimising the action functional
$$E(\gamma) = \frac{1}{2} \int_0^1 g(\dot{\gamma},\dot{\gamma}) dt.$$
I can do this in coordinates no problem, but this calculation is a bit messy. In general, the Lagrangian $L$ is not linear, but in this case $g$ is bilinear. Let $v \in C^1$, $v(0) = v(1) = 0$. Question: is this use of the metric $g$ correct, and can we conclude the result via this calculation, or am I forgetting to use the chain rule somewhere?
\begin{align*}
A(\gamma+tv) &= \frac{d}{dt}\bigg|_{t=0} \int_0^1 \sqrt{g(\dot{\gamma}+t\dot{v},\dot{\gamma}+t\dot{v})} dt \\
&= \frac{d}{dt}\bigg|_{t=0} \int_0^1 \sqrt{g(\dot{\gamma},\dot{\gamma}) + 2t g(\dot{v},\dot{\gamma}) + t^2 g(\dot{v},\dot{v})} dt \\
&= \int_0^1 \frac{1}{\sqrt{g(\dot{\gamma},\dot{\gamma})}}g(\dot{v},\dot{\gamma})dt
\end{align*} By comparison, the first variation of the action functional is
$$\frac{d}{dt}\bigg|_{t=0} E(\gamma+tv) = \int_0^1 g(\dot{\gamma},\dot{v})dt.$$
So if $\gamma$ has constant speed, i.e. if $g(\dot{\gamma},\dot{\gamma})$, then it seems that minimizing these functionals is identical. But this seems too easy (no derivatives of $g$ coming out)! Also, I can't get the Euler-Lagrange equations for geodesics to come out of this computation (integration by parts, right? -- so that's where the derivatives of $g$ would come out?). A simple ""incorrect"" will be appreciated, and an explanation why even more so. Thanks!","['calculus-of-variations', 'differential-geometry', 'geodesic']"
522920,Is this epsilon-delta proof correct?,"Consider the function $f:\mathbb{R}\rightarrow\mathbb{R}$ $$f(x)=\begin{cases}x,\ x\in\mathbb{Q} \\ -x,\ x \notin \mathbb{Q}.\end{cases}$$
I'm trying to prove that for all $a \neq 0$, $\lim_{x \to a}f(x)$ does not exist. I tried to do this by contradiction, so my first step was to suppose that $$\lim_{x \to a}f(x)=A,$$ for some $A \in \mathbb{R}$. Then this implies that $$\forall \varepsilon>0\ \exists\delta:\ 0<|x-a|<\delta\implies|f(x)-A| < \varepsilon.$$
So I said, consider some $p \in \mathbb{Q}:0<|p-a|<\delta$, and therefore $|f(p) - A|=|p-a|<\varepsilon_1$. Also consider a $q \in \mathbb{R}, q \notin \mathbb{Q}:0<|q-a|<\delta$, and therefore $|f(q)-A|=|-q-A|=|q+a|<\varepsilon_2$. Since the epsilon-delta definition allows us to choose whatever $\varepsilon$ we want, I chose to let $\varepsilon_1 = p$ and $\varepsilon_2 = q$.  This then implies the following $$|p-A|<\varepsilon_1=p \implies p-A<p \implies A>0,$$ $$|q+A|<\varepsilon_2=q \implies q+A<q \implies A<0.$$ Since we cannot have $A>0$ and $A < 0 $, this is a contradiction, and therefore the limit does not exist. $\square$ Does this proof seem correct? In particular I'm concerned that I never made use of the fact $a \neq 0$, so I was hoping someone could review it and let me know if there are any errors. This problem is from Spivak's Calculus , 4th ed., and the proof give in the solution book is quite different than mine, so I wasn't able to check my answer that way. Thanks. EDIT:
Here's the corrected proof. Assume for some $a > 0$ that $\lim_{x \to a} f(x) = A$, for some $A > 0$. Then from the epsilon-delta definition there is some delta such that $0 < |x-a| < \delta \implies |f(x) - A| < A$. Choose some irrational $q > 0$ such that $0 < |q - a| < \delta$, which implies that $|f(q) - A) = |-q - A| = |q + A| < A$, but this would mean that $q + A < A \implies q < 0$, a contradiction. To prove that $f$ does not approach a negative limit either, let $\varepsilon = -A$, and pick some $p \in \mathbb{Q}$ such that $0 < |p - a| < \delta$, so therefore $|f(p) - A| = |p - A| < -A$. This implies that $p - A < -A \implies p < 0$, again a contradiction. Finally, to prove that $f$ does not approach a $0$ limit, let $\varepsilon = a$, and then pick some $y > a$ such that $0 < |y-a| < \delta$. This would imply that $|f(y)| = y < a$, which is again a contradiction, so $f$ does not approach a limit for $a > 0$, and therefore $a < 0$. $\square$","['calculus', 'continuity', 'proof-verification', 'limits']"
522921,The ring $ℤ/nℤ$ is a field if and only if $n$ is prime,"Let $n \in ℕ$. Show that the ring $ℤ/nℤ$ is a field if and only if $n$
  is prime. Let $n$ prime. I need to show that if $\bar{a} \neq 0$ then $∃\bar b: \bar{a} \cdot \bar{b} = \bar{1}$. Any hints for this ? Suppose $ℤ/nℤ$ is a field. Therefore: for every $\bar{a} \neq 0$ $∃\bar b: \bar{a}\cdot \bar{b}=1$. How can I show that $n$ must be prime ?","['ring-theory', 'abstract-algebra']"
522961,The eigenvalues of the product of a positive definite and a symmetric matrix.,"A fellow student posed the following question and I'd like to stop thinking about it so I can get back to work on my own research! Suppose that $A>0$, i.e. $A$ is a real symmetric positive definite matrix, and $B$ is a real symmetric nonsingular matrix. What can we say about the eigenvalues of $AB$?  For instance, suppose $B$ has $n$ positive and $m$ negative eigenvalues.  Will $AB$ have the same number of positive and negative eigenvalues? Obviously if $B$ is either positive or negative definite, the result is straightforward, i.e. we have the `matrix sign rules' $$
(+)\cdot (+)=(+)\qquad\text{and}\qquad (+)\cdot(-)=(-)
$$ Whereby we mean `a positive definite times a positive definite has positive eigenvalues' and 'a positive definite times a negative definite has negative eigenvalues'. Playing around with matrix decompositions such as polar, spectral, etc, and identities such as $\{\lambda(AB)\}=\{\lambda(\sqrt{A}B\sqrt{A})\}$ (here $\lambda(\cdot)$ meaning `eigenvalues of') doesn't seem to lead to a quick result. Any ideas?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
522964,Multivariable local maximum proof,"Suppose we have a twice differentiable function $f: \mathbb{R} ^n \to \mathbb{R}$, a point ${\bf x^0} = (x_1 ^0 , \ldots , x_n ^0)$ and we know that $\nabla f({\bf x}^0) = 0$ $({\bf x - x^0})H({\bf x^0})({\bf x - x^0})^T <0 $, $(H({\bf x^0})$ is the Hessian matrix of $f$) Prove that $f({\bf x^0})$ is the local maximum of $f$. Attempt at a solution Since $\nabla f({\bf x}^0) = 0$ we know that ${\bf x^0}$ is a critical point of the function $f$. Because the Hessian is smaller than $0$ at the point ${\bf x^0}$, $f$ has a local maximum at the point ${\bf x^0}$.$\hspace{0.5em} \square$ Here is my dilemma. My ""proof"" feels very cheap. However, I'm not taking a proof heavy class (in fact proofs of why $f$ has a local maximum at a critical point if the Hessian is smaller than zero are not included in my text!) so I don't know what to add ... I feel like I have said everything that has to be said so I'm hoping any of you can point out to me how I can buff it up. I just want to add that this question isn't really homework, it's from an old final by my teacher which I'm solving in my free time. Thanks. Improved solution We know that $\nabla f({\bf x}^0) = 0$. Then, by definition, ${\bf x}^0$ is a critical point of $f$. Define function $g({\bf x}^0) = ({\bf x - x^0})H({\bf x^0})({\bf x - x^0})^T < 0$. Since $g({\bf x}^0) < 0$, all the eigenvalues of $H({\bf x^0})$ are less than $0$ resulting in $f$ having a local maximum at the point ${\bf x^0}$. All there is left to do is reference where I use known theorems. Is this sufficient?","['optimization', 'multivariable-calculus', 'quadratic-forms', 'real-analysis']"
522973,$\lim_{x\to0^{+}} x \ln x$ without l'Hopital's rule,"I have a midterm coming up and on the past exams the hard question(s) usually involve some form of $\lim_{x\to0^{+}} x \ln x$. However, we're not allowed to use l'Hopital's rule, on this year's exam anyways. So how can I evaluate said limit without l'Hopital's rule? I got somewhere with another approach, don't know if it's useful: $\lim_{x\to0^{+}} x \ln x = \lim_{x\to0^{+}} x^2 \ln (x^2) = L$ $= (\lim_{x\to0^{+}} 2x)(\lim_{x\to0^{+}} x \ln x)$ $= 0 * L$ Then I just need to prove that L is finite/exists (which means it must be 0)","['calculus', 'limits']"
522981,Changing Lebesgue-measurable function to Borel function,"Show that if $f:\mathbb{R}^2\rightarrow\mathbb{R}$ is measurable (with respect to the Lebesgue-measurable sets in $\mathbb{R}^2)$, then there exists a Borel function $g$ such that $f(x)=g(x)$ for almost every $x\in\mathbb{R}^2$ (i.e. for all $x\in\mathbb{R}^2$ except a set of measure zero). I guess ""Borel function"" means Borel-measurable functions. If so, $g$ Borel-measurable would mean that $g^{-1}(A)$ is a Borel set in $\mathbb{R}^2$ for all Borel $A\in\mathbb{R}$. And $f$ Lebesgue-measurable would mean that $f^{-1}(A)$ is a Lebesgue-measurable set in $\mathbb{R}^2$ for all Borel $A\in\mathbb{R}$. Given this setting, it is hard to see how to proceed. I am allowed to change the value of $f(x)$ for a subset of measure zero in $\mathbb{R}^2$, and I want to get a Borel-measurable function. How can I do that?","['measure-theory', 'real-analysis']"
522994,Euler function and $\mathbb{Z}/n\mathbb{Z}$,"I am trying to solve a very interesting problem about the ring $\mathbb{Z}/n\mathbb{Z}$ and Euler function $\phi (n)$, but i am not sure how to start, i have a few ideas, but none of them leads me to the end of the proof. So, here is the problem. Let $n$ be a squarefree integer( integer is one divisible by no perfect square, except 1 ). Let $k\in \mathbb{Z}/n\mathbb{Z}$ and $e=1+j\phi (n)$, where $\phi (n)$ is the Euler function and $j\in \mathbb{N}$. Show that $k^{e}=k$. My first thought, when i saw what i have to prove, was that i have to show the idempotence of the element $k$. I tried to show it, but i couldn't...
Then i recalled that $\phi (n)$ is the order of the unit group of $\mathbb{Z}/n\mathbb{Z}$, but i don't know how should i use it here...or i also know that $\phi(n)$ is always positive and even number, so $j\phi(n)$ must be also even, so the number $e$ is odd... Can anybody help me with this problem? I have the feeling the things must be easy. I would be glad to read your hints, ideas or remarks. Thank you in advance!","['group-theory', 'abstract-algebra', 'number-theory']"
522996,Differentiating an integral using dominated convergence,"Let's say we have $$F(x)=\int^b_af(x,t)\ \mathrm{dt}$$ And we want to calculate $F'(x)$. Then: $$F'(x)=\lim_{h\to0}\frac{\int_{a}^{b}f(x+h,t)\mathrm{dt}-\int_{a}^{b}f(x,t)}{h}\mathrm{dt}=\lim_{h\to0}\int_{a}^{b}\frac{f(x+h,t)-f(x,t)}{h}\mathrm{dt}\tag1$$ Now, in class we were given (without proof) the proposition that $F'(x)=\int^b_a\frac{df}{dx}(x,t)\ \mathrm{dt}$ under certain conditions, one of which is that $\frac{df}{dx}(x,t)$ be dominated by some integrable function $g(t)$. If I could just commute the $\lim$ and the $\int$ in $(1)$, I could prove this proposition. In order to justify that, I need to find an integrable $g(t)$ such that: $$\frac{f(x+h,t)-f(x,t)}{h}\leq g(t)$$ in a neighborhood of $0$ (right?). This seems very similary to the requirement we learned in class, but how is the boundedness of $\frac{df}{dx}(x,t)$ equivalent to the boundedness of the above? All I can see is that as $h\to0$, the difference quotient is pointwise eventually smaller than $g$. But I don't see that I can conclude that there is therefore a neighborhood of $0$ where the difference quotient is bounded by $g$.","['integration', 'analysis']"
522998,"Conjecture $\int_0^1\frac{\ln\left(\ln^2x+\arccos^2x\right)}{\sqrt{1-x^2}}dx\stackrel?=\pi\,\ln\ln2$","$$\int_0^1\frac{\ln\left(\ln^2x+\arccos^2x\right)}{\sqrt{1-x^2}}dx\stackrel?=\pi\,\ln\ln2$$
Is it possible to prove this?","['closed-form', 'calculus', 'integration', 'logarithms', 'conjectures']"
523022,Intuition of Chern-Weil theory,"Let $ P \rightarrow M$ be a $G$-principal bundle. The lie algebra of $G$ is $\frak{g}$ and $P$ has connection form $\omega \in H^1(P,\frak{g})$ and curvature form $\Omega \in H^2(P,\frak{g})$. We consider $I^*(G)$ the set of invariant polynomials of $G$ ie the multilinear functions $f: \frak{g} \times ... \times \frak{g} \rightarrow \mathbb{R}$ satsifying $f(Ad(g)X_1,...,Ad(g)X_k) = f(X_1,...,X_n)$ for all $g \in G$ with $Ad(g) = (R_g)_*$ the map induced on $\frak{g}$ by the right multiplication with an element of $G$. It turns out very surprisingly that 1)the form $f(\Omega)(V_1,...,V_{2k}) = f(\Omega(V_1,V_2),...,\Omega(V_{2k-1},V_{2k}))$ can be projected to a form in $H^{2k}(M)$ is independant of the choice of connection for $P$ and 2) in the case of the $GL(n,\mathbb{K})$-bundle (with $\mathbb{K} = \mathbb{R} $ or $ \mathbb{C}$) associated to a vector bundle this form represents a characteristic class of the bundle. My problem is that I have read proofs of the statements but I do not feel I understand why they are true. In other words, what made Chern and Weil expect that this construction would yeild characteristic classes?","['characteristic-classes', 'principal-bundles', 'algebraic-topology', 'differential-geometry']"
523027,"A math contest problem $\int_0^1\ln\left(1+\frac{\ln^2x}{4\,\pi^2}\right)\frac{\ln(1-x)}x \ \mathrm dx$","A friend of mine sent me a math contest problem that I am not able to solve (he does not know a solution either). So, I thought I might ask you for help. Prove:
  $$\int_0^1\ln\left(1+\frac{\ln^2x}{4\,\pi^2}\right)\frac{\ln(1-x)}x dx=-\pi^2\left(4\,\zeta'(-1)+\frac23\right).$$","['improper-integrals', 'calculus', 'integration', 'contest-math', 'definite-integrals']"
523074,Differential calculus vs Integral calculus,"I have never done integration in my life and I am in first year of university. Is it harder than taking the derivative? I've heard its just going backwards. Also, my high school taught me only differentiation, I don't know why we never touched on integration. I'm going to be starting it next week and I want to know what I'm facing. Is it generally considered harder than differentiation? Thank you in advance.","['calculus', 'integration', 'derivatives']"
523077,Radical expression for Cosine formulas,"Is there nice radical expression for $$\cos\left(\frac{\pi}{2^k+1}\right)?$$ Example: $\cos\left(\dfrac{\pi}{5}\right)=\dfrac{\sqrt{5}+1}{4}$. Please provide some concrete examples. Also please provide a general procedure. I would like to handle $$\cos\left(\frac{a\pi}{2^k+1}\right)$$ as well for $a\in\{0,1,2,\dots,k-1\}$.","['radicals', 'trigonometry']"
523090,How to list the prime factorised natural numbers?,"Today I set out to invent a two character numeral system designed to make factorization trivial. Indeed, it lets one factor non-trivial numbers with over thousand digits within 30 seconds per hand - the upshot is that the notation isn't particularly suited for arithmetic. In fact, when I try to add certain two digit numbers, my computer gives me an overflow warning. The idea is to not use any base like binary or decimal, as in $28=2\cdot 10^1+8\cdot 10^0$, but to hardcode the prime factors $28=2^2\cdot 3^0 \cdot 5^0 \cdot 7^1$ into the notation. So denote the start and end of a number by ""$s$"" and ""$e$"". I set $0:=se$ and declare a natural number to be any string of the form ""$sxe$"" where $x$ is a finite string of numbers. The $n$'th number in the sequence $x$ denotes the power oth the $n$'th prime number and ""$sxe$"" is the associated product. So from an ordinal point of view $1=2^0=s0e=ssee$ $2=2^1=s1e=ssseee$ $3=2^0\cdot 3^1=s01e=ssesseee$ $4=2^2=s2e=sssseeee$ $5=2^0\cdot 3^0\cdot 5^1=s001e=ssesesseee$ ... $28=2^2\cdot 3^0 \cdot 5^0 \cdot 7^1=s2001e=sssseeesesesseee$ I came to the conclusion that the language consists of all the strings with equal number of $s$'s and $e$'s, where while scanning from the left there are always more $s$'s than $e$'s and the substring $esee$ isn't allowed. The first condition makes sure that all numbers close and the second one disallows superfluous factor of powers of 0. I've written a script which brute force generates these strings (it forms all permutations of even numbers of $s$'s and $e$'s and then drops the disallowed ones) and also one to translate them to decimal expression (which relies on knowing what the $n$'th prime is): http://pastebin.com/RwkGX6TV This e.g tells me that 2417851639229258349412352 is sssesssseeeeee and the nice thing is that all numbers factor easily: $sssesssseeeeee$ $= s(s(se)(s(s(s(se)e)e)e)e)e$ $=s(s0(s(s(s0e)e)e)e)e$ $=s(s0(s(s1e)e)e)e$ $=s(s0(s2e)e)e$ $=s(s0(2^2)e)e$ $=s(2^0\cdot 3^{2^2})e$ $=2^{3^{2^2}}.$ For now, I've generated most of the numbers with 20 characters and I've added an artificial bound of $R=10^{50}$ to the size of the exponents. This is necessary, as e.g. the number $13$, being the $6$th prime, reads $ssesesesesesseee$, i.e. $s000001e$ but it's neighbors in this enumeration can be numbers with thousands of digits. Generating the strings is simple down at $14$ but multiplication is hard. Later, also higher number of strings are needed and the way I produce the permutation is probably inefficient. To generate a bigger library of numbers, I'd like to know if someone has an idea for a less arbitrary enumeration of the the strings which avoid the uncomputably big numbers. Does someone maybe know an good way to enumerate the numbers in the form $1,2,3,2^2,5,2\cdot 3,7,\cdots,3^{2^5}\cdot 11^2\cdot 19^3,\cdots$?","['formal-languages', 'number-theory', 'prime-factorization', 'computer-science', 'prime-numbers']"
523095,Convert trig of angle in degrees to decimal value without a calculator,"Been forever since I did trig, I know how to use my calculator to do it, but I can't remember if there is a way to evaluate $\cos(x)$ without a calculator.  For example: $\cos(30)$ evaluates to $0.866025$ How would one come up with that value without plugging it into a calculator?",['trigonometry']
523100,Can we use $n\log n$ instead of $n$-th prime?,"Denote $\pi(x)$ be the number of primes $\leq x,$ $p(n)$ be the $n$-th prime number. 
We have $\pi(p(n))=n.$ It's well known that 
$$\pi(x)\sim \frac{x}{\log x}
\\p(n)\sim n\log n.$$ Is it always true that if $f(x)$ is a function and $f(x)>0, \forall x>0$ $f(x)$ is a monotonic function $f(x)=O(x^r)$ for some $r>0$ $\sum_{n=1}^{\infty}f(n)=\infty$ then $$\sum_{p\leq x}f(p)\sim \sum_{t\leq \pi(x)}f(t\log t)$$?","['analytic-number-theory', 'number-theory']"
523111,path connected subspaces of $\mathbb R^2$,"I am trying to prove two statements that visually I think they are ""obvious"", but I am totally lost when it comes to do a formal proof.
The statement of the exercise is:
Decide whether $\mathbb R^2 \setminus \{(0,0)\}$ and $\mathbb R^2 \setminus \{(x,0)\mid x \in \mathbb R\}$ are path connected. Visually, this is what I see : removing a point from the plane doesn't alterate much. I mean, the only problem I would have is with the points $x$,$y$ that live in a line that also contains the point $(0,0)$. That being the case, I could define a curve joining those two points without passing through $(0,0)$. If I remove a line from the plane, then I am in trouble. This line divides the plane into two regions. If I take a point $x$ that lives in one part and another point $y$ that is contained in the other side, then there is no continuous function that can join me those two points. I have no idea how to prove it without the ""hand-waving"". Also, I have a doubt when it comes to generalizing this idea to $\mathbb R^n$. I suppose that removing a hyperplane is what affects path-connectedness, but I'm not so sure, I am just generalizing from the case of the real line and the plane. Is there any good topology textbook that treats this topic of metric spaces?","['general-topology', 'connectedness', 'analysis']"
523119,Discrete math proof issue,"This is a question from my discrete math quiz. I was asked to prove there exists a Q(x). I used Disjunctive Syllogism to prove it. I was marked incorrectly because I used two different variables in the syllogism. My view is the variables can be implicitly the same, and I don't think this is incorrect. What do you think?","['predicate-logic', 'propositional-calculus', 'discrete-mathematics']"
523159,$50^{th}$ digit from the left in the expansion of $(\sqrt{50}+7)^{50}$.,"The $50^{th}$ digit from the left in the expansion of $(\sqrt{50}+7)^{50}$ after the decimal point. $\underline{\bf{My\; Try}}::$ Let $\left(\sqrt{50}+7\right)^{50} = I+f$, where $I = $Integer part and $f = $ fractional part. and $0\leq f<1$ Now Let $\left(\sqrt{50}-7\right)^{50} = g$ and here $0\leq g<1$ Now $\displaystyle \left(\sqrt{50}+7\right)^{50}+\left(\sqrt{50}-7\right)^{50} = 2\left(\binom{50}{0}\cdot (\sqrt{50})^{50}+\binom{50}{2}\cdot (\sqrt{50})^{48}\cdot 7^2+..............+\binom{50}{50}\cdot 7^{50}\right)$ $\displaystyle \left(\sqrt{50}+7\right)^{50}+\left(\sqrt{50}-7\right)^{50} = $Integer quantity. $\displaystyle I+f+g = $ Integer Quantity. and $0\leq f+g<2$ So $(f+g) = 0$ or $(f+g) = 1$ So $I=$Integer quantity or $I = $ Integer quantity$\;\;  -1$. Now I did not understand how can i get it. Help required. Thanks edited.",['algebra-precalculus']
523163,"$C^{2, \alpha}$ regularity for elliptic equations with Neumann boundary conditons","Say $\Omega\subseteq \mathbb{R}^n$ is a bounded open set and $0<\alpha<1$. I need some $C^{2, \alpha}(\overline\Omega)$ regularity result for elliptic equations with Neumann boundary conditions but that is what I find in Jurgen Jost' book: If $u$ is a weak solution of $\Delta u=f$ in $\Omega$ and $f\in C^\alpha(\Omega)$, then $u\in C^{2,\alpha}(\Omega)$..........(1) But it says that we can identify $C^{2, \alpha}(\Omega)$ with $C^{2,\alpha}(\overline\Omega)$ here: http://www.math.ucsd.edu/~bdriver/231-02-03/Lecture_Notes/Holder-spaces.pdf . However, Jost used both $C^{2, \alpha}(\Omega)$ and  $C^{2,\alpha}(\overline\Omega)$ (when he is doing regularity for Dirichlet boundary) in his book, which indicated these two spaces are not the same? Or do we have $u\in C^{2,\alpha}(\overline\Omega)$ in (1)? Otherwise where can I find some $C^{2,\alpha}(\overline\Omega)$ regularity result with Neumann boundary conditon?","['definition', 'partial-differential-equations', 'analysis']"
523172,Show convergence in probability,"Let $X_1,X_2,\dots$ be I.i.d. And $S_n = X_1+X_2+\dots +X_n. $Prove if $S_n/n \to 0$ in probability then $(\max_{1\leq m \leq n}S_m)/n \to 0$ in probability. I know the idea and there is a detail I don't know how to prove. 
If |Sn-Sk|$\leq$|Sn|+|Sk| and Sn/n limits to 0 in probability, how can I prove that minP(|Sn-Sk|$\leq n\delta$)$\to $ 1 as $ n \to \infty$ ($0\leq k \leq n$)","['convergence-divergence', 'probability']"
523177,"Prove maximum value of $(z-xy)(x-yz)(y-zx)$ is $\frac{1}{64}$ given $x,y,z \in (0,1)$","Prove maximum value of $(z-xy)(x-yz)(y-zx)$ is $\frac{1}{64}$ given $x,y,z \in (0,1)$ I can make it $\frac{1}{64}$ by setting $x,y,z = \frac{1}{2}$, but I have no idea how to show that's the maximum.",['algebra-precalculus']
523198,What does it mean to induce a topology?,"I am reading the definition of ""metrizability"" which states that if there exists a metric $d$ on set $X$ that induces the topology of $X$, then it is metrizable. My question is how can we possibly know what topology is being induced by metric $d$ which is supposed to be a distance function. How can the distance function and collection of open sets be related?",['general-topology']
523289,"What are the differences between Jacobson's ""Basic Algebra"" and ""Lectures in Abstract Algebra""?","Nathan Jacobson's books ""Basic Algebra I, II"" and ""Lectures in Abstract Algebra - Volumes I, II, III (GTM 30, 31, 32)"". What are the differences between these two books? 1) The subject. The material of the two books overlap, which one is better? 2) Does ""Lectures in Abstract Algebra"" aim to undergraduate? 3) ""Basic Algebra I, II"" Cannot edit a word! Really? 4) Is it necessary to read the two books? Thanks a lot!","['reference-request', 'abstract-algebra']"
523299,square matrix is not invertible if at least one row or column is zero,"How to show that a square matrix is not invertible if at least one row or column is zero ? I can show if a row is zero, the result C of $AB=C$ can not be the identity matrix because there is a zero row. But for the column case ? Assume I don't know something about determinants.",['matrices']
