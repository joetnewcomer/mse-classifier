question_id,title,body,tags
288911,About Measure Theory $\mu$-almost everywhere.,"Can anyone help me with my big problem about real analysis and measure theory. In Mathematics are a lot of theorem which are proved with the help of the notion $\mu$-almost everywhere . I know that $\mu$ is a measure, but I want to know when can I apply the  theory of $\mu$-almost everywhere and when I cannot. Can you give me some example please. Thanks :)","['measure-theory', 'real-analysis']"
288912,The Gram-Schmidt process is a deformation retraction,"Consider the Gram-Schmidt process $r : GL(n) \rightarrow O(n)$ that sends invertible matrices to orthogonal matrices. I need to show this is a deformation retraction and, by restrictions of $r$, establish each space is a deformation retract of the following: $SO(n) \subset SL(n) \subset GL^{+}(n)$ where $GL^{+}(n)$ is the set of matrices with positive determinant. I'm not very experienced with linear algebra so I'm having some difficulty in this. The idea I had was to define, for vectors $u, v \in R^{n}$ and real $t \in [0, 1]$, the altered projection:
$P(u, v, t) = \displaystyle\frac{<u, (1 - t)u + tv> u}{<u, u>}$. Then we'd have the homotopy $H((a_{1}, ..., a_{n}), t) = (w_{1}, ..., w_{n})$ where $w_{1} = a_{1}$ $w_{2} = a_{2} - P(w_{1}, a_{2}, t)$ .
. $w_{n} = a_{n} - \displaystyle\sum_{i = 1}^{n - 1} P(w_{i}, a_{n}, t)$. But actually now I think this doesn't work, because I can't really guarantee it's invertible for all $t$.  I have no other ideas.","['lie-groups', 'linear-algebra', 'algebraic-topology']"
288920,Sudoku puzzles and propositional logic,"I am currently reading about how to solve Sudoku puzzles using propositional logic. More specifically, they use the compound statement $$\bigwedge_{i=1}^{9} \bigwedge_{n=1}^{9} \bigvee_{j=1}^{9}~p(i,j,n)$$ where $p(i,j,n)$ is the proposition that is true when the number
$n$ is in the cell in the $ith$ row and $jth$ column, to denote that every row contains every number. I know that this is what the entire compound statement implies, but I am trying to read each individual statement together. Taking one single case, does $$\bigwedge_{i=1}^{9} \bigwedge_{n=1}^{9} \bigvee_{j=1}^{9}~p(i,j,n)$$ say that in the first row, the number one will be found in the first column, or second column, or third column, etc?","['propositional-calculus', 'discrete-mathematics', 'sudoku']"
288921,Converting $\exists x \exists y (x\geq y)$ into English,"$\exists x \exists y (x\geq y)$ The universe of discourse is all real numbers. This says that there exists an $x$ and there exists a $y$ such that $x\geq y$. But what is this actually trying to say?  I would like to think that it's saying ""a number is as large as itself"", but I would like some clarification.","['logic', 'quantifiers', 'discrete-mathematics']"
288922,Can an event be possible if its probability is zero?,"Consider a computer program that generates any random number between 0 and 1(exclusive). There are infinitely many numbers between 0 and 1. So the probability that the random-number generate the same number twice, will be given by - $P(E)={1\over \infty}=0$ ($\because$ number of favourable outcome = 1, sample space = $\infty$) But it has happened many times that the program repeats a number, even though, the probability of that event is 0. Please explain this.","['statistics', 'probability']"
288936,Convergence of the sequence $(1+\frac{1}{n})(1+\frac{2}{n})\cdots(1+\frac{n}{n})$,"I have a sequence $(a_n)$ where for each natural number $n$,
  $$a_n = (1+\frac{1}{n})(1+\frac{2}{n})\cdots(1+\frac{n}{n})$$ and I want to find its limit as $n\to\infty$. I obviously couldn't prove it and after several futile attempts decided to post it here. Here is a list of a few observations which I got from those attempts: The sequence $(a_n)$ is a strictly increasing sequence. To prove this, I rewrote each element as $$a_n = (1+\frac{1}{n})(1+\frac{2}{n})\cdots(1+\frac{n}{n})= \frac{(n+1)\cdots(n+n)}{n^n}= \frac{(2n)!}{n!n^n}.$$
Then $$\frac{a_{n+1}}{a_n}= \frac{2(n+1)!}{(n+1)!(n+1)^{n+1}}\frac{n!n^n}{(2n)!}=\frac{(2n+1)(2n+2)}{(n+1)^2(1+\frac{1}{n})^n} \to \frac{4}{e}$$ as $n\to\infty$. Since $\frac{4}{e}>1$ we have $a_{n+1}>a_n$ eventually. The limit of this sequence is bounded below by $e$. By replacing $1,2, \ldots, n$ with $1$ in the expression of $a_n$, we get $a_n \geq (1+\frac{1}{n})^n$. And thus $\lim{(a_n)}\geq e$. $\lim{(a_n)}\geq e^2$ and $\lim{(a_n)}\geq e^3$. The first assertion follows from the fact that $$a_n\geq(1+\frac{1}{n})(1+\frac{2}{n})^{n-1}= \frac{(1+\frac{1}{n})(1+\frac{2}{n})^{n}}{(1+\frac{2}{n})} \to e^2.$$ And the last one follows the same way because $$a_n\geq (1+\frac{1}{n})(1+\frac{2}{n})(1+\frac{3}{n})^{n-2}.$$ Now I have a gut feeling that for any natural number $k$, one can show that for all sufficiently large natural number $n$, $$a_n\geq (1+\frac{1}{n})\cdots(1+\frac{k-1}{n})(1+\frac{k}{n})^{n-(k-1)}.$$ And therefore for all $k \in \mathbb{N}$, $\lim{(a_n)}\geq e^k$ making the sequence divergent. But I'm really not sure about this approach and I'll appreciate any help towards this end. Thank you. [Note: As this sequence is quite common, there may be other posts on math.SE asking the same question. I didn't search for them because I just don't know how to search for an expression this big. Though a link related to any previous question concerning this particular sequence will be good enough, I will greatly appreciate if someone takes the trouble to look into my approach/observations and point out where  I'm going wrong.]","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
288938,$x^2+1=0$ uncountable many solutions [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Why are the solutions of polynomial equations so unconstrained over the quaternions? Coudl someone explain me the following: Why should $x^2+1=0$ have uncountable infinite many solutions $x\in\mathbb H$? In my opinion it has only 4 solutions, namely $i^2=j^2=k^2=ijk=-1$ ?","['abstract-algebra', 'complex-numbers', 'quaternions', 'real-analysis']"
288954,What does it mean to show that something is well defined?,"This is coming from my first course in undergraduate analysis, and it's confusing to me how to show that some operation is ""well-defined"". For example, my professor left as something for us to figure out on our own, not homework, to show ourselves that if $a,b,c$ and $d$ are integers, and ($b,d\not=0$) that $$\left[\left(\frac{a}{b}\right)\right]+\left[\left(\frac{c}{d}\right)\right]=\left[\left(\frac{ad+bc}{bd}\right)\right]$$ is well defined. He then made an example that said: If $\frac{a'}{b'}\sim\frac{a}{b}$ and $\frac{c'}{d'}\sim \frac{c}{d}$, then $\frac{a'c'}{b'd'}\sim \frac{ac}{bd}$. Also above in the brackets are supposed to be $2$ classes of element's.",['real-analysis']
288956,Surjectivity in exact sequence coming from the sheaf axioms,"Let $\mathcal{O}_{X}$ be a sheaf of rings on a topological space $X$, and let $U\subseteq X$ be an open set.  It is common to give the sheaf axioms as exactness of a sequence.  For any open covering $\left\{U_{i}\right\}$ of $U$, we have the exact sequence: $ 0 \to \mathcal{O}_{X}(U) \to \prod_{i}\mathcal{O}_{X}(U_{i}) \to \prod_{i,j} \mathcal{O}_{X}(U_{i}\cap U_{j})$ The last map's projection to each factor sends a sequence $(s_{i}) \mapsto s_{i}\vert_{U_{i}\cap U_{j}} - s_{j}\vert_{U_{i}\cap U_{j}}$. My question: Are there conditions in which this last map is a surjection?  Do these kinds of sheaves have a name? Thanks!","['sheaf-theory', 'algebraic-geometry']"
288958,Does $\lim_{n\to\infty}\underset{n}{\underbrace{\cos(\cos(...\cos x))}}$ exist? [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Explaining $\cos^\infty$ Does the following limit exist? $$\lim_{n\to\infty}\underset{n}{\underbrace{\cos(\cos(...\cos x))}}$$ If yes, find the limit. If no, please explain why the limit doesn't exist. I think, the limit exists. So, I tried to use Squeeze theorem but didn't work.","['dynamical-systems', 'trigonometry', 'calculus', 'limits']"
288965,Show that $(a+b+c)^3 = a^3 + b^3 + c^3+ (a+b+c)(ab+ac+bc)$,"As stated in the title, I'm supposed to show that $(a+b+c)^3 = a^3 + b^3 + c^3 + (a+b+c)(ab+ac+bc)$. My reasoning: 
$$(a + b + c)^3 = [(a + b) + c]^3 = (a + b)^3 + 3(a + b)^2c + 3(a + b)c^2 + c^3$$ $$(a + b + c)^3 = (a^3 + 3a^2b + 3ab^2 + b^3) + 3(a^2 + 2ab + b^2)c + 3(a + b)c^2+ c^3$$ $$(a + b + c)^3 = a^3 + b^3 + c^3 + 3a^2b + 3a^2c + 3ab^2 + 3b^2c + 3ac^2 + 3bc^2 + 6abc$$ $$(a + b + c)^3 = (a^3 + b^3 + c^3) + (3a^2b + 3a^2c + 3abc) + (3ab^2 + 3b^2c + 3abc) + (3ac^2 + 3bc^2 + 3abc) - 3abc$$ $$(a + b + c)^3 = (a^3 + b^3 + c^3) + 3a(ab + ac + bc) + 3b(ab + bc + ac) + 3c(ac + bc + ab) - 3abc$$ $$(a + b + c)^3 = (a^3 + b^3 + c^3) + 3(a + b + c)(ab + ac + bc) - 3abc$$ $$(a + b + c)^3 = (a^3 + b^3 + c^3) + 3[(a + b + c)(ab + ac + bc) - abc]$$
It doesn't look like I made careless mistakes, so I'm wondering if the statement asked is correct at all.",['algebra-precalculus']
288974,Funny thing. Multiplying both the sides by 0?,"Alright this maybe really funny but I want to know why is this wrong. We often come across identities which we prove by multiplying both the sides of the identity by a certain entity but why don't we multiply it by $0$ . That way every identity will be proved in one single line. That is so stupid. I mean, by that way we may also say that $1=2=3$ . I know it is wrong. But why? I mean if we can multiply both the sides by $2$ then why not by $0$ .  For example, consider the following trigonometric identity : Prove the identity : $\sin^2 \theta = \tan^2 \theta \cos ^2 \theta$ Usual way To Prove : $\sin^2 \theta = \tan^2 \theta \cos ^2 \theta $ $\displaystyle \implies {\sin^2 \theta \over \cos^2 \theta } = {\tan^2 \theta \cos ^2 \theta \over \cos^2 \theta}$ (multiplying both the sides by $\displaystyle 1 \over \cos^2 \theta$ ) $\implies \tan ^2 \theta = \tan^2\theta$ $\implies LHS=RHS$ $\therefore proved$ Funny way To Prove : $\sin^2 \theta = \tan^2 \theta \cos ^2 \theta $ $\displaystyle \implies {\sin^2 \theta \times 0} = {\tan^2 \theta \cos ^2 \theta \times 0}$ (multiplying both the sides by $0$ ) $\implies 0 = 0$ $\therefore proved$ Please explain why is this wrong.","['trigonometry', 'fake-proofs']"
288985,Homomorphism between finitely generated algebra,"Let $A,B,C$ are the coordinate ring of three affine varieties in affine space over an algebraically closed field $k$, $B$ and $C$ are normal, and $i: A\longrightarrow B$ is an injective $k$-algebra homomorphism. If there is another injective $k$-algebra homomorphism $\varphi$ from $A$ to $C$, can we deduce that there exists a homomorphism $\psi: B\longrightarrow C$ such that $\varphi=\psi\circ i$ ? If such homomorphism exists, is it unique ?","['commutative-algebra', 'algebraic-geometry', 'abstract-algebra']"
288996,Solving $\;5^{2x}-4\cdot 5^x=12$,I need to solve $\quad\displaystyle 5^{2x}-4\cdot 5^x=12$. I've only gotten this far: $\quad \displaystyle 5^{2x}-20^x=12.$ I don't know what to do next. Thanks in advance!,"['logarithms', 'algebra-precalculus']"
289006,Definite double integral of a trigonometric function,"I am in trouble in the calculation of the following double integral:
$$\int_0^a d\rho\int_0^{2\pi}d\phi\exp(-ik\rho(\sin(\theta_0)\cos(\phi_0-\phi)+\sin(\theta_1)\cos(\phi_1-\phi)))\rho$$
Many thanks","['definite-integrals', 'trigonometry']"
289016,Partitions and Bell numbers,"Let $F(n)$ be the number of all partitions of $[n]$ with no singleton blocks. Find the recursive formula for the numbers $F(n)$ in terms of the numbers $F(i)$, with $i ≤ n − 1$ Find a formula for $F(n)$ in terms of the Bell Numbers $B(n)$. For the first question, it's obviously something like $F(n+1) = \sum_{i=0}^n {n \choose i} F(i)$, since that's what it is for Bell numbers, but I really can't see how I'd get to the correct formula. For the second one, I believe I'm supposed to use inclusion-exclusion, but I'm a bit lost.","['bell-numbers', 'integer-partitions', 'inclusion-exclusion', 'combinatorics']"
289027,Prove that the centralizer $C_K(H)$ has finite index in $K$,"Let $H,K$ be subgroups of a group $G$. If $[H,K]$ is finite and $H$ is finitely generated, then the centralizer $C_K(H)$ has finite index in $K$. More precisely, if $[H,K]$ has order $n$ and $H$ is $m$-generated, then $|K : C_K(H)| \leq n^m$.",['group-theory']
289035,how prove that $|f(x)|\ge2^n (n+1) $ under these conditions?,"Assume $f:[0,1]\mapsto\mathbb{R}$ is continuous and satisfies $\int_0^1x^kf(x) \, dx=0 \quad\forall k\in\{0,1,2,\ldots,n-1\}$, $\int_0^1x^n f(x) \, dx=1$. How do you prove that $\exists x\in[0 ,1]$ such that $|f(x)|\ge2^n (n+1) $?","['integration', 'analysis']"
289037,integral of the complex function $1/\cos(1/z)$,"I am looking for $\underset{|z|=1}{\oint}\frac{1}{\cos\left(\frac{1}{z}\right)}dz$ I was able to do the following: 
$$\underset{|z|=1}{\oint}\frac{1}{\cos\left(\frac{1}{z}\right)}dz=\underset{|z|=1}{\oint}\frac{1}{\cos\left(\overline{z}\right)}dz=\underset{|\overline{z}|=1}{\oint}\overline{\frac{1}{\cos\left(z\right)}}dz$$ But got stuck here, any help would be greatly appretiated.","['integration', 'complex-analysis']"
289038,"Reflexive , symmetric and transitive closure of a given relation","Given a relation $R = \{(x,y)\mid y=x+1\}$ and I have to find the reflexive, transitive and symmetric closure. For reflexive , I added $y=x$ with given condition so now the relation becomes 
  $R = \{(x, y)~| ~y=x+1 , \text{ or}\; y=x\}$ To make it symmetric , I added $y=x-1$ as one more condition but I am confused about transitive closure, what will be that? Will the final result be a reflexive relation ?","['relations', 'discrete-mathematics', 'elementary-set-theory']"
289054,Solve $y^{\prime \prime}-(y^{\prime})^2-y^{\prime}=0$,Solve $y^{\prime \prime}-(y^{\prime})^2-y^{\prime}=0$. I use $$u=\frac{dy}{dx}$$ to transform the DE into $$\frac{du}{dx}-u^2-u=0$$. I know that this is an Bernoulli equation with $n=2$. I get the final solution is $$y=-ln|1-Ae^x|+D$$ where $A=+-e^c$. But my lecturer's answer is $$y=-ln|C_1+c_2e^x|$$. May I know what is the difference my answer and my lecturer answer ?,['ordinary-differential-equations']
289063,$\sum\limits_{n=1}^\infty |a_n|$ converges implies $\sum\limits_{n=1}^\infty |a_n|^2$ converges? [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Prove that $\sum_{n=1}^{\infty}\ a_n^2$ is convergent if $\sum_{n=1}^{\infty}\ a_n$ is absolutely convergent If $\sum\limits_{n=1}^\infty |a_n|$ converges, the $\sum\limits_{n=1}^\infty (a_n)^2$ is also always convergent?","['sequences-and-series', 'convergence-divergence', 'calculus']"
289079,Proof that final topology with a certain property is unique,"Assume we are given a set of topological spaces $(X_i,\tau_i), \forall i \in I$, a set $Y$, a set of functions $f_i: X_i\rightarrow Y$, a topological space $(Z,\sigma)$ and a function $h : Y\rightarrow Z$. Then assume that $h$ is continuous $\iff$ $h \circ f_i $ is continuous $\forall i \in I$. Let $\tau$ be final topology on $Y$, defined $\tau = \{U \subset Y | f^{-1}_i (U) \in \tau_i, \forall i \in I\}$. I must prove that this topology is unique, ie. only topology on $Y$ that fulfills the requirement that $h$ is continuous $\iff$ $h \circ f_i $ is continuous $\forall i \in I$. Attempt: Assume that instead of $\tau$ we had $\tau^´$. Then assume that $g \in \sigma$. Now $(h \circ f_i)^{-1} (g) \in \tau_i,\  \forall i \in I$, for for continuous function, the preimage of an open set is open. Also $ f_i^{-1}(h^{-1}(g)) = f_i^{-1}(v), \ v \in \tau^´$, for the same reason. Now $f_i^{-1}(v) \in \tau_i, \ \forall i \in I,$ for if they weren't, then $\tau_j \not\owns U=f_j^{-1}(v)=f_j^{-1}(h^{-1}(g))=(h \circ f_j)^{-1} (g) = U \in \tau_j$, for some $j \in I$, this is contradiction. But what I cannot get out of my head are a few questions. Like, how can we know that there isn't some set $k \in \tau^´$ where $h (k) \notin \sigma$? This image $h (k)$ doesn't have to be closed, or does it? If it needs to be, then this case is violation of the continuity of $h$. Also, how can we know that there is not some $t \subset Y$ in $\tau^´$ for which $f^{-1}_j(t) \notin \tau_j$ and it is not the preimage of any set in $\sigma$? This would be bigger than $\tau$ but we would have no way to get to these extra sets.","['general-topology', 'continuity']"
289086,Does the gradient always point outward of a level surface?,"Let $f:\mathbb{R}^n\to \mathbb{R}$ be a differentiable function, with $a\in \mathbb{R}$ a regular value of $f$. Let $M=f^{-1}((-\infty,a])$. Then $M$ is an $n$-manifold with boundary, whose boundary is $\partial M=f^{-1}(a)$. Let $p\in \partial M$. Then $T_p\partial M=\{\nabla f(p)\}^{\perp}$. Question : Does $\nabla f(p)$ point outwards of $\partial M$? I know it's not true if we take the interval the other way around. E.g. $-1$ is a regular value of $f:\mathbb{R}^2\to \mathbb{R}$, $f(x,y)=-x^2-y^2$, but the gradient of $f$ points inwards of the boundary of $f^{-1}([-1,+\infty))$ which is $S^1$. In fact, by symmetry, if the answer to the question is positive, I suspect that if we take $M=f^{-1}([a,+\infty))$ then $\nabla f(p)$ always points inwards of $\partial M$.","['multivariable-calculus', 'differential-geometry']"
289101,Evaluating $\lim_{n \to \infty} \oint_{ |z| = 1/4} \frac{1}{(4 z(1-z))^n} \frac{\mathrm{d}z}{z (1-2 z)} = \frac{1}{2}$,"While working on an earlier question involving $\sum_{j=0}^n \binom{n+j-1}{j} \frac{1}{2^{n+j}}$ I rewrote the sum as a contour integral, using generating functions:
$$
     \sum_{j=0}^n \binom{n+j-1}{j} \frac{1}{2^{n+j}} =  \sum_{j=0}^n \left( \frac{1}{4^n} \binom{n+j-1}{j} \right) 2^{n-j} = [t^n] \left( \sum_{j=0}^\infty \frac{t^j}{4^n}\binom{n+j-1}{j}  \cdot \sum_{j=0}^\infty t^j 2^j \right)
$$
Now, using well known generating functions, for $|t|<1/2$:
$$
   \sum_{j=0}^\infty t^j \binom{n+j-1}{j} = \frac{1}{(1-t)^n} \quad \sum_{j=0}^\infty (2t)^j = \frac{1}{1-2t}
$$
We get
$$
   \sum_{j=0}^n \binom{n+j-1}{j} \frac{1}{2^{n+j}} = [t^n] \left( \frac{1}{1-2t} \frac{1}{\left(4(1-t)\right)^n} \right) = \frac{1}{2 \pi i} \oint \frac{1}{1-2t} \left(\frac{1}{4 t(1-t)} \right)^n \frac{\mathrm{d} t}{t}
$$
where the Cauchy integral formula was used along with $n! [t^n] g(t) = g^{(n)}(0)$. Now, Byron Schmuland showed that the large $n$ limit of the left-hand-side equals $\frac{1}{2}$. Question: Can one demonstrate $$ \lim_{n \to \infty} \frac{1}{2 \pi i} \oint_{ |t| = \rho} \frac{1}{1-2t} \left(\frac{1}{4 t(1-t)} \right)^n \frac{\mathrm{d} t}{t} = \frac{1}{2}$$ using asymptotic methods? Here $0<\rho<\frac{1}{2}$.","['contour-integration', 'limits']"
289114,"Show that holomorphic $f_1, . . . , f_n $ are constant if $\sum_{k=1}^n \left| f_k(z) \right|$ is constant.","While studying for an exam in complex analysis, I came across this problem. Unfortunately I was not able to solve it. Any help would be greatly appreciated. Let $U ⊂ \mathbb{C}$ be a domain and $f_1, . . . , f_n : U \rightarrow \mathbb{C}$ holomorphic functions, such that $\sum_{k=1}^n \left| f_k(z) \right|$ is constant on $U$. Show that $f_1, . . . , f_n$ are constant.",['complex-analysis']
289124,Prove that the entire function $f$ is a polynomial if it maps every unbounded sequence to an unbounded sequence.,"While studying for an exam in complex analysis, I came across this problem. Unfortunately I was not able to solve it. Any help would be greatly appreciated. Let $f$ be an entire function mapping every unbounded sequence in $\mathbb{C}$ to an unbounded sequence. Prove that $f$ is a polynomial.",['complex-analysis']
289128,Geometric interpretation of a vector space and subspace?,"I understand how to manipulate vector spaces and subspaces and how to prove various statements about them, but I still don't fully understand what they represent geometrically. I just need an intuitive grasp as to what these are. Is a vector space a geometric area that contains all possible vectors of the field $\Bbb F$? For example, if $V$ is a vector space over $\Bbb R^3$ then does that mean $V$ contains all vectors in three-dimensions that are part of $\Bbb R$? But then what is a subspace of $V$? Would that perhaps be a plane? Would it be a vector space in $\Bbb R^2$?",['linear-algebra']
289138,Binomial sum of $n$ terms in closed form,Can we calculate the given combinatorial sum in closed form? $$ \frac{\binom{2}{0}}{1}+\frac{\binom{4}{1}}{2}+\frac{\binom{8}{2}}{3}+\frac{\binom{16}{3}}{4}+\cdots+\frac{\binom{2^n}{n-1}}{n}$$,"['summation', 'sequences-and-series', 'binomial-coefficients']"
289147,Symmetry of a Plücker function,"Let $d \in \mathbb{N}$ and let $I$ be a set. Let $\omega : I^d \times I^d \to \mathbb{R}$ be a function, denoted by $(a_1,\dotsc,a_d,b_1,\dotsc,b_d) \mapsto a_1 \cdots a_d | b_1 \cdots b_d$, with the following properties: It is antisymmetric in the first $d$ variables, e.g. $a_1 a_2 \cdots a_d | \cdots = - a_2 a_1 \cdots a_d | \cdots$. It is also antisymmetric in the last $d$ variables. For all elements $a_1,\dotsc,a_{d-1}$ and $b_0,\dotsc,b_d$ of $I$ we have
  $$\sum_{k=0}^{d} (-1)^k a_1 \cdots a_{d-1} b_k | b_0 \cdots \widehat{b_k} \cdots b_n=0.$$ One might call $\omega$ a Plücker function because these relations resemble the Plücker relations . Claim. $a_1 \cdots a_d | b_1 \cdots b_d = b_1 \cdots b_d |a_1 \cdots a_d$ for all  $(a,b) \in I^d \times I^d$. For $d=1$ it is clear. Here is a proof for the case $d=2$: Using the relation $ab|cd- ac|bd + ad|bc=0$ four times, we get $$ab|cd = ac|bd - ad|bc=da|bc-ca|bd = db|ac-dc|ab-cb|ad+cd|ab$$
$$=bc|ad-bd|ac+2 cd|ab = ba|cd + 2 cd|ab ~ \Longrightarrow ~ 2 ab|cd = 2 cd|ab  ~~~\square$$ In the case $d=3$, a long calculation shows $abc|def=ade|bcf-adf|bce+aef|bcd$. So this already puts $bc$ on the right, but I don't know how to do this with $a$ without destroying this. There is some background for the claim, coming from categorified Grassmannians, but I won't explain this here because it is not necessary to understand the question, I think. It maybe that the claim is false, but then I am pretty sure (but have no proof) that a weaker version of it holds, but it needs even more variables and relations. I will add  this in case someone asks. Perhaps one can ask a computer algebra software to do the whole work? I have tried it with SAGE, but it didn't work out because non-commutative quotient rings are only available in conjunction with a representing system.","['grassmannian', 'abstract-algebra', 'symmetric-functions']"
289158,Proof of Cauchy–Schwarz inequality,"I was reading about the Cauchy–Schwarz inequality from Courant, Hilbert - Methods Of Mathematical Physics Vol 1 and I can not understand what they mean when they said the line that has been highlighted with red in the picture given below I can not understand why a and b has to be proportional and why is this so crucial for the roots to be imaginary and why we want the roots to be imaginary in the first place.","['triangles', 'linear-algebra', 'inequality', 'cauchy-schwarz-inequality']"
289172,Compute $\lim_{s\to 0} \left(\int_0^1 (\Gamma (x))^s\space\mathrm{dx}\right)^{1/s}$,"Compute 
$$\lim_{s\to 0} \left(\int_0^1 (\Gamma (x))^s\space\mathrm{dx}\right)^{1/s}$$ This is a problem I thought of these days and I think I know a way although
not completely justified. This is what I have Firstly take log
$$\lim_{s\to 0} \frac{\ln\left(\int_0^1 (\Gamma (x))^s\space\mathrm{dx}\right)}{s}\space \text{(Unjustified part where considering the numerator tends to 0) }$$
and then apply  l'Hôpital's rule
$$\lim_{s\to 0} \frac{\displaystyle \frac{d}{ds}\ln\left(\int_0^1 (\Gamma (x))^s\space\mathrm{dx}\right)}{\displaystyle \frac{d}{ds}s}\space=$$
$$\lim_{s\to 0} \frac{\displaystyle \frac{d}{ds} \left(\int_0^1 (\Gamma (x))^s\space\mathrm{dx}\right)}{\int_0^1 (\Gamma (x))^s\space\mathrm{dx}}\space=$$
and now differentiate under the integral sign
$$\lim_{s\to 0} \frac{\displaystyle \int_0^1 \frac{d}{ds}(\Gamma (x))^s\space\mathrm{dx}}{\int_0^1 (\Gamma (x))^s\space\mathrm{dx}}\space=$$
$$\lim_{s\to 0} \frac{\displaystyle \int_0^1 (\Gamma (x))^s \ln (\Gamma(x))\space\mathrm{dx}}{\int_0^1 (\Gamma (x))^s\space\mathrm{dx}}\space=$$
$$\int_0^1 \ln (\Gamma(x))\space\mathrm{dx} \space \text{(Unjustified - I considered $\lim_{s\to 0} \int_0^1 (\Gamma (x))^s=1$ ) }$$
At this point I'm done since we know to compute $\int_0^1 \ln (\Gamma(x))\space\mathrm{dx}$. So, for the problematic part I managed to split
$$\lim_{s\to 0} \int_0^1 (\Gamma (x))^s \mathrm{dx}$$
into 
$$\lim_{s\to 0} \left(\int_0^{\epsilon} (\Gamma (x))^s \mathrm{dx}+\int_{\epsilon}^{1} (\Gamma (x))^s \mathrm{dx}\right)$$
and then I'm thinking to use the uniform convergence for the first integral to prove that it tends to $0$. Am I on the right way? What would you suggest me to do further? Would you approach the problem in a different manner? Thanks!","['definite-integrals', 'calculus', 'real-analysis', 'limits']"
289180,What is this set theory question even asking me?,"I saw some other questions that had similar titles and checked them out, but none of them seemed to match this format. The question I have is: One quarter of the five-element subsets of $\{1, 2, 3, \cdots, n\}$
contain the element $7$. Determine $n (\ge 5)$. I don't understand what this question wants me to do. I understand what a subset is, and I know what elements are, but I don't know what ""Determine $n (\ge 5)$"" is asking me to do.","['elementary-set-theory', 'combinatorics']"
289185,Minimum of $\left| \sin x- 1\right| + \left|\sin x- 2\right| + \left| \sin x -3\right| + \left| \sin x+1\right|$,"I would like to know the minimum value of $$\left| \sin x- 1\right| + \left|\sin x- 2\right| + \left| \sin x -3\right| + \left| \sin x+1\right|$$ 
for $x \in \mathbb{R}$.",['algebra-precalculus']
289195,"For a differentiable map $\Phi$ between manifolds $M$ and $W$, what is $d\Phi?$ (Aubin)","I can't understand a passage from A Course in Differential Geometry by T. Aubin. First, there is Definition 2.6., which I posted in this question . And now there's this: $(\Phi_*)_P$ is nothing else than $(d\Phi)_P.$ ($\Phi:M_n\to W_p$, where $M_n$ and $W_p$ are manifolds of dimensions $n$ and $p$ respectively. $P\in M_n.$) I don't understand what this sentence means. I can't find a definition of $(d\Phi)_P$ earlier in the book. There is a definition for the case of $\Phi$ being a map between open subsets of Euclidean spaces, but not for general manifolds. So how can we establish that the two objects are the same if we haven't defined one of them? The author goes on to explain thus: Indeed, consider a local chart at $P$ with coordinates $\{x^i\}$ and a local chart at $Q$ with coordinates $\{y^a\}$. $\Phi$ is defined in a neighbourhood of $P$ by $p$ real-valued functions $\Phi^a(x^1,x^2,\cdots,x^n),\;a=1,2,\cdots,p.$ I don't get it. What are the $\Phi^a?$ If they're real-valued, then $(\Phi^1,\cdots,\Phi^p)$ cannot be equal to $\Phi$ because $\Phi$ goes from $M_n$ to $W_p$, not to $\Bbb R^p$. To get to $\Bbb R^p$, I need to compose $\Phi$ with a chart. And aren't the coordinates $x^i$ real too? I understand that when I have a chart $(\Omega,\varphi)$ for an open set $\Omega\subseteq M_n$ and $\varphi:\Omega\to\Bbb R^n,$ then the coordinates $x^i$ of a point $m\in M_n$ are the coordinates of $\varphi(m)$ in $\Bbb R^n$. So that would mean that $\Phi^a$ are actually functions from $\Bbb R^n\supseteq\Omega$ to $\Bbb R$. And probably $(\Phi^1,\cdots,\Phi^p)=\psi\circ\Phi\circ\varphi^{-1}$ for some charts $\phi$ and $\psi$. Is that correct? If so, isn't the notation very counterintuitive? The author now says the following. I don't understand it at all. He uses the symbol $(d\Phi)_P$ again, and I think it still hasn't been defined. Using intrinsic notations to simplify, we get $$X(f\circ\Phi)=d(f\circ\Phi)_P\circ X=(df)\circ(d\Phi)_P\circ X=(df)\circ(\Phi_*)_PX.$$ Indeed, $\{X^i\}$ being the components of $X$ in the basis $\{(\partial/\partial x^i)_P\},$ the components of $Y=(\Phi_*)_PX$ are $$Y^a=\sum_{i=1}^n \frac{\partial\Phi^a}{\partial x^i}$$ in the basis $\{\partial/\partial y^a)_Q\}.$ When we use intrinsic notation, we do not specify the local charts. In the coordinate systems $\{x^i\}$ and $\{y^a\}$, the equality above shows that $(d\Phi)_P=((\partial\Phi^a/\partial x^i))_P=(\Phi_*)_P.$ I don't understand what the intrinsic notations are. I can't see how the notation is intrinsic if we use the coordinates $x^i$ and $y^a$ which are real.","['derivatives', 'differential-geometry', 'definition']"
289211,Matrix multiplied by itself n times equals identity,"Given a $A \in \mathbb{R}^{100\times 100}$ and $A^{6} = I_{100}$ and $A^{14} = I_{100}$, ist say $A^{2} = I_{100}$ too? And what would then be the relationship governing whether $A^{2} = I_{100}$ or even $A^{n}$  is valid given two different conditions as above?","['matrices', 'linear-algebra']"
289212,Geometric Distribution $P(X\ge Y)$,"I need to show that if $X$ and $Y$ are idd and geometrically distributed that the $P(X\ge Y)$ is $1\over{2-p}$. the joint pmf is $f_{xy}(xy)=p^2(1-p)^{x+y}$, and I think the only way to do this is to use a double sum: $\sum_{y=0}^{n}\sum_{x=y}^m p^2(1-p)^{x+y}$, which leads to me getting quite stuck. Any suggestions?","['statistics', 'summation', 'probability-distributions', 'probability']"
289219,On Symmetric Group $S_n$ and Isomorphism,"I use Abstract Algebra by Dummit and Foote to study abstract algebra! At page 120, section 2 in chapter 4, there is a great result form my point of view which proves that, for any group $G$ of order $n$, $G$ is isomorphic to some subgroup of $S_n$. My question: Is there any way to calculate the subgroup of $S_n$ which is isomorphic to some group $G$ ? I mean, if we have a group $G$, how can we calculate the subgroup of $S_n$ which $G$ is isomorphic to it ? my question is in general ! the question is edited !","['symmetric-groups', 'finite-groups', 'group-theory', 'abstract-algebra']"
289227,"Is there a statistical interpretation of Green's theorem, Stokes' theorem, or the divergence theorem?","I'm teaching a class on integration of functions of several variables and vector calculus this semester.  The class is made up most of economics majors and engineering majors, with a smattering of math and physics folks as well.  I taught this class last semester, and I found that a lot of the economics majors were rather bored during the second half.  I was able to motivate multiple integrals by doing some calculations with jointly distributed random variables, but for the vector analysis part of the course the only motivation I could think of was based on physics. So I'm wondering if anybody knows a statistical/probabilistic interpretation of any of the main theorems of vector calculus.  This might require having such an interpretation of div, grad, and curl, and it's not so obvious what it might be.  Anyone have any ideas?","['multivariable-calculus', 'probability']"
289228,Gauss-Bonnet theorem for spheres that almost look like a torus,"[Corrected due to Jason's answer.] Imagine a torus and a flat disk fitting in the middle of its ""hole"" (a doughnut with a membrane in the middle). Cut the torus at its inner equator, duplicate the disk, move the two copies away from each other slightly, widen the cut appropriately and join the two flat disks with the sliced torus (anyway you like). You get a surface $M$ homeomorphic to the sphere - thus with integral curvature $\int_S\kappa = 4\pi$ - , but with integral curvature equal to that of the torus $\int_T\kappa = 0$ plus a contribution from the ""regions of agglutination"" where the two disks and the sliced torus are glued together (the disks by themselves having zero curvature). Is it simply a consequence of the Gauss-Bonnet theorem that however smoothly or abruptly you glue the two disks and the sliced torus together the integral curvature in the ""region of agglutination"" has to be $4\pi$? Or is there a mistake in my description of the surface or in my
understanding of the Gauss-Bonnet theorem?",['differential-geometry']
289233,Can every ideal have a minimal generating set?,"Let $I$ be an ideal of commutative ring $A$ with unity. Does $I$ have a minimal generating set? At times, I am able to compute what they are for specific example, but it seems like it is true in general with some existence proof (I guess it is true for non-commutative rings with some adjectives such as ""left"" or ""right""). I have thought about Zorn's lemma but generating sets are very likely to be incomparable (nor the existence of lower bound of each chain was not clear) and the intersection of all generating sets may be too small to generate an ideal. Sounds not too difficult, but it seems not clear what to do.","['commutative-algebra', 'ideals', 'abstract-algebra']"
289266,Proof of equivalence theorem about left invertible matrices,"I am taking a course in Matrix Theory and we have a theorem that states (among other things) that: The following conditions on the matrix $A$ of size $m \times n$ are equivalent: (1) A has left inverse (2) The system $Ax=b$ has at most one solution for any column vector $b$. ... The proof that (1) $\implies$ (2) goes like this: If $Ax=b$ and $V$ is a left inverse, then $VAx=Vb \implies x=Vb$, so we have at most one solution (if any). The thing is, left inverses are not unique right? Take 
$A =
\left( 
\begin{matrix}
1 \\ 0
\end{matrix}
\right)$
That has left inverses
$V_1=
\left(
\begin{matrix}
1 & 0
\end{matrix}
\right)
$
and
$ V_2 =
\left( 
\begin{matrix}
1 & 1
\end{matrix}
\right)$ Does this mean that the proof is wrong or am I missing something?",['matrices']
289271,Unknown result in probability theory relating CDF of any density to the CDF of normal distribution,"There is apparently a result in probability theory saying: If $A(z)$ is any cumulative distribution function, $\alpha(t)$, the corresponding characteristic function and $\Phi(z) = \int_{-\infty}^{z}e^{-\frac{t^{2}}{2}}\mathrm{d}t$ is the cumulative distribution of the normal distribution, then, for any $T > 0$: $$|A(z) - \Phi(z)| \leq \int_{-T}^{T}\mathrm{d}t\left|\dfrac{\alpha(t) - e^{-\frac{t^{2}}{2}}}{t}\right| + \dfrac{24}{T \pi \sqrt{2 \pi}}$$ Reference: Eq. 4, Page 11 of http://www.glassonion.org/ecc.pdf Could anyone tell me what name this theorem goes by ? I am unable to find any in the above form. Could anyone tell what parameter of $\Phi(z)$ is specific to the CDF function $A(z)$ ? I presume that for a different CDF, say, $A^{\prime}(z)$ satisfying the above result, the corresponding $\Phi(z)$ would be different.","['probability-theory', 'normal-distribution', 'probability-distributions']"
289277,Analytic functions branch,"I am having trouble understanding branch cuts. It seems right when I understand one thing another issue arises. The questions asks: Find a branch of each of the following multiple valued functions that
  is analytic in the given domain: a.) $(z^2-1)^{1/2}$ in the unit disk, $|z|< 1$. b.)$(4+z^2)^{1/2}$ in the complex plane slit along the imaginary axis
  from $-2i$ to $2i$. c.) $(z^4 -1)^{1/2}$ in the exterior of the unit circle $|z|>1$. d.) $(z^3-1)^{1/3}$ in the exterior of the unit circle, $|z|>1$. For a, I had a question earlier similar to this and it says the prinicipal branch won't work because it is not defined in some of the x-axis and all of the y-axis (not entirely sure why that is though). The answer to this question is $ie^{[(1/2)Log(1-z^2)]}$, which doesn't make sense to me because it says the principal branch is not defined there. For b, I kind of do understand because if it is on the imaginary axis  from $-2i$ to $2i$ which will be undefined so I must use another branch. For c and d both similar to a.",['complex-analysis']
289305,prove : if $G$ is a finite group of order $n$ and $p$ is the smallest prime dividing $|G|$ then any subgroup of index $p$ is normal,"Prove: If $G$ is a finite group of order $n$ and $p$ is the smallest prime dividing $ |G| $ then any subgroup of index $p$ is normal
where $ |G| $ is the order of $G$ This is a result in Abstract Algebra by Dummit and Foote at page 120 . The proof is produced but there is some points which is not obivous for me ! First, in page 121 in the proof, it says, all divisors of $ (p-1)!$ are less than $p$ .
why this is true ? can any one explain? Second, why does ""every prime divisor of $ k$ is greater than or equal to $p$ ""force that k=1 ?? Why does $ k = 1 $ under this condition?? Third, if $ k=1 $ Then, the order of $  K$ = the order of $H$ Why does this mean that $ K=H $ in this case?? Can you help in explaining these three things?","['finite-groups', 'group-theory', 'abstract-algebra']"
289322,When would a function be differentiable at the end point?,"Let's say the function is defined on $[x,y]$ I just don't know what to think of here. I think that every function is not differentiable at the end points because they are points! How can the limit exist from the other side of the end point? More importantly, when would a function be differentiable at the end point? Can anyone provide an example and explain how he came with it?","['calculus', 'derivatives']"
289325,Is $\frac{1}{\exp(z)} - \frac{1}{\exp(\exp(z))} + \frac{1}{\exp(\exp(\exp(z)))} -\ldots$ entire?,"Let $z$ be a complex number. Is the alternating infinite series
$$ f(z) = \frac{1}{\exp(z)} - \frac{1}{\exp(\exp(z))} + \frac{1}{\exp(\exp(\exp(z)))} -\dotsb
$$
an entire function ? Does it even converge everywhere ? Additional questions (added dec 16) Consider the similar case for $z$ being real or having a small imaginary part: $$ g(z) = \frac{1}{z} +  \frac{1}{\exp(z)} + \frac{1}{\exp(\exp(z))} + \frac{1}{\exp(\exp(\exp(z)))} + \dotsb$$
As such $g(z)$ converges for real $z$ but diverges for nonreals. So we try Some sort of continuation: $$ g(z) = 1/z + 1/\exp + \dotsb$$
$$g(\exp) = 1/\exp + \dotsb $$ Thus $ g(z) - g(\exp(z) ) = 1/z $ $$ \exp(z) = g^{[-1]} ( g(z) - 1/z ) $$ Call that solution $g_1(z)$. Assume differentiability and take the derivative at both sides. (Notice we can repeat to get infinite many equations!) $$ \exp(z) = \frac{d}{dz} g^{[-1]} ( g(z) - 1/z) $$ 
[ ofcourse we can simplify the RHS by applying the chain rule and the rule for the derivative of the functional inverse - name ? - ] And in General the equations $$ exp(z) = \frac{d^m}{dz^m} g^{[-1]} ( g(z) - 1/z ) $$ Point is: are these equations getting analytic solutions or not? Also we could combine the equations to get new ones. Like this for example : $$ g^{[-1]} ( g(z) - 1/z ) = \frac{d}{dz} g^{[-1]} ( g(z) - 1/z ) $$ And we could continue by taking any positive integer number of $a$ th derivative on the LHS and any positive integer number of $b$ th derivative on the RHS ! So are all these equations nowhere analytic ?? 
Or Some ? Or all of them ?
And when they are analytic is it possible to do analytic continuation ? Are there natural boundaries ?? Many questions. In fact ; not even sure how to solve these equations , neither with expressions nor numerical. - in terms of complex Numbers ofcourse otherwise i simply use the Sum from the beginning -. < ps i considered using the functional inverse of $ g $ with notation $G$ so the simplifications of the derivatives take a different form , yet this makes no essential difference i guess >","['complex-dynamics', 'convergence-divergence', 'complex-analysis']"
289329,"Is the event $\{\max\{X_1,X_2\}=X_2\}$ measurable with respect to $\sigma(\max\{X_1,X_2\})$?","Let $X_1$ and $X_2$ be arbitrary random variables defined one the same probability space $(\Omega,\mathcal{F},P)$. I am trying to determine if the event $\{\max\{X_1,X_2\}=X_2\}$ is measurable with respect to $\sigma(\max\{X_1,X_2\})$? Normally I would try to decompose the event into a countable union or intersection of events which are clearly elements of the $\sigma(\max\{X_1,X_2\})$. However, the only way that I can think to rewrite the original set is as $\{\max\{X_1,X_2\}=X_2\}=\{X_1\leq X_2\}$. I'm not sure where to go from here.","['probability-theory', 'measure-theory']"
289336,How do I find the area of this region?,"A square with edge length 2 cm has semicircles drawn on each side. Find the total area of the shaded region. Here is an image of the diagram shown : Please show your work in pictures, numbers, words, anything. (Try to keep it to a Grade 8 level too)",['geometry']
289338,Is the notorious $n^2 + n + 41$ prime generator the last of its type?,"The polynomial $n^2+n+41$ famously takes prime values for all $0\le n\lt 40$. I have read that this is closely related to the fact that 163 is a Heegner number, although I don't understand the argument, except that the discriminant of $n^2+n+41$ is $-163$. The next smaller Heegner number is 67, and indeed $n^2+n+17$ shows the same behavior, taking prime values for $0\le n\lt 16$. But 163 is the largest Heegner number, which suggests that this is the last such coincidence, and that there might not be any $k>41$ such that $n^2+n+k$ takes on an unbroken sequence of prime values. Is this indeed the case?  If not, why not? Secondarily, is there a $k>41$, perhaps extremely large, such that $n^2+n+k$ takes on prime values for $0<n<j$ for some $j>39$?",['number-theory']
289347,"Finding the Moment Generating Function of $X^2$ when $X\sim N(0,1)$","If $X\sim N(0,1)$ , integrate to find the moment generating function of a random variable $X^2$ and identify the distribution of $X^2$ using the moment generating function. $$E\left[e^{tX^2}\right]=\int_{-\infty}^{\infty}{e^{tx^2}e^{-x^2}\over{\sqrt{2\pi}}}dx$$ which reduces to $$=\frac1{\sqrt{2\pi}} \int_{-\infty}^{\infty}{e^{tx^2}e^{-x^2}}dx
=\frac1{\sqrt{2\pi}} \int_{-\infty}^{\infty}{e^{x^2(t-\frac12)}}dx$$ and thus I am stuck. I'm sure there must be some trick to this (like completely the square for the mgf of a standard normal variable X) but I can't figure out what it might be. Any hints?","['integration', 'statistics', 'moment-generating-functions', 'normal-distribution', 'probability-distributions']"
289352,Nowhere dense set,"I am preparing for an exam and trying to solve this exercise about nowhere dense set. I would be very happy if someone could help me. Let $(X, \tau )$ be a topological space. A set $S\subset X$ is nowhere dense if it does not contain any internal point. Prove that a closed set $C\subset X$ is nowhere dense if and only if it is the boundary of an open set $U\subset X$. Thank you very much in advance!",['general-topology']
289353,System of differential equations with triple eigenvalue,"Could anybody, please, explain to me, how to solve system of 3 differential equations, when it has triple eigenvalue? I mean... we solved these equations by creating a matrix $A$ of the system and finding eigenvalues $\lambda_1,\lambda_2,\lambda_3$. Then we found eigenvectors $\overrightarrow{v_1},\overrightarrow{v_2},\overrightarrow{v_3}$ by computing result for the matrix $A-\lambda_iE$. Then there was a formula for result $u_i = c_i\cdot e^{\lambda_i\cdot t}\cdot \overrightarrow{v_i}$. And $x =u_1+u_2+u_3$. And if any eigenvalue were doubled, the second time, when eigenvector was searched we put to the matrix on the right-handed side the eigenvector from the first solution ($A-\lambda_2E=\overrightarrow{v_1}$) and computed results. But what if the eigenvalue is triple? What then?","['linear-algebra', 'ordinary-differential-equations']"
289382,"What are all conditions on a finite sequence $x_1,x_2,...,x_m$ such that it is the sequence of orders of elements of a group?","My Definition: The finite sequence $x_1,x_2,...,x_m$ of nonnegative integers is said to be generated by a finite group $G$ iff $n:=|G|=x_1+x_2+\cdots+x_m$. $n$ has $m$ divisors. if $d_1<d_2<\cdots<d_m$ are all divisors of  $n$, for every $k = {1,...,m}$ we have
$$x_k=\left|\{x \in G  \mid o(x)=d_k\}\right|.$$ What are all conditions on a finite sequence $x_1,x_2,...,x_m$ such that it is generated by some group $G$? Some conditions I found: For $k = {1,...,m}$ we have $$\phi(d_k)\mid x_k$$ where $m$ and $d_k$ are as above. $x_1=1$. $x_m\leq\phi(n)$ and if $x_m=\phi(d_m)$ then for $k = {1,...,m}$, $$x_k=\phi(d_k) $$ If $x_k\ne 0$ then for every $i$ such that $d_i|d_k$, we have $$x_i\ne 0$$ If $d_k$ is a prime, $$x_k\ne 0$$","['graph-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
289397,A theorem concerning unique linear mapping between vector spaces: What does it say?,"Theorem (from Schaum's Linear Algebra) Let $V$ and $U$ be vector spaces and $\{v_1, \ldots, v_n\}$ be a basis on $V$. Let $\{u_1,\ldots, u_n\}$ be arbitrary vectors in $U$. Then there exists a unique linear mapping $F: V \to U$ such that $F(v_i) = u_i$. I omit the proof, it is not so hard. But I don't understand what this theorem means or what does it imply, how one can use it to deduce more results. Can anybody briefly explain it? Thanks in advance!","['vector-spaces', 'linear-algebra']"
289405,New twist on a Putnam problem,"A recent Putnam problem: Let $f$ be a real-valued function on the plane such that for every square $ABCD$ in the plane, $f(A)+f(B)+f(C)+f(D)=0$. Does it follow that $f$ is identically zero? The answer is yes. Without loss of generality consider only the origin. We have $$f(1,1)+f(-1,1)+f(1,-1)+f(-1,-1)\tag{a}$$
$$f(0,0)+f(0,1)+f(1,0)+f(1,1)\tag{b}$$
$$f(0,0)+f(0,1)+f(-1,0)+f(-1,1)\tag{c}$$
$$f(0,0)+f(0,-1)+f(1,0)+f(1,-1)\tag{d}$$
$$f(0,0)+f(0,-1)+f(-1,0)+f(-1,-1)\tag{e}$$
$$f(1,0)+f(-1,0)+f(0,-1)+f(0,1)\tag{f}$$ are all zero. Then $f(0,0)=[\rm(b)+(c)+(d)+(e)-(a)-2(f)]/4=0$. A similar argument works when we replace the condition in the problem with triangles $\triangle ABC$. I have pictured both ideas as so-called ""proof without words"" below: What happens when we replace the codomain of $f$ with an abelian group of exponent dividing $4$ or $6$ respectively? Do there then exist non-constant maps with these properties?","['geometry', 'abelian-groups', 'contest-math', 'analysis']"
289408,Calculating the 4th number from 3 related numbers,"I was taught a long time ago this really useful trick to calculate an unknown value when you know 3 existing values that are related. An example would be something like: If there are 21 peas in 3 pods how many are there in 17 pods? This gives us 2 values that have a relation, the next value that fits a certain rule that would reveal the missing value. I was taught to write it down in a kind of 3 out of 4 square, and you would multiply diagonally and divide up and down. But I can't quite remember the exact rule and if this little trick has a name.",['statistics']
289420,"Differentiating $x+2x^2\sin(1/x)$ near $0$, discontinuity of the derivative","I have this function
$$
\begin{array}{l}
f:\mathbb{R}\rightarrow\mathbb{R}\\
x\rightarrow\left\{\begin{array}{ll}
x+2x^2\sin\left(\frac{1}{x}\right)&x\neq 0\\
0&x=0
\end{array}\right.
\end{array}
$$
I need to calculate its derivative in $x=0$. I'm not sure how can I compute it at zero, since the limit of its derivative goes to 1 when x tends to zero but at zero I thought $f'(0)$ must be zero (therefore its derivative is not continuous at the origin). If is not zero then it is invertible around the origin via the Inverse Function Theorem, right?","['derivatives', 'real-analysis']"
289427,"What is a ""linear set""","I'm reading "" L'hypothèse du continu "" by Sierpinski. He mentions many times ""ensembles linéaires"" or ""linear sets"" without defining this notion. Does anyone know what the definition of a such a set is ? Here is a translation into English of 2 propositions he gave : ""There exists a linear set whose cardinality is that of the continuum and whose image by any continuous function is of measure zero"". ""There exists a linear set whose cardinality is that of the continuum and whose homeomorphic images have the same measure"".","['set-theory', 'measure-theory', 'analysis']"
289449,Looking for Cover's hubris-busting ${\mathbb R}^{N\gg3}$ counterexamples,"In lecture 4 of his Introduction to Dynamical Linear Systems course, right after interpreting the inner product in ${\mathbb R}^N$ in terms of the cosine of the subtended angle, Stanford's Stephen Boyd goes into humorous aside in which he pokes fun at the notion that one can ""visualize"" and reason about ${\mathbb R}^N$—for some $N$ greater than, say, $5$—by relying on intuitive analogies with ${\mathbb R}^2$ or ${\mathbb R}^3$. (FWIW, I found Boyd's commentary pretty funny.  It starts at 59'46"" of the YouTube video, and goes for about 3 minutes.) At some point during this riff, Boyd remarks that ""[the late Stanford professor Thomas] Cover has a series of examples showing that [when it comes to ${\mathbb R}^{N\gg3}$] you know nothing! ""  He then adds something like ""I should really collect some of these from him, 'cuz they're really good...  There are about four of 'em..."" I've been positively haunted by this mythical list of counterexamples ever since I heard Boyd's mention of it. If anyone can point me to some version of Cover's list I'd greatly appreciate it. The matter goes beyond satisfying my idle curiosity.  I feel this is an issue that really does need a bit of awareness-raising in the research community.  I'm surrounded by researchers who blithely rely on their ${\mathbb R}^3$-based intuitions to reason about algorithms that search through an ""energy landscape"" (i.e. a hypersurface) in ${\mathbb R}^{1\; \mathrm{bazillion}}$, and they poo-pooh any concern over the applicability of said intuitions, and the soundness of the reasoning based on them.  (Heck, even assuming that what holds in, say, ${\mathbb R}^2$ will necessarily hold in ${\mathbb R}^3$, or that what holds in ${\mathbb R}^1$ will necessarily hold in ${\mathbb R}^2$, can get one all wet...) So my hope is that Cover's list will rattle them enough to show them their hubris.","['general-topology', 'examples-counterexamples', 'dimension-theory-analysis', 'intuition']"
289452,invertible if and only if bijective,"I need to show that a linear transformation $T \in L(W,W)$ is invertible if and only if $T$ is bijective. I'm not sure how to go about this, can someone give me an idea where to start? I know is injective if $T_u = T_w$ aka null $T = {0}$, surjective if range $T = W$, and invertible if there is an inverse that give you the identity",['linear-algebra']
289465,Solve without using L'Hôpital's rule?,"Is it possible to solve this without using L'Hôpital's rule? $$
\lim_{x\to 0} \Big(\frac{3x+1}{x}-\frac{1}{\sin x}\Big)
$$ I tried to solve it but I got stuck at the $\frac{1}{\sin x}$ part. $$
=\lim_{x\to 0}\frac{3+x^{-1}}{1}-\lim_{x\to 0}\frac{1}{\sin x}
$$ since $\lim_{x\to 0}\frac{1}{\sin x}$  does not exist.",['calculus']
289466,Why isn't several complex variables as fundamental as multivariable calculus?,One typically studies analysis in $\mathbb{R}^n$ after studying analysis in $\mathbb{R}$ .  Why can't the same be said of $\mathbb{C}$ ?,"['several-complex-variables', 'complex-analysis']"
289478,"Method of Moments on a Uniform distribution (a,b)","Given that $x_1,x_2,...,x_n$ are i.i.d. random variables drawn from a Uniform distribution over $(a,b)$ (with $a<b$ and both are unknown), I hope to estimate $a$ and $b$ using the method of moments. My problem (embarrassingly enough) comes when I attempt to solve the system of equations obtained. First, set $\bar{x}=\frac{a+b}{2}$, as that is the expected value of a uniform distribution. (Where $\bar{x}=\frac{x_1+x_2+...+x_n}{n}$) Then, the second moment $\sum_{i=1}^{n}\frac{[E(x_i)^2]}{n}$$=\frac{(b-a)^2}{12}+(\frac{b+a}{2})^2$. (Just the variance plus the expected value squared). So now, two systems of equations, two unknowns (as I'm hoping to solve for a and b in terms of $\bar{x}$ and $x_i$. Foiling out the second equation and letting $a=2\bar{x}-b$, I obtain the following equation: $4b^2-8b\bar{x}+14\bar{x}^2=\sum_{i=1}^{n}\frac{[E(x_i)^2]}{n}$. I think I'm missing two steps from here: first, I'm not sure how to deal with the summation on the right side. Second, my grasp of algebra is not nearly what it once was, and I'm not really sure how to solve for b at all. Any help would be greatly appreciated!
Thanks!","['statistics', 'probability-distributions', 'algebra-precalculus']"
289491,Tangent Space Exercise,"Can you please describe how to use the intrinsic definition of tangent space to show that the tangent space of the curve $Z \left( y^2-x^3 \right)$ at the point $x = \left(1,1\right)$ is one-dimensional? That is, if $m_x/m_x^2$ is one dimensional, then so is the tangent space. Show that $m_x/m_x^2$ is one dimensional. Thanks.",['algebraic-geometry']
289494,How compute $\lim_{p\rightarrow 0} \|f\|_p$ in a probability space?,"I not solve the follow limit
$$\lim_{p\rightarrow 0} \bigg[\int_{\Omega} |f|^p d\mu \bigg]^{1/p} = \exp\bigg[ \int_{\Omega} \log|f|d\mu \bigg],$$ where $(\Omega, \mathcal{F}, \mu)$ is a probability space and $f,\log |f| \in L^1(\Omega).$ Can someone help me? Thank you!","['probability-theory', 'lp-spaces', 'probability', 'real-analysis']"
289521,Closed subspaces of a locally compact space are locally compact,"I need to show that any closed subspace of a locally compact space is locally compact. My definition of a locally compact space $S$ is that for each point in $S$ there exists a compact neighborhood $U$ in $S$ . Now let $K$ be a closed subspace in $X$ , then for each $x \in K$ , there exists a compact neighbourhood $U_x \subset X$ . Then $x \in U \cap  K$ is a neighbourhood of $x$ in $K$ , but how do I show that it is compact as well?","['general-topology', 'compactness']"
289525,Function on $\mathbb{R}^{2}-\{0\}$.,"Does there exist any compactly supported function $f= (f_1,f_2): \mathbb R^2-\{0\}\to \mathbb R^2$ such that $$\frac{\partial}{\partial x_2}f_1=\frac{\partial}{\partial x_1}f_2.$$ Also there does not exists any function $F: U(\subset \mathbb R^2-\{0\})\to \mathbb R$ such that 
$$\frac{\partial}{\partial x_1}F= f_1\text{ and } \frac{\partial}{\partial x_2}F= f_2.$$","['multivariable-calculus', 'calculus', 'homology-cohomology', 'differential-forms', 'real-analysis']"
289538,Combinatorial proof: $p^{r-n}$ divides $\binom{p^{r-2}}{n}$,"Let $p$ be an odd prime. Then if $1<n<r$, $$p^{r-n}\,\left|\,\binom{p^{r-2}}{n}\right.$$
Does anyone have a clever combinatorial proof of this fact? There's an easy argument just by counting multiples of $p$ (with multiplicity) in the numerator and denominator, but it feels a bit clumsy, and this sort of thing ought to have a more elegant argument. This problem arises naturally when looking at the structure of groups of the form $(\mathbb{Z}/n)^*$, which is why I've posted the above problem with what appears to be a stronger-than-necessary hypothesis and what is certainly a weaker-than-necessary conclusion.","['elementary-number-theory', 'binomial-coefficients', 'combinatorics']"
289540,"How show that $\lim_{\varepsilon \rightarrow 0}\int_A h_\varepsilon(x)dx =0$, whenever $\bigg|\int_I h\bigg|\leq |I|^{1/2}$?","Let $h$ be a bounded, measurable function, such that, for any interval $I$
$$\bigg|\int_I h\bigg|\leq |I|^{1/2}.$$ I want show that, for any $A$, with $|A|<\infty$,
$$\int_A h_\varepsilon(x)dx\rightarrow 0,\ \ \mathrm{as}\  \varepsilon \rightarrow 0,$$ where $h_\varepsilon(x) = h(\frac x\varepsilon)$. My idea was to take $\eta>0$, and a open set $O$ such that $|O-A|<\eta$. How $O$ is open in $\mathbb{R}$, there exist disjoint intervals, $\{I_k\}$, such that $O = \cup I_k$. Then $$\bigg| \int_{O-A} h_\varepsilon(x)dx \bigg|\leq \|h\|_{\infty}\eta$$
and
$$\bigg| \int_{O} h_\varepsilon(x)dx \bigg| \leq \sum_k\bigg| \int_{I_k} h_\varepsilon(x)dx \bigg| \leq \varepsilon^{1/2} \sum_k|I_k|^{1/2}.$$ But, for instance, if $|I_k|=1/n^2$, then $|O| = \sum_k|I_k|=\pi/6$, however $\sum_k|I_k|^{1/2}=\infty$. How can I solve this problem? Thank you!","['lebesgue-integral', 'measure-theory', 'real-analysis']"
289542,How do I find the MLE of $\theta$ when x is dependent on $\theta$?,"Let $X_{1},X_{2},...,X_{n}$ represent a random sample from a distribution with pdf: $f(x; \theta)=e^{-(x-\theta)}, \theta \le x<\infty, -\infty<\theta<\infty$ | zero elsewhere I need to find the MLE $\hat {\theta}$ of $\theta$. Since the support space of the pdf is dependent on $\theta$, do I need to express the pdf in terms of an indicator function? i.e. $f(x; \theta)=e^{-(x-\theta)}I_{(\theta,\infty)}(x)$ If so, do I find the MLE in the standard manner? i.e. $L(x;\theta)=\displaystyle \prod^{n}_{i=1} f(X_{i};\theta)=e^{-(\sum^{n}_{i=1}X_{i}-n\theta)}I_{(\theta,\infty)}(X_{(1)})$ $\ln L(x;\theta)=-\displaystyle \sum^{n}_{i=1} X_{i} +n\theta +\ln I_{(\theta,\infty)}(X_{(1)})$ The next step would be to take the partial derivative of the log-likelihood function with respect to $\theta$, but how would I find the partial derivative of the indicator function? Am I approaching this question in the correct manner? Any help would be greatly appreciated!","['statistics', 'maximum-likelihood', 'statistical-inference', 'exponential-distribution']"
289560,How does one prove (A - B) - C ⊆ (A - C) - (B - C),When proving this I'm not sure how to 'take out' the C on the RHS of the equation. The LHS is (x ∈ A) ∧ !(x ∈ B) ∧ !(x ∈ C) The RHS is (x ∈ A) ∧ !(x ∈ C) ∧ !(x ∈ B) ∧ !(x ∈ C) How does how prove LHS is a subset of RHS?,['elementary-set-theory']
289562,Recurrence relation help,"The function $\psi_k(n)$ satisfies the recurrence relation:
$$\sum_{j=0}^k\binom{k}{j}(-1)^j\psi_j(n)\ln(n)^{k-j}=\psi_k(n)$$
Using this, is there a general way I can re-write the function  $
\psi_k(n)$, when $k$ is odd, in terms of other $\psi_i(n)'s$ where $i$ is even? The first few odd ones I solved for, in terms of there even counter parts are: $\psi_1(n)=\frac{1}{2}\psi_0(n)\ln(n)$ $\psi_3(n)=\frac{3}{2}\psi_2(n)\ln(n)-\frac{1}{4}\psi_0(n)\ln(n)^3$ $\psi_5(n)=\frac{5}{2}\psi_4(n)\ln(n)-\frac{5}{2}\psi_2(n)\ln(n)^3+\frac{1}{2}\psi_0(n)\ln(n)^5$ I know in practice this can be done for all of them, but its very tedious to solve for them, so is there a general way I can re-write the functions of odd subscript in terms of other functions of even subscribt? I would appreciate any help","['recurrence-relations', 'functions']"
289568,3D Numerical differentiation with spline approximation,"I have three 3D matrices X, Y, and Z that define a matrix V of the same size over some region. The matrices are regularly spaced. I'm trying to compute the gradient of V. I have read that interpolating and computing derivatives with splines leads to better results than using central differences. For instance, I have worked before with splinefit and ppdiff ( http://www.mathworks.com/matlabcentral/fileexchange/13812-splinefit ). The problem is that I can't find code to do this in 3D. Assuming I only want the derivatives at the sampled locations define by the X, Y, and Z matrices, could I do 1D spline approximations for each dimension and compute the partial derivatives that way? I've tried it with a simple 2D Matlab example, and this idea works; however, I wanted to see if it made mathematical sense Thanks for your help!","['interpolation', 'spline', 'derivatives']"
289575,Car racing: How to calculate the radius of the racing line through a turn of varying length,"I am in the process of designing a board game involving car chases, and I am stumped by the following problem: A car will have a maximum speed through a constant radius speed turn, giving a maximum safe cornering speed for a given turn radius. But, if the car follows the racing line (an apex turn?), the radius of the turn is greater, and the car can take the turn faster A simplified situation would be sufficient to cater to my needs (no need for curves of changing radius, etc), see https://i.sstatic.net/odIyF.jpg for an illustration The radius of the racing line R(race) must be dependent on 3 factors: Outer radius: R(outer) Inner radius: R(inner) And the length of the turn in degrees. From this I should get R(race) R(inner) and R(outer) have the same center, and the center of R(race) must be somewhere on the line that bisects the turn (midpoint of the curve) I would love to have a formula for the 90 degree turn, but preferably I would like a general solution, where the turn can be of any angle of turn (up to 180 degrees or more). Looking at my sketches, at 180 degrees of turn, the radius of the racing line will equal R(outer), while the radius will approach infinity, as the angle of turn becomes smaller and smaller I have tried searching online for answers, but the formula I have dug up have given results I haven't been able to reproduce when mocking up on graph paper",['geometry']
289583,Formula for calculating transaction fees,"Let's say a credit card processor wants to charge $(3\% + \text{US}\$ 2)$ for all transaction.
What formula do I use to make sure that after the charges are deducted, I get the figure I want. Example: If my product is $\text{US}\$ 100$  How much do I need to increase the price so that I will get $\text{US} \$100$ even after the transaction is charges by the credit card processor. If it is purely $\% $-based, then I believe it is $\dfrac{\text{US}\$100}{1-0.03}$. But with the $\text{US}\$2$ in play, I am not sure how to do it. Please help :)",['algebra-precalculus']
289587,"log sin and log cos integral, maybe relate to fourier series","I try to use the method of differentiation under integral sign for the first one
And integrate it back, but I failed to find the constant $c$ ....
Anyone hav other method? 
$$\begin{align}
  & \int_{0}^{\frac{\pi }{2}}{{{x}^{2}}{{\ln }^{2}}\left( 2\cos x \right)\text{d}x} \\ 
 & \int_{0}^{\frac{\pi }{3}}{x{{\ln }^{2}}\left( 2\sin \frac{x}{2} \right)}\text{d}x \\ 
\end{align}$$","['fourier-series', 'sequences-and-series', 'fourier-analysis', 'calculus', 'integration']"
289612,classical topology but with lattices,"I'm looking for a reference, if such a references exists. So there are currently at least two approaches to topology. The point-set or ""classical"" approach to topology, which concerns itself with ordered pairs $(X,\tau)$ called topological spaces . The ""pointless"" approach to topology, which concerns itself with (particular kinds of) lattices $(\tau,\wedge,\vee)$ called frames . (For more information, see e.g. Wikipedia .) I'm interested in a concept halfway between 1 and 2. We might call it ""the classical approach, but with lattices."" In particular, rather than studying point-set topological spaces $(X,\tau)$, we concern ourselves with ""lattice-theoretic"" topological spaces $(P,\tau)$, where $P$ is a lattice that is isomorphic to a powerset lattice, and $\tau$ is a subset of $P$ that is closed with respect to arbitrary joins etc. The main motivation: We may be able to weaken the requirement that $P$ needs to be isomorphic to a powerset, and thereby obtain a more general theory, which is still classical in flavor. Has this idea been studied before? If so, a reference recommendation would be great.","['general-topology', 'lattice-orders', 'reference-request']"
289617,An equation concerning eisenstein integers,"An interesting exercise on gaussian integers is to prove that those of the form $n-i$, with $n$ a positive integer, are multiplicatively independant. To solve this, one has to consider the equation involving the norms of elements, that is, $n^2+1=(m^2+1)^k$, which can be written as $n^2 = (m^2+1)^k-1$, and it is well known that this equation has no solutions (this is a particular case of Catalan-Mihailescu theorem, but we don't even need such a strong result as this specific form was already solved by Lebesgue). I was wondering whether one can get the same result considering Eisenstein integers (numbers of the form $a+bj$ with $j=\frac{-1+i\sqrt{3}}{2}$. Determining whether $n-j$ and $m-j$ are multiplicatively independant leads to the equation $$n^2+n+1=(m^2+m+1)^k, \qquad(*)$$ and then we are done with the previous method of solving as it seems that there is no easy way to rewrite this equation. It would have been nice to prove that this equation has no solution; unfortunately this is not the case since $(18^2+18+1)=(2^2+2+1)^3$, and one checks that $(2-j)^18 = (18-j^2)^6$ since $(2-j)^3$ and $18-j^2$ are conjugated. So far, I don't know if there are other solutions (but scilab seems to answer me that this is the only one) and I can't obtain anything more than trivial results ($k$ is odd, $n$ is bounded by $m^k$ and $(m+1)^k$). So, I would like to know if this equation $(*)$ has already been studied somewhere, and/or if you have any idea to find all solutions; feel free to add any comment!",['number-theory']
289623,Solve the DE $yy^{\prime}+x=\sqrt{x^2+y^2}$,"Solve the DE $$yy^{\prime}+x=\sqrt{x^2+y^2},x>0$$ I show it is a homogenous first order DE and I use the substitution $y=Vx$. Then, I solve until $$\int \frac{V}{\sqrt{1+V^2}-(1+V^2)}dV=\int \frac{1}{x}dx$$ I don know how to integrate LHS. Any hint?",['ordinary-differential-equations']
289626,A functional equation problem on $\mathbb{Q}^{+}$: $f(x)+f\left(\frac{1}{x}\right)=1$ and $f(2x)=2f\bigl(f(x)\bigr)$,"Let $f$ be a function which maps $\mathbb{Q}^{+}$ to $\mathbb{Q}^{+}$ and satisfies $$
\begin{cases}
f(x)+f\left(\frac{1}{x}\right)=1\\
f(2x)=2f\bigl(f(x)\bigr)
\end{cases}
$$ Show that $f\left(\frac{2012}{2013}\right)=\frac{2012}{4025}$ . I tried to prove that $f(x)=\frac{x}{x+1}$ (which satisfies all these comditions), but failed. So I tried induction: Surely, $f(1)=\frac{1}{2}$ by $f(1)+f\left(\frac{1}{1}\right)=1$ . By $f(2)=2f\bigl(f(1)\bigr)=2f\left(\frac{1}{2}\right)$ , we know $f\left(\frac{1}{2}\right)=\frac{1}{3}$ and $f(2)=\frac{2}{3}$ . Note that $f(1)=2f\Bigl(f\left(\frac{1}{2}\right)\Bigr)$ , we have $f\left(\frac{1}{3}\right)=\frac{1}{4}$ . By $f(4)=2f\bigl(f(2)\bigr)=2f\left(\frac{2}{3}\right)$ as well as $f\left(\frac{2}{3}\right)=2f\left(\frac{1}{4}\right)$ , we know $f\left(\frac{1}{4}\right)=\frac{1}{5}$ , $f\left(\frac{2}{3}\right)=\frac{2}{5}$ and $f(4)=\frac{4}{5}.$ Unfortunately, these procedures seems to have no similarity, and the larger the denominator, the more complex the procedure is. Is there any hints or solutions? Thanks for attention!","['functional-equations', 'analysis']"
289627,"Average of function, function of average","I'm trying to find all functions $f : \mathbb{R} \to \mathbb{R}$ such that, for all $n > 1$ and all $x_1, x_2, \cdots, x_n \in \mathbb{R}$: $$\frac{1}{n} \sum_{t = 1}^n f(x_t) = f \left ( \frac{1}{n} \sum_{t = 1}^n x_t \right )$$ My intuition is that this is only true if $f$ is a linear function. I started from the relation: $$\sum_{t = 1}^n f(x_t) = f \left ( \sum_{t = 1}^n x_t \right )$$ That is, $f$ is additive. Then, by multiplying by $\frac{1}{n}$ each side, we obtain: $$\frac{1}{n} \sum_{t = 1}^n f(x_t) = \frac{1}{n} f \left ( \sum_{t = 1}^n x_t \right )$$ And hence, any $f$ which has the property that $f(ax) = a f(x)$ (a linear function) will work. And since all linear functions are trivially additive, any linear function is a solution to my relation. But all I have done is prove that linear functions are solutions, how should I go about showing that only linear equations are solutions? Is it valid to just ""go backwards"" in my argument, proving that if $f$ is a solution, then it must be linear? I feel it is not sufficient, since I only have implication and not equivalence. How do I proceed? I think the $\frac{1}{n}$ term was added to confuse me, since without it, this would be straightforward.","['functions', 'functional-equations']"
289655,The solution of the differential equation $\frac{\mathrm{d}y}{\mathrm{d}x}=2xy^2$,"Question from pg 32 of Barron's AP Calculus The solution of the differential equation $\frac{\mathrm{d}y}{\mathrm{d}x}=2xy^2$ for which $y = -1$ when $x = 1$ is (A) $y = -\frac{1}{x^2}$ for $x \neq 0$ (B) $y = -\frac{1}{x^2}$ for $x > 0$ I think A is a possible solution; however the answer given is This function is discontinuous at $x=0$ . Since the particular solution much be differentiable in an interval containing the inital value $x = 1$ , the domain is $x > 0$ . Giving (B) as the correct answer. Even from the answer given in the book, should not (A) be an acceptiable answer as well because its domain contains the domain of (B)?","['ordinary-differential-equations', 'calculus']"
289664,Expectation conditional on indicator function,"Let T and K be dependent continuous random variables, and note the Indicator function as I{.}: Is it correct to say that $E[T|I\{T>t,K<k\}]=E[T|T>t,K<k]$? Is that a property of the Indicator function?",['probability-theory']
289699,Can a sum of idempotents vanish?,"Let $A$ be a finite dimensional $\mathbb C$-algebra. Let $e_1,\ldots,e_r\in A$ be nonzero idempotents (with $r>0$), i.e. $e_i^2=e_i$. My question is: Can it happen that $e_1+\cdots+e_r=0$? I can't think of a single example. Note: I do not require the $e_i$ to be central, primitive, or orthogonal.","['idempotents', 'abstract-algebra']"
289716,Hyperbolic diameter of Amsler's surface,"I've recently learned about Amsler's surface , a surface of constant negative Gaussian curvature. If I understand things correctly, there is a whole family of such surfaces, differing in the angle of intersection for the two lines that generate it. But I guess I'm only interested in the most symmetric version, where these lines are orthogonal. I'd like to know how large a portion of the hyperbolic plane I can embed on this surface. So if the unit of length is chosen such that the Gaussian curvature of the surface becomes $-1$, what is the radius of a circle which is centered at the intersection of the asymptotic lines and just touches the cuspidal edges of the surface? A “circle” here would be the set of points on the surface with fixed geodesic distance to a central point. That intrinsic circle would not be a planar circle in the 3D embedding of the surface. The following illustration of Amsler's surface was taken from the Gallery of pseudospherical surfaces by A. Ovchinninkov. I'm not sure how accurately it matches what I ask for, since there are other figures on the web which look somewhat different from this.","['hyperbolic-geometry', 'curvature', 'metric-spaces', 'differential-geometry']"
289736,Convergence of sequences in topological spaces.,"To reference in my thesis, at first, I'd like a book of general topology that addressed  convergence of sequences in topological spaces not necessarily metrizables​​ . The concept seems plausible in Hausdorff topological spaces. See these notes for more. The references I could get (as the books of John L. Kelley , MG Murdeshwar and Bourbaki ) do not address sequences in topological spaces. In fact, Kelley's book is a brief definition of sequences in first countable topological spaces. But its definition depends completely on the definition of convergence in nets.  And I do not want to deal with convergence in nets. Question: Is there a book of general topology  well accepted by the mathematical community to define convergence in topological spaces without speaking nets? Question: Is there any research article that talks about convergence of sequences in topological spaces? Thank's.","['general-topology', 'convergence-divergence', 'sequences-and-series', 'reference-request']"
289769,How to find the inverse Fourier Transform of the product of two bessel functions of the first kind and a complex exponential function?,"I am attempting to find a closed form or symbolic expression of the inverse Fourier transform of the product of two Bessel functions of the first kind and a complex exponential, e.g. $P(t) = IFT_w \{ F(w)\}  = \frac{1}{{2\pi }}\int_{ - \infty }^\infty  {J_0 (aw)J_0 (bw)e^{ - jcw} e^{jwt} dw}$ where $a, b, c$ are real values and $0<a, b, c<1$. I've been tried so hard to solve it and recently found some clue in the textbook, Table of Integrals, Series, and Products, 7th ed. witten by Gradshteyn and Ryzhik: $\int_0^\infty  {e^{ - ax} J_v (\beta x)J_v (\gamma x)} dx = \frac{1}{{\pi \sqrt {\gamma \beta } }}Q_{v - \frac{1}{2}} \left( {\frac{{\alpha ^2  + \beta ^2  + \gamma ^2 }}{{2\beta \gamma }}} \right)$ , where $Q_{v}$ is Legendre function of the second kind,and the equality holds only if ${\mathop{\rm Re}\nolimits} \{ \alpha  \pm i\beta  \pm i\gamma \}  > 0,{\rm  }\gamma  > 0,{\rm  }{\mathop{\rm Re}\nolimits} \{ v\}  >  - \frac{1}{2}$. Since the complex exponential term in $P(t)$ becomes $e^{-jw(c - t)}$; thus, $\alpha=j(c-t)$, and we also have $\beta=a$, $\gamma=b$, which are all reals, $P(t)$ does not satisfy ${\mathop{\rm Re}\nolimits} \{ \alpha  \pm i\beta  \pm i\gamma \}  > 0$, so I couldn't use the result. I've tried to get $P(t)$ with Mathematica, but it has returned with nothing. Today, I tried to solve it using the convolution theorem, but the result is somewhat very long and messy; the direct solving of the integral seems a nightmare for me. Does anyone knows how to solve the integral or a closed form expression of $P(t)$?
Any little clue will be helpful.
Thanks in advance!","['special-functions', 'fourier-analysis', 'integration']"
289772,References for quasi finite and proper implies finite,Does anybody know a reference for a proof of: Let $f: X \rightarrow Y$ be a quasi-finite proper morphism of varieties. Then $f$ is finite. Is there one in Hartshorne? I could not find it. Thanks!,"['algebraic-geometry', 'schemes']"
289791,"Base for a topology, euclidean topology and Hausdorff","I am trying to solve an exercise from an old exam, but i am stuck at some parts of the exercise, which are not very clear for me or i can't move on. I would be very glad if someone could help me.
So, this is the exercise: On $\mathbb{R}$ consider the collection $\mathbb{B} :=\left \{ [a,b) \subset \mathbb{R}: a,b \in \mathbb{R}, a<b \right \}$ (a) Prove that $\mathbb{B}$ is a base for a topology $\tau$ on $\mathbb{R}$ and that $\tau$ satisties the axiom $T_{2}$. Ok, here I proved easily that this collection is a base. I don't understand why $\tau$ should be a topology of Hausdorff space...we know that $\mathbb{R}$ is uncountable and has infinitely many elements. In this case it can't be Hausdorff? (b) Consider the identity function $I: (\mathbb{R},\tau )\rightarrow (\mathbb{R},\tau _{\varepsilon })$, where $\tau _{\varepsilon }$ denotes the usual euclidean topology. Is $I$ continuous? Is it an homeomorphism? (c) Does $\tau$ satisfy the axiom $T_{3}$?
$T_{3}$ was about that a closed set and a point, which is not contained in this set, have disjoint open neighborhoods. Thank you in advance!","['general-topology', 'separation-axioms', 'sorgenfrey-line']"
289797,Minimising Length and Energy for Finsler Manifold,Is it true that a minimiser of Finsler energy is automatically parameterised by arc length? As in the Riemannian case. Is there a reference for this fact?,"['geometry', 'differential-geometry']"
289802,"Question about the functional equation $B(t,T)=c(t)B^2(t,T)$ arising from certain differential equations","We are looking at a theorem which characterizes the affine term structure (ats) models in interes rate theory. What follows is from ""Filipović, D. (2009): ""Term-structure models: A graduate course"", Springer-Verlag"", chpt. 5, page 84. We denote by $F(t,r,T)$ the bond price and say it is of (ats) if and only if $$F(t,r,T)=e^{-A(t,T)-B(t,T)r}$$ for smooth functions $A$ and $B$ . $r$ denotes the interest rate and is a stochastic process. Then the theorem states a short rate model of the form $$\mathrm dr(t)=b(t,r)\mathrm dt+\sigma(t,r)\mathrm dW(t)\tag{*}\label{*}$$ for continuous $b$ and $\sigma$ provides ats if and only if $$\sigma^2(t,r)=a(t)+\alpha(t)r \text{ and } b(t,r)=b(t)+\beta(t)r$$ for continuous function $a$ , $\alpha$ , $b$ and $\beta$ , and the functions $A$ and $B$ satisfy the system of ODE, for all $t\le T$ : $$\partial_tA(t,T)=\frac{1}{2}a(t)B^2(t,T)-b(t)B(t,T), \, A(T,T)=0$$ $$\partial_tB(t,T)=\frac{1}{2}\alpha(t)B^2(t,T)-\beta(t)B(t,T)-1, \, B(T,T)=0$$ The key point of the proof is that $F$ should satisfy the following equation $$ \partial_t F+b\partial_rF+\frac{1}{2}\sigma^2\partial_{rr}F-rF=0\tag{1}\label{1}$$ where $b,\sigma$ are from \eqref{*}. For the proof, you put the explicit formula of $F$ into \eqref{1}, we see that the short rate model provides an ats if and only if $$\frac{1}{2}\sigma^2B^2-bB=\partial_tA+(\partial_tB+1)r \tag{2}\label{2}$$ where I wrote $B$ for $B(t,T)$ and the same for $A$ . Looking about the equation above the direction "" $\Leftarrow$ "" is proved. For the direction "" $\Rightarrow$ "", they first assume that $B$ and $B^2$ are linearly independent for fixed $t$ and show the claim. After that the only case which we now have to look at, is $$B(t,T)=c(t)B^2(t,T)\tag{3}\label{3}$$ for some constant $c(t)$ . I guess we also fix here $t$ . Then they conclude the following things, which I do not understand: \eqref{3} should imply that $B(t,\cdot)=B(t,t)=0$ . Why is that true?
From there they say, well then \eqref{2} implies that $\partial_tB(t,T)=-1$ . I also do not get that conclusion. After all they conclude that the set of elements $t$ , for which $B(t,\cdot)$ and $B^2(t,\cdot)$ are linearly independent is open and dense in $\mathbb{R}_+$ . I have no idea how one can conclude all these things. Some help would really be appreciated.","['real-analysis', 'functional-equations']"
289803,$1/4$ is in the Cantor set?,"I would like to know if $1/4$ is in the Cantor set, I tried a lot without success, I need some hint or help how to proceed in this case. Maybe there is some tool or trick I can use. Thanks a lot","['real-analysis', 'cantor-set']"
289816,"Is it correct, or legitimate to write $P(\prod_{i \in I}{X_i}) = \prod_{i \in I}{P(X_i)}$?","I'm trying to formulate Axiom of Choice in terms of $P(\prod_{i \in I}{X_i})$, but end up with the following questions. Let $P(X)$ be the power set of $X$.In general, is it correct, or legitimate to write: $P(\prod_{i \in I}{X_i}) = \prod_{i \in I}{P(X_i)}$? Let $|X|$ be the cardinality of $X$.Is it the case $|P(\prod_{i \in I}{X_i})| \leq \prod_{i \in I}{|P(X_i)|}$?","['elementary-set-theory', 'axiom-of-choice']"
289818,On the continuity of Riemann Integral,"I have the following equation $$g(y)=\int_{0}^{\infty} f(x,y) dx$$ I know that $f$ is continuous in $x$ and $y$. But I would like to infer that $g$ is continuous in $y$. Can I do this? EDIT: I wont write down the function here, since it is huge, but I can guarantee that: $f$ is differentiable in both $x$ and $y$ $\lim_{y\rightarrow \infty} f(x,y) = \infty$ I could try to solve the integral, but I do not know if I'm able too. Applying some theorem that guarantees continuity would be great, but now I see I would need further hypothesis.","['multivariable-calculus', 'calculus']"
289819,Fundamental theorem of Algebra using fundamental groups.,I tried to prove the fundamental theorem of algebra using fundamental groups. I am not able to understand the proof. Can anyone help me?,"['algebraic-geometry', 'algebraic-topology']"
289823,"Can a norm take infinite value? For example, $\|\cdot \|_1$?","A definition for norm from Wikipedia says Given a vector space $V$ over a subfield $F$ of the complex numbers, a norm on $V$ is a function $p: V → \mathbb{R}$ with the following properties: For all $a ∈ F$ and all $u, v ∈ V$, $p(av) = |a| p(v)$, (positive homogeneity or positive scalability). $p(u + v) ≤ p(u) + p(v)$ (triangle inequality or subadditivity). If $p(v) = 0$ then $v$ is the zero vector (separates points). Can a norm take value $+\infty$? I think topology and convergence are what I had in mind. If we modify the definition of a norm to allow it take $\infty$,  in such a generalized norm space, does it induce a topology, so that we can talk about convergence relative to the generalized norm being equivalent to convergence relative the induced topology? My question comes from an example: can $\|\cdot \|_1$ be defined on all measurable functions which are allowed to have infinite integrals not just finite integrals? Thanks!","['normed-spaces', 'real-analysis']"
289857,Integral of $\int \frac{1}{\sqrt{x(1-x)}} dx $,"$$\int \frac{1}{\sqrt{x(1-x)}} dx $$
I solved the integral in this way: make the substitution $x=\sin^2(u)$, then $dx=2\sin(u)\cos(u)du$. So the integral now becomes 
$$\int \frac{2\sin(u)\cos(u)}{\sqrt{\sin^{2}(u)(1-\sin^{2}(u))}} du=\int 2 du=2u+C.$$ 
Then subbing in $u=\arcsin(\sqrt{x})$ I get the solution 
$$2\arcsin(\sqrt{x})+C.$$
However when I typed in this integral onto Wolfram it gave me this . So my question is did I get it wrong or are the two forms equivalent?","['calculus', 'integration']"
289864,How to Construct orthogonal circles?,Let $C_{1}$ be a circle of unit radius. Let A and B be two points inside $C_{1}$. Now I want to construct another circle $C_{2}$ such that A and B lie on $C_{2}$ and $C_{2}$ is orthogonal to $C_{1}$ at their point of intersection(I want $C_{2}$ in such a way that it intersects $C_{1}$). I tried and failed to find a way to construct such a $C_{2}$. Any help is appreciated.,"['geometry', 'recreational-mathematics']"
289873,Is the Dirac measure named after P.A.M. Dirac?,"Does anyone know if the notion of a Dirac measure was named after P.A.M. Dirac? If yes, did he actually introduce it, or is it because integration w.r.t. a Dirac measure does what the so-called Dirac delta function is supposed to be used for?","['probability-theory', 'measure-theory', 'math-history']"
