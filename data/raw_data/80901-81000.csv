question_id,title,body,tags
1049419,Finding Basis for a Radical of an Ideal,"I am to find a basis of the following ideal: $$\sqrt{<x^5-2x^4+2x^2-x, \quad x^5-x^4-2x^3+2x^2+x-1>}$$ Truth be told, I'm not entirely confident of my solution. I will present it and then ask the pertinent questions: First of all, note that $$x^5-2x^4+2x^2-x=x(x-1)^3(x+1),$$ and 
$$x^5-x^4-2x^3+2x^2+x-1=(x-1)^3(x+1)^2$$ According to a theorem in the textbook of which I'm doing these problems, if $I$ is an ideal in $k[x_1,x_2,...,x_k]$, then $\sqrt{I}=I(V(I))$. Using this theorem, I found that $V(I)$ is $\{-1,1\}$. Thus, $$I(V(I))=(x-1)(x+1)=x^2-1.$$ Is this correct? I think this is the right theorem to use, and I think what I provided was indeed a basis of some sort; can someone confirm/correct this? Thank you in advance","['algebraic-geometry', 'polynomials']"
1049431,"Number of solutions to equation, range restrictions per variable","Find the number of solutions of the equation $x_1+x_2+x_3+x_4=15$ where variables are constrained as follows: (a) Each $x_i \geq 2.$ (b) $1 \leq x_1 \leq 3$ , $0 \leq x_2$ , $3 \leq x_3 \leq 5$, $2 \leq x_4 \leq 6$ I believe I understand part A. I can fix the values at greater than two by adding two to each term, as in: $(x_1 + 2) + (x_2 + 2) + (x_3+2) +(x_4+2) = 15$ $x_1+x_2+x_3+x_4=7$ So, $C(7+4-1,7) = {10! \over 7!3!} = 120$ For part B, i really have no idea where to start. Thanks for any insight!",['combinatorics']
1049471,How to prove the existence of a vector potential for a solenoidal vector field?,"If $\textbf{F}$ is a vector field and $\bf{divF}=0$, how would you show that this implies the existence of a vector field $\bf{A}$ such that $\bf{F}=curl A $?","['multivariable-calculus', 'calculus']"
1049477,Proofs with Relations and functions,"I need help with setting up a homework problem. I am having trouble finding where to start. Problem: Suppose A is a set. Show that $i_A$ is the only relation on A that is both an equivalence relation on A and also a function from A to A. First of all I'm not very clear what $i_A$ is. I think its a relation $_AR_A$? I'm really having trouble with the intuition behind proofs such as this. What proof strategy do I normally use to prove that ONLY ONE thing satisfies my conditions? Should I start my proof with $i_A$ or with the part about equivalence relation and function? I'm also not very clear on what an equivalence relation is. I know that it has to be transitive, symmetric, and reflexive... but how does that help me? I really want to learn all of this proof based math stuff but it is very counter intuitive to me.","['relations', 'equivalence-relations', 'discrete-mathematics']"
1049502,"The map $f\colon\mathbb{A}^2_k\to\mathbb{A}^2_k$ given by $f(x,y)=(x,xy)$ is birational?","I'm reading a bit about rational maps, and I'm still trying to get get my head around birational maps. Consider the map $f\colon\mathbb{A}^2_k\to\mathbb{A}^2_k$ on the affine $2$-space over $k$ algebraically closed, defined by $f(x,y)=(x,xy)$. I believe this map is regular, hence a rational map. Apparently this is also a birational isomorphism. I computed the inverse map to be defined by $f^{-1}(u,v)=(u,v/u)$. However, I think the domain of definition of $f^{-1}$ is $\mathbb{A}^2\setminus\{(0,y):y\in k\}$ since $u$ can't be zero. Is this the correct domain of definition, or can it be extended to all of $\mathbb{A}^2_k$ somehow? I thought the domain would have to be all of $\mathbb{A}^2_k$ for it to be a rational inverse. Also, it's probably clear, but why is $f^{-1}$ a rational map? Thanks for your explanations.","['algebraic-geometry', 'self-learning', 'birational-geometry']"
1049507,Is a one point space Hausdorff?,This may be a silly question but I'll ask anyway: Is a topological space consisting of a single point Hausdorff?,['general-topology']
1049521,Show that $ {x}_{k+1} - {x}_{k} \rightarrow L \Rightarrow \frac {{x}_{k}} { k} \rightarrow L $,"I have to show that the implication in the title is true as $ k \rightarrow \infty $ and where $ \left< {x}_{k} \right> $ is a sequence This question is from Wade's Introduction to Analysis and I think that it is something to do with Cauchy sequences because right before the question it says ""[Cauchy]"". However, the book doesn't give any hints or anything on how to prove it. $ {x}_{k+1}- {x}_{k} -L \rightarrow 0$ as $ k \rightarrow \infty $ is a Cauchy sequence $ \Rightarrow \frac {{x}_{k+1} - {x}_{k} - L} {k} \rightarrow 0 $ as $ k \rightarrow \infty $ is a Cauchy sequence as well. Another way I was thinking about it is $ lim _{k \rightarrow \infty} {{x}_{k}} = lim_{k \rightarrow \infty} ( {x}_{k+1} - L) $ so it would be sufficient to show that $ lim _{k \rightarrow \infty} \frac {{x}_{k+1} - L}  {k} = L$ However, I'm not sure how to follow through on either in order to show the implication. Any help is greatly appreciated. Thanks in advance.","['limits', 'sequences-and-series', 'analysis']"
1049522,Rudin's chain rule: Why is continuity at interval necessary?,"Theorem 5.5, Rudin's Principles of Mathematical analysis says: Suppose $f$ is continuous on $\color{red}{[a,b]}$ ,$ f'(x)$ exists at some point $x\in [a,b], g$ is defined on an interval $I$ which contains the range of $f$, and $g$ is differentiable at the  point $f(x)$. If $$h(t)=g(f(t)) \quad (a\le t \le b)$$ then $h$ is differentiable at $x$, and $$h'(x)=g'(f(x))f'(x)$$ I believe, I have understood the proof. But why is continuity at $[a,b]$ required? To me differentiablity at $x$ of $f$ and the same at $f(x)$ of $g$ is the only required conditions.","['derivatives', 'real-analysis']"
1049523,"For continuous invertible $f$, how many discontinuities can $f^{-1}$ admit?","The inverse of a continuous function need not be continuous. A canonical example is $f:[0,2\pi)\rightarrow S^1$, where $S^1$ is the unit circle in $\mathbb{R}^2$, and $$f(\theta)=(\sin\theta,\cos\theta).$$ We can run with this construction to add more discontinuities to the inverse of a continuous function. For example, consider a function $g:[0,2\pi)\rightarrow \mathbb{R}^{2n}$, $n\in \mathbb{N}$, defined by: $$g(\theta)=(\sin\theta,\cos\theta,\sin2\theta,\cos2\theta,...,\sin P_{n}\theta,\cos P_{n}\theta)$$ where $P_{n}$ is the $n$th prime number. But is it possible to go further still? This brings me to my question: Is it possible to construct a continuous invertible function with its inverse containing uncountably many discontinuities? My gut tells me no, but I may be wrong, and I have little clue on how to go about proving this. My only thought was to try and decompose $f^{-1}$ into a set of intervals on which the inverse is either CADLAG or CAGLAD. But I am not sure specifically how I could make this construction, or if it is a sensible idea in the first place.","['functions', 'real-analysis']"
1049545,Evaluating $ \int_{0}^{\infty}\frac{\ln (1+16x^2)}{1+25x^2}\mathrm d x$,"how to solve such type of definite integration?
I would like to see various methods to evaluate following integral
$$
\int_{0}^{\infty}\frac{\ln (1+16x^2)}{1+25x^2}\mathrm d x$$","['improper-integrals', 'calculus', 'integration']"
1049553,Function of Pauli matrices,"Let $\hat{n}$ be a 3D unit vector and let $\vec{\sigma}$ be a vector of the Pauli matrices
\begin{align}
\vec{\sigma} = \left( \left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right)\ ,\ \left(\begin{matrix}0 & - i \\ i & 0 \end{matrix}\right)\ ,\ \left(\begin{matrix} 1 & 0 \\ 0 & -1\end{matrix}\right)\right)
\end{align}
Let $\theta \in \mathbb{R}$ and $f$ be a function taking complex matrices to complex matrices. Show that
\begin{align}
f(\theta\ \hat{n} \cdot \vec{\sigma}) = \frac{f(\theta) + f(-\theta)}{2}I + \frac{f(\theta) - f(-\theta)}{2}\hat{n} \cdot \vec{\sigma}
\end{align} I have tried expressing $f$ as a Fourier Series in order to exploit the known fact that 
\begin{align}
\exp(i\theta \hat{n} \cdot \vec{\sigma}) = \cos\theta I + i\sin\theta \hat{n} \cdot \vec{\sigma}
\end{align}
but I'm not sure if matrix-valued Fourier Series are even a thing. Could I please get some suggestions on how to prove this?","['matrices', 'hilbert-spaces', 'functions']"
1049584,Coin flips and prediction - Is this a paradox?,"Let's say a coin is given to you which is shown to have two sides (head and tail). I threw the coin 10 times and I got the sequence HHHHHHHHHH (all heads). Now, I am about to throw it the eleventh time. You lose a large bet if you predict the next toss wrongly. How will you predict the outcome of next toss? Here are some of my answers: It is rare to see 10 heads together unless the coin is biased. Hence, the probability that the coin is biased (the hyperparameter, theta) is very high. So, I should bet that the next outcome will also be a head. 10 flips are too small a number to conclude that the coin is biased. Getting 11 heads is extremely rare and hence I must bet on a tail for eleventh toss. Coin flips are IID and hence it does not depend on the previous tosses. You can bet on anything and your chances of winning is the same. Am extremely confused on which of these is a good answer if any of them is a good answer at all. What do you think?","['independence', 'probability', 'paradoxes']"
1049608,Lattice generated by vectors orthogonal to an integer vector,"Given a non-zero vector $\boldsymbol{v}$ composed of integers, imagine the set of all non-zero integer vectors $\boldsymbol{u}$, such that $\boldsymbol{u} \cdot \boldsymbol{v} = 0$, i.e., the integer vectors orthogonal the original vector.  The set $S = \{\boldsymbol{u} : \boldsymbol{u} \cdot \boldsymbol{v} = 0\}$ seems to form a $dim(\boldsymbol{v})-1$ dimensional lattice.  Specifically, it's clear that for any two elements of $S$, their linear combination is also in $S$.  However, because S is a subset of the lattice of all integer vectors, it's also a lattice. It there a name for this lattice?  Additionally, how can it's basis vectors be computed?","['integer-lattices', 'linear-algebra', 'vector-lattices', 'algorithms']"
1049719,Difference between homomorphisms and homomorphic images,"I was reading Group Homomorphisms from Contemporary Abstract Algebra - Gallian. In pg-216, 8th ed (pg-200, 4th ed), the author writes - ""We know that the number of homomorphic images of a cyclic group G of order n is the number of divisors of n, since there is exactly one subgroup of G (and therefore one factor group of G) for each divisor of n. (Be careful: The number of homomorphisms of a cyclic group of order n need not be the same as the number of divisors of n, since different homomorphisms can have the same image.)"" How are homomorphic images and homomorphisms different? They sound very similar... Thanks..","['group-homomorphism', 'group-theory', 'abstract-algebra']"
1049724,Prove that orientable surface has differentiable normal vector,"Prove that: a regular surface
  $S\subset \mathbb{R}^3$ is an
  orientable manifold if and only if
  there exists a differentiable mapping
  of $N:S\rightarrow \mathbb{R}^3$ with
  $N(p)\perp T_p(S)$ and $|N(p)|=1$, for
  all $p\in S$. If part: I guess I have to first let $X_a,X_b$ be parametrization of $S$, and $<dX_a,N>=<dX_b,N>=0$. Differentiability of $N$ imply (not sure) $N\circ X_a$ and $N\circ X_b$ are also differentiable, which their differentials are linear function. I then have no idea how to show that $\det(d(X_b^{-1}X_a))>0$. Only if part: Zero idea. Please give me some insight!!",['differential-geometry']
1049780,"Why is a Hyperplane called a ""Hyper""plane?","I just had this curious question. In other fields, the word ""hyper"" is actually used to refer to something which is ""over; beyond; above"" as defined by Google. An example of such terms would be Hyperglycaemia, defined by Wikipedia as: a condition in which an excessive amount of glucose circulates in the blood plasma. Or Hypersonic, defined by Google as: relating to speeds of more than five times the speed of sound. So, my question is, what would be the motive to give a Hyperplane such a name when it is defined as : a subspace of one dimension less than its ambient space","['geometry', 'self-learning']"
1049784,Find the derivative of the inverse of this real function $f(x) = 2x + \cos(x)$,"I don't know how to attack this problem. The last I've tried is using a differential equation, but I don't know how to solve it. Let $y$ be $f^{-1}(x)$. Knowing that $x=f(y)= 2y + \cos(y)$ and derivating I obtained the following non-linear first order differential equation: $y' \cdot (2-\sin(y))=1$ I would thank you if you can help me. Edit: I haven't said, but it is trivial to check that the function is injective, so it has an inverse, because $\forall x \in \mathbb{R}$ $f'(x) \neq0$","['ordinary-differential-equations', 'calculus']"
1049788,Haar measure of an angle-distance ball in SO(3),"If for rotations $R_0$, $R_1$ we define the distance $d(R_0, R_1)$ to be the angle of $R_0 R_1^{-1}$ and given $r\in [0,\pi]$, what is the ""volume"" (normalised Haar measure) in SO(3) of the ball $\{R\in\mathrm{SO}(3):d(R, \mathrm{Id})<r \}$. I want to know for putting prior probabilities on subsets of the space of rigid transforms in some software.","['measure-theory', 'lie-groups']"
1049869,limsup of average smaller than limsup,"I have read this solution , but I could not understand it. It has shown $$\sigma_n\leqslant  \frac 1n\sum_{j=1}^ks_j+\sup_{l\geqslant k}s_l,$$ but how does it go to $$\sup(\sigma_n)\leqslant \frac 1n\sum_{j=1}^ks_j+\sup_{l\geqslant k}s_l$$ I have thought of regarding the RHS as upper bound of $\sigma_n$, but I am not sure about this, since RHS varies as $n$ changes. The writer wrote ""take on both sides the limsup when $n \to \infty$"", but I could not understand it. Please help.","['limsup-and-liminf', 'inequality', 'limits']"
1049871,question on translation of operator proof,"Has anyone studied the book 'Nonlinear Partial differential equations with applications' by Tomas Roubicek? I am interested in discussing a point of interest in this book. Specifically, on page 52, in the proof of Theorem 2.36 (Leray-Lions) it states that $A_{0}$ inherits coercivity from $A$. How does one prove this? Thanks for any assistance.","['reference-request', 'proof-writing', 'functional-analysis', 'partial-differential-equations']"
1049873,Exterior derivative cohomology,"Let $\Omega^k (U)$ denote the set of differential $k$-forms on an open subset $U\subseteq \mathbb{R}^n$. For each $k\in \mathbb{N}$ the exterior derivative $d_k=d : \Omega^{k-1} (U) \rightarrow \Omega^k (U)$ sends the $(k-1)$-form $\omega$ to the $k$-form $d \omega$ defined by $d(\omega) = d(\omega_{i_1 \dots i_{k-1}} f^{(i_1)} \wedge \dots \wedge f^{(i_{k-1})})=d\omega_{i_1 \dots i_{k-1}}\wedge f^{(i_1)} \wedge \dots \wedge f^{(i_{k-1})}$ where we define the $1$-form $d\omega_{i_1 \dots i_{k-1}}=\frac{\partial}{\partial x^j}(\omega_{i_1 \dots i_{k-1}}) f^{(j)}$ (and $f^{(i)}$ are the dual basis vectors for ${\mathbb{R}^n}^*$). Since $d^2 = 0$, we obtain a sequence of vector spaces $C^\infty (U) =\Omega^0 (U) \xrightarrow{d_1} \Omega^1 (U) \xrightarrow{d_2} \cdots\xrightarrow{d_k} \Omega^k (U) \xrightarrow{d_{k+1}}\cdots$ where $\operatorname{im} d_k \subseteq \ker d_{k+1}$ for all $k$. I haven't studied any (co)homology formally (although I have some limited experience now with modules and exact sequences) but I do recognise that this looks like a complex on which we might ""do"" cohomology. I asked my lecturer about this but I don't think he wanted to go into anything deeply - the differential geometry course I'm taking seems to be more on the concrete side with particular emphasis on subsets of $\mathbb{R}^n$ rather than general manifolds. However I am really interested in the abstract side of things and I'd like to know more about this sequence. Could anyone tell me anything ""interesting"" about the above complex: for example, how can we go about studying the cohomology and can we use it to say anything useful about our spaces of forms? What objects of study does this complex lead us to? My question is intentionally vague because I'd like to see a range of answers so as to get a feel for the first real instance of cohomology that I've seen in my degree. Many thanks!","['homology-cohomology', 'soft-question', 'differential-geometry']"
1049876,Sufficient condition for u.c.p. convergence of processes,"Assume that all processes are cadlag.
I am trying to prove the following claim: Let a sequence of processes $X_n$ be given. Assume that for all $s$ in a dense subset of $\mathbb R^+$ $
X_n(s) \overset{\mathbb P}{\rightarrow} X(s).
$ If the paths of $X_n$ are increasing for all $n$ a.s. and the paths of $X$ are continuous a.s., then we also have, for all $t>0,\epsilon>0$, ucp convergence: $
\lim_{n\to \infty} \mathbb P \left( \sup_{s\leq t} |X_n(s)-X(s)|>\epsilon\right)=0.
$ My attempt was to use that if a sequence of increasing functions converges pointwise to a continuous function, then convergence is uniform.
To do so I thought that if the dense subset is countable, you can find a subsequence $n_k$ for which, for all $s$, $X_{n_k}(s) \to X(s)$ a.s. Then applying the theorem you get ucp convergence along the subsequence. But how can you now conclude that it holds for the original sequence?","['probability-theory', 'stochastic-processes', 'stochastic-analysis']"
1049890,how can I find the smallest integer $n$ such that a polynomial divides $x^{n}-1$,"I have a simple question.. Assume that I have an arbitrary polynomial $f$ in $F_q[x]$. Is there a practical way to find the smallest integer $n$ for which $f$ divides $x^n-1$ ? A small example would be appreciated. Thanks, in advance. -I have my own answer for now for anyone interested, but not as practical as I would prefer-","['cyclotomic-polynomials', 'extension-field', 'abstract-algebra', 'polynomials']"
1049895,Can we take negative step size in Euler's method?,"Thus far we've taken the step size $h$ to be positive, and therefore we've developed solutions to the right of the initial point. Is Euler's method valid if we use a negative step size $h<0$ and develop a solution to the left? I think it is not possible.How we can explain that it is possible or not? Thanks.","['ordinary-differential-equations', 'numerical-methods']"
1049903,How can I prove $\sqrt{(111...)+(55...)^2}=5...6$,"The formula in my question can be illustrated as follow: $$\sqrt{11+5^2}=6$$
  $$\sqrt{111+55^2}=56$$ $$\sqrt{1111+555^2}=556$$ $$\sqrt{11111+5555^2}=5556$$ and so on How can I prove the general formula $$\sqrt{\underbrace{11\ldots 1}_{n+1\text{ times}} + (\underbrace{55\ldots 5}_{n\text{ times}})^{2}} = (\underbrace{55\ldots 5}_{n-1\text{ times}}6)^{2}$$","['calculus', 'number-theory']"
1049952,Recurrence relation for a differential equation,"I am reading a book that talks about series solutions of differential equations, and I couldn't seem to understand the following question: Consider the differential equation and use the assumption that then find the recurrence relation for the infinite series to be a solution. I am not entirely sure what the question means, especially about the recurrence relation. The only thing that I could get from the book is that the original equation is the  Legendre differential equation. How should I approach this problem? Thanks.","['legendre-polynomials', 'ordinary-differential-equations', 'recurrence-relations']"
1049954,Why does the support of measure on $\mathbb{R}^n$ exist?,"DEFINITION : The support of a measure on $\mathbb{R}^n$, written spt $\mu$, is the smallest closed set such that $\mu(\mathbb{R}^n \setminus X)=0$. Why does this set exist?","['measure-theory', 'metric-spaces']"
1049982,Jacobson radical of a certain ring of matrices,"Let $A$ be the $\mathbb{C}$-subalgebra of $M_4(\mathbb C)$ consisting of matrices of the form
  \begin{pmatrix}
* & * & * & *\\
* & * & * &*\\
0 & 0 & *&0 \\
0 & 0&* &*
\end{pmatrix}
  Then how would I find the Jacobson radical $J(A)$ of $A$? I don't really understand finding the Jacobson radical of $\mathbb{C}$-subalgebras. Any help on this would be greatly appreciated, thank you!","['matrices', 'ring-theory', 'abstract-algebra']"
1050007,How to prove that $Aut(\mathbb{P}^2) \cong PSL_3 (\mathbb{C})$?,"Notation: $\mathbb{P}^2$ denotes complex projective plane. We have an action $$SL_3 \times \mathbb{P}^2 \to \mathbb{P}^2, \ (A,[v])\mapsto [Av]$$ with kernel $\mathbb{C}^*.Id\cap SL_3 \cong C_3$ where $C_3$ is cyclic group of order $3$ generated by a third root of unity. $SL_3 / C_3 = PSL_3$ acts effectively on $\mathbb{P}^2$. Hence, we have an injective homomorphism $$
\phi: PSL_3 \hookrightarrow Aut(\mathbb{P}^2).$$ Is it true that $PSL_3 \cong Aut(\mathbb{P}^2)$ ? How to prove this? I know that $Aut(\mathbb{P}^2) \cong PGL_3$? But I am not sure how does this help?","['projective-space', 'algebraic-geometry']"
1050038,There's a small detail in this proof on why $\sum_{k=1}^{\infty}\frac{1}{k^2} = \frac{\pi^2}{6}$ that I can't figure out,"http://www.maa.org/sites/default/files/pdf/upload_library/2/Kalman-2013.pdf Here is a link to the article I have been reading. It's really interesting and easy to follow. What bothers me is a result the author uses. On page 45, the author goes on to say that $\ln(-1) = i\pi$ because $e^{i\pi} = -1$. Just take $\ln$ to both sides. Then he substitutes that result in and gets $\displaystyle\frac{\pi^2}{6}$. Makes sense. Here is my problem. Technically $e^{3i\pi}$ is also equal to $-1$ but if we were to substitute it in, we would not get the correct solution. So I guess my question is, does using other forms of $e^{i\pi}$ like $e^{3i\pi}$ work or is there a reason why you can only choose $e^{i\pi}$?","['polylogarithm', 'power-series', 'complex-analysis']"
1050057,Prove that $\lim_{n\rightarrow\infty}\frac{1}{n^{p+1}}\sum_{k=1}^{n}k^{p}=\frac{1}{p+1} $,"I need to prove that $$
\lim_{n\to\infty}\frac{1}{n^{p+1}}\sum_{k=1}^n k^p
 = \frac{1}{p+1}
$$ By Stolz lemma, $$\frac{(n+1)^{p}}{(n+1)^{p+1}-n^{p+1}}=\lim_{n\rightarrow\infty}\frac{1}{n^{p+1}}\sum_{k=1}^{n}k^{p}=\frac{1}{p+1}$$ and $$\frac{(n+1)^{p}}{(n+1)^{p+1}-n^{p+1}}\geq\frac{1}{\frac{p+1+\frac{1}{n}}{1+\frac{1}{n}}}\rightarrow  \frac{1}{1+p}$$ And know I'm stuck..","['summation', 'sequences-and-series', 'limits']"
1050082,Algebraic fundamental group vs arithmetic fundamental group,"I'm trying to read about anabelian geometry and obviously the things to start with is the algebraic (etale) fundamental group. Every now and again I encounter authors talking about the arithmetic fundamental group, especially when they're talking about curves. Are these really the same thing, except the term algebraic fundamental group is used when talking about arbitrary schemes and the arithmetic fundamental group when talking about curves?","['geometry', 'fundamental-groups']"
1050095,Embedding a torus in $\mathbb{R}^{n+1}$,"It is easy to see that $T^2=S^1 \times  S^1$ can be embedded in $\mathbb{R}^4$ but also there is an embedded in $\mathbb{R}^3$. The question is $T^n = S^1 \times \ldots \times S^1$ can be embedded into $\mathbb{R}^{n+1}$, $n>2$.","['differential-topology', 'differential-geometry']"
1050110,Explain why $|x^2-x|$ is not differentiable at $x=1$,Explain why $|x^2-x|$ is not differentiable at $x=1$..... lets go.... we need to show that $\lim_{a\to0}$ of $\frac{f(1+a)-f(1)}{a}$ doesn't exist...which is to say $\lim_{a\to0}$ of $\frac{(|(1+a)^2 - (1+a)|- |1^2-1|)}{a}$ doesn't exist which is like $\lim_{a\to0}$ of $\frac{(|(a)^2 + a|)}{a}$ so we take off absolute value (Is this allowed?) and get  $\lim_{a\to0}$ of $\frac{((a)^2 + a)}{a}$ which is $1$ Not quite what expected...How do we do this?,"['calculus', 'derivatives']"
1050112,"The ""muscle"" behind the fact that ergodic measures are mutually singular","This is really motivated by the soft question at the end, but let me begin with something more circumscribed: Let $(X,\mathcal{B})$ be a measurable space and let $T:X\circlearrowleft$ be a self-map measurable with respect to $\mathcal{B}$ . Let $\mu$ and $\nu$ be $T$ -invariant finite measures such that $\nu \ll \mu$ . Let $f\in L^1(X,\mu)$ be the Radon-Nikodym derivative $d\nu/d\mu$ . I have two questions: (1) Is $f$ a $T$ -invariant element of $L^1(X,\mu)$ , in the sense that $\int_Efd\mu = \int_E f\circ T d\mu$ for all $E\in\mathcal{B}$ ? (2) If the answer is yes, is it possible to prove this without recourse to the Birkhoff Ergodic Theorem or an equivalent? If the answer is no, what is an example? Motivation, thoughts, and the soft question: I am asking because on the one hand, it seems to me on general grounds that the fact that $f$ is defined uniquely in terms of the $T$ -invariant measures $\nu$ and $\mu$ ought to force it to be $T$ -invariant. (Where could the ability to change with $T$ come from, if not from $\mu$ or $\nu$ ?) On the other hand, when I apply the definitions directly, so far I have only been able to demonstrate the equality $$ \int_E fd\mu = \int_E f\circ Td\mu$$ for sets $E$ in the pullback $\sigma$ -algebra $T^{-1}\mathcal{B}$ . For example, we have $$\int_{T^{-1}E}fd\mu = \nu(T^{-1}E) = \nu(E)=\int_E fd\mu = \int_EfdT_*\mu = \int_{T^{-1}E} f\circ Td\mu$$ verifying the equality for sets of the form $T^{-1}E$ . Maybe I'm just not being clever enough, but every time I've played with it so far, this is how it comes out. Thus if $T$ is invertible, I have the desired equality, but if not, then I am not sure. Meanwhile, if we make the additional assumption that $\mu,\nu$ are probability measures and that $\mu$ is ergodic, then using the Birkhoff Ergodic Theorem I can prove that $\nu = \mu$ , which of course implies that $f=1$ . After some more work this implies that distinct ergodic measures are mutually singular. My soft question , which is really what the title is about, is, does this result in some essential way ""come from"" the Birkhoff Ergodic Theorem? If the answer above to (1) is yes, and it is possible to prove it without the BET, then this could in turn be used to prove that if $\mu,\nu$ are probability measures with $\mu$ ergodic, then $\nu=\mu$ , and then this would imply that distinct ergodic measures are mutually singular without needing the BET. But my experience playing around so far makes it seem as though somehow without the BET, the definitions themselves are ""not enough power."" Is there anything to this? If so, what do I really mean? What aspect of the situation that the BET illuminates is needed for this result? Thanks in advance for your thoughts.","['dynamical-systems', 'measure-theory', 'ergodic-theory', 'soft-question']"
1050129,Derivative of a norm vs norm of a derivative,"Consider a vector-valued function of the time, say $$v: \tau\in\mathbb{R}\to\mathbb{R}_N.$$
Suppose that for $\tau=t$, the function is equal to the zero vector, i.e. $$v(t)=0_N.$$ Denote as $\alpha\in\mathbb{R}_N$ the value of the time derivative of $v$ in $\tau=t$, i.e. $$\dot{v}(t)=\frac{d}{d\tau}v(\tau)|_{\tau=t}=\alpha.$$
Of course we can write that $$||\dot{v}(t)||=||\frac{d}{d\tau}v(\tau)|_{\tau=t}||=||\alpha||.$$
But I wonder if I can say that $$(\frac{d}{d\tau}||v(\tau)||)_{\tau=t} \le ||\alpha||.$$
And if so, why?","['normed-spaces', 'calculus', 'derivatives']"
1050164,What is the matrix norm induced by weighted vector norm?,"I denote vector norms with doulbe bars and matrix norms with triple bars. It is well known that the vector norm $L_2$ i.e. $\| x \|_2 = \sqrt{x^\top x}$ induces the matrix norm $||| \cdot  |||_2$, which is the largest singular value of a matrix. Consider the weighted norm, i.e. $\| x \|_W = \sqrt{x^\top W x} = \| W^\frac12 x\|_2$, where $W$ is some diagonal matrix of positive weights. What is the matrix norm induced by the vector norm $\| \cdot \|_W$ ? Does it have a formula like $||| \cdot |||_W = |||F \cdot |||_2$ for some matrix $F$?","['matrices', 'normed-spaces', 'linear-algebra']"
1050182,global behavior of an ODE system,"Consider the ODE system 
$$
(x',y')=f(x,y)
$$
where
$$
f(x,y)=((1-x/2-y/2)x,(-1/4+x/2)y)
$$
in the first (open) quadrant. It is not hard to show that $z_0=(1/2,3/2)$, which is a equilibrium of the system, is locally a spiral sink. Using Mathematica, one can get Let $\phi_t(z) = (x(t),y(t))$ be the  solution to the system with initial condition $(x(0),y(0))=z$ in the first quadrant.
One can tell from the figure that
$$
\lim_{t\to\infty}\phi_t(z)=z_0
$$
for every $z$ in the first quadrant. How can one prove that this is indeed true?",['ordinary-differential-equations']
1050184,Difference between Poisson and Binomial distributions. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question If both the Poisson and Binomial distribution are discrete, then why do we need two different distributions?",['statistics']
1050207,How likely are extreme observations in a probability distribution?,"Given a measurement that follows a probability distribution (for the sake of argument, Gaussian) how likely is it that repeated observations on the distribution are an extreme of low or high? I realise that the first two will be by definition, but how quickly does the probability reduce by the 10th, 20th, 50th etc observation? How quickly does the cumulative probability go up when taking multiple observations on different distributions? Background I am having a hard time forming my question (edits appreciated), so I will give some background. I was having a conversation with a friend about the weather when he remarked that it had been the hottest September in 20 years(1). I said that he shouldn't be surprised, and in fact given the number of different weather measurements (hottest, coldest, wettest, driest, most sunny, least sunny, etc) and given the number of times the observations are made (weekly, monthly, annually) then I thought it quite normal, and indeed likely, to get some sort of extreme observation. I realise there is no exact answer to this question; I am not asking what is the probability is of it being the hottest September in 20 years. (1) After some research it is apparent that weather recordings don't follow Gaussian distributions, but its still an interesting topic of thought.","['statistics', 'probability-distributions', 'probability', 'soft-question']"
1050291,Show that quotient rings are not isomorphic,"I've been given a homework problem that requires me to show that the rings $\mathbb{C}[x,y]/(y - x^2)$ and $\mathbb{C}[x,y]/(xy-1)$ are not isomorphic. This is my attempt at a solution: For $\mathbb{C}[x,y]/(y - x^2)$, we can parametrize in the following way: $x = t$ and $y = t^2$. Then this ring is isomorphic to $\mathbb{C}[t]$. For $\mathbb{C}[x,y]/(xy-1)$, we can parametrize $x = t$ and $ y = 1/t$. Then this is isomorphic to $\mathbb{C}[t, 1/t]$. But $\mathbb{C}[t, 1/t]$ is not isomorphic to $\mathbb{C}[t]$. Am I on the right track? If not, any helpful hints ?","['ring-theory', 'abstract-algebra']"
1050319,proving equalities in stochastic calculus,"I am struggling with this question: FIRST PART (almost done, but stuck somewhere): Let $Z $~$ N(0,1)$ be a standard normal random variable, and define a function $F$ by
the formula
\begin{equation}
F(v,m) = \mathbb{E} \bigg[ \Big( \exp\big\{-\frac{v}{2} + \sqrt{v} Z\big\} -m \Big)^{+} \bigg].
\end{equation}
Let $W$ and $Z$ be independent Brownian motions, let $r$, $\sigma_0$, $\rho$ and $S_0$ be real constants with $S_0 >0$ and $-1 \leq \rho \leq 1$ and let $a$ and $b$ be smooth functions. Suppose that
\begin{equation}
dS_t = S_t \Big(r dt + \sigma_t \big[ \rho dW_t + \sqrt{1- \rho^2} dZ_t \big] \Big), \quad d \sigma_t = a(\sigma_t)dt + b( \sigma_t) dW_t.
\end{equation}
Also, assume that the process $\sigma = (\sigma_t)_{t \geq 0}$ is bounded and adapted to the filtration $\{ \mathcal{F}_t \}$ generated by $W$, by conditioning on $\{ \mathcal{F}_t \}$, show that 
\begin{equation}
\mathbb{E} ( e^{-rT} (S_T - K)^{+} ) = \mathbb{E} \Bigg\{ S_0 \epsilon_T F \bigg( \int_{0}^{T} (1- \rho^2 ) \sigma^2_t dt, \, Ke^{-rT}/(S_0 \epsilon_T) \, \bigg) \, \Bigg\},
\end{equation}
where $\epsilon_T$ is defined by 
\begin{equation}
\epsilon_T= \exp \bigg( -\frac{1}{2} \int_0^T \rho^2 \sigma^2_t dt + \int_0^T \rho \sigma_t dW_t \bigg).
\end{equation} $\mathbf{\text{What I obtained so far (applying Ito's formula and did some algebra)}}:$
\begin{eqnarray}
&&\mathbb{E} ( e^{-rT} (S_T - K)^{+} ) \\
& = & \mathbb{E} \Bigg[ S_0 \epsilon_T \mathbb{E} \Bigg\{ \bigg( \exp \bigg[ -\frac{1}{2} \int_0^T (1-\rho^2) \sigma^2_t \,dt + \int_0^T \sqrt{1- \rho^2} \sigma_t dZ_t \bigg] - \frac{K e^{-rT}}{S_0 \epsilon_T} \bigg)^{+} \Bigg| \mathcal{F}_T \Bigg\} \Bigg].
\end{eqnarray}
The only difference between my expression and the answer is the term $\int_0^T \sqrt{1- \rho^2} \sigma_t dZ_t$. Does that have something to do with the conditional expectation? SECOND PART (don't really have a hint): Show that 
\begin{equation}
\mathbb{E} ( e^{-rT} (S_T - K)^{+} ) = \mathbb{E} \Bigg\{ S_0  F \bigg( \int_{0}^{T} (1- \rho^2 ) \hat{\sigma}^2_t dt, \, Ke^{-rT} \hat{\epsilon}_T/S_0  \, \bigg) \, \Bigg\},
\end{equation}
where 
\begin{equation}
d \hat{\sigma}_t= ( a(\hat{\sigma}_t) + \rho \hat{\sigma}_t b(\hat{\sigma}_t)) dt + b( \hat{\sigma}_t) d\hat{W}_t, \quad \hat{\sigma}_0 = \sigma_0
\end{equation}
and 
\begin{equation}
\hat{\epsilon}_T= \exp \bigg( -\frac{1}{2} \int_0^T \rho^2 \hat{\sigma}^2_t dt - \int_0^T \rho \hat{\sigma}_t d\hat{W}_t \bigg),
\end{equation}
where $\hat{W}$ is a Brownian motion. $\mathbf{\text{I only know that the Girsanov's theorem should be used as it is in that form but }}$ 
$\mathbf{\text{don't know where to start. Any suggestions?}}$","['stochastic-integrals', 'probability-theory', 'stochastic-calculus', 'brownian-motion', 'stochastic-differential-equations']"
1050380,Finding $\sum_{n=1}^{\infty }\frac{243}{16(n\pi )^5}\sin(2n\pi /3)$,"The WolfarmAlpha couldn't give me the sum of $$\sum_{n=1}^{\infty }\frac{243}{16(n\pi )^5}\sin(2n\pi /3)$$ therefore I thought that this problem is difficult so I used my calculator to get $(1/24)$ Is this value right or not?
If this right, why the WolfarmAlph couldn't find it?","['sequences-and-series', 'calculus', 'residue-calculus']"
1050413,Trigonometry. Finding the angle alpha,Refer the diagram below : What should be the angle alpha such that the variable x is between 7mm and 7.3mm.,"['trigonometry', 'triangles']"
1050458,how to generate rook polynomial,"I've encountered rook polynomials. I just can't seem to understand how to generate them by hand for small examples such as 3x3 boards. Take for instance: $$\begin{matrix}
1 & 1 & 0 \\
1 & 1 & 1 \\
0 & 1 & 0 \\
\end{matrix}$$ where $0$ means occupied. I'd appreciate a guide or at least a suitable literature, where it's explained.
Thanks.","['generating-functions', 'polynomials', 'combinatorics']"
1050479,How many Sylow $3$-subgroups can a group of order $72$ have?,How many Sylow $3$-subgroups can a group of order $72$ have? Let $G$ be a group of order $72=2^3 \cdot 3^2$. The number of Sylow $3$-subgroups $n_3$ divides 24 and has the form $n_3=3k+1$ by the Sylow Theorems. Therefore $n_3=1$ or $n_3=4$. Am I done?,"['sylow-theory', 'finite-groups', 'group-theory']"
1050496,Recurrence relation to find ternary strings that do not contains 3 consecutives 0's,"I'm stuck and I can't find this recurrence relation which is : Find a recurrence relation that count the number of ternary strings $(0,1,2)$ of length n that do not contains three consecutives 0's. I can easily find the recurrence relation for ternary strings that contains two consecutives zeros which is : $$a(n)=2\cdot a(n−1)+2\cdot a(n−2)+3^n−2$$ but I can't find a way to count it for three $0$'s. If someone could give me advice, it would be appreciated. Thanks.","['recurrence-relations', 'discrete-mathematics']"
1050522,I have lost part of text of problem condition.,I have the only last sentence. Prove that $X \approx X \times \{ x \}$ for every set$X$ and every object $x$. Question. What does mean the $\approx ?$ That there exist a biective map between the two sets  $X$ and  $X \times \{ x \}$?,"['algebra-precalculus', 'elementary-set-theory']"
1050525,Norm of covariance and precision matrices: is there any meaning?,"Let $\Sigma$ be a covariance matrix of some distribution. Then $\Sigma^{-1}$ is the precision matrix. Question: Does $\|\Sigma\|$ or $\|\Sigma^{-1}\|$ have any meaning (for any norm, though I ask in particular for the spectral norm).?","['probability', 'covariance']"
1050527,Sequence with denominators of products of consecutive Fibonacci numbers,"I'm trying to figure out a way to solve the value of this:
$$\frac{1}{1\times 2}-\frac{1}{2\times 3}+\frac{1}{3\times 5}-\frac{1}{5\times 8}+\frac{1}{8\times 13}-\dots$$ The only thing I can come up with is a summation involving the $nth$ fibonacci term formula that uses $\phi$.  Any other insights?","['fibonacci-numbers', 'sequences-and-series']"
1050532,Solve the recurrence relation by taking the logarithm of both sides and making the substitution $b_n = \lg a_n$,"Solve this recurrence relation: $$a_n = \left(\frac{a_{n-2}}{a_{n-1}}\right)^{\frac{1}{2}}$$ by taking the logarithm of both sides and making the substitution $$b_n = \lg a_n$$ A couple years ago I took precalc and a couple years before that I took College Algebra to brush up since before then I'd been out of school for a couple of years already. So I'm extremely rusty and this first step, getting the logarithm of both sides, has me confused enough... Like how would I even get the logarithm of the left side?? and then what exactly is that ""substitution"" supposed to be substitut ing ? So log'ing both sides I get $$\ln(a_{n}) = \frac{1}{2}\ln(a_{n-2}) - \frac{1}{2}\ln(a_{n-1})$$ Thank you Alex below but I still don't get how that translates to the substitution equation given... or how to solve for b..? Sorry... Please help me understand better... Would b_n = $$b_{n} = \frac{1}{2}[\ln(a_{n-2})-\ln(a_{n-1})]$$ ? Then still, how to solve that...","['logarithms', 'discrete-mathematics', 'recurrence-relations']"
1050561,How many $2$'s are needed?,There is a positive integer $N$. $N$ is made up of only two distinct digits- $2$ and $3$. $N+18$ is divisible by $37$. What is the minunum amount of times the number $2$ can appear in $N$? I'm pretty sure the answer is only one time. But how can I prove this?,"['elementary-number-theory', 'contest-math', 'discrete-mathematics']"
1050633,What do zero eigenvalues mean?,"What is the geometric meaning of a 3x3 matrix having all three eigenvalues as zero? I have interpretations in mind for 0, 1, and 2 eigenvalues being zero, but what about all of them?","['linear-algebra', 'eigenvalues-eigenvectors']"
1050639,Discrete Math Probability and Random Variable review question,"I can't solve this question on my review. If anyone can give me some help to start it, it would be appreciated! Consider an experiment that is successful with probability 0.8. We repeat
this experiment (independently) until it is successful for the first time. The first 5 times we
do the experiment, we have to pay 10 dollars per experiment. After this, we have to pay 5 dollars per
1 experiment. Define the random variable X to be the total amount of money that we have
to pay during all experiments. Determine the expected value E(X). EDIT: Do it use E(X) = 1/p so 1/0.8* 10 = 12.5 the answer is 12.5$?","['discrete-mathematics', 'probability', 'random-variables']"
1050659,How does this derivative notation work?,"Elasticity of substitution = $\dfrac{\mathrm d \ln(k/l)\;\;\;}{\mathrm d \ln(f_l/f_k)}$ This is type of notation I haven't really worked with before. Is this read as ""The change in the natural log of k over l with respect to the change in the natural log of the partial derivative of f with respect to l over the partial derivative of f with respect to k""? The production function I am working with specifically is $f(k, l) = k^{1/3}l^{2/3}$ and I know it should equal 1 (via another elasticity of substitution equation). But what and how does this equation I posted work? Thanks :)","['economics', 'calculus', 'derivatives']"
1050690,affine and projective line are homeomorphic,"Reading this post here Problem in proving that $\mathbb{A}^2$ is not homeomorphic to $\mathbb{P}^2$ I came up with the following question: Why are the $\mathbb A^1$ and $\mathbb P ^1 $ homeomorphic? (with the Zariski topology endowed, and algebraically closed underlying field) Sorry, if this is something very easy, but I can't understand it. Any help would be really appreciated!","['algebraic-geometry', 'projective-geometry']"
1050694,Closed orbits of vector fields under perturbation,"Consider a vector field $V$ on an annulus $U$, say. Also, assume that the vector field $V$ has a closed orbit. I am looking for a reference that gives stability results of the following type: If the vector field $V$ satisfies properties (collectively called) A, then under small perturbations of type (collectively called) B of the vector field, the perturbed vector field would still have a closed orbit which is ""close"" in sense C to the original closed orbit. The best situation would be to find a body of results for different A, B and C. My background in dynamical systems is very rudimentary, and the prospect of reading 5 volumes to work a solution out for myself is daunting. Any help would be highly appreciated. Edit (after Robert Israel's answer): The situation I am looking at does not necessarily have a closed orbit, and now I have checked that the vector fields can indeed be tangent to the boundaries. I was wondering what we can say in such situations (I don't necessarily need existence of a closed orbit. I am more interested in the stability of such an orbit in case it exists). Also, please include a reference if you can, I really need to read the theory up myself.","['dynamical-systems', 'ordinary-differential-equations', 'reference-request']"
1050697,"If $f: A\rightarrow B$ and $g: B\rightarrow C$ are surjective, then $g\circ f$ is surjective.","In my homework, I wrote: Assume $f$ and $g$ are surjective. Let $m$ be an element of $C$ . Then there exists a $b$ that's an element of $B$ , such that $g(b) = m$ and an $a$ that's an element of $A$ such that $f(a) = b$ by definition. Thus, $g \circ f = g(f(a)) = g(b)$ so $g \circ f$ is surjective. I was marked down to 75%. The notes were ""WHY?"" twice for the statements ""there exists a $b$ that's an element of $B$ , such that $g(b) = m$ "" and ""an $a$ that's an element of $A$ such that $f(a) = b$ "". and then when I say ""by definition"", he asked ""Defn of what??"" How can I correct this proof? I assumed that by definition of subjectivity, it was obvious, but I guess I was wrong?","['function-and-relation-composition', 'proof-writing', 'functions', 'solution-verification']"
1050700,estimation of $\pi$ and $e$ by using the Taylor series of $\cos x$,"how can one show, that $3<\pi<3.2$, 
$2.7<e<3$ by just knowing, the estimation of $\cos(x)$, namely: $$1-x^2/2+x^4/24-x^6/720\le\cos(x)$$  ? If I substitute Pi/2 into this estimation, I just have an expression with a lot of Pies..?
Do I have to use the Euler's formula for the second exercise?
Thank you","['trigonometry', 'taylor-expansion']"
1050709,Why is it that $f(x)$ is even if $f(-x) = f(x)$?,"I found this definition in this PDF file on page 17: http://math.byu.edu/home/sites/default/files/u107/proofs_crash_course.pdf I couldn't quite grasp it. I tried substituting x for a value in both f(x) and f(-x) but the result wasn't equal. So then, how was this proven? Is it correct? Please understand that I'm requesting an explanation of the definition : f(x) is even if f(-x) = f(x). I'm not asking for an answer to the question asked in the PDF reference.",['functions']
1050711,"If $x$, $y$, $z$ are in arithmetic progression, show that $\frac{\sin x + \sin y + \sin z }{\cos x + \cos y + \cos z} = \tan y. $","Show that if $x, y,$ and $z$ are consecutive terms of an arithmetic sequence, and $\tan y$ is defined, then 
$$\frac{\sin x + \sin y + \sin z }{\cos x + \cos y + \cos z} = \tan y.
$$ I'm not sure what trig identities I would use and how to use them.  Could I get some help?  Thanks.",['trigonometry']
1050730,Cardinality with a Bijection,"Suppose that $a, b \in \mathbb{R}: a<b$.  Show that $(a, b) ≈ℝ$ by finding a bijection between the sets. I think this might work but am not certain: $g(x) = \frac{2x-b-a}{b-a}$ I was also told to give a formula for my function. Any help is appreciated.","['discrete-mathematics', 'proof-writing']"
1050736,Proof involving chords of a circle,"In a circumference with center $O$, three chords $\overline{AB},\overline{AD}$ and $\overline{CB}$ such that the last two intersect in $E$. Show that $AE·AD+BE·BC=AB^2 $. Added : $O\in\overline{AB}$. Hi, I have been trying to solve this problem with the power of a point with respect to a circumference and with pythagoras, but it seems that I'm going nowhere: $2(AB)^2=AD^2+BD^2+BC^2+AC^2$ I hope you could give me a hint. Thanks Edit: Taking into account what Blue mentioned:","['geometry', 'euclidean-geometry']"
1050770,How to solve system of stochastic differential equations?,"I have the following two SDEs $$dN_1=(2a-1)pN_1dt+\alpha_1 N_1dW_1$$ $$dN_2=(2pN_1-\mu N_2)dt+\alpha_2 N_2dW_2$$ where $W$ is the standard Brownian motion/Wiener process. This isn't homework, I'm just curious. I can solve the first one but the second one is in terms of $N_1$ and $N_2$ so I don't know how to go about it. I'm new to SDEs so any help is appreciated! $$N_1(t)=N_1(0)exp\left\{((2a-1)p-\frac{1}{2}\alpha_1^2)t+\alpha_1 W_1\right\}$$","['stochastic-processes', 'ordinary-differential-equations', 'stochastic-differential-equations']"
1050796,Why are period integrals naïve periods?,"Apologies for the long question. I recall the definition of a (naïve) period according to Kontsevitch and Zagier [KS] : A (naïve) period is a complex number whose real and imaginary parts are absolutely convergent integrals of rational functions with rational coefficients on domains of $\mathbb R^d$ bounded by polynomial inequalities with rational coefficients. For example, $$\pi = \iint_{x^2+y^2 \leq 1} dx dy$$ is a period, whereas $e$ is conjecturally not a period. As [KS] point out, the following definition is equivalent: A period is a complex number which is an absolutely convergent integral of an algebraic function defined over $\mathbb Q$, on a domains of $\mathbb R^d$ bounded by polynomial inequalities with real algebraic coefficients. To illustrate, remark that for $\lambda>1 \in \mathbb Q$, $$2\int_0^1 \frac{dx}{\sqrt{x(x-1)(x-\lambda)}}$$ is a period according to the second definition, but not obviously to the first one. But it can be rewritten as $$\iint_{0 \leq x \leq 1, y^2 \leq x(x-1)(x-\lambda)} dx dy,$$ and so it is a period also according to the first definition. Kontsevitch and Zagier point out that the periods of algebraic varieties in the classical sense are naïve periods. Let $X/\mathbb Q$ be a smooth projective variety over $\mathbb Q$ of dimension $d$, and $\omega \in H^0(X, \Omega^d_{X/\mathbb Q})$ a global algebraic differential form of top degree on $X$. Being of top degree, the form $\omega$ is automatically closed, and gives rise to a de Rham cohomology class $[\omega] \in H^d_{dR}(X/\mathbb C)$ in the middle cohomology of the variety $X(\mathbb C)$, which has real dimension $2d$. Now let $D$ be a divisor on $X$ with normal crossings, and let $[\sigma] \in H_d(X(\mathbb C), D(\mathbb C), \mathbb Q)$ be a homology class relative to $D$, represented by a $d$-chain whose boundary lies on $D$. Then the integral $$\int_\sigma \omega|_{\sigma}$$ depends only on the relative homology class of $\sigma$ and on the cohomology class of $\omega$. Claim : the integral $\int_\sigma \omega|_{\sigma}$ is a period. Kontsevitch and Zagier seem to treat this as an obvious fact. It seems to me like a fairly difficult theorem. Am I overlooking a simple proof? To illustrate, let $X$ is the elliptic curve $y^2z=x(x-z)(x-\lambda z)$,  $\omega = dx/y$ is the invariant differential on $X$, and $D$ is the empty divisor,  then the periods of $\omega$ in this sense are precisely the linear combinations of the classical period integrals $$2\int_0^1 \frac{dx}{\sqrt{x(x-1)(x-\lambda)}}, 2\int_\lambda^\infty \frac{dx}{\sqrt{x(x-1)(x-\lambda)}},$$ which shows that the statement is true as both of these integrals are naïve periods. In order to get these integral formulas, we treat $X$ as a degree $2$ ramified covering of $\mathbb P^1$ via $(x,y) \mapsto x$; then $y$ becomes a multi-valued function on $\mathbb A^1$ with branch points at $\lambda = 0,1,\lambda, \infty$. The first homology of $X(\mathbb C)$ is generated by two cycles whose image in $\mathbb P^1(\mathbb C)$ circle the branch cuts $[0,1]$ and $[\lambda, \infty] \subseteq \mathbb P^1(\mathbb R)$ clockwise.  Thus it suffices to see that the integrals of $\omega$ along these cycles are periods. Consider a $1$-cycle $\sigma$ which circles the branch cut $[0,1]$ clockwise on the branch of $y$ which is positive for real $x$ large enough. This cycle is homologous to the cycle which goes from $0$ to $1$ along the positive branch of $y$, then goes back to $1$ along the negative branch. Thus $$\int_\sigma \omega = \int_0^1 \frac{dx}{\sqrt{x(x-1)(x-\lambda)}} - \int_0^1 \frac{dx}{-\sqrt{x(x-1)(x-\lambda)}} = 2 \int_0^1 \frac{dx}{\sqrt{x(x-1)(x-\lambda)}}.$$ Very good. But what about a variety of dimension $d>1$? I am happy with supposing that the divisor $D$ is empty, so that $[\sigma]$ is the homology class of a $d$-cycle. Here is how I thought one might prove that the integral $\int_\sigma \omega$ is a period. Let $U$ be an affine open subvariety of $X$ such that $U(\mathbb C)$ contains the image of the $d$-cycle $\sigma$. By the Noether normalization lemma, there is a finite map $U \to \mathbb A^d$, and an open $V\subseteq \mathbb A^d$ such that the restriction $U' \to V$ is finite étale of some degree $n$. Let us suppose still that $U'(\mathbb C)$ contains the image of $\sigma$.  Locally in the complex topology of $V(\mathbb C)$, the morphism $U' \to V$ has $n$ sections along which we can pull back the differential $\omega$, to get a multivalued differential $\omega$ on $V$. Let  $\sigma'$ denote the $d$-cycle on $V(\mathbb C)$ obtained by composing $\sigma$ with $U'(\mathbb C) \to V(\mathbb C)$; the integral $$\int_{\sigma'}\omega$$ has $n$ possible values, depending on the branch of $\omega$ which is chosen (and then analytically continued along $\sigma'$). It should therefore be proven that the integrals $\int_{\sigma'} \omega$ are periods. The problem is that the cycle $\sigma$ is only differentiable. For instance, in the example above, if we re-parametrize the integral $$\int_0^1 \frac{dx}{\sqrt{x(x-1)(x-\lambda)}}$$ by a diffeomorphism $t \mapsto x(t)$ of the interval, preserving the boundary, then we get $$\int_0^1 \frac{x'(t) dt }{\sqrt{x(t)(x(t)-1)(x(t)-\lambda)}}$$ which is not recognizable as a period anymore. Hence, it appears crucial that the homology class of a path $\sigma$ circling the branch cut $[0,1]$ can be represented also by a path which is piecewise-linear , namely the path which goes from $0$ to $1$ in constant time on the top sheet and goes back to $0$ in constant time on the bottom sheet. It appears to me that the statement that $\int_{\sigma'} \omega$ is a period depends on the fact that any $d$-cycle $\sigma$ on $V(\mathbb C) \subseteq \mathbb A^d(\mathbb C)$ is homologous to one which is piecewise-linear, or even piecewise-polynomial, with algebraic coefficients. It seems to me that this is true, although it is probably a fairly difficult theorem of algebraic topology. Is my way of approaching this problem correct, or am I overlooking something much simpler? Thank you for reading, and for your ideas.","['definite-integrals', 'arithmetic-geometry', 'algebraic-geometry', 'homology-cohomology']"
1050799,Infinite products of non-measurable sets,"I just proved for a homework problem that the direct product of two non-measurable sets is non-measurable. It seems to me that the finite direct product of finitely many non-measurable sets is also definitely non-measurable. But what about infinite products? I would imagine that uncountably infinitely many non-measurable sets might potentially be measurable, since uncountable products tend to do strange things. Does anyone know the conditions for when products of non-measurable sets is non-measurable? Could you point me to a proof?","['measure-theory', 'lebesgue-measure', 'real-analysis']"
1050809,"If $F$ is injective, and so is $F \circ G$, does $G$ have to be?","If $F$ is an injective (one-to-one) function, and the composite of the two $(F \circ G)$ is injective, is it possible for $G$ to not be injective?",['functions']
1050814,Prove that $1 + 4 + 7 + · · · + 3n − 2 = \frac {n(3n − 1)}{2}$,"Prove that
$$1 + 4 + 7 + · · · + 3n − 2 =
\frac{n(3n − 1)}
2$$ for all positive integers $n$. Proof: $$1+4+7+\ldots +3(k+1)-2= \frac{(k + 1)[3(k+1)+1]}2$$ $$\frac{(k + 1)[3(k+1)+1]}2 + 3(k+1)-2$$ Along my proof I am stuck at the above section where it would be shown that: $\dfrac{(k + 1)[3(k+1)+1]}2 + 3(k+1)-2$   is equivalent to $\dfrac{(k + 1)[3(k+1)+1]}2$ Any assistance would be appreciated.","['induction', 'summation', 'discrete-mathematics', 'arithmetic-progressions']"
1050853,Differentiability/continuity of piecewise defined functions,"Let $$f(x)=\begin{cases}x^2\sin(\frac{1}{x}), &x\not= 0,\\ 0, &x = 0.\end{cases}$$ Since I can differentiate both parts of this, technically, $f$ is differentiable for all $x$. However I have written down in my notes that $f'(x)$ is not even continuous at $0$ and thus not differentiable. However, I am confused about this because isn't my original function not continuous?","['calculus', 'continuity', 'derivatives']"
1050880,Are subspaces of paracompact spaces normal?,"Are all subspaces of a paracompact space normal? This is what I think about this question...
First a paracompact Hausdorff space turns out to be Normal, second the paracompact property  is not hereditary, meaning any subspace need to be closed+Hausdorff to be normal. So I think the answer is no, but I have to find a counter-example. Am I right about this and what counter-example do we have?","['general-topology', 'separation-axioms', 'examples-counterexamples', 'paracompactness']"
1050884,$L^2$ limit of Gaussian random variables,"Let $X_n$ be a sequence of Gaussian random variables defined on the same probability space. The statement is that if $X_n$ converges to some random variable $X$ in $L^2$-sense, then $X$ is also Gaussian. I think it is possible to do with Characteristic functions; but I am curious what is the simplest way to see it.","['normal-distribution', 'convergence-divergence', 'probability']"
1050888,"There is no homeomorphic copy of $[0,1]$ in the plane which contains an open ball","Problem: Let $A \subseteq \mathbb{R} \times \mathbb{R}$ be homeomorphic to the interval $[0,1]$.  Then $A$ contains no nonempty open set of $\mathbb{R} \times \mathbb{R}$. What I've got so far: if it does, then it contains an open ball, say $O$.  Since $[0,1]$ is compact and path connected, so is $A$, and in particular $A$ is closed.  Thus $\overline{O} \subseteq \overline{A} = A$, meaning $A \setminus O$ contains the boundary of $O$. I think that $A \setminus O$ should be path connected; if $x, y \in A \setminus O$, we already know there is a path $\tau$ in $A$ which goes from $x$ to $y$.  If this path doesn't go through $O$, no problem; if it does, by compactness (somehow) we should be able to find an interval $(c,d) \subseteq [0,1]$ for which $\tau(c), \tau(d) \in \overline{O}$ and $\tau(t) \in O$ only for values of $t \in (c,d)$.  On $(c,d)$ we can then reroute $\tau$ to go along the boundary of $O$. If $f: A \rightarrow [0,1]$ is a homeomorphism, the fact that $A \setminus O$ is path connected means that $[0,1] \setminus f(O)$ should also be path connected. $f(O)$ is open in $[0,1]$, so it would be nice if I could assume that $f(O)$ contained some interval $(a,b)$ for $0 < a < b$, so then $[0,1] \setminus f(O)$ wouldn't be path connected, a contradiction.  But how do I know that $f(O)$ isn't an open set of the form $[0,b)$ for $b < 1$ (so that $[0,1] \setminus f(O)$ is still path connected)?",['general-topology']
1050895,Prove spatial velocity identity - screw theory,"This question involves a proof regarding coordinate transformations of velocities of screw motions. This comes from ""A Mathematical Introduction to Robotic Manipulation"" (the text is available for free here: http://www.cds.caltech.edu/~murray/books/MLS/pdf/mls94-complete.pdf ) The identity is shown below, and is on pg. 59 of the above link. Here's the image: I know how to get $V_{a,c}^c$ (with respect to frame c). That comes directly from the chain rule, switching the order of $\dot{g}$ and $g^{-1}$. But I don't know how to get $V_{a,c}^b$ (with respect to frame b), i.e. the left-hand side. Any help much appreciated.","['linear-algebra', 'transformation', 'proof-writing']"
1050897,integral of positive definite matrix is positive definite?,"Say $A_{t}$ is a positive definite matrix for all t, do we have that $\int_{0}^{1}A_{t}dt$ is a positive definite matrix. Is there an obvious counterexample? The arguement in the book was that the weighted average of positive definite matrices is also positive definite. http://books.google.ca/books?id=k4ODAwAAQBAJ&pg=PA38&lpg=PA38&dq=maximum+principle+minimal+surfaces+interior&source=bl&ots=D8AGQK9QXi&sig=vWX5-I_c2QyAKsT7CQKGXuTEECQ&hl=en&sa=X&ei=28J_VITVLIS2yASt7YCoBw&ved=0CEQQ6AEwBg#v=onepage&q=maximum%20principle%20minimal%20surfaces%20interior&f=false page 37 A condition for a matrix to be positive definite is $det(A)\geq0$ and  $Tr(A)\geq 0$. So since we have a Riemann sum, we should have $Tr(\int_{0}^{1}A_{t}dt)=lim_{n\to \infty}\sum_{i}^{n}Tr(A_{t_{i}})(t_{i}-t_{i-1})>0$. However determinants don't decompose into sums. Thank you","['matrices', 'matrix-calculus', 'linear-algebra']"
1050904,"Show that $\int_{a}^{c}f(x)dx = 0$ for all $c\in [a,b]$ if and only if $f(x) = 0$ for all $x\in [a,b]$.","Exercise: Suppose that $a<b$ and that $f:[a,b]\rightarrow R$   is continuous. Show that $\int_{a}^{c}f(x)dx = 0$ for all $c\in [a,b]$ if and only if $f(x) = 0$ for all $x\in [a,b]$. attempt of proof: Suppose  that $a<b$ and that $f:[a,b]\rightarrow R$   is continuous. 
Let $m$ and $M$ be the infimum and supremum of f. Since $f(x) = 0 $ for all $x\in [a,b]$ $m = 0$ since  $f(x) = 0$. Thus, for all any partition $P$ of $[a,b]$, $L(f,P) = m(b-a) = 0$ implies $L(f,P) = 0$. Hence,  $(L)\int_{a}^{c}f(x)dx$ = $sup{L(f,P)}$ = $0$. In a similar way we can working with the supremum. Thus, if both the lower integral of f and the upper integral of f have the same value , we can conclude then the value of the $\int_{a}^{c}f(x)dx = 0$ for all $c\in [a,b]$ The converse is trivial, since $\forall c\in [a,b]$ $f(c) = 0$ since $f(x)=0$ , so $\int_{a}^{c}f(x)dx = 0$ Can someone please help me? I don't know if this is a way to prove it. Any feedback/hint or better way would be really appreciated.Thank you in advance.","['riemann-sum', 'proof-verification', 'integration', 'real-analysis']"
1050906,Construct a sequence of continuous functions which converges pointwise to $\lfloor x \rfloor$,"Suppose $f(x)=\lfloor x \rfloor$ for $x \geq 0$. Define a sequence of functions $(f_n(x))_{n \geq 1}$ where $f_n(x) = \left\{
     \begin{array}{lr}
       x^n & : x \in [0,1)\\
       (x-1)^n+1 & : x \in [1,2)\\
       (x-2)^n+2 & : x \in [2,3)\\
       \vdots \\
    \end{array}
   \right.$ Questions: $1)$ Is $f_n(x)$ continuous for all $x \geq 0$? $2)$ Does the function $f_n(x)$ converge pointwise to $\lfloor x \rfloor$? If yes to both questions above, can we write $f_n(x)$ in a single function instead of piece-wise function? My guess: Yes to both questions. But I am unable to express $f_n(x)$ in a single function.","['sequences-and-series', 'functions', 'continuity', 'real-analysis', 'ceiling-and-floor-functions']"
1050914,Transforming a PDE given basis vectors,"I have a non-orthogonal coordinate system defined by $\mathbf x=\mathbf x(r,\beta,z)$, and so I can find the basis vectors as
$$ \mathbf g_r=\frac{\partial \mathbf x}{\partial r},\quad\mathbf g_\beta=\frac{\partial \mathbf x}{\partial \beta},\quad \mathbf g_z=\frac{\partial \mathbf x}{\partial z},$$
where $\mathbf g_r$, $\mathbf g_\beta$, and $\mathbf g_z$ are functions of $r$ and $\beta$. In this coordinate system I have written a system of PDEs, for example
$$\frac{\partial v}{\partial r}+\rho(r)\frac{\partial v}{\partial z}=0 $$
for some arbitrary known function $\rho(r)$. Now I want to replace the $\mathbf g_z$ coordinate direction with a new one, defined as $\mathbf g_n=\mathbf g_r\times\mathbf g_\beta$. I can write $\mathbf g_n=f(r)\mathbf g_r+g(r)\mathbf g_\beta+h(r)\mathbf g_z$, or $\mathbf g_z=\tilde f(r)\mathbf g_r+\tilde g(r)\mathbf g_\beta+\tilde h(r)\mathbf g_n$. This is where I'm unsure what to do next. Considering the equation for $\mathbf g_z$ in terms of the other directions, I've considered doing the following:
$$\begin{align} \frac{\partial}{\partial z}&=\frac{\partial}{\partial r}\frac{\partial r}{\partial z}+\frac{\partial}{\partial \beta}\frac{\partial\beta}{\partial z}+\frac{\partial}{\partial n}\frac{\partial n}{\partial z} \\
&=\tilde f(r)\frac{\partial}{\partial r}+\tilde g(r)\frac{\partial}{\partial \beta}+\tilde h(r)\frac{\partial}{\partial n} \end{align}$$
however this feels wrong. I think I need to use equations for $r$, $\beta$, and $n$ in terms of $r$, $\beta$, and $z$ then do the chain rule for the derivatives. Given coordinate directions, $\mathbf g_r$, $\mathbf g_\beta$, and $\mathbf g_n$, how can I find these equations for the transformations of the variables in the PDE?","['coordinate-systems', 'ordinary-differential-equations', 'partial-differential-equations']"
1050930,Composition of Inverse Functions,"$f$ and $g$ are inverses of each other when $f(g(x)) = x = g(f(x))$. However, can there be 2 functions where $f(g(x)) = x$ but $g(f(x))$ does not equal to $x$? I feel like there are but I cannot find it. Could you please post examples of this?","['soft-question', 'functions', 'function-and-relation-composition']"
1050941,What is the result of truncating Platonic solids?,"Let $P$ denote a Platonic solid. Truncating $P$ at a vertex $v$ consists of marking the midpoints of the edges that touch $v$ and then slicing off a corner of $P$ by the plane that passes through all those points. For each Platonic solid $P$, determine the the polyhedron that results from truncating $P$ simultaneously at each of its vertices. Now, I had a little difficulty imagining the shapes and their truncations, but this is what I came up with. If we truncate at the midpoint of each edge for all vertices of each Platonic solid, we get its dual polyhedron. So, for the tetrahedron, truncating it in this manner results in another tetrahedron. When you truncate the cube and the octahedron, you get the other Platonic solid. Finally, the same goes for the icosahedron and dodecahedron. Since I am having difficulty envisioning the actual results, I was wondering if you guys could help me out. Also, is there a program I can use to manually do this operation? Thanks!","['geometry', 'platonic-solids']"
1050944,Can a set have subsets of different lengths,"Can a set $S$ be defined as such $S = \lbrace(x_0), (x_1, y_1),(x_2, y_2,z_2),...\rbrace$? Or should every element be of equal length?",['elementary-set-theory']
1050949,Question regarding Radon-Nikodym derivative...,"The problems are as follows: (1) Let $X=[0,1]$ with Lebesuge measure and consider probability measures $\nu,\mu$ given by densities $f,g$ as follows:
  $$\nu(E)=\int_{E} f\;dm\;\;and\;\;\mu(E)=\int_{E}g\;dm$$
  $\forall E \subset [0,1]$ s.t $E$ measurable. Suppose $f(x),g(x)>0$ $\forall x\in [0,1]$. Is $\nu$ absolutely continuos w.rt to $\mu$? If it is, determine the Radon-Nikodym derivative $\frac{d\nu}{d\mu}$. Is $\mu$ absolutely continuos w.r.t to $\nu$? (2) For a point $x$, define the Dirac measure $\delta_x$ to be
  $$\delta_x=\chi_{A}$$
  where $\chi_{A}$ is the indicator function over set A. For a fixed set $B$, define the Lebesgue measure restricted to $B$ by $m_B(A)=m(A \cap B)$. Let $\mu=\delta_1 + m_{[2,4]}$ and $\nu=\delta_0+m_{(1,2)}$. Show that $\nu$ is singular to $\mu$. So, here's what I've done: 1) Since $f(x),g(x)>0$ $\forall x \in [0,1]$, it follows that
  $$\nu(E),\mu(E)>0 \iff m(E)>0$$
  and
  $$\nu(E),\mu(E)=0 \iff m(E)=0$$
  $$\implies \nu(E) << \mu(E)\;\;\;,\;\;\; \mu(E) << \nu(E)$$ We wish to find $\frac{d\nu}{d\mu}$. Having $f=\frac{d\nu}{dm}$ and $g=\frac{d\mu}{dm}$, and then dividing $f$ by $g$, we obtain
  $$\frac{\frac{d\nu}{dm}}{\frac{d\mu}{dm}}=\frac{f}{g}$$
  $$\implies \frac{d\nu}{d\mu}=\frac{f(x)}{g(x)}$$
  $\square$ (2) Have
  $$\mu=\delta_1 + m_{[2,4]}\;\;,\;\;\nu=\delta_0+m_{(1,2)}$$
  $$\implies \mu(A)=\delta_1(A)+m_{[2,4]}(A)=\delta_1(A) + m(A\cap [2,4])$$
  $$\nu(A)=\delta_0(A)+m_{(1,2)}(A)=\delta_0(A)+m(A\cap(1,2))$$
  Notice that at each delta, we're dealing with a single point. In particular, the singletons $\{1\}=[1,1]$ and $\{0\}=[0,0]$. Thus,
  $$\mu(A)=\delta_1(A) + m(A\cap [2,4])=\mu(A\cap([1,1]\cup [2,4]))$$
  $$\nu(A)=\delta_0(A)+m(A\cap(1,2))=\nu(A\cap([0,0]\cup (1,2)))$$
  Since $(A\cap([1,1]\cup [2,4])\cap(A\cap([0,0]\cup (1,2)))=\emptyset$, it follows that $\mu$ and $\nu$ are singular to one another. $\square$ Did I pull some nonsense? Radon and I have not been getting along so well, so I've had trouble properly wrapping my head around these findings. If I've gone down the wrong path, how I would I go about solving these problems?","['measure-theory', 'lebesgue-measure', 'proof-verification', 'real-analysis']"
1050964,$\mathbb {R}^{\omega}$ in the box topology is not first countable.,"I'm trying to show that $\mathbb {R}^{\omega}$ in the box topology is not first countable. But I cannot come up with a contradiction by assuming that for each $x \in \mathbb {R}^{\omega}$, there is a countable basis. My intuition is that I need to use the fact that a countable product of countable sets is uncountable, so I need to show that for any local basis, I can come up with a basis consisting of the product of countable open intervals in each coordinate. Can anyone help me through?",['general-topology']
1051002,How do I find out if a polynomial is irreducible?,I have this polynomial: $f(x)=x^4+x^3-4x^2-5x-5$ . How can I find out if this polynomial is irreducible over the field $\mathbb{Q}$ of rational numbers? I know about mod $p$ irreducibility test but it fails in this case. In general how do you find out if a polynomial is irreducible or prove that it is reducible?,"['irreducible-polynomials', 'abstract-algebra', 'polynomials']"
1051006,Path connected but not metrizable,"What are the examples of path connected spaces which are not metric spaces. The only examples I know are sets with indiscrete topology?
Are there such spaces which are not simply connected (the indiscrete space is simply connected)?","['general-topology', 'algebraic-topology']"
1051007,Symmetries of Weyl Tensor,"We know that the Riemannian curvature $(0,4)-$tensor may be decomposed as
$$Rm=W\;+\;A *g$$
where $*$ is the Kulkarni-Nomizu product, and $A$ the Schouten tensor. I am studying the proof of a theorem which uses that $W_{1212}+W_{1313}+W_{1414}=0.$ Why is this true? Can you please help me with this?","['geometry', 'riemannian-geometry', 'differential-geometry']"
1051032,Projection matrices identity: $P_{M_ZX}=P_{M_Zx}+P_{M_{[x\; Z]}X_2}$,"For any real matrix $Y$ with $n$ rows and full column rank, we define the orthogonal projection matrices
$$
\underbrace{P_Y}_{n\times n}=Y(Y'Y)^{-1}Y',\quad \underbrace{M_Y}_{n\times n}=I_n-P_Y.
$$
Among many other properties, $P_Y$ fixes the column space of $Y$ whereas $M_Y$ sends each vector in that space to $0$. A paper (reference available if you are interested) I'm reading cites the following identity
  $$
P_{M_ZX}=P_{M_Zx}+P_{M_{[x\; Z]}X_2}.\tag{$\star$}
$$
  (The subscript of the first term on the RHS is $M_Z\cdot x$.) The dimensions of various things are
  $$
Z:n\times l;\quad x:n\times1;\quad X_2:n\times k;\quad X=[x\; X_2]:n\times(1+k).
$$ I've spent some time trying to prove ($\star$) suspecting it is probably clever algebraic manipulation but I can't figure it out. A better approach probably involves looking at the RHS of ($\star$) and recognize some relationship between $M_Zx$ and $M_{[x\;Z]}X_2$. I don't have enough knowledge at the moment for this latter approach but I'm interested in learning more about projection matrices. This book will probably aid me but I don't have a copy yet. Can someone help please? Thank you very much.","['matrices', 'linear-algebra']"
1051034,Is the symmetric definition of the derivative equivalent?,"Is the symmetric definition of the derivative (below) equivalent to the usual one? \begin{equation}
\lim_{h\to0}\frac{f(x+h)-f(x-h)}{2h}
\end{equation} I've seen it used before in my computational physics class. I assumed it was equivalent but it seems like it wouldn't matter if there were a hole at $x=h$ in the symmetric derivative, whereas with the usual one it wouldn't be defined. Which is kinda interesting... If they're not equivalent - is there a good reason as to why we should use the common one? Or is the symmetric one actually more useful in some sense because it ""doesn't care"" about holes?","['calculus', 'derivatives', 'real-analysis', 'definition']"
1051048,Counting the number of rotations of a cube.,"Take a cube $C$ $[-1,1]^3\subset\Bbb{R^3}$. How many rotations are there which take $C$ to itself? What does this question even mean? If you take any line in $\Bbb{R^3}$, and rotate the cube around it by $2\pi$ rad, you are mapping the cube to itself! Ans: 24. I don't understand.",['algebra-precalculus']
1051055,Indefinite integral of absolute value,"When I looked up about absolute value on Wikipedia, I found that the antiderivative of $|x|$ is $\frac12 x|x|+C$. I am able to find the derivative of $|x|$ by treating the function as $\sqrt{x^2}$, but I am not able to integrate it. When I put $\int_{-4}^{-1}|x|\,dx$ into Symbolab, the online calculator did not break the integral into piecewise function but calculate the indefinite integral first before using $F(b) - F(a)$. When I view the steps it used, it said: If $\int f(x)\,dx = F(x)$
then $$\int \sqrt{(f(x))^2)}\,dx = \frac{\sqrt{f(x)^2}}{f(x)}$$ multiplied to $F(x)$
which becomes $\frac{\sqrt{x^2}}{x}$ multiplied to $\int x\,dx$","['definite-integrals', 'integration', 'indefinite-integrals', 'math-software']"
1051056,Amann & Escher Integral vs. Lebesgue Integral,"In the textbook the authors define the integral via cauchy sequences of simple functions:
$$S_n\to F:\quad\int F\mathrm{d}\mu:=\lim_n\int S_n\mathrm{d}\mu\quad\left(\int\|S_m-S_n\|\mathrm{d}\mu\to0\right)$$
Now, how come that this is really the usual Lebesgue integral for positive functions:
$$f\geq0:\quad\int f\mathrm{d}\mu:=\lim_n\int s_n\mathrm{d}\mu=\sup_{s\leq f}\int s\mathrm{d}\mu$$ (I tried wiggling around with monotone and dominated convergence but couldn't get ahead.)","['integration', 'definition', 'measure-theory', 'real-analysis', 'lebesgue-integral']"
1051097,Resource for learning about the Laplacian on Riemannian manifolds,"Does anyone have any recommendations for, as the title suggests, a book from which to learn about the Laplacian on Riemanian manifolds, or even just on smooth manifolds? I found this presentation , which deals with it in cursorily and without proofs - in the style of a presentation - and at a deeper-than-introductory level. I do not know much about the Laplacian at all (I'm familiar with smooth manifold theory and Riemannian geometry through Lee's and do Carmo's books, respectively, but none of Lee's books cover the Laplacian and neither does do Carmo's). My main goal is to learn about the isospectral problem, that is, ""Can one hear the shape of a drum?""","['laplacian', 'riemannian-geometry', 'differential-geometry']"
1051108,Largest and smallest shape enclosed within circles,"There is a convex shape $C$. It is known that the largest disc contained in $C$ has radius $r$ and the smallest disc containing $C$ has radius $R$. What are the smallest-area and largest-area shapes that fit this description? My current conjecture is based on the following diagram: For the largest-area shape, I tried to build the widest shape that is still not wider than the enclosed disc. This is the shape QTUS (where again the lines QT and US are curved). In this case, the measured area is slightly less than $4rR$, and it seems to converge to $4rR$ when $R\gg r$. This makes sense because QTUS converges to a rectangle whose side-lengths are the diameters of the two discs ($2r\cdot 2R$). For the smallest-area shape, I tried to build the most ""economic"" shape that still contains a full diameter of the enclosing disc. This is the shpae CGJDIH (where the lines GJ and IH are curved around the disc). The area of this shape changes when the enclosed disc moves along the diameter; the minimal area seems to be when the two discs have the same center. In this case, the empirically-measured area is slightly more than $2rR$, and it seems to converge to $2rR$ when $R\gg r$. This makes ssense because CGJDIH converges to a union of two triangles and the area is 1/2 the area of QTUS. MY QUESTION IS: are these indeed the smallest and largest possible convex shapes?","['geometry', 'convex-analysis', 'packing-problem']"
1051134,"Evaluating $\int_0^1\frac{x^{-a}-x^{a}}{1-x}\,\mathrm dx$","How to evaluate following integral $$\int_0^1\frac{x^{-a}-x^{a}}{1-x}\,\mathrm dx$$ I tried the feynman way $$\begin{align} 
I'(a)&=\int_0^1\frac{-x^{-a}\ln x-x^{a}\ln x}{1-x}\,\mathrm dx\\
&= \int_0^1\ln x\left(\frac{-x^{-a}-x^{a}}{1-x}\right)\,\mathrm dx\\
\end{align}$$ I don't have any idea about how to proceed! Some help is appreciated","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
1051193,Proving $\int_0^1\frac{\log 2-\log\left({1+\sqrt{1-x^2}}\right)}{x}dx=\frac{\left(\pi^2-12\log^22\right)}{24}$,"$$\int_0^1\frac{\log 2-\log\left({1+\sqrt{1-x^2}}\right)}{x}dx=\frac{\left(\pi^2-12\log^22\right)}{24}$$ At first, I think it can be calculated like the following one with differential method. $$\int_0^1\frac{x-\log\left({x+\sqrt{1-x^2}}\right)}{x}dx$$ $\\$ But, I'm wrong. I try my best to do it with differential method, but failed. Who can help me to prove it? Thank you.","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
1051211,Find an example of a sequence of random variables,"Find an example of a sequence of integrable random variables $\lbrace X_n,n\geq1 \rbrace$ that has the following properties, $E[X_{n+1}\mid X_n]=X_n$ for every $n\geq 1$ but $E[X_{n+1}\mid F_n\phantom{.}]\neq X_n$ for every $n\geq 2$, where $F_n=\sigma(X_j;1\leq j \leq n)$. How do we construct such sequence?","['probability-theory', 'probability']"
1051232,If $f$ has a zero of order m then $f'/f$ has a simple pole,"Let $f$ be analytic in $D_r(z_0)$ and has a zero of order $m$ at $z_0$. I need to show that $f'/f$ has a simple pole at $z_0$. This is part of attempt. Since f has a zero of order $m$ there exists a analytic $g$ such that $$f(z)=g(z)(z-z_0)^m,g(z_0)\neq0$$. Also for some $R_1>0$ such that $0<R_1\leq r$, $g(z)\neq 0$ in $D_{R_1}(z_0)$. Now there are possibilities. $f$ is identically zero or for some $0<R_2\leq r, $ $f(z)\neq 0$ in $D_{R_2}(z_0)$\ {$z_0$}. Assuming the latter is true let $R$=min{$R_1,R_2$}. Let $z\in D_R(z_0)$\ {$z_0$}. Then $$f'(z_0)=mg(z)(z-z_0)^{m-1}+g'(z)(z-z_0)^m \implies \frac{f'(z)}{f(z)}=\frac{m}{z-z_0}+\frac{g'(z)}{g(z)}$$. I am stuck here and don't know how to finish it off. And what about the case where f is identically zero? Any help is appreciated thanks","['complex-analysis', 'analysis']"
1051262,Is a semidirect product of linear groups a linear group?,"It is known that linear groups are not closed under extensions, but what if the extension splits, i.e. it is a semidirect product? Suppose that $K,R$ are subgroups of $\mathop{GL}(n,\mathbb{F})$ , where $\mathbb{F}$ is a field, and suppose that I have a homomorphism $\phi \colon R \to \mathop{Aut}(K)$ which defines the semidirect product $G = K \rtimes_{\phi}R$ . My question is, does $G$ embed into $\mathop{GL}(m,\mathbb{F})$ for some $m > n$ ? Or perhaps into $\mathop{GL}(m,\mathbb{F}')$ , where $\mathbb{F}'$ is some extension of $\mathbb{F}$ ?","['representation-theory', 'group-theory', 'semidirect-product']"
1051317,A difficult trigonometry problem [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How to prove that $$\left(\sin{\frac{9\pi}{70}}+\sin{\frac{29\pi}{70}}-\sin{\frac{31\pi}{70}}\right)\left(\sin{\frac{\pi}{70}}-\sin{\frac{11\pi}{70}}-\sin{\frac{19\pi}{70}}\right)=\frac{\sqrt{5}-4}{4}?$$
I don't have any idea.",['trigonometry']
1051335,Sequence of differentiable functions converging to non-differentiable function,"Purely out of interest, I wanted to try and construct a sequence of differentiable functions converging to a non-differentiable function. I began with the first non-differentiable function that sprung to my mind, namely
\begin{align}
&f:\mathbb{R}\to\mathbb{R}\\
&f(x)=|x|.
\end{align}
After some testing I considered the function defined by
$$f_\varepsilon(x) = |x|+\frac{\varepsilon}{|x|+\sqrt{\varepsilon}} $$
for some $\varepsilon>0$. Then $\lim\limits_{\varepsilon\to0^+}f_\varepsilon(x)=f(x)$, and $f_\varepsilon(x)$ looks smooth, i.e. differentiable for every $\varepsilon>0$ on the entire domain. Question: How can I prove that $f_\varepsilon$ is differentiable for every $\varepsilon>0$ (or disprove) using the definition of the derivative? If this assertion is true, then I construct the sequence simply by setting $\varepsilon = 1/n$ for $n\in\mathbb{N}$. Attempt: I set up the definition for the derivative
\begin{align}
\frac{\mathrm{d}f_\varepsilon}{\mathrm{d}x} &= \lim_{h\to 0}\frac{1}{h}\left[\left(|x+h|+\frac{\varepsilon}{|x+h|+\sqrt{\varepsilon}}\right)-\left(|x|+\frac{\varepsilon}{|x|+\sqrt{\varepsilon}}\right)\right]\\
&=\lim_{h\to 0}\frac{1}{h}\left[|x+h|-|x|+\frac{\varepsilon}{|x+h|+\sqrt{\varepsilon}}-\frac{\varepsilon}{|x|+\sqrt{\varepsilon}}\right],
\end{align}
but I could not figure out how to proceed. Sidenotes: An interesting thing I discovered when constructing $f_\varepsilon$, was that almost any small change removes its smoothness, for example
\begin{equation}
g_\varepsilon(x) = |x|+\frac{2\varepsilon}{|x|+\sqrt{\varepsilon}}\hspace{2cm} h_\varepsilon(x) = |x|+\frac{\varepsilon}{|x|+2\sqrt{\varepsilon}}
\end{equation}
do both not look smooth at all. Similarly for the other terms; changing the coefficients will remove the smoothness. I am also somewhat intrigued by this. So if anyone can shed some light on this, even better.","['sequences-and-series', 'calculus', 'derivatives']"
1051338,Maps to all finite cyclic groups factor implies map to integers factors,"Let $G$, $H$ be groups (we lose nothing here if we assume they're abelian), let $f:G\to H$ and $g:G\to \mathbb{Z}$ be homomorphisms. This last map gives us homomorphisms $g_n:G\to {\mathbb{Z}}/{n \mathbb{Z}}$ for each positive integer $n$, by composing with the usual quotient. Now suppose that for every $n$, the map $g_n$ factors through $H$ in the sense that there is some homomorphism $h_n:H\to{\mathbb{Z}}/{n \mathbb{Z}}$ with $g_n=h_n \circ f$. This clearly happens if $g$ itself factors (there's some $h:H\to\mathbb{Z}$ with $g=h\circ f$), but is the converse true? If all the $g_n$ factor, does it follow that $g$ factors?","['group-theory', 'abelian-groups']"
