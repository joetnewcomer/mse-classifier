question_id,title,body,tags
1397452,Solving a matrix differential equation,I am trying to solve: $\frac{d U_t}{dt} = Tr(G^{\dagger}U_t)G - Tr(U_t^{\dagger}G)U_t G^{\dagger} U_t$ Where $U_t \in SU(4)$ and $G \in SU(4)$ is given and constant. Is it possible to solve this equation? A solution not in coordinates would be most helpful. I've tried several series methods previously.,"['lie-groups', 'linear-algebra', 'ordinary-differential-equations', 'lie-algebras']"
1397453,"Integral $\int_0^{1/\phi}x\log(x)\log(1+x)\log(1-x)\,dx$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question How can we evaluate this definite integral
$$I=\int_0^{1/\phi}x\log(x)\log(1+x)\log(1-x)\,dx,$$
where $\displaystyle\phi=\frac{1+\sqrt5}2$ is the golden ratio?","['calculus', 'definite-integrals', 'logarithms', 'integration', 'golden-ratio']"
1397459,On pentagonal tilings,The following image has been in the news recently: My understanding is that these are all the known (to-date) tilings of the plane using convex pentagons. Can someone explain to me why the following are not in the list?,"['tiling', 'geometry']"
1397461,minimum kullback leibler estimator,"Suppose that one has independent and identically distributed samples $x_i,i=1,...,n$ from some unknown density and one wants to fit a probability distribution $f_\theta(x)$, where $\theta$ is a (finite-dimensional) parameter, e.g. $\theta \in \mathbb{R}$,  to that data. It seems that one way to estimate $\theta$ could be to minimize the Kullback-Leibler divergence between an estimate of pdf computed from data $x_i$ (using e.g. some kernel estimator) and the model $f_\theta$. I know that KL is used in many problems as a distance measure between two probability distributions (though it not actually a distance since it is not symmetric) but I don't think I have seen any theory about an estimator that it defined as a minimizer of this distance. Also there is a connection to maximum likelihood estimation since if $p(x)$ is the pdf computed from the data we have \begin{align} KL(p || q) &= \int p(x) \log\frac{p(x)}{f_\theta(x)} dx = \int p(x) \log p(x) dx - \int p(x) \log f_\theta(x) dx \\ &= H(p) - E(\log f_\theta(x)),\end{align}
where the first term (entropy of $p$) is constant and the latter term can be approximated with $\frac{1}{n}\sum_{i=1}^n \log f_\theta(x_i)$. So maximizing the last term (i.e. ML estimator) gives approximately the minimum KL divergence. So my question is that is there any general theory about such estimator and some (not overly uncommon) applications where such method is used? Or is it so that such estimator typically has not-so-nice properties or is it just overrun by other estimation methods (like maximum likelihood, (generalized) method of moments etc.) that are likely easier to apply. Also I know there is some theory about minimum Hellinger distance estimation which seems to have nice efficiency and robustness properties but I would guess that is not the case with KL then?","['statistics', 'statistical-inference', 'parameter-estimation']"
1397478,Counterexamples to Banach Fixed Point (Banach's Contraction) Theorem with relaxed inequalities?,"Banach Fixed Point theorem states: Let $(X,d)$ be a complete metric space. Suppose that $f:X→X$ is a strong contraction, i.e. there exists $q ∈ [0, 1)$ such that $d(f(x),f(y))$ $\le$ $q$ $d(x,y)$, then there is a unique point $x_0∈X$ s.t. $f(x_0)=x_0$ My questions are: 1-  If we allow $q$ to be equal to $1$, does the theorem fail? Could someone provide an example? 2- If we  substitute the strong contraction condition with the following condition:
$d(f(x),f(y))$ $<$ $d(x,y)$, does the theorem fail? example?","['real-analysis', 'banach-spaces']"
1397517,Measure spaces proof,"This theorem comes from the book Real Analysis by Folland Note: $M$ is a $\sigma$-algebra Suppose that $(X,M,\mu)$ is a measure space. Let $\mathcal{N} = \{N\in M: \mu(N) = 0\}$ and $\bar{M} = \{E\cup F: E\in M  \ \ \text{and} \ \ F\subset N \ \ \text{for some} \ \ N\in\mathcal{N}\}$. Then $\bar{M}$ is a $\sigma$-algebra, and there is a unique extention $\bar{\mu}$ of $\mu$ to a complete measure on $\bar{M}$ I believe I need to first show that since $M$ and $\mathcal{N}$ are closed under countable unions then so is $\bar{M}$, but I am not exactly sure how to show this. Then, once I have proven that $\bar{M}$ is a $\sigma$-algebra and given how they defined $\mathcal{N}$ then there must be a unique $\bar{\mu}$ that is a complete measure on $\bar{M}$. I am trying to not look at the proof in the book and do this on my own but I just need some help with the finer details, any suggestions would be greatly appreciated.","['real-analysis', 'measure-theory']"
1397520,showing an inequality not using stirling formula,"I don't know how to show that $$
\frac{k^k}{k!}\leq e^{k}
$$ without using Stirling's approximation. I want to show it directly. I guess I need some inequality to achieve this but I don't know.",['calculus']
1397530,"If $\sup_n\int_E f_n(x)\ \mathsf dx\leq M\mu(E)$ then the measure of $\{x\in [0,\infty)\mid f(x)>M\}=0$.","This question came up when I was studying for an analysis qualifying exam: Suppose $f_n\geq 0$ for all $n\geq 1$, $f_n\rightarrow f$ a.e. on $[0,\infty)$ and there exists $M>0$ such that $$\sup_n\int_E f_n(x)\ \mathsf dx\leq M\mu(E)$$ for every measurable set $E\subset [0,\infty)$ with $\mu(E)>0$. Then $\mu\{x\in [0,\infty)\mid f(x)>M\}=0$. ($\mu$ denotes Lebesgue measure on $\mathbb{R}$.) I have been trying to do something with Chebyshev's inequality, but I'm not sure I am on the right track. I would appreciate any pointers. Thanks in advance!","['lebesgue-measure', 'real-analysis', 'lebesgue-integral', 'measure-theory']"
1397533,"""multiplicative inverse in the modulo of the larger number"" what does that mean?","while I was reading this artical I have read the following paragraph: The interesting thing is that if two numbers have a $\gcd$ of $1$, then the smaller of the two numbers has a multiplicative inverse in the modulo of the larger number. It is expressed in the following equation: and he gives the following example: Lets work in the set $\mathbb{Z_9}$, then $4\in\mathbb{Z_9}$ and $\gcd(4,9)=1$. Therefore $4$ has a multiplicative inverse (written $4^{−1}$) in $\bmod9$, which is $7$. And indeed, $4\cdot7=28\equiv1\pmod9$. But not all numbers have inverses. For instance, $3\in\mathbb{Z_9}$ but $3^{−1}$ does not exist! This is because $\gcd(3,9)=3\neq1$. but what I do not understand is what does he mean by: then the smaller of the two numbers has a multiplicative inverse in
  the modulo of the larger number. and how he got the $7$","['calculus', 'modular-arithmetic']"
1397569,Help with Spivak's Calculus: Chapter 1 Problem 22,"I've tried a lot of things, but I can't seem to get anywhere with this problem. I'm hoping the solution is simple but that I'm just missing it. The problem is as follows: Prove that if $y_0 \neq 0$ and $|y-y_0| < \min(\frac{|y_0|}{2}, \frac{ \varepsilon |y_0|^2}{2})$ then $y \neq 0$ and $|\frac{1}{y} - \frac{1}{y_0}| < \varepsilon$ I've tried a lot of various things, but nothing seems to get me really any closer. One thing I think may be related is that you can rewrite $|\dfrac{1}{y} - \dfrac{1}{y_0}|$ as $|\dfrac{y_0 - y}{y y_0}|$ and from $|y-y_0| < \dfrac{ \varepsilon |y_0|^2}{2}$ you can say that $|\dfrac{y-y_0}{y_0^2}| < \dfrac{ \varepsilon}{2}$ which implies that $|\dfrac{y-y_0}{y_0^2}| < \varepsilon$ So if you can prove that $|\dfrac{y-y_0}{y y_0}| \leq |\dfrac{y-y_0}{y_0^2}|$ (which may not even be true) then you can prove that $|\dfrac{y-y_0}{y y_0}| = |\dfrac{1}{y} - \dfrac{1}{y_0}| < \varepsilon$ which all hinges on proving that $|y| \leq |y_0|$ , which may not even be true, which would make all my assumptions fall apart. Also, as far as proving that $y \neq 0$ , I can easily prove that $y \neq 0$ from the first part of the inequality $|y-y_0| < \frac{y_0}{2}$ , but I have no idea how to prove it from the other statement that $|y-y_0| < \frac{ \varepsilon |y_0|^2}{2}$ . In any case, I'm convinced I'm going about this the wrong way, and am missing some key observation that would allow me to solve this. Thanks for any help or insight you're able to give.","['analysis', 'calculus']"
1397622,Showing $X^*$ is separable implies $X$ is separable using the Riesz lemma,"If $X$ is a Banach space and $X^*$ is separable, then $X$ is
  separable. Here, David Mitra mentions a proof using the Riesz lemma. However, I do not fully understand it. You could also use Riesz' lemma: Let $Y$ be a  proper closed subspace of the normed space $X$ and
  $0<\theta<1$. Then there is an $x_\theta$ of norm 1 for which $\Vert
 x_\theta-y\Vert>\theta$ for all $y\in Y$. If $X$ were not seperable, you could use Hahn Banach to   construct
  uncountably many functionals $f_\alpha\in X^*$ with  $\Vert
 f_\alpha-f_\beta\Vert\ge \theta$ whenever $\alpha\ne\beta$. If $X$ is not separable, why does that allow us to construct uncountably many separated functionals $f_\alpha$? I see why this fact would imply the theorem. Taking a countable dense set and $\epsilon$ balls around each point in that set, we see that two elements of the uncountable set $\{ f_\alpha\}$ must lie in a single ball. But then they are at most $2\epsilon$ apart. Making $\epsilon$ small shows we can find two elements of the set less than $\theta$ apart, a contradiction.","['dual-spaces', 'separable-spaces', 'banach-spaces', 'functional-analysis']"
1397641,Line for set of three-dimensional vectors,"If there is a set for 3D vectors $v$ where
$ v \times \begin{pmatrix} -1 \\ 1 \\ 4 \end{pmatrix} = \begin{pmatrix} 5 \\ -27 \\ 8 \end{pmatrix}$
is a line, what is this line's equation? I'm not sure how to solve this, except for setting $v = \begin{pmatrix} a \\ b \\ c \end{pmatrix}$ and maybe having a linear system of equations, but I don't see how I could use that to solve the problem.","['calculus', 'matrices', 'algebra-precalculus', 'trigonometry', 'vectors']"
1397655,Proof of the Banach–Alaoglu theorem,"The Banach–Alaoglu theorem states that the closed unit ball of $B'$ (where $B'$ is the dual to a Banach space $B$ over a field) is compact in the weak* topology. I'm having trouble trying to prove the theorem. I first considered the field to be $\mathbb{C}$, and for each $x$ in $B$, we let $U_{x}$ be the closed ball of radius $||x||_{b}$ in $\mathbb{C}$. Then, we can take $U = \Pi_{x\in B} U_{x}$ which will be compact by the Tychonov Product Theorem in the product topology (so, an element of U would be $(z_{x})_{x \in B}$). Then I saw a proof, in where we can define for $x_{1}, x_{2} \in B$ and $t_{1}, t_{2} \in \mathbb{C}$: $$E_{x_{1}, x_{2}, t_{1}, t_{2}}= \{(z_{x})|z_{t_{1}x_{1}+t_{2}x_{2}}=t_{1}z_{x_{1}}+t_{2}z_{x_{2}}\}$$ Then, it is stated that the above condition defines a closed subset of $$U_{t_{1}x_{1}+t_{2}x_{2}} \times U_{x_{1}} \times U_{x_{2}}$$ (I don't see the reason why) and hence $E_{x_{1}, x_{2}, t_{1}, t_{2}} \subset D$ is closed as well (which I don't understand why as well). Now, define: $$E=\displaystyle\bigcap_{x_{1},x_{2}\in B, t_{1},t_{2}\in \mathbb{C}} E_{x_{1},x_{2},t_{1},t_{2}}$$ Which is clearly closed. Then, it is stated that there is a bijection between the closed unit ball of $B'$ and $E$ given by $u \mapsto (z_{x})$, where $z_{x}=u(x)$, $\forall x \in B$ which shows $B'$ is compact in the weak star topology. However, how would this be a continuous bijection? (if this is the case, how does this prove the compactness of $B'$?) Thanks for your help.","['functional-analysis', 'banach-spaces', 'general-topology', 'compactness']"
1397659,Is the limit $ \lim_{n\to \infty}\left(\sum^{n}_{r=0} \binom{n}{r}\big/{n^{r}(r+3)}\right)$ rational or irrational? [duplicate],"This question already has answers here : Evalute $ \lim_{n\rightarrow \infty}\sum^{n}_{k=0}\frac{\binom{n}{k}}{n^k(k+3)} $ (5 answers) Closed 4 years ago . How can I prove that the result of the following limit is rational/irrational?$$ \lim_{n\to \infty}\left(\sum^{n}_{r=0} \frac{\binom{n}{r}}{n^{r}(r+3)}\right)$$ Would solving this limit satisfy? How would I solve this? So, if the result came out to be say $\pi$, can we conclude that it is irrational? Meaning, is it a complete proof?","['calculus', 'summation', 'number-theory', 'combinatorics', 'rationality-testing']"
1397685,A normal extension over $\mathbb{Q}$,"Let $f(x)$ be an irreducible polynomial of degree $5$ in $\mathbb{Q}[x]$. Suppose $a$ and $b$ are distinct roots of $f$ and that $\mathbb{Q}(a)=\mathbb{Q}(b)$. Show that $\mathbb{Q}(a)$ is a normal extension of $\mathbb{Q}$. Now both $\mathbb{Q}(a)$ and $\mathbb{Q}(b)$ have degree $5$ and $f$ has at least one real root and I also think that the given roots can not be conjugate of each other, otherwise $f$ wouldn't be an irreducible polynomial of degree $5$. But I couldn't get the statement. Any help would be great.","['abstract-algebra', 'galois-theory']"
1397706,"Is ""random variable"" really random?","This is a concept question. The fundamental of modern probability theory is measure theory. A probability space is just a finite measure space and a random variable is just a measurable function. We know that for a fixed function $f$, $f(x)$ is unique for each $x$. How can a function be random? In what sense do we call a measurable function ""random variable""?","['probability-theory', 'random-variables', 'measure-theory']"
1397723,Elementary Differential Equations,"I'm currently studying Elementary differential equations, and I came across a confusion that I had that I think arises from notation, but I would like to clarify with someone. The example problem said this: 
$$\frac{\frac{df(t)}{dt}}{f(t)} \equiv \frac{d}{dt} (ln|f(t)|)$$
The way I would usually attain this (Assuming that the above is equal to 1) is by splitting the derivative into the differentials and obtaining something like this:
$$\frac{d(f(t))}{f(t)} = dt$$
and then integrating on both sides to obtain
$$ln|f(t)| = t +c$$
and then taking the derivative to confirm the equivalence. 
But I feel like my approach is somewhat wrong because the book I am using seems to do this using the derivative operator and integral operator. I think my understanding is somewhat flawed. Can someone please clarify this and explain how the first equivalence is true?","['calculus', 'ordinary-differential-equations']"
1397735,Convergence of improper integral $\int_{0}^{\frac{\pi}{6}}\dfrac{x}{\sqrt{1-2\sin x}}dx$,"I'm trying to determine whether the following improper integral is convergent or divergent. $$
\int_{0}^{\pi/6}\frac{x}{\sqrt{1-2\sin x}}dx
$$ At first, I substituted $t=\dfrac{\pi}{2} - x $
and then I used $1-\dfrac{1}{2}x^2  \le \cos x$. But I couldn't determine. :-( $$$$
Second attempt, I used $\sin x\le x $ on $[ 0, \frac{\pi}{6} ]$. But I couldn't determine. :-[ Could you give me some advice? Thanks in advance.","['analysis', 'real-analysis', 'improper-integrals']"
1397739,An Example of a Nested Decreasing Sequence of Bounded Closed Sets with Empty Intersection,"Could someone provide me with an example of a metric space having a nested decreasing sequence of bounded closed sets with empty intersection?
I first thought of Cantor set but the intersection is not empty!","['metric-spaces', 'examples-counterexamples', 'real-analysis']"
1397743,Intuition behind an integral identity,"A proof for the identity $$\int_{-\infty}^{\infty} f(x)\, dx=\int_{-\infty}^{\infty} f\left(x-\frac{1}{x}\right)\, dx,$$ has been asked before (for example, here ), and one answer to that question actually generalized this identity to $$\int_{-\infty}^{\infty} f(x)\, dx=\int_{-\infty}^{\infty} f\left(x-\frac{a}{x}\right)\, dx,$$ for any $a>0$. I've looked through those answers, and I understand the proofs well enough, but none of them provides any intuition on why this identity is true. It seems very strange to me that you can transform the function like this while preserving the integral, and even stranger that the choice of $a$ doesn't matter either. Just to be clear, I'm not asking to see a rigorous proof - there are plenty of those in the other question's answers. But if anyone could give me an intuitive sense of why this holds, or a heuristic argument, I'd really appreciate it.","['calculus', 'differential-forms', 'improper-integrals', 'definite-integrals', 'integration']"
1397756,existence of probability density function,"Let $X$ be a random variable on a probability space $(\Omega,\Sigma,\mathbb{P})$. Let $F_X$ denote the probability distribution function of $X$ given by: $$F_X(y) = P(X\leq y) \text{ for } y \in \mathbb{R}$$ Then, I came across the following: Almost everywhere differentiability of $F_X$ does not imply that the probability density function of $X$, denoted by $f_X$, exists. For example, if $X$ is a random variable such that $P(X = \frac{1}{2}) = 1$, then $F_X$ is differentiable almost everywhere but $f_X$ does not exist. What is the reason that $f_X$ does not exist for $X$ such that $P(X = \frac{1}{2}) = 1$?","['probability-theory', 'probability']"
1397768,"Let $h(z) = g(f(z))$. If two of the three functions $f$, $g$, and $h$ are holomorphic and non-constant, must the third also be holomorphic?","If $h$ and $g$ are holomorphic it seems like the answer is no. Let $f(z) = f(re^{i\theta}) = \sqrt re^{i\theta/2}$ for $\theta \in [0,2\pi)$, and let $g(z)=z^2$. Then $f$ is discontinuous on the non-negative real axis but $g(z)$ and $h(z) = z$ are holomorphic. If $g$ and $f$ are holomorphic the answer is yes, because $h$ is holomorphic by the chain rule. If $h$ and $f$ are holomorphic I think the answer is yes: if $h(z)=g(f(z))$ is defined in an open set $\Omega$, then $g$ is holomorphic in $f(\Omega)$. Proof: For any $z_0\in \Omega$ we have $$\lim_{z\to z_0} \frac{h(z)-h(z_0)}{z-z_0} = \lim_{z\to z_0} \frac{g(f(z))-g(f(z_0))}{f(z)-f(z_0)}\frac{f(z)-f(z_0)}{z-z_0}$$ so that if $f'(z_0) \ne 0$ $$\lim_{z\to z_0} \frac{g(f(z))-g(f(z_0))}{f(z)-f(z_0)} = \frac{h'(z_0)}{f'(z_0)}$$ Let's say I first show that if $f'(z_0) \ne 0$, then $g$ is holomorphic at $y_0 = f(z_0)$. By the holomorphicity of $f'$ its zeros are isolated; and since a holomorphic map is open, I'd have shown that $g$ is holomorphic everywhere in $f(\Omega)$ except possibly at an isolated set of points. If I can then show that $g$ is continuous in all of $f(\Omega)$, then those points are removable singularities, so $g$ is holomorphic in all of $\Omega$. So pick $y_0 = f(z_0) \in f(\Omega)$ such that $f'(z_0) \ne 0$. Choose $\delta$ such that $\left|\frac{g(f(z))-g(f(z_0))}{f(z)-f(z_0)}-\frac{h'(z_0)}{f'(z_0)}\right|<\epsilon$ for $z \in B_\delta(z_0)$. $f$ is holomorphic and thus an open map, so $f(B_\delta(z_0))$ is open, so we can find $\delta'$ such that $B_{\delta'}(y_0) \in f(B_\delta(z_0))$. Then substituting $y=f(z)$, we have $\left|\frac{g(y)-g(y_0))}{y-y_0}-\frac{h'(z_0)}{f'(z_0)}\right|<\epsilon$ for every $y \in B_{\delta'}(y_0)$. So $g$ is holomorphic at every such $y_0$. Lastly, to show that $g$ is continuous, the argument is very similar. Given $y_0$, choose any $z_0$  such that $f(z_0) = y_0$. Then $\lim_{z\to z_0} \left|g(f((z))-g(f(z_0))\right| = \lim_{z\to z_0} \left|h(z)-h(z_0)\right| = 0$. Given epsilon there is a $B_\delta(z_0)$ such that $\left|g(f((z))-g(f(z_0))\right|<\epsilon$ for $z \in B_\delta(z_0)$. $f$ is open, so $f(B_\delta(z_0))$ is open, so there is a $B_{\delta'}(y_0) \in f(B_\delta(z_0))$. For every $y \in B_{\delta'}(y_0), \left|g(y)-g(y_0)\right|<\epsilon$. Is this correct? Is there an easier way to show this?","['analysis', 'function-and-relation-composition', 'complex-analysis']"
1397770,Equivalent Norms for Intermediate Subspaces,"Let $(X,\left\|\cdot\right\|)$ be a Banach space, and let $\left\{T(t) : t\geq 0\right\}$ be an equibounded strongly continuous semi-group on $X$. Define a functional $\left\|\cdot\right\|_{\alpha,r;q}:X\rightarrow[0,\infty)$ by $$\left\|f\right\|_{\alpha,r;q}:=\begin{cases} \displaystyle{\left\|f\right\|+\left(\int_{0}^{\infty}(t^{-\alpha}\left\|[T(t)-I)]^{r}f\right\|^{q}\dfrac{dt}{t}\right)^{q}} & {(0<\alpha<r;1\leq q<\infty)}\\ \\
\displaystyle{\left\|f\right\|+\sup_{0<t<\infty}(t^{-\alpha}\left\|(T(t)-I)^{r}f\right\|)} & {(0\leq\alpha\leq r; q=\infty, r\in\mathbb{N})}\end{cases}
$$ where for $r\in\mathbb{N}$, $[T(t)-I]^{r}f$ is the $r^{th}$ difference. Definition. We say that an element $f\in X$ belongs to the intermediate space $X_{\alpha,r;q}$ if $\left\|f\right\|_{\alpha,r;q}<\infty$. One can show that the spaces $(X_{\alpha,r;q},\left\|\cdot\right\|_{\alpha,r;q})$ are Banach space and that they are continuously embedded between $D(A^{r})$ (the domain of the $r^{th}$ power of the infinitesimal generator of the semigroup) and $X$. For $f\in X$, define the $r^{th}$ modulus of continuity $\omega_{r}(t;f)$ by $$\omega_{r}(t;f):=\sup_{0\leq h\leq t}\left\|[T(h)-I]^{r}f\right\|$$ Problem. I am trying to show that the norms $$\left\|f\right\|+\left(\int_{0}^{\infty}(t^{-\alpha}\left\|[T(t)-I]^{r}f\right\|)^{q}\dfrac{dt}{t}\right)^{1/q} \tag{1}$$ and $$\left\|f\right\|+\left(\int_{0}^{\infty}(t^{-\alpha}\omega_{r}(t;f))^{q}\dfrac{dt}{t}\right)^{1/q} \tag{2}$$ are equivalent for the intermediate subspace $X_{\alpha,r;q}$, where $0<\alpha<r, 1\leq q<\infty$. This problem stems from Theorem 3.4.2 in Butzer and Berens, Semi-Groups of Operators and Approximation , in which the authors assert the equivalence saying ""it is not hard to see"". I have shown the case $r=1$ (see answer below), but I am not seeing how my argument generalizes to the case $r>1$. I think I may be missing some algebraic identity. Edit 2: Generalized the formulation of the original question.","['semigroup-of-operators', 'banach-spaces', 'functional-analysis']"
1397775,Proof Algebraic geometry R. Hartshorne,"In book Algebraic geometry R. Hartshorne I'm confused in the proof of theorem 3.4 first chapter. 1) In the first paragraph of the proof the theorem 3.4: what is the significance of ""this isomorphis sends $I(Y_i)$ to $I(Y)S_{(x_i)}$""? My question is: $I(Y)S_{(x_i)}=I(Y)S_{x_i}\cap S_{(x_i)}$??","['algebraic-geometry', 'notation']"
1397776,Existence of complete sufficient statistics,"Suppose $X_1,\ldots,X_n$ are iid r.v.'s, each with pdf $f_{\theta}(x)=\frac{1}{\theta}I\{\theta<x<2\theta\}$. I find the minimal sufficient statistics $(X_{(1)},X_{(n)})$. I am trying to prove it is complete. Can someone give me hint? Also are there any complete sufficient statistics in this model?","['statistics', 'statistical-inference']"
1397795,Why does basic algebra provide one value for $x$ when there should be two?,"I have the equation $x^2=x$. If I divide $x$ from both sides I get $x=1$. Yet clearly $x$ can also equal $0$. What step in this process is wrong? It seems to me that there's only one step. And isn't dividing the same thing from both sides a valid step? I hope this isn't a stupid question because I feel dumb asking about something so basic. EDIT: To clarify, what I'm looking for is not only an explanation for why my methodology is wrong, but also a better methodology that will keep me from missing possible solutions in the future.",['algebra-precalculus']
1397803,A box contained within larger box has a smaller surface area than the larger box?,Suppose we have a box (parallelepiped) A completely contained within another box B. Is the surface area of A nessecarily less than the surface area of the B? Edit: note that the sides of A are not nessecarily parallel to the sides of B. I happen to know that the answer is yes but the only solution I know of is very hand-wavy.,['geometry']
1397864,The least value of the function $f(x)=|x-a|+|x-b|+|x-c|+|x-d|$ [duplicate],"This question already has answers here : The median minimizes the sum of absolute deviations (the $ {\ell}_{1} $ norm) (11 answers) Closed 8 years ago . If $a<b<c<d$ and $x\in\mathbb R$ then what is the least value of the function $$f(x)=|x-a|+|x-b|+|x-c|+|x-d|\ ?$$ $f(x)= \begin{cases} 
      a-x+b-x+c-x+d-x & x\leq a \\
      x-a+b-x+c-x+d-x & a< x\leq b \\
      x-a+x-b+c-x+d-x & b< x\leq c \\
      x-a+x-b+x-c+d-x & c< x\leq d \\
      x-a+x-b+x-c+x-d & x> d
   \end{cases}$ then $f'(x)=\begin{cases} 
      -4 & x\leq a \\
      -2 & a< x\leq b \\
      0 & b< x\leq c \\
      2 & c< x\leq d \\
      4 & x> d
   \end{cases}$ From here on,i am stuck.Help me out","['supremum-and-infimum', 'derivatives']"
1397891,Complex Conjugate of Integral,"I want to know that the equality
$$
\overline{\int_{\mathbb R} f(x)dx} = \int_{\mathbb R} \overline{f(x)}dx
$$
holds, if the both integral converges. Here $f:\mathbb R \ni x \mapsto f(x)\in \mathbb C $.","['calculus', 'complex-analysis', 'functional-analysis', 'integration']"
1397892,iff $E\Bigl(|X_1|\log ({1+|X_1|)}\Bigr)<\infty$,"Question : $X_n$'s are i.i.d then
$$E\Bigl(\sup_{n\geq 1} \frac{|X_n|}{n}\Bigr)<\infty \iff E\Bigl(|X_1|\log ({1+|X_1|)}\Bigr)<\infty$$ My attempt : for $\Rightarrow$ part, because $\limsup \frac{|X_n|}{n} \leq \sup_{n\geq 1} \frac{|X_n|}{n}$ a.s. from which I get $\limsup \frac{|X_n|}{n} < \infty$ a.s. implying $X_1 \in L_1$. But the question says something stronger. Motivation : (1)
$$0<p<1 \hspace{10pt} \text{then}\hspace{10pt} E\Bigl(\sup_{n\geq 1} \frac{|X_n|}{n^{1/p}}\Bigr)<\infty \iff X_1 \in L_1$$ (2) $$1<p<\infty \hspace{10pt} \text{then}\hspace{10pt} E\Bigl(\sup_{n\geq 1} \frac{|X_n|}{n^{1/p}}\Bigr)<\infty \iff X_1 \in L_p$$ These two problems I was able to solve but then I saw a comment saying ""what about the case $p=1$? Although it's much complicated to show, it turns out that..."". I tried a lot but could not crack it. Any idea/hint/help? Thank you,","['probability-theory', 'probability', 'statistics', 'random-variables']"
1397910,Regression of Irregular Exponential,I am trying to model the population growth of countries with the following logistic equation: $$p(t) = \frac{P_oK}{P_0+(K-P_0)e^{(-rt)}}\tag{displayed}$$ Where $p$ = population; $P_0$ = initial population; $K$ = carrying capacity; $r$ = constant; and $t$ = time I have the data of the population over time and a set carrying capacity. But I would like to know how to go about performing a regression with this function to best fit the all the data I have available. Preface: I think I may be out of my depth here in the math required but I am very willing to try... and if nothing else it would at least satisfy my curiosity. Thanks.,['statistics']
1397945,Squeezing an open set and a compact set between two sets,"Let $U\subseteq \mathbb{R}^2$ be open, and $C\subset U$ be compact. Show there exists $V$ open and $D$ compact such that $C\subset V\subset D\subset U$. My attempt :
For each $x\in U$ consider balls $B(x,\epsilon_x)\subset U$. Now $\displaystyle C\subset \bigcup_{x\in U} B(x,\epsilon_x)$ so there is a finite subcollection $\{x_1,\dots ,x_k\}\subset U$ such that $\displaystyle C\subset \bigcup_{i=1}^{k} B(x_i,\epsilon_{x_i})=V$ say. Now since $C$ is compact in $\mathbb{R}^2$ it's closed and bounded. So $C\subseteq B(0,M)$ for some $M>0$. Now we can replace $U$ by $U\cap B(0,M)$ wlog. So we may assume $U$ is bounded. So if we can show $\bar{V}\subseteq U$ then we are done. Then we can take $D=\bar{V}$ and we have $D$ is compact. But I can't do this. Some help? Thanks.","['general-topology', 'compactness']"
1397983,Finding tangents to a circle with a straightedge,"There is a geometric construction that I heard years ago and I still haven't figured out why it works despite several attempts.
Playing with pen, paper and GeoGebra makes me confident that it does indeed work.
Could someone explain it to me? Task: Given a circle and a point outside it, construct the two tangents to the circle through the point, using only a straightedge. Solution: Draw any three different lines through the given point $P$ that intersect the circle twice.
Let $A_1,A_2,B_1,B_2,C_1,C_2$ be the six intersection points, with the same letter corresponding to the same line and the index 1 corresponding to the point closer to $P$.
Let $D$ be the point where the lines $A_1B_2$ and $A_2B_1$ intersect, and similarly $E$ for the lines $B_1C_2$ and $B_2C_1$.
Draw a line through $D$ and $E$.
This line meets the circle at two points, $F$ and $G$.
The tangents are $PF$ and $PG$.","['euclidean-geometry', 'geometric-construction', 'geometry', 'plane-geometry']"
1397992,The sum of the lengths of the hypotenuse and another side of a right angled triangle is given.,"The sum of the lengths of the hypotenuse and another side of a right angled triangle is given.The area of the triangle will be maximum if the angle between them is: $(A)\frac{\pi}{6}\hspace{1cm}(B)\frac{\pi}{4}\hspace{1cm}(C)\frac{\pi}{3}\hspace{1cm}(D)\frac{5\pi}{12}$ Let $a,b$ are sides of a right triangle other than hypotenuse.Then given that $\sqrt{a^2+b^2}+a$=constant=$k$ Area of triangle=$\frac{1}{2}ab=\frac{1}{2}a\sqrt{(k-a)^2-a^2}$ and then?","['optimization', 'geometry', 'calculus', 'derivatives']"
1397996,For all $n$ there exists $x$ such that $\varphi(x)<\varphi(x+1)<\ldots<\varphi(x+n)$,"Let $\varphi$ be the Euler's function, i.e. $\varphi(n)$ stands for the number of integers $m \in \{1,\ldots,n\}$ such that $\text{gcd}(m,n)=1$. Let $n\ge 2$ be a positive integer. Show that there exists infinitely many $x$ for which $$
\varphi(x)<\varphi(x+1)<\ldots<\varphi(x+n).
$$ [It is a generalization of a math contest asking the same question for $n=2$; I know the answer, and it is positive]","['totient-function', 'contest-math', 'number-theory', 'elementary-number-theory', 'arithmetic-functions']"
1398022,Evaluating $\int_{-3}^{3}\frac{x^8}{1+e^{2x}}dx$,"$$\int_{-3}^{3}\frac{x^8}{1+e^{2x}}dx$$ I can't find solution for this task, can someone help me?","['calculus', 'real-analysis', 'definite-integrals', 'integration']"
1398023,Question about eigenvectors of real matrix with real eigenvalues,I have two related questions: Can a real matrix with real eigenvalues have complex eigenvectors? Is it always the case that a real matrix with real eigenvalues is diagonalisable?,"['eigenvalues-eigenvectors', 'matrices']"
1398024,Is it normal surface of general type to have infinitely many positive rank elliptic curves? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 6 years ago . Improve this question Answered at MO . I am not good at algebraic geometry and almost surely am
misunderstanding something. Got an alleged argument against Bombieri-Lang conjecture and
would like to know what the mistake is. One of the most simplest formulations of Bombieri-Lang conjecture
is in Joe Silverman's answer on MO , paraphrasing ...For a surface of general type ... the Bombieri-Lang conjecture says that the solutions in rational numbers ...are.. not Zariski dense ( lie on a finite set of curves ). Take the affine surface over the rationals: $$ z^6 + x^4 - y^2=0$$ According to Magma it is of general type. Fix $z$ squarefree integer $k$. This gives quartic model
of elliptic curve $k^6+x^4-y^2=0$. This is birationally equivalent to Weierstrass $$v^2=-4k^6u+u^3 $$ As $k$ varies, this gives infinitely many positive rank elliptic curves. What is wrong with this alleged contradiction? Comment suggests it might be not of general type. In Magma online: http://magma.maths.usyd.edu.au/calc/ K<x,y,z,t>:=ProjectiveSpace(Rationals(),3);
 p:=z^6 + x^4*t^2 - y^2*t^4;
 S:=Surface(K,p);
 KodairaEnriquesType(S);
 KodairaDimension(S);
 //returns:
 // 2 0 General type
 // 2 Added The main misunderstanding was caused by incorrect usage of
Magma function. The correct way to check is KodairaEnriquesType(S : CheckADE := true); because of certain assumptions, but this might take much longer. With this change I get error and no result.","['elliptic-curves', 'algebraic-geometry']"
1398027,Group $G$ acting on $\Omega$ such that each $\alpha \in \Omega$ has unique $p$-element fixing $\alpha$.,"Let $G$ be a group acting on a set $\Omega$ and let $p$ be a prime. Suppose that for each $\alpha \in\Omega$ there is a $p$-element $x \in G$ such that $\alpha$ is the only point fixed by $x$. If $\Omega$ is finite, show that $G$ is transitive on $\Omega$; and if $\Omega$ is infinite, show that $G$ has no finite orbit on $\Omega$. Any hints how to solve this problem? EDIT: My initial thoughts were all wrong as I am assumed uniqueness of the $p$-element there.","['abstract-algebra', 'group-theory', 'group-actions', 'permutations']"
1398035,$32$ Goldbach Variations - Papers presenting a single gem in number theory or combinatorics from different point of view,"A short time ago I found the nice paper Thirty-two Goldbach Variations written by J.M. Borwein and D.M. Bradley. It presents $32$ different proofs of the Euler sum identity \begin{align*}
\zeta(2,1)=\zeta(3)=8\zeta(\overline{2},1)
\end{align*} Such a walk through different methods around a single theme is for me an extraordinary pleasure and a good opportunity to associate and to link aspects which I wasn't aware before. Here I'm asking for papers like this one which present a single gem and  provide us with an anthology of different representions, or different proofs or other aspects around this gem. To keep the selection managable I'd like to put the focus on number theory and combinatorics . Two more examples which perfectly match my requirements/wishes: Catalan Addendum by R.P. Stanley provides us with a wealth of different representations of Catalan Numbers extending his $66$ combinatorial representations from the second volume of his classic Enumerative Combinatorics . The Harmonic Series Diverges Again and Again by S.J. Kifowit and T.A. Stamps presenting some rather elementary proofs together with the follow-up paper More Proofs of Divergence of the Harmonic Series .","['number-theory', 'big-list', 'combinatorics', 'reference-request']"
1398073,Convergence of $\int_{0}^{+\infty }\frac{e^{-x}} {1+x^2}dx$,"$$\int_{0}^{+\infty }\frac{e^{-x}} {1+x^{2}}dx$$ One more task that i got on my exam, and i failed.
I tried with partial integration.
I need to find out does it converge?",['integration']
1398116,Fundamental group of a quotient space,"I want to calculate the fundamental group of the space $(S^1 \times [0,1])/$~ where $(z,0)$ ~ $(e^{2\pi i/n}z, 0)$ and $(z,1)$ ~ $(e^{2\pi i/m}z, 1)$. My idea is to find a pushout and then use the van - Kampen - theorem. We get a pushout from the inclusions $S^1 \times \{1/2\} \hookrightarrow (S^1 \times [1/2, 1])/$~ and $S^1 \times \{1/2\} \hookrightarrow (S^1 \times [0, 1/2])/$~ and since $(S^1 \times [1/2, 1])/$~ and $(S^1 \times [0, 1/2])/$~ are homotopy-equivalent to $S^1$, van - Kampen suggests that the sought-after fundamental group is isomorphic to $\mathbb{Z}$, specifically $\langle a, b| a=b \rangle$, which is obviously wrong. So where are my mistakes? I think the induced inclusions are wrong, but how do I see the correct ones?","['group-theory', 'algebraic-topology', 'general-topology']"
1398131,"Let $H,K\lhd G$, if $H\cong K$ and $H\cap K\neq\{1\}$ then does it follow that $H=K?$","Let $H,K\lhd G$, if $H\cong K$ and $H\cap K\neq\{1\}$ then does it follow that $H=K?$ It is clear that if $H\cap K=\{1\}$ then $H$ need not be equal to $K$ . But if it follows that there intersection isn't empty, does it follow that they must be equal?",['group-theory']
1398150,The logarithm is non-linear! Or isn't it?,"The logarithm is non-linear Almost unexceptionally, I hear people say that the logarithm was a non-linear function. If asked to prove this, they often do something like this: We have
  $$
\ln(x + y) \neq \ln(x) + \ln(y) \quad\text{and}\quad \ln(\lambda \cdot x) = \ln(\lambda) + \ln(x) \neq \lambda \cdot \ln(x),
$$
  and therefore $\ln$ is not linear. And indeed, the literature is abundant with the claim that... ... a function $f : V \to W$ is linear, if and only if
  $$
f(x + y) = f(x) + f(y) \quad\text{and}\quad f(\lambda \cdot x) = \lambda \cdot f(x)
$$
  for all $x,y$ and all scalars $\lambda$. Often, there is no hint that the symbols $+$ and $\cdot$ on the left belong to $V$, whereas the symbols $+$ and the $\cdot$ on the right belong to $W$. The logarithm is linear My proof that the logarithm is a linear function goes like this: $$\ln(x \cdot y) = \ln(x) + \ln(y) \quad\text{and}\quad \ln(x^\lambda) = \lambda \cdot \ln(x).$$ The rationale for this is that $\ln : \mathbb{R}_{>0} \to \mathbb{R}$, i.e., the logarithm is a function from the $\mathbb{R}$-vector space $\mathbb{R}_{>0}$ (the positive-real numbers), to the $\mathbb{R}$-vector space $\mathbb{R}$ (the real numbers). Vector addition in $\mathbb{R}_{>0}$ is, however, not usual addition, but multiplication. Likewise, scalar multiplication in $\mathbb{R}_{>0}$ is not usual multiplication, but potentiation. In fact, the linear-algebra definition of linearity is (e.g. Ricardo, 2009 ; Bowen and Wang, 1976 ): A function $f : V \to W$ from a vectors space $(V,\oplus,\odot)$ over a field $F$ to a vector space $(W,\boxplus,\boxdot)$ over $F$ is linear if and only if it satisfies
  $$
f(x \oplus y) = f(x) \boxplus f(y) \quad\text{and}\quad f(\lambda \odot x) = \lambda \boxdot f(x)
$$
  for all $x,y \in V$ and $\lambda \in F$. Another proof goes as follows: The logarithm is an isomorphism between the vector space of positive-real numbers to the vector space of real numbers. And as every isomorphism is a linear function, so is the logarithm. Question We have two conflicting statements here: The logarithm is non-linear. The logarithm is linear. Can both statements be correct simultaneously, depending on something I cannot imagine now? But wouldn't this also imply that two conflicting concepts of linearity exist? Or is this a case of sloppy notation, e.g., abuse of the same symbol $+$ for vector addition or $\cdot$ for scalar multiplication even though two different vector spaces are involved? Update The solutions given to rescue the first statement haven't convinced me yet, because they are inconsistent: Using usual addition and multiplication on $\mathbb{R}_{>0}$ implies that $(\mathbb{R}_{>0},+,\cdot)$ is not a vector space anymore. But a precondition of the linearity proof is that the domain and the range of $f$ are vector spaces. Allowing the domain of $\ln$ to be $\mathbb{R}$ with usual addition and multiplication instead of $\mathbb{R}_{>0}$ doesn't work, because then the image of $\ln$ is the set of complex numbers. A mathematically consistent definition of ""linearity"" for subsets (but not subspaces) of a vector space was given in a comment by @Alex G. Let $S$ be an arbitrary subset of a real vector space $V$, and let $W$ be a real vector space. A function $f : S \to W$ is called ""linear"" if for all $x,y \in S$ such that $x+y \in S$, then $f(x+y) = f(x)+f(y)$, and for all $x \in S$, $k \in \mathbb{R}$ such that $kx \in S$, then $f(kx)=k⋅f(x)$. However, this definition is not what is meant by the concept of linearity coming from linear algebra. One would actually need to use another term for ""linearity"" here.","['notation', 'terminology', 'logarithms', 'linear-transformations', 'linear-algebra']"
1398165,Separating family of functions for measures,"Given a family $X$ of real-valued functions $f\colon\Omega\to\mathbb{R}$ on some set $\Omega$, consider the smallest $\sigma$-algebra on $\Omega$ making all $f\in X$ measurable with respect to the Borel $\sigma$-algebra on $\mathbb{R}$. I am wondering if there is a sufficient condition for the equality $\int f\,\mathrm{d}\mu=\int f\,\mathrm{d}\nu$ for every $f\in X$ to imply $\mu=\nu$.
Hereby, both $\mu$ and $\nu$ are countably additive measures such that for every
nonnegative $f\in X$ we have $\int f\,\mathrm{d}\mu<\infty$ (for $\nu$ resp.).
I am guessing that $X$ has to be large enough, but on the other hand this enlarges $\sigma(X)$ as well so i am not sure about that.",['measure-theory']
1398168,"Integral $\int_0^1 \ln(x)^n \operatorname{Ei}(x) \, dx$","I've conjectured the following identity for $n\geq0$ integers:
$$
\int_0^1 \ln(x)^n \operatorname{Ei}(x) \, dx = (-1)^{n+1}n! \cdot \left(-\operatorname{Ei}(1)+\sum_{k=1}^{n+1} {_kF_k}\left(\begin{array}c1,1,\dots,1\\2,2,\dots,2\end{array}\middle|\,1\right)\right),
$$
where $\ln$ is the natural logarithm , $\operatorname{Ei}$ is the exponential integral and ${_pF_q}$ is the generalized hypergeometric function . For $n=0$ it is $1-e+\operatorname{Ei}(1)$ and for $n=1$ it is $e-1-\gamma$, where $e$ is base of the natural logarithm , and $\gamma$ is the Euler-Mascheroni constant. How could we prove this identity?","['calculus', 'special-functions', 'closed-form', 'definite-integrals', 'integration']"
1398201,Expectation of Independent Variables Equals Zero?,"Given $n$ independent random variables, $X_1, X_2, ..., X_n$ , each having a normal distribution, why is it that the following expectation holds? $$E[(X_i - \mu)(X_j - \mu)] = 0$$ where $i \neq j$ I saw this statement in a proof explaining why we divide by $n-1$ when computing the sample variance and of course there was no explanation. An intuitive explanation and/or a link to more detailed information about why this is true would be greatly appreciated","['expectation', 'probability', 'statistics', 'intuition']"
1398210,"If $K\lhd G$ and $(|K|,[G:K])=1$ then $K$ is characteristic.","Here is my Idea I think I am somehow supposed to use the fact that $K$ is a unique subgroup of order $|K|$. To prove this. I think the proof is that for every automorphism of G ($\varphi$), $|\varphi(K)|=|K|$. But I am not sure if that is true, or if it is how to prove that it is true.",['group-theory']
1398218,Determine coordinates for Mandelbrot set zoom.,"I am writing a computer program to produce a zoom on the Mandelbrot set.  The issue I am having with this is that I don't know how to tell the computer where to zoom.  As of right now I just pick a set of coordinates in the complex plane and zoom into that point.  Only problem is that eventually it will either become completely light or dark because those coordinates are not exactly on the border of the fractal.  Any ideas for how to calculate the ""most interesting"" coordinates?","['geometry', 'fractals']"
1398234,The Product map of a Lie Group is a Submersion.,"Problem 7.1 of Lee's Introduction to Smooth Manifolds (2nd Edition) reads: Show that for a Lie group $G$, the multiplication map $\mu:G\times G\to G$ is a submersion (Hint: Use Local Sections). I did the following: Fix $g, h\in G$. Then since $T_{(g, h)}(G\times G)\cong T_g G\oplus T_h G$, we have $$
d\mu_{(g, h)}(X, Y)= d(\mu\circ i^h)_gX+d(\mu\circ j^g)_h Y
$$
for $X\in T_gG, Y\in T_hG$, where $i^h:G\to G\times G$ is the map defined as $i^h(x)=(x, h)$ for all $x\in G$ and similarly for $y^g$. Thus we have $$
d\mu_{(g, h)}(X, Y)= dR_h|_gX+dL_g|_hY
$$ Since $dR_h|_g:T_gG\to T_{gh}G$ is a linear isomorphism, we see that the rank of $\mu$ is full. So we are done. I do not see how to do it using the hint Lee has given Can somebody please do it using the hint?","['lie-groups', 'differential-geometry']"
1398243,Lagrange Multipliers Example,"Minimize $$f(x,y) = x^2+y^2$$ subject to the constraint $xy=3$. I know the formula for Lagrange multipliers to be $\nabla f = \lambda \nabla g$ so we get a system of equations like this $$\begin{cases}f_x = \lambda g_x \\ f_y = \lambda g_y \end{cases}$$
However that gives me $2$ equations, but $3$ variables. I do not know what to do from here.","['lagrange-multiplier', 'calculus', 'multivariable-calculus']"
1398251,"Convolution can smooth an input function, is there an operation which bunches it up?","An easy to remember description of what the convolution of two functions is, is to say that one is a weight function and the result is a weighted average of the other function. The canonical example would be a lowpass filter, which smoothes the input function by means of the filter (weight) function. A highpass filter, on the other hand does roughly the opposite by removing the smoothness. What I am looking for: is there an operation where a function is ""bunched up"" by another one, where ""bunching up"" should roughly mean: keep the value of the integral, reduce the support, or at least reduce function values which are already small, while increasing the larger ones, keep the symmetry between the two input functions (despite the fact that we call one the filter or weight). My hunch is that I could Fourier transform the input, shift all frequencies towards zero somehow making use of the second function and then reverse transform and normalize, but then the two input functions are not used symmetrically. And I don't want to invent this. I would think that this concept exists already. EDIT: If I understand the first answer correctly, @josh suggests that if a convolution kernel $\phi$ had a convolutional inverse $\phi^{-1}$, we could reverse a smoothing. Smoothing an $f$ by $f\ast\phi = g$ could then be reverted to $f\ast\phi\ast\phi^{-1} = g\ast\phi^{-1} = f$. As mentioned in that answer, the ""convolutional inverse"" does not seem to exist always as a well behaved function. So I would like to invite more answers, not bound to convolution at all, maybe even non-linear operations.","['binary-operations', 'convolution', 'functions']"
1398256,About metric and the Ricci curvatrue,"Recently, I met a question about the relation between $g$ and $-Ric_g$ on the Riemmannian manifold $(M^n, g)$. One said that ""without loss of generality that by scaling $g$ in space we have $g \geq - Ric_g$"". Is there anyone who can explain it? Thank you!",['differential-geometry']
1398275,Proof if $I+AB$ invertible then $I+BA$ invertible and $(I+BA)^{-1}=I-B(I+AB)^{-1}A$ [duplicate],"This question already has answers here : $I_m - AB$ is invertible if and only if $I_n - BA$ is invertible. (4 answers) Closed 5 years ago . I have the following question : Proof if $I+AB$ invertible then $I+BA$ invertible and $(I+BA)^{-1}=I-B(I+AB)^{-1}A$ I managed to proof that $I+BA$ invertible My proof : We know that $AB$ and $BA$ has the same eigenvalues, and Since $I+AB$ invertible $-1$ is not an eigenvalue for $I+AB$ since if $-1$ is an eigenvalue then $I+AB$ is singular which is a contradiction. and since $AB$ and $BA$ has the same eigenvalues then $-1$ is also not an eigenvalue for $I+BA$ therefore $I+BA$ is also invertible. But how do I show that $(I+BA)^{-1}=I-B(I+AB)^{-1}A$ I tried to ""play"" with the equations to reach one end to other end meaning that $(I+BA)^{-1}=...=...=...=I-B(I+AB)^{-1}A$ Or to show that
$ I=(I+BA)^{-1}(I-B(I+AB)^{-1}A)$ But wasn't successful. Any ideas? Thank you!","['eigenvalues-eigenvectors', 'matrix-equations', 'linear-algebra', 'matrices']"
1398279,Differentiability of this picewise function,"$$f(x,y) = \left\{\begin{array}{cc}
\frac{xy}{x^2+y^2} & (x,y)\neq(0,0) \\
f(x,y) = 0 & (x,y)=(0,0)
\end{array}\right.$$ In order to verify if this function is differentiable, I tried to prove it by the theorem that says that if $\frac{∂f}{∂x}$ and $\frac{∂f}{∂y}$ exist and are continuous at the point $(x_0,y_0)$, then the function is differentiable at this point. So I did: $$\frac{\partial f}{\partial x}(0,0) = \lim_{h\to 0}\frac{f(0+h,0)-f(0,0)}{h} = 0$$
$$\frac{\partial f}{\partial y}(0,0) = \lim_{h\to 0}\frac{f(0,0+h)-f(0,0)}{h} = 0$$ so we have that the partial derivatives at point $(0,0)$ is $0$. Now, if we take the derivative at $(x,y)\neq (0,0)$ and then take the limit of it as $(x,y)\to(0,0)$, we can see if the derivatives are continuous or not. So here it is: $$\frac{\partial f}{\partial x}(x,y) = \frac{y(y^2-x^2)}{(x^2+y^2)}$$ but $$\lim_{(x,y)\to(0,0)} \frac{y(y^2-x^2)}{(x^2+y^2)} $$
does not exist (by wolfram alpha... but can anybody tell me an easy way to prove this limit does not exist? easier than taking the limit in different directions?), therefore the derivative is not continuous at $(0,0)$, so we can't say $f$ is differentiable at $(0,0)$, but for $(x,y)\neq (0,0)$ the function is continuous, as it is a quotient of continuous functions. So $f$ is at least differentiable at $(x,y)\neq (0,0)$. Now, to verify differentiability at $(0,0)$ I think we must use the limit definition of differentiablity:
A function is differentiable at $(0,0)$ iff:
$$\lim_{(h,k)\to (0,0)} \frac{f(0+h,0+k)-f(0,0)-\frac{\partial f}{\partial x}(0,0)-\frac{\partial f}{\partial y}(0,0)}{\|(h,k)\|} = 0$$ Let's calculate this limit: $$\lim_{(h,k)\to (0,0)} \frac{f(0+h,0+k)-f(0,0)-\frac{\partial f}{\partial x}(0,0)-\frac{\partial f}{\partial y}(0,0)}{\|(h,k)\|} = \\ \lim_{(h,k)\to (0,0)} \frac{\frac{hk}{h^2+k^2}}{\sqrt{h^2+k^2}} = \\ \lim_{(h,k)\to (0,0)} \frac{hk}{(h^2+k^2)\sqrt{h^2+k^2}}$$ which I think, it's a limit that does not exist, therefore the function isn't differentiable at $(0,0)$","['calculus', 'limits', 'partial-derivative', 'multivariable-calculus', 'derivatives']"
1398309,On the space $L^0$ and $\lim_{p \to 0} \|f\|_p$,"For $0 < p < \infty$, the definitions of the spaces $L^p$ are very natural. Then, we of course want $L^\infty$ and $L^0$ to be some kind of limits of $L^p$ spaces. What does the parameter $p$ tell about a function $f \in L^p$? If $f \in L^p$ for very large $p$, it means that $f$ behaves very well near its singularities. If $f \in L^p$ for very small $p$, it means that $f$ decreases fast at infinity. The limiting case $p \to \infty$ then of course means that $f \in L^\infty$ if $f$ has no singularities in some sense (essentially bounded). Then we define $\|f\|_\infty = \operatorname{ess sup}_{x\in X} |f(x)|$, which is a norm in $L^\infty$. In some cases it even holds that $\|f\|_\infty = \lim_{p \to \infty} \|f\|_p$. How about $p \to 0$? I've never really seen anything said about this space, so I guess it's not very interesting. But I still started to think about it. Now, $f \in L^0$ should mean that $f$ is extremely bounded at infinity, meaning that $f$ is compactly supported. Of course because we are talking about measure and integration theory, the notion of compact support has to be modified accordingly. I guess we want to define that $f \in L^0$ if the support of $f$ is compact modulo sets of measure $0$. Is this how we should think about $L^0$? If it is, then we probably want to define $\|f\|_0 = \mu(\operatorname{spt} f)$, or something like that. So, what is the number $\lim_{p \to 0} \|f\|_p$? For measurable compactly supported bounded functions it is easy to see that 
\begin{align}
\lim_{p \to 0} \int_X |f|^p = \mu(\operatorname{spt} f)\,.
\end{align}
But if we want to take the limit of $\|f\|_p$, the integral should be raised to the power $1/p$, which tends to infinity, which complicates things. So my questions are: what should the space $L^0$ be, what should be its ""norm"" $\|f\|_0$ and when is $\|f\|_0$ the limit of $\|f\|_p$? Also, why does the wikipedia page on $L^p$ spaces refer to $L^0$ as the space of measurable functions? (In the case $\mu(X) < \infty$ it would make sense since $L^0$ restricts the behavior of its elements at infinity, and in the $\mu(X)< \infty$ case there is no ""behavior at infinity"".)","['measure-theory', 'real-analysis', 'functional-analysis', 'lp-spaces', 'intuition']"
1398322,The locker puzzle - predetermined strategy,"The question is related to the famous locker puzzle : The director of a prison offers 100 prisoners on death row, which are numbered from 1 to 100, a last chance. In a room there is a cupboard with 100 drawers. The director puts in each drawer the number of exactly one prisoner in random order and closes the drawers afterwards. The prisoners enter the room one after another. Each prisoner may open and look into 50 drawers in any order and the drawers are closed again afterwards. If during this search every prisoner finds his number in one of the drawers, all prisoners are pardoned. If just one prisoner does not find his number, all prisoners have to die. Before the first prisoner enters the room, the prisoners may discuss their strategy, afterwards no communication of any means is possible. What is the best strategy for the prisoners? I am interested in the modification where the prisoners are only allowed to use a predetermined strategy: each of them must choose the 50 boxes he will open before entering the room. In this case I believe the optimal strategy is the following one. Divide the prisoners into two groups, say, with numbers 1-50 and 51-100. Each prisoner from the first group should open boxes 1-50, from the second, 51-100. More generally, if each of $nm$ prisoners is allowed to open $m$ boxes, then the best strategy seems to be the same: divide into groups $1$ to $m$, $m+1$ to $2m$, ... $(n-1)m+1$ to $nm$ and let each prisoner open the boxes with numbers from his group. This is easily seen to be optimal for $m=2$. Is this so for any $m$? Is there any reference?","['puzzle', 'graph-theory', 'combinatorics', 'discrete-optimization', 'reference-request']"
1398331,Prove that if $E[X|\sigma(Y)] = Y$ and $E[Y|\sigma(X)] = X$ then $X = Y$ almost surely. [duplicate],"This question already has answers here : Question about Conditional Expectation (1 answer) If $E[X|Y]=Y$ almost surely and $E[Y|X]=X$ almost surely then $X=Y$ almost surely (4 answers) Closed 8 years ago . Prove that if  $E[X|\sigma(Y)] = Y$ and $E[Y|\sigma(X)] = X$ then $X = Y$ almost surely.
This is my idea: By assumption, $Y = E[X|\sigma(Y)] = E\left\lbrack E[Y|\sigma(X)]|\sigma(Y)\right\rbrack$, and I would like to show that this equals $E[Y|\sigma(X)]$ which equals $X$.  If I can show that $E[Y|\sigma(X)]$ is $\sigma(Y)$ measurable, then the proof is finished.  But I am not sure how to do this. Any help would be greatly appreciated.",['probability']
1398358,Showing that a space is not homeomorphic to $\mathbb{R}^4$.,"I have a space $X$ which is defined to be the quotient of $[0,1)\times T^3$ ($T^3$ is the 3-torus) by the relation $(0,x)\sim (0,y)$ for all $x,y \in T^3$. It is a kind of cone over $T^3$, except that the interval $[0,1)$ is only half closed. I want to show that this space is not homeomorphic to $\mathbb{R}^4$. I believe that the image of one of the $S^1$ factors in $T^3$ will be a non-null-homotopic loop, which would yield the result using fundamental groups. I can't seem to show this though, and am not sure it is a good approach. A quick look at the cases for $T^1$ and $T^2$ : in the same constructions for $T^1$ and $T^2$ I believe the fundamental groups are $0$ and $\mathbb{Z}$ respectively and in the latter case, the image of one of the $S^1$ factors is the generator. I believe this because I imagine $[0,1)\times T^2$ as a thickening of the $2$-torus with $\{0\}\times T^2$ being the outer shell which is mapped to a point in the quotient. Mapping the outer shell to a point can be thought of as first pinching the central ""donut"" hole, as it were, to a point. We then have something homotopic to a 3-ball but missing an interior circle, and whose boundary must be identified to a point. Identifying the boundary of a 3-ball in this way yields $S^3$ minus a circle, which is homeomorphic to $\mathbb{R}^3$ minus a line, which has fundamental group $\mathbb{Z}$ generated by a loop coming from the image of one of the $S^1$ factors of the original $T^3$. I believe the same sort of thing may happen in the case of $T^3$ but cannot currently prove it. Any thoughts or guidance here would be greatly appreciated. Edit : I just realized that the analysis for the $T^2$ case is wrong. When I think of identifying the boundary of a 3-ball to a point, I also have a curve in this ball each end of which is touching the boundary and which must be mapped to the same point. In this case, I am now inclined to believe that the fundamental group is also $0$ in the case of $T^2$ because that curve is homotopic to what I originally thought would be the generator.","['fundamental-groups', 'algebraic-topology', 'general-topology']"
1398383,Relearning multivariable calculus through differential forms,"While I learned multivariable calculus a few years ago, I have never felt I understand it well enough. Now I have time to go back and correct this. Since I have been through subjects like real analysis, I want this understanding to be more rigorous than the more intuition based learning that I initially encountered. That lead me to consider differential form. Is it any good idea to learn things like line integrals, Lagrange multipliers and the like through differential forms? Things that bother me the most about my understanding of multivariable calculus is, for instance, while I do know the purpose of the Jacobian in changing variables, I cannot prove it. In fact, beyond an intuitive understanding of what it does, I cannot show what exactly it does. Also, I have very little understanding of the equivalents of the fundamental theorem of calculus in multivariable calculus. So, considering this... Should I embark upon trying to relearn calculus through differential forms? I am considering A Geometric Approach to Differential Forms by David Bachman.","['differential-forms', 'multivariable-calculus']"
1398399,Stochastic variables independent given Tau,"Say we have a filtration $(\mathbb{F}_s)$, and a stopping time $\tau$ w.r.t. to that filtration.Let $X_t$ be a continuous stochastic process (not required to be adapted to the mentioned filtration), such that $X_t$ is independent of $(\mathbb{F}_s)_{s\leq s_0}$ for $s_0\leq t$ I strongly believe that it holds that for all $c>0$ (correct me if its not intuitively clear)
$$P(X_{\tau}>c\vert \tau=s)=P(X_{s}>c).$$
 or atleast
$$P(X_{\tau+\epsilon}> c\vert \tau=s)=P(X_{s+\epsilon}> c).$$
Can anybody help me prove it? What i have tried: Well in discrete time the proof of the 2nd statement is straight forward
$$P(X_{\tau+1}>c\vert \tau=j)=\dfrac{P(X_{\tau+1}>c, \tau=j)}{P(\tau=j)}=\dfrac{P(X_{j+1}>c, \tau=j)}{P(\tau=j)}=P(X_{j+1}>c).$$ 
I have troubles making it work in continuous time. Our definition of 
$P(X_{\tau}>c\vert \tau=s)$ is the function $\phi(s)$ such that $\phi(\tau)$ is a.s the random variable $E(1_{(X_{\tau}>c)}\vert \tau).$","['probability-theory', 'markov-process', 'stochastic-processes', 'independence', 'stopping-times']"
1398410,"Möbius band as line bundle over $S^1$, starting from the cocycles","The professor asked us to construct a non-trivial line bundle over $S^1$ by giving an open cover of $S^1$ and the cocycles. My idea was to take as open cover $U_1:=S^1\setminus\{0\}$ and $U_2:=S^1\setminus\{\frac{1}{2}\}$. Then, as cocycles,
$$
g_{12}:U_1\cap U_2\to\mathbb{R}\\
g_{12}(x)(y):=1-y
$$
for every $x\in U_1\cap U_2$, $y\in\mathbb{R}$. I want to verify that I've actually obtained the Möbius band using the ""canonical"" construction starting from the coccycles. Define
$E:=\dfrac{(U_1\cup U_2)\times\mathbb{R}}{\sim}$ where $\sim$ is the equivalence relation defined as
$$
(p_1,y_1)\sim (p_2,y_2)\iff p_1=p_2,\,\,g_{12}(p_1)(y_2)=y_1
$$
We can rewrite the equivalence relation as $(p,y)\sim(p,1-y)$. But this is not the Möbius band, since I should have gotten $(0,y)\sim(1,1-y)$. What am I doing wrong? For me, the Möbius band is $([0,1]\times\mathbb{R})/\sim$ where $\sim$ is the equivalence relation which identifies the points $(0,y)$ and $(1,1-y)$.","['vector-bundles', 'mobius-band', 'fiber-bundles', 'differential-geometry', 'algebraic-topology']"
1398411,Limit Question involving infinite multiplication?,"$$\lim_{n\to ∞} \prod_{i=1}^n ({n+i\over n})^{1\over n} $$ For this question I tried using the substitution $$ u = {1\over n}$$ So as ""n"" goes to infinity, ""u"" goes towards zero. So the limit changes to: $$\lim_{u\to 0} ((1+u)(1+2u)...(2-2u)(2-u)(2))^{u}$$ So my thinking was that since the terms inside are being raised to the ""u"" power and ""u"" is getting infinitely close to 0 the limit should tend towards 1. But according to Wolfram Alpha $$\lim_{n\to ∞} \prod_{i=1}^n ({n+i\over n})^{1\over n} = {4\over e} $$ I'm not sure how they ended up with that answer and was hoping that someone can help.","['calculus', 'limits']"
1398416,"Intersection of $36x^2 -9y^2+4z^2+36 = 0$ with plane $x=1$, derivative at a point","The exercise asks me to find the inclination of the line tangent to the intersection of $36x^2 -9y^2+4z^2+36 = 0$ with the plane $x=1$ in the point $(1,\sqrt{12},3)$, and then say to me that I have to interpret this as a partial derivative. So, that's what I did: if we solve for $z$ in the equation, we have: $$z = \pm \frac{\sqrt{9y^2-36x^2-36}}{2} \implies $$ if I take the partial with respect to $x$ for the $+$ function (because the point in $z$ is positive), all I'm doing is taking the partial derivative with respect to $x$, of the function defined by the intersection of that graph and the plaxe $x=1$, so I have: $$\frac{\partial z}{\partial x} = \frac{-6x}{\sqrt{-4-4 x^2+y^2}}$$ that, in the point $(1,\sqrt(12),3)$ gives: $$-3$$ Is everything ok? UPDATE: I think now that this partial derivative should be with
  respect to $y$, rigth?","['partial-derivative', 'calculus', 'multivariable-calculus', 'derivatives']"
1398421,"True or false. If A ∪ B = ∅ , then A = ∅ and B = ∅ .","True or false. If A ∪ B = ∅ , then A = ∅ and B = ∅ . True or false. If A ∩ B = ∅ , then A = ∅ or B = ∅ or both A and B are empty sets. True or false. (A ∪ A^c)^c = ∅ . True or false. If A ∈ B, then n(B) = n(A) + n(A^c ∩ B). my work 1-TRUE. We see that the union of both sets presents an empty set. So this can happen only if A and B, both sets are empty sets. 2-FALSE. If the intersection of two states is an empty set, it does not mean that any of the sets is empty. It also means that there are no common elements in both A and B and these sets may not be empty. 3-TRUE. A^c means compliment of set A i.e. all elements leaving the elements of set A. So, the union of A and A^c will be U (universal set) i.e. all the elements are included. 4-TRUE. The n(A)+n(B) includes the number of elements common in both which is added twice. If we have 5 elements in set A and 4 elements in set B out of which 2 elements are common in both the sets, so, n(A)+n(B)=9 I need you confirm if my answers are correct or wrong",['elementary-set-theory']
1398438,Differential Entropy,"I'm a little temporarily confused about the concept of differential entropy. It says on wikipedia that the differential entropy of a Gaussian is $\log(\sigma\sqrt{2\pi e})$. However I was thinking as $\sigma \rightarrow 0^+$, the only intuitive value for an entropy to me seems to be 0. We are then 100% sure that the outcome will be equal to $\mu$, and nothing is required to store the knowledge of what the outcome will be. Instead the expression above gives $-\infty$. So I must be misunderstanding something, right? Just to clarify, the reason why I'm asking is that I'm trying to figure out if my approach at this question about Empirical Entropy makes any sense. Edit: ""Own work"" Now I have thought a bit about this. If we take the easiest distribution, the uniform distribution, which (according to wikipedia) has differential entropy $\log(b-a)$, say $b-a = 2^k$. If k = -1, this would be -1 bit and the interval would be length 0.5. If k =  0, this would be 0 bit and the interval would be length 1.0. If k =  1, this would be 1 bit and the interval would be length 2.0. So if the interval is 0.5, we would ""save"" one bit, as compared to if we had to store the precision of an interval of length 1. So differential entropy is in some sense the information needed ""in excess"" to whatever resolution we want to store with. Does this make any sense?","['probability-theory', 'entropy', 'information-theory', 'statistics']"
1398441,Weak $L^p$ implies strong $L^q$ for $q<p$,"Another prelim question... Suppose $0<q<p<\infty$, and $E\subseteq \mathbb{R}^n$ has finite measure. Suppose $f$ is in weak $L^p$, i.e. $\lambda(|f| > t) \leq N/t^p$. Show $f \in L^q(E)$ and moreover $\int_E |f|^q \leq C_{n,p,q} N^{q/p}\lambda(E)^{1-q/p}$. First let's show $f \in L^q(E)$. For $g$ a strictly increasing function with $g(0)=0$
$$
\int_E |f|^q = \sum_{k} \int_E |f|^q 1_{g(k) < f \leq g(k+1)}
\leq \sum_k g^q(k+1) (\lambda(f > g(k)) \wedge \lambda(E))
$$
$$
\leq\sum_k g^q(k+1) (\frac{N}{g^p(k)} \wedge \lambda(E))
$$
so it suffices to choose $g$ such that $\sum_{k\geq M} \frac{g^q(k+1)}{g^p(k)} < \infty$ for some $M$. Taking $g(k) = 2^k$ (except $g(0)=0$) and $M>1$ this turns into $\sum_{k\geq M} 2^q (2^{(q-p)})^n < \infty$ which is of course true. Okay so we have $f \in L^q(E)$. Now what can be done to show the bound? I've tried writng $|f|^q = (|f|^p)^{q/p}$ and using Fubini and Holder
$$
\int_E |f|^q = \int_0^\infty \int \frac{p}{q}t^{p/q-1} 1_{E} 1_{0\leq |f|^p \leq t}dx dt \leq \int_0^\infty\frac{p}{q}t^{p/q-1} \lambda(E)^{1-q/p} \lambda(f>t^{1/p})^{q/p}dt
$$
$$
= \frac{p}{q}\lambda(E)^{1-q/p} \int_0^\infty t^{p/q-1} \lambda(f>t^{1/p})^{q/p} dt
$$
but I can't get an estiamte like this to turn out to be finite.","['lp-spaces', 'real-analysis', 'measure-theory']"
1398442,For what $p$ is $\frac{1}{(x(1+\ln(x)^2))^p}$ Lebesgue integrable?,"I'm trying to use the fact that given $f:[a,\infty)\to\mathbb{R}$ Riemann integrable for every closed interval $[c,d]\subset [a,\infty)$, then $f$ is Lebesgue integrable if, and only if, $\int_a^\infty|f(x)| \, dx$ exists. In particular, $f(x)=\frac{1}{x(1+\ln(x)^2)}$ is $p$-Lebesgue integrable if $\int_0^\infty\frac{1}{x^p(1+\ln(x)^2)^p} \, dx<\infty $. Here using the fact that $f>0$. But I can't solve this Riemann integral.","['measure-theory', 'improper-integrals', 'lp-spaces', 'integration', 'lebesgue-integral']"
1398445,How is $\left|\frac{xy}{\sqrt{x^2+y^2}}\right| \leq \frac{\sqrt{|xy|}}{\sqrt{2}}$,"$$\left|\frac{xy}{\sqrt{x^2+y^2}}\right| \leq \frac{\sqrt{|xy|}}{\sqrt{2}}$$ Does this apply in general, because here in this example i have $x \to 0, y \to 0$. Some inequality is used I believe to prove this one, but I do not see which.","['analysis', 'inequality']"
1398462,"Does the set $\left\{\left(f,\int_a^b f\right):f\in X\right\}$ represent a function?","I'm working through Undergraduate Topology by Kasriel, and the author asks the following: Let $X$ be the set of all continuous, real-valued functions defined on
   $\left[a,b\right]$. Does \begin{align}
 \Gamma=\left\{\left(f,\int_a^bf\right):f\in X\right\},\tag{1}
 \end{align} represent a function, or further, a 1-1 function? So far I have determined that it cannot be 1-1 because on some interval $\left[a,b\right]$, $\int_a^b f$ always results in the same value as it depends only on the endpoints. Hence, the range of this set will be the singleton $\left\{\int_a^b f\right\}$. Now, what of the domain? If $f$ is monotonic, then I'm guessing this set could be defined on all possible $\left[a,b\right]\subset\mathbb{R}$. If, however, it is periodic with period $L$, like $\cos$ or $\sin$, then it would only be a function so long as throughout the interval, some subset of that period, the function is monotonic. Does this sound right? I feel like there's a flaw somewhere in my logic.","['elementary-set-theory', 'functions']"
1398474,Find a function such that follows to normal in distribution,"Suppose that $X_{n}\sim \text{Binomial}(n,\theta)$, where $n=1,2,\ldots$ and $0<\theta<1$. Find a function $g$ such that $\sqrt{n}(g(\frac{1}{n}X_n)-g(\theta))\xrightarrow{D} N(0,1)$ for each value of $\theta\in(0,1)$. Can someone give me hints by using Delta method? I was trying to prove $\sqrt{n}(X_{n}-\theta)\xrightarrow{D} N(0,\sigma^2)$. But I find I only know $\bar{X}_n$ has similar property. Delta Method Theorem
Let $Y_n$ be sequence of random variables that satisfies $\sqrt{n}(Y_n-\theta)\xrightarrow{D}N(0,\sigma^2)$. For a given function $g$ and a specific value of $\theta$, suppose that $g'(\theta)$ exists and is not $0$. Then $$\sqrt{n}[g(Y_n)-g(\theta)]\xrightarrow{D}N(0,\sigma^2[g'(\theta)]^2).$$","['statistics', 'statistical-inference']"
1398501,Why are there only 2 solutions for $x^n=1$?,"(where $n>0$) I have been taught that an equation with the highest power $n$ will always have $n$ solutions. This does not appear to be the case with:
$$x^n=1 \implies x=\pm1$$
Where $n$ is even, the solutions are $1$ and $-1$; where $n$ is odd, the only solution is $1$. Why? Is it a special case, or is there something I'm missing?","['polynomials', 'algebra-precalculus']"
1398533,What is the difference between a subgroup and semigroup?,"In my text it says $\{e^{i\theta}:\theta\in\mathbb{R}\}$ is a subgroup but it did not clarify the subgroup of which group. Furthermore I remember this entire set as being a semigroup, is there a difference between a subgroup and semigroup?","['group-theory', 'terminology']"
1398555,$N$ commuting vector fields on an $N$-dimensional compact manifold,"If an $N$-dimensional compact manifold has $N$ commuting vector fields, does this mean the manifold is actually a torus?","['manifolds', 'general-topology']"
1398556,Integrate $\int^{\pi }_{0}\frac{x}{2-\tan ^{2}\left( x\right) }\mathrm dx $,The integral I tried to solve by using this rule $$\int \limits^{a}_{0}f\left( x\right)\mathrm  dx = \int \limits^{a}_{0}f\left( a-x\right)\mathrm dx.$$ The  integral is $$\int \limits^{\pi }_{0}\frac{x}{2-\tan ^{2}\left( x\right) }\mathrm dx $$ I tried Wolfram Alpha put it was useless...  Is there any hint or solution? Thanks for help.,"['calculus', 'definite-integrals', 'integration']"
1398592,Proving uniform continuity of function of two variables.,"Proving uniform continuity of function:$$f(x,y)=\begin{cases} \frac{x^3-xy}{x^2+y^2},  & (x,y)\neq (0,0) \\ 0, & (x,y)=(0,0) \end{cases}$$ This is supposedly solve, but I don't understand the solution. It is proved that it is continuous and differentiable (asked in sub questions, but might be important for overall idea.) After this, it is proved that $\frac{\partial f}{\partial x}(x,y)\leq 3$ and also $\frac{\partial f}{\partial y}(x,y)\leq 2$. Then it goes onto say: $$|f(x)-f(y)|\leq k \|x-y\|\\ 
  |f(x)-f(y)|\leq |f(x)-f(z)|+|f(z)-f(y)| \leq k \|x-z\|+ k \|z-y\|\\
   \leq k(\|x-z\|+ \|z-y\|)...$$ Does this make any sense? Im interested in this variation of the answer...","['calculus', 'partial-derivative', 'real-analysis', 'analysis', 'derivatives']"
1398597,When only eventually constant sequences are convergent?,Let $X$ be a compact Hausdorff topological space whose convergent sequences are eventually constant. Is there a description of such spaces. How ''far'' these spaces from Stonean ones?,"['general-topology', 'compactness']"
1398601,Determining if a map on a space is continuous by checking on a dense subset,"I recently read a proof of something my calculus teacher had told me, namely that the set of continuous maps $f: \mathbb{R} \to \mathbb{R}$ had the cardinality of $\mathbb{R}$. The proof was simple enough: There must be at least that many, as it includes all constant maps, but can be no more because we can injectively map the continuous maps on $\mathbb{R}$ to $\mathbb{R}^{\mathbb{Q}}$ by $\phi : f \mapsto (f(q))_{q \in \mathbb{Q}}$, and $\mathbb{R}^{\mathbb{Q}}$ has the same cardinality as $\mathbb{R}$, as this is enough to determine the value of $f$ on any real value by taking $f(x) = \lim_{q \to x, q \in \mathbb{Q}} f(q)$; that is, assuming the map is continuous. But there's also the following: Let $g: \mathbb{Q} \to \mathbb{R}$ be given by
\begin{align*}
g(x) & = \begin{cases}
0, & x < \sqrt{2} \\
1, & x > \sqrt{2} .
\end{cases}
\end{align*}
Then $g$ is continuous on $\mathbb{Q}$, but does not extend to a continuous map on $\mathbb{R}$. So my question is: Is there a way to determine if a map $g : \mathbb{Q} \to \mathbb{R}$ extends to a continuous map $f: \mathbb{R} \to \mathbb{R}$? Thanks.",['general-topology']
1398603,Is there any $F \in \mathscr{F}$ such that $\mu(F)=x$?,"Let $ (\Omega,\mathscr{F},\mu)$ be a probability space such that $\mu$ is non-atomic, and fix $x \in [0,1]$. Is it true that one can find $F \in \mathscr{F}$ for which $\mu(F)=x$? And what if $\mu$ is only finitely additive? Ps. Here we recall that $\mu$ is non-atomic if $\mu(X)>0$ for some $X \in \mathscr{F}$ implies that there exists $Y \in \mathscr{F}$ for which $0<\mu(Y)<\mu(X)$.","['probability-theory', 'probability', 'measure-theory']"
1398613,Proof of $\sum_{d|n} {\tau}^3(d)=\left(\sum_{d|n}{\tau}(d)\right)^2$ (not standard proof),"I am trying to prove that $\sum_{d|n} {\tau}^3(d)=\left(\sum_{d|n}{\tau}(d)\right)^2$ without using the fact that $\tau$ is multiplicative and products/sums of multiplicative funcions are also multiplicative ( here you can find multiple arguments that show this result using such properties). My approach was the following: LHS counts the cardinality of the following set: $$\bigcup_{d| n}\big\{(x,y,z,d)\ /\ x,y,z|d \big\}  $$ and RHS counts this one $$\big\{(x,d,y,e)\ / \ x|d; \ y|e; \ d,e|n\big\}$$ I tried to establish an explicit bijection between those sets, but I already spent enough time and my biggest efforts on it, unsuccesful. Any idea or hint you can give me? Thanks in advance!","['combinatorial-proofs', 'arithmetic-functions', 'number-theory', 'elementary-number-theory', 'combinatorics']"
1398618,Any correlation to Merten's function?,"Here is a plot of partial sums of Liouville Lambda and Moebius Mu: Notice the differences (in green) are tantalizingly close to $-n^{\frac{1}{2}}$. Does this have any correlation to Merten's function? Edit $$M(x)=O(x^{
\frac{1}{2}+\epsilon})$$ for some $\epsilon<\frac{1}{2}$ Edit tested to 50 million with $\epsilon=\frac{1}{32},$ no exceptions.","['riemann-hypothesis', 'number-theory', 'experimental-mathematics', 'mobius-function']"
1398634,Finding a perpendicular vector from a line to a point,"Let's say I have an arbitrary linear line described by $y=mx+b$. I also have a point $P(x_1,y_1)$ that is not on that line. I suppose $P$ can be anywhere relative to the line. How can I find the vector $v$ the stretches from the point to the line (and is perpendicular to it)? Here's what I tried: I figured that the difference in the $x$ and $y$ components ($\delta y$ and $\delta x$) basically describe a vector twice as large as $v$ but in the same direction. So I tried finding $\delta x$ and $\delta y$ by the following: $\delta y=y_1-(m\cdot x_1 +b)$ $\delta x = x_1-(y_1/m - b/m)$ The vector V is then $[\delta x/2, \delta y/2]$. I divide by two because I figure the vector described by $[\delta x, \delta y]$ goes all the way to the top left corner of the imaginary rectangle that is completed by $\delta x$ and $\delta y$. Am I correct? If not, why? Regardless if I am, is there an alternative or smarter way to accomplish this? I would appreciate any input here.","['geometry', 'matlab', 'vectors']"
1398639,definition of trapezoid,"In my country, for many years, trapezoid is defined as such in the textbooks: a quadrilateral with only two parallel sides. But today, referring to foreign sources, someone told me that: a quadrilateral with at least two parallel sides. Wikipedia uses a similar definition. I want to know that does it make sense for a trapezoid to have more than one pair of parallel sides? Does it make sense for a quadrilateral to have for example, three parallel sides? What's wrong with the former definition?","['geometry', 'quadrilateral']"
1398665,"Let $a,b,c>0$ so that $a+b+c=1$...","Let $a,b$ and $c$  be positive real numbers such that $a+b+c=1$. Prove that $$\frac{a}{b}+\frac{b}{a}+\frac{b}{c}+\frac{c}{b}+\frac{c}{a}+\frac{a}{c}+6\geq 2\sqrt{2}\left ( \sqrt{\frac{1-a}{a}}+\sqrt{\frac{1-b}{b}} + \sqrt{\frac{1-c}{c}}\right )$$ What I think is we should replacing $1-a ,1-b ,1-c$ with $b+c,c+a, a+b$ respectively on the right hand side, I have no idea if this is true, any help will be appraciated.","['contest-math', 'algebra-precalculus']"
1398673,When is the image of a $\sigma$-algebra a $\sigma$-algebra?,"Let $(E,\mathcal{E})$ and $(F,\mathcal{F})$ be measurable spaces and $f:E \rightarrow F$ with $f$ $\mathcal{E}/\mathcal{F}$ measureable. When is $f(\mathcal{E})$ a $\sigma$-algebra? I am aware that the inverse image of a $\sigma$-algebra is a $\sigma$-algebra. It is obvious that $f$ must be surjective. Also since $f(\bigcup_{n \in \mathbb{N}}A_n)= \bigcup_{n \in \mathbb{N}} f(A_n)$ and $f(\emptyset ) = \emptyset $, $f(\mathcal{E})$ is $\sigma$-algebra iff for each $A \in \mathcal{E}$ there exists $A' \in \mathcal{E}$ with $f(A')=f(A)^C$ ($f(\mathcal{E})$ is closed under complements). Is there anyway of simplifying this condtion?",['measure-theory']
1398696,Why does L'Hôpital's rule work for sequences?,"Say, for the classic example, $\frac{\log(n)}{n}$, this sequence converges to zero, from applying L'Hôpital's rule.  Why does it work in the discrete setting, when the rule is about differentiable functions? Is it because at infinity, it doesn't matter that we relabel the discrete variable, $n$, with a continuous variable, $x$, and instead look at the limit of  $\frac{\log(x)}{x}$? But then what about the quotients of sequences that go to the indeterminate form $\frac{0}{0}$?  Why is it OK to use L'Hôpital's rule, as $n$ goes to zero? I haven't found anything on Wikipedia or Wolfram about the discrete setting. Thanks.","['calculus', 'limits', 'real-analysis', 'indeterminate-forms', 'convergence-divergence']"
1398698,$\sum_{n=1}^\infty \frac{1}{(n^2-1)!} - \sum_{n=1}^\infty \frac{1}{(7n+1)!}$ is almost $1+1/6$,"I've recognized, that
$$\mathcal{S} = \sum_{n=1}^\infty \frac{1}{(n^2-1)!} - \sum_{n=1}^\infty \frac{1}{(7n+1)!} \approx 1.1666666666666666666657785992648796$$
which is almost $1+1/6$. I think it is not a mathematical coincidence , but I'm not sure what are behind the scences. Why is this value almost $1+1/6$? In the first terms of the sequences $n^2-1$ [$A005563$ ] and $7n+1$ [$A016993$ ] the terms $8$ and $15$ coincide. Furthermore $$\sum_{n=1}^\infty \frac{1}{(n^2-1)!} \approx 1.166691468254732970341437561639 $$ and $$\sum_{n=1}^\infty \frac{1}{(7n+1)!} \approx 0.000024801588066303675658962374$$ Are there a family of this type of identities? Also would be nice to see the exact value of $1+1/6-\mathcal{S}$ which is approximately
$$
8.880674017870608390962304909410175868736976 \cdot 10^{-22}
$$","['closed-form', 'sequences-and-series', 'calculus', 'recreational-mathematics']"
1398716,"A plane contains a set of marked points, such that any three can be covered by a unit disk. Prove that the entire set can be covered by a unit disk.","A set of points is marked on the plane, with the property that any three marked
  points can be covered with a disk of radius 1. Prove that the set of all marked
  points can be covered with a disk of radius 1. This question is from the 2009 Canada National Olympiad. I would be grateful for any suggestions on: how to prove by an alternative method, e.g. probabalistic how to streamline the proof how to make the proof more rigorous Formulation Prove the worst case where there is at least one limiting triangle that could not be covered if it were scaled up in size by any factor exceeding 1. That is, apply a uniform scaling to the set of points until there is at least one limiting triangle. The notion of limiting triangle is important because there is then a unique circle that covers the triangle; the circle will not cover the entire triangle if it is translated by any nonzero amount in any direction from the covering position. We distinguish two cases: There is a limiting triangle(s) that is right or obtuse All limiting triangle(s) are acute Case 1: Limiting Triangle is Right or Obtuse By comparison with a right triangle whose longest side is on the diameter of the covering circle, we see that any triangle with a diametral side will have its other vertex outside the circle if and only if the angle at this vertex is $<90^\circ$, and will have its other vertex on or inside the circle otherwise. So a right or obtuse triangle can be covered by a unit circle if and only if its longest side is $\le 2$ units in length. The longest side is the sole limiting feature of a non-acute triangle. In the diagram below, $AB$ is the longest side and $\angle ACB = 90^\circ, \angle AC'B > 90^\circ, \angle ADB < 90^\circ$. Then if any other point (say $D$) is outside the circle with diameter AB, we have a triangle $\Delta ABD$ that cannot be covered by a unit circle (because $AB$ is limiting), which contradicts the original stipulation that any three points forms a triangle that is coverable. Hence, there are no points outside the unit circle with $AB$ diametral. This proves case 1. What suggestions for making the above argument more rigorous? Case 2: Limiting Triangle is Acute When the limiting triangle is acute, its circumcenter will coincide with the center of the covering circle. We first need to prove: Lemma 1 : If a triangle is acute and all its vertices lie on a circle, then no larger circle can cover the triangle. With reference to the diagram below, for an acute triangle the circumcenter is inside the triangle. If the covering circle is translated in a direction that is not aligned with, say, $AB$, then it will need to move in a general direction away from vertex $C$, as indicated by the arrows. It is impossible to satisfy all three sets of requirements (relative to all sides), so the covering circle is unique and the triangle limiting. This argument relies on the circumcenter being inside the triangle, and hence does not work for obtuse triangles (nor should it) . This proves the lemma. What suggestions for making the above argument more rigorous, or streamlining it? Now suppose that we have a limiting triangle $\Delta ABC$ and a point $D'$ outside the covering circle for $\Delta ABC$, as per the next diagram. Construct point $D$ as the intersection of $AD'$ with the circle. Then show that a triangle with vertex $D$ is limiting, so that the analogous triangle with vertex $D'$ cannot be covered. Prove by contradiction. Suppose WLOG that $D\in\text{arc}\stackrel{\Large\frown}{BC}$. Suppose also that perpendiculars to $AB$ and to $AC$ cross at point $G$ inside the circle, and that $D\in\text{arc}\stackrel{\Large\frown}{FE}$ as shown, so that it not possible to find an acute (or right) triangle having $D$ as one vertex and having one of the sides of $\Delta ABC$ as a side. But in quadrilateral $ABGC$, for one pair of opposite angles $\angle ABG = \angle ACG = 90^\circ$, so $ABGC$ is a cyclic quadrilateral. So point $G$ is on the same circle as points $A,B,C$ thereby showing that points $E,F,G$ coincide. Hence, it is not possible to have $D\in\text{arc}\stackrel{\Large\frown}{FE}$, so $D$ must form an acute or right triangle with one side of $\Delta ABC$, e.g. if $D\in\text{arc}\stackrel{\Large\frown}{BG}$ we have acute triangle $\Delta ADC$. Then $\Delta ADC$ is limiting, so $\Delta AD'C$ cannot be covered as required. Otherwise, $D\in\text{arc}\stackrel{\Large\frown}{GC}$ and the argument is similar, or points $D$ and $G$ coincide and $\Delta ACD$ is a right triangle, so we then proceed as in Case 1. This proves Case 2.","['contest-math', 'geometry', 'proof-verification']"
1398722,Complex irreducible representations of the Klein 4 group,"I wrote an answer to the following question. Can someone please verify it? Completely and explicitly describe, up to isomorphism, the set of all complex irreducible representations of the Klein 4 group We know that the Klein 4 group is isomorphic to $\mathbb{Z}_2 \times \mathbb{Z}_2$. Firstly, we have the trivial representation, given by the homomorphism $\psi(g) = 1$ for all $g \in \mathbb{Z}_2 \times \mathbb{Z}_2$. Secondly, we have the representation given by the homomorphism $\psi(0,0) = 1, \psi(0, 1) = -1, \psi(1, 0) = 1, \psi(1,1) = -1$. Thirdly, we have the representation given by the homomorphism $\psi(0,0) = 1, \psi(0, 1) = 1, \psi(1, 0) = -1, \psi(1,1) = -1$ Lastly, we have the representation given by the homomorphism  $\psi(0,0) = 1, \psi(0, 1) = -1, \psi(1, 0) = -1, \psi(1,1) = 1$ We can verify that the characters of these representations are orthonormal, and hence irreducible.","['abstract-algebra', 'solution-verification', 'group-theory', 'representation-theory']"
1398764,Does orthogonal decomposition characterize direct sums in Hilbert space?,"Let $H$ be a Hilbert space with inner product $(\cdot, \cdot)$. I know that if $M$ is a closed subspace of $H$, then $H$ can be written as the direct sum $M \oplus M^\perp$, where $M^\perp$ stands for the orthogonal complement of $M$. I would like to know if this decomposition above essentially describes all direct sums in Hilbert spaces: If $M,N$ are closed subspaces of $H$ with $H$ being the direct sum $M \oplus N$, then is it true that $N = M^\perp$. So far I've tried using a direct proof that's not really getting me anywhere: take $n \in N$ and show that $(n,m) = 0$ for $m \in M$ arbitrary. Without knowing any specific about $M$ and $N$, I am not able to move any further. Is there some basic fact about the inner product that makes this all work? Or is the question deeper? Hints or solutions are greatly appreciated.","['hilbert-spaces', 'functional-analysis']"
1398769,Dual Space Isomorphism,"If $V$ is a finite dimensional real vector space. Let 
$$
V^* = \{f: V \to \mathbb{R} : f ~\text{is linear}\}
$$
(Note $V^*$ is called the dual space of $V$.) Prove the vector spaces $V$ and $V^*$ are isomorphic. I have attempted this question by trying to prove the dimensions of both vector spaces are equal. 
$$
V = Span(v_1,\ldots,v_n)
$$
$f_i$ is an element of $V^*$ and $f_i(v_j) = 1$ when $f_i = v_i$ and $0$ otherwise and now I want to show $V^*$ is spanned by $\{f_1,\ldots,f_n\}$. Can somebody please help me out? Is this even possible or am I way off?","['vector-space-isomorphism', 'vector-spaces', 'linear-algebra']"
1398789,Number of independent components of a unitary matrix,"By definition, a $n$ dimensional unitary matrix $U$ satisfies the condition
$U^{\dagger}U=I$,
and
$UU^{\dagger}=I$.
I'd like to ask if these two equations are independent. If so, there will be $n^2$ independent equations of constrain, which is equal to the number of independent components of a general $n$ dimensional matrix. This is obviously impossible. If not, how to prove it?","['unitary-matrices', 'linear-algebra', 'matrices']"
1398799,Negative binomial maximum likelihood,"The pdf of a negative binomial is $$θ(X=x)= \left( \begin{array}{c}
x+j-1  \\
x  \end{array} \right)(1-θ)^xθ^j,$$ How would I create the likelihood of this function in order to maximize θ?And how does the likelihood change if there is n observations vs. 1 observation? So far, I have that the likelihood is ∏ (j + x − 1 C x) θ^j (1-θ)^x which is simplified to (through the derivative of the log-likelihood) =jn lnθ+∑X ln(1-θ) Meaning that jn/θ=∑X/1-θ I solved for theta and have: θ-hat= jn/(jn+∑x) Is there something wrong? If so, where? Something extra: (The alternative pdf is $$P(X=x|j,θ)= \binom{x-1}{j-1}θ^{j}(1-θ)^{x-j}$$ would it yield the same likelihood?)","['probability', 'statistics']"
1398810,Proving $\lim\limits_{x \to \infty} xf(x)=0$ if $\int_{0}^{\infty}f(x) dx$ converges.,"Let $f(x)$ be a monotone non-increasing function such that $\int_{0}^{\infty}f(x) dx$ converges. Prove: $\lim\limits_{x \to \infty} xf(x)=0$. My question is, why can't I simply contradict any other possibility by using the Integral Limit Comparison Test with $1\over x$? I am, after all, to show that $f(x)=o(x)$ as $x\to \infty$. I really don't understand why monotony is crucial here. I could use some help.","['calculus', 'integration']"
1398849,Countable product of first countable Spaces is first countable,"Suppose $X_i$ are first countable Space , $X = \prod_{i=n}^{\infty} X_i $, Then $X$ is first countable  Space in product topology. Is it first countable in Box topology. Is uncountable product of first countable space is first countable I have tried : Let  $ x \in X$, we shall show that $X$ has a local countable basis at $x$. we can assume that $x = \prod_{i =1}^{\infty} x_i$, where $x_i \in X_i$. Since $X_i$ is first countable space , then there is a local countable basis at $x_i$ says $B_{x_i} = \{ B_{x_i}(j) | j \in \mathbb N \} $ Define $W_n = \{ \prod_{i=1}^n B_{x_i}(j) | j \in \mathbb N \}  = \{ B_{x_1}(j_1) \times B_{x_2}(j_2 \times \dots  \times B_{x_n}(j_n) \ \  | \ \ j_i \in \mathbb N\} $ , Clearly $W_n$ is countable. Let $W$ be the set of all subsets of the product space $X$ of the folowing form : $\prod _{j=1}^\infty V_j$ , where there is some $n \in \mathbb N$ such that $\prod_{j=1}^n V_j \in W_n$ and for all $j > n , V_j = X_j$ we shall show that $W$ is a locall countable basis at $X$ Clearly $W$ is countable Let $G$ be an open set containg $x$. So we can assume that $G = \prod_{i=1}^n G_i$, there exist some $ n \in \mathbb N$ such that $G_i$ is open in $X_i$ for all $i \leq n$ and $G_i = X_i$ for all $i >1$. Since $B_{x_i} $ is a local countable basis at $x_i$. So for $x_i \in G_i$ for all $ i \leq n$, there is some $B_{x_i}(j_i)$ such that $ x_i \in B_{x_i}(j_i) \subset G_i$ for all $ i \leq n$. let $V = \prod_{i=1}^\infty V_i$ such that $\prod_{i=1}^n V_i = \prod_{i=1}^n B_{x_i}(j_i)$ and $V_i = X_i $ for all $i>n$ Thus $V \in W_n$ and $V \subset G$, Thus $X$ is first countable. Please see my solution and tell me $X$ is first countable in box topology and give me a counter example if collection $\{ X_{\alpha} \}$ is uncountable, then $\prod X_{\alpha} $ is not first countable in  product toplogy. Thank you",['general-topology']
1398910,Show that $\mu(f)\mu(1/f)\geq\mu(\Omega)^2$,"Prove that $\mu(\Omega)^2\leq\int f \,d\mu\int\frac{1}{f}\,d\mu$. I don't know if that what I did is correct or if it will help to solve the problem, but here it is: Using the Hölder inequality $\mu(\Omega)=\int_{\Omega} 1 \,d\mu=\int_{\Omega} |f.\frac{1}{f}|\,d\mu\leq (\int_{\Omega}|f|^1\, d\mu)^{\frac{1}{1}}(\int_{\Omega}|\frac{1}{f}|^1\, d\mu)^{\frac{1}{1}}=
\int_{\Omega}f\, d\mu\int_{\Omega}\frac{1}{f}\, d\mu$. I stopped here.","['lebesgue-integral', 'lp-spaces', 'measure-theory', 'integration']"
1398918,How to expand $(x_1 + x_2 + x_3 + x_4 + x_5 +\cdots+x_n)^{2}$,How to expand $(x_1 + x_2 + x_3 + x_4 + x_5 +\cdots+x_n)^{2}$. Is their any general formula for this? Thanks,['algebra-precalculus']
1398928,How is the epsilon-delta definition of continuity equivalent to the following statement?,"Claim: A function $f: \mathbb{X} \to \mathbb{Y}$ is continuous if given any open set  $\mathbb{U} \subseteq \mathbb{Y}$ the inverse image $f^{-1} (\mathbb{U}) \subseteq \mathbb{X}$ is open. How is this definition intuitively compatible with the $\epsilon-\delta$ definition of continuity? Furthermore, on an application level, how is the above claim applicable in proving continuity of a function? i.e. is it useful for say proving that $f(x) = e^x$ is continuous?","['definition', 'metric-spaces', 'continuity', 'general-topology', 'epsilon-delta']"
1398929,for which positive integer $m$ does $(ab)^{2015} = (a^2 + b^2)^m$ have positive integer solutions [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question For which positive integers $m$ does the equation
$(ab)^{2015} = (a^2 + b^2)^m$
Have positive integer solution ?","['elementary-number-theory', 'algebra-precalculus']"
1398964,The limit points of $\{\sin (n+n^2)\mid n\in\mathbb N\}$,"We can prove that  $\exists \{c_i\}_{i=1}^{\infty} \subseteq \mathbb N$ and $c_1<c_2<c_3<...$ such that $\lim_{i\rightarrow \infty}\sin (c_i^{\alpha})=c$, $\forall c\in [-1,1]$,where $\alpha $ is a positive rational number. But what about the limit points of { $\sin(n+n^2)\mid n\in N\} $? Is it also the closed interval $[-1,1]$? Furthermore, what about $\sin \bigg(\sum_{i=1}^ma_in^{i}\bigg)$, where all coefficients $a_i$ are rational numbers?","['analysis', 'cauchy-sequences', 'real-analysis']"
