question_id,title,body,tags
1066347,Triangle of maximum perimeter for a given area,"What type of triangle has the maximum perimeter for a certain area? Suppose I start with a rectangle of that area (axb=Z). I can stretch one dimension of the rectangle until infinity, reducing the other side, and decompose it into two halves that create an isosceles triangle of the same area but larger perimeter (since the diagonal will always be greater than b, therefore larger than 2b and the base will be equal (a/2)x2). Is this the way to the maximum perimeter possible or is there another construction that I'm missing?","['geometry', 'trigonometry']"
1066363,Probabilistic Proof of $\prod\limits_{i=1}^\infty\cos\left(\frac t{2^i}\right)=\frac{\sin t}t$ [duplicate],"This question already has answers here : Finding the limit $\lim \limits_{n \to \infty}\ (\cos \frac x 2 \cdot\cos \frac x 4\cdot \cos \frac x 8\cdots \cos \frac x {2^n}) $ (3 answers) Closed 6 years ago . Using probability methods (characteristic function?) prove 
$$\prod_{i=1}^\infty\cos\left(\frac t{2^i}\right)=\frac{\sin t}t$$
I know what is characteristic function but I have no idea how use it in this task. I will grateful for help.","['measure-theory', 'probability-theory', 'trigonometry', 'real-analysis', 'probability']"
1066366,Proof that $\cos(\pi/4)=\frac{\sqrt2}{2}$,"Normally I just look up or remember that $\cos(\pi/4)=\frac{\sqrt2}{2}$, or type ""$\cos(\pi/4)$"" into WolframAlpha to check the answer. But what about the first time someone wanted to know what $\cos(\pi/4)$ was? How could they find out before trig tables and WolframAlpha? How can you prove that $\cos(\pi/4)=\frac{\sqrt2}{2}$?","['geometry', 'trigonometry', 'calculus']"
1066377,Rolle's Theorem with roots,"Let $f : [a, b] \to \Bbb R$ be $n$ times differentiable and have $n+1$ distinct roots (i.e. solutions of $f(x) = 0$ ) in $[a,b]$ . Show that there is an $x \in [a, b]$ s. t. the $n^{\text{th}}$ derivative of $f$ has a root in $[a,b]$ . I know that you need to use Rolle's Theorem for this problem. Do I prove by induction?
So for the base case $(n=1)$ then $f$ has $2$ distinct roots, then by Rolle's Theorem $f'(x)$ must have a root? How would I do the inductive case? Thanks",['derivatives']
1066382,Solve $x^7-5x^4-x^3+4x+1=0$ for $x$,"Solve for $x$ $$x^7-5x^4-x^3+4x+1=0$$ This equation has been bugging me since the past few days. I have found, using the Rational Root Theorem that $x=1$ is a root of this equation. However, after dividing, I cannot solve the six degree equation thus generated. I have also tried factorizing the equation, but it's not working.","['algebra-precalculus', 'roots', 'polynomials']"
1066386,Study the convergence of $\sum_{n=1}^{\infty}{\prod_{k=1}^{n}{\sin (k)}}$,Can you help me to study the convergence of the following series: $$\sum_{n=1}^{\infty}{\prod_{k=1}^{n}{\sin (k)}}$$ Thanks.,"['sequences-and-series', 'convergence-divergence', 'calculus', 'products']"
1066387,Is this question a pigeon hole question?,"How many integers must you pick in order to be sure that at least two of them have the same remainder when divided by 15? Explain. It seems like this is similar to the birthday pigeon hole example. I really want to understand this question as I have been staring at it for quite some time.  So please, just hints if possible to get me started.","['pigeonhole-principle', 'discrete-mathematics']"
1066401,"Unusual pattern in the distribution of primes of form $4n\pm1, 6n\pm 1$ [Chebyshev's bias]","I have recently noticed an unusual pattern in the distribution of odd primes. Each one of the following sets contains approximately half of all odd primes: $A_n=\{4k+1: 0\leq k\leq n\}=\{1,5,9,13,\dots,4n+1\}$ $B_n=\{4k+3: 0\leq k\leq n\}=\{3,7,11,15,\dots,4n+3\}$ $C_n=\{6k+1: 0\leq k\leq n\}=\{1,7,13,19,\dots,6n+1\}$ $D_n=\{6k+5: 0\leq k\leq n\}=\{5,11,17,23,\dots,6n+5\}$ More precisely: Let $P(S)$ denote the number of odd primes in the set $S$ Let $\pi(x)$ denote the number of odd primes smaller than $x$ Then for every sufficiently large value of $n$: ${P(A_n)}\approx{P(B_n)}\approx\frac12\pi(4n+4)$ ${P(C_n)}\approx{P(D_n)}\approx\frac12\pi(6n+6)$ Now, all of this is pretty easy to observe (though probably not so easy to prove). The following facts are subsequently obvious for every sufficiently large $n$ as well: ${P(A_n)}\leq{P(B_n)}\implies{P(A_n)}\leq\frac12\pi(4n+4)\leq{P(B_n)}$ ${P(A_n)}\geq{P(B_n)}\implies{P(A_n)}\geq\frac12\pi(4n+4)\geq{P(B_n)}$ ${P(C_n)}\leq{P(D_n)}\implies{P(C_n)}\leq\frac12\pi(6n+6)\leq{P(D_n)}$ ${P(C_n)}\geq{P(D_n)}\implies{P(C_n)}\geq\frac12\pi(6n+6)\geq{P(D_n)}$ This is because $A_n$ and $B_n$ as well as $C_n$ and $D_n$ are ""complementary"" to each other: The set ${A_n}\cap{B_n}$ is empty, and the set ${A_n}\cup{B_n}$ contains all odd primes smaller than $4n+4$ The set ${C_n}\cap{D_n}$ is empty, and the set ${C_n}\cup{D_n}$ contains all odd primes smaller than $6n+6$ Nevertheless, for almost every value of $n$: ${P(A_n)}\leq{P(B_n)}$ ${P(C_n)}\leq{P(D_n)}$ The graphs and table below provide some empirical evidence: range     | odd primes | cases where either P(A)>P(B) or P(C)>P(D)
-----------|------------|-------------------------------------------
 10000     | 1228       | 0
 100000    | 9591       | 1
 1000000   | 78497      | 239
 10000000  | 664578     | 239
 100000000 | 5761454    | 1940 I would expect primes to be equally distributed between $A_n$ and $B_n$ and between $C_n$ and $D_n$. In other words, I would expect: [Number of primes of the form $4k+1$] $\approx$ [Number of primes of the form $4k+3$] [Number of primes of the form $6k+1$] $\approx$ [Number of primes of the form $6k+5$] But since the empirical evidence above suggests otherwise, my questions are: Is this indeed the case, or do they become equally distributed on a larger range? If this is indeed the case, what research has been conducted attempting to explain it? Thanks","['prime-numbers', 'number-theory']"
1066448,"Is $[0,1]^2 \setminus \{(a,b)\}$ connected?","I am pretty sure that this set is in fact connected but I am struggling to see how to prove it, it is simple to see that $[0,1] \setminus \{x\}$ is disconnected but I can't see how to relate techniques used in that example to this one.","['connectedness', 'analysis']"
1066452,I can't solve this limit without using L'Hospital: $\lim_{x \rightarrow -\infty} e^x \log|x|$,"I am unable to solve this easy limit without using L'Hospital, can you help me and maybe explain how can I solve it? $$\lim_{x \rightarrow -\infty} e^x \log|x|$$","['limits-without-lhopital', 'calculus', 'limits']"
1066456,Summing of factorials to produce perfect cubes,"I was playing around with factorials the other day, and I realized that $4!+5!$ is a perfect square. Perplexed by this result, I started looking for other pairs of factorials that produce a perfect square when added together (unbeknownst to me, I had stumbled across a well-known open problem in number theory). I could only find three: $1!+4!$, $1!+5!$, and $1!+7!$. Since $4!+5!$ seemed like an outlier, I decided to focus on the three which satisfy the formula $n!+1=m^2$. I turned to the main Math.SE chatroom, asking if there were any more, which is when I was informed that this is called Brocard's problem. Since it's a well-known open problem, I decided to put my own spin on it. It has probably been done before, but I can't find anything online. What about the equation $n!+1=m^3$? As far as I know, there is no pair of integers that satisfies this equation. What if the conditions are relaxed? This brings me to the following question I came up with yesterday: How many perfect cubes can be expressed as the sum of two or more unique integer factorials without subtractions, divisions, or multiplications of factorials? Notice I said unique, meaning any factorial cannot appear more than once in a sum. With that in mind, I've only found three:$$ \begin{align}&2!+3!=8=2^3\\&1!+2!+4!=27=3^3\;\;\;\Bbb{and}\\&1!+2!+3!+6!=729=9^3\,.\end{align}$$ Are there more solutions, or are these the only three? Using this link , I've concluded any additional solution must have the factorials add up to be greater than $341^3$. Since I hardly have any experience with programming, I can't go much further on this problem... Any and all help would be greatly appreciated. Note: My question is NOT a duplicate of this one . I'm not restricting my problem to the partial sums $S_n$ of the series $\displaystyle \sum_{k=1}^nk!$.","['factorial', 'number-theory']"
1066465,Prove that $\sum_{n=0}^\infty \frac{(-1)^n}{3n+1} = \frac{\pi}{3\sqrt{3}}+\frac{\log 2}{3}$,Prove that $$\sum_{n=0}^\infty \frac{(-1)^n}{3n+1} = \frac{\pi}{3\sqrt{3}}+\frac{\log 2}{3}$$ I tried to look at $$ f_n(x) = \sum_{n=0}^\infty \frac{(-1)^n}{3n+1} x^n $$ And maybe taking it's derivative but it didn't work out well. Any ideas?,"['sequences-and-series', 'calculus', 'real-analysis', 'pi', 'summation']"
1066479,How to estimate variances for Kalman filter from real sensor measurements without underestimating process noise.,"As the title says, I want to estimate the variances needed for a Kalman filter from real sensor measurements only. For example we can take a temperature sensor, but the solution shall be as generalized as possible. Assume, we cannot accurately influence the sensor input (i.e. we cannot too accurately generate a fixed temperature) or do not want to do this. I need to estimate two variances for the Kalman filter: The measurement noise variance, $\sigma_m$ , which is the inaccuracy introduced by the sensor itself (e.g. fluctuations in power supply or limited measurement resolution). It models the difference between sensor's measurement value and real temperature that is to be measured. The process noise variance, $\sigma_p$ , which estimates the error in our system model. It is dependent on the model, i.e. how exactly it estimates future values from the current state of the Kalman filter. For the temperature sensor, we could model the temperature to be static and we predict the next temperature to be the same as our latest temperature estimation. However, as the real temperature slowly changes over time the filter's prediction is incorrect. Basically, the process noise means: If we have an estimation $e_t\sim N(\mu_e,\sigma_e^2)$ of the real value at time $t$ and we apply our prediction model $f(x)$ which introduces a Gaussian distributed process noise with a variance $\sigma_p^2$, the new estimation will be $e_{t+1}\sim N( f(\mu_e), \sigma_e^2+\sigma_p^2))$. How you can help... I already did some work on this and came to some practical solution. However, there is still an issue that could lead to underestimation of the process noise. But, it would be advisable to only use overestimated values for the Kalman filter. In that case one can use the variance from the filter state to give reasonable information on the accuracy of the current estimation. If you have an idea how to resolve the underestimation problem (see explanations below), please let me know. I didn't study math. So please check my math below for any stupid mistakes ;-) Here is what I came up with so far... Estimation of the measurement noise I model my sensor reading as: $m_t = x_t + e_t$ with $e_t \sim N(0,\sigma_m^2)$, where $m_t$ is the measured value, $x_t$ is the real value in absence of noise and $e_t$ is the measurement noise; whereas $t$ refers to the time. The noise is assumed to be Gaussian distributed without bias (zero mean). I assume that my signal is continuous such that: $\lim_{\delta\to0}(x_{t+\delta} - x_t) = 0$. This means that two real values that are very close in time are equal. Therefore,
$\lim_{\delta\to0} m_{t+\delta}-m_t$ $= \lim_{\delta\to0} ((x_{t+\delta} + e_{t+\delta}) - (x_t + e_t))$ $= \lim_{\delta\to0} ((x_{t} + e_{t+\delta}) - (x_t + e_t))$ $= \lim_{\delta\to0} ((x_{t+\delta} + e_t) - (x_t + e_t))$ $= \lim_{\delta\to0} (e_{t+\delta} - e_t)$ $= e_{t+\delta} - e_t$. Thus, $\lim_{\delta\to0} Var(m_{t+\delta}-m_t)$ $= Var(e_{t+\delta}-e_t)$ $= Var(e_{t+\delta}) + Var(e_t)$. We know that $e_t\sim N(0,\sigma_m^2)$ and $e_{t+\delta}\sim N(0,\sigma_m^2)$ therefore $Var(e_{t+\delta}) + Var(e_t) = \sigma_m^2 + \sigma_m^2 = 2\sigma_m^2$. Resulting in $\hat{\sigma_m^2} = \frac{1}{2}\lim_{\delta\to0} Var(m_{t+\delta}-m_t)$. Hence, assuming we can take measurements very quickly (i.e. a magnitude quicker than the real signal values are usually changing as much as the the measurement noise) we could estimate the measurement noise by $\hat{\sigma_m^2} = \frac{1}{2}\lim_{\delta\to0} Var(m_{t+\delta}-m_t)$. Note, as $\delta$ will never be zero in a real scenario the estimator tends to overestimate the measurement noise, which will be important in the next step. Estimation of the process noise While the estimation of the measurement seems to be straightforward, I've some trouble with the process noise. As already mentioned, it is dependent on the estimation model. The approach that I came up with is to use the following formula that I used to describe what the process noise is: $e_{t+1}\sim N( f(\mu_e), \sigma_e^2+\sigma_p^2))$ We just take one measurement $\mu_m = x_t$ and $\sigma_m^2$ as the estimations for time step $t$, whereas we use the measurement noise $\sigma_m^2$ estimated as described above. Then we should get an estimation like this: $e_{t+1}\sim N( f(x_t), \sigma_m^2+\sigma_p^2))$ We could then take a measurement $x_{t+1}$ at time $t+1$ which should fulfill this equations: $x_{t+1} = f(x_t) + e_{t+1} \iff$ $e_{t+1} = x_{t+1} - f(x_t) \iff$ $Var(x_{t+1} - f(x_t)) = \sigma_m^2 + sigma_p^2 \iff$ $\hat{\sigma_p^2} = Var(x_{t+1} - f(x_t)) - \sigma_m^2$ But, if we use the overestimating estimator $\hat{\sigma_m^2}$ from the last step for $\sigma_m^2$ we will have an underestimating estimator for $\sigma_p^2$: $\hat{\sigma_p^2} = Var(x_{t+1} - f(x_t)) - \hat{\sigma_m^2}$ The Problem: underestimated process noise Meaning, whenever the estimation for the measurement noise $\hat{\sigma_m^2}$ is too high, the estimation $\hat{\sigma_p^2}$ for the process noise will be too low.
In other words: While the estimated mean value of the filter might be very accurate, the estimation of its accuracy will be too optimistic. So if the result would say ""I know the temperature is 23.122... °C with a variance of 0.03232 K²"" you could not rely on this, as the variance given would probably be too low (and in fact should be higher than this). Is there any way to easily resolve this issue? How? PS: Let me know if you noticed any incorrect formulas and/or assumptions.","['parameter-estimation', 'kalman-filter', 'statistics', 'error-propagation', 'bayesian-network']"
1066484,"Given a simple connected bipartite graph $G$ with degree of vertices equal to $k$, where $k\ge 2$. Prove that there is no cut vertex exist in $G$.","Given a simple connected bipartite graph $G$ with degree of vertices equal to $k$, where $k\ge 2$. Prove that there is no cut vertex exist in $G$. Cut vertex $v$ here is a vertex which make the graph induced have number of connected component $>1$ when $v$ is removed. I have tried to prove by contradiction but i have no clue about what contradiction can be obtained. I am quite curious about what the point the graph has to be bipartite is here. I have not come across any place to adopt the property of a bipartite graph so far. Any hints on tackling this problem would be appreciated. Last but not least, thanks for reading. Edited: i have found something","['graph-theory', 'discrete-mathematics']"
1066502,"Proving that $\Phi_{t*}[\mathbb{Y},\mathbb{Z}]=[\Phi_{t*}\mathbb{Y},\Phi_{t*}\mathbb{Z}]$","Let $\mathbb{X},\mathbb{Y}$ be vector fields on $\mathbb{R}^n$. Let $\Phi_t$ denote the flow of $\mathbb{X}$. Define $L_{\mathbb{X}}\mathbb{Y}=[\mathbb{X},\mathbb{Y}]$. You are given that $\displaystyle L^j_{\mathbb{X}}[\mathbb{Y},\mathbb{Z}]=\sum_{k=0}^{j} \binom jk [L^k_\mathbb{X}\mathbb{Y},L^{j-k}_\mathbb{X}\mathbb{Z}]$ and that $\displaystyle \Phi_{t*}\mathbb{Y} = \sum_{j=0}^{\infty}\frac{(-t)^j}{j!}L^j_{\mathbb{X}}\mathbb{Y}$ Show that $\displaystyle \Phi_{t*}[\mathbb{Y},\mathbb{Z}]=[\Phi_{t*}\mathbb{Y},\Phi_{t*}\mathbb{Z}]$ Let $F$ be a diffeomorphism on $\mathbb{R}^n$, define
  $$ \mathbb{X}^i(x)=\frac{\partial F^i}{\partial x^1}(F^{-1}(x)), \mathbb{Y}^i(x)=\frac{\partial F^i}{\partial x^2}(F^{-1}(x))$$
  Show that $[\mathbb{X},\mathbb{Y}]=0$. $\begin{align}
\displaystyle \Phi_{t*}[\mathbb{Y},\mathbb{Z}] &= \sum_{j=0}^{\infty}\frac{(-t)^j}{j!}L^j_{\mathbb{X}}[\mathbb{Y},\mathbb{Z}] \\
&= \sum_{j=0}^{\infty}\frac{(-t)^j}{j!} \left(\sum_{k=0}^{j} \binom jk [L^k_\mathbb{X}\mathbb{Y},L^{j-k}_\mathbb{X}\mathbb{Z}]\right) \\
&= \sum_{l,k=0}^{\infty} \frac{(-t)^{k+l}}{(l+k)!} \binom{l+k}{k}[L^k_\mathbb{X}\mathbb{Y},L^{l}_\mathbb{X}\mathbb{Z}] \\
&= \sum_{l,k=0}^{\infty} \frac{(-t)^{k}(-t)^{l}}{l!k!} [L^k_\mathbb{X}\mathbb{Y},L^{l}_\mathbb{X}\mathbb{Z}] \\
&= [\Phi_{t*}\mathbb{Y},\Phi_{t*}\mathbb{Z}]
\end{align}$ I cannot see how to proceed now. For the last part I assume somehow the first part has been used as I just cannot see how. Please that $[\cdot,\cdot]$ denotes the Jacobi bracket, not the Poisson bracket. So $$ [\mathbb{X},\mathbb{Y}]=\left( \mathbb{X}\cdot \nabla \right) \mathbb{Y} - \left( \mathbb{Y}\cdot \nabla \right) \mathbb{X} $$","['lie-algebras', 'calculus', 'binomial-coefficients', 'differential-geometry']"
1066534,Rings where every subgroup of the additive group is an ideal?,"The rings $\mathbb Z$ and $\mathbb Z/n\mathbb Z$ have the property that every subgroup of the additive group is also an ideal (i.e., every subgroup absorbs multiplication by all ring elements). This is because every element of these rings can be written as the sum of $1$'s, so multiplication is the same as repeated addition. Are there any other rings for which this is true?","['ring-theory', 'abstract-algebra']"
1066557,How to prove that if R is a partial order then also $R^{-1}$ is also a partial order?,"My guess was to divide the problem into 3 cases : prove that  $R^{-1}$ is reflexive, antisymmetric and transitive. To prove that $R^{-1}$ is reflexive , I did: If  $R$ is reflexive, that follows that if $(a, a) \in R$, then $(a, a) \in R^{-1}$. For the 2. case , prove that $R^{-1}$ is antisymmetric, I did like this: Suppose $R$ is antisymmetric, this means that if $(x, y) \in R \land (y, x) \in R$, then $x = y$. But, if $x = y$, then if I replace $y$ by $x$ nothing changes, so $(x, x) \in R$, thus $(x, x) \in R^{-1}$. So, finally, also $(x, x) \in R^{-1}$, and $x = x = y$, hence also $R^{-1}$ is antisymmetric. For the 3. case : Suppose $R$ is transitive. This means that if $(x, y) \in R$ and $(y, z) \in R$, then also $(x, z) \in R$. If $(x, y) \in R$, then $(y, x) \in R^{-1}$ If $(y, z) \in R$, then $(z, y) \in R^{-1}$ If the 2 statements before are true, if $(x, z) \in R$, then $(z, x) \in R^{-1}$ Now we have: $(y, x) \in R^{-1}$ $(z, y) \in R^{-1}$ $(z, x) \in R^{-1}$ Now, we can observe from the 3 statements just above that also $R^{-1}$ is transitive, in fact: If $(z, y) \in R^{-1}$ and $(y, x) \in R^{-1}$, we have also $(z, x) \in R^{-1}$. Is my proof correct?","['elementary-set-theory', 'proof-verification', 'order-theory']"
1066561,Limiting probability that the sum of the values of a die is a multiple of 13,"A fair die is thrown repeatedly. Let $X_n$ denote the sum of the $n$ first throws. I have to find $\lim_{n\rightarrow \infty}P(X_n \text{ is multiple of 13})$. Now follows what I tried, which I don't think is really efficient: We can look modulo 13 and then we have an irreducible Markov chain on a finite state-space which is aperiodic (because for $n>2$ and for all $i,j\in\{1,2,...,13\}$ it is clear that $p_{ij}^{(n)}>0$, this is the $n$-step probability). So by Convergence to equilibrium we have that the asked limit actually exists. Now for calculating it, we have to find an invariant distribution of a matrix of dimensions 13 by 13. The matrix looks like $$\left(\begin{array}{ccccc}
0& 1/6 & 1/6 &1/6 & \dots\\
0&0&1/6&1/6&\dots\\
0& 0&0&1/6&\dots\\
\dots&\dots&\dots&\dots&\dots
\end{array}\right)$$
This is easily done by a computer, but I think this exercise can be done more efficiently.","['probability-theory', 'markov-chains']"
1066604,Are finitely presentable modules closed under extensions?,"If $0 \to A \to B \to C \to 0$ is an exact sequence of modules, and $A$ and $C$ are finitely presentable, then is $B$ finitely presentable? The answer is ""yes"" if we replace modules with groups, as shown here . The answer is also ""yes"" if we replace ""finitely presentable"" by ""finitely generated"": take a set-theoretic splitting of $B \to C$ to view $B$ as $A \times C$ with the addition given by twisting the addition on $A \oplus C$ by a cocyle: then generators for $B$ are given by pairs of generators for $A$ and generators for $C$. When we're working over a Noetherian ring, this means the same goes for finite presentability. How about in non-Noetherian situations? I'm particularly interested in non-commutative rings, especially group rings. The obvious way to get finitely many relations would be to take the relations for $A$, the relations for $C$, and add each relation of the form $(a_i,b_j) + (a_{i'},b_{j'}) = (a_i + a_{i'}, b_j + b_{j'} + \omega(a_i,a_{i'}))$ (where the $a_i$'s and $b_j$'s are our generators and $\omega$ is our cocycle). But this doesn't obviously work because $\omega$ is typically not bilinear. My intuition is that because the obvious approach doesn't work, the answer should be ""no"". But knowing that the answer is ""yes"" for groups makes me less confident.","['modules', 'commutative-algebra', 'noncommutative-algebra', 'abstract-algebra']"
1066650,Number of ways to fill a $2\times n$ grid with $1\times 2$ and $2\times 2$ tiles,"How many ways are there to  fill a $2\times n$ grid with $1\times 2$ and $2\times 2$ tiles? Rotating is allowed. Progress Let $T_n$ be the number of ways; then $T_n = T_{ n-1} + T_{ n-2} + 1 $ (based on removing one of tiles, as in quid's answer).","['induction', 'tiling', 'combinatorics']"
1066687,"Let $X \sim \text{HGeom}(w,b,n)$, what is the distribution of $n-X$?","Let $X \sim \text{HGeom}(w,b,n)$, what is the distribution of $n-X$? The distribution of $X$ (e.g., number of white ($w$) balls in a sample of size $n$) is hypergeometric, so $$P(X=x) = \frac{\binom{w}{x}\binom{b}{n-x}}{\binom{w+b}{n}}.$$ If $X$ is the number of white balls, then $n-X$ must be the number of black balls. Let $Y=n-X$, then $P(Y=y)=P(n-X=y)=P(X=n-y)$, so plugging in, I get $$P(Y=y) = \frac{\binom{w}{n-y}\binom{b}{y}}{\binom{w+b}{n}}$$ Is this a correct proof (not only if the results is correct)? What kind of manipulations are actually allowed within the $P(\dots)$? I'm always tempted to do some stuff like $P(Y=y)=P(n-X=n-x)=P(X=x)$, which is obviously meaningless, but I can't figure out what is formally wrong with it. Why is it allowed to plug in $n-X$ for $Y$, but not $n-x$ for $y$?","['statistics', 'probability']"
1066702,Finding the flow of a pushforward of vector field,"Let $\mathbb{X}$ be the vector field on $\mathbb{R}^2$ given by  $$ \mathbb{X}(x,y) = (y,x). $$ Compute the flow $\Phi_t$ of
  $\mathbb{X}$. Let $F:\mathbb{R}^2\to \mathbb{R}^2$ be the diffeomorphism given by $$ F(x,y) = (y + \sin x, x) $$ Find $F^{-1}$ and compute
  $(F,\mathbb{X})(u,v)$. Let $(u(t),v(t))$ denote the solution of the system of differential equations $$ \dot{u} = \cos v(u-\sin v) + v, \quad \dot{v} = u - \sin
 v. $$ Find an explicit formula for the set of initial conditions
  $(u_0,v_0)$ for which $(u(t),v(t)) \to (0,0)$ as $t \to \infty$. $(1)$ I get that $\displaystyle \Phi_t(x,y)=\left(\frac{x+y}{2}e^t + \frac{y-x}{2}e^{-t}, \frac{x+y}{2}e^t + \frac{x-y}{2}e^{-t} \right)$ $(2)$ I get that $F^{-1}(x,y)=(y,x - \sin y)$ and $F_*X(x,y)=(\cos y (x-\sin y)+y , x -\sin y )$ $(3)$ This is the bit I am stuck on. I cannot see how to use part ii) which strongly resembles the system of differential equations to solve part iii). I think somehow you have to use that I dont think this question should be as difficult as I am finding it. I believe that I am just missing one step. I dont think there needs to be much working done on your behalf. UPDATE: $$\begin{align}
&\Psi_t(x,y)\\ 
&= \left(F \circ \Phi_t \circ F^{-1})(x,y)\right) \\
&= \left(F  (\Phi_t(y, \sin x -y)\right) \\
&= F\left(\frac{y+(x-\sin y)}{2}e^t + \frac{(y-\sin x)-y}{2}e^{-t}, \frac{y+(y-\sin x)}{2}e^t + \frac{y-(y-\sin x)}{2}e^{-t} \right) \\
&= \left(\frac{y+(y-\sin x)}{2}e^t + \frac{y-(y-\sin x)}{2}e^{-t} )+\sin\left(\frac{y+(x-\sin y)}{2}e^t + \frac{(y-\sin x)-y}{2}e^{-t}\right), \frac{y+(x-\sin y)}{2}e^t + \frac{(y-\sin x)-y}{2}e^{-t} \right)
\end{align}$$ Surely this mess cannot be correct???","['ordinary-differential-equations', 'calculus', 'derivatives', 'differential-geometry']"
1066708,"Proving $[L_X,i_Y]=[i_X,L_Y]=i_{[X,Y]}$","Let $X,Y$ be vector fields. $L_X$ is the Lie derivative and $i_X$ is the contraction of a $k$-form. I am really stuck on how you could prove the identity $[L_X,i_Y]=[i_X,L_Y]=i_{[X,Y]}$. Update: I have the definition $L_X \omega = \frac{\partial}{\partial t}|_{t=0} \Phi_t^* \omega$, where $\Phi_t$ is the flow of $\mathbb{X}$. I have not seen the formula $(\mathcal{L}_X\alpha)(V_1, \dots, V_k) = X(\alpha(V_1, \dots, V_k)) - \sum_{i=1}^k\alpha(V_1, \dots, V_{i-1}, [X, V_i], V_{i+1}, \dots, V_k)$.","['differential-forms', 'lie-derivative', 'differential-geometry']"
1066712,Question about sines of angles in an acute triangle,"Let $\triangle ABC$ be a triangle such that each angle is less than $ 90^\circ $ .
  I want to prove that $\sin A + \sin B + \sin C > 2$ . Here is what I have done: Since $A+B+C=180^{\circ}$ and $0 < A,B,C < 90^\circ$ , at least two of $A,B,C$ are in the range 45 < x < 90, without loss of generality, let these angles be $A$ and $B$ . $\sin A + \sin B + \sin C = \sin A + \sin B + \sin(180^\circ-A-B) = \sin A + \sin B + \sin(A+B)$ Since $45^\circ < A,B < 90^\circ$ it follows that $2^{0.5} < \sin A + \sin B < 2.$ Am I near the answer?","['geometry', 'trigonometry']"
1066728,The unit ball in $L^p$,"Let $X$ Consist of two points $a$  and $b$, put $\mu(\{a\})=\mu(\{b\})=1/2$, and let $L^p(\mu)$ be the resulting real $L^p$ space. $\textbf{Identify each real function $f$ on $X $ with the  point $(f(a),f(b))$ in the plane}$, and sketch the unit balls of $L^p(\mu)$, for $1\leq p \leq \infty$. For which $p$ is this unit ball a square? A circle?. The unit ball in $L^p$ is: $$B_1=\{f\in L^p : ||f||_p\leq 1\}=\{(\alpha_1,\alpha_2)\in\mathbb R^2: (|\alpha_1|^p+|\alpha_2|^p)^{1/p}\leq 1 \}$$ (By identification of real functions with points in the plane.) Is correct my description of the unit ball? Thank you all.","['measure-theory', 'real-analysis']"
1066729,Probability of having always flipped more $H$ than $T$ in an infinite coin flip sequence,"A biased coin has probability $p \in [0,1]$ of landing heads ($H$) and hence probability $1-p$ of landing tails ($T$). We will flip this coin infinitely many times, obtaining a sequence $(x_i)_{i=1}^\infty$ of flips, where $x_i \in \{H, T\}$ for $i \in \mathbb{N}$. What is the probability that for all $N \in \mathbb{N}$, $(x_i)_{i=1}^N$ contains strictly more $H$s than $T$s? I've tried using the Ballot Theorem and taking limits, but nothing has seemed to work so far.","['probability', 'combinatorics']"
1066731,Montmort's card matching problem: Distribution of the number of matching cards?,"(Introduction to Probability, Blitzstein and Nwang) Recall de Montmort’s matching problem from Chapter 1: in a deck of n cards labeled 1
  through n, a match occurs when the number on the card matches the card’s position in
  the deck. Let X be the number of matching cards. Is X Binomial? Is X Hypergeometric? Again stuck at a textbook problem that was probability designed for 2 minutes... It's clearly not binomial, as the 'draws' are not independent, but I can't see why it should be hypergeometric. As I understand it, the story behind the hypergeomtric was that there is a urn with black and white balls, we take a sample of size n without replacement and count the number of white (or black) balls we see. But where are the black and white ball analogues in the card matching problem? To get the PMF, I would have guess something like $$
P(X=k) = \frac{\binom{n}{k} !(n-k)}{n!},
$$
where $n!$ is the number of possible card arrangements, $\binom{n}{k}$ the number of possibilities to have $k$ matching cards out of $n$ and the subfactorial $!(n-k)$ the number of possibilities to derange the remaining cards such that there is no additional match. What is the 'Hypergeometric story' behind the card matching problem? How to derive the hypergeometric distribution from the problem?","['statistics', 'probability-distributions', 'probability']"
1066803,Arzela-Ascoli Anthony Knapp Proof,"STATEMENT: (Arzela Ascoli Theorem) If $\left\{f_n\right\}$ is an equicontinuous family of scalar-valued functions defined on a compact Hausdorff space $X$ and if $\left\{f_n\right\}$ has the property that $\left\{f_n(x)\right\}$ is bounded for each $x$, then $\left\{f_n\right\}$ has a uniformly convergent subsequence. Proof: We may assume that there are infinitely many distinct functions $f_n$, since otherwise the assertion is trivial. Let $|f_n(x)|\leq c_x$ for all $n$, and form the product space $C=\prod_{x\in X}\left\{z\in \mathbb{C}\mid |z|\leq c_x\right\} $. The space $C$ is compact by Tychonoff theorem, and we are now assuming that there are infinitely many members of the sequence $\left\{f_n\right\}$ in the space. Let $S$ be the image of the sequences as a subset of $C$. If $S$ were to contain all its limit points, then each $f_n$ would have an open neighborhood in $C$ disjoint from the rest of $S$; these open sets and $S^c$ would form an open cover of $C$ with no finite sub cover, in contradiction to compactness of $C$. Thus $S$ has a limit point $f$ not in $S$. By Lemma 10.47 and the remarks before it, the family $S\cup \left\{f\right\}$ is equicontinuous. Lemma 10.47: Let $\mathcal{F}=\left\{f_\alpha\right\}$ is equicontinuous at $x$ in $X$, then the closure $\mathcal{F}^{cl}$ of $\mathcal{F}$ in the product topology on $\mathbb{C}^X$ is equicontinuous at $x$. QUESTION: How does Knapp conclude that each $f_n$ would have an open neighborhood in $C$ disjoint from $S$.","['real-analysis', 'analysis']"
1066822,Manifold Orientability Definition,"In Shigeyuki Morita's Geometry of Differential Forms , orientability is defined in the following way: If we can assign an orientation to each point on a manifold $M$ in such a way that the orientations as any two sufficiently near points on $M$ are coherent, we say that $M$ is orientable . (Page 48) However, leading up to this definition, it is never explicitly defined what it means that two points have coherent orientations. The only explanation is in the discussion about surfaces: When an orientation is specified at a point, the ""same"" orientation is specified at an arbitrary point in a neighborhood of the point. This is called the coherent orientation . We specify an orientation at a point on a surface, and choose the coherent orientation at each point on a curve starting at the point. If the curve goes back to the starting point, the original orientation may or may not coincide with the orientation propagated along the curve. Now a surface is orientable if the orientation propagated along any curve always comes back to the starting orientation. In this case we can assign an orientation to all points on the surface in such a way that near points have mutually coherent orientations. (Page 46) Page 47 then involves defining orientations at a point $p\in M$ by choosing a basis on the tangent space $T_{p}M$ along with the standard ""right-hand orientation"" of $\mathbb{R}^{3}$ example, but never is it said what it means for orientations to be the ""same"" or coherent between points, or how the orientation of one point specifies one on points in a neighborhood of that point. The closest thing I could think of would be that the existence of an atlas so that the Jacobians of the transition maps between two local charts is positive, as is the definition in do Carmo's Differential Forms and Applications , Page 50. However, the equivalence of these statements is given as a proposition in Morita's text right after the definition of orientability without proof, which does not allow for me to see how the definition is used. Any help with providing an explicit definition of orientations between two points being coherent would be greatly appreciated. Maybe I'm just missing something obvious, and if this is the case, I would very much like to be shown where it is.","['differential-topology', 'differential-geometry', 'definition']"
1066871,"Nakayama's lemma, second version","Let $R$ be a commutative ring with identity, $J$ an ideal that is contained in every maximal ideal of $R$, and $A$ is finitely generated $R-$ module. If $R/J\otimes _R A=0$, then $A=0$. ==================================================================== Nakayama's lemma says that it is enough to show that $JA=A$. Hungerford give two hints : use the exact sequence $0\rightarrow J \rightarrow R \rightarrow R/J \rightarrow 0$ use the natural isomorphism $R\otimes _R A \cong A$ What I know is that $$ J\otimes _R A \rightarrow R\otimes _R A \rightarrow R/J \otimes _R A \rightarrow 0 $$ is exact sequence. Can you help me?","['commutative-algebra', 'ring-theory', 'abstract-algebra', 'tensor-products']"
1066877,Poincare map trouble,"Consider $ X' = F(X)$, $F \in C^1(\mathbb{R}^2)$. Suppose that the system has an orbit $\mathcal{O}_p$ and $\Sigma$ an transversal section in $P$. Show that if
$$\pi^{n+1}(\Sigma) \subset \pi^{n}(\Sigma)$$
and
$$\bigcap_{n \geq 1}\pi^{n}(\Sigma) = \mathcal{O} $$
then $\mathcal{O}$ is Lyapunov asymptotically stable.","['dynamical-systems', 'analysis']"
1066889,"Questions regarding ""integrable systems""","Consider a smooth differential equation on the plane
  $$
x'=g(x,y),\quad y'=h(x,y).
$$
  Suppose there exists a function $D(x,y)$ such that
  $$
(Dg)_x+(Dh)_y=0. 
$$ Then $D$ is an integrating factor and the system is integrable. A quick search for ""integrable system"" on Google returns results not satisfying. Could anyone explain what the last sentence in the argument above means? [Added:]
The question is motivated by reading a paper about the Bendixson-Dulac Theorem . In particular, $$
g(x,y)=ax+bx^2+cxy,\quad h(x,y)=dy+exy+fy^2
$$ and $D(x,y)=x^ry^s$ for some $r,s$. [Added:] I asked this question in MO. I don't understand though, there is an answer there: $X=g\partial_x + h\partial_y$ is the vector field whose flow lines are wanted. $\omega=hdx - gdy$ is a 1-form with kernel the span of $X$. Also $D\omega$ has kernel the span of $X$ for any function $D$ which does not vanish anywhere. If $d(D\omega)=0$ (this is your condition) then $D\omega$ is a closed 1-form, thus exact on simply connected sets. So $D\omega = dF$ for a function $F$ which can easily be computed by line integrals.
  Thus the wanted flow lines are contained in the level sets of $F$. Finally,
  the time dependence of the flow has to be computed extra. I would really appreciate it if anyone could explain what that answer means (in a more ""elementary"" way) here.",['ordinary-differential-equations']
1066898,Find a function in $L^p(\mathbb{R})$ only for $p=4$ [duplicate],"This question already has answers here : Is it possible for a function to be in $L^p$ for only one $p$? (4 answers) Closed 9 years ago . I'm having trouble with this problem from an old analysis qual:  Find a function $f$ such that for $p\in (1,\infty)$, $f$ is in $L^p(\mathbb{R})$ only when $p=4$.","['lebesgue-integral', 'measure-theory', 'lebesgue-measure', 'real-analysis']"
1066921,"System of equations $x^2=y^3, x^y=y^x$","Solve the system of equations $x^2=y^3, x^y=y^x$ in positive real numbers. Taking $\ln$ of the second equation, we have $\ln x/x=\ln y/y$. This function is increasing in $(0,e)$ and decreasing in $(e,\infty)$. For any value of $x\neq e$, we can find a unique value of $y$ such that $x^y=y^x$. But how can we find a closed form to substitute into $x^2=y^3$?","['algebra-precalculus', 'systems-of-equations']"
1066926,How many distinct integer solutions does the inequality $|x_{1}|+|x_{2}|+...+|x_{n}| \leq t$ have?,"How many distinct integer solutions does the inequality  $|x_{1}|+|x_{2}|+...+|x_{n}| \leq t$ have? We know that:
$x_{i} \in Z,\ \forall i \ 0\leq i \leq n \ and \ t\geq0.\ $ I know that if we have this type of equation:
  $x_{1}+x_{2}+...+x_{n} = t$ where 
  $x_{i} \in Z \ and \ x_{i}\geq 0 \ \forall i\ \ 0\leq i \leq n. $
  The number of distinct integer solutions will be 
  $_{t+n-1}C_{n-1}$ where $_{n}C_{k} = \frac{n!}{k!(n-k)!}$ (Stars and bars (combinatorics)) Then for this $|x_{1}|+|x_{2}|+...+|x_{n}| = t$. I think the number of distinct solutions will be 
$_{t+n-1}C_{n-1} * 2^n $(each of $x_{i}$ can be negative or positive), but this is wrong answer, because I've considered the solution where $x_{i} = 0 \ and \ x_{j} > 0 \ i \ne j$ twice and the solution $x_{i} = 0, x_{j} = 0 \ and \ x_{k} > 0 \ i \ne j \ i\ne k \ j\ne k$ four time ..... this is my mistake: $0 = 0*-1 = 0*+1$ Maybe, you know how to find out the number of solutions for this inequality without solving this problem for each of equation ($|x_{1}|+|x_{2}|+...+|x_{n}| = t_i \ 0\leq t_i\leq t \ and \ t_i \in Z$). Do you have any idea how to solve this? Thank you for your time.","['discrete-mathematics', 'calculus', 'abstract-algebra', 'linear-algebra', 'combinatorics']"
1066944,How do the answers to combinatorial problems change if instead of $4$ different objects we have $4$ identical ones?,"I think I did the first parts of these correctly, but I really don't know about the last part? Could I just divide all my previous answers by $4!$ If you have $4$ children, $8$ unique fruit, and $8$ identical candy bars. 1: how many ways can $8$ fruit be distributed among $4$ kids. There are no restrictions. (is this $4^8$ ) 2: how many ways can you distribute the fruit if you have to give at least $1$ to each kid. (Is this $4!\cdot\binom84$ ) 3: how many ways can you give candy bars to the kids. there are no restrictions. (Is this $\binom{8+4-1}{4-1}$ ) 4: how many ways can you give out the candy bars if each kid has to get $1$ . (give each kid $1$ bar, and do the same as problem $3$ ?) How would $1 - 4$ change if the kids were replaced by $4$ identical bowls?","['discrete-mathematics', 'combinatorics']"
1066950,"Law of sines: uniform proof of Euclidean, spherical & hyperbolic cases","There is a unified formulation of law of sines which is true in all 3 constant curvature geometries (Euclidean, spherical, hyperbolic):
$$
\frac{l(a)}{\sin\alpha}=
\frac{l(b)}{\sin\beta}=
\frac{l(c)}{\sin\gamma},
$$
where $l(r)$ is the circumference of a circle of radius $r$. Is there a ‘uniform’ proof that works in all 3 geometries? Comments and thoughts Of course, spherical law of sines implies Euclidean law by taking limit $R\to\infty$ and hyperbolic law by analytic continuation. One may argue that this is a unified proof. Still, it would be nice to have one argument applicable in each of 3 geometries. One approach is to try to find a geometric meaning of this ratio. The answer in the Euclidean case is well-known ($\approx$circumradius), but it seems that there is no simple  answer in either hyperbolic or spherical case. In all 3 geometries the law of sines can be deduced from the law of cosines. Unfortunately (1) I don’t know a nice unified formulation of law of cosines; (2) this deduction uses some not very enlightening computation — that magically fits together with a completely unrelated computation of the circumference of a circle to give the unified formulation mentioned above…","['hyperbolic-geometry', 'geometry', 'spherical-geometry']"
1066963,Theorem 4.22 from baby Rudin: continuity and connectedness,"I have some parts that I don't understand from the given proof. 
The theorem is: If $f$ is a continuous mapping of a metric space $X$ in to a metric space $Y$, and if $E$ is a connected subset of $X$, the $f(E)$ is connected. For the proof we assume on the contrary that $f(E)=A\cup B$, where $A$ and $B$ are nonempty separated subset of $Y$. Then we put $G=E\cap f^{-1}(A)$ and $H=E\cap f^{-1}(B)$ My questions are: 1) How can I get the intuition to set up like this? 2) Why isn't $G$ just $f^{-1}(A)$ and $H$ just $ f^{-1}(B)$?
We take $f^{-1}$ then $E=f^{-1}(A\cup B)$, then $E=f^{-1}(A) \cup f^{-1}(B)$. I think I definitely missing some important idea or fact.","['general-topology', 'continuity', 'real-analysis', 'analysis', 'connectedness']"
1066973,Solving $y'(x)\left(4-3y(x)x^2\right)=4x$,"Solve the differential equation
  $$y'(x)\left(4-3y(x)x^2\right)=4x$$ I would appreciate some help with this problem.",['ordinary-differential-equations']
1066999,Abstract Varieties,"Hartshorne does not seem to bring this concept up so far in his AG book but I am guessing that one may define an ""abstract variety"", in a similar way as one defines an abstract manifold from DG. When we study varieties we care about two things about them. First, the topology on the variety and, secondly, the regular functions defined on them (or their open subsets). Thus, perhaps, we can define an abstract variety to be a topological space $X$ together with a collection of functions $X\to k$ which we call ""regular"". Why is this a useful concept, assuming we can define it? Consider the product $\mathbb{P}^n \times \mathbb{P}^m$ with the Segre embedding $\sigma$ into $\mathbb{P}^{nm+n+m}$. I find it really annoying that if I want to work with the product, $\mathbb{P}^n \times \mathbb{P}^m$, which is pretty easy to grasp, I instead have to work with $\sigma( \mathbb{P}^n \times \mathbb{P}^m) $. Which is conceptually more difficult. What if we use the bijection of sets, $\sigma: \mathbb{P}^n \times \mathbb{P}^m \to \sigma (\mathbb{P}^n \times \mathbb{P}^m)$ and par transport de structure onto the set $\mathbb{P}^n \times \mathbb{P}^m$? We define the topology on $\mathbb{P}^n \times \mathbb{P}^m$ by pulling back the open sets. And we define that a function $f:U\to k$, where $U\subseteq \mathbb{P}^n \times \mathbb{P}^m$ is ""regular"" if and only if $f\circ \sigma^{-1} : \sigma(U) \to k$ is regular in the usual sense. I am guessing that schemes are the abstraction of varieties, but I did not study them yet. Can one get away with this simple generalization of what a variety is?",['algebraic-geometry']
1067004,How many ways are there to place 7 distinct balls into 3 distinct boxes?,"How many ways are there to place $7$ distinct balls into $3$ distinct boxes? is the question I'm confused about. The solution shows that the correct answer is $3^7$.
I'm just confused why this is. My thinking is that if there are 3 boxes, and 7 possible balls for each box: number of choices:  7 6 5 individual boxes:  _ _ _ So $7*6*5$ total possibilities... But clearly, the logic in this problem is the following: Number of choices: 3 3 3 3 3 3 3 Individual balls:   _ _ _ _ _ _ _ Why is the 1st solution incorrect?","['permutations', 'discrete-mathematics', 'combinatorics']"
1067005,Proving the limit at $\infty$ of the derivative $f'$ is $0$ if it and the limit of the function $f$ exist. [duplicate],"This question already has answers here : Proving that $\lim\limits_{x\to\infty}f'(x) = 0$ when $\lim\limits_{x\to\infty}f(x)$ and $\lim\limits_{x\to\infty}f'(x)$ exist (6 answers) If a function has a finite limit at infinity, does that imply its derivative goes to zero? (6 answers) Closed 8 years ago . Suppose that $f$ is differentiable for all $x$, and that $\lim_{x\to \infty} f(x)$ exists. Prove that if $\lim_{x\to \infty} f′(x)$ exists, then $\lim_{x\to \infty} f′(x) = 0$, and also, give an example where $\lim_{x\to \infty} f′(x)$ does not exist. I'm at a loss as to how to prove the first part, but for the second part, would a function such as $\sin(x)$ satisfy the problem?","['real-analysis', 'analysis']"
1067023,Difference between an eigenvalue and a spectral value,"What is the difference in the definition of a spectral value and an eigenvalue. My notes from functional analysis says $\lambda$ is an eigenvalue of an operator $A$ if $\,\exists \, x \in \mathbb{C^n}$ such that $$Ax = \lambda x$$ This implies $(A - \lambda I)x = 0  \Rightarrow \ker(A - \lambda I) \neq {0}$. This is equivalent
  of saying that $A$ is not injective. On the other hand, the definition of a spectral value is $\lambda$ is called a spectral value of $A$ if $A - \lambda I$ is not
  invertible. What is the difference here? How is it that some operators can have spectral values and not eigenvalues (eigenvalues $\subset$ spectrum(A)) and lastly, how do they conincide when the space is finite dimensional ?","['spectral-theory', 'functional-analysis']"
1067028,Good Pre-Calculus book?,"I was reading an online article and the author mentioned I should come here and get some advice. I'm 17, currently taking Pre-Calc in high schooling doing really good, but I feel like I'm not getting the most out of it. The teacher feels like he's more interested in covering chapters than getting us to understand things deeply and that worries me. The article says: Try to find a book where the author treats you as the intelligent, independent person you are, not as someone who has to take a course for a degree requirement...go to some math forums (like Math Overflow) and ask for book recommendations, telling them you want to become good at math and not just pass a required course; give them specific details and they can help find a book perfect for you. So yeah asked on Math Overflow and was suggested to come here. I want to get better at math and really understand the concepts deeply and appreciate it like it was intended to. Any help I can get will be appreciated. Thanks!","['book-recommendation', 'algebra-precalculus', 'reference-request']"
1067036,Show that $\mathbb Q[x]/(x^2+2)$ and $\mathbb Q[x]/(x^2-2)$ are not isomorphic. [duplicate],"This question already has answers here : $\mathbb{Q}(\sqrt{n}) \cong \mathbb{Q}(\sqrt{m})$ iff $n=m$ [duplicate] (2 answers) Closed 5 years ago . I have a proof that says $\mathbb Q[x]/(x^2+2)$ and $\mathbb Q[x]/(x^2-2)$ are not isomorphic. However I feel that it is not good one... First I see that $x^2+2$ and $x^2-2$ are irreducible in $\mathbb Q$. Then I notice that $x^2=2$ and $x^2=-2$. Now, if we take $(a+bx)(c+dx)$ on both, we end up $ac-2bd + (ad + bc)x$ and $ac+2bd + (ad + bc)x$. Can I now say, that these fields do not have the same structure, so they cannot be isomorphic? I do not want exact answer (homework :) ), but a hint would be nice to guide me into right direction.","['ring-theory', 'abstract-algebra']"
1067052,Find the determinant of a matrix definition [duplicate],"This question already has answers here : Determinant of a rank $1$ update of a scalar matrix, or characteristic polynomial of a rank $1$ matrix (2 answers) Closed 9 years ago . Let $A$ be a matrix that is defined like this: $$A_{ij}=\begin{cases}
\alpha,  & \text{if i=j} \\
\beta , & \text{if i $\ne$ j}
\end{cases}
$$
So I realized this matrix looks somehow like this
$$
        \begin{pmatrix}
        \alpha & \beta & \beta \\
        \beta & \alpha & \beta \\
        \beta & \beta & \alpha \\
        \end{pmatrix}
$$ I tried to manipulate the rows to get an upper triangular matrix but couldn't succeed, am I in the right direction... some help?:)","['matrices', 'linear-algebra']"
1067059,How can I prove the last digit of $(2^{121985292}-1)$ is $5$,"My friend asked me this question, but I don't know how to prove it. Can anyone help me about this. Thanks",['number-theory']
1067079,Trigonometric substitution and Integration of $\frac{1}{x^2\sqrt{x^2+1}} $,"Regarding the integral
$$
\int \frac{dx}{x^2\sqrt{x^2 + 1}}
$$
I'm not sure what to do about the extra $x^2$ in the denominator. What can I do about it?","['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
1067119,Norm of linear transformation: why restrict ourselves to $\|x\|\leq 1$?,"If $f$ is linear transformation from a normed linear space $X$ into a normed linear space $Y$, and define its norm by $$\|f\|=\sup\{\|f(x)\|: x\in X, \ \|x\|\leq 1\}$$ My question is: why restrict ourselves to vectors $x$ with $||x||\leq 1$?","['vector-spaces', 'functional-analysis', 'real-analysis']"
1067129,"If $f(x)+2f(1/x)=3x$, find all $y$ such that $f(y)=f(-y)$.",The function $f(x)$ is not defined when $x=0$. This function has the property that $f(x) + 2f\left(\frac 1x\right) = 3x$. Find all such values of $y$ such that $f(y) = f(-y)$. (This means it is an even function!).,"['algebra-precalculus', 'functions']"
1067149,What is difference between all of these derivatives?,"In calculus II we were introduced to a bunch of new derivatives: the gradient, the derivative $D=\begin{bmatrix} \partial_{x_1} \\ \partial_{x_2} \\ \vdots \\ \partial_{x_n}\end{bmatrix}$, the Jacobian, the Hessian, the total differential, the directional derivative, the partial derivative, and something called a Frechet derivative (that one was only mentioned in passing). I can apply the formulas to calculate these things, but what exactly are they?  And how do they relate to each other? For instance, the derivative of a function $f: \Bbb R \to \Bbb R$ gives the slope of the line tangent to $f$.  Which one of the above gives you, for instance, the ""slope"" (I don't even know what to call a $2$-D slope) of a function $g: \Bbb R^2 \to \Bbb R$?  I know that the partial derivatives give you the slope in the $x$, $y$, etc directions, but then what do the others do? And how do they relate to each other?  For instance, how does $D$ relate to say the directional derivative $\partial_{\vec v}$? Thanks.","['multivariable-calculus', 'derivatives']"
1067155,Does the sequence $f\chi_{E_n^c}$ converge pointwise to $f$ if the measure of $E_n$ tends to zero?,"If $(X,\mathcal{M},\mu)$ is a measure space, $f:X\rightarrow \mathbb{R}$ are such that $f\geq 0$ and $E_n\subseteq X$ measureable are such that $\mu(E_n)\rightarrow 0$, how would I be able to show that $f_n\equiv f\chi_{E_n^c}$ converges pointwise almost everywhere to $f$?","['measure-theory', 'convergence-divergence', 'real-analysis']"
1067166,Simplify a quick sum of sines [duplicate],"This question already has answers here : How can we sum up $\sin$ and $\cos$ series when the angles are in arithmetic progression? (8 answers) Closed 9 years ago . Simplify $\sin 2+\sin 4+\sin 6+\cdots+\sin 88$ I tried using the sum-to-product formulae, but it was messy, and I didn't know what else to do.  Could I get a bit of help?  Thanks.",['trigonometry']
1067182,Spectra of periodic Schrödinger equations,"This question might be a little bit physics-related, but I kind of have a deep interest to ask this here, cause I would like to get an idea of the Mathematics behind the things I just covered in my physics lecture. Please do not refer me to Reed/Simon or anything else, since I know that this topic is highly specialised (even in Spectral theory). I am just curious and hope to understand this in the future, so I just want to get an appetizer, if you understand what I mean. So assume we have a periodic 1d Schrödinger operator $$- f'' + V(x) f(x)= \lambda f(x)$$ 
and we want $V$ to be periodic. Now if we assume that we are on a finite interval and that we have periodic boundary conditions where $R$ denotes the period of the potential, then we have eigenvalues $E_0 < E_1 \le E_2 < E_3 \le E_4...$ and so on. Okay, this is clear to me. Then, there is the case that such an operator is defined on the full interval.
First question: Do we then need any boundary conditions? In my physics lecture we used so-called Born von Karmann boundary conditions (saying that $f(x+R) =f(x)$) in order to ""prove"" the Floquet or Bloch theorem which says that we can decompose $f(x) = e^{ikx} u_k(x)$. This theorem says that we can decompose the wavefunction in a periodic part$ u_k(x+R) = u_k$ and a complex exponential $e^{ikx}$. I somehow feel as if these Born von Karmann boundary conditions are not necessary in the sense that any eigenfunction to this Schrödinger operator is automatically periodic with the potential's period, is this true?- In that case: Why do we want Born von Karmann boundary conditions?- My problem with the Born von Karmann conditions is that I find that they are not really boundary conditions, as they don't act on some boundary.
So what about the domain of such an operator? 2.) Actually, imagine the case $V=0$, then we are just left with $-f'' = \lambda f$. On the finite interval, this is alright, if we assume to have any periodic bounday conditions, we get a discrete spectrum. But on the infinite interval, there are obviously no square integrable eigenfunctions( as I would say). Thus, I have even troubles to understand this very simple example from a theoretical point of view. 3.) In my physics lecture we noticed that due to these Born von Karmann conditions the possible $k'$s for the problem (appearing in the exponentials) are discrete. Not sure if this is automatically satisfied, even if we don't assume Born von Karmann boundary conditions?
Then we said that for every $k$, the Schrödinger operator equation that you get by pluggin in the ansatz from the Bloch or Floquet thoerem has a discrete spectrum. Is this true? If so, what does this all have to do with bands, if everything is so nicely discrete? - Or do we just cal these things bands, since the $k$'s get so close, that we cannot really resolve the discrete structure? 4.) Is there any relationship between the finite-interval problem and the infinite interval problem or are these two completely different things?","['operator-theory', 'mathematical-physics', 'spectral-theory', 'real-analysis', 'functional-analysis']"
1067188,Limit of an integral,"I'm not sure how to approach (no pun intended) the following limit: $$\lim_{x \to 0^{+}} \sqrt{|\sin x - \tan x | } \int_{\cos x}^{1+ \sin x} e^y \, \, \mathrm{d}y$$ I know that the indefinite integral of $e^y$ is just $e^y$, so we can rewrite the limit as $$\lim_{x \to 0^{+}} \sqrt{|\sin x - \tan x |} \left(e^{1+\sin x} - e^{\cos x}\right)$$ We can also rewrite the difference of the $\sin $ and $\tan$ to get $$\lim_{x \to 0^{+}} \sqrt{\left| \frac{\sin x \cos x - \sin x}{\cos x} \right|} \left(e^{1+\sin x} - e^{\cos x}\right)$$ Since $\sin 2x = 2 \sin x \cos x$, we have $$\lim_{x \to 0^{+}} \sqrt{\left| \frac{\frac{1}{2}\sin 2x - \sin x}{\cos x} \right|} \left(e^{1+\sin x} - e^{\cos x}\right)$$ Maybe I could use the Taylor series for $\sin$  and $\cos$ to justify approximations like $\sin x \approx x$ for $x \ll 1$? I'm not sure ... EDIT: I think the answer is zero. I've written up my reasoning.","['trigonometry', 'integration', 'real-analysis', 'limits']"
1067193,Covariant derivative of vector field along itself: $\nabla_X X$,"Consider a vector field $X$ on a smooth pseudo-Riemannian manifold $M$. Let $\nabla$ denote the Levi-Civita connection of $M$. Under which conditions can something interesting be said about the covariant derivative of $X$ along itself, i.e. $\nabla_X X$?","['riemannian-geometry', 'connections', 'differential-geometry']"
1067200,How to show that geodesics exist for all of time in a compact manifold?,"Let $M$ be a compact manifold and the tangent bundle $TM$ have a Riemannian metric $g$ so that it is isomorphic to the cotangent bundle $T^*M$. Consider the pull-back of the canonical symplectic form $\omega_{std}$ to define a symplectic form $\omega_g$ on $TM. $
Assuming the following theorem: The geodesics in $M$ are the images by the standard projection $$\pi: TM \to M$$ of the integral curves of the vector field $X_H$ where $H$ is the norm function squared in TM defined by the metric $g$ I want to show that the geodesics exist for all of time. Please help by giving some ideas!","['riemannian-geometry', 'symplectic-geometry', 'differential-geometry']"
1067204,How to embed the torus into the Klein bottle?,"Is there a continuous map of the torus into the Klein bottle? Can one do this so that it is locally a homeomorphism (or a complete embedding)? My idea is to take the square $[-1,2] \times [-1,1]$ and identify $(-1,y) \sim (1,y)$ and $(x,-1) \sim (x,1)$ to create the torus. To create the Klein bottle, I take the square $[-1,1] \times [-1,1]$ and identify $(-1,y) \sim (1,y)$ and $(x,-1) \sim (-x,1)$. Because of the difference in identification between the top/bottom torus and the top/bottom of the Klein bottle squares, I know there must be a flip involved. My idea is to use affine linear transformations. I tried various points along the bottom line of the square but everything I tried either broke the continuity of the map or did not meet the orientation of the Klein bottle. Any ideas on what to try? As for is there an embedding, there cannot be a complete embedding as the Klein bottle is not orientable but the torus is not. However, I feel that the torus can be mapped into the Klein bottle so that it is a local homeomorphism or at least ""piecewise"" a local homeomorphism. I feel this can be done as above using affine linear transformations.","['general-topology', 'covering-spaces', 'klein-bottle', 'algebraic-topology']"
1067223,A Sum that came up while solving a integral,"While evaluating $I$, I did the following- $$\begin{align}I= \int_{0}^{1} \log \left(\dfrac{1+x}{1-x}\right) \dfrac{1}{x\sqrt{1-x^2}} \ \mathrm{d}x &= 2 \int_{0}^{1}\sum_{n=0}^{\infty} \dfrac{x^{2n+1}}{2n+1} \dfrac{1}{x\sqrt{1-x^2}} \ \mathrm{d}x\\ &=2\sum_{n=0}^{\infty} \int_{0}^{1} \dfrac{x^{2n}}{(2n+1)\sqrt{1-x^2}}  \ \mathrm{d}x \end{align}$$ Then I used the substitution $x \mapsto \sin \theta $. $$\begin{align} \therefore I &=2\sum_{n=0}^{\infty} \int_{0}^{\pi/2} \dfrac{\sin^{2n} {\theta}}{2n+1} \ \mathrm{d}\theta\\ &=\pi \sum_{n=0}^{\infty} \dfrac{(2n)!}{2^{2n}(n!)^2(2n+1)} \end{align}$$ The last step is due to Wallis' formula. However, I couldn't solve the last series. My question is that how do we prove that $$\displaystyle\sum_{n=0}^{\infty} \dfrac{(2n)!}{2^{2n}(n!)^2(2n+1)}=\dfrac{\pi}{2} \ ?$$","['summation', 'integration']"
1067242,Show g is unbounded above if g and g' are increasing,"Suppose $g$ is a function defined on the set of real numbers where $g(y)$, $g'(y)$, and $g''(y)$ are all greater than $0$ for all $y \in \mathbb R$. Show that $g$ is unbounded above as $y$ approaches ∞. I know that $g$ and $g'$ are strictly increasing since $g'$ and $g''$ are greater than $0$, but I am having trouble with the rest of the reasoning.","['real-analysis', 'analysis']"
1067258,How to find the inverse Laplace transform?,I'm trying to calculate $$\mathcal{L}^{-1}\left(\frac{3s^3-3s^2+3s-5}{s^2(s^2+2s+5)}\right)$$ But I am not sure how to go from here. I would be really grateful for any help. Thanks.,"['ordinary-differential-equations', 'laplace-transform']"
1067267,Book recommendations for topics leading upto Algebraic geometry,"I'm interesting in studying algebraic geometry (specifically either from Shafarevich or Hartshorne). Assuming a high school and basic college math education, what should be the topics and the order that I should study them to get there? Also, could you recommend books/online resources for each topic. Thanks! PS - I apologize if this question does not fit the rules of the forum. I will modify it as required if it doesn't.","['advice', 'algebraic-geometry', 'book-recommendation', 'soft-question']"
1067268,"$\lim_{n \to \infty} \int_X f_n \, d\mu = \int_X f \, d\mu$ implies $\lim_{n \to \infty} \int_B f_n \, d\mu = \int_B f \, d\mu$ for $B \subseteq X$","I'm having trouble with the following problem. Let $(X, \mathcal{M},\mu)$ be a measure space, where $X = [a,b] \subset \mathbb{R}$ is a closed and bounded interval and $\mu$ is the Lebesgue measure. Let $f_{n}$ be a sequence of non-negative functions in $L^{1}(X,\mathcal{M},\mu)$ $\textit{converging in measure}$ to a function $f \in L^{1}(X,\mathcal{M},\mu)$. Given that the following holds, $\lim\limits_{n\rightarrow\infty}\int\limits_{X}f_{n}d\mu = \int\limits_{X}fd\mu$ show that for all $B \subset X$, $\lim\limits_{n\rightarrow\infty}\int\limits_{B}f_{n}d\mu = \int\limits_{B}fd\mu$ where $B$ belongs to the Borel $\sigma$-algebra. I was given a hint where convergence in measure in X implies convergence in measure in B, but I'm not sure where to proceed from here.","['lebesgue-integral', 'measure-theory', 'convergence-divergence', 'lebesgue-measure']"
1067304,How can I pick up analysis quickly? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 6 months ago . Improve this question I have a 2-3 week recess from university for winter break. In this time, I would like to learn analysis, starting with Walter Rudin's Principles of Mathematical Analysis , and then, if at all possible, continuing with Walter Rudin's Real and Complex Analysis . If necessary, I would be willing to complete the second book after returning to college (that is, outside of the 2-3 week time frame). A few questions come to mind: How reasonable are these goals? My background in maths is an elementary Moore method single-variable calculus course, and the beginning of (undergraduate) introductory real analysis. However, most of my time during the break will be available for mathematics. Is only the goal of completing the first book reasonable, with the second book requiring additional time? Is Principles of Mathematical Analysis sufficient for reading Real and Complex Analysis ? If not, what else should I know? What advice can you give me? I'm reading these primarily for entertainment, and I hope with this to learn enough mathematics to do interesting things. (I am a maths student in college, but have just started undergraduate analysis. My courses do not use either Rudin book.) This does not need to be advice on the books themselves, perhaps it could be advice on how to learn math quickly (and properly) if one has sufficient time to think about it exclusively.","['self-learning', 'soft-question', 'real-analysis', 'analysis', 'learning']"
1067308,Lebesgue measure is separable?,"I would like to better understand the following definition: $(M, \mathcal {A}, \mu) $ a probability space is separable if there exists a countable family $ \mathcal {E} \subset \mathcal {A} $ such that for all $ A \in \mathcal{A} $ and $ \varepsilon> $ 0, there is $ B \in \mathcal {E} $ such that $ \mu (A \triangle B )<\varepsilon$. I wonder if the Lebesgue probability space ($M=[0,1],$ $\mathcal {A}=$Lebesgue measurable sets in [0,1], $\mu=m$) is separable, as finding  $\mathcal {E} $? Thanks for any suggestions","['measure-theory', 'lebesgue-measure', 'analysis']"
1067331,"Erwin Kreyszig's Introductory Functional Analysis With Applications, Section 2.6, Problem 11","Let $X$ be the vector space of all complex $n \times n$ matrices and define $T \colon X \to X$ by $Tx \colon= bx$, where $b \in X$ is fixed and $bx$ denotes the usual product of matrices. I know that $T$ is linear. Under what conditions does $T^{-1}$ exist? If $b$ is an invertible matrix, then of course $T^{-1}$ exists. But does the existence of $T^{-1}$ necessarily imply the invertibility of the matrix $b$? What condition(s) (other than invertibility), if any, should $b$ satisfy in order for $T^{-1}$ to exist?","['matrices', 'linear-algebra', 'analysis', 'matrix-equations', 'functional-analysis']"
1067335,Interlacing of eigenvalues for Hermitian matrices,"This is a problem from Matrix Analysis by Horn and Johnson. Let $A \in M_n$ be Hermitian, let $a_k$$=$det$A$[{$1$, $\dots$,$k$}] be the leading principal minor of $A$ of size $k$, $k = 1, \dots, n$, and suppose that all $a_k \neq 0$. Show that the number of negative eigenvalues of $A$ is equal to the number of sign changes in the sequence $+1, a_1, a_2, \dots, a_n$. Explain why $A$ is positive definite if and only if every principal minor of $A$ is positive. What happens if some $a_i =0?$ The hint on the book tells me to use the interlacing theorem, which is the following. Let $B \in M_n$ be Hermitian, let $y\in \mathbb C^n$ and $a \in \mathbb R$ be given, and let $A$ $=$ $$ \begin{pmatrix}
        B & y \\
        y* & a \\
        \end{pmatrix}  \in M_{n+1}
$$ Then, $\lambda_1(A) \le \lambda_1(B) \le \lambda_2(A) \le \cdots \le \lambda_n(A) \le \lambda_n(B) \le \lambda_{n+1}(A)$. However, I have not been able to solve this so far and I would greatly appreciate any solution, hint, or suggestions.","['matrices', 'linear-algebra']"
1067362,isomorphism of pointed sets,"What is an isomorphism in the category of pointed sets?
Is it just an exact sequence
$$ 1 \to A \to B \to 1 ?$$
(Note: even though the kernel of the middle map is zero, $A$ might not inject into $B$.) I guess my confusion comes from the two (possibly distinct) notions of ""bijection of pointed sets"", which I interpret as a set-theoretic bijection preserving the distinguished point, and ""isomorphism of pointed sets"", which I'm not sure how to interpret. If it helps, my motivation for this question comes from nonabelian cohomology (especially  $H^1$).","['category-theory', 'algebraic-geometry', 'algebraic-topology']"
1067391,Show that hermitian element $h=\sum p_n/3^n$ generates $ C_0(\Omega)$,"Let $\Omega$ be a locally compact Hausdorff space, and suppose that the C*-algebra $C_0(\Omega)$ is generated by a sequence of projections $(p_n)_{n=1}^{\infty}$. Show that the hermitian element $h=\sum_{n=1}^\infty \frac{p_n}{3^n}$ generates $C_0(\Omega)$. My attempt: firstly, I show that $h\in C_0(\Omega)$. It means that $h$ is continuous and for every $\epsilon >0$, the set $\{x\in \Omega ; |h(x)|\geq \epsilon\}$ is compact.
 Suppose $p_np_m=0$ for every $n,m\in \Bbb N$ and $n\neq m$. Let $x_m\to x$ , there is $n_0\in \Bbb N$ such that $x\in p_{n_0}$. Also there is a subsequence $\{y_m\}$ of $\{x_m\}$ such that $\{y_m\}\subset p_{n_0}(\Omega)$. Then $$|h(y_m) - h(x)| \leq \sum_{n=1}^\infty\frac{|p_n(y_m)-p_n(x)|}{3^n}=0$$
So $h$ is continuous. To show for every $\epsilon >0$, the set $\{x\in \Omega ; |h(x)|\geq \epsilon\}$ is compact. I know that for every $\epsilon>0$, there is $n_0$ such that $\sum_{n=n_0+1}^\infty\frac{1}{3^n} <\epsilon$. Thus for $x\in p_1+...+p_{n_0}(\Omega)$, $|h(x)|\geq \epsilon$. Clearly $Im(p_1+...+P_{n_0})$ is closed, but I can not show that it's compact. Now I show that $h$ generates $C_0(\Omega)$. Let $f\in C_0(\Omega)$. there is a sequence of polynomials $\{q_m\}\subset C_0(\Omega)$ such that $f=\lim q_m$. Also every polynomial has a representation of projections $\{p_n\}$ as $q_m = \sum \lambda_n p_n$. Clearly  for $n$, there is $t_n$ such that $\lambda_n=t_n/3^n$ . So $h$ generates $C_0(\Omega)$. Please check my attempt and give me a hint to show that $h\in C_0(\Omega)$. Thanks in advance","['operator-theory', 'banach-algebras', 'functional-analysis', 'c-star-algebras']"
1067396,Prove that primitives of $\frac{x^3}{{\rm e}^x - 1}$ have no closed form in terms of elementary functions,"It is known the following indefinite integral
$$\int \frac{x^3}{{\rm e}^x - 1} dx$$
cannot be evaluated in closed form in terms of any of the elementary functions of mathematics. A proof of this can be found here . The proof given there expresses the integral in terms of four infinite series, one of which is the dilogarithm function . This term is then shown it cannot be expressed in closed form in terms of elementary functions using the Risch algorithm . My question is, using the Risch algorithm, is it possible to shown directly from the form of the integral given above that it cannot be expressed in closed form in terms of any of the elementary functions of mathematics? I must confess my experience in working with the Risch algorithm is rather limited (and yes I do understand a 100 plus page document exists somewhere which completely describes its implementation) so any outline of a possible proof would be greatly appreciated.","['closed-form', 'integration']"
1067409,Sets: why slice category is not isomorphic to functor category,"Is known that the slice category $\mathbb{Set}/I$ is equivalent to the category of $I$-indexed sets $\mathbb{Set}^{I}$. We can establish two functors $$\varphi: \mathbb{Set}^{I} \rightarrow \mathbb{Set}/I$$
$$\psi: \mathbb{Set}/I \rightarrow \mathbb{Set}^{I}$$ by $\varphi \left( \left( A_{i}  \right)_{i \in I}  \right) \mapsto \pi_{A}: \oplus_{i \in I} A_{i} \rightarrow I $, where $\oplus$ stands for the disjoint union and $\pi$ is the indexing projection, and $\psi \left( \pi: A \rightarrow I \right) \mapsto \oplus_{i \in I} \{ \pi^{-1}(i) \} $. It is then easy to show the equivalence $ \mathbb{1}_{ \mathbb{Set}/I } \simeq \varphi \psi, \mathbb{1}_{ \mathbb{Set}^{I} } \simeq \psi \varphi $. But I cannot see how these functors are not essentially the inverses of each other. The operations seem to be completely reversible and we get exactly the original result after applying $\psi \varphi$ or $\varphi \psi$. I could not come up with a counterexample. Any help is appreciated.","['category-theory', 'elementary-set-theory', 'abstract-algebra']"
1067464,Showing that this function is identically zero,"Suppose that $f$ is an entire function and has the property that for all $z ∈ \mathbb{C} \backslash \mathbb{R}$, $|f(z)| \le |1/|Im(z)|$. I want to show that $f ≡ 0$. I think I probably want to use Liouville's Theorem to show that $f$ is in fact bounded on on $\mathbb{C}$, and then show that the constant $c$ that $f$ is equal to is actually $0$, but I'm getting lost in showing this. Any hints or suggestions would be appreciated.",['complex-analysis']
1067481,Limit law of real-valued independent random variables,"Let $X_n$ and $Y_n$ be real-valued independent r.vs, each of whose limit law is $X$ and Y, resp. i.e $X_n \overset{d}{\to} X$ and $Y_n \overset{d}{\to} Y$ for some r.vs $X$ and $Y$. Then, are $X$ and $Y$ independent as well? I don't think it holds, but with the lemma below, I make it, which makes me surprised. Lemma. $X_{1}, \cdots, X_{n}$ are independent if and only if
  $$ \Bbb{E}[ f_{1}(X_{1})\cdots f_{n}(X_{n}) ] = \Bbb{E} f_{1}(X_{1}) \cdots \Bbb{E} f_{n}(X_{n})$$
  for any bounded continuous functions $f_{1}, \cdots, f_{n}$. Thus, I wonder if there exists such result. Anyone, any comments would be helpful. Thanks in advance.","['probability-theory', 'weak-convergence', 'random-variables']"
1067484,Differential Geometry of Curves and Surfaces,"I'm self-studying differential geometry using Lee's Intro to Smooth Manifold and Do Carmo's Riemannian Geometry. However, I've never studied the subject so-called ""differential geometry of curves and surfaces"" (such as the one dealt with by Do Carmo's Differential Geometry of Curves and Surfaces). Since this topic exclusively deals with 3-dimensional space, it doesn't attract me as much as other DG topics so far. What's the point of studying this topic? How important is it for those who will later study more advanced DG, especially Riemannian Geometry? If you think it's a kind of an optional subject, what would you learn instead? If you think it's an integral part of DG sequence, could you give me the reason why it is so important as well as some of its interesting applications and theorems?","['surfaces', 'differential-geometry']"
1067486,Compute almost sure limit of martingale?,"Let $Y$, $Y_1$, $Y_2$, $\dots$, be nonnegative i.i.d random variables with mean $1$. Let 
  $$X_n = \prod_{1\le m \le n}Y_m$$
  If $P(Y = 1) < 1$, prove that $\lim\limits_{n\to\infty}X_n = 0$ almost surely. I feel like this question has something to do with the idea that $(X_n)$ is a martingale (which I can prove easily) but I am not sure if I am overthinking it or not. I was trying to use Doob's upcrossing inequalities in a clever way but there might be an easier approach to the problem.","['probability-theory', 'stochastic-processes', 'stochastic-calculus']"
1067499,How to evaluate $\int_{0}^{\infty}\frac{(x^2-1)\ln{x}}{1+x^4}dx$?,"How to evaluate the following integral
$$I=\int_{0}^{\infty}\dfrac{(x^2-1)\ln{x}}{1+x^4}dx=\dfrac{\pi^2}{4\sqrt{2}}$$
without using residue or complex analysis methods?","['improper-integrals', 'closed-form', 'calculus', 'integration', 'real-analysis']"
1067542,Why aren't integration and differentiation inverses of each other?,"Integration is supposed to be the inverse of differentiation, but the integral of the derivative is not equal to the derivative of the integral: $$\dfrac{\mathrm{d}}{\mathrm{d}x}\left(\int f(x)\mathrm{d}x\right) = f(x) \neq \int\left(\dfrac{\mathrm{d}}{\mathrm{d}x}f(x)\right)\mathrm{d}x$$ For instance:
$$\begin{align*} &\dfrac{\mathrm{d}}{\mathrm{d}x}\left(\int 2x+1\;\mathrm{d}x\right) &&= \dfrac{\mathrm{d}}{\mathrm{d}x}\left(x^2+x+C\right) &= 2x+1\\
&\int\left(\dfrac{\mathrm{d}}{\mathrm{d}x}\left(2x+1\right)\right)\mathrm{d}x &&= \int 2\;\mathrm{d}x &= 2x+C\end{align*}$$ Why isn't it defined such that $\dfrac{\mathrm{d}}{\mathrm{d}x}a = \dfrac{\mathrm{d}a}{\mathrm{d}x}$, where $a$ is a constant, and $\int f(x)\;\mathrm{d}x = F(x)$?
Then we would have:
$$\begin{align*} &\dfrac{\mathrm{d}}{\mathrm{d}x}\left(\int 2x+1\;\mathrm{d}x\right) &&= \dfrac{\mathrm{d}}{\mathrm{d}x}\left(x^2+x\right) &= 2x+1\\
&\int\left(\dfrac{\mathrm{d}}{\mathrm{d}x}\left(2x+1\right)\right)\mathrm{d}x &&= \int \left(2+\dfrac{\mathrm{d1}}{\mathrm{d}x}\right)\;\mathrm{d}x &= 2x+1\end{align*}$$ Then we would have: $$\dfrac{\mathrm{d}}{\mathrm{d}x}\left(\int f(x)\mathrm{d}x\right) = f(x) = \int\left(\dfrac{\mathrm{d}}{\mathrm{d}x}f(x)\right)\mathrm{d}x$$ So what is wrong with my thinking, and why isn't this the used definition?","['inverse', 'derivatives']"
1067565,Solution to differential equations $y(0)=1$ and $y^{(n)}=y+1$,"When I was solving some differential equations, I asked myself the following:
Is there a function has the following:
$$y'=y+1$$
$$y''=y+1$$
$$y'''=y+1$$
$$......$$
$$......$$ If the initial value is $$y(0)=1$$","['ordinary-differential-equations', 'exponential-function']"
1067581,Rules for whether an $n$ degree polynomial is an $n$ degree power,"Given an $n$ degree equation in 2 variables ($n$ is a natural number)
$$a_0x^n+a_1x^{n-1}+a_2x^{n-2}+\cdots+a_{n-1}x+a_n=y^n$$ If all values of $a$ are given rational numbers, are there any known minimum or sufficient conditions for $x$ and $y$ to have: Real number Rational number Integer solutions and how many of them would exist. If it is not known/possible (or too hard) for an $n$ degree polynomial, do such conditions exist for quadratic ($n=2$) and cubic ($n=3$) polynomials.","['exponentiation', 'algebra-precalculus', 'roots', 'polynomials']"
1067582,The basis of a matrix representation,"If I have the linear map $f:\Bbb{R}^n\rightarrow \Bbb{R}^m$ then we can write $f$ as like the following: $$f\left(\vec x\right)=A\vec x$$ Where $A$ is a matrix. I think $A$ is called the standard matrix for $f$ . Linear maps act on vectors and therefore should not be associated with any basis i.e. they act on vectors rather then ' coordinate vectors '. Does this mean that the matrix $A$ is not associated with any basis? (noting that in the standard basis of the two vector spaces, the matrix representatin of $f$ will be equivlent to $A$ ). i.e. is the following statement correct: The matrix $A$ is equivalent to the linear map $f$ when acting on a vector in $\Bbb{R}^n$ . The matrix $\tilde A$ which is the matrix representation of $f$ in the standard bases of $\Bbb{R}^n$ and $\Bbb{R}^m$ has exactly the same components as $A$ but acts on coordinate vectors rather then actual vectors the linear map $f$ acts on. These coordinate vectors will however take exactly the same form, in the standard bases, as the original vectors that $f$ acts on.","['vector-spaces', 'matrices', 'matrix-equations', 'linear-algebra']"
1067585,"How can I show that the ""binary digit maps"" $b_i : [0,1) \to \{0,1\}$ are i.i.d. Bernoulli random variables?","In this post What is the Lebesgue measure of the set of numbers in $[0,1]$ that has two thirds of ones in their infinite base-2 expansion? we needed the fact that if we let $b_i (x) \in \{0,1\}$ for $x \in [0,1)$ denote the $i$-th digit in the infinite binary expansion of $x$, i.e. $$
x = \sum_{n=1}^\infty b_n (x) \cdot 2^{-n},
$$ where $b_n (x) = 1$ for all but finitely many $n$ (except for $x=0$), then the $(b_n)_n$ form a family of independent Bernoulli random variables, if they are considered as maps defined on the probability space $([0,1), \mathcal{B}, \lambda)$, where $\mathcal{B}$ are the Borel sets and $\lambda$ denotes Lebesgue measure. A quick search did not turn up any useful results, so my question is for a nice, more or less elementary, proof of this result, which can also be used for future reference. I will ""answer my own question"", i.e. provide one possible proof. But I would also be interested in other proofs!","['probability-theory', 'measure-theory', 'lebesgue-measure']"
1067589,Proving if $A \subseteq B$ and $A \nsubseteq C$ then $B \nsubseteq C$,"This is one of the problem I have been solving in Velleman's How to prove book: Prove that if $A \subseteq B$ and $A \nsubseteq C$ then $B \nsubseteq C$ This is my solution: Suppose $A \subseteq B \cap A \nsubseteq C$. Let x be an arbitrary
   element in A. From $x \in A$ and $A \subseteq B$, it follows that $x
 \in B$. From $x \in A$ and $A \nsubseteq C$, it follows that $x \notin
 C$. Therefore, $x \in B$ and $x \notin C$. Since x is arbitrary, $B\nsubseteq C$. This is the solution given in the book: Suppose that $A \subseteq B$ and $A \nsubseteq C$. Since $A \nsubseteq C$, we
  can choose some $a \in A$ such that $a \notin C$. Since $a\in A$ and $A \subseteq B$,
  $a \in B$. Since $a \in B$ and $a \notin C$, $B \nsubseteq C$. The book uses existential quantification to prove it but I assume x as arbitrary and prove that. Is there some flaw in my way of thinking ?","['logic', 'quantifiers', 'elementary-set-theory', 'proof-verification']"
1067606,"$f:\mathbb R\to\mathbb R$ continuous function. Which of the following sets can not be image of $(0,1]$ under $f$?","Let $f:\mathbb R\to\mathbb R$ continuous function. Which of the following sets can not be image of $(0,1]$ under $f$? A. $\{0\}$. B. $(0,1)$. C.$[0,1)$. D.$[0,1]$. My effort: Continuous image of connected set connected. $(0,1]$ is connected and remove $1$ from the set left the set connected...but removing any point from $(0,1)$ make it disconnected.....I am not sure though","['general-topology', 'continuity', 'real-analysis']"
1067644,prove that $\sqrt{2} \sin10^\circ+ \sqrt{3} \cos35^\circ= \sin55^\circ+ 2\cos65^\circ$,Question: Prove that: $\sqrt{2} \sin10^\circ + \sqrt{3} \cos35^\circ = \sin55^\circ + 2\cos65^\circ$ My Efforts: $$2[\frac{1}{\sqrt{2}}\sin10] + 2[\frac{\sqrt{3}}{2}\cos35]$$ $$= 2[\cos45 \sin10] + 2[\sin60 \cos35]$$,"['trigonometry', 'self-learning']"
1067687,Evaluate this limit in terms of f,"I want to evaluate the following limit: $$\lim_{d\to x} \dfrac{\dfrac{2x}{f'(x)}+f(x)-f(d)-\dfrac{x^2-d^2}{f(x)-f(d)}}{2\left(\dfrac{d-x}{f(x)-f(d)}+\dfrac{1}{f'(x)}\right)}$$ I tried L'hopital's rule but it just keeps getting worse and worse. I got this limit by wondering about circles fitting on a curve at a point $(x,f(x))$ and this limit is the $x$ coordinate of the circles center, in terms of a dummy point $d$.",['limits']
1067696,"Combinatorics problem with ""at least"" condition","I had a regular combinatorcics exercise to solve and I thought it's possible to solve it in two ways but it turned out that only one way is correct. It is:
A team of 4 students is to be selected for a competition. There are 8 boys and 12 girls to choose from. If the team have to include at least one boy and at least one girl, in how many ways can the team be selected? So the simplest solution which is correct is to find the total number of possible selections (without any conditions) and then subtract from it the number of possible solutions including only boys and only girls. But I thought the method mentioned below would be correct, it turned out to be wrong:
(8 nCr 1) (12 nCr 1) (18 nCr 2) = 14688
The two first pair of parantheses mean that we need at least one boy and at least one girl of our group of 20. And (18 nCr 2) means that we need two more people to complete our team and it doesn't matter if it's a boy or a girl. Unfortuantelly, this method isn't somewhere incorrect. The correct answer is 4280 so now I think there may be some extraneous selections in my method but I can't think of any.
Would you please tell me where my approach falls?",['combinatorics']
1067711,An intuitive understanding of the equation $Var(X)=E(X^2)-E(X)^2$,"I know the equation $Var(X)=E(X^2)-E(X)^2$ and its proof. After reading the textbook of mine, I found that this equation has been used in a lot of place. I want to know whether there is an intuitive understanding of this equation?",['probability']
1067736,Why is this intuitive method valid?,"Problem . There are $2$ white and $3$ black balls in the urn. A person randomly picked $2$ balls and put $1$ white ball. What is the probability of the event that the next randomly-picked ball would be white . To solve this problem formally you have to consider conditional probabilities and so on. But in the childhood I did not know such words so I was solving problems of this type in the following way. Intuitive solution . Let's grind balls into powder and mix it. We will have $5$ (whatever you want, for instance) kilograms of powder. $\frac{2}{5}$ of each kilogram is white and $\frac{3}{5}$ is black . A person randomly took $2$ balls in my model means that he took $2$ kilogram of powder. Putting $1$ white ball means that he put $1$ kilogram of white powder. After all actions there are $\left(5 \cdot\frac35-2\cdot \frac35\right)=\frac95$ kilograms of black powder and $\left(5 \cdot\frac25-2\cdot \frac25\right) + 1=\frac95=\frac{11}5$ kilograms of white powder. So the final probability of picking white ball is $\frac{11}{5}/\left(\frac{11}{5}+\frac{9}{5}\right) = \frac{11}{20}$. You can check that this is the right answer, but the question is why is this intuitive method valid?","['intuition', 'probability']"
1067752,How to prove a right angle if i have two tangents?,"I would appreciate your help, it is long time since I solve trigonometric, like if I have the tangent of angle B equal to $\sqrt{2}-1$ and the tangent of angle C equal to $\sqrt{2}+1$, how can I prove that ABC is right at A using trigonometric functions.","['trigonometry', 'algebra-precalculus']"
1067761,"How many positive integers of n digits chosen from the set {2,3,7,9} are divisible by 3?","I'm preparing myself for math competitions. And I am trying to solve this problem from the Romanian Mathematical Regional Contest “Traian Lalescu’', $2003$ : Problem $\mathbf{7}$ : How many positive integers of $n$ digits chosen from the set $\{2,3,7,9\}$ are divisible by $3$ ? Solution. Let $x_n,y_n,z_n$ be the number of all positive integers of $n$ digits $2,3,7$ or $9$ which are congruent to $0,1$ and $2$ modulo $3$ . We have to find $x_n$ . Consider $\varepsilon=\cos\dfrac{2\pi}3+i\sin\dfrac{2\pi}3$ . It is clear that $x_n+y_n+z_n=4^n$ and $$x_n+\varepsilon y_n+\varepsilon^2z_n=\sum_{j_1+j_2+j_3+j_4=n}\varepsilon^{2j_1+3j_2+7j_e+9j_4}=(\varepsilon^2+\varepsilon^3+\varepsilon^7+\varepsilon^9)^n\;.$$ It follows that $x_n-1+\varepsilon y_n+\varepsilon^2z_n=0$ . Applying Proposition $4$ in Subsection $2.2.2$ we obtain $x_n-1=y_n=z_n=k$ . Then $3k=x_n+y_n+z_n-1=4^n-1$ , and we find $k=\dfrac13(4^n-1)$ . Finally, $x_n=k+1=\dfrac13(4^n+2)$ . Please help me with the solution, I don't understand it well enough, especially the displayed line. Are there any other solutions for this problem?","['number-theory', 'combinatorics']"
1067778,If $|z-3i|+|z-4|=5$ then find the minimum value of $|z|$,"Question : If $|z-3i|+|z-4|=5$  then find the minimum value of $|z|$ What I did : $$|z-3i| \leq |z|+3 \tag i$$ Also $$|z-4| \leq |z| +4 \tag{ii}$$ Now adding (i) and (ii) we get $$ \Rightarrow |z-3i|+|z-4| \leq 2|z| +7 $$ $$\Rightarrow 2|z| +7 \leq 5$$ $$\Rightarrow |z| \leq -1 $$ Please suggest whether this is correct or wrong , also suggest the mistake thanks.","['complex-numbers', 'algebra-precalculus']"
1067793,A problem on infinite domain diffusion equation,"Consider the following problem
$$u_t-u_{xx}=p(x,t), -\infty<x<\infty,t>0$$
$$u(x,0)=0$$
$$u\rightarrow0 \text{ as } x\rightarrow \pm \infty$$ This can be solved using many sub problems as follows. Let $\zeta>0, \tau >0$. Consider the neighborhood $\zeta\leq x \leq \Delta \zeta+\zeta,\tau\leq t \leq \Delta \tau+\tau$ and $p(\zeta,\tau) $ is constant in this neighborhood. Now we build a new problem as follows. $$u_{1t}-u_{1xx}=p(\zeta,\tau) \delta(x-\zeta)\delta(t-\tau)d\zeta d\tau, -\infty<x<\infty,t>0$$
$$u_1(x,0)=0$$
$$u_1\rightarrow0 \text{ as } x\rightarrow \pm \infty$$ Then the solution is $$u_1(x,t)=\frac{p(\zeta,\tau) d\zeta d\tau}{\sqrt{4\pi(t-\tau)}}exp(-\frac{(x-\zeta)^2}{4(t-\tau)})$$ So the solution to main problem is $$u(x,t)=\int_0^t \int_{-\infty}^{\infty}\frac{p(\zeta,\tau)}{\sqrt{4\pi(t-\tau)}}exp(-\frac{(x-\zeta)^2}{4(t-\tau)}) d\zeta d\tau$$ I am not sure whether everything I have done here is right. But a similar way of solving is given below. $$u_{1t}-u_{1xx}=p(\zeta,\tau) \delta(x-\zeta)\delta(t-\tau), -\infty<x<\infty,t>0$$
$$u_1(x,0)=0$$
$$u_1\rightarrow0 \text{ as } x\rightarrow \pm \infty$$ Then the solution is $$u_1(x,t)=\frac{p(\zeta,\tau) }{\sqrt{4\pi(t-\tau)}}exp(-\frac{(x-\zeta)^2}{4(t-\tau)})$$
 $$u(x,t)=\int_0^t \int_{-\infty}^{\infty}\frac{p(\zeta,\tau)}{\sqrt{4\pi(t-\tau)}}exp(-\frac{(x-\zeta)^2}{4(t-\tau)}) d\zeta d\tau$$
Are both of these methods correct or one of them is? Any help will me much appreciated as this has confused me for many days! thanks!","['mathematical-physics', 'ordinary-differential-equations', 'partial-differential-equations']"
1067798,"Are the polynomial functions on $S^1$ dense in $C(S^1,ℂ)$?","A friend of mine came up with this problem: Let $S^1$ be the unit circle in $ℂ$ and $P$ the space of polynomial functions $S^1 → ℂ$ (with complex coefficients). Is $P$ dense in $C(S^1,ℂ)$? Stone–Weierstraß is not applicable because $P$ is not closed under complex conjugation. We’re wondering if complex conjugation on $S^1$ (= inverting) is a uniform limit of polynomials. We suspect not, but don’t know how to prove it.",['functional-analysis']
1067820,How probable is that a randomly typed 47 digit odd integer is a prime?,"So, I have been playing around with prime numbers, I have installed gmp and gmpy2 gmpy2 has a function gmpy2.is_prime for primality testing (non deterministic) which uses the Miller-Rabin primality test. Now to test the speed of gmpy2.is_prime I typed some random digits '1245268798719487981976914598618498569816481948' and added a '3' to the end so that the number is not even . It took it milliseconds to get the result and to my surprise, In [18]: gmpy2.is_prime(12452687987194879819769145986184985698164819483)
Out[18]: True What? really? the number I randomly typed is a prime? To make sure is_prime wasn't returning true for every other number I added a few digits and expectedly In [25]: gmpy2.is_prime(124526879871948798197691459861849856981648139483)
Out[25]: False

In [26]: gmpy2.is_prime(12452687987194879819769145986555184985698164819483)
Out[26]: False I was blown away, but now, I am curious. What is the probability of this happening? More specifically, What is the probability that a randomly selected odd 47 digit number passes Miller-Rabin primality test? Did I just get really really lucky?","['prime-numbers', 'primality-test', 'probability']"
1067847,Dirichlet Series and Asymptotic Expansions: $\tilde{f}(s)= \sum_{n=1}^{\infty} f(n) n^{-s}$,"Consider the Dirichlet series $\tilde{f}(s)= \sum_{n=1}^{\infty} f(n) n^{-s}$ . In the page Zeta Function Regularization I found a relation among an asymptotic expansion of $\tilde{f}(s)$ and an asymptotic expansion of $F(t)=\sum_{n=1}^{\infty}f(n)e^{-tn}$ , that is if \begin{equation}
F(t)=\frac{a_N}{t^N}+\frac{a_{N-1}}{t^{N-1}}+...
\end{equation} then \begin{equation}
\tilde{f}(s)=\frac{a_N}{s-N}+...
\end{equation} Is it correct? Where could I find a rigorous treatment of such a subject? Thank you very much in advance for your help.","['summation', 'integration', 'complex-analysis', 'integral-transforms']"
1067854,What is $\Bbb{R}^n$?,"I earlier asked this question The basis of a matrix representation . I now have a another question related to the same topic. The vector space $\Bbb{R}^n$ I have seen defined as all $n$-tuples of real numbers$^1$. But I think a more intuitive definition would be that $\Bbb{R}^n$ is simply the $n$-dimensional real space such as a plane for $n=2$ or a line for $n=1$. My problem with the first definition is that it seems like we have already specified a basis, namely $(i,j,k)$ for n=3, which themselves have no meaning as column vectors until we define them to be $(1,0,0),(0,1,0)$ and $ (0,0,1)$ respectively. Thus if we write vectors in $\Bbb{R}^n$ as column vectors we have already defined our basis and the tuples are therefore not basis independent objects. So my point is that if we change basis, the $n$-order tuples will change but the actual  'arrow' from one point to another in the $n$-dimensional space will not. So surely this 'arrow' is the actual element $\Bbb{R}^n$ and the $n$-order tuple is its coordinate map. Is this right or wrong? If it is right please could you give me a source where it states it explicitly, I have tried to look for one without success. from http://www.math.vt.edu/people/dlr/m2k_svb01_vecspc.pdf","['vector-spaces', 'matrices', 'linear-algebra']"
1067883,Castelnuovo-Mumford regularity of Cohen-Macaulay modules,"Let $S=K[X_1,\ldots,X_n]$ and $M$ be a Cohen-Macaulay $S$-module. This equality holds
  $$ \operatorname{reg}(M)=\dim(M)+\max\{i\in\mathbb{Z}\colon P_{M}(i)\neq H(M,i)\}. $$ It's been proved in Eisenbud, ""The Geometry of Syzygies"" in Theorem 4.15. I can't understand it because that book has a lot of geometry in its proofs. Can you help me understand it? Or can anybody help me find a more algebraic version in other books?
Thank you.","['commutative-algebra', 'algebraic-geometry', 'reference-request', 'cohen-macaulay']"
1067894,Convergence in measure implies convergence almost everywhere (on a countable set!),"Here is an interesting problem from ""Real Analysis for Graduate Students"" by Richard Bass (which is an amazing book, by the way). Suppose $(X, \mathcal{A}, \mu)$ is a measure space, and $X$ is a countable set. Prove that if $f_n$ is a sequence of measurable functions converging to $f$ in measure, then $f_n$ also converges to $f$ a.e. (almost everywhere). This is Exercise 10.9 in page 79. I tried applying the theorem that if $f_n\to f$ in measure, then $f_n$ has a subsequence $\{f_{n_k}\}$ that converges to $f$ a.e. But I am having trouble using the fact that $X$ is a countable set. I would appreciate a hint in the right direction.","['measure-theory', 'convergence-divergence', 'real-analysis']"
1067906,Supremum of a sine integral,"Let $M_T=\int\limits_{0}^{T}\frac{\sin(t)}{t}dt$ be a sine integral.
Why is $2\displaystyle\sup_{T}M_T < \infty$?","['trigonometry', 'supremum-and-infimum', 'integration']"
1067909,If $dx/dy =\sin(x)$ then is $dy/dx = 1/\sin(x)$?,"If $\dfrac{dx}{dy} = \sin(x),$ then is $\dfrac{dy}{dx} = \dfrac{1}{\sin(x)}$? I'm trying to understand how to manipulate $dx$ and $dy$ quantities effectively.","['calculus', 'derivatives']"
