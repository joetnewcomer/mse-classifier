question_id,title,body,tags
1735126,"In a right triangle, can $a+b=c?$","I understand that due to the Pythagorean Theorem, $a^2+b^2=c^2$, given that $a$ and $b$ are legs of a right triangle and $c$ is the hypotenuse of the same right triangle. However, most of the time, $a+b\neq c$. What I have been wondering is, is there any set of values for $a$, $b$, and $c$ that make the statement $a+b=c$ true?","['euclidean-geometry', 'triangles', 'geometry']"
1735133,Decomposition of $x^n-y^n$,"As a part of textbook assignment I was asked to prove that $x^2-y^2=(x+y)(x-y)$, and I did so as follows:
$$x^2-y^2=x^2-y^2+xy-xy=x(x+y)-y(x+y)=(x+y)(x-y)$$
Later, I used similar method to decompose $x^3-y^3$, with different ""cofactors"":
$$x^3-y^3=x^3-y^3+x^2y+xy^2-x^2y-xy^2=...$$
However, when I needed to do this for $x^n-y^n$ I was  slightly disconcerted, because up to this point there was no particular reasoning behind adding fitting ""cofactors"", I just made them up to suit my equation, and it became a problem, because now it was not as evident. 
The solution I resorted to looked like this:
$$x^n-y^n+(x^{n-1}y+x^{n-2}y^2+...x^2y^{n-2}+xy^{n-1})-(x^{n-1}y+x^{n-2}y^2+...x^2y^{n-2}+xy^{n-1})$$
But this time I too picked the terms to cancel each other out without any reasoning. Is there even one, to justify them appearing out of nowhere? And what interests me is whether or not this can be regarded as satisfactory proof, and are there other, nicer ways to do it?",['algebra-precalculus']
1735134,prove this :$\sum_1^{100} A_i = \sum_0^{99} C_i $,"In a class there are 100 student. We define $A_i$  as the number of friends of $ i^{th}$ student and $C_i$ as the number of students who has at least $i$ friends. Prove that:
$\sum_1^{100} A_i = \sum_0^{99} C_i$","['combinatorics', 'discrete-mathematics']"
1735148,$P+Q-PQ$ is a projection if and only if $PQ=QP$.,"Let $\mathcal H$ is a Hilbert space and $P,Q:\mathcal H \to \mathcal H$ are projections. I want to show that $P+Q-PQ$ is a projection if and only if $PQ=QP$. If $PQ=QP$ clearly $P+Q-PQ$ is a projection. But when $P+Q-PQ$ is a projection, how I can show that $PQ=QP$? I tried to use $$(P+Q-PQ)^2=P+Q-PQ$$ And I got: $$QP-QPQ-PQP+(PQ)^2=0$$ And from here: $$(Q-PQ)(P-PQ)=0$$ Can somebody give me a hint? Thanx in advance.","['functional-analysis', 'linear-algebra', 'hilbert-spaces', 'operator-theory']"
1735181,Probability of Winning in Sports,"In sports such as volleyball (prior to 1999), you can score a point only if it is your turn, with turns alternating until a point is scored. Suppose your probability of scoring a point when it is your turn is $p$, and your opponent's probability of scoring a point when it is her turn is $q$. Find a formula for the probability $S$ that you are the first to score the next point, assuming it is currently your turn. I have little experience with probability problems, so any help would be well appreciated!",['probability']
1735193,"In practice, what does it mean for the Newton's method to converge quadratically (when it converges)?","I was studying about the Newton's method (and other root-finding methods) and apparently Newton's method converges quadratically (or more) when it does. Suppose that the sequence $\{x_k \}$ converges to the number $L$. We say that this sequence converges linearly to $L$, if $\exists$ a number $\mu \in (0, 1)$, such that $$\lim_{k \to \infty} \frac{|x_{k+1} - L|}{|x_{k} - L|} = \mu$$ and $\mu$ is called the rate of convergence. Similarly, it would converge quadratically to $L$ if $$\lim_{k \to \infty} \frac{|x_{k+1} - L|}{|x_{k} - L|^2} = \mu$$ where $\mu > 0$. Why is that? How can I see in practice if a sequence of iterations of the Newton's method is converging or not quadratically? I guess I need to check for all $x_k$ that the second limit above is $\mu$ for some $\mu$ greater than $zero$...but how would I check this practically for a real concrete example?","['numerical-methods', 'rate-of-convergence', 'newton-raphson', 'limits']"
1735208,What is an intuition behind permanent?,"I would like to know what is your intuition behind permanent of a matrix. For me, it looks like someone came and saw determinant, deleted permutation sign and voila, we have permanent and it counts the number of perfect matchings. But I am sure that is not how it was. :)","['graph-theory', 'abstract-algebra', 'determinant', 'permanent', 'linear-algebra']"
1735222,Convert time in seconds to 24-Hour clock and AM/PM clock [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Maybe it is a basic problem but it confused me. How can we formulate a translation of given seconds to 24 hour clock or am/pm clock. For example; 77400 seconds is $21:30:0$ in 24 hour clock and $9:30:0$ $PM$ in am/pm clock.","['number-theory', 'discrete-mathematics', 'elementary-number-theory']"
1735287,Non empty set with zero diameter,"Let $A \subset X$ where $X$ is a metric space. by definition diam$(A) = \sup\{ d(x,y), x,y \in A\}$. if $A$ is non empty and has zero diameter, can I conclude that $A$ is a singleton? i reason as follows: there is at least one $a \in A$. If there is $b \in A$ such that $a \neq b$, then $d(a,b) > 0$ so diam$(A) > 0$. so contradiction. is this correct? just making sure. thanks","['general-topology', 'metric-spaces', 'proof-verification']"
1735294,"Counting with Combinatorics (Just need my work checked over, pretty sure it's right)","Consider the alphabet A,B,C,D,E,F and make words without repetition of letters allowed. A.) How many six-letter words are there? B.) How many words begin with D or E? C.) How many words end in B or A? D.) How many words begin with D or E and end in B or A? E.) How many have first letter neither D nor E and last letter neither B nor A? A. The total number of six-letter words without repetition of letters: 6 letters. = 6! = 720 B. How many words begin with D or E? -- Seeing that we're using 1 of the 6 letters to start off with, the answer will remain the same for both. Beginning with D would remove the first letter from the equation. Therefore, the answer would be 5!. Same for beginning with E. Correct me if I'm wrong! Do I add these results together (5! + 5!=240)? C. How many words end with B or A? --Same concept as part B, right? We take the last letter out of the six-letter word equation and we're left with 5. =5!+5!=240 for both ending in B or A. D. Here's where I may get confused. How many words begin with D or E and ends with B or A? -- There would be 4 cases? Begins with D and ends with B, begins with D and ends with A, begins with E and ends with B, begins with E and ends with A. Each case would retrieve the same result? Therefore, we know what the first and last letters are. We just need to calculate the middle 4 letters that are not repeated. That equals 4!. 4 cases, so 4!+4!+4!+4!=96. Once again, correct me if I'm wrong. E. How many have first letter neither D nor E and last letter neither B nor A? --This means the first letter can be A,B,C, or F. This gives us 4 total choices. The last letter can be C,D,E, or F. This also gives us 4 total choices, but we can't repeat letters. C and F are the common letters. So, to calculate the first letter combinations, we can do 4!/((4-2)!)=12 combinations. Same with the last letter. And, for the middle 4 letters that can't be repeated, we have 4! combinations. Therefore to solve for the total combinations, it would be 12+4!+12= 48 combinations. Just looking for someone to check over my work! I'm not 100% sure that I did this all correctly. Thanks!","['combinatorics', 'discrete-mathematics']"
1735366,integral $\int_0^1\frac{1}{\sqrt{1+x^4}}\text{d}x$,How to prove that $$0.78<\int_0^1\frac{1}{\sqrt{1+x^4}}\text{d}x<0.93$$ approch: $x^2<\sqrt{1+x^4}<x^2+\frac{1}{2x^2}$ Any hint would be appreciated.,"['integration', 'definite-integrals', 'calculus']"
1735385,Need help understanding this example of a distribution,"Consider the following example of a distribution (given here ): I tried to draw this. If $p=(a,b,c)$ then 
$$ X_p = (1,0,-b), Y_p = (0,1,0)$$ Then the planes in the distribution are planes spanned by $X_p,Y_p$. We see that the plane spanned by $X_p,Y_p$ is a plane that rotates around the vector $Y_p$ as $p$ moves along the $y$-axis. Assume we had a surface $S$ that was tangent to all this twirling planes. Without loss of generality, assume the surface is located in $\mathbb R^3$ such that the origin is on the surface. Then we have a plane, coincidentally parallel to the $xy$-plane, that is tangent to $S$ at $0$. In other words: the $xy$-plane is tangent to $S$. This is as far as I can follow the explanation given in the text. But everything that follows I do not understand. For example, only because the $xy$-plane is tangent to $S$ at $0$ it is not clear to me why $S$ would intersect the $x$-axis in a line segment (for example, $S^2$ can be tangent to the $xy$-plane an does not intersect the $x$-axis in a line segment). But even if this was clear to me and I assume that $S$ intersects this axis in a line segment the rest of the explanation is also not clear to me: travelling along an intersection axis does not seem to contradict that the planes are twisting. Please could someone explain this to me?","['contact-topology', 'differential-geometry']"
1735387,"Is there a locally compact, locally connected, Hausdorff and second countable space that is ""nowhere locally Euclidean""?","When I study topological manifold, I think some property of manifolds are so important that they can ""almost characterize"" manifolds. But I know a topological manifold is not easily to be characterized because of its locally Euclidean property. I want to find a ""weird"" example of a locally compact, locally connected, Hausdorff and second countable space $X$ that is ""nowhere locally Euclidean"", i.e. for any point in $X$, there doesn't exist an open neighborhood that is homeomorphic to a open subset of a Euclidean space. Since a discrete space is a 0-dimensional manifold(locally $\mathbb R^0$), the following type of example is not what I want: A straight line union a point which is not on that line Does such an example exist? Every solution or reference or even more generalized example(Even stronger conditions can't guarantee the locally Euclidean property) will be appreciated!","['manifolds', 'general-topology']"
1735390,What is the point of subspaces? [duplicate],"This question already has answers here : Why a subspace of a vector space is useful (7 answers) Closed 8 years ago . I've been studying for my linear algebra final for the past few days, and just had this thought. 
I know what a subspace is; It's a subset of a vector space that contains the zero vector, and preserves addition and scalar multiplication. But what can we do with a set after we've discovered that it's a subspace? The questions in my textbook only go as far as telling us to determine if a set is a subspace or not, we're not asked to use the fact that a set is a subspace to do something else. So my question is, what is the point of a subspace then? Thanks","['linear-algebra', 'vector-spaces']"
1735458,"To prove that $C_0(X)$ is a $C^*$-algebra, is it necessary to assume that $X$ is a locally compact Hausdorff space?","I know this seems like a dumb question. But I can't see why we need the condition that $X$ is a locally compact Hausdorff space when we define $C_0(X)$. I think many properties still hold without locally compact Hausdorff property. For example,I think $C_0(X)$ is still a $C^*$-algebra for a general topological space $X$, am I right?","['functional-analysis', 'c-star-algebras']"
1735484,limit of $6x\sin(\frac{4}{x})$ as $x$ approaches infinity,Limit of $6x\sin(\frac{4}{x})$ as $x$ approaches infinity. I know its $24$ thanks to wolfram alpha. I don't know how to get there. Just need to understand how this is done so I am not lost in the future.,['limits']
1735501,Calculus optimization problem leads to a quartic polynomial - is there a better way?,"I am tutoring a student in first-semester Calculus.  He needs to minimize the function
$$f(x)=\frac{\sqrt{4+x^2}}{2}+\frac{\sqrt{1+(3-x)^2}}{4}$$
Taking the derivative and setting it equal to zero, we find (after some cleanup)
the equation
$$\frac{x}{\sqrt{4+x^2}}=\frac{3-x}{2\sqrt{1+(3-x)^2}}$$
At this point, it seems (to me) that the most likely avenue of solution is to square both sides, cross-multiply, and collect like terms.  This leads (after some heavy lifting) to the polynomial equation
$$x^4-6x^3+9x^2+8x-12=0$$
Solving quartics is not a lot of fun, but in this case we get lucky:  plugging in $x=1$ we find that it is a solution, because $1-6+9+8-12=0$.  Phew!  And with hindsight, we can see that $\frac{1}{\sqrt{4+1^2}}$ and $\frac{3-1}{2\sqrt{1+(3-1)^2}}$ are both equal to $\frac{2}{\sqrt{5}}$. But it seems unlikely to me that this is the intended method of solution.  First of all, the algebra is considerably thornier than what the student has had to deal with prior to this question.  Second, solving a quartic equation seems way out of bounds for a first-semester Calculus class; it happens that in this case the coefficients sum to $0$, but I don't think a typical student would be expected to notice that. For all of the above reasons, I suspect that there is probably an easier way to solve this problem, but I am at a loss.  Is there some trick that I am missing?","['optimization', 'calculus']"
1735507,"What are the smooth map and the vector field in the Fig. 8.2, page 182 of John Lee's Smooth manifolds, 2nd","The purpose of this figure is to show that when $F$ is not surjective, then 
the differential of $F$ can't decide what vector can be assigned to the points outside of Im$F$ and when $F$ is not injective, then for some points of $N$, there may be several different vectors obtained by applying $dF$ to $X$ at different points of M. But I find it hard to make up a concrete example of such map. I know to many professional geometricians, drawing pictures is enough to give such examples, but a beginner like me is still curious about(or suspect) the existence of such a map. This explains why I want to find an explicit, written-down example. Specifically, are there a smooth vector field on $\mathbb S^1$ and a smooth map from $\mathbb S^1$ to $\mathbb R^2$ taking a unit circle to a ""figure eight"" that make trouble at the cross of ""figure eight""?(Please note that the example I want is a smooth map and a vector field defined on the whole unit circle, not just an open arc of it)","['smooth-manifolds', 'differential-geometry']"
1735544,Proving that $f = 0$ if $\int fg = 0$ for all $g \in S$,"Let $f \in L^1$. I want to prove that if $\int f g = 0$ for all $g\in S$, then $f = 0$ a.e. $S$ denotes Schwartz space. My Approach: My idea is to let $h = sgn(f)$ and then smooth it somehow to get a function in $S$. But I don't know how to proceed. Any hint?",['functional-analysis']
1735552,Solving $e^x = 6x$ for $x$ without a graph.,"Throughout my high school career I was always told that an equation of this sort ( $e^x = 6x$ for example) couldn't be solved algebraically. However I feel that there may be a way (and you may be out there saying ""of course there is a way"") I know that it can be solved graphically, but is there any other way(s) to solve this equation: $$e^x = 6x$$
**Without graphing or using a equation solver **",['algebra-precalculus']
1735558,Folland's Real Analysis 7.11,"Suppose $\mu$ is a Radon measure on $X$ such that $\mu(\left\lbrace x \right\rbrace)=0$ for all $x \in X$, and $A \in \mathbb{B}_X$ satisfies $0 < \mu(A) < \infty$. Then for any $\alpha$ such that $0 < \alpha < \mu(A)$ there is a Borel set $B \subset A$ such that $\mu(B) = \alpha$ I'm not even sure how to start this problem. It seems like a nice result, but any hints on how to start?","['real-analysis', 'measure-theory']"
1735601,Space which is connected but not path-connected,"Consider the following two definitions: Connected : A topologiocal space X is connected if it is not the disjoint union of two open subsets, i.e. if X is a disjoint union of two open sets A and B, then A or B is empty set. Path Connected : A topological space X is path-connected if any two points in X can be joined by a continuous path. So far I can picture, I think they should be equivalent. If X is connected iff it is path-connected. But, the Thm I got from lecture is just if X path connected then X is connected (The converse not necessarily true.) Can anyone give me some picture of space which is connected but not path-connected? Just picture please, cuz I wanna grab the idea. I have already seen some examples like in connected but not path connected? , I cannot grab the idea if it (such space) consist of a single piece, then I couldn't make a continuous path from any two points. Thank you :)","['general-topology', 'examples-counterexamples', 'path-connected', 'connectedness']"
1735633,How to evaluate $\int_{0}^{+\infty }\frac{x^{3}\sin\left ( (1/2)\pi x \right )}{e^{2\pi \sqrt{x}}-1}\mathrm{d}x$,"I got an answer below \begin{align*}
\int_{0}^{\infty }\frac{x^{3}\sin\left ( \frac{1}{2}\pi x \right )}{e^{2\pi \sqrt{x}}-1}\mathrm{d}x&=\frac{17}{16}-\frac{8}{3\pi }-\frac{7}{\pi ^{2}}+\frac{35}{2\pi ^{3}}-\frac{105}{16\pi ^{4}} \\&\approx 0.00145669538148559\cdots \cdots 
\end{align*} which agree with mathematica.But I have no idea how to prove it.","['integration', 'calculus', 'analysis']"
1735648,"If 5 points are necessary to determine a conic, why are only 3 necessary to determine a parabola?","I've just been reading about how 5 points are necessary and sufficient to determine a conic section in Euclidean geometry ( https://en.wikipedia.org/wiki/Five_points_determine_a_conic ). But if parabolas are conic sections, and if 3 points are sufficient to determine a parabola (since we can solve the resulting system of equations for the parabola equation's constant, coefficient of $x$, and coefficent of $x^2$), how can it be that 5 points are necessary to determine any conic section?","['algebra-precalculus', 'conic-sections', 'geometry']"
1735657,"If $n={k^2 \choose k}$, then what is $k$?","Given that:
$$n={k^2 \choose k}$$
what is $k$ as a function of $n$? So far, I have found the following approximation: $$ n \approx (k^2)^k  = (k^k)^2 $$
$$ \sqrt{n} \approx k^k $$ If we take this approximation as an equality, then according to this answer : $$ k = {\ln{\sqrt{n}} \over W(\ln{\sqrt{n}})} $$
where $W$ is Lambert's function. Asymptotically, $W(z) = \Theta(\ln z)$, so we get: $$ k = \Theta\left({\ln n \over \ln \ln n}\right) $$ Is this approximation correct (asymptotically)? Is there a better approximation?","['combinatorics', 'asymptotics', 'inverse-function']"
1735683,$n\times n$ chessboard game with coins,"The rows and the columns of an $n\times n$ chessboard are numbered $1$ to $n$, and a coin is placed on each field. The following game is played:
  A coin showing tails is selected. If it is in row $x$ and column $y$, then every coin with row number at least $x$ and a column number at least $y$ is turned over. This procedure is repeated. What is the number $L(n)$ for which it is possible to achieve in at most $L(n)$ steps that all coins on the board show heads, whatever be the initial distribution of heads and tails? I proved by induction that it is always possible to achieve the final position in maximum $n^2$ steps, but I can't show for every $n$ a case where $n^2$ is actually needed.","['chessboard', 'combinatorics', 'induction', 'extremal-combinatorics']"
1735723,limit of product exists and one limit exists,"Question is to check : If  $\lim_{n\rightarrow \infty}a_nb_n$ exists and $\lim_{n\rightarrow \infty}a_n$ exists implies $\lim_{n\rightarrow \infty}b_n$ exists. Considering $a_n=\frac{1}{n}$ and $b_n=n$ then we see that  $\lim_{n\rightarrow \infty}a_nb_n$ exists, equals to $1$  and
$\lim_{n\rightarrow \infty}a_n$ exists and equals to $0$. In this case $\lim_{n\rightarrow \infty}b_n$  does not exists.. So, the answer to the question is Not always .. Now, what if $\lim_{n\rightarrow \infty}a_n$ exists and is non zero and $(b_n)$ is bounded? Suppose that $\lim_{n\rightarrow \infty}a_nb_n=M$ with  $\lim_{n\rightarrow \infty}a_n=P\neq 0$ and $|b_n|\leq A$ for all $n\in \mathbb{N}$. I claim that $\lim_{n\rightarrow \infty}b_n=\frac{M}{P}$ Consider $|b_n-\frac{M}{P}|$.. We estimate this. Given $\epsilon>0$ there exists $N\in \mathbb{N}$ such that $|a_nb_n-M|<\epsilon$ and $|a_n-P|<\epsilon$ for all $n\geq N$. $$|b_n-\frac{M}{P}|=\frac{1}{P}|Pb_n-M|=\frac{1}{P}|Pb_n-a_nb_n+a_nb_n-M|\leq \frac{1}{P}|b_n||a_n-P|+\frac{1}{P}                                   \epsilon$$
As $(b_n)$ is bounded, we have for all $n\geq N$
$$|b_n-\frac{M}{P}|\leq \frac{1}{P}A\epsilon+\frac{1}{P}                                   \epsilon=\epsilon\left(\frac{1}{P}(A+1)\right)$$ Thus, we are done. I am just wondering if i can relax any of the conditions that i have assumed. Help me to know more about this.","['real-analysis', 'limits']"
1735743,Quotient of a scheme under infinite group action,"Let $X=\mathbb{A}^2\setminus\{(x,y)\}$ be the affine scheme minus the origin (say over a field $k$). Consider the action of the group $G=k^*$ given by $(x,y)\mapsto (\alpha x,\alpha^{-1}y)$ for any $\alpha\in k^*$. Prove that $X/G$ (which a priori is just a ringed space) is in fact a scheme. What if $X=\mathbb{A}^2$? I think that the first quotient is $\mathbb{P}^1$, but I'm not sure how to show it for real. My intuitive reasoning is as follows: let's assume that $k$ is algebraically closed. Then the equivalence classes of closed points are the $x$-axis, the $y$-axis, and all the equilateral hyperbolas $xy=c$ ($c\neq 0$). So if I take say the line $y=1$ this intersects exactly once all the classes apart from one (namely, the $x$-axis). The quotient of $X$ minus the $x$-axis is then (or, at least, seems like) $\mathbb{A}^1$, and then the whole quotient is $\mathbb{P}^1=\mathbb{A}^1\cup\{[\text{$x$-axis}]\}$. Also, if I compute the ring of fixed polynomials of $X$ minus the $x$-axis I get $k[xy]\cong k[t]$ (the problem with this is that I get the same with $X$ minus the $y$-axis, so it doesn't seem to give a $k$ as global sections, as I would expect). Also this doesn't help me for the second question. Could you please show me how to really prove this (that is: to give a proof in the language of schemes that considers all points equal, and that adapts to the second case).","['schemes', 'quotient-spaces', 'algebraic-geometry']"
1735746,What is the idea behind Green's function? What does it do?,"I have an exam on ordinary and partial differential equations in a couple of days and there is one concept that I am really struggling with: Green's function. I have basically read every PDF-file on the first ten Pages of google but it just doesn't make any sense to me. Maybe some of you can help me understand the following questions: What is Green's function exactly? When can I use it to solve
  differential equations (when shouldn't I use it)? Which differential
  equations can be solved using this method? Can you maybe show me an example how one would solve an ode or pde using Green's function?","['greens-function', 'ordinary-differential-equations', 'partial-differential-equations']"
1735751,Existence of incompressible surface in a non-orientable manifold.,"Let $M$ be a compact $P^2$ -irreducible 3-manifold.
  If $M$ is non-orientable, then there is a compact surface $F$ properly embedded in $M$ such that $F$ is two-sided, non-separating and incompressible. Proof : We have that $H^1(M)$ is non zero.
  In particular, there is an essential map $f$ from $M$ to the circle $S^1$. Now let $v$ be a point of $S^1$
  to which $f$ is transverse,we can perform surgery on $f^{−1} (v)$ to make it incompressible. Then $f^{−1}(v)$ is
  the required non-separating incompressible surface $F$. What I don't understand is how do we get such an essential map and why is $f^{-1}(v)$  an incompressible surface?","['differential-topology', 'low-dimensional-topology', 'algebraic-topology', 'general-topology', 'differential-geometry']"
1735755,Why matrices are multiplied the way they are multiplied?,"I couldn't see a specific reason for multiplying every row of A with every column of B. Is this an arbitrary property of multiplication function of matrices? Instead, why don't we simply multiply row#1 of matrix A with row#1 of matrix B, which would help us to do multiplication easier without all that confusion of what we are gonna multiply with what? In this case, product of A(mxn) and B(kxn) would be P(mxk). I know a lot of things would change in today's mathematics if we define multiplication this way. But would that approach cause any problem in the future?",['matrices']
1735762,Prove that trace of a matrix is $0$.,"Let $ n\geq 2 $ and $ A,B,C  \in M_{n}(\mathbb{C}) $ be three matrices so that $$ A^{2}B+BA^{2}=2ABA $$ and $ C=AB-BA $. Prove that $ \mbox{tr}(C^{k})=0,\forall k\in \mathbb{N}. $
I tried solving it by mathematical induction, but it didn't work. The only thing I know is that $ \mbox{tr}(C)=0. $","['matrices', 'trace', 'matrix-equations']"
1735764,dimension and intersection,"Let $X$ be a scheme (say of finite type over a field), $i: Y \hookrightarrow X$ a closed immersion and $j : U \hookrightarrow X$ be the open complement. Let $F$ be an étale sheaf over $X$ ($\overline{\mathbf{Q}}_l$-sheaf if it helps). In the book Weil conjectures, perverse sheaves and the l-adic fourier transform of Kiehl and Weissauer they claim (at least I think that's what they claim) that it is obvious that $$\text{dim}(\text{Supp}(F)) \leq i$$
 is equivalent to 
$$\text{dim}(\text{Supp}(j^*F)) \leq i \text{ and } \text{dim}(\text{Supp}(i^*F))\leq i$$
That the first line implies the second seems reasonable to me but i'm not sure how to show the other implication ? I'm guessing the reasoning is that first of all it's just a statement about topological space : i.e. we are saying that a closed subspace $Z$ of $X$ has dimension less and $i$ if and only if $Z \cap U$ and $Z \cap Y$ have dimension less than $i$. But i'm not sure how to prove this nor that the claim above reduces to this.",['algebraic-geometry']
1735825,Definition of a regular surface,"Here is the definition of a regular surface from Differential Geometry of Curves and Surfaces by Manfredo do Carmo: A subset $S ⊂ \mathbb R^3$ is a regular surface if, for each $p ∈ S$ , there exists a neighborhood $V ⊂ \mathbb R^3$ and a map $f : U → V ∩ S$ of an open set $U ⊂ \mathbb R^2$ onto $V ∩ S ⊂ \mathbb R^3$ such that $f$ is $C^\infty$ . $f$ is a homeomorphism. Since $f$ is continuous, this means that $f$ has an inverse $f^{-1} : V ∩ S → U$ which is continuous; that is, $f^{-1}$ is the restriction of a continuous map $F : W ⊂ \mathbb R^3 → \mathbb R^2$ defined on an open set $W$ containing $V ∩ S$ . For each $q ∈ U$ holds $f'(q) : \mathbb R^2 → \mathbb R^3$ is one-to-one. I don't understand what is meant by that is, $f^{-1}$ is the restriction of a continuous map $F : W ⊂ \mathbb R^3 → \mathbb R^2$ defined on an open set $W$ containing $V ∩ S$ Why does it mention $W ⊂ \mathbb R^3$ and the restriction?","['differential-geometry', 'surfaces']"
1735838,Inconsistency in partial derivatives in polar and Cartesian coordinates,"We know that for polar $(r,\theta)$ and Cartesian $(x,y)$ coordinates: $r=\sqrt{x^2+y^2}$ (1) $x=r\cos\theta$ (2) I am trying to find $\dfrac{\partial r}{\partial x}$. I have tried two methods, which do not give the same answer, and I want to know where I've gone wrong. Method 1 : Use equation (1) to get $$\frac{\partial r}{\partial x}=\frac{x}{\sqrt{x^2+y^2}}=\frac{r\cos\theta}{r}=\cos\theta$$ Method 2 : Use equation (2) to write $$r=\frac{x}{\cos\theta}$$ so $$\frac{\partial r}{\partial x}=\frac{1}{\cos\theta}$$ I think that it's Method 1 that's correct, but I can't see what the mistake is that I've made in Method 2. I'm sure it's blindingly obvious, but any advice would be highly appreciated.","['derivatives', 'partial-derivative']"
1735863,Norm of element $\alpha$ equal to absolute norm of principal ideal $(\alpha)$,"Let $K$ be a number field, $A$ its ring of integers, $N_{K / \mathbf{Q}}$ the usual field norm, and $N$ the absolute norm of the ideals in $A$. In some textbooks on algebraic number theory I have seen the fact: $\vert N_{K / \mathbf{Q}}(\alpha) \vert = N(\alpha A)$ for any $\alpha \in A$. However, I wasn't able to find a proof (neither in books nor by myself). Can someone explain to me, why this is true? Thanks!","['abstract-algebra', 'algebraic-number-theory', 'field-theory', 'ideals']"
1735881,Number of subsets from an ordered set where adjacent elements may or may not be tied together,"Assume we have an ordered set $S$ with a finite number of elements $S=\{1,2,3,\ldots,N\}$. I need to know the number of subsets where adjacent elements from the original set may either be tied together as one ""unit"" shown with a ""-"" between them or separate elements shown as "","" as normally in a subset. For instance, with 2 elements, if $S=\{1,2\}$ this number is 5 where the 5 subsets are: $\{\},\{1\},\{2\},\{1,2\}$ and $\{1-2\}$. And with 3 elements, if $S=\{1,2,3\}$ there are 13 subsets of this kind: $\{\}, \{1\}, \{2\}, \{3\}, \{1,2\}, \{1-2\}, \{1,3\}, \{2,3\}, \{2-3\}, \{1,2,3\}, \{1-2,3\}, \{1,2-3\}$ and $\{1-2-3\}$. With 4 elements I have counted this number to be 34. What is this number in the general case of $N$ elements, where $S=\{1,2,3,\ldots,N\}$ and can a formula be given?","['permutations', 'combinatorics', 'sequences-and-series']"
1735895,Using implicit differentiation,I'm kind of stuck on this question. Use implicit differentiation to find the derivative of $ y =\arccos \left( {\sqrt x}\right) $  as a function of x and say where this derivative is defined. Don't really get the concept of implicit differentiation.,"['derivatives', 'implicit-differentiation']"
1735902,Prove if $f'(1)$ is Real then $f'(1)\ge 1$,"While Solving exams of previous years I encountered this problem which I cannot solve Prove if $f'(1)$ is Real then $f'(1)\ge 1$, Let $f$ be holomorphic(has a derivative) at $\Omega = \{|z|<1\}\cup\{|z-1|<r\}$ for some $r>0$. Assume: $f(0)=0$ $f(1)=1$ $\forall z\in\Omega \space(|z|<1 \implies |f(z)|<1)$ Anyway I try to look at it... I don't get anywhere :\ Thanks",['complex-analysis']
1735910,How to win Matt Parker's jackpot - finding the median of the following distribution,"In a recent video the legendary Matt Parker claimed he kept flipping a two-sided (fair) coin untill he scored a sequence of ten consecutive 'switch flips', i.e. letting $T$ denote a tail and $H$ a head, then a sequence of ten switch flips is defined to be either $THTHTHTHTH$ or $HTHTHTHTHT$. He set up a contest and allowed each viewer to guess once at the exact amount of flips he needed to obtain such a sequence. The ten viewers with the ten closest answers would be awarded a prize. The contest is over, so there is no incentive to keep a solution to the following problem to yourself. What is the best number to bet? Of course this somehow depends on how other viewers answer: you are more likely to win if your bet is not close to many other bets, so if a large number of viewers is mathematically inclined and bets the same number - say 1023 - then it no longer is the best (profit maximizing) bet. I've therefore simplified to the following question: let $X$ be the stochastic variable representing the number of flips needed untill a sequence of ten consecutive switch flips if obtained, then for which number $a \in \mathbb{N}$ does the expected value of the (absolute value of the) error
$$
\mathbb{E}[\vert X - a \vert]
$$
reach its minimal value? It is well-known that $a$ is the median of the (distribution of) $X$, but how can one compute it? Numerical approximations are welcome, theoretical (generalizable) results are preferred. I found a way to compute the expected value of $X$ itself for general $n$ (i.e. the total number of coin flips needed to get a sequence of the form $THTHTHTH...$ or $HTHTHTHT...$ of length $n$). Let $\mathbb{E}_i$ denote the expected number of coin flips needed to get a desired sequence of length $n$, assuming we already have a sequence of length $i \in \mathbb{N}$. We immediately find
$$
\mathbb{E}_0 = 1 + \mathbb{E}_1
$$
since we are certain to have a sequence of length $1$ after one flip. Furthermore, for $1 \leq i \leq n-1$
$$
\mathbb{E}_i = \frac{1}{2}\left(\mathbb{E}_1 + 1\right) + \frac{1}{2}\left(\mathbb{E}_{i+1} + 1\right)
$$
since, given a sequence of $i$ flips which ends, say, on a tail, we have a $\frac{1}{2}$ chance to increase this to a sequence of $i+1$ flips (if we get, say, a head) and a $\frac{1}{2}$ chance to get back where we started, at $1$ flip. Using that $\mathbb{E}_n = 0$ the above gives us system of $n$ equations in the $n$ variables $\mathbb{E}_0, \ldots, \mathbb{E}_{n-1}$. One can easily check that the unique solution is given by
$$
\mathbb{E}_i = 2^{n} - 2^{i} \quad 0 \leq i \leq n
$$
Since Matt Parker started at $0$ and wanted to get $10$ flips, the expected value of the number of flips needed is $2^{10} - 1 = 1023$ and this should be a reasonable bet. Does anyone know how to find the distribution of $X$ (or directly the median of $X$)? Like I said, analytical solutions are of course preferred, but any kind of method - even requiring numerical computations, but preferably not Monte Carlo simulations - would be interesting to me. EDIT: I found out that the problem can be reduced to a combinatorial problem. Indeed, we have that
$$
P(X \leq k) = \frac{\# \lbrace \text{sequences of length $k$ which contain a desired subsequence of length $n$}\rbrace}{2^k}
$$
where $2^k$ is the total number of sequences of length $k$, since every sequence of length $k$ is equally likely to occur. Let $S_k$ be the set of sequences of length $k$ of $0$'s and $1$'s (we identify tails with $0$ and heads with $1$). We have a map
$$
f: S_k \to S_{k-1}
$$
where, for any sequence $s \in S_k$, the $i$th element of $f(s)$ is $1$ if $s(i) \neq s(i+1)$ and $0$ is $s(i) = s(i+1)$. This map makes the desired sequences in $S_k$ correspond bijectively with the sequences in $S_{k-1}$ which contain $n-1$ zeroes in a row. Hence, it suffices to count the number of sequences of a given length $k-1$ which contain $n-1$ zeroes in a row. Any ideas on how to continue?","['median', 'probability-distributions', 'statistics', 'combinatorics', 'recreational-mathematics']"
1735943,"What does the ""$+$"" typically denote when summing random variables?","Let $X_1$ and $X_2$ be two random variables. When in the literature (for example, in the context of the law of large numbers) one sees statements along the lines of $$
X = X_1 + X_2
$$ ...does the ""$+$"" simply denote normal function addition, as in $$
X(k) = X_1(k) + X_2(k)
$$ for all $k$ the domain of $X$, $X_1$, and $X_2$?  Or does this $+$ denote something else?","['statistics', 'random-variables']"
1735961,"Is this a valid definition of ""self-similar fractal""?","I have always been fascinated by self-similarity, particularly in fractals. I was always wanted to find a simple definition of a self-similar fractal. Of course, saying ""is self-similar, and is a fractal (has noninteger fractal dimension)"" is a valid definition, but not the one I was looking for. So here I go. A shape $S$ in euclidean space is a self-similar fractal if: It is self similar (this definition seems as suitable as any, but feel free to use another if you prefer). It does not tessellate the plane (if it does, it is trivially self-similar). For example, the square is self-similar (if you remove the right and bottom edge), but it also tessellates the plane. A line segment too is self similar, and, using an uncountable number of lines it can tessellate the plane. An octagon can not tessellate the plane, but it is not self-similar. So these things are not fractals. Sierpinski's triangle is self-similar but can not tessellate the plane. The Koch Curve is also self-similar and can not tessellate the plane (if you try the same trick with the line, it will necessarily intersect itself). My question is, is the above definition equivalent to being a fractal and being strictly self-similar in the plane? Does it work in other euclidean dimensions? How about other unbounded metric spaces?","['definition', 'metric-spaces', 'fractals', 'geometry']"
1735962,"Find the gradient of $f(x,y,x)$ given its maximum value at a point $P_0$ in the direction $(1,1,-1)$","I am asked to solve the following problem: The directional derivative of the function $f(x,y,z)$ has maximum value of $2\sqrt{3}$ at the point $P_0$ in the direction $(1,1,-1)$. What is the gradient of $f$ at the point? What is the derivative of $f(x,y,z)$ on the direction $(1,1,0)$? My solution: Let's say the gradient is $(a,b,c)$ and given that the unit vector for the direction $(1,1,-1)$ is $\frac{1}{\sqrt{3}} \left( 1,1,-1 \right)$ $$
2 \sqrt{3} = \frac{1}{\sqrt{3}} (a,b,c) \cdot (1,1,-1)\\
6 = (a,b,c) \cdot (1,1,-1)\\
a+b-c = 6
$$ We also know that he maximum value for the directional derivative occurs on the direction of the gradient: $$
(a,b,c) = k (1,1,-1)\\
a = k\\
b = k\\
c = -k
$$ Substituting the equations found, we have that $k=2$ and $$(a,b,c) = (2,2,-2)$$ For the second question, the directional derivative is $$
\frac{1}{\sqrt{2}} (2,2,-2) \cdot (1,1,0) = 2 \sqrt{2}
$$ Did I make a mistake somewhere? Thank you.","['multivariable-calculus', 'partial-derivative', 'calculus']"
1736067,"If $f(x)=Ax^2+Bx+C$ and $2A,A+B,C$ are integers, prove that $f(x)$ is integer whenever $x$ is an integer","If $f(x)=Ax^2+Bx+C$ and $2A,A+B,C$ are integers, prove that $f(x)$ is integer whenever $x$ is an integer. I found a way to prove the reverse statement. That is, I can prove that if $f(x)$ is integer whenever $x$ is integer, $2A,A+B,C$ are integers, by finding $f(0),f(1)$ and $f(-1)$. How can I prove the actual statement?","['algebra-precalculus', 'quadratics']"
1736068,What's the intuition behind the identities $\cos(z)= \cosh(iz)$ and $\sin(z)=-i\sinh(iz)$?,"I'm trying to understand in an intuitive manner the relationship between the circular and hyperbolic functions in the complex plane, i.e.: $$\cos(z)= \cosh(iz)$$ $$\sin(z)=-i\sinh(iz)$$ where $z$ is a complex number. From a geometric point of view, what I understand is that cos is the composition of a rotation through $\frac{\pi}{2}$, followed by cosh, and sin is the composition of a rotation through $\frac{\pi}{2}$, followed by sinh, followed by a rotation through $-\frac{\pi}{2}$ (where sin, cos, sinh, cosh are defined as complex functions). Where does this connection come from? Is there some way it can be visualized in terms of complex mappings? (I'm not asking for a proof of the identities, I already know one).","['intuition', 'trigonometry', 'functions', 'complex-analysis', 'visualization']"
1736087,How is the normal ordering on the Natural Numbers defined in Zermelo set theory?,"A fact that often gets mentioned in the elementary development of arithmetic in ZFC is that there are a bunch of different ways one could have defined the natural numbers. The most common alternative to the modern way of doing things is due to Zermelo, who sets $0=\emptyset$ and $n'=\{n\}$. My question is how does one define the normal ordering on this collection using only the resources Zermelo allowed himself (i.e. The normal ZFC axioms, minus replacement, foundation, and a modified version of the axiom of infinity which states the existence of the above set rather than the first von Neumann ordinal)?",['elementary-set-theory']
1736123,Proof that $\partial(A\times B) = ((\partial A)\times B)\cup (A\times(\partial B))$,"I need to prove that: $$\partial(A\times B) = ((\partial A)\times B)\cup (A\times(\partial B))$$ In other terms, the boundary of the cartesian product is the union of the things in the RHS. I've found this question but it does not even provide an intuition. If $x\in ((\partial A)\times B)\cup (A\times(\partial B))$, then certainly $x
\in \partial(A\times B)$ because: $$((\partial A)\times B)\cup (A\times(\partial B))$$ is the union of $$(\partial A, something)$$ with $$(something, \partial B)$$
Any ideads on how to say it rigorously? What about the other side of the proof? What does this result means?","['general-topology', 'elementary-set-theory']"
1736129,How to visualize a $120^\circ$ (or $240^\circ$) rotation of a cube about its body diagonal?,I'm finding rotational symmetries of a cube and have some difficulties with visualizing $120^\circ$ or $240^\circ$ rotations. Any tips?,"['visualization', 'geometry']"
1736138,Abelianization of free product is the direct sum of abelianizations [duplicate],"This question already has answers here : Reference Request: Abelianization of free product is the direct sum of abelianizations (2 answers) Closed 3 years ago . I define $\text{Ab}(G)=G/[G,G]$ where $[G,G]$ is the commutator subgroup. I want to show that $$\text{Ab}(G_1*G_2)\cong \text{Ab}(G_1)\oplus\text{Ab}(G_2)$$ This page gives a categorical proof, but I don't know much category theory. Can someone give a purely group-theoretic proof of this (I know the universal property of abelianizations)? By the universal property, it would suffice to show that the RHS is an abelianization of $G_1*G_2$.","['free-product', 'abstract-algebra', 'free-groups', 'algebraic-topology', 'group-theory']"
1736182,Is a group with exponent 3 abelian?,"Let be $G$ a group. Is the following statement true? If every $x\in G, x\neq e=1$ has order at most 3 (i.e. $x^3=1$), then $G$ is abelian. I wanted to prove that $xy=yx\ \forall x,y\in G$. $$xy=x1y = x(xy)^3y=xxyxyxyy \neq xxxyxyyy=x^3yxy^3=1yx1=yx.$$ So, I've proved that the group with the following properity is not abelian. But I'm not sure whether my proof is correct.","['abelian-groups', 'abstract-algebra', 'group-theory']"
1736201,How do I find time derivatives?,"For example, how would I simplify $ \frac {d}{dt} (q - k\sin\theta)$, where $q$ and $\theta$ are both variables and $k$ is a constant? Can I distribute $\frac {d}{dt}$?","['multivariable-calculus', 'derivatives']"
1736248,Why is this vanishing set nowhere dense? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $A$ be a commutative ring and $f\in A$ be a nonzerodivisor. Why is $\mathrm{V}(f)$ nowhere dense in $\mathrm{Spec(A)}$ ? Edit: This question has been closed because it lacks context and motivation. I try to provide it here. Back when I asked the question, I was a beginner in the field of algebraic geometry, and didn't have enough intuition in the subject to see the right approach. Of course, this is a very basic question in algebraic geometry, and a good exercise for a beginner of the field to learn how to combine geometric intuition and algebraic rigor, which in my opinion should be reason enough to discuss this question here.","['abstract-algebra', 'general-topology', 'algebraic-geometry', 'commutative-algebra']"
1736253,"Let $X,Y$ have the same distribution on common prob space, do they generate same $\sigma$-algebra?","So let $X,Y$ be real random variables on common probability space $(\Omega, \mathcal{F}, P)$, the measures on Borel $(\mathbb{R},\mathcal{B}_{\mathbb{R}})$ induced by $X$ and $Y$ are equal, that is for all $A \in \mathcal{B}_{\mathbb{R}}$. $$ P_{X}(A) = P_{Y}(A)$$
where
$$P_{X}(A) := P(X^{-1}(A))$$ and $$P_{Y}(A) := P(Y^{-1}(A))$$ Do $X,Y$ generate the same $\sigma-$algebra? I feel that it might not be necessarily the case but was not able to construct a counter example. Any help would be appreciated","['lebesgue-measure', 'probability', 'measure-theory']"
1736270,Inverse of cosh(x),"My goal is to find the inverse of $y=\cosh(x)$ Therefore:
$$x=\cosh(y)=\frac{e^y+e^{-y}}{2}=\frac{e^{2y}+1}{2e^y}$$
If we define $k=e^y$ then:
$$k^2-2xk+1=0$$
$$k=e^{y}=x\pm\sqrt{x^2-1}$$
$$y=\ln(x\pm\sqrt{x^2-1})=\cosh^{-1}(x)$$ However, apparently: $\cosh^{-1}(x)=\ln(x+\sqrt{x^2-1})$ is right, but NOT $\cosh^{-1}(x)=\ln(x-\sqrt{x^2-1})$ What step did I miss?","['hyperbolic-functions', 'inverse-function', 'calculus', 'inverse']"
1736273,$\lim_{n\to \infty} (1+n+\cos n) ^\frac{1}{2n+n \sin n}$,"While in class, we were proving a limit problem using the Squeeze Theorem, but when I was reviewing my notes, I came up with a problem,, The first question was to prove that 
$$\lim_{n\to \infty}(1+n)^\frac{1}{n}=1$$ Okay, this was easy. The next question was to use the limit proven above to evaluate the following limit:
$$\lim_{n\to \infty}(1+n+n\cos n)^\frac{1}{2n+n\sin n}$$ In my notes, this was written; $$1\leq(1+n+n\cos n)^\frac{1}{2n+n\sin n} \leq (1+2n+n\sin n)^\frac{1}{2n+n\sin n}$$ And since $$\lim_{n\to \infty}(1+2n+n\sin n)^\frac{1}{2n+n\sin n}=1$$ Therefore by Squeeze Theorem, 
$$\lim_{n\to \infty}(1+n+n\cos n)^\frac{1}{2n+n\sin n}=1$$ My question is that the inequality doesn't seem to make sense.
Is the inequality correct? Does it only hold for very large $n$ or something? Then how would I evaluate this limit by using the first limit equation?","['exponential-function', 'real-analysis', 'trigonometry', 'limits']"
1736287,"I don't understand what a ""free group"" is!","My lecture note glosses over it really, introduces it and says ""well it intuitively makes sense"" but I say, nope it doesn't. Free groups on generators $x_1,...,x_m,x_1^{-1},...,x_m^{-1}$ is a group whose elements are words in the symbols $x_1,...,x_m,x_1^{-1},...,x_m^{-1}$ subject to the group axioms. The group operation is concatenation. What do I not understand? Well, to star with, where's the identity? The operation, say I denote it $*$, is $x_1 * x_2=x_1x_2$ yes? How is the identity defined? I mean, $e*x_1=ex_1$ because it's ""concatenation""  so I cannot conveniently say $e*x_1=x_1$ and ignore the fact I need to ""concatenate"" it. These are apparently words, symbols not numbers. The inverse doesn't make sense too, $x_1*x_1^{-1}=x_1x_1^{-1}$ and period. Not $x_1*x_1^{-1}=e$. I mean, I don't even know what $e$ is supposed to be in this supposedly group object so I am left puzzled. I don't see any mathematics here, concatenation, in other words, is just ""lining up the symbols in order."" It's not like $1 \times 2 \times 10=20$ but $1 \times 2 \times 20=1220$. And another problem. Doesn't the free group have order infinity? It can't be finite can it? Because, say I start with $x_1,...,x_m,x_1^{-1},...,x_m^{-1}$ but it must be closed under concatenation. Well, $x_1*x_2=x_1x_2$ already causes an issue because clearly we just created a new element. A new word $x_1x_2$. Continuing this way, we keep adding the newly created words and reach infinity. And before someone directs me to it, no, wikipedia's page on free groups didn't help me understand this either. This bizarre notion is confusing and incomprehensible than ever. Does anyone know the answers to my questions?","['abstract-algebra', 'group-theory', 'free-groups']"
1736322,Uniformly Most Powerful Test for a Uniform Sample,"Let $X_{1}, \dots, X_{n}$ be a sample from $U(0,\theta), \theta > 0$ (uniform distribution). Show that the test: $\phi_{1}(x_{1},\dots,x_{n})=\begin{cases} 1 &\mbox{if } \max(x_{1},\dots,x_{n}) > \theta_{0} \quad or \quad \max(x_{1},\dots,x_{n}) \leq \alpha^{1/n}\theta_{0}\\ 
0 & \mbox{else } \end{cases}$ Is the UMP (uniformly most powerful test) of size $\alpha$ for testing $H_{0}:\theta = \theta_{0}$ against $H_{1}:\theta \neq \theta_{0}$ I know that the statistic $T$ given by $T(x_{1},\dots,x_{n})=\max(x_{1},\dots,x_{n})$ has the property that $U(0,\theta)$ has an MLR (monotone likelihood ratio) property in $T$. Then, by the Karlin-Rubin Theorem we get a test for $H_{0}: \theta \leq 
\theta_{0}$ against $H_{1}: \theta > \theta_{0}$, of the form $\phi(x)=1$ if $x > x_{0}$ and $0$ if $x < x_{0}$, for $x_{0}$ chosen such that $E_{\theta_{0}}(\phi(x))=\alpha$ However, the Karlin-Rubin Theorem does not give an UMP of the form as specified in the problem. What would be a way to approach this problem? I'm completely lost. Thanks for the help!","['statistics', 'hypothesis-testing', 'probability-distributions']"
1736345,"A subset of [0,1] of measure 1 is dense in [0,1] [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Suppose $E \subseteq [0,1]$ is a lebesgue measurable set with $m(E)=1$. Show that $E$ is dense in $[0,1]$. I would appreciate any useful hints.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
1736351,On normal and algebraic numbers,"I have two questions regarding the nature of normal numbers. 1. It's been shown that 'almost all' real numbers are absolutely normal (meaning they're normal for any integer base $b>1$). Since the set of irrational algebraic numbers is countable, it seems plausible that all members of that set are absolutely normal; Generally, numbers are believed to be normal unless we have a special reason to believe they're not. By the look of it, though, we're still far from proving it- In fact, there hasn't been any algebraic number which was formally proven to be normal! So for all we know, all irrational algebraic numbers may not be absolutely normal. In fact, maybe none of them is normal to any base. Is this possible? Or did I miss any result regarding the normality of algebraic numbers? 2. Has there ever been shown an example of a number which is normal in some base $b$, but is not absolutely normal? (For an example, someone may prove that $\pi$ is normal in base $2$, but not in base $10$) If not, then how do we know that such numbers even exist? Maybe there's no difference between the terms ""normal"" and ""absolutely normal"", and every number that's normal in some base is normal in all bases? Now, saying that normal numbers are hard to research is an understatement. It seems like even though the notions of probability and decimal notation have been there forever, we still hardly know anything about it. What are the current tools that mathematicians use to investigate the subject? Has there been any interesting progress on it lately? (There's this article with explicit example of a computable, absolutely normal number, but that's about it)",['number-theory']
1736372,Variance converging to zero implies weak convergence to delta measure?,"I have the following question: Suppose that I have a sequence of random variables $X_n$ such that all moments exists and are finite. I have that $E[X_n]\to a$, where $a$ is a finite number and also $\text{Var}(X)\to 0$. We may also assume that a density with respect to the Lebesgue measure exists. Does this imply that $X_n\to_w \delta_a$? weakly? Thanks a lot, any ideas on conditions are welcomed! This is true for the Gaussian distribution, but I wondered to what extend we can transfer it. Literature is also welcomed!","['weak-convergence', 'probability', 'stochastic-approximation', 'probability-distributions']"
1736377,Probability of having a disease and testing positive for it,"In a random test you test positive for a disease.In  $5$%  of  cases,  the  test  shows positive  even  when  the  subject does  not  have  the  disease. In  the  population  at  large,  one person  in  $1000$  has  the  disease. What  is  the  conditional  probability  that you  have  the  disease  given  that  you have  been  tested  positive,  assuming that  if  someone  has  the  disease,  he  will test  positive  with  probability  $1$? 
My approach was
$P($Teating positive)=P(test positive).$P($you dont have the disease)+$P($test positive).$P($you have the disease)$$=\frac {999}{1000}.\frac{5}{100}+\frac {1}{1000}=\frac {5095}{100000}$$
P(You have the disease$|$you test positive)=$\frac {P(\text{you have the disease,you test positive})}{P(\text{test positive})}$
$$=\frac {1}{1000}.\frac{100000}{5095}=\frac {20}{1019}$$
Is this correct?",['probability-theory']
1736386,Metrizable space and homeomorphism,"Show that a topological space $X$ is metrizable if and only if there exists a homeomorphism of $X$ onto a subspace of some metric  space $Y$. First, assume that there exists an homeomorphism $f$ between a topological space $X$, and a subspace of a metric space $(Y,d)$, define for $a,b$ in $X$ $$d'(a,b)= d(f(a),f(b)) $$ $d'$ is a metric on $X$, How can I prove that  it generates  the topology on $X$? Also, for the converse, can I just take a metric space $Y$ such that $X\subset Y$ ? or how can I prove that? .",['general-topology']
1736398,Understanding convergence of fixed point iteration,"I was reading some slides explaining the convergence of the fixed point iteration, but honestly I'm not seeing or having an intuitive idea of how fixed-point iteration methods converge. Assuming $p < 1$ as for the fixed point theorem, yields $$|x_{k+1} - x^*| = |g(x_k) - g(x^*)| \leq p |x_k - x^*|$$ This is a contraction by a factor $p$ . So $$|x_{k+1} - x^*| \leq p|x_k - x^*| \leq p^2|x_{k-1} - x^*| \leq \cdots \leq p^{k+1}|x_{0} - x^*| \rightarrow 0$$ The smaller the $p$ , the faster the convergence. Could someone explain me this? Also have another problem. There's then a statement saying For root $x_1^*$ we have the conditions for fixed-point theorem holding $|g'(x)| < 0.4$ , and we expect faster convergence than with the bisection methods. Regarding this last statement, I would have a few questions. What's the relation between the definition above, and the derivative of $g$ being less than $0.4$ ? Why would it be faster than the bisection method? I know that the bisection method converges linearly, but honestly I still didn't have an intuitive idea of these convergence rates.","['derivatives', 'numerical-methods', 'convergence-divergence', 'fixed-point-iteration']"
1736428,Efficiently evaluating $\int x^{4}e^{-x}dx$ [duplicate],This question already has answers here : How to integrate $ \int x^n e^x dx$? (4 answers) Closed 8 years ago . The integral I am trying to compute is this: $$\int x^{4}e^{-x}dx$$ I got the right answer but I had to integrate by parts multiple times. Only thing is it took a long time to do the computations. I was wondering whether there are any more efficient ways of computing this integral or is integration by parts the only way to do this question? Edit: This question is similar to the question linked but slightly different because in the other question they are asking for any method to integrate the function which included integration by parts. In this question I acknowledge that integration by parts is a method that can be used to evaluate the integral but am looking for the most efficient way. This question has also generated different responses than the question linked such as the tabular method.,"['integration', 'calculus']"
1736483,There are apparently $3072$ ways to draw this flower. But why?,"This picture was in my friend's math book: Below the picture it says: There are $3072$ ways to draw this flower, starting from the center of
  the petals, without lifting the pen. I know it's based on combinatorics, but I don't know how to show that there are actually $3072$ ways to do this. I'd be glad if someone showed how to show that there are exactly $3072$ ways to draw this flower, starting from the center of the petals, without lifting the pen (assuming that $3072$ is the correct amount).","['combinatorics', 'graph-theory', 'recreational-mathematics']"
1736551,Bound for a certain integration,"Let $\psi$ be a smooth function with compact support, and $\phi$ is smooth and $\phi'(x) \neq 0$ for any $x$ in support of $\psi$. Define $$I(\lambda) = \int_\mathbb{R} e^{i\lambda \phi(x)}\psi(x) dx$$ for $\lambda > 0.$ Then there exists a constant $c$ such that $$|I(\lambda)| \leq c\lambda^{-a}$$ for any $a > 0$ as $\lambda \rightarrow \infty.$ I guess I should apply integration by parts to have some term related to $\lambda$, but it does not work. Any suggestion or guidance what to try ? --------------------------------- update ------------------------------ First set $$F(\psi)(\lambda) = I(\lambda),$$ then $$F(\psi')(\lambda) = \int_\mathbb{R} e^{i\lambda \phi(x)}\psi'(x) dx = (-i\lambda)F(\phi'\psi).$$
Generally, $$F(\psi^p)(\lambda) = (-i\lambda)^pF((\phi')^p\psi)$$ for $p \in \mathbb{N}.$ Then, by compactness of $\psi$, $$|\int_\mathbb{R} e^{i\lambda \phi(x)}\psi(x)(\phi')^p dx| \leq C.$$
I want to show that, somehow,
$|I(\lambda)| \leq k|\int_\mathbb{R} e^{i\lambda \phi(x)}\psi(x)(\phi')^p dx| $ for some constant $k$, but I get stuck.","['analysis', 'partial-differential-equations']"
1736554,Find f(z) where Z= X+Y,"Let $f_{X,Y}(x,y) = \frac{1}{8}$ for $-2<x<2$ and $0<y<2$. Find $f(z)$ where $Z = X+Y.$ Should I find the marginal of X and Y first, then $$f(z) = \int_{-\infty}^{\infty} f_X(x) f_Y(z-x)dx ?$$","['statistics', 'probability-distributions']"
1736581,Algebraic shortcut to find $a^n + b ^n$?,"Recently, I found this problem online: Given $a+b=1$ and $a^2+b^2=2$, find $a^7+b^7$. Although I could've solved it by substituting the first equation into the second and then using the quadratic formula; the way the question was set up, I suspected that there was a shortcut. However, I couldn't find the solution to the problem on that website, so I'm asking here: If you are given $a+b$ and $a^2+b^2$, is there a shortcut to finding $a^n+b^n$?",['algebra-precalculus']
1736589,Why can't I solve for this second derivative?,"Here's the equation I have to find the second derivative point for. $$f(x)=\frac{x+2}{x^{\frac{1}{2}}}$$
$$f'(x) = \frac{x-2}{2x^{\frac{3}{2}}}$$ From here I then calculate the second derivative and set it equal to 0.
But it doesn't work.. Take a look: $$f''(x)=\frac{-x^\frac{3}{2} + 6x^{\frac{1}{2}}}{4x^{3}} = 0$$
FROM first DERIVATIVE TO second: $$\frac{2x^{\frac{3}{2}}[x-2]'-((x-2)[2x^{\frac{3}{2}}]'}{4x^{3}}$$ $$\frac{2x^{\frac{3}{2}} -3x^{}\frac{3}{2}+6x^{\frac{1}{2}}}{4x^{3}}=0$$
$$-x^{\frac{3}{2}} + 6x^{\frac{1}{2}} = 0$$
$$(-x^{\frac{3}{2}})^{2} + (6x^{\frac{1}{2}})^{2}$$
$$x^{3} + 36x = 0$$
$$x (x^{2} + 36) = 0$$
$$x = 0  \text{   or    } x^{2} = - 36 \text{      no solution..}$$ This doesn't seem right.. Yet I have no idea why. It's easier to write the function as a product but I want to solve it using the quotient rule..
What's going on?","['derivatives', 'calculus']"
1736622,Proving a binomial coefficient identity [duplicate],This question already has answers here : How to prove Vandermonde's Identity: $\sum_{k=0}^{n}\binom{R}{k}\binom{M}{n-k}=\binom{R+M}{n}$? (7 answers) Closed 8 years ago . I'm having some trouble with the following proof: $$\sum^k_{a=0} {{n}\choose{a}}{{m}\choose{k-a}} = {{n+m}\choose{k}}$$ I'm trying to prove this to learn a couple of things about the Pascal's triangle. I don't know where to start on the proof. I have tried expanding both sides using the binomial coefficient property but have had no luck.,"['combinatorics', 'binomial-coefficients']"
1736635,I know Galois theory is used to study fields using properties of groups. Is it ever used to study groups using properties of fields?,"More specifically, are there any results in pure, abstract group theory that are most easily proved using Galois theory?","['galois-theory', 'field-theory', 'group-theory']"
1736666,Show that $L^1$ function is $0$ a. e.,"Suppose $f \in L_1(\mathcal{R})$ satisfies for every measurable $A \subset \mathcal{R}$ $$
|\int_A f| \leq [m(A)]^{(1+\epsilon)}
$$ for some $\epsilon >0$. Prove $f=0$ a.e. This is a problem on my analysis qual review sheet. I've been trying a proof by contradiction with no avail... Help?","['lp-spaces', 'measure-theory']"
1736756,What are the projections of a commutative C* algebra?,I am aware that the commutative C* algebra is $C_0(X)$ for some nice space $X$ but I cannot figure out what the projections should be. The natural candidates (indicator functions on nice subsets of $X$ don't work because they are not continuous).,"['functional-analysis', 'c-star-algebras', 'operator-theory']"
1736801,Is $X$ an algebraic subset? Analytic subset?,"Suppose that $X$ is a subset of $\mathbb{C}^n$, and that every (complex) hyperplane section of $X$ is an algebraic subset (respectively analytic subset) of complex dimension at least one (or empty). Is it then true that $X$ is an algebraic subset (respectively analytic subset)? Note that if every hyperplane section is a bunch of points, then nothing can be said, since any real $2$-dimensional surface in $\mathbb{C}^n$ has this property.","['complex-geometry', 'algebraic-geometry']"
1736860,Simplify $\sum_{k=0}^n (-1)^k {{n}\choose{ k}} {{k}\choose{ j}}$,I have to simplify $\sum_{k=0}^n (-1)^k {{n}\choose{ k}} {{k}\choose{ j}}$. I found following identity which might be useful $(-1)^i{{x}\choose{ i}} = {{i - 1 - x}\choose{ i}}$ [but I don't know how it's possible since $i - 1 - x$ is negative]. Could you help me?,['discrete-mathematics']
1736919,"Definite Integral $\int_0^1 \left \{\frac{1}{x^\frac{1}{6}} \right\}\, dx$","The curly brackets mean 'FractionalPart' which, I believe, is defined as {${x}$}$=x-\lfloor x \rfloor$ where $x \in \mathbb{R}$. My best approximation so far is:  .182657 , however, I suspect there is a closed form expression for this definite integral. My approximation was attained by using a lower bound of .00000001 (a bit to the right of 0) with a graphing program.","['definite-integrals', 'calculus', 'closed-form']"
1736931,Defining a homomorphism given a mapping and terminology/notation associated?,"So the problem is: ""Define a homomorphism $f: (\mathbb{Z}_6, +_6) \  \xrightarrow{onto} (\mathbb{Z}_3, +_3)$. Explicitly tell me how f is defined: Show f is a function, show f is a homomorphism. "" So the wording confuses me a bit, f is just some mapping so it's telling me to FIND a homomorphism that has that same domain and codomain, correct? If so, I made it a piecewise function $
f(x) = \left\{\begin{aligned}
&[0] &&: x=[0],[3] \\
&[1] &&: x=[1],[4] \\
&[2] &&: x=[2],[5] \\
\end{aligned}
\right.
$ where $x \ \epsilon \ (\mathbb{Z}_6)$. Should I put $x \ \epsilon \ (\mathbb{Z}_6, +_6)$ here instead? I feel like that doesn't really workout but I could very easily be wrong, $x \ \epsilon \ (\mathbb{Z}_6)$ seems more natural to me. Now, would it be better to use $f(x) = [1] : x= [3k+1],$ such that $k = 0, 1, 2, ...$ instead of the x = [1],[4] even though the set is small enough that it's easy to described all possible values of x I'm discussing(and doing this for [0] and [2] as well of course). Supposing I already showed f is a function, and I go to show it's a homomorphism, is it okay to go about it by just showing $f([x_1] +_6 [x_2]) = f(x_1) +_3 f(x_2)$, where those $x_1, x_2$ values are all the combinations of x that I've listed? Or should I go about it more generally using x=3k, x=3k+1, x=3k+2 (shorthanding a bit here) as described above? Lastly, for the final conclusion, would the correct form of wording be: $\therefore f(x)$ is a homomorphism $f: (\mathbb{Z}_6, +_6) \  \xrightarrow{onto} (\mathbb{Z}_3, +_3)$ ? Or do I just say something like $\therefore f$ is a homomorphism? All help would be appreciated, just trying to get the proper conventions and understanding down!","['abstract-algebra', 'modular-arithmetic', 'group-theory', 'group-homomorphism']"
1736942,Transpose a matrix then flip it over the anti-diagonal. What is the name of this operation?,"What do you call a matrix operation where you transpose it and then flip it over its anti-diagonal? I find it very useful in electrical network analysis to flip the input and output of a two-port network. $$
\begin{bmatrix}
Y_{11} & Y_{12} \\
Y_{21} & Y_{22}
\end{bmatrix} \rightarrow
\begin{bmatrix}
Y_{22} & Y_{21} \\
Y_{12} & Y_{11}
\end{bmatrix}
$$","['matrices', 'linear-algebra']"
1736950,Two wins in a row in a game involving three players,"Three players, let's call them $A,B$ and $C$, play a game of chess. The first match is between $A$ and $B$. The winner will go on to play the third player (who is $C$ in the second match). The game continues until a player win $2$ matches in a row, who will be the eventual winner. The chance for each player to win a match is one half. Find the chance of winning the game for $A,B$ and $C$.",['probability']
1737014,"Show that $\Bbb Q(\sqrt[p]{a}, \omega )=\Bbb Q(\sqrt[p]{a}+ \omega )$","Show that $\Bbb Q(\sqrt[p]{a}, \omega )=\Bbb Q(\sqrt[p]{a}+ \omega )$, where $\omega=e^{2\pi i/p}$ and $a$ is prime.  For simplicity let's call the left hand field $K$, and the right hand field $R$.  I know that the strategy is to show inclusion both ways to get the inequality.  I also know that $K$ is the splitting field of the polynomial of $\sqrt[p]{x}-a$, I have proven this. I can show that $R \subseteq K$ since I know that $\omega, \sqrt[p]{a} \in K$ implying that $\omega+\sqrt[p]{a} \in K$ implying $R \subseteq K$. I have trouble showing the opposite inclusion.  I know the goal is to show that $\omega, \sqrt[p]{a} \in R$ knowing that $\omega+\sqrt[p]{a} \in R$.  I tried multiple times to show this, mainly playing around with different polynomial and using the binomial theorem but I can't figure anything out for this. Any hints or help to show this is appreciated.  Thanks in advance",['abstract-algebra']
1737017,Show that $f$ is either injective or a constant function.,"Let $\Omega$ be a domain in $\mathbb{C}$ and let $\{f_n\}_{n \in \mathbb{N}}$ be a sequence of injective functions that converge in
$O(\Omega)$ to $f$ . Show that $f$ is either injective or a constant function. How does the conclusion change if, instead of a domain, we allow $\Omega$ to be an arbitrary open set ? I know that $f$ is holomorphic as an almost uniform limit. But I dont know how to proceed.",['complex-analysis']
1737022,"Showing that $\langle T(u),T(v)\rangle = \langle u, v \rangle$ implies $T$ is a linear isometry","Let $T$ belong to $\mathcal{L}(H)$ (i.e., the set of linear operators from $H \mapsto H$ where $H$ is a Hilbert space). I need to show that $T$ is an isometry iff $\langle T(u),T(v) \rangle = \langle u, v \rangle$ for all $u,v \in H$ . I have been successfully able to show that if $T$ is an isometry, then $\langle T(u), T(v) \rangle=\langle u, v \rangle $ : Suppose that $T$ is an isometry; i.e., that $\forall w \in H$ , $||T(w)||=||w||$ . Then, of course we have that $||T(w)||^{2} = ||w||^{2}$ . Now, consider $u+v \in H$ . Then, since $T$ is an isometry, $||T(u+v)||^{2} = ||u+v||^{2}$ implies that $\langle T(u+v),T(u+v) \rangle = \langle u + v, u+v \rangle \implies \langle T(u), T(u+v)\rangle + \langle T(v), T(u+v)\rangle = \langle u,u+v \rangle + \langle v, u+v \rangle \implies \langle T(u), T(u) \rangle + \langle T(u), T(v) \rangle + \langle T(v), T(u) \rangle + \langle T(v), T(v) \rangle = \langle u, u \rangle +  \langle u, v \rangle + \langle v, u \rangle + \langle v,v \rangle \implies \langle T(u), T(u) \rangle + \langle T(u), T(v) \rangle + \langle T(u), T(v) \rangle + \langle T(v), T(v) \rangle = \langle u, u \rangle +  \langle u, v \rangle + \langle u, v \rangle + \langle v,v \rangle \implies \langle T(u), T(u) \rangle + 2\langle T(u), T(v) \rangle + \langle T(v), T(v) \rangle = \langle u, u \rangle +  2\langle u, v \rangle + \langle v,v \rangle \implies ||T(u)||^{2} + 2\langle T(u),T(v) \rangle + ||T(v)||^{2} = ||u||^{2} + 2\langle u,v \rangle + ||v||^{2}$ . Then, because $T$ is an isometry, $||T(u)||=||u|| \implies ||T(u)||^{2} = ||u||^{2}$ and $||T(v)||=||v|| \implies ||T(v)||^{2} = ||v||^{2}$ , we have that $2\langle T(u),T(v) \rangle = 2\langle u,v \rangle \implies \langle T(u),T(v) \rangle = \langle u,v \rangle$ . I am having difficulty showing the other direction without using the thing I am trying to prove! Everywhere I've looked has said this direction is ""obvious"", which, although it might be true to those more knowledgeable than I, is meaningless to me. Short of telling me this is ""obvious"" or ""directly follows from"" something without explaining in detail why, could someone please help me show the $\langle T(u), T(v) \rangle = \langle u, v \rangle \implies \, T\,\text{is an isometry}$ direction? Thank you. Also, I understand that a lot of books give this as the definition of what it means to be an isometry; however, it is not. It's something that needs to be proven. The definition of isometry I am assuming as a basic principle here is $\forall w \in H$ , $||T(w)||=||w||$ . And please refrain from snarkiness. Sometimes I have trouble with very simple things, even though very complicated things come easy to me. Please try to understand that not everybody's brain works the same way.","['hilbert-spaces', 'isometry', 'normed-spaces', 'inner-products', 'analysis']"
1737064,Drawing cards without replacement: all kings before any jacks,"This is a question that came up with my friends while playing a card drinking game: You draw cards without replacement from a standard 52-card shuffled deck. What is the probability that you draw all of the kings before drawing any of the jacks? I was thinking of a solution along the lines of combinations, but I'm not sure if that's the way to go. Simulation tells me the answer is ~1.4%, but I don't know how to get to this answer. Disclaimer: This is not a homework question. I'm really just curious.","['probability', 'discrete-mathematics']"
1737066,Well-ordering Principle Equivalent to Discreteness of Integers?,"The Well-Ordering Principle/Axiom for $\mathbb{Z}$ states that every nonempty subset of $\mathbb{Z}^+$ has a minimal element. From this it is easy to show that there do not exist any $n$ such that $0 < n < 1$, and consequently no $n$ with $k < n < k+1$ for all $n$, so that $\mathbb{Z}$ is ""discrete."" My question is: what about the converse? Assuming we have an ordered ring with no $n$ such that $k < n < k+1$ for all $k = k\cdot 1$, must the given ordering be a well-ordering? (Nonempty subsets of the positive set defined by the ordering have a minimal element.) I think I've heard the answer is no, as there exists a model of an ordered ring satisfying this criteria without being well-ordered, but I cannot think of one. If anyone has an answer/proof on this matter, I'd like to see it. Thanks.",['number-theory']
1737073,Number of solutions of $x_1+2\cdot x_2+2\cdot x_3 = n$,"I have to find number of solutions of $x_1+2\cdot x_2+2\cdot x_3 = n$. I guess it would be $[x^n](1+x+x^2 \dots)(1 + x^2 + x^4 \dots)^2$, but how to compute it? I know only that $\frac{1}{1-x} = 1+x+x^2 \dots$.","['generating-functions', 'discrete-mathematics']"
1737080,Exercise #9 in chapter 11 of Rudin's Principles of Mathematical Analysis.,"Suppose $f$ is Lebesgue integrable on $[a,b]$. Let $F(x)$=$\int_{a}^x fdt$. Then prove that $F$ is continuous on $[a,b]$. I know that $F$ is continuous almost everywhere, because $F'(x)=f(x)$ almost everywhere on $[a,b]$. But does this imply that $F$ is continuous on $[a,b]$?","['continuity', 'lebesgue-integral', 'analysis']"
1737175,How to show this subset of $\mathbb{R}$ is countable,"For a finite set $X$, we write $\sum X$ to be the sum of all the numbers in $X$. Suppose we have a set $S \subseteq \mathbb{R}$ such that $-100\le \sum X \le 100$ for all finite subsets $X \subseteq S$. How to show that $S$ is countable? I do not really know where to begin. Hints would be nice. Thank you!",['elementary-set-theory']
1737191,How to know whether an ODE is chaotic?,"Assuming we have an ordinary differential equation (ODE) such as the Lorenz system : $$\begin{aligned}
\dot x &= \sigma(y-x)\\
\dot y &= \gamma x-y-xz\\
\dot z &= xy-bz
\end{aligned}$$ where $$ \sigma = 10, \qquad \gamma = 28, \qquad b = \frac{8}{3}, \qquad
x(0)=10, \qquad y(0)=1, \qquad z(0)=1 $$ This system is known to be chaotic because of its behavior [1] , [2] . However, we normally judge about a system by the output results plot. But how can I judge about a system whether it is chaotic or not just by looking at its formulation in state space representation without plotting it? Or if there is no way for 100% judging, at least is there any way to guess it?","['chaos-theory', 'ordinary-differential-equations', 'dynamical-systems']"
1737194,Extension of Vector field along a curve always exists?,"Let $c:I\to M$ be a $C^{\infty}$ curve on smooth manifold $M$ of dimension $n$ and $X:I\to TM$ be a vector field along $c$, 
$$\forall t\in I\qquad X(t)\in T_{c(t)}M.$$
does there exist a vector field $\bar{X}:M \to TM$ such that $X=\bar{X}\circ c$?","['manifolds', 'vector-fields', 'smooth-manifolds', 'differential-geometry']"
1737211,"If you throw a fair dice $10$ times, what is the probability to throw number $6$ at most once?","If you throw a fair die $10$ times, what is the probability to throw number $6$ at most once? I thought the answer was the sum of probability to throw $6$ once in $10$ throws plus probability to throw $6$ zero times in $10$ throws:
$$\frac{1}{6}\left(\frac{5}{6}\right)^9+\left(\frac{5}{6}\right)^{10}$$ 
Why is this not correct?","['binomial-distribution', 'probability']"
1737230,"Order of integration can be swapped if limits are constants, right?","The order of integration can be easily swapped if the limits are constants, right? $$\int_{a}^{b}\int_{c}^{d}f(x,y)dydx=\int_{c}^{d}\int_{a}^{b}f(x,y)dxdy$$ It only gets computationally hard if the limits are functions of each other, right? $$\int_{a}^{b}\int_{c(x)}^{d(x)}f(x,y)dydx \neq \int_{c(x)}^{d(x)}\int_{a}^{b}f(x,y)dxdy$$ Sorry for the potentially trivial answer. Just doing a reality check over here.","['multiple-integral', 'integration', 'calculus']"
1737253,Continuity of Derivative at a point.,"Is it possible that derivative of a function exists at a point but derivative does not exist in neighbourhood of that point. If this happens then how is it possible.
I feel that if derivative exists at a point then the left hand derivative is equal to the right hand derivative so derivative should exist in neighbourhood of that point.","['derivatives', 'differential']"
1737286,The Zariski closure of a constructible set is the same as the standard closure?,"Question: Let $X$ be an affine variety over $\Bbb C$, and let $Y\subseteq X$ be a constructible set (i.e. $Y$ is a finite union of locally closed sets). Is it true that the Zariski closure of $Y$ is the same as the closure of $Y$ in the standard Euclidean topology inherited from the inclusion $X\subseteq\Bbb C^n$? In this question I asked whether these two closures were the same when $Y$ is the orbit of an algebraic group action. Then, this answer says that the answer is yes because orbits are constructible sets. However, I don't know a proof of the fact that these orbit closures are the same for constructible sets. If $\bar{Y}^E$ denotes the euclidean closure and $\bar{Y}^Z$ the Zariski one, then it is clear that
$$\bar{Y}^E\subseteq \bar{Y}^Z$$
since the Euclidean topology is finer than the Zariski topology. But for the converse, I am clueless.","['general-topology', 'algebraic-geometry']"
1737290,"In a triangle $ABC,$if $\angle A=30^\circ,b=10$ and $a=x$,then the values of $x$ for which there are $2$ possible triangles is","In a triangle $ABC,$if $\angle A=30^\circ,b=10$ and $a=x$,then the values of $x$ for which there are $2$ possible triangles is given by $(A)5<x<10(B)x<\frac{5}{2}(C)\frac{5}{3}<x<10(D)\frac{5}{2}<x<10$ $\cos\angle A=\frac{AB^2+AC^2-BC^2}{2\times AB\times AC}=\frac{AB^2+100-x^2}{20\times AB}$ $\frac{\sqrt3}{2}=\frac{AB^2+100-x^2}{20\times AB}$ I am stuck here.",['trigonometry']
1737315,Distinguishable and indistinguishable objects in distinguishable containers,"My question is rather simple, but I can't seem to figure out how to provide an answer. There are 5 distinguishable toys and 7 indistinguishable sweets that we try to give to 4 distinguishable children. How many ways are there to do that, so that every child gets at least one thing? I could assign an object for every child first and then try to calculate for how many ways it's possible to assign the rest but that seems tricky as I would have to consider lots of cases. Actually all I can think of gets complicated quickly... I did my research and I know there are similar questions, but I couldn't find any which would account for two type of objects (distinguishable and not) at once.","['inclusion-exclusion', 'combinatorics']"
1737328,Maximum number of right-angled triangles,"Let $S$ be a set of $n$ points in the plane, no $3$ collinear. Determine the maximum number of right-angled triangles with all three vertices as points in $S$. This is a slightly more difficult and precise question than IMO 1970 . For $n=3$, clearly the maximum is one. For $n=4$, we can have four triangles, etc. However, I don't know how to continue.","['combinatorics', 'combinatorial-geometry', 'extremal-combinatorics']"
1737340,All-Russian Olympiad question (sum of symmetrical functions),"(All-Russian Olympiad, $1995$, $11^{th}$ Graders, Final Round) Prove that every real function, defined on all of $\mathbb R$, can be represented as a sum of two functions each of which has a vertical axis of symmetry (presumably the line $x=$ something). There's a ""solution"" on Art of Problem Solving but it's hardly complete and gives me little help. In essence, it says that arbitrary functions $g,h$ such that $g+h=f$ on $[0,1]$ can be extended so that $g$ is symmetrical around $x=0, h$ around $x=1$. How can such an extension be done?","['contest-math', 'symmetry', 'functions']"
1737397,Second derivative of Kullback–Leibler divergence,"The Kullback-Leibler divergence is defined here . I have to find the second derivative of $\textrm{KL}(p(s, \theta)||\mu(s) q(\theta, s))$ regarding $p(s, \theta)$, where $p(s, \theta)$ is a joint probability (and therefore, $\frac{1}{p(s, \theta)} \geq 0$), and $\frac{\partial^2 p(s, \theta)}{\partial p(s,\theta)} = 0$. By definition, $\textrm{KL}(p(s, \theta)||\mu(s) q(\theta, s)) = \sum\limits_{i} P(i) \log \frac{P(i)}{Q(i)}$, where $Q(s,\theta)=\mu(s) q(\theta, s)$. The final result of the derivation must show that the second derivative of $\textrm{KL}(p(s, \theta)||\mu(s) q(\theta, s))$ is non-negative. My colleague scribbled these steps before leaving: $ \frac{\partial^2 \sum\limits_{i} p(s, \theta) \log \frac{p(s,\theta)}{Q(s, \theta)}}{\partial p(s,\theta)|s,\theta} = \\
 P(s,\theta) \log P(s,\theta)-P(s,\theta) \log Q(s,\theta) = \\
 \log P(s,\theta) * \frac{1}{P(s,\theta)} = \\
 \log P(s,\theta) - \log Q(s,\theta) = \\
 \frac{1}{P(s,\theta)} \geq 0.$ But this was really fast, and his handwriting isn't the best. Therefore, there might be some details wrong (and he might also have made a mistake). I'm guessing in the second line, some of terms must be derivated (as if it were a first derivation of a multiplication $(fg)' = f'g + fg'$), but the minus sign doesn't correspond and we are doing a second derivation. I'm also assuming he omitted the $\sum$. On the third line, I guess the second half of the equation equals $0$ and he derived the $\log$ into $\frac{1}{P(s,\theta)}$, but why is there a $\log$ still? On the fourth line there are other $\log$s, which I have no idea where they came from, but if we derive everything, we reach the final line, which we know is positive, and the proof ends. I tried to reach the solution on my own, like this $ \frac{\partial^2 \sum\limits_{i} P(i) \log \frac{P(i)}{Q(i)}}
 {\partial P(i)} = \sum\limits_{i} P'' \log \frac{P}{Q} + 2 P' \log '\frac{P}{Q} + P \log '' \frac{P}{Q} = \sum\limits_{i} 0 + 2\frac{Q}{P} + P \frac{PQ'-QP'}{P^2} = \sum\limits_{i} 2\frac{Q}{P} + \frac{PQ'-QP'}{P} = \sum\limits_{i} 2\frac{Q}{P} - \frac{Q}{P} = \sum\limits_{i} \frac{Q}{P}
 $ But I can't really move from here to the final solution. What did I do wrong? What was my colleague doing?","['derivatives', 'partial-derivative']"
1737403,Proof of this inequality,"I have a finite sequence of positive numbers $(a_i)_1^n$ for which: $a_1>a_n$, $a_j\geq a_{j+1}\geq\cdots\geq a_n$ for some $j\in\{2,\ldots,n-1\}$, $a_1>a_2>\cdots>a_{j-1}$, $a_j\geq a_i$ for all $1\leq i\leq n$. I conjecture that: $$(a_n+a_2+\cdots+a_j)\left(\sum_{i=j+1}^{n-1}{\frac{a_i^2}{(a_1+\cdots+a_i)(a_n+a_2+\cdots + a_i)}}+\frac{a_1+a_n}{a_1+\cdots+a_n}\right) \geq  (a_n+a_1+\cdots+a_j)\left(\sum_{i=j+1}^{n-1}{\frac{a_i^2}{(a_1+\cdots+a_i)(a_n+a_1+\cdots + a_i)}}+\frac{a_n}{a_1+\cdots+a_n}\right).$$ I have an unappealing brute-force proof when $n\in\{3,4,5\}$  but I can't prove it in general. I have tried calculus to no avail, and it doesn't seem like a good fit for any of the standard inequalities.Does this look even remotely similar to anything already done? I appreciate that it's a rather ugly inequality but some suggestions would be greatly appreciated! The proof when $n=3$ is outlined below. By condition 2. we know that $j=2$ so that \begin{align*}
(a_3+a_2)\left(\frac{a_1+a_3}{a_1+a_2+a_3}\right)-(a_3+a_1+a_2)\left(\frac{a_3}{a_1+a_2+a_3}\right)=\frac{a_2(a_1-a_3)}{a_1+a_2+a_3}>0
\end{align*}
where we have used condition 1, which states that $a_1>a_3$.The proofs when $n=4$ and $n=5$ are likewise, only uglier. When $n=5$ the trick is to find common denominators then simply pair each negative term with some larger positive term. It's horrible, but it works. Perhaps a general proof would involve a similar argument but more formalised? If a full proof can't be found then I'd be happy for a proof in the special case where $j=2$ and $j=3$.","['real-analysis', 'inequality', 'sequences-and-series']"
1737419,infimum in inequalities,"I am just starting on analysis and I have a question about the concept of infimum: Consider this scenario: Theres is metric space (X,d) and a set $A \subseteq X$, hence for any $x,y \in X$ and $a\in A$ $ d(x,a) \leq d(x,y) +d(y,a) \; \forall a \in A$ .... this is true since d() is a valid metric. Now can I justify the following statement: $\inf_{a\in A} d(x,a) \leq d(x,y) + \inf_{a \in A} d(y,a)$ Basically $ d(x,A) \leq d(x,y) + d(y,A) $? Is is it OK to take the infimum on both sides of the inequality? How to argue that doing so is right? the '$a\in A$' which minimises (weakly speaking here) d(x,a) need not be the same '$a\in A$' which minimises d(y,a)? P.S: This question is in the backdrop of proving that the function d(x,A) is continuous","['functional-analysis', 'real-analysis']"
