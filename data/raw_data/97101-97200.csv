question_id,title,body,tags
1339134,One-to-one correspondance between zeta zeros and the prime powers?,"I have noticed an interesting property related to the Gibbs phenomenon for the Fourier transform of the zeta zeros in Riemann's explicit formula, namely that the rate at which $r\rightarrow 2 $ in the interval $[2,3]$ where $r$ is the point at which $$\operatorname{li}(x)-\sum_{\rho}\operatorname{li}(x^\rho)-\log 2+\int_{x}^{\infty}(dt)/(t(t^2-1)\log t)=1$$ for partial sums of $\sum_{\rho}\operatorname{li}(x^\rho).$ From initial observations, it seems that for each sucessive zero added, $r-2\sim C/\operatorname{li}(n)$ for some $C<1/2.$ Much the same results can be achieved with finding $r$ for the partials sums at the points where $$n-\sum_{\gamma}^{}\dfrac{2\log n\sin(\gamma \log n )}{\gamma\sqrt{n}} = 5/2$$ where $\gamma=$ imaginary parts of zeta zeros. Does this suggest that the zeta zeros and the prime powers are in some sort of one to one correspondance? Resposted to MO here","['number-theory', 'riemann-zeta']"
1339146,Difference between quadric and conic,"What is the difference between a conic and a quadric? I'm guessing that this depends on your ambient space? I think that conics are just special quadrics and are a codimension 1 object and a quadric is the space that gets cut out by a quadric polynomial in any ambient space? Is that correct? For example, would $$\left\{[u:v:w]\in \mathbb{C}\mathbb{P}^2 \; \vert \; u^2 +3v^2 -vw = 0\right\}$$ be a conic (and quadric) hypersurface, but $$\left\{[u:v:w:z]\in \mathbb{C}\mathbb{P}^3 \; \vert \; u^2 +3v^2 -vw = 0\right\}$$ is a quadric hypersurface? Or is it too much to talk about projective space? Or maybe I have to be in Real space? Thanks for the help.","['algebraic-geometry', 'surfaces', 'quadrics', 'algebraic-curves']"
1339161,"What are the odds that the pattern, win lose lose, will happen 23 times in a row (69 rounds)?","In a game of 50/50 (this example could be a coin flip). Before any flips, What are the odds that the pattern win lose lose (heads tails tails if your choice was heads each time.) will happen 23 times in a row (69 rounds)? What about after the chain starts?
After the initial wll, what do the odds become for the next ""Set"" of wll conditions? And the third, up to the 23 occurrence? Again, keeping with your initial choice (option) each time. To put a twist on the question, how does the solution change if the odds are based off the roulette ""50/50"" options? (With pesky zeros added, or coin landing on its edge) Would that change the odds since it's not about the number but rather pattern if the option won or lost? Can this also be broken down to what are the odds for each round (or flip) for round 1 to be a winner round 2 will lose round 3 will lose, (rnd 4 will win 5 will lose 6 will also lose etc to rnd 69?)
wllwllwllwllwllwllwllwllwllwllwllwllwllwllwllwllwllwllwllwllwllwllwll I have seen similar questions about odds and statistics asked, and one of those formulas may work for this riddle, but my knowledge of mathematics are limited. I greatly appreciate the helpfulness of the stack network communities and the cumulative knowledge we share. https://stats.stackexchange.com/questions/12174/time-taken-to-hit-a-pattern-of-heads-and-tails-in-a-series-of-coin-tosses is an enlightening read. The following Stack Exchange links are very informative on the subject as well. What is the probability of a coin landing tails 7 times in a row in a series of 150 coin flips? Measuring Roulette sequence probability Roulette outcome probability If I flip a coin $100$ times, why do the results trend towards $50-50$? Roulette Conditional Probability Roulette betting system probability Simple coin flip probability Probability of $5$ fair coin flips having strictly more heads than $4$ fair coin flips",['probability']
1339165,Expected value of sorted subsequence,"Consider the following discrete random variable: Given an array of size n containing random unique integers, what is the maximal length of a sorted subsequence from that array. What is the expected value of that variable? I strongly consider that it is $O(log(n))$ or $O(\sqrt n)$, but there must be a formal proof or something like this.","['probability-theory', 'probability-distributions']"
1339170,"Does there exist a continuous function from [0,1] to R that has uncountably many local maxima?","Does there exist a continuous function from $[0,1]$ to $R$ that has uncountably many strict local maxima?","['real-analysis', 'functions']"
1339183,Showing that the Prime Number Theorem is Plausible.,"I have started to work through the course notes titled ""Integers, Polynomials and Finite Fields"" by Kenneth Davidson to keep me busy this summer, and there is a question in here This is an exercise to show that the prime number theorem is plausible. (a) Use the integral test to show that the following series converge. $$\sum_{n=2}^{\infty}\frac{1}{n(\log n)^2}$$ and $$\sum_{n=2}^{\infty}\frac{1}{n^2}$$ (b) Show that $\pi(n) > \frac{n}{(\log n)}$ infinitely many times. $\textbf{Hint:}$ Show that the sum of the reciprocals of the primes between $2^{k-1}$ and $2^k$ is at most $2^{1-k} \pi({2^k})$. Use this to estimate the sum of the reciprocals of all primes. part (a) is straight foreward, however I am having some trouble with (b).
I came across this on my search for clues as how to solve it, but the solution assumes the prime number theorem is true , which I obviously cannot do (unless im supposed to use it to see if I end up with a reasonable answer). Here is what I've done so far: There are at most $(2^k - 2^{k-1})/2 = 2^{k-1}$ primes between $2^{k-1}$ and $2^{k}$ (which is an obvious over-estimate since not every odd integer is prime) and so the sum of the reciprocals of the primes cannot be more than the product of the inverse of the least possible prime within the range and number of the most possible primes from $2$ to $2^k$, or $$ \sum_{2^{k-2}}^{2^k} \frac{1}{p_i} < \frac{\pi(2^k)}{2^{k-1}}$$
  (where we simply choose $2^{k-1}$ as the least possible value.) So to estimate the sum of the primes up to $N$ I get,
  $$\sum_{n=2} \frac{1}{p_n} < \sum_{n=2}\frac{\pi(2^n)}{2^{n-1}}$$ Which covers all of the primes I feel like I should do something along the lines of $m = 2^n$ and write $\pi(2m)/m$ or $2\pi(m)/m$ but I don't see how exactly I could change the sum of $\pi(2^k)2^{1-k}$ to $2\pi(m)/m$ without double counting. My first attempt was to try and show $$\sum_{p\;\text{prime}}\frac{1}{p} < \sum_{n\;\text{ odd}}\frac{1}{n} < \int_{2^{k-1}}^{2^{k}}\frac{1}{x}dx < \frac{\pi(2^k)}{2^{k-1}}$$ for primes and odd numbers between $2^{k-1}$ and $2^k$, but was unable to do so. Could someone just nudge me in the right direction, or even let me know if I'm going about this the right way? It would be greatly appreciated.","['prime-numbers', 'number-theory']"
1339190,Are there fewer positive integers than all integers? [duplicate],"This question already has answers here : How to show the integers have same cardinality as the natural numbers? (4 answers) Closed 9 years ago . In our 6th grade math class we got introduced to the concept of integers. With all the talk about positive and negative, it got me wondering. Is the amount of elements in $\mathbb{Z^+}$ less than the amount of elements in $\mathbb{Z}$? Here is how I thought of it. If we have $\mathbb{Z^+}$ and add one element to the ""back"" of it ($\mathbb{Z}^{\geq-1}$) there are certainly more elements in that new set, so there must be more elements in $\mathbb{Z}$ than in $\mathbb{Z}^+$ but on the other side if we try to express the amount of elements in them ""numerically"" (In a loose sense of the word) they both have $\infty$ elements. So what is the right answer? Is there even one? (Please note I am a bit of a layman when it comes to mathematics) Edit: About the possible duplicate, I am not looking for a bijection between the two sets, I am looking for if they even have the same number of elements and why a bijection shows that they do/don't",['elementary-set-theory']
1339197,Modular curves over finite fields,"I'm looking for a detailed reference for modular curves over finite fields, such as $X(N)$, $X_1(N)$, and $X_0(N)$. There seems to be a lot of literature dealing with them over $\mathbb{C}$, but I'm specifically interested in them from the perspective of algebraic geometry. Also, do there exist tables of their point counts over $\mathbb{F}_q$ for some small (but hopefully at least up to $N=15$ or so) values of $N$, or algorithms (e.g. in Sage) for calculating such information? For genus 0 the Riemann hypothesis for curves over finite fields gives an exact formula, of course.","['elliptic-curves', 'modular-forms', 'algebraic-geometry', 'finite-fields', 'reference-request']"
1339224,Integral of binomial coefficients,"Let the integral in question be given by
\begin{align}
f_{n}(x) = \int_{1}^{x} \binom{t-1}{n} \, dt.
\end{align}
The integral can also be seen in the form
\begin{align}
f_{n}(x) = \frac{1}{n!} \, \int_{1}^{x} \frac{\Gamma(t) \, dt}{\Gamma(t-n)} = \frac{(-1)^{n+1}}{n!} \int_{1}^{1-x} (u)_{n} \, du.
\end{align}
The first few values are
\begin{align}
f_{0}(x) &= x-1 \\
f_{1}(x) &= \frac{(x-1)^{2}}{2!} \\
f_{2}(x) &= \frac{2}{4!} \, (2 x^{3} - 9 x^{2} + 12 x - 5).
\end{align} The question then becomes: What is the general series form of $f_{n}(x)$ ? Is there a connection to known special functions? In particular can $f_{n}(x)$ be related to the Bernoulli numbers of the second kind?","['gamma-function', 'special-functions', 'bernoulli-numbers', 'integration', 'pochhammer-symbol']"
1339233,Boundedness of the norm of the Riemann curvature tensor,"Let $(M,g)$ be a Riemannian manifold and let $R(X,Y)Z$ be its $(3,1)$ Riemann curvature tensor given by $$R(X,Y)Z=\nabla_X\nabla_YZ-\nabla_Y\nabla_XZ-\nabla_{[X,Y]}Z$$ Let the input vectors $X,Y,Z$ come from a compact subset of the tangent bundle. Then is the metric norm of the vector $R(X,Y)Z$ bounded? If not, what extra conditions should we impose on $X,Y,Z$ to make $R$ bounded? EDIT: The input vector fields $X,Y,Z$ won't have to be smooth or continuous, assume that the vector fields just come from a compact subset of the tangent bundle. EDIT II: Since the Riemann curvature tensor does NOT depend on the values of vector fields $X,Y,Z$,but just depends on the pointwise values, I can re-ask my question by saying will $R(X,Y)Z$ be bounded if I just work with uniformly bounded values of $X,Y,Z$? Thanks!","['analysis', 'geometry', 'riemannian-geometry', 'differential-geometry']"
1339244,Is there a theory of transcendental functions?,"Lately I've been interested in transcendental functions but as I tried to search for books or articles on the theory of transcendental functions, I only obtained irrelevant results (like calculus books or special functions). On the other hand, there's many books and articles on algebraic functions like: Algebraic Function Fields and Codes Topics in the Theory of Algebraic Function Fields Introduction to Algebraic and Abelian Functions Are there any references for the theory of transcendental functions? Did anyone studied rigorously such functions or is this field of mathematics outside the reach of contemporary mathematics?","['reference-request', 'real-analysis', 'functions']"
1339278,"joint distribution of $(W(1),W(3),W(3)-W(2))$ for a brownian motion $(W(t))_{t \geq 0}$","Let $(\Omega,\mathcal{F},P)$ be a probability space, $(W(t),t \ge 0)$ a Brownian motion and $(\mathcal{F}_t,t \ge 0)$ its natural filtration. What is the joint probability distribution of $(W(1),W(3),W(3)-W(2))$? All I know is that $W(1) \sim \mathcal{N}(0,1),W(3) \sim \mathcal{N}(0,3), W(3)-W(2) \sim \mathcal{N}(0,1)$ and that $W(3)-W(2)$ is independent of $W(1)$. A hint would be great. Merci!","['probability-theory', 'brownian-motion', 'normal-distribution', 'probability-distributions']"
1339326,Conditional expectation $\mathbb E\left(\exp\left(\int_0^tX_sdB_s\right) \mid \mathcal F_t^X\right)$,"I have found a theorem (see below) in two papers an I try to figure how it could be proved. The result seems to be intuitive, but I'm not able to prove it in a rigorous way. Assumptions : Consider a continuous stochastic process $(X_t)$ together with a Brownian motion $(B_t)$. The two processes are assumed to be independent. Their natural filtrations are denoted by $(\mathcal F_t^X)$ and $(\mathcal F_t^B)$ Theorem : Under the above assumption, the following relation holds:
$$\mathbb E\left(\exp\left(\int_0^tX_sdB_s\right) \mid \mathcal F_t^X\right)=\exp\left(\frac12\int_0^tX_s^2ds\right)$$ Proof 1 I have found a proof in Piterbarg page 1 (see here for the main article). The proof is based on computing the expectation path by path. That is, they assume that the path $(X_t)$ is known and compute the integral. However, I believe that this argument only works when the number of paths $(X_t)$ is finite, using this result. Proof 2 In Sin this result is proved (in particular) when $(X_t)$ is given by the dynamic $dX_t=X_td\tilde B_t$, where $(\tilde B_t)$ is a Brownian motion independent of $(B_t)$.
They define the processes 
$$S_t=\exp\left(\int_0^tX_sdB_s-\frac12\int_0^tX_s^2ds\right)\quad\text{and}\quad S_t^{(n)}=S_{t\wedge\tau_n},$$
where we define the following stopping time
$$\tau_n=\inf\left\{t>0:\int_0^t X_s^2ds\geq n\right\}.$$
In the paper, they use the following step, based on the Lebesgue dominated convergence:
$$\mathbb E(\lim_{n\to\infty}S_T^{(n)})=\lim_{n\to\infty}\mathbb E(S_T^{(n)})$$ However I don't directly see how the Lebesgue dominated convergence can be applied in this case. Question : Can someone explain me why this results holds or has a good reference book about it? Attempt of a proof : Following this post , one can prove the result for simple processes, that is when
$$X_s =\sum_{j=1}^n 1_{[t_{j-1},t_j)} \xi_j.$$
Now, we can take a sequence of processes $(X_s^n)$ converging to $(X_s)$ (with respect to the sup norm):
$$(X_s^n)\to(X_s)\quad(n\to\infty)$$
Using the Itô isometry, we obtain the following convergence in probability:
$$\int_0^tX_s^ndB_s\to\int_0^tX_sdB_s\quad (n\to\infty)$$
For each subsequence, we can find a subsubsequence (wlog $n_k$) such that the following convergence holds almost surely:
$$\int_0^tX_s^{n_k}dB_s\to\int_0^tX_sdB_s\quad (k\to\infty)$$
If the Lebesgue dominated convergence theorem did hold, then we could conclude that 
$$\mathbb E\left(\exp\left(\int_0^tX_sdB_s\right) \mid \mathcal F_t^X\right)=\exp\left(\frac12\int_0^tX_s^2ds\right).$$ However I can't find an integrable majoring function. Remark :
What I basically did above is use the following property, which is true when $X$ is a discrete-valued random variable (see here ). The conditional expectation of $Y$ given $X$ is given by $\mathbb E(Y \mid \sigma(X))=f(X)$
  where $f(x)=E(Y \mid X=x)$. This computation seems to work above, by conditioning on the process $(X_t)$, even though it is not mathematically correct. In my view, this way of reasoning would fail in the following case if we say that
$$\mathbb E\left(\exp\left(\int_0^tX_sdB_s\right) \mid \mathcal F_t^B\right)=f((B_s)_{0<s<t})$$
where 
$$f((b_s)_{0<s<t})=\mathbb E\left(\exp\left(\int_0^tX_sdB_s\right) \mid(B_s)_{0<s<t}=(b_s)_{0<s<t}\right)=\mathbb E\left(\exp\left(\int_0^tX_sdb_s\right)\right)$$ Namely, we would (almost surely) integrate with respect to a realization of the Brownian path $(b_s)_{0<s<t}$ which isn't of locally bounded variation. Thus the function $f$ is not well defined.","['probability-theory', 'conditional-expectation', 'proof-verification', 'stochastic-processes', 'brownian-motion']"
1339336,What is the asymptotic value of the smoothed probability in a HMM model?,"If I have a HMM model with a hidden markov chain $(S_t)_t$ with 3 states and if I assume that the distribution of the observation knowing in which state it is, is a normal. Do I know what is the value asymptotic of the smoothed probabilities? In other words what is $P(S_t=s|Y_1,..,Y_{\infty})$?","['probability-theory', 'statistical-inference', 'bayesian-network', 'statistics', 'probability']"
1339342,Classification of isolated singularity by limit,"Let $z_0$ be an isolated singularity of $f$ so there exist a punctured ball $B'$ centered in the singularity where $f$ is holomorphic.
Let $f(z)=\sum_n a_n (z-z_0)^n$ be the Laurent series of $f$ in $B'$. 1. $z_0$ is a removable singularity iff $\lim_{z \to z_0}f(z)$ exists 2. $z_0$ is a pole iff $\lim_{z \to z_0}f(z)=\infty$ 3. $z_0$ is an essential singularity iff $\lim_{z \to z_0}f(z)$ does not exists (either finite or infinite) Proof of 1 .
If $z_0$ is a removable singularity then $f(z)=\sum_{n=0}^{+\infty} a_n (z-z_0)^n$ so it follows $\lim_{z \to z_0}f(z)=a_0$. Conversely if the limit exists, putting $f(z_0):=\lim_{z \to z_0}f(z)$ gives an holomorphic extension of $f$. Proof of 2 .
If $z_0$ is a pole of order $m$ then $g(z)=f(z)(z-z_0)^m$ is holomorphic and so $\lim_{z \to z_0}f(z)=\lim_{z \to z_0}\frac{g(z)}{(z-z_0)^m}=\infty$.
Conversely by hypotesis one has that $\lim_{z \to z_0}g(z)=0$ where $g(z):=1/f(z)$; so $g$ can be extended holomorphic over all the ball and has a zero in $z_0$. It follows that $f$ has a pole in $z_0$. Proof of 3 .
Let $z_0$ be an essential singularity. By Casorati-Weierstrass, $f(B')$ is dense in $\mathbb C$ and so $\forall w \in \mathbb C, \forall \epsilon>0, \exists \zeta \in B'$ such that $|f(\zeta)-w|<\epsilon$. Take $w,w' \in \mathbb C$ with $w \neq w'$, then using the previous statement one can construct two sequences $\{z_n\}$ and $\{u_n\}$ such that $f(z_n) \to w$
 and $f(u_n) \to w'$. So $ \lim_{z \to z_0}f(z)$ does not exist. Can I use exclusion for the converse? I mean, if the limit of $f$ in $z_0$ does not exist then $z_0$ is not a removable singularity or a pole and so it is an essential singularity.",['complex-analysis']
1339377,Extend a map to a 1-cocycle,"Let $\Gamma=PSL(2,\mathbb{Z})$ be the modular group with the usual presentation $\Gamma=\langle S,U,T|\ S^2=U^3=1, T=US\rangle$ where $S=\left(\begin{smallmatrix}0&-1\\1&0\end{smallmatrix}\right)$, $U=\left(\begin{smallmatrix}1&-1\\1&0\end{smallmatrix}\right)$ and $T=\left(\begin{smallmatrix}1&1\\1&0\end{smallmatrix}\right)$. Then $\Gamma$ acts on the vector space $V$ of polynomials of degree $\leq k$ for an even positive integer $k$ by $$P|_k\gamma=(cx+d)^kP\left(\frac{ax+b}{cx+d}\right), \qquad \gamma=\left(\begin{smallmatrix}a&b\\c&d\end{smallmatrix}\right)\in \Gamma.$$ A 1-cocyle is a map $f:\Gamma \rightarrow V$ such that $f(\gamma_1\gamma_2)=f(\gamma_1)|\gamma_2+f(\gamma_2) \ \forall \gamma_1,\ \gamma_2 \in \Gamma $. Suppose $f:\Gamma \rightarrow V$ is a map such that $f(T)=0$, $f(S)=Q$ with $Q+Q|S=0, \ Q+Q|U+Q|U^2=0$ then can one extend $f$ to a 1-cocycle?","['modular-forms', 'number-theory', 'group-cohomology', 'homological-algebra']"
1339387,Sum of Reciprocals of Primes in Imaginary Quadratic Field Diverges (2014 Miklós Schweitzer),"Problem 5 of the 2014 Miklós Schweitzer states: Let $\alpha$ be a non-real algebraic integer of degree two, and let $P$ be the set of irreducible elements of the ring $\mathbb{Z}[\alpha]$. Prove that $$\displaystyle\sum_{p\in P}\frac{1}{|p|^2}=\infty.$$ I think I've figured this out for the cases in which $\mathbb{Z}[\alpha]$ has class number $1$, but have no idea how to extend this reasoning (if it is even correct): Let $\delta$ denote the discriminant of $\mathbb{Z}[\alpha]=\mathcal{O}(\mathbb{Q}(\sqrt{-d}))$. Then, a prime $p$ is expressible as a quadratic form (here, the norm of our quadratic field) with fundamental discriminant $\delta$ of class number $1 \iff (p/\delta)=1$. Rational primes $q$ are inert if $(q/\delta)=-1$. Thus, the sum in question should look something like $$\sum_{(p/\delta)=1}\frac{1}{p}+\sum_{(q/\delta)=-1}\frac{1}{q^2},$$ where $p$ and $q$ range over all rational primes. By Dirichlet's theorem, the sum on the left contains $\frac{1}{2}$ of all primes, and should thus diverge, causing the entire sum to diverge. Note that this chain of reasoning holds only in the very specific case that $\mathbb{Z}[\alpha]$ is a UFD, since we can write things like $(\delta/p)=(p/\delta)$ by Quadratic reciprocity. I'm clueless to how to approach the general case when $\mathbb{Z}[\alpha]$ is not a UFD, and any help would be greatly appreciated. Perhaps since number fields are Dedekind we could look at the norms of prime ideals? I've scoured the internet but am unable to find any solution to this. Thanks in advance, and hopefully what I've written isn't completely bogus.","['number-theory', 'algebraic-number-theory', 'analytic-number-theory']"
1339399,"A bijective continuous map is a homeomorphism iff it is open, or equivalently, iff it is closed. [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Wikipedia states that ""a bijective continuous map is a homeomorphism if and only if it is open, or equivalently, if and only if it is closed."". How do we prove this fact? I can prove the obvious direction, but im unsure how to proceed the other ways","['open-map', 'closed-map', 'continuity', 'general-topology']"
1339439,Poker Combinations: How many ways can you get 4 of the same suit in a hand of 5 cards?,"The homework question is: in how many ways can we get exactly 4 cards of the same suit in a hand of 5 cards? (Order does not matter.) Here is what I have: we need to pick two different suits, decide which suit will have 4 cards and which will have 1, pick 4 ranks for one suit, pick 1 for the other. That is, $$\binom{4}{2}\binom{2}{1}\binom{13}{4}\binom{13}{1}$$ Does this seem correct? Thanks!","['combinations', 'combinatorics']"
1339443,Conversion between trig functions and hyperbolic trig functions,"Using trig identities we can see that  $\sin^2 x + \cos^2 x =  \tanh^2 x + \text{sech}^2 x = 1$ , and so the parametric graph $(\cos t, \sin t)$ is similar to $(\text{sech} t, \tanh t)$. The first graph produces a semicircle when $-\frac \pi2 \le t \le \frac \pi2$ and the second graph when $-\infty \lt t \lt \infty$. My question is if it is possible to convert between the graphs;  e.g. if there is a function $f$ where $(\text{sech} t, \tanh t) = (\cos f(t), \sin f(t))$.","['parametric', 'functions', 'trigonometry', 'graphing-functions', 'circles']"
1339459,"$A=\{A,\emptyset\}$ and axiom of regularity","The axiom of regularity says: (R) $\forall x[x\not=\emptyset\to\exists y(y\in x\land x\cap y=\emptyset)]$. From (R) it follows that there is no infinite membership chain (imc). Consider this set: $A=\{A,\emptyset\}$. I am confused because it seems to me that A violates and does not violate (R). It seems to me that A does not violate (R) because $\emptyset\in A$ and $\emptyset\cap A=\emptyset$. It seem to me that A violates (R) because we can define the imc $A\in A\in A\in ...$ I checked some sources, but I am still confused. Can anyone help me? Thanks.","['elementary-set-theory', 'axioms']"
1339472,Gaussian Curvature of $x^4+y^4+z^4=1$,"Let $S=\{(x,y,z)\in \mathbf R^3 | x^4+y^4+z^4=1  \}$  . To compute the Gaussian curvature $k$ of $S$, I tried an elementary method to find $dN_p$. Let $\alpha (t) = (x(t),y(t),z(t))$ be an parametried curve on $S$. Since $4x^3x'+4y^3y'+4z^3z'=0$, we obtain the normal map $N(t)=\dfrac{1}{n(t)}(x^3(t),y^3(t),z^3(t))$ where $n(t)$ is the absolute value of the vector $(x^3(t),y^3(t),z^3(t))$. Then we can find the explicit form of $dN_P$ from the relation $dN_p(\alpha ' (0))=N'(0)$. However $N'(t)$ is much complicated by $n(t)$. So I doubt whether my approach is right. Is there an easy method of computing $k$? My ultimate goal is to compute $\displaystyle \int_S k$. Should I try another approach?","['differential-geometry', 'curvature']"
1339481,Find a second solution of the given differential equation.,"$$
xy''+y'=0; y_1=ln(x)
$$ I solved this all the way to the end and found my second solution to be $y_2=-1$, but the book says it is $y_2=1$. I am checking my algebra and the method I used was to get it to $u''+u'(\frac{2+ln(x)}{xln(x)})=0$. I then made the substitution $w=u'$. Is this correct? I feel as though I was supposed to use $w=u'(\frac{2+ln(x)}{xln(x)})$ but I'm not sure. Is there a faster way to do this problem?",['ordinary-differential-equations']
1339491,Shapes for tiling a circular disk?,"Does anyone know of a catalog of sorts for what shapes are allowed for tiling a circular disk?  For example, if you are allowed one piece to tile the disk, are all the possibilities essentially ""pie""-shaped wedges, like these examples below? ...where all the pieces meet at a common point at the center of the circle, and all the pieces have an edge which makes up the circumference of the disk?  Are all one-piece tilings rotationally symmetric?  Or are there other possibilities of exactly covering the disk with a single tile?  What about for two or more different tiles? Is there a better set of terms I should use in my search?","['tiling', 'geometry', 'tessellations']"
1339525,"Integral basis of $\mathbb{Q}(\theta)$, where $\theta^3-\theta-4=0$","I am working on the text book ""algebraic number theory"" by Jurgen Neukirch(P15, exercise 6). To prove the integer basis is$ \{1, \theta, \frac{\theta^2+\theta}{2}\}$. After a long and tedious calculation, I still get nothing.(Following the method which can be used in exercise 5: the $\mathbb{Q}(\sqrt[3]{2})$'s case, which is typical and you can find in stackexchange!). Any help is going to be appreciated.","['extension-field', 'abstract-algebra', 'algebraic-number-theory']"
1339540,Why does the derivative of sine only work for radians?,"I'm still struggling to understand why the derivative of sine only works for radians. I had always thought that radians and degrees were both arbitrary units of measurement, and just now I'm discovering that I've been wrong all along! I'm guessing that when you differentiate sine, the step that only works for radians is when you replace $\sin(dx)$ with just $dx$, because as $dx$ approaches $0$ then $\sin(dx)$ equals $dx$ because $\sin(\theta)$ equals $\theta$. But isn't the same true for degrees? As $dx$ approaches $\theta$ degrees then $\sin(dx \,\text{degrees})$ still approaches $0$. But I've come to the understanding that $\sin(dx \,\text{degrees})$ approaches $0$ almost $60$ times slower, so if $\sin(dx \,\text{radians})$ can be replaced with $dx$ then $\sin(dx \,\text{degrees})$ would have to be replaced with $(\pi/180)$ times $dx$ degrees. But the question remains of why it works perfectly for radians. How do we know that we can replace $\sin(dx)$ with just $dx$ without any kind of conversion applied like we need for degrees? It's not good enough to just say that we can see that $\sin(dx)$ approaches $dx$ as $dx$ gets very small.  Mathematically we can see that $\sin(.00001)$ is pretty darn close to $0.00001$ when we're using radians. But let's say we had a unit of measurement ""sixths"" where there are $6$ of them in a full circle, pretty close to radians. It would also look like $\sin(dx \,\text{sixths})$ approaches $dx$ when it gets very small, but we know we'd have to replace $\sin(dx \,\text{sixths})$  with $(\pi/3) \,dx$ sixths when differentiating. So how do we know that radians work out so magically, and why do they? I've read the answers to this question and followed the links, and no, they don't answer my question.","['derivatives', 'calculus', 'trigonometry']"
1339593,anyone can help me with solving this $x^{x^{3}}=3$?,"Find the value of $x$ : $x^{x^{3}}=3$ I tied with ""log"" but I couldn't. any help?",['calculus']
1339599,Compact linear operator,"Today in lecture we were told that for a linear compact operator $T$ on an infinite-dimensional Hilbert space with infinite-dimensional range, we have that $\ker(T)^{\perp}$ is infinite-dimensional, too. Does anybody know why this is the case? I know that this is the same as the closure of the range of the adjoint operator, and in fact the adjoint operator is compact, too. But I don't know if this already tells us that this space is in fact infinite-dimensional?","['analysis', 'operator-theory', 'real-analysis', 'functional-analysis']"
1339609,Quotients of Solvable Groups are Solvable,I just proved that subgroups of solvable groups are solvable. So given that $G$ is solvable there is $1=G_0 \unlhd G_1 \unlhd \cdots \unlhd  G_s=G$ where $G_{i+1}/G_i$ is abelian and for $N$ a normal subgroup we know it is solvable so there is $1=N_0 \unlhd N_1 \unlhd \cdots \unlhd N_{r}=N$ where $N_{i+1}/N_i$ is abelian. I'm trying to construct the chain for the entire group $G/N$ using the Lattice Isomorphism Theorem but am stuck. Is it possible to do this?,"['abstract-algebra', 'group-theory', 'solvable-groups', 'group-isomorphism']"
1339613,Proof: Derivative of $(-1)^{x}$,"The derivative for $(-1)^{x}$ is 
\begin{equation}
\frac d{dx}\left[(-1)^x\right]=i\pi(-1)^{x}
\end{equation}
But why? What happens with higher order derivatives? Thanks in advance.","['calculus', 'complex-numbers', 'derivatives']"
1339618,Connection form on a frame bundle,"Let $(E(M),\pi,M)$ be the frame bundle over a manifold $M$ of rank $n$. Consider a covering of $M$ by open neighborhoods $U_{\alpha}$. Let $s_{i}$ and $t_{j}$ where $i,j\in {1,...,n}$ be frames of $M$ over $U_{\alpha}$ and $U_{\beta}$, respectively. Then there is a $g_{ij}\in GL(n,\mathbb{R})$ such that $t_{j}= s_{i}.g_{ij}$. My question: Why does  connection $1-$form $\omega_{U_{\alpha}}$ over $U_{\alpha}$ with values in the Lie algebra of the group $GL(n,\mathbb{R})$ satisfy the following condition, locally? $$\omega_{U_{\beta}}= g_{ij}^{-1}\omega_{U_{\alpha}}g_{ij}+ g_{ij}^{-1} dg_{ij}$$ Second question:Is there any book on frame bundles that can help me? Thanks.","['differential-geometry', 'fiber-bundles']"
1339631,Integrate $\frac{1}{(1+x^2)(1+x^c)}$ from $0$ to $\infty$ for any $c$. [duplicate],"This question already has answers here : Is the integral $\int_0^\infty \frac{\mathrm{d} x}{(1+x^2)(1+x^a)}$ equal for all $a \neq 0$? (4 answers) Closed 7 years ago . The question is to evaluate 
$$
\int_0^\infty \frac{dx}{(1+x^2)(1+x^c)}
$$
for arbitrary $c\geq0$. Here are my attempts: (The methods behave somewhat differently for $c=0$ but that case is trivial so I will assume $c>0$) Integrate by parts:
\begin{align*}
\int_0^\infty \frac{dx}{(1+x^2)(1+x^c)}&=\arctan(x)\frac{1}{1+x^c}\Big|_0^\infty+\int_0^\infty\arctan(x)\frac{cx^{c-1}}{(1+x^c)^2}dx\\
&=0+\int_0^\infty\arctan(x)\frac{cx^{c-1}}{(1+x^c)^2}dx\\
&=\int_0^\infty\frac{\arctan(x^{1/c})}{(1+x)^2}dx.
\end{align*}
This looks just as bad, if not worse, as before... Partial fractions: good for small values of $c$, but seems impossible as $c$ gets large. Along the same line as partial fractions, but I tried the Ostragodski method, which only helped simplify things for $c=2$. Try and show it doesn't depend on $c$: For $c=1$, $c=2$, and $c=3$, the integral evaluates to $\pi/4$. My gut tells me this isn't a coincidence, so define 
$$
f(c)=\int_0^\infty\frac{dx}{(1+x^2)(1+x^c)}
$$
so that 
$$
f'(c)=\int_0^\infty\frac{-x^c\log(x)}{(1+x^2)(1+x^c)^2}dx.
$$
It would be great if this evaluated to $0$ for arbitrary $c$, but I don't see a nice way to show that it does. Any hints would be greatly appreciated. Thanks in advance.","['contest-math', 'integration']"
1339648,Basic absolute value property,"Hello all I am wondering if anyone has the correct proof that I should use for Spivak calculus ( chapter 1, question 12 )  that says $$|xy|=|x| \cdot |y|$$ from past times I know it is true , but I am not sure the best way to prove it, and I need this property to use in the rest of the proofs as well. Should I write something like $|xy|= xy$ , for  $xy \ge 0$ and $|xy|= -(xy)$ if $xy \le 0 ?$ Or should I write $$|xy|=\sqrt{(xy)^{2}}$$ and expand from that or what? Thanks a lot everyone, I just want to make sure I have covered it all correctly. Preferably the answer will be from someone that is familiar with Spivak , because I would like to be able to prove it the way he would have wanted, i.e., only using what we had learnt up to this point. Thanks!","['absolute-value', 'algebra-precalculus']"
1339649,What's my mistake in the calculation?,"Summation convention holds. If $\frac{\partial}{\partial t}g_{ij}=\frac{2}{n}rg_{ij}-2R_{ij}$, then ,I compute: 
$$
\frac{1}{2}g^{ij}\frac{\partial}{\partial t}g_{ij}=\frac{1}{2}g^{ij}(\frac{2}{n}rg_{ij}-2R_{ij})=\frac{1}{n}r(\sum\limits_i\sum\limits_jg^{ij}g_{ij})-g^{ij}R_{ij}=nr-R
$$ But on the Hamilton's THREE-MANIFOLDS WITH POSITIVE RICCI CURVATURE,the result is :
$$
\frac{1}{2}g^{ij}\frac{\partial}{\partial t}g_{ij}=r-R
$$ I don't know where I make my mistake,and who can tell me ? Very thanks.","['differential-geometry', 'riemannian-geometry', 'ricci-flow']"
1339666,"Why do we refer to the denominator of Bayes' theorem as ""marginal probability""?","Consider the following characterization of the Bayes' theorem: Bayes' Theorem Given some observed data $x$ , the posterior probability that the paramater $\Theta$ has the value $\theta$ is $p(\theta \mid x) = p(x \mid \theta) p (\theta) / p(x)$ , where $p(x \mid \theta)$ is the likelihood, $p(\theta)$ is the prior probability of the value $\theta$ , and $p(x)$ is the marginal probability of the value $x$ . Is there any special reason why we call $p(x)$ the ""marginal probability""? What is ""marginal"" about it?","['probability-theory', 'probability', 'bayes-theorem']"
1339676,What is Homogeneous Coordinates? Why is it necessary in 2D transformation?,"What is Homogeneous Coordinates? Why is it necessary in 2D transformation of objects in computer graphics? The concept of homogeneous coordinates in effect converts the 2D system a 3D one. So, why don't we just use a 3D system instead?","['linear-algebra', 'matrices']"
1339681,Circular uses of L’Hôpital’s rule,"If you try to find the $\lim_{x\to \infty}\frac{\sqrt{x^2+1}}{x}$
using L’Hôpital’s rule, you’ll find that it flip-flops back and forth between $\frac{\sqrt{x^2+1}}{x}$ and $\frac{x}{\sqrt{x^2+1}}$. Are there other expressions that do a similar thing when L’Hôpital’s rule is applied to them? I already know that this applies to any fraction of the form $\frac{\sqrt{x^{2n}+c}}{x^n}$.","['calculus', 'limits']"
1339683,Determinant of a special $4\times 4$ matrix,"Let $f(x)=\sum_{k=1}^{4}a_{k}x^{k},\varepsilon =\cos\frac{\pi}{2}+i\sin\frac{\pi}{2}.$ $\qquad\qquad 4\times 4$ matrix $$T=\begin{bmatrix}
 1&  a_{2}&  a_{3}& a_{4}\\ 
 1&  a_{1}&  a_{2}& a_{3}\\ 
 1&  a_{4}&  a_{1}& a_{2}\\ 
 0&  \varepsilon^{2}&  \varepsilon& 
1\end{bmatrix}$$ Show that $$\det(T)=f(\varepsilon^{2})f(\varepsilon^{3})$$ Further I can generalize this question : Let $f(x)=\sum_{k=1}^{n}a_{k}x^{k},\varepsilon =\cos\frac{2\pi}{n}+i\sin\frac{2\pi}{n}.$ $\qquad\qquad n\times n$ matrix $$T=\begin{bmatrix}
 1&  a_{2}&  a_{3} & \cdots & a_{n}\\ 
 1&  a_{1}&  a_{2}&\cdots & a_{n-1}\\ 
 \cdots&   \cdots&   \cdots&\cdots &  \cdots\\
 1&  a_{4}&  a_{5}& \cdots &a_{2}\\ 
 0&  \varepsilon^{n-2}&  \varepsilon^{n-3}& \cdots&
1\end{bmatrix}$$ Show that $$\det(T)=f(\varepsilon^{2})f(\varepsilon^{3}) \cdots f(\varepsilon^{n-1})$$ Let $$A=\begin{bmatrix} 
 1& 0&  a_{3}&  a_{4}& a_{1}\\
 0& 1&  a_{2}&  a_{3}& a_{4}\\ 
 0& 1&  a_{1}&  a_{2}& a_{3}\\ 
 0& 1&  a_{4}&  a_{1}& a_{2}\\ 
 0& 0&  \varepsilon^{2}&  \varepsilon& 
1\end{bmatrix}$$ then $\det(T)=\det(A)$.  Now add $\varepsilon^{2}$ of row 4 to row 1, add $\varepsilon^{4}$ of row 3 to row 1, add $\varepsilon^{6}$ of row 2 to row 1, we get
$$A=\begin{bmatrix} 
 1& 0&  a_{3}&  a_{4}& a_{1}\\
 0& 1&  a_{2}&  a_{3}& a_{4}\\ 
 0& 1&  a_{1}&  a_{2}& a_{3}\\ 
 0& 1&  a_{4}&  a_{1}& a_{2}\\ 
 0& 0&  \varepsilon^{2}&  \varepsilon& 
1\end{bmatrix}\longrightarrow \begin{bmatrix} 
 1& 0&  \varepsilon^{4}f(\varepsilon^{2})&  \varepsilon^{2}f(\varepsilon^{2})& f(\varepsilon^{2})\\
 0& 1&  a_{2}&  a_{3}& a_{4}\\ 
 0& 1&  a_{1}&  a_{2}& a_{3}\\ 
 0& 1&  a_{4}&  a_{1}& a_{2}\\ 
 0& 0&  \varepsilon^{2}&  \varepsilon& 
1\end{bmatrix}=A_{1}$$ How can I separate $f(\varepsilon^{2})$ from $\det(A_{1})$? If you have another proof to my question,please give me some hints. Any help would be appreciated","['determinant', 'linear-algebra', 'matrices']"
1339708,Dominating a Four Dimensional Chessboard with Rooks,"There is a family of chess problems where you try to dominate a board with as few copies of a given piece as possible. The chessboard is dominated if every square either contains a piece, or is attacked by one. For example, to dominate a usual chessboard with $8$ rooks, simply place a rook on every square of a diagonal. You can easily verify this is optimal, that is, no $7$ rooks can dominate a chessboard. This result easily extends to an $n\times n$ board, for any $n$. You can also ask about rook domination in three dimensions, where rooks can slide left/right, back/front, or up/down. This problem is harder, but there is a nice solution: $\lceil n^2/2\rceil$ rooks are necessary and sufficient to dominate an $n\times n\times n$ board. See here for a proof. My question is about the four dimensional case. Here, there are four axes, and rooks can slide along any axis. Specifically, How many rooks does it take to dominate a $4\times4\times4\times4$ board? I was wondering if anyone had studied this problem before, or had any good ideas of an attack. I know that $32$ rooks are sufficient, while $22$ rooks are insufficient. I've filled pages trying to succeed with $31$ rooks, to no avail. If your curious, the optimal number for a 2 x 2 x 2 x 2  board is 4 rooks, and for a 3 x 3 x 3 x 3 board is 9 rooks.","['graph-theory', 'combinatorics']"
1339713,"$f$ continuous on $\overline{D} \setminus \{1\}$, holomorphic and bounded on $D$. Then $f$ attains its supremum on the boundary","Let $D$ be the unit disc, $f$ continuous on $\overline{D} \setminus \{1\}$, holomorphic and bounded on $D$.  The problem is to show that for all $z \in D$, $$|f(z)| \leq \sup\limits_{|\zeta| = 1, \zeta \neq 1} |f(\zeta)|$$ I'm stuck.  Here are two approaches I tried: I .  $f$ is represented by a convergent power series $\sum\limits_{n=0}^{\infty} a_n z^n$, absolutely and uniformly convergent for $|z| \leq r$, where $r < 1$.  I don't know. II .  For each $0 < r < 1$, there is an angle $\theta \in (-\pi/2, \pi/2]$ such that $|f(z)| \leq |f(r e^{i \theta})|$ for all $|z| < r$ (maximal modulus principle).  Pick $\theta_r$ to be such that $|\theta_r|$ is the supremum of all $|\theta|$ satisfying the condition I just mentioned.  $\theta_r$ would be a limit of the $\theta$, so $|f(z_r)| \geq |f(z)|$ for all $|z| < r$ by continuity, where $z_r$ is defined to be $re^{i \theta_r}$.  The idea is I'm trying to get the $\theta_r$ to not be too close to $0$, if possible. Now pick any sequence of radii $r_1 < r_2 < \cdots $ which converges to $1$.  Then $|f(z_{r_1})| \leq |f(z_{r_2})| \leq \cdots$, and we may choose a convergent subsequence of the $z_n$ converging to, say, $z_0 \in \partial D$.  If $z_0 \neq 1$, we're clearly done. To do this, I want to find a subsequence $z_{n_k}$, and a $\delta > 0$, such that $|\theta_{r_{n_{k}}}| > \delta$ for all $k$.  I can then pick a convergent subsequence of this subsequence to do the trick.  If this is not possible, then it's easy to see that $z_n$ has to converge to $1$ as a result.  The numbers $|f(z_n)|$ are nondecreasing and bounded, so $|f(z_n)|$ tends to a limit as $z_n \to 1$.  By the way I picked $z_n$, this shows that if $\theta_{r_n}'$ is another sequence of angles such that the maximum of $f$ on $|z| = r_n$ is attained at $r_ne^{\theta_n'}$, then $r_ne^{\theta_n'}$ also goes to $1$. Not sure if this approach will go anywhere.",['complex-analysis']
1339754,Linear Operators Denseness and Injectivity,"I'm studying for a Real Analysis prelim and have the following problem: ""Let $X$ and $Y$ be normed spaces over $\mathbb{R}$ and let $$\mathcal{L}(X, Y) = \{T: X \rightarrow Y \mid T \text{ is bounded and linear}\}.$$  Let $X^{*}$ and $Y^{*}$ be the dual spaces of $X$ and $Y$ respectively, and let $T^{+}: Y^{*} \rightarrow X^{*}$ be defined by $T^{+}f = f \circ T$.  Prove that $T^{+}$ is injective if and only if the image of $T$ is dense in $Y$."" I think I have a proof for the forward direction but for some reason the reverse direction is evading me.  Please let me know if what I have so far is correct, and if anyone can give a hint or something about the reverse direction, it would be greatly appreciated. ($\Rightarrow$) Suppose $T^{+}$ is injective but that $T(X)$ is not dense in $Y$.  Then for some $y \in Y \backslash T(X)$, there exists an $\varepsilon > 0$ such that $||Tx - y||\geq \varepsilon$ for all $x \in X$.  Let $f \in Y^{*}$ be defined by $f(z) = || z - y ||$  if $z \in Y\backslash B_{\varepsilon}(y)$ and $\varepsilon$ otherwise.  Also, let $g \in Y^{*}$ be defined by $g(z) = ||z - y ||$ for all $z \in Y$.  Then $T^{+}f = T^{+}g$ and $f(z) = g(z)$ when $z \in T(X)$ but not always when $z \in Y\backslash T(X)$, contradicting $T^{+}$ being injective. ($\Leftarrow$) For this direction, I'm thinking about showing through contraposition by assuming $T^{+}f = T^{+}g$ with $f(z) \neq g(z)$ for some $z \in Y\backslash T(X)$ and arriving at the conclusion that $T(X)$ is not dense in $Y$, but for now can't think of how to do that. P.S. This is my first post on StackExchange, so go easy on me if I made a complete fool of myself; Functional Analysis is quite new to me.","['real-analysis', 'functional-analysis']"
1339777,The least $\aleph$ that has no surjective map from $m$ to it.,Without $AC$. Let $\aleph^*(m)$ be the least aleph that $\not\leq^* m$. How to show that $\aleph^*(m)$ exists and $\aleph^*(m)= \{\alpha\in ON\mid\ \alpha\leq^*m\}$. $ON$ is the class of all ordinal. $a \leq^* b$ means there is a surjective map from $b$ to $a$.,"['elementary-set-theory', 'axiom-of-choice']"
1339805,How to prove this sequence tends to zero [duplicate],"This question already has answers here : Prove $\lim\limits_{n\to\infty}na_n\ln(n)=0$ [duplicate] (3 answers) Closed 9 years ago . Suppose $a_n>0$,$\sum a_n$ converges, $\{na_n\}_{\Bbb N}$ is monotonic, prove
  $$\lim na_n\ln n=0$$ My attempt so far has shown that $\{na_n\}$ is decresing: otherwise, $na_n\ge a_1\implies a_n\ge\frac{a_1}{n}\implies \sum a_n=+\infty$ which contradicts the convergence of $\sum a_n$. My friend has got a bit further:
$(n+1)a_{n+1}< na_n\implies \frac{a_{n+1}}{a_n}<\frac{n}{n+1}$. He then let $$b_n:=\frac{a_n}{\frac{1}{n\ln n}}$$
and therefore
$$\frac{b_{n+1}}{b_n}=\frac{a_{n+1}}{a_n}\cdot\frac{(n+1)\ln(n+1)}{n\ln n}<\frac{\ln(n+1)}{\ln n}$$
However he can't prove the monotony of $b_n$ because the RHS of the inequality is too weak. In fact it only shows $\limsup \frac{b_{n+1}}{b_n}\le 1$, which is not effective here. And I can't come up with a stronger version, either. Can you help me? Any direct help or hint will be appreciated. Thanks!","['sequences-and-series', 'calculus', 'real-analysis', 'limits']"
1339822,$R$ is semisimple iff it is Artinian and $J(R) = 0$,"Let $R$ be a ring with identity. The ring $R$ is semisimple if it is semisimple as a left $R$ module. A module $M$ is semisimple if it can be expressed as a direct sum of simple submodules.
The Jacobson radical of $R$ , denoted by $J(R)$ , is the intersection of all maximal left ideals of $R$ . I am asked to prove this: The ring $R$ is semisimple if and only if it is Artinian and $J(R) = 0$ . I have proved the $\implies$ part. How to prove the converse?
Since $R$ is Artinian every collection of left ideals of $R$ has a minimal element. How to go from here?","['semi-simple-rings', 'abstract-algebra', 'artinian', 'ring-theory']"
1339873,(Is it a set?) Set of all months having more than 28 days.,"Set is a well defined collection of distinct objects. Is the following is a set? Set of all months having more than 28 days. I'm confused here. Because on one hand I think that it is well defined because from person to person its meaning is not changed. On the other hand I think that it is not well defined because if we consider a leap year then February is included else not. Note that the year is not specified , I'm you cannot surely say that February is included or not. Set of eleven best cricketers of the world. This is not a set because the criteria for best cricketer changes from person to person. So the set of all months having more than 28 days . Is it really a set?","['elementary-set-theory', 'definition']"
1339892,Equivalent formulations: pure contraction,"I want to prove the following equivalence: let $T$ be a bounded self-adjoint operator on a Hilbert space $H$. TFAE: $\|Tx\|<\|x\|$ for each $x\in H\setminus\{0\}$ $\|T\|\leq1$ and $\pm1\notin\sigma_p(T)$ where $\sigma_p(T)$ is the point spectrum (the set of all eigenvalues of $T$).
One implication has to be easy from my point of view. Can someone help me with this proof? Thanks a lot.","['hilbert-spaces', 'operator-theory', 'functional-analysis']"
1339901,Hilbert space and uncountable cardinal,Given an uncountable cardinal does there exist Hilbert space with orthonormal basis of that cardinality?,"['hilbert-spaces', 'functional-analysis', 'cardinals']"
1339924,Compute ratio of a rectangle seen from an unknown perspective,"TL;DR: Given 4 points on a two dimentional plane, representing a reclangle seen from an unknown perspective, can we deduce the width / height ratio of the rectangle ? Details: From a picture, and some opencv work (canny, hough lines, bucketing to tell appart ""lines"" and ""columns"", choosing interesting lines, math to deduce lines intersections), I get this: From this step, it's easy to warp it to a ""from the top"" view, using opencv getPerspectiveTransform and wrapPerspective to ""remove"" the perspective, being on the top of the rectangle. My goal now is to keep the aspect ratio of it, as I loose it while doing my actual warping, because I don't know the ratio it should have. For this I have to give to getPerspectiveTransform the 4 destination points where I want my 4 found red points to be after warping, not just 4 random points like (0, 0), (0, 100), (100, 100), (100, 0) leading to a deformation if my 4 red points are not a square. So is there a known way to compute the width/height ratio, or even better the size, of this ""seen thrue a perspective rectangle"" ? For the record and the curious, work-in-progress is here: https://github.com/JulienPalard/grid-finder","['rectangles', 'geometry', '3d']"
1339947,Prove that $\det\left[A^{T}B-B^{T}A\right]=\det[A+B]\cdot\det\left[A-B\right]$,"So I need to prove that: $$\det\left[A^{T}B-B^{T}A\right]=\det[A+B]\cdot\det\left[A-B\right]$$ where $A$, $B$ are two orthogonal matrices, but it seems I'm missing something.","['determinant', 'linear-algebra', 'matrices']"
1339961,Prove that $|GL_n(\mathbb{F})|< q^{n^2}$.,"Let $\Bbb F$ be a finite field, say $|\Bbb F|=q$; then we know that $|GL_n(\Bbb F)| < \infty$. But how can we prove that $|GL_n(\mathbb{F})|< q^{n^2}$? I'm guessing because there $n^2$ entries in a $n\times n$ matrix. A little background would be helpful for me about the proof as I am inexperience with algebra proofs.","['matrices', 'abstract-algebra', 'group-theory', 'finite-groups', 'linear-algebra']"
1339963,The vertices of the $n$-cube are painted in two colors,The vertices of the $n$-dimensional cube are painted in two colors. The number of vertices of each color is the same ($2^{n-1}$). Prove that  at least $2^{n-1}$ edges connect vertices of different colors.,['combinatorics']
1340007,Can every vector space (over $\mathbb{R}$ or $\mathbb{C}$) can be a Banach space (or Hilbert space)?,"For a vector space $V$ over $\mathbb{R}$ (or $\mathbb{C}$ ) with Hamel basis of cardinality $\kappa$ such that $\kappa^{\aleph_0} = \kappa$ , can we define inner product(or norm) on $V$ such that $V$ is a Hilbert space (or Banach Space)? (The condition $\kappa^{\aleph_0} = \kappa$ is necessary because Arthur Kruse showed in ""Badly incomplete normed linear spaces"" (Math. Z. 83 (1964) 314--320) that a Banach space of infinite (Hamel) dimension $\kappa$ exists if and only if $\kappa^{\aleph_0} = \kappa$ .)","['hilbert-spaces', 'functional-analysis']"
1340011,Counterexamples to Brouwer's fixed point theorem for the closed unit ball in Banach space,"Brouwer fixed point theorem states that for any compact convex set $X$, a continuous mapping from $X$ to $X$ has at least one fixed point. Brouwer fixed point theorem applies in particular on the close unit ball of a finite dimensional space. Do you have counterexample(s) where Brouwer fixed point theorem does not hold on the close unit ball of a Banach space (of infinite dimension)? Note: this question is a refinement of this one which was put on hold.","['fixed-point-theorems', 'general-topology']"
1340028,Differential equation Physical Example.,I am Learning Differential equation with ordinary differential equation. How to tell students the actual geometric  meaning of differential equation? What is first order differential equation actually mean? what is nth order differential equation actually mean? I am confused how to tell these things. Please give some geometric meaning of these terms and also if possible some examples so that i can get an idea of these . In ordinary books just definition is given all of these but how to tell what geometrically they represent? Please help me. Thanks in advance.,['ordinary-differential-equations']
1340042,Is the complement of a closed set always open? [duplicate],This question already has answers here : Prove that a set $E$ is closed iff it's complement $E^{c}$ is open (2 answers) Closed 9 years ago . My book says that that a set is closed if its complement is open. Can a set be closed for other reason or is this if supposed to be an iff? Is there a way to prove this statement?,['general-topology']
1340094,Non-Linear System of uniform distributions. Determine the Density functions.,"Consider the non-linear system:
$$
Z = -X + W\\
Y = X + XV.
$$
Where $X$, $V$ and $W$ are mutually independent and all are $\sim U(0,1)$. I have got some problems finding the distributions of the given exercises. First : Determine the distribution of $Z$.
$$
P(Z\leq z) = \int_{-\infty}^{\infty}\left(P_W(z+s)\right)f_X(s)ds
$$
Now I know that I have to watch out with the boundaries, since 
$$
\begin{align}
P_W(q) &= 0,\quad q < 0\\
P_W(q) &= q,\quad q \in[0,1]\\
P_W(q) &= 1,\quad q>1.
\end{align}
$$
So $f_Z(z) = \frac{d}{dz}\int_{-z}^{1-z}\left(P_W(z+s)\right)f_X(s)ds = 1$ if $z\in[0,1]$, with help of Leibniz. Furthermore, $F_Z(z) = -1$ if $z\in[-1,0]$ and $0$ elsewhere. Is this correct? Second : I have to find $E[Z|Y]$. I thought of finding it the following way:
$$
E[Z|Y] = E[-X + W|Y] = E[-X|Y] + E[W]\text{ since white noise and independence}\\
=E[-X|Y = y] + \frac{1}{2} = -\int_{}^{} x\frac{f_{X,Y}(x,y)}{f_Y(y)}dx + \frac{1}{2}.
$$ Edit :
Thank you @Did for the explanation, I too was lost in my own calculations. Thank you for your time.","['probability-theory', 'conditional-expectation', 'uniform-distribution', 'probability-distributions']"
1340117,Can I prove set propositions using first-order logic?,"I'm studying logic and sets and I have to say there's a strong similarity between the two. Most boolean/logic axioms also apply to sets. At the end of my course I also studied first-order logic (or predicate logic) and how one can actually define statements using first-order logic. This was quite a revelation to me because it is quite easy to prove first-order logic statements compared to set propositions (my brain just works better at decomposing first-order logic propositions). So I'm wondering, is it possible to prove set propositions using first-order logic? Here's an example of a set proposition I have to prove: if C ⊆ B then A ⇒ C ⊆ A ⇒ B (not that A ⇒ B is assumed to mean ¬A ∪ B) Now I was thinking I could convert this into a first-order logic statement, such as: Subset(C, B) ⇒ Subset(A ⇒ C, A ⇒ B) As you can see however I can't seem to understand how to prove that in first-order logic. Anyway, perhaps I am confusing the two and this is not possible but I was wondering what you guys thought about proving these set statements using first-order logic.","['first-order-logic', 'elementary-set-theory', 'predicate-logic']"
1340121,Lower bound for the size of a maximal matching in a general graph,"Let $G=(V,E)$ be a graph, let $M\subseteq E(G)$ be a maximal matching, and let $M^\star\subseteq E(G)$ be a maximum matching. Prove that $|M|\ge |M^\star|/2$. Any hints on how to prove this?","['discrete-mathematics', 'graph-theory', 'combinatorics']"
1340152,How is the multiplicative group an algebraic variety?,"According to various places, we define an algebraic group as a group that is also an algebraic variety (along with some compatibility conditions). Many places also list some examples, one of which is the multiplicative group $\mathbb{G}_m$ of a field $k$. But $\mathbb{G}_m = \mathbb{A}^1\setminus\{0\}$, which is not Zariski-closed in $\mathbb{A}^1$ (i.e. is not a variety). So how exactly is it an algebraic group? I'm sure there's something really obvious that I've missed, but I'm new to this area and have yet to really get to grasps with such basics.","['algebraic-groups', 'algebraic-geometry']"
1340158,"What is the relationship between poisson, gamma, and exponential distribution?","I'm having a hard time understanding the intuitive relationship between these three distributions. I thought that poisson is what you get when you sum n number of exponentially distributed variables, but if seems that gamma is the same...Could someone describe the relationship in layman's terms?","['probability', 'poisson-distribution', 'gamma-distribution']"
1340174,Minimum value of $\cos A+\cos B+\cos C$ in a triangle $ABC$,I have used jensen's inequality but couldn't move on.,"['triangles', 'inequality', 'trigonometry']"
1340212,"Prove that a classical solution of $-\langle\nabla,A\nabla u\rangle=f$ is also a weak one","Let $\Omega\subseteq\mathbb{R}^n$ a domain $f\in L^2(\Omega)$ $A:\Omega\to\mathbb{R}^{n\times n}$ be Borel-measurable and $A(x)$ be symmetric, for all $x\in\Omega$ $u\in C^2(\Omega)$ with $A\nabla u\in L^1_\text{loc}(\Omega)$ and $$-\langle\nabla,A\nabla u\rangle=f\;\;\;\text{in }\Omega\tag{1}$$ How can we show, that $$-\int_\Omega\langle A\nabla u,\nabla\varphi\rangle\;d\lambda^n=\int_\Omega f\varphi\;d\lambda^n\;\;\;\text{for all }\varphi\in C_0^1(\Omega)\tag{2}\;?$$ Clearly, from $(1)$ we get $$-\int_\Omega\langle\nabla,A\nabla u\rangle\varphi\;d\lambda^n=\int_\Omega f\varphi\;d\lambda^n\;,$$ but I've no idea how we can show $$-\int_\Omega\langle\nabla,A\nabla u\rangle\varphi\;d\lambda^n=-\int_\Omega\langle A\nabla u,\nabla\varphi\rangle\;d\lambda^n$$ I assume we need to apply one of Green's identities, but how?","['real-analysis', 'integration', 'analysis', 'ordinary-differential-equations', 'partial-differential-equations']"
1340223,Plot of a ... Square?,"Well there are equations which can plot a square like : $|x-y|+|x+y|=a$ But how about this equation: ? (At the end ... bear with me!) [Here I have taken $a = 1$ ] Plot of $$x^2 + y^2 = a^2$$ Plot of $$x^4 + y^4 = a^4$$ Plot of $$x^6 + y^6 = a^6$$ Plot of $$x^{100} + y^{100} = a^{100}$$ Since we can see that as the degree of the equation is increasing, the sharpness of the possible rounded square is also increasing ... So can we say that: Plot of : $$\lim\limits_{p \rightarrow \infty} \space (x^p + y^p = a^p)$$ is the plot of a square???","['graphing-functions', 'algebra-precalculus']"
1340243,What's the best approach for a red light so you'll pass at maximum speed when it turns green?,"So me and a couple of friends were driving back home when we started wondering about this (admittedly silly) question. Say you are driving your car on a straight lane and see a red light up ahead. What is the best course of action to do, so that when it turns green you'll pass it at maximum speed possible? For sake of simplicity, we're putting aside more complicated situations like if the road is curved or uphill or there are other cars or whatever. All you have is a pretty decent assumption of the length between you and the traffic light, and knowing that the red light will change between, say, the next 1 and 45 seconds. To clarify, we obviously understand there's no fullproof solution that will always work, because we don't know the exact timing until the light turns green. Instead we're looking for a constant mathematical method that will work most of the time (i.e., where the percentage of success is the highest possible), and that will also not break any laws (we can't apply a method where we speed up and hope it changes, we have to account for the possibility of having to stop if it doesn't on time). Also, assume we're only interested in saving time (ignore gas usage and other issues). Thank you all","['optimization', 'probability']"
1340251,Prove $\det(A - nI_n) = 0$.,"Problem: Prove that $\det(A - n I_n) = 0$ when $A$ is the $(n \times n)$-matrix with all components equal to $1$. Attempt at solution: I tried to use Laplace expansion but that didn't work. I see the matrix will be of the form \begin{align*} \begin{pmatrix} 1-n & 1 & \cdots & 1 \\ 1 & 1-n & \cdots & 1 \\ \vdots \\ 1 & 1 & \cdots & 1-n \end{pmatrix} \end{align*} I want to somehow get two equal rows or columns here, or a row/column of zero using elementary operations. But I don't see what I should do?","['determinant', 'linear-algebra', 'matrices']"
1340257,A derivation of the Euler-Maclaurin formula?,"The generating function for the Bernoulli numbers $B_n$ is
$$\frac{x}{e^x-1}=\sum_{n=0}^\infty\frac{B_n}{n!}x^n$$ The sum of an infinite geometric series is
$$\frac{1}{1-x}=\sum_{k=0}^\infty x^k$$ Replacing $x$ with $e^x$ yields
$$\frac{1}{1-e^x}=\sum_{k=0}^\infty(e^x)^k$$ Multiplying both sides by $-x$ yields
$$\frac{x}{e^x-1}=-\sum_{k=0}^\infty(e^x)^kx$$ Hence
$$\sum_{k=0}^\infty(e^x)^kx+\sum_{n=0}^\infty\frac{B_n}{n!}x^n=0$$ Replacing $x$ with the derivative operator $D$ yields
$$\sum_{k=0}^\infty(e^D)^kD+\sum_{n=0}^\infty\frac{B_n}{n!}D^n=0$$ The exponential of the derivative operator is the shift operator $T$:
$$e^D=T$$ Hence
$$\sum_{k=0}^\infty T^kD+\sum_{n=0}^\infty\frac{B_n}{n!}D^n=0$$ Applying this to a function $f$ yields
$$\sum_{k=0}^\infty (T^kDf)(x)+\sum_{n=0}^\infty\frac{B_n}{n!}(D^nf)(x)=0$$ which is equivalent by $(Tf)(x)=f(x+1)$ to
$$\sum_{k=0}^\infty (Df)(x+k)+\sum_{n=0}^\infty\frac{B_n}{n!}(D^nf)(x)=0$$ If $Df=g$, this means
$$\sum_{k=0}^\infty g(x+k)+\int_a^xg(t)\,\mathrm{d}t+\sum_{n=0}^\infty\frac{B_{n+1}}{(n+1)!}(D^ng)(x)=0$$ Since the values of the Riemann zeta function at the negative integers are
$$\zeta(-n)=-\frac{B_{n+1}}{(n+1)}$$ This can be expressed as
$$\sum_{k=0}^\infty g(x+k)+\int_a^xg(t)\,\mathrm{d}t-\sum_{n=0}^\infty\frac{\zeta(-n)}{n!}(D^ng)(x)=0$$ or
$$\sum_{k=0}^\infty g(x+k)=\sum_{n=0}^\infty\frac{\zeta(-n)}{n!}(D^ng)(x)-\int_a^xg(t)\,\mathrm{d}t$$ Have I derived a version of the Euler-Maclaurin formula correctly? Is an additional error term needed somewhere? Why does the expression on the right side of the equation seem to depend on $a$, while the one on the left does not? How can I manipulate this procedure to obtain the more traditional version of the formula, e.g. with finite sums? I know, for example, that one can express a finite sum of powers using $$\frac{1-x^{n+1}}{1-x}=1+x+x^2+x^3+\ldots+x^n=\sum_{k=0}^n x^k$$","['taylor-expansion', 'calculus', 'sequences-and-series', 'analysis', 'euler-maclaurin']"
1340262,Prove image of symmetric group into additive group of real numbers is zero,"Suppose $ f : S_{n} \rightarrow (\mathbb{R} , + , 0 , - )$ is a group homomorphism. Prove $ f(S_{n}) = {0} $, i.e., $f(\sigma) = 0$ for every $ \sigma \in S_{n}$with $n \geq 1 $ I cannot seem to find the reason why the transpositions ( $ S_{2} $ ) should have this property. This would of course immediately solve it. Help would be much appreciated!!","['abstract-algebra', 'group-theory', 'finite-groups', 'permutations']"
1340275,"Given that $f(1) = f'(1) = 1$, use Taylor polynomials to show that $\lvert f(x) - x \rvert \leq A(x - 1)^2$","Given that $\ f$ has continuous second derivatives in$\ [0,2]$ and  $\ f(1)=f'(1)=1$, I'm trying to prove that for every $\ x \in [0,2]$ exists an A so that: $$
|f(x)-x| \le A(x-1)^2
$$ The second derivative made me try Taylor with little success, so far I manage to develop the data on both sides, but I just can't get them to connect. Any ideas?","['taylor-expansion', 'calculus', 'derivatives']"
1340289,Bibilography: Riemann's hypothesis and positive semi-definite billinear forms,"This is a bibliography request: I remember browsing through a book, some years ago, in a library, in which Riemann's hypothesis was proved over some type of fields (I cannot remember what type), the main tool being some billinear form and $p$-adic cohomology (if I recall correctly). It was proven that Riemann's hypothesis in this context was equivalent to proving the positive semi-definiteness of that billinear form, I think. The book was physically small, quite thin too (maybe less than 100 pages?), was a succession of numbered paragraphs and was not recently published. I was under the impression that it was by Weil, but I seem unable to find it among Weil's published works (judging by their titles). It was in English, its style was concise and very clear. Unfortunately, not being an algebraist, I cannot be more precise (and possibly some of the memories above are distorted by the passage of time). I would like to meet this book again and spend my holidays together with it. Can you help me, please?","['riemann-hypothesis', 'riemann-zeta', 'number-theory', 'algebraic-number-theory']"
1340290,"Why $R^q(\Gamma \circ \eta_{*}) (\Bbb G_{m, \eta}) = H^q(\eta_{ét}, \Bbb G_{m, \eta})$?","Let $X$ be a smooth, projective and connected curve over an algebraically closed field, and let $\eta \rightarrow X$ be its generic point (we also call the inclusion as $\eta$). I want to understand the proof of the computation of the étale cohomology of $\Bbb G_{m, \eta}$ on $X$. Reading SGA 4.5, by P. Deligne, I got stacked at the lemma 3.3 of the section ""Cohomolgie des courbes"" of . It says the following: $H^q(X_{ét}, \eta_* \Bbb G_{m, \eta})=0$ for $q >0$. In the proof, they consider the exact sequence arising from the spectral sequence given by the functors $\eta_*: Ab(\eta_{ét}) \rightarrow Ab(X_{ét})$ and $\Gamma(X_{ét}, -): Ab(X_{ét}) \rightarrow Ab$ (I will denote this functor as $\Gamma$), where Ab(-) are the sheaves of abelian groups. More precisely, we obtain the exact sequence
$$ 0 \rightarrow R^1\Gamma(\eta_* \Bbb G_{m, \eta}) \rightarrow R^1(\Gamma \circ \eta_*)(\Bbb G_{m, \eta}) \rightarrow \Gamma \circ R^1(\eta_* \Bbb G_{m, \eta}) \rightarrow \cdots.$$ Since the $R^q(\eta_* \Bbb G_{m, \eta})$ are zero, we get isomorphisms
$H^q(X_{ét}, \eta_* \Bbb G_{m, \eta}) \cong R^q(\Gamma \circ \eta_*)(\Bbb G_{m, \eta})$. So the question is, why  $R^q(\Gamma \circ \eta_{*}) (\Bbb G_{m, \eta}) = H^q(\eta_{ét}, \Bbb G_{m, \eta})$? Once this equality is stablished, a previous result concludes the proof.","['etale-cohomology', 'algebraic-geometry', 'algebraic-number-theory']"
1340297,Finding the number of elements of particular order in the symmetric group,"I know how to find the order of element in any group $G$, for example the order of $2$ in $\mathbb{Z}_5$ is $5$ as $2 + 2 + 2 + 2 + 2 = [10]_5 = 0 0$, which is the identity in $\mathbb{Z}_5$. But, how to calculate number of element of particular order in symmetric group $S_n$? I know how to calculate order of an element in $S_n$, for example in $S_5$, $(123)(45)$ has an order $6$. But how to calculate easily number of such elements? That is, how to calculate number of elements order $5$, number of elements of order $4$ in $S_5$? Is there is any easy formula? Also is there is any formula to calculate the number of elements of particular order in the alternating group $A_n$ as well?","['abstract-algebra', 'group-theory', 'finite-groups', 'symmetric-groups']"
1340307,Bounded function on compact interval that is not Lebesgue integrable,"Is there an example of a bounded function $f : [a,b] \to \mathbb R$ which is not Lebesgue integrable?","['lebesgue-integral', 'analysis', 'measure-theory', 'integration']"
1340324,"Show that $ Y/\sqrt{\lambda } \xrightarrow{d} N(0,1) $ as $ \lambda \rightarrow \infty $","Given that the characteristic function for Y is 
$$
\varphi_Y (t) = e^{\lambda (e^{-t^2/2}-1)}
$$ Show that $$
Y/\sqrt{\lambda } \xrightarrow{d} N(0,1) 
$$
as
$$
\lambda \rightarrow \infty
$$ I've tried to find the characteristic function of $Y/\sqrt\lambda$ to show convergence from there, but I am getting stuck. Here is what I have tried: $$
\varphi_{Y/\sqrt\lambda}(t) = E[e^{ty/\lambda}] = e^{\lambda (e^{-t^2/2}-1)}\bullet\varphi_Y(t/\sqrt\lambda) \\=e^{\lambda (e^{-t^2/2}+e^{-t^2/2\lambda}-2)}
$$ But when I try and take the limit of this function it is way to complicated and I keep hitting a dead end. Any hints or ideas would be helpful!","['probability-theory', 'normal-distribution', 'characteristic-functions', 'convergence-divergence', 'weak-convergence']"
1340333,Hamel Basis in Infinite dimensional Banach Space without Baire Category Theorem,Prove that every Hamel basis in an infinite dimensional Banach Space is uncountable without using Baire Category Theory. We are assuming axiom that vector space dimension (if exist) is well-defined. Note: Axiom that vector space dimension(if exist) is well-defined is independent of  DC. See Sizes of bases of vector spaces without the axiom of choice at MathOverflow.,"['hamel-basis', 'alternative-proof', 'banach-spaces', 'functional-analysis']"
1340355,Solitaire probability,"I would like to know the exact probability of the following game. I start counting from one to 13 and do this totally four times. On each turn I say a number and turn a card from a deck. Ace is considered to be as 1. If on one turn I say the same number as it is on the card, I lose. What is my winning probability?",['probability']
1340378,Reducing multi-variable functions to a composition of 1- or 2-variable functions,"There are some special functions of 3 or more complex variables that are analytic in some domain (a region in $\mathbb C^n$) with respect to each variable. To give some examples: the incomplete beta function $B(z; a, b)$, the Lerch transcendent $\Phi(z, s, a)$, the Weierstrass elliptic function $\wp(z;g_2,g_3)$, hypergeometric-family functions, etc. Is it possible to express each (or at least some) of these functions as a composition of several analytic functions of 1 or 2 complex variables? Or, if we restrict their domain to reals, it is possible to express them as a composition of several inifinitely differentiable (with respect to each variable) functions of 1 or 2 real variables? The same question applies to functions of 2 variables (e.g. polylogarithms, incomplete elliptic integrals, Hurwitz zeta function, Bessel-family functions, etc.): Is it possible to represent them as a composition of several infinitely differentiable functions of 1 variable and the single fixed function of 2 variables $(x,y)\mapsto x+y$? To give an example when the answer to the last question is positive, consider the complete beta function $B(a,b)$. It can be represented as
$$B(a,b)=\exp\big((\ln\Gamma(a)+\ln\Gamma(b))+(-\ln\Gamma(a+b))\big)$$
that is a composition of the 2-variable sum function and several infinitely differentiable 1-variable functions $x\mapsto\exp(x)$, $x\mapsto\ln\Gamma(x)$ and $x\mapsto -x$.","['calculus', 'special-functions', 'real-analysis', 'multivariable-calculus', 'complex-analysis']"
1340386,How do I determine if a given function is entire? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question Consider the three functions $\displaystyle e^{\frac{r}{\ln r}}$, $\displaystyle e^r$, and $\displaystyle e^{r\ln r}$, where $r = |z|$. Note that these are not constant functions. Can someone explain to me why all these three functions are not entire, especially the second one?",['complex-analysis']
1340403,"Show that $dim(X,\succeq)\leq |X^2|$ when $X$ is finite","I am trying to prove that when $(X,\succeq)$ is a finite preorder, the $dim(X,\succeq)\leq |X^2|$. Here's the full context (Exercise 11 (a)): My idea of resolution was to show that any set of elements of $X^2$ can be created through the intersection of at most $n^2$ different sets. But since $\succeq$ is reflexive, it already has $n$ elements, namely $(x_1,x_1),\cdots,(x_n,x_n)$, so the number of sets required to make it (through intersections) is less than $n^2-n\leq |X^2|$. I have two problems, though. Insecurity: I don't know if this idea is correct; Writing: I don't know how to translate that into math. Can someone give me some help? Thanks for helping!","['elementary-set-theory', 'proof-writing']"
1340405,Inclusion-exclusion-like fractional sum is positive?,"Let $A_1,A_2,\ldots,A_n$ be finite nonempty sets. Is it true that 
$$\sum_{i=1}^n\frac{1}{|A_i|}-\sum_{1\leq i<j\leq n}\frac{1}{|A_i\cup A_j|}+\sum_{1\leq i<j<k\leq n}\frac{1}{|A_i\cup A_j\cup A_k|}-\cdots+\frac{(-1)^{n-1}}{|A_1\cup\cdots\cup A_n|}$$ is always positive? For $n=1$ this is obvious. 
For $n=2$ it is true because $\frac{1}{|A_1|}\geq\frac{1}{|A_1\cup A_2|}$ and $\frac{1}{|A_2|}>0.$ For $n=3$ it is true because $\frac{1}{|A_1|}\geq\frac{1}{|A_1\cup A_2|}$, $\frac{1}{|A_2|}\geq\frac{1}{|A_2\cup A_3|}$, $\frac{1}{|A_3|}\geq\frac{1}{|A_3\cup A_1|}$, and $\frac{1}{|A_1\cup A_2\cup A_3|}>0$. But for $n=4$ this reasoning ceases to hold.","['inclusion-exclusion', 'algebra-precalculus', 'combinatorics', 'inequality']"
1340419,"Lebesgue integrable function over $(0,1)$ vs $[0,1]$","Up till now, I thought saying $u \in L^2([0,1])$ is the same as saying $u \in L^2((0,1))$, because I see people emphasizing ""$u$ is Lebesgue integrable over $[0,1)$"". I thought the whole point of the Lebesgue integral is that null sets don't matter, so it doesn't matter whether the endpoint is included or not. What do I miss?","['lebesgue-integral', 'measure-theory', 'integration']"
1340438,Definite solution for the mean distance from an external point to the surface of a sphere.,"Sphere, radius $E$, is centred at point $O$ $[0,0,0]$. External point $Q$ is at $[D,0,0]$. I can slice the sphere by making multiple planar cuts parallel to the $YZ$ plane to produce circular zones (quasi-discs) of equal infinitessimal width $dx$ and position $x_i$.  The curved surface of each zone has the same surface area.  The radius $R_i$ of any zone $i$ lies in the $YZ$ plane and has magnitude: $R_i = \sqrt{E^2 - x_i^2}  .$ The distance $L_i$ from point $Q$ to any point $P_i$ in the zone $i$ is given by:-
$$L_i = \sqrt{ (D-x_i)^2 + R_i^2} 
 = \sqrt{ D^2 -2Dx_i + x_i^2 + E^2 - x_i^2} 
= \sqrt{ D^2 -2Dx_i + E^2 } $$
$$L_i  = D \sqrt{ 1 -\frac{2x_i}{D} + \frac{E^2}{D^2} }. $$ Now I wish to integrate this expression over the range $-E\cdots+E$ and then divide by $2E$ to obtain the average value $\bar{L}$ thus $$\bar{L} = \frac{D}{2E} \int_{-E}^{+E} \sqrt{ 1 -\frac{2x_i}{D} + \frac{E^2}{D^2} } dx.$$ I can make a Taylor Series approximation of the square root term using the standard formula $(1+x)^{0.5} = 1 + x/2 - x^2/8 + x^3/16 -\cdots$ Applying this to the square root term I obtain
$$
\sqrt{ 1 -\frac{2x_i}{D} + \frac{E^2}{D^2} } = 1-x_i/D + (1/2)E^2/D^2 -(1/2)x_i^2/D^2 + (1/2)x_iE^2/D^3  + \cdots$$ where the subsequent terms on the RHS diminish in magnitude.  By dropping terms with odd powers of $x_i$ (because
they will go to zero when integrating over the range $-E \le x_i \le +E$ ) and consolidating and integrating I come up with the following approximate result:- $$\bar{L} = \frac{D}{2E} \int_{-E}^{+E} \sqrt{ 1 -\frac{2x_i}{D} + \frac{E^2}{D^2} } dx
\approx
D\left(1 + \frac{E^2}{3D^2} + A\right) $$
where A is a small term whose expression depends on the number of terms evaluated in the Taylor series approximation.  From numerical modelling it appears plausible that the term $A$ vanishes if the Taylor Series is extended to infinite terms and thus the definite solution would be given by:- $$\bar{L} = 
D\left(1 + \frac{E^2}{3D^2} \right)
= D + \frac{E^2}{3D}
$$ MY QUESTION Is there a way to derive a definite solution to this problem?","['geometry', 'calculus']"
1340451,Denseness: Closed Space,"I need this as lemma. Topological Space Given a topological space $\Omega$. Consider a closed space:
$$\mathcal{S}\subseteq\Omega:\quad\mathcal{S}=\overline{\mathcal{S}}$$ Then for dense domains:
$$\mathcal{D}\subseteq\Omega:\quad\overline{\mathcal{D}}=\Omega\implies\overline{\mathcal{D}\cap\mathcal{S}}=\mathcal{S}$$ Does this really hold? Hilbert Space Given a Hilbert space $\mathcal{H}$. Consider a closed space:
$$\mathcal{S}\leq\mathcal{H}:\quad\mathcal{S}=\overline{\mathcal{S}}$$ Then for dense domains:
$$\mathcal{D}\leq\mathcal{H}:\quad\overline{\mathcal{D}}=\mathcal{H}\implies\overline{\mathcal{D}\cap\mathcal{S}}=\mathcal{S}$$ Does this hold here? Reducing Space Given a Hilbert space $\mathcal{H}$. Consider a closed space:
$$\mathcal{S}\leq\mathcal{H}:\quad\mathcal{S}=\overline{\mathcal{S}}$$ Denote its projection:
$$\mathcal{R}P=\mathcal{S}:\quad P^2=P=P^*$$ Regard a reducing domain:
$$P\mathcal{D}\subseteq\mathcal{D}\leq\mathcal{H}$$ Then the dense domain:
$$\overline{\mathcal{D}}=\mathcal{H}\implies\overline{\mathcal{D}\cap\mathcal{S}}=\mathcal{S}$$ Does this hold now?",['general-topology']
1340452,Elementary set theory notation verification,"Reading Velleman's ""How To Prove It"" I came across the following expression:
$$ x \in\bigcup\{\mathscr P(A)\mid A\in \mathcal F\} $$ such that $\mathcal F$ is a family of sets, $A$ is a set, and $\mathscr P(A)$ is the power set of $A$. Now according to Velleman, it holds: $$ x \in\bigcup\{\mathscr P(A)\mid A\in \mathcal F\} \iff \exists A \in \mathcal F(x\in \mathscr P(A)).$$ The last term means ""there is the set A which is an element of F, such that x is an element of the power set of A"". Now, it seems to me, however, that the following equality also: $$ \exists A \in \mathcal F(x\in \mathscr P(A)) \iff x \in\{\mathscr P(A)\mid A\in \mathcal F\}.$$ Which implies:$$ x \in\bigcup\{\mathscr P(A)\mid A\in \mathcal F\} \iff x \in\{\mathscr P(A)\mid A\in \mathcal F\}.$$ Is that correct? Thanks in advance.",['elementary-set-theory']
1340468,Furstenberg theorem and twin primes,"The theorem of Furstenberg  showing there exists infinitely many primes (and variants, including those stripping away the topological side of things) has been discussed several times on MSE, e.g. in this question . For clarity let me follow the paper of Mercer in the Monthly which sets it up as : Claim 1. A finite intersection of Arithmetic Progressions is either empty or infinite. Claim 2. If S is any collection of sets, then a finite intersection of finite unions of sets in S is also a finite union of finite intersections of sets in S. Claim 3. If $p_1$,...,$p_n$ were all primes, then since the finite intersection of non-multiples is a two-element set, we'd get a contradiction (i.e.  it is a fact that $\{-1;1\} =$ $NM(p_1) \cap\dots\cap NM(p_n)$, where $NM(p_i):=$ $(1+p_i\mathbb{Z})\cup\dots\cup ((p_i-1)+p_i\mathbb{Z})$). Now, surely the following is wrong (otherwise how on earth has it not been found earlier), but let's try to apply this to show the existence of infinitely many twin primes. Let us assume that there exists infinitely many primes $p_1,p_2,\dots$ that there exists only finitely many pairs of twin primes, say $(q_1;q_1+2),\dots,(q_m;q_m+2)$, where for each $i$ there exists some $j=j(i)$ such that $q_i=p_j$. But then, we have that $\{-1;1\} =$ $NM(q_1+2) \cap\dots\cap NM(q_m+2)$ since all the $q_i+2$ are prime. A contradiction just as well, i.e. primes of the form $q_i+2$ must occur infinitely many times, too (indeed of any form $q_i+2k$, by the same token). Question: could someone please point out where is the flaw in this reasoning? (It feels like there's gap in logic right at the end, but I can't articulate it.) Thank you!","['number-theory', 'twin-primes']"
1340470,How to make an icosahedron from 20 tetrahedra?,"To make an icosahedron out of Sierpinsky tetrahedrons is difficult because regular tetrahedra can't tile in space. The dihedral angle of a tetrahedron is ~70.53. So the first step would be to make tetra's with 72'angles (360/5) and to tile them into two sets of five tetrahedra to form the top and bottom of the icosahedron, and then i would have to fill the middle area with 10 tetrahedra. What is the easiest way to roughly make an icosahedron from tetrahedra? what are the dimensions of the tetrahedra involved, are they all the same? ideally it would be possible to see through all the triangles in a line from one end to the other, is it possible?","['solid-geometry', 'geometry', 'fractals']"
1340485,"What is $\operatorname{Hom}_R(P,R)$ isomorphic to when $P$ is projective?","Let $R$ be a (possibly noncommutative) ring with $1$. Now, quite clearly we have $$\operatorname{Hom}_R(R^n,R)\cong R^n.$$ I am wondering if there is any similar result for $\operatorname{Hom}_R(P,R)$ where $P$ is a projective $R$-module.","['commutative-algebra', 'noncommutative-algebra', 'abstract-algebra', 'projective-module', 'modules']"
1340497,What is $\nabla Au$ for $A:\mathbb{R}^n\to\mathbb{R}^{n\times n}$ and $u:\mathbb{R}^n\to\mathbb{R}$?,"Let $A:\mathbb{R}^n\to\mathbb{R}^{n\times n}$ and $u:\mathbb{R}^n\to\mathbb{R}$. How can we compute $\nabla Au$? I assume we need to apply some kind of product rule, but I wasn't able to figure out how exactly.","['calculus', 'real-analysis', 'analysis', 'multivariable-calculus', 'derivatives']"
1340503,Tangent space as derivations exercise,"Thinking of the tangent space to a manifold as derivations is a concept which just kind of eludes me. I am comfortable thinking about tangent vectors as equivalence classes of curves and with the physicists' tangent space. Something about the derivation itself just does not lend itself in my head to the idea of a tangent vector, and as a result, I can't really work with this definition. In particular the following exercise is giving me a hard time. For any $(U,x)$, consider the tangent lift $Tx: TU \rightarrow TV$ where $V=x(U)$. Since $V \subset \mathbb R^n$ we will identify $T_{x(p)}V$ with $\{ x(p) \} \times \mathbb R^n$. Using this identification show that $T_px \cdot v_p = (x(p), \frac{d}{dt}|_{t=0}(x \circ \gamma))$, interpreting both sides as derivations. (presumably $\gamma$ is a parameterized curve) The point of this exercise is going to be to use this result to produce natural charts on the tangent bundle. This part I'm okay with, since it's mostly just manipulating the equations. I just feel stuck when trying to think about the tangent space as derivations - like in this question I don't even see what the Leibniz law has to do with this problem. I'd appreciate it if someone could break down this idea for me in some amount of detail - I've been trying to read other explanations and I know what the definition of a derivation is, I just don't at all see what it has to do with tangent vectors, or how to use that idea to solve problems. Thanks for the help.","['differential-geometry', 'manifolds', 'intuition']"
1340508,e and its applications [duplicate],"This question already has answers here : Euler's identity: why is the $e$ in $e^{ix}$? What if it were some other constant like $2^{ix}$? (4 answers) Closed 6 months ago . In math when people want to model population growth or radioactive decay we use exponential functions. In many cases, we use base $e$. My question is, what is the purpose of using base $e$ rather than some other base?",['algebra-precalculus']
1340527,Probability with changing number of marbles,"Given a bag containing 20 marbles of 5 different colors in this configuration: 8x Blue 6x Red 3x Green 2x White 1x Black How would you determine the probability of picking a marble of a specific color given these rules: 4 marbles are picked one after the other from the bag Once a marble is picked, all remaining marbles of the same color are removed from the bag So as an example of how the process might happen: From the initial 20 marbles, the first one that is picked is blue All the remaining blue marbles are removed, leaving 12 marbles The next marble that is picked is black There aren't any black marbles left, so 11 marbles remain The next marble that is picked is red All the remaining red marbles are removed, leaving 5 marbles remaining The last marble that is picked is white So a blue, black, red and white marble was picked, and only the green marbles remained untouched. In essence the question is given the initial configuration and the rules, what are the probabilities for each of the colors of being picked. So the probability of 1 of the 4 marbles being Blue is x and the probability of 1 of the 4 marbles being Red is y.","['discrete-mathematics', 'probability', 'combinatorics']"
1340531,What does this definition mean: $F_Y(y) =P(Y<y)$?,"I am doing calculations on $F_Y(y) := P(Y<y)$, but I am clueless as to what $P(Y<y)$ means. For instance the following question: Given function: $f_X(x)= 2\lambda x e^{-\lambda x^2}$ when $x \geq 0$ (parameter $\lambda>0$)
Show that for $x>0$ $P(X>x)=e^{-\lambda x^2}$ I did the calculation (integration) and that's fine. I just don't know what it is I am doing. What does $P(X>x)$ mean? Because the following question I'm not sure how to solve: Compute the probability mass function of $Y=X^2$ So the teacher says it should be solved as follows, but again I don't know what it means: For $y<0,\ F_Y(y)=P(Y<y)=0$ (Why does this equal zero?) 
For $y>0,\ F_Y(y)=P(X^2<y)$ (substitute for the definition, but why?) $=P(-\sqrt{y} < X < \sqrt{y})$ (okay) $=P(0<X<\sqrt{y})$ (why is it zero?) $=1-P(x>\sqrt{y})=1-e^{-\lambda y}$ (why is this so? the integral is $e^{\lambda x^2}$, how come I am allowed to substitute the y for $x^2$ and how does all of this have anything to do with $Y=X^2$?) And then you have to differentiate, because you've got Fy, but you want $f_y$, which I get. Would appreciate the help a lot! Got an exam on the 30th!","['probability-theory', 'probability-distributions', 'probability-limit-theorems', 'statistics', 'probability']"
1340536,What does $\mathbb{R} \setminus S$ mean?,What does $\mathbb{R}\setminus S$ mean? I am not getting it what it actually means. I have found it manywhere in real-analysis like in the definition of boundary points of a set. Can anyone tell me what it means really?,['notation']
1340552,"Show that $f(x) = x^2$ is not uniformly continuous on $[0,\infty)$","Ok, I know the same question has already been asked here , and I am not looking for an answer even though my proof looks kind of the same. But, I need to know whether or not I am on the right track. Also, the choice of $y$ on the other proof doesn't many much sense to me. So, here it goes: Show that $f(x) = x^2$ is not uniformly continuous on $[0,\infty)$ This is what I did: Suppose, it is. Then, fix $\epsilon = 1 > 0.$ Let, $x < \delta \in [0, \infty)$ and $y = 2x \in [0,\infty)$. Then, according to the definition, $$\forall \epsilon > 0, \quad\exists \delta > 0\quad\text{such that} \quad\forall x,y \in [0,\infty),\qquad\mid x-y\mid < \delta\quad \implies\quad\mid f(x) - f(y)\mid < \epsilon$$ If we replace $y = 2x$, then $$\mid x -2x\mid = \mid -x\mid = x < \delta.$$ So, that holds. Now, $$\mid f(x) - f(y)\mid = \mid x^2 - 4x^2\mid = \mid -3x^2\mid = 3x^2 > \epsilon = 1,$$ which is a contradiction depending on the choice of $x$. Is it correct? Can I do that? Thanks.","['uniform-continuity', 'solution-verification', 'proof-verification', 'real-analysis']"
1340561,Is the total space of a vector bundle over an irreducible scheme irreducible?,"Let $X$ be an irreducible scheme over $\mathbb{C}$ and let $F$ be a locally free sheaf of rank $r$ on $X$. Is the total space $Y$ of the associated vector bundle to $F$, $Y=Spec(Sym(F^{\vee}))$, irreducible? I know some results, like if $f: Y\rightarrow X$ is surjective with irreducible fibers, $X$ irreducible and $f$ closed, then $Y$ is irreducible. Here i would like to apply this to $\pi: Spec(Sym(F^{\vee}))\rightarrow X$. But I only know that $\pi$ is an affine morphism. Is there some more properties in this special situation such that we can conclude the irreducibility of the total space? (We may assume $X=\mathbb{A}^n$) If this is not true in general, are there some special situations for which this is true?","['algebraic-geometry', 'vector-bundles']"
1340563,Existence of unique circle passing through interior points of unit disk meeting the boundary orthogonally,"I am a self-studies and this is a hw problem from a complex analysis scourse I've been doing. The problem set pertains to the topic Automorphism Groups and has a high concentration of fractional linear transformations. So I would be appreciative of any help, but especially if those concepts are applicable. Show that for any points $a, b\in D$, the unit disk, there is a unique circle $C$ passing through $a$ and $b$ and meeting $\partial D$ orthogonally. (Suggestion: Prove first that the only circles through $0$ and perpendicular to $\partial D$ are diameters of D.) As far as the hint goes, it makes sense that radii are perpendicular to tangents to the circle, so if the radii lie on a line, it is a diameter. But this doesn't seem like much of a proof. Also as far as the general case, I can see how a circle through $a$ and $b$ and centered outside of $D$ can have orthogonal intersections with the $\partial D$ and how the respective right triangles formed by $0$ and the two tangents to the circle from the center of $C$ work. But I would appreciate help proving the existence and uniqueness. Especially if there is a way using fractional linear transformations. Thanks","['hyperbolic-geometry', 'complex-analysis']"
1340612,Compute definite integral,"Question : Compute 
$$\int_0^1 \frac{\sqrt{x-x^2}}{x+2}dx.$$ Attempt : I've tried various substitutions with no success. Looked for a possible contour integration by converting this into a rational function of $\sin\theta$ and $\cos \theta$.","['contour-integration', 'complex-analysis', 'definite-integrals', 'integration']"
1340613,Proof or Counterexample:Is every open connected set $D \subset \mathbb C$ is a domain of holomorphy?,Def: An open set  $D \subset \mathbb C^n$  is called a domain of Holomorphy if there exists a holomorphic function $f$ on $D$ such that $f$ cannot be extended to a bigger set. Is every non empty open set $D \subset \mathbb C$ is a domain of holomorphy? I personally believe that this result is true but I'm unable to find a proof.Any ideas?,"['several-complex-variables', 'complex-analysis']"
1340616,Proof of the power rule for logarithms,What is the proof for the power rule for logarithms? And are there different ways to prove it?,['algebra-precalculus']
1340637,"What does ""bounded away from zero"" actually mean?","For example, is $f(z) = 1/z$, on the set $0<z<1$ ""bounded away from zero""?","['complex-analysis', 'real-analysis']"
1340655,Show that $\frac{(x^2 + y^2 )}{4} \leq e^{x+y-2}$,"Show that 
\begin{equation}
\frac{x^2 + y^2}{4} \leq e^{x+y-2}
\end{equation}
is true for $x,y \geq 0$. As far, I have prove that 
\begin{equation}
x^2 + y^2 \leq e^{x}e^{y}\leq e^{x+y}
\end{equation}
since $e^{x}\geq x^2$ and $e^{y}\geq y^2$. If someone can give some aid it would be nice!","['exponential-function', 'analysis', 'inequality']"
