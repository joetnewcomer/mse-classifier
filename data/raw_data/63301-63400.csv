question_id,title,body,tags
725171,Idempotents in a local ring,"Is it true that a local ring, i.e., a commutative ring with a unique maximal ideal, doesn't contain idempotent elements $\neq 0, 1$ ? 
Why ? Any hint ?","['commutative-algebra', 'ring-theory', 'ideals', 'abstract-algebra']"
725214,Question about definition of binary relation,"Wikipedia says : Set Theory begins with a fundamental binary relation between and object $o$ and a set $A$. If $o$ is a member of $A$, write $o \in A $. I thought that a binary relation is a collection of ordered pairs of elements of $A$. Why is relating one element of a set to the set a binary relation? Thanks.","['logic', 'elementary-set-theory', 'binary-operations', 'terminology']"
725232,Groups statements equivalence,"Problem statement Let $G$ be a group and $H \subset G$ a subset. Prove that the following statements are equivalent (i) $H$ is a subgroup (ii) $H$ is nonempty and for any $x, y \in H, xy^{-1} \in H$ If $G$ is finite, prove that these statements are equivalent to (iii) $H$ is nonempty and for any $x,y \in H, xy \in H$ The attempt at a solution I didn't have problems to show the equivalence of statements (i) and (ii): $(i) \implies (ii) $ This is by definition, since if $H$ is a subgroup, then is closed under operation, so it satisfies $xz \in H$ for all elements in $H$, in particular, for $z=y^{-1}$. $(ii) \implies (i)$ is also easy: To prove the existence of $e \in H$, we can write $e=xx^{-1}$ for any $x \in H$ (we can assure there exists some $x$ since $H$ is non-empty).Now that we've proved the existence of the identity element, by hypothesis, if $x \in H$, then $ex^{-1}=x^{-1} \in H$, so all the elements have inverse in $H$. We prove closure of the operation just by using that $y={y^{-1}}^{-1}$, by hypothesis, $xy=x{y^{-1}}^{-1} \in H$. Associativity follows directly from the fact that $G$ is a group. Now, $(i),(ii) \implies (iii)$ is immediate, by definition of group, we have that $H$ is closed under the operation, so, for any $x,y \in H, xy \in H$. I got stuck trying to show that $(iii)$ implies $H$ is a subgroup. If I could prove that for any $x \in H$, $x^{-1} \in H$, then I would be done but I don't know how to show this. I thought to prove it by the absurd: suppose there is an element $x : x^{-1} \notin H$, then how I could conclude that $G$ cannot be finite?","['group-theory', 'abstract-algebra']"
725240,Show that the quotient of the Heisenberg Group with its center is abelian.,"I'm trying to show that the quotient of the Heisenberg group with it's own center, H/Z(H), is abelian. I'm not entirely sure what makes up this quotient group in the first place though... and I'm a little confused as to what quotients of matrix groups with multiplicative operators look like. Help, thanks",['abstract-algebra']
725252,Do I correctly understand the constructions involved in definition of Cartier divisor?,"Let $(X,\mathcal O)$ be a ringed space, where $\mathcal O$ is a sheaf of unital commutative integrity domains. Let $\widetilde{\mathcal M}_U$ be the field of fractions of ring $\mathcal O_U$ for any open $U$ and $\widetilde{\mathcal M}$ be the presheaf given by $\widetilde M_U$ over an open $U$. Sheafification $\mathcal M$ of $\widetilde{\mathcal M}$ is called the sheaf of meromorphic functions on $X$. Its sections over an open $U$ will be denoted by $\mathcal M_U$. Then $\mathcal O_U$ is naturally included in $\mathcal M_U$. Now let $\mathcal O^\times$ and $\mathcal M^\times$ be the sheaves of multiplicative groups of invertible elements of $\mathcal O$ and $\mathcal M$. Again, $\mathcal O_U^\times \subset \mathcal M_U^\times$. We can consider the sheaf $\mathcal M^\times / \mathcal O^\times$. Its global sections are called Cartier divisors. If I'm not mistaken, any section of $\mathcal M$ over an open $U$ is given by an open cover $\{U_i\}$ of $U$ together with a family of elements $\{f_i / g_i \mid f_i, g_i \in \mathcal O_{U_i}$, $g_i \neq 0 \}$ and such that 
$$
  f_i|_{U_i \cap U_j} g_j|_{U_i \cap U_j} - g_i|_{U_i \cap U_j} f_j|_{U_i \cap U_j} = 0
$$
 if $U_i \cap U_j \neq \varnothing$.Thus the inclusion $\mathcal O_U \to \mathcal M_U$ for any $f \in \mathcal O_U$ is given by the data of the single set $U_1 = U$ and of a single fraction with $f_1 = f$, $g_1 = 1_{\mathcal O_U}$. Then any section of $\mathcal M^\times / \mathcal O^\times$ over an open $U$ is given by an open cover $\{U_i\}$ of $U$ together with a family of elements $\{f_i / g_i \cdot \mathcal O_U^\times|_{U_i} \mid f_i, g_i \in \mathcal O_{U_i}$, $f_i, g_i \neq 0 \}$ each of which represents a set and such that 
$$
f_i|_{U_i \cap U_j}/ g_i|_{U_i \cap U_j} \cdot \mathcal O^\times_U |_{U_i \cap U_j} = f_j|_{U_i \cap U_j} / g_j|_{U_i \cap U_j} \cdot O^\times_U |_{U_i \cap U_j} \tag{1}
$$ if $U_i \cap U_j \neq \varnothing$. Are these considerations correct?","['sheaf-theory', 'algebraic-geometry', 'complex-analysis']"
725279,Algorithm to find best in class of groups with weighting?,"I have widgets and a single widget will have attributes of: Name
Weight (decimal from 0-1)
Group (letter A-F)
Price (an integer from 1 - 100) I must pick one widget from each Group (A-F) for a total of 6 widgets. How do I write an algorithm to find the 6 widgets that give me the aggregate highest Price while at the same time keeping the aggregate Weight less-than or equal to 1? Obviously, a lot of combinations will have an aggregate weight less than 1, but I need to come up with a way to get the combination that ALSO results in the highest Price. I suppose I could solve this with a Monte Carlo simulation, but I'm hoping there is a better way.","['statistics', 'monte-carlo', 'linear-algebra']"
725291,Show that $x^2 + x + 12 = 3y^5$ has no integer solutions.,"Show that $x^2 + x + 12 = 3y^5$ has no integer solutions. Use the fact that the class group of $K$ is cyclic of order 5,  where $K=\mathbb{Q}[\alpha]$ and $\alpha$ is the root of $x^2-x+12$. We get that $$\alpha = \frac{1+\sqrt{-47}}{2}$$ One can factor the LHS: $$(x+\alpha)(x+\bar{\alpha})$$ and then what?
If we show the above factors are coprime, saying that they are the 5th powers of some ideal doesn't help much, since we know that the 5th power of any ideal is a principal ideal due to the class group being $C_5$. -How does ""3"" come into play?","['algebraic-number-theory', 'abstract-algebra']"
725297,About B. Ya Levin's proof that $|f(x)| \leq M$ implies $|f(x+iy)| \leq Me^{\sigma y}$,"This question is about Theorems 1 through 3 on pages 37-38 of B. Ya Levin's Lectures on Entire Functions , available on Google Books . If you can't access the Google Books link there is also a screenshot of the relevant portion of the book available here: https://i.sstatic.net/8f9kV.jpg I'm trying to understand the proofs of these three theorems for the case where the hypotheses of Theorem 3 are satisfied. In Theorem 3, $f$ is a function analytic in $\operatorname{Im} z \geq 0$ which is bounded on the real axis by a constant, $M$.  Further, there is a positive number $\sigma$ such that, for any $\epsilon > 0$, the bound $$
|f(z)| < e^{(\sigma + \epsilon)|z|}
$$ holds for $|z|$ large enough with $\operatorname{Im} z > 0$.  The theorem states that, for such an $f$, $$
|f(x+iy)| \leq M e^{\sigma y}
$$ for all $x+iy \in \mathbb C$ with $y \geq 0$. To prove Theorem 3, the author recommends applying Theorem 2 with $\alpha = \pi/2$ and $\rho = 1$ to the rotated function $f(iz)$.  (Actually the author suggests using $f(-iz)$ instead, but I believe this is a typo.  This function is not analytic for $\operatorname{Re} z > 0$, which is a requirement of Theorem 2.) Now in Theorem 2, the author defines $$
D = \left\{z : |\arg z| < \alpha = \frac{\pi}{2\rho}\right\} = \{z:\operatorname{Re}z > 0\}
$$ and $$
\varphi_\epsilon(z) = f(iz)e^{-(\sigma + \epsilon)z}.
$$ The function $\varphi_\epsilon$ is bounded by $M$ on the boundary of $D$, since $$
|\varphi_\epsilon(ix)| = \left|f(-x) e^{i(\sigma + \epsilon)x}\right| \leq M.
$$ Further, it tends to zero along the positive real axis.  Indeed, for $|z|$ large enough we have $|f(z)| < e^{(\sigma + \epsilon/2)|z|}$, so for $x > 0$ large enough we see that $$
|\varphi_\epsilon(x)| < e^{(\sigma+\epsilon/2)x}e^{-(\sigma+\epsilon)x} = e^{-x\epsilon/2}.
$$ Thus there is a constant $C_\epsilon$ such that $$
|\varphi_\epsilon(x)| \leq C_\epsilon
$$ for all $x \geq 0$.  I believe this is what the author means by the first sentence of the proof, The function $\varphi_\epsilon(z)$ is bounded on a positive ray and on the boundary of $D$. I can understand the next line, According to the previous theorem [Theorem 1], it is bounded by a constant in each angle $D_+ = \{z:0<\arg z<\pi/2\}$ and $D_- = \{z:-\pi/2<\arg z<0\}$. Here the author seems to have applied Theorem 1 with $\rho = 1$ and $\lambda = 2$ to $\varphi_\epsilon(z)$ in each of the angles $D_+$ and $D_-$.  It seems that the $M$ in Theorem 1 was taken to be $\max\{M,C_\epsilon\}$.  This is then the constant bound being referred to. I do not understand the next line, Applying the previous theorem once more, we obtain $|\varphi_\epsilon(z)| \leq M$ for $z \in D$. How was the previous theorem applied this time?  How does he conclude that $|\varphi_\epsilon(z)| \leq M$ when we apparently only have $$
|\varphi_\epsilon(z)| \leq \max\{M,C_\epsilon\}?
$$","['inequality', 'complex-analysis']"
725311,The product of a matrix and its transpose can always be written as an exponential,"For every real matrix $X$ with $\det X = 1$, there exists a real symmetric traceless matrix $Y$ such that $$ X^TX = e^Y $$ Is this true? If so, why?",['matrices']
725314,Solving equation involving the ceiling function,"How can I solve the equation $$\lceil \log_{b}{1024} \rceil = n$$ where $n \in \mathbb{N}$ in terms of $b$? I have seen equations of a similar form ( Solving an equation with floor function before), but I'm not sure how to proceed with this one.","['discrete-mathematics', 'diophantine-equations', 'ceiling-and-floor-functions']"
725317,Get diagonal from Quadrilateral described by vectors,"I have the following problem: in 2D space. I have quadrilateral which have 2 of angles = 90 degree And 2 non unit vectors h1 and h2. (Have length and direction) We, also, have point P where h2 and diag begins. I need to find diagonal vector diag. I need solution that use only vector operations(no trigonometric functions) if possible.","['geometry', 'linear-algebra']"
725329,Explicitly computing the isomorphism class of the tensor product of two finite abelian groups,"How do I compute the isomorphism class of $A\otimes_\mathbb{Z} B$, where $A$ and $B$ are abelian of finite order? I can do this for a few examples, but I am unsure of how to proceed in the general case. Specifically, I am interested in the cases where... $|A|$ and $|B|$ are coprime $\pi(|A|)\cap\pi(|B|)=1$  (where $\pi(n)$ denotes the set of prime divisors of $n$) all Sylow subgroups of $A$ and $B$ are elementary abelian Is there a way of seeing such results intuitively?","['abelian-groups', 'abstract-algebra', 'tensor-products', 'finite-groups', 'group-theory']"
725335,Help finishing proof via induction for a summation,"So I have to prove the following equation using induction for n >= 2: 
$$
\sum\limits_{i=1}^n 4/5^i < 1
$$
However the question asks me to prove something stronger such as this:
$$
\sum\limits_{i=1}^n 4/5^i <= 1 - \frac{1}{5^n}
$$
first to imply the first equation is true.
So far I have the following: Base Case: Let n = 2 $$
\sum\limits_{i=1}^2 4/5^i = \frac{4}{5} + \frac{4}{25} = \frac {24}{25}
$$ 
then I also applied it to 
$$ 1 - \frac{1}{5^n} \rightarrow 1 - \frac{1}{5^2} = \frac{24}{25}$$
Therefore I can make the following assumptions yes? Inductive Hypothesis for all 2 <= n <= k it is 
$$
\sum\limits_{i=1}^n 4/5^i = 4\frac{\frac{1}{5^n} - 1}{\frac{1}{5} - 1} = 1 - \frac{1}{5^n} < 1
$$ Inductive Step Hopefully I'm ok up to here, I'll show what I have so far for this step. 
$$
\sum\limits_{i=1}^{k+1} 4/5^i = \frac{\frac{1}{5^{k+1}} - 1}{\frac{1}{5} - 1} = 4\frac{(\frac{1}{5^k}-1) * \frac{1}{5} - \frac{4}{5}}{\frac{1}{5} -1} $$
$$
= \frac{1}{5} *   4\frac{(\frac{1}{5^k}) - 1}{\frac{1}{5} -1} -  4\frac{\frac{4}{5}}{\frac{1}{5} - 1}
$$
so here I have:
$$
4\frac{(\frac{1}{5^k}) - 1}{\frac{1}{5} -1}
$$
which I know is:
$$
= \sum\limits_{i=1}^k 4/5^i
$$
which is my inductive hypothesis, I am unsure of how to finish my proof from here... any help correcting or finishing the proof is very much appreciated","['discrete-mathematics', 'education', 'proof-verification', 'induction', 'summation']"
725350,Is Geometric Algebra isomorphic to Tensor Algebra?,"Is geometric algebra (Clifford algebra) isomorphic to tensor algebra?  If so, how then would one relate a unique 2-vector (this is what I'm going to call a multivector that is the sum of a scalar, vector, and bivector) to every 2nd rank tensor? Edit by the OP, converted from ""answer"" Okay.  Well I'm still curious if there's a way to represent any 2nd-rank tensor by a bivector, vector, and scalar.  Or in particular, can any $3 \times 3$ matrix be represented by a 2-vector in 3D. It seems to me that they can't because I would guess the matrix representation of a bivector (grade 2 element of a 2-vector) would be exactly the same as the $3 \times 3$ matrix representation of the cross product (i.e. $[a \times b]_{ij} = a_j b_i - a_i b_j$) which only uniquely identifies 3 components. I would also assume that the scalar part of the 2-vector would be represented by a scalar times the $3 \times 3$ identity matrix.  This would fill in 3 numbers, but really only uniquely gives 1 component. I don't know how to represent the vector component of the 2-vector as a $3 \times 3$ matrix but I don't see how it could identity the remaining 5 components by itself. Am I right then in assuming that there is a canonical matrix representation of a general 2-vector, but that there are matrices that cannot be represented by any 2-vector?","['geometric-algebras', 'clifford-algebras', 'abstract-algebra']"
725361,The rank of general inverse of $A$ times $A$?,"Supposing $X$ is the general inverse of $A$, that $AXA = A$. 
Then $XA$ is idempotent, that is $(XA)(XA) = XA$. Why is the rank of $XA$ equal to the rank of $A$ ? Thanks.","['matrices', 'inverse']"
725396,How many routes possible in the traveling salesman problem with $n$ cities? And more...,"SO the general answer I come across on the internet is $(n-1)!/2$. But it would seem to be $n!$, or at least $(n-1)!$. Which one is it? If you have 2 cities, you would have 1 path. So $(n-1)!/2$ can't hold? EDIT: Another question. Let $P$ be the transition matrix between the routes according to the 2-opt procedure. The pairwise exchange or 2-opt technique involves iteratively removing
  two edges and replacing these with two different edges that reconnect
  the fragments created by edge removal into a new and shorter tour. The transition probabilities $P_{kl}$ for given $k$ and $1\leq l \leq size(P)$ can only take two values. What are the two value? I guess $P_{kk} = 0?$","['optimization', 'graph-theory', 'combinatorics']"
725430,Prove Converse continuity using the Preimages,"I would like to prove that if pre images $f^{-1}(U) \subset D $ of open subsets $U\subset  \mathbb{C}$ are open in $D$ implies a function $f:D \to \mathbb{C}, D\subset  \mathbb{C}$ is continuous. EDIT: I need help with the converse. I thought I had shown the converse when I had really shown the direction written above. Any help is appreciated! Also: Is it true that the image $f(U)$ of an open subset $U \subset D$ under a continuous function is open in $ \mathbb{C}$? Thanks!",['complex-analysis']
725434,"LU factorization problem - Writing a code, don't understand partial pivoting","I'm trying to write a matlab code for the following question: The program gets a matrix $A$ (lets say square matrix) and it returns $P,L,U$ such that $PA=PLU$ and $P$ is the permutation matrix, the partial pivoting matrix. The obvious way to go about this is to:
1) find matrix $P$ via switching rows with the maximum value, and then doing gauss eliminiation, and continuing with the row switching. 2) doing regular LU decomposition of $A$ 3) We now have $PA=PLU$ The problem here is that we essential do gauss elimination twice. once to find the $P$ matrix, and then to find $LU$ such that $A=LU$ The second problem, is that the entire point of partial pivoting is so we don't have to find such $LU$ matrices such that $A=LU$ since we don't know how numerically stable it is. So it defeats the point. My problem is this : after switching rows, I don't know what value to put in matrix $L$. For example: $A=\begin{pmatrix} 3 & 1 & 4\\ 1 & 5 & 9 \\ 9 & 2 & 6\end{pmatrix}$ A row change is needed since $9>3$, so we now have: $P=\begin{pmatrix} 0 & 0 & 1 \\ 0 & 1 & 0 \\ 1 & 0 & 0\end{pmatrix}$ and $PA = \begin{pmatrix} 9 & 2 & 6\\1 & 5 & 9\\ 3 & 1 & 4\end{pmatrix}$ Now I somehow need to find the original $L$ that I would get if I hadn't done the row change, by doing gauss elimination on $PA$ and  I don't understand how that's possible. Take heart, we need to find such matrices $L,U$ such that $A=LU$ without actually doing an lu decomposition of $A$, but of the more numerically stable $PA$ rather. It's kind of hard to explain","['matrix-decomposition', 'matrices', 'linear-algebra', 'gaussian-elimination']"
725435,What is the largest circle that fits in $\sin(x)?$,"Imagine dropping a circle into the trough of $\sin(x)$. Would it reach the bottom or get wedged between two points on the curve? Depends on the size of the circle. So, what is the radius of the largest circle that will reach the bottom of the curve $y=\sin(x)$? This problem was inspired by this similar one I found in a calculus textbook: Find the radius of the largest circle that will reach the bottom of the curve $y=x^2$ without getting stuck. I was intrigued by the answer of $r=1/2$. I have tried attacking this problem from several angles but all have failed. Perhaps an exact numerical solution is not obtainable, I don't know. All help will be appreciated.
Thanks!","['optimization', 'geometry', 'algebraic-geometry', 'circles']"
725441,"What is the 2nd order taylor polynomial of f(x,y)?","I'm just computing the 2nd order taylor polynomial for $f(x,y) = tan(x + 3y + \frac{\pi}{4})$ centered at (3,-1) and wondering if I have done this correctly or if anyone has any suggestions on how I can improve my answer (I've never done this before with mulitvariables so just want to be sure I am on the right track): I have that: $$f(3,-1) = tan(\frac{\pi}{4}) = 1$$
$$f_{x}(3,-1) = sec^2(\frac{\pi}{4}) = 2$$
$$f_{y}(3,-1) = 3sec^2(\frac{\pi}{4}) = 6$$ So the gradient vector for $f$ is $(2,6)$ The letting $u = x + 3y + \frac{\pi}{4}$, I get that $\frac{du}{dx}= 1 $ and $\frac{dy}{dx}= 3 $ So, $$f_{x}(u) = sec^2(u)$$
$$f_{xx}(u) = 2tan(u)sec^2(u)\frac{du}{dx}$$
$$f_{xy}(u) = 2tan(u)sec^2(u)\frac{du}{dy}$$ and similarly, $$f_{y}(u) = 3sec^2(u)$$
$$f_{yx}(u) = 6tan(u)sec^2(u)\frac{du}{dx}$$
$$f_{yy}(u) = 6tan(u)sec^2(u)\frac{du}{dy}$$ Substituting back for $u$ and plugging in $(3,-1)$ I get: $$f_{xx}(3,-1) = 2tan(\frac{\pi}{4})sec^2(\frac{\pi}{4})\cdot1 = 4$$
$$f_{xy}(3,-1) = 2tan(\frac{\pi}{4})sec^2(\frac{\pi}{4})\cdot3 = 12$$ and similarly, $$f_{yx}(3,-1) = 6tan(\frac{\pi}{4})sec^2(\frac{\pi}{4})\cdot1 = 12$$
$$f_{yy}(3,-1) = 6tan(\frac{\pi}{4})sec^2(\frac{\pi}{4})\cdot3 = 36$$ So, $$T_{2}((x,y),(3,-1)) = 1+(2,6) \cdot (x-3,y+1) + \frac{1}{2} \bigl( \begin{smallmatrix} 
  x-3 & y+1\\
\end{smallmatrix} \bigr) \bigl( \begin{smallmatrix} 
  4 & 12\\
  12 & 36 
\end{smallmatrix} \bigr) \bigl( \begin{smallmatrix} 
  x-3 \\
  y+1  
\end{smallmatrix} \bigr)$$ Performing the calculations I get: $$= 1+2x-6+6y+6+\frac{1}{2}[(x-3)(4x-12+12y+12)+(y+1)(12x-36+36y+36)]$$ $$ = 2x^2 + 18y^2 + 12xy + 2x + 6y + 1$$ Is this correct and have I done the steps correctly? Many thanks in advance!","['multivariable-calculus', 'taylor-expansion']"
725447,Help with discrete math proof?,"I am having trouble proving the following: If $x\in R$ and $x > 0$, then $x^4+1 \geq x^3+x$. Work: I tried to rearrange the equation as $x^4-x^3-x+1 \geq 1$, but that does not really help. I also tried proof by cases where case 1 would be that x is irrational and case 2 would be that x is rational. However, that has not got me far either. I am not really sure how to approach this problem.",['discrete-mathematics']
725449,Prove $\sin^2(x)<\sin(x^2)$ for $0<x<\sqrt{\frac{\pi}{2}}$,"I'm trying to prove  $\sin^2(x)<\sin(x^2)$ for $0<x<\sqrt{\frac{\pi}{2}}$. Attempt: This is equivalent to showing $f(x)=\sin(x^2)-\sin^2(x) = \sin(x^2)-\left(\frac{1-\cos(2x)}{2}\right)>0$. Since $f(0)=0$, if we show $f$ is increasing we are done. $f'(x) = 2x\cos(x^2)-\sin(2x)$ but I can't see why it's greater than zero.","['trigonometry', 'inequality']"
725483,Remainder for picard iteration for exponential function,"Consider the initial-value problem:
$$y'=y,\quad y(0)=1.$$
The solution is of course the exponential function
$$y=\exp x=\sum\limits_{n=0}^{\infty}\frac{x^n}{n!}.$$
We can obtain this by Picard iteration where $y_0=1$ and 
$$y_n(x)=1+\int\limits_0^x y_{n-1}(x)\mathrm{d}x.$$
Doing this on page 2, Schlag  ( http://www.math.uchicago.edu/~schlag/bookweb.pdf ) gives the solution:
$$y(x)=1+\int_0^xy(x)\mathrm{d}x=1+x+\int_0^x (x-t)y(t)\mathrm{d}t=\cdots =\sum_{n=0}^N\frac{x^n}{n!}+\int_0^x (x-t)^Ny(x)\mathrm{d}x.$$ Where do the remainder terms $\int_0^x (x-t)y(t)\mathrm{d}t,\dotsc, \int_0^x (x-t)^Ny(x)\mathrm{d}x$ come from? For instance 
$$y_2(x)=1+\int_0^x\left(1+\int_0^t y(s)\mathrm{d}s\right)\mathrm{d}t=1+x+\int_0^x\int_0^t y(s)\mathrm{d}s\mathrm{d}t.$$ How does the last term here become the remainder term given by Schlag?",['ordinary-differential-equations']
725531,Determining a branch of logarithm,"The question I have is that what is the explicit mapping that takes the value $-i \pi/2$ at $-i$ where the mapping is a branch of the logarithm in the slit plane $\mathbb{C}- [0,\infty)$? I'm familiar with the branch cut for the principal branch of the logarithm given by the slit plane $\mathbb{C}- (-\infty, 0)$ where $-\pi \leq \theta < \pi$, with $\theta$ the argument of $z$.",['complex-analysis']
725549,Stereographic projection is a homeomorphism $S^n \setminus \{p\} \to \mathbb{R}^n$,"Let $S^n$ be the $n$-sphere, $N=(0,0,...,0,1)$ and be the north pole of $S^n$.  I am trying to show that stereographic projection gives a homeomorphism $\sigma: S^n \setminus \{N\} \to \mathbb{R}^n$. I know that a map can be constructed by considering a line from the north pole to a point $x=(x_1,...,x_{n+1}) \in S^n$ and taking $x$ to the point that this line intersects in the plane formed by setting $x_{n+1}=0$.  Ultimately we end up with a map $\sigma: S^n\setminus\{N\} \to \mathbb{R}^n$ given by $\sigma(x)=(tx_1,...,tx_n)$, where $t=\frac{1}{1-x_{n+1}}$. It's not hard to see that $\sigma$ is injective: If $\sigma(x)=(tx_1,...,tx_n)=(ty_1,...,ty_n)=\sigma(y)$, then $tx_i=ty_i$ for all $i$, so $x_i=y_i$ and $x=y$. For surjectivity, let $y=(y_1,...,y_n) \in \mathbb{R}^n$.  Then $\sigma(x)$ where $x=(t^{-1}y_1,...,t^{-1}y_n,y_{n+1})$ and $y_{n+1}=t\cdot \sqrt{1-(t^{-1}y_1)^2-\cdots - (t^{-1}y_n)^2}$ equals $y$, so $\sigma$ is surjective. It follows that $\sigma$ is a bijection, so now we just need to show that it is continuous.  Unfortunately my point-set topology is a bit rusty, and am having a hard time doing this part.  Let $U \subseteq \mathbb{R}^n$ and let $x=(x_1,...,x_n) \in U$.  I am unsure of how to find an open set around $\sigma^{-1}(x)$ that is contained in $\sigma^{-1}(U)$.  How do we go about doing this?",['general-topology']
725562,Equivalence of Frobenius norm and trace norm,"According to [1] , [2] and other related publications, the following holds for any matrix $X$: $$\| X\|_\Sigma=\min_{X=UV'}\|U\|_\mathrm{Fro}\|V\|_\mathrm{Fro}=\min_{X=UV'}\frac{1}{2}(\|U\|_\mathrm{Fro}^{2}+\|V\|_\mathrm{Fro}^2)$$ where $\|\cdot\|_\Sigma$ is the trace (nuclear/Ky-Fan) norm and $\|\cdot\|_\mathrm{Fro}$ is the Frobenius norm. Can anyone show why this equality is true? In the publications, it is filed under ""Preliminaries"" and one of the few Lemmas without proof. I find this relationship very fundamental and interesting, but could not find it anywhere else, let alone proof. Thank you for any help! What I already have: If I understand the 'hint' in ref. 1 (above) correctly, $\min_{X=UV'}\|U\|_\mathrm{Fro}\|V\|_\mathrm{Fro}$ is minimized by $U=\hat{U}\sqrt{\Lambda}$ and $V=\hat{V}\sqrt{\Lambda}$, where $X=\hat{U}\Lambda \hat{V'}$ is the singlular value decomposition of $X$ (Page 75, Lemma 8 in ref. 1 (above)).","['trace', 'matrices', 'normed-spaces', 'nuclear-norm']"
725582,Why $ \|x^* x \| = \|x\|\|x^*\|$ is equivalent to $\|xx^*\| = \|x\|^2$ in the definition of $C^*$ algebra?,I read the definition of $C^*$ algebra in Wikipedia where it says $\|x^* x \| = \|x\|\|x^*\|$ is equivalent to $\|xx^*\| = \|x\|^2$ but I do not know why. Can you show me how to derive $\|xx^*\| = \|x\|^2$ from $\|x^* x \| = \|x\|\|x^*\|$?,"['operator-theory', 'operator-algebras', 'functional-analysis', 'c-star-algebras']"
725592,"How to evaluate $\int_0^1\frac{1+x^4}{1+x^6}\,dx$ [duplicate]","This question already has answers here : Compute: $\int_{0}^{1}\frac{x^4+1}{x^6+1}\, dx$ (8 answers) Closed 9 years ago . $$\int_0^1\frac{1+x^4}{1+x^6}\,dx$$ Can anyone help me solve the question? I am struggling with this.","['definite-integrals', 'rational-functions', 'calculus', 'integration']"
725672,Constructing matrices $A$ and $B$ such that $(A B)^+ \neq B^+ A^+$,How do I go about constructing two matrices $A$ and $B$ such that the pseudoinverse of $AB$ is not equal to the pseudoinverse of $B$ times the pseudoinverse of $A$ ?,"['matrices', 'pseudoinverse', 'linear-algebra']"
725788,Why does the function $\overline{F}([x]_R)=[F(x)]_R$ have to be unique?,"My book ""Elements of Set Theory"" by Enderton says that Assume that $R$ is an equivalence relation on $A$ and that $F:A\to A$. If $F$ is compatible with $R$, then there exists a unique $\overline{F}:A/R\to A/R$ such that $$\overline{F}([x]_R)=[F(x)]_R$$ I don't understand this. Isn't the identity function $F=id_A$ always such a function, regardless of whatever the equivalence relation $R$ is? And considering we know more such functions exist (an example is given in the book for $R=\mod 6$ and $F:\Bbb{N}\to \Bbb{N}$ such that $f(n)=2n$), how does uniqueness hold up? EDIT : Am I mixing up the uniqueness of $\overline{F}$ and $F$? Does $\overline{F}$ have to be unique, regardless of whether $F$ is unique or not? Thank you.",['elementary-set-theory']
725817,Number of solutions of $x+y+z=10$ [duplicate],"This question already has answers here : Counting bounded integer solutions to $\sum_ia_ix_i\leqq n$ (5 answers) Closed 1 year ago . The number of different solutions $(x,y,z)$ of the equation $x+y+z=10$ where each of $x, y$ and $z$ is a positive integer is $36$. How to derive this answer? I know that $x, y$ and $z$  have to be $1\leq x,y,z\leq8$ and $x,y,z\in\mathbb Z.$ This said me $8+7+6+5+4+3+2+1=36.$ But I can't understand the process of counting the solutions.","['discrete-mathematics', 'combinatorics']"
725838,How to prove that $n^5 - n$ is a multiple of $5$? [duplicate],"This question already has answers here : Prove $(n^5-n)$ is divisible by 5 by induction. (6 answers) Closed 10 years ago . Hello I'm new to induction so please bare with me. For this problem I have to use induction to prove: For every integer $n\geq 1$, the number $n^5 âˆ’ n$ is a multiple of $5$. Can someone please help me figure this out. I've tried to follow the examples in the book, but they were very confusing.","['induction', 'discrete-mathematics']"
725843,Likelihood function for continuous densities,"When doing ML-estimates for discrete distributions, the definition of likelihood makes perfect sense $ \ L(x,\theta) = \Pi_{1:n}\ P(X_i=x_i|\theta)$ Since there is a non-infinitesimal probability that $X=x$. But why does this work for continuous distributions? Isn't $P(X=x)$ always infinitesimal? When doing excercises, everything works out fine. But I don't understand how. Why doesn't the likelihood function require intervals for $P(X)$? (Found a related thread Why is likelihood not always 0 in continuous case? but it's more about explaining why $L(x,\theta)$ can be greater than one. I still don't get how $P(X=x) \neq 0$ for continuous distributions.)","['statistics', 'probability']"
725852,Proving $\det \left( \begin{smallmatrix} A & -B \\ B & A \end{smallmatrix} \right) =|\det(A+iB)|^2$,"The complex general linear group is a subgroup of the group of real matrices of twice the dimension and with positive determinant. Let us decompose complex matrices $M$ as $M=A+iB$ , where $A,B$ are real matrices. Now consider the correspondence $$f(A+iB)=\begin{pmatrix} A & -B \\ B & A\end{pmatrix}.$$ If $\det f(M)=|\det M|^2$ for square matrices, then we would have $GL(n,\mathbb C)\subseteq GL_+(2n,\mathbb R)$ with the identification $M\to f(M)$ , which is an injective homomorphism. In other words, the complex general linear group would be a subgroup of the group of real matrices of twice the dimension and with positive determinant. How is $\det f(M)=|\det M|^2$ ?","['matrices', 'complex-numbers', 'linear-algebra', 'determinant']"
725885,Parametrizing a 3D surface,"Find a parametrization of the surface $x^3 + 3xy + z^2 = 2$, $z > 0$, and use it to find the tangent plane at $x = 1$, $y = \dfrac{1}{3}$, $z = 0$. I know how to find the tangent plane once I have the parametrization - it's the first part that's troubling me. I started by solving for $z$, which gave me the parametrization $(u, \, v, \, \sqrt{2-u^3-3uv})$. Then the partial derivative w.r.t. $u$ is $\left( 1, \, 0, \, \dfrac{-3(u^2+v)}{2 \sqrt{2-u^3 - 3uv}} \right)$. But when I plug in $u = 1$ and $y = \dfrac{1}{3}$, I get a discontinuity. Not really sure what else to try. Maybe cylindrical coordinates would work better?","['multivariable-calculus', 'parametric']"
725914,Find the limit $\lim_{n\to\infty} \frac{x_1 y_n + x_2 y_{n-1} + \cdots + x_n y_1}{n}$,"When $\lim_{n\to\infty} x_n = a$, and $\lim_{n\to\infty} y_n = b$, find the limit,
$$\lim_{n\to\infty} \frac{x_1 y_n + x_2 y_{n-1} + \cdots + x_n y_1}{n}.$$
Thank you for your help in advance.","['calculus', 'limits']"
725923,Find the sum $\sum_{n = 1}^{\infty}(-1)^{n + 1}\log(1 + (1/n))$,"I started as follows $$\begin{aligned}S &= \sum_{n = 1}^{\infty}(-1)^{n + 1}\log\left(1 + \frac{1}{n}\right)\\
&= \sum_{n = 1}^{\infty}(-1)^{n + 1}\sum_{k = 1}^{\infty}(-1)^{k + 1}\frac{1}{k n^{k}}\\
&= \sum_{k = 1}^{\infty}\frac{(-1)^{k + 1}}{k}\sum_{n = 1}^{\infty}(-1)^{n + 1}\frac{1}{n^{k}}\end{aligned}$$ Let $$f(k) = \sum_{n = 1}^{\infty}\frac{(-1)^{n + 1}}{n^{k}}$$ and this is related to $\zeta(k)$ for $k > 1$. Clearly $$f(k) = (1 - 2^{1 - k})\zeta(k)$$ and $f(1) = \log 2$. It follows that we have $$S = \log 2 - \sum_{k = 2}^{\infty}(-1)^{k}\cdot\frac{(1 - 2^{1 - k})\zeta(k)}{k}$$ After this I am not aware how to proceed further. Also I have doubt whether the sums in $k, n$ can be interchanged (because the series involved are conditionally convergent) as I have done above but for the time being I have assumed it to be so. Please help me out here.","['sequences-and-series', 'riemann-zeta']"
725926,Consecutive heads in $N$ coin tosses.,"Suppose we toss a fair coin $n$ times. We want to show that we can find a run of $\log_2 n - O(\log_2 \log_2 n)$ heads with probability at least $1 - 1/n^c$ for any $c \geq 1$. I realize that there are already questions and answers on stack exchange where the length of the run is for arbitrary $k$. However, in this case I have a specific run length and am trying to show that we can find a relatively simple lower bound. Initially, I feel like the ""trick"" is try to find a way to deal with the $O(\log_2 \log_2 n)$ term. In order to try to accomplish this, we can use a union bound argument to show that the probability of $\log_2 n$ consecutive heads is bounded above by 1. The problem with this is it makes it very difficult to deal with the $O(\log_2 \log_2 n)$ term and as a result, I get stuck. This isn't homework, but is a problem I came across awhile back. It has really been bugging me. Any help/hint would be appreciated. :)",['probability']
725932,a good introduction to Laplace Beltrami operator over differential manifolds?,"I'd like to have a good reference to understand how the Laplacian operator get generalized over differential manifolds. More concretely, I want to understand and prove the equation :
$$\Delta Id_{\mathbf{X}}=H.\mathbf{N}$$
Where $\mathbf{X}$ is a smooth surface in $\mathbb{R}^3$, $Id_\mathbf{X}$ the identity function defined on $\mathbf{X}$, $H$ its mean curvature and $N$ the normal vector to the surface $\mathbf{X}$ (ie its Gaussian map). I have read Andrew Pressley's book Elementary Differential Geometry .
I'm used to the classical Laplacian of differential calculus that operates on scalar fields, but I dont really understand what the Laplacian of a vector field represents, how it relates to the scalar version or how you define a Laplacian over manifolds. I have not finished Pressley, but it does not seem to cover this topic. But trying to look into it, I also saw lot of references to things like tensors, connection form, volum form, that I dont know. If you have also good recommandation regarding those topics, I would be grateful.
Basically, I would like to understand how to do multivariable calculus over surfaces.
Thank you.","['surfaces', 'differential-geometry']"
725945,Indeterminate two-dimensional limit,"I'm pretty sure that \begin{equation}
\lim_{(x,y) \rightarrow (0,0)} \frac{x^4y}{x^2 + y^2} = 0,
\end{equation} but I'm having some trouble proving it. The only technique I'm aware of that can be used to show indeterminate limits of $\geq 2$ variables exist is the Squeeze Theorem. I've tried applying it here (by assuming $|y| < 1$ and bounding the quantity of interest by $\pm\frac{x^4y}{x^2 + y^2}$), but I didn't get anywhere. Any help is appreciated.","['multivariable-calculus', 'limits']"
725951,Intuition behind chain rule [duplicate],This question already has answers here : Chain Rule Intuition (8 answers) Closed 10 years ago . What is the intuition behind chain rule in mathematics in particular why there is a multiplication in between?,"['calculus', 'intuition', 'derivatives']"
725980,Steepest descent with quadratic form converges in 1 iteration,"Well I'm stuck on an exercise given: The steepest descent method is applied to the quadratic form $$Q(\mathbf{x}) = \tfrac{1}{2}\mathbf{x}^TA\mathbf{x} - \mathbf{b}^T\mathbf{x} + c$$ where $A$ , $\mathbf{b}$ and $c$ , are matrix, vector and scalar constants. Under what condition on the matrix $A$ does the steepest descent method converge to the exact minimum in 1 iteration, from any initial condition $x_0$ ? [Hint: If the initial search line $\mathbf{x}_0 + \alpha \mathbf{d}_0$ includes the exact minimum of $Q(\mathbf{x})$ , then the method will converge in 1 iteration.] More specifically, some conditions about the matrix $A$ are asked, seeing this is a multiple choice question, the options: $A$ is a multiple of the identity matrix $A$ is diagonal $A$ is symmetric $A$ is positive definite $A$ has only positive eigenvalues $A$ is equal to $\mathbf{b}\mathbf{b}^T$ It never converges in 1 iteration It always converges in 1 iteration Now following the ""hint"", the exact solution is given by solving $Q'(\mathbf{x}) = 0$ : $$A\mathbf{\tilde{x}} - \mathbf{b} = 0$$ $$\mathbf{\tilde{x}} = A^{-1} \mathbf{b}$$ From the definition of the steepest descent method ( $x_{n+1} = x_n - \alpha f'(x_n)$ ): $$\mathbf{x}_1 = \mathbf{x}_0 + \alpha (A\mathbf{x}_0-\mathbf{b})$$ Now $\mathbf{x}_1 = \mathbf{\tilde{x}}$ has to be solved, or written out: $$\mathbf{x}_0 + \alpha (A\mathbf{x}_0-\mathbf{b}) = A^{-1} \mathbf{b} \qquad \forall\ \mathbf{x}_0,\alpha \in \mathbb{R}$$ Now I'm stuck, what can be said about $A$ ? Geometrically it feels like solution should be easy to be found, an example is a ""cone like surface"".","['optimization', 'quadratic-forms', 'linear-algebra', 'numerical-methods']"
725984,Hypothesis testing: how do you call the variable that is being hypothesized about?,"The question is easy but it is really hard to find via Google. Say you have the following hypothesis: $H0: \mu = 0$ $Ha: \mu \neq 0 $ Now I know that $ \mu $ is called the population mean. But how do you call a variable (or value) that is hypothesized with in general? Because instead of $\mu$ I could also test for a different variable (e.g. $\sigma = 0$ vs. $\sigma \neq 0$). It's also not the ""statistic"" (e.g. t-statistic). So how do you call it?",['statistics']
725989,Is there an intuition for why power sets come in powers of $2?$,"My title is a bit sloppy. First let me say that I perfectly understand the proof that $|P(S)|=2^{|S|}$, I am not asking for an easy to understand proof. My question is more whether there is an intuitive reason why we should expect : $|P(S)|$ to be a power of the size of $S$ (by this I mean $|P(S)|=n^{|S|}$ for some $n\in\mathbb{N}$) this power to be a power of $2$ In other words, is there anything inherent to the power set operation that should suggest the cardinalities of power sets come in powers of $2?$ (I am not saying there should be - ""no, that is just how it is"" is a perfectly acceptable answer, if it is indeed so)","['intuition', 'elementary-set-theory']"
725996,Reaching a level before another for a random walk,"Suppose we are given a simple random walk starting in $0$, i.e. $(X_k)_{k\in\mathbb{N}}$ with $P[X_k=+1]=P[X_k=-1]=\frac{1}{2}$. What is the probability of hitting the level $a$ before hitting the level $b$, where we assume $b<0<a$ and $|a|\le |b|$. Let's define $$T_a:=\inf\{n|S_n=a\}$$
and similarly
$$ T_b:=\inf\{n|S_n=b\}$$
where $S_n:=\sum_{i=1}^nX_i$.
Therefore we are interested in the probability $$P[T_a< T_b]$$ I think one needs the reflection principle at some point, but I'm not sure how it is exactly applied.","['probability-theory', 'random-walk', 'probability']"
726007,"Is there a name for this object? (Like a group, but the inverse is not necessarily a member of the set)","A group is a set $G$, together with a binary operation $\cdot$ that is closed - if $f\in G$ and $g \in G$ then $f\cdot g \in G$ is associative - $(f \cdot g) \cdot h = f \cdot (g \cdot h)$ has an identity element $e$ such that $ef=f$ for all $f\in G$ has an inverse function : for every $f\in G$ there exists $f^{-1}\in G$ such that $ff^{-1}=e$ I'm interested in a related concept where $f^{-1}$ exists, but isn't necessarily a member of $G$. This means that the identity function doesn't need to be in $G$ either. As a simple example, consider the set $T$ of transformations $x\to x+a$, where $a>0$. Each element of this set has an inverse ($x\to x-a$), but neither the inverses nor the identity transformation are members of $T$. So I'm looking for something very roughly like this: A <<insert name here>> is a tuple $\langle G, H, e, \cdot \rangle$, where $G$ is the set of forward elements and $H$ is the set of reverse elements, and $e$ is the identity element. The binary operation $\cdot$ is: closed independently for $G$ and $H$. That is, if $f\in G$ and $g \in G$ then $f\cdot g \in G$, and if $f\in H$ and $g \in H$ then $f\cdot g \in H$. is associative (again independently for $G$ and $H$) has the invertibility property that for every $f\in G$ there exists $f^{-1}\in H$ such that $ff^{-1}=f^{-1}f=e$, and similarly for every  $h\in H$ there exists $h^{-1}\in G$ such that $hh^{-1}=h^{-1}h=e$. $(fg)^{-1} = g^{-1}f^{-1}$ for all $f, g \in G$, and similarly $(fg)^{-1} = g^{-1}f^{-1}$ for all $f, g \in H$. It's very similar to a group, but where the elements are partitioned into (possibly overlapping) ""forward"" and ""reverse"" sets that might not contain the identity element. Note that if $g\in G$ and $h\in H$ then $fh$ might not be in either set. In the example above, $G$ is the set of translations in the positive direction and $H$ is the set of translations in the negative direction. I'm not sure what consequences this definition would have, but it seems like it might be a useful thing to define in the context of reversible dynamical systems. Does this concept already have a name, and if so where can I read about it?","['terminology', 'group-theory']"
726015,The definition the group of rigid motions in $\mathbb R^3$ of a tetrahedron,"In Dummit & Foote's Abstract Algebra text, page 28 the following problem appears: 9 . Let $G$ be the group of rigid motions in $\mathbb R^3$ of a tetrahedron. Show that $|G|=12$. Apparently, I misunderstand something. In page 23 the authors define the dihedral group $D_{2n}$ with the same wording, ""rigid motions"": For each $n \in \mathbb{Z}^+$, $n \geq 3$ let $D_{2n}$ be the set of symmetries of a regular $n$-gon, where a symmetry is any rigid motion of the $n$-gon... Here they allow for the symmetries to be reflections, thus getting $|D_{2n}|=2n$. However, following that approach I find that the $G$ in problem 9 has order $|G|=24$. Am I doing something wrong? Is there a mistake in the formulation of the problem? Thanks!","['group-theory', 'abstract-algebra']"
726027,"If $f(x) + f'(x) + f''(x) \to A$ as $x \to \infty$, then show that $f(x) \to A$ as $x \to \infty$","This problem is an extension to the simpler problem which deals with $f(x) + f'(x) \to A$ as $x \to \infty$ (see problem 2 on my blog ). If $f$ is twice continuously differentiable in some interval $(a, \infty)$ and $f(x) + f'(x) + f''(x) \to A$ as $x \to \infty$ then show that $f(x) \to A$ as $x \to \infty$. However, the approach based on considering sign of $f'(x)$ for large $x$ (which applies to the simpler problem in the blog) does not seem to apply here. Any hints on this problem? I believe that a similar generalization concerning expression $\sum\limits_{k = 0}^{n}f^{(k)}(x) \to A$ is also true, but I don't have a clue to prove the general result.","['ordinary-differential-equations', 'calculus', 'convergence-divergence', 'real-analysis', 'limits']"
726039,Calculate Linear regression segment [duplicate],"This question already has answers here : Derivation of the formula for Ordinary Least Squares Linear Regression (3 answers) Closed 9 years ago . I have array of random numbers. How can I calculate linear regression segment? I am interested in finding the exact formula so I be able to use it in my work, please help me finding this formula with the next declarations: $N$ - the number of random numbers in the array $S$ - the sum of the numbers in the array. $array_{min}$ - the minimum number in the array $array_{max}$ - the maximum number in the array $E$ - the average number in the array. We are looking for $y = mx + c$. So you need to find a formula to represent $m$ and $c$ with the above declarations. The array of random number are the $Y$. $X$ is just neutral numbers from $0$ to $N$","['statistics', 'linear-algebra']"
726045,Knight's metric: ellipse and parabola.,"Knight's metric is a metric on $\mathbb{Z}^2$ as the minimum number of moves a chess knight would take to travel from $x$ to $y\in\mathbb{Z}^2$. What does a parabola (or an ellipse) became with this new metric?
I apologize if the question is too vague.","['geometry', 'recreational-mathematics', 'analytic-geometry', 'metric-spaces', 'combinatorics']"
726046,"$f(x)=x^3+ax^2+bx+c$ where $1\ge a\ge b\ge c\ge 0$. If $\lambda$ is any root of the polynomial, show that $|\lambda|\le 1$","$f(x)=x^3+ax^2+bx+c$ where $1\ge a\ge b\ge c\ge 0$. If $\lambda$ is any root of the polynomial, show that $|\lambda|\le 1$. My attempt: As the polynomial is a cubic, it must have atleast one real root. So, I consider the $\mid\lambda\mid>1$ and $\lambda$ to be real and show that there arises a contradiction. Now, I differentiated the polynomial to see that $f'(x)>0$ from which I could conclude that if the roots are equal then I am done, but if roots are distinct then the other roots are imaginery. But, after several attempts, I could not show that $\mid\lambda\mid\le 1$. I considered using $\lambda\lambda'=\mid\lambda\mid^2$ where $\lambda'$ is the conjugate of the imaginery root, but that didn't seem to help. Please help. EDIT: Rouche's theorem is too advanced for me, please consider giving a more elementary solution. My level of knowledge should be near the undergraduate level.","['complex-numbers', 'roots', 'complex-analysis', 'polynomials']"
726084,Does a Brownian motion remain in any given open set for a given interval of time with positive probability?,"Let $B$ be a standard $d$-dimensional Brownian motion. Given $b>a>0$ and an open ball $U$ in $\mathbb{R}^d$, I want to be able to comment on the probability that $B$ remains in $U$ during the time interval $(a, b)$. I am aware that we can derive a complicated-looking density for the exit time corresponding to that ball(I think I have seen that in the $d = 1$ case, the distribution of the time taken by the Brownian motion to exit an interval around its starting point), and then possibly condition on the value of $B$ at time $a$(and using the density of $B_a$) and use Markov property to get a formula for the above probability. But is it possible to somehow directly prove that this probability is always non-zero(because I anyway need only this conclusion at the moment)? I feel that it should follow from a simpler argument(without much calculations) as we shouldn't really need the exact density of the exit time to determine whether that probability is non-zero.","['probability-theory', 'stochastic-processes', 'probability', 'brownian-motion']"
726087,Periodic-Like Holomorphic Function,"I am reading a paper ( this one ), and the authors (on page 4) implicitly use a result that I do not know. There may be some inaccuracy; I'm inferring the result from the context of the paper. Let $f$ be a holomorphic function from the upper half-plane in $\mathbb{C}$ to $\mathbb{C}$ ( $f:H \rightarrow \mathbb{C})$ . Suppose there is constant $\exp(2 \pi i a)$ with $a>0$ real such that $f(z+1)=\exp(2 \pi i a)f(z)$ . Then, there exists a function $g$ holomorphic near 0 in $H$ such that $f(z)=\exp(2 \pi i a z)g(\exp(2 \pi i z))$ . Proof?",['complex-analysis']
726096,Balls and bins question with nlogn balls and n bins.,"The question: Suppose we randomly drop nlogn balls into n bins. Give an
upper bound on the expectation of the maximum number of balls in any bin. How would this be done? I believe the answer is well on the order of the mean, but I don't remember how to obtain it.","['balls-in-bins', 'discrete-mathematics', 'probability']"
726110,When is it possible to pass to the limit in the base and the exponent separately?,"$$\eqalign{
  & \mathop {\lim }\limits_{n \to \infty } {\left( {{{4{n^2}} \over {(2n + 1)(2n - 1)}}} \right)^{1 - {n^2}}} = \mathop {\lim }\limits_{n \to \infty } {\left( {{1 \over {{{(2n + 1)(2n - 1)} \over {4{n^2}}}}}} \right)^{1 - {n^2}}} = \mathop {\lim }\limits_{n \to \infty } {\left( {{1 \over {{{4{n^2} - 1} \over {4{n^2}}}}}} \right)^{1 - {n^2}}} = \mathop {\lim }\limits_{n \to \infty } {\left( {{1 \over {1 - {1 \over {4{n^2}}}}}} \right)^{1 - {n^2}}} = \mathop {\lim }\limits_{n \to \infty } {1 \over {{{\left( {1 - {1 \over {4{n^2}}}} \right)}^{1 - {n^2}}}}} = \mathop {\lim }\limits_{n \to \infty } {1 \over {{{\left( {{{\left( {1 + {1 \over { - 4{n^2}}}} \right)}^{ - 4{n^2}}}} \right)}^{{{1 - {n^2}} \over { - 4{n^2}}}}}}} =   \cr 
  & \mathop {\lim }\limits_{n \to \infty } {1 \over {{e^{{{1 - {n^2}} \over { - 4{n^2}}}}}}} = {1 \over {{e^{{1 \over 4}}}}} = {\left( {{1 \over e}} \right)^{{1 \over 4}}}  \cr} $$ Is is right to do this? EDIT: Please notice that at some point I ""converted"" the expression
$\mathop {\lim }\limits_{n \to \infty } {\left( {1 + {1 \over { - 4{n^2}}}} \right)^{ - 4{n^2}}}$ to $e$, and then kept evaluating the ""rest"" of the expression. Why is it legal?","['exponential-function', 'calculus', 'limits']"
726125,"Is this it a theorem that numbers congruent modulo two relatively prime $m,n$ are congruent modulo $mn$?","""If $a \equiv b \pmod m$ and $a \equiv b \pmod n$ and $\gcd(m,n)=1$, then $a \equiv b \pmod {mn}$ "" Is that a true theorem? I can't find it in my textbook!","['modular-arithmetic', 'number-theory']"
726138,For a finite group of order $2n$ does there exist $x$ such that $x\ast x=e$? [duplicate],"This question already has answers here : Group of even order contains an element of order 2 (2 answers) Closed 9 years ago . Let $ (G,\ast)$ be a group with identity $e$ and cardinality $2n$ for some $n\in\omega$. Then, does there exist $x\in G$ such that $x\ast x=e$ and $x\neq e$?","['faq', 'finite-groups', 'group-theory', 'abstract-algebra']"
726144,Probability distribution of the product of random numbers,"For applied mathematics to evolutionary biology I am often faced to have to describe a probability distribution function (PDF) which results from the product of a function in which a parameter is drawn from a PDF. For example the random variable for which I'd like to describe the PDF is $Y$ such as $$Y = \prod_{i=1}^{n} f(x_i)$$ , where each $x_i$ is drawn from a known PDF. Do you have some kind of general hints/advice for solving this kind of issue? If general advice are not possible, below I am suggesting two simple (or at least I hope they are simple) examples of problems: Find the PDF of $Y$ such as $$Y = \prod_{i=1}^n x_i$$, where each $x_i$ is a value drawn from an exponential distribution with parameter $\lambda$. Below is the exponential distribution: $$Pr(X=x) = \lambda e^{-\lambda x}$$ Find the PDF of $Y$ such as $$Y = \prod_{i=1}^n log_e(x_i)^2$$, where each $x_i$ is a value drawn from an gaussian distribution with mean $\mu$ and variance $\sigma ^2$. Below is the gaussian distribution: $$Pr(X=x) = \frac{1}{\sigma \sqrt {2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma ^2}}$$","['applications', 'products', 'probability-theory', 'probability-distributions', 'probability']"
726148,Gumbel distribution,"Let $(X_i)_{i \geq 1}$ be a sequence of i.i.d. normal $\mathcal{N}(0,1)$ random variables. Let $M_n = \max_{i=1,\ldots,n} X_i$. Show that 
$$P[\sqrt{2 \log n} M_n - 2 \log n \leq u ] \rightarrow e^{-e^{-u}} \text{ as } n \rightarrow \infty$$
I thought maybe to use the following property:
$$P[\sqrt{2 \log n} M_n - 2 \log n \leq u ] = P(M_n \leq \frac{u+2 \log n}{\sqrt{2 \log n}})= F^n(\frac{u+2 \log n}{\sqrt{2 \log n}})$$ but dont know how to proceed..","['statistics', 'probability-distributions', 'probability', 'probability-theory']"
726163,Are different constructions of an algebraic structure always isomorphic?,"Any two complete ordered fields are isomorphic (as proved, e.g., in Spivak's Calculus; see also this question ). While I understand this proof, I cannot yet appreciate why it is necessary . Given any set of axioms for some algebraic structure, is it not always the case that any two constructions satisfying those axioms are isomorphic? If not, can someone supply a counterexample?","['axioms', 'self-learning', 'elementary-set-theory', 'abstract-algebra']"
726195,Equation with floor function,"How would one solve an equation with a floor function in it: $$a - (2x + 1)\left\lfloor{\frac {a - 2x(x + 1)}{2x + 1}}\right\rfloor - 2x(x + 1) = 0$$ $a$ is a given and can be treated as a natural number, and all $x$ other than integers can be discarded. At least one non-trivial solution would be sufficient. Maybe an algorithmic method could be used?","['discrete-mathematics', 'ceiling-and-floor-functions']"
726205,"Inferring covariance cov[X,Z] from cov[X,Y] and cov[Y,Z] of known distributions [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question Suppose X, Y and Z are real random variables of known distributions. If one knows the covariance $COV(X,Y)$ and $COV(Y,Z)$, is it possible to infer $COV(X,Z)$?","['statistics', 'correlation', 'probability', 'random-variables']"
726232,Optimization with a constrained function,"Okay so I understand how to find points of extrema when for example, We have $3x^2 + 2y^2 + 6z^2$ subject to the constaint $x+y+z=1$. I followed the method of the Lagrange multiplier and resulted in the point $(\frac13, \frac12, \frac16)$. I know this point is correct. However, I don't know how to prove that it's a minimum value. Any ideas?","['optimization', 'multivariable-calculus', 'calculus']"
726234,L'Hospital's rule problem $\lim_{x\to 0^+}(x^{x}-1)\ln(x)$,"$$\lim_{x\to 0^+}(x^{x}-1)\ln(x)$$ I need to solve this by LÂ´HopitalÂ´s rule: this is an indetermination of the type $0 \cdot \infty$: $$\lim_{x\to 0^+}(x^{x}-1)\ln(x)=\lim_{x\to 0^+}{(x^{x}-1)\over {1\over \ln(x)}} $$ and this is an indetermination of the type $0/0$, so by L'Hospital's rule:
$$\lim_{x\to 0^+}{(x^{x}-1)\over {1\over \ln(x)}}
=\lim_{x\to 0^+}{(x^{x}(1+\ln(x))\over {-1\over x\ln^{2}(x)}}$$ and this is an indetermination of the type $\infty/\infty$. but if I keep on using L'Hopital's rule, the limit will just get bigger so how can I do to solve this?","['calculus', 'derivatives', 'limits']"
726266,Proof for: semidirect product of solvable groups is solvable,"Do you know the proof for the following statement or where I can find it? Semidirect product of solvable groups is solvable? I thought that this property is so general that it should somewhere on the Net, but unfortunately I didn't find the answer. Thanks","['solvable-groups', 'group-theory', 'semidirect-product']"
726317,Show each eigenvalue of a companion matrix has geometric multiplicity $=1$.,"Given the differential equation $$x^{(n)}(t)+c_{n-1}x^{(n-1)}(t) + \dotsb + c_1x'(t) + c_0=0,$$ we can form a vector $\xi = (x, x', \dotsc, x^{(n-1)})$, and then we have $$\xi'(t) = A\xi,$$ 
where $A$ is the transpose of the companion matrix for the polynomial $$z^n + c_{n-1}z^{n-1}+\dotsb + c_1z + c_0.$$ A problem in Teschl's ODE book is to show that each eigenvalue of $A$ has geometric multiplicity $1.$ The hint it gives is ""can you find a cyclic vector for $A$? How does that help?"" (By a cyclic vector he means $v$ such that $\{A^{k}v\}\,\, (0\leq k <n)$ spans the vector space.) I see that $e_n$ is a cyclic vector for $A$, but I'm not seeing how that helps. Any ideas?","['eigenvalues-eigenvectors', 'ordinary-differential-equations', 'matrices', 'linear-algebra', 'companion-matrices']"
726324,Unique line in $\mathbb{P}^3$ through a point $p$ and intersecting two disjoint lines,"I'm a bit stuck with this exercise from a script I'm reading, and I'm not very familiar with projective $n$-space yet. The problem: Let $L_1$ and $L_2$ be two disjoint lines in $\mathbb{P}^3$, and let $p\in\mathbb{P}^3\smallsetminus(L_1\cup L_2)$. Show that there is a unique line $L\subseteq\mathbb{P}^3$ meeting $L_1$, $L_2$, and $p$ (i.e. such that $p\in L$ and $L\cap L_i\neq\varnothing$ for $i=1,2$). To be honest, I already have a problem with the term 'line'. As I take it, a line in $\mathbb{P}^3$ should be something cut out by two degree-1 polynomials (homogeneous, since it wouldn't be well defined otherwise, right?). But what are disjoint lines in projective space? As far as I understood it, two distinct lines should always intersect in exactly one point there, so how can they be disjoint? Can it be that these two statements mean a different kind of 'line'? Any explanation of this, hints, or even a solution would be very appreciated. Thanks in advance!","['projective-space', 'algebraic-geometry']"
726333,Uniqueness of curve of minimal length in a closed $X\subset \mathbb R^2$,"Suppose $X$ is a simply connected closed subset of $\mathbb R^2$. Let $a,b$ belong to $X$. Is it true that there is at most one curve inside $X$ from $a$ to $b$ such that the length of the curve is minimal?","['metric-spaces', 'algebraic-topology', 'differential-geometry']"
726336,"Proof that the function $\cot(\pi z)$ is uniformly bounded on the sides of the square with vertices $\pm(N+1/2)\pm i(N+1/2),nâˆˆâ„•$.","Proof that the function $\cot(\pi z)$ is uniformly bounded on the
   sides of the square with vertices $\pm(N+1/2)\pm i(N+1/2),nâˆˆâ„•$. My idea was that since those squares are compact and this function is continuous on those squares the image must be compact and therefore bounded. But I'm not sure what to do with the ""uniform"" notion.",['complex-analysis']
726357,"Show there must be another ""partial limit""","Let $P$ the set of all partial limits of the sequence $\{a_n\}$ (partial limit = limit of a subsequence). It's given that $\{0,2\} \subseteq P$ and $\forall n\in \mathbb{N}. \left| {a_{n+1}-a_n} \right| < 1$. Show that there must be another partial limit. My try: Assuming by contradiction there are only $2$ partial limits; $\{0,2\}$. We have: $$\eqalign{
  & \forall \varepsilon  > 0\exists K \in N.\forall k > K:\left| {{a_{{n_k}}} - 0} \right| < \varepsilon   \cr 
  & \forall \varepsilon  > 0\exists L \in N.\forall l > L:\left| {{a_{{n_l}}} - 2} \right| < \varepsilon  \cr} $$ Now, there must $k_0$ such that $k_0+1=l_0$. From the two inequalities above we have: $$2 - 2\varepsilon  < \left| {{a_{{k_0}}} - {a_{{l_0}}}} \right| < 2 + 2\varepsilon $$ Since we can choose $\varepsilon$ to be as small as we want, clearly 
$$\left| {{a_{{k_0}}} - {a_{{l_0}}}} \right| > 1$$ Which is a contradiction to 
$$\left| {{a_{n + 1}} - {a_n}} \right| < 1$$ Am I right? I'm not 100% percent sure of what I did here.","['probability-limit-theorems', 'calculus', 'limits']"
726362,Why is this estimate using a compact embedding in a sobolev space true?,"Let $\Omega\subset\mathbb{R}^3$ be a bounded Lipschitz-domain. We then have, for $s\in[1,6)$ the compact embedding $H^1(\Omega)\stackrel{c}{\hookrightarrow}L^s(\Omega)$ ensuring the existence of a $C>0$ such that $$\|u\|_{L^s(\Omega)}\leq C \|u\|_{H^1(\Omega)}\leq C\left(\|u\|_{L^2(\Omega)}+\|\nabla u\|_{L^2(\Omega)^3}\right)$$ for all $u\in H^1(\Omega)$. I came across a different conclusion in this paper (in the middle of p. 8). This conclusion being: For all $\alpha>0$ there exists $C(\alpha,\Omega)>0$ such that $$\|u\|_{L^4(\Omega)}\leq \alpha\|\nabla u\|_{L^2(\Omega)^3}+C(\alpha,\Omega)\|u\|_{L^2(\Omega)}$$ for all $u\in H^1(\Omega)$. My questions: 1) Why is this statement true? I fear that this is trivial, but I fail to come up with a justification. Maybe a hint or a good reference would already do the trick for me. 2) Beyond that: Is it possible to determine the order of (an optimal) $C(\alpha,\Omega)$ w.r.t. $\alpha$? (Possibly something like $C(\alpha,\Omega)= \mathcal{O}(\alpha^{-1})$ when fixing $\Omega$).","['sobolev-spaces', 'compact-operators', 'functional-analysis']"
726365,A scheme with not-numerable affine covering.,"This question maybe finds the answer in the definition. Let $X$ be a scheme with not hypothesis on it (not noetherian, not affine,... ). Can I find a scheme that has a not numerable affine covering? For example, if a take a set of rings $\{R_i\}_{i \in I}$ such that $|I|=|\mathbb{R}|$, is it true that $\bigsqcup_{i \in I} \mathrm{Spec}(R_i)$ is a scheme?","['algebraic-geometry', 'schemes']"
726376,Does this really converge to 1/e? (Massaging a sum),"Short version: can we prove that
$$\sum_{k=0}^n (-1)^k \binom{n}{k}^2 \frac{k!}{n^{2k}} \to \frac1e$$
as $n \to \infty$? Long version: First, consider
$$a_n = \sum_{k=0}^n \frac{(-1)^k}{k!}$$
It is well-known that $a_n \to \dfrac1e$ as $n \to \infty$; indeed $a_n = \dfrac{!n}{n!}$ is the truncation to the first $n$ terms of the power series for $e^x$, evaluated at $x = -1$ (where $!n$ denotes the subfactorial; it is also equal to the number of derangements on $n$ elements). There is also a simple expression for the generating function $A(z) = \sum_{n=0}^{\infty} a_n z^n$, which is $A(z) = \dfrac{e^{-z}}{1-z}$. (See Exponential Generating Functions For Derangements .) Next, consider
$$b_n = \sum_{k=0}^n \frac{n^{\underline k}}{n^k} \frac{(-1)^k}{k!}$$
where $n^{\underline k} = \binom{n}{k}k!$ denotes a falling factorial, so the extra factor $\frac{n^{\underline k}}{n^k}$ is $\frac{n(n-1)\cdots(n-k+1)}{n(n)\cdots(n)} = 1\cdot\left(1 - \frac1n\right)\cdot\left(1 - \frac2n\right)\cdots\left(1 - \frac{k-1}n\right)$ which for large $n$ (and fixed $k$) is close to $1$. 
I don't know if $b_n$ has a simple form for its generating function too, but it is easy to see that $b_n \to \dfrac1e$ as well; indeed by the binomial theorem we have $b_n = \sum_{k=0}^n \binom{n}{k} (\frac{-1}{n})^k = \left(1 - \frac1n \right)^n$ which is well-known to converge to $\frac1e$ (indeed such a limit is sometimes taken to be the definition of $e^x$). Finally, consider
$$c_n = \sum_{k=0}^n \frac{n^{\underline k}}{n^k} \frac{n^{\underline k}}{n^k} \frac{(-1)^k}{k!}$$ This is the same transformation going from $b_n$ to $c_n$ as from $a_n$ to $b_n$. But can we prove that $c_n \to \frac1e$ too? (And can we write down its generating function compactly, perchance?) More generally, what techniques exist that help in proving something about $\sum t_n s_n$, given $\sum s_n$? This question arose from an attempt to answer this question , where I arrived at the expression $c_n$ above (there I called it $P_{n, n, 0}$; next I'll try to understand $P_{m, w, k}$). [Note: I'm tagging this special-functions too, as I understand $c_n$ has something to do with hypergeometric functions / Bessel functions / something like that.]","['special-functions', 'sequences-and-series', 'binomial-coefficients', 'real-analysis']"
726387,Prove that a pentagon with congruent angles and rational sides is regular.,"The following problem is from the 18th Balkan Mathematics Olympiad. ""In a pentagon all interior angles are congruent and all its sides have
rational lengths. Prove that this pentagon is regular."" Besides the fact that no generality is lost replacing rational sides by integer sides, I am totally lost on this one. I would like hints only, as small as you can make them. I would like to come to a solution on my own if possible.",['geometry']
726398,Inner product on direct sum of Hilbert spaces,Let $H_1$ and $H_2$ are two different Hilbert spaces then how can we define the inner product on $H_1\oplus H_2$,"['inner-products', 'hilbert-spaces', 'functional-analysis']"
726442,Prove $\frac{\sin\theta}{1+\cos\theta} + \frac{1+\cos\theta}{\sin\theta} = \frac{2}{\sin\theta}$,"How to prove:
$\frac{\sin\theta}{1+\cos\theta} + \frac{1+\cos\theta}{\sin\theta} = \frac{2}{\sin\theta}$ Please help.",['trigonometry']
726555,Gauss Elimination - Diagonal dominant matrices don't need row changes,"I was asked to prove the following statement: let $A$ be an $n$ by $n$ matrix with real entries such that $\forall k \in \mathbb N, k\leq n$: $$\sum_{i \neq k} |A_{i,k}| < |A_{kk}|$$ Show that if we were to do gauss elimination (or LU factorization) of $A$, then there will be no need for row changes, no need for partial pivoting. I don't see why this is true, I'd appreciate a hint in the right direction. Maybe I should take a general $n$ by $n$ matrix that is diagonly dominant, try to $LU$ factor it and see that I don't need row changes? is this the way?","['matrices', 'gaussian-elimination']"
726575,Why is a perfect group called a perfect group,"A group is called perfect if we have $[G,G]=G$. I was wondering in what sense is this group perfect? I've never really done anything much with perfect groups so I don't really know anything about their properties and so I was wondering in what sense are they perfect? I suppose I see that it's abelianization is trivial but I don't really know what that will give? Thanks for any help","['terminology', 'group-theory', 'soft-question']"
726587,"Expectation number of cycles in a ErdÅ‘sâ€“RÃ©nyi random directed graph $G(n,p)$","Let $G \sim G(n,p)$ be a directed ErdÅ‘sâ€“RÃ©nyi random graph with $n$ vertices and the probability $p$ that 
there is a directed edge between any two ordered pairs of vertices. What is the expected number of cycles in $G$? Is there an exact formula or an upper bound and lower bound
on the expected number of simple cycles in $G$?","['random', 'random-graphs', 'expectation', 'graph-theory', 'probability']"
726601,Need help with $\int_0^\infty\frac{e^{-x}}{\sqrt[3]2+\cos x}dx$,"Please help me to evaluate this integral:
$$\int_0^\infty\frac{e^{-x}}{\sqrt[3]2+\cos x}dx$$","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
726609,Prove by induction on $n\geq k$ that $n^3 \lt 3^n$. What is the value $k$?,"Prove by induction on $n\geq k$ that $n^3 \lt 3^n$. What is the value $k$? It looks like $k$ should be $0$ after trying random values but obviously that is a terrible way of doing things. Proof: P(n): n^3<3^n

Assume k holds
Prove k+1
P(k+1): (k+1)^3<3^(k+1) At this point, I am not entirely sure where to go. Any advice would be great. Thanks,",['discrete-mathematics']
726616,Geodesic eqautions and length of a curve in geodesic coordinate system.,"About geodesic coordinates: Let S be regular surface. $p\in S$ $\gamma$ be unit speed geodesic on $S$ with parameter $v$ and $\gamma (0)=p$ $\tilde \gamma^v$ be unit speed geodesic s.t. $\tilde \gamma^v(0)=\gamma(v)$ $\tilde \gamma^v$ is perpendicular to $\gamma$ at $\gamma (v)$ . Define $\sigma : U\to S$ $\sigma (u,v)=\tilde \gamma^v (u)$ In this coordinate system first fundamental form is $ds^2=du^2+G(u,v)dv^2$ Where $G(0,v)=1 $ and $G_u(0,v)=0$ Thank you for helping.","['geometry', 'self-learning', 'differential-geometry', 'geodesic']"
726650,How can $x^2y''-3xy'+3y=0$ be solved?,"a) How does $x^2y''-3xy'+3y=0$ can be solved? I know how to solve for constant coefficients, but in this case they are functions... b) In which maximum interval there is a solution that  confirms $y'(1)=6, y(1)=4$?",['ordinary-differential-equations']
726667,"Can a countably generated $\sigma$-algebra be ""approximated"" by a $\sigma$-algebra generated by a countable partition?","My question is a bit vague, hopefully someone can still clarify. Let $(\Omega,\mathcal F,\mathbb P)$ be a probability space and assume that $\mathcal F$ is countably generated. My question is, does there exists a Theorem asserting that there exists a $\sigma$-algebra $\mathcal E\subseteq\mathcal F$ which is generated by a countable partition and such that $\mathbb P$ on $\mathcal F$ can be well approximated by elements in $\mathcal E$? Related references are here Countably generated versus being generated by a countable partition and here Approximating a $\sigma$-algebra by a generating algebra . What I have in mind is for example that for every $F\in\mathcal F$ and every $\varepsilon>0$ there exists $E\in\mathcal E$ with $\mathbb P(F\Delta E)<\varepsilon.$ I am generally looking for a strategy to prove some property, which holds for $\sigma$-algebras generated by countably partition, for countably generated $\sigma$-algebra... After the answer of Michael Greinecker, I realized that what I am really looking for is a Theorem stating something similar to what follows: Let $(\Omega,\mathcal F,\mathbb P)$ be a probability space as above. Let $\varepsilon>0.$ Does there exists a $\sigma$-algebra $\mathcal E_\varepsilon$ which is generated by a countable partition and such that for every $F\in\mathcal F$ there exists $E\in\mathcal E$ with $$\mathbb P(F\Delta E)<\varepsilon?$$","['probability-theory', 'measure-theory']"
726680,Prove that $6(10^{n_1}+10^{n_2}+\cdots+10^{n_k})$ cannot be a perfect square.,"Let $m$ be a natural number with digits consisting entirely of $6$â€™s and $0$â€™s. Prove that m is not the square of a natural number. I started by noting that $m=6(10^{n_1}+10^{n_2}+\cdots+10^{n_k})$ for some natural numbers, $n_1,n_2,\cdots,n_k$ Clearly $m$ has factors of $2,3,5$. I asserted that since $10^a$ is not divisible by $3$, the sums wont be divisible either, so $m$ has one factor of $3$ and cannot be a perfect square. But I realized that this needn't be valid, since $111$ is divisible by $3$, so my argument fails.",['number-theory']
726686,Riemann-integrable functions and pointwise convergence,"Hello, I was hoping for some advice on finding a function which will satisfy this. I think I am okay with the actual execution of the answer, but I don't know how I'm supposed to find a suitable function. Thank you","['integration', 'functions', 'analysis']"
726689,Partial limits and sets of indices,"Let $\{a_n\}$, and $A_1...A_n \subseteq \mathbb{N}$, such that $A_1\cup A_2... \cup A_n= \mathbb{N}$. We denote $P_k$ as the set of all partial limits (= limit of a subsequence) with indices $\in$ $A_k$. Show that $P$, the set of all partial limits is:  $$P = P_1 \cup... \cup P_n$$ My thoughts: First denote $L_i$ a partial limit of $A_i$, and $L_j$, a partial limit of $A_j$. Lets assume by contradiction that there's a limit $L_k$ which involves indices from both $A_i$ and $A_j$. By definition of limit: $$\forall \varepsilon  > 0\exists K \in N.\forall k > K:\left| {{a_{{n_k}}} - {L_k}} \right| < \varepsilon $$ We notice that $\left| {{L_i} - {L_k}} \right|$ is a fixed size. The subsequences are infinite, and therefore we can choose $n_{{k_0}} \in A_i$ such that: $$\left| {{a_{{n_{{k_0}}}}} - {L_k}} \right| < \varepsilon  \wedge \left| {{a_{{n_{{k_0}}}}} - {L_i}} \right| > \varepsilon $$ Which contradicts the assumption $L_i$ is a partial limit of $\{a_n\}$. Can you criticize my work? Am I right? If not, what should I do different?","['probability-limit-theorems', 'calculus', 'limits']"
726712,homeomorphism of cantor set extends to the plane?,"Suppose C is a Cantor set in the Euclidean plane, or even in R^3. Suppose h is a homeomorphism of C onto itself. Can h be extended to a homeomorphism of the whole space? What about if h preserves the Â´end pointsÂ´ of the Cantor set? Seems that the latter is a necessary condition but I donÂ´t know how to prove it.","['general-topology', 'descriptive-set-theory', 'knot-theory']"
726724,hat problem and probability [duplicate],"This question already has answers here : A riddle about guessing hat colours (which is not among the commonly known ones) (2 answers) Closed 8 years ago . There are 7 prisoners in the room. In the entrance all of them get hat in one of random 2 colors: white or black. They are sitting in the circle and the light on. All of them see hat color of the rest but can't see himself. They will be free if at least one of them say the right color of himself hat color and no one is wrong (they could see the answer or no). The other prisoners can't hear the answer. 
How to find the best strategy with the best probability?","['probability-theory', 'probability']"
726782,Find a 3D vector given the angles of the axes and a magnitude,"I would like to know how one would find a point from the angles of three axes and a magnitude. I know how to do this in 2D: $(\cosÎ˜ * m, \sin(Î˜) * m)$. However, I would like to know how this would be computed in 3D with three angles (not two). Thanks","['trigonometry', '3d', 'vectors']"
726789,Prove a set contains an interval centered at zero.,"Prove that if $E \subset [0,1]$ has positive measure, then the set $E-E = \{x-y : x,y \in E\}$ contains an interval centered around zero. Hint: consider the function $h(x)=\textbf{1}_{-E} \star \textbf{1}_{E} $. Ideas: use the continuity of h(x)?","['measure-theory', 'real-analysis']"
726937,What does it mean geometrically for a variety to be locally a complete intersection?,"We say that an affine variety $X \subset \mathbb{A}^n$ of dimension $n-k$  is a complete intersection if the ideal of $X$, call it $I(X)$ is generated by $k$ polynomials, $f_1,\dots,f_k$. We say that an affine variety is locally a complete intersection if at every point the local ring is a complete intersection ring . I find this last definition rather opaque. If a variety is locally a complete intersection does it mean that every point has an affine open neighborhood which is isomorphic to a variety $Y \subset \mathbb{A}^m$ with $Y$ a complete intersection? A reference to a reliable source with this statement would suffice as an answer.  I'm not sure I know enough to understand a proof of this result yet.  If you can give me some intuition that would be great too!","['commutative-algebra', 'algebraic-geometry']"
726940,Finding the derivatives of inverse functions at given point of c,"Hoping someone can help me the understand the steps to solve a problem like this. I'm guessing it involves the formula: $\frac{d}{dx}f^{-1}(f(x))=1/f'(x)$. Am I right in this assumption? I would post some work that I've tried, but I'm not sure where to even start. My professor is bad at explaining things so I'm turning to the site for supplemental instruction. ""For each of the given functions $f(x)$, find the derivative 
$\left. \frac{d}{dx}f^{-1}(x) \right|_{x=c}$ at the given point $c$, first finding $a=f^{-1}(c)$.
$$
f(x)= 3 x + 9 x^{13}; \ \
c = -12, \ \ \
a=? \ \ \
(f^{-1})'(c)=?
$$ $f(x)= x^2 - 13 x + 58$ on the interval $[6.5,\infty);$  $c = 18$,
$a=?$
$(f^{-1})'(c)  = ?$"" I've been able to find the inverse of other functions not involving higher powers like the $9x^{13}$, and then finding the derivative of that inverse, but this particular kind of question stumps me.","['ordinary-differential-equations', 'calculus', 'derivatives', 'inverse']"
726944,Value of a certain integral,"How to find the value of the integral
$$
\int_o^{\infty} \! \frac{x^8}{1+x^4+x^6+x^{10}} \, \mathrm{d}x
$$
given to be $\frac{1}{12}(3\sqrt{2}-1) \pi$ by WolframAlpha and, in general, is there a procedure to find the value of the definite integral of a rational function of the form $\dfrac{x^l}{p(x)}$ where $deg(p) > l > 1$ from $0$ to $\infty$ ?","['definite-integrals', 'integration']"
726950,How is it that treating Leibniz notation as a fraction is fundamentally incorrect but at the same time useful?,"I have long struggled with the idea of Leibniz notation and the way it is used, especially in integration. These threads discuss why treating Leibniz notation as a fraction and cancelling differentials is incorrect, but also go on to say that the notation is suggestive and we use it because it simplifies things: What is the practical difference between a differential and a derivative? If dy/dt * dt doesn't cancel, then what do you call it? In them they say to treat the differential at the end of an integration expression as a ""right parenthesis"". This throws me off a bit because we can so easily do something like: $$\int\cos(3x) \, dx\\
u=3x\\[2ex]
du=3\,dx\\[2ex]
\frac{1}{3}du=dx$$ and then proceed to integrate: $$\frac{1}{3}\int\cos(u) \, du$$ and arrive at the correct answer with ""incorrect"" notation. I am supposed to treat the differential as a parenthesis but using this notation the differential seems to have a value. How does this incorrect notation do such a good job ensuring that we do not disobey the ""reverse chain rule"" and ensures that our integrand is in the form $f'(g(x))\,g'(x)$ ? People often say that it is very suggestive and I am wondering how. Excuse the LaTeX if it looks weird. This is my first time using it.","['calculus', 'integration', 'notation', 'math-history', 'differential']"
726976,Solve $\lim_{x\to0}{\frac{x^2\cdot\sin\frac{1}{x}}{\sin x}}$,"Find the limit: $$\lim_{x\to0}{\frac{x^2\cdot\sin\frac{1}{x}}{\sin x}}$$
After treating it with l'Hopital rule, we get:
$$\lim_{x\to0}{\frac{2x\cdot\sin \frac{1}{x}-\cos\frac{1}{x}}{\cos x}}$$
Now, the numerator of fraction doesn't have a limit, so I can't use l'Hopital rule again.
What to do?
I can split it into two fractions, but I'm not sure how would it help:
$$\lim_{x\to0}{\frac{2x\cdot\sin \frac{1}{x}}{\cos x}} - \lim_{x\to0}{\frac{\cos\frac{1}{x}}{\cos x}}$$",['derivatives']
727000,Equation of intersection of two cones,The equations of two cones are given; $(x-x_{0})^2+(y-y_{0})^2=\frac {(z-z_{0})^2}{m^2}$ and $(x-x_{1})^2+(y-y_{1})^2=\frac {(z-z_{1})^2}{m^2}$ How to find the equations of intersections 1) When the intersection is an ellipse? 2) When the intersection is a hyperbola?,"['geometry', 'conic-sections']"
727012,"A function continuously differentiable that is bijection from $\mathbb R$ to $ \mathbb R$, but the continuous inverse is not differentiable.","Does there exist a function $f: \mathbb R \to \mathbb R$ , $f$ is continuously differentiable and bijection and has a inverse function $g: \mathbb R\to \mathbb R$ , but $g$ is not differentiable everywhere? I compare it with the inverse theorem and found that the difference is that the differentiable function of $f$ doesn't have to be invertible, but I am struggling to find such a function.","['calculus', 'analysis']"
727036,How did the Symmetric group and Alternating group come to be named as such?,"The Dihedral group makes sense, ""Di"" means two, and ""hedral"" means.. shape I think (I've just realised how much of what I think words mean are guesses based on experience) like a ""polygon"" is a 2d shape, a ""polyhedron"" I've always thought is just ""any shape"" (example 3 dimensions). So ""Dihedral"" means 2 dimensions, which it is. (Octagon and cube have different ... reflection+rotation groups (I hope)) The symmetric group has nothing to do with symmetries of shapes, it instead is the group of all bijections from one set to another. I suppose this means symmetry as in ""abc->acb"" has the ""symmetric"" version ""$abc\to bac$"". Now the alternating group... I have no idea. Now I discovered these in ""Algebra"" and ""Abstract Algebra"" but I've peeked at the contents page of the Combinatorics book I am reading and the symmetric is discussed there, this makes a lot of sense really, combinatorics seems to be the study of finite functions and seems to be easier than functions on the reals and stuff (which felt odd as I was sketching $x^3$ before I was considering ""discreet"" functions, but if anything they're easier) So I guess that they were named because Combinatorics got there first. How? What (general case) question was being faced that lead to the solution being called ""The symmetric group"" (or even set, I doubt combinatorics would care that it is a group). Sometimes how and why are similar, like turning points, ""how did we decide to call $\frac{dy}{dx}=0$ a turning point"" and ""why"" are identical. However there may be many ""whys"" with these groups as they apply in many areas, there can be only one how. Where the term first cropped up would be a good starting point, but I've yet to find anything. I'll answer this myself if my searching yields anything.","['math-history', 'group-theory', 'symmetric-groups', 'terminology', 'combinatorics']"
727050,"Is the determinant the ""only"" group homomorphism from $\mathrm{GL}_n(\mathbb R)$ to $\mathbb R^\times$?","This might be a dumb question; I know only enough group theory to be able to ask dumb questions. Ken W. Smith has pointed out that one way to get intuition about the determinant is to observe that it maps matrix multiplication to real multiplication. As it is continuous, too, this means that it is a Lie group homomorphism from $\mathrm{GL}_n(\mathbb R)$ to the multiplicative group of the nonzero reals, $\mathbb R^\times$. The natural question to ask, then, is whether it is the only such homomorphism. Obviously not: any function $\mathbf A \mapsto (\det\mathbf A)^k$ for $k\in\mathbb Z$ is also a homomorphism. But are all homomorphisms between the two groups of such a form? That is, Is every Lie group homomorphism from $\mathrm{GL}_n(\mathbb R)$ to $\mathbb R^\times$ identical to $\mathbf A \mapsto f(\det\mathbf A)$ for some homomorphism $f:\mathbb R^\times\to\mathbb R^\times$?","['lie-groups', 'linear-algebra', 'group-theory']"
