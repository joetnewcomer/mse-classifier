question_id,title,body,tags
2400145,"Does the curve $c(t)=\langle \sqrt{1-t^2}\cos t,\sqrt{1-t^2}\sin t,t\rangle$ lie on unit sphere?","Given curve $c(t)=\langle \sqrt{1-t^2}\cos t,\sqrt{1-t^2}\sin t,t\rangle$ and $|t|\le 1$ does the curve lie on a sphere which has radius of $1$ and is centered at $(0,0,0)$? I thought that:
$$
x=\sqrt{1-t^2}\cos t\implies\cos t=\frac{x}{\sqrt{1-t^2}}\\
y=\sqrt{1-t^2}\sin t\implies\sin t=\frac{y}{\sqrt{1-t^2}}
$$
but I have no idea what to do with $z$ coordinate.","['multivariable-calculus', 'parametric']"
2400197,How to find recurrence of prime numbers with periodic function [duplicate],"This question already has answers here : Formula for prime counting function (2 answers) Closed 6 years ago . The aim is to find a recurrence of prime numbers. So we'll take the trigonometric functions as they're standard periodic functions, like $\sin(x)$: we'll take as an argument of $\sin(x)$ the angle found before: $$y=\sin(πx/n) \mid n ∈ ℕ, n>1.$$ Fixed $n$ the function gives as result 0 exactly when $x=n$ for obvious reasons and the other zeros are given for every k*n, where $k=1,2,3,...$ Then take $n_1 ∈ ℕ, n_1 > 1$, for all $n ≠ n_1$ and $ n_1 ∉ $ set of all zeros of the harmonics, $n_1$ is prime because there is only one harmonic that has the first zero in $x=n_1$. This harmonic is called prime harmonic . The set of all zeros of prime harmonics are ℕ/{1} then we can build a function that preserves these zeros. The best method is the multiplication. If the first prime harmonic has n=2, the next number without the zero is 3. Then take the second harmonic that has n=3, the next number without zero is 5 and so on. With this method we build gradually a function $p(x)$: $$p(x) = \prod_{n=2}^\infty \sin (πx/n)$$  where $x, n ∈ ℕ$ for all $n \in \sin (πx/n).$
This function $(p(X))$ is called prime function .","['number-theory', 'trigonometry', 'prime-numbers']"
2400224,On the example of the The Hahn decomposition,"Suppose $d\nu = fdm$ is the measure for the following function $f$,
$$
f(x)=
\begin{cases}
x& \text{if}~x\geq 1;\\
0& \text{if}~-1<x\leq 1; \\
-x^2& \text{if}~x\leq -1;\\
\end{cases}
 $$
 I am trying to construct an elaborative example to understand the Hahn decomposition and the Jordan decomposition of $\nu$ in the following manner: The positive set $P=\{x\in\mathbb{R}; \nu(E)=\int_1^{+\infty}xdx\}=+\infty>0$ The negative set $N=\{x\in\mathbb{R}; \nu(E)=\int_{-\infty}^{-1}-x^2dx\}=-\infty<0$ and the null set $M=\{x\in\mathbb{R}; \nu(E)=\int_{-1}^{1}0dx\}=0$ The Jordan decomposition of $\nu$ is the set $\{-\nu,+\nu\}$ I thought The Hahn decomposition is the set $\{P,N\}$ since $P\cap N=\emptyset$. However, $\mathbb{R}\neq P\cup N$. Please, help me rectify all the shortcomings in my attempt on the  Hahn decomposition, Jordan decomposition and compute the total variation of $\nu$.","['real-analysis', 'lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
2400226,Find the smallest $a\in\Bbb N$ if $a-\lfloor\sqrt a\rfloor^2=100$,"I don't know how to solve this algebraically. Sure, I could just brute-force this, but that wouldn't help me understand this equation. (It is not the solution that is so important, it is the way that got you there.) How do I find the smallest $a\in\Bbb N$ for which this is true?
$$a-\lfloor\sqrt a\rfloor^2=100$$
What about an arbitrary number $b\in \Bbb N$?
$$a-\lfloor\sqrt a\rfloor^2=b$$","['algebra-precalculus', 'square-numbers', 'elementary-number-theory']"
2400234,Why did Grothendieck invent schemes when they seem at odds with his philosophy?,"From what I understand, a scheme is basically a sheaf on $\mathbf{Ring}^{\mathrm{op}}$ equipped with an appropriate Grothendieck topology, subject to an axiom that says that schemes look locally like commutative rings. If it weren't for this axiom, the category of schemes would be a topos, and hence very well behaved. But because of this axiom, the category of schemes isn't very well-behaved; for example, it's neither complete nor cocomplete. If so, then focusing on schemes seems to run at odds with Grothendieck's philosophy that it's better to have a good category with bad objects than a bad category consisting only of good objects. What gives here?","['math-history', 'algebraic-geometry']"
2400239,Closed balls are closed,"Let $E \subset X, p \in X$ and $(X,d)$ a metric space such that $E := \{q \in X\mid d(p,q) \leq r\}$. By definition, this is a closed ball with center $p$ and radius $r$. I now want to show that this set is closed (i.e. it contains all its limit points). Proof Let $k$ be a limit point of $E$. Let $\epsilon >0$ and define $N_{\epsilon}(k)$ as the open ball (neighborhood) with center $k$ and radius $\epsilon$. By definition of limit point, there exists $z \in E \cap N_{\epsilon}(k)$ such that $z \neq k$. Hence we have $d(p,z) \leq r$ and $d(k,z) < \epsilon$, so by triangle inequality, we have $d(p,k) < r + \epsilon$. Because $\epsilon >0$ is chosen arbitrarily, it follows that $d(p,k) \leq r$ (if $d(p,k) > r$, then $d(p,k) - r > 0$, implying that $d(p,k) < d(p,k)$, which is absurd). We deduce that $k \in E$ and hence $E$ is closed. $\quad \square$ Is my proof correct? Is there an easier proof?","['general-topology', 'real-analysis', 'proof-verification']"
2400258,Measure function similarity,"I need functional $F(f,g)$ to measure similarity of two real-valued functions $f$, $g$ defined on real segment [a, b] As a simple reasonable example we can consider functional $F(f,g) = \frac{1}{b-a}\int_a^b e^{-(f(x)-g(x))^2} dx$ which have desired properties $F(f,f) = 1$; $F(f,g)\lt 1$ I wandering about a bit sophisticated $F$ that can reveal similarity of two function if: $g(x) = \alpha f(x)$ $g(x) = f(\alpha x)$ $g(x) = \theta (x-a_1) \theta (b_1-x) f(x)$ ($g$ is only 'part' of function $f$) Maybe problem is simpler if functions $f,g$ are defined on finite set ${x_i}$","['information-theory', 'statistics']"
2400259,Limits and substitution,"As in @RobertZ's answer to this question , we often perform substitutions when evaluating limits. For instance, if you're asked to show that 
$$
L = \lim_{t \to 0} \frac{\sin t^3}{t^3} = 1,
$$
it's pretty common to say ""Let $x = t^3$; then as $t \to 0$, we have $x \to 0$, so 
$$
L = \lim_{x \to 0} \frac{\sin x}{x}
$$
which we know is $1$, and we're done."" What's going on here in general is an application of the following ""Theorem"" Theorem 1 : If the function $g$ satisfies [ fill in missing properties ] and $$\lim_{t \to a} g(t) = b,$$ then 
$$
\lim_{t \to a} f(g(t)) = \lim_{x \to b} f(x),
$$
i.e., one limit exists if and only if the other does , and if they both exist, they're equal. In the example above, $f(x) = \frac{\sin x}{x}$ and $g(t) = t^3$ and $a = b = 0$. There's an alternative form, in which we're asked to show that
$$
L = \lim_{t \to 0} \frac{\sin \sqrt[3]{t}}{\sqrt[3]{t}} = 1,
$$
it's pretty common to say ""Let $t = x^3$; then as $t \to 0$, we have $x \to 0$, so 
$$
L = \lim_{x \to 0} \frac{\sin x}{x}
$$
which we know is $1$, and we're done."" In this case, the implicit theorem is very similar to the other, but with the role of $g$ reversed (i.e., we're substituting $ t = x^3$ instead of $x = t^3$, so the natural form of the theorem puts $g$ on the other side): Theorem 2 : If the function $g$ satisfies [ fill in missing properties ] and $$\lim_{x \to b} g(x) = a,$$ then 
$$
\lim_{t \to a} f(t) = \lim_{x \to b} f(g(x)).
$$ In the second example above, we have $a = b = 0$, $f(t) = \frac{\sin \sqrt[3]{t}}{\sqrt[3]{t}}$, and $g(x) = x^3$. The two theorems are obviously the same: if you swap $a$ and $b$, $x$ and $t$, and reverse the equality in the last line, they're identical. But each represents a different approach to working with limits, so I've stated both. In the second form, it's clearly important that $g$ be surjective near $a$ (i.e., for every small enough interval $I = (b-\epsilon, b + \epsilon)$, there's an interval $I' = (a-\delta, a + \delta)$ such that $I- \{b\} \subset g(I' - \{a\})$. (Hat-tip to MathematicsStudent1122 for the observation that I need to delete $a$ and $b$ from those intervals).  Otherwise you could use things substitutions like $s = t^2$, which would turn a two-sided limit into a one-sided one (or vice versa), in which case one limit might exists and the other might not. Addendum to clarify why this might matter, for @MathematicsStudent1122: Consider $$f(x) = \begin{cases}
1 & x \ge 0 \\
0 & x < 0
\end{cases}.$$ and look at $L = \lim_{x \to 0} f(x^2)$. It's clear that $L$ exists and is $1$. But if we substitute $t = x^2$, then we get $L = \lim_{t \to 0} f(t)$, which does not exist; hence this ""substitution"" is not valid: I've turned what amounts to a 1-sided limit (which exists) into a two-sided limit (which does not exist). The domains of $f$ and $g$ are both all of $\Bbb R$. (End of addendum) My question is this: What is a reasonable set of missing properties for each of these theorems? (I can work out the exact properties easily enough by running through the definitions, but they don't seem to be very helpful/checkable.) One answer might be ""$g$ is locally a bijection"", but that rules out things like $y = x + x\sin \frac{1}{x}$ near $x = 0$, so it seems too limited. (It also rules out things like $x \mapsto x + \sin x$ for limits as $x \to \infty$, which is a pity.) I recognize that this is not a strictly mathematical question. But my goal is to come up with a ""calculus student's theorem"", one that says ""if you're trying to work out a limit, which may or may not exist, then it's OK to do substitutions of this sort along the way,"" and which will cover the vast majority of the problems that they might encounter in a standard calculus book, or even in Spivak's book. This question gives two theorems, but both have assumptions about the existence of limits. This one comes a little closer, but still isn't entirely satisfactory. I'd love any nice-enough condition to be broadly useful. In particular, I think it's completely reasonable to require, for instance, that the ""substitution function"" $g$ be continuous, and perhaps even differentiable (although I doubt that's of much use).","['real-analysis', 'calculus']"
2400266,How to find unit group of $\Bbb Z[x]/(nx)$?,"I am trying to work out the group structure of the group of units of $$\Bbb Z[x]/(nx)$$
where $n\ge 2$ is an integer. So finding the units isn't the hard part, they will be of the form $u+t$ where $u$ is a unit of $\Bbb Z$ and $t$ is a nilpotent element of the polynomial ring. The difficult part is trying to work out how they multiply. As far as I can tell these groups don't seem to have any torison, which is probably why I couldn't understand their structure. Is there any way to determine what the group structure might be?","['abstract-algebra', 'ring-theory', 'group-theory']"
2400271,How do I solve an exponential equation like $2^x-3^x+4=0$?,"I was wondering if there was a general way to solve an equation like this: $$2^x-3^x+4=0.$$ Can this be done using logarithms? If not, then is there a way to solve it that doesn't involve ""guessing"" and approximations? The Desmos graphing calculator gives me an answer that is about $1.8453$, but I'm sure the calculator is using Newton's method or something similar to find the zero. I would like to know if logs can be used here.","['logarithms', 'exponential-function', 'calculus', 'functions', 'algebra-precalculus']"
2400300,Evaluate the area of the surface using double integral,"Surface of the cylinder $x^2+y^2=2x$ delimited by $z=0$ and
  $z=\sqrt{x^2+y^2}$. I have to say that I found similar posts but none has helped me, some gave me wrong anwears. The surface integral I take always gave me $\pi$ in it. The real anwear is 8. I preffer polar coordinates, but it's ok without.","['multivariable-calculus', 'surface-integrals']"
2400323,Let $f(x)=\ln(x+\sqrt{x^2+1})$. Find a function $g(x)$ such that $g(f(x))=x$,Let $f(x)=\ln(x+\sqrt{x^2+1})$. Find a function $g(x)$ such that $g(f(x))=x$ for every $x$. Find $g(2)$. I don't have even the slightest idea how to solve such question.I tried to transform the rhs of equation $g(\ln(x+\sqrt{x^2+1})) =x$ in form of $f(x)$ but got struck..,['functions']
2400339,What are the values of the following integrals?,"For each $k = 1,2,3,\dots, $, let $I_k=\left( \frac{1}{k+1}, \frac{1}{k}\right)$, $|I_k| = \frac{1}{k(k+1)}$. Let
  $$g_k(x)=k(k+1)\chi_{I_k} \, : \, \int_0^1 g_k(x)dx=1$$
  for each $k$. Let $f: \mathbb{R}^2 \rightarrow \mathbb{R}$ be defined as follows
  $$f(x,y) := 
\begin{cases}
0, \quad &\text{if}\ (x,y)\not\in[0,1]^2\\
\sum_{k=1}^{\infty}[g_k(x)-g_{k+1}(x)]g_k(y) \quad &\text{if}\ (x,y)\in [0,1]^2
\end{cases}$$
  Find the values of $$\int_0^1\int_0^1f(x,y)dxdy, \, \int_0^1\int_0^1 f(x,y)dydx,\, \text{and}\, \iint_{[0,1]^2}f(x,y)dxdy$$ The values of the integrals are supposed to be $1, 0$ and $\infty$ respectively, but I don't know why (I get that both the iterates are $0$). For example:
 \begin{align*}
\int_0^1 \int_0^1 f(x,y)dydx &= \int_0^1 \int_0^1 \sum_{k=1}^{\infty} [g_k(x)-g_k(x)]g_k(y)dydx\\
& =\int_0^1 \sum_{k=1}^{\infty}\int_0^1[g_k(x)-g_{k+1}]g_k(y)didx\\
& =\sum_{k=1}^{\infty} \int_0^1 g_k(y) \int_0^1 [g_k(x)-g_{k+1}(x)]dx dy\\
& = \sum_{k=1}^{\infty}1\cdot 0 = 0
\end{align*} 
and with the same calculations, I get the same result for the other iterate. Where were my mistakes? If someone could point them out and explain to me how to get to the desire result, I'd be more than happy. Thank you!","['measure-theory', 'integration', 'definite-integrals', 'sequences-and-series']"
2400383,Suppose $\mathcal F$ is a nonempty family of sets and $B$ is a set. Prove that $B ∪ (∪\mathcal F) = ∪(\mathcal F ∪ \{B\})$.,"This is Velleman's exercise 3.5.16.a: Suppose $\mathcal F$ is a nonempty family of sets and $B$ is a set. Prove that $B ∪ (∪\mathcal F) = ∪(\mathcal F ∪ \{B\})$. And here's my proof of it: Proof. ($\rightarrow$) Suppose $x ∈ B ∪ (∪\mathcal F)$. Suppose $x ∈ ∪\mathcal F$. Now we choose an $A_0$ such that $A_0 ∈ \mathcal F$ and $x ∈ A_0$. Thus we have $x ∈ ∪(\mathcal F ∪ \{B\})$. Therefore, $x ∈ B ∪ (∪\mathcal F) \Rightarrow x ∈ ∪(\mathcal F ∪ \{B\})$. ($\leftarrow$) Suppose $x ∈ ∪(\mathcal F ∪ \{B\})$. We now choose some $A_0$ such that $A_0 ∈ \mathcal F ∪ \{B\}$ and $x ∈ A_0$. We now have two cases: Case 1. $A_0 ∈ \mathcal F$. Since $x ∈ A_0$, $x ∈ ∪\mathcal F$. Ergo $x ∈ B ∪ (∪\mathcal F)$. Case 2. $A_0 ∈ \{B\}$. Since $x ∈ A_0$, $x ∈ B$ and therefore $x ∈ B ∪ (∪\mathcal F)$. From both cases we have $x ∈ B ∪ (∪\mathcal F)$. Therefore $x ∈ B ∪ (∪\mathcal F) \Leftarrow x ∈ ∪(\mathcal F ∪ \{B\})$. Since $x ∈ B ∪ (∪\mathcal F) \Rightarrow x ∈ ∪(\mathcal F ∪ \{B\})$ and $x ∈ B ∪ (∪\mathcal F) \Leftarrow x ∈ ∪(\mathcal F ∪ \{B\})$ then, $x ∈ B ∪ (∪\mathcal F) \iff x ∈ ∪(\mathcal F ∪ \{B\})$. Since $x ∈ B ∪ (∪\mathcal F) \iff x ∈ ∪(\mathcal F ∪ \{B\})$, then $B ∪ (∪\mathcal F) = ∪(\mathcal F ∪ \{B\})$. Now I have three questions : Is my proof valid? In the first part (i.e. $x ∈ B ∪ (∪\mathcal F) \Rightarrow x ∈ ∪(\mathcal F ∪ \{B\})$) I ignored ""$x ∈ B$ "" as a possible case, is there any problem with that? From $A_0 ∈ \{B\}$ and $x ∈ A_0$, I concluded $x ∈ B$. Is that correct (I kind of doubt it)? Thanks in advance.","['logic', 'elementary-set-theory', 'proof-verification']"
2400385,"Find monotonically increasing function $f$ on $[ 1,+\infty )$ such that $ x ( f ( x^{2} ) + 1 ) = f ( x ) ( x^{2}+1 ) $?","Find all monotonically increasing functions $f$ on $\left[1,+\infty\right)$ such that $$x\left( f \left( x^{2} \right) + 1 \right) = f \left( x \right) \left( x^{2}+1 \right) $$ Does there only exist the unique solution $f(x)=x$? At first time, I think that $f$ is monotonically increasing is necessary and meaningful here. Thanks for the comments, there are some strange solutions beyond my thought. And now it seems the property of monotonically increasing is not important, maybe it is because there exists a closed and beautiful form of the solutions.",['functions']
2400404,Find solutions of a dynamical system,"Let $t\in\mathbb{R}$. Consider the following autonomous dynamical system:
\begin{equation}%\label{eqn: u'(phi)}
x'(t)=-\frac{a_{12}\, r _2-r _1\left(\frac{d_2}{y(t)}+a_{22}\right)}{a_{12}\,a_{21}-\left(\frac{d_1}{x(t)}+a_{11}\right)\left(\frac{d_2}{y(t)}+a_{22}\right)},
\end{equation} \begin{equation}%\label{eqn: v'(phi)}
y'(t)=-\frac{a_{21}\, r _1-r _2\left(\frac{d_1}{x(t)}+a_{11}\right)}{a_{12}\,a_{21}-\left(\frac{d_1}{x(t)}+a_{11}\right)\left(\frac{d_2}{y(t)}+a_{22}\right)},
\end{equation}
where $a_{ij} (i,j=1,2)$, $d_i (i=1,2)$ and $r_1$ are positive constants; $r_2$ is a negative constant. I have found numerical solutions for some parameters. These numerical solutions show the monotonicity property, i.e. $x'(t)<0$ and $y'(t)>0$. However, I have no idea to give a rigorous proof and determine under which parameters the solutions are monotone. Moreover, I also want to try some standard methods in dynamical systems to find other types of solution which are not monotone. I am not so familiar with dynamical systems. Any suggestion, idea, or comment is welcome, thanks!","['ordinary-differential-equations', 'dynamical-systems']"
2400420,Show that any finite group $G$ is isomorphic to a subgroup of $GL_{n}(\mathbb{R})$ for some $n$.,"We are told the following: Let $S_n$ denote the permutation group on $\{1,\dots,n\}$ and let $GL_n(\mathbb{R})$ denote the group of invertible $n \times n$ matrices.  Now assume the following fact: for each $n$ there is a group homomorphism $\varphi : S_n \rightarrow GL_n(\mathbb{R})$ such that $\ker (\varphi) = \{\iota\}$, where $\iota$ is the identity permutation. How do I show that any finite group $G$ is isomorphic to a subgroup of $GL_{n}(\mathbb{R})$ for some $n$? I realise I need to use Cayley's theorem for a finite group which is: Every finite group $G$ of order $n$ is isomorphic to a subgroup of $S_n$. However, I am unsure how I can answer this question. Thank you","['matrices', 'abstract-algebra', 'finite-groups', 'group-homomorphism', 'permutations']"
2400426,"Traveling between points on the surface $C(x,y)=e^{-2x^2-3y^2}$","We have a start point $(0,0)$ and an end point $(1,2)$, we would like to travel from the start to the end point. The surface is given by the equation $C(x,y)=e^{-2x^2-3y^2}$ and we would like to always travel in the direction of where the slope is the steepest (meaning that in each point we travel in the gradients direction). This means we will get some path between the points, and this path can be seen as the graph of the function $y=\phi (x)$. I want to determine what this function $\phi$ is. How do I approach this problem?","['multivariable-calculus', '3d', 'ordinary-differential-equations']"
2400431,Inequality in functional analysis,"I have a little question about functional analysis, limit and inequality. Let a function $f$ with domain $]0,+\infty[$ and codomain $]0,+\infty[$ and twice differentiable with the following inequality :
  $$f'+f''\geq f^2$$ Show that the limits of $f$ when $x$ tends to infinity exists and determine it. My try : I make the following substition :
  $$f(x)=-g(-e^{-x})$$
  And the inequality becomes :
  $$g(-e^{-x})^2\leq e^{-2x}(-g''(-e^{-x}))$$
  Or 
  $$g(X)^2\leq X^2(-g''(X))$$
  if we put $X=-e^{-x}$ After that, I think we can use a Wirtinger-like type inequality (perhaps generalized) but I don't know how. If you can read in french see here. Thanks a lot.","['functional-analysis', 'real-analysis']"
2400433,Baby rudin theorem 3.6: proof verification,"Theorem 3.6 in Rudin's principles of mathematical analysis says the following thing: (a) If $(p_n)$ is a sequence in a compact metric space $X$, then some
  subsequence of $(p_n)$ converges to a point of $X$ I will now provide the worked out proofs, and I wonder if someone could verify whether I understood the details left out correctly. Before I start the proof, let me introduce the notation $N_r(p)$, which is the open ball (or neighborhood) with center $p$ and radius $r$ Proof : (a) Define $E:= \{p_n \in X\mid n \in \mathbb{N}\}$ We consider two cases: $\boxed{1}$ $E$ is finite In this case, since a sequence is infinite, it must follow that there is an element $p \in E$ that occurs an infinite amount of times in the sequence. So, there are integers $n_1 <n_2 <\dots$ such that $p_{n_i} = p$ for $i = 1,2,3, \dots$. So, the sequence $(p_{n_i})_{i }$ is a constant subsequence with limit $p \in X$ $\boxed{2}$ $E$ is infinite By a theorem that is already proven (theorem 2.37), the set $E$ has a limit point $p \in X$, since $X$ is compact. Now, we construct a subsequence that converges to $p$. Since $p$ is a limit point of E, for any neighborhood $N$ of $p$, there are infinitely many point in the intersection $E \cap N$. Because of this, we can find an element in $N_1(p) \cap E$, meaning that we can pick an element of the sequence on distance less than $1$ from $p$. 
Call this element $p_{n_1}$. Now, pick an element of the sequence on distance less than $1/2$ from $p$. Moreover, pick this element such that it occurs after $p_{n_1}$ in the sequence. This is certainly possible, because there are an infinite elements on such a distance and only a finite amount of elements 
occur before $p_{n_1}$ in the sequence. Call this element $p_{n_2}$ Continuing in this way (i.e. every time, we pick a point $p_{n_i}$ such that $d(p,p_{n_i}) < 1/i$, the argumentation to make this rigorous can be found in the previous paragraphe), we obtain the existence of a subsequence $(p_{n_i})_i$ with $d(p,p_{n_i}) < 1/i$. We now prove that $p_{n_i} \to p$ . For this, let $\epsilon > 0$. By the archimedian property of the real numbers, there is a positive integer $I$ such that $1/I < \epsilon$. So, let $i > I$, then $1/i < 1/I < \epsilon$, such that $d(p,p_{n_i}) < \epsilon$. This shows that $p_{n_i} \to p \quad \square$ Questions: Have I filled up the details correctly?
  Is the last paragraph correct?","['real-analysis', 'limits', 'proof-verification', 'compactness', 'sequences-and-series']"
2400443,Prove that there is no positive integer between 0 and 1,"In my textbook ""Elementary Number Theory with Applications"" by Thomas Koshy on pg. 16, there is an example given just after the well ordering principle: Prove that there is no positive integer between $0$ and $1$ . My question is how can you even start this proof? I checked the book and google for a formal definition of integers, but they are pretty vague. The book just says $\{\ldots, -3, -2, -1, 0, 1, 2, 3, \ldots\}$ , and some of the websites say that it's a number without a fractional component. Then what is a fractional component? I took a course on Algebra and we defined them as equivalence classes... but to obtain that, it would require the knowledge of basic things like $1$ is the least positive integer. So I'm getting stuck in this loop. Here's what the textbook says. Proof. (as in textbook) Suppose there is a positive integer a between $0$ and $1$ . Let $S = \{n \in \mathbb{Z}^+ | 0 < n < 1\}$ . Since $0 < a < 1$ , $a \in S$ , so $S$ is nonempty. Therefore, by the well-ordering principle, $S$ has a least element $l$ , where $0 < l < 1$ . Then $0 < l^2 < l$ , so $l^2 \in S$ . But $l^2$ < $l$ , which contradicts our assumption that $l$ is a least element of $S$ . Thus, there are no positive integers between $0$ and $1$ . However, we have no definition of $l^2$ (and we can't say anything about its order). I'm just simply not getting convinced by this proof. Can someone help?","['number-theory', 'well-orders']"
2400449,How to find $\lim_{x \to \infty} \frac{ex^{x+1}-x(x+1)^x}{(x+1)^x}$,"I came across this problem a few days ago and I have not been able to solve it. Wolfram Alpha says the answer is 1/2 but the answer I came up with is 0. Can anyone see what is wrong with my work and/or provide the correct way of solving this problem? $$\lim_{x \to \infty} \frac{ex^{x+1}-x(x+1)^x}{(x+1)^x} $$
$$\lim_{x \to \infty} \frac{ex^{x+1}-x[(x)(1+\frac{1}{x})]^x}{[(x)(1+\frac{1}{x})]^x} $$
$$\lim_{x \to \infty} \frac{ex^{x+1}-x^{x+1}(1+\frac{1}{x})^x}{x^x(1+\frac{1}{x})^x} $$
$$\lim_{x \to \infty} \frac{ex^{x+1}-x^{x+1}e}{x^xe} $$
$$\lim_{x \to \infty} \frac{x-x}{1} $$
$$\lim_{x \to \infty} \frac{0}{1} $$
$$0$$ I understand my mistakes may be simple and trivial, but I'm trying to learn. Thank you for your help!","['rational-functions', 'calculus', 'limits']"
2400526,Induction for f$(n+2)=f(n+1)+6f(n)$ and its property,"i'm having real hard time with this: f:N->N is defined in recursion as following: f(0)=0, f(1)=10, and for ever $n \in N$ $f(n+2)=f(n+1)+6f(n)$. a) prove by induction (only induction) that $f(n)=2*3^n+(-2)^{n+1}$ b)is f surjective? what i tried to do: a)i don't even know how to prove it by induction, so i tried to use common sense. since it's known that $f(0)=0$, $f(1)=10$, then if we input n=0, we get $f(0+2)=f(0+1)+6f(n) -> f(2)=10$. so we'll check for n=1, and get $f(1)=2*3+4=10$ which is valid. now we'll assume that f(n) is true and used it as the basis of induction and try to prove it for the next element, i.e f(n+1): $f(n+1)=2*3^{n+1}+(-2)^{n+2}=2*3^n*3+(-2)*(-2)^{n+1}$, now since we assumed $f(n)=2*3^n+(-2)^{n+1}$ is true, we'll substract $f(n+1)-f(n)$ to get f(1) and we get it's equal to 10. so by using the induction principle we've proven it's true for every $n \in N$ b)after showing f(n) is true, we can use it's properties to assert that for every $y \in Y$ there exists $x \in x$ there's f(x)=y, to claim it's surjective, while considering it's definition, i.e: f:N->N. if we look at f, we see that it is always natural, since $3^n \geq (-2)^{n+1}$, since if $(-2)^{n+1}$ is negative then 3^n will always make it bigger than 0, and if it's positive there would always be a representation of it in N (i don't know how to prove it correctly). please help me write it correctly. i've written everything i've done and tried to elabroate as much as i can","['recurrence-relations', 'relations', 'discrete-mathematics']"
2400584,Range of $|x+3|+|x-3|=6$,"I can solve this equation by som tedious algebra, I got $x_1=3$ and $x_2=-3$. But according to the book the solutions are given by $x\in[-3,3]$, which means that for example $x=1$ and $x=2$ are solutions as well. How can I algebraically show this? Or can I interpret the absolutes as distances along the x-axis and somehow proceed from there?",['algebra-precalculus']
2400613,Let $\frac13\sin a-\frac17\cos a=\frac{1}{2017}.$ ...,"Let $a$ in $[0, \pi]$ such that $\frac13\sin a-\frac17\cos a=\frac{1}{2017}.$ If $\lvert\tan{a}\rvert=\frac mn$, where m and n are relatively prime, find m+n. My work: $\frac13\sin a-\frac17\cos a=\frac{1}{2017}$ From the trig identity $a \cos{t} + b \sin{t} = \sqrt{a^2 + b^2} \; \sin(t + \tan^{-1} \frac{a}{b})$ it follows that: $\sqrt{\frac{1}{9}+\frac{1}{49}}\sin (a-\arctan{\frac37})=\frac{1}{2017}$ $a=\arcsin{\frac{1}{2017\sqrt{\frac{58}{441}}}}+\arctan{\frac37}$ ... From here I bashed out long equations using more trig identities/cancelling by taking the sine of both sides, but I did not get a fraction and the work is not worth putting here. I'm assuming the approach of using $a \cos{t} + b \sin{t} = \sqrt{a^2 + b^2} \; \sin(t + \tan^{-1} \frac{a}{b})$ was somehow incorrect or I made a simple error somewhere later on. When I originally tried solving this problem I multiplied through by 3*7*2017 but this leads to the same issue and gigantic numbers everywhere. Is there a better approach to solving this? This question was from the AMSP 2017 Test C entrance exam.","['contest-math', 'trigonometry']"
2400614,Prove that $∩\mathcal H ⊆ (∩\mathcal F) ∪ (∩\mathcal G)$.,"This is Velleman's exercise 3.5.17: Suppose $\mathcal F$, $\mathcal G$, and $\mathcal H$ are nonempty families of sets and for every $A ∈ \mathcal F$ and every $B ∈ \mathcal G$, $A ∪ B ∈ \mathcal H$. Prove that $∩\mathcal H ⊆ (∩\mathcal F) ∪ (∩\mathcal G)$. And here's my proof of it: Proof. Let $x$ be an arbitrary element of $∩\mathcal H$. We now have two cases to consider: Case 1. $x ∈ ∩\mathcal F$. Thus certainly $x ∈ (∩\mathcal F) ∪ (∩\mathcal G)$. Case 2. $x ∉ ∩\mathcal F$ which is equivalent to $∃A ∈ \mathcal F(x ∉ A$). From $∃A ∈ \mathcal F(x ∉ A$) and $x ∈ ∩\mathcal H$, we have $A ∉ \mathcal H$ from which we can conclude $B ∈ \mathcal H$. Since $B ∈ \mathcal H$ and $x ∈ ∩\mathcal H$, then $x ∈ ∩\mathcal G$. Ergo $x ∈ (∩\mathcal F) ∪ (∩\mathcal G)$. Since from the both cases we get $x ∈ (∩\mathcal F) ∪ (∩\mathcal G)$ and $x$ was arbitrary, then $∩\mathcal H ⊆ (∩\mathcal F) ∪ (∩\mathcal G)$. Is my proof valid? Particularly this part: ""From $∃A ∈ \mathcal F(x ∉ A$) and $x ∈ ∩\mathcal H$, we have $A ∉ \mathcal H$ from which we can conclude $B ∈ \mathcal H$"". Thanks in advance.","['logic', 'elementary-set-theory', 'proof-verification']"
2400631,The curve $y^2 - x^3=0$ isn't a differential submanifold of $\mathbb{R}^2$,"So, I would like to prove that the curve $\alpha :y^2 -x^3 =0$ is not a differential submanifold of $\mathbb{R}^2$ . My notes are quite messy about this, and at the time it was an argument that I really didn't get. Moreover, it's one of the first times I have to deal with manifolds. I know that I am supposed to use (I mean, the teacher used) the implicit function theorem, and see the curve as the locus of zeros of a differentiable function in $\mathbb{R}^2$ , because I need a submanifold of $\mathbb{R}^2$ . If you consider such a function, you can prove that in $(0,0)$ both partial derivatives are zero. Then you say you can't apply the implicit function theorem and so the curve is not a submanifold of $\mathbb{R}^2$ . There are a few things I am not sure about. However, the most troublesome is by far the application of the implicit function theorem. I mean, the theorem is great if you want to prove that some curve has a regular parametrization without bothering searching for an explicit one, which is great if I had wanted to prove that a curve is a differential submanifold. Here I cannot apply  the theorem in $(0,0)$ . How can you conclude then? Doesn't the implicit function theorem give only sufficient conditions? I mean, if you prove that every differentiable function in $\mathbb{R}^2$ with $\alpha$ as locus of zeros has partial derivatives equal to $0$ at the origin, why should it mean that no structure of differential submanifold is possible at all?","['differential-geometry', 'differential-topology']"
2400637,"Simple probability question, with faulty screws.","I have translated the problem as follows: A factory produces screws, the probability of them being faulty is 0.01 independently. The factory makes a box with 10 screws and recalls the boxes containing 2 or more faulty screws. What is the percentage of boxes that the factory has to recall?","['combinatorics', 'percentages', 'probability']"
2400645,to prove an integral operator with a kernel is compact,"emphsisingly, I just need a hint not a whole solution please. Problem :
  Consider the operator
  $T:C([0,1])\to C([0,1])$defined by 
  $$ (Tf)(t):=\int_{0}^{1}k(s,t)f(s)ds $$ 
  where 
  $k:[0,1]^{2}\to \mathbb{R}$
  satisfies the following for all 
  $t\in [0,1],$
  the function
  $k_{t}(s)=k(t,s)$
  is integrable in $s$:
  $$ \int_{0}^{1}k(s,t)ds<\infty, $$ the function 
  $ t\mapsto k_{t}\in L^{1}([0,1]) $
  is continuous. Show that $T$ is compact.","['real-analysis', 'compact-operators', 'operator-theory', 'functional-analysis', 'analysis']"
2400666,Any elegant reason behind the following identity?,"$$
\sum_{i=1}^{n-k+1} {{n - i}\choose{k - 1}} i = {{n + 1}\choose{k + 1}} 
$$ Note that the identity is obviously true for $k=1$ and $k=2$. For $k=1$ left hand side = $\sum_{i=1}^n i = \frac{n(n+1)}{2} = {{n + 1}\choose{2}}$ = right side For $k=2$ left hand side = $\sum_{i=1}^n (n-i)i = \frac{n^2(n+1)}{2} -\frac{n(n+1)(2n+1)}{6} = \frac{(n-1)n(n + 1)}{6} = {{n+1}\choose{3}}$ = right side I proved the above identity using some boring algebra. I used the trick that left hand side is equal to coefficients of $x^{k - 1}$ in the series  $\sum_{i=1}^{n-k+1} i(1 + x)^{n-i}$. Using the geometric progression trick, we can show that $$\sum_{i=1}^{n-k+1} i(1 + x)^{n-i} = -\frac{(1+x)^{k-1}(n-k+1)}{x} + \frac{(1+x)^{n+1}}{x^2} - \frac{(1+x)^k}{x^2}.$$ 
  Clearly the coefficients of $x^{k-1}$ in right hand side is ${{n+1}\choose{k+1}}$.",['combinatorics']
2400670,Dimension of $\mathbb{Q}$-vector space if a nonsingular linear transformation $T$ exists such that $T^{-1} = T^{2} + T$,"We're given $V$ a finite dimensional vector space over $\mathbb{Q}$, $T$ a non-singular linear transformation of $V$ such that $T^{-1} = T^{2} + T$. The question has two parts. If I understand part (a), I should be able to get part (b), so right now I'm looking for a hint on part (a): (a) Prove that the dimension of $V$ is divisible by 3.
(b) Prove that if the dimension is exactly 3, then all such transformations $T$ are similar. I'm trying to think of $T$ as a matrix. I can get $v = A^{3}v + A^{2}v$ for any $v$, but I don't know where to go from there.","['abstract-algebra', 'linear-algebra', 'linear-transformations']"
2400719,How to correctly understand submanifolds?,"First a disclaimer: the particular interest that led me to this is the use of submanifolds in General Relativity, in particular spacelike hypersurfaces. This idea used a lot in GR led me to seek a better understanding of submanifolds. So, the point is that up to now my understanding of submanifolds has been quite ""informal"", mostly based on examples, and most examples are something like: pick a manifold $M$ a chart $(x,U)$ and hold some coordinate functions constant. This defines a submanifold. Now this is not a good understanding of the subject. So searching for a formal understanding I've tried Spivak's book. He defines actually four things: Definition 1: A differentiable function $f : M\to N$ is called an immersion if the rank of $f$ is $\dim M$ . Definition 2: A subset $M_1\subset M$ together with a differentiable structure that need not be inherited from $M$ is called an immersed submanifold if the inclusion $i : M_1\to M$ is an immersion. Definition 3: An embedding is an immersion $f: M\to N$ which is injective and a homeomorphism over its image. Definition 4: A submanifold of $M$ is an immersed submanifold $M_1$ such that the inclusion $i : M_1\to M$ is an embedding. Other authors do differently. For example, Sean Carroll in his Spacetime and Geometry says: Consider an $n$ -dimensional manifold $M$ and an $m$ -dimensional manifold $S$ , with $m\leq n$ , and a map $\phi : S\to M$ . If the map $\phi$ is both $C^\infty$ and one-to-one, and the inverse $\phi^{-1} : \phi(S)\to S$ is also $C^\infty$ , then we say that the image $\phi(S)$ is an embedded submanifold of $M$ . If $\phi$ is one-to-one locally but not necessarily globally, then we say that $\phi(S)$ is an immersed submanifold of $M$ . When we speak of ""submanifolds"" without any particular modifier, we are imagining that they are embedded. The major difference here is: for Spivak, submanifolds are subsets obeying certain properties (that is what I would expected), for Carroll, they are other manifolds which we map into subsets, which seems quite odd. Strangely, I've read some authors saying that this is one concept that is really done different by each author. What I find confusing is that the idea of a ""sub-structure"" in general is quite straightforward. In Algebra defining subgroups, vector subspaces and so forth is quite easily done, it is just a subset with a straightforward property that makes it ""inherit"" the structure of the first set. The same happens with topology when defining topological subspaces with the relative topology. Submanifolds seems different. One author resorts to ""external"" sturcture, namely, another manifold. Spivak also says that the ""submanifolds"" might have another differentiable structure. This all confuses me. For example: what if we have a subset and want to inherit the structure of the original manifold? After all that is what is done in all those examples I've mentioned. How to correctly understand submanifolds, the various definitions and the relations between them? Why this is a good definition of submanifold? How to truly understand why this is the correct definition of a sub-structure for manifolds?","['smooth-manifolds', 'manifolds', 'submanifold', 'general-topology', 'differential-geometry']"
2400755,Misunderstanding on maximal atlas,"From this topic : Definition of Maximal atlas I found the definition of a Maximal Atlas. But I don't understand how a maximal atlas could exist. Indeed, I understand the maximal atlas as the one such as if we add another map then it will no longer be compatible. But if we take $\mathbb{R}^2$ as manifold and imagine that we have a chart $(U,\phi_U)$ that maps the subset $U$ of $\mathbb{R}^2$ to a disk in $\mathbb{R^2}$. For example, we take $U$ the disk of radius $1$ and $\phi_U$ the identity ( $\phi_U:x\in U \mapsto x\in \mathbb{R}^2$). We can take $V \subset U$ a disk of radius $1/2$ and $\phi_V(x)=x+(1,0)$ such as $(V,\phi_V)$ is another chart. Thoose two charts are compatible (I can find a map from the disk centered at the origin and the disk centered in $(1,0)$). And if we iterate we can always take a subset inside the previous one and we can add as much charts as we want and they would be compatible. Here I took $M=\mathbb{R}^2$ as the manifold of example but this could be generalized to any M. Where do I miss something ?","['differential-geometry', 'definition']"
2400764,Is integrability of the almost complex structure redundant in the definition of Kähler manifolds?,"In the definition of a Kähler manifold, is the integrability of the underlying  almost complex structure redundant? In other words, is there a manifold $M$ with almost complex structure $J$, symplectic structure $\omega$ and Riemannian metric $g(X,Y)=\omega(JX,Y)$ but $J$  is not integrable?","['complex-geometry', 'symplectic-geometry', 'kahler-manifolds', 'differential-geometry', 'definition']"
2400798,Let $f: X\to\mathbb{R}$ be bounded and measurable (X meas.). Show that $f$ is Lebesgue integrable,"Let $f: X\to\mathbb{R}$ be bounded and measurable and $X$ is a measurable subset of $\mathbb{R}$.
Suppose $\exists M>0$, $\alpha \in (0,1)$, s.t $\forall \epsilon > 0$ $$ m(\{x \in X: |f(x)| > \epsilon \}) < \frac{M}{\epsilon^{\alpha}} $$ Show that $f$ is Lebesgue integrable. I already solve this problem when $f: [0,1] \to \mathbb{R}$ and when M is not in the problem. That is easier, because only considering a simple partition of [0,1] we can get that $\int|f(x)| < \infty$. But on this problem, I have a measurable set $X$ and it's not given that it has finite measure and that complicates the problem. I believe I have to use the simple approximation theorem.","['real-analysis', 'lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
2400809,"Derivative of evaluation along diagonal $g(x) := f(x,x)$","Let $f:\mathbb{R}^2 \to \mathbb{R}$ be a differentiable function. Define $g(x) := f(x,x)$. I want to prove that $g$ is differentiable as well and that $$Dg(x)h = Df(x,x)(h,h) = [\partial_1f(x,x) + \partial_2f(x,x)]h.$$ I was trying to prove the fact by directly using the definition of differentiability for functions of one variable. We have \begin{align*}
g(x+h) - g(x) &= f(x+h,x+h) - f(x,x)\\
&= f(x+h,x+h) - f(x+h,x) + f(x+h,x) - f(x,x)\\
\end{align*}
Now, if we devide by $h$ \begin{align*}
\frac{f(x+h,x+h) - f(x+h,x)}{h} + \frac{f(x+h,x) - f(x,x)}{h}\\
\end{align*} and take the limit $h \to 0$ we get \begin{align*}
\lim_{h \to 0} \frac{f(x+h,x+h) - f(x+h,x)}{h} + \partial_1f(x,x).
\end{align*} Here I'm stuck. How can I show that the first limit equals $\partial_2f(x,x)$?","['multivariable-calculus', 'real-analysis', 'derivatives']"
2400817,How to find the derivative of $\frac{1}{x^3}$ by definition of derivative,"$$f(x) = \frac{1}{x^3}$$
  Find the derivative of $f$ by using the derivative definition. I have tried several pages of working, but nothing seemed to work until I actually used the quotient rule (definitions of derivative are soo complicated lol).","['derivatives', 'calculus', 'limits']"
2400818,What is the Fréchet derivative?,"I'm sorry if I sound too ignorant, i don't have a high level of knowledge in math I've been lately trying to understand the Frèchet derivative. I'm just starting Calc II, but I have a tiny grasp in multivariable calculus. That is, I understand that one can treat some of the variables as constants and get a directional derivative. According to wikipedia, if the limit of the equation below as $h$ tends to $0$ is equal to $0$ then the function is said to be Fréchet differentiable at $x$. $$\frac{||f(x+h)-f(x)-T(x)||}{||h||}$$ And as much as this can work as a definition, I'm still wondering what the Fréchet derivative actually is. My confusion might also come from the fact that there are some ideas in multi-variable calculus I don't get, so I will try to summarize my questions below. Q1. If I understood correctly, $f$ could be a multi-variable function, so how come we use only one $x$? Is it because $x$ is itself a multi-variable vector? Q2. What is the meaning of $T(h)$? As in, what is it, and what is it doing in this equation? Q3. Why does this equation -when $h$ tends to $0$- somehow tells whether a function is (Fréchet) differentiable or not? How does this equation relates to what a Fréchet derivative is? Any help/thoughts would be really appreciated.","['derivatives', 'calculus', 'multivariable-calculus', 'definition', 'frechet-derivative']"
2400877,Expected value of Compond Poisson Process,"I'm having trouble understanding why we do this: Information Definition. A stochastic process $\{X(t),t\geq 0\}$ is a compound Poisson process if 
$$X(t) = \sum_{i=1}^{N(t)} Y_i, \qquad t\geq 0$$
where
$\{N(t),t\geq 0 \}$ is a Poisson process and $\{Y_i , i = 1,2,3,\ldots\}$ are independent and identically distributed random variables. Expected Value This is what they did
$$\mathbb{E}(X(t))=\mathbb{E}(\mathbb{E}(X(t)\mid N(t))) \qquad \text{law of total expectation} \\ = \mathbb{E}\left\{\mathbb{E}\left[\sum_{i=1}^{N(t)}Y_i\mid N(t) \right] \right\}\\ = \mathbb{E}(N(t)\mathbb{E}(Y_1)) = \lambda t \mathbb{E}(Y_1).$$ Query I don't understand why in the first equality, they used the law of total expectation. As in, what's the point? Can't I simply have $$\mathbb{E}(X(t)) = \mathbb{E} \left(\sum_{i=1}^n Y_i\right)= \sum_{i=1}^{N(t)} \mathbb{E}(Y_i) \qquad \text{by independence} \\ =N(t)\mathbb{E}(Y_1)$$
which is clearly not correct, but why isn't it correct? Also, how did they go from the second equality to the third? Thanks in advance!","['poisson-process', 'probability-theory', 'proof-explanation']"
2400918,Proof that $f$ is injective iff $\bigcap_{i\in I} f(A_i) = f( \bigcap_{i \in I} A_i)$ for every $(A_i)_{i\in I}$,"I think I have a proof by contradiction of the following result but I am not sure about it. Show that $f$ is injective iff $\bigcap_{i\in I} f(A_i) = f( \bigcap_{i \in I} A_i)$ for every $(A_i)_{i\in I}$. This is my first contact with actual mathematical theory, and it has always been my biggest knowledge gap as my actual field of study(physics) relies mostly on just applying math more than really understanding it, so I can say it has been a pretty rough first contact... My try is as follows:
Assuming f(x) is not injective, then,
$ \exists x \land x' \in X; x \neq x'; f(x) = f(x')$
Taking $x \in \bigcap_{i \in I}A_i \land x' \in A_i$, but, 
$x' \notin \bigcap_{i \in I}A_i \Rightarrow f(x) \in f(\bigcap_{i \in I}A_i) \land f(x') \notin f(\bigcap_{i \in I}A_i)$, however, $f(x) = f(x')$.
Hence, being a contradiction!","['elementary-set-theory', 'functions']"
2400927,About metrizability of weak topology on $\mathcal{M}(\Omega)$ the space of all finite borel measures,"Is the weak$^*$ topology on space of all finite Borel measures defined on a compact set metrizable? Is this true for any bounded domain instead of compact set?
I know a result from Kesavan that A Banach space $X$ is separable if and only if the weak$^*$ topology on the closed unit ball in $X^*$ is metrizable In order to use this result I need $\textbf{Space of all finite Borel measures defined on a compact set}$ is separable. Is this true? $\textbf{OR}$ Is there any other way to prove this?
Any references is greatly appreciated. Thanks!!","['functional-analysis', 'measure-theory']"
2400941,Check proof that every point in open set $E \subset\mathbb R^2$ is a limit point of $E$,"Would appreciate if somebody can comment if my writing is clear and accurate. Prove that every point in open set $E \subset\mathbb R^2$ is a limit point of $E$. Suppose $x \in E.$ Then, there exists a neighborhood of $x$ with radius $r, N_r(x)$ such that $N_r(x) \subset E.$ Now consider any neighborhood of $x, N_s(x).$ If $s \leq r$ then $N_s(x) \subset N_r(x)$ and contains a point of $E$ other than $x.$ If $s \geq r$ clearly it contains some other point of $E$ other than $x$ as $N_r(x)$ contains a point of $E$ other than $x.$ Hence, $x$ is a limit point.","['general-topology', 'proof-verification']"
2400943,Find the total Number of Path of length L,"find the number of the  path between two points on a grid where you can only move one unit up, down, left, or right? Is there a formula for this?. Any shortest path from $(0,0)$ to $(m,n)$ includes $m$ steps in the x axis and $n$ steps in the y axis. This is counted by the binomial coefficient $\binom{m+n}{m} = \binom{m+n}{n}$. But what number about the total path exist of Length L in a grid  and We can revisit the cell ?","['permutations', 'combinatorics', 'graph-theory']"
2401018,singluar values unchanged when multiplied with an orthogonal matrix?,"revisiting singular values of ""rotated"" matrix Maybe I've since forgotten - or maybe I never bothered to ask myself - but Since $A^T$ has the same singular values as $A$ and $K$ is orthogonal, conclude that [        $A^\top K$        ] indeed has the same singular values. Why does this hold? Why can we say that multiplying by an orthogonal matrix retains the singular values?","['matrices', 'matrix-decomposition', 'svd', 'singular-values', 'linear-algebra']"
2401037,Choosing 3 roles from 10 contestants,"The question is:
For an association, a president, vice president and secretary, all different, are to be chosen from 10 contestants. How many different choices are possible if Ramu and Ravi will not associate together? The answer provided is:
Without Ramu and Ravi, the number of choices is $8 \times 7 \times 6$ and with one of them in association the number of choices is $3 \times 2 \times 8 \times 7$. So the total number of choices:
$(8 \times 7 \times 6) + (3 \times 2 \times 8 \times 7) = 672$. My answer is:
Case 1, Both Ramu and Ravi are not chosen:
8P3 = 336 Case 2, Either Ramu or Ravi is not chosen:
$(8 \times 7 \times 3!) \times 2 = 672$ Total different choices: $672 + 336 = 1008$ Why shouldn't I multiply by 2? My thought process is... $(8 \times 7 \times 3!)$ only takes into account that if one of them, say Ramu, was chosen. But Ravi can also be chosen and I have to take that case into account too? If someone could explain to me why I shouldn't multiply by 2... that would be great, thanks!","['permutations', 'combinatorics']"
2401048,Is there a good software that helps with the outline of a proof?,"Since I'm self-studying, it'll be very helpful to have a software to check the correctness of my proofs. Is there a software like that? And more importantly, is it a good idea to use such a software?","['math-software', 'elementary-set-theory', 'proof-verification']"
2401074,$Q(Q)$ is not complete while it is a finite dimensional vector space.,"Theorem: Every finite dimensional normed space is complete. $Q$ is a finite-dimensional normed space over $Q$ with the norm $||x||=$ $|x|$. But it is not complete.
We have a Cauchy sequence $(1+1/n)^n$ tending to $e\in Q^c$.","['functional-analysis', 'normed-spaces']"
2401114,Inequalities about arctan and tanh.,"Prove that for all real numbers $x\geq 0$ and $y \geq 0$ the following inequalities are true:
  $$\arctan(x+y)\leq\arctan(x)+\arctan(y) \qquad \tanh(x+y)\leq \tanh(x)+\tanh(y)$$ I tried to use both the addition formula and the geometrical approach, but I couldn't find anything leading me to the solution. Any hint/help is appreciated! Thanks in advance.","['real-analysis', 'inequality', 'functions', 'calculus', 'analysis']"
2401125,"Prove that if $ u(x,t) = f(x-ct) + g(x + ct)$ then $u_{tt} = c^2 u_{xx}$","Prove that if $$ u(x,t) = f(x-ct) + g(x + ct)$$ then $$u_{tt} = c^2 u_{xx}$$ My approach: Let $f(x-ct) = f(A)$ and $g(x+ct)=g(B)$ $$ u_t = \frac{\partial u}{\partial t} = \frac{\partial f}{\partial A }\frac{\partial A}{\partial t } + \frac{\partial f }{\partial B } \frac{\partial B }{\partial t } $$ $$ u_{tt} = \frac{\partial }{\partial t} \left(  \frac{\partial u}{\partial t }  \right) = \frac{\partial^2 f }{\partial t \partial A } \cdot \frac{\partial    A}{\partial t } + \frac{\partial f }{\partial A }  \cdot \frac{\partial^2 A }{\partial t^2 }   +  \frac{\partial^2 f}{\partial t \partial B } \cdot \frac{\partial B }{\partial t} + \frac{\partial f }{\partial B } \cdot \frac{\partial^2 B }{\partial B \partial t } $$ Evaluating some partials
$$\frac{\partial A }{\partial t } = -c ,  \frac{\partial^2 A }{\partial t^2} =0, \frac{\partial B }{\partial t } =c , \frac{\partial^2 B }{\partial t^2 } =0$$
hence
$$u_{tt} =\frac{\partial^2 f }{\partial t \partial A } \cdot -c + \frac{\partial^2 f }{\partial t \partial B }\cdot c$$ Using similar approach,
$$ u_{xx} =\frac{\partial^2 f }{\partial x \partial A } + \frac{\partial^2 f }{\partial x \partial B }$$ Is what I did correct? I am stuck at this level. What needs to be done to complete the proof?","['derivatives', 'real-analysis', 'partial-derivative']"
2401137,find $f(\frac{1}{2014})+f(\frac{2}{2014})+.....+f(\frac{2013}{2014})$ of $f(x)=\frac{2}{2+4^x}$,"$f(x)=\frac{2}{2+4^x}$ 
find
$f(\frac{1}{2014})+f(\frac{2}{2014})+.....+f(\frac{2013}{2014})$ Please guide me through it, the only step I know is probably to eliminate the denominator
ps. Not a homework","['functions', 'quadratics']"
2401142,How to calculate $\lim_{\delta \to 0} \frac{x^\delta - 1}{\delta}$ and its derivative with respect to $x$?,"Consider $$ f(x) = \lim_{\delta \to 0} \frac{x^\delta - 1}{\delta} $$ Then, naively,
$$ \frac{df(x)}{dx} = \lim_{\delta \to 0} \frac{\frac{d{x^\delta}}{dx}}{\delta} = \lim_{\delta \to 0} \frac{\delta x^{\delta-1}}{\delta} = \lim_{\delta \to 0} x^{\delta-1} = \frac1{x}$$ what is $f$? And why? Are there any problems with using this?","['derivatives', 'calculus', 'limits']"
2401152,What is the relationship between $f(A)$ and $f(B)$ if $A \subseteq B$ but $A\neq B$?,"Suppose $X$ and $Y$ are sets, that $f : X \to Y$ is a function from $X$ to $Y$ and that $A$ and $B$ are subsets of $X$. Given a subset $C \subseteq X$ let $f(C) = \{y ∈ Y : y = f(c) \text{ for some } c ∈ C\} \subseteq Y$. I have proved that if $A \subseteq B$ then $f(A) \subseteq f(B)$. 
Proof: let $y \in f(A)$. Then there exists $a \in A \subseteq B$ such that $f(a) = y$. Since $a \in B \Rightarrow f(a) \in f(b) \Rightarrow f(A) \subseteq f(B)$. Using this as a guide, I would assume $f(A)$ is can still be $\subseteq$ of $f(B)$ because $A \subseteq B$ can either coincide or not coincide but I'm not too sure.",['elementary-set-theory']
2401166,Calculus of Variation: Trouble finding the Euler-Lagrange equation,"Let $\;f:\mathbb R^n\rightarrow \mathbb R^m\;$ and $\;G:\mathbb R^m
 \rightarrow \mathbb R_{+}\;$ (NOTE: $\;n\;$ is not necessary equal to
  $\;m\;$). Assume the functional: $\;I_{\mathbb R^n} (f) = \int_{\mathbb R^n} \frac{1}{2} {\vert \nabla
 f \vert}^2 + G(f) \;dx\;$ where $\;\nabla f=(\frac{\partial
 f_i}{\partial x_j})_{1\le i \le m,1\le j \le n}\;$ and $\;\vert \cdot
 \vert\;$is the Euclidean norm of the matrix. Prove the Euler-Lagrange equation of the above functional is given by
  the system : $\;\Delta f -G_f(f)=0\;$ where $\;G_f(f)=(\frac{\partial
 G}{\partial f_1}, \dots, \frac{\partial G}{\partial f_m})^{T}\;$ My attempt: I searched on my Evans PDE's book , where I found this: The formula $\;(16)\;$, I believe is the solution to my problem. However I have trouble applying it here because I don't know what exactly is the $\;\frac{1}{2} {\vert \nabla f \vert}^2\;$. I understand that $\;p_i^{k}\;$ from the book stands for $\;\frac{\partial
 f_k}{\partial x_i}\;$ but I'm a bit unsure how this appears in $\;\frac{1}{2} {\vert \nabla f \vert}^2\;$. How can I compute $\;L_{p_i^{k}}\;$ if I don't know what $\;\frac{1}{2} {\vert \nabla f \vert}^2\;$ looks like? I would really appreciate any help because I've been stuck here! Thanks in advance","['euler-lagrange-equation', 'matrices', 'normed-spaces', 'calculus-of-variations', 'ordinary-differential-equations']"
2401167,"Show that for any natural number n between $n^2$ and$(n+1)^2$ there exist 3 distinct natural numbers a, b, c, so that $a^2+b^2$ is divisible by c","Show that for any natural number n ,one can find 3 distinct natural numbers a, b, c, between $n^2$ and$(n+1)^2$, so that $a^2+b^2$ is divisible by c. It's easy to prove that such three distinct numbers exist, by supposing the contrary and coming to contradiction(i.e.""suppose $(n+1)^2-n^2=0$ -->$n=-1$, $-1$ is not a natural number, and so on..""), but how to show divisibility? (The task is from 1998 St. Petersburg City Mathematical Olympiad)","['number-theory', 'divisibility', 'gcd-and-lcm', 'elementary-number-theory']"
2401172,"Suppose $A$, $B$, and $C$ are sets. Prove that $A △ B ⊆ C \iff A ∪ C = B ∪ C$.","This is Velleman's exercise 3.5.20 ( And NO, not a duplicate of "" Suppose $A,B,C$ are sets. Prove that $A\mathbin\triangle B\subseteq C \iff A\cup C=B\cup C$. "" or "" Prove that $A∆B⊆C$ iff$ A∪C=B∪C$ "", my question is different ): Suppose $A$, $B$, and $C$ are sets. Prove that $A\,\triangle\,B \subseteq C \iff A \cup C = B \cup C$. Here's my proof of it: Proof. ($\rightarrow$) Suppose $A △ B ⊆ C$. Let $x$ be an arbitrary element of $A ∪ C$, which means either $x ∈ A$ or $x ∈ C$. If $x ∈ B$, then clearly $x ∈ B ∪ C$. If $x ∉ B$, then since  $x ∈ A$, we have $x ∈ A\setminus B$ and therefore $x ∈ A △ B$. From $A △ B ⊆ C$ and $x ∈ A △ B$, we get $x ∈ C$. From the two cases we have $x ∈ B ∪ C$ and since $x$ was arbitrary, $x ∈ A ∪ C \Rightarrow x ∈ B ∪ C$. Now let $x$ be an arbitrary element of $B ∪ C$, which means either $x ∈ B$ or $x ∈ C$. If $x ∈ A$, then clearly $x ∈ A ∪ C$. If $x ∉ A$, then since  $x ∈ B$, we have $x ∈ B\setminus A$ and therefore $x ∈ A △ B$. From $A △ B ⊆ C$ and $x ∈ A △ B$, we get $x ∈ C$. From the two cases we have $x ∈ A ∪ C$ and since $x$ was arbitrary, $x ∈ A ∪ C \Leftarrow x ∈ B ∪ C$. From $x ∈ A ∪ C \Rightarrow x ∈ B ∪ C$ and $x ∈ A ∪ C \Leftarrow x ∈ B ∪ C$, we get $x ∈ A ∪ C \iff x ∈ B ∪ C$ and therefore $A ∪ C = B ∪ C$. Thus, $A △ B ⊆ C \Rightarrow A ∪ C = B ∪ C$. ($\leftarrow$) Suppose $A ∪ C = B ∪ C$. Let $x$ be an arbitrary element of $A △ B$. Now we can consider two different cases: Case 1. $x ∈ A\setminus B$, which means $x ∈ A$ but $x ∉ B$. From $x ∈ A$ and $x ∈ A ∪ C$, we get $x ∈ B ∪ C$. But since we saw that $x ∉ B$, thus $x ∈ C$. Case 2. $x ∈ B\setminus A$, which means $x ∈ B$ but $x ∉ A$. From $x ∈ B$ and $x ∈ B ∪ C$, we get $x ∈ A ∪ C$. But since we saw that $x ∉ A$, thus $x ∈ C$. Since from both cases we get $x ∈ C$ and since $x$ was arbitrary, then $x ∈ A △ B ⊆ C$ and therefore $A ∪ C = B ∪ C \Rightarrow A △ B ⊆ C$. From ($\rightarrow$) and ($\leftarrow$), we get $A △ B ⊆ C \iff A ∪ C = B ∪ C$.$\square$ Now here is my question: Is my proof valid? Particularly the first part (i.e. ($\rightarrow$)): in the first part, in the goal (i.e. the statement that we wanted to prove) there was a conjunction which I kind of ignored it and proved ""$x ∈ A ∪ C \Rightarrow x ∈ B ∪ C$"" and ""$x ∈ A ∪ C \Leftarrow x ∈ B ∪ C$"" separately! Is that correct? Thanks in advance.","['logic', 'elementary-set-theory', 'proof-verification']"
2401193,How to separate this ODE?,Find the general solution to the first-order differential equation $$(4-x^2)\frac{dy}{dx}+y=0$$ I'm painfully stuck on this ODE with no clear idea on how to approach solving it. The method I tried was wrong due to algebraic mishaps. Can someone please give me an idea on how to break this up so I can solve?,"['multivariable-calculus', 'integration', 'ordinary-differential-equations', 'calculus']"
2401241,Verifying the interpretation of stopping times and stopping time $\sigma$-algebras,"I have been thinking about the intuition of stopping times and stopping time $\sigma$-algebras. While I feel more or less comfortable with the former notion, I would like to get more insight in the latter. Having read different intuitive explanations, I tried to come up with the following interpretations which I would like to be verified. Let $\mathbb{F} = {(\mathcal{F}_n)}_{n \in \mathbb{N}_0}$ be a filtration in $(\Omega, \mathcal{F})$. A random variable $\tau : \Omega \rightarrow \mathbb{N}_0 \cup \{ \infty \}$ is called a stopping time if
$\{ \tau \leq n \} \in \mathcal{F}_n$ for all $n \in \mathbb{N}_0$. It can easily be shown that $\{ \tau \leq n \} \in \mathcal{F}_n \quad \forall n \in \mathbb{N}_0 \iff \{ \tau = n \} \in \mathcal{F}_n \quad \forall n \in \mathbb{N}_0$. Interpretation I have come up with: The relation $\{ \tau \leq n \}\in \mathcal{F}_n$ means that all the elementary events $\omega$ in the case of which I stop before time $n$ or at $n$ comprise an event in $\mathcal{F}_n$. This means, in particular, that at time $n$, having observed the current event I am at, I know precisely whether I have or whether I have not stopped before time $n$ or at $n$. For example, suppose that at time $n$ I am on some event $A \in \mathcal{F}_n$. Two mutually exclusive cases are possible: $A \cap \{ \tau \leq n \} = \emptyset\in \mathcal{F}_t$, so the decision to stop before time $t$ or at $t$ has not been made. $A \cap \{ \tau \leq n \} \neq \emptyset$.  Additionally, $A \cap \{ \tau \leq n \} \in \mathcal{F}_n$ so  $A \cap \{ \tau \leq n \}$ is also an event which I can distinguish at time $n$. So depending on whether I am on $A \cap \{ \tau \leq n \}$ or on $(A \setminus A \cap \{ \tau \leq n \})$, I can tell whether I have or whether I have not stopped before time $n$ or at $n$. A similar interpretation and example can be given for the relation $\{ \tau = n \} \in \mathcal{F}_n$. Now consider the stopping time $\sigma$-algebra:
$$
\mathcal{F}_{\tau} := \{ A \in \mathcal{F}: A \cap \{ \tau \leq n\} \in \mathcal{F}_n \quad \forall n \in \mathbb{N}_0\}
$$
It can indeed be verified that the above family is a $\sigma$-algebra and that $$A \in \mathcal{F}_{\tau} \iff A \cap \{ \tau = n\} \in \mathcal{F}_n \quad \forall n \in \mathbb{N}_0.$$ In literature, usually, $\mathcal{F}_{\tau}$ is described as the $\sigma$-algebra of the events observed up to the stopping the $\tau$, in analogy to $\mathcal{F}_n$, which represents the events observable up to time n. Interpretation I have come up with: Suppose that at some arbitrary but fixed time $n$ the event  $\{ \tau \leq n \} \in \mathcal{F}_{n}$ has occurred which means that there has been a decision to stop before time $n$ or at $n$. Then for every $A \in \mathcal{F}_{\tau}$ I can tell whether $A$ has occurred or not depending on whether I am at the event $A \cap \{ \tau \leq n\} \in \mathcal{F}_{n}$ or not. So the events in $\mathcal{F}_{\tau}$ are those for which I can tell whether they have occurred or not provided that the event $\{\tau \leq n \}$ for some $n \in \mathbb{N}_0$ has occurred (i.e. there has been a decision to stop). Conversely, take any $A \in \mathcal{F}_{\tau}$ and arbitrary but fixed time $n$. Further assume that event $A$ has occured at time t, in the sense that some $B \in \mathcal{F}_n$ has occured with $B \subset A$. So I can tell whether I have or whether I have not stopped before time $n$ or at $n$ depending on whether the event $B \cap (A \cap \{ \tau \leq n \}) \in \mathcal{F}_n$ has occurred or not.
(However I think this second point is irrelevant since at every time $n$ I know whether the event $\{\tau \leq n\} \in \mathcal{F}_n$ has occurred or not.) I feel more or less assured regarding the first interpretation for the stopping time however I am unsure of the interpretation for the $\sigma$-algebra, namely, whether it actually corresponds to the description stated earlier: $\mathcal{F}_{\tau}$ is the $\sigma$-algebra of the
  events observed up to the stopping time $\tau$. So here are my questions: Do you agree with the two interpretations? Can you add something to make them better (especially to that of the $\sigma$-algebra)? Can you come up with different interpretations?","['stochastic-processes', 'probability-theory', 'stochastic-calculus', 'stopping-times']"
2401254,Surface Area of a Lemon,"I'm a high school senior doing the AP Calc course, and recently I studied surface area of revolutions. As background research for a class project, I tried to look for things found in nature that roughly involve revolutions, and shortlisted eggs and lemons. But eggs were already analysed, and lemons seemed more challenging. So now I'm trying to find an approximation for the surface area of a lemon. From research, I've found that a lemon takes the approximate shape of a prolate spheroid. This is what that shape looks like: I know that the equation for the surface area of revolution is: $S = 2\pi\int_a^b f(x)\sqrt{1+\left(\frac{dy}{dx}\right)^2} \,dx$ I can try finding the side profile of a lemon, model it into a function, and then apply the equation above from 0 to pi. However, this doesn't look like the best way to me, because I'm not sure how to find an equation to describe a lemon's shape. Plus, the lemons in different countries, such as India, are of a different shape. I'm looking for a different way to model the equation describing a lemon's cross-sectional shape. My knowledge about elliptic integrals is limited, but I'm willing to do research to find a way which involves mathematics beyond my high-school level. [Update] After research, I realized rather than going for an ellipse rotated around the axis, I could go for a lens shape too. A bulbous lens might approximate the ends of the lemon too.","['solid-geometry', 'solid-of-revolution', 'surfaces', 'geometry']"
2401268,"The definition of ""entire function""","I am reading about the definition of ""entire functions"" :
""If a complex function is analytic at all finite points of the complex plane $\mathbb{C}$, then it is said to be entire ..."" In fact, I'd like to understand this definition. Thus I wish a help to respond my questions. Are all analytic functions on $\mathbb{C}$ entire? Why do we need to use this definition? Thank you very much for all of your answers!","['functional-analysis', 'complex-analysis', 'analytic-number-theory']"
2401270,Reference request: Geometric Limit,"In this video , prof. J.Morgan explains the idea of what he calls ""Geometric Limit"". He says that it is a notion of convergence stronger than that of the Gromov-Hausdorff distance. Can someone give me a reference (such as a book) where this geometric limit is dealt with in detail? Moreover, can someone give me an insight as to in which way this limit is related to the Gromov-Hausdorff one, and as to what the fact that the latter is weaker entails (I just need the idea, not necessarily a proof)?","['manifolds', 'reference-request', 'differential-geometry']"
2401281,"Show that if $a+b+c=0$, $2(a^4 + b^4+ c^4)$ is a perfect square [duplicate]","This question already has answers here : Show that $a+b+c=0$ implies that $32(a^4+b^4+c^4)$ is a perfect square. (3 answers) Closed 6 years ago . Show that for $\{a,b,c\}\subset\Bbb Z$ if $a+b+c=0$ then $2(a^4 + b^4+ c^4)$ is a perfect square. This question is from a math olympiad contest. I started developing the expression $(a^2+b^2+c^2)^2=a^4+b^4+c^4+2a^2b^2+2a^2c^2+2b^2c^2$ but was not able to find any useful direction after that. Note : After getting 6 answers here, another user pointed out other question in the site with similar but not identical content (see above), but the 7 answers presented include more comprehensive approaches to similar problems (e.g. newton identities and other methods) that I found more useful, as compared with the 3 answers provided to the other question.","['algebra-precalculus', 'contest-math', 'polynomials', 'elementary-number-theory']"
2401293,Exercise on convergence of sequences of functions,"Let $f: \mathbb{R} \to \mathbb{R}$ be a function. For every $n \in \mathbb{N}_{0}$, define the function $f_{n}: \mathbb{R} \to \mathbb{R}: x \mapsto f(x+\frac{1}{n})$.
Now, I have to examine if the following statements are true or false: a) If $f$ is continuous, then $(f_{n})_{n}$ converges pointwise on $\mathbb{R}$ to $f$. b) If  $f$ is uniformly continuous, then $(f_{n})_{n}$ converges uniformly on $\mathbb{R}$ to $f$. I think that the first statement is true and I also think that I got a proof for it. I also think that the second statement is true but I have some doubts about it, is there someone that can help me?","['real-analysis', 'convergence-divergence', 'functions']"
2401299,Compute the determinant,"The following problem is taken from here exercise $2:$ Question: Evaluate the determinant: 
  \begin{vmatrix}
0 & x & x & \dots & x \\
y & 0 & x & \dots & x \\
y & y & 0 & \dots & x \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
y & y & y & \dots & 0
\end{vmatrix} My attempt: I tried to use first row substract second row to obtain 
\begin{pmatrix}
y & -x & 0 \dots & 0
\end{pmatrix}
and also first row subtracts remaining rows. 
However, I have no idea how to proceed.","['matrices', 'contest-math', 'linear-algebra', 'determinant']"
2401340,On a differentiable extension of a function.,"Let $G\subseteq \mathbb{R}^n$ be an open set and $f:G\to \mathbb{R}$ a differentiable function at each point of $G.$ Does there exists a differentiable function $\hat{f}:\mathbb{R}^n\to \mathbb{R}$ such that $\hat{f}|_G= f,$ i.e, a differentiable extension of $f$ to all of $\mathbb{R}^n?$ What about if we replace 'differentiable' by 'continuously differentiable' above? In case both answers are negative, under what conditions can I guarantee some statement like that?","['real-analysis', 'partial-differential-equations', 'functional-analysis', 'complex-analysis', 'multivariable-calculus']"
2401341,$\sin(40^\circ)<\sqrt{\frac{3}7}$,"Prove without using of calculator, that $\sin40^\circ<\sqrt{\frac{3}7}$. My attempt. Since $$\sin(40^\circ)=2\sin(20^\circ)\cos(20^\circ)<2\sin(20^\circ)$$ $$=2\sin(60^\circ-40^\circ)=\sqrt{3} \cos(40^\circ)-\sin(40^\circ),$$ $$2\sin(40^\circ)<\sqrt{3} \cos(40^\circ).$$ Hence, $$4\sin^2(40^\circ)<3\cos^2(40^\circ)=3(1-\sin^2(40^\circ))$$ $$7\sin^2(40^\circ)<3$$ $$\sin(40^\circ)<\sqrt{\frac{3}7}$$ Is there another way to prove this inequality?","['derivatives', 'inequality', 'number-comparison', 'trigonometry', 'fractions']"
2401356,How many solutions does the equation $n_1 + n_2 + n_3 + n_4 + n_5 = 20$ have in the positive integers if $n_1 < n_2 < n_3 < n_4 < n_5$?,"Let $n_1 < n_2 < n_3 < n_4 < n_5$ be positive integers such that $n_1 + n_2 + n_3 + n_4 + n_5 = 20$. Then the number of such distinct arrangements $(n_1, n_2, n_3, n_4, n_5)$ is......
I have no idea how to proceed. Manually, I have done it
$$1+2+3+4+10$$
$$1+2+3+5+9$$
$$1+2+3+6+8$$
$$1+2+4+5+8$$
$$1+2+4+6+7$$
$$1+3+4+5+7$$
$$2+3+4+5+6$$
But is there any way I can do it by Permutation and Combination method?",['combinatorics']
2401390,Prove that $2\left(\frac{6}{e}\right)^e>17$,"I was doing some exercises in my calculus textbook and to finish one, I need to prove that
$$2\left(\frac{6}{e}\right)^e>17.$$
This is supposed to be simple (,,easy to notice'', the textbook says). However, I cannot figure it out withour a calculator (17.2 is about the exact value of the left hand side). My only idea was to use Bernoulli inequality:
$$2\left(\frac{6}{e}\right)^e=2\left(1+\left(\frac{6}{e}-1\right)\right)^e\ge 2\left(1+e\left(\frac{6}{e}-1\right)\right)=2(7-e)=14-2e$$
but this is to weak. Could anybody give me some hints?","['inequality', 'calculus']"
2401397,integral definition: Durrett's vs Rudin's,"I'm a little uncertain about the definition of integral of measurable functions.  First I read W. Rudin's book ( PMA ), where integration was defined in 3 steps: (1) integrals of simple functions, (2) integrals of non-negative functions, and then (3) integrals of measurable functions.  Specifically, (2): $\int_E fd\mu\triangleq \sup \int_E sd\mu,$ where $f\ge 0,$ and $s$ are simple functions with $s\le f.$ (3): $\int_E fd\mu\triangleq \int_E f^+d\mu-\int_E f^-d\mu,$ where $f^+\triangleq \max(f,0),$ and $f^-\triangleq \max(-f, 0).$ Then I read R. Durrett's book ( Probability: Theory and Examples ).  The definition was almost the same, except for one difference: Durrett defined the integral of a bounded function, and then he defined the integral of non-negative functions (The rest are the same.), i.e. Let $f$ be a bounded function on $E$, with $\mu(E)<\infty.$  Then, $\int_E fd\mu\triangleq \sup \int_E sd\mu$, where $s\le f$ are simple functions. Let $f\ge 0$.  Then, $\int fd\mu\triangleq\sup \int hd\mu$, where $h$ is bounded, with $\mu(\{x:h(x)>0\})<\infty$, and $0\le h\le f.$ I have 2 questions: 1) Are these 2 definitions equivalent? 2) Rudin's definition appears simpler to me.  Why do we bother with Durrett's definition, defining integral of bounded functions and then the integral of non-negative functions?  Are there advantages in doing so? Thanks a lot!","['probability-theory', 'measure-theory']"
2401425,"If $|z|=1$, $z\neq-1$, show that $z$ may be expressed in the form $ z=\frac{1+it}{1-it}$ where $t\in \mathbb{R}$.","If $|z|=1$, $z\neq-1$, show that $z$ may be expressed in the form $$ z=\frac{1+it}{1-it},$$ where $t\in \mathbb{R}$. I don't know, how to begin. I started with the given conditions. Given that $|z|=1 \text{ and } z\neq-1\implies z=e^{it}, t\in[0,2\pi]/\{\pi\}.$","['complex-analysis', 'complex-numbers']"
2401428,Road Shape for Square Wheels,"Let's say you have a bike with square wheels of side a. In order for a smooth ride, there must be these bumps in the road. Is there a formula for the area of each bump using a?","['graphing-functions', 'area', 'geometry']"
2401434,"Suppose $A$, $B$, and $C$ are sets. Prove that $C ⊆ A △ B$ iff $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$.","This is Velleman's exercise 3.5.21 ( And NO, not a duplicate of "" Suppose $A, B$, and C are sets. Prove that $C\subset A\Delta B \Leftrightarrow C \subset A \cup B$ and $A \cap B \cap C = \emptyset $ "", my question is different ): Suppose $A$, $B$, and $C$ are sets. Prove that $C \subseteq A\,\triangle\,B$ iff $C \subseteq A \cup B$
and $A \cap B \cap C = \emptyset$. And here's my proof of it: Proof. ($\rightarrow$) Suppose $C ⊆ A △ B$ and let $x$ be an arbitrary element of $C$, then we have  $x ∈ A △ B$. We now consider two cases: Case 1. $x ∈ A\setminus B$, which means $x ∈ A$ but $x ∉ B$. Thus $x ∈ A ∪ B$. Case 2. $x ∈ B\setminus A$, which means $x ∈ B$ but $x ∉ A$. Thus $x ∈ A ∪ B$. Now suppose $A ∩ B ∩ C \neq ∅$. From $x ∈ A △ B$ we have that either $x ∉ A$ or $x ∉ B$ which in either case is a contradiction and hence $A ∩ B ∩ C = ∅$. We have $x ∈ A ∪ B$ and $A ∩ B ∩ C = ∅$ and therefore, if $C ⊆ A △ B$, then $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$. ($\leftarrow$) Suppose $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$ and let $x$ be an arbitrary element of $C$. We now have two different cases to consider: Case 1. $x ∈ B\setminus A$, then clearly $x ∈ A △ B$. Case 2. $x ∉ B\setminus A$, which means $x ∈ A$ but $x ∉ B$. Since $A ∩ B ∩ C = ∅$ is equivalent to $∀x(x ∈ A \Rightarrow (x ∈ C \Rightarrow x ∉ B))$, then by $x ∈ A$ we have $(x ∈ C \Rightarrow x ∉ B)$. Since we had $x ∈ C$, then $x ∉ B$ and then $x ∈ A\setminus B$. Ergo $x ∈ A △ B$. From both case we have $x ∈ A △ B$. Since $x$ was arbitrary, $C ⊆ A △ B$ and therefore, if $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$, then $C ⊆ A △ B$. By ($\rightarrow$) and ($\leftarrow$) we have $C ⊆ A △ B$ iff $C ⊆ A ∪ B$
and $A ∩ B ∩ C = ∅$. Now here are my questions: Is my proof valid? In part one (i.e. ($\rightarrow$)), is there anything wrong with the proof of $A ∩ B ∩ C = ∅$? In part two (i.e. ($\leftarrow$)), the second case seems to be a little redundant to me! Is that correct (i.e. is my proof of it correct)? Thanks in advance.","['logic', 'elementary-set-theory', 'proof-verification']"
2401454,Does Measurablity of Cuts imply Measurability in Product Space?,"Thinking about some problem I arrived at the following question: Let $\Omega \neq \emptyset$ a set and $\Sigma$ a $\sigma$-algebra on $\Omega$. Consider the product space $\Omega \times \Omega$ with the product $\sigma$-algebra $\Sigma \otimes \Sigma$. Now it is a well known fact that if $M \in \Sigma \otimes \Sigma$ then the cuts satisfy
$$M_x = \lbrace y \in \Omega \mid (x, y) \in M\rbrace \in \Sigma, \quad M_y = \lbrace x \in \Omega \mid (x, y) \in M\rbrace \in \Sigma,$$
i.e. are measurable. Now I got interested in the converse: Assuming we have $M_x = \lbrace y \in \Omega \mid (x, y) \in M\rbrace \in \Sigma$ for all $x \in \Omega$ and $M_y = \lbrace x \in \Omega \mid (x, y) \in M\rbrace \in \Sigma$ for all $y \in \Omega$, can we deduce that $M \in \Sigma \otimes \Sigma$? I couldn't see a quick argument and I feel like it doesn't suffice. On the other hand I couldn't think of a counter example to this question.","['real-analysis', 'examples-counterexamples', 'measure-theory']"
2401476,Number of natural numbers less than million with sum of the digits equal to $12$,Number of natural numbers less than million with sum of the digits equal to $12$ My Try: obviously we need 6 places to filled with digits $0$ to $9$ such that sum of the digits is $12$ so the required number is number of non negative integral solutions of $$x_1+x_2+x_3+x_4+x_5+x_6=12$$ which is nothing but $\binom{17}{5}$ Is this correct approach?,"['permutations', 'combinatorics', 'binomial-coefficients', 'systems-of-equations']"
2401510,Find the area of the shaded region of this figure,Find the area of the shaded region. (Each arcs of circles in the figure are assumed to be $\frac{1}{4}$ of a full circle),['geometry']
2401515,Differential Equation : $\frac{dy}{dx} -2xy = e^{x^2}$,"My study buddy and I are getting different answers for this one. Here is the equation:
$\frac{dy}{dx} -2xy = e^{x^2}$ And my solution $P(x) = -2x  
\implies   I(x)= e^{-x^2}$ $I(x)*\frac{dy}{dx} - 2xyI(x) = e^{x^2}  I(x)$ $e^{-x^2}\frac{dy}{dx} - 2xye^{-x^2}$ = $e^{x^2}e^{-x^2}$ $\frac {d(-2yx)}{dx}=e^{x^2}e^{-x^2}$ Since $e^{x^2} * e^{-x^2} = e^{0} = 1$ Therefore, $-2yx = 1 + c$ If I'm doing something wrong, please show me! Thanks!",['ordinary-differential-equations']
2401536,What is the expected number of tyres that are installed in their original positions?,"After summer, the winter tyres of a car (with four wheels) are to be put back. However, the owner has forgotten which tyre goes to which wheel, and the tyres are
installed `randomly', each of the $4! = 24$ permutations being equally likely. What is the expected number of tyres that are installed in their
  original positions? Expected no. of tyres installed in original position = $P(1\ \text{tyre}) + 2P(2\ \text{tyre}) + 3P(3\ \text{tyre}) + 4P(4\ \text{tyre})$ I'm stuck after that. When counting $P(1\ \text{tyre})$ am I allowed to take the combination that all 4 tyres are in their right position ? Because that also includes 1 tyre in its original position... If yes then $P(1\ \text{tyre}) = 13/24$ Or must I find the probability that exactly 1 tyre is in the original position ? If so, then what is the probability that 3 tyres are in their original position ? Because having 3 tyres in the original position would mean the 4th tyre must be in the original position ?","['combinatorics', 'probability']"
2401546,Density of $\mathbb{Q}$ in $\mathbb{R}$ and countability,"I don't understand why the density of $\mathbb{Q}$ in $\mathbb{R}$ does not contradict the fact that $\mathbb{Q}$ is countable and $\mathbb{R}$ is not. There is always a rational number $r$ between two irrational $i,j$ numbers, why does this not imply that there are as many rationals as irrationals? I mean we could just take for every irrational $i$ the nearest greater rational $r$ and count it this way? By choosing the nearest greater rational, we have a condition that there is only one rational for one irrational. I don't understand why this does not contradict fact that $\mathbb{R}$ is uncountable. Is there a good intuitive explanation why we can not? (Please not just a proof why $\mathbb{R}$ is uncountable and $\mathbb{Q}$ is countable)","['elementary-set-theory', 'real-analysis', 'calculus']"
2401554,Proving $f(\lVert x\rVert)$ is differentiable in $\Bbb R^n$,"Let $f: \Bbb R \to \Bbb R$ be an even, differentiable function, 
and let $F: \Bbb R^n \to \Bbb R$ be defined as follows: $F(x) = f(\lVert x\rVert)$
,when $\lVert x\rVert = \sqrt{\sum_{i=1}^n x_i^2}$ . Prove that $F$ is differentiable in $\Bbb R^n$. What I tried: It's pretty easy to see that $F$ is differentiable in every $x \neq 0$. For $x = 0$ I got for the partial derivative of $x_1$: $\frac{\partial F}{\partial x_1}=\lim_{h\to 0} \frac{F(h,...0)-F(0,..,0)}{h} = 
\lim_{h\to 0} \frac{f(|h|)-f(0)}{h}$ = $f'(0)$ When the last equality follows since $f$ is even. Next I want to show that  $\frac{\partial F}{\partial x_1}$ is continuous in $0$, and then finish, but I couldn't prove it. **Edit: since $f$ is even and differentiable, we also have $f'(0) = 0$. Still having trouble finishing the proof.","['multivariable-calculus', 'normed-spaces', 'derivatives']"
2401574,Prove: if $n-5$ is odd then $3n+2$ is even (make a true table on the statement that shows that is always true),"This problem consist in two parts. first: prove the statement. Second: create a true table showing that the statement is always true ($n-5$ is odd if and only if $3n+2$ is even). This is my reasoning for both parts, and I will be grateful for your insights. Part 1: If $n-5$ is odd, then $n-5=2k+1$ for some integer $k$, and $3(n-5)=3(2k+1)$ $3n-15=6k+3$ $3n-15+17=6k+3+17$ $3n+2=6k+20=2(3k+10)$ Proving that $3n+2=2m$ is even for some integer $m=3k+10$ Part 2: I really don´t know how to show that. Should I use $n-5$ is odd as $P$ and $3n+2$ as $Q$? Because that's the normal table for $P\leftrightarrow Q$ and doesn't show that it's always true. Thanks in advance for your help.","['logic', 'discrete-mathematics']"
2401589,Monotonicity with Euclidean distance,"We have a curve $y=f(x)>0$ and a moving point along the $x$ axis. For every position of the point, we find the nearest point on the curve, let $(x',f(x'))$, in the sense of the Euclidean distance. Can we show that $x'$ is a monotonic (possibly discontinuous) function of $x$ ?","['monotone-functions', 'functions', 'graphing-functions']"
2401604,Suppose $X$ is a finite set and $f : X \to X$ is a function. Then $f$ is injective if and only if $f$ is surjective.,"Suppose $X$ is a set and $f : X \to X$ is a function.  If $X$ is a finite set, prove that $f$ is injective if and only if $f$ is surjective.
Show that when $X$ is an infinite set, the statement is not true in general. For that, let $X = \mathbb{R}$ and find a function $f: \mathbb{R} \to \mathbb{R}$ which is injective but not surjective, and a function $g: \mathbb{R} \to \mathbb{R}$ which is surjective but not injective My attempt at the first part Suppose that the function is surjective but not injective. Let $a,b \in X$ such that $f(a)=f(b)$ but $a \not =b$. Now since this is a finite set mapping to itself then there are not enough elements in $X$ to map to $X$ since two elements were used to map to one element, thus the function can't be surjective. Therefore if the function is surjective it is also injective. Now suppose that the function is injective but not surjective. Let $a \in X$ such that $f(b)\not =a$ for all $b \in X$. Since the function was assusmed to be injective each $a \in X$ must map to an element of $X$, thus must have two elemetns in $X$ mapping to the same element in $X$. Hence the function can't be injective, therefore if the function is injective it must be surjective. Would an exponetial function work for injective but not surjective since can't map to negative numbers. And an example of a function that is surjective but not injective could be a log function since none of the negative numbers get mapped to anything? Also I'm having trouble seeing why it has to be finite for the first part to work. I understand it has something to do with the pigeonhole principle but its not that clear to me.","['functions', 'proof-verification']"
2401619,Geometry of rational functions,"Scott Carnahan writes at https://sbseminar.wordpress.com/2007/08/21/p-adic-fields-for-beginners/ that ""One might ask if there are natural extensions of $\Omega_p$ that don’t add geometry (e.g., taking rational functions shouldn’t count)."". In what sense taking rational functions adds geometry to a field? For example, what is the difference between $\mathbb Q$ and $\mathbb Q(x)$ from the geometrical point of view?","['field-theory', 'soft-question', 'geometry']"
2401634,"Characterization of weak convergence in $W^{1, p}(\Omega)$","I have to prove that, given $\Omega\subset\mathbb{R}^n$ an open subset, $1\leq p<\infty$ and $\{u_n\}\subset W^{1, p}(\Omega)$, we have $u_n\rightharpoonup u$ in $W^{1, p}(\Omega)$ if and only if $u_n\rightharpoonup u$ in $L^p(\Omega)$ and $Du_n\rightharpoonup Du$ in $L^p(\Omega, \mathbb{R}^n)$. The hint of the exercise is to consider the map 
$$
T:W^{1, p}(\Omega)\longrightarrow L^p(\Omega)\times L^p(\Omega, \mathbb{R}^n)
$$
and prove that it is an isometry. So, my attempt is: by giving $W^{1,p}(\Omega)$ the norm
$$
\|u\|_{W^{1, p}(\Omega)}=\left(\|u\|_{L^p(\Omega)}^p+\sum_{i=1}^n\left\|\frac{\partial u}{\partial x_i}\right\|_{L^p(\Omega)}^p\right)^{\frac{1}{p}}
$$
and by giving $L^p(\Omega)\times L^p(\Omega, \mathbb{R}^n)$ the norm
$$
(u, v) = \left(\|u\|^p_{L^p(\Omega)}+\sum_{i=1}^n\|v_i\|^p_{L^p(\Omega)}\right)^{\frac{1}{p}},
$$
the application $T$ is an isometry (right?). But now, how can I conclude that the equivalence of the assertions follows? The definition of weak convergence in $W^{1, p}(\Omega)$ is that $u_n\rightharpoonup u$ in $W^{1, p}(\Omega)$ if and only if $L(u_n)\longrightarrow L(u)$ for all $L\in (W^{1, p}(\Omega))'$. By the Riesz Representation Theorem on $W^{1, p}(\Omega)$ I know that there exist $f_0,\ldots,f_n\in L^{p'}(\Omega)$ such that, for every $L\in (W^{1, p}(\Omega))'$,
$$
L(u)=\int_{\Omega}\left(f_0(x)u(x)+\sum_{i=1}^nf_i(x)\frac{\partial u}{\partial x_i}(x)\right)\ dx
$$
for all $u\in W^{1, p}(\Omega)$ and
$$
\|L\|_{(W^{1, p}(\Omega))'}=\left(\sum_{i=0}^n\|f_i\|_{L^{p'}(\Omega)}^{p'}\right)^{\frac{1}{p'}}.
$$
Thank you","['functional-analysis', 'lp-spaces', 'weak-convergence', 'sobolev-spaces']"
2401702,"Suppose $A$, $B$, and $C$ are sets. Prove that $A △ C ⊆ (A △ B) ∪ (B △ C)$.","This is Velleman's exercise 3.5.22.b: Suppose $A$, $B$, and $C$ are sets. Prove that $A △ C ⊆ (A △ B) ∪ (B △ C)$. Here's my proof of it: First I prove ""Theorem $\alpha$"" which states that for sets $A$, $B$, and $C$, $A \setminus C ⊆ (A \setminus B) ∪ (B \setminus C)$. Proof of ""Theorem $\alpha$"": Proof. Suppose $x ∈ A\setminus C$, which means $x ∈ A$ but $x ∉ C$. Now we consider two different cases: Case 1. $x ∈ B$. Then since $x ∉ C$, $x ∈ B\setminus C$ and ergo $x ∈ (A \setminus B) ∪ (B \setminus C)$. Case 2. $x ∉ B$. Then since $x ∈ A$, $x ∈ A\setminus B$ and ergo $x ∈ (A \setminus B) ∪ (B \setminus C)$. Since from both cases we have $x ∈ (A \setminus B) ∪ (B \setminus C)$, therefore $x ∈ A\setminus C \Rightarrow x ∈ (A \setminus B) ∪ (B \setminus C)$, which means $A △ C ⊆ (A △ B) ∪ (B △ C)$. And now the proof of the original statement: Proof. Suppose $x ∈ A △ C$, which means either $x ∈ A \setminus C$ or $x ∈ C \setminus A$ and hence we consider two different cases: Case 1. $x ∈ A \setminus C$. Thus by ""Theorem $\alpha$"" we have either $x ∈ A \setminus B$ or $x ∈ B \setminus C$. Subcase 1. $x ∈ A \setminus B$, from which we get $x ∈ A △ B$ and from which we'll have $x ∈ (A △ B) ∪ (B △ C)$. Subcase 2. $x ∈ B \setminus C$, from which we get $x ∈ B △ C$ and from which we'll have $x ∈ (A △ B) ∪ (B △ C)$. Case 2. $x ∈ C \setminus A$. Thus by ""Theorem $\alpha$"" we have either $x ∈ B \setminus A$ or $x ∈ C \setminus B$. Subcase 1. $x ∈ B \setminus A$, from which we get $x ∈ A △ B$ and from which we'll have $x ∈ (A △ B) ∪ (B △ C)$. Subcase 2. $x ∈ C \setminus B$, from which we get $x ∈ B △ C$ and from which we'll have $x ∈ (A △ B) ∪ (B △ C)$. From both cases we have $x ∈ A △ C \Rightarrow x ∈ (A △ B) ∪ (B △ C)$ which is equivalent to $A △ C ⊆ (A △ B) ∪ (B △ C)$. Is my proof correct? Could have I done it in any easier way? Thanks in advance.","['alternative-proof', 'logic', 'elementary-set-theory', 'proof-verification']"
2401742,"Is there any particular way to approach ""finding an example"" questions in elementary set theory?","How should one approach answering questions like: ""Find an example of sets [a different number of sets] such that [some statement involving those sets]."" Guess and trial based on your intuition of the whole statement is the only way? If so, what about more complex statements? So I'll give you an example: Find an example of sets $A$, $B$, and $C$ such that $(A ∪ B) △ C \neq (A △ C) ∪ (B △ C)$. What's your way of solving this problem (except for guessing, if there's any that I'm missing)? One short note: If you're considering that my question is too general then please only answer the example above and the way that you approached to solve it (if possible). Thanks in advance.","['problem-solving', 'elementary-set-theory']"
2401746,Is there a closed form for $\sum_{n=0}^{\infty}{2^{n+1}\over {2n \choose n}}\cdot\left({2n-1\over 2n+1}\right)^2?$,"We have $$\sum_{n=0}^{\infty}{2^{n+1}\over {2n \choose n}}\cdot{2n-1\over 2n+1}=4-\pi\tag1$$ I would like to know if there exist a closed form for $$\sum_{n=0}^{\infty}{2^{n+1}\over {2n \choose n}}\cdot\left({2n-1\over 2n+1}\right)^2 =\,??\tag2$$ I was able to roughly estimate it as $\approx\sqrt{8+2\pi}$ but it is not the closed form. How can we find the closd form for $(2)?$","['binomial-coefficients', 'sequences-and-series', 'closed-form']"
2401761,"Compute $\int_0^{\pi /2}\frac x {\tan x} \, dx$ using contour integration","How can I calculate the integral $$\int_0^{\pi /2}\frac x {\tan x} \, dx$$ with complex integration? (Contours, residue theorem, etc.) I was thinking on using the fact that $\displaystyle \tan x=\frac{e^{ix}-e^{-ix}}{i(e^{ix}+e^{-ix})}$, which implies $e^{ix}=z$. I still have not been succesful.","['residue-calculus', 'complex-analysis', 'integration', 'definite-integrals', 'contour-integration']"
2401777,Stabilizer of a Group Action,"I am trying to solve the following problem. Let $p$ me a prime and $L$ a linear map from $\mathbb{F}_p^n$ to $\mathbb{F}_p^n$. Suppose that there exist $k\geqslant 0$ such that $L^{p^k}=1$ where $1$ means the identity map from $\mathbb{F}_p^n$ to $\mathbb{F}_p^n$. Prove that there exist a non-zero vector $v$ such that $L(v)=v$. I am trying to solve this in the context of group actions. Since $L^{p^k}=1$ the group generated by $L$ is cyclic of order $p^k,$ let's call it $G$. We define $\cdot: G \times \mathbb{F}_p^n \to \mathbb{F}_p^n$ by setting $L^m\cdot v = L^m(v).$ It is not that hard to verify that $\cdot$ is indeed an action. Okay, now to conclude what I want I need to show that $L$ is an element of $Stab(v)$ for some non-zero $v$. It is equivalent to show that $Stab(v)=G$ for some $v$ or even that the $orb(v)=\{v\}$ for some non-zero $v$. I have tried to do this directly but it does not seem easy, then I tried by contradiction: suppose that for all $v \in \mathbb{F}_p^n$, $L(v)\neq v$ then $L \notin Stab(v)$ for all non-zero $v$. Then since $Stab(b)\leqslant G$, its order has to be a power of $p$, but not $p^k$. Then we have two options, either the order is $1$ which would imply that the action is transitive or the order is a non-zero power of $p$. But I don't know how to derive a contradiction from here. Another thing that I also though of was that this actions induces the homomorphism $\phi:G\to S_{\mathbb{F}_p^n}$ by setting $\phi(L^m)(v)=L^m(v)$. What I could prove was that $\phi$ is injective since $\phi(L^m)=1$ implies $\phi(L^m)(v)=v$ for all $v$, then $L^m(v)=v$ for all $v$ and then $L^m=1.$ From this we can see that $G$ is isomorphic to the group $\{L^m; m\in \mathbb{N}\}$. I don't know anything else to think in the context of group actions, so I think I have already touched the key to solve it but I cannot see it by myself. Could someone take a look at this and show me WHERE I could give more attention to solve it? Please, I would like to solve it by myself because I have an Algebra qualyfing exam next wednesday and I really need to learn, so I would really appreciate good hints just for me to give some steps more... I would not like to have a full answer. Thank you very much!","['group-actions', 'abstract-algebra', 'group-theory']"
2401793,Generating function in combinatorics: combining ordinary and exponential generating functions,"I want to make a generating function for a combinatorics problem with $2$ different simultaneous constraints. In the one variable cases, one of the constraints would use an ordinary generating function, the other an exponential generating function. So I'm not sure how to combine them into a multivariate generating function. Let's make up the following problem to illustrate: Using the ten digits $0$-$9$, I can make a length $k$ string, eg. for $k=5$, the string $27485$. Now say I want the number of $k$-strings (the number of all possible arrangements of length $k$ using the digits $1$-$9$), that satisfy not just one but $2$ conditions, for example: The $k$-string must have $1$ or $2$ occurrences of the digit ""$4$"". The sum of the digits in the $k$-string must be $N$. Make things concrete: use $k=3$, and $N=10$:
If it was the just the first constraint, I think I could use the exponential generating function: $$g(x) = \left[x + \frac{1}{2!}x^2\right]\cdot\left[1 + x + \frac{1}{2!}x^2 + \frac{1}{3!}x^3\right]^8.$$ The first term for the ""$4$"" digit which has to occur once or twice, the second term raised to the $8$ is for the other $8$ digits which can occur any number of times. Then I would look for the coefficient of $x^3$ and multiply by $3!$. And if it were only the $2^{\text{nd}}$ constraint, I think I could do: $$g(y) = \left[1 + y + y^2\right]\cdot \left[1 + y^2 + y^4\right]\cdot \left[1 + y^3 + y^6\right]\cdots\left[1+y^8+y^{16}\right]\cdot\left[1+y^9+y^{18}\right],$$ then look for the coefficient of $y^N$. How do I combine these constraints? Do I just multiply them together, $g(x,y) = g(x)g(y)$ and then look for the coefficient of $(1/k!)x^ky^N$?","['combinations', 'combinatorics', 'generating-functions']"
2401795,Solving for $x$ in modular equation [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let's say I have $2 \equiv 35x \bmod 71$. Wolfram tells me $x=67$ but how can I solve this without guessing and checking from $0$ to $71$? What if the variable is an inverse?","['modular-arithmetic', 'discrete-mathematics']"
2401799,"When 3 random variables are independent, the sum of the first two is independent from the third","Let $X_1, X_2, X_3$ be independent real random variables. That is, for all Borel measurable sets $S_1, S_2, S_3 \subset \mathbb{R}$ it holds true that: $P(X_1 \in S_1 \text{ and } X_2 \in S_2 \text{ and } X_3 \in S_3) = P(X_1 \in S_1)P(X_2 \in S_2)P(X_3 \in S_3)$. Now we define $Z = X_1 + X_2$. How can we prove that $Z$ is independent from $X_3$?","['probability-theory', 'measure-theory']"
2401808,Linear equation with square root,Linear equation in two variables must have the form $ax+by=c$. But can we see $\sqrt{x+y}=2$ as a linear equation because if we square both sides we get $x+y=4$ and both equations have the same solution set?,"['real-analysis', 'linear-algebra']"
2401814,A trigonometric sum related with the primitive $q$-th roots of $1$,"I am having problems proving the following:
For what values of $q$ does the following relationship hold
$$\sum_{\substack{1\leq d < q\\ \gcd(d,q)=1}}\!\!\!\cos\left(2\pi \cdot \frac{d}{q}\right) =0$$ I have found by computer analysis this may hold true for $q=p^r \cdot k$
where $p$ is any prime and $k$ is an integer and $r$ is an integer greater than one. For example $$q=4,8,9,12,16,18,20,24,25,27,28,32,36,40,44,45,48,49,50,52,54,56,60,63,64,68,72,75,76,80,81,84,88,90,92,96,98,99,100,104,108,112,116,117,120,121,124,125,126,128,132,135,136,140,144,147,148,150,152,153,156,160,162,164,168,169,171,172,175,176,180,184,188,189,192,196,198,200,204,207,208,212...$$
For instance for $q=12$ we have
$$\cos\left(2\pi\cdot \frac{1}{12}\right)+\cos\left(2\pi\cdot \frac{5}{12}\right)+\cos\left(2\pi\cdot \frac{7}{12}\right)+\cos\left(2\pi\cdot \frac{11}{12}\right)=0$$ But I am unable to prove this for the general case  $q=p^r\cdot k$. Any help would be greatly appreciated.","['number-theory', 'elementary-number-theory']"
2401837,Points where the Jacobian of a coordinate transformation vanishes,"Consider the coordinate transformation 
\begin{align*}
x &= r\sin\theta\cos\phi \\
y &= r\sin\theta\sin\phi \\
z &= r\cos\theta
\end{align*}
from spherical coordinates $(r,\theta,\phi)$ to rectangular coordinates $(x,y,z)$. Here $r$ is the radius, $\theta$ is the inclination, and $\phi$ is the azimuth. Its Jacobian 
$$\frac{\partial(x,y,z)}{\partial(r,\theta,\phi)} = r^2\sin\theta$$
vanishes on the $z$-axis. According to C. Lanczos in The Variational Principles of Mechanics : [The Jacobian of a coordinate transformation may vanish] at certain singular points, which have to be excluded from consideration. For example, [for the coordinate transformation above] special care is required at the values $r = 0$ and $\theta = 0$, for which the Jacobian of the transformation vanishes. Question : Are points at which the Jacobian of a coordinate transformation vanishes ""excluded from consideration"" altogether or included in the analysis but handled with ""special care""? Perhaps a problem (from the same book) will clarify the question. Characterize the position of a spherical pendulum of length $l$ by spherical coordinates $r$, $\theta$, $\phi$ and obtain : 
  \begin{align*}
T &= \frac{m}{2}l^2\Big(\dot{\theta}^{\,2} + \sin^2\!\theta \,\dot{\phi}^{\,2}\Big), \\
V &= mgl(1 - \cos\theta).
\end{align*}
  Form the Lagrangian equations of motion. The Lagrangian is 
$$L = T - V = \frac{m}{2}l^2\Big(\dot{\theta}^{\,2} + \sin^2\!\theta \,\dot{\phi}^{\,2}\Big) + mgl(\cos\theta - 1).$$
Since 
\begin{gather*}
\partial_{\dot{\theta}}L = ml^2\dot{\theta}, \\
\partial_\theta L = ml^2\sin\theta\cos\theta\,\dot{\phi}^{\,2} - mgl\sin\theta, \\ 
\partial_{\dot{\phi}}L = ml^2\sin^2\!\theta\,\dot{\phi}, \\
\partial_\phi L = 0,
\end{gather*}
the Lagrangian equations of motion are
\begin{gather*}
\frac{d}{dt}\Big(ml^2\dot{\theta}\Big) - ml^2\sin\theta\cos\theta\,\dot{\phi}^{\,2} + mgl\sin\theta = 0 \\
\frac{d}{dt}\Big(ml^2\sin^2\!\theta\,\dot{\phi}\Big) = 0
\end{gather*} In the solution to this problem, should it be stated that points on the $z$-axis are ""excluded from consideration""? Or should they be included, but treated with ""special care""? In particular: Do the equations in this problem (for kinetic and potential energy; the Euler-Lagrange equations) hold on the $z$-axis? Do the partial derivatives $\partial_r$, $\partial_\theta$, $\partial_\phi$ (as defined in differential geometry) exist on the $z$-axis?","['coordinate-systems', 'spherical-coordinates', 'physics', 'differential-geometry']"
2401841,"How to show that $\sin^2(1/n)\leq 1/n^2, \forall n\in\mathbb{N}?$","I'm trying to prove that $\sum_{n=1}^\infty \sin^2(1/n)$ is convergent, by using the comparison test. I hypothesize that the sequence defined by $b_n:=1/n^2$ is always larger than $\sin^2(1/n)$. But when I do induction on $n$, the inequality isn't clear.","['real-analysis', 'inequality', 'sequences-and-series']"
2401859,"""Note that connectedness is not defined for closed sets"" explanation","I'm learning Complex Analysis, and we are given the following definitions: Definition. Suppose that 
$\Omega \subseteq$ C and that 
 $\Omega$ is open. (1) The set $\Omega$
 is connected if any two points of $\Omega$
 can be joined by a polygonal
path lying inside $\Omega.$ (2) The set 
 $\Omega$ is simply connected if the interior of every simple closed polygonal
path in $\Omega,$ 
 lies in $\Omega$
 that is, if “$\Omega$
 has no holes”. (3) The set 
 is a domain if it is connected as well as open. Later, my note makes a remark saying: Note that connected is not defined for closed sets, but there are questions
about closed sets being connected. I don't understand this, it says that it's not defined for closed sets, yet it also says there are questions regarding closed sets being connected..? Why is do closed sets not have connectedness defined?","['complex-analysis', 'general-topology']"
2401864,What is the smallest prime $P>2$ with this property?,"Let P be a prime number and P=$m^{\text{th}}$ prime number. Here I'm interested in a prime P$>2$, such that P divides the concatenation of the first $(2m-1)$ prime numbers. Using my old laptop I've checked P up to $7919$ (i.e: up to the $1000^{\text{th}}$ prime number)without finding a solution. Can you find the smallest /some primes P$>2$ with such property ?","['number-theory', 'prime-numbers']"
2401871,Limit of the fraction of numbers $\le n$,"For a set $E \subseteq \mathbb{N}$, we defined $r_n(E):=\left |{E \cap[n]}\right |$, where $[n]:=\left\{{1,2,...,n}\right\}$. I need to find a set $E^* \subseteq \mathbb{N}$ for which $\nexists \lim_{n \to \infty} \frac{r_n(E^*)}{n}$. I have tried with some set formed by unions, intersections, and complements between the sets of multiples of different prime numbers, but I could not find this set.","['number-theory', 'prime-numbers', 'limits']"
2401941,"Let $G$ be a group such that $a^2 = a$ for all $a \in G$, Is $G$ an abelian group?","I tried to solve this by following: Since $G$ is a group, an inverse exists for every element in $G$. Multiply by inverse to $a$ on both sides of $a^2 = a$. We will get $a = i$, where $i$ is the identity element. This holds true for all $a*$, which implies $G$ contains only one distinct element i.e. $i.$ Hence $G$ is abelian. Is my approach correct?","['abstract-algebra', 'group-theory', 'proof-verification']"
2401947,Limit of $n$-Cesaro summation as $n \to \infty$,"I recently learned that a Cesaro summation extends the usual summation in the following way:  Given a sequence $a_1, a_2, \ldots $ we construct the Cesaro sequence by defining $$\sigma_n = \frac{1}{n}\sum_{j=1}^n a_j$$
Then we say that $(a_j)$ is Cesaro summable if $\sigma_n$ coverages to some point. Now let's relabel the sequence $(\sigma_j)$ as $(\sigma^{1}_j)$, and say $(a_j)$ is $1$-Cesaro summable if it is Cesaro summable. We could, obviously, construct a new Cesaro sequence, call it $(\sigma^2_j)$, which is the Cesaro sequence of the original Cesaro sequence.  Then we say the sequence $(a_j)$ is $n$-Cesaro summable if the sequence $(\sigma^{n-1}_j)$ is Cesaro summable.  Clearly if a sequence is $n$-Cesaro summable then it is $j$-Cesaro summable for all $j\ge n$. Question:  Is there a proper way to define $\infty$-Cesaro summability? Are there sequences which are not $n$-Cesaro summable for any finite $n$ yet are $\infty$-Cesaro summable?  Finally, a good definition would require the existence of sequences which are not $\infty$-Cesaro.","['functional-analysis', 'cesaro-summable']"
