question_id,title,body,tags
2121600,Would this be a proper way to define a linear function using Matrix transformation?,"Would it be correct to define the function $y = 2x$ as the matrix transormation $ \begin{bmatrix} 1 & 0\\ 2 & 0 \end{bmatrix}$ on any two-dimensional vector $\begin{bmatrix} x \\ y \end{bmatrix}$ where $x, y \in \mathbb{R}$? It feels weird to pass in a two-variable argument, but at the same time the output over the entire domain does seem to be $y = 2x$.","['matrices', 'linear-algebra', 'functions']"
2121618,Modeling a Small Ball Rolling Off a Bigger ball,"A friend gave a challenging math problem to solve for fun, but since I'm a high school calc student, it's too hard for me to figure out. If a small ball is at the top of a larger
  stationary sphere (radius = $1$) and it starts to roll down
  the side, at what point will the smaller ball lose contact with the
  larger sphere? I got off to a good start, but then got stuck. Here's my work. If you don't care to read it all, you can skip to the last paragraph: I first aim to find the velocity. I start with the acceleration of the ball: $a = g\dot{}\sin(\theta)$ where theta is the angle of inclination the ball is rolling at any given instant. The derivative of the circle equation gives the slope of this incline. The circle is modeled by $f(x) = \sqrt{1-x^2}$ and $f'(x)= -x\dot{}(1-x^2)^{-1/2} \ $Therefore: $\ \theta = \tan^{-1}(f'(x))$. Substituting this back into the original equation, this is where it gets ugly: $$a = g\dot{}\sin\left(\tan^{-1}(f'(x))\right)$$ I figured I needed to put all of this is terms of time, so I change $x$, horizontal displacement of the ball, to $s(t)$, and $a$ to $a(t)$. Using my current knowledge of kinematics, I can relate displacement to acceleration such that $s(t) = \int_{}v(t)~dt \ $ and $\ v(t) = \int_{}a(t)~dt$ so if I'm not mistaken $$s(t) = \int_{}\int_{}a(t)\ dt\ dt$$ So, substituting this all back into my original equation, I get this: $$a(t) = g\dot{}\sin\left(\tan^{-1}\left(f'(\int_{}\int_{}a(t)\ dt\ dt)\right)\right)$$ Not sure if this is even correct syntax at this point. Anyways, I got everything in terms of $a$! But, I've never formally learned to solve DE's, so I'm not sure what to do next or if this DE is solvable, and if it is, it must be so complex that it's not a practical solution. There must be a simpler way that I'm missing, what do I do? After solving for the velocity, how would I use it to find when the ball loses contact with the larger sphere?","['recreational-mathematics', 'ordinary-differential-equations', 'calculus']"
2121646,Why does the discriminant tell us how many zeroes a quadratic equation has?,"The quadratic formula states that: $$x = \frac {-b \pm \sqrt{b^2 - 4ac}}{2a}$$ The part we're interested in is $b^2 - 4ac$ this is called the discriminant. I know from school that we can use the discriminant to figure out how many zeroes a quadratic equation has (or rather, if it has complex, real, or repeating zeroes). If $b^2-4ac > 0$ then the equation has 2 real zeroes. If $b^2-4ac < 0$ then the equation has 2 complex zeroes. If $b^2-4ac = 0$ then the equation has repeating zeroes. But I don't uderstand why this works.","['algebra-precalculus', 'quadratics']"
2121658,Can Atlas on S^1 only contain one chart?,"The smallest atlas for the $S^1=\{(x,y)\in \Bbb R^2|\,x^2+y^2=1\}$ must contain two charts. How to prove it? My route is first to prove that it can only be homeomorphic to $
\Bbb R^1$ by invariant of domain (dimension). Then it restricts on mapping from $S^1$ into $\Bbb R$. Secondly, I want to show such a homeomorphism cannot exist. But I got stuck, since I do not know how to partition a circle and I noticed that the topological structure on the circle can be defined by those arcs on the circle with one end be filled one end be empty . Then for the topology structure one should have a homeomophism eventually map$: (a,b]\rightarrow (c,d)$ which is not true. Then I do not know what is wrong.","['manifolds', 'differential-geometry', 'differential-topology']"
2121662,"Is the product of primes + 1 always eventually composite and, if so, how long does it take?","I was thinking about Euclid's proof of the infinitude of primes the other day and started thinking about what would happen for different initial sets of primes than the usual first $N$ primes. Is there a finite subset of the primes which never actually hits a composite number when generating numbers as in Euclid's proof? Consider the following algorithm: Take a set $A_{k}=\left\{q_{1},\ldots,q_{k}\right\}$ of primes and let $n = q_{1}\cdots q_{k}+1$. If $n$ is prime, start over with $A_{k+1} = A_{k}\cup\left\{n\right\}$. If $n$ is composite, terminate. Written in a C-like pseudocode: function euclid(array primes[])
{
    n = 1;
    steps = 1;
    for(i = 0; i < primes.size(); i++)
    {
        n *= primes[i];
    }
    n++;

    while(isPrime(n))
    {
        steps++;
        primes.append(n);
        n = n*(n-1) + 1;
    }
    return steps;
} My question is: Does this always terminate for any initial set of primes? If so, how can we express the number of steps in terms of the initial set of primes? Is the number of steps taken unbounded if we vary the initial set of primes? The only thing I've been able to determine on my own, so far, is that this obviously terminates after the first step whenever 2 isn't included. Here are some examples (all include 2): $\{2\}\to\{2,3\}\to\{2,3,7\}\to\{2,3,7,43\}\to\{2,3,7,43,1807\}\to$ Terminate: $13\mid1807$. 4 steps. $\{2,5\}\to\{2,5,11\}\to\{2,5,11,111\}\to$ Terminate: $3\mid111$. 2 steps. $\{2,7\}\to\{2,7,15\}\to$ Terminate: $3\mid15$. 1 step. $\{2,3,5\}\to\{2,3,5,31\}\to\{2,3,5,31,931\}\to$ Terminate: $7\mid931$. 2 steps. Since $q_{\ell+1} = q_{\ell}\left(q_{\ell}-1\right)+1$ for all $\ell>k$, it seems that looking at the polynomial $x^{2}-x+1$ may provide some insight. If anyone can link to references for this or similar problems, I'd really appreciate it.","['number-theory', 'reference-request', 'prime-numbers']"
2121695,What is the difference between the Taylor and Maclaurin series?,What is the difference between the Taylor and the Maclaurin series? Is the series representing sine the same both ways? Can someone describe an example for both?,"['power-series', 'taylor-expansion', 'sequences-and-series']"
2121705,Proof of $L^2$ inner product?,"Can anyone help me prove that the $L^2$ inner product is in fact an inner product? I'm particularly struggling to prove that it is conjugate-symmetric and that length is positive. This is the inner product in question: For $f,g \in L^2([a,b])$, 
$\langle f,g \rangle = \int_a^b f(t) \overline{g(t)}dt$","['complex-analysis', 'linear-algebra']"
2121715,Proof by Induction Help: Prove that there are unique integers $a\geq 0$ and $k>0$ such that $n=(3^a)\cdot k$ and $k$ is not divisible by $3$.,"Suppose $n$ is a positive integer. Using induction, prove that there are unique integers $a\geq 0$ and $k>0$ such that $n=(3^a)\cdot k$ and $k$ is not divisible by $3$. Note: I have already proven the base step of $P(1)$ and have set the induction hypothesis (I.H.) to be $P(t): t=(3^a)\cdot k$ [I used $t$ here instead of $k$ since $k$ already exists in the equation]. I am to the point of proving $P(t+1)$ but am unsure of whether or not this means $t+1=(3^a)\cdot k$ or if it means $t+1=(3^a)\cdot k+1$? With the latter, couldn't you just subtract a $1$ and then be left with your I.H.? If it is the first equation, I'm not quite sure how this can be proved. The induction proofs I have done so far were all summation problems, so I could group sections together and set it equal to the I.H. which doesn't seem to be a possibility here.","['induction', 'formal-proofs', 'discrete-mathematics']"
2121733,How to find the left inverse of a piece wise defined function,"$F(x)=\begin{cases} x-1 & \text{if } x \text{ is even}\\ 2x &\text{if } x \text{ is odd}\end{cases}$ I need to exhibit the left inverse of this function. I know it exists because the function is one-to-one. Now, it's easy for me to switch the $x$'s and $y$'s to get:
$$g(x)=\begin{cases} \frac{x}{2} \\ x+1 \end{cases}$$
I know (because the back of the book tells me) that it's $\frac{x}{2}$ if $x$ is even and $x+1$ if $x$ is odd, but I don't know why these evens and odds flipped from the original function. Is there a systematic way to go about solving these inverses that would let me see more clearly what is happening?",['functions']
2121735,Differential Equations Help,"I need to answer the following question Assume that all the cash flows in this problem occur continuously,
rather than only at discrete times.
Suppose that your parents deposit money into your bank account at the
rate of \$50 a day. You start out with \$3,000 in your account. You also spend
at a rate of 5% of your money per day. Your account is a no-interest checking
account.
Write a differential equation for the amount of money in your account as
a function of time, and solve the equation.
Also find an equilibrium solution. I'm having trouble writing a differential equation that represents the situation, everything else I can do","['ordinary-differential-equations', 'linear-algebra', 'calculus']"
2121864,Generalization to higher dimension of $e^r \not \in \mathbb Q$,"The following is well known and not difficult to prove: 
$$\forall r \in \mathbb Q^*,  e^r \not \in \mathbb Q.$$
See for instance https://proofwiki.org/wiki/Exponential_of_Rational_Number_is_Irrational Could this be generalized with the following result, for $n\geq 2$:
$$\forall M \in \mathrm{GL}(n,\mathbb Q),  \exp(M) \in \mathrm{GL}(n,\mathbb R)\setminus \mathrm{GL}(n,\mathbb Q)?$$
If yes, do you have any proof or reference?","['matrices', 'matrix-exponential', 'rational-numbers']"
2121881,query on diagonalizability of matrix,Here I think matrix A can be an identity matrix . But it's answer is that A is diagonalizable . It's a single correct question . How can it be diagonalizable only . Why can't A be an identity matrix?,"['matrices', 'diagonalization', 'projection-matrices', 'linear-algebra']"
2121911,Evaluate$\sum_{n=0}^\infty\binom{3n}{n}x^n$,"The question is: Evaluate $$\sum_{n=0}^\infty\binom{3n}{n}x^n$$ After applying a few numbers as $x$ in Wolfram Alpha, I guess that the answer is probably:
$$2\sqrt{\frac1{4-27x}}\cos\left( \frac13\sin^{-1}\frac{3\sqrt{3x}}{2} \right)$$
that I can never prove. (Interestingly the above becomes simply $2\cos\frac{\pi}9$ when $x=\frac19$.) (*) To give you the background, the motivation that led me to this question is the Algebra problem #$10$ in the Harvard-MIT Math Test in Feb. 2008, that concludes to:
$$\sum_{n=0}^\infty\binom{2n}{n}x^n=\frac1{\sqrt{1-4x}}$$
And then I thought about what if it was $3n$ instead of $2n$.","['algebra-precalculus', 'binomial-coefficients', 'sequences-and-series']"
2121981,Derivative of measures,"I think most upper level analysis books (including Rudin) decide to ""reintroduce"" the idea of a derivative by transitioning from measure theory to the idea of differentiating measures. I get that this theory has power because it extends to a lot more than ""differentiable functions"" as we learn in high school, but specifically what are the advantages of this concept of differentiating measures (as opposed to functions)? Also, one extra minor question. What's the quickest way to recover the standard
$$lim_{h\to 0} \frac{f(x+h)-f(x)}{h}$$ definition of a limit from the derivative of measures lingo?","['derivatives', 'measure-theory', 'calculus']"
2121993,If $f$ is holomorphic and $\left| f \right|$ is constant then $f$ is constant,"Given that $f:D\to \mathbb{C}$ is holomorphic on $D$ and $\left| f \right|$ is constant on $D$, then $f$ is constant on $D$. Where $D$ is a connected open set. My approach: Write $f=u(x,y)+iv(x,y)$.
Since $f$ is holomorphic on $D$, it is complex-differentiable on $D$, which implies that the $\mathbb{R}^2$-Jacobian of $f$ is defined on all of $D$. That is, $$Df=\begin{bmatrix}
u_x & v_x \\ 
u_y & v_y
\end{bmatrix}$$ Now, since $\left| f \right|$ is constant, it must be true that $$\left| Df \right|=\det\left(\begin{bmatrix}
u_x & v_x \\ 
u_y & v_y
\end{bmatrix}\right)=u_xv_y-v_xu_y=0 \text{  (*)}$$ Since $f$ is $\mathbb{C}$-differentiable on $D$, the Cauchy-Riemann equations hold for $f$. Thus, $$ u_xv_y-v_xu_y=u_x^2+u_y^2=0 \iff u_x^2=-u_y^2$$ Thus $u_x=u_y\equiv 0 \implies u(x,y)$ is constant. Similarly, we can make the substitutions in (*) to obtain $v_y^2=-v_x^2$ and $v_x=v_y\equiv 0$. This implies that both $u$ and $v$ are constant, and thus $f$ is constant. Please let me know if my approach is correct. I'm just a little concerned about my treatment of the Jacobian of $\left|f\right|$ as the determinant of the Jacobian of $f$, but I think this should be correct.","['jacobian', 'complex-analysis', 'holomorphic-functions', 'proof-verification']"
2122014,Composite Functions and Derivatives,"I have two functions, f is monotonically increasing for every x. g has a local minimum at x=0. Now I define a new function h(x)=f(g(x)). I need to determine if h has minimum at x=0, maximum, either minimum or maximum, or if h is monotonically increasing like f is. I am not sure how to approach this. Any hints will be mostly appreciated ! Thank you.","['derivatives', 'calculus']"
2122045,Proving Ramanujan's Integral Formula,"In a letter to Hardy, Ramanujan described a simple identity valid for $0<a<b+\frac 12$ : \begin{align}
& \small\int\limits_{0}^{\infty}\frac {1+\dfrac {x^2}{(b+1)^2}}{1+\dfrac {x^2}{a^2}}\dfrac {1+\dfrac {x^2}{(b+2)^2}}{1+\dfrac {x^2}{(a+1)^2}}\dfrac {1+\dfrac {x^2}{(b+3)^2}}{1+\dfrac {x^2}{(a+2)^2}}\cdots \, dx
\\[5mm] = &\
\dfrac {\sqrt{\pi}}2\dfrac {\Gamma\left(a+\frac 12\right)\Gamma\left(b+1\right)\Gamma(b-a+1)}{\Gamma(a)\Gamma\left(b+\frac 12\right)\Gamma\left(b-a+\frac 12\right)}\tag1
\end{align} Which I find remarkable. Questions: Has anyone discovered a way to prove $(1)$ ? If so, how do you prove it? Where did Ramanujan learn all of his integrational-calculus material (It doesn't appear in the Synopsis book )? Does anyone know a pdf or book where I can start learning advanced integration? I'm wondering how you would prove $(1)$ and if there are similar identities that can be made. Wikipedia doesn't have any information.","['integration', 'definite-integrals', 'calculus']"
2122051,Quadratic form in summation form,"Why is 
$$x^TAx= \sum_{j}^{n}\sum_{i}^{n} a_{ij}x_ix_j $$ $x$ is n × 1, $A$ is n × n. What I have tried? If $y=Ax$, then
$$y_j =\sum_{j}^na_{ij}x_{j}$$ Now, $$x^TAx= \sum_{i}^n x_iy_i $$ which becomes $$\sum_{i}^n x_i\sum_{j}^na_{ij}x_{j}=\sum_{i}^n \sum_{j}^na_{ij}x_{i}x_j$$ Now, the orders of i and j are reversed which is the problem, and confuses me.","['matrices', 'quadratic-forms']"
2122066,Probability from rolling 4 sided die?,"I am unsure how to go about doing this question. Could a binomial probability distribution be applied to this? Full question: Assuming I have a $4$ sided die (labeled $1,2,3,$ and $4$), with equal probability of landing on each side, and I roll the die $9$ times. What is the probability that I'll roll $1$ and $2$ $2-$times each, a $3$ $4-$times, and a $4$ $1-$time?","['combinatorics', 'probability', 'discrete-mathematics']"
2122078,Counting triangles,"I got a question yesterday, to count the number of triangles in the above figure. I counted them, then thought about a formula to do the counting. I can't do that. Can someone show me how?","['puzzle', 'combinatorics', 'discrete-mathematics', 'geometry']"
2122110,Differentiation of a double summation,How does one reach from from 45 to 46?,"['matrices', 'summation', 'derivatives']"
2122124,Polar plot of $r^2=16\sin(3\theta)$ -- $3$ or $6$ leaves?,"I'm having a bit of trouble figuring out what the polar plot of the following equation would look like: $$r^{2} = 16\sin 3\theta.$$ 1.) One way to interpret the above is to rewrite it as $r = 4\sqrt{\sin 3\theta}$ and $r = -4\sqrt{\sin 3\theta}$, thus yielding a graph that is very similar to a 6-leaf rose. 2.) The other way to interpret this is to rewrite the graph in rectangular form, resulting in the equation $$(x^{2}+y^{2})^{3}=3x^{2}y - y^{3}$$, which yields a 3-leaf rose. I was wondering which is correct, and why?","['trigonometry', 'polar-coordinates', 'graphing-functions']"
2122146,How to show that $\int_{0}^{\infty}{(2x)^4\over (1-x^2+x^4)^4}\mathrm dx=\int_{0}^{\infty}{(2x)^4\over (1-x^2+x^4)^3}\mathrm dx=3\pi$,"Consider
  $$I=\int_{0}^{\infty}{(2x)^4\over (1-x^2+x^4)^4}\mathrm dx
\qquad J=\int_{0}^{\infty}{(2x)^4\over (1-x^2+x^4)^3}\mathrm dx$$
  I want to show that $I=3\pi$ and that $I=J$. First, we noticed that $x^4+x^2+1=(x^2-x+1)(x^2+x+1)$ So it gives us an idea to try and factorise $x^4-x^2+1$ but cannot find any factors. Integrate $I$ (We try some substitutions to see where it will get us to) $x=\sqrt{u}$ then $dx={2\over \sqrt{u}}du$ $$I=16\cdot{1\over 2}\int_{0}^{\infty}{u^{3/2}\over (1-u+u^2)^4}\mathrm du$$ $u=\tan(y)$ then $du=\sec^2(y)dy$ $$I=8\int_{0}^{\pi/2}{\tan^{3/2}(y)\over (1-\tan(y)+\tan^2(y))^4}{\mathrm dy\over \cos^2(y)}$$ then simplified down to $$I=128\int_{0}^{\pi/2}{\cos^6(y)\tan^{3/2}(y)\over (2-\sin(2y))^4}\mathrm dy$$ we further simplified down to $$I={128\over 2^{3/2}}\int_{0}^{\pi/2}{\cos^3(y)\sin^{3/2}(2y)\over (2-\sin(2y))^4}\mathrm dy$$ Not so sure what is the next step.","['improper-integrals', 'integration', 'definite-integrals', 'calculus']"
2122152,A limit question puzzled me,"$$\frac{1}{\sqrt{k}}＝\frac{2}{\sqrt{\pi}}\int_{0}^{\infty}e^{-kq^{2}}dq$$
so $$\sqrt{x}e^{-x}\sum_{k＝1}^{\infty}\frac{x^{k}}{k!\sqrt{k}}$$ $$＝\frac{2\sqrt{x}e^{-x}}{\sqrt{\pi}}\sum_{k＝1}^{\infty}\frac{x^{k}}{k!}\int_{0}^{\infty}e^{-kq^{2}}dq$$ $$＝\frac{2\sqrt{x}e^{-x}}{\sqrt{\pi}}\int_{0}^{\infty}(e^{xe^{-q^{2}}}-1)dq$$ The question is how to prove
$$lim_{x\rightarrow \infty}\frac{2\sqrt{x}e^{-x}}{\sqrt{\pi}}\int_{0}^{\infty}(e^{xe^{-q^{2}}}-1)dq＝1$$ Thanks in advance",['limits']
2122157,Number of unique items in a big set from small sample,"We have a box with $m=1\,000\,000$ cards. Each card contains one word. The words are repeated so there is a relatively small number of $n$ unique words. $n$ is unknown. If we get a sample of $k=5000$ cards, we find that there is $42$ unique words in our sample. With this information, we know $P(n\geq42) = 1$. How can we know $P(n\geq43)$, $P(n\geq44)$..., and so on? Is this problem common, and does it have a ""common name""? PS: we have the information on the frequency of each of our $42$ words for the $5000$ card sample, they can be used for the solution if it is relevant. Lets call this frequencies $f_1, f_2, \dots,f_{42}$.","['statistics', 'probability', 'combinatory-logic']"
2122169,Residue Proof of Fourier's Theorem Dirichlet Conditions,"Whittaker gives two proofs of Fourier's theorem, assuming Dirichlet's conditions. One proof is Dirichlet's proof, which involves directly summing the partial sums, is found in many books. The other proof is an absolutely stunning proof of Fourier's theorem in terms of residues, treating the partial sums as the residues of a meromorphic function and showing that, on taking the limit, we end up with Dirichlet's conditions. My question is about understanding the latter half of the residue proof, given here . The jist of the proof is to consider a trigonometric series with real coefficients, assume the coefficients are Fourier coefficients of a function $f$, and then simplify the partial sum \begin{align}
S_k(f) &= a_0 + \sum_{m=1}^k (a_m \cos(mz) + b_m \sin(mz)) \\
&= \frac{1}{2 \pi} \int_0^{2 \pi} f(t)dt  + \frac{1}{\pi} \sum_{m=1}^k  \int_0^{2 \pi} f(t)\cos[m(z-t)] dt \\
&= \sum_{m=-k}^k  \frac{1}{2\pi} \int_0^{2 \pi} f(t)e^{im(z-t)} dt \\
&=  \sum_{m=-k}^k  \frac{1}{2\pi} \int_0^z f(t)e^{im(z-t)} dt + \sum_{m=-k}^k  \frac{1}{2\pi} \int_z^{2 \pi} f(t)e^{im(z-t)} dt \\
&= U_k + V_k.
\end{align}
Next we try to turn $U_k$ into the sum of the residues of a meromorphic function derived from this, so try to modify it:
\begin{align}
U_k(z) &= \sum_{m=-k}^k  \frac{1}{2\pi} \int_0^z f(t)e^{im(z-t)} dt  \\
&= \sum_{m=-k}^k  \frac{w}{2\pi w} \int_0^z f(t)e^{w(z-t)} dt  |_{w = im, m \neq 0} \\
&= \sum_{m=-k}^k  \frac{w}{1 + 2\pi w  - 1} \int_0^z f(t)e^{w(z-t)} dt |_{w = im, m \neq 0} \\
&\to  \frac{1}{1 + 2\pi w + \dots - 1} \int_0^z f(t)e^{w(z-t)} dt  \\
&=  \frac{1}{e^{2 \pi w} - 1} \int_0^z f(t)e^{w(z-t)} dt
\end{align}
to find
$$\phi(w) =  \frac{1}{e^{2 \pi w} - 1} \int_0^z f(t)e^{w(z-t)} dt$$
so that, if $C_k$ is a circle in the $w$ plane containing $0,i,-i,2i,-2i,\dots,ki,-ki$ and no more poles, say of radius $k+1/2$, we see
$$ \frac{1}{2 \pi i} \int_{C_k} \phi(w) dw = U_k.$$
From this we integrate over the boundary explicitly via $w = (k + 1/2)e^{i\theta}$ so that $U_k$ reduces to
$$U_k = \frac{1}{2 \pi} \int_0^{2 \pi} w \phi(w) d \theta$$
and from here on we are supposed to end up with Dirichlet's conditions. Can anybody explain the rest of the proof? Since this aspect of the proof seems to be the crux of other flawed proofs, need to make sure I get the rest of it with no hand-waving, seems unmotivated.","['real-analysis', 'fourier-series', 'fourier-analysis', 'residue-calculus', 'complex-analysis']"
2122174,Solution of the equation $\frac{\log x}{x}=1-\frac{1}{a}$,"I'm just a high school guy so this question is hopeless for me. I don't know advanced mathematics. I'm trying to get $x$ in terms of a. When I try to cancel the $\log$ by substitution, exponential functions appear. Is there some way to at least approxumate $x$ in terms of $a$ by using infinite series or anything else?","['sequences-and-series', 'functions']"
2122188,The equation with arccos and arcsin,For what value of parameter $a$ the equation $$ \text{arccos}(\sin(x)+a)=\text{arcsin}(\cos(x)+a) $$ has exactly one solution in the interval for $x$ $(0; 2\pi)$?,['trigonometry']
2122222,"show $ x \to (x,f(x))$ is an embedding","Let $f:\mathbb{R}^n \to \mathbb{R}^m$ be ca continuous function and $(\mathbb{R}^n,\mathcal{O}_{\mathbb{R}^n}) $ the real numbers equipped with the euclidian topology.  Why the map $F:\mathbb{R}^n \to \mathbb{R}^{m+n}$ with $ x \to (x,f(x))$ is an embedding?
Of course $F$ is naturally injective and F is also continuous. But it's not clear to me why the map $F: (\mathbb{R}^n,\mathcal{O}_{\mathbb{R}^n}) \to (F(\mathbb{R}^n),\mathcal{O}_{\mathbb{R}^{m+n} | \mathbb{R}^n})$ is open? Where $\mathcal{O}_{\mathbb{R}^{m+n} | \mathbb{R}^n}$ is the subspace topology from $\mathbb{R}^n$ in $\mathbb{R}^{m+n}$.  Can someone give me a little hint?","['general-topology', 'analysis']"
2122224,number of surjective mapping from a set to another,Is there a simple formula for finding the number of surjective mappings from a set of cardinality m to a set of cardinality n with m > n ?,['elementary-set-theory']
2122242,At least ten language is spoken,"At a party of $250$ mathematician , each mathematician speaks one or more languages. It is found that for any two mathematicians, each speaks at least one language not spoken by other. Show that there are at least $10$ different languages spoken in the party. I have a feeling that Pigeon Hole Principle to be used, but I am clueless how to use it. Please help.","['combinatorics', 'extremal-combinatorics']"
2122244,Statistics probability die question,"Suppose a die has been loaded so that a six is scored five times more often than any other score, while all the other scores are equally likely. Express your answers to three decimals. I have gotten the following answers. What is the probability of scoring a three? 0.090909091
I have deciphered since it is a 11 sided die so I simply came up with 1/11 since there is only 1/11 chance of getting a 3 What is the probability of scoring a six? 
0.454545455
I have reasoned since there are 5 chances in the 11 sided die so I have gotten 5/11. I have gotten both of them wrong. What are the answers?","['statistics', 'probability', 'dice']"
2122260,Why arc-length parametrized curves has unit tangent vector?,"I'm studying that if we have a smooth  parametrized curve $r(t)$, we can reparametrize it according to its arc-length so that the derivative will always have module $1$. Is there a proof?","['arc-length', 'tangent-line', 'parametrization', 'differential-geometry', 'vector-spaces']"
2122275,Maximum of stopping times is not a stopping time,"Is the maximum of two stopping times a stopping time? I wrote $$\{max(\tau, \sigma) \le t\} = \{\tau \le t\} \cap \{\sigma \le t\} \in \mathcal F_t$$ Because both $\tau$ and $\sigma$ are stopping times. In my book there is written that it isn't though. Can you tell me where the error is?","['probability-theory', 'probability', 'stopping-times']"
2122316,Relation between decomposition field and complete decomposition of a prime ideal,"In my lecture on Algebraic Number Theory in the chapter about Galois extensions we had the following statement:
$$ G_{\mathfrak{p}}= \{id\} \iff Z_{\mathfrak{p}}=L  \iff p~ \text{is completely decomposed} $$
where $A$ is a Dedekind domain, $K$ its quotient field, $L/K$ a finite Galois extension of degree $n$, $\mathcal{O}_L$ the integral closure of $A$ in $L$, $G=\mathrm{Gal}(L/K)$, $\mathfrak{p}$ a non-zero prime ideal in  $\mathcal{O}_L$ over $p$ which is a non-zero prime ideal in $A$. $G_{\mathfrak{p}}$ denotes the decomposition group of $\mathfrak{p}$ and $Z_{\mathfrak{p}}$ the corresponding decomposition field. I do understand the first $\Leftrightarrow$, but have unfortunately some trouble to show (and understand) the second $\Leftrightarrow$. My ideas so far were (for $\Rightarrow$):  If $G_{\mathfrak{p}}= \{id\}$, then the number of prime ideals in $\mathcal{O}_L$ above $p$ is $n$ as $(G:G_{\mathfrak{p}})=\vert G \vert= [L:K]=n$ and $G$ acts transitively on the set of all prime ideals over $p$. This gives $p \mathcal{O}_L= ({\mathfrak{p}_1} \cdot \dotsc \cdot \mathfrak{p}_n)^e$ as the decomposition of $p$ with $e$ the ramification degree. Now you should somehow get that $e$ equals one (as is required in the definiton of completely decomposed) but I just don't see why this follows? For the converse: no idea. I would be very thankful for any hints and/or solutions!","['number-theory', 'galois-theory', 'algebraic-number-theory']"
2122350,Proving the triangle inequality for the euclidean distance in the plane,"I'm looking to introduce my students to the triangle inequality in the plane with the regular euclidean distance. They have no knowledge of functions or vectors (and therefore norms) so the proof should contain no mention of those concepts. I'm finding it rather difficult to prove with such basic tools. Let $A=(x_A,y_A)$, $B=(x_B,y_B)$ and $C=(x_C,y_C)$ be points in $\mathbb{R}^2$. I want to prove that $$
\sqrt{(x_A-x_B)^2+(y_A-y_B)^2} \leq \sqrt{(x_A-x_C)^2+(y_A-y_C)^2} + \sqrt{(x_C-x_B)^2+(y_C-y_B)^2}
$$ Any ideas?",['algebra-precalculus']
2122351,An intuitive understanding of Cauchy completeness?,"The standard procedure for completing a metric space is adding a limit for every Cauchy sequence, thus making the space Cauchy-complete. When elementary analysis is first taught, however, the completeness of the real numbers is usually introduced using the axiom of completeness, which asserts that the real numbers are Dedekind complete, that is, every Dedekind cut is generated by a real number (or equivalently, every upper-bounded nonempty subset has a least upper bound). For the real numbers, the two definitions coincide; but for a general metric space, the Dedekind definition is stronger. I'm struggling to understand, or to give an intuitive explanation, for why the Cauchy definition truly implies ""completeness"", in the sense that any ""place"" (or ""hole"") in the space will have a point in it. I can rationalize the Dedekind definition: it basically implies that wherever you ""cut"" the line, you will find a number there; thus there are no ""holes"". If this definition was provable from the Cauchy one, I would not have complained; However the Cauchy definition is strictly weaker, and thus I'm struggling to see why does Cauchy completeness truly counts as ""completeness"", in the intuitive or geometric sense of ""continuousness"". Can anyone find a sort of intuitive or graphical explanation for that?","['general-topology', 'real-analysis']"
2122402,"Show that $(x^3+2y^3)/x^2+y^2$ is continuous at $(0,0)$","I used polar coordinates to solve the problem and reached up to $$
r|\cos^3(\theta) + 2\sin^3(\theta)|
$$ I am stuck after that and don't know how to figure out epsilon and delta.","['multivariable-calculus', 'continuity']"
2122422,Find the rank of the following matrix depending on $\lambda\in\Bbb R$,"Find the rank of the following matrix depending on $\lambda\in\Bbb R$.
$$A=\begin{pmatrix}
1&2&3&4\\
2&\lambda&6&7\\
3&6&8&9\\
4&7&9&10
\end{pmatrix}$$ My attempt: $$\begin{pmatrix}
1&2&3&4\\
2&\lambda&6&7\\
3&6&8&9\\
4&7&9&10
\end{pmatrix}\sim\begin{pmatrix}
1&2&3&4\\
0&\lambda-4&0&-1\\
0&0&-1&-3\\
0&-1&-3&-6
\end{pmatrix}\sim\begin{pmatrix}
1&0&-3&-8\\
0&\lambda-4&0&-1\\
0&0&-1&-3\\
0&-1&-3&-6\\
\end{pmatrix}$$
For $\lambda=4$ we have: 
$$\begin{pmatrix}
1 &0&-3&-8\\
0&0&0&-1\\
0&0&-1&-3\\
0&-1&-3&-6
\end{pmatrix}\sim\begin{pmatrix}
1&0&0&1\\
0&0&0&-1\\
0&0&-1&-3\\
0&-1&0&3\end{pmatrix}\sim\begin{pmatrix}
1&0&0&0\\
0&0&0&-1\\
0&0&-1&0\\
0&-1&0&0\\
\end{pmatrix}$$ $\Rightarrow r(A)=4$ For $\lambda\neq 4$ we have: $$\begin{pmatrix}
1&0&0&1\\
0&\lambda-4&0&-1\\
0&0&-1&-3\\
0&-1&0&3\\
\end{pmatrix}\sim\begin{pmatrix}
1&0&0&1\\
0&0&0&3\lambda-13\\
0&0&-1&-3\\
0&-1&0&3
\end{pmatrix}$$ For$\lambda=\frac{13}{3}\Rightarrow r(A)=3$ and for $\lambda\neq \frac{13}{3} \Rightarrow r(A)=4$ Is this correct? Thanks!","['matrices', 'matrix-rank', 'linear-algebra']"
2122462,"If $\sin(a+b)=1$ and $\sin(a-b)=\frac{1}{2}$ wher $a \geq 0$ and $b \leq \frac{\pi}{2}$ , find value of $\tan(a+2b)$ and $\tan(2a+b)$","If $\sin(a+b)=1$ and $\sin(a-b)=\frac{1}{2}$ where $a \geq 0$ and $b \leq \frac{\pi}{2}$ , find the value of $\tan(a+2b)$ and $\tan(2a+b)$. I have tried to apply the formula for $\tan(a+(a+b))$ but couldn't reach anywhere. THANKS",['trigonometry']
2122474,locate a point inside a triangle such that the total distance from the vertices is a maximum,"In geometry, the Fermat point is a point inside or on a triangle such that the total distance from the three vertices of the triangle to the point is the minimum possible. After I studied the Fermat point, I am curious about the following Question Where is the point located inside or on a triangle such that the total distance from the three vertices of the triangle to the point is the maximum possible? I guess the point is located either on the edges or at the vertices of the triangle.","['locus', 'triangles', 'geometry']"
2122493,Show that $\mathbb{Q_p} $ is locally compact,"Suppose $\mathbb{Q_p} $ is the fraction field of $\mathbb{Z_p}$ ($p$-adic integers) i.e. $$\mathbb{Q_p} = \left\lbrace\frac{x}{y} \space \bigg{|} \space x,y \in \mathbb{Z_p} , y\neq 0 \right\rbrace$$ Now with respect to the topology defined by $d(x,y) = e^{-v_p(x-y)}$ ($v_p$ is the $p$-adic valuation) , we need to show that $\mathbb{Q_p} $ is locally compact. Any suggestions?","['p-adic-number-theory', 'topological-groups', 'algebraic-number-theory', 'number-theory', 'general-topology']"
2122503,A graph theoretical/combinatorial problem,"I'll try to describe a problem that I am currently working on, hoping to get some direction out of anyone possibly interested in the problem. Let $G_1=([n],E_1), G_2=([n],E_2)$, such that $E_1\bigcup E_2 = {[n]\choose 2}, E_1\bigcap E_2 = \emptyset$. I.e. $E_1$ and $E_2$ form a partition of the complete graph. Observe the following process, consisting of two sides, god and the devil. At each step the devil chooses a graph, for example - $G_1$, and constructs a partition of its edges into two subsets, say $A, B$, i.e. $A\bigcup B = E_1$ and $A\bigcap B = \emptyset$. God, in his turn can choose either $A$ or $B$, say he chose $A$, now $G_1=([n],A)$. And they continue to another iteration. God's objective is to maximize the set of vertices $V:=\{i\in[n]|d_1(i),d_2(i) > 0\}$. I.e., to maximize the set of vertices with positive degree on both graphs, while the devil's goal is adverserial, he wishes to form partitions that would minimize the size $|V|$. I can prove that for all graphs $G_1,G_2$ such that all vertices have degree of $n/2(1\pm o(1))$, and for all adversarial strategies of the devil, there exists a strategy for god (a choice of partitions) such that after $k$ steps, $|V|\ge\dfrac{n}{2^k}$. My goal is to show that there exist graphs $G_1, G_2$ such that for all adversarial strategies, there exist counter strategies that would guaranty $|V|\ge\dfrac{n}{2^{k/2}}$. It can be shown using chernoff that the degree requirement holds for $G_1$ chosen according to $G(n,0.5)$ and $G_2$ being its complement with high probability. Some thoughts: I am convinced that with high probability choosing $G_1=G_{n,0.5}$ and $G_2$ to be its complement would be good candidates for the conjecture. Simply choosing the side with the larger cardinality at each step doesn't work. I have constructed a simple strategy that dictates god's choice at each step according to the following rule, that I suspect to be optimal strategy but I am short of proving it: Given a partition of $G_1$'s edges into two subsets $A$ and $B$, choose the set that maximizes $\Sigma_{(u,v)\in C}d_2(u) + d_2(v)$ for $C\in \{A,B\}$. The idea is defining a potential function $\Phi = \Sigma_{(u,v)\in E_1}d_2(u) + d_2(v)$ and taking notice that for a partition of $E_1$ into $A,B$ it holds that: $\Phi = \Sigma_{E_1} = \Sigma_A + \Sigma_B$, therefore there is a choice of either $A$ or $B$ that decreases $\Phi$ by a factor of at most $2$. $\Phi$ is also symmetric as it can be rewritten as $\Sigma_{i\in [n]}d_1(i)d_2(i)$. It can be (easily) shown that choosing according to this strategy guaranties $|V|\ge\dfrac{n}{2^k}$ for all graphs. I suspect that it is an optimal strategy that would also yield the conjectured lower bound for the random graph $G(n,0.5)$ and its complement. This is the problem, and those are some of my main thoughts. A simpler problem that I also can't solve would be to show that for 2 steps I can guaranty $|V|\ge n/2$. I hope I was clear, and will remain available to make any clarifications required. Edit: I am interested in proving that there exists a strategy for the case where $k\le c\log n$ for some $c\in (0,1)$ and in particular would be happy in showing, as stated above, the existence of such strategy in case $k=2$. Thanks! :)","['graph-theory', 'random-graphs', 'probability', 'combinatorics', 'research']"
2122527,Fields having exactly one quadratic extension (up to isomorphism),"Let $F$ be an infinite field such that $F$ has, up to field isomorphisms$^{[1]}$, exactly one extension $K/F$ of degree $2$. Does it imply  that $[\overline F : F]<\infty$ ? What happens if $F$ has characteristic $0$? I don't think that this holds, even if characteristic $0$, but I didn't have an example of a field $F$ of characteristic $0$ ($\implies F$ is infinite) such that $[\overline F : F] = \infty$ and in $F^*$, any product of two non-squares is a square, and there is at least one non-square (see 4) below). My thoughts: 1) The only example of such $F$ I know is $\Bbb R$: any quadratic extension embeds in $\Bbb C$, which has already degree $2$ over $\Bbb R$. My question is to know if other examples exist: if $[\overline F : F]<\infty$ then (by Artin-Schreier theorem) $F$ is a real closed field . 2) Any finite field $\Bbb F_q$ has exactly one extension of degree $n$ (namely $\Bbb F_{q^n}$), up to field isomorphisms, for every $n \geq 1$. 3) It implies that all the quadratic extensions are isomorphic as fields, but this is not sufficient, precisely when $F$ has no quadratic extension , e.g. $\overline F=F$ (or $\bigcup_{n \geq 0} K_n$, with $K_0=\Bbb Q,K_{n+1}=\{x \in \Bbb C \mid x^2 \in K_n\}$). 4) In characteristic different from $2$, any quadratic extension of $F$ is separable and has the form $F(\sqrt a)$ where $\sqrt a \not \in F$.
Therefore, as mentioned here , the quadratic extensions of $F$ correpond to $A:=F^* / F^{*,2}$ where $F^{*,2} = \{x^2 \mid \in F^*\}$. 
Notice that $A$ is a $\Bbb F_2$-vector space, via $[a]_2 \cdot [x]_{F^{*,2}} = [x^a]_{F^{*,2}}$. So the most interesting case is when we are looking for fields of characteristic $\neq 2$ such that $A=F^* / F^{*,2}$ has order $2$ . Equivalently, in $F^*$, any product of two non-squares is a square, and there is at least one non-square (because $x,y$ non squares $\implies x,1/y$ non-squares $\implies x/y = a^2 \in F^{*,2} \implies [x]_{F^{*,2}} = [y]_{F^{*,2}}$). Let $a$ be a non-square in $F^*$ and let $i = \sqrt a$. Showing that $F(i)$ is algebraically closed is not reasonable. Notice that this condition about $[F^* : F^{*,2}]=2$ is involved in 3. here , which is precisely the situation where $a=-1$ is not a square. Then I thought to some extension $F$ of $K=\mathrm{Frac}(\Bbb R[x,y]/(x^2+y^2+1))$ since $-1$ is not a square in $K^*$ but is a sum of squares ; we just need $[F^* : F^{*,2}]=2$, and then it's a counterexample, since $F$ won't be a formally real field . I only know how to do $[F^* : F^{*,2}]=1$, see my $K_n$'s in 3). 5) I tried $F = \overline{\Bbb F_2}(t)$, because $t^{1/n}$ has degree $n$ for any $n$, so $[\overline F :F]=\infty$. I think that any extension $F\left(\sqrt{P(t)/Q(t)}\right)$ is isomorphic to $F(\sqrt t) = \overline{\Bbb F_2}(\sqrt t)$ when $P,Q \in \overline{\Bbb F_2}[t]$ i.e. $P/Q \in F$, because we have $\sqrt{a+b}=\sqrt a + \sqrt b$ in the sense that $x^2=a,y^2=b \implies (x+y)^2 = a+b$, so that $\sqrt{P(t)/Q(t)}$ is just a rational fraction in $\sqrt t$, i.e. belongs to $F(\sqrt t)$.
However, in characteristic $2$ , it is not clear that all quadratic extensions arise as $F(\sqrt a)$ for some non-square $a \in F$. 6) In characteristic 0 (at least $\neq 2$), it is not clear that $F(\sqrt{t+1}) \not \cong F(\sqrt t)$. If there was a field isomorphism, then there is $u \in  F(\sqrt t)$ such that $u^2=t+1$, hence there are $a,b \in F[t]$ such that $(a(\sqrt t)/b(\sqrt t))^2 = t+1$, which yields
$a(x)^2=(x^2+1)b(x)^2$ as polynomials in $F[x]$... $^{[1]}$ I'm only interested in fields isomorphisms, not in ""field extensions"" isomorphisms (i.e. not in $F$-algebras isomorphisms – these are equivalent to saying that $f : K \stackrel{\cong}{\to} K'$ commutes with the embeddings $i : F \to K$ and $i' : F \to K'$).","['abstract-algebra', 'extension-field', 'field-theory']"
2122536,"$f: \mathbb R^2 \to \mathbb R$ be a function whose restriction on the graph of any continuous function on open set is continuous , is $f$ continuous?","Let $f: \mathbb R^2 \to \mathbb R$ be a function such that for every open set $U \subseteq \mathbb R$ and continuous function $h:U \to \mathbb R$ , $f|_{G(h)} : G(h) \to \mathbb R$ is continuous ($G(h):=\{(x,h(x))|x \in U\}$) , then is it true that $f$ is continuous ?","['multivariable-calculus', 'metric-spaces', 'continuity']"
2122553,How to analytically find the length of the gap between five tetrahedra,The tetrahedra are regular with side lengths 1 and are joined face-to-face. How do I determine the length $AB\approx0.111111\dots$ analytically?,"['trigonometry', 'geometry']"
2122591,Prove that $f(x) = \lim_{\epsilon\rightarrow 0}\frac{1}{Vol(B_\epsilon(x))}\int_{B_\epsilon(x)}f(y)dV$,"Let $f:\mathbb{R}^3\rightarrow\mathbb{R}$ be a continuous function. Prove that $f(x) = \lim_{\epsilon\rightarrow 0}\frac{1}{Vol(B_\epsilon(x))}\int_{B_\epsilon(x)}f(y)dV$ where $B_\epsilon(x)$ denotes the ball of radius $\epsilon$ centered at $x$, and $Vol(B_\epsilon(x))$ denotes its volume. My attempt: Intuitively, this makes sense, as when you decrease the radius of the ball to $0$, you wind up at the point $x$ anyways. However, I'm having difficulties proving this rigorously. Would taking the derivative help at all?","['real-analysis', 'calculus', 'limits']"
2122615,When does $n$ divide $2^n+1$?,"For which $n$ does $n\mid2^n+1$ ? My hypothesis is that the only solution is $n=3^k$, for some positive integer $k$.","['number-theory', 'divisibility', 'elementary-number-theory']"
2122628,How to Simplify : sin x / ( 1 + cos x ) [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question I want to simplify this expression to contain 2 or fewer terms.  Is this possible, and if so, what are the steps I can take to do so? sin x / ( 1 + cos x )",['trigonometry']
2122703,Solve $(y* \sin)(t)=t^2$,"Solve $(y* \sin)(t)=t^2$ What I did: We know that
$$\mathscr{L} \{ y(t) \}=Y(s)\quad\mathscr{L} \{ \sin(t) \}=\frac{1}{s^2+1} \quad\mathscr{L} \{ t^2 \}=\frac{1}{s^3} \quad\mathscr{L} \{ f(t)*g(t) \}=F(s) \ G(s)$$
hence
$$Y(s)=\frac{s^2+1}{s^3}=\frac{A}{s^3}+\frac{B}{s^2}+\frac{C}{s}$$
with
$$A=\lim_{s\rightarrow 0}\ s^2+1=1$$
$$B=\lim_{s\rightarrow 0} \ D(s^2+1)=\lim_{s\rightarrow 0} \ 2s=0$$
$$C=\frac{1}{2} \lim_{s\rightarrow 0} \ D^2(s^2+1)=\frac{1}{2} \lim_{s\rightarrow 0} \ 2=1$$
hence
$$Y(s)=\frac{1}{s^3}+\frac{1}{s}$$
and
$$y(t)=t^2+1$$ Is this correct?","['laplace-transform', 'convolution', 'analysis']"
2122753,Find the derivative of $f=\arcsin\left(\frac{2x}{1+x^2}\right)$,I'm trying to find the derivative of $f=\arcsin\left(\frac{2x}{1+x^2}\right)$. I think I'm mistaken and perhaps using the chain rule incorrectly. Let $g(x) = \frac{2x}{1+x^2}$ and let $h(x) = \arcsin x$ According to the chain rule - $$f'(x) = \frac{1}{\sqrt{1-\frac{2x}{1+x^2}}}⋅((2⋅(1+x^2 )-2x⋅2x)/(1+x^2 )^2 ) = \cdots \frac{-2(x^4-1)}{x-1}$$ Is this a correct usage of the chain rule?,"['derivatives', 'chain-rule', 'functions', 'limits']"
2122778,If $\sum a_n$ converges then $\liminf na_n=0$,"I am trying to prove the following statement: Let $(a_n)_{n\in\mathbb N}$ be a positive sequence such that the series $\sum a_n$ is convergent. Prove that $$\liminf_{n}na_n=0$$ Now, if $(a_n)_{n\in \mathbb N}$ is a real valued sequence, then $\liminf a_n=\alpha$ if and only if the following two conditions hold: If $\beta \in \mathbb R \cup \{\pm \infty\}$ is such that $\beta<\alpha$ there exists $n_0\in \mathbb N$ such that $a_n>\beta$ for every $n>n_0$ There exists a subsequence $(a_{\varphi (k)})_{k\in \mathbb N}$ of $(a_n)_{n\in \mathbb N}$ that converges to $\alpha$. The first one is trivial since $(na_n)_{n\in \mathbb N}$ is positive, so the problem basically boils down to constructing a subsequence on $na_n$ that converges to zero. The given hypothesis implies that $a_n\to 0$ and that $a_n<\frac{1}{n}$ eventually, but I cannot seem to be able to use these bits of information to construct a subsequence that converges to $0$. I also tried by contradiction, assuming that $\liminf na_n\neq 0$, but did not get very far. This brings me to the two following questions: Is it possible to explicitly construct a subsequence of $(na_n)_{n\in \mathbb N}$ that converges to zero? How can I prove the given statement?","['real-analysis', 'sequences-and-series', 'limits']"
2122795,Restriction of self-adjoint operator self-adjoint?,"Consider an unbounded self-adjoint operator $A$ on a Hilbert space $\mathcal{H}$. Let $\mathcal{J} \subset \mathcal{H}$ a closed subspace reducing $A$, i.e. such that $P A \subset A P$ where $P$ denotes orthogonal projection onto $J$. Equivalently, $P \mathcal{D}(A) \subset \mathcal{D}(A)$ and $P A \psi = A P \psi$ for all $\psi \in \mathcal{D}(A)$. Then the restriction $A|\mathcal{J}$ is a densely defined operator on $\mathcal{J}$ with domain $\mathcal{D}(A) \cap \mathcal{J}$. My question is this: is $A|\mathcal{J}$ again self-adjoint? The reason I am interested in this question is the following: Take $\mathcal{H} = L^2(\mathbb{R}^{3N})$, and $\mathcal{J} = \Lambda L^2(\mathbb{R}^{3N})$, where the $\Lambda$ denotes the totally antisymmetric subspace, i.e. those functions $\psi(\vec{x_1},...,\vec{x_N})$ with the property that for any permutation $\sigma \in S^N$, \begin{equation}
\psi(\vec{x_{\sigma(1)}},...,\vec{x_{\sigma(N)}}) = sign(\sigma) \psi(\vec{x_1},...,\vec{x_N})
\end{equation} Then $\mathcal{H}$ is the phase space of an atom consisting of $N$ electrons, with the nucleus fixed at the origin, and $\mathcal{J}$ is the phase space for the same system, but respecting the Pauli principle. My operator on $\mathcal{H}$ is the self-adjoint operator given by \begin{equation}
H^N = - \sum_{j=1}^{N} \Delta_j + \sum_{j = 1}^{N} V_{en}(x_j) + \sum_{i < j} V_{ee}(x_i - x_j)
\end{equation} where the $V_{ee}$ terms denote electron-electron repulsion, and $V_{en}$ electron-nucleus attraction. In fact, in this case I know of a proof: since the Fourier transform maps antisymmetric functions to antisymmetric functions, one can first show that $H_0 = - \Delta$ is self-adjoint when restricted to $\mathcal{J}$. Then use the fact that the remaining terms are $H_0$-bounded with $H_0$-bound $0$, which remains true for the restriction. I am aware of the related question at Selfadjoint operators . However, the case I am interested in is very different, in the sense that the restricted operator $A|\mathcal{J}$ is considered an operator on $\mathcal{J}$ rather than on the full Hilbert space $\mathcal{H}$. Indeed, considering $A|\mathcal{J}$ to be an operator on $\mathcal{H}$, it is in general (and certainly in my case) not even densely defined.","['functional-analysis', 'quantum-mechanics', 'unbounded-operators']"
2122803,Find the determinant of order $100$,"Find the determinant of order $100$: $$D=\begin{vmatrix}
5 &5 &5 &\ldots &5 &5 &-1\\
5 &5 &5 &\ldots &5 &-1 &5\\
5 &5 &5 &\ldots &-1 &5 &5\\
\vdots &\vdots &\vdots &\ddots &\vdots &\vdots &\vdots\\
5 &5 &-1 &\ldots &5 &5 &5\\
5 &-1 &5 &\ldots &5 &5 &5\\
-1 &5 &5 &\ldots &5 &5 &5
\end{vmatrix}$$ I think I should be using recurrence relations here but I'm not entirely sure how that method works. I tried this: Multiplying the first row by $(-1)$ and adding it to all rows: 
$$D=\begin{vmatrix}
5 &5 &5 &\ldots &5 &5 &-1\\
5 &5 &5 &\ldots &5 &-1 &5\\
5 &5 &5 &\ldots &-1 &5 &5\\
\vdots &\vdots &\vdots &\ddots &\vdots &\vdots &\vdots\\
5 &5 &-1 &\ldots &5 &5 &5\\
5 &-1 &5 &\ldots &5 &5 &5\\
-1 &5 &5 &\ldots &5 &5 &5
\end{vmatrix}=\begin{vmatrix}
5 &5 &5 &\ldots &5 &5 &-1\\
0 &0 &0 &\ldots &0 &-6 &6\\
0 &0 &0 &\ldots &-6 &0 &6\\
\vdots &\vdots &\vdots &\ddots &\vdots &\vdots &\vdots\\
0 &0 &-6 &\ldots &0 &0 &6\\\
0 &-6 &0 &\ldots &0 &0 &6\\
-6 &0 &0 &\ldots &0 &0 &6
\end{vmatrix}$$ Applying Laplace's method to the first column $$D=5\begin{vmatrix}
0 &0  &\ldots &0 &-6 &6\\
0 &0 &\ldots &-6 &0 &6\\
\vdots &\vdots &\ddots &\vdots &\vdots &\vdots\\
0 &-6 &\ldots &0 &0 &6\\
-6 &0 &\ldots &0 &0 &6
\end{vmatrix}+6\begin{vmatrix}
5 &5 &\ldots &5 &5 &-1\\
0 &0 &\ldots &0 &-6 &6\\
0 &0 &\ldots &-6 &0 &6\\
\vdots &\vdots &\ddots &\vdots &\vdots &\vdots\\
0 &-6 &\ldots &0 &0 &6\\
-6 &0 &\ldots &0 &0 &6
\end{vmatrix}$$ I can see that this one is $D$ but of order $99$...Is this leading anywhere? How would you solve this?","['matrices', 'linear-algebra', 'determinant']"
2122841,$\lim _{x\to 0}\left(\frac{\tan\left(x\right)-x}{x-\sin\left(x\right)}\right)$ without L'Hopital's Rule,"Here are the functions: a) $\displaystyle\lim _{x\to 0}\left(\frac{\tan\left(x\right)-x}{x-\sin\left(x\right)}\right)$ If I used L'Hopital's rule the limit is $2$ b) $\displaystyle\lim _{x\to 0}\:\frac{e^x\cdot \:\sin\left(x\right)-x\cdot \left(1+x\right)}{x^3}$ here $\dfrac{1}{3}$ c) $\displaystyle\lim _{x\to 0}\left(\frac{\ln\left(\sin\left(3 x\right)\right)}{\ln\left(\sin\left(7x\right)\right)}\right)$ and here $1$ but the problem is that I am not allowed to use L'Hopital's rule, can you give me ideas for another type of approaches? UPDATE: I apologize, I see there is some discussion and confusion among people, which obviously goes beyond my functions, but still I wanted to explain that I have been missing a lots of lectures recently due to illness and last week I got $0$ points for using L'hopital because we have not learnt it, so my guess was that we are not allowed this time either, but  I just talked to my tutor and he told me that just in the last lecture, they introduced L'hopital rule to us so I am free to use it. I'm very sorry.","['limits-without-lhopital', 'limits']"
2122856,Enderton's A mathematical introduction to logic: Question about $n$-tuples in the lemma,"I am reading A Mathematical Introduction to Logic by Herbert B. Enderton.
The following is an excerpt and my question pertains to the lemma below, but I provided additional information preceding the lemma, so that it appears in context. We define $n$ -tuples recursively by $$\big<x_1, \dotsc, x_{n+1}\big> = \big<\big<x_1, \dotsc, x_n\big>, \, x_{n+1}\big>$$ for $n>1$ . [...] define also $\big<x\big> = x$ ; the preceeding equation then holds also for $n=1$ . $S$ is a finite sequence (or string) of members of $A$ iff for some positive integer $n$ , we have $S = \big<x_1, \dotsc, x_n\big>$ where each $x_i \in A$ . The segment of the finite sequence $S$ is a finite sequence $$\big<x_k, x_{k+1}, \dotsc, x_{m-1}, x_m\big> \enspace \textrm{where} \enspace 1 \leq k \leq m \leq n$$ If $\big<x_1, \dotsc, x_m \big> = \big<y_1, \dotsc, y_n\big>$ , then it does not in general follow that $m = n$ . But we claim that $m$ and $n$ can be unequal only if soe $x_i$ iss itself a finite sequence of $y_j$ 's, or the other way around. Lemma 0A Assume that $\big<x_1, \dotsc, x_m\big> = \big<y_1, \dotsc, y_m, \dotsc, y_{m+k}\big>$ . Then $x_1 = \big<y_1, \, \dotsc \, , y_{k+1} \big>$ . PROOF. We use induction on $m$ . If $m=1$ , the conclusion is immediate. For the inductive step, assume that $\big<x_1, \dotsc, x_m, \, x_{m+1}\big> = \big<y_1, \, \dotsc \,, y_{m+k}, \, y_{m+k+1}\big>$ . Then the first components of this ordered pair must be equal: $\big<x_1, \, \dotsc \, , x_m\big> = \big<y_1, \, \dotsc \, , y_{m+k}\big>$ . Now apply the inductive hypothesis. Quetsions. How are $k$ and $m+k$ related to each other in the lemma? Initially, I thought they satisfied the inequality $1\leq k \leq m \leq n$ provided in the definition of a segment above, but I want to make sure. Honestly, I don't understand what the lemma is claiming or what makes it useful. Would someone explain to me what this lemma means? I've been thinking about this for a couple of days, and would like some instruction. Thanks.","['notation', 'logic', 'sequences-and-series', 'proof-explanation']"
2122916,Graphing Complicated Functions,"Recently, I was bombarded by dozens to ""sketch/graph the following function"" exercises. Some such functions are $y=x\sqrt{\frac{x}{4-x}}$ (cissoid of Diocles) , $y=e^{-x^2}$ (probability curve) , $y=x+\frac{1}{x}$ (trident of Newton) , and $y=\log{(\log x)}$. Currently, I have 2 methods: dumbly and tediously find $f(x)$ of several $x$ and plot the points; then interpolate the curve; or, plug the functions into Wolfram|Alpha (which isn't really me sketching the graph). Are there any methods that quicken the process of sketching a graph? I was thinking of a few methods, but they seem almost as tedious as functions get more complicated. For example, regarding the trident of Newton (see above): sketch $y=x$ and $y= \frac{1}{x}$ on the same graph. Then add the $y$ values to assemble the curve $y = x + \frac{1}{x}$. $^\text{Note: I added the soft-question tag because this question doesn't solve a particular problem; if this tag is not needed, feel free to remove it.}$","['soft-question', 'functions', 'graphing-functions']"
2123002,How to evaluate $\lim_{x\to +\infty} 1^{x} $?,is it  true  that : $$\lim_{x\to +\infty} 1^{x} = 1$$ because we can write this limit as : $$ \lim_{x\to +\infty} e^{~x\ln(1)}$$ but this limit is an indertminate form : $$\lim_{x\to+\infty} x\ln(1)$$ so how to evaluate this limit  ?,"['real-analysis', 'calculus', 'limits']"
2123061,Why are the axes of a quadratic form ellipse along the eigenvectors?,"Suppose $A$ is a $2$ x $2$ real symmetric matrix, then $$x'Ax =\lambda_1(e_1'x)'(e_1'x) + \lambda_2(e_2'x)'(e_2'x) = c^2$$ where $x$ is an arbitrary $2$ x $1$ vector, $e_i$ and $\lambda_i$ the eigenvectors and eigenvalues of $A$, and $c$ is a constant. If we set $y_i = e_i'x$ then the above becomes $$x'Ax =\lambda_1y_1'y_1 + \lambda_2y_2'y_2 = c^2$$
$$x'Ax =\lambda_1y_1^2 + \lambda_2y_2^2 = c^2$$ And this defines the ellipse $$\bigg(\frac{y_1}{c/\sqrt\lambda_1}\bigg)^2 + \bigg(\frac{y_2}{c/\sqrt\lambda_2}\bigg)^2 = 1$$ It's said that this ellipse has axes along the eigenvectors of $A$, because $y_i = e_i'x$. But can't this also be an ellipse along $x$? Also the eigenvectors have more than one component but the $y_i$'s are a scalar, how do you get direction from a scalar?","['linear-algebra', 'algebraic-geometry', 'geometry']"
2123068,The $n$th term of this infinitely nested radical sequence,"While playing around with some friends, we found the closed form to the sequence that goes $y_1=0$ and $y_{n+1}=\sqrt{2+y_n}$ using the half angle-formula for cosine, which you may derive to be $y_n=2\cos(\pi/2^n)$.  This let's us easily show that $$\sqrt{2+\sqrt{2+\sqrt{2+\dots}}}=\lim_{n\to\infty}2\cos(\pi/2^n)=2$$ Howeven, this does not generalize to the problem of any number beneath the radical: $$y_{n+1}=\sqrt{a+y_n},\ y_1=0\implies y_n=?$$ Does anyone know how to derive a closed form for the general case of the $n$th term in the sequence ?","['nested-radicals', 'trigonometry', 'sequences-and-series', 'closed-form']"
2123106,(Non)existence of circular arcs through set of points,"I have two circular arcs $ABCF$ and $ADEF$ which have the same endpoints $A, F$ and 'contain' the points $B, C$ and $D, E$ in the specified order. How can I prove that there cannot be a circular arc $BCDE$, i.e. one that starts in $B$, intersects $C$ before $D$ and ends in $E$? If both arcs are minor circular arcs, I can show that $B$ and $E$ must lie on different sides of the line through $C$ and $D$, hence either $BCD$ would be clockwise and $CDE$ counterclockwise or the other way around. Either way they could not form a circular arc $BCDE$ together. However the case where one (or both) are major circular arcs cause me trouble. Edit 1: Please note that the circular arcs may not overlap. Edit 2: To clarify – the 'drawing' whose (non)existence I want to prove contains circular arcs $AB, BC, CF, AD, DE, EF, BC, CD, DE$. None of these may overlap and they shall form larger circular arcs together: $ABCF$ is made of $AB, BC, CF$; $ADEF$ is made of $AD, DE, EF$; and $BCDE$ is made of $BC, CD, DE$.","['circles', 'geometry']"
2123125,Matrix Group generated by Roots of Unity,The question is essentially as follows: let $W$ be a primitive $n$-th root of unity where $n$ is an odd integer. Let $G$ be the subgroup (of $GL(n)$) of all 2x2 matrices generated by matrices $$\begin{bmatrix}0&-1\\1&0\end{bmatrix} \ \ \text{and} \ \  \begin{bmatrix} W&0\\0&W^{-1}\end{bmatrix}.$$ Prove that $G$ has order $4n.$,"['matrices', 'abstract-algebra', 'group-theory']"
2123127,Recurrence Relation : Divisible Numbers,"Given an integer, n, find the smallest integer m such that is divisible by n (i.e.n,  is a factor of m ) and satisfies the following properties: m must not contain zeroes in its decimal representation. The sum of m's digits must be greater than or equal to the product of m's digits.
Given n , find the number of digits in m's decimal representation. Note: n is not divisible by 10. How should I derive the Recurrence Relation for this problem? My approach: Suppose the n = 32, I am multiplying n by 1,2,3... and checking for the number at the units place if the number at the unit's place is greater than the largest digit of n and the number at the tens digit is greater than smallest digit of n then I ignore the m generated and move to the next multiplication. I am not able to come up with the recurrence relation for doing this operation. Please Help! Thanks!","['dynamic-programming', 'combinatorics', 'recurrence-relations']"
2123187,Period of the nonlinear ODE $y''+\cos(y) = 0$,"Suppose an equation $$ y'' + \cos(y) = 0; y(0) = y'(0) = 0 $$ Numerical solution suggest periodic behavior. But how to derive it analytically (a systematic approximate is also acceptable)? Attempt 1 Write the equation as $y''= - \cos(y)$, together with initial condition, we have $y(0) = 0, y'(0) = 0, y''(0) = -cos(y(0)) = -1$ and so on. So the Taylor expansion approximation is $y = -1/2 x^2 + ...$, but this won't tell the qualitative periodic behavior, not to mention quantitative ones. Attempt 2 With the familiar trick $y''(x) = dy'/dy \cdot dy/dx = 1/2 dy'^2 /dx$, the equation can be reduced to first order (initial condition used): $y'^2 + 2 sin(y) = 0$. But I don't know how to proceed with this either. Numerical solution is presented in figure below, the blue curve (get out of plot range around x > 3) is the Taylor series approximation $-1/2x^2$, the yellow and green curves overlap a lot, one is the numerical solution, another is an eyeball fitting with this function ($T\sim 7.4$):
$$ \frac{\pi}{2} (\cos(2\pi x/T )-1) $$","['ordinary-differential-equations', 'dynamical-systems', 'nonlinear-system']"
2123218,"Right Triangle: Given hypotenuse and ratio of legs, find legs","We are given a Right triangle where the Hypotenuse = $20$ cm.
The opposite side is $3$ times longer than the bottom side. 
Is it possible to calculate the length of the opposite side? 
(Tried substitution)
$$a^2 + b^2 = 400$$
$$a = 3b$$
$$(3b)^2 + b^2 = 400$$
$b = 10$ = not correct",['geometry']
2123242,Solve $y ^2-x(\frac{dy}{dx})^2 = 1$ using proposed change of variables,"I am kind of stuck with this non linear differential. I am preparing for my finals and I cannot get this one. Full question goes like this: Find all the solutions to the equation $y ^2-x(\frac{dy}{dx})^2 - 1= 0$ stating in each case the maximal solution interval. Hint: Use $u=y'\sqrt{-x},\,x<0$
and $u=y'\sqrt{x},\,x>0$ Also the final solutions are also given: $y=1$ and $y=-1 \quad\forall x $ $y(x)=cosh(2\sqrt{x}+K),\quad x>0$ $y=cos(2\sqrt{-x}+K),\quad x<0$ What I have done so far.
Let $u=y'\sqrt{x}\Rightarrow u'=y''\sqrt{x}+y'\frac{1}{2\sqrt{x}}$ and I plug it into the original equation and I differentiate w.r.t x: $y^2-u^2=1\Rightarrow 2yy'-2u(y''\sqrt{x}+\frac{y'}{2\sqrt{x}})=0$. Switching back the change $u=y'\sqrt{x},\,x>0$ we get: $2yy'-2y'\sqrt{x}(y''\sqrt{x}+\frac{y'}{\sqrt{x}})=yy'-y'y''x-y'^2
=y'(y-y''x-y')=0$. So we get $y'=0 \Rightarrow y=C$, which is not one of the stated solutions or $(y-y''x-y')=0$ which does not make a lot of sense to me as we ended up with a second order equation, which needs two arbitrary constants, when we actually started with a first order equation. I actually got the first three solutions using a different approach, which is not the one hinted, but I posted nonetheless in case it might help someone in order to help me :) $y'^2=\frac{y^2-1}{x}\Rightarrow\frac{1}{\sqrt{y^2-1}}dy=\pm\frac{1}{\sqrt{x}}dx$. Solutions $y=\pm 1$ appear at this step. Using the substitution $y=cosht$ we get $t=\pm2\sqrt{x}+C$ which gives the third one: $y=cosh(2\sqrt{x}+C)$. However I just cannot get the proposed substitution to work and I cannot find the last solution when x is negative.
Any help is really appreciated!!!! Thanks!!!",['ordinary-differential-equations']
2123271,Methods for choosing $u$ and $dv$ when integrating by parts?,"When doing integration by parts, how do you know which part should be $u$ ? For example, For the following:
$$\int x^2e^xdx$$ $u = x^2$? However for:
$$\int \sqrt{x}\ln xdx$$ $u = \ln x$? Is there a rule for which part should be $u$ ? As this is confusing.","['integration', 'integration-by-parts', 'calculus']"
2123298,"What is $\, _4F_3\left(1,1,1,\frac{3}{2};\frac{5}{2},\frac{5}{2},\frac{5}{2};1\right)$?","I have been trying to evaluate the series $$\, _4F_3\left(1,1,1,\frac{3}{2};\frac{5}{2},\frac{5}{2},\frac{5}{2};1\right) = 1.133928715547935...$$ using integration techniques, and I was wondering if there is any simple way of finding a closed-form evaluation of this hypergeometric series.  What is a closed-form expression for the above series?","['hypergeometric-function', 'sequences-and-series', 'calculus', 'closed-form']"
2123343,Everywhere Super Dense Subset of $\mathbb{R}$,"First, this question is motivated by the imprecise question: Is there a sensible notion of parity (evenness and oddness) for real numbers? Here are some properties a notion of parity for $\mathbb{R}$ should have: It should be an equivalence relation on $\mathbb{R}$ with exactly two equivalence classes. Each equivalence class should be dense in $\mathbb{R}$. There should be some kind of symmetry between the two equivalence classes. (This is intentionally imprecise.) If we divide $\mathbb{R}$ into rationals and irrationals, this lacks symmetry, since the rationals have measure zero and are countable, while the rationals have infinite measure and are uncountable. So we could require that each equivalence class be uncountable and/or have positive (or infinite) measure. Then take one equivalence class to be the rationals, union with countably many fat cantor sets with positive measure, and the other class its complement. Then both classes are now dense, uncountable, and have infinite measure. But again, symmetry is lacking. One of these classes is ""uncountable everywhere"" and has ""positive measure everywhere"" while the other does not. I propose some definitions: A subset $A \subset \mathbb{R}$ is uncountable everywhere if for any open interval $(a,b)$, the intersection $A \cap (a,b)$ is uncountable. A subset $A \subset \mathbb{R}$ has positive measure everywhere if for every open interval $(a,b)$, the intersection $A \cap (a,b)$ has positive measure. We can see immediately that having positive measure everywhere implies being uncountable everywhere, since a positive measure set must be uncountable. Finally, my questions: Is there a partition of $\mathbb{R}$ into two sets that are both
uncountable everywhere? Is there a partition of $\mathbb{R}$ into
two sets that both have positive measure everywhere? Is there a partition of $\mathbb{R}$ into two sets that split each interval $(a,b)$ into two parts of equal measure? Potential generalizations for extra credit: What about partitions of $\mathbb{R}$ with $n$ equivalence classes, where $n \in \mathbb{N}$, or even with countably many, or even uncountably many equivalence classes? Note: If you've seen these definitions of uncountable everywhere or positive measure everywhere somewhere under a different name, please let me know. I've never found anything where other people were thinking about these notions. EDIT: By ""measure,"" I mean Lebesgue outer measure, so we don't have to worry about anything being measurable.",['real-analysis']
2123377,$A=\emptyset $ if and only if $B = A \bigtriangleup B$,"Is this true? If $A$ and $B$ are sets, then $A=\emptyset $ if and only if $B = A \bigtriangleup B$. If $A=\emptyset$ then $B=\emptyset$ too? Could someone help me please?","['algebra-precalculus', 'elementary-set-theory']"
2123388,Find a formula for $\cos(5x)$ in terms of $\sin(x)$ and $\cos(x)$,"I was asked to find a formula for $\cos(5x)$ in terms of $\sin(x)$ and $\cos(x)$. I tried to use the formula $\cos(5x) + i\sin(5x) = (\cos(x)+i\sin(x))^5  
$ and what I get is 
$16i\sin^5(x) - 20i\sin^3(x) + 5i\sin(x) + \cos(x) + 16 \sin^4(x) \cos(x) - 12 \sin^2(x) \cos(x)$ But how do I deal with the $i\sin(5x)$? Because I only can use $\sin(x)$ and $\cos(x)$ to express $\cos(5x)$. Thank you for your help!","['complex-analysis', 'trigonometry', 'complex-numbers']"
2123430,Show that $\frac {1} {r-1} = \frac {1} {r+1} + \frac {2} {r^2+1} + \frac {4} {r^4+1} +\cdots$,"Problem: Show that
$$\frac {1} {r-1} = \frac {1} {r+1} + \frac {2} {r^2+1} + \frac {4} {r^4+1} +\cdots $$
for all $r > 1$, with a hint given that $\displaystyle\frac {1} {r-1} - \frac {1} {r+1} = \frac {2} {r^2-1}$. Thoughts :
I am having difficulty seeing a connection from the hint to the problem. Any insights appreciated.","['sequences-and-series', 'analysis']"
2123461,On the equivalence of two definitions for summations over the integers,"If $a_k\in\mathbb{C}$, then define
$$
\sum_{k=-\infty}^{\infty}a_k=L\\
\Updownarrow\\\forall\epsilon>0,\exists N,m,n> N\implies\left|\sum_{k=-m}^na_k-L\right|<\epsilon
$$ Question: Is it true that $$
\sum_{k=-\infty}^{\infty}a_k=L\\
\Updownarrow\\
\sum_{k=0}^{\infty}a_k\text{ and }\sum_{k=1}^{\infty}a_{-k}\text{ both exist and }\sum_{k=0}^{\infty}a_k+\sum_{k=1}^{\infty}a_{-k}=L
$$ Thoughts: $[\Downarrow]$ Couldn't come up with something useful. Tried to show that both series are Cauchy. Failed. $[\Uparrow]$ Let
$$
\alpha:=\sum_{k=0}^{\infty}a_k\\
\beta:=\sum_{k=1}^{\infty}a_{-k}
$$
Given $\epsilon>0$, there exist $N_1,N_2$ such that
$$
\left|\sum_{k=0}^na_k-\alpha\right|<\frac{\epsilon}{2}\\
\left|\sum_{k=1}^ma_{-k}-\beta\right|<\frac{\epsilon}{2}
$$
whenever $n>N_1$ and $m>N_2$. Hence if $N:=\max\{N_1,N_2\}$ then
\begin{align}
\left|\sum_{k=-m}^na_k-L\right|&=\left|\sum_{k=0}^na_k-\alpha+\sum_{k=1}^ma_{-k}-\beta\right|\\
&\leq\left|\sum_{k=0}^na_k-\alpha\right|+\left|\sum_{k=1}^ma_{-k}-\beta\right|\\
&<\frac{\epsilon}{2}+\frac{\epsilon}{2}\\
&=\epsilon
\end{align}
whenever $m,n>N$.","['real-analysis', 'sequences-and-series', 'calculus', 'convergence-divergence', 'analysis']"
2123487,Recurrence Relation T(n)=T(n/8)+T(n/4)+lg(n),"Recurrence Relation T(n)=T(n/8)+T(n/4)+lg(n) I have been doing recurrence relations, but I just can't even get this one started. I tried iteration method, but don't think that's a good way to go about it and couldn't get anywhere. A friend told me master method should work, and another said substitution, but haven't had luck with either. Edit: Just started learning, so assume I'm a beginner to this material. Edit2: I've been told the answer is $n\lg(n)$ (base-2), but I still can't see how you would arrive to that.","['recurrence-relations', 'algorithms', 'discrete-mathematics']"
2123514,|sin(nx/2)/sin(x/2)| <= n,"I have this assignnent Show that 
$$\left|\frac{sin(\frac{nx}{2})} {sin(\frac{x}{2})}\right| \leq n \space (x \ne 0,\pm2\pi, \pm4\pi, ...)$$ The question comes with an hint Argue first that $z = e^{ix}$ Then the left-side equals $ |\frac{1 - z^n} {1 - z}| $ I have managed to solve other questions in the assignment but this one has been problematic. Any help would be appreciated. Thanks in Advance.","['complex-analysis', 'inequality', 'trigonometry', 'analysis']"
2123577,Conditional probability of spam,"I got that $P(A_1) = 0.07875, P(A_2) = 0.008, P(A_3) = 0.0625$, we know that $$P(\text{Spam} \mid A_1A_2A_3) = \frac{P(\text{Spam} \cap A_1A_2A_3)}{P(A_1A_2A_3)}$$ We know that $\{A_1, A_2, A_3\}$ is an independent set., so $P(A_1A_2A_3) = 0.00039375$ I cant figure out $P(\text{spam} \times A_1A_2A_3)$? But I'm not sure of numerator?","['statistics', 'probability']"
2123603,Why is sheaf Hom left-exact?,"Fix a ringed space $(X,\mathcal{O}_X)$ and two sheaves of $\mathcal{O}_X$-modules $\mathscr{F}$ and $\mathscr{G}$, then we can define the sheaf $\mathscr{H}\!\mathit{om}_{\mathcal{O}_X}(\mathscr{F},\mathscr{G})$ by setting $$\mathscr{H}\!\mathit{om}_{\mathcal{O}_X}(\mathscr{F},\mathscr{G})(U)=\mathrm{Hom}_{\mathcal{O}_X\vert_U}(\mathscr{F}\vert_U,\mathscr{G}\vert_U)$$ with the obvious restriction maps, so that using maps of $\mathcal{O}_X$-modules $\varphi:\mathscr{G}\to\mathscr{G}'$ and $\psi:\mathscr{F}'\to\mathscr{F}$ we can induce maps $$\mathscr{H}\!\mathit{om}_{\mathcal{O}_X}(\mathscr{F},\mathscr{G})\to \mathscr{H}\!\mathit{om}_{\mathcal{O}_X}(\mathscr{F},\mathscr{G}')$$ and $$\mathscr{H}\!\mathit{om}_{\mathcal{O}_X}(\mathscr{F},\mathscr{G})\to\mathscr{H}\!\mathit{om}_{\mathcal{O}_X}(\mathscr{F'},\mathscr{G})$$ given on the open set $U$ by $$f\mapsto \varphi\vert_U\circ f$$ and $$f\mapsto f\circ\psi\vert_U$$ respectively. Now, Lemma 17.20.12 of the Stacks Project claims that any short exact sequence $$0\to\mathscr{F}_1\to\mathscr{F}_2\to\mathscr{F}_3\to 0$$ induces exact sequences $$0\to\mathscr{H}\!\mathit{om}_{\mathcal{O}_X}(\mathscr{F_3},\mathscr{G})\to\mathscr{H}\!\mathit{om}_{\mathcal{O}_X}(\mathscr{F_2},\mathscr{G})\to\mathscr{H}\!\mathit{om}_{\mathcal{O}_X}(\mathscr{F_1},\mathscr{G})$$ and $$0\to\mathscr{H}\!\mathit{om}_{\mathcal{O}_X}(\mathscr{G},\mathscr{F_1})\to\mathscr{H}\!\mathit{om}_{\mathcal{O}_X}(\mathscr{G},\mathscr{F_2})\to\mathscr{H}\!\mathit{om}_{\mathcal{O}_X}(\mathscr{G},\mathscr{F_3})$$ Now, I can prove that the first (nontrivial) map is injective in both cases, but I don't see how to show exactness in the middle.","['sheaf-theory', 'homological-algebra', 'algebraic-geometry', 'commutative-algebra']"
2123633,Write $\sum\limits_{n=0}^\infty e^{-xn^3}$ in the form $\sum\limits_{n=-\infty}^\infty a_nx^n$,"This is a very simple question; I apologize if it has already been asked here. Define the following function (superficially similar to a theta function ): $$\varsigma(x)=\sum_{n=1}^\infty e^{-xn^3}$$ I am interested in knowing the Laurent series about $x=0$ of this series if it exists, i.e. I would like to know if there exist $\{a_n\}$ such that: $$\varsigma(x)=\sum_{n=-\infty}^\infty a_nx^n\tag{1}$$ for small enough $x>0$. I'm pretty sure that $\varsigma(x)$ diverges to infinity at $x=0$ so I assume that some of the $a_n$ for $n<0$ will be nonzero. Ideally I would love a closed form for the $a_n$ but I am especially interested for the moment in $a_1$. I have no idea how to find these terms, since this is not a Taylor series and since I do not know the complex behaviour of $\varsigma(z)$. Wolfram Alpha doesn't help me either. I am aware of the formula for Laurent series coefficients, and that for instance we will have: $$a_1=\frac{1}{2\pi i}\oint_C \frac{\varsigma(z)}{z^2}\;dz$$ where $C$ is a closed contour around $z=0$, but I am not sure how I should go about evaluating this; formally interchanging integral and sum only gives me a divergent sum : for instance making use of the fact that $e^{az}=\sum\limits_{n=0}^\infty \frac{a^nz^n}{n!}$ I formally get $a_1=-\sum\limits_{n=1}^\infty n^3$ but I don't know whether I can make this argument rigorous to get $a_1=-\zeta(-3)$. Background : This question arose from some recreational thoughts of mine on summing divergent series ; this answer used an $ne^{-\epsilon n}$ regularization rather than the usual $n^s$ to 'evaluate' $\sum\limits_{n=1}^\infty n$ and curiously obtained a constant term of $-\frac{1}{12}$ in the Laurent series in $\epsilon$; this interested me and made me wonder what an $n^3e^{-\epsilon n^3}$ regularization of $\sum\limits_{n=1}^\infty n^3$ would give. We have $\sum\limits_{n=1}^\infty n^3e^{-\epsilon n^3}=-\varsigma'(\epsilon)$ so the constant term in the Laurent series expansion of this function will be $-a_1$; thus I would conjecture that $a_1=-\frac{1}{120}$ (i.e. $-\zeta(-3)$; see here ). The above calculation supports this, but I don't know whether it can be made rigorous. Thus I have the following questions : Do there exist $a_n$ such that $(1)$ holds for small $x>0$? If so, does $a_1=-\frac{1}{120}$? Is it possible to write a closed form for the $a_n$?","['calculus', 'closed-form', 'complex-analysis', 'recreational-mathematics', 'sequences-and-series']"
2123638,"Let $X \sim \operatorname{Exp}(\theta)$. Show that $Y = \mathrm{e}^{-X/\theta} \sim \operatorname{Uniform}(0,1]$.","Let $X \sim \operatorname{Exp}(\theta)$. Show that $Y = \mathrm{e}^{-X/\theta} \sim \operatorname{Uniform}(0,1]$. Hi, I tried to prove this in my tutorial but I got stuck trying to prove it using MGF. Can someone help me with the first method? I was planning to get the $My(t)$ expression to see if I can see any similarity with that of a uniform distribution. Is my train of thoughts correct? I also tried to prove using the pdf of $Y$. I have written my questions in red, and I was wondering how to prove the part where the uniform distribution is valid from $0$ (exclusive) to $1$ inclusive. Attached are my workings, I hope someone can enlighten me on this! thank you! EDIT:
**I have taken down my detailed workings as I have verified that the workings are correct.* To answer my above questions, The  $My(t)$ expression can be gotten via a direct integration from E($\mathrm{e}^{tY}$) , and then a comparison of that with the  $Mx(t)$ of a uniform distribution. Also, the Uniform distribution is valid (0,1] because the exp distribution is valid from x more than or equals to 0.","['statistics', 'probability', 'moment-generating-functions', 'probability-distributions']"
2123642,"If the radius of convergence of the power series $a$ is positive then it ""reciprocal"" power series have positive radius of convergence","Im trying to solve this exercise from the book Analysis I of Amann and Escher (page 216, exercise 9). Let $a=\sum a_k X^k\in\Bbb C[\![X]\!]$ with $a_0=1$ . (a) Show that there is some $b\in\Bbb C[\![X]\!]$ such that $ab=1$ . Provide a recursive algorithm for calculating the coefficients $b_k$ . (b) Show that the radius of convergence of $\rho_b$ of $b$ is positive if $\rho_a$ of $a$ is positive. The first part is easy, we have that $b_0=1$ and $$b_n=-a_n-\sum_{k=1}^{n-1}a_kb_{n-k},\quad\forall n\ge 1$$ (with the convention that the empty sum is zero). But Im stuck in the second part. To context the exercise: this exercise comes prior to any definition of continuity, derivative or analyticity in the book, then, from this context, I dont know how to prove it or if it is provable. My work so far: let $a:=\sum a_k X^k$ a formal power series with radius of convergence $\rho_a>0$ , then for $a(x):=\sum_{k=0}^\infty a_k x^k$ for $x\in\Bbb B(0,\rho_a)$ we have $$a_0=1\le\left|\sum_{k=0}^\infty a_kx^k\right|\le \sum_{k=0}^\infty |a_k|r^k=M<\infty,\quad\forall x\in\Bbb B(0,r),\text{ with }0<r<\rho_a$$ If we define $b:=\sum b_k X^k$ such that $ab=1$ then from above we have that $$\frac1M\le\left|\sum_{k=0}^\infty b_kx^k\right|\le 1,\quad\forall x\in\Bbb B(0,r),\text{ with }0<r<\rho_a$$ but from the last expression I cannot conclude that $b$ is absolutely convergent for all $|x|<\rho_b$ for some $\rho_b$ , hence I cannot conclude that $b$ have a positive radius of convergence. Some help will be appreciated, thank you.","['absolute-convergence', 'power-series', 'analysis']"
2123668,find the least value of $n$ such $2017^{{2017}^{2017}}~~|~n!$,"Let $n$ be positive integer. Find the minimum of the $n$ such
  $$2017^{{2017}^{2017}}~~|~n!$$ [Note that 2017 is a prime] use this formula: $$v_{2017}(n!)=\dfrac{n-S_{2017}(n)}{2016}$$so find least $n$ such $$ n-S_{2017}(n)\ge 2017^{2017}$$
$S_{p}(n)$ denotes the sum of the standard base-p digits of n, then How find this  least $n?$",['number-theory']
2123853,When to use integral?,"I have a question concerning when to use integral and what is the difference between two formulations, one with integral and another one without. I have formulated a simple example: Let's assume we have m = 1 kg of water that is heated. And because of this, there is some vapor forming. Now let's say that the fraction of vapor ($\theta$) takes values from 0 to 1 and has the profile shown below: Now it comes. For calculating the mass of the vapor ($m_{vapor}$), there are two formulations in my mind: $m_{vapor} = m \cdot \theta(t)$ $m_{vapor} = m \cdot \int_t \theta (t) dt$ But the problem is that I don't know why would I use one over another and here is where I need help. Can anyone please help me to understand why would one use the integral formulation and why not? What makes them different? I have serious problems understanding the function of the integral, other than the fact that it represents the area under a curve. But when to use it? I would highly appreciate if anyone can explain it to me in detail. Thank you in advance!","['integration', 'definite-integrals']"
2123859,A problem with a determinant,"Let $A$ and $B$ be $n\times n$ matrices. Let $x$ be a scalar variable and define $D(x):=det(A+Bx)$.
It can be easily shown by induction on $n$ that $D(x)$ is a polynomial of degree at most $n$.
The problem is to find an explicit polynomial if the matrices are as of the following form (with $a\neq b$): $$A= \begin{pmatrix}
    \lambda_1       & a & a & \dots & a \\
    b       & \lambda_2 & a & \dots & a \\
    \vdots & \vdots & \vdots & \ddots & \vdots \\
    b      & b & b & \dots & \lambda_n
\end{pmatrix}$$ $$B= \begin{pmatrix}
    1     & 1 & 1 & \dots & 1 \\
    1       & 1 & 1 & \dots & 1 \\
    \vdots & \vdots & \vdots & \ddots & \vdots \\
    1      & 1 & 1 & \dots & 1
\end{pmatrix}$$ I already spotted an inductive pattern not really that useful:
I found some regularity by calculating the determinant on the first column:
the first term is $(\lambda_1+x)*D_{n-1}$ and the other terms are summations of $(b+x)(a+x)*D_{n-2}$ where every $D$ is called on submatrices with different $\lambda$ but it doesnt't really help for finding an explicit formulation.
It seems to me at most useful for proving an already found polynomial is the right one.","['polynomials', 'matrices', 'determinant', 'induction', 'linear-algebra']"
2123873,Is the maximum of a probability distribution function of a Binomial distribution always the expected value?,"Consider some $X \sim B(n,p)$. I know that $E[X] = np$. I was looking at practice problems on the binomial distribution. One of the exercises asked the following: Given a histogram and $n$ for some $B(n,p)$, find $p$. (The histograms look like those in the attached image, obviously with $p$ removed.) The solution seems to be to find the value $k$ for which the histogram is maximal (by reading it off the histogram.) Then, $p = \frac{k}{n}$, since apparently $k$ is the expected value. Obviously, the mean and mode don't coincide for an arbitrary probability distribution. So does this mean that for any $B(n,p)$, the mean and mode are equal? Also: What happens if there are two maxima, like in the figure below?","['statistics', 'probability', 'probability-distributions']"
2123880,Does the potential exist?,"Verify Green's theorem for $X(x,y)=(xy^2,-yx^2)$ in the circle of radius $R$ with center $(0,0)$. I think there is a mistakein the field. I suppose the first thing I should do is to find a function $F$ such that $\nabla F= X$. I don't think it is possible: $\displaystyle{\int xy^2 = \frac{1}{2}x^2y^2+g(y)}$ and then it should be $\displaystyle{\frac{\partial}{\partial y}\left(\frac{1}{2}x^2y^2+g(y)\right)}=-yx^2$ but $\displaystyle{\frac{\partial}{\partial y}\left(\frac{1}{2}x^2y^2+g(y)\right)=yx^2+g'(y)}$ since $g$ only has the $y$ variable is impossible to get $-yx^2$","['multivariable-calculus', 'greens-theorem', 'vector-spaces']"
2123892,Prove: If $x+y+z=xyz$ then $\frac {x}{1-x^2} +\frac {y}{1-y^2} + \frac {z}{1-z^2}=\frac {4xyz}{(1-x^2)(1-y^2)(1-z^2)}$,"If $x+y+z=xyz$, prove that:
$$\frac {x}{1-x^2} +\frac {y}{1-y^2} + \frac {z}{1-z^2}=\frac {4xyz}{(1-x^2)(1-y^2)(1-z^2)}$$. My Attempt: $$L.H.S=\frac {x}{1-x^2}+\frac {y}{1-y^2}+\frac {z}{1-z^2}$$
$$=\frac {x(1-y^2)(1-z^2)+y(1-x^2)(1-z^2)+z(1-x^2)(1-y^2)}{(1-x^2)(1-y^2)(1-z^2)}$$
$$=\frac {x+y+z-xz^2-xy^2+xy^2z^2-yz^2-yx^2+x^2yz^2-zy^2-zx^2+zx^2y^2}{(1-x^2)(1-y^2)(1-z^2)}$$. I could not move on from here.Please help. Thanks",['algebra-precalculus']
2123912,"What is the color number of the 3D space, if we allow only convex regions?","I am thinking on the analogy of the well-known 2D coloring problem for the 3D space (with the trivial geometry & topology). As this reference says, simply increasing the dimensions by one doesn't work. It would elevate the color number to infinite, because: In this case, however, once you go to three dimensions, you can make
partitions of space into regions for which you need N colors to color
the regions in order that no two adjacent regions will have  the same
color for any N. You can make an example by starting with one ball. Now, add a ball to the picture and connect it with a thin tube to the
first ball. Now, add a third ball to the picture and connect this ball with two
thin tubes to the two balls already in the picture. You can keep adding balls and connecting them to all the other balls
like this because there is enough space in three dimensions to work
with. If the balls represent regions, since each ball is touching every
other ball, you need at least as many colors as there are balls to
color them. I think it would be useful if we would add a restriction: all of the regions should be convex . Also I think not I am the first one who thought on this possibility. Is it possible? How to even start to think on such a problem? What could be the result?","['combinatorial-geometry', 'general-topology']"
2123931,is the kernel the same thing as annihilator?,"This is what I have for the definition of kernel;
The kernel of $f$, denoted by $ker f$, is the set of elements in $R$ annihilated by $f$:
$ker f = \{a \in R : f (a) = 0\}$. and the definition of annihilator;
$ann(a)=\{x \in R: xa=0\}$","['abstract-algebra', 'discrete-mathematics']"
2123934,Evaluate $\lim_{x\to0} \big((1+x)^x-1\big)^x$,"How can one evaluate this limit?
$$\lim_{x\to0} \big((1+x)^x-1\big)^x$$
I've already tried writing that using $f(x) = e^{\ln f(x)}$, but I don't dare going any further with this approach.","['exponential-function', 'limits']"
2123958,How to evaluate $\lim_{n\rightarrow \infty} \sqrt{n}(\frac{e^{rt/n+\sigma\sqrt{t/n}}-1}{e^{2\sigma\sqrt{t/n}}-1}-\frac{1}{2})$?,"I know it evaluates to $\frac{rt-\frac{1}{2}\sigma^2t}{2\sigma\sqrt{t}}$ but how to get there is the problem. Using L'Hôpital you find $$\lim_{n\rightarrow\infty}\frac{e^{rt/n+\sigma\sqrt{t/n}}-1}{e^{2\sigma\sqrt{t/n}}-1} = \frac{1}{2}$$But L'Hôpital doesn't work on the whole thing. The only limit calculator that could figure it out was wolfram but that couldn't give me the steps to get there.
using Taylor series expansion gives me:$$\lim_{n\to\infty}\sqrt{n}(\frac{\sum_{k=0}^{\infty}(rt/n+\sigma\sqrt{t/n})-1}{\sum_{k=0}^{\infty}(2\sigma\sqrt{t/n})^k-1}-\frac{1}{2})$$But I fail to see how to go further from here, any help would be appreciated","['taylor-expansion', 'limits-without-lhopital', 'limits']"
2123984,Norms of linear maps,"Let $M_n(\mathbb{C})$ denote the algebra of $n \times n$ complex matrices, and $H_n(\mathbb{C})$ denote the linear space of $n \times n$ Hermitians. Both spaces are endowed with the usual operator norm. Assume that 
 $$ \Phi \colon H_n(\mathbb{C}) \rightarrow H_n(\mathbb{C})$$
is a (real) linear map of norm $1.$ Then $\Phi$ has a natural linear extension to $M_n(\mathbb{C})$ by $$\Phi(A) := \Phi\left({A+A^* \over 2}\right) + i\Phi\left({A-A^* \over 2i}\right).$$ Could you give me an example with $\|\Phi\| > 1 ?$ Or an explanation why this might happen?","['matrices', 'operator-theory', 'functional-analysis', 'operator-algebras', 'linear-algebra']"
2124023,finding limit with $\cos$ function occur $n$ times,"Finding $\displaystyle \lim_{x\rightarrow 0}\frac{1-\cos(1-\cos(1-\cos(1-\cdots \cdots (1-\cos x))))}{x^{2^n}}$ where number of $\cos$ is $n$ times when $x\rightarrow 0$ then $\displaystyle 1-\cos x = 2\sin^2 \frac{x}{2} \rightarrow 2\frac{x}{2} = x$ so $1-\cos (1-\cos x) = 1-\cos x$ some help me., thanks",['limits']
2124071,Distribution of blood types and alleles,"The blood type distribution in the US is as follows (according to this link ): O 45%
A 40%
B 11%
AB 4% However the blood type is a result of the 2 alleles (in lower case) that a person gets from her parents. aa -> A
oa -> A
ao -> A
oo -> O
ob -> B
bo -> B
bb -> B
ba -> AB
ab -> AB How can I extract the distribution of the alleles {a,b,o} from the the known distribution of the blood types {O,A,B,AB} ?","['statistics', 'probability', 'multinomial-coefficients', 'probability-distributions']"
2124101,How to show that a set is convex?,"My problem is as follows: 
Let f(x,y) be a general concave function (i.e. any concave function), and let S be points (x,y) such that f(x,y) greater than or equal to zero. I understand that this means S is the set of points on or below f(x,y) and >0, and I can show how it is convex in a sketch/graph. I just don't understand how you show it mathematically in a sufficient way using the definition of a convex set. Any help would be greatly appreciated.","['multivariable-calculus', 'convex-optimization', 'linear-algebra', 'convex-analysis']"
2124112,Must independent random variables be defined on a product set?,"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space on which independent random variables $X$ and $Y$ are defined. Suppose neither $X$ and $Y$ are almost surely constant. Must $\Omega$ be of the form $\Omega=\Omega_1\times\Omega_2$ for some sets $\Omega_1$ and $\Omega_2$? Even in the simplest case of $X$ and $Y$ being $\text{Bernoulli}(1/2)$ I was unable to make them independent, at least using $\Omega=\mathbb{R}$.","['probability-theory', 'probability']"
2124113,A proof for the identity $\sum_{n=r}^{\infty} {n \choose r}^{-1} = \frac{r}{r-1}$,"Do you have any idea to prove the following identity via a combinatorial (or algebraic) method? 
$\sum_{n=r}^{n=\infty} {n \choose r}^{-1} = \frac{r}{r-1}$ This is Exercise 71 in Chapter 2 of the book Chen C.C., Koh K.M. Principles and techniques in combinatorics. The book does not give a solution, although it mentions: ""see H. W. Gould, Combinatorial Identities , Morgantown, W.V. (1972), 18-19"". many thanks in advance,
Shahram","['combinatorics', 'binomial-coefficients', 'sequences-and-series']"
2124117,Proving trigonometrical identity from given identity.,"Given $$\dfrac{\sin^4 A}{a}+\dfrac{\cos^4 A}{b}=\dfrac{1}{a+b}$$ prove that:$$\dfrac{\sin^8 A}{a^3}+\dfrac{\cos^8 A}{b^3}=\dfrac{1}{(a+b)^3}$$ Using given, I proved: $b\sin^2 A=a\cos^2 A$ Help me proceeding after this.","['algebra-precalculus', 'trigonometry']"
2124139,Positive-definite derivative implies injective function,"Suppose $f:\mathbb R^n\to \mathbb R^n$ is differentiable and that $Df$ is positive-definite at every point. As homework, I need to prove $f$ is injective. I thought about proving by contradiction. If $f(a) = f(b) ,a\neq b$, consider the straight line  $\gamma:a\to b$ in $\mathbb R^n$, the composition $f\circ \gamma:\mathbb R\to \mathbb R$ (we take the codomain as $\mathbb R$ only) allows using the mean value theorem to find some $c\in (a,b)$ for which $(f\circ \gamma)^\prime (c)=0$. Then, by the chain rule $(f\circ \gamma)^\prime(c)=Df|_{\gamma c} \gamma^\prime(c)=0$. At this point I'm stuck. I don't see how to get to an inner product to contradict positive definiteness. Positive-definiteness implies invertibility whence $\gamma^\prime(c)=0$, which can't happen for a straight line, so it looks like the weaker hypothesis that $Df$ is everywhere invertible implies $f$ is injective. But that doesn't sound right...","['multivariable-calculus', 'derivatives']"
2124161,Let $f(z)=\sum\limits_{n=0}^{\infty}a_n z^n$ be an analytic function in $|z|\leq R$ such that $|f(z)|\leq M$. Prove an inequality about $f$'s zero,"Let $f(z)=\sum\limits_{n=0}^{\infty} a_n z^n$ be an analytic function in $|z|\leq R$ , such that for all $z$ , $|f(z)|\leq M$ . Let $z_0$ be one of $f$ 's zeros such that for all other zeros $z$ , $|z_0|\leq |z|$ . Let's write $d=|z_0|$ . Show that $d\geq \frac{R|a_0|}{M+|a_0|}$ . I tried several directions here. For example, I used Cauchy's theorem to write out: $$f(z_0)=\int\limits_{|z|=R}\frac{f(z)}{z-z_0}dz$$ such that: $$0=|f(z_0)|=\left|\space \int\limits_{|z|=R}\frac{f(z)}{z-z_0}dz\right|\leq 2\pi R\cdot \frac{M}{R-d}$$ I also tried looking at the circle $|z|<d$ , such that since $z_0$ is $f$ 's closest circle then, for all $|z|<d$ , $f(z)\neq 0$ . I used Cauchy's theorem here to show that: $$\forall |z|<d, 0<|f(z)|=\left|\space\int\limits_{|\xi |=d}\frac{f(\xi)}{\xi-z}d\xi\right|\leq 2\pi d \cdot \frac{M}{d-|z|}$$ This didn't yield any results. In order to get $a_0$ into this equation, I tried to say that this is in particular true for $z=0$ , such that: $$|a_0|=|f(0)|\leq 2\pi d\cdot \frac{M}{d}$$ But this didn't yield any results. What would be a good direction for this type of question?","['complex-analysis', 'analytic-functions']"
2124173,"If $[\overline F : F] = \infty$, does $F$ have extension of degree $n$ for any $n \geq 1$?","Let $F$ be a field and assume that $[\overline F : F] = \infty$. Does it imply that for any $n \geq 1$, there is a field extension $K/F$ of degree $n$? Notice that if $[\overline F : F] < \infty$ then $F$ is a real closed field so the answer is no (for $n > 2$). Moreover, it is not interesting to ask for extensions $\overline F/K$ such that $[\overline F : K] = [\overline K : K] = n$ because, by Artin-Schreier, this implies $n \leq 2$. I know that there exist extensions $K/F$ with arbitrarily large degree (take $x_0 \in \overline F \setminus F$ then $K_0 = F(x_0)$ has finite degree over $F$, so we can find $x_1 \in \overline F \setminus K_0$, then $K_1=K_0(x_1)$ has finite degree over $F$ and so on). Clearly, there are $F$-vector subspaces of $\overline F$ of dimension $n$ over $F$, but they might not be subfields. I know that $L = \Bbb Q(\sqrt p \mid p \text{ prime}) / \Bbb Q$ has no sub-extension $K/\Bbb Q$ of degree $3$. But here $L$ is not the algebraic closure of $\Bbb Q$.","['abstract-algebra', 'extension-field', 'field-theory']"
