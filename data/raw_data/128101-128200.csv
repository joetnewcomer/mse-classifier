question_id,title,body,tags
1963626,"A conjecture on partitions of $\{1,\ldots,n\}$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Conjecture: Let $n$ $∈$ $N$. Then for each factor $m ≥ n$ of $n$($n + 1$)/$2$, one can partition the set $\{1, 2, 3, \ldots , n\}$ into disjoint subsets such that the sum of elements in each subset is equal to $m$. The conjecture is based on numerical evidence.","['combinatorics', 'arithmetic-combinatorics', 'discrete-mathematics']"
1963632,Proving a given formula for projection matrix,"In an $n$-dimensional inner product space $V$, I have $k$ ($k\le n$) linearly independent vectors $\{b_1,b_2,\cdots,b_k\}$ spanning a subspace $U$. The $k$ vectors need not be orthogonal. Then I was told that the projection of an arbitrary vector $c$ onto $U$ is given by
$$P_Uc=A(A^TA)^{-1}A^Tc$$
where $A$ is the $n\times k$ matrix with column vectors $\left((b_1)(b_2)\cdots(b_k)\right)$. My questions are (1) How to prove that it is the projection? (EDIT: which has been answered, thanks!) (2) how can one be sure that the matrix $A^TA$ is invertible?","['matrices', 'projection-matrices', 'linear-algebra', 'inner-products']"
1963640,Why does $\frac{dq}{dt}$ not depend on $q$? Why does the calculus of variations work?,"The Euler–Lagrange equations for a bob attached to a spring are $${d\over dt}\left({\partial L\over\partial v}\right)=\left({\partial L\over\partial x}\right)$$ But is $v$ a function of $x$ ? Normal thinking says that $x$ is a function of $t$ and $v$ is a function of $t$ , but it is not necessary that $v$ be a function of $x$ . Mathematically, however, $x=f(t)$ and $v=g(t)$ , so $g^{-1}(v)=t$ and $x=f(g^{-1}(v))$ . The chain rule should be applied in these equations – why not here? I had previously asked this question on the physics Stack Exchange but it was marked a duplicate. In one of the answers there I found that the dedication of William Burke's Applied Differential Geometry read To all those who, like me, have wondered how you can change $\dot q$ without changing $q$ . I couldn't understand the answer there. My mathematics is not that good. So I asked it here again. If someone could give an answer without the concept of manifolds, I think I will be able to understand it. And Most importantly answers here say that notation is not that, but W. Burke has another reasons while the answers in the link have another reason. So what is the correct reason ? Like in f=(g(t)) we apply the chain rule. So why not here  when f'(x) is function of f(x)? Answer: It's so because the q and q dot are explicit functions of time so their partial derivative with each other is 0.....","['calculus-of-variations', 'differential-geometry', 'implicit-differentiation']"
1963710,"Finding number of elements $n\in\{1,2,...,20\}$ for which $1.9\le\frac{A_n}{A_{n-1}}\le2$ where $A_n=\max\left\{\binom{n}{r}:0\le r\le n\right\}$","Q.For each positive no. $n$
$$A_n=\max\left\{\left(\begin{array}{c}n\\ r\end{array}\right):0\leq r\leq n\right\}$$Then the no. of elements of $n$ in ${1,2,3.............20}$ for which $1.9\leq\frac{A_n}{A_{n-1}}\leq2$ is__? Attempt: $$\frac{\text{d}}{\text{d}r}\left(\frac{n!}{(n-r)!r!}\right)=0$$ to calculate the maximum $r$ for a particular $n$.I do not know how to calculate this. How to perform this derivation? Another Attempt: I plotted the graph of $$\frac{n!}{(n-x)!x!}$$ for any particular $n$. On inspection,I found that the function reaches maximum value at $x=n/2$ $$A_n=\frac{n!}{(\frac{n}{2})!\frac{n}{2})!}$$ $$A_{n-1}=\frac{(n-1)!}{(\frac{n-1}{2})!\frac{n-1}{2})!}$$ Therefore,$$1.9\leq\frac{\frac{n!}{(\frac{n}{2})!\frac{n}{2})!}}{\frac{(n-1)!}{(\frac{n-1}{2})!\frac{n-1}{2})!}}\leq2$$ Now I am stuck again. Can I proceed from here and how? If none of this attempts are useful, how to solve this question?","['combinatorics', 'inequality']"
1963756,"If $X$ is independent of $Y$ and $Z$, then $X$ is independent of $(Y,Z)$","I have two questions concerning Independence between random variables and vectors. Let $X,Y,Z,U:\Omega\rightarrow\mathbb{R}$ be random variables. If $X$ is independent of $Y$ and $Z$, is $X$ independent of $(Y,Z)$? If $X$ and $U$ are independent of $Y$ and $Z$, is $(X,U)$ independent of $(Y,Z)$? MOTIVATION: I know that, if $X$ is independent of $(Y,Z)$, then $X$ is independent to both $Y$ and $Z$ (because the real maps $(y,z)\mapsto y$ and $(y,z)\mapsto z$ are measurable). I would like to know if the converse holds, and if not, under which conditions it does (for instance, if the random variables have a certain distribution). I do know that, for 1., if $Y$ and $Z$ are also independent, then $X$ is indeed independent of $(Y,Z)$.","['self-learning', 'independence', 'probability-theory', 'probability', 'measure-theory']"
1963773,"Can $(\mathbb Q,+)$ be made a vector space over $\mathbb R$?",Does there exist an external multiplication $\mathbb R \times \mathbb Q \to \mathbb Q$ w.r.t. which $\mathbb Q$ forms a vector space over $\mathbb R$ ?,"['elementary-set-theory', 'vector-spaces']"
1963784,Uniform continuity preserved with equivalent metrics?,"I am told that any two metrics that equip a space with the same topology yield the same uniformly continuous functions. Surely this is not true ?
The reason I ask is because in one of my exams I'm expected to prove that some function is uniformly continuous on $[0,1]^2$ and when trying to do so I found myself stuck not knowing exactly relative to which metric. I asked the examinor and he said ""any one of them that equips it with its natural topology"" but I'm pretty sure that doesn't work out. Are there two metrics that equip this space with its natural product topology and a function which is uniformly continuous wrt one and not the other ?","['general-topology', 'equivalent-metrics', 'real-analysis']"
1963848,How to solve differential equation $(y'/y)'=a((b/x^2)+xy)$?,"In a physics problem I'm working on, the following differential equation has appeared $$\left(\frac{y'}{y}\right)'=a\left(\frac{b}{x^2}+xy\right),~~(x>0)$$ The first approaches tried were those that were outlined in this previous question of mine. Alas, there is a new complicating term (the $1/x^2$ one) that makes this quite complicated. This time, wolframalpha doesn't give me a closed form solution, so I don't know exactly what to expect. If it helps, I'm looking for solutions that are big but not divergent near the origin (i.e. for small values of $x$), and that decay down (along with all its derivatives) to 0 at infinity..",['ordinary-differential-equations']
1963851,Proof for Riemann's isolated singularity.,"Let $f$ be complex function has isolated singularity at $z_0$. Suppose $f$ is bounded on some deleted neighborhood of $z_0.$ Then $f$ is holomorphic and bounded on some deleted neighborhood of $z_0.$ Let $h(z)= \begin{cases}  (z-z_0)^2f(z)\mbox{, if z is not z_0 }\\
0 \mbox{, if $z=z_0$}
\end{cases}$ Then Since $f$ is bouned on some deleted neighborhood of $z_0$,
$$ \lim_{z \to z_0} h(z) =0 $$ $$\lim_{z\to z_0}\frac{h(z)-h(z_0)}{z-z_0} = 0.$$ So $h$ is analytic at $z_0$. since $h(z_0)=h^\prime (z_0)=0$, $$h(z)=\sum_{n=2}^{\infty} a_n(z-z_0)^n $$ so $f(z)=\sum_{n=2}^{\infty}a_n(z-z_0)^{n-2}$ on some deleted neighborhood of $z_0$ , By properties of powerseries $f$ is defined at $z_0$ so that $f$ is analytic at $z_0$ [[ I want you guys to be check whether my proof is correct ]]","['complex-analysis', 'proof-verification']"
1963910,How to plot a complex trigonometric function with a computer?,"I want to plot, on the complex plane, $\cos(x+yi)$, where $-\pi\le y\le\pi$. Which software can accomplish this? It is best to use a free software. Please include your script to do this. More concretely, I want the image of $\cos(x+yi)$ on the complex plane. A point $a+bi$ is placed on the graph if there exist some $x$ and $y$ such that $\cos(x+yi)=a+bi$ and $-\pi\le y\le\pi$. A point $a+bi$ has distance $a$ on the real axis and distance $b$ on the imaginary axis. The set of all such points is the graph I want.","['trigonometry', 'complex-numbers', 'graphing-functions']"
1963925,"How do I calculate the UMVUE of $P(X\leq c)$ where $X_i\sim \mathrm{N}(\mu,9)$?","How do I calculate the UMVUE of $P(X\leq c)$ where $X_i\sim \mathrm{N}(\mu,9)$? I know that $\mathbf{1}_{\{X_1\leq c\}}$ is an unbiased estimator of $P(X_1\le c)$. Besides, $S=\bar{X}$ is a complete sufficient statistic for $\mu$, so applying Rao-Blackwell once by calculating $\mathrm{E}[\mathbf{1}_{\{X_1\leq c\}}|S=s]$ should give the UMVUE (by Lehmann-Scheffé). How do I proceed from here?","['probability-theory', 'statistics', 'normal-distribution']"
1963953,Find the solution of the differential equations $p^2-y^2=0$ and $(p+1)^3=27(x+y)^2$,Find the solution of the differential equations : i) $p^2-y^2=0$ ii) $(p+1)^3=27(x+y)^2$ These questions in (non linear ordinary differential equations - can be solve in y) My answer: For (i) $p^2=y^2$ $p=y$ ${dp\over dx}={dy\over dx}$ And we know [$p={dy\over dx}$] So ${dp\over dx}=p$ $\ln p=x+\ln c$ $p=ce^x$ By delet $p$ from : $y=p$ and $p=ce^x$ We get : $y=ce^x$ True ? And for (ii) $(p+1)^3=27(x+y)^2$ $3(p+1)^2 {dp\over dx}=54(x+y+x{dy\over dx}+y{dy\over dx})$ $3(p+1)^2 {dp\over dx}=54(x+y+xp+yp)$ $3(p+1)^2 {dp\over dx}=54(x(p+1)+y(p+1))$ ${dp\over dx}={18(x+y)(p+1)\over (p+1)^2}$ ${dp\over dx}={18(x+y)\over (p+1)}$ Is it true? And how can I complete ? Thanks.,['ordinary-differential-equations']
1963999,Surface of revolution with zero mean curvature,"I want to show that the only surfaces of revolution with zero mean curvature are the plane and the catenoid (revolving $x = \frac{1}{a}\cosh(ay+b)$ about $y$-axis). Aiming to do this, I have calculated the first and the second fundamental form for the general surface of revolution $r(\rho, \phi) = (x(u), \rho(u)\cos\phi, \rho(u)\sin\phi), ~~\rho(u) > 0$, which I am not sure if is correct. The result is \begin{align}
b_{11} &= \frac{x''\rho' - x'\rho''}{\sqrt{\rho'^2+x'^2}} \\
b_{12} &= 0 = b_{21} \\
b_{22} &= \frac{x'\rho'}{\sqrt{\rho'^2+x'^2}},
\end{align} \begin{align}
g_{11} &= x'^2 + \rho'^2 \\
g_{12} &= 0 = g_{21} \\
g_{22} &= \rho^2.
\end{align} Denote $G = (g_{ij})$ and $Q = (b_{ij})$. Therefore, the mean curvature is, by definition, the trace of the matrix $G^{-1}Q$, and then I have ended up with some nasty differential equation which hardly seems possible to solve: \begin{equation}
\frac{x''\rho' - x'\rho''}{(\rho'^2+x'^2)^{3/2}} +  \frac{x'\rho'}{\rho^2\sqrt{\rho'^2+x'^2}} = 0.
\end{equation} To make things better, I have tried parametrising the surface by different parameters, e.g. the arc length of the curve, which reduces $\rho'^2+x'^2$ to $1$. But so far my efforts are in vain. Is there any errors in my calculations or any way can I take to bypass such difficulties?",['differential-geometry']
1964024,"Two spheres, triple integration, not their intersection","Two spheres, one of radius $1$ and one of radius $\sqrt{2}$, have centres that are $1$ unit apart. Find the volume of the smaller region that is outside one sphere and inside the other. Can use either spherical or cylindrical coordinates. The $2$ spheres can be anywhere in three dimensional space. Apparently using the correct coordinates will lead into an easy integration. Been tossing around the two and haven't seen any of them working out to be easy.","['multivariable-calculus', 'spheres', 'integration', 'calculus']"
1964039,Why do positive definite matrices have to be symmetric? [duplicate],This question already has answers here : Do positive semidefinite matrices have to be symmetric? (3 answers) Closed 7 years ago . Definitions of positive definiteness usually look like this: A symmetric matrix $M$ is positive definite if $x^T M x > 0$ for all vectors $x \neq 0$. Why must $M$ be symmetric? The definition seems to make sense for general square matrices.,"['matrices', 'symmetric-matrices', 'positive-definite', 'quadratic-forms']"
1964046,Is a function that integrates to zero against all polynomials constant?,"Suppose $f := [0,\infty) \rightarrow \mathbb{R}$ satisfies $|f(x)| \leq e^{-x}$ for all $x \in (0,\infty)$, and also has the property that $$
\int_0^{\infty} f(x) x^n dx = 0 \qquad \forall n \in \{0,1,2,3,...\}.
$$ Does it follow that $f$ is constant? If so, is this a standard theorem? Many thanks for your help.","['real-analysis', 'harmonic-analysis', 'functional-analysis', 'integration', 'power-series']"
1964101,"$\lim_{x \to 2, y\to 1}\frac{\sin^{-1}(xy-2)}{\tan^{-1}(3xy-6)}$","$$\lim_{x \to 2, y\to 1}\frac{\sin^{-1}(xy-2)}{\tan^{-1}(3xy-6)}$$
Since the numerator and denominator both go to $0$ when $(x,y) \to (2,1)$, for one variable case we can use L'Hopitals rule, but for two variables case, I do not know how to calculate it. I also tried to use the definition, means wrote as 
$$\lim_{h \to 0, k\to 0}\frac{\frac{\sin^{-1}[(x+h)(y+k)-2]}{\tan^{-1}[3(x+h)(y+k)-6]}-\frac{\sin^{-1}(xy-2)}{\tan^{-1}(3xy-6)}}{?}$$
But still do not know how to do further...Any help? Thank you~","['trigonometry', 'functions', 'limits']"
1964106,Countable additivity and continuity of measures,"Let N be the set of all natural numbers, $2^N$ the set of all subsets of N with product topology and $\mu:2^N \rightarrow G$ an additive set function. Prove that $\mu$ is countably additive iff it is continuous where $G$ denotes a commutative Hausdorff complete topological group.","['functional-analysis', 'topological-vector-spaces', 'measure-theory']"
1964162,Why does this hacky derivation for least-squares regression work?,"Consider the regression problem where we have $m$ measurements of the dependent variable and a model with $n$ degrees of freedom, where $m>n$. We can write the dependent variable measurements in a vector $\mathbf{y}$ (size $m\times 1$) and the model parameters in a vector $\mathbf{x}$ (size $n\times 1$), and arrange the independent measurements appropriately in a matrix $\mathbf{A}$ (size $m\times n$). The problem is now to choose $\mathbf{x}$ such that $\mathbf{y}$ is represented as closely as possible by $\mathbf{A}\mathbf{x}$. The most common way of quantifying ""as closely as possible"" is in the least-squares sense. We write:
$$
E = \left(\mathbf{y} - \mathbf{A}\mathbf{x}\right)^T\left(\mathbf{y} - \mathbf{A}\mathbf{x}\right)
\tag{1}
$$ By taking the derivative of $E$ wrt $\mathbf{x}$ and setting it to zero, we end up with the least-squares solution: $$
\mathbf{x}=\left(\mathbf{A}^T \mathbf{A}\right)^{-1} \mathbf{A} \mathbf{y}
\tag{2}
$$ I once had a professor show me a hacky way to have to neither remember this formula, nor do the tedious derivation in an exam situation. He was very clear that it was a hack and that I should never use it as a serious derivation. It goes as follows - start out by writing: $$
\mathbf{A}\mathbf{x} = \mathbf{y}
\tag{3}
$$ Observe that we cannot solve this equation by taking the inverse of $\mathbf{A}$ because this is not a square matrix. No problem! - multiply each side by $A^T$ (size $n\times m$) to get:
$$
\left(\mathbf{A}^T\mathbf{A}\right) \mathbf{x} = \mathbf{A}^T \mathbf{y}
\tag{4}
$$
Now $A^T A$ is a square matrix (size $n\times n$), which means it's (potentially) invertible. Multiply each side by $\left(\mathbf{A}^T \mathbf{A}\right)^{-1}$ to get:
$$
\mathbf{x} = \left(\mathbf{A}^T \mathbf{A}\right)^{-1} \mathbf{A} \mathbf{y}
\tag{5}
$$ We get the right result, in the least-squares sense! Of course the hack is that, in general, Eq. (3) is not true to begin with; it is an inconsistent equation with no solution. My question is: Is it just pure coincidence that this hack works in this particular case? Or is there perhaps a deeper reason? Maybe an insight as to why it leads to the least-squares solution as opposed to other one? Thank you!","['regression', 'least-squares', 'matrices', 'matrix-calculus', 'statistics']"
1964176,Solving $x+x^3=5$ without using the cubic equation.,"In lessons, I get quite bored and recently throughout these lessons I have been trying to solve for x in:
$$x+x^3=5$$ I've figured out how to do it for squares using the quadratic equation, but the cubic equation looks so dauntingly massive it actually makes my bladder hurt. So, is there a way to figure this out using a different process, and better so for $x^n$. Danke Chien","['algebra-precalculus', 'cubics', 'polynomials', 'factoring']"
1964193,Finding coefficient of $x^k$ in a product of two polynomials,"Let $a(x)= a_{0}+a_{1}x+a_{2}x^2+...+a_{n}x^n$ and $b(x)= b_{0}+b_{1}x+b_{2}x^2+...+b_{m}x^m$ be two polynomials. Write down a formula for the coefficient of
$x^k$ in the product $a(x)b(x)$, where $0 ≤ k ≤ n + m.$ I noticed the coefficient is always the sum of products of these coefficients whose powers sum to $k$, so for example for two polynomials $(2+5x+7x^2)$ and $(9+2x+3x^2)$ the coefficient of $x^2$ is $3\times2+5\times2+7\times9=79$. So to generalize this observation for the product of $a(x)b(x)$, in order to get a coefficient of $x^k$, we would need a sum of products whose subscripts sum to $k$. For example, the coefficient of $x^4$ in $a(x)b(x)$ would be $a_{4}b_{0}+a_{3}b_{1}+a_{2}b_{2}+a_{1}b_{3}+a_{0}b_{4}$. However, the question asks for a specific formula, whereas I have found only a pattern which needs more concise form. How to go about finding the actual formula?","['generating-functions', 'combinatorics', 'discrete-mathematics']"
1964213,Prove that for a Brownian motion B the hitting time is a stopping time.,"As in the title, I have to prove that for a Brownian motion B the time
$$
\tau_x = \inf \{t\geq 0 : B(t)=x \} 
$$
is a stopping time. It seems obvious intuitively but I struggle with the formal proof. I know that the random variable $\tau$ is a stopping time for a given filtration $(\mathcal{F}_t)$, $t\in T$ if
$$
\{\tau \leq t \}\in \mathcal{F_t} \hspace{0.2cm} \forall t\in T.
$$
However I can't seem to conduct a formal proof (still new to the probability theory). I also have to proof that collection $\mathcal{F_t}$ associated with a stopping time $\tau$ is a $\sigma$-algebra. I have the same problem here: I know what a $\sigma$-algebra is but I don't know how to show the required property. Thanks in advance for any help!","['probability-theory', 'brownian-motion', 'stopping-times']"
1964228,computing Laplacian of hyperbolic spaces,"Ok, as a beginner to Riemannian manifolds, let me ask the following embarrassing question. Consider the hyperbolic  manifold $(\mathbb H^n,g)$ with hyperbolic metric $g_{ij}=\delta_{ij}\frac{1}{x^2_n}$. Why is that the Laplace-Beltrami operator equal to $$\Delta_g=-x_n^2\sum_{i=1}^n\frac{\partial^2}{\partial x_i^2}?$$
Even for  $\mathbb H^2$ my computations does not confirm the above expression (which should be $\Delta_g=-y^2(\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2})$ ). Or am I missing something in here?","['riemannian-geometry', 'differential-geometry']"
1964291,Probability that the last digit of the product is zero,"I tried much in this problem but I didn't get my answer correct. The question is----- If n positive integers taken at random are multiplied together ,show that the probability that the last digit of the product being zero is $$\frac{10^n-8^n-5^n+4^n}{10^n}$$ My attempt ---- Case 1--when at least one of $x1,x2,\cdots,xn$(let it be n positive integers taken at random) has zero in its unit place.
$$P(\overline{A}) = \frac{9^n}{10^n}$$
$$P(A) = 1- \frac{9^n}{10^n}$$ Case 2----when zero doesnot occur and at least one five occurs in any of the unit place of positive integers taken at random. Also at least one of (2,4,6,8) comes.
Let $\overline{B}$---there is no five. $P(\overline{B} \mid \overline {A}) =\frac{8^n}{9^n}$ $P(B \mid \overline {A}) =1-\frac{8^n}{9^n}$ Let C----there is no (2,4,6,8)
$P(\overline{C} \mid B \mid \overline {A}) =\frac{5^n}{9^n}$ $P(C \mid B \mid \overline {A}) =1-\frac{5^n}{9^n}$ This gives me $P(\overline{A}\cap B \cap C) =P(\overline{A})P(B \mid \overline{A}) P(C \mid B \mid \overline{A})$.this doesn't give me the desired result.
I don't understand where I have made mistake.please help me in this regard. Thanks.",['probability-theory']
1964374,References for differential cohomology and secondary characteristic classes,"I am interested in differential cohomology & secondary characteristic classes and am currently studying the notes by Ulrich Bunke. While these are nice notes, I sometimes find it hard to fill in the gaps in the proofs. Could someone please suggest a reference that I could use to supplement the article ?
Are there any other good references on this subject for a beginner ? As regards my background, I have studied homology and cohomology theory, basic homotopy theory & topology of fibre bundles (from Husemoller's book) and differential geometry (connections, curvature, deRham cohomology, chern classes). Thanks a lot !","['algebraic-topology', 'reference-request', 'differential-geometry']"
1964430,Funny double infinite sum,I was playing with a modified version of Pascal's triangle (with ${n \choose k}^{-1}$ instead of $n \choose k$ everywhere) and this infinite sum popped out: $$\sum_{k=2}^{\infty}\sum_ {n=1}^{\infty} \frac{1}{n(n+1)(n+2)...(n+k-1)} $$ The partial sums seem to approach $\alpha \approx 1.317...$ Does a closed form for $\alpha$ exist?,"['real-analysis', 'sequences-and-series']"
1964471,Product of two infinite summations,"I want to show
\begin{equation*}
\sum_{n=1}^\infty f(n)\sum_{m=1}^\infty g(m)=\sum_{n=1}^\infty \sum_{m=1}^\infty f(n)g(m)\end{equation*}
Do I have to invoke the conditions on Fubini's theorem? Or is this always true? I tried this proof, which does not require absolute convergence, just convergence.
\begin{align*}
\sum_{n=1}^\infty f(n)\sum_{m=1}^\infty g(m)&=\lim_{N\rightarrow\infty}\sum_{n=1}^Nf(n)\sum_{m=1}^\infty g(m)\\
&=\lim_{N\rightarrow\infty}\left[f(1)\sum_{m=1}^\infty g(m)+...+f(N)\sum_{m=1}^\infty g(m)\right]\\
&=\lim_{N\rightarrow\infty}\left[f(1)\lim_{M\rightarrow\infty}\sum_{m=1}^M g(m)+...+f(N)\lim_{M\rightarrow\infty}\sum_{m=1}^M g(m)\right]\\
&=\lim_{N\rightarrow\infty}\left[\lim_{M\rightarrow\infty}\sum_{m=1}^M f(1)g(m)+...+\lim_{M\rightarrow\infty}\sum_{m=1}^M f(N)g(m)\right]\\
&=\lim_{N\rightarrow\infty}\lim_{M\rightarrow\infty}\left[\sum_{m=1}^M f(1)g(m)+...+\sum_{m=1}^M f(N)g(m)\right]\\
&=\lim_{N\rightarrow\infty}\lim_{M\rightarrow\infty}\sum_{m=1}^N\sum_{m=1}^M f(n)g(m)\\
&=\lim_{N\rightarrow\infty}\sum_{m=1}^N\lim_{M\rightarrow\infty}\sum_{m=1}^M f(n)g(m)\\
&=\sum_{n=1}^\infty\sum_{m=1}^\infty f(n) g(m)
\end{align*}",['sequences-and-series']
1964499,How do we know that graphs have the shapes they do?,"This is a pretty simple question I think, but I don't know how to answer it. For example, we all know that a parabola such as y=x^2 looks something like this: parabola But my question is, how do we know that the graph actually looks like this? We can't actually plot out an infinite amount of points to see that the graph follows a smooth pattern, but instead we can only individually plot points and we just connect them. Why do we just assume that the points can be connected? If anyone needs any clarification about my question, feel free to ask.","['algebra-precalculus', 'graphing-functions']"
1964502,Evaluating the sum $\sum_{i=0}^\infty \frac{F_n}{2015^n}$,Find $$\sum_{n=0}^\infty \frac{F_n}{2015^n}$$ Where $F_n$ is the $n$ -th Fibonacci number. Any clues?,"['fibonacci-numbers', 'sequences-and-series']"
1964607,When will a parametric solution generate all possible solutions?,"I was looking for integer solutions to this equation: 
$$a^2+b^2+c^2=3d^2$$
And found a parametric solution. Given r, s, t:
$$a=r^2+s^2-t^2+2t(r+s)$$
$$b=r^2-s^2+t^2+2s(t-r)$$
$$c=-r^2+s^2+t^2+2r(t-s)$$
$$d=r^2+s^2+t^2$$ My question is will this generate every possible solution?","['number-theory', 'parametric']"
1964626,"Related rates, using the Pythagorean theorem or otherwise","I'm having a hard time understanding this question: A spotlight is placed on the ground, and shines on a wall 12 meters away. Frank is a 75 cm tall dog who walks at a speed of 1.6 m/s. Frank walks from the spotlight directly towards the wall, projecting a shadow onto the wall. When Frank is 9 meters from the wall (a) how high is his shadow on the wall? (b) how fast is the length of his shadow decreasing? Specifically, do I relate the Pythagorean Theorem to the total distance from the spotlight to the wall, or the distance from Frank to the wall, or the distance from the spotlight to Frank? And if the latter two, how would I include the total distance into finding part (a)? How would I set up the Pythagorean Theorem to accommodate this scenario in order to find dy/dt? Thank you!","['derivatives', 'calculus']"
1964629,Probability that the person speak true (has he drawn two aces when he says so ?),"I tried much in this problem But I didn't get my answer correct. The question states-- A person draws two cards successively without replacement from a pack of 52 playing cards.He tells that both cards are aces,then what is  the probability that both cards are actually aces if there are 60% chances that he speaks truth----- My attempt ----- $P(T)=0.6$ let$ E1 $be the event that the person says that the first card drawn is ace and $E2 $be the second card drawn is ace said by the person. Then $$P(E1)=\frac{1}{13}\cdot 0.6+\frac{48}{52}\cdot 0.4$$
Similarly  $$P(E2 \mid E1)=(\frac{7}{15}\cdot 0.6+\frac{95}{51}\cdot 0.4)\cdot (\frac{0.6}{13}+\frac{4.8}{13})$$
So,$$P(E1 \cap E2)=P(E2 \mid E1)\cdot P(E1)$$ But I am not getting the answer.please help me in this regard. Thank you.",['probability-theory']
1964649,"If $F(x,y)=0$, prove $\frac{d^2y}{dx^2}=-\frac{F_{xx}F_y^2-2F_{xy}F_xF_y+F_{yy}F^2_x}{F_y^3}$","If $$F(x,y)=0$$
prove $$\frac{d^2y}{dx^2}=-\frac{F_{xx}F_y^2-2F_{xy}F_xF_y+F_{yy}F^2_x}{F_y^3}$$
I tried 
$$\frac{dy}{dx}=-\frac{F_x}{F_y}$$
Then 
$$\frac{d^2y}{dx^2}=-\frac{F_{xx}F_y-F_xF_{xy}}{F_y^2}$$
I do not know where I got wrong... any help? Thanks~","['derivatives', 'partial-derivative']"
1964653,Fourth root in denominator for derivatives,The problem I'm working with right now looks like this $$\dfrac{(6x^3 + x)(4x-2x^2)}{3 \cdot x^\frac14}$$ How do I deal with the fourth root in the denominator to find the derivative? This problem's really driving me crazy.,"['derivatives', 'roots', 'functions']"
1964675,Understanding Baker and Rippon's proof of a result in iteration theory,"Let $a \in \mathbb{C}, b = e^a, T(z) = e^{az}$ .  Define $W_n = T^n(1)$ where $T^n$ is the nth iterate of $T$ .  The main result that motivated asking this question is Theorem 1 below. Note : in Theorems 2,3,4 and in the proof of Theorem 1, $f$ is a non-linear entire function; $\mathscr{F}(f)$ is the set of points in the complex plane in whose neighborhood the sequence $f^n$ fails to be a normal family; and $\mathscr{C}(f)$ is the complement of $\mathscr{F}(f)$ Theorem 1 : If $a = te^{-t}, |t| = 1$ and $t^k = 1$ for some $k \in \mathbb{N}$ then $W_n$ converges to $e^t$ Proof : Suppose that $a=te^{-t}$ with $|t|=1$ so that $e^t$ , is a fixed point of $T(z)= e^{az}$ with multiplier $t$ . Since $te^{-t}$ is univalent in $|t|=1$ there is only one such $t$ for a given $a$ and $e^t$ is the only possible limit for $W_n$ .  By Theorem 2, $e^t$ belongs to a component $D$ of $\mathscr{C}(T)$ which contains the only singular point of $T^{-1}$ , namely the origin. But $T(D) \subset D$ by Theorem 4 so that $1 \in D$ and thus $W_n= T^n(1)$ converges to $e^t$ . I am trying to figure out exactly where Baker and Rippon have used the assumption that $t$ is a root of unity.  This is important to me because the sequence $W_n$ does not converge if $|t| = 1$ but $t$ is not a root of unity, and I am struggling to understand how the addition or removal of this one condition produces such a drastic change in the behavior of $W_n$ .  I believe the fact that $t$ is a root of unity is used in Theorem 2. Theorem 2 :  If $\alpha$ is a fixed point of $f$ such that $f'(\alpha)$ is a root of unity, then $\alpha \in \mathscr{F}(f)$ but $\alpha$ lies on the boundary of one or more components $D$ of $\mathscr{C}(f)$ in which $f^n \to \alpha$ as $n \to \infty$ , and at least one such $D$ contains a singularity of $f^{-1}$ . Theorem 3 : For any integer $p > 1, \mathscr{F}(f) = \mathscr{F}(f^p)$ The proof of Theorem 2 relies on being able to study the iteration of $F = f^p$ instead of $f$ itself, since by Theorem 3 $\mathscr{F}(F) = \mathscr{F}(f)$ . Theorem 4 : $\mathscr{C}(f)$ and $\mathscr{F}(f)$ are completely invariant under $f$ in the sense that if $z\in \mathscr{C}(f)$ then $f(z)\in \mathscr{C}(f)$ , and if further $f(w) = z$ then $w \in \mathscr{C}(f)$ To be clear, I am asking for the proofs of Theorems 3 and 4.  This is because the authors state them without proof, and because I consider them important in understanding the proof of Theorem 1. Note : all results are taken from I. N. Baker and P. J. Rippon's article Convergence of infinite exponentials , Ann. Acad. Sci. Fenn. 8, 179–186 (1983), DOI: 10.5186/aasfm.1983.0805 .","['fixed-point-iteration', 'complex-analysis', 'sequences-and-series', 'complex-numbers']"
1964678,"Prove $\frac{\partial (x,y,z)}{\partial (u,v,w)}\frac{\partial (u,v,w)}{\partial (x,y,w)}=1$","If $$x=f(u,v,w)$$
$$y=g(u,v,w)$$
$$z=h(u,v,w)$$ Provided $\frac{\partial(x,y,z)}{\partial(u,v,w)\neq 0}$, prove $$\frac{\partial (x,y,z)}{\partial (u,v,w)}\frac{\partial (u,v,w)}{\partial (x,y,w)}=1$$
I tried to use the property of determinant, if for matrix
$$M=AB$$
then
$$det(M)=det(A)det(B)$$
So I want to prove that the product of these two Jacobian equals the determinant of the product of these two matrix. I wish the later one would be easier, but I did not go anywhere... Any help? Thanks~","['matrices', 'partial-derivative', 'functions', 'derivatives']"
1964680,Is $f(x)$ necessarily a polynomial if $f(f(x))$ is?,"If $g(x)$ is a polynomial, and $$g(x) = f(f(x))\ \forall x\in \mathbb{R}$$ is $f(x)$ necessarily a polynomial, given that $f$ is infinitely differentiable? Reading this question I noticed that the answer fails if we consider the domain to be the whole real line. I'm wondering whether removing the increasing condition allows for solutions that work across the whole real line, without allowing for ""weird"" functions like $$f(x) = \left|x\right|^{\sqrt{2}}$$ hence the infinitely differentiable condition. The only progress I've mad on this is as follows: Assume $g(x)$ has degree $d$ and leading coefficient $a$. Thus $$\lim_{x\to\infty} \frac{g(x)}{ax^d} = 1$$ $$\lim_{x\to\infty} \frac{f(f(x))}{ax^d} = 1$$ If $$x^{k-\epsilon} << f(x) << x^{k+\epsilon}\ \forall\ \epsilon>0$$ for some $k$ (which I think has to hold), then $$x^{k^2-\epsilon} << f(f(x)) << x^{k^2+\epsilon}$$ and thus $d=k^2$. I don't think this does much though. Does anyone have any ideas?","['polynomials', 'calculus', 'functions']"
1964688,Tail of probability distribution,"I need to analyze the plot of a probability distribution for a group of random samples. The question asked:
""What does the tail of probability distribution of the sample values look like?""
I don't know how should I answer this question. Are there specific categories and definition for the tail of probability distribution? Can anyone provide an insight (or introduce a source) please? Thanks in advance.","['statistics', 'sampling', 'distribution-tails', 'probability-distributions']"
1964731,Calculating the perimeter of an ellipse,"The hydraulic diameter is defined as $$D_h=\dfrac{4A}{P}$$ 
where $A$ is the area and $P$ is the perimeter.
The area of an ellipse is simply $\pi ab$.
The perimeter has many many different representations.... However doing some googling I found that the Hydraulic diameter is $$\dfrac{4ab(64-16e^2)}{(a+b)(64-e^4)}$$
Where $$e=(a-b)/(a+b)$$
And $a$ is the major axis and $b$ is the minor axis
How did they derive this? What is the procedure for calculating the perimeter of the ellipse?","['calculus', 'geometry']"
1964759,construct a sequences of integrable function that tends to the dirichlet function.,"so I wanted to ask if (it is even possible) to construct a sequence of integrable function $f_n$ such that $f_n \rightarrow f$ where $f$ is the dirichlet function. $f := \begin{cases}0\ \ x\in[a,b]\cap\mathbb{Q}\\1 \ x\in [a,b]\ \  \cap \mathbb{R}\backslash\mathbb{Q}\end{cases}$ If it is possible, could someone show me how it is done. I just think that this might be a good counter-example to know for some of the true/false questions I have been facing in my course of studies. Any help and insight is deeply appreciated.","['real-analysis', 'real-numbers', 'sequences-and-series', 'functions']"
1964801,Derivative notation between $D$ and $\nabla$,"Sorry if this is likely a duplicate question (and that I am asking two questions) but I am confused on some notation. For a function $f(x_1, x_2): \mathbb{R}^2 \to \mathbb{R}$, for simplicity, why does the product rule tell us that $$ \displaystyle Df(x_1, x_2) = \frac{\partial f(x_1, x_2)}{\partial x_1} \ dx_1 + \frac{\partial f(x_1, x_2)}{\partial x_2} \ dx_2 $$ Wouldn't we need a given functional form to know to apply the product rule (ie. if $f(x_1, x_2) = x_1 / x_2$ then we apply the quotient rule. Further given the above, since the codomain of $f$ is scalar, it does not seem to match the following identity: $$ \nabla f= [Df]^T $$ That is $Df$ is the transpose of the gradient of $f$, a vector. (edit: I read these in Microeconomic Theory by Mas-Collel, Whinston and Green)","['notation', 'differential-forms', 'multivariable-calculus', 'differential-geometry', 'vectors']"
1964827,Reconcile two anti-derivatives of $\int \frac{dx}{A + \cos x} $,"I see in a calculus textbook that, for $|A| \neq 1$ , \begin{align}
f(x) &\equiv \int \frac{1}{A + \cos x} \,\text{d}x \\&=\frac{1}{ \sqrt{A^2 - 1} } \left( x - 2 \tan^{-1} \frac{ \sin x }{ A + \sqrt{A^2 - 1} + \cos x } \right)
\end{align} which I have verified using Mathematica $$\frac{\text{d}\, f(x)}{\text{d}\, x} = \frac{1}{A + \cos x}$$ However, I have failed to show the equivalence (up to a constant) of $f(x)$ to the more sensible form obtained by Mathematica (as explained here) : $$g(x) \equiv \int \frac{1}{A + \cos x} \,\text{d}x = \frac{-2}{\sqrt{1-A^2}} \tanh ^{-1}\frac{(A-1) \tan \frac{x}{2}}{\sqrt{1-A^2}}$$ With the half angle substitution, one can replace $\tan \frac x2$ in above result. However, what really stumps me is how to get the linear term and arctangent in $f(x)$ . It seems reasonable to try some identities involving inverses like $$\tanh^{-1}(\sin x) = \sinh^{-1}(\tan x) $$ or equivalently $$ \sin^{-1}( \tanh x ) = \tan^{-1}( \sinh x )$$ together with some common ways to combine $\sin x$ and $\cos x$ . But, so far, I have gotten nowhere.","['indefinite-integrals', 'integration', 'trigonometric-integrals', 'calculus']"
1964882,Does a injective function need every element of the domain to map onto some element of the codomain?,"My question is, is it necessary for every element of the domain to map onto some element of the range for a function to be injective? For example, is $$f(x) = x,\ f:\Bbb R \to \Bbb Z$$ one-to-one/injective, even though there are many elements of the reals that cannot map onto the integers? Obviously for every element that can map onto $\Bbb Z$, it is the only element that corresponds to its output, but I guess I'm wondering if this ""overflow"" of elements in $\Bbb R$ that don't map onto $\Bbb Z$ matter. Another example, which is the reason I wanted to know the answer to this question: $$f(x)= 1/x,\ f:\Bbb R \to \Bbb R \setminus \{0\}$$ So obviously, every element of the domain points to only $1$ element of the range in this function, but does it matter that when $x=0$ the function is undefined? Or does that not effect whether the function is one-to-one or not?","['elementary-set-theory', 'functions', 'discrete-mathematics']"
1964885,"What is meant by a ""discontinuity of $1$""?","I am confused by the solution to part $(\mathrm{c})$ of the following question for which I have typed out the full question and solutions for context: The equation for a driven, damped harmonic oscillator is $$\frac{d^2y}{dt^2}+2\frac{dy}{dt}+(1+k^2)y=f(t)$$ $(\mathrm{a})$ If the initial conditions are $y=0$ and $\dfrac{dy}{dt}=0$ at $t=0$ , show that the Green's function, valid for $t\ge 0$ , is $$G(t,T)=\begin{cases}A(T)e^{-t}\cos(kt)+B(T)e^{-t}\sin(kt)\quad\text{for}\quad 0\lt t\lt T \\C(T)e^{-t}\cos(kt)+D(T)e^{-t}\sin(kt)\quad\text{for}\quad t\gt T\end{cases}$$ Part $(\mathrm{a})$ solution: For $t\lt T$ , $$\frac{\partial^2G(t,T)}{\partial t^2}+2\frac{\partial G(t,T)}{\partial t}+(1+k^2)G(t,T)=\delta(t-T)=0$$ With a trial solution $G(t,T)\propto e^{mt}$ , we have $$m^2+2m+(1+k^2)=0$$ $$\implies m=\frac{-2\pm\sqrt{4-4(1+k^2)}}{2}=-1\pm\sqrt{-k^2}=-1\pm ik$$ Hence $$\begin{align}G(t,T)&=ae^{-1+ik}+be^{-1-ik}\\&=e^{-t}\Big(a(T)e^{ikt}+b(T)e^{-ikt}\Big)\\&=e^{-t}\Big(A(T)\cos(kt)+B(T)\sin(kt)\Big)\\&=A(T)e^{-t}\cos(kt)+B(T)e^{-t}\sin(kt)\end{align}$$ and similarly for $t\gt T$ , with $A\to C$ and $B\to D$ . $(\mathrm{b})$ Show that $\mathrm{A}=\mathrm{B}=0$ and so $G(t,T)=0$ for $t\lt T$ . Part $(\mathrm{b})$ solution: $G(0,T)=0\implies A=0$ , $\dfrac{\partial G}{\partial t}\bigg|_{t=0}=B(T)\cos(0)=0\implies B(T)=0$ . Hence $G(t,T)=0$ for $t\lt T$ $(\mathrm{c})$ By matching $G(t,T)$ at $t=T$ , and requiring $\dfrac{dG}{dt}$ to have a discontinuity of $1$ there, show that, for $t\gt T$ $$G(t,T)=\frac{e^{T-t}}{k}\bigg(\cos(kT)\sin(kt)-\sin(kT)\cos(kt)\bigg)$$ Part $(\mathrm{c})$ solution: Continuity of of $G$ at $t=T$ gives $$\color{blue}{C(T)e^{-T}\cos(kT)+D(T)e^{-T}\sin(kT)=0}$$ Discontinuity of $1$ in $\dfrac{\partial G(t,T)}{\partial t}$ at $t=T$ gives $\color{red}{[-kC(T)e^{-t}\sin(kt)+kD(T)e^{-t}\cos(kt)]_{t=T}-[C(T)e^{-T}\cos(kT)+D(T)e^{-T}\sin(kT)]_{t=T}=1}$ I understand why the part marked blue is correct as it was explained to me in this previous question but I have no idea about the logic behind the red equation. Specifically I don't understand why subtracting those two terms must be equal to $1$ . I notice that the second term on the LHS of the red equation is actually the blue equation and hence equal to zero. I also know from the same previous question why a first derivative must change by $1$ . But what is meant by a ""discontinuity of $1$ "" and why does the red equation take that form? Put in another way, if I wrote ""discontinuity of $7$ "" instead; What do those three words mean? Does it mean that there is a region on the $x$ -axis consisting of $7$ units where the function is not present? Or does it mean that there is a region on the $y$ -axis where the function is not there? Any hints or tips is greatly appreciated, thank you.","['derivatives', 'continuity', 'greens-function', 'proof-explanation', 'ordinary-differential-equations']"
1964945,"Ideal class ""group"" of Lipschitz (fully-integer) quaternions","Let $H = \left\{a+bi+cj+dk \in \mathbb{H} : a,b,c,d \in \mathbb{Z} \;\mbox{ or }\, a,b,c,d \in \mathbb{Z} + \tfrac{1}{2}\right\}$ be Hurwitz (or semi-integer) quaternions. Then $H$ is Euclidean, thus principal ideal domain. Now let $L = \left\{a+bi+cj+dk \in \mathbb{H} : a,b,c,d \in \mathbb{Z}\right\}$ be Lipschitz (or fully-integer) quaternions. It is easy to see that the right ideal $(1+i+j+k, 2)$ is not principal. How can I prove using $H$ that the ideal class ""group"" $Cl(L)$ contains only two elements, the classes of $(1)$ and $(1+i+j+k,2)$? Here, the ideal class ""group"" $Cl(L)$ is a set of non-zero right ideals $I \subset H$ modulo the relation $I_1 \sim I_2 \Leftrightarrow x_1I_1=x_2I_2$ for $x_1, x_2 \in L$.","['number-theory', 'quaternions', 'class-field-theory']"
1964946,What do $L$-functions of curves over $\mathbb Q$ tell us about the curve,"Following up this thread: $L$-function of an elliptic curve and isomorphism class I'd like to ask some more questions for the case of smooth projective curves $C$ over $\mathbb Q$ To be more precise, take this definition ( https://webusers.imj-prg.fr/~marc.hindry/Notes_rev_Brasilia.pdf , (2.2)): $$L(\rho,s)=\prod_{\mathfrak p}\det(1-\rho(\mathrm{Frob}_p)p^{-s}\mid V^{I_{\mathfrak p}})^{-1}$$ where $\mathfrak p$ runs over the primes of $\mathbb Q$ , or more generally: the number field $K$ . And $V=H^1_{et}(C,\mathbb Q_\ell)$ . Is there a similar statement for curves of higher genus? I.e. if two $L$ -functions $L(C,s)$ and $L(C',s)$ coincide, what can be said about $C$ and $C'$ ? Are there further interesting properties that can be read off the $L$ -function $L(C,s)$ , and not the curve $C$ itself? Assuming the Generalized Riemann Hypothesis holds for $L$ -functions of  curves over $\mathbb Q$ , what does that imply about the curve? Best, Dan","['algebraic-curves', 'riemann-zeta', 'algebraic-geometry', 'l-functions']"
1964957,$\omega_{\alpha+1}$ is a projection of $\wp(\omega_{\alpha})$,"some classmates and I are attacking this problem, which is exercise 3.10 of Jech's ""Set theory"" book: $\omega_{\alpha+1}$ is a projection of $\wp(\omega_{\alpha})$ So, we need to find an onto function from $\wp({\omega_{\alpha}})$ to $\omega_{\alpha+1}$. We know that $|\omega_{\alpha}\times\omega_{\alpha}|=\omega_{\alpha}$, therefore we search for a surjective function from $\wp(\omega_{\alpha}\times\omega_{\alpha})$ to $\omega_{\alpha+1}$. The book's hint goes as follows: ""if $R\subseteq\omega_{\alpha}\times\omega_{\alpha}$ is a well-order, let $f(R)$ be its order type"". However we can't have a good idea about how to proceed. Can anyone please help us?","['elementary-set-theory', 'ordinals']"
1964966,"If a collection of disjoint disks covers the unit square, then the circumferences add up to infinitude.","A question from Makarov & Podykorytov, Real analysis: Measures, Integrals and Applications (Can't recall what page though, but it's in the chapter about product measure). Assume a collection of disjoint disks cover the unit square, $[0,1]^2$ up to a (Lebesgue) null set.
  Then, the sum of the lengths of their boundaries is infinitude. My attempt: We denote the disks $\{D_n\}_{n=1}^\infty $, their corresponding radii with $r_n$, the union $\bigcup_{n=1}^\infty D_n = C$ and Lebesgue measure on $\mathbb{R}^2$  with $m^2$, $\sum_{n=1}^\infty m^2(D_n) =\sum_{n=1}^\infty \pi r_n^2 =1 $ But this does not (and i think, cannot) produce a good bound on the sum of lengths of circumferences. Almost all (vertical and horizontal) cross-sections must have 1-dimensional measure $1$. I speculate this implies that up to a null-set, every cross-section intersects infinitely many disks, but did not manage to show this. If the last remark is true, then maybe we can show that almost-all cross-sections of the circumferences have positive measure, (as the fact that the cross-section intersects infintely many disks is encouraging).","['real-analysis', 'lebesgue-measure', 'measure-theory']"
1964993,Upper bound for distance between actual and sample quantiles,"Let $\xi_p$ be pth quantile of the distribution $F(x)$ with derivative at $\xi_p$, $f(\xi_p) >0$. Then, $$
|\hat\xi_{p,n} - \xi_p| \leq \frac{2}{f(\xi_p)}\sqrt{\frac{\log n}{n}}
$$ almost surely for large enough $n$ and any $p \in (0,1)$, where $\hat\xi_{p,n}$ is the pth sample quantile from an empirical distribution $F_n(x)$ for $F(x)$ with $1/n$ mass for each observation. I have tried Taylor expansion to get a bound but this approach does not seem to work; it seems like I need to rather work with empirical distribution (using Hoeffding's inequality) rather than sample quantile to derive the term $\log n$, but I am not sure of how I can derive this upper bound.","['probability-theory', 'quantile', 'statistics', 'probability', 'order-statistics']"
1965002,Calculate position based on angles between three known points,"Assume that the positions of three points - A, B and C - are known (arbitrary 2D orthonormal coordinates). Hence it is easy to calculate the sides and angles of the resulting triangle. The position of the observer, denoted O, is unknown (although on the same plane) but the angles between the points A, B and C are measured by the observer; $ \theta_{AB},\;\theta_{AC},$ and $\theta_{BC} $. Is it possible to calculate the position of the observer based on this information? According to my intuition the answer is affirmative, however a google search has left me disappointed.","['euclidean-geometry', 'trigonometry']"
1965012,Does the sum $\sum_{n \geq 1} \frac{2^n\operatorname{mod} n}{n^2}$ converge?,"I am somewhat a noob, and I don't recall my math preparation from college. I know that the sum $\displaystyle \sum_{n\geq 1}\frac{1}{n}$ is divergent and my question is if the sum $$\sum \limits _{n\geq 1}\frac{2^n\mod n}{n^2}$$ converges. I think is not but I do not know how to prove that! Thanks!",['sequences-and-series']
1965022,What is the mathematical symbol for the unique values of union of two sets?,"Let's say you have two sets: A=[875 900 925 950 975 1000] and B=[825 850 875 900 925 950] . You'd like find the set of unique elements after the union sets A and B . In Matlab you can use the unique function and obtain the result: A=[875 900 925 950 975 1000];
B=[825 850 875 900 925 950];
C=unique([A,B]);
>> C
C =
825 850 875 900 925 950 975 1000 How to write the unique function in the mathematical notation? update. I have tried: $A \bigcup B = \{x: (x \in A \vee x \in B) \}.$
In Matlab the union function gives the same result: C = union(A,B)
C =
 825 850 875 900 925 950 975 1000","['notation', 'elementary-set-theory']"
1965023,Definition of quotient ring,"I have a question about the definition of quotient ring (I mean a commutative ring  case) . Let $(a+I)$ be a coset of $R$ and $(b+I)$ be another left coset of $R$ . Then the multiplication in the quotient ring is defined as $(a+I)(b+I)=(ab+I)$ However, if we consider the setwise product of $(a+I)$ and $(b+I)$ we know that their product is just a subset of a fixed coset of $I$ . Then why should I believe the multiplication in the quotient ring is well-defined?","['abstract-algebra', 'ring-theory', 'group-theory', 'ideals']"
1965060,"Can $\nabla$ be called a ""vector"" in any meaningful way?","I used to think that $\nabla$ (or $\vec \nabla$) was just some fancy notation to represent some differential operators ($\nabla f \equiv \text{grad} \ f$, $\nabla \cdot \vec v \equiv \text{div} \ \vec v$, $\nabla \times \vec v \equiv \text{curl} \ \vec v$), which is particularly convenient because it happens to behave like a vector in algebraic manipulations. However, I've read in some posts on this site (like this answer or this answer ) that seem to suggest that there could in fact be a way to consider $\nabla$ as a vector in a formally meaningful way. For example, quoting from this answer : There are at least two layers of ideas here. First, as you say, the ""dual space"" $V^*$ to a real vector space is (by definition) the
  collection of linear maps/functionals $V\rightarrow \mathbb R$, with
  or without picking a basis. Nowadays, $V^*$ would more often be called
  simply the ""dual space"", rather than ""covectors"". Next, the notion of ""tangent space"" to a smooth manifold, such as
  $\mathbb R^n$ itself, at a point, is (intuitively) the vector space of
  directional derivative operators (of smooth functions) at that point.
  So, on $\mathbb R^n$, at $0$ (or at any point, actually),
  $\{\partial/\partial x_1, \ldots, \partial/\partial x_n\}$ forms a
  basis for that vector space of directional-derivative operators. It thus seems to me that there could be a meaningful, rigorous way to interpret $\nabla$ as an element of some vector space, maybe the dual space of an appropriate vector space of functions. Is this line of reasoning correct? PS I am a physicist, not a mathematician, and I only have a very basic background on functional analysis and differential geometry.","['functional-analysis', 'differential-geometry', 'vector-spaces']"
1965076,Why is chi-square statistic not dimensionless?,"I figure, if I measure something in meters, and then take a chi-square from it to test a hypothesis, the value I get will be in meters too. But that doesn't make sense: by simply switching to kilometers, I'd get a 1000 times smaller value. Or is it only supposed to be used with dimensionless quantities to begin with? For example, if I am using poll data (yes, Presidential) to test a hypothesis, should I use percentages as inputs or actual numbers of people that voted? It seems that the latter would make more sense (if a poll includes two people, and both vote one way, it's 100%, but doesn't mean very much), but brings the question of units into the picture (if I count people in thousands, rather than in persons, I'd get a very different result).",['statistics']
1965089,Find a bijection between 2 intervals,"So I'm supposed to find a bijection between $[0,1) \longrightarrow [0,1]$. My attempt of solution is the function defined as $$f(x):=\begin{cases}
2x, & \text{iff} \,\, x=\dfrac{1}{2^n} \\
x, &\text{otherwise} 
\end{cases}$$ Using this we have that if $x=\frac{1}{2}$, then $f(1/2)=1$ and so we got that covered. And for $x=\frac{1}{4}$ we have $f(1/4)=1/2$ and so on. Is this correct? Is it possible to assume that there is a bijection, when $n$ goes to infinity? I also got another question: define a bijection from $[0,1) \longrightarrow [0,1) \times [0,1) \times \ \dots \ \times [0,1)$
$(n-$times$)$. My solution is just to define the value of $f(x)$ as a vector, i.e take $x \in [0,1)$ and $$f(x):=(x,x,x,\dots , x)$$ Is this correct? Thank you in advance!","['real-analysis', 'functions']"
1965092,cofinite filter is intersection of all non-principal ultrafilter,"It is clear that Cofinite filter on any infinite set is contained in every non-principal ultrafilter so it is contained in the intersection of all non-principal ultrafilters, but my question is that Is Cofinite filter the intersection of all non-principal ultrafilters?","['filters', 'elementary-set-theory']"
1965128,"$\operatorname{frac}(na)$ is dense in $[0,1]$ for irrational $a$. How to find the smallest $n$ efficiently?","It is well known that the sequence $\operatorname{frac}(na)$ , where $\operatorname{frac}$ denotes the fractional part and $n$ runs over the positive integers, is dense in $[0,1]$. Suppose, I have an irrational number $a$ and two rational numbers $s,t$ with $0<s<t<1$. Then, there must be a positive integer $n$ with $s<\operatorname{frac}(na)<t$. How can I efficiently calculate the smallest positive integer $n$ with the desired property ? I tried the best approximations related to the continued fraction of $a$, but these only help to find integers $m,n$ , such that $|na-m|$ is very small. I also thought about the possibility of using the lindep-command of PARI/GP, but the problem is that I need integers with $na-m-u\approx 0$ , where $u$ could, for example be $\frac{s+t}{2}$. But as far as I know, I cannot fix the coefficient belonging to $u$ to be $-1$, in which case I could find possible solutions. But even if this were possible, the solution might not give the smallest value $n$ doing the job. Any ideas?","['number-theory', 'approximation-theory', 'continued-fractions', 'irrational-numbers']"
1965129,"Why is the Affine line irreducible, yet the Real line is not?","The explanation I have in my notes is ""The affine line $A^1$ is irreducible because it is infinite. The real line $R$ is not irreducible because it can be written $R = (-\infty, 0] \cup[0, \infty) $"" I understand that in the affine line we ""forget"" where the origin is, or where we ""are"" on the line, but whats to stop be picking a random point on the affine line and writing it as the sum of two disjoint sets, just like the real line? Thanks!","['algebraic-topology', 'affine-geometry', 'algebraic-geometry']"
1965164,Calculating the integral $\int\limits_{0}^{2\pi} \frac{d \theta}{a^2 \sin^2\theta+b^2 \cos^2\theta}$,"I wanted to calculate $$\int\limits_{0}^{2\pi} \frac{d \theta}{a^2 \sin^2\theta+b^2 \cos^2\theta}$$ So I solved the indefinite integral first (by substitution): $$\int\frac{d \theta}{a^2 \sin^2\theta+b^2 \cos^2\theta}=\frac{1}{b^2}\int\frac{d \theta}{\cos^2\theta \left(\frac{a^2}{b^2} \tan^2\theta+1 \right)} =\left[u=\frac{a}{b}\tan\theta, du=\frac{a}{b\cos^2\theta} d\theta \right ]\\=\frac{1}{b^2}\int\frac{b}{a\left(u^2+1 \right)}du=\frac{1}{ab}\int\frac{du}{u^2+1}=\frac{1}{ab} \arctan \left(\frac{a}{b}\tan\theta \right )+C$$ Then: $$\int\limits_{0}^{2\pi} \frac{d \theta}{a^2 \sin^2\theta+b^2 \cos^2\theta}=\frac{1}{ab} \arctan \left(\frac{a}{b}\tan (2\pi) \right )-\frac{1}{ab} \arctan \left(\frac{a}{b}\tan 0 \right )=0$$ Which is incorrect (the answer should be $2\pi/ab$ for $a>0,b>0$ ). On the one hand, the substitution is correct, as well as the indefinite integral itself (according to Wolfram it is indeed $\frac{1}{ab} \arctan \left(\frac{a}{b}\tan\theta \right )$ ), but on the other hand I can see that had I put the limits during the substitution I'd get $\int\limits_{0}^{0} \dots = 0$ because for $\theta = 0 \to u=0$ and for $\theta = 2\pi \to u=0$ . Why is there a problem and how can I get the correct answer? Edit : Here is Wolfram's answer: Wolfram is correct because $$\frac{a^2 b^2}{2}\int\limits_{0}^{2\pi} \frac{d \theta}{a^2 \sin^2\theta+b^2 \cos^2\theta}$$ is the area of an ellipse (defined by $x=a\cos t , y=b\sin t$ ), that is $$\frac{a^2 b^2}{2}\int\limits_{0}^{2\pi} \frac{d \theta}{a^2 \sin^2\theta+b^2 \cos^2\theta}=\pi ab$$","['integration', 'calculus']"
1965167,How to prove every radical ideal is a finite intersection of prime ideals?,"Let $k$ be an algebraically closed field, $\mathbb{A}^n(k)$ the affine space corresponding to $k[x_1, \dots, x_n]$ , which is Noetherian by the Hilbert Basis Theorem. We know that any algebraic set $V$ can be written as the finite union of irreducible algebraic varieties, $V_1 \cup \dots \cup V_k$ , no one containing the other (See Hartshorne, Algebraic Geometry , Corollary I.1.6, p. 5). By a variant of the Strong Nullstellensatz, there is a one-to-one correspondence between radical ideals in $k[x_1, \dots, x_n]$ and algebraic sets in $\mathbb{A}^n(k)$ . Likewise, corresponding to the fact that every prime ideal is radical, there is a one-to-one correspondence between prime ideals in $k[x_1, \dots, x_n]$ and algebraic varieties in $\mathbb{A}^n(k)$ . Question: Thus we know that for any algebraic set $V$ , $$Z(I) = V = V_1 \cup \dots \cup V_k = Z(I_1) \cup \dots \cup Z(I_k) \\ \implies Z(I) = Z(I_1) \cup \dots \cup Z(I_k) $$ where $Z(S)$ denotes the zero set of a collection of polynomials, $I$ is a radical ideal in $k[x_1, \dots, x_n]$ and $I_1, \dots, I_k$ are prime ideals in $k[x_1, \dots, x_n]$ . How do we use this to show that $$I = I_1 \cap \dots \cap I_k $$ which is a special case of the Lasker-Noether theorem when all ideals involved are radical? (Since every prime ideal is the radical of a primary ideal, and again $k[x_1, \dots, x_n]$ is Noetherian.) My attempt: See my community wiki ""answer"" for what I have tried so far -- this question is already too long due to context.","['maximal-and-prime-ideals', 'ideals', 'algebraic-geometry', 'commutative-algebra']"
1965174,Power set of a set with an empty set,"When a set has an empty set as an element, e.g.$ \{\emptyset, a, b \}$. What is the powerset? Is it:  $$ \{ \emptyset, \{ \emptyset \}, \{a\}, \{b\}, \{\emptyset, a\} \{\emptyset, b\}, \{a, b\}, \{\emptyset, a, b\}\}$$ Or $$ \{ \emptyset, \{a\}, \{b\}, \{\emptyset, a\} \{\emptyset, b\}, \{a, b\}, \{\emptyset, a, b\}\}$$ Or 
$$ \{ \{\emptyset\}, \{a\}, \{b\}, \{\emptyset, a\} \{\emptyset, b\}, \{a, b\}, \{\emptyset, a, b\}\}$$ The confusion arises for me because, the powerset of every non-empty set has an empty set. Well the original set already has the empty set. So we don't need a subset with an empty set. Somehow, the first one seems correct. Yet, I can't seem to accept it.","['elementary-set-theory', 'discrete-mathematics']"
1965315,Problem with Probability Density Function definition,"I have a problem with the definition of probability density function (PDF). Usually this concept is defined in terms of a given distribution function, while I would like to know if it is possible to define the concept in one shot (i.e. for both the discrete and continuous case) without passing through cdf. Thus,... ... can we say that a PDF is any function $f : \mathbb{R} \to [0 ,1]$ that satisfies the following two basic requirements? $f \geq 0$ , $\int f d \lambda = 1$ , where $\lambda$ is the Lebesgue measure on $\mathbb{R}$ . If this is correct , does this definition encompass in one shot both the discrete and continuous case (thanks to the Lebesgue integration)? I would say no , because condition (2) should be ill-defined for the discrete case, because it is based on the Lebesgue measure according to which every point has measure zero. Is this last intuition correct (which implies that we need to explicitly add a third condition with summation instead of integration to deal with the discrete case) , or my intuition is simply wrong ? If it is wrong , what am I missing? As always, any feedback is enormously appreciated. Thank you for your time.","['probability-theory', 'measure-theory', 'probability-distributions']"
1965347,Relationship between Taylor and Weierstrass theorem,"I'm not a mathematician, but these two theorems sound related to me. Taylor's theorem. Every k -times differentiable function can be approximated in a neighborhood around a given point by a k -th order polynomial to an arbitrary degree. Weierstrass theorem . Every continuous function defined on a closed interval $[a, b]$ can be approximated to an arbitrary degree by a polynomial function. (The statements are probably not precise.) I always wondered what is the underlying relationship between those two? Does one imply the other, or are they each special cases of some more general result?","['approximation-theory', 'real-analysis']"
1965355,Geometric transformations and limit (pi=4 revisited!!),"Consider three geometric transformations. 1st: The geometric ""proof"" that hypotenuse of a right triangle  is equal to the sum of squares of the other sides. The link is here. 2nd: The famous ""pi=4"" ""proof"" by geometric transformation 3rd: Archimedes's method of calculation  of pi What is inherently different in these transformations that 1st 2nd yield wrong results while the 3rd doesn't? Is there any heuristic which could hint us when the transformation is valid for calculation of the limit?
I have read the discussion on mathstackexchange about pi=4, but still I couldn't get that intuition.
There was an interesting argument about the divergence of the derivatives of those two curves. But I still don't understand if it is a satisfactory condition to prove that Archimedes construction was a valid one. If possible, please give 2 two explanations from intuitional and strictly mathematical point of view.","['real-analysis', 'limits', 'fake-proofs', 'calculus', 'pi']"
1965407,Deriving the integrating factor for exact equations.,"Show that if $\frac{N_x - M_y}{M} = Q$, where Q  is a function of $y$ only, the the differential equation $M + Ny' = 0$      (*) has an integrating factor of the form $u(y) = exp$$\int Q(y) \, dy$. (The subscripts in the first equation are partial derivatives). I've done quite a few examples and see that it indeed works, but I'm not sure how to prove this general formula. (So we need to show that multiplying through by $u(y)$ makes (*) exact.)",['ordinary-differential-equations']
1965431,"Explanation of the formula for combinations without repetition, probability","The formula for combinations without the repetitions is as follows:
$$ \frac{n!}{r!(n-r)!}$$ This is achieved by doing
$$\frac{n!}{(n-r)!}*\frac{1}{r!}$$ What I don't understand where $\frac{1}{r!}$ comes from. I know that the first part is what you do when you have n things and want all the combinations of r of those things, in a way that order doesn't matter. How does this $\frac{1}{r!}$ remove repetitions taking in consideration the order? My guess is that $\frac{1}{r!}$ is the percentage of $\frac{n!}{(n-r)!}$ things that are repetitions, but how was this value discovered? Is it just a coincidence or property or is there some logic behind this? Thanks.",['probability']
1965468,"What's the appropriate definition of ""tree"" here?","The free monoid on $X$ can be described as the underlying set of the skeleton of the groupoid whose objects are finite totally ordered sets graded in $X$, and whose morphisms are isomorphisms of totally-ordered sets that preserve the grading. Ergo, the aforementioned groupoid can be viewed as ""groupoidifying"" the free monoid on $X$. But since it's always a thin groupoid, we're not getting any new by doing this. We can do something similar for commutative monoids; the free commutative monoid on $X$ is the underlying set of the skeleton of the groupoid whose objects are finite sets graded in $X$. If $X$ has one or more elements, this won't be a thin groupoid, so this time, we're actually getting something new by doing this. I'd like to do this for free magmas and/or free commutative magmas (where ""commutative"" means $xy=yx$.) The idea is to: replace finite sets with finite full binary trees, defined appropriately. replace finite totally ordered sets with totally-ordered finite full binary trees. Question. What are the appropriate definitions here? I'd want something a bit like this: a finite full binary tree consists of a finite set $X$ (of leaves) together with some further structure on $X$, subject to some axioms, that can somehow be viewed as making $X$ into a full binary tree. Maybe we should be viewing the vertexes of $X$ as being subsets of $X$, or something like that.","['category-theory', 'abstract-algebra', 'definition', 'discrete-mathematics']"
1965517,Solve for power series $y'' - 9y = 0$,"I really need help with this, the solution from this equation is $y(x) = c_1 e^{3x} + c_2 e^{-3x}$. But I can't get to it, I obtain the next:
$$y(x) = \sum_{n=0}^{\infty}a_nx^n$$
$$y''(x) = \sum_{n=0}^{\infty}n(n-1)a_nx^{n-2}$$ Then the coefficients must be $a_{2m} = \frac{9^m a_0}{(2m)!}$ and $a_{2m+1}= \frac{9^ma_1}{(2m+1)!}$ Substituting in the first equation I have:
$$y(x) = a_0 \sum_{m=0}^{\infty} \frac{(3x)^{2m}}{(2m)!} + a_1\sum_{m=0}^{\infty} \frac{3^{2m}x^{2m+1}}{(2m+1)!} $$ Since $e^{x}=\sum_{n=0}^{\infty} \frac{x^{n}}{n!}$, I think its obvious that the first part of the last equation is $a_0e^{3x}$, but in the second part I dont really know how to get $a_1e^{-3}$. I am wrong?","['algebra-precalculus', 'ordinary-differential-equations', 'power-series', 'calculus']"
1965561,Interior and accumulation points,"Show that every interior point of a set must also be an accumulation point of that set. Definitions : Any point $x$ that belongs to $E$ is said to be an interior point of $E$ provided that some interval $(x-c,\ x+c)\subset E$. Any point $x$ (not necessarily in $E$) is said to be an accumulation point of $E$ provided that  for every $c>0$ the intersection $(x-c,\ x+c)\cap E$ contains infinitely many points. How do I show that every interior point of a set must also be an accumulation point of that set from these 2 definitions?","['general-topology', 'real-analysis']"
1965574,"Given a set of 3 orthogonal vectors, how can I find a minimum volume enclosing ellipsoid expressed in the Cartesian coordinate frame?","Generalized Problem Given values to start the problem: A 3D orthonormal coordinate frame (we'll call it the 'V' coordinate frame) that is rotated from the global coordinate system (we'll call it 'G') but shares a common origin. 3 magnitudes representing the semi-major axes of an ellipsoid defined in the 'V' coordinate frame All necessary information (angles, etc.) required to fully describe the system. Desired output: 3 magnitudes representing the semi-major axes of an ellipsoid expressed in the 'G' coordinate frame that completely encompasses the input ellipsoid. I realize that there may be different solutions depending on the type of ellipsoid-fit. I believe what I desire is a minimum volume enclosing ellipsoid. I don't believe that a mere direction cosine matrix rotation is a sufficient solution to be physically meaningful. Problem Background To give context for this problem, I am trying to geolocate a ground feature using Line-of-Bearing measurements (with range measurements) from a quad-copter in the air the stationary ground feature. I am trying to convert the sensor covariances ($\sigma_{psi}$, $\sigma_{theta}$, and $\sigma_{range}$) of the sensor to their minimum equivalent values represented in the global coordinate system (North, East, and Up in this instance). Given that $\sigma_{psi}$ and $\sigma_{theta}$ are expressed as covariance of an angular measurement, their values can be converted to a distance using the approximation of $s=r\theta$ or any similar equation. $\sigma_{range}$ is already expressed in units of distance. Depending on the location and altitude of the quad-copter, the alignment of the 'V' coordinate system with 'G' will change. As I will be tracking the location of the target using an estimator (in the global coordinate frame), I want to know the equivalent covariances in XYZ of each measurement as they depend on the location and slant range of the quad-copter and target. Please let me know if any further information or explanations are needed. Thanks in advance for any help!","['rotations', 'coordinate-systems', 'covariance', 'geometry', 'conic-sections']"
1965576,Everybody present,"Once upon a time there was a big party with n participants. People arrived to the party,spent some time there and went home. the bartender noticed that any two people had a drink together. a)Show that there was a moment when everybody was present at the same time b)What should we assume about endpoints of the time intervals for the statement to hold? c)What if there were infinitely many people? My approach: Since everyone had a drink together then for every 2 participantsthere was a time when they were together, then we supose that for any n=k participants there was a time that they were together. Now assume that there wasn't a time when k+1 participants were together Now let's call them with $p_1,p_2,...,p_k,p_{k+1}$ and w.l.o.g. say $T(p_1,p_2,...,p_k) < T(p_2,...,p_k,p_{k+1})<T(p_1,p_3,...,p_{k+1}) $
, where T is the time when they have been together so: in order to happen second one $p_1$ should go home before and to happen third one after second one $p_1$ should be there but he went home so contradiction. I don't have any clue about b and c","['induction', 'real-analysis', 'analysis']"
1965590,Finding numbers satisfying a given condition,"How many 4-digit number exists , such that the sum of it's digit is $29$ & also the number is divisible by $29$? I literally don't know how to approach this question . What is the basic concept that would be used in solving these type of questions ?Please let me know !!","['number-theory', 'elementary-number-theory']"
1965599,All random variables following a distributional equation,"How to find out all random variables $X$ satisfying the following 2 conditions: $E(X^2)<\infty$ $X$ follows the distributional equation : $X\stackrel{d}{=}{X+Y\over \sqrt2}$ for any random varibale $Y$ independent of $X$ such that $Y\stackrel{d}{=}X$ I am not getting where to begin with. EDIT : Any $X$ following $N(\mu,\sigma^2)$ will hold true, since $X^2$ will follow $\chi^2$ distribution which has finite mean. Edit $2$: $\mu=0$ by the second equation. So $N(0,\sigma^2)$ is one candidate. So still the question remains. Is this the only one? is there any general way to characterize all of them?","['probability-theory', 'random-variables', 'probability-distributions']"
1965673,Multiple integral over two dependent beta distributions,"I want to evaluate this multiple integral:
$$ \iiint\limits_{ \sum_{i=1}^4 x_i=1,\ \ \ x_1,\, x_2,\,x_3,\, x_4\, \ge \,0  } (x_1+x_2)^{N1} (x_3+x_4)^{N2} (x_1+x_3)^{N3} (x_2+x_4)^{N4} \, dX$$ For context, this problem comes up when computing the marginal likelihood of data consisting of two dependent binary variables $(a,b)$. The conditional probability distribution for $B$ given $A$ is:
\begin{align}
P(B=0\mid A=0)=x_1+x_2; & &  P(B=1\mid A=0)=x_3+x_4 \\
P(B=0\mid A=1)=x_1+x_3; & &  P(B=0\mid A=1)=x_2+x_4  
\end{align} The marginal likelihood turns into this integral, where $N_i$ are the counts of $B\mid A$ in the data. This looks like a dirichlet integral of type 1, but the problem is that I am unable to separate out the integral into integrals over fewer variables. I have tried: Use dirac delta function to remove the simplex and then use laplace
transform to find a closed form solution . However, it does not 
work here because the integrals are not separable. Using the variable substitution for beta variables as in this answer . Interpret the equation as product of two Beta functions: $B(N_1 +1, N_2 +1), B(N_3 +1, N_4 +1)$. However, I am stuck because $x_i$ are shared across the terms. Any ideas?","['probability-distributions', 'multivariable-calculus', 'integration', 'definite-integrals', 'beta-function']"
1965675,axiomatic definition of trigonometric functions,"A friend told me that in addition to the axioms for the real numbers, it can be proved (without appeal to sine and cosine) that a function exists satisfying the following conditions: $C(a-b)=C(a)C(b)+S(a)S(b)$ $ S(x) \geq 0 ,\forall x \in [0,p]$ $ S(p)=1$ This would allow an alternative definition of sine, cosine and even $\pi$, without using geometry, calculus or non-elementary arguments. See Timothy Gowers blogpost for a discussion of how difficult it can be to define sine. Now, using the conditions as 'axioms', I managed to show that: $C(x)$ and $S(x)$ were both periodic with period $4p$ $C^2(x)+S^2(x)=1$ $C(x+p)=-S(x)$ $S(x+p)=C(x)$ And, I found that if I defined $ \alpha_n= S(\frac{p}{2^n})$ and $\epsilon := \frac{p}{2^n}$, then I could show that $ S(x)$ could be defined as a function for countably infinite points $B = \{k \in \mathbb{Z},n \in \mathbb{N}:n\epsilon+kp\} \subset \mathbb{R}$, and simultaneously show that $\alpha_n$ was strictly decreasing. However, after this point I got stuck. I didn't manage to show the existence and uniqueness of $ S(x), \forall x \in \mathbb{R}_+\setminus B$. Can this be done without using geometry? Note: The fact that $S$ is a function is something to be proven. Writing $S(x)$ assumes functionness. So we should really be careful that we don't give circular arguments.","['real-analysis', 'trigonometry']"
1965716,Version of Hille-Yosida Theorem for non contractive semigroups,"We say that a semigroup $\{T(t)\}_{t\geq 0}$ of bounded linear operators on a Banach space $X$ is of type $(M,\omega)$ if there are constants $\omega\geq0$ and $M\geq 1$ such that
$$\|T(t)\|_{\mathcal{L}}\leq M\mathrm{e}^{\omega t},\qquad\forall\ t\geq 0.$$ Let $A:D(A)\subset X\to X$ be a linear operator. The Hille-Yosida Theorem states: The following conditions are equivalent: $A$ is the infinitesimal generator of a $C_0$-semigroup of type $(\color{red}{1},0)$ on $X$. $A$ is closed, $D(A)$ is dense in $X$, $(0,\infty)\subseteq\rho(A)$ and
  $$ \|(\lambda-A)^{-1}\|_{\mathcal{L}}\leq\frac{\color{red}{1}}{\lambda},\quad\forall\ \lambda>0. $$ By considering the rescaled semigroup $S(t)=\mathrm{e}^{-\omega t}T(t)$, we get the version below. The following conditions are equivalent: $A$ is the infinitesimal generator of a $C_0$-semigroup of type $(\color{red}{1},\omega)$ on $X$. $A$ is closed, $D(A)$ is dense in $X$, $(\omega,\infty)\subseteq\rho(A)$ and
  $$ \|(\lambda-A)^{-1}\|_{\mathcal{L}}\leq\frac{\color{red}{1}}{\lambda-\omega},\quad\forall\ \lambda>\omega. $$ Concerning to Pazy's proof, it seems to me that the argument also works with $\color{red}{1}$ replaced by $\color{red}{M}$. So, I'd like to confirm if the following conditions are equivalent: $A$ is the infinitesimal generator of a $C_0$-semigroup of type $(\color{red}{M},\omega)$ on $X$. $A$ is closed, $D(A)$ is dense in $X$, $(\omega,\infty)\subseteq\rho(A)$ and
  $$ \|(\lambda-A)^{-1}\|_{\mathcal{L}}\leq\frac{\color{red}{M}}{\lambda-\omega},\quad\forall\ \lambda>\omega.\tag{A}$$ I've never seen this version in any book. The usual generalization states: The following conditions are equivalent: $A$ is the infinitesimal generator of a $C_0$-semigroup of type $(\color{red}{M},\omega)$ on $X$. $A$ is closed, $D(A)$ is dense in $X$, $(\omega,\infty)\subseteq\rho(A)$ and
  $$ \|(\lambda-A)^{-\color{red}{n}}\|_{\mathcal{L}}\leq\frac{\color{red}{M}}{(\lambda-\omega)^{\color{red}{n}}},\quad\forall\ \lambda>\omega,\;\color{red}{\forall\ n\in\mathbb{N}}. \tag{B}$$ The Wikipedia says that this version ""is mainly of theoretical importance since the estimates on the powers of the resolvent operator that appear in $(B)$ can usually not be checked in concrete examples"".
On the other hand, it seems to me that if ""$5.\Leftrightarrow 6.$"" were true, then it would be of practical importance (because $(A)$ can be checked). So, if it is true, why it is not in the books? if it is not true, where the Pazy's argument fails?","['functional-analysis', 'semigroup-of-operators', 'partial-differential-equations']"
1965777,Substitution Makes the Integral Bounds Equal,"This seems like a really basic calculus question, which is a tad embarrassing since I'm a graduate student, but what does it mean when a substitution in a definite integral makes the bounds the same? For example, if we have some function of $\sin(x)$: $$\int_0^{\pi} f(\sin(x)) \,\mathrm{d}x$$ If we make the substitution $u = \sin(x)$, then $du = \cos(x)\,\mathrm{d}x$, we find $$\int_{\sin(0)}^{\sin(\pi)} \frac{f(u)}{\cos(x)} \,\mathrm{d}u 
= \int_0^0 \frac{f(u)}{\sqrt{1-u^2}} \,\mathrm{d}u$$ This would imply that the integral is zero. Is this always the case? For another example (more relevant to the problem I'm actually trying to solve) consider $$\int_{-b}^{b} \frac{1}{\sqrt{x^2 + a^2}}\,\mathrm{d}x$$ Clearly this can be solved using a trigonometric substitution to get $2\operatorname{arcsinh}(b)$, but what if I substituted $u = \sqrt{x^2 + a^2}$? Then $$\mathrm{d}u = \frac{x\,\mathrm{d}x}{\sqrt{x^2 + a^2}} \implies \mathrm{d}x = \frac{u\,\mathrm{d}u}{x} = \frac{u\, \mathrm{d}u}{\sqrt{u^2 - a^2}},$$ so the integral becomes $$\int_{\sqrt{b^2 + a^2}}^{\sqrt{b^2 + a^2}} 
\frac{1}{\sqrt{u^2 - a^2}}\,\mathrm{d}u$$ This integral seems to be zero, which is not the case for the integral before the substitution. What's going on here? Does this just mean that these substitutions are not valid?","['substitution', 'integration', 'calculus']"
1965789,dimension of invariant subspaces,"Let $V$ be a complex vector space, $G\subset SL_n(V)$ a finite group. Define a function $f:V\to \mathbb{Z}$ by $f(v)=\text{dim} V^{G_v}$, where $G_v$ is the stabiliser subgroup of $v$, i.e. $g\in G$ such that $gv=v$. And $V^{G_v}$ is the invariant subspace of $V$ under this subgroup. My question is: Do we know if this function is lower-semicontinuous (or maybe upper?) Does it have any semi-continuity if we consider the Zariski topology, i.e. treating $V$ as spectrum of a complex polynomial ring?","['group-actions', 'linear-algebra', 'algebraic-geometry']"
1965815,Probability that the lot contains defective articles.,"I tried much in the problem but I didn't get my answer correct. The question is--- A lot contains 20 articles.the probability that the lot contains exactly 2 defective articles is 0.4 and that the lot contains exactly 3 defective articles is 0.6.articles are drawn from the lot at random one by one without replacement and are tested till all defective articles are found.then the probability that the testing procedure ends at the twelfth testing is------ My attempt ----- let E1 be the event that the lot contains exactly 2 defective articles and E2 be the event that the lot contains exactly 3 defective articles. I noticed that $P(E1)+P(E2)=1 $and also it is easy to see E1 and E2 ate mutually exclusive. So that implies that the lot contains exactly 3 or 2 defective articles. Hence my approach was $$\frac{\binom{12}{2} \times 0.4 +\binom{12}{4} \times 0.6}{\binom{20}{12}}$$
But I am not getting the answer.please help me in this regard. Thanks.",['probability-theory']
1965855,How do I solve differential equation $\frac{dx}{dt}=x^2+5x$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question How do I solve differential equation $\frac{dx}{dt}=x^2+5x$ I don't understand what type of differential equation is this. What to do with 't', we don't have it on right side at all?",['ordinary-differential-equations']
1965892,"""Del"" operator vs Vectors","I'm reading about the del operator on wikipedia, there is a section called ""Precautions"" ( https://en.wikipedia.org/wiki/Del#Precautions ) that I'm trying to understand for the last 4 hours. Here is what it says, I've highlighted the parts I don't quite understand. Most of the above vector properties (except for those that rely explicitly on del's differential properties—for example, the product rule) rely only on symbol rearrangement, and must necessarily hold if the del symbol is replaced by any other vector. This is part of the value to be gained in notationally representing this operator as a vector . Though one can often replace del with a vector and obtain a vector identity, making those identities mnemonic , the reverse is ''not'' necessarily reliable, because del does not commute in general. A counterexample that relies on del's failure to commute:
  :\begin{align}
              (\vec u \cdot \vec v) f &\equiv (\vec v \cdot \vec u) f \\
              (\nabla \cdot \vec v) f &= \left (\frac{\partial v_x}{\partial x} + \frac{\partial v_y}{\partial y} + \frac{\partial v_z}{\partial z} \right )f
                                        = \frac{\partial v_x}{\partial x}f + \frac{\partial v_y}{\partial y}f + \frac{\partial v_z}{\partial z}f \\
              (\vec v \cdot \nabla) f &= \left (v_x \frac{\partial}{\partial x} + v_y \frac{\partial}{\partial y} + v_z \frac{\partial}{\partial z} \right )f
                                        = v_x \frac{\partial f}{\partial x} + v_y \frac{\partial f}{\partial y} + v_z \frac{\partial f}{\partial z} \\
  \Rightarrow (\nabla \cdot \vec v) f &\ne (\vec v \cdot \nabla) f \\
\end{align} A counterexample that relies on del's differential properties:
  : \begin{align}
  (\nabla x) \times (\nabla y) &= \left (\vec e_x \frac{\partial x}{\partial x}+\vec e_y \frac{\partial x}{\partial y}+\vec e_z \frac{\partial x}{\partial z} \right ) \times \left (\vec e_x \frac{\partial y}{\partial x}+\vec e_y \frac{\partial y}{\partial y}+\vec e_z \frac{\partial y}{\partial z} \right ) \\
                               &= (\vec e_x \cdot 1 +\vec e_y \cdot 0+\vec e_z \cdot 0) \times (\vec e_x \cdot 0+\vec e_y \cdot 1+\vec e_z \cdot 0) \\
                               &= \vec e_x  \times \vec e_y \\
                               &= \vec e_z \\
  (\vec u x )\times (\vec u y) &= x y (\vec u \times \vec u) \\
                               &= x y \vec 0 \\
                               &= \vec 0
\end{align} Central to these distinctions is the fact that del is not simply a vector; it is a vector operator. Whereas a vector is an object with both a magnitude and direction, del has neither a magnitude nor a direction until it operates on a function. For that reason, identities involving del must be derived with care, using both vector identities and differentiation identities such as the product rule . 1) What are other representations for del? 2) What is a ""mnemonic identity""? 3) The final part I don't understand at all. Why I must use vector identities and del differential properties? Is it all ""unnecessary"" pedantry? Is it worth being aware of this all?
Before reading this wikipedia page I thought I knew how to use the del operator, now I'm confused. Please help-me clarify all this mess in my head. Thank you.","['derivatives', 'calculus', 'multivariable-calculus', 'differential-operators', 'vector-analysis']"
1966012,Existence and uniqueness theorem - ODE solutions,"So we have an ODE namely $$\frac{dy}{dx} =\frac{-x+\sqrt{x^2+4y}}{2}, \ y(2)=-1 $$. 
Ok so we have two solutions $y_1=1-x$ which is valid for $x\geq 2 $ and $y_2=-x^2/4$ which seems to be valid for $x\in \mathbb{R} $. 
Now a question asks how the existence of two solutions to the initial value problem does not contradict the existence and uniqueness theorem. 
Anyone have a simple explanation?","['derivatives', 'differential', 'integration', 'ordinary-differential-equations']"
1966026,"Trying to prove, by induction, that $2^{4n} + 5 $ is divible by $21.$","I want show by induction $$ 21 \mid (2^{4n}+5) $$ So I assume: $ 2^{4k}+5= 21p$ to prove that $ 21 \mid 2^{4(k+1)}+5 $ So I get it: $2^{4(k+1)}+5 = 2^{4k+4}+5 = 2^{4k}2^{4}+
2^{4}2^{4k}+5 = 2^{4k} 16 +5 $ = $16(2^{4k} +5 -5 )+5 = 16(21p-5)+5 = 16 \cdot 21p - 80+5 = 16 \cdot 21p - 75 $ But its not divisible by 21. Whats I doing wrong ?","['algebra-precalculus', 'discrete-mathematics']"
1966057,What is $\lim\limits_{n\to\infty}\frac {1}{n^2}\sum\limits_{k=0}^{n}\ln\binom{n}{k} $?,It was originally asked on another website but nobody has been able to prove the numerical result. The attempts usually go by Stirling's approximation or try to use the Silverman-Toeplitz theorem.,"['factorial', 'sequences-and-series', 'calculus', 'limits']"
1966062,How do you find the area of a parallelogram with the vertices? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question How do you find the area of a parallelogram with the following vertices; $A(4,2)$, $B(8,4)$, $C(9,6)$ and $D(13,8)$.","['analytic-geometry', 'area', 'geometry']"
1966106,A proof that parallel transport preserves orientation,"Let $M$ be a riemannian manifold (With the Levi-Civita connection), $c$ a curve in $M$ with $c(t_0)=c_0,c(t)=c_t$ $P_{c,t_0,t}$ denote the function $T_{c_0}M\to T_{c_t}M$ given by parallel transporting each tangent vector $v\in T_{c_0}M$ to $T_{c_t}M$ along the curve $c$. I want to prove that $P=P_{c,t_0,t}$ is an isometry which preserves orientation, given that $M$ is orientable. I've already proven that it's an isometry and its inverse is given by $P_{c,t,t_0}$. I now want to prove, that, with the orientation induced by
$\phi_t:\mathbb{R}^n\to T_{c_t}M$ with $\phi_t(e_i)=\partial_{i,c_t}$ the orientation is preserved. In other words, the mapping $P':T_{c_t}M\to T_{c_t}M$ given by $\partial_{i,c_t}\mapsto P_{c,t_0,t}\partial_{i,c_0}$ has positive determinant with respect to those bases. Since it's an isometry, then its determinant is $\pm 1$, so I just have to prove it's $1$. If the function $d:\text{dom} c\to \mathbb{R}$ given by $t\mapsto \det P'$ is continuous, then since $d(t_0)=1$, if $d(t_1)=-1$ there would be some $t\in (t_0,t_1)$ such that $d(t)=0$ and this is impossible. So the only thing left is to prove that $d$ is continuous. How could I do that? An idea would be, that this function can be seen as a composition of continuous functions: $t_0\stackrel{V}{\to} V_{c(t_0)}\stackrel{P}{\to} V_{c(t)}\stackrel{?}{\to}d(t_0)$
but I'm not sure what would go in ?.","['riemannian-geometry', 'differential-geometry']"
1966182,Seeking an intuitive explanation of the Mapping Class Group,"For a surface $S$ the mapping class group $MCG(S)$ of $S$ is defined as the group of isotopy classes of orientation preserving diffeomorphisms of $S$:
$$MCG(S)=Diff^+(S)/Diff_0(S).$$ I understand this definition as well as all of its component pieces. What I don't understand is why this quotient is a natural thing to study. Specifically, I can see why the full diffeomorphism group $Diff(S)$ would be natural to study, and if $S$ happens to be orientable, I can see why it would be reasonable to restrict ones attention to $Diff^+(S)$. However, I don't see why the quotient is a natural or intuitive next step. Is there a good explanation why diffeomorphisms that are isotopic to the identity are 'uninteresting'? Thanks!","['differential-geometry', 'mapping-class-group']"
1966188,Problem based on ages of two persons.,"Bibhu said to Bigyata, ""I was twice as old as you were when I was as old as you are."". If the sum of their ages is 35 years, find their present ages. My Attempt: Let the present ages of Bibhu and Bigyata be $x$ years and $y$ years respectively.
From the second statement of the question:
$x+y=35$. $y=35-x$. But I did not understand the first condition(the first statement) given in the question. Please help.","['algebra-precalculus', 'systems-of-equations']"
1966211,Probability vs Confidence,"My notes on confidence give this question: An investigator is interested in the amount of time internet users spend watching TV a week. He assumes $\sigma = 3.5$ hours and samples $n=50$ users and takes the sample mean to estimate the population mean $\mu$ Since $n=50$ is large we know that $\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}$ approximates the Standard Normal. So, with probability $\alpha = 0.99$ , the maximum error of estimate is $E = z_{\alpha/2} \times \frac{\sigma}{\sqrt{n}} \approx 1.27$ hours. The investigator collects that data and obtain $\bar{X}=11.5$ hours. Can he still assert with 99% probability that the error is at most 1.27 hours? With the answer that: No he cannot, because the probability describes the method/estimator, not the result . We say that ""we conclude with 99% confidence that the error does not exceed 1.27 hours."" I am confused. What is this difference between probability and confidence? Is it related to confidence intervals? Is there an intuitive explanation for the difference?","['statistical-inference', 'statistics', 'estimation', 'probability', 'confidence-interval']"
1966227,strange duel chances and my analysis,"There is two guy, A and B they are shooting each other by turns, A shoot first, A has 30 percent chances to shoot and kill B and 70 percent to miss, B has 50 percent chances to kill A and 50 percent to miss.  A takes the first shot. So I first encounter this kind of questions, here is my analysis:
first attempt: I think A has 30 percent to kill B, then if he succeed, then he will not die, so his prob of death is 0, but if he missed, next round B will take the gun, so A can see he might die at next round is 70 percent of miss multiply 50 percent of B's shot, which equas to 35 percent, then next round......... Don't laugh I realized this is an endless loop and you don't know when the game will over because it's a probability game, of course my statistics grade in my school is so bad... next attempt: So I try to understand this thing, normally if I am in this duel I would like to take first shot, I don't know why, cause if I am lucky and shoot that motherfucker to death at first round then I don't have to worry about dying, so I think the person first shoot has some advantage? I don't do any calculation at this attempt. last attempt: Okay I feel the person first shoot has some advantages somehow but I don't really know, so I choose to ignore it and some how I figured an equation like $$\dfrac{\dfrac1{0.3}}{\dfrac1{0.3}+\dfrac1{0.5}}$$ as B's chance of winning? I feel it's not right either... It's really some tough question, cuz I never encounter this thing before, and it seems easy but I can't find the direction to solve it, anyone can help a brother out? thx!","['statistics', 'simulation', 'probability']"
1966233,Prove that number of parenthesizing is Catalan number,"Consider a product of 4 numbers, abcd. It can be “parenthesized” in
5 ways: $((ab)c)d, (a(bc))d, (ab)(cd), a((bc)d),$ and $ a(b(cd))$. Prove that
the number of such parenthesizings of a product of n numbers is the
Catalan number $b_{n-1}$. I don't know how to begin.","['combinatorics', 'catalan-numbers', 'discrete-mathematics']"
1966283,How do I find a flaw in this false proof that $7n = 0$ for all natural numbers?,"This is my last homework problem and I've been looking at it for a while. I cannot nail down what is wrong with this proof even though its obvious it is wrong based on its conclusion. Here it is: Find the flaw in the following bogus proof by strong induction that
  for all $n \in \Bbb N$, $7n = 0$. Let $P(n)$ denote the statement that $7n = 0$. Base case: Show $P(0)$ holds. Since $7 \cdot 0 = 0$, $P(0)$ holds. Inductive step: Assume $7·j = 0$ for all natural numbers $j$ where $0 \le j \le k$ (induction hypothesis). Show $P(k + 1)$: $7(k + 1) = 0$. Write $k + 1 = i + j$, where $i$ and $j$ are natural numbers less than $k + 1$.  Then, using the induction hypothesis, we get $7(k + 1) = 7(i + j) = 7i + 7j = 0 + 0 = 0$. So $P(k + 1)$ holds. Therefore by strong induction, $P(n)$ holds for all $n \in \Bbb N$. So the base case is true and I would be surprised if that's where the issue is. The inductive step is likely where the flaw is. I don't see anything wrong with the strong induction declaration and hypothesis though and the math adds up! I feel like its so obvious that I'm just jumping over it in my head.","['induction', 'fake-proofs', 'discrete-mathematics']"
1966306,"if $abc=1$,show that $a^3+b^3+c^3+\frac{256}{(a+1)(b+1)(c+1)}\ge 35$","Let $a,b,c>0,abc=1$ show that $$a^3+b^3+c^3+\dfrac{256}{(a+1)(b+1)(c+1)}\ge 35\tag{1}$$ iff $a=b=c=1$ I know use AM-GM inequality $$a^3+b^3+c^3\ge 3abc=3$$ and $$(a+1)(b+1)(c+1)\ge 2\sqrt{a}\cdot 2\sqrt{b}\cdot 2\sqrt{c}=8$$ In this way, will lead to inequality reverse, but $(1)$ seem is right,so How to prove this inequality","['multivariable-calculus', 'inequality', 'uvw', 'symmetric-polynomials']"
1966390,How to compute $\mathbb{E}(\exp(\int_0^t W_s ds)|W_t)$?,"I am trying to compute the conditional expectation $$\mathbb{E}\left[\exp\left(\int_0^t W_s ds\right)\middle|\, W_t\right]$$ where $W$ is a standard Wiener process and where $s\le t$. To initially simplify the problem, I have started with the calculations of $\mathbb{E}[W_s|W_t]$ and $\mathbb{E}\left[\int_0^t W_s \,ds\middle|\,W_t\right]$. On the one hand, since $W_t$ and $W_s- \frac{s}{t}W_t$ are independent (having zero covariance and using a gaussian vector argument), we can see that:
$$\mathbb{E}\left[W_s\middle | W_t\right]=\mathbb{E}\left[W_s-\frac{s}{t}W_t\middle |\, W_t\right]+\frac{s}{t}W_t=\frac{s}{t}W_t$$
On the other hand, by independence of $W_t$ and $\int_0^t (W_s- \frac{s}{t}W_t)ds$:
\begin{align}\mathbb{E}\left[\int_0^t W_s ds\middle|\,W_t\right]&=\mathbb{E}\left[\int_0^t \left(W_s-\frac{s}{t}W_t\right) ds\,\middle |\, W_t\right]+\frac{t}{2}W_t\\[0.3cm]&=\int_0^t \mathbb{E}\left[W_s-\frac{s}{t}W_t\right]ds+\frac{t}{2}W_t=\frac{t}{2}W_t\end{align}
Coming back to our initial problem, we thus have:
$$\mathbb{E}\left[\exp\left(\int_0^t W_s ds\right)\,\middle|\,W_t\right]=\exp\left(\frac{t}{2}W_t\right)\mathbb{E}\left[\exp\left(\int_0^t \left(W_s-\frac{s}{t}W_t\right) ds\right)\,\middle|\,W_t\right]$$
We also know that $\int_0^t \left(W_s-\frac{s}{t}W_t\right)ds$ is normally distributed with zero mean (easy to see) and variance given by:
$$\mathbb{E}\left[\int_0^t\int_0^t \left(W_s- \frac{s}{t}W_t\right)\left(W_u- \frac{u}{t}W_t\right)dsdu\right]=\int_0^t\int_0^t\left(\min(s,u)-\frac{su}{t}\right)dsdu=\frac{t^3}{12}$$
By independence of $W_t$ and $\exp\left(\int_0^t \left(W_s- \frac{s}{t}W_t\right)ds\right)$, we finally obtain ($Z$ being a standard unit normal variable):
$$\mathbb{E}\left[\exp\left(\int_0^t W_s ds\right)\,\middle|\,W_t\right]=\exp\left(\frac{t}{2}W_t\right)\mathbb{E}\left[\exp\left(Z\sqrt{\frac{t^3}{12}}\right)\right]
=\exp\left(\frac{t}{2}W_t+\frac{t^3}{24}\right)$$
However, I am not sure if this answer and the arguments I have used are correct? Any ideas or comments would be greatly appreciated.","['stochastic-processes', 'probability-theory', 'probability', 'brownian-motion', 'stochastic-calculus']"
1966393,"Why does $ \frac{\partial r_i}{\partial r_j} \neq \frac{\partial r_i}{\partial r}\frac{\partial r}{\partial r_j} $ for $ i, j \in \{x,y,z\} $?","I have a function f(r) that depends only on the distance from the origin. I need to find $ \frac{\partial^2 f}{\partial r_i \partial r_j} $ where $ i, j \in \{x,y,z\} $; in other words, I need to find $ \begin{bmatrix}
\frac{\partial^2}{{\partial x}^2} & \frac{\partial^2}{\partial y \partial x} & \frac{\partial^2}{\partial z \partial x} \\ \frac{\partial^2}{\partial x \partial y}
 & \frac{\partial^2}{{\partial y}^2} & \frac{\partial^2}{\partial z \partial y}\\ 
 \frac{\partial^2}{\partial x \partial z} & \frac{\partial^2}{\partial y \partial z} & \frac{\partial^2}{{\partial z}^2}
\end{bmatrix} f $. I apply the chain rule $ \frac{\partial f}{\partial r_i} = \frac{\partial f}{\partial r}\frac{\partial r}{\partial r_i} $ and again $ \frac{\partial^2 f}{\partial r_i \partial r_j} = \frac{\partial}{\partial r}(\frac{\partial f}{\partial r_i})\frac{\partial r}{\partial r_j} $. These leave me with a cross term $ \frac{\partial r_i}{\partial r}\frac{\partial r}{\partial r_j} $. Now I have a choice: Evaluate $ \frac{\partial r}{\partial r_i} = \frac{r_i}{r} $ and $ \frac{\partial r_j}{\partial r} = (\frac{\partial r_j}{\partial r})^{-1}  = \frac{r}{r_j} $ right away, leaving me with $ \frac{\partial r_i}{\partial r}\frac{\partial r}{\partial r_j} = \frac{r_j}{r_i} $ . Cancel the $ \partial r $'s, leaving me with $ \frac{\partial r_i}{\partial r}\frac{\partial r}{\partial r_j} = \frac{\partial r_i}{\partial r_j} = \delta_{ij} $ . As far as I can tell, these two results are not equivalent. This comes from one of those ""show this is true"" homework problems, so I know the correct method is method 2. So what did I do wrong in method 1?","['multivariable-calculus', 'tensors']"
1966409,Prove $\operatorname{GL}_n(\mathbb{R})$ has no subgroup of finite index,"We are asked to prove that $\operatorname{GL}_n(\mathbb{R})$ has no subgroup of finite index. And think about $\operatorname{GL}_n(\mathbb{Z})$ with the same question. However, I think if there is a homomorphism $\varphi\colon\operatorname{GL}_n(\mathbb{R}) \to C = \left \{  1, -1\right \}$ , which take matrix with positive determinant to 1 while matrix with negative determinant to -1, then the kernel is a subgroup with finite index. Am I wrong?","['abstract-algebra', 'group-theory']"
1966410,How to solve for the roots of a 4th degree polynomial with complex coefficients?,"Given the following equation $c_4Z^4+c_3Z^3+c_2Z^2+(c_1+\frac{i}{\beta})Z^1-\frac{i}{\beta} =0$ where $Z$ lies in the complex domain. Each of the coefficients, $c_n$ for $n=1:4$, are real and can be either positive or negative. They are known, but left as variables here for the sake of generality. My objective is to determine expressions for each of the 4 roots and plot them versus $\beta$. I have done this numerically using Matlab's roots function and got the correct results, but in order to plot each of the roots as a function of $\beta$ in a meaningful way, I have to sort them to appear as continuous curves or plot them as points in a scatter plot. Either way, it takes way too long to explore the full complex domain for $\beta$. This is a whole other issue, so don't lose focus here. That being said, I'm wondering if I can solve for each of the roots in the form of an analytic expression as a function of $\beta$? If so, I could program each of the expressions as anonymous functions and save a bunch of time exploring the complex domain for $\beta$. Unfortunately, my subpar math skills have left me scratching my head on how to proceed. I've looked at a bunch of different examples/tricks on determining the roots for 4th degree polynomials, but they all seem to apply to real polynomials with real coefficients. In the polynomial I've expressed above, $\beta$ can be complex. So again, my question is, can I solve for each of the roots in the form of an analytic expression as a function of $\beta$ and if so, how do I proceed given the complex nature of the polynomial?","['complex-analysis', 'roots', 'polynomials', 'complex-numbers']"
1966523,integration of a nonnegative definite matrix,"I wanted to know, whether the integration of a nonnegative definite matrix is again going to be a nonnegative definite matrix?
for example, if $A(t)$ is a nonnegative definite  $n\times n$ matrix, then what we can tell about $\int_{a}^{b} A(t) dt,$   where $t\in [a, b]$","['matrices', 'linear-algebra']"
1966567,Limit of a sequence of intervals,"Let $\{a_n\}_{n\geqslant 1} $ be a sequence such that $a_n>0\ \forall n$ and $\lim_{n\to\infty} a_n=0$ . What will be $$\bigcup_{n=1}^\infty [a_n,1) \ \ =?$$ Will it be $(0,1)$ or $[0,1)$ ? Edit: This was originally a part of a larger question. Consider $2$ sequences $\{a_n\}\ \&\ \{b_n\}$ with $a_n>0$ and $b_n>1$ for all $n$ and $\lim_{n\to\infty}a_n=0$ and $\lim_{n\to\infty}b_n=1$. Define $A_n=[a_n,b_n)$. Find $\limsup_{n\to\infty} A_n$ and $\liminf_{n\to\infty} A_n$ Can someone confirm me whether both the answers are $(0,1)$ or not?","['sequences-and-series', 'interval-arithmetic', 'limits']"
