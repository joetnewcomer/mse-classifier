question_id,title,body,tags
3074388,The closest value to $\int_0^1 \sqrt{1+\frac{1}{3x}} dx$?,"This is a multiple choice among 1.6, 2, 1.2. So the approximation should be sufficiently accurate. The solution is 1.6 as can be verified using Taylor expansion. But Taylor expansion method takes too long and this is supposed to be answered quickly. I wonder what alternatives there are to approx integral question like this. Thanks!","['integration', 'calculus', 'definite-integrals']"
3074457,Change of variables and the partial derivative,"From time to time, I suddenly get confused with a change of variables in a partial derivative. Here, I am trying to perform a change of variables $(x,t) \mapsto (\xi, \eta)$ where $$\xi = t \qquad \qquad \text{and} \qquad \qquad \eta = x+t$$ The question is, how to compute $$\frac{\partial u}{\partial t}$$ in the new coordinate system? Intuitively, since $\xi = t$ (or rather $t=\xi$ ), we should have $$\frac{\partial u}{\partial t} = \frac{\partial u}{\partial \xi}$$ However, applying the chain rule for partial derivatives, we instead get $$\frac{\partial u}{\partial t} = \frac{\partial u}{\partial \xi}\frac{\partial \xi}{\partial t} + \frac{\partial u}{\partial \eta}\frac{\partial \eta}{\partial t} = \frac{\partial u}{\partial \xi}(1) + \frac{\partial u}{\partial \eta}(1) = \frac{\partial u}{\partial \xi} + \frac{\partial u}{\partial \eta}$$ So which one is correct?","['partial-derivative', 'multivariable-calculus', 'change-of-variable']"
3074484,Why products do not exist in the category of measurable spaces and probability kernels?,"Consider a category whose objects are measurable spaces and morphisms are probability kernels (also called stochastic kernels or Markov kernels). That is, objects are pairs $(X,\mathbf{A})$ where $\mathbf{A}$ is a $\sigma$ -field of subsets of $X$ , and morphisms $F\colon(X,\mathbf{A})\to(Y,\mathbf{B})$ are maps $F\colon X\times\mathbf{B}\to [0,1]$ such that $F_x\colon B\mapsto F(x,B)$ is a probability measure for every $x\in X$ , $F_B\colon x\mapsto F(x,B)$ is a measurable function for every $B\in\mathbf{B}$ . The composition $G\circ F$ of morphisms $F\colon(X,\mathbf{A})\to(Y,\mathbf{B})$ and $G\colon(Y,\mathbf{B})\to(Z,\mathbf{C})$ is defined by $$(G\circ F)(x,C)=\int_{y\in Y}G_C(y)\,\mathrm{d}F_x.$$ This category was introduced by Lawvere in 1962, see here . Various papers mention as a clear fact that products do not exist in this category. Could someone please provide an argument that would make this fact clear also to me?","['measure-theory', 'probability-theory', 'category-theory']"
3074537,Which of these numbers could be the exact number of elements of order $21$ in a group?,"I'm reading ""Contemporary Abstract Algebra,"" by Gallian. This is Exercise 4.46. Which of the following numbers could be the exact number of elements of order $21$ in a group: $21600, 21602, 21604$ ? My Attempt: Lemma: In a finite group, the number of elements of order $d$ is a multiple of $\varphi(d)$ . (This is a Corollary of Theorem 4.4 ibid.) Since $\varphi(21)=12$ and $12\mid 21600$ but not the other two candidate numbers, the lemma above implies that $21600$ is the exact number of elements of order $21$ for some (finite) group. I'm quite sure I got this right $^{\dagger}$ . I intuited the result, having forgotten the Lemma (well, Corollary) above. This question is just so I can make note of it, really, but I suppose I could use the post to ask the following: Is the assumption that the group is finite necessary? My guess is that it's not. I have a rough idea of using a presentation with some free generators in such a way that it has the required number of order $21$ elements all within some finite subgroup (and no other such elements in the group given by the presentation). Please help :) Here $\varphi$ is Euler's totient function. $\dagger$ The Dunning-Kruger effect in action . . . It's the right number, yeah, but, as pointed out below , I didn't show that such a group actually exists .","['group-presentation', 'group-theory', 'finite-groups', 'totient-function']"
3074572,Find the limit $\lim_{n\to\infty}\frac{x_n + x_n^2 + \cdots + x_n^k - k}{x_n - 1}$ given $x_n \ne 1$ and $\lim x_n = 1$,"Let $x_n$ denote a sequence, $n\in\Bbb N$ . Evaluate the limit: $$
\lim_{n\to\infty} \frac{x_n + x_n^2 + \cdots + x_n^k - k}{x_n - 1},\ k\in\Bbb N
$$ given $$
\lim_{n\to\infty} x_n = 1 \\ 
x_n \ne 1
$$ I'm interested in verifying the following results. Denote: $$
y_n = \frac{x_n + x_n^2 + \cdots + x_n^k - k}{x_n - 1}
$$ After some trials long division seem to produce a pattern here. Not sure how to put it here in a fancy way, so I will post the result only. It appears that: $$
y_n = x_n^{k-1} + 2x_n^{k-2}+\cdots + (k-1)x_n + k
$$ It is given that $\lim x_n = 1$ therefore we may use the following properties: $$
\lim(a_n + b_n) = \lim a_n + \lim b_n\\
\lim(a_n \cdot b_n) = \lim a_n \cdot \lim b_n
$$ In particular: $$
y_n = x_n^{k-1} + 2x_n^{k-2}+\cdots + (k-1)x_n + k\\
\lim_{n\to\infty}y_n =\lim_{n\to\infty}\left(x_n^{k-1} + 2x_n^{k-2}+\cdots + (k-1)x_n + k\right)
$$ Then since $\lim x_n = 1$ and by the sum of first $k$ integers: $$
\lim_{n\to\infty} y_n = \frac{k(k+1)}{2}
$$ Could you please verify whether the reasoning above is correct or not and point to the mistakes in case of any? Thank you!","['limits', 'calculus', 'proof-verification', 'sequences-and-series']"
3074593,What is actually the geometry or analysis behind the fact that $Mob(\hat{\Bbb C})$ is simple?,"Let, $Mob(\hat{\Bbb C})$ be the group of all Mobius transformations from the extended complex plane to itself i.e. from $\hat{\Bbb C} \to \hat{\Bbb C}$ . I have been able to prove that (i) $Mob(\hat{\Bbb C}) \cong PSL_{2}(\Bbb C)$ where $PSL_{2}(\Bbb C)$ is defined to be , $PSL_{2}(\Bbb C) := SL_{2}(\Bbb C)/ \{\pm I\}$ and that, (ii) $SL_{2}(\Bbb C)$ does not have a proper normal subgroup containing its center i.e. $\{\pm I\}$ and thus by correspondence theorem, $PSL_{2}(\Bbb C) = SL_{2}(\Bbb C)/ \{\pm I\}$ is simple. Combining (i) and (ii) we get that $Mob(\hat{\Bbb C})$ is simple! My question precisely is, What is actually the geometry or analysis behind the fact that $Mob(\hat{\Bbb C})$ is simple ?","['complex-analysis', 'geometry', 'mobius-transformation']"
3074620,Can I take a derivative of any complex function so long as I treat the complex numbers as matrices?,"Complex numbers can be represented as matrices, for example $$
a+bi \leftrightarrow \pmatrix{a &b\\-b&a}
$$ Only some functions of a complex variable have a derivative that is a complex number (those which are holomorphic). However, I can take derivatives of all smooth maps from matrices to matrices, even those that correspond to functions that are not holomorphic. What gives?","['matrices', 'complex-analysis']"
3074630,Probability that $25$ calls are received in the first $5$ minutes.,"Calls are received at a company according to a Poisson process at the
  rate of 5 calls per minute. Find the probability that $25$ calls are
  received  in the first $5$ minutes and six of those calls occur during
  the first minute. Denote the number of calls with $N_t$ at time $t$ . We have that $N_t\sim\text{Poi}(\lambda t),$ where $\lambda=5$ . We are looking for $$\mathbb{P}(N_5=25\ | \ N_1=6 )=\frac{\mathbb{P}(N_1=6,N_5-N_1=19)}{\mathbb{P}(N_1=6)}=\frac{\mathbb{P}(N_1=6,\tilde{N_4}=19)}{\mathbb{P}(N_1=6)}=...$$ by stationary increments. Independent icrements also give that we can proceed with $$...=\frac{\mathbb{P}(N_1=6)\mathbb{P}(\tilde{N_4}=19)}{\mathbb{P}(N_1=6)}=\mathbb{P}(\tilde{N_4}=19)=\frac{(5\cdot 4)^{19}e^{-5\cdot 4}}{19!}\approx0.0888.$$ Which is incorrect. However I get the correct answer if I, with the same method using increments, calculate $\mathbb{P}(N_5=25\ , \ N_1=6 ).$ Question: Why is it wrong to calculate $\mathbb{P}(N_5=25\ | \ N_1=6 )$ ? To me this seems intuitive: We want to find the probability that $25$ calls are received given that $6$ calls already have happened in the first minute.","['poisson-distribution', 'probability-theory', 'probability', 'poisson-process']"
3074662,Is there a way to evaluate analytically the following infinite double sum?,"Consider the following double sum $$
S = \sum_{n=1}^\infty \sum_{m=1}^\infty
\frac{1}{a (2n-1)^2 - b (2m-1)^2} \, ,
$$ where $a$ and $b$ are both positive real numbers given by \begin{align}
	a &= \frac{1}{2} - \frac{\sqrt{2}}{32}  \, , \\
	b     &= \frac{1}{4} - \frac{3\sqrt{2}}{32}  \, .
\end{align} It turns out that one of the two sums can readily be calculated and expressed in terms of the tangente function.
Specifically, $$
S = \frac{\pi}{4\sqrt{ab}} \sum_{m=1}^\infty 
\frac{\tan \left( \frac{\pi}{2} \sqrt{\frac{b}{a}} (2m-1) \right)}{2m-1} \, .
$$ The latter result does not seem to be further simplified. i was wondering whether someone here could be of help and let me know in case there exists a method to evaluate the sum above. Hints and suggestions welcome. Thank you PS From numerical evaluation using computer algebra systems, it seems that the series is convergent. This apparently would not be the case if $b<0$ .","['summation', 'real-analysis', 'calculus', 'sequences-and-series', 'trigonometry']"
3074737,"Solving a Cauchy problem, differential equation",I have the following Cauchy problem \begin{cases} y'(x) + \frac{1}{x^2-1}y(x) = \sqrt{x+1} \\ y(0) = 0 \end{cases} I proceed by finding $e^{A(x)}  $ where $A(x)$ is the primitive of $a(x)= \frac{1}{x^2-1}$ : $$\int A(x)dx=\int \frac{1}{x^2-1}dx= \frac{1}{2} \log\Big(\frac{|x-1|}{|x+1|}\Big)+c  $$ then  I obtain : $$e^{A(x)}=e^{\frac{1}{2} \log\Big(\frac{|x-1|}{|x+1|}\Big)}=\Big(\frac{|x-1|}{|x+1|}\Big)^{\frac{1}{2}}=\sqrt{\frac{|x-1|}{|x+1|} }$$ I have attempted to solve it in this way: $$ \sqrt{\frac{|x-1|}{|x+1|} }\cdot y'(x) + \frac{1}{x^2-1}\cdot \sqrt{\frac{|x-1|}{|x+1|} }y = \sqrt{x+1}\cdot\sqrt{\frac{|x-1|}{|x+1|} }$$ $$\sqrt{\frac{|x-1|}{|x+1|} }*y(x) =\int \sqrt{\frac{x+1}{|x+1|}}\cdot\sqrt{|x-1|}dx$$ $$y(x) =\Big(\sqrt{\frac{|x-1|}{|x+1|} }\Big)^{-1}\cdot\int \sqrt{\frac{x+1}{|x+1|}}\cdot\sqrt{|x-1|}dx$$ Is it correct doing this? From here I am not sure how to proceed. Thanks in advance for any help.,"['cauchy-problem', 'ordinary-differential-equations']"
3074765,Binomial sum which adds to $2^n n!$,"I'm looking for a combinatorial interpretation for the identity $$
  \sum_{k=0}^n\binom nk (2k-1)!!\,(2n - 2k - 1)!! = 2^n n!
$$ where $(2n - 1)!! = (2n - 1)(2n - 3) \cdots 5 \cdot 3 \cdot 1$ . Perhaps the most natural interpretation of the right-hand side is the number of $2$ -colorings of the letters of the permutations on $[n] = \{1,2,...,n\}$ . However, I can't find a way to make the sum fit this interpretation. Perhaps there is a way to use the fact that $(2n-1)!!$ is the number of ways to choose $n$ disjoint pairs of items from $2n$ items ? We can do some trickery to show that this is equivalent to showing that $$
\sum_{k=0}^n\binom{2n}{n}\binom{2n-2k}{n-k} = 4^n,
$$ which is addressed by this question , but I'm interested in the earlier interpretation.","['binomial-coefficients', 'combinatorics', 'combinatorial-proofs']"
3074775,When is a Lebesgue integrable function a Riemann integrable function?,"When is a Lebesgue integrable function a Riemann integrable function ? And if we have $f\in \mathcal{L}^1([0,1],\lambda)$ , does it implies that $f$ is Riemann integrable, and why ?","['integration', 'riemann-integration', 'lebesgue-integral']"
3074793,Equivalence of definitions for the approximate point spectrum,"Let $T: X \rightarrow X$ be a continuous, linear operator on some Banach space $X$ . We defined the approximate point spectrum $AP\sigma(T)$ as the set $$
\{ \lambda \in \mathbb{C} : \lambda - T \;\text{is not injective or}\; \text{Im}(\lambda - T) \;\text{is not closed in X} \}.
$$ I want to show equivalence with the definition $$
\lambda \in AP\sigma(T) :\Leftrightarrow \exists (x_n) \subset X, \Vert x_n \Vert =1 \;\text{with}\; \Vert \lambda x_n - Tx_n\Vert \rightarrow 0.
$$ What I have done: "" $\Leftarrow$ "". What I need: Show that if $\lambda -T$ is injective and $\text{Im}(\lambda - T)$ is not closed in $X$ , then there is a sequence such as above.","['spectral-theory', 'functional-analysis']"
3074824,"Convergence in $C([0,T_0],L^2)$ and uniform boundedness in $C([0,T_0],H^2)$ gives convergence in $C([0,T_0],H^1)$.","Let $\Omega$ be a compact set of $\mathbb{R}$ and $s\geq 1$ . Let $$
v_n\in C([0,T_0];H^{s+1}(\Omega)).
$$ Also $\sup_{t\in[0,T_0]} ||v_n||_{H^{s+1}(\Omega)}\leq M$ , $M$ is a constant. We are also given that $$ 
v_n\longrightarrow v \quad\text{   in  }  \quad C([0,T_0];L^2(\Omega)).
$$ How do I show that $$
v_n\longrightarrow v\quad\text{   in  }  \quad C([0,T_0];H^s(\Omega))?
$$ Note : This problem is a portion of a paper I am reading. As an argument for this problem, the authors write ‘interpolating the given convergence with the uniform bound estimates’. I don’t know what they mean by this.","['convergence-divergence', 'sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
3074905,"A curve through two vertices of a triangle, whose tangent lines bisect the area of that triangle","Say we have a triangle $ABC$ . I want to find a curve $\gamma:[0,1]\to\mathbb{R}^2$ such that $\gamma(0)=A$ , $\gamma(1)=B$ and for all $t\in(0,1)$ the tangent line at $\gamma(t)$ divides $\triangle ABC$ into two pieces of same area (a smaller triangle and a quadrilateral). The curve can be as smooth as you might need of course. I came up with this problem about a week ago and got a bunch of few equations at first. Now I'm otherwise engaged so I'm posting the problem before I forget about it. Cheers!","['locus', 'geometry', 'differential-geometry']"
3074960,"A connected, but not path-connected, space whose fundamental group depends on the basepoint","It is a well known result that the fundamental group of a path-connected space is independent (up to isomorphism) of the choice of the basepoint.
Can someone provide an explicit example of a connected, but not path-connected, space for which the fundamental group does indeed depend on the basepoint?","['general-topology', 'examples-counterexamples', 'algebraic-topology']"
3074996,"Why do the ""rules"" of horizontal asymptotes of rational functions work?","Note: My current understanding is only at a college algebra level From what I've seen online, in layman terms, the rules for horizontal asymptotes are as follows: Rule 1) If the degree of the numerator is less than the degree of the denominator, then the horizontal asymptote will be $y=0$ Rule 2) If the numerator and denominator have equal degrees, then the horizontal asymptote will be a ratio of their leading coefficients Rule 3) If the degree of the numerator is exactly one more than the degree of the denominator, then the oblique asymptote is found by dividing the numerator by the denominator. The resulting quotient is a linear expression which defines the oblique asymptote, and if there's a remainder, it's discarded. For the first rule, I somewhat understand why the horizontal asymptote would be $y=0$ If the degree of the denominator is larger than the degree of the numerator, then the denominator is increasing at a faster rate than the numerator as $x\rightarrow\infty$ . The numerator ""can't keep up"" and it would be getting divided by increasingly larger values so the outputs would be getting smaller and smaller approaching $0$ . Am I on the right track with my thinking here? For rule 2 I'm not sure why the ratio of the leading coefficients of the numerator and denominator are used as the horizontal asymptote. For Rule 3 why divide the numerator by the denominator to get an oblique asymptote? Why isn't there a horizontal asymptote instead?","['algebra-precalculus', 'rational-functions']"
3074999,Function whose graph is dense in the plane [duplicate],This question already has an answer here : graph is dense in $\mathbb{R}^2$ (1 answer) Closed 5 years ago . Is there a function $f:\mathbb R\to\mathbb R$ such that for every disc in $\mathbb R^2$ the graph of that function has at least one point that lies inside that disc? I searched for something similar but don't know which phrases to use. The general/another problem is that: does there exist a function $f:\mathbb R\to\mathbb R$ such that its graph in some sense has a positive area or even an infinite area?,"['functions', 'area', 'real-analysis']"
3075020,"Is there a reason why $Z(G)$ is named the ""centre"" of a group?",I just stumbled upon the definition of the center Z of a group G: $$Z= \{x \in G \mid xz = zx \text{ for all } z \in G\}$$ The name “center” seems to suggest that there is some kind of geometric interpretation of the concept which I fail to see. My question is the following: is there some intuition/motivation behind the choice of naming $Z$ the “center” of a group?,"['group-theory', 'abstract-algebra']"
3075057,When is a group homomorphism “extendable”?,"$\newcommand{iotaLift}{\iota\!\uparrow\!(S, H)}$ Say we have finite groups $S\leq G$ and $H$ . If we have a homomorphism $\phi\colon S\to H$ , it does not always have to be the case that we find a homomorphism from $G\to H$ that agrees with $\phi$ on $S$ . For instance, the identity homomorphism $G \geq S\to S$ cannot be extended if (surjective) homomorphisms $G\to S$ don't even exist at all.  This happens for instance if there is no $N\lhd G$ such that $S \simeq G/N$ . Definition Let $S, G, H$ be finite groups, $\iota\colon S\to G$ a monomorphism (that is, an injective group homomorphism). Define $$
\iotaLift := \{\phi\colon S\to H \mid \exists \overline\phi\colon G\to H: \overline\phi\circ \iota = \phi\}
$$ to be the set of all such extendable homomorphisms. For which $H$ is $\iotaLift$ trivial (contains only the zero homomorphism)? For which $H$ is $\iotaLift = \operatorname{Hom}_{\underline{\operatorname{Grp}}}(S, H)$ ? Does this set have any obvious algebraic structure, e.g. a partial order, or an algebraic operation that constructs new extendable functions from old ones? Does the complement of this set? (I know that the last two points are rather open-ended, and hope this is still acceptable for M.SE.) Examples Assume the injection $\iota$ “splits”, i.e., admits an inverse $\sigma: \sigma\circ\iota = \operatorname{id}_S$ . Then every $\phi$ can be extended to $\phi\circ\sigma$ , which indeed satisfies $\phi\circ\sigma\circ\iota=\phi$ . So $\iotaLift = \operatorname{Hom}_{\underline{\operatorname{Grp}}}(S, H)$ . Similar to the case mentioned above, Let $G$ be simple, $S$ any subgroup, and $H$ a group such that $G$ does not embed into $H$ . Therefore, the only homomorphisms $G\to H$ must be trivial, and so is every restriction onto $S$ . Ergo, $\iotaLift=\{(s\mapsto 1)\}$ . Consider the (only nontrivial) embedding $C_2\to C_4$ with arbitrary $H$ .  Since morphisms $C_n\to H$ correspond with elements $h\in H$ of order dividing $n$ , extendable morphisms $C_2\to H$ correspond to elements who have a square root (including the identity). If we have an extendable function, we can compose it with any element of $\operatorname{Aut}(H)$ that is not trivial on its image to obtain a new function, whose extandability is easily checked.","['finite-groups', 'group-theory', 'definition', 'soft-question']"
3075069,"Prove $u(x,y,z)=f(t+r)/r+g(t-r)/r$ satisfies $u_{xx}+u_{yy}+u_{zz}=u_{tt}$.","I'm trying to prove that any function $u=u(x,y,z)$ of the form $$u(x,y,z)=\frac{f(t+r)}{r}+\frac{g(t-r)}{r},$$ with $r^2=x^2+y^2+z^2$ , satisfies the differential equation $ u_{xx}+u_{yy}+u_{zz}=u_{tt}, $ but I'm stuck when relating the derivatives. From what I get, $$u_{tt} = \dfrac{1}{r}(f''+g''),$$ as $r$ does not depend on $t$ . Furthermore, $$ u_x = \dfrac{r_x}{r^2}\left( r(f'-g')-(f+g) \right), $$ so, if I'm not mistaken, $$u_{xx} = \dfrac{x^2}{r^3} (f''+g'') + \dfrac{r^2-3x^2}{r^4}(f'-g') + \dfrac{x^2-r^2}{r^5}(f+g). $$ (By symmetry, $u_{yy}$ and $u_{zz}$ have the same form). But I don't know how to relate this expression to the other second derivatives, so I think I'm missing something... Any ideas are greatly appreciated.
Thanks in advance! EDIT: Corrected a $r^2$ term in the expression for $u_x$ . Also, thanks to @Klaramun's and @TedShifrin's suggestions, I managed to reduce the expression for $u_{xx}$ , noting that $f_x=f_y=f_z=f',\, g_x=g_y=g_z=g'$ , so I fixed that a couple lines up.","['multivariable-calculus', 'calculus', 'partial-differential-equations']"
3075074,Birthday Calendar Gaps,"I work at a company that posts a birthday calendar. I noticed that there was a string of four consecutive days with no birthdays. What is the probability of that happening? Problem Statement Given $n$ people, what is the probability of a observing a birthday calendar with no gaps of length $g$ or greater. In my case $n = 400$ and $g = 4$ . I'm mostly interested in an analytical solution. Partial Solution We will count the number of birthday assignments that have gaps less than $g$ . To do this, we will count assignments which have exactly $d$ distinct birthdays ( $d = 1, 2, 3, ..., 365$ ) and sum over $d$ . For a given $d$ , we will require a counting of two things: Number of ways to partition $n$ birthdays among $d$ days. Number of ways to select $d$ days from the year with no gaps of $g$ or greater. I found a solution to 1: $S(n,d) \times d!$ where $S(n,d)$ is a Stirling Number Of Second Kind. See solution here: Consecutive birthdays probability I need help on 2.","['combinatorics', 'probability']"
3075129,"Let $p,q$ be odd primes. Prove that a group of order $2 pq$ is solvable.","I got a problem as below. Let $p,q$ be odd primes.  Prove that a group of order $2 pq$ is solvable. ( $p$ and $q$ may or may not be distinct.) Honestly, I even don't know where to start. Thanks for any help in advance! Definition of Solvability(From dummit and Foote) A group $G$ is solvable if there is a chain of subgroups $$1=G_0\trianglelefteq G_1\trianglelefteq \cdots \trianglelefteq G_s=G$$ such that $G_{i+1}/G_i$ is abelian for $i=0,1,\dots, s-1$ .","['group-theory', 'abstract-algebra', 'finite-groups', 'prime-numbers']"
3075225,f irreducible polynomial with $p-2$ real roots $\Rightarrow$ $Gal(\mathbb{Q}_{f}/\mathbb{Q}) \cong S_{p}$,I have no idea what to do to show the following Let $p\ge 5$ be a prime number 1) Let $H\subset S_{p}$ be a subgroup of the symmetric group. Assume that $p$ divides the order of $H$ and that $H$ contains a transposition. Show that $H=S_{p}$ . 2) Let $f(X)\in \mathbb{Q}[X]$ be an irreducible polynomial of degree $p$ with exactly $p-2$ real roots and $\mathbb{Q}_{f}$ is the splitting field of $f$ in an algebraic closure $\overline{\mathbb{Q}}$ of $\mathbb{Q}$ . Show that $Gal(\mathbb{Q}_{f}/\mathbb{Q})$ is isomorphic to $S_{p}$ . Thanks in advance for any help.,"['galois-theory', 'symmetric-groups', 'abstract-algebra']"
3075263,How to show $\sqrt{\text{Tr}(A^2)} \leq \text{Tr}(A)$?,"Let $A$ be a positive semi-definite matrix. How to show that Frobenius norm is less than trace of the matrix? Formally, $$\sqrt{\text{Tr}(A^2)} \leq \text{Tr}(A)$$ Also, show when $A$ is an $n \times m$ the following is true $$\sqrt{\text{Tr}(A^TA)} \leq \|A\|_*$$ where $\|\cdot\|_*$ is nuclear norm which is the summation of the singular values.","['matrices', 'inequality', 'trace']"
3075275,"Precalc Trig Identity, verify: $1 + \cos(x) + \cos(2x) = \frac 12 + \frac{\sin(5x/2)}{2\sin(x/2)}$","Working with LHS: I've tried using the sum to product trig ID to get: $1 + 2\cos(3x/2)\cos(x/2)$ from here I've tried a couple of things, but can't seem to get closer. I've tried changing the $(3x/2)$ into $(5x/2 - x)$ and using sum identity, but this just makes things even messier. I also tried working the RHS. I'm only allowed to use the basic trig ID's: pythag, double and half angle, and sum to product and product to sum.",['trigonometry']
3075286,Necessity of the Hahn Banach Theorem for the Gateaux Mean Value Theorem,"The following theorem is in Drabek, Milota's Nonlinear Analysis. Like Drabek and Milota, I won't assume a priori Gateaux differentials are continuous nor linear. Theorem . Let $X,Y$ be normed spaces, and $f: X \rightarrow Y$ a map (perhaps not continuous). Fix $a,b \in X$ . Suppose that the Gateaux differential $df(a+t(b-a); b-a)$ exists for all $t \in [0,1]$ . Then, we have the estimate $$ ||f(b)-f(a)||_Y \leq \sup_{t \in [0,1]} ||df(a+t(b-a) ; b-a) ||_Y.$$ The proof uses the Hahn-Banach Theorem (or a corollary thereof) by taking a linear functional $\varphi \in X^*$ such that $||\varphi||_{X^*}=1$ and $\varphi(f(b)-f(a)) = ||f(b)-f(a)||$ . I would like to know if the use of the Hahn-Banach Theorem - or more generally, the Axiom of Choice - is needed to prove the theorem (that is, does there exist a proof that does not make use of choice principles)? I would also be interested in weaker choice principles, such as dependent or countable choice. I have also tried to modify the argument I saw in Cartan's Differential Calculus in the proof of the Mean Value Theorem for differentiable maps $[a,b] \rightarrow Y$ , $Y$ a normed space (the argument requires no choice principles); see Theorem 3.1.1, page 37-39 in Cartan. Somewhat in analogy to Cartan's argument, I have tried to define $$E= \{t \in [0,1] | \text{ for every neighbourhood } U \text{ of } 0, \text{ there is } p \in U \text{ such that } |p| ||f(b)-f(a)||_Y > ||f(a+t(b-a) + p(b-a)) - f(a+t(b-a)) ||_Y \}.$$ Then perhaps one could show $E$ is open in $\mathbb R$ and one notes that $\inf E \notin E$ . I am not sure exactly how to proceed to obtain a contradiction (as in Cartan's proof), however. My ideas for this attempt aren't well-formed, but I thought it would be useful to mention Cartan's proof. Perhaps this stackexchange question is also useful: Does one need the Hahn-Banach theorem to prove the mean value inequality for maps into a normed space? , though I'm interested in the version of the Mean Value theorem involving Gateaux derivatives as stated above. Thanks in advance. Edit: for reference, I'll include Cartan's Theorem here and a sketch of the proof. (The theorem is stated for Banach $Y$ , but completeness is in fact unnecessary). It is the proof of Theorem 3.1.1 I have tried to modify to my particular case, but it seems that I am unsure how to proceed. Theorem (Cartan, 3.1.1) . Let $Y$ be normed, let $f:[c,d] \rightarrow Y, g:[c,d] \rightarrow \mathbb R$ be maps. Suppose that the right derivatives $f'_{+}, g'_{+}$ exists at all points in $(c,d)$ , and assume that $||f'_{+}(x)|| \leq g'_{+}(x)$ for all $x \in (c,d)$ . Then, $$||f(d)-f(c)|| \leq g(d)-g(c).$$ Sketch : Following Cartan, one fixes $\varepsilon>0$ and puts $$U = \{x \in [c,d] | ||f(x)-f(c)|| > g(x)-g(c)+ \varepsilon(x-c) \}.$$ Aiming for a contradiction, suppose $U$ is not empty. Then, $U$ is open and let us define $\alpha= \inf U$ ; then, $\alpha \notin U$ , and in fact, $\alpha>c$ . By the existence of the right derivatives, there is a $\delta>0$ such that for any $\alpha<t<\alpha+\delta$ , one has $$ - \frac{\varepsilon}{2} + \left | \left | \frac{f(t)-f(\alpha)}{t-\alpha} \right | \right | \leq || f'_{+}(\alpha) || \leq g'_{+}(\alpha) < \frac{g(t)-g(\alpha)}{t-\alpha} + \frac{\varepsilon}{2}.$$ It follows that $||f(t)-f(\alpha)|| < g(t)-g(\alpha) + \varepsilon(t-\alpha)$ for every $\alpha<t<\alpha+\delta$ . Since $\alpha \notin U$ , we also have $||f(\alpha)-f(c)|| \leq g(\alpha)-g(c)-\varepsilon(\alpha-c)$ . If $t \in (\alpha, \alpha+\delta)$ , then \begin{align*} ||f(t)-f(c)|| &\leq ||f(t) - f(\alpha)|| + ||f(\alpha)-f(c) || \\
& \leq (g(t)-g(\alpha) + \varepsilon(t-\alpha) ) + (g(\alpha)-g(c)+ \varepsilon(\alpha-c) \\
&= g(t)-g(c)+\varepsilon(t-c). 
\end{align*} So, $(\alpha, \alpha+\delta) \cap U = \emptyset$ and supposedly $\alpha = \inf U$ , which is impossible. So in fact $U=\emptyset$ , and thus $b \in U^c$ , from which it follows $||f(b)-f(a)|| \leq g(b)-g(a)+\varepsilon(b-a)$ and $\varepsilon$ was arbitrary. $\blacksquare$ Remark : the Theorem remains true if right differentiability is assumed for all but countably many points in $(c,d)$ . Corollary (Cartan, 3.3.1) . Let $X,Y$ be normed, let $f:U \rightarrow Y $ be a map (where $U \subseteq X$ is open and not empty) and fix $x,y \in U$ . Suppose the line segment between $x$ and $y$ is contained in $U$ , and suppose that $f$ is Frechet differentiable on $U$ . Then, $$||f(x)-f(y)||_Y \leq \sup ||f'(\zeta)||_Y ||x-y||_X,$$ where the sup is taken over the line segment between $x$ and $y$ . (The corollary follows from applying Theorem 3.1.1 to $g:= f \circ \psi$ , where $\psi:[0,1] \rightarrow X, t \mapsto tx+(1-t)y$ ).","['gateaux-derivative', 'functional-analysis']"
3075288,How to show the von Neumann trace inequality?,"Let $A,B$ have the appropriate size. How can we show the von Neumann trace inequality? $$ \mbox{Tr}(AB) \leq \sum_{i=1}^n \sigma_{A,i}\sigma_{B,i} $$ Also, what is the intuition behind this inequality?","['matrices', 'inequality', 'trace', 'singular-values']"
3075324,Improper integral $ \int\limits_0^{\infty} \frac{ x^2 \arctan x }{x^4 + x^2 + 1 } dx $,"Im trying to find $$ \int\limits_0^{\infty} \frac{ x^2 \arctan x }{x^4 + x^2 + 1 } dx $$ Thoughts: My first thought was to write the denominator as $(x^2+1)^2 -x^2 $ and then by difference of squares we have $(x^2+1-x)(x^2+1+x)$ . Then write the numerator as $x^2+x+1-x-1 = (x^2+x+1) - (x+1) $ and so our integral reduces to $$ I = \int\limits_0^{\infty} \frac{ \arctan x }{x^2-x+1} +\int\limits_0^{\infty} \frac{ (-x-1) \arctan x}{x^4+x^2+1}$$ Also, write $-x-1= -x-1 +x^2 +1 - 1 - x^2 = (x^2-x+1) - (x^2+2)$ to reduce $$ \int\limits_0^{\infty} \frac{ (-x-1) \arctan x}{x^4+x^2+1} =  \int\limits_0^{\infty} \frac{ \arctan x }{x^2+x+1} - \int\limits_0^{\infty} \frac{ (x^2+2) \arctan x }{x^4+x^2+1} $$ Therefore, so far we got $$ 2I = \int\limits_0^{\infty} \frac{ \arctan x }{x^2-x+1}  + \int\limits_0^{\infty} \frac{ \arctan x }{x^2+x+1} - \int\limits_0^{\infty} \frac{ 2 \arctan x }{x^4+x^2+1}$$ But, here I get stuck again. Perhaps my approach is bad? I dont see a way out from there, I suck at integration :x. Any ideas?",['calculus']
3075327,Every finite measure on a metric space is regular,"let $(X,d)$ be a metric space with the Borel $\sigma$ -algebra. Let $\mu$ be a finite measure on $(X,\Sigma)$ . Show that $\mu$ is regular in the following sense: for every $A\in \Sigma$ and for every $\epsilon>0$ there exist a closed set $C$ and an open set $U$ such that $C\subset E \subset U$ and $\mu(U-C)<\epsilon$ . Hint: show that this is true for every closed set $E\in \Sigma$ and then show that the collection of measurable sets for which this assertion holds is a $\sigma$ -algebra. I'm stuck on the first step.
What I believe is the answer is to take $C=E$ and $U=\cup_{x\in E} B(x,\epsilon)$ . Now I ""feel"" like $\mu(U-C)<\epsilon$ but I fail to see how to connect the idea of distance $\epsilon$ in a metric space to the idea of a measure. Any help would be appreciated.",['measure-theory']
3075357,"Homology group of $X=\operatorname{SL}(2,\mathbb{R})/\operatorname{SL}(2,\mathbb{Z})$","My friend asks me how to compute the homology group of $X=\operatorname{SL}(2,\mathbb{R})/\operatorname{SL}(2,\mathbb{Z})$ . It is not hard to see that $H_0(X)=\mathbb{Z}$ , and for $q\ge 4$ we have $H_q(X)=0$ . But I don't know how to compute $H_q(X)$ for $q=1,2,3$ , since the action of $\operatorname{SL}(2,\mathbb{Z})$ seems 'strange' to me, and I can't make $X$ into a CW complex. Can anyone help me?","['abstract-algebra', 'manifolds', 'group-theory', 'homology-cohomology', 'algebraic-topology']"
3075388,Express Negation in Simple English: There is a student in this class who has chatted with exactly one other student,"Am I correct in the following: If the domain is all students, and C(x,y) is the predicate of x having chatted with y. Then the sentence There is a student in this class who has chatted with exactly one other student Can be represented as $$\exists x\exists y(y\ne x\land \forall z(z\ne x\to(z=y\leftrightarrow C(x,z))))$$ Which is logically equivalent to: $$\exists x \exists y[(x\neq y) \land\forall z ([z=x] \lor[(z\neq y) \lor C(x,y)] \land [\lnot C(x,y) \lor (z = y)])]$$ The negation of which would be: $$\forall x \forall y [(x=y) \lor \exists z([z\neq x] \land [(z =y) \land \lnot C(x,y)] \lor[C(x,y) \land(z \neq y)])]$$ That is also logically equivalent to: $$\forall x \forall y [(x = y) \lor \exists z([z \neq x] \land [C(x,y) \leftrightarrow (z \neq y)])]$$ Which can be translated to: All students have spoken with at least one other student or themselves?","['predicate-logic', 'first-order-logic', 'logic', 'discrete-mathematics', 'logic-translation']"
3075426,Statistics Olympiad Problem,"Given that the mean, median, range and the only mode of 200 integers are also 200. If $A$ is the largest integer among those 200 integers, find the maximum value of $A$ . I have asked some of my friends and colleagues to solve this problem, but no one give me a light. Attempt: Assuming first that all the numbers are $200$ . 
To maximize $A$ , but satisfies all the criterion given, we need to make $A$ ascending while descending the value of other numbers. 
Logically, $100, 200, 200, \cdots, 300$ still satisfies.
Maybe we have $A_{\text{max}} = 300$ ? 
I don't know how to approach it clearly.",['statistics']
3075429,Does Young's inequality hold only for conjugate exponents?,"Suppose that $ab \leq \frac{1}{p}a^p+\frac{1}{q}b^q$ holds for every real numbers $a,b\ge 0$ . (where $p,q>0$ are some fixed numbers). Is it true that $ \frac{1}{p}+\frac{1}{q}=1$ ? I guess so, and I would like to find an easy proof of that fact. Plugging in $a=b=1$ , we get $ \frac{1}{p}+\frac{1}{q}\ge1$ . Is there an easy way to see that the converse inequality must hold? To be clear, I am not looking for proofs of Young's inequality; only for a way to see why the relation between the conjugate exponents is the only possible option. Edit: Here is a comment to help future readers (including future me) to see how can one come with Nicolás's nice idea to apply the inequality for $a=\lambda^{\frac{1}{p}}, b=\lambda^{\frac{1}{q}}$ . The idea is that it is inconvenient to compare a sum with another number; By using the specific choice of $a,b$ above, the sum is simplified, since the scales of the auxiliary parameter $\lambda$ in both summands are now identical. Comment: I know that the relation $ \frac{1}{p}+\frac{1}{q}=1$ is necessary for Holder's inequality in general; this can be seen by scaling the measure. However, I don't think this approach is applicable here.","['inequality', 'symmetry', 'young-inequality', 'real-analysis']"
3075449,Is a simply connected subset of $\mathbb{R}^n$ necessarily measurable?,"Let $S\subset\mathbb{R}^n$ be a subset that is simply connected as a topological space. Is $S$ necessarily Lebesgue measurable? Is it necessarily Borel measurable? What's the proof? (Intuitively I think the answer should be ""yes"" to both, but I would have no idea how to prove. I mean, $S$ could be pretty wild.)","['general-topology', 'lebesgue-measure', 'measure-theory']"
3075464,How to easily see the time integral of a Brownian motion is normally distributed?,"It's well known that $X_t:=\int_0^tB_\tau d\tau$ where $\{B_\tau\}$ is a 1D standard Brownian motion is distributed as $N(0, t^3/3)$ . Is there any ""immediate"" way to see this fact? The easiest one I can get: discretise $X_t$ into Riemannian sum, and break each $B_{\tau_i}$ into independent increments over tiny intervals, then we see the sum is just a linear sum of independent normal distributions, then take the limit and use convergence in distribution to conclude. I wouldn't say this is hard, but this is in no way trivial or immediate either. Can we somehow see this fact without any effort or whatsoever? Thanks.","['stochastic-processes', 'brownian-motion', 'probability-theory', 'normal-distribution']"
3075475,How would you calculate this limit? $\lim\limits_{n \rightarrow\infty}\frac{\pi}{2n}\sum\limits_{k=1}^{n}\cos\left(\frac{\pi}{2n}k\right)$,"I decided to calculate $\int_{0}^{\pi/2}cos(x)dx$ using the sum definition of the integral. Obviously the answer is $1$ . I managed to calculate the resulting limit using the geometric series, taking the real part of the complex exponential function and several iterations of l'hopital's rule. Are you able to simplify this absolute mess, i.e. find a better way of arriving at the desired answer? $$\lim\limits_{n \rightarrow\infty}\frac{\pi}{2n}\sum\limits_{k=1}^{n}\cos\left(\frac{\pi}{2n}k\right)$$ Every answer is highly appreciated =) PS: If you want to see my solution, feel free to tell me! =)","['limits', 'definite-integrals', 'real-analysis']"
3075526,Is it correct to say the field of complex numbers is contained in the field of quaternions?,"I believe it is correct to refer to the complex numbers and their 'native algebra' as a field.  See for example Linear Algebra and Matrix Theory , by Evar Nering.  I assume the same may be said for the set of quaternions.  Please correct me if that is wrong. Based on that assumption, I ask: is the field of complex numbers a subset (sub-field?) of the quaternions in the same sense that the real numbers are 'contained' in the complex numbers ? Is there a term for such a subordination of number fields? I admit that I am reaching well beyond my realm of familiarity, and that my question may be nonsensical to those who are more knowledgeable in these matters.","['field-theory', 'definition', 'abstract-algebra', 'complex-numbers', 'quaternions']"
3075559,Probability for a boolean matrix from a certain class to have full rank,"While considering a certain type of computational problems, I have encountered the following probabilistic problem over the two element field $GF_{2}$ . For $c\in \mathbb{Q}_{>0}$ , let $p_{c}(n)$ be the probability for a
matrix over $GF_{2}$ with $n$ columns and $c\cdot n$ rows, such that
each row contains precisely $3$ non-zero entries, to have a full rank.
Is there a $c\geq 1$ with $\lim_{n\rightarrow \infty} p_{c}(n)>0 $ ? Im only interested in the case $c>1$ ; there are results of Calkin from 1997 that solve the case $c\leq 1$ , see Dependent Sets of Constant Weight Binary Vectors . Calkin proved that there exists a sharp treshold $0<\beta<1$ with $\lim_{n\rightarrow \infty} p_{c}(n)=1$ for $c\in (0,\beta)$ and $\lim_{n\rightarrow \infty} p_{c}(n)=0$ for $c\in (\beta,1]$ . Now if I am not mistaken Calkin's results do not have any implications for the case $c>1$ . I would be very happy to see $\lim_{n\rightarrow \infty} p_{c}(n)>0 $ for some $c>1$ and thought that some of you guys might know these kind of problems or simply see an obvious answer. I have been googling for a while without any success. Ps.: There is a positive answer already for $c=1$ if one considers arbitrary $(c\cdot n) \times n$ matrices over $GF_{2}$ . A simple counting exercise shows $p_{1}(n)=(1-1/2)\cdot ... \cdot (1-1/2^{n})$ whose limit lies somewhere in $(0,1)$ (my source is https://arxiv.org/pdf/math/0102059.pdf , p. 38). However, these behave very differently compared to the $3$ -nonzero entries case.","['matrix-rank', 'finite-fields', 'matrices', 'combinatorics', 'probability']"
3075574,Constructing sigma algebras in countably many steps,"I'm learning about $\sigma$ -algebras and was interested when my textbook briefly mentioned the impossibility of constructing the Borel $\sigma$ -algebra of $\mathbb{R}$ , $\mathcal{B}(\mathbb{R})$ , from the open intervals in countably many steps. More precisely, let $\mathcal{L}_0$ be the collection of all open intervals $(a,b)\subseteq\mathbb{R}$ . Given $\mathcal{L}_i$ , we define $$\mathcal{L}_{i+1}=\bigg\{\bigcup_{k\in\mathbb{N}}A_k, \Big(\bigcup_{k\in\mathbb{N}}A_k\Big)^{c}\ :\ A_k\in \mathcal{L}_{i} \bigg\}\ \ \ \text{ and } \ \ \ \hat{\mathcal{L}}=\bigcup_{i\in\mathbb{N}}\mathcal{L}_i$$ Then my textbook says that $\hat{\mathcal{L}}\subsetneqq\mathcal{B}(\mathbb{R})$ . My question is this: can one (easily) exhibit a Borel set not in $\hat{\mathcal{L}}$ ? Is it necessary to use heavy machinery like AC or CH in order to construct such a set? I'm quite stuck. Many thanks!","['borel-sets', 'measure-theory']"
3075636,Maximum value of function $f(x)=\frac{x^4-x^2}{x^6+2x^3-1}$ when $x >1$,What is the maximum value of the $$f(x)=\frac{x^4-x^2}{x^6+2x^3-1}$$ where $x > 1$ . My try Unable to solve further.,"['a.m.-g.m.-inequality', 'real-analysis', 'maxima-minima', 'functions', 'optimization']"
3075646,Numerator layout for derivatives and the chain rule,"We have three matrices $\mathbf{W_2}$ , $\mathbf{W_1}$ and $\mathbf{h}$ (technically a column vector): $$
\mathbf{W_1} =
\begin{bmatrix}
    a & b \\
    c & d \\
\end{bmatrix}
\;\;\;\;\;\;\;\;\;
\mathbf{W_2} =
\begin{bmatrix}
    e & f \\
\end{bmatrix} 
\;\;\;\;\;\;\;\;\;
\mathbf{h} =
\begin{bmatrix}
    h_1 \\
    h_2 \\
\end{bmatrix} 
$$ And a scalar $y$ , where: $$
y = \mathbf{W_2} \mathbf{W_1} \mathbf{h}
$$ I'd like to compute the derivative of $y$ with respect to $\mathbf{W_1}$ , assuming numerator layout . Using the chain rule: $$
y = \mathbf{W_2} \mathbf{u}
\;\;\;\;\;\;\;\;\;
\mathbf{u} = \mathbf{W_1} \mathbf{h} \\
$$ $$
\begin{align}
\frac{\partial y}{\partial \mathbf{W_1}} &=
\frac{\partial y}{\partial \mathbf{u}} \frac{\partial \mathbf{u}}{\partial \mathbf{W_1}} \\
&= \mathbf{W_2} \frac{\partial \mathbf{u}}{\partial \mathbf{W_1}} \\
&= \mathbf{W_2} \mathbf{h}^{\top} \\
\end{align}
$$ All well and good. Except - this isn't a $2x2$ matrix!! In fact, the dimensions don't match up for matrix multiplication, so something must be incorrect. If we take the Wikipedia definition of the derivative of a scalar by a matrix, using numerator layout, we know that actually: $$
\frac{\partial y}{\partial \mathbf{W_1}} =
\begin{bmatrix}
    \frac{\partial y}{\partial a} & \frac{\partial y}{\partial c} \\
    \frac{\partial y}{\partial b} & \frac{\partial y}{\partial d} \\
\end{bmatrix}
$$ Each element is just a scalar derivative, which we can calculate without any matric calculus. If we do that by hand and then factorise, we end up with: $$
\frac{\partial y}{\partial \mathbf{W_1}} = \mathbf{h} \mathbf{W_2}
$$ Clearly, $\mathbf{h} \mathbf{W_2} \neq \mathbf{W_2} \mathbf{h}^\top $ . Can anybody suggest where I went wrong?","['matrices', 'matrix-calculus']"
3075656,$\sum_{n=1}^\infty \frac{n!e^n}{n^{n+ \frac{3}{2}}}$ - any ideas for a simple proof of divergence?,"I am looking for a simple proof of divergence for the series: $\sum_{n=1}^\infty \frac{n!e^n}{n^{n+\frac{3}{2}}}$ That's a part of the more general problem: For what values of X is the series $\sum_{n=1}^\infty \frac{n!e^n}{n^{n+X}}$ convergent and for what values is it divergent? I am not allowed to use Stirling's approximation in the proof. I've already managed to prove convergence for $X>\frac{3}{2}$ and divergence for $X<\frac{3}{2}$ .
And now I am stuck with $X=\frac{3}{2}$ - I know the series is divergent (from Stirling approximation and WolframAlpha) but I have no idea for an elementary proof. This question is related to my previous one about the elementary proof for the simpler case i.e.: $\sum_{n=1}^\infty \frac{n!e^n}{n^n}$ so you might be interested in checking it out: Divergent infinite series $n!e^n/n^n$ - simpler proof of divergence?","['divergent-series', 'analysis', 'real-analysis', 'calculus', 'convergence-divergence']"
3075677,differential forms- $\omega $ closed but not exact,"let be $$ \omega= |x|^{-3} \left(x_1 dx_2 \wedge dx_3+x_2dx_3 \wedge dx_1 + x_3dx_1 \wedge dx_2\right) $$ and $G:= \mathbb{R}^3 \backslash \{ 0 \} $ I want to prove, that $ \omega$ is closed, but not exact That $ \omega $ is closed, I can prove it by looking if $ d\omega =0 $ But how can I prove it's not exact? I know that a continous 2-form is exact in $G$ if there exists a 1-Form $y$ so, that $\omega = dy $ how can I show there doesn't exist such $y$ ? Edit:
Showing $\int_S \omega \neq 0 $ Where $S$ is the unitsphere
Set $r=1$ and set $$x_1= \sin \phi \cos \theta $$ $$x_2= \sin \phi \sin \theta$$ $$x_3= \cos \phi $$ $ \theta=[0, 2\pi], \phi=[0, \pi]$ then $ dx_1 \wedge dx_2 = -\sin \phi \cos \phi d\theta \wedge d\phi $ $ dx_2 \wedge dx_3 = -\sin^2 \phi \cos \theta d\theta \wedge d\phi $ $ dx_3 \wedge dx_1 = -\sin^2 \phi \sin \theta d \theta \wedge d\phi $ Putting in the equation: $$ \int_0^{2 \pi} \int_0^{ \pi} |x| ( \sin \phi \cos \theta - \sin^2 \phi \cos \theta ~d \theta \wedge d\ \phi \\+ \sin \phi \sin \theta -\sin^2 \phi \sin \theta ~d\theta \wedge d\phi + \cos \phi -\sin \phi \cos \phi~ d \theta \wedge d\phi $$ what do I put for $x$ ?
I don't know how to solve the integral
thank you for any help!","['multivariable-calculus', 'differential-forms', 'real-analysis']"
3075736,Why Dirichlet form are interesting?,"I'm currentely studing the Dirichlet form and to be honest, I really don't see in what they are useful. I don't really get the point with them. I recall the definition : Definition Let $(H,\left<\cdot ,\cdot \right>)$ a Hilbert space. Set $E=E^s+E^a$ a bilinear form defined on a dense subset $D$ of $B$ where $E^s$ is symmetric and $E^a$ antisymmetric. We Then $E$ is a Dirichlet form if $E^s$ is positive definite on $D$ $(E^s+\left<\cdot ,\cdot \right>,D)$ is a Hilbert space, $(E,D)$ is coercive, i.e. there is $K>0$ s.t. $$|E(x,y)+\left<x,y\right>|^2\leq K |E^s(x,x)+\left<x,x\right>||E^s(y,y)+\left<y,y\right>|$$ for all $x\in D$ , we have $x^*=\min(x^+,1)\in D$ where $x^+=\max\{x,0\}$ and $$E(x+x^*,x-x^*)\geq 0\quad \text{and}\quad E(x-x^*,x+x^*)\geq 0.$$ Seeing this definition, what is the motivation behind ? Because as written, it looks a bit barbarous for me. I can accept the first point of the definition, but the 3 other assumption looks to arise from nowhere. Maybe someone knows a very good small introduction to get the point with these Dirichlet form ?","['operator-theory', 'functional-analysis']"
3075741,Young's convolution inequality: Equivalent representations,"According to Wikipedia Young's inequality for convolutions states that For functions $f \in L^p$ and $g \in L^q$ one has $|| f*g ||_r \leq ||f||_p ||g||_q$ $\hspace{6.75cm}$ (Eq. 1) with $1/p + 1/q = 1 + 1/r$ and $1 \leq p,q,r$ . Here $*$ represents a Fourier convolution and $||\cdot||_p$ stands for the usual $L^p$ -Norm. Equivalently, if $1/p + 1/q + 1/r = 2$ and $1 \leq p,q,r$ then $\int \int f(x) g(x-y) h(y) \mathrm d x \mathrm d y \leq ||f||_p ||g||_q ||h||_r$ $\hspace{2.5cm}$ (Eq. 2) holds true. My question: I am wondering what the connection between (Eq. 1) and (Eq. 2) actually is. Are they truly identical? Is it possible to derive (Eq. 2) from (Eq. 1) without too much effort? $^*$ What properties does $h$ have to fulfill? Can it be any suitably integrable function? $^*$ I have already tried to read the original Papers of Young and Brascamp & Lieb but I was not able to fully understand the derivation.","['measure-theory', 'convolution', 'young-inequality', 'inequality']"
3075763,Stolz-Cesàro $0/0$ case: is $\limsup \frac{a_n}{b_n}\le \limsup\frac{a_{n+1}-a_n}{b_{n+1}-b_n}$?,"The general form of Stolz-Cesaro $\infty/\infty$ case states that any two real two sequences $a_n$ and $b_n$ , with the latter being monotone and unbounded, satisfy $$\liminf\frac{a_{n+1}-a_n}{b_{n+1}-b_n}\le\liminf\frac{a_n}{b_n}\le\limsup \frac{a_n}{b_n}\le \limsup\frac{a_{n+1}-a_n}{b_{n+1}-b_n}.$$ Does the same hold for the $0/0$ case? That is, is it true that if $\lim a_n=\lim b_n=0$ and $b_n$ is strictly monotone, then $$\liminf\frac{a_{n+1}-a_n}{b_{n+1}-b_n}\le\liminf\frac{a_n}{b_n}\le\limsup \frac{a_n}{b_n}\le \limsup\frac{a_{n+1}-a_n}{b_{n+1}-b_n}$$ ? EDIT : Here's my attempt, please any feedback is appreciated. I tried with the $\limsup$ , assuming $0<b_{n+1}<b_n$ for all $n$ . Suppose $\alpha>\limsup_{n\to\infty}\frac{a_{n+1}-a_n}{b_{n+1}-b_n}$ . Then there exist infinitely many $N$ such that for all $k\ge0$ , $$\alpha>\frac{a_{N+k}-a_{N+k-1}}{b_{N+k}-b_{N+k-1}}.$$ Since $b_{n+1}<b_n$ , we have for $k\ge0$ that $\alpha(b_{N+k}-b_{n+K-1})<a_{N+k}-a_{N+k-1}$ .
Thus for any $m\ge0$ , \begin{align} \alpha\sum_{k=0}^m(b_{N+k}-b_{N+k-1}) &< \sum_{k=0}^m(a_{N+k}-a_{N+k-1}) \\ \alpha(b_{N+m}-b_{N-1})&<a_{N+m}-a_{n-1}\end{align} and taking $m\to\infty$ , \begin{align} -\alpha b_{N-1}&<-a_{N-1}  \\ \alpha&>\frac{a_{N-1}}{b_{N-1}}.\end{align} Taking finally $N\to\infty$ , we must have $\alpha\ge\limsup_{n\to\infty}\frac{a_n}{b_n}$ . Thus we can conclude $$\limsup_{n\to\infty}\frac{a_{n+1}-a_n}{b_{n+1}-b_n}\ge\limsup_{n\to\infty}\frac{a_n}{b_n}.$$","['limsup-and-liminf', 'proof-verification', 'real-analysis', 'calculus', 'sequences-and-series']"
3075790,Solve the differential equation $t^2y''+3ty'+y=\frac{1}{t}$,Solve the equation $$t^2y''+3ty'+y=\frac{1}{t}$$ with $t \gt 0$ My try: The given differential equation is actually of second order: Let us use the substitution: $ty=p$ $$ty'+y=\frac{dp}{dt}-(1)$$ $$ty''+2y'=\frac{d^2p}{dt^2}$$ $$t^2y''+2ty'=t\frac{d^2p}{dt^2}-(2)$$ Adding (1) and (2) we get: $$t^2y''+3ty'+y=t\frac{d^2p}{dt^2}+\frac{dp}{dt}$$ Hence the equation is now: $$t\frac{d^2p}{dt^2}+\frac{dp}{dt}=\frac{1}{t}$$ Let us use another substitution: $\frac{dp}{dt}=q$ Then the equation is: $$t\frac{dq}{dt}+q=\frac{1}{t}$$ $$\frac{dq}{dt}+\frac{q}{t}=\frac{1}{t^2}$$ Which is a Linear first order differential equation with integrating factor given by: $$I(t)=e^{\int \frac{dt}{t}}=e^{\ln|t|}=|t|=t$$ The solution is: $$qt=\int \frac{dt}{t}+C$$ $$qt=\ln t+C$$ $$q=\frac{\ln t+C}{t}$$ Now we get: $$\frac{dp}{dt}=\frac{\ln t+C}{t}$$ Integrating we get: $$p=\int \frac{ln t}{t}+\int \frac{C}{t}+D$$ $$p=\frac{1}{2}\left(\ln t\right)^2+C\ln(t)+D$$ Hence the final solution is: $$ty=\frac{1}{2}\left(\ln t\right)^2+C\ln(t)+D$$ $$y=\frac{\frac{1}{2}\left(\ln t\right)^2+C\ln(t)+D}{t}$$ Where $C$ and $D$ are constants: Is there any different approach?,"['integration', 'algebra-precalculus', 'derivatives', 'ordinary-differential-equations']"
3075829,Does there always exist a continuous map saturating a given open set?,"Let $X$ and $Y$ be two general topological spaces. Is the following statement true? For any open $U\subset X$ , there exists an open $V\subset Y$ and a continuous map $f:X\rightarrow Y$ , such that $f^{-1}V=U$ .","['continuity', 'general-topology']"
3075869,Prove that quotient maps $q$ are characterized by $f:Y\to Z$ being continuous iff $f\circ q$ is,"The following is quoted from https://en.wikipedia.org/wiki/Quotient_space_(topology) Quotient maps q : X → Y are characterized among surjective maps by the following property: if Z is any topological space and f : Y → Z is any function, then f is continuous if and only if f ∘ q is continuous. Assuming that $q$ is a quotient map, I can prove the characterizing property using the definition of a quotient map, namely, $q^{-1}U$ is open if and only if $U$ is open. However, I could not see how to prove the converse: how does the property imply that $q$ is quotient?","['general-topology', 'quotient-spaces']"
3075915,Fair Sharing of a Pizza When Opinions About the Edge Differ,"Two friends wants to share a pizza. One of them loves the edge of the pizza and the other one hates it. Both consider the pizza to get tastier the closer to the center you get. What is the fairest way to cut the pizza if you are only allowed four straight cuts, such that the two sets of slices sum up to the same area and one set contains all edges? I have attached an intuitive sketch, which seems somewhat fair, but I don't know how to approach a problem like this one.","['fair-division', 'optimization', 'geometry']"
3075950,"Why is sinh called ""sinus hyperbolicus"" despite being just a regular e function?",What does the sinus hyperbolicus have to do with the sinus? Their graphs do not look alike at all. The only similarity I can find is that their exponential representation looks similar. $sin(x) = \frac{1}{2i}(e^{ix}-e^{-ix})$ $sinh(x) = \frac{1}{2}(e^{x}-e^{-x})$,"['trigonometry', 'complex-numbers', 'hyperbolic-functions']"
3075961,Why are polynomials tangential to the $x$ axis at real double roots?,"If $(x-a)^2$ is a root of a polynomial, then the graph will be tangent to the $x$ axis at $x=a$ but why? I know this is always the case for real double roots however I do not know the explanation for this behavior. Does this behavior apply to all real polynomial roots with even index multiplicities?","['calculus', 'roots', 'polynomials', 'real-analysis']"
3075979,Prove that $\frac{k^7}{7}+\frac{k^5}{5}+\frac{2k^3}{3}-\frac{k}{105}$ is an integer. [duplicate],This question already has answers here : Prove $\frac{k^7}7+\frac{k^5}5+\frac{2k^3}3-\frac k{105}$ is a integer by mathematical induction [duplicate] (2 answers) Closed 5 years ago . Prove that $$\frac{k^7}{7}+\frac{k^5}{5}+\frac{2k^3}{3}-\frac{k}{105}$$ is an integer using mathematical induction. I tried using mathematical induction but using binomial formula also it becomes little bit complicated. Please show me your proof. Sorry if this question was already asked. Actually i did not found it. In that case only sharing the link will be enough.,"['algebra-precalculus', 'proof-writing', 'induction']"
3075982,Compact spaces in which any closed set can be partitioned into finitely many closed sets whose clopen subsets extend to the whole space,"Let $X $ be a compact topological space (not necessarilly Hausdorff). I am looking for a charactrization for the following property: Property: If $C $ is a closed subset of $X $ , then there are pairwise disjoint closed subsets $C_1$ ,..., $C_n $ of $X $ such that $C=C_1\cup\dots\cup C_n $ , and each $C_i $ has the property that if $A $ is a clopen subest of $C_i $ , then there exists a clopen subset $B $ of $X $ with $A=C_i\cap B$ ? Any comment is very welcome.","['connectedness', 'general-topology', 'compactness']"
3076002,Does there exist a real number a given distance from each rational number?,"Let $r_n$ be an enumeration of the rational numbers and let $a_n$ be a sequence of positive real numbers that converges to zero. Does there exist $x\in \mathbb{R}$ such that $|x-r_n|>a_n$ for all $n$ ? This problem was inspired by an easier version of the problem where we assume the stronger condition that $\displaystyle\sum_{n=1}^\infty a_n$ converges. I have a simple solution in this particular case but I will spoiler it in case anyone would like to try this too. Let $\Omega$ denote the set of $x\in \mathbb{R}$ that do not satisfy the   given property; we claim that $\Omega \neq \mathbb{R}$ and so an $x\in \mathbb{R}$ with given property exists. Indeed, $\Omega=\{x\in\mathbb{R} \ | \ \exists \ n\in \mathbb{N} \ \mathrm{such \ that} \ |x-r_n| \leq a_n\}=\displaystyle\bigcup_{n=1}^\infty \ [r_n-a_n,r_n+a_n]$ whose Lebesgue measure $\lambda(\Omega)\leq \displaystyle\sum_{n=1}^\infty \lambda([r_n-a_n,r_n+a_n])=\displaystyle\sum_{n=1}^\infty 2a_n < \infty$ , so $\Omega \neq \mathbb{R}$ . Unfortunately it is very specific to this particular case so I doubt it helps with the general case, which I have no idea how to solve. I assume that, unless I'm missing something obvious, it uses some deeper theory (irrationality measure?) that I have not learned. Ideas for the general case or alternative (more elementary) solutions to the easier case would be appreciated.","['alternative-proof', 'sequences-and-series', 'real-analysis']"
3076005,How to integrate $\int_{0}^{2\pi}\frac{\mathrm dx}{(1-a\cos x)^2}$,"I'm having a hard time trying to resolve this integral : $$\int_{0}^{2\pi}\frac{\mathrm dx}{(1-a\cos x)^2}$$ where $a$ is a positive real constant. I tried using substitution, but I'm stuck by the fact that the integral must be computed between $0$ and $2\pi$ , which leads to integration between $X$ and $X$ (where $X$ can be $0$ or $1$ anything following the substitution in the boundaries).
I'm not looking for the full result if the computation is complicated, just some lead to start off... Thanks UPDATE : seeing the answers proposed, I checked that indeed $|a|<1$ .","['integration', 'calculus', 'analysis', 'trigonometric-integrals']"
3076041,"Using cylindrical coordinates, find the volume of the region $D =\{y^2+z^2\le5+x^2,4x^2+y^2+z^2\le25\}$","I want to calculate this volume region, using cylindrical coordinates: $$D=\{y^2+z^2\le5+x^2,4x^2+y^2+z^2\le25\}$$ So, I have a hyperboloid and an ellipsoid. Is it correct to calculate the volume like this: $$2\int_{0}^{2\pi}\int_{0}^{3}\int_{2}^{\frac12\sqrt{25-r^2}}rdxdrd\theta  + 2\int_{0}^{2\pi}\int_{0}^{2}\int_{0}^{\sqrt{5+x^2}}rdrdxd\theta$$ Is there a more efficient method ?","['integration', 'multivariable-calculus', 'calculus', 'definite-integrals']"
3076042,Is there any way to find out total number of simple graphs of given sequence?,"This problem came randomly to my mind while studying graph theory.Suppose 3,3,3,3,3,3 is a given sequence of degree of vertices of a graph.We know one of its graph is a hexagon with opposite diagonals attached.But suppose any arbitrary sequence is given and suppose it is guaranteed that it's graph exists,then how to find all such graphs(I mean is there some algorithm or we have to find those graphs randomly).","['graph-theory', 'discrete-mathematics']"
3076048,A bag contains $6$ white balls and $8$ blue balls.,"A bag contains $6$ white balls and $8$ blue balls. Two balls are drawn from the bag at random one after another without replacement. Find the probability that: a) the first is white and the second is blue, b) both are white c) One is white and the other is blue. I tried as: $6$ white balls + $8$ blue balls = $14$ balls. So, exhaustive cases $=^{14}C_{2}=48$ a). Favourable cases $=^{6}C_{1}.^{8}C_{1}=48$ Then, Probability $=\dfrac {48}{91}$ . b). Favourable cases $=^{6}C_{2}=15$ Then, Probability $=\dfrac {15}{91}$ The answer for part (a) doesn't match with the answer key. However answer to (b) is correct as per the answer key. Why is it so? I am not able to solve the third part of the question.","['probability-theory', 'probability']"
3076072,"Find distance to the origin of the tangent plane of $x^2-y^2+2z^2=5$ in the point $(2,-1,1)$","I'm asked to find the distance to the origin of the tangent plane of the surface $x^2-y^2+2z^2=5$ in the point $(2,-1,1)$ . This seems to be an optimization problem with constraint, which I think can be solved with Lagrange multiplier. The tangent plane is of the form $f_x(p_0)(x-x_0)+f_y(p_0)(y-y_0)+f_z(p_0)(z-z_0)$ where $f_x=2x, f_y=-2y, f_z=4z$ . So in that point, we get $4(x-2)+2(y+1)+4(z-1)$ . This will be our constraint $g(x,y,z)$ The function we want to optimize is the Euclidian distance squared $(x-0)^2+(y-0)^2+(z-0)^2:=f(x,y,z)$ So with lagrange : $(2x,2y,2z)=\lambda(4,2,4)$ so $(x,y,z)=\lambda(2,1,2)$ . So $\lambda=\frac{x}{2}=y=\frac{z}{2}$ So $x=z=2y$ My questions are : 1) Is what I did until now correct ? 2) If yes, how am I supposed to find the given point(s) now ? I have everything expressed in term of one variable but how do I find the value of this variable ? I thought about plugging $x$ and $z$ in terms of $y$ into the original surface equation $x^2-y^2+2z^2=5$ but we're asked to find the distance of the tangent plane of that equation at a point, so the tangent plane of that point isn't necessarily member of that surface, or am I wrong ? Thanks for your help !","['analysis', 'real-analysis', 'multivariable-calculus', 'calculus', 'optimization']"
3076193,Prove $f$ is decreasing?,"Let $f:\mathbb{R}\to\mathbb{R}$ be a differentiable function on $[a,+\infty)$ , such that $f^\prime$ is increasing and $\lim_{x\to\infty}f(x)=0$ I have two questions as follows (1) how do you prove that $f$ is decreasing on $[a,+\infty)$ (2) Can the condition ""the sequence $f(n)$ convergent to zero"" work instead of $\lim_{x\to\infty}f(x)=0$ ? I tried to prove this by definition of derivative as follows Since $f^\prime(a)\leq f^\prime(x)$ when $a\leq x_0\;;x_0\in[a,+\infty)$ then we have $$\lim_{x\to a}\frac{f(x)-f(a)}{x-a}\leq\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}$$ but this way can not work.","['calculus', 'derivatives']"
3076204,Exchange limit on bounds of Lebesgue integral,Let $(E_n)_{n \in \mathbb{N}}$ be a sequence of measurable sets such that $\lim_{n \to \infty} E_n =E$ for some measurable set $E$ . When does it hold that $$ \lim_{n \to \infty}\int_{E_n}f d \mu = \int_{E}f d\mu$$ What if we replace $\lim$ with $\lim \sup$ or $\lim \inf$ ?,"['measure-theory', 'lebesgue-integral']"
3076215,Summation of: (binomial coefficients * Stirling numbers of the second kind),"Problem: Simplify the following equation: \begin{equation}
\sum\limits_{k=1}^n \dbinom{n}{k} \begin{Bmatrix} n\\ k \end{Bmatrix} k!
\end{equation} A solution: I am aware of the following relation: \begin{equation}
\sum\limits_{t=1}^n t^n = \sum\limits_{k=1}^n \dbinom{n+1}{k+1} \begin{Bmatrix} n\\ k \end{Bmatrix} k!
\end{equation} Now, I am struggling to get to a somewhat similar (i.e., clean) expression for the given equation. Thanks for your help!","['binomial-coefficients', 'combinatorics', 'stirling-numbers']"
3076217,How do I find the following limit of $f'(a+(1/x))$ without assumption of continuity of $f '$?,"We are given $a$ is a real number such that $f(a)=5$ , $f'(a)=2$ . Calculate the limit: $$\lim_{n \to \infty}\left(\frac{f\left(a+1/n\right)}{f(a)}\right)^n$$ Here is what I tried: I just raised $e$ to the power of all of that and then took $\log$ and I got that I'd need to calculate the limit of $$\exp\left( n \cdot \log\left(\frac{f(a+(1/n))}{f(a)}\right)\right).$$ Now using L'Hospitals rule, I got: $$\lim_{x \to \infty}\frac{\log(f(a+(1/x))-\log(f(a))}{1/x}=\lim_{x \to \infty}(f'(a+(1/x))/f(a+(1/x)). $$ Now $f(a+(1/x))$ approaches $f(a)=5$ , because $f$ is continuous at $a$ . But what does $f'((a+(1/x))$ approach? If we knew $f'$ was continuous, the answer would be $2$ , and then the total answer would be $e^{2/5}$ which is the real answer, but how can you get it without knowing $f'$ is continuous at $a$ ?","['limits', 'calculus', 'derivatives']"
3076295,$\mathbb{C}P^1\times...\times \mathbb{C}P^1/S_m=\mathbb{C}P^m$,Let $X:=\mathbb{C}P^1\times...\times \mathbb{C}P^1$ be the product of $m$ copies of $\mathbb{C}P^1$ and $S_m$ acts on $X$ by permuting the factors. Then why is $X/S_m=\mathbb{C}P^m$ ?,"['algebraic-geometry', 'projective-space']"
3076357,Asymptotic approximation regarding the Gamma function $\Gamma$.,"On the wikipedia page for Gamma function I saw an interesting formula $$
\lim_{n\to \infty} \frac{\Gamma(n+\alpha)}{\Gamma(n)n^\alpha} = 1
$$ for all $\alpha\in\Bbb C$ . I couldn't find the source of this and searching here in MSE didn't provide the result I want. Could anyone show me how this formula is derived? I'm very inexperienced with properties/identities of $\Gamma$ so forgive me if this question is trivial.","['gamma-function', 'number-theory', 'special-functions', 'real-analysis']"
3076366,How to fit data to a piecewise function?,"My question today regards a set of data that I wish to fit a piecewise-defined continuous function. This data set covers a domain of x-values from $0$ to $\mu$ on the x-axis. What I need is to determine a value $x_0 \in {\rm I\!R}+$ and two functions of given forms $f_1: [0, x_0] \mapsto {\rm I\!R}$ and $f_2: [x_0, \mu] \mapsto {\rm I\!R}$ such that $f_1$ and $f_2$ are both continuous and $f_1(x_0) = f_2(x_0)$ and $f_1 \cup f_2$ is the piecewise function of this type which best fits the data. Can I please have some information/instruction on the background theory regarding how to do this? Would linear least squares and elementary multivariable calculus be enough given that $f_1$ and $f_2$ must both be smooth on $(0, x_0)$ and $(x_0, \mu)$ respectively? In this case, I need to find $f_1 = ax^\frac{3}{2}$ for some $a \in {\rm I\!R}$ and $f_2 = bx + c$ for some $b, c \in {\rm I\!R}$ such that $b \in [-d,d]$ for some given $d \in {\rm I\!R}$ ; so the goal is essentially to find a piecewise function consisting of a power law curve and a line that is nearly horizontal which best fits the data I am looking at. I would very much appreciate help on this problem if you would be so kind.","['statistics', 'calculus', 'least-squares', 'linear-algebra', 'piecewise-continuity']"
3076369,"""Standard reference"" for $C_c^\infty(\mathbb R)$ is dense in $C_c(\mathbb R)$","$C_c^\infty(\mathbb R)$ is dense in $C_c(\mathbb R)$ . This can be shown by mollification. This is a well-known, widely used fact. However, I wasn't able to find any book which I could point in a reference to. Is there any kind of ""standard reference"" with a readable proof?","['smooth-functions', 'functional-analysis', 'reference-request']"
3076370,Fast way to Invert ADA' when D is a diagonal matrix that changes each iteration?,"So I have a statistical learning algorithm in which D is a diagonal matrix that changes each iteration while A stays the same. I'm looking for a fast way to invert ADA' each iteration which ends up being a .9 million by .9 million sized matrix. A is m by n with m < n. My thoughts have been drawn to doing an economic SVD on A to get A=SVU' (and V ends up being a square diagonal matrix) at which point I only need to worry about inverting the inner U'DU term and U'*U=I, I feel like there should be something possible but I can't figure it out. Any ideas? some additional notes: A is fairly sparse, preprocessing things like the SVD of A can take as long as necessary...etc MATLAB code that i've tested to show that the suggested approach doesn't work (unsure how to format this): rows=90;
cols=120;
G=rand(rows,cols);
[X,Y,Z]=svd(G,'econ');
A=Z'; %the above was just to generate A s.t. A'A=I, as in second paragraph above
d=rand(1,cols);
D=diag(d);
M=A*D*A';
Minv=M^(-1) %something to compare with
%[U,E,V]=svd(A); %also tried this, it didn't work either
[U,E,V]=svd(A,'econ');
Einv=E';
Einv(1:rows,1:rows)=diag(1./diag(E)); %calculate inverse of E
Ap=V*Einv*U';
Minv2=Ap'*D^(-1)*Ap;
max(max((Minv-Minv2).^2))  %did it work? (no)","['matrices', 'sparse-matrices', 'inverse']"
3076396,Is it possible to recognize when an endomorphism of a finite dimensional vector space is unitary for some choice of inner product?,"Let $V$ a finite dimensional vector space over $\mathbb{C}$ . Let $T\in GL(V)$ . Are there reasonable criteria for recognizing whether or not there is some inner product on $V$ w.r.t. to which $T$ is unitary? (equivalently, whether or not $T$ is similar to a unitary operator?)","['inner-products', 'linear-algebra']"
3076425,Compact operator $L:\ell^2\to\ell^2$ with $\Vert L\Vert=1$ such that $\Vert L(x)\Vert<\Vert x\Vert$ for all $x$,"Let $\ell^2$ denote the space of square summable sequences of complex numbers. Let $L:\ell^2\to\ell^2$ be a linear operator with $\Vert L\Vert=1$ such that for all $x\in\ell^2\setminus\{0\}$ , $\Vert L(x)\Vert_2<\Vert x\Vert_2$ . Give an example of a compact operator with these properties or show that no such compact operator exists. I thought of some bounded operators with the above properties and none of them were compact, so I feel like no such compact operator exists. Since $\Vert L\Vert=\sup_{\Vert x\Vert_2=1}\Vert L(x)\Vert_2=1$ , there exists a sequence $x_n\in\ell^2$ such that $\Vert x_n\Vert_2=1$ for all $n$ and $\Vert L(x_n)\Vert_2\to 1$ . My idea was to show that no subsequence of $L(x_n)$ converges (as that tended to be the case in the examples I thought of) which would show that the image of the closed unit ball is not contained in any compact set and hence, $L$ is not compact. But I'm not sure  whether that is actually true, and if it is true, I'm not sure how to prove it.","['operator-theory', 'compact-operators', 'functional-analysis']"
3076449,"If $\mu$ has a density with respect to the Lebesgue measure, is $C_c(\mathbb R)$ dense in $L^p(\mu)$?","Let $\mu$ be a probability measure on $(\mathbb R,\mathcal B(\mathbb R))$ . Is $C_c^\infty(\mathbb R)$ dense in $L^p(\mu)$ for all $p\ge1$ ? Let $\lambda$ denote the Lebesgue measure on $(\mathbb R,\mathcal B(\mathbb R))$ . We know that $C_c(\mathbb R)$ is dense in $L^p(\lambda)$ for all $p\ge1$ . Since, $C_c^\infty(\mathbb R)$ is dense in $C_c(\mathbb R)$ , we can conclude that $C_c^\infty(\mathbb R)$ is dense in $L^p(\lambda)$ for all $p\ge1$ . Now, I'm especially interested in the case where $\mu$ has a density $f$ with respect to $\lambda$ . It would be even fine for me to assume that $f\in C^2(\mathbb R)$ and that $f>0$ . Moreover, it would be sufficient for me to obtain the desired claim for $p=2$ ? Is there any chance to use the known result for the Lebesgue measure?","['measure-theory', 'functional-analysis', 'real-analysis']"
3076460,How is this step acheived? $h(x)= 27x^6+26x^3-1 $,Find all real roots of $h(x)$ . Solution I have solved the question by letting $u = x^3$ and then using the quadratic formula to solve $27u^2+26u-1 = 0$ . However I don't have a clue as to how they've achieved $27x^3 -1x^3+1=0$ as one of the steps. I have highlighted the section in the image linked Solution.,"['quadratics', 'functions', 'roots']"
3076461,Hypersurfaces of degree $d$ in $\mathbb{P}^n_k$ that contain a given closed $X$,"Let $k$ be an algebraically closed field and consider $\mathbb{P}^n_k$ , the be the $n-$ dimensional projective space over $k$ . It is known that, for any integer $d>0$ , there is a bijection between the hypersurfaces of degree $d$ and $\mathbb{P} H^0(\mathbb{P}^n_k, \mathcal{O}_{\mathbb{P}^n_k}(d))$ . Now, let $X\subseteq \mathbb{P}^n_k$ be a closed subscheme and let $\mathcal I_X$ be the corresponding sheaf of ideals. Intuitively I can say that there is a bijection between the hypersurfaces of degree $d$ containing $X$ and $\mathbb{P} H^0(\mathbb{P}^n_k, \mathcal{I}_X(d))$ . How can I show this fact formally?","['algebraic-geometry', 'projective-schemes', 'schemes']"
3076469,Different definitions of an algebra over a commutative ring,"Let $R$ be a commutative ring. Here are two definitions of an $R$ -algebra: An $R$ -algebra is a ring $A$ together with a ring homomorphism $f: R\to A$ (Atiyah) An $R$ -algebra is an $R$ -module $A$ together with an $R$ -bilinear mapping $\cdot: A\times A \to A$ ( https://proofwiki.org/wiki/Definition:Algebra_over_Ring ) Are these two equivalent? I can see that there is an $R$ -module structure on $A$ in the first definition; addition is given by addition in $A$ and multiplication by elts of $R$ is given by $(r,a)\mapsto f(r)a$ (the product in $A$ ). But definition 2 says that there is also an $R$ -bilinear mapping. What is it in the first definition?","['abstract-algebra', 'linear-algebra', 'modules']"
3076511,Is there any inequality between 2-norm condition number and Frobenius norm condition number for rectangular matrix?,"What I have found in [1] Condition number inequality between Frobenius norm and 2-norm for square matrix, Consider a full rank matrix $X \in \mathbb{C}^{n \times m}$ , $m=n$ , then we can have, $$n - 2 + \frac{1}{\kappa_2(X)} + \kappa_2(X) \le \kappa_F(X).$$ Question: Does this inequality works for the case when $m \neq n$ ? If not, have you seen other relationship between them? Update: The following paper [2] mentioned that it is a natural extension to non-rectangular case, I don't get why. read the two equations below equation (3.7) in [2] . Ref: [1] Smith, Russell A. ""The condition numbers of the matrix eigenvalue problem."" Numerische Mathematik 10.3 (1967): 232-240. [2] Bazán, F. S. V. (2000). Conditioning of Rectangular Vandermonde Matrices with Nodes in the Unit Disk. SIAM Journal on Matrix Analysis and Applications, 21(2), 679–693. https://doi.org/10.1137/S0895479898336021","['condition-number', 'matrices', 'linear-algebra', 'matrix-analysis', 'inequality']"
3076532,Let $A$ be $2 \times 2$ nonzero real matrix.which of the following is true?,"Let $A$ be $2 \times 2$ nonzero real matrix.which of the following is
  true? $(A)$ trace of $A^2$ is positive $(B)$ $A$ has non zero eigenvalue. $(C)$ All entries of $A^2$ can't be negative. $(D)$$A^2$ has at least one positive entry. I tried to find examples to counter these statements. I took $A$ as $\begin{pmatrix}1&2\\-3&2\end{pmatrix}$ and $A^2$ is $\begin{pmatrix}-5&6\\-9&-2\end{pmatrix}$ This cancels out option $A,C$ Now I am not sure how to figure out option $(B)$ and $(D)$ I tried to change numbers of $A$ to find the example that counters $(D)$ but it is time-consuming. Is there any fact that I am missing for $(B)$ and $(D)$ ? I think $A$ can have zero eigenvalues because in my experience I never saw any statement saying a matrix must have zero value to have an eigenvalue zero. So (D) is my last option to tick. What could be another way to solve this problem quickly?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
3076559,Does Weil's converse theorem holds for weight 1?,"I'm reading Iwaneic's ""Topics in classical automorphic forms"". Now, I'm reading the proof the theorem that for any Hecke character $\xi$ of a quadratic field $K/\mathbb{Q}$ , there exists a $\mathrm{GL}_{2}/\mathbb{Q}$ automorphic form (holomorphic modular form or Maass form), which is a special case of automorphic induction. The proof uses Weil's converse theorem and the functional equation of the Hecke $L$ -function. The author proved the case of modular forms, i.e. when $K$ is an imaginary quadratic field and left the real case as an exercise. For the real case, let $\xi$ is a Hecke character of $K = \mathbb{Q}(\sqrt{D})$ where $D = \mathrm{disc}(K) >0$ . Let $\mathfrak{m}$ be a modulus of $\xi$ and $\xi((a)) = (a/|a|)$ or $(a'/|a'|)$ ( $a'$ is a conjugate of $a$ ) for $a\equiv 1$ (mod $\mathfrak{m}$ ). 
Then the theorem claims that $$
f(z) = \sum_{\mathfrak{a}\subseteq \mathcal{O}_{K}}\xi(\mathfrak{a})e^{2\pi i (N\mathfrak{a})z}
$$ is a modular form of weight 1 on $\Gamma_{0}(|D|\cdot N\mathfrak{m})$ . I tried to imitate the proof of the imaginary case, so I defined $$g(z) = C\sum_{\mathfrak{a}} \overline{\xi}(\mathfrak{a})e^{2\pi i (N\mathfrak{a})z}$$ for some appropriate constant $C$ and tried to prove that $g = f|_{\omega}$ where $\omega = \begin{pmatrix} & -1 \\ N & \end{pmatrix}$ and some other twisted functional equations. However, in the book, it only states the Weil's converse theorem for even positive weight $k$ , so I'm not sure whether it also holds for $k=1$ . (It seems that it works, according to this note.) Actually, I can't find where the author used the condition $k\geq 2$ in the proof of Weil's converse theorem.","['number-theory', 'automorphic-forms', 'modular-forms', 'algebraic-number-theory']"
3076634,Sum of two multinomial random variables,"I have two independent multinomial random variables $Y_1$ and $Y_2$ . I have to find the distribution of $$X=Y_1+Y_2$$ $$Y_1 \sim \text{Multinomial}(n_1,(p_1,p_2...p_k))$$ $$Y_2 \sim \text{Multinomial}(n_2,(p_1,p_2...p_k))$$ I tried using the convolution to calculate the distribution but got stuck after a while $$P(x_1,x_2..x_k) = \sum_{y_1,y_2..y_n} \binom{n_1}{y_1 y_2..y_k}p_1^{y_1}p_2^{y_2}..p_k^{y_k} \binom{n_2}{(x_1-y_1) (x_2-y_2)..(x_k-y_k)}p_1^{x_1-y_1}p_2^{x_2-y_2}..p_k^{x_k-y_k}$$ such that $y_1+y_2+...+y_n = n_1$ and by similar reasoning we see that $x_1+x_2+...+x_n=n_1+n_2$ $$P(x_1,x_2..x_k) = p_1^{x_1}p_2^{x_2}...p_k^{x_k}\sum_{y_1,y_2..y_n} \binom{n_1}{y_1 y_2..y_k} \binom{n_2}{(x_1-y_1) (x_2-y_2)...(x_k-y_k)}$$ $$P(x_1,x_2..x_k) = (n_1!)(n_2!) p_1^{x_1}p_2^{x_2}...p_k^{x_k}\sum_{y_1,y_2..y_n} \frac{1}{y_1! y_2!..y_k!} \cdot\frac{1}{(x_1-y_1)! (x_2-y_2)!...(x_k-y_k)!}$$ $$P(x_1,x_2..x_k) = \frac{(n_1!)(n_2!) p_1^{x_1}p_2^{x_2}...p_k^{x_k}}{x_1! x_2!..x_k!}\sum_{y_1,y_2..y_n} \binom{x_1}{y_1}\binom{x_2}{y_2}...\binom{x_k}{y_k}$$ But after this I couldn't solve it. Please help","['statistics', 'probability-distributions', 'probability']"
3076662,"If $x$ and $y$ are acute, and $\sin y = 3 \cos (x+y) \sin x$⁡, then find the maximum value of $\tan y$","Given $x,y$ are acute angles such that $$\sin y = 3 \cos(x+y)\sin x$$ Find the maximum value of $\tan ⁡y$ . Attempt:
We have $$\begin{aligned} 3(\cos x \cos y - \sin x \sin y) \sin x & = \sin y \\ 3 \cos x \sin x - 3 \sin^2 x \tan y & = \tan y \\ 3 \cos x \sin x & = \tan y(1 +3 \sin^2 x) \\ \tan y & = \dfrac{3 \sin x \cos x} {1+3 \sin^2 x} \end{aligned}$$ Now, how about the next step? Or maybe I did some mistakes?","['optimization', 'trigonometry', 'maxima-minima', 'a.m.-g.m.-inequality']"
3076667,"Proving $(\Bbb R,+)$ has no proper subgroup isomorphic to itself","A captioned image with the text "" My love for you is like a group which has a proper subgroup isomorphic to itself "" was recently posted in a group chat I'm in.  Ignoring the argument about the semantics of the language used ( I am of the firm opinion that ""itself"" is in reference to the parent group, not the subgroup ) this got me wondering about examples of groups which have this property.  That is to say, a group $G$ that has a proper subgroup $H$ such that $G$ is isomorphic to $H$ . A few examples came to mind such as $(\Bbb Z,+) > (2\Bbb Z,+)$ and $(\Bbb Q^*,\times) > (K,\times)$ where $K=\{\frac{a}{b}~:~a,b\in\Bbb Z\setminus\{0\},~\gcd(a,2)=\gcd(b,2)=1\}$ and similar.  ( Note: subgroup, not subring ) I got to thinking about $(\Bbb R,+)$ however and wondering whether or not the real numbers have a subgroup isomorphic to the reals with respect to addition.  My gut feeling is no, but I am at a loss as to how to prove this or come up with an example.  Proper subgroups certainly exist, such as how $(\Bbb Q,+)<(\overline{\Bbb Q},+)<(\Bbb R,+)$ , and so by specifying that our proper subgroup $H$ doesn't contain some element $x$ , be it rational or irrational, that doesn't preclude $H$ from existing. So then, I ask you, does $(\Bbb R,+)$ have a proper subgroup isomorphic to $(\Bbb R,+)$ ?  How does one prove it doesn't ( if it doesn't )?  Does it even have a proper subgroup which is uncountable?  ( All examples I can think of are countable )","['group-theory', 'abstract-algebra', 'group-isomorphism']"
3076718,"If $g$ is the inverse of function $f$ and $f'(x)= \frac{1}{1+x^n}$, Find $g'(x)$","I tried the question and got an answer by the following steps: $f(g(x))=x$ Differentiating both sides w.r.t to $x$ , we get $f'(g(x)).g'(x)=1$ And therefore, $g'(x)=1+\left[{g(x)} \right]^n$ Now my question is, are there any alternate ways to approach this problem? Especially ones which may need some Integration?","['calculus', 'inverse-function', 'derivatives', 'inverse']"
3076720,Geometric multiplicity of the largest eigenvalue,"Let $$
A= \begin{bmatrix}
 a  &  2f  &  0  \\
 2f &  b   & 3f  \\
  0 &  3f  &  c  
\end{bmatrix},
$$ where $a$ , $b$ , $c$ , $f$ are real numbers and $f\neq 0$ . Find the geometric multiplicity of the largest eigenvalue of $A$ . I don't think I have to use the characteristic equation. Or do I?","['linear-algebra', 'eigenvalues-eigenvectors']"
3076842,"Coefficient of determination, why?","I mean it is written in a book ""Statistics for Management and Economics"", that coefficient of determination is coefficient of correlation squared. Well, am I the only one to whom this is surprising fact as he expected something more clear or natural?? I mean, if someone can present me the proof why, or why some other, more natural things do not work, like I don't know, absolute value of the coefficient of correlation or something similar to Chebyshev theorem ( $1-\text{coefficient of correlation}$ )?",['statistics']
3076875,Intuition behind the Connecting Morphism,"I have seen that a s.e.s of $G$ -modules $$0\longrightarrow A \longrightarrow B\longrightarrow C \longrightarrow 0$$ gives rise to the following long exact sequence: $$ 0 \rightarrow H^0(G,A) \rightarrow H^0(G,B) \rightarrow H^0(G,C) \rightarrow H^1(G,A) \rightarrow \ldots.$$ Here, we have a conneting morphism $\Delta: H^i(G,C) \rightarrow H^{i+1}(G,A).$ My question is: What does this connecting morphism do with the cocycles and coboundaries? Any help is greatly appreciated!","['group-theory', 'abstract-algebra', 'group-cohomology']"
3076881,A weird value obtained by using Cauchy Principal Value on $\int_{-\infty}^{\infty}\frac{1}{x^2}dx$,"so I'm trying to evaluate the integral in the title, $$\int_{-\infty}^{\infty}\frac{1}{x^2}dx$$ by using complex plane integration. I've chosen my contour to be a infinte half circle with it's diameter on the real axis. (integration is preformed ccw). when R tends to infinity, the arch part of the contour yields zero, and so we are left with the part along the real axis, which is the one I'm trying to evalute. there are no other poles in my contour, only a second order pole at $z=0$ lying on it. the residue of this pole is $0$ so the integral sums up to be zero (by using Cauchy principal value.) However my function is always positive and greater than $0$ , so this doesn't make sense. Any help would be appreciated","['complex-analysis', 'complex-integration']"
3076930,Is there any relationship between growth rate and amenability?,"Let $G$ be a finitely generated group, I'm interested in whether there is any relationship between amenability of $G$ (as a discrete group) and its growth rate. To make the question more precise let's divide the class of finitely generated groups into groups of polynomial, intermediate and exponential growth and into groups which are not amenable, elementary amenable and amenable but not elementary so. This gives $9$ possible combinations of growth rate and amenability, can they all occur? Thanks to Ycor's comments the table is now complete. $$\begin{array}{c|ccc} \text{amenable/growth} & \text{polynomial} & \text{intermediate} &\text{exponential} \\
\hline
\text{no} & \varnothing & \varnothing & F_2 \\
\text{elementary} & \Bbb Z & \varnothing & BS(1,n)\\
\text{yes but not elementary} & \varnothing & \Gamma & \Bbb Z/(2)\wr\Gamma\end{array}$$ where $F_2$ is the free group on two generators, $BS(1,n)=\langle a,b\mid b^{-1}ab=a^n\rangle$ is a Baumslag-Solitair group, and $\Gamma$ is Grigorchuk's group. I'm looking for examples to fill in the remaining cells or proofs that some of them are empty","['geometric-group-theory', 'group-theory', 'examples-counterexamples']"
3076938,Find any local max or min of $x^2+y^2+z^2$ s.t $x+y+z=1$ and $3x+y+z=5$,"Find any local max or min of \begin{align}
f(x,y,z)=x^2+y^2+z^2 && (1)
\end{align} such that \begin{align}
x+y+z=1 && (2)\\
3x+y+z=5 && (3)
\end{align} My attempt . Let $L(x,y,z,\lambda_1, \lambda_2)= f(x,y,z)+\lambda_2 (x+y+z-1) + \lambda_1 (3x+y+z-5)$ $L_x=2x+ 3 \lambda_1 + \lambda_2 =0$ $L_y=2y+ \lambda_1 + \lambda_2=0$ $L_z=2z+\lambda_1 + \lambda_2=0$ Solve for $x,y,z$ we get: $x=\frac{-3 \lambda_1 - \lambda_2}{2}$ $z=y=\frac{-\lambda_1 - \lambda_2}{2}$ with the use of $(2)$ and $(3)$ $\implies$ $x=2$ $y=z= \frac{-1}{2}$ so the stationary point is $(x,y,z)=(2, \frac{-1}{2},\frac{-1}{2})$ The Hessian of $L$ gives a postive definite matrix for all $(x,y,z)$ thus $(x,y,z)=(2, \frac{-1}{2},\frac{-1}{2})$ is the only local minimizer of $f$ and there is no maximizors of $f$ . Is this correct?","['nonlinear-optimization', 'lagrange-multiplier', 'multivariable-calculus', 'calculus', 'optimization']"
3077020,Complex quadratic equation always comes out as wrong,For some reason I always get the wrong answer and I don't understand why: $$4z^2-12z+19=0$$ I got $z= \frac{12 \pm \sqrt{260}i}{8}  $ and the answer is supposed to be $z=\frac{3 \pm \sqrt{10}i}{2} $ where is my mistake?,"['algebra-precalculus', 'quadratics', 'complex-numbers']"
3077046,How is the dual cone of a subspace its orthogonal complement?,"From Boyd and Vandenberghe's Convex Optimization : A dual cone of a subspace $V \subseteq \Bbb R^n$ is it's orthogonal
  complement. $V^{*} = \{y : v^Ty = 0, \forall v \in V\}$ but the dual cone is defined by: $V^{*} = \{y : v^Ty \ge 0, \forall v \in V\}$ . Why are there no vectors $v$ such that $v^Ty > 0$ ?","['convex-optimization', 'optimization', 'convex-analysis', 'functional-analysis']"
3077097,Pythagorean triples where the sum of the two cubes is also a square,"Are there any Primitive Pythagorean triple solutions $(a,b,c)$ where the sum of the two cubes is also a square? In other words are there coprime $a,b>0 \in \mathbb{N} \;, (a,b)=1$ where $a^2+b^2=c^2$ and $a^3+b^3=d^2$ for some $c,d \in \mathbb{N}$",['number-theory']
3077128,Integrals depending on a parameter: $\int_{0}^{\pi/2} \ln(a^2\sin^2{x} + \cos^2{x})dx $,"I'm trying to calculate this integral: $$ \int_{0}^{\pi/2} \ln(a^2\sin^2{x} + \cos^2{x})dx $$ For $a > 0$ . This is what I did: $$ I(a) = \int_{0}^{\pi/2} \ln(a^2\sin^2{x} + \cos^2{x})dx \\\
I'(a) = \int_{0}^{\pi/2} \frac{2a\sin^2{x}}{(a^2\sin^2{x} + \cos^2{x})} dx \\\  
I'(a) = \int_{0}^{\pi/2} \frac{2a}{(a^2 + \frac{\cos^2{x}}{\sin^2{x}})} dx  \\\
I'(a) = 2a \int_{0}^{\pi/2} \frac{1}{a^2 + \cot^2{x}}dx  \\\
I'(a) = \frac{2}{a} \int_{0}^{\pi/2} \frac{1}{1 + \frac{\cot^2{x}}{a^2}}dx $$ Here I tried to substitude $\frac{\cot^2{x}}{a^2} = t$ . This should lead me to $\arctan(something)$ (I write $\arctan{x} = \tan^{-1}{x}$ .) But I got stuck. After I get the derivative I should integrate it back to get $I(a)$ . Also there are steps that need some prepositions to be checked. Could one help me with this integral and also to clarify the steps that need special attention; such as the second step, where I can get the derivative $I'(a)$ only if the function under the integral can be differentiated? It must be possible to find its derivative.","['calculus', 'analysis', 'real-analysis']"
3077162,"Name for ""the kernel lemma""?","Lately I've been fascinated by the result that one might state slightly informally Lemma. (In the context of linear algebra over a field.) If $p$ and $q$ are relatively prime polynomials and $T$ is a linear operator then $\ker(pq(T))=\ker(p(T))\oplus\ker(q(T))$ . Follows easily from the fact that $F[x]$ is a PID; you can use it to start a proof of the existence of the Jordan Canonical Form, also for a proof that the solution to a constant-coefficient linear homogeneous DE is what it is. Q: Does this result have a standard name? Or do we know who proved it?","['abstract-algebra', 'linear-algebra', 'math-history', 'reference-request']"
3077173,Fundamental Theorem of Calculus for functions with one-sided derivative.,"Let's assume we have a continuous function $F:[0,\infty)\to\Bbb R$ such that its one-sided derivative $$
f(t):=\lim_{h\searrow 0} \frac {F(t+h)-F(t)}{h}
$$ exists everywhere on $[0,\infty)$ . Does the ""Fundamental Theorem of Calculus"" hold, i.e. for each $t\in[0,\infty)$ we have $$
F(t) = F(0) + \int_0^t f(s)\, ds?
$$ Usually we'd use the Mean Value Theorem to prove the (normal) FCT but I don't know if something similar to the MVT would be provable with only these assumptions. If the above doesn't hold in general, what kind of condition can we impose on $F$ or $f$ to make the ""FTC"" holds? Note : I also think it is possible that the assumptions that $F$ is continuous and that its one-sided derivative exists everywhere might be strong enough to deduce better property of $F$ , like the existence of $F'$ . If anyone know a result in this direction I'd really love to hear it.","['calculus', 'analysis', 'real-analysis']"
3077178,"Geometry problem related to circle, triangles.","Given acute triangle $\triangle ABC$ satisfying $|\overline{AB}| \ne |\overline{AC}|$ . Let $D,E$ , respectively, be the midpoints of $\overline{AB}, \overline {AC}$ . Let $Q, P$ be the intersections of $(\triangle ADE)$ and $(\triangle BCD)$ , $(\triangle ADE)$ and $(\triangle BCE)$ , respectively. Prove that $|\overline{AP}| = |\overline{AQ}|$ . I have already tried using radical axis but still cannot figure out the solution. Please help me with this. Thanks.",['geometry']
3077243,"Prove for any positive integer $n$, $(4n)!$ is divisible by $2^{3n}\cdot 3^n$","Problem : Prove for any positive integer $n$ , $(4n)!$ is divisible by $2^{3n}\cdot 3^n$ Solution given by the professor : $$4! = 2^3\cdot 3$$ $$(4!)^n = 2^{3n}\cdot 3^n$$ $$\frac{(4n)!}{(4!)^n}=\frac{(4n)!}{2^{3n}\cdot 3^n}$$ My question : The steps are pretty straightforward but I don't understand the last and most crucial step. For $\frac{(4n)!}{2^{3n}\cdot 3^n}$ to be an integer, we need $(4!)^n$ to divide $(4n)!$ , is it a clear property of the factorial? How is it obvious?","['divisibility', 'elementary-number-theory', 'binomial-coefficients', 'combinatorics', 'discrete-mathematics']"
3077274,Solving a difficult differential equation,"Well, I've to solve the following DE: $$y(t)=x(t)\cdot\text{a}+\text{b}\cdot\ln\left(1+\frac{x(t)}{\text{c}}\right)+\int_0^tx(\tau)\cdot p(t-\tau)\space\text{d}\tau\tag1$$ And I've no idea how to start. Some background information: this DE describes a current in an electric circuit. For the values of $a,b$ and $c$ I know that they are real and positive. For $c$ I know that $10^{-16}\le c\le10^{-4}$ . The function $y(t)=k\cdot\theta\left(t-m\right)+(n-k)\cdot\theta\left(t-v\right)$ where all the values of the constants are ral and positive and $\theta$ is the Heaviside Theta function. The function $p(t-\tau)=\mathcal{L}_\text{s}^{-1}\left\{\frac{1}{\frac{1}{R_2+sl}+\frac{s}{sR_3+\frac{1}{z}}}\right\}_{\left(t-\tau\right)}$ where all the constants are again real and positive.","['integration', 'definite-integrals', 'ordinary-differential-equations', 'logarithms']"
3077308,"$f : [0,\infty) → \mathbb{R}$ with $f(0) = f'(0) = 0$ and $f(x) < x^2$ and $f',f'',f''' > 0$?","I want to intuitively argue that there is no function with some properties, and find it tricky to explain it to someone who just understands that derivatives are representative of increase rates of a function. Here is the statement: There is no function $f(x)$ on $x \ge 0$ such that $f(0)=0$ , $f'(0)=0$ , $f(x)<x^2$ for $x>0$ and that the first, second and third derivative of $f(x)$ are strictly positive on $x>0$ . I appreciate any help!","['functions', 'derivatives', 'real-analysis']"
3077337,Derivative of $\sqrt{x^{2}}$ at $x=0$,"I'm suppose to calculate the derivative of $f(x)=\sqrt{x^2}$ when $x=0$ .
I.e., I need to determine $f'(0)$ .  I worked it out this way: $\begin{align} f'(0 )&= \lim_{x\rightarrow 0} \frac{f(x)-f(a)}{x-a}\\ \\
&=\lim_{x\rightarrow 0} \frac{\sqrt{x^2} - 0}{x-0}\\\\
&=\lim_{x\rightarrow 0} \frac{x}{x}\\ \\
&=1\end{align}$ I know I'm doing something wrong, because the solution says there is no derivative, But I don't know why.","['calculus', 'derivatives']"
