question_id,title,body,tags
2289004,"Put fraction in ""arctan-friendly"" form","I would like to put $\int\frac{1}{(2x^2+x+1)}dx$ into something like $\int\frac{1}{(u^2+1)}dx$. What is the quickest way to proceed? I know that previous fraction can be rewritten as $2t^2+t+1 = \frac{7}{8}\left( \left( \frac{4t+1}{\sqrt{7}} \right)^2 +1 \right)$, but I don't have any explaination from where this comes from. Finally, the integral yields 
$$\int_b^a \frac{7}{8} \left( \left(\frac{4t+1}{\sqrt{7}} \right)^2+1 \right)dt = \frac{2}{\sqrt{7}}\left[\arctan \left(\frac{4t+1}{\sqrt{7}}\right)\right]^a_b $$","['integration', 'fractions']"
2289017,What causes the last item of the simple periodic continued fraction of the square root of positive prime to be double the first item?,"What makes the last item of the simple periodic continued fraction of the square root of positive prime to be double the first item? The general notation of the periodic continued fractions for even items is $$\sqrt{Z^+_\text{prime}} = [a_0; \overline{a_1, a_2, ..., a_2, a_1, 2a_0}],$$ and for odd items, $$\sqrt{Z^+_\text{prime}} = [a_0; \overline{a_1, ..., a_n, ..., a_1, 2a_0}].$$ So I'm interested to see how come the last item is $2a_0$? I have formulated this question based on initial curiosity and further investigation of the topic posted here: Identity and possible generalization of the reflective periodic continued fractions and here: How do you proof that the simply periodic continuous fraction is palindromic for the square root of positive primes? , and I wanted to separate my questions into two different sub topics.","['number-theory', 'prime-numbers', 'continued-fractions']"
2289019,A linear operator $T:V\rightarrow V$ has a cyclic vector iff $f_T=m_T$ (minimal polynomial=characteristic polynomial) [duplicate],"This question already has an answer here : Minimal polynomials and cyclic subspaces (1 answer) Closed 7 years ago . I want to prove the following statement: Let linear operator $T:V\rightarrow V$ ($V$ is $n$-dimentional). Then there exists a vector $v$ such that $\left\{ v, Tv, ..., T^{n-1}v \right\}$ form a basis of $V$, iff $f_T=m_T$. (Actually, the $\Rightarrow$ direction is quite easy. I need to prove the other direction.) I've seen couple of answers to this problem in this site, all using the ""Rational Canonial Form"", which is something I wasn't tought in the course (but I am familiar with the Jordan Form). Moreover, the only proof I've found on the internet is this , which seemed to be promising, until I got to this sentence, which unfortunately seems to be a mistake: See that $V_i$ is a subspace of $V$, for all $1 \leq i \leq m$, and
  $V=\bigcup_{i=1}^m V_i$. Therefore $V=V_k$, for some $1 \leq k \leq m$. I don't know if that's true for infinite vector spaces, but for finite ones, such as $\mathbb{F}_p^n$ it's certainly isn't. Any step towards a proof would be appriciated (as well as an explanation for the suspicious claim stated above). Thank you!","['eigenvalues-eigenvectors', 'generalized-eigenvector', 'minimal-polynomials', 'linear-transformations', 'linear-algebra']"
2289044,"Is there an example for $\|f_n-f\|_p\rightarrow 0$, but $\|f_n\|_p\nrightarrow \|f\|_p$, $0<p<1$","I know that if $p\geq1$, $\|f_n-f\|_p\rightarrow 0$ implies $\|f_n\|_p\rightarrow \|f\|_p$, since then Minkowski inequality holds for the $L^p$ norm ($p\geq1$). 
Is there an example for $\|f_n-f\|_p\rightarrow 0$, but $\|f_n\|_p\nrightarrow \|f\|_p$, when $0<p<1$ and $\|f_n\|_p, \|f\|_p<\infty$? Here $\|f\|_p=(\int_\Omega|f(x)|^p \mathrm{d}x)^{1/p}$. Nathanael Skrepek's anwer reminded me that though the Minkowski inequality does not hold when $p<1$, the Cr inequality still implies the convergence.","['real-analysis', 'lp-spaces']"
2289082,Compute integral $\int_1^3\frac{\ln x}{x^2+3}\ dx $,"How to solve the integral $$\int_1^3\dfrac{\ln x}{x^2+3}\ dx\ ?$$ I was thinking of substituting $t=\ln x$ and then factor one $x$ out,is it correct?",['integration']
2289089,Has any [nontrivial] subset of the integer primes been proven to be finite?,"It has been proved that the set of irregular primes is infinite (in fact, it has been proven that even the smaller subset of irregular primes of the form $4n+3$ is infinite); whether the set of regular primes is infinite is still an open question (or, put another way, it has not yet been proven that the set of regular primes is finite). It is not known whether the set of Mersenne primes is finite or infinite. It has been conjectured that infinitely many Wilson primes exist. etc. Ignoring any sets defined by trivial limitations ( e.g. , “primes less than a billion” or similarly defined by some magnitude-based criteria), is there any subset of the integer primes that has been proven to be finite? EDIT: The distinction between “trivial” and “nontrivial” is clearly critical in this question. I’m not sure I can think of a better wording. I don’t accept the AP theorem given in the first answer (below) as a counterexample, because it necessarily includes a magnitude-based criteria: the number of primes in an AP of given [fixed] difference $d$ starting with a given prime $q$ is finite, but the number of primes which are in any AP of given [fixed] distance $d$ is apparently infinite.","['number-theory', 'prime-numbers', 'elementary-number-theory']"
2289098,Show that $n^4-20n^2+4$ is composite when $n$ is any integer.,"Crux Mathematicorum June 1978, Show that $n^4-20n^2+4$ is composite when $n$ is any integer. My question: What is meant by 'composite'? Besides, I found out that this expression could be factorised into $(n^2-4n-2)(n^2+4n-2)$. Is this related to the question? Hope someone can clarify what is meant by composite and what the question actually and solve this. Thanks in advance.",['algebra-precalculus']
2289106,Area of ascending regions on implicit plot - $\cos(y^y) = \sin(x)$,"Take the equation $$ \cos \left( y^y \right) = \sin(x) $$ The plot forms a kind of skew checkerboard, where each ""tile"" shrinks as $y$ increases. I was attempting to find the sum of the areas (the blue regions in the image below), but cannot find an expression for each area. I would like to find an expression where $a_n$ is the $n$-th region up and show whether $\sum a_n$ diverges or converges and if so the value of the sum. I'm not entirely sure how to find the corners of the region algebraically, but the first one has approximate corners: left- $\left(-\frac{\pi}{2},2.47 \right)$, top- $ \left(\frac{\pi}{2},2.62 \right)$, right- $ \left(\frac{3\pi}{2},2.47 \right)$, bottom- $ \left(\frac{\pi}{2},2.26 \right)$. If we approximate the shape of the first region as a rhombus, we get $$A \approx \frac{(3\pi/2 + \pi/2) (2.62 - 2.26)}{2} = 1.130973 \text{ or } a_0 \approx 1.130973.$$","['area', 'trigonometry']"
2289109,"Is the decomposition $M = AA^T$ unique for $M,A \in \operatorname{SL}(n,\mathbb{Z})$?","I'm trying to extend the univariate discrete gaussian kernel $f(k|t)=e^{-t}I_k(t)$ to $\mathbb{Z}^d$. In analogy to the multivariate normal, let $X=AK + b$ where $K$ is a vector of iid discrete gaussian variables with unit variance. The pdf of $K$ is then $$P(K) = e^{-d}\prod_i^d I_{k_i}(1)$$ and it is a valid distribution on $\mathbb{Z}$. By substitution $$P(X) = e^{-d}\prod_i^d I_{[A^{-1}(X-b)]_i}(1)\equiv I(A^{-1}(X-b)).$$ Because $A$ and $A^{-1}$ must map $\mathbb{Z}\to\mathbb{Z}$, $\det{A} = 1$ such that $A\in \operatorname{SL}(d,\mathbb{Z})$ (note $P(K) = P(-K)$). Since $\operatorname{E}[K] = 0$ and assuming $$e^{-t}\sum_{k=-\infty}^{\infty}k^2I_k(t)=t$$ (I've only been able to verify this numerically), then $\operatorname{E}[X] = b$ and $$\Sigma_X=\operatorname{E}[(AK+b)(b^T+K^TA^T)-bb^T]=AA^T$$ just like the continuous case. I'm curious if, like the continuous case, this distribution is uniquely defined by the matrix $\Sigma$ or whether it is instead defined by the unique matrix $A$. Hence the question of whether $M = AA^T$ is a unique decomposition on $\operatorname{SL}(d,\mathbb{Z})$. EDIT: I realized that $M = AA^T = LL^T$ where $A\neq L$ is not unique on $\operatorname{GL}(d,\mathbb{R})$, which probably makes this question moot; there are several matrices $A$ that produce random vectors from a given distribution.","['probability-distributions', 'linear-groups', 'discrete-mathematics']"
2289115,What is it that makes holomorphic functions so rigid?,"This semester I took a complex analysis class and, as far as I've seen, holomorphic functions on the complex plane have very ""powerful"" properties; For example, the identifying theorem, or the Casorati-Weierstrass theorem, Morera's Theorem, or even Gauss' mean value theorem. Thing is, most of the theorems have very ""light"" conditions but lead to ""heavy"" results. One comes to the conclusion that the holomorphy of a function is itself a very strong property. But what is it that makes it that way? In real analysis, one can say some things about differentiable functions, but not that much as one can say about complex-differentiable functions. EDIT: As stated in the answers, complex-differentiability implies complex-analyticity and that is a big thing indeed. Actually, the proof of this theorem uses Cauchy's integral formula and the uniform convergence of a series on a circle. I'm already familiar with this things though and I was kinda hoping for an answer orientated around the fact that the field $\mathbb{C}$ is algebraicly closed. Does this algebraic property of the plane play a crucial role in the implicitation ""differentiability $\rightarrow$ analyticity"" ?","['complex-analysis', 'holomorphic-functions', 'analysis']"
2289130,"Find $xyz$, given that the value of $x^2+y^2+z^2$, $x+y+z=x^3+y^3+z^3=7$","Given that $$x^2+y^2+z^2=49$$  $$x+y+z=x^3+y^3+z^3=7$$ Find $xyz$. My attempt, I've used a old school way to try to solve it, but I guess it doesn't work. I expanded $(x+y+z)^3=x^3+y^3+z^3+3(x^2y+xy^2+x^2z+xz^2+yz^2)+6xyz$ Since I know substitute the given information into the equation and it becomes $112=x^2y+xy^2+xz^2+yz^2+2xyz$ In another hand, I also expanded $(x+y+z)^2=x^2+y^2+z^2+2(xy+xz+yz)$ $7^2=49+2(xy+xz+yz)$, So from here, I know that $xy+xz+yz=0$. It seems that I stuck here and don't know how to proceed anymore. How to continue from my steps? And is there another trick to solve this question? Thanks a lot.",['algebra-precalculus']
2289131,Determining the mode or median in a statistical survey of a continuous variable,"we learned in school that the rule to determine a mode in a statistical distribution of a continuous variable is Mo=Lower boundary of modal classe+(fmo-fb)/(fmo-f before+fmo-f greater) ×class width.
Actually, I wasn't  convinced because there is no logical reason for the answer that we get to be the mode. The mode doesn't  necessarily belong to the modal class; it may be any number between the least and greatest variable although it is nearly impossible to have two exactly equal variables of same frequency. So the great question is: is the previous rule really correct and makes sense? Why are we interested in determining the exact mode? Isn't what really matters the modal class?
Similarly for the median.",['statistics']
2289190,How many independent parameters are in a skew-symmetric as well as orthogonal matrix?,"I'm currently trying to parameterize a given real and square matrix $A$ with the properties $A^T=-A$ and $A^TA=\textbf{1}_N$, for even $N$. I don't know how many independent parameters I would have for a given choice of $N$ and I would like to have a formula and a proof for this, but I don't know how. For instance, a general orthogonal matrix has $N(N-1)/2$ independent parameters. I've found that if $A$ is a $4 \times 4$, then I have $2$ independent parameters, if there are no further restrictions.","['matrices', 'orthogonal-matrices', 'linear-algebra']"
2289270,The complement of a circle in $\mathbb R^3$,"Is there a direct proof (for analysts; not using results from algebraic topology) that the complement of a circle in the Euclidean space $\mathbb R^3$ is not simply connected?  I thought about using the  following characterisation:
A pathwise connected set $X$ in $\mathbb R^3$ is simply connected if every continuous function $\varphi: \mathbb T\to X$ admits a continuous extension to $\overline{\mathbb D}$ with the same range space $X$.","['general-topology', 'complex-analysis', 'real-analysis']"
2289282,Number of linearly independent solutions for a second order linear inhomogeneous ODE and PDE,"A second order, linear, homogeneous ordinary differential equation (ODE) has two linearly independent solutions. $\bullet$ Is it also true for a second order, linear, inhomogeneous ODE? $\bullet$ How many linearly independent solutions do a second order partial differential equation (PDE) have?","['partial-derivative', 'ordinary-differential-equations']"
2289315,How do you derive definite integrals?,"How do you get $g'(y)$? $$g(y)=\int_{1}^{e^{y^{2}}}\cos\left(\sqrt{\log(x)}\right)\,dx$$","['multivariable-calculus', 'definite-integrals']"
2289329,No. of values of $n$ such that $n \leq 1000$ and $n^2+7n+1$ is divisible by $33$,"I have a problem and I have got stuck in it. The problem states that Find the no. of integral values of $n$ such that $n^2+7n+1$ is divisible by $33$ and $1\leq n\leq1000$ What I did : $$n^2+7n+1=33k$$$$n^2+7n+1-33k=0$$$$n=\frac{-7\pm\sqrt{45+132k}}{2}$$ since $n$ is integer $$45+132k=m^2$$ for some integer $m$ LHS is a multiple of $3$ so it has to be a multiple of $9$ to be a perfect square. Now I am left with $$5+44x=m^2$$ where $k=3x$ and $x$ must end with $1,0,4,5,6,9$ Now I tried some values for $x$ to make LHS a prefect square and some solutions were $n=7,19,40,52...$ But I can't do it till $1000$ How to get it mathematically? My friend suggested me to do it with the help of congruences, But I am not so strong at using them. If anyone can explain how it can be handled with congruences, it would be appreciated...","['algebra-precalculus', 'number-theory']"
2289342,finding the eigenvalues of a matrix without the polynomial,"I have a matrix $A = \begin{bmatrix}
-1 && 1 && 1 \\
1 && -1 && 1 \\
1 && 1 && -1
\end{bmatrix}$ I already know that one eigenvector of that matrix is $(1, 1, 1)$ and one eigenvalue is $1$, based on the constant sum of rows. Now I am supposed to calculate the other eigenvalues, without using the polynomial of the matrix.. 
I know that there are supposed to be two more eigenvalues and that the product of the eigenvalues is equal to $detA=4$ and that the sum of eigenvalues is equal to $trA=-3$, but I just can't seem to get the right answer. Is this even the right approach? Any hints or ideas on how to proceed are appreciated.","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2289380,Does $\pi$ have infinitely many prime prefixes?,"This is inspired by this question . Does $\pi$ have infinitely many prime prefixes (in base $10$)? That is, is the sequence A005042 infinite? It says on the OEIS that a naïve probabilistic argument suggests that the sequence of such primes is infinite. What argument would that be? Such primes would be examples of pi-primes .","['formal-languages', 'probability', 'pi', 'prime-numbers']"
2289407,Sum of two particular irrationals is irrational,"I am trying to show that a rational number say, $Q$, plus two specific irrational numbers, $\frac{\pi}{4}$ and $\ln(2)$, will produce an irrational number. I realize that if I can show $\frac{\pi}{4} \pm \ln(2)$ is irrational then $Q$ plus that result will also be irrational. I am feeling stuck because I know the irrationals aren't closed under addition and I don't think $\frac{\pi}{4} \pm \ln(2)$ will produce a rational, but how can I rigorously show this? My question explicitly is:
Does a rational number $Q + \frac{\pi}{4} + \ln(2)$ produces a rational number and does 
Q + $\frac{\pi}{4} - \ln(2)$ produces a rational number?","['abstract-algebra', 'transcendental-numbers', 'discrete-mathematics']"
2289428,Proof the area of a given triangle with coordinates is half determinant,"I was given a problem, tried to solved it but couldn't get to a solution. 
It goes like that:
There's a triangle ABC with area S. $$ \vec{AB} = (a,b) $$
$$ \vec{AC} = (c,d) $$ Prove that $$ S = \frac{\lvert ad - bc \rvert}{2} $$ I tried to solve it that way: Express $AB \cdot AC$ as $ac+bd$ and as $\sqrt{a^2+b^2}\sqrt{c^2+d^2}\cos(\alpha)$
then I expressed with $a,b,c,d \sin(\alpha)$ (by squaring both sides and using $\cos^2\alpha=1-\sin^2\alpha$)
then I expressed S as $|AC||AB|\sin(\alpha)/2$, put $\sin(\alpha)$, $|AC|$ and $|AB|$ expressed with $a,b,c,d$ and got a disgusting expression which is probably not equal $ad-bc$...
Would be happy to get your help,
Thanks","['area', 'trigonometry', 'vectors', 'determinant']"
2289449,Parallel transport around a closed loop,"Imagine an arbitrary closed loop in some Riemannian manifold $M$ with the Levi-Civita connection $\nabla$. If this curve $\gamma$ were infinitesimal (parametric distance ~ $\epsilon$) and given by 2 vector fields $U,V$, then starting from a point $A$ and parallel transporting some vector $W$ around the loop, we obtain the vector $$ \tau^{\gamma}_{A,A} W = W - \epsilon^2 R(U,V)W + \ldots$$
where $$ R(U,V) \equiv [\nabla_{U}, \nabla_{V}] - \nabla_{[U,V]} $$ is the curvature tensor and $$ \tau^{\gamma}_{A,A}: T_AM \rightarrow T_AM $$ is the operator of parallel transport around $\gamma$. My question is, is it possible to find such an operator (explicitly) for a general non-infinitesimal loop? I tried to decompose the loop into infinitesimal loops (as if in Kelvin-Stokes theorem) and to construct the operator from them, but I am stuck at how to traverse the infinitesimal loops. I guess the operator should somehow depend on the curvature tensor, since it is an identity for vanishing curvature. What is the dependence? N.B.: This is not a homework question. I am just curious.","['connections', 'riemannian-geometry', 'tensors', 'curvature', 'differential-geometry']"
2289477,Find a superior alternative to Backward Euler method,"Currently, we are using the backward Euler (or implicit Euler) method for the solution of stiff ordinary differential equations during scientific computing. Assuming a quite performant computer hardware and an identical step size which is smaller than 100us. Are there other stable integration methods that are able to compute y(n+1) in just one time step (real-time) and have lower truncation errors? What are their pros and cons? I would like to implement the most promising ones and benchmark their results. External references: Numerical Solution of Ordinary Diﬀerential Equations One-Step Methods: Chapter 3.3 John Butcher´s Tutorials","['computational-mathematics', 'algorithms', 'runge-kutta-methods', 'numerical-methods', 'ordinary-differential-equations']"
2289480,Collection of Graphs,"Let $n \in \mathbb{N}$ and $r \in \mathbb{R}$. We say that $(V, G_{1}, G_{2}, ..., G_{t})$ is a $(r,n)$-collection if $V$ is a set of $n$ vertices, and $G_{1}, G_{2}, ..., G_{t}$ are $t = n^{20}$ graphs on $V$ such that $\chi(G_{i}) \ge r$ for every $i$. We say that a $(r,n)$-collection $(V, G_{1}, G_{2}, ..., G_{t})$ is special if there exist $U \subseteq V$ such that $|U| \le 2n/3$ and $\chi(G_{i}[U]) \ge r/3$ for every $i$. Is it true that for sufficiently large $n$, every $(r,n)$-collection is  special: (i) when $r = 3n^{0.1}$? (ii) when $r = 3\log_{2}(n)$? Now I don't really know how to approach this question. I tried to use martingales but I don't understand how to use it here. I also don't know how to construct graphs with such chromatic numbers.","['combinatorics', 'graph-theory', 'probability']"
2289484,"If $f\in L^1_{loc}(\mathbb{R})$ and $\int f\varphi=0$ for all $\varphi$ continuous with compact support, then $f=0$ a.e.","I can show this for $f\in L^1(\mathbb{R})$ by creating a sequence of continuous functions of compact support $\varphi_n\to \frac{f}{|f|+1}$ so $\int\frac{f^2}{|f|+1}=0$ by Dominated Convergence so we must have $f=0$ in $L^1$. However, I'm unsure how to extend this for $f\in L^1_{loc}$, the space of locally integrable functions. Any help with this would be greatly appreciated. Thanks!","['functional-analysis', 'lp-spaces']"
2289496,Prove that a differentiable function f with $f'(x) \geq f(x)^2$ is non positive and has limit $0$,"Let $f:(0,\infty) \to \mathbb{R}$, with $f'(x) \geq f(x)^2$, be a differentiable function. I must prove that $f(x)\leq 0$ and $\lim_{x \to \infty}f(x) = 0$ As $f'(x) \geq f(x)^2 \geq 0$, $f$ is non decreasing. So, if I have $\lim_{x \to \infty} = 0$, it is easy to prove that $f(x) \leq 0$. But I'm stuck on proving $\lim_{x \to \infty} = 0$ I'd appreciate some help.","['derivatives', 'real-analysis', 'limits']"
2289509,"Why when ""fluxions"" are zero can equation be considered linear?","Reading an article form the 40's, there is a passage like this: Why can the equations be considered linear? (I assume ""fluxions"" are the derivatives.) P.S.: Article is ""Effects of Controls on Stability, Ashby, 1945"", p. 7 in Mechanisms of Intelligence, full PDF here .",['ordinary-differential-equations']
2289546,"Using a contour integral to evaluate $\int^\infty_0 \frac{(\log(x))^2}{x^2+1}\,dx $","Say we want to evaluate $\int^\infty_0 \frac{(\log(x))^2}{x^2+1}\,dx $ via integrating over a complex contour. My lecturer said to use the function
$f(z) = \frac{(\log(z) - \frac{i \pi}{2})^2}{z^2+1}\ $ with the branch cut along the negative imaginary axis over the following contour: I understand the contour choice: we include the $i$ pole to take the residue of, and we avoid the branch cut. However, I don't understand the intuition behind why they've change the function from $\log(z)$ to $\log(z) - \frac{i \pi}{2}$. Why is that of benefit to us?","['complex-analysis', 'contour-integration', 'complex-integration']"
2289604,Lines tangent to a unit circle on a complex plane,"Let $a$ and $b$ be two complex numbers on the unit circle, i.e. $|a| = |b| = 1$. (a) Show that the equation of the tangent to the unit circle at $a$ is given by
$$z + a^2 \overline{z} = 2a$$ (b) Use the result from Part (a) to show that the intersection of the tangents to the unit circle at $a$ and $b$ is
$$\frac{2ab}{a + b}$$ I got part $a$ like this: (a) Since we know the tangent line and the radius from the origin to $a$ are perpendicular, we can say $$z-a = a(e^{\pi i/2}k) = aki$$ where $k$ is some integer.
Manipulating the equation we get:
\begin{align*}
z-a &= aki \\
z &= a(1+ki) \\
\overline{z} &= \overline{a}(1-ki) \\
a^2\overline{z} &= a^2\overline{a}(1-ki)
\end{align*}
Let's simplify the right side: $$a^2\overline{a}(1-ki) = a\cdot a\overline{a}(1-ki) = a\cdot |a|^2(1-ki) = a(1-ki)$$
Now we can continue:
\begin{align*}
a^2\overline{z} &= a^2\overline{a}(1-ki) \\
a^2\overline{z} &= a(1-ki) \\
a^2\overline{z} &= a-aki \\
a^2\overline{z} &= 2a - a - aki \\
a^2\overline{z} &= 2a - z \\
z+a^2\overline{z} &= 2a
\end{align*} However, I need help on part $b$. I assume that we would need to use the answer from part $a$ for 2 lines and set them equal, but I'm not sure. Could someone help? Thank you!","['algebra-precalculus', 'complex-numbers']"
2289612,Proving existence of equal holomorph periodic function composition from strip onto annulus,"The question: Let $a,b \in \mathbb{R} \cup \{ + \infty , -\infty \} , a < b$. $\theta : S(a,b) \rightarrow \mathbb{C}$ by $\theta (z) := e^{2 \pi i z}$. Let $f \in \mathcal{O}(S(a,b))$ with $\forall z\in S(a,b): f(z+1)=f(z)$. Show there exists exactly one 
$ F \in \mathcal{O}(K_{e^{-2 \pi b}, e^{-2 \pi a}}(0))$ such that $\forall z\in S(a,b) : f(z) = (F \circ \theta)(z) $. (Here K is the annulus and $S(a,b) = \{ z \in \mathbb{C}: a < Im(z) < b \}$) I know that $\theta$ is a holomorph mapping from $S(a,b)$ onto $K_{e^{-2 \pi b},e^{-2 \pi b}}(0)$. I'm not at all sure how to abuse the periodicity/holomorphicity of $f$ to find $F$. Does anyone have any pointers?","['periodic-functions', 'holomorphic-functions']"
2289613,Find the function $f$ such that $f(x)=\frac{f(2x)}{x+1}$.,"I've been trying to find a function with the property
$$f(x)=\frac{f(2x)}{x+1}$$
using elementary functions only, and it has proven to be harder than I thought. Does anyone know how to go about finding a function given one of its properties in a systematic manner? I can already guess that this function will use a logarithm (base 2) somewhere in it, but I still can't find the function. Does it exist in the elementary functions? Does it exist elsewhere? Please help!","['functions', 'functional-equations']"
2289642,Represent n! by binomial coefficients,"I find the following formula to be true
$$
\sum_{k=0}^n {{n}\choose{k}}(k+1)^n(-1)^k=(-1)^nn!
$$
at least for $n=1,2,3$, could any one give a proof about this in general? I'm almost sure it is true, because I use a different method to compare with a known result (in fact something of much higher level and in a very different field, the author said the result without proof, and I deduce that that result comes down to the above formula), for which I want to give an alternative proof. A good reference about this formula is preferred. I guess there should be a more general formula for which this is a special case. Thanks!","['combinatorics', 'reference-request']"
2289712,"If $\lim_{n \to +\infty} \ f(\alpha n)$ exists , does this imply $\lim_{x \to +\infty} f(x)$ exists?","Let $f:\mathbb{R} \to \mathbb{R}$. Suppose $f$ has the following property: for all $\alpha >0$, the sequence $\{f(\alpha n)\}_{n \geq 0}$ converges either to a finite or infinite extended real number as $n \to +\infty$. In other words, we assume $$\forall \alpha \in \mathbb{R}_+,\lim_{n \to +\infty} f(\alpha n) = L(\alpha) $$ where $L(\alpha)$ is a value depending on $\alpha$. Note that $L(\alpha)$ may be $\pm \infty$. Does it follow that $$\lim_{x \in \mathbb{R}, x \to +\infty} f(x)$$ exists as a finite or infinite extended real number? Note that if the above claim is true, then $L(\alpha)$ is in fact independent of $\alpha$. However, we do not assume this. We can also play around with this to get stronger and weaker statements. Does it hold if we just assume $a \in \mathbb{Q}_+$? Does it hold if we assume $f$ is continuous? I haven't made too much progress. However, this is quite similar to a classic little theorem which states that for continuous $f$, if for all $\alpha>0$, $f(\alpha n)\xrightarrow[n \in \mathbb{N}, n\to+\infty]{} 0$ then $f(x)\xrightarrow[x \in \mathbb{R}, x\to+\infty]{} 0$ which is proven with the Baire category theorem. However, my 'conjecture'  only assumes the existence of the limit (rather than giving an explicit value, like $0$) and also does not assume continuity. I can't quite modify that proof to make it work here.","['real-analysis', 'sequences-and-series', 'calculus']"
2289716,"Local constancy of winding number, proof by differentiation","May someone explain the proof meant in Terren's Notes for Ex 45? Lemma 44: Let $\gamma$ be a closed curve. Then $W_\gamma: z_0 \mapsto \int_{\gamma}\frac{1}{z-z_0} \, dz $ is locally constant. If $z_0 \notin Im(\gamma)$, then exists $D(z_0,r) \cap Im (\gamma) = \emptyset $ such that $W_\gamma(z) = W_\gamma(z_0)$ for all $z \in D(z_0,r)$. Exercise 45: Give a proof based on differentiation under the integral sign and using the fact that $\frac{1}{(z-z_0)^2}$ has an antiderivative away from $z_0$. What I had in mind was 
$$ \Big| \frac{W_\gamma (a+h) - W_\gamma(a) }{h} \Big | = \Big | \int _\gamma \Big( \frac{1}{(z-z_0)^2}+\frac{1}{(z-a)(z-a-h)} \Big)\, dz \Big| \le  |h||\gamma|M \rightarrow 0$$
as $h \rightarrow 0 $, for some constant $M$. The second equality follows from adding $\int_\gamma \frac{1}{(z-z_0)^2} = 0$. Is this right? And is this what was intended?","['derivatives', 'complex-analysis', 'winding-number', 'contour-integration']"
2289725,Is the defining representation of the orthogonal group (over any field) irreducible?,"Let $V$ be a vector space over an algebraically closed field, equipped with a symmetric, non-degenerate, bilinear form $\beta : V \times V \to \mathbb{C}$. Let $O \subset GL(V)$ be the group of linear transformations preserving $\beta$. $O$ is the orthogonal group. Is $V$ irreducible as a representation of $O$? I can prove this using a fact from algebraic geometry, but this only works over $\mathbb{C}$ (as far a I know). Proposition: Work over $\mathbb{C}$. Let $X$ be a the quadric hypersurface of $\{v : \beta(v,v) = 0\}$. Then $X$ is a homogeneous space for the action of $O$, that is, the action of $O$ is transitive. Pf: We can assume that $\beta(v,w) = \Sigma v_i w_i$. Let $G^+$ be the space of oriented $2$ planes in $\mathbb{R}^n$, equipped with the usual dot product. For an orthonormal basis $v_1, v_2$, the point $w = v_1 + i v_2 \in \mathbb{C}^n$ satisfies $w^T w = 0$. A different choice of orthonormal basis would changed $w$ by a phase, and $w$ determines the orthonormal basis up to phase. Morover, if $w = v_1 + i v_2$ satisfies $w^T w = 0$, it is easy to see that $\alpha v_1, \alpha v_2$ are orthonormal, for some $\alpha$. Thus there is a correspondence between $G^+$ and the (projective) quadric hypersurface $X$. This correspondence shows us how to prove that the action is transitive. Let $[x],[y] \in X$, with $x = x_1 + x_2 i$ and $y = y_1 + y_2 i$ so that $x_1, x_2$ and $y_1, y_2$ are each an orthonormal pair of vectors in $\mathbb{R}^n$. Then there is an $A \in O(\mathbb{R})$ so that $Ax_1 = y_1$ and $Ax_2 = y_2$. This $A$ lifts to an action on $\mathbb{C}^n$ by $A(v_1 + i v_2) = Av_1 + i Av_2$. Moreover, this action is in $O(\mathbb{C})$, which can be seen by explicitely comparing $\beta( A(s + it) , A(x + iy))$ with $\beta(s + it, x + iy)$. QED Lemma: The action of $O$ is transitive on $X^c$. (This is true because any $v \in V$ with $\beta(v,v) \not = 0$ can be extended into an orthonormal basis for $\beta$. ""QED"".) So if $W \subset V$ is a subrepresentation, and $W \not = 0$, then one of $\mathbb{P}(W) \cap X$ or $\mathbb{P} \cap X^c$ is non-empty. Transitivity of the $O$ action and invariance of $W$ now implies that $\mathbb{P}(W) \supset X$ or $\mathbb{P}(W) \supset X^c$, and in both cases this implies that $W = V$. Thus $V$ is irreducible as an $O$ representation, at least over $\mathbb{C}$. To reiterate my questions: Is there an ""easier"" way to show that the defining representation of $O$ is irreducible? A more algebraic argument? (The isomorphism between $X$ and the Grassmannian of oriented planes is not obvious without hindsight, and seems to be only true over $\mathbb{C}$, or fields with some similar properties.) Not that I dislike geometry - I prefer it - but I wouldn't be surprised if there was an easier manpulation I was missing. Is it still true over other fields? Algebraically closed fields of positive characteristic? Finite fields?","['algebraic-groups', 'representation-theory', 'algebraic-geometry']"
2289754,How can prove that $T$ is a distribution?,"Let $f_t: \mathbb R^2 \to \mathbb R$ define by $f_t(x,y) = t \sin(t|x^2+y^2-1|)$. For all $\phi\in D(\mathbb R^2-\{(0,0)\})$, we denote by $T$ the map given by
$$T(\phi)=\lim_{t\to +\infty}\int_{\mathbb R^2} f_t(x,y) \, \phi(x,y)\, \mathrm{d}x\, \mathrm{d}y$$ How can prove that $T$ is a distribution of order $0$ on $\mathbb R^2-\{(0,0)\}$? Remark: I have prove that $T: D(\mathbb R^2-\{(0,0)\}) \to \mathbb R $  is a linear map. It remains to show $T$ is continuous. In fact, I started by using the polar coordinate system, then we get
$$T(\phi)=\lim_{t\to +\infty}\int_{0}^{2\pi} \int_{0}^{\infty}\,  t \sin(t|r^2-1|) \, \phi(r,\theta)\,r\, \mathrm{d}r\, \mathrm{d}\theta=... ??$$ Thank you in advance","['complex-analysis', 'real-analysis', 'distribution-theory', 'calculus']"
2289775,What is meant by the Fisher information of a particular of a particular quantity for a quartile function?,"My provided definition of the Fisher information $\mathcal{I}(\theta)$ is the expected value of the observed information $I(\theta)$, where $I(\theta)$ is the second derivative of the log-likelihood function of some distribution $F(x|\theta)$. There is an exercise in my notes which mentions that the median of the exponential distribution can be estimated using maximum likelihood, using $$
Q(p=0.5|\hat{\theta})
$$ where $Q$ is the quartile function. The exercise asks for me to find the Fisher information for this quantity . I can't really understand what this means. Clearly 
$$
Q(p=0.5|\hat{\theta}) = \theta^{-1} \ln{2}
$$
which I understand to be the median, but now what is the Fisher information? I don't think I have a distribution , do I? $\theta$ is the true value of the parameter, so it seems to me like I have an unknown quantity here... which leaves me with no idea how to derive the Fisher information. I'm not looking for a drawn out answer if that's what is required here, but rather just an idea of what is meant by the Fisher information in this context. Thanks!","['statistics', 'quantile']"
2289791,What qualifies as an infinite population?,"I've been looking for a clear guideline to distinguish between a finite population and an infinite one, for example, in some places an infinite population is described as something like the number of stars in the universe, and in other places it's described as something way smaller, like the number of products in the market. I'm studying highschool math so I'd like an answer for that level of knowledge. Thanks!","['descriptive-statistics', 'statistics']"
2289792,"Show that the function $\mathbb{Q}(A) = \sum _{ i:\omega _{ i }\in A }^{}{\,p_i}$ is a probability measure on $(\Omega, \mathcal{F})$","While working on some probability problems I got stuck in the understanding of the following: Question Let $p_1, p_2, ...p_N$ be non- negative numbers s.t. $\,p_1 + p_2 + ... + p_N = 1$ and let $\Omega = \{\omega_1, \omega_2, ..., \omega_N$}, with $\mathcal{F}$ the power set of $\Omega$. Show that the function $\mathbb{Q}$ given by: $\mathbb{Q}(A) = \sum _{ i:\omega _{ i }\in A }^{  }{ \,p_i }\quad\,for\, A\in \mathcal{F}$ is a probability measure on $(\Omega, \mathcal{F})$. Prove I understand that $\mathbb{Q}(A) \geq 0$ and $\mathbb{Q}(\Omega)=1, \mathbb{Q}(\emptyset)=0$ holds. The following should fulfill the requirement that: if $A_1, A_2, ...$ are disjoint events in $\mathcal{F}$, then $\,\mathbb{P}(\bigcup _{ i=1 }^{  \infty}{  A_i} )\,=\,\sum_{i=1}^{\infty}\mathbb{P}(A_i)$ . For this part chose some disjoint events $A_1, ..., A_k$. Every $A_i$ 
  contains different $\omega_j$ which indicates: $\mathbb{Q}\,(\bigcup _{ i=1 }^{ k }{ A_ i})\quad =\quad \sum
 _{j:\omega_j\in\, \bigcup _{ i=1 }^{ k }{A_ i}}^{  }{ p_ i }\quad = \quad\sum_{i=1}^{k}\sum_{j:\omega_j\in \,A_i}p_i \quad = \quad
 \sum_{i=1}^{k}\mathbb{Q}(A_i)$ I've been trying to figure out what is going on out here for hours, but it keeps confusing me. Is there anyone who could describe the idea behind this in a somewhat less abstract/ difficult way than shown out here? Thank you!",['probability-theory']
2289801,Valuative criterion for properness up to extensions,"Given a morphism $f : X\rightarrow Y$ of schemes of finite type, the usual valuative criterion for properness says that if for every valuation ring $R$ with fraction field $K$, and commuting morphisms $\text{Spec K}\rightarrow\text{Spec }R\rightarrow Y$ and $\text{Spec }K\rightarrow X\rightarrow Y$, then there is a unique map $\text{Spec }R\rightarrow X$ making the resulting diagram commute, then $f$ is proper. Now suppose instead we assume that $f$ is of finite type, and for every valuation ring $R$ with fraction field $K$ admitting maps as above, there exists a field extension $K'/K$ with a valuation ring $R'\subset K'$ dominating $R$ with the property that $f$ satisfies the usual valuative criterion with respect to $R',K'$. Is this 'weakened' valuative criterion (ie, valuative criterion up to extensions) actually equivalent to the original one?","['algebraic-geometry', 'commutative-algebra']"
2289805,Expected angle between bivariate normal vectors,"I am trying to find an expression for the expected angle between two correlated gaussian vectors, i.e., find $E[\theta] = E\left[\cos^{-1}\left(\frac{\bf x_1'x_2}{\|\bf x_1\|\|x_2\|}\right)\right]$ where $\bf x_1$ and $\bf x_2$ $\in R^2$,
\begin{equation}
\left(\begin{array}{c}
\bf x_1\\
\bf x_2\end{array}\right) \sim N(\bf 0,\Sigma)
\end{equation}
and
\begin{equation}
\bf \Sigma = \left(\begin{array}{cc}
\bf \Sigma_{11} &\bf \Sigma_{12}\\
\bf \Sigma_{21} &\bf \Sigma_{22} \end{array} \right)
\end{equation}
and $\bf \Sigma_{12}=\bf \Sigma_{21}' \neq \bf 0$. Assume all covariance submatrices are known. Any help will be greatly appreciated.","['statistics', 'probability', 'correlation', 'probability-distributions']"
2289830,Find the size of the central angle of a sector with the largest area,"Question: The perimeter of a central sector is equal to the sum of two radii and the length of the arc subtending the central angle of the sector. Among all sectors with a fixed perimeter that can be cut out of circles with different radii, find the size of the central angle of the sector with the largest area. I am very confused, because wouldn't the largest sector just be the whole circle itself? However, the correct answer is 2 rad.","['circles', 'trigonometry', 'geometry']"
2289831,"solve the set of simultaneous congruences using Chinese Remainder Theorem 2x= 1 (mod 5), 3x= 9 (mod 6), 4x = 1 (mod 7), 5x = 9 (mod 11)","Solve the set of simultaneous congruences using Chinese Remainder Theorem $\begin{cases}
2x \equiv 1 \pmod{5} \\
3x \equiv 9 \pmod{6} \\
4x \equiv 1 \pmod{7} \\
5x \equiv 9 \pmod{11} \\
\end{cases}$ This is what I got so far: I simplify: $2x \equiv 1 \pmod 5$ becomes $x \equiv 3 \pmod 5$ $3x \equiv 9 \pmod 6$ has $3$ solutions since $\gcd(3,6)=3$ they are $x = 17$, $19$, or $21 \pmod 6$. $4x \equiv 1 \pmod 7$ becomes $x \equiv 2 \pmod 7$ $5x \equiv 9 \pmod {11}$ becomes $x \equiv 4 \pmod {11}$ By CRT, and substituting the $3$ different solutions, I got: $x \equiv 653 \pmod{2310}$, $x \equiv 1423 \pmod{2310}$ and $x \equiv 2193 \pmod {2310}$. But, the key answer from the book is $x \equiv 653 \pmod{770}$. I am struggling to figure out how to get $x = 653 \pmod{770}$. I need help. Thank you.","['number-theory', 'congruences', 'elementary-number-theory']"
2289835,"Prove Fourier Transformation: $\int_{-\infty}^{\infty} \Theta(t) \sin (w_0 t) e^{- i w t} \,dt =- \frac{w_0}{ w^2-w_0^2 +i \text{sgn}(w)0^{+}}$","Prove:
$$\begin{align}\int_{-\infty}^{\infty} \Theta(t) \sin (w_0 t) e^{- i w t} \,dt &=- \frac{w_0}{ w^2-w_0^2 +i \text{sgn}(w)0^{+}}\\\\
&=- \frac{w_0}{w^2-w_0^2}+ \frac{i \pi }{2}(\delta(w-w_0)-\delta(w+w_0))\end{align}$$ where $\delta(x)$ is the Dirac function , $\Theta(x)$ is the Heaviside step function , $\text{sgn}(x)$ is the Sign function . I think that the 2nd equation may   need to use Sokhotski–Plemelj theorem , but there is $\text{sgn}(w)$ in the  denominator, so I don't know how to use the identity.","['improper-integrals', 'integration', 'fourier-transform', 'calculus']"
2289836,Density of continuous functions with compact support in weak $L^1$,"One can prove that the space of continuous functions with compact support is dense in $L^p$. But is it also dense in $L^{1,\infty}$ (or $L^{p,\infty}$)? I am not able to come up with a counter-example but if there should be one, it would involve $f(x) = \frac{1}{|x|^{n/p}}$ since this does not belong to $L^p$ but is in $L^{p,\infty}$.","['functional-analysis', 'analysis']"
2289868,Any method to efficiently compute SVD of a perturbation of matrix $\bf A$ if the SVD of $\bf A$ is already known?,"Suppose we know the SVD of matrix $\bf A$, and $\bf B$ is a slight perturbation of $A$ (e.g. $\|{\bf B}-{\bf A}\|_{\text F}$ is relatively small), then is there any method that can efficiently compute the SVD of $\bf B$? That is, can the knowledge of SVD of $\bf A$ be helpful for SVD of $\bf B$? I searched a little bit and found there are some papers on the bound of perturbation, e.g. Perturbation Theory for the Singular Value
Decomposition , but I currently have no luck in finding a method to compute SVD of perturbation taking advantage of the SVD of the original matrix. Any help or reference will be very much appreciated!","['svd', 'numerical-methods', 'numerical-linear-algebra', 'linear-algebra']"
2289873,How to solve a differential equation with sign function?,"I was modeling the motion of a spring oscillator with dry friction and thus I met with this equation $$kx+\operatorname{sgn} (x′)⋅|f|+mx''=0,$$ where $x$ stands for the position (positive for stretching the spring and negative for compressing it) and $k,|f|$ and $m$ are constants. I just want to solve the equation without involving more physics things like the law of energy conservation.",['ordinary-differential-equations']
2289899,"Show that $E(Z^p) = p \int_0^\infty (1-F_Z(x))x^{p-1} \, dx$ for every $p>0$ and nonnegative random variable $Z$ [duplicate]","This question already has answers here : Explain why $E(X) = \int_0^\infty (1-F_X (t)) \, dt$ for every nonnegative random variable $X$ (3 answers) Closed 7 years ago . Given a continuous positive r.v. (I think this means $Z \geq 0$), with pdf $f_Z$ and CDF $F_Z$, how would I show that the following expression $$\mathbb{E}(Z^p) = p \int_0^\infty (1-F_Z(x))x^{p-1} \, dx\text{?}$$ I don't know where to start, I tried maybe changing it to a by-parts question or something using $px^{p-1} = \frac{d}{dx}(x^p)$ but that's all I can think of.","['probability-theory', 'expectation', 'probability-distributions']"
2289911,How does Wolfram Alpha perform Taylor Expansions of functions about singular points?,"I am trying to use a Taylor Expansion to expand a function about a singular point z_0 to obtain a Laurent Series about the point z_0 . As an example, consider the function f(z) = exp(2z) / (1-z)^3 about z_0=1 First, I converted the denominator from (1-z)^3 to -(z-1)^3 . I've done Taylor Expansions about non-singular points many times using this process . According to this post , it is impossible to do a Taylor Expansion about a singular point. Yet, typing the operation into Wolfram Alpha produces the correct Laurent Series. How can I manually reproduce the output returned by Wolfram Alpha? I'd appreciate even the smallest hint, as my problem is that evaluating the function and a few consequent derivatives at z=z_0 returns .../0 , as is easier to see here .","['wolfram-alpha', 'taylor-expansion', 'laurent-series', 'complex-analysis', 'singularity']"
2289915,The inverse of a Kac-Murdock-Szegő matrix,"I want to calculate the inverse of a matrix resembling the following form: \begin{bmatrix}
1 &\rho &\rho^2 &\cdots &\rho^{n-1}\\
\rho& 1& \rho& \cdots &\rho^{n-2}\\
\rho^2& \rho& 1 &\cdots&\rho^{n-3}\\
\vdots&\vdots &\vdots &\ddots &\vdots\\
\rho^{n-1} & \rho^{n-2}&\rho^{n-3} &\cdots&1
\end{bmatrix} each line of the off-diagonal is a polynomial of $\rho$ and the exponential is increasing towards the boundary.
I wonder how to solve this problem.","['matrices', 'linear-algebra', 'toeplitz-matrices', 'inverse']"
2289928,Are the analytic functions dense in the space of continuous functions?,"We can consider functions defined on the real or complex numbers in any finite number of dimensions. The functions are defined everywhere. They need not have limited support. They may be defined over open or closed subsets of R^n or C^n (typing on my phone so avoiding latex) or everywhere. In defining continuous functions, continuity is considered in the context of the topology induced by the Euclidean metric. Distance between functions can be taken to be the distance in the L2 norm (the integral over the entire domain of the squared difference between two functions). Which of these assumptions, if changed, might change the answer to the question? For example, we might want to be able to approximate continuous functions with analytic functions. But we might also wish to do this confidently for as wide a class of functions as possible: for instance, what about piecewise continuous functions with finite or countable points of discontinuity? We can consider widening the class of functions to include either of the latter two. Moreover, we might want to impose the strictest convergence criteria as possible for the approximations. For example, we might want to strengthen the requirement from closeness in L^2 to closeness that is uniform or close to uniform (e.g. uniform but for a finite set of points, i.e. ""almost everywhere""), where closeness is viewed in the sense of convergence of a sequence of successively better approximations. So consider the stated (numbered) assumptions, but feel free to comment on whether the answer would still hold for more favorable assumptions given that the goal is to approximate functions as stated.","['complex-analysis', 'real-analysis', 'analysis']"
2289964,Does the Dorroh Extension Theorem simplify ring theory to the study of rings with identity?,"I came across a theorem called Dorroh Extension Theorem while reading a textbook on ring theory. What the theorem essentially says is that any ring $R$ can be embedded in a ring $R^{\prime}$ with identity, i.e. there exists a subring $S^{\prime}$ of $R^{\prime}$ such that $R\cong S^{\prime}$. What I cannot understand is the following question. Why does not this theorem simplify ring theory to the study of rings with identity? The fastest answer that comes to my mind is that a subring of a ring is not necessarily a ring with identity . But is this the only reason? I'll be grateful for any help provided. Edit : Proof of the Dorroh Extension theorem. Consider $R\times\mathbb{Z}$. Define the operations as $(a,m)+(b,n)=(a+b,m+n)$ and $(a,m)(b,n)=(ab+an+mb, mn)$. Then $R\times \mathbb{Z}$ is a ring with identity $(0,1)$. And $R\times\{0\}$ is a subring of $R\times\mathbb{Z}$. Moreover $f:R\to R\times\{0\}$ given by $f(a)=(a,0)$ is an isomorphism. Hence the theorem "" Any ring can be embedded in a ring with identity"" .","['abstract-algebra', 'ring-theory']"
2290020,Is there a non-affine harmonic map with constant determinant?,Does there exist a smooth harmonic map $f:\mathbb{R}^2 \to \mathbb{R}^2$ such that: $\det(df)$ is constant. $f$ is not affine. Is there such a map with $\det(df) \neq 0$? ($f$ is harmonic if each of its two components is a harmonic function).,"['multivariable-calculus', 'harmonic-functions']"
2290037,Zariski closure of a set using the topological definition of closure,"I am aware of the more standard proof that for $Z \subseteq \mathbb{A}^n(k)$, $\overline Z = V\left(I(Z)\right)$, its closure in the Zariski topology. I was wondering if this result could also be had using the definition of closure in general topology as the intersection of all closed sets containing $Z$. The proof I imagined was along these lines \begin{align}\overline{Z} &= \displaystyle\bigcap_{C\supseteq Z,\\C \subseteq \mathbb{A}^n \text{ closed}} C \\& = \displaystyle\bigcap_{\mathfrak{a} \subseteq k[x_1, \ldots, x_n],\\\mathfrak{a} \text{ vanishes on } Z} V(\mathfrak{a}) \\ &= V\left(\sum_{\mathfrak{a} \text{ vanishes on } Z} \mathfrak{a}\right) \\&\ldots?\\ &= V\left(\bigcap_{\mathfrak{m} \text{ vanishes on } Z,\\\mathfrak{m} \text{ maximal}} \right) \\ &= V\left(\bigcap_{x \in Z} \mathfrak{m}_x\right) \\&= V(I(X))  \end{align} Have I messed this up anywhere? If not, what are the missing steps?","['general-topology', 'ring-theory', 'algebraic-geometry']"
2290051,Going Up Theorem - Examples? Witnesses?,"I am currently in Chapter 5 - Integral Dependence and Valuations of the text Introduction to Commutative Algebra by Atiyah - Macdonald. I am in particular studying the `Going-up theorem', and I have a request/question that the community here may be able to help with. First I should mention that I know there are many other questions on MSE regarding the Going-up theorem, and none of them address my question. I have also spent several hours scouring google, and still have nothing. I currently feel confident that I understand both the statement and proof of the Going-up theorem, but I feel I am missing the importance. It has been noted in this question that the algebro-geometric interpretation is a more compelling account of the result. What I believe would solidify my understanding is to see concrete examples and applications of the Going-up theorem. I am also familiar with the results in the exercises from Chapter 5 that give the geometric equivalent of the theorem, i.e. the conditions of the map $f^*:\mathrm{Spec}(B) \to \mathrm{Spec}(A)$ when the map $A \to B$ is an integral morphism, or satisfies the Going-up property, so geometric examples that transpire from the algebraic theorem would also be nice. Working out of Atiyah-Macdonald is currently my only exposure to commutative algebra, I am familiar with nearly all of the content in the previous chapters and have done the majority of the exercises from the previous chapters. However, as most know the book is very terse and general, in my opinion, in the sense that there are not many explicit examples included, which is fine, but filling in the blanks with explicit examples has been one of my main difficulties while working out of the text. In case it is relevant, I also have exposure to elementary algebraic geometry - so feel free to provide an example relating to varieties, coordinate rings, etc. To be explicit, my question is: Can someone provide explicit examples of any of the following: Explicit (preferably interesting) rings $A$ and $B$ such that $B$ is integral over $A$. An explicit chain of prime ideals $\mathfrak{p_1} \subseteq \dots \subseteq \mathfrak{p_n}$ of $A$ and a chain $\mathfrak{q_1} \subseteq
> \dots \subseteq \mathfrak{q_m}$ ($m < n$) such that $\mathfrak{q_i}
> \cap A = \mathfrak{p}_1$ and explicitly find the extended chain 
  $\mathfrak{q}_1 \subseteq \dots \subseteq \mathfrak{q}_m$ $\mathfrak{q}_1 \subseteq \dots \subseteq \mathfrak{q}_n$ Show explicitly what geometric information can be learned from $f \colon A \to B$ being an integral homomorphism implying that
  $\mathrm{Spec}(B) \to \mathrm{Spec}(A)$ being a closed map. One of my thoughts was that coordinate rings of varieties might lead to good examples? Last, I must mention that I know this is not a typical MSE question, but after reviewing the criteria of acceptable questions for MSE, I think it satisfies since it is mathematical and it is answerable , that is, there are objectively correct answers containing the explicit examples I seek. That said, I am entirely open to suggestions if anyone objects or if anyone has suggestions as to how to make this question better suited for the community. Thank you for any help.","['algebraic-geometry', 'maximal-and-prime-ideals', 'affine-schemes', 'commutative-algebra', 'integral-dependence']"
2290083,definition of monotone increasing sets,"I've started reading All of Statistics by Larry Wasserman with the hope of gaining understanding of machine learning fundamentals.
The author gives the following definition in the first chapter: A sequence of sets $A_1, A_2,\dots$ is monotone increasing if $A_1
 \subset A_2 \subset \dots$ and we define $\lim_{n\rightarrow
 \infty}A_n = \bigcup_{i=1}^{\infty}A_i$. (The author then analogously defines the
  monotone decreasing sequence of sets.) In either case, we will write $A_n \rightarrow A$. It's obvious that for any finite k , $A_k = \bigcup_{i=1}^{k} A_k$, so I guess it's an infinite extension of this. My problem is I don't really understand the motivation behind this definition; i.e. what it ""buys us"". I'd appreciate any insight.",['elementary-set-theory']
2290090,Probability that the sum of $k$ dice is $n$,"The probability of two dice summing to k is simple enough, make a diagram of the throws, $$
\begin{array}{c}
 &|&1&2&3&4&5&6\\\hline
1&|&2&3&4&5&6&7\\
2&|&3&4&5&6&7&8\\
3&|&4&5&6&7&8&9\\
4&|&5&6&7&8&9&\color{green}{10}\\
5&|&6&7&8&9&\color{green}{10}&11\\
6&|&7&8&9&\color{green}{10}&11&12\\
\end{array}
$$ and the probability of a sum is just the length of the corresponding diagonal divided by $36$. For instance, $\mathrm{P}(\mathrm{sum} = 10) = \frac{3}{36} = \frac{1}{12}$. However, it's not as easy to draw a diagram for three dice or more, so how would a general formula look?","['probability', 'dice']"
2290099,Trigonometry+inequality.,"I saw this question in one of my Trigonometry textbooks and I am unable to find any way to move ahead.
The question says that let $A,B$ and $C$ be the angles of a triangle, then prove that $$ \sum_{cyc} \frac{\sqrt { \sin A}}{\sqrt { \sin B}+\sqrt { \sin C}-\sqrt { \sin A}} \ge \sqrt3 $$ Kindly tell me about a good approach to strike the question.","['radicals', 'inequality', 'trigonometry', 'geometric-inequalities', 'triangles']"
2290136,"Prove that the interval $(0, 1)$ and the Cartesian product $(0, 1) \times (0, 1)$ have the same cardinality","Prove that the interval $(0, 1)$ and the Cartesian product $(0, 1) \times (0, 1)$ have the same cardinality 
using the SB theorem?
Also how does one find a bijection on $f:(0, \infty) \to (0,1)$ such that they have the same cardiniality?",['elementary-set-theory']
2290137,How do I make a primitive recursive function that does division?,"I am trying to define a primitive recursive function that does division. I looked at this answer but it seems wrong to me, because according to Wikipedia: The primitive recursive functions are among the number-theoretic functions, which are functions from the natural numbers (nonnegative integers) {0, 1, 2, ...} to the natural numbers So the inequality x−t⋅y≥0 will always be true and the function will always keep adding +1. The function given in the answers seems right but only assuming that I have negative numbers. Now how could I build a PRF with just natural numbers? EDIT: I found a way to either make a division that always rounds up or always rounds down. But I haven't found one yet that always does the correct thing. So far: Div(x,y,0) = 0
Div(x,y,S(m) = A(Div(x,y,m),V(D(x,M(y,S(m))))) where S(m) is successor, A is addition, V is 0 if 0 and 1 otherwise, D is subtraction and M is multiplication. Now the above always rounds down and the next one always rounds up: Div(x,y,0) = 0
Div(x,y,S(m) = A(Div(x,y,m),V(D(x,M(y,m))))",['functions']
2290144,L2 is separable for regular Borel measures on $\mathbb R^d$,"Let $d\geq1$ and let $\mu$ be a regular Borel measure on $\mathbb{R}^d$. Show that $L^2(\mu)$ is separable. I seem to have reduced the problem to showing that indicator functions of cubes with rational coordinates can be made arbitrarily close to indicator functions of bounded measurable sets, but I am unable to proceed further.","['borel-sets', 'measure-theory', 'hilbert-spaces']"
2290158,How do I show that two random variables have the same cumulative distribution function?,"Let $X$ be a random variable on $\mathbb N_0$ and $Y$ a uniformly distributed random variable on $[0,1]$, independent of $X$. Now define the random variable $$Z:=\inf\{n\in \mathbb N_0 : Y < \mathbb P(X \leq n)\}.$$ How can I show that the cdf of $X$ and $Z$ are the same? Or how do I approach problems like these in general?","['probability', 'probability-distributions']"
2290167,What would happen if you divide each side of the equation $\cot\beta\cos2\beta = 2\cot\beta$ by $\cot\beta$?,Explain what would happen if you divide each side of the equation $\cot\beta \cos2\beta = 2\cot\beta$ by $\cot\beta$ . Is this a correct method to use when solving equations?,['trigonometry']
2290192,A concise guide to basic probability,"I am looking for a reference to learn probability theory which satisfies the following criteria: Not beginner oriented, but starting from the basis. That means, it can assume the reader to have some mathematical maturity, and analysis, linear algebra, etc can be assumed from page one. On the other hand, it should assume no knowledge of probability itself. Concise but still showing some examples. I would prefer something rather brief, say within 300 pages, if shorter and still understandable better. A  subset of a longer book is of course also fine. It should cover the basic results of probability one should know (if I knew what it should include I would not need such a book, but imagine central limit, Bayes theorem and other such things should be there). It should not be sloppy, but I am mostly interested in learning how to use probability to solve problems rather than in the discipline per se, so I am not looking for a totally abstract text in measure theory or similar things. Why am I looking for this: I would like to get a first understanding of machine learning and other data science techniques. I do not want to rush copy-pasting code and applying recipes without any understanding of them, so I am trying to get some grounding in probability and statistics, two subjects I know exceedingly little about. On the other hand, I am not trying to prepare to do research, and it should not take exceedingly long (4-6 weeks is roughly the amount of time I am planning to spend on this). I hope that there is something satisfying these criteria around there! EDIT: I have opened a similar question asking for references in statistics here .","['reference-request', 'probability-theory', 'machine-learning', 'book-recommendation', 'probability']"
2290199,"Green's theorem, double integral over a triangle","The original problem is given as thus Find $$\iint_Dx\,dxdy $$
  where $D$ is a triangle with vertices $(0,2),(2,0),(3,3)$. Green's theorem says that $$\iint_D(G_x-F_y)dxdy = \int_{\partial D}Fdx+Gdy $$
I could parametrize the individual sides of the triangle as such:
$$L_1 = (0,2)\to(2,0) : \begin{cases}x = t\\y=2-t\end{cases}0\leq t\leq 2  $$
$$L_2 = (2,0)\to (3,3) : \begin{cases}x = t+2\\y=3t\end{cases}0\leq t\leq 1$$
$$L_3 = (3,3)\to (0,2) : \begin{cases}x = 3-t\\y=3-\frac{t}{3}\end{cases}0\leq t\leq 3 $$
Is this parametrization correct? The confusing part is utilizing the theorem. I have to pick $F,G$ such that $G_x,F_y$ are continous in $D$, but $x = x-0 = 2x - x = (y+x)-y = \ldots$ there are endless possibilities. Is the theorem implying no matter which representation of $x$ I choose, the result will always be the same?
For instance: $x = x-0 \Longrightarrow G = \frac{x^2}{2}\quad F = x\qquad$ or $\qquad x = (y+x)-y\Longrightarrow G=yx+\frac{x^2}{2}\quad F = \frac{y^2}{2}$","['multiple-integral', 'greens-theorem', 'multivariable-calculus', 'integration', 'definite-integrals']"
2290206,How to find asymptotic density?,"How do I find asymptotic density of the set of even numbers $\{2,4,6,\cdots\}$ ? I know that for a subset of the natural numbers $A⊆ℕ$ let $a(n)$ be the number of elements of A which are less than or equal to n. i.e. $a(n)=\|A∩\{1,2,⋯,n\}\|$ . Then, the asymptotic density of a subset of $\mathbb N$ is defined as $\lim_{n→∞}a(n)/n$ . But I'm unsure how to calculate still. Thanks.","['number-theory', 'asymptotics']"
2290209,A concise guide to basic statistics,"I am asking for a reference in basic statistics following, in the same spirit as my similar question for probability here . That is it should: Assume some mathematical maturity and can make use of analysis, linear algebra, etc from page 1. On the other hand it should assume nothing itself on statistics itself. Be concise but still show examples. It should present the basics results of statistics (whatever that means, I am trying to say that I prefer a book focusing on few fundamental things). Not sloppy, but I am not looking for particularly abstract or research oriented viewpoint. What is it for: I would like to get some basic understanding of machine learning and other data science related techniques. Before doing so, I would like to get some basics in statistics. The rough amount of time I would like to dedicate to this is roughly 6-8 weeks. I am not pretending to learn everything which can be useful for data science in such a short time, but rather the most essential things which would allow me to have a look ahead with some real understanding, rather than just following recipes and copy-pasting code found somewhere.","['reference-request', 'machine-learning', 'statistics', 'book-recommendation', 'probability']"
2290222,Do flat morphism of schemes induce injection on cotangents?,"In the proof that an étale morphism induces an isomorphism on tangents, we use the fact that, if the morphism is unramified, then the induced map on cotangents is surjective. Then we conclude using flatness. Something I can't get from the proof is the following: is it true that a flat (possibly not étale) morphism induces an injective morphism on cotangents? (And a surjective morphism on tangents?) I know that an étale morphism preserves regularity ""downwards"", so it would not be surprising if my claim were true. But the proof of this last fact uses homological algebra, so I don't find it useful in order to proof the claim. Thank you for your possible suggestions.","['schemes', 'algebraic-geometry', 'regular-rings']"
2290308,"Is this definite integral possible to evaluate? $\int_0^\infty\frac{\log x}{(1+x^2)^2}\,dx$","$$\int_0^\infty\frac{\log x}{(1+x^2)^2}\,dx$$ I have tried to evaluate this by trying I.B.P. on various different products, and have also tried the substitution $x\mapsto1/x$. None of these work. I have put this into an online integration tool and it gives a solution using some function called ""Li"", but I have never been taught this, so do not want to use it. Is there some way of evaluating this definite integral, perhaps using complex analysis and contour integrals? I have been able to evaluate similar integrals, such as $\int_0^\infty\frac{\log x}{1+x^2}\,dx=0$ and $\int_0^\infty\frac{1}{(1+x^2)^2}\,dx=\pi/4$, but it is this one which is proving to be a struggle.","['complex-analysis', 'integration', 'definite-integrals']"
2290333,Dense subspace of $\ell_2$,"How can I show that the subspace $\{x\in \ell_2 \mid \sum_{n=1} ^\infty x_n \frac 1{\sqrt n}=0\}$ is dense in $\ell_2$? Can it be done with ""simple"" tools just by using the definition of a dense subspace? or can it be done by using the fact that $\ell_2$ is a Hilbert space?",['functional-analysis']
2290362,On eigenvalues of complex-orthogonal matrices,"Suppose that $A$ is a complex matrix satisfying $A^TA = I$ (so $A$ is the entrywise transpose, not the conjugate transpose).  What can be said about the eigenvalues of $A$, if $A$ is ""complex-orthogonal"" in this sense? Of course, for any eigenpair $(\lambda,x)$, we have
$$
x^Tx = x^TA^TAx = (Ax)^TAx = \lambda^2 (x^Tx)
$$
which allows us to conclude that $\lambda^2 = 1$... so long as $x^Tx \neq 0$.  Can anything else be said?  Does the case in which $A$ has real entries allow us to conclude that $|\lambda| = 1$?","['matrices', 'linear-algebra']"
2290382,Semi-cartesian product of graphs,"I was going through following article, where a new graph product named as Semi-cartesian product of graphs is introduced. http://download.springer.com/static/pdf/757/art%253A10.1007%252Fs10910-013-0297-6.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10910-013-0297-6&token2=exp=1495368383~acl=%2Fstatic%2Fpdf%2F757%2Fart%25253A10.1007%25252Fs10910-013-0297-6.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Farticle%252F10.1007%252Fs10910-013-0297-6 *~hmac=edf0cf8704b407f3d1902aa2aff525986a4470dc3a40a8c5ed394c72ca607d18 The author considered bipartite graphs to define this product. Does it mean that we can not consider Semi-cartesian product of non-bipartite graphs??","['terminology', 'combinatorics', 'graph-theory', 'discrete-mathematics']"
2290402,Krein-Milman theorem and dividing pizza with toppings,"In this question the OP mentions the following problem as an exercise on Krein-Milman theorem : You have a great circular pizza with $n$ toppings. Show that you can divide the pizza equitably among $k$ persons, which means every person gets a piece of pizza with exactly $\frac{1}{k}$ of any of the $n$ topping on it. I would like to ask both about interpretation (formalization) of this exercise and about the solution. I am not sure whether I interpreted it correctly. To me it seems that mathematical reformulation of the problem could be that I have functions $f_i\colon X\to [0,1]$ for $i=1,\dots,n$ corresponding to how the toppings are distributed on the surface of pizza - the space $X$. And I would like to obtain a decomposition $X=A_1,\dots,A_k$ such that for any $i=1,\dots,n$ I have $\int_{A_1} f_i = \dots = \int_{A_k} f_i$, i.e., each person has the same portion from each of the toppings. I am not sure whether this is the correct formalization. (Certainly the fact that Krein-Milman is supposed to be used is some kind of a hint on how the problem is supposed to be interpreted.) But even if my interpretation is correct, I am not sure where to start. To apply Krein-Milman theorem, I need some locally convex topological vector space and some compact convex subset. I am not sure what space I could choose, since based on the above formulation it seems that the elements of this spaces should be somehow related to divisions of the circle. Another possible interpretation I can think of is that I work with the functions $\{1,2,\dots,k\} \to \mathbb R^n$ representing how much of each topping gets the $k$-the person. It is certainly possible that $k$-the person gets the whole pizza, which would correspond to $f(k)=(1,1,\dots,1)$ and $f(i)=(0,0,\dots,0)$ for $i\ne k$. By I do not see how to show that the set of all admissible possibilities is convex. And if I can show that it is convex, then I do not really need Krein-Milman theorem.","['functional-analysis', 'locally-convex-spaces', 'convex-analysis']"
2290412,"uniform and pointwise convergence of $\sum_{n=1}^{\infty}\frac{1}{n^z}$ , Is the family $\{f_n : n \in \mathbb{N^*} \}$ normal?",Study the Convergence(pointwise and uniform ) of the sequence $(f_n)_{n \in \mathbb{N^*}}$ Where $$f_n(z)=\sum_{n=1}^{n}\frac{1}{n^z}$$ Is the family $\{f_n : n \in \mathbb{N^*} \}$ normal ? First we study the uniform convergence We must show that $\sum_{n=1}^{\infty} \frac{1}{n^z}$ is uniformly convergence in $\text{Re}\  z \geq 1+ \epsilon$ where $\epsilon >0$ $$\frac{1}{n^z} = \frac{1}{e^{z\  \text {Log}\  n}} =\frac{1}{e^{x\  \text {Log}\  n}}\frac{1}{e^{i y\  \text {Log}\  n}} $$ Now $$|\frac{1}{n^z}| = \frac{1}{n^x} \leq \frac{1}{n^{\epsilon +1}} \ \ \text{if} \ \ x \geq 1 + \epsilon$$ Let $M_n = \sum_{n=1}^{\infty} \frac{1}{n^{\epsilon +1}}$ which is converge So $\sum_{n=1}^{\infty} \frac{1}{n^z} $ converges uniformly if $x \geq 1 + \epsilon$ Moreover since $$\sum_{n=1}^{\infty}|\frac{1}{n^z}|=\sum_{n=1}^{\infty}\frac{1}{n^x} \ \ \text{which converges } \ \ \forall \ x >1$$ So $\sum_{n=1}^{\infty} \frac{1}{n^z}$ is absolutely poinwise convergent for $x > 1$ Finally How to prove that the  family is normal ? Thank you .,"['real-analysis', 'uniform-convergence', 'complex-analysis', 'sequences-and-series', 'analysis']"
2290425,finding maximum and minimum of a multivariable function in restricted domains,"Find the maximum and minimum values of $f(x,y)=xy-2x$ on the rectangle $-1\leq x \leq1 $ and $0\leq y \leq 1$ . I don't understand the approach. The solution manual suggests that the critical point is not inside my domain so maximum and minimum values of $f$ must be on one of the four boundary points. I don't understand how we get to this conclusion.",['multivariable-calculus']
2290442,Paths of length n on $\mathbb{Z}^2$ given fixed endpoint and startpoint,"Consider $\mathbb{Z}^2$ as an infinite grid where the nodes are elements , choose a startpoint $x$ and an endpoint $y$. Let $n$ be a natural number, we would like to know the number of paths from $x$ to $y$ with exactly length $n$. For a path $p : \{1,...,n\} \to \mathbb{Z}^2$ to be a valid solution it has to satisfy following conditions: $p(1) = x$ and $p(n) = y$. The path is injective, meaning $p(i) \neq p(j)$ if $i \neq j$. $p(i+1) = p(i) \pm (1,0)$ or $p(i+1) = p(i) \pm (0,1)$. If we discard the second condition the problem was solved over here . I do not understand why the given recusive form is a solution to the problem posed over there. Perhaps understanding why that solution is correct would be helpfull for this problem. example Without loss of generality we can asume $x = (0,0)$ let $y = (1,1)$ clearly there will be no paths of uneven length. The sequence for the first 10 even numbers is: $(2 , 4, 16, 76, 396, 2164, 12240, 71024, 20436, 2528780)$. Graphed on a semilogarithmic scale: . We can see an exponential-like graph. (this of course is only an example for $y = (1,1)$ it would be nice to have a closed form for all $y$) I tried some other examples too they all seem to display exponential-like behavior when they are not zero, I cannot calulate a lot of terms but it seems like it grows a bit faster than exponential: $t_n/t_{n-1}$ seems to grow. For the example from (0,0) to (1,1) the terms the sequence of fractions are approximately $(2, 4, 4.75, 5.21, 5.46, 5.66, 5.80, 5.92, 6.01) $ Graph: It seems like the fractions possibly converge. basecase If we expect to prove an explicit or recursive form the proof will probably be with induction on $n$. Here I prove the basecase: the number of different paths with minimal distance, the proof will be in the more general setting of $\mathbb{Z}^p$. Let $x=(0,0, ... ,0)$, $y = (y_1, y_2, ... , y_p)$. For a path $p:\{1,2, ...,d\} \to \mathbb{Z}^p $ from $x$ to $y$ to be of minimal length it is neccesary and sufficient that $p$ is monotone in every component. Since $p$ has to end in $y$: $\sum_i(\delta_i) = \sum_i(p(i+1) - p(i)) = y$. Here $\delta_i \in \{\mbox{sign(}y_j)\cdot e_j | j \in \{1,2,...,p\}\}$ $e_j$ is the j'th basis vector for $\mathbb{Z}^p$ in the standard basis. Every permutation of the $\delta_i$'s will result in an alternative path of minimal length from $x$ to $y$.  
Therefor the number of paths of minimal length is equal to 
$$\frac{(d-1)!}{\lvert y_1\rvert!\cdot \lvert y_2 \rvert!\cdot ...\cdot \lvert y_p \rvert!}$$
$$\tag*{$\blacksquare$}$$","['combinatorics', 'graph-theory']"
2290458,Compact iff all continuous functions are uniformly cont.,"I wonder if someone can help me with this problem: Let $(X,d)$ be a connected metric space such that all continuous functions $f:(X,d) \to \mathbb{R}$ are uniformly continuous. Show that $(X,d)$ is compact. A hint is to work with the counter positive and assume that $(X,d)$ is not totally bounded and to use Urysohn functions. I've been trying to tackle it from different directions and one idea I had was to pick  a sequence $\{x_n\}_{n\in \mathbb{N}}$ such that $x_n \in X \backslash \cup_{k=1}^{n-1} B(x_k,\epsilon)$ and define $f_n(x)=\frac{d(x,X \backslash \mathcal{U}_n )}{d(x,X \backslash \mathcal{U}_n )+ d(x,\overline{B(x_n,\epsilon)} }$ where $\mathcal{U}_n$ is an open set containing $\overline{B(x_n,\epsilon)}$ s.t 
$d( \overline{B(x_n, \epsilon)} , X \backslash \mathcal{U}_n ) <\frac{1}{n}$ and put $f(x)=\sum_{n=1}^{\infty} f_n(x)$. Would this work, is there any better way to do it? EDIT I found the following results that I think might help solving the case: Def. A space $X$ is said to be compactly generated if it satisfies: A set $A$ is open in $X$ if $A\cap C$ is open in $C$ for each compact subspace $C$ of $X$. Lemma: A space $X$ is compactly generated if it satisfies the first axiom of countability. So in particular a metric space is compactly generated(if I'm not mistaken). Lemma: If $X$ is compactly generated, then a function $f: X \to Y$ is continuous if for each compact subspace $C$ of $X$ the restricted function $\left.f\right|_C$ is continuous. So if I get this right it boils down to showing that $f(x)= \sum_{n=1}^{\infty} \frac{d(x,X \backslash \mathcal{U}_n )}{d(x,X \backslash \mathcal{U}_n )+ d(x,\overline{B(x_n,\epsilon)} }$ is continuous for each compact subset $C$. Take an arbitrary compact set $C \subset X$. Since $C$ is compact and $\{x_n \}_{n\in \mathbb{N}}$ is a diverging sequence $C$ can contain at most finitely many elements of $\{x_n \}_{n\in \mathbb{N}}$. Then 
$\left.f\right|_C(x) \sum_{i=1}^{m} \frac{d(x,X \backslash \mathcal{U}_{n_i} )}{d(x,X \backslash \mathcal{U}_{n_i} )+ d(x,\overline{B(x_{n_i},\epsilon)} }$ which is continuous since it's a finite combination of continuous functions.
This implies that $f(x)$ is continuous. However for any $\delta >0$ one can find an $n \geq 1 : \frac{1}{n} < \delta$.
Then since $d(X \backslash \mathcal{U}_{n},\overline{B(x_{n},\epsilon)})< \frac{1}{n}$ one can pick $x_0 \in X \backslash \mathcal{U}_{n}$ and $x_1 \in 
\overline{B(x_{n},\epsilon)}$ such that $d(x_0,x_1)<\frac{1}{n} < \delta$.
But since $x_0\in X \backslash \mathcal{U}_{n}, f(x_0)=0$ while $x_1 \in \overline{B(x_{n},\epsilon)}$ so $f(x_1)=1$. I haven't used the fact that $X$ is connected, and that makes me a little uneasy. If someone could check if this looks correct I would be very grateful!","['general-topology', 'real-analysis', 'metric-spaces', 'uniform-continuity']"
2290463,Plücker coordinates and grassmannians,"Let $X$ denote the set of lines in $\mathbb{P}_k^3$ and $\varphi:X\rightarrow\mathbb{P}_k^5$ be the morphism that sends, once we have chosen a reference, each $(a_0:\cdots:a_3)\vee(b_0:\cdots:b_3)$ to 
$$(\Delta_{01}:\Delta_{02}:\Delta_{03}:\Delta_{12}:\Delta_{13}:\Delta_{23}),$$
where each $\Delta_{ij}$ is given by the determinant
$$
\Delta_{ij}=\left|\begin{array}{cc}
a_i & a_j \\
b_i & b_j\end{array}\right|
$$
Which is the relationship between the Plücker coordinates of a line and the intersections of such line with the reference tetrahedron? I am aware that in many textbooks the approach to this problem is exterior algebras. Is there an elementary, alternative way of seeing that relationship? On the other hand, would that relationship imply that $\varphi$ is injective? If so, how?","['grassmannian', 'algebraic-geometry']"
2290471,Epimorphisms from a free group onto a free group,"Let $f:F_n\to F_m$ be an epimorphism ($n\geq m$). Then it is true that there is a basis $X=X_1\sqcup X_2$ in $F_n$ such that $f$ maps $\langle X_1\rangle$ isomorphically onto $F_m$, and maps $X_2$ to identity. One can probably deduce this statement from the Grushko-Neumann theorem, but somehow I cannot get an elegant proof of it. I can see that by the Grushko-Neumann we can assume that $m=1$, and hence our epimorphism factors through the abelianization. And then an ugly linear algebra appears... Any suggestions how to make the proof slick?","['group-theory', 'free-groups']"
2290478,Show that orthogonal matrices have eigenvalues with magnitude $1$ without a sesquilinear inner product,"Is it possible to consider complex eigenvalues without a Hermitian (i.e. sesquilinear) inner product over a complex vector space? For instance: let $A$ be a real orthogonal matrix (so $A^TA = I$).  Without referencing a Hermitian inner product, is it possible to show that the complex eigenvalues of $A$ have magnitude $1$? The usual proof of this fact is as follows: if $x,\lambda$ is an eigenpair of $A$, then we have
$$
\|x\|^2 = x^*x = x^*(A^*A)x = (Ax)^*(Ax) = \lambda\overline{\lambda} (x^*x) = |\lambda|^2 \|x\|^2
$$
from which it follows that $|\lambda| = 1$.  Note: this proof required the use of the sesquilinear inner product $\langle x,y \rangle = y^*x$. A rephrasing of the original question: consider $\Bbb C^n$ with the bilinear from 
$$
\langle x,y \rangle = y^Tx
$$
note that this bilinear form is not an inner product. The complex-orthogonal matrices are those matrices $A$ that satisfy $A^TA = I$, where $T$ is the entrywise transpose.  Notably, the complex-orthogonal matrices preserve the above bilinear form.  How can we show that if $A$ is complex-orthogonal with real entries, then the eigenvalues of $A$ have magnitude $1$?","['matrices', 'linear-algebra', 'alternative-proof']"
2290494,Is there a way to show the infinite Euclidean plane in a finite way?,I'm a huge fan of hyperbolic geometry. I find the Poincaré disk pretty impressive because it represents an infinite space within a finite space. Is there a way to show the infinite Euclidean 2D space (aka an Euclidean plane) in a finite way? Is it feasible or just unthinkable?,"['hyperbolic-geometry', 'euclidean-geometry', 'geometry']"
2290519,$ \lim_{x \to \infty } ( \sqrt[3]{4 x^{a} + x^{2} } - \sqrt[3]{ x^{a} + x^{2} } )^{x-[x]} $,"fine limit : $$ \lim_{x \to  \infty } ( \sqrt[3]{4 x^{a} + x^{2} } - \sqrt[3]{ x^{a} + x^{2} } )^{x-[x]} $$ such that : $$ a \in (0,2)$$ and : $[x]: \ \ $  floor function My Try : $$f(x):=( \sqrt[3]{4 x^{a} + x^{2} } - \sqrt[3]{ x^{a} + x^{2} } )^{x-[x]}$$ $$\ln f(x)=(x-[x])\ln(\sqrt[3]{4 x^{a} + x^{2} } - \sqrt[3]{ x^{a} + x^{2} } )$$ Now ?please help",['limits']
2290527,$\sin 9^{\circ}$ or $\tan 8^{\circ} $ which one is bigger?,"$\sin 9^{\circ}$ or $\tan 8^{\circ} $ which one is bigger ? someone ask me that , and said without using calculator !! now my question is ,how to find which is bigger ? Is there a logical way to find  ? I s there a mathematical method to show which is greater ? I am thankful for your guide , hint  or solution","['inequality', 'number-comparison', 'trigonometry', 'algebra-precalculus', 'geometry']"
2290530,derivative of $e^x$ using the limit definition [duplicate],"This question already has answers here : Using the Limit definition to find the derivative of $e^x$ (7 answers) Closed 7 years ago . Looking to prove  $ f(x) = e^x =f'(x) $ using the limit definition of the derivative. So far I have gotten to here: $e^x * \lim\limits_{h \to 0} \frac{e^h-1}{h}$ Any hints on what I can do next to get that entire limit to $1$? I can't use l'hopital's rule, otherwise that'd defeat the purpose.","['derivatives', 'calculus', 'limits-without-lhopital']"
2290534,Calculate the sum of $\sum_{n=1}^{\infty} \frac{x^{n+1}}{n(n+1)}$,"I would like to calculate the sum for $x\in(-1,1)$ of this:  $$\sum_{n=1}^{\infty} \frac{x^{n+1}}{n(n+1)}$$
So far I managed that 
$$\int \frac{x^n}{n}dx = \frac{x^{n+1}}{n(n+1)}, $$
and
$$\sum_{n=1}^\infty \frac{x^n}{n}=-\log(1-x), $$
and
$$ \int -\log(1-x) dx \overset{c}{=} x+(1-x)\log(1-x). $$
But I really don't know if I can put it somehow together or not.",['sequences-and-series']
2290539,Inclusion not a cofibration,"What is an example of a compact Hausdorff space $X$ and a contractible subspace $A\subset X$ such that $H^2(X)\ncong H^2(X/A)$? Note that $A\subset X$ must not be a cofibration. I was thinking that $X=[0,1]^2$ and $A$ the comb space might work but I am not sure.","['algebraic-topology', 'general-topology', 'homotopy-theory']"
2290545,Prove that matrix can be square of matrix with real entries,Prove that matrix \begin{bmatrix}1&0&0\\0&-1&0\\0&0&-1\end{bmatrix} can be square of matrix with all real entries. I have found one such matrix to be \begin{bmatrix}1&0&0\\0&1&-1\\0&2&-1\end{bmatrix} but is there an elegant way to do it without any trial and error?,"['matrices', 'matrix-equations', 'linear-algebra']"
2290590,"Derivation of inverse sine, what is wrong with this reasoning?","I'm trying to find the derivative of $\sin^{-1}(x)$. I know the steps that lead to $\frac{1}{\sqrt{1-x^2}}$, however I don't understand why the following reasoning leads to a wrong answer. Because $$\frac{d}{dx}f^{-1}(x) = \frac{1}{f'(f^{-1}(x))} $$ If we plug in for $f(x) = \sin(x)$, and because $\frac{d}{dx}\sin(x) = \cos(x)$ we get $$\frac{d}{dx}\sin^{-1}(x) = \frac{1}{\cos(\sin^{-1}(x))} $$ Since $\sin(x) = \cos(x-\frac{\pi}{2})$, we can state that $\sin^{-1}(x) = \cos^{-1}(x-\frac{\pi}{2})$. (I suspect this is what is wrong) Thus, $$\frac{d}{dx}\sin^{-1}(x) = \frac{1}{\cos(\cos^{-1}(x-\frac{\pi}{2}))}$$ Then, by the definition of inverse function, we have $$\frac{d}{dx}\sin^{-1}(x) = \frac{1}{x - \frac{\pi}{2}}$$","['derivatives', 'trigonometry', 'inverse-function', 'calculus', 'inverse']"
2290610,Smooth fibration is a submersion,"in Wikipedia and the following questions: [1] , [2] or their respective answers or comments it is said that a smooth fibration is a submersion. To make clear what I mean: Definition. A smooth map $p\colon E \to B$ is said to satisfy the homotopy lifting property in the smooth category if given the following commutative diagram where all maps are smooth: there exists an smooth map $\widetilde{F}$ making the following diagram smooth: Definition. A smooth map is said to be a smooth (Hurewicz) fibration if it satisfies the homotopy lifting property in the smooth category for all manifolds $Y$. Definition. A smooth map is said to be a smooth Serre fibration if it satisfies the homotopy lifting property in the smooth category for all discs $I^n$, $n\ge 0$. Question. Could you please help me to understand why smooth Serre fibrations or smooth Hurewicz fibrations are submersions. I have tried using the characteristic property of submersions and so on.....but I haven't been able to prove anything. By the way, I know that the projections in smooth fiber bundles are smooth submersions. That is straightforward. But I would like to generalize it to fibrations. Remark. If necessary we can assume both $B$ and $E$ are compact since it is the case I am interested in.","['algebraic-topology', 'differential-geometry', 'differential-topology']"
2290683,Sums of the form $S_k=\sum_{n\geq 1}\frac{1}{\sinh^{2k}(n \pi)}$ and the residue theorem.,"Let us define the sums $$S_k=\sum_{n\geq 1}\frac{1}{\sinh^{2k}(n \pi)}$$ A few days ago, i was able to give a surprisingly simple derivation of the fact
that
$$
S_1=\sum_{n\geq 1}\frac{1}{\sinh^2(\pi n)}=\frac{1}{6}-\frac{1}{2\pi}
$$ as an answer to this nice old question in terms of contour integration.
Being curious i immediatly tried to generalize this result to higher orders of $\sinh$, which as it turned out will not work that easily. For example, considering the case of $k=2$ it turns out that $$\text{Res}\left(\frac{
\cot(\pi z)}{ \sinh^4(\pi z)},z=z_k\right)=
\begin{cases}
\frac{1}{\pi\sinh^4(\pi k)} \quad\text {if}\,\,k \in \mathbb{Z}/0,\\
-\frac{1}{\pi\sinh^4(\pi k)} -\frac{4}{3\pi\sinh^2(\pi k)} \quad\text {if}\,\,ik \in \mathbb{Z}/0
\end{cases}
$$ So integrating over a large quadratic contour gives us absolutly no information about $S_2$, since the residues cancel (For details of the exact procedure please have a look at the post linked above). This is in fact a simple consequence of the transformation properties of $\sinh^{2k}(z)$ along the imaginary axis: $\sinh^{2k}(i y)=(-1)^k\sin^{2k}(y)$ Looking at $S_3$ with the same approach, it turns out that it contains $S_2$ as well as $S_1$ so it is clear that we need this value to make any progress in a generalization at all. I also want to mention that a Laplace/Mellintransform approach seem to suffer from the same cancellations then what i tried above, so this  is maybe also not the way to go...:/ My questions are 1.) Is there any chance to proof the result for $S_2$ (and $S_k$ in general if possible) using an an approach which is close to the one i used to calculate $S_1$ ? 2.) What is a general approach to derive calculate such sums using a minimum of knowledge about the realm of elliptic integrals, Jacobi theta functions etc. (where i'm sure they can be derived but i have far too less knowledge in this field to do this by my own) PS:
It turns out that a closed form is, according to mathematica, given by $$
S_2=-\frac{11}{90}+\frac{1}{3\pi}+\frac{\bar{\omega}^4}{7680
\pi^4}
$$
where $\bar{\omega}$ is the Lemniscate constant .","['complex-analysis', 'contour-integration', 'elliptic-integrals', 'modular-forms', 'sequences-and-series']"
2290733,"Limit with 2 variables: $\frac{x^2y}{x^4 +y^2}$, $\frac{e^{xy^3}-1}{x^2 +y^4}$ and $(x^2 +y^2)^{xy}$ at $(0,0)$","I am new to this topic so I appreciate any help on this. a)$$\lim_{(x,y) \rightarrow (0,0)} f(x,y) = \frac{x^2y}{x^4 +y^2}$$ For $x=0 \lor y=0 :  f(x,y) \longrightarrow 0$ but for $y = x^2$ the limit is $\frac{1}{2}$ so the limit does not exist. b)
$$\lim_{(x,y) \rightarrow (0,0)} f(x,y) = \frac{e^{xy^3}-1}{x^2 +y^4}$$
I don't have any ideas here c)
$$\lim_{(x,y) \rightarrow (0,0)} f(x,y) = (x^2 +y^2)^{xy}$$
Let $x \geq y$ then $|x^2 +y^2|^{xy} \leq |2y^2|^{y^2} \longrightarrow 1 \quad $for $y \longrightarrow 0$ but for $x = \frac{1}{y} \Longrightarrow f(x,y) = (\frac{1}{y^2} + y^2)^1 \longrightarrow \infty \quad$ for $y \longrightarrow 0 $ so the limit does not exist.","['multivariable-calculus', 'real-analysis', 'limits']"
2290810,How to show that all solutions of$ x'' = -x$ is $\alpha sin(t) +\beta cos(t)$,"I have this problem: Show that any solution of $x'' = -x$ is one of these: $αsin(t) + βcos(t)$ for some $(α, β)$. I'm not sure is I should use the Mean Value Theorem that says if $f '(x) = 0$ for all $x$, then $f$ is constant on that interval.","['ordinary-differential-equations', 'calculus']"
2290850,Question related to Polya urn model,"Just in case I will remind what is called Polya urn: Suppose you have an urn containing one red and one blue ball. You draw one at random. Then if the ball is red, put it back in the urn with an additional red ball, otherwise put it back and add a blue ball. Now denote by $N$ number of balls drawn before first appearance of a blue one. What will be $\operatorname{E}(N+2)^{-1}$? I can find a mean for the $N$ itself just by
$$\operatorname{E}(N) = \left(\frac 1 2 \cdot\frac 1 3 \right)\cdot1+ \left( \frac 1 2 \cdot \frac 2 3 \cdot\frac 1 4  \right)\cdot2+\cdots = \sum_{i=1}^\infty \left( \prod_{k=1}^i \frac{k}{k+1}\cdot\frac{1}{i+2}\right)\cdot i$$ but get stuck what to do with $\operatorname{E}(N+2)^{-1}$. Can anyone explain it?","['probability', 'martingales']"
2290869,Showing that $(1-\varepsilon)^2 \frac{E(X)^2}{E(X^2)} \leq P(X> \varepsilon E(X))$ for a positive random variable,I'm having problems with the following inequality. $X$ is a positive r.v. and $0 \leq \varepsilon < 1$. $$(1-\varepsilon)^2 \frac{E(X)^2}{E(X^2)} \leq P(X> \varepsilon E(X)).$$ I could use a hint.,"['probability-theory', 'measure-theory']"
2290894,"Method of Frobenius, constants replaced by power series","The source I am using is Differential Equations with Applications and Historical Notes (Simmons). I appologize in advance if I did not include enough information from the text about my question. The method of Frobenius is motivated with the $z = log(x)$ substitution in the Euler equation $$x^2y'' + pxy' + qy = 0,$$ which has solutions $x^{m_1}$ and $x^{m_2}$ (or $x^{m_1}\log{x}$ ) corresponding to $m^2 + (p-1)m + q = 0$ . It then says that if $p$ and $q$ are replaced by power series, $$y'' + \frac{(p_0 + p_1x + p_2x^2 + \dots)}{x}y' + \frac{(q_0 + q_1x + q_2x^2 + \dots)}{x^2}y=0$$ then it is natural to guess that the solutions (to the equations with power series) might be found by replacing the original solutions with solutions of the form $$y_1 = x^m(a_0 + a_1x + a_2x^2 + \dots),\\ y_2 = x^m\log{x}(a_0 + a_1x + a_2x^2 + \dots)$$ Why would this be a natural guess? I assume that there is more to this than simply multiplying our solutions by a power series simply because power series now appear in the differential equation. But I also feel like there is something really obvious that I am missing. Thanks in advance.","['frobenius-method', 'ordinary-differential-equations']"
2290899,Find $\sin(A)$ and $\cos(A)$ given $\cos^4(A) - \sin^4(A) = \frac{1}{2}$ and $A$ is located in the second quadrant.,"Question: Find $\sin(A)$ and $\cos(A)$, given $\cos^4(A)-\sin^4(A)=\frac{1}{2}$ and $A$ is located in the second quadrant. Using the fundamental trigonometric identity, I was able to find that: •　$\cos^2(A) - \sin^2(A) = \frac{1}{2}$ and • $$ \cos(A) \cdot \sin(A) = -\frac{1}{4} $$ However, I am unsure about how to find $\sin(A)$ and $\cos(A)$ individually after this. Edit: I solved the problem through using the Fundamental Trignometric Identity with the difference of $\cos^2(A)$ and $\sin^2(A)$.",['trigonometry']
2290931,Is every seminorm induced by a linear operator into a normed space?,"I'm reading an analysis textbook chapter on convex topological vector spaces, and there is this statement that (one of) the most common way(s) to define a topology on a vector space $X$ is by requiring the continuity of certain linear maps, (i.e via the semi-norms induced by given linear maps $T\colon X\to Y$ where $Y$ is a normed space). This makes sense, but then there's this that bugs me: ""Can any semi-norm on $X$ be shown to be induced by some linear map T, to some normed linear space?"" I can't find a counter-example to this, or show that it is true. Any insight would be appreciated.","['real-analysis', 'normed-spaces', 'functional-analysis', 'locally-convex-spaces', 'topological-vector-spaces']"
2290945,Proving $\cos^n(x) = \sum_{k=0}^{n} a_k \cos(kx)$,"I'm being asked to prove that, for some coefficients $a_k$,
$$
\cos^n(x) = \sum_{k=0}^{n} a_k \cos(kx)
$$ I think I got pretty close,
$$
\begin{align}
\cos^n(x) & = { \left( \frac{e^{ix} + e^{-ix}}{2} \right) ^n} \\
& = \sum_{k=0}^{n} {n \choose k} {\left( \frac{e^{ix}}{2} \right)}^k {\left( \frac{e^{-ix}}{2} \right)}^{n-k} \\
& = \frac{1}{2^n} \sum_{k=0}^{n} {n \choose k} e^{i(2k-n)x} \\
& = \frac{1}{2^n} \sum_{k=0}^{n} {n \choose k}\cos((2k-n)x) \\
\end{align}
$$ But I can't seem to get any further...",['trigonometry']
2291028,The set theoretical reason for $f(\emptyset) = \emptyset$ [duplicate],This question already has answers here : What is an image of empty set? (2 answers) Closed 2 years ago . Why is it that $f(\emptyset) = \emptyset $? I could not write a rigorous explanation for this. Could anyone explain this for me please?,['elementary-set-theory']
2291042,$(a^2+b^2)\cdot (c^2+d^2) = z^2+1$ then $z = ac+bd$ ?,"I have the following equation : 
$$(a^2+b^2)\cdot (c^2+d^2) = z^2+1$$ with $a, b, c, d, z \in \mathbb{N}$ Then how can I prove that : $z = ac+bd$ ? I tried Brahmagupta identity but it doesn't seem to work...","['number-theory', 'diophantine-equations']"
