question_id,title,body,tags
628877,Mantel's Theorem proof verification,"I found the following proof for Mantel's theorem in Lecture 1 of David Conlon's ""Extremal graph theory"" course . I cannot understand the equality that I have highlighted in the image was arrived at. I would appreciate some assistance. Theorem 1 (Mantel's theorem) *If a graph $G$ on $n$ vertices contains no triangle then it contains at most $\frac {n^2}{4}$ edges. First proof Suppose that $G$ has $m$ edges. Let $x$ and $y$ be two vertices in $G$ which are joined by an edge. If $d(v)$ is the degree of a vertex $v$, we see that $d(x)+d(y)\leq n$. This is because every vertex in the graph $G$ is connected to at most one of $x$ and $y$. Note now that 
  $$\bbox[5px,border:2px solid red]{
   \sum_x d^2(x)=\sum_{x,y\in E} \big( d(x)+d(y)\big)
   }
   \leq mn.$$
  On the other hand, since $\sum_x d(x)=2m$, the Cauchy-Schwarz inequality implies that 
  $$\sum_x d^2(x)\geq\frac{\big(\sum_x d(x)\big)^2}{n} \geq \frac{4m^2}{n}.$$
  Therfore
  $$\frac{4m^2}{n} \leq mn,$$
  and the result follows. $\tag*{$\square$}$ For people with visulal limitations, the highlighted part is: $$\sum_x d^2(x)=\sum_{x,y\in E} \big( d(x)+d(y)\big) \leq mn.$$","['graph-theory', 'discrete-mathematics']"
628882,Is there an integral domain such that none of its irreducible elements is prime?,"Is there some integral domain such that none of its irreducible elements is prime? Recall that a nonzero, non invertible element $a$ of an integral domain $D$ is said to be Irreducible , if for all $b,c\in D$ such that $a=bc$ , then either $b$ or $c$ is a unit in $D$ . Prime , if for all $b,c\in D$ such that $a$ divides $bc$ , then either $a$ divides $b$ or $a$ divides $c$ . Clearly prime implies irreducible. The converse is not true in general, but is valid when $D$ is a UFD. Obviously these notions are vacuously equivalent if $D$ has not irreducible elements (see here for examples). Summarizing, I want to know if there is some integral domain with at least one irreducible element, but without prime elements.","['commutative-algebra', 'ring-theory', 'abstract-algebra']"
628925,Relation between determinant and matrix rank,"Let $A$ a square matrix with the size of $n \times n$. I know that if the rank of the matrix is $<n$, then there must be a ""zeroes-line"", therefore $\det(A)=0$. What about $\text{rank}(A)=n$? Why does it imply $\det(A)\ne0$? Of course, there is no ""zeroes-line"", but that doesn't prove it yet. I've seen a proof in a book which does this conclusion immediately, but IMHO this alone, doesn't prove it. What's the missing part?","['matrices', 'linear-algebra', 'matrix-rank', 'determinant']"
628934,$\int_{0}^{\infty}{\left(x^3\cdot(e^x-1)^{-1} \right)}dx$,"In a certain list of exercises, contained the question $$\int_{0}^{\infty}{\left(x^3\cdot(e^x-1)^{-1} \right)}dx$$ How do you solve?","['improper-integrals', 'integration']"
629068,A different type of Law of Large Numbers,"Let $(X_i)_{i\in\mathbb{N}}$ be a sequence of i.i.d. real random variables (with finite variance if needed).
For $k>0$ fixed, I'm interested in estimating the quantity
$$ p_N(k):=\mathbb{P}(\exists\,i=1,\dots,N\text{ s.t. }|X_i-\mathbb{E}[X_i]|\geq k\,N) \;.$$ Using the Markov inequality, if $X_1$ has finite variance, it can be shown that
$\sup_{N\in\mathbb{N}} p_N(k)\to0$ as $k\to\infty$. I would like to prove that, for $k$ large enough, $\sum_{N=1}^\infty p_N(k) <\infty$. Is it true?","['probability-theory', 'law-of-large-numbers', 'sequences-and-series']"
629087,Oxtoby Thm 5.4 Bernstein sets,"I am reading Measure and Category of Oxtoby. I have a question about Theorem 5.4 added below. I think I understand the construction of Bernstein sets, and also the main line of the Proof. My question is mush more basic I think: Suppose that every measurable subset of either $B$ or $B'$ is a Nullset, and any subset of $B$ or $B'$ that has the property of Baire is of first category. Why, Does it implies that $B$ is non-measurable? Am I missing something obvious? 
Thank you for your help!!
Shir","['descriptive-set-theory', 'general-topology', 'measure-theory', 'real-analysis', 'baire-category']"
629106,Find the value of : $\lim_{x\to\infty}\sqrt{x+\sqrt{x+\sqrt{x+\sqrt{x}}}}-\sqrt{x}$,"$\lim_{x\to\infty}\sqrt{x+\sqrt{x+\sqrt{x+\sqrt{x}}}}-\sqrt{x}$ I tried conjugating and it didn't lead me anywhere please help guys. Thanks,","['radicals', 'nested-radicals', 'calculus', 'limits']"
629120,"$h(z)=|z-a| \cdot |z-b| \cdot |z-c|$, max value of $h$ is attained","Let $a,b,c$ be non-collinear points in complex plane, $\Delta$ be the closed triangular region of the plane with vertices $a,b,c$ . for $z\in\Delta$ , let $$h(z)=|z-a| \cdot|z-b| \cdot |z-c|$$ Then max value of $h$ 1. is not attained at any point of $\Delta$ 2. is attained at an interior point of $\Delta$ 3. is attained at the centre of gravity of $\Delta$ 4. is attained at the boundary point of $\Delta$ 4 is correct due to Maximum Modulus Principle. Just confirm me please.",['complex-analysis']
629122,Proving that expression is equivalent to the definition of derivative,"Let $f$ be differentiable at $x=a$. Prove that if $x_n \to a^+$ and $y_n \to a^-$ then: $$\lim_{n\to \infty} \frac{f(x_n)-f(y_n)}{x_n-y_n}=f'(a).$$ Every option that I think about seems to my very trivial, so I believe that I am doing something wrong. 
Both numerator and denominator approach zero as $n\to\infty$ as the case of the formal definition of derivative, but it isn't guaranteed that the limits are equal (“$\frac{0}{0}$”). Any direction?","['calculus', 'derivatives', 'real-analysis', 'limits']"
629129,$f$ be a nonconstant holomorphic in unit disk such that $f(0)=1$. Then it is necessary that,"$f$ be a non-constant holomorphic in unit disk such that $f(0)=1$. Then it is necessary that there are infinitely many points inside unit disk such that $|f(z)|=1$ $f$ is bounded. there are at most finitely many points inside unit disk such that $|f(z)|=1$ $f$ is rational function. Counter examples for $2,4$ are ${1\over z-1},e^z$ If there are infinitely many points in the open disk such that $|f(z)|=1$ then that set is being bounded. Since there are infinite points so it must have a limit point in it and $f$ will be bounded. And hence by Liouvilles Theorem, it is constant. This is a contradiction So $3$ is the correct statement.
Thank you for confirming.",['complex-analysis']
629136,Why $\mathcal{O}_{\mathbb{P}^n}(1)$ is a line bundle?,"Why $\mathcal{O}_{\mathbb{P}^n_{\mathbb{C}}}(1)$ is a line bundle? In the book of Hartshorne, $\mathcal{O}_{\mathbb{P}^n_{\mathbb{C}}}(1)$ is defined by $\mathcal{O}_{\mathbb{P}^n_{\mathbb{C}}}(1) = \tilde{S(1)}$, where $S=\mathbb{C}[x_0, \ldots, x_n]$. The line bundle is defined as follows. Given a complex manifold $X$, a line bundle is given by the data of a cover $U_i$ ($i \in I$ some index set), and trivializations $U_i \times \mathbb{C}$, and transition functions $f_{ij}$ on $U_i \cap U_j$ that is an analytic function, nowhere zero, satisfying $f_{ij} f_{jk} = f_{ik}$ (the cocyle condition), from which $f_{ii} = 1$ and $f_{ij} = f_{ji}$. That is, if $u \in U_i \cap U_j$, then the point $(u, z) \in U_j \times \mathbb{C}$ is identified with the point $(u, f_{ij} z) \in U_i \times \mathbb{C}$. How to show that $\mathcal{O}_{\mathbb{P}^n}(1)$ is a line bundle using this definition? Thank you very much.",['algebraic-geometry']
629156,Showing that this function is infinitely differentiable,"Show, that the function $$ \mathcal E: \mathbb R \to \mathbb R:
 x \mapsto \begin{cases}
 \exp(-\frac{1}{x^2}), & \text{if x $\neq$ 0}, \\
 0, & \text{otherwise},
 \end{cases} $$ is infinitely differentiable and that $\frac{d^k\mathcal E}{dx}(0) = 0$ for all $k \in \mathbb N$. We just introduced differentiation, so the solution should not contain very advanced techniques to solve this. We also got the tip it should be done by induction. @fgp I found that it is
$$f^{(n)}(x) = P_n \left(\frac1x\right)e^{-\frac1{x^2}}$$
where $P_n$ is a polynomial with integer coefficients. I could also do the initial step for the induction: For $n=1:$
$$f'(x) = \frac2{x^2}e^{-\frac1{x^2}} = P_1 \left(\frac1t\right) e^{-\frac1{x^2}}$$
where $P_1(x)=2x^2.$ I am stuck at the induction step: $f^{(n+1)}(x) = $.....","['derivatives', 'analysis']"
629201,Phillips spectral theorem,"In Reed-Simon (see References) the following theorem due to Phillips is cited (but not proved): Theorem (Phillips). Let $X$ be a Banach space, $T \in \mathcal L(X)$. Then $\sigma(T) = \sigma(T')$ and $R_\lambda(T') = R_\lambda(T)'$. If $\mathcal H$ is in a Hilbert space, then $\sigma(T^*) = \{ \lambda : \bar\lambda \in \sigma(T) \}$ and $R_\lambda(T^*) = R_\lambda(T)^*$. Now, the Hilbert space part is quite easy (is a standard result in many books) while the Banach space one looks more difficult. Considering that $\rho(T) = \{ \lambda : T_\lambda := T - \lambda I \, \mbox{is an isomorphism} \}$ and $\sigma(T) := \mathbb C \setminus \rho(T)$, the first claim seems true if was true that Claim (?). $T$ isomorphism $\implies T'$ isomorphism. I don't think this statement holds (maybe I'm wrong, but it doesn't sound familiar). Indeed, it is true that Proposition. $T$ isometric isomorphism $\iff T'$ isometric isomorphism. The proof of this proposition is not completely trivial (although is not too hard) and can be found, for example, in Costara-Popa. The property ""$T$ isometry"" is essential to get $T'$ isometry and hence injective, so it can't be weakened keeping the same argument for the remainder. On the other hand, from definition of $T'$, I don't see other ways to go. Does anyone know the proof of the Phillips theorem or can provide a reference? And can anyone prove or disprove the claim? Notation. $T'$ is the dual operator of $T$ (in the sense of Banach spaces), $T^*$ is the adjoint of $T$ (in the sense of Hilbert spaces), $\sigma(T)$ spectrum of $T$, $\rho(T)$ is the resolvent set and $R_\lambda(T)$ is the resolvent of $T$. References Reed-Simon, Methods of modern mathematical physics, Functional analysis , Thm VI.7; Costara-Popa, Exercises in Functional Analysis , Chp. 2, Ex. 28.","['operator-theory', 'functional-analysis']"
629213,Limits infinite with fraction [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question $$\lim_{x\to\infty} \frac{(x+1)^{10}+(x+2)^{10}+\cdots+(x+100)^{10}}{x^{10}+10^{10}}$$
Seems easy but no idea how to do it Thanks","['calculus', 'limits']"
629220,"Premetrics, where are they useful?","Wikipedia defines a premetric as a function $d : X\times X \to \mathbb R$ such that $d(x,y) \ge 0$ $d(x,x) = 0$. For me these axioms are so weak that I am wondering where they are used, do you know any examples? I can not find anything, and when I look for the term premetric I just found references to pseudometrics.","['metric-spaces', 'functional-analysis', 'analysis']"
629226,Notation used for integrals w.r.t. probability measures,"I was staring at one of my questions at SE and realized that I do not really understand what I mean by $dP(\omega)$ when I write: $$EX = \int_{\Omega} X(\omega) \, dP (\omega)$$ where $X: \Omega \to \mathbb{R}$ is a real-valued random variable defined on a probability space $(\Omega, \mathcal{F}, P)$. It seems $P(\omega)$ does not make much sense since $P: \mathcal{F} \to [0, 1]$. I started looking at what Durrett writes in his book, and, when it comes to integrals with respect to measures, there is no any argument next to $P$: $$EX = \int X \, dP = \int_\Omega X(\omega) \, dP.$$ Question : What does one actually mean by $dP$ in this context? If it is $P(\{ \omega \})$ then again I cannot make heads or tails of it since $P(\{ \omega \})$ is zero assuming that there are no atoms, and $\{ \omega \}$, $\forall \omega \in \Omega$, should be in $\mathcal{F}$. Thank you! Regards,
Ivan","['probability-theory', 'lebesgue-integral', 'measure-theory', 'notation']"
629248,"How do i prove that ""countably monotone + Finitely Additive"" implies ""Premeasure"" on a semiring?","Let $S$ be a semi-ring of subsets of $X$ Let $\mu:S \rightarrow [0,\infty]$ be a set function on $X$ If $\mu$ is countably monotone and finitely additive, then $\mu$ is a premeasure. I know that this must be true, since $\mu$ can be extended to $\mu^*$ on a ring generated by $S$ which is countably monotone and finitely additive. However, i don't know how to prove this directly. Help..",['measure-theory']
629250,"Show that if operator $T$ is such that $||I-T||<1$ , then $T$ is bijective.","I came across this statement in a proof and I can't figure out why its true, could someone point out why (or give a hint). Thanks. Suppose that $T:X\to X$ is a bounded linear operator that maps a Banach space $X$ to itself such that $$||I-T||<1,\quad\quad(*)$$ where $I$ denotes the identity on $X$, and the $||\cdot||$ the induced operator norm. Then $T$ is bijective. In case anyone comes across this later on here's a follow up on Karene's answer. It follows from $(*)$ that $$S_n:=\sum_{i=0}^n(I-T)^i$$ is bounded for all $n$ and that the sequence $(S_n)$ is Cauchy. Since $X$ is complete, the space of linear bounded operators on $X$ is complete as well. Thus $S_n$ tends to some linear bounded operator $S$ as $n$ tends to infinity. Then, it's easy to verify that $$(I-T)S=S-I\Rightarrow TS=I$$ and similarly to show that $ST=I$.",['functional-analysis']
629275,Geometric interpretation of derivative of a function of more than one variable,"A function $f$ is defined on an open set $D$ of $\mathbb R^{2}$ is called a differentiable at a point $x\in D$ if there is a vector $m \in \mathbb R^{2} $ such that
$$\lim_{h\to 0} \frac{f(x+h)-f(x)-m\cdot h}{|h|}=0.$$ My questions are :
(1) What is a geometric  interpretation of $f:\mathbb R^{2} \to \mathbb R$ is a differentiable at a point in $D$ ? ( Let $f:\mathbb R^{2} \to \mathbb R $such that 
$f(x, y)= \frac{x^{3}y}{x^{4}+y^{2}}$ for $(x,y)\not = (0,0)$ and $f(0,0)= 0$. Notice that all the directional derivatives of $f$ exists at $(0, 0)$  and they are equal at $(0, 0)$ but although $f$ is fails to be differentiable at $(0,0)$. ) (2) What is a geometric interpretation of $f:D\subset \mathbb R^{n}\to \mathbb R^{m}$ is differentiable at point in $D$ ?","['differential-geometry', 'multivariable-calculus', 'real-analysis']"
629276,How prove this integral equation $\int_{a}^{b}\frac{1}{\sqrt{|f(x)|}}dx=\int_{c}^{d}\frac{1}{\sqrt{|f(x)|}}dx$,"let $a>b>c>d$,and
$$f(x)=(x-a)(x-b)(x-c)(x-d)$$
show that
$$\int_{a}^{b}\dfrac{1}{\sqrt{|f(x)|}}dx=\int_{c}^{d}\dfrac{1}{\sqrt{|f(x)|}}dx$$ my try: maybe let
$$u=x+( )$$
such when $x=a,b$ then $u=c,d$? if $$a+d=b+c$$
then we take
$$y=a+d-x$$
then we have $$\int_{a}^{b}\dfrac{1}{\sqrt{|f(x)|}}dx=\int_{c}^{d}\dfrac{1}{\sqrt{|f(x)|}}dx$$ other case,
 I can't,Thank you",['integration']
629282,"the word ""derivative""","When did the word ""derivative"" come into use in calculus, and why? As in Can the word ""derive"" be used to mean ""take the derivative of""? the word ""derivative"" in normal English means ""stemming from"". But $\int f$ ""derives"" from $f$ just as much as does $f'$, and $f'$ ""integrates"" information from $f$ just as much as does $f'$. So who decided that a ratio of fluxions should be called the derivative, and why?","['calculus', 'terminology', 'math-history']"
629294,Evaluation of $ \displaystyle \lim_{x \to 0} \frac{\sin ( \pi \cos(x) )}{x \sin x}$ using a Taylor Approximation,"Compute the limit: $$ \displaystyle \lim_{x \to 0} \frac{\sin ( \pi \cos(x) )}{x \sin (x)}$$
  using a Taylor approximation It seems very intuitive for me to use a Taylor Approximation for this kind of a problem, since the values of $x$ get arbitrary small. My Approach (wrong): $$\cos (x)= 1 - \frac{x^2}{2}+O(x^4) \implies \pi \cos (x)= \pi - \frac{\pi x^2}{2}+ \dots  \\ \sin (x) = x - \frac{x^3}{6}+O(x^6)$$
My problem now is to compute $\sin ( \pi \cos (x)) $. One of my tutors once told me for small values of $x$ I can always use $\sin (x) \sim x$, so I thought that the following must be true as well for small values of $x$: $$\sin (\pi \cos (x))= \sin\left(\pi - \frac{\pi x^2}{2}+ \dots \right) \sim \pi - \frac{\pi x^2}{2}+ \dots$$ Which is indeed very wrong, the correct answer is:
$$\sin (\pi \cos (x))\sim \frac{\pi x^2}{2}\pm O(x^4)$$ While it seems clear to me that my answer cannot be true, (I did it by naively plugging in the values and obtained the same result as I already had for $\pi \cos (x)$) , I don't see how the above result is obtained. Could somebody show me how to correctly process in that manner? Note : In class we were not yet introduced to the $O$-Notation. In the book by C.T. Michaels he simply uses dots for the higher terms and says that they can be neglected. I tried to include the $O$-Notation in my question, but only with my intuitive understanding of it.","['limits', 'calculus', 'analysis']"
629295,Estimates on Derivatives,"I have trouble in filling in the details of the proof on Estimates on derivates, from page 29 of PDE Evans, 2nd edition. Namely, I am lost at some steps. The book gives: Theorem 7 (Estimates on derivatives).  Assume u is harmonic in U. Then
  \begin{align}
|D^\alpha u(x_0)| \le \frac{C_k}{r^{n+k}} \|u\|_{L^1(B(x_0,r))} \tag{18}
\end{align}
  for each ball $B(x_0,r) \subseteq U$ and each multiindex $\alpha$ of order $|\alpha| = k$. Here 
  \begin{align}
C_0 = \frac{1}{\alpha(n)}, C_k = \frac{(2^{n+1}nk)^k}{\alpha (n)} \text{ for } k=1,2,\ldots \tag{19}
\end{align} Proof. 1. We establish $(\text{18}), (\text{19})$ by induction on $k$, with the case $k=0$ being immediate from the mean value formula $u(x) = \frac{1}{\alpha(n)r^n} \int_{B(x_0,r)} u \, dx = \frac{1}{\alpha(n)r^{n-1}} \int_{\partial B(x,r)} u \, dS$ (which denote average values of $u$ over the ball and sphere, respectively). For $k = 1$, we note upon differentiating Laplace's equation that $u_{x_i}$ (for $i=1,...n$) is harmonic. Consequently, \begin{align}
\left|u_{x_i}(x_0)\right| &= \left|\frac{1}{\alpha(n) (\frac{r}{2})^n} \int_{B(x_0,\frac{r}{2})} u_{x_i} dx\right| \tag{20} \\
&= \left|\frac{2^n}{\alpha(n) r^n} \int_{B(x_0,\frac{r}{2})} u_{x_i} dx\right| \\
&= \left|\frac{2^n}{\alpha(n) r^n} \int_{\partial B(x_0,\frac{r}{2})} u \nu_i dS\right| \\
&\le \frac{2n}{r} \|u\|_{L^\infty(\partial B(x_0,\frac{r}{2})}
\end{align} Now if $x \in \partial B(x_0,\frac{r}{2})$, then $B(x,\frac{r}{2}) \subseteq B(x_0,r) \subseteq U$, and so
  \begin{align}
|u(x)| \le \frac{1}{\alpha(n)} \left(\frac{2}{r}\right)^n \|u\|_{L^1(B(x_0,r))}
\end{align}
  by (18), (19) for $k=0$. Combining the inequalities above, we get
  \begin{align}|D^\alpha u(x_0)| &\le \frac{2^{n+1}n}{\alpha(n)} \frac{1}{r^{n+1}} \|u\|_{L^1(B(x_0,r))} \\
&= \frac{2^{n+1}n}{r^{n+1}} \|u\|_{L^1(B(x_0,r))} \\
\end{align}
  if $|\alpha| = 1$. This verifies $(\text{18})$ and $(\text{19})$ for $k = 1$. (There is a second part of this proof for $k \ge 2$, but I think I can understand that on my own, once I fully understand $k=1$.) I had major trouble understanding all the steps that involve inequalities (with the $\le$), though I completely understand the equality steps (=). May I seek help in understanding how these inequalities are obtained and how they are true? (I think Evans likes to skip a lot of steps...) $\displaystyle \left|\frac{2^n}{\alpha(n) r^n} \int_{\partial B(x_0,\frac{r}{2})} u \nu_i dS \right| \le \frac{2n}{r} \|u\|_{L^\infty(\partial B(x_0,\frac{r}{2})}$ $\displaystyle |u(x)| \le \frac{1}{\alpha(n)} \left(\frac{2}{r}\right)^n \|u\|_{L^1(B(x_0,r))}$ $\displaystyle |D^\alpha u(x_0)| \le \frac{2^{n+1}n}{\alpha(n)} \frac{1}{r^{n+1}} \|u\|_{L^1(B(x_0,r))}$ I would love to show my work attempt in filling in the details for these relations, but they are a mess and probably won't be helpful here. But hopefully what's given above will suffice. (As far as only equalities are concerned, I tried to add a little more detail to the steps in the above proof than what is originally presented by the textbook.)","['harmonic-functions', 'partial-differential-equations', 'analysis']"
629340,Question on connected graphs,Is it true that if for each partition of a graph G's vertices into two non empty sets there is an edge with end points in both sides then G is connected? Intuitively this seems true to me. But I cannot prove this. I would very much appreciate some assistance. Thanks,"['graph-theory', 'discrete-mathematics', 'combinatorics']"
629347,What is the dot product and why do we need it?,"I understand how to calculate the dot product of the vectors. But I don't actually understand what a dot product is, and why it's needed. Could you answer these questions?",['geometry']
629364,How to show the monotonicity of $\frac{1+ny}{1-y^{n+1}}-\frac{1}{1-y}$?,"The question is to prove that $\dfrac{1+ny}{1-y^{n+1}}-\dfrac{1}{1-y}$ is a decreasing function in $y$ for $y>1$, where $n$ is a positive integer. My first thought is to take the derivative and show the sign is negative. But it seems the derivative is a bit complicate to easily draw the conclusion.  Any other thoughts/hints/comments?   Thanks a lot.",['derivatives']
629380,Understanding Euler's Identity,"I would like to understand one specific moment in Euler's Identity, namely $$e^{j\theta}=\cos(\theta)+j\sin(\theta)$$ where $j=\sqrt{-1}$. We also know that $$e^{j2(\pi)}=\cos(2\pi)+j\sin(2\pi)$$ but  $\sin(2\pi)=0$  and  $\cos(2\pi)=1$, and $1=e^{0}$, so we get that  $e^{j2(\pi)}=e^{0}$. But we get that $j2\pi=0$ which means that $j=0$, but on the other hand $j=\sqrt{-1}$. I want to ask one question: why is it allowed to use such symbols in identity, which finally may cause some strange equality?","['trigonometry', 'complex-numbers']"
629388,How to project a polygon on an axis.,"I'm trying to learn the Separating Axis Theorem, for my programming. I'm making a simple 2D game an I need this as a way to detect wether two polygons are intersecting. Problem is, I suck at math. So far, I understand that in order to know if two polygon are intersecting, I need to do the following: Creata a perpendicular line to every edge of the two polygons. Project each polygon to each of the new lines created (the axes). If all projections of the first polygon overlap all projections of the second polygon, the shapes intersect. Else, the shapes do not intersect. I know how to do step 1. But I don't understand how to perform step two. Can you explain to me how to project a polygon onto an axis, in a language that a person with pretty basic knowledge at math will be able to understand? Thanks a lot",['geometry']
629404,Probability the three points on a circle will be on the same semi-circle [duplicate],"This question already has answers here : Probability that n points on a circle are in one semicircle (6 answers) Closed 4 years ago . Three points are chosen at random on a circle. What is the probability that they are on the same semi circle? If I have two portions $x$ and $y$, then $x+y= \pi r$...if the projected angles are $c_1$ and $c_2$. then it will imply that $c_1+c_2=\pi$...I have assumed uniform distribtuion so that $f(c_1)=\frac{\pi}{2}$...to calculate $P(c_1+c_2= \pi)$ I have integrated $c_2$ from $0$ to $\pi-c_1$ and $c_1$ from $0$ to $\pi$..but not arriving at the answer of $\frac 3 4$","['uniform-distribution', 'probability']"
629406,How can we compute the multiplicative partition function,"Please how can we compute the multiplicative partition function. For example $24$, has precisely $6$ valid factorizations: $2\cdot2\cdot2\cdot3$, $2\cdot2\cdot6$, $2\cdot3\cdot4$, $2\cdot12$, $3\cdot8$, and $4\cdot6$.",['number-theory']
629407,Proving $a\le f(a)$ for a monotonically increasing function on a well-ordered set,"Let $(x,\le)$ be well-ordered set and let $f: \ x \rightarrow x$ be monotonically increasing function. Prove that $\forall a \in x$ $$a \le f(a)$$ Find an example of set $x$ linearly ordered such that the statement doesn't hold. My try: Assume $X=\{a \in x \ : \ a \ge f(a) \}$ is non-empty set with a minimal element S (we can assume that there is such element, because the set is well ordered). According to the definition of set $X$ we know that $S\ge f(S)$ , but $f(S)$ is in X, thus we found an element smaller than S and that is contradiction. It seems too easy and I made no use of monotone characteristic of the function. I have no idea of how to find proper example and what I need to do to complete the proof. Please help, thank you!","['well-orders', 'examples-counterexamples', 'ordinals', 'elementary-set-theory', 'functions']"
629413,"Is $x_n =\sqrt{n} (\sqrt{n+1}− \sqrt{n})$ , $n \ge 1$ convergent?","$$x_n =\sqrt{n} (\sqrt{n+1}− \sqrt{n}) ,\quad n \ge 1$$ My work is: First i analyzed the convergence of this sequence in 2 parts: a) $\lim \sqrt{n+1}− \sqrt{n} = \lim \frac{(\sqrt{n+1}− \sqrt{n})(\sqrt{n+1}+\sqrt{n})}{\sqrt{n+1}+\sqrt{n}} = \lim \frac{n+1-n}{\sqrt{n+1}+\sqrt{n}} = \lim \frac{1}{ \infty} = 0$ when $n  \rightarrow \infty$. But now how can I conclude that $\lim_{n  \rightarrow \infty}x_n = 0$","['sequences-and-series', 'convergence-divergence', 'calculus', 'limits']"
629418,A property of $I$-adic topologies,"Let $R$ be a commutative ring with multiplicative identity and $I$ a proper ideal of $R$ such that the intersection of its powers is the zero ideal. It can be shown that if the $I$-adic topology is complete, then $I$ is included in the Jacobson radical $J(R)$. Is the converse true, i.e., if $I$ is included in $J(R)$, is the $I$-adic topology complete?","['general-topology', 'commutative-algebra', 'ring-theory', 'ideals']"
629419,Please explain to me why the Expected Value is $ E[X] = \int_{-\infty}^{\infty} x f_X(x) dx $,"For probability density functions (at least for the normal distribution and beta distribution) it holds that the expected value is given by $ E[X] = \int_{-\infty}^{\infty} x f_X(x) \, dx $. I have to solve this for a homework for the beta distribution. Finding a solution on the internet wasn't that hard but I wouldn't mind understanding this calculation. I'd like to know first why $ f_X(x) $ is multiplied by $ x $. The same thing is done if the variance gets calculated - but in this case the function gets multiplied by $ x^2 $. So why is this the case? The other thing is that I don't even understand why this function gets integrated and not derived e.g.? Could anyone explain this to me? I am not looking for a solution, just an explaination. Thank you.","['probability-distributions', 'probability', 'integration']"
629488,Set Theory - Well Order (Lexiographical combination),"Question: Prove constructively that if $(A_{1},\prec_{1})$ and $(A_{2},\prec_{2})$ are two well-ordered sets then their lexicographical combination $(A_{1} \times A_{2},<_{1,2})$ is also well ordered. I have tried to spell out all the things I think are necessary to prove the desired result constructively, namely: If $(A_{1},\prec_{1})$ and $(A_{2},\prec_{2})$ are two sets with relations, then we can form the juxtaposition of these $(A_{1} \times A_{2}, \prec_{1,2})$
\begin{equation}
(a,b) \prec_{1,2} (c,d) \iff a \prec_{1} c \lor I(A_{1},a,c) \land b \prec_{2} d
\end{equation}
where we define
\begin{align}
&inl(a) \prec_{1,2} inl(b) \iff a \prec_{1} b
\\ &inl(a) \prec_{1,2} inr(b) \iff \top
\\ &inr(b) \prec_{1,2} inl(a) \iff \bot
\\ &inr(a) \prec_{1,2} inr(b) \iff a \prec_{2} b
\end{align} Now, by definition, a well-order means that we have a well founded linear order; which is to say that for every progressive predicate $P$ on A, $(\forall x:A)P(x)$ and $x \prec_{1} y \lor x=_{1}y \lor y \prec_{1} x$. However, I struggle to connect find a brief, sound and constructive argument that will answer the question. That is why I humble I ask this forum for help, hoping someone more enlighten may guide me to greater understanding. Thanks!","['order-theory', 'self-learning', 'elementary-set-theory', 'type-theory', 'constructive-mathematics']"
629495,Intuition behind the residue at infinity [duplicate],"This question already has an answer here : The residue at $\infty$ (1 answer) Closed 10 years ago . The residue at infinity is given by: $$\underset{z_0=\infty}{\operatorname{Res}}f(z)=\frac{1}{2\pi i}\int_{C_0} f(z)dz$$ Where $f$ is an analytic function except at finite number of singular points and $C_0$ is a closed countour so all singular points lie inside it. It can be proven that the residue at infinity can be computed calculating the residue at zero. $$\underset{z_0=\infty}{\operatorname{Res}}f(z)=\underset{z_0=0}{\operatorname{Res}}\frac{-1}{z^2}f\left(\frac{1}{z}\right)$$ The proof is just to expand $-\frac{1}{z^2}f\left(\frac{1}{z}\right)$ as a Laurent series and to see that the $1/z$ is the integral mentioned. I can see that we change $f(z)$ to $f(1/z)$ so the variable tends to infinity. But, is there any intutive reason of why we introduce the $-1/z^2$ factor?","['residue-calculus', 'intuition', 'complex-analysis']"
629500,Non second countable space which has limit point not expressable as the limit of a sequence,"Theorem: If a topological space $(X, \tau)$ has a countable base (2nd countable), then for every $Y \subseteq X$ its closure $cl(Y)$ is the set of limit points of sequences $(x_j)_{j\in \mathbb N}$ where $x_j \in Y$ for all $j \in \mathbb N$. Now I wanted to find a ""non-example"" for this Theorem, namely a not second countable space with a subset $Y$ who has a limit point that could not be expressed as the limit point of a sequence in $Y$. i) For an uncountable $X$, the co-finite topology
$$
 \tau = \{ A \subseteq X : A = \emptyset \mbox{ or } A^C \mbox{ is finite } \}
$$
is not second-countable. In this topology each finite set has no limit points, and each infinite set is dense, i.e. every point of $X$ is a limit point. So if $Y \subseteq X$ is infinte we can select some $\{ x_i \} \subseteq Y$ which is infnite, and this sequence will converge to every point of $X$, i.e. to each limit point of $Y$. For if $x \in X$ and $U$ is some open set containing $x$, then $U^C$ is finite, and so for some $N$ all $x_i$ with $i > N$ must lie in $U$.
So this example is not working. ii) The discrete topology for uncountable $X$ is not second countable, but because each point is isolated it has no limit points. So these two ""non-examples"" would not work, do you know a not second countable space who has a subset containing a limit point which is not the limit point of a sequence in that set?","['general-topology', 'analysis']"
629531,How to find the limit $\lim_{x \to 0}\sin(x)^{2\sin(x)}$,"I can't find the following limit:
$$\lim_{x \to 0}\sin(x)^{2\sin(x)}$$
My attempt : Let $y =\sin(x)^{2\sin(x)}$. Then we take the natural logarithm of this expression:
$$y=\sin(x)^{2\sin(x)}$$
$$\ln(y) = 2\sin(x)\cdot \ln(\sin(x))$$ $$y=e^{2\sin(x)\cdot \ln(\sin(x))}$$
Then we put this in limit
$$\lim_{x \to 0}\sin(x)^{2\sin(x)}= \lim_{x \to 0}(e^{2\sin(x)\cdot \ln(\sin(x))})=e^{0\cdot (-\infty)}=e^0=1$$
I want to know whether it is correct.","['real-analysis', 'limits']"
629539,Sesquilinear Forms: Reals,"Given a real Hilbert space $\mathcal{H}$. Consider symmetric forms:
$$s:\mathcal{H}\times\mathcal{H}\to\mathbb{R}:\quad s(\psi,\varphi)=s(\varphi,\psi)$$ By polarization one obtains:
$$s(\varphi,\psi)=\frac{1}{4}\{s(\varphi+\psi,\varphi+\psi)-s(\varphi-\psi,\varphi-\psi)\}$$ Consider arbitrary forms:
$$s:\mathcal{H}\times\mathcal{H}\to\mathbb{R}:\quad s(\psi,\varphi)\neq s(\varphi,\psi)$$ Can one reconstruct them?","['vector-spaces', 'sesquilinear-forms', 'linear-algebra', 'hilbert-spaces', 'functional-analysis']"
629551,Conservation Law for Heat Equation on Infinite Domain,"Let $$ u_{t}(x,t) = \Delta u(x,t) \space \space \space \text{ for } \space t \ge 0 \space \space\space\space , \space x \in \mathbb{R}^{n} $$ and $$ u \rightarrow 0 \space \text{ as }  \space ||x|| \rightarrow \infty $$ Show $$I(t) =  \int_{\mathbb{R}^{n}} {u(x,t) } dx = constant $$ What i have attempted so far is to apply Lipschitz and the Divergence Theorem on a finite sphere and then try and show the limit comes out as zero. This works up until the limit part, then i get a bit  stuck. Maybe i'm missing something obvious. thanks for any hints/advice you can provide! EDIT: very grateful for the solutions you provided","['multivariable-calculus', 'heat-equation', 'integration', 'partial-differential-equations']"
629628,Let $f_n$ and $f$ be in $L^1$. We wish to show $f_n \rightarrow f$ in $L^1$.,"Let $f_n$ and $f$ be in $L^1$. We wish to show $f_n \rightarrow f$ in $L^1$. Question: Does it follow that $\int |f_n - f| \,d\mu \rightarrow 0$ if it is true for all measurable sets $E$ that $\int_E f_n \rightarrow \int_E f$. Note that $f_n, f$ are in $L^1$. The converse of this question is easy.  We are trying to prove this direction.",['measure-theory']
629630,Simple proof Euler–Mascheroni $\gamma$ constant,I'm searching for a really simple and beautiful proof that the sequence $(u_n)_{n \in \mathbb{N}} = \displaystyle\sum_{k=1}^n \frac{1}{k} - \log(n)$ converges. At first I want to know if my answer is OK. My try: $\lim\limits_{n\to\infty} \left(\sum\limits_{k=1}^n \frac{1}{k} - \log (n)\right) = \lim\limits_{n\to\infty} \left(\sum\limits_{k=1}^n \frac{1}{k} + \sum\limits_{k=1}^{n-1} [\log(k)-\log(k+1)]\right)$ $ = \lim\limits_{n\to\infty} \left(\frac{1}{n} + \sum\limits_{k=1}^{n-1} \left[\log(\frac{k}{k+1})+\frac{1}{k}\right]\right) = \sum\limits_{k=1}^{\infty} \left[\frac{1}{k}-\log(\frac{k+1}{k})\right]$ Now we prove that the last sum converges by the comparison test: $\frac{1}{k}-\log(\frac{k+1}{k}) < \frac{1}{k^2} \Leftrightarrow k<k^2\log(\frac{k+1}{k})+1$ which surely holds for $k\geqslant 1$ As $ \sum\limits_{k=1}^{\infty} \frac{1}{k^2}$ converges $ \Rightarrow \sum\limits_{k=1}^{\infty} \left[\frac{1}{k}-\log(\frac{k+1}{k})\right]$ converges and we name this limit $\gamma$ q.e.d,"['euler-mascheroni-constant', 'harmonic-numbers', 'logarithms', 'limits']"
629644,Localization of an integral domain and fields of fractions,"Is it true that every localization of an integral domain is isomorphic to a subring of its field of fractions? How are the localizations of an integral domain related to its field of fractions? Is there a handy criterion to tell whether a subring of an integral domain has the same field of fractions as the overring? I've read that $k[x^2,x^3]\subset k[x]$ ($k$ a field, algebraically closed if this matters) have the same field of fractions, how come? I am very curious about these things.","['commutative-algebra', 'ring-theory', 'abstract-algebra']"
629678,Continuation from here...,p.s I have no idea how to type math on this program so I just copied and pasted from a document. p.p.s I also tried doing it with log base a and that was a travesty. This was my best attempt because it was the nicest looking,['algebra-precalculus']
629682,A bounded function and lebesgue measurable sets.,"Let $f : [0, 1] \to {\mathbf R}$ be bounded. (a) Show that the set where $f$ is continuous is Lebesgue measurable (even
if $f$ is not Lebesgue measurable). (b) Show that if $f$ is not continuous on a set of full Lebesgue measure,
then $f$ is not Riemann integrable. This is a old prelim question, which I have no idea how to start.  Any suggestions would be appreciated.","['measure-theory', 'lebesgue-measure']"
629707,How should I think about Ihara's Lemma?,"I am trying to learn about Ihara's lemma because I see it mentioned in many papers in arithmetic geometry. To be more precise, I would like to know: What is the significance of this result? Why is it so powerful? Intuitively, how should I think about it? Why should I believe it? I have seen at least two formulations of the lemma. The original result is formulated using Jacobians. In Darmon-Diamond-Taylor's paper on Fermat's Last Theorem, it is formulated using cohomology. Why are the two equivalent? I see that there are many generalizations of the results. What are the latest state of art? Thank you very much in advance!","['arithmetic-geometry', 'modular-forms', 'algebraic-geometry', 'algebraic-number-theory']"
629725,Why does raising group elements to the power of the order of the group yield the identity?,"Does someone know the why raising the element of a group to the power of the order of the group yields the identity? By (finite) group I mean a tuple (G,*) that satisfies the following: closure under operation * associative under operation * has identity element has inverse I was unsure why: $$
a^{|G|} = I
$$ [I am aware that its a basic fact but I was unable to find the proof online [don't know the name of the theorem]). I wanted to try to prove it myself, but I was not sure how to because, the statement of the theorem does not seem to state anything about what is allowed to be an element of the group and what isn't allowed, does it only apply to integers? What is allowed to be an element of the group (binary strings?)? Also, I was not sure what a raised to the order meant, because, the group might not have ""multiplication"" defined, maybe it has its own way of doing stuff to its elements, so I didn't know what raising it to the power of meant. Does it mean using operation * |G| times? 
Does this only apply to cyclic groups? I usually post my (failed) attempts to solve the question first but I was not sure how to start proving anything because I was not sure what the elements of the group were allowed to be or what the raising meant with respect to operations on the elements of the group. Can anyone state the name of the theorem?","['elementary-number-theory', 'group-theory']"
629736,Number of subgroups of order 48 in $\mathbb{Z}_{8} \oplus\mathbb{Z}_{12}$,"I thought it would have sufficed to show that every subgroup of G=$\mathbb{Z}_{8} \oplus\mathbb{Z}_{12}$ must be formed by couples (a,b) whose set of a's and the set b's form a subgroup of $\mathbb{Z}_{8}$ and $\mathbb{Z}_{12}$ respectively.
By this way of reasoning I should find 2 subgroups one generated by $\mathbb{Z}_{8} \oplus\mathbb{Z}_{6}$ and by $\mathbb{Z}_{4} \oplus\mathbb{Z}_{12}$.
But I am wrong since I'm am missing one. I can't figure out how can I concretely generate that one. Where am I wrong? Thanks in advance.","['arithmetic', 'finite-groups', 'group-theory']"
629740,How would you explain to a 9th grader the negative exponent rule?,"Let us assume that the students haven't been exposed to these two rules: $a^{x+y} = a^{x}a^{y}$ and $\frac{a^x}{a^y} = a^{x-y}$. They have just been introduced to the generalization: $a^{-x} = \frac{1}{a^x}$ from the pattern method: $2^2 = 4, 2^1 = 2, 2^0 = 1, 2^{-1} = \frac{1}{2}$ etc. However, some students confuse $2^{-3}$ to be $(-2)(-2)(-2)$ since they are familiar with $2^{3} = 2 \cdot 2 \cdot 2$. This is a low-income urban school and most kids in this algebra class struggle with math dealing with exponents, fractions and decimals. What would be the best approach to reach all 32 students?","['education', 'algebra-precalculus']"
629751,Trigonometry or inequality problem,"Today, I saw this question: If $x,y,z \in [0,\frac\pi 2]$ , $x+y+z=\frac{3\pi}{4}$ and $\sec^2(x)\sec^2(y)\sec^2(z)=8$ , calculate $E=\tan x\tan y+\tan y\tan z+\tan z\tan x$ My first thought was getting everything in term of $\tan$ , and everything went as expected. Let $a=\tan x, b=\tan y, c= \tan z$ . Then, after playing with the equations I got: $$x+y+z=\frac{3\pi}{4}$$ $$\implies 1+a+b+c=ab+bc+ac+abc \tag1$$ And since $\tan^2x+1=\sec^2x$ , by AM-GM we have $$8=(1+a^2)(1+b^2)(1+c^2)\ge 8abc$$ $$\implies 1 \ge abc$$ So now I want to show that $$(1+a^2)(1+b^2)(1+c^2)=8 \implies a+b+c\ge ab+bc+ac$$ in order to show that $LHS\ge RHS$ , so that they only achieve equality when $a=b=c=1$ . Wolfram confirms that it is possible to do so , but I have not managed to prove it. Edit: A solution to the problem From $(1)$ , we know: $$a=\frac{(b+c)+(1-bc)}{(b+c)-(1-bc)}$$ Substituting $u=b+c$ , $v=1-bc$ , we have that $u^2+v^2=(1+b^2)(1+c^2)$ (A special case of the Brahmagupta-Fibonacci identity). Therefore $$1+a^2=2\frac{u^2+v^2}{(u-v)^2}=2\frac{(1+b^2)(1+c^2)}{(u-v)^2}=\frac{8}{(1+b^2)(1+c^2)}$$ Since $x\le \frac{\pi}{2}$ , we have that $y+z\ge \frac{\pi}{4}\implies \tan(y+z)=\frac{u}{v}\ge1$ . Therefore, $u-v\ge 0$ , and we can safely take the square root without losing solutions. $$\implies (1+b^2)(1+c^2)=2(u-v)$$ $$\implies (1+b^2)(1+c^2)=2(b+c+bc-1)$$ $$\implies 1+b^2+c^2+b^2c^2=2b+2c+2bc-2$$ $$\implies (b-1)^2+(c-1)^2+(bc-1)^2=0$$ $\implies a=b=c=1, \implies E=3$ But that last inequality I pointed still intrigue me. Can we prove it with elementary methods? Also, is there a simple solution to the problem?","['inequality', 'trigonometry', 'algebra-precalculus']"
629759,Anyone has a good recommendation of a free pdf book on group theory?,"Anyone has a good recommendation of a free pdf book on group theory? I am specially interested in its application for computer science, however, I do not want it to be less mathematically rigorous just because of that. I found one that was good, but it only dealt with commutative groups throught the text :(","['reference-request', 'book-recommendation', 'group-theory', 'online-resources']"
629768,"Show that $\max_{x\in[a,b]}|f'(x)|\geq\frac{4}{(b-a)^2}\int_a^b|f(x)|dx$ [duplicate]","This question already has answers here : Prove that $|f''(\xi)|\geqslant\frac{4|f(a)-f(b)|}{(b-a)^2}$ (2 answers) Closed 10 years ago . Let $f:[a,b]\to\mathbb{R}$ be differentiable and $f'$ is continuous. Suppose $f(a)=f(b)=0$, show that $$\max_{x\in[a,b]}|f'(x)|\geq\frac{4}{(b-a)^2}\int_a^b|f(x)|dx$$ My approach. For any $x$, by Taylor's theorem there is $\xi\in(a,x)$ s.t. $$|f(x)|=|f(a)+f'(\xi)(x-a)|\leq\max_{x\in[a,b]}|f'(x)|(x-a)$$ Hence $$\int_a^b |f(x)|dx\leq\max_{x\in[a,b]}|f'(x)|\int_a^bx-adx=\frac{(b-a)^2}{2}\max_{x\in[a,b]}|f'(x)|$$ I can only get this, and I don't know how to obtain $\frac{(b-a)^2}{4}$.","['calculus', 'real-analysis']"
629779,harder expected value probability question,"I have a question on expected value. I have the solutions for it but they havent explained exactly what they have done, and i am a bit confused whilst revising for an exam in a few days. Here is the question Suppose 2 teams, A and B, play a series of games that ends when one of them has won 2 games. Suppose that each play is, independently won by player A with probability $p$ Find the expected # of games. So we want to find the expected number of games before one of them wins. I can usually do these types of questions with probability $p$ and $q=(1-p)$ but just not exactly sure why and how for this particular question Solution Let $X$ denote the total # of games played. then for one of the teams to win twice, $X$ can take values in ${2,3}$, and $$EX=2 \times (p^{2}+(1-p)^{2})+3 \times(2p(1-p)^{2} + 2p^{2}(1-p))$$
$$=2p(1-p)+2$$ So what i really want to know is how they have decided the $p's$ and $q=1-p$'s I know there is independence here, so i know that has something to do with it. Please could someone explain exactly how this works so i can master this! Many thanks","['probability-theory', 'probability']"
629781,Is Fourier transform of a $L^{1}$ integrable function is $L^{1}$ integrable?,"Let $f:\mathbb R \to \mathbb R$ such that 
$$f(x)= \frac{\sin \pi x}{x (x^{2}-1)}$$ for $x\in \mathbb R - \{ 0, -1, 1 \}$ and $f(x):= \pi $ for $x=0$ and $f(x)=-\frac{\pi}{2}$ for $x= -1, 1$. Let $g:\mathbb R \to \mathbb R$ such that 
$$g(x): = |f(x)|.$$ As $g\in L^{1}(\mathbb R)$, we get $\hat{g} \in C_{0}(\mathbb R)$. My questions are : 
(1) Can we compute the Fourier transform of $g$ ?
(2) Is it true that $\int_{\mathbb R} |\hat {g} (\xi)| d\xi = \infty  $, that is,  $\hat{g} \notin L^{1} (\mathbb R)$ ? Fourier transform of $f$ : By complex analysis method one can compute the Fourier transform of  cardinal sine function or sinc function : 
 $$\int_ {\mathbb R}\frac{\sin (ax)}{ax} e^{-2\pi i x \xi} dx = \frac{\pi}{a}; (|\xi|\leq \frac{a}{2\pi}); (*).$$ Note that,
$$\frac{\sin (\pi x )}{x (1-x^{2})}= \pi \frac{\sin (\pi x)}{\pi x }+ \frac{\pi}{2} \frac{\sin (\pi (x+1))}{\pi (x+1)}+\frac{\pi}{2}\frac{\sin (\pi (x-1))}{\pi (x-1))} .$$ We define $f_{1}:\mathbb R \to \mathbb R$ such that $f_{1}(x)= \frac{\sin (\pi x)}{\pi x}$ for $x\not = 0$ and f(0)=1. Also we define, $f_{1}, f_{2}:\mathbb R \to \mathbb R$ such that $f_{1}(x):= f(x+1)$ and $f_{2}(x):= f(x-1)$. By  $(*)$ we get, $$ \hat{f_{1}(\xi)}=\begin{cases}
1 & \text{if}  \ |\xi| < \frac{1}{2},\\
\frac{1}{2} & \text{if} \ |\xi| = \frac{1}{2}, \\
0, & \textbf{if} \  |\xi|> \frac{1}{2}.
\end {cases}$$ By translation property of Fourier transform we get, 
$$ \hat{f_{2}(\xi)}=\begin{cases}
e^{2\pi i \xi} & \text{if}  \ |\xi| < \frac{1}{2},\\
\frac{e^{2\pi i \xi}}{2} & \text{if} \ |\xi| = \frac{1}{2}, \\
0, & \text {if} \  |\xi|> \frac{1}{2};
\end {cases}$$
and
$$ \hat{f_{3}(\xi)}=\begin{cases}
e^{-2\pi i \xi} & \text{if}  \ |\xi| < \frac{1}{2},\\
\frac{e^{-2\pi i \xi}}{2} & \text{if} \ |\xi| = \frac{1}{2}, \\
0, & \text {if} \  |\xi|> \frac{1}{2}.
\end {cases}$$ Now, by using the linearity of the Fourier transform, we get,
$\hat{f}(\xi)= \pi \hat{f}_{1}(\xi)+ \frac{\pi}{2}\hat{f}_{2}(\xi	) + \frac{\pi}{2} \hat{f}_{3}(\xi);$
next by putting above values, 
$$ \hat{f(\xi)}=\begin{cases}
\pi (1 + \cos (2 \pi  \xi)) & \text{if}  \ |\xi| < \frac{1}{2},\\
0, & \text {if} \  |\xi|\ge \frac{1}{2}.
\end {cases}$$ Clearly, $\hat{f} \in L^{1} (\mathbb R)$. Fourier transform of $|\frac{\sin x}{x}|$ : Fourier transform of $\left|\frac{\sin x}{x}\right|$ Thanks to Math fraternity;-)","['harmonic-analysis', 'fourier-analysis', 'complex-analysis']"
629800,Cannot follow proof that between two reals there is a rational.,"I am following a textbook and as is good practice, I am only skipping things I can do. this is self-learning I always struggle with chapter 1, the one that builds the ""axioms"", hate it. Anyway, I am struggling to follow some proofs, and it's supposed to not require the application of later things. There are two parts, firstly: a) if $x,y\in\mathbb{R}$ and $x>0$ then $\exists$ a positive integer $n$ such that $nx>y$ b) if $x,y\in\mathbb{R}$ and $x<y$ then there $\exists$ a $p\in\mathbb{Q}$ such that $x<p<y$ Both things I can do, but not the way it is laid out. Part A For part a) it goes as follows: (I follow this one) Let $A$ be the set of all $nx$ (I would have used a sequence.... but it's not a huge problem) if a) were false (negating yields: $\forall n,\ nx\le y$ ) then y is an upper bound. Then $A$ has a least upper bound in $\mathbb{R}$. I am happy with this. Let $\alpha = \sup(A)$, since $x>0,\ \alpha-x<\alpha$ and $\alpha-x$ is not an upper bound of $A$ - a little confused here with the since part,I don't see how since $x>0$ $\alpha-x$ is not an upper bound. I agree with the conclusion though. This is why I would have used a sequence, I'm not sure how to show $\alpha-x$ is not a lower bound with the equipment to hand. But I am happy with the process. Here's where the author looses me: Hence $\alpha-x<mx$ for some positive integer m Then I am happy again: but then $\alpha<mx+x=(m+1)x$ which is a contradiction that $\alpha$ is an upper bound. Part B Since $x<y$ we have $y-x>0$ and using a) we can furnish ourselves with a positive integer, $n$, such that $n(y-x)>1$ (I am happy with this, the 1 is the ""y"" from part a)) Apply a) again to obtain positive integers $m_1$ and $m_2$ such that $m_1>nx$ and $m_2>-nx$ okay,in this case ""x"" is 1 (from part a) and ""y"" is nx, so I am happy with this. I'm also happy with orders, so $-m_2<nx<m_1$ Here is where I get lost. Hence there is an integer $m$ (with $-m_2\le m\le m_1$) such that $m-1\le nx<m$ I'm not sure why it says ""hence"" nor what has been applied here. If we combine these inequalities we obtain $nx<m\le 1+nx<ny$ Since n > 0 it follows that $x<\frac{m}{n}<y$ this proves b) with $p=\frac{m}{n}$ I ""sort of"" see it, in that $-m_2<m_1$ and as they're integers.... but I wouldn't say I am confident in it. Nor do I see why. Hence usually means ""thus we can get to"" and I'm uncomfortable because I cannot see how one can think to do this given what's at hand, which is why I am doing the chapter, I should be able to think for myself, rather than recall proofs Addendum Thinking about it, $-m_2<nx<m_1$ is useful, as the set $\{-m_2,-m_2+1,-m_2+2,...,m_1-1,m_1\}$ is finite. not quite sure how to use this though.","['real-numbers', 'real-analysis']"
629852,Heat equation and semigroup theory.,"Theorem: Let $X$ be a Banach space, $\{T(t)\}_{t\geq 0}$ a $C_0$ -semigroup on $X$ and $U_0\in D(A)$ . If $A:D(A)\subset X\to X$ is the infinitesimal generator of $\{T(t)\}_{t\geq0}$ , then the function $U:[0,\infty)\to X$ given by $U(t)=T(t)U_0$ is a solution of $(1)$ . $$\left\{\begin{align*}
U_t(t)=AU(t);&~~~~t\in[0,\infty)\\
U(0)=U_0&
\end{align*}\right.\tag{1}$$ Now consider the problem $$\left\{\begin{align*}
y_t(x,t)=y_{xx}(x,t);&~~~~&&x\in\mathbb{R};\;t\in[0,\infty)\\
~y(x,0)=f(x);&&&x\in\mathbb{R}
\end{align*}\right.\tag{2}$$ where $y_{xx}$ is the weak derivative of second order of $y$ . By theorem above, it's possible to show that $(2)$ has a solution. So, could someone explain me (with some details) how can we rewrite $(2)$ in order to get a equivalent system, analogous to $(1)$ ? The solution that I saw just says that it's enough to show that the operator $A:H^2(\mathbb{R})\to L^2(\mathbb{R})$ defined by $A(y)=y_{xx}$ is a infinitesimal generator of a $C_0$ -semigroup on $L^2(\mathbb{R})$ (for this, the Hille-Yosida theorem is used however my question is not about the application of the Hille-Yosida Theorem. I need help to understand how to transform the original system in a system like $(1)$ and why the existence of a solution for $(1)$ implies the exitece of a solution for the original system ). Thanks.","['semigroup-of-operators', 'heat-equation', 'functional-analysis', 'partial-differential-equations']"
629874,Evaluate: $ \sum _ {k=1}^{n}{\frac{k}{n}\binom{n}{k}t^k(1-t)^{n-k}}$,"Evaluate: $$ \sum _ {k=1}^{n}{\frac{k}{n}\dbinom{n}{k}t^k(1-t)^{n-k}} $$ $\dbinom{n}{k}$stands for the usual binomial coefficient giving the number of
ways of choosing $k$ objects from n objects. Totally stuck.How can I able to solve this?","['binomial-coefficients', 'number-theory']"
629892,Determinant of a special $n\times n$ matrix [duplicate],"This question already has answers here : Determinant of a rank $1$ update of a scalar matrix, or characteristic polynomial of a rank $1$ matrix (2 answers) Closed 9 years ago . Compute the determinant of the nun matrix:
$$
\begin{pmatrix}
2 &  1  & \ldots & 1 \\
1  &  2 & \ldots & 1\\
\vdots & \vdots & \ddots & \vdots\\
1  &   1       &\ldots & 2
\end{pmatrix}
$$ For $n=2$, I have$$
\begin{pmatrix}
2 &  1   \\
1  &  2 
\end{pmatrix}
$$ Then $det = 3$. For $n=3$, we have
$$
\begin{pmatrix}
2 &  1 & 1\\
1  &  2 & 1\\
1 & 1 & 2 \\
\end{pmatrix}
$$ Then $det = 4$. For $n=4$ again we have $$
\begin{pmatrix}
2 &  1  & 1 & 1 \\
1  &  2 & 1 & 1\\
1 & 1 & 2 & 1\\
1  &   1  & 1 & 2
\end{pmatrix}
$$
Then $det = 5$ How can I prove that the determinant of nun matrix is $n+1$.","['matrices', 'linear-algebra', 'determinant']"
629899,How to solve this infinite set of equations?,"If I can find a solution to the following set of equations then, with a bit of luck, I should be able to derive all sorts of nifty new results in non-equilibrium statistical mechanics. However, I'm not sure if there is a general solution. The equations are as follows. There is one equation for every $k \in \mathbb{Z}^\star$ (the positive ingtegers). 
$$
e^{-\eta_k}\sum_{j=0}^\infty e^{\eta_j-\lambda f_{kj}} = e^{\eta_k}\sum_{i=0}^\infty e^{-\eta_i-\lambda f_{ik}}. 
$$
What I want is an expression for $\eta_k$ in terms of $k, \lambda$ and $\{f_{ij}\}$, so this is an infinite number of equations in an infinite number of unknowns, with an infinite number of parameters. (It could also be seen as a singe functional equation.) The numbers $f_{ij}$ are arbitrary real parameters. We can assume they are bounded below (i.e. there exists $g$ such that for every $i$ and every $j$, $f_{ij}>g$) but not necessarily bounded above. $\lambda$ is also a real parameter; if necessary we can assume that it is sufficiently large that the infinite sums in the equations converge. Equivalently, if we let $x_k = e^{-\eta_k}$ and $A_{ij}=e^{-\lambda f_{ij}}>0$ then we're trying to find positive solutions (for $\{x_k\}$) of
$$
\sum_{j=0}^\infty A_{kj} \frac{x_k}{x_j} = \sum_{i=0}^\infty A_{ik} \frac{x_i}{x_k}.
$$
I've tried everything I can think of to solve this, but I'm not much of a mathematician and haven't really got very far. Can anyone else see how to do it?","['sequences-and-series', 'systems-of-equations', 'functional-equations']"
629908,Let $A$ be a $2 × 2$ matrix with real entries which is not a diagonal matrix and which satisﬁes $A^3 = I$. Pick out the true statements:,Let $A$ be a $2 \times 2$ matrix with real entries which is not a diagonal matrix and which satisﬁes $A^3 = \mathcal{I}_2$. Pick out the true statements: $\operatorname{tr}(A) = −1$ $A$ is diagonalizable over $\mathbb{R}$ $λ = 1$ is an eigenvalue of $A$ The characteristic polynomial of $A$ will divide the equation $x^3-1$ and it has degree $2$. So the characteristic polynomial will be $x^2+x+1$ which has two non real complex roots and sum of them is $-1$. so only (a) is true. Am I right?,['linear-algebra']
629912,"If two sets have the same cardinality, then so do their power sets. Converse can't be answered?","The following is my rewrite of this proof for the following assertion : For infinite sets $A, B$, $|A| = |B| \Longrightarrow  \require{cancel} \cancel{\Longleftarrow} |P(A)| = |P(B)|$. $\bbox[2px,border:1px solid black]{\text{ Proof Strategem : }}$ We are given that $f :A \rightarrow B$, is a bijection. How do we construct a bijection between subsets of A and subsets of B? We need a rule whereby, if we take one subset of A, then we can use the rule to uniquely construct a unique subset of B. My intuition on this is to take all the elements of the subset of A, and map them under $f$ to elements of B, which will form a subset of B. $\bbox[2px,border:1px solid black]{\text{ Proof : }}$  In mathematical notation, we define $g$ as: 
$g : P(A) \rightarrow P(B)$ by means of $\color{#009900}{g(S) = \{f(x) : x ∈ S\}} \; \forall S \subseteq A$. $\bbox[2px,border:5px solid grey]{\text{ $g$ onto ? }}$ For all $T \subseteq B$, does there exist $S \subseteq A$ such that $\color{#009900}{g(S) = \{f(x) : x ∈ S\}} \; = T$? Since $f^{-1}$ exists, define $S = \{f^{-1}(x) : x ∈ T\}.$ We must prove $\color{#009900}{\{f(x) : x ∈ S\}} = T$. $\bbox[5px,border:1px solid grey]{T \subseteq g(S)}$ Take $y \in T \iff  f^{-1}(y) ∈ S \iff  \color{ #FF4F00}{f}[f^{-1}(y)] ∈ \color{ #FF4F00}g[S] \iff y \in g[S]. $ $\bbox[5px,border:1px solid grey]{{g(S)} \subseteq T}$ Take $y \in g(S)$ which means there exists $x \in S \ni f(\color{#C154C1}{x}) = y $. Since $x \in S$ means there exists $t \in T \ni \color{#C154C1}{f^{-1}(t) = x}$, substitute this into the previous equation: $f(\color{#C154C1}{f^{-1}(t)}) = y \implies t = y $. Since $t \in T$, thus $y \in T$. $\bbox[2px,border:5px solid grey]{\text{ $g$ 1-1 ? }}$
Suppose we have $G,H ⊆ A$ such that: $g(G) = g(H)$ which means $\{f(x) : x ∈ G\} = \{f(x) : x ∈ H\}$. $\bbox[5px,border:1px solid grey]{\{f(x) : x ∈ G\}  \subseteq \{f(x) : x ∈ H\}}$ Take $g \in G \implies f(g) ∈ \quad g(G) = g(H) \quad \implies f(g) ∈ g(H)$. Thus there exists a $h ∈ H$ such that  $f(g) = f(h)$ $\implies g = h$ because $f$ is a bijection.  Since $g ∈ G$, thus $g ∈ H$. We can prove the other direction by the same argument, just with $G$ and $H$ swapped around. $1.$ In the proof for $g$ onto, how would you (fore)know (ie: divine or presage) to define $S = \{f^{-1}(x) : x ∈ T\}$? $2.$ Would someone please explain the step $f^{-1}(y) ∈ S \iff  \color{ #FF4F00}{f}[f^{-1}(y)] ∈ \color{ #FF4F00}g[S] $? $3.$ Are there easier proofs? The result seems intuitive but the proof is complex. $4.$ Are there any pictures? $5.$ My course doesn't include $ZFC$. So what's the intuition why the converse is false ?","['intuition', 'elementary-set-theory', 'visualization']"
629913,Bound for Analytic Function on Unit Disk,"The following is an old qualifying exam problem that I can't seem to piece together: Suppose we have an analytic function $f$ on the unit disk $\mathbb{D}$ s.t. $|f|  \leq 1$. Show $$ \frac{|f(0)|-|z|}{1-|f(0)||z|} \leq |f(z)| \leq \frac{|f(0)|+|z|}{1+|f(0)||z|}  $$. I've tried two things. First, decomposing $f$ into its real and imaginary parts and applying the Harnack inequality to each (after adding 1 so that it is nonnegative) and then piecing them together so they say something about $f$. I couldn't get that to look close to the inequality.  Second, I define $h(z) = \frac{f(z)-f(0)}{1+|f(0)|}$ and apply the Schwartz lemma. This comes close but I couldn't get it to work.",['complex-analysis']
629928,Limit of sequence with floor function,"$$
\mbox{How do I compute}\quad
\lim_{n \to \infty}%
\left\lfloor\sqrt[4]{\vphantom{\Large A}n^{4} + 4n^{3}}-n\right\rfloor\ {\large ?}
$$ I know that could use squeeze theorem, but for that I would need to find two sequences, which I don't know how to find. For floor function I know that I can somehow use $x - 1 < \left\lfloor x\right\rfloor \leq x$. Thank you","['ceiling-and-floor-functions', 'calculus', 'limits']"
629936,"Describe the set of harmonic functions $h(x,y)$on $\mathbb{C}$ s.t. $(x^2-y^2)h(x,y)$ is harmonic.","The following is a qual-prep question: Describe the set of harmonic functions $h(x,y)$on $\mathbb{C}$ s.t. $(x^2-y^2)h(x,y)$ is harmonic. I've tried using the definition of harmonic function from which after some algebraic manipulations I can see that $h$ must satisfy $y \frac{\partial h}{\partial y} = x \frac{\partial h}{\partial x}$. But I think the answer calls for a more explicit answer and I don't know how to go from here.",['complex-analysis']
629949,Why is Euler's totient function equal to $(p-1)(q-1)$ when $N=pq$ and $p$ and $q$ are prime in a clean intuitive way?,"I had my own proof for it but I really don't like it (it feels not intuitive at all because it requires factoring!) and I feel there must be a more direct way to do it by a different counting argument. If anyone has one it would be greatly appreciated! My ""proof"": Recall: $\phi(N) = $ the number of elements that are relatively prime to $N$ (i.e. have a mod inverse) $N = pq$ where $p$ and $q$ are prime. Let's count the number of elements between $1$ to $N-1$ that are NOT relatively prime to $p$ and $q$. Those elements must have at least $p$ or $q$ as one of its factors. So let include all number that have $p$ as a factor and $q$ as a factor and are in the given range. thus: $0p, 1p, 2p, ..., kp, ..., p(q-1)$ and $0q,1q,2q,...,jq,...,q(p-1)$ That gives a count of: $N - p - q + 1 = pq - p - q + 1 = (p -1)(q-1)$ QED as required. The reason I am not happy with this argument is that it seems to me there should be a clear intuitive way of doing it without having to factor or substitute the definition of $N$. This seems clear because multiplying $(p-1)$ by $(q-1)$ seems to be a very cute formula and it I would be surprise that its a coincidence because $(p-1)$ and $(q-1)$ also have clear interpretations. I am looking for a more intuitive clear reasoning, because it seems evident from the form of the formula that it should exist.","['totient-function', 'cryptography', 'number-theory', 'combinatorics']"
629986,Largest set whose subsets have distinct sums,"What is the largest size of a subset $A$ of the integers $\{1,\dots,n\}$ such that no two non-identical subsets of $A$ have the same sum? You can always take the integer powers of $2$ (1,2,4,8, etc.) giving  $|A| = \lfloor \log_2{n} \rfloor + 1$.  Can you do much better?","['number-theory', 'combinatorics']"
629992,how to solve $x^3y′′−xy′+y=0$,"I tried to use Frobenius method to solve $$
x^{3}{\rm y}′′\left(x\right) − x\,{\rm y}′\left(x\right) + {\rm y}\left(x\right)=0,
$$ but it does not work. And the solution most be $y_{1} = ax + b$.
I tried also using first change of variables $\left(~s = 1/x~\right)$, and then applied the power series method but I did not get the $y_{1} = ax + b$ solution.
Does anyone know how this equation can be solved ?.",['ordinary-differential-equations']
630007,How to find the number of intersections of diagonals in icosahedron?,How to find the number of points of intersection of the diagonals in icosahedron?,['geometry']
630014,Can a unitary matrix be constructed from any doubly stochastic matrix?,"Here is a question that came up while I was thinking about the foundations of quantum mechanics: Consider a unitary $n\times n$ complex matrix $U$, with elements $u_{ij}$.  We know that the rows and columns of such a matrix must form orthonormal bases of $\mathbb{C}^n$. It follows that the matrix $P$, with elements $p_{ij} = |u_{ij}|^2$, must be doubly stochastic, i.e. $\sum_i p_{ij} = \sum_j p_{ij} = 1$, and every $p_{ij}\ge 0$. The question is, is the reverse also true? That is, for any arbitrary doubly stochastic matrix $P = (p_{ij})$, does there exist a unitary matrix $U$ with elements $u_{ij}$ such that $|u_{ij}|^2 = p_{ij}$? If so, is there a systematic way to construct such a unitary matrix, given $P$? (I realise the solution will not be unique.) If not, is there some other property, besides being doubly stochastic, that $P$ must have in order to make this conjecture true?","['linear-algebra', 'quantum-mechanics']"
630018,Finding generating functions - how was this jump made?,"I'm going through examples of probability-generating functions in a book and am confused by the following example:
$$1+2s+4s^2+...=\sum_{n=0}^\infty (2s)^n=(1-2s)^{-1}$$
I understand the summation but how did they infer that $\sum_{n=0}^\infty (2s)^n=(1-2s)^{-1}$?","['generating-functions', 'sequences-and-series', 'probability', 'functions']"
630042,Are $\mathbb{Z} \times \mathbb{Z}$ and $\mathbb{Z} \times \mathbb{Z} \times \mathbb{Z}$ isomorphic as groups? [duplicate],"This question already has answers here : Determine whether $\mathbb{Z}\times \mathbb{Z}$ and $\mathbb{Z}\times \mathbb{Z}\times \mathbb{Z}$ are isomorphic groups or not. (5 answers) Closed 10 years ago . To be clear, by $\mathbb Z$ I mean the group $(\mathbb Z, +)$. My intuitive answer would be no, but I haven't been able to find a proof for it. The basic invariants I know of (e.g. order of elements) are not useful here and my knowledge of infinite abelian groups is very limited. In general, is it true that $\mathbb Z^n \cong \mathbb Z^m \iff n=m$?",['group-theory']
630118,How find this limit $\lim_{x\to 0^{+}}\int_{x}^{1}\frac{\ln{(1+t)}}{\sqrt{t}}dt$,"Find this limit
$$\lim_{x\to 0^{+}}\left(\int_{x}^{1}\dfrac{\ln{(1+t)}}{\sqrt{t}}dt+\int_{0}^{x}\dfrac{\sin{2t}}{\sqrt{4+t^2}\int_{0}^{x}(\sqrt{y+1}-1)dy}dt\right)$$ My try: since
$$\int_{0}^{x}(\sqrt{y+1}-1)dy=\dfrac{2}{3}(1+x)^{3/2}-x$$ maybe
$$\lim_{x\to 0^{+}}\int_{x}^{1}\dfrac{\ln{(1+t)}}{\sqrt{t}}dt$$ exsit? and
$$\lim_{x\to 0^{+}}\int_{0}^{x}\dfrac{\sin{2t}}{\sqrt{4+t^2}\int_{0}^{x}(\sqrt{y+1}-1)dy}dt$$
exsit?
then I can't",['limits']
630127,Matrix Exponent,"I know that the exponential function for an $n\times n$ non-degenerate square matrix $A$ is:
$$e^{At}=S \operatorname{diag}(e^{\lambda_1t},\dots,e^{\lambda_nt}) \space S^{-1}, $$
where $S$ is the eigenvector matrix and $\lambda_i$ are its eigenvalues. What is $e^{A}$? Is it
$$e^{A}=S \operatorname{diag}(e^{\lambda_1},\dots,e^{\lambda_n}) \space S^{-1}?$$ Also, what is $\cos(A)$?","['matrices', 'linear-algebra']"
630131,Finding a radius of convergence of power series,"I have  to find the radius of convergence of some power series but I find myself in trouble for three of them : the series are $\sum2^kx^{k!}$ $\sum\sinh(k)x^k$ $\sum\sin(k)x^k$. For the first one I have tried the Ratio Test for series first but I don't kow how to deal with the factorials as exponents... For the second one, I'm tempted to say it never converges but I cannot prove it. And for the last one, I'd say it converges for $|x|< 1$ since $-1<\sin(h)<1$ anyway, but I'm not quite sure... Some hints would help a lot! Thank you.","['power-series', 'convergence-divergence', 'analysis']"
630134,Calculating $a^n\pmod m$ in the general case,"It is well known, that $$a^{\phi(m)}\equiv1\pmod m ,$$ if $\gcd(a,m)=1.$ So, $a^n\pmod m$ can be calculated by reducing n modulo $\phi(m)$. But, for the tetration modulo $m$ $$a \uparrow \uparrow n\pmod{m},$$ I need the general case, where $a$ and $m$ need not to be coprime. Which reduction can I use in this case ? Is there an easier method to calculate the tetration modulo m without
using the reductions modulo $m , \phi(m) , \phi(\phi(m)) ...$ ? I tried to write a program in PARI, but I failed because reducing modulo
$\phi(m)$ does not work, if a and m are not coprime.","['modular-arithmetic', 'exponentiation', 'tetration', 'number-theory']"
630137,AP Calculus Extrema Help,"A particle moves along the t-axis with displacement $s(t) = t^4-8t^3+18t^2+60t-8$. Find the largest and smallest values of its velocity for $1<=t<=5$. So is this correct: $v(t) = s'(t) = 4t^3-24t^2+36t+60$ Now do I solve for $v(t) = 0$, so $4t^3-24t^2+36t+60 = 0$, so $t=-.958$ So, $s(1) = 63, s(5) = 367, s(-.958) = -41.084$ Would the maximum be s(5) and the minimum be s(-.958)?","['calculus', 'derivatives']"
630138,Rank of homology basis in Ahlfors' Complex Analysis,"In Ahlfors' Complex Analysis book Section 4.4.7, he decomposes the complement in the extended plane of a region $\Omega$ into connected components. He then constructs a collection of cycles $\gamma_i$ in $\Omega$, one for each component, such that every cycle $\gamma$ in $\Omega$ is homologous to an integer linear combination of the $\gamma_i$. Each homology class for $\Omega$ is represented uniquely as such an integer linear combination. He then mentions that there are other such collections of cycles that also serve as a homology basis, but that ...by an elementary theorem in linear algebra we may conclude that every homology basis has the same number of elements. I think I understand at least partially why this should be true: Homology classes of cycles in $\Omega$ form a module over the integers, and because we've already found the basis $\gamma_i$ we know that it's in fact a free module on these generators. We know from slightly more than elementary algebra that the rank of a finitely generated free module over a commutative ring is well-defined. Question: What is the elementary linear algebra argument that he's using? EDIT: Does the fact that it's a module over the integers help out? Can you embed the module of homology classes into its module of fractions (without using a basis to do so), show that the homology basis for the module becomes a basis for the module of fractions as a vector space over the rationals. Then you could use the linear algebra result for dimension of a vector space? Thank you!","['linear-algebra', 'complex-analysis']"
630142,What is the difference between a Hamel basis and a Schauder basis?,"Let $V$ be a vector space with infinite dimensions. A Hamel basis for $V$ is an ordered set of linearly independent vectors $\{ v_i \ | \ i \in I\}$ such that any $v \in V$ can be expressed as a finite linear combination of the $v_i$'s; so $\{ v_i \ | \ i \in I\}$ spans $V$ algebraically: this is the obvious extension of the finite-dimensional notion. Moreover, by Zorn Lemma, such a basis always exists. If we endow $V$ with a topology, then we say that an ordered set of linearly independent vectors $\{ v_i \ | \ i \in I\}$ is a Schauder basis if its span is dense in $V$ with respect to the chosen topology. This amounts to say that any $v \in V$ can be expressed as an infinite linear combination of the $v_i$'s, i.e. as a series. As far as I understand, if a $v$ can be expressed as finite linear combination of some set $\{ v_i \ | \ i \in I\}$, then it lies in its span; in other words, if $\{ v_i \ | \ i \in I\}$ is a Hamel basis, then it spans the whole $V$, and so it is a Schauder basis with respect to any topology on $V$. However Per Enflo has constructed a Banach space without Schauder basis (ref. wiki ). So I guess I should conclude that my reasoning is wrong, but I can't see what's the problem. Any help appreciated, thanks in advance! UPDATE: (coming from the huge amount of answers and comments)
Forgetting for a moment the concerns about cardinality and sticking to span-properties, it has turned out that we have two different notions of linear independence: one involving finite linear combinations (Hamel-span, Hamel-independence, in the terminology introduced by rschwieb below), and one allowing infinite linear combinations (Schauder-stuff). So the point is that the vectors in a Hamel basis are Hamel independent (by def) but need not be Schauder-independent in general. As far as I understand, this is the fundamental reason why a Hamel basis is not automatically a Schauder basis.","['schauder-basis', 'hamel-basis', 'linear-algebra', 'functional-analysis']"
630156,What can we learn about a magma by studying these monoids?,"Given a magma $(X,*)$, we get three monoids in the following way. First, define a pair of functions $L,R : X \rightarrow (X \rightarrow X).$ $$(Lx)(y) = x*y,\quad (Rx)(y) = y*x$$ Then each of the following forms a subset of the functions $X \rightarrow X.$ $\mathrm{im} \,L$ $\mathrm{im} \,R$ $\mathrm{im} \,L \cup \mathrm{im} \,R$ Thus each generates a monoid of functions $X \rightarrow X.$ General Question. What can we learn about the magma $M=(X,*)$ by studying these three monoids? For example, are there any interesting pairs of identities $I,J$ such that $(X,*)$ satisfies identity $I$ iff the monoid generated by $\mathrm{im} \,L$ satisfies identity $J$? A link or reference would be nice.","['semigroups', 'reference-request', 'abstract-algebra', 'magma']"
630166,Coefficient of $x^n$ in the series,"How will we find the coefficient of $x^n$ in the following series:
$$(1+x+2x^2+3x^3+...)^n$$ Please suggest if there is some formula or if it can be computed using the computer in $\log n$ time. I have figured out the differentiation approach which is slow.
Thanks in advance.I am guessing matrix multiplication/exponentiation and linear algebra could help.
Edit: I tried multinomial theorem too, but couldn't build on the solution as it requires the coefficients to be constant.","['multinomial-coefficients', 'matrices', 'linear-algebra', 'binomial-coefficients', 'combinatorics']"
630194,To prove the independency of two random variables,"Suppose two random variables $X_1$ and $X_2$ are of identical independent distribution, with the same PDF $f(x) = e^{-x},  \space x>0$. Now, we have $$Y_1=\min(X_1, X_2)$$ $$Y_2=\max(X_1, X_2)$$  $$Y_3=Y_2 - Y_1$$
The problem is to determine if $Y_1$ and $Y_3$ are independent, and prove why.
Unfortunately, I have no idea how to prove it. I only have the notion of $f(X_1X_2)=f(X_1)f(X_2)$ for $X_1$ and $X_2$ independent. Please help me.",['probability']
630196,Non-polynomial $C^{\infty}$ function $f:\mathbb{R}\rightarrow\mathbb{R}$ with rational values for rational arguments?,Let's say that $ \ f : \mathbb{R} \rightarrow \mathbb{R} \ $ and $ \ f \ $ is  $C^{\infty}$ function. Assume that for every $ \ x \in \mathbb{Q} \ $ we have also $ \ f(x) \in \mathbb{Q}$. Are the polynomials the only such functions?,"['functions', 'continuity', 'real-analysis']"
630198,"Ideals in ring of continuous functions $\mathcal{C}[0,1]$ ... NBHM- Algebra","I would like to compile all questions I have encountered with Ideals in the ring $\mathcal{C}[0,1]$ of all continuous real valued functions and ask if there are any gaps. Question is to see if : the ideal $\mathcal{I}=\{f\in \mathcal{C}[0,1] : f(0)=0\}$ is maximal ideal in the ring $\mathcal{C}[0,1]$ of all continuous real valued functions. What I have done so far is : consider $\eta :\mathcal{C}[0,1]\rightarrow \mathbb{R}$ where $f\rightarrow f(0)$ $Ker (\eta) = \{ f\in \mathcal{C}[0,1] : f(0)=0\}$ I could see that for each $r\in \mathbb{R}$, I would set $f$ such that $f(x)=x+r$ So, $\eta$ is surjective. So, I would get $\mathcal{C}[0,1]/\mathcal{I}\cong \mathbb{R}$ As $\mathbb{R}$ is a field so ia the quotient $\mathcal{C}[0,1]/\mathcal{I}$ which means that $\mathcal{I}$ is an ideal in $\mathcal{C}[0,1]$. Now Another Question on same idea : Question is to see if : the ideal $\mathcal{I}=\{f\in \mathcal{C}[0,1] : f(0)=f(1)=0\}$ is maximal ideal in the ring $\mathcal{C}[0,1]$ of all continuous real valued functions. I thought of using same ideas as above but i am unable to choose perfect $\eta$ I believe that this is not even a prime ideal.. I set  $f(x)=x$ and $g(x)=x-1$ and consider $f(x)g(x)=(x)(x-1)$ then, $(fg)(0)=f(0)g(0)=0.(-1)=0$ $(fg)(1)=f(1)g(1)=1.0=0$ So, $fg\in \mathcal{I}=\{f\in \mathcal{C}[0,1] : f(0)=f(1)=0\}$ but the neither $f$ nor $g$ is in $\mathcal{I}$. I have two questions: I see that $0$ does not play any role in the question $\mathcal{I}=\{f\in \mathcal{C}[0,1] : f(0)=0\}$ I mean I would have same case if i replace $0$ by any real number. So, I would like to say that $$\mathcal{I}=\{f\in \mathcal{C}[0,1] : f(r)=0\}$$  is a maximal ideal in the ring $\mathcal{C}[0,1]$ of all continuous real valued functions. And one more thing I would claim is that If the collection $\mathcal{I}$ is such that all elements of $\mathcal{I}$ has more than $1$ common zero then $\mathcal{I}$ is not a maximal ideal and not even a prime ideal.. I would like to learn more about this kind of ideals in $\mathcal{C}[0,1]$. I would be thankful if some one can assure that what  have done is sufficient to conlcude what i have concluded and I would be thankful if some one can suggest some material to read regarding this. Thank you","['proof-verification', 'reference-request', 'abstract-algebra']"
630201,How to arrive at a specific formulation of the relative median deviation? Related to integration and statistics.,"So my title is not very specific but here is the question in more detail.
I am an economist currently working with this book: Frank Cowell - Measuring Inequality On page 25 a formulation of the relative mean deviation is given as follows:
$$
M = 2 \left[ F\left(\bar{y}\right) - \Phi(\bar{y}) \right]
$$ $F$ is the CDF, $\Phi$ is the proportion of total income received by persons who have an income less than or equal to $y$ ( per the book's definition: $\Phi=\frac{1}{\bar{y}} \int_0^y zdF(z)$), and $\bar{y}$ is the mean. 
All this is also defined on page 152 in the appendix. 
The appendix also gives a definition of $M$: $$
M = \int \left| \frac{y}{\bar{y}} -1\right|dF
$$ The book says that the former formulation can be derived from the latter, but I have no idea how to begin with this. How do I perform the integration here and get to the first formulation? Any help would be greatly appreciated.","['calculus', 'integration', 'statistics', 'probability-distributions', 'probability']"
630236,"Is $\sin{(\log{x})}$ uniformly continuous on $(0,\infty)$?","Is $\sin{(\log{x})}$ uniformly continuous on $(0,\infty)$? Let $x,y \in (0,\infty)$.
$$
|f(x)-f(y)| = |\sin{\log{x}} - \sin{\log{y}}| = \left|2 \cos{\frac{\log{xy}}{2}}\sin{\log{\frac{x}{y}}{2}} \right| \leq 2 \left|\sin{\frac{\log{\frac{x}{y}}}{2}} \right| \leq \left|\log{\frac{x}{y}} \right| = |\log{x} - \log{y}| 
$$ If we consider the interval is $(1,\infty)$, then it is easy to finish the above inequality.
But now the interval is $(0,\infty)$, I guess it is not uniformly continuous and now I don't have any idea to show it is not uniformly continuous.
Can anyone give a favor or some hints? Thank you!","['functions', 'real-analysis', 'uniform-continuity']"
630247,$R/I$ is not Noetherian. Prove that $I$ is a prime ideal.,"Let $R$ be a commutative ring with $1$ and let $I$ be an ideal of $R$, maximal with respect to the property that $R/I$ is not Noetherian. Prove that $I$ is a prime ideal. I need some hints to start.","['commutative-algebra', 'ring-theory', 'abstract-algebra']"
630262,About the proof that lebesgue measure is a premeasure.,"let $\lambda^n$ be $n$-dimensional Lebesgue measure. I am having trouble understanding the proof that this ""mapping"" is a premeasure on the set of half open rectangles $\lambda^n ([a,b))= \prod_{i=1}^n(b_i-a_i)$. The proof uses induction over the dimension $n$. I understood how it was shown that $\lambda$ is a premeasure. So now assume $\lambda^n$ is a premeasure the goal is to show $\lambda^{n+1}$ is too, which can be simply reduced to showing that $\lambda^{n+1}$ is $\sigma$-additive. Let $I_j=I_1^j \times I_j^n \in \mathcal J^1 \times \mathcal J^n=\mathcal J^{n+1}$ be mutually disjoint and $\bigcup_{j \in \Bbb N}I_j=I\in \mathcal J^{n+1}$(disjoint union). Ok so now to the first thing I can't understand : Since $I \in \mathcal J^{n+1}$ we know that $$\bigcup_{j\in\Bbb{N}}I_j^d \in \mathcal J^d, \ d=1,n$$ What does he mean by this, and what does $d=1,n$ mean? Define $\hat{I}_1^d=I_1^d$ and $\hat{I}_{j+1}^d=I_{j+1}^d \setminus (I_1\cup \ldots\cup I_j^d)$. The $\hat{I}_j^d$ are disjoint and $$\bigcup_{j=1}^NI_j^d=\bigcup_{j=1}^N\hat{I}_j^d$$ 
for all $N \in \Bbb{N}$ and $d=1,n$ (I still don't get what this notation is, the second union is disjoint). 
Now since $\mathcal J^d$ is a semi-ring each $\hat{I}_j^d$ is a finite union of disjoint union of disjoint rectangles. Hence there are disjoint sets $\widetilde{I}_k^1\in \mathcal J^1$ and $\widetilde{I}_l^n\in \mathcal J^n$ such that(all union below are disjoint) 
$$I=\bigcup_{j \in \Bbb{N}}(I_j^1 \times I_j^n)=\text{why?}\bigcup_{k \in \Bbb{N}}\bigcup_{l \in \Bbb{N}}(\widetilde{I}_k^1 \times \widetilde{I}_l^1)=\bigcup_{k \in \Bbb{N}}\widetilde{I}_k^1 \times \bigcup_{l \in \Bbb{N}}\widetilde {I}_l^n \in \mathcal J^1 \times \mathcal J^d $$ Is $ \mathcal J^d$ a typo? Also why is $\lambda^{n+1}(\bigcup_{k \in \Bbb{N}}\widetilde{I}_k^1 \times \bigcup_{l \in \Bbb{N}}\widetilde {I}_l^n )=\lambda^1(\bigcup_{k \in \Bbb{N}}\widetilde{I}_k^1) \cdot \lambda^n (\bigcup_{l \in \Bbb{N}}\widetilde {I}_l^n) $? (this is just stated without any proof and doesn't really seem direct) And finally why is $$\sum_{j\in \Bbb{N}}\mathop{\sum\sum}_{(k,l):(\widetilde{I}_k^1 \times \widetilde{I}_l^n)\subset (I_j^1 \times I_j^n)}\lambda^{n+1}(\widetilde{I}_k^1 \times \widetilde{I}_l^n)=\sum_{k \in \Bbb{N}}\sum_{l \in \Bbb{N}} \lambda^{n+1}(\widetilde{I}_k^1 \times \widetilde{I}_l^n)$$ Such hardness much handwavery.","['measure-theory', 'lebesgue-measure', 'proof-explanation']"
630264,Find the probability the same color was used twice in a chess game given the player did not lose,"Here's the question and its solution: I don't see how the solution to the problem is to compute: $[1-P(W|L)]^2+[1-P(B|L)]^2$ i.e. I don't think the expression above reflects what the question is asking and I actually computed this: $
\begin{align}
P((W^1 \cap W^2) \cup (B^1 \cap B^2) \left| L_c^1 \cap L_c^2 \right.) &= \frac{P([(W^1 \cap W^2) \cup (B^1 \cap B^2)] \cap (L_c^1 \cap L_c^2))}{P(L_c^1 \cap L_c^2)} \\
&=\frac{P((W^1 \cap L_c^1) \cap (W^2 \cap L_c^2)) + P((B^1 \cap L_c^1) \cap (B^2 \cap L_c^2))}{P(L_c^1 \cap L_c^2)}\\
&=\frac{\left[P \left(L_c^1 \left| W^1\right.\right)P(W^1) \right]\left[ P \left(L_c^2 \left| W^2 \right. \right)P(W^2)\right] + \left[P \left(L_c^1 \left| B^1\right.\right)P(B^1) \right]\left[ P \left(L_c^2 \left| B^2 \right. \right)P(B^2)\right]}{P(L_c^1 \cap L_c^2)}\\
&=\frac{[(1-0.2)(0.5)][(1-0.2)(0.5)]+[(1-0.3)(0.5)][(1-0.3)(0.5)]}{(0.75)(0.75)}\\
&= \frac{0.4^2+0.35^2}{0.75^2} \\
&= \frac{113}{225}
\end{align}$ Why is my attempted solution incorrect? EDIT: Where the superscripts denote the number of the game (1st game, 2nd game) and $L_c$ denote the event that the chess player does not lose i.e. win or draw.",['probability']
630270,Solve the differential equation $y''-10y'+21y=15e^{4t}$ using Laplace transform,"I need to solve the following with Laplace transform:
$$y''-10y'+21y=15e^{4t}$$ $$y(0)=3,y'(0)=0$$ After Laplace transform I got:
$$L(y)=\frac{15}{(S-4)(S^2-13S+21)}+\frac{30}{(S^2-13S+21)}$$
and now, what do I need to do?","['ordinary-differential-equations', 'laplace-transform']"
630295,"Simpler proof of $g\,h\,g^{-1} = h^a \Rightarrow g^n\,h\,g^{-n} = h^{a^n}$","In a rather easy online lecture on group theory (which included many obvious statements such as ""the only divisors of a prime number $p$ are $1$ and $p$""), the professor began a proof by assuming that $g\,h\,g^{-1} = h^a$, where $g$ and $h$ are elements of some group $G$ having prime orders $p$ and $q$, respectively, and from this he immediately asserted, without proof (i.e. as if it were obvious): $$a^p \equiv 1 \mod{q}.$$ This blew me away.  The assertion does not look obvious to me at all.  Is it? It's easier to see that the assertion above must be true if one has already established the more general implication (valid for any two elements $g$ and $h$ in any multiplicative group) $$g\,h\,g^{-1} = h^a \;\; \Rightarrow \;\; g^n\,h\,g^{-n} = h^{a^n}, \forall \, n \in \mathbb{N},$$ ...but he had not established this, and it is not something that jumps out at me as obvious either (even though I can prove it 1 ). Am I somehow missing some immedate proof of either of the two assertions? 1 My proof is by induction.  Assuming that $g^k\,h\,g^{-k} = h^{a^k}$ holds for all $k\in\{1\dots n-1\}$, then
$$g^n\,h\,g^{-n} = g (g^{n-1}\,h\,g^{-(n-1)})g^{-1} = g\,h^{a^{n-1}}\,g^{-1} = (g\,h\,g^{-1})^{a^{n-1}} = (h^a)^{a^{n-1}} = h^{a^n},$$
...where the second and fourth equalities follow from the induction hypothesis for $k = n - 1$ and $k = 1$, respectively. EDIT: I thought of a slight improvement on my original proof: $g\,h\,g^{-1} = h^a$ implies that, for any positive integer $k$, $g\,h^k\,g^{-1} = (g\,h\,g^{-1})^k = (h^a)^k = h^{ka}$.  It also holds for any negative integer $k$, because, by taking inverses of both sides of the preceding equality, $(g\,h^k\,g^{-1})^{-1} = g\,h^{-k}\,g^{-1} = h^{-ka}.$  Finally, the equality also holds (trivially) if $k = 0$.  The assertion $g\,h^k\,g^{-1} = (g\,h\,g^{-1})^k = h^{ka} = (h^k)^a, \forall\,k \in \mathbb{Z}$ says that conjugation by $g$ of any element $h^k$ of the cyclic group $\langle h \rangle$ is the same as raising the element to the $a$-th power.  Hence, $n$ successive conjugations by $g$ (or equivalently, conjugation by $g^n$) is the same as raising the conjugated element to the $a^n$-th power. Granted, this revised proof is significantly longer than my original one, but I like it better because it clarifies for me the scope of validity (namely, all of $\langle h \rangle$) of identifying the operation $h\mapsto g\,h\,g^{-1}$ with the operation $h\mapsto h^a$.  The assertion I proved originally then follows trivially: each side of that equality represents $n$ successive applications one of these two equivalent operations.","['alternative-proof', 'group-theory']"
630311,Tate module of product of abelian varieties,"Is there a way to relate the Tate module $T_{l}(A \times B)$ of the product of two abelian varieties $A$ and $B$ over a field $k$ (where $l \neq \text{char}(k)$), to the Tate modules $T_{l}(A)$ and $T_{l}(B)$? The only thing I have so far is that the rank of $T_{l}(A \times B)$ as a $\mathbb{Z}_{l}$-module is the same as the sum of the ranks of the Tate modules of $A$ and $B$ as $\mathbb{Z}_{l}$-modules.","['modules', 'algebraic-geometry', 'abelian-varieties']"
630314,Applying Open Mapping Theorem,"Let $X$ and $Y$ Banach spaces and $F: X \to Y$ a linear, continuous and surjective mapping. Show that if $K$ is a compact subset of $Y$ then there exists an $L$, a compact subset of $X$ such that $F(L)= K$. I know by the Open Mapping Theorem that $F$ is open. What else can I do? Thank yoU!",['functional-analysis']
630315,For which groups does existence of a subgroup of prime index $p$ implies the existence of a subgroup order $p$?,"Subgroups and quotient groups are very different things, but when $G$ is finite and has a quotient group $Q$ of order $p$ with $p$ prime we know from Cauchy's theorem (or the stronger, more famous version by Sylow) that $G$ also has a subgroup $H$ of order $p$. (Here I have no pretensions as to elements of $H$ being representatives of elements of $Q$ although results in that direction would be nice too) My question is: is there a more general class of groups than just finite groups for which this implication (subgroup of index $p$ implies subgroup of order $p$) holds? The example of $\mathbb{Z}$, the infinite cyclic group shows that this property is not automatic, but still I am cautiously optimistic about compact topological groups. And what is known about reductive algebraic groups?",['group-theory']
630337,Proof that a line cuts in half the area of a parallelogram iff it goes through the intersection of the diagonals?,"I read a theorem in a book which says that a line bisects a parallelogram iff it goes through the intersection of the diagonals. The edge case of this is of course if the line is one of the diagonal which creates 2 triangle. It is well known that these 2 triangle have the same area. Is the full theorem true? Can you give me an elementary proof, for this? (I am still in secondary school.)","['analytic-geometry', 'geometry', 'proof-writing', 'euclidean-geometry']"
630339,"Pedagogy: How to cure students of the ""law of universal linearity""?","One of the commonest mistakes made by students, appearing at every level of maths education up to about early undergraduate, is the so-called “Law of Universal Linearity”: $$ \frac{1}{a+b} \mathrel{\text{“=”}} \frac{1}{a} + \frac{1}{b} $$ $$ 2^{-3} \mathrel{\text{“=”}} -2^3 $$ $$ \sin (5x + 3y) \mathrel{\text{“=”}} \sin 5x + \sin 3y$$ and so on.  Slightly more precisely, I’d call it the tendency to commute or distribute operations through each other. They don't notice that they’re doing anything, except for operations where they’ve specifically learned not to do so. Does anyone have a good cure for this — a particularly clear and memorable explanation that will stick with students? I’ve tried explaining it several ways, but never found an approach that I was really happy with, from a pedagogical point of view.","['education', 'algebra-precalculus']"
630343,"Is there any difference between linear dependence, collinearity and coplanarity?","The way it seems to me, linearly dependent vectors have to be collinear, and collinear vectors have to be coplanar. However, since a plane doesn't really have a direction, I'm assuming coplanar vectors can point in different directions as long as their lines exist on the same plane. Or do coplanar vectors/points also have to point in the same direction? If so, what's the practical difference between these concepts? I'm wondering this in terms of orientation and position in three-space, not in terms of whether the math is done differently or not. For example, what would be the difference between 3 linearly dependent vectors, 3 collinear vectors and 3 coplanar vectors? EDIT:
So far I still can't visualize the difference in 3D space. It's not that I don't understand that the math is different, I just want to be able to clearly visualize what the similarities and differences are, because if I don't then the math won't make sense to me. I need to understand what the math does in order to make it stick.","['linear-algebra', 'vectors']"
630360,Series of inverses of binomial coefficients,"Can you think of a simple way of proving that
$$
\sum_{n=k+1}^\infty \frac{1}{n \choose k}
$$ 
is rational for any $k \geq 2$? Here's the background. Consider a series:
$$
\sum_{n=1}^\infty \frac{1}{n(n+1)}
$$ Elementary algebra gives us that:
$$
\sum_{n=1}^\infty \frac{1}{n(n+1)} = \sum_{n=1}^\infty \left(\frac{1}{n} - \frac{1}{n+1}\right) = \lim_{k\to\infty} (1 - \frac{1}{k+1}) = 1
$$ so the sum turns out to be rational. Next, consider 
$$
\sum_{n=1}^\infty \frac{1}{n(n+1)(n+2)(n+3)(n+4)}
$$ With the same method, but much more effort we can show that:
$$
\sum_{n=1}^\infty \frac{1}{n(n+1)(n+2)(n+3)(n+4)} = \sum_{n=1}^\infty \left(\frac{1}{24 n}-\frac{1}{6(n+1)}+\frac{1}{4(n+2)}-\frac{1}{6(n+3)}+\frac{1}{24(n+4)}\right)
$$
and again we'll see that stuff cancels out, and the sum is again rational. So the obvious conjecture is that this method will work for arbitrary (but $\geq 2$) fixed number of factors in denominator, and the sum will always be rational. Indeed that's the case. I provide a solution as an answer, but I'm not fully satisfied with it (it seems for me to be too brute force), so I'm looking for alternative solutions.","['sequences-and-series', 'power-series', 'calculus', 'binomial-coefficients']"
630406,calculation of Stefan's constant,"In the calculation of Stefan's constant one has the integral
$$J=\int_0^\infty \frac{x^{3}}{\exp\left(x\right)-1} \, dx$$
which according to Wikipedia is equal to $\frac{\pi^4}{15}$. In this page of Wikipedia there is a (long) method of calculation using  the Taylor expansion of $f(k) = \int_0^\infty \frac{\sin\left(kx\right)}{\exp\left(x\right)-1} \, dx$ obtained with contour integration. In this article is written that $J=\Gamma(4)\,\mathrm{Li}_4(1) = 6\,\mathrm{Li}_4(1) = 6 \zeta(4)$. How to obtain these equalities? It is also written that there is number way to obtain the result. Someone know another way?","['calculus', 'integration', 'physics', 'analysis', 'complex-analysis']"
630407,How can I calculate $\iint_S\frac{\bf x}{|{\bf x}|^3}\cdot d{\bf S}$ with a semisphere $S$ not centered at the origin?,"Let $$
F(x,y,z)=\frac{x{\bf i}+y{\bf j}+z{\bf k}}{(x^2+y^2+z^2)^{3/2}}. 
$$
  How can I calculate 
  $$
\iint_SF\cdot d{\bf S}
$$
  where $S$ a the ""upper semi-unit-sphere"" and  the boundary of $S$ given by
  $$
\begin{cases}
x+y+z=3\\
(x-1)^2+(y-1)^2+(z-1)^2=1
\end{cases}?
$$ If I change the coordinate to make the equations of the boundary of the semisphere simpler:
$$
z'=0,\quad x'^2+y'^2+z'^2=1,
$$
then I messed up with $F(x',y',z')$. But if I don't change the coordinates, I messed up with the parameterization of the surface. Any idea? Does the integral $$\iint_S\frac{\bf x}{|{\bf x}|^3}\cdot d{\bf S}$$ have some meaning in physics? [Added] I didn't expect that my description of the surface in the integral is so difficult to be understood. Suppose we have a unit sphere centered at $(1,1,1)$ 
$$
\Omega=\{(x,y,z)\in{\Bbb R}^3:(x-1)^2+(y-1)^2+(z-1)^2=1\}
$$
and the plane 
$$
P=\{(x,y,z)\in{\Bbb R}^3:x+y+z=3\}.
$$
Geometrically, the plane $P$ would cut the sphere $\Omega$ into two pieces and $S$ is one of them while I don't specify which one so that the result would be up to the choice of these two pieces. The confusion might due to my notation:
$$
\begin{cases}
x+y+z=3\\
(x-1)^2+(y-1)^2+(z-1)^2=1
\end{cases}.
$$
which is equivalent to 
$$
\{(x,y,z)\in{\Bbb R}^3:x+y+z=3\ {\bf and}\ (x-1)^2+(y-1)^2+(z-1)^2=1\}
$$
which is the boundary of $S$.",['multivariable-calculus']
630415,Divide and Count,"I have question that I can't understand it and I don't know how should I solve it.
here is the whole question: Jack has several beautiful diamonds, each of them is unique thus precious. To keep them safe, he wants to divide and store them in different locations. First, he has bought some coffers. These boxes are identical except that their capacities (the number of the diamonds that a box can contain) may diverse. Before he puts his diamonds in, he wants to figure out how many different ways he can store these diamonds into the coffers For example: We have 2 coffers with capacity 3, with 6 different diamonds and the answer is 10 way First:can you tell me why the answer is 10. Second:Is there any formula or special way to calculate this",['discrete-mathematics']
