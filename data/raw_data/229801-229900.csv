question_id,title,body,tags
4761698,Definition of injection and the meaning of codomain [duplicate],"This question already has answers here : How is the codomain for a function defined? (6 answers) Closed 10 months ago . As far as I understand, the main difference between bijective and injective functions are that the codomain of injective could contain some elements that is not in the image of $f:X \rightarrow Y$ where $X$ is domain and $Y$ is codomain. My question is: Why do we need to define a codomain? If nothing will be mapped to those elements that are in the codomain but not in the image, why can't we just redefine the codomain just to be the image? When we talk about a function/map, what is the point of defining this codomain?","['functions', 'random-variables', 'real-analysis']"
4761704,Prove that $S_4$ is isomorphic to a presentation,"I would like to prove that $G=\langle a,b \, | \, a^2,b^4,(ab)^3\rangle \cong S_4$ .
I tried to list out all the elements in the group presentation and show that it is isomorphic to $S_4$ , but it was too tedious. I've also tried to use the homomorphism $\phi:F(a,b)\rightarrow S_4$ where $\phi(a)=(12)$ and $\phi(b)=(1234)$ . However I do not know how to show that the normal closure of the relator is actually the kernel of this map. I've also found a different post where this isomorphism is proved by assuming that $S_4$ is isomorphic to another presentation with $3$ generators. But to show that $S_4$ is isomorphic to $\langle x,y,z \mid x^2=y^3=z^4=xyz=1 \rangle$ is also not easy. Are there any clever ways to prove this isomorphism?","['group-presentation', 'group-isomorphism', 'combinatorial-group-theory', 'abstract-algebra', 'group-theory']"
4761714,Orbit stabiliser theorem as an analogue to first isomorphism theorem,"The notes I'm using to study group theory make a remark that another appropriate name for the ""orbit stabiliser theorem"" is the ""first isomorphism theorem for group actions"". For reference, here are the two theorems: First isomorphism theorem: let $\phi: G \to H$ be a group homomorphism with kernel $K$ . Then $G / K \cong \text{Image}(\phi)$ . The isomorphism is given by $\psi: G / K \to \text{Image}(\phi)$ with $\psi(gK) = \phi (g)$ . Orbit stabiliser theorem: let $G$ be a group acting on a set $X$ . Let $x \in X$ . Then the map $\phi: G / \text{Stab} (x) \to \text{Orb} (x)$ where $g \: \text{Stab} (x) \mapsto gx$ is a bijection. Also, if $G$ is finite, then $|G| = | \text{Stab} (x) | | \text{Orb} (x) |$ . I can see why the orbit stabiliser theorem is like the first isomorphism theorem, especially when considering that the stabiliser fixes points (i.e. for the stabiliser, the group action is the same as the identity action), so the stabiliser is a kind of analogue to the kernel. Similarly, the orbit is a bit like the image of a map. What I want is to understand how they're analogous in a more rigorous way, and maybe if any results can be derived for group actions in much the same way as the second and third isomorphism theorems and the correspondence theorem can be derived from the first isomorphism theorem.","['group-homomorphism', 'group-isomorphism', 'abstract-algebra', 'group-theory', 'group-actions']"
4761786,Cauchy Residue Theorem with Logarithms,"I've been trying to use Cauchy's Residue Theorem to calculate the following integral, but I am getting stuck with the logarithm and not sure how to proceed. Q: Evaluate $\int_{-\infty}^{\infty} \frac{\ln|x|}{(x^2 + 1)(x + 1)} dx$ First, let $I = \int_{-\infty}^{\infty} \frac{\ln|x|}{(x^2 + 1)(x + 1)} dx$ . We can rewrite the integrand so that \begin{equation*}
I = \int_{-\infty}^{\infty} \frac{\ln|x|}{(x^2 + 1)(x + 1)} dx = \frac{1}{2} \int_{-\infty}^{\infty} \frac{2\ln|x|}{(x^2 + 1)(x + 1)} dx \Rightarrow 2I = \int_{-\infty}^{\infty} \frac{\ln(x^2)}{(x^2 + 1)(x + 1)} dx
\end{equation*} So we first find what $J = 2I$ is. Let $f(z) = \frac{\ln(z^2)}{(z^2 + 1)(z + 1)}$ . Note that $f(z)$ has simple poles located at $z_0 = i$ , $z_1 = -i$ and $z_2 = -1$ . Furthermore, note that $z \neq 0$ from $\ln(z^2)$ . Then for $\epsilon$ ""small"" and $\rho$ ""large"", define $\Gamma_{\rho, \epsilon} = [-\rho, -\epsilon] + C_{\epsilon}^+ + [\epsilon, \rho] + C_{\rho}^+$ to be the contour that is oriented once in the counterclockwise direction. Note that only $z_0$ and $z_2$ are only inside this contour. Then by using Cauchy's Residue Theorem, we have \begin{align*}
\lim_{\rho \to \infty, \epsilon \to 0} \int_{\Gamma_{\rho, \epsilon}} f(z) dz &= \lim_{\rho \to \infty, \epsilon \to 0} \int_{[-\rho, -\epsilon]} f(z) dz + \lim_{\epsilon \to 0} \int_{C_{\epsilon}^+} f(z) dz + \lim_{\rho \to \infty, \epsilon \to 0} \int_{[\epsilon, \rho]} f(z) dz + \lim_{\rho \to \infty} \int_{C_{\rho}^+} f(z) dz \\
&= 2\pi i [Res(f, z_0) + Res(f, z_2)]
\end{align*} Computing the residues we have \begin{align*}
Res(f, z_0) = \lim_{z \to i} (z - i)f(z) = \lim_{z \to i} \frac{\ln(z^2)}{(z + i)(z + 1)} = \frac{\ln(-1)}{2i(1 + i)} = \frac{i\pi}{2i(1 + i)} = \frac{\pi(1 - i)}{4} \\
Res(f, z_2) = \lim_{z \to -1} (z + 1)f(z) = \lim_{z \to -1} \frac{\ln(z^2)}{(z + i)(z - i)} = 0
\end{align*} I am not sure if this is the correct way to approach this problem and this is where I am getting stuck. I am not sure if I have used the log correctly in this sense.","['complex-analysis', 'complex-integration', 'cauchy-principal-value']"
4761808,Finding the range of $f(x) = \frac{\sqrt{1-x}}{x^2-1}$,"I am trying to find what is the range of this function $$f(x) = \frac{\sqrt{1-x}}{x^2-1}$$ I try to isolate $x$ in terms of $y$ , but I obtain a fourth-degree function and I don't know what to do next. Thanks for your help.","['algebra-precalculus', 'functions']"
4761831,On the rank of product of matrices of order 10,"I had been asked the following question: Suppose $A$ and $B$ are two $10 \times 10$ matrices over $\mathbb{C}$ with $rank(AB)=6$ . What is the maximum possible value of rank of $BA$ ? First, I realized that both $rank(A)$ and $rank(B)$ are at least 6. Further, from Sylvester's inequality, we must have $$rank(A)+rank(B) \leq 16.$$ Now, counting down all the possibilities (For instance, one possibility is $rank(A)=6$ and $rank(B)=10$ ), I arrived at a possible maximum value of $rank(BA)$ which is 8. For this to happen we must have $rank(A) = rank(B) = 8$ . I tried, but could not get an answer to the question, `do there exist two matrices $A$ and $B$ each with rank $8$ and that $rank(AB)=6$ , $rank(BA)=8$ ?","['matrices', 'matrix-rank', 'linear-algebra']"
4761839,"Evaluation of the integral of $\int_0^\infty \frac{\mathrm{Ti}_2(x)}{e^{2 \pi x} - 1}\,dx$","I am trying to evaluate the integral \begin{align*} \Omega \equiv \int_0^\infty \frac{\mathrm{Ti}_2(x)}{e^{2 \pi x} - 1}dx\end{align*} where $\mathrm{Ti}_2(x)$ denotes the inverse tangent integral . I first attempted to convert the integral into an infinite series like this: \begin{align*} \Omega &= \int_0^\infty \frac{e^{-2\pi x} \mathrm{Ti}_2(x)}{1-e^{-2 \pi x}}\,dx \\ &= \int_0^\infty \sum_{n=1}^\infty e^{-2 \pi n x} \mathrm{Ti}_2(x)\,dx \\ &= \sum_{n=1}^\infty \int_0^\infty e^{-2 \pi n x} \mathrm{Ti}_2(x)\,dx \end{align*} From here I am stuck evaluating the integral. I tried looking for whether the inverse tangent integral has a Laplace transform. However, I was not able to find or derive it. I also considered using the Abel-Plana formula alongside the known identity $$\mathrm{Ti}_2(x) = \frac{1}{2i}(\mathrm{Li}_2(ix)-\mathrm{Li}_2(-ix))$$ where $\mathrm{Li}_2(x)$ denotes the dilogarithm, but I did not know how to continue my steps from there. Is there a better way to attack this problem?","['integration', 'complex-integration', 'definite-integrals', 'special-functions']"
4761869,"Approximate the sum of a non $C^1(0,1)$ function by its integral","Consider the function $f: [0,1] \to \mathbb{C}$ defined by $$
f(x)=\sum_{n=1}^{9} e^{2\pi n i x},
$$ so that $$
|f(x)|=\bigg|\frac{\sin(9\pi x)}{\sin(\pi x)}\bigg|.
$$ I'm interested in approximating $\frac{1}{q}\sum_{0 \lt a \lt q} |f(\frac{a}{q})|$ by $\int_{0}^{1} |f(t)|dt$ . The first idea that comes to mind is using the Euler Mac Laurin formula. The problem is that the function $|f(x)|$ is not continuosly differentiable. Another approach I tried was the following: By partial integration, for any $\alpha\in\mathbb{R}$ and $\delta\gt 0$ , $$
\int_{\alpha}^{\alpha+\delta}(x-\alpha)f'(x)dx=\delta f(\alpha+\delta)-\int_{\alpha}^{\alpha+\delta} f(x)dx.
$$ Therefore, by taking $\delta=1/q$ and $\alpha=a/q$ , we have $$
\frac{1}{q}f\Big(\frac{a+1}{q}\Big)=\int_{\frac{a}{q}}^{\frac{a}{q}+\frac{1}{q}}f(x)dx+\int_{\frac{a}{q}}^{\frac{a}{q}+\frac{1}{q}}\Big(x-\frac{a}{q}\Big)f'(x)dx.
$$ Hence, by taking absolute value and summing with respect to $a$ from $0$ to $q-1$ , we have $$
\frac{1}{q}\sum_{0 \lt a \le q} |f\Big(\frac{a}{q}\Big)|\le \int_{0}^{1}|f(x)|dx + \frac{1}{q}\int_{0}^{1} |f'(x)| dx
$$ The problem is that I would like a much more precise approximation because $\int_{0}^{1} |f'(x)|dx$ is quite big compared to $\int_{0}^{1}|f(x)|dx$ , and I know that as $q$ gets bigger this is less of a problem, but I would also like to know how big does $q$ has to be in order for this sum to be well approximated by the integral. Is it possible to obtain a similar lower bound in terms of the integral plus an error term? And is there any way to bound the error term in terms of $q$ but that it doens't involve the integral of the absolute value of the derivative?","['analytic-number-theory', 'calculus', 'analysis', 'real-analysis']"
4761892,Convergence of a sum to an integral using Riemann sum,"In physics, the following problem arises in the context of statistical mechanics. Let $L \gg 1$ be a fixed parameter. Let $\beta > 0$ be also fixed. Consider the following series: $$\rho = \frac{1}{L^{3}}\sum_{p \in \frac{2\pi}{L}\mathbb{Z}^{3}}\frac{1}{e^{\beta(|p|^{2}-\mu)}-1}. \tag{1}\label{1}$$ Here, $|p|^{2} = p_{1}^{2}+p_{2}^{2}+p_{3}^{2}$ , as usual and $\mu$ is (another) parameter, which is supposed to be $-\infty < \mu \le 0$ . One wants to take $L\to \infty$ and replace the sum by an integral: $$\frac{1}{L^{3}}\sum_{p\in \frac{2\pi}{L}\mathbb{Z}^{3}} \to \frac{1}{(2\pi)^{3}}\int dp$$ My question is: what are the conditions which allow such replacement or, putting in another words, what conditions guarantee convergence of the sum into an integral? Let me just explain the motivation of the question. It turns out that, if one replaces the series by an integral without worrying about the convergence, it leads to a very strange physical consequence where the density of the system is bounded when $\mu \to 0^{-}$ . The explanation in the physics literature is that $\mu$ is itself a function of $L^{3}$ , implicitly by (\ref{1}). Hence, one has to be careful when taking the limit $L\to \infty$ . So, if the parameters $\beta$ and $\rho$ are such that, in the limit $L\to \infty$ , $\mu \to 1$ , then the term $(e^{-\beta\mu}-1)^{-1}$ (the term with $p=0$ ) in the sum (\ref{1}) diverges, and one cannot replace the sum by an integral. So, getting back to my question, I wonder if that ensuring that every term in the sum (\ref{1}) is not divergent for every $\mu$ (also in the limit $\mu \to 0$ ) is sufficient to ensure that the sum converges to an integral.","['mathematical-physics', 'discrete-mathematics', 'analysis', 'real-analysis']"
4761903,"How to tell if a cubic equation with positive coefficients has three real, negative roots","I have a cubic equation in $x$ $$x^3+bx^2+cx+d=0$$ where all the coefficients are positive. I know that with Descartes' Rule, the equation has no positive real roots, it either has 3 negative real roots or 1 negative real root and 2 complex roots. If I would somehow know for sure that all 3 roots are real and negative, then my problem would be solved. Is there a way of knowing if this is really the case? Or if it is not, how can I know if the complex roots have negative or positive real parts?",['algebra-precalculus']
4761941,"How to show $ |(Bx,x)|\leq (Ax,x) $ for any $ x\in D(A) $ here?","On the Hilbert space $ H $ , $ A $ is a non-negative self-adjoint operator and $ B $ is a symmetric operator. Let $ D(B)\supset D(A) $ , where $ D(A) $ and $ D(B) $ are definite domain for $ A $ and $ B $ repectively. Assume that \begin{align*}
\|Bx\|\leq \|Ax\|,\quad\forall x\in D(A).
\end{align*} Show that $ |(Bx,x)|\leq (Ax,x) $ for any $ x\in D(A) $ . Here I want to use the norm $ \|\cdot\| $ to represent the $ (Ax,x) $ and $ (Bx,x) $ but I do not how to go on. Can you give me some hints or references?","['operator-theory', 'unbounded-operators', 'functional-analysis', 'analysis']"
4761970,"What counts as a sequence, and how would we know that it isn't deceiving?","A sequence, in my understanding is just a list of numbers in order. In that case, if I write down random numbers with no pattern at all except for the fact that it gets larger, is it a viable sequence? In that case, given a graph, how can we tell if a sequence is linear? Everywhere I've looked just says that linear sequences lie in a line. However, what if the sequence graphed is infinite and is linear for some, but then curves? In that case, couldn't there be sequences that go ""1,2,3,4,9,54,321,556..."" where if the first few numbers were graphed, we would think it's linear. So, my point is, how can we be sure if a sequence is linear other than ""the points lie in a line."" And what is even considered to be a sequence? As an extra note, when do we ever know the rule of a sequence if there is no context? Can't a sequence always be deceiving and we can never be sure of its nature?
Finally, am I overthinking this or does nobody talk or teach this ever and why?",['sequences-and-series']
4761998,Does there exist a second-countable locally connected space with no countable basis of connected sets?,"Space $X$ is called locally connected if it has a basis consisting of connected sets. It's called second-countable if it has a countable basis. If $X$ is both locally connected and second-countable, does that imply that there exists a countable basis consisting of connected sets? Note that this is true if $X$ is a metric space, since for any basis $\mathcal{B}$ of $X$ , we can just take a refinement of $\mathcal{B}_n = \{B\in\mathcal{B} : \text{diam}(B) < \frac{1}{n}\}$ consisting of connected sets from local connectedness, use the Lindelof property, and then the union of those covers for each $n$ will be a countable basis consisting of connected sets.","['general-topology', 'second-countable', 'connectedness']"
4762066,Evaluating $\sum_{i=1}^{\infty} \sum_{j=1}^{\infty} \frac{1}{ij(i+j)^2}$,"I was playing around with double sums and encountered this problem: Evaluate $$\sum_{i=1}^{\infty} \sum_{j=1}^{\infty} \frac{1}{ij(i+j)^2}$$ It looks so simple I thought it must have been seen before, but after using ApproachZero I only found extremely similar variants of the problem: $\sum_{j=1}^{\infty} \sum_{k=1}^{\infty} \frac{1}{j^2(j+k)^2}$ here $\sum_{k=1}^{\infty} \sum_{n=1}^{\infty} \frac{1}{n^2k^2(n+k)^2}$ here $\sum_{n,k \in \mathbb{N_1}} \frac{1}{n^2k^2(n+k)}$ here Some general facts about $T(r,s,t)=\sum_{u,v=1}^{\infty} \frac{1}{u^rv^s(u+v)^t}$ here While the last link looks promising, I don't believe that it answers my specific question(but I haven't read the paper fully, only skimmed). I have an answer to this question(shared Q&A style), but I am curious as to whether there is another way to evaluate the sum. I have been experimenting with double sums for a few weeks now, so many techniques to attack ""simple"" sums such as this would be much appreciated! In terms of level, I have officially finished a Calculus 2 course but I have self-taught myself Calculus 3 and Complex Analysis, and worked through a few ""integration problems"" books so any further integral techniques would be fine.","['integration', 'summation', 'alternative-proof', 'calculus', 'sequences-and-series']"
4762089,Find the point on a line that's closest to an infinite cone,"I have two objects: A line $L$ defined by one of its points $l_0$ and a direction vector $d$ . (I.e. $l_0 + t \cdot d$ ) An infinite cone $C$ defined by its apex $a$ , a direction $e$ and a half-angle $\alpha < \frac{\pi}{2} $ . ( Geogebra ) I want to find the point on the line that is closest to the cone. In the case that the two objects intersect (in more than one point), I would expect the algorithm to return the point that's furthest ""inside"" the cone. So far I failed to figure this out myself. Approaches I thought about/tried: The point closest to the cone's axis is not necessarily the one closest to the cone itself. I found out by finding a counter-example . I read about ways to calculate the intersection(s) between a line and a cone, but that doesn't help me in the case that there is no intersection: then I have no clue. I thought about finding a formula for cone-point-distance and then substitute my line equation for the point, finding a minimum in that function in regards to $t$ . But I haven't found anything that looks like I could analytically find a minimum. With this, I don't know how to proceed, hence this question. Any help is greatly appreciated :)","['analytic-geometry', 'geometry', '3d']"
4762143,Finding the minimum value of $X+Y$ given inputs $A$ and $B$ and some constraints,"The problem is to find the minimum value of $X+Y$ given some value of $A$ and $B$ and the constraint that $$(A+X)\ \big|\ (B+Y)$$ and $X,Y \ge 0$ . This was given as a coding problem, but I want to see if this has a solution without using code. First we know that $(B+Y) = k(A+X)$ for some integer $k \ge 1$ . If $A\ | \ B$ then trivially $X=0=Y$ works. Otherwise, taking into consideration that $Y\ge 0$ , we get the bound $$k(A+X) \ge B$$ Also from the fact that minimizing $X+Y$ is the same as minimizing $X+Y+A+B = (k+1)(A+X)$ . Since $X,Y\ge 0$ this gives us $$(k+1)(A+X) \ge A+B$$ From this we tried the ""trivial"" thing $$ k = \max\left\{\lceil \sqrt{A+B}-1\rceil,\lceil\sqrt B\rceil\right\}$$ $$ X = \max\left\{\lceil \sqrt{A+B}-A\rceil,\lceil\sqrt B-A\rceil\right\}$$ But this does not work, as it gives a large value for $X+Y$ or $X$ becomes negative. For an example where this fails: Let $A = 4394, B = 993298361$ . This gives us a minimum value of $X+Y$ as $65$ with $X=25, Y=40$ . I'm at a loss on how to proceed. Any help is appreciated. Here are some more values of $A$ and $B$ with the expected minimum value of $X+Y$ . $A$ $B$ $X+Y$ $11$ $23$ $2$ $8$ $16$ $0$ $4394$ $993298361$ $65$ $95392025$ $569922442$ $2429708$ $8399283$ $10293$ $8388990$","['number-theory', 'inequality', 'optimization']"
4762153,Isomorphism between tetrahedron and cube paths,"Consider the following two problems: A bug is sitting on vertex $A$ of a regular tetrahedron. At the
start of each minute, he randomly chooses one of the edges at the
vertex he is currently sitting on and crawls along that edge to the
adjacent vertex. It takes him one minute to crawl to the next
vertex, at which point he chooses another edge (at random) and
starts crawling again. What is the probability that, after 6
minutes, he is back at vertex $A$ ? Same as 1., except the bug is crawling along the edges of a cube. We can compute the probability of both to find that they are both $\frac{61}{243}$ , which probably implies there exists an isomorphism between the paths on the cube and the tetrahedron. However, I don't quite see what or how the morphism can be built, because there are $4$ states for where the bug can be on the cube, while there are only $2$ states for where the bug can be on the tetrahedron. I am not necessarily asking for a fully rigorous argument, some solid intuition (preferably geometric) will be accepted as well. (Of course, a rigorous argument will be accepted.)","['random-walk', 'combinatorics', 'probability']"
4762179,$f$ is a real function. What is the largest interval $S$ such that no open subset $I\subset S$ makes $f(I)$ constant?,"Let $f:[0,1]\to \mathbb R$ be a real function. We say a set $I$ is trivial if $f(I)$ is constant. We say a set $S$ is purely non-trivial if no open subset of $S$ is trivial. Question: Does there exist a largest $S$ , such that all other pure non-trivial open sets $S'\subseteq S$ ? For example , if $f(x)=x$ , then $[0,1]$ is the largest purely non-trivial. If $f(x)=x-0.5+|x-0.5|$ , then $[0,0.5]$ is trivial and $[0.5,1]$ is a largest purely non-trivial. My try so far: The following results might be correct: Lemma 1: $S$ is purely nontrivial, open set $O\subset S$ , then $O$ is purely nontrivial. Lemma 2: Suppose open sets $S_1,S_2$ are purely non-trivial, then $S_1\cup S_2$ are purely non-trivial. Lemma 3: The collection $\Omega$ of all purely nontrivial open sets is an algebra. My stuck: if we can prove that $\Omega$ is a sigma field then I can say that the largest $S$ is simply $\cup_{S\in \Omega} S$ or its closure. However, $\Omega$ is not a sigma field!","['measure-theory', 'abstract-algebra', 'analysis', 'real-analysis']"
4762215,All linear inequalities on probabilities of pairwise intersection of events,"Let $A_1,\cdots,A_n$ be events in some probability space. Let $P_i=\Pr[A_i]$ and $P_{i,j}=\Pr[A_i\cap A_j]$ for $i\neq j$ . I'm looking for an exhaustive list of all linear inequalities that must be satisfied by the $P_i,P_{i,j}$ . Here are a few categories of inequalities: The Boole–Fréchet inequalities tell us that $$P_i+P_j-1\leq P_{i,j}\leq P_i,P_j$$ The Bonferroni inequalities give us some more, as: $$1\geq \Pr[\cup_{1\leq i\leq n} A_i]\geq \sum_{1\leq i\leq n} P_i - \sum_{1\leq i<j\leq n}P_{i,j}$$ We can also apply this inequality to any subset of the $A_i$ to get more inequalities. We can also take inequality 2., and take the conjunction of all terms with one of the events $A_i$ . For example, by applying 2. to $A_1,\cdots,A_n$ and then conjuncting with $A_n$ , we get $$P_n\geq\sum_{1\leq i\leq n-1}P_{i,n}-\sum_{1\leq i<j\leq n-1}P_{i,j,n}\geq\sum_{1\leq i\leq n-1}P_{i,n}-\sum_{1\leq i<j\leq n-1}P_{i,j}$$ where above $P_{i,j,n}=\Pr[A_i\cap A_j\cap A_n]$ . Are there any other linear inequalities, besides these above? If not, how do we show that the list above is exhaustive?","['probability-theory', 'probability']"
4762263,Primality testing for quaternions,"Let $H(-1,-p) = \mathbb{Q}+\mathbb{Q}i+\mathbb{Q}j+\mathbb{Q}k$ be the quaternion algebra over $\mathbb{Q}$ such that $i^2=-1, j^2=-p$ and the quaternion is ramified exactly at $p$ and $\infty$ . $\mathcal{O}=\mathbb{Z}+\mathbb{Z}i+\mathbb{Z}j+\mathbb{Z}k$ is an order of the quaternion. We define an element $a\in \mathcal{O}$ is a prime if $a$ cannot be represent as the product of two non unit elements $b,c$ , namely, $a=bc,$ where $b,c\in \mathcal{O}$ and $b$ , $c$ are not units. The question is, given an element $ a\in \mathcal{O}$ . How to efficiently test its primality? To our best knowledge, this question is solved when the $\mathcal{O}$ is a Hurwitz order, we have no idea about this question when the quaternion algebra is not Hamilton. There exists a very trivial method. First we compute its norm $N$ and factor it $N=p_1^{e_1},\ldots, p_n^{e_n}$ , next list all possible elements in the order with proper norm ,namely the factot of $N$ and test whether it is a factor of $a$ . But this method is not efficiently.","['number-theory', 'quaternions']"
4762284,How many Color Balanced sets can you make with n colors?,"You have n colors and you make nonempty sets from them. A set of these color sets is color balanced if each color is in the same number of the color sets. Ex. For n=3 , using Red Green Blue (RGB) as the colors, the set { {RG}, {RB}, {GB} } would be color balanced as each color is in two color sets. As would: { {R}, {G}, {B} } { {B}, {G}, {RB}, {RG} } { {RGB}, {R}, {BG}} { } { {RGB}, {RG}, {RB}, {GB}, {R}, {G}, {B}} The sets { {R}, {G} } and { {RGB}, {R}, {G} } would not be color balanced for n=3 , as Blue (B) fails to appear in as many color sets as Red (R) and Green (G). How many color balanced sets can you create with n colors? The obvious brute force method is to a. enumerate all the color sets b. enumerate all sets of color sets and check each one for color balance. With this I found: 3 colors: 20 color balanced sets 4 colors: 880 5 colors: 5,280,908 ( code ) But this requires $2^{2^n}$ color balance checks, which is obviously intractable for larger n . Question : Is there a more tractable algorithm or combinatoric trick for finding the number of color balanced sets you can make with n colors? How many color balanced sets are there using 7 colors? We've broached this subject before , though not with this particular question. Dan Uznanski came up with a list of primitive canonical groups for n=5 , where all non-primitive color balanced sets are combinations of these primitive groups. That seems like a promising direction, but it's not clear to me how you'd actually form and count the non-canonical sets from these primitive bases, or if you can actually find the primitives without brute forcing (as I think Dan did) . The motivation for this question was the same: Magic the Gathering expansions are almost always divided into ""factions"" that have colors associated with them (the color sets). One of the most popular expansions, for instance, is divided by all the 2-color pairs (Green-Blue, Green-Red, Green-White, Green-Black, Blue-Red etc). The factions have always been color balanced within the expansion, and I was curious exactly how many configurations there were.","['combinatorics', 'algorithms']"
4762304,Evaluating $\sum_{i=1}^{\infty}\frac{i}{2^i-1}$,"I have been asked to find the sum to infinity for the following: $$\sum_{i=1}^{\infty}\frac{i}{2^i-1}$$ I attempted to create some sort of relation between successive terms, in order to use a telescoping method, however, I was unsuccessful in doing so. Then I tried to get to a relation between terms $a_i$ , $a_{2i}$ . However, this too did not help me calculate the required sum. Any help with this would be greatly appreciated.","['summation', 'sequences-and-series']"
4762308,Geometric representation of $2z^2 - \bar{z}^2 = 1$,"I have tried to put $z = x + iy$ and $\bar z = x - iy$ but one $i$ still remains in the equation and to get rid of it, I have to square the whole thing again which makes it a $4^{th}$ degree polynomial and I'm feeling that this isn't right. Is there a better approach for this?","['complex-analysis', 'complex-numbers']"
4762313,Question on the classification of groups of order 102,"I have a question regarding the classification of groups of ""small"" order; we'll take groups of order $102=2 \cdot 3 \cdot 17$ as an example. Let G be a group of order 102, note that $P_{17}\in Syl_{17}(G)$ by Sylow theorems is unique, so $P_{17} \trianglelefteq G$ . Now consider the surjective canonical projection map $\pi:G\twoheadrightarrow{}\frac{G}{P_{17}}$ , then the subgroup $\pi(P_{3})$ is normal in $\frac{G}{P_{17}}$ (by Sylow theorems), so $P_{3} \trianglelefteq G$ . We can conclude that $G\cong (P_{17}\times P_{3})\rtimes_{\psi} P_{2}$ , which is fully determined by the choice of $\psi:P_{2}\to Aut(P_{17}\times P_{3})$ with $Aut(P_{17}\times P_{3})\cong C_{16}\times C_{2}$ . We have four cases (I believe, this is were my understanding get shaky); let x be non unit element in $P_2$ , y be the unique element in $C_{16}$ with order two, and z be the unique element of $C_2$ with order two: trivial morphism, that correspond to $P_{17}\times P_{3}\times P_{2}=C_{102}$ $\psi$ maps $x\longmapsto (y, 0)$ $\psi$ maps $x\longmapsto (y, z)$ $\psi$ maps $x\longmapsto (0, z)$ Intuitively, I think the groups are $D_{2\cdot 51}$ , $C_{3}\times D_{2\cdot 17}$ , and $C_{17}\times D_{2\cdot 6}$ (where D denotes the dihedral group), but the question I have is: how to map these groups to the cases 2), 3), and 4)? Thanks in advance","['group-theory', 'abstract-algebra', 'finite-groups', 'sylow-theory']"
4762322,Measures of noncompactness in locally convex topological vector spaces,"Let $X$ be a Banach space and denote by $B(x,r)$ the closed ball centered at $x\in X$ and radius $r>0$ . We recall that the Hausdorff measure of noncompactness (MNC) is defined as $$
\beta(B):=\inf\{r>0 : B\subset \cup_{i=1}^{n}B(x_{i},r),\textrm{ for some } x_{1},\ldots ,x_{n}\in X\}.
$$ for each non-empty and bounded $B\subset X$ . The Kuratowski MNC is defined as $$
\alpha(B):=\inf\{r>0 : B\subset \cup_{i=1}^{n}D_{i},\textrm{ for some } D_{1},\ldots ,D_{n}\subset X, diam(D_{i})\leq r\}.
$$ where $diam(D_{i})$ is the diameter of $D_{i}$ . For instance, if $X$ is the space of the continuos functions defined on $[0,1]$ , for the set $$
C:=\big\{f\in X: 0\leq f(0)\leq \frac{1}{3},0\leq f(x)\leq 1, \frac{2}{3}\leq f(1)\leq 1 \big\},
$$ I have read, without proof that $\alpha(C)=1$ and $\beta(C)=1/2$ . Now, assume $X$ is a Hausdorff locally convex topological vector space (LCTVS), but not a Banach space, whose topology is generated a family of seminorms $P$ . For each $p\in P$ , we denote by $B_{p}(x,r):=\{y\in X:p(x-y)\leq r\}$ the closed ""ball"" defined by $p$ . We can define in the class of bounded subsets of $X$ the function $$
\beta_{p}(B):=\inf\{r>0 : B\subset \{x_{1},\ldots,x_{n}\}+B_{p}(0,r),\textrm{ for some } x_{1},\ldots ,x_{n}\in X\}.
$$ Replacing, in the above definition of $\alpha$ , $diam(D)$ by $diam_{p}(D):=\sup\{p(x-y):x,y\in D\}$ we obtain $$
\alpha_{p}(B):=\inf\{r>0 : B\subset \cup_{i=1}^{n}D_{i},\textrm{ for some } D_{1},\ldots ,D_{n}\subset X, diam_{p}(D_{i})\leq r\}.
$$ Thus, the families $(\beta_{p})_{p\in P}$ and $(\alpha_{p})_{p\in P}$ are called, respectively, the Hausdorff and the Kuratowski MNC. I am looking for an example where $$
0<\beta_{p}(C)\neq \beta(C) \textrm{ and/or } 0<\alpha_{p}(C)\neq \alpha(C) \quad (*)
$$ for some closed and convex $C$ subset of $X$ . My attempts have been the following. Let $X$ be the Banach space of the continuos functions defined on $[0,1]$ , and $C$ as above. Consider $X$ endowed the point-wise convergence topology. Such topology is generated by the seminorms $p_{x}(f):=|f(x)|$ for each $x\in [0,1]$ . As $[0,1]$ is compact, given $\varepsilon>0$ there is a finite set, put $F=\{x_{1},\ldots,x_{n}\}\subset [0,1]$ such that for each $x\in[0,1]$ there exists $x_{i}\in F$ such that $|x-x_{i}|\leq \varepsilon$ . Then, by putting $f_{i}(x):=x_{i}$ for each $x\in [0,1]$ , for each $x\in [0,1]$ for a given $f\in C$ there is $f_{i}$ such that $$
p_{x}(f-f_{i})=|f(x)-f_{i}(x)|=|f(x)-x_{i}|\leq \varepsilon.
$$ So, $\beta_{p_{x}}(C)=0$ . Likewise, $\alpha_{p_{x}}(C)=0$ for each $x\in [0,1]$ . I am not sure if the above proof is correct at all, but if it is correct, (*) is not satisfied. If $X$ is the space of the null sequences $c_{0}$ endowed the topology generated by the seminorms $p_{n}(x):=|x_{n}|$ for each $n\geq 1$ and $x:=(x_{n})_{n\geq 1}\in c_{0}$ , I think (reasoning as above) that $\beta_{p_{n}}(B)=\alpha_{p_{n}}(B)=0$ for each $n\geq 1$ , where $B$ stands for the unit closed ball of $c_{0}$ . So, (*) is not satisfied in this case. Note that $\beta(B)=1$ and $\alpha(B)=2$ if $c_{0}$ is endowed its usual supremum norm. Somebody know an example where (*) be satisfied? Many thanks for your comments and suggestions.","['general-topology', 'functional-analysis', 'compactness']"
4762340,Partial limits in general topological spaces,"Let $X$ be a general topological space, let $\{x_n\}_{n=1}^\infty\subseteq X$ be a sequence, and let $y\in X$ . Suppose that for every $V\subseteq X$ open neighborhood of $y$ , the set $\{n\in\mathbb{N}\mid x_n\in V\}$ is infinite. Does it necessarily follow that there is a subsequence of $\{x_n\}_{n=1}^\infty$ that converges to $y$ ? (I discovered that the answer is yes under the additional assumption that $X$ is first countable, but I don't know whether this assumption is necessary.)","['general-topology', 'first-countable']"
4762485,Why is the sample space of n tossed coins identical to the expansion of a binomial to the nth power?,"I'm a newbie in math and also in this StackExchange. I apologize for any mistakes. The sample space of $n$ coins tossed seems identical to the expanded form of a binomial at the $n$ th power. Let's take the sample space $S$ of a situation with $n=3$ coins tossed. $$S=\{HHH,\ HHT,\ HTH,\ HTT,\ THH,\ THT,\ TTH,\ TTT\}$$ Now, let's treat $H$ and $T$ as algebraic variables (I don't think it's legal to do that, but let's do it anyway). So, due to commutative properties of multiplication, $HHT=HTH=THH$ , etc. So the new set now looks like this $$S=\{H^3,\ H^2T,\ H^2T,\ HT^2,\ H^2T,\ HT^2,\ HT^2,\ T^3\}$$ Now, let's add up the elements of the set, and we get- \begin{align}
&\quad\ \ H^3\, +\, H^2T\, +\, H^2T\, +\, HT^2\, +\, H^2T\, +\, HT^2\, +\, HT^2\, +\, T^3 \\
&= H^3\, +\, 3H^2T\, +\, 3HT^2\, +\, T^3
\end{align} -which is the binomial expansion of $(H+T)^3$ . Why does this happen? How are sample space of $n$ tossed coins and the binomial expansion of $(H+T)^n$ related?","['statistics', 'binomial-theorem', 'probability']"
4762540,In what metric spaces does bounded + unique limit point imply convergence of a sequence?,"A theorem stated by multiple sources is that any sequence of real numbers converges if and only if it is bounded and has a unique limit point.  Apostol has a theorem that generalizes half of this: for any sequence in a metric space, convergence implies bounded and a unique limit point. There are counterexamples to the other half, for instance a sequence in the open interval $(0,2)$ which alternates between 1 and $1/n$ : $1,1/2,1,1/3,1,1/4,...$ is clearly bounded, has only the limit point 1 because 0 isn't in the space, but diverges.  There are even counterexamples in complete metric spaces, for instance take the natural numbers (or the reals, if you prefer) with the discrete metric
where $d(x,x)=0$ and $d(x,y)=1$ for $x\neq y$ .  The sequence $1,2,1,3,1,4,1,5,...$ has only the limit point 1 but diverges, and under the discrete metric the sequence is actually bounded because all points are within distance 1. My question is, what condition must be true on the metric space (not on the sequence) in order for bounded + unique limit point to imply convergence?  I expect that if it's true for the reals, it's true in any ${\mathbb R}^n$ (with the usual Euclidean metric), and I expect completeness must be necessary, but it's clearly not sufficient. Thanks for helping me think about this!","['general-topology', 'convergence-divergence', 'metric-spaces', 'analysis']"
4762559,Motivation for triple cover of $A_6$ (and $A_7$),"In finite simple groups by Wilson, he constructs the triple cover of $A_6$ by considering the action of the subgroup of $A_6$ preserving the partition $\{12, 34, 56\}$ on the two vectors $(0, 0, 1, 1, 1, 1)$ and $(0, 1, 0, 1, \omega, \omega^*)$ where $\omega$ is a cube root of unity He then adjoins further elements permuting the set of vectors generated, and shows that the resulting group is a triple cover of $A_6$ What is the motivation for this, and why is it exceptional? I can somewhat see how to motivate it as we want to basically make “copies” of $A_6$ (corresponding to each cubic root of unity) lie over $A_6$ , but this doesn’t explain to me (A) why there aren’t higher covers of $A_6$ (B) why there aren’t higher covers than double of $A_n$ for $n > 7$ Similarly (for basically the same reasons) the triple cover of $A_7$ by extending the set of vectors by $(2, 0, 0, 0, 0, 0)$ and considering the symmetries of the $7$ orthogonal sets of $6$ vectors doesn’t really seem motivated to me","['group-theory', 'simple-groups', 'finite-groups']"
4762587,"Exponential map of flow, does it locally look like a power series/matrix exponential?","Let $g_t : M \rightarrow M$ be the flow of a vector field, that is a family of diffeomorphisms such that $g_t \circ g_s = g_{t+s}$ to $t,s > 0$ and $g_0 = \operatorname{id}$ . One can interpret the diffeomorphism group as an infinite dimensional Lie group, up to some technicalities I am not interested in, with its Lie algebra given by vector fields. This group admits an exponential map that sometimes coincides with the Riemannian exponential map, namely there is an $\exp: \mathfrak{X}(M) \rightarrow Diff(M)$ such that: $$\exp(tX) = g_t$$ Where $X : M \rightarrow TM$ is a vector field satisfying $$\frac{d}{dt}g_t(x) = X(g_t(x))$$ My question is, using a coordinate chart a diffeomorphism can be represented locally as just a collection of mappings $g = (g_t^i)_{i=1}^n$ with $g^i_t = F^i(x,t) : \mathbb{R}^n \times \mathbb{R} \rightarrow \mathbb{R}^n$ . Similarly, a vector field can be identified as a first order differential operator that has components with respect to a basis induced by the same chart. Can we say, that in a small neighbourhood we have: $$\exp(tX) = \sum \frac{1}{k!}X^k$$ Where the RHS is some sort of operator/matrix exponential instead of some abstract time 1 geodesic map?","['matrix-exponential', 'lie-algebras', 'lie-groups', 'differential-geometry']"
4762603,Discrepancy in the number of simplices in the barycentric subdivision of an $n$-simplex,"According to OEIS, the number of simplices in the barycentric subdivision of an $n$ -simplex is either given by the sequence: ( A002050 ): 1, 5, 25, 149, 1081, 9365, 94585, 1091669, 14174521, 204495125, etc.; OR ( A005461 ): 1, 15, 180, 2100, 25200, 317520, 4233600, 59875200, 898128000, etc. Despite them both having the description ""Number of simplices in barycentric subdivision of $n$ -simplex,"" these appear to be very different sequences. However, I don't immediately see why this is the case, seeing as the terms of the sequences appear to differ by quite a lot. What is causing the difference in these two sequences, and is one of them more ""correct"" than the other?","['oeis', 'combinatorics', 'discrete-mathematics', 'sequences-and-series']"
4762604,"It is impossible for a regular polygon to have a focus, vertex, and point of a parabola","A conjecture I made about four years ago about parabolas and vertex and focus regular polygons I think the problem is related to algebra and number theory and not to geometry despite the geometric way of phrasing the problem The conjecture states that it is impossible for a regular polygon whose sidelength is FV where F is the focus and V the vertex of a parabola to have a vertex belonging to the parabola that is different from vertex V.
Although it is possible to get an infinite number of good approximations, it is impossible to get a completely accurate case These are, for example, some numbers that give polygons that have a vertex that roughly belongs to a parabola: $14,25,31,38,44,45,52,60,68,77,85,94,...$ I couldn't find a way to deal with the issue, whoever can help please be so kind This conjecture can also be strengthened in several ways, for example we can accept regular stellar polygons","['number-theory', 'conic-sections', 'geometry']"
4762661,Prove that $\lim_{n\rightarrow\infty}\frac{f(n)}{n!}=e$,"Prove that $$\lim_{n\rightarrow\infty}\frac{f(n+1)}{n!}=e\tag{1}$$ where $$f(n+1)=n(1+f(n))$$ The recurrence relation of $n!$ is $a_n=na_{n-1}$ or $a_{n+1}=(n+1)a_n$ . I thought of making a new recurrence relation but we swap the $n$ and the $a_n$ . Then, I noticed that although $f(n)<n!$ , $f(n)>(n-1)!$ when $n>2$ . At first, I thought the limit of their quotient would be $2$ , but I found that $\frac{f(8)}{7!}\approx2.718$ , so there is a very small chance that $(1)$ is not true. According to Wolfram Alpha, $f(n+1)=c\Gamma(n+1)+en\Gamma(n,1)$ , where $$\Gamma(s,x)=\int_x^\infty t^{s-1}e^{-t}dt$$ is the incomplete gamma function. Setting $c=0$ , our limit becomes $$e\lim_{n\rightarrow\infty}\frac{\Gamma(n,1)}{\Gamma(n)}=e\lim_{n\rightarrow\infty}\left(1-\frac{\gamma(n,1)}{\Gamma(n)}\right)=e$$ Where $\Gamma(n)=\Gamma(n,x)+\gamma(n,x)$ . The last equality is obtained by L'hopital's rule. My question here is either proving $(1)$ in a completely different way or proving the closed form that Wolfram Alpha gives (the proof I give of $(1)$ is technically not valid unless there is proof for that closed form). Apparently, we have $$\frac{f(n+1)}{n!}=\sum_{k=0}^{n-1}\frac1{k!}$$ So proving this obviously proves $(1)$","['summation', 'recurrence-relations', 'calculus', 'sequences-and-series', 'limits']"
4762671,Making the bisection theorem rigorous - Munkres Exercise 4 Section 57,"CONTEXT I am trying to prove the following Theorem: ""Let $\lbrace{A_1,...,A_{n+1}\rbrace}$ be bounded Lebesgue measurable sets in $\Bbb R ^{n+1}$ . Show that there exists an $n$ -dimensional hyper-plane that bisects (i.e. divides into subsets of equal measure) each set."" Assuming the n-dimensional Borsuk-Ulam Theorem ( ""if $f:S^{n+1} \to \Bbb R ^{n+1}$ is continuous then $\exists x \in S^{n+1}: f(x)=f(-x)$ "" ), the key idea behind the proof is to consider the sets imbedded in $\Bbb R ^{n+1} \times \lbrace{1\rbrace} \subseteq \Bbb R ^{n+2}$ and to define a function $g:S^{n+1} \to \Bbb R ^{n+1}$ where $g_i(v)$ is the $(n+1)$ -dimensional measure of the subset $A_{i,1}$ of $A_i$ such that $A_{i,1} \times \lbrace{1\rbrace}$ consists of those points of $A_i \times \lbrace{1\rbrace}$ that lie on the same side of the $(n+1)$ -dimensional homogeneous hyper-plane, generated by the normal vector $v$ , as the normal vector itself (i.e. those points $x$ such that $\langle v|x \rangle \geq 0$ ). Therefeore $g_i(v)+g_i(-v) = m(A_i)$ and $g$ is assumed to be continuous so that, by the Borsuk-Ulam Theorem, there exists $v \in S^{n+1}$ such that $g_i(v) = g_i(-v) = \frac{1}{2} m(A_i)$ . Finally, the $n$ -dimensional affine hyper-plane obtained by intersecting the $(n+1)$ -dimensional homogeneous hyper-plane generated by the normal vector $v$ is the desired one. PROBLEM I would like to make precise and rigorous the statement $g$ is continuous MY ATTEMPT My best try was to show that if $A$ is a bounded measurable set in $\Bbb R ^{n+1}$ and $\pi$ is the $n$ -dimensional hyper-plane generated by the normal vector $w$ and translated by the vector $c$ then the function $f: S^n \times \Bbb R ^{n+1} \to \Bbb R$ given by $$f(w,c):= m(\lbrace{ x \in A-c: \langle x|w \rangle \geq 0\rbrace})$$ (i.e. the measure of the subset of $A$ on the same side of the hyper-plane as the normal vector $v$ applied to $c$ ) is continuous. The idea would then be to show that the function that sends the vector $v \in S^{n+1}$ to the corresponding $(w,c)$ is also continuous so that its composition with $f$ is a typical $g_i$ . Now, my initial claim could be proved by restricting the attention to the case $c=0$ (indeed the translation can be made to be followed by the computation of the measure and it is clearly continuous). To this purpose I fixed $\epsilon > 0$ , $w \in S^n$ and $u \in S^n$ such that $||w-u||<\delta$ and I am now trying to show that the slice of a ball containing $A$ and consisting of the points such that $\langle w|x \rangle \geq 0$ and $\langle u|x \rangle < 0$ has measure $< \epsilon$ for a suitable $\delta$ but I am having some trouble doing it. MY QUESTION Is my attempt even close to the easiest way available for solving my problem? Is there any easier way that does not involve such convuluted arguments? Any reference for it? Any answer or comment is much appreciated and let me know if I can explain myself more clearly!","['measure-theory', 'real-analysis', 'solution-verification', 'general-topology', 'algebraic-topology']"
4762690,Confused about the definition of a limit point,"I am studying topology, and the definition of a limit point on my book is: Let $A$ be a subset of a topological space $X$ and $x$ a point of $X$ , we say that $x$ is a limit point of $A$ if every neighborhood of $x$ intersects $A$ at some point other than $x$ itself . The definition of a neighborhood is an open subset containing $x$ . My question is, why do we require the intersection to be at some point other than $x$ itself?",['general-topology']
4762691,Bijection between the set of all Partitions and the set of all Algebras,"I am interested in showing that, given a set $S$ there exists a bijection between the set of all algebras of $S$ , denoted $A$ and the set of all partitions of $S$ , denoted $P$ . As a simple example, I considered the set $S=\{1, 2, 3\}.$ Then, the set of all partitions $P$ consists exactly of the  the sets $$ \{\{1 \}, \{2\}, \{3 \}\}, \{\{1, 2\}, \{3\}\}, \{\{1\}, \{2, 3\}\}, \{\{2\}, \{1, 3\}\}, \{1, 2, 3\}.$$ I then computed the set of all algebra and found that it consisted of all the following sets: $$\{\emptyset, S\}, \{\{1\}, \{2,3\}, S, \emptyset\},\{\{2\}, \{1,3\}, S, \emptyset\}, \{\{3\}, \{1,2\}, S, \emptyset\}, 2^S.$$ It does seem like both sets have the same number of elements, but I am not sure how to construct the bijection in this case. One possible map that came to mind was the map $f:P\to A$ , $$f:P\mapsto \{S, \emptyset\} \cup P$$ for all partitions except the one consisting of all the singleton, and for the later, $$f:\{\{x_0\}: x\in S\} \mapsto 2^S. $$ The map seems to be bijective in this case, but does it work for the general case?
If not, what is the correct mapping?","['elementary-set-theory', 'set-partition']"
4762723,Bijective group homomorphisms are isomorphisms [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 10 months ago . The community reviewed whether to reopen this question 10 months ago and left it closed: Original close reason(s) were not resolved Improve this question Why are all bijective group homomorphisms $\phi: G \to H$ automatically isomorphisms? That is, their inverses are also  homomorphisms. I have seen this fact mentioned before, but never a proof. We need to show that $\phi^{-1}(ab) = \phi^{-1}(a) \phi^{-1}(b)$ for all $a, b \in G$ … no idea where to start.","['group-theory', 'abstract-algebra', 'group-isomorphism']"
4762780,"Assume $\int_0^\infty f(x)dx$ converges. Prove there exists $\xi\in[1,\infty)$ such that $\int_1^\infty \frac{f(x)}x dx=\int_1^\xi f(x)dx$.","Assume $\int_0^\infty f(x)dx$ converges. Prove there exists $\xi\in[1,\infty)$ such that $$\int_1^\infty \frac{f(x)}x dx=\int_1^\xi f(x)dx.$$ I used various mean value theorems but couldn't get the desired result. Another attempt beyond these is: Let $\displaystyle F(x)=\int_1^x f(t)dt$ , then \begin{align*}
\int_1^\infty \frac{f(x)}x dx=\int_1^\infty \frac1x ~dF(x)&=\left.\frac {F(x)}x\right|_1^\infty-\int_1^\infty F(x) ~d\frac1x\\
&=0-0+\int_1^\infty \frac {F(x)}{x^2}dx\\
&=\int_1^\infty \frac {F(x)}{x^2}dx.
\end{align*} How to analyze next? Any help would be appreciated!","['integration', 'mean-value-theorem', 'calculus']"
4762787,Symmetry group of rectangular cuboid,"In this Wikipedia page it is said that the symmetry group of the rectangular cuboid (a box with three unequal dimensions) is a dihedral group $D_8$ (well, some people may call it $D_4$ ...) However, I don't see how it is the case. If the symmetry group is $D_8$ , there is a rotation element $r$ that has order $4$ , i.e., $r^4=e$ , but there is no such element in the symmetry group of the rectangular cuboid that has order $4$ . Every element in the symmetry group of the rectangular cuboid seems to have order $2$ (except for the identity, of course) and I think it should be $\mathbb{Z}_2 \times \mathbb{Z}_2\times \mathbb{Z}_2$ . Is there anything I misunderstand here?","['group-theory', 'symmetry']"
4762812,Convergence of joint distribution and measurability implies convergence in probability,"currently I started to ask myself the following question motivated by this classical exercise: Suppose that $(Y_n)_{n \in \mathbb N}$ is a sequence of random variables defined on the same probability space such that $Y_n \to c$ in distribution as $n \to \infty$ where $c \in \mathbb R$ is a constant then $Y_n \to c$ in probability. Now change the setup in the following sense: Instead of $Y_n \to c$ we introduce another random variable $X$ on the same probability space and require that $(X,Y_n) \to (X,Y)$ in distribution as $n \to \infty$ . Now in order to compare this to the classical exercise above we introduce the fact that $Y$ is measurable  with respect to $X$ . In that sense it is not constant as before but varies ''random constantly'', now we precisely formulate this as the following exercise. Exercise : Let $X$ , $Y$ and $\{Y_n\}_{n \in \mathbb N}$ be random variables defined on the same probability space $(\Omega, \mathcal{F}, \mathbb P)$ . Assume that $(X, Y_n) \to (X,Y)$ in distribution as $n \to \infty$ . Show that if $Y$ is a measurable function of $X$ , then $Y_n \to Y$ in probability as $n \to \infty$ . My attempt : I have trouble writing this quite precisely but intuitively it is clear. Since one has the following $$
(X,Y_n) \stackrel{(d)}{\to} (X,Y) = (X,f(X)) \quad \text{ as } n \to \infty,
$$ then fixing one realization given by $X = c$ this is basically the classical exercise from above. In this setting with $X=c$ one has $Y_n \to c$ in probability as $n \to \infty$ conditional on given that $X = c$ but integrating over all the choices of $X=c$ yields everything you need. Maybe one can write $$
P(|Y_n - Y| < \epsilon) = (P \otimes P)\left((X,Y_n) \in \mathbb R \times [-\epsilon + f(X), \epsilon + f(X)]\right),
$$ but now using properties of the product measure yields that the right hand side is nothing different than $$
\int_{\mathbb R} P(f(x)-\epsilon < Y_n < f(x)+\epsilon) dP_{X}(x), 
$$ using the assumption we also know that $Y_n \to Y$ in distribution, hence since inside the integral $f(x) \in \mathbb R$ is fixed, we know that as $\epsilon \to 0$ the inside is equal to constant $1$ , thus integrating over this constant we get the desired. Question : How can you write this better?","['probability-theory', 'probability']"
4762843,Every $K[G]$-module is torsionless?,"Let $G$ be a finite group and $K$ a field. Consider the group ring $R:=K[G]$ . Let $M$ be a (left) $R$ -module. Is it true that then there exists a set $S$ and an injective $R$ -module homomorphism $M\hookrightarrow \prod_{s\in S}R$ ? In other words I am asking if any $R$ -module can be embedded into a cofree $R$ -module (relative to $R$ ). For free $R$ -modules $M$ this is clearly true. I tried to find a group ring $K[G]$ which is torsion-free as a left module over itself together with a $K[G]$ -module with torsion — in order to disprove the statement. This does not work, however, since the group ring has non-trivial zero-divisors for any non-trivial group. Any other ideas?","['free-modules', 'representation-theory', 'modules', 'group-rings', 'abstract-algebra']"
4762852,"What does it mean that a random variable has ""Lebesgue density""?","My question is basically what the title says. I am solving some exercises in statitics and was told no knowledge of measure theory is required but I am not sure if that is the case. I've been looking into Lebesgue measures but I cannot find a definition of what it means that a random variable has Lebesgue density given by some formula. For example a question where I've been stuck because of this: Let $Y$ be a random variable with a Lebesgue density, and let $Z$ be a discrete random variable with (probable) probabilities $\{ z_k \mid k \}$ . Furthermore, let $Y$ and $Z$ be independent. Justify that $X = Y + Z$ also has a Lebesgue density and calculate it. Thank you!","['statistics', 'lebesgue-measure']"
4762862,Calculating variance for normal distribution,"A random variable is said to be normally distributed with parameters $\mu$ and $\sigma^2$ , if its density function is given by $$f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^2}{2\sigma^2}}\;\;\;-\infty<x<\infty$$ . Now I need find the variance of the normal distribution i.e. the integral $$\int_{-\infty}^{\infty}(x-\mu)^2f(x)dx$$ . Now to prove we use the fact that $$\int_{-\infty}^{\infty}e^{-x^2}=\sqrt\pi.$$ I have proved the above identity using multivariable calculus, double integration, and polar coordinates. So now I consider $\int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi}\sigma}(x-\mu)^2e^{\frac{-(x-\mu)^2}{2\sigma^2}}dx$ = $\lim_{R\longrightarrow  \infty}\frac{1}{\sqrt{2\pi}\sigma}\int_{-R}^{R}(x-\mu)^2e^{\frac{-(x-\mu)^2}{2\sigma^2}}dx $ . Now I use substitution and take $y=\frac{x-\mu}{\sigma}$ . So I get $\lim_{R\longrightarrow  \infty}\frac{\sigma^2}{\sqrt{2\pi}}\int_{\frac{-R-\mu}{\sigma}}^{\frac{R-\mu}{\sigma}}y^2e^{\frac{-y^2}{2}}dy $ .
Now I use integration by parts and get $$\lim_{R\longrightarrow  \infty}\frac{\sigma^2}{\sqrt{2\pi}}\left\{-e^{-\frac{y^2}{2}}y\Biggr|_{\frac{-R-\mu}{\sigma}}^{\frac{R-\mu}{\sigma}}   +\int_{\frac{-R-\mu}{\sigma}}^{\frac{R-\mu}{\sigma}}e^{\frac{-y^2}{2}}dy\right\} .$$ My question is how do I proceed now and use that $\int_{-\infty}^{\infty}e^{-x^2}=\sqrt\pi?$ . My main issue is that I want to compute the variance using the definition of improper integral i.e. the infinite limit of definite integrals.","['improper-integrals', 'probability-distributions', 'normal-distribution', 'probability-theory', 'probability']"
4762865,"Prove that if $f\in C([a,b])$ satisfies $\int_a^bx^kf(x)dx=0 \ \forall k\geq0$ then $f=0$","Prove that if $f\in C([a,b])$ satisfies $\int_a^bx^kf(x)dx=0 \ \forall k\geq0$ then $f=0$ . I saw this problem online and as I'm currently studying functional analysis I'm interested in a solution using this field. I proceed as follows: Let $L:C([a,b])\rightarrow\mathbb{R}$ given by $L(x)=\int_a^bf(t)x(t)dt$ . From linearity of the integral que see that $L$ is linear. Furthermore, $$|L(x)|=\bigg\vert\int_a^bf(t)x(t)dt\bigg\vert\leq\int_a^b|f(t)x(t)|dt\leq C||x||_{\infty}, \ \ C=\int_a^b|f(t)|dt$$ So $L$ is continuous ( $L\in (C([a,b]))^*$ ). By Weiertrass approximation theorem, the span of $\{x^k\}_{k\geq0}$ is dense in $C([a,b])$ , and by hypothesis $L$ is identically $0$ on this set, so $L=0$ (as $\mathbb{R}$ is Hausdorff and $L$ and the zero functional are equal on a dense set). Now use that to conclude that $$
L(f)=\int_a^bf(t)^2dt=0
$$ and so $f=0$ .
Is my solution correct?","['continuity', 'solution-verification', 'functional-analysis', 'real-analysis']"
4762866,An interesting problem from Iran MO,"This year there was an interesting question in 3rd round of the Iran math olympiad: Assume that we want to tile a $n\times n$ table with $1\times 1,1\times 2,\cdots,1\times n$ tiles.
Assume that someone gives us some tiles of these types such that the sum of their area is at least $n^2$ . Let $f(n)$ be the biggest number that we can cover an area of $f(n)$ with these tiles independent of what tiles the other person gives us. Prove that $$n^2-\lceil n^2/4\rceil\le f(n)\le n^2-\lfloor n^2/8\rfloor$$ (Tiles should not overlap, and the other person can give us several tiles of the same type.) There  is still a big gap between these bounds, can someone give a better bound for $f(n)$ at least for big enough $n$ ?","['contest-math', 'combinatorics']"
4762868,How to solve $\int xe^x \cos(2x) \mathrm dx$,"$$\int xe^x \cos(2x) \mathrm dx$$ I have been trying to solve this for some time by using integration by parts, but can't figure out how to divide it into suitable parts. It becomes some sort of loop. Can anyone help as to which ones I should take as $u$ and $v$ ?
Also, is there any other method to approach this problem? Because, integration by parts might get lengthy, perhaps.","['integration', 'calculus']"
4762925,Minimum of two integer-valued random variables,"Suppose we have two integer-valued random variables $N_1,N_2$ and they satisfy $P(N_i\geq n)>0$ for any $n\geq 1$ and $i=1,2$ . Will it be true that $P(\min(N_1,N_2)\geq n)>0$ for any $n\geq 1$ ?","['probability-distributions', 'probability-theory', 'probability', 'sequences-and-series']"
4762936,Rephrasing the strong Markov property with regular conditional distributions,"This question is about definition 17.12 (of the strong markov property) and the following remark 17.13 in A. Klenke's Probability Theory . For completeness, the definition : Let $E$ a polish space,
and let $I\subset[0, \infty)$ be closed under addition. A Markov process $\left(X_t\right)_{t \in I}$ with values in $E$ and distributions $\left(ℙ_x, x \in E\right.$ ) has the strong Markov property if, for every a.s. finite stopping time $\tau$ , every bounded $\mathcal{B}(E)^{\otimes I}$ - $\mathcal{B}(\mathbb{R})$ measurable function $f: E^I \rightarrow \mathbb{R}$ and every $x \in E$ , we have \begin{equation*}
𝔼_x\left[f\left(\left(X_{\tau+t}\right)_{t \in I}\right) \mid \mathcal{F}_\tau\right]=𝔼_{X_\tau}[f(X)]:=\int_{E^I} \kappa\left(X_\tau, d y\right) f(y) . \tag{$*$}
\end{equation*} Here, $κ: E \times \mathcal B(E)^{⊗ I} → [0,1]$ is defined by $κ(x,A) = ℙ_x[X ∈ A]$ , which is a stochastic kernel by definition of a Markov process. The remark following this definition states that if $I$ is countable, then the strong Markov property holds if and only if, for every almost surely finite stopping time $\tau$ , we have \begin{equation*}
\mathcal{L}_x\left[\left(X_{\tau+t}\right)_{t \in I} \mid \mathcal{F}_\tau\right]=\mathcal{L}_{X_\tau}\left[\left(X_t\right)_{t \in I}\right]:=\kappa\left(X_\tau, \cdot\right) .
\tag{$\diamond$}
\end{equation*} Here, $\mathcal L_x[(X_{\tau+t})_{t \in I} | \mathcal F_τ]$ denotes a regular conditional distribution (r.c.d.) of $\left(X_{\tau+t}\right)_{t \in I}$ given the sub-σ-algebra $ \mathcal F_τ$ (this notation is defined at the end of the definition of a Markov process). The question is: why does the remark emphasise that the index set $I$ be countable? I understand that this would guarantee existence of the r.c.d. (since then $E^I$ is polish, so $(X_{\tau+t})_{t \in I}$ takes values in a polish space and thus has a r.c.d. given $\mathcal F_τ$ ), but I don't see why we need this guarantee: It seems to me that if the strong Markov property holds, then $(ω,A) ↦ κ(X_τ(ω),A)$ is a stochastic kernel which by $(*)$ is a r.c.d. of $(X_{\tau+t})_{t \in I}$ given $\mathcal F_τ$ . On the other hand, if $(\diamond)$ holds for every a.s. finite stopping time $τ$ , then $(*)$ follows from properties of regular conditional distributions (specifically Theorem 8.38 in the same book).","['markov-process', 'probability-theory']"
4762975,Complex Analysis: image of $\mathbb{D}$ under $z+\frac{1}{z}$,"The context is the following questions with 2 parts: Define $f(z) = z + \frac{1}{z}$ . Show that f is injective on {|z| < 1} and {|z| > 1}. Determine its image. Write 1/f as a rational function to see that it maps $\mathbb{D}$ to $\mathbb{C}\setminus\{(-\infty, -\frac{1}{2}] \cup [\frac{1}{2}, \infty)\}$ in a biholomorphic way. Here's what I came up with: First of all part one, we show that $z+\frac{1}{z}$ is injective on $\mathbb{D}$ . For this we simply set $$\frac{z^2+1}{z} = \frac{w^2+1}{w} \\
\Leftrightarrow (z-w)(wz-1) = 0
$$ and see that this is not possible for $z \neq w$ and $wz \neq 1$ . Additionally, at 0 we have a pole of order 1. For the second part we can look at what the mapping 1/f does to $z \in \partial \mathbb{D}$ . It sends it to $\frac{1}{2 Re z}.$ This means $\partial \mathbb{D}$ is mapped to $\{(-\infty, -\frac{1}{2}] \cup [\frac{1}{2}, \infty)\}$ Now, I assume $z+\frac{1}{z}$ maps $\mathbb{D}$ to $\mathbb{\hat{C}}\setminus\partial\mathbb{D}$ , but I need help proving this. Edit: Reworked the entire question to include context and my progress.","['complex-analysis', 'analysis']"
4762980,"Is there a concept of ""local"" measurability?","Measurability of functions between measurable spaces is defined so very similarly to the continuity for topological spaces. However, we also have a fruitful notion of ""continuity at a point $x_0$ "" in topology—""points nearby $x_0$ get mapped to point nearby $f(x_0)$ "". I was wondering if there's a parallel for this in measure theory. If so, what does it represent?",['measure-theory']
4762981,In how many ways can four distinctive letters be posted in 6 post boxes such that any two go in same post box and remaining go to different boxes?,"I have tried to solve it in two different ways. But I ended up with different answers. First method There are $\binom{4}{2}=6$ different $2$ letter combinations from a set of $4$ letters. With the remaining letters, the first has $5$ possible choices, and the last one has $4$ . So there are in total $(6×6)×5×4=720$ ways to arrange the letters in the post boxes within the given criteria. Second method The first letter (among $4$ possible choices) has $6$ possible choices for the post box. The second one has $5$ possible choices among the $3$ remaining letters. The remaining two can go in any of the four postboxes left, in order to satisfy the requirement that there must be a post box with 2 letters. So, in total there are $(4×6)×(3×5)×4=1440$ ways. I do not see any logical flaws in the arguments made in each method. I do think the first one is correct. Please, point out any flaws in my reasoning.","['permutations', 'combinations', 'combinatorics']"
4762994,Different value of derivative after applying Leibniz Rule,"I was trying to find the general differential question of $\arcsin(x)$ for Taylor's series and noticed this: $$y=\arcsin^2(x)\\y_1=2(\arcsin(x))\dfrac1{\sqrt{1-x^2}}$$ Squaring both sides $$y_1^2=4y\left(\dfrac1{1-x^2}\right)\\y_1^2(1-x^2)=4y$$ Taking derivative wrt $x$ $$2y_1y_2(1-x^2)+y_1^2(-2x)-4y_1=0$$ $$(1-x^2)y_2-xy_1-2=0\tag1\label{eq1}$$ Taking $n$ th derivative by applying Leibniz Rule: $$y_{n+2}(1-x^2)-2nxy_{n+1}+\dfrac{n(n-1)}{2}(-2)y_n-y_{n+1}x-ny_n=0\\y_{n+2}(1-x^2)-(2n+1)xy_{n+1}-n^2y_n=0$$ when $x=0$ , $$y_{n+2}=n^2y_n\tag2\label{eq2}$$ So when I calculate $y_2$ by $\eqref{eq1}$ , I get $y_2=2$ But when I do the same by $\eqref{eq2}$ , $$y_2=(0)^2y_0=0$$ I get $y_2=0$ Why this inconsistency?
I know I am making a silly mistake somewhere.","['calculus', 'derivatives', 'ordinary-differential-equations']"
4763007,Completion of operator space,"Definition : An (abstract) operator space is a linear space $X$ together with a sequence $\{\|\cdot\|_n\}_{n=1}^\infty$ of norms such that $\|x\oplus y\|_{m+n}= \max\{\|x\|_m, \|y\|_n\}$ for $x\in M_m(X), y \in M_n(X)$ . $\|\alpha x \beta\|_n \le \|\alpha\|\|x\|_m\|\beta\|$ for $\alpha \in M_{n,m}(\mathbb{C}), x \in M_m(X), \beta \in M_{m,n}(\mathbb{C})$ . I now want to understand what the completion $Y$ of the operator space $X$ is, in a way that $Y$ becomes an operator space. The first step should be to begin to define $Y$ to be the Banach space completion of $X$ . To define an operator space structure on $Y$ , we still require norms on $$M_2(Y), M_3(Y), M_4(Y), \dots$$ and it is not clear to me how to do this with the definition of abstract operator spaces. If we use the concrete operator space approach (Ruan's theorem), then we can choose a Hilbert space $H$ and a complete isometry $$\sigma: X \to B(H).$$ We can then define $Y =  \overline{\sigma(X)}\subseteq B(H)$ which shows that the Banach space completion of $X$ carries the canonical structure of an operator space (of course, it should be shown that this does not depend on the choice of representation and stuff like that). I would like to know if there is a way to avoid Ruan's theorem? To illustrate where such a situation as in this question may happen: if $X,Y$ are operator spaces, then one can define norms on $M_n(X \odot Y)$ (where $X\odot Y$ is the algebraic tensor product) which satisfy the two requirements above. Thus, $X\odot Y$ becomes an abstract operator space. But then one defines the projective tensor product $X\hat{\otimes} Y$ to be the completion of this space (whatever this means).","['operator-theory', 'complete-spaces', 'operator-spaces', 'functional-analysis']"
4763014,Filtration dependence of martingales,"Let $Y_1,...,Y_T$ be iid. random variables with $E_P(Y_1)=0$ and $P(Y_1\neq 0)>0$ . Consider the filtration generated by $Y$ , i. e. $\mathcal{F}_0=\{\emptyset, \Omega\}$ and $\mathcal{F}_t=\sigma(Y_1,...,Y_t)$ .  Furthermore, define $S_t=Y_1+\cdots +Y_t$ . So I know that $S$ is a martingale with respect
to $(\mathcal{F}_t)_{t=0,...,T}$ . I have to show that $S$ is not a martingale with respect to the ""enhanced"" filtration $\mathcal{F}^*_t=\sigma(\mathcal{F}_t,S_T)$ . My attempt: So, if we know at time $t$ the value of $S_T$ consider $\mathbb{E}(S_T\mid \mathcal{F}^*_{T-1})$ . If $S$ was a martingale, it would be $=S_{T-1}$ but since we know the end value it would intuitively be $S_T$ . How can I make this more rigorous?","['stochastic-processes', 'filtrations', 'probability-theory', 'martingales']"
4763025,Error in Solution to $\frac{1}{\phi(n)}$ Bound,"While proving the standard expression for $\sum_{n \le x} \frac{1}{\phi(n)}$ , my solution seems to claim  that $$\sum_{y \le x} \sum_{d > x/y} \frac{\mu^2(d)}{d\varphi(d)} \cdot \frac{1}{y} = \sum_{d = 1}^\infty \frac{\mu^2(d) \log(d)}{d\varphi(d)} + O\left(\frac{1}{x}\right)$$ with the proof \begin{align*}
    &\sum_{y \le x} \sum_{d > x/y} \frac{\mu^2(d)}{d\varphi(d)} \cdot \frac{1}{y} > 
    \int_{1}^{x+1} \sum_{d > x/y} \frac{\mu^2(d)}{d\varphi(d)} \frac{1}{y}\ dy = \\
    &\sum_{d = 1}^\infty \int_{x/d}^{x+1} \frac{\mu^2(d)}{d\varphi(d)} \frac{1}{y}\ dy =
    \log\left(\frac{x+1}{x}\right) \sum_{d = 1}^\infty \frac{\mu^2(d)}{d\varphi(d)} + \sum_{d = 1}^\infty \frac{\mu^2(d) \log(d)}{d\varphi(d)} \\
    &> \sum_{2 \le y \le x} \sum_{d > x/y} \frac{\mu^2(d)}{d\varphi(d)} \cdot \frac{1}{y}.\end{align*} as $\sum_{d \ge x} \frac{1}{d \phi(d)} = O\left(\frac{1}{x}\right)$ and $\log\left(\frac{x+1}{x}\right) = O\left(\frac{1}{x}\right)$ as well. However, this seems to imply an extremely strong $O\left(\frac{1}{x}\right)$ error bound for the entire result, which seems to suggest the more likely fact that I've messed up in this claim somewhere. Any help is appreciated on finding exactly where that happens.","['number-theory', 'solution-verification', 'sequences-and-series']"
4763084,Is it possible to construct a positive random variable such that truncated means are always linear?,"Let $X$ be a random variable that takes positive values. Let $\tau \in (0,\infty)$ be a truncation point. Is it possible to construct a distribution of $X$ such that both $u(\tau):=\mathbb{E}[X\mid X\ge \tau]$ and $l(\tau):=\mathbb{E}[X\mid X\le \tau]$ are linear in $\tau$ ? Intuitively, if the density of $X$ has a peak, then the rate of change in $u$ and $l$ cannot be constant, so I guess it should have a monotone density? For example, if $X$ follows the exponential distribution with scale $\beta$ , then $u(\tau)=\beta + \tau$ and $l(\tau)=\beta - \tau/(\exp(\beta^{-1}\tau - 1)$ . Thus, $u$ is linear but $l$ is not linear in $\tau$ . I tried to work from here by considering a weighted density or mixture of densities of exponential form, but I haven't gotten any results.","['statistics', 'probability-distributions', 'probability']"
4763085,Why can we take the collection of all open balls?,"I have a set theoretic question. I don't understand why the collection of open balls of a metric space is a well-defined set. From my understanding of sets, a set is well-defined in Naive set theory if we can check whether an element is in it or not. But how can we check whether a subset is either an open ball or not? It seems very difficult to check. Maybe my view of a set is too rigid. Is there a better view of whether a set is well-defined? Thank you.","['elementary-set-theory', 'metric-spaces']"
4763125,show that solutions which start in the first quadrant must remain there for all time,"I want to show that all solutions $x(t)$ , $y(t)$ of $$x' = x^2+y\sin{x}$$ $$y' = -1+xy+\cos{y}$$ which start in first quadrant ( $x, y >0$ ) stay there for all time. I have seen same questions on this site but i do not understand provided answers. I realize that on boundaries i.e when $x = 0$ then $x'=0$ and when $y = 0$ then $y' = 0$ . I do not see why would that mean that $x$ or $y$ stay equal to 0 whenever the trajectory first enters either boundary, which seemed to be main point of answers I saw. I tried computing trajectories from $\frac{dy}{dx}$ but its not easily solvable if at all, so i dont think that is the way.",['ordinary-differential-equations']
4763133,Suppose $\sum \frac{1}{a_n} $ diverges. Then does $\sum \frac{1}{n\Delta a_n}\ $ diverge?,"Let $(a_n)$ be a strictly increasing sequence of positive real numbers, and denote $\Delta a_n:= a_{n+1} - a_n.$ Suppose $\displaystyle\sum \frac{1}{a_n} $ diverges. Then does $\displaystyle\sum \frac{1}{n\Delta a_n}\ $ diverge? My first thought for counter-examples was to try $a_n = n\log n.$ But I'm pretty sure $\displaystyle\sum \frac{1}{n\left( (n+1)\log(n+1) - n\log n \right)}\ $ diverges. I can't think of a good proof strategy for the affirmative.","['divergent-series', 'examples-counterexamples', 'real-analysis', 'sequences-and-series', 'convergence-divergence']"
4763171,Geometric Interpretation of Matrices with Repeated Nonzero Singular Values,"Let $P\in \mathbb{R}^{d\times n},d<n$ be a $d$ -dimensional coordinate matrix with $\text{rank}(P)=d$ . And let singular value decomposition $P = U\Sigma V^T$ where $U,V$ are orthogonal matrix and $\Sigma\in \mathbb{R}^{d\times n}$ is a diagonal matrix with non-negative real numbers as its diagonal entries. I am particularly interested in understanding the geometric and symmetry implications of having repeated nonzero singular values for $P$ . Specifically, if $\Sigma_{ii} = \Sigma_{jj} > 0$ , it is clear that there exists an infinite number of corresponding unit vectors in $U$ that can perform the orthogonal transformation. In other words, these dimensions form an invariant subspace under some actions of $O(d)$ . However, I am uncertain if this is directly related to the geometry or symmetry of $P$ . Are there any theorems or properties that can shed light on the direct geometric or symmetry implications of repeated nonzero singular values in $P$ ? Any insights, references, or suggestions for further reading would be greatly appreciated.","['matrices', 'group-theory', 'matrix-decomposition', 'reference-request']"
4763174,Conjecture on equal areas in regular heptagon,"I was experimenting with regular polygons and I've found an interesting property with the regular heptagon in particular. Here it is: Let $ABCDEFG$ be a regular heptagon. Now extend rays $GA$ and $CB$ to met at a point $H.$ It seems that the sum of the areas of $FED, GCBA, ABH$ are equal to $FDCG.$ Is this true? There doesn't seem much to do aside from directly computing the areas. If you put the heptagon on the coordinate plane with $E=(1,0), F=(\cos(\frac{2\pi}{7}), \sin(\frac{2\pi}{7})),$ and so on, some computation leads to the area of $FDCG$ is $8\sin(\frac{\pi}{14})\cos^3(\frac{\pi}{14})\cos(\frac{\pi}{7}).$ The area of $FED$ is $(\sin(\frac{3\pi}{14})-1)(-\cos(\frac{3\pi}{14}))$ , the area of $GCBA$ is $(\cos(\frac{\pi}{7})-\sin(\frac{\pi}{14}))(\sin(\frac{\pi}{7})+\cos(\frac{\pi}{14}))$ , The area of $ABH$ is $\sin(\frac{\pi}{7})(1+2\sin(\frac{\pi}{14})-\cos(\frac{\pi}{7})).$ It seems really messy to check that the sum of the latter three values is equal to the former, how should I approach doing this?","['euclidean-geometry', 'geometry']"
4763206,"Prove $f(x)=\begin{cases} x, & x\in[0,1]\setminus\mathbb Q\\ p\sin(1/q), & x=p/q\in[0,1]\cap\mathbb Q\end{cases}$ is continuous at irrational points.","The function is defined on $[0,1]$ by $f(x) = x$ when $x \in \mathbb{R} \setminus \mathbb{Q}$ and $f(x) = p\sin(1/q)$ when $x=p/q \in \mathbb{Q}$ , where $p < q, p \in \mathbb{Z}, q \in \mathbb{Z} \setminus \{ 0 \}.$ My observations so far: Let $x_{0} \in \mathbb{R}\setminus\mathbb{Q}.$ Then $|f(x) - f(x_{0})| = |x-x_{0}|$ for $x \in \mathbb{R} \setminus \mathbb{Q}.$ So we choose $\delta = \epsilon.$ Then $|x - x_{0}| < \delta \implies |f(x) - f(x_{0})| < \epsilon.$ Now I consider the case when $x = \frac{p}{q} \in \mathbb{Q}.$ In this case, we have that $|f(x) - f(x_{0})| = |p\sin(1/q) - x_{0}| \leq |p\cdot 1/q - x_{0}| < |1 - x_{0}|,$ since $p < q.$ Now I'm struggling a little to find a suitable $\delta > 0$ .. Any HINTS are appreciated! Thank you.","['continuity', 'calculus', 'analysis', 'real-analysis']"
4763222,A different approach to proving a property of nilpotent injectors in solvable groups,"Let $G$ be a finite solvable group. Call $J\subseteq G$ a nilpotent injector if it is a nilpotent subgroup that contains $\mathbf{F}(G)$ , and that is maximal with this property (not properly contained in a larger nilpotent subgroup). I would like to show the following: Theorem: If $M$ is subnormal in $G$ , then $J\cap M$ is a nilpotent injector of $M$ . It suffices to assume that $M$ is maximal normal in $G$ , then apply induction to get to any subnormal subgroup. I have only managed to prove the theorem in the case that $M$ doesn't contain $\mathbf{F}(G)$ . Here's how it goes: PARTIAL PROOF: Let $F=\mathbf{F}(G)$ , and suppose $F\not\subseteq M$ . Then by maximality of $M$ , $G=MF$ . Since both $F$ and $M$ are normal in $G$ , $[M,F]\subseteq F\cap M\subseteq\mathbf{F}(M)$ . Let $J$ be a nilpotent injector of $G$ . Let $K=J\cap M$ . Dedekind's Lemma tells us that $J=FK$ . We want to show that $K$ is a nilpotent injector of $M$ . $\mathbf{F}(M)=\mathbf{F}(G)\cap M\subseteq J\cap M=K$ , so $K$ is contained in some nilpotent injector $D$ of $M$ . We aim to show that $D=K$ . Since $[M,F]\subseteq\mathbf{F}(M)\subseteq D$ , we have that $[D,F]\subseteq D$ , so $F$ normalizes $D$ . Since $D$ and $F$ are both normal nilpotent subgroups of $\mathbf{N}_G(D)$ , $DF$ is nilpotent. Since $K\subseteq D$ , we must have that $J=KF\subseteq DF$ . By maximality of $J$ , this forces $J=DF$ , so $D\subseteq J\cap M=K$ . Hence, we have that $K=D$ as desired. END OF PARTIAL PROOF I feel that this is a promising approach, but I haven't been able to complete this proof. Does anyone know how to settle the remaining case of $F\subseteq M$ ? Edit: Notice that I haven't used the assumption that $G$ is solvable!","['nilpotent-groups', 'group-theory', 'finite-groups', 'solvable-groups']"
4763230,"Small parameter expansion of the definite integral, divergence of coefficients","I’m considering the following integral with one parameter $\omega$ $$I(\omega):=\int_0^{\infty}(1+x)^2\Bigg(\sqrt{x^2+\frac{\omega^2}{(1+x)^\delta}}-x\Bigg)dx,$$ where $\delta>2$ and $\omega $ is small parameter. I want to know the expansion of $I(\omega)$ around $\omega=0$ . Naively, it is accomplished by the standard Taylor expansion, but the problem is its coefficient has a divergence, for example, $$\frac{d^2I(0)}{d\omega^2}= \int_0^{\infty}\frac{1}{(1+x)^{\delta-2}}\frac{1}{x}dx\sim\infty.$$ Does anyone know how to fix this problem?","['divergent-integrals', 'definite-integrals', 'taylor-expansion', 'real-analysis']"
4763231,Is closure of an open subset of $\mathbb{R}$ always a countable union of closed intervals?,"The title pretty much is the question (by ""closed interval"" I mean to include possibly ""degenerate"" closed intervals consisting of a single point). The plausibility argument (I wouldn't quite call it a ""proof"") that leads me to think the answer is ""yes"" goes something like this: We know the open set $O$ is a countable union of disjoint open intervals, call them $o_i$ . It seems the closure of $O$ can, in general, introduce two kinds of limit points not already members of $O$ : Any endpoint of an $o_i$ (thus each $o_i$ ""becomes"" a closed interval in $\overline{O}$ ) A point which is some finite distance from every $o_i$ , but is the limit to which some (infinite) subset of the $o_i$ converges. It seems plausible (though I don't have a proof ) that there would be at most countably many such limit points. By this reasoning, the closure of any open subset of $\mathbb{R}$ would be equal to some countable union of closed (possibly ""degenerate"") intervals. Is this right? Or am I missing some case where it fails to hold?","['real-numbers', 'general-topology', 'metric-spaces']"
4763254,Implicit function theorem / Implicit selections when Jacobian not invertible,"I saw the attached result in the book by Dontchev and Rockafellar. It requires the Jacobian to be of full rank m. I suspect this condition can be further relaxed. Assume that we know that the columns of $\nabla_p f(\bar p, \bar x)$ are in the  column space of A. Couldn't we conclude that $$
\nabla s(\bar p) = A^\dagger \nabla_p f(\bar p, \bar x),
$$ where $\dagger$ represents the Moore-Penrose pseudo inverse. If true, is there a good reference I can read to learn about such a result and its extensions?","['multivariable-calculus', 'implicit-function-theorem', 'differential-forms', 'real-analysis']"
4763260,Taylor series up to first order,"I have an expression of the form: $$\frac{1}{1+f(x)}$$ which I want to simplify by employing Taylor series up to linear order. I know that in general: $$\frac{1}{1+x}=1-x+x^2-x^3+....$$ if $|x|<1$ or $|x|<<1$ ? I want to know whether it is also applicable to the case above? i.e., $$\frac{1}{1+f(x)}=[1+f(x)]^{-1}=1-f(x)+f^2(x)-f^3(x)+....$$ with the condition that $|f(x)|<1$ or $f(x)<<1$ ? for any $f(x)$ . A linear order approximation would yield $$\frac{1}{1+f(x)}=1-f(x)$$ which is a reasonable approximation if $f(x)<<1$ .","['derivatives', 'taylor-expansion']"
4763306,Does it imply that $\sum_{n=1}^{\infty}a_n$ converges absolutely?,"Let $(a_n)_{n=1}^{\infty}$ be a sequence of reals and $\lim\limits_{n\to\infty}a_n = 0$ . Suppose that there exists $M \in (0, 1)$ s.t for each $n \in \mathbb{N}$ : $|a_{n+2}-a_{n+1}| \leq M|a_{n+1}-a_{n}|$ . Does it imply that $\sum_{n=1}^{\infty}a_n$ converges absolutely? This questions follows my previous one: Is it necessary that $\sum{a_{2^k}}$ converges? . I struggle to either prove or find a counter-example to this argument and I'm not sure how to proceed (I could only find a counter-example for the case where $M=1$ ). I'd like to have some insights\guidance, thanks.","['sequences-and-series', 'real-analysis']"
4763324,Evaluate $\int\limits_0^{\sqrt 2 } {\frac{1}{{3{a^2} + 2}}\frac{{\arctan \left( {\sqrt {{a^2} + 1} } \right)}}{{\sqrt {{a^2} + 1} }}da}$,"I am trying to evaluate this: $$I=\int\limits_0^{\sqrt 2 } {\frac{1}{{3{a^2} + 2}}\frac{{\arctan \left( {\sqrt {{a^2} + 1} } \right)}}{{\sqrt {{a^2} + 1} }}da} $$ It looks like Ahmed's integral, but I don't know how to solve this.
Here is what I tried: $$\eqalign{
  & I\left( b \right) = \int\limits_0^{\sqrt 2 } {\frac{1}{{3{a^2} + 2}}\frac{{\arctan \left( {b\sqrt {{a^2} + 1} } \right)}}{{\sqrt {{a^2} + 1} }}da} ,I\left( 0 \right) = 0  \cr 
  & I'\left( b \right) = \int\limits_0^{\sqrt 2 } {\frac{1}{{\left( {3{a^2} + 2} \right)\left( {1 + {b^2}\left( {{a^2} + 1} \right)} \right)}}da}  = \left. {\left( {\frac{{\sqrt 6 }}{{2{b^2} + 6}}{{\tan }^{ - 1}}\left( {\sqrt {\frac{3}{2}} a} \right) - \frac{b}{{\sqrt {{b^2} + 1} \left( {{b^2} + 3} \right)}}{{\tan }^{ - 1}}\left( {\frac{{ab}}{{\sqrt {{b^2} + 1} }}} \right)} \right)} \right|_0^{\sqrt 2 }  \cr 
  &  = \frac{{\pi \sqrt {\frac{2}{3}} }}{{2{b^2} + 6}} - \frac{b}{{\left( {{b^2} + 3} \right)\sqrt {{b^2} + 1} }}{\tan ^{ - 1}}\left( {\frac{{\sqrt 2 b}}{{\sqrt {{b^2} + 1} }}} \right),{\text{ integrate both sides from 0 to }}1  \cr 
  & I\left( 1 \right){\text{ = }}\int\limits_0^1 {\left( {\frac{{\pi \sqrt {\frac{2}{3}} }}{{2{b^2} + 6}} - \frac{b}{{\left( {{b^2} + 3} \right)\sqrt {{b^2} + 1} }}{{\tan }^{ - 1}}\left( {\frac{{\sqrt 2 b}}{{\sqrt {{b^2} + 1} }}} \right)} \right)db = \frac{{{\pi ^2}}}{{18\sqrt 2 }} - } {\text{ }}\int\limits_0^1 {\frac{b}{{\left( {{b^2} + 3} \right)\sqrt {{b^2} + 1} }}{{\tan }^{ - 1}}\left( {\frac{{\sqrt 2 b}}{{\sqrt {{b^2} + 1} }}} \right)db}  \cr} $$ At this  point, I don't know how to process further. May I ask for help? Thank you very much.","['integration', 'calculus']"
4763331,Does the mean ratio of the largest prime factor in prime gaps to the lower bound of the gap converge?,"Note : Posted in MO since (2) is open in MSE Let $p_n$ be the $n$ -th prime and $p_n < c_n < p_{n+1}$ be the composite number such that $c_n$ has the largest prime factor $l_n$ in this prime gap. If the largest prime factors occurs in two or more composites then we take $c_n$ to be the smallest among them. Question 1 : Is it true that $$
\lim_{n \to \infty}\frac{1}{n}
\left(\frac{c_2 + c_3 + \cdots c_n}{l_2 + l_3 + \cdots l_n}\right)\left(\frac{l_2}{p_2} + \frac{l_3}{p_3} + \cdots \frac{l_n}{p_n}\right) = 1 \tag 1
$$ Moreover, if we look at the individual components $$
\lim_{n \to \infty}\frac{1}{n}
\left(\frac{l_2}{p_2} + \frac{l_3}{p_3} + \cdots \frac{l_n}{p_n}\right) \tag 2
$$ we observe that its value close to $0.2614$ Experimental data for $(2)$ : $n = 10^8$ , mean $\approx 0.27815$ $n = 10^9$ , mean $\approx 0.27578$ $n = 3.5 \times 10^9$ , mean $\approx 0.27470$ Update : 14-Dec-2023 I evaluated the above ratios for consecutive prime gaps for $p_n > 10^{40}, p_n > 10^{50}$ and $p_n > 10^{60}$ respectively. The limiting value in these tests were $0.2592, 0.2551$ and $0.2511$ which show a very slow decreasing trend. Question : Does the above limit exist? If yes, what does it converge to?","['analytic-number-theory', 'limits', 'number-theory', 'prime-numbers']"
4763397,"Closed ideals of the continuous functions on the locally compact space $X$ vanishing at infinity, $C_0(X)$, with Stone-Weierstrass theorem","I am reading the book ""Operator Algebras and Quantum Statistical Mechanics"" by O. Bratteli and D. W. Robinson, and Example 2.1.9 says the following: Let $\mathfrak{A}=C_0(X)$ , the commutative $C^*$ -algebra(...). If $F$ is a closed subset of $X$ , and $\mathfrak{B}$ consists of the elements in $\mathfrak{A}$ which are zero on $F$ then $\mathfrak{B}$ is a closed two-sided ideal of $\mathfrak{A}$ (...). Using the Stone-Weierstrass theorem one can show that each closed, two-sided ideal in $\mathfrak{A}$ has this form. Here $X$ is a locally compact Hausdorff space. I found a proof which shows this fact for compact $X$ using Stone-Weierstrass theorem ( Ideal in $C(X)$ ), and I tried to show the statement above based on this argument. Unfortunately, in the link we need to use that $X/F$ is compact when $X$ is compact and $F$ is closed, which is not true for locally compact space: i.e. $X/F$ could be not locally compact when $X$ is locally compact and $F$ is closed(see Quotient of a locally compact space ). This makes us hard to use the Stone-Weierstrass theoem, since we do not know the ${}^*$ -subalgebra of $C_0(X/F)$ which separates points and vanishes nowhere is dense(see https://en.wikipedia.org/wiki/Stone%E2%80%93Weierstrass_theorem for definitions). Thus, what should I do? Am I missing something, or is Stone-Weierstrass theorem also holds for the quotiented locally compact space? Or should I take a different route?","['c-star-algebras', 'general-topology', 'functional-analysis']"
4763428,"Is it possible to integrate $\frac{ \tan ^{-1}(t)}{t^{2n}\,\sqrt{t^2-1}}$","Working on this question , I faced the problem of computing: $$I_n=\int_1^a \frac{ \tan ^{-1}(t)}{t^{2n}\,\sqrt{t^2-1}}\,dt$$ For a given value of $n \geq 1$ , Mathematica does not face any problem and the results are quite simple. For example, if $a=\sqrt 3$ as in the linked question $$I_{5}=\frac{8346321-4992192 \sqrt{2}+3246848 \sqrt{6}}{58786560}\pi+$$ $$\frac{7867 \sqrt{2}-309123 \cot ^{-1}\left(\sqrt{2}\right)}{1088640}$$ My question is : Is it possible to find the antiderivative even in terms of special functions ?","['integration', 'trigonometry', 'special-functions']"
4763442,Differential equation $f''-f'-f=1$,"Suppose $f:\Bbb R\rightarrow\Bbb R$ is a solution of $f''-f'-f=1$ and $f(0)=f(k)=0$ for some $k>0$ . Then, $f$ has positive and negative values over $(0,k)$ $f$ has only positive values over $(0,k)$ $f$ has only negative values over $(0,k)$ $f=-1$ on $(0,k)$ I have done a similar ques in which the differential equation was $f''-f'-1=0$ and I thought of it like there would be some $c\in (0,k)$ such that $f'(c)=0$ and at c the differential equation will give $f''(c)=1$ and that will be true for all stationary points and therefore there will be no maxima and we can conclude that the funtion will be below the x axis always. But i was not able to do same for this question.","['derivatives', 'ordinary-differential-equations']"
4763451,Number of sequences that satisfy the absolute difference condition,"Let $x_0 =0$ and let $x_1,.....x_{10}$ satisfy that $|x_i - x_{i-1}|$ = 1 for 1≤i≤10 and $x_{10} = 4$ . How many such sequences are there satisfying these conditions? I tried to calculate it by backtracking from $x_0$ and $x_{10}$ , and built an entire tree for the possible values. Based on the edges of the trees, I calculated the answer to be $2*4*6*7*7*7*7*6*4*2$ but the answer is clearly wrong. The question is supposed to be a probability question, but I was thinking of trying to solve it using dynamic programming. It is supposed to be an easy question though, can anyone help me out?","['trees', 'combinatorics', 'dynamic-programming', 'sequences-and-series', 'probability']"
4763558,"Can the following nested sum be stated generally as a binomial coefficient, or ""nicely"" in any other way?","$$\sum_{n_m>n_{m-1}>\dots>n_1\ge 1}n_1(-1)^{(n_1+n_2+...+n_m)} $$ I know for the case where the terms are all positive, i.e: $$\sum_{n_m\ge n_{m-1}\ge\dots\ge n_1\ge 1}n_1 $$ You retrieve the $m$ -dimensional equivalent of the $n_m$ th ""tetrahedral"" number given by $\binom{n_m+m-1}{m}$ . I was wondering if the same was true for the above. When I try to work it out, I end up picking up so many extra terms that I can't trust myself to not make any mistakes.",['combinatorics']
4763563,Expected number of points inside a disc with center inside a square,"Let's say we have $n$ points that are uniformly, identically, and independently distributed in a square of side length $l$ . Now, we take a disk of radius $r\leq l/2$ with the center randomly placed inside the square. How many points are expected to be inside the disk? Initially, I was making an approximation based on the areas of the disk and square: $$\frac{\pi r^2 n}{l^2}.$$ However, this ignores the fact that when the center of the disk is closer to the edge, we would have a lesser number of points. So, I tried dividing the main square into parts, as shown in the figure below. AKME is a square of side of side $r$ . Now, the previous result holds true for the innermost square region, with reduced side length. I will need to find out the expected area for one of the smaller squares and one of the side rectangles, and then I can multiply by 4. Now, the side rectangles can be treated as the expected area if the center lies on the line KM, and then we can multiply by the side length MN. I used calculus and circular segments to compute it as (hopefully correctly): $$ (l-2r)\left(\pi r^2 r - \int_0^\pi \frac{r^2}{2}(\theta-\sin \theta)d\theta\right) = (l-2r)\left(\pi r^3 - \frac{r^2 (\pi^2-4)}{4}\right).$$ I guess I could do something similar with the corner squares as well, which would require double integration. Is the approach correct? Is there a simpler way? Would I be counting the area on the intermediate sides such as MN multiple times?","['geometry', 'probability']"
4763574,Is there an expression for $I(n)=\int_{0}^{\frac{\pi}{4}}x\tan^{n}x dx$?,"I've played around a little with this integral, and I can straightforwardly evaluate it with a substitution $\tan x\mapsto x$ in terms of the Beta function if the bounds were $(0,\pi /2)$ . But for the bounds $(0,\pi /4)$ the substitution takes the bounds to $(0,1)$ which can't be done with the Beta function. Alternatively, if we substitute $\tan 2x \mapsto x$ , we get that $$I(n)=\frac{1}{4}\int\limits_{0}^{\infty}\frac{\left(\sqrt{x^{2}+1}-1\right)^{n}\tan^{-1}x}{x^{n}\left(1-x^{2}\right)}dx=\frac{1}{4}\int\limits_{0}^{\infty}\frac{x^{n}\tan^{-1}x}{\left(1-x^{2}\right)\left(\sqrt{x^{2}+1}+1\right)^{n}}dx$$ I'm wondering if there is a nice expression for this integral. Side note, I'm only actually interested in what it is for $n\geq1$ . Checking with Wolfram Alpha, it seems that the integral behaves slightly differently for odd and even $n$ . For $n=2k-1$ , $k$ $n$ $I(2k-1)$ $1$ $1$ $\frac{1}{2}G-\frac{\pi}{8}\ln 2$ $2$ $3$ $-\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{1}{4}\pi+\frac{1}{2}\right)$ $3$ $5$ $\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{1}{4}\pi+\frac{2}{3}$ $4$ $7$ $-\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{1}{3}\pi+\frac{73}{90}\right)$ $5$ $9$ $\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{1}{3}\pi+\frac{284}{315}$ $6$ $11$ $-\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{23}{60}\pi+\frac{3103}{3150}\right)$ $7$ $13$ $\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{23}{60}\pi+\frac{54472}{51975}$ $9$ $15$ $-\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{44}{105}\pi+\frac{10459489}{9459450}\right)$ (where $G$ is Catalan's constant.) $I(n)$ for odd $n$ takes the form of $(-1)^{k-1}\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-p_{k}\pi+q_{k}\right)$ where $p$ and $q$ form some kind of sequence of rational numbers. If we plot a graph of $p_{k}$ (purple) and $q_{k}$ (red) against $k$ , we get something that looks like a logarithm but is also not really: Whereas for $n=2k$ , $k$ $n$ $I(2k)$ $1$ $2$ $\frac{1}{4}\pi-\frac{1}{32}\pi^{2}-\frac{1}{2}\ln 2$ $2$ $4$ $-\left(\frac{1}{6}+\frac{1}{6}\pi-\frac{1}{32}\pi^{2}-\frac{2}{3}\ln2\right)$ $3$ $6$ $\frac{13}{60}+\frac{13}{60}\pi-\frac{1}{32}\pi^{2}-\frac{23}{30}\ln 2$ $4$ $8$ $-\left(\frac{29}{105}+\frac{19}{105}\pi-\frac{1}{32}\pi^{2}-\frac{88}{105}\ln2\right)$ $5$ $10$ $\frac{2333}{7560}+\frac{263}{1260}\pi-\frac{1}{32}\pi^{2}-\frac{563}{630}\ln 2$ The first thing I noticed was the denominator. If we make them the same each time, we get $k$ $n$ $I(2k)$ $1$ $2$ $\frac{1}{4}\pi-\frac{1}{32}\pi^{2}-\frac{2}{4}\ln 2$ $2$ $4$ $-\left(\frac{1}{6}+\frac{1}{6}\pi-\frac{1}{32}\pi^{2}-\frac{4}{6}\ln2\right)$ $3$ $6$ $\frac{13}{60}+\frac{13}{60}\pi-\frac{1}{32}\pi^{2}-\frac{46}{60}\ln 2$ $4$ $8$ $-\left(\frac{29}{105}+\frac{19}{105}\pi-\frac{1}{32}\pi^{2}-\frac{88}{105}\ln2\right)$ $5$ $10$ $\frac{2333}{7560}+\frac{1578}{7560}\pi-\frac{1}{32}\pi^{2}-\frac{6756}{7560}\ln 2$ Which indicates that $I(n)$ for even $n$ takes the form of $(-1)^{k-1}\left(-\frac{1}{32}\pi^{2}+\frac{1}{r_{k}}\left(a_{k}+b_{k}\pi-c_{k}\ln{2}\right)\right)$ where $r,a,b,c$ form a sequence in the natural numbers. Plotting $r$ (black), $b$ (blue) and $c$ (green) against $k$ yields these exponential graphs: But $a_{1}=0$ , and its graph (red) looks like this: Seems like they're in pairs, but I also fail to see any relation between the numbers at all. If we plot $\frac{a}{r},\frac{b}{r},\frac{c}{r}$ against $k$ , we get We see that $\frac{b}{r}$ approaches some value around $0.19$ . None of the number sequences mentioned above show up on OEIS. I have been stuck here for a few days, and any insight would be highly welcomed. Kisaragi Ayami","['integration', 'definite-integrals', 'calculus', 'taylor-expansion', 'catalans-constant']"
4763586,Is this example of 1-dimensional geometric class field theory correct?,"I'm trying to understand the main theorem of geometric class field theory. Could someone tell me if this example is correct? Main theorem. Let $K$ be a function field of a curve over a finite field. There is a bijection between unramified $\ell$ -adic Galois representations of $G_K := \operatorname{Gal}(K^{sep}/K)$ and $\ell$ -adic characters of $K^{\times}\backslash\mathbf{A}_K^{\times}/\mathcal{O}_K^{\times}.$ (Here I mean the ideles modulo the diagonal on the left, and on the right quotiented by the subgroup of ideles which have non-negative valuation at every place.) I was trying to understand what this means when $K = \mathbb{F}_p(T),$ say. In that case, I think unramified Galois representations are the same as representations of $\operatorname{Gal}(K^{un}/K) = \operatorname{Gal}(\overline{\mathbf{F}_p}(T)/\mathbf{F}_p(T))= \hat{\mathbf{Z}}.$ -- On the other side, I believe that I can simplify that double quotient as follows. The places of $K$ are described as follows: there is one place with uniformizer $1/T,$ and then for every monic irreducible polynomial $f(T) \in \mathbb{F}_p[T],$ there is a place with uniformizer $f.$ These are distinct places, and every place is of one of these two forms. There is a surjective map $\mathbf{A}_K^{\times}\to \bigoplus_{v\in P} \mathbf{Z},$ for $P$ the set of places of $K,$ sending an idele to its valuation at each place. The kernel is precisely $\mathcal{O}_K^{\times},$ and so $$\mathbf{A}_K^{\times}/\mathcal{O}_K^{\times} \cong \bigoplus_{v\in P} \mathbf{Z}.$$ The diagonal embedding of $K^{\times}$ then corresponds to the subgroup of $\bigoplus_{v\in P}\mathbf{Z}$ consisting of elements whose sum is $0.$ In particular, the quotient by the diagonal subgroup leaves us with just $\mathbf{Z}.$ As a sanity check, $\operatorname{Pic}(\mathbb{P}^1) = \mathbf{Z},$ as found in any book on algebraic geometry, and I believe part of the proof of geometric class field goes by identifying the double quotient with the Picard group, so it makes sense we got $\mathbf{Z}$ here. -- So, I think that in this case, it is telling me that continuous homomorphisms $\rho : \hat{\mathbf{Z}} \to \overline{\mathbf{Q}_{\ell}}^{\times}$ are in bijection with continuous homomorphisms $\mathbf{Z}\to \overline{\mathbf{Q}_{\ell}}^{\times}.$ But this surely is incorrect -- the image of a map out of the profinite integers must be compact, but the image out of $\mathbf{Z}$ is not. So, where have I made a mistake?","['class-field-theory', 'number-theory', 'algebraic-geometry']"
4763635,Solving a non-linear Bernoulli ODE with a power substitution,"So I have this problem where I have a differential equation on the form $$\frac{dy}{dt}=ay-\frac{a}{b^2}y^3$$ In this case I am only interested in the positive solution to the equation. Now since this is a non-linear ODE, it appeared somewhat tedious to solve, but then I recognised that it was infact an equation on the form $$y'+p(x)y=q(x)y^\beta$$ With $p(x)=-a$ and $q(x)=-a/b^2$ ,
so using the substitution $u=y^{1-\beta}$ we can write the equation as $$u'+(1-\beta)py=(1-\beta)q$$ Now for convenience we define $\gamma=(1-\beta)p$ and $\delta=(1-\beta)q$ such that the relationship between $\gamma$ and $\delta$ is $$\delta=\frac{q}{p}\gamma$$ Since we have reduced the non-linear ODE to a linear ODE, I thought it be wise to throw the laplace transform at it, so we end up with $$U(s)=\frac{q}{p}\frac{\gamma}{s(s+\gamma)}+\frac{U(0)}{s+\gamma}$$ Taking the inverse laplace transform and using $q/p=1/b^2$ and $\gamma=(1-\beta)p=(1-3)(-a)=2a$ , will then give $$u(t)=\frac{q}{p}(1-e^{-\gamma t})+U(0)e^{-\gamma t}=\frac{1}{b^2}(1-e^{-2at})+c_1e^{-2at}=\frac{e^{2at}-1+b^2c_1}{b^2e^{2at}}$$ Where U(0) is just some constant $c_1$ .
Resubbing in $u(t)=y^{1-\beta}=y(t)^{-2}$ , inverting and then taking the square root yields $$y(t)=\frac{|b|e^{at}}{\sqrt{e^{2at}+b^2c_1-1}}$$ . However, when running this equation through Wolfram (y'know just in case...) I get the solution $$y(t)=\frac{be^{\frac{1}{2}(2at+2b^2c_1)}}{\sqrt{e^{2at+2b^2c_1}-1}}$$ And I am for the lack of better words too daft to see where I done goofed. If anyone immediately sees where it is I would love to have it pointed out.",['ordinary-differential-equations']
4763652,To show the given limit does not exist,"Given the following function $$f(x)=2 x \sin \left(\frac{1}{x}\right)-\cos \left(\frac{1}{x}\right) ~~ \text{for} ~~ x \neq 0 ,$$ to show that $\displaystyle \lim _{x \rightarrow 0} f(x)$ not exist, I take a sequence $x_n = \dfrac{1}{2n \pi}$ and conclude that though $x_n \rightarrow 0$ as $n \rightarrow \infty$ , $$f \left( x_n \right) = -\cos (2n\pi) = -1 \not\rightarrow f(0).$$ Is this argument correct ? Or do I have to come up with two sequences, both of which converge to zero but the function has two different limits ?","['continuity', 'functions', 'analysis', 'real-analysis']"
4763683,Why is the abstract functorial definition of the tangent bundle not widely accepted?,"The following quote from page 595 of Spivak's Calculus exemplifies my viewpoint on definitions: It is an important part of a mathematical education to follow a construction of the real numbers in detail, but it is not necessary to refer ever again to this particular construction. It is utterly irrelevant that a real number happens to be a collection of rational numbers, and such a fact should never enter the proof of any important theorem about the real numbers. Reasonable proofs should use only the fact that the real numbers are a complete ordered field, because this property of the real numbers characterizes them up to isomorphism, and any significant mathematical property of the real numbers will be true for all isomorphic fields. This makes a lot of sense to me! This line of thought is very much in the spirit of mathematical abstraction, and is why, for example, we define vector spaces in terms of their operations rather than geometric properties. Now, onto the question. Recently I've been learning about the tangent bundle, and in my view the best definition of it that I can see is as follows: There exists a unique functor $T$ (up to natural equivalence) from the category of differentiable manifolds to the category of vector bundles, such that its restriction to Euclidean spaces is naturally equivalent to the trivialising functor (which sends $\mathbb R^n$ to its trivial bundle, and which sends a smooth map to its derivative), and its restriction to open submanifolds is naturally equivalent to the restriction of the functor. (This definition is given and proved in Chapter 3 of Spivak's Intro to Differential Geometry.) The image of $M$ under $T$ is the tangent bundle of $M$ . In my opinion, this definition is the most natural one for the tangent bundle. It emphasises the locally Euclidean nature of manifolds, as well as the idea that the pushforward is essentially the derivative of a given map. However, I have not seen many people give or endorse this definition. Most people define tangent vectors as equivalence classes of curves, or as point derivations. These definitions feel a lot less fundamental, like the definitions of real numbers involving Dedekind cuts or equivalence classes of Cauchy sequences. Everything you need to know about the tangent bundle can be inferred from the functorial definition, and in a more geometric way, so I can't see why the other definitions are still uncontested (at most, they allow for easy proofs that the tangent bundle functor $T$ actually exists). Thus, my question is the following: why isn't the functorial definition more commonly used? What is it about the curve-based or derivation-based definitions that saves them from being ""utterly irrelevant""?","['definition', 'soft-question', 'tangent-bundle', 'differential-geometry']"
4763711,Does $\mathbb{E}[g(X)Y]=0$ for all functions $g$ imply $\mathbb{E}[Y|X]=0$?,"Is there any result saying something like $$\mathbb{E}[g(X)Y]=0 \,\,\forall g\in\mathcal{G}\,\,\,\implies\mathbb{E}[Y\mid X]=0$$ where $\mathcal{G}$ is some function class? Have been searching online but didn't find anything useful. Context: I came across a paper where the objective function is of the form $\mathbb{E}[(X-Y)\mid X]=0$ but the authors instead use $\mathbb{E}[g(X)(X-Y)]=0$ for a class of $g\in\mathcal{G}$ in their actual implementation. I understand the reason is to avoid the conditional moment and replace it by the unconditional one, but are the two moments equivalent (the if direction is easy to show so I'm wondering the other direction...)?","['measure-theory', 'statistics', 'conditional-expectation', 'lp-spaces', 'probability-theory']"
4763750,When can standard deviation be equal to range,I was learning basic statistics and I read a proof that the standard deviation is always less than or equal to the range.  I don't understand how range can ever be equal to the standard deviation. I could only think of one case: when all data points have the same value. Is there any other case possible in which the equality holds?,['statistics']
4763772,Find the polynomial whose zeros are reciprocal of each other,"I have been trying this sum taking the zeros as $\alpha$ and $\alpha^{-1}$ , using the formula $x^2-(\alpha+\beta)x+\alpha \beta$ .
However I am stuck in this step: $$
\alpha x^2-(\alpha^2+1)x+\alpha=0.
$$ This could have been the answer, but $\alpha$ is not defined in the question and hence cannot be a part of the answer. I have searched the internet for this question but nowhere the answer seems to be available. The source of the question is unknown, I found this question in a really old school question paper and that school is not in existence anymore.","['linear-algebra', 'polynomials', 'roots']"
4763789,Three-sided pyramid with given base triangle and tip angles,"I have a practical problem that boils down to this geometric problem: I have a three-sided irregular pyramid where everything about the base triangle is known: all $3$ side-lengths $(a, b, c) $ and the angles $(\angle ab,\angle cb, \angle ac)$ . I also do know the $3$ angles at the tip of the pyramid $(α, β, γ)$ . What I want to calculate is the length of the remaining edges $e, f,$ and $g$ (that are connecting the base triangle with the tip). With the law of cosine, I get this as a starting point: $$a^2 = e^2 + f^2 - (2ef\cos(\alpha))$$ $$b^2 = f^2 + g^2 - (2fg\cos(\beta))$$ $$c^2 = g^2 + e^2 - (2ge\cos(\gamma))$$ When I try to solve this system of equations (using substitution and $pq$ -formula) I had to give up at a point where I had a really long equation to the power of $4$ . Is there a practical way in solving this? Thanks :-) UPDATE:
As mentioned in a comment by Paul Sinclare another approach to solve this problem would be the use of the law of sine: $$\frac{e}{sin(θ)}=\frac{a}{sin(\alpha)}=\frac{f}{sin(\alpha+θ)}$$ $$\frac{g}{sin(Φ)}=\frac{c}{sin(\gamma)}=\frac{e}{sin(\gamma+Φ)}$$ $$\frac{g}{sin(Ω)}=\frac{b}{sin(\beta)}=\frac{f}{sin(\beta+Ω)}$$ θ = angle between a and f Φ = angle between e and c Ω = angle between b and f Trying to solve these equations for one angle also results in a huge equation I'm not able to solve by hand anymore. Any advice on how I should proceed?","['trigonometry', 'geometry', '3d']"
4763828,Concatenated diagonalization of combined real/imaginary diagonalization,"I have a problem involving a complex matrix that I need to diagonalize and apply weights to the entries according to a function relating only to the eigenvalues of the real part of the matrix. Suppose that I have diagonalized separately the real and imaginary parts of $ A=A_r+iA_i $ such that: $ A_r=U_r\Lambda_rU_r^{-1} $ and $ A_i=U_i\Lambda_iU_i^{-1} $ . What I need to do next is calculate a weighted ""error"" norm which, given two complex vectors $ x,\ y $ is written as: $ \sum_{i=1}^N w_i|y-Ax|_i^2 $ and $ A=U_r\Lambda_rU_r^{-1}+iU_i\Lambda_iU_i^{-1}  $ I then rewrite the problem as: $ \begin{bmatrix} y_r \newline y_i \end{bmatrix}=\begin{bmatrix} A_r & -A_i \newline A_i & A_r \end{bmatrix} \cdot \begin{bmatrix} x_r \newline x_i \end{bmatrix} $ I thought that to correctly apply weights to my rows, I would first need to find a new $ 2N\times 2N $ orthogonal matrix $ U $ such that $ \tilde{y}=U^{-1}\begin{bmatrix} y_r \newline y_i \end{bmatrix},\ \tilde{x}=U^{-1}\begin{bmatrix} x_r \newline x_i \end{bmatrix} $ and $ \sum w_i|y-Ax|_i^2 = \sum w_i|\tilde{y}-\Lambda\tilde{x}|_i^2 $ where $ \Lambda $ would be a new diagonal matrix* and then I could correctly apply the weights to my rows according to some function of the $ [\Lambda_r]_{ii} $ for each $ i $ . Essentially, is there any way to find a new diagonalization $ U,\ \Lambda $ such that: $ \begin{bmatrix} U_r\Lambda_r U_r^{-1} & -U_i\Lambda_i U_i^{-1} \newline U_i\Lambda_i U_i^{-1} & U_r\Lambda_r U_r^{-1} \end{bmatrix} = U\Lambda U^{-1} $ Thanks for your inputs in advance! *(possibly $ \begin{bmatrix} \Lambda_r & 0 \newline 0 & \Lambda_i \end{bmatrix} $ ?)","['orthogonal-matrices', 'diagonalization', 'linear-algebra']"
4763841,$A \subset \ell^2(\Bbb Z)$ as a collection of Fourier coefficients,"Let $A$ be a closed subspace of $\ell^2(\Bbb Z)$ . Suppose for every $\{a_n\}_n \in A$ , we have $\{a_{n+m}\}_n \in A$ for each $m \in \Bbb Z$ . Show that there exists a measurable set $E\subset \Bbb T$ such that $$A = \{\{\hat f(n)\}_{n\in \Bbb Z}: f\in L^2(\Bbb T), \operatorname{supp} f \subset E\}$$ Let $\mathcal F: L^2(\Bbb T) \to \ell^2(\Bbb Z)$ be the usual map $f\mapsto \{\hat f(n)\}_{n\in \Bbb Z}$ . This is a surjective isometry, and so $\mathcal F^{-1}$ makes sense. My first guess for $E$ is $\bigcup_{f\in \mathcal F^{-1} (A)} \operatorname{supp} f$ but this may not even be a measurable set. I'd like some hints or ideas to complete this proof!","['fourier-analysis', 'functional-analysis', 'analysis']"
4763965,Proving that $(H_0^1)^\perp = H^\infty$,"The question is clear. Note that $H_0^1 =\{ g \in H^1 : g(0)=0\}$ , and $f \in H^1$ if $\sup \frac{1}{2\pi} \int \lvert f(re^{i \theta}) d \theta < \infty$ , and $H^\infty$ contains all bounded analytic functions. What I found that might work for this is the following: If $Y=H_0^1$ , by the definition, $Y^\perp = \{ f \in L^\infty : \langle g, f\rangle =0, \forall g \in H_0^1\}$ . Note that $z^n=e^{i n \theta}$ belongs to $H_0^1$ when $n>0$ . So integrating against it, it follows that any function in the dual must have all coefficients $a_m=0$ , for $m<0$ . However, a function in $L^{\infty}$ with that property is analytic so it is in $H^{\infty}$ , and if $f \in H^\infty$ , with the same reasoning it lies in $Y^\perp$ and hence, $Y^\perp =H^\infty$ . However, it doesn't seem to be clear to myself and I still don't see the part where we conclude the functions are analytic and hence lie in $H_0^1$ .","['complex-analysis', 'functional-analysis']"
4763994,"What is the max of $x+y+z$ where $(x,y,z)$ is a real solution of the system","I am trying to calculate the maximum of $x +y +z$ and $(x_0 ,y_0,z_0)$ is a real solution of the system: $$2x=y+ \frac{2}{y}$$ $$2y=z+ \frac{2}{z}$$ $$2z=x+ \frac{2}{x}$$ I tried to sum them and got that $$x+y+z=2\left( \frac{1}{y} + \frac{1}{z} +\frac{1}{x} \right)$$ and with $$(x+y+z)\left(\frac{1}{y} + \frac{1}{z} +\frac{1}{x} \right) ≥9,$$ I got $$x+y+z≥3\sqrt{2}.$$ I am stuck here because they want the maximum of the sum. Any help will be appreciated.","['systems-of-equations', 'functions']"
4764007,Show that the sum of these four vectors is $0$.,"Four vectors are erected perpendicularly to the four faces of a general tetrahedron. Each
vector is pointing outwards and has a length equal to the area of the face. Show that the sum of these four vectors is 0. Let $A, B,$ and $C$ be vectors representing the three edges starting from a fixed vertex. Express each of the four vectors in terms of $A, B$ , and $C$ , and show that their sum is the zero vector; do not introduce a coordinate system. I was trying to:
let's call the four vectors $$v_1,v_2,v_3,v_4$$ we know that: $$\frac{AC \times BC}{2} = v_1$$ I was trying to express the other vectors but I would need a fourth edge to do that  using origin as edge we have $$\frac{OC \times OA}{2} = v_2$$ $$\frac{OB \times OC}{2} = v_3$$ $$\frac{OA \times OB}{2} = v_4$$ hence: $$s =\frac{AC \times BC}{2} + \frac{OC \times OA}{2}+ \frac{OB \times OC}{2} + \frac{OA \times OB}{2}$$ $$s = \frac{1}{2}((AC \times BC) + (C \times A) + (B \times C )+ (A \times B) )$$ $$s = \frac{1}{2}(((C-A) \times (C-B)) + (C \times A) + (B \times C )+ (A \times B) )$$","['proof-explanation', 'cross-product', 'linear-algebra', 'geometry']"
4764029,Fourier transform of $\frac{1-e^x}{1+e^x}$,"I was trying to compute $\int_{-\infty}^{\infty}e^{ikx}\frac{1-e^x}{1+e^x}\, dx$ from a Mathematical trivium . I tried first with contour integration but finding the right shape was hard. I gave it a go with a rectangle, with corners at $R, R+i\pi, -R+i\pi$ and $-R$ with a detour around $i\pi$ : $$\oint_C=\int_{-R}^{R}{e^{ikx}\frac{1-e^x}{1+e^x}\, dx}+\int_{0}^{\pi}{e^{ik(R+iz)}\frac{1-e^{R+iz}}{1+e^{R+iz}}\, dz}+\int_{R}^{-R}{e^{ik(z+i\pi)}\frac{1-e^{z+i\pi}}{1+e^{z+i\pi}}\, dz}+\int_{\pi}^{0}{e^{ik(-R+iz)}\frac{1-e^{-R+iz}}{1+e^{-R+iz}}\, dz}-i\pi\mathrm{Res}(z=i\pi)=0$$ But I'm not sure how to make progress here. For example the 3rd integral becomes : $$\int_{-R}^{R}{e^{ikz}\frac{1+e^z}{1-e^{z}}\, dz}$$ Which is not the same as the initial integral on the real axis. Can this be continued or should a different contour/ different integration method be used?","['integration', 'complex-analysis', 'fourier-analysis']"
4764052,How do I go about finding $\int\limits_{0}^{\frac{\pi}{4}}x\ln\left(1+\tan x\right)dx$?,"By some analysis and through Wolfram|Alpha I know that the integral in question is equal to a fascinating $$I=\int\limits_{0}^{\frac{\pi}{4}}x\ln\left(1+\tan x\right)dx=\frac{21}{64}\zeta(3)+\frac{\pi^{2}}{64}\ln 2-\frac{\pi}{8}G$$ where $G$ is Catalan's constant. However, I have tried many methods to evaluate this integral, all to no avail.
Using the Maclaurin series for $\ln(1+\tan x)$ unfortunately produces $$I=\sum\limits_{k=0}^{\infty}\frac{\left(-1\right)^{k}}{k+1}\int\limits_{0}^{\frac{\pi}{4}}x\tan^{k+1}xdx$$ the integral in which is particularly hard to deal with - spawning this question of mine , the answers and comments to which destroyed my dreams of continuing down this path. Alternatively, differentiating under the integral sign with $$I(n)=\int\limits_{0}^{\frac{\pi}{4}}x\ln\Big(\tan\left(nx\right)+1\Big)dx\Rightarrow I'(n)=\int\limits_{0}^{\frac{\pi}{4}}\frac{x}{n+\tan x}dx$$ looks equally hopeless after a few calculations. Integration by parts does not seem to work very well because the antiderivative of $\ln\left(1+\tan x\right)$ is absolutely hideous. Perhaps Clausen functions can help? Or maybe the Fourier series of $\ln\left(1+\tan x\right)$ which I unfortunately am unfamiliar with... In any case, the existence of $\zeta(3)$ and $G$ in the answer scream an infinite sum, and the fractional coefficients also hint at some substitutions that could aid us along the way - but my ideas stop here. Any insights are greatly appreciated.","['integration', 'calculus', 'trigonometric-integrals', 'taylor-expansion', 'sequences-and-series']"
4764104,Let $D:\mathbb{R}(x)\to\mathbb{R}(x)$ be the algebraic(!) differential operator such that $D(x)=1$. Is it true that $D(c)=0$ for all $c\in\mathbb{R}$?,"Define the field of rational functions $\mathbb{R}(x)$ with algebraic differential operator $D:\mathbb{R}(x)\to\mathbb{R}(x)$ such that $D(x)=1$ . By algebraic differential operator, we mean a mapping such that the additive rule and product rule apply for all $f,g\in\mathbb{R}(x)$ : $$D(f+g)=D(f)+D(g),$$ $$D(fg)=fD(g)+gD(f).$$ Also, with this definition of the derivative, the following are easy to prove: $D(0)=D(1)=0$ ; $D(-f)=-D(f)$ ; $D\left(\frac{f}{g}\right)=\frac{gD(f)-fD(g)}{g^2}$ for $g\neq0$ ; $D(f^n)=nf^{n-1}D(f)$ for every $n\in\mathbb{Z}$ and $f\neq0$ ; If $c\in\mathbb{R}(x)$ is such that $D(c)=0$ , then $D(cf)=cD(f)$ . I want to prove that, for all $c\in\mathbb{R}$ , we have $D(c)=0$ . I've already proved that this is true if $c\in\mathbb{Q}$ . I wanted to use an argument that involved sequences, like using the fact that for every $c\in\mathbb{R}$ we could define a sequence $(c_n)\subseteq\mathbb{Q}$ such that $c_n\to c$ . However, this doesn't work, as the differential operator is (usually) not continuous, and we can't just do $$D(c)=D\left(\lim_{n\to\infty}c_n\right)=\lim_{n\to\infty}D(c_n)=\lim_{n\to\infty}0=0.$$ Hence, I'm stumped. For now I've been defining the field of constants of $\mathbb{R}(x)$ as $\mathbb{R}$ , but I would like to know if this result can be proved just using algebra and non-differential tools from analysis.","['field-theory', 'abstract-algebra', 'derivatives', 'differential-algebra']"
4764136,ODE's: Continuity Equation,"The context of this question is Machine Learning (more specifically, my question results from this paper , yet I have a math question, so I'm posting it here). First of all, some definitions (Sec. 2 of the mentioned paper): Let $\mathbb{R}^{d}$ denote the data space with data points $x = (x^{1}$ , $\dots$ , $x^{d})\in\mathbb R^{d}$ . Two important objects we use in this paper are: the probability density path $p: [0, 1]\times\mathbb R^{d} \rightarrow \mathbb R_{> 0}$ , which is a time dependent probability density function, i.e. $\int p_{t}(x)dx = 1$ , and a time-dependent vector field , $v: [0, 1]\times \mathbb R^{d}\rightarrow\mathbb R^{d}$ . A vector field $v_{t}$ can be used to construct a time-dependent diffeomorphic map, called a flow , $\phi: [0, 1]\times \mathbb R^{d} \rightarrow \mathbb R^{d}$ , defined via the ordinary differential equation (ODE): $$\frac{d}{dt}\phi_{t}(x) = v_{t}(\phi_{t}(x)) \tag{1}\label{eq:cnf}$$ $$\phi_{0}(x) = x\tag{2}$$ [...] A CNF [Continuous Normalizing Flow] is used to reshape a simple prior density $p_{0}$ density ( e.g. , pure noise) to a more complicated one, $p_{1}$ , via the push-forward equation $$\tag{3}\label{eq:push_forward} p_{t} = \left[\phi_{t}\right]_{\star}p_{0}$$ where the push-forward (or change of variables) operator $\star$ is defined by $$\left[\phi_{t}\right]_{\star}p_{0}(x) = p_{0}(\phi_{t}^{-1}(x))\det\left[ \frac{\partial \phi_{t}^{-1}}{\partial x}(x) \right].$$ A vector field $v_{t}$ is said to generate a probability density path $p_{t}$ if its flow $\phi_{t}$ satisfies equation $\eqref{eq:push_forward}$ . One practical way to test if a vector field generates a probability path is using the continuity equation [...], see Appendix B. The continuity equation given in App. B is (cf. Eq. (26)): $$\tag{26}\label{eq:continuity}\frac{d}{dt}p_{t}(x) + \text{div}(p_{t}(x)v_{t}(x)) = 0,$$ where $\text{div} = \sum_{i=1}^{d}\frac{\partial}{\partial x^{i}}$ I'd like to show that the $v_{t}$ from Eq. $\eqref{eq:cnf}$ satisfies the continuity equation $\eqref{eq:continuity}$ (this should kinda trivially hold by definition, but I'd like to do it explicitly via the continuity equation). The LHS of $\eqref{eq:continuity}$ is: $$\frac{d}{dt}p_{t}(x) = \frac{d}{dt}\left( p_{0}(\phi_{t}^{-1}(x))\det\left[ \frac{\partial \phi_{t}^{-1}}{\partial x}(x) \right]\right)$$ and the RHS $$\text{div}(p_{t}(x)v_{t}(x)) = \text{div}\left(p_{0}(\phi_{t}^{-1}(x))\det\left[ \frac{\partial \phi_{t}^{-1}}{\partial x}(x) \right]\frac{dx}{dt}\right)$$ Now, on the LHS, we have the time-derivative of the determinant, but not on the RHS, so I was wondering whether I'm on the right track? Any help would be appreciated.","['machine-learning', 'stochastic-processes', 'transport-equation', 'ordinary-differential-equations']"
4764226,"Given $p\in[0,1]$ form a set $\Omega$ and a function $f$ such that $\{f = 1\} = p$ and $\{f = 0\} = 1-p$","Given $p\in[0,1]$ is it always possible to form a set $\Omega$ and a function $f$ such that the expressions below are true? $$
\begin{align}
    \frac{|\{\omega\in\Omega\,:\, f(\omega) = 1\}|}{|\Omega|} &= p \\
    \frac{|\{\omega\in\Omega\,:\, f(\omega) = 0\}|}{|\Omega|} &= 1-p
\end{align}
$$ Ideally, I would like $\Omega$ to always be finite, but I recon this could be difficult when $p$ is irrational, althogh the fact that one can choose $f$ might actually make this possible. Context I am trying to write down a detailed definition of a Bernoulli random variable and of its distribution using measure theory. I am working ""backwards"" from the distribution, to figure out all the measurable spaces and functions involved. Bernoulli Distribution : Discrete Probability Measure : Here's the definition of a discrete measure. Let $(\mathsf{E}, \Sigma_\mathsf{E})$ be any measurable space, let $\mathsf{D}\subset\mathsf{E}$ be a countable subset of $\mathsf{E}$ . For any $x\in\mathsf{D}$ let $m(x)$ be a positive number, such that $\sum_{x\in\mathsf{D}} m(x) = 1$ . Then $$
\eta(\mathsf{A}) = \sum_{x\in\mathsf{D}} m(x) \delta_x(\mathsf{A}) \qquad \mathsf{A}\in\Sigma_\mathsf{E}
$$ is a valid probability measure, and we call all distributions of this form discrete probability measures. Bernoulli Distribution : This makes me believe that the Bernoulli distribution, for $p\in[0, 1]$ is defined as $\text{Ber}_p:\Sigma_\mathsf{E}\to\{p, 1-p\}$ $$
\text{Ber}_p(\mathsf{A}) = \sum_{x\in\{0, 1\}} p^x (1 - p)^{1-x}\delta_x(\mathsf{A})
$$ for any measurable set $\mathsf{A}$ . The challenge is understanding what sigma algebra these sets come from, i.e. what is $(\mathsf{E}, \Sigma_\mathsf{E})$ in this case? By definition $\{0, 1\}\subset\mathsf{E}$ , but there are infinitely many such sets, so one has to choose a sensible one. Counting Measure : To try and figure out $(\mathsf{E}, \Sigma_\mathsf{E})$ I tried to think about a dominating measure on the same space. The classical dominating measure is the counting measure $$
d\text{count}(\mathsf{A}) = \begin{cases}
    \text{number of elements in } \mathsf{A} & \text{ if } \mathsf{A} \text{ is finite.} \\
    \infty & \text{ if } \mathsf{A} \text{ if infinite.}.
\end{cases}
$$ This doesn't tell us what $(\mathsf{E}, \Sigma_\mathsf{E})$ is though. Bernoulli Random Variable : To try and figure this out, I tried thinking about the Bernoulli random variable $X$ that has $\text{Ber}_p$ as its distribution. Of course, the random variable must take values in $\{0, 1\}$ , but the domain of this random variable is unclear to me. However, by definition, if $\text{Ber}_p$ is the distribution of a random variable, there must exist another probability space $(\Omega, \Sigma_\Omega, \lambda)$ such that $$
\text{Ber}_p = \lambda\circ X^{-1}
$$ These two things combine tell me that $(\mathsf{E}, \Sigma_\mathsf{E}) = (\{0, 1\}, 2^{\{0, 1\}})$ , where $2^{\{0, 1\}}$ is the power set of $\{0, 1\}$ , since we know the values that $X$ takes. However, I now need to figure out $(\Omega, \Sigma_\Omega, \lambda)$ . My guess is that $\lambda$ is the counting measure on some countable measurable set. Then, I tried to guess that given $p\in[0, 1]$ one would construct $\Omega$ and $X$ so that the expressions in the original question hold.","['calculus', 'elementary-set-theory', 'descriptive-set-theory', 'algebra-precalculus', 'set-theory']"
4764228,Average distance from point to unit circle,"If I measure the average distance from the origin to the points of the unit circle, obviously the answer is 1. But if I instead measure the average distance from the point (0.1, 0) to the unit circle, I get this integral: $$\frac1{2\pi}\int_0^{2\pi} \sqrt{(\cos(t)-0.1)^2 + (\sin(t))^2} dt \neq 1 $$ Is there a nice intuitive explanation why this ""average distance"" is not 1? I think of this as averaging all rays from (0.1,0) to the circle- some of these are less than 1, and some are more than 1. Intuitively, I had expected this average to also be 1. Why is it different?","['analytic-geometry', 'calculus']"
4764252,Existence and Uniqueness of ODEs under weaker Lipschitz continuity condition.,"It is well known that if $f:\mathbb{R}^n\to\mathbb{R}^n$ is locally Lipschitz at $x_0$ , i.e., there exists a neighborhood $U$ of $x_0$ and $L>0$ such that \begin{align*}
\|f(x)-f(y)\|\leq L\|x-y\|
\end{align*} for all $x,y\in U$ then the ODE $\dot{x}=f(x)$ with initial condition $x(0)=x_0$ has a unique solution.
However, assume that we only know that $f$ satisfies the following weaker condition:
there exists a neighborhood $U_2$ of $x_0$ and a constant $L_2>0$ such that \begin{align*}
\|f(x)-f(x_0)\|\leq L_2\|x-x_0\|
\end{align*} for all $x\in U_2$ .
Does existence and uniqueness also hold here? If not, what is a counterexample?",['ordinary-differential-equations']
4764283,A cone through two circles on a sphere,"In page 37 of Blaschke's Vorlesungen Über Differentialgeometrie , vol. III, when proving a theorem on Möbius transformations the author says ""Denn durch zwei Kugelkreise läßt sich bekanntlich immer ein Kegel zweiter Ordnung legen, ..."" . In a free translation: ""As is well-known, there is always a second-order cone through two circles on a sphere"". Although I know how to prove the above fact by interpreting the map of the sphere onto itself given by a central projection in terms of a Lorentzian reflection on the space $\mathbb{R}^4$ of homogeneous coordinates, I would be happy to see a more geometric argument which constructs the vertex of such a cone (let's say, some argument that Poncelet, or even Euclid, would find).",['geometry']
4764308,Limit of a time dependent series.,"I have the following problem. Let $\sum_{n}c_{n}(t)$ be a bounded series, in particular $c_{n}(t)>0$ for all $t>0$ and $n$ and $\sum_{n}c_{n}(t)<1 $ for all $t>0$ . Furthermore, assume the following $$
\lim_{t\rightarrow \infty}\sum_{n}c_{n}(t) = 0
$$ and $$
\sum_{n}\sqrt{c_{n}(t)}<1 \;\; (\forall t>0).
$$ I would like to show that $$
\lim_{t\rightarrow \infty}\sum_{n}\sqrt{c_{n}(t)} = 0 
$$ What I Have tried: I have considered using DCT and WMT theorems but to no avail. The issue I have is that I do not have an explicit form for the $c_{n}$ so I can not dominate this sequence in order to apply the Wierstrass M test and or the Dominated convergence theorem. I have also considered the monotone convergence theorem but this does not work since I have no assumptions regarding monotonicity. Nevertheless, it seems that this problem should be provable; I am just not having any luck. Approaching it by contradiction and showing that there will be an infinite amount of $t>0$ such that at least one $c_{n}(t)$ is infinitely often bounded away from zero seems like the only path but I would rather not prove by contradiction. Any help would be very much appreciated.","['analysis', 'real-analysis', 'calculus', 'sequences-and-series', 'limits']"
4764348,Computing $E\left[\log\left(1 + \frac{\sum X_i}{n}\right)\right]$ when $X_i$ is iid $Geom\left(e^{-\lambda}\right)$,"Originally, I was attempting to find a Method of Moments estimator for $\lambda$ given $X_i \sim Geom(e^{-\lambda})$ s.t. $f_\lambda(x) = e^{-\lambda}(1 - e^{-\lambda})^x$ . I found it to be $\hat{\lambda} = \log\left(1 + \frac{\sum_{i=1}^n X_i}{n}\right)$ .  I am now attempting to verify if it is unbiased ( $E\left[\hat{\lambda}\right] \stackrel{?}{=} \lambda$ ). This leads to a super nasty summation: $$
E\left[\log\left(1 + \frac{\sum_{i=1}^n X_i}{n}\right)\right] = \sum_{k=0}^\infty \log\left(1 + \frac{k}{n}\right)\cdot 
\underbrace{\pmatrix{k + n - 1 \\ k} 
\cdot (1 - e^{-\lambda})^k e^{-n\lambda}}_\text{Negative binomial pmf}
$$ Note that $\sum X_i \sim NB(n, e^{-\lambda})$ . My thoughts: I am convinced that the sum is either divergent or not at all equal to $\lambda$ . Are there any tools I could use to indirectly state this? Is there a feasible pen/paper way to calculate the exact sum or should this be left for something like Mathematica?","['expected-value', 'statistics', 'probability', 'sequences-and-series']"
