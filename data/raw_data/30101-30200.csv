question_id,title,body,tags
281650,Derivative definition,"Let $f$ be a differentiable function in $x_0$. Calculate the following $\lim$:
$$\lim_{h\to 0}\frac{f(x_0+2h)-f(x_0-h)}{5h}$$ since we know from theory that $f'(x_0)=\lim_{h\to 0}\frac{f(x_0+h)-f(x_0)}{h}$, then I said that $x_0-h=t$ and $x_0+2h=t+3h$ where $3h=k$ so $$\frac{3}{5}\lim_{k\to 0}\frac{f(t+k)-f(t)}{k}=\frac{3}{5}f'(t)=\frac{3}{5}f'(x_0-h)$$","['calculus', 'derivatives']"
281653,How to compute the index of a given vector field on a triangular mesh,"Suppose that I have a triangular mesh (discrete surface composed of triangles). Now, I have been given a vector field (one vector with each triangle, tangential, unit length, so can be represented by only one angle). I would like to compute the index of this vector field on every vertex. One of the definition of the index can be the number of full rotations experienced by a vector transported along a loop of triangles around the vertex. I have some confusions because if only the vector of one triangle (among all triangles around the vertex) is changed, it seems that the index will not change. But the index will be definitely determined by the vectors of all triangles. What am I missing here?",['differential-geometry']
281655,Product of complex measures,"Let $\lambda, \mu$ be complex measures on $(X,\alpha)$ and $(Y,\beta).$
  Prove there exists a unique complex measure $\lambda\times \mu$ on the sigma algebra $\alpha\otimes \beta,$ such that $(\lambda\times \mu)(A\times B)=\lambda(A)\mu(B),$ for every $A\in \alpha, B\in \beta.$ This question is from an old exam I am studying for. My idea goes as follows. Because $\mu\ll|\mu|,$ by Radon Nikodym we have $$ \mu(A)=\int_A fd|\mu|,$$ also $\lambda(A)=\int_B gd|\lambda|.$ Now we have $$\mu(A)\lambda(B)=\int_A fd|\mu|\int_B gd|\lambda|=\int_B\int_Af(x)g(y)d|\mu|(x)d|\lambda|(y)=\int_{A\times B}f(x)g(y)d(|\mu|\times|\lambda|).$$ The expression 
$$\int_{A\times B}f(x)g(y)d(|\mu|\times|\lambda|)$$
defines a measure on $A\times B.$ I know $|\mu|\times|\lambda|$ is a unique positive measure on $A\times B$ such that $(|\mu|\times|\lambda|)(A\times B)=|\mu|(A)\cdot|\lambda|(B).$ 
I cant finish the proof from here on, but I suppose my idea is on the right way. If I knew that $(|\mu|\times|\lambda|)(A\times B)=|\mu|(A)\cdot|\lambda|(B),$ then the uniqueness is obvious. But is that true? How can I prove that?  If it is not true, how can I finish the proof? Please help.",['measure-theory']
281659,How to show the intersection of a prime ideal and a subring is a prime ideal,"I am a self-studier. This is a problem (1.5b) from Andrew Baker's excellent notes (freely available for download) on Galois Theory. $R \subseteq S$ are rings containing $1$. $Q$ is a prime ideal of $S$. Show $Q \cap R$ is a prime ideal of $R$. I have seen this can be proved knowing that the inverse of a ring homomorphism (where $1$ maps to $1$) of a prime ideal is a prime ideal. And considering $\phi: R \rightarrow S$ as an inclusion map and taking the inverse of $Q$, one can get the desired result. I was trying to prove this more ""directly"" and it is here I would appreciate help. The approach I am taking is to show that if $ab \in Q \cap R$, then WLOG $a \in Q \cap R$. Since $Q$ is prime, $a \in Q$. I would appreciate help as to how to show $a \in R$. Is it valid to say that since $1 \in R$ then $a1 \in R$? As always thanks for you help.",['abstract-algebra']
281687,Are limit superior and limit inferior defined for $z_n$ being a complex sequence?,"All the definitions of limit superior and limit inferior I have seen (even in the books about complex analysis) define them for a real sequence only. What could stop us from defining it as follow for a complex sequence? $$\limsup\limits_{n\to\infty} z_n := \lim_{n\to\infty}\Big(\sup\{|z_k|:k \geq n\}\Big)$$
$$\liminf\limits_{n\to\infty} z_n := \lim_{n\to\infty}\Big(\inf\{|z_k|:k \geq n\}\Big)$$","['complex-analysis', 'limsup-and-liminf']"
281694,Can a founded relation find minimal elements in proper classes?,"My definition of a founded relation $R$ on a (possibly proper) class $A$ is
$$R\mbox{ Fr }A\iff \forall x\subseteq A\,(x\neq\emptyset\rightarrow\exists y\in x\ \forall z\in x\ \neg zRy),$$
or equivalently,
$$R\mbox{ Fr }A\iff \forall x\subseteq A\,(x\neq\emptyset\rightarrow\exists y\in x\ x\cap R^{-1}\{y\}=\emptyset).$$ I am working in ZF, so obviously $x$ must be a set so that I can quantify over it. But I would like to conclude from this definition that $$X\subseteq A\rightarrow(X\neq\emptyset\rightarrow\exists y\in X\ \forall z\in X\ \neg zRy),$$ where $X$ is now an arbitrary class, which we can assume is a proper class. Since $X$ is then not included in the quantifier, I cannot immediately conclude this theorem, but my question is if it is possible for me to derive this by other means. If it is not true, are there definable counterexamples?",['elementary-set-theory']
281695,Statistics Probability Help,"I just began to take this stats course in HS and I'm a little stuck on these 2 problems below. Can anybody please help me out with the solutions? Thank you. Anything is appreciated. Let $Y$ be a random variable. Define a function $Q$ by $Q(m) = E[(Y − m)^{2}]$ (a) Write $\mu E[Y]$. How do you show that $Q(m) = \text{var}[Y] + (m − \mu)^{2}$. I was thinking it had something to do with $Y −m=(Y −\mu)−(m−\mu)$. (b) Also, how do you show that $Q(m)$ is minimized at $m = E[Y]$. I was thinking that it had something to do with checking the sign of $Q(m) − Q(\mu)$. Let $Y$ be a random variable distributed with $N(3, 16)$. Find $Pr[Y \gt 9.2]$.","['statistics', 'probability', 'random']"
281697,Is Exercise 8.3 in Rudin's Principles of Analysis as easy as it seems?,"Rudin Theorem 8.3 says that if $$\sum_{j=1}^\infty |a_{ij}| = b_i$$ and $\sum b_i$ converges, then $$\sum_i \sum_j a_{ij} = \sum_j \sum_i a_{ij}$$ Rudin 8.3 asks us to show that if $a_{ij} \geq 0$ for all $i,j$, then $$\sum_i \sum_j a_{ij} = \sum_j \sum_i a_{ij}$$ including the case $\infty = \infty$. It seems to me that the conditions of the Theorem follow pretty simply from the fact that $a_{ij} = |a_{ij}|$, and so we can say that if the LHS converges then the RHS converges, and to the same number, and that if the RHS converges, then the LHS converges, and to the same number. So the LHS converges if and only if the RHS converges to the same number. If one side diverges, then the other also diverges, and they both must diverge to $+\infty$. Hence we have equality. But that seems too easy. Is there something I am missing?","['sequences-and-series', 'real-analysis', 'analysis']"
281700,Showing that $\lim_{\delta \to 0^+} \frac{1}{\delta} \int_x^{x + \delta} f(t) \ \mathrm{d}t = f(x)$,"I'm working on proving the following equation: $\lim_{\delta \to 0^+} \frac{1}{\delta} \int_x^{x + \delta} f(t) \ \mathrm{d}t = f(x)$, where $f$ is given to be Riemann integrable and continuous on [0,1]. Attempted Proof I thought about applying the Fundamental Theorem of Calculus to arrive at, for the LHS, something like, $\lim_{\delta \to 0^+} \frac{F(x + \delta) - F(x)}{\delta}$, where $F$ is the antiderivative of $f(t).$ However, this feels very circular to me, since this expression of course equals $F'(x) = f(x)$, and we would then have equality on $(0, 1).$ I'd be grateful for any direction. Thanks so much.","['integration', 'real-analysis', 'analysis']"
281710,How to prove this collection is a sigma algebra,"This is one of the previous comp question. I would appreciate if somebody can give me a proof. Let $\mathbb A= \{E \subset X: E $ is a countable or $E^c$ is countable $\}$. To prove this collection is a sigma algebra. What I think is I need to prove there is a empty set in the collection which is vacuously true because empty set has finite number of elements, namely $0$ elements. To prove complement is there I think I need to show for the two cases. That's where I confused. Would somebody explain that to me? I also want to see how the infinite union of the elements of the collection belong to it?","['measure-theory', 'real-analysis']"
281723,Special matrices for which the cost of matrix-vector multiplication is less than $O(n^2)$,"I am looking for some special type of matrices for which the cost of matrix-vector multiplication is less than $O(n^2)$ . Examples are Hankel and Toeplitz matrices, which have few degrees of freedom (i.e., less than the number of free variables). Is there some other kind of matrix that has more degrees of freedom?","['numerical-linear-algebra', 'matrices', 'linear-algebra']"
281735,Quantification over the empty set [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Why is predicate “all” as in all(SET) true if the SET is empty? In don't quite understand this quantification over the empty set: $\forall y \in \emptyset: Q(y)$ The book says that this is always TRUE regardless of the value of the predicate $Q(y)$, and it explain that this is because this quantification adds no predicate at all, and therefore can be considered the weakest predicate possible, which is TRUE. I know that TRUE is the weakest predicate because $ $P$ \Rightarrow$ TRUE is TRUE for every $P$.
I don't see what is the relationship between this weakest predicate and the quantification.","['logic', 'discrete-mathematics', 'elementary-set-theory']"
281747,Questions about an example,"Recently, I met an example. I have two questions about the example: Why the author said, because $z \notin A$, then $z$ is not in the closure in $\beta \mathbb{R}$ of $A \cap (\beta \mathbb{R} \setminus \mathbb{R})$? And It seems that the point $z$ is a $P$-point is useless in this example. Am I right? (A point of a space is a $P$-point if the point belongs to the interior of any $G_\delta$-set which contains this point.) Thanks ahead:)","['general-topology', 'compactness', 'examples-counterexamples']"
281749,Finding a mistake in the incorrect proof for $(S\setminus T)\circ R\subseteq (S\circ R)\setminus(T\circ R)$,"This is from Velleman's ""How to Prove It"", exercise 4.2.11.b). The exercise requires finding a mistake in the proof, but everything looks good to me. Must be that I'm missing some important fact, but any pointers are well appreciated. $R$ is relation from $A$ to $B$, and $S$ and $T$ are relations from $B$ to $C$. Proof . Suppose $(a,c)\in (S\setminus T)\circ R$. Then we can chose some $b\in B$ such that $(a,b)\in R$ and $(b,c)\in S\setminus T$, so $(b,c)\in S$ and $(b,c)\not\in T$. Since $(a,b)\in R$ and $(b,c)\in S$, $(a,c)\in S\circ R$. Similarly, since $(a,b)\in R$ and $(b,c)\not\in T$, $(a,c)\not\in T\circ R$.Therefore $(a,c)\in (S\circ R)\setminus(T\circ R)$. Since $(a,c)$ was arbitrary, this shows that $(S\setminus T)\circ R\subseteq(S\circ R)\setminus(T\circ R)$. What am I missing here? P.S. The author does not imply that the proposition is true, so I cannot say if there actually is a proof for this.","['relations', 'elementary-set-theory']"
281759,Does Multiplicative Version of Azuma's Inequality Hold?,"We know that there are multiplicative version concentration inequalities for
sums of independent random variables. For example, the following
multiplicative version Chernoff bound. Chernoff bound: Let $X_1,\ldots,X_n$ be independent random variables and $X_i \in
\{0,1\}$. Let $X=\sum_{i=1}^n X_i$. Then for any $\delta>0$, $\Pr\left(X \ge (1+\delta)EX \right) \le e^{-c\cdot(EX)\delta ^2},$ where $c$ is some absolute constant. Now we consider dependent random variables. A slight variant of Azuma 's inequality states the following. Azuma's Inequality: Let $X_1,\ldots,X_n$ be (dependent) random variables and $X_i \in
\{0,1\}$. Assume that there exists $m$, such that $\Pr\left( \sum_{i=1}^n \mathbb{E}[X_i|X_{<i}] \le m\right) = 1.$ Let $X=\sum_{i=1}^n X_i$. Then for any $\lambda > 0$, $\Pr\left(X \ge m+\lambda \right) \le e^{-2 \lambda^2/n}.$ Clearly Azuma's inequality is additive. My question is that does a
multiplicative version of Azuma's inequality such as the following
hold? My question: Let $X_1,\ldots,X_n$ be (dependent) random variables and $X_i \in
\{0,1\}$. Assume that there exists $m$, such that $\Pr\left( \sum_{i=1}^n \mathbb{E}[X_i|X_{<i}] \le m\right) = 1.$ Let $X=\sum_{i=1}^n X_i$. Then for any $\delta
>0$ $\Pr\left(X \ge (1+\delta)m \right) \le e^{-c\cdot m \delta^2},$ where $c$ is some absolute constant. Note that the standard Azuma's inequality does not imply the
multiplicative version when $m \ll
\sqrt{n}$.","['statistics', 'probability', 'probability-theory']"
281765,Convergence of $\sum_{n=1}^{\infty}(-1)^n\frac{n}{f_n}$ where $f_n$ is the $n$'th Fibonacci number,Can we show convergence of$$B=\sum_{n=1}^{\infty}(-1)^n\frac{n}{f_n}$$where $f_n$ is the $n$'th Fibonacci number? And then can we determine the exact value of $B$?,"['fibonacci-numbers', 'sequences-and-series', 'calculus', 'real-analysis']"
281769,What is an algebra?,"Is an algebra or 'a algebra' the same thing as an algebraic structure?
Or does it have a different meaning? Thanks","['abstract-algebra', 'definition']"
281780,Polynomial bound,"Let $P(x)=a_4 x^4+a_3 x^3+a_2 x^2+a_1 x+a_0$ such that
$$\forall i\in \{0, 1, 2, 3, 4\};\phantom{;}a_i\in\mathbb{Z} \wedge |a_i|\leq T\phantom{.}(T\in\mathbb{Z}^+ )$$
Suppose that $P(x)> 0$ for all $x\in \mathbb{R}$. Prove that
$$\forall x\in\mathbb{R};\phantom{;}P(x)\ge \frac{1}{2^{195} T^{64}}$$","['elementary-number-theory', 'inequality', 'algebra-precalculus', 'polynomials']"
281817,Explicit bijection between Jordan curves and real numbers,"It is my understanding that the set of all Jordan curves and the set of real numbers are of the same cardinality.  So, it follows that there should exist a bijection between them.  Is there a known, explicit bijection between these two sets?  If so, what is it?","['elementary-set-theory', 'analysis']"
281831,Complex Exponential as a limit,"I need some help with a homework problem. This is Ahlfors exercise 1 p. 178: Using Taylor's Theorem applied to a branch of $\log (1 + \frac{z}{n})$ prove that $\lim (1 + \frac{z}{n})^n=e^z$ uniformly on all compact sets. What I did: Taking the principal branch we have by Taylor's: $$\log \left(1 + \frac{z}{n}\right) = z -\frac{z^2}{n}+\frac{2z^3}{n^2}- \ldots +f_m(z)z^m$$
Where $f_m(z)$ is a analytic function in the region where the branch is defined, hence:
$$1 + \frac{z}{n} = e^{z -\frac{z^2}{n}+\frac{2z^3}{n^2}- \ldots +f_m(z)z^m}$$
$$\Rightarrow \left(1 + \frac{z}{n}\right)^n = e^{n\left(z -\frac{z^2}{n}+\frac{2z^3}{n^2}- \ldots +f_m(z)z^m\right)}$$ then I got stuck, I really apreciate your help. Thanks.",['complex-analysis']
281833,matrix similarity upper triangular matrix [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question How to show: Any matrix A with real or complex entries is similar to an upper triangular matrix M whose diagonal entries are the eigenvalue of A. Thank you!","['numerical-linear-algebra', 'linear-algebra', 'numerical-methods']"
281845,Number of non degenerate boolean functions,"I got in my lecture the formula that describe the number of nondegenerate Boolean functions of $n$ variables (or how many boolean functions have no fictitious variables), but we don't have proof for it and I don't understand where did it get from. Here is it 
$$
\sum_{0\le k\le n} (-1)^k \binom{n}{k} 2^{2^{n-k}}.\qquad
$$ I would be greatly appreciated if someone explained it. Thanks.","['boolean-algebra', 'discrete-mathematics']"
281846,Exterior algebra of a vector bundle,"Associated to any vector space $V$ is its exterior algebra $\Lambda(V)$ which has the direct sum decomposition $\Lambda(V) = \bigoplus_{i=0}^n\Lambda^i(V)$ where $n = \dim V$. My first interaction with the concept of an exterior algebra was in differential geometry where one defines a $k$-form on a smooth manifold $M$ to be an element of $\Gamma(M, \Lambda^k(T^*M))$. Here $\Lambda^k(T^*M)$ is a vector bundle; in particular, $\Lambda^k(T^*M) = \bigsqcup_{m\in M}\Lambda^k(T_m^*M)$. A little bit further into my differential geometry studies, I encountered the concept of an $E$-valued $k$-form, where $E$ is a vector bundle on $M$, which is defined to be an element of $\Gamma(M, \Lambda^k(M)\otimes E)$. Before seeing the definition of an $E$-valued form (or truly understanding the concept), I was under the impression that the exterior algebra of $E$ would appear in the definition. I now know why it doesn't, but I have come to realise that I have never seen the exterior algebra associated to a vector bundle other than the cotangent bundle. Therefore, I ask the following question: Are there any situations in which one wants/needs to consider the exterior algebra of a vector bundle other than the cotangent bundle?","['exterior-algebra', 'differential-geometry']"
281863,Book recommendations for commutative algebra and algebraic number theory,Are there any books which teach commutative algebra and algebraic number theory at the same time. Many commutative algebra books contain few chapters on algebraic number theory at end. But I don't need that. I'm seaching for book which motivates commutative algebra using algebraic number theory.My main is to learn algebraic number theory but while doing so I also want to pick up  enough commutative algebra to deal with algebraic geometry as well.,"['commutative-algebra', 'algebraic-number-theory', 'algebraic-geometry', 'reference-request']"
281893,How to find the derivative of the sine from the definition of derivative?,"How to find the derivative of this function: $f(x) = \sin(x)$ - using definition of derivative: \begin{equation}
    f'(x) = \lim_{h\to0}\dfrac{f(x + h) - f(x)}{h}
\end{equation}","['trigonometry', 'calculus', 'derivatives']"
281895,Derivation of the density function of product of two random variables,"I am looking for distribution of product of two random variables. Best I could found so far was this formula from the relevant Wikipedia page : $$ f_Z(z) = \int_{-\infty}^{+\infty} \frac{1}{|x|} f_{XY}(x, \frac{z}{x}) dx $$ However, when I try to derive it myself, I find a different result. The work I have done so far is below. $X$: The first random variable $Y$: The second random variable $Z$: The product of these two random variables; that is: $$ Z = XY $$ $$ F_Z(z) = P(Z \leq z) = \iint\limits_{D_z} f_{XY}(x, y) dx dy $$ Region of $Z$, $D_Z$, depends on the sign of $Z$: So I decided to solve it in the situations; for $z<0$ and $z>0$. Case #1 - $(z>0)$ $$ F_Z(z) = \int_{y=-\infty}^{y=0} \int_{x=\frac{z}{y}}^{x=0} f_{XY}(x, y) dx dy
+ \int_{y=0}^{y=+\infty} \int_{x=0}^{x=\frac{z}{y}} f_{XY}(x, y) dx dy $$
$$ f_Z(z) = \frac{d F_Z(z)}{dz} =
\int_{y=-\infty}^{y=0} (-\frac{1}{y}) f_{XY}(\frac{z}{y}, y) dy
+ \int_{y=0}^{y=+\infty} (\frac{1}{y}) f_{XY}(\frac{z}{y}, y) dy
$$ Case #2 - $(z<0)$ $$ F_Z(z) = \int_{y=-\infty}^{y=0} \int_{x=0}^{x=\frac{z}{y}} f_{XY}(x, y) dx dy
+ \int_{y=0}^{y=+\infty} \int_{x=\frac{z}{y}}^{x=0} f_{XY}(x, y) dx dy $$
$$ f_Z(z) = \frac{d F_Z(z)}{dz} =
\int_{y=-\infty}^{y=0} (\frac{1}{y}) f_{XY}(\frac{z}{y}, y) dy
+ \int_{y=0}^{y=+\infty} (-\frac{1}{y}) f_{XY}(\frac{z}{y}, y) dy
$$ By combining these two cases, I find the general partial equation: $$ f_Z(z) =
\left\{
	\begin{array}{ll}
		+ \int_{y=-\infty}^{y=0} \frac{1}{y} f_{XY}(\frac{z}{y}, y) dy
- \int_{y=0}^{y=+\infty} \frac{1}{y} f_{XY}(\frac{z}{y}, y) dy   & \mbox{if } z < 0 \\
		??? & \mbox{if } z = 0 \\
		- \int_{y=-\infty}^{y=0} \frac{1}{y} f_{XY}(\frac{z}{y}, y) dy
+ \int_{y=0}^{y=+\infty} \frac{1}{y} f_{XY}(\frac{z}{y}, y) dy  & \mbox{if } z > 0
	\end{array}
\right.$$ Why is my solution SO different from the one in Wikipedia? What am I doing wrong? Can you please fix any mistakes in my derivation, or make the derivation in your own way?","['proof-writing', 'probability-distributions', 'probability']"
281910,Lipschitz Continuity,"I have a quick question on how to interpret Lipschitz Continuity rather than normal continuity. What is the exact difference between the two, because I can't really find one. And is it more general than normal continuity or is it a more strict kind of continuity?",['ordinary-differential-equations']
281915,What is the domain of $\vert \Delta\vert^{1/2}$?,"Assume $U$ is a bounded open subset of $\mathbb{R}^N$. Furthermore $\Delta: H^2(U) \subset L^2(U) \to L^2(U)$ is the Laplace operator. My question is: What is the domain of $\vert \Delta\vert^{1/2}$? I've seen this notation a lot recently and still don't know what to make of it. First of all the Laplace operator is not a positive operator. I guess, that is what the $\vert \cdot \vert$ is for. Here is a definition of the root of $-\Delta$, which suggests that the domain could be $L^1 (U)$. It would be perfect for my cause, if the domain could be taken as $H^2(U)$ again.","['operator-theory', 'functional-analysis']"
281940,What is a 'critical value' in statistics?,"Here's where I encountered this word: The raw material needed for the manufacture of medicine has to be at least $97\%$ pure. A buyer analyzes the nullhypothesis, that the proportion is $\mu_0=97\%$, with the alternative hypothesis that the proportion is higher than $97\%$. He decides to buy the raw material if the nulhypothesis gets rejected with $\alpha = 0.05$. So if the calculated critical value is equal to $t_{\alpha} = 98 \%$, he'll only buy if he finds a proportion of $98\%$ or higher with his analysis. The risk that he buys a raw material with a proportion of $97\%$ (nullhypothesis is true) is $100 \times \alpha = 5 \%$ I don't really understand what is meant by 'critical value'",['statistics']
281942,"for $|f (x_1) + ... + f (x_n)| \le M$ how to prove that $S=\{ x\in [0,1]:f(x)\ne 0\}$ is countable?","Let f be a real-valued function defined for every $x$ in the interval
  $0\le x \le 1$. Suppose there is a positive number M having the following
  property: for every choice of a finite number of points $x_1, x_2, ..., x_n$ in the
  interval $0 \le x \le  1$, the sum
  $$|f (x_1) + ... + f (x_n)|  \le M$$
  Let $S$ be the set of those $x$ in $0 \le x \le 1$ for which $f(x) \neq 0$. Prove that $S$
  is countable. I am having hard time to understand it's solution. The solution is as follows. Proof : Let $S_n = \{x \in [0, 1] : |f (x)| \ge 1/n\}$ , then $S_n$ is a finite set by
  hypothesis. In addition, $S = \cup_{n=1}^\infty S_n$. So, S is countable. There are infinite irrationals between $0$ and $1$, how does defining taking $x$ such that $|f(x)| \ge 1/n$ prove that the set is countable. Aren't we counting irrationals as well as rationals between $0$ and $1$? I think it would be more intuitive to begin by assuming that the set $S$ in uncountable and arrive at contradiction that $|f (x_1) + ... + f (x_n)|$ is bounded. But I don't know how. Can we do this way? Also can anyone elaborate that proof from manual so that I can understand?",['analysis']
281961,Radius of convergence for the exponential function,"I'm studying physics and am currently following a course on complex analysis and in the section on analytic functions, the radius of convergence $R$ for power series was introduced. The Taylor expansion around $z_0=0$ for the exponential function was considered as an example of a power series with $R\rightarrow\infty$. The notes state this can be proved by using Weierstrass' Criterion for uniform convergence, which I'll state in my own words: Consider a series $\sum\limits_{k=0}^{\infty} f_k(z)$. If you know numbers $a_k$ for which $|f_k(z)| < a_k$ for all $z$, and $\sum\limits_{k=0}^{\infty} a_k$ converges uniformly, then also $\sum\limits_{k=0}^{\infty} f_k(z)$ converges uniformly. For the exponential, we have the power series $e^z = \sum\limits_{k=0}^{\infty}\dfrac{z^k}{k!}$. Now I've been thinking about this, but I can't seem to think of a uniformly converging series of $a_k$'s that bound the terms of this power series. Perhaps this is really straightforward and I wouldn't have any difficulties with it if I remembered my course on real analysis a bit better... It's not a homework problem and series convergence is not a main goal in this course, but it's been bugging me that I don't understand why Weierstrass's Criterion proves that the radius of convergence goes to infinity for the exponential, so I thought I'd ask here. Thanks in advance.","['power-series', 'exponential-function', 'convergence-divergence', 'complex-analysis']"
282006,"Evaluate $\int\frac{1+x+\sqrt{1+x^2}}{\sqrt{x+1}+\sqrt{x}}\,dx$","Question: Solve the integral
  $$
\int\frac{1+x+\sqrt{1+x^2}}{\sqrt{x+1}+\sqrt{x}}\,dx
$$ My solution: Multiply both the numerator and denominator by $\sqrt{x+1}-\sqrt{x}$. This changes the integral to $$
\begin{align}
\int&\left(1+x+\sqrt{1+x^2}\right)\left(\sqrt{x+1}-\sqrt{x}\right)\,dx\\
&= \int{(1+x)^{3/2}}\,dx-\int{\sqrt{(1+x)(1+x^2)}}\,dx-\int{\sqrt{x}(1+x)}\,dx-\int{\sqrt{x}\sqrt{1+x^2}}\,dx\\
& = \frac{2}{5}(1+x)^{5/2}-I-\frac{2}{3}x^{3/2}-\frac{2}{5}x^{5/2}-J
\end{align}
$$ where $I = \int{(1+x)^{1/2}(1+x^2)^{1/2}}\,dx$ and $J = \int{x^{1/2}(1+x^2)^{1/2}}\,dx$. How can I solve the integrals $I$ and $J$?","['calculus', 'integration', 'indefinite-integrals']"
282014,Evaluating real integral using residue calculus: why different results?,"I have to evaluate the real integral
$$
I = \int_0^{\infty} \frac{\log^2 x}{x^2+1}.
$$
using residue calculus.
Its value is $\frac{\pi^3}{8}$, as you can verify (for example) introducing the function
$$
  \frac{(\log z-i(\pi/2))^2}{z^2+1}.
$$ and considering the branch cut for the logarithm function on the negative semiaxis of the immaginary numbers and an upper half-circle indented at 0 as integration contour. I tried a different method , but unfortunately I obtained a different result and I don't know why. I consider the branching axis of the logarithm function as the positive real semiaxis.
I tried as integration contour this closed curve. I used the complex function
$$
f(z)=\frac{\log^3z}{z^2+1}
$$
obtaining 
$$
\int_r^{R} \frac{\log^3 x}{x^2+1}\;dx + \int_\Gamma \frac{\log^3 z}{z^2+1}\;dz - \int_r^{R} \frac{(\log x+2\pi i)^3}{x^2+1}\;dx - \int_\gamma \frac{\log^3 z}{z^2+1}\;dz.
$$
It is easy to see that integrals over circular paths $\gamma$ and $\Gamma$ tend to zero when $R\to \infty,r\to 0$. So we have to evaluate
$$
\int_r^{R} \frac{\log^3 x}{x^2+1}\;dx - \int_r^{R} \frac{(\log x+2\pi i)^3}{x^2+1}\;dx,
$$
which immaginary part is ( EDIT : changed $8\pi i$ to $8\pi^3 i$ )
$$
-6\pi i \int_r^{R} \frac{\log^2 x}{x^2+1}\;dx + 8\pi^3 i \int_r^{R} \frac{1}{x^2+1}\;dx,
$$
that has to be equal to the immaginary part of
$$
2\pi i\;\left( \mathrm{Res} \left[f,i \right] + \mathrm{Res}\left[f,-i \right]\right) = -i \frac{\pi^4}{4}.
$$ 
So, doing the rest of the work, finally I found that the result is $\frac{17\pi^3}{24}$, that is clearly different from $\frac{\pi^3}{8}$... but where is the flaw in my argument? Please help","['residue-calculus', 'complex-integration', 'complex-analysis']"
282016,A qualifying exam problem involving Schwarz lemma,"This is a problem in the book ""Berkeley Problems in Mathematics"", which I think the solution given is wrong, can someone help? The following problem appeared in Spring 1991. Let the function $f$ be analytic in the unit disc, with $|f(z)|\leqslant 1$ and $f(0)=0$ . Assume that there is a number $r$ in $(0,1)$ such that $f(r)=f(-r)=0$ . Prove that $$|f(z)|\leqslant |z|\left| \frac{z^2-r^2}{1-r^2z^2}\right|.$$","['inequality', 'complex-analysis']"
282020,Is every bounded sequence convergent? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question It's true, that every convergent sequence is bounded, but is every bounded sequence convergent?","['sequences-and-series', 'calculus']"
282034,Do projections onto convex sets always decrease distances?,"Suppose $(M, d)$ is some $\ell_p$ metric space (not necessarily Euclidean), and $C \subseteq M$ is a closed convex set. Consider the projection function $f_C:M\rightarrow C$ defined such that:
$$f_C(x) \in \arg\min_{y \in C} d(x,y)$$ Is it the case that for all $x,y \in M$:
$$d(f_c(x),f_c(y)) \leq d(x,y)$$
i.e., is it the case that projections onto convex sets can never increase the distance between a pair of points?","['geometry', 'convex-analysis', 'metric-spaces']"
282037,Which families of groups have interesting formulas for the number of elements of given order?,"Suppose that $G$ is a group and that $n$ is a positive integer diving the order of $G$. Let $f_n(G)$ be the number of elements satisfying $x^n = 1$ in $G$. According to a theorem of Frobenius, then we have $f_n(G) \equiv 0 \mod{n}$. Hence if we have a family of groups and a formula for the number of solutions to $x^n = 1$, an application of Frobenius theorem proves that the formula is $\equiv 0 \mod{n}$. One family of groups where we can find a formula are the symmetric and alternating groups, since the order of a permutation is determined by cycle structure. For example, let $p$ be a prime number and $n \geq p$ some integer. Then the number of elements satisfying $x^p = 1$ in $S_n$ is $$\sum_{k = 1}^{\lfloor \frac{n}{p} \rfloor} \frac{n!}{p^k (n-pk)! k!} + 1 \equiv 0 \mod{p}$$ by Frobenius theorem. It does not seem immediately obvious without Frobenius theorem that the sum on the left should be $\equiv -1 \mod{p}$. Also, notice that $n = p$ gives us Wilson's theorem: $$(p-1)! \equiv -1 \mod{p}$$ More congruences can be found by calculating the number of elements of some order in the symmetric groups $S_n$ and alternating groups $A_n$. My question is this: Besides $S_n$ and $A_n$, for what other families of finite groups can we find congruences like the one above by applying Frobenius theorem? Of course, if you feel like there's some noteworthy/interesting/useful congruence in $S_n$ to be found with Frobenius theorem, feel free to answer or comment with those too.","['elementary-number-theory', 'abstract-algebra', 'q-analogs', 'finite-groups', 'group-theory']"
282046,What does $\lg x$ mean? is it $\log_2 x$ or $\log_{10} x$ in binary trees,"I'm a bit confused, $\log_{10} x = \log x $ right? I believe I've read somewhere that $\log_{2} x = \lg x$ but some people say $\lg = \log$ . So what does $\lg$ really stand for? specifically when talking about ""binary trees""","['trees', 'logarithms', 'algebra-precalculus', 'definition']"
282056,"From a mathematician's point of view, what is the purpose of '$dx$' in $\int f(x)\ dx$?","I've done a bit of searching and found a fairly well written explanation, but at the end, the author noted that this explanation seems to work fine for a physicist's purposes - but a mathematician would groan at it due to oversimplifications or inaccuracies. Since I first posted this paper, two different people have emailed me
  to tell me that Real Mathematicians don't do this. Playing with dx in
  the ways described in this paper is apparently one of those smarmy
  tricks that physicists use to give headaches to mathematicians. http://www4.ncsu.edu/unity/lockers/users/f/felder/public/kenny/papers/dx.html I was also confused when reading it because my Calculus prof last semester said that the chain rule $$\frac{dy}{dz}=\frac{dy}{dx}\cdot \frac{dx}{dz}$$ cannot be treated as fractions, despite the fact that they look like it, and the $dx$ would not cancel out between the two since you can't do that with differentials. But this article said just the opposite.","['notation', 'calculus']"
282058,Normal subgroups of the group of invertible $2×2$ upper triangular matrices,Let $G$ be the group of all invertible $2×2$ upper triangular matrices (under matrix multiplication). Pick out the normal subgroups of $G$ from the following: (a) $H=\{A\in G:a_{12}=0\}$; (b) $H=\{A\in G:a_{11}=1\}$; (c) $H=\{A\in G:a_{11}=a_{22}\}$. After calculation I get only (b) is right. Am I correct?,"['group-theory', 'abstract-algebra']"
282060,An approximate solution to an ODE,I am interested in the ODE: $x^\prime = x^2 + t^2$ $x(0)=0$ The power-series method is not (easily?) applicable here. Do you have any suggestions how to solve it?,"['power-series', 'ordinary-differential-equations']"
282061,Composing two discontinuous functions into a continuous one,Please help me think of an example of two discontinuous functions on $\mathbb R$ whose composition gives a continuous function on $\mathbb R$.,"['functions', 'continuity', 'real-analysis']"
282062,Cancellation conditions on finitely generated projectives over a commutative ring,"A class $\mathcal{C}$ of $R$-modules is called -separative if $A \oplus A \simeq A \oplus B \simeq B \oplus B$ implies $A \simeq B$ for each $A,B \in \mathcal{C}$ -cancellative if $A \oplus C \simeq B \oplus C$ implies $A \simeq B$ for all $A,B,C \in \mathcal{C}$. According to literature, if $R$ is commutative then the class of finitely generated projectives over $R$ is separative iff it is cancelative. Even though I keep finding it as 'easy to see' in literature I seem unable to prove separative => cancelative. I would be grateful for any hint.","['modules', 'commutative-algebra', 'projective-module', 'abstract-algebra']"
282070,A problem on which of the following rings are integral domains?,"Which of the following rings are integral domains? (a) $\mathbb{R}[x]$, the ring of all polynomials in one variable with real coefficients. (b) $M_n(\mathbb{R}) $. (c) the ring of complex analytic functions defined on the unit disc of the complex plane (with pointwise addition and multiplication as the ring operations). Only (a) & (c) are correct. Am I right?",['abstract-algebra']
282080,Detail about the definition of orientability,"I am a bit struggling with one of the many definitions of orientability. In what follows $M$ will always denote a smooth, connected manifold, $T_{m}M$ will be the tangent space at $m$, $\mathcal{B}_{m}$ will be the set of ordered bases of $T_{m}M$, i.e. $$\mathcal{B}_{m}:=\{(v_{1},\ldots,v_{n})\in (T_{m}M)^{n};\operatorname{span}_{\mathbb{R}}\{v_{1},\ldots,v_{n}\}=T_{m}M\}$$$\sim_{m}$ will denote the equivalence relation on $\mathcal{B}_{m}$ obtained by $v\sim_{m}w:\Leftrightarrow \det(A(v,w))>0$, where $v=(v_{1},\ldots,v_{n})$ and $w=(w_{1},\ldots,w_{n})$ are elements in $\mathcal{B}_{m}$ and $A(v,w)$ is the unique element in $\operatorname{GL}(T_{m}M)$ satisfying $A(v,w)v_{i}=w_{i}$ for all $1\leq i\leq n$. Finally $\Lambda_{n}(T_{m}M)$ denotes the space of alternating $n$-forms on $T_{m}M$ and $\Lambda_{n}^{\ast}(M):=\bigcup_{m\in M}\{m\}\times\Lambda_{n}(T_{m}M)$. I have topologized $\Lambda_{n}^{\ast}(M)$ by requiring that if $(U,\rho)$ is a chart in the maximal atlas on $M$, then the map $\tilde{\rho}:\tilde{U}\to\mathbb{R}^{n+1}$ is smooth, where:
$$\tilde{U}:=\bigcup_{m\in U}\Lambda_{n}(T_{m}M) \text{ and }\tilde{\rho}(m,\omega):=\left(\rho(m),\omega\left(\frac{\partial}{\partial x_{1}}\bigg|_{m},\ldots,\frac{\partial}{\partial x_{n}}\bigg|_{m}\right)\right)$$ Indeed the image of $\tilde{\rho}$ is open in $\mathbb{R}^{n+1}$ and so on. The main goal is to put more sense into the following statement: Definition M is orientable iff $\Lambda_{n}^{\ast}(M)\setminus N$ has two connected components, where $N$ is the range of the map $\omega:M\to\Lambda_{n}^{*}(M): \omega(m):=(m,0)$. I am struggling with the following statement: Problem $\Lambda_{n}^{\ast}(M)\setminus N$ has at most two components. That is it has either one or two. I approached it by comparing different notions of orientability. So far I have managed to prove the following statement: Theorem Let $M$ be a smooth manifold and $\dim M=n$. Then the following are equivalent: There exists a smooth, no-where vanishing differential $n$-form on $M$ There exists an atlas $\mathcal{A}$ on $M$ such that for all $(U,\rho),(V,\psi)\in\mathcal{A}$ holds $\det(\operatorname{d}_{m}(\rho\circ\psi^{-1}))>0$ for all $m\in U\cap V$. There exists a map $\epsilon:M\to\bigcup_{m\in M}\mathcal{B}_{m}/\sim_{m}$ and for all $m\in M$ there exists $U\subseteq M$ an open neighbourhood of $m$ and smooth vector fields $X_{1},\ldots,X_{n}$ on $U$ such that for all $p\in U$ holds $(X_{1}(p),\ldots,X_{n}(p))\in\epsilon(p)$. $\Lambda_{n}^{\ast}(M)\setminus N$ has two components. This does not tell me why we have either one or two components (and definitely not more). I have no idea what to do (I even tried a direct proof). Edit: It seems to me to be most promising to prove that non-3 implies that $\Lambda_{n}^{\ast}(M)$ has only one component, i.e. I would try to show that if for every $\epsilon:M\to\bigcup_{m\in M}\mathcal{B}_{m}/\sim_{m}$ there exists $m\in M$ such that for every open neighbourhood $m\in U\subseteq M$ and all smooth vector fields $X_{1},\ldots,X_{n}$ on $U$ satisfying $(X_{1}(p),\ldots,X_{n}(p))\in\mathcal{B}_{p}$ for all $p\in U$ we can find $p,q\in U$ such that $(X_{1}(p),\ldots,X_{n}(p))\in\epsilon(p)$ and $(X_{1}(q),\ldots,X_{n}(q))\not\in\epsilon(q)$, then $\Lambda_{n}^{\ast}(M)\setminus N$ has one component. What do you think of this? Is this feasible? Thank you so much Manuel",['differential-geometry']
282097,Integral of simple functions in standard and non-standard representation,"Some definitions Let $(X,\mathbb X,\mu)$ be a measure space. 
A real-valued function is simple if it has only a finite number of values. A simple $\mathbb X$-measurable function $\varphi$ can be represented in the form
  $$\varphi=\sum_{j=1}^n a_n\chi_{E_j}$$
where $a_j\in\mathbb R$ and $\chi_{E_j}$ is the characteristic function of a set $E_j\in\mathbb X$. If we add the restriction that the $a_j$ be distinct and the $E_j$ form a partition of X, then the representation is unique and is called the standard representation of $\varphi$. If $\varphi$ is a simple function in $M^+(X,\mathbb X)$ with the standard representation above, we define the integral of $\varphi$ with respect to $\mu$ to be the extended real number
  $$\int\varphi\,d\mu=\sum_{j=1}^n a_j\mu(E_j)$$ My question If the simple function $\varphi\in M^+(X,\mathbb X)$ has the (not necessarily standard) representation
  $$\varphi=\sum_{k=1}^m b_k\chi_{F_k}$$
where $b_k\in\mathbb R$ and $F_k\in\mathbb X$, it can be shown that
  $$\int\varphi\,d\mu = \sum_{k=1}^m b_k\,\mu(F_k).$$
My problem is that I cannot find a clean yet rigorous step-by-step proof of that result. My idea is to rewrite the function $\varphi$ as $\sum_{k=1}^n a_k\chi_{\phi^{-1}(a_k)}$ where $a_k$ is the sum of some $b_k$ terms and $\phi^{-1}(a_k)$ is the union of intersections of some $F_k$ terms. After some manipulations I note that I can put back together all the ""pieces"" and find $\sum_{k=1}^m b_k\,\mu(F_k)$. Unfortunately, that very last passage is left to the reader. Is there a way to make all the process explicit and yet clean and easy to follow?",['measure-theory']
282102,"Prove that the orbit of an iterated rotation of 0 (by (A)(Pi), A irrational) around a circle centered at the origin is dense in the circle.","I think the title of the question says it all. I unfortunately did not seem to conclude anything. Some ideas I had: It is easy to show that (given $T$ is the rotation) $\{T^n(\theta)\}$ is a set of distinct points. Furthermore, given that the circle is a compact metric, it must have a limit point $x$. By continuity of the rotation function, $T^n(x)$ is a limit as well since taking $T$ of every term yields the same sequence (with only the first term removed). By induction, we have infinitely many distinct limit points $\{T^n(x)\}$. That's all I could come up with! It was also easy to show that the orbit is infinite. I still don't seem to be able to get close to the required result however.","['general-topology', 'dynamical-systems', 'real-analysis']"
282105,"Transcendence degree of $K[X_1,X_2,\ldots,X_n]$","Let $K$ be field. How do I proof that transcendence degree of $K[X_1,X_2,\ldots,X_n]$ is $n$? The set $\{X_1,X_2,\ldots,X_n\}$ is algebraically independent over $K$. So, I have to show that every subset of size greater than $n$ is algebraically dependent.","['commutative-algebra', 'ring-theory', 'dimension-theory-algebra', 'abstract-algebra']"
282110,why algebraic structures?,"According to wikipedia, an algebraic structure is an arbitrary set with one or more finitary operations defined on it. From a model theory perspective, I understand this definition as:  structure with no relations, only functions and constants (I added the constants to my definition, because I know that group, rings, have them). So for example an ordered field is not an algebraic structure (has relation), and a set isn't too (no function).
Regardless of the exact definition, a massive part of mathematics is concerned with the study of these structures, and the relations between them. Geometry benefits from algebraic geometry, number theory from algebraic number theory, and so on.
My question is, what do this sort of structures have in them, that makes us study and use them so much, and not other structures?","['soft-question', 'model-theory', 'abstract-algebra']"
282118,"Number of strings of length n formed by $\{0,1,2\}$ such that $1$ and $2$ do not occur successively.","What is the number of ways of forming a string of length $n$ from the set $\{0,1,2\}$ such that $1$ and $2$ do not occur successively.",['combinatorics']
282121,Is the Space of bounded functions with the maximums norm a Banach space and even a Banach Algebra?,"X is a arbitrary non empty set , B(X) the set of bounded functions $f:X\rightarrow \mathbb{R}$ and $||f||_\infty = \sup_{x\in X} |f(x)|$ Completeness: Let $(f_n(x))_{n \in \mathbb{N}}$ be a cauchy sequence, then: $$||f_n-f_m||\le \frac{\epsilon}{2} \ \text{for n,m greater than some N}$$ the cauchy sequence $f_n$ will have a limit $f(x)$ for $x \in \mathbb{R}$, so there must be a $f_{n_k}$ with a $n_k > N$ such that : $|f_{n_k}(x)-f(x)|\le \frac{\epsilon}{2}$ so one can put: $$|f_n(x)-f(x)| \le ||f_n(x)-f_{n_k}(x)||+ |f_{n_k}(x)-f(x)| \le \epsilon $$ And for every $x\in \mathbb{R}$: $$|f(x)|\le |f_{n_k}(x)|+|f_n(x)-f(x)|\le ||f_{n_k}(x)||+\epsilon < \infty$$ Is this sufficient to say that it was shown that $(B(X), ||.||_\infty )$ is a Banach space? Is it also a Banach Algebra?","['multivariable-calculus', 'real-analysis', 'analysis']"
282122,Topological properties of symmetric positive definite matrices,Let $S$ be the set of all symmetric positive definite matrices of size $n\times n$. Which of the following statements are true? (a) $S$ is closed in $\mathbb{M}_n(\mathbb{R})$. (b) $S$ is connected in $\mathbb{M}_n(\mathbb{R})$. (c) $S$ is compact in $\mathbb{M}_n(\mathbb{R})$. Only the option (a) & (b) are right. I guess that it is not bounded so (c) is not true. Am I correct?,"['positive-definite', 'general-topology', 'matrices', 'connectedness', 'compactness']"
282144,Model theory in group theory,I am interested in useful results for group theorists that can be shown using model theory. For example : Theorem: Let $\langle X \mid R \rangle$ be presentation of a group $G$ with $X$ finite and $R$ infinite. If $G$ is finitely presented then there exists $R' \subset R$ finite such that $\langle X \mid R' \rangle$ is a presentation of $G$. A possible proof is to use compactness theorem or Gödel's completeness theorem. This result can be used to show that some groups are not finitely presented. Do you know other such results?,"['group-theory', 'model-theory']"
282150,"Which of the following sets are compact in $\mathbb{M}_n(\mathbb{R})$[NBHM_PhD Screening Test-2013, Topology]","Which of the following sets are compact in $\mathbb{M}_n(\mathbb{R})$ (a) The set of all upper triangular matrices all of whose eigenvalues
satisfy $|\lambda|≤2 $ . (b) The set of all real symmetric matrices
all of whose eigenvalues satisfy $|\lambda|≤2 $ . (c) The set of
all diagonalizable matrices all of whose eigenvalues satisfy $|\lambda|≤2 $ . (a) & (c) are not true. But I am not sure about (b).can anybody help me please.",['general-topology']
282159,What $h$ and $k$ would make this system have infinitely many solutions?,If there are an infinite number of solutions to the system $$\left|\begin{array}{cc|c} -5 & 6 & h\\ -8 & k & -7\end{array}\right|$$ then what do $h$ and $k$ equal? I know that for a system to have infinity many solutions then both of the rows must be equal.,['matrices']
282160,Differentials and second order derivative,"I have a question from my tutorials and I don't know how to start... Let $U$ be open in $\mathbb{R}^{n}$ and let $f:U\rightarrow \mathbb{R}$ a $C^{2}$ function. Let $p$ be a point in $U$ where $df_{p}$ of $f$ at $p$ does not vanish. Show that there exists a system of local coordinates $x^{i}$ defined in a neighbourhood of $p$ in which \begin{eqnarray*}
\frac{\partial^{2}f}{\partial x^{i}\partial x^{j}}=0
\end{eqnarray*} for all $1\leq i,j\leq n$. Thanks!",['differential-geometry']
282207,Is the following function continuous at $x = 0$?,"Define $f: \mathbb{R} \to \mathbb{R}$ by $$ f(x) = \cases{
x - 1 \ \ \text{ if } x \in \mathbb{Q}
\\1 - x \ \ \text{ if } x \not\in \mathbb{Q}.
}$$ I'm trying to prove whether or not $f$ is continuous at $x = 0$. Here's my strategy so far. Proof Sketch Construct a sequence of irrationals $\{x_n\}$ such that $\{x_n\} \to 0$ (which can be done as a result of the density of $\mathbb{R} \setminus \mathbb{Q}$ in $\mathbb{R}$). Now examine $\lim_{n \to \infty} f(x_n) = 1 - 0 = 1$. However $f(0) = 0 - 1 = -1$, since $0$ is a rational number. Thus, we have found a sequence converging to $0$ such that $\lim_{n \to \infty} f(x_n) \neq f(0)$, and, as a result, $f$ is discontinuous at $x = 0.$ Update: Proving $f$ continuous at $x = 1$ We wish to show that for every $\epsilon > 0$ there exists $\delta > 0$ such that $$|x - 1| < \delta \implies |f(x) - f(1)| < \epsilon.$$ Since $x = 1$ is rational, $f(1) = x - 1 = 1 - 1= 0$. So, equivalently, we need $$|x - 1| < \delta \implies |f(x)| < \epsilon.$$ We now take two cases. Assume first that $x$ is rational, so $f(x) = x - 1$. Now set $\delta = \epsilon.$ Clearly,
$$|x - 1| < \delta = \epsilon \implies |f(x)| = |x - 1| < \epsilon.$$ The next case is similar. Assume $x$ is irrational, so $f(x) = 1 - x.$ Again, set $\delta = \epsilon.$ We have
$$|x - 1| < \delta  = \epsilon \implies |x - 1| = |1 - x| < \epsilon.$$","['continuity', 'real-analysis', 'analysis']"
282224,What is an additive group?,"Is an additive group a group which only has an addition operation, or can it also have other operations on it? Thanks","['linear-algebra', 'group-theory']"
282231,How to break apart this sum?,"I have a summation I need to break apart but I can't figure it out http://www.collectionscanada.gc.ca/obj/s4/f2/dsk1/tape10/PQDD_0027/MQ50799.pdf $p.15$, right after line $(3.8)$ Going from the first $ns^{2}$ identity to the next line, where the author breaks apart the sum. I understand how he's trying to take out the $nth$ (jth) in this case) term, and use the equality identity above (for the distance between the sample mean and ""reduced sample"" mean) to get to the solution, but I can't figure out how that's a legal move, to break out the sum of two things squared into its components or the sequence of steps that was omitted... If you guys could help I would appreciate it, thanks","['statistics', 'factoring', 'summation']"
282241,Why doesn't Dirichlet function have a derivative in X=0,"$\newcommand{\dirichlet}{\mathop{\rm dirichlet}\nolimits}$
I'm trying to find two examples for the following criterias: A method that is continuous in exactly one point but doesn't have a derivative  in that point A method that is continuous in exactly one point and does have a derivative  in that point After looking deeper at some examples, I found out that $f(x) = x\cdot\dirichlet(x)$ doesn't have a deriviate at $x = 0$ however $f(x) = x^2\cdot \dirichlet(x)$ does have. I can't understand the difference between the two.
Any helps could help.","['continuity', 'derivatives']"
282244,Computing the spectral decomposition for the multiplication operator $f(x) = \frac{1}{1+x^2}$,"I am trying to use the spectral theorem for self adjoint operators to decompose the spectrum of the multiplication operator $f(x) = \frac{1}{1+x^2}$ on $L^2(\mathbb{R}).$ This is a problem in Teschl's ""Mathematical Applications to Quantum Mechanics."" Here is what I have done so far. The function $f \in L^\infty(\mathbb{R})$ so it is a bounded operator and its spectrum is equal to the closure of the range of $f$ which is the interval $[0,1].$ There are clearly no eigenvectors since $g = \frac{g}{1+x^2}$ implies that $g=0$ a.e. If $\psi(x) \in L^2(\mathbb{R})$ then the spectral measure is defined by $$\mu_\psi(\Omega) = \langle\psi, \chi_{f^{-1}(\Omega)} \psi \rangle$$ for $\Omega \subset \mathbb{R}$ measurable. Since $f$ is smooth and everywhere 2 to 1, if $\Omega$ is a set of Lebesgue measure $0$ then so is $f^{-1}(\Omega)$ so $\mu_\psi$ is absolutely continuous with respect to the Lebesgue measure for all $\psi.$ Therefore the spectrum is entirely absolutely continuous. I am having trouble finding a spectral basis so that I can decompose the operator into a direct sum of multiplication operators on finite measure spaces. There doesn't seem to be a general procedure for doing this and I can't think of a good place to start.","['operator-theory', 'spectral-theory', 'functional-analysis']"
282249,Extensions of degree two are Galois Extensions.,"This question from Allan Clark's ""Elements of Abstract Algebra"" Show that an extension of degree 2 is Galois except possibly when the characteristic is 2. What is the case when the characteristic is 2? Tips are helpful, a solution is ideal. Thanks.","['galois-theory', 'extension-field', 'abstract-algebra', 'field-theory']"
282250,An n dimensional even function,"I am now investigate some behavior of n-dimensional even functions on $\Bbb R^n$. For 1-dimensional even functions, because $f(x) = f(-x)$ for all $x \in \Bbb R$, so we only have to investigate for $x \geq 0$. For 2-dimensional even functions, because $f(x_1, x_2) = f(-x_1, -x_2)$ for all $x = (x_1, x_2) \in \Bbb R^2$, we only have to investigate for the region $R = \{ (x_1, x_2) \in \Bbb R^2 \; | \;x_2 \geq -x_1 \}. $ Then how can I generalize this for $n$ dimensional  even functions? (I mean how can I genralize the region $R$ above) Please help!","['functions', 'multivariable-calculus', 'real-analysis']"
282268,Unit sphere in $\mathbb{R}^\infty$ is contractible?,"Let $\mathcal{T}_{\infty}= \left\{ U \subset \mathbb{R}^{\infty}: \ U \cap \mathbb{R}^n \in \mathcal{T}_n, \text{ for } n=1,2,... \right\} $.
Of course $\mathcal{T}_{\infty}$ is topology in $\mathbb{R}^{\infty}$. How to prove that $S^{\infty} = \{ v \in \mathbb{R}^{\infty} : \ \|v\|=1 \}$ is contractible? :) Can we find homeomorphism without fixed point from $D^{\infty} = \{ v \in \mathbb{R}^{\infty} : \ \|v\| \le 1 \}$ onto $D^{\infty}$? I was trying to find such homeomorphism, but I failed...","['general-topology', 'algebraic-topology']"
282271,"""Scaled $L^p$ norm"" and geometric mean","The $L^p$ norm in $\mathbb{R}^n$ is
\begin{align}
\|x\|_p = \left(\sum_{j=1}^{n} |x_j|^p\right)^{1/p}.
\end{align}
Playing around with WolframAlpha, I noticed that, if we define the ""scaled"" $L^p$ norm in $\mathbb{R}^n$ to be \begin{align}
\| x \|_p = \left(\frac{1}{n}\sum_{j=1}^{n} |x_j|^p\right)^{1/p}
\end{align}
then
\begin{align}
\lim_{p \to 0} \|x\|_p &= \left( \prod_{j=1}^{n} |x_j| \right)^{1/n},
\end{align}
which is the geometric mean of the coordinates' absolute values. This is interesting maybe because the $L^p$ norm doesn't have a nice limit at zero. My questions: How do I prove this? Is this definition of ""scaled $L^p$ norm"" interesting, or known by another name, or used anywhere? Is there any interesting reason to define the $L^0$ norm as the geometric mean, as above? Further reading? Thanks!","['measure-theory', 'lp-spaces']"
282275,Is this function - characteristic function of a random variable?,"$\phi(t)=
\begin{cases}
1,&\text{if $|x|< 1$;}\\
e^{-(|x|-1)^2} ,&\text{if $|x|\geq1$.}
\end{cases}
$ Can anyone help?","['probability-theory', 'fourier-analysis', 'characteristic-functions']"
282279,Derivative of $\sqrt{\sin (x^2)}$,"I have problems calculating derivative of $f(x)=\sqrt{\sin (x^2)}$. I know that $f'(\sqrt{2k \pi + \pi})= - \infty$ and $f'(\sqrt{2k \pi})= + \infty$ because $f$ has derivative only if $ \sqrt{2k \pi} \leq |x| \leq \sqrt{2k \pi + \pi}$. The answer says that for all other values of $x$,  $f'(0-)=-1$ and $f'(0+)=1$. Why is that? All I get is $f'(x)= \dfrac{x \cos x^2}{\sqrt{\sin (x^2)}} $.","['calculus', 'derivatives']"
282297,How to represent each natural number?,"Assume we get the set of natural numbers $\mathbb{N}$ from any model of the Peano axioms. We're given the symbols: $0,1,2,3,4,5,6,7,8,9$, or rather, we're given $0$ and we choose to use the symbols $1,2,3,4,5,6, 7, 8,9$. Of course $0$ is the same from the model. Then we'll have, by definition,
  $1=S(0)$,
  $2=S(1)$,
  $3=S(2)$,
  $4=S(3)$,
  $5=S(4)$,
  $6=S(5)$,
  $7=S(6)$,
  $8=S(7)$ and
  $9=S(8)$. But how do we represent the rest of the natural numbers the way we expect them to be represented? I understand that $1, 2, 3, 4, 5, 6, 7, 8, 9$ are just shorthand representations for the entities written above. I guess my question can be particularized by: how do you know that the short hand notation for $S(999)$ is $1000$? I'm assuming the way to get a representation for each natural number starts the way I write it. If that's not the case, please do it from the top.","['notation', 'elementary-set-theory']"
282301,Fixed-Time Brownian Motion Exit Probabilities,"A standard computation using martingale techniques allows us to compute probability that a Brownian motion started at zero exits the interval $[-a,b]$ ($a, b > 0$) at $-a$ or $b$.  It appears to me that if we replace $B_t$ by $B_{t \wedge \delta}$ for small $\delta$, then the argument used in that computation breaks down because we no longer know that the new martingale exits this region almost surely.  This feels like a classical problem that should have been analyzed in detail at some point and I am curious if anyone happens to know the answer off-hand. Formally, there are two related questions I am interested in: Are there explicit formulas for $P(B_{t\wedge \delta}$ exits $(-a,b))$ or $P(B_{t \wedge \delta}$ exits $(-a,b)$ at $-a$)?","['probability-theory', 'stochastic-processes', 'brownian-motion']"
282307,Hard Telescoping Series,"Finding the explicit sum of a telescoping series with two factors in the denominator is quite easy: we split the fractions in the difference of two subpieces. But what about 2+ factors? E.g., consider: $$\sum\frac{1}{(2n+1)(2n+3)(2n+5)}$$ We could split it in three pieces by partial fractions, but difference of three pieces would be useless. Suggestions? Thanks.",['sequences-and-series']
282314,Is this analysis problem or discrete math problem?,"Suppose $x_{n} \in \mathbb{R}, x_{1} = 1, 2x_{n+1} = x_{n} + 3/x_{n}$. Then show that $\lim x_{n}$ exists and find its value. So is this problem (real) analysis problem or a discrete math one? Could you suggest me a good textbook that deals with this kind of problems? As for the solution of this problem, I'd love to get a solution but if you can't be bothered then you don't have to.","['discrete-mathematics', 'real-analysis']"
282321,how to solve a system with more equations than unkowns?,"In general, how do you solve a system with more equations than unknowns? I know that if I select the equations to match them with the number of unknowns, there may be zero or many solutions depending on our selection. Where can I go from there? And how does a ""pseudo inverse"" come in the picture? Thank you. -Cody EDIT: I know overdetermined system usually have no solution, but in my case (triangulation matting, i.e filtering out the weatherman from the blue screen), I was told there is a solution and I need to find it using pseudo inverse.",['linear-algebra']
282322,Is this proof correct? Textbook has no solution.,"Most of the problems in my textbook have numeric solutions in the back of the book except the proofs. Is this proof correct? Prove that if $A \cup B$ and $A \cap B$ are independent events, then either $P(A \cap B)=0$ or $P(A \cup B) = 0)$. $P((A \cup B) \cap (A \cap B)) = P(A \cup B)P(A \cap B)$ (definition of independence) $P(A \cap B)=P(A \cup B)P(A \cap B)$ (properties of sets and intersections) Either $P(AB)=0$ or $P(A\cup B)=1$. In the first case we already proved the proposition. In the second case $P(A\cup B)=1\implies P(\bar{A} \cap \bar{B})=0$. $\square$","['statistics', 'probability']"
282339,Logarithm as limit,Wolfram's website lists this as a limit representation of the natural log: $$\ln{z} = \lim_{\omega \to \infty} \omega(z^{1/\omega} - 1)$$ Is there a quick proof of this? Thanks,"['logarithms', 'limits']"
282342,"board game: 10 by 10 light bulbs, minimum switches to get all off?","Hy all!
My problem is as follows:
There's a board of 10 by 10 light bulbs. (So it's a square with 10 columns and 10 rows.)
Every single bulb has got its own switch. However, something went wrong and when you use a switch not only does it change the state of the proper light bulb but states of all other 18 bulbs in its column (9) and row (9). (a state change obviously means: off lights turn on, on lights turn off)
So one click changes the required bulb's state AND all the bulbs in its row and column.
How many clicks (switches used) will be needed at least to turn off all the bulbs if they are all on? I've literally spent hours thinking it over and over.
It's kinda straight-forward that the order of the clicks are irrelevant and using the same switch more than once is meaningless. (I mean using the same switch twice is like not using it at all, and using it three times is like only once {only parity (even/odd) matters}.) Consequently, there are 2^100 possibilities, so unfortunately more than a computer could check in reasonable time. Anyway, I would like to have a number with some kind of mathematical proof. My 'conjecture' is 100. I think one has to use all the switches to change the state of the whole table. (which works because all light bulbs would change 19 times) Although, there may be a better way (with a lesser number of switches)...
Any thoughts? :D","['combinatorial-game-theory', 'combinatorics']"
282347,Binomial distribution with random parameter uniformly distributed,"I have a problem with the following exercise from Geoffrey G. Grimmett, David R. Stirzaker, Probability and Random Processes , Oxford University Press 2001 (page 155, ex. 6): Let $X$ have the binomial distribution bin( $n$ , $U$ ), where $U$ is uniform on $(0,1)$ . Show that $X$ is uniformly distributed on $\{0,1,\ldots,n\}$ . So far, what I have is this: $$P(X=k | U) = {n \choose k} U^k (1-U)^{n-k}$$ $$P(X=k) = \int_0^1 {n \choose k} u^k (1-u)^{n-k} f_U(u) \text{ d}u$$ where $f_U(u)$ is density function of random variable $X$ . Of course, $f_U(u) = 1$ on $u\in (0,1)$ . $$P(X=k) = {n \choose k} \int_0^1 u^k (1-u)^{n-k} \text{d}u$$ And I don't know what to do next... How to calculate this integral? Am I solving it right so far?","['probability-theory', 'uniform-distribution', 'probability-distributions', 'binomial-distribution']"
282355,give an example of a function that is integrable in $\mathbb R $ and $\lim_{ x\to \infty}f(x)\neq0$,"i did a search for such function but didn't found anything useful/complete ! , like this : Integrable function $f$ on $\mathbb R$ does not imply that limit $f(x)$ is zero is there any function that is integrable and $\lim_{x \to \infty}f(x) \neq0 $ and $\infty$ ??","['lebesgue-integral', 'integration', 'real-analysis']"
282374,approximating Dirac delta with bounded derivatives,"Consider the Dirac delta distribution $\delta$ in $\mathbf{R}^d$. It is quite standard to approximate it by functions $g_n$ with $\|g_n\|_{L^1} = 1$. Is it possible to choose a sequence of test functions $\{g_n\}$ converging to $\delta$ as a distribution such that their derivatives are $L^1$-bounded?
I mean, such that for a given a natural number $k$ there is a constant $M>0$ so that $\|\partial^\mu g_n \|_{L^1} \le M$ for all $n$'s and all multi-indices $|\mu| \le k$?","['distribution-theory', 'functional-analysis']"
282386,Generalized divergence theorem,"In the common divergence theorem, shall the boundary (surface) not be smooth everywhere? Is there a version of this theorem where the boundary is nowhere differentiable?",['multivariable-calculus']
282414,Factoring Polynomials with four terms and two variables,"I've been working on this for hours and cannot figure it out. When I search, I find factorization techniques that I already know but don't seem to be able to apply here, or that are for polynomials that don't have the same form. I am beginning to wonder if this can even be factored. $$4x^2 + 4x - 9y^2 -1$$ The most I can figure to factor is: $$4x(x+1) - 9y^2 -1$$ Mahalo for the help, I am really trying to understand this.","['factoring', 'algebra-precalculus', 'polynomials']"
282436,Fibonacci( Binet's Formula Derivation)-Revised with work shown,"Okay so here is the revised question with my current work. Links to previous post(s)(Just for Gerry): Fibonacci Numbers - Complex Analysis Here's my attempt on the problem set thus far: (Note that $\bullet$ represents a completed problem (in my opinion) while $\circ$ represents a semi-completed problem.) ~Problem set can be found on page 106: http://www.math.binghamton.edu/sabalka/teaching/09Spring375/Chapter10.pdf (2) To derive a generating function for $f_n$, note that the fibonacci series is defined by the sequence of numbers $(0,1,f_1+f_0,f_2+f_1,...f_n+f_n-1)$. If we break this up into three separate generating functions and sum them to obtain the generating function $F(z)$ it will look something like: $$(0,1,0,0,0...) \rightarrow\,z)$$
$$+(0,f_0,f_1,f_2,...)\to\,zF(z)$$ for a $F(z) = f_0+f_1z+f_2z^2+...+f_nz^n$ 
$$+ (0,0,,f_0,f_1,f_2,...)\to z^2F(z)$$ for the same $F(z)$ This all equals $$(0,1+f_0,f_1+f_0,f_2+f_1,f_3+f_2,...)\to z+zF(z)+z^2F(z)$$ Therefore $F(z)=z+zF(z)+z^2F(z)$, solving for $F(z)$ we obtain $$F(z) = \frac {z}{1-z-z^2} \bullet$$ P.S. I don't understand why it says $\frac{1}{1-z-z^2}$ instead of  $\frac{z}{1-z-z^2}$ in the original problem set. Is it because they're excluding the $f_0$ and $f_1$ terms? ~ I felt that it would make more sense to do (2) before (1) so here's (1) *First note that by the quadratic formula, the two roots of the denominator are $\varphi,\bar \varphi$ where $\varphi= \frac {1+\sqrt5}{2}$. So $F(z)$ has a positive radius of convergence by the ratio test which gives $r=\lim_{n\to\infty}\frac{f_n+1}{f_n}= \bar \varphi \bullet$ ~ (3) Now to show that $Res (\frac{1}{z^n+1(1-z-z^2)})$ at $z=0$ = $f_n$ I know that you must use the formula: $Res(f,c) = \frac{1}{n-1!}\lim_{z\to c}\frac{d^n-1}{dz^n-1} ((z-c)^nF(z)$ for a pole of order n. I need a little help here. I'm also confused as to where they get the $z^n+1$ from. Why does it appear there?      $\circ$ Edit I realized that since $$1=Res_{z=0}z^{-1}$$ then  z^n+1 would be the extracting term: $$f_n=Res_{z=0}\frac{1}{z^{n+1}} \sum_{n>1}{f_nz^n}$$ Is this correct? Edit According to Brian M. Scott, the proper work for this problem (3) is $$\begin{align*}
\operatorname{Res}_{z=0}\left(\frac1{z^{n+1}(1-z-z^2)}\right)&=\frac1{n!}\lim_{z\to 0}\frac{d^n}{dz^n}\left(z^{n+1}\frac1{z^{n+1}(1-z-z^2)}\right)\\
&=\frac1{n!}\lim_{z\to 0}\frac{d^n}{dz^n}\big(F(z)\big)\\
&=\frac1{n!}\lim_{z\to 0}\frac{d^n}{dz^n}\sum_{k\ge 0}f_kz^k\\
&=\frac1{n!}\lim_{z\to 0}\sum_{k\ge 0}f_k\frac{d^n}{dz^n}z^k\\
&=\frac1{n!}\lim_{z\to 0}\sum_{k\ge n}f_k \Big( \prod_{i=0}^{n-1} (k-i) \Big)z^{k-n}\\
&=\frac1{n!}\lim_{z\to 0}\left(f_nn!+\sum_{k>n}f_k \Big( \prod_{i=0}^{n-1} (k-i) \Big) z^{k-n}\right)\\
&=f_n+\frac1{n!}\lim_{z\to 0}z\sum_{k\ge n+1}f_k \Big( \prod_{i=0}^{n-1} (k-i) \Big) z^{k-(n+1)}\\
&=f_n\; \bullet
\end{align*}$$ I follow this work until the third to last step where I don't understand how he obtained the $f_nn!$ term. Any Explanations? (4) 
Using the residue theorem $$\int_{\gamma} f(z) dz = 2 \pi i \sum_{\rho} \text{Res}(f(z)),z=\rho)$$ Now quite obviously applying this: $$\int_{\gamma} \frac{dz}{z^{n+1}(1-z-z^2)} = 2 \pi i [f_n + R\varphi + R_{\bar \varphi}]$$ Okay, so obviously we must parametrize over a circle of radius R. This parametrization is $\gamma(t) = Re^{it}$ because a circle is just a simple curve. Performing a change of variables, we obtain  $$\int_0^{2 \pi} \frac{i R e^{it} dt}{R^{n+1}e^{it(n+1)}(1-(Re^{it})-(Re^{it})^2)}$$ The only reason that I personally thought of why this integral $\to 0$ is because the one can trivially see that the denominator would be $>>$ than the numerator because you have $\infty$ raised to a power. I'm also confused as to why it's even necessary to show that this integral disappears as the Radius of the circle approaches $\infty$. Could someone care to explain? Finally, for the exact calculations of $(R\varphi, R_{\bar \varphi})$ First note that $(1-z-z^2)=(\varphi + z)(\bar \varphi-z)
$$R_\varphi = \text{Res}(\frac{1}{z^{n+1}(1-z-z^2)},z=\varphi) = \lim_{z \to \varphi}\frac{z-\varphi}{z^{n+1}(1-z-z^2)} = \lim_{z \to -\varphi}\frac{z-\varphi}{z^{n+1}(\varphi + z)(\bar \varphi-z)} =\frac{1}{\varphi^{n+1}(1-\bar \varphi)}$$  
  Alternatively,  
$$R_\bar \varphi = \text{Res}(\frac{1}{z^{n+1}(1-z-z^2)},z=\bar \varphi) = \lim_{z \to \bar \varphi}\frac{z-\bar \varphi}{z^{n+1}(1-z-z^2)} = \lim_{z \to \bar \varphi}\frac{z-\bar \varphi}{z^{n+1}(\varphi + z)(\bar \varphi-z)} =\frac{1}{\bar \varphi^{n+1}(1- \varphi)} \circ$ (5) Requires the completion of (4) This is all of my current work that I have thus far. I honestly do not know where to go from my last step in (4). I still need to arrive at a final identity for $f_n$. So I need to know how to continue this work. Any hints, etc? Thanks!~ Edit I now understand that $$f_n=Res (F(z)) at z=0= \Big(Res(F(z) at z=0 + Res(F(z) at z= \varphi + Res(F(z) at z=\bar \varphi\Big) - \Big(Res(F(z) at z= \varphi + Res(F(z) at z=\bar \varphi\Big) = {2\pi i}\int F(z)dz - - \Big(Res(F(z) at z= \varphi + Res(F(z) at z=\bar \varphi\Big) = - \Big(Res(F(z) at z= \varphi + Res(F(z) at z=\bar \varphi\Big) $$ because the integral $$2\pi i\int F(z)dz \to 0$$ as $R \to \infty$ Is this correct?","['fibonacci-numbers', 'residue-calculus', 'complex-analysis']"
282442,a neighbourhood of identity $U$ generates $G$ where $G$ is a connected lie group,Let $G$ be a connected Lie group and  $U$ any neighbourhood of the identity element. How to prove that $U$ generates $G$.,"['lie-groups', 'differential-geometry']"
282454,The converse of Tychonoff theorem?,"Suppose, a topological space  $(X, \mathscr{T})$ is compact, and the cardinality of $X$ is $2^\kappa$. Is there a compact space $A$ with the cardinality not larger than $2^\kappa$, such that $A^\kappa$ with the product topology $\mathscr{T'}$coincide with $(X, \mathscr{T})$? In other words, Could $(X, \mathscr{T})$ be homeomorphic to $(A^\kappa, \mathscr{T'})$? Added: As pointed out in Ittay Weiss's and Nate Eldredge's answers, the answer is negative when $\kappa$ is finite and when  $(X, \mathscr{T})$ contains a isolated point. I become interested in the condition that guarentees the homeomorphism exists. In particular, I'm interested in the case when $\kappa$ is infinite, and no isolated point in  $(X, \mathscr{T})$, say, the closed interval with the usual topology.","['general-topology', 'compactness']"
282462,Upper bound for the absolute value of an inner product,"I am trying to prove the inequality
$$ 
\left|\sum\limits_{i=1}^n a_{i}x_{i} \right|  \leq \frac{1}{2}(x_{(n)} - x_{(1)}) \sum\limits_{i=1}^n \left| a_{i} \right| \>,$$
where
$x_{(n)} = \max_i x_i$ and $x_{(1)} = \min_i x_i$, subject to the condition $\sum_i a_i = 0$. I've tried squaring and applying Samuelson's inequality to bound the distance between any particular observation and the sample mean, but am making very little headway. I also don't quite understand what's going on with the linear combination of observations out front. Can you guys point me in the right direction on how to get started with this thing?","['statistics', 'inequality', 'sequences-and-series', 'analysis']"
282489,"Show that the rational conic $F(x,y)=ax^2+bxy+cy^2+dx+ey+f$, subject to a certain condition, is non-singular","Let $C$ be the conic given by the equation $F(x,y)=ax^2+bxy+cy^2+dx+ey+f=0$.  Show that if $$\begin{vmatrix}
 2a&b  &d \\ 
 b&2c  &e \\ 
 d&e  &2f 
\end{vmatrix}\neq 0,$$ then $C$ has no singular points. So I want to show that there are no points $(x,y)$ such that $F(x,y)=\frac{\partial F}{\partial x}(x,y)+\frac{\partial F}{\partial y}(x,y)=0$.  I've come at this a couple different ways.  First, since the determinant is non zero then this matrix is bijective and thus since its first two rows are precisely the coefficients of $\frac{\partial }{\partial x}$ and $\frac{\partial }{\partial y}$, respectively, this means that I should look at vectors $[x,y,z]$ which it maps to the vectors $[0,0,\lambda]$.  This means that the singular point (there can be only one since otherwise the determinant would be zero) must lie on some complex plane through the origin (in $\mathbb{C}^3$ I guess), which maps to the the $x=y=0$ subspace of $\mathbb{C}^3$.  This doesn't really seem to go anywhere though, so @#%! it, I'll just set the two partial derivatives equal to zero, solve for $x$ and $y$, and then plug those into $F(x,y)$ and hope I can show it can't be equal to zero while keeping the determinant non-zero.  This was a ton of computation but I did it and ended up with a somewhat messy expression in $a,...,e$, but I can't find enough commonality among the terms to say anything useful about its structure. Thoughts: There must be some reason for their choice of the third row of this matrix, but I'm not sure what it is.  It does make the matrix hermitian, and in a way writing this matrix is based on a homogenization of the equations for the partial derivatives, so maybe I'm suppose to look at things in the projective plane? So this is where I am, can anyone help me? Thanks.",['abstract-algebra']
282493,analytic function $f$ such that $f(z)^2 = z$,"Delete from the complex plane the non-positive part of the imaginary axis. How do we explicitly define an analytic function $f$ on our ""modified complex plane"" satisfying $f(z)^2 =z$? This was an exercises from years ago. My old notes just put $f(z)= \sqrt{x}$, which I think is wrong. Also, I have no idea what our professor meant by explicitly. My guess is to show its analyticity, but I'm at a loss on where to start here.",['complex-analysis']
282498,Is Wikipedia incorrect on the Cauchy - Riemann equations (sufficient condition for differentiability)?,"According to Wikipedia , ""Moreover, the equations are necessary and sufficient conditions for complex differentiation once we assume that its real and imaginary parts are differentiable real functions of two variables.""  I've always thought that the C-R equations holding alone isn't sufficient for differentability.  You would need the continuity of the partial derivatives, right?  The talk page made me more confused.",['complex-analysis']
282503,"Density and closedness of $C[0,1]$ in $L^\infty[0,1]$ in norm and weak-* topologies","With results: ""For convex subsets of a locally convex space,
a, originally( strongly) closed equals weakly closed, and 
b, originally (strongly dense equals weakly dense.""
Could you help me solve this problem? $L^\infty[0,1]$ has its norm topology coming from the essential supremum norm $$\|f\|_\infty=\operatorname{ess sup}|f|=\inf\{a\in\mathbb{R}\mid \mu(\{x\in X\mid |f(x)|>a\})=0\}$$ and its weak*-topology as the dual of $L^1$. Prove that C, the space of all continuous functions on $[0,1]$, is dense in $L^\infty$ in one of these topologies but not in the other. (Compare with the above result). Shoe the same with ""closed "" in place of ""dense."" Thanks in advance.","['general-topology', 'real-analysis', 'topological-vector-spaces', 'hilbert-spaces', 'functional-analysis']"
282506,Asymptotic rate of growth of a sum,"Consider $$\Phi_0(x) = \sum_{i=0}^{\infty} (1-x)^i,$$ where $x \in (0,1)$. As $x \rightarrow 0$, $\Phi_0(x)$ blows up as $\Theta(1/x)$. Similarly, consider $$ \Phi_1(x) = \sum_{i=0}^{\infty} i (1-x)^i.$$ As $x \rightarrow 0$, a direct calculation shows that $\Phi_1(x)$ blows up as $\Theta(1/x^2)$. What I am interested in is the sum
$$ \Phi_{1/2}(x) = \sum_{i=0}^{\infty} \sqrt{i} (1-x)^i.$$ My question is: how fast does $\Phi_{1/2}(x)$ blow up as $x \rightarrow 0$? I suspect this is routine and easily solvable with some trick. In the case of $\Phi_0$ and $\Phi_1$, explicit expressions make the asymptotic rate of blowup easily calculable. I don't know a simple expression for $\Phi_{1/2}$.","['asymptotics', 'sequences-and-series', 'analysis']"
282517,Uniqueness of Hermitian inner product,"Let V be an irreducible representation of a finite group G.How to show that up to scalars,there is a unique Hermitian inner product on V preserved by G. i know of how to get an inner product. but i have no idea on the uniqueness part. i think i have to use schur's lemma in some way","['linear-algebra', 'representation-theory']"
282541,Special properties of $\mathbb{R}^3$,"Are there any special (nontrivial) properties of $\mathbb{R}^3$ that distinguish it from any other $\mathbb{R}^n$? If there are, what are some of the important ones?","['general-topology', 'euclidean-geometry']"
282554,"distance between two subset , seperation of two subset in a metric space","Given $(X,d)$ a metric space for subsets $A,B$ of $X$, define $$d(A,B)=\inf\{d(a,b):a\in A,b\in B\}$$ could any one confirm me with logic which of the following are/is true and false? if $\bar{A}\cap\bar{B}=\phi$, then $d(A,B)>0$ if $d(A,B)>0$ then there exists open sets $U\supsetneq A,V\supsetneq B$, $U\cap V=\phi$ $d(A,B)=0$ iff there exist a sequence of points $\{x_n\}$ in $A$ converging to a point in $B$. well,  I took several example from $\mathbb{R}$ and found that $1$ is true, as any metric space is normal $2$ is also true, $3$ is true as in that case $x\in \bar{A}\cap\bar{B}$ and hence by the definition it is true. Thank you.",['general-topology']
282557,"Construct with a rule and compass a square, given one point from each side","Construct with a ruler and compass a square, given one point from each side. I was reading the answer to Square Deal , and I do not understand how the rest is easy to solve.  Could someone help me understand?  I don't see the square.",['geometry']
282559,"(Paul Bartha and Christopher Hitchcock, “The Shooting Room Paradox and Conditionalizing on Measurably Challenged Sets,” Synthese, March 1999)","I first read this problem here . I am having trouble finding the expected value of the game.  I understand for the first round,but on the 2nd round assuming that no group is killed, does just one person role the dices and if not (6,6), then someone roles for the other 89? Or is it 10 people role the dice and if none of them die, then one role for the other 80? I am having trouble viewing a copy of the primary paper.",['probability']
282589,101 positive integers placed on a circle,"A Pigeonhole Principle problem: 101 positive integers are placed on a circle whose sum is 300. Prove
  that it is possible to choose from these numbers some consecutive
  numbers whose sum is equal to 200. (I don't know if the word 'consecutive' is appropriate in this case ,I mean that these numbers follow each other on that circle)","['pigeonhole-principle', 'combinatorics']"
282597,Problem from Herstein on group theory,"The problem is: If $G$ is a finite group with order not divisible by 3, and $(ab)^3=a^3b^3$ for all $a,b\in G$, then show that $G$ is abelian. I have been trying this for a long time but not been able to make any progress. The only thing that I can think of is:
$$ab\cdot ab\cdot ab=aaa\cdot bbb\implies(ba)^2=a^2b^2=aabb=(\text{TPT})abba.$$
Now, how can I prove the last equality? If I write $aabb=abb^{-1}abb$, then in order for the hypothesis to be correct, $b^{-1}abb=ba\implies ab^2=b^2a$. Where am I going wrong? What should I do?","['finite-groups', 'group-theory', 'abstract-algebra']"
282609,Is the space of bounded functions with the Supremum norm a Banach Algebra,"X is an arbitrary , non empty set, B(X) the set of bounded functions $f:X\rightarrow \mathbb{R}$ and $||f||_\infty = \sup_{x\in X }|f(x)|$. Is $(B(X),||.||_\infty )$ a Banach Algebra? My attempt at showing that this is true: Definition of a Banach Algebra: A normed space E with elements f,g,... is called normed Algebra if it is an Algebra and the multiplication with the norm fulfills: $$||fg||\le ||f||\cdot||g||$$ A normed algebra is a Banach algebra , if it is complete as a space (if it is a Banach space). * Defintion of an Algebra:* If K is a field , A a vector space equipped with multiplication operation in form of $A \times A \rightarrow A$, then A is an algebra if for $x,y,z \in A $ and $a,b \in K$ scalars it holds that: $$1. (x+y)\cdot z = xz+yz \\2: x\cdot(y+z)=xy+xz \\ 3: (ax)\cdot (by)=(ab)(x\cdot y)$$ In this case A is B(X) and x,y,z are bounded functions, $a,b\in \mathbb{R}$ and it fulfills (1-3) of the Algebra definition. Now for the step from  Algebra to normed Algebra one has to check the submultiplicativity :  $$\sup_{x\in X}|f(x)g(x)| \le \sup _{x \in X} |f(x)|\sup_{x\in X}|g(x)|$$ How to show this ???","['multivariable-calculus', 'banach-algebras', 'real-analysis', 'analysis']"
282620,Equation $\displaystyle\sum_{k=0}^{n-1}(-1)^{n-k-1}\dfrac{(n+k)!}{(k!)^2(n-k-1)!}=n^2$,"I think  this equality is very inters
prove that: $\displaystyle\sum_{k=0}^{n-1}(-1)^{n-k-1}\dfrac{(n+k)!}{(k!)^2(n-k-1)!}=n^2$","['sequences-and-series', 'calculus', 'discrete-mathematics']"
282628,Second derivative of function of two variables,"I'm having problemes using the chain rule in the 2-variables case. I know that the first derivative of a function $f=f\left(t,u(t)\right)$ is $$\frac{df}{dt}=\frac{df}{dt}+\frac{df}{du}\frac{du}{dt}$$ Then, if I apply the chain rule in this expression I get: $$\frac{d^2f}{d^2t}=\left[\frac{df}{dtdu}\frac{du}{dt}+\frac{d^2f}{d^2t}\right]+\left[\frac{d^2u}{d^2t}\frac{df}{du}+\frac{du}{dt}\left(\frac{d^2f}{d^2u}\frac{du}{dt}+\frac{df}{dudt}\right)\right]$$ where the first group comes from derivating the first term of $\frac{df}{dt}$ and the second group from derivating the second one. However, shouldn't this derivative look like the following? $$\frac{d^2f}{d^2t}=\frac{d^2f}{d^2t}+2\frac{du}{dt}\frac{df}{dudt}+\frac{d^2f}{d^2u}\left(\frac{du}{dt}\right)^2$$ I'd appreciate if someone could explain me a little bit what I am doing wrong.",['multivariable-calculus']
282635,"Quotient topology of $[0,1]$","Is it possible to define an equivalence relation $\sim$ on $[0,1]$ in such a way that $[0,1]/\sim$ is not second countable?",['general-topology']
