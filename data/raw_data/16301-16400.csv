question_id,title,body,tags
132200,A mountain given my an elliptic paraboloid.,"The Question Suppose that a mountain has the shape of an elliptic paraboloid given by $z = c - ax^2 - by^2, a,b,c \in (0,\infty)$ and $x$ and $y$ are the east-west and north-south map coordinates, and $z$ is the altitude above sea level. At point $(1,1)$ , in what direction is the altitude increasing most rapidly? If a marble were released at $(1,1)$ in what direction would it begin to roll? My answer: To start I turned the paraboloid into a level set given by $ax^2 + by^2 + z = c$ and then found the gradient function $\nabla f = (2ax, 2by, 1)$ which at $(1,1)$ is $(2a, 2b, 1)$. But I know that this is the direction of the normal to the 'mountain' so it can't be the direction that the altitude is increasing most rapidly. Can someone please shed some light? For the second part I assume that the marble would roll in the opposite direction to the direction the altitude is increasing most rapidly. So just the negative of the answer to the last part!","['multivariable-calculus', 'vector-analysis']"
132221,Exhibiting open covers with no finite subcovers.,"How do I exhibit an open cover of the closed unit ball of the following: (a) $X = \ell^2$ (b) $X=C[0,1]$ (c) $X= L^2[0,1]$ that has no finite subcover?","['examples-counterexamples', 'hilbert-spaces', 'functional-analysis', 'banach-spaces']"
132225,"Under weak convergence, is the limit's moment infinite if the sequence's moments are infinite?","If a sequence of random variables $X_n$ converges in distribution to some r.v. $X$, the convergence of moments doesn't immediately follow. However, if the sequence is uniformly integrable, then we have the convergence of moments. Thus, for example, if $X_n\Rightarrow X$ and $\sup \mathbb{E}[|X_n|^{1+\varepsilon}]<\infty$ for some $\varepsilon >0$ (a sufficient condition for uniform integrability), then $\mathbb{E}[|X|]<\infty$ and $\mathbb{E}[X_n]→\mathbb{E}[X]$. (See for example Theorem 25.12 and Corollary in Billingsley's Probability and Measure). My situation however is this: $X_n\Rightarrow X$, and $\mathbb{E}[X_n]=\infty$. QUESTION: Does it follow that $\mathbb{E}[X]=\infty$ too? Let me add that all the $X_n$ and $X$ are nonnegative so their moments are defined ($\mathbb{R}_+ \cup \infty$). The moment convergence results I've seen all invoke uniform integrability and finiteness of moments, which doesn't apply here. Is it even possible to have $\mathbb{E}[X]<\infty$ (a counterexample would be instructive)? Or might anyone be able to suggest other additional conditions so that $\mathbb{E}[X]=\infty$?",['probability-theory']
132238,convergence with respect to integral norm but not pointwise,"I want to give an example of a sequence of functions $f_1 \dots f_n$ that converges with respect to the metric $d(f,g) = \int_a^b |f(x) - g(x)| dx$ but does not converge pointwise. I'm thinking of a function $f_n$ that is piecewise triangle, whose area converges to some constant function, but doesn't converge pointwise. I just can't manage to formalize it.",['real-analysis']
132250,Could you give a application of a special function on number theory or analysis?,"With the best effort i have ever taken, i couldn't find a application of a special function on number theory or analysis on the internet. By the way, why is the applications of special functions in pure math almost never mention in books","['analysis', 'special-functions', 'number-theory']"
132251,"Show $\langle a^m \rangle \cap \langle a^n \rangle = \langle a^{\operatorname{lcm}(m, n)}\rangle$","So I want to show that $\langle a^m \rangle \cap \langle a^n \rangle = \langle a^{\operatorname{lcm}(m, n)}\rangle$. My approach to this problem was to show a double containment, i.e. to show that $\langle a^m \rangle \cap \langle a^n \rangle \subseteq  \langle a^{\operatorname{lcm}(m, n)}\rangle$ and $ \langle a^{\operatorname{lcm}(m, n)}\rangle \subseteq \langle a^m \rangle \cap \langle a^n \rangle$. I would like to see a full proof for this, specifically $\langle a^m \rangle \cap \langle a^n \rangle \subseteq \langle a^{\operatorname{lcm}(m, n)}\rangle$. (I tried it with the approach of breaking it down into to cases; $a$ has infinite order and $a$ has finite order, the latter of which i would appreciate the most help on.) My approach to solving the whole problem: (I would appreciate any feedback on anything that is wrong, or a different approach to the proof.) To show the easier containment, $\langle a^{\operatorname{lcm}(m, n)}\rangle \subseteq \langle a^m \rangle \cap \langle a^n \rangle$, I did the following:
 Let $l = \operatorname{lcm}(m, n)$. Let $j \in \langle a^l\rangle$, so $j = (a^l)^k = a^{lk}$ for some $k \in \mathbb Z$. Since $l$ is a multiple of $m$ and $n$ by definition, we can say $l = ms = nt$ for some $s, t \in \mathbb Z$. Now $j = a^{kl} = a^{kms} = (a^m)^{ks} \in \langle a^m\rangle$. Similarly, $j = a^{kl} = a^{knt} = (a^n)^{kt} \in \langle a^n\rangle$. Now, since $j \in \langle a^m\rangle$ and $j \in \langle a^n\rangle$, it follows that $j \in \langle a^m \rangle \cap \langle a^n \rangle$. Thus, by definition, $\langle a^{\operatorname{lcm}(m, n)}\rangle \subseteq \langle a^m \rangle \cap \langle a^n \rangle$. For the second containment, the one which I'm having more problems with, I attempted the following: Case in which $a$ is infinite: Suppose that $\vert a \vert = \infty$. Let $c \in \langle a^m \rangle \cap \langle a^n \rangle$. Then $c = a^{mx} = a^{ny}$ where $x, y \in \mathbb Z$. It follows that $a^{mx - ny} = e$ and so $mx = ny$ because if $mx  > ny$ then the difference would not be zero, and we would have an element that was finite, contradicting our hypothesis. And since $mx = ny$ we know $\operatorname{lcm}(mx, ny) = mx = ny$ and $\operatorname{lcm}(mx, ny)$ is a multiple of $\operatorname{lcm}(m, n)$. Hence $c \in \langle a^{\operatorname{lcm}(m, n)}\rangle$ and thus $\langle a^m \rangle \cap \langle a^n \rangle \subseteq  \langle a^{\operatorname{lcm}(m, n)}\rangle$. Case in which $a$ is finite: I tried starting it out the same as the previous case, but i could never reach my conclusion :(","['cyclic-groups', 'group-theory', 'abstract-algebra', 'gcd-and-lcm']"
132260,Product of two regular spaces,"Def: A space $X$ is regular if $\forall x \in X$, and for every closed set $C \subset F$ with $x \notin C$, there exists disjoint open sets $U$ and $V$ s.t $x \in U$ and $C \subset V$. Problem: A subspace of a regular space is regular; $X \times Y$ is regular iff each of $X$ and $Y$ is regular. So, the first part I think I figure out. A Subspace of a regular space is regular. Proof: Let $Y$ be a subspace of a regular space $X$ and let $x \in Y$ and $F$ be a closed set in $Y$ not containing $x$.  Since $Cl_{X}(F) \cap Y = F$ then $x \notin Cl_{X}(F)$.  Then because $X$ is regular $\exists U,V$ disjoint open set in $X$   such that $  x \in U$ and $Cl_{X}(F) \subset V$. Then $U \cap Y$ and $V \cap Y$ are open sets in Y such that $x \in U \cap Y$ and $F \subset V \cap Y$.  Therefore $Y$ is a regular subspace of $X$. The second half of the question is where I'm having trouble.  I feel like it should follow straight forward from the definition of a regular space and work out component wise on $X \times Y$, but at the same time I know how these questions go and that the question wouldn't be phrased how it is if I didn't need to use the fact that a subspace of a regular space is regular.  Also,  talking to a friend made me feel this to be even more true, but I can't seem to get it or see why it is really needed. Here's my attempt though. $X \times Y$ is regular iff each of $X$ and $Y$ is regular. Proof: $\Rightarrow$) Assume $X \times Y$ is regular.  Then $\forall (x,y) \in X \times Y$ and for every closed $(F_{1}, F_{2}) \subset X \times Y$ with $(x,y) \notin (F_{1}, F_{2})$ there exists disjoint open sets $(U_{1}, U_{2}), (V_{1}, V_{2}) $in $ X \times Y$ such that $(x,y) \in (U_{1}, U_{2})$ and $(V_{1}, V_{2}) \subset (F_{1}, F_{2})$.  Then $x \in U_{1} \subset X$, $y \in U_{2} \subset Y$, and $V_{1} \subset F_{1}$ in $X$ and $V_{2} \subset F_{2}$ in $Y$.  Therefore, $X$ is regular and $Y$ is regular. $\Leftarrow$) I'm not really sure here, and the proof I have now for this part is fairly analogous to the first implication. As far as using the subspace result for proving the second half of the question the only thing I can really think to do is to consider, the subspaces $X$ and $Y$ in $X \times Y$ but I wasn't able to quite get the proof when messing around with that and my notation is probably a little off since I have not done much with products in topology, so I'll spare everyone and not post that. This question seemed like it would be fairly easy on first glance I'm not sure why it's getting me so confused. Anyways, thank you very much for any help/insight you can provide.","['general-topology', 'separation-axioms', 'product-space']"
132267,Countable union of measure $0$ sets has measure $0$,I want to ask if it is true in general topological space that the countable union of sets of measure $0$ has $0$ measure?,['measure-theory']
132284,Two related questions about flipping a coin an infinite number of times,"So I've been thinking about probability, and frequently you hear people talking about what it means for a coin to come up heads with probability $\frac{1}{2}$. If you were to flip the coin an infinite number of times, then the proportion of heads to tails would be $\frac{1}{2}$. This seems weird to me, and here's why: say we had a special coin that came up heads with probability $\frac{9}{10}$, and we flipped it infinitely many times. This seems to mean that the set of coin flips that come up heads should be $9$ times bigger than the set of coin flips that come up tails. However, both sets are denumerable, so strictly speaking these sets should be the same size—no? Is this not contradictory? My second question is related: it occurs to me that what is truly meant by ""if we let $n$ be the number of coin flips and $p(n)$ be the proportion of $n$ tosses that come up heads, $\lim_{n\rightarrow\infty}p(n)=\frac{9}{10}$"" (this still bothers me however because it seems to imply that there's no such thing as an infinite set of coin tosses, and, well, shouldn't there be?), but the $\infty $ that we are approaching here is the countable one. Could we ever imagine flipping a coin once for every real number? It would be like, a function $t:\mathbb{R}\rightarrow \{H,T\}$ with the property that for all $x\in \mathbb R, P(t(x)=H)=\frac{9}{10}$. Same question though: I would want the set $\{x\in \mathbb{R}|t(x)=H\}$ to be somehow nine times bigger than $\{x\in \mathbb{R}|t(x)=T\}$, but they're both infinite (uncountably so, this time). What's going wrong? I've tried asking this in other places, but I got some answers that seemed not to check out to me. You guys seem pretty smart though.",['probability-theory']
132286,Proving a set is uncountable,"I'm having a bit of trouble thinking of how to prove this homework problem. Prove that a set $A$ is uncountable if there is an injective function $f:(0, 1)\rightarrow A$. I know $(0, 1)$ is uncountable, but I can't think of a proof to show that $A$ must be as well. Could I do it through contradiction and say that there is no injective function? Thanks!","['elementary-set-theory', 'functions']"
132304,Taylor series of an entire function which is not a polynomial,I have an entire function which is not a polynomial. Is there a way to use the Casorati-Weierstrass theorem to prove there exists a point $z_0$ such that every coefficient of the Taylor series at $z_0$ is not zero?,['complex-analysis']
132305,How to prove that $\lim \limits_{n\rightarrow \infty} \frac{F_{n+1}}{F_n}=\frac{\sqrt{5}+1}{2}$,"How would one prove that
$$\lim_{n\rightarrow \infty} \frac{F_{n+1}}{F_n}=\frac{\sqrt{5}+1}{2}=\varphi$$ where $F_n$ is the nth Fibonacci number and $\varphi$ is the Golden Ratio?","['fibonacci-numbers', 'golden-ratio', 'limits']"
132320,Rudin's Complex and Real Analysis: Regular measure,"This is for anyone who has Rudin's Real and Complex analysis book at hand. I was looking at Rudin's Theorem 2.17 and 2.18. So far everything makes sense, except for one statement that Rudin makes in Theorem 2.18 on page 48. He states the following: ""Since $\lambda(K) < \infty$ for every compact $K$, $\Lambda$ is a positive linear functional on $C_c(X)$,...."" I'm more interested in how he used the hypothesis that $\lambda(K) < \infty$ for all compact set $K$ to conclude that $\Lambda$ is a positive linear function on $C_c(X)$. At least to my limited knowledge, we are trying to verify that $\Lambda(\alpha f + \beta g) = \alpha \Lambda(f) + \beta \Lambda(g)$ for scalars $\alpha, \beta$ and $f,g \in C_c(X)$. In the first line of Theorem 2.18, Rudin sets $\Lambda f = \int_X f \ d\lambda$ for every $f \in C_c(X)$. Since each $f$ has compact support, then $ \Lambda f = \int_X f \ d\lambda = \int_K f \ d\lambda $. Then from there, I was uncertain how to verify $\Lambda$ is a positive linear functional. Any tips for this question would be appreciated.",['measure-theory']
132321,Reflection of orthocenter about side midpoints lies on circumcircle,"For triangle $AB$C with orthocenter $H$, let midpoint of $AB$ be $C'$. Let point $P$ be such that $PH$ has $PC' = C'H$. That is, $P$ is reflection of orthocenter about midpoint of $AB$. Show $P$ lies on circumcircle of $ABC$. I approached this by trying to show that $\angle ABC = \angle APC$. I showed that $\angle ABC$ is same as angle between lines $HA$ and $CH$ but I can't get any further. I don't know how to use the fact that orthocenter is reflecting across the midpoint.",['geometry']
132323,Show that the matrix $A$ with integer entries is injective on the reals to $\mathbb{R}^m$ iff it is injective on the integer lattice.,"Show that the $m \times n$ matrix $A$ with integer entries is an injective linear map from $\mathbb{R}^n$ to $\mathbb{R}^m$ iff  it is injective as a linear map from $\mathbb{Z}^n$ to $\mathbb{Z}^m$. One direction is quite obvious, it is injective on the reals, the kernel is empty and intersecting that with $\mathbb{Z}^n$ is still empty so the map restricted to the lattice has trivial kernel and is therefore injective. In the other direction I can't seem to make progress. I have been trying to think about it in two different ways. The first, consider the columns of the matrix. For it to be injective as a map between lattices, these columns need to be linearly independent, i.e. they satisfy no non trivial relation ($\sum r_iv_i =0$ implies $r_i = 0$). However, the key is that they don't satisfy an non trivial relation over the integers, but this may not be the case over the reals; there may be some non-zero real numbers $r'_i$ that cause $\sum r_iv_i =0$ and thus the map is not injective as a map between real spaces. This is where we need to use the fact that entries in the column vectors are also integers. Clearly injectivity over integers implies it for the rationals because if we could find special rationals $r'_i$ that cause $\sum r_iv_i =0$ we could just clear denominators and derive a contradiction. The other way I've been trying to think about it is by proving the converse. Suppose the map wasn't injective we have to show that it can't be both composed of integer entries and injective as map between lattices. For it to be injective as a lattice map though would mean that the none of standard basis elements of $\mathbb{R}$ are in the kernel, and that no integer (or rational and just clear denominators) combination of them are in the kernel either, thus for something to be in the kernel it has to be linear combination of the basis vectors with at least one coefficient irrational. I think this proves it, but I feel unsatisfied, so I am not sure if something is wrong.","['modules', 'integer-lattices', 'linear-algebra']"
132329,Evaluate $\lim_{x \to 0} \left(\frac{1}{\ln(1+x)} + \frac{1}{\ln(1-x)}\right)$,"Evaluate $\displaystyle \lim_{x \to 0} \left(\frac{1}{\ln(1+x)} +
 \frac{1}{\ln(1-x)}\right)$ I am having trouble starting this one. I couldn't see any log laws that I'm familiar with to rearrange the formula. I also tried combining the fractions and using L'Hospital's, but it only seemed to make things worse. What direction should I take with this?","['calculus', 'limits']"
132349,The set of all nilpotent elements is an ideal,"Given that R is commutative ring with unity, I want show that set of all nilpotent elements is an ideal of R. I know how to show ideal if set is given but here set is not given to me. Can anyone help me?","['ideals', 'abstract-algebra']"
132364,How Many Three-of-a-Kinds in Standard Poker?,"Given 5 cards hand,How many ways are there to have a three of a kind hand? I think that it is $13*(4C3)*48*49-(\text{Full Houses})-(\text{4 of a Kinds})$ which is $13*4*48*49-13*12*(4C3)*(4C2)-13*48=122304-3744-624$ Can you confirm that? Correction thanks to Arturo Magidin:
$13*(4C3)*(49C2)-(\text{Full Houses})-4*(\text{4 of a Kinds})=54,912$",['combinatorics']
132377,Question on Radon Nikodym Theorem,"Let $\mu,\lambda$ and $\nu$ be $\sigma$-finite measures on $(X,M)$ such the $\nu\ll \mu$. Let $\mu= \nu + \lambda$. Then if $f$ is the Radon-Nikodym derivate of $\nu$ wrt $\mu$, we have $0\leq f\lt 1~\mu$-a.e. where $f = \frac{d\nu}{d\mu}$. Approach. Suppose to the contrary that $f\geq 1$. Then since I can infer $\nu \ll \mu$, $$\nu(E) = \int_E f~d\mu \geq \int_E 1 d\mu = \mu(E).$$ But then $\nu(E) \leq \nu(E) + \lambda(E) = \mu(E)$. So a contradiction. Thus $f\lt 1~\mu$-a.e. Please, does this look okay?",['measure-theory']
132415,Vector derivation of $x^Tx$,"Let $x \in \mathbb{R}^n$ What is $$\frac{\partial}{\partial x} [ x^Tx ]$$ My guess is: $\frac{\partial}{\partial x} [ x^Tx ] = 0$, because $[x^Tx] \in \mathbb{R}^1$, hence a real number as is interpreted as scalar in this derivation.","['vector-analysis', 'derivatives']"
132416,"Basis for $\Bbb Z[x_1,\dots,x_n]$ over $\Bbb Z[e_1,\dots,e_n]$","I'm reading the introductory bits in Procesi's Lie Groups , and on p. 22 we have (paraphrasing) Theorem 2. $\mathcal{B}=\{x_1^{\large h_1}\cdots x_n^{\large h_n}: 0\le h_k\le n-k\}$ is a basis for the ring $\Bbb Z[x_1,\dots,x_n]$ considered over $\Bbb Z[e_1,\dots,e_n]$ , where $e_i$ are the elementary symmetric polynomials in the $x_i$ . I haven't been able to see why this is true. The previous theorem was the fundamental theorem of symmetric polynomials, which was proven inductively with a recursive algorithm: If $x_n\mid f$ then $x_1\cdots x_n\mid f$ , and dividing out we are left with a symmetric polynomial of smaller degree than before. Otherwise, write $f(x_1,\dots,x_{n-1},0)$ as a polynomial $p$ in the elementary symmetric polynomials $\hat{e}_i$ of the first $n-1$ variables, $p(\hat{e}_1,\dots,\hat{e}_{n-1})$ . Now the polynomial $$f(x_1,\dots,x_n)-p(e_1,\dots,e_{n-1})$$ is symmetric in all of $x_1,\dots,x_n$ and evaluates to $0$ at $x_n=0$ , i.e., is divisible by $x_n$ . Induct. Is there a straightforward adaptation of this with which we can argue for theorem 2? Or is there perhaps another way to see that it must be true? I feel I am missing something simple here.","['invariant-theory', 'symmetric-polynomials', 'abstract-algebra', 'polynomials']"
132420,Why is $\ln N - \ln(N-1) = \frac1N$ for large $N$?,May I ask why is $\ln N - \ln(N-1) = \frac1N$ for large $N$? Thank you very much.,['algebra-precalculus']
132423,Is there an unbiased random walk on a colored plane for any number of colors?,"So I was trying to motivate the fundamental postulate of statistical mechanics (i.e. all microstates are assumed to be equally probable $-$ even if we can't practically measure them, but only their macroscopic properties) using simple examples. I came up with the simple analog of a dice, where the six sides $1-6$ are the random microstates and a yes/no-answer machine can only compute some rough ""macroscopic"" property of the result. When I tried to incorporate a metaphor for the dynamics, which changes one microstate to another, a mathematical problem emerged: The idea is to create a two-dimensional plane, (source: gstatic.com ) $\ \ \ $ (example of a random plane) with $n$ (e.g. six) differently colored fields and the following property: If you stand on one field of some color and you take a random step to a neightboring field you can end up on any of the other colors. So the problem is to find a colored plane, finite or not, such that every other color can be reached from every colored field. The number of colors $n$ is fixed, but the number of fields on the plane is $n$ or more (i.e. repitition of equally colored fields is allowed). Up to four colors, I figured that a solution would just be projections of a tetrahedron. For these solution you need only exactly $n$ fields and if you want them to they are even finite or ""compact"" as board: But from there on it gets tricky. For which $n$ is it possible to solve the problem described above and why ? If there are some ways around it, how can the constructions be formalized? Sadly, I guess there are some topological restrictions above $n=4$ . This leads to a more difficult secondary follow up question. Let's say I come up with a plane, which doesn't fulfill the criteria of equal propability for each color, like for example in where there are some red fields, which don't connect to blue ones. Then if I start somewhere and take $100$ random steps, I will collect fewer blue than yellow steps. Is there a canonical way to classify the dependency of the descriptive statistics of the random walk on the structure and coloring of the plane? This gets difficult very fast, but I can imagine inductive investigations on geometries with high symmetry. I also have a little second question for the dice metaphor, which has no definitive answer and is too trivial for a seperate post: To define a ""macroscopic property"" of a dice roll, what are some good/interesting ways to distinguish two out of the six numbers $\{1,2,3,4,5,6\}$ ? The best thing I could come up with is ""these numbers are divisible by 3"", but that's kind of lame.","['random-walk', 'general-topology', 'statistics', 'graph-theory', 'coloring']"
132451,Sequence which converges in probability but neither almost surely nor in $L^p$,"Is it possible to find a sequence of r.v.'s $\{X_n\}$ that converge in probability but not almost surely nor in $L^p$? Does anyone know of a single example that illustrates this point? I've been trying to think of one for ages and I've not come up with anything. I'm sure such a sequence must exist, but can't think what it could be.","['probability-theory', 'convergence-divergence', 'probability']"
132462,Understanding a proof of corollary of Farkas lemma,"I'm trying to understand a proof of a corollary to the Farkas lemma in some lecture notes. For completeness sake I'll first state the Farkas lemma and then the corollary + proof, as stated in these lecture notes. (Farkas lemma) Given $A \in \mathbb{R}^{m\times n}$, $b \in \mathbb{R}^m$. Then $Ax = b$ has a nonnegative solution if and only if there is no vector $y$ satisfying $y^{T}A \geq 0$ and $y^{T}b < 0$. (Corollary) The system $Ax \leq b$ has a solution if and only if there is no vector $y$ satisfying $y \geq 0$, $y^T A = 0$ and $y^T b < 0$. (Proof of corollary) Let $A'$ be the matrix $A' :=[A\quad -A\quad  I]$, where $I$ is the identity matrix. Then $Ax \leq b$ has a solution $x$ iff the system $A'x' = b$ has a nonnegative solution $x'$. Applying the Farkas lemma to the latter system gives the corollary. Here, I parse $[A\quad -A\quad  I]$ as being the matrix created by appending $A$, $-A$ and $I$. What I don't understand is how I should calculate $A'x'$ and of what dimension $x'$ should be. It seems to me that $A'$ has dimensions $m \times 3n$ so that $x'$ has dimensions $3n \times 1$, but this isn't right since $b$ is of dimension $m \times 1$. I'm guessing I'm missing something really obvious but alas I can't see it.",['linear-algebra']
132472,Hausdorff measure for Lebesgue measurable sets?,"As I never had a course which dealt with Hausdorff measures and every time I heard about Hausdorff measure I was only thinking using my intuition what that should be. So I decided to take a look at the definition, and try some typical examples. I am reading a chapter on Hausdorff measure of Real Analysis by Stein and Shakarchi. I saw that they define the Hausdorff measure only for Borel measurable sets. My questions are: Can we define Hausdorff measure for Lebesgue measurable sets or not? If a set $E \subset \Bbb{R}^n$ has Lebesgue measure zero, then it's Hausdorff dimension is strictly smaller than $n$? I am concerned about this since I sort of rushed out and 'proved' the following thing using Hausdorff measures: If $E \subset \Bbb{R}^n$ has Lebesgue measure zero and $f :\Bbb{R}^n \to \Bbb{R}^n$ is Lipschitz continuous then  $f(E)$ also has Lebesgue measure zero. and I don't think my proof is right.","['dimension-theory-analysis', 'measure-theory']"
132495,"Why don't you need the Axiom of Choice when constructing the ""inverse"" of an injection?","Suppose $f:X\rightarrow Y$ is a surjection and you want to show that there exists $g:Y\rightarrow X$ s.t. $f\circ g=\mathrm{id}_Y$. You need the AC to show this. However, suppose $f$ is a injection and you want show there is $g$ s.t. $g\circ f=\mathrm{id}_X$. Then, according to my textbook, you don't need the AC to show this. This is counterintuitive to me, because it's like you need a special axiom to claim that an infinite product of big sets is nonempty, while you don't need one to claim that an infinite product of singleton sets is nonempty, which seems smaller than the former. So why don't you need the AC to show the latter? EDIT: $X$ should be nonempty. EDIT 2: I realized (after asking this) that my question mostly concerns whether the AC is needed to say that an infinite product of finite sets is nonempty, and why.","['elementary-set-theory', 'axiom-of-choice']"
132519,A combinatorial inequality [duplicate],"This question already has answers here : Inequality ${n \choose k} \leq \left(\frac{en}{ k}\right)^k$ (3 answers) Closed 4 years ago . How can I prove
$$
\log \binom nk \leq k \left(1 +\log\frac{n}{k}\right)
$$ where $\binom\cdot\cdot$ stands for combination. I tried to use stirling approximation but I couldn't get the inequality.","['inequality', 'binomial-coefficients', 'combinatorics']"
132520,Complement of $c_{0}$ in $\ell^{\infty}$,"How can I show that $c_{0}$ cannot be complemented in $\ell^{\infty}$?
Complement in the following sense $$c_{0}+V = \ell^{\infty}$$ And the projections are continuous.","['functional-analysis', 'banach-spaces']"
132533,Can we think of a chain homotopy as a homotopy?,"I'm taking a course in algebraic topology, which includes an introduction to (simplicial) homology, and I'm looking for a bit of intuition regarding chain homotopies. The definitions I'm using are: Let $f,g : X \to Y$ be continuous functions between topological spaces. A homotopy from $f$ to $g$ is a continuous map $H : X \times [0,1] \to Y$ such that $H(\, \cdot\, , 0) = f$ and $H(\, \cdot\, , 1) = g$ . Let $f_{\bullet}, g_{\bullet} : A_{\bullet} \to B_{\bullet}$ be chain maps between chain complexes $(A, d_A)$ and $(B,d_B)$ . A chain homotopy from $f$ to $g$ is a sequence of maps $h_n : A_n \to B_{n+1}$ such that $f_n-g_n=d_Bh_n+h_{n-1}d_A$ . I'm aware of the properties of a chain homotopy and how they are similar to those of a homotopy, but I still find the definition quite opaque and the notion quite hard to picture $-$ it would help me a lot if I could think of a chain homotopy in a similar way to how I think of a homotopy. Or, to make my question a bit less vague, I'd like to know: What is the rationale behind the definition of a chain homotopy? Is there a fundamental similarity between a chain homotopy and a homotopy, beyond their further consequences? (General waffle would also be appreciated; I'd really like to develop a good understanding.)","['homological-algebra', 'intuition', 'algebraic-topology', 'abstract-algebra']"
132552,Showing a matrix is not diagonalizable,"For eigenvalue 1, the eigenspace I got was $span[ 1,0,0]$, and for eigenvalue 4, the eigenspace I got was $span[ 1,-3,9]$. Do they look right? The reason the matrix is not diagonalizable is because we only have 2 linearly independent eigevectors so we can't span R3 with them, hence we can't create a matrix E with the eigenvectors as its basis. Is that correct, did I word it right?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
132572,How do I solve $(x-1)(x-2)(x-3)(x-4)=3$,How to solve $$(x-1) \cdot (x-2) \cdot (x-3) \cdot (x-4) = 3$$ Any hints?,"['algebra-precalculus', 'polynomials']"
132650,Verifying Stokes Theorem,"The first part of the question states prove, $$\oint_{c} r \wedge dr= 2 \iint_{s} ds$$ This I have done using stokes theorem, however stuck on the next part which states, verify this forumla is also applicable when s has a mild singularity, by evaluating both sides of the equation for the case when s is the cone, ${(x,y,z): (1-z)^{2}=x^{2}+y^{2}, x^{2}+y^{2} \leq 1, z\geq0}$ and c is the circle $x^{2}+y^{2}=1$ in the xy plane. Many thanks in advance.","['multivariable-calculus', 'calculus']"
132664,Inscribed angle is always the same and twice the central angle -- is this absolute?,We all know that in Euclidean geometry a) the inscribed angle is always the same b) it's half of the central angle. Can we prove either of these without presuming the parallel postulate?,['geometry']
132689,"Elementary proof that if $A$ is a matrix map from $\mathbb{Z}^m$ to $\mathbb Z^n$, then the map is surjective iff the gcd of maximal minors is $1$","I am trying to find an elementary proof that if $\phi$ is a linear map from $\mathbb{Z}^n\rightarrow \mathbb{Z}^m$ represented by an $m \times n$ matrix $A$, then the map is surjective iff the gcd of the determinants of all the $m\times m$ minors of $A$ is $1$. I know that for there to be surjectivity between $\mathbb{Z}^n$ and $\mathbb{Z}^m$ $n$ must be greater than or equal to $ m$ and for there to even be $m \times m$ minors $n$ again must be greater than or equal to $ m$, so I just assume this throughout. I sort of have one direction $\Leftarrow$ i) Greatest Common Divisor =1 implies surjectivity: First observe that the if $ | \mathbb{Z}^m/ Im(M)| < \infty$ then $|\det M| = | \mathbb{Z}^m/ Im(M) |$ otherwise $\det(M) = 0$ where $M$ is an $m\times m$ matrix. We can consider the $n$ columns of $A$ as column vectors $v_1, v_2, \ldots, v_n$. These $n$ column vectors live in $\mathbb{Z}^m$. Let $S'' = \{ v_i\}$ and then let $S'$ be subsets of $S''$ of cardinality $m$ and lastly let $S$ be the elements of $S'$ such that when the $m$ $v_i$ vectors are considered as $m\times m$ matrices, the determinant is not zero, thus $S$ consists of all $m\times m$ minors of $A$ with non-zero determinant (we ignore zeroes since they do not affect gcd). For each $s\in S$ define a map $i_s: \mathbb{Z}^m \rightarrow \mathbb{Z}^n$ that maps the standard basis of 
$\mathbb{Z}^m$ to the basis elements $e_k \mathbb{Z}^n$ such that $v_k \in s$. That is, $\phi \circ i_s$ gives the matrix created by the column vectors of 
$s$. Let $\Lambda$ be the lattice Im$\phi \supset \sum_{s\in S}$ Im
$\phi\circ i_s =\sum_{s \in S} \Lambda_s$. Thus $\forall s \in S$, 
$\Lambda_s \subset \Lambda \subset \mathbb{Z}^m$. Thinking in terms of group theory, we have that $\Lambda$ is a subgroup of $\mathbb{Z}^m$ and all the 
$\Lambda_s$ are subgroups of $\Lambda$. Thus by Lagrange's Theorem, we have 
$|\mathbb{Z}/\Lambda| \Big\vert |\mathbb{Z}^m/\Lambda_s|$ Since $|\mathbb{Z}^m/\Lambda_s|$ are the determininants of the $m\times m$ minors and the definition of the common divisor of several integers is the greatest positive integer dividing all of them. Thus by hypothesis $|\mathbb{Z}/\Lambda| \leq 1$ and so $|\mathbb{Z}/\Lambda| =1$ and we have that Im$A=\Lambda = \mathbb{Z}^m$ so the map is surjective. I was hoping to get a more elementary proof that doesn't rely on the observation that the if $ | \mathbb{Z}^m/ Im(M)| < \infty$ then $|\det M| = | \mathbb{Z}^m/ Im(M) |$ otherwise $\det(M) = 0$ where $M$ is an $m\times m$ matrix or normal forms. Thanks!","['modules', 'integer-lattices', 'abstract-algebra', 'determinant']"
132690,Any orientation preserving self-homeomorphism of $S^2$ is isotopic to identity,"I want to show that any orientation preserving self-homeomorphism of a 2-sphere $S^2$ is isotopic to identity. Any help or reference is appreciated. Edit; I want to show this to prove the following.
Suppose we have two solid torus and we have a homeomorphism of the boundaries. The manifold obtained by indentifying boundaries via the homeomorphism depends only on the image of the meridian. To show this, first cut out the cylinder neighborhood of a meridian and glue it to the other solid torus. The reminder is homeomorphic to $B^3$. So if I can prove the question above, I can finish this proof.","['general-topology', 'algebraic-topology']"
132703,What does $2^x$ really mean when $x$ is not an integer?,"We all know that $2^5$ means $2\times 2\times 2\times 2\times 2 = 32$, but what does $2^\pi$ mean? How is it possible to calculate that without using a calculator? I am really curious about this, so please let me know what you think.","['exponentiation', 'algebra-precalculus', 'real-analysis']"
132722,Bertrand's box paradox,"I have $3$ coins, $1$ coin has $2$ heads (HH), 1 coin has $2$ tails (TT), $1$ coin has $1$ head and $1$ tail (HT). I toss the coin, it fells on my hand, and the side i see is a tail. What's the chance that the other side is also a tail? I got this as a teaser from a friend, possible from here , as you can see he is insisting on $\frac12$ as not being the correct answer, I got $\frac13$ as my answer, am I right?","['faq', 'probability', 'paradoxes', 'conditional-probability']"
132751,Riemann-Roch for vector bundles,"The Riemann-Roch theorem is one of the most essential theorems on Riemann Surfaces, or so I am told. I have encountered two formulations for vector bundles (and clearly there are many more), and I am trying to understand why it is that they are equivalent. I would greately appreciate some explanation of this issue. In either case, we are given a compact Riemann surface $\Sigma$, and and a holomorphic line bundle $E$ over $\Sigma$. The genus of $\Sigma$ is $g$, and degree of $E$ is $d$. We consider the space of holomorphic functions by $H^0(E)$, and take $h^0(E) = \dim H^0(E)$.
Now, the first formulation says that:
$$
h^0(E) - h^0(E^{-1} \otimes K) = d + 1 - g
$$
where $K$ is the canonical bundle, and (I think) in this context the symbol $E^{-1}$ can be taken to mean just $E^*$ (the dual bundle) for reasons having to do with divisors.
Now, for the second formulation, we take $H^1(E)$ to be the quotient space of (the closed $1$-forms with coefficients in $E$) divided by (the exact $1$-forms with coefficients in $E$). We define $h^1(E) = \dim H^1(E)$ and the second version of the theorem says:
$$
h^0(E) - h^1(E) = d + 1 - g
$$ Now, it is far from clear for me why it is that these two formulations are equivalent. Unless I'm getting something seriously wrong here (rather plausible), it should hold that $ h^0(E^{-1} \otimes K) = h^1(E) $, but I would very much appreciate an explanation why it should be so. I would be also grateful for ideas, references and examples concerning computation of the quantities occurring in the Riemann-Roch formula (i.e. starting from a given Riemann surface and ending with (all but one of) $h^0(E), h^1(E), d, g$) [Note: this last question is realted to a homework I have]. Also, remarks on any blunders that I have written above are more than welcome (the only way to get rid of one's misconceptions, I guess).","['riemann-surfaces', 'algebraic-geometry', 'differential-geometry']"
132757,Showing a function satisfies a particular differential equation,"How do I show that the function $$ y(x) = \int_0^\infty \cos(t^3/3 + xt)~dt\qquad -\infty \lt x \lt \infty,$$ satisfies the differential equation $y''=xy$? I can't simply differentiate under integral since the integrand is oscillatory and does not decay as $t$ becomes large.","['ordinary-differential-equations', 'complex-analysis']"
132772,Equivalence of two characterizations of the norm of a quadratic integer.,"Let $a+bi=\alpha\in\mathbb{Z}[i]$ be a Gaussian integer. why is it that $N(\alpha)=a^2+b^2$ is equal to the cardinality of $\mathbb{Z}[i]/(\alpha)?$ My question can be generalized to quadratic integers in general, and I'm not sure to what extent it goes further. An answer addressing any of these points, or leading me to a good source, would be valuable.","['gaussian-integers', 'abstract-algebra', 'number-theory']"
132775,A sub-additivity inequality,"In trying to understand a result of D. Rider (Trans. AMS, 1973) I've got stuck on a lemma that he uses. At one point he makes a step without comment or explanation, but I can't see why it works. Here is a paraphrase of what I think he is claiming. Let $d_1,\dots, d_n$ be complex numbers of modulus $1$; let $b_1,\dots, b_n$ be complex numbers of modulus $\leq 1$. (In the intended application the numbers $b_1,\dots, b_n$ are actually the diagonal entries of a unitary $n\times n$ matrix, but I strongly suspect that is not used in the argument.)
Then Rider seems to assert, without further comment, that
$$ \left\vert\sum_{j=1}^n (d_jb_j-1)\right\vert^{1/2}
\leq \left\vert\sum_{j=1}^n (d_j-1)\right\vert^{1/2} +  \left\vert\sum_{j=1}^n (b_j-1)\right\vert^{1/2}
$$ Probably I am just being dense, and have failed to spot a routine estimate that does the job. If anyone could get me started on the right track that would be most helpful, as this is starting to get very irritating, and is not even the main part of Rider's argument. Update Firstly, thanks to everyone who answered, but in particular to Will Jagy for various off-MSE exchanges, and to George Lowther for his elegant argument (the key part that I had failed to think of, was the use of $\rm Re$ and its linearity rather than $\vert\cdot\vert$ and its sub-additivity, allowing one to boost up the observation made by Gerry Myerson). In case it's of interest, here are some more details on how the question I asked corresponds to Lemma 5.1 in Rider's paper. The paper is dealing with central trigonometric polynomials on compact groups, which means: linear combinations of traces of irreducible representations. Paraphrased lightly, and with a fairly trivial reduction step thrown in, the aforementioned lemma says the following: Let $\phi: G \to U(n)$ be an (irreducible) unitary representation of a (compact) group $G$. If $$\vert n^{-1}\operatorname{\rm Tr}\phi(g_i)-z_i\vert \leq \delta_i \qquad(i=1,\dots, p)$$
  where $\vert z_i\vert=1$ for all $i$, then
  $$ \left\vert n^{-1}\operatorname{Tr}\phi(g_1\dotsb g_n) - \prod_{i=1}^p z_i \right\vert \leq \left(\sum_{i=1}^p \delta_i^{1/2}\right)^2 $$ The proof given in the paper goes as follows: reduce to the case $p=2$ (if this can be done then induction will do the rest); then observe that WLOG $\phi(g_1)$ is a diagonal unitary matrix, w.r.t. an appropriate basis. If we let $d_1,\dots, d_n$ be the diagonal entries of $\phi(g_1)$ and $b_1,\dots, b_n$ be those of $\phi(g_2)$, then the trace of $\phi(g_1g_2)$ is just $\sum_{i=1}^n d_ib_i$, and so we have to prove Claim. If $|z_1|=|z_2|=1$, $\left\vert\sum_{i=1}^n (d_i - z_1)\right\vert\leq n\delta_1$, and
   $\left\vert\sum_{i=1}^n (b_i - z_2)\right\vert\leq n\delta_2$, then
  $$\left\vert \sum_{i=1}^n (d_ib_i - z_1z_2) \right\vert \leq n(\delta_1^{1/2}+\delta_2^{1/2})^2. $$ This is where Rider is content to say ""done""; and it is hopefully clear that this is equivalent to my original question.","['inequality', 'real-analysis']"
132787,give a counterexample of monoid,"If $G$ is a monoid, $e$ is its identity, if $ab=e$ and $ac=e$, can you give me a counterexample such that $b\neq c$? If not, please prove $b=c$. Thanks a lot.","['examples-counterexamples', 'abstract-algebra', 'monoid', 'semigroups', 'group-theory']"
132807,"If a group is $3$-abelian and $5$-abelian, then it is abelian","In a group $G$ , $(ab)^{5}=a^{5}b^{5},\forall a,b\in G$ and $(ab)^{3}=a^{3}b^{3}$ then prove that $G$ is abelian. I know that for three consecutive integer if $(ab)^{i}=a^{i}b^{i},\forall a,b\in G$ holds then $G$ is abelian. I know I have to use this property and I have to use three consecutive integer $3,4$ and $5$ . But I am stuck.","['group-theory', 'abstract-algebra', 'abelian-groups']"
132809,Inserting if else in a mathematical expression is it possible,"Hope you guys can help me out. I have a mathematical expression which I constructed its:
$$
A_S = \frac{A_{U_{Max}} - A_{U_{Min}}}{U\sqrt{2}}
$$ Is there a way in which I could mathematically specify along with this equation that if
$A_{U_{Max}}=A_{U_{Min}}=$NULL then $A_S = U$? This would then mean that the variable $A_S$ could basically have two values it could either be equal to $U$ on the condition that $A_{U_{Max}}$=NULL and $A_{U_{Min}}$=NULL or it could be something else depending on the values of $A_{U_{Max}}$ and $A_{U_{Min}}$. Any suggestions would be appreciated.","['notation', 'functions']"
132842,Applying difference of cubes to cube roots,"I am stumped as to why this application of the difference of cubes is valid... 
I am rationalizing the denominator.  I don't understand the reasoning of why the difference of cubes formula is applicable to cubed roots, removing the root one gets an exponent of $a^{1/3}$ - I know how to simplify this expression, but I am hoping someone can help me along with the logic. $$\frac{1}{\sqrt[3]{a}-\sqrt[3]{b}}.$$",['algebra-precalculus']
132847,Counting strings that contain only trivial repeats.,"Let $A$ be a finite alphabet with $|A| = n$.   Is there an elementary formula for counting the number of strings over $A$ that don't contain any repeated substrings of length greater than $1$?  More formally, let $t$ be a substring of a string $s$ over $A$ with $|t| > 1$.    $t$ is said to repeat in $s$ if there is at least two disjoint copies of $t$ in $s$.  For example $s=abaaab$ is not counted since $ab$ is a repeat, however $s=abaaa$ contains no repeats since $aa$ has no two disjoint copies. I've tried your basic discrete math, balls-in-bins, type solutions, but each time end up over counting.  I know that for fixed $n$, there is a finite number of such strings, and a bound on their length.",['combinatorics']
132853,Capelli Lemma for polynomials,"I have seen this lemma given without proof in some articles (see example here ), and I guess it is well known, but I couldn't find an online reference for a proof. It states like this: Let $K$ be a field and $f,g \in K[x]$. Let $\alpha$ be a root of $f$ in the algebraic closure of $K$. Then $f \circ g$ is irreducible over $K$ if and only if $f$ is irreducible over $K$ and $g-\alpha$ is irreducible over $K(\alpha)$. Can you please give a proof for this?","['field-theory', 'abstract-algebra', 'polynomials']"
132854,"Why is better to work with the spectrum of prime ideals than with the maximal one, for example in the definition of affine scheme.","When we have an algebraic variety we can identify the points of the variety with maximal ideals of the coordinate ring. I would like to know why it is more natural to define the main structure of the theory of schemes, the affine scheme, with prime ideals and not with maximal ones. When Grothendieck was creating theory of schemes, why did he decide to work with the normal spectrum instead of the maximal one? (As you can see I dont have an strong background of Algebraic Geometry, I just want to have some intuition) In which sense the schemes generalize the notion of variety and why is better to work with this notion?","['algebraic-geometry', 'intuition']"
132857,Is there a fundamental domain for $\Gamma(2)$ contained in the following strip,"Let $\Gamma(2)$ be the subgroup of $\mathrm{SL}_2(\mathbf{Z})$ satisfying the usual congruence conditions. It acts on the complex upper half-plane. Does it have a fundamental domain contained in the strip $$\{x+iy: -1\leq x \leq 1\}?$$ Is the following a correct argument? The matrix $$\left( \begin{matrix} 1 & \pm 2 \\ 0 & 1 \end{matrix}\right)$$ is in $\Gamma(2)$. If $\tau$ is not in the above strip, we can translate $\tau$ into this strip by multiplying with the above matrix a couple of times.","['algebraic-geometry', 'algebraic-curves', 'arithmetic-geometry', 'riemann-surfaces', 'modular-forms']"
132870,Taking derivative below an integral,"I am trying to solve the following question : If $t>0$, then
\begin{align*}
    \int_{0}^{+\infty} e^{-tx} \; dx = \frac{1}{t}
\end{align*}
Moreover, if $t \geq a > 0$, then $e^{-tx} \leq e^{ax}$. Use this and Exercise 4.M. to justify differentiating under the integral sign and to obtain the formula
\begin{align*}
    \int_{0}^{+\infty} x^n e^{-x} \; dx = n!
\end{align*} $\bf{Note:}$ Exercise 4.M. states that if $X = [0, \infty)$ and $\lambda$ is the Lebesgue measure and $f$ is a non-negative function on X, then $$\int f \; d\lambda = \lim_{b\to \infty} \int_0^b f \; d\lambda$$ I would like to use a Corollary of the Dominated Convergence Theorem, 
$$\frac{d}{dt}\int f(x,t) \; d\mu(x) = \int \frac{\partial f}{\partial t}(x,t) \; d\mu(x)$$ However, for in order to use this I need to find an integrable function $g$ such that 
$$\left|\frac{\partial f}{\partial t}(x,t)\right| \leq g(x) $$ I guess I am having difficulty finding this $g(x)$. If I start with $f(x,t) = e^{-tx}$ then,
$$\left|\frac{\partial f}{\partial t}(x,t)\right| \leq xe^{-tx} \leq xe^{ax}$$ How would I show that this last term is in $L_1$? Moreover, I assume that I would have to iterate this process several times so what I am trying to bound should actually be $x^n e^{-tx}$. If so, how should I go about constructing my $g$? Also if anyone could redirect me to problems of this similar structure I would appreciate it, as I find them rather interesting. I am currently using Bartle's ""The Elements of Integration and Lebesgue Measure"".","['derivatives', 'measure-theory', 'integration', 'real-analysis']"
132874,Computation of a Particular Convolution,"Let $\xi_{1}, \xi_{2}, \xi_{3}$ be i.i.d. $N(0,1)$. I'm attempting to compute the density of $\max \{\xi_{1}, \xi_{2}\} + \xi_{3}$. I know the density of $\max \{\xi_{1}, \xi_{2}\} $ is $2\Phi(y) \phi(y)$ and the density of $\xi_{3}$ is $\phi(s)$ so that the density of interest is the convolution $\int_{\mathbb{R}} 2\Phi(y) \phi(y) \phi(z-y)dy$. Is there any way to get at this expression, say, express it in terms of $\Phi$?","['probability-theory', 'convolution']"
132881,how best to draw two planes intersecting at an angle which isn't $\pi /2$?,"What's the best way to draw two planes intersecting at an angle that isn't $\pi /2$? If I make them both vertical and vary the angle between them, the diagram always looks as though our viewpoint has changed but the planes are still intersecting at $\pi /2$. I can't quite work out how to draw one or both of them non-vertical in such a way as to make the angle between them appear to be obviously not a right angle. Thanks for any help with this!","['geometry', 'euclidean-geometry']"
132892,Counting process which is not a Poisson process,"Please construct a counting process N, whose r.v. N(t) are distributed as Poisson(λt) but the process N itself is not a Poisson process. This is an assignment in our Stochastic Process class. So I suppose this counting process N should meet all but one of a Poisson's process conditions. 1) N(0)=0 2) independent increments 3) At any given time t N(t) ~ Poiss( λt). So making the increments dependent should probably be the way to go. However, I've no idea how that could be done.","['stochastic-processes', 'probability', 'combinatorics']"
132897,Geometric intuition behind the Lie bracket of vector fields,"I understand the definition of the Lie bracket and I know how to compute it in local coordinates. But is there a way to ""guess"" what is the Lie bracket of two vector fields ? What is the geometric intuition ? For instance, if we take $U = x \frac{\partial}{\partial x} + y \frac{\partial}{\partial y}$ and $V = -y \frac{\partial}{\partial x} + x \frac{\partial}{\partial y}$, should it be obvious that $[U, V] = 0$ ?","['lie-algebras', 'vector-fields', 'differential-geometry', 'lie-groups', 'lie-derivative']"
132920,What is the best state-of-the-art numerical integral algorithm?,"I'm trying to implement a numerical integrator that should have the minimum relative error and is not slow. So I was looking for the best accepted state-of-the-art algorithm to do so but there seems to be so many approaches that I could not understand which one should I choose. So I'm turning to you for a recommendation. Thank you for your attention,","['definite-integrals', 'integration', 'algorithms', 'numerical-methods']"
132926,Evaluating $\sqrt{6+\sqrt{6+\cdots}}$,"Tough as introduction to analysis for beginners (Dutch handbook - I'm Belgian). Again
($n$) means index $n$, $x_1 = \sqrt6$, $x_{n+1} = \sqrt{6+x_n}$ Question: $$|x_{n+1} - 3| \le 1/5 \cdot |x_n - 3|$$ For me this means that $3$ as a 'limit', we need to find that the distance between $x_{n+1}$ and the 'limit' is $1/5$ the distance between the $x_n$ and the limit.
Where does the $1/5$ come from? Prove that $|x_n - 3|\le (1/5)^{n-1}$ prove that the sequence converges to $3$. ps: 
When I studied maths in 1980. we went quickly towards metric spaces, so these calculus minded times are nothing compared to those times. But still, as I didn't pass then, I'd like to restart on a new basis.
Thanks for all the help. 
If you know where maths can be studied in community on the net, always welcome.","['nested-radicals', 'sequences-and-series', 'limits']"
132953,An Expression for the Wedge Product,"For the question below, I have the following definitions and concepts in mind:
The $k^{th}$ exterior power of a real vector space $V$, denoted $\Lambda^k(V)$ can be realized as the quotient
of the tensor product $\bigotimes^k V$ with the subspace of $\bigotimes^k V$ generated by all elements of the form
$v_1 \otimes \dots \otimes v_k$ where $v_i = v_j$ for some $i \neq j$. The equivalence class of $(v_1, \dots, v_k)$
in $\Lambda^k(V)$ is denoted by $v_1 \wedge \cdots \wedge v_k$; it can be thought of as the image of $(v_1, \dots, v_k)$
under the canonical alternating multilinear map that sends each element in $V^k$ to its equivalence class in $\Lambda^k(V)$.
By the universal property of the exterior product, I understand that every alternating multilinear form defined on $V^k$
can identified with a unique linear form with domain $\Lambda^k(V)$. Finally, I know that the determinant of an endomorphism $T:V\rightarrow V$ can be defined as the unique real number $\det T$ such that 
$$ 
Tv_1 \wedge \cdots \wedge Tv_n = (\det T)v_1 \wedge \cdots \wedge v_n
$$ My Question : It is a fact that if $\phi^i, \dots, \phi^k$ are linear forms on $V$ then
$$
\phi^1 \wedge \cdots \wedge \phi^k(v_1, \dots, v_k) = \det[\phi^i(v_j)]
$$
Can this be proved using the facts outlined above without resorting to the combinatorial definition of the determinant/wedge product?","['linear-algebra', 'multilinear-algebra']"
132967,History of $f \circ g$,"$f \circ g$ is usually interpreted as $f(g(x))$ although, as Google shows, $g(f(x))$ is used frequently too. My question: Does anybody know who was the first mathematician to use this symbol and what was his interpretation?","['notation', 'math-history', 'functions']"
133030,Finding a point above the line in $O(\log n)$,"I am trying to solve the following problem. So far with no success. Let $S$ be a set of $n$ points in the plane. Preprocess $S$ so that, given a (non-vertical) line $l$, one can determine whether there is any point of $S$ above $l$ in time $O(\log n)$. Few details: preprocess $S$ without knowing line $l$ in advance. Preprocessing doesn't have any special requirements. According to big-$O$ requirement $O(\log n)$ the determination should be implemented similarly to binary search. I have considered few options, $y$ - coordinate, slopes, but in any case it seems not relevant. If you have any idea, I will appreciate sharing it with us. Thanks!","['geometry', 'computer-science', 'computational-geometry', 'algorithms']"
133041,How can I solve $x^x = 5$ for $x$? [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Is $x^x=y$ solvable for $x$? I've been playing with this equation for a while now and can't figure out how to isolate $x$. I've gotten to $x \ln x = \ln 5$, which seems like it would be easier to work with, but I can't figure out where to go from there. Is it possible to solve this algebraically? If not, how can I find the value of $x$?","['exponentiation', 'logarithms', 'algebra-precalculus']"
133069,what is value of $\lim_{n\to\infty} n^{-2}e^{(\log(n))^a}$?,"What is value of $\displaystyle\lim_{n\to+\infty} n^{-2}e^{(\log(n))^a}$, where $a > 1$? I tried l'Hospital's rule but it gets complicated.","['real-analysis', 'limits']"
133076,Computing the Smith Normal Form,"Let $A_R$ be the finitely generated abelian group, determined by the relation-matrix $$R := \begin{bmatrix}
-6 &  111  & -36 & 6\\
5  &  -672 & 210 & 74\\
0 & -255 & 81 & 24\\
-7  &   255       &-81 & -10
\end{bmatrix}$$ Reduce this matrix using Smith Normal Form and determine the isomorphism type of $A_R$. I know that the Smith Normal Form of this matrix is: $$\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 3 & 0 & 0 \\
0 & 0 & 21 & 0 \\
0 & 0 & 0 & 0 
\end{bmatrix}
$$ However, this was computed using Maple and I need to understand the method of computing this manually which I am struggling to grasp. Can anyone help?","['matrix-decomposition', 'smith-normal-form', 'abelian-groups', 'matrices', 'finite-groups']"
133079,Splitting field of $x^6+x^3+1$ over $\mathbb{Q}$,"I am trying to find the splitting field of $x^6+x^3+1$ over $\mathbb{Q}$. Finding the roots of the polynomial is easy (substituting $x^3=t$ , finding the two roots of the polynomial in $t$ and then taking a 3-rd root from each one). The roots can be seen here [if there is a more elegant way of finding the roots it will be nice to hear] Is is true the that the splitting field is $\mathbb{Q}((-1)^\frac{1}{9})$ ?
I think so from the way the roots look, but I am unsure. Also, I am having trouble finding the minimal polynomial of $(-1)^\frac{1}{9}$, it seems that it would be a polynomial of degree 9, but of course the degree can't be more than 6...can someone please help with this ?","['abstract-algebra', 'field-theory']"
133083,Euler line of triangle $ABC$ is parallel to side $BC$ $\implies$ $\tan B \tan C = 3$,"I'm having some trouble on this exercise from Geometry Revisited : On triangle $ABC$, the Euler line is parallel to $BC$. Prove that $\tan B \tan C = 3$. Here is the solution given: (in this context, $D$ is the base of the altitude from $A$, $O$ is the circumcenter, $A'$ is the midpoint of $BC$, and $R$ is the radius of the circumcircle) I understand everything up to the last line. However, I do not understand how the line $OA'$ is related to the circumradius. Why is $OA'= R \cos A$?",['geometry']
133098,Proving an entire  function which misses a ball is constant,Let $f$ be an entire function s.t $f(\mathbb{C}) \cap B_R(z_0) = \varnothing$ for some $z_0$ and some $R$. Then $f$ is constant. I guess since the image of the whole plane isn't dense then $f$ doesn't have an essential singularity at infinity. Now I have to exclude it has a polar singularity at infinity..,['complex-analysis']
133113,"Dense subset of $[0,1]$ and fat rationals","Talking about an example of an open dense subset of $[0,1]$ with measure $1/2$  I heard talking about 'fat rationals' but I don't find anything on the internt.. Does someone know about this?","['measure-theory', 'real-analysis']"
133121,$\zeta(2)$ via partial fractions,"I was looking at old complex analysis exams, and there is one problem I can't figure out. ""Use the partial fraction expansion of $\frac{z}{e^z-1}$ to show $\sum_1^\infty 1/k^2=\frac{\pi^2}{6}$."" I recognize that as the generating function for the Bernoulli numbers, but I think the point of the problem is to solve it ""from scratch"", without that kind of knowledge. The function has simple poles at $2\pi i k$ for $k\in\mathbb{Z}$, and residue $2\pi i k$  at $2\pi i k$ . Unfortunately, the obvious series, with terms of the form $\frac{2\pi i k}{z-2\pi i k}$, doesn't converge. Adding convergence terms (like in the proof of Mittag-Leffler's theorem) I get a series with terms of the form $\frac{z^2}{z^2-k^2}$, modulo some constants, but I don't see where to go from there, because it vanishes at 0. I think point is that we are supposed to evaluate the partial fraction decomposition at 0, as the function is clearly 1 there. Thanks for the help. As noted in the comments, there is an answer here that looks similar to what is intended: https://math.stackexchange.com/a/8373/1102 , however it seems much too involved for an exam setting, and is deliberately not rigorous. Would it be possible to modify it to be simpler and faster? Edit: I managed to figure out a fairly slick solution that's much better than the accepted answer. I don't have time to write it up right now. If you read this and want to see it, ping me by posting a comment to this question.","['sequences-and-series', 'complex-analysis']"
133122,Why are there $|G/G'|$ 1-dimensional representations of $G$?,"Let $G'$ be the derived subgroup of a finite group $G$. We have a correspondence $\{\mathrm{reps \ of \ G/G'}\} \longleftrightarrow \{\mathrm{reps \ of \ G \ with \ kernel \ containing \ G' }\} $ If we restrict to 1-dimensional reps, we get: $\{\mathrm{1\ dimensional \ reps \ of \ G/G'}\} \longleftrightarrow \{\mathrm{1 \ dimensional \ reps \ of \ G \ with \ kernel \ containing \ G' }\} $ Now my notes say that there are $|G/G'|$ 1-dimensional reps of $G$. Since there are $|G/G'|$ 1-dimensional reps of $G/G'$, this must mean that all 1-dimensional reps of $G$ have kernel containing $G'$. Why is this so? Thanks","['representation-theory', 'group-theory']"
133143,"Complex integral revision, this is just Cauchy's Theorem right?","(a) Give the definition of $e^z$ for a complex number $z = x+iy$ ( 2 marks ) (b) Use the Cauchy-Riemann equations to prove that $f\colon \mathbb C \to \mathbb C$ , $f(z) = e^{2z+i}$ is differentiable at every point of $\mathbb C$ , and that $f'(z) = 2f(z)$ . ( 6 marks ) (c) Explain why the function $f(z) = e^{2z+i}$ , $z \in \mathbb C$ , is analytic at all points of $\mathbb C$ . ( 2 marks ) (d) Determine the value of the integral $$\int_\gamma e^{2z+i}\, dz,$$ where $\gamma$ is the triangle in $\mathbb C$ with vertices in the 3rd roots of $1+i$ , oriented clockwise. ( 5 marks ) In part (d) of this question...As the function $e^{2z+i}$ is analytic everywhere in the complex plane, particularly on and inside the curve $\gamma$ by Cauchy's Theorem $\int e^{2z+i}dz$ = 0. Is that correct...I dont have to bother with any of the triangle related stuff? And for (c), I have proved in (b) that this function is differentiable everywhere in C so I can't see why I am being asked why it is analytic at all point in C. Am I basically just supposed to repeat what I found in (b)? That f(z) is analytic at all points of C as because it is differentiable at all points of C, as it is a composition of analytic functions?",['complex-analysis']
133147,How to find x that defined in the picture?,"$O$ is center of the circle that surrounds the ABC triangle. $|EF| // |BC|$ we only know $a,b,c$ $(a=|BC|, b=|AC|,c=|AB|)$ $x=|EG|=?$ Could you please give me hand to see an easy way to find the x that depends on given a,b,c?",['geometry']
133169,Showing that a function below is in VMO,I am trying to show that the function $\log||\log |x||$ is in VMO . The book that I was reading just mentioned that it was a straightforward verification. Can some help me to figure it out?,"['real-analysis', 'analysis']"
133173,Permutations don't affect summation in complex series implies absolute convergence?,"Let $\sum a_{n}$ be a complex series that converges. Now let $\sum a'_{n}$ be a rearrangement of that series. If we have
$$
\sum a_{n}=\sum a'_{n}
$$
for all rearrangements, is it true that $\sum a_{n}$ converges absolutely? On a similar note, for all of you who own Rudin's Principles of Mathematical Analysis, can you check if there is a Theorem 3.56 in your book? Rudin cites it in Real and Complex Analysis, and I can't tell if it's a typo or was the theorem added in later printings.","['calculus', 'complex-analysis', 'analysis']"
133175,"In the context of the fundamental theorem of algebra, why does $p(z)\overline{p(\bar z)}$ have only real coefficients?","I just read about a Wikipedia page on Fundamental Theorem of Algebra , and it says ""Some proofs of the theorem only prove that any non-constant polynomial with real coefficients has some complex root. This is enough to establish the theorem in the general case because, given a non-constant polynomial $p(z)$ with complex coefficients, the polynomial $$q(z)=p(z)\overline{p(\bar z)}$$ has only real coefficients and, if z is a zero of q(z), then either z or its conjugate is a root of p(z)."" I don't understand why $q(z)$ here has only real coefficients. Suppose $p(z)=\sum_{i=0}^na_iz^{i}\in\mathbb {C}[z].$ Then $\overline{p(\bar z)}=\sum_{j=0}^n\bar {a_j}z^j.$ (Right?) We have $$p(z)\bar{p(\bar z)}=\left(\sum_{i=0}^na_iz^{i}\right)\left(\sum_{j=0}^n\bar {a_j}z^j\right)=\sum_{k=0}^{2n}\left(\sum_{i+j=k}a_i\bar{a_j}\right)z^k.$$ However, it seems not true that $\sum_{i+j=k}a_i\bar{a_j}$ is always a real number, for some $k$ . What's wrong here? Moreover, I was wondering whether $p(z)p(\bar z)$ has only real coefficients. Why do people like choosing $p(z)\overline{p(\bar z)}$ ? Thanks in advance.","['algebra-precalculus', 'complex-analysis', 'polynomials']"
133177,Finding a unit vector perpendicular to another vector,"For example we have the vector $8i + 4j - 6k$, how can we find a unit vector perpendicular to this vector?","['vector-spaces', 'linear-algebra']"
133185,Explaining Horizontal Shifting and Scaling,"I always find myself wanting for a clear explanation (to a college algebra student) for the fact that horizontal transformations of graphs work in the opposite way that one might expect. For example, $f(x+1)$ is a horizontal shift to the left (a shift toward the negative side of the $x$-axis), whereas a cursory glance would cause one to suspect that adding a positive amount should shift in the positive direction. Similarly, $f(2x)$ causes the graph to shrink horizontally, not expand . I generally explain this by saying $x$ is getting a ""head start"". For example, suppose $f(x)$ has a root at $x = 5$. The graph of $f(x+1)$ is getting a unit for free, and so we only need $x = 4$ to get the same output before as before (i.e. a root). Thus, the root that used to be at $x=5$ is now at $x=4$, which is a shift to the left. My explanation seems to help some students and mystify others. I was hoping someone else in the community had an enlightening way to explain these phenomena. Again, I emphasize that the purpose is to strengthen the student's intuition ; a rigorous algebraic approach is not what I'm looking for.","['soft-question', 'education', 'algebra-precalculus', 'functions']"
133217,How do I solve this equation?,$\displaystyle \large \cos 2x + 1 - \sin 2x=\frac{2 \cos 2x \cos x}{\cos x + \sin x}$ I've been trying for a long time but I can't get it.,"['trigonometry', 'algebra-precalculus']"
133218,why does $\frac{1}{z\cdot \sin{z}} $ only have pole when clearly its undefined at $n\pi$,"I am having trouble with a specific problem actually. I have a function $$f(z) = \frac{1}{z\cdot \sin{z}}$$ Now I want to find the residues of this. The Laurent series expanded about $0$ shows that $0$ is a pole of order $2$. The expansion looks something like this $$\frac{1}{z^2}+\frac{1}{6} + \frac{7z^2}{360} +  \cdots $$ so since the first coefficient of $z$ is just zero, the residue of this function is $0$. BUT I want to know why zero is the ONLY pole. Clearly $2\pi$ is a singularity point. Then when you expand about $2\pi$ you get the following expansion $$\frac{1}{2\pi (z - 2\pi)} - \frac{1}{4\pi^2} + \frac{(3+2\pi^2)(z-2\pi)}{24\pi^3} + \cdots $$ Again, it looks to me that the first negative power of $z$ has the coefficient $\frac{1}{2\pi}$. So why is it that when I type in ""poles of function 1/(z*sin(z))"" wolfram only identifies 0 as the pole. If I type in ""poles of function 1/(sin(z))"" then it identifies the poles as $n\pi$. Furthermore if you type in ""residues of 1/(z*sin(z))"" it only identifies 0 as a residue when we just saw above that $\frac{1}{2\pi}$ is also a residue. Whats even more weird is that if you type in ""residues of 1/(z*sin(z)) at 2pi"" it does give the right residue. Weird.",['complex-analysis']
133226,Showing $\sin(\bar{z})$ is not analytic at any point of $\mathbb{C}$,"Use the Cauchy-Riemann equations to show that the function $$g(z) = \sin (\bar z)$$
is not analytic at any point of $\mathbb{C}$. Here's as far as I got - $$\sin \left(\frac{\bar z}{1}.\frac{z}{z}\right)
=\sin \left(\frac{|z|^2}{z}\right)
=\sin \left(\frac{x^2 + y^2}{x+iy}\right)$$ I can't see how to separate the real and imaginary parts so that I can apply the Cauchy-Riemann equations.",['complex-analysis']
133230,Books for Understanding Bayesian probability from the Beginning,"Lets pretend I have no experience with statistics... what books, in what order, will get me to the point of being able to understand  Bayesian probability fastest.","['reference-request', 'probability']"
133233,Is $A_n$ characteristic in $S_n$?,"The title is the question. Is $A_n$ characteristic in $S_n$? If $\phi \in \operatorname{Aut}(S_n)$, Then $[S_n : \phi(A_n)]$ (The index of $\phi(A_n)$) is 2. 
Maybe the only subgroup of $S_n$ of index 2 is $A_n$? Thanks in advance.","['finite-groups', 'group-theory']"
133262,Is there a name referring to this result?,"For any real $m \times n$ matrix $A$, it seems that
$$\det(I_n + A^{T}A) = \det(I_m + AA^{T}) $$
always holds, where $I_n$ is the identity matrix of size $n$. Though I have not tried to prove this yet, I'm sure it is a part of well-known results in linear algebra. So my question is, what is the name referring to this fact, and where can I find a reference to it?","['matrices', 'linear-algebra', 'determinant']"
133268,How to transform the factored form of $\sin(x)$?,"We know $\sin(x)=0$ has solutions $0,\pm\pi,\pm2\pi,\pm3\pi,\dots$. So $\sin(x)$, if interpreted as a polynomial, could be written as: $a_0x^0+a_1x^1+a_2x^2+\cdots$ and we know this polynomial too: $$x-\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\cdots$$ So, the question is, is it possible to transform the factored form of $\sin(x)$: $$\sin(x)=a x(x-\pi)(x+\pi)(x-2\pi)(x+2\pi)(x-3\pi)(x+3\pi)\dots$$ to $$x-\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\cdots\ ?$$","['trigonometry', 'power-series', 'sequences-and-series', 'polynomials']"
133282,How to prove $\Delta DEF$ is an equilateral triangle?,$\Delta ABC$ is an equilateral triangle and $AD = BE = CF$. Prove that $\Delta DEF$ is an equilateral triangle.,"['geometry', 'triangles']"
133290,Complement of a bounded set $B$ in $\mathbb{R}^{n}$ has exactly one unbounded component.,"I'm working on a problem that I think has a very intuitive result, but I'm having a hard time coming up with a rigorous proof. The problem reads If $B$ is a bounded subset of $\mathbb{R}^{n}$ where $n\geq2$, then the complement of $B$ in $\mathbb{R}^{n}$ has exactly one unbounded component. I naively intuit that because $B$ is bounded, the complement is of course unbounded and the complement of $B$ must be connected. I guess I think of this as making a hole in $\mathbb{R}^{n}$ which of course leaves one connected set and therefore exactly one unbounded component.",['general-topology']
133306,Is a meromorphic function always a ratio of two holomorphic functions?,"Suppose $D$ is a region (connected open set) in complex plane, and $f$ is a meromorphic function on $D$. Question : Does there always exist two holomorphic function $g$ and $h$ such that $f=\frac{g}{h}$? When $D$ is the whole complex plane I know it is true thank to Weierstrass infinite multiply formula, and I don't know whether it is true for any region $D$. Any comments are welcome.",['complex-analysis']
133316,Proof of $\lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^n\frac{\sigma(k)}{k}=\zeta(2)$,"Numerically, they seem to be the same, but can we prove that
$$\lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^n\frac{\sigma(k)}{k}=\zeta(2),$$
where $\sigma(k)$ is the sum of divisors of $k$.",['number-theory']
133333,Rank of projective module,We define the rank of free module as the number of elements on the basis of free module. It may be infinity. How do we define the rank of projective module?,"['modules', 'abstract-algebra']"
133350,"help me understand a line in an “$A^TA$ is positive, semi-definite” proof","I am looking at a proof for why $A^TA$ is positive semi-definite when $A$ is $n\times n$ and it has this line.
$$
v^TAA^Tv = A^Tv \cdot A^Tv ≥ 0.
$$
I understand what $v^TAA^Tv$ means and the purpose of proving that it's nonnegative, etc... My problem is that I am a linear algebra novice and do not necessarily understand how the first part $v^TAA^Tv$ is equivalent to $A^Tv \cdot A^Tv$. I know that $a^Tb = a \cdot b$, but something else is going on, no? Appreciate any help!","['linear-algebra', 'proof-writing']"
133368,Systematically solving $ax^2+bx+c>0$ and the like,"We know that if $ax^2+bx+c=0$ with $a\ne0$, then the solution(s) can be given by the quadratic formula $x=\frac{-b \pm \sqrt{b^2-4ac}}{2a}$. But what if we want to solve a quadratic inequality such as $ax^2+bx+c>0$? First, if $ax^2+bx+c$ can be factored into $(x+p)(x+q)$, then we have $(x+p)(x+q)>0$, so we know: Both $(x+p)$ and $(x+q)$ are positive; or, Both $(x+p)$ and $(x+q)$ are negative. For the first case, we have $(x+p)>0$ and $(x+q)>0$, which simplify to $x>-p$ and $x>-q$, which is just $x>\max\{-p,-q\}$. For the second case, we have $(x+p)&lt0$ and $(x+q)&lt0$, which simplify to $x&lt-p$ and $x&lt-q$, which is just $x<\min\{-p,-q\}$. So the final answer is just $x\in\{x:x>\max\{-p,-q\}\text{ or }x<\min\{-p,-q\}\}$. Next suppose $\sqrt{b^2-4ac}$ is imaginary. Then we have two cases: $a>0$ so that the graph of $f(x)=ax^2+bx+c$ is completely above the $x$-axis. Then all real numbers are solutions to $ax^2+bx+c>0$. $a&lt0$ so that the graph of $f(x)=ax^2+bx+c$ is completely below the $x$-axis. Then no real number is a solution. Now suppose $ax^2+bx+c$ does not factor. Then ""force-factor"" using the quadratic equation into $(x-\frac{-b + \sqrt{b^2-4ac}}{2a})$ and $(x-\frac{-b - \sqrt{b^2-4ac}}{2a})$ and repeat the steps above. Another way to think about this: since we are guaranteed that $\sqrt{b^2-4ac}$ is real (we took care of the imaginary cases already), we can divide the real number line into three intervals: $(-\infty,\frac{-b - \sqrt{b^2-4ac}}{2a})$, $(\frac{-b - \sqrt{b^2-4ac}}{2a},\frac{-b + \sqrt{b^2-4ac}}{2a})$, and $(\frac{-b + \sqrt{b^2-4ac}}{2a},+\infty)$ (or the other way round if $a&lt0$). Then check some number in each interval, and if that number is greater than $0$, then include that entire interval in the final answer. Otherwise don't include it. We can also do this by taking the outer two intervals when $a>0$ and taking the middle interval when $a&lt0$ (I think). Questions: (1) Is this approach correct? (2) If so, is there a more efficient way to do it, i.e., how might one go about programming an algorithm for this type of problem?","['inequality', 'algebra-precalculus']"
133406,Why is Parseval's Equality and Bessel's Inequality Different?,"Bessel's Inequality:   $\sum_n |\langle x, e_n \rangle |^2 \leq \|x\|^2$ Parseval: $\;\;\;\;\;\;\;\;\;\;\;\;\;\;$ $\sum_n |\langle x, e_n \rangle |^2 = \|x\|^2$","['hilbert-spaces', 'fourier-analysis', 'functional-analysis']"
133412,Union of non-measurable sets,"Let $\mathcal{N}$ be a Vitali non-measurable set in [0,1], and $\{r_k\}_{k=1}^{\infty}$ be an enumeration of all the rationals in [-1,1]. Consider the sets $$\mathcal{N}_k=\mathcal{N}+r_k.$$ My question is that, whether the union of all the $\mathcal{N}_k$'s, $$\mathop{\cup}_{k=1}^{\infty}\mathcal{N}_k$$ is measurable.","['measure-theory', 'real-analysis']"
133433,Approximation of a bounded measurable function with step functions?,"I'm having trouble judging whether this statement is correct: For an arbitrary bounded measurable function $f$ defined on $[0,1]$, $\exists{}\ $a sequence of step functions $\{\phi_n\}$, such that $\{\phi_n\}$ converges to $f$ pointwisely a.e. on $[0,1]$. By the Simple Approximation Theorem, this is true if we are allowed to use simple functions. But I am curious whether this still holds when we restrict ourselves to step functions only. I have a feeling that this may not be true because for a measurable function, its domain may be too ""broken up"" to be fitted by step functions. But I don't know how to find a counter-example... So can anybody help me find a counterexample or confirm that this is correct? Thank you very much! Edit: By a step function I mean a (finite) linear combination of indicator functions for intervals.","['approximation', 'measure-theory', 'real-analysis']"
133440,PDEs with non-local terms,"Not sure if I've used the correct terminology here (`non-local'). I think the lack of knowing the correct terminology is why I haven't been able to find any information about my query thus far. I'm interested in particular systems of semi-linear first-order (functional?) PDEs. One example where I seek solutions defined on $\mathbb{R}_+ \times \mathbb{R}_+$ is: $\frac{\partial F_1(z,t)}{\partial t} + \gamma \frac{\partial F_1(z,t)}{\partial z} = \lambda F_2(z,t) - \beta F_1(z,t) F_1(0,t)$ $\frac{\partial F_2(z,t)}{\partial t} = \beta F_1(z,t) F_1(0,t) - \lambda F_2(z,t)$ when $z > 0$; and: $\frac{\partial F_1(z,t)}{\partial t} = \lambda F_2(z,t) - \beta F_1(z,t) F_1(0,t)$ $\frac{\partial F_2(z,t)}{\partial t} = \beta F_1(z,t) F_1(0,t) - \lambda F_2(z,t)$ when $z = 0$. Boundary conditions are $F_1(z,0) = \sigma(z)$ and $F_2(z,0) = 0$
for all $z$. The thing which appears to make these special is the presence of the `non-local' terms $F_1(0,t)$. I guess I could try and solve the system using finite difference methods, but I was wondering, is there anything better that can be done here, e.g. can the method of characteristics still be used? I'm not particularly familiar with PDEs so any help would be gratefully received --- do systems like this even have a name, are there any references I should see? Thanks!","['ordinary-differential-equations', 'partial-differential-equations']"
133443,"Is $[0,1]^\omega$ homeomorphic to $D^\omega$?","Let $n\in \mathbb N$ and let $D^n$ be the closed $1$-ball in $\left(\mathbb R^n, \|\,\cdot\,\|_1\right)$. It is not too hard to show that $[0,1]^n \cong D^n$ in this case. This observation leads to the question whether we also have $[0,1]^\omega \cong D^\omega$, where $$D^\omega = \left\{(x_n)_{n\in \mathbb N} \in \ell^1 \; \Bigg| \; \sum_{n=1}^\infty |x_n|\le 1\right\}$$ is the closed unit ball in $\ell^1$. Now if we view $D^\omega$ as a subspace of $\ell^1$, then we can prove that it is not homeomorphic to $[0,1]^\omega$ by arguing that the latter is compact, while the former is not. But what happens if we view $D^\omega$ as a subspace of $\mathbb R^\omega$? Is $D^\omega$ homeomorphic to $[0,1]^\omega$, when both sets are endowed with the subspace topologies induced by $\mathbb R^\omega$ (in the product topology)? In this case both spaces are compact ($D^\omega$ is the intersection over all $n\in \mathbb N$ of the compact sets $\{x\mid \sum_{i=1}^n |x_i| \le 1\} \cap [-1,1]^\omega$) and all topological properties I can think of are preserved when we go from $[-1,1]^\omega \cong [0,1]^\omega$ to the subspace $D^\omega$. I have also tried to explicitly construct a homeomorphism, but to no avail. I hope some of the topologically savvy guys on this site could help me out here! Thanks =)","['general-topology', 'convex-analysis', 'locally-convex-spaces', 'functional-analysis']"
133447,If both $H$ and $G/H$ are locally compact then $G$ is locally compact (topological Group),"How do I prove this statement? Let $G$ be a Topological group and let $H$ be a subgroup of $G$, if both $H$ and $G/H$ are locally compact then $G$ is locally compact. (we will endow the set $G/H$ with the quotient topology)","['general-topology', 'topological-groups', 'locally-compact-groups']"
133453,Complex integration with Cauchy's Integral Formula,"Calculate$$\int_\gamma \frac{(z+27i)(z+16)}{z(z+81)^2}dz$$ where $\gamma$ is the triangle whose vertices are the third roots of $z = -8i$, oriented counterclockwise. Answer: I calculated the third roots of $-8i$ and they all have modulus $2$. This tells me that the maximum distance of $\gamma$ from the origin will be $2$. There are singularities at $z=0, z=-81$. As $81 > 2$, this singularity falls outside $\gamma$ so the only one that matters is $z = 0.$ I then applied Cauchy's Integral Formula
$$\int_\gamma \frac{(z+27i)(z+16)}{z(z+81)^2}dz = 2\pi i [\frac{(z+27i)(z+16)}{(z+81)^2}] |_{z=0}$$ And I got a final result of $\displaystyle\frac{-32\pi}{243}$. Is my analysis and final result correct?",['complex-analysis']
133454,Describe the interior of Cantor set,"Describe the interior of Cantor set I think the interior is empty because the cantor set of nowhere dense, but as I write it correctly?",['general-topology']
133457,Cauchy Riemann equations and analyticity of a function,"A At which points if any does the function $$f(z) = z\operatorname{Re}(z) + \bar{z}\operatorname{Im}(z)$$
satisfy the Cauchy-Riemann equations? B At which points, if any is this function analytic. Justify your answer. Answer A. I applied the Cauchy Riemann equations and found that they are satisfied at x = 1, y = -1. B. As they are not differentiable anywhere else in C, particularly in some neighbourhood of (1, -1), they function is analytic nowhere. Are my answers for A and B correct?",['complex-analysis']
133464,Where is complex Log continuous,Write down the biggest subset $D$ of $\mathbb C$ on which ${\rm Log(z)}$ is a continuous function. Explain why ${\rm Log(z)}$ is not continuous at points outside $D.$ Anyone know the answer to this?,['complex-analysis']
