question_id,title,body,tags
2512941,What is the simplest way to compute :$\int^{\pi}_0\bigl(\frac{\sin(x)}{5-4\cos(x)}\bigr)^2dx=\frac{\pi}{24}$,"I am trying to compute the following integral. $$\int^{\pi}_0\biggl(\frac{\sin(x)}{5-4\cos(x)}\biggr)^2dx$$ My attempt was to expand the integrand and make use of the standard change of variables $t =\tan x/2$. But it turns out to be a lengthy and exhausting computations. I can put all details here since it is not pleasant.
at the end I got the answer: $$\int^{\pi}_0\biggl(\frac{\sin(x)}{5-4\cos(x)}\biggr)^2dx =\frac{\pi}{24}$$
Maybe it is not correct so do not trust this result at 100% I would like to know if there is an easiest way or trick that quickly leads to the answer?","['real-analysis', 'trigonometry', 'calculus', 'complex-analysis', 'integration']"
2513021,Understanding the proof to Egorov's Theorem,"Theorem (Egorov). Let $\{f_n\}$ be a sequence of measurable functions converging almost
  everywhere on a measurable set $E$ to a function $f$. Then, given any
  $\delta > 0$, there exists a measurable set $E_{\delta} \subset E$
  such that $\mu(E_{\delta}) > \mu(E) - \delta$ $\{f_{n}\}$ converges uniformly to f on $E_{\delta}$ proof (partial) In the above link is a picture of (partially) the proof for the theorem in my book. They begin the proof by considering the following set $$E_{n}^{m} = \bigcap_{i > n} \left \{ x \; : \; |f_{i}(x) - f(x)| < \frac{1}{m}\right \}$$ I do not understand the motivation in considering this set. To me, here is what I see. I know that this theorem is meant to show the relationship between convergence a.e. and uniform convergence. The definition of uniform convergence is A sequence of function $\{f_n\}$ (with domain $D$) converges uniformly to $f$ if $$\forall \epsilon > 0 \; \exists N \in \mathbb{N}\; \forall n \geq N\; \forall x \in D, \; |f_n(x) - f(x)| < \epsilon$$ A sequence of functions converge to the function a.e. if the set of points for which the convergence fails to hold is of measure zero. The set $E_{n}^{m}$ looks like the definition of uniform convergence I think. The $\frac{1}{m}$ is the $``\epsilon""$ and the $i > n$ is the $``n > N""$. But I don't see the idea of what we want to do with this. Could someone explain the motivation to me please?","['real-analysis', 'measure-theory']"
2513039,P-Value of a Z-Score by Hand,"I am running into an issue with a question that I am working on.  I want to find the $p$-value of a $z$-score by hand.  Here is the exact question and the work that I have done so far on it.: A controversy has arisen in the mathematics department at a large university over the proportion of freshman who had AP statistics in high school.  The department chair insists that exactly $70\%$ of freshman had AP statistics in HS, but the other department member suspect that the proportion may be different.  To resolve this issue, the department surveys $55$ freshman finding that $32$ had AP statistics in high school.  Using level $0.05$, test for evidence that the ""other department members"" are right.  Give the p-value. The work that I have done so far is as follows:
$H_0$: $\pi=0.7$ vs HA: $\pi \ne 0.7$. This is a two sided test.  $\hat\pi=32/55=.5818$ about.  $\alpha=0.05$ Working the formulas I obtain $z=-1.91$.  The rejection region is $|z|>1.96$.  We conclude that we fail to reject $H_0$ as $1.91 \ngtr 1.96$. My issue now is figuring out how to find the $p$-value without using a calculator.  Any advise would be helpful.","['statistics', 'probability', 'hypothesis-testing']"
2513043,Orientability of Lie Group,"I am trying to show that a Lie Group $G$ is orientable. I would like to do this by construccting a nowhere vanishing top form $\omega$ on $G$, which would then imply that $G$ is orientable. I think that the general idea should be to somehow find a nowhere vanishing form at a point (probably the identity?) and then somehow ""shift"" the form around $G$ by left multiplication, but I am not sure about how the details would work. Could someone help me this more precise?","['manifolds', 'general-topology', 'lie-groups']"
2513112,Finding number of distinct terms when collected in $(x+y+z)^{20}(x+y)^{15}$,"Find the number of distinct terms when expanded and collected in $(x+y+z)^{20}(x+y)^{15}$ How would I do this nicely? I know that the first expansion has general algebraic term of $$\frac{20}{b_1!b_2!b_3!} x^{b_1}y^{b_2}z^{b_3}
$$
where $b_1+b_2+b_3 = 20, b_1 \geq 0$ and the second is
$$\frac{15}{c_1 ! c_2 !} x^{c_1}y^{c_2}
$$
where $c_1 + c_2 = 15, c_i \geq 0$.",['discrete-mathematics']
2513121,"If number of customers are known, find probability wait time exceeds certain number","The question is: There is one checkout line and the average service time is 4 minutes per customer. There are 3 people in the queue ahead of you. What is the probability that your wait time will exceed 6 minutes? I thought that the distribution was gamma with n = 3 and $\lambda$ = 1/4 but apparently I'm not correct. That is, I thought it was
$$\int^{\infty}_{6} {\frac{(1/4) e^{-x/4}(x/4)^{3-1}}{(3-1)!} dx} \approx 0.808847.$$
I'm thinking that there is a simpler way of computing this without (at least directly) using calculus because it is supposed to be an algebra-based statistics course. EDIT. The reason why I think I am wrong is because the answer was marked incorrect for this online homework that I'm trying to help out a friend with. I wonder if Central Limit Theorem needs to be used here.","['statistics', 'probability']"
2513141,"Show $f(x,y) = y^2 - x^2$ at $(0,0)$ has a critical point, but is not a max/min value","So as always... I found the partial derivative with respect to $x$ and $y$ of $f(x,y)$ which gave me: $f_x=-2x$ $f_y=2y$ So I wasn't too sure what to do next, but I set $f_x = 0$: $0 = -2x$ $x=0$ And I got stuck again. How do I continue AND prove that $f(x,y)$ at $(0,0)$ has a critical point but is not max/min value? Thanks!","['multivariable-calculus', 'extreme-value-theorem']"
2513148,Is there an analogous Gibbs phenomena to approximating sinusoidal but with polynomial terms?,"I was trying to approximate a sine curve with a finite number of polynomials terms using linear regression (or the pseudo-inverse). I construct a Vandermonde matrix (or a Kernel polynomial feature matrix) and then solve the linear system (usually using the pseudo-inverse): $$ y = \Phi(x)w$$ then I try to visualize the solution. For low degree polynomials the approximation seems fine but eventually when the degree of the polynomial is pretty high, there is a weird funky bit at the edge: This reminded me of Gibbs phenomenon where at discontinuities there seems to be high oscillations near the jump. I know that Gibbs phenomena happens with a finite sum of Fourier series. However, this empirical observation really made me wonder. Is this the reason the edge of the approximation looks strange? Also from a statistics/machine learning point of view it seems clear that if the solution is not regularized, then a high complexity model should overfit to noise. However, in this model there is no noise. Therefore, I was not quite sure what was going on and was wondering what it was. Thus, my question is, is there a Gibbs phenomena for approximating sinusoidal with a finite number of polynomial terms? If yes, then what is it and what are its details? Another observation that I found odd is that the high oscillation/jump only happened at the right discontinuity. I am not sure why that is but I thought it was quite puzzling.","['fourier-series', 'polynomials', 'fourier-analysis', 'machine-learning', 'statistics']"
2513194,"$G$ a Lie group, $V, S$ submanifolds of $G$ containing $e$, $\psi : V \times S \rightarrow G$; $\psi(v,s)=vs$, then $d\psi(X,0)=X$ and $d\psi(0,Y)=Y$","Okay I couldn't fit this all in the title but here is the full setup: $G$ a Lie group with $V,S$ submanifolds of $G$ containing the identity element $e$. We are considering the map $\psi: V \times S \rightarrow G$ obtained by restricting the multiplication map on $G$, i.e. $\psi(v,s)=vs$. I am stuck trying to show that since $\psi(v,e)=v$ for $v \in V$ and $\psi(e,s)=s$ for $s \in S$, then it follows that the differential of $\psi$ at $(e,e)$ satisfies $d\psi(X,0)=X$ and $d\psi(0,Y)=Y$ for $X \in T_{e}V$ and $Y \in T_{e}S$. I am also confused about how we are identifying $T_{(e,e)}(V \times S)$ with $T_{e}V \oplus T_{e}S$. This problem arises in the proof of Theorem 7.21 of John Lee's introduction to smooth manifolds book (second edition).","['smooth-manifolds', 'differential-geometry', 'differential-topology', 'lie-groups']"
2513211,Proof on Injection/Surjection,"Let A and B be sets. There exists an injection from A to B if and only if there exists a surjection from B to A. I know that I also need to prove the converse of the statement: If there is a surjection from B to A, then there is an injection from A to B. I started off with:
If there is an injection from A to B, then there exists g:from B to A such that g(f(a))=idA(identity of A). I have to use this fact in the proof, I didn't think it was necessary though. I was trying to use the fact that for all a1 and a2 in A, f(a1)=f(a2) implies a1=a2 and build off that. If anyone can give me some direction, that'd be good. Thanks","['proof-writing', 'functions']"
2513258,Multivariable Chain Rule / Partial Derivatives,"If $z = f(x − y)$ and $g(x, y) = x − y$, so that $z =f∘g$ Why/How does the chain rule imply this? $$\frac{∂z}{∂x} =\frac{∂f}{∂g}\frac{∂g}{∂x} =\frac{∂f}{∂g}$$ and $$\frac{∂z}{∂y}=\frac{∂f}{∂g}\frac{∂g}{∂y} =-\frac{∂f}{∂g}$$","['multivariable-calculus', 'partial-derivative', 'chain-rule', 'calculus']"
2513266,Finding one sided limit using L'Hospital's rule,$\lim_{x\to 0^+}\left(x^\sqrt{x}\right)=?$ How do I turn it into a fraction? Is L'Hospital's rule even applicable?,"['calculus', 'limits']"
2513275,Homotoping a Morse function to put all of the critical points on the boundary,Let $M$ be a connected manifold with boundary and let $f: M \to \mathbb{R}$ be a Morse function (that does not necessarily send the boundary of $M$ to a point).  Is it always possible to homotope $f$ through Morse functions so that all of the critical points are on the boundary of $M$? My initial thought was that this can not be true since then the interior of $M$ admits a Morse function that does not have any critical points - but there is no problem with that as all open manifolds admit Morse functions without critical points.,"['geometric-topology', 'differential-geometry', 'differential-topology']"
2513326,confusion in a combinatorics problem of IMO 2001,"Original Problem: Twenty-one girls and twenty-one boys took part in a mathematical competition. It turned out that each contestant solved at most six problems, and for each pair of a girl and a boy, there was at least one problem that was solved by both the girl and the boy. Show that there is a problem that was solved by at least three girls and at least three boys. Same problem but a diferet formulation: Integers are placed in each of the $441$ cells of a $21 \times 21$ array. Each row and each column has at most 6 different integers in it. Prove that some integer is in at least $3$ rows and at least $3$ columns. My Solution: We have $21$ cells in diagonal and we have to place atmost $6$ integers in it. By pigeon hole principal there is always exist a number from $1$ to $6$ which appears $4$ times in cells of digonal. Hence, we have at least three integers which appears in at least three rows and at least three columns. Rest of cells present in $21 \times 21$, we fill any way. Surely, I am not able to understand this problem. Please, can any body interpreat this problem?",['combinatorics']
2513327,Limit as $x$ approaching $0$ of$ (9/x) - 9cot(x)$,"Ok so the correct answer is $0$ and it is confirmed graphically, but how do we conclude this algebraically? This is breaking the property of limits where u can take the individual limits of $(9/x)$ and $9cotx$ and the limit of the function would be $L - C$, but $L$ and $c$ does not exist?",['limits']
2513348,Order Statistics w/ Max,"Let $X_1, X_2, \ldots$ be i.i.d. r.v.s with CDF $F$, and let $M_n = \max(X_1,X_2, \ldots ,X_n)$. Find the joint distribution of $M_n$ and $M_{n+1}$, for each $n \geq 1$. So, CDF of $M_{n+1}$ is given as, 
$$ \begin{align} 
P(M_{n+1} \leq x) &= P(X_1 ≤ x, X_2 ≤ x, \ldots, X_n ≤ x, X_{n+1} ≤ x ) \\
&= \underbrace{F(x) \times F(x) \times \ldots}_{(n+1) \text{ times}} \\
&= F(x)^{n+1}
\end{align}$$ We want to consider two cases: $P(M_n \leq a,M_{n+1} \leq b)$. However, after getting these facts, I am lost. Can someone help me in finding this joint distribution? Much thanks.","['statistics', 'probability', 'order-statistics', 'probability-distributions']"
2513349,Directional Derivatives (2 var),"Compute the directional derivatives of the following functions along unit vectors at the indicated points in directions parallel to the given vector. $f(x, y) = x^y$ $(x_0, y_0)$ = (e, e) d = 3 i + 4 j The formula for directional derivatives = gradient f(e,e) ⋅ v I got the answer $3ee^{e-1}+4\ln \left(e\right)e^e$ which is incorrect. What is the correct way of doing this problem? I can show my steps if necessary. MY STEPS: find gradient f = $(yx^y-1 , ln(x)x^y)$ gradient f(e,e) = $(ee^{e-1},ln(e)e^e)$ d = 3 i + 4 j $(ee^{e-1},ln(e)e^e)$ ⋅ (3,4) = $3ee^{e-1}+4\ln \left(e\right)e^e$","['multivariable-calculus', 'partial-derivative']"
2513352,Why do row operations not change the column rank?,"From this question link , I got to know that row operation (row subtraction and row permutation) do change column space. But still it seems that it does not change the column rank. I am trying to prove that row rank == columns rank, but for that I need confirm the statement above. I am referring to this note Have any intuitive explanation or proof for that row operation does not change the column rank?","['matrix-rank', 'linear-algebra']"
2513355,"A circle centered at $(0,2)$ is tangent to $y=x^2$ at exactly two points. What is its radius? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question A circle is centered at $(0,2)$ and is tangent to $y=x^2$ at exactly two points. What is the radius of the circle? Don't really have an idea at how to solve the problem. Help is appreciated!","['derivatives', 'conic-sections', 'tangent-line', 'circles']"
2513367,Finding composition of a function,"Let $f,g:\mathbb{R}\rightarrow\mathbb{R}$ be functions given by
$$f(x)=(x-1)^2 \quad \text{and}\quad g(y) \ \begin{cases}0,\qquad 
 \qquad y<0\\\sqrt{y}+1\quad\quad y\geq 0.\end{cases}
$$
Show that $g\circ f = \mathfrak{i}_\mathbb{R}$ where $\mathfrak{i}_\mathbb{R}$ is the identity function on $\mathbb{R}$. Determine $f\circ g$. I tried doing the first part and seem to not be getting it... Suppose $x\geq 1$. Then $f(x)\geq 0$. We have $g(f(x)) = \sqrt{(x-1)^2} + 1 = |x-1| + 1 =  x-1+1 = x$ Now suppose $x<1$. Then $f(x)\geq 0$ and so $g(f(x)) = \sqrt{(x-1)^2}+1 = |x-1|+1 = 1-x + 1 = 2-x$ I don't see how this is the identity function. Also, I see that the range of $g$ is $[1,\infty]\cup\{0\}$.",['functions']
2513374,Finding conditional probability and minimum trials in binomial distribution,"I have a question like this: A missile protection system is set up in a particular zone. The system consists of $n$ radar sets operating independently. Each set has a probability of $0.95$ of detecting a missile which enters the zone. Question Suppose that there are 6 radar sets operating in a particular day (i.e. $n = 6$), Given that a missile is detected by at least one set, what is the conditional probability that it is only detected by exactly one set? We have: $X \sim B(6, 0.95)$. Therefore:
$$P(X = 1 | X \geq 1) = \frac{P(X = 1)}{P(X \geq 1)} = \frac{2}{1122807} \approx 0$$ If the probability of detecting a missile in the zone is required to be at least $0.9999$, what is the smallest $n$ can be? Assuming: $X \sim B(n, 0.95)$. We need: $P(X \geq 1) \geq 0.9999$ or equivalently:
$$P(X = 0) \leq 0.0001 = \binom{n}{0}*0.95^{0}*0.05^{n} = 0.05^{n}$$
Therefore, $n \geq 3.0744 $. Minimum $n$ is $4$. Is my solution right?","['statistics', 'binomial-distribution', 'probability']"
2513378,How to get joint probability density from bivariate distribution function,"Let $X_{i} \sim \varepsilon(\lambda_{i}), i = 1,2,3$ be mutually independent ($\varepsilon$ means exponential, $\lambda_{i}$'s are parameters). Then $(T_{1},T_{2}) = (X_{1} \wedge X_{3}, X_{2} \wedge X_{3})$ has a bivariate Marshall-Olkin exponential survival function, for $t_{1}\geq 0$ and $t_{2} \geq 0$: $$ \overline{F}(t_{1},t_{2})=P(T_{1}>t_{1},\, T_{2}>t_{2}) = P(X_{1}>t_{1},\, X_{2}>t_{2}, X_{3}>t_{1} \vee t_{2}) \\ = \exp\{-\lambda_{1}t_{1}-\lambda_{2}t_{2} - \lambda_{3}(t_{1} \vee t_{2})\} $$ I need to derive the joint probability density function $f(t_{1},t_{2})$ for this distribution function $\overline{F}$, and then compute $\int \int_{\mathbb{R}_{+}^{2}}f(t_{1},t_{2})dt_{1}dt_{2}$, and then say whether there is anything strange about my answer. Usually, in the case of one variable, to get from a distribution function $F$ to a probability density function $f$, I would take the derivative of $F$. However, in the case of two variables, I am not sure what to do - do I take partial derivatives of $t_{1}$ and $t_{2}$? How does the $\vee$ operator impact that? Then, I assume I have to integrate them again, and I'm guessing that the ""strange"" part is that when I integrate, I'm not going to get back my original $\overline{F}$, possibly because the $X_{i}$ are mutually independent. But, like I said, I am not sure how to formally go about showing any of these things, primarily because of the multivariate nature of this problem, and because the relationship between the $X_{i}$ and the $T_{i}$ is confusing me. Could somebody please help me finish this? I am extremely confused and very much in need of guidance! Thank you!","['probability-theory', 'probability', 'probability-distributions']"
2513406,"A familiar limit, but in general form . [duplicate]","This question already has answers here : Evaluating $\lim\limits_{n\to\infty} \left(\frac{1^p+2^p+3^p + \cdots + n^p}{n^p} - \frac{n}{p+1}\right)$ (7 answers) Closed 2 years ago . Suppose $a \in \mathbb{R} ,a>1$
Is there an idea to compute the limit below ?
$$\lim_{n \to \infty}\left( \frac{1^a+2^a+3^a+...+n^a}{n^a}-\frac{n}{a+1} \right)$$ I tried it for $a=1,2,3$ but I get stuck in general form . Can someone help me ? Thanks in advance.","['real-analysis', 'integration', 'calculus', 'limits']"
2513445,"Given two tangent circles, find the two centers of a third that is tangent to both with given radius","Click to see my hand drawn image Given the center and radius of two circles that are tangent to each other, I need the two possible centers of a third circle with a given radius that is tangent to the first two. Sorry about the hand-drawn image.  I need $(x_3, y_3)$ in the picture where all three circles touch and I know the radii of all the circles.  I understand there should be two such points. Thanks! UPDATE: I thought I would share the code I came up with using the accepted answer below.  When I finally worked it all out, the code is surprisingly simple!!! (The variable names are from the image in the accepted answer here: https://stackoverflow.com/questions/3349125/circle-circle-intersection-points ).  Oh, this is in the Processing language. // Find the center of a third circle tangent to two original tangent
// circles with a given radius.  Works by finding the intersection of
// the two circles centered where the original two are but with radii
// r0+newR and r1+newR.

PVector findThirdCenterOfTangentCircles(
              float x0, float y0, float r0,
              float x1, float y1, float r1,
              float newR){

     float d = dist(x0, y0, x1, y1);
     r0 += newR; // if it wasn't for these two lines we would just be finding the
     r1 += newR; //   intersection of the original two circles
     float a = ((r0*r0)-(r1*r1)+(d*d))/(2*d);
     float h = sqrt((r0*r0)-(a*a));
     float x2 = x0 + a*(x1-x0)/d;
     float y2 = y0 + a*(y1-y0)/d;
     float x3 = x2 + h*(y1-y0)/d;
     float y3 = y2 - h*(x1-x0)/d;
     // other point would be...
     //    float x3 = x2 - h*(y1-y0)/d;
     //    float y3 = y2 + h*(x1-x0)/d;

     return new PVector(x3, y3);
}","['circles', 'trigonometry']"
2513477,Help me prove $\lim_{n→∞}\left(\sum_{k=1}^{n}\frac{1}{k} -\log n \right) >1/2$,"I am a high school student.
I was able to prove that the limit of $\sum_{k=1}^{n}\frac{1}{k}-\log n$ converges. However, I can’t prove the convergence value is greater than $\frac{1}{2}$.
I tried a lot and was able to prove it is smaller than $1$. However, I can't greater than $\frac{1}{2}$.","['sequences-and-series', 'calculus', 'limits']"
2513488,How can i understand this contradiction of $H^{-s}(\Omega)$,"This makes me puzzled.Here $H^{k}(\Omega)$ is the sobolev space $W_p^k(\Omega)$ with $p=2$. We all know that $H^{k}(\Omega)$ is Hilbert space,This means that $(H^k(\Omega))^{*}=H^{-k}(\Omega)$ should be $H^{k}(\Omega)$ itself from Risez Representation theorem. However,we know that Dirac $\delta$-function $\delta\in W^{k}_p(\Omega)$ if $k<-n+n/p \  $ from Sobolev's Inequality.Clearly $\delta\notin H^{k}(\Omega),\forall k>0$.This will be a contradiction,cause there are some $k$ such that $\delta\in H^{-k}(\Omega)$ while $\delta\notin H^{k}(\Omega)$. What's wrong with my previous statement?","['functional-analysis', 'sobolev-spaces', 'finite-element-method', 'partial-differential-equations']"
2513490,Prove that if $n$ is a positive odd integer then $1947\mid (46^n+296\cdot 13^n)$,"This is an exercise from The Kürschák Mathematics competition from the year 1947: Prove that if $n$ is a positive odd integer then $1947\mid (46^n+296\cdot 13^n)$. I have the solutions in the back of the book but I would like to tackle the problem myself. I don't really know how to start, any HINTS are appreciated. Thank you!","['divisibility', 'exponential-function', 'elementary-number-theory', 'contest-math', 'discrete-mathematics']"
2513493,Is this quotient ring finite?,"Let $R$ be a commutative ring with unity satisfying $r^{10}=r^2$  $\forall$$r$$\in$$R$, and $P$ a prime ideal of $R$. The original question is to find the possible orders of the quotient ring $R/P$. My thoughts: If $R/P$ is finite it is a finite domain which is a field and since $r^8=1$ iff $r\neq0$, isomorphic to the Galois field $GF(9), GF(5), GF(3),$ or $GF(2)$. It remains to show that $R/P$ is finite. Can I use the fact that $P$ is a prime ideal? Or should I somehow make use of the given equation? Thank you in advance.","['abstract-algebra', 'ring-theory']"
2513525,"Compute the integral $\int_0^1\int_0^1\ldots\int_0^1 f(x_1 + x_2 + \ldots + x_n)\,dx_1\,dx_2\ldots dx_n $","A mysterious result , probably by Euler himself, goes as follows: If $n$ is a positive integer and $f:\mathbb R \rightarrow \mathbb C$ is integrable on the open interval $(0, n)$, then
  $$\int_0^1\int_0^1\ldots\int_0^1 f(\lfloor x_1 + x_2 + \ldots +x_n\rfloor) \, dx_1 \, dx_2\ldots dx_n = \sum_{k=1}^\infty A(n,k)\frac{f(k)}{k!},
$$
  where the $A(n,k)$'s are the Eulerian numbers. Is there an analogous result without the floor function ? Thats is, is there an analogous formula for the integral $$
\int_0^1\int_0^1\ldots\int_0^1 f(x_1 + x_2 + \ldots + x_n)\,dx_1\,dx_2\ldots dx_n \; ?
$$","['multivariable-calculus', 'eulerian-numbers', 'integration', 'sequences-and-series']"
2513579,Matrix equation: why can't I simplify by multiplying by the inverse matrix?,"I know, it's standard stuff, but I could not find a good place where I could read about this. Please help me understand, or refer me to some good source where I could learn. Thank you very much! I want to solve the equation: $X^TX a = X^Ty$ Where $X$ is a matrix, $y$ and $a$ are vectors. Can I solve the equation by multiplying both sides by the inverse matrix of $X^T$? $\color{red}{(X^T)^{-1}} X^TX a = \color{red}{(X^T)^{-1}} X^Ty $ ? $Xa = y$ $a = X^{-1}y$ Or am I doing something wrong? I watched a course where they solved the equation to: $a = (X^T X)^{-1}X^Ty$ but I don't understand why they didn't simplify the equation first.","['matrices', 'matrix-equations']"
2513596,Fraction of the sets receive each color,"Let $S_1,S_2,\dots,S_k$ be subsets of the set $S=\{1,2,\dots,n\}$, not necessarily distinct. We will color each element of $S$ red, green, or blue. From this coloring, each set $S_i$ will receive one or more color according to the following rule: Let $r_i,g_i,b_i$ denote the number of red, green, and blue elements of $S_i$, respectively, and let $m_i=\max(r_i,g_i,b_i)$. If $r_i\geq m_i-1$, we give the color red to $S_i$. Similarly for green and blue. Does there exist a positive constant $d$ for which we can always color the elements of $S$ in such a way that for any color, at least a fraction $d$ of the sets $S_i$ receive that color?","['combinatorics', 'elementary-set-theory']"
2513680,Why do we take positive square roots when proving the derivatives of the trig functions?,"The proofs of the derivatives of the trig functions typically use the identity $$\cos^2(x) + \sin^2(x) = 1$$ but I usually see something like this $$\sin^2(x) = 1 - \cos^2(x)$$
$$\implies \sin(x) = \sqrt{1-\cos^2(x)}$$ to prove, say, the derivative of $\cos^{-1}(x)$. Why do we take the positive square root of $\sin(x)$? I'm sure I'm missing something really obvious. (For one thing, the RHS must be non negative ... ) Thanks.","['derivatives', 'trigonometry', 'calculus']"
2513695,On a base 10 Infinite Series,"What is the sum of the reciprocals of numbers with only $0$ 's and $1$ 's in their base $10$ expansion? $$x=\frac{1}{1}+\frac{1}{10}+\frac{1}{11}+\frac{1}{100}+\frac{1}{101}+\frac{1}{110}+\frac{1}{111}+\cdots.$$ Is the result transcendental, and does it have a closed form? I have figured out that $1.238405615301<x<1.238405615306$ , but do not know where to go from there.","['number-theory', 'transcendental-numbers', 'sequences-and-series', 'closed-form']"
2513708,How many times do you have to use L'Hôpital's rule?,"I'm looking for cases like $$\lim_{x \to 0} \frac {1-\cos(x)}{x^2}$$ that will not give you the answer the first time you use L'Hôpital's rule on them. For example in this case it will result in a number $\frac{1}{2}$ the second time you use L'Hôpital's rule. I want examples of limits like  $\lim_{x \to c} \frac {f(x)}{g(x)}$ so that you have to use L'Hôpital's rule $5$ times, $18$  times, or say $n$ times on them to get an answer. Another question is about the case in which you use L'Hôpital's rule as many times as you want but you always end with $\lim_{x \to 0} \frac {0}{0}$. Does this case exist?","['derivatives', 'real-analysis', 'examples-counterexamples', 'limits', 'calculus']"
2513744,Monotone increasing sequence converging probability wise implies convergence almost surely,"Let $(\Omega, \mathcal F,\mathbb P)$ be a probability space. Let $X,X_j\in m\mathcal F, j\in\mathbb N$, $X_1\leq X_2\leq\ldots$ such that $X_n\to X$ by probability. Show that $X_n\to X$ almost surely. By letting $A_n(\varepsilon) := \{\omega : |X_n(\omega)-X(\omega)|>\varepsilon\}$, it's sufficient to show
$$(\forall\varepsilon > 0)\left (\mathbb P (\limsup _n A_n(\varepsilon))=0\right ). $$ To show the above it's also sufficient to show for every $\varepsilon >0$ the series $\sum _n \mathbb P (A_n(\varepsilon))$ converges (and apply Borel-Cantelli's lemma). Let $\varepsilon > 0$, we'll show the sequence
$$\sum_{j=1}^n \mathbb P(A_j(\varepsilon)), n\in\mathbb N $$
is a Cauchy sequence (therefore convergent) i.e we'll show 
$$\sum_{j=n+1}^{n+m}\mathbb P (A_j(\varepsilon))\xrightarrow[n\to\infty]{}0\qquad (m\in\mathbb N). $$ Fix $c>0$. Due to convergence $X_n\to X$ by probability, for some $N\in\mathbb N$
$$n>N \Longrightarrow \mathbb P(A_n(\varepsilon))< \frac{c}{m} \overset{??}\Longrightarrow \sum_{j=n+1}^{n+m}\mathbb P(A_j(\varepsilon))<c ?! \tag{*}$$ Wrong! Fixing $c>0$, convergence in probability provides for every $m\in\mathbb N$ an index $N(m)\in\mathbb N$ with
$$n > N(m) \Longrightarrow \mathbb P(A_n(\varepsilon))<\frac{c}{m}. $$
Clearly, these indices may increase without bound, however,  we may note 
$$a\leq b \Longrightarrow A_n(b)\subseteq A_n(a). $$
Fix the smallest $N(m) =: N$. By monotonicity, we also have
$$A_{n+1}(\varepsilon)\subseteq A_n(\varepsilon), n\in\mathbb N $$
Therefore, the argument in $(*)$ doesn't depend on the choice of $m\in\mathbb N$. Still wrong! There is also the choice of $\varepsilon$ to take into account. There is no hope of remedying that. This approach is doomed to fail.","['real-analysis', 'probability-theory', 'proof-verification', 'functional-analysis', 'measure-theory']"
2513771,Determining the countability of a set with a particular property [duplicate],"This question already has answers here : Uncountable set with exactly one limit point (3 answers) Closed 6 years ago . Let $E \subset \mathbb{C}$ be a set with the following property: for any sequence of elements $(e_n)_{n \in \mathbb{N}}$ with $e_n \neq e_m$ for $m \neq n$, $e_n \to 0$. Is $E$ necessarily countable? (Also convergence is in norm, of course). It seems like this problem should yield to contrapositive, that is, given an uncountable set, I can always find at least one nonrepeating sequence that does not converge to $0$. My idea is that for some $\epsilon >0$, if $E$ is uncountable, there must exist infinitely many distinct elements in the complement of $B_\epsilon (0)$. Then we can construct a sequence not converging to $0$ from that (so the statement is true). Is there a direct proof for the above?","['elementary-set-theory', 'analysis']"
2513775,Finite Subgroup Test,"The book I'm using gives the following test for checking if a subset of a group is a subgroup: Let $G$ be a group and let H be a nonempty subset of $G$. If $ab$ is in $H$ whenever $a$ and $b$ are in $H$ ($H$ is closed under the operation), and $a^{-1}$ is in $H$ whenever $a$ is in $H$ ($H$ is closed under taking inverses), then $H$ is a subgroup of $G$. It uses this to prove the following statement: Let $H$ be a nonempty finite subset of a group $G$. If $H$ is closed under the operation of $G$, then $H$ is a subgroup of $G$. It provides the following proof: In view of the above theorem, we need only prove that $a^{-1} \in H$ whenever $a \in H$. If $a=e$, then $a^{-1}=a$ and we are done. If $a \neq e$, consider the sequence $a$, $a^2$,.... By closure, all of these elements belong to $H$. Since H is finite, not all of these elements are distinct. Say $a^i=a^j$ and $i \geq j$. Then, $a^{i-j}=e$; and since $a \neq e$, $i - j > 1$. Thus, $aa^{i-j-1}=a^{i-j}= e$ and, therefore, $a^{i-j-1}=a^{-1}$. But $i-j-1>1$ implies $a^{i-j-1}\in H$ and we are done. I understand the proof, but before reading it, I tried proving this myself. An my proof seems very different: First check $e \in H$ -- 
  $H$ is non-empty. So there exists $a \in H$. H is closed, so it is true that for $x,y\in H$ (not necessarily different from $a$) that $x*y \in H$. In particular consider $a*y=a$. Then $y=e$. So $e \in H$ Now check $ab \in H$ --
  H is closed so $ab\in H$ whenever $a \in H$ and $b \in H$. Finally check $a^{-1} \in H$ --
  By 1, $a$ and $e$ are in $H$. Consider $a*x=e$. Thus $x = a^{-1}$. We know $H$ is closed. So $a^{-1} \in H$. My proof didn't use the finiteness of $H$, so there's a flaw somewhere - but I can't spot it. Where did I use finiteness?","['finite-groups', 'group-theory']"
2513782,Probability with an urn,"Given an urn with $5$ balls: red or blue . We draw a ball from the urn and replace this ball with a ball of the other color. We repeat this process until all balls have the same color. Prove that with probability one all balls have the same color ultimately. Hint: give an upper bound for the probability that you replace a ball more than nn times for all $n\in\mathbb{N}$ and use the continuity of the probability measure. I have no idea how to do this question, although I know that I need to use the squeeze theorem and the continuity to prove that the given probability is equal to $1$ . Could someone help?",['probability-theory']
2513841,What is the derivative of a polynomial at $\infty$?,"Let $f$ be a polynomial defined on the Riemann sphere. I'm struggling to understand in what sense such a map can be said to be ""holomorphic"" at $\infty$. What is the derivative of $f$ at $\infty$? I have a chart $z\to\frac1z$ mapping $\infty$ to $0$ and vice versa. So I think I need to work out the derivative of $1/f(\frac 1 z)$ at $z=0$. So: $$\lim_{z\to 0} \frac {\frac{1}{f(\frac1z)}-\frac1{f(\frac 1 0)}} {z}=\lim_{z\to0}\frac{1}{zf(\frac 1 z)}$$ Expanding the polynomial $f$, we see that if $\deg f>1$, $zf(\frac 1 z)\to \infty$ as $z\to 0$, so the derivative of $f$ at infinity is $0$, but if $f$ is affine of leading coefficient $a$, the derivative will be $\frac 1 a$. Is this correct? And what is the meaning of the calculation I've just done ? In particular, does this result not depend on the choice of chart?","['riemann-sphere', 'complex-analysis', 'complex-manifolds']"
2513851,Use Fermat's Little Theorem to find all the roots of the following,"Am I doing this problem right? Use Fermat's Little Theorem to find all the roots of the following polynomials in $\mathbb{Z}_{7}[x]$: $2x^{74}-x^{55}+2x+6$ If I know that Fermat's Little Theorem states $a^{p-1} \equiv1 \pmod{p} $ Therefore if the if we are using $\mathbb{z}_{7}[x]$ we can use $a^6 \equiv1 \pmod {7}$ Which will allow for: $$2(x^{74})-(x^{55})+2x+6=$$
$$2\Big(x^{(6*12)=72}\equiv 1 \pmod{7}\Big)x^2-\Big(x^{(6*9)=54} \equiv 1 \pmod 7\Big)x+2x+6=$$
$$2x^2-x+2x+6=2x^2+x+6$$ Am I doing this right ? Any feedback would be greatly appreciated","['number-theory', 'abstract-algebra']"
2514008,What is the one-point compactification of the Loch Ness Monster?,"The Loch Ness Monster surface is the noncompact orientable surface with one end accumulated by genus. If we take the one-point compactification of this surface we get some surface with finite genus by the classification. and get a manifold, it would have finite genus by the classification. This seems a little absurd. What is the one-point compactification of the Loch Ness Monster, and in general, is there any intuition behind determining compactifications of surfaces with infinite genus?","['general-topology', 'surfaces']"
2514031,Spectrum of bounded self-adjoint operator,"Suppose $A$ is a bounded self-adjoint operator on the Hilbert space $\mathcal{H}$. How do I prove that $\sigma(A) \subseteq \overline{\{\langle Ax,x\rangle: x\in \mathcal{H},\; \lVert x\rVert = 1\}}$?","['functional-analysis', 'spectral-theory']"
2514038,Measuring 'parallelness' of vectors,"I wish to construct some sort of 'measure' (not in the formal sense) of the 'parallelness' of a finite set of $m$ vectors $S = \{v_1 , \ldots , v_m\} \subset \mathbb{R}^n$. This parallelness $p$ should have the following properties: If $v \in \mathbb{R}^n$ and $\{\lambda_1 , \ldots , \lambda_m \} \subset \mathbb{R}^+$ then
$$
p(\lambda_1 v , \ldots , \lambda_m v) = 1
$$
since, with our set of positive $\lambda$'s, all vectors of the form $\lambda_iv$ point in the 'same diection' In any other case
$$
p < 1
$$
to indicate that these vectors are not totally parallel An easy way to construct such a thing for $m=2$ is using the dot product. Denoting unit vectors by a hat then
$$
p(v_1,v_2) = \hat{v}_1 \cdot \hat{v}_2
$$
Note that $p(v_1,v_2) \leq 1$ because $\hat{v}_1$ and $\hat{v}_2$ are unit vectors. For more vectors it gets trickier. I currently have the approach
$$
p(v_1, \ldots , v_m) = \left\lVert \frac {\hat{v}_1 + \ldots + \hat{v}_m}{m} \right\rVert
$$
which has the nice property that if the vectors are uniformly distributed over a sphere then $p=0$, no parallelness.
This version is inspired by the mean of circular quantities Is there a general approach and theory behind what I'm trying to do? Is there a 'better' way to measure how parallel a set of vectors are? Motivation:
This question is inspired by numerical computations, where I get a number of vector fields and I need to know if the vector fields are parallel. Of course there will be some error in the computation, and so I need to check if the vector fields exceed some level of parallelness.
However, I am interested in whether there is some general approach to get something like a 'standard deviation of direction' or similar in high dimensional space, an analytical tool to approach this kind of problem. Edit (13/Nov/2017): After considering Raskolnikov's answer, it turns out that I want to first determine whether the vectors are 'parallel' without caring whether they are aligned or anti-aligned, so at this stage $v$ and $-v$ are considered the same, this gives me a 'region' in my vector field. I then want to identify the type of region by comparing all vectors to the first and determining whether they are parallel or anti-parallel. This second step is trivial, it is the first step I am addressing in this question. I therefore update my required properties to be: If $v \in \mathbb{R}^n$ and $\{\lambda_1 , \ldots , \lambda_m \} \subset \mathbb{R}$ then
$$
p(\lambda_1 v , \ldots , \lambda_m v) = 1
$$
since all vectors of the form $\lambda_iv$ are parallel/antiparallel In any other case
$$
p < 1
$$
to indicate that these vectors are not totally parallel/antiparallel","['normed-spaces', 'statistics', 'linear-algebra', 'vector-spaces']"
2514058,Importance of group action in abstract algebra [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question What are the important consequences of group action in abstract algebra? Why the action of a group on a set is defined?","['group-actions', 'abstract-algebra', 'group-theory']"
2514073,Check the differentiability of the function,"Question Check the differentiability of the function f$\left(x,y\right)=\begin{cases}
\frac{2x^{2}y}{x^{2}+y^{2}} & \left(x,y\right)\neq\left(0,0\right)\\
0 & otherwise,
\end{cases}$ My Approach I know a function of two variable is differentiable
at $\left(a,b\right)$ $\Leftrightarrow$
f$\left(a+h,b+k\right)-f\left(a,b\right)=Ah$$+Bk+\phi\left(h,k\right)\sqrt{h^{2}+k^{2}},where$
A=$\frac{\partial f}{\partial x}$ =$f_{x}$=0 ,B=$\frac{\partial f}{\partial y}$=$f_{y}=0$
and $\phi\left(h,k\right)$$\longrightarrow0$ as$\left(h,k\right)\longrightarrow\left(0,0\right)$. $f$$\left(a+h,b+k\right)-f\left(a,b\right)=$$\phi\left(h,k\right)\sqrt{h^{2}+k^{2}}$$\Longrightarrow$$\phi\left(h,k\right)\sqrt{h^{2}+k^{2}}=\frac{2h^{2}k}{h^{2}+k^{2}}$ taking h=rcos$\theta$ and 
 k=rsin$\theta$$\Longrightarrow$$\phi\left(h,k\right)=2cos^{2}\theta$$sin\theta$$\neq$0
$\forall$$\theta$$\Longrightarrow$ $\phi\left(h,k\right)$do not
tend to 0 as$\left(h,k\right)\longrightarrow\left(0,0\right)$.So
function is not differentiable at origin BOOK's Approach A function of two variable is differentiable at
$\left(a,b\right)$ $\Leftrightarrow$f$\left(a+h,b+k\right)-f\left(a,b\right)=Ah$$+Bk+\psi\left(h,k\right)h+\xi\left(h,k\right)k$
(i know this is equivalent to mine rule) $\frac{2h^{2}k}{h^{2}+k^{2}}=$h$\left(\frac{hk}{h^{2}+k^{2}}\right)+k\left(\frac{h^{2}}{h^{2}+k^{2}}\right)$$\Longrightarrow$$\psi\left(h,k\right)=$$\left(\frac{hk}{h^{2}+k^{2}}\right)$and
$\xi\left(h,k\right)$=$\left(\frac{h^{2}}{h^{2}+k^{2}}\right)$ Book says as$\left(h,k\right)\rightarrow\left(0,0\right)$$\psi$and
$\xi$ also go to $0$.So Function is differentiable at origin.Book uses the word h and k tends to zero simultaneously. But,Lim$_{\left(h,k\right)\longrightarrow\left(0,0\right)}\psi\left(h,k\right)$and
Lim$_{\left(h,k\right)\longrightarrow\left(0,0\right)}\xi\left(h,k\right)$
do not exist. Please tell me if book is right , then where i was wrong in my approach.It
would be very helpful if the posted answers use my approach and go
further.","['multivariable-calculus', 'derivatives', 'continuity', 'limits']"
2514081,Question on geodesically convex set,"Let $(X,d)$ be a geodesic metric space (this means that every couple of points in $X$ are joined by a minimizing geodesic) and $C\subset X$ a geodesically convex set (given any couple of points in $C$ the minimizing geodesic joining them is entirely contained in $C$). Is it true that for any point $x\in X\setminus C$ there is always a point $x'\in \partial C$ (the border of $C$) such that $d(x,c)\ge d(x',c)$ for every point $c\in C$?","['general-topology', 'metric-spaces', 'convex-analysis']"
2514108,function ${\displaystyle \varphi }$ such that ${\displaystyle \varphi (\varphi (u))=\exp(u)}$,"Here it's cited: the existence of the holomorphic function ${\displaystyle \varphi }$  such that ${\displaystyle \varphi (\varphi (u))=\exp(u)}$ had been demonstrated in 1950 by Hellmuth Kneser. However I can't find the definition of the function $\varphi(u)$ anywhere. Does this function truly exist? And if so, What is the function?","['exponential-function', 'chain-rule', 'calculus', 'holomorphic-functions', 'tetration']"
2514144,Topologies on topologies,"Let $(X,\tau)$ be a topological space.  Is there anything like ""dual space"" whose points are members of $\tau$?  Would there be a natural way to define the topology on $\tau$?",['general-topology']
2514169,Calculate $E(S_T^2)$.,"Let $Y_1,Y_2,\dots \,$ i.i.d and centered random variables in $L^2$ in the probability space $(\Omega,F,P)$. Let $F_n:=\sigma(Y_1,\dots,Y_n), F_0:=\{\Omega,\emptyset\}$ and $S_0:=0$, $S_n=Y_1+\dots Y_n \,(n=1,2,\dots)$. $\dots$if needed, I have shown that $S_n^2$ is a $F_n$-Submartingale and I have found a previsible process $A_n$ such that $(S_n^2-A_n)$ is a $F_n$-martingale. Let T a $F_n$-stopping time in $L^1$. Calculate $E(S_T^2)$. I started like this, using the submartingale property $$E(S_T^2)=E(E(S_T^2)\mid F_o)\ge E(S_0^2)=0.$$
I am not sure how to continue here. Maybe one can use this $\textbf{theorem}$: 'Let $X$ a $F$-submartingale with $sup_{n\in N_0}E(X_n^+) < \infty$. Then there exists a $F_{\infty}$ measerable integrable random variable $X_{\infty}(\omega)=lim_{n \to \infty}X_n(\omega) \,$a.s.. Furtheremore $E \mid X_{\infty}\mid \le \text{liminf}_{n\to \infty}E\mid X_n\mid$.' I tried to use this theorem and concluded $E(S_T^2)=E(S_{T\land n}^2)$. So actually I do not get anywhere $\dots$ So how should one solve this problem? Any help is much appreciated! P.S. I believe that $E(S_T^2)=0$, but this is just a guess.","['probability-theory', 'martingales', 'stopping-times']"
2514187,Eigenvalues of anti-circulant matrix,"Is there any theorem to find the eigenvalues of any anti-circulant matrix with real entries? 
By anti-circulant matrix, I mean any $n\times n$ matrix  of the form : $$ \begin{pmatrix}a & b & c & d & e & f \\ b & c & d & e & f & a \\ c & d & e & f &  a & b \\ d & e & f & a & b & c \\ e & f & a & b & c & d  \\ f & a & b & c & d & e  \end{pmatrix}$$","['matrices', 'eigenvalues-eigenvectors']"
2514189,Transpose formula to find a value,"Can someone help with this please? Ive differentiated a formula to get a value, now I need to find the positive value for t for when $\frac{dR}{dt} = 0$ So: $0 = (27t^{0.5}    e^{-3t}) + (-54t^{1.5} e^{-3t})$ How would go about finding t here?",['derivatives']
2514236,Is there a generalization of matrices that allows uncountably many entries?,"For example, the matrix could have finitely many rows and columns, but each row/column has uncountably many elements and you can do the standard matrix multiplication by taking care to match up the entries with corresponding pairs of real number indices. Do such objects exist and has there been any work on them? Does",['matrices']
2514245,What is a nice way to prove that : $\frac{t}{t+1} \le 1-e^{-t}\le \frac{2t}{1+t}$,I am trying to prove that for $t>0$$$\frac{t}{t+1} \le 1-e^{-t}\le \frac{2t}{1+t}$$ I know that Simplest or nicest proof that $1+x \le e^x$ taking $$e^{-x} \le \frac{1}{1+x} \implies 1-e^{-x}\ge \frac{x}{x+1}$$ Now I don't know to prove the other inequality.,"['real-analysis', 'inequality', 'exponential-function', 'calculus', 'analysis']"
2514259,How to calculate: $\lim\limits_{z\to \infty} e^{-zt}\sum\limits_{k\le zx} \frac{(zx)^k}{k!} $,"I am trying to compute, for fixed $x,t\in \Bbb R_+$, $$f(x,t)=\lim_{z\to \infty} e^{-zt}\sum_{k\le zx} \frac{(zx)^k}{k!}. $$ My attempt: Since, $$e^x =\sum_{k\ge 0} \frac{x^k}{k!}$$ I said that the formula is $$f(x,t)=\lim_{z\to \infty} e^{-zt}\sum_{k\le zx} \frac{(zx)^k}{k!} = 0 $$
My professor told me that it is wrong. I don't know  how to arrive at this. any help?","['real-analysis', 'limits', 'exponential-function', 'calculus', 'sequences-and-series']"
2514291,Prove that $\cosh(x)=\sec(\theta )$ if $x=\ln(\sec \theta + \tan \theta)$,"I'm trying to prove that $\cosh(x)=\sec(\theta )$ if $x=x=\ln(\sec \theta + \tan \theta)$. I've substituted the value of $x$ into $\cosh(x)$ to get $$\frac{e^{\ln(\sec \theta + \tan \theta)}+e^{-\ln(\sec \theta + \tan \theta)}}{2}$$ and simplified to get $$\frac{(\sec \theta +\tan \theta)+\frac{1}{(\sec \theta + \tan \theta)}}{2}$$. However, I do not know where to continue from here. Help would be greatly appreciated.","['hyperbolic-functions', 'trigonometry']"
2514311,$A:= \{y \in X | f(x) = f(y) \text{ for all measurable } f : X \longrightarrow \mathbb R\}$ is an atom,"My definition of an atom : $A \in \mathcal U$ atom of measurable space ($ X, \mathcal U$) if from $A \supseteq B \in \mathcal U$ it follows that $B=A $ or $B = \emptyset$ Question : For any $x \in X$ it follows that $A:= \{y \in X | f(x) = f(y) \text{ for all measurable } f : X \longrightarrow \mathbb R\}$ is an atom . I already showed that for all measurable $f: X \longrightarrow \mathbb R$ it follows that $f$ is constant on atoms of $X$. Now I have trouble on showing this so any help is appreciated.","['real-analysis', 'measure-theory']"
2514372,Limit of measure of sequence of sets,"Recently in my class there was talk of a sequence of sets $A_1 \supseteq A_2 \supseteq \dots $, where each set has infinite measure. Although I found an example that violated the equality (which was the point of the exercise):
$$\mu(\bigcap_{n=1}^\infty A_n) = \lim_{n \rightarrow \infty}\mu(A_n),$$
namely,
$$ A_n = [n, \infty[, \text{ where } n \in \mathbb{N}^+,$$
I am still a bit puzzled at how I did it. I can see that the measure of the intersection of the sets is  $0$, as can be shown be contradiction (assume it weren't empty, containing a positive real number $r$; but then $r \notin [\lceil{r}\rceil, \infty[$, so it cannot be an intersection of all the sets). Regarding $\lim_{n\rightarrow \infty}\mu(A_n)$, I'm somewhat conflicted: On the one hand, $\forall  \ n \ \mu(A_n) = \infty$. Hence, $\lim_{n \rightarrow \infty} \infty = \infty$ On the other hand, $\lim_{n \rightarrow \infty}A_n = \varnothing$. Hence, $\mu(\lim_{n \rightarrow \infty}A_n) = 0$. So am I right to conclude that in general $\mu(\lim_{n \rightarrow \infty}A_n) \neq \lim_{n\rightarrow \infty}\mu(A_n)$? Why?
Thanks for clarifying these issues.","['real-analysis', 'measure-theory', 'limits']"
2514441,Minimize $\min_{f\in E}\left(\int_0^1f(x) dx\right)$,"Inspired by this question , I pose this following problem. Let $E$ be the set of all nonnegative continuous functions $f:[0,1]\to \mathbb{R}$ such that $$f(x)\,f(y)\ge |x-y|\qquad\forall\{x,y\}\subset [0,1]$$ Find $$\min_{f\in E}\left(\int_0^1f(x) \,dx\right)$$","['real-analysis', 'inequality', 'optimization', 'calculus', 'contest-math']"
2514479,Card combinatorics - two answers,"A hand of $10$ cards is dealt from a standard pack of $52$ cards. How many ways can the hand contain exactly $3$ cards of the same value and the remaining $7$ cards from the remaining suit? I have two answers and one is correct. If so, why is the other incorrect? Answer 1: Choose any possible card in $52$ ways. Fix this card value. There are now 3 remaining cards in that value, and we choose 2 in $\binom{3}2$ ways. The remaining suit is chosen in $\binom{1}1$ ways and we choose $7$ out of this suit in $\binom{12}7$ ways. Total is 123552. Answer 2: Choose a card value in $\binom{13}1$ ways. Fix this card value. We choose 3 out of the 4 in $\binom{4}3$ ways. The remaining suit is now fixed and we choose the remaining 7 cards in $\binom{12}7$ ways. Total is 41184.",['combinatorics']
2514510,"How many solutions are there to $x+y+z=14$ where $x,y,z$ are all non-negative integers, $x \leq 5, y \leq 6, z \leq 7$?","Through using brute force, I have got 15 triplets of solutions. Have I reached the right answer, and how can I not use brute force?","['algebra-precalculus', 'diophantine-equations']"
2514533,"Existence of open and dense subset of $A \subseteq \mathbb R^n$ with measure between $[0,1]$",I am trying to study abit of measure theory. I would appreciate it if someone could explain me step by step on how to deal with this kind of task. Let $A \subseteq \mathbb R^n$ a set with lebesgue measure $1$. How does one show that for any $0 \lt \alpha \lt 1$ there exists an open and dense subset of $A $ with lebesgue measure $\alpha$?,"['lebesgue-measure', 'measure-theory']"
2514538,Inverse gamma sum convergence,"I have been working on the following problem: Assume $X_k$ is a random variable that follows a $\Gamma(3,k)$ distribution. Then $$\sum_{i=1}^n \frac{1}{X_i}-\frac{1}{2} \log n\overset{p}{\to}0$$ Well, I know that the random variable $Y_k=\frac{1}{X_k}$ follows an inverse gamma distribution,and clearly $-\frac{1}{2}\log (n)=\log(n^{-1/2})$ so I am guessing  $\sum_{i=1}^n \frac{1}{X_i}$ can be written in terms of logarithm in some way.... I am wondering if anyone has any other ideas.","['probability-theory', 'convergence-divergence']"
2514552,Is there something wrong with this proof question?,"Question: If $P(x)$ is a predicate using a variable x and $Q$ is a statement that does not contain x, show that $$((\exists x.P(x))\implies Q) \iff (\forall x.(P(x)\implies Q))$$ Does this question make sense? I don't even know where to start because it seems to imply that there is a contradiction by itself: the first statement is that there is only one $x$ but the second statement is that there are all $x$. How can both of this be simultaneously true at the same time? Unless we assume there is only one $x$...which I don't think is what the question gives. Also, what kind of concepts should we use here? The most obvious one I could see is that by taking out the $\exists$ symbol, it becomes a $\forall$ symbol. But I have never seen this concept before. Could the question be set wrongly?","['first-order-logic', 'predicate-logic', 'quantifiers', 'logic', 'discrete-mathematics']"
2514553,Determine $\lim_{a\to 0^+} \int _0 ^{\infty} \dfrac{t^{a-1}}{1+t^4} dt$,"For $a>0$ we define
$$G(a)= \int _0 ^{\infty} \dfrac{t^{a-1}}{1+t^4} dt$$
Determine $\lim_{a\to 0^+} G(a)$ I don't know really know how to approach this problem that I saw in my measure theory course, without using complex analysis, so I would appreciate any hint. Thank you so much!","['real-analysis', 'improper-integrals', 'lebesgue-integral', 'measure-theory']"
2514566,(Complex) angle between vectors in $\mathbb{C}^n$?,"For real vector spaces, the Cauchy-Schwarz inequality $|x\cdot y|\leq\Vert x\Vert \Vert y\Vert$ allows one to define a unique angle $\theta\in[0,\pi]$ between vectors $x$ and $y$ via $\cos^{-1}\frac{x\cdot y}{\Vert x\Vert \Vert y\Vert}$. But the Cauchy-Schwarz inequality is still valid for complex vectors. I was wondering if one can define the ""angle"" between complex vectors by the same inverse cosine formula. $x\cdot y=x^{\ast T} y$ is now complex, so the angle would become complex, but what is the ""principal domain"" of the angle to ensure single-valuedness of the inverse cosine function? Or does such a domain exist at all? I tried analyzing the formula
$$\cos^{-1}z=-i\log[z+i(1-z^2)^{1/2}]$$
without much success.","['complex-analysis', 'trigonometry', 'inverse-function']"
2514567,How do I show this equality for triangular numbers?,"A triangular number is defined as a number $u_{n} = 1 + 2 + 3+ \cdots + n$. Show that there exists a natural number $z$ such that: $$(2x+1)^2 u_y + u_x = u_z$$ Am I supposed to show by observation that there exists such a number $z$ or am I supposed to show that the left side of the equation gives a formula similar to a triangular number? But could the left side of the equation even be a triangular number with two variables instead of one? If this cannot be done, then how can I observe that one number that proves this statement?","['proof-explanation', 'proof-verification', 'discrete-mathematics']"
2514577,Grassmanian of k-plane in R^n,"I am reading the script http://www3.math.tu-berlin.de/geometrie/Lehre/WS16/DGII/script.pdf and I want to prove exercise 9 where you need to show that $G_1(\Bbb R^3) \subset sym(3)$ is a submanifold diffeomorphic to $ \Bbb RP^2 $. The Grassmanian of k-plane in $ R^n $ is defined as follows $ G_k(\Bbb R^n):= \{ p\in \Bbb R^{n \times n}|p^*=p , p^2=p, tr(p)=k \}$ and there is a theorem that says $ G_k(\Bbb R^n)$ is a submanifold of $\Bbb R^{n \times n}$ of dimension $k(n-k)$. I don't really see how I can show it's a submanifold of $sym(3)$ and how it's diffeomorphic to $\Bbb RP^2$ .","['differential-geometry', 'differential-topology']"
2514579,Intuition for Möbius function on a poset,"I am attempting to learn about Möbius inversion in the context of partial order theory. However, I'm hitting a bit of a mental block when it comes to understanding the Möbius function, and I'm looking for a clearer understanding of the motivation and intuition behind it. Rota , for example, defines the function inductively as follows:
$$
\mu(x,x)=1
$$
$$
\mu(x,y) = -\sum_{x\le z<y} \mu(x,z)
$$
but then says ""clearly $\mu$ is an inverse of $\zeta$"". Unfortunately it's far from clear to me! The definition doesn't seem to give me any intuition for what this function is, how I should expect it to behave, or even really how to do algebra with it. I've tried tabulating all the values of $\mu$ for a few small lattices, and I can verify that it is indeed an inverse of $\zeta$ in those cases, but it hasn't been very enlightening - I haven't been able to discern any meaning in the numbers it assigns. In short, my question is, what is the Möbius function? How should I think about what it's doing, and how can I see its fundamental properties? A note about my background: I'm working on applications in probability theory and information theory and I have zero knowledge of number theory --- so motivations and analogies from that direction won't help me, unless they can be explained starting from a novice level. Edit: it's now clear to me that $\mu$ is indeed an inverse of $\zeta$. It helped to realise that for finite posets we can write these functions as matrices, in which case convolution is matrix multiplication and $\mu$ is the matrix inverse of $\zeta$. However, I'm still looking for a good explanation of what $\mu$ ""really is"", other than a convenient algebraic tool. I suspect this question has an answer, because if my poset is a family of sets with the partial order relation being set inclusion, then $\mu$ seems to be saying something about which things you have to subtract off to avoid double-counting. (i.e. the inclusion-exclusion principle.) It's this intuition that I'd like to get a firmer handle on, particularly when it comes to general posets where the order relation is not set inclusion.","['mobius-inversion', 'combinatorics', 'lattice-orders', 'order-theory']"
2514584,Can the difference of 2 undefined limits be defined?,"Is this limit defined or undefined?
$$\lim\limits_{x \to 0+} \left(\sqrt{\frac{1}{x}+2}-\sqrt{\frac{1}{x}}\right)$$
When I apply the rule of difference of limits, it's undefined. But, when I manipulate it, it gives me zero. And the graph of the function indicates it's defined on the right side. By multiplying by $\frac{\sqrt{\frac{1}{x}+2}+\sqrt{\frac{1}{x}}}{\sqrt{\frac{1}{x}+2}+\sqrt{\frac{1}{x}}}$:
$$\lim\limits_{x \to 0+} \frac{\left( \sqrt{\frac{1}{x}+2}-\sqrt{\frac{1}{x}} \, \right) \left(\sqrt{\frac{1}{x}+2}+\sqrt{\frac{1}{x}} \, \right)}{\sqrt{\frac{1}{x}+2}+\sqrt{\frac{1}{x}}}$$ $$=\lim\limits_{x \to 0+} \frac{\frac{1}{x}+2-\frac{1}{x}}{\sqrt{\frac{1}{x}+2}+\sqrt{\frac{1}{x}}}$$
$$=\lim\limits_{x \to 0+} \frac{2}{\sqrt{\frac{1}{x}+2}+\sqrt{\frac{1}{x}}}$$
Then, we multiply by $\frac{\sqrt{x}}{\sqrt{x}}$:
$$=\lim\limits_{x \to 0} \frac{2\sqrt{x}}{\sqrt{1+2x}+1}$$
And, we substitute:
$$=\frac{2\sqrt{0}}{\sqrt{1+2\times0}+1} = 0$$
So, is this limit defined or not? and what's my error, if any?","['calculus', 'limits']"
2514602,Limit of non-negative real root of $x^n+x^{n-1}+x-1=0$ as $n \to \infty$,Let $x_n$ be the unique non-negative real solution of a equation $x^n+x^{n-1}+x-1=0$. Prove the sequence {$x_n$} is increasing and converges to 1. I found out that $ 0 < x_n < 1$ but just that..,"['real-analysis', 'sequences-and-series', 'limits']"
2514617,quotient set A/R if R is an euqivalence relation on A A/R is a partition of A,"I am struggeling with figuring out how to stat with this proof. I understand how to go about this if I need to prove that R is a partition of A. But the quotient set is confusing me. Prove that: 
IF $R$ is an equivalence relation on set $A$. Then A modulo R,
$A/R = \{[x]_R|x\in A\}$, is a partition of A. Any hints on how to get started would be appreciated!","['relations', 'elementary-set-theory']"
2514643,Statistics for $N$ in sum of cubes $a^3+b^3+c^3 = N^3$?,"Q: What is the percentage of $n$ up to a bound $N$ such that,
  $$a^3+b^3+c^3 = n^3\tag1$$
  has a solution in positive integers? The sequence A023042 shows a large percentage. I have extended that to $N=10000$, $$\begin{array}{|c|c|}
\hline
N&\text{%}\\
\hline
2000&85.8\text{%}\\
4000&89.8\text{%}\\
6000&92.1\text{%}\\
8000&93.3\text{%}\\
10000&94.2\text{%}\\
\hline
\end{array}$$ This means that $94\text{%}$ of all positive integers $N<10000$ has a solution to $(1)$. How high does the percentage go? From the trends, can one assume that it may reach $97,98,\,\text{or}\;99\text{%}$ if we go up the millions to $N=1000000$?","['number-theory', 'experimental-mathematics', 'diophantine-equations']"
2514653,Why two derivatives do not match,"Let $$
\begin{align}
u = \begin{cases}
\sqrt{r} \cosh(t) & \text{if } r\gt 0\\
\sqrt{-r} \sinh(t) & \text{if } r \lt 0\\
\end{cases}
\end{align} \tag 1 $$
and
$$  
\begin{align}
 v = \begin{cases}
\sqrt{r} \sinh(t) & \text{if } r\gt 0\\
\sqrt{-r} \cosh(t) & \text{if } r \lt 0\\
\end{cases}
\end{align} \tag 2
$$ Combining both $(1)$ and $(2)$ and using $\cosh^2-\sinh^2=1$, $ u^2 - v^2=r \tag 3$
Using $(1)$, $$\frac{\partial{u}}{\partial{r}}=\frac{\cosh(t)}{2\sqrt{r}} \text{ if } r\gt 0 \quad \lor \quad  -\frac{\sinh(t)}{2\sqrt{-r}} \text{ if } r\lt 0$$ However, using $(3)$, 
$$ \frac{\partial{u}}{\partial{r}}= \frac{1}{2u} = \frac{1}{2\sqrt{r}\cosh(t)}\text{ if } r\gt 0 \quad \lor \quad \frac{1}{2\sqrt{-r}\sinh(t)}\text{ if } r\lt 0$$ Why don't both of the derivatives of $\frac{\partial{u}}{\partial{r}}$ match? What did I do wrong?","['derivatives', 'partial-derivative', 'implicit-differentiation']"
2514701,Ricci tensor of the Grassmannian manifold,"I'm wondering if anyone could help me with calculating the Ricci tensor for the Grassmannian manifold. For Kähler manifolds we have:
\begin{equation}
    R_{\mu \bar{\nu}} = -\partial_{\bar{\nu}} \partial_{\mu} \log \det g_{\mu\bar{\nu}}
\end{equation} For the Grassmannian, we are using the two-index notation
\begin{equation}
\Phi^{n\alpha} \quad,\qquad \text{where} \quad n=1\ldots N,\quad \alpha=1\ldots M
\end{equation}
And so, the Ricci tensor will have four indices, $R_{i\bar{j}\alpha\bar{\beta}}$. The Kähler potential is given by:
\begin{equation}
    K = \operatorname{Tr} \ln (\delta^{n\bar{m}} + \Phi^{n\gamma}\overline{\Phi}^{\bar{\gamma} \bar{m}})
\end{equation}
Here we take the trace over the Latin indices, but we could also define $K = \operatorname{Tr} \ln (\delta^{\alpha\bar{\beta}} + \Phi^{n\alpha}\overline{\Phi}^{\bar{\beta}\bar{n}})$ and take the trace with respect to the Greek indices. The subscripts are reserved for lowering with the aid of the metric tensor. The latter is obtained as follows:
\begin{gather}
    G_{i\bar{j} \alpha \bar{\beta}}
    =
    \dfrac{\partial}{\partial \Phi^{i\alpha}}
    \dfrac{\partial}{\partial \overline{\Phi}^{\bar{\beta}\bar{j}}}
    K
    = \operatorname{Tr} \left\{
    \delta^{ni}\delta^{\alpha\bar{\beta}}(A^{-1})^{\bar{j} m}
     - \Phi^{n\beta}
    (A^{-1})^{\bar{j} i}
    \overline{\Phi}^{\bar{\alpha} \bar{l}}
    (A^{-1})^{\bar{l} m}
    \right\}
\end{gather} How should I proceed from here? I guess, the answer should be
\begin{equation}
    R_{i\bar{j}\alpha\bar{\beta}} \propto (M+N)G_{i\bar{j}\alpha\bar{\beta}}
\end{equation}","['grassmannian', 'riemannian-geometry', 'differential-geometry', 'curvature']"
2514721,"If the summation of $\frac{1}{^nC_r}$ is $a_n$, find the summation of $\frac{r}{^nC_r}$ in terms of $a_n$","My attempt to solve this question: Write $a_n=\Sigma^n_{r=0}\frac{1}{^nC_r}$ as => $a_n=\frac{1}{^nC_0}+\frac{x}{^nC_1}+\frac{x^2}{^nC_2}...+\frac{x^n}{^nC_n}$ Differentiate $a_n$ with respect to x, obtaining: $a_n=\frac{1}{^nC_1}+\frac{2x}{^nC_2}+\frac{3x^2}{^nC_3}...+\frac{nx^{n-1}}{^nC_n}$ Replace $x=1$ in $\frac{d(a_n)}{dx}$, but now I don't have $a_n$ as a function of x. So I guess my basic question is which binomial expansion has $^nC_r$ in the denominator, which I can use to write $a_n$ as a function of x?","['derivatives', 'binomial-theorem', 'binomial-coefficients']"
2514733,Find examples of $f$ such that $f'$ is a probability density function,"Let $f$ be a probability density function with a continuous derivative on $[1,+\infty)$. I know that the conditions for a function to be probability density is as follows (a) $f(x)\geq0$ for all $x\in\mathbb{R}$ (b) $\int_{-\infty}^{+\infty}f(x)dx=1$ Now I want to find examples of $f$ such that $f'$ is a probability density function. Is there exist any way to do this?","['probability-theory', 'probability', 'statistics']"
2514744,one to one correspondance between points on the number axis and real numbers,"My question is arose by the three statements: An interval could be thought of as a line segment on the number axis
according to this book . I think it is true that every line segment has two end points. The Cantor-Dedekind axiom : The points on a line can be put into a one-to-one correspondence with
  the real numbers. so the unit interval [0,1] corresponds to a line segment AB on the number axis with its end points corresponding to real numbers 0 and 1 respectively , (0,1) is an interval different from [0,1], so I think it must correspond  to a line segment CD on the number axis different from AB, CD must have two end points different from the end points of AB, so what are the real numbers the two end points of CD respectively corresponding to ? Can we name them using some symbolic notations? Is there something wrong with my reasoning here ?","['real-analysis', 'calculus']"
2514761,How is the Dirac function different from the indicator function,My question is straightforward though I cant find an answer online. What is the difference between an indicator function and a Dirac function?,"['elementary-functions', 'calculus']"
2514778,Toeplitz Theorem.,"Theorem: Let $a_n$ be a real sequence convergent to $a \in \mathbb{R}$. Let
  $c_{k,n}$ (where $1\le k \le n$) be a sequence such that: $$\quad \forall k \lim_{n \to \infty}c_{k,n} = 0$$ $$\quad \lim_{n \to
> \infty} \sum_{k=1}^n c_{k,n} = 1$$ $$\quad \exists M>0 : \forall n\ \
> \sum_{k=1}^n |c_{k,n}| \le M$$ Then $\lim_{n \to \infty}s_n =a$, where $$s_n \equiv \sum_{k=1}^n
 c_{k,n} \cdot a_k.$$ The author of my textbook begins by observing that if $a_n$ is a constant sequence then $$s_n=a\sum_{k=1}^n
 c_{k,n}$$ implying that $\lim_{n\to \infty}s_n=a.$ He then remarks that it is enough to consider the case when the sequence is equal to zero. I don't understand the reasoning behind this argument and would, therefore, be grateful if someone could explain this step in the proof. Here is the complete proof by the way.",['real-analysis']
2514789,"Find the integral $\int_{0}^{1} f(x)dx$ for $f(x)+f(1-{1\over x})=\arctan x\,,\quad \forall \,x\neq 0$.","Suppose that $f:\mathbb{R}\rightarrow\mathbb{R}$ such that
$$f(x)+f\left(1-{1\over x}\right)=\arctan x\,,\quad \forall \,x\neq 0$$
Find $$\int_{0}^1 f(x)\,dx$$
My Attempt : Replace $x$ by $1/x$ in given equation $$f\left({1\over x}\right)+f(1-x)=\arctan {1\over x}$$Add both equations 
$$f(x)+f\left(1-{1\over x}\right)+f\left({1\over x}\right)+f(1-{x})=\arctan x\,+\arctan {1\over x}$$Rearranging thenm gives
$$f(x)+f(1-x)+f\left({1\over x}\right)+f\left(1-{1\over x}\right)={\pi\over2}$$Now it seems to me that $f(x)=f\left({1\over x}\right)$ Am I correct here? (I don't have proof though)
$$f(x)+f(1-x)={\pi\over 4}$$ $$\int_0^1 f(x)\,dx =\int_0^1f(1-x)\, dx={\pi\over 8}$$
I'm not sure about my assumption. Thank you","['integration', 'calculus', 'functional-equations']"
2514872,A rarely seen form of substitution of definitite integral theorem: $\int_\alpha^\beta f(u(t))dt=\int_{u(\alpha)}^{u(\beta)}f(x)\cdot(u^{-1})'(x)dx$,"Below is a theorem about substitution of definite integral that I found today. However, I had never seen this form in analysis books. How to understand its meaning and usage? Is it really made used in practice? The characters for $u^{-1}$, $f(u(t))$ is messy to me. (Though I know the classic form of such theorem.) Let $J=[\alpha,\beta],~u:J\to\Bbb R$ be a $C^1$ function and
  $u'(x)\neq 0$ for all $x\in J$, $I$ be an interval and
  $u(J)\subseteq I$, $f:I\to\Bbb R$ be continuous. Then
  $$\int_\alpha^\beta f(u(t))dt=\int_{u(\alpha)}^{u(\beta)}f(x)\cdot(u^{-1})'(x)dx$$ Edit: We are looking for explicitly examples where this method is usefully for computing integrals.","['real-analysis', 'analysis', 'riemann-integration']"
2514879,Sufficient condition for measure convergence on the Borel set of $\mathbb{R}^d$,"This question follows a previous one : Let $(\mu_n)_{n\geqslant 1}$ and $\mu$ be $\sigma$-finite measures on $(\mathbb{R}^d,\mathscr{B}(\mathbb{R}^d))$ such that $\forall n\geqslant 1$, $\mu_n(\mathbb{R}^d)\leqslant 1$ and $\mu(\mathbb{R}^d)\leqslant 1$. Let $\lambda$ denote the Lebesgue measure on $\mathbb{R}^d$. Suppose that
  $$\forall n\geqslant 1\quad\exists g_n\in\mathbb{L}_1(\lambda)\quad\forall A\in\mathscr{B}(\mathbb{R}^d)\quad\mu_n(A)=\int_Ag_n\,\mathrm{d}\lambda\tag{1}$$
  and
  $$\exists g\in\mathbb{L}_1(\lambda)\quad\forall A\in\mathscr{B}(\mathbb{R}^d)\quad\mu(A)=\int_Ag\,\mathrm{d}\lambda.\tag{2}$$
  Is it true that, if $$g_n\xrightarrow[n\to+\infty]{}g\qquad \text{$\lambda$-a.e.}\tag{3}$$ and $$\int_{\mathbb{R}^d}g_n\,\mathrm{d}\mu_n\xrightarrow[n\to+\infty]{}\int_{\mathbb{R}^d}g\,\mathrm{d}\mu\tag{4},$$ then
  $$\sup_{A\in\mathscr{B}(\mathbb{R}^d)}|\mu_n(A)-\mu(A)|\xrightarrow[n\to+\infty]{}0~?\tag{5}$$
  And if it is, how does one establish this result ? If I replace (4) by $$\int_{\mathbb{R}^d}g_n\,\mathrm{d}\lambda\xrightarrow[n\to+\infty]{}\int_{\mathbb{R}^d}g\,\mathrm{d}\lambda\tag{4'},$$ does the result hold ? And if it does, how to prove it ?","['real-analysis', 'integration', 'measure-theory']"
2514902,"Find the number of real roots for $x+\sqrt{a^2-x^2}=b$, $a>0$, $b>0$, as a function of $a$ and $b$","Given: (1) $x+\sqrt{a^2-x^2}=b$ , $(a,b,x)\subset \mathbb R$ , $a>0$ , $b>0$ . Find: number of roots for (1), given possible values for $a$ and $b$ . This is a question from a book for the preparation for math contests. It states as final answer: (a) 1 root if $b<a$ ; and (b) 2 roots if $a<b<a\sqrt{2}$ . I'm having difficulties on finding this answer. I don't know whether it is correct or perhaps I'm not finding the right approach. I started moving $x$ in (1) to the left, to get $$\sqrt{a^2-x^2}=b-x$$ Before proceeding with squaring both sides, I saved 2 needed conditions for checking the final solution (c1) $a^2-x^2\ge 0$ and (c2) $b-x\ge 0$ . Then squaring both sides, we get: $$a^2-x^2=b^2+x^2-2bx\Leftrightarrow 2x^2-2bx+(b^2-a^2)=0$$ with discriminant $\triangle$ defined by: $$\triangle=4(2a^2-b^2)$$ From this it is easy to see that a condition for 2 roots is (c3) $\sqrt{2}a>b,$ and for 1 root is (c4) $\sqrt{2}a=b,$ as $a>0$ and $b>0$ . Then I find the roots as $$x=\frac{2b\pm \sqrt{\triangle}}{4}=\frac{b\pm \sqrt{2a^2-b^2}}{2}$$ From this point, I can't see a way to reach the stated answer, if it is right. Full solutions or helpful hints are welcome. Sorry if it is a duplicate.","['algebra-precalculus', 'contest-math']"
2514932,Martingale representation theorem discrete,"Let $X_1,X_2,...$ be an iid sequence of random variables such that $P(X_i=1)=p$, $P(X_i=0)=1-p$, defined on a probability space $(\Omega, \mathcal{F}, P)$. Take $\mathcal{F}_0$ to be be the trivial $\sigma$- algebra and let $\mathcal{F_n}=\sigma(X_1,...,X_n)$. Suppose that $M$ is a martingale adapted to this filtration. Show that there exists a constant $m$ and a predictable process $Y$ such that $M_n=m+\sum_{k=1}^nY_k(X_k-p)$. The things I have thought of so far is that since $\mathcal{F}_0$ is the trivial $\sigma$-algebra, $M_0$ is a constant. Therefore we should take $m=M_0$. For any predictable process $Y$, $m+\sum_{k=1}^nY_k(X_k-p)$ is also a martingale because the $X_i$ form an independent sequence. It seems then that $M_1$ can take on only two distinct values since it is $\mathcal{F_1}$-measurable.. I do not know how to proceed and what to take for the predictable process $Y$. Could anyone give me a hint?","['martingales', 'probability-theory', 'measure-theory']"
2514966,Prove that $\lim_{n\to \infty}S_n = \infty$,"Let $(x_n),(y_n)$ be two sequences of positive real numbers, with $x_n \to \infty$ and $$S_n=\frac{x_n}{x_n+y_1}+\frac{x_n}{2x_n+y_2}+\dots+\frac{x_n}{nx_n+y_n}$$
  Prove that $\lim_{n\to \infty}S_n = \infty$ I tried to write the given sum as $S_n=x_n \left(\frac{1}{x_n+y_1}+\frac{1}{2\left(x_n+\frac{y_2}{2}\right)}+\dots+\frac{1}{n\left(x_n+\frac{y_n}{n}\right)} \right)$ and managed to prove the claim when $\left(\frac{y_n}{n}\right)$ is bounded. For the case when it is unbounded, I tried to use the sequence $a_n=\max \{\frac{y_1}{1}, \dots , \frac{y_n}{n} \}$, for which $a_n \to \infty$, in order to get $S_n \geq \frac{x_n}{x_n+a_n}\left(1+\frac{1}{2}+\dots+\frac{1}{n} \right)$, but I couldn't finish. Also, I tried writing the sum as $S_n=\frac{1}{1+\frac{y_1}{x_n}}+\frac{1}{2+\frac{y_2}{x_n}}+\dots+\frac{1}{n+\frac{y_n}{x_n}}$, but nothing came out of it...","['real-analysis', 'limits', 'sequences-and-series', 'calculus', 'convergence-divergence']"
2515008,Generalized version of L’Hospital’s rule?,"I was wondering if the following inequalities are true:$\liminf_{x \to c} \frac{f'(x)}{g'(x)} \leq \liminf_{x \to c} \frac{f(x)}{g(x)} \leq \limsup_{x \to c} \frac{f(x)}{g(x)} \leq \limsup_{x \to c} \frac{f'(x)}{g'(x)}$ under some conditions on $f$ and $g$. Under assumptions for L'Hospital's rule, if $\lim_{x \to c} \frac{f'(x)}{g'(x)}$ exists, then the above inequalities imply the conclusion of L'Hospital's rule. I think the above inequalities are the generalized version of L'Hospital's rule if they are right. Is it true? Would you give me any comment about it? Thanks in advance.","['real-analysis', 'calculus', 'analysis']"
2515012,Expectation of the product of two discrete random variables.,"Let $X_i, X_j$ be two random variables that can each assume the values $\zeta_1, ..., \zeta_m$. Then my book claims $E(X_iX_j) = \sum_{k = 1}^m\sum_{l = 1}^m\zeta_k\zeta_lP(X_i = \zeta_k \textrm{ and } X_j = \zeta_l$). I don't get how they acquired this result. To my understanding $E(X_iX_j) = \sum_{k = 1}^m\sum_{l = 1}^m\zeta_k\zeta_lP(X_i
X_j = \zeta_k\zeta_l)$. So why is $P(X_iX_j = \zeta_k\zeta_l) = (X_i = \zeta_k \textrm{ and } X_j = \zeta_l)$?",['probability']
2515048,How close are solutions of systems of homogeneous linear inequalities with close coefficients?,"Suppose I have two systems of $n$ homogeneous inequalities of $k$ variables: 
$$Ax \geq 0$$
and 
$$Bz \geq 0,$$
where both $A$ and $B$ are $n \times k$ matrices such that for any $i=1, \ldots, n$, and $j=1, \ldots, k$, we have $|a_{ij}-b_{ij}|\leq \epsilon$, where $\epsilon>0$ is very small. Can I conclude from here that there is some distance $\phi(\epsilon)$ (such that $\phi(\epsilon) \rightarrow 0$ as $\epsilon \rightarrow 0$) with the following property: for any solution $x_0$ to the first system with $\|x_0\|=1$ there is a solution $z_0$ to the second system such that 
$$\|x_0-z_0\|\leq \phi(\epsilon)$$ 
for some norm $\|\cdot\|$ in $\mathbb{R}^k$? I am interested in the form (or approximation) of such $\phi(\epsilon)$. EDIT. I am interested in situations when both systems have non-trivial (non-zero) solutions. I would be even willing to assume that both solution sets have non-empty interiors if this would help.","['inequality', 'linear-algebra', 'linear-programming']"
2515053,$(X_n) $ a $\{F_n \}$ martingale that a.s. converges. Does this imply $\sup_n E (X_n^+) < \infty$?,"Let $(X_n) $ a $\{F_n \}$ martingale that a.s. converges. Does this imply  $\sup_n E (X_n^+) < \infty$? The other way round this statement is true (MCT). I tried to construct a counter example like symmetric random walk in combination with a well constructed stopping time, but that does not work. 
An example is highly appreciated!","['martingales', 'probability-theory', 'examples-counterexamples', 'convergence-divergence']"
2515137,Prove directly from the definition that $({1\over2}+\frac{1}{2^2}+...+\frac{1}{2^n})_n $ is Cauchy,"Prove directly from the definition that $({1\over2}+\frac{1}{2^2}+...+\frac{1}{2^n})_n$ is cauchy
I know from the definition of Cauchy that |$x_n$-$x_m$|< ϵ but how do you do this with |$\frac{1}{2^n}- \frac{1}{2^m}$| what I've tried:
if $n\gt m$ then
$$ |\frac{1}{2^n}- \frac{1}{2^m}| \le |\frac{2^m-2^n}{2^n2^m}| \le |\frac{2^m +2^n}{2^{n+m}}| \le \frac{2^n+2^n}{2^{2n}}= \frac{1}{2^{n-1}}     \le \frac{1}{2^{N-1}} \le \epsilon   $$ and rearrange to get N $ \ge 1+ \frac{ln(\epsilon)}{ln(2)}$
is this correct?","['real-analysis', 'cauchy-sequences', 'analysis']"
2515166,Find a continuous solution to dy/dx + y = f(x),"Find a continuous solution satisfying:
  $$
\frac{dy}{dx} +y= f(x)
$$
  Where
  $$ 
f(x) =  \begin{cases} 1  &\text{ for } 0 < x < 1, \\
0 & \text{ for } x > 1 \end{cases} 
$$ 
  with the initial condition $y(0)=0$. I'm not sure what the best way to approach this question is. 
I thought I could solve it using Fourier series which gave me the particular solution of: $$f(x) = -\frac12 + \sum_{n=1}^{\infty}\left[-\frac{1}{n\pi} + \frac{1}{n\pi} (-1)^n \right] \sin (n\pi x) $$ Then I found the complementary function $y = e^{-x}$ Is this correct?
If so, I'm not sure what the full general solution would be, or if this is even a 'continuous solution'.","['continuity', 'fourier-series', 'ordinary-differential-equations', 'fourier-analysis']"
2515214,Is the space of periodic real sequences a closed subspace of the bounded real sequences?,"Let $E$ be the set of bounded real sequences equipped with the following norm: $$||(a_n)_{n \in \mathbb{N}}||_{\infty}=\sup_{n \in \mathbb{N}}|a_n|$$ Let $P$ be the set of real periodic sequences, which is a subspace of $E$. Is $P$ is closed in $E$? I suspect the answer is yes. I tried of a good while to construct a counterexample but failed. Edit: what I tried... Suppose $(s_n)_{n \in \mathbb{N}}$ is a sequence of elements of $P$ with limit $a$ in $E$, and let $p_n$ denotes the period of $s_n$. If $(p_n)_{n \in \mathbb{N}}$ is bounded then there is some number $p$ and a subsequence of $(s_n)_{n \in \mathbb{N}}$ in which each term is a sequence of period $p$, which implies $s$ has period $p$. To find a counterexample we would thus need $(p_n)$ unbounded and, assuming without loss of generality that $(p_n)$ is increasing, we would even need $p_{n+1}-p_n$ to be unbounded. Finally the limit sequence $a$ would need to satisfy for all $k$ and $m$: $a_{k+mp_n} \to a_{k}$  as $n$ tends to infinity. Already constructing such a limit sequence $a$ is far from obvious!","['general-topology', 'sequences-and-series', 'linear-algebra']"
2515218,Spotting a pattern for the $n-th$ derivative,"I have a function $y=\sqrt{\frac {x+1}{1-x}}$ and I am trying to find a pattern for the $n-th$ derivative, I have so far found this: $y'={1\over (x-1)^2({\frac {x+1}{1-x}})^{1/2}}$ $y''={2x+1\over (x-1)^4{(\frac {x+1}{1-x})}^{3/2}}$ $y'''= {3(2x^2+2x+1)\over (x-1)^6{(\frac {x+1}{1-x})}^{5/2}}$ I can see a pattern forming on the denominator but I can't seem to find a pattern on the numerator that I can express in terms of $n$. Any ideas?",['ordinary-differential-equations']
2515226,Exit Time of an Interval Brownian Motion - Distribution,"Let $W_t$ be a Brownian motion, fix $a<0<b$ and let $\tau_x=\mathrm{inf}(t\ge0:W_t=x)$. Show there is an $\alpha<1$: $P(\tau_a \wedge \tau_b>n )\le \alpha^n$ for all $n \in \mathbb{N}$. Proof-Idea: Use the distribution of the min and max of the brownian motion and their independence, pray and find an estimate: $$
\begin{eqnarray}
P(\tau_a \wedge \tau_b>n ) &=& (1-P(\tau_a\le n ))(1-P(\tau_b\le n))\\
&=&(1-\Phi(\frac{-a}{\sqrt{n}})(1-\Phi(\frac{b}{\sqrt{n}})\\
\end{eqnarray}
$$ But i am not able to find an estimation such that this expression is dominated be $\alpha^n$.","['stochastic-processes', 'brownian-motion', 'probability', 'stochastic-calculus']"
2515240,Book reference for Double/ triple integrals,"Can someone please suggest me a Calculus book that includes Double integrals, triple integrals, volume bounded between two curves, line integrals and surface inetgrals? I am looking for a book with plenty of examples and with geometrical approach. Thanks","['multivariable-calculus', 'reference-request', 'book-recommendation', 'calculus']"
2515315,Prove: the union of all n-tuples is countable,"Prove: $\mathbb N^*=\bigcup_{n\in \mathbb N} \mathbb N^n$ is countable. My idea is to show this for $\mathbb N^2$ first, which is not difficult. After this I say, that every tuple, could be reduced to a 2-tuple: $(n_1,n_2,n_3,n_4) \mapsto ((n_1,n_2),n_3,n_4)$, $((n_1,n_2),n_3,n_4) \mapsto (((n_1,n_2),n_3),n_4)$ and so on. Can I do this? If yes, is it formally correct? If not, does someone has hints?","['real-analysis', 'elementary-set-theory']"
2515396,Suspension of a circle is a sphere,"Define the suspension of a topological space as 
$$SX=S\times I/\sim$$
where $\sim$ is the relation that identifies points of the form $(x,0)$ with one point and the ones of the form $(x,1)$ with another. When taking $X=S^1$, $SS^1$ looks like two cones glued by the unit cicle on the $XY$ plane (the Wikipedia article has a more illustrative pictur). The resulting space looks already homeomorphic to the sphere and I thought there might be a nice proof involving just the planar representation of compact surfaces, in this case the cylinder, so here is my try: Identify $S^1\times I$ as the unit square with the vertical sides identified. Now the equivalence relation results on colapsing the boundary of the cylinder (to copies of $S^1$). In the planar model that should mean that the horizontal sides collapse into one point each, so that is just the unit disk $D^2$ with its boundary $\partial D^2=S^1$ identified with a single point. Since $D^2/S^1 \cong S^2$, then $SS^1\cong S^2$. Does this work, or am I missing something? Also, is there another proof of this result? And is this generalizable to more dimensions? Thank you in advance.","['alternative-proof', 'proof-verification', 'algebraic-topology', 'general-topology', 'quotient-spaces']"
2515427,Finitely generated R-module,"Let $R$ be an integral domain and also Noetherian ring. Let $f$ be an element in Quot$R$ (field of fractions of $R$). Let $R[f]$ be the subring of Quot$R$ generated by $R$ and $ \{ f \}$. Let suppose that $R[f] \subseteq M$ where $M$ is an $R$-submodule of Quot$R$ and $M$ is finitely generated as $R$-module. Is it true that $R[f]$ is also finitely generated as $R$-module? If is it true, can you give me a rigorous and possibly elementary proof?","['modules', 'algebraic-geometry', 'abstract-algebra', 'ring-theory', 'commutative-algebra']"
2515435,What is wrong with this naive approach to Hilbert's 10th problem?,"Background: I have been studying some decidability results in number theory. In doing so, I have always assumed there was no need for me to study pedantic definitions of decidability using Turing machines or similar, since the naive idea of an algorithm ('something which you could program a computer to do') seemed to be enough to understand most proofs. I now notice that this intuitive understanding might lead me to false conclusions. /Background Consider the following problem: to find an algorithm which - on input a polynomial with coefficients in $\mathbb{Z}$ and an arbitrary number of variables - outputs YES if and only if the polynomial has an integer root, NO otherwise (Hilbert's 10th problem). By a theorem of Matiyasevich, this problem is unsolvable, in that such an algorithm does not exist. The following naive approach of mine would imply that such an algorithm does exist: Clearly if a polynomial $f \in \mathbb{Z}[X_1, \ldots, X_n]$ has a root $\bar{z} = (z_1, \ldots, z_n) \in \mathbb{Z}^n$ then there is a proof for this in the theory of arithmetic (axiomitized by the Peano axioms, for example). Indeed: just calculate $f(\bar{z})$ and note that this equates to zero. It follows by Gödel's Completeness Theorem that also if $f$ has no root in $\mathbb{Z}^n$, there is a proof of this fact in the first-order theory of arithmetic. Given a finite sequence of symbols from the language of arithmetic (logical symbols, $+, -, \cdot, 0, 1$ and a symbol $\downarrow$ indicating that a new line should begin), there exists an algorithm which checks whether this sequence is a valid proof in the theory of arithmetic. The number of finite sequences of symbols in the language of arithmetic is countable. Even stronger: a bijection $\varphi$ from $\mathbb{N}$ to this set can be constructed explicitly as the number of symbols is finite, so we can just list all sequences with only 1 symbol, then all sequences with 2 symbols and so on. Now define the following algorithm: for $m = 1,2,3, \ldots$, verify whether $\varphi(m)$ is a valid proof. If so, check if the last line spells ""$f$ has a root in $\mathbb{Z}^n$"" or ""$f$ has no root in $\mathbb{Z}^n$. If so, output YES or NO accordingly. If not, continue with $m+1$ instead of $m$. By my first point, the above algorithm always terminates. Where did I make a mistake, i.e. what part of my argument violates the strict definition of what an algorithm is? Unless I am overlooking something, it seems like something I could make a computer do if my programming skills would allow it.","['first-order-logic', 'proof-verification', 'number-theory', 'logic', 'decidability']"
2515476,Von Neumann's Trace Inequality for Multiple Matrices,"Von Neumann's trace inequality states that $|tr(AB)| \le \sum_{i=1}^{n} \sigma_i(A) \sigma_i(B)$ where $A, B$ are general square matrices with singular values $(\sigma_i(A)), (\sigma_i(B))$, respectively. Question : does the analogous inequality hold for 3 (or more) matrices? Related : If it were true, I would expect to find this generalization elsewhere. However, it seems to be proven in a slightly different form in Theorem 2 of [Kristof 69] . When checking the reference, note (1) that $\lambda_i(A A^*) = \sigma_i(A)^2$ and (2) that $tr(ABC) \le tr(Z_1 diag(\sigma(A)) Z_2 diag(\sigma(B)) Z_3 diag(\sigma(C)))$ where $Z_i$ are unitary. The second claim can be easily argued via SVD and trace cycling. I would like somebody more knowledgable to point out my mistake to me. I haven't checked the proof in the paper.","['matrices', 'trace', 'inequality']"
