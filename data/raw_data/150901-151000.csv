question_id,title,body,tags
2515479,"If $K$ is an algebraically closed field and $F \in K[X, Y]$ is irreducible, then $\dim K[X, Y]/(F) = 1$","$\newcommand{\trianglelefteqslant}{\leqslant \hskip{-7.8pt} \raise{0.9pt}\vartriangleleft}$
Let $K$ be an algebraically closed field. I will now state some basic definitions as I don't know how standard they are. $K^n$ is equipped with the Zariski topology. Any closed or open subset of $K^n$ will be understood with respect to this topology; The dimension of a closed set $V \subseteq K^n$ is
$$\dim V = \sup \{ n \in \mathbb{N} : (\exists V_0 \subsetneq V_1 \subsetneq \ldots \subsetneq V_n \subseteq V) \, V_k \text{'s are closed, irreducible} \};$$ The (Krull) dimension of a ring $R$ is
$$\dim R = \sup \{ n \in \mathbb{N} : (\exists I_0 \supsetneq I_1 \supsetneq \ldots \supsetneq I_n ) \, I_k \text{'s are prime ideals in } R \};$$ The coordinate ring of $V \subseteq K^n$ is 
$$K[V] = \{ F \upharpoonright V : F \in K[\overline{X}] \} \cong K[\overline{X}] / I(V).$$ The problem is: Suppose $F \in K[X, Y]$ is irreducible and $V = Z(F) \subseteq K^2$. Prove that $\dim V = 1$. What I know: Hilbert's Nullstellensatz: $I(Z(I)) = \sqrt{I}$; If $V \subseteq K^n$ is an affine algebraic set, then Zariski-closed subsets $U \subseteq V$ correspond bijectively to radical ideals $I \trianglelefteqslant K[\overline{X}]$ containing $I(V)$ by $U \substack{\xleftarrow{Z(I)} \\ \xrightarrow[I(U)]{}} I$; These in turn correspond to radical ideals $I \trianglelefteqslant K[V]$; In the above, irreducible closed subsets correspond to prime ideals; $\dim V = \dim K[V]$; I was presented a theorem that if $R$ is a domain and a finitely generated $K$-algebra, then $\dim R = \operatorname{td}_K R_0$, but it was said that the proof is somewhat complicated (uses an external theory), so I don't want to use that theorem; I can see how Krull's principal ideal theorem can be applied to immediately solve the problem, but I wasn't taught that theorem either, so if possible, I would rather avoid using it. However, if someone's really convinced there is no easier way, I will accept that as an answer. Now my recognition of the problem: obviously there is some $\overline{a} = (a_1, a_2) \in V$ and $(X-a_1, Y-a_2) \supsetneq (F)$ is a chain of length $n=1$ of prime ideals in $K[\overline{X}]$ containing $I(V)$. Also if there were a chain $I_0 \supsetneq I_1 \supsetneq I_2$, we can assume that $I_0 = (X-a_1, Y-a_2)$ for some $\overline{a} \in V$ and $I_2 = (F)$. As $K[X, Y]$ is Noetherian, $I_1 = (G_1, \ldots, G_n)$ for some $G_1, \ldots, G_n \in K[X, Y]$, which can be assumed to be irreducible since $I_1$ is prime, and pairwise unassociated. But that doesn't seem to give any easy contradiction. From the geometric side, suppose we have $V_0 \subsetneq V_1 \subsetneq V_2 \subseteq V$ closed, irreducible, so again we can assume $V_0 = \{ \overline{a} \}$ and $V_2 = V$ (and $V_1 = Z(I_1)$ if we want a connection). Any finite non-singleton is reducible, so $V_1$ is infinite (in fact, if $F$ depends on $Y$, the other case being trivial, then the projection $\pi_X[V_1]$ is co-finite). But I don't see any contradiction here either. Any hint would be appreciated.","['abstract-algebra', 'algebraic-geometry']"
2515524,Differential Equation with Delta Dirac,"This is my first question, and it was my last solution, since no article could help me solve this differential equation. The equation is in the following form: $$\dfrac{d^2 f(x)}{dx^2}-Af(x)+B\delta(x-C)f(x) = 0 \quad x \in [0,L]$$ where $$\delta(x-C)= \infty\quad if \quad x=C$$or$$ \delta(x-C)=0 \quad if\quad x\neq C$$ What I'm Asking is the solution of $f(x).$ Ignoring the delta results in Exponential solutions, but delta function makes it difficult to calculate $f(x)$ P.S. : Had Kronecker instead of Dirac, which was TOTALLY wrong, that's why the 1st comments are kind of ""strange"" now.","['dirac-delta', 'ordinary-differential-equations']"
2515572,Hint to find angle $\hat{C}$,"excuse me ! I put right picture ...sorry $\hat {D}=150$ my typing was wrong $105$ I need some hint to find the angle $\hat{C}$ All we know is that $$AB=DA=DC\\\hat{D}=150$$
I get stuck to find $CB$ or angle $\hat{C}$","['algebra-precalculus', 'trigonometry', 'geometry']"
2515596,If $1 \leq |f| |g|$ $\Rightarrow$ $1 \le \Vert g\Vert_{1} \Vert f \Vert_1 $,"Let $(X,A,\mu)$ be a measure space such that $\mu(X) = 1$ and let
  $f,g : X → [0,\infty]$ be measurable functions such that $fg ≥ 1$.
  Prove that $$1 \le \Vert g\Vert_{1} \Vert f\Vert_1 $$ Where $\Vert f\Vert_1 = \int_X|f| d\mu.$ Using Hölder's inequality we get that $$1 \leq \Vert g \Vert_1 \Vert f \Vert_\infty, \quad\mbox{and} \quad 1 \leq \Vert g \Vert_\infty \Vert f \Vert_1,  $$
but I don't know if this implies something good. Does anyone know how to solve this question?","['inequality', 'measure-theory']"
2515636,"Baire's Category Theorem fails for uncountable intersection of open, dense subsets","Since $\mathbb{Z}$ is not dense in $\mathbb{R}$, but equals $\cap_{x\in\mathbb{R}\cap\mathbb{Z}^c}[(-\infty,x)\cup(x,\infty)]$, where each $[(-\infty,x)\cup(x,\infty)]$ is dense and open in $\mathbb{R}$, can I use this to show the necessity of the intersection being countable in the Baire Category Theorem?","['examples-counterexamples', 'proof-verification', 'baire-category', 'elementary-set-theory', 'general-topology']"
2515671,Square Root of a Characteristic Function.,"For any $\phi$ a characteristic function, is there a characteristic function $\Phi$ such that $\Phi ^2=\phi$? I know that if $\phi$ is a characteristic function, then $\phi ^2$ is as well. 
Also that $\sqrt{|\phi|}$ is not always a characteristic function. But I don’t know how to get to the other way round. Thanks!!!","['characteristic-functions', 'probability-theory', 'probability', 'elementary-probability']"
2515679,Determinant of a companion matrix,I have to find determinant of $$A := \begin{bmatrix}0 & 0 & 0 & ... &0 & a_0 \\ -1 & 0 & 0 & ... &0 & a_1\\ 0 & -1 & 0 & ... &0 & a_2 \\ 0 & 0 & -1 & ... &0 & a_3 \\ \vdots &\vdots &\vdots & \ddots &\vdots&\vdots \\0 & 0 & 0 & ... &-1 & a_{n-1}     \end{bmatrix} + t I_{n \times n}$$ It is not a difficult thing to do. My method is as follows : $$\begin{bmatrix}0 & 0 & 0 & ... &0 & a_0 \\ -1 & 0 & 0 & ... &0 & a_1\\ 0 & -1 & 0 & ... &0 & a_2 \\ 0 & 0 & -1 & ... &0 & a_3 \\ \vdots &\vdots &\vdots & \ddots &\vdots&\vdots \\0 & 0 & 0 & ... &-1 & a_{n-1}     \end{bmatrix} + t I_{n \times n} = \begin{bmatrix}t & 0 & 0 & ... &0 & a_0 \\ -1 & t & 0 & ... &0 & a_1\\ 0 & -1 & t & ... &0 & a_2 \\ 0 & 0 & -1 & ... &0 & a_3 \\ \vdots &\vdots &\vdots & \ddots &\vdots&\vdots \\0 & 0 & 0 & ... &-1 & a_{n-1} + t     \end{bmatrix} $$ Performing the row reduction of type $R_{k+1} \to R_{k+1} + \dfrac{1}{t}R_k$ I get an upper triangular matrix $$\begin{bmatrix}t & 0 & 0 & ... &0 & a_0 \\ 0 & t & 0 & ... &0 & a_1 + \dfrac {a_0} t\\ 0 & 0 & t & ... &0 & a_2 + \dfrac{a_1}{t} + \dfrac {a_0} {t^2} \\ 0 & 0 & 0 & ... &0 & a_3 + \dfrac{a_2}{t} + \dfrac{a_1}{t^2} + \dfrac {a_0} {t^3} \\ \vdots &\vdots &\vdots & \ddots &\vdots&\vdots \\0 & 0 & 0 & ... &0 & a_{n-1} + t   + \sum_{k=0}^{n-2} \dfrac{a_{k}}{t^{(n-1) - k }}  \end{bmatrix} $$ Determinant of which is $t^n + \sum^{n-1}_{k = 1} a_k t^{k}$ . My friend says this is not a rigorous proof and that I have to use induction to prove $$\det A = t^n + \sum^{n-1}_{k = 1} a_k t^{k}$$ She says that I have only found a formula for $\det A$ and I can't be sure if it works for all $n\in \Bbb N$ without a proof. Is she correct?,"['matrices', 'determinant', 'proof-writing', 'companion-matrices', 'linear-algebra']"
2515709,Prove by Induction that every term of the following sequence is irrational,"Let $x_1 = (44)^{1/2}$ and $x_{n+1} = (3x_n + 1)^{1/2}$ for $n\geq 1$. Prove that $x_n$ is irrational for every $n\geq 1$. I really have no idea how to proceed, I couldn't even find a nice closed form. I know $(44)^{1/2}$ is irrational, but what should I do. I would like a sketch of the proof and hints are greatly appreciated.","['induction', 'sequences-and-series', 'irrational-numbers']"
2515775,"Prove that if $A \subset C$ is bounded and closed, then $A$ is compact. (Proof guidance)","So I'm working on a problem with the following statement: Problem Statement: Assume metric space $C$ is complete and has this property: If $(x_n)_{n \ge 0}$ is a sequence in $C$ and there exists $\varepsilon > 0$ such that $d(x_i,x_j) > \varepsilon$ for all $i \neq j$, then the sequence $(x_n)$ is not bounded. Prove that if $A \subset C$ bounded and closed, then $A$ is compact. Here is what I have done so far/my thoughts... Proof: From the statement, we know that $C$ is complete thus this means that every Cauchy sequence converges to a point in metric space $C$. Now, compactness means that a subset $A$ in metric space $C$ is compact when the set $A$ is contained in the union of a collection of open subsets of $C$, then $A$ is contained in a finite number of these subsets. From the property given, we know that the metric space $C$ contains a divergent (non-convergent) sequence that is not bounded. Hence, a subset $A$ of $C$ must be select points which are bounded thus we let $\varepsilon > 0$ such that $d(x,y) < \varepsilon$ $\forall$ $x,y \in A\subset C$. Since $A$ is bounded and closed, we select $x < y$ such that A is monotonically increasing, thus $A$ is a convergent sequence because it is a bounded monotonically increasing sequence. Thus, since $A$ contains a convergent subsequence it is compact. Thus, metric space $C$ is compact. To me, I feel like I'm in the right direction but am struggling to have that closing logic for this proof. I appreciate the help!","['general-topology', 'real-analysis', 'metric-spaces', 'compactness']"
2515779,Understanding how the Thurston Geometrization conjecture implies the Poincaré conjecture.,"I have already read this post, which answers the problem by first delving into the elliptization conjecture, which seems to me to be hiding details, because I don't understand how the elliptization conjecture is a special case of the Geometrization conjecture (now Theorem I suppose). Let us consider the following statement of Thurston's theorem: Theorem 1: Let $M$ be a closed, orientable, prime $3$-manifold. Then there exists an embedding of a disjoint union of incompressible $2$-tori and Klein bottles in $M$ such that every component of their complement admits a locally homogeneous Riemannian metric of finite volume, isometric to one of the $8$ model geometries. We also have the following lemma Lemma 1: If $M$ is a Riemannian Manifold, with universal cover $X$, which admits a complete locally homogeneous Riemannian metric then $M$ is isometric to $X/\Gamma$, where $\Gamma$ is the deck group of $X$. Now my attempt to understand how the Geometrization theorem implies the Poincaré conjecture is as follows: Let us now consider a compact, simply connected $3$ manifold $M$. As it has a trivial fundamental group, the decomposition referred to in Theorem 1 must be trivial (because Tori and Klein bottles have non trivial fundamental groups, so there can be no such incompressible embedded surfaces.) Thus $M$ must have a complete locally homogeneous metric. Lemma 1 thus implies that $M\simeq X/\Gamma$, where $X$ is its universal cover, and $\Gamma$ its deck group. The deck group is isomorphic to $N(H_0)/H_0$, where $N$ is the normalizer, and $H_0$ is the pushforward of the fundamental group of $X$ under the covering map. As the fundamental group is trivial this then implies that the deck group is trivial, hence $M$ is isometric to its universal cover $X$. Now I'm hoping that a simply connected $3$ manifold being isometric to its universal cover means it has to be diffeomorphic to $S^3$, but so far have found no evidence to support my hope. Am I on the right track? Or do I need to consider something fundamentally different? As is apparent from this post I am a novice in the areas of differential geometry and algebraic topology, so would appreciate it if answers used as simple tools as possible. I am also aware of the Kesner decomposition theorem, but I am sure understand none of its subtleties. New Attempt: Following the informative comment of Mike Miller and answer from Eric Towers I present their argument with some of the gaps filled in, just in-case any novices like me stumble across this post, as I did not immediately understand how their argument worked. Let us consider a compact, simply connected $3$ manifold $M$. As it has a trivial fundamental group, the decomposition referred to in Theorem 1 must be trivial (because Tori and Klein bottles have non trivial fundamental groups, so there can be no such incompressible embedded surfaces.) Thus $M$ must have a complete locally homogeneous metric. This implies that $M\simeq X/\Gamma$, where $X$ is one of the $8$ Thurston geometries, and $\Gamma$ a group of isometries of $X$ acting transitively on $X$. Thus $X/\Gamma$ is also simply connected. The quotient map $\pi:X\to X/\Gamma$ is a regular covering map, because the action of $\Gamma$ is properly discontinuous [1]. As each of the model geometries is path connected, so too is $X/\Gamma$, which means $X$ is homeomorphic to $X/\Gamma$ due to the latter being simply connected. Hence $M$ is homeomorphic to $X$, meaning $X$ is compact, but $S^3$ is the only compact model geometry. [1] Munkres, James R. , Topology, Pearson Education (2000).","['geometric-topology', 'general-topology', 'differential-topology']"
2515792,Uniqueness of Representation for Open Sets on the Real Line,"I reading about Representation Theorem for Open Sets on the Real Line from Apostol's Mathematical analysis. Consider the following definitions and Theorems from the text. Definition . Let $S$ be an open set of $\mathbb{R}$ . An open interval (which may be finite or infinite) is called a component interval of $S$ if $I\subseteq S$ and if there is no open interval $J\ne I$ such that $I\subseteq J\subseteq S$ . Theorem 3.10 . Every point of a nonempty open set $S$ belongs to one and only one component interval of $S$ . Theorem 3.11 . Every nonempty open set $S$ in $\mathbb{R}$ is the union of a countable collection of disjoint component intevals of $S$ . Note . This representation of $S$ is unique. In fact, if $S$ is a union of disjoint open intervals, then these intervals must be the component intervals of $S$ . This is an immediate consequence of theorem 3.10. My Questions $1$ . In the definition, it says ""open intervals (which may be finite or infinite)..."". Can open intervals be finite!? I assume he wants to say bounded or unbounded, right? $2$ . About the Note , I don't get that how the uniqueness follows immediately from theorem 3.10. Can someone shed some light on this? $3$ . Does the Note really raises a uniqueness question of such a representation? I mean if I were going to pose such a question I would say, if there were two countable collection of disjoint component intervals of $S$ such that their union is $S$ then the collections would be the same. I mean that the claim in the Note is just another theorem but not about the uniqueness of the representation mentioned in theorem 3.11.","['general-topology', 'real-analysis', 'analysis']"
2515813,Uniform convergence of difference quotient function implies differentiability in $\mathbb{R}^n$,"This arises in the context of the proof of the Rademacher theorem. Suppose that $f: \mathbb{R}^n \to \mathbb{R}$ is a Lipschitz function. It therefore has a distributional gradient $L$ and suppose that $x$ is a point in the Lebesgue set of $L$. We can define $f_r(y) = \frac{f(x+ry)-f(x)}{r}$ and the claim is that if $f_r(y) \to \langle L(x), y\rangle$ uniformly as $r \to 0$ then $f$ is differentiable at $x$. Why is this true and why is uniform convergence necessary rather than just point wise convergence?","['derivatives', 'real-analysis', 'partial-differential-equations', 'multivariable-calculus', 'lipschitz-functions']"
2515821,Convergent Sequence + Limit is Compact using Sequential Compactness,"Proposition: Let $(X,d)$ be a metric space and $\lbrace x_n \rbrace_{n=1}^\infty \subset X$ be a convergent sequence with $x_n \rightarrow x_0, n \rightarrow \infty$. Show that $K = \lbrace x_n \mid n \in \mathbb{N} \cup \lbrace 0 \rbrace \rbrace$ is a compact set. Question: It is easy to see how to do this with open covers via the standard definition of compactness. What I am wondering is how one would prove this theorem using sequential compactness (since it is equivalent to regular compactness for metric spaces), if it is even possible to do so.","['alternative-proof', 'metric-spaces', 'compactness', 'analysis']"
2515825,Using Chain Rule in Matrix Differentiation,"I have the following parameters and their respective dimension: $X:2\times 1$, $W_1:7\times2$, $W_2:1\times7$, $B_1: 7\times 1$ and $B_2:1\times1$, with the following formulation: $Y=W_2H+B_2$ where $H=\verb+ReLU+(W_1X+B_1)$, the rectified linear unit applied element-wise ($\verb+ReLU+(x)=\max(0,x)$). I want to compute $$\frac{\partial Y}{\partial W_1},$$
by using the chain rule. Hence, I compute $$\frac{\partial Y}{\partial W_1}=\frac{\partial Y}{\partial H}\cdot\frac{\partial H}{\partial W_1}$$ which is equal to $$W_2\cdot\frac{\partial H}{\partial W_1}.$$ My problem is computing $\frac{\partial H}{\partial W_1}$. I take out $X^T$ from this, by using chain rule, but then it doesn't match the dimesnion for multiplication. How do we go about taking the derivative of $H$ w.r.t. $W_1$, which is a $7\times 2$ matrix? I was told that the final result has dimesnion $7\times2$, but no matter how I arrange things, I can't come up with the correct result.","['matrices', 'neural-networks', 'matrix-calculus', 'derivatives']"
2515870,Prove that $\operatorname{null}(A)+\operatorname{null}(B)≥\operatorname{null}(AB)$ in matrix formulation,"I've already seen this question , but I'd like to prove the case in a matrix form as below; however, I have no justification for a particular part of my proof: Let $A_{m*n}$, and $B_{n*k}$, so $AB_{m*k}$. According to the rank-nullity theorem, we have: $n(A) + r(A) = n$ $n(B) + r(B) = k$ $n(AB) + r(AB) = k$ Adding the first two equations and using the third one to get rid of $k$ yields: $n(A) + n(B) + r(A) +r(B) = n + n(AB) + r(AB)$ Since $r(B) \ge r(AB)$, we have $n(A) + n(B) + r(A) \le n + n(AB)$ Here is the problem: I know that $r(A) \le n$, so I can't justify how to eliminate $r(A)$ and $n$ to end up with $n(A) + n(B) \ge n(AB)$","['matrices', 'linear-algebra']"
2515888,"Given is relation $R$. What is $R^T, R^2, R^+, h_{\text{sym}}(R)$?","Let $V = \left\{1,...,5\right\}$ and there is relation $R$ on $V$ $$R=\left\{(1,1),(1,5),(2,4),(3,3),(4,1),(4,2),(5,4)\right\}$$ What is $R^T, R^2, R^+, h_{\text{sym}}(R)$? Hi maths people I need info how these notation is correct for learn it because not sure I understand all notation good. I check on internet $R^T$ mean transpose of relation $R$ is defined: $R^T= \left\{(y,x) | xRy\right\}$ That's why I write $R^T=\left\{(1,1),(5,1),(4,2),(3,3),(1,4),(2,4),(4,5)\right\}$ $R^2$ I don't know.. Definition of $R^+ = \bigcap\left\{S \subseteq A \times A \mid S \text{ is transitive and  } R \subseteq S\right\}$ I understand that I need take all pair from $R$ which keep it transitive? $R^+ = \left\{(1,1), (5,1)\right\}$ Definition $h_{\text{sym}}(R)=\bigcap\left\{S \subseteq A \times A \mid S \text{ is symmetric and } R \subseteq S\right\}$ I take all pair from $R$ as long as it's symmetric? $h_{\text{sym}}(R)= \left\{(1,1), (3,3), (2,4),(4,2)\right\}$ Please help for understand it I do it good or not?","['relations', 'discrete-mathematics']"
2515891,Standardizing Normally Distributed Random Variables,"Having the normally distributed Random variables. We can normalize it and use table values in order to calculate probability of some event. The standardization takes formula $$z = \frac{ X - \text{expected value} }{ \text{variance}}$$ It is told that by doing this, we are forcing our variable $X$ to have expected value $0$ and variance $1$. However why is that? Why by doing steps above we force the distribution to behave like that? Thanks for help.","['statistics', 'probability', 'normal-distribution', 'probability-distributions']"
2515900,Probability space,"Let $(X,\mathcal{M})$ be a $\sigma$-algebra where $\mathcal{M}:=\{A\subset X: A \hspace{0.2cm}\mbox{or} \hspace{0.2cm} X\setminus A \hspace{0.2cm}\mbox{is countable} \}$. I want to find all the $\mu\colon \mathcal{M} \longrightarrow [0,1]$ measures that turn $(X,\mathcal{M},\mu)$ into a probability space.",['measure-theory']
2515951,"Finding 2 nonabelian, nonisomorphic groups of order 225","I need to find 2 nonabelian, nonisomorphic groups of order 225. Here's what I have so far: Let $G$ be a group of order 225. By Sylow's theorems, we have that $G$ contains $P_{25}$ and $P_{9}$, subgroups of order $25$ and $9$, respectively. It's easy to see that $n_5 = 1$ and, so, $P_{25}$ is normal in $G$. Therefore, $G = P_{25}P_9$, since $P_{25} \cap P_9 = \{1\}$. Therefore, $G \simeq P_{25} \rtimes_{\varphi} P_9$ for some $\varphi: P_9 \rightarrow \text{Aut}(P_{25})$. Since $P_{25}$ and $P_9$ are both abelian, we need $\varphi$ to be non-trivial. Now, $P_{25}$ cannot be cyclic (because that would make $G$ abelian), and so, $P_{25} = \mathbb{Z}/5\mathbb{Z} \times \mathbb{Z}/5\mathbb{Z}$. We know that $\text{Aut}(\mathbb{Z}/5\mathbb{Z} \times \mathbb{Z}/5\mathbb{Z}) = GL(2,5)$ which has order $480$, and so, $|\varphi(P_9)| = 1$ or $3$ and, since we need $\varphi$ non trivial, we have $|\varphi(P_9)| = 3$. Now, we have two choices (upto isomorphism) for $P_9$, $\mathbb{Z}/3\mathbb{Z} \times \mathbb{Z}/3\mathbb{Z}$ and $\mathbb{Z}/9\mathbb{Z}$. I figure finding such a $\varphi$ for each of these choices will give me what I need. However, I get stuck here. I tried to find an element of order $3$ in $GL(2,5)$ (for the case where $P_9$ is the cyclic group), but I'm not sure how to do this easily. I'm not really sure how to proceed when $P_9 = \mathbb{Z}/3\mathbb{Z} \times \mathbb{Z}/3\mathbb{Z}$ either.","['finite-groups', 'sylow-theory', 'group-theory', 'abelian-groups', 'semidirect-product']"
2516056,Why the sample method of mixture distribution works?,For example this thread: Generating random variables from a mixture of Normal distributions First choose a distribution according to the weights. Then sample from the chosen distribution. How to prove the correctness of this method?,"['statistics', 'sampling', 'probability', 'simulation']"
2516078,Totally disconnect space and the real number set with lower limit topology,"Is $\mathbb R_l$ totally disconnected?
We know  $\mathbb R_l $ is finer than  $\mathbb R$ and intervals and one point sets are only connected subsets of   $\mathbb R$ .hence only possible connected sets in  $\mathbb R_l$ is intervals and one point set .as intervals are seperated by $(-\infty ,a),[a,\infty)$ in  $\mathbb R_l$.   Therefore one  point sets are only connected sets in  $\mathbb R_l$. Am I wrong?","['general-topology', 'proof-verification']"
2516123,"Recent Question in American Math Monthly, proposed by Donald Knuth","Problem 11985, by Donald Knuth, American Mathematical Monthly , June-July, 2017: For fixed $s,t \in \mathbb{N}$. with $s\leq t$. let $a_{n}=\sum\limits_{k=s}^{t}$ $ {n}\choose{k}$. Prove that this sequence is log-concave, namely that $a_{n}^{2}\geq a_{n-1}a_{n+1} \ \forall n\geq 1$. The submission deadline for this problem was over on 31st October.
Does this statement follow from some well known results?","['combinatorics', 'inequality', 'summation', 'binomial-coefficients']"
2516147,Why is $H \rtimes_{\varphi} K$ isomorphic to $H \rtimes_{\varphi \circ \phi} K$ where $\phi \in \text{Aut}(K)$?,"Why is $H \rtimes_{\varphi} K$ isomorphic to $H \rtimes_{\varphi \circ \phi} K$ where $\phi \in \text{Aut}(K)$? I can see that $\varphi(K) = \varphi(\phi(K))$, but it is not clear to me how the semidirect products themselves are isomorphic. I tried constructing an isomorphism, but they were really messy and didn't seem to go anywhere. Is there any easy way to see why this is true?","['abstract-algebra', 'semidirect-product', 'group-theory', 'group-isomorphism']"
2516155,How is $f(x)=x+1$ not backwards stable if I consider the error propagated in the addition?,"Many sources claim that $f(x)=x+1$ is not backwards stable.  That is, it does not give an exact solution to a slightly perturbed (or ""nearby"") problem. e.g. https://www.cs.usask.ca/~spiteri/CMPT898/notes/numericalStability.pdf on page 24. Now, when I work this out myself, I think I'm able to show that $\exists\,\,\, \epsilon $ s.t. the computed problem with errors of $\epsilon_1, \epsilon_2,$ and $\epsilon_3 $ is equal to a slightly perturbed problem.  Since there is an error for rounding on each input, and then an error for the addition, the computed solution is $(x(1+\epsilon_1)+1(1+\epsilon_2))(1+\epsilon_3)$, and the exact solution slightly perturbed is $(x+1)(1+\epsilon)$.  So i am showingthese are equal for some epsilon on the order of machine precision: $(x(1+\epsilon_1)+1(1+\epsilon_2))(1+\epsilon_3)=(x+1)(1+\epsilon)$ multiplying these out we get: $x+\epsilon_1x+1+\epsilon_2+\epsilon_2x+\epsilon_3\epsilon_1x+\epsilon_3+\epsilon_3\epsilon_2=x+1+\epsilon x+\epsilon$ subtract $x$ and $1$ from both sides $\epsilon_1x+\epsilon_2+\epsilon_2x+\epsilon_3\epsilon_1x+\epsilon_3+\epsilon_3\epsilon_2=\epsilon x+\epsilon$ Now, it seems clear to me that we cna always find an epsilon on the right hand side that will complete the equation. Most sources cite $x=0$ as the value that breaks this condition, but if I set $x=0$ I am still able to see an $\epsilon$ that mkaes this work. What am i missing here?","['numerical-linear-algebra', 'stability-theory', 'condition-number', 'numerical-methods', 'linear-algebra']"
2516158,Connectedness of $\mathbb R^\omega$ in different topologies,Is $\mathbb R^\omega$ with box topology connected? Is it connected in uniform topology? It is connected with product topology. But I don't know the case for box and uniform topology.,"['general-topology', 'topological-vector-spaces', 'connectedness']"
2516194,supervised version of TF-IDF [term frequency inverse document frequency],"In classification tasks involving documents, the documents will commonly be preprocessed by doing things like getting counts / tf-idf weights for each term-document pair. I understand how tf-idf works but it seems like one shortcoming is that it doesn't directly look at how the tf-idf weightings affect classification ability. Instead it creates tf-idf weights and then as a separate step, you can use things like cosine similarity and train your classifier on the feature vectors produced this way, and then transofrm the test data in the same way [using same vocabulary]. So e.g. consider binary classification task (like spam / not spam). You can apply tf-idf in an unsupervised way, just getting tf-idf weights for each term in each document. Then you take this matrix of feature vectors and train your classifier on it. If a word occurs across many documents, it will be downweighted by the idf term because it is a ubiquitous word. But if you have labeled training data [documents each have category label], and you saw that almost all of the time the word occurred it was in one of the document classes, then actually this is a strong feature. So it seems like you could better build your vocabulary by directly seeing how it impacts classification ability. So my question is if there any techniques that turn tf-idf into a supervised version of tf-idf by directly taking advantage of the known document labels? Basically making TF-IDF a supervised approach?","['machine-learning', 'statistics', 'clustering']"
2516199,Bijection between $N$ and $Q $ [duplicate],"This question already has answers here : Produce an explicit bijection between rationals and naturals (9 answers) Closed 6 years ago . We know that set of rational numbers is countable. We have bijection betwee $\mathbb{N} $ and $\mathbb{N} \times \mathbb{N }$, whose graphical representation is beow: Also the bijection between $\mathbb{N} $ and $\mathbb{Z }$ exists. I am unable to find the bijection between $\mathbb{N} $ and $\mathbb{Q} $. Can anyanybody tell me the bijection between $N$ and $Q$ with its graphical representation.",['elementary-set-theory']
2516222,Do $e$ and $\pi$ satisfy a non-trivial diophantine equation?,"Do there exist integers $a,b,c$ such that at least one of them is non-zero and $ae+b\pi = c$? Please note that, I am only asking if e and $\pi$ can satisfy a non-trivial diophantine equation $ax + by = c$. I am not interested in any arbitrary polynomial relation between them. I think this is false. Any help is welcome!","['analytic-number-theory', 'algebraic-number-theory', 'number-theory', 'field-theory', 'open-problem']"
2516245,Is there a natural way to prove trig identities also hold for complex numbers?,"In complex analysis trig functions are defined via $\exp$ which in turn is defined via power series. It's of course easy to see that on $\Bbb R$, all these functions agree with their usual real-variable versions that we are well familiar with. In the real case there are some basic identities like $\cos$ is even, $\sin$ is odd and $\cos(x)=\sin(\frac\pi 2 -x)$ etc. There are also more complicated ones like 
$$\cos(x-y)=\cos x\cos y+\sin x\sin y.\tag{1}$$ Q1: do real variable identities like $(1)$ also hold when $x,y$ are complex numbers? (Of course, identities involving square roots are not included here. We basically only care about $\cos(x\pm y), \sin(x\pm y)$ etc. Q2: if so, is there any natural (or slick) way to see this, other than going down to the basic $\exp$ definition and calculating term by term? Thanks!","['algebra-precalculus', 'complex-analysis', 'trigonometry', 'complex-numbers']"
2516270,Prove that $f(f^{-1}(T)) \subset T$,"I'm stuck solving this question. Could somebody point me in the right direction? Let $f: A \rightarrow B$ be a function and $T \subset B$, prove that 
$$f(f^{-1}(T)) \subset T$$ I think I need to prove that: $$\forall t \in T: t \in f(f^{-1}(T))$$ which is equivalent with $$\forall t \in T : t \in f(S) = \{ s \in S | f(s) \in T\}$$ with $S \subset A$ But I'm not sure if this even remotely correct.","['elementary-set-theory', 'functions']"
2516284,Derivative of the product of matrices,"please give me a hint for the following exercise: It is the third part of this exercise Complementar Lie subalgebra of $\mathfrak{o}(2n)$ Let $O(n)$ be the real orthogonal group and define the map
$$F:O(n)\times GL(n;\mathbb{R})\to GL(n;\mathbb{R})$$
given by $(M,N)\longmapsto MN^{-1}$. Find $D_{(I,I)}F$. I see that $$F(M,N)=m(M,i(N)),$$ where $m$ is the multiplication of matrices and $i$ the invertion. Also I know that $D_{(I,I)}m(A,B)=A+B$ and $D_Ii=-I_d$ How can I continue? Thank you","['derivatives', 'matrix-calculus', 'differential-geometry', 'linear-algebra', 'lie-groups']"
2516301,Let $V$ be a finite dimensional vector space over a field $F$ and $T$ a linear operator on $V$ such that $T^2 = I_V$.,"Let $V$ be a finite dimensional vector space over a field $\mathbb{F}$
  and $T$ a linear operator on $V$ such that $T^2 = I_V$. If $\mathbb{F}
 = \mathbb{R}$ or $\mathbb{C}$, show that $T$ is diagonalizable! I have no idea how to do this question, the best i did was to have take any basis $B$, we have $$[T^2]_B = [T]_B[T]_B = [I_V]_B$$ which is pretty meaningless. My answer sheet used a way in which i do not understand, it claimed that any $V$ in this situation will be a direct sum of the eigenspace of $1$ and $-1$. Anyone has a better proof or direct me to the right direction! THanks","['diagonalization', 'linear-algebra', 'vector-spaces']"
2516312,Showing $g'(x_0)$ exists and equals $f'(x_0)$ and $h'(x_0)$ if $f(x_0)$=$h(x_0)$,"I have three functions, $f,g,h$ that all map from $[a,b]$ to $\mathbb{R}$. I know the following: $$f(x) \leq g(x) \leq h(x)\ \forall x\in [a,b]  $$
$$x_0 \in (a,b)$$
$$f(x_0)=h(x_0)$$
$$h'(x_0) \ \& \ f'(x_0) \ exist$$ I want to show that $g'(x_0)$ exists and that $g'(x_0)=f'(x_0)=h'(x_0)$ Any suggestions? I'm really lost. I tried applying the definition of something being differentiable at a point but made no progress.","['real-analysis', 'functions']"
2516317,Equivalent characterization of compactness for a bounded operator,"This question is related to a question I asked yesterday: Toeplitz operator on Bergman space Consider a linear bounded operator $T: H \rightarrow H$, where $H$ is a Hilbert space of holomorphic functions on the unit disc $\mathbb{D}$ in $\mathbb{C}$ (in my case, even a reproducing kernel Hilbert space), and suppose that the unit ball in $H$ is a normal family (every sequence of the unit ball in $H$ has a subsequence that converges uniformly on compact subsets of $\mathbb{D}$). Is it true that $T$ is compact on $H$ if and only if every bounded sequence $(f_n)$ in $H$ with $$f_n \rightarrow 0$$ as $n \rightarrow \infty$ uniformly on compact subsets of $\mathbb{D}$ has a subsequence $(f_{n_k})$ such that $$Tf_{n_k} \rightarrow 0$$ as $k \rightarrow \infty$ in $H$? I am also interested in references where I may find similar results.","['functional-analysis', 'operator-theory']"
2516367,Variable versus Function,"When we write $y=f(x)$ what do we mean? Would we call $y$ a function of $x$ as well? $y=f(x)$ would represent geometrically a curve in the xy-plane, but other than that I don't understand why we would write something like that.","['notation', 'functions']"
2516396,Pathway to Gromov's works,"My question is really simple and short: I want to understand Gromov's works. Assuming I have background in basic abstract algebra (groups, rings, fields, etc.), general topology and analysis (the last two from Munkres and Rudin respectively), what would be a pathway to study Gromov's works? Kindly mention reference books and/or lecture notes.","['reference-request', 'geometry']"
2516435,Mean and Variance from a Cumulative Distribution Function,"I'm trying to find the mean (expected value) and variance for the following distribution function: $F(x)=\begin{cases}
    0 & \text{for } x \lt  0\\
    x/4 & \text{for } 0 \le x \lt 1\\
    x^2/4 & \text{for } 1 \le x \lt 2\\
    1  & \text{for } x \ge 2\\
\end{cases}$ First I got the probability density function by differentiating $f(x)=\begin{cases}
    0 & \text{for } x \lt  0\\
    1/4 & \text{for } 0 \le x \lt 1\\
    x/2 & \text{for } 1 \le x \lt 2\\
    0  & \text{for } x \ge 2\\
\end{cases}$ Which I simplified as $f(x)=\begin{cases}
    1/4 & \text{for } 0 \le x \lt 1\\
    x/2 & \text{for } 1 \le x \lt 2\\
    0  & \text{elsewhere}\\
\end{cases}$ Now I need to find the mean (expected value) and variance. I know that $E(X)=\int xf(x)\,dx.$ Except I am not sure how I would calculate this as one value due to the function being in multiple parts. Any help is appreciated - Thank You!","['means', 'variance', 'probability-distributions', 'statistics', 'probability']"
2516443,Pushforward of structure sheaf under an isogeny splits,"In Edixhoven, van der Geer, abelian varieties , the proof of the statement 9.18.(iii) includes the claim that for any isogeny $f : X \to Y$ of degree $k$ there is a so-called ""trace map"" $f_{\ast}\mathcal{O}_X \to \mathcal{O}_Y$ that induces a section of $\mathcal{O}_Y \to f_{\ast}\mathcal{O}_X$. The corollary would be that $f_{\ast}\mathcal{O}_X = \mathcal{O}_Y \oplus E$ with $E$ of rank $k - 1$. My question is: What should we require of $X, Y$ and $f$ to make sure that $E$ actually splits in $k - 1$ line bundles belonging to $\mathrm{Pic}^0(Y)$? It would take some time to explain the question I'm actually thinking about, so any help would be appreciated if you may.","['abelian-varieties', 'vector-bundles', 'algebraic-geometry']"
2516445,Show that $f^{-1}(F-B)=E-f^{-1}B$ where $f:E\to F$ and $B\subset F.$,"Show that $f^{-1}(F-B)=E-f^{-1}(B)$ where $f:E\to F$ and $B\subset F.$ Proof: Let $e\in f^{-1}(F-B).$ Then $f(e)\in F-B$ which means that $f(e)\in F$ and $f(e)\not \in B.$ Now since $B\subset F$ we have that $f^{-1}(B)\subset f^{-1}(F)=E.$ And so, since $e\not \in f^{-1}(B)$ we have that $e\in E-f^{-1}B.$ We can therefore say that $e\in E-f^{-1}(B).$ Thus $f^{-1}(F-B)\subset E-f^{-1}(B).$ Now for the other inclusion we consider $e\in E-f^{-1}(B)$ which means that $e\in E$ and $e\not \in f^{-1}(B).$ Thus $f(e)\in F$ and $f(e)\not \in B.$ Since $B\subset F$ we have that $f(e)\in F-B.$ And therefore $e\in f^{-1}(F-B).$ I don't know whether this proof is correct or not and would, therefore, appreciate any inputs/suggestions.","['proof-verification', 'discrete-mathematics']"
2516494,Expected value of the sign of a normal random variable,"Let $x\in\Bbb{R}$ be a normal random variable with mean $\bar{x}$ and variance $\sigma_x^2$. I'm curious about a new variable that is defined as the sign of $s$, say $s=\operatorname{sgn}(x)\in\{\pm1\}$. What is the expected value of this variable?
Based on the answers below,
$$
\Bbb{E}[s]
=
(-1)\cdot P(x<0) + 1\cdot P(x>0)
=
-P\left(\frac{x-\bar{x}}{\sigma_x}<-\frac{\bar{x}}{\sigma_x}\right)
+
P\left(\frac{x-\bar{x}}{\sigma_x}>-\frac{\bar{x}}{\sigma_x}\right)
\implies
\Bbb{E}[s]
=
-P\left(z < -\frac{\bar{x}}{\sigma_x}\right)
+
P\left(z > -\frac{\bar{x}}{\sigma_x}\right),
$$
where $z\sim\mathcal{N}(0,1)$ is the standard normal variable. Thus,
$$
\Bbb{E}[s]
=
-\Phi\left(-\frac{\bar{x}}{\sigma_x}\right)
+
1 - \Phi\left(-\frac{\bar{x}}{\sigma_x}\right)
=
1 - 2\Phi\left(-\frac{\bar{x}}{\sigma_x}\right),
$$
where $\Phi$ is the cumulative distribution function of the standard normal variable. Thus,
$$
\Bbb{E}[s]
=
\operatorname{erf}
\left(
\frac{\bar{x}}{\sqrt{2}\sigma_x}
\right).
$$","['expectation', 'probability', 'normal-distribution']"
2516551,Determine whether it is a partial order set,"the question is:
""$A = \{4, 5, 6, 7, 8\}$
For each of the following sets R< determine whether they are partial orders between
A and A (justify your answer!). When not, determine the least combined number of
additions/removals of elements to/from R< such that the result, denoted by PO<, is
a partial order.""
There's quite a few parts, I think what I have done so far is correct, but I'm quite unsure about this question:
$R_< = \{(4, 4),(5, 5),(6, 6),(7, 7),(8, 8)\}$
I understand that reflexivity and antisymmetry hold, and transitivity doesn't, but I don't what pairs would I need to add to R< to make it hold transitivity besides just $(4, 5), (5, 6) (6, 7), (7, 8)$.",['elementary-set-theory']
2516554,Solve $A^2=B$ where $B$ is the $3\times3$ matrix whose only nonzero entry is the top right entry,"Find all the matrices $A$ such that  $$A^2= \left( \begin {array}{ccc} 0&0&1\\ 0&0&0 \\ 0&0&0\end {array} \right) $$  where $A$ is a $3\times 3$ matrix. $A= \left( \begin {array}{ccc} 0&1&1\\ 0&0&1 \\ 0&0&0\end {array} \right) $
 and 
$A= \left( \begin {array}{ccc} 0&1&0\\ 0&0&1 \\ 0&0&0\end {array} \right) $ work, but how can I find all the matrices?","['matrices', 'linear-algebra']"
2516555,Why is a circle not a convex set?,"Why is a circle not a convex set? My attempt: I was googling it, but I didn't find the correct answer, as I didn't understand the explanation why a circle is not a convex set as defined here: As shown in diagram 1, points A and B and points C and D lie inside the circle, thus I think the circle must be a convex set, as clearly shown in figure 1. Why isn't the circle a convex set?","['convex-analysis', 'geometry']"
2516578,Characterisation of measurability for $\mathbb{R}\cup\{\pm\infty\}$-valued functions,"Let $(X,\mu,\mathcal{A})$ be a measure space. $f\colon X\to \mathbb{R}$ is $\mu$-measurable if $f$ is a $\mu$-a.e. limit of simple functions $f_j\colon X\to\mathbb{R}$. Functions $f\colon X\to\bar{\mathbb{R}}$, however, are said to be $\mu$-measurable if $f^{-1}(\pm\infty),f^{-1}(O)\in\mathcal{A}$ for all $O$ open in $\mathbb{R}$. I know the definitions coincide if we consider $f\colon X\to \mathbb{R}$ to be a function with values in $\bar{\mathbb{R}}$. But, if we speak about convergence in $\bar{\mathbb{R}}$, is the pointwise limit $f\colon X\to \bar{\mathbb{R}}$ of a sequence of simple functions $f_j\colon X\to\mathbb{R}$ not necessarily $\mu$-measurable?","['measurable-functions', 'measure-theory']"
2516579,Trivial normal bundle $NS$ equivalence,"I am trying to prove the following assertion: Suppose S is a properly embbeded submanifold of $\mathbb R^n$ of
  codimension $k$. Show that the following are equivalent: There exists a neighborhood $U$ of $S$ in $\mathbb R ^n$ and a smooth function $\Phi: U \rightarrow \mathbb R^k$ such that $S$ is a regular
  level set of $\Phi$. The normal bundle $NS$ is a trivial vector bundle This is an exercise of the book Introduction to Smooth Manifolds - John M. Lee and I don't have a clue how to start to prove this.","['vector-bundles', 'smooth-manifolds', 'differential-geometry', 'differential-topology']"
2516604,Elementary question on notation in implicit differentiation,"I've been watching a video series called ""The Essence of Calculus"" on the YouTube channel $3$Blue$1$Brown, and I'm familiar with taking derivates, even moderately advanced derivatives, but on this occasion I come across a use of the notation I hadn't seen before. In this particular case, the following was said: ""The derivative of the equation $x^2+y^2=5^2$ can be taken by the following means: the derivative of $x^2$ is given as $2x~dx$ and the derivative of $y^2$ is given as $2y~dy$, therefore $2x~dx+2y~dy=0$ [etc]"" Now, I'm familiar with the chain rule, but only very briefly familiar with implicit differentiation. I understand how, when differentiation something like the equation for a circle, you end up with $$2x+2y\frac{dy}{dx}=0$$ $$\frac{dy}{dx}=-\frac{x}{y}$$ but even so, I'm unsure as to where the individual $dx$ and $dy$ tags came from. Provided we follow a slower approach, and we consider $x^2+y^2$ to be a multivariable function, $S$, of $x$ and $y$, then $$S=x^2+y^2$$ $$S+dS=(x+dx)^2+(y+dy)^2$$ $$dS=x^2+2x~dx+dx^2+y^2+2y~dy+dy^2-x^2-y^2$$ $$dS=2x~dx+dx^2+2y~dy+dy^2$$
we know that, since this is the derivative of a circle equation, that $dS=0$, since the radius of the circle will remain the same everywhere, but even we set the current expression to equal $0$, i.e. $0=2x~dx+dx^2+2y~dy+dy^2$, this I'm still far from where I want to be, which stokes a few questions. One is, is the $dx$ and $dy$ a notational trick, or is there more than this behind it? And what is it that we are even differentiating with respect to? Given the situation, this question has led me to believe that $x$ and $y$ are in fact functions of some other variable, as if I wasn't lost before! Having followed the symbolic (non-intuitive) method of differentiating implicit functions has left me a little stumped by this situation. Also, I'm aware that my question and this question are very similar, however I have not managed to find an answer that has explained my particular situation in a satisfactory way to myself in it. Any help is appreciated, thank you.","['derivatives', 'implicit-differentiation']"
2516662,an optimisation problem folding paper,"A standard $8.5$ inches by $11$ inches piece of paper is folded so that one corner touches the opposite long side and the crease runs from the adjacent short side to the other long side, as shown in the picture below. What is the minimum length of the crease? So I put the shorter leg of the folded portion (since it's a right triangle) as $x$ and the longer leg $y$. Then the crease is $\sqrt{x^2+y^2}$ and deriving it (which is what I'm supposed to be doing for optimisation) in terms of x to minimise the crease length, I got $\frac{x+yy'}{\sqrt{x^2+y^2}} = 0$, so $x+yy' = 0$. Then I was able to find some similar triangles - one with hypotenuse $x$ and one leg $8.5-x$ and the other with hypotenuse $y$ and the not-corresponding leg $8.5$. From there I was able to get the equation $y=\sqrt{y^2-8.5^2} + \sqrt{x^2-(8.5-x)^2}$. Then I started squaring the equation but it got quite messy, and I'm not even sure if the problem is supposed to be so messy... Can someone help me solve this? Disclaimer: I do know that there is a post with the same problem on this site, but unfortunately the answers there didn't really help me, and I don't get what I am doing wrong.","['derivatives', 'optimization', 'calculus', 'congruences', 'triangles']"
2516690,"Sharpness of Cramer-Wold: A pair $(X,Y)$ where a finite set of projections are normal but $(X,Y)$ not joint normal","In the case of normality, the Cramer-Wold Theorem states: Let $(X,Y)$ be a bivariate random variable.  If for all $a,b \in \mathbb{R}$, $aX + bY$ is Gaussian, then $(X,Y)$ is jointly Gaussian. I'm aware that Cramer-Wold can be improved: you only need to check a countably infinite collection of pairs $(a,b)$.  My question is: Let $(a_i,b_i)_{i = 1}^N$ be a finite collection of pairs of real numbers.  Can you construct a bivariate random variable $(X,Y)$ so that $a_i X + b_i Y$ is Gaussian for each $i$, but $(X,Y)$ is not jointly Gaussian? I'm struggling to come up with a robust way of making counterexamples for this problem; I know the classic example when we want $X$ and $Y$ to be normal but not jointly normal, but am stuck here.  Any help would be appreciated.","['probability-theory', 'probability', 'measure-theory']"
2516704,Extend Markov's inequality to $P(X > a)$,"In Wikipedia and many textbooks, they explain Markov's inequality for $X \geq a$ for a non-negative random variable $X$ and any $a > 0$ as follows: 
$$ \text{Pr}(X \geq a) \leq \frac{\mathbb{E}(X)}{a}$$
where $\mathbb{E}(X)$ is the expectation of $X$. Then, how to get the bound of $\text{Pr}(X > a)$ (i.e., without the equality in $\text{Pr}(X \geq a)$)? If the bound exists, is it meaningful to obtain the bound? My guesses are: under a p.d.f., $\text{Pr}(X>a)$ has the same bound as $\text{Pr}(X \geq a)$ according to Proof 1. under a p.m.f., for a non-negative integer random variable X, the bound of $\text{Pr}(X>a)$ is represented as follows: B-PMF-1) $\text{Pr}(X \geq a+1)=\text{Pr}(X>a) \leq \frac{\mathbb{E}(X)}{a+1}$, or B-PMF-2) $\text{Pr}(X \geq a)= \text{Pr}(X > a) + \text{Pr}(X=a) \leq \frac{\mathbb{E}(X)}{a} \Leftrightarrow \text{Pr}(X > a)  \leq \frac{\mathbb{E}(X)}{a} - \text{Pr}(X=a)$ B-PMF-2 will has the same bound as B-PMF-1 or tighter one than B-PMF-1. Are those claims true? Proof 1) 
Suppose that we have very small $\delta \geq 0$. Then, $\mathbb{E}(X)$ is
$$ \mathbb{E}(X) = \int_{0}^{\infty}xp(x)dx = \int_{0}^{a-\delta}xp(x)dx + \int_{a-\delta}^{\infty}xp(x)dx \geq \int_{a-\delta}^{\infty}xp(x)dx \geq (a - \delta)\int_{a-\delta}^{\infty}p(x)dx = (a-\delta)\text{Pr}(X \geq a -
 \delta)$$
Note that $\text{Pr}(X \geq a - \delta) \geq \text{Pr}(X > a)$. Hence, 
$$ \mathbb{E}(X) \geq (a-\delta)\text{Pr}(X > a) \Leftrightarrow \text{Pr}(X > a) \leq \frac{\mathbb{E}(X)}{a - \delta}$$ 
As $\delta \rightarrow 0$, the bound converges to $\frac{\mathbb{E}(X)}{a }$. Another way is that $\text{Pr}(X > a)=\text{Pr}(X \geq a) - \text{Pr}(X = a) \leq \frac{\mathbb{E}(X)}{a} - \text{Pr}(X = a)$, and $\text{Pr}(X = a) = 0$ when $p(\cdot)$ is a p.d.f. Thus, $\text{Pr}(X > a) \leq \frac{\mathbb{E}(X)}{a}$.","['probability-theory', 'inequality']"
2516716,Please help me calculate a integral in complex analysis.,"EXERCISE: Let $C_p$ is a semi-circle $\{z\in \mathbb{C}:\left| {z - 1} \right| = p,\operatorname{Im}(z)>0\}$, described in the counterclockwise direction. Prove that: $$I=\mathop {\lim }\limits_{p \to {0^ + }} \int\limits_{{C_p}} {\left( {\frac{1}{{z - 1}} + \frac{{{e^z}}}{{z + 1}}} \right)d} z = \pi i$$ if $C_p$ is a circle $z\in \mathbb{C}:\left| {z - 1} \right| = p$, I can prove that $I=\operatorname{Res}(f,1)=2\pi i$. But $C_p$ is a semi-circle, can some one help me?","['complex-analysis', 'complex-integration']"
2516740,A true statement with a false contrapositive?,"Here is the statement: Given $f$ is continuous on $[a,b]$ and differentiable on $(a,b)$ . If the graph of $f$ is not a straight line when $x\in[a,b]$ , then $\exists p,q\in(a,b)$ such that $$f'(p)\le \frac{f(b)-f(a)}{b-a}\le f'(q).$$ The statement is TRUE by Mean Value Theorem . Its contrapositive: Given $f$ is continuous on $[a,b]$ and differentiable on $(a,b)$ . If $\forall p,q\in(a,b)$ , $f'(p)>\dfrac{f(b)-f(a)}{b-a}$ or $f'(q)<\dfrac{f(b)-f(a)}{b-a}$ , then the graph of $f$ is a straight line when $x\in[a,b]$ . Which is probably FALSE since $f'(p)\equiv\dfrac{f(b)-f(a)}{b-a}\equiv f'(q)$ for any $p,q\in(a,b)$ when the graph of $f$ is a straight line. I am confused about which part on the above is incorrect..?","['derivatives', 'logic']"
2516774,"If numbers of heads and tails are independent, then number of tosses $N \sim \mathrm{Poisson}$","A fair coin is tossed a random number $N$ of times, giving a total $X$ of heads and $Y=N-X$ tails. Show that if $X$ and $Y$ are independent and the generating function $G_N(s)$ of $N$ exists for $s$ in a neighbourhood of $s=1$, then $N$ is Poisson distributed. In other exercises, I showed the converse , which was relatively easy. I'm working through my probability book myself, but my book does not provide an answer. I came this far: Because we have a fair coin, each coin toss follows a $\mathrm{Bernoulli}(\frac12)$ distribution, thus having generating function $G_{X_i}(s)=\frac12+\frac12 s$ for each $i \in \{1,2,\ldots, n\}$. Using the random sum formula I found $G_N(s)=(G_N(\frac12 +\frac12 s))^2$, for the probability generating function for the random sum, because $N=X+Y$, because each coin toss yields either a heads or a tails. The book gives as a hint: use $H(s)=G_N(1-s)$. However, I have no idea how to solve this one. This is also supposed to be one of the most difficult exercises so I'm just curious how this one has to be solved. Any ideas?",['probability']
2516782,Binomial-Theorem proof,"I have the following problem: $n,m \in \mathbb{N_0}$. Write $(1+x)^{n+m}=(1+x)^{n}(1+x)^{m}$ with the help of binomial formulas, multiply the right side, and deduce the following
Identity between binomial coefficients: $\begin{pmatrix} n+m\\k\\ \end{pmatrix}= \sum_{l=0}^{k}{\begin{pmatrix} n\\l\\ \end{pmatrix}}{\begin{pmatrix} m\\k-l\\ \end{pmatrix}}  \forall k \in \mathbb{N_0}$ My idea:
I know that: $(a+b)^n=\sum_{k=0}^{n}{\begin{pmatrix} n\\k\\ \end{pmatrix}a^{n-k}b^k=\sum_{k=0}^{n}{\begin{pmatrix} n\\k\\ \end{pmatrix}a^{k}b^{n-k}}}$ So:$(1+x)^{n+m}=\sum_{k=0}^{n}{{\begin{pmatrix} n\\k\\ \end{pmatrix}x^k}*\sum_{k=0}^{n}{{\begin{pmatrix} m\\k\\ \end{pmatrix}x^k}}} =\sum_{k=0}^{n}{{\begin{pmatrix} n+m\\k\\ \end{pmatrix}x^k}}=(1+x)^{n+m}$
But this doens't seem right.. Can anyone help me here?","['real-analysis', 'binomial-theorem', 'binomial-coefficients', 'combinatorics', 'analysis']"
2516783,A problem about the dimension of the intersection of two subspaces,"I'm trying to solve the problem below. $U$ and $W$ are subspaces of polynomials over $\mathbb{R}$. $U = Span(t^3 + 4t^2 - t + 3, t^3 + 5t^2 + 5, 3t^3 + 10t^2 -5t + 5)$
  $W = Span(t^3 + 4t^2 + 6, t^3 + 2t^2 - t + 5, 2t^3 + 2t^2 -3t + 9)$ What is $dim(U \cap W)$? I have solved it using the fact that $dim(U) + dim(W) - dim(U \cap W) = dim(U \cup W)$, but was wondering how to solve it without using this fact. In order to find $dim(U \cap W)$, I first try and find $U \cap W$. Clearly if $v \in U \cap W$, then $$\alpha_1(t^3 + 4t^2 - t + 3) +\alpha_2(t^3 + 5t^2 + 5) +\alpha_3(3t^3 + 10t^2 -5t + 5) = \beta_1(t^3 + 4t^2 + 6) + \beta_2(t^3 + 2t^2 - t + 5) + \beta_3(2t^3 + 2t^2 -3t + 9)$$ for some $\alpha_1, \alpha_2, \alpha_3, \beta_1, \beta_2, \beta_3 \in \mathbb{R}$. Using this fact, you can reduce a system of linear equations to work out that: $\alpha_1 + 5\alpha_3 - \beta_2 - 3\beta_3 = 0$ $\alpha_2 -2 \alpha_3 + 2\beta_2 + 6\beta_3 = 0$ $\beta_1 + 2\beta_2 + 5\beta_3 = 0$ But I don't know where to go from here. Any help would be greatly appreciated.","['matrices', 'systems-of-equations', 'linear-algebra', 'vector-spaces']"
2516792,Conditions for the invertibility of doubly stochastic matrix,"I am trying to find conditions for the invertibility of the matrix resulting from the convex combination of all possible permutation matrices of dimension $n \times n$ (to put it in context, and in case it helps, each of the permutation matrices identifies a different order in which an agent would rank n distinct alternatives), where: a permutation matrix is a square matrix for which each column/row has exactly one element equal to 1, and takes value zero elsewhere. a doubly stochastic matrix is a square matrix of non negative real numbers for which the row sum and the column sum is equal to 1 a convex combination is a linear combination whose coefficients add up to 1 So for instance for $n=3$ the object of study would be:
$$
\tau_{1}\left[\begin{array}{ccc}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{array}\right]+\tau_{2}\left[\begin{array}{ccc}
1 & 0 & 0\\
0 & 0 & 1\\
0 & 1 & 0
\end{array}\right]+\tau_{3}\left[\begin{array}{ccc}
0 & 1 & 0\\
1 & 0 & 0\\
0 & 0 & 1
\end{array}\right]+\tau_{4}\left[\begin{array}{ccc}
0 & 1 & 0\\
0 & 0 & 1\\
1 & 0 & 0
\end{array}\right]+\tau_{5}\left[\begin{array}{ccc}
0 & 0 & 1\\
1 & 0 & 0\\
0 & 1 & 0
\end{array}\right]+\tau_{6}\left[\begin{array}{ccc}
0 & 0 & 1\\
0 & 1 & 0\\
1 & 0 & 0
\end{array}\right] = \left[\begin{array}{ccc}
\tau_1+\tau_2 & \tau_3+\tau_4 & \tau_5+\tau_6\\
\tau_3+\tau_5 & \tau_1+\tau_6 & \tau_2+\tau_4\\
\tau_4+\tau_6 & \tau_2+\tau_5 & \tau_1+\tau_3
\end{array}\right]
$$
where $\sum_{i=1}^{6}\tau_{i}=1$ and $\tau_{i}\geq0$ for all $i=1,...,6$. Of course I am looking for answers in the case of generic $n$. Even conditions under which the resulting matrix is non-singular for a finite number of values would still do it for me. Is there a standard reference for this? I could not find any, but as I am not a mathematician I suspect it may be something really obvious that is dealt with e.g. in problem sets. Thank you!","['matrices', 'matrix-rank', 'linear-algebra']"
2516813,How many five letter words can be formed from the letters of the word INFINITESIMAL?,"We have $4I,2N,1F,T,E,S,M,A,L$. Word of type: 
$AAAAB=8C1*\frac{5!}{4!}=40$ $AAABB=\frac{5!}{(3!*2!)}=10$ $AAABC=\frac{8C2*5!}{3!}=560$ $AABBC=\frac{7C1*5!}{(2!*2!)}=210$ $ABBCD=\frac{2C1*8C3*5!}{2!}=6720$ $ABCDE=9C5*5!=15120$ My answer is $40+10+560+210+6720+15120=22660$ But the answer is $22260$.  I don't know where I am making mistake?","['permutations', 'combinatorics']"
2516827,Regular and irregular points,"In the following 2 examples, I am trying to find all the singular points of the given equations and determine whether each one is regular or irregular I can determine the singular points of the equations but I am having some trouble determining if they are regular or irregular. 1)  $$x^2 (1-x^2)y'' + \frac {2}{x}y'+4y =0$$ The singular points of the equation are $x=\pm 1, 0$ The answer is that $0$ is irregular and $\pm 1$ regular but I am not sure why 2) $$xy'' + (1-x)y' +xy =0$$ The singular point is $0$ but why is this considered regular? Do I have to consider the $p (x)$ term in each equation?",['ordinary-differential-equations']
2516831,How do we evaluate this general integral?,"From convolving two chi-squared distributions, I find the general integral
$$\int _0^yx^{\frac m 2 -1} \cdot (y-x)^{\frac n 2 -1}dx$$ Is there a way to evaluate this for arbitrary integers $n, m$? We can of course assume without loss of generality that $n>m$ or $n<m$.","['integration', 'probability-distributions']"
2516852,How to find CDF of $|X-Y|$ when X and Y uniformly distributed in a coordinate triangle?,"Let $XY$ be two uniformly distributed random variables indicating a coordinate on a triangle $T ∶ ((0,1), (1,0), (0, −1))$, how to find both cumulative and probability density function of $|X − Y|$. My solution to the problem Figure If $Z = |X-Y|$,
\begin{equation*}
\begin{split}
F(z) &= P{(|X-Y|\le z)} = P(Y\le X-z)\cup P(Y\ge X+z) \\
&= 1-z \text{ (Given the area formula in above linked figure)} \\
%&= \int_0^{\frac{1+z}{2}}\int_{x-z}^{x+z}dydx = \int_{0}^{\frac{1+z}{2}}2zdx \\
%&= z+z^2 \\
P(z) &= \frac{d}{dz}F(z)\\
&= -z
\end{split}
\end{equation*}","['uniform-distribution', 'probability-theory', 'probability']"
2516859,Solve Differential equation.,"$$ y' = \frac{2y^{2}-xy}{x^2-xy+y^2} $$
so i have done it by making a substitution  $ u=y/x $
$$ u+u'x = \frac{2u^2-u}{1-u+u^{2}} $$
$$ \frac{dx}{x} = \frac{1-u+u^{2}}{3u^{2}-2u-u^{3}}du $$
and when i want to integrate it i need to find integral of a right side which is kinda tought so present it as
 $$ \frac{dx}{x} = \frac{1}{u-1}du-\frac{1}{2u}du-\frac{3}{2(u-2)}du $$
and after that i have no problem but this substitution took me a while, so maybe is there any option to do this example a bit faster?",['ordinary-differential-equations']
2516861,How to solve a system of linear differential equations using laplace transformation when one of the initial condition is not at zero?,"A new user here! For specifics, the problem is:
$$x' - y'' = - 2 \cosh t$$
$$y' - x'' = 2 \sinh t$$ $$y(0) = y'(0) = y''(0) = 1$$
$$x(1) = - x'(1) =x'' (1) = 1/e$$ From what I know, I need to change $x(1)$ to $x(0)$, by letting a variable $u = t-1$. But if I do that, $y(0)$ would change to $y(-1)$. I am at a loss to what to do. No need to solve the whole problem, just point me to the right direction. Thanks!","['ordinary-differential-equations', 'laplace-transform']"
2516871,Recursive formula (IMO 2017 #3),"The  2017 International Math Olympiad posed a question involving a rabbit and hunter https://artofproblemsolving.com/community/c6h1480157_imo_2017_problem_3 Assume: the rabbit always moves 1 unit on a vector away from the hunter the tracker always emits a signal which is 1 unit perpendicular to that vector the hunter always moves 1 unit on a vector toward the position reported by the tracker The distance d(n) between hunter and rabbit after n rounds can be expressed recursively as $$ d(n)  = \sqrt{((d(n-1)+1)^2 +1} -1 $$ Essentially, the problem is asking whether d(1e9) can feasibly be larger than 100. With the use of computer and spreadsheet tool one can show that $$ d(n)  = \sqrt{n - 2\sqrt{n+1} +2}  $$ Question: how could one derive the non-recursive expression of d(n) without benefit of a computer spreadsheet","['contest-math', 'recursive-algorithms', 'ordinary-differential-equations']"
2516898,Prove a certain imaginary quadratic field contains three ideal classes.,"I'm trying to show $\mathbb{Z}[\sqrt{-31}]$ has three distinct ideal classes, but something keeps going wrong and I can only find the identity and one other class. I found $|d_{K}| = 31$ because $-31 \equiv 1 \bmod 4$, and using Minkowski's Bound I computed $\frac{1}{2} \frac{4}{\pi} \sqrt{31} < 4$, so I need only check primes 2 and 3 (I feel like this is where I may be missing something). $\langle 2 \rangle$ splits into $\left\langle 2, \frac{1 \pm \sqrt{-31}}{2} \right\rangle$ which I can show is not principal by considering the norm of an arbitrary element needs to equal $2$ $\implies$ $N(\alpha) = N\left(\frac{a + b\sqrt{-31}}{2}\right) = \frac{a^{2} + 31b^{2}}{4} \neq 2$. My problems is with $\langle 3 \rangle$ because it is prime in $\mathcal{O}_{K}$ due to $-31$ not being congruent to a square modulo $3$. Thus $\langle 3 \rangle$ is equivalent to the identity in the ideal class group, therefore the ideal class group has only two classes. Can anyone see where I am making a mistake? Your comments would be much appreciated. Thanks for reading.","['number-theory', 'algebraic-number-theory', 'ideal-class-group']"
2516907,"Transitive, reflexive and symmetric closures of relations","I have this problem I'm trying to solve. Given is a set $X$ and a relation $r$ on $X$. For an equivalence relation $c$ on $X$ we say that $c$ is produced by r, if $r \subseteq c$ and for all equivalence relations $d$ on $X$ with $r \subseteq d$ it follows that that $c \subseteq d$. (1) Let $s$ be the transitive-reflexive closure of $r$. Show that: If $r$ is symmetric, then $s$ is symmetric.
(2) Show that there is at most one equivalence relation that is produced by $r$. My solution attempts: (1) Let $x,y \in X$ and $(x,y) \in s$. If $(x,y) \in r$, then also $(y,x) \in r$, because $r$ is symmetric and because $r \subseteq s$, we have $(y,x) \in s$. If $(x,y) \not \in r$ and $x=y$, then clearly $(y,x) \in s$, because $s$ is reflexive. If $(x,y) \not \in r$ and $x \not=y$, then there is $z \in X$ such that $(x,z) \in r$ and $(z,y) \in r$. But since $r$ is symmetric, also $(z,x) \in r$ and $(y,z) \in r$ and because $s$ is transitive, also $(y,x) \in s$. (2) Let $c,e$ be equivalence relations produced by $r$. It follows that $r \subseteq c$ and $r \subseteq e$. Since for all equivalence relations $d$ on $X$ with $r \subseteq d$, we have $c \subseteq d$ and $e \subseteq d$, we must also have $c \subseteq e$ and $e \subseteq c$. Therefore, we must have $c=e$. I'm sure there are some mistakes. So I'd be very glad if you could point them out. I'd also appreciate if you could propose an alternative proof.","['relations', 'proof-writing', 'elementary-set-theory', 'proof-verification']"
2516917,How do I solve $e^{iz} = 3i$?,"I am stuck on the question that asks me to solve $e^{iz} = 3i$. 
I rewrote $e^{iz}$ as $e^{ix-y}$ and thus as $e^{ix}\cdot e^{-y}$ and thus as $e^{-y}\cdot (\cos x + i\sin x)$. 
I then wrote $e^{-y}\cos x = 0$ and $e^{-y}\sin x = 3$. When I try to solve this, however, I find $x = \pi/2 + 2k\pi$ as solution for the first expression, but I can't find a solution for $e^{-y}\sin x = 3$, because there are no solutions for $\sin x = 3$.
I then tried to find y through solving $e^{-y}\cdot \cos(\pi/2 + 2k\pi)=0$, this however gives me $y = \log 0$, which has no solutions. What am I doing wrong? Thanks!","['complex-analysis', 'complex-numbers']"
2516997,What is the derivative of $f(tx)$ with respect to $t$?,"I think is a super basic question but I just can't seem to wrap my head around how think about this. Let $f: \mathbb{R}^n \rightarrow \mathbb{R}$ be differentiable. We fix an $x \in \mathbb{R}^n$ and define the function $g: \mathbb{R} \rightarrow \mathbb{R}$ by $g(t) = f(tx), \forall t \in \mathbb{R}$. Now, my question is what is $g'(t)$? If I were deriving $f(tx)$ with respect to $x$, this is easy, I have $f'(tx)t$, but it's not really clear how to derive with respect to $t$. Is it $f'(tx)x = \nabla f(tx)x$? If yes, why? Wouldn't that imply that $g'(t) \in \mathbb{R}^n$, since $f'(tx) =\nabla f(tx) \in \mathbb{R}$ and $x \in \mathbb{R}^n$? I apologize if this a super basic question and I'm just missing something crucial! EDIT: Ok, I think I have an understanding now. Here's what I have: Let $h: \mathbb{R} \rightarrow \mathbb{R}^n, h(t) = tx$. Now, we have $g(t) = f(h(t))$, and so, by the chain rule: \begin{align}
Dg(t) & = Df(h(t))\cdot Dh(t) = \begin{pmatrix}\frac{\partial f}{\partial h_1(t)} & \dots & \frac{\partial f}{\partial h_n(t)}\end{pmatrix} \begin{pmatrix}\frac{\partial h_1}{\partial t} \\ \vdots \\ \frac{\partial h_n}{\partial t}\end{pmatrix} \\[10pt]
& = \frac{\partial f}{\partial h_1(t)}\frac{\partial h_1}{\partial t} + \dots + \frac{\partial f}{\partial h_n(t)}\frac{\partial h_n}{\partial t} \\[10pt]
& = \frac{\partial f}{\partial h_1(t)}x_1 + \dots + \frac{\partial f}{\partial h_n(t)}x_n = \frac{\partial f}{\partial tx_1}x_1 + \dots + \frac{\partial f}{\partial tx_n}x_n = Df(tx)x.
\end{align} Is this understanding correct? Moreover, is $\nabla f(x) = \begin{pmatrix}\frac{\partial f}{\partial x_1} & \dots & \frac{\partial f}{\partial x_n}\end{pmatrix}$ or $\nabla f(x) = \frac{\partial f}{\partial x_1} + \dots + \frac{\partial f}{\partial x_n}$? I thought it was the latter, which led to my confusion, but dealing with everything in jacobian form, it seems that it is the former?","['derivatives', 'real-analysis', 'partial-derivative', 'calculus', 'multivariable-calculus']"
2517008,Does $\mathbb{E}(X-a)^2$ finite imply $\mathbb{E}(X^2)$ finite?,"Can we say that, if for some arbitrary constant  $a$, $$\mathbb{E}(X-a)^2< \infty$$ $$\implies \mathbb{E}(X^2)< \infty$$ I think that we can say, yes, because $\mathbb{E}(X-a)^2= \mathbb{E}(X^2-2aX+a^2)=a^2-2a\mathbb{E}X+\mathbb{E}X^2$ Hence, if we can show that $\mathbb{E}X$ is finite, then we would be done. I think that if $\mathbb{E}X$ was not finite, then $\mathbb{E}(X-a)^2$  would not be finite, however I am not sure how to show that this would be true.","['probability-theory', 'expectation']"
2517013,"For which $\alpha>0$ the function $f(x)=d(x, C)^{\alpha}$ is absolutely continuous on $[0, 1]$, when $C$ is the Cantor $1/3$-set?","Let $C\subset [0, 1]$ be the usual Cantor ternary set and define $f(x)=d(x, C)^{\alpha}$, when $\alpha>0$. I need to determine the values $\alpha$ s.t. $f$ is absolutely continuous on $[0, 1]$. It follows easily from the reverse triangle inequality that $f$ is absolutely continuous when $\alpha=1$. But the general case is not clear to me. What I've found is: 1) The function $x\mapsto d(x, C)$ is differentiable at every $x\in [0, 1]$ which is not in $C$ or which is not a midpoint of an interval removed in the construction of Cantor set. So $f$ is differentiable a.e. in $[0, 1]$. 2) Let $[a, b]$ be an interval which is removed in the construction and let $m$ be the midpoint of $[a, b]$. The derivative of $x\mapsto d(x, C)$ is $1$, when $x\in ]a, m[$ and $-1$, when $x\in]m, b[$. Also I know that function $g$ is absolutely continuous iff $g$ is differentiable a.e., $g^{\prime}$ is integrable and satisfies the fundamental theorem of calculus. Can I use this characterization to deduce when $f$ is absolutely continuous? Thank you in advance.","['geometric-measure-theory', 'measure-theory', 'cantor-set']"
2517074,What exactly is a countable union?,"For example, $A_i$ be the set of all numbers divisible by $i$, consider: $\bigcup_{n \in \mathbb{N}} A_n$ Is this union a countable union because I am enumerating over a countable set (the natural numbers)?","['elementary-set-theory', 'discrete-mathematics']"
2517123,Sum of subgaussian random variables,"Let $\{X_i\}_{i=1}^N$ be a set of $\nu$-subgaussian random variables, meaning
$$
\mathbb{E}(\exp(tX_i)) \leq e^{\nu t^2/2}.
$$
Suppose also that $X_i$ are normalized so that $\mathbb{E}(X_i) = 0$
and $\mathbb{E}(X_i^2) = 1$. Let $a_i$ be a fixed (deterministic) sequence of coefficients, and define the random variables
$$
Y = \sum_{i=1}^N a_i X_i,
$$
and its normalization
$$
Z = \frac{Y}{\sqrt{\mathbb{E} Y^2}}. 
$$
If the $X_i$ are assumed to be independent, then it is not hard to check that $Z$ is also $\nu$-subgaussian, because one can compute its moment generating function. My question is whether this hypothesis is necessary. Is $Z$ a $\nu$-subgaussian random variable, even if $X_i$ are not independent? The reason one might hope that this is true is that the normalization of $Z$ takes care of any growth of $Z$ that might arise from the dependencies. My best guess for how to prove this is to bound the joint distribution of $(X_i)$ by a multivariate Gaussian distribution, and then observe that $Y$ is some marginal and is therefore bounded by a Gaussian of the correct variance(?).  But I'm not sure how to fill in the details.","['probability', 'random-variables']"
2517133,The relationship between the curvature of a curve and a circle,"Let $c$ be a circle with constant curvature $k_c$, and the green curve $\alpha$ below with curvature at a point $x$ $k_{\alpha}(x)$ I would like to know if this inequality is true: $$k_{\alpha}(q)\lt k_c\lt k_{\alpha}(p)$$ is there anything I can say about $k_{\alpha}(r)$?","['curves', 'differential-geometry', 'plane-curves']"
2517142,Induction in Lee's proof of Darboux theorem,"In Lee's Introduction to Smooth manifolds (earlier version), he proves the  Darboux theorem using Lemma. Let $(M, \omega)$ be a symplectic manifold, and let $(U;x_1, \ldots , x_n, y_1, \ldots, y_n)$ an open chart. Then $(x_1, \ldots , x_n, y_1, \ldots, y_n)$ are Darboux coordinates if and only if $$\{ x_i, x_j \}  = \{ y_i, y_j \} =0 \qquad , \qquad \{ x_i, y_j \}= - \delta_{ij} $$ Lemma. Let $M$ be a manifold and $X_1 , \ldots , X_r$ linearly independent vector fields. Then there exist coordinates $(u_1, \ldots, u_n)$ such that $X_i = \frac{\partial}{\partial u_i}$ if and only if $[X_i, X_j]=0$. He uses induction on $k=0, \ldots , n$, and claim ""for $k=0$ there is nothing to say"", and start proving the general case. But I don't feel really comfortable with that, since $k=0$ is literally nothing. So I would like to see at least the case $k=1$. But my problem arises when I discover that the arguments he uses for the general case are not valid for $k=1$. So, how to do it? How to obtain functions $(x_1, y_1)$ such that $\{ d_p x_1, d_p y_1  \}$ are linearly independent and $\{ x_1, y_1 \}= -1 $?","['symplectic-geometry', 'differential-geometry']"
2517173,Verify the Conversion to First Order Logic,"I have been trying to convert the following sentences to First Order Logic. Could you please verify it, if I am doing it right. Thank you Every firm whose all employees can code is happy. Fi(X)-> X is a firm E(Y,X)-> Y is an employee of X C(Y)-> Y  can code H(X)-> X is happy. ∀X((Fi(X)∧∀y(E(Y,X)→C(Y)))→H(X)) Is this right or is it done this way? Because the above case evaluates to True if even an employee exists that doesn't code. Does this work? ∀X((F(X)→∀y(E(Y,X)→C(Y)))→H(X)) Every manager who has a female employee is female. F(X)-> X is a female
E(Y,X)-> Y is an employee of X
M(X)-> X is a Manager
F(Y)-> Y is a female. ∀X(∃Y(M(X)∧E(Y,X)∧F(Y))→F(X)) Is this right? Thank you","['quantifiers', 'predicate-logic', 'logic', 'discrete-mathematics']"
2517175,"A box contains a penny, two nickels, and a dime. If two coins are selected randomly from the box, without replacement, and if X is the sum...","A box contains a penny (1¢), two nickels (5¢), and a dime (10¢). If two coins are selected randomly from the box, without replacement, and if $X$ is the sum of the values of the two coins, What is the probability distribution table of $X$? $$\begin{array}{|c|c|c|c|c|}\hline X & 6¢ & 10¢ & 11¢ & 15¢ \\ \hline f(x) & 2/6 & 1/6 & 1/6 & 2/6\\\hline\end{array}$$ What is the cumulative distribution function $F(x)$ of $X$? The cumulative distribution function, $F(x)$ of $X$ is defined as:   $F(x) = P(X ≤ x)$ So would that mean I just write: $P(X ≤ 6) = 2/6$ $P(X ≤ 10) = 1/6$ $P(X ≤ 11) = 1/6$ $P(X ≤ 15) = 2/6$ \begin{align*}
P(X \leq 6) & = P(X = 6)=2/6\\
P(X \leq 10) & = P(X = 6) + P(X = 10)=2/6+1/6=1/2\\
P(X \leq 11) & = P(X = 6) + P(X = 10) + P(X = 11)=1/2+1/6=2/3\\
P(X \leq 15) & = P(X = 6) + P(X = 10) + P(X = 11) + P(X = 15)=2/3+2/6=1
\end{align*}","['probability', 'probability-distributions']"
2517203,Why is $\mathbb{R}\cup\{\infty\}$ compact?,"I am brand new to compactification and have a couple basic questions tied to it. I read that the one-point compactification of $\mathbb{R}$, $\mathbb{R}\cup\{\infty\}$ is compact, but struggle to see why. My thoughts: Let's take an arbitrary open cover of $\mathbb{R}\cup\{\infty\}$, call it $(U_\alpha)_{\alpha\in A}$. Since $(U_\alpha)_{\alpha\in A}$ covers the whole space, there exists $\alpha$ such that $\infty\in U_\alpha$. Therefore, the complement of $U_\alpha$ is compact. This gives us that $U_\alpha^c$ has a finite subcover. If we add back $U_\alpha$ to this finite subcover, we have a finite cover of $\mathbb{R}\cup\{\infty\}$. However, I am concerned that this finite cover is not necessarily a sub cover of our original open cover. Am I correct in my concern? Is there some other piece I am missing?","['general-topology', 'compactification', 'compactness', 'proof-verification']"
2517206,A regular connected graph has k loops?,"Suppose $A$ is an order-$n$ matrix of zeroes and ones such that $A^2 = J$, the matrix of all ones. Show that $A$ has exactly $k$ ones along the diagonal, where $k^2 = n$. I can show that $AJ=JA=kJ$, so in graph theoretic terms, $A$ is a regular graph of order $k$. And $A$ is connected, or else $A^2$ would have zeroes in it. I wonder if there's a theorem that can establish that the graph has exactly $k$ loops? Or perhaps it's more obvious from a matrix perspective. I know that regularity and connectivity by itself isn't sufficient, since for example the matrix $$A_\varnothing=\begin{bmatrix}1& & &1\\ &1&1& \\1& &1& \\&1&&1\end{bmatrix}$$ is $k$-regular and connected, but fails to satisfy $A_\varnothing^2 = J$ and fails to have $k$ ones along the diagonal. An example that does exhibit this property is $$A_\checkmark = \begin{bmatrix}1&1&&\\&&1&1\\1&1&&\\&&1&1\end{bmatrix}$$","['matrices', 'graph-theory', 'algebraic-graph-theory']"
2517215,Calculate Surface Area of a Bicubic Bezier Surface Patch,"Given the 16 3D control points as input for a bicubic Bézier surface patch, how would one go about calculating the surface area of such a patch?","['bezier-curve', 'riemannian-geometry', 'differential-geometry']"
2517222,Closure of the set of degree $n$ polynomials with $n$ real roots,"A very beautiful (but maybe classic) exercise: Consider the set $\Omega_n$ of polynomials of degree $n$ with real coefficients and $n$ distinct real roots. What is the closure of $\Omega_n$ in $R_n[x]$? ($R_n[x]$ denotes the set of polynomials with real coefficients of degree at most $n$) The answer is the set of polynomials in $R_n[x]$ all of whose roots are real, plus the constant polynomials. Showing that this set is contained in the closure is not too hard, however the reverse implication is more difficult and I'm wondering what is the most elementary method to prove it (without talking about holomorphic functions for example).","['general-topology', 'polynomials']"
2517250,Determining discontinuity on a set,"For the following set, construct $f:\mathbb{R} \to \mathbb{R}$ such that it is discontinuous at every point in the set and continuous on the complement. This is the set I am given: Let $X$= $(0,1)$. Here is my proposed answer, but I am not sure how to prove it works. Suppose $f(x) =
\begin{cases}
0&\text{if $x\leq 0$}\\ 
1 &\text{if $x \in (0,1)$ and rational,} \\
2 &\text{if $x \in (0,1)$ and irrational, and} \\
0 &\text{if $x\geq 1$} \\
\end{cases}$ Does this work?","['continuity', 'real-analysis', 'proof-writing', 'functions']"
2517271,Show that the area of a regular tube of radius $r$ around a curve $\alpha = 2\pi r $(length of $\alpha$),"This is a question from do Carmo exercises, Sec 2-5. I know I just have to compute the area by using First Fundamental form, area $$ = \int\int\sqrt{EG-F^2}du dv$$ for a paramatrisation $x(u, v)$ of the tube surface, but I can't think of a parametrisation in just $2$ variables.",['differential-geometry']
2517313,General solution to nth order linear inhomogeneous ode,"I am trying to understand Problem 3.21 in Teschl's book on ODE's. Prove that the solution to the inhomogeneous equation
  $$
x^{(n)} + c_{n-1} x^{(n-1)} + \cdots + c_1 \dot{x} + c_0 x = g(t)
$$
  is given by
  $$
x(t) = x_h(t) + \int_0^t u(t-s) g(s) ds
$$
  where $x_h(t)$ is an arbitrary solution of the homogeneous equation and $u(t)$ is the solution of the homogeneous equation corresponding to the initial condition $u(0) = \dot{u}= \cdots = u^{(n-2)} = 0$ and $u^{(n-1)}=1$. Hint: either reduce it to the general form of the inhomogeneous linear equation
  $$
x(t) = Ax(t) + g(t)
$$
  which is given by
  $$
x(t) = e^{tA} x_0 + \int_0^t e^{(t-s)A} g(s) ds
$$
  or verify it directly.  I recommend doing both. I am able to verify directly by repeated differentiation.  However, I cannot seem to manipulate the nth order equation solution into the form of the solution of the inhomogeneous linear system despite the fact that the solutions look quite similar.  I really want to understand this connection though and would very much appreciate some insight into how this reduction is done.","['ordinary-differential-equations', 'linear-algebra']"
2517326,$f(z)=\frac{z}{1+|z|} $ Is 1-1?,So i have to prove if $f(z_1)=f(z_2)$ then $z_1=z_2$ . I tried substituting $z=x+yi$ i also tried proving their differences in absolute value are zero.None of this work .Im sure im missing a property or something that will make this very easy. I also tried making the first part of the eq belonging is $R$  so the  second part of the eq must have imaginary part  zero. I just dont get to the result i want.,"['complex-analysis', 'analysis', 'functions']"
2517354,Convergence of a sequence of number.,"Let $0<\varepsilon<1$ be a very small number. Define a sequence of number by
$$
a_1=1+\varepsilon,\,\, a_2=1+\varepsilon a_1^2,\,\, a_3=1+\varepsilon a_2^2,\,\,\cdots,\,\, a_n=1+\varepsilon a_{n-1}^2,\cdots
$$
Under what condition on $\varepsilon$, does the limit of $a_n$ exists, i.e.,
$$
a=\lim_{n\rightarrow\infty}a_n<\infty?
$$","['real-analysis', 'analysis', 'discrete-mathematics']"
2517384,"Probability of ""union"" of events","Let $\{X(t)\}$ be a stochastic process with $t\in [0, T]$. It is possible to prove that $P(\exists t\in [0, T] : X(t) >a) \leq\int_0^TP(X(t)>a)dt$? My idea was to write the left hand side as union of events, the problem is this union is not countable... Is that a problem?","['probability-theory', 'probability']"
2517390,Measure that has the same null sets as the lebesgue measure,I'm searching for a measure $ \mu $ in $ \mathbb{R} $ for that $\mu(\mathbb{R})=1$ and a set is a $\mu$-null-set if and only if it is a $\lambda$-null-set for the lebesgue measure $\lambda$. The main problem are uncountable null sets like the cantor set. Cant think of a way to include those.,"['lebesgue-measure', 'measure-theory']"
2517436,Properties of Transpose Matrices... Flippable?,"I'm learning linear regression using ""A Primer on Linear Models"" by John F. Monahan. On page 14, it says $$Q(b) = (y-Xb)^T(y-Xb)=y^Ty − 2y^T Xb + b^T X^T Xb$$
Where $y$ is a $N ×1$ vector of observed responses, $X$ is a $N × p$ matrix of fixed constants, $b$ is a $p × 1$ vector of fixed but unknown parameters. by developing brackets I can get $-y^TXb-(Xb)^Ty$. But I don't know from this how to get $− 2y^T Xb$ term. Why is it possible to just flip $(Xb)^Ty$ to $y^TXb$? Also, on the same page 14, $$\frac{d Q}{d b}=-2X^Ty + 2X^TXb = -2X^T(y-Xb)$$ I don't understand how I can get this result.","['matrices', 'transpose', 'derivatives']"
2517469,Direct sums in projective modules,"Let $P$ be a projective module and $P=P_1+N$, where $P_1$ is a direct summand of $P$ and $N$ is a submodule. Show that there is $P_2\subseteq N$ such that $P=P_1\oplus P_2$. I know that there is a submodule $P'$ of $P$ such that $P=P_1\oplus P'$. I wanted to consider the projection from this to $P_1$ and use the definition of being projective. But I would also need a map from $P=P_1+N$ to $P_1$ and I don't know how to get a well defined map there because it is not a direct sum.","['abstract-algebra', 'ring-theory', 'projective-module']"
2517485,Subspace of 2 variable polynomials homeomorphic to Klein bottle,"I'm reading a paper, which considers the space $X$ of polynomials of the form $p(ax+by)$ for $p$ a single variable quadratic function (i.e. $p(x,y) = c(ax+by)^2 + d(ax+by) + e$ for $a,b,c,d,e \in \mathbb{R}$) such that $\int\int_D p(x,y) \ dx dy = 0$ and $\int \int_D p^2(x,y) \ dxdy = 1$, where $D$ is the unit disk. The paper claims that this space is homeomorphic to the Klein bottle, however I'm struggling with some of the details. Specifically, it says that the space $P$ of all polynomials in two variables (i.e. $f(x,y) = b_0 + b_1x+b_2y + b_3x^2 + b_4 xy + b_5 y^2$) such that $\int \int_D f = 0$ and  $\int \int_D f^2 = 1$ is homeomorphic to a 4-dimensional ellipsoid. That part I proved and agree with. From there, we consider the subspace $X$ of $P$. Plugging into the constraint $\int\int_D p(x,y) \ dx dy = 0$ gives me that $e = -\frac{1}{4} c (a^2+b^2)$, so $X$ has polynomials of the form $c(ax+by)^2 + d(ax+by) - \frac{c(a^2+b^2)}{4}$. Plugging into the constraint $\int \int_D p^2(x,y) \ dxdy = 1$ gave me an algebra mess. The text says to consider the function $g:S^1 \times S^1 \rightarrow c(ax+by)^2 + d(ax+by),$ which is onto and has the relations $g(a,b,c,d) = g(-a,-b,c,-d)$. So letting $\theta = (a,b) \in S^1$ and $\phi = (c,d) \in S^1$, we have $(a,b) \sim (-a,-b) = \theta + \pi$ and $(c,d)
 \sim (c,-d) = 2\pi - \phi$. Then since $g$ is surjective onto $\{c(ax+by)^2 + d(ax+by) \mid a^2+b^2 = c^2 + d^2 = 1\} \equiv Y$, we have $Y = \text{Im}(g) = S^1 \times S^1 \big/ [(\theta,\phi) \sim (\theta+\pi, 2\pi-\phi)] = K$ (the Klein bottle). However, we want $X$ (not $Y$) to be homeomorphic to $K$. My question is: how can we get a homeomorphism from $X$ to $K$? I know that: $Y$ is a subset of a 4-dimensional ellipsoid (which is homeomorphic to $S^4$), so I could consider $g:S^4 \rightarrow Y$ such that $g(a,b,c,d) = c(ax+by)^2 + d(ax+by) - \frac{c(a^2+b^2)}{4}$, which has the same relations $(a,b,c,d) \sim (-a,-b,c,-d)$. So $Y$ could be homeomorphic to $S^4 \big/ [(a,b,c,d) \sim(-a,-b,c,-d)]$, but I don't see how those identifications on $S^4$ yield a Klein bottle. (Also letting $(a,b) = \theta, (c,d) = \phi$ seems wrong since $(a,b), (c,d)$ each don't necessarily lie on a copy of $S^1$. ) I also know that the space $A$ of single variable quadratic functions $q(t) = -\frac{c(a^2+b^2)}{4} + c t + dt^2$ in $X$ form an ellipse ($\frac{d^2}{4\pi}+\frac{9c^2}{72\pi}) = 1$, which is homeomorphic to $S^1$. (Plugging these functions into $\int\int_D q = 0$ and $\int\int_D q^2 = 0$ is much easier.) Also, for $g(a,b,c,d) = c(ax+by)^2 + d(ax+by) - \frac{c(a^2+b^2)}{4}$ in $Y$, $g(a,b,c,d)(x,y) = q((a,b) \cdot (x,y))$. Maybe this is helpful?","['algebraic-topology', 'geometric-topology', 'polynomials', 'algebraic-geometry']"
2517504,Doubt about proof,"I was trying to solve the following problem: Show that if a surface is tangent to a plane along a curve, then the points of this curve are either parabolic or planar. I found the following solution: if $N$ is the Gauss map, and $\alpha(t)$ is the curve, then $N(\alpha(t))$ is normal to the plane and hence constant. Thus $0 \equiv dN/dt = dN(\alpha'(t))$ at all points of the curve. Assuming $\alpha$ is a regular parametrization, $\alpha'(t) \neq 0$, and so $\ker dN \neq 0$, i.e $dN$ is not injective and $det(dN) \equiv 0$ on $\alpha$. The result follows by deﬁnition. My question is: why do we need to prove that $dN$ is not injective? Once we prove that $0 \equiv dN/dt$, we are basically done since this directly implies that $\det(dN) \equiv 0$ on $\alpha$.","['curvature', 'parametrization', 'differential-geometry', 'surfaces']"
2517537,Fundamental Subspaces Theorem's proof,"According to the theorem of fundamental subspaces if A is $m \times n$ matrix, then $N(A) = R(A^T)^\bot$ and $N(A^T)$ = $R(A)^\bot$. The proof from Linear Algebra with Applications book by Steven J.Leon is: On the other hand, we have already seen that $N(A) \bot R(A)^\bot$, and this implies that $N(A)\subset R(A^T)^\bot$. On the other hand, if $\mathbf{x}$ is any vector in $R(A^T)^\bot$, then $\textbf{x}$ is orthogonal to each of the column vectors of $A^T$ and consequently, $A\textbf{x} = 0$. Thus, x must be an element of $N(A)$ and hence $N(A) = R(A^T)^\bot$. Can someone explain this proof with more details? Especially the part where it says On the other hand, if x is any vector in $R(A^T)^\bot$, then x is orthogonal to each of the column vectors of $A^T$ and consequently, $A\textbf{x} = 0.$","['matrices', 'orthogonality', 'linear-algebra']"
2517542,Probability density function and probability measures,"I have to answer a question on an assignment, and I am not entirely sure what the question is asking, let alone how to answer it. Suppose $X$ has a Pareto distribution with density $$f(x)=\frac{ab^a}{x^{a+1}}\, \text{for}\, x \geq b,\,a > 0,\, \text{and}\, b>0. $$ The question actually states ""clarify the density function $f$ and the two concerned probability measures"". I'm not entirely sure what is meant by ""clarify"" here, but if what some of my classmates had to say is true, what he wants us to do is talk about how the density function is a measurable function that maps events $A$ in the sample space $\Omega$ (in the probability space $(\Omega, \mathcal{F}, P)$, where $\mathcal{F}$ is a $\sigma$-field containing $A$, and $P$ is a probability measure) to subsets of $(\mathbb{R},\mathcal{B},\mathcal{L})$, where $\mathcal{L}$ is the Lebesgue measure and $\mathcal{B}$ are the Borel sets. Are the probability measure and the Lebesgue measure the two probability measures that are meant here, and what does it mean for $f$ to be the density between them?  Thank you.","['probability-theory', 'probability', 'measure-theory', 'lebesgue-measure']"
2517554,Is the diagonal morphism of schemes the result of a base change?,"In general, if $f : X \to Y$ is a morphism of schemes, then is it true that the diagonal morphism $\Delta : X \to X \times_Y X$ is the result of some base extension of $f$? Specifically, I was onto the idea that, given $X \times_Y X$ is a scheme over $Y$, we might have that $X$ satisfies the universal fiber product properties with projections $id: X \to X$ and $\Delta : X \to X \times_Y X$. But working through the commutative diagrams, this doesn't appear to be the case unless I could assume e.g. $f$ is a monomorphism.","['schemes', 'algebraic-geometry']"
2517555,Consider the set of all $n×n$ invertible real matrices. Is that set connected? [duplicate],"This question already has answers here : invertible matrices connected or not (4 answers) Closed 6 years ago . I thought of creating a path from a matrix $A$ to a matrix $B$ using their traces, but got nowhere.","['matrices', 'general-topology']"
2517557,Finding the height and probability of a probability density function,"A continuous random variable X has a probability density function f(x) represented on the diagram below (0’A’B’C’). A) FIND THE VALUE OF H We know that the total area must be equal to 1. We can divide the probability density function into two different sections that can be easily calculated (rectangle and a triangle). Given this, we know that we know that the total area is the sum of the area of the rectangle and the area of the triangle. We have both the height, and the width needed to calculate the area of the rectangle Area rectangle = 1/4 · 3 = 3/4 We don’t have the height for the triangle, so we solve with reference to total area
1 =  3/4 + Area triangle Area triangle = 1/4 Using the area of the triangle, we solve for height h 1/4 = ((h-1/4)2)/2 = h - 1/4 h = 1/4 + 1/4 = 1/2 B) COMPUTE P (0 < X ≤ 1) The probability of P (0 < X ≤ 1) is equivalent to the area under the curve from 0 to 1. This area is a rectangle so we use the formula A = hb to find the area. A= (0.25)(1) = 1/4 C)COMPUTE P (1 < X < 2) I'm really not sure how to answer this one, any help would be appreciated.","['statistics', 'area', 'probability', 'functions']"
2517576,Function with $f(0)=1$ and $\int_{-\infty}^{\infty}f(x)dx=1$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I don't think there's any other approach except guessing. I thought of $$f(x)=e^{-2x} ; x\geq0$$ $$e^{2x} ; x<0$$ But this is basically two different functions. Is there a function with a single formula satisfying $f(0)=1$ and $\int_{-\infty}^{\infty}f(x)dx=1$? I think the graph should look like this: Has anyone seen this function? EDIT: There's two more conditions: The value of the function should drop faster than or at least the same rate as $e^{−2|x|}$ on both sides of $x=0$. And the function should keep decreasing on both sides of $x=0$. So, the function should keep decreasing on both sides of $x=0$ and the decreasing rate should be faster or at least equal to the exponential decrease rate.","['calculus', 'functions']"
2517587,Find probability given moment generating function?,"So, I have a question that asks me to find the probability $P(Y<2)$ if $Y$ has a moment generating function $$M_Y(t) = (1-p+pe^t)^5$$ Is this a special distribution? Is there a trick I'm missing? Solving it algebraically/ with calculus gets really messy",['probability-theory']
2517626,Determining compositions of trig functions by knowing Euler's identity etc,"How does one determine:
$$\cos^2(\arctan(x))?$$ I know what it is equal to, since its in the tables. But without working with many trigonometric identities, its not clear how to find such things. How would you see this with the minimal number of trig identities? $\cos^2(\arctan(x))=\cos(\arctan(x))\cos(\arctan(x))=\frac{1}{\sqrt{1+x^2}}\frac{1}{\sqrt{1+x^2}}=\frac1{1+x^2}.$ The one identity I used here, I didn't know. It seems in similar situations, on an exam, I would have massive trouble without these identities. Can all of these sorts of things be solved by knowing something about Eulers identity and such?","['trigonometry', 'calculus']"
2517634,Showing a limit is 1,Let $m(n) = \min \{ m : 2^mm^{3/2} \geq n \}$. I want to show that $\lim_{n \rightarrow \infty} m(n)/ \log_2(n) = 1$. I have been able to show that the limsup of this limit is at most 1. How can I show the other direction? I'm sure the minimality of $m(n)$ has to be used somwhere.,"['analysis', 'limits']"
2517713,Solving simple wave equation,"This is a homework question for numerical analysis that I do not know how to find the solution to. $\frac{du}{dt}-\frac{du}{dx}=0$ $u(x,0)=e^x$ $u(1,t)=e^{t+1}$ $0\leq x \leq1,0\leq t \leq1$ I know the solution should be of the form $u=f(x)g(t)$ but I can't find any literature that explains what to do with the boundary conditions. My teacher said I don't need to have worked with PDEs before to solve this but I am lost.","['linear-pde', 'wave-equation', 'ordinary-differential-equations', 'partial-differential-equations']"
2517763,The motivation of positive mass theorem,"I have read some papers on positive mass theorem, mainly those by Schoen and Yau. I am awed by their minimal surface technique. Yet, I found little information about the motivation of this conjecture. Is it simply because we suppose mass in a naive sense must not be negative? Why scalar curvature makes sense to determine positivity of mass? Thank you!","['differential-geometry', 'general-relativity']"
