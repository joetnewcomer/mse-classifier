question_id,title,body,tags
4003198,The converse problem about duality of $L^p$,"Let $Ω$ be a bounded open subset in $R^n$ and $f$ be measureable with respect to Lebesgue measure on $Ω$ . If there exist $M＞0$ s.t. $$\left|\int fg\,\mathrm{d}x\right|≦M\left(\int |g|^q\mathrm{d}x\right)^\frac{1}{q}$$ for all continuous function $g$ on $Ω$ (the integral is on $Ω$ ), where $1＜q＜+∞$ , $\frac{1}{p}+\frac{1}{q}=1$ , then $f \in L^p(Ω)$ and $\|f\|_{L^p(Ω)}≦M$ . I find some references: the conclusion is true if $g$ can be substituted by all simple functions. But how can we do this in the continuous case? Should we choose simple functions that approximate the continuous $g$ by using Lusin's theorem  (but I have some problem in seeing how to do this)? Could someone show me the details? Thank you! My doubt : even though we can use a continuous $g$ to approximate simple functions in $L^1$ (i.e. in the left side integral), we need that to prove they are close enough also in $L^q$ (i.e. in the right side integral).","['measure-theory', 'functional-analysis', 'real-analysis']"
4003210,Differential equation with partial fraction,How do you separate this differential equation into a partial fraction? Solve the following differential equation: $$\frac{dy}{dx}=\frac{2y^2-xy+x^2}{xy-x^2}$$,"['partial-fractions', 'ordinary-differential-equations']"
4003225,Prove that $\sigma(am) < \sigma(am + 1)$ for infinitely many positive integers $m$,"Given a positive integer $a$ , prove that $\sigma(am) < \sigma(am + 1)$ for infinitely many positive integers $m$ . ( $\sigma(n)$ is the sum of all positive divisors of the positive integer number $n$ .) I have two problem when trying to use the hint. Let $p_1,p_2,...,$ be the primes which do not divide $a$ . Let $k$ be the minimum integer such that $\dfrac{2\sigma(a)}{a} < \prod_{i=1}^k \left (1 + \dfrac{1}{p_i} \right )$ . How can I prove $\prod_{i=1}^\infty \left (1 + \dfrac{1}{p_i}\right )$ diverges to show $k$ exist. By Dirichlet's Theorem there exists infinitely many primes $q$ such that $q \equiv -a^{-1} \pmod{p_i}$ for $1 \le i \le k$ . Choose $m=q$ , then $\sigma(aq+1) \ge (aq+1) \cdot \prod_{i=1}^k \left (1 + \dfrac{1}{p_i}\right ) > \dfrac{2(aq+1)\sigma(a)}{a} > 2q\sigma(a) > \sigma(aq)$ . The problem is done after that, but how can I prove $q$ exists without using Dirichlet's Theorem (which are too much for a High School Olympiad problem).","['number-theory', 'divisor-sum']"
4003278,What notation should I use for indexed family?,"So I've just started learning a bit of topology and set theory and im getting confused on definitions of indexed family. I've seen various websites and books describe an indexed family of sets like this $\{A_{i}|i\in I \}$ is a function $S:I\longrightarrow A$ and we write $A_{i}$ instead of $S(i)$ . But on a post I saw on here I understood that an indexed family can contain repeated elements if this is so why do we use set builder notation to describe a family?
Shouldn't it be something more like $(U_i)_{i\in I}$ in this case the braces do not indicate a set. Thanks in advance.","['elementary-set-theory', 'notation']"
4003334,Reduction of order,"I have the equation $$x^2 y'' + (2x^2 - 3x) y' + 3y = 0$$ and the solution $$y_1 = x^3 e^{-2x}$$ Using reduction of order: $$y_2 = v y_1$$ I reduced the equation to $$v'' x^5 + v' x^4 = 0$$ so $v(x) = \ln x + C$ . However, I thoroughly checked $$y_2 = x^3 e^{-2x} \ln x$$ and it does not work in the original equation. Any suggestions?","['reduction-of-order-ode', 'ordinary-differential-equations']"
4003368,How to contextualize an inverse function for interpolation purposes?,"I have a function that describes the growth of a population in a logistic term: $$N_t = rN_0(1-\frac{N_0}{\kappa})$$ I would like to interpolate the values so that, given a known $y$ I can get the related $x$ . To make it easier, I linearized the equation by taking log( $N_t$ ). I removed the point that were not in a straight line and the obtained a linear model: $$log(N_t) = y = st + i = mx + b$$ Using R, I can interpolate x given the model y~x , as in this picture: But what I need to do is the opposite: Since in R is not possible to get y from the model, and it is not correct to invert the model as x~y , I found the inverse function as: $$log(y) = sx+i$$ (where $s$ and $i$ are the slope and intercept of the first model $$log(x) = sy+i$$ $$y = \frac{log(x) -i}{s}$$ But now I am lost on what to do next. Shall I use the inversed function on the original x or y values? How do I convert these values into the original space's one? In other words, I get something like this: How do I use the inverted function?
Manually, I have found that if $y=1000000$ , then $x=16.6$ . The parameters are: $s=0.022$ , $i=0.328$ . If I solve, I get: $$log(x) = s \cdot 10^6 -i$$ $$x = 10^{s \cdot 10^6 -i}= ∞$$ OR $$x = 10^{s \cdot 6 -i}= 0.6$$ My apologies but I am not a mathematician. Thank you","['calculus', 'functions', 'interpolation', 'inverse-function']"
4003372,Grasping the practical usage of Central Limit Theorem,"I've been reviewing the Central Limit Theorem in statistics and I'm having trouble intuitively grasping how it can be practically used. The theorem tells us, subject to constraints, that the distribution of the sample mean will be approximately normal, even if the population distribution is not. From what I understand, this remarkable fact now allows us to use inferential statistical methods that apply to the normal distribution to answer questions about the population distribution. But I struggle with intuitively grasping why this is possible? That is, if I want to answer some question about a random variable X of unknown distribution, how does working with the sample mean of X get me to the answer about X? Is there a step missing that allows me to infer properties of X from properties of the sample mean of X?","['statistics', 'central-limit-theorem']"
4003376,Neural ODE definition of derivative $\frac{d L}{dz(t)}$ (adjoint),"The authors of Neural Ordinary Differential Equations (NeuRIPS 2018 best paper award), propose to model machine learning problems with an ODE $$ \dot z(t) = f(t, z(t), \theta) \quad{\text{s.t.}}\quad z(t_0)=z_0$$ where $f$ is e.g. a neural network with parameters $\theta$ . The Gradient with respect to a loss function $L$ is computed via the adjoint method: $$\begin{aligned}
\frac{d L}{d\theta} = -\int_{t_1}^{t_0}a(t)^T\frac{\partial f}{\partial \theta} d t
\quad\text{where}\quad
\dot a(t) = -a(t)^T\frac{\partial f}{\partial z},\,
a(t_1)=\frac{dL}{dz(t_1)}
\end{aligned}$$ I have a problem with interpreting the adjoint state $a(t)$ . The paper claims that the adjoint state is given by $a(t)=\frac{dL}{dz(t)}$ . However, let's consider the simple example $\,\dot z = w z,\, z(t_0)=z_0$ with solution $\hat z(t) := z^*(t;t_0, z_0, w) = e^{w (t-t_0)}z_0$ and loss function $L(w)=\frac{1}{2}|\hat z(t_1) - z_1|^2$ . Then, solving the adjoint system yields: $$\left.\begin{aligned}
\dot a(t) &= - a(t)^T \tfrac{\partial f}{\partial z} = -w \cdot  a(t) 
\\ a(t_1) &= \frac{d L }{d z(t_1)} = \hat z(t_1) - z_1
\end{aligned}
\right\rbrace\implies a(t) = e^{-w(t-t_1)}(\hat z(t_1) - z_1)
$$ I veried that this is indeed correct, integrating $-\int_{t_1}^{t_0} a(t)\frac{\partial f}{\partial\theta}dt$ gives the correct derivative $\frac{dL}{dw}$ . Plugging back the solution $\hat z$ of the ODE yields $a(t)=e^{-w(t-t_1)}(e^{w (t_1-t_0)}z_0 - z_1)$ (I think I got all the signs correct here.) However, I do not see how to mechanistically form the derivative $\frac{d L}{dz(t)}$ directly and arrive at the same result. If we interpret $\frac{dL}{dz(t)}$ as $\frac{d}{dz}(\frac{1}{2}|z-z_1|^2)\big|_{z=\hat z(t)}$ we get $\hat z(t)-z_1$ , which is unequal to $a(t)$ . So how is $\frac{dL}{dz(t)}$ formally defined, such that it ends up equal ? The paper never explains this. Secondly, I would like to know if there is a more direct way to derive the adjoint equation. I am aware of the author's derivation in the appendix as well as the derivation via Pontryagin's maximum principle . The first one appears unmotived whilst the second one for some reason requires the consideration of an optimization problem, when all we want to do is compute a derivative.","['neural-networks', 'ordinary-differential-equations', 'chain-rule']"
4003400,"A triangle $ABC$ with $c=60,l_c=10$ and $P=125$","A triangle $ABC$ is given with $c=60,l_c=10$ and $P=125$ , where $AB=c$ , $l_c$ is the angle bisector of $\measuredangle C$ and $P$ is the perimeter. Find $a$ and $b$ . Here are my thoughts: We have $\begin{cases}\dfrac{m}{n}=\dfrac{b}{a}\\l_c^2=ab-mn\end{cases}.$ From the first equation we can get $$\dfrac{m+n}{n}=\dfrac{a+b}{a}$$ or $$\dfrac{12}{n}=\dfrac{13}{a}.$$ Then we can substitute $l_c=10$ into the second equation to get $$100=ab-mn.$$ I am stuck here. Thank you in advance!
Katherine","['euclidean-geometry', 'geometry']"
4003420,Triangle inequality infinite terms $|a-b|\leq \sum_{i=1}^\infty|x_{i}-x_{i-1}|$,"While solving a problem, I thought of kind of ""Triangle inequality infinite terms"". Clearly for finite terms if $a=x_0$ and $x_n=b$ we have $$|a-b|\leq |a-x_1+x_1-x_2+\cdots+x_{n-1}-b|\leq \sum_{i=1}^n|x_{i-1}-x_{i}|  $$ It seems like, under the conditions $\lim_{n\to \infty}x_n=b$ and $x_0=a$ , this should be extended to $$|a-b|\leq \sum_{i=1}^\infty|x_{i-1}-x_{i}|$$ Is it right? Is not a surprising idea, but I think I could not find this usually on textbooks.","['limits', 'sequences-and-series']"
4003429,Implicit form of Burgers' equation,"I’m having a hard time trying to figure out how $u_t$ and $u_x$ have bern derived from $$u(x,t)=u_0(x-u(x,t)t).$$ I’ve tried using the product & chain rules multiple times but I’m just not getting the derivatives below. I know that something has been omitted in the argument but I can’t figure where it would fit in to begin with. Here is the original question:","['partial-derivative', 'calculus', 'derivatives', 'partial-differential-equations']"
4003448,Unique continuation at the boundary for harmonic functions in the plane,"Consider the set $U = (-1,1) \times \{ 0\} \subset \mathbb R^2$ and a continuous function $f : U \rightarrow \mathbb R$ . Then for any domain $\Omega \subset \mathbb R^2$ such that $U \subset \partial\Omega$ , there exist many functions $u$ harmonic in $\Omega$ such that $u|_U = f$ (as the Dirichlet problem is not completely determined). My question is what happens if we want to prescribe the value of $u$ on $U$ and also the value of $\partial_\nu u$ on $U$ ? Does there exist a (maximal) domain $\Omega$ and function $u$ harmonic in $\Omega$ with the desired behavior in $U$ ? I think, in general, there cannot exist a function $u$ and domain $\Omega$ satisfying this. For example, we could ask for $\partial_\nu u|_U=0$ and $u|_U(x)=\max(0,\vert x \vert -\frac 1 2)$ . Thus, by unique continuation at the boundary for harmonic functions, since $u$ and its gradient are both $0$ in an open set of the boundary then $u$ must be identically zero. But the prescribed value at $u$ is not identically zero, so there cannot exist any $u$ . I was wondering whether we can find some compatibility conditions on the prescribed values of $u$ and its normal derivative such that we can ensure the existence of some solution. Also, if there exists a solution, what can we say about the maximal domain where it is defined?
Does anybody know about any reference on this kind of problem?","['harmonic-functions', 'harmonic-analysis', 'reference-request', 'complex-analysis', 'partial-differential-equations']"
4003449,Solving this problem without Taylor series ( I made an extra assumption),"I want to show that the derivative of a (one-time differentiable) function $f(x)$ is given by $$f'(a)= \lim \limits_{h \to 0} \dfrac {1}{h} \displaystyle \int_{-1}^{1} \dfrac{3u}{2} f(a+uh) \ du$$ I used the Taylor's expansion about the point $x=a$ and the conventional $h$ as $uh$ [i.e. $f(x+h)= f(x) + h f'(x) + \cdots$ ] and got the answer. However, I made an additional assumption that the function $f(x)$ possesses a convergent series about $uh$ and this includes the assumption that the function is differentiable more than once. Tried applying the Leibniz rule, but could not get to the RHS. How can I prove the result without using the Taylor series?","['integration', 'limits', 'derivatives']"
4003456,Size of a linear image of a cube in $\mathbb{Z}^d$,"Suppose that we have an element $v = (v_1, \dots, v_d) \in \mathbb{Z}^d$ such that $\gcd(v_1, \dots, v_d) = 1$ . Then $v$ is contained in some base of $\mathbb{Z}^d$ (seen as a free-abelian group or a free module over $\mathbb{Z}$ ). In particular, there exists a regular integer matrix $A \in \mathop{GL}_d(\mathbb{Z})$ such that $A(v) = (1, 0, \dots, 0)$ . My question is the following: assuming that $|v_1| + \dots + |v_d| = n$ , what is the smallest $\ell \in \mathbb{N}$ (taken over all possible matrices $A$ ) such that the image $A\left([-1, 1]^d\right)$ is contained in the cube $[-\ell, \ell]^d$ ? I care about asymptotics of $\ell(n)$ up to multiplicative constant.","['abelian-groups', 'group-theory', 'linear-algebra', 'modules']"
4003500,Evaluate $\int_{0}^{1} \frac{\ln(1 + x + x^2 + \ldots + x^n)}{x}\mathrm d x$,"How to evaluate: $$\int_{0}^{1} \frac{\ln(1 + x + x^2 + \ldots + x^n)}{x}\mathrm d x$$ Attempt: $$\int_{0}^{1}\frac{\ln(1 + x + x^2 + \ldots + x^n)}{x} \mathrm dx
= \int_{0}^{1}\frac{\ln(1 -x^{n+1}) - \ln(1 - x)}{x}\mathrm d x$$ Any hints would be appreciated. Edit: Testing it with different values of $n$ , it seems like the integral evaluates to be $\frac{n \pi^2}{6(n+1)}$","['integration', 'calculus', 'definite-integrals']"
4003521,Analyse convergence of: $\displaystyle \sum^{\infty}_{n=3} \left (\sqrt[3]{n^3 + 2} - \sqrt{n^2 + 7}\right)$,"Analyse convergence of: $$\displaystyle \sum^{\infty}_{n=3} \left(\sqrt[3]{n^3 + 2} - \sqrt{n^2 + 7}\right )$$ I know that all elements are negative, so I need to take $-1$ out and I will have only positive elements and then I can use comparison criterion. However, I don't know how to do the first step. I need to make it rational.","['convergence-divergence', 'sequences-and-series', 'analysis', 'real-analysis']"
4003599,"Finding my mistake in a ""proof"" that there is no non-trivial knot","I am working on a presentation about the complexity of determining whether a knot is trivial, and while reading about some topological stuff I somehow managed to ""show"" that there are no non-trivial knots. Obviously, there has to be something wrong with my ""proof"", but I can't see where I did something wrong, or maybe which of the things I read about are inaccurate. Here are the definitions and propositions I've picked up from various papers. Definition 1: An embedding $N\hookrightarrow M$ is proper , if $\partial N=N\cap\partial M$ . And a properly embedded hypersurface $S\subset M$ is essential in $M$ , if it cannot be homotoped into $\partial M$ while keeping $\partial S$ fixed in place, and if the fundamental group $\pi_1(S)$ of $S$ injects into $\pi_1(M)$ . Proposition 2: Let $K$ be a tame knot embedded in $\mathbb S^3$ , and let $T_K\subseteq\mathbb S^3$ be an open tubular neighborhood of $K$ . The knot $K$ is trivial, if and only if the knot complement $M_K:=\mathbb S^3\setminus T_K$ of $K$ contains an essential disk (whose boundary certainly is a longitude of $\overline{T_K}$ ). (as far as I know this is a corollary from the fact that a knot embedded in $\mathbb R^3$ is trivial, if and only if it has a spanning disk , that is, a disk embedded in $\mathbb R^3$ whose boundary is the knot traversed once.) Proposition 3: The complement $T'$ of the interior of a solid torus $T$ in $\mathbb S^3$ is homeomorphic to a solid torus, the longitudes of $T$ are the meridians of $T'$ and the meridians of $T$ are the longitudes of $T'$ . Proposition 4: Every solid torus $T$ contains an essential disk, and every such disk has a meridian of $T$ as boundary. And here is my corollary from those propositions. My corollary: Every tame knot is trivial. Proof. Let $K\subset\mathbb S^3$ be any tame knot. Since $K$ is an embedding of the circle $\mathbb S^1$ into $\mathbb S^3$ , any open tubular neighborhood $T_K\subseteq\mathbb S^3$ of $K$ is homeomorphic to $\mathbb S^1\times(D^2)^\circ$ , i.e. the interior of a solid torus. By proposition 3 the knot complement $M_K=\mathbb S^3\setminus T_K$ is homeomorphic to a solid torus which, by proposition 4, contains an essential disk (with a meridian of $M_K$ or a longitude of $\overline{T_K}$ as boundary). Hence, $K$ is trivial by proposition 1. Can you see where I've made a mistake or which propositions are inaccurate?","['knot-theory', 'general-topology']"
4003617,Empty theory is a sequence of isolated points,"I'm working my way through Henson and van den Dries Model Theory lecture notes doing odd-numbered exercises. Yet I am stuck on the exercise 4.17: Show that if $T$ is the empty theory in the language $L$ of equality, then the space $S_0(T)$ consists of a sequence of points $(T_n | n \geq 1)$ that are isolated, together with a point $T_\infty$ to which this sequence converges. Nowhere in the notes do they define what an ""empty theory"" is (I am only aware of an empty language). How would such a thing even look like? What are the consequences of it? In particular, wouldn't it imply everything? Then the ""isolated points"" are also not defined anywhere. How could I possibly start proving the statement? It seems more of a topology question to me than model theory... Any help or hints would be appreciated!","['general-topology', 'logic', 'first-order-logic', 'model-theory']"
4003621,what value of K does the system have a unique solution,"$\begin{cases}x_1 + kx_2 - x_3 = 2\\2x_1 - x_2 + kx_3 = 5\\x_1 + 10x_2 -6x_3= 1\\
\end{cases}$ I've been trying echelon form where i took $R_2 = R_2 - 2R_1$ and $R_3 = R_3-R_1$ So I have $\left[\begin{array}{ccc|c}1&K&-1&2\\2&-2&K&5\\1&10&-6&1\end{array}\right]$ I've been trying echelon form where i took $R_2 = R_2 - 2R_1$ and $R_3 = R_3-R_1$ and reduced it So I have $\left[\begin{array}{ccc|c}1&K&-1&2\\0&-1-2K&K+2&1\\0&10-K&-5&-1\end{array}\right]$ But now I am not sure how i could remove $10-K$ with $-1-2K$ any help would be appreciated",['linear-algebra']
4003636,Polya's Urn for Three Colors Instead of Two,"Is it possible to extend Polya's Urn problem to balls with $3$ different colors instead of just $2$ ? ie. An urn contains $1$ red, $1$ blue, and $1$ green ball. At each turn you draw one ball and put it back along with another ball of the same color. Let $X_R$ be the number of red balls in the urn after turn $n$ . What is the distribution for $X_R$ ? From this post, in a regular Polya's urn with two colors, the number of red balls in the urn after $n$ draws is uniform over $\{1, ..., n+1\}$ ie: $$P(X_R = k) = \frac{1}{n+2} \text{ for } 1 \le k \le n+1$$ How would I need to change this for my scenario in which there are three colors? Any help would be great!","['polya-urn-model', 'probability-distributions', 'polya-counting-theory', 'probability-theory', 'probability']"
4003670,Can the following expression be related to the multinomial formula?,"The following formula $$(n,p,q,r\ \text{odd})\quad	\sum_{\genfrac{}{}{0pt}{1}{p\leq q \leq r}{p+q+r =n}} \frac{n!}{p!\, q!\, r!} \times \begin{cases} 1 & \text{if}\ p< q <r\\
	\frac{1}{2} & \text{if exactly two indices are equal}\\
	\frac{1}{3!}& \text{if}\ p=q=r= \frac{n}{3} \end{cases}$$ reminds me very much of the ""multinomial formula"" $$ \left( x_1 + x_2 + \cdots + x_d \right)^n = \sum_{\left|\boldsymbol{\alpha}\right|=n} \genfrac{(}{)}{0pt}{0}{\left|\boldsymbol{\alpha}\right|}{\boldsymbol{\alpha}}\, \mathbf{x}^{\boldsymbol{\alpha}}
$$ where $\boldsymbol{\alpha}\in \mathbb{N}^d,\ \left|\boldsymbol{\alpha}\right| = \alpha_1 + \alpha_2 + \cdots + \alpha_d $ and $$ \begin{split}
	\genfrac{(}{)}{0pt}{0}{\left|\boldsymbol{\alpha}\right|}{\boldsymbol{\alpha}} & = \genfrac{(}{)}{0pt}{0}{n}{\alpha_1} \genfrac{(}{)}{0pt}{0}{n-\alpha_1}{\alpha_2}\, \cdots \, \genfrac{(}{)}{0pt}{0}{n-\alpha_1 -\alpha_2 - \cdots - \alpha_{d-1}}{\alpha_d}= \frac{n!}{\alpha_1 !\, (n-\alpha_1)!} \frac{(n-\alpha_1)!}{\alpha_2 !\, (n-\alpha_1-\alpha_2)!}\, \cdots\, \frac{(n-\alpha_1 -\alpha_2 - \cdots - \alpha_{d-1})!}{\alpha_d !\, 0 !} \\
	& = \frac{n!}{\alpha_1 !\, \alpha_2 ! \, \cdots \, \alpha_d!}
	\end{split}
$$ is the number of times the facteur $x^{\boldsymbol{\alpha}}:= x_1^{\alpha_1} x_2^{\alpha_2} \cdots x_d^{\alpha_d}$ appears in the expansion of $\left( x_1 + x_2 + \cdots + x_d \right)^n$ . In our case $d=3,\ \boldsymbol{\alpha}= (p,q,r)$ . There could be other possibilities but I'm thinking of taking $(x_1,x_2,x_3)= \left(1, \frac{1}{2}, \frac{1}{3} \right)$ then I need to find a ""simple"" function of $\boldsymbol{\alpha}$ , $f:\mathbb{N}^3 \to \mathbb{N}^3 $ which would take value $(1,0,0)$ if $p<q<r$ (i.e. if $\boldsymbol{\alpha}$ view as a function $1\mapsto \alpha_1=p,\ 2\mapsto \alpha_2=q,\ 3\mapsto \alpha_3=r$ is injective), take value $(0,1,0)$ if exactly two indices are equal (or if $\boldsymbol{\alpha}$ view as a the previous function takes only two values) and $(0,1,1)$ if $p=q=r$ . If we find such a function then the first sum can be rewritten $$\sum_{\genfrac{}{}{0pt}{1}{p\leq q \leq r}{p+q+r =n}} \frac{n!}{p!\, q!\, r!} \mathbf{x}^{f(\boldsymbol{\alpha})}$$ The final step, if possible would be to relate $\mathbf{x}^{f(\boldsymbol{\alpha})}$ to $\mathbf{x}^{\boldsymbol{\alpha}}$ by integration or derivation or maybe something different.","['multinomial-theorem', 'functions', 'combinatorics', 'multinomial-coefficients', 'algebra-precalculus']"
4003682,Computing turning number of closed curve,"I'm trying to compute the turning number of a closed plane curve, which should be a really straight forward computation. But my result is not a whole number, i.e. the total curvature is not a multiple of $2\pi$ , which is impossible so I'm making a mistake somewhere. I know from plotting the curve that the turning number should be $-2$ . I've been looking for hours but cannot seem to find it. Maybe someone can spot the mistake... Here is my work: Let $\beta(t) = ((1+2\cos(t))\sin(t), (1+2\cos(t))\cos(t))$ be a regular closed plane curve. To compute the turning number $n_{\beta}$ I want to use the following: $$n_{\beta} = \frac{1}{2\pi}\int_{0}^{L}K_{\beta}(t)dt\, ,$$ where $L$ is the period of $\beta$ and $K_{\beta}(t)$ is the curvature. I can compute the curvature like this: $$K_{\beta} = \frac{1}{||\dot{\beta}(t)||^3}\cdot\det({\dot{\beta}(t), \ddot{\beta}(t)})$$ Computations: $$\dot{\beta}(t) = (\cos t + 2\cos 2t, -\sin t -2\sin 2t)$$ $$\ddot{\beta}(t) = (-\sin t - 4 \sin 2t, -\cos t - 4 \cos 2t)$$ $$||\dot{\beta}(t))|| = (4\cos t + 5)^{1/2}$$ $$\det({\dot{\beta}(t),\ddot{\beta}(t)}) = -6 \cos t - 9$$ This is giving me the curvature $$K_{\beta}(t) = \frac{-6 \cos t -9}{(4 \cos t + 5)^{3/2}}$$ At this point I integrated the curvature with the help of Wolframalpha, which did it numerically but I'm pretty sure it's $-2\pi-1$ , when from the picture it should be $-4\pi$ . Oddly enough, if I integrate the curvature without the power of $\frac{3}{2}$ in the denominator i actually get the correct result. Can anyone help me spot my mistake? Thanks a lot! Edit: Here's a link to see the graph: https://www.desmos.com/calculator/vcxbpj2ios","['curves', 'geometry']"
4003700,Volumes of submanifolds with respect to two different riemannian metrics,"Suppose we have a compact manifold $M$ and two riemannian metrics $g_1,g_2$ . For each riemannian metric we can define the riemannian measure and for each compact submanifold $Y\subset X$ we have the induced metrics on $Y$ and we can compute the volume of $Y$ with respect to this metric. Now I know that for each $x\in M$ and $v\in T_x M$ we have that there exist constants $a,b>0$ such that $ag_x^1(v,v)\leq g_x^2(v,v)\leq bg_x^1(v,v)$ , using the fact that $SM$ is compact since $M$ is compact. Now I would like to see that for the volume of a submanifold with respect to each metric we get a similar inequality, i.e, that $aVol_1(Y)\leq Vol_2(Y)\leq bVol_1(Y) $ , and for that I belive it suffices to get such an equality for $\sqrt{G^{\alpha}}$ , where this denotes the determinant of the matrix $g_{ij}^{\alpha}=g(\frac{\partial}{\partial x_i^{\alpha}},\frac{\partial}{\partial x_j^{\alpha}})$ , for each one of the metrics. Does anyone know if this is possible and if so if how can one prove it ? (My interest in this comes from the Yomdin's Theorem for the topological entropy of the geodesic flow)","['smooth-manifolds', 'differential-geometry']"
4003737,Evaluate $\int \frac{\left(x^2+x+3\right)\left(x^3+7\right)}{x+1}dx$.,"Evaluate: $$\int \frac{\left(x^2+x+3\right)\left(x^3+7\right)}{x+1}dx$$ The only thing I can think of doing here is long division to simplify the integral down and see if I can work with some easier sections. Here's my attempt: \begin{align}
\int \frac{\left(x^2+x+3\right)\left(x^3+7\right)}{x+1}dx &= \int \left(\:x^4+3x^2+4x+3+\frac{18}{x+1} \right )dx \\
&= \int \:x^4dx+\int \:3x^2dx+\int \:4xdx+\int \:3dx+\int \frac{18}{x+1}dx \\
&= \frac{x^5}{5}+x^3+2x^2+3x+18\ln \left|x+1\right|+ c, c \in \mathbb{R}
\end{align} The only issue I had is that the polynomial long division took quite some time. Is there another way to do this that is less time consuming? The reason I ask this is that, this kind of question can come in an exam where time is of the essence so anything that I can do to speed up the process will benefit me greatly.","['integration', 'calculus', 'polynomials', 'real-analysis']"
4003756,Modified weight 2 Eisenstein series is a modular form for $\Gamma_0(N)$,"I'm doing exercise 1.2.8(e) in Diamond & Shurman's A First Course in Modular Forms . The problem is to show that $G_{2,N}(\tau) := G_2(\tau)-NG_2(N\tau)$ is in $M_2(\Gamma_0(N))$ . To show this, I need to argue that $G_{2,N}$ satisfies $G_{2,N}[\gamma]_2=G_{2,N}$ where $f[\gamma]_2(\tau):=j(\gamma,\tau)^{-2}f(\gamma(\tau))$ is the weight-2 operator for every $\gamma\in\Gamma_0(N)$ , and that $G_{2,N}$ is holomorphic on $\mathcal{H}$ and holomorphic at the cusps. So far, I proven that $G_2(\tau)$ satisfies the transformation formula $$G_2[\gamma]_2(\tau) = G_2(\tau)-\frac{2\pi ic}{c\tau+d},\;\;\;\;\gamma = \begin{bmatrix}a&b\\c&d\end{bmatrix}$$ and that $$\frac{\pi}{j(\gamma,\tau)^2\Im(\gamma(\tau))}=\frac{\pi}{\Im(\tau)}-\frac{2\pi ic}{c\tau+d},$$ and I've concluded that $G_2(\tau) - \frac{\pi}{\Im(\tau)}$ is weight-2 invariant under $SL_2(\mathbb Z)$ . I have no idea how to conclude that $G_{2,N}(\tau)$ is a modular form for $\Gamma_0(N)$ . Specifically, how does the weight-2 operator act on $G_{2,N}$ ? Is it $$G_{2,N}[\gamma]_2(\tau) = (c\tau+d)^{-2}(G_2(\gamma(\tau))-NG_2(\gamma(N\tau)))$$ or $$G_{2,N}[\gamma]_2(\tau) = (c\tau+d)^{-2}(G_2(\gamma(\tau)) - NG_2(N\gamma(\tau))?$$ In either case, $N\gamma(\tau)$ and $\gamma(N\tau)$ are not of the form $\alpha(\tau)$ for some $\alpha\in SL_2(\mathbb Z)$ , so how should $G_2(\tau)$ transform? Moreover, I don't know how to verify that $G_{2,N}$ is holomorphic on $\mathcal{H}$ or at the cusps. I would greatly appreciate detailed answers to both of these. P.S. This is not homework, I'm simply trying to better understand computational aspects of modular forms.","['complex-analysis', 'modular-forms', 'modular-group']"
4003768,Carmichael lambda function proof,"Let $\lambda$ be the Carmichael Lambda function, as defined on wikipedia . Let $a,b\in\mathbb{Z}.$ Prove the following If $a \mid  b$ then $\lambda(a) \mid\lambda(b).$ $\lambda(\operatorname{lcm}(a,b)) = \operatorname{lcm}(\lambda(a), \lambda(b))$ . I think the first statement can be shown using the unique factorization theorem and a case-by-case proof for the values of $\lambda$ on prime powers. Wikipedia says that the second statement follows immediately from the recursive definition, but I don't think this is so; there's more to it than that. However, I'm not really sure how to prove the second statement by using the first definition more closely; if $a$ and $b$ are coprime then maybe using the unique factorization theorem will help but I'm not sure how to extend this result to when $a$ and $b$ are not coprime. I'd probably start by using this result for $\frac{a}{\gcd(a,b)}$ and $\frac{b}{\gcd(a,b)}.$","['elementary-set-theory', 'number-theory', 'elementary-number-theory']"
4003831,Area bounded with curves [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I need to calculate area bounded with curves $(x^2+y^2)^2\le 3(x^2-y^2), x^2+y^2\le \sqrt{2}x$ . Here we have inside of leminscate and circle. I think i should use that $P=\iint dxdx$ but not sure how.","['integration', 'multivariable-calculus', 'area']"
4003853,"〈b, a, b〉 and 〈a, b, a〉: For what non zero values of a and b are these two vectors parallel?","Looking for a hint on how to solve this problem.
I know for the vectors to be parallel, the cross product must equal the zero vector, but I'm unsure on how to use that information to solve for values. $\langle b, a, b\rangle \times\langle a, b, a\rangle$ . For what non zero values of $a$ and $b$ are these two vectors parallel?","['multivariable-calculus', 'calculus', 'vectors']"
4003864,UMVUE for some function $\tau(\theta)$ when $f(x;\theta)=\frac{\ln(\theta)}{\theta -1} \theta^x$,"I need to find an UMVUE for some function $\tau(\theta)$ for $X_1, \dots, X_n$ random variables with $f(x;\theta)=\frac{\ln(\theta)}{\theta -1}  \theta^x$ where $x\in (0,1)$ . I know that $\sum_{i=1}^{n}X_i$ is a Sufficient and complete statistic, but I don't know which function to choose such that it turns out to be an unbiased estimator. Any hint?","['statistics', 'parameter-estimation', 'random-variables']"
4003900,"Analytic expression for $\mathbb E_X[(X^\top u)^p (X^\top v)^p]$, where $u$ and $v$ are fixed vectors in $\mathbb R^d$ and $X$ is uniform on sphere","Let $u$ and $v$ be fixed vectors in $\mathbb R^d$ . Let $X$ be a random vector uniformly distributed on the unit-sphere in $\mathbb R^d$ , and let $f_p$ be a real polynomial of degree $p \ge 1$ (for simplicity, we might simply consider $f_p(t) \equiv t^p$ ). Question. What is an analytic expression for the correlatetion $c(u,v) := \mathbb E_X[f(X^\top u)f(X^\top v)]$ ? Special case $p=1$ In this case, a simple computation gives $$
c(u,v) = \mathbb E[X^\top uv^\top X] = \mbox{trace}(\mbox{cov}(X)uv^\top) = \mbox{trace}((1/d) I_d uv^\top) = \frac{u^\top v}{d}
$$ Is it too crazy to conjecture that in general, $c(u,v) = K_{d,p} \cdot (u^\top v)^p$ , for some constant $K_{d,p}$ which only depends on $d$ and $p$ ?","['statistics', 'covariance', 'tensors', 'functional-analysis', 'probability']"
4003905,Prove that $\sum_{n=1}^{\infty}\frac{q^n}{1+q^{2n}}=\sum_{n=1}^{\infty}(d_1(n)-d_3(n))q^n$,Prove that $$\sum_{n=1}^{\infty}\frac{q^n}{1+q^{2n}}=\sum_{n=1}^{\infty}(d_1(n)-d_3(n))q^n$$ where $d_1(n)$ is the number of divisors of $n$ congruent to $1$ modulo $4$ and $d_3(n)$ is the number of divisors of $n$ congruent to $3$ modulo $4$ . I tried using the geometric series and interchanging the sum but that did not yield anything useful. I would prefer a algebraic solution rather than a one that depends on partitions but both are welcome. Thanks!,"['integer-partitions', 'sequences-and-series']"
4003914,"$A \oplus B \cong A \oplus C$ implies $B \cong C$ where $A,B,C$ are finitely generated $R$ modules and $R$ is a PID","There are number of similar questions to this, but I have read through them all and the answers either rely on results that I don't have access to or I'm unsure how to translate them to this situation. The exact problem is as follows. Suppose $R$ is a PID, $A,B$ and $C$ are finitely generated $R$ modules and that $A \oplus B \cong A \oplus C$ , then $B \cong C$ . It seems like we should be able to apply the structure theorem for finitely generated modules over a PID. In the version I'm most familiar with, this result says that given a PID $R$ and an $R$ module $M$ , we have that $$
M \cong R^n \oplus R/(a_1) \oplus ...\oplus R/(a_m)
$$ where $n \in \mathbb{N}$ , $a_i \in R$ , and $a_1|a_2|...|a_n$ . Further, if $$
M \cong R^s \oplus R/(b_1) \oplus ...\oplus R/(b_t)
$$ and $b_1|...b|t$ , then we have that $n=s$ , $m=t$ and $a_i$ is associate to $b_i$ for all $a_i$ . Applying that to this problem at hand, we can write down decompositions for $A,B$ , and $C$ : $$
A \cong R^a\oplus R/(a_1)\oplus ... \oplus R/(a_l)
$$ $$
B \cong R^b\oplus R/(b_1)\oplus ... \oplus R/(b_m)
$$ $$
C \cong R^c\oplus R/(c_1)\oplus ... \oplus R/(c_n)
$$ So we have that $$
R^a\oplus R/(a_1)\oplus ... \oplus R/(a_l) \oplus R^b\oplus R/(b_1)\oplus ... \oplus R/(b_m) \cong R^a\oplus R/(a_1)\oplus ... \oplus R/(a_l) \oplus R^c\oplus R/(c_1)\oplus ... \oplus R/(c_n) 
$$ $$
R^{a+b}\oplus R/(a_1)\oplus ... \oplus R/(a_l) \oplus R/(b_1)\oplus ... \oplus R/(b_m) \cong R^{a+c} \oplus R/(a_1)\oplus ... \oplus R/(a_l) \oplus R/(c_1)\oplus ... \oplus R/(c_n) 
$$ What I would like to do here is to apply the uniqueness part of the structure theorem I referenced above, but it is not at all clear to me why the divisibility condition on the invariant factors would still hold, since now we have factors from from $A$ and $B$ on the left hand side and the same problem on the right. What am I missing here? Is this easier to understand with the elementary divisor form? Also as I mentioned at the beginning, I know there are some similar questions already posed, but I have read them and I am still unsure, so if you give a link to another question please try to explain more precisely how that question applies.","['principal-ideal-domains', 'abstract-algebra', 'modules']"
4003919,Hard limit - integral with trigonometric function in the exponent yield $\pi$,"The function: $$ \frac{1}{x^{2 \cos (x)} + 1}$$ Looks like it is built out of these bricks, which keep on forever: The ""length"" of each one of them is $\sim2 \pi$ meaning that each block sits on $[ 2d \pi , 2 (d+1) \pi]$ for all $d \in \mathbb{N}$ But because I am highly confident these bricks are not the same - because they depend on $x$ and for each value of $x$ the block will be more and more ""fixed"". I tried to calculate using a program and found that: $$ \int_{2 \pi}^{4\pi} \frac{1}{x^{2 \cos (x)} + 1} ~ dx \approx \pi$$ But not quite, it only goes to pi as we increase the bounds (but keep them $2 \pi$ from each other), and so I thought to declare it as: $$ \lim_{a \to \infty} \int_{2 a \pi}^{2(a+1)\pi} \frac{1}{x^{2 \cos (x)} + 1} ~ dx = \pi$$ One thing to note: even by removing the $2$ from the exponent, keeps the answer close to $\pi$ . Meaning that also: $$ \int_{2 \pi}^{4\pi} \frac{1}{x^{\cos (x)} + 1} ~ dx \approx \pi$$ Is it written correct (mathematically) because I need $a$ to be a whole number, but how can I write it in this limit form? Is there any way to prove this? a rigorous proof or any simplifications to do here? trigonometric exponents are pretty tricky and hard to deal with, and I've tried all the ways I could think of - $u$ -sub, trig-sub, Feynman's method etc.. Renaming $\cos(x) \to t = \frac{t}{1} \\ - \sin(x) dx = dt \\ dx = \frac{1}{\sqrt{1-t^2}} dt$ $$ \int \frac{1}{x^{2 \cos (x)} + 1} ~ dx  = -\int \frac{1}{(x^{2t} +1)} \cdot \frac{1}{\sqrt{1-t^2}} ~ dt $$ The problem is that we are stuck with this $x$ and not $t$ .. Any help would be appreciated! This is not for a specific class, no main ""topic"" other than integrals and calculus as far as I know. I unfortunately don't have a reference / contex.","['integration', 'calculus', 'definite-integrals', 'trigonometry']"
4003923,Conceptual (homological) interpretation of a theorem about flat modules,"I just learned the following beautiful result about flat modules from J. S. Milne's book Étale Cohomology : Lemma 2.10(b'): Let $M$ be any flat $A$ -module. If $$\sum_i a_ix_i=0,$$ $a_i\in A$ , $x_i\in M$ , then there are equations $$x_i = \sum_j a_{ij}x_j'$$ with $x_j'\in M$ , $a_{ij}\in A$ , such that $$\sum_i a_ia_{ij} = 0$$ for all $j$ . It is stated under the hypothesis that $A$ is a commutative, noetherian ring, but as far as I can tell, the proof does not use noetherianity. (Actually I am not sure it even uses commutativity, but I will leave that matter alone for the purposes of this question.) The proof given in Milne is essentially computational. However, the result struck me as almost a statement that something is exact (I'll make this precise in a moment), and of course flatness is all about exactness, so I wondered, is there a conceptual argument, or at least some reasonably satisfying conceptual handwaving, that gives us the claimed result in terms of an assertion that something is exact, or some (co)homology vanishes, in a way that is straightforwardly connected to $M$ 's flatness? (I'm using the soft-question tag because, while there could easily be a fully precise answer [which would be best possible], I will probably be happy with what I'm calling ""satisfying conceptual handwaving,"" and what I mean by ""straightforwardly"" isn't precise either. Apologies in advance about this vagueness.) Here is what I mean when I say the result struck me as ""almost a statement that something is exact"". The tuple $(a_i)_{i=1,\dots,r}$ defines a map $\varphi: M^r\rightarrow M$ by $$(y_i)_{i=1,\dots,r} \mapsto \sum_i a_iy_i.$$ If $A$ is commutative, this is a map of $A$ -modules. Then the equation $$\sum_i a_ix_i=0$$ asserts that $(x_1,\dots,x_r)\in M^r$ lies in the kernel of this map. Similarly, the matrix $(a_{ij})$ defines a map $\psi: M^s\rightarrow M^r$ by $$(y'_j)_{j=1,\dots,s}\mapsto \left(\sum_j a_{ij}y'_j\right)_{i=1,\dots,r},$$ whereupon the equations $$\sum_i a_ia_{ij} = 0$$ assert that the composed map $\psi\circ\varphi = 0$ , and the equations $$x_i = \sum_j a_{ij}x_j'$$ assert that $(x_1,\dots,x_r)$ lies in the image of $\psi$ . Thus the lemma ""comes close"" to asserting that we have a complex $M^s\xrightarrow{\psi} M^r \xrightarrow{\varphi} M$ which is exact in the middle. It is not actually asserting this because the matrix $(a_{ij})$ is allowed to depend on the tuple $(x_i)$ (and the proof indeed requires the data of the $(x_i)$ for the construction of the $(a_{ij})$ ). So the real statement is: given an $A$ -linear map $\varphi: M^r\rightarrow M$ defined by a tuple $(a_1,\dots,a_r)$ , and given an element $(x_1,\dots,x_r)$ of the kernel of this map , there is an $A$ -linear map $\varphi: M^s\rightarrow M^r$ defined by a matrix $(a_{ij})$ , such that $M^s\rightarrow M^r\rightarrow M$ forms a complex and the particular given $(x_1,\dots,x_r)\in M^r$ lies in the image of $\psi$ . There is no assertion that the entire kernel of $\varphi$ is exhausted by the image of $\psi$ . Nonetheless, these musings are sufficiently suggestive to me that I wanted to ask here: can you explain Milne's Lemma 2.10(b') in terms of the exactness of something, or the vanishing of some homology or cohomology, in a way that is evidently linked to $M$ 's flatness over $A$ ?","['homological-algebra', 'abstract-algebra', 'flatness', 'soft-question', 'commutative-algebra']"
4003938,Normal modes in physics - solution of set of 2nd order linear differential equations,"In physics we study normal modes for vibrating system. Mathematically speaking we have a set of linear differential equations. For example we have something like this: $$
\begin{align*}
m \frac{dx_1}{dt^2} &= k(x_2-x_1) \\ 
M \frac{dx_2}{dt^2} &= k(x_3-x_2) - k(x_2-x_1) \\
m \frac{dx_3}{dt^2} &= -k(x_3-x_2)
\end{align*}
$$ We seek solutions for $x_i(t)$ . A general solution is to assume to look for these functions to be sines, cosines or exponents for all $x_i(t)$ having the same frequency $\omega$ . For above example our solution would be something like: $$
\begin{align*}
x_1 (t) &= A e^{\omega t + \varphi} \\ 
x_2 (t) &= B e^{\omega t + \varphi} \\
x_3 (t) &= C e^{\omega t + \varphi}
\end{align*}
$$ I could not find a clear explanation why we assume that we seek solution with the same $\omega$ (normal modes), and later why the general solution is the superposition of all such solutions (we obviously find . Many thanks for comments and explanation.","['physics', 'ordinary-differential-equations']"
4003948,"$Φ : V → V$ all such linear mappings have same determinant, what does it mean?","In the Book that I'm reading (Mathematics for Machine Learning), the following para is given, while listing the properties of a matrix determinant: Similar matrices (Definition 2.22) possess the same determinant.
Therefore, for a linear mapping $Φ : V → V$ all transformation matrices $A_Φ$ of $Φ$ have the same determinant. Thus, the determinant is invariant
to the choice of basis of a linear mapping. I know that matrices $A$ and $B$ are similar if they satisfy $B=C^{-1}AC$ .
I can prove that determinants of such $A$ and $B$ are equal using other properties of a determinant. But beyond that I don't understand what this paragraph is saying. I can understand all matrices $Y$ such that $Y=X^{-1}AX$ have the same determinant as $A$ , for varying $X$ s. But how do I connect this to linear mappings of the form $Φ : V → V$ . What does $Φ : V → V$ mean here? Maybe someone can give me an example. EDIT:
This video is pretty basic, but it helped me understand better https://www.youtube.com/watch?v=s4c5LQ5a4ek","['determinant', 'matrices', 'machine-learning', 'linear-algebra', 'linear-transformations']"
4003978,Lusin’s Theorem for Polish spaces with infinite Radon measure,"I’m working on the following exercise in Klenke’s Probability Theory: A Comprehensive Course (Exercise 13.1.3), which asks us to prove the following generalization of Lusin’s Theorem: Let $\Omega$ be a Polish space, let $\mu$ be a $\sigma$ -finite measure on $(\Omega, \mathcal B(\Omega))$ , and let $f : \Omega \to \mathbb R$ be a map. Show that the following are equivalent: There is a Borel measurable map $g : \Omega \to \mathbb R$ with $f = g$ almost everywhere. For any $\epsilon > 0$ , there is a compact set $K_\epsilon$ with $\mu(\Omega \setminus K_\epsilon) < \epsilon$ such that the restricted function $f|_{K_\epsilon}$ is continuous. As stated, this exercise is wrong when $\mu(\Omega) = \infty$ : if $\Omega = \mathbb R$ , no compact set has a complement with finite Lebesgue measure, so it should be a closed set $K_\epsilon$ . Furthermore, $\mu$ must be more than just $\sigma$ -finite. Let $\Omega = \mathbb R$ , and $\mu = \sum_{q \in \mathbb Q} \delta_q$ be the counting measure of the rationals. Then $\mu$ is certainly $\sigma$ -finite, but if $f$ is a Borel-measurable map and if $K \subset \mathbb R$ is closed with $\mu(K^c) < \epsilon$ for $\epsilon < 1$ , then we must have $\mu(K^c) = 0$ , or $K \supset \mathbb Q$ . But then since $K$ is closed, $\overline{\mathbb{Q}}= \mathbb R \subset K$ , so $f$ must be continuous on $\mathbb R$ in order for the claim to hold. So we need more than $\sigma$ -finite. One way to edit the exercise is to instead assume $\mu$ is Radon and modify Statement 2 like so: There is a Borel measurable map $ g : \Omega \to \mathbb R$ with $f = g$ $\mu$ -a.e. For any subset $A \subset \Omega$ with $\mu(A) < \infty$ , and for any $\epsilon > 0$ , there is a compact $K_\epsilon \subset A$ such that $f|_{K_\epsilon}$ is continuous. These statements may be shown to be equivalent, since one can show Radon measures on Polish are $\sigma$ -finite (see the discussion below). But suppose we want to show the “original” Statement 2: For any $\epsilon > 0$ , there is a closed $K_\epsilon \subset \Omega$ with $\mu(K_\epsilon^c) < \epsilon$ such that the restricted function $f|_{K_\epsilon} : K_\epsilon \to \mathbb R$ is continuous. What conditions must we impose on the Polish space $\Omega$ with infinite Radon measure $\mu$ in order to guarantee that this is true?","['measure-theory', 'measurable-functions', 'polish-spaces']"
4003992,"Nonattacking ""queens"" on tiled triangles","I'll start with what my question is not. My question is not Nonattacking rooks on a triangular chessboard or The number of spacing $k$ non-attacking towers on the board $\left\{(i,j):1 \le i \le j \le n \right\}$ . Those questions are about taking a square grid and making a ""triangular chessboard"" by removing the squares of a chessboard above the diagonal. My question is about tiled triangles of the following form (not truncated square grids): I will define a ""queen"" on this tiled triangle to attack in the three directions parallel to the triangle on which the queen is located. Below, I have placed a queen on the darkest blue triangle and the light blue triangles are where the queen attacks. I am interested in the maximal number of non-attacking queens I can place on this tiled triangle. For example, I can imagine placing down queens until every triangle is under attack: Or, as another example, My questions are: For a tiled equilateral triangle of side length $n$ , what is the maximal number of non-attacking queens I can add to the triangle? How many configurations have the maximal number of non-attacking queens? By side length, I mean for example that the above tiled triangles have a side-length of five. I think my trouble has been that I'm unsure of a good coordinate system for the tiled triangle. It's two dimensional, but I take out three straight lines corresponding to the horizontal, diagonal, and antidiagonal directions when I add a queen. Further, knowing which horizontal row and diagonal I am in does not typically fix the antidiagonal I am in (there are typically two choice for the antidiagonal). From inspection, it looks like the maximum number of non-attacking queens on a tiled triangle of sidelength $n$ is $\lceil n/2 \rceil$ . Maybe induction on the length of the sides could work? It looks like adding row of triangles at the base of a maximal-number-of-queens odd $n$ triangle gives a maximal number-of-queens even $n+1$ triangle, but I am unsure of how to show this.","['chessboard', 'combinatorics']"
4004044,What is wrong with my derivation of the general formula of the power series for $\cos^{2}(x)$,"I have arduously obtained the series for $\cos^2(x)$ by using long multiplication method (multiplying twice the Taylor series of $\cos(x)$ which is $\sum_{n=0}^{+\infty} \frac{(-1)^nx^{2n}}{(2n)!}$ $$\cos^2(x)=1-x^2+\dfrac{1}{3}x^4-\dfrac{2}{45}x^6+\dfrac{1}{315}x^8+...$$ I wish to manipulate with the sigma notation to reduce the cost of labour, so I square the above general formula for $\cos(x)$ : $$\cos^2(x)=\sum_{n=1}^{+\infty} \left(\frac{(-1)^nx^{2n}}{(2n!)}\right)^2=\sum_{n=1}^{+\infty} \dfrac{(-1)^{2n}x^{4n}}{[(2n)!]^2}$$ But this is plain wrong, the formula that I obtain is not the general formula for the series of $\cos^2(x)$ . So what is wrong with my manipulation with the sigma notation of this series. The power of $x$ and $-1$ is too high, it should be $2n$ . Also, is my denominator correct? How do you obtain the general formulae for this series?","['analysis', 'calculus', 'taylor-expansion', 'sequences-and-series', 'power-series']"
4004092,Partial derivative vs Total derivative,"Are partial derivative and total derivative different for a system with independent variables?
The term $\frac{df(x,y)}{dx} = \frac{\partial f(x,y)}{\partial x}+\frac{\partial f(x,y)}{\partial y}\frac{dy}{dx}$ . But as $y$ and $x$ are independent, so $\frac{dy}{dx} = 0$ . So, how are two different?","['partial-derivative', 'derivatives']"
4004096,Proof that $\sum 2^{-i}X_i$ converges in distribution to a uniform distribution,"Question: Let $X_1, X_2, \ldots, X_n$ be independent and identically distributed random variables such that: $$P(X_i = 1) = P(X_i = -1) = \frac{1}{2}$$ Derive the moment generating function of $Y_n := \sum^n_{i=1} a_iX_i$ where $a_1, \ldots, a_n$ are constants.
Then, let $a_i = \frac{1}{2^i}$ and show that $Y_n$ converges in distribution to the uniform distribution on $(-1, 1)$ . Attempt: For the moment generating function: $$M_{Y_n}(t) = \mathbb{E}(e^{t(a_1x_1 + ... +a_nx_n)}) = \prod_{i=1}^n \mathbb{E}(e^{ta_iX_i}) = \frac{1}{2^n} \prod_{i=1}^n (e^{ta_i} + e^{-ta_i})$$ (Using $\mathbb{E}(e^{ta_iX_i}) = \frac{1}{2} (e^{ta_i} + e^{-ta_i})$ .) However, I'm not sure about the distribution function. So far, I can show that: $Y_n := \sum^n_{i=1} \frac{1}{2^i} X_i$ , and since $-1 \leq X_i \leq 1$ , $-\sum^n_{i=1} \frac{1}{2^i} \leq Y_n \leq \sum^n_{i=1} \frac{1}{2^i} \quad \Rightarrow \quad -1 \leq \lim Y_n \leq 1$ . I'm not sure how to proceed from here, because I feel like my next few lines are lacking rigor. I wrote: Hence, $\forall x < -1, \quad  \lim P(Y_n \leq x) = 0$ , and $\forall x > 1, \quad \lim P(Y_n \leq x) = 1$ Which is so far consistent with the distribution function of the uniform distribution. However, I am unsure if this is correct, and of how to tackle the case for $-1 \leq x \leq 1$ . Any suggestions and corrections would be appreciated, thank you!","['statistics', 'probability-distributions', 'moment-generating-functions', 'convergence-divergence', 'probability-theory']"
4004104,A geometric proof for the inequality $\frac{2x}{\pi} \le \sin(x)$,"The inequality $\frac{2x}{\pi}\le \sin(x)\le x$ for $0 \le x\le \frac \pi 2$ is well known; it can be proved using calculus. The second part can be proved for $x\in [0,\pi/2]$ by geometric arguments: Take unit circle with center origin. Then compare areas of (sector with angle $x$ ) and (right angled triangle with height $\sin x$ ). Q. Can we prove $\frac{2x}{\pi}\le \sin(x)$ for $x\in [0,\pi/2]$ by geometric arguments? Note: There are proof of first inequality are available using calculus, but I want to know if there is a proof, not based on calculus (Rolle's theorem, or mean value theorem etc.), but with some basic geometric arguments as done in the proof of $\sin(x)\le x$ .","['trigonometry', 'inequality']"
4004141,"Prove that $16(a\sin a + \cos a - 1)^2 \le 2a^4 + a^3 \sin 2a, \ \forall a\ge 0$","Problem 1 : Prove that $$16(a\sin a + \cos a - 1)^2 \le 2a^4 + a^3 \sin 2a, \ \forall a\ge 0.\tag{1}$$ This is the stronger version of the following Prove that $12(a\sin a+\cos a-1)^2\le 2a^4+a^3\sin(2a)$,$\forall a\in (0,\infty)$ : Problem 2 : Prove that $$12(a\sin a + \cos a - 1)^2 \le 2a^4 + a^3 \sin 2a, \ \forall a\ge 0. \tag{2}$$ For Problem 2, there is a very nice solution using Cauchy-Bunyakovsky-Schwarz inequality for integral Prove that $12(a\sin a+\cos a-1)^2\le 2a^4+a^3\sin(2a)$,$\forall a\in (0,\infty)$ .
Indeed, the inequality (2) is nothing but $$12\left(\int_0^a x\cos x \mathrm{d} x \right)^2 \le 12\left(\int_0^a x^2 \mathrm{d} x\right)
\left(\int_0^a \cos^2 x \mathrm{d}x\right).$$ For Problem 2, I gave a complicated proof. See Prove that $12(a\sin a+\cos a-1)^2\le 2a^4+a^3\sin(2a)$,$\forall a\in (0,\infty)$ Are there any nice solutions for Problem 1? Any comments and solutions are welcome and appreciated.","['calculus', 'inequality', 'real-analysis']"
4004170,Recurrence relations for strings of $0$'s and $1$'s of length $n$ where no $k$ consecutive $1$'s appear.,"This question is related to this one , but the answers there do not explain my confusion. This is exercise 20 in page 28 in the book generatingfunctionology : Let $f(n,m,k)$ be the number of strings of $n$ $0$ 's and 1's that contain exactly $m$ $1$ 's, no $k$ of which are consecutive. Then (a) Find a recurrence formula for $f$ . It should have $f(n,m,k)$ on the left side, and exactly three terms on the right. (b) Find, in simple closed form, the generating functions $$ F_k(x,y)=\sum_{n,m\geq 0}f(n,m,k)x^ny^m\quad(k=1,2,...)$$ Here's what I have: I didn't get exactly three terms in the recurrence, but I did come up with one plausible. Well, we want to use $n-m$ $0$ 's to separate $m$ $1$ 's. That's the same as putting $m$ balls into $n-m+1$ ordered boxes, and each box can at most contain $k-1$ balls. We divide the cases by how many balls the last box has: it could be $0,1,...,k-1$ . Hence we have the recurrence relation: $$f(n,m,k)=\sum_{i=1}^{k}f(n-i,m-i+1,k)$$ This recurrence should hold for arbitrary $n,m,k$ as long as we specify the appropriate initial values, or at least it should hold for $k$ large enough. (This might be where I ran into problems but I can not see it immediately). However, when I carry this to the next part I am confused, because \begin{aligned}
 F_k(x,y)& = \sum_{n,m\geq 0}f(n,m,k)x^ny^m \\
& = \sum_{n,m\geq 0}\sum_{i=1}^{k}f(n-i,m-i+1,k)x^ny^m \\
& = \sum_{i=1}^k\sum_{n,m\geq 0}f(n-i,m-i+1,k)x^ny^m \\
& = \sum_{i=1}^kx^iy^{i-1}\sum_{n,m\geq 0}f(n-i,m-i+1,k)x^{n-i}y^{m-i+1}\\
& = \sum_{i=1}^kx^iy^{i-1}F_k(x,y)
\end{aligned} The second to bottom equality holds in my mind because $f(m,n,k)=0$ if either of $m$ or $n$ is $0$ . However, it confuses me since at the end the equation implies $F_k(x,y)=0$ ? Where did I go wrong? Any kind of help would be appreciated.","['combinatorics-on-words', 'combinatorics', 'recurrence-relations', 'generating-functions']"
4004171,Prove that the midpoint of $AH$ lies on the radical axis of $(REC)$ and $(QFB)$.,"The incircle of $\triangle ABC$ , centered at $I$ , touches $AC$ and $AB$ at $E$ and $F$ , respectively. Let $H$ be the foot of the altitude from $A$ and let $R = CI \cap AH$ and $Q = BI \cap AH.$ Prove that the midpoint of $AH$ lies on the radical axis of $(REC)$ and $(QFB)$ . The source is Peru TST. Progress: Let $X:=$ midpoint of $AH.$ $J,G$ as point of intersection of $(REC)$ and $(QFB).$ Let the perpendicular to $BC$ from $B$ and $C$ intersect $(QFB)$ and $(REC)$ at $K$ and $L.$ Claim: $G$ lies on $BC$ Proof: For this we will define $G':=(QFB)\cap BC.$ And we will show that $G'\in (RFC).$ For this note that since $BQ$ is angle bisector, we get $FQ=QG'.$ ( using incentre-excentre lemma). But $FQ=QD$ by angle bisector property. So $FQ=QG'=QD.$ So $G'$ and $D$ are reflection of each other wrt altitude. Hence $RG'=RD.$ But $RD=RE.$ So $RG'=RE.$ So by converse of incentre -excentre lemma, we get $G=G'$ . Now note that $K-J-L$ are collinear. This is because by cyclicity, $\angle GBK=90=\angle GJK$ and $GCL=90=\angle GJL.$ So $KJL\perp GJ.$ So enough to show $XJ\perp KJL.$ I also thought of introducing $A-$ excentre, because $X-D-I_A$ are collinear( well known). Any elementary solutions ( not using trig, vectors, complex or any calculative stuff)?","['contest-math', 'euclidean-geometry', 'geometry']"
4004353,Calculate integral $\int_0^{\pi/2} \frac{\cos^3x}{\sin^2x + \cos^3x}dx$.,"Calculate integral $$\int_0^{\pi/2} \frac{\cos^3x}{\sin^2x + \cos^3x}dx.$$ My direction: Since this integral can't calculate normally, I tried to use the property following: $$\int_{a}^{b}f(x)dx = \int_{a}^{b}f(a+b-x)dx.$$ Then, I have $$I=\int_0^{\pi/2} \frac{\cos^3x}{\sin^2x + \cos^3x}dx = \int_0^{\pi/2} \frac{\sin^3x}{\cos^2x + \sin^3x}dx.$$ Therefore $$2I = \int_0^{\pi/2} \left(\frac{\cos^3x}{\sin^2x + \cos^3x} + \frac{\sin^3x}{\cos^2x + \sin^3x}\right) dx.$$ I stucked here.","['integration', 'calculus', 'definite-integrals', 'trigonometric-integrals']"
4004357,Proving $\int_0^1 \frac{(\ln(x))^5}{1+x} \mathrm{d}x = -\frac{31\pi^6}{252}$,"I would like to show the following identity: $$\boxed{
I := 
\int_0^1 \dfrac{(\ln(x))^5}{1+x} \mathrm{d}x =
-\dfrac{31\pi^6}{252}
}$$ Here is what I tried.
The change of variables $u=1/x$ yields
$$I=
\int_1^{\infty} \dfrac{(\ln(x))^5}{1+1/u} \dfrac{1}{u^2} \mathrm{d}u =
\int_1^{\infty} \dfrac{(\ln(x))^5}{u^2+u} \mathrm{d}u$$
Then $z=u-1$ gives
$$I = \int_{0}^{\infty} \dfrac{(\ln(z+1))^5}{z^2+3z+2} \mathrm{d}z $$
with $z^2+3z+2=(z+1)(z+2)$.
I wanted to use contour integration like here , but I was not sure how to proceed in this case. Anyway, the computations of the residues (of which ""well-chosen"" function? Maybe something like this ?) seem to be difficult. I believe that we can generalize to $\frac{(\ln(x))^n}{1+x}$, or maybe even more (e.g. $\frac{(\ln(x))^n}{ax^2+bx+c}$).
Related computations are: (1) , (2) , (3) , (4) . Thank you for your detailed help.","['integration', 'definite-integrals', 'calculus', 'contour-integration', 'closed-form']"
4004414,Algebraic and definable closure of a vector space is a span of its subset,"I am trying to show that for every infinite $K$ -vector space $V$ (we use the first order language of vector spaces over $K$ ) and each $A \subseteq V$ , $acl(A)$ is the $K$ -linear subspace of $V$ spanned by $A$ . The general notion I got is that it follows from strong minimality, yet I cannot see a connection between the two. How should I start thinking about it? Is it also true for a definable closure? EDIT [as suggested by @Berci in the comments]: Definitions The first-order language of vector spaces is: a constant $0$ , a binary function "" $+$ "", and a unary function symbol $F_a$ for each $a\in K$ . Given a $K$ -vector space $V$ , $0$ is interpreted by the identity element of $V$ , "" $+$ "" is interpreted by the addition of $V$ , and each $F_a$ is interpreted by the operation of scalar multiplication by $a$ . $acl(A)$ is the set of elements of $M$ that are algebraic over $A$ in an $L$ -structure $\mathcal{M}$ . An element $a$ of $M$ is algebraic over $A$ in $\mathcal{M}$ if there is an $L$ -formula $\phi(x,y_1,\ldots,y_n)$ and elements $e_1,\ldots , e_n$ of $A$ such that: (i) $\mathcal{M}\models \phi [a,e_1,\ldots ,e_n]$ AND (ii) $\{c\in M|\mathcal{M}\models[c, e_1, \ldots ,e_n]\}$ is finite.","['first-order-logic', 'model-theory', 'logic', 'vector-spaces', 'linear-algebra']"
4004433,"Function ""evaluation"" just means ""composition""?","I am self-studying and have a basic or naive question that follows from a simple observation. I have also included tags for type theory, etc because ""evaluation"" probably has a different meaning in these constructive approaches, which I'm also curious about. Any set $X$ with elements $x_i$ can be characterized by a set denoted $(X)$ of pairs $(\star, x_i)$ , alternatively denoted $(\star \mapsto x_i)$ (for all $x_i \in X$ ). Each one of these latter pairs encodes a distinct function from common domain $\{ \star \}$ to (each different element of) $X$ . If we name such functions after their image, i.e. $(x_i):\star \mapsto x_i$ , then the symbol "" $f(x_i)$ "", traditionally interpreted as function evaluation , is reinterpreted as function composition , i.e. $f\circ (x_i)$ and the $\circ$ is often notationally suppressed. And roughly, $f = \cup_xf(x)$ , every function decomposes to a unique set of singleton functions (better word?). Question: Is there anything more to evaluation, or can I exactly equate evaluation with composition and forever de-clutter my mind of the term ""evaluation""? Is the above perspective unusual or fruitful beyond reducing terminological clutter? The notion of evaluation above - perhaps ""extensional"" is the right term? - means essentially subsetting the function at the chosen argument $x$ . Perhaps I will see that a full answer to my question requires considering an intentional (?) or constructive perspective on ""evaluation"" (as in lambda calculus, etc). Perhaps only there will composition and evaluation legitimately have distinct meanings. Edit: The notation $(x)$ seemed the most natural way to denote any function with singleton domain because it coheres with the conventional way to write evaluation as $f(x)$ . The notation seems unambiguous because there is no context I can think of, other than ""evaluation"", where a single symbol, say $x$ , is enclosed in brackets ""()""? It does seem useful to notationally distinguish functions on singleton domain in some way: I would like the notation to be a mnemonic for whether the resulting function composite is a singleton function (i.e. a ""value"" like $f(x_i) = f \circ (x_i) = (\star, y_j)$ ) versus a non-singleton function. Perhaps there is a conventional notation for functions from singleton domain, other than $(x)$ and a conventional name for such functions, other than ""singleton functions""?","['lambda-calculus', 'functions', 'type-theory', 'category-theory']"
4004465,The value of $\sin\left(\frac{1}{2}\cot^{-1}\left(\frac{-3}{4}\right)\right)$,"What is the value of this expression : $$\sin\left(\frac{1}{2}\cot^{-1}\left(\frac{-3}{4}\right)\right)$$ Using calculator and wolfram alpha, the answer is, $-\frac{1}{\sqrt{5}}$ But, by solving it myself the result comes out to be different. My solution is as follow: $$\begin{aligned} Put,\, &\cot^{-1}\left(\frac{-3}{4}\right) = \theta
\\\implies &\cot(\theta) = \frac{-3}{4} =\frac{b}{p}
\\So,\,&\cos(\theta) = \frac{-3}{5}\end{aligned}$$ $$\begin{aligned}\\Then,
\\\sin\left(\frac{1}{2}\cot^{-1}\left(\frac{-3}{4}\right)\right) &= \sin\left(\frac{\theta}{2}\right) \\&= \sqrt{\frac{1-\cos{\theta}}{2}}
\\&= \sqrt{\frac{1+\frac{3}{5}}{2}}
\\&= \frac{2}{\sqrt{5}}
\end{aligned}$$ This solution is used by a lot of websites. So, I got two different values of single expression but I am not sure which one is correct. Can you point out where I have done the mistake?",['trigonometry']
4004500,"How to integrate $\int_{0}^{2\pi}\cos x\times \exp\left [ \frac{a}{\cos x}\right]\,dx$","$$\int_{0}^{2\pi}\cos x\times \exp\left [ \frac{a}{\cos x}\right]\,dx$$ where $a$ is complex parameter. ( Integral does not converge if $a$ is Real ) I tried to solve it by two methods. The first is direct replacement $z=e^{ix}$ . After that the integral goes to $$-\frac{i}{2}\oint_{\left| z \right| < 1}\frac{1+z^2}{z^2}\exp{\left[\frac{2az}{z^2+1}\right]}\,dz$$ Before switching to complex numbers, you can use substitution $t=1/\cos x$ to reduce this integral to the form: $$2\int_{0}^{+\infty }\frac{e^{at}}{t^2\sqrt{t^2-1}}\,dt$$ And after that we can go to complex plane. But because of the complex contours, integrating in both cases is a difficult task for me.","['complex-analysis', 'complex-integration', 'definite-integrals']"
4004526,"Very simple to state, but..... (Quadrilateral and its diagonal's adventure.)","Let $ABCD$ be a quadrilateral. $BA$$\cap$ $CD$ = $K$ , $BC$$\cap $$AD$ = $M$ . $O$ is the intersection of the diagonals. The segment parallel to $MK$ and goes through $O$ meet at sides $BC$ and $AD$ at $E$ and $F$ , respectively. Then prove that $EO$ = $OF$ . My try: Let $BF$$\cap $$MK$ = $P$ and $BD$$\cap$ $MK$ = $Q$ . From here, if we can prove $P, D, E$ are collinear, we can say $MQ=QP$ by the Ceva theorem. Moreover it will be $EO$ = $OF$ . However, I can't prove it at all. Can you guys give me some hints? I don't know any complex, vector and projective geometry, so please consider giving me an Euclidean one.","['contest-math', 'euclidean-geometry', 'quadrilateral', 'geometry']"
4004559,Truncated Taylor series of the exponential,"Let $N \in \mathbb N^*$ , $\delta > 0$ , $t > 0$ and consider \begin{equation}
f(t,\delta, N)= e^{-t/\delta} \sum_{k=0}^{N-1}\frac{(t/\delta)^k}{k!}. \qquad \qquad \qquad (1)
\end{equation} Let now $N = \lceil\delta^{-\gamma}\rceil$ , with $0 < \gamma < 1$ . Can we conclude that \begin{equation}
\lim_{\delta \to 0} f(t,\delta,\lceil \delta^{-\gamma}\rceil)=0,
\end{equation} for all $t > 0$ ? The reasoning is that if $N \to \infty$ (for $\delta$ fixed), then the sum tends to $e^{t/\delta}$ and therefore $f(t,\delta,N)\to 1$ . If on the other hand $\delta \to 0$ , for $N$ fixed, we have that $f(t,\delta,N)\to 0$ since the exponential goes faster to zero than the polynomial to infinity. In this case, we let $\delta \to 0$ and simultaneously $N \to \infty$ , but with a ""slower pace"". Can we conclude that the limit is zero? If yes, how? Edit: After some reasoning I came up with $$
f(t,\delta,N)= \frac{\Gamma(N, t/\delta)}{(N-1)!},
$$ with $\Gamma(\cdot, \cdot)$ the upper incomplete Gamma function. I implemented this in Matlab, and the interesting behaviour is that if $N=\delta^{-1}$ , then the limit (1) is $1/2$ if $0 <t \leq 1$ and it is 0 if $t > 1$ . If $N=\delta^{-\gamma}$ , with $\gamma \in (0, 1)$ , the limit is 0, and if $N = \delta^{-\gamma}$ , with $\gamma > 1$ , then the limit is 1, independently of $t$ .","['limits', 'calculus', 'exponential-function', 'taylor-expansion']"
4004565,Generalisation of an inequality to infinite dimensional normed linear spaces,"Lemma 6.3 in Rudin's Real and Complex Analysis states that: For every $n$ and for every $n$ -tuple of complex number $z_1,...,z_n$ , there exists $S\subseteq \{1,...,n\}$ such that $$\left| \sum_{k \in S} z_k \right| \geqslant \frac1\pi\sum_{i=1}^{n} | z_i |$$ This can be generalised to $\mathbb R^d$ for all $d$ (see, for example, here ) and, exploiting the fact that all norms on a finite dimensional vector space are equivalent, we arrive at the following generalisation Let $(X,||\cdot||)$ be a finite dimensional normed space. There exists a constant $c>0$ , that depends only on $X$ and $||\cdot||$ , such that the following holds: for any $n$ and any $n$ -tuple $(v_1,v_2,…,v_n)$ of elements of $X$ , there exists a subset $J⊆\{1,2,…,n\}$ such that $$\left\| \sum_{j \in J} v_j \right\| \geqslant c \sum_{i=1}^{n} \| v_i \|.$$ This is not always the case for infinite dimensional normed spaces. For example, if $(X,\langle\cdot,\cdot\rangle)$ is an infinite dimensional Hilbert space, pick a countable orthonormal subset $\{e_n\}_{n\in\mathbb N}$ . Then for all $n$ and for all subsets $J\subseteq\{0,...,n\}$ , we have that $\sum_{i=0}^{n} \| e_i \|=n$ and $\left\| \sum_{j \in J} e_j \right\|=\sqrt{|J|+1}\leqslant\sqrt{n+1}$ , but there is no constant $c>0$ such that $\forall n\in\mathbb N:\sqrt{n+1}\geqslant cn$ . A similar argument also works for $\ell^p$ for all $p\in(1,\infty]$ , however, I wasn't able to apply the same argument for $\ell^1.$ My question is: does there exist an infinite dimensional normed space for which the theorem above holds? I couldn't come up with an example, so i tried to prove that is is never the case. My idea was to use Riesz's lemma , but I got stuck.","['inequality', 'normed-spaces', 'functional-analysis']"
4004617,Change from differentiation wrt to matrix to wrt to inverse of matrix for symmetric matrices,"For the rule below: $$
\frac{\partial J}{\partial \mathbf{A}}= -\mathbf{A}^{-T} \frac{\partial J}{\partial \mathbf{W}} \mathbf{A}^{-T} 
$$ where $\mathbf{A}$ is an invertible square matrix, $\mathbf{W}$ is the inverse of $\mathbf{A}$ , and J is a function (see end of section 2.2 in matrix cookbook https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf ) Does this rule hold if $\mathbf{A}$ is a symmetric matrix?","['matrix-calculus', 'derivatives', 'symmetric-matrices']"
4004666,Relationship between Pigeonhole Principle and Hall's Theorem,"I am wondering if there is any sort of relationship between the Generalized Pigeon Hole Principle and Hall's Theorem. For example, is possible to use the Pigeonhole Principle in order to prove that there does not exist a perfect matching between two sets?","['pigeonhole-principle', 'matching-theory', 'discrete-mathematics']"
4004667,Birthday Paradox with Leap Year,"I looked online, and found more than one and inconsistent answers to the Birthday Paradox when we throw the leap year into the mix. None of the answers I saw match with my own. I am posting my solution to see if it is correct, or if I am missing something. Question: Assume that the leap year occurs every four years. (i.e. ignore the 100 and 400 year rule). Also assume that the number of people born each day is the same. What is the probability that in a group of $n$ people (each one selected randomly), no two people share the same birthday ? My Solution: Let $\mathcal{D}$ be the set of all possible dates in an year. (Thus $\mathcal{D}$ contains 366 elements. Note that these possibilities are not equally likely, since a person is four times as likely to be born on (say) Jan 1 than on Feb 29. This is true for any given day other than Feb 29, and it is encoded in the probability assignments given below.) Now probability that a randomly selected person is born on Feb 29 is $\frac{1}{1 + 4 \times 365} = \frac{0.25}{365.25}$ . Also, the probability that a randomly selected person is born on a given day other than Feb 29 is $\frac{1}{365.25}$ . Now, for a group of $n$ randomly selected people, the Sample Space of birthdays is $\mathcal{D}^n$ . Let $\mathcal{A} \subset \mathcal{D}^{n}$ be the subset such that no two people share the same birthday. Divide $\mathcal{A}$ into two disjoint sets $\mathcal{A}_1$ and $\mathcal{A}_2$ such that $\mathcal{A}_1 = \{\xi: \xi \in \mathcal{D}^n \text{ and no two people have same birthday, and none is born on Feb 29} \}$ , and $\mathcal{A}_2 = \{\eta: \eta \in \mathcal{D}^n \text{ and no two people have same birthday, and exactly one is born on Feb 29} \}$ Now, $\mathbb{P}(\xi) = \frac{1}{(365.25)^n}$ for each $\xi \in \mathcal{A}_1$ , and $\mathbb{P}(\eta) = \frac{0.25}{(365.25)^n}$ for each $\eta \in \mathcal{A}_2$ . Also, $|\mathcal{A}_1| = \; ^{365}P_{n}$ , and $|\mathcal{A}_2| = \; n \; \cdot \; ^{365}P_{n-1}$ Finally, $\mathcal{A}_1$ and $\mathcal{A}_2$ being disjoint, it follows that $$\mathbb{P}(\mathcal{A}) = \mathbb{P}(\mathcal{A}_1) + \mathbb{P}(\mathcal{A}_2) = \frac{^{365}P_{n}}{(365.25)^n} + \frac{0.25 \; \cdot \; n \; \cdot \; ^{365}P_{n-1}}{(365.25)^n}$$ PS: As usual, if you want to find out the probability that at least two people share the same birthday then you would calculate $1 - \mathbb{P}(\mathcal{A})$ . Interestingly, the number of people required so that this probability is more than 0.5 is still $n = 23$ , same as the birthday paradox without leap year. Please let me know if the solution above looks accurate.","['solution-verification', 'birthday', 'probability']"
4004671,Cauchy-Riemann Equation for Surface Equations,"Suppose we are given smooth functions $W,V:\mathbb{R}^2\times\mathbb{C}\to\mathbb{C}^2$ and are asked to determine if the function $Q(W(x,y,z(x,y)),V(x,y,z(x,y))$ solving $$
Q(W(x,y,z(x,y)),V(x,y,z(x,y)))=0,
$$ is analytic. Following Chapter 10 of Lectures on Random Lozenge  Tilings , Gorin states that the sufficient condition for $Q$ to be analytic is to establish $W(V)$ is analytic or in other words $$\frac{\partial W}{\partial\bar{V}}=0.
$$ Of course this form of the Cauchy-Riemann equations $$\frac{\partial f}{\partial \bar{z}}=0
$$ is recognisable when establishing $f(z):\mathbb{C}\to\mathbb{C}$ is analytic, but I don't understand how $\frac{\partial W}{\partial\bar{V}}=0$ implies $Q$ is analytic. What's the basic reason for this? Also, would $\frac{\partial V}{\partial\bar{W}}=0$ do the job, too? For context, see the latter portion of Chapter 9 from the linked reference which derives the surface equation $Q=0$ from the method of complex characteristics and where there is a concrete example of the functions $W,V$ .","['complex-analysis', 'cauchy-riemann-equations', 'characteristics']"
4004696,Identify this graph problem.,"[Edit 01/02/2021] : Now the problem has been identified, as a relaxation of "" minimal spanning tree "" (it is more a minimal spanning sub-graph). Are they some references I could use on this problem ? Let consider a graph made of $N$ nodes, numeroted from $B_1$ to $B_N$ . Each nodes can or cannot be connected to the other nodes, but overall we consider a family of weighed edges : $(\nu_{ij})_{1 \leq i < j \leq N} \in \mathbb{R}^{\frac{N(N-1)}{2}}$ . The edges must be understood as followed : $\nu_{ij}=0$ if $B_i$ and $B_j$ are not linked by an edge. there is no edge connecting one node to himself. I want to operate with a specific way on this graph (I want to select some specific edges), and I believe I am looking for a family of numbers $(x_{ij})_{1 \leq i < j \leq N}$ with $x_{ij}=0$ or $1$ that verifies the following discrete optimization problem : $$\underset{(x_{ij})_{1 \leq i < j \leq N} \in (0,1)^{\frac{N(N-1)}{2}}}{\min} \sum_{i<j}\  \nu_{ij} \  x_{ij}$$ with the following constraints on the $(x_{ij})$ : $\sum_{i<j} x_{ij} = N-1$ (i.e we are only gonna keep $N-1$ edges in the graph) $\forall i \in \{1,\dots,N\}$ , we have $$\sum_{j=i+1}^N x_{ij} + \sum_{j=1}^{i-1} x_{ji}  \geq 1$$ (i.e every nodes have at least one ""non-zero"" edge) My questions Is this problem known in operation research or discrete optimization or is it closed to a known problema with a theoritical analysis ? I don't know a lot of them, except for the traveling salesman problem or the cover set problem but I am quite unfamiliar with them. Separately from this first question, I believe (heuristically, at least) that any family $(x_{ij})_{1 \leq i < j  \leq N}$ admissible for this problem verifies the following property : the final graph with value $(x_{ij} \nu_{ij})$ on the edge is made of cycles and of only one path But i am not sure how to prove it. I'have been looking for counter-examples using $4/5$ nodes and cycle but couldn't find any...
Any help, references or remarks are welcomed on the problem :).","['graph-theory', 'operations-research', 'reference-request', 'discrete-mathematics', 'terminology']"
4004701,Double integral comes out different after changing $dx$ with $dy$.,"$$\int_{0}^{1}\,dx \int_{0}^{1}\frac{x-y}{(x+y)^{3}}\,dy$$ My maths teacher gave this question to explain that if you change $dy$ with $dx$ the integral will have different value. My opinion is that the integral should come out as equal because this integral represents volume under a curve and the area over which we are integrating is same in both cases. Moreover this volume has to be $0$ because I plotted this curve in a 3d graph plotter and the surface is positive on one side of line $x=y$ and equally negative on the other side. BUT! after integrating the answer is coming as $1/2$ in one case and $-1/2$ in the other. Please explain.","['integration', 'multivariable-calculus', 'multiple-integral', 'fubini-tonelli-theorems']"
4004707,Classifying the point $x=2$ for $f(x)=\cos(|x-2|)$,"What is the point $x=2$ for this function? $$f(x)=\cos(|x-2|)$$ I calculated $$\lim_{x \to2^+} \frac{-\sin(|x-2|)|x-2|}{x-2}=0^-$$ $$\lim_{x \to2^-} \frac{-\sin(|x-2|)|x-2|}{x-2}=0^+$$ and it's a corner point.
If I calculate the limit of the incremental ratio $$\lim_{h \to0^+} \frac{\cos(|h|)}{h}=+\infty$$ $$\lim_{h \to0^-} \frac{\cos(|h|)}{h}=-\infty$$ it's a cusp.
Can it just be a stationary point?","['limits', 'derivatives']"
4004712,Continuous functions and preservation of topological structure.,"In some book I read ""continuous fuctions between topological spaces preserve their topological structure"" and they say that this is similar to the case when homomorphims perserve algebraic structures. But thinking about it, it seems to me that this structure preservation is made backwards. For example, given $f:X \Rightarrow Y$ , both $X$ and $Y$ topological spaces, it is true that the inverse image of finite intersection of open sets in $Y$ will be open in $X$ . But this not happen with direct images. I might conclude that topological structure of $Y$ is preserved when the inverse images of $f$ send it to $X$ . It that true? Thanks in advance.","['elementary-set-theory', 'general-topology', 'real-analysis']"
4004715,Shortest time to travel around quicksand,"You want to travel from one side of a quicksand $(1,0)$ pit to another side of the quicksand pit $(-1,0)$ . The speed you can run is determined by how far you are away from the quicksand $|v(x,y)| = \sqrt{x^2+y^2}$ . What is the optimal path you should travel such that the time taken to travel is minimized? In my attempted solution: Use cylindrical coordinates $(r,\theta)$ and find an expression for the total time taken $T$ Attempt to minimize $T$ using Beltrami's identity Solve the resulting differential equation to find $r(\theta)$ However, when I do this, I find $r = c_2 e^{c_1 \theta}$ . This is strange because I would have expected a symmetrical path around the y axis. Also, when I plug in the start and end points I get nonsensical values for the constants $c_1$ and $c_2$ . Can someone help me figure out what I'm doing wrong?","['optimization', 'multivariable-calculus', 'euler-lagrange-equation']"
4004720,How to find a real sequence $x_n$ such that $n x_n \to 0$ as $n \to \infty$ and $\sum_{n=1}^{\infty} x_n$ diverges?,"I'm stuck on trying to find a real sequence $x_n$ such that $n x_n \to 0$ as $n \to \infty$ and $\sum_{n=1}^{\infty} x_n$ diverges. Here's what I have tried so far: I've started with trying to find $x_n$ as a real-valued function of $n$ . In order to have $n x_n \to 0$ , we require $$\frac{x_n}{1/n} \to 0$$ and since the denominator tends to $0$ as $n$ increases, we require that $x_n \to 0$ . We also require that $x_n$ tends to $0$ ""faster"" than $1/n$ does, in order for the above quotient to go to $0$ . However if you try functions such as $x_n=1/n^2$ or $x_n=n/2^n$ (for example) which tend to $0$ faster than $1/n$ does, then you see that $\sum_{n=1}^{\infty} x_n$ converges and I haven't been able to find a function for $x_n$ that satisfies the above conditions and also has a divergent infinite sum. It's certainly possible that the form for $x_n$ might not be a simple elementary function of $n$ , but I don't know how you'd go about finding any ""unusual constructions"" that work.","['sequences-and-series', 'real-analysis']"
4004778,how do I write the function obtained from these two graphs?,I would like to design a function that has the maximums of the first image as maximums and the minimums of the second. in the first image f(x) is $$ \cos ^ {- 1} (\cos (x)) + x / 3 $$ while the second is $$ \cos ^ {- 1} (\cos (x)) + x / 6 $$ the lines are $$ x / 3 + \pi $$ (the blue one) and $$ x / 6 $$ the other.,['functions']
4004859,Characterization of pretty compact spaces,"I believe that the following problem have already been considered by some sophisticated topologist. Definition 1. A non-compact Hausdorff topological space $X$ is called almost compact if its Stone-Cech compactification coincides with its one point compactification. An example of almost compact space is $[0,\omega_1)$ for first uncountable ordinal $\omega_1$ . Definition 2. A compact Hausdorff space $X$ is called pretty compact if $X\setminus\{p\}$ is almost compact for all non-isolated points $p\in X$ . I would like to hear answers to any of the following questions. Questions: What are examples of pretty compact spaces? Is it true that pretty compact spaces are extremally disconnected? Is it true that pretty compact spaces contain dense extremally disconnected subspace? Does there exist any characterization of pretty compact spaces?","['general-topology', 'compactification', 'compactness']"
4004896,Prove that some group is infinite based on its presentation.,"Suppose $G$ is a group with presentation $$G = \langle a, b, c\mid a^2=b^2=c^2=(ab)^3=(bc)^3=(ca)^3=1\rangle.$$ I want to show that this group is of infinite order. I think since the element $abc$ is of infinite order, we can conclude that $G$ is infinite. I feel that for any $n \in\mathbb{N},$ we have that $(abc)^n = (abc)(abc) \cdots (abc)$ (with $n$ factors) cannot be reduced further, as we do not have any relations involving $a, b,$ and $c$ consecutively. But I also think that this reasoning is not that convincing, and hence, I am asking for help.","['combinatorial-group-theory', 'group-presentation', 'group-theory']"
4004897,Calculate $\displaystyle \lim_{x \to 3} \frac{\sqrt{19-x} - 2\sqrt[4]{13+x}}{\sqrt[3]{11-x} - x + 1}$,Calculate: $$\displaystyle  \lim_{x \to 3}  \frac{\sqrt{19-x} - 2\sqrt[4]{13+x}}{\sqrt[3]{11-x} - x + 1}$$ The problem with that case is that the roots are in different powers so multiplication in nominator and denominator by conjugate is not an option (at least I think it's not).,"['limits', 'limits-without-lhopital', 'real-analysis']"
4004908,Find the condition in which $\angle ADB = 3\angle BAC$,"See below in acute triangle $ABC$ , $D$ is on $AC$ such that $AD=BC$ . $CF$ is the angle bisector of $\angle ACB$ . $DE \parallel CF$ . $E$ is on $AB$ . $AE = CD$ . Prove that $\angle ABC = 2 \angle BAC$ . In addition, find the condition in which $\angle ADB = 3 \angle BAC$ I struggle to find ways to use two conditions $AD = BC$ and $AE = CD$","['contest-math', 'euclidean-geometry', 'geometry', 'plane-geometry']"
4004974,Finding the least number of plants watered by three gardeners,"There are 100 plants and three gardeners A, B, and C. If A watered 68 plants, B watered 78 plants, and C watered 88 plants, at least how many plants are watered by all three gardeners? I drew a Venn diagram and let $|A \cap B| - |A \cap B \cap C| = |A \cap C| - |A \cap B \cap C| = 34.$ Then, I let $|B \cap C| - |A \cap B \cap C| = 44,$ so that meant that $|C| - |A \cap C| - |B \cap C| = 10.$ However, this totaled to $122,$ so I concluded that the answer was $122 - 100 = 22.$ Can somebody tell me if my logic is correct or not? Thanks.","['inclusion-exclusion', 'combinatorics', 'discrete-mathematics']"
4004978,Sum of square roots inequality,"For all $a, b, c, d > 0$ , prove that $$2\sqrt{a+b+c+d} ≥ \sqrt{a} + \sqrt{b} + \sqrt{c} + \sqrt{d}$$ The idea would be to use AM-GM, but $\sqrt{a} + \sqrt{b} + \sqrt{c} + \sqrt{d}$ is hard to expand. I also tried squaring both sides, but that hasn't worked either. Using two terms at a time doesn't really work as well. How can I solve this question? Any help is appreciated.","['algebra-precalculus', 'a.m.-g.m.-inequality', 'inequality']"
4005005,Strict inequalities in real-valued continuous random variable,"Let $X$ be a real-valued continuous random variable, such as the exponential random variable. Is the equation $$
\mathbb{P}(X\le a) = \mathbb{P}(X < a)
$$ true? In other words, can we replace an ""inequality"" with its ""strict"" version? For instance, in the case of exponential random variable, do we have $\mathbb{P}(X\le a) = \mathbb{P}(X < a) = 1 - e^{-\lambda a}$ ? Intuitively, this seems correct to me (at least for non-pathological random variables) because the probability of a single point is zero, i.e., the integral of pdf over a single point is zero.
I appreciate any comment or answer to this question.","['stochastic-processes', 'probability-distributions', 'probability-theory', 'probability']"
4005018,How can I prove (without cardinal numbers) that $P(P(\mathbb{N}))$ is equipollent to $P(P(\mathbb{N})) \times P(P(\mathbb{N}))$,"I am stuck trying to prove that $P(P(\mathbb{N}))$ is equipollent to $P(P(\mathbb{N})) \times P(P(\mathbb{N}))$ . I was thinking that it is enough to prove $P(\mathbb{R}) \sim P(\mathbb{R}) \times P(\mathbb{R})$ , or even $2^{\mathbb{R}} \sim 2^{\mathbb{R}} \times 2^{\mathbb{R}}$ , but I still don't know how to finish this. It would be even better if you can prove that in general for any infinite set $X$ it's true that $X \times X \sim X$ .","['elementary-set-theory', 'cardinals', 'set-theory', 'real-analysis']"
4005111,"Given $z^{z^x}=x$, estimate $\frac{dx}{dz}$","I'm reading Knoebel's Exponentials Reiterated , page 242 and have very hard time understanding the following: If $z^{z^x}=x$ , then $\frac{dx}{dz}\gt 0$ on the open line $$L=\{<z,x>|0\lt z\lt e^{-e}\,\text{and}\, x=e^{-1}\}.$$ This doesn't make sense to me. Because if $z^{z^x}=x$ , then $x=e^{-1}$ implies $z=e^{-e}$ , which is not in the open interval $\left(0,e^{-e}\right)$ . I know that, if $j(z,x)=z^{z^x}-x$ , then $$dj(z,x)=z^{z^x}z^{x-1}(x\ln z+1)\,dz+\left(z^{z^x}z^x\ln ^2z-1\right)\,dx,$$ and there is a unique trajectory satisfying $j(z,x)=0$ when it is not true that $z=e^{-e}$ and $x=e^{-1}$ simultaneously by the Implicit function theorem ,
but how could that be used to prove $\frac{dx}{dz}\gt 0$ on the line?","['calculus', 'derivatives', 'real-analysis']"
4005134,Find closure of topologist's comb,"Find the closure and limit points of $C=\{(x,0)|x \in [0,1]\} \cup \bigcup\limits_{i \in \mathbb{N}}\{(\frac{1}{n},y)|y \in [0,1]\} $ Would this be the correct closure/limit points for this set? My attempt:
Every point of $C$ is a limit point, since for each $(x,y) \in C$ and $\epsilon>0$ , $B((x,y),\epsilon)-\{(x,y)\} \cap C \neq \varnothing$ .Thus if $C'$ is the set of limit points, $C \subset C'$ . For each $y \in [0,1]$ , the set of points $\{(\frac{1}{n},y)|n \in \mathbb{N}\}$ have a first coordinate that forms a sequence $(\frac{1}{n})$ , converging to $0$ . Then because each neighborhood of a point $(0,y), y\in [0,1]$ contains some point in $\{(\frac{1}{n},y)|n \in \mathbb{N}\}$ , $\{(0,y)|y \in [0,1]\} \subset C'$ .So $\bar C=C\cup \{(0,y)|y \in [0,1]\}$ . Edit:I gave the proof of this an attempt, here is my try. Every point in $(\frac{1}{n+1},\frac{1}{n}) \times [0,1]$ is not a limit point. Let $(x,y) \in (\frac{1}{n+1},\frac{1}{n}) \times [0,1]$ . Choose $\epsilon=\text{min}\{x-\frac{1}{n+1},\frac{1}{n}-x\}$ . Then $B((x,y),\epsilon) \cap C =\varnothing.$ Similarly, any point $(x,y)$ in the lower half plane is not a limit point. Choose $0<\epsilon<|y|$ .Every point $(x,y)$ in the left half plane is not a limit point. Choose $0<\epsilon<|x|$ .Any point satisfying $x>1$ is not a limit point, choose $0<\epsilon<x-1$ . Any point satisfying $y>1$ is not a limit point, choose $0<\epsilon<y-1$ .","['elementary-set-theory', 'general-topology']"
4005160,Derivative of submatrix with respect to the whole block matrix,"I am reading a research paper and getting stucked with how they derived a formula. Suppose that we have the following block matrix $$\underset{d \times d}{\boldsymbol{A}} = \begin{bmatrix} \underset{q \times q}{\boldsymbol{A}_{11}} & \underset{q \times (d - q)}{\boldsymbol{A}_{12}} \\ \underset{(d - q) \times q}{\boldsymbol{A}_{21}} & \underset{(d - q) \times (d - q)}{\boldsymbol{A}_{22}} \end{bmatrix}$$ The formula involves taking the derivative of a quantity that involves $\boldsymbol{A}_{22}$ with respect to $\boldsymbol{A}$ . In particular, that quantity is $$\text{trace} (\boldsymbol{A}_{22} \boldsymbol{B}),$$ where $\boldsymbol{B}$ is matrix with dimension $(d - q) \times (d - q)$ . We need to take the following derivative $$\frac{\partial }{\partial \boldsymbol{A}} \text{trace} (\boldsymbol{A}_{22} \boldsymbol{B}).$$ In the context of my paper, $\boldsymbol{A}$ is a symmetric matrix, but if possible, I would assume $\boldsymbol{A}$ is a square matrix. Please help me if you have an idea. Thank you so much.","['matrices', 'derivatives', 'matrix-calculus', 'linear-algebra']"
4005178,Ring of integer-valued polynomials Int(X) is not isomorphic to Z[X],"Write $\operatorname{Int}(\mathbb{Z})$ for the set of polynomials $p$ mapping integers to integers, i.e., $p(\mathbb{Z}) \subseteq \mathbb{Z}$ . I have shown that $\operatorname{Int}(\mathbb{Z})$ is a subring of $\mathbb{Q}[X]$ . I am now asked to prove that $\operatorname{Int}(\mathbb{Z})$ is not isomorphic to $\mathbb{Z}[X]$ . By dabbling around online I found that $\operatorname{Int}(\mathbb{Z})$ is non-Noetherian, whilst $\mathbb{Z}$ as a PID is Noetherian and so $\mathbb{Z}[X]$ is Noetherian, hence the two rings in question cannot be isomorphic. However, I would like to have a more elementary proof. We have $\mathbb{Z}[X] \subsetneq \operatorname{Int}(\mathbb{Z})$ since the latter contains polynomials  such as $\frac{1}{2} X^2 + \frac{1}{2} X$ . I thought I could get a contradiction by considering the 'extra elements', but since both rings are infinite and a ring automorphism needs not be the identity I don't know how to proceed. What are some other properties of ring isomorphisms that I can consider to reach a contradiction?","['ring-isomorphism', 'abstract-algebra', 'polynomials', 'integer-valued-polynomials']"
4005188,Derivative of Trig Function with exponent and chain rule logic,"I'm new to calculus and self-learning it, I am having trouble grasping why $\sin^2 5x$ can be rewritten as $(\sin 5x)^2$ I fumble when I try to understand the logic behind it. For example, if I plug in a number for 'sin' I would get a different answer when I plugged it in the original equation and when I plugged it into the rewritten equation. Just trying to understand the logic and the 'why', so I don't go through calculus mindlessly solving equations. Thanks.","['exponential-function', 'calculus', 'derivatives', 'trigonometry']"
4005189,Random list lengths,"I am trying to analyze analytically what would happen if I build a random simulator as follow: I begin with $ N $ lists of length 1, at each iteration, I will pick a random (non-empty) list, reduce its length by 1. And then, with probably $ p $ , I create a new list of length 1, otherwise, I pick a random (non-empty) list and increase its length by 1. Every iteration keeps the total lengths of the lists constant, and I am interested in the distribution of list lengths. A simple Monte Carlos simulation yield some interesting findings. With $ N = 100 $ and $ p = 0.5 $ , we have, approximately $ P(L = 1) \approx 2 P(L = 2) $ and $ P(L = 2) \approx 2 P(L = 3) $ , and so on. As it is just a simulation, the number is not exact of course. I run the simulator 1,000,000 times to be sure we reach stationary. I really wonder there could be some time-reversible Markov Chain that could explain this, but my skill there is really rusty and some help would be greatly appreciated. Attached below is the code I used to perform the Monte Carlos simulation, just for reproducibility. from random import *

Size = 100
D = {}
N = [1] * Size
L = Size
R = Size
p = 50

for i in range(0, Size + 1):
    D[i] = 0

for i in range(0, 1000000):
    toremove = randint(0, R - 1)
    N[toremove] = N[toremove] - 1
    if N[toremove] == 0:
        N[toremove] = N[R - 1]
        N[R - 1] = 0
        R = R - 1
    tocreate = randint(0, 100)
    if tocreate < p: 
        N[R] = N[R] + 1
        R = R + 1
    else:
        if R == 1:
            toappend = 0
        else:
            toappend = randint(0, R - 1)
        N[toappend] = N[toappend] + 1
    for n in N:
        D[n] = D[n] + 1
print(D) EDIT: To make the problem more tractable for a manual calculation. I reduced the list size to 3. In this case, we have only 3 meaningful states. We have 3 lists of size 1, 1 list of size 2 together with 1 size of size 1, and 1 list of size 3. The transition matrix for these states is as follow (the probability values can be reasoned by a case by case analysis). $\left(\begin{array}{ccc}
p & 1-p & 0 \\
\frac{p}{2} & \frac{1}{2} & \frac{1-p}{2} \\
0 & p & 1-p
\end{array}\right)$ For $ p = \frac{1}{2} $ , the stationary probability can be found as the eigen vector of $ T' $ corresponding to eigenvalue 1 to be $\left(\begin{array}{c}
\frac{1}{4} \\
\frac{1}{2} \\
\frac{1}{4} 
\end{array}\right)
$ That explains the list length distribution because the expected number of lists of length 1 will be $ N \times (\frac{1}{4} \times 3 + \frac{1}{2} \times 1) = \frac{5N}{4} $ . The number of list of length 2 would be $ N \times \frac{N}{2} =  $ and the number of lists of length 1 would be $ N \times \frac{1}{4} = \frac{N}{4} $ , which is roughly the doubling that we are seeing. In fact $ \frac{5N}{4} $ matches better to the experiment data than $ N $ . Attached is the octave code for computing the Markov chain stationary state probability as well as the expected list lengths. The 10000 power is used as an easy way to approximate. With this code, now I can easily tune $ p $ and figure $ p $ can be used effectively to change list length distributions. p = 0.5
T = [p, (1-p), 0;p/2,1/2,(1-p)/2;0,p,(1-p)];
([1,0,0] * T^10000) * [3,0,0;1,1,0;0,0,1] All the above shown Markov chain could be used to analyze the situation. However, it requires a lot of effort to analyze the states in the case by case manner and it certainly won't scale for big $ N $ . I am planning to run this simulator with $ N = 1000000 $ or above.",['probability']
4005227,"Writing a Recursive Sequence and finding out limit by a ""weird"" property","I apologize for lacking of a better title and for potencial math language mistakes as I'm not an english native so there's some terms I might miss. I found out a note of my college that had the following written on: Calculate $\lim(x_n)$ if $$x_n=\frac{n}{2^{n+1}}\sum_{i=1}^{n}\frac{2^i}{i}$$ Then their resolution follows as: This sequence can be defined by recursion as $$x_{n+1}= \frac{n+1}{2n}.\underbrace{\frac{n}{2^{n+1}}\sum_{i=1}^{n}\frac{2^i}{i}}_{x_n} + \frac{n+1}{2^{n+2}}\frac{2^{n+1}}{n+1} = $$ $$\frac{n+1}{2n}x_n + \frac{1}{2} = x_{n+1}$$ I really don't understand how they defined the recursive sequence, I tried to calculate $x_{n+1}$ and had a different result than the solution everytime I tried (if I even did it correctly). The next step is perhaps the most confuse to me, as they said: $\frac{n+1}{2n} \to \frac{1}{2}\hspace{1.5mm}\text{(obvious to me)}$ and as stated in a theorem we studied before (I really don't recognize this theorem and can't search for it) $x_n$ has a limit and it is given by $$\frac{\frac{1}{2}}{1 - \frac{1}{2}} = 1$$ Besides not getting how they defined the recursive sequence I believe I'm not aware of the theorem they stated as well (even though the outcome looks like the sum of a geometric series of ratio $\frac{1}{2}$ starting on the first term) so I would really appreciate it if someone could help me figuring out both things. Thank you so much for your attention.","['recursion', 'recurrence-relations', 'calculus', 'sequences-and-series', 'limits']"
4005247,Dual problem for Prokhorov metric,"In optimal transport, one of the fundamentals of the theory is that the problem defining the Wasserstein/Kantorovich metric admits a dual problem. Namely that $$ \inf_{\pi \in \Pi(\mu,\nu)} \int_{X \times Y} c(x,y) d\pi = \sup_{\varphi \in C(X)} \int_X \varphi(x) + \int_Y \varphi^c(y) $$ The Prokhorov-Levy metric, defined as $$ \rho(\mu,\nu) = \inf_{\varepsilon >0 } \{ \mu(A) \leq \nu(A^\varepsilon) + \varepsilon : \forall A \in \mathcal{B}(X) \} $$ where $A^\varepsilon = \bigcup_{a \in A} B(a,\varepsilon)$ . This metric also metrizes weak* convergence in $\mathcal{P}(X)$ , and is also defined by an optimization problem. Is there any research into a dual problem for this? It seems hard to find any modern references on this metric at all. I tried writing the objective in terms of $\varepsilon +$ indicators of the constraints, but attempting to apply some sort of Fenchel duality produces a conjugate that depends on the primal (I can detail this if there is interest, it doesn't seem to work).","['optimization', 'measure-theory', 'optimal-transport', 'convex-analysis']"
4005248,Functional Notation Confusion,"This is a fairly basic question but I still can't seem to wrap my head around it, so any help would be appreciated. In my homework, I have seen this functional notation being used: $$\ln(1-n)$$ I am confused on what this means, because usually I am more familiar with functional notation like this: $$f(n) = \ln n$$ So would that mean the $1-n$ in the first expression used is an input into the $\ln n$ function? Like so: $$f(1-n) = \ln(1-n) = \text{constant}$$ Please let me know as I believe I'm interpreting it wrong.","['notation', 'functions']"
4005256,Div-Curl lemma and precompactness in $H^{-1}$,I am trying to understand $\operatorname{div-curl}$ lemma. An important requirement to apply $\operatorname{div-curl}$ lemma is the precomapctness of the sequences $\operatorname{div}(A_n)$ and $\operatorname{curl}(B_n)$ in $H^{-1}(\Omega).$ What are the important compactness results which help in checking whether a sequence is precompact in $H^{-1}(\Omega)$ or not? Where can I find the details? Are there any books which illustrate the application of $\operatorname{div-curl}$ through some examples? Any help is appreciated..,"['compact-operators', 'sobolev-spaces', 'functional-analysis', 'partial-differential-equations', 'compactness']"
4005280,Obtain B to minimize $\|\boldsymbol{X}-\boldsymbol{B}\|_{\boldsymbol{F}}^{2}$ with constraint on the spectral norm of B to be ≤ 1,"I stumbled upon this problem where I have to I want to obtain B such that we Minimize $\|\boldsymbol{X}-\boldsymbol{B}\|_{\boldsymbol{F}}^{2}$ subject to the constraint
that the spectral norm of 𝑩 is less than or equal to one. I tried to proceed using the SVD decomposition and trying to involve some inequalities of norms. but with no result.
Any suggestions??","['matrices', 'optimization', 'svd', 'matrix-norms']"
4005282,How do I approach this Combinatorics problem?,"This is a question put up by Jane Street in their monthly Puzzle Archive.
The Problem I'll write the problem here as well. Jane received 78 figurines as gifts this holiday season:  12 drummers drumming, 11 pipers piping, 10 lords a-leaping, etc., down to 1 partridge in a pear tree. They are all mixed together in a big bag.  She agrees with her friend Alex that this seems like too many figurines for one person to have, so she decides to give some of her figurines to Alex. Jane will uniformly randomly pull figurines out of the bag one at a time until she pulls out the partridge in a pear tree, and will give Alex all of the figurines she pulled out of the bag (except the partridge, that’s Jane’s favorite). If n is the maximum number of any one type of ornament that Alex gets, what is the expected value of n, to seven significant figures? I approached the problem in this way. Please have a look. My Approach I'll assume the following (in my approach) - Let Ci - Selecting 'i' Identical candies before partridge is taken out.
Then I'll compute for each, C2 to C12 - for each type of figurine that fits the criteria. Example C5 - Selecting 5 identical candies before partridge is taken out. It can be anything from type-5 figurine to type 12 (Drummers). Is this the right way to solve it. Am i right in the fundamentals ? Is there a better way to go about the problem.","['permutations', 'combinations', 'expected-value', 'combinatorics', 'probability']"
4005372,To find all integers n such that the given expression is a perfect square,"The question is as follows Determine all integers n such that $n^{4}-n^{2}+64$ is the square of an integer Here is my approch Let $n^{4}-n^{2}+64=k^{2}$ . On multiplying both sides by 4, we get $$4n^{4}-4n^{2}+256=4k^{2}$$ $$\Rightarrow(2n^{2}-1)^{2}+255=4k^{2}$$ $$\Rightarrow(2k+2n^{2}-1)(2k-2n^{2}+1)=255$$ The only ordered pair of factors possible are (3,85); (5,51); (15,17). We need not consider negative factors as we are squaring later. Thus, we get $k=8, 14, 22$ , which implies $k^{2}=64, 196, 484$ and finally $k^{2}-64=0, 132, 420$ $$\Rightarrow n^{4}-n^{2}=0, 132, 420$$ These 3 equations admit only $n=0, \pm1$ as integer solutions. However, $n=\pm8$ also satisfies. Thus, my solution is incomplete or wrong Could anyone please point out the mistake in my solution or provide the necessary extension to fix it. Thanks a lot for help!! :)","['number-theory', 'square-numbers', 'elementary-number-theory']"
4005390,"By differentiation or otherwise, prove that $(c(z))^2 +(s(z))^2 = 1$","Assume that the two power series $s(z) = \sum a_nz^n$ and $c(z) =\sum b_nz^n$ are convergent for all $z\in \mathbb{C},$ and that they satisfy the relations $s'(z) = c(z), c'(z) =-s(z).$ Deduce the identities $$ a_n = -a_{n-2}/(n(n-1)) , b_n=-a_{n-2}/(n(n-1))
$$ (To me, it looks like there is a typo for $a_n$ )
If further $s(0)=0, c(0) =1,$ determine $s(z)$ and $c(z)$ completely. By differentiation or otherwise, prove that $(c(z))^2 +(s(z))^2 = 1$ To me it looks like $s(z) = sin(z)$ and $c(z) = cos(z)$ but I don't know what to do with this information. Also while taking the derivate of the power series in an attempt to deduce the identities, I have $(n+1)a_{n+1}=b_n$ and it does not seem like I have the correct identity","['complex-analysis', 'convergence-divergence', 'power-series', 'derivatives']"
4005395,Can every cohomology class be represented by an analytic form,Let $M$ be an analytic manifold (you may assume it is equipped with an analytic metric). Must each De Rham cohomology class be representatble by an analytic differential form ? I think Hodge theory maybe relevant here but I can't judge as I don't know if harmonic forms are necessarily analytic or not Thank you,"['hodge-theory', 'differential-topology', 'de-rham-cohomology', 'differential-geometry']"
4005404,How to complete this proof process of Arzelà-Ascoli theorem?,"Theorem. Let $X$ be a compact space and $Y$ be a metric space. A set $\mathscr F \subseteq C(X,Y)$ is precompact if and only if it is
pointwise precompact and equi-continuous. Definitions. A subset $\mathscr F \subseteq C(X,Y)$ is called: equi-continuous if for every $x ∈ X$ and every $ε > 0$ , there exists an
open neighborhood $U \subseteq X$ of $x$ such that $d_Y(f(x), f(x')) < ε$ for all $ x'∈ U$ and all $f ∈ \mathscr F$ . precompact if the closure of $\mathscr F$ is compact. pointwise precompact if for each $x∈X$ , $\mathscr F(x) = \{f(x): f∈\mathscr F \}$ is precompact. Lemma. Let $(X,d)$ be a metric space and let $K \subseteq X$ . Then every sequence in $K$ has a Cauchy subsequence if and only if $K $ is totally bounded. I know how to prove it from left, the way is similar with $X$ is compact metric space. But from right: auth give me some hint.
The key is is to prove every sequence has Cauchy subsequence. By the lemma, we only need to prove $\mathscr F$ is totally bounded. He gives me two hint: The set $F = \{f(x) :  x ∈ X, f ∈ \mathscr F\} \subseteq Y$ is precompact so  is totally bounded. Let $ε > 0$ . Cover $F$ by finitely many open balls $V_1,\dots,V_n$ of radius $ε/3$ and cover $X$ by finitely many open sets $U_1,\dots,U_m$ such that $$\sup_{x,x' ∈ U_i} \sup_{f ∈ \mathscr F} d_Y(f(x),f(x'))＜\frac ε3.$$ Let $\alpha $ be a any map from $\{1,\dots,m\}$ to $\{1,\dots,n\}$ .
Define $$\mathscr{F}_α = \{f ∈ \mathscr F : f(U_i) ∩ V_{\alpha(i)} ≠ \varnothing \} .$$ Let $A$ be
the set of all $α$ such that $\mathscr F_α ≠ \varnothing$ . Prove that $\mathscr F = \bigcup_{α∈A} \mathscr F_α$ . I can following the hint 2 to achieve it, but I don't how to prove hint 1. My try: Originally, I choose $f_n(x_n)$ be sequence of $F$ , I use diagonal method to find a subsequence $g_n$ of $f_n$ such that $f_{n_k}$ converges at each $x_i$ , and I want to prove that $f_{n_k}(x_{n_k})$ converges to subsequence of $f_n(x_n)$ . However I think this way is not ture now.","['functional-analysis', 'real-analysis']"
4005442,the probability that the product of all the numbers is $\color{red}{irrational}$,"When i  get around the deep of stacke exchange , i found a  nice question and wanted to change it a little $\color{blue}{Original:}$ Three dice having sides labelled $e,i,π,1,0,\sqrt2$ are rolled. Find the probability of getting the product of the three results a real number. $\color{green} { Question:}$ There are three fair six-sided dice with sides $0,1,e,π,i,\sqrt{2}$ . If these dice are rolled, the probability that the product of all the numbers is $\color{red}{irrational}$ can be expressed as $\frac{a}{b}$ where $a$ and $b$ are positive, co-prime integers. What is $a+b$ ? $\color{orange} { Solution:}$ $\color{pink} { Firstly:}$ All possibilities $-$ rationals $\color{pink} { Secondly:}$ The number of rationals $=$ (At lest one zero) $+$ (two $\sqrt{2}$ , $1$ ) $+$ (two $i$ , $1$ ) $=$ $(6^3 - 5^3)$ $+$ ( $\frac{3!}{2! \times 1!}$ ) $+$ ( $\frac{3!}{2! \times 1!}$ ) $=$ $91+3+3 =97$ $\color{pink} { Thirdly:}$ $6^3 - 97 =119$ ,so $\frac{119}{216} =119+216=335$ Is my solution correct ? If not, can you share your approach ?","['solution-verification', 'discrete-mathematics', 'probability']"
4005467,Is the set of essentially bounded and not-necessarily-measurable functions a Banach space?,"Suppose that $(\Omega, \mathcal{F}, \mu)$ is a probability space and for $f : \Omega \to \mathbb{R}$ define $$\DeclareMathOperator{esssup}{ess\,sup}
\esssup f = \inf_{A : \mu(A) = 0} \sup_{x \notin A} f(x).
$$ To me it seems that a short elementary argument shows that for measurable $f$ this agrees with the usual definition of the essential supremum, yet there is nothing in the definition that requires $f$ to be measurable. Is it true that the set of equivalences classes of a.e. equal, bounded $\mathbb{R}$ -valued functions on $\Omega$ is a Banach space when equipped with the norm $\|f\| = \esssup |f|$ ?","['measure-theory', 'functional-analysis']"
4005504,Examples of almost compact spaces.,"This question is a follow up question to this one Definition 1. A non-compact Hausdorff topological space X is called almost compact if its Stone-Cech compactification coincides with its one point compactification. The only two examples of almost compact spaces I know are from the book Pseudocompact topological spaces. M. Hrusak, A. Tamariz-Mascarua, M. Tkachenko . On the page 17 authors say that $[0,\omega_1)$ is almost compact and Mrowka-Isbell space $\Psi(\mathcal{A})$ is almost compact for some specific maximal almost disjoint family $\mathcal{A}\subset 2^\omega$ . I would like to know more on almost compact spaces, but I found almost nothing on this subject. Questions: What are other examples of almost compact spaces? Is true that $\beta\mathbb{N}\setminus\{p\}$ is almost compact for $p\in\beta\mathbb{N}\setminus\mathbb{N}$ ? Is it true that $X\setminus \{p\}$ is almost compact whenever $X$ is extremally disconnected and $p\in X$ .","['general-topology', 'examples-counterexamples', 'compactness']"
4005546,Determine the partial derivative of $\frac{\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}}{\cos ^2\left(x^2y^2\right)}$.,"Determine the partial derivative of $f(x)$ : $$f(x,y)=\frac{\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}}{\cos ^2\left(x^2y^2\right)}$$ Here's what I have so far: \begin{align}
\frac{\partial \:}{\partial \:x}\left(\frac{\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}}{\cos ^2\left(x^2y^2\right)}\right) &= \frac{\frac{\partial \:}{\partial \:x}\left(\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}\right)\cos ^2\left(x^2y^2\right)-\frac{\partial \:}{\partial \:x}\left(\cos ^2\left(x^2y^2\right)\right)\left(\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}\right)}{\left(\cos ^2\left(x^2y^2\right)\right)^2} \\
&= \frac{\left(\frac{2\tan \left(\frac{1}{x^2+1}\right)}{x}-\frac{2x\ln \left(y^2x^2\right)\sec ^2\left(\frac{1}{x^2+1}\right)}{\left(x^2+1\right)^2}+\frac{2x}{3\left(x^2+y^2\right)^{\frac{2}{3}}}\right)\cos ^2\left(x^2y^2\right)-\left(-2y^2x\sin \left(2y^2x^2\right)\right)\left(\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}\right)}{\left(\cos ^2\left(x^2y^2\right)\right)^2} \\
&= \frac{\cos ^2\left(x^2y^2\right)\left(\frac{2\tan \left(\frac{1}{x^2+1}\right)}{x}-\frac{2x\ln \left(x^2y^2\right)\sec ^2\left(\frac{1}{x^2+1}\right)}{\left(x^2+1\right)^2}+\frac{2x}{3\left(x^2+y^2\right)^{\frac{2}{3}}}\right)+2xy^2\sin \left(2x^2y^2\right)\left(\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}\right)}{\cos ^4\left(x^2y^2\right)}
\end{align} However, I am not sure if this answer is correct since I get a different answer on emathhelp website.","['real-analysis', 'complex-analysis', 'calculus', 'partial-derivative', 'derivatives']"
4005556,Multidimensional integral of symmetric function,"It holds that $$
\int_0^\infty \int_0^\infty f(x_1,x_2) dx_1 dx_2 = 2 \int_0^\infty \int_0^{x_2} f(x_1,x_2) dx_1 dx_2
$$ when $f$ is symmetric, or, in other words, it is invariant under permuting the variables. Does it hold for some $C$ that $$
\int_0^\infty \cdots \int_0^{\infty}f(x_1, \cdots, x_n) dx_1 \cdots dx_n = C \int_0^\infty\int_0^{x_n}\cdots\int_0^{x_n}f(x_1, \cdots, x_n) dx_1 \cdots dx_n
$$ where $n$ is the number of integrals, again for $f$ being symmetric. If so, how does $C$ depend on $n$ ?","['integration', 'definite-integrals']"
4005683,Solve $x^3=(1256)(37)$ in $S_7$,"I would like to solve the equation $$x^3=(1256)(37)$$ in $S_7$ . I went like this. Let's consider $x$ 's decomposition into disjoint cycles. $x$ cannot have a cycle of length $5$ or of length $7$ in its decomposition, because these cubed result in a cycle of length $5$ or of length $7$ . Also, a cycle of length $6$ cubed gives us a product of $3$ disjoint cycles of length $2$ and this doesn't work either. So, $x$ can only be the product of disjoint cycles of length $2$ , $3$ and $4$ . Now, a cycle of length $2$ cubed equals itself, a cycle of length $3$ cubed is the identity and a cycle of length $4$ cubed is a cycle of length $4$ . Since $x^3$ must have a cycle of length $4$ and one of length $2$ in its decomposition, we see that it is necessary that $x$ be the product of a cycle of length $2$ and a cycle of length $4$ (there is no room for some other cycle of length $3$ ). So, after some computations, we get that the only solution is $x=(37)(1652)$ . Is this solution correct?","['permutations', 'group-theory', 'abstract-algebra', 'symmetric-groups']"
4005684,"Number of couples of columns of a certain binary matrix ""connecting"" top and bottom","Consider a $h \times l$ binary matrix (a matrix with all entries $a_{ij}$ , $1 \le i \le h$ , $1 \le j \le l$ , equal to $0$ or $1$ ). We know that each row has $n \lt l$ entries equal to $1$ and $l - n$ entries equal to $0$ . All rows are different. There are a total of ${l \choose 2}$ possible couples of columns in it. Let $c$ be the number of couples of columns with index $j$ and $k$ such that $a_{ij} = 1 \lor a_{ik} = 1$ , $1 \le i \le h$ . It's like there is a path of ones from the top to the bottom of the matrix along the two columns. I would like to find a function $f(h, l, n)$ to have a lower bound for $c$ : $$c \ge f(h, l, n)$$ My thoughts: we have a total of $n \cdot h$ entries equal to $1$ , thus on average a column will have $\frac{nh}{l}$ ones, therefore there exist a column with at least $\lceil\frac{nh}{l}\rceil$ ones, but it is difficult to extend this reasoning for counting the couples. Also, maybe using generating functions in some way like in this answer of mine . I am especially interested in $n = \frac{l}{2}$ (or near to it) and $h \le \frac{l}{4}$ (about; for $h$ big enough it is clear that $c = 0$ ). Any hint?",['combinatorics']
4005706,How many combinatorially distinct ways are there to tile an equilateral triangle with $k$ $60^\circ-120^\circ$ trapezoids?,"I believe there is exactly one way (up to combinatorial equivalence) to arrange 3 trapezoids with angles of $60^\circ$ and $120^\circ$ into an equilateral triangle: With $4$ trapezoids, I see two ways: With $5$ trapezoids, there are many more; I count at least $13$ (thanks to Dan Uznanski for discovering the last of these): In general, how many ways are there to do this with $k$ trapezoids, and what are the corresponding arrangements? Knowing that the sequence starts $1,2,13?,\ldots$ isn't quite enough to try and find it on OEIS. (I'd also appreciate hearing about any configurations that I may have missed above.) Edit : It seems that the terminology above was not clear to everyone, so two clarifications: When I say ""trapezoids"" here, I am referring only to those pictured above, where there is exactly one pair of parallel sides and the $60^\circ$ angles are adjacent; I am not including parallelograms with angles in cyclic order $(60^\circ, 120^\circ, 60^\circ, 120^\circ)$ . Two arrangements are combinatorially equivalent if there is a bijection between the corners, edges, and faces of the two which preserves inclusion (e.g. of a vertex on a face or one line segment in another), adjacency, overlaps, and maps $60^\circ$ and $120^\circ$ angles in trapezoids to themselves. In other words, we care about the incidence structure of the trapezoids, and whether trapezoids $A$ and $B$ coincide along a shared leg, but not about specific lengths of line segments or a rotation of the large triangle.","['geometry', 'oeis', 'reference-request', 'combinatorial-geometry', 'tiling']"
4005725,Bijection between a set of injections and a union of bijection,"Consider $A$ a set with $n$ elements and $k\leq n$ . Show that $$
\phi:\left\{  f:\left\{  1,2,\ldots,k\right\}  \rightarrow A\mid f\text{
injective}\right\}  \rightarrow
{\bigsqcup\limits_{B\subset A,card(B)=k}}
\left\{  g:\left\{  1,2,\ldots,k\right\}  \rightarrow B\mid g\text{
bijective}\right\}
$$ by constructing an explicit bijection. By generalizing the construction above, show that $$
\Phi:\left\{  f:A\rightarrow C\mid f\text{ injective}\right\}  \rightarrow
{\bigsqcup\limits_{B\subset C.card(C)=n}}
\left\{  g:B\rightarrow C\mid g\text{ bijective}\right\}  .
$$ I attempted to start from the observation that every injective function $f$ has an image $\operatorname{Im}f$ as subset of $A$ with exactly $k$ elements.
Reciprocally every subset of $A$ with $k$ elements is the image of some
injection. But there are $k!$ injections that maps a fixed set $C$ into a
subset of $A$ with $k$ elements. Now, every $$
f:\left\{  1,\ldots,k\right\}  \rightarrow A
$$ gives us a bijection $g:\left\{ 1,\ldots,k\right\}  \rightarrow B,B\subset A$ and $card(B)=k$ . From this point, I don't know how to move forward. How can I
find an explicit bijection?",['elementary-set-theory']
4005748,Banach spaces admitting a coarser topology for which the closed unit ball is compact.,"Let $X$ be a Banach space and let $B$ be its closed unit ball. It is well known that $B$ is compact in the weak topology provided $B$ is reflexive.   Otherwise,   if $X$ is at least
a  dual space, then $B$ is compact in the weak* topology. These examples show that, in many situations, there exists a Hausdorff locally convex topology on $X$ , coarser than the
norm topology,  relative to which $B$ is compact. For $X=c_0$ , I cannot think of such a topology and I doubt it exists.  The reason is I feel the sequence $\{x_n\}_n$ given
by $$
  x_n= (1,1,\ldots, 1,0,0, 0\ldots)
  $$ ( $n$ ones) cannot possibly have a cluster point in any sensible topology. Question .  Given a Banach space $X$ ,  is there always  a Hausdorff locally convex topology on $X$ , coarser than the
norm topology, relative to which the
closed unit ball is compact? Can one characterize the spaces for which this is true?
What if $X=c_0$ ?","['banach-spaces', 'reflexive-space', 'functional-analysis', 'weak-topology', 'locally-convex-spaces']"
4005835,What are all the integral solutions of $n!=m(m^2-1)$?,"Observe that: $3!=2(2^2-1)$ $4!=3(3^2-1)$ $5!=5(5^2-1)$ $6!=9(9^2-1)$ Question : What are all the integral solutions of $n!=m(m^2-1)$ ? I guess it is just $(n,m) = (3,2),(4,3),(5,5),(6,9)$ , but how to prove that there is no other one? I checked that there is no other one for $n<20$ . Let reformulate the problem using Cardano's formula :    consider the cubic equation $$x^3+px+q=0,$$ its discriminant is $\Delta = -(4p^3+27p^2)$ . Our case corresponds to $(p,q) = (-1,-n!)$ , so $\Delta = 4-27(n!)^2 <0$ . Thus the cubic has one real root and two non-real complex conjugate roots, and by Cardano's formula, the real root is $$ \left(-\frac q2+\sqrt{\frac{q^2}4+\frac{p^3}{27}} \right)^{1/3} +\left(-\frac q2-\sqrt{\frac{q^2}4+\frac{p^3}{27}}\right)^{1/3} $$ So the problem ""reduces"" to ask whether there exists an integer $n>6$ such that $$ \left(\frac{n!}{2} +\sqrt{\frac{(n!)^2}{4} - \frac{1}{27}} \right)^{1/3} +\left(\frac{n!}{2} - \sqrt{\frac{(n!)^2}{4} - \frac{1}{27}} \right)^{1/3}  $$ is also an integer. It is not clear that it helps...","['number-theory', 'elementary-number-theory', 'integers', 'diophantine-equations', 'arithmetic']"
