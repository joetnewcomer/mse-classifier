question_id,title,body,tags
137255,Kullback divergence vs chi-square divergence,"If the probability measures $P$ and $Q$ are mutually absolutely continuous, Kullback divergence $K(P,Q)=\int \log\left(\frac{\mathrm{d}P}{\mathrm{d}Q}\right)\mathrm{d}P$, and chi-square divergence $ \chi^2(Q,P) = \int \left( \frac{\mathrm{d}Q}{\mathrm{d}P}−1\right)^2 \mathrm{d}P$, how to prove that $$ K(P,Q) \leqslant \frac{1}{2}\chi^2(Q,P)$$",['probability-theory']
137277,Constructing a subset not in $\mathcal{B}(\mathbb{R})$ explicitly,"While reading David Williams's "" Probability with Martingales "", the following statement caught my fancy: Every subset of $\mathbb{R}$ which we meet in everyday use is an element of Borel $\sigma$-algebra $\mathcal{B}$; and indeed it is difficult (but possible!) to find a subset of $\mathbb{R}$ constructed explicitly (without the Axiom of Choice) which is not in $\mathcal{B}$. I am curious to see an example of such a subset.","['probability-theory', 'descriptive-set-theory', 'reference-request', 'axiom-of-choice']"
137287,Proving that a subgroup of a finitely generated abelian group is finitely generated,"A question says: Using the isomorphism theorems or otherwise, prove that a subgroup of a finitely generated abelian group is finitely generated. I would say that for a finitely generated abelian group $G$, there exists elements $g_1,\dots, g_n$ such that a linear combination of them generates the whole group. Therefore as every element of a subgroup has an element in $G$ and so can be made by a linear combination of $g_1,\dots, g_n$. This means that $g_1,\dots, g_n$ span the whole subgroup and so there exists a subset of $g_1,\dots, g_n$ which generates the subgroup. This answer seems far too 'linear algebra-ish' rather than 'group theory-ish' and I can't seem to see how one would use the isomorphism theorems? Help would be appreciated!","['group-theory', 'abstract-algebra', 'abelian-groups']"
137290,Lie and Weierstrass' visualization of complex functions,"I am reading Whittaker and Watson's A Course of Modern Analysis . In the third chapter where they discuss different ways to visualize functions that map the complex plane to the complex plane, they remark: One suggestion (made by Lie and Weierstrass) is to use a doubly-manifold system of lines in the quadruply-manifold totality of lines in three-dimensional space. This is their entire description of Lie and Weierstrass' approach, and it is too vague for me to figure out what is being suggested. Does anyone know what this refers to? Does anyone have references for Lie and Weierstrass' work on complex function visualization?","['math-history', 'complex-analysis']"
137297,Twists of rational points,"Let $X$ be a  ""nice"" algebraic curve over some field $K$, say characteristic zero. The twists of $X$, i.e., the curves $Y$ over $K$ such that $X_{\overline K} \cong Y_{\overline K}$, are in bijection with the continuous cohomology pointed set $$H^1(\mathrm{Gal}(\overline{K}/K),X).$$ I was just wondering about an analogous question for ""sections"" of curves. Now, let $x\in X(K)$. Define a twist of $x$ to be a point $y\in X(K)$ such that $x_{\overline K}$ is ""isomorphic""  to $y_{\overline K}$. (I don't know if it makes sense to talk about ""isomorphic"" sections. But what I mean is that there is an automorphism $\sigma$ of $\overline K$ such that $x_{\overline K}\circ \sigma = y_{\overline K}$. Q1. Are twists of $x$ in bijection with some ""cohomology set""? Q2. Do there even exist any non-trivial twists of $x$? I get a feeling that $x_{\overline K}\circ \sigma$ always descends to $x$ forcing $x=y$.","['arithmetic-geometry', 'algebraic-geometry', 'schemes', 'algebraic-curves']"
137304,An application of Runge's theorem,"I have been thinking about the following exercise from some complex analysis lecture notes I found online for a while but I can't seem to be able to conclude the desired result. The exercise says that If $A$ is an open subset of the complex plane, and if $g: A \rightarrow \mathbb{C}$ is analytic, then there is a sequence of rational functions $(f_n)$ such that no pole of the $f_n$'s lies in $A$ (that is, that the poles are in $\overline{\mathbb{C}} \setminus A$) and such that $f_n \rightarrow g$ uniformly on compact subsets of $A$. I know that I have to apply Runge's theorem here, but the problem is that Runge's theorem tells me that the sequence of functions $f_n$ converges uniformly to $g$ on a compact set $K \subseteq A$ and not on the whole $A$. I thought that maybe I can approximate the open set $A$ by compact sets $K_n$ and take elements from a sequence $f_{n,k}$ that converges uniformly on each of the compacts, and then any given compact $K\subset A$ would have to be contained in one of the compacts  $K_n$ approximating $A$ but I'm not sure if this is possible of if it this works. I would appreciate any help with this exercise. Thanks.",['complex-analysis']
137314,compactness property,"I am a new user in Math Stack Exchange. I don't know how to solve part of this problem, so I hope that one of the users can give me a hand. Let $f$ be a continuous function from $\mathbb{R}^{n}$ to $\mathbb{R}^{m}$ with the following properties:$A\subset \mathbb{R}^{n}$ is open then $f(A)$ is open. If $B\subset \mathbb{R}^{m}$ is compact then $f^{-1}(B)$ is compact. I want to prove that $f( \mathbb{R}^{n}) $ is closed.",['general-topology']
137316,Why is the numerical range of a self-adjoint operator an interval?,"I was reviewing for a test for functional analysis when I came across the following statement: Let $T$ be a bounded self-adjoint operator on a Hilbert space $H$. Then the numerical range of it is an interval $[m, M]$ with $M>0$. Is the above statement correct? How can I prove it? Thank you!!","['spectral-theory', 'hilbert-spaces', 'functional-analysis']"
137319,How do we justify functions on the Ordinals,"In ZFC there seem to be two ways to define a function, as an ordered triple of domain, codomain and the set of ordered pairs that make its graph, or a relation over the two sets. Whichever we use doesn't matter, but this seems to present a certain problem. Both are defined over sets, but no-one seems to have any problem defining functions on the ordinals like Hartog's function giving the minimum ordinal that doesn't have an injective function on to the given ordinal. I know we want to be able to obviously, but how are we supposed to justify this, because the definitions of functions don't seem to include classes. Or is there a nicer definition I've missed?","['set-theory', 'ordinals', 'functions']"
137332,Relationship between ratios and averages of ratios?,"My colleague and I were wondering: For a weighted average of ratios - what weight would need to be assigned to each term in the expression such that the result of the weighted average was the same as the sum of the numerators in the ratios divided by the sum of the denominators in the ratios: $\displaystyle \frac{\sum_{i = 1}^{n} x_i }{\sum_{i = 1}^{n} y_i} = \frac{\sum_{i = 1}^{n} ( (\frac{x_i}{y_i})  ? ) }{n} $ In the equation above, what would the ""?"" need to be such that the equality holds?",['algebra-precalculus']
137343,"When expressing area of $f(D)$ using Jacobian, why exactly must $f$ be one-to-one?","I was working on a question very similar to this one: Expressing the area of the image of a holomorphic function by the coefficients of its expansion Clearly the key lies in the formula 
$$\iint_{f(D)}dxdy=\iint_D\operatorname{Jac}(f)\,dx\,dy,$$
which turns out to be
$$\iint_D|f'|^2\,dx\,dy$$
for holomorphic functions (using Cauchy-Riemann equations). But it has been pointed out that this is only true for one-to-one functions. Intuitively this makes sense to me since the integral would sum the same area more than once if it were not one-to-one. But then... Is it correct to generalize this formula to functions which are not one-to-one by saying
  $$\iint_{f(D)}dxdy\leq \iint_D|f'|^2\,dx\,dy$$
  with equality when $f$ is one-to-one? Would equality also hold if the set of points in the image which have more than one pre-image is non-empty but has measure zero? Or can stranger things happen that I have not considered? If my question makes more sense with $\operatorname{Jac}(f)$ in place of $|f'|^2$, please let me know, and feel free to use the former instead. Thanks.","['complex-analysis', 'analysis']"
137346,"Why are $\mathbb A_k^2 \backslash \{(0,0) \} $ and $\mathbb P_k^2 \backslash \{(0,0) \} $ not isomorphic to affine nor projective varieties?","Why are $\mathbb A_k^2 \backslash \{(0,0) \} $ and $\mathbb P_k^2 \backslash \{(0,0) \} $  isomorphic to neither affine nor projective varieties? I've seen this question in several different places, but haven't been able to do it. Any hints/explanations appreciated. Thanks",['algebraic-geometry']
137354,Compactness of the set of all unitary matrices in $M_2(\mathbb{C})$,Is the set of all unitary matrices in $M_2(\mathbb{C})$ is compact? I can show that as determinant map is continuous so unitary matrices are closed but how to show they are bounded? Please help.,"['general-topology', 'matrices', 'linear-algebra']"
137362,How to find perpendicular vector to another vector?,"How do I find a vector perpendicular to a vector like this: $$3\mathbf{i}+4\mathbf{j}-2\mathbf{k}?$$
Could anyone explain this to me, please? I have a solution to this when I have $3\mathbf{i}+4\mathbf{j}$, but could not solve if I have $3$ components... When I googled, I saw the direct solution but did not find a process or method to follow. Kindly let me know the way to do it. Thanks.","['vector-spaces', 'geometry', 'linear-algebra', 'vectors']"
137364,Thoughts on the Collatz conjecture; integers added to powers of 2,"I've had a thought about the Collatz conjecture (the 3n+1 problem). Suppose some number, C, diverges under the iteration. We first note that C must be odd because if C were even it would be halved immediately, and so $\frac {C}{2}$ would be the lowest. Take some arbitrary power of 2, $2^a, a>1$, and let us perform the iteration on $2^a +1$ $2^a+1$ is odd, so we go to $3*2^{a}+4$, then to $3*2^{a-1}+2$ and to $3*2^{a-2}+1$ Since we observe that $3*2^{a-2}+1 < 2^{a}+1$, C cannot be of the form $2^a+1$. Now suppose we have some number n which definitely goes to 1. We now perform the Collatz iteration on $2^{a}+n$. The parity of this number is identical to the parity of n. If we were to perform 3n+1, then we would have $3*2^{a}+3n+1$ Indeed, since the parity of the number is determined by n, the iteration (i.e. whether we triple and add one or halve) is identical to that of n. If we say there are $\alpha$ '3n+1's and $\beta$ '$\frac{n}{2}$'s, this gives us the expression $\frac{3^{\alpha}}{2^{\beta}}*2^{a}+1 < 2^{a}+1 < 2^{a}+n$ (provided $\frac{3^{\alpha}}{2^{\beta}}<1$) We know this is the same iteration which n must undergo, and we know that when n is iterated, we will arrive at the following: $\frac{3^{\alpha}}{2^{\beta}}n+k=1 > \frac{3^{\alpha}}{2^{\beta}}n$ Where k is some positive constant dependent on the order of the iterations. This implies that $\frac{3^{\alpha}}{2^{\beta}}<1$. So, as we had with the case n=1, provided that n goes to 1, $2^{a} +n$ goes to 1. Now suppose we had verified the case of the collatz conjecture for some small numbers; say 1 and 3. Not only is it true for n=1 & 3, but it is also true for 5,7,9,11,17,19, etc. And since it is true for 1,3,5,7... it must be true for 9,11,13 and 15, from which we can say it is true for 17,19,21 and so on for all odd whole numbers. And therefore our number C at the start is neither odd nor even, and so there is no smallest number which diverges to infinity. In fact, if we say that C could be the smallest element in a cycle then we would also have a contradiction. Is this legit? I've probably made an error somewhere, but I figured it was worth putting it on here since it might get some attention. Thank you for your time. UPDATE:
It has been pointed out that there is a flaw in the argument. Specifically, that we have assumed that a, the power on 2, Is larger than $\beta$ when, in general, it is not. The consequence of this is that certain numbers, specifically those of the form $2^{a}-n$ where a is any integer greater than 1 and n is either 1, 5 or 17. For example, if we take $2^{4}-5=11$, we have: $2^{4}-5 \rightarrow 3*2^{4}-14 \rightarrow 3*2^{3}-7 \rightarrow 3^{2} * 2^{3}-20 \rightarrow 3^{2} * 2^{2}-10 \rightarrow 3^{2} * 2^{1}-5 \rightarrow 3^{3} * 2^{1}-14 \rightarrow 3^{3}-7 $ Apologies for the rather messy notation but it helps us to see what is going on. First of all, we see that 4 has been reduced to nothing without us learning very much about the number (certainly not whether it decreases). We also note that in the 1st and 6th terms 5 appears on the end - this is because when we extend the iteration into negative integers, there are more cycles than 1-2-4 , and their smallest elements are precisely -1, -5 and -17.","['collatz-conjecture', 'open-problem', 'number-theory']"
137374,Eccentricity of an ellipse,"How is $\frac{PF}{PD} = e = \frac{C}{A}$ ? where e is eccentricity, P stands for any point on the ellipse. $F$ stands for one of the foci. $e$ stands for eccentricity. $D$ is a point on the directrix of the ellipse. 'C' is the distance from the center to the focus of the ellipse 'A' is the distance from the center to a vertex. This is referring to an ellipse/hyperbola/parabola and their conic sections. The problem is not the proof for how $PF/PD = e$, or how $C/A = e$, but how the two equate to each other. (The letters stem from the points/foci of an ellipse of a cone and its directrix). What is the answer that does NOT use analytic geometry? (only trigonometry)","['geometry', 'trigonometry', 'conic-sections']"
137399,"Is there a ""continuous product""?","Is there a ""continuous product"" which is the limit of the discrete product $\Pi$ , just like the integral $\int$ is the limit of the summation operator $\sum$ ? Thanks!","['products', 'calculus', 'integration']"
137410,Arc Length under change of parameter,"This is from Apostol's Calculus Vol. I, Section 14.13 #21: Let $C$ be a curve described by two equivalent functions $X$ and $Y$, where $Y(t)=X[u(t)]$ for $c\le t\le d$. If the function $u$ which defines a change of parameter has a continuous derivative in $[c,d]$ prove that $$\int_{u(c)}^{u(d)} \! ||X'(u)||\,\mathrm du=\int_c^d \! ||Y'(t)||\, \mathrm d t$$
and deduce that the arc length of $C$ is invariant under such a change of parameter. I believe that the condition placed on the derivative of $u$ should not have been continuity but rather non-negativity. First a counter-example:
$$Y(t)=t\boldsymbol i\,,\quad X(t)=-t\boldsymbol i \, , \quad u(t)=-t\,.$$
Then $Y(t)=X[u(t)]$ over, say, $0\le t\le 1$ and $u'(t)=-1$ is certainly continuous. Now $||X'(t)||=1$ and $||Y'(t)||=1$ but
$$\int_{u(0)}^{u(1)} \! ||X'(u)||\,\mathrm du=\int_0^{-1}\!\mathrm d u=-1$$
and
$$\int_0^1 \! ||Y'(t)||\,\mathrm dt=\int_0^1\!\mathrm d t=1\,.$$ On the other hand, if we require $u'(t)\ge0$ (and I don't think we even need continuity, do we?) then we can write $$\begin{align}Y'(t)&=X'[u(t)]u'(t)\\
||Y'(t)||&=||X'[u(t)]u'(t)||\\
&=||X'[u(t)]||\cdot |u'(t)|\\
&=||X'[u(t)]||u'(t)\\
\implies\int_c^d\!||Y'(t)||\,\mathrm d t&=\int_c^d \!||X'[u(t)]||u'(t)\,\mathrm d t\\
&=\int_{u(c)}^{u(d)}\!||X'(u)||\,\mathrm d u \end{align}$$ Is this correct? Should the condition on $u'$ be non-negativity, rather than continuity, or do I need non-negativity in addition to continuity? I don't see anything in my proof at the end that requires continuity, but maybe I'm glossing over it.","['calculus', 'integration']"
137424,"I need some advice for $ \; "" \; 3xy+y-6x-2=0 \;""\, $","PS: I edited the title again and I think, it's better now... :) Actually, almost the whole solving way is wrong but, I understood why ... :D :) You can check that or add some more useful links about my method, unfortunately, which I applied it wrong... Thank you. :) Here is a problem which I've encountered and found the answer luckily, I think. But, actually, I need some better or faster ways to solve that: The problem: $ \; \large{ 3xy+y-6x-2=0 \; , \; y=\,?  } \; $ $$ My \; method:  $$ $$ \large{ y(3x+1)-6x-2=0 } \\ $$ 
$$ \large{ X_{1}+X_{2}=\frac{-b}{a} \; \land \; X_{1}-X_{2}=\frac{ \sqrt{\Delta} } {|a|} \; \land \; \Delta=(b)^{2}-((4) \times (a) \times (c)) } $$
$$ \large{ X_{1}+X_{2}=\frac{-(-6)}{(3x+1)} \; , \; \; X_{1}-X_{2}=\frac{ \sqrt{44+24x} } {|3x+1|} \; , \; \; \Delta=44+24x  } $$
$$ \large{ (X_{1}+X_{2})+(X_{1}-X_{2})=2X_{1} \\ 
2X_{1}=\frac{-(-6)}{(3x+1)}+\frac{ \sqrt{44+24x} } {|3x+1|} \\ 
\frac{ \sqrt{44+24x}+6 } {|3x+1|}=2X_{1} \\ 
8X_{1}=\sqrt{44+24x}+6 \\ 
(8X_{1})^{2}=(\sqrt{44})^{2}+(\sqrt{24})^{2}+(6)^{2} \\
64X_{1}=44+24x+36 \\ 
40X_{1}=80 \\ 
X_{1}=2 } $$
$$ \text{ Then, I recalled the first equation with } \, ''X_{1}'' \, \text{ and rewrote it down: } $$
$$ \large{ 3 \times (2) \times y + y - 6 \times (2) = 0 \\
7y-14=0 \\
y-2=0 \\
y=2 } $$ My other question is, if you would encounter this problem in a test , which method you would try to do it as fast as you could? Thank you very much!...","['algebra-precalculus', 'advice']"
137431,one counter example for sum of two closed set need not be closed [duplicate],This question already has answers here : Sum of two closed sets in $\mathbb R$ is closed? (5 answers) Closed 8 years ago . I know the proof that If A is compact and B closed then A+B is closed but would like to have an example where both are closed but not A+B.I am not able to figure out.,['general-topology']
137435,"order of ""truncated"" braid groups","Consider the braid group on n strands given in the usual Artin presentation. Then add extra relations: each Artin generator has order d. For example, if d=2, one recovers the symmetric group. I would like to know what the order of the group is for arbitrary n and d. Even knowing the name of such groups would be helpful, though, as my attempts to determine this by searching the literature have so far failed.",['group-theory']
137468,"""Algebraic multiplicity"" for eigenvalues of a Sturm-Liouville-like problem?","Following Coddington-Levinson's book Theory of ordinary differential equations , chapter 7: ""Self-adjoint problems on finite intervals"", let us consider the eigenvalue problem $$\pi(l):\begin{cases} Lx(t)= lx(t) & t \in [a, b] \\ Ux=0 \end{cases}$$ where $Lx=p_0(t)x^{(n)}+p_1(t)x^{(n-1)}+\ldots + p_n(t)x(t)$ (with $p_0(t)\ne 0$, the problem is not singular) and $Ux=0$ stands for the boundary conditions $$U_jx=\sum_{k=1}^n(M_{jk}x^{(k-1)}(a)+N_{jk}x^{(k-1)}(b)),\qquad j=1\ldots n.$$ Also let $\pi$ be self-adjoint , meaning that $\int_a^b Lu\overline{v}\, dt=\int_a^bu\overline{Lv}\, dt$ for all $u, v \in C^n$ satisfying boundary conditions $Uu=Uv=0$. We say that $l\in \mathbb{C}$ is an eigenvalue of $\pi$ if $\pi(l)$ admits non trivial solutions. Coddington-Levinson's theorem 2.1 asserts that all eigenvalues are real and that they have no finite cluster point. What is interesting for this question is the proof: the authors start taking a fundamental system $\{\varphi_j, j=1\ldots n\}$ of solutions of the linear equation $Lx=lx$, observing that each $\varphi_j$ depends analytically on $l$. Then they point out that the generic solution $$x=\sum_{j=1}^nc_j \varphi_j$$ of $Lx=lx$ is an eigenvalue of $\pi$ if and only if $$\tag{1} \sum_{j=1}^n c_j U_k\varphi_j=0 \qquad k=1\ldots n, $$ which is a system of $n$ homogeneous linear equations in $n$ unknowns $c_1 \ldots c_n$. The determinant $\Delta$ of  $(1)$ is an entire function of $l$ and it vanishes exactly at the eigenvalues of $\pi$. At this point the authors finish off their proof, while we proceed to our question. Question This $\Delta$, being entire and vanishing at eigenvalues, might be regarded as an infinite-dimensional analogue of the
  characteristic polynomial of a matrix. Is there any relationship
  between the multiplicity of its zeros and the geometric multiplicity of the
  corresponding eigenvalues (i.e. the dimension of the associated
  eigenspaces)? Thank you.","['linear-algebra', 'spectral-theory', 'ordinary-differential-equations']"
137483,Scalar product on manifold.,"Let $M$ be a closed Riemannian manifold and $\omega$ and $\eta$ two differential forms of the same degree. Then one can consider $\int_M \omega \wedge *\eta$, where $*$ denotes the Hodge star operator. Can you tell me, why this defines a scalar product or at least where I can find a proof of this fact? In particular I would be very interested why this expression is symmetric in $\omega$ and $\eta$ and why it is positive definite.",['differential-geometry']
137518,Determining the Length of a Curve Using Partitions,"I have encountered the following problem: Let $f$ be continuous on $[a,b]$. Define the length of $f$ on $[a,b]$ by
  $$l=\sup_P[\lambda_P(f)],$$
  where
  $$\lambda_P(f)=\sum_{k=1}^N\sqrt{(x_k-x_{k-1})^2+(f(x_k)-f(x_{k-1}))^2},$$
  and the supremum is taken over all partitions $P=\{a=x_0<x_1<\cdots<x_N=b\}$ of $[a,b]$. Show that $\lambda_P(f)\leqslant\lambda_Q(f)$ for any refinement $Q$ of $P$. Then, show that there is a sequence $(P_n)_{n=1}^\infty$ such that
  $$l=\lim_{n\to\infty}\lambda_{P_n}(f).$$ This is what I have done: Let $Q\supseteq P$. If $Q=P$, then $\lambda_Q(f)=\lambda_P(f)$. If $Q\neq P$, then it must be the case that there is at least one $c\in Q$ such that $c\notin P$. This implies that $\lambda_Q(f)$ will have at least one more sum than $\lambda_P(f)$, and because distance is a non-negative value, we must have that $\lambda_P(f)\leqslant\lambda_Q(f)$. Moreover, take the sequence $(P_n)_{n=1}^\infty=P_1\supset P_2\supset\cdots$. Then, from above, $\lambda_{P_1}(f)\leqslant\lambda_{P_2}(f)\leqslant\cdots$. Hence, if the limit exists, we must have that
$$l=\lim_{n\to\infty}\lambda_{P_n}(f).$$ Does this seem reasonable?",['real-analysis']
137532,Existence of an entire function with algebraically independent derivatives,"Let $\mathbb{A}$ be the algebraic closure of $\mathbb{Q}$ in $\mathbb{C}$. A collection of functions $F=\lbrace f_i:X \rightarrow\mathbb{C}\rbrace$ is said to be algebraically independent over $\mathbb{Q}$ at $x \in X$ if the $f_i(x)$ are distinct, at most one of the $f_i(x)$ is algebraic and $ \lbrace f_i(x) \rbrace - \mathbb{A} $ is algebraically independent over $\mathbb{Q}$. (The reason why I allow one $f_i(x)$ to be algebraic will become clear shortly.) I would like to know whether there exists a 2-sided sequence of entire functions: $\ldots, f^{(-2)},f^{(-1)},f^{(0)},f^{(1)},f^{(2)}, \ldots$ such that for every $n \in \mathbb{Z}$, $f^{(n)}(z)=\frac{d}{dz}f^{(n-1)}(z)$, and the collection $\{f^{(i)} \: | \: i \in \mathbb{Z}\}$ is algebraically independent over $\mathbb{Q}$ everywhere except possibly on a ""small"" set S. Ideally, I'd like S to be empty, or at least closed and discrete, but pretty much any smallness condition you like would help me at least get some intuition for how to deal with such a problem. Note that unless S is dense, there is an open set $U$ in its complement. By the open mapping theorem, each $f^{(i)}(U)$ is open and hence contains algebraic numbers. So allowing one $f^{(i)}$ to be algebraic at each point is necessary. My thoughts (feel free to ignore them if you have your own approach): It's pretty easy with the Lindemann–Weierstrass theorem to construct $f^{(0)}$ such that the derivatives of $f^{(0)}$ at 0 are algebraically independent, and choosing integration constants appropriately for negative $n$ gives a sequence which works at 0. The problem is that evaluating the function anywhere other than 0 requires summing an infinite series, something which behaves poorly with respect to transcendence. It is likely not plausible to prove that any specific function works, since transcendence theory doesn't have many general results. On the other hand, I suspect that if such a function exists, they will be generic, or at least common. There may be an easy way to approach the problem nonconstructively with functional analysis. I couldn't think of anything in this direction, though. On the other hand, if such a function does not exist, there should be a good reason why not. I suspect it would be demonstrable with just a few derivatives based mostly on topology. By the open mapping theorem, on each open set $\mathbb{A}(f^{(i)}(z))$ takes every value possible for each $i$. This seems like a strong condition, but it also implies that one can't topologize the field extensions of $\mathbb{A}$ in any nice way, which poses a bit of an issue if one wants to continue on this route.","['transcendence-theory', 'complex-analysis']"
137538,Calculate the vector normal to the plane by given points,"How can one calculate the vector normal to the plane that is determined by given points? For example, given three points $P_1(5,0,0)$, $P_2(0,0,5)$ and $P_3(10,0,5)$, calculate the vector normal to the plane containing these three points. The compute the normal is by vector product.
$$
a = \left(\begin{matrix} x_2-x_1\\y_2-y_1\\z_2-z_1 \end{matrix} \right)
\qquad
b = \left(\begin{matrix} x_3-x_1\\y_3-y_1\\z_3-z_1 \end{matrix} \right)
$$
therefore $a = -5i+5k$, and $b=5i+5k$
$$
a\times b = \left|\begin{matrix}
    i & j & k \\
    -5 & 0 & 5 \\
    5 & 0 & -5 \\
\end{matrix}\right|
$$ The questions are: 1) Are A and B is given, that means no matter which three point i use, the $a$ and $b$ is still using this to calucate? 2) How to get $a$ , $b$ and $a\times b$ ? Thank you","['analytic-geometry', 'cross-product', 'linear-algebra']"
137541,Coterminal Angles?,"I understood coterminal angles as angles that have the same terminal angle value. By this logic, why aren't 135 and 315 coterminal? They both have a terminal angle of  45. Is my interpretation of coterminal angles wrong?","['trigonometry', 'terminology']"
137544,Expectation of $QQ^T$ where $Q^TQ=I$,"It's exercise 1.1 on p.2 of this book . The goal is to is to show that, for some random matrix $Q \in \mathbb{R}^{n\times k}$ where $k<n$ and the columns of $Q$ are orthogonal (i.e. $Q^T Q = I$; and assuming $Q$ is uniformly distributed in whatever space it's a member of), then for $u \in \mathbb{R}^{n}$ and $v = \sqrt{n/k}Q^Tu$, the following holds:
$$E(\|v\|^2)=\|u\|^2$$ I tried a few monte carlo experiments, and it does work out. It seems that
$$E(QQ^T) = \textrm{diag}(k/n,\ldots,k/n)$$ If $Q$ is relaxed to be standard gaussian, I can work it out analytically. But I'm stumped how this works if $Q$ has an orthogonality constraint. So how does $$E(\|v\|^2)=\|u\|^2$$ work?","['geometry', 'probability']"
137556,Book recommendations from basic algebra to precalculus?,"I graduated high school a while ago, hardly remember anything and have no idea where to begin relearning.","['geometry', 'trigonometry', 'algebra-precalculus', 'reference-request']"
137568,Sex distribution,"Suppose there are N male and N female students. They are randomly distributed into k groups. Is it more probable for a male student to find himself in a group with more guys and for female student to find herself in a group with more girls? The question is motivated by an argument with my mother. She claimed that in the majority of collectives where she was, the number of women besides her was greater than men, while I had the opposite impression, that in most collectives where I was a member there was more men even if not to count myself. I never was in a majority-girls collective, so I think for a male it is more probable to find oneself in a majority-male collective (even if we exclude oneself).","['probability-theory', 'probability']"
137573,divergence of a vector field on a manifold,"I've been asked to show the following: For a vector field $V$ on a semi-Riemannian manifold with metric $g$ that $$Div \cdot V = \frac{1}{\sqrt{\det(g)}}\partial_i\left(\sqrt{\det(g)}V^i\right)$$ I know we're supposed to use Christoffel symbols as well as a few matrix formulas, but I'm not sure how to proceed. In particular, we were given that for a (invertible) matrix $M$ with some parameter $s$, that $$\frac{d}{ds}\det M(s)=\det M(s) \cdot tr\left(M(s)^{-1}\frac{d}{ds}M(s)\right)$$ and $$\frac{d}{ds}(M(s)^{-1})=-M(s)^{-1}M'(s)M(s)^{-1}$$ Any help would be greatly appreciated. The definition of divergence that we were given was $$Div \cdot V = \nabla_{\partial_i}V^i = \partial_iV^i+\Gamma_{ij}^iV^i$$",['differential-geometry']
137577,number of combination in which no two red balls are adjacent.,"given x spaces(you can fit 1 ball in 1 space) and unlimited number of identical red and white balls, find the total number of combinations in which no two red balls are adjacent to each other. i tried this theory like lets says i have 5 spaces then i fill in the white balls like this _W_W_ and W_W_W then in the rest of the spaces i fill in either red or white balls but unfortunately values like RWWRW get left out, so my that theory is wrong. does any one have any idea how to solve this. i know the number of values your are suppose to get if it helps. for 3 spaces-->5 for 4 spaces-->8 for 5 spaces-->13 for 6 spaces-->21","['permutations', 'combinatorics']"
137583,How to find $\int{\left(\frac{\sqrt{x+1}}{x-1}\right)^x}dx$?,"I have tried to find $$\int{\biggl(\dfrac{\sqrt{x+1}}{x-1}\biggr)^x}dx$$ but I don't know how to do it, because it combines $u^x$ and $\dfrac{u}{v}$.","['calculus', 'integration']"
137589,Interesting puzzle about a sphere and some circles,"Suppose I have a sphere and I choose a point $P$ on it. Then I draw $N\ge 3$ circles on the sphere passing through that point in a manner such that all the intersection points of the final result involve $\ge 3$ circles. Why then must there be a point other than $P$ where all the circles pass through? My thoughts are that we cannot have a polygonal decomposition of the sphere where every vertex has $\ge 6$ edges coming out of it (follows from Euler's relation). So there has to be an ""object"" with 2 edges only. But then I am not sure how to conclude that the above is true. Added: I think @joriki 's assumption is right -- the circles don't just touch at $P$. Otherwise the question would be trivially wrong.",['geometry']
137593,Factor 90301 without the aid of the computer,"Computer break down easily know $90301=73\cdot1237$
Is there any way I want, 
without the aid of the computer to determine 90301
 is a prime number or Composite number",['number-theory']
137594,Showing that some symplectomorphism isn't Hamiltonian,"I have the next symplectomorphism $(x,\xi)\mapsto (x,\xi+1)$ of $T^* S^1$, and I am asked if it's Hamiltonian symplectomorphism, i believe that it's not, though I am not sure how to show it. I know that it's Hamiltonian when there's a hamiltonian isotopy $\phi_t$ s.t $\phi_0=Id \ \phi_1=\psi$ where $\psi$ is the above symplectomorphism, and its vector field associated with it is Hamiltonian. But I don't see how to relate it to the question above. I was given a hint to calculate the Jacobian of this transformation, but don't see relevancy here. Any tips? Thanks, depressed MP.","['differential-topology', 'symplectic-geometry', 'differential-geometry']"
137609,Proving the non-existence of a limit,"Here's a homework question I'm trying to solve: Prove or disprove: if $\lim_af$ and $\lim_ag$ do not exist, then $\lim_a(f
 \cdot g)$ do not exist either. So I know that
$$(\forall l\in\mathbb{R})(\exists\epsilon\gt0)(\forall\delta_1\gt0):(\|x-a\|\lt\delta_1)(\rightarrow\|f(x)-l\|\ge\epsilon/2)$$
$$(\forall m\in\mathbb{R})(\exists\epsilon\gt0)(\forall\delta_2\gt0):(\|x-a\|\lt\delta_2)(\rightarrow\|g(x)-m\|\ge\epsilon/2)$$ Now, since this is true for every $l,m\in\mathbb{R}$, it's also true for for every $r\in\mathbb{R}, r=m\cdot n$. In the same way, the two statements hold for every $\delta\gt0$ then
$$(\forall r\in\mathbb{R})(\exists\epsilon\gt0)(\forall\delta\gt0):(\|x-a\|\lt\delta)(\rightarrow\|f(x)-l\| \cdot \|g(x)-m\|\ge\epsilon/2 \cdot \epsilon/2)$$ How do I continue from here, assuming I was right so far? Thanks","['calculus', 'limits']"
137628,"Evaluating $ \int_{-\infty}^{\infty}x\exp\left(-b^{2}\left(x-c\right)^{2}\right)\mathrm{erf}^{2}\left(a\left(x-d\right)\right)\,\mathrm{d}x $","I have big difficulties solving the following integral:
$$
\int_{-\infty}^{\infty}x\exp\left(-b^{2}\left(x-c\right)^{2}\right)\mathrm{erf}^{2}\left(a\left(x-d\right)\right)\,\mathrm{d}x
$$ I tried to use integration by parts, and also tried to apply the technique called “differentiation under the integration sign” but with no results. I’m not very good at calculus so my question is if anyone could give me any hint of how to approach this integral. I would be ultimately thankful. If it could help at all, I know that
$$ 
\int_{-\infty}^{\infty}x\exp\left(-b^{2}\left(x-c\right)^{2}\right)\mathrm{erf}\left(a\left(x-d\right)\right)\,\mathrm{d}x=\frac{a}{b^{2}\sqrt{a^{2}+b^{2}}}\exp\left(-\frac{a^{2}b^{2}\left(c-d\right)^{2}}{a^{2}+b^{2}}\right)+\frac{\sqrt{\pi}c}{b}\mathrm{erf}\left(\frac{ab\left(c-d\right)}{\sqrt{a^{2}+b^{2}}}\right),
$$ for $b>0$.","['definite-integrals', 'calculus', 'special-functions', 'error-function']"
137629,Find equation of a plane that passes through point and contains the intersection line of 2 other planes,"Find equation of a plane that passes through point P $(-1,4,2)$ that contains the intersection line of the planes 
$$\begin{align*}
4x-y+z-2&=0\\
2x+y-2z-3&=0
\end{align*}$$ Attempt:
I found the the direction vector of the intersection line by taking the cross product of vectors normal to the known planes. I got $\langle 1,10,6\rangle$. Now, I need to find a vector normal to the plane I am looking for. To do that I need one more point on that plane. So how do I proceed?",['geometry']
137656,Riemann sphere and Maps,"Could somebody please clarify the following for me? I am not too clear about the relationship between the Riemann sphere and Möbius maps. I know that we can through projection make some Möbius maps correspond to isometries of the sphere. But it is not a bijection right? Which maps have corresponding isometries and which don't, vice versa? Thanks","['linear-algebra', 'conformal-geometry', 'complex-analysis']"
137673,Direct approach to the Closed Graph Theorem,"In the context of Banach spaces, the Closed Graph Theorem and the Open Mapping Theorem are equivalent.
It seems that usually one proves the Open Mapping Theorem using the Baire Category Theorem , and then, from this theorem, proves the Closed Graph Theorem . I was wondering about a more direct approach to the
Closed Graph Theorem.
What I want to show, possibly using the Baire Category Theorem,
but without the Closed Graph Theorem or any of its equivalent
theorems, that if $T: X \to Y$ is not continuous, then,
there is a convergent sequence $x_n \rightarrow x$ such that
$T x_n \rightarrow y \neq Tx$.
Of course, $X$ and $Y$ are Banach Spaces. Because $T$ is not bounded, I know that there is a sequence $a_n$ of
unitary vectors such that $T a_n \rightarrow \infty$.
Now, taking $b_n = \frac{a_n}{\|T a_n\|}$, we have that
$b_n \rightarrow 0$, and $\|T b_n\| = 1$. I wonder, if there is a simple argument for constructing a
$x_n \rightarrow x$, based on $a_n$ or $b_n$, such that
$T x_n$ is a Cauchy Sequence , but such that
$\|T x_n\|$ is ""far from"" $\|T x\|$. Of course, $x_n$'s construction would have to use the fact that
$X$ is complete.
For example, $x$ could be the limit of an absolutely convergent sequence,
pretty much in the same fashion as the construction in the proof of the
Open Mapping Theorem.","['alternative-proof', 'functional-analysis', 'banach-spaces']"
137674,The elliptic curve $y^2 = 23328x^3-890273x^2+14755570x-7^7$,"The elliptic curve, $$y^2 = 23328x^3-890273x^2+14755570x-7^7 \tag{1}$$ has the small solution $x = 58$.  I know how to find other rational points, but the   number of digits in the denominator gets large fast. Question : Does (1) have other rational points of small height, maybe where the numerator or denominator has only 5 digits or less ? P.S. I routinely come across situations like this. Is there an online Alpertron equivalent for elliptic curves, where given $ax^4+bx^3+cx^2+dx+e = y^2$, you just input {$a,b,c,d,e$} into the applet, and it outputs, if any, rational "" x "" with small height below a bound? (The Alpertron is a very useful site.)","['elliptic-curves', 'reference-request', 'number-theory']"
137677,What is the predual of $L^1$,"Is there a nice characterization of the predual of $L^1$? So, what does the space $X$ look like, such that $X^*=L^1$, where the star denotes the dual of a Banach space. How do you start to find such preduals in general? For some context, it is well known that given a measure space $(S, \Sigma, \mu)$, $L^p := L^p(S, \mu)$ is a Banach space for $p\in (1,\infty)$ and that $L^p \cong (L^q)^*$ where $q$ is the Holder conjugate of $p$, that is $\frac 1p + \frac 1q =1$. It is also known that $L^1$ is the predual of $L^\infty$. This leaves the above questions as the only remaining case. When $S$ is (for example) finite of course the question is moot. If you like one can consider only very simple measure space, like $[0,1]$ with the Lebesgue measure.","['lp-spaces', 'functional-analysis', 'banach-spaces']"
137692,Pulling back vector fields,"I want to find conditions under which one can pull-back vector fields (if it is at all possible). Let $F:M \to N$ be a smooth surjective map between two $C^{\infty}$ manifolds of the same dimension.
Let $Y$ be a vector field on $N$ (i.e. smooth section of the tangent bundle $TN$). 
Define: $T^\ast Y(p)(f)=Y(F(p))(f\circ F^{-1})$, where $f \in C^{\infty}(M,\mathbb R)$.
We check that $T^\ast Y$ is a derivation, and this is true since: $T^\ast Y(p)(fg)=Y(F(p)(fg \circ F^{-1})=Y(F(p)((f \circ F^{-1})(g \circ F^{-1}))$ My question: Is it enough for $F$ to be a local diffeomorphism for this to work?","['differential-topology', 'differential-geometry']"
137695,Why minus times minus needs to be plus? [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Why negative times negative = positive? An Abstract Algebra text book has a sentence on its 1st chapter about natural numbers that i cannot get around easily. The sentence reads ""Why minus multiplied by minus needs to be plus is something you might reflect on now."" I cannot answer the question, why minus multiplied by minus needs to be plus?
thanks",['abstract-algebra']
137710,An entire function $g$ such that $|g(z^2)| \leq e^{|z|}$ and $g(m) = 0 \quad \forall m \in \mathbb{Z}$ is identically $0$,I have been trying to solve the following exercise from a collection of old complex analysis qualifier exams. Suppose that $g$ is an entire function that satisfies the inequality $|g(z^2)| \leq e^{|z|}$. Also suppose that $g(m) = 0 \quad \forall m \in \mathbb{Z}$. Then prove that $g(z) \equiv 0$ (i. e. that $g$ is identically $0$). So what I think is that the inequality by putting $z^{1/2}$ gives me $|g(z)| \leq e^{|z|^{1/2}}$ and this means that the entire function $g$ is of finite order and its order $\lambda = \lambda(g) \leq \frac{1}{2}$. Then I have been looking at the basic theorems for finite order entire functions but I don't really see if one of them would be helpful here. So my question is how can I solve this problem? Is it really helpful to look at the theorems for finite order entire functions?,['complex-analysis']
137727,Evaluate $\sum\limits_{k=0}^n \binom{n}{k}$ combinatorially [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Locked . This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions. Please help me  to evaluate combinatorially the following sum:
$$\sum_{k=0}^n \binom{n}{k}$$ Thank you.","['summation', 'combinatorial-proofs', 'binomial-coefficients', 'combinatorics']"
137735,How to find the number of unique sets of 7 letters?,"The order of the letters does not matter, so: ABALNKM is the same as ALMKNBA bonus points How would I determine the number of sets where any letter can only be repeated a maximum of 4 times?","['statistics', 'combinatorics']"
137738,Proving that closed (and open) balls are convex,"Let $X$ be a normed linear space, $x\in X$ and $r>0$. Define the open and closed ball centered at $x$ as 
$$
B(x, r) = \{y \in X : \Vert x − y\Vert < r\}
$$ 
$$
\overline{B}(x, r) = \{y \in X : \Vert x − y\Vert \leq r\}.
$$
Then $B(x, r)$ and $\overline{B}(x, r)$ are convex. I tried to prove this, but either my calculation is incorrect, or I am on the wrong path: I aim to show for the closed ball $\overline{B}(x,r)$ (for open ball I assume the proof is similar). Suppose $y,z \in \overline{B}(x, r)$. Then $\Vert x − y\Vert \leq r$ and $\Vert x − z\Vert \leq r$. We must show that $t \in [0,1]$ implies $ty + (1-t)z \in \overline{B}(x,r)$. But $t \in [0,1]$ implies
$$
\Vert ty + (1-t)z - x\Vert = \Vert t(y-z) + z - x\Vert
\leq |t| \Vert y-z\Vert + \Vert z-x\Vert
\leq |t|(\Vert y-x\Vert + \Vert x-z\Vert) + \Vert z-x\Vert
< |t|(2r) + r = r(2|t| + 1),
$$
which is not necessarily $\leq r$. We probably wanted to end up with $< |t|r$ or $\leq |t|r$ as our final inequality. Thanks in advance.",['functional-analysis']
137757,Function fields of irreducible varieties,"The following might seem long, rambling and to contain more information than necessary. The problem is, I'm having a macro-understanding issue and feel like I need to tell you everything I think so that you can tell me why I'm wrong. I'm learning Algebraic Geometry somewhat prematurely (without much knowledge of commutative algebra, category theory etc). The most general variety I'm dealing with are quasi-projective varieties, and I couldn't tell you the definition of a general variety (well, I could, but I wouldn't know what I was talking about). As such I'm getting in a fine muddle over definitions and equivalences of definitions. In my notes, the function field $K(X)$ of an irreducible affine variety is defined to be the field of fractions of its coordinate ring $K[X]$. Okay, fine, I'm happy with that. I can see that under this definition, functions in the function field (which I think are called rational functions ) look like quotients of polynomials, have (possibly) many different representations and are not (in general) defined everywhere. In fact, the only rational functions which are defined everywhere on $X$ (i.e. are regular on the whole of X) are those from the coordinate ring $K[X]$. Now it's not too hard to see that, under this definition, $\displaystyle K(X) = \bigcup _{U \ \mathrm{Zariski \ open \ affine}} k[U]$. My notes then tell me to ""observe"" that if $U \subseteq X$ is Zariski open and $X \backslash U$ is a hyperplane (so $U$ is also affine), then $k(U) = k(X)$. I cannot see why this is true . By the above equality, I can see that rational functions on $X$ are functions which are ""locally polynomial"", i.e. functions which are polynomial maps on some open affine neighbourhood in $X$. $X$ being irreducible implies any two such open neighbourhoods have non-empty intersection, which feels like a relevant observation but I don't know what to do with it. I'm then told that if $X$ is an arbitrary irreducible variety, we can define $K(X) = K(U)$ for $U$ any affine open neighbourhood in $X$ I'd much appreciate an enlightening statement that makes all this premature learning feel somewhat more worthwhile. I've seen another definition of a function field for a projective variety $V$, namely that it's quotients of homogeneous polynomials (where numerator and denominator have the same degree), modulo the fairly obvious equivalence relation. Given the standard open affine cover of projective space, it's kind of easy to see that $K(V)$ is isomorphic to $K(U)$, where $U$ is one of the affine sets in the cover. By the relationship above, this means that $K(V)$ is isomorphic to $K(W)$ where $W$ is any open affine subset of $V$. So in this respect, a rational function here is something that is locally a polynomial map, which gives one direction of the supposed equivalence. However, it seems to me like these objects are more like examples of rational functions, rather than all rational functions; under the definition ""$K(V)$ is space of functions which are locally polynomial maps"", why must these things look like quotients of homogeneous polynomials? Anything relevant would be great. Thanks for your time.",['algebraic-geometry']
137759,Joint distribution of two functions of two random variables,"1) Suppose I have two random variables $A > 0$ and $B > 0$ with joint p.d.f. $f_{A,B}(a,b)$, and two random variables $X = g_1(A,B)$ and $Y = g_2(A,B)$. What is the general procedure for determining the joint p.d.f. $f_{X,Y}(x,y)$ ? 2) More specifically, suppose that: $A$ and $B$ are i.i.d. with $A \sim \Gamma (k, m)$. $X = AB$ $Y = A + B$ Clearly it this case $X$ takes a K distribution and $Y$ takes a Gamma distribution.  Due to struggling with 1) above, I've unfortunately been unable to determine whether in this case a closed non-integral expression for the joint p.d.f. $f_{X,Y}(x,y|k,m)$ even exists, let alone what it is... Any assistance / suggestions would be greatly appreciated.","['reference-request', 'probability-distributions', 'probability']"
137765,How to calculate $\int{\frac{dx}{3x^2+2}}$?,"I've started doing $$\displaystyle\int{\dfrac{dx}{3x^2+2}}$$
but I only get
$$\displaystyle\int{(3x^2+2)^{-1}dx}\\
\frac{1}{6}\displaystyle\int{\frac{6x(3x^2+2)^{-1}}{x}dx}\\
$$
And I don't know how to do solve this.","['calculus', 'integration', 'indefinite-integrals']"
137798,How to solve a linear algebra homework problem?,"Let $K$ be a field, suppose that $D\colon M_{n\times n}(K) \to K$ is a function such that $D(AB)=D(A)\cdot D(B)$ and $D(I) \neq D(0)$, where $0$ is the zero matrix. Show that if $\operatorname{rank}(A) < n$, then $D(A)=0$. My consideration is that:
first by $D(0)=D(0)D(I)$ and $D(0)\neq D(I)$, I can show $D(0)=0$ and $D(I)=1$.
then I want to show $D(I_k)=0$, where $I_k $ is $n\times n$ diagonal matrix with k diagonal entries equal to $1$ and others $0$. Then $D(A)=D(P^{-1}I_kP)=0$. However, I fail to prove $D(I_k)=0$. Any suggestions? Thanks a lot","['matrices', 'linear-algebra']"
137804,Number of ways of partitioning $a+b$ objects into $k $ partitions such that every partition has at least one object,"Given 'a' identical objects of one kind and 'b' identical objects of other kind. Also, given 'k' indistinguishable buckets. In how many ways can one put the '(a+b)' objects into the 'k' buckets such that every bucket has atleast a single object? As an example, let's suppose we have 3 As and 2 Bs and we need to partition them into 2 buckets. (a=3, b=2, k=2).
The possible combinations are: A  | AABB AA | ABB AAA | BB AAAB | B AAB | AB So, there exist 5 such partitions.","['integer-partitions', 'combinatorics']"
137813,"If the minimal polynomial is irreducible $\bmod p$ for some $p$, is the Galois group cyclic?","Say $\mathbb{Q}\subset\mathbb{Q}(\theta)$ is a Galois extension, and $\theta$ is integral over $\mathbb{Z}$. What I'm having a hard time understanding is, if $f(X)=\min_{\theta,\mathbb{Q}}(X)\in\mathbb{Z}[X]$ is the minimal polynomial of $\theta$ over $\mathbb{Q}$ and is irreducible $\mod p$ for some prime, how does this imply that the Galois group is in fact cyclic? Is it isomorphic to $C_p$ somehow or is my hunch off? I tried writing out $f(X)=g(X)h(X)\pmod{p}$ implies $g(X)$ or $h(X)$ is constant $\pmod{p}$, but I don't know what to say about the Galois group from this. Is there a clever way to see the cyclicity of the Galois group without actually knowing what the minimal polynomial looks like here? Thanks. Later : I appreciate the answers I received so far, but is it possible to derive this result without much knowledge of algebraic number theory? If not, I guess I know what I have to do next.","['galois-theory', 'abstract-algebra']"
137818,"How to prove a random variable taking values in $[0,1]$ range has variance no larger than $\frac{1}{4}$?","How can I prove that a random variable taking values in $[0,1]$ has variance no larger than $\frac{1}{4}$?
If it matters, discrete and continuous proofs are both welcome.","['statistics', 'probability']"
137820,Please help with word problem involving Trigonometry,"I'm kind of clueless, apart from its a min/max thing. The question is as follows: The water levels in a dock follow (approximately) a 12-hour cycle, and are modeled by the equation $D = A+ B\sin30t$, where $D$ metres is the depth of water in the dock, $A$ and $B$ are positive constants, and $t$ is the time in hours after 8 a.m. Given that the greatest and least depths of water in the dock are 7.80m and 2.20m respectively, find the value of A and the value of B Find the depth of water in the dock at noon, giving your answer correct to the nearest cm. Thanks in advance.",['trigonometry']
137826,"A 1-1 homomorphism from $\operatorname{Iso}(\mathbb{R}^2)$ to $GL(3,\mathbb{R})$","In class we saw A 1-1 homomorphism from $\operatorname{Iso}(\mathbb{R})$ to $GL(2,\mathbb{R})$ $$\operatorname{Iso}(\mathbb{R})\cong \left\{ \begin{pmatrix}\pm1 & x\\
0 & 1
\end{pmatrix}|x\in\mathbb{R}\right\}. $$ How can I get this result ? (It works, but it's probably not a guess, whats the idea ?) Seeing this I think that there is a 1-1 homomorphism from $\operatorname{Iso}(\mathbb{R}^2)$ to $GL(3,\mathbb{R})$ , how can we find it ? (that's why I'm trying to gain a better understanding of $\operatorname{Iso}(\mathbb{R})$) I could use some help with this.","['geometry', 'representation-theory']"
137832,Embedding of a field extension to another,Can $\mathbb{Q}(\sqrt {-2})$ be embedded into a cyclic extension of degree 4 over $\mathbb{Q}$?,"['galois-theory', 'abstract-algebra', 'field-theory']"
137836,Finding the radical of some ideals,"I need to find the radicals of the following ideals: i) $\mathfrak{a} = (xy^3, x(x-y))$ ii) $\mathfrak{b} = (xy^3, x^2(y-3))$ iii) $\mathfrak{c} = (x^2(y-z), xy(y-z), xz(y-z)^2)$ Can I just use the Nullstellensatz? My working below seems a bit too easy, which makes me think I'm doing something horrendously awful. Let $k$ be an algebraically closed field. i) It's pretty obvious that $Z(\mathfrak{a}) = \{ (0,t) \ | \ t \in k \} = Z(x) $. So by the Nullstellensatz, $\sqrt{\mathfrak{a}} = I(Z(\mathfrak{a})) = I(Z(x)) = (x) $. ii) Isn't this the same as above? iii) $Z(\mathfrak{c}) = \{ (0,s,t) \ | \ s,t \in k \}\cup \{(s,t,t) \ | \ s,t \in k\} = Z(x) \cup Z(y-z)$. So $I(Z(\mathfrak{c})) = I(Z(x)) \cap I(Z(y-z)) = (x) \cap (y-z) = (x(y-z))$ Am I breaking any laws? Thanks!","['commutative-algebra', 'algebraic-geometry']"
137849,Stationary distribution of random walk,"Let $\mathcal{X}$ be a simple random walk with barrier at zero, state space $E = \mathbb{N}_0$ and transition matrix below with $0<q<1$. \begin{bmatrix} 
 1-q     & q     &   &      &   \\
 1-q     & 0     & q  &      &   \\
      & 1-q     & 0  & q     &   \\
      &      & 1-q  &  0    & q  \\
      &      &   & \ddots     & \ddots & \ddots
\end{bmatrix} How would I determine the stationary distribution for $q < \frac{1}{2}$? And why is the condition that $q < \frac{1}{2}$ necessary for $\mathcal{X}$ to have a stationary distribution? Also, is saying that $\mathbb{P}(X_n = n |X_0 =0) = q^n >0$ and $\mathbb{P}(X_n =0 | X_0 =n) = (1-q)^n >0$ enough to show $\mathcal{X}$ is irreducible? Update: I get $\pi_n = \left( \frac{1-q}{q} \right)\pi_{n+1}$ for all $n \in \mathbb{N}_0$, but why is the condition that $q < \frac{1}{2}$ necessary for $\mathcal{X}$ to have a stationary distribution?","['probability-theory', 'stochastic-processes', 'markov-chains']"
137856,Finding singular points and computing dimension of tangent spaces (only for the brave),"I'm currently looking at the following two questions: i) Consider $V = Z(I) \subset \mathbb A_k^3$ where $I$ is generated by $X_1^3 - X_3$ and $X_2^2-X_3$. Find the points at which $V$ is singular and compute the dimensions of the tangent spaces there. ii) Determine the singular points of the surface $Y$ in $\mathbb P^3$ defined by the polynomial $X_1X_2^2 - X_3^3 \in k[X_0, X_1, X_2, X_3]$ and compute the dimensions of the tangent spaces there. Now I should state the definitions I have. For an affine variety $X = Z(f_1, \ldots, f_r) \subset \mathbb A_k^n$ and a point $p \in X$, we define the tangent space of $X$ at $p$ to be $T_pX = \mathrm{Der}(k[X], \mathrm{ev}_p)$, where $\mathrm{Der}(A,\phi)$ denotes the space of derivations $A \to k$ centred at $\phi$. This can be shown to be equivalent to $T_pX = \mathrm{ker} \begin{pmatrix} \frac{\partial f_1}{\partial x_1}(p) & \ldots & \frac{\partial f_1}{\partial x_n}(p) \\ \vdots & \ldots & \vdots \\ \frac{\partial f_r}{\partial x_1}(p) & \ldots & \frac{\partial f_r}{\partial x_n}(p) \end{pmatrix}: k^n \to k^r$. For $X$ an arbitrary variety, we define $T_pX = T_pU$ where $U$ is any affine open neighbourhood of $p$ (this can be shown to be well-defined). If $X$ is an irreducible variety, define $\mathrm{dim}(X) = \mathrm{min} \{ \mathrm{dim} \ T_pX \ | \ p \in X \}$. If $X$ is irreducible and $k$ is algebraically closed, say $p \in X$ is a smooth point if $\mathrm{dim} \ T_pX = \mathrm{dim} X$, and say $p$ is singular otherwise. For question i), seeing as my definition of singular only applies to irreducible varieties, I better show $V$ is in fact irreducible. I'm not sure how easy this is - I can't really spot how to do it. With some guesswork I'd say that $k[V] \cong k[x^2, x^3]$ which is clearly in integral domain so $V$ is irreducible, but I'm not sure about the details. Now let's write out the relevant matrix: $\begin{pmatrix} 3p_1^2 & 0 & -1 \\ 0 & 2p_2 & -1 \end{pmatrix}$ where $p = (p_1, p_2, p_3)$. We have the points $p = (\frac{1}{\sqrt{3}}, \frac{1}{2}, p_3)$ where the rank is $2$  i.e. $\mathrm{dim}T_p X = 1$. The rank can obviously never be $3$, so we have that $\mathrm{dim}X = 1$. So the singular points are those for which the rank is 1. That's true precisely for the points $\{ (0,0,t) \ | \ t \in k \}$. For question ii), I'm also unsure. Again, why is the surface $Y$ irreducible? Now I'm not sure how to deal with the fact that we're in projective space, so what I'm writing from now onwards may be complete nonsense. We have the standard affine open cover $\mathbb P^3 = U_0 \cup \ldots \cup U_3$, and it's obvious that $Y \cap U_0 \neq \emptyset$. So if the first coordinate of $p$ is non-zero, we can use the definition above to ascertain $T_pY = T_p (Y\cap U_0)$. If the first coordinate is zero, I'll worry about that later. So we're now assuming the first coordinate of $p$ isn't zero, and we're living in (irreducible if $Y$ is) affine space. The ""affine"" (de-homogenised) polynomial corresponding to $X_1 X_2^2 - X_3^3$ is just $xy^2 - z^3 \in k[x,y,z]$. Now there's a lemma that says if $f \in k[x_1, \ldots , x_n]$ is prime, then $\mathrm{dim} Z(f) = n - 1$. I'll assume our polynomial is prime (I don't know what else to do, so I might as well check later). So the singular points are those for which $\mathrm{dim} T_p (Y \cap U_0) = 3$, which are precisely those whose partial derivatives all vanish. These are the points $\{ (t,0,0) \ | \ t \in k^\times \}$, and the tangent spaces all have dimension 3. Now I think about it, if the first coordinate of $p$ is 0 everything seems to break, so let's leave the answer there. I greatly appreciate the effort it takes to wade through this potential nonsense. My method seems very long-winded; I don't know if I've missed the point somewhere, or if the definitions I'm using are bad, or if this genuinely is how to go about solving these problems. I'm especially unconfident in my answer to ii). Thank you.",['algebraic-geometry']
137858,A group where every two elements different than 1 are conjugate has order 1 or 2.,"I need help showing this: Let G be a finite group such that for every $x$, $y$ in G, $x\neq 1$ and $y\neq 1$, we have that $x$ and $y$ are conjugates. Under those conditions, G must have order 1 or 2. This is under the topic ""actions of groups on sets"", but I couldn't figure out a way to start it. Since every element is conjugate, then G must have only one conjugation class, which is itself, but how can this information help?",['group-theory']
137859,What is awry with this proof?,"Let $x=5$, $y=7$, $z=6$ $x+y = 2z$ Rearranging, $x-2z = -y$ and $x = -y+2z$ Multiply both sides respectively. $x^2-2xz = y^2-2yz$ $$x^2-2xz+z^2 = y^2-2yz+z^2$$
$$(x-z)^2 = (y-z)^2$$
$$x-z = y-z$$
Hence $x=y$, or $5 = 7$ Well, the conclusion is clearly false, but what went wrong? I think it may be the step in which one square roots both sides because it's taking out one solution?","['algebra-precalculus', 'fake-proofs']"
137874,Pontryagin classes of a product manifold,"I'm imagining there's a way to relate the pontryagin classes of $T(M\times N)$ to the pontryagin classes of $M$ and those of $N$, but I haven't been able to find a helpful reference. Could someone explain this or direct me to a good source? I am interested specifically in $CP^2\times CP^2$ but also in the general case.
Thanks!","['general-topology', 'characteristic-classes', 'vector-bundles']"
137876,A subring of the field of fractions of a PID is a PID as well.,"Let $A$ be a PID and $R$ a ring such that $A\subset R \subset \operatorname{Frac}(A)$, where $\operatorname{Frac}(A)$ denotes the field of fractions of $A$. How to show $R$ is also a PID? Any hints?","['ring-theory', 'integral-domain', 'abstract-algebra', 'principal-ideal-domains', 'commutative-algebra']"
137884,Equivalence relation defined by a group action,"This is very simple, but as far as I can tell it has not been asked yet. Let the group $G$ act on the set $S$ and define an equivalence relation by $x \sim x'$ if there exists a $g \in G$ for which $gx=x'$. Proving reflexivity and transitivity is easy, so let's look at the symmetric property: Say $x \sim x'$ with $gx=x'$.  Then we have $x=x'g^{-1}$.  So $x$ is equal to $x'$ multiplied by an element of $G$, but does this work since we are now using right multiplication?  Can we do something 'clever' like $ex=x'g^{-1} \Rightarrow xe=g^{-1}x' \Rightarrow x=g^{-1}x' \Rightarrow x' \sim x$?  Something about that last bit seems foul to me. The group theory tag isn't really appropriate here.  I would create a 'group actions' tag if I were able.","['group-theory', 'abstract-algebra']"
137888,"Why is $O_K\otimes \mathbb{Z}_p\cong \oplus_{\mathfrak{p}|p}O_{K,\mathfrak{p}}$?","In my old number theory notebook this is stated as a fact. However, I ran into problems when I tried to prove it. First let me state the (supposed) theorem accurately: Theorem (?) Let $K$ be a number field with ring of integers $O_K$. Let $p$ be a prime of $\mathbb{Z}$. Then $O_K\otimes \mathbb{Z}_p\cong \oplus_{\mathfrak{p}|p}O_{K,\mathfrak{p}}$, where $\mathfrak{p}$ runs over those primes of $O_K$ that lie over $p$, and where $O_{K,\mathfrak{p}}$ is the formal local ring of $O_K$ at $\mathfrak{p}$ (i.e., $\varprojlim O_K/\mathfrak{p}^n$). Attempt The way I was thinking of proving this is through the Chinese Remainder Theorem. The following is true for every natural number $n$:
$$O_K\otimes \mathbb{Z}/p^n\mathbb{Z}\cong O_K/p^nO_K\cong O_K/\mathfrak{p}_1^{ne_1}\cdots \mathfrak{p}_m^{ne_m}\cong O_K/\mathfrak{p}_1^{ne_1}\oplus...\oplus O_K/\mathfrak{p}_m^{ne_m}.$$
where $pO_K=\mathfrak{p}_1^{e_1}\cdots \mathfrak{p}_m^{e_m}$. The next natural step is to take inverse limits of both sides with respect to n. As inverse limits commute with direct sums (as both are limits), $\varprojlim O_K/\mathfrak{p}_1^{ne_1}\oplus...\oplus O_K/\mathfrak{p}_m^{ne_m}\cong O_{K,\mathfrak{p}_1}\oplus...\oplus O_{K,\mathfrak{p}_m}$. This is where the wheels come off the argument: inverse limits don't generally commute with tensor products. This is because inverse limits are categorical limits, whereas tensor products are categorical colimits (indeed they are the coproduct of the category of $\mathbb{Z}$-algebras). So there is no reason, a priori, that $\varprojlim O_K\otimes \mathbb{Z}/p^n\mathbb{Z}$ would be isomorphic to $O_K\otimes \mathbb{Z}_p$. So this leads me to the Question Why is the theorem true? (if it even is.)","['commutative-algebra', 'p-adic-number-theory', 'abstract-algebra', 'number-theory']"
137892,The diffeomorphism of $\mathbb R^n$,"If $f$ is a diffeomorphism of $\mathbb R^n$ and $K$ is a compact set in $\mathbb R^n$, can we find another diffeomorphism $\tilde f$ of $\mathbb R^n$ such that: (1)$f=\tilde f$ on a neighborhood of $K$.
(2)There is a bounded set $V$ and $\tilde f=id$ outside $V$?",['differential-geometry']
137906,Algebraic closure of $\mathbb{C}(x)$ is isomorphic to $\mathbb{C}$,Let $x$ be transcendental over $\mathbb{C}$. Let $K$ be the algebraic closure of $\mathbb{C}(x)$. How to show that $K$ is isomorphic to $\mathbb{C}$?,"['abstract-algebra', 'field-theory']"
137909,Proving continuity of $f$,"Here is a problem I encountered some time back: Suppose $f$ is bounded for $a\leq x\leq b$ and for every pair of values $x_1$ and $x_2$ with $a\leq x_1\leq x_2 \leq b$,
$f(\frac{1}{2}(x_1+x_2))\leq \frac{1}{2}(f(x_1)+f(x_2))$. Prove that $f$ is continuous for $a<x<b$. I tried to solve it but I could not really come with anything... Here's an attempt.The idea is not due to me but to a friend; By the condition given, $f(\frac{2x+2\delta}{2})\leq \frac{1}{2}(f(x+2\delta)+f(x))$,i.e. $f(x+\delta)-f(x)\leq \frac{1}{2}f(x+2\delta)-f(x)$ and in this manner, $f(x+\delta)-f(x)\leq \frac{1}{2}f(x+2\delta)-f(x)\leq \frac{1}{2^2}(f(x+4\delta)-f(x))\leq$ $ \dots \dots \dots \dots $ $\frac{1}{2^n}(f(x+2^n\delta)-f(x))$ where $a<x+2^n\delta<b$ As $\delta\to 0$,$f(x+2^k\delta)\to f(x)$ for $k=1,2,\dots n$ i.e. $f$ is continuous in the interval $(a,b)$. I tried posting this flawed attempt on Aops , but no one has suggested how to finish off the proof using what I used.I will be happy if someone could suggest something.Thanks!",['calculus']
137912,Can $e_n$ always be written as a linear combination of $n$-th powers of linear polynomials?,"User Eric Gregor and I were talking in chat and he mentioned this question and postulated the possibility of an approach through symmetric polynomials. After some thinking, I came to this: Hypothesis . For any $n$ , the elementary symmetric polynomial $e_n\in k[x_1,\cdots,x_n]$ can be expressed as a $k$ -linear combination of $n$ th powers of degree one homogeneous polynomials. $^\dagger$ $^\dagger$ We assume the characteristic does not divide $n!$ . We could assume it's zero for more simplicity. Let us denote $s(a,b,\cdots,c)=(a+b+\cdots+c)^n-(a^n+b^n+\cdots+c^n).$ I have two examples: $$xy=\frac{s(x,y)}{2} \tag{$n=2$}$$ $$xyz=\frac{s(x,y,z)-\big(s(x,y)+s(y,z)+s(z,x)\big)}{6} \tag{$n=3$}$$ My scratchwork was getting tedious so I didn't finish the $n=4$ case. Besides this I haven't really made any substantive headway, but I did derive the following equality. We denote $\mathrm{pt}\,\lambda$ the number of parts of an integer partition $\lambda\vdash n$ , and $m_\lambda$ the sum of all monomials of shape $\lambda$ in $x_j,j\in J$ . $$T_{J,\ell}:=\sum_{\large I\subseteq J \atop \large |I|=\ell}\left(\sum_{i\in I}x_i\right)^n=\sum_{\large \lambda\vdash n \atop \large \mathrm{pt}\lambda\le\ell}\binom{n}{\lambda}\binom{|J|-|I|}{\ell-\mathrm{pt}\,\lambda}m_\lambda.$$ This can be justified as follows: expanding the inner summands of the LHS with the multinomial theorem will result in the terms $m_\lambda$ (with the appropriate multinomial coefficents), times the count of supersets $I$ ( $\subseteq J$ ) of cardinality $\ell$ containing a particular subset $K$ of cardinality $\mathrm{pt}\,\lambda$ ; construct such $I$ by choosing $|K/I|$ elements out of $|J/I|$ available. In our context $J=[n]$ of course. The reason I mention this is that the $T_{[n],\ell}$ 's appear to be relevant in the computations I was going through for $n=2,3,4$ (as if inverting a linear system in the $m_\lambda$ 's...). It may or may not be the correct way of thinking about the problem. I guess my question is then: Is the hypothesis correct? If so, how would we prove it? ( Optional ) If this isn't already inherently answered in the hypothetical proof, how would we explicitly compute what the combinations of powers are?","['symmetric-polynomials', 'polynomials', 'combinatorics']"
137915,Strengthening a result on the growth of continuously differentiable functions.,"Given two continuously differentiable functions $f,\
 g:\mathbb{R}\rightarrow \mathbb{R}$ such that $f(x_0) = g(x_0)$ and
   $f'(x_0) < g'(x_0)$, there exists $\epsilon > 0$ such that $f(x) <
 g(x)$ for $x \in (x_0, x_0 + \epsilon)$. The above result is not too difficult to prove, but I was wondering if the condition that the functions be continuously differentiable is absolutely necessary. I have not taken much analysis, but I'm wondering if the fact that the derivative exists at $x_0$ would be enough to prove this result without needing the derivative to be continuous. The reason I ask this is because it seems that the existence of a derivative function already implies it must satisfy some quite stringent requirements (i.e. Darboux's Theorem), perhaps these are enough?","['calculus', 'derivatives', 'real-analysis']"
137927,Are there any simple ways to see that $e^z-z=0$ has infinitely many solutions?,"Joseph Bak and Donald Newman's complex analysis book (p.236)  has a proof that the equation $e^z-z=0$ has infinitely many complex solutions: I'm curious if there are any particularly elegant ways to see this, other than that given in the text.",['complex-analysis']
137936,Log-likelihood gradient and Hessian,"Considering a binary classification problem with data $D = \left\{ (x_i, y_i) \right\}_{i=1}^n$ , $x_i \in \mathbb{R}^d$ and $y_i \in \{0,1\}$ . Given the following definitions, $$f(x) = x^T \beta$$ $$p(x) = \sigma(f(x)) \quad \text{with}  \quad\sigma(z) = 1/(1 + e^{-z})$$ $$L(\beta) = \sum_{i=1}^n \Bigl[ y_i \log p(x_i) + (1 - y_i) \log [1 - p(x_i)] \Bigr]$$ where $\beta \in \mathbb{R}^d$ is a vector. $p(x)$ is a short-hand for $p(y = 1\ |\ x)$ . The task is to compute the derivative $\frac{\partial}{\partial \beta} L(\beta)$ . A tip is to use the fact $$\frac{\partial}{\partial z} \sigma(z) = \sigma(z) (1 - \sigma(z))$$ So here is my approach so far: \begin{align*}
L(\beta) & = \sum_{i=1}^n \Bigl[ y_i \log p(x_i) + (1 - y_i) \log [1 - p(x_i)] \Bigr]\\
\frac{\partial}{\partial \beta} L(\beta) & =  \sum_{i=1}^n \Bigl[ \Bigl( \frac{\partial}{\partial \beta} y_i \log p(x_i) \Bigr) + \Bigl( \frac{\partial}{\partial \beta} (1 - y_i) \log [1 - p(x_i)] \Bigr) \Bigr]\\
\end{align*} \begin{align*}
\frac{\partial}{\partial \beta} y_i  \log p(x_i) &= (\frac{\partial}{\partial \beta} y_i) \cdot \log p(x_i) + y_i \cdot  (\frac{\partial}{\partial \beta} p(x_i))\\
&= 0 \cdot \log p(x_i) + y_i \cdot (\frac{\partial}{\partial \beta} p(x_i))\\
&= y_i \cdot (p(x_i) \cdot (1 - p(x_i)))
\end{align*} \begin{align*}
\frac{\partial}{\partial \beta} (1 - y_i) \log [1 - p(x_i)] &= (1 - y_i) \cdot (\frac{\partial}{\partial \beta} \log [1 - p(x_i)])\\
& = (1 - y_i) \cdot \frac{1}{1 - p(x_i)} \cdot p(x_i) \cdot (1 - p(x_i))\\
& = (1 - y_i) \cdot p(x_i)
\end{align*} $$\frac{\partial}{\partial \beta} L(\beta) = \sum_{i=1}^n \Bigl[ y_i \cdot (p(x_i) \cdot (1 - p(x_i))) + (1 - y_i) \cdot p(x_i)  \Bigr]$$ So basically I used the product and chain rule to compute the derivative. I am afraid, that my solution is wrong, because on page 120 of The Elements of Statistical Learning it says the gradient is $$\sum_{i = 1}^N x_i(y_i - p(x_i;\beta))$$ I don't know what could have possibly gone wrong. Any advice on this?","['multivariable-calculus', 'matrices', 'vector-analysis', 'regression', 'derivatives']"
137944,meaning of topology and topological space,"After looking at the Wikipedia article on topological space, I still cannot grasp intuitively what topological space is. For example, if we are to define topology on real numbers, can there be many topological space models, and why is defining topology on real numbers important? Edit: to simply say, what I really need is somehow formal or intuitive concept of topology and topological space that would allow me to grasp the meaning of topology and topological space. Thanks.",['general-topology']
137949,The construction of a Vitali set,Can anyone explain the concept of a Vitali set ? I am not able to understand the construction of the set.,['measure-theory']
137972,No function that is continuous at all rational points and discontinuous at irrational points. [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Set of continuity points of a real function I think I saw somewhere(but I'm not sure) that there is no function $g$ on $[0,1]$ that is continuous at all rational points and discontinuous at all irrational points. Please, is this true? If yes how can I show it?  Thanks.",['real-analysis']
137999,What is the topology of a world with portals?,"Portal is a video game where you can create 2 disks $D\in\mathbb{R}^3$ , which then are identified. The world is glued together at these points. (source: thebuzzmedia.com ) This kind of reminds me of some procedures to construct spaces for CW complex and whatnot in algebraic topology. I don't know if that kills properties like smoothness, but that doesn't really matter here. My question: What is the topology of a world with one or $n$ portals? If you take topological $\mathbb{R}^3$ and two or even $2n$ therein separated two-dimensional discs $D_1,D_2$ which you identify (say pairwise), what is the resulting topology? (source: ngfiles.com ) The question was motivated by my own answer here .","['general-topology', 'algebraic-topology']"
138020,Proving that every isometry of $\mathbb{R}^n$ is of the form of a composition of at most $n+1$ reflections,"I know, for example, the every isometry of $\mathbb{R}^3$ can be written as a composition of at most $4$ reflections (through planes that doesn't necessarily have the 0 vector in them). I wish to prove to more general statement that says every isometry of $\mathbb{R}^n$ is of the form of a composition of at most $n+1$ reflections. The proof for the cases $n=2,3$ that I saw are a bit technical and I don't think that rotating and reflecting in $\mathbb{R}^n$ is a good way to show this (though possible and probably a lot more technical...) I need help with my tactic to prove this : I want to use induction, knowing this is true for $n=1$. The idea is this: if I were to define an isometry of the required form that acts the same on: the $0$ vector,$e_{1},...,e_{n}$ then I would be done. Now I want to use, somehow, the induction hypothesis, my thoughts are that the given isometry, $f$, takes $e_{1},...,e_{n}$ into $n$ points and from the induction hypothesis there is a composition of at most $n$ reflections that take the projection of $e_{1},...,e_{n}$ to $\mathbb{R}^{n-1}$ to the projection of $f(e_{1}),...,f(e_{n})$. From here I'm a bit lost, I want to say that this build also takes the zero vector of $\mathbb{R}^{n-1}$ to the projection of $f(0)$ to $\mathbb{R}^{n-1}$ and that I can compose what I got with one more reflection in a way that won't ruin what I already did and also help take care of the last coordinate. Any thoughts ? Edit: The proof in the link in the accepted answer it correct, but it seems that the proof given in the other answer is what I am trying to do, I would appriciate if someone could go into more details (I commented to the answer what I don't understand in it). Edit 2 : I tried writing the proof and complete all the details, did I do this correctly ? We will prove by induction that every isometry of $\mathbb{R}^n$ can be represented
as a composition of at most $n+1$reflections. Base case: We know that the claim is true for $n=1$(and $n=2$but
I think that this will follow). Step: Let $V:=\left\{ x\in\mathbb{R}^n|x_{n}=0\right\} $and let $f\in Iso(\mathbb{R}^n)$. If $f(0)\neq0$ then there exist $\tau\in O(n)$ s.t $\tau\circ f(0)=0$
(explicitly: $\tau$ is the reflection around the plane consistent
of all point in $\mathbb{R}^n$ with equal distans from both $0$ and $f(0)$). We now assume $f(0)=0$ (otherwise we denote $g=\tau\circ f$ and
continue with $g$ ). Consider $f|_{V}$ : $f$ is an isometry of $\mathbb{R}^n$ hence $\forall x,y\in\mathbb{R}^n:d(x,y)=d(f(x),f(y))$,
in particular this holds for very $x,y\in V$ . Let $E$ be the projection $E:\mathbb{R}^n\to\mathbb{R}^{n-1}$. $E(V)=\mathbb{R}^{n-1}$and
$E\circ f|_{V}$ is an isometry of $\mathbb{R}^{n-1}$ hence be the induction
hypothesis it can be represented as $R=R_{1}\circ...\circ R_{n-1}$. We now expand $R$ to $\mathbb{R}^n$ in this manner: denote the matrix representin
$R$ as $R_{M}$ ($R_{M}\in M_{n-1}(\mathbb{R})$) then $R$ expanded to
$\mathbb{R}^n$ is represented by $\begin{pmatrix}R & 0\\
0 & 1
\end{pmatrix}$that is : on the first $n-1$coordinates we act the same as $R$ did
and we keep the last coordinate (note that $|R_{M}|=1$ and that it
is straightforward to check that $R_{M}$ is an orthogonal matrix,
$R_{1},...,R_{n}$are expanded from $\mathbb{R}^{n-1}$to $R^{n}$ in the
same manner). Denote $\varphi=R^{-1}\circ f$ (here $R$ is the expended isometry
to $\mathbb{R}^n$). if $\varphi(e_{n})=e_{n}$ then we are done, otherwise
there exist a reflection $\alpha$ s.t $\alpha\circ\varphi(e_{n})=e_{n}$and
s.t $\alpha|_{V}\equiv f|_{V}$. (explicitly: $\alpha$ is a rotation
around the plane consistent of all points $v\in\mathbb{R}^n$ s.t $\langle v,e_{n}-f(e_{n})\rangle=0$). $\varphi$ is at most $n-1$ reflections hence $\alpha\circ\varphi$
is at most $n$ reflections. In te first case $(f(0)\neq0)$ we are doing the process with $\tau\circ f$
hence in this case $f$ is represented by at most $n+1$ reflections. Any comment about the style of the proof is also welcomed, this is one of the times I am writing a proof in English.",['geometry']
138022,What makes Probability so difficult to get it right in the first place? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 9 years ago . Improve this question I took two classes of Probability, I did very well and was confident on the subject. Now I meet it again in my Combinatorial Algorithm course, and guess what? I feel completely blank again! I have to review all my notes, look for examples ... even though I've already ""solved"" them thoroughly. I realize the amount of time I spent for these Probability classes is usually double/triple the time I spent for any other science classes. Why is it so difficult to grasp the concepts in Probability in the first place?","['probability', 'advice']"
138023,Basis-free formulation of Jordan normal form theorem,"Is there a basis-free formulation of Jordan normal form theorem? From some search I did in Google, the answer is apparently yes. But I didn't find any article that I could understand. (I've only taken two semester course in linear algebra.) My curiosity comes from the question whether the theorem can be generalized to infinite dimensional situation. If it's a separable Hilbert space, we can still represent the linear operator as a matrix, but does the theorem remain true? In case of non-separable space, I think there's no way to put the linear operator in matrix form. So we need to find a basis-free formulation. Wikipedia says that there is an analogue of Jordan normal form theorem for compact operators in Banach space. What is this analogous result?",['linear-algebra']
138043,Does convergence in $L^p$ imply convergence almost everywhere?,"If I know $\| f_n - f \|_{L^p(\mathbb{R})} \to 0$ as $n \to \infty$ , do I know that $\lim_{n \to \infty}f_n(x) = f(x)$ for almost every $x$ ?","['lebesgue-integral', 'measure-theory', 'real-analysis']"
138056,Is the right shift operator bounded?,"I was reading my lecture notes for functional analysis when I came across the following statement: Let $(e_{n})$ be a total orthonormal sequence in a separable Hilbert space H. The right shift operator, defined as the linear
  operator $T: H\rightarrow{}H$ such that $Te_{n} = e_{n+1}$ for all n,
  is bounded. The statement seems intuitively correct to me, but I find the proof of it quite confusing. The proof goes like this: Proof: For $\forall x\in{}H$, since $(e_{n})$ is total, write $\displaystyle x=\lim_{n\rightarrow{\infty}}x_{n}$, where
  $\displaystyle x_{n}=\sum_{k=1}^{n}\left<x,e_{k}\right>e_{k}$. Then we have
  $||Tx_{n}||^{2}=||\sum_{k=1}^{n}\left<x,e_{k}\right>Te_{k}||^{2}=||\sum_{k=1}^{n}\left<x,e_{k}\right>e_{k+1}||^{2}= \sum_{k=1}^{n}|\left<x,e_{k}\right>|^{2}$. Therefore
  $||Tx||^{2}\stackrel{(\ast)}{=}\lim_{n\rightarrow{\infty}}||Tx_{n}||^{2}=\sum_{k=1}^{\infty}|\left<x,e_{k}\right>|^{2}=||x||^{2}$.
  Thus, $T$ is bounded and isometric. However, I think there is something fishy with the proof: In the equality $(\ast)$, I believe the proof is using that $\displaystyle ||Tx||=||T\left(\lim_{n\rightarrow\infty}x_{n}\right)||=||\lim_{n\rightarrow\infty}Tx_{n}||=\lim_{n\rightarrow{\infty}}||Tx_{n}||$. But for the second equality to hold, it is already assuming that T is indeed continuous, which implies boundedness. And that makes it a circular reasoning here... Is my judgement about the proof right? If this proof is indeed wrong, can anybody suggest a correct way to prove the statement?","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
138065,Automorphism of $L|K$ mapping 3 distinct rational points of $S_{L|K}$ to other 3 distinct ones,"Let $K$ be a field and consider $L = K(x)$ the field of rational functions. Let $v_{1}, v_{2}, v_{3}$ rational points in the abstract Riemann surface $S_{L|K}$, distinct from each other, and $w_{1}, w_{2}, w_{3}$ also rationals points in $S_{L|K}$, distinct from each other. I have to prove that there is a unique automorphism $\sigma$ of the extension $L|K$ such that $w_{i} = v_{i} \circ \sigma$.","['commutative-algebra', 'algebraic-geometry', 'algebraic-curves', 'valuation-theory']"
138072,How to show that the set of points of continuity is a $G_{\delta}$,"I am trying to solve this exercise from Royden's 3rd edition. The question is as follows: Let $f$ be a real-valued function defined for all real numbers. Show that the set of points at which $f$ is continuous is a $G_{\delta}$ . Let $$A_n = \{y : \text{there is a }~\delta_y \gt 0 : |f(s)-f(t)|\lt 1/n ~ \text{whenever}~ s,t \in (y-\delta, y+\delta)\}\;.$$ Then by the definition of open sets, $A_n$ is open. To complete the proof, I need help in showing that $f$ is continuous at say $x$ if and only if $x\in \cap A_n$ . If $f$ is continuous at $x$ , there is a $\delta \gt 0$ such that $|f(x) - f(a)| \lt 1/n$ whenever, $x\in (a-\delta, a+\delta)$ , so $x \in A_n$ , so it must be in $\cap A_n$ . Thanks.",['real-analysis']
138084,regularization of a divergent integral,"is there any way to regularize the following divergent  integral : $$\int_{0}^{\infty}\frac{dx}{xe^{x}(e^{x}-1)}$$ the integral comes from trying to find an analytic continuation of 
$$I(s)=s\int_{0}^{\infty} \frac{dx}{2x}\left(E_{s/2}((\pi x)^{s/2})-1\right)\omega(x)-\left(E_{s/2}(( x)^{s/2})-1\right)e^{-x}$$
$E_{s}(x)$ is the mittag-leffler function . and admits the beautiful continuation :
$E_{s}(x^{-1})=1-E_{-s}(x)$ 
and $$\omega(x)=\sum_{n=1}^{\infty}e^{-n^{2}\pi x}$$ which is the jacobi theta function in disguise another representation of the integral above is - for a minute assume i'm correct about this equivalence -  :
$$I(s)=s\int_{0}^{\infty}\frac{E_{s}(x^{s})-1}{xe^{x}(e^{x}-1)}dx$$ i was wondering if we can apply Riemann's trick, and replace this integral with a contour integral to obtain a meromorphic integral !? following Riemann's trick, here is what i did : start with contour integral : $$I(s)=-s\oint_{c}\frac{E_{s}((-x)^{s})-1}{xe^{x}(e^{x}-1)}dx$$ the contour is the usual Hankel contour. consider $I(-s)$ : $$I(-s)=s\oint_{c}\frac{E_{-s}((-x)^{-s})-1}{xe^{x}(e^{x}-1)}dx=-s\oint_{c}\frac{E_{s}((-x)^{s})}{xe^{x}(e^{x}-1)}dx$$ or $$I(s)-I(-s)=s\oint_{c}\frac{dx}{xe^{x}(e^{x}-1)}=s\oint_{c}(-x)^{-1}e^{-x}dx-s\oint_{c}\frac{(-x)^{-1}dx}{e^{x}-1}$$ now :$$\oint_{c}(-x)^{-1}e^{-x}dx=\frac{-2\pi i}{\Gamma(1)}=-2\pi i$$
and the second integral could be thought of as: $$\oint_{c}\frac{(-x)^{-1}dx}{e^{x}-1}=\lim_{z\rightarrow 0}\oint_{c}\frac{(-x)^{z-1}dx}{e^{x}-1}=-2i\lim_{z\rightarrow 0}\sin(\pi z)\Gamma(z)\zeta(z)=i\pi$$ or : $$I(s)-I(-s)=-3\pi is$$ lets go back to the 1st integral, and expand the Mittag-leffler function : $$I(s)=-s\oint_{c}\frac{E_{s}((-x)^{s})-1}{xe^{x}(e^{x}-1)}dx=-s\sum_{n=1}^{\infty}\frac{1}{\Gamma(1+ns)}\oint_{c}\frac{(-x)^{sk-1}dx}{e^{x}(e^{x}-1)}$$ $$=s\sum_{n=1}^{\infty}\frac{2i \sin(k\pi s)\Gamma(ks)}{\Gamma(1+ns)}\left(\zeta(ks)-1\right)=2i\sum_{n=1}^{\infty}\sin(k\pi s)\frac{\zeta(ks)-1}{k}$$ now the problem becomes finding a function of the variable s -lets call it $A(s)$- such that: $$\sum_{n=1}^{\infty}\sin(k\pi s)\frac{\zeta(ks)-1}{k}=A(s)\sum_{n=1}^{\infty}\frac{\zeta(ks)-1}{k}$$ if we define : $$k(s)=\sum_{n=1}^{\infty}\frac{\zeta(ks)-1}{k}$$ then : $$A(s)k(s)-A(-s)k(-s)=-\frac{3}{2}\pi  s$$
and the problem becomes proving the existence of $A(s)$ for all s, and of course, finding it !!","['divergent-integrals', 'regularization', 'special-functions', 'integration', 'real-analysis']"
138086,A group of order $p^2q^2$ is never simple,"Let $p,q$ be primes and let $G$ be a group of order $p^2q^2$ , what's the best way to show $G$ is non-simple? I know it suffices to show that one of the Sylow-p or Sylow-q subgroup of $G$ is normal, but the counting elements argument doesn't work here since different Sylow subgroups may have non-trivial intersection.","['finite-groups', 'group-theory', 'abstract-algebra']"
138089,Base and subbase of a topology,"I'm confused about subbases: the sub in the name suggests that a subbase $S$ is a subset of a base $B$ of a topology $T$. Can there be a topology $T$ such that it is generated by a subbase that is not a subset of a given base $B$ that generates $T$? The definitions are: A subbase $S$ is a subset of a topology $T$ that generates $T$, i.e. $T$ is the smallest topology such that $S \subset T$. A base $B$ is a subset of a topology $T$ that generates $T$ and such that every set in $T$ can be written as a union of elements in $B$. Is this correct?",['general-topology']
138102,A highschool factoring problem,"$x+y+z=0$ $x^3+y^3+z^3=9$ $x^5+y^5+z^5=30$ $xy+yz+zx=?$ I solved this problem by setting $xy+yz+zx=k$ and using the cubic equation with roots $x,y,z$. But is there any other methods?",['algebra-precalculus']
138130,Visualizing identity $m\le3n-6$ for simple connected finite planar graphs,"How can I visualize the identity $m\leq3n-6$ (where $m$ is the number of edges, $n$ the number of vertices) for simple connected finite planar graphs?","['differential-topology', 'graph-theory', 'visualization', 'combinatorics']"
138158,Roots of polynomial with natural coefficients,A polynomial equation with natural coefficients can have natural roots ?,['algebra-precalculus']
138169,Integration: area enclosed by graph of $x^4 + y^4 = 1$,I'm attempting to find the area enclosed by the graph $x^4 + y^4 = 1$ as shown below. My approach was to rearrange the equation so it is in terms of $y = f(x)$ and integrate one of the top two quadrants with respect to $x$ and then multiply by $4$ to get the area for the whole shape.  I've never tried to integrate this kind of graph before and I'm not sure If I've done it correctly.  Any input or assistance would be much appreciated.  Thanks.,"['calculus', 'integration']"
138183,Varieties given by non-algebraic equations,"In algebraic geometry one (mostly) studies varieties given by polynomial equations. Such equations define algebraic varieties and there are many ""dictionaries"" available. For example, the category of rings is anti-equivalent to the category of affine schemes, etc. What if we enlarge our realm of possible equations to equations of the form $x^y+y^z = z^x$ over the rational numbers. These also define ""varieties"" which are no longer algebraic. It doesn't define a scheme, I think, but can we define a locally ringed space or something similar or maybe more general to it? Sorry for the vagueness. I just have the feeling that sometimes one should enlarge their category in order to get their hands on what's really going on.","['algebraic-geometry', 'schemes', 'soft-question']"
138185,Why is the kernel of this strange polynomial homomorphism what it is?,"I've been trying to delve a little further into linear algebra, but I'm not following something I think is supposed to be obvious. Suppose $M_{m,n}(\mathbb{C})$ is the set of rectangular $m\times n$ matrices over $\mathbb{C}$, and let $S$ be the set of rank $1$ matrices. Furthermore, let $K\subset\mathbb{C}[S_{11},\dots,S_{mn}]$ be the ideal associated to $S$. Then the homomorphism $\mathbb{C}[S_{11},\dots,S_{mn}]\to\mathbb{C}[X_1,\dots,X_m,Y_1,\dots,Y_n]$ such that $S_{ij}\mapsto X_iY_j$ has kernel $K$. I don't follow the last claim. I'm used to the associated ideal of $S$ to be the polynomials in $\mathbb{C}[S_{11},\dots,S_{mn}]$ to be the ideal of polynomials which vanish on all points of $S$ for an algebraic set of zeroes, but that doesn't quite make sense with a set of rank $1$ matrices. Would someone be nice enough to explain why the kernel above is what it is? Thank you.","['matrices', 'linear-algebra', 'algebraic-geometry']"
138196,Linearly independent functions,"Show that the set consisting of the functions
$$x, e^x, e^{-x}$$
on $\mathbb R$ is linearly independent. So I have the equation $$ax + be^x + ce^{-x} = 0$$ and I want to show that this is only satisfied when $a = b = c = 0$ Letting x = 0, $b + c = 0$ Letting x = 1, $a + be + ce^{-1} = 0$ Letting x = -1, $-a + be^{-1} + ce = 0$ Using these equations as columns of a matrix I have $\begin{bmatrix}
0 & 1 & 1 \\
1 & e & e^{-1} \\
-1 & e^{-1} & e
\end{bmatrix}$ $\begin{bmatrix}
1 & e & e^{-1} \\
0 & 1 & 1 \\
-1 & e^{-1} & e
\end{bmatrix}$ $\begin{bmatrix}
1 & e & e^{-1} \\
0 & 1 & 1 \\
0 & e^{-1}+e & e^{-1}+e
\end{bmatrix}$ But if I now subtract (e^{-1}+e) times row 2 from row 3 I will get all zeros in the last row meaning linear dependence. So what have I done wrong?",['linear-algebra']
138208,Improper Integral Question: $ \int_0 ^ \infty\frac{x\log x}{(1+x^2)^2} dx $,"I have to test the convergence of the integral : $$ \int_0 ^ \infty\frac{x\log x}{(1+x^2)^2} dx $$ Please suggest. Also, have to show that the value of the integral is zero ?","['improper-integrals', 'integration', 'real-analysis']"
138226,Endomorphisms of a ring $R$ considered as $R$-module,"Let $R$ be a ring. Determine all $R$-module homomorphisms $\varphi:R\rightarrow R$. For any $\varphi$, $\ker\varphi$ and im $\varphi$ both have to be submodules of $R$.  In this case, that makes them ideals of $R$. So every $\varphi$ is a surjective map from $R$ to an ideal of $R$ so, if $I$ is some ideal of $R$ I'm really looking for every $\varphi:R \twoheadrightarrow I$. That's about as far as I've managed to get. I'm not even sure what form the answer is supposed to take. Thanks...","['modules', 'abstract-algebra']"
138232,"Books, Video lectures, other resources to Teach Yourself Analysis","So my limited mathematics education has been especially ignorant of analysis.  In this vein, I'd like to teach myself some of the introductory basics. I'm intrigued by sources that might contain video lectures to complement readings and problems.  Self-contained packages of all of the above are especially welcome! Free is always better, but if quality comes at a price, feel free to suggest pocket lightening options... And I'm certainly not ignorant of MIT's (awesome) opencourseware!  Options are always nice though...","['self-learning', 'reference-request', 'analysis']"
138234,How does a conformal mapping preserve angles in hyperbolic geometry?,"Suppose I have a sector $D = \{0 < \arg z < \alpha\}$ where $\alpha \leq 2\pi$. If I apply the function $w = \frac{\zeta - i}{\zeta + i}$ from the upper half plane to the unit disc ($\zeta = z^{\frac{\pi}{\alpha}}$), I get that the vertex of the sector goes to -1 and $z = \infty$ goes to 1. I get the unit circle essentially. My question for this example is: How do we know that the angles are preserved?","['hyperbolic-geometry', 'conformal-geometry', 'complex-analysis']"
