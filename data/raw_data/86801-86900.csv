question_id,title,body,tags
1154106,First Cohomology Group,"Is it true that the first cohomology group of a differentiable manifold with finite fundamental group is trivial? If so, could you explain why? Thanks very much","['homology-cohomology', 'algebraic-topology', 'differential-geometry']"
1154118,Essential Selfadjointness of Quantum Harmonic Oscillator Hamiltonian,"The Hamiltonian for the Quantum Harmonic Oscillator is (disregarding constants) the Hermite operator
$$
                    Hf = -f''+x^{2}f,
$$
where $\mathcal{D}(H)$ consists of all twice absolutely continuous functions $f \in L^{2}(\mathbb{R})$ for which $Hf \in L^{2}(\mathbb{R})$. Question: Without using properties of Hermite functions or Hermite polynomials, is there a direct method to show that $f \in \mathcal{D}(H) \implies xf, f' \in L^{2}(\mathbb{R})$. $f,g \in \mathcal{D}(H) \implies (Hf,g)= (f',g')+(xf,xg)=(f,Hg)$. $H$ is selfadjoint. (2 implies the spectrum is non-negative.) Background: Using these facts, the standard ladder argument used in Physics becomes a rigorous proof that $f$ is an $L^{2}(\mathbb{R})$ eigenfunction of $H$ with eigenvalue $\lambda$ iff $\lambda=2n+1$ for some $n=0,1,2,3,\cdots$, and $f$ is a constant multiple of the Hermite function
$$
       h_{n}(x) = (-1)^{n}e^{x^{2}/2}\frac{d^{n}}{dx^{n}}e^{-x^{2}}.
$$ (Actually, only properties (1) and (2) are needed to fully justify the ladder argument.)","['special-functions', 'operator-theory', 'mathematical-physics', 'spectral-theory', 'functional-analysis']"
1154155,"Sum of squares of i.i.d. finite mean variables, divided by $n^2$, approaches $0$ a.s.","Given $X_1,X_2,\dots$ are i.i.d, $X_n\ge0$, and $EX_1<\infty$, how can you show that
  $$
\frac{X_1^2+\dots+X_n^2}{n^2}\to 0\qquad \text{a.s.}?
$$ This is from an old probability qualifying exam. Some thoughts: You can show that $P(X_n\ge n\epsilon \text{ i.o})=0$, so that letting $Y_n=X_n1_{\{X_n\le n\epsilon\}}$, and $T_n=\sum_1^n Y_k^2$, it suffices to show $\frac{T_n}{n^2}\to 0$. Using Borel-Cantelli, to prove that it suffices to show $\sum_1^\infty P(T_n>\epsilon n^2)<\infty$ for all $\epsilon>0$. It's hard to get a good bound on $P(T_n>\epsilon n^2)$, though, since $ET_n$ grows as $n^3$. I imagine some kind of Holder/Jensen's inequality trick is necessary, though I cannot see it. Does anyone have any ideas? My question is equivalent the $p=1/2$ case of the $(\Longleftarrow)$ part of this unsolved question. This may make my question a duplicate, but I figured that mine being a special case might mean it was easier.",['probability-theory']
1154159,$\lim S_n$ finite implies $\sum E(X_n)$ finite,"I am learning Second Borel-Cantelli Lemma now and come across a problem. If $X_n \in [0,1]\forall n$,$S_n=\sum^n_{i=1}X_i$,$X_i$ independent and $\lim S_n<\infty$, then $\sum EX_n$ is finite. The question gives a hint: $$e^{-x}\leq 1-ax\leq e^{-ax},\forall x\in [0,1]\;\text{where} \; a=1-e^{-1}$$ and try to use product rule for expectation. The hint seems to suggest us to go through the proof of Second Borel -Cantelli but I really don't get it. I tried to plug the $X_n$ into the inequality but it leads me nowhere.  I also tried to see $E(e^{-S_n})$ and use the product rule but still fails. Something obvious am I missing?","['probability-theory', 'random-variables']"
1154169,Evaluate $\frac{x^3-x^2-5x-3}{x^3-x^2-15x} \ge 0$,I've been trying to simplify the problem but I can't. I tried long division factoring and perfect cube but I can't still solve it. My calculator shows $x=3$ and $x=-1$ but wait how? this is for the numerator,"['inequality', 'algebra-precalculus']"
1154208,Cramer-Rao and Efficient Estimators,"Let $X_1,X_2,X_3,...,X_n$ be a random sample from the exponential distribution having PDF $f(x;\lambda)= \frac{1}{\lambda}e^\frac{-x}{\lambda}\chi\{x>0\}.$ A) Find the Cramer-Rao lower bound for the variance of unbiased estimators for $\theta = \lambda^2$, B)Determine k so that $W=k\sum\limits_{i=1}^n X^2_i$ is unbiased for $\theta$. Is W an efficient estimator for $\theta?$ (Recall:$E(X^2_i)= 2\lambda^2$ and $E(X^4_i)=24\lambda^4.)$ This is a homework problem, The notes in class and book only cover C.R.L.B  for $f_Y(x;\lambda)$ and comparing it to variance of a given estimator which I understand. I don't see the connection though for using it on the variance of unbiased estimators. Is it just different terminology for the same thing or what is it that i'm missing? Can some one help me get started in the right direction? Every online source seems to reference Fisher information, haven't cover Fisher yet.","['statistics', 'probability', 'order-statistics', 'probability-theory']"
1154218,How should you prove product rules by induction?,"For example:
$$\prod_{i=2}^n\left(1-\frac{1}{i^2}\right)=\frac{n+1}{2n}$$
For every $n$ greater than or equal to $2$ my approach for this was that I need to prove that:
$$ \left(1-\frac{1}{n^2}\right)\left(1-\frac{1}{(n+1)^2}\right)=\frac{n+1+1}{2(n+1)}$$ is this the right approach? Because when i try and work out the algebra i keep on hitting a wall. \begin{align}
\left(1-\frac{1}{n^2}\right)\left(1-\frac{1}{(n+1)^2}\right)&=1-\frac 1{(1-n)^2}-\frac 1{n^2}-\frac 1{n^2(n+1)} \\
&=\frac{n^2}{(n+1)^2}-\frac 1{(n+1)^2} \\
&=\frac{n^2-1}{(n+1)^2}-\frac 1{n^2}+\frac 1{n^2(n+1)^2} \\
&=\frac{n^2(n^2-1)}{n^2(n+1)^2}-\frac{(n+1)^2}{n^2(n+1)^2} \\
&=\frac{n^2(n^2-1)-(n+1)^2}{n^2(n+1)^2}+\frac 1{n^2(n+1)^2} \\
&=\frac{n^2(n^2-1)-(n+1)^2+1}{n^2(n+1)^2}
\end{align}","['discrete-mathematics', 'contest-math', 'recreational-mathematics']"
1154234,$\log$ is continuous,"I'm trying to prove that the complex logarithm function is continuous using this theorem , but I'm hitting a snag in part of the proof. Let $D=\Bbb C\setminus(-\infty,0]$. The claim is that the function $\log\upharpoonright D:D\to\Bbb C$ is continuous on $D$. What we know so far is that $\log$ is defined as the inverse of $\exp\upharpoonright (\Bbb R\times(-\pi,\pi])$ (where the notation refers to the set of all complex numbers with real part in $\Bbb R$ and imaginary part in $(-\pi,\pi]$), and it is well-defined because we have shown that $\exp$ on this domain is a bijection onto $\Bbb C\setminus\{0\}$. We also know that $\exp$ is continuous. Given $x\in D$, we wish to show that $\log$ is continuous at $x$. In order to apply the linked theorem, we need a compact region, so let $y=\log x$ and define $Y=[\Re y-1,\Re y+1]\times[\frac{\Im y-\pi}2,\pi]$. Then $Y$ is compact, so $\exp(Y)$ is also compact, and since $y\in \Bbb R\times(-\pi,\pi]$ follows from the definition of $\log$ and $\Im y\ne\pi$ because this would imply $x\in(-\infty,0]$, we also have $$y\in Y^\circ=(\Re y-1,\Re y+1)\times(\frac{\Im y-\pi}2,\pi).$$ Now we can apply the theorem to deduce that $\exp\upharpoonright Y:Y\to\exp(Y)$ is a homeomorphism, so $\log$ is continuous on $\exp(Y)^\circ$. Where I got stuck is in the last part, to show that $x\in\exp(Y)^\circ$ given that we already know $x\in\exp(Y^\circ)$, because the subspace topologies involved don't play well with interior here. Specifically, we know that $\exp(Y^\circ)$ is open in $\exp(Y)$, but I don't see how this implies that it is open in $\Bbb C$ (or $D$). I realize that I can probably grok this proof with sufficient details of the shape of the transformed region $\exp(Y)$, but I'm going for maximum ""slick""-factor with this proof as well, so I'd prefer to avoid any calculations more complicated than necessary. In particular, if possible I don't want to use any other properties of the exponential function than those mentioned here. If there is another entirely different way to prove this nicely, I'm all ears.","['general-topology', 'complex-analysis', 'continuity', 'real-analysis']"
1154235,"Are countably infinite, compact, Hausdorff spaces necessarily second countable?","Let $X$ be a compact Hausdorff space. If $X$ is finite, then there are at most finitely many open sets and so it is second-countable. On the flipside if $X$ is uncountably infinite, it is possible that $X$ not be second-countable. A classic example is $\omega_1+1$ given the order topology (here $\omega_1$ is the first uncountable ordinal). But what about if $X$ is countably infinite? Glancing at the abstract of this paper , it seems that the existence of a non-second-countable, countably infinite, compact Hausdorff space is plausible if one forbids the use of the axiom of choice. It turns out I'm perfectly happy using the axiom of choice. So I'm left wondering whether it is true that a countably infinite, compact Hausdorff space must be second-countable in ZFC. All the examples I concoct work but a proof eludes me. Could someone provide a proof, reference or counterexample, it would be much appreciated!","['general-topology', 'axiom-of-choice']"
1154263,Is a product of two Noetherian schemes over Spec $\mathbb Z$ a Noetherian scheme?,"In Hartshorne's proof of Proposition 6.6 in Chapter 2, he says that if $X$ being Noetherian implies $X\times\mathbf A^1$ is ""clearly"" Noetherian. I assume this is because $X$ can be covered by affine open sets $U_i=\text{Spec}\ A_i$ with Noetherian $A_i$ and then $X\times\mathbf A^1$ is covered by the affine open sets $U_i\times_{\mathbb Z}\mathbf A^1$, which are $\text{Spec}\ \big(A_i\otimes_{\mathbb Z}\mathbb Z[x]\big)=\text{Spec}\ A_i[x]$, and $A_i[x]$ is Noetherian from Hilbert's basis theorem. Is there a simpler way to see this? More generally if $X,Y$ are schemes over $\mathbb Z$, is $X\times_{\text{Spec}\ \mathbb Z}Y$ always Noetherian? With a similar argument as above this is the same as asking whether $A\otimes_{\mathbb Z}B$ is a Noetherian ring if $A$ and $B$ are, correct? I guess my confusion arises from ""Noetherianness"" as modules vs. ""Noetherianess"" as a ring. Over what schemes $S$ (instead of $\text{Spec}\ \mathbb Z$) is it true that products of two Noetherian schemes over $S$ is a Noetherian scheme?","['commutative-algebra', 'algebraic-geometry', 'tensor-products']"
1154274,Strange approximation of $\pi$?,"I was playing with my calculator (Casio fx-991MS) the other day. I input $$\arcsin(\sin(2))$$ The result came out as $$1.141592653\ldots$$ I immediately noticed that the digits seem to resemble $\pi$. So, I decided to investigate further. I input $$\arcsin(\sin(2))+2-\pi$$ I was expecting some small number to pop out but instead I got $0$. I know my calculator has precision only upto $10$ digits. So, naturally, I decided to put the number on another (albiet higher precision) calculator. This time, I got a number in the range of $10^{-19}$. I also put it through WA which surprisingly gave $0$ as answer. Finally,I put the result on an online ultra high precision calculator. It was even more crazy. I got a mind bogglingly small number in the range $10^{-600}$ My question is, what the hell is happening here!?","['pi', 'trigonometry', 'approximation']"
1154366,Gamma function proof of gamma $\;Γ(1/2) = \sqrt \pi\;$,"So our teacher doesnt use the same demonstration as most other sites use for proving that gamma of a half is the square root of pi.
I dont understand the demonstration from the first step because he uses the Wallis product but first he represents $Γ(1/2)$ as : $$Γ(n + 1/2) = 2^{-n}Γ(1/2)\prod_{k=1..n}(2k-1)$$ This is just the first step and i dont undderstand how they get that..
I understand the gamme function and that when you integrate it you get $Γ(x+1) = xΓ(x)$ and i know i need to somehow use this identity but i dunno how.","['integration', 'real-analysis', 'analysis', 'factorial', 'gamma-function']"
1154390,"Dimension of $X=\{a,b\}$ as a zariski or general topological space","This is an example from Gathmann's notes on algebraic geometry. His definition of the dimension of a non-empty topological space is: The dimension $\dim X\in N\cup\{\infty\}$ is the supremum over all $n\in N$ such that there is a chain
$$\emptyset \ne Y_0 \subsetneq Y_1 \subsetneq Y_2 \subsetneq ... \subsetneq Y_n \subset X$$ of length $n$ of irreducible closed subsets $Y_1,Y_2, ..., Y_n$ of $X$. Next he gave two examples:
(a) If $X$ is a non-empty finite affine variety then $\dim X=0$. I can understand this since the chain would be $Y_0={a}$ for any point $a\in X$, and $X$ itself is reducible, so cannot be in the chain. (b) General finite topological spaces need not have dimension $0$. For example, the set $X=\{a,b\}$ whose closed subsets are $\emptyset, \{a\}$, and $X$. It has dimension when since ${a}\subsetneq X$ is a chain of length $1$. I don't understand part (b). Why is $X$ considered to be irreducible, hence in the chain here? I think $X$ can be written as the union of two closed sets $\{a\}$ and $\{b\}$, which means it is reducible. Thank you for any help!","['zariski-topology', 'algebraic-geometry']"
1154409,Is the cardinals of $P(P(\Bbb{N}))$ $C$ or $2^C$?,Let us look at $P(P(\Bbb{N}))$. Is the cardinals $C$ or $2^C$? Really confusing...,['elementary-set-theory']
1154423,Alternate construction of the universal cover of a space,"Suppose you have a connected, locally path connected Hausdorff space $Y$ that admits a universal covering (i.e. is semilocally simply connected). It occured to me that maybe one can describe the universal covering slightly differently than is usually done (at least from what I have seen). Fix a point $x_0\in Y$ and consider the set $$C_{x_0}([0,1]; Y)=\{ \gamma:[0,1]\to Y\textrm{ continuous path }| \gamma(0)=x_0\}$$ which is a subset of $C([0,1];Y)$ equipped with the compact-open topology . Introducing an equivalence $\simeq$ on $C([0,1];Y)$ where $\alpha \simeq \beta$ if $\alpha$ and $\beta$ are endpoint-preserving homotopic, set $$\widetilde Y= C_{x_0}([0,1];Y)/\simeq. $$ This construction certainly agrees as sets with the original (because we simply take the homotopy classes of paths starting at the given fixed point). On the other hand, one may naturally endow $\widetilde Y$ with the quotient topology of  $C_{x_0}([0,1];Y)$ by the equivalence relation $\simeq$. The question is, does this topology agree with the topology in the original construction? While I'm only really interested in proper geodesic spaces $Y$ I find it interesting that if the above is indeed the 'right' topology then there is a natural constuction that makes sense even if $Y$ does not have a universal cover (what goes wrong in that case is also an interesting question!)","['general-topology', 'covering-spaces', 'algebraic-topology']"
1154426,Finding constants in intial value problems,"I have some problems in determining constants in initial value problems, especially for linear nonhomogenous differential equations. Use this as an example: $$x'(t) = 2t - 2x(t) + 5, x(0) = -1$$ We are basically allowed to simply solve these by using the formula for nonhomogenous ODEs: $$ y = (\int_0^t b(t)e^{A(t)} dt + c)e^{-A(t)}$$ So in this case I have: $a(t) = 2, b(t) = 2t + 5$ and therefore: $$y = (\int_0^t(2t+5)e^{2t} dt + c)e^{-2t}$$ for which I get: $$y=(\frac{1}{2}e^{2t}(2t-1)+\frac{1}{2}e^0 + \frac{5}{2}e^{2t}-\frac{5}{2}+c)e^{-2t}$$ $$y = t-2e^{-2t}+2+ce^{-2t}$$ Now what value should the constant take? First of all is it correct to simply carry the c ""with me"" in the calculations? I know that ultimately the first c comes from the integration of $a(t)$, then after the term in the braces is integrated, that c changes. So if I get this term in the end: $$y = t-2e^{-2t}+2+ce^{-2t}$$ Can I simply determine c by plugging in $t=0$ and setting the value of that expression equal to -1? $$y(0)=0-2e^0+2+ce^0=-1$$ And then solve for c? Would that be correct?",['ordinary-differential-equations']
1154429,"Prove $\int_{[a,b]}f=\int_{[a,c]}f+\int_{[c,b]}f$","Let $a,b\in\mathbb C$ and $c\in[a,b]$. Let $f$ be continuous on $[a,b]$. Use the definition to show that
\begin{equation}
\int_{[a,b]}f=\int_{[a,c]}f+\int_{[c,b]}f
\end{equation} Note: You should stick to the definition, which gives, e.g., $\int_{[a,b]}f=\int_0^1 f(a+t(b-a))\cdot (b-a)dt$. Ok. My first step is noting that $[a,b]$ is actually the line segment connecting the complex numbers $a$ and $b$, which is the image of the curve
\begin{equation}
\gamma(t)=a+(b-a)t, \quad 0 \le t \le 1
\end{equation}
which explains where the definition of $\int_{[a,b]}$ comes from, using 
\begin{equation}
\int_\gamma f = \int_a^b f(\gamma(t))\gamma'(t)dt
\end{equation} Now here is the start of my proof:
\begin{align*}
\int_{[a,c]}f+\int_{[c,b]}f&=\int_0^1 f(a+t(c-a))\cdot (c-a)dt+\int_0^1 f(c+t(b-c))\cdot (b-c)dt \\
&=(c-a)\int_0^1 f(a+t(c-a))dt+(b-c)\int_0^1 f(c+t(b-c))dt
\end{align*} I'm not great with manipulating integrals, so I appreciate any help you can offer. Thanks!","['multivariable-calculus', 'definite-integrals', 'plane-curves', 'complex-analysis', 'contour-integration']"
1154432,"$f(x)=q$ if $x=p/q$, properly reduced is unbounded at every point.","Define the function $f$ as follows: $$f(x) =
\begin{cases}
q,  & \text{if $x=p/q$,properly reduced} \\
0, & \text{if $x$ is irrational}
\end{cases}$$ Prove that for every real number $x_0$, $f$ fails to be bounded at $x_0$, i.e. there does not exist any neighborhood of $x_0$ for which $f$ is bounded at. It's enough to consider only rational points. Given any $x_0 \in \mathbb Q$, and any $\delta$-neighborhood of $x_0={p\over q}$ contains infinitely many rational points. So given any $M \gt 0$, in fact, greater than $q$, there can be only finitely many rationals in the $\delta$-neighborhood of $x_0$ with denominator less than or equal to $M$ . Thus, there must be a rational in a properly reduced form with denominator greater than $M$ in the specified $\delta$-neighborhood of $x_0$, and so the value of the function at this point would be greater than $M$. Hence, $f$ is unbounded at any neighborhood of $x_0$. This is my solution and I think it's correct but I'm unsure how to rigorously show the bolded part. That is, how can I write it down to guarantee that there are only finitely many rationals satisfying the assertion? I'd appreciate a formal explanation on this part.","['limits', 'real-analysis', 'analysis']"
1154447,Proving one version of equivariant formality,"Let $G$ be a compact, connected Lie group acting smoothly on a compact, connected and oriented smooth manifold $M$. We denote by $H_G^*(M)$ the corresponding equivariant cohomology. We have a canonical map, the characteristic map ,
$$
c:H^*(BG)\rightarrow H_G^*(M)
$$
that endows $H_G^*(M)$ with the structure of an $H^*(BG)$-module. There's also a canonical restriction map
$$
r:H_G^*(M)\rightarrow H^*(M).
$$
We say that $M$ is equivariantly formal if $r$ is onto. Any hints on how to prove the following will be appreciated: Propositon: If $M$ is equivariantly formal, then $H_G^*(M)\simeq H^*(M)\otimes H^*(BG)$ as $H^*(BG)$-modules. N.B.: I am aware that there are many different ways to define equivariant formality, but I'd like to use only the given definitions, if possible.","['equivariant-cohomology', 'algebraic-topology', 'differential-geometry']"
1154463,Solving the differential equation $\frac{y'}{x\sqrt{1+y'^2}}=C$,"I have tried solving the differential equation: $$\frac{y'}{x\sqrt{1+y'^2}}=C,$$ where $y=y(x),\;y'=dy/dx$ and $C$ is a constant. The solution should be a circle apparently. My boundary conditions are $y(1)=0,\;y(2)=1$. Here is my attempt (UPDATE I added LaTex and corrected my solution by using Prajakta's hint): $$\frac{y'}{x\sqrt{1+y'^2}}=C$$ $$\frac{y'^2}{1+y'^2}=Dx^2$$ $$y'^2(1-Dx^2)=Dx^2$$ $$y'^2=\frac{Dx^2}{1-Dx^2}$$
$$y'=\pm\frac{\sqrt{D}x}{1-Dx^2}$$ $$\int \;dy=\pm\int \frac{\sqrt{D}x}{1-Dx^2}\;dx$$ $$u=1-Dx^2,\;\;du/dx=-2Dx,\;\rightarrow\;-\frac{1}{2D}\;du=x\;dx$$ $$y=\pm\int \frac{\sqrt{D}x}{1-Dx^2}\;dx=\pm\frac{\sqrt{D}}{2D}\int \frac{du}{\sqrt{u}}=\pm\frac{\sqrt{D}}{2D}\left(2\sqrt{u}+H\right)$$ $$y=\pm \frac{\sqrt{D}}{D}\left(\sqrt{1-Dx^2}+H\right)$$ $$y=\pm \frac{\sqrt{D}}{D}\left(\sqrt{D\left(\frac{1}{D}-x^2\right)}+H\right)$$ $$y=\pm \sqrt{\frac{1}{D}-x^2}+N$$ Thank you =)",['ordinary-differential-equations']
1154472,Understanding singularities of differential equations,"Is there a simple reference which explains how to see geometrically an algebraic differential equation ? I tried to read ""Équation différentielles à points singuliers réguliers"" of Pierre Deligne but it was a bit too complicated for me. I only follow a basic course on Riemann surfaces, is there some reference or books which can helps me to understand it better this paper of Deligne (or more generally what is the geometry hidden behind theses equations and these singularities ? Thanks in advance and sorry if my question is a bit unclear.","['ordinary-differential-equations', 'algebraic-geometry']"
1154476,How do I prove $\mathbb{Z}\times\mathbb{Z}\times\mathbb{Z}$ and $\mathbb{Z}\times\mathbb{Z}$ are not isomorphic?,"Here is how I proved this exercise. Suppose $\phi:\mathbb{Z}\times \mathbb{Z}\rightarrow \mathbb{Z}\times\mathbb{Z}\times\mathbb{Z}$ is a group isomorphism. Set $\phi(1,0)=(a,b,c)$ and $\phi(0,1)=(d,e,f)$. Then, it can be viewed as $span(\{(a,b,c),(d,e,f)\}) = \mathbb{R}^3$. This is obviously false. (Is my argument correct?) However, is there another way to prove this not using linear algebra, just using group theory?","['group-isomorphism', 'solution-verification', 'abstract-algebra', 'proof-verification', 'group-theory']"
1154544,Why not add something to both sides of a purported identity to prove it? [duplicate],"This question already has answers here : Why is it that when proving trig identities, one must work both sides independently? (7 answers) Closed 9 years ago . A section in my precalculus book is devoted to establishing (=proving) trigonometric identities, and a typical problem in the book presents a purported identity and asks students to establish it. The book recommends this method for doing so:
Consider the more complicated-looking side of the purported identity.
Use rules of algebra and known trigonometric identities to manipulate that side until it matches the other side.
(Sometimes you'll need to manipulate both sides until they match one another.) The book then has this warning: Be careful not to handle identities to be established as if they were equations. You cannot establish an identity by such methods as adding the same expression to each side and obtaining a true statement. This practice is not allowed, because the original statement is precisely the one that you are trying to establish. You do not know until it has been established that it is, in fact, true. Huh? I mean, I understand that you need to be careful. I understand that you can't manipulate your purported identity thus:$$\{\textrm{purported identity}\}\Rightarrow\{\textrm{something else}\}$$I understand that every implication must be instead like this:$$\{\textrm{purported identity}\}\Leftarrow\{\textrm{something else}\}$$And therefore, for example, one cannot raise both sides of the purported identity to an even power, or multiply both sides by $0$. Fine. But what's wrong with ""adding the same expression to each side and obtaining a true statement"" ??","['trigonometry', 'algebra-precalculus']"
1154605,$ \int_{0}^{2} (2x - x^2)^n dx $ recurrence relation,"Given $$ I_n =  \int_{0}^{2} (2x - x^2)^n dx $$ Compute $I_2$ I simply expanded it into $$ \int_0^2 4x^2 - 4x^3 + x^4 dx $$ and computed it. Show that $$ (2n+1)I_n = 2nI_{n-1} $$ I first tried doing integration by parts by writing it as $ \int_0^2 (x)' (2x-x^2)^n dx$ but that led nowhere and I also tried splitting it into $\int_0^2 (2x+x^2)^{n-1} (2x+x^2) dx$ and that didn't work either. How do I do this? Compute
$$ \lim_{n \rightarrow \infty} I_n $$",['calculus']
1154658,Fast search of local positive quadruples on the sphere,"Let $U = \{u_{1}, u_{2}, \ldots, u_{n}\} \subset \mathbb{R}^{3}$ be the finite set of points on the unit sphere in $\mathbb{R}^{3}$: $||u_{i}||_{2} = 1$ Definition : Quadruple of points $(u_{i}, u_{j}, u_{k}, u_{l})$ is said to be positive if
$$
\exists \alpha_{i j} > 0, \alpha_{i k} > 0, \alpha_{i l} > 0: u_{i} = \alpha_{i j} u_{j} + \alpha_{i k} u_{k} + \alpha_{i l} u_{l}
$$ Definition : Positive quadruple $(u_{i}, u_{j}, u_{k}, u_{l})$ is said to be local relatively to the set U if $\nexists u_{s} \in U$ such that $(u_{s}, u_{j}, u_{k}, u_{l})$ is positive. Question : Is there any fast algorithm to find all local positive quadruples in the given set $U$? EDIT :
Of course, in worst case the complexity of the algorithm should be $\Theta(n^3)$, since there is an example when there are $\Theta(n^3)$ local positive quadruples. But suppose that $u_{i}$ are taken from some real-world example, and they are distributed on the sphere somehow uniformly (~close to uniform).","['geometry', 'computational-geometry']"
1154687,How to test if a given elliptic curve has complex multiplication,"Is there a general, reasonably easy to understand, algorithm for testing whether an elliptic curve has CM?
For example, consider the curve
$y^2=x^3+\frac{27}{1727}x+\frac{54}{1727}$ This has j-invariant 1, which in particular is an algebraic integer. Is there a good way of seeing that this doesn't have CM? [I would prefer an answer which gives a general procedure rather than a trick which works for that specific curve.]","['algebraic-geometry', 'algebraic-number-theory', 'complex-multiplication', 'elliptic-curves']"
1154705,Find roots of $e^z=-3$ given that z=x+iy,Can you give me some idea of how to do this?  I'm really stuck.,"['complex-numbers', 'complex-analysis']"
1154750,Prove that $\operatorname{trace}(A^TA) = 0\ \iff\ A = 0$.,"Given that $A_{m \times n}$ has real entries, I want to prove that $\operatorname{trace}(A^TA) = 0$ if and only if $A = 0$ . In other words, I want to show that the only way for the trace of $(A^TA)$ to be zero is if $A$ is a zero matrix, and that if $A$ is a zero matrix then $A^TA$ has a trace of zero. Intuitively this makes sense to me. My idea is that in order to get zeros on the main diagonal of any product of matrices I'd need at least one of the matrices to have zeros on its main diagonal. In this case, because the product is between $A$ and its transpose, I figure it $A$ does indeed need to be a zero matrix. However, I'm having difficulty turning my intuition into an actual proof.","['matrices', 'linear-algebra']"
1154787,Calculating using Taylor's series with Remainder: $ \lim \limits_{x \to 1} \frac{\ln x}{x^2+x-2} $,"How to Calculate with Taylor's series with Remainder: $$ \lim \limits_{x \to 1} \frac{\ln x}{x^2+x-2} $$ without using L'Hopital's Rule? Here is what I reached: 
$$\lim \limits_{x \to 1} \frac{(x-1) + \frac{(x-1)^2 }{2!}+R_2(x)}{x^2+x-2}$$
and I know that $\lim \limits_{x \to 1} \frac{R_n(x)}{(x-1)^n} = 0 $ (and here I'm supposed to insert $n=2$ and use it somehow to find the limit). But couldn't somehow get a result. I think I'm missing something essential here. can someone tell me if all the things I wrote are true until here and try to complete the solution in a clear way ?","['taylor-expansion', 'limits-without-lhopital', 'limits']"
1154805,On Spec of a localized ring,"Let $A$ be a commutative ring with unity, and $S$ a regular multiplicative subset of $A$ containing $1$. I know that given $f \in A$, Spec $A_f$ corresponds to an open subscheme of Spec $A$. I was wondering does Spec $S^{-1}A$ also correspond to an open subscheme of Spec $A$ as well (for any multiplicative subset $S$)? Thank you! PS I guess what I am curious is that: when I consider the subset of Spec $A$ that does not meet $S$, is it isomorphic to Spec $S^{-1}A$ as schemes?","['affine-schemes', 'algebraic-geometry']"
1154817,Norm of orthogonal projection,Consider $\Bbb R^n$ with the standard inner product and let $P$ be an orthogonal projection defined on $\Bbb R^n$. It is known that the operator norm of $P$ induced by the inner product is less than or equal $1$. Let $\|\cdot\|$ be any arbitrary norm on $\Bbb R^n$. Is it true that the operator norm of $P$ induced by the new norm is less than or equal to $1$?,"['matrices', 'linear-algebra', 'operator-theory']"
1154825,Prove the increasing union of ideals is an ideal,prove that $I_{1} \subseteq I_{2} \subseteq I_{3} \subseteq....$ are ideals of $R$ then $\bigcup_{n =1} I_n$ is an ideal of $R$. I am having a hard time picture this in my mind. Help anyone.,"['ring-theory', 'ideals', 'abstract-algebra']"
1154873,A question about complement of a closed subspace of a Banach space,Let $X$ be  a Banach space and $M$ be a closed subspace of $X$. Suppose that there exists a subspace $N$ of $X$ such that $X=M\oplus N$. Does it imply that $N$ is closed ? I know that not every closed subspace of a Banach space is complemented (see here ). But my question is slightly different from that question. I think the answer is no. But I do not able to construct a counter example.,"['functional-analysis', 'banach-spaces']"
1154875,A parabola lemma,"I am looking for a previous reference and/or a geometric proof of the following lemma: Let $P$ be the parabola $y=x^2$. Let $a$, $b$, $c$, $d$ be four points on $P$ sorted from left to right, and let $z$ be the point of intersection of the segments $ac$ and $bd$. Define the horizontal distances $p=b_x-a_x$, $q=d_x-c_x$, $r=z_x-b_x$, $s=c_x-z_x$. Then, $p/q=r/s$. This is easily proven algebraically, but I was wondering whether there is a geometric argument.","['analytic-geometry', 'geometry']"
1154944,Squaring of the circle,"From curiosity I read about enhancements of the squaring of the circle. Right now I do not see what is wrong with the following approach: Archimedes devised that the surface of a circle equals the surface of a triangle which has one leg of the length of the radius and one leg has the length of the circumference of the circle, as shown in the following picture: Which just means: Surface of circle = 1/2 * radius * circumference From this triangle, one can create a rectangle of equal surface by ""cutting"" the triangle into two halfes. (Please excuse the loosey picture, it is just to visualize the idea) And any rectangle can be tranformed into a square easily, as shown here: So, as far as I understood, the problem with squaring a circle is that PI is irrational. But if PI is respected in constructing the square (as in the leg of the triangle), it seems legit at first glance (at least to me). I know lots of very smart people tried this, so this approach is flawed and has already been thought. Why is this construction not legal? As I do not see any reason to use compass and ruler here, I want to express it in
a more mathematical construction: Assume a circle with radius r and circumfence of 2 π r and surface area = π * r^2 Create Archimedes orthogonal triangle with: AO=r, BO=2 π r Create rectangle from this triangle with: AB = p = (1/2 * 2 π r) = π r AC = q = r Make a square of this: h^2 = p  * q = (π r) * (r) = π r^2 so h = sqrt(π r^2) With a surface of sqrt(π r^2) ^2 = π r^2 So Surface square = Surface circle q.e.d.","['geometry', 'rectangles', 'circles']"
1154998,$\dim C(AB)=\dim C(B)-\dim(\operatorname{Null}(A)\cap C(B))$,"Let $A \in M_{n \times m}\left(F\right)$ and $B\in M_{m \times p}\left(F\right)$ for a field $F$. Prove: $\dim C(AB)=\dim C(B)-\dim(\operatorname{Null}(A)\cap C(B))$, where $C(X)$ denotes the column span of a matrix $X$.","['matrices', 'linear-algebra']"
1155012,$k$ with an even sum of digits for all multiples of $k$?,Is there a number $k\in\mathbb{N}$ such that $k\cdot n$ has an even sum of digits for all $n\in\mathbb{N}$? I would be grateful for any ideas of how to attack this problem...,"['elementary-number-theory', 'contest-math', 'number-theory']"
1155016,n-by-n degree grid on a sphere?,"I've been trying to generate an evenly spaced grid centred at a given point on a sphere, such that the angular separation between any neighbouring pair of points is the same (e.g., 1 degree). The grid should be oriented with the central column of points along the same meridian as the given point. I have little experience with spherical trigonometry (aside from knowing about the Haversine formula and the spherical law of cosines) but after some reading I'm fairly certain that each cell will require four unique great circle arcs. The previous approach I followed using vectors only found great circles perpendicular to the central column (like the coloured grids shown in the first plot) and so the points were not evenly spaced, especially at the edges. Each point in the second plot (showing the result of my latest attempt) is plotted with a 1 degree-radius circle surrounding it, which ideally should coincide with the surrounding four points. The updated method described below finally generates a regular grid. However, for a 20-by-20 degree grid the angular separation of the corner point to the central column is ~4.5 arcseconds smaller than the ideal 10 degree separation. Does anyone know of a method that can determine the required grid points to greater precision? Current method:
The procedure I've followed so far to generate the n-by-n degree grid centred at a given point (e.g. longitude=0, latitude=0; let's call this point A) involves three stages: Note: a 10-by-10 degree grid would consist of 11-by-11 points each separated from the nearest four points in the adjacent rows and columns by 1 degree. All calculations assume a sphere of radius 1. Find the points along the `central' column: Simply increment the latitude (i.e. following the meridian running through the centre point) and wrap the latitude and longitude if a pole is crossed (i.e. if the current point's latitude is less than -90 or greater than +90). Find the points along the `central' row (through the grid centre): 
Since the row of points through A follow a great circle that intersects the meridian at a right angle, we need to find the plane that this second great circle lies on. Consider two points at the given central longitude; let point A be the grid centre at 0 degrees longitude and 0 degrees latitude, and point B at 0 degrees longitude and 1 degree north. The two points can be expressed in Cartesian coordinates, and so the unit vector (N) normal to the great circle that contains A and B is found using the cross product, i.e. N = BxA. The cross product of the unit vector N with a unit vector in the direction of A gives another normal vector (M). The vector M can then be used as an axis to rotate N by (90-x) degrees^, where x is the offset (in this case 1 deg) from the central column. This is repeated outwards in steps of 1 degree for one half of the central row then the other half using a unit vector in the opposite direction to N.
^ http://en.wikipedia.org/wiki/Rotation_matrix#Rotation_matrix_from_axis_and_angle Fill in the remaining points in each quadrant:
Each point in the grid forms a rectangle lying on the same plane as three other points in the grid - let A be the point at the grid centre, B is a point 'above' or 'below' A in the same column and C is a point on the central row, and the unknown point D is in the same row as B and same column as C. For the upper left quadrant, the rectangle (sometimes a square) would have corners clockwise from the upper-left D, B, A, and C. First compute vectors AB and AC then a unit vector normal to the triangle BAC can be found from their cross-product, i.e. t=ABxAC. To find D, the approach I've used is to rotate the plane on which A/B/C/D lie to align it with the xy-plane. The rotation matrix requires a rotation axis and rotation angle that I found here: https://gamedev.stackexchange.com/a/48102 The dot product of the rotation matrix and each of vectors A, B and C allows vector D' (the equivalent of vector D in the xy-plane) to be found from their components,
i.e., $D' = (b_x-a_x+c_x, b_y-a_y+c_y, b_z-a_z+c_z)$ The dot product of the rotation matrix using the same rotation axis but rotation angle of opposite sign to that given above with vector D' gives the coordinates of vector D, which can be converted to the latitude and longitude for point D. This is repeated for every remaining point in the four quadrants. I've spent a few days looking for a better method but without any luck. Fig 1. Sphere with grids: Fig 2. Grid points - note circles shown are 1 degree in radius (i.e. the perimeter of a 1 degree spherical cap centred at the given grid point). I had used a gnomonic projection to present the grid in figure 2 (using the python plotting package APLpy) but replaced it with an orthographic projection since the former shows great circles as straight lines but in this case the rows of points are joined by different great circle arcs, except the (n/2+1)th row.","['cartography', 'geometry', 'spherical-trigonometry', 'spherical-geometry']"
1155046,Will this equation have real solutions?,"Consider the following equation: $$ax^2 + bx + c = f(x)$$ $a$, $b$, and $c$ are arbitrary real constants. $f(x)$ is not a polynomial. Does there exist a condition on $f(x)$ such that the solutions are guaranteed to be real? Update: A fixed, more detailed version of the question can be found here Do nth degree polynomials derived using Least Squares Interpolation always have n+1 intersections with the function?",['functions']
1155060,prove that $f$ is periodic,"A function $f\colon\mathbb{R}\to(0,\infty)$ satisfies equation $f(x)=f(x+64)+f(x+1999)-f(x+2063)$. Prove that $f$ is periodic. I'm quite sure that 1999 and 64 are random numbers (probably 1999 = year of competition) and any positive integers $p$ and $q$ would work fine. I had an idea that in general $pq$ or $pq(p+q)$ should be a period of a positive function $f$ which satisfies $f(x+p+q)+f(x)=f(x+p)+f(x+q)$, so I tried substitutions like $x=p$, $x=q$, $\dots$, $x=pq-p$, $x=pq-q$, $x=pq-p-q$ and adding obtained equations and doing reductions using others, but it was an unsuccessful attempt. I have no idea how to use the assumption that $f$ is positive.","['contest-math', 'functions', 'periodic-functions']"
1155062,Arzela-Ascoli: Proof?,"Problem Given a compact domain. Regard the function space:
$$\mathcal{C}(\Omega):=\{f:\Omega\to\mathbb{C}:f\text{ continuous}\}$$ Consider a bounded family:
$$\mathcal{F}\subseteq\mathcal{C}(\Omega):\quad\|f\|_{f\in\mathcal{F}}<\infty$$ Then Arzela-Ascoli states:
$$\mathcal{F}\text{ precompact}\iff\mathcal{F}\text{ equicontinuous}$$
How to prove this from scratch? Attempt For a precompact family one finds:
$$\mathcal{F}\subseteq\mathcal{B}_\delta(g_1)\cup\ldots\cup\mathcal{B}_\delta(g_I)$$
So one can always pick one close enough:
$$f\in\mathcal{F}:\quad|f(x)-f(z)|\leq|f(x)-g_f(x)|+|g_f(x)-g_f(z)|+|g_f(z)-f(z)|<\varepsilon\quad(x\in B_\delta(z))$$ Conversely, prove for a sequence:
$$f_n\in\mathcal{F}:\quad\|f_{m'}-f_{n'}\|\to0$$ For a compact domain one finds:
$$\Omega\subseteq B_\delta(a_1)\cup\ldots\cup B_\delta(a_I)$$ Bolzano-Weierstrass gives a subsequence:
$$|f_n(a_i)|_{n\in\mathbb{N}}<\infty:\quad|f_{m'}(a_i)-f_{n'}(a_i)|\to0$$ Take as threshold:
$$m',n'\geq N':=\max_{i=1\ldots I}N'_i$$ So one can again always pick one close enough:
$$x\in\Omega:\quad|f_{m'}(x)-f_{n'}(x)|\leq|f_{m'}(x)-f_{m'}(a_x)|+|f_{m'}(a_x)-f_{n'}(a_x)|+|f_{n'}(a_x)-f_{n'}(x)|<\varepsilon$$ Is this proof correct or do I miss something? Discussion Moreover, why does the usual proof exploit separability before? (For example see wiki: Arzela-Ascoli: Proof ) Sure for a proposition on its own:
$$\Omega\text{ separable}:\quad|f_n(x)-f(x)|\to0$$
$$\Omega\text{ precompact}:\quad\|f_n-f\|\to0$$ But why both together in a single proof?","['functional-analysis', 'real-analysis', 'banach-spaces']"
1155091,Young tableaux of $8\otimes 8$ in $SU(3)$,"In Georgi's Lie Algebras in Particle Physics , one finds the following Young tableaux for $8\otimes 8$ in $SU(3)$: I am unsure of all the cancellations. Let us number the canceled tableaus increasing from left to right and top to bottom. There are seven cancellations. I understand cancellations 4, 6 and 7 because they are antisymmetric fourth rank, which must vanish. For instance, I don't know why 2 gets cancelled but the one next to it, which has virtually the same structure, doesn't get cancelled. Any help would be greatly appreciated.","['representation-theory', 'abstract-algebra', 'young-tableaux', 'lie-groups', 'group-theory']"
1155104,Expected number of coin tosses to land n heads,"In reading about how to calculate the expected number of (fair) coin tosses to land n Heads in a row, using the equations produces the following: $$E(1|H) = 2$$
$$E(2|H) = 6$$
$$E(3|H) = 14,$$
and so on. What I also noticed is that given the following probabilities of landing N heads in a row (using $\frac1{2^n}$) we have: $$P(1|H) = \frac1{2}$$ 
   $$P(2|H) = \frac1{4}$$
   $$P(3|H) = \frac1{8},$$
and so on. From this it looks like we can calculate the expected number of tosses for a run of n heads by summing up the inverse of the probabilities for landing n head from 1 to n: For instance the expected number of tosses for $3$ heads is just $8 + 4 + 2 = 14.$ It is not clear to me from reading through the derivations and formulas of the expected values why this pattern emerges. Is this simply another way of stating the formulas using concrete values for P?","['conditional-expectation', 'probability']"
1155108,Lebesgue measure of sets [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Calculate the Lebesgue measure of following sets: $A=\{(x,y): x\in\mathbb{Q} \vee y\in\mathbb{Q}\}$ $B=\{(x,y): x-y\in\mathbb{Q}\}$ So I guess I need to calculate an integral over those sets. But I have no idea how to proceed?","['lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
1155140,Use induction to prove that $n! \leq n^{n-1}$,Use induction to prove that $n! \leq n^{n-1}$ for all integers $n\geq 1$. I'm having a hard time with induction and my professor said this is a good future test like question if someone can post a solution and explain it would help me out a lot. Thank you.,"['induction', 'discrete-mathematics']"
1155142,Justification for cancelling variables in a rational expression,"Why are we allowed to cancel the x's in a expression such as $\dfrac{x^2(x-1)}{x^4}$? Don't we lose information about the function when we do, such as the fact that the function is undefined at $x = 0$? Specifically, concerning limits, why are we allowed to cancel variables in the rational expression and evaluate the limit as if it applied to the original function? How do we know for sure that each time the function that results from cancellation will yield the correct limit as it applies to the function before cancellation?",['functions']
1155150,Integrate using Cauchy Integral Theorem,"Evaluate the integral I=$\int_0^\infty \sin(x^3)dx$ I already know that the answer is $(1/2)\Gamma(4/3)$. So far I have considered the integral $\int_0^\infty e^{-x^3}dx=\Gamma(4/3)$ which I have already shown to be true, I'm not really sure how to proceed. I am told to consider the integral $\oint_C e^{-z^3}dz$ along the contour C, being simply the contour in the first quadrant. Unfortunately, this is from a math methods for physics course, basically the professor just rambles and writes out sparse solutions to everything on the board (including this one) but I don't really get it since I've never studied complex variables at all before and he never bothered to really go through it (it's not a prerequisite for the course).",['complex-analysis']
1155261,Books in the spirit of Problems and Theorems in Analysis by George Pólya and Gábor Szegő,"In the Preface of the first German Edition of the book Problems and Theorems in Analysis by George Pólya and Gábor Szegő, one can read [emphasis mine] : The chief aim of this book, which we trust is not unrealistic, is to 
  accustom advanced students of mathematics, through systematically 
  arranged problems in some important fields of analysis, to the ways 
  and means of independent thought and research . It is intended to serve
  the need for individual active study on the part of both the student
  and  the teacher. The book may be used by the student to extend his
  own  reading or lecture material, or he may work quite independently
  through  selected portions of the book in detail. The instructor may
  use it as an  aid in organizing tutorials or seminars. This book is no mere collection of problems. Its most important feature is the systematic arrangement of the material which aims to  stimulate the
  reader to independent work and to suggest to him useful  lines of
  thought .
  [...] The origin of the material is highly varied . We have made selections 
  from the classical body of knowledge of mathematics and also from 
  treatises of more recent date . We collected problems which had in part
  already been published in various periodicals and in part communicated
  to us verbally by their authors. We have adapted the material to our 
  purpose, completed, reformulated and substantially expanded it. In 
  addition we have published here for the first time in the form of
  problems  a number of our own original results. We thus hope to be
  able to offer something new even to the expert . To put it briefly, I think that the description of the key features that distinguish this book which is given in the preface is perfectly appropriate. With respect to these aspects, I regard this book as a sort of introduction to the methods, the ideas, and the results of mathematical research . It is actually the first book of this kind which I have ever come across, and I've really enjoyed going through it. So, the natural question that I pose is: $\color{#c00}{\text{Question:}}$ Are there other similar books (in analysis or also different topics )
    that are in the spirit of Pólya and Szegő's work? That is, are there
    other books that are actually introductions to mathematical research in the sense which is implied by the emphasized parts of the passage
    quoted above ?","['book-recommendation', 'big-list', 'soft-question', 'reference-request', 'real-analysis']"
1155285,Can someone clarify the definition of flux?,"I am confused by the concept of flux as used in vector calculus. Suppose I have a sphere. On the inside of this sphere is a spherically symmetric electric charge distribution. Now I want to find the flux through the surface of the sphere. Obviously, the electric field of that charge distribution is a vector field. So presumably I can apply a surface integral here to find the total flux through the surface. But this is what I am having trouble understanding.  What am I adding up with a surface integral in computing the flux through a surface? In other words, I have heard flux described as ""Field lines per unit area"" of the surface. How can we quantify the density of a vector field? I thought in a vector space like $\Bbb{R}^3$ there would be an infinite number of possible lines going through a patch of a surface. In that sense, then this definition  of flux as ""Field lines per unit area"" makes no sense. My Question: Can someone clarify the definition of flux in a rigorous enough way that some of the mathematical contradictions (ie infinite number of lines through surface) I named are clarified? EDIT: Tom Apostol mentions the term ""flux density vector field"" that essentially assigns a flux density vector to each point in space. Perhaps answerers could clarify what this is as I think it's likely related to my question.","['surface-integrals', 'multivariable-calculus', 'vector-fields', 'physics', 'surfaces']"
1155321,What is known about the numbers $M_p = \left\vert C(\mathbb{F}_p )\right\vert$?,"There is a question (2.4.c) marked ** (to denote ""extremely difficult/currently open problem"") in Silverman and Tate's Rational Points on Elliptic Curves which I found really interesting and wondered if anyone can shed any more light on the problem for me. Let $p\geq 5$ be a prime and let $C=C_p: y^2  = x^3 + 1$ be the cubic curve over the finite field $\mathbb{F}_p$. Let $M_p = \left\vert C(\mathbb{F}_p)\right\vert$ be the order of the group of rational points of $C$ (this includes the point at infinity). Looking at some small primes I proved that if $p\equiv 2 \pmod 3$ then $M_p = p+1$. The interesting case is when $p\equiv 1 \pmod 3$. I wrote a program which computes $M_p$ where $p\equiv 1\pmod 3$ is prime. We get the following sequence, where the $i$th term is the value of $M_p$ for the $i$th largest prime $p$ of the form $p\equiv 1\pmod 3$, and I have computed here for all $p\leq 1000$: $12, 12, 12, 36, 48, 36, 48, 84, 84, 84, 84, 84, 108, 108, 156, 156, 144, 156, 156, 192, 228, 228, 252, 252, 228, 300, 252, 252, 324, 336, 300, 372, 336, 372, 336, 372, 432, 372, 444, 432, 468, 468, 444, 444, 468, 516, 588, 588, 588, 624, 576, 588, 624, 588, 588, 684, 624, 624, 684, 732, 684, 684, 756, 804, 732, 768, 732, 756, 876, 876, 912, 804, 912, 876, 948, 972, 912, 948, 948, 1008, \dots$ It seems that however many terms you take their GCD is always $12$, and this doesn't change as far as $p\leq 3000$, so I have two questions: Can anyone prove that $M_p$ is always divisible by 12? Since 1992 when the book was published, has anyone found an expression for $M_p$? Any extra information about this sequence (or related topics/papers) is very welcome!","['finite-fields', 'finite-groups', 'elliptic-curves', 'number-theory']"
1155342,Irreducible closed subsets of a scheme corresponds to points,"I have posted an answer here for the case of an affine scheme, but I got stuck when I tried to generalize the argument to schemes. My thoughts Consider a point $p$ in the scheme, its closure in the scheme is an irreducible closed subset. This gives us one direction of the correspondence. Let $C$ be an irreducible closed subset of the scheme, pick an affine neighborhood $U$ that intersects nontrivially with $C$. Then the intersection is a closed subset of $U$ which decomposes into finite union of irreducible closed subsets of $U$ by Noetherian property of $U$. This is where I got stuck, and don't know how to proceed from here.","['commutative-algebra', 'algebraic-geometry', 'schemes']"
1155366,What is wrong with this approach evaluating $\int \sec \theta \ d \theta$?,"When integrating a function like $\sin^m \theta \cdot \cos^n \theta$ where where $m,n$ are nonnegative integers and $n$ is odd, a common approach is to peel off one power of $\cos \theta$ and then rewrite the resulting even power of $\cos \theta$ in terms of $\sin \theta$ using $\cos^2 \theta = 1 - \sin^2 \theta$. What remains is a polynomial in $\sin \theta$, multiplied by $\cos \theta$, so the substitution $u = \sin  \theta$ can be used. Since $\sec \theta =(\sin \theta)^0 (\cos \theta)^{-1}$ and $-1$ is odd, it seems like a good idea to try out the same approach here. \begin{align*}
\int \sec \theta \ d \theta 
&= \int \frac{\cos \theta}{\cos^2 \theta} \ d \theta && \text{Splitting off a power of $\cos \theta$}\\
&=\int \frac{ \cos \theta}{1-\sin^2 \theta} \ d \theta && \text{Eliminating the even power of $\cos \theta$} \\
&=\int \frac{1}{1-u^2}\ du &&  \text{Substituting $u=\sin \theta$}\\
&=\frac{1}{2} \int \left( \frac{1}{1+u} + \frac{1}{1-u} \right) \ du&& \text{Partial fractions}\\
&=\frac{1}{2} \left( \log |1+u| + \log |1-u| \right) && \\
&=\frac{1}{2} \log |1-u^2|  && \\
&=\frac{1}{2} \log| \cos^2 \theta| && \text{Restoring $u=\sin \theta$} \\
&=\frac{1}{2} \log (\cos^2 \theta) && \text{Eliminating redundant absolute signs}\\
&= \log \sqrt{ \cos^2 \theta}&& \\
&= \log|\cos \theta|. \\
\end{align*} I didn't bother adding the customary constant because the domain of $\sec \theta$ is disconnected and so you would actually need to add a piecewise constant function in order to specify the general antiderivative. My questions are: Question 1: Since $\frac{d}{d \theta} \log|\cos \theta| = - \tan \theta$, where does this calculation go wrong? And also: Question 2: Can this approach be salvaged?","['calculus', 'integration', 'indefinite-integrals']"
1155395,Inverse Laplace Transform of $\frac{s}{(s-a)^{3/2}}$,"Find the inverse laplace of: $\frac{s}{(s-a)^{3/2}}$ I tried working through this using partial fractions and convolution but I can't seem to get a requitible answer. How would I go about solving this? (by the way, we have yet to learn the integral definition of inverse laplace transforms, so we are expected not to use that.)","['laplace-transform', 'ordinary-differential-equations', 'inverse', 'contour-integration']"
1155398,Difference between second order derivative and curvature.,"I am studying space curves and I found the following equation for the curvature of $f(x)$ when $f(x)$ is a plane curve. $\displaystyle\kappa=\frac{|f''(x)|}{(1+(f'(x))^2)^\frac{3}{2}}$ I always thought of curvature as something similar to the second derivative of a function but for space curves, but this makes me think they are different concepts. Can someone help me understand?","['calculus', 'differential-geometry']"
1155407,Proving pointwise convergence of series of functions,"Show that
$1/(1+x)+2x/(1+x^{2})+\cdots+mx^{m-1}/(1+x^m)+\cdots=1/(1-x)$
where $ m= 2^{n−1}$ and $−1 < x < 1$, in the sense of pointwise convergence. I have tried to bound this by Wierestrass M-Test but haven't found one, also this test doesn't tell you about the limiting function. Another idea could be that if we can differentiate term by term on Right hand side and then check for the convergence of the differentiated series. If it converges then, the proof is done. But differentiating the RHS is getting clumsier because $m$ is a function of $n$ and I am not getting any conclusive result. Please suggest me if there are easier ways to do this or even if it can be done the way I suggested, then please give an outline of proof.","['sequences-and-series', 'integration', 'functions', 'real-analysis', 'derivatives']"
1155410,Number Theory : Infinitude Of Primes - a different proof,"I was doing some basic Number Theory problems and came across this problem : Show that the integer : $Q_{n} = n ! + 1$ , where $n$ is a positive integer, has a prime divisor greater than $n$ . Conclude that there are infinitely many primes. My Solution (partial) We know that as $Q_{n}$ is $\gt$ $1$ $\Rightarrow$ $Q_{n}$ has a prime divisor $p$ Let us assume , that $p$ $\le$ $n$ If $p \le n$ then $ p \mid n! $ So , in the equality ; $Q_{n} - n ! =  1$ , $p$ divides the LHS $\Rightarrow$ it also divides $1$ But that is not possible as no prime divides $1$ Hence , we have achieved a contradiction and there exists a prime divisor $>n$ My Question : I am not able to prove the infinitude of primes from this result , how can I do that ?","['prime-numbers', 'elementary-number-theory', 'proof-verification', 'number-theory']"
1155411,A consequence of the open mapping theorem,"We let $f$ be a bounded and surjective linear map from the Banach space $X$ onto the Banach space $Y$ and put
$$
r_0=\inf\{r: f(B^X(0,r)\supset B^Y(0,1)\}.
$$
Using the open mapping theorem, I have shown that $0<r_0<\infty$ (in fact $||f||\geq 1/r_0$) and that 
$$
f(B^X(0,r_0)\supset B^Y(0,1).
$$
 But I'm still wondering if
$$
f(\overline{B^X(0,r_0)}\supset \overline{B^Y(0,1)}
$$
holds or not?","['normed-spaces', 'functional-analysis', 'real-analysis', 'banach-spaces']"
1155472,Continuous functions in a metric space using the discrete metric,"Let X be any set and define $d: X \times X \to \Bbb R$ by
$d(x,y)= \begin{cases} 0 & x=y \\ 1 & x \neq y \end{cases}$. Classify all continuous functions $f: X \to X$ using the discrete metric on both sets. This is my first course in topology and I am struggling to make sense of how I would classify all of the continuous functions in this case. I can see that $f(x) \neq f(a)$, then there exists $\epsilon > 0$ which do not satisfy the definition of continuity, so is it just that every continuous function in this case must map all of the elements in the domain to exactly one value in the codomain? Or am I just completely misunderstanding the question? Thanks!","['general-topology', 'metric-spaces', 'continuity', 'functions']"
1155502,Automorphism group of the general affine group of the affine line over a finite field?,"I am wondering what the structure of the automorphism group of the general affine group of the affine line over a finite field looks like. I'll make that a bit more precise: If $k$ is a finite field, and $\operatorname{AGL}_1(k)$ its group of affine transformations, i.e. maps of the form
$$k\ \longrightarrow\ k:\ x\ \longmapsto\ ax+b,$$
with $a\in k^{\times}$ and $b\in k$, then what is the isomorphism type of $\operatorname{Aut}(\operatorname{AGL}_1(k))$? I know that $\operatorname{AGL}_1(k)\cong k\rtimes k^{\times}$, where the semi-direct product is given by the natural action of $k^{\times}$ on $k$ by multiplication. Also, as the center of $\operatorname{AGL}_1(k)$ is trivial, it is isomorphic to a subgroup of its isomorphism group. Any automorphism of $\operatorname{AGL}_1(k)$ restricts to a group automorphism of $k^{+}$, of which there are very many, unfortunately. What is a good way to approach this problem?","['finite-fields', 'linear-algebra', 'finite-groups', 'group-theory']"
1155545,Number Theory : Primes not in Twin Primes,"I was working through some basic number theory questions , when I came across : Show that there are infinitely many primes that are not one of the primes in a pair of twin primes How can I go about solving it ? I have absolutely no idea ...","['prime-numbers', 'elementary-number-theory', 'number-theory']"
1155561,Finding x and y?,"Can someone help me with this problem. I came out with the answer of 7.8 ounces needed. I used x =15% solution and y = 35% solution. I just don't know for sure if I did it right. The problem is: A 15% acid solution is to be mixed with a 35% acid solution to produce  12 ounces of a 22% acid solution. How much of the 15% acid solution is needed?
Let x = ____
Let y = ____
Thank you.","['algebra-precalculus', 'polynomials']"
1155563,"How many faces, edges and vertices are fixed when $S_4$ permutes the diagonals of a cube?","Consider the action of $S_4$ on a cube, where it acts by permuting the long diagonals. The conjugacy classes of $S_4$ are denoted by $id$, (12), (123), (1234) and (12)(34). I want to know the number of faces, vertices and edges each of the elements (12), (123), (1234) and (12)(34) fix. For example, (12) and (123) fix no face and (1234) fixes 2. I think (12)(34) also doesn't fix a face. Is that so? And can someone please enumerate the number of vertices and edges each of these elements fix. I'm having trouble imagining the permuation of the diagonals.","['group-theory', 'group-actions', 'combinatorics']"
1155567,Exercise 5.5.F. on Ravi Vakil's Notes related to associated points,"Let $A$ be a Noetherian ring and $M$ a finitely generated $A$ module. In Ravi Vakil's notes he first states that the associated points of $M$ satisfy the following: (A) The associated points of $M$ are precisely the generic points of irreducible components of the support of some element of $M$ on Spec $A$. I am working on the following exercise: Assuming (A) show that the associated points of $S^{-1}M$, where $S$ is a multiplicative subset of $A$, are precisely those associated points of $M$ that do not meet $S$. I was able to show that: given $m/s \in S^{-1}M$ there is a bijective correspondence as sets between Supp $m/s$ and the the points on Supp $m$ that do not meet $S$.
From here I think I can use (A) somehow to complete the exercise, but 
I am having difficulties with it. I would appreciate any assistance! Thank you very much! PS I asked this question also here working on this exercise. It might be helpful here, but I couldn't quite complete the exercise...","['commutative-algebra', 'affine-schemes', 'algebraic-geometry', 'schemes']"
1155571,How to show $t \mapsto E[Z|\mathscr{F}_t]$ is a.s. borel measurable.,"I'm going through Revuz and Yor and am stuck at a technicality. Suppose $Z$ is bounded and $A$ is bounded increasing continuous with $A_0 =0$. The goal of the problem is to show $E[ZA_\infty] = E\int_0^\infty E[Z|\mathscr{F}_t] dA_t$. I'm having trouble seeing why $t \longmapsto E[Z|\mathscr{F}_t]$ should be measurable for a fixed $\omega$, so that the integral on the right even makes sense. I see that $E[Z|\mathscr{F}_t]$ is a UI martingale. So for $t_n \uparrow t$ we have $E[Z|\mathscr{F}_{t_n}] \to E[Z|\mathscr{F}_{t_-}]$ and similarly for $t_n \downarrow t$ we have $E[Z | \mathscr{F}_{t_n}] \to E[Z|\mathscr{F}_{t_+}]$ a.s. and in $L^1$. I don't see how any of this will lead to measurability though. Edit:
Suppose the filtration is right continuous. Then the previous line looks like it means $E[Z|\mathscr{F}_t]$ is right continuous, but I don't think it does. The convergence occurs almost surely, and the almost sure set depends on $t$ and the sequence $t_n \downarrow t$. Since there are uncountably many $t$ and sequences $(t_n)$, I don't see how we can conclude right continuity.","['stochastic-processes', 'stochastic-analysis', 'probability-theory', 'stochastic-calculus', 'conditional-expectation']"
1155577,"Induced Lie Algebra Representation, Left invariant vector fields and more...","The following is an excerpt from a proof in John Lee's Introduction to Smooth Manifolds I am struggling to understand. I would appreciate if someone was able to help me with whatever it is I am missing! Theorem:
Let $G$ be a Lie group, let $\mathfrak{g}$ be its Lie algebra, and let $\text{Ad}:G\rightarrow GL(\mathfrak{g})$ be the adjoint representation of $G$. The induced Lie algebra representation $\text{Ad}_*:\mathfrak{g}\rightarrow \mathfrak{gl(g)}$ is given by $\text{Ad}_*=\text{ad}$. Here, $\text{ad}:\mathfrak{g}\rightarrow \mathfrak{gl}(g)$ is the adjoint representation of the Lie algebra $\mathfrak{g}$ defined by $\text{ad}(X):\mathfrak{g}\rightarrow \mathfrak{g}$,$\text{ad}(X)Y=[X,Y]$. Outline of beginning of proof: He shows earlier that $\text{Ad}:G\rightarrow GL(\mathfrak{g})$ is a Lie group representation, particularly, it is a Lie group homomorphism. Thus, the quantity $\text{Ad}_* X$ is well defined, being the unique element of $\mathfrak{gl(g)}$ that is $\text{Ad}$-related to $X$. He says (not only here, but uses this terminology a lot) that $\text{Ad}_* X$ is 'determined by its value at the identity'. What I think he means by this is because it's left invariant, its value at any point $g$ is found by computing $(dL_g)_e (\text{Ad}_* X)_e$?? Though I don't fully grasp why this is relevant. Moving on, he writes, because $t\mapsto \exp tX$ is a smooth curve in $G$ whose velocity vector at $t=0$ is $X_e$, we can compute the action of $\text{Ad}_* X$ on an element $Y\in \mathfrak{g}$ by $
\begin{align*}
(\text{Ad}_* X)Y&=\left(\frac{d}{dt}\bigg|_{t=0} \text{Ad}(\exp tx)\right)Y.
\end{align*}
$ He then continues the proof. I do not understand how he gets from the left hand side to the right and side in the above equation. This is what I have got so far, let $\gamma$ be the integral curve generated by $X$, $
\begin{align*}\frac{d}{dt}\bigg|_{t=0} \text{Ad}(\exp tX)&=\frac{d}{dt}\bigg|_{t=0}\text{Ad}(\gamma(t))\\
\\
&=(\text{Ad}\circ \gamma)^{\prime}(0)\\
\\
&=d\text{Ad}_e (\gamma^{\prime}(0))\\
\\
&=d\text{Ad}_e(X_e)
\end{align*}
$ This is where I get stuck. I don't see how the above quantity is $\text{Ad}_* X$. As I understand it, the formula for $\text{Ad}_* X$ is given by $\begin{align*}
\text{Ad}_* X=(d\text{Ad}_e X_e)^L,
\end{align*}
$
where the value at a point $g$ is $\begin{align*}
(\text{Ad}_* X)_g=(d\text{Ad}_e X_e)^L_g=(dL_g)_e\left(d\text{Ad}_e X_e\right)
\end{align*}
$ I can see some similar terms lying around but don't understand exactly what is going on here. Is my calculation correct? If it is, it seems he is only evaluating $\text{Ad}_* X$ at the identity? Is he only evaluating at the identity because it is 'determined by its value at the identity' and can somehow conclude later that because equality holds at the identity it holds everywhere? It's clear I am missing something crucial here so if anyone could help it would be much appreciated!","['lie-algebras', 'vector-fields', 'differential-geometry', 'manifolds', 'lie-groups']"
1155643,How to evaluate $ \int_{0}^{2015}e^{e^{e^{e^{2015x}}}}e^{e^{e^{2015x}}}e^{e^{2015x}}e^{2015x}dx $? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question I need to evaluate the following integral. $$\int_{0}^{2015}e^{e^{e^{e^{2015x}}}}e^{e^{e^{2015x}}}e^{e^{2015x}}e^{2015x}dx. $$ But I still have no idea how to do it. Can anyone please give me some help? Thanks a lot.","['definite-integrals', 'calculus', 'integration']"
1155648,Exercise about the Strong Law of Large Numbers,"This is Exercise 5.3.2 from Achim Klenke: »Probability Theory — A Comprehensive Course«. Exercise: Let $(X_n)_{n\in \mathbb{N}}$ be a sequence of independent identically distributed random variables with $\frac{1}{n}(X_1 + \cdots + X_n) \overset{n\rightarrow\infty}{\longrightarrow} Y$ almost surely for some random variable $Y$. Show that $X_1 \in \mathcal{L}^1(\mathbf{P})$ and $Y = \mathbf{E}[X_1]$ almost surely. Hint: First show that
  \begin{align*}
  \mathbf{P}\bigl[ |X_n| > n \text{ for infinitely many } n \bigr] = 0 \Longleftrightarrow X_1 \in \mathcal{L}^1 (\mathbf{P}).
\end{align*} My solution so far: We follow the hint... Assume that $\mathbf{P}\bigl[|X_n|>n \text{ for infinitely many } n\bigr] = 0$. Because $X_n$ is independent, the events $\{|X_n| > n\}$ must also be and it follows by the second Borel-Cantelli-Lemma, that
\begin{equation*}
\infty > \sum_{n=1}^\infty \mathbf{P}\bigl[|X_n| > n\bigr] = \sum_{n=1}^\infty \mathbf{P}\bigl[|X_1| > n\bigr] \, .
\end{equation*} We can add $\mathbf{P}\bigl[|X_1| > 0 \bigr]$ and the sum is still finite, of course, so $\infty > \sum_{n=0}^\infty \mathbf{P}\bigl[|X_1| > n\bigr] \geq \int |X_1| \, d\mathbf{P}$ and we conclude that $X_1 \in \mathcal{L}^1(\mathbf{P})$. Now assume that $X_1 \in \mathcal{L}^1(\mathbf{P})$, then \begin{equation*}
  \infty > \int |X_1| \, d\mathbf{P} \geq \sum_{n=1}^\infty \mathbf{P}[|X_1| > n] = \sum_{n=1}^\infty \mathbf{P}[|X_n| > n]
\end{equation*} and by the first Borel-Cantelli-Lemma we conclude that $\mathbf{P}\bigl[|X_n| > n \text{ for infinitely many }n\bigr] = 0$. But what shall I do now? Somehow we must end up using this theorem: Theorem 5.17 (Etemadi’s strong law of large numbers (1981)) Let $X_1, X_2, \ldots  \in \mathcal{L}^1 (\mathbf{P})$ be pairwise independent and identically distributed. Then $(X_n)_{n\in \mathbb{N}}$ fulfills the strong law of large numbers. Can somebody help me, please?","['probability-theory', 'law-of-large-numbers', 'probability-limit-theorems']"
1155658,Differentiable at a point and invertible implies inverse is differentiable?,"If $f:D\to\Bbb C$ is invertible and real (complex) differentiable at $c$ with $f'(c)\ne0$, it is easy to prove that if $f^{-1}$ is continuous at $f(c)$ and defined in a neighborhood of $f(c)$, then it is also real (complex) differentiable at $f(c)$ with derivative $1/f'(c)$: $$\lim_{x\to f(c)}\frac{f^{-1}(x)-f^{-1}(f(c))}{x-f(c)}=\lim_{x\to f(c)}\frac{f^{-1}(x)-c}{f(f^{-1}(x))-f(c)}=\frac1{f'(c)},$$ where the latter limit goes to $1/f'(c)$ because $f^{-1}(x)\to c$ as $x\to f(c)$ by the assumption of continuity. My question is: What additional assumptions are necessary to also deduce the extra assumptions on $f^{-1}$? In the real case, I know that it is sufficient that $f$ be continuous in a neighborhood of $c$, because then $f$ is monotone on an interval around $c$ and $f^{-1}$ is monotone and continuous in an interval around $f(c)$. In the complex case is this assumption sufficient?","['complex-analysis', 'inverse', 'derivatives', 'real-analysis']"
1155662,Topology for Divergent Sequence,"Let $a_n$ be a sequence of real numbers and define the ""Cesàro limit"" of $a_n$ to be $C \lim\limits_{n\rightarrow \infty}{a_n} = \lim\limits_{N\rightarrow\infty}{\frac{1}{N}} \sum\limits_{n=1}^{N}{a_n}$. I'd like to give $\mathbb{R}$ a topology that gives rise to this mode of convergence. However, if we take the closure of a set as the set of all limit points of that set (i.e. $Cl(S)$ is set of real numbers which are Cesàro limits of sequences of numbers in $S$), then it's clear to me that $Cl(S)$ is the (closure of) the convex hull of $S$. This ensures that this closure operator cannot come from a topology, since $Cl(S\cup T) \neq Cl(S)\cup Cl(T)$ whenever $Cl(S)\cup Cl(T)$ is not connected. My question is then this. Is there a generalization of ""topology"" that would allow such a thing? Is there anything useful that can be gained from this definition?","['general-topology', 'divergent-series', 'real-analysis']"
1155676,Why erf(a-b)+erf(a)+erf(a+b) is so close to 3erf(a)?,"I am approximating an empirical distribution function with a sum of three gaussians, and noticed that for erf function $erf(a-b)+erf(a)+erf(a+b)$ is numerically very close to $3erf(a)$ for applicable values of $a$ and $b$, $a>>b$. Close, but not quite the same, of course. Could you suggest an analytical explanation why these functions are so close?","['statistics', 'normal-distribution', 'approximation']"
1155693,Number of subgroups of an infinite group,Is there an infinite group with only a finite number of subgroups?,"['group-theory', 'abstract-algebra']"
1155714,"If $G/H$ is a group, then does $H$ have to to be normal?","If $H$ is normal then $G/H$ is a group. But is the converse true? That is, if $G/H$ is a group, does this mean that $H$ is normal? Or are there any counterexamples?","['group-theory', 'abstract-algebra']"
1155724,What happens when square root is performed in inequalities?,Simplify: $x^2 > 1$. My solution: Taking square root on both sides: $±x > ±1$ So my results are: $x > 1$ $x > -1$ $-x > 1$ $\implies$ $(-1 > x)$ $-x > -1$ $\implies$ $(1 > x) $ But I strongly feel this is wrong. What is wrong here? A step-by-step explanation will help me.,"['inequality', 'radicals', 'algebra-precalculus']"
1155728,Quantified Proposition,"I've been trying to translate the following sentences into quantified propositions by making sure I state all propositional functions that I use and any assumptions that I make. There is exactly one person who hates everyone. Let $H(x, y)$ be '$x$ hates $y$,'
where the domain of $x$ is all people in the world. Then, $\exists x \forall y\ (\ H(x,y)\ \land \forall z\ (z \neq x) \rightarrow \neg H(z,y)\ ) $. Can you see if I'm on the right track here?","['logic', 'discrete-mathematics', 'predicate-logic']"
1155757,Classes of measures that are closed under multiplication,"Consider the space $\mathcal M$ of all finite complex Borel measures on a segment with norm $\|\mu\|=\int d\,|\mu|$. Assume that a norm-closed linear subspace $\mathcal M_0$ of $\mathcal M$ has the following property: if $\mu\in\mathcal M_0$ and $f\in L^1(|\mu|)$, then $f\mu\in \mathcal M_0$. Can $\mathcal M_0$ be characterized as the family of all measures that vanish on a certain fixed collection of subsets of the segment? Example : the class of all measures $\mu$ such that $d\mu=f\,dx$ for some $f\in L^1$ coincides with the class of measures that vanish on all subsets of zero Lebesgue measure. Update : For any fixed measure $\mu$, one can define $\mathcal M_0$ as the class of all measures that are absolutely continuous wrt $\mu$. Then the class of subsets in question is the class of subsets of zero $\mu$-measure.","['measure-theory', 'functional-analysis', 'analysis']"
1155785,Outer measured induced by a point measure over an algebra of sets,"I'm helping a friend with problem 7 from section 3.3 of Vestrup's 'Theory of Measures and Integrals'. We got partway into the problem, but after a few hours of chatting about it we were still stumped. I think it's a fun problem (though not exactly research-grade), so I'm posting it here! First we fix a set $\Omega$, a point $\omega \in \Omega$, and an algebra of sets $A \subset 2^\Omega$ such that $\{\omega\}$ is an atom of $\sigma(A)$. Then define $\mu(M) = 1_M(\omega)$ for $M \in A$. We define the outer-measure associated with $\mu$ by letting $\mu^*(M) = \inf \{\sum{ \mu(F_i)}\ |\ F_i \in A,\ M \subset \cup F_i \} $, where $F_i$ are at most countable $A$-covers of M. The question is what is $\mu^*$? What are the measurable sets of $\mu^*$? Some work so far: If $\omega \in M$, then $\mu^*(M) = 1$. To see this, note that any $A$-cover of $M$ must cover $\omega$ at least once, and hence $\mu^*(M) \geq 1$. However $\mu(\Omega) = 1$ bounds things sharply from above. On the other hand, if $M$ is nonempty and $\omega \notin M$, it seems reasonable that $\mu^*(M) = 0$. However, we had a hard time ruling  out the possibility where $M$ does not admit any $\omega$-free $A$-covers. We think the condition on the generated $\sigma$-algebra of $A$ is key to understanding what happens, but don't know how to apply it. If we relax the condition that $\{\omega\} \in \Sigma(A)$, we can get a very trivial outer measure. Let $A = \{\Omega, \emptyset\}$, and fix an arbitrary $\omega$. Then $\mu^*(M) = 1$ for any non-empty $M$, and is zero otherwise. In this case $\sigma(A) = A$ and $\{\omega\}$ is nowhere to be found. On the other hand, let $\Omega = [0,1]$, fix $\omega = 0$, and let $A$ by the algebra generated by the family of sets $F_i = [1, 1/i]$. In this case, $\{0\}$ is not an atom of $A$, however it does belong to $\sigma(A)$. But now, we get things like $\mu^*((0,1]) = 1$ and in general, $\inf{M} = 0$ entails $\mu^*(M) = 1$, since all $A$-covers of $M$ must include $0$. So, barring any mistakes, it seems like it may not be so easy to characterize $\mu^*$ ! [Edit:] It looks like I did make a mistake. Namely, in the example I gave, $A$ has the sets $G_i = (1/i, 1]$, being the complements of the $F_i$. But $G_i$ eventually covers any individual point in $(0,1]$, without ever including $0$ so it turns out $\mu*((0,1]) = 0$, as expected. I do not yet know how to show if  $0 \in \sigma(A)$ is necessary or sufficient for this. Is there a deeper story here?","['measure-theory', 'real-analysis']"
1155791,"Properties of the multiplication operator, self-ajointness","Let $(\Omega, \Sigma,\mu)$ a measurable space, $f:\Omega\to \mathbb{R}$ $\mu$-measurable. a.My first question: What does ""f $\mu$-measurable"" mean?I only know, what it means that ""f is measurable"" but including the measure ""$\mu$"", $\mu$-measurability? Now consider the operator $$M_f:D(M_f)=\{u\in L^2(\Omega); f\cdot u\in L^2(\Omega)\}\subseteq L^2(\Omega)\to L^2(\Omega),\; u\mapsto f\cdot u$$ $D(M_f)$ means the domain of the multiplicationoperator $M_f$. $M_f$ is always linear and if $f\in L^{\infty}(\Omega)$, $M_f$ is bounded. Now, let $f:\Omega\to \mathbb{R}$ be only measurable. I want to know, why $M_f$ is self-adjoint. Therefore I have to check the following properties: $$1. M_f\; \text{ is densely defined}$$
$$2. M_f\; \text{ is symmetric}$$
$$3. Im(M_f+iId)=L^2(\Omega);\; Im(M_f-iId)=L^2(\Omega)\; \text{(I think, it is enough to prove $Im(M_f+iId)=L^2(\Omega))$}$$
The second property is no problem. I stuck with 1. and 3. We had this proof in lecture and we said if we proved 1.:It is $\Omega=\bigcup_{n\in\mathbb{N}}\Omega_n$ with $\Omega_n=\{x\in\Omega; |f(x)|\le n\}$ and $\{u\in L^2(\Omega);\exists  n\in\mathbb{N}:$ such that $u=0$ almost everywhere in $\Omega\setminus\Omega_n$ $\}\subseteq D(M_f)$. And the set $\{u\in L^2(\Omega);\exists  n\in\mathbb{N}:$ such that $u=0$ almost everywhere in $\Omega\setminus\Omega_n$ $\}$ is dense in $L^2(\Omega)$. b. I don't understand this. Why is the set $\{u\in L^2(\Omega);\exists  n\in\mathbb{N}:$ such that $u=0$ almost everywhere in $\Omega\setminus\Omega_n$ $\}$ dense in $L^2(\Omega)$? And the proof of the 3. property we had in lecture: We only want to prove $Im(M_f+iId)=L^2(\Omega)$ (in other words: $M_f+iId$ is surjective). Let $g\in L^2(\Omega)$. It is $u:=\frac{g}{f+i}\in L^2(\Omega)$ (auxiliary calculation: $(M_f+iId)(u)=g\iff fu+iu=g\iff u=\frac{g}{f+i}$) and $f\cdot u\in L^2(\Omega)$. Therefore it is $u\in D(M_f)$ and $M_fu+iu=g$, so it is $g\in Im(M_f+iId)$. My questions: c. Why is  $u:=\frac{g}{f+i}\in L^2(\Omega)$ and $f\cdot u\in L^2(\Omega)$? Any help would be appreciated. Regards","['operator-theory', 'functional-analysis']"
1155794,Probability of intersection of line segments,A pair of points is selected at random inside a unit circle and a line segment is drawn joining the two. Another pair is selected and a second line segment is drawn. Find probability that the two segments don't intersect. I don't have a clue where to start with this one. I assumed the first pair but I'm not able to come up with the condition for the two segments to not intersect. Please help me out. Thank you. Here is an example of a possible position of the segments -,"['geometry', 'calculus', 'probability', 'geometric-probability']"
1155797,How to show this equation have exactly single solution?,"Consider $a=1,\:b\in \mathbb{R}$. Show that there is single solution for the equation:$$x-a\sin x\:=\:b$$ So far I defined funtion $f\left(x\right)=x-a\sin \left(x\right)-b\:=\:x-\sin \left(x\right)-b$ and learned that $\lim _{x\to \infty }\left(f\left(x\right)\right)\:=\:\infty \:,\:\lim _{x\to -\infty }\left(f\left(x\right)\right)=-\infty \:$. Now, the derivative of this function not always increasing because in $x_0=0$, $f'\left(x\right)\:=\:0$, so I can't use the Intermediate value theorem .. Any idea? tnx in advance!","['calculus', 'derivatives', 'limits']"
1155828,"Help with a trigonometric proof, please?","Hexagon $ABCDEF$ is inscribed in the circle of radius $R$ . $AB=CD=EF=R$ . Points $I$ , $J$ , $K$ are the midpoints of segments $\overline{BC}$ , $\overline{DE}$ , $\overline{FA}$ respectively. Then prove $\Delta IJK$ is equilateral. I know this proof is really easy using complex numbers and rotation and stuff, but I'm trying to do this using trigonometry. The method is to find a symmetric expression for one of the sides of $\Delta IJK$ and since it is symmetric, we can claim that the triangle is equilateral. Note that $\angle IOC = \angle IOB = u$ , $\angle JOD = \angle JOE = v$ , $\angle KOA = \angle KOF = w$ . I need to find $OI$ and $OJ$ . Then using cosine rule, in $\Delta OIJ$ I'll find $IJ$ and then simplify it until it becomes symmetrical in $u$ , $v$ and $w$ and $R$ . Then we can say that the triangle is equilateral. I got $OI=R\cos(u)$ and $OJ = R\cos(v)$ . Also, in $\Delta OIJ$ , $\angle IOJ = 60^{\circ} + u + v$ . So using cosine rule, $IJ^{2} = R^{2}\cos^{2}(u) + R^{2}\cos^{2}(v) - 2(R\cos(u))(R\cos(v))(\cos(60^{\circ}+u+v))$ ahead of which I don't know what to do. I need to make this expression symmetrical in $u$ , $v$ and $w$ and $R$ , of course. Two helpful points are that $u+v+w=90^{\circ}$ and without loss of generality, we can take the radius of the circle to be one (to simplify calculations). Could someone please finish this for me? Help would be appreciated. Thanks! :)","['trigonometry', 'proof-writing']"
1155857,Why is $\lim_{x \to +\infty}\log x = +\infty$ if $\mathrm{d}/\mathrm{d}x (\log x) = 1/x$?,"Why is $\lim_{x \to +\infty} \log(x) = +\infty$? I would have expected that the value of this limit is some fixed number, since $$\frac{\mathrm d}{\mathrm dx} \log x = \frac1x$$ and $$\lim\limits_{x \to +\infty} \frac1x = 0,$$
so the tangent of $\log(x)$ approaches $0$ if $x$ is large enough. How do I prove that the limit of $\log x$ is indeed infinity?","['logarithms', 'calculus', 'limits']"
1155877,Consistency Conditions of the Kolmogorov Extension Theorem,"Kolmogorov's extension theorem allows for the construction of a variety of measures on infinite-dimensional spaces, and its conditions are supposedly ""trivially satisfied by any stochastic process"". However, I'm a little confused about the extent of generality of these conditions. Following wikipedia's notation, let $\nu_{t_1 \dots t_k}$ be a probability measure on $\mathbb R^k$. The first consistency condition requires that for every $k \in \mathbb N$ and for all permutations $\pi$ of $\{1 \dots k\}$ and measurable sets $F_i \in \mathbb R$, 
$$
\nu_{t_{\pi(1)}\dots t_{\pi(k)}}(F_{\pi(1)} \times \dots \times F_{\pi(k)}) = \nu_{t_1\dots t_k}(F_1 \times \dots \times F_k)
$$ Doesn't this condition imply that all finite-dimensional marginals of the process are exchangeable? If so, then this condition cannot be said to hold for any random process. Am I missing something? Thank you very much!","['probability-theory', 'stochastic-processes', 'measure-theory']"
1155880,Double Integral related to Gaussian Integral.,"We know that $\int_{-\infty}^{\infty} e^{-x^2}dx=\sqrt{\pi}.$ Using this , how can you evaluate $\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-(x^2+y^2+xy)}dxdy= ?$ Are there any standard tricks for integrals which are related to the gaussian integral ?","['multivariable-calculus', 'improper-integrals', 'integration', 'definite-integrals', 'gaussian-integral']"
1155888,"Theorem $($Transfinite Induction and Construction$)$ (James Dugundji - 5.1, Page - 40)","Let $W$ be a well ordered set, and let $Q \subset W$.  If $[ W(x) \subset Q] \Rightarrow [ x \in Q]$ for each $x \in W$, then $Q = W$. For each $a \in W$, the set $W(a) = \{x \in W; (x\prec a) \land (x\ne a)\}$ is the initial interval determined by a. The proof given is Dugundji's book is the following. Proof: The first element, $0$, of $W$ is in  $Q$, since $\emptyset = W(0) \subset Q$,
  and evidently there can be no first among the elements not in $Q$. Let $0$ be the first element of $W$, I can easily show that $0 \in Q$. Further I am not understanding what he wants to prove. Please help me. Thank you","['transfinite-induction', 'ordinals', 'elementary-set-theory']"
1155899,Minimal polynomial of an $n\times n$ matrix $A$ is $x^3+2x+2$; then $3$ divides $n$,Let $A$ be an $n × n$ matrix with rational entries such that the minimal polynomial of $A$ is $x^3 + 2x+2$. Prove that $3$ divides $n$. I think there is no rational root of this polynomial but how I use this. Please give me hint.,"['matrices', 'linear-algebra', 'minimal-polynomials']"
1155915,What is the poinacre dual of the projectivization of a line bundle inside the projectivization of the sum of two line bundles?,"Let $S:= \mathbb{CP}^1 \times \mathbb{CP}^1$. Let $TS \approx L_1 \oplus L_2$, 
where $L_1$ and $L_2$ are the pullback of $T\mathbb{CP}^1$ wrt to the respective projection maps. Note that $\mathbb{P}(L_1)$ is a submanifold of $\mathbb{P}(L_1 \oplus L_2)$. Note that the cohomology of $\mathbb{P}(L_1 \oplus L_2)$ is generated by $a_1$, $a_2$ and $\lambda$, where $a_i$ and $\lambda$ are the fist chern classes of the dual of the tautological line bundles over $\mathbb{CP}^1$ and $\mathbb{P}(L_1 \oplus L_2)$ respectively. My question is the following: what is the Poincare Dual of the homology class 
$[\mathbb{P}(L_1)]$ inside $\mathbb{P}(L_1 \oplus L_2)$? It has to be a linear combination of $a_1$, $a_2$ and $\lambda$. Note that $L_1$ and $L_2$ are both bundles over $\mathbb{CP}^1 \times \mathbb{CP}^1$, i.e. $L_i:= \pi_i^* T\mathbb{CP}^1 \rightarrow \mathbb{CP}^1 \times \mathbb{CP}^1$.","['characteristic-classes', 'vector-bundles', 'complex-geometry', 'homology-cohomology', 'algebraic-geometry']"
1155916,Spot mistake in finding $\lim \limits_{x\to1}\left(\frac x {x-1} - \frac1 {\log(x)} \right)$,"This is the limit I'm trying to solve: $\lim \limits_{x\to1}\left(\frac
x {x-1} - \frac1 {\log(x)}
\right)$ I thought: let's define $x=k+1$, so that $k\to0$ as $x\to1$. Then it becomes:
$$\lim \limits_{k\to0}\left(\frac
{k+1} {k} - \frac1 {\log(k+1)}
\right)$$
and then,
$$\lim \limits_{k\to0}\left(\frac
{k+1} {k} - \frac1 {\frac {\log(k+1)\times k}k}
\right)=\lim \limits_{k\to0}\left(\frac
{k+1} {k} - \frac1 {k}
\right).$$
Which results in $\frac k k$ , that should be 1, but wolfram says it's $\frac 1 2$... Did I do something illegal?","['fake-proofs', 'calculus', 'limits']"
1155986,Why use homogeneous coordinates?,"I am having trouble understand the use of homogeneous coordinates for when describing transformations in 3D space. From what I have seen, the only difference between a transformation matrix in standard coordinates, and homogeneous coordinates, is that a fourth row is added, of [0 0 0 1]. Then, when transforming a point, an additional row of [1] is added to the point vector. What is the point of this additional 1? And is it ever a different number? From what I have read, homogeneous coordinates enable perspective transformations to be achieved using matrices and linear algebra, but I don't see the connection....","['matrices', 'linear-algebra']"
1155994,Adding distances/weights to absorbing markov chain,"in presence of an absorbing state, I want to calculate mean/expected 'distance' from any state to that absorbing state. What I mean by distance is that I want to give different lengths from one particular state to another. For example, below i wrote a simple coin toss, 2 levels deep. One player is in Start S, with a coin toss he goes A or B. If he reaches A, with %100 probability he reaches End after. But if he reaches B, he either reaches End or he turns back to Start with equal probability. \begin{align*}
\begin{pmatrix}
 & S & A & B & E \\
 S & 0 & \frac{1}{2} & \frac{1}{2} & 0\\
 A & 0 & 0 & 0 & 1  \\
 B & \frac{1}{2} & 0 & 0 & \frac{1}{2} \\
 E & 0 & 0 & 0 & 1
\end{pmatrix}
\end{align*} Later I found total transition matrix between transient states \begin{align*}
    (I-Q)^{-1} = \left(\begin{array}{rr}
\frac{4}{3} & \frac{2}{3} & \frac{2}{3} \\
0 & 1 & 0 \\
\frac{2}{3} & \frac{1}{3} & \frac{4}{3}
\end{array}\right)
  \end{align*} So if I sum first row, I find 8/3 , that is expected number of steps from Start to End Now where I am stuck is, probabilities stay same but if going from one state to another  differs, I dont know how to manipulate these matrices to take distances. For example, distance from A-> E may be 1 km, but B -> E may be 5 kms. S-> A may be 20 kms, rest can be 1 km. How can I manipulate these matrices to get this information. Thanks in advance","['markov-chains', 'probability']"
1156043,"If $A$ is a square matrix that is linearly independent, is $AA$?","I'm just not sure how to start this problem from Linear Algebra Done Wrong. The problem is to prove that if the columns of $A$, square matrix, are linearly independent, then the columns of $A^2$ = $AA$ are also linearly independent. I'm mostly just not sure how to start this proof.","['matrices', 'linear-algebra']"
1156088,Probability to pick at least one pair of socks,"There are 10 pairs of socks. What is the probability that in 4 socks chosen at random there is at least one pair. My try: Let $A$ be an event of choosing exactly one pair of socks among 4 socks and $B$ be an event of choosing exactly two pairs, $$P(A)=\frac{\binom{10}{1}\left(1-\frac{\binom{9}{1}}{\binom{18}{2}}\right)}{\binom{20}{4}}$$ and $$P(B)=\frac{\binom{10}{2}}{\binom{20}{4}}$$ So the total probability is $P(A)+P(B)$. But i know that some mistake is there in my solution... can any one help?","['statistics', 'probability', 'combinatorics']"
1156118,Let $H \leq G$. If $G = H H^x$ then $G=H$.,"Let $H \leq G$. If $G = H H^x$ then $G=H$. According to the source, it should solve with elementary knowledge of group theory, but my tries have no result! Any help would be appreciated. Thanks in advance.","['group-theory', 'abstract-algebra']"
1156130,Abelian groups and $\mathbb{Z}$-modules,We know that any Abelian group is a $\mathbb{Z}$-module. Is the converse true?,"['modules', 'group-theory', 'abstract-algebra']"
1156152,How to put this into set notation?,"if you could please help me put this sentence into set notation, examine my (flawed?)attempts, and tell me where I went wrong with them? So we call a function $f\colon \mathbb{N} \to \mathbb{N}$ zero almost everywhere iff $f(n)=0$ for all except a finite number of arguments. My question is ""how do we represent the the set of functions that are zero almost everywhere?"" Here is my attempt: $E=\{f\colon \mathbb{N} \to \mathbb{N}\mid f(n)=0\}$ Thank you!","['logic', 'elementary-set-theory', 'functions', 'proof-verification', 'predicate-logic']"
1156206,Proving not equicontinuity in $\Bbb R$ but equicontinuity in any other closed subset of $\Bbb R$,"Let $F = {f_{n} | n ∈\Bbb N }$ be an infinite collection of functions $f_{n}(x)=e^{−n(x−n)^2} , x ∈ \Bbb R$. Prove that $F$ is not equicontinuous on $\Bbb R$ but equicontinuous on $[−a, a]$ for any $a > 0$. I am trying a modified proof (Initially I posted a proof but didn't reach any conclusions): First proving not equicontinuous on $\Bbb R$, $f_{n}(x)=e^{−n(x−n)^2}$ Let $\epsilon =1/2$. let $x=n$ Then, for $|n-y|<\delta$ , we have $|f_{n}(n)-f_{n}(y)|$=$|1-e^{-n(y-n)^2}|\leq 1$.
For $n$ large enough, $|f_{n}(n)-f_{n}(y)|=1>\epsilon$ . So $f_{n}$ is not equicontinuous on $\Bbb R$. Now proving equicontinuous on $[-a,a], a>0$, Here lets use the fact that on a compact set, if $f_{n}$ is continuous and if $f_{n}$ converges uniformly on the compact set, then it is equicontinuous on the compact set. So lets prove that $f_{n}$ converges uniformly on $[-a,a]$. To do this lets first look at the following: Given an interval $[-a,a]$ and  any $\epsilon>0$.
The pointwise limit of $f_{n}$ is $0$. Now, what I need to show for uniform convergence is the following: $$|f_{n}(x)-0|<\epsilon \implies |e^{-n(x-n)^2}|<\epsilon \implies |{n(x-n)^2}|<ln (\epsilon) $$ $$\implies n-\sqrt(ln \epsilon/n)\leq x \leq n+\sqrt(ln \epsilon/n)$$ So for any $a>0$, I can always choose $n$ such that the above condition is satisfied, i.e., $n>a$. hence, $F_{n}$ is equicontinuous on $[-a,a]$ Please check if it is correct. Else suggest a suitable proof.","['functions', 'sequences-and-series', 'proof-writing', 'real-analysis']"
1156237,Existence and uniqueness of strong solution of stochastic differential equation.,"I am currently going through the proof of the existence of a solution of the SDE \begin{align}
dX_t = bdt + \sigma dB_t
\end{align} where $B_t$ is a Brownian motion with respect to a filtration $\{\mathcal{F}_t\}_{t\in[0,T]}$.  We assume the following conditions hold for $t \in [0,T]$: 1) $b(t,X_t) \text{ and } \sigma(t,X_t) \text{ are } \mathcal{B}\times\mathcal{F} \text{-measurable}$ and $\mathcal{F}_t$-adapted. 2) $|b(t,x)| \leq L(1 + |x|)$ and $\sigma(t,x) \leq L(1 + |x|)$. 3) $|b(t,x) - b(t,y)| \leq L|x - y|$ and $|\sigma(t,x) - \sigma(t,y)| \leq L|x - y|$. 4) $X_0$ is $\mathcal{F}_0$-measurable, and $E[|X_0|^2] < \infty$. Now, every proof I have seen uses the Picard iterations \begin{align}
\begin{cases}
X_t^0 &= X_0. \\
X_t^{n+1} &= X_0 + \int_0^tb(s,X_s^n)ds + \int_0^t \sigma(s,X_s^n)dB_s.
\end{cases}
\end{align} There are several things I am struggling to understand in the proof, and I am happy with any help/hints I can get. First we need to show that the iterates $X_t^n$ are elements of $L_{\text{ad}}^2([0,T]\times \Omega)$, that is, that properties a), b), and c) are satisfied: a) $X_t^n$ is continuous in $t$ b) $X_t^n$ is $\mathcal{B}\times\mathcal{F}$ -measurable and $\mathcal{F}_t$-adapted c) $E\Big[ \int_0^t |X_s^n|^2 ds \Big] < \infty$ We proceed by induction, and clearly a) - c) are satisfied for $n=0$, due to condition 4). Now, we assume that a) - c) hold for $X_t^n$. By condition 2), the Cauchy-Schwarz(C-S) inequality as well as $(x_1+x_2+ \cdots+x_n)^2 \leq n(x_1^2 + x_2^2 + \cdots + x_n^2)$ it is easy to see that \begin{align*}
E\bigg[ \int_0^t \big| \sigma(s,X_s^{n})\big|^2 ds \bigg] &\leq 2 L^2 \int_0^t 1 + E\big[ |X_s^{n}|^2 \big] ds < \infty \\
\int_0^t \big| b(s,X_s^{n}) \big| ds & \leq L\sqrt{2t} \sqrt{\int_0^t 1 + |X_s^{n-1}|^2 ds} < \infty
\end{align*}
 where the last inequality holds almost surely. Hence the above integrals exist with probability 1. Now, the argument is that this implies that properties a) and b) are satisfied. I fail to see why. Thoughts: $T_1$ - If $\sigma(t,X_t^n)$ is measurable and adapted, we have that, since the expected integral of $\sigma(t,X_t^n)^2$ is finite, that the Ito integral is $t$-continuous a.s. (a property of processes satisfying a) - c) ). $T_2$ - Once a) and b) is settled, c) is found by using condition 2), $(x_1+x_2+ \cdots+x_n)^2 \leq n(x_1^2 + x_2^2 + \cdots + x_n^2)$ and C-S. Questions: $Q_1$ - We know from condition $1$) that for instance $b(t,X_t)$ is jointly measurable and adapted. Is this different from $b(t,X_t^n)$ satisfying these properties? I really don't see how to prove that $X_t^{n+1}$ is jointly measurable and adapted.","['stochastic-calculus', 'ordinary-differential-equations', 'stochastic-analysis']"
1156266,Good book to study ODEs through geometric ideas,"When studying a subject, geometric intuition is important for me. The algebra books I know do not convey such intuition. Please recommend books on ordinary differential equations with an emphasis on geometric intuition.","['ordinary-differential-equations', 'book-recommendation', 'reference-request']"
1156282,defining the canonical divisor,"I am just starting to learn some basic algebraic geometry, but I am very confused with some definitions. So I hope I am not asking something that is completely trivial. Suppose $X$ is a normal variety. I understand (I think!) that the canonical sheaf is simply defined to be the top wedge of the sheaf of differentials. My question is - can the canonical divisor (as a Weil divisor) be defined in general? Since the variety is normal, as I understand, it is enough to look at the regular part, $X_0 \subset X$. On the regular part, the sheaf is invertible and is the sheaf of sections of the canonical line bundle. But in order for this to induce a Weil divisor, does it not need to have a meromorphic section? So how can one be sure (without any assumptions that $X$ is projective) that there does exist a meromorphic section of $K_{X_0}$. Also, there are many examples of even smooth varieties with no irreducible sub-varieties. So in particular there will be no non-trivial Weil divisor. In such cases, the canonical divisor would be forced to be trivial. Are there any example of  such varieties whose canonical bundle is still non-trivial as a line bundle?","['algebraic-geometry', 'complex-geometry']"
1156332,What is the flaw in this proof that uses induction?,"Find the flaw in the following proof that $a^n = 1$ for all non-negative integers $n$ , whenever $a$ is a non-zero real number. Proof: $P(n)\!:\ \forall k \leq n,\ a^n = 1$ where k is non-negative integer valued variable. Base case: $P(0)$ is equivalent to $a^0 = 1$ , which is true. Inductive step: By induction hypothesis, $a^k = 1\ \forall k \in \mathbb N\ \mbox{s.t.}\ k \leq n$ But then $$a^{n + 1} = \frac{a^n\cdot a^n}{a^{n-1}} = \frac{1\cdot1}1 = 1$$ which implies that $P(n+1)$ holds!","['calculus', 'discrete-mathematics']"
1156356,Why is $\lim_{n\to\infty} n(e - (1+\frac{1}{n})^n) = \frac{e}{2}$,I'm having trouble understanding why $$\lim_{n\to\infty} n(e - (1+\tfrac{1}{n})^n) = \frac{e}{2}$$ Can someone offer me a proof for this?,"['sequences-and-series', 'limits']"
