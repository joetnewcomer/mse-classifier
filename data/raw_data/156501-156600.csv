question_id,title,body,tags
2660598,Determinant derivative in index notation,"I'm new to index notation and i'm trying to prove the identity $$\frac{d}{dt}\det(A(t))=\det(A)\operatorname{tr} \left(A^{-1}\frac{dA}{dt}\right) $$ for the special case when $A$ is an invertible second order tensor, using just index notation in the following fashion:
\begin{align}
\frac{d}{dt}\det(A(t)) & =\frac{d}{dt}(\varepsilon_{ijk}A_{i1}A_{j2}A_{k3}) \\[10pt] & =\varepsilon_{ijk} \left(\frac{d}{dt}(A_{i1})A_{j2}A_{k3}+\frac{d}{dt}(A_{j2})A_{i1}A_{k3}+\frac{d}{dt}(A_{k3})A_{i1}A_{j2})\right) \\[10pt]
& =\varepsilon_{ijk}A_{r1}A_{j2}A_{k3} \left( A^{-1}_{1r}\frac{A_{i1}}{dt} + A^{-1}_{2r} \frac{A_{j2}}{dt}+A^{-1}_{3r}\frac{A_{k3}}{dt} \right)
\end{align}
where $\varepsilon$ is the permutation symbol. This is as far as I can get and it frustrates me because if I just switch the index ""$r$"" to ""$i$"" then the proof is done. Have I missed something obvious or made some error? I don't know how to proceed from here. Best regards Bengt","['derivatives', 'tensors', 'index-notation']"
2660606,Is there a classifying topos for schemes?,"Is there a topos $\mathcal E$ such that, for any sober topological space $X$, the geometric morphisms
$$\mathrm{Sh}\left(\mathcal O\left(X\right)\right)\rightarrow \mathcal E$$
are in correspondance with the schemes whose underlying topological space is $X$?","['schemes', 'topos-theory', 'algebraic-geometry']"
2660622,Circuit current from series resistor and inductor + pulse voltage using Laplace method,"A series $RL$ circuit experiences a pulse of voltage, $V$, occurring during the interval $t_0 \lt t \lt t_1$.  Determine the circuit current $i(t)$. First I've broken up the pulse into $\pm V u(t - t_j), \ j=0,1$ and will add the two solutions $i_j(t), \ j=0,1$ when done, via superposition. So the differential equation modeling the system is: $\pm V u(t - t_j) = R i_j(t) + L \dfrac{d i_j(t)}{dt}$. Taking the Laplace transform and rearranging I get: $I_j(s) = \dfrac{e^{-t_j s}}{s}\dfrac{ \pm \dfrac{V}{L}}{\dfrac{R}{L} + s}$ and taking the inverse transform I get: $\pm \dfrac{V}{L} \int\limits_0^t u(\tau - t_j) e^{-\frac{R}{L}(t - \tau)} d\tau$. My question is how do I evaluate this integral, or am I doing it wrong?","['laplace-transform', 'calculus', 'integration', 'definite-integrals', 'ordinary-differential-equations']"
2660652,Plants and probabilities,"I am trying to work through some probability and statistics questions. We recently covered joint probability distributions but it is still quite fuzzy to me. I am not sure if this question (at least all of it) uses JPD's but here goes. There are three varieties of a particular type of plant: variety A, variety B and a hybrid variety. 50% of the plants are of variety A, 20% of variety B and the remainder are hybrids. (a) If a random sample of 10 plants is collected, nd the probability that the sample
contains: (i) Exactly three plants of variety A; (ii) Exactly two plants of variety B; (iii) Exactly three plants of variety A and two plants of variety B. In the sample, are the numbers of plants of each variety independent of each
other? Justify your answer clearly. (b) Suppose now that the sample of 10 plants contains exactly four plants of variety
A. In this case, what is the distribution of the number of variety B plants in
the sample? For part a), I think that for i and ii, it is enough to use Binomial but  I feel like there is a catch and that I will have to change the parameters for the 2 or 3 picks (namely, taking away one of the plants from the sample size and changing the probability accordingly). In iii I have to use Bayes from what I understand For part b), I am not quite sure where to begin.","['statistics', 'probability']"
2660714,Proof every convex function is continuous (Problem 10 Convex Functions Spivak),"I am working on exercise 10 of the appendix between chapters 11 and 12 of Spivak's Calculus. The problem is to show that a convex function must be continuous. 
I would like to check my proof as it is different from the ones I have found so far. Let $f$ be a function that is convex in $ (a,b)$. 
Let us assume that $f$ is not continuous in the point $a$. By the definition of convexity, we have: 
$ \dfrac{f(x)-f(a)}{x-a}<\dfrac{f(b)-f(a)}{b-a}$ To remove the inequality let $ \dfrac{f(x)-f(a)}{x-a} +h(x) = \dfrac{f(b)-f(a)}{b-a} ~(1)$, where $h(b)=0$ and $h(a)=\dfrac{f(b)-f(a)}{b-a}$ Now let's rearrange equation 1:
$ f(x)-f(a) = (x-a)\left(\dfrac{f(b)-f(a)}{b-a} - h(x)\right)$ Taking $lim_{x\to a^+}$ on both sides: $ lim_{x\to a^+} (f(x)-f(a)) = lim_{x\to a^+} (x-a)\left(\dfrac{f(b)-f(a)}{b-a} - h(x)\right)= 0$ So  $~lim_{x\to a^+} f(x)= f(a)$ Thus $f(x)$ is right continuous on $a$ I can use a similar argument to prove that $f(x)$ is left continuous on $b$ Since $f$ is convex in $(a,b)$, it is also convex in $(a+h,b)$ with $h< b-a$. And by letting $h \to b-a$, I prove right continuity over the whole interval. Similarly, as $f$ in convex in $(a,b)$, it is also convex in $(a,b-k)$ with $k > b-a$. And by letting $k \to b-a$, the whole interval is left continuous. As any $x_0 \in (a,b)$ can be uniquely expressed as $x_0= a+h = b-k$ and $f$ is right continuous for $a+h$ and left continuous for $b-k$ then $f$ is continuous in $x_0 \in (a,b)$ While writing the question, I have cleaned the logic from what I had initially drafted, so I am more confident about it. Still I am not sure if this logic is correct, as it is longer than any other answer I have found.","['real-analysis', 'convex-analysis', 'proof-verification']"
2660742,How many ways are there to get a sum of $25$ when $10$ distinct dice are rolled?,"I have come across the following problem and have given it a good attempt below. I am wondering if I have proceeded correctly, and if not if someone could show me the correct answer or maybe a more efficient solution, thanks! How many ways are there to get a sum of $25$ when $10$ distinct dice are rolled? Each die can be a number from $1$ to $6$. With $10$ dice, our generating function becomes: $$g(x) = (x+x^2+x^3+x^4+x^5+x^6)^{10}$$ We want to find the coefficient of $x^{25}$. Observe that the expression inside the brackets is a finite geometric series with $a=x, r=x, n=6$. Thus we have $$(x+x^2+x^3+x^4+x^5+x^6)^{10}$$
$$=\left(\frac{x(1-x^6)}{(1-x)}\right)^{10}$$
$$=x^{10}(1-x^6)^{10}(1-x)^{-10}$$ Then, $$(1-x^6)^{10}(1-x)^{-10}$$
$$=\sum \binom{10}{i}(-x^6)^i \cdot\sum\binom{-10}{j}(-x)^j$$ In order to get terms that involve $x^{15}$ there are $3$ combinations of $i$ and $j$ to consider so that $6i+j = 15$ Thus we have: $$\left[ \binom{10}{0}(-1)^0\binom{-10}{15}(-1)^{15}\right] + \left[ \binom{10}{1}(-1)^1 \binom{-10}{9}(-1)^9\right] + \left[\binom{10}{2}(-1)^2\binom{-10}{3}(-1)^3\right]$$
$$ = \left[\binom{10}{0}\binom{-10}{15}(-1)\right]+\left[ \binom{10}{1} \binom{-10}{9} \right] + \left[ \binom{10}{2} \binom{-10}{3}(-1)\right] $$ $$=\left[ \binom{10}{0}\binom{10+15-1}{15}(-1)^{15}(-1)\right] + \left[ \binom{10}{1} \binom{10+9-1}{9}(-1)^9\right] + \left[ \binom{10}{2}\binom{10+3-1}{3}(-1)^3(-1)\right]$$ $$= \left[ \binom{10}{0}\binom{24}{15}\right] - \left[ \binom{10}{1}\binom{18}{9}\right] + \left[ \binom{10}{2}\binom{12}{3}\right]$$ $$= 831204$$","['generating-functions', 'combinatorics', 'discrete-mathematics']"
2660747,Determinant using factor theorem,"Prove
  $$\Delta=\begin{vmatrix}
(y+z)^2 & x^2 & x^2 \\
y^2 & (z+x)^2 & y^2 \\
z^2 & z^2 & (x+y)^2 \\
\end{vmatrix} = 2xyz(x+y+z)^3$$
  using factor theorem. This is solved in Demonstrate using determinant properties that the determinant of A is equal to $2abc(a+b+c)^3$ using factor theorem. My Attempt: $$
x=0\text{ or }y=0\text{ or }z=0\implies\Delta=0\text{ , So $x,y,z$ are factors of }\Delta.\\
(x+y+z)=0\implies \Delta=\begin{vmatrix}x^2&x^2&x^2\\y^2&y^2&y^2\\z^2&z^2&z^2\end{vmatrix}=0\text{ , So $(x+y+z)$ is a factor of $\Delta$.}
$$
$\color{black}{\text{But how do i extract the remaining term $(x+y+z)^2$ to prove $\Delta=2xyz(x+y+z)^3$ }\color{red}{ ?}}$ Similar Example: Please check answer of @user348749 in How to solve this determinant ,
$$
\Delta'=\begin{vmatrix}
(b+c)^2&ab&ca\\
ab&(a+c)^2&bc\\
ac&bc&(a+b)^2
\end{vmatrix}=2abc(a+b+c)^3
$$
it is said that
$$
(a+b+c)=0\implies\Delta'=\begin{align*}
\begin{vmatrix}
c^2 & ca & bc \\ 
ca & a^2 & ab \\
bc & ab & b^2 \\ 
\end{vmatrix}
=abc\begin{vmatrix}
c & a & b \\ 
c & a & b \\
c & a & b \\ 
\end{vmatrix} 
\end{align*}=0
$$
""Since all rows are identical, $(a+b+c)^2$ is a factor. The determinant is a polynomial of degree 6 and hence the remaining factor is linear and since it is symmetric, the factor must be $k(a+b+c)$."" $\color{black}{\text{How can we say this }\color{red}{ ?}}$ My Understanding: If the problem was similar to this, answer of @Saibal in Factorise a matrix using the factor theorem ,
$$\Delta''=
\begin{vmatrix}
x&y&z\\
x^2&y^2&z^2\\
x^3&y^3&z^3\\
\end{vmatrix}$$
I could without doubt do as below:
$$
x=0\text{ or }y=0\text{ or }z=0\implies\Delta''=0\\
x=y\text{ or }y=z\text{ or }z=x\implies\Delta''=0
$$
Thus, $x,y,z,(x-y),(y-z),(z-x)$ are factors of $\Delta''$. ie. $\Delta''=kxyz(x-y)(y-z)(z-x)$","['matrices', 'factoring', 'linear-algebra', 'determinant']"
2660755,"Let $\omega$ be an (n-1)-form on $\mathbb{R}^n-{0}$, calculate $d\omega$","$$\omega=\sum_{i=1}^n(-1)^{i-1}f_idx_{1}\wedge dx_{i-1}\wedge dx_{i+1}\wedge ...\wedge dx_{n}$$ Where $$f_i= {x_i\over|x|^m}$$ Calculate $d\omega$ Now, I feel like this is the next step to make, but im unsure where to go from here. The textbook explained the differential operator fairly quickly, so im not sure i really understand it. 
$$d\omega=\sum_{i=1}^n(-1)^{i-1}df_i\wedge dx_{1}\wedge dx_{i-1}\wedge dx_{i+1}\wedge ...\wedge dx_{n}$$","['multivariable-calculus', 'multilinear-algebra']"
2660814,"Find $p,q $ prime numbers s.t. $p+p^2+...+p^{10}-q=2017$","Find $p,q $ prime numbers s.t. $$p+p^2+\cdots+p^{10}-q=2017.$$ It's easy to see that $p=2; q=29$ is solution. There exists another solutions?","['algebra-precalculus', 'number-theory', 'prime-numbers']"
2660845,"Suppose M is a module over integral domain R. If M is generated by k elements, then $rank(M) \leq k$ (Confirm my proof ?)","I am self studying algebra and am wondering if the following proof works. By rank we mean the supremum of cardinalities of linearly independent sets. Now this is equivalent to the supremum of cardinalities of maximal linearly independent set which is equal to the cardinality of any maximal independent set as any two maximal independent sets have the same cardinality.
Here is my argument: I said let $B=\{a_1,...a_n\}$ be a maximal linearly independent subset of M of cardinality rank(M). (We can always choose such a B whose cardinality is the rank of M).
Then consider passing to the field of fractions F. B is easily seen to be a linearly independent set over F by clearing denominators as R is an integral domain: Namely if $(c_1/d_1)a_1 + ... (c_n/d_n) a_n=0$ we have by multiplying through by $d_1 d_2... d_n$   that $(c_1 d_2... d_n) a_1 + ... + (c_n d_1...d_{n-1}) a_n =0$ but now these coefficients are in R and hence they must all equal $0$ by linear independece over R. But R is integral domain and the $d_i$ are non zero being denominators, so each $c_i=0$ and hence we see that B is an independent subset over F as well. Now M is finitely generated over R, so by embedding M in its quotient field, M is also finitely generated over F obviously. Now if this finite set that generates M has cardinality k, then the basis of M as a vector space over F has cardinality less or equal to k being a minimal spanning set. Finally B being a independent subset of a vector space M has cardinality less than the cardinality of the basis which has cardinality less than k. Hence B has cardinality less than k. But B is a maximal linearly independent set, hence $rank(M)\leq k$. Is my proof correct? I realise I have assumed that the rank is finite, but assuming it is finite, is it a correct proof? Thanks in advance. Edit: Oh wait, I guess I can't really do this as M is not free.. I was thinking M is isomorphic to R^d for some d hence pass to F^d but M is not necessarily free.","['abstract-algebra', 'modules', 'linear-algebra']"
2660867,The binomial coefficient - prove this property,"Prove that $$ {n\choose k}= \frac{n}{k} {n-1\choose k-1}$$
I have been thinking about it for a very long time and I have finally come to this solution: First of all, multiply by $k$: $${n\choose k}k = n {n-1 \choose k-1}$$ Let's say that we have a group of $n$ people. The left hand side first chooses $k$ of them who get a candy and then chooses $1$ from the chosen group to get a toy truck. The right hand side first chooses one person who gets a candy and a toy truck and then chooses $n-1$ people to get a candy. In both scenarios we have chosen exactly $k$ people, $k$ of them got a candy and $1$ of them got the toy truck. Thus, LHS and RHS are the same. Is this solution valid to any extent? What other ways to prove this are there? I tried induction - it works, too, but is a little tedious.","['combinatorics', 'proof-verification']"
2660875,"Evaluating $\int_0^{2\pi} \frac {\cos(\theta)}{5-3\cos(\theta)} \, d\theta$ using residue theorem","I am to evaluate the following integral using residue theorem: $$\int_0^{2\pi} \frac {\cos(\theta)}{5-3\cos(\theta)} \, d\theta$$ I know that I need to perform substitution with the following: $$d\theta = \frac {dz}{iz}$$ $$\cos\theta = \frac 12(z+\frac1z)$$ which yields: $$\frac 1i=\int_{|z|=1} \frac{z+\frac1z}{-3z^2+10z-3}\, dz$$ Finding the roots for the denominator yields two roots at $1/3$ and $3.$ Only $1/3$ falls within our unit circle so we ignore the root at $3.$ This is where I am a little stuck. I was taught to use the shortcut here to calculate the residue where I would leave the numerator $p(z)$ as is and take the derivative of the denominator $q'(z)$ then plug in the value of the singularity $z=\frac13$ but this approach doesn't give me the correct answer which I know is $\frac\pi6$ Am I making a mistake in setting up the problem? Thanks!","['complex-analysis', 'integration', 'residue-calculus']"
2660890,"Let $f$ be a continuous function such that $f(a)= f(b)$, prove a property","Let $ a,b $ be real numbers such that $a<b$ , and $f : [a,b] \rightarrow R $ is continuous such that $ f(a) = f(b) $ . Prove that there exists $\delta > 0$ such that for every $ t \in [0,\delta]$ there is $ x \in [a,b-t] $ that $f(x) = f(x+t)$ . I first defined a new function $g(x) = f(x) - f(x+t)$ for some $t \in [0,\delta]$ .
And tried to prove that $g(a) = f(a) - f(a+t) < 0 \space, g(b-t) = f(b -t )  -f(b) >0 $ or vice versa. And then use the intermediate value theorem but couldn't proceed any further. I also tried to take $c$ is the absolute maximum or absolute minimum, and take $ \delta = b - c$ and work around the point $(c,f(c))$ point to find the property. Thanks for any help.","['continuity', 'calculus']"
2660935,What's the point of variance?,"The big question: Why should I use variance over standard deviation? In what contexts should variance be used (on its own, not with SD)? I'm failing to understand the point of variance - anything I found on the internet about variance can easily be explained with SD.","['statistics', 'standard-deviation', 'soft-question', 'variance']"
2660949,Order of an element in a finite Group,"Theorem 2.4.5 in Herstein's book says if $G$ is a finite group of order $n$ then $a^n = e$ for all $a$ in $G$. Is this a typo? I know the order of each element must divide $n$, but must it equal the order of the group?","['abstract-algebra', 'group-theory']"
2660966,If functions agree at all but finitely many points then the integrals are the same,"Exercise 3-2 from Calculus on Manifolds by Spivak: Let $A\subset R^n,\ f:A\rightarrow R$ an integrable (in the sense of
  Darboux) function. Let $g=f$ except at finitely many points. Prove
  that $g$ is also integrable and $\int_Af=\int_A g$. Note that there is a similar question show that $g$ is integrable, with $f=g$ except in finite set and $f$ integrable but the answers assume the knowledge of measure theory whereas Spivak doesn't. I guess I need to use the criterion saying that $f$ is integrable iff there is a partition $P$ of $A$ such that $U(f,P)-L(f,P)< \epsilon$ for any $\epsilon < 0$. But I don't know how to apply it to both functions. I thought about considering $f-g$ (which should be integrable except finitely many points), but Spivak doesn't even state that the sum of two integrable functions is integrable, so perhaps I'm not supposed to use this. (Even if I consider $f-g$, I don't know how to proceed).","['multivariable-calculus', 'real-analysis', 'integration', 'calculus']"
2661049,All functions can be written as sum of product of $x$ and $y$?,"Can all functions of two variables ($x$ and $y$) be written as the sum of the products of a function of $x$ and a function of $y$?
E.g. $a(x,y) = f(x)g(y) + h(x)i(y) + j(x)k(y) ...$",['functions']
2661096,Lower bound on integral of coefficient in an ODE,"Suppose that $\phi$ solves $x'' + A \left( t \right) x = 0$, is positive on $\left(0, b \right)$, and $\phi \left( 0 \right) = \phi \left( b \right) = 0$. ($A(t)$ is continuous) Is it true that
$$\int_{0}^{b} \left| A \left( t \right) \right| dt > \frac{4}{b}$$
Any help or hints appreciated. One attempt: By the MVT for integrals, for some $0 < c < b$, $$\int_0^b \left| A \left( t \right) \right| dt = b \left| A \left( c \right) \right| \geq b \inf_{0 \leq t \leq c} \left| A \left( t \right) \right| $$
However, I think this is too restrictive. Another attempt: since $\int_0^b \left| A \left( t \right) \right| \phi \left( t \right) dt \leq M \int_0^b \left| A \left( t \right) \right| dt$, where $M = \sup \left| \phi \left( t \right) \right|$,
$$\int_0^b \left| A \left( t \right) \right| dt \geq \frac{1}{M} \int_0^b \left| A \left( t \right) \right| \phi \left( t \right) dt = \frac{1}{M} \int_0^b \left| A \left( t \right) \phi \left( t \right) \right| dt = \frac{1}{M} \int_0^b \left| \phi'' \left( t \right) \right| dt \geq \frac{1}{M} \left| \int_0^b \phi'' \left( t \right) dt \right| = \frac{1}{M} \left| \phi' \left( b \right) - \phi' \left( 0 \right) \right| $$
or, again by the MVT for integrals,
$$ = \frac{b}{M} \left| \phi'' \left( c \right) \right| $$
for some $0 < c < t$. Again, I'm not sure how to turn this into a solution. FINAL EDIT: To anyone finding this result in the future, this is a famous result by Lyapunov. One may complete my second attempt as follows: Apply Rolle's theorem to obtain $\alpha$ and $\beta$, $s$ and $t$ such that $x'(t) = -M / \alpha$ and $x' (s) = M / \beta$, and $\beta + \alpha = b$. An application of the AGM inequality finishes the job.",['ordinary-differential-equations']
2661099,No possible Level Surface?,"Given a function of three variables, is it possible to not have a level surface at all? Ex:
I'm working on a problem that tells me to describe the level set (level surface) for $p(x,y,z) = e^{-x^2-y^2-4z^2}$. I manipulated the function to be $ln(k)=-x^2-y^2-4z^2$. I'm thinking the level surface must be a type of ellipsoid but I'm having trouble graphing it both by myself and my program doesn't seem to be able to graph it. Am I doing something wrong or is this just an odd case? Ex: I'm plugging in a number for the constant and trying to graph it. Should I possibly be moving z over and having x and y equal to z?","['multivariable-calculus', '3d', 'exponential-function']"
2661113,A game with $n$ players - II,"Consider $n$ player numbered $1,2,\ldots,n$. If player $i$ fights against $j$ then $i$ wins with probability $i/(i+j)$. There are no ties. A player $i_1$ is extracted at random. Then, a second different player $i_2$ is extracted at random. They fight against each other. Then, we extract another player $i_3$ ($\neq i_1,i_2$). The winner of the latter round fights against $i_3$.The fights continues until all players have been extracted, hence $n-1$ fights in total. Now, given $i\le j$, I think that player $i$ wins the game with probability at most $i/j$ times the probability that player $j$ wins the game. (I can prove it manually for $n\le 4$.) Question. Is it possible to prove it for all $n$? Ps. Another property of the same game has been asked here . Ps2. Is it a ""known game"" ?",['probability']
2661210,"Does there always exist real numbers $w_{1},\dots, w_{n} > 0$ of such a kind?","Let $a_{1}, \dots, a_{n}$ be real numbers not all zero; let $b_{1},\dots, b_{n}$ be real numbers; let $\sum_{1}^{n}b_{i} \neq 0$. Then does there exist real numbers $w_{1},\dots, w_{n} > 0$ such that 
$$
\frac{\sum_{1}^{n}w_{i}a_{i}}{\sum_{1}^{n}w_{i}b_{i}} > \frac{\sum_{1}^{n}a_{i}}{\sum_{1}^{n}b_{i}}?
$$
Some function theory results seem prominent. But it seems that perhaps such a result is not in my current set of working knowledge.","['summation', 'functions']"
2661279,Why doesn't $A^2=I$ imply $A=\pm I$? [duplicate],"This question already has answers here : If $A^2 = I$ (Identity Matrix) then $A = \pm I$ (5 answers) Closed 6 years ago . Im having trouble believing this T/F Question:
if $\mathrm A^2=I$ then $\mathrm A = \pm \mathrm I$ The answer is False but why? If the matrix is $\mathrm A = \mathrm I,$ say \begin{bmatrix}1& 0\\ 
    0 & 1 \end{bmatrix} then $\mathrm A^2$ is also that. And if $\mathrm A = -\mathrm I,$ then it is \begin{bmatrix}-1 & 0\\
                   0 &-1 
\end{bmatrix} and that squared is also the same? Where am i going wrong?","['matrices', 'linear-algebra']"
2661290,Continuity of Probability Measure and monotonicity,"In every textbook or online paper I read, the proof of continuity of probability measure starts by assuming a monotone sequence of sets $(A_n)$. Or it assumes the $\liminf A_n = \limsup A_n$ But what about the following proof. It seems we don't need this property (monotonic). If $\{A_i, i ≥ 1\}$ are events (not necessarily disjoint nor monotonic) , then $$P [\cup_{i=1}^∞ A_i] = \lim_{m\to\infty}  P [\cup_{i=1}^m A_i]$$ This result is known as continuity of probability measures. Proof: - Define a new family of sets $$B_1 = A_1, \ B_2 = A_2 - A_1,\ ..., B_n = A_n-\bigcup_{i=1}^{n-1} A_i,.... $$
Then, the following claims are placed: Claim 1: - $B_i ∩ B_j = ∅, ∀i \neq j$. Claim 2: - $\bigcup_{i=1}^∞ A_i = \bigcup_{i=1}^∞ B_i$ Since $\{B_i, i ≥ 1\}$ is a disjoint sequence of events, and using the above claims, we get $$P (\bigcup_{i=1}^∞ A_i) = P(\bigcup_{i=1}^∞ B_i) = \sum_{i=1}^∞ P(B_i)$$ Therefore, $$P (\bigcup_{i=1}^∞ A_i) = \sum_{i=1}^∞ P(B_i)$$ (a) $$= \lim_{m\to\infty}  \sum_{i=1}^m P(B_i)$$ (b) $$= \lim_{m\to\infty}   P(\bigcup_{i=1}^m B_i)$$ (c) $$= \lim_{m\to\infty}   P(\bigcup_{i=1}^m A_i)$$ Here, (a) follows from the definition of an infinite series, (b) follows from Claim 1 in conjunction with Countable Additivity axiom of probability measure and (c) follows from the intermediate result required to prove Claim 2.
Hence proved. So my original $A_n$'s were NOT a monotonic sequence of sets, so why do we require them to be?","['probability-theory', 'elementary-set-theory']"
2661333,"The $n$th statement in a list of $100$ statements is ""Exactly $n$ of the statements in this list are false"".","I was going through ""Discrete Mathematics and its Applications - 7th edition"" by Konneth H Rosen when I stumbled across the following question:- The $n$th statement in a list of $100$ statements is ""Exactly $n$ of the statements in this list are false"". What conclusion can you draw from the statement? Answer (1) if the $nth$ statement is ""At least $n$ of the statement in this list are false"". Answer (2) assuming that the list contains $99$ questions. How to conclude from the given data? If $n$ statements are false is the $n$th statement, then maybe the first statement states that exactly $1$ statement is false. This is possible because maybe some statement from the remaining $99$ statements can be false. But, the answer given is ""99th statement is true and the rest are false"". How was this concluded? Also, for part (2) and (3), how to proceed?","['propositional-calculus', 'logic', 'discrete-mathematics']"
2661361,"Prove $\frac{x^{n}}{x+y^3}+\frac{y^{n}}{y+x^3} \geqslant \frac{2^{4-n}}{5}$ for $x, y > 0$ with $x+y=1$","Positive real numbers $x$ , $y$ satisfy $x+y=1$ . For any integer $n \geqslant 2$ , show that $$\frac{x^{n}}{x+y^3}+\frac{y^{n}}{y+x^3} \geqslant \frac{2^{4-n}}{5}.$$ So far, I've tried some elementary ways, such as AM-GM, Holder, induction. Maybe certain method mentioned above is feasible, but I've made little progress, please help.","['inequality', 'polynomials', 'algebra-precalculus', 'multivariable-calculus', 'jensen-inequality']"
2661443,Underlying Reason For Taking Log Base 10,For the equation $2^x = 7$ The textbook says to use log base ten to solve it like this $\log 2^x = \log 7$. I then re-arrange it so that it reads $x \log 2 = \log 7$ then divide the RHS by $\log 2$ to isolate the $x$. I understand this part. I can alternatively solve it in an easier way by simply using $\log_2 7$ on my calculator. Using both methods the answer comes to the same which is $2.807$ My question is twofold: Why would the textbook suggest to use log base ten rather than simply using log base two? I can see how using log base ten and the suggested method in the textbook makes me arrive at the same answer but I don't understand WHY this is so. How does base ten play a factor in the whole scope of things. Thank you,"['algebra-precalculus', 'logarithms', 'exponentiation']"
2661497,"How many pair-wise touching ""shapes"" are there in an $n\times n\times n$ grid?","Partition an $n\times n\times n$ grid of cubes into ""shapes"" which are sets of cubes connected by faces.  What's the largest number of shapes that can touch every other shape (touching = sharing a face)? Here is an image of the $2$-dimensional version of the problem, which is simple to solve: for $n=1,2,3$ the answers are $1,3$ and $4$ respectively.  Presumably for $n\ge4$, the answer is still $4$ or we would have a graph that is not $4$-colourable.","['graph-theory', 'tiling', 'geometry', '3d', 'coloring']"
2661538,How to prove that $\dim \mathrm{Spec}~A = \dim \mathrm{Spec}~ A_\mathfrak{p} + \dim \mathrm{Spec}~A/\mathfrak{p}$.,"$\DeclareMathOperator{Spec}{Spec}$
$\newcommand{p}{\mathfrak{p}}$
I was trying to solve the following exercise. Let $A$ be a finitely generated $k$-algebra over an infinite field $k$. Assume that 
  $A$ is a domain, thus $\Spec A$ is irreducible. Let $\p \subset A$ be a prime 
  ideal and let $A_\p$ be the localization of $A$ at $\p$. Show that $\dim \Spec A = 
\dim \Spec A_\p + \dim \Spec A/\p$. I'm not very sure how to proceed. Is it possible to proceed somehow by using Noether Normalization Theorem and that in this setting we have $\dim \Spec A = \mathrm{tr.deg}_k A$? To be clear, this has been asked in a somewhat different form previously, but if  possible, I wonder if one can furnish a proof using the transcendence degree and the normalization lemma?","['krull-dimension', 'dimension-theory-algebra', 'algebraic-geometry', 'commutative-algebra']"
2661543,Proof for the inverse in sub group is as same as inverse in group,"I have a question:
Let H be the subgroup of G. I want to prove that if for any element that is in the H, the inverse of that element in the group and sub group is the same. I don't know where to start. I know that and know how to prove that ""identity of subgroup is same as identity of group"", but I don't know how to proof for the inverse element. Thanks.",['abstract-algebra']
2661561,Example of $V^* \otimes V^*$ not isomorphic to $(V \otimes V)^*$,"There is always an injection between $V^* \otimes V^*$ and $(V \otimes V)^*$ given by
$$
f(v^* \otimes w^*)(x \otimes y)=v^*(x)w^*(y),
$$
where $x,y \in V$. I've been given to understand that in infinite dimension it is not surjective. Does anybody can explain me why it is the case? 
Does anybody have a concrete and simple example where $V^* \otimes V^*$ is not isomorphic to $(V \otimes V)^*$ Edit. This problem is involved in basic theory of Hopf Algebra since the fact that in infinite dimension $V^* \otimes V^*$ is only a proper subset of $(V \otimes V)^*$  is the key point for which the dual of a co-algebra is an algebra, but in general the dual of an algebra is not a co-algebra. Second Edit The answer given here doesn't seem to answer my question as the answer of Mariano does. So even if the question may seem a duplicate, the answer is not. And as Hardmath notes "" the proposed duplicate does not restrict to the tensor product of a vector space with itself, and indeed the answer given there involves one factor being the dual of the other factor. It doesn't address the problem here. ""","['tensor-products', 'functional-analysis', 'hopf-algebras', 'linear-algebra', 'coalgebras']"
2661571,Find the kernel of a 4x4 matrix,"$$
    \begin{pmatrix}
    1 & 2 & 3 & 4\\
    5 & 6 & 7 & 8\\
    9 & 10 & 11 & 12\\
    13 & 14 & 15 & 16\\
    \end{pmatrix}
$$ I am asked to find the kernel of the matrix $M$. After doing some row operation I get to 
$$
    \begin{pmatrix}
    1 & 2 & 3 & 4\\
    0 & -4 & -8 & -12\\
    0 & 0 & 0 & 0\\
    0 & 0 & 0 & 0\\
    \end{pmatrix}
$$ and for $x$ I find $x = \alpha + 2\beta$, whereas $y = -2\alpha -3\beta$
Therefore, 
$$
    \begin{pmatrix}
    \alpha + 2\beta\\
    -2\alpha - 3\beta\\
    \alpha\\
    \beta\\
    \end{pmatrix}
$$ When we take outside alpha and beta:
we get two vectors:
$$
    \begin{pmatrix}
    1\\
    -2\\
    1\\
    0\\
    \end{pmatrix}
$$
and
$$
    \begin{pmatrix}
    2\\
    -3\\
    0\\
    1\\
    \end{pmatrix}
$$
which are linearly independent and form a basis of this $ker(M)$
Could you please confirm with me whether you get the same result? Thank you.","['matrices', 'linear-algebra']"
2661617,Question on the operation of set inclusion,"If $A,B$ are two sets in a space $X$, can I define (in a way similar to the operation of implication in logic) $A\subseteq B$ as $(X\setminus A)\cup B$, where $\setminus$ denotes the operation of set difference?",['elementary-set-theory']
2661620,"Showing $8.9<\int_3^5 \sqrt{4+x^2} \, \mathrm d x < 9$","I am asked to show that $$8.9<\int_3^5 \sqrt{4+x^2} \, \mathrm d x < 9$$ I tried computing the integral but I end up with $$\frac 5 2 \sqrt{29} - \frac 3 2 \sqrt{13} + 2 \log{\left(\frac {5 + \sqrt{29}} {3+\sqrt{13}}\right)}$$ which isn't really easy to approximate. I was thinking there might be a clever way of bounding the integrand with two functions that are easy enough to integrate. I was thinking Taylor series but I'm not sure how I can ensure that gives me an actual bound as opposed to a mere approximation.",['integration']
2661621,"For a random variable $X$, how can we characterize the events that unambigously describe possible properties of the outcome of $X$?","Let $(\Omega, \mathcal{A}, P)$ be a probability space, $(\hat{\Omega}, \hat{\mathcal{A}})$ be a measurable space and $X : \Omega \rightarrow \hat{\Omega}$ be a random variable. We say that an event $A \in \mathcal{A}$ is a possible property of $X$ if and only if, for all $w \in \Omega$, knowing the value of $X(w)$ is enough information to unambigously decide whether $w \in A$ or $w \in A^{c}$ ( = whether $A$ happened or did not happen). In other words, $A \in \mathcal{A}$ is a possible property of $X$ if and only if there is a set $E \subseteq \hat{\Omega}$ such that $A = X^{-1}(E)$. If $A$ is a possible property of $X$, one can always choose $E \subseteq X(\Omega)$. We denote the set of all possible properties of $X$ as $\mathcal{B}(X)$. I am trying to characterize $\mathcal{B}(X)$  and understand its relation to the $\sigma$-algebra generated by $X$. The $\sigma$-algebra generated by $X$ is the smallest $\sigma$-algebra such that $X$ is measurable and is given by $$ \sigma(X) := X^{-1}(\hat{\mathcal{A}}) =\{X^{-1}(\hat{A}) \ \vert \ \hat{A} \in \hat{\mathcal{A}}  \}. $$ Clearly, all events in $\sigma(X)$ are possible properties of $X$ and it holds that $\sigma(X) \subseteq \mathcal{B}(X) \subseteq \mathcal{A} $. Note, that $\sigma(X)$ depends on $X$ and $\hat{\mathcal{A}}$. I wonder what necessary and sufficient conditions on $X$ and $\hat{\mathcal{A}}$ are such that $$ \sigma(X) = \mathcal{B}(X).  $$ It is not hard to see that $$ \mathcal{B}(X) =  X^{-1}(\mathcal{P}(\hat{\Omega})) \cap \mathcal{A}, $$ where $\mathcal{P}$ denotes the power set. In particular, this implies that $\mathcal{B}(X)$ is always a $\sigma$-algebra. If we write $$ \sigma(X) =  X^{-1}(\hat{\mathcal{A}}) \cap \mathcal{A}  ,$$ it becomes clear that $\hat{\mathcal{A}} = \mathcal{P}(\hat{\Omega})$ is a sufficient condition for $ \sigma(X) = \mathcal{B}(X)$. However, I do not think this condition is necessary and it is rarely fulfilled in practical applications. What are conditions on $X$ and $\hat{\mathcal{A}}$ for $ \sigma(X) = \mathcal{B}(X)$ that are both necessary and sufficient? I'm happy to hear as many thoughts as possible on this! Kind regards,
Joker","['probability', 'measure-theory', 'stochastic-filtering', 'random-variables']"
2661650,Can a hyperbolic fixed point be inside a homoclinic loop on a plane?,"Consider a system of odes on a plane. It is obvious that a fixed point of centre-type stability (imaginary e-values) can exist inside a homoclinic loop to a hyperbolic saddle fixed point. For example, take the Hamiltonian $H(x,y) = \frac{1}{2}(y^{2}-x^{2}) + x^{3}$. Here the hyperbolic saddle point at origin has a ""fish"" shaped homoclinic loop enclosing the centre fixed point at $(1/3, 0)$. What I'm wondering is whether a homoclinic loop can enclose fixed points other than centre type, i.e. can a ""sink / source"" or a ""saddle"" exist inside a homoclinic loop? And can this situation be generalised to $\mathbb{R}^{n}$? I cannot think of a way to either prove / disprove this. I suspect Poincare-Bendixson and index theory could be used, but not sure how.","['dynamical-systems', 'bifurcation', 'ergodic-theory', 'classical-mechanics', 'ordinary-differential-equations']"
2661677,Is there Cauchy-type estimate for real analytic functions?,"A real analytic function $f: I\subset \mathbb{R}\to \mathbb{C}$ can be expressed as a power series on a neighbourhood of each point in $I.$ (See here ). I wonder whether there is a Cauchy estimate for such functions. Namely, 
$$f^{(n)}(a) \leq \frac{M n!}{r^n}$$
for $[a-r, a+r]\subset I$ and $\max_{t\in [a-r, a+r]}|f(t)|\leq M.$ Such estimate exists for ""complex"" analytic functions and can be derived using the Cauchy integral formula (see here ). Thank you in advanced.","['analyticity', 'complex-analysis', 'real-analysis', 'analytic-functions']"
2661724,Show that $\frac{5}{n}+e^{-n}=O(\frac{1}{n})$,"Show that $\frac{5}{n}+e^{-n}=O(\frac{1}{n})$ I know that $e^n>n, (n\geq 0)$, with which $e^{-n}<\frac{1}{n}$ and so $\frac{5}{n}+e^{-n}<\frac{5}{n}+\frac{1}{n}=6\frac{1}{n}$, then $\frac{5}{n}+e^{-n}=O(\frac{1}{n})$. Is this argument right? Thank you very much.","['real-analysis', 'calculus', 'numerical-methods', 'sequences-and-series', 'analysis']"
2661759,Proof of Hopf's theorem (the one about cohomology of Lie groups being equal to the cohomology of a product of spheres),"Theorem (H. Hopf). Let $G$ be a compact connected Lie group. Then $G$ has the real cohomology of a product of odd dimensional spheres,
  $H(G,\mathbb{R}) \approx H(\prod_q S^{2k_q - 1},\mathbb{R})$. The only place I could find the proof of this theorem was the book by Greub, Connections, curvature and cohomology . Do you guys know where else can I find a proof of this theorem? The original papers are in german and french, and I couldn't find any translations. Thanks in advance.","['homology-cohomology', 'reference-request', 'algebraic-topology', 'differential-geometry', 'lie-groups']"
2661763,Eigenvector Riesz basis under operator multiplication?,"I recently encountered the Riesz Spectral Operators which roughly speaking are closed operators whose eigenvectors form a Riesz basis and I became interested in when such operators can be perturbed and still be of the same type. I must admit that my knowledge of spectral theory is a bit rusty, but I feel like this is a reasonable question. My hypothesis is the following: So, suppose $(\phi_n)$ is a Riesz basis for a complex hilbert space $X$. I.e. $\overline{span} \phi_n=X$ and there exist $m,M$ such that for all $N$ 
$$m\sum^N |\alpha_n|^2 \leq \|\sum^N a_n\phi_n \|^2 \leq M \sum^N|\alpha_n|^2.$$
Suppose further $A$ is a closed operator such that $(\phi_n)_n$ are its eigenvectors. Let us also assume $\bar \sigma_p$ totally disconnected. Now - I wonder: can I find a (bounded) operator $B : X \to V$ where $V$is another hilbert space (possibly a subspace, or $X$ itself) such that $(B\phi_n)_n$ is a Riesz Basis for $V$ and correspond in some reasonable way to the eigenvectors of $BA$? As I said, my knowledge of spectral theory is abit rusty, but I guess this is obviously true for $B=I$ and should also be true for $B=P_\Gamma$ (although I am not sure of this as of yet) when $\Gamma$ a jordan curve separating the point spectrum of $A$ since such projetions interact nicely with the eigenvectors. Recall
$$P_\Gamma x=\frac{1}{2\pi i}\int_\Gamma R(A: \lambda ) x d\lambda.$$ Now can this be extended for a broader class $B$? What are necessary/sufficient conditions on $B$ for such statements to hold. I appreciate any links/help/references/explanations why I am daft. EDIT: I guess the bound condition for the Riesz Basis is kind of trivial when $B$ itself is bounded. What is not trivial is then when $(B\phi_n)$is a Riesz basis and when there is a nice correspondence of the spectra.","['functional-analysis', 'spectral-theory', 'operator-theory']"
2661789,Euler function and sums,"I've come across a nice little combinatorial problem.
Firstly we have vector $(1, 1)$. On each iteration for each two consecutive numbers in the vector we add their sum between them:
$$(1, 2, 1)$$
$$(1, 3, 2, 3, 1)$$
$$(1, 4, 3, 5, 2, 5, 3, 4, 1)$$
$$(1, 5, 4, 7, 3, 8, 5, 7, 2, 7, 5, 8, 3, 7, 4, 5, 1)$$
ad infinitum. Here's the question. How many times number $n$ will be written in the final vector? I'v computed the answers for $1, \dots, 15$:
$$2, 1, 2, 2, 4, 2, 6, 4, 6, 4, 10, 4, 12, 6, 8$$ And this values coincide with the values of Euler's totient function. But how to prove that the answer is always $\phi(n)$? And can one simply derive this idea without explicitly writing first values?","['number-theory', 'combinatorics', 'totient-function', 'elementary-number-theory']"
2661796,In search of intuition for Integral Curvature,"EDIT 1/2/3: The intuitive understanding  of Integral Curvature ( the non-dimensional geometrical parameter measured in steridians  for surfaces in $ \mathbb R^3 $) seemed to me elusive. In a simple sphere case where Gauss curvature is constant and a certain area of a spherical cap is covered it is comprehensible as a fraction of full sphere maximum value $4 \pi$. It is a scalar invariant preserved in isometric mappings, an object of first fundamental form of surface theory. Its innate understanding to the extent other isometrically preserved entities is just not there, imho. I supposed that if the concept is extended to more prismatic surfaces it may even help in building a mechanics model of  Gauss-Bonnet theorem with forces, pressure and bending moments. Anyhow in order to gain better geometric intuition about what Integral Curvature really is (apart from its definition, the sphere and torus examples ), I tried to setup the following problem with geometric surface less round and more prismatic cylindrical surface. Whatever may be my motivation of this post stated above can be please ignored as a matter of my opinion, for an answer the following question: Find  meridian profile of a surface of revolution that maximizes volume for  given integral curvature $\int K\, dA$. The functional is $$\int K\, dA - \lambda_1 \, \int \pi \, r^2 \,dz $$
or
$$ \int \dfrac{r^{''}}{r(1+r^{'2})^{2}} \, 2 \pi r \sqrt{1+r^{'2}} dz- \lambda_1 \int \pi r^2 dz $$ Lagrangian with adjusted multiplier $a$ introduced $$ F= \dfrac{r^{''}}{(1+r^{'2})^{3/2}}- \dfrac{r^2}{a^3} $$ and using Euler-Lagrange equation of second degree $$ F - r' \dfrac{\partial F}{\partial r'} +  r{''} \dfrac{\partial F}{\partial r{''}} = c, $$ where $c$ is an arbitrary constant, which after simplification results in the ODE: $$r^{'} = \tan \phi,\quad \kappa =\dfrac{  r^{''}}
 {(1+r^{'2})^{3/2} } $$ $$ a^3 \kappa = \dfrac{r^2+c^2}{5-3 \cos^{2} \phi} $$ Results are plotted below for two cases $ a= \pm 1 , c= 0.5, r_i =0.75, r_i^{'} =0 ;$ Every Lagrange Multiplier is a geometrical property of the sought-after curve or surface upto a multiplicative constant .. ..right? So $a$ is the property parameter here. ( Like in Dido's iso-parametric problem has f ( Area, perimeter,  Lagrange Multiplier radius = $\lambda$)=0 However, no intuition gained from the new found looped shapes. There is no feel (for me) of integral curvature to correlate to maximum volume here say between two vertical tangent planes... I request for comments on the validity of the problem formulation and the result. Any remarks would be highly appreciated. Continuing the inquiry along same lines to find maximum area for given integral curvature , we get ODE $$ a^2  \kappa =\frac{(c+ r \cos \phi )}{ 5- 3 \cos^2 \phi}$$ and meridian curves ( $ BC: r_i=1, c= \frac12 $) with varying initial slopes as the following:","['calculus-of-variations', 'differential-geometry']"
2661940,Calculating $\lim_{x\rightarrow 0}\frac{1}{x^n}e^{\frac{-1}{x^2}}$ (by hand),$$\lim_{x\rightarrow 0}\frac{1}{x^n}e^{\frac{-1}{x^2}}$$ I tried using de l'Hospital but can't get any further Thanks!,"['derivatives', 'calculus', 'analysis']"
2661991,Prove that $A$ is dense if and only if any non-empty open set in $X$ has an intersection with $A$,"Let $(X,d)$ be a metric space and let $A \subseteq X$. Prove that $A$ is dense if and only if any non-empty  open set in $X$ has an intersection with $A$ In my proof $\text{Cl}(A)$ denotes the closure of $A$. I need to prove, equivalently, that $\forall O$ non-empty open subset of $X$:
$$\text{Cl}(A)=X\Longleftrightarrow O\cap A\neq \emptyset$$ I feel my attempt has some logical errors, and I kindly request criticism and insight. If my attempt is entirely wrong, please help me with alternative ways. Thank you very much. Here is my attempt: PART 1 ($\Longrightarrow$): We have $\text{Cl}(A) = X$, therefore by definition of the closure:
$$\forall a\in X:\forall N\in N(a), N\cap A\neq\emptyset$$
Every neighborhood of every point of $X$ intersects $A$. Therefore one could add, every open neighborhood of every point of $X$ intersects $A$. Let $N_O(a)\subseteq N(a)$ be the set of open neighborhoods of $A$, then by definition:
$$\forall a\in X: \forall O\in N_O(a),O\cap A\neq\emptyset$$
Therefore, every non-empty open neighborhood of every point of $X$ intersects  $A$. In other words, every non-empty open subset of $X$ intersects  $A$. PART 2 ($\Longleftarrow$): We have $\forall O \subseteq X$ that $O \cap A \neq \emptyset$. ($O$ is non-empty and open) Let $a \in O$. Assume $\text{Cl}(A) \neq X$, therefore $\text{Cl}(A)^\text{C} \neq \emptyset$. By negating the definition of the closure of $A$, we get $\forall a\in \text{Cl}(A)^\text{C}$:
$$\exists N \in N(a): N\cap A = \emptyset$$
$N$ is a neighborhood for $a$, therefore $\exists O$ open: $a \in O \subseteq N$. Therefore, $O \cap A = \emptyset$ but $O \cap A \neq \emptyset$. Contradiction , therefore $\text{Cl}(A) = X$.","['general-topology', 'real-analysis', 'metric-spaces', 'analysis']"
2662005,How much of a group $G$ is determined by the category of $G$-sets?,"Suppose $G$ and $H$ are groups and we have an equivalence of categories between $G\textrm{-}\mathbf{Set}$ and $H\textrm{-}\mathbf{Set}$. (One can think of this as a form of ""nonlinear Morita equivalence"".) What can be said about $G$ and $H$? I suspect that $G$ and $H$ have to be isomorphic, but I can't prove it. If this is too hard in general, I'm also interested in the case that $G$ and $H$ are assumed to be finite. Here are some things I've tried: Since $G$-modules are the abelian group objects in $G\textrm{-}\mathbf{Set}$, we get a Morita equivalence between $\Bbb{Z}[G]$ and $\Bbb{Z}[H]$. So if we tensor with any field $k$, we get a Morita equivalence between $k[G]$ and $k[H]$. Assume for a moment that $G$ and $H$ are finite. If we take $k = \Bbb{C}$, then this means that $G$ and $H$ have the same number of irreducible representations, so the same number of conjugacy classes. If we take $k=\Bbb{R}, \Bbb{Q}, \overline{\Bbb{F}_p}$, we also get the same number of real, rational and $p$-regular conjugacy classes. While this approach gives some common properties between $G$ and $H$, it's not possible to conclude that $G$ and $H$ are isomorphic, because there are known examples of non-isomorphic finite groups with isomorphic integral group algebras. (See here ) This means that we have to use some of the ""nonlinear"" information from the category $G\textrm{-}\mathbf{Set}$. Another thing I considered is that the automorphism group of the forgetful functor $G\textrm{-}\mathbf{Set} \to \mathbf{Set}$ is isomorphic to $G$, by a simple Yoneda-argument, so if we could somehow reconstruct the forgetful functor just from the category $G\textrm{-}\mathbf{Set}$, this would show that $G$ and $H$ must be isomorphic. I haven't been able to do this, but I reconstructed some other functors: The terminal object in $G\textrm{-}\mathbf{Set}$ is a one-point set with a trivial action, denote this $G$-set by $\{*\}$, we have a natural bijection $\operatorname{Hom}_{G\textrm{-}\mathbf{Set}}(\{*\},X) \cong X^G$, where $X^G$ denotes the set of fixed points under the action of $G$.
So we can reconstruct the fixed point functor $G\textrm{-}\mathbf{Set} \to \mathbf{Set}$. The left adjoint of that functor is the functor $\mathbf{Set} \to G\textrm{-}\mathbf{Set}$ which gives each set a trivial $G$-action. Denote $X$ with a trivial $G$-action by $X_{triv}$. We have $\operatorname{Hom}_{G\textrm{-}\mathbf{Set}}(X,Y_{triv}) \cong \operatorname{Hom}_{\mathbf{Set}}(X/G,Y)$, so the functor which sends each $G$-set to the orbit space $X/G$ is left adjoint to the functor which gives each set a trivial $G$-action, so we can reconstruct the functor $X \mapsto X/G$ from the category $G\textrm{-}\mathbf{Set}$. Not sure if that's helpful. Maybe it's even possible that $G$ and $H$ don't have to be isomorphic? I'm looking either for a counterexample or a proof.","['category-theory', 'representation-theory', 'group-theory', 'group-actions']"
2662045,Is there a word for restricting the codomain of a function?,"Consider a function $f : A \rightarrow B$. We can restrict the function to any subset of its domain. That is completely standard. Sometimes we would also like to restrict the codomain of a function. Notably and obviously, the codomain must be large enough to contain the image $f(A)$ of the domain under $f$. Is there a word or a formalism for restricting the codomain of a function?","['terminology', 'elementary-set-theory']"
2662046,Explicit solution for ODE,"I’ve been attempting to find a solution to the following differential equation but to no avail
$$2q^{2}h\frac{d^{2} C}{d q^{2}}-h(1+2(v+1)q)\frac{d C}{d q}=\ln (C) - \ln{(h\exp({2h(v+1)}))}$$ Subject to the boundary condition $$C(0)=\frac{\exp(2h(1+v))-1}{2(v+1)}$$ Is it possible to find a closed form solution for this equation? Does anyone know a reference to a paper discussing ODEs of the form $f’’(x)+f’(x)+\ln(f(x))=0$ ? Thanks,
J","['ordinary-differential-equations', 'closed-form']"
2662094,Real time bayesian analysis,"Currently our memcached cluster shields our database from heavy load. If the cache were to go down, it would take our application down with it. With a cold cache, we could avoid this downtime by switching into a ""safe mode"", where $1\%$ of cache miss requests go to master and warm the cache. The remainder of requests go to read replicas, serve potentially stale data and  aren't used to populate the cache(to avoid stale sets). I want to create a model that can recognize when the cache is likely in a cold state. I imagine I could track cache hit rate over a period of time and get a good idea of the mean and variance of the cache hit rate. Given a prior of how frequently I expect to be in a cold state (rare) and a certain hit rate, it seems I could create a posterior distribution that estimates how likely we are to be in a cold state, and switch into ""safe mode"" given some threshold value. What would be the best way to measure hit rate? I could somewhat arbitrarily set a window of say $1$ second or $30$ seconds and measure hit rate in that interval. Although that raises the issue of finding the best window — smaller windows will have larger variance, but too large of a window means the model doesn't trigger ""safe mode"" quickly enough. What I really want is a sliding window where more recent hits weigh more heavily in the models decisions but all previous hits are taken into account as well. What would be the best way to approach this?","['statistical-inference', 'bayes-theorem', 'bayesian', 'statistics', 'bayesian-network']"
2662102,"Does it make sense to talk about ""frequency"" when expanding a function using spherical harmonics?","If I had a function defined in the sphere and I expand it using spherical harmonics, such as $$
f(\theta,\phi) = \sum_{l=0}^{+\infty} \sum_{m=-l}^{l} c_{lm}Y_l^m(\theta,\phi)
$$ does it make any sense to talk about ""low frequency"" and ""high frequency""? If yes, what is usually meant by that? My analogy is with the Fourier analysis where low frequency is usually associated wit the first terms of a series. I think something similar can be said here, is it correct?","['spherical-harmonics', 'complex-analysis', 'real-analysis', 'fourier-analysis']"
2662106,"Showing that preimage of a subset of $[0,1]$ is Lebesgue measurable under the Cantor function.","Let $C$ be the Cantor function . I am asked to show that for any $A \subset [0,1]$, $C^{-1}(A)$ is Lebesgue measurable. I've shown so far that the Cantor function is uniformly continuous, increasing and that the image of the cantor set under the cantor function is $[0,1]$. I don't really know how to start working on this problem so any help would be appreciated.","['lebesgue-measure', 'measure-theory', 'cantor-set']"
2662110,How does Axiom of Choice imply Axiom of Dependent Choice?,"Axiom of Choice: Given a collection $A$ of nonempty sets, there exists a function

$$c: A \to \bigcup_{A_{i} \in A}A_{i}$$

such that $c(A_{i})\in A_{i}$ for all $A_{i} \in A$. Axiom of Dependent Choice: Given a nonempty set $A$ and a binary relation $\mathcal{R}$ on $A$ such that for all $a\in A$, there exists $b\in A$ such that $a\mathcal{R}b$. There exists a sequence

$$(a_{n})_{n\in \mathbb{N}}$$

such that $a_{n}\mathcal{R}a_{n+1}$ for all $n \in \mathbb{N}$. Here is my incomplete proof that Axiom of Choice implies Axiom of Dependent Choice: For $a\in A$, let $R(a)=\{b\in A\mid a\mathcal{R}b\}\implies R(a)\neq\varnothing$ for all $a\in A$. Using Axiom of Choice for the indexed family of sets $(R(a))_{a\in A}$, there exists a mapping $$f:A\to A$$

such that $$\forall a\in A:f(a)\in R(a)$$ $\text{That is }\forall a\in A:a\mathcal{R}f(a)$. Let $B=\{(a,f(a))\mid a\in A\}$ I don't know how to proceed to prove the existence of the required sequence $(a_{n})_{n\in \mathbb{N}}$ from set $B$. Please help me complete my proof! Many thanks for you!","['elementary-set-theory', 'axiom-of-choice']"
2662111,For what irreducible $f\in\mathbb{Q}[X]$ is this sequence periodic modulo $f$?,"This is just an interesting problem I found in an old notebook of mine: Given an irreducible $f\in\mathbb{Q}[X]$, is there a way to determine whether
  the sequence $(p_n)_{n=0}^{\infty}\subset \mathbb{Q}[X]$ given by:
  $$p_0=X$$ $$p_{n+1}=p_n^2-2$$ is periodic modulo $f$, without first having to determine the roots of $f$? I've only found a way which involves finding the exact roots and that's nearly impossible for $\deg f\ge 5$. The direct formula for $p_n$ might be useful:
$$p_n=\left(\frac X2+\frac12\sqrt{X^2-4}\right)^{2^n}+\left(\frac{X}{2}-\frac12\sqrt{X^2-4}\right)^{2^n}$$ My method using the roots For anyone interested, here's my method, which relies on finding the exact roots of $f$. Given an irreducible polynomial $f\in\mathbb{Q}[X]$ with $f\neq X$ such that $(p_n)_{n=1}^{\infty}$ is periodic with period $d$, let $\alpha$ be a root of $f$ and define $(a_{n})_{n=1}^{\infty}$ by:
$$a_n=p_n(\alpha)$$
We can also define $(a_{n})_{n=1}^{\infty}$ by:
$$a_0=\alpha$$
$$a_{n+1}=a_n^2-2$$
and if we take $\beta$ with $\alpha=\beta+\beta^{-1}$, then it can easily be shown via induction that 
$$a_n=\beta^{2^n}+\beta^{-2^n}$$
Suppose $|\beta|\neq 1$. If $|\beta|<1$, exchange $\beta$ and $\beta^{-1}$, so we can be sure that $|\beta|>1$ and $|\beta^{-1}|<1$. It follows that:
$$|\alpha|=\lim_{k\to\infty} |a_{kd}|=\lim_{k\to\infty}|\beta^{2^{kd}}+\beta^{-2^{kd}}|=\infty$$
Which is a contradiction. Therefore, $\beta=e^{i\gamma}$ for some $\gamma\in\mathbb{R}$ and:
$$a_n=e^{i\gamma n}+e^{-i\gamma n}=2\cos(\gamma n)$$
Which is only periodic if $\gamma$ is a rational multiple of $2\pi$. The only $f$ we have't checked is $f=X$, but it is easily seen that $p_n\equiv 2\pmod X$ for all $n$. So $(p_n)_{n=1}^{\infty}$ can only be periodic modulo $f$ when all the roots of $f$ are of the form:
$$2\cos\left(\frac{2\pi p}{q}\right)$$
for some $p/q\in\mathbb{Q}$. On the other hand, if for some $p/q\in\mathbb{Q}$ we take
$$\alpha:=2\cos\left(\frac{2\pi p}{q}\right)$$
Then we can define $(a_n)_{n=1}^{\infty}$ as before and show it's periodic, say with period $d$. For all $k,m$, we now have:
$$p_k(\alpha)=p_{k+md}(\alpha)\implies (p_{k+md}-p_k)(\alpha)=0$$
and since for $m\neq 0$, we have $\deg p_k\neq \deg p_{k+md}$, it follows that $f^{\alpha}_{\mathbb{Q}}\mid p_{k+md}-p_k$. This implies that all such $\alpha$ are algebraïc over $\mathbb{Q}$ and if a monic irreducible $f\in\mathbb{Q}[X]$ has just one root of the form
$$2\cos\left(\frac{2\pi p}{q}\right)$$
then all of its roots are of this form (because it's a unity times $f^{\alpha}_{\mathbb{Q}}$, the sequence is periodic modulo $f^\alpha_{\mathbb{Q}}$ and can only be periodic if all roots are of this form.","['irreducible-polynomials', 'abstract-algebra', 'recurrence-relations', 'sequences-and-series']"
2662157,Jump of dilogarithm,"I am reading about the dilogarithm function $$ \mathrm{Li}_2(z):= - \int_0^z \frac{\log(1-u)}{u}du, \quad z \in \mathbb{C} \backslash [1, \infty).$$ I found it stated that the ""jump"" of the dilogarithm across the axis where it is not defined is $2\pi i \log(r)$ for crossing at $r>1$. Why is that so? I can see that $\log(1-u)$ jumps by $2\pi i$ when $u$ crosses the axis, but I cannot see how to procede from there.","['complex-analysis', 'integration', 'polylogarithm']"
2662174,When do Taylor series provide a perfect approximation?,"To my understanding, the Taylor series is a type of power series that provides an approximation of a function at some particular point $x=a$. But under what circumstances is this approximation perfect, and under what circumstances is it ""off"" even at infinity? I realize is a little hazy so I'll rephrase: By ""perfect"" I refer to how a regular limit doesn't ever actually reach something but instead provides a sort of error term that you can make as small as you want, so for all practical purposes we treat it as zero error. Whereas for something that is an imperfect approximation maybe that arbitrarily small error piece doesn't exist, or maybe the function is only correct for that particular point and nowhere else, etc. So maybe what I am asking is when the Taylor series provides an equivalent representation of the function over all $x$ in $f$'s domain, and when does it not? And when it doesn't, how do we even know?","['derivatives', 'taylor-expansion', 'calculus', 'definition', 'approximation']"
2662192,Show that a pivotal quantity has a chi-square distribution,"Let $Y$ be a random variable with an exponential distribution with E(Y)=$\theta$. Show that the pivotal $\frac{2Y}{\theta}$ has a chi-square distribution using moment-generating function technique. What I did: Mu(t) = E(e$^{tu})$ = E(e$\frac{t(2Y)}{\theta})$. Then I integrated: $\int_{0}^{\infty}$e$^\frac{t(2Y)}{\theta}*f(y) dy$. This produces $\frac{-\theta}{2 \beta t-\theta}$ This looks nothing like a chi-square distribution. It then asks how many degrees of freedom it has. Please help! Thanks in advance, oh wise Stats geniuses.",['statistics']
2662196,Characteristic Polynomial of Restriction to Invariant Subspace Divides Characteristic Polynomial,"I am interested in finding a proof of the following property that does not make reference to bases, and ideally doesn't use facts about determinants that depend on the block structure of a matrix. Let $T \in L(V,V)$ be a linear operator on a finite-dimensional space $V$.  Suppose $W \preccurlyeq V$ is a $T$-invariant subspace, that is, $T(W) \subset W$.  Consider the restriction $T_W \in L(W,W)$ of $T$ to $W$.  Then the characteristic polynomial of $T_W$ divides the characteristic polynomial of $T$. Let $p,p_W$ be the characteristic polynomials and $m,m_W$ be the minimal polynomials.  It is easy to show ""algebraically"" that $m_W \mid m$ since $m$ annihilates $T_W$, so must be a multiple of the monic generator $m_W$.  However, the only proofs I have seen that $p_W \mid p$ make use of basis expansions: Let $\mathcal{B}=\{ v_1,\dots,v_n \}$ be a basis for $V$ such that $\mathcal{B}'=\{ v_1, \dots, v_r \}$ form a basis for $W$. The matrix of $T$ with respect to $\mathcal{B}$ has the following block form, where $A \in F^{r \times r}$ is the matrix of $T_W$ with respect to $\mathcal{B'}$, $$[T]_{\mathcal{B}} = \begin{bmatrix} A & B \\ & C \end{bmatrix} \implies xI - [T]_{\mathcal{B}} = \begin{bmatrix} xI - A & B \\ & xI-C \end{bmatrix}$$ Then $p = \det(xI - [T]_\mathcal{B}) = \det(xI-A)\det(xI-C)$ is a multiple of $p_W = \det(xI-A)$. The use of basis expansions and block matrices leaves something to be desired. Is there a ""matrix-free"" way to prove this? Assume we know about Cayley-Hamilton, if it helps.","['alternative-proof', 'matrices', 'determinant', 'minimal-polynomials', 'linear-algebra']"
2662213,Calculating the Inverse of a matrix.,"$A)$ Solve: $x_1-x_2=1$ $-x_1+2x_2-x_3=0$ $\vdots$ $-x_{99}+2x_{100}=0$ $B$)Deduce the inverse of A=\begin{pmatrix}
        1 & -1 & 0 & \cdots& \cdots & 0   \\
        -1 & 2 & -1 & \ddots& \cdots  &\vdots\\
        0 & -1 & 2 &-1& \ddots& \vdots\\
        \vdots & \ddots & \ddots & \ddots &\ddots&0\\
        \vdots & \cdots & \ddots & \ddots &2&-1\\
        0 & \cdots & \cdots & 0 &-1&2\\
\end{pmatrix} I've solved the first part and got: $x_1=100$ $x_2=99$ $\vdots$ $x_{100}=1$ (Correct me if I'm wrong) For the part B , I'm not sure how to approach it although I'm quite sure the first column of $A^{-1}$ should contain $x_1$ till $x_{100}$ in this order , however I have no idea on how to fill the other columns. If anyone could help me or give me hints , I would be grateful. Thanks in advance.","['matrices', 'linear-algebra', 'systems-of-equations']"
2662231,Creating a 3D ellipsoid from a 2D ellipse (rotated around a symmetric axis),"Hello fellow mathematicians, I am trying to generate the equation for a 3D tapered spheroid, so that I may obtain its contour plot. I am using Mathematica and/or Wolfram Alpha. The tapered ellipse $ (x^2 + y^2)^2 = 1.2 x^3 + {0.36}xy^2 $ is to be rotated around the x-axis to form an egg-shape. The image below is generally what it should look like, but I do not have the code that produced this image. The difference between my spheroid and the one in the image is that mine has a major axis of $1.2$ whereas the picture denotes a major axis of $1$. Picture An equation/code to produce this figure in WA or Mathematica would be most appreciated! Thank you all! Addendum, more equations! Generalized tapered ellipse (the above is the special case $a=1.2$):
\begin{equation} (x^2+y^2)^2 = ax^3 + \frac{3a}{10}xy^2 \end{equation} Parametrics for the generalized tapered ellipse: \begin{align}
x &=\left(\frac{a}{2}-\frac{b}{2}\sin^2\left(\frac{t}{2}\right)\right)\left(1+\cos t\right) \nonumber \\
y &=\left(\frac{a}{2}-\frac{b}{2}\sin^2\left(\frac{t}{2}\right)\right)\sin t \label{eq:2}
\end{align} where $\forall ((a,b)\in\mathbb{R})\ |\  (a,b)>0$, $a$ and $b$ are the lengths of the major and minor axes of the ellipse. The minor axis is fixed in the general ellipse, but is appropriately represented in the parametrics. Note that the general equation is simply the Cartesian form of the parametrics where minor axis $b=\frac{7a}{10}.$","['3d', 'geometry']"
2662295,"What is the mistake in finding the irreps of $SU(3)$ multiplets $6 \otimes 8$, or $15 \otimes \bar{15}$?","I wrote a Mathematica paclet that can be used to find irreducible representations of $SU(n)$.
Specifically, given a product of $SU(n)$ multiplets, it can compute the corresponding sum.
To test the paclet, I compare its output with various examples from books. 
It fails on two occasions, when I compare against Table 4.13.1 on page 83 in The Lie Algebras of su(N) by Walter Pfeifer. 
I also did the calculations by hand, but I obtain the same answer as my program. My calculation:
$$6 \otimes 8 = \color{red}{\bar{3}} \oplus \bar{15} \oplus 6 \oplus 24$$
Book:
$$6 \otimes 8 = \color{red}{3} \oplus \bar{15} \oplus 6 \oplus 24$$ My calculation:
$$15 \otimes \bar{15} = 1 \oplus \bar{10} \oplus \color{red}{10} \oplus 8 \oplus 8 \oplus \bar{35} \oplus 27 \oplus 27 \oplus 64 \oplus 35$$
Book:
$$15 \otimes \bar{15} = 1 \oplus \bar{10} \oplus \color{red}{\bar{10}} \oplus 8 \oplus 8 \oplus \bar{35} \oplus 27 \oplus 27 \oplus 64 \oplus 35$$ Is this my mistake, or are these typos in the book? Here is the explicit calculation of the first example, using Young tableaux:","['young-tableaux', 'representation-theory', 'group-theory', 'lie-algebras']"
2662313,Quadratics which produce no primes,"There are some famous polynomials which produce a series of consecutive prime numbers, including Euler's $n^2 + n + 41$, which produces primes for $0 \leq n \leq 39$. What I've been thinking about recently are quadratic polynomials with integer coefficients which don't produce any primes at all for $n \geq 0$.  There are trivial cases: $$
n^2 + n
$$ $$
an^2 + bn + c \quad,\quad \gcd(a, b, c) > 1
$$ There's at least one family of polynomials which is borderline trivial, but worth mentioning: $$
n^2 + (2a - 1)n + a^2 \quad,\quad a\quad \text{even}
$$ All values of polynomials of this form are even; the reader can easily check using parity rules.  What I am very curious about is the case when $a$ is odd. Does there exist an $a \in \mathbb{N}$ such that
  $$f_a(n) = n^2 + (2a - 1)n + a^2 \quad,\quad a\quad \text{odd}$$
  produces no primes for $n \geq 0$? It can be shown using parity rules that $f_a$ is odd for all $n$. Any thoughts appreciated.","['polynomials', 'number-theory', 'elementary-number-theory', 'prime-numbers', 'quadratics']"
2662333,Probability that you have exactly one correct answer on a test,"I have two questions from a practice test which I have some concerns about: Assume you write a multiple-choice exam that consists of 100 questions. For each question,
  4 options are given, one of which is the correct one. If you answer each of the 100 questions
  by choosing an answer uniformly at random, what is the probability that you have exactly
  one correct answer? (a) $\frac{100}{4^{100}}$ (b) $\frac{3^{99}}{4^{100}}$ (c) $\frac{100+3^{99}}{4^{100}}$ (d) $\frac{100\cdot3^{99}}{4^{100}}$ The answer is (d) . Can someone help me understand how to go about this problem? How does  $100\cdot3^{99}$ count the number of ways there can be exactly one correct answer? I know that $3^{99}$ is the number of ways to choose $3$ possible answers from $99$ questions, while $1$ question is already fixed (correct). Why multiply by $100$? You flip a fair coin 5 times. Define the events $A =$ ""the number of heads is odd"" and $B =$ ""the number of tails is even"" (a) $Pr(A) = Pr(B)$ (b) $Pr(A) < Pr(B)$ (c) $Pr(A) > Pr(B)$ The answer is (a) . My initial understanding was that, the numbers $1$ to $5$ consist of $1, 2, 3, 4, 5$. There are $3$ odd numbers and $2$ even numbers. So $Pr(A) > Pr(B)$.","['probability', 'discrete-mathematics']"
2662342,"Is there a typo on this remark? Should it be $(\bar u,\bar v)$ instead of $(u,v)$?","I'm working through a text that provides an introduction to differential geometry, and the author writes the following in one of the demonstrations: (...) Let $X(u,v) = (x(u,v), y(u,v),z(u,v))$ be a regular parameterized surface and let $\overline{X}(\overline{u}, \overline{v}) = X \circ h=X(h(\overline{u}, \overline{v}))$ be a reparametrization of $X$, denoting by $(u,v) = h(\overline{u}, \overline{v})$ (...) I believe there is a typo, and the following would be correct: (...) Let $X(u,v) = (x(u,v), y(u,v),z(u,v))$ be a regular parameterized surface and let  $\overline{X}(\overline{u}, \overline{v}) = X \circ h=X(h(\overline{u}, \overline{v}))$ be a reparametrization of $X$, denoting by $\color{red}{(\overline{u}, \overline{v})} = h(\overline{u}, \overline{v})$ (...) Since taking $(u,v) = h(\overline{u}, \overline{v})$ then $\overline{X}(\overline{u}, \overline{v}) = X \circ h = X(u,v)$, the same parametrization! And this would be rather pointless. I haven't provided further context because I don't think it's necessary (if it is I'll do so, though).","['notation', 'differential-geometry', 'surfaces']"
2662508,Equivalence of Two Norm and Infinity Norm,How could you show that: $$\|x\|_\infty \le \|x\|_2 \le \sqrt{n} \|x\|_\infty. $$ I was able to show the left hand side but got stuck showing the right hand side. What would be the best way to approach it? For the LHS: $$\|x\|_\infty = \max\limits_{j}|x_j| \le \sqrt{\sum_i {x_i^2}} = \|x\|_2 $$ .,['linear-algebra']
2662602,Stuck trying to prove that $A\cup(\overline{A}\cap B)= A \cup B $,I am a beginner in set theory and would like to prove exactly that: $$A\cup(\overline{A}\cap B)= A \cup B $$ I'm stuck here and I can't find alternative solutions i) $$\Omega\cap(A\cup B)= A \cup B $$    where $\Omega$ is the universal set ii) $$(A\cup\overline{A})\cap(A\cup B)= A \cup B $$ iii) $$((A\cup\overline{A})\cap A)\cup((A\cup\overline{A})\cup B)= A \cup B $$ iv) $$((\Omega\cap A)\cup((A\cup\overline{A})\cup B)= A \cup B $$ v) $$(A\cup((A\cup\overline{A})\cup B)= A \cup B $$,['elementary-set-theory']
2662639,Ordinary Differential Equation with 3 unknowns,"Solve the IVP system $\displaystyle{\begin{cases}x_1'=3x_1-4x_2+4x_3\\x_2'=4x_1-5x_2+4x_3\\x_3'=4x_1-4x_2+3x_3\\x_1(0)=2,\ x_2(0)=1,\ x_3(0)=-1\end{cases}}$ I am having trouble solving this. I know one method involves finding the eigenvalues and eigenvectors but is there not a method without using linear algebra and eigenvalues?","['ordinary-differential-equations', 'linear-algebra']"
2662676,Numerical methods for 2nd order non-linear ODE $\ddot y=f(x)$ where $f$ is unknown,"Say we have a simple 2nd order non-linear ODE $\ddot y=f(x)$. We don't know what $f$ is but have several known data points $(x_1,f(x_1)),...,(x_n,f(x_n))$. Could you help suggest numerical methods (esp. iterative algorithms ) to numerically estimate $y$? Any suggestion is helpful, including classic ones and new methods in recent researches. Thanks!","['numerical-linear-algebra', 'numerical-methods', 'ordinary-differential-equations']"
2662694,$xy'=y\ln(xy)$ differential equations,"I am really struggling with this problem. This section of my book is about solutions of differential equations through substitutions. We were taught about three methods of substitution in this section. 
The first about Homogeneous equations. where you have something like 
$$ M(x,y) + N(x,y) = 0$$
and 
$$M(tx,ty) = t^\alpha *M(x,y)\; and\; N(tx,ty) = t^\alpha *N(x,y)$$ then using the substitution u=y/x or v=x/y the other method we learned was Bernoullis equation where you have the DE in the form 
$$\frac{dy}{dx}+P(x)y = f(x)y^n$$ and the last we learned of was Reduction to separation of variables. Where you have $$\frac{dy}{dx}=f(Ax+By+C)$$ and you use subsitutions The problem states determine an appropriate substitution and solve
$$xy'=yln(xy)$$
I found an answer on yahoo answers but I am lost in the steps. https://answers.yahoo.com/question/index?qid=20150420091352AA9lvDl The answer given is the same as the correct answer. Can anyone explain the steps especially the part where it transitions from $$xydu=xdy+ydx = y(u+1)dx$$ or tell me another approach.Thank you Edit:
My teacher has told me that this problem was not of three types I mentioned above, which was confusing me as I was set on it having to be one of them. Thank you everyone for your time and solutions.",['ordinary-differential-equations']
2662707,"When I have 2 variables and 2 base cases, can I use mathematical induction multiple times to form a proof?","My textbook is asking me to prove this statement about the Fibonacci numbers: $$F_{m+n} = F_{m} F_{n+1} + F_{m-1} F_{n}, \qquad \text{given that }m \geq 1, n \geq 0.$$ TL,DR : Can I prove this by mathematical induction on m, and then on n, separately? In more detail: I think I'm supposed to expand this out using the closed-form equation $$F_k = \frac{\varphi^k - \hat\varphi^k}{\sqrt{5}}$$ since that's what the chapter is on, after all, but I can't help but feel that if I did the following variant on mathematical induction, Prove the base case where $m=1$ and $n=0$, Prove that the case of $m, n=0$ implies the case of $m+1, n=0$, and Prove that the case of $m=1, n$ implies the case of $m=1, n+1$. I would still have a valid proof on my hands. I've shown that the cases can expand ""outwards"" in two directions, so to speak, and so they should be able to be composed together to show that the $m, n$ case implies the $m+1, n+1$ case in general. On the other hand, I feel like there's a subtlety that makes that not a good strategy that I'm not seeing here. Since I ""know"" a proof exists (because this is a textbook problem), doing that without understanding whether it applies in general could be a false step.","['combinatorics', 'fibonacci-numbers', 'induction', 'discrete-mathematics']"
2662732,Having difficulty in evaluating limit of the product,I am trying to solve past year exam problem. I need to show that $\lim _{n\to \infty }\left(\left(1+\frac{1}{n^4}\right)\left(1+\frac{2^4}{n^4}\right)^{1/2}\left(1+\frac{3^4}{n^4}\right)^{1/3}..\left(2\right)^{1/n}\right)= e^{\pi^2/32}$. I am completely stucked. I need help to solve this problem. Thanks,"['real-analysis', 'riemann-integration', 'limits']"
2662792,Finding a Galois extension of the rationals whose Galois group is isomorphic to $\mathbb{Z}_3 \oplus \mathbb{Z}_3$,"I'm looking for a Galois extension $F$ of $\mathbb{Q}$ whose associated Galois group $\mbox{Gal}(F, \mathbb{Q})$ is isomorphic to $\mathbb{Z}_3 \oplus \mathbb{Z}_3$. I'm wondering if I should just consider some $u \notin Q$ whose minimum polynomial in $Q[x]$ has degree 9. In that case we'd have $[\mathbb{Q}(u) : \mathbb{Q}] = 9$ and thus $|\mbox{Gal}(\mathbb{Q}(u), \mathbb{Q})| = 9$ (assuming the extension is Galois). But since there are two distinct groups of order 9 (up to isomorphism), I'm not sure that this will yield the desired result.","['abstract-algebra', 'galois-theory']"
2662809,Proof for $f(x)=e^x+x$ strictly increasing,"I am asked: Let $f:\mathbb{R} \to \mathbb{R}$ be given by $f(x)=e^x+x$. Prove that $f$ is strictly increasing. That is to say, prove that for any $a,b\in \mathbb{R} $ 
     $$(a<b)\implies (e^{a}+a<e^{b}+b)$$ Here's my attempt: For any $a,b\in \mathbb{R}$, assume that $a<b$, i.e. $b=a+c$ for some $c\in \mathbb{R}^+$. Then, $e^a+a<e^b+b\implies e^a+a<e^{a+c}+(a+c)\implies e^a+a<e^a*e^c+a+c\implies e^a<e^a*e^c+c\implies 1<e^c+\frac{c}{e^a}\implies 0<e^c+\frac{c}{e^a}-1$. Since $c\in \mathbb{R}^+,e^c>1$. Therefore, $0<e^c+c$ is true for $c\in \mathbb{R}^+$. Thus, the original implication is true, so the function $f$ is strictly increasing. $\blacksquare$ Did I miss anything? Thanks!","['functions', 'proof-verification']"
2662820,Derivative of $\sin(x)$ issues,"$$\frac{d}{dx} \sin(x) = \lim_{h\to 0} \frac{\sin(x+h) - \sin(x)}{h}$$ $$\frac{d}{dx} \sin(x) = \lim_{h\to 0} \frac{\sin(x)\cos(h) + \cos(x)\sin(h) - \sin(x)}{h}$$ $$\frac{d}{dx} \sin(x) = \sin(x)\lim_{h\to 0} \frac{\cos(h) -1}{h} + \cos(x)\lim_{h\to 0} \frac{\sin(h)}{h}$$ Normally I'd use L'Hopital's Rule here but considering that I'm trying to find the derivative in the first place, that kind of defeats the purpose. Is there an easier way to approach these limits? I'm not seeing anything obvious.","['derivatives', 'limits', 'trigonometry', 'calculus', 'proof-explanation']"
2662822,How do I parametrise the surface $x^2 + y^2 + z^2 -2x =0$?,How do I parametrise the surface $x^2 + y^2 + z^2 -2x =0$? This is the beginning of a question where we have to work out a tangent plane at a point. I understand the rest of this method but somehow cannot work out how to parametrise tricky surfaces. The other surfaces we have to parametrise are $x^2 + y^2 - z^2 = 2y + 2z$ where $−1 ≤ z ≤ 0$ and $(4 − x^2 + y^2)^2 + z^2 = 1$. Obviously I don't expect someone to parametrise all these surfaces for me but any help would be appreciated!,"['multivariable-calculus', 'surfaces']"
2662849,Image of a closed set is closed under bounded linear transformation between Banach spaces?,"Let $A,B$ be Banach spaces and let $T:A \to B$ be a surjective, bounded, linear operator. Let $A_1$ be a non-empty subset of $A$, then: $T(A_1)$ is closed if and only if $A_1+ \textrm{ker}(T)$ is closed. I have shown that if $A_1+ \textrm{ker} (T)$ is closed, then $T(A_1)$ is closed, but am unsure of how to proceed in the other direction. Note that we know that $T(A \setminus [A_1 + \textrm{ker}(T)]) = B \setminus T(A_1)$. Figured the reverse direction could be proved using some modification of the Open Mapping Theorem or Closed Graph theorem, but not sure how to tackle this. Thanks.","['functional-analysis', 'banach-spaces', 'open-map']"
2662859,Proof of $f(x)=e^x+x$ injective,"I am asked: Let $f:\mathbb{R} \to \mathbb{R}$ be given by $f(x)=e^x+x$. Prove that $f$ is injective. Here's my attempt: Proof: (Contrapositive) Assume $x_1,x_2\in \mathbb{R}, x_1\neq x_2$. So if $x_1\neq x_2$, then either $x_1<x_2$ or $x_2<x_1$. If $x_1<x_2$, then $x_2=x_1+a$ for some $a\in \mathbb{R}^+$. Thus, $e^{x_1}+x_1<e^{x_1+a}+(x_1+a)\implies e^{x_1}+x_1<e^{x_1}*e^a+x_1+a\implies \frac{e^{x_1}}{e^{x_1}}<\frac{e^{x_1}*e^a}{e^{x_1}}+\frac{x_1}{e^{x_1}}\implies 1<e^a+\frac{x_1}{e^{x_1}}\implies 0<e^a+\frac{x_1}{e^{x_1}}-1$. Since $a\in \mathbb{R}^+$, $e^a\in \mathbb{R}^+,e^a>1$. Thus, this inequality must be true, so when $x_1<x_2$, $e^{x_1}+x_1<e^{x_2}+x_2\implies f(x_1)\neq f(x_2)$. Alternatively, if $x_2<x_1$, then $x_1=x_2+b$ for some $b\in \mathbb{R}^+$ Thus, $e^{x_2}+x<e^{x_2+b}+(x_2+b)\implies e^{x_2}+x_2<e^{x_2}*e^b+x_2+b\implies 1<e^b+\frac{x_2}{e^{x_1}}\implies 0<e^b+\frac{x_2}{e^{x_2}}-1$. Since $b\in \mathbb{R}^+$, $e^b\in \mathbb{R}^+,e^b>1$. Thus, this inequality must be true, so when $x_2<x_1$, $e^{x_2}+x_2<e^{x_1}+x_1\implies f(x_1)\neq f(x_2)$. In either case, $x_1\neq x_2\implies f(x_1)\neq f(x_2)$, which is the contrapositive of the definition of injectivity. Therefore, the function $f$ is injective. $\blacksquare$ Did I miss anything? Thanks!","['functions', 'proof-verification']"
2662889,"Definition: rational prime, rational integer","Context: In the first 4 pages of Neukirch's text algebraic number theory, there are references to 'rational primes' and 'rational integers'. These come up in the context of finding all primes and units in $\Bbb{Z}[i]$. What does this refer to? A guess: A rational prime in $\Bbb{Z}[i]$ is a prime element in $\Bbb{Z}[i]$, which is also an element of $\Bbb Q$, rather than being, say, $1+i$ (which is prime, but not a rational number). 'Rational integer' is less clear to me though, since all integers are rational. Question: What do the terms 'rational integer' and 'rational prime' actually mean.","['number-theory', 'rational-numbers', 'definition']"
2662898,Differential with sub y = ux,I am differentiating a first order DE. I want to use the substitution y = ux and the differential $dy = udx +xdu$. I thought $dy = u + xdu$ because $dx = x$. I thought I am differentiating with respect to x. I would appreciate any feedback. thank you,['ordinary-differential-equations']
2662931,"rank of $PQ$, rank of $QP$","Given that $m$ and $n$ are natural numbers and $m < n$. $P$ is an $n{\times}m$ real matrix, and $Q$ is an $m{\times}n$ real matrix. Then which of the following is/are not possible. a)$\;\text{rank}(PQ)=n$ b)$\;\text{rank}(QP)=m$ c)$\;\text{rank}(PQ)=m$ d)$\;\text{rank}(QP)=[(m+n)/2]$ ,where $[x]$ is defined as the smallest integer greater or equal to $x$. option a) is not possible because of the theorem $\text{rank}(PQ) \le \min\{\text{rank}(P),\text{rank}(Q)\}$. Now $[(m+n)/2] > m$, but $QP$ is an $m{\times}m$ matrix, so option d) should not be possible. The answer is given only option a). Am I doing any mistake for option d).",['matrices']
2662957,Is the definition of the following set controversial: $\{x\mid x\in \mathbb N \space \space x \text{ can be described in less than 30 words}\}$,"Is the definition of the following set: $$\{x\mid x\in \mathbb N \space \space x \text{ can be described in less than 30 words}\}$$ problematic? I for one don't see a problem with it, the set is finite and a formula could be written in set theory to describe every such number. Since $x\in \mathbb N$ a ""set of all sets"" monstrosity can't be built. There is somewhat ambiguity as to what counts as mathematical language, but I see no other problem. Is this correct or can a contradiction somehow be derived?","['number-theory', 'elementary-set-theory']"
2662992,Let $M\subset l^{\infty}$ be the subspace of $\; l^{\infty}$ consisting of all sequences $(x_{i})$ with at,"Please let me know if the solution to the following problem is true. Just a hint can be enough. Problem : Let $M\subset l^{\infty}$ be the subspace of  $\; l^{\infty}$ consisting of all sequences $(x_{i})$ with at most finitely many nonzero terms. Find a Cauchy sequence in $M$ which does not converge in $M$, so that $M$ is not complete. What I have done : Define 
  $x_{n}=\{1,\frac{1}{2},\cdots , \frac{1}{n},0,0,\cdots\}$
  So we have for any m\leq n,
  $$ d(x_{n},x_{m})=\vert x_{n}-x_{m}\vert= \{ 0,\cdots,0,\frac{1}{m+1},\dots, \frac{1}{n},0,\cdots\}, $$
  so we see that $d(x_{n},x_{m})\to 0\; $ as $\;m,n\to\infty.$
  Therefore, ${x_{n}}$ is a Cauchy sequence. On the contrary, $x_{n}\to x$ as $n\to \infty,$ where $x=\{1,\frac{1}{2},\cdots , \frac{1}{n},\frac{1}{n+1},\cdots\}$ which does not belong to $M.$","['real-analysis', 'cauchy-sequences', 'complete-spaces', 'functional-analysis', 'analysis']"
2663001,Making Sense of the Exponential Distribution and the Probability Density Function,"I read that, due to the memoryless property of exponential distributions, the distribution should be used when the rate of an event is constant during the entire period of time. An example would be the rate of failure for transistors over a number of hours. But wouldn't this constant rate of an event occurring over time result in a probability density function (PDF) that is a horizontal line? And as such, isn't this incompatible with the exponential PDF desired for exponential distributions? I'm trying to look at the graphs for exponential distributions (and, thus, their PDF) and reconcile this with the theory I'm reading. I would greatly appreciate it if people could please take the time to clarify this.","['exponential-distribution', 'probability-theory', 'density-function', 'probability-distributions']"
2663016,"Determine $n$ so that the difference between the $n$-th Taylor-polynomial of $\sin(x)$ with $x_0=0$ and $\sin(x)$ on $[-3,3]$ is at most $10^{-6}$?","$\sin(x)$ can be expressed as a power series: $$\sin(x)=\sum_{n=0}^\infty (-1)^n\frac{x^{2n+1}}{(2n+1)!}$$ How can I determine how large $n$ has to be, so that the difference between the $n$-th Taylor-polynomial of $\sin(x)$  with $x_0=0$ and $\sin(x)$ on $[-3,3]$ is at most $10^{-6}$? I should use the Lagrange-remainder to answer this question:
$$R_n(x,x_0)=\frac{f^{n+1}(\xi)}{(n+1)!}(x-x_0)^{n+1}$$","['real-analysis', 'taylor-expansion', 'functions', 'calculus', 'analysis']"
2663039,Stability of Euler's Method for non-linear ODE,"Consider the ODE
$$y'(t) = \lambda y(t), \quad y(t_0) =y_0.$$
Euler's method $y_{i+1}=y_i+h\lambda y_i $ is stable (meaning that the solution decays or stays constant as $ i \to \infty$) provided that $ |1 + h\lambda| \leq 1 $. This idea can be extended to systems of $n$ dimensions by placing a similar condition on the maximum coefficient instead of just $\lambda$. This question is about non-linear, $n$ dimensional systems. Under what conditions is Euler's method stable for the system $$\mathbf{y}'(t)=\mathbf{F}(\mathbf{y}(t)), \quad \mathbf{y}(t_0)= \mathbf{y}_0$$? I suspect this will involve the Jacobian of the non-linear term. The only resource I've found is on slide 18 of these lecture slides , but the notation isn't explained (what is $l_{k+1}$?). It was probably introduced in a previous lecture. The integral of the Jacobian that appears here is interesting, it looks like some kind of weighted average between the numerical and the true solution. Where does this come from?","['numerical-methods', 'ordinary-differential-equations', 'linearization']"
2663066,How does Axiom of Dependent Choice imply this weaker variant?,"Here is the excerpt from the textbook A Course in Mathematical Analysis by Prof D. J. H. Garling. So I have the Theorem 1 : Given a set $A\neq\varnothing$, a mapping $\varphi:A\to P(A
)\setminus \{\varnothing\}$, and $\bar{a}\in A$. Then there exists a sequence

$$(a_{n})_{n\in \mathbb{N}}$$

such that $a_{0}=\bar{a}$ and $a_{n+1}\in \varphi(a_{n})$ for all $n\in \mathbb{N}$ Axiom of Choice : Given a collection $A$ of nonempty sets, there exists a function

$$c: A \to \bigcup_{A_{i} \in A}A_{i}$$

such that $c(A_{i})\in A_{i}$ for all $A_{i} \in A$. Axiom of Dependent Choice : Given a nonempty set $A$ and a binary relation $\mathcal{R}$ on $A$ such that for all $a\in A$, there exists $b\in A$ such that $a\mathcal{R}b$. There exists a sequence

$$(a_{n})_{n\in \mathbb{N}}$$

such that $a_{n}\mathcal{R}a_{n+1}$ for all $n \in \mathbb{N}$. The author states that The axiom of dependent choice
states that this [Theorem 1] is always possible . But I can only infer Theorem 1 from Axiom of Choice , not from Axiom of Dependent Choice . Below is how I did it. Using Axiom of Choice for the collection $P(A)\setminus \{\varnothing\}$ of nonempty sets, then there exists a choice function $$\varphi':P(A)\setminus \{\varnothing\} \to A$$ such that $\varphi'(X)\in X$ for all $X\in P(A)\setminus \{\varnothing\}$. Let $\bar{\varphi}=\varphi'\circ \varphi:A\to A\implies\bar{\varphi}(a)=\varphi'(\varphi(a))\in \varphi(\bar{a})$ for all $a\in A$ To sum up, we have $\bar{\varphi}:A\to A$ and $\bar{a}\in A$. Applying Recursion Theorem, we get a sequence $$(a_{n})_{n\in \mathbb{N}}$$ such that $a_{0}=\bar{a}$ and $a_{n+1}=\bar{\varphi}(a_{n})\in\varphi(a_{n})$ for all $n\in \mathbb{N}$.

So this $(a_{n})_{n\in \mathbb{N}}$ is the required sequence. I would like you to check my above proof and check whether it is possible for Axiom of Dependent Choice to imply Theorem 1 . Many thanks for your help!","['elementary-set-theory', 'axiom-of-choice']"
2663073,Reference Request: Infinite-Dimensional Analysis,"I am aware that there is a whole lot of literature out there on the expansive field of infinite-dimensional analysis . Moreover, almost every book I've glanced at so far seems to have a different focus than the next one. Specifically, I am interested in the study of maps $f: M \to H$, where $M$ is a finite-dimensional manifold and $H$ is a Hilbert space (or a Banach space). Here are some concrete topics that I want to learn more about a) Fréchet-Derivatives (generalizing total derivatives), Gateaux-Derivaties (generalizing directional derivates), their connection, and the infinite-dimensional analogue of classic theorems such as the Mean-Value Theorem or Schwarz' theorem . b) (This is most important to me) Differential forms over $M$ with values in $H$, the corresponding concept of exterior derivative on such forms, integrating $k$-forms over $k$-dimensional embedded submanifolds (via the Bochner Integral ) and a generalization of Stokes Theorem . Does anybody know a good reference for this ?","['reference-request', 'differential-topology', 'differential-geometry', 'hilbert-spaces']"
2663152,Convergence of $1+\frac13-\frac12+\frac15+\frac17-\frac14+\frac19+\frac1{11}-\frac16+\ldots$,"I was reading Rudin PMA, example 3.53 on P76. There he points out that rearrangement may not give same limit of a series. Then he says that it is left as exercise to show that above mentioned series converges. I thought clubbing three terms, but did not seem 'legal'. How to show that series $1+\dfrac13-\dfrac12+\dfrac15+\dfrac17-\dfrac14+\dfrac19+\dfrac1{11}-\dfrac16+\ldots$ converges? I tried root test: Let this series be $\sum_{n=1}^{\infty}a_n$, then $\limsup\limits_{n\to\infty}\sqrt[n]{|a_n|}=1$, since basically, this series is rearrangement of $\sum \frac {(-1)^n}n$. So root test is inconclusive.","['real-analysis', 'sequences-and-series']"
2663167,Simplifying $\frac{6\tan x }{1-\tan^2 x}$ to $3 \tan 2x$,"How do I perform the following simplification?
  $$\frac{6\tan x }{1-\tan^2 x} \qquad\to\qquad 3 \tan 2x$$ I tried to take a common factor from denominator then use the laws of trigonometry, but I got nothing. Please explain the steps.",['trigonometry']
2663265,What is the value of $\sin^2 (\frac{\pi}{10}) \sin^2 (\frac{3\pi}{10})$?,"PROBLEM $$ \prod_{i=0}^4 \left(1 + \cos \left(\frac{(2k+1)\pi}{10}\right)\right)$$ My Try $$
\left(1 + \cos \frac{\pi}{10}\right)
\left(1 + \cos \frac{9\pi}{10}\right)
\left(1 + \cos \frac{7\pi}{10}\right)
\left(1 + \cos \frac{3\pi}{10}\right)
= \sin^2 \left(\frac{\pi}{10}\right)
  \sin^2 \left(\frac{3\pi}{10}\right)
$$ I am not able to proceed further. 
Please help me.","['products', 'trigonometry', 'fractions']"
2663288,"What is the approach to showing the differentiability of $F(s,f) = \int_{0}^{1}f(x+s)g'(x)dx$?","Let $E$ be the set of functions $f: \mathbb{R} \rightarrow \mathbb{R}$, that are $\mathcal{C}^1$ and such that $\forall x \in \mathbb{R}$, $f(x+1)=f(x)$. Let $g \in E$ and $F: \mathbb{R} \times E \rightarrow \mathbb{R}$ such that $$F(s,f)= \int^{1}_{0}f(x+s)g'(x)dx $$
  Show that $F$ is $\mathcal{C}^1$. Now, I found this exercise in past terms exams, so it might be possible that in order to solve it I require some notions that I haven't seen yet in my course. Anyway, I wonder, how should I approach this exercise? Is there a way to apply the Leibniz integral rule?","['derivatives', 'real-analysis', 'differential', 'partial-derivative', 'integration']"
2663299,Different ways of solving inequation - different solutions?,"After 'solving' the following exercise, I entered the solution in a website that gave me the graph and I noticed that It wasn't the same as the solution it gave me for the 'original' inequation. The inequation is: $5-\frac{4-5x}{2}<3\left(2x-1\right)$ And I solved it like: 1)
 $\frac{10-4+5x}{2}*\frac{1}{2x-1}<3$ 2)
$\frac{6+5x}{4x-2}-\frac{3(4x-2)}{4x-2}<0$ 3)
$\frac{12-7x}{4x-2}<0$ Then I solved it and I got: Solution= $]-\infty ,\frac{1}{2}[ U [\frac{12}{7},+\infty[$ But, it's wrong , it should be: $[\frac{12}{7},+\infty[$ I then did the exercise in a different way: 1) $\frac{6+5x}{2}-3(2x-1)<0$ 2)$\frac{6+5x}{2}-\frac{2*3(2x-1)}{2}<0$ 3)$\frac{12-7x}{2}<0$ And the result is now the correct one: $[\frac{12}{7},+\infty[$ Can someone explain me why there are these differences between the first way of solving and the second one?","['algebra-precalculus', 'inequality']"
2663349,How to determine if a ray intersects a wedge in 2d space,"Assume that I have a ray in 2d space Assume that I am given a point in this 2d space $P = (p_x, p_y)$ Assume that I have an area $A$ defined as follows: The area is bounded by a minimum distance $r_{min}$ and maximum distance $r_{max}$ from point $P$ The area is bounded by a minimum angle $\theta_{min}$ and maximum angle $\theta_{max}$ around the point $P$ How do I find if the ray intersects the area $A$? EDIT: After a quick google, the shape that the area $A$ forms is similar to python's matplotlib wedge shape, which looks like some of these examples: EDIT: This is not required to answer the question, but my work requires me also to find the section of the ray that is inside of $A$, if there is an intersection.  Finding this will net you brownie points.",['geometry']
2663374,"Find $\lim_{x\to \infty} \left[f\!\left(\sqrt{\frac{2}{x}}\,\right)\right]^x$.","Let $f:\mathbb{R} \to \mathbb{R}$ be such that $f''$ is continuous on $\mathbb{R}$ and $f(0)=1$ ,$f'(0)=0$ and $f''(0)=-1$ . Then what is $\displaystyle\lim_{x\to \infty} \left[f\!\left(\sqrt{\frac{2}{x}}\,\right)\right]^x?$ When I was solving this problem, I supposed $f(x)$ to be a polynomial of degree two (because $f''$ is continuous) i.e. $f(x)=ax^2+bx+c$ and found coefficients with the help of given values . I got $f(x)=\frac{-x^2}{2} +1$. After solving , I found limit to be $e^{-1}$. I know this is a particular case. Questions $1$ : Will the limit be same for all functions with these properties ? $2$ : Please give me some method which works for all such $f(x)$. $3$: I want to practice more questions of this kind, please give me some references i.e. books, problem books, any online source. Any kind of help will be highly appreciated. Thanks!","['reference-request', 'real-analysis', 'calculus']"
2663379,How to compute $\int_{0}^{1}x\sin (bx) J_0\!\!\left(a\sqrt{1-x^2}\right)\!\mathrm dx$?,"I need a help with integral below, $$\int_{0}^{1}x\sin (bx) J_0\left(a\sqrt{1-x^2}\right)\,\mathrm dx$$ where $a \geq 0$ and  $b$ are constants and $J_0(x)$ is the zeroth-order of Bessel function of the first kind. This integral has a closed form solution ? I found some integrals similar to the integral above, but I don't have any idea on how to apply it. I found this integral expression below on Gradshteyn and Ryzhik's book 7th edition, section 6.677, number 6: $$\int_{0}^{a} \cos (cx)J_0\left(b\sqrt{a^2-x^2}\right)\,\mathrm dx = \frac{\sin (a\sqrt{b^2+c^2})}{\sqrt{b^2+c^2}} \quad [b\geq 0]$$ I try use the definition of zeroth-order of Bessel function of the first kind to solve this integral: $$J_0(z) = \sum_{k=0}^\infty (-1)^k\frac{(\frac{1}{4}z^2)^k}{(k!)^2}$$ then i found: $$J_0(a) \sum_{k=0}^\infty \int_{0}^{1}x\sin (bx)\left(1-x^2\right)^k\,\mathrm dx $$ On Wolfram Alpha i found that: $$\int_{0}^{1}x\sin (bx)\left(1-x^2\right)^k\,\mathrm dx = \frac{1}{4}\sqrt{\pi}a\Gamma (k+1)\tilde{F}_1\Big(;k+\frac{5}{2};-\frac{a^2}{4}\Big)$$ where $\tilde{F}_1$ is the Regularized Hypergeometric Function , where: $$\tilde{F}_1\Big(;k+\frac{5}{2};-\frac{a^2}{4}\Big) =  \frac{J_{k+\frac{3}{2}}(a) }{(\frac{a}{2})^{k+\frac{3}{2}}}$$ therefore: $$\int_{0}^{1}x\sin (bx) J_0\left(a\sqrt{1-x^2}\right)\,\mathrm dx = J_0(a)\frac{1}{4}\sqrt{\pi}a \sum_{k=0}^\infty \Gamma (k+1) J_{k+\frac{3}{2}}(a)\Big(\frac{a}{2}\Big)^{-(k+\frac{3}{2})} $$ The solution found above is right ? Thanks in advance.","['bessel-functions', 'integration']"
2663426,General circle identity proof,"I very much suspect this is true but I don't have a proof of it. Take a circle of radius $R$. Pick a point $P$ in the circle, a distance $d$ from the center of the circle. From $P$, extend $N$ ($N>1$) line segments equally-angularly-spaced connecting $A$ to the circle (orientation relative to the circle is irrelevant) (see the figure). The geometric mean of the lengths of the $N$ segments is always $\sqrt{R^2-d^2}$, irrespective of $N$ or how the segments are oriented relative to the circle. Does anyone know how to prove this? It seems like such a fundamental and general theorem but I haven't been able to find anything.","['euclidean-geometry', 'geometry']"
2663442,Taylor expansion for vector fields on manifolds,"I have a problem to proof this theorem:
""Lex $X$ a vector field in a differentiable manifold $M$ and $f\in\mathcal{C}^\infty(M\to R)$ $\Rightarrow$ for all $k\in\mathbb{N}$ the map $f\circ\Phi_X^t$ is globally defined on the manifold if the flow $\Phi_X^t$ is complete; alternatively the map is defined in an opportune set $D_t(X)$ and  $f\circ\Phi_X^t=f+tX(f)+ \dfrac{t^2}{2}X^2(f)+...+ \dfrac{t^k}{k!}X^k(f)+O(t^{k+1}).""$ Where $X^k$ is $k$-application of $X$ to $X$. I have a problem to prove by induction that $\dfrac{d^k}{dt^k}(f\circ\Phi_X^t(p))|_t=(X^k(f(\Phi_X^t))$ in a neighbourhood of $0$. For $k=1$ the assertion in prooved because $\dfrac{d}{dt}(f\circ\Phi_X^t(p))|_t=(\Phi_X^t)_{\star,t}(\dfrac{d}{dt}|_t)(f)=(X(f(\Phi_X^t))$, where the last equality follows from the fact that the flow is the unique solution of the Cauchy's problem $\begin{cases}(\Phi_X^t)_{\star,t}(\frac{d}{dt}|_t)(f)=X(f(\Phi_X^t)) & \\ \Phi_X^0=p
\end{cases}.$ Supposed true for $n-1$, when i prove for $n$ I have this: $\dfrac{d^k}{dt^k}(f\circ\Phi_X^t(p))|_t=\dfrac{d}{dt}(\dfrac{d^{k-1}}{dt^{k-1}}(f\circ\Phi_X^t)|_t)|_t=\dfrac{d}{dt}(X^{k-1}(f(\Phi_X^{t-1})))|_t$ in a neighbour of $0$. How to complete this? Is possible that I have to use this theorem: ""Let $f:M\to N$ a differentiable map between two differentiable manifolds, $X$ a vector field on $M$ and $Y$ a vector field on $N$ such that $Y(f(q))=f_{\star,q}(X(q))$ $\forall q\in M$. If $f\circ\Phi_X^t$ is an integral curve of $X$ $\Rightarrow f\circ\Phi_X^t $ is an integral curve for $Y$ and in particular $f\circ\Phi_X^t=\Phi_Y^t\circ f.""$ If the answer is yes, how can I show that $X^{k-1}(f(\Phi_X^t))$ is an integral curve for $X$? I do not found a book with this generalized Taylor formula to manifold.","['vector-fields', 'taylor-expansion', 'smooth-manifolds', 'differential-geometry']"
2663460,The hopf fibration is a submersion.,"Let $F:\mathbb{S}^{3}\to \mathbb{S}^{2}$, where $F(x,y,u,v)=(2.(xu+yv),2.(xv-yu),,u^{2}+v^{2}-x^{2}-y^{2})$. A submersion has a rank equal to dimension of codomain, then the work is prove that $rank F=2$. In my notes the author prove that there exists a minor with ordem $3$ with determinant non-zero, but i don't understand this, because in my definition i should prove that there exist a minor with order two with non-zero determinant and every minor with order $3$ has determinant zero. Lastly, there exists a way to prove that $F$ is a submersion without calculate the Jacobian?","['spheres', 'smooth-manifolds', 'differential-geometry', 'differential-topology']"
2663489,Holomorphic function is injective,"Let $f:\Omega \rightarrow \mathbb{C}$ be a holomorphic function where $\Omega:=\{z\in\mathbb{C}; -1<Re(z)<|Im(z)|\}$ (i.e. $\Omega$ is open, connected, non-convex). If $|f'(z)-1|<1/4$ then $f$ is injective on $\Omega$. PS.:
1)It is obvious that it is gonna be locally injective since $f'(z)\neq 0$, $\forall z\in\Omega$ (using b)... but how can I guarantee that it is gonna be for whole $\Omega$? 2) If $\Omega$ is convex it is trivial: In fact, suppose that $a\neq b$ s.t $f(a)=f(b)$. So, consider the straight line $\gamma$, connecting $a$ to $b$, i.e. $\gamma:[0,1]\rightarrow \Omega$ is defined as $\gamma (t)=a+(b-a)t$. Since $\Omega$ is convex, this line lies in $\Omega$ and so $f$ is holomorphic here. Thus, $0=f(b)-f(a)=\displaystyle\int_{\gamma}f'(z)dz=\int_{0}^{1}f'(\gamma(t))\gamma'(t)dt=\int_{0}^{1}f'(a+(b-a)t)(b-a)dt$ As $(b-a)\in\mathbb{C}^{*}$ is just a constant (non-zero since $a\neq b$, by assumption). We have: $\displaystyle0=\int_{0}^{1}f'(a+(b-a)t)dt$ $\Rightarrow \displaystyle -1=\int_{0}^{1}(f'(a+(b-a)t)-1)dt $ (adding (-1) both sides). Now, Taking the module, we have $1=\displaystyle|\int_{0}^{1}(f'(a+(b-a)t)-1)dt|\leq \int_{0}^{1}|(f'(a+(b-a)t)-1)|dt<\int_{0}^{1}\frac{1}{4}dt=\frac{1}{4}$ (we have to use the assumption here for the last inequality). So, $1<\frac{1}{4}$, Contradiction. Therefore, $f(a)\neq f(b)$, i.e. $f$ is injective. $\square$ $\Omega$:","['complex-analysis', 'analytic-functions', 'holomorphic-functions', 'complex-integration']"
2663523,Convergence of $\sum_{n=1}^{\infty} \frac{{i}^{3^n}}{n}$,"I’m given a problem for homework and I want to as how to solve it: does the following sum converge? $$\sum_{n=1}^{\infty} \frac{{i}^{3^n}}{n}$$ It converges since ${i}^{3^n} $ is $-i, \space i, \space -i, \space i, \space -i, \space ...$ and it is $i (-1)^n$. So our given sum is equivalent to the sum $$i \sum_{n=1}^{\infty} \frac{ (-1)^n}{n} $$. But how can I prove without using wolfram alpha that ${i}^{3^n} \equiv i (-1)^n$ ?","['complex-analysis', 'modular-arithmetic', 'complex-numbers']"
2663592,Relative Abelian Varieties,"If $A$ is an abelian variety, we have an addition map $\mu:A\times A\to A$. Now, suppose we have a relative abelian variety $\mathcal{A}\to B$, i.e. the morphism is flat and proper and for any $b\in B$, $\mathcal{A}_b$ is an abelian variety. Can we define a morphism $\mu\colon\mathcal{A}\times_B\mathcal{A}\to\mathcal{A}$ such that it restricts to the addition map on every fibre? I think it should exist at least locally and I tried to prove its existence using base changes, but I failed. Naively, I expect that the addition maps on the fibres glue together to form such a morphism but since I cannot find a rigorous argument I start thinking that maybe it only exists locally...? To contextualise the question: I would like to define a relative Pontrjagin product on $\mathcal{A}$ and I was naively trying to understand if the easiest generalisation would work. Thank you very much!","['abelian-varieties', 'algebraic-geometry']"
2663622,Solve recurrence relation.,"I've got an recurrent function to solve. $T_1 = 1$ $T_n = 2T_{\frac n2} + \frac{1}{2}n\log n$ I've got a tip to this excercise to determine additional variable as $k = 2^n$, where $ k = 1, 2, 3, ...$ But after some calulations I'm wondering if $k=2^n$ can i say that $2^{k-1} = n - 1$ ? I recieve following equation:
$T_{2^k} = 2T_{2^{k-1}} + 2^{k-1}k*\log2$  , am i correct? What can i do next?","['recurrence-relations', 'discrete-mathematics']"
2663646,Diophantine Equation $a^6+b^6+c^6=d^6$,"Within the literature on Diophantine equations there seems to be very little on the $6,1,3$ equation: $$a^6+b^6+c^6=d^6\quad\quad(1)$$ Mathworld , for example, simply records that there are no known solutions of $6.1.n$ equations for $n \leq 6$ . The former Euler Project searching for solutions of equations in equal sums of like powers showed $6,1,5$ at the top of its most wanted list but did not mention $6,1,3$ . One way of looking at the $6,1,3$ equation is as a special case of the much more familiar $3,1,3$ equation: $$w^3+x^3+y^3=z^3\quad\quad(2)$$ in which each of the terms is also a square. It may be considered relevant that there are known solutions of $(2)$ in which two or three of the terms are square, the smallest respectively being: $$(1^2)^3 + 6^3 + 8^3 = (3^2)^3\quad\quad(3)$$ $$118^3 + (15^2)^3 + (18^2)^3 = (19^2)^3\quad\quad(4)$$ Question : Are there any discussions in the literature of either: direct strategies for searching for solutions of $(1)$ ; research seeking a proof that $(1)$ has no non-trivial solutions? By a direct strategy I mean one which addresses 6,1,3 itself, rather than one which searches for $6,1,n$ for higher $n$ with the remote possibility of finding a solution in which some of the terms are zero.  An example of a direct strategy would be to take the following parametric solution of $(2)$ : $$(9s^4)^3 + (3s(t^3-3s^3))^3 + (t(t^3-9s^3))^3 = (t^4)^3$$ which already has two square terms, and to try to find values of $s$ and $t$ such that the other two terms are also square.","['number-theory', 'reference-request', 'diophantine-equations']"
