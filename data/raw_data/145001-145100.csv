question_id,title,body,tags
2365996,Pair of straight lines as a conic section,Can someone tell me how is pair of straight lines a conic section. I know the equation is of second degree and other mathematical facts prove that. But how to visualise it? How is a pair of straight lines formed when a plane intersects a cone?,"['conic-sections', 'geometry']"
2366022,Peter Weyl theorem in $SU(2)$ : basis of $L_2[SU(2)]$,"I have a very basic question about the Peter Weyl theorem in $SU(2)$. I don't want any generalisation, I just want to basically understand what the book precisely mean here. First some explanations. The Peter Weyl theorem says that the entries of Wigner matrices form an ortogonal basis of $L_2[SU(2)]$. So this ensemble form an orthogonal basis of $L_2[SU(2)]$ : $$ \{ U \mapsto D^j_{mm'}(U) \} $$ with $U \in SU(2)$, $j$ is the spin, $m$ and $m'$ are the line and columns entries of the Wigner Matrix $D(U),$ ($-j \leq m \leq j$ and  $-j \leq m' \leq j$) . In my book it is written : What I don't totally understand is in red. I agree that $D^j(U)$ is a map from $H_j$ to $H_j$ but : Why can we say it is an element of $H_j \otimes H_j$ ? And if we admit it, we are talking about the matrices element $D_{mm'}^j(U)$ and not the map  $U \mapsto D^j_{mm'}(U)$ . In other words, on the lhs of 5.17 we have maps from $SU(2)$ to $\mathbb{C}$ and on the rhs we have linear map in a vector space (so at fixed $j$ it is map from $H_j$ to $H_j$). So, it is not the same ""kind"" of quantities and I don't understand","['representation-theory', 'group-theory', 'linear-algebra']"
2366032,convergent or divergent $\int_{-4}^{1} \frac{dz}{(z + 3)^3}$,"Question Determine whether convergent or divergent. $$
\int_{-4}^{1} \frac{dz}{(z + 3)^3}
$$ Thinking I'm not sure how best to go about this, whether I'm justified in my result. Basically I'm saying that as I can't find the first limit, the integral is divergent. I'm not sure if I should be, in some way, trying to combine the two limits (and using L'Hopitals), or if as soon as I've established that one doesn't exist the whole thing can be determined to be divergent (I think this is correct). If of one of the two limits is divergent, can I conclude that the integral is divergent? Definition If $f$ is continuous at all $x$ in the interval $[a, b]$, except maybe at $c$ ,
where $a < c < b$ , and if $\lim_{x \to c} |f(x)| = + \infty$ , then $$
  \int_{a}^{b} f(x) \mathop{dx} =
  \lim_{t \to c^- }  \int_{a}^{t}  f(x) \mathop{dx}
  + 
  \lim_{s \to c^+ }  \int_{s}^{b}  f(x) \mathop{dx}
$$ if this limit exists, otherwise it is divergent. Working The improper integral is $$
\int \frac{dz}{(z + 3)^3} = - \frac{1}{2(z + 3)^2} + C
$$ There's a discontinuity at $z = -3$ , so splitting the integral up as \begin{equation*}
  \begin{aligned}
    \int_{-4}^{1} \frac{dz}{(z + 3)^3}
    &    =
    \lim_{a \to -3^-}
    \int_{-4}^{a} \frac{dz}{(z + 3)^3}
    +
    \lim_{b \to -3^+}
    \int_{b}^{1} \frac{dz}{(z + 3)^3}  \\
    &=
    - \frac{1}{2}
    \left(
      \lim_{a \to -3^-}
      \left[
        \frac{1}{(z + 3)^2}
      \right]_{-4}^{a}
      +
      \lim_{b \to -3^+}
      \left[
        \frac{1}{(z + 3)^2}
      \right]_{b}^{1}
    \right)
  \end{aligned}
\end{equation*} The first limit, $\lim_{a \to -3^-} \left[\frac{1}{(z + 3)^2} \right]_{-4}^{a}$,
is found as \begin{equation*}
  \begin{aligned}
    \lim_{a \to -3^-} \left[\frac{1}{(z + 3)^2} \right]_{-4}^{a} &=
    \lim_{a \to -3^-} \left[\frac{1}{(a + 3)^2} - \frac{1}{(-1)^2}  \right] \\
    &= \lim_{a \to -3^-} \left[\frac{1}{(a + 3)^2} - 1   \right] \\
    &= \lim_{a \to -3^-} \left[\frac{1 - (a + 3)^2}{(a + 3)^2}   \right] \\
  \end{aligned}
\end{equation*}","['real-analysis', 'integration', 'convergence-divergence', 'calculus']"
2366033,Show differentiability of $e^{\int_0^t A(\tau)\operatorname{d}\tau}$,"Consider $A\in C(\mathbb{R},\mathcal{L}(E))$ for some Banach space $E$. For any $t\in\mathbb{R}$ $$B(t):=e^{\int_0^t A(\tau)\operatorname{d}\tau}:= \sum_k \left(\int_0^t A(\tau)\operatorname{d}\tau\right)^k/(k!)$$ is well-defined. How can I show that $B\in C^1(\mathbb{R},\mathcal{L}(E))$? Is a general result about the differentiability of $e^{f(\cdot)}$ for $f\in C^1(\mathbb{R},\mathcal{L}(E))$ possible?","['real-analysis', 'banach-spaces', 'ordinary-differential-equations', 'matrix-exponential']"
2366036,Probability puzzle about crossing lights – what is wrong with my reasoning?,"Calvin has to cross several signals when he walks from his home to
  school. Each of these signals operate independently. They alternate
  every 80 seconds between green light and red light.At each signal,
  there is a counter display that tells him how long it will be before
  the current signal light changes. Calvin has a magic wand which lets
  him turn a signal from red to green instantaneously. However, this
  wand comes with limited battery life, so he can use it only for a
  specified number of times. If the total number of signals is 2 and Calvin can use his magic
  wand only once, then what is the expected waiting time at the signals
  when Calvin optimally walks from his home to school? I was convinced that I had the right solution, but apparently I didn't but I cannot see what is wrong with my reasoning. My solution is as follows: Each light, $Y_1$ and $Y_2$ have uniformly distributed waiting times in $[0, 80]$. Basically, he has to make a decision at the first light. At the second light, he always uses the wand if it is available. I assume that he has to pick some optimal waiting time $x \in [0, 80]$ at the first light such that if $Y_1 > x$, he uses the wand. In that case, the waiting time at the first light becomes $0$. Using this reasoning, the total expected time is
$$
\mathbb E[Y_1 1_{\lbrace Y_1 \leq x \rbrace} + Y_2 1_{\lbrace Y_1 > x \rbrace}]  = \\ 
\mathbb E[Y_1 1_{\lbrace Y_1 \leq x \rbrace}] + \mathbb E[Y_2]\mathbb P(Y_1 > x )
$$
This becomes
$$
\int^x_0 \frac{1}{80}u du + 40 \frac{80-x}{80} = \frac{1}{2} \left(\frac{x^2}{80} + 80 -x \right)
$$
Then differentiating, setting to $0$, solving for $x$ and plugging it back into the expectation gives me $30$ as the answer. I have been told that this is incorrect. Where is the mistake?",['probability']
2366108,Baire Category Theorem without Completeness,"Let $(X,d)$ be a metric space. We say that $Y \subseteq X$ is dense in $X$ if for any non-empty open set $U\subseteq X,$ we have $U \cap Y \neq \emptyset.$ Baire Category Theorem states that If $(X,d)$ is a complete metric space with $(U_n)_{n \in \mathbb{N}}$ being a sequence of open dense sets in $X,$ then their intersection $\bigcap_{n \in \mathbb{N}}U_n$ is dense in $X.$ If we remove openness in the condition, then the theorem will not hold anymore, simply let $X = \mathbb{R},$ $U_1 = \mathbb{Q}$ and $\mathbb{R} \setminus \mathbb{Q}.$
Clearly $X$ is complete and $U_1$ and $U_2$ are dense in $X,$ but $U_1 \cap U_2 = \emptyset$ is not dense in $X.$ Question : Give an example such that $X$ is not complete with $(U_n)_{n \in \mathbb{N}}$ a sequence of open dense sets but their intersection $\bigcap_{n \in \mathbb{N}}U_n$ is not dense in $X.$ I have been trying to come out with an example that satisfies the question above.
Since finite dimensional space is always complete, I have to let $X$ be infinite dimensional. 
One example that comes to my mind is $C[0,1],$ the set of continuous functions on $[0,1].$ However, I do not know which set is dense in $C[0,1].$ Any hint would be appreciated.","['real-analysis', 'examples-counterexamples', 'functional-analysis', 'baire-category', 'metric-spaces']"
2366158,Locally Analytic Nullstellensatz,"On pg. 13 of Milnor's Singular Points of Complex Hypersurfaces , the author seems to be using the following statement without proof: Let $V\subseteq \mathbf C^m$ be a complex variety (that is, an irreducible algebraic set), and $f_1, \ldots, f_k\in \mathbf C[z_1,\ldots, z_m]$ be polynomials which generate the prime ideal $I(V)$. Let $h:\mathbf C^m\to \mathbf C$ be a complex analytic function which vanishes on a neighborhood of a point $p\in V$. ( Here our neighborhood is NOT taken in the Zariski topology, but in the topology induced on $V$ from the Euclidean topology on $\mathbf C^m$ ). Then some power $h^s$ of $h$ can be written as $a_1 f_1+ \cdots + a_k f_k$, where $a_1, \ldots, a_k$ are germs of analytic functions (at the point $p$). Milnor refers to this as the Locally Analytic Nullstellensatz and mentioned a book by Gunning and Rossi (pg. 90) for a proof.
Does anybody know a proof of this?","['complex-geometry', 'algebraic-geometry', 'analytic-geometry']"
2366159,When is a measure the pushforward of another measure?,"Let $(X,\Sigma)$ be a measurable space. Let $\mu$ and $\nu$ be two measures on thereon. Are there any reasonable restrictions on these measures to ensure the existence of a (measurable) function, $f: X \to X$ such that 
$$ \nu = f_*\mu$$
where $f_*\mu$ is the push forward of $\mu$ with respect to $f$, i.e., 
$$\nu(A) = \mu(f^{-1}(A))$$
for all $A \in \Sigma$. I understand this is a pretty unstructured question. Perhaps, if we require structure of $f$. For example, if $X = \mathbb{R}$ and we require $f$ to be monotone or linear?",['measure-theory']
2366181,"Suppose $x:[0,\infty) \to [0,\infty)$ is continuous and $x(0)=0 $","Suppose $x:[0,\infty) \to [0,\infty)$ is continuous and $x(0)=0 $
If $$(x(t))^2 \leq  2+\int_{0}^{t}x\left(s\right){\rm d}s .
$$  for all $t \geq 0$,
Then which of the following is true? $a$) $x(\sqrt2)\in[0,2]$ $b$) $x(\sqrt2)\in [0,\frac3{\sqrt2}]$ $c$) $x(\sqrt2) \in [\frac5{\sqrt2},\frac7{\sqrt2}]$ $d$) $x(\sqrt2)\in [10,\infty)$ I tried function $x=0$ and $x=\frac{3t}2$.
And I want to discard $a$ or $b$ ...(as I think $a$ should be wrong and $b$ is answer) not arguments like $a$ is true then $b$ should be true and only one answer can be correct so $b$ is correct.",['ordinary-differential-equations']
2366198,"Let $g:= f(x,y) ||(x,y)||^4$. Prove that $g$ is differentiable on $(0,0)$","I'm having problems with the following demonstration: let $f:\mathbb{R}^2\rightarrow\mathbb{R} $ a continuous function on $(0,0)$ and let $g:= f(x,y) ||(x,y)||^4$. Prove that $g$ is differentiable on $(0,0)$. We know by definition that the function $g$ will be differentiable on $(0,0)$ if and only if: $\lim_{(x,y)\to(0,0)}=$$\frac{f(x,y)- <\nabla g,(x,y)> - g(0,0)}{||(x,y)||}=0$ I started by finding the $\nabla g=(\frac{\partial g}{\partial x},\frac{\partial g}{\partial y})$ to could be able to construct my limit of differentiability and after prove that is  zero. But, the problem is we don't know too much about $f$. Notice that: $\frac{\partial g}{\partial x}(0,0) = \lim_{(t)\to(0)} \frac{g((0,0)+t(1,0)) -g(0,0)}{t}$ $\frac{\partial g}{\partial y}(0,0) = \lim_{(t)\to(0)} \frac{g((0,0)+t(0,1)) -g(0,0)}{t}$ Where we can easily see observing the definition of $g$ that $g(0,0)=0$. And we also know that $f(x,y)= \frac{g(x,y)}{||(x,y)||^4}$ Having said this how can I find the partial derivatives from what I know? Any hint?","['derivatives', 'real-analysis', 'limits', 'partial-derivative', 'algebra-precalculus']"
2366238,For which $z$ does $\sum_{n=1}^\infty \left[\frac {z(z+n)}{n}\right]^{n}$ converge?,"Here is one of my olympiad problem, I have to find the radius of following series
$$\sum_{n=1}^\infty \left[\frac {z(z+n)}{n}\right]^{n}$$
And here is my attempt
$$U_{n}= \left[\frac {z(z+n)}{n}\right]^{n}$$
$$U_{n+1}=\left[\frac {z(z+n+1)}{n+1}\right]^{n+1}$$ but the problem is when I take $\lim_{n\to \infty} \left|\frac {U_{n+1}}{U_{n}}\right|$ 
But it will leave me ugy terms which i cant see any good way to see the center or radius of circle , could you give me some hint ?",['complex-analysis']
2366240,Linear Independence,"I've come across a question in Linear Algebra that I can't quite figure out. I've tried a multitude of things that either don't work or aren't sufficient enough to convince me I understand linear independence well enough. I know a set of vectors, S, in vector space V are linearly independent if their linear combination, that is, $\lambda_1 \mathbf{v}_1 + ... + \lambda_n \mathbf{v}_n = \mathbf{0}$ means all scalars are equal to each other and 0, $\lambda_1 = ... = \lambda_n = 0.$ I can also show a set of vectors S is linearly independent if I'm given a set of vectors with numerical values - by creating a matrix and reducing it to row echelon form. However, my understanding isn't great enough that I can expand on this and answer questions such as the following: Assume the vectors u, v and w are linearly independent elements of a vector space V. 
For each of the following sets decide whether it is linearly independent. A. { u + v + w , v - 2 w ,  2 u + 3 w } B. { u + 2 w , v + 2 w , 2 w } C. { x, y, z } where, x = u + 2 v - w , y = 2 x + u + 2 v - w , z = 3 x - 2 y . If anyone can explain to me the connection between this type of question and the definition of linear independence by answering A or providing a guideline of how to answer A then hopefully I can tackle B and C and any related questions. Thanks.",['linear-algebra']
2366244,"Is $f$ differentiable and continuous at$ (0,0)$?","We have $f: \mathbb{R}^2 \to \mathbb{R}$ definied by: $f(x,y) =
\begin{cases}
x^2,  & \text{for $y \gt0$} \\
0, & \text{for $y =0$} \\
-x^2, & \text{for $y \lt0$} 
\end{cases}$ Is $f$  continuous and differentiable at $(0,0)$ ? How do I do that with this function? Thanks in advance!","['functions', 'real-analysis', 'calculus', 'analysis']"
2366246,Fractional Order Derivative,"A friend and I were talking about derivatives, and he asked an interesting question. Since both of us have not taken our calculus courses yet, neither of us were sure of the answer. His question has two parts: 1. can you have a fractional order derivative i.e. could you have $\frac{d^ny(x)}{dx^n}$ where, for example, $n=\frac{1}{2}$? And, 2. can you have a variable as the order of a derivative i.e. $\frac{d^ny(x)}{dx^n}$ where n=some variable? I have doubts as to whether either are even possible, but I decided to post the qestion to find out for sure.","['derivatives', 'calculus', 'fractional-calculus', 'fractional-differential-equations', 'analysis']"
2366284,What is a piecewise function in set theory (or alternative ways to describe piecewise functions)?,"I have searched, but I haven't found an answer to this question. How are piecewise functions defined in set theory? And what are alternative ways to represent them? Let's say we have a piecewise function $f:\mathbb{R}_+ \to \mathbb{R}$, that is defined by the equation $$ f(x)=
 \begin{cases} 
      x & x \in [0,3] \\
      3 & x \in (3,8] \\
      x^2 & x \in (8,\infty) 
\end{cases}
$$ The graph of this function is the set $$ \text{graph } f= \{ (x,y) \mid y=f(x), x \in \mathbb{R}_+ \}, $$ but how can I write out this set ""graph $f$"" using information from the above equation? My quess would be something like this: $$ \{ (x,y) \mid (x\in[0,3] \rightarrow y=x) \text{ or } (x \in (3,8] \rightarrow y=3) \text{ or } (x \in (8,\infty) \rightarrow y=x^2) \} $$ Is there anything else to know about piecewise functions in set theory, other than the function's graph?","['notation', 'functions', 'definition']"
2366296,Logical suite and inequalities,"This is a related problem (see here ) We have the following inequalities : For $n=3$ with $a,b,c$ real numbers the following inequality holds.
  $$\frac{1}{(a-b)^2}+\frac{1}{(c-b)^2}+\frac{1}{(a-c)^2}+(c-b)^2+(c-a)^2+(a-b)^2\geq \sqrt{54}$$ For $n=4$ with $a,b,c,d$ real numbers $$\frac{1}{(a-d)^2}+\frac{1}{(d-b)^2}+\frac{1}{(d-c)^2}+\frac{1}{(a-b)^2}+\frac{1}{(c-b)^2}+\frac{1}{(a-c)^2}+(d-b)^2+(c-d)^2+(a-d)^2+(a-b)^2+(b-c)^2+(a-c)^2\geq \sqrt{288}$$ If we continue with $n=5,6,7\cdots$ there is a logical suite but I don't know how to prove this and what is the following numbers .
Thanks.","['contest-math', 'real-analysis', 'inequality']"
2366299,What does Cramer's Theorem tell us?,"Cramer's Theorem States, Let $(Y_i)_{i\geq 1}$ be a sequence of i.i.d. random variables, ${S_n=\frac{1}{n}\sum_{i=1}^n Y_i}$ be their average sum and $M_{Y_1}(u):=\mathrm{E}[e^{uY_1}]<\infty$ be the moment generating function of the r.v. . Then, for all $t>\mathrm{E}[Y_1]$ \begin{equation}
\lim_{n\rightarrow \infty}\frac{1}{n}\ln P(S_n\geq t)=-I(t)\quad\quad\quad    
\end{equation} where the rate function $I$ is defined by \begin{equation*}
I(t):=\sup_{u}\left(tu-\ln M_{Y_1}(u)\right)
\end{equation*} I am not quite sure what this means, I would guess it means $\lim_{n\rightarrow \infty}P(S_n\geq t)$ converges at rate $I(t)$? Am I on the right lines?","['large-deviation-theory', 'probability-theory']"
2366306,Is my sequence its own inverse?,"Today I asked a question on codegolf.se about a rather elementary sequence.  The sequence is defined as a function $f : \mathbb{Z}^+\setminus\{1\} \mapsto \mathbb{Z}^+ \setminus \{1\}$ where $f(n)$ is the smallest number $m$ such that the following properties are satisfied: $\gcd(m,n) = 1$ $\nexists x < n:f(x) = m$ $\left|n-m\right| > 1$ The first couple terms in this sequence are $$ 5,7,9,2,11,3,13,4,17,6,19,8,23,22,21,10,25,12,27,16,15,14$$ Along with the challenge to write code to calculate the sequence I also added a extra challenge to prove that $f$ was its own inverse. Commenters verified that this was the case for the first few million values in the sequence, but no one has been able to prove that it is the case as of yet.  I looked for literature, but because I made the sequence up and it has no OEIS entry I did not get very far. What I have proven so far is that there can be no loops of size $3$, (that is $f\circ f\circ f(x)\neq x$).  To prove this let us assume we have $3$ values $a$, $b$, and $c$ such that $a < b < c$.  In order to have a 3 loop we need either: \begin{equation}f(a) = b, f(b) = c, f(c) = a \end{equation} or \begin{equation}f(a) = c, f(c) = b, f(b) = a \end{equation} The first cannot be the case because for $f(b)$, $a$ must satisfy all of the requirements, because $f(a)=c$ they are coprime and differ by more than 1 and because $f(b)=a$ we know that $a$ cannot have already appeared in the sequence.  Thus $f(b)=a$ contradicting our earlier statement.  The same reasoning can be applied to the other case. I think this reasoning may be extensible to larger loops but I am not very sure that this is the case, and even if we prove that loops of size larger than $2$ are impossible we still have to prove that every number does loop , in order to get the result we want.","['functions', 'inverse']"
2366364,Can you distinguish topological properties of (sub)spaces by embedding them in an ambient space?,"I'm curious, but I can't seem to reason through it myself. For instance, is it logical to deduce things like ""[0,1] is not homeomorphic to (0,1)"" by considering both as subspaces of $\mathbb{R}$ with the usual topology, where we have tools like the Heine-Borel theorem?  Can this be done in general with other spaces and topological invariants? Thanks, Edit: For what it's worth, I'm not concerned about the particular example (but thank you for your answers anyway). I just chose something familiar and simple to illustrate the point.  I just wanted to know if it's possible (or useful) to determine topological properties this way.","['algebraic-topology', 'general-topology']"
2366373,Does the weak law of large numbers hold in a general Banach space?,"Let $B$ be a Banach space. Let $X_n$ be i.i.d. random variables on $B$ with expectation $\mu$. Is it true that their empirical mean converges to $\mu$ in law? If not, are there additional assumptions? A reference would also be welcome.","['probability-limit-theorems', 'probability-theory', 'banach-spaces']"
2366401,Find limit of sum,I suspect that $\lim_{n \to \infty} \sum_{k = 0}^{n  - 1}\frac{k}{a^k(n - k)} = 0$ for $a > 1$. I know that this product represents the taylor coefficients of $\frac{-ax\ln(1 - x)}{(a - x)^2}$ by the Cauchy product. Unfortunately the limit as $x \to 1^{-1}$ is not defined so I can't use Abel's theorem. How can I prove this?,"['cauchy-product', 'sequences-and-series', 'calculus']"
2366405,Variable Dimensionality Manifolds,"I am curious about different notions of dimensionality, particularly as it relates to manifolds. For instance, there is the standard fixed dimensionality of a pure smooth manifold , the Hausdorff dimension , various different notions of Fractal dimension , and other notions of dimension (e.g. [1] , [2] ). Some allow for fractional dimensionality ; my question is whether this is possible somehow for manifolds (or rather for some manifold-like objects). One interesting note in the manifold wiki article mentions the notion of manifolds where the dimensionality changes, by e.g. disjoint unioning of a sphere and line. However, the connected components must have the same dimension, I believe. But is there a notion of generalized manifold with dimensionality that can be ""smoothly varying"", in some sense? My question is partly motivated by the idea that one can easily ""imagine"" such a construct (e.g. a surface that forms a long cone that thins out into a line).
Of course, this would not be a manifold
(indeed, in computer science, discrete ""manifolds"", e.g. meshes or point sets, that do this are called ""non-manifold""), but perhaps there is a generalized notion that admits this and analysis? The most obvious issue is local coordinates are obviously integral in nature. But is there no way to parameterize fractals locally (which are of fractional dimension)? Related questions: Can a fractal be a manifold? If so, will its boundary (if it exists) be strictly one dimension lower? Can a fractal be a manifold? (Relation to invariant manifolds)","['fractals', 'dimension-theory-analysis', 'manifolds', 'general-topology', 'differential-geometry']"
2366438,"Is the fourier orthonormal system special? If I chose some arbitary orthonormal system, could I hope for pointwise convergence for nice functions?","As the title says, I would like to understand and get intution for fourier expanstion converging pointwise for nice functions. In particular, I might start by asking how often (of course this isn't well defined), when I pick an orthonormal system with respect to the usual integral inner product, does it give pointwise convergence for nice functions. Let's define nice functions as analytic (of course I'll be much happer if things hold for just diffrentiable functions for instance). I'm not sure how to define an arbtiary orthonormal system, so I leave this open to the answerer that is more knowledgeable than me. Thanks","['fourier-series', 'real-analysis', 'fourier-analysis', 'convergence-divergence']"
2366483,Computing the first variation of volume: all around confusion,"$\DeclareMathOperator{\vol}{vol}$I've been working through the computation of the first variation of volume presented in Jost's Riemannian Geometry and Geometric Analysis (page 196 in the sixth edition, section titled: Minimal Submanifolds ), and I've been getting caught up in all the notation, and I've been having a lot of trouble exactly understanding how to interpret the partial derivatives in this context. I'll start with the setup: let $M$ be a smooth submanifold of $N$ and let $F:M\times(-\epsilon,\epsilon)\to N$ be a local variation with compact support. For small enough $t$ we have that $\Phi_t(\cdot):=F(\cdot,t)$ is a diffeomorphism from $M\to M_t\subseteq N$. Now let $\{e_1,\dots,e_m\}$ be an orthonormal frame on $M$. Using this diffeomorphism we can write
$$\vol(M_t)=\int_{M}\left\langle\Phi_{t*}e_1\wedge\cdots\wedge\Phi_{t*}e_m,\Phi_{t*}e_1\wedge\cdots\wedge\Phi_{t*}e_m\right\rangle^{\frac{1}{2}}\eta_{M},$$
where $\langle{\cdot,\cdot}\rangle$ is the induced inner product on $\bigwedge^m(TN)$, that is $\langle{v_1\wedge\cdots\wedge v_m,w_1\wedge\cdots\wedge w_m}\rangle=\det(\langle{v_i,w_j}\rangle)$, and $\eta_M$ denotes the Riemannian volume form on $M$. Then we differentiate this with respect to $t$ to find that
$$ \left.\frac{d}{dt}\vol(M_t)\right|_{t=0}=\left.\sum_{i=1}^{m}\int_{M}\frac{\left\langle\Phi_{t*}e_1\wedge\frac{\partial}{\partial t}\Phi_{t*}e_i\wedge\cdots\wedge\Phi_{t*}e_m,\Phi_{t*}e_1\wedge\cdots\wedge\Phi_{t*}e_m\right\rangle}{\|\Phi_{t*}e_1\wedge\cdots\wedge\Phi_{t*}e_m\|}\eta_M\right|_{t=0}$$ My first question is about the notation $\frac{\partial}{\partial t}\Phi_{t*}e_i$. Should I interpret this as follows: Let $\gamma:(-\epsilon,\epsilon)\to TN$ be given by $\gamma(t)=\Phi_{t*}e_i\in T_{\Phi_{t}(p)}M$. Then  does $\frac{\partial}{\partial t}\Phi_{t*}e_i$ simply mean $d\gamma\left(\frac{\partial}{\partial t}\right)$, where we naturally identify $T(T_qN)\cong T_qN$? He goes on consider the vector field $X:=\left.\frac{\partial}{\partial t}\Phi_{t}\right|_{t=0}$. I'm assuming the interpretation of this vector field is the same as before. My main confusion is with this next part: To compute $\frac{\partial}{\partial t}\Phi_{t*}e_i$ at $t=0$ we consider a curve $c_i(s)$ in $M$ with $c_i(0)=p$ and $c_i'(0)=e_i$ and let $c_i(s,t):=\Phi_t(c_i(s))$. Then 
$$\left.\Phi_{t*}e_i=\frac{\partial}{\partial s}c_i(s,t)\right|_{s=0}.$$ How do I justify this? It definitely lives in the right tangent space since $c_i(0,t)=\Phi_t(p)$, but why does this coincide with the pushforward $d\Phi_t(e_i)$. I'm probably missing something pretty fundamental. Carrying on with the computations we have
$$\left.\frac{\partial}{\partial t}\Phi_{t*}e_i\right|_{t=0}=\left.\frac{\partial}{\partial t}\frac{\partial}{\partial s}c_i(s,t)\right|_{s=t=0}=\left.\frac{\partial}{\partial s}\frac{\partial}{\partial t}c_i(s,t)\right|_{s=t=0}=\left.\nabla^N_{\frac{\partial}{\partial s}}X\right|_{s=0} =\nabla^N_{e_i}X, $$
where $\nabla^N$ is the Levi-Civita connection on $N$. My question is why do the partial derivatives commute in this case? Again, how should these mixed partials be understood, and what justifies this computation? Even intuitively, it doesn't make sense to me that they should.","['minimal-surfaces', 'calculus-of-variations', 'riemannian-geometry', 'differential-geometry']"
2366504,"What does $L(n,\chi_4)$ mean?","I was reading some articles related to Euler sums and the Riemann zeta function, when I came across this definition: $$
L(n,\chi_4) = \sum_{k=0}^{\infty}\frac{(-1)^k}{(2k+1)^n}
$$ What is this function called and how is it related to the zeta function?","['number-theory', 'riemann-zeta', 'elementary-number-theory']"
2366557,Limit with a summation and sine: how to calculate $\lim_{n\to \infty} n^2\sum_{k=0}^{n-1} \sin\left(\frac{2\pi k}n\right)$?,"This is the limit:
$$\lim_{n\to \infty} n^2\sum_{k=0}^{n-1} \sin\left(\frac{2\pi k}n\right)$$ I found that $k/n <1$ if $n=2k$ the term of the summation is $0$ until $n=4$ the summation is $0$ $ \sin\left(\frac{2\pi k}n\right)= 2\sin\left(\frac{\pi k}n\right)\cos\left(\frac{\pi k}n\right)$ I also tried to increase or decrease the summation  with an integral but I think I can do it only if the term in the summation  is monotonous. I totally don't know how to deal with this kind of exercise, I'm looking for a general approach Thanks! Sorry for english.","['summation', 'trigonometry', 'calculus', 'limits']"
2366561,equivalence of measures on separable spaces,"I would like to check if my conclusion is right. Let $(X, \|\cdot \|_1)$ be a separable normed space endowed with the $\sigma$-algebra $B$ generated by the norm $\|\cdot \|_{1}$. Therefore, since the measurable space $(X, B)$ is separable, then $\sigma$-algebra $B$ is equal to the one generated by the open balls in $(X, \|\cdot \|_1)$. Therefore, two measures are equal if and only if they agree on the finite intersections of open balls, since the finite intersections of the balls in $(X, \|\cdot \|_1)$ constitute a $\pi$-system. Next, consider the norm $\|\cdot \|_2$ on $X$, which is equivalent to $\|\cdot \|_1$. Since $||\cdot ||_2$ is equivalent to $\|\cdot \|_1$, then they define the same topologies and, therefore, the same $\sigma$-algebras. Then I conclude the following: in order to prove that two measures on $(X, B)$ are equivalent, one has to show that they agree on the the finite intersections of open balls, balls in ANY norm equivalent to $\|\cdot \|_1$.","['real-analysis', 'functional-analysis', 'probability', 'measure-theory', 'general-topology']"
2366580,What's the average euclidian distance between two points on a unit n-sphere?,"Suppose we randomly place 2 points the 100-dimensional unit sphere. So we have
$$x_1, x_2\in \mathbb{R}^{100}\quad\text{ and }\quad|x_1|=|x_2|=1$$ What's the expected value of the euclidian distance between them?
$$E[|x_1 - x_2|]=\ ?$$
From just eyeballing some data, the answer looks like $\approx1.2$ And what about in general? So for 2 points on an n-dimensional sphere?","['spheres', 'probability']"
2366588,Does global Lyapunov stability imply unique equilibrium?,"Recall that given a time-invariant dynamical system $$\dot x = f(x)$$ We say that an equilibrium point at the origin, $x_e \in \mathbb{R}^n$, of the above system is stable (in the sense of Lyapunov) if: $$\forall \epsilon > 0, \exists \delta > 0, \text{ s.t. } \|x(t_0) - x_e\| < \delta \implies \|x(t) - x_e\|< \epsilon, \forall t \geq t_0$$ Suppose that the above condition holds for all $x_0 = x(t_0) \in \mathbb{R}^n$, then we can say that the equilibrium point is globally stable. Suppose that $x_e$ is globally stable, then is it the unique equilibrium of $\dot x = f(x)$? Note that global asymptotic stability implies uniqueness because every trajectory has to converge to that point.","['dynamical-systems', 'stability-theory', 'stability-in-odes', 'ordinary-differential-equations', 'definition']"
2366608,How can I solve this limit without L'Hopital rule?,"I have found this interesting limit and I'm trying to solve it without use L'Hopital's Rule. $$\lim\limits_{x\rightarrow 0}\frac{\sinh^{-1}(\sinh(x))-\sinh^{-1}(\sin(x))}{\sinh(x)-\sin(x)}$$ I solved it with L'Hopital's rule and I found that the solution is $1$. But if I try without this rule, I can't solve it. Any ideas?","['hyperbolic-functions', 'calculus', 'limits-without-lhopital']"
2367625,"Finding a quadruplet of ""cow-equivalent"" integers","This a follow up question/puzzle from an earlier question here How does rounding affect Fibonacci-ish sequences? Explanation For this new question, one needs only to understand a particular transformation $$
f\big(
\begin{bmatrix}
a\\b\\c\\d
\end{bmatrix}\big)
=
\begin{bmatrix}
a+\text{floor}(\frac{d}{2})\\a\\b\\c
\end{bmatrix}
$$
So for example, this sequence is generated by repeatedly applying the transformation
$$
\begin{bmatrix}5\\0\\0\\0\end{bmatrix}\rightarrow
\begin{bmatrix}5\\5\\0\\0\end{bmatrix}\rightarrow
\begin{bmatrix}5\\5\\5\\0\end{bmatrix}\rightarrow
\begin{bmatrix}5\\5\\5\\5\end{bmatrix}\rightarrow
\begin{bmatrix}7\\5\\5\\5\end{bmatrix}\rightarrow
\begin{bmatrix}9\\7\\5\\5\end{bmatrix}\rightarrow
\begin{bmatrix}11\\9\\7\\5\end{bmatrix}\rightarrow
\begin{bmatrix}13\\11\\9\\7\end{bmatrix}\rightarrow
\begin{bmatrix}16\\13\\11\\9\end{bmatrix}\rightarrow
\ ...
$$
Because the function rounds down $d$, it's very hard to predict the exact values after many iterations. Interestingly though -- certain initial values eventually converge to the same sequence For example if we continue the sequence above
$$
\cdots\ 
\rightarrow
\begin{bmatrix}16\\13\\11\\9\end{bmatrix}\rightarrow
\begin{bmatrix}20\\16\\13\\11\end{bmatrix}\rightarrow
\begin{bmatrix}25\\20\\16\\13\end{bmatrix}\rightarrow
\begin{bmatrix}31\\25\\20\\16\end{bmatrix}\rightarrow
\begin{bmatrix}39\\31\\25\\20\end{bmatrix}\rightarrow
\begin{bmatrix}49\\39\\31\\25\end{bmatrix}\rightarrow
\ \cdots
$$
And compare it to the sequence of another initial value
$$
\begin{bmatrix}9\\0\\0\\0\end{bmatrix}\rightarrow
\begin{bmatrix}9\\9\\0\\0\end{bmatrix}\rightarrow
\ \cdots \ \rightarrow
\begin{bmatrix}25\\21\\17\\13\end{bmatrix}\rightarrow
\begin{bmatrix}31\\25\\21\\17\end{bmatrix}\rightarrow
\begin{bmatrix}39\\31\\25\\21\end{bmatrix}\rightarrow
\begin{bmatrix}49\\39\\31\\25\end{bmatrix}\rightarrow
\ \cdots
$$
The sequences hit the same point. More specifically, we will say that
$$
f^{13}\big(\begin{bmatrix}5\\0\\0\\0\end{bmatrix}\big)
=
f^{10}\big(\begin{bmatrix}9\\0\\0\\0\end{bmatrix}\big)
$$
This means the sequence for $5$ and the sequence for $9$ will be the same as each other if continued further. I've been calling numbers like this ""cow-equivalent"" because this iteration models the population growth of animals in Minecraft – when bred every 5 minutes by the player. A related-but-simpler transformation is also discussed here Exponential growth of cow populations in Minecraft Here we'll use the ""$\equiv$"" symbol to denote cow-equivalency. So
$$a\equiv b \quad\text{if and only if there exists}\quad m, n \in \mathbb{N}$$
$$\text{ such that}$$
$$f^m(a\cdot\vec{e_1})=f^n(b\cdot\vec{e_1})$$ Questions A quick computer search shows that there are triplets of cow-equivalent numbers like
$$34\equiv 259\equiv 406$$
because
$$f^{35}(\begin{bmatrix}34\\0\\0\\0\end{bmatrix})=
f^{26}(\begin{bmatrix}259\\0\\0\\0\end{bmatrix})=
f^{24}(\begin{bmatrix}406\\0\\0\\0\end{bmatrix})=
\begin{bmatrix}113171\\90268\\72000\\57429\end{bmatrix}$$
Thus the primary question here is Does a quadruplet of cow-equivalent numbers exist? Other interesting/related questions Are all numbers potentially cow-equivalent? Is the triplet above – or any other cow-equivalence set – complete? Is there a deterministic test one can apply for cow-equivalence?","['recurrence-relations', 'rounding-error', 'sequences-and-series']"
2367635,Sides of a triangle in arithmetic progression. Find possible values of common difference,"Question If the sides of a triangle are in arithmetic progression with first term $1$ and
common difference $d$ find the set of possible values of $d$ Attempt I do not have much of a clue on how to go about solving this. I've tried letting the angles be $\theta,$ $\theta+\varepsilon$ and $\pi-2\theta-\varepsilon$ and using the sine rule, and even the cosine rule, but to no prevail. Any hints would be very much appreciated!","['trigonometry', 'arithmetic-progressions', 'triangles', 'geometry', 'sequences-and-series']"
2367647,General method for solving recursive linear ordinary differential equations for analytic functions,"Are there general methods to solve recursive ordinary differential equations? Consider the following two kinds of equations. Explicit recursion: Solve for $f_n(x)$ in $$\frac{\mathrm{d}\left(f_n(x)p(x)\right)}{\mathrm{d}x} = f_{n-1}(x)q(x) + r(x)\\
f_0(x)=h(x)$$ where $p(x), q(x), r(x), h(x)$ and $f_i(x), \forall i \in \mathbb{N}$ are real analytic functions. Assume the equation have solution(s). Implicit recursion: Consider the same set of equations, with a more general implicit acyclic recursive relation $ m(n): \mathbb{N} \rightarrow \mathbb{N}$ , instead of the explicit recursion $n \rightarrow n-1$ as in the first equation. Namely: $$\frac{\mathrm{d}\left(f_n(x)p(x)\right)}{\mathrm{d}x} = f_{m(n)}(x)q(x) + r(x)$$ Is there a general method of solving these? If not, is there a proof (apart from the ""obvious"" intuition that you would need to know the structure of the recursive map to actually solve it, so a general method of solving is a no-no) that such a general method does not exist?","['recurrence-relations', 'functional-analysis', 'computability', 'ordinary-differential-equations', 'analysis']"
2367649,A very tricky integral,"I am trying to integrate $$
\int \frac{11\sec^2\theta\tan^2\theta}{\sqrt{49-\tan^2\theta}}d\theta
$$ and I am continually getting the wrong answer. I would like steps in solving this problem","['indefinite-integrals', 'integration', 'calculus']"
2367661,Explanation of OEIS:A000046,"I'm looking at OEIS:A000046 , whose definition states: Number of primitive n-bead necklaces (turning over is allowed) where complements are equivalent. I can't quite understand this. This is what I have so far: The necklace should have 2 types of beads (i.e. it is binary (?)) The necklace should have $n$ beads Two necklaces are identical if one can be rotated, reflected, or complemented (all beads' types are flipped), or have any combination of those operations applied to it and become equal to the other However, this doesn't seem to match A46, or A11 for that matter. Can someone finish the explanation or explain where it's wrong? Also, what does ""primitive"" mean? Edit It was actually because I forgot the return statement in one of the functions in my Python interpretation... So the question becomes, what does ""primitive"" mean in this case?","['combinatorics', 'oeis']"
2367663,Density of finite rank operator in compact operators on Hilbert spaces,"Show the subspace of finite rank operators (defined on a Hilbert space) is dense
  in the space of all compact operators. I just started reading about compact operators and I saw this questions. 
So far I learnt any finite rank operator on a Hilbert space is compact, to show it's dense in space of all compact operators, there must exist a sequence of finite rank operator $(T_n)$  such that it converges to compact operator $T$, but I'm not sure how I can construct this sequence, I may need to think about complete orthogonal sequence $\{e_1\:,e_2\dots\} $ of the Hilbert spaces, so I get 
$$T(x)=\sum_{i=1}^{\infty}\langle T(x),e_i\rangle e_i$$
If I define $T_n(x)=\sum_{i=1}^{n}\langle T(x),e_i\rangle e_i$, this is off course a finite dimensional and compact operator. Can I say it's the sequence that converges to $T$? Or maybe I'm totally wrong, but I appreciate, if you give me some hints about this.","['functional-analysis', 'compact-operators', 'hilbert-spaces']"
2367670,How to solve this equation of two variables,"$$
F(X,Y)=(t_1^2+t_2^2+2t_1t_2X)^2Y^2-2t_3^2(t_1^2X+t_2^2X+2t_1t_2)Y+t_3^4
$$ I want to know the point $(X,Y)$ which satisfied with $F(X,Y)=0$.
Now, $t_1,t_2,t_3$ are positive numbers. By numerical calculation, I noticed $F(1,(\frac{t_3}{t_1+t_2})^2)=0$ when $\frac{t_3}{t_1+t_2}<1$. I want to know how to know this result analytically.
Is it possible??","['multivariable-calculus', 'real-analysis', 'maxima-minima', 'functions']"
2367693,Is the quotient of standard parabolic subgroups isomorphic to a Schubert variety,"Let $G$ be a reductive algebraic group over an algebraically closed field. Let $B \subseteq P_2 \subseteq P_1$ be a Borel subgroup and two parabolic subgroups. Then $P_1/P_2 \subseteq G/P_2$ is a closed subvariety. Is $P_1/P_2$ a Schubert variety defined in $G/P_2$? If not, what are the intersection of $P_1/P_2$ with the Schubert cells, also defined in $G/P_2$? More precisely, let $W_{P_i}$ be the subgroup of the Weyl group $W$ of $G$ defined with a maximal torus $T\subseteq B$, such that $W_{P_i} \simeq N_{P_i}(T)/T$, for $i=1,2$. Let $$W_{P_i}^{\text{min}} = \{w \in W | \ell(ww') = \ell(w)+\ell(w'), \text{ for all } w' \in W_{P_i}\},$$
for $i=1,2$. Let $w_0$ be the longest element in $W$. Then there is a unique element in $W_{P_i}^{\text{min}}$ with maximal length, which is denoted as $w_i$, satisfying $w_0 = w_i \cdot w_{P_i}$, where $w_{P_i}$ is the longest element in $W_{P_i}$, for $i=1,2$. Since $W_{P_2}$ is a subgroup of $W_{P_1}$, there exists $w_1' \in W_{P_1}$, such that $w_{P_1} = w_1' \cdot w_{P_2}$. So $w_2 = w_1 \cdot w_1'$. Let $X_i(\cdot)$ denote the Schubert variety defined in $G/P_i$ for $i=1,2$. Then $G/P_1 \simeq X_1(w_1)$ and $G/P_2 \simeq X_2(w_1 \cdot w_1')$. This makes me suspect that $P_1/P_2$ and $X_2(w_1')$ are related in some sense. Is it true? Thank you very much. P.S. In a Coxeter group, we say $x = y \cdot z$ if $x = yz$ and $\ell(x)=\ell(y)+\ell(z)$. 2.For the definition of all the terms, please check: Billey and Lakshmibai's Singular Loci of Schubert Varieties , Chapter 2.","['algebraic-groups', 'schubert-calculus', 'algebraic-geometry']"
2367739,Can every finite dimensional division ring be endormorphism ring of some representation？,k is a field，G is a finite group and V is a finite dimensional irreducible representation of G over k， then $End_GV$ is a finite dimensional division ring over k by Schur lemma. Can every finite dimensional division ring over k be obtained in this way?,"['abstract-algebra', 'representation-theory']"
2367796,$\textbf Z[\sqrt{pq}]$ is not a UFD if $\left( \frac{q}p \right) = -1$ and $p \equiv 1 \pmod 4$. [duplicate],This question already has answers here : Why isn't $\mathbb Z [\sqrt{pq}]$ a factorial domain (2 answers) Closed 5 years ago . Let $p$ and $q$ be primes such that $p \equiv 1 \pmod 4$ and $\left( \frac q p \right) = -1$. Show that $\textbf Z[\sqrt {pq}]$ is not a UFD. I tried some examples like $p=5$ and $q = 2$. But I have no clue about the general case. Any hint?,"['unique-factorization-domains', 'abstract-algebra', 'ring-theory', 'algebraic-number-theory']"
2367821,Polynomial having rational coefficients and one root: $\sqrt{2}+\sqrt{3}-\sqrt{5}$,"Form a polynomial of smallest degree having rational coefficients and one root as $\sqrt{2}+\sqrt{3}-\sqrt{5}$ Idea 1: I thought that other roots would be just different combination of signs on the surds, ie $\sqrt{2}+\sqrt{3}+\sqrt{5}$ $\sqrt{2}-\sqrt{3}+\sqrt{5}$ so least degree would be $2^3 = 8$. Polynomial then could be formed using viete's formulas. Idea 2: We let $x = \sqrt{2}+\sqrt{3}-\sqrt{5}$. Then rearranging and squaring repeatedly gives us the polynomial. Questions This method seems unsatisfactory and is just a thought. Please help me with a proper method. Is the polynomial i found unique? or there are more polynomials with rational coefficients with this root ($\sqrt{2}+\sqrt{3}-\sqrt{5}$)? Also can we generalise this result: that the least degree of a polynomial whose root is a sum of $n$ distinct surds is $\sum \binom{n}{k} = 2^n$ ? Edit As stated by Hagen Von Elitzen , the result in third question is correct only for square roots of numbers which are pairwise coprime. Eg. ($\sqrt{2}, \sqrt{3}, \sqrt{5}$) and not ($\sqrt{2}, \sqrt{5}, \sqrt{10}$)","['algebra-precalculus', 'polynomials', 'irrational-numbers', 'rational-numbers']"
2367829,How to prove that the Galois group of a polynomial is generated by transpositions?,"Let $f_n(x)=x^n-x^{n-1}-....-x-1$ be the polynomial where $n$ is even. Now, $f_n(x)$ is an irreducible polynomial over $\mathbb{Q}$, so Galois group of $f_n(x)$, say Gal$(f_n)$ is a transitive subgroup of $S_n$. Also, Gal($f_n$) contains a transposition. Now, I need to show that Gal$(f_n)$ is generated by transpositions. How do I show that? Thanks!","['abstract-algebra', 'galois-theory', 'algebraic-number-theory']"
2367832,A $3 \times 3$ matrix with one eigenvalue and one eigenvector?,"Suppose we have to construct a $3 \times 3$ matrix with only one eigenvalue which has only one linearly independent eigenvector, what should be our approach? I was asked this in an interview, so first thing that came on my mind was to look for a matrix with $\lambda=2$ on the diagonal such that char poly comes out to be $(\lambda-2)^3=0$. I was going for something like $A=\begin{bmatrix}2&0&0\\0&2&1\\1&0&2\end{bmatrix}$. It has only one eigenvalue i.e. $\lambda =2$ but when I find $A-\lambda I= \begin{bmatrix}0&0&0\\0&0&1\\1&0&0\end{bmatrix}$ it's only element in null space is zero. And I end up with nothing. I was interrupted in between and asked another question? Was I completely in a wrong direction?",['linear-algebra']
2367863,Distributivity in boolean subalgebras of orthomodular lattice,"A boolean subalgebra $B$ of the orthomodular lattice $L$ of closed subspaces of a separable Hilbert space, may be defined like a sublattice with $0$ and $1$, with pairwise commuting elements.
How to prove that, in this subalgebra, the distributive property holds?","['functional-analysis', 'abstract-algebra', 'lattice-orders', 'boolean-algebra']"
2367893,Details of gluing sheaves on a cover,"I am sure this is a simple question, but I am really not able to think straight at the moment and this is bugging me. I am doing Exercise 1.22 from Hartshorne. It is the classic gluing of of sheaves on a cover given the cocycle condition question. In particular, we have a space $X$ and a cover for this space $\{ U_{i} \}_{i \in I}$. Further, we are given a family of sheaves indexed by the same set $I$, $\{ \mathcal{F}_{i} \}_{i \in I}$ on each of the $U_{i}$. We are given isomorphisms
$$
\phi_{ij}: \mathcal{F}_{i}|_{U_{i} \cap U_{j}} \longrightarrow \mathcal{F}_{j}|_{U_{i} \cap U_{j}},
$$
along with the so-called cocycle condition
$$
\phi_{ik} = \phi_{ik} \circ \phi_{ij} \quad \text{on} \quad U_{i} \cap U_{j} \cap U_{k}.
$$
The task is to construct a sheaf on $X$ compatible with these local sheaves. I have gone ahead and done the obvious steps of defining a base by taking all open sets contained in one of the $U_{i}$ etc. I then defined a sheaf $\mathcal{G}$ on this base and this is well defined since if there is some $V$ in $U_{i}$ and $U_{j}$ with $i \neq j$, then via the isomorphism $\phi_{ij}$, we have
$$ \mathcal{F}_{i}(V) \stackrel{\simeq}{\longrightarrow} \mathcal{F}_{j}(V) $$
My understanding is that to make the restriction maps work, you need to invoke the cocycle condition. My issue is that I can't see exactly where. It seems that the isomorphism alone is enough. The frustrating part is that every resource I look at (and there are a lot since this is a common exercise) simply says ""the restrictions are compatible because of the cocycle condition"" or ""this is well defined because of the cocycle condition"" or something similar. Nowhere seems to explicitly lay out where the cocyle condition is invoked, and what breaks when it is not. Is someone able to shed some light on this? Other than this small step I feel like I understand the rest of it completely, but I feel like this is a vital thing to not understand. Thanks","['ringed-spaces', 'sheaf-theory', 'algebraic-geometry']"
2367906,"Is it true, that for $m$-accretive operators in a reflexive Banach space the generalized domain is equal to the domain of the operator?","For $m$-accretive operators $A$ in a Banach space $(X,\|\cdot\|)$ we define the generalized domain by
\begin{align}
\hat{D}(A) := \{ x \in X : \exists (x_n,y_n) \in A , n \in \mathbb{N}: x_n \rightarrow x \,\, \text{in} \,\,  X, \sup_{n \in \mathbb{N}} \|y_n\| < \infty \}.
\end{align}
In general we have $D(A) \subseteq \hat{D}(A) \subseteq \overline{D(A)} $. If $X$ is reflexive and $A: D(A) \rightarrow X$ is linear, we have $D(A) = \hat{D}(A)$. Sketch of proof: Since $A$ is $m$-accretive, $A$ is closed. Therefore its graph is closed, moreover $A$ is linear, so we get that its graph is convex. Because closed and convex subsets of a Banach space are weakly closed, the graph of $A$ is also weakly closed. So we now have that $A$ is weakly closed. Now let $x \in \hat{D}(A)$ and $(x_n)_{n} \subseteq D(A)$, such that $x_n \rightarrow x$ and 
$\sup_{n \in \mathbb{N}} \|y_n\| < \infty$. Because $X$ is reflexive we can assume that $Ax_n \rightharpoonup y$ for some $y \in X$ after extraction of a subsequence because of the Eberlein-Shmulyan theorem. Since $A$ is weakly closed we get $x \in D(A)$ and $Ax = y$ and therefore $D(A) = \hat{D}(A)$. Now assume $A$ is a nonlinear and $m$-accretive operator in the reflexive space $X$. We then do not have the convexity of the graph of $A$ and therefore the proof does not hold. Is the equation $D(A) = \hat{D}(A)$ still true? If yes, how to proof it?","['functional-analysis', 'nonlinear-analysis', 'partial-differential-equations']"
2367923,Is there a systematic way of finding the matrix of a quadratic form? [duplicate],"This question already has an answer here : How to find the matrix of a quadratic form? (1 answer) Closed 6 years ago . For example i have this quadratic form $q(x_1,x_2)=8{x_1}^2-4x_1x_2+5{x_2}^2$ , here it's a simple factoring: $q\begin{bmatrix}x_1 \\x_2 \\x_3\\\end{bmatrix}=\begin{bmatrix}x_1 \\x_2 \\x_3\\\end{bmatrix} \cdot \begin{bmatrix}8x_1 &-2x_2\\-2x_1&5x_2\end{bmatrix}=\vec{x}^{T}A\vec{x} ,A=\begin{bmatrix}8 &-2\\-2&5\end{bmatrix}$. But this is not always the case where one can simply see how the matrix is going to be ,so is there a certain method of finding this matrix?","['quadratic-forms', 'linear-algebra']"
2367993,Normal closure is minimal normal subgroup,"The following problem is from the book ""Finite Group Theory"" by Martin Isaacs. (2.A.7) Let $S \lhd \lhd G$ (S is subnormal in G), where $S$ is nonabelian and simple and $G$ is finite. Show that $S^{G}$ , the normal closure of $G$ is minimal normal subgroup in $G$ HINT : Work by induction on $|G|$ to conclude that $S \subseteq \text{Soc}(H)$ whenever $S \subseteq H$ . Deduce that each conjugate of $S$ in $G$ is a minimal normal subgroup of $S^{G}$ . Then apply the previous problem to the group $S^{G}$ , where $X$ is the set of all $G$ -conjugates of S. I've been strugling with the first part of the hint. I tried to prove the claim, as said by author, but I have troubles with the inductive step. For $|G| = 1$ the claim is obviously true. Now assume it holds for any $H$ , s.t. $|H| < |G|$ . Now if $S = G$ , then the claim follows from the simplicity of $S$ . If $S < G$ then for any proper subgroup $H$ of $G$ , s.t. $S \le H$ we have $S = S \cap H \lhd \lhd G \cap H = H$ , so by the inductive hypothesis $S \subseteq \text{Soc}(H)$ But I can't do the inductive step, i.e. $S \subseteq \text{Soc}(G)$ . We know that $S \cap \text{Soc}(G) \unlhd S$ , so from the simplicity of $S$ we have that $S \cap \text{Soc}(G) = \{e\}$ or $S \cap \text{Soc}(G) = S$ . It's easy to deal with the second case, as it immediately follows that $S \subseteq \text{Soc}(G)$ . But I can't do anything about the first case. It seems that we need to use the fact that $S$ is nonabelian, as if $S$ is a noncentral involution in $G=D_8$ we get that $S$ is subnormal in $G$ and simple, but $S \not \subseteq \text{Soc}(G) = Z(G)$ . The only way I can see how to use the fact that $S$ is nonabelian is by proving that $S$ is contained in a center of a subgroup and hence derive a contradiction, but I couldn't achieve any progress in this direction. Also I don't see how we can use the inductive hypothesis for this part, as $\text{Soc}(H) \subseteq \text{Soc}(G)$ is not necessarily true in general. Much of the problem seems to revolve around the mentioned previous problem, which I have proven. The claim is that if $X$ is a collection of minimal normal subgroups of $G$ , then $N = \Pi \ X$ is a direct product of some members of $X$ and moreover a direct product of simple groups. Further more it says that any normal and nonabelian subgroup of $G$ contained in $N$ contains a member of $X$ . Unfortunately I don't see how we can use this problem until the last stage of the proof.","['socle', 'finite-groups', 'abstract-algebra', 'normal-subgroups', 'group-theory']"
2368020,Defining Binomial distribution centered at any integer,"Given the Binomial distribution: $$\Pr(k;n,p) = \Pr(X = k) = \binom n k p^k (1-p)^{n-k}$$
It is clear that for choices of $n$ and $p$ we can shift the binomial distribution left or right since $\mu = np$. I want to consider the case for $p =0.5$, hence the mean and median are equivalent. Does anyone know if there is an extension of this distribution which allows the distribution to be centered at any integer (including negative of course)? Where centered refers to centering with respect to the mean. This was somewhat addressed in the post but here they are looking for a shift to zero from a programming perspective not analytically. Thanks.","['probability-theory', 'binomial-distribution', 'statistics']"
2368023,Counter-example for a matrix not being a correlation matrix,"Is there an example of an $n \times n$ matrix that: is real-valued and symmetric with entries between $-1$ and $+1$ has diagonal elements equal to $1$ has a non-negative determinant has non-negative determinant for each leading principal minor but is not a correlation matrix , i.e., is not positive semidefinite ? I am well-aware of Sylvester's criterion for positive definiteness, which requires all principal minors to be non-negative to ensure positive semidefiniteness. However, for structured matrices of the specified format (correlation matrix type), I never came across an actual example illustrating the subtle difference.","['correlation', 'matrices', 'determinant', 'positive-semidefinite', 'linear-algebra']"
2368082,measure on sphere,"In a set of notes I am using (physics related), it states that ""we denote $$M = \{ (x,y,z)| x^2 + y^2 + z^2 = 1 \}$$ and $L^2(M)$ the space of square integrable functions on $M$ with measure $$\Omega = (\theta, \phi),~~0 \leq \theta \leq \pi, ~0 \leq \phi \leq 2 \pi$$ and $$d \Omega = \sin \theta d \theta d \phi.""$$ Is it clear how this defines a measure? As I know a measure is defined as a function from a $\sigma-$algebra to the real line, which satisfies the properties as in the link.","['lebesgue-measure', 'measure-theory', 'analysis']"
2368100,Need reference for working with branch cuts,"I am in a MOOC where we are using contour integration a lot, in conjunction with special functions (not an introductory or undergrad class). Working with branch cuts, deforming them, or just determining when to add which phase to multi-valued functions to compute integrals correctly, is proving to be challenging (the MOOC is: https://www.edx.org/course/complex-analysis-physical-applications-misisx-18-11x ). The class uses deformations of contours and branch cuts in a very advanced way (e.g. ""double deforming"" semi-infinite branch cuts to wrap around multiple branch points while preserving steepest descent directions when evaluating some integrals), without systematically presenting all the details of how to work with those deformations and phases introduced by multi-valued functions. I am left with the impression that I am not really mastering the topic. Most of the references I've found online - and there are many good ones - do not go far enough in presenting ""real life""  examples (usually from physics, when estimating the asymptotic behavior of integral representations that cannot be solved exactly, those representing solutions of ODEs). Is there a comprehensive and systematic reference out there, preferably with worked out examples, that I could consult to get more mastery of multi-valued functions and branch cuts?","['complex-analysis', 'contour-integration', 'complex-integration', 'branch-cuts']"
2368109,When is Morrie's Law a rational number,"I recently stumbled across Morrie's law after noticing that $\sin(20)$ x $\sin(40)$ x $\sin(80)=\frac{1}{8}$. $$\\$$ It's a simple proof to show that, in general: $$\prod_{i=0}^{k}\cos(2^ix)=\frac{\sin(2^{k+1}x)}{2^{k+1}\sin(x)} $$
This led me to think about when the R.H.S is a rational number. For the case where $\sin x, x, \sin(2^{k+1}x)$ are $\in\mathbb{Q}$, I can show that the only solution set is: $k\in\mathbb{N}, x=\frac{\pi}{2},-\frac{\pi}{2}$, but I'm unsure about how to deal with the other cases, I've looked at Niven's Theorem but this doesn't account for the other cases. I've also seen a result that for all rational, $x$, $\sin(x)$ is irrational, is this true (when $x=30, \sin(x)=\frac{1}{2}$) which is rational, see discussion thread: https://www.reddit.com/r/math/comments/4gh1i4/is_sinx_where_x_is_rational_always_an_irrational/ ? $$\\$$ In particular, I want to know how to find rational solutions when $x$ is rational but $\sin{x}$ isn't rational, and similar conditions on $\sin(2^{k+1}x)$. Any help would be much appreciated.","['trigonometry', 'irrational-numbers', 'rational-numbers']"
2368174,Show that $HK\cong H\times K$ [duplicate],"This question already has answers here : Let $G$ a group with normal subgroups $M,N$ such that $M\cap N=\{e\}$. Show that if $G$ is generated by $M\cup N$ then $G\cong M \times N$. (2 answers) Closed 6 years ago . Let $H\lhd G$ and $K\lhd G$ s.t. $H\cap K=\{1\}$. Show that $$HK\cong H\times K.$$ Attempts Using second isomorphism theorem, we have that $HK/K\cong H$ and $HK/H\cong K$, so I need to prove that $$HK\cong HK/K\times HK/H.$$ To simplify notatino let $W=HK$. I consider the group morphism $$W\longrightarrow W/H\times W/K$$
defined by $$w\longmapsto (wH,wK).$$
The injectivity is clear, but I have problem to show surjectivity. Could someone help ?",['group-theory']
2368195,"$X=ABA^T$, X, A are matrix and need to solve matrix B by enforcing it as a diagonal matrix.","$X=ABA^T$, 
X is a square matrix and A is rectangular matrix and I need to solve matrix B by enforcing it as a diagonal matrix. For non-singular matrix we can write B as $A^+XA^{+T}$, but B gets to be non-diagonal matrix. How can I get B as diagonal matrix. (Eigen decomposition of X gives different values of A).","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'least-squares']"
2368199,Expansive homeomorphism on $\mathbb{R}^{2}$,"Homeomorphism $f:(X, d)\to (X, d)$ is called $c$-expansive whenever for  $x\neq y$ in $X$,  there is $n\in \mathbb{Z}$ such that $d(f^{n}(x), f^{n}(y))>c$. Let $A=\left(
  \begin{array}{cc}
    2 & 0 \\
    0 & \frac{1}{2} \\
  \end{array}
\right)
$ and $f:\mathbb{R}^{2}\to \mathbb{R}^{2}$ be defined by $f(x)=Ax$. Consider the stereographic projection $P:S^{2}-\{(0, 0, 1)\}\to \mathbb{R}^{2}$ defined by $P(x, y, z)=\frac{(x,y)}{1-z}$. Is it true that $f$ is expansive when $\mathbb{R}^{2}$ has the
metric induced by $P$? I know that $f$ is not expansive, but its proof is not clear for me.","['general-topology', 'real-analysis', 'dynamical-systems']"
2368214,Closed form for $\sum_{0\le x\lt\infty}n^{2^{-x}}-1$,Is there a closed form for the expression below? $$f(n)=\sum_{0\le x\lt\infty}n^{2^{-x}}-1=(n-1)+(\sqrt{n}-1)+(\sqrt{\sqrt{n}}-1)+\cdots$$ Approximations are good as well. This appeared to me while analyzing an algorithm.,"['sequences-and-series', 'discrete-mathematics']"
2368230,Not Cauchy Implies No Convergent Subsequence?,"Show that if $f : X \to X$ is an isometry and $X$ is compact metric space, then $f$ is bijective and hence a homeomorphism Hint: If $a\in X$ \ $f(X)$, choose so that the neighborhood of a is disjoint from $f(X)$. Set $x_1 = a$, and $x_{n+1} = f(x_n)$. Show that $d(x_n, x_m) \ge \epsilon$ for $n \neq m$. Okay. So this question was addressed here . I was able to show that $d(x_n, x_m) \ge \epsilon$ for $n \neq m$, but was unable to discern the contradiction from this. As the answer in the link suggests, this evidently implies that $(x_n)$ cannot have a convergent subsequence, which contradicts sequential compactness. I haven't been able to find a proof of this, so I provide my own and hope that someone could critique it: Suppose that there exists an $\epsilon > 0$ such that $d(x_n, x_m) \ge \epsilon$ for $n \neq m$, but, by way of contradiction, suppose that there exists a subsequence $x_{n_k}$ converging to $L$. Given $\frac{\epsilon}{2} > 0$, there exists a natural number $N$ such that $d(x_{n_k},L) < \frac{\epsilon}{2}$ for every $k \ge N$. Choosing $k=N$ and $k=N+1$, we get $d(x_{n_N},L) < \frac{\epsilon}{2}$ and $d(x_{n_{N+1}},L) < \frac{\epsilon}{2}$, and adding the two gives us
$$d(x_{n_N},x_{n_{N+1}}) \le d(x_{n_N},L) + d(x_{n_{N+1}},L) < \epsilon,$$ contradicting the hypothesis. How does this sound?","['general-topology', 'metric-spaces', 'cauchy-sequences', 'solution-verification']"
2368231,Spivak' Calculus Chapter 7 Problem 19(b) [continuity],"The question is from Spivak's Calculus 3rd Ed: Suppose $ 0<a<1 $, but that $a$ is not equal to $1/n$ for any natural number $n$.  Find a function $f$ which is continuous on $[0,1]$ and which satisfies $ f(0) = f(1) $, but which does not satisfy $f(x) = f(x+a)$ for any $x$. The solution from Spivak's solutions book is as follows: In general if $ {1 \over n+1} <a< {1 \over n} $ then define $f$ arbitrarily on $[0,a]$, subject only to $f(0)=0 , f(a)>0$ and  $f(1-na)=-nf(a).$  Then define $f$ on $[ka,(k+1)a]$ by $ f(ka+x)=f(x)+ ka.$  In particular we have, we have $f(1) = f(na + (1-na))= na+f(1-na)=0$ but $f(x+a)-f(a)=f(a)>0$ for all $x$. I don't see how we get $na+f(1-na)=0$ and the final $f(x+a)-f(a)=f(a)>0$ for all $x$. EDIT:  Post below found an error in the answer book.  Instead we require $f(ka+x)=k\color{red}{f(a)}+f(x)$, then we have $f(1)=0$ and the final statement also follows.","['continuity', 'calculus', 'analysis']"
2368238,Distance of satellite from tracking station given angles of elevation,"In my 10th grade precalculus class, we are learning trigonometry. One of the problems we had to solve was the following: A satellite passes over two tracking stations, A and B, 100 km apart. When the satellite is between the two stations the angles of elevation at the stations are measured as 89°  and 87° respectively. What is the distance a, between the satellite and station B. 'a' is the side opposite of the angle A. I've made the following image to help visualize the problem: Note: this image was not included with the original problem. Using the law of sines, I arrived at an answer of 1433 km. This was marked as the correct answer. (My class is virtual so I do not have any interaction with the teacher other than the online assignments unless I email her). I'm quite certain this is the way the problem was intended to be solved. Then I remembered that the Earth is not flat and at that scale, the Earth's curvature should have some kind of noticeable effect on the answer. Here's a summary of what I tried: using a value of 6371 km as the radius of the Earth. I assumed the angles of elevation of the stations were relative to the tangent of their location on the surface of the earth as I have hopefully demonstrated in this image: (The angles are exaggerated to show what I mean). I placed the origin at the center of the earth and gave station A a location of (6371, 0). I found the location of station B using a bit more trigonometry. Then, I calculated what the slope of the line of sight passing from each station to the satellite should be. I then found the equation of each line of sight using the point-slope formula for each station. After that, I found the location of the satellite by finding the intersection of the two lines. Then I used the distance formula to find the distance between the location of the satellite and station B.
I arrived at an answer of around 1842 km. However, I'm not sure if this is actually the right answer and don't know of any way to confirm it other than posting here. Is my answer actually correct? Although the curvature of the Earth should not be ignored, an extra 400 km does not quite seem right. Then again, the lines were almost parallel to begin with so any change could affect the answer more than I might expect. How would you go about calculating the actual answer to this problem? Is there a simpler way of going about this than what I outlined here?","['algebra-precalculus', 'trigonometry']"
2368243,$\cos^2 76^{\circ} + \cos^2 16^{\circ} -\cos 76^{\circ} \cos 16^{\circ}$,"Find the value of $$\cos^2 76^{\circ} + \cos^2 16^{\circ} -\cos 76^{\circ} \cos 16^{\circ}$$ I did it like this $$\cos^2 76^{\circ}+\cos^2 16^{\circ} = \cos(76^{\circ}+16^{\circ}) \, \cos(76^{\circ}-16^{\circ}).$$ So the expression is $$\cos 92^{\circ} \cos 60^{\circ}-\cos 76^{\circ} \, \cos16^{\circ}.$$ I couldn't simplify after that.",['trigonometry']
2368246,Is the construction of Zariski topology from polynomial rings functorial?,"Given a polynomial ring $k[X_1,...,X_n]$ over a field $k$, we can consider the space $k^n$ equipped with Zariski topology whose closed sets are exactly the algebraic sets. Is this construction functorial ? I.e. given two polynomial rings over some fields $k[X_1,...,X_n]$ and $L[X_1,...,X_m]$, and a ring homomorphism $ \phi : k[X_1,...,X_n] \to L[X_1,...,X_m]$, does there exist a continuous map (w.r.t. Zariski topology)  $\phi^* : L^m \to k^n$ such that  the assignment $\mathcal F$ from the category of polynomial rings over some field to the category of topological spaces defined as $\mathcal F (k[X_1,...,X_n])=k^n$ and $\mathcal F(\phi)=\phi^*$ , is a contravariant functor ? If this cannot be done in general, then is there some modification of the underlying category or the topology on the space so that the construction is functorial ? (I want an answer for this particular case of polynomial rings, not any general algebraic geometric answer, as I don't know any general algebraic geometry yet.)","['polynomials', 'algebraic-geometry', 'zariski-topology', 'commutative-algebra', 'category-theory']"
2368268,Does this system of non-linear differential equations have an analytical solution?,"I have this system of linear differential equations:
\begin{align*}
\frac{dA}{dt} & = k_1 - k_2AB - k_3A\\
\frac{dB}{dt} & = -k_2AB - k_4B\\
\frac{dC}{dt} & = k_2AB - k_5C\\
\frac{dD}{dt} & = k_6C
\end{align*}
Where $k_{i}$ are constants for $i\in\{1,2,3,4,5,6\}$. Will an analytic solution to these equations exist? Is there an easy way to tell? Thank you in advance","['ordinary-differential-equations', 'nonlinear-system', 'calculus']"
2368287,Do isometries send lines to lines?,"My question is if any isometry $f:V\to W$ between real normed spaces sends lines to lines. I've seen several questions/answers about this but only in euclidean spaces. So I thought it was false on general (real) normed spaces. However I found this theorem of Mazur-Ulam: any surjective isometry $f:V\to W$ is an affine map, hence it maps lines to lines. But if my isometry is not surjective, would this still apply? I think that considering the image space $f(V)$ it would be the same, because $f:V\to f(V)$ is affine and any line $L$ would be sent to a line $f(L)$ in $f(V)$ which is also a line in $W$. Is this correct? Thank you.","['real-analysis', 'isometry', 'normed-spaces', 'functional-analysis', 'linear-algebra']"
2368302,In how many ways the sum of 5 thrown dice is 25?,"What I thought about is looking for the number of solutions to
$$x_{1}+x_{2}+x_{3}+x_{4}+x_{5}=25$$ such that $1\leq x_{i}\leq6$
for every $i$. Now I know that the number of solutions to this such that
$0\leq x_{i}$ for every $i$ is $${5+25-1 \choose 5-1}={29 \choose 4}$$ How can I continue from here? Thanks",['combinatorics']
2368362,"$\int_\gamma{(x-y)dx + (x+y)dy}, \quad \gamma : x^2 + 2y^2 = 1 , \quad 0 \leq y $","I'm asked to find 
$$\int_\gamma{(x-y)dx + (x+y)dy}$$
where 
$$\gamma : x^2 + 2y^2 = 1 , \quad 0 \leq y$$
(with positive direction) i.e the upper half of the ellipse $x^2 + 2y^2 = 1$. My attempt Let $\sigma = \gamma + \gamma_1$ where $\gamma_1 = (t,0) \quad , \quad 0\leq t\leq 1.$ Since $\sigma$ is both positive and closed, Greens Formula can be used with
$\frac{dQ}{dx} - \frac{dP}{dy} = 2.$ $$\int_\gamma(x-y)dx + (x+y)dy = \int\int_D2dxdy - \int_{-1}^1t\cdot dt$$
$$= 2\cdot\frac{1}{2}\cdot (\frac{1}{\sqrt{2}}\pi) - 2 = \frac{\pi}{\sqrt{2}} - 2$$
where I evaluate the double integral simply by getting half of the area of the ellipsoid $ = \frac{1\cdot\frac{1}{\sqrt{2}}\cdot\pi}{2}.$ However, the answer is supposed to be $\frac{\pi}{\sqrt{2}}.$ What am I doing wrong?","['multivariable-calculus', 'greens-theorem']"
2368370,Does the Rogers-Ramanujan continued fraction $R(q)$ satisfy this conjectured infinite series,"Given the Rogers-Ramanujan continued fraction $R(q)= \cfrac{1}{1+\cfrac{q}{1+\cfrac{q^2}{1+\cfrac{q^3}{1+\ddots}}}}$ where $q=\exp(2\pi i \tau)$ , $|q|\lt1$ for the sake of brevity, let us introduce the following notation $R_{0}=\frac{1}{R(q)}$ $R_{1}=\frac{1}{\Big(\frac{1}{q}\Big(\frac{1}{R(q)}-1\Big)\Big)}$ $R_{2}=\frac{1}{\Big(\frac{1}{q^2}\Big(\frac{1}{\Big(\frac{1}{q}\Big(\frac{1}{R(q)}-1\Big)\Big)}-1\Big)\Big)}$ $R_{3}=\frac{1}{\Big(\frac{1}{q^3}\Big(\frac{1}{\Big(\frac{1}{q^2}\Big(\frac{1}{\Big(\frac{1}{q}\Big(\frac{1}{R(q)}-1\Big)\Big)}-1\Big)\Big)}-1\Big)\Big)}$ up to $R_{n}$ , $\frac{1}{R_{n}}=R(q^n,q)$ for natural number $n$ , where $R(a,q)$ is the Generalized Rogers-Ramanujan continued fraction as pointed out by @ccorn It is then conjectured that the following infinite series holds $\displaystyle -\frac{R'(q)}{R(q)}=\frac{1}{R_{0}R_{1}}-\frac{2q^2}{R_{0}R^2_{1}R_{2}}+\frac{3q^5}{R_{0}R^2_{1}R^2_{2}R_{3}}-\frac{4q^9}{R_{0}R^2_{1}R^2_{2}R^2_{3}R_{4}}+\frac{5q^{14}}{R_{0}R^2_{1}R^2_{2}R^2_{3}R^2_{4}R_{5}}-\dots\tag1$ It has the ascending continued fraction equivalent $\displaystyle -\frac{R'(q)}{R(q)}=
\frac{\frac{1}{R_1}+\large{\frac{\frac{-2q^2}{R_2}+\large{\frac{\frac{3q^5}{R_3}+...}{R^2_2}}}{R^2_1}}}{R_0}
\tag2$ After considering the Rogers-Ramanujan continued fraction with the factor $q^{1/5}$ and applying the identity $\frac{R'(q)}{R(q)}=\frac{1}{5q}\frac{(q;q)^5_{\infty}}{(q^5;q^5)_{\infty}}$ due to Ramanujan,we are led to the following beautiful identity $\displaystyle \frac{(q)^5_{\infty}}{(q^5)_{\infty}}=1-\frac{5q}{(R_{0}R_{1})}+\frac{10q^3}{(R_{0}R_{1})(R_{1}R_{2})}-\frac{15q^6}{(R_{0}R_{1})(R_{1}R_{2})(R_{2}R_{3})}+\frac{20q^{10}}{(R_{0}R_{1})(R_{1}R_{2})(R_{2}R_{3})(R_{3}R_{4})}-\frac{25q^{15}}{(R_{0}R_{1})(R_{1}R_{2})(R_{2}R_{3})(R_{3}R_{4})(R_{4}R_{5})}+\dots\tag3$ $\displaystyle \frac{(q)^5_{\infty}}{(q^5)_{\infty}}=1+5\sum_{n=1}^{\infty}\frac{(-1)^n nq^{\frac{n(n+1)}{2}}}{\prod_{k=1}^{n-1}\Big(R_{k}+q^k\Big)}$ Question :How do we prove that the conjecture is true? Remark As entry $9$ in chapter $19$ of Ramanujan's second notebook we have the ff well known identity $\displaystyle \frac{(q)^5_{\infty}}{(q^5)_{\infty}}=1-5\sum_{n=1}^{\infty}\left(\frac{n}{5}\right) \frac{n q^n}{1-q^n}\tag{4}$ Combining $(1)$ and Ramanujan's identity $(4)$ , we are immediately led to $\displaystyle \sum_{n=1}^{\infty}\left(\frac{n}{5}\right) \frac{n q^n}{1-q^n}=\sum_{n=1}^{\infty}\frac{(-1)^{n-1} nq^{\frac{n(n+1)}{2}}}{\prod_{k=1}^{n-1}\Big(R_{k}+q^k\Big)}\tag{5}$","['conjectures', 'number-theory', 'q-series', 'modular-forms', 'continued-fractions']"
2368376,"If $f$ is a real analytic function, then the solutions of $\dot{x} = f(x)$ are analytic as well","Let $f: \mathbb{R}^n \rightarrow \mathbb{R}^n$ be a real analytic function, i.e; for 
 all $x$ $\in$ $\mathbb{R}^n$ exists a neighbourhood $U_x \subset \mathbb{R}^n$ of $x$, satisfying $$f(y) = \sum_{i=0}^{\infty} \frac{1}{n!}f^{(n)}(x) \cdot(y-x)^n \hspace{0.1cm}\mbox{  for all }y\in U_x.$$ where $f^{(n)}$ is the $n$-th derivative of $f$, and $(y-x)^n = (y-x,\ldots,y-x)$. I want to prove that the solutions of the ODE
$$\dot{x} = f(x) $$
are analytics as well. I have seen many books saying that this result is true, but I could not find the proof anywhere","['ordinary-differential-equations', 'dynamical-systems']"
2368383,Showing a measure is transformation invariant as in the proof of Krylov Bogolubov,"First, context: Let $X$ be a compact metric space, and $C(X)$ the set of continuous functions on $X$ equipped with the sup norm. Let $T:X\to X$ continuous. Fix $x \in X$. Then one can show that $S_f^n(x) =\displaystyle \frac1n\sum_{k=0}^{n-1}f(T^k(x))$ is a bounded linear functional on $C(X)$, which has a convergent subsequence for all $g\in C(X)$. Denote the limit to be $S_g^\infty(x)$. This gives rise to the linear functional $L_x(g) = S_g^\infty(x)$, which is positive, so by Riesz Representation Theorem, we have $L_x(g) = \int_X gd\mu$ for some Borel probability measure. Now we are basically at my question. The author of the book I'm using (Dynamical Systems by Brin & Stuck) next shows that $S_g^\infty (x) = S_g^\infty (Tx)$ to conclude that $\mu$ is $T$-invariant. However, I don't know why this is. If we could work with characteristic functions, we would have the following: $\mu(A) = \int_X {\mathcal{X}}_A d\mu = L_x(\mathcal{X}_A)= L_x(\mathcal{X}_A\circ T) = \int_X \mathcal{X}_A \circ T d\mu = \mu(T^{-1}(A)).$ However, we've been working with continuous functions. It is not true, I don't think, that we can approximate simple functions by continuous functions in the sup norm. So I'm quite confused about how we get that $\mu$ is $T-$invariant. Moreover, I'm not sure I get why $T$ being continuous is necessary. For more context, here is the statement of the the theorem. Let $X$ be a compact metric space and
$T: X → X$ a continuous map. Then there is a $T$-invariant Borel probability
measure $\mu$ on $X$.","['real-analysis', 'dynamical-systems', 'functional-analysis', 'ergodic-theory', 'measure-theory']"
2368394,Derive the labour demand function.,"$$Y = 4[(K^α)(L^{(1-α)})]$$ I took the derivative with respect to $L$ , and ended up with: $$Y'= 4[(K^α)(1-α)L^{(-α)}$$ But the correct answer is something like: $$[4(1-a)K^a/w]^{(1/a)}$$ I'm not totally sure where the $w$ came from but my guess is MP of labor $= w$ , where $w =$ wages. Please show me the correct method.","['derivatives', 'partial-derivative', 'economics']"
2368411,Difference Between Double vs Single Integration in Polar Coordinates,"I am familiar with integrating polar equations in single variable calculus to find area. For example, to find the area enclosed by one loop of the four-leaved rose $r= \cos(2\theta)$ I would preform the integral $\frac {1}{2}\int^{\pi/4}_{-\pi/4}\cos^{2}\left(2\theta \right) d\theta$. Now, I am learning to do double integrals on polar coordinates, but I am conceptually stuck. A problem given by my textbook is to evaluate
$$\int^{2\pi}_{\pi}\int^{7}_{4}rdrd\theta$$
the answer to the question is found here. The answer states that the region described looks like this: I am used to thinking that an integral essentially takes a function in one dimension makes its antiderivative, which is described in one higher dimension. So, when performing a double integral I expect a volume, although the answer is an area. Because it is an area, it is no different than a single integral, but this must be wrong. I am thinking that the inter integral creates a line from $r=4$ to $r=7$, and then the outer integral sweeps this line from $\pi$ to $2\pi$ to create an area. I do not understand what the purpose of this would be, when we could essentially use single variable calculus to find the areas of two half circles and subtract the smaller one. What is the purpose and conceptual background of double integrals like the one above?","['multivariable-calculus', 'polar-coordinates']"
2368417,$\Bbb{R}^\omega$ is not Locally Compact,"Here is example 2 in chapter 3.29 in Munkres: The space $\Bbb{R}^\omega$ [defined as $\Bbb{R} \times \Bbb{R} \times \Bbb{R} \times ...$ endowed with the product topology] is not locally compact...For if $B = (a_1,b_1) \times ... \times (a_n,b_n) \times \Bbb{R} \times ...$ were contained in a compact subspace, then its closure $\overline{B}$ would be compact, which it is not. Would the following be a sufficient way of filling in the details? Recall that every compact subspace of a Hausdorff space ($\Bbb{R}^\omega$ is in fact metrizable) is necessarily closed. Thus this compact space containing $B$ must be closed. Now since the closure of $B$ is the smallest closed set containing $B$, the closure of $B$ must be contained in this compact set also. Again, recall that every closed subspace of a compact subspace is itself compact, making $\overline{B}$ compact too. However, if it were compact, then its image under the continuous map $\pi_{n+1}$, the projection of the $(n+1)$-th factor, would also be compact, but this is a contradiction since the image is $\Bbb{R}$, which is known not to be compact.","['general-topology', 'proof-verification']"
2368442,Probability that no two people sit next to each other,"Assume there are 10 people sitting around a circular table for lunch and those same 10 people meet again during dinner. I am interested in the probability no one sits next to the same person (I interpret ""sitting next to"" as being on left or right of the person). I ran a simulation and after 1 million randomizations comparing the lunch seating to the dinner seating, I got exactly 1 scenario that occurred where this happened. Is there a rigourous way to see if my simulation is correct?","['combinatorics', 'probability']"
2368471,Intuition for the differences between characteristic and minimal polynomial,"I understand the definitions of the characteristic and minimal polynomials, but I don't quite see an easy way to explicitly come up with examples of matrices for which the two polynomials satisfy some properties. For example, consider the following three exercises from Sheldon Axler's Linear Algebra Done Right , chapter 8C: Give an example of an operator on $\mathbb{C}^4$ whose characteristic polynomial equals $(z-1)(z-5)^3$ and whose minimal polynomial equals $(z-1)(z-5)^2$ . Give an example of an operator on $\mathbb{C}^4$ whose characteristic and minimal polynomials both equal $z(z-1)^2(z-3)$ . Give an example of an operator on $\mathbb{C}^4$ whose characteristic polynomial equals $z(z-1)^2(z-3)$ and whose minimal polynomial equals $z(z-1)(z-3)$ . For Exercise 6, it is obvious that we just take a diagonal matrix with diagonal $0,1,1,3$ . However, I don't quite see how to come up with examples of operators in questions 4 and 5 - I don't have any intuition between how the structure of an operator/matrix relates to its characteristic and minimal polynomials. Can someone please explain the reasoning one can use to find answers to the questions? From a quick search I understand that Jordan forms of matrices could be useful in finding explicit forms of matrices satisfying these properties, but these exercises are actually before the introduction of Jordan forms in the book so I would appreciate not using them in the answers. Thank you.","['matrices', 'linear-algebra']"
2368472,$n+1$ points in $\mathbb{R}^n$ with pairwise rational distances are linearly dependent,"Let $v_0$ be the zero vector in $\mathbb{R}^n$ and let $v_1, v_2, . . . , v_{n+1}$ be vectors in $\mathbb{R}^n$ such that the Euclidean norm $|v_i − v_j|$ is rational for every $0 ≤ i, j ≤ n + 1$. Prove that $v_1, . . . , v_{n+1}$ are linearly dependent
over the rationals. I was reading an ingenious proof of this result, an outline of which I present here: ""by passing to a subspace"", we may assume that $v_1,...,v_n$ are linearly independent over $\mathbb{R}$ since $v_1,...,v_{n+1}$ is a family of $n+1$ vectors in the $n$- dimmensional space $\mathbb{R}^n$ (considered over the field $\mathbb{R}$), they are linearly dependent over $\mathbb{R}$. Hence write $v_{n+1}=\sum_{k=1}^n\lambda_kv_k$. The goal is to show that $\lambda_k$ is rational. by the parrallelogram inequality, all the scalar products $<v_i,v_j>$ are rational. Hence the Grammian matrix $G$ of $v_1,..,v_n$ has all entries rational. Furthermore, since $v_1,...,v_n$ are linearly independent $G$ is invertible (well-known property of the Grammian) Let $w$ denote the column vector of size $n$ with coordinate $k$ given by $<v_{n+1},v_k>$. Let $\lambda$ denote the column vector of size $n$ with coordinate $k$ given by $\lambda_k$. Then we have $w=G\lambda$. From the above, $\lambda=G^{-1}w$ which is a product of matrices with rational entries, thus a rational matrix. done. The only step I don't understand is step 1. Why do we have the right to assume $v_1,...,v_n$ are linearly independent over $\mathbb{R}$, and which subspace are we ""passing to""?",['linear-algebra']
2368523,Find two points and one angle so that cone intersects the $xy$-plane in the parabola $y=x^2$,"Find $\vec{p}\in \mathbb{R}^3$, $\vec{u}\in S^2$ and $\phi \in \left(0, \frac{\pi}{2}\right)$ such that the cone $C(\vec{p}, \vec{u}, \phi)$ intersects the $xy$-plane in the parabola $y=x^2$. What I'm trying to do is the following: (1) Pick point $\vec{p}=(0,0,h)$, pick $\phi = \frac{\pi}{4}$ (to be adjusted later as needed). (2) The definition of the cone is as follows: $$C=C(\vec{p}, \vec{u}, \phi)=\left\{\vec{x}\in \mathbb{R}^3:|(\vec{x}-\vec{p})\cdot \vec{u}|=|\vec{x}-\vec{p}|\cos\phi\right\},$$ so we have $$\left((x,y,-h)\cdot (u,v,w)\right)^2=\left(x^2+y^2+h^2\right)\cos^2\phi=\frac12\left(x^2+y^2+h^2\right),$$ so that $$\left(xu+yv-hw\right)^2 = \frac12\left(x^2+y^2+h^2\right)$$ Now I'm lost. How can I now check whether or not my cone intersects the $xy$-plane in the parabola $y=x^2$? I can probably substitute $y=x^2$ into $\frac12\left(x^2+y^2+h^2\right)$ to get $$\frac12\left(x^2+y^2+h^2\right)=\frac12\left(x^2+x^4+h^2\right)$$ But then what next?","['analytic-geometry', 'projective-geometry', 'geometry']"
2368527,Geodesic Dome of Hexagons,"I am trying figure out the minimum size of a world that is made of hexagonal tiles for it to be not very noticeable. I cannot find anything online that is directly helping me; so I come here. In my model, every hexagon is 10 meters in diameter. Make a geodesic sphere with only hexagons. What is the minimum number of hexagons to produce this? What is the minimum number of hexagons I need to add to make the geodesic sphere larger? How do I calculate the angle of declination given the number of hexagons in a geodesic sphere? There are the questions I have come up with. Let me know if they need to be on their own question, but they are all closely related to each-other. Any help on this is much appreciated. Thank you","['geodesic', 'geometry']"
2368530,Stirling numbers of the first kind,"Proposition :  The Stirling numbers, $s(n, k)$ , satisfy the recurrence relation $$s(n,k) = s(n - 1, k - 1) + (n - 1)s(n - 1, k) \qquad (n \ge 1)$$ with initial conditions $s(0,0) = 1$ and $s(n,0) = s(0,n) = 0, n > 0$ . Proof : Consider forming a new permutation with $n$ objects from a permutation of $n - 1$ objects by adding a distinguished object. There are exactly two ways in which this can be accomplished. First, we could form a singleton cycle, leaving the extra object fixed. This increases the number of cycles by $1$ and so accounts for the $s(n - 1, k - 1)$ term in the recurrence. Second, we could insert the object into one of the existing cycles. Consider an arbitrary permutation of $n - 1$ objects with $k$ cycles. To form the new permutation, we insert the new object before any of the $n - 1$ objects already present. This explains the $(n - 1)s(n - 1, k)$ term of the recurrence. These two cases include all of the possibilities, so the recurrence relation follows with the given initial conditions. QED Here, I cannot understand the second part of the proof. How one arrives to this part: $$(n-1)s(n-1,k) $$","['permutations', 'combinatorics', 'stirling-numbers']"
2368565,"Does $(\bar X-\mu_X)/\hat{\theta}$ approach $N(0,1)$ in distribution for any unbiased estimator $\hat{\theta}^2$ of $\sigma_{X}^2/n$?","Note: I've asked this question on ""cross validated stackexchange"" with no biters. I guess this question belongs here instead. (I've deleted my question there.) In a basic statistics course we see CLT-like theorems appear for three cases of $\hat \theta$: For $\hat \theta=\frac{\sigma_X}{\sqrt{n}}$, this is classical CLT. For $\hat \theta=\frac{s}{\sqrt{n}}$, where $s$ is the sample variance. In the case of hypothesis testing, with $H_0: \mu_U=\mu_W$, let $X=U-W$. Then use $\hat \theta=\sqrt{\frac{s_1^2}{n}+\frac{s_2^2}{m}}$, where $s_1$ is the sample variance for $U$, and $s_2$ is the sample variance of $W$. So this makes me wonder. Is the statement in the title of the question, which generalizes all of these cases, correct? References (or counter-examples) would be ideal. If the statement in the title of the question incorrect, then what is the right generalization of CLT that captures cases 1-3 above?","['probability-theory', 'probability', 'statistics', 'central-limit-theorem']"
2368571,Principal disjunctive normal form conversion problem.,"I am solving a question where I have to convert $(\neg P \ \lor Q)$ this equation into principal disjonction normal form. so far I know that to convert it I have to multiply 1 with it. ie; $(\neg P \ \lor Q) \land T$, where $T$ is true.
now in the solution of the question after multiplying the equation with 1 it is written like this.
$(\neg P \ \lor Q) \land (\neg P \ \lor P)$.
so my question is why $(\neg P \ \lor P)$ is coming why can't we write $(P \ \lor \neg Q)$ instead.",['discrete-mathematics']
2368582,Abelian group structure on roots of a polynomial,"Assume $f \in \Bbb Z[x]$ is a monic polynomial,  s.t for every commutative ring $R$,  the solutions of $f(x)=0$ in $R$ can be endowed with an abelian group structure that is functorial respect to $R$. Some examples of  f include $ f(x)=x^n-1, 
 f(x)=x$ , with the group structure inherited from the additive group or the unit group. But there is an example with new group structure: $ f(x)=x^2-x$ with group operation given by $(x,y) \mapsto (x-y)^2$. So are there other types of such polynomial？How to classify all such $f$？ A neccesary condition is $f$ has root in every $R$ hence $f $ must have a linear factor.","['number-theory', 'abstract-algebra', 'group-schemes', 'algebraic-geometry']"
2368583,Find the determinant when all entries are $1$ except for zeroes on the main diagonal,"Let $J_n$ be an $n\times n$ matrix all of whose entries are $1$, and $I_n$ be the identity matrix. Define $$K_n = J_n-I_n$$ For $n=1$ to $5$ my (usually unreliable!) hand calculations suggest that $$\det K_n = (-1)^{n-1}(n-1)$$ Question (a) are these values correct?
(b) is the generalization to any positive integer $n$ valid?
(c) if (b) is true, how can the result be demonstrated? My only idea so far is to use the product of eigenvalues: $$\det K_n = \prod_{j=1}^n \lambda_j$$ ($-1$ is an eigenvalue for all $n$) Any assistance much appreciated. (note: a similar question concerning skew-symmetric matrices Determinant of a special skew-symmetric matrix may contribute some relevant ideas. or perhaps Determinant of a matrix with $t$ in all off-diagonal entries. has greater relevance)","['matrices', 'determinant']"
2368600,Is there a deeper pattern in the radius of convergence?,"I'm curious why the Taylor expansion of $\sin(x)$ and $\cos(x)$, for example, converge everywhere on the domain. But the expansion of $\frac{1}{1-x}$ converges for $|x| < 1$. I can compute it trivially using the ratio test and understand that the terms must decrease geometrically with the expansion for $\frac{1}{1-x}$ to convergence. But my question is more geared towards why this is the case: why some functions have power series' that converge everywhere and some that converge only on a certain interval? In other words, besides doing the ratio test, I don't see any sort of pattern or reasoning for why this is the case. Is there some higher level explanation someone can give to a person like myself who hasn't taken real or complex analysis, if the answer lies in those fields? I'm already a bit familiar with the fact that it is called the radius of convergence because it converges on a disc in the complex plane, but nothing further. Thank you.","['power-series', 'taylor-expansion', 'sequences-and-series', 'calculus']"
2368602,"Why is $\bigcup_{n\geq 1}[0,1-1/n] \neq [0,1]$?","Sorry but aren't we taking limits $\lim_{m \to \infty} \cup_{n =1 }^{m}[0,1-1/n] = [0,1]$? Why is this supposed to be equal to $[0,1)$?",['elementary-set-theory']
2368617,show that $xyz\in N$ if $x^n+y^n+z^n\in Z$,"Let $x,y,z\in R$ and such for any postive integers $n$ have
$$a_{n}=x^n+y^n+z^n\in Z$$
show that $xyz\in Z$ I have use
$$a_{n+3}=(x+y+z)a_{n+2}-(xy+yz+xz)a_{n+1}+xyza_{n}$$ since $2(xy+yz+xz)=(x+y+z)^2-(x^2+y^2+z^2)\in Z$
but $xy+yz+xz$ can't integers,because $2(xy+yz+xz)$ is integers","['algebra-precalculus', 'number-theory', 'polynomials', 'integers']"
2368630,Prove this trigonometric inequality about the angles of $\triangle ABC$,"In $\Delta ABC$ show that
  $$\cos{\frac{A}{2}}+\cos\frac{B}{2}+\cos\frac{C}{2}\ge \frac{\sqrt{3}}{2} \left(\cos\frac{B-C}{2}+\cos\frac{C-A}{2}+\cos\frac{A-B}{2}\right)$$ since
$$\frac{\sqrt{3}}{2}\left(\cos\frac{B-C}{2}+\cos\frac{C-A}{2}+\cos\dfrac{A-B}{2}\right)=\frac{\sqrt{3}}{2}\sum\cos\frac{A}{2}\cos\frac{B}{2}+\sin\frac{B}{2} \sin\frac{C}{2}$$","['inequality', 'trigonometry', 'cauchy-schwarz-inequality', 'uvw', 'holder-inequality']"
2368636,Functional and Borel measure,"Let $g:\mathbb R\to\mathbb R$, $g\in V$ Define functional $F:V \times\mathbb R\to\mathbb R$
$$(g,x)\mapsto F(g,x)$$ Since $\forall \text{operator }  T\  \exists\mu$ s.t. $  T(f)=\int_{\mathbb R} f \, d\mu$, where $\mu$ is a complex Borel measure, Is it possible to prove that $\forall  F\  \exists\mu$ s.t. $  F(g,x)=\int_{-\infty}^x g \, d\mu$? or any similar forms. On what kind of text I could learn more no this topic? After some reading I find a possible way of doing this: For any operator $F$ there exists another operator $T_x:V\to V$ s.t. $F(g,x)=T_x(g)$
then, if $T_x$ is continuous and linear,
$$T_x(g)=\int_\mathbb R gd\mu$$ where $\mu:\mathbb R\to\mathbb R$ is a Bounded variation (BV) function. I am not sure that, in this case, whether $\mu$ has to be a complex Borel measure or just BV function is enough?","['borel-sets', 'operator-theory', 'functional-analysis', 'measure-theory', 'analysis']"
2368651,Roots of continuous function,"Suppose $\varphi : \mathbb{C} \to \mathbb{C}$ is a continuous function. Are the roots of $\varphi$ necessarily discrete? I'm aware that the roots of a holomorphic function are discrete, but I cannot find a reference for continuous functions.","['continuity', 'complex-analysis']"
2368655,Limit of a function is equal to $L$ iff limit of absolute value of the function is equal to $|L|$.,"I've been watching complex analysis videos and it seems that a common technique is to consider the modulus of the complex-valued function and taking the limit instead. I was wondering if this is true: $$\lim_{z \rightarrow z_0} f(z) = L \iff \lim_{z \rightarrow z_0} |f(z)| = |L|.$$ If so, how would I prove this via epsilon-delta? I was wondering the validity of proving that $$\lim_{z \rightarrow -i} (z-i)\mathrm{Log}(z^2 + 1) = L$$ by doing these following steps: $$L = \lim_{z\rightarrow -i} |z-i||\mathrm{Log}(z^2 + 1)| \\=2\lim_{z\rightarrow -i}|\mathrm{Log}(z^2+1)| = 2\lim_{z\rightarrow -i}|\ln(z^2 +1) + i\mathrm{Arg}(z^2+1)|$$ which goes to infinity since the principle argument function is defined for $z^2 + 1$ for any $z$ but $\ln$ will go to infinity. Specifically, I'm doubting the step where I took the product of limits in the 2nd equality since the limit was infinite, and also the step where I conclude that the original limit is also infinite.","['complex-analysis', 'limits']"
2368669,Prove that $φ^x$ is close to an integer $y : x = 2^{n - 1}(2^n - 1)$,"I have a question. I have recently discovered that if you get the golden ratio $φ$, which is equal to $\frac{1 + \sqrt 5}{2}$, then if you raise this to the power of $2^{n - 1}(2^n - 1)$, the higher the value of $n$, the closer this comes to an integer. It does not converge to a particular integer, but just gets very close to some integer. Let this integer be $y$. I know that the expression $2^{n - 1}(2^n - 1)$ attains perfect numbers, which are numbers that are the sum of all its divisors. And if $2^n - 1$ is prime, then $2^n - 1$ is a Mersenne prime. Let's call this formula $x$. By testing $φ^x$ with the value $n \leq 30$ (on a $2000$ digit calculator), I have seen that it gets closer and closer to some integer $y$. I have also seen that if there is a Mersenne prime that divides into $x$ then $y$ is divisible by it as well. However, I cannot prove that this is true. Just by looking at some equation and seeing similar results does not mean I have proven it works for all results (which I can't test because $n$ can tend to infinity), so how do I prove/disprove that $φ^x$ gets closer to an integer $y$ the higher the value of $n?$ I would appreciate it if you showed me step by step and not skip all the steps and possibly show a formula that proves/disproves this if there is one. Thanks.","['golden-ratio', 'perfect-numbers', 'proof-verification', 'number-theory', 'prime-numbers']"
2368745,Equivalent definitions of $C^1-$boundary,"I am studying PDE, and I have two definition of $C^1$ open set as follow: Definition 1. (Evans' PDE book) An open set $\Omega \subset \mathbb{R}^N$ is $C^1$ if for each point $x_0 \in \partial \Omega$, there exist $r > 0$ and a $C^1$ function $\gamma: \mathbb{R}^{N-1} \to \mathbb{R}$ such that - upon relabeling and reorienting the coordinates axes if necessary - we have
$$\Omega \cap B(x_0,r) = \left\{ x \in B(x_0,r): x_N > \gamma(x_1,...,x_{N-1}) \right\}.$$ Definition 2. (I rewrote it partly based on Brezis' book and Trudinger's book) An open set $\Omega \subset \mathbb{R}^N$ is $C^1$ if for every $x_0 \in \partial \Omega$, there is an neighborhood $U \subset \mathbb{R}^N$ of $x_0$ and a $C^1-$diffeomorphism $\varphi: U \to B(0,1)$ such that
$$\varphi(U \cap \Omega) = B(0,1) \cap \{ y_n > 0\}, \varphi(U\cap \partial \Omega) = B(0,1) \cap \{ y_n = 0 \}.$$
The question is: Are two definitions actually equivalent?","['functional-analysis', 'real-analysis', 'partial-differential-equations']"
2368754,A proposition by the definition below has to be necessarily true.,"In the book by Kenneth H.Rosen the definition is- A proposition is a declarative sentence(that is a sentence which declares a FACT)which is either true or false but not both. There are 2 facets to my doubt-
1.The word ' fact ' in all its possible senses is something which is necessarily true,thus a proposition has to be true by definition.
2.what kind of sentence can be both true and false ,the 'but not both' portion seems superfluous. Could someone shed some light on this?I have gone through similar questions on here but they do not answer this exact question.","['logic', 'discrete-mathematics']"
2368816,Galois group of $x^7-2$,"Determine the fixed field of a non-trivial element of least order and the element of highest order and its action on the roots of $x^7-2$ in the galois group. With a little bit of research I was able to find out that $\text{Gal}(x^7-2)\cong\mathbb{Z}_6\ltimes\mathbb{Z}_7$. Unfortunately I'm not really familiar with the semi direct product so I fail to classify that group any further (if that's possible at all). Is it of order $42$? And if so, how do I find a fixed field of degree $21$ over $\mathbb Q$ (which corresponds to an element of order 2)? Also I don't know how to find out which element is of highest order? Edit: I would guess that I can take $\mathbb{Q}\left(\cos(\frac{2\pi}{7}),\sqrt[7]{2}\right)$ as the fixed field of the complex conjugation?","['abstract-algebra', 'galois-theory', 'group-theory']"
2368847,Showing that a metric space is discrete if and only if any function from it to another metric space is continuous,"Let $(X, d)$ be a metric space and $(Y, p)$ is another metric space that has at least two distinct elements. Show that $(X, d)$ is a discrete metric space (a metric space is defined to be discrete if every subset is open) if and only if any function from $X$ to $Y$ is continuous. I'm not too sure how to prove this, I'm guessing we need to use the open set characterization of continuity, i.e., $f:X \rightarrow Y$ is continuous if and only if for every open set $A \subset Y$, the set $f^{-1}(A) = \{x \in X : f(x) \in A\} \subseteq X$ is open. Can anyone provide a proof?","['real-analysis', 'metric-spaces']"
2368879,Unable to reach the desired answer in trigonometry.,"The question is: If $\sin x + \sin y = \sqrt3 (\cos y - \cos x)$
show that $\sin 3x + \sin 3y= 0 $ This is what I have tried: Squaring of the first equation (Result: Failure) Tried to use the $\sin(3x)$ identity but got stuck in the middle steps because I couldn't simplify it any further. Can someone provide any hint/ suggestion?","['algebra-precalculus', 'trigonometry']"
2368880,Does whether or not we assume the Axiom of Choice change the definition of a set?,"A set is ...  is a well-defined collection of distinct objects, considered as an object in its own right. For example, the numbers 2, 4, and 6 are distinct objects when considered separately, but when they are considered collectively they form a single set of size three, written {2,4,6} (from Wikipedia ). This means that $\{1, 1, 1, 1, 1, 1, ..., 2, 2, 2, 2, 2, 2, ..., 3, 3, 3, 3, 3, 3, ..., ...\}$ is the set $\{1, 2, 3, ...\}$, by definition. But, without the axiom of choice, how can we differentiate between the two?","['elementary-set-theory', 'axiom-of-choice']"
2368898,What do the Stone-Cech compactification's youger brothers look like?,"$X$ is a non-compact completely-regular space. $C(X)$ is the ring of continuous functions $X \to \mathbb R$. The Stone-Cech compactification $\beta(X)$ is the space of all multiplicative linear functionals $C(X) \to \mathbb R$, under the pointwise topology. $\beta(X) \  -$ in particular $\beta(\mathbb R) \ -$ is a well-studied space. It is compact and satisfies a universal property about extending continuous functions on $X$. Many of its topological properties are known to be independent of ZFC. But what if we only consider a subring $A \subset C(X)$ and the space of all multiplicative linear functionals $A \to \mathbb R$? Call the associated compactification $Y$. Then by Gelfand duality there is a continuous surjection $\beta(X) \to Y$ and so $Y$ is compact, and connected if $X$ is connected. But what else is known about $Y$? What properties does it share with $\beta(X)$ and what properties can we change by choosing $A$ differently? For example what is known when $X = \mathbb R$ and $A$ is any of the following subrings: $A = C^1(X)$ the ring of once-differentiable functions $A = C^\infty(X)$ the ring  of smooth functions $A = P(X)$ the ring of polynomials $A = L(X)$ the ring of Lipschitz functions I can easily believe all the $Y$'s satisfy a corresponding property about lifting the elements of $A$ to $Y$. But what else? Or does all of these $A$'s being dense in $C(X)$ just turn out that $Y = \beta(X)$?","['functional-analysis', 'general-topology', 'ring-theory']"
2368904,"Stirling #s of 1st kind. Prove the following: $ \sum_{k=0}^n S_1(n,k)x^k = x(x +1)···(x +n−1) $","$\mathbf {Theorem:} $ $$ \sum_{k=0}^n S_1(n,k)x^k = x(x +1)···(x +n−1) $$ I want to prove the above theorem, and I know that I should use the recurrence relation $$ S_1(n,k)=S_1(n-1,k-1)+(n-1)S_1(n-1,k). $$ 
I also know that $$\sum_{k=0}^n S_1(n,k)=n! ,\quad S_1(n,1)=(n-1)! ,\quad S_1(n,n)=1,$$
and $$S_1(n,0)=S_1(0,n)=0 \quad \text{if} \quad n\neq0. $$
I just started doing this:$$ \sum_{k=0}^n S_1(n,k)x^k =S_1(n,0)+S_1(n,1)x+S_1(n,2)x^2+...+S_1(n,n)x^n.$$
However I do not know how to proceed further. Can anybody help at this point?","['permutations', 'combinatorics', 'stirling-numbers']"
2368912,Proof of Theorem 9.9 in Part III of Hartshorne's Algebraic Geometry,"I am studying section III.9 on flat morphisms of  Hartshorne's Algebraic Geometry and stuck in the proof of the following Theorem 9.9 (Hartshorne, page 261) . Let $T$ be an integral noetherian scheme. Let $X \subseteq \mathbb{P}^n_T$ be a closed subscheme. For each point $t \in T$, we consider the Hilbert polynomial $P_t \in \mathbb{Q}[z]$ of the fibre $X_t$ considered as a closed subscheme of $\mathbb{P}^n_{k(t)}$. Then $X$ is flat over $T$ if and only if the Hilbert polynomial $P_t$ is independent of $t$. My situation is the following. $\mathscr{F}$ is a coherent sheaf on $X=\mathbb{P}^n_T$ for $T=Spec(A)$ with a local noetherian ring $A$ and I want to show that if $H^0(X, \mathscr{F}(m))$ is a free $A$-module of finite rank for $m\gg0$, then $\mathscr{F}$ is flat over $T$. For this, Hartshorne defines a graded $A[X_0,\dots,X_n]$-module \begin{align*}
 M = \bigoplus_{m\geq m_0}	H^0(X, \mathscr{F}(m)),
 \end{align*} where $m_0$ is choosen large enough, so that the $H^0(X, \mathscr{F}(m))$ are all free for $m \geq m_0$. (By the way: Don't we need the finiteness condition on the rank?) Then he claims that $\mathscr{F}=M^{\sim}$ by a Proposition (Prop. 5.15 in II.5), which states that there is a natural isomorphism $(\Gamma_*(\mathscr{F}))^{\sim} \cong \mathscr{F}$. But I don't see why this gives what he claims. He says ""Note that $M$ is the same as $\Gamma_*(\mathscr{F})$ in degrees $m \geq m_0$.""  On this I agree with him, since by definition \begin{align*}
 \Gamma_*(\mathscr{F}) = \bigoplus_{m \in \mathbb{Z}} \Gamma(X, \mathscr{F}(m)),
 \end{align*} and $\Gamma(X, \mathscr{F}(m)) \cong H^0(X, \mathscr{F}(m))$. But what has happened to the parts of degree less than $m_0$ in the tilde-construction, so that he gets $M^{\sim}=(\Gamma_*(\mathscr{F}))^{\sim}$, which now would imply $M^{\sim} \cong \mathscr{F}$ by the Proposition mentioned above?","['hilbert-polynomial', 'sheaf-cohomology', 'algebraic-geometry', 'flatness']"
2368988,Reflection inside spherical mirror,"Suppose you are inside a perfectly spherical mirror. You shoot one beam of light and it reflects on the walls of the mirror. Considering the intensity is constant will the beam of light hit you again? I can shoot it from anywhere inside the sphere and I am a point. One answer mentions that the beam will always come arbitrarily close. How to prove this? I thought of this question while sleeping. But even after a day of thinking about this problem I couldn't solve it. Note The only answer is brief and does not explain or prove what is says. Looking for detailed answers preferably using illustration and valid mathematical proofs for the statements they make. Would like to read about possible generalizations and variations of this question. Please don;t restrict yourself to this specific situation and do not hesitate to write long answers which give a wide overview of these type problems. Bounty-awarded answer is likely to be long, detailed and self-sufficient mathematically in terms of proving the facts it states.","['physics', 'proof-explanation', 'geometry']"
