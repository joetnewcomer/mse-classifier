question_id,title,body,tags
2446094,Is this a Taylor series? $\ln(x) +1 = \sum_{n=0}^{\infty} \frac{n+1}{n!} \cdot \frac{(\ln(x))^n}{x}$,"Can you provide a proof of this identity using only calculus? $$\ln x + 1 = \sum_{n=0}^{\infty} \frac{n+1}{n!} \cdot \frac{(\ln x)^n}{x}$$ By the way, here is how I arrived at it: There is string of length $x$ units. Select a point on the string uniformly at random and cut the string at that point. Repeat the process with the string on the left side of the cut until the string you have is shorter than $1$ unit. The problem is to figure out the expected number of cuts. Here is how I did it: Let $E(x)$ denote the expected number of cuts to be made on a string of length $x$. If $x<1$, clearly, $E(x)=0$. If $x>1$, we have: \begin{align} E(x) &= 1 + \int_0^x E(u) \cdot \frac{du}{x} \\
                   &= 1 + \frac 1x \int_1^x E(u) \ du
\end{align} Multiplying by $x$ and differentiating (applying the Fundamental Theorem of Calculus), \begin{align} xE'(x) +  E(x) &= 1 + E(x) \\
   \Rightarrow E(x) &= \ln x + C \end{align} Clearly for $x=1, \ E(x)=1$ thus $E(x) = \ln x + 1$ However, we can also calculate $E(x)$ in a different way: Let $P(n,\ x)$ denote the probability of exactly $n$ cuts being made on a string of length $x$. If $x<1$, $P(n,\ x) = 0$; if $n=1$ and $x>1$ $P(n,\ x)=\frac 1x$; if $n>1$ and $x>1$: \begin{align} P(n,\ x) &= \int_0^x P(n-1,\ u) \cdot \frac{du}{x} \\
                       &= \frac 1x \int_1^x P(n-1,\ u) \ du \end{align} I calculated that $P(1,\ x) = \frac 1x,\ P(2,\ x) = \frac{\ln x}{x},\ P(3,\ x) = \frac{(\ln x)^2}{2x},\ P(4,\ x) = \frac{(\ln x)^3}{6x}$ This led me to hypothesize that $P(n,\ x)=\frac{(\ln x)^{n-1}}{x(n-1)!}$, which can be proven by induction: \begin{align} P(n,\ x) &= \frac 1x \int_1^x P(n-1,\ u) \ du \\
                       &= \frac 1x \int_1^x \frac{(\ln u)^{n-2}}{u(n-2)!} \ du \\                     &= \frac 1{x(n-2)!} \int_1^x (\ln u)^{n-2}\ d(\ln u) \\
                       &= \frac 1{x(n-2)!} \left[\frac {(\ln u)^{n-1}}{n-1}  \right]_1^x \\         &= \frac{(\ln x)^{n-1}}{x(n-1)!} \end{align} But then $E(x)$ can be written as follows: \begin{align} E(x) &= \sum_{n=1}^{\infty} n \cdot P(n,\ x)  \\ 
                   &= \sum_{n=1}^{\infty} n \cdot \frac{(\ln x)^{n-1}}{x(n-1)!} \\                 &=  \sum_{n=0}^{\infty} \frac{n+1}{n!} \cdot \frac{(\ln(x))^n}{x} 
\\ \\
\therefore \ \ln x + 1 &=  \sum_{n=0}^{\infty} \frac{n+1}{n!} \cdot \frac{(\ln(x))^n}{x} \ \blacksquare \end{align} So can you prove this result by finding an appropriate Taylor series (this would be especially appreciated) or if not using Taylor series then using just the methods of calculus?","['real-analysis', 'taylor-expansion', 'probability', 'calculus']"
2446101,Finding the general formula for the powers of a matrix,"Let $A=\begin{bmatrix}0&1\\1&0\end{bmatrix}$. Find the formula for $A^n$ and prove it. The way I tried to solve it is like this: If we find $A^2$, $A^3$ and so on you will notice this patern: If $n$ is odd $A^n=\begin{bmatrix}0&1\\1&0\end{bmatrix}$. If $n$ is even then $A^n=I$. To prove this I used mathematical induction.
We see that the base case is $A^1$ and $A^2$.
Now we suppose the statement holds for a natural number $n$. If $n+1$ is odd then this means that n is even and we see that the matrix $A^{n+1}=A^nA=\begin{bmatrix}0&1\\1&0\end{bmatrix}$, so the statement holds in this case. If $n+1$ is even then this means that $n$ is odd and we see that the matrix $A^{n+1}=A^nA=I$, so the statement holds in this case also. As a consequence the statement holds for all natural numbers. I want to know if this proof is right or not? Can someone help me?","['matrices', 'induction', 'proof-verification']"
2446135,Continuity on paths implies continuity on space?,"Suppose we have some map $f:X\rightarrow Y$. Given any path in $X$, $\gamma:I\rightarrow X$ we know the composite map $f\circ\gamma:I\rightarrow Y$ is continuous. Can we say that $f$ is continuous? Note: $I=[0,1]$ is the closed unit interval in the real line Also, I'm specifically interested in the case for which $X=I\times I$.","['continuity', 'general-topology']"
2446222,"Proof that $C([-1,1])$ not complete","I need help with the following exercise, leading to the conclusion that $X := C([-1,1])$ (space of continuous functions $f: [-1,1] \to \mathbb R$) equipped with the $\lVert \cdot \rVert_1$-norm is not complete: For each $n\in \mathbb N$, define $\delta_n : X \to \mathbb C$ by 
  $$\delta_n(f) := \frac{n}{2} \int_{-1/n}^{1/n}f(x)\,dx.$$
  Prove: 1) $\delta_n \in X'$ for each $n\in \mathbb N$ and $\lVert \delta_n \rVert = \frac{n}{2}$ (the last norm is the operator norm). 2) $\delta_\infty : X \to \mathbb C, \delta_\infty(f) := f(0)$ does not define a bounded linear functional on $X$. 3) $\lim_{n \to \infty} \delta_n(f) = f(0) $ for all $ f \in X$. 4) $X$ is not complete. Attempt:
1) To show that $\delta_n(f)$ is bounded is straight forward. However, how do I compute the operator norm? I showed $$\lVert \delta_n \rVert \leq \frac{n}{2}$$
but how do I get equality? 2) I tried to find a bounded sequence $f_n$ for which $(\delta_\infty(f_n))_n$ is unbounded, but couldn't think of something that worked out. 3) No problems here. 4) How does this follow from the other points?","['functional-analysis', 'complete-spaces', 'real-analysis', 'analysis']"
2446252,"If $T$ is one-to-one linear transformation, then can we prove that $T$ has a left inverse transformation without AC?","Let $V,~W$ be two vector space of a field $F$. Let $T:V\to W$ be a linear transformation. Then does $T$ has a left inverse linear transformation? I'd tried very hard to think of it, but I still can't see the way. And if so, can we prove it without Axiom of Choice? PS: The problem is that, the left inverse $S$, must be a function such that $S\big\vert_{\text{range}(T)}(y)$ be defined by the value $x\in V$, such that $T(x)=y$. However, how do we define the function value of $S$ outside $\text{range}(T)$, such that $S$ is linear ?","['functions', 'linear-transformations', 'set-theory', 'linear-algebra', 'axiom-of-choice']"
2446256,Would this be classified as a corner or a cusp?,"I am teaching about differentiability in an introductory single-variable calculus course.  We went through the usual classification of points at which functions are non-differentiable into corners, cusps, and vertical tangents.  One of my students then asked a question which I'm not sure of the answer to.  Here's my write-up for the community here (using more formal language than I use in my class, of course). We begin by defining our terms: Let $X \subseteq \mathbf R$ and let $f: X \to \mathbf R$.  Let $c \in X$ be a point at which $f$ is continuous.  We say that $f$ is differentiable at $x=c$ if and only if $\lim_{h \to 0}\frac{f(c+h)-f(c)}{h}$ exists. Suppose now that this limit fails to exist, so $f$ is not differentiable at $x=c$.  The limit may fail to exist for several different reasons. If there exist $a, b \in \mathbf R$ such that $\lim_{h \to 0^+}\frac{f(c+h)-f(c)}{h}=a$ and $\lim_{h \to 0^-}\frac{f(c+h)-f(c)}{h}=b$, but $a \neq b$, then we say that $f$ has a corner at $x=c$. If $\lim_{h \to 0^+}\frac{f(c+h)-f(c)}{h}=\pm\infty$ and $\lim_{h \to 0^-}\frac{f(c+h)-f(c)}{h}=\mp\infty$, then we say that $f$ has a cusp at $x=c$. If $\lim_{h \to 0}\frac{f(c+h)-f(c)}{h}=\pm\infty$, then we say that $f$ has a vertical tangent at $x=c$. Here's the question: Suppose our function $f$ is defined by $f(x)=\begin{cases} -\arctan(x) & ,\; x \leq 0 \\ \sqrt{x} & ,\; x \gt 0 \end{cases}$ It is clear that $\lim_{h \to 0^-}\frac{f(0+h)-f(0)}{h}=-1$ and $\lim_{h \to 0^+}\frac{f(0+h)-f(0)}{h}=\infty$.  So how should we classify the failure of $f$ to be differentiable at $x=0$?","['derivatives', 'calculus', 'limits']"
2446258,How to calculate expected loss in money when overbooking?,"I'm currently stuck on the following problem where we know that for an airline it is a 7% probability that a passenger will not meet up for departure. So to get a better use of the plane capacity the airline overbook the tickets. The plane for this task has 243 seats. The thing is that the airline loses 1000\$ for each non-used seat in the plane. If a passenger does not get a spot because of the overbooking, the passenger will be compensated with 4000\$. We want to find an expression for the expected loss if we take $n$ orders. And by using the expression/graph we want to find the number of orders such that we minimize the expected loss. The numerical answer is given, which is 258 orders which results a loss of $5564\$$. I understand that this will be a binomial distribution if we define a stochastic variable $X$ which says how many passengers that really meet ups for departure... but how do I use this fact to get the desired expression? If we do not overbook, i.e. only take 243 orders, the expected loss is to be $243 \cdot 0.07 \cdot 1000 = 17010 \$$, but if I try to do the same for $n = 258$ orders I do not get the same answer as the solution(which would be $5564\$$), why could I do that for $n = 243$, but not for $n= 258$?","['statistics', 'binomial-distribution', 'probability']"
2446292,Tricky dice problem,"We simultaneously roll two dice in one round until at least one of them shows 3 once. What is the expected number of rolls needed? I've calculated probability of getting 3 on the 1st roll 
I am really bad in math, sorry ðŸ˜– $= (1/6)^2 + 2(5/6 * 1/6) = 11/36$ Then on the second $= (1 - p(\text{on the 1st roll})) \cdot (11/36)$ Third $= (1 - p(\text{on the 2nd})) \cdot (11/36)$ And so on, then I've just calculated the expected number of this distribution and reached the conclusion that I'll need at least $4$ rolls, since we operate only with integers. I am really confused, if this approach is correct?
Or should we use the geometric distribution and to get the expected number of rolls we just have to divide $1$ over probability of success, i.e. $11/36$? And consequently how can we find the minimum number of dice needed to get $3$ at least once on at least one dice if we can simultaneously  roll them no more than $2$ times? Thank you in advance.ðŸ’•","['statistics', 'probability', 'dice']"
2446329,How to prove $\sqrt 2 x + \sqrt {2{x^2} + 2x + 1} + \sqrt {2{x^2} - 10x + 13} + \sqrt {2{x^2} - 22x + 73} \geq \sqrt{157}$?,"$$
\quad{\forall x\in \mathbb{R}:\\
\sqrt 2 x + \sqrt {2{x^2} + 2x + 1}  + \sqrt {2{x^2} - 10x + 13}  + \sqrt {2{x^2} - 22x + 73} \geq \sqrt{157}}$$ I want to prove this.I tried to graph it and see whats going on ... https://www.desmos.com/calculator/xgjovvkal6 I also tried to prove it by derivation ,but it become complicated . Can anybody give me an idea ? I am thankful in advance.","['radicals', 'inequality', 'roots', 'calculus', 'algebra-precalculus']"
2446363,"Conditions to ensure that if every element of a finitely generated group $G$ of is of finite order, then $|G|< \infty$.","In general, it's not true that every element being of finite order with $G$ finitely generated is enough to ensure that $G$ is finite. I made some observations: the first observation is incorrect. Maybe a different argument can be used? If $G$ is finitely presented, then the previous data is enough to ensure that $G$ is finite 
since  for generators $\{a_i\}$ with order $n_i$, there should be a surjection $$\langle a_1, \dots a_n \mid a_1^{n_1}, \dots, a_n^{n_n}\rangle=H \to G$$
by taking the quotient by the normal closure of further relations. Or, since all said conditions in $H$ are true in $G$ as well, we should be able to find tietze transformations that make this work. If $G$ is abelian, we should also be good by the classification theorem. Question: Are there conditions for which we can conclude that a finitely generated group where every element is of finite order, is finite.","['finite-groups', 'group-theory']"
2446392,How to work out the trajectories of the cannons in Mario 64,"So recently I've played one of my childhood games again, namely Super Mario 64, and as anyone who has played it as well knows, you will find cannons at specific locations that allow Mario to send himself flying in the direction he is pointing at, even allowing him to change its rotational angle . Now obviously the trajectory resembles a parabola, and obviously the parabola's general shape (as in its coefficient a) depends on the cannon's angle, and (correct me if I am wrong, physicists) on how much Mario gets accelerated by the cannon. Some quick research said Mario's mass = 90kg = m_mario I couldn't really come up with a velocity through research, so I am just gonna assume that v = 20m/s v0 = 0m/s The acceleration from firing the cannon feels rather fast, so I am gonna assume a = (20-v0)/ 0.3 = 66m/sÂ². Therefore, f_Cannon = 90*66 = 5940N (just in case that's gonna be of use later on) Now my first question is: I'm sure there must be a way of sort of ""converting"" the rotational angle and f_cannon into a correlating coefficient ""a"" for the parabola trajectory. I suspect trigonometric functions might be helpful, but I can't really think of a way to solve this problem. Question #2: I also wondered if it would be possible to find out what ""a"" would have to be equal to in oder for the parabola to have a specific root apart from x = 0 (assuming b = 1 and c = 0, always). Example: Say at x = 7 there is a power star, and Mario wants to collect the star hovering in the air just before he hits the ground at x = 7. if the parabola = axÂ²+x, then it is possible to find a: f(a) = 49a+7 a = (-7/49) Here are my personal figures for solving this problem How to find a for the root x = 7, assuming b = 1 and c = 0 Please excuse any mathematical errors of mine, I'm just your average freshman who likes math a lot, lol. Thanks!","['algebra-precalculus', 'physics']"
2446396,Probability of not finding a joker among 54 cards until the 54th draw?,"I manage a ""Joker Poker Raffle"" for a veterans club in Shelton, WA.  We start each round with 54 cards (4 suits @ 13 cards plus 1 mini Joker and 1 Jackpot Joker) sealed in identical envelopes.  Each Saturday we sell tickets and then draw one ticket from a tumbler.  The person with the winning ticket selects one envelope.  If the selected envelope contains the Joker, the Jackpot is awarded, if not the game goes on.  The current round has gone for 53 weeks without a Jackpot win.  Folk are asking me what are the odds. I wonder if the question can be viewed as flipping a fair coin 53 times and getting 53 heads and then getting 1 tail? In addition, several players take the position that inasmuch as everybody knows that the last envelope contains the Joker, we should end this round and start a new round with 54 new envelopes.  Their thinking is that the first 53 draws posed dual risk; i.e. the risk that one's ticket would be selected plus the risk that the winning ticket holder would select the envelope with the Joker.  Obviously, on the 54th draw, there is only singular risk. Can you mathematicians help us veterans?  (A)  Is not identifying the Joker until the 54th draw a rare event, or can we expect this to happen frequently and (B) Is it fair to allow the person whose ticket is selected next Saturday to claim the Jackpot, or should we start a new round with 54 envelopes? Thank you
Brian Walsh",['probability']
2446431,What's the difference between saddle and inflection point?,"As far as I know, inflection point is a point where the concavity of the function changes. These points can be found by taking the second derivative and check if it is 0 and see whether the concavity actually changes on the either sides of the point. I saw a video which states that saddle point is essentially the same thing but it applies to functions having two or more input variables.
But in this link http://mathworld.wolfram.com/SaddlePoint.html , they have found saddle points of a single variable function. I am confused between both of these.","['maxima-minima', 'calculus']"
2446443,Definition of sum of subspaces.,"The definition of sum of subspaces in Axler Sheldon book ""Linear Algebra Done Right"" is: The sum of $U_1,\dots,U_m,$ denoted $U_1+\cdots+U_m$, is defined to be the set of all possible sums of elements of $U_1,\dots,U_m$. More precisely, $$U_1 + \cdots + U_m = \{u_1 + \cdots + u_m : u_1 \in U_i,\dots, u_m \in U_m\}.$$ Right after the definition, the  following example is provided: Suppose $U$ and $W$ are subspaces of $F^3$ given by
$$ U = \{(x,0,0) \in F^3 : x \in F\} \text{ and } W = \{(0,y,0)\in F^3: y \in F\}.$$
then \begin{equation}\tag{1}\label{1}U+W = \{(x,y,0) : x,y \in F\}.\end{equation}
Then let $V$ be $$V = \{(y,y,0)\in F^3: y \in F\}.$$ the book says that $U+V$ is still given by equation \eqref{1}. I am confused with the previous statement, as I would expect that $U+V = \{(x+y,y,0):x,y\in F\}.$ I would appreciate an explanation of this example.","['linear-algebra', 'vector-spaces']"
2446491,First Order DE Mixing Problem,"I've tried this problem quite a few times but I can't seem to get it right. A large tank contains 60 litres of water in which 23 grams of salt is dissolved. Brine containing 15 grams of salt per litre is pumped into the tank at a rate of 8 litres per minute. The well mixed solution is pumped out of the tank at a rate of 2 litres per minute. (a)    Find an expression for the amount of water in the tank after t minutes. (b)    Let x(t) be the amount of salt in the tank after t minutes. Which of the following is a differential equation for x(t)? EDIT: I totally misread part (a) and thought it was asking for an equation for the amount of salt in the tank. I do still need help finding x(t), since I need it for the next question. I'm assuming I have to find (b) before I can answer (a). I found the differential equation to be $$\frac{dx}{dt}=120-\frac{2 x(t)}{60+6t}$$ which was correct. Since this is a linear first order DE, I found the integrating factor $$m(x)=e^{\int\frac{2}{60+6t} dt}$$ $$m(x)=e^{\frac{1}{3}\int\frac{1}{10+t} dt}$$ $$m(x) = e^{\frac{1}{3} ln(10+t)}$$ $$m(x) = (10+t)^{\frac{1}{3}}$$ Multiplying the DE by this gives $$\int ((10+t)^{1/3}x(t))'= \int 120*(10+t)^{1/3}$$ $$(10+t)^{1/3}x(t)=120(\frac{3}{4}(10+t)^{4/3}+C)$$ $$\therefore x(t) = \frac{120(\frac{3}{4}(10+t)^{4/3}+C)}{10+t)^{1/3}}$$ Using the inital value $x(0)=23$ , since 23 grams of salt is dissolved in the tank initially, I found C to be $$23 = \frac{120(\frac{3}{4}(10+0)^{4/3}+C)}{10+0)^{1/3}}$$ $$C = \frac{23}{900}$$ Subbing this into the equation and simplifying gives the final answer $$x(t) = \frac{120(\frac{3}{4}(10+t)^{4/3}+\frac{23}{900})}{(10+t)^{1/3}}$$ $$x(t) = \frac{90(10+t)^{4/3}+\frac{46}{15}}{(10+t)^{1/3}}$$ Which wasn't correct. EDIT: Also, I should add, I only have one try left on the above question, but the next question is In Problem #8 above the size of the tank was not given. Now suppose that in Problem #8 the tank has an open top and has a total capacity of 192 litres. How much salt (in grams) will be in the tank at the instant that it begins to overflow? Since there is 60L in the tank initially, and the contents if increasing at 6 L/min, I found t with the equation $$60+6t = 192$$ $$t = 22$$ I never actually entered the above equation, so I'm not 100% sure that it's incorrect, but I entered $x(22) = 2880.97$ into this question and it was incorrect.",['ordinary-differential-equations']
2446495,Cell Structure of Three holed torus,"How do I construct a torus as a cell structure? Visually I do not think I quite see the construction. Furthermore, how do I construct a 3-holed torus, that is, a 3 genus surface as a cell structure?","['algebraic-topology', 'general-topology', 'cw-complexes']"
2446496,Prove that $K = \cap_{g \in G} g^{-1}G_xg$,"Relevant definitions: $$G_x = \{g \in G \mid \rho_g(x) = x\}$$ Question: Let $\rho: G \to S(X): g \mapsto \rho_g$ be a transitive group
  action. Let $K := \ker \rho$. Then $K = \cap_{g \in G} g^{-1}G_xg$ My attempt (which I know is wrong, since I didn't use transitivity!): $\boxed{\supset}$ Let $k \in \cap_{g \in G} g^{-1}G_xg$. Then, for all $g \in G$, there
  exists $l \in G_x$ such that $k = g^{-1}lg$, such that $\rho_k =
 \rho_{g^{-1}lg} = 1_X$, meaning that $k \in K$ $\boxed{\subset}$ Let $k \in K$ and $g \in G$. Then, consider the group element $h :=
gkg^{-1}$. Then, we have $\rho_h(x) = x$, such that $h \in G_x$. Now,
  it follows that $k = g^{-1}hk \in g^{-1}G_xg$ for any $g \in G$, as
  desired. Can someone point out where my mistake is? I am quite sure I made a mistake since I never used transitivity.","['group-actions', 'abstract-algebra', 'group-theory']"
2446528,"Is the limit $\lim_{(x,y) \to \infty} \frac{x+2y}{x^2 - 2xy + 2y^2}$ zero?","I have this limit:$$\lim_{(x,y) \to \infty} \frac{x+2y}{x^2 - 2xy + 2y^2}$$ At first sight seems that limit equals 0. But WolframAlpha says that there is no limit. I tried to prove it. I considered cases $y = kx$, and so on. I never got to find subsequence, whose has limit $\neq 0$. I think there is a problem in denominator. When $x\rightarrow \infty$ and $y \rightarrow \infty$ we got there $\infty - \infty + \infty$. It's unclear what to do with it and how to find necessary subsequence. Maybe i'm on the wrong way to solve it. Please, give me a tip.","['functions', 'calculus', 'limits']"
2446630,Showing a set is finite or countable,Let $B$ be a set of positive real numbers with the property that adding together any finite subset of elements of $B$ always gives a sum of 2 or less. Show $B$ must be finite or countable. I do not know where to start with this proof. Any help is appreciated.,"['real-analysis', 'elementary-set-theory']"
2446698,Discrete Math (Proof Techniques),"I'd like to get a bit of an explanation with the correct answer, for the following questions that I missed on my hw. Consider the following proof that all squares are positive: Let $n$ be an integer; $n$ is either positive or negative.  If $n$ is
positive, then $n^2$ must be positive since it's the product of
positive numbers; if $n$ is negative then $n^2$ must be positive as the
product of two negative numbers.  Therefore $n^2$ is always positive. What is wrong with this proof? There's an issue with the logic in one of the cases. The case structure doesn't cover all possibilities. The case structure contains overlapping cases. Nothing, this is a perfectly good proof. (I thought there would be nothing wrong, because both parts of the statement are always true) Which of the following statements are true? Contraposition is a more powerful proof method than contradiction, because anything we can prove by contraposition can also be proved by contradiction. Contradiction is a more powerful proof method than contraposition, because we're not limited to proving universal conditional statements. The methods of contradiction and contraposition are completely equivalent to each other. Anything that we can prove by contradiction can also be proved by direct methods. Suppose you need to prove that all perfect numbers are even; you proceed by showing that any odd perfect number must also be even.  This is an example of: An invalid argument. Proof by contraposition. Proof by contradiction. Proof by division into cases. (I believe I had my contraposition and contradiction mixed up, and the correct answer to this question should be contradiction?) Which of these would disprove the universal assertion ""All pentagonal numbers are either triangular or square""? An example of a number that is both square and triangular, but not pentagonal. A proof that there are no pentagonal numbers. An example of a pentagonal number that was neither triangular nor square. A proof that no triangular number can be pentagonal. An example of a pentagonal number that is both square and triangular. Thank you",['discrete-mathematics']
2446699,$X^4-4X^2-1$ irreducible over $\mathbb{Q}[X]$,"I want to show, that $X^4-4X^2-1$ is irreducible over $\mathbb{Q}[X]$.
Since there are no roots in $\mathbb{Q}$ it has to be: $(X^4-4X^2-1)=(X^2+aX+b)(X^2+cX+d)$ Comparision of the coefficients shows that this can not hold over $\mathbb{Q}$. But I am searching for an easier way to show this which uses less calculation. I tried this: $X^4-4X^2-1=X^4-4X^2+4-5=(X^2-2)^2-5=(X^2-2-\sqrt{5})(X^2-2+\sqrt{5})$ Which is obviously not in $\mathbb{Q}[X]$ anymore.
But would this calculation be enough to show, that $X^4-4X^2-1$ is irreducible.
How do I know, that this is the only possible way to factor it? Thanks in advance.","['irreducible-polynomials', 'abstract-algebra', 'polynomials', 'field-theory']"
2446725,Integral Representation of the Dottie Number,"I noticed that a lot of commonly-used mathematical constants that can't be expressed in closed-form can be expressed by integrals, such as
$$\pi=\int_{-\infty}^\infty \frac{dx}{x^2+1}$$
and
$$\frac{1}{1+\Omega}=\int_{-\infty}^\infty \frac{dx}{(e^x-x)^2+\pi^2}$$
I was wondering if anyone knows how to express the Dottie Number $\omega$, or the unique solution to the equation
$$\cos(\omega)=\omega$$
using an integral. In general, what are some strategies for expressing constants as integrals? I'm also struggling to express the reciprocal fibonacci constant as an integral (but don't tell me how to do that one).","['fixed-points', 'definite-integrals', 'constants', 'trigonometry']"
2446729,Prove: (arithmetic mean $=$ geometric mean) $\Rightarrow$ all variables are equal for $n>2$,"Given: $\{x_1,x_2,\ldots,x_n\}\subset \Bbb R^+$ and 
  $$\text{(AM)}\ \ \ \frac{x_1+x_2+\ldots+x_n}{n}=\sqrt[n]{x_1 x_2 \ldots x_n}\ \ \  \text{(GM)}$$ Prove: $x_1=x_2=\ldots=x_n$ Background: I am a 9th grader with some experience in math contests. I always see this result but was wondering on how to prove it using simple arguments in the general $n>2$. I know how to prove the converse... it's straightforward. My attempt (for $n=2$): It is given that: $$\frac{x_1+x_2}{2}=\sqrt[2]{x_1 x_2}$$ Squaring both terms and rearranging leads to: $$x_1^2+x_2^2+2x_1x_2=4x_1x_2 \ \ \Rightarrow\ \ x_1^2+x_2^2-2x_1x_2=0 \ \ \Rightarrow\ \ (x_1-x_2)^2=0$$ This last result is true only if: $x_1=x_2$, completing the proof. Question: How to prove when $n>2$ ? (9th grader understandable arguments please)","['algebra-precalculus', 'inequality']"
2446757,is the sup of functions measurable function?,"Good day, remembering the definition: The function $f(x)$ defined on the set $E$ is said to be measurable if 
the bounded set $E$ is measurable and if the set $E\cap \left \{ x:f(x)> a \right \}$ is measurable for all $a$. Prove that the least upper bound of a finite or denumerable set of measurable functions is a 
measurable function. Can I use this result? If $f(x)$ is a measurable function defined on the set $E$, then the sets $E\cap \left \{ x:f(x) \geq a \right \}$, $E\cap \left \{ x:f(x)= a \right \}$, $E\cap \left \{ x:f(x) \leq a \right \}$ are measurables for all $a$.","['real-analysis', 'lebesgue-measure', 'supremum-and-infimum', 'measure-theory', 'analysis']"
2446785,"What does the notation $1_{[0,\infty)}(x)$ mean?","I came across this problem with the Rayleigh distribution where this notation was used: $f(x|\theta) = \displaystyle\frac{x}{\theta^2}\exp(-\displaystyle\frac{x^2}{2\theta^2})1_{[0,\infty)}(x)$ What does the notation $1_{[0,\infty)}(x)$ mean?","['statistics', 'probability', 'notation']"
2446811,On the existence of limits of multivariable rational functions,"Standard limit-related counterexamples in multivariable calculus include limits like $$\lim_{(x,y) \to (0,0)} \frac{2xy}{x^2 + y^2}$$ which tends to $0$ if the origin is approached along $x=0$ or $y=0$ , but approaches $1$ if the origin is approached along the line $x=y$ . This implies that the limit does not exist. Indeed, there's rational functions for which the limit exists (and is the same) along all lines containing $(x_0, y_0)$ , and yet the limit still fails to exist. For example, if we consider $$\lim_{(x,y) \to (0,0)} \frac{2xy^2}{x^2 + y^4}$$ the limit is $0$ along lines of the form $y=\alpha x$ but $1$ along the curve $y^2 = x$ . I was wondering if we could have a more general counterexample of this sort. Suppose $g(x,y)$ and $f(x,y)$ are two-variable polynomials defined on an open subset of $\mathbb{R}^2$ containing the origin such that $\lim_{(x,y) \to (0,0)} f(x,y) = \lim_{(x,y) \to (0,0)} g(x,y) = 0$ . In addition, suppose the rational function $$\frac{f(x,y)}{g(x,y)}$$ tends to some limit $L$ when $(0,0)$ is approached along curves of the form $y=\alpha x^{\beta}$ where $\alpha \in \mathbb{R}$ and $\beta>0$ (the limit $L$ is independent of the curve). Does it follow that $$\lim_{(x,y) \to (0,0)} \frac{f(x,y)}{g(x,y)} = L?$$","['multivariable-calculus', 'limits']"
2446824,"Is $\pi_1^{et}(\mathrm{Spec}\, k) \simeq \mathrm{Gal}(k^{sep}/k)$? (confusion about profinite completions)","The question is in the title, namely: Suppose that $k$ is a field and $k^{sep}$ its absolute algebraic separable closure. Denote $\bar s :\mathrm{Spec}\, k^{sep} \rightarrow \mathrm{Spec}\, k$ the corresponding geometric point. Is $\pi_1^{et}(\mathrm{Spec}\, k, \bar s ) \simeq \mathrm{Gal}(k^{sep}/k)$ (as topological groups)? This seems really as something that should hold, since this is a motivating example of Ã©tale fundamental groups. Let me describe where is my problem. At the moment, I hold the following conflicting believes: $\pi_1^{et}(\mathrm{Spec}\, k, \bar s) \simeq \mathrm{Gal}(k^{sep}/k)$, as stated. $\pi_1^{et}(\mathrm{Spec}\, k, \bar s)$ is given as the group of automorphisms of the fibre functor $F_{\bar s}: \mathsf{FEt}_{\mathrm{Spec}\, k} \rightarrow \mathsf{Sets}, X \mapsto X_{\bar s}=X \times_k\mathrm{Spec}\,k^{sep}.$ Moreover (more importantly), $(\mathsf{FEt}_{\mathrm{Spec}\, k}, F_{\bar s})$ is a Galois category, e.g. as in Definition 52.3.6 on Stacksproject. There is an equivalence of Galois categories $(\mathsf{FEt}_{\mathrm{Spec}\, k}, F_{\bar s})$ and $(G\mathsf{-sets}, U)$, where $G=Aut(F_{\bar s}),$ $G\mathsf{-sets}$ denotes the cat. of all finite $G$-sets with continuous $G$-action and $U:G\mathsf{-sets}\rightarrow \mathsf{Sets}$ is the forgetful functor (cf. e.g. Proposition 52.3.10 on Stacksproject). In particular, $Aut(F_{\bar s})=Aut(U)$ as topological groups. Given a topological group $G$ and $U: G\mathsf{-sets}  \rightarrow \mathsf{Sets}$ the forgetful functor, $Aut(U) \simeq \widehat G$, the profinite completion of $G$, as in Lemma 52.3.3 on Stacksproject. The group $\mathrm{Gal}(k^{sep}/k)$ is not necessarily its own profinite completion, because there are in general subgroups of finite index that are not open. I believe this is shown e.g. in Milne's field theory notes (chapter 7, Proposition 7.26) in the case $k=\mathbb{Q}$. It seems to me that using 2.-4., one obtains that 
$$\pi_1^{et}(\mathrm{Spec}\, k, \bar s ) \simeq \widehat{\mathrm{Gal}(k^{sep}/k)},$$
which by 5. is in general not isomorphic to $\mathrm{Gal}(k^{sep}/k).$ That is in conflict with 1. So more specifically: Which one of the above statements is wrong? If neither one is, why is the conclusion wrong? Thanks in advance for any help.","['fundamental-groups', 'etale-cohomology', 'algebraic-number-theory', 'algebraic-geometry']"
2446826,Finding presentation of group of order 39,"I am trying to find all groups of order $39.$ So far, I have shown that only two such groups exist ($\mathbb{Z}_{39}$ and one nonabelian group). My question is: how can I find a presentation for the nonabelian group? I know that it contains elements of order $3$ and $13$, so I need two generators. But I also need to find some relation that exists between the two generators. Is there any systematic way to go about doing this?","['finite-groups', 'abstract-algebra', 'group-theory', 'group-presentation']"
2446854,Question on foiling with vectors?,"Show that
$$\frac1{f}\sum_{i=1}^n(\mathbf{x}_i-\bar{\mathbf{x}})(\mathbf{x}_i-\bar{\mathbf{x}})'=\frac1{f}\sum_{i=1}^n(\mathbf{x}_i\mathbf{x}_i'-n\bar{\mathbf{x}}\bar {\mathbf{x}}').$$ I need this to understand an example in my textbook on Hotelling's $T^2$ but I can't figure out how they get this result. I imagine it's quite trivial but I can't seem to figure it out.. Edit, my textbook is using this result to simplify computation. Otherwise you need to sum a lot of vectors :/","['statistics', 'linear-algebra']"
2446861,How do you know if a line is straight?,"How do you know a line is straight? How can you check in a practical way if something is straight - without assuming that you have a ruler?
How do you detect that something is not straight? If you fold a piece of paper the crease will be straight â€” the edges of the paper neednâ€™t even be straight. This utilizes mirror symmetry to produce the straight line. Carpenters also use symmetry to determine straightness â€” they put two
boards face to face, plane the edges until they look straight, and then turn one board over so the planed edges are touching.They then hold the boards up to the light. If light passes between the boards the edges are not straight. Are there other ways to determine if a line is straight?","['geometric-construction', 'geometry']"
2446875,Generating function for the sequence,"$$
2, 2\sqrt 2, \sqrt 2 ( \sqrt 2 -1 ); \frac 1 3 \sqrt 2( \sqrt 2 - 1 )(
\sqrt 2 - 2), \frac 1 {3*4} \sqrt 2( \sqrt 2 - 1)(\sqrt 2 - 2)(\sqrt 2 - 3),...
$$
We can derive summation:
$$
\sum_{i=0}^{\infty}x^i \frac 2 {i!} \prod_{j=0}^i (\sqrt 2 - j)
$$
$e^x$ expansion is pretty close but I am stuck beyond this.","['generating-functions', 'combinatorics', 'sequences-and-series', 'discrete-mathematics']"
2446913,Find domain of the quotient of two square root functions,"Question :
Given
$$f(x)=\sqrt{36-x^2} \\
g(x)=\sqrt{x+1}$$
then find
$$\left(\frac fg\right)(x) = \sqrt{\frac{36-x^2}{x+1}}$$
and find its domain. My Solution :
The domain comes from
$$x+1\ne0$$
and (intersection)
$$\frac{36-x^2}{x+1}\ge0.$$
The first part implies that
$x\ne-1$. But
$$\frac{36-x^2}{x+1} \ge 0$$
when $x$ is in $(-\infty,-6] \cup (-1,6].$ So my final answer is $(-\infty,-6] \cup (-1,6]$. WebAssign's Answer : $(-1,6]$.","['algebra-precalculus', 'radicals', 'fractions', 'functions']"
2446916,Trace of the Hessian is the Laplacian(divergence of a gradient field) in Riemannian geometry,"Here are two equivalent definitions of Hessian. The trace of a (0,2)-tensor $h$ can be defined in coordinates by $$\text{tr}_g(h)=\sum_{i,j}g^{ij}h_{ij},$$
where $g^{ij}$ is the component of the inverse matrix $(g_{ij}).$ We know that in calculus, the trace of Hessian of a function $u$ is clearly the Laplacian $\Delta u$(In Riemannian geometry, it is defined to be the divergence of a gradient field). But I don't know how to prove this for general Riemannian manifolds(coordinate free or not).","['riemannian-geometry', 'differential-geometry']"
2446951,Modern book on differential geometry?,"I found this thread What is a covector and what is it used for? , in which the top answer states ""Many of us got very confused with the notions of tensors in differential geometry not because of its algebraic structure or definition, but because of confusing old notation"". I am currently working through Barret Oniell: Elementary Differential Geometry 2nd Edition and going through all of the problems, it feels rather like fumbling in a dark room for a light switch (at the end of chapter 4). I find myself having to review all sorts of different material using different notations and try to piece everything together in a sensible way on my own. I also have purchased Wolfgang Kuhnel's book on the matter, but before I spend another few months headed down that road, I think it best to ask this advice... What is a thorough, articulate and reliable (i.e. not riddled with mistakes) book on the subject matter suitable for self study that uses modern (by which I understand to be less confusing) notation? Preferably it would be available for purchase in an electronic format if possible.","['reference-request', 'book-recommendation', 'differential-geometry']"
2447013,Julia Sets of $z^k$.,"I'm trying to figure out a way to show that the Julia sets of $z^k$ with $k\geq 2$ are the unit circle.  I had a question posted before, but I wanted to add more details and how I'm thinking about it differently. Intuitively, I get why it must be the unit circle based on the discussion below.  Let $R(z)=z^k$.  Then $R^n(z)=z^{k^n}$.  As $n \to \infty$ when $|z|>1$ we have that $R^n(z) \to \infty$.    However, if $|z|<1$, we have that $R^n(z)\to 0$ as $n \to \infty$.  So the place I have to consider are the points $|z|=1$.  In my mind, it's clear that any open set contain a point on the unit circle will contain points that will both go to $0$ or $\infty$. Theorem:  Let $F$ be any family of maps, each mapping $(X,d)$ into $(X_1,d_1)$.  Then there is a maximal open subset of $X$ on which $F$ is equicontinuous.  In particular, if $f$ maps a metric space $(X,d)$ into itself, then there is a maximal open subset of $X$ on which the family of iterates $\{f^n\}$ is equicontinuous. I'm not sure if this is the correct way of applying the above theorem, but $R^n(z)$ maps points outside of the unit circle to points still outside the unit circle and similarly to those within the unit circle.  But I'm still not sure how to make the connection to the points on the unit circle.","['complex-analysis', 'complex-dynamics']"
2447020,Diffusion/Heat equation with spatially variable source,"Many resources including but not limited to 1 , 2 , 3 , 4 , 5 , 6 , 7 ** discuss various forms of diffusion and heat equations under different conditions. However, the following specific formulation with a spatially variable source and inhomogeneous flux BCs was not studied in them: $$\frac{\partial c}{\partial t}=\frac{\partial}{\partial x}J=\frac{\partial}{\partial x}(k(\frac{\partial c}{\partial x} +S)) \quad \text{or} \quad c_t=k c_{xx}+k S_x$$
$$J(-L/2,t)=J_{-} \\
J(+L/2,t)=J_{+} \\
c(x,0)=c_0$$ where $-L/2\leq x \leq L/2$ and $S(x)$ is spatially variable. I'm looking for a nice closed form or an (infinite series-based) analytic expression -- if possible. I have done some work by using the technique of Laplace transformations but could not get it done fully. Any help on the rest of my work is highly appreciated. Here is my attempt: Transform inhomogeneous BCs to homogeneous BCs Introducing $u$ and $v$ such that $c = u + v$ and $u$ satisfies the non-homogeneous BCs, yields: \begin{align*}
x = -L/2: & \quad u_x = (J_-/k) - S_- \\
x = +L/2: & \quad u_x = (J_+/k) - S_+
\end{align*} where the subscripts for $J$ and $S$ indicate evaluation at the corresponding endpoint. An easy function $u$ is $u(x) = A x^2 + B x$, where $A=\frac{(J_+-J_-)-(S_+-S_-) k}{2kL}$ and $B=\frac{(J_++J_-)-(S_++S_-) k}{2k}$. Now, the problem for $v$ is homogeneous and given by ($-L/2 < x < L/2$): $$ v_t = kv_{xx} + Q(x) $$
$$v_x(-L/2,t) = v_x(+L/2,t) = 0 \\ v(x,0) = c_0 - u(x)$$ where the source term is $Q(x) = k (u_x + S)_x$ which is also known. Thanks to superposition, the problem has now homogeneous BCs but contains a nonzero, in general, source term. I found the solution for the problem with $Q = 0$ and $0<x<L$ ( rather that $-L/2<x<L/2$) which is as follows (I verified it with 5 ): $$v=2\sum_{n=1}^{n=\infty}e^{-k\alpha_n^2t}\frac{\beta_n \cos(\alpha_n x)}{\alpha_n^2L/2}\int_{0}^{L}f(x)[\beta_n \cos(\alpha_n x)]dx+\frac{1}{L}\int_{0}^{L}f(x)dx$$ where $\beta_n=\alpha_n \cos(\alpha_n L/2)$ and $\alpha_n=\frac{(2n+1)\pi}{L}$. Also $f(x)=c_0-u(x)$. Extending the solution to where there is $Q(x)$ I was not able to convert the intervl from $0<x<L$ to $-L/2<x<L/2$ properly and expand the obtained solution to the original problem with a spatially variable source (i.e. $Q(x)$). A sanity check is also greatly appreciate as there might be some errors in my work. ** Essentially the question asked in 7 is even a more general form of the current question. While I learned a lot from the discussion done in 7 , the questions remained unanswered (in a complete way). The main and intersting complication in 7 was the varying diffusion coefficient rather than what is focused in current question. Special thanks to dmoreno for providing fruitful discussions.","['taylor-expansion', 'laplace-transform', 'partial-differential-equations', 'heat-equation', 'ordinary-differential-equations']"
2447054,How to derive a generating function when given a sequence,"I am asked to derive a generating function for the sequence $2,2\sqrt{2}, \sqrt{2}(\sqrt{2} - 1), \frac13\sqrt{2}(\sqrt{2}-1)(\sqrt{2}-2), \frac{1}{(3)(4)}\sqrt{2}(\sqrt{2}-1)(\sqrt{2}-2)(\sqrt{2}-3), \frac{1}{(3)(4)(5)}\sqrt{2}(\sqrt{2}-1)(\sqrt{2}-2)(\sqrt{2}-3)(\sqrt{2}-4),... $ I have no idea how to approach this problem. Usually when I'm asked to derive a generating function for a sequence I start with a familiar generating function and sequence such as $\frac{1}{1-x} $ and then manipulate it till it matches the given sequence. For this sequence however, I'm only recognizing the pattern of $\sqrt{2}! $  and not sure where to continue from there. Any help with the problem or a better strategy for deriving generating functions is appreciated.","['generating-functions', 'discrete-mathematics']"
2447062,Show tensor $g_{ij}A^iB^j $ is invariant under coordinate change,"The components of a $(0,2)$ tensor is $(g_{ij})$ and the components of a $(1,0)$ tensor is $A^i,B^j$ . How can I show that the quantity (using Einstein summation convention) $$g_{ij}A^iB^j $$ is invariant? 
So I want to show that the value does not change when coordinate systems are changed. One hint that the textbook gives me is to use the Kronecker delta, so I know that is: $$\sum_{i=1}^n \frac{\partial\bar{x}^i}{\partial x^j}\frac{\partial x^k}{\partial\bar{x}^i} = \delta_{j}^k$$","['tensors', 'index-notation', 'differential-geometry']"
2447101,Curve with constant torsion and curvature is a circular helix.,"I am trying to find a proof for the 9th question of section 2.4, from the book Elementary Differential Geometry by Barrett O'Neill.
I want to show that a curve $\alpha$ with curvature $\kappa$ and torsion $\tau$ both constant is a circular helix. My thoughts: I know $\alpha$ must be a cylindrical helix since $\tau/\kappa$ is a constant. Remains to show that it is circular. I'm not sure how to do this. I found this question here : Is the helix the unique path with constant curvature and constant torsion? where the answer gives a hint to prove Nâ€²â€²(s)=âˆ’(Îº2+Ï„2)N(s). I can do this, but where does it head me toward? I cannot see where this will lead me. Random thought: It occurs to me that if I can project the curve $\alpha$ on the xz plane, it must be a circle. But I don't know how I would go about showing this. Any help is appreciated. Thank you for your time.","['curves', 'frenet-frame', 'differential-geometry']"
2447155,Show $\nabla x^TAx = (A + A^T)x$ using property of $\nabla$,"This question is similar to How to take the gradient of the quadratic form? But I do not like the answer to that question. The reason is because the answerer is mixing $\nabla$ with $\dfrac{\partial}{\partial x}$. What I have learned is that $\nabla f$ is a column vector, it is the gradient of $f$, and$\dfrac{\partial}{\partial x} f$ is the Jacobian of $f$, which evaluates to a row vector when $f$ is a scalar. Why is it even appropriate to mix these notations...? ... In any case, is there a straight forward way of using properties of $\nabla$ to show $$\nabla x^TAx = (A + A^T)x, A \in \mathbb{R}^{n \times n}, x \in \mathbb{R}^n$$ I like the approach used in the linked question. Let $y(x) = Ax$, then $$\nabla x^TAx = \nabla x^Ty(x)$$ Is there a way to use a chain rule for $\nabla$ at this stage? I'm thinking of something like $$\nabla x^TAx = \nabla x^Ty(x) = y(x)^T \nabla x + x^T\nabla y(x)$$ But I have no idea if the above holds.","['derivatives', 'multivariable-calculus', 'quadratic-forms', 'linear-algebra', 'vector-analysis']"
2447237,Learning roadmap for algebraic curves,"I have recently started a Phd in the subject of algebraic curves and arithmetic geometry. In general I have a good background in algebra and analysis, but only an introductory course in algebraic geometry (varieties and schemes). I also lack a thorough knowledge of geometry, with only a course in manifolds and algebraic topology. My teacher suggested learning Riemann surfaces first, up to the Riemann-Roch theorem, and then building on that. My questions are the following: What are the relevant subjects that I must learn in my first year? (Besides Riemann surfaces, I believe function fields are related.) What are some good books for self-learning in the subject? I found Rick Miranda's book astonishing but a bit slow. Reading Fulton's section on Riemann surfaces (from the algebraic topology book), I noticed that I should read cohomology from scratch. What is a good (and fast) introduction for that? Thanks a lot!","['riemann-surfaces', 'self-learning', 'algebraic-geometry', 'reference-request', 'algebraic-curves']"
2447262,"In a circle, parallel chords of length $2$, $3$, and $4$","I was helping my comrade answering some questions taken from review classes when I stumbled upon this question. It looks like this: In a circle, parallel chords of length $2$, $3$, and $4$ determine central angles of $A$, $B$, and $A+B$ radians, respectively, where 
  $A+B < \pi$. Express the $\cos A$ into a fraction in lowest term and find the sum of the numerator and denominator of the fraction. My work The problem sounds difficult for us, so we came here to seek help. How do you answer the above problem?",['trigonometry']
2447325,Confusing result about stability of a limit cycle,"I want to understand a confusing result about this ODE system from Arnold's book on dynamical systems. $$\dot{r}=[r^2-1][2 r \cos \phi - 1]$$ 
$$\dot{\phi}=1$$ The limit cycle is given for $r=1$ and $\phi = t$. My question : The limit cycle seems to be asymptotically stable (if I
  didn't do any mistakes; see 1. Determining stability by Floquet analysis ) but the phase portrait seems to suggest, that
  there are trajectories that start close to the limit cycle but drift
  away from it (see: 2. Understanding stability in the phase portrait ). I would interpret the phase portrait of the original system as evidence that
  the limit cycle is not stable because there are trajectories that start close to it but then drift away on the $x$-axis $r=1$. I would be glad if someone could help
  me in resolving this confusion. 1. Determining stability by Floquet analysis One way of dealing with the stability of this limit cycle is by first rewriting the ODE such that the origin is the trivial solution to the ODE. In order to do this use the following substitution $r = 1 + x_1$ and $\phi = t + x_2$. The system then can be written as 
$$\dot{x}_1=[x_1^2+2x_1]\left[2(x_1+1)\cos(t+x_2)-1 \right]$$ $$\dot{x}_2=0.$$ It is obvious that $x_1=0$ and $x_2=0$ is now the trivial solution, which corresponds to the limit cycle in the original equation. Now we can linearize the system at the origin to obtain: $$\Delta \dot{x}_1=-2\Delta x_1 +4\Delta x_1\cos(t) $$
$$\Delta \dot{x}_2=0.$$ Note, that the system in question is a linear time-variant system but has periodic coefficients with period $T = 2\pi$. Such systems can be investigated using Floquet theory . One will have to simulate the system for two pairs of initial conditions $x_{1,1}(0)=1\, \wedge \,x_{2,1}(0)=0$ and $x_{1,2}(0)=0 \,\wedge \, x_{2,2}(0)=1$ form $t=0$ to $t=2\pi$. One will obtain the states $x_{1,1}(2\pi),x_{2,1}(2\pi),x_{1,2}(2\pi),x_{2,2}(2\pi)$ which can be put together into the so called  monodromy matrix $$C=\begin{bmatrix} x_{1,1}(2\pi) & x_{1,2}(2\pi)\\ x_{2,1}(2\pi) & x_{2,2}(2\pi) \end{bmatrix}.$$ This can be as previously told by numerical integration or analytically like in this case. Note that the linearized equation is a decoupled first order linear equation. The general solution is given by $$\Delta x_1(t) = c_1\exp(4\sin(t)-2t)$$
$$\Delta x_2(t) = c_2.$$ Using the initial conditions and setting $t=2\pi$ we obtain: $$C = \begin{bmatrix}\exp(-4\pi) & 0 \\ 0 &1 \end{bmatrix}$$
The eigenvalues of this matrix, which can also be complex, are called Floquet multipliers $\lambda_i$. The eigenvalues are given by the entry on the diagonal, as we have an upper triangular matrix. The first eigenvalue is $\lambda_1= \exp(-4\pi)<1$ and the second one is given as $\lambda_2=1$. It can be shown that linearization of a limit cycle will always lead to one Floquet multiplier $\lambda = 1$, which can be excluded from the analysis. This eigenvalue corresponds to a disturbance along the limit cycle. If the remaining Floquet multipliers fulfill the following inequality $|\lambda_i| < 1$, then the limit cycle is asymptotically stable. If there is at least one remaining Floquet multiplier with $|\lambda_i|>1$ then the limit cycle is unstable. If there exist at least one remaining Floquet multipliers for which $|\lambda_i|=1$ but the absolute value of all other Floquet multipliers is smaller or equal to $1$ then this method is indecisive. As we can see that the only remaining eigenvalue is $0<\lambda_1=\exp(-4\pi)<1$, we can conclude that the limit cycle is asymptotically stable . 2. Understanding stability in the phase portrait In order to get a better picture of the limit cycle, I plotted some trajectories of the ODE system. Which you see in the following figure ($x$-axis: $r$ and $y$-axis: $\phi$).","['stability-in-odes', 'ordinary-differential-equations', 'dynamical-systems', 'stability-theory']"
2447342,"$\gcd(p_{n-1}, \ n^5 - n^3 + n^2 - n + 1) = 1$ where $p_n = n$th prime.","How can I prove in general that, for all $n\geq 2$: $$
\gcd(p_{n-1}, \ n^5 - n^3 + n^2 - n + 1) = 1
$$ Seems to always be true: from sympy import *
from sympy.ntheory.generate import prime


def f(n):
    return n**5 - n**3 + n**2 - n +  1

for n in range(3, 100000000):
    p = prime(n-1)
    d = gcd(f(n), p)
    if d != 1:
        print (n) Assume true. $$
f(X) = X^5 - X^3 + X^2 - X + 1
$$ is irreducible and modulo each prime, i.e. $f(n+1) \neq 0 \pmod {p_n}$ so that $\prod_{j=2}^n\overline{f(j+1)} \in $ the units of $\Bbb{Z}/2 \times \Bbb{Z}/3 \times \Bbb{Z}/5 \times \dots $ So far it seems like the polynomials $g(X) = f(X \pm 1)$ are such that $g(n) \neq 0 \pmod {p_n}$","['polynomials', 'gcd-and-lcm', 'number-theory', 'prime-numbers', 'elementary-number-theory']"
2447358,How can the set of all graphs be the same size as its power set?,"Supose a set $G$ containing all graphs, either finite or infinite. If I take a set $S\in P(G)$ and draw all the graphs in $S$ on a paper I can always just combine them and create one posibly disconnected graph which is an element of $G$. So the combination of some graphs is itself a graph, meaning that $G=P(G)$. How can this be posible or where is the error?","['graph-theory', 'elementary-set-theory']"
2447377,Probability Density Function Interpretation,"I am BEGINNING to study Statistics and Probability and am trying to understand what a probability density function is/is used for. My current interpretation is : The name function indicates to me something that provides an output dependent on the input I give it. Taking for example the PDF for the standard normal distribution (shown below); $$
p(x) = \mathcal{N}(x;0,1) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2}
$$ In my mind the above equation describes the probability/likelihood that a continuous random variable $x$ takes on a value in it's sample space (i.e. set of all possible values). So lets say this PDF (normal distribution) describes the time taken for men to run a marathon (real average is about 4 hours).
If plotting this PDF the $y$-axis would contain non-negligible values for corresponding marathon times from around 2 hours (on the extreme left) to 6 hours (on the extreme right) with the average/mean centered at 4 hours. If I programmed the PDF equation (above) into computer and then ran a script that requested a input $x$; I could provide any real valued input in the domain from $-\infty$ to $+\infty$ and the output of the PDF equation would give me the probability that a man would finish the race in that time? Why is this useful; If i'm standing at the start line before the race begins and a competitor walks over to me and bets me $20 that he can finish the race in exactly 3 hours, if I know nothing else about him, his training regime etc... I can quickly take out my phone, run the script and enter the value 3 hours and the output can be interpreted as the probability the man will finish the race in exactly 3 hours? If I fancy the odds I might decide it is a good idea to accept his bet. Questions related to my current understanding are as follows : (1) Is the the above interpretation correct whole/partially? (1.1) If partially then where exactly am I getting my wires crossed? (2) Bonus Question : How would you link an understanding of standard deviation and/or variance into this example?","['statistics', 'probability', 'normal-distribution']"
2447425,When does the Picard iteration give a power series?,"I been trying to figure out when or if it is possible to see that the Picard i.e  iteration $x_{k+1}=x_{0}+\int f(t,x_{k}(t))dt$ leads to a power series expansion of the solution $x$. In simple and concrete cases I can see it. But it would be nice to be able to think about this iteration as a general way of obtaning a power series solution theoretically.",['ordinary-differential-equations']
2447434,Card guessing game,"There is a pile of $52$ cards with $13$ cards in each suit (diamonds, clubs, hearts, spades). The cards are turned over one at a time. At any time, the player must try to guess its suit before it is revealed. If the player guesses the suit that has the most cards and if there is more than one suit with the most cards, he guesses one of these, show that he will make at least thirteen correct guesses. Attempt: At first, the probability for each suit is $\frac{1}{4}$. If the first card is, say, a diamond then, for the second card, the probability of diamonds, clubs, hearts, spades are $\frac{12}{51}, \frac{13}{51}, \frac{13}{51}, \frac{13}{51}$. So the player should guess the suit that has most cards, but I don't know how to show that he will make at least thirteen correct guesses.","['combinatorics', 'card-games']"
2447451,"How to prove continuity of a concave, non-decreasing $f : [0, 1] \to [0, 1]$.","Let $f : [0, 1] \to [0, 1]$ be non-decreasing, $f(0) = 0$ and $f(1) = 1$. In a paper which I have read, concavity for this $f$ is defined as follows: $f$ is called concave, if for each $q \in (0,1]$, there are reals $a_q, b_q$ and a line $l_q(x) = a_q x + b_q$ such that $l_q(q) = f(q)$ and $l_q(p) \ge f(p)$ for all $p \in (0, 1]$. Such an $f$ is called convex, if $-f$ is concave. Now there are made three statements, and I do not quite see how to prove them with the given definition. Let $f : [0, 1] \to [0, 1]$ be non-decreasing. If $f$ is concave, then $f$ is continuous on $(0, 1]$ and a jump of f can only occur at $0$. If $f$ is convex, then $f$ is continuous on $[0, 1)$ and a jump of $f$ can only occur at $1$. If $f$ is concave or convex and does not have a jump, then $f$ is absolutely continuous. I have managed to prove in (1) that $f$ is right-continuous, but I still need to prove the left-continuity and struggle with that.
Does (2) follow directly from statement (1) as $-f$ is concave?
About (3), I could already prove for the case that $f$ is concave, $f$ is absolutely continuous on $(0, 1]$ but I do not know how to show that this is the case for the entire interval $[0, 1]$. I suppose that in the scenario that $f$ is convex one uses the statement for $-f$. Any help is appreciated. Thanks!","['continuity', 'real-analysis', 'convex-analysis', 'analysis']"
2447464,"If X is a random variable with a Poisson distribution, rate parameter $\lambda$ show that...","If X is a random variable with a Poisson distribution, rate parameter
  $\lambda$ show that $$E(X(X-1)(X-2)...(X-k)) = \lambda^{k+1}$$ I know that for the probability generating function $G(N)$ of a Poisson random variable, $$G''(1)=E(X(X-1))=\lambda^2$$ and I'm guessing that with each proceeding derivative we add $(X-2), (X-3)$, etc inside the expectation, eg: $G'''(1)=E(X(X-1)(X-2))=\lambda^3$. But I don't really know how to show it.","['stochastic-processes', 'statistics', 'generating-functions']"
2447501,Generalization of Markov's Inequality to Vector-valued Random Variables,"Suppose we have some sample space $\Omega$ and a random variable (rv) $X:\Omega\to\mathbb{R}$. Then it is well known that for $a>0$
$$
P(|X-E[X]|\geq a)\leq\frac{\text{Var}(X)}{a^2}.
$$
I was wondering whether there is generalization of this result to a rv $Y:\Omega\to V$ for some arbitrary vector space $V$. In particular I am interested in an upper bound on 
$$
P(\|Y-E[Y]\|\geq a)
$$
for some norm $\|\cdot\|$. We may assume $V$ finite-dimensional if necessary. Thank for your help.","['probability-theory', 'probability']"
2447568,String of letters and ways to have at least one vowel,"We would like to construct $3$ letter strings from the english alphabet ($26$ letters: $21$ consonants and $5$ vowels). a. How many ways can you construct strings with no vowel? b. How many ways can you construct strings with at least one vowel? This is what I did for both of them... however I think at least one of them is incorrect. a. Ways with no vowel = $21^3$ since for each letter, we have $21$ options. b. Ways with at least one vowel = total ways with no restrictions - ways with no vowel = $26^3 - 21^3$. However, manually computing it: Ways with at least one vowel = ways with one vowel + ways with two vowels + ways with three vowels 
= $\binom{5}{1} \times \binom{21}{2} \times 3! + \binom{5}{2} \times \binom{21}{1} \times 3! + \binom{5}{3} \times \binom{21}{0} \times 3!$ which doesn't equal to the other way.","['combinatorics', 'proof-verification']"
2447569,Can $A\cap B$ be represented in terms of the symmetric difference?,"Suppose we have a collection of subsets $\mathfrak C$ of $M$ such that $M \in \mathfrak C$ $A,B\in \mathfrak C \implies A \Delta B \in \mathfrak C$ I was wondering how this kind of collection of sets is related to an algebra of sets. My hunch is that the two concepts might be the same. Clearly, an algebra of sets satisfies the above two properties. For the reverse direction note that for any $A$ and $B$ in $\mathfrak C,$ 
$$
A^C = M \Delta A,
$$ 
and
$$
A\cup B = (A\Delta B) \Delta (A\cap B).
$$
So the reverse direction is true if and only if $A\cap B$ can be represented in terms of the symmetric difference. Therefore my question: Can $A\cap B$ be represented in terms of the symmetric difference? If not, is there a name for a set that is closed under symmetric differences? Definitions: The symmetric difference of two sets $A$ and $B$ is
$$
A\Delta B = A\cup B - (A\cap B).
$$ An algebra of sets on a set $M$ is a collection $\mathfrak A$ of subsets of $M$ such that $M \in \mathfrak A$ $A \in \mathfrak A \implies A^C \in \mathfrak A$ $A, B \in \mathfrak A \implies A\cup B \in \mathfrak A$","['logic', 'elementary-set-theory']"
2447570,It is possible to write open subsets in the form $\Omega=\{x\in \mathbb{R}^N:g(x)>0 \}$,"Let $\Omega$ be an open subset of $\mathbb{R}^N$. Do we have in general the existence of a continuous function $g:\mathbb{R}^N\to\mathbb{R}$ such that
  $$\Omega=\{x\in \mathbb{R}^N:g(x)>0 \}$$","['continuity', 'general-topology', 'metric-spaces', 'vector-spaces']"
2447605,Eigenvalues of $AB$ and $BA$ where $A$ and $B$ are arbitrary matrices,"This question is a generalisation of Eigenvalues of $AB$ and $BA$ where $A$ and $B$ are rectangular matrices which itself is a generalisation of Eigenvalues of $AB$ and $BA$ where $A$ and $B$ are square matrices . Let $A$ be an $m \times n$ matrix and B and $n \times k$ matrix. Obviously, the matrix product $AB$ is possible, whereas the product $BA$ is not. Assume $n<k<m$, such that $AB$ is a large matrix. Is there anything we can do to either matrix $A$ or $B$, such that the product $BA$ becomes possible and such that the eigenvalues of $BA$ say something about the eigenvalues of the original $AB$? I am thinking of procedures such as: Truncating $A$ (making it $k \times n$) Appending some values to $B$ (making it $n \times m$) Interpolating values in $B$ Taking random samples etc. Motivation 1 (theoretical): The matrix $AB$ is large and clearly degenerate. Therefore, there must be a smaller matrix which captures the same information as $AB$ (i.e. has the same eigenvalues). If $k=m$, then $BA$ would be such a smaller matrix, as discussed in Eigenvalues of $AB$ and $BA$ where $A$ and $B$ are rectangular matrices . Motivation 2 (practical): The eigendecomposition of a very large matrix is computationally expensive and may require special hardware. If the problem can be simplified, e.g. by decomposing the smaller $BA$, then the analysis can be performed more efficiently. Alternatively, is there anything we can say about the eigenvalues of $AB$ without performing the product, i.e. based on analyses of $A$ and $B$ separately.","['matrices', 'matrix-rank', 'matrix-decomposition']"
2447627,Guess explicit formula for sequence and then prove it is correct,"just trying to work through the following problem but have come to point where I don't know what to do. Info: Let $a_0, a_1, a_2, ...$ be the sequence defined recursively as $a_0 = 0, a_k = k + a_{k-1}$ for each integer $k\ge 1$. Question is: Using this information write out the first 6 terms of the sequence, guess the explicit formula and then prove your guess is correct. So I've done as follows: First 6 terms: $a_0 = 0, a_1 = 1, a_2 = 3, a_3 = 6, a_4 = 10, a_5 = 15, a_6 = 21$ Explicit formula guess: $ a_n = \frac {n^2 + n}{2}$ Proof: Using the guessed explicit formula $a_n = \frac {n^2 + n}{2}$ for each integer $n \ge 0$ we see that $a_0 = \frac {0^2 + 0}{2} = 0$ so we have the correct initial condition. Let $a_0, a_1, a_2, ...$ be the sequence defined as $a_0 = 0$ and $a_k = k + a_{k-1}$ for each integer $k \ge 1$ Then, let P(n) be the predicate $a_n = \frac {n^2 + n}{2}$ for each integer $n \ge 0$ Basis step: $a_0 = 0$ from the recursive definition and $\frac {n^2 + n}{2} = 0$, so P(0) is true. Inductive Hypothesis: Suppose that P(k) is true for some integer $k \ge 0$. Then $a_{k+1} = (k + 1) + a_k$ = $(k + 1) + \frac {k^2 + k}{2}$ = $\frac{2(k + 1) + (k^2 + k)}{2}$ = $\frac{2k + 2 + k^2 + k}{2}$ = $\frac{k^2 + 3k + 2}{2}$ = $\frac{k^2 + 3k}{2} + 1$??? I'm not sure what to do after the previous step. Any help would be greatly appreciated.","['sequences-and-series', 'discrete-mathematics']"
2447722,Is this a regularity in primes?,"For any prime $p$ subtract $24$ continuously. The last value before $0$ will always be one of these $8$ primes:
$\{ 1, 5, 7, 11, 13, 17, 19, 23 \}$. Prime Distribution Across Lengths of 24 Primes in Blue. Root Prime Path in Red As can be observed above prime numbers do not deviated from the original host numbers. This suggests that primes have a geometric component underpinning their formation. Further, it should hold true that primes persist to appear in just $8$ or $24$ locations as observed above. 
Consider then: $24^2 = 576 $ $576$ is the $24$th column of the images above. Subtracting $-1, -5, -7, -11, -13, -17, -19$ or $-23$ should then result in a prime hit or miss. $-1$ is a miss $-5$ is a hit: $571$ â€¦a prime $-7$ is a hit: $569$ â€¦a prime $-11$ is a miss $-13$ is a hit: $563$ â€¦a prime $-17$ is a miss $-19$ is a hit: $557$ â€¦a prime $-23$ is a miss Now, letâ€™s do this with arbitration: Choose a large number: 
$1024169726$ The nearest prime to $1024169726$ is $1024169717$. $1024169726 â€“ 1024169717 = 9$. This would seem to violate what I have stated above. However, $1024169726$ is not divisible by $24$. $1024169726 â€“ 14 = 1024169712$. $1024169712$ is divisible by $24$. $1024169717 - 1024169712 = 5$, one of the prime conditions stated above in this sieve. Again, choosing from arbitration a number: $3248715756$.
$3248715756 + 12 = 3248715768$ which is divisible by $24$. $\dfrac{3248715768} {24} = 135363157$. $3248715768 â€“ 1, -5, -7, -11, -13, -17, -19, -23$ does not produce primes. $3248715768 â€“ 24 = 3248715744.$ $3248715744 â€“ 13 = 3248715733$ which is prime. Here we can see again that while there are not always primes within the gaps of $24$ the primes will nevertheless occur along the vector issued by adding $24$ to $\{ 1, 5, 7, 11, 13, 17, 19, 23 \}$ continuously. This hypothesis was formed by myself and another professor at Penn State by investigating the mathematics behind old astrological sites such as Knowth. Unfortunately our network of Number Theorists from this campus is very small. If anyone can confirm this is indeed a pattern in primes it would be incredibly helpful. Thank you,
Iapyx P.S. 
This website's formatting doesn't allow the original spacing in the numerical formatting. Sorry for the clutter.","['number-theory', 'prime-numbers', 'distribution-of-primes']"
2447817,"If $\cos p\alpha$ and $\cos q\alpha$ are rational with $p,q$ relatively prime, then $\cos \alpha$ is rational, or $\alpha$ is a multiple of $\pi / 6$.","Would you please help me solve Exercise 2 , which I repeat here: Suppose that $p$ and $q$ are relatively-prime positive integers.  Show that if $\cos p \alpha$ and $\cos q \alpha$ are rational, then $\cos \alpha$ is rational or $\alpha$ is a multiple of $\pi / 6$. The exercise is a supplement to An Introduction to the Theory of Numbers by Niven, Zuckerman, and Montgomery. There are two approaches to solve the problem.  The first is to assume that $\cos \alpha$ is irrational and prove that $\alpha$ must then be a multiple of $\pi / 6$.  In this case, I know from Exercise 1 that $\cos (p + q) \alpha$ is irrational, which is equivalent to the fact that $\sin p \alpha \sin q \alpha$ is irrational, deduced from my solution to Exercise 1.  I can construct examples that satisfy this approach but cannot devise a general proof. The other approach is to assume that $\alpha$ is not a multiple of $\pi / 6$ and prove that $\cos \alpha$ must then be rational.  Once again, I can construct examples but cannot figure out how to prove it in general.","['coprime', 'trigonometry', 'elementary-number-theory']"
2447846,Are the eigenvalues of Laplacian times Diagonal times Laplacian matrix non-negative?,"Consider two (not identical) symmetric Laplacian matrices $L_1$ and $L_2$ and a diagonal matrix $D > 0$. My question is if the eigenvalues of the product $A =L_1 D L_2$ have non-negative real-part. It is well known that the product of two positive semi-definite matrices have eigenvalues with non-negative real part. (see e.g. the book by Bernstein: Matrix Mathematics, Theory, Facts, and Formulas). Extensive simulations show that $A$ has indeed eigenvalues with non-negative real part and that this not true in general if $L_1$ and $L_2$ were `only' positive semi-definite matrices. However, I have been, trying similarity transformations and Sylvester's law of inertia, unable to find a proof. Of course, a counterexample would be very useful as well.","['matrices', 'spectral-graph-theory', 'linear-algebra', 'graph-laplacian']"
2447850,Prove that $\lim\limits_{n \rightarrow \infty}\frac{x^n}{n!} = 0$ [duplicate],"This question already has answers here : Prove that $\lim \limits_{n \to \infty} \frac{x^n}{n!} = 0$, $x \in \Bbb R$. (15 answers) Closed 6 years ago . So I have to prove 2 things: That $\lim\limits_{n \rightarrow \infty}\frac{x^n}{n!} = 0$ where $n \in \mathbb N$ and $x \in \mathbb R, x>0$. That $\lim\limits_{n \rightarrow \infty}\frac{x^n}{n!} = 0$ where $n \in \mathbb N$ and $x \in \mathbb R$. For #1, I know that $\frac{x^n}{n!} >0$, which means that I can find an upper bound and use squeeze theorem. For #2, I have no idea where to start.","['proof-writing', 'sequences-and-series', 'limits']"
2447941,Problem Books in Algebraic Topology/Differential Topology (with solutions),"For Differential Geometry there's this wonderful book called ""Analysis and Algebra on DIfferentiable Manifolds"" , which is a big problem book containing problems (and solutions). For a self-studying student this is particularly helpful because these sorts of books provide us with a good feedback loop. If we attempt a problem, get stuck on and can't solve it, we can always read the first few lines of a solution to see a hint on where to go next, and if we are really stuck we can check the full solution. Do such books exist for Algebraic Topology, or Differential Topology? Or is the best method to gain a similar sort of feedback loop to read the theorems and examples in a book like Hatcher or Guillemin and Pollack and attempt to prove the theorems and examples by hand?","['algebraic-topology', 'reference-request', 'differential-geometry', 'differential-topology']"
2447954,Prove the recursive formula $a(n)=a(n-1)+a(n-2)$,"A set $S$ of integers is said to be lacunar if no two consecutive integers
occur in $S$ (that is, there exists no $i\in\mathbb{Z}$ such that both $i$ and $i+1$ belong to $S$). For example, $\{1,3,6\}$ is lacunar, but $\{2,4,5\}$ is not. (The empty set and any $1$-element set are lacunar, of course.) For a positive integer $n$, let $a(n)$ denote the number of all lacunar subsets of $[n]$. Find and prove a recursive formula for $a(n)$ in terms of $a(nâˆ’1)$ and $a(nâˆ’2)$. I think I already found the recursive formula to be $a(n)=a(n-1)+a(n-2)$ but I could be wrong. Proving it is what I'm really stuck on. Thanks!","['combinatorics', 'recurrence-relations', 'discrete-mathematics']"
2447995,"Determine the number of functions that have at least one integer $x$ in $\{1,2,\ldots,n\}$ for which $f(x) = x$.","The function is $f\colon\{1,2,\ldots,n\}\to\{1,2,\ldots,n\}$. I'm assuming that since there needs to be at least one integer $x$ where $f(x) = x$ and there is $n$ integers in the function, then the integer $x$ can be a possibility of $n$ integers. So the answer would be that there are n number of functions that have at least one integer? Am I getting some where with that or is it completely wrong? Thanks for the help!","['functions', 'discrete-mathematics']"
2448074,"Probabilities : A red die, a blue die, and a yellow die (all six-sided) are rolled.","A red die, a blue die, and a yellow die (all six-sided) are rolled. We are interested in the probability that the number appearing on the blue die is less than that appearing on the yellow die which is less than that appearing on the red die $P(B < Y < R)$. I know one way to calculate this is: E = event that no two dice land on the same number: $$P(E) = \frac{6 \cdot 5 \cdot 4}{6 \cdot 6 \cdot 6} = \frac{5}{9}$$ F = event that B < Y < R and no two dice land on the same number $$P(F) = P(E) \cdot P(B < Y < R|E) = \frac{5}{9} \cdot \frac{1}{6} = \frac{5}{54}$$ Is there another way to find the number of outcomes where $B < Y < R$ using the formula $N(E)/N(S)$, where $N(S) = 6 \cdot 6 \cdot 6 = 216$?","['combinations', 'combinatorics', 'probability']"
2448104,Probability: What is the best solution for this problem about Discrete distributions?,"Here is the problem: The drainage system of a city has been designed for a rainfall intensity that will  be exceeded on an average once in 50 years.
What is the probability that the city will be flooded at most 2 out of 10 years? May you tell me what do you think about my solution? In my perspective, we can use the Binomial or the Poisson Distribution. However, I think that the precise one, is the Poisson because of this explanation of my book, the ninth edition of Probability and Statistical Inference written by Robert Hogg, Elliot Tanis and Dale Zimmerman. Please read it: In despite of that, the same book talks also about the Binomial Distribution. Please read it: Which solution would be the best solution? Thank you so much for your help!","['statistical-inference', 'probability-theory', 'probability-distributions', 'statistics', 'probability']"
2448156,Surface measure=Lebesgue measure on $\mathbb{R}^{N-1}$?,"Let $\Omega$ be an open subset of $\mathbb{R}^N$ with $C^1$ boundary $\partial\Omega$. In the Gauss-Green theorem (page 711 in Evan's PDE book):
$$\int_\Omega\frac{\partial u}{\partial x_i}dx=\int_{\partial\Omega}u\nu^i dS.$$
where $dx$ is the Lebesgue measure on $\mathbb{R}^{N}$. Does $dS$ means the Lebesgue measure on $\mathbb{R}^{N-1}$? If not where can I find a definition of this measure?","['partial-differential-equations', 'reference-request', 'greens-theorem', 'manifolds', 'differential-geometry']"
2448196,Establishing the convergence or divergence of the sequences $(x_n)$,Establish the convergence or the divergence of the sequence $$(x_n) = \frac{(-1)^n n}{n+1}$$ At the moment all I can conclude is that $$(x_n) = \frac{(-1)^n n}{n+1} < (-1)^n\left(\frac{n}{n}\right) = (-1)^n$$ So $(x_n)$ is bounded above by $1$ and below by $-1$. How can I show that $(x_n)$ is convergent or isn't convergent?,"['real-analysis', 'sequences-and-series', 'limits']"
2448214,Convergence and limit of $\left((n+3)^{1/(n+3)}-(n+4)^{1/(n+4)}\right)^{1/(n+5)}$ as $n \to \infty$?,"I was calculating in WA some values of some sequences and constructed this  sequence:
$$a_n=\left((n+3)^{1/(n+3)}-(n+4)^{1/(n+4)}\right)^{1/(n+5)}$$ It is immediate that expression in parentheses tends to $0$ since both terms tend to $1$, but the exponent also tends to $0$ so it may be that in the limit this behaves similarly to $x^x$ when $x$ tends to $0$ from the right side, but I am not sure. How to prove existence of this limit and what is its value?","['sequences-and-series', 'limits']"
2448229,Is every Hilbert space separable?,"A Hilbert space is a complete inner product space; that is any Cauchy sequence is convergent using the metric induced by the inner product. From Wikipedia: A Hilbert space is separable if and only if it has a countable orthonormal basis. What are the examples of non-separable Hilbert spaces?
From an applied point of view, are all interesting (finite or infinite) Hilbert spaces separable?","['functional-analysis', 'hilbert-spaces', 'inner-products']"
2448245,"Formulas involving the polynomials $\frac{1}{n!}x^n(a_n-b_nx)^n,$ where the coprime integers $a_n,b_n$ satisfy $H_n=\frac{a_n}{b_n}$ for $n\geq 1$","For integers $n\geq 1$ let
$$H_n=1+\frac{1}{2}+\ldots+\frac{1}{n}$$
the $nth$ harmonic number. After I've seen the form of the polynomials used by Niven in [1] I wanted to create a puzzle with a new definiton. Definition. For integers $n\geq 1$, I define the following polynomials 
  $$\operatorname{Niv}_{n}(x):=\frac{1}{n!}x^n(a_n-b_nx)^n,\tag{1}$$ where $a_n$ and $b_n$ are positive integers satisfying $\gcd(a_n,b_n)=1$ and $$H_n=\frac{a_n}{b_n}.\tag{2}$$ I would like to know if such polynomials satisfy some nice recurrence, or some nice ordinary differential equation. Since my definiton was a puzzle (I mean that there are no mathematical reason to define those as I did) isn't required that these have a special features. Question. Can you set a simple recurrence or a simple ordinary differential equation that satisfy the polynomials $\operatorname{Niv}_{n}(x)$? Only is required an aproach to set a recurrence* or a differential equation. Many thanks. Isn't required that the order of our equation to be $1$. Using the definiton one can write $$\left(a_n-b_nx\right)^n\operatorname{Niv}_{n+1}(x)=\frac{x^{n+1}}{n+1}\left(a_{n+1}-b_{n+1}x\right)^{n+1}\operatorname{Niv}_{n}(x).\tag{3}$$
But it does not explode $H_{n+1}=H_n+\frac{1}{n},$ that is $$\frac{a_{n+1}}{b_{n+1}}=\frac{a_n}{b_n}+\frac{1}{n}.\tag{4}$$ 
Thus I don't know if this recurrence, although it is simple, 
isn't the best recurrence by capturing the information of the definition. So here is a compromise on the purpose of finding a simple recurrence or well a differential equation, but interesting enough in relation to our definition. Thus you can develop your reasoning to find a simple formula, understanding this word in a flexible way. *In the case of the recurrence if you prefer it you can write an asymptotic identity (as $n\to\infty$) involving our polynomials. References: [1] I. Niven, A simple proof that $\pi$ is irrational , Bull. Amer. Math. Soc. Volume 53, Number 6 (1947).","['recurrence-relations', 'real-analysis', 'polynomials', 'harmonic-numbers', 'ordinary-differential-equations']"
2448251,Polyhedron with $\chi = -2$ with the least number of faces?,"What is the least number of faces you need on a polyhedron that has Euler-characteristic $V-E+F = \chi = -2$ (i.e. 2 holes)? So far I just found the solution of gluing two copies of the following toroidal shape together, which results in 16 faces, but is it possible to do it with even fewer? (The faces should be simply connected (i.e. have no holes and one continuous border), and there should be no points or edges where the polynomial touches itself. ) Here is a quick 3d model: (EDIT: This approach yields 15 faces if you flatten two faces two one, as I wrote in the comments, but this results in a non-convex face. So it would also be interesting what happens if we restrict this to only convex faces. Here is what it looks like with those flattened faces: )","['polyhedra', 'graph-theory', 'geometry']"
2448290,Any variety is a subset of $\mathbb{P}^n$?,"Lemma I.4.1 of Hartshorn's Algebraic Geometry , states that two morphisms of varieties $\phi,\psi:X\to Y$ which are equal on a nonempty open subset $U\subset X$ are equal on all of $X$. In the proof, Hartshorne states that we may assume $Y\subset \mathbb{P}^n$ for some $n$. Why can we make this assumption?",['algebraic-geometry']
2448312,Understanding the proof for the divergence of the harmonic series,"I'm trying to understand the following proof for the divergence of the harmonic series: The parts which I can't seem to understand are: 
$$1. \sum_{i=0}^{n-1} \sum_{r=2^i+1}^{2^{i+1}} \frac{1}{r} > \sum_{i=0}^{n-1} 
\sum_{r=2^i+1}^{2^{i+1}} \frac{1}{2^{i+1}}$$ 
$$2. \sum_{i=0}^{n-1} \sum_{r=2^i+1}^{2^{i+1}} \frac{1}{2^{i+1}} = \sum_{i=0}^{n-1} (2^{i+1} - 2^i)\frac{1}{2^{i+1}}$$ I think understanding 2. follows from understanding 1. but I'm not entirely sure. Anyway for 1. I couldn't understand if the series on the RHS of the equality was $(\frac{1}{2^3})+(\frac{1}{2^3} + \frac{1}{2^4})+(\frac{1}{2^5} + \frac{1}{2^6}+\frac{1}{2^7}+\frac{1}{2^8})+...$ or $(\frac{1}{2^1})+(\frac{1}{2^2} + \frac{1}{2^3})+(\frac{1}{2^4} + \frac{1}{2^5}+\frac{1}{2^6}+\frac{1}{2^7})+...$ . And for part I simply could not understand 2. (probably  because I didn't understand 1.). So I'm wondering what the series on the RHS of 1. actually is and how it equals $\sum_{i=0}^{n-1} (2^{i+1} - 2^i)\frac{1}{2^{i+1}}$ .","['divergent-series', 'sequences-and-series', 'convergence-divergence']"
2448317,Conditional Probability of Good vs Bad Drivers,"I have a problem I'm working on that I'm not quite getting. The problem starts as such: Suppose that there are two types of drivers: good drivers and bad drivers. Let G be the event that a particular man is a good driver, A be the event that he gets into a car accident next year, and B be the event that he gets into a car accident the following year. Let P(G) = g and P(A|G) = P(B|G) = p1,P(A|G^c) = P(B|G^c) = p2, with p1 < p2. Suppose that given the information of whether or not the man is a good driver, A and B are independent. (for simplicity and to avoid being morbid, assume that the accidents being considered are minor and wouldnâ€™t make the man unable to drive). (a) Explain intuitively whether or not A and B are independent. (b) Find P(G|A^c) (c) Find P(B|A^c) I am looking for hints on how to start or think about this problem, as I'm quite stuck at the moment. My work is as follows thus far: A) If a driver gets into a car crash in the first year (meaning event A occurs, this means that it is more likely that the driver is a bad driver. Hence, it is more likely that event B occurs, meaning they are not independent. B) I immediately expand our desired probability as follows: $$P(G|A^c) = \frac{P(A^c|G)P(G)}{P(A^c)}$$ Using LOTP, we can expand the denominator as such: $$P(G|A^c) = \frac{P(A^c|G)*g}{P(A^c|G)*g + P(A^c|G^c)P(G^c)}$$ Any hints?","['bayesian', 'probability']"
2448324,How to show that the cuspidal cubic is not smooth using the formal smoothness criterion?,"Let $X/k$ be the cuspidal cubic over an algebraically closed field? How do I show that this is not formally smooth? The definition I am using for formally smooth is the one at the stacks project: https://stacks.math.columbia.edu/tag/02GZ What I really want to know is the following : a smooth morphism should roughly correspond to being a submersion, yes? If so, why is the cuspidal cubic not smooth? I guess we can be change to a scheme over which the map on tangents spaces is not smooth?",['algebraic-geometry']
2448481,"Convergence of sequence of function in $C[0, 1]$ and $C^1[0, 1]$","I try to prove that the sequence $\frac{t^{n+1}}{(n+1)}-\frac{t^{n+2}}{n+2}$ is convergent in $C[0, 1]$ but not convergent in $C^1[0, 1]$ where $C^1$ is the space of continuously differentiable functions. I try to show that the it is in fact a cauchy sequence, then I lost in the middle. Is there any way to that it is not cauchy in  the space of continuously differentiable function.","['continuity', 'convergence-divergence', 'sequences-and-series', 'functions']"
2448519,Discovering Quadratic Reciprocity,"Is there anything similar to this (page written by Field Medalist Timothy Gowers) for quadratic reciprocity ? I mean, the link there explains how you can figure out the solution of cubic equation by yourself without having a suddent flash of inspiration/ genius genes. Is there some similar guide for quadratic reciprocity ?","['number-theory', 'quadratic-reciprocity', 'intuition', 'motivation']"
2448521,Group of order $2555$ is cyclic,"I am preparing for an exam and am stuck on the following problem : Let $G$ be a group of order $2555 = 5 \cdot 7 \cdot 73$, show that $G$ is cyclic. It is not hard to show that the Sylow-73 subgroup is normal in $G$ and that at either the Sylow-5 or the Sylow-7 subgroup is normal. My thought was to prove that both the the Sylow-5 and Sylow-7 subgroups are normal, because then the claim would follow, but I am unsure how to proceed. Perhaps using the fact that $G$ mod the Sylow-73 subgroup is cyclic? Any hint would be appreciated. EDIT: So it suffices to show that $G$ is abelian because there is only one abelian group of order 2555, namely the cyclic group of order $2555$. Let $P_{73}$ denote the Sylow 73-subgroup. It is easy to see that $G/P_{73}$ is cyclic. Further we have that $G$ is abelian if $P_{73} \subseteq Z(G)$. I believe that $P_{73} \subseteq Z(G)$ can (may?) be shown by letting $G$ act on $P_{73}$ via conjugation. Then by the class equation, $73 =  \sum_{i =1}^n \text{cl}(x_{i})$ where $x_{1}, \dots, x_{n}$ is a set of representatives of each conjugacy class. I think that one can show that $\text{cl}(x_{i})$ is trivial, which implies that $gx_{i}g^{-1} = x_{i}$ for all $g \in G$ or, equivalently, that $gx_{i} = x_{i}g$. This would show that each element of $P_{73}$ is an element of the center of $G$ and then the claim would follow.","['finite-groups', 'sylow-theory', 'group-theory']"
2448601,Prove that $\frac{ab}{a+b} + \frac{cd}{c+d} \leq \frac{(a+c)(b+d)}{a+b+c+d}$,"$$\frac{ab}{a+b} + \frac{cd}{c+d} \leq \frac{(a+c)(b+d)}{a+b+c+d}$$
I tried applying a.m. g.m inequality to l.h.s and tried to find upper bound for l.h.s and lower bound for r.h.s but i am not getting answer .","['algebra-precalculus', 'inequality', 'a.m.-g.m.-inequality', 'cauchy-schwarz-inequality']"
2448606,"If $G$ is a group of order $231$, show that every element of order $11$ belongs to its center?","By Sylow's theorems, $G$ has a unique $11$-sylow subgroup of order $11$ and then cyclic, say this $11$-sylow subgroup called $N$.
And $N$ contains every element of order $11$ in $G$.
Then how can I complete the proof since I am stuck here.","['abstract-algebra', 'group-theory', 'sylow-theory']"
2448628,High school geometry proof help,"I need help with a high school geometry proof.  I think I've figured out why the prompt is true, but the proof attempt I've come up with seems very inelegant.  Is there an easier method I'm missing? Consider two circles with the second internally tangent to the first at point $A$ and also passing through the center of the first. Show that every chord of the first circle which has $A$ as an endpoint is bisected by the second circle. My attempted proof: Let there be any chord of the first circle which has $A$ as an endpoint.  Let the other endpoint of the chord be called $B$. Then let the following line segments be drawn: A segment connecting $A$ and the first circle's center $C$; A segment connecting $B$ and the first circle's center $C$; and A segment connecting the first circle's center $C$ with the point $I$ where the chord intersects the second circle. Segments $AC$ and $BC$ are the same length because they both represent the radius of the first circle. We have two right triangles $ACI$ and $BCI$.  Since the two hypotenuses $AC$ and $BC$ are the same length and the two heights $CI$ are the same length, then the two bases $AI$ and $BI$ must also be the same length.  Since $AI$ is half the length of the chord, the second circle bisects the chord. Thanks in advance for your help.",['geometry']
2448646,To prove $\left|\frac{p_n(z)}{q_m(z)}\right|\leq \frac{M}{|z|^{m-n}}$ for some $M>0$,"To prove there exist $M>0$ and $a_0>0$ such that for $|z|>a_0$,
$$\left|\frac{p_n(z)}{q_m(z)}\right|\leq \frac{M}{|z|^{m-n}}$$ where $p_n$ and $q_m$ are the polynomials of degree $n$ and $m$ respectively with $n<m$. I encountered this question in this post . According to the hint, it is enough to show that for large enough $R$ and for every $|z|>R$, we have
$$\left|\frac{z-z_1}{z-z_2}\right|<M$$
In fact,
$$\left|\frac{z-z_1}{z-z_2}\right|<\frac{|z-z_2|+|z_2-z_1|}{|z-z_2|}=1+\frac{|z_2-z_1|}{|z-z_2|}<M.$$","['complex-analysis', 'inequality']"
2448725,Prove that group of order 112 is solvable,"$|G|=112$, prove that $G$ is solvable. I already proved that $G$ is not simple so I know that it has normal subgroup but I don't know from what order. Another solution that I tried was looking at the sylow subgroups. In that case, if 2-sylow subgroup is normal or 7-sylow subgroup is normal then the solution is obvious, but in case that there are 7 2-sylow subgroups and 8 7-sylow subgroups, I don't know how to continue.","['normal-subgroups', 'solvable-groups', 'group-theory', 'sylow-theory']"
2448739,Do there exist algebras of more directions of operation than left-right?,"Again I am kind of new to most things algebraic, only having learned the very basics about groups. As little I have learned about groups and their operations is that an operation has two arguments, one from the left and one from the right. $$a\circ b = c$$ But is it meaningful and possible to define algebraic structures with operations with more than two operands? Like this three operand one for example (replacing $\circ$ with curlybraces to clarify direction of operation): $$\underset{o_2}{\underbrace{o_1}} \} o_3 = c$$ or four: $$o_4\{\underset{o_2}{\underbrace{o_1}} \} o_3 = c$$ This notation will make it get crowded on a 2D paper once we have a chain of many operations, but I hope you get the idea. Do you think such a thing would be possible to combine with the demands on a group in some sense? What meaning would ""inverse"" have for such a construction? Just pairs of elements as each others inverses would no longer make sense, right?","['operads', 'abstract-algebra', 'group-theory', 'soft-question']"
2448926,"$(e_1,e_2,..)$ is not a Schauder basis of $\ell^\infty$ [duplicate]","This question already has answers here : Why is $(e_n)$ not a basis for $\ell_\infty$? (2 answers) Closed 6 years ago . Show that $(e_1,e_2,...)$ is not a Schauder basis of $\ell^\infty$ where $e_i$ is the vector in $\mathbb R^\infty$ with 1 in the ith coordinate and 0 elsewhere and $\ell^\infty=\{(x_1,x_2,...)|x_i\in \mathbb R ~~and ~~ \|x\|_\infty<\infty\} ,\|x\|_\infty=\sup\{|x_1|,|x_2|,...\}$ I am wondering how to prove it and why this statement is true. Actually I think it is a basis since for any given vector $(x_1,x_2,...)=x_1e_1+x_2e_2+...$. I already proved that $(e_1,e_2,...)$ is a Schauder basis of $\ell^p$ where p>1. I just can't see what changes when it comes to the case of $\ell^\infty$","['banach-spaces', 'functional-analysis', 'lp-spaces', 'schauder-basis', 'linear-algebra']"
2448964,Show that $S_n$ has no subgroup of index $t$ for $2 < t < n$,"I am trying to solve the following exercise Show that $S_n$ has no subgroup of index $t$ for $2 < t < n$ which is the exercise 3.25 of An Introduction to Theory of Groups , by Joseph J. Rotman. I think I should use a theorem that says that if $H \le G$ and $[G : H] = \ell$ , then $\exists \rho \in \mathrm{Hom}(G, S_\ell)$ such that $\ker(\rho) \le H$ .  That would give me an isomorphism between $S_n / \langle \ker(\rho) \rangle $ and $\mathrm{Im}(\rho) \le S_t$ and I was hoping to prove that it is impossible. I tried to fix some value for $t$ , for instance, $t = 3$ , to have some idea about the general problem, but even in this scenario, I am not able to prove it, because I can't visualize the group $S_n / \langle \ker(\rho) \rangle $ . Well, do you have any tip? I am not looking for a full answer to that exercise, but maybe you could point out some theorems and properties of $S_n$ that might be useful here.","['abstract-algebra', 'group-theory', 'symmetric-groups']"
2449006,"Prove that $G$ is abelian if there exists $m\in \mathbb{N}$, so that $f(x)=x^m$, $f \in Aut(G)$","Let $G$ be a finite group with the following property: for any automorphism $f \in G$, there exists $m\in \mathbb{N}$ such that $f(x)=x^{m},\forall x\in G$. Prove that $G$ is abelian. Let $s,t \in G$, with $ord(s)|ord(t)$. We know that $f:G\rightarrow G, f(x)=txt^{-1} \in Aut(G)$. Therefore $f(x)=x^m, m \in \mathbb{N}, m \geq 1.$ Then $t=t\cdot t\cdot t^{-1}=f(t)=t^m$, hence $t^{m-1}=1$, following that $ord(t)|m-1.$ Obviously, $ord(s)|m-1$, so $s^{m-1}=1$, which means $s=s^m=f(s)=tst^{-1}.$ Multiplying with $t$ on the right side, we obtain $st=ts$. So I proved that $ts=st$, for any $s,t \in G$, with $ord(s)|ord(t)$. But I got stuck here, because I don't know how to prove that any two elements of $G$ commute, regardless of their order.","['finite-groups', 'abstract-algebra', 'group-theory']"
2449007,"If $\lim\limits_{x\to\infty}\frac{n}{u_n}=1$, what can we say about $\sum\limits_{n=1}^{\infty}(-1)^n \frac{1}{u_n}$?","If $\lim\limits_{x\to \infty}\frac{n}{u_n}=1$, can we prove that series $\sum\limits_{n=1}^{\infty}(-1)^n \frac{1}{u_n}$ converges,  doesn't converge or it's indefinite? I know that $\sum\limits_{n=1}^{\infty}\frac{1}{u_n}$ diverges by the comparing theorem. But I didn't find an explicit theorem about the alternate series. Any help will be appreciated, thank you!","['multivariable-calculus', 'sequences-and-series', 'calculus']"
2449010,Determinant of locally free sheaf,"In $\textit{Liu's Algebraic Geometry and Arithmetic Curves}$, on page $237$, he defines the determinant $\operatorname{det} \mathscr{F}$ of a locally free $\mathcal{O}_X$-module $\mathscr{F}$ by setting $(\operatorname{det} \mathscr{F})|_{X_i}:=\bigwedge^{r_i}(\mathscr{F}|_{X_i})$, where the $X_i$'s are the connected components of the scheme $X$ and $r_i$ denotes the rank of $\mathscr{F}$ on $X_i$. How does one make sense of this definition? The $X_i$'s aren't even open in $X$ in general, so a glueing approach does not work. Actually there wouldn't be anything to check in this case since $X$ is the disjoint union of the $X_i$'s.","['algebraic-geometry', 'commutative-algebra']"
2449021,Are there infinitely many Mama's numbers and no Papa's numbers?,"Just playing with square numbers, I made an interesting observation. $$11\times 11=121$$ $$12\times 12=144$$ $$13\times 13=169$$ $$.$$ $$.$$ $$.$$ $$20\times 20=400$$ $$21\times 21=441$$ $$.$$ $$.$$ $$.$$ . So, we will go from left to right and take two number to form a new number from the square numbers I listed above. For example from the number $169$ we can make three numbers $16,19,69$ but numbers $61,91,96$ are not allowed. Similarly for four digit numbers like $2401$ we are allowed to take $6$ numbers which are $24,20,21,40,41,01$ but we are not allowed to count $42,02,12,04,14,10$ . Now, look at the number $289$ . It is square of $17$ . We see that we can select three two digit numbers $28,89,29$ . Notice that $28$ is composite while $89$ and $29$ are primes. Next notice the number $256$ . It is square of $16$ . We can select three two digit numbers $25,26,56$ all of which happen to be composite. So, now we are in the position to have definitions: A Mama's number is a number $x>10$ such that all the two digit combinations of numbers chosen from $x^2$ from left to right are composite. Some trivial examples of Mama's numbers are $24$ as $24^2=576$ and $28$ as $28^2=784$ . Next: A Papa's number is a number $y>10$ such that all the two digit combinations of numbers chosen from $y^2$ from left to right are primes. The numbers which contain a prime as well as a composite in two digit combinations from left to right are neither Mama's nor Papa's numbers. I checked from $1$ to $50$ by hand and sadly I found no Papa's numbers. While several Mama's numbers were $15,16,18,20,22,24,25,28,30,38,40$ . Now, I have two questions: Are there infinitely many Mama's numbers? Is there any Papa's number? I hope I made myself clear. I beg you to point out if there are any errors in calculations or typos  (or edit them yourself). Thanks.","['number-theory', 'decimal-expansion', 'square-numbers', 'elementary-number-theory']"
2449072,Prove that exists $\lim_{x\rightarrow \infty }\frac{f(x)}{x}$ and determine its value [duplicate],"This question already has answers here : Show that if $\int_0^x f(y)dy \sim Ax^\alpha$ then $f(x)\sim \alpha Ax^{\alpha -1}$ (2 answers) Closed 6 years ago . Let $f:[0,\infty )\rightarrow \mathbb{R}$ be an increasing function, such that $\lim_{x\rightarrow \infty }\frac{1}{x^{2}}\cdot \int_{0}^{x}f(t)dt=1$. Prove that exists $\lim_{x\rightarrow \infty }\frac{f(x)}{x}$ and calculate this limit. If $f$ would be continuous, we'd have $1=\lim_{x\rightarrow \infty }\frac{1}{x^{2}}\cdot \int_{0}^{x}f(t)dt=\lim_{x\rightarrow \infty }\frac{f(x)}{2x}$, therefore $\lim_{x\rightarrow \infty }\frac{f(x)}{x}=2.$ But we don't know if $f$ is continuous or not, and I wasn't able to find any other idea.","['real-analysis', 'definite-integrals', 'calculus', 'limits']"
2449077,$|\text{det}(A)| = 1$ implies $A$ is orthogonal,"I know that $A$ orthogonal $\Rightarrow$ |det($A$)| = 1. Now I need to prove or disprove the reversed statement: $$
|\det(A)| = 1 \Rightarrow A \,\text{ is orthogonal}
$$ This is what I'm currently trying: $$
|\det(A)| = 1 \Rightarrow \det(A)^2 = 1 \Rightarrow \det(AA^t) = 1
$$ But I'm unsure whether this implies, that $AA^t = E_n$. Any help is welcome at this point. Maybe the statement isn't even true.","['transpose', 'determinant', 'proof-writing', 'orthogonal-matrices', 'linear-algebra']"
2449111,Existence of a subsequence such that $\lim_{n\to \infty} \|x_{n_k}-x\|=\ell>0$ in a Banach space?,"Let $x_n$ be a sequence in a uniformly convex Banach space $E$ such that $x_n \to x$ weakly in $E$ and $\|x_n\|_E \to \|x\|_E$. Then $x_n \to x$ strongly in $E$. To show this by contradiction a proof I'm reading states that first we suppose that (for the non-trivial $x\neq 0$ case)
$$
\limsup_{n\to \infty} \|x_n-x\|>0.
$$
Then there exists a subsequence $x_{n_k}$ such that
$$
\lim_{n\to \infty} \|x_{n_k}-x\|=\ell>0.
$$
My question is how can we say there exists such a subsequence that converges to a finite number? I don't see anything in the assumptions that gives us this?","['real-analysis', 'banach-spaces', 'functional-analysis', 'convergence-divergence', 'sequences-and-series']"
2449134,How to evaluate the sum : $\sum_{k=1}^{n} \frac{k}{k^4+1/4}$,"I have been trying to figure out how to evaluate the following sum:
$$S_n=\sum_{k=1}^{n} \frac{k}{k^4+1/4}$$ In the problem, the value of $S_{10}$ was given as $\frac{220}{221}$. I have tried  partial decomposition, no where I go. Series only seems like it telescopes, otherwise there isn't another way. Any ideas are appreciated!","['algebra-precalculus', 'telescopic-series', 'summation', 'sequences-and-series']"
2449146,Finding the limit of $ \lim_{x\to0} \frac {\sqrt[3]{1+x} - 1} {x} $,$$ \lim_{x\to0} \frac {\sqrt[3]{1+x} - 1} {x} $$ I think I'm missing out on something. Is there a concept to factor $\sqrt[3] {1+x}$? Thanks.,"['real-analysis', 'calculus', 'limits']"
2449213,"Proving $f: \Bbb{Z} \times\Bbb{Z} \to \Bbb{Z}, \ f(a,b)=3a-2b$ is surjective without using linear diophantine equation","I'm doing an exercise where I have to determine if $f: \Bbb{Z} \times\Bbb{Z} \to \Bbb{Z}, \ f(a,b)=3a-2b$ is injective, surjective or bijective. Coming up with a counterexample to show that it is not injective is fairly easy. $f(2,1) = f(0,-2)$ and $(2,1)\ne(0,-2)$ Now, for the surjectivity: Knowing this theorem: $\exists (a,b) \in \Bbb{Z} \times\Bbb{Z} : xa+yb = c \iff (x : y) | c$ we have $(3:2) = 1$ and $1|z \ \forall z \ \in \Bbb{Z}$ and we are done. But in the book where I found this exercise, linear diophantine equations are introduced a few chapters after the section containing this exercise . So I'm supposed to show the surjectivity without using the solvability of a linear diophantine equation . There has to be a more ""basic"" way of doing  this using only the following content, which is what the book covers up to the page where this exercise appears: Definition of a subset and basic operations between subsets (intersection, union, symmetric difference, exclusion, etc) Tables of truth and propositional logic Definition of cartesian product Definition of relations, reflexivity, symmetry, antisymmetry, transitivity. Order and equivalence relations. Equivalence clases. Definition of a function. Injective, surjective,  and bijective  functions. Inverse functions. Composition of functions. How can I show that this function is surjective without using the theorem that determines whether a linear diophantine equation is solvable?","['algebra-precalculus', 'functions', 'arithmetic']"
2449253,Sufficient statistic: prove Fisherâ€“Neyman factorization theorem using conditional expectation,"I am studying the following problem: Consider $X = (X^{(1)}, \ldots, X^{(n)})$ a random variable drawn from a distribution with density $p_{\theta}$ for some $\theta \in \Theta$, where $\theta$ is itself a random variable. Assume that the joint distribution of $(X, \theta)$ has the density $p(x, \theta) = p(x\mid\theta)p(\theta)$. The statistic $T(X)$ is said to be a sufficient statistic if there exists functions $f$ and $h$ such that for any $x$ $$ 
p(x\mid\theta) = h(x, T(x))f(T(x), \theta)
$$ Show that $T$ is a sufficient statistic if and only if $\theta$ and $X$ are conditionally independent given $T$. I have found a few proofs online, and they usually suppose that either all variables are discrete or all of them are continuous. I was thinking about proving a similar result in a more general case, in order to take into account all the possibilities (for example, $X$ and $T(X)$ continuous and $\theta$ discrete, or $X$ and $\theta$ continuous and $T(X)$ discrete). For that, I reformulated the problem using conditional expectations: Prove that there exists measurable functions $g$ and $h$ such that, for all measurable $f$:
  $$
E[f(X)\mid\theta] = h(X, T(X))g(T(X), \theta)
$$ if and only if $$
E[\phi(X)\psi(\theta)\mid T(X)] = E[\phi(X)\mid T(X)] E[\psi(\theta)\mid T(X)]
$$ for all measurable $\psi$, $\phi$. I would like to know if it is true (and how to prove it, if it is), as I couldn't prove it myself. Thank you for your help!","['probability-theory', 'conditional-expectation', 'statistics']"
2449302,"For set of segments, check if they can create n-side polygon","If we have given set of $n$ segments (or lengths of segments), how can we easily check if this set is forming polygon with $n$ sides. Example Let our set be $A$, $A = \{3, 6, 6\}, n = 3$ The answer here should be true, because we can arrange those segments to make triangle. But the problem for me is when there are more segments. So I tried to come with some statment, I started from triangle, it says: To form a triangle there shouldn't be side that is bigger than the sum of the other two sides, and I came to statement for more than 3 sides. Is this correct: For any n-sided polygon, there shouldn't be side that is bigger than the sum of any two other sides. Thanks in advance.","['triangles', 'geometry']"
2449318,Variance with specific PMF [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I'm having issues finding the variance of the following PMF: $$\mathbb P(X=k) = C \frac{p^k} k,\quad k=1,2,\ldots$$ where $C$ is a normalizing constant and $p$ is between $0$ and $1$ (inclusive). I have gotten the expected value-- which is $(Cp/q)$ -- but I am having issues calculating the $\operatorname{Var}(X)$, specifically with $E(X^2)$. Help please?","['statistics', 'probability']"
2449346,For an orthonormal basis and a linear transformation $T$ which is not possible,"Let, $H$ be a Hilbert space and let, $\{e_n:n \ge 1\}$ be an orthonormal basis of $H$. Suppose that $T:H\to H$ be a bounded linear operator. Then which of the following CANNOT be true: (A) $T(e_n)=e_1$. (B) $T(e_n)=e_{n+1}$ (C) $T(e_n)=\sqrt\frac{n+1}{n}e_n$ (D) $T(e_n)=e_{n-1}$ for all $n \ge 2$ and $T(e_1)=0$ How to start? Any hint?","['functional-analysis', 'hilbert-spaces', 'linear-algebra', 'analysis']"
