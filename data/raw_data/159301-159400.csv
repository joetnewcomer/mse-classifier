question_id,title,body,tags
2742349,What is this module in Hartshorne?,"In his book Algebraic Geometry, Hartshorne introduces the twisting sheaf on a scheme $X = \operatorname{Proj} $ of a graded algebra $S$. He does this by taking the associated sheaf on $X$ of the $S$-module $S(n)$. This is on pg. 117 of my edition. I don't know what the module $S(n)$ is. Is it the submodule of $S$ generated by the component of homogeneous elements of degree $n$?",['algebraic-geometry']
2742367,Is it possible to draw $6$ circles of equal radius each passing through the centres of exactly three others?,"Is it possible to draw $6$ circles of equal radius each passing through the centres of exactly three others? The problem seems to be a direct application of pigeonhole principle but how to use it? May I get a hint? Here's my take on the Problem : Consider the nodes of the graph as the centres of the circle and the edges as the connection between two circles. Then there will be 9 such edges. Assume that the radius of each circle is $1$ unit. So, how do we ensure that each edge is indeed $\leq 1$ unit?","['combinatorics', 'pigeonhole-principle']"
2742536,Is the product $\prod_{n=1}^{\infty}\left(\frac{\Gamma(n+\frac{1}{2})}{\sqrt{n}\Gamma(n)}\right)$ convergent?,"Consider the infinite product 
$$\prod_{n=1}^{\infty}\left(\frac{\Gamma(n+\frac{1}{2})}{\sqrt{n}\Gamma(n)}\right).$$
I know that it has the necessary condition for convergence ( i.e., $\frac{\Gamma(n+\frac{1}{2})}{\sqrt{n}\Gamma(n)}\to 1$) and the sequence $\frac{\Gamma(n+\frac{1}{2})}{\sqrt{n}\Gamma(n)}$ is increasing. Is the product convergent? If yes, anyone can determinate its value exactly or represent it by a closed form?","['special-functions', 'infinite-product', 'sequences-and-series', 'calculus']"
2742664,Showing that $\frac{1}{2\pi}\int^{2\pi}_{0}(2\cos\theta)^{2n}d\theta=\frac{(2n)!}{n!n!}$,"As the title suggests, I would like to show that: $$\frac{1}{2\pi}\int^{2\pi}_{0}(2\cos\theta)^{2n}d\theta=\frac{(2n)!}{n!n!}$$ for every positive integer $n$. How can I go about doing that? I understand the that there are already solutions for the problem: $\frac{1}{2\pi}\int^{2\pi}_{0}(\cos\theta)^{2n}d\theta= {2n \choose n} \frac{\pi}{2^{2n-1}}$. Is there any modifications I can do to obtain the desired solution?","['complex-analysis', 'complex-integration']"
2742678,CheckMyProof: Proofs involving Big-O Notation,"This is a homework exercise for a few weeks ago and I wanted your feedback on my improved proofs. For $g: \mathbb{N} \to \mathbb{R}$ let
  $$o(g):= \{f:\mathbb{N} \to \mathbb{R} |\forall \alpha > 0 : \exists n_0 \in\mathbb{N} : \forall n \geq n_0 : 0 \leq f(n) \leq \alpha g(n)\}$$
  Let $g: \mathbb{N} \to \mathbb{R}$ so that $g(n)\not= 0$ for infinitely many $n \in \mathbb{N}$. Prove or disprove $\mathcal{O}(g) \setminus \Theta(g) \subseteq o(g)$ $o(g) \subseteq \mathcal{O}(g) \setminus \Theta(g)$ $f \in o(g) \implies g \notin o(f)$ Our definitions of $\mathcal{O}$ and $\Omega$ and $\Theta$ are as follows
$$
f \in \mathcal{O}(g) \iff
\exists n_0 \in \mathbb{N} ~\exists \alpha >0 : 0 \leq f(n) \leq \alpha g(n) ~~\forall n \geq n_0 ~~~\textrm{and}
$$
$$
f \in \Omega(g) \iff
\exists n_0 \in \mathbb{N} ~\exists \beta >0 : 0 \leq \beta g(n) \leq f(n) ~~\forall n \geq n_0
$$ $$
f \in \Theta(g) \iff f \in \Omega(g) \land f \in \mathcal{O}(g)
$$ The incorrectness of the statement is proven by counterexample. Let $f(n) := \begin{cases} 1 & n ~\textrm{odd} \\ 0 & n ~\textrm{even} \end{cases}~~~$ and $g(n) = 1$, then  $f \in \mathcal{O}(g) \setminus \Theta(g)$ but $f \notin o(g)$. Proof: From the definition we know, that
$$
f \in \mathcal{O}(g) \iff
\exists \hat{n_0} \in \mathbb{N} ~\exists \alpha >0 : 0 \leq f(n) \leq \alpha g(n) ~~\forall n \geq \hat{n_0} ~~~\textrm{and}
$$
$$
f \notin \Theta(g) \iff
\exists \tilde{n_0} \in \mathbb{N} ~\nexists \beta >0 : 0 \leq \beta g(n) \leq f(n) ~~\forall n \geq \tilde{n_0}
$$
Combining those statements we obtain for all  $ n \geq \tilde{n_0}, \hat{n_0} \in \mathbb{N}$
$$
0 \leq \beta g(n) \leq f(n) \leq \alpha g(n) \iff
0 < \beta \leq f(n) \leq \alpha
$$
Since $~f(n) \in \{0,1\}$, there exists no $\beta >0$ to make $0 < \beta  \leq f(n)$ true, because for every even $n$ we obtain $0 = f(n) < \beta  ~\forall \beta > 0$. $~~~~\square$ (Question specifically here: $\beta > 0 $, but the condition is $\beta g(n) = \beta \geq 0$. In the last paragraph, do I use $\geq$ or $>$ ?) The statement is correct. Let $f \in o(g)$, then clearly $f \in \mathcal{O}(g)$. Now we have to show that $f \notin \Theta (g)$.
Let's assume $f \in \Theta (g)$, while $f \in o(g)$, then follows that
$$
f(n) \leq \alpha g(n) ~\forall \alpha > 0 ~\textrm{and}~ n \geq n_0 \in \mathbb{N} \land \beta g(n) \leq f(n) ~\textrm{for one}~ \beta > 0 ~\forall n \geq \tilde{n_0} \in \mathbb{N}
$$
Which is a contradiction, because the first condition is only true if $f(n) = \beta g(n)$. Then $\beta g(n) > \alpha \beta g(n)$ for a $\alpha <1$, so the second condition can't hold. So $f \notin \Theta (g)$ and therefore the statement is true. The statement is correct. Let $f \in o(g)$ and $g \in o(f)$. Then
$$
\exists n_0 \in \mathbb{N} ~\forall \alpha > 0: 0 \leq f(n) \leq \alpha g(n) ~~\forall n \geq n_0 ~~~\textrm{and}
$$
$$
\exists \tilde{n_0} \in \mathbb{N} ~\forall \tilde{\alpha} > 0: 0 \leq g(n) \leq \tilde{\alpha} f(n) ~~\forall n \geq \tilde{n_0}
$$
Combing both conditions we obtain
$$
\exists \hat{n_0} := \max\{n_0, \tilde{n_0}\} ~\forall \alpha, \tilde{\alpha} >0 : 0 \leq f(n) \leq \alpha g(n) \leq \alpha \tilde{\alpha} f(n)~~\forall \hat{n_0} \geq n \in \mathbb{N}
$$
Which is only possible if $f = g = 0$, but $g \not= 0$ for infinitely many $n \in \mathbb{N}$, producing a contradiction, so we know that $g \notin o(g)$, proving the statement correct. Alternatively choose $\alpha = 1, \tilde{\alpha} = 0.5$ to obtain
$$
0 \leq f(n) \leq g(n) \leq 0.5 f(n) \implies 2f(n) \leq f(n) \implies 2 \leq 1
$$
arriving at a contradiction.
(Here: searching for a better justification of the contradiction)","['real-analysis', 'computer-science', 'asymptotics', 'proof-verification', 'discrete-mathematics']"
2742697,$\lim_{x\rightarrow \frac{\pi }{3}}\frac {\sin x-\sqrt {3}\cos x}{\sin 3x}$ has two different values?,"Given a limit like:
$$\lim_{x\rightarrow \frac{\pi }{3}}\frac {\sin x-\sqrt {3}\cos x}{\sin 3x}$$ How did I solve it: $$\begin{align}\lim_{x\rightarrow \frac{\pi }{3}}\frac {-2 (-\frac {1}{2}\sin x+\frac {\sqrt {3}}{2}\cos x)}{\sin 3x} &= \lim_{x\rightarrow \frac{\pi }{3}}\frac {-2 (-\sin\frac {\pi}{6}\sin x+\cos \frac {\pi}{6}\cos x)}{\sin 3x}\\&= \lim_{x\rightarrow \frac{\pi }{3}}\frac {-2\cos (\frac{\pi }{6}+x)}{\sin 3x}\\&= \lim_{x\rightarrow \frac{\pi }{3}}\frac {-2\cos (\frac{\pi }{6}+x)}{\sin 3x}\\&= \lim_{x\rightarrow \frac{\pi }{3}}\frac {-2\cos \left[\frac{\pi }{2}-(\frac{\pi}{3}-x)\right]}{\sin 3x}\\&= \lim_{x\rightarrow \frac{\pi }{3}}\frac {-2\sin (\frac{\pi}{3}-x)}{\sin 3x}\\&= \lim_{t\rightarrow 0}\frac {-2\sin t}{\sin \left[3 (\frac{\pi}{3}-t)\right]}\\&= \lim_{t\rightarrow 0}\frac {-2\sin t}{-\sin 3t}\\&= \frac {2}{3}\end{align}$$ I don't know if this is correct but Wolfram Alpha points out it's $-\frac {2}{3}$ instead (L'hopital Rules).
Can anyone show me if there's any error above? Or the limit really has two answers?
Thanks in advance.","['limits-without-lhopital', 'trigonometry', 'calculus', 'limits']"
2742820,Almost sure convergence of the average of the product of 0-1 random variables,"Assume that $X_n^N$, $n=1,\ldots,N$ for all $N>0$ are 0-1 random variables such that 
$$
\frac{1}{N} \sum_{n=1}^N X_n^N \to p
$$
almost surely. Now, consider $a$ sequence of i.i.d. Bernoulli random variables $(Y_n)$ with parameter $q$.
It is known that $Y_n$ is independent of $X_n$, and that $X_n$ may depend on $Y_i$ but only if $i<n$. My question is:
can we conclude that
$$
\frac{1}{N} \sum_{n=1}^N X_n^N Y_n \to pq
$$
almost surely? My attempt/note :  if the LHS would be replaced by expectation, then the result would be true because $\mathbb{E}[X_n Y_n] = \mathbb{E}[X_n] q$ and 
$\frac{1}{N} \sum_{n=1}^N \mathbb{E}[X_n] \to p$ by the uniformly integrability of the $X_n^N$. This should also mean that if the random variable $\frac{1}{N} \sum_{n=1}^N X_n^N Y_n$ converges, then it must converge to $pq$. So it would remain to show that it converges.","['probability-limit-theorems', 'probability-theory', 'probability', 'convergence-divergence', 'random-variables']"
2742831,"In proving that $\sqrt{a}$ is always irrational, $\forall a\in\left\{\Bbb R^+ : 1< a\neq b^2\right\}$... a different way.","I was trying to prove the following statement: $$\sqrt{a}\text{ is always irrational, }\forall a\in\left\{\mathbb{R}^+ : 1<a\neq b^2\right\}.\tag{$b\in\mathbb{Z}$}$$ I know there is at least one other post of this, but I have not looked at it because I already know how to prove this (using the Fundamental Theorm of Algebra , or FTOA). However, I wanted to come up with my own proof, instead of using a well-known proof. Below is what I came up with. I have used proof by contradiction (or in latin, reductio ad absurdum ). May somebody  verify whether or not it is true? Supposed Proof: Proof : Assume the statement otherwise, then $$\exists p, q\in\left\{\mathbb{R}^+ : \sqrt{a}=\frac{p}{q}\Leftrightarrow aq^2=p^2\right\}.\tag{$q\neq 1$}$$ Since $a\neq 1$ then $p\neq q$, and either $p>q$ or $p<q$. Consider the former, i.e. $p > q$. Subtract $q^2$ from both sides. $$\begin{align} aq^2 - q^2 &= p^2 - q^2 \\ \Leftrightarrow q^2(a-1) &= (p+q)(p-q) \\ \Leftrightarrow a - 1&{\ \mid} \ \ (p+q)(p-q) \\ \Leftrightarrow a &\equiv 1\pmod {p\pm q}.\end{align}$$ For the last statement, it is unknown whether $a-1\mid p+q$ and $a-1\nmid p-q$ or vice versa, but what is known, is that $a-1$ divides one of those factors. Since there are infinitely many primes $s$, then there are infinitely many numbers $s_0$ such that $s-1=s_0$. By Fermat's Little Theorem, raising both sides of the congruence to the power of $s-1$ yields that the modulo is prime, i.e. $$a^{s-1}\equiv 1^{s-1}= 1\pmod {p\pm q},$$ thus $p+q$ and/or $p-q$ is prime. If we were to assume that the fraction $p/q$ was irreducible, then $\gcd(p,q)=1$, making it perfectly allowable for one of the conjugates to be prime. However, $$\begin{align} q^2(a-1)&=(p+q)(p-q) \\ \Leftrightarrow q^2&{ \ \mid} \ \ (p+q)(p-q) \\ \Leftrightarrow q&{ \ \mid} \ \ p\pm q.\end{align}$$ This is of course a contradiction, because now $q\mid p$, therefore $\gcd(p,q)\neq 1$; therefore $p/q$ can be simplified; and therefore $p\pm q$ is not prime, unless $p=0$. But that means $\sqrt{a} = 0$ $\Leftrightarrow a = 0 < 1$, even though $1 < a$. Contradiction. Because of this contradiction, the first case cannot be true, i.e. $p\not > q$. Therefore, the only case left is that $p<q$. But, using the same steps, since $p < q$, then $p - q < 0$. $$\therefore \exists t\in\mathbb{R}^+ : q^2(a-1) = -t(p+q)(p-q).\tag{$p,q>0$}$$ But $q^2\nmid -t$ because otherwise $\sqrt{-1}\mid q$ or $-1\mid q$, and thus either way, $q\notin\mathbb{R}^+$. And $a-1\nmid -t$ because if $1 < a$, then $a - 1 > 0 > -t$. And, trivially, $t\neq 0$, for otherwise $q^2 = 0$ $\Leftrightarrow q = 0$ and $ a = 1$. Contradiction. Thus our second case cannot be true either, and since both of our two cases lead to a contradiction, then it is false to assume the statement otherwise. This completes the proof. $\qquad\qquad\qquad\quad\,\,\,\Box$ Edit: As noted in the comments, $a\neq 2$, but I can prove seperately that $\sqrt{2}$ is irrational, so $a\neq 2$. If my proof is correct, how can I prove the same statement but with the condition that $a\in (0,1)$? I want to prove that in the same fashion. This post is entirely derived from my curiosity. Thank you in advance.","['proof-verification', 'algebra-precalculus', 'number-theory', 'proof-writing', 'modular-arithmetic']"
2742849,Number of non-negative integral solutions [duplicate],"This question already has answers here : Counting bounded integer solutions to $\sum_ia_ix_i\leqq n$ (5 answers) Closed 1 year ago . This is a problem I've seen a couple times around here, but I couldn't find one quite like this. Say we have ten variables, $a, b,$ and $c_1, c_2, c_3,\dots, c_8$. How many non-negative integral solutions are there to the following problem such that $a\leq 5$ and $b\geq 5$:
$$a+b+c_1 +c_2+c_3 +c_4 +c_5+c_6+c_7+c_8 = 100$$
I understand that the total number of solutions when $a$ and $b$ are unrestrained is ${10+100-1\choose 100}$, but I don't know any real way to formulate these restraints without something like
$$\sum_{a=0}^{5}\sum_{b=5}^{100-a}{107 - b-a\choose 7}$$
or something of the sort. Is there an easier way?","['combinatorics', 'discrete-mathematics']"
2742859,Hints on how to solve $(x+y^2)dy = ydx$?,"I'm looking for hints on how to solve the differential equation: $(x+y^2)dy = ydx$ .
I tried finding an integrating factor and dividing both sides by $y$ but that didn't work.","['ordinary-differential-equations', 'calculus']"
2742862,Inclusion of $C^*(S)$ in $W^*(S)$ is proper,"I have a little question concerning operator algebras. Consider the unilateral shift $S\in \mathcal{B}(\ell^2)$ defined by $Se_n=e_{n+1}$, $e_i$ being the canonical orthonormal basis of $\ell^2$. Then take the $C^*$-algebra generated by $S$, that is the the completion of the algebra of all polynomials in $S$ and $S^*$ with respect to the operator norm, and the von-Neumann-Algebra $W^*(S)$ generated by $S$ which is the same but with respect to the strong operator topology. It is easy to see that $C^*(S) \subset W^*(S)$ and that $W^*(S)$ is actually the whole space $\mathcal{B}(\ell^2)$. But is this inclusion proper? What would be a linear Operator that is not in $C^*(S)$? I tried to think of a property that all elements in $C^*(S)$ fulfill and then find a linear operator that does not have this property but i can't seem to find something fitting. Does someone know an example? Thanks!","['functional-analysis', 'c-star-algebras', 'operator-algebras', 'von-neumann-algebras']"
2742879,"$f^{(n)}(x)$ exist $\forall x \in I$, an interval in $\mathbb{R}$ but $f^{(n+1)}(x)$ does not exist for any $x \in I$","$f'(x)$ , $f''(x)$ , $f^{(3)}(x)$ , ..., $f^{(n)}(x)$ all exist $\forall x \in I$ , an interval in $\mathbb{R}$ but $f^{(n+1)}(x)$ does not exist for any $x \in I$ Can such a function exist? In words: Does there exist a function $f$ that is $n$ -times differentiable on an interval $I$ but is not $(n+1)$ -times differentiable anywhere on $I$ (i.e. $(n+1)$ -differentiable nowhere on $I$ )? I think it can't but can't think of the reason why. I can construct a function with countably infinite points in I where the function is only differentiable n times, but, it seems impossible to have every point in the interval, I, have this property.","['derivatives', 'real-analysis', 'calculus']"
2742927,Sum of subsets of N i.i.d Bernoulli trials,"suppose we have subsets $I_1,I_2 \subseteq \{1,\dots,n\}$ of size $n_1,n_2 <= n$ of n i.i.d Bernoulli trials $X_1,\dots,X_n$ and let $Y=\sum_{i \in I_1}X_i, Z=\sum_{i \in I_2}X_i$. Any ideas on how to calculate $\mathbb{P}(\{Y\leq k\}\cap\{Z\leq k\})$ in terms of the distribution of sums of  some $X_i$ for some $k\leq n$? I assume it will be useful to describe
$Y = C + \tilde Y$ and $Z = C + \tilde Z$, where $C = \sum_{i \in I_1 \cap I_2} X_i$ since then $C, \tilde Y, \tilde Z$ are independent. I appreciate your help :)","['probability-distributions', 'probability', 'binomial-distribution', 'discrete-mathematics']"
2742968,How many ways can you color the edges of a square with 4 colors?,"In this case, colorings that differ by the action of an element of $D_4$ are considered the same. We also can use any combination of the 4 colors. I am using Burnside's Lemma for this. First, the set of possible colorings $X$ has $4^4$ elements since we can paint any edge any color. The identity fixes every element of $X \therefore \mathrm{Fix}(e)=4^4$ $j_x$ the flip along the x axis, let us choose any colors for the two vertical edges, and the color of the horizontal edges has to match, therefore that is a total of $\mathrm{Fix}(j_x) = 4^3$ possible combinations of color. Without loss of generality, we obtain the same for $j_y$, the flip along the y axis. We have two more flips along the diagonals of the square. In this case, the two edges of one side of the diagonal have to match their respective edges of the other side, giving a total of $\mathrm{Fix}(j_{\pm\pi/4}) = 4^2$ possible combinations for each flip. The rotation by $\pi/4$ needs every color to be the same in every edge, therefore we get $\mathrm{Fix}(r_{\pi/4}) = 4$ possible combinations. This also counts for $\mathrm{Fix}(r_{-\pi/4}) = 4$ Finally, for the rotation by $\pi/2$, the top and bottom edges swap places, and the left and right edges swap places as well, giving $\mathrm{Fix}(r_{\pi/2}) = 4^2$ since the top-bottom pair can have 4 possible colors and the left-right pair can have 4 possible colors. Using Burnside's Lemma we get $$\mathrm{\# Colorings} = \frac{1}{|D_4|} \sum_{g\in G} \mathrm{Fix}(g) = \frac{4^4+2\cdot4^3+3\cdot4^2+2\cdot4}{8} = 55$$","['proof-verification', 'group-actions', 'combinatorics', 'coloring', 'group-theory']"
2743002,Power series solution of $y'' + e^x y = 0$,"In the book of Int. to the Ordinary Differential Equation by Coddington, at page 130, in question 130, it is asked that The equation $$y'' + e^x y = 0$$ has a solution $\phi$ of the form 
  $$\phi(x) = \sum_{k=0}^\infty c_k x^k$$ which satisfies $\phi (0) =
 1$, $\phi'(0) = 0$. Find $c_k$. I have plugged the Power series solution $\phi$ into the ODE, and found that every $$\sum_{k_0}^\infty [(k+2)(k+1)a_{k+2} + a_k e^x] x^k = 0$$. However, we can interpret this result in two different way. First; For a given $x$, the expression $$[(k+2)(k+1)a_{k+2} + a_k e^x]$$ has to be zero for all $k=0,1....$, Second; we can write this equation as $$\sum_{k_0}^\infty [ (k+2)(k+1)a_{k+2}x^k + a_k e^x x^k] = 0 $$,
and since each $x^j$ and $x^ie^x$ are linearly independent provided that $x\not = 0$, each coefficient $a_k$ has to be zero. Since in particular, we are dealing with $x = 0$, we can still reach the same conclusion as in the first case, but what if we were dealing with $x=x_0 \not = 0$, then can we apply the first logic ?",['ordinary-differential-equations']
2743023,Is there a class of real functions strictly between $C^{\infty}$ (smooth) and $C^{\omega}$ (analytic)?,"I'm relatively new to the concept of analytic functions, and began wondering: Is it possible to exist a class of functions strictly between $C^{\infty}$ (smooth functions) and $C^{\omega}$ (analytic functions)? In other words, could there be a class $C^{\alpha}$ of functions from $\mathbb{R}$ to $\mathbb{R}$ such that $f \in C^{\omega} \Rightarrow f \in C^{\alpha} \Rightarrow f \in  C^{\infty}$, but $f \in C^{\infty} \nRightarrow f \in C^{\alpha}$ and $f \in C^{\alpha} \nRightarrow f \in C^{\omega}$? If so, what coud be this class? Thanks.","['real-analysis', 'analytic-functions', 'functions']"
2743033,Study the continuity domain and derivability domain,"Let $(u_n)_{n\in\mathbb{N}}$ with the general term $u_n=\frac {1+x^{n}}{1+x+x^{2}+...+x^{n+p-1}}$, where $x\ge0$ and $p \in \mathbb{N}$. Let $f(x)= \lim_{n\to\infty}u_n$. Find the differentiability and continuity domain. First I tried to simplify a little $u_n$ using the sum of the geometric progression and I got this
$$u_n=\frac{(1+x^{n})(x-1)}{x^{n+p}-1}.$$
So if $x \in (0,1)$, then $f(x)=1-x$. What should I do when $x = 1$ and $x>1$?","['derivatives', 'real-analysis', 'calculus']"
2743054,"Solution for $\frac{dy}{dx}=\frac{1}{y^2}-\frac{1}{x^2}$, change of variables, integrating factor","I encountered the following nonlinear 1st order ODE as a simplified case of this question . $$\frac{dy}{dx}=\frac{1}{y^2}-\frac{1}{x^2}$$ I didn't find it in the literature and Wolfram Alpha couldn't solve it either. However, I believe it might have a solution,. Replace: $$y= r \sin t, \qquad x=r \cos t$$ After simplifications, this leads to the following ODE: $$(r^2 \sin^3 t \cos^2 t+\sin^2 t \cos t- \cos^3 t) dr+\left(r^3 \sin^2 t \cos^3 t+r( \sin t \cos^2 t-\sin^3 t) \right)dt=0$$ $$P(r,t) dr+Q(r,t)dt=0$$ Checking if the new ODE is exact or not, we find that it's not, but the partial derivatives look promising: $$P_t =r^2 (3 \sin^2 t \cos^3 t-2 \sin^4 t \cos t) +5 \sin t \cos^2 t-\sin^3 t$$ $$Q_r =r^2 (3 \sin^2 t \cos^3 t) +\sin t \cos^2 t-\sin^3 t$$ I feel like there's a simple integrating factor we can use here, but I have no idea what it is. Can we find an integrating factor which makes the last ODE exact? If we can, what is it? Is there another way to obtain an explicit or implicit solution for the titular ODE in terms of known functions? What about the more general case ( $a,b$ - constants)? $$\frac{dy}{dx}=\frac{a}{y^2}-\frac{b}{x^2}$$ Edit Multiplying by $\frac{1}{\cos^2 t}$ we obtain: $$\left(r^2 \sin^3 t +\frac{\sin^2 t }{\cos t}- \cos t\right) dr+\left(r^3 \sin^2 t \cos t+r\left( \sin t -\frac{\sin^3 t}{\cos^2 t}\right) \right)dt=0$$ Now we have: $$P_t=3 r^2 \sin^2 t \cos t+ \sin t +\frac{\sin^3 t }{\cos^2 t}$$ $$Q_r=3 r^2 \sin^2 t \cos t+ \sin t -\frac{\sin^3 t }{\cos^2 t}$$ It's almost exact. Did I make a mistake somewhere? Or do we need a more elaborate integrating factor? Edit 2 Hyperbolic substitution: $$y= r \sinh t, \qquad x=r \cosh t$$ leads to a similar equation, which is still not exact: $$\left(r^2 \sinh^3 t-\frac{1}{\cosh t} \right) dr+\left(r^3 \sinh^2 t \cosh t-r \frac{\sinh t}{\cosh^2 t} \right) dt=0$$ $$P_t=3 r^2 \sinh^2 t \cosh t +\frac{\sinh t }{\cosh^2 t}$$ $$Q_r=3 r^2 \sinh^2 t \cosh t -\frac{\sinh t }{\cosh^2 t}$$","['integrating-factor', 'ordinary-differential-equations']"
2743096,Adding Gaussian Distributions,"I am trying to show that a set of numbers distributed from a Gaussian distribution {g1, g2,...,gn} with a standard deviation of 1 and a mean of zero can be transformed to a set of Gaussian numbers {G1, G2,...,Gn} that have a standard deviation of s and a mean of m by the formula: Gi = s * gi + m  (ignoring any normalization constants) Despite my best efforts I cannot seem to find a way to prove this well known relationship true.","['statistics', 'normal-distribution', 'probability-distributions']"
2743100,Why are these $\sum \cos$ and $\csc$ equivalent?,"Mathematica 'simplifies' this formula $$\sum_{k=1}^R \cos \frac{2k \pi x}{R}$$ to this $$\frac{1}{2} \biggl(\csc \frac{\pi x}{R} \sin \frac{(2R+1) \pi x}{R}-1\biggr)$$ A graphical plot of the two formulae generates two identical continuous curves - but why? Surely $\csc \frac{\pi x}{R}$ is discontinuous, with poles at $x={0,R,2R,3R...}$? So, how can $\frac{1}{2} \bigl(\csc \frac{\pi x}{R} \sin \frac{(2R+1) \pi x}{R}-1\bigr)$ produce a continuous curve? I'd be grateful for: A proof of this equivalence An explanation for why the resulting curve is continuous despite $\csc \frac{\pi x}{R}$ being discontinuous.","['trigonometry', 'sequences-and-series', 'trigonometric-series']"
2743105,Can the limit of a sequence of matrices of fixed rank have higher rank?,"Consider the $n\times n$ matrices given by $A_n=1/n*I_{n\times n}$. For every finite $n$ each $A_n$ has rank $n$ but the limit is the zero matrix, and has rank zero. So the limit of a sequence of rank $n$  matrices need not be of rank $n$.  Now I am considering the reverse question. Consider a sequence $A_k \in \mathbb{R}^{m \times n}$ (or $\mathbb{C}^{m \times n}$). Is it possible to construct a sequence such that each $A_k$ has some rank $d \le \min(m,n)$ but: $\operatorname{rank} \left( \lim \limits _{k \to \infty} A_n \right) >d$? If not how would one go about proving that matrices cannot jump rank?","['matrices', 'real-analysis', 'matrix-rank']"
2743166,Ricci flow of the Torus,"Let us consider the torus  of revolution, say $T$, and consider a local parametrisation \begin{aligned}x(\theta ,\varphi )&=(R+r\cos \theta )\cos {\varphi }\\y(\theta ,\varphi )&=(R+r\cos \theta )\sin {\varphi }\\z(\theta ,\varphi )&=r\sin \theta. \end{aligned} Given $T$ the induced metric of $\mathbb E^3$, we have in local coordinates $(\theta,\varphi)$ that we can write the metric as \begin{aligned} g|_T=r^2d\theta^2+(R+r\cos\theta)^2d\varphi^2.\end{aligned} I know that \begin{aligned} Ric_{g|_T}=\frac {r\cos\theta}{R+r\cos\theta}d\theta^2+\frac 1r\cos\theta(R+r\cos\theta)d\varphi^2.\end{aligned}
How can I, if it is even possible, find the explicit solution of the Ricci flow: \begin{aligned} \partial_tg=-2Ric_g\\g(0)=g|_T~~~\end{aligned} (I have seen how it is done for the sphere, cigar soliton, and the immortal solution stated in The Ricci Flow: An Introduction -- by Bennet Chow and Dan Knopf.) If it is not possible, why? Thanks in advance.","['ricci-flow', 'differential-geometry', 'geometry']"
2743169,Asymptotics of number of ways of putting balls into bins with constraints,"Suppose you have $n$ white balls and $n$ blacks balls. Let us define $f(n)$ to be the number of different ways there are of putting the balls into unlabelled bins so
  that you have an odd number of each color in each bin. For example, if you have $3$ white and $3$ black there are $2$ different ways, so $f(3) = 2$. You either put them all in one bin or one white and one black in each of $3$ bins.  For $5$ white and $5$ black balls there are $4$ different ways so $f(5) = 4$.  These are: (wwwwwbbbbb)
(wwwbbb)(wb)(wb)
(wwwb)(wbbb)(wb)
(wb)(wb)(wb)(wb)(wb) I am interested in the following question. What is $f(n)$ asymptotic to? For the task of computing the exact value of $f(n)$,
very nice answers were given by Marko Riedel and Christian Sievers .  I reproduce them here: The first answer was in reply to a question with only odd $n$ and says: The cycle  index $Z(S_n)$  of the  symmetric group  (multiset operator
$\def\textsc#1{\dosc#1\csod}     \def\dosc#1#2\csod{{\rm     #1{\small
#2}}}\textsc{MSET}$) has $Z(S_0)=1$ and the recurrence $$Z(S_n) = \frac{1}{n}\sum_{l=1}^n a_l Z(S_{n-l}).$$ Extracting coefficients from this Maple will produce $$1, 2, 4, 12, 32, 85, 217, 539, 1316, 3146, 7374, 16969, 38387, 85452, 
\\ 187456, 405659, 866759, 1830086, 3821072, 7894447, 16148593, 
\\ 32723147, 65719405, 130871128, 258513076, 506724988,
\ldots$$ 
where we have used memoization. The repertoire here was 
$$f(W, B) = \sum_{p_1=0}^q \sum_{p_2=0}^q W^{2p_1+1} B^{2p_2+1},$$ the substitution $a_l = f(W^l, B^l)$  and the coefficient being extracted $$\sum_{k=1}^{2q+1} [W^{2q+1}] [B^{2q+1}] Z(S_k)(f(W,B)).$$
The second answer says: More general, the coefficient of $x^my^n$ in $$ \prod_{i,j\geq 0}(1-x^{2i+1}y^{2j+1})^{-1} $$ tells you how many ways there are to distribute $m$ white and $n$ black balls into bins such that each bin contains an odd number of white and an odd number of black balls. By computer calculation of the coefficients, the ratio of successive answers (for $m=n$ as in the original question), seems to tend slowly towards 1.    Therefore it's not even clear that the answer is asymptotic to $c^n$ for any $c>1$. For odd $n$ the sequence is https://oeis.org/A302919 .","['combinatorics', 'asymptotics']"
2743175,Complex integral $I=\int_{|z|=2} \frac{z^3 e^{\frac{1}{z}}}{z+1}dz$,"I have this integral from someone who told me it has a nice answer.$$I=\int_{|z|=2} \frac{z^3 e^{\frac{1}{z}}}{z+1}dz$$ I tried to evaluate this using residues theorem, and expanded into series to find the residue at $\infty$$$f(z)=z^3[\sum_{n=0}^{\infty}(-1)^nz^n(\sum_{n=0}^{\infty} \frac{1}{(n!)z^n})]$$ And with Cauchy product:$$f(z)=z^3(\sum_{n=0}^{\infty}\sum_{k=0}^n \frac{(-1)^k z^{2k-n}}{(n-k)!})$$ Now I am lost, how can I find the coefficient of $z^{-1}$ in this double series? It seems that is not just a simple number... Or shall I use another method?","['complex-analysis', 'contour-integration', 'residue-calculus']"
2743185,"Finding all the maximal ideals of $C([0,1])$ and also prime ideals in it which are not maximal","Hope this isn't a duplicate. I have been able to prove that the maximal ideals of $C([0,1])$ are of the form $M_c = \big\{ f \in C([0,1]) : f(c)=0 \text{ for some fixed $c$ }\in [0,1]\big\}$ . I was trying to find all the maximal ideals of $C([0,1])$ and also prime ideals in it which are not maximal. No idea so far...","['c-star-algebras', 'maximal-and-prime-ideals', 'general-topology', 'ring-theory']"
2743187,Integrate $\sin(\cos x)\text{d}x$,"Soo.. a question appeared in my exam in which I had to compare the values of the following integrals $$J=\int_0^{\pi/2} \sin(\cos x)\,\mathrm dx\\I=\int_0^{\pi/2} \cos(\sin x)\,\mathrm dx \\K=\int_0^{\pi/2} \cos x\,\mathrm dx$$ I was able solve it using an indirect method but it left me wondering whether I could find the exact values of the three integrals. PS: I have linked a picture of the problem and its solution for your reference.","['definite-integrals', 'integration', 'trigonometry', 'trigonometric-integrals']"
2743197,A function not equal to its Taylor series.,"I have been given this problem as a practice for an upcoming exam and I am unsure how to approach it. Give and example of a function that has derivatives of all orders, but is not equal to the sum of its Taylor series. Justify your example.","['derivatives', 'taylor-expansion', 'sequences-and-series']"
2743238,"$U \subset \mathbb R^n$ is an open set, $f \in C^1(U, \mathbb R^m)$. If $E \subset U$ is a null set, then $f(E)$ is also a null set.","I am trying to prove the following statement: Suppose $U \subset \mathbb R^n$ is an open set, $f \in C^1(U, \mathbb R^m)$. If $E \subset U$ is a null set, then $f(E)$ is also a null set. The professor gave a hint: ""any open subset in $\mathbb R^n$ can be exhuasted from inside by a finite union of closed boxes."" This statement is of course false, as a finite union of closed sets is closed. Could the teacher have meant countable? That would help immensely to prove what I want to prove. It's obviously true for an uncountable union of closed boxes, but what about countable? Is this true? If so, why?","['elementary-set-theory', 'general-topology', 'calculus']"
2743275,"A non-zero ring $R$ is a field if and only if for any non-zero ring $S$, any ring homomorphism from $R$ to $S$ is injective.","Show that a non-zero ring $R$ is a field if and only if for any non-zero ring $S$, any unital ring homomorphism from $R$ to $S$ is injective. I would like to verify my proof, especially the reverse implication. $\Rightarrow$ Let $S$ be any ring, and $f:R\rightarrow S$ be a ring homomorphism. If $x\in \ker f$ where $x$ is non-zero, then $0= f(x)f(x^{-1}) = f(xx^{-1})=f(1) = 1$ contradiction. Thus $x=0$, so $f$ is injective. $\Leftarrow$ Since any ring homomorphism is injective, the only ideals of $R$ are $\{0\}$ and $R$. Thus $R$ is a field.","['abstract-algebra', 'ring-theory', 'proof-verification']"
2743293,Conformal map from two disks to the unit disc,"Find a conformal equivalence f from $U$ onto $ D = \{ z : |z| < 1 \} $, where $U=\{z: |z+1|<2\}\cup \{z: |z-1|<2\}.$ How to find such a map $f$? I think we need to map the two discs to two strips individually. I have no idea how to do this.",['complex-analysis']
2743313,Prove that the number of answers for $|a_1|+|a_2|+...+|a_k| \le n$ is equal to the number of answers for $|a_1|+|a_2|+...+|a_n| \le k$.,"I'm trying to solve this problem: Prove that the number of answers for $|a_1|+|a_2|+...+|a_k|≤n$ is equal to the number of answers for $|a_1|+|a_2|+...+|a_n|≤k$. all $a_i$ is an integer number. I have a solution for non negative $a_i$:
We convert $|a_1|+|a_2|+...+|a_k|≤n$ to $a_1+a_2+...+a_k+c=n$ and convert $|a_1|+|a_2|+...+|a_n|≤k$ to $a_1+a_2+...+a_n+c=k$. By bars and stars theorem:
Number of answers for $a_1+a_2+...+a_k+c=n$ is equal to $\binom{n+k}{k}$ and number of answers for $a_1+a_2+...+a_n+c=k$ is equal to $\binom{n+k}{n}$. That $\binom{n+k}{k} = \binom{n+k}{n}$. but i don't know how to prove for negative integers.","['diophantine-equations', 'combinatorics']"
2743332,Distributing $4$ different red balls and four different green balls to $4$ people,"Let $m$ denote the number of ways in which $4$ different balls of green colour and $4$ different balls of red colour can be distributed equally among $4$ persons if each person has balls of the same colour and $n$ be the corresponding figure when all the four persons have balls of different colours. Find $\frac{m+n}{132}$. I've tried it using distribution theorem $\dfrac{m}{132} = \dfrac{8!}{2!\cdot2!\cdot2!\cdot2!\cdot2^4}\cdot\dfrac{4!}{132}$
but while calculating $\dfrac{n}{132}$ I am getting answer in decimal. Please help me in this?","['permutations', 'combinatorics']"
2743346,"Finite sum $\sum_{k=1}^{p-1} \frac{1-\cos\left(\frac{2\pi k r}{p}\right)}{1-\cos\left(\frac{2\pi k s}{p}\right)}$ for $\gcd(p,rs)=1$.","I am wondering if there is a closed form to the following finite sum: $$\sum_{k=1}^{p-1} \frac{1-\cos\left(\frac{2\pi k r}{p}\right)}{1-\cos\left(\frac{2\pi k s}{p}\right)},$$ where $\gcd(p,rs)=1$ and $r,s,p$ are positive integers, and if so how would I go about figuring out the closed form? EDIT: I arrived at this sum as I am investigating the value of the $T_2$-norm of units in the cyclotomic ring $\mathbb{Z}(\zeta_{p})$ for prime $p$. The $T_2$-norm of an element $x \in K$ for some number field $K$ of degree $n$ is defined: $$
||x|| = \left(\sum_{i=1}^n |\sigma_i(x)|^2\right)^{1/2},
$$ where $\{\sigma_1, \dots, \sigma_n\}$ are the embeddings of $K$ and $|x|^2 = x\bar{x}$ where the bar represents complex conjugation. Lemma: For $\gcd{(rs,p)}=1$, $\frac{\zeta^r -1}{\zeta^s -1}$ is a unit of $\mathbb{Z}(\zeta_p)$. Proof: Let $r \equiv st \mod p$. Then $\frac{\zeta^r-1}{\zeta^s-1} = 1 + \zeta^s + \dots + \zeta^{s(t-1)} \in \mathbb{Z}(\zeta_p)$, and its inverse is also in $\mathbb{Z}(\zeta_p)$ by the same logic. So for unit $u$ of the aforementioned form, we have: $$
|u|^2 = \frac{\zeta^r-1}{\zeta^s-1} \frac{\zeta^{-r}-1}{\zeta^{-s}-1} = \frac{2-(\zeta^r + \zeta^{-r})}{2-(\zeta^{s} + \zeta^{-s})} = \frac{1-\cos(\frac{2\pi r}{p})}{1-\cos(\frac{2\pi s}{p})}.
$$ Since $\sigma_k(\zeta_p) = \zeta_p^k$, we have: $$
||u||^2 = \sum_{k=1}^{p-1} \frac{1-\cos(\frac{2\pi k r}{p})}{1-\cos(\frac{2\pi k s}{p})}.
$$","['number-theory', 'real-analysis', 'summation', 'trigonometry']"
2743359,Is this property of a sequence of random probabilities well-known?,"Let $(\Omega, \mathcal{F}, (\mathcal{F}_n)_n, P)$ be a probability space equipped with a filtration, and let $(P_n)_n$ be a sequence of random probabilities adapted to $(\mathcal{F}_n)_n$. By that I mean that $P_n: \mathcal{F} \times \Omega \to [0,1]$ is a probability measure on $(\Omega, \mathcal{F})$ in its first argument and a $\mathcal{F}_n$-measurable random variable in its second argument. Assume that $P_1(A, \omega) = P(A)$. I'm wondering if the following property is well-known and if it has any interesting consequences: For all $n$, all $m > n$, ($P$-almost) all $\omega \in \Omega$, and all $A \in \mathcal{F}$, 
  $$P_n(A, \omega) = \int P_m(A, \omega')P_n(d\omega', \omega).$$ It seems plausible to me, for instance, that this property could guarantee that $(P_n(A))_n$ has an almost sure limit for every $A$, but I haven't been able to prove it yet. Mainly, I'm just wondering if this property has been studied, and if so, what a good reference is.","['reference-request', 'probability-theory', 'measure-theory', 'random-variables']"
2743360,Improving clarity and argumentation with hard-to-describe combinatorial proof,"I'm doing undergraduate research and the content of my paper depends on the following lemma. I tried something like a combinatorial proof, but it is clearly not rigorous, partly because my argument is hard to describe. How can I improve my proof? Lemma. Let $p_i$ give the $i$th prime. Then the number of ways we can uniquely distribute $k_1$ [color-one] balls, $k_2$ [color-two] balls, $k_3$ [color-three] balls, ... $k_f$ [color-$f$] balls into $n$ indistinguishable boxes is equal to the number of ways to factor $$\prod_{i=1}^f p_i^{k_i}$$ into $n$ distinct factors. Before we begin our proof, we start with a demonstration. Suppose we sought to uniquely distribute 2 blue balls and 1 red ball into 3 indistinguishable boxes. We'd have the following distributions (each distribution has its own row): $$[\color{blue}{* *}\color{red}{*}] \, \, \, []\, \, \,[] $$ $$[\color{blue}{* *}] \, \, \, [\color{red} *] \, \, \, []$$ $$[\color{blue} *] \, \, \, [\color{blue} * \color{red} *] \, \, \,  []$$ $$[\color{blue} *] \, \, \, [ \color{blue} * ] \, \, \, [ \color{red} *]$$ Now suppose we sought to generate unique factorizations of $12=2^2 \cdot 3^1$ into $3$ factors. We'd have the following factorizations (each factorization has its own row, and blanks spaces represent multiplications by $1$): $$\color{blue}{2 \cdot 2} \cdot \color{red} 3 *  \, \, \, * $$ $$\color{blue}{2 \cdot 2} * \color{red} 3 * \, \, \,$$ $$\color{blue} 2 * \color{blue} 2 \cdot \color{red} 3 * $$ $$\color{blue} 2 * \color{blue} 2 *  \color{red} 3$$ Note that the number of factorizations we have is the same as the number of distributions. Our factorization process is identical to the distribution process, except we replace blue balls with $2$s, replace red balls with $3$s, and consider groups of balls as products of factors. We generalize this observation below. Proof. Consider a ball distribution for some $k_1, k_2, ..., k_f$. Recall that within each box, the order of the balls does not matter. Likewise, in a product of primes, a clear ""order"" of its factors does not exist. In each box, balls of the same color are indistinguishable. Likewise, in a product of primes, repeats of the same factor are not distinguishable (as a consequence of the previous remark about prime products). Furthermore, in each box, balls are immutable; they cannot be broken up into more balls, and so each group of balls is unique. Likewise, as each ""ball"" (i.e. factor) in each group of factors is prime, no factor group can be broken up into an syntactically different factor group, and so each group of separated factors (e.g. $2^1, 2^1 \cdot 3^1, \emptyset$) are separated factors in the third row in the example above) is unique. Lastly, the order of groups between each of the boxes does not matter. Likewise, the order of each of the separated factors does not matter, as a clear ""order"" of its factors does not exist. Therefore, each color of balls can be replaced by a specific prime number, and the product of these prime numbers is $\prod_{i=1}^f p_i^{k_i}$, which we seek to separate into $n$ separated factor groups, i.e. $n$ distinct factors. If there's a way to prove this that isn't explicitly combinatorial, I would appreciate that as well, especially if it is simpler.","['proof-verification', 'number-theory', 'proof-writing', 'combinatorics', 'prime-numbers']"
2743366,$f(x+1/2)+f(x-1/2)= f(x)$ Then the period of $f(x)$ is?,$f(x+1/2)+f(x-1/2)= f(x)$. Then the period of $f(x)$ is: a)$1$ b)$2$ c)$3$ d)$4$? Attempt: I substituted $x= x \pm1/2$ but the equations I got didn't help at all. How do I go about solving such a question? I am just looking for a hint and not the entire solution.,['functions']
2743378,What is the intuition behind a ((final - midterm)^2)/(100-midterm) grade bonus?,"In my course ( https://www.cs.bgu.ac.il/~ppl182/Guidelines ) we have a grading policy in which you can gain a bonus to your final grade if you improve your grade between the midterm exam and the final exam. The formula for the bonus $b$ is
$$b = \frac{0.1(f - m)^2}{100 - m},$$ where $f$ is the final exam and $m$ is the midterm. I've noticed very similar bonus calculations in other courses. My question is: what is the intuition behind this formula? It seems to have some clear internal idea behind it, but I can't figure out what it is. PS The general grade formula for the course is = 0.60*(final exam grade) +  0.20*(midterm grade) + 0.20*(assignments grade) + bonus",['functions']
2743383,properties of the multiplication operator on $L^2$,"Let $H=L^2([0,1],\lambda)$, where $\lambda$ is the Lebesgue measure on $[0,1]$. 
Let $f\in C([0,1])$ and consider the multiplication operator $M_f\colon H\to H$, $M_f(g)=fg$. Let $f,g\in C([0,1])$ such that $M_f=M_g$. I want to show that $f=g$. It is:
$M_f=M_g$ $\iff$ $fh=gh$ for  all $h\in H$ $\iff$ (f-g)h=0 for all $h\in H$ $\iff$ $M_{f-g}(h)=0$ for all $h\in H$. How to proceed without knowing that $M$ is isometric? Let $M_f$ be invertible as a linear bounded operator on $H$. I want to show that $f(x)\neq 0$ for all $x\in [0,1]$. I started as follows: Assume that there exists an $x\in [0,1]$ such that $f(x)=0$. For $n\in\mathbb{N}$ consider the nonempty set $S_n=\{y\in [0,1]: |f(y)|<\frac{1}{n} \}$, and thus the nonzero characteristic funtion $\chi_{S_n}\in H$ regarding $S_n$. It is $$\|M_f(\chi_{S_n})\|_H=\|f\chi_{S_n}\|_h\le ||f_{|S_n}\|_{\infty}\|\chi_{S_n}\|_H\le \frac{1}{n}\|\chi_{S_n}\|_H.$$
Can I conclude that $M_f$ is not invertible from here and if yes, how? Thank you","['functional-analysis', 'analysis']"
2743427,Chi Square Contingency Table - Formula Derivation,"A chi-square distribution is constructed from normal random variables $X_{i=1, \dots ,n}$ , each with normal distribution and mean $\mu$ and variance $\sigma^2$ .  Transforming to standard normal and squaring, i.e.: $$\frac{(X_i - \bar{X})^2}{\operatorname{Var}(X_i)}\sim N(0,1)^2$$ Then add these over all your $n$ random variables, then you get $\chi^2_{n-1}$ - a chi-square with $n-1$ degrees of freedom. For contingency tables, suppose there are $k$ categories of observations $O_i, i = 1, \ldots , k,$ each with probability $p_i$ . The statistic
we’re proposing, assuming $O_i \sim \operatorname{Normal}$ , is: $$\frac{(O_i-np_i)^2}{\operatorname{Var}(O_i)} \sim N(0,1)^2$$ The variance of each observation is $np_i(1-p_i)$ For contingency tables, a test to see if the underlying mean is the same across categories, the standard equation taught for calculating the Chi-Square statistic is: $$\sum_{i=1}^k\frac{(O_i-np_i)^2}{np_i} \sim \chi^2_{n-1}$$ So, where in the equation for assessing contingency tables does the term $(1-p_i)$ disappear to?","['independence', 'statistics', 'chi-squared', 'actuarial-science']"
2743439,Number of possible sequences,"Let $(a_1,...,a_{10})$ be a sequence with $a_i \in \{1,...,10\}$ and the following properties: $i)$ $a_1\in\{1,...,10\}$ $ii)$ $a_i\neq a_j \ \forall i,j\in \{1,...,10\}$ with $i\neq j$ $iii)$ $a_i\in \{a_1\pm 1,...,a_{i-1}\pm1\}\cap\{1,...,10\} \quad \forall i\in \{2,...,10\}$ How many sequences with these properties exist? Is it possible to generalize this for any $n$ instead of $10$ ? I tried looking at the different cases for starting values: For $a_1=\{1,10\}$ there is only one possible sequence each. For $a_1=\{2,9\}$ there are 9 possible seuqences each, because you have 9 possibilities for $1$ or $10$ and the rest of the sequences is clear. But for $a_i=\{3,4,5,6,7\}$ I don't know how to go one with that way of thinking. Can someone give me a hint?","['combinatorics', 'sequences-and-series']"
2743440,Prove that $\lim_{x\rightarrow 0}\frac{f(x^2)-f(0)}{x}=0$ if $f:\mathbb{R}\rightarrow\mathbb{R}$ is differentiable at $x=0$,"Let the function $f:\mathbb{R}\rightarrow\mathbb{R}$ be differentiable at $x=0$. Prove that $\lim_{x\rightarrow 0}\frac{f(x^2)-f(0)}{x}=0$. The result is pretty obvious to me but I am having a difficult time arguing it precise enough for a proof. What I have so far is of course that since $f$ is differentiable;
$$f'(0)=\lim_{x\rightarrow 0}\frac{f(x)-f(0)}{x}$$
exists. Any help would be greatly appreciated.","['derivatives', 'real-analysis', 'limits']"
2743467,Why care distribution functions more than random variables?,"This may be wrong, but I have often heard some saying "" we mainly care about CDFs"". Similarly, in textbooks, one sees $X \sim N(0,1)$, without any reference to sample space. But why - and how do we justify this? My thoughts: with my limited knowledge in probability, two results: Any distribution function $F:\mathbb{R} \rightarrow [0,1]$, yields a Lebesgue-Stiltjes measure $\mu_F$. Considering the space $(\mathbb{R}, B_{\mathbb{R}}, \mu_F)$ with randon variable $X$ being identity, we obtain, 
  $$P(X \le t ) = \mu((-\infty, t]) = F(t)$$ This implies it is sufficient in specifying cdf $F$, and say there exists a RV, $X$ with cdf $F$. (Skorokhod's construction, in Williams) Let $F: \mathbb{R} \rightarrow [0,1]$ be a cdf. $U\sim U[0,1]$. 
  $$ X^-:= \sup \{ y \in \mathbb{R} \,: \, F(y) < U \} $$
  is a RV on $[0,1]$ with same distribution as $F$. I believe there is also a generalization to joint variables. But these results are not satisfying, I don't see how they are canonical .","['big-picture', 'probability-theory', 'soft-question', 'probability-distributions']"
2743545,Baffled with $\lim\limits_{x\to 0}{e^x-e^{\sin x} \over x-\sin x}$ [duplicate],"This question already has answers here : Limit: $\lim\limits_{x\to0}\frac{e^x-e^{\sin x}}{x-\sin x}$ (5 answers) Closed 6 years ago . Calculate $$\lim\limits_{x\to 0}{e^x-e^{\sin x} \over x-\sin x}$$ Personal work: $$\lim\limits_{x\to 0}{e^x-e^{\sin x} \over x-\sin x}=^{0 \over 0}\lim\limits_{x\to 0}{e^x-e^{\sin x}\cdot\cos x \over 1-\cos x}=^{0 \over 0}\lim\limits_{x\to 0}{{e^x-(e^{\sin x}\cdot\cos x-\sin x}\cdot e^{\sin x}\over \sin x})=\cdots$$ This gets to nowhere. Also, I substituted $t=e^{\sin x}$ but I could not replace the $e^x$.","['trigonometry', 'limits']"
2743558,What numbers are in the set $S$?,"Here is a problem that I came up with that has been bothering me for a while, and I haven't been able to solve it. Let $S$ be the set defined by the following rules: $2\in S$. Define the functions $\alpha$ and $\beta$ as
$$\alpha(n)=n^2$$
$$\beta(n)=\lfloor n/3\rfloor$$
If $n\in S$, then $\alpha(n)\in S$ and $\beta(n)\in S$. If the previous two rules do not imply that a number $n$ is in $S$, then $n\notin S$. QUESTION: What numbers are in $S$? So far, I've verified that every positive integer from $1$ to $14$ is in $S$, since I've found ""composition sequences"" of $\alpha$ and $\beta$ that, when applied to $2$, yield each of those numbers. For example,
$$3=(\beta^{\circ 4}\circ\alpha^{\circ 3})(2)$$
Things get a little crazy when I get to $n=6$:
$$6=(\beta^{\circ 10}\circ\alpha^{\circ 2}\circ \beta\circ\alpha^{\circ 2})(2)$$
...and even crazier at $n=14$:
$$14=(\beta^{\circ 3}\circ \alpha\circ \beta^{\circ 10}\circ \alpha^{\circ 2}\circ \beta\circ \alpha\circ \beta^{\circ 10}\circ \alpha^{\circ 2}\circ\beta^{\circ 2}\circ \alpha^{\circ 3})(2)$$ Any ideas how to prove (or disprove) that any positive integer can be reached? NOTE: It is true that all positive integers are in $S$ if (not iff) the following is true: Blockquote
  For any positive integer $N$, there exist positive integers $a,b$ such that
  $$N=\bigg\lfloor \frac{2^{2^a}}{3^b}\bigg\rfloor$$ If someone figures out how to prove this, then we're done... if it's false, then there remains some work to be done.","['number-theory', 'function-and-relation-composition']"
2743639,Why does a simple permutational approach doesn't work for this combinatorics problem?,"Let's say I have 10 apples, 8 oranges and 7 bananas. I want to know in how many ways I can spread them over four distinct boxes. So my approach would be to immediately consider this as an anagram permutation problem: AAAAAAAAAA|OOOOOOOO|BBBB|BBB The above example would give us 10 apples on the first box, 8 oranges on the second box, 4 bananas on the third box, and then 3 bananas on the fourth box. So the solution would be simply $$\frac{( 10 + 8 + 7 + 3)!}{10! * 8! * 7! * 3!} = \frac{28!}{10! * 8! * 7! * 3!}$$ However my teacher told me this leads to a wrong conclusion, although he didn't explain me why. Then he went on to show me the right way to do this. So I'd like to know not what would be the right way to solve this ( as I already know it ) but why my proposed solution doesn't work.","['permutations', 'combinatorics']"
2743687,Inverse map preserving positivity with Haar measure?,"It is known that homeomorphisms in general do not preserve null sets. However, I am wondering about the case where $G$ is a locally compact group with haar measure $\mu$ and the homeomorphism in question is the inverse map. Is the following true for a borel subset $A$? $$ 0<\mu (A)<\infty \Longleftrightarrow 0<\mu (A^{-1})<\infty $$","['locally-compact-groups', 'group-theory', 'haar-measure']"
2743691,Huisken's monotonicity formula,"In mean curvature flow there is an important tool, namely the Huisken's monotonicity formula: For a solution of the mean curvature flow $F: M^n \times [0,T) \rightarrow \mathbb{R}^m$ we have
$$ \frac{d}{dt} \int_{M} \rho \: d \mu_t   =  - \int_{M} \left| H + \frac{\langle x, \nu \rangle}{2(T-t)} \right|^2 \rho \: d \mu_t, $$
where
$$ \rho(x,t) =\frac{1}{(4\pi(T-t))^{\frac{n}{2}}} e^{-\frac{|x|^2}{4 (T-t)}}. $$
However in the literature of mean curvature flow I can find many statements of the formula where they all assume different conditions: Can the codimension of the solution, i.e. $m-n$ be bigger than $1$? Does $M$ have to be compact? If not, does $M$ have to be complete? Does $M$ have to be orientable? ... In every proof I have seen it seems that the codimension does not play a role and that it may be arbitrary. For the second: I know that Stoke's Theorem is used to show the monotonicity formula in many proofs and that for this we need orientability and compactness. However none of the references did explicitly require the orientability? The Stoke's theorem is used in the form:
$$ \int_M \Delta \rho=0. $$
Is there any need to introduce the Hausdorff measure for a rigorous statement? EDIT: To make my question a little bit more precise: The question would be completely solved if someone can state (and maybe reference) a statement which allows noncompact manifolds in any codimension but possibly with additional assumptions: does $M$ have to be complete or orientable, does $F$ have to be an embedding,...? To give some specific references in the literature: Huisken proved the statement when $M$ is compact and in the codimension $1$ case in the paper Asymptotic behavior for singularities of the mean curvature flow ,
  J. Differential Geometry, 31 (1990) 285-299. Later K. Ecker wrote a book where he proved a generalization to the noncompact case but where the integral of $\rho$ has to exist over $M$ (this is clearly natural), however in the beginning of the book he states that throughout the book he works in the case where $F$ is at each time a hypersurface which seems not to be necessary.","['geometric-measure-theory', 'mean-curvature-flows', 'riemannian-geometry', 'differential-geometry']"
2743703,Angular rates components order from time-derivative of rotation matrix,"I'm currently confused at the moment about the components order obtained from a well-known relationship between derivative of a rotation matrix and its angular velocity: $\dot{R} = R \hat{\Omega}$. I constructed the rotation matrix $R$ from consecutive rotations around $Z,Y,X$ axis using the formulae given in https://en.wikipedia.org/wiki/Euler_angles . So is it true that the $\Omega$ vector (whose skew-symmetric form is $\hat{\Omega}$) will be $[\omega_z,\omega_y,\omega_x]^T$? Moreover, if $R$ is a rotation matrix from frame $B$ to frame $A$, is $\Omega$ angular rate written with respect to frame  $B$? I'd very grateful to hear from you. Thanks in advance.","['rotations', 'control-theory', 'classical-mechanics', 'differential-geometry']"
2743712,How to find all irreducible elements in $\mathbb{Z}[\sqrt{2}]$,"I am trying to find all irreducible elements in $\mathbb{Z}[\sqrt{2}]$. So, all the elements of the form $(2bd+ac)+(bc+ad)\sqrt{2}$ such that either $(a+b\sqrt{2})$ or $(c+d\sqrt{2})$ is a unit. I know all the units in this ring 
( $U(\mathbb{Z}[\sqrt{2}]) = \{(1+\sqrt{2})^n | n \in \mathbb{N}\}$). So I suppose one thing I can do is just plug in a unit I know (e.g. $(1+\sqrt{2})$ or $(3+2\sqrt{2})$ and just know that any element of the form $(4d+3c+(2c+3d)\sqrt{2})$ where $c,d$ are integers is an irreducible (as long as it is not a unit itself, and of course we would get rid of all the ones that were associates of each other). Seems quite long-winded and inefficient, though. I'm still not seeing a pattern though for how I can find all the irreducible elements. Can someone help?","['abstract-algebra', 'ring-theory']"
2743729,Intuitive reason why contour integral around origin of $z^n$ is 0 unless n = -1,"The contour integral of an analytic function around a point is determined entirely by the $\frac{1}{z}$ term in a function's Laurent series. In particular, $\int_{\gamma} z^n dz = \begin{cases} 
      2 \pi i & n = -1 \\
      0       & n \ne -1 
   \end{cases}
$ Where $\gamma$ is any contour wrapping once around the origin. I understand how to do the calculation and derive this result, but as this result is important to complex analysis I want to understand it better. Is there an intuitive reason why this is true? For example, $z^{-3}$ and $z^{-1}$ qualitatively look similar, so why do the integrals turn out qualitatively differently? Or to ask differently, why does $z^n$ not have an antiderivative when $n = -1$","['complex-analysis', 'contour-integration', 'residue-calculus']"
2743774,Definition of a derivative,"This may seem like a very stupid question but I know the definition of a derivative is $f'(x) = \lim_{h \rightarrow 0} \frac{f(x+h)-f(x)}{h}$, is an equivalent definition of the derivative: $f'(x) = \lim_{h \rightarrow 0} \frac{f(x+h/2)-f(x-h/2)}{h}$? If I draw a graph, it appears to me that they should be the same, but how can I show it algebraically?","['derivatives', 'definition', 'calculus', 'limits']"
2743827,Why is $\frac{\sinh(t)+i}{\cosh(t)}$ an arc-length parametrization of the circle,"This came up on page 40 of Hubbard's Teichmuller Theory (Vol 1), in the context of parametrizing geodesics in the upper half. Where it is essentially implied that 
$$\frac{\sinh(t)+i}{\cosh(t)}$$
is an arc-length parametrization of the unit circle. This is my first time seeing such a parametrization and I was wondering there was a (preferably visual or geometric) way to see this.","['hyperbolic-geometry', 'differential-geometry']"
2743867,General formula of $\sum_{n\ge1}{\binom{2n}{n}^{-k}}$.,"If $k=1$, we have
\begin{align}
\sum_{n\ge1}\frac{1}{\binom{2n}{n}}&=\frac12\sum_{n\ge1}n\mathrm{B}(n,n)\\
&=\frac12\int _{0}^{1}\sum_{n\ge1}n(t-t^2)^{{n-1}}{\mathrm  d}t\\
&=\frac12\int _{0}^{1}\frac{1}{(t-t^2-1)^2}{\mathrm  d}t\\
&=\frac13+\frac{2\sqrt3\pi}{27}
\end{align}
I wonder if there exists a general formula of $\sum_{n\ge1}{\binom{2n}{n}^{-k}}$ with $k\in\Bbb N^*$. This may involve some ${}_pF_q$ functions.","['real-analysis', 'binomial-coefficients', 'sequences-and-series', 'hypergeometric-function']"
2743889,Finding number fields with certain decomposition group?,"I have no reason to expect this to be true, but I thought it wouldn't hurt to ask. For a Galois number field $K/\mathbb{Q}$, and a rational prime $(p)$ with a prime $\mathfrak{q}_i\subseteq\mathcal{O}_K$ lying above it, the decomposition group is defined as:
$$
D = D_{\mathfrak{q}_i\mid p} = \{\sigma\in\text{Gal}(K/\mathbb{Q})\mid \sigma(\mathfrak{q}_i) = \mathfrak{q}_i\}
$$
This is just the stabilizer of the action of $\text{Gal}(K/\mathbb{Q})$ on the prime ideals lying above $p$. Is there anything known about, given a particular group $D$, which pairs of $(K,p)$ have this group as a decomposition group? I'm interested in the case of $D = \mathbb{Z}/2\mathbb{Z}$ specifically, which may be simple enough that something about it is known.","['number-theory', 'galois-theory', 'algebraic-number-theory']"
2743922,Eigenvalues of a symmetric matrix with blocks that are diagonal matrices,"I have the following symmetric matrix of the form (had trouble finding out if there was a name for this kind of special structure):
$$A = \begin{bmatrix}
   X & Y \\ Y & X
\end{bmatrix}$$ where $X$ and $Y$ $\in \mathbb{R}^{n \times n}$ and diagonal. How can I find the eigenvalues?","['matrices', 'eigenvalues-eigenvectors', 'numerical-linear-algebra', 'linear-algebra']"
2743936,A combinatorial proof of Wilson's theorem [Proof Verification],"I am trying to prove the non-trivial assertion of Wilson's theorem, If $p$ is a prime, $p$ divides $(p-1)! - (p-1)$. I'm going to consider the set of $p$-cycles on $\mathbb{S}(\mathbb{Z}_p)$, which I'll denote $C_p$. Now, $C_p$ has size $(p-1)!$ for the following reason: it suffices to choose the images of $1,,...,p$ without repeating values or having fixed points, therefore we have $p-1$ options for the image of $1$, $p-2$ for the image of $2$, and so on until we get to the image of $p$, which is at this point already determined. Now, let's observe that if $a \in \mathbb{Z}_p^{\times}$, the translation given by summing $a$, $$
\tau_a : \mathbb{Z}_p \rightarrow \mathbb{Z}_p
\\ x \ \mapsto a + x 
$$ is an element of $C_p$ with inverse $\tau_{-a}$. We can then define the set $X_p = C_p - \{\tau_a : a \in \mathbb{Z}_p^{\times}\}$ with $|X| = (p-1)! - (p-1)$, and the following equivalence relation on $X_p$: $$
f \sim g \iff f = \tau_{-a}\cdot g\cdot \tau_a, \ \text{ for some } a \in \mathbb{Z}_p
$$ If we can conclude that each equivalence class on $X_p/\sim$ has size $p$, this will imply that $p \ | \ |X_p| = (p-1)! - (p-1)$ as we claim. It is clear that if $f \in \mathbb{S}(\mathbb{Z}_p)$, $$
[f] \subseteq \{\tau_{-a}\cdot f\cdot \tau_a : a \in \mathbb{Z}_p\}
$$ To finish, it will be sufficient to see the other inclusion, that is, that for any $a$ in $\mathbb{Z}_p$ the element $\tau_{-a}\cdot f\cdot \tau_a$ is not a translation and therefore is in $X_p$ (the fact that $\tau_{-a}\cdot f\cdot \tau_a \sim f$ is immediate). Let's suppose that, on the contrary, there exists $b \in \mathbb{Z}_p^{\times}$ such that $$
\tau_{-a}\cdot f\cdot \tau_a \equiv \tau_b
$$ and therefore $$
f \equiv \tau_a\cdot \tau_b \cdot \tau_{-a} \equiv \tau_b
$$ since translation commute. We've reached then a contradiction, since $f$ cannot be a translation, so in effect each class is as previously described and has size $p$, which concludes the proof. Is this correct? I'd also appreciate any suggestions to simplify the argument. Thanks in advance! Edit: I've noticed that it is also necessary to see that the set $\{\tau_{-a}\cdot f\cdot \tau_a : a \in \mathbb{Z}_p\}$ has in fact $p$ distinct elements. Any ideas?","['combinatorics', 'proof-writing', 'proof-verification', 'elementary-number-theory']"
2743947,$\phi (n) = n \prod (1-1/p)$,"Is there a way to prove that $$\phi (n) = n \prod_p\left(1-\frac{1}{p}\right)$$ using group theory? For example, using the fact that $$\left|\left(\frac{\mathbb{Z}}{n\mathbb{Z}}\right)^* \right| = \phi(n) $$","['abstract-algebra', 'group-theory']"
2743966,Probability of a coin stack being greater than a value? What's wrong with my reasoning?,"Basic probability question. Consider a pile of 9 coins where each could either be 1 cent or 10
  cents and the distribution of the coin combinations is uniform.
  Knowing that the upper 4 coins are all 10 cents, what is the
  probability that the total value is greater than 50 cents? My reasoning was simply that we have 5 coins leftover and we needs at least 10 more cents to get to 50 cents. We have a total of $2^5$ combinations for the remaining 5 coins. Our sample space size is $2^5-1$ because the only way which wouldn't work out is if we get all pennies. So the probability should be $\frac{2^5-1}{2^5}$ What's wrong here?",['probability']
2743987,Control over bump function's second derivative,"The usual constructions of bump functions supported on an interval $[a,b]$ are based on the non-analytic function $f(x) = e^{\frac{1}{(x-a)(x-b)}}$. However, the $n$-th order derivatives of these functions are very high (in fact, they grow exponentially with $n$). I wonder if one can control some of the derivatives (at the expense, for example, of the other ones). In my application, I'd like to construct the following function: Question: Is it possible to construct a bump function $\phi: \mathbb{R}
 \rightarrow \mathbb{R}$ which satisfies: $$ \phi(x)  = \begin{cases} x^2 \,\,\,, |x| \leq 1\\ 0\,\,\,, |x|\geq
 2\\ \end{cases} $$ and  $$ \phi''(x) \leq 2 \,\,\, \forall x \in [1,2] ? $$ To give some context, this function is useful in the so-called virial-like identities in Nonlinear Dispersive PDE's. If $u_0 \in H^1\left(\mathbb{R}^N\right)$ is such that $|\cdot |u_0 \in L^2\left(\mathbb{R}^N\right)$, the solution $u(x,t)$ of the equation:
$$
\begin{cases}
\partial_t u + \Delta u + |u|^{p-1}u = 0\\
u(x,0) = u_0(x)
\end{cases}
$$ Also satisfies $u(\cdot,t) \in H^1\left(\mathbb{R}^N\right)$ and $|\cdot|u(\cdot,t) \in L^2\left(\mathbb{R}^N\right)$ for all t in the existence time of the solution. Moreover, we have the inequality:
$$
\frac{d^2}{dt^2} \int |x|^2 |u(x,t)|^2 dx \leq C E[u_0]
$$ which allows us to prove blow-up in some cases. However, if one drops the decay assumption, the term $|x|^2$ in the integral must be replaced for some compactly supported function. I'd like to use the function $\phi$ above, and the bound on the second derivative would be useful on controlling some error terms. The obvious try, that is multipliyng $|x|^2$ by a function constant (and equal to 1) in some neighborhood of the origin and constant (and equal to 0) away from the origin doesn't seem to work.","['functional-analysis', 'real-analysis', 'partial-differential-equations']"
2743992,"Is there a pattern in the sequence $l_1,l_2,l_3,\ldots$?","Wilson's theorem asserts the following statement: $$(n-1)!\equiv -1\pmod n\Leftrightarrow n\text{ is prime.}\tag1$$ This means that $$\begin{align} n&{ \ \mid} \ \ (n-1)!+1 \\ \Leftrightarrow n&{ \ \mid} \ \ (n-1)!+1-n \\
 &=(n-1)!-(n-1) \\ &= (n-1)\big((n-2)!-1\big) \\ \therefore n&{ \ \mid} \ \ (n-2)!-1 \\ \Leftrightarrow (n-2)!&\equiv 1\pmod n.\tag2\end{align}$$ Or, in the congruence, I could add $n$ to the right hand side, and then divide both sides by $n-1$, yeilding the same result. I then asked myself, why wouldn't Wilson's theorem assert that $$(n-2)!\equiv 1\pmod n\Leftrightarrow n\text{ is prime,}$$ as opposed to $(1)$ ? It is more useful because $(n-2)! < (n-1)!$, so we can test this theorem with more primes without the factorial becoming too large as fast in $(1)$, and it is still just as interesting. However, I went here and found that it really is not that necessary to simplify the theorem. Now, I have been trying to find some similar result for $(n-3)!$, and I found that $$(n-3)!\equiv \frac{n-1}{2}\pmod n\Leftrightarrow n\text{ is prime $> 2$.}$$ Main Question: If for some $k\in\mathbb{Z^+}$ and remainder $l_k\in\mathbb{Z}$, $$(n-k)!\equiv l_k\pmod n,\tag{$n$ is prime}$$ is there a pattern in the sequence $l_1, l_2, l_3,\ldots$? Do there exist similar congruences for $(n-k)!$ such that $k > 3$? Thank you in advance. This post was inspired by this post .","['divisibility', 'number-theory', 'prime-numbers', 'modular-arithmetic', 'elementary-number-theory']"
2744008,Laurent series for $f(z)=\frac{1}{\sin z}$,"Since the isolated singularities are $z=k\pi, k \in \mathbb Z$, so we divided the complex plane into the disjoint annulus, i.e. $\{z: n\pi <|z|<(n+1)\pi\}, n \in \mathbb N \cup \{0\}$. On these annuli, $f$ is analytic, so has a unique Laurent series. First, let's consider $\{z: 0 < |z|<\pi\}$, then the solution says
$$\begin{aligned}
f(z)& =\frac{1}{\sin z}\\
& =\frac{1}{z-\frac{z^3}{3!}+\frac{z^5}{5!}-\cdots}\\
& =\frac{1}{z}\cdot \frac{1}{1-\left(\frac{z^2}{3!}-\frac{z^4}{5!}+\cdots\right)}\\
& =\frac{1}{z}\left[1+\left(\frac{z^2}{3!}-\frac{z^4}{5!}+\cdots\right)+\left(\frac{z^2}{3!}-\frac{z^4}{5!}+\cdots\right)^2+\cdots\right]
\end{aligned}$$
My questions are: Do we need $\left|\frac{z^2}{3!}-\frac{z^4}{5!}+\cdots\right|<1$ to get the last step? If we do, then why it is less than 1? Thanks for any help!","['laurent-series', 'complex-analysis']"
2744178,How to calculate sum over set of vectors $\sum\limits_{\vec q\in E}f(\vec q)$?,"Summation over integers is easy, since there are many rules that we can follow. For example,$$
\sum\limits_{i=1}^ni=\frac{n(n+1)}{2}.
$$
A summation can also be taken over a set of vector of integers $E\subset\mathbb{Z}_+^N$ as $\sum\limits_{\vec q\in E}f(\vec q)$. An example when $N=3$:\begin{align*}
\sum_{|\vec q|\le 2}|\vec q|&=|(0,0,0)|+|(1,0,0)|+|(0,1,0)|+|(0,0,1)|\\
&\quad +|(1,1,0)|+|(2,0,0)|+|(0,1,1)|+|(0,0,2)|+|(1,0,1)|+|(0,2,0)|=15.\end{align*} However this is much harder to find a close form, as here is an example from an algorithm that iterates on a set of vectors. Let $\vec q=(q_1,q_2,\cdots,q_N)\in\mathbb{Z}_+^N\cup\{(0,\cdots,0)\}$. What is a close form of $$\sum_{\{\vec q:|\vec q|\le M\}}|\vec q|\sum_{n=0}^M\sum_{\{\vec l:0\le\vec l\le\vec q,|\vec l|\ge n\}}1$$ in terms of $M$, $N$? Here $\vec l\le\vec q$ means every entry of $\vec l$ is less than or equal to that of $\vec q$. If an exact closed form is difficult, then a tight upper-bound or approximation is acceptable. If bounds are difficult, then only consider when $M<<N$ is acceptable. If we replace $\{\vec l:0\le\vec l\le\vec q\}$ by $\{\vec l:0\le|\vec l|\le|\vec q|\}$, then by a stars-and-bars argument above is approximately $$\sum_{|\vec q|=0}^M\begin{pmatrix}|\vec q|+N\cr N\end{pmatrix}|\vec q|\sum_{n=0}^M\sum_{|\vec l|=n}^{|\vec q|}\begin{pmatrix}|\vec l|+N\cr N\end{pmatrix}=\sum_{m=0}^M\begin{pmatrix}m+N\cr N\end{pmatrix}m\sum_{n=0}^M\sum_{k=n}^m\begin{pmatrix}k+N\cr N\end{pmatrix}$$ First, how to then get a closed form of this? Second, this is not a very good approximation because eventually it is hard to express$$
\sum_{n=0}^M\sum_{\{\vec l:0\le\vec l\le\vec q,|\vec l|\ge n\}}1$$
as a function of $|\vec q|$ instead of $\vec q$. A more precise calculation yields $$\sum_{\{\vec q:|\vec q|\le M\}}|\vec q|\sum_{n=1}^M \left[\prod_{i=1}^Nq_i-\begin{pmatrix}N+n\cr N\end{pmatrix}\right].$$ Can anyone give a close form of this?","['combinatorics', 'summation', 'discrete-mathematics']"
2744206,Is the “distance to boundary” function smooth in a neighborhood?,"Let $M$ be a connected Riemannian manifold with boundary. We define the “distance to boundary” function $d(p)=d(p,\partial M)$, i.e. the infimum of lengths of (piecewise) smooth paths connecting $p$ with some point in $\partial M$. Does there always exist a neighborhood $U$ of $\partial M$, so that $d$ is smooth in $U$? This is not true if we replace $\partial M$ by an arbitrary subset $A$, e.g. consider $A=\text{point}$.","['riemannian-geometry', 'differential-geometry', 'differential-topology']"
2744230,"3 red, 3 blue and 3 green beads are arranged in a circle. What is the probability that each bead has at least one neighboring bead of other color?","All possible arrangements of the beads in the circle are 9!.
If we start from a specific bead to which we assign number 1 (starting point), then the number of possible arrangements of the 3 different colors is 
$\binom{9}{3}\binom{6}{3}\binom{3}{3} = \frac{9!}{3!3!3!}$ It seems to me that it is impossible for ALL beads to have neighboring beads of the same color - am I missing something?",['combinatorics']
2744258,Bus arrival probability...,"This question has two parts, Question one A municipal bus system, when operating perfectly on time, provide at any given bus stop every 30 min. A person arrive at a random time at bus stop. What is the average waiting time until the next bus arrives? The Answer Since buses are following uniform distribution the average waiting time will be 15 min. Question two If the busses become totally disorganized and random following Poisson random process what will be the average waiting time given that number of buses remains content I know the answer is 1/lambda, but how to find the lambda, is it still 15 min since the same number of busses are running. Can someone explain this to me!!! Thanks","['descriptive-statistics', 'statistics', 'probability']"
2744280,Relations between distance function and gradient on a Riemannian manifold (II),"As I mentioned in this question( Relations between distance function and gradient on a Riemannian manifold ), there's question says $d(x,y) = \sup \{f(x)-f(y):f \in C^{\infty}(M)$, with $\|\nabla f\| \leq 1\}$. @Frieder Jäckel says he had a solution to the non-trivial part of the inequation, but too long to post it in a comment. So I am to ask it again it this question.","['riemannian-geometry', 'differential-geometry']"
2744299,Construct a meromorphic function on Riemann surface of genus $3$,"I am working on the following questions: Let $X$ be a compact Riemann surface of genus $3$ with two points $p\neq q$ . Find a non-constant meromorphic function on $X$ with at least a double zero at $p$ and holomorphic everywhere except possibly at $q$ . What is the smallest possible pole under at $q$ we need to accept in order to guarantee the existence of such a function? and Construct an example of a Riemann surface of genus $3$ that has a holomorphic $1$ -form with a zero of order $1$ at a point $p$ , and zero of order $3$ at a different point $q$ . My attempt: The second part of the first problem is easy. I think it is just some simple application of Riemann-Roch theorem. But I am desperate to construct something on Riemann surface. Could anyone show me how to do this?","['riemann-surfaces', 'complex-analysis', 'divisors-algebraic-geometry']"
2744423,Finite measure fundamental domain for a discrete group implies it's a lattice,"Here $G$ is a locally compact second countable topological group with left haar measure $\mu$, and $\varGamma$ is a discrete subgroup with a borel subset $\varOmega \subseteq G$ s.t.  $G=\biguplus_{\gamma\in\varGamma}\varOmega\gamma$. Claim: If $ \mu (\varOmega)<\infty $ then there exists a $G$ invariant finite non-trivial radon measure $\nu$ on $G/\varGamma$ Remarks on what I managed: My main issue is that it is NOT assumed that the ambient group is unimodular and infact we don't assume anything on the modular function. Ideally I would hope that $\nu(A)=\mu(\pi^{-1}(A)\cap\Omega)$ for borel $A\subseteq G/\varGamma$ is left invariant. If this measure $\nu$ is left invariant without assuming the condition on the modular function, then we're done. Is this the case? I did not manage to show this. [Though I did manage to show that it is true in case we know in addition that $\triangle_G|_\varGamma=1$. But I cannot assume this.] In general, homogeneous spaces do not necessarily admit an invariant measure, and in our case they will admit a semi invariant measure with character $\triangle_G$ by some famous criterion. But since the fundamental domain is finite measure , then I would like to believe that it will have an invariant one, and many documents claim this without proof. Extra failed attempt: In the original claim, I have also managed to show that $\nu(A)=\lambda(\pi^{-1}(A)\cap\Omega)$ where $\lambda(B)=\mu(B^{-1}$) is a left semi-invariant measure, and that in this case $\nu (G/\varGamma)=\mu(\varOmega^{-1})$. If I knew $\mu(\varOmega^{-1})<\infty$ then the semi-invariance is actually an invariance, because $\nu (G/\varGamma)=\nu (gG/\varGamma)=u(g)\nu (G/\varGamma)$ so $u=1$ and thus $\nu$ is left invariant. But that assumption may not be true, as inverse map in general  does not necessarily preserve finite measure sets.","['locally-compact-groups', 'group-actions', 'haar-measure', 'homogeneous-spaces', 'group-theory']"
2744471,Image of Borel set under continuous and injective map,"Let $f: \mathbb{R}^n \rightarrow \mathbb{R}^n$ a continuous and injective map. Let $A \subset \mathbb{R}^n$ a Borel set, i.e. $A \in \mathscr{B}(\mathbb{R}^n)$, where $\mathscr{B}(\mathbb{R}^n)$ denote the Borel $\sigma$- algebra. Show that the image of $A$ is also a Borel set, i.e. $f(A) \in \mathscr{B}(\mathbb{R}^n)$. My attempt: Let $A \subset \mathbb{R}^n$ a Borel set. Since $f$ is injective, then we have that $A = f^{-1}(f(A))$. NTS: $f(A)$ Borel set. We suppose by contradiction that $f(A)$ is not a Borel set, so $f(A)$ is not an open or a closed set. I'd like to find a contradiction using the continuity of $f$ but I don't see how. Any suggestions? Thanks!","['borel-sets', 'real-analysis', 'lebesgue-measure', 'measure-theory', 'analysis']"
2744497,What does Gradient actually mean?,"One day I was reading my physics book and suddenly I came across the word gradient . The following mathematical method is used in my book to determine gradient: $$\Omega(x,y,z)=3x\cdot(y^2)\cdot(z^3)-4xy$$ Now they determined the gradient in point (2,1,1) and it was $$ \nabla \Omega = 7i-20j+18k$$ Now what does it actually mean? I mean if we know that 20 N of net force is applied on a mass of 2 kg than it will have an acceleration of 10 $\rm m/s^2$. In my example, the gradient in point (2,1,1) is determined. What information can I get from that? The same is also for divergence and curl.","['derivatives', 'vector-fields', 'vectors']"
2744553,How can I evaluate this function numerically stable?,"I have a cross-entropy like function, that I want to evaluate. However, I encounter numerical instabilities due to overflows. I want to compute the cross-entropy of the following function: $$\sigma(p,q) = \frac{2}{1+e^{d}} \text{ with } d=||p-q||_2^2$$ To be specific, for $z$ in $\{0,1\}$: $$-z\log(\sigma(p,q))-(1-z)\log(1-\sigma(p,q))$$ I know that there are efficient ways to this for the standard sigmoid $$\sigma(x) = \frac{1}{(1+e^{-x})}$$ which is also described here : Doing it in a similar manner, I derived the following equivalent formula: $$z\log(\frac{1}{2}) + \log(1+e^d) + (z-1)\log(e^d-1))$$ How do I go on from here? There are problems for $d\approx0$ as well as $d>>0$.","['algebra-precalculus', 'numerical-methods', 'entropy']"
2744579,Soulé vanishing for $H^2$ of $\mathbb{Q}_p(n)$,"In his paper ""The motivic fundamental group of the projective line minus three points and the theorem of Siegel"", M. Kim uses the following result:
let $p$ be an odd prime, $T$ be a finite set of primes of $\mathbb{Z}$ that contains $p$, and let $\mathbb{Q}_T$ be the maximal extension of $\mathbb{Q}$ unramified outside $T$; finally, let $G_T$ be the absolute Galois group of $\mathbb{Q}_T$. Then
$$
H^1(G_T, \mathbb{Q}_p(2n))=0 \quad \forall n \geq 1 \quad \text{and}\quad \dim H^1(G_T, \mathbb{Q}_p(2n+1)) =1 \quad \forall n \geq 1.
$$
In Kim's lectures at the IHES (see http://www.ihes.fr/~abbes/CAGA/kim.html , lecture 3, around minute 55), he explains that the equalities above are proven by studying the Euler characteristic of the Galois module $\mathbb{Q}_p(n)$ and using the fact that $H^2(G_T, \mathbb{Q}_p(n))=0$ by ""Soulé vanishing"". The reference for this result given in Kim's paper is to Soulé's ""K-théorie des anneaux d'entiers de corps de nombres et cohomologie étale"" (Inventiones mathematicae (1979), volume 55, pp. 251-296); I've tried reading part of this paper, but unfortunately I don't know the first thing about K-theory, and I don't see how to extract the statement $H^2(G_T, \mathbb{Q}_p(n))=0$ from Soulé's results; more precisely, one of the main sources of my confusion is the fact that most of the theorems in Soulé's paper seem to only be stated for even $n$ (see for example his Théorème 6, part (iii), which gives a surjective morphism from $K_{2i-2}(A) \otimes \mathbb{Z}_\ell$ onto $H^2(\operatorname{Spec}A', \mathbb{Z}_\ell(i))$ only for $i$ even), while - if I understand correctly - Kim's proof needs the result for all values of $n$. It is more than likely that I've misunderstood something either in Kim's explanation or in Soulé's paper, and I would be more than grateful for any help with the matter.","['number-theory', 'etale-cohomology', 'algebraic-geometry']"
2744587,How to see the symmetry in this trigonometric equation,"Consider the equation $2\cos^2x-\cos x-1=0$. We can factor the LHS to obtain: $$(2\cos x + 1)(\cos x-1)=0,$$ leading to three solutions in the interval $[0,2\pi)$, namely $x=0, \frac{2\pi}{3}, \frac{4\pi}{3}$. If we want all solutions over $\Bbb R$, then we can add any multiple of $2\pi$ to each of these solutions. However, all solutions over $\Bbb R$ are more efficiently expressed as simply the integer multiples of $\frac{2\pi}{3}$. That kind of solution is what one would expect from a problem that started out with something like $\cos (3x)=1$. However, if we expand $\cos(3x)$ using sum formulas, that equation leads us to a different polynomial in $\cos(x)$, namely: $$(2\cos x+1)^2(\cos x-1)=0.$$ So, it's clear that both polynomials have the same roots, and that ""explains"" why the solution sets are the same. Great. My question : Is there a reasonable way to recognize the symmetry in the original equation, and transform it into an equation in $\cos(3x)$, other than just knowing ahead of time how it's going to work out?","['symmetry', 'trigonometry']"
2744589,How do I use rule induction to prove this relation?,"Suppose $T^*$ denotes the reflexive-transitive closure of some relation T on set $A$. For relations $R$ and $S$ on set $A$, prove that if $id_A \subseteq (R \cap S)$ then $(R \cup S)^* = (R \circ S)^*$. We are given the following inductive rules: $$\frac{(x,y) \in T}{(x,y)\in T^*} (x,y\in A)$$
$$\frac{}{(x,x)\in T^*} (x \in A)$$
$$\frac{(x,y)\in T^*\qquad (y,z)\in T^*}{(x,z)\in T^*}(x,y,z \in A)$$ My thoughts: The inductive rules seems to show the basic properties of transitivity and reflexivity. For the proof, I think we might need to show two things, essentialy $(R\cup S)^* \subseteq (R\circ S)^*$ and $(R\circ S)^* \subseteq (R\cup S)^*$ to show the equality, using the identity relation. Some stuff I've done: First we know $id_A \subseteq (R \cap S)$ $$\implies \forall a \in A . a (R \cap S) a$$ $$\implies \forall a \in A .  aRa \land aSa$$ But I'm stuck in transforming the intersection into the union as required, and since I start with the identity relation, I'm stuck with proving only reflexivity and not transitivity. Also, I'm unable to use the rule induction methods . ==== Edit: Is there a way to find a pure rule induction method to solve? i.e. something like this: Source: https://www.andrew.cmu.edu/user/annpenny/15317-f13/rule-induction.pdf The problem I've been facing is I can't seem to find a concrete way to use rule induction. I understand we can derive the rules in normal set theoretic form to try solve the problem, but is there a way to directly use the rule induction method? I've not been able to understand how the ""derivatives"" of rule induction works unfortunately (nevertheless there are great answers set out below).","['induction', 'logic', 'elementary-set-theory', 'proof-explanation']"
2744626,When sum of two Poisson variables is not Poisson,"If $X$ and $Y$ are independent Poisson random variables, then $X+Y$ is Poisson. We also know that sum of two dependent Poisson variables might result in another Poisson variable. My question is: what would be the counterexample (not the rigorous proof which might exist) that negates the claim that sum of two Poissons, irrespective of their dependency,  would always result in Poisson.","['probability', 'poisson-distribution']"
2744627,"Is this sequence convergent? If so, then how to find the limit? [duplicate]","This question already has answers here : Evaluation of the limit $\lim\limits_{n \to \infty } \frac1{\sqrt n}\left(1 + \frac1{\sqrt 2 }+\frac1{\sqrt 3 }+\cdots+\frac1{\sqrt n } \right)$ (8 answers) Closed 6 years ago . For each natural number $n$, let
$$ x_n \colon= \frac{1}{\sqrt{n}} \left( \frac{1}{\sqrt{1}}  + \frac{1}{\sqrt{2}}+ \cdots + \frac{1}{\sqrt{n}} \right). $$ Then is the sequence $\left( x_n \right)_{n \in \mathbb{N} }$ convergent? And if so, then how to find the limit of this sequence? I'm just not sure how to proceed.","['real-analysis', 'limits', 'sequences-and-series', 'convergence-divergence', 'analysis']"
2744639,Upper Derivative and Increasing Function on a Compact Interval,"Definition. For a real valued function $f$ and an interior point $x$ of its domain, the upper derivative of $f$ at $x$ denoted by $\overline{D}f(x)$ is defined as follows: $$\overline{D}f(x)=\lim_{h\rightarrow0}\left[ \sup \left \{\frac{f(x+t)-f(x)}{t}: 0<|t|\leq h \right \} \right]$$ I am working through Royden and Fitzpatrick's proof of the following lemma: Lemma. Let $f$ be an increasing function on the closed, bounded interval $[a,b]$ . Then for each $\alpha>0$ , $$m^*\{x\in (a,b) : \overline{D}f(x) \geq 
\alpha \} \leq \frac{1}{\alpha}[f(b)-f(a)].$$ Here is the relevant part of the proof giving me trouble. Let $\alpha>0$ . Define $E_{\alpha}:=\{x\in (a,b): \overline{D}f(x)\geq\alpha \}$ . Choose $\alpha' \in (0,\alpha)$ . Let $\mathscr{F}$ be the collection of closed, bounded intervals $[c,d]$ contained in $(a,b)$ for which $f(d)-f(c)\geq \alpha ' (d-c)$ . Since $\overline{D}f\geq \alpha$ on $E_{\alpha}$ , $\mathscr{F}$ is a Vitali covering for $E_{\alpha}$ . I realize that the questions am I about to pose have been asked here (indeed, I copied-&-pasted the relevant parts from that post), but астон вілла олоф мэллбэрг's answer is much too brief for my liking and the long string of comments, which appear to contain part of the answer to Kurome's question, are way to jumbled to get anything out of them. I have the same question as the OP in the link: why is $\scr{F} \neq \emptyset$ and why is $\scr{F}$ a Vitali covering of $E_\alpha$ . Specifically, I don't understand the implication $$t<\delta \implies\frac{f(x+t)-f(x)}{t}\geq\alpha'$$ holds (I tried unpacking the definition of the upper derivative, but I couldn't see it); nor do I understand how астон вілла олоф мэллбэрг is able to choose $d \in (a,b)$ such that $d-x < \delta$ . And why does does $[x,d]$ having a length less than $\delta$ imply $\scr{F}$ is a Vitali covering of $E_\alpha$ ? That $\delta$ wasn't arbitrary. For ease of references, here is астон вілла олоф мэллбэрг's answer: [астон вілла олоф мэллбэрг's answer]: Take any $x \in E_\alpha$ . Now, since $\overline{D}f(x)\geq\alpha$ , it follows that for some small $\delta$ , $t<\delta \implies\frac{f(x+t)-f(x)}{t}\geq\alpha'$ . (The definition for the upper derivative above is slightly wrong, I will edit it) Putting $t=d-x$ , this means that $t<\delta \implies f(d)-f(x) \geq \alpha'(d-x)$ . The interval $[d,x]$ is in $\mathscr{F}$ for every $d$ close enough to $x$ ,for arbitrary $x$ in $E_\alpha$ . This makes $\mathscr{F}$ a Vitali covering for $E_\alpha$ .","['real-analysis', 'measure-theory', 'proof-explanation']"
2744643,Strictly Increasing Integers,"Q: How many positive integers are there whose digits strictly increase from left to right? ($0$ is not allowed to be the leading digit) Here're my thoughts on the problem. For one digit numbers. There are only $9$ such integers that satisfy the problem. For two digit numbers. If we start with $1$ as the left most digit, then we have $8$ choices for the one's place. So we have $8$ such numbers. If we start with $2$ as the left most digit, then we have $7$ choices for the one's place. If we start with $3$ as the left most digit, then we have $6$ choices for the ones place. Continuing this process we have $8+7+6+ ... +2+1 = 36$ such numbers. But for three - digit numbers, I'm stuck. What am I suppose to do, after I've chosen the first digit? I'll have to make sub cases for the second digit, and it'll get more complicated as I go up to 9 - digit numbers. P.S. I know we have a question such as [ Number of strictly increasing and decreasing 4 digit numbers? ], but I don't quite get the hints ...",['combinatorics']
2744669,Doubts in the design of a mechanism,"I am doing a little study of the question found in the Engineering mechanics Dynamics book. I tried to define the position of the point P on the $\mathbf{x}$ and $\mathbf{y}$ axes with respect to the point 0 using the circle equation . $x^2+y^2=r^2 \Rightarrow y=\sqrt{r^2-x^2}$ Using this relationship I have tried to relate the ratio between $\theta$ and $x$. $tan(\theta)=\frac{x}{y} \Rightarrow \theta(x)=arctan(\frac{x}{r^2-x^2})$ I made the derivative of this function to obtain a relation between the velocity of x and the angular velocity $\frac{d(arctan(\frac{x}{r^2-x^2}))}{dx}=\frac{1}{\sqrt{r^2-x^2}}$ Therefore: $\theta(\dot{x})=\frac{1}{\sqrt{r^2-x^2}}$ I made the derivative of this function to obtain relation between the acceleration of x with the angular acceleration $\frac{d(\frac{1}{\sqrt{r^2-x^2}})}{dx}=\frac{x}{(r^2-x^2)^\frac{3}{2}}$ Therefore: $\theta(\ddot{x})=\frac{x}{(r^2-x^2)^\frac{3}{2}}$ The question is this: With these two functions found, can I get the answer to the image question or am I in the wrong way? I have this doubt ...",['functions']
2744671,"Is it true that $\lim_{n\to\infty}\sum_{i=1}^nx_{i,n}=\sum_{i=1}^\infty x_{i,\infty}$?","Suppose that $\{x_{i,n}:1\le i\le n,n\ge1\}$ is a real-valued triangular array such that the limit $\lim_{n\to\infty}\sum_{i=1}^nx_{i,n}$ exists and $x_{i,n}\to x_{i,\infty}$ for each $i\ge1$ as $n\to\infty$. Is it true that
  $
\lim_{n\to\infty}\sum_{i=1}^nx_{i,n}=\sum_{i=1}^\infty x_{i,\infty}?
$
  If not, when can we say that it is true? It is quite easy to construct an example where this is the case (for instance, $x_{i,n}=a_ia_n$, where $\sum_{i=1}^\infty a_i$ converges and $\lim_{n\to\infty} a_n$ exists). I do not think that this is always the case even though I am struggling to construct a counterexample. It seems that we might be able to use the dominated convergence theorem, but we actually have just one limit and I do not think that the dominated convergence theorem is applicable in this situation. Any help is much appreciated!","['sequences-and-series', 'convergence-divergence', 'limits']"
2744679,"Solve nonlinear ODE's System $x_1'(t)=-x_1(t)x_3(t)$, $x_2'(t)=-x_2(t)x_3(t)$, $x_3'(t)=x_1^2(t)+x_2^2(t)$","I need to study the flow generated by the vector field $X(x,y,z)=(-xz,-yz,x^2+y^2)$. Therefore, I need to solve the system: $$ \left\{  \begin{array}{ccc}  x_1'(t)&=&-x_1(t)x_3(t)\\
x_2'(t) &=& -x_2(t)x_3(t)\\
x_3'(t) &=&x_1^2(t)+x_2^2(t)
\end{array}\right. $$ I don't know how to solve this. I would appretiate any reference or help to solve this kind of equations.","['ordinary-differential-equations', 'dynamical-systems']"
2744731,Strong Stationary Time of a Markov Chain,"Definitions. Let $X_0, X_1, X_2, \ldots$ be a Markov chain on a finite state space $\Omega$ . Assume the Markov chain is irreducible and aperiodic.
So there is a unique stationary distribution $\pi$ . An $\mathbb N$ valued random variable $T$ is called a stopping time if the event $T=t$ depends only on $X_0, \ldots, X_t$ (I guess this formally means that $T=t$ is measurable in the $\sigma$ -algebra generated by $X_0, \ldots, X_t$ ). A stopping time $T$ is called a strong stationary time (SST) if $$P[X_t=x|T=t]= \pi(x)$$ for all $x\in \Omega$ . Let $p^{(t)}_x(y)$ denote the probability that $X_t=y$ if the chain starts at $x$ , that is, if $P[X_0=x]=1$ .
We write $\Delta_x(t)$ to denote the total variation distance between $p^{(t)}_x$ and $\pi$ . Questions. Let $T$ be a strong stationary time.
In this document, Claim 4.2 states that $$\Delta_x(t)\leq P[T>t|\ X_0=x]$$ and the author says that this should be intuitively reasonable. I am quite stumped. Can somebody elaborate on as to what is the intuitive reason to expect this. In fact, I do not have much in the way of intuition regarding the very concept of SST. Next, in the proof of Claim 4.2 on Pg 4, a line reads ""... we denote by $T_x$ the SST for the chain started at state $x$ ..."" I am not sure what is the meaning of this. Does this mean that for each $x$ there is associated a (unique) SST?","['intuition', 'markov-chains', 'probability-theory']"
2744787,"Why can't a parameterization $c(t) = ( x(t), y(t) )$ describe a 2-dimensional surface in the plane?","Consider a parameterization 
$$c(t) = (x(t), y(t)) $$ For every $t$, you have some $(x,y)$ output. This will be some curve in the plane. My textbook seems to imply that only a single parameter is needed for a curve because curves are 1-dimensional. Now consider a parametrization $$ g(u,v) = (x(u,v), y(u,v))$$
For every $(u,v)$ you have some $(x,y)$ output. This will be some surface in the plane. My textbook seems to imply that 2 parameters are needed for a surface because surfaces are 2-dimensional. So my question is, does a single parameter always result in a curve? Why can't the curve fold up on itself to form a 2-dimensional surface in the plane? And if we go beyond the plane, why can't a parameterization $c(t)$ give you a surface in 3-space (adding in a $z(t)$)or a volume in 3-space? If I just scribble my pen on a sheet of paper, I create a bunch of lines. But couldn't my scribbling form a surface if it was fine enough? I feel like this is getting into the ""philosophy of continuous mathematics."" Limits, continuous number lines, and whatnot as opposed to ""discrete mathematics"". Likewise, why can't $g(u,v)$ describe a volume? Does a single parameter always give a curve, 2 a surface, and 3 a volume?","['multivariable-calculus', 'curves', 'surfaces']"
2744795,Proof of Inversion formula for characteristic function,"I have a question about the proof to the inversion formula for characteristic function. The Theorem is stated as following: $\lim_{T\rightarrow\infty}\frac{1}{2\pi}\int_{-T}^T \frac{e^{-ita} - e^{-itb}}{it}\phi(t)dt = \mathbb{P}(a,b) + \frac{1}{2}\mathbb{P}(\{a,b\})$, where $\phi_{X}(t)$ is the characteristic function of a random variable. In the proof of Chung in his book ""A course in probability theory"" on page 162 there is the following identity: \begin{align} 
\int_{-T}^{T}\frac{e^{-ita} - e^{-itb}}{2\pi it}e^{itx}dt &= \int_{-T}^{T}\frac{e^{it(x - a)} - e^{it(x-b)}}{2 \pi it}dt \\
&= \frac{1}{\pi}\int_{0}^{T}\frac{\sin(t(x-a))}{t}dt - \frac{1}{\pi}\int_{0}^{T}\frac{\sin(t(x-b))}{t}dt
\end{align} I don't know how to show this. My attempt is the following:
  \begin{align} \frac{e^{-ita} - e^{-itb}}{it}e^{itx} &= \frac{e^{it(x - a)} - e^{it(x-b)}}{it}\\&=\frac{-i\left(e^{it(x - a)} - e^{it(x-b)}\right)}{t}\\ &=\frac{\sin(t(x-a)) - \sin(t(x-b)) + i\left(\cos(t(x-b)) - \cos(t(x-a))  \right)}{t}. \end{align} Has anyone an idea?","['complex-analysis', 'probability-theory', 'characteristic-functions', 'calculus']"
2744829,Short way for upper triangularization,"We are given a matrix $$A = 
\begin{bmatrix}
3 & 0 & 1 \\
-1 & 4 & -3 \\
-1 & 0 & 5 \\
\end{bmatrix}$$
  and we are asked to find a matrix $P$ such that $P^{-1}AP$ is upper triangular. Here, we first find one eigenvalue as $\lambda= 4$. Then the matrix $$
A-4I = 
\begin{bmatrix}
-1 & 0 & 1 \\
-1 & 0 & -3 \\
-1 & 0 & 1 \\
\end{bmatrix}$$
has basis formed from $f_1 = (-1,-1,-1)^T$, $f_2 = (1,-3,1)^T$. We extend this to a basis of the whole space by adjoining $f_3 = (1,0,0)^T$, and so we have base-change matrix
$$ P = 
\begin{bmatrix}
-1 & 1 & 1 \\
-1 & -3 & 0 \\
-1 & 1 & 0 \\
\end{bmatrix}.$$ Then, by using some computational tools, we find that
$$ P^{-1}AP = 
\begin{bmatrix}
3 & 1 & 1 \\
-1 & 5 & 0 \\
0 & 0 & 4 \\
\end{bmatrix}$$ Now, we need to look at $$B = \begin{bmatrix}
3 & 1 \\
-1 & 5 \\
\end{bmatrix},$$ which has eigenvalue $\lambda = 4$. So we have $$B-4I = \begin{bmatrix}
-1 & 1 \\
-1 & 1 \\
\end{bmatrix}.$$
So basis for the image of this is $(1,1)^T$. We extend this to the basis $(1,1)^T$, $(1,0)^T$ of $\mathbb{R}^2$. Now, going back to $\mathbb{R}^3$, we have the matrix $$Q = \begin{bmatrix}
1 & 1 & 0 \\
1 & 0 & 0 \\
0 & 0 & 1 \\
\end{bmatrix}.$$ Then, by using calculation tools, we get
$$Q^{-1}P^{-1}APQ = \begin{bmatrix}
4 & -1 & 0 \\
0 & 4 & 1 \\
0 & 0 & 4 \\
\end{bmatrix},$$
which is in upper triangular form. Now, what I wanted to ask is that is there a way to directly find the matrix $R = PQ$ such that $R^{-1}AR$ is upper triangular, without going through these steps?","['eigenvalues-eigenvectors', 'matrices', 'matrix-decomposition', 'triangularization', 'linear-algebra']"
2744869,Question about the binomial distribution,"$X$ is a random variable with binomial distribution parameters $n$ and $p_1$. $Y$ is a random variable with binomial distribution parameters $n$ and $p_2$. $p_1 < p_2$ How can I show that $P(X \leqslant k) \geqslant P(Y \leqslant k)$? Please just give me a hint. I tried comparing the terms ${n \choose k}p_1^k(1-p_1)^{n-k}$, but this doesn't work (after trying this, it's obvious in hindsight that it doesn't work.","['probability', 'probability-distributions']"
2744879,Jacobi triple product comes from the Weyl Character formula?,"From the Weyl character formula says that the irreducible representation of Lie algebra $\mathfrak{g}$ with highest weight $\lambda$ has character
$$\frac{1}{\prod(e^{\alpha/2}-e^{-\alpha/2})}\sum_{w\in W} (-1)^w e^{w(\lambda+\rho)}$$
where the product is over the positive roots and $\rho$ is half of the sum of the positive roots. The trivial (!) representation with $\mathfrak{g}=\mathfrak{sl}_n$ is the Vandermonde identity 
$$\det \begin{pmatrix}
x_1&x_2&\cdots&x_n\\
x_1^2&x_2^2&\cdots&x_n^2\\
\vdots&\vdots&&\vdots\\
x_1^n&x_2^n&\cdots&x_n^n
\end{pmatrix}=\prod_{i<j}(x_j-x_i)$$ $$\text{}$$
I've heard* that the Jacobi Triple product identity
$$\prod \left( 1 - x^{2n}\right) \left( 1 + x^{2n-1} y^2\right) \left( 1 +x^{2n-1}y^{-2}\right)
\ = \ \sum x^{n^2} y^{2n}$$
is a trivial-representation case of a `Kac-Moody' version of the Weyl character formula. If this is true, what does this general character formula say, and what other classical identities like this does it imply? Is there geometric/representation theoretic content to these results? $$\text{}$$
$$\text{}$$
*In page 221 of 'Moonshine, Beyond the Monster'' (which gives the Kac-Moody character formula, but not its relation to such identities).","['representation-theory', 'sequences-and-series', 'lie-algebras']"
2744899,Chromatic number of complement of cycle graph,"What is the chromatic number of the complement of the cycle graph , $\chi(\overline{C_n})$?","['combinatorics', 'graph-theory', 'coloring']"
2744978,Representations and Vector Bundles over the Classifying Space,"I'm merely trying to understand the following statement I came across while reading. The text doesn't provide a reference or a recap of the construction that explains this fact. I'm adequately versed in the definitions of representation, Lie group, and vector bundle, so probably I don't understand the classifying space $BG$ sufficiently well to know how this would work. If anyone could elucidate I would be grateful.","['characteristic-classes', 'representation-theory', 'algebraic-topology', 'vector-bundles', 'differential-geometry']"
2744981,Spectrum of isometry,"Let $X$ be a Banach space. Let $T\in \mathbb{B}(X)$. If $T$ is an
  isometry and not invertible, prove that $\sigma(T) = \overline{\mathbb{D}}$. I can show that $\sigma(T) \subset \overline{\mathbb{D}}$. Since $T$ is not invertible, then $0 \in \sigma(T)$. Suppose $\sigma(T) \neq \overline{\mathbb{D}}$, then we can find $|\lambda|<1$ on the boundry of the spectrum, $\partial \sigma(T)$. Then $\lambda \in \sigma_{ap}(T)$. How can I go from here to a contradiction?","['functional-analysis', 'spectral-theory', 'operator-theory']"
2744985,Show $2+\alpha$ is a primitive root of $\mathbb{F}_{25}$.,"Suppose $\alpha \in \mathbb{F}_{25}$ is an element with $\alpha^2 = 2$, I need to prove that $2+\alpha  \in \mathbb{F}_{25}$ is a primitive root (that is: a generator of the cyclic group $\mathbb{F}_{25}^\ast$ of order 24). So far, I have tried the following. 
Since $\mathbb{F}_{25} = \mathbb{F}_{5^2}$, consider $f = X^2+X+2 \in \mathbb{F}_5[X]$. This is irreducible since it has no roots in $\mathbb{F}_5$. Furthermore we have
$$
f(2+\alpha) = (2+\alpha)^2+(2+\alpha)+2 = \alpha^2 + 4\alpha + 4 + 2 + \alpha + 2 
= \alpha^2 + 3 = 5 = 0. 
$$
So it follows that $f$ is the minimum polynomial of $2+\alpha \in \mathbb{F}_{25}$, hence
$$
\mathbb{F}_{5}(2+\alpha) \cong \mathbb{F}_5[X]/(X^2+X+2) \cong \mathbb{F}_{25}. 
$$
How to proceed from here though?","['finite-fields', 'abstract-algebra', 'field-theory', 'primitive-roots']"
2744987,Existence of solution for ODE,"The Question: Consider the inhomogeneous ODE $$y''(x)+y(x)=f(x) \; \; \; \; \; \; y(0)=0 \;,\;y(\pi)=1 \; \; \; \; \; \; 0<x<\pi$$ Give a condition on $f$ such that a solution exists My Thoughts: I get how if, for example, $f(x) = 0$ then the general solution is $y(x)=A\cos (x)+B\sin (x)$ so then no solutions exist. By the Fredholm Alternative Theorem, the homogeneous adjoint problem $$w''(x)+w(x)=0 \; \; \; \; \; \; w(0)=0 \;,\;w(\pi)=0 \; \; \; \; \; \; 0<x<\pi$$ has non-trivial solutions (namely $w(x)=C\sin (x)$), so that the original problem either has no solutions or non-unique solutions. How should I proceed?",['ordinary-differential-equations']
2745016,"Support of $f + g$ lies in the union of supports of $f, g$.","Let $X$ be a topological space and $f, g : X \to \Bbb{C}$ be two continuous, compactly-supported, complex-valued functions on $X$. Support of $f$ is the closure of the set $\{x \in X : f(x) \neq 0\}$.  Similarly for $g$.  These are assumed to be compact sets. I'm trying to prove that $C_c(X)$ the space of continuous, complex-valued, compactly-supported functions on $X$ is a vector space. Rudin's ""Real & Complex Analysis"" book says that $\text{Support}(f + g) \subset \text{Support}(f) \cup \text{Support}(g) = $ union of two compact sets = compact set. $$
\text{Support}(f + g) = \overline{\{ x \in X : f(x) \neq - g(x)\}}
$$ I'm not seeing how this lies in that union.","['complex-analysis', 'general-topology', 'compactness', 'vector-spaces']"
2745029,Why Does the Characteristic Equation of a Differential Equation Depend on the Solution?,"I have learnt about the characteristic equations of differential equations (D.E.) only informally and recently observed that the way they are defined seems to depend not only on the equation, but on the solution / eigenfunctions. e.g. compare the following: First , a 2nd order constant coefficient D.E. $$ay'' + by' + cy = 0,$$ with characteristic polynomial $p(D) = aD^2 + bD + C$ (which we can find by taking the ansatz $y = e^{\lambda x}$ and substituting into the D.E.).$\\[5pt]$ Second , a 2nd order Cauchy-Euler D.E. $$x^2 \, y'' + \alpha \, x \, y' + \beta\, y = 0,$$ with characteristic polynomial $f(D) = D^2 +(\alpha-1)D + \beta$, which we can find by taking the ansatz $y = x^r$ and substituting into the D.E.). Clearly the characteristic polynomial in each case would be different if we started with a different ansatz , which leads me to suspect that my informal understanding is missing an important point in how these polynomials are defined. Can anyone clarify the situation, please? I suspect this is an issue with definitions, but am curious to know if the bigger picture might lend greater insight into D.E.","['characteristics', 'ordinary-differential-equations', 'eigenfunctions', 'definition']"
2745093,What is minimum speed needed to jump over sphere object that has radius R and at distance d?,"(I am not expert in English. I will write as well as I can.) To understand this question easier, lets see this picture. From this picture, what is minimum initial speed that this grasshopper need to jump over this log? The grasshopper movement path can touch the log but can't cross through inside of the log. d and R can be any positive real number which d>R. g is a gravitational acceleration(approximately 9.80665 $m/s^2$). This is a mathematical-physics question but mainly in maths. I can do physics part but have problem in maths part. Physics Part : Let red ball is grasshopper and at origin point and y is height The relation between x and y for projectile motion is $y(x) = xtan\theta - \frac{gx^2}{2u^2cos^2\theta}$ , $0 < \theta < \frac{\pi}{2}$ Upper curve of sphere can de describe in function : $y_s(x) = R + \sqrt{R^2-(x-d)^2}$ , for $ d-R \leq x \leq d+R$ Condition of the sphere is $y(x) \geq y_s(x)$ , for $ d-R \leq x \leq d+R$ or $xtan\theta - \frac{gx^2}{2u^2cos^2\theta} \geq R + \sqrt{R^2-(x-d)^2}$ , for $ d-R \leq x \leq d+R$ At this point, I don't how to find $u_{min}(d,R)$ from this. (If you give value of d and h (for example, d = 2m and R = 1m), it is possible to find $\theta$ that minimize u.) I know only that y(x) (parabola curve) for $u_{min}(d,R)$ look like. Case : d = cR (c is a constant. There is a ratio that make y(x) have maximun point at the top of the sphere.) Case : d > cR Case : d < cR Please help me.","['trigonometry', 'calculus', 'multivariable-calculus', 'classical-mechanics', 'projectile-motion']"
2745150,Closed form for an integral $\int_{0}^{\infty} \frac{dx}{(1+x^2)(5-4\cos(2x))}$,"This integral was also posted recently on other sites like AoPS, but since it didnt get an answer I thought no one minds if I post this here too. $$I=\int_{0}^{\infty} \frac{dx}{(1+x^2)(5-4\cos(2x))}$$ I have no successful attempt that lead actually to something relevant, but I would love to see a closed form.","['integration', 'closed-form']"
2745240,Using Connectedness to Define Topology,"I have had this idea to define some kind of “topology” on the integers for graphical purposes. However, i do not know if this is approchable from the standard topological framework. The idea is to define “connectedness” by stating what subsets of the integers are connected.
Let $C$ be a collection of subsets in the integers that are stated to be connected. For every integer $i$ there exist a connected subset of the integers, and that is $\{i-1,i,i+1\}$ Is $C$ together with the integers is a topology? I am planing to use this concept for the topological study of computer graphics or pixelated visuals. I guess a better question would be Can declaring what subsets are connected be enough to define a unique topology?","['graph-theory', 'integers', 'algebraic-topology', 'general-topology', 'definition']"
2745243,"How to figure out if a function is Big O, Big Ω, or Big θ of x?","I'm working on my last Discrete Mathematics online question set at the moment, and I've finished everything except this one problem on Big O. Essentially, it gives me 5 functions, and I have to figure out if each one is O(x), Ω(x), or θ(x). While I (at least vaguely) understand what each term means, I've not been able to get it correct, and I've only been allotted 3 attempts, so I wanted to get a solid answer before I press submit for the last time. My understanding, graphically, is that if f(x) is always less than x after a certain point, then f(x) is O(x). If it's always more, than that would be Ω(x). If it's both above and below the function after the given point, though, then it's θ(x). Here are the five functions I must check: f(x) = 10, g(x) = 3x + 7, h(x) = x^2 + x + 1, j(x) = 5log(x), and k(x) = floor(x). As for my current answers, f(x) is both above and below x, so I said f(x) was θ(x). g(x) is both above and below, but since the question didn't specify I imagined it meant after x = 0, so I said g(x) was O(x). This is the same case for h(x). j(x) is always less than x, so I said j(x) was Ω(x), and k(x) was always less than or equal to as well, so I said it was Ω(x). Thank you for your help.","['computer-science', 'discrete-mathematics']"
2745246,Is this group the 4-permutation group?,"Recently I came along the set of $3\times 3$ matrices defined by taking any three vectors of (-1,-1,-1) or the three standard unit basis vectors as your columns. For example, one might take $$\left(\begin{array}{ccc}
-1 &-1& -1\\
1 &0 &0 \\
0& 1 &0
\end{array}\right),$$ or the identity. Both are of the sort I am interested in. More specifically, I suspect that there is an isomorphism between this set of matrices and the 4-permutation group, $S_4$. However, I am not sure how to prove this. Help, of course, would be appreciated.","['permutations', 'group-theory', 'linear-algebra', 'group-isomorphism']"
2745268,Line Intersection - Queries,"The initial setting consists of the Cartesian plane without any lines. After that we're are given $n$ queries of the form: $\bullet$ $k$ $b$ $+$ add the line with equation $y$ = $kx + b$ to the plane $\bullet$ $k$ $b$ $-$ remove the line with equation $y = kx + b$ from the plane $\bullet$ $?q$ find the number of lines $y= q$ that are currently on the plane at a point with an integer $x$ -coordinate All the aforementioned parameters are always integers. There can be up to $n = 10^5$ queries and $0 \leq b, q \leq 10^5$ . I've no idea how to come up with a solution that's better than $O(n^2)$ which is too slow. The key insight I've been able to extract up to this point is that in order for a line to satisfy the given constraints, the following must hold: $$q \equiv b \text{ (mod k)}$$ But this doesn't seem particularly useful, since I still have to go through all the lines I've encountered so far. Since this seems to be some kind of number theory, modulo arithmetic question, I figure there may be some solution of complexity $O(n\sqrt{n})$ , but I haven't been able to arrive at it no matter how much I played with the data.","['number-theory', 'algorithms', 'geometry']"
