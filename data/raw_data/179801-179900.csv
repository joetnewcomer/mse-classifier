question_id,title,body,tags
3268363,Is divergence theorem applicable for improper integrals?,"Consider the expression: $$\lim\limits_{\delta \to 0} \iiint_{V-\delta} \nabla \cdot \mathbf{F}(x,y,z)\ dV \tag1$$ where $\delta$ is a small volume inside volume $V$ Now can we apply the divergence theorem and write $(1)$ as: $$\iint_{\partial V} \mathbf{F}(x,y,z) \cdot \hat{n}\ dS
+\lim\limits_{\delta \to 0} \iint_{\partial \delta} \mathbf{F}(x,y,z) \cdot \hat{n}\ dS$$","['divergence-operator', 'improper-integrals', 'definite-integrals', 'multivariable-calculus', 'calculus']"
3268364,Expansion of the Mittag-Leffler function $E_{s}(x^{s})$,"I want to find an expansion of the Mittag-Leffler function $E_{s}(x^{s})$ of the form : $$E_{s}(x^{s})=\sum_{n=0}^{\infty}f_{n}(x)g_{n}(s)\;\;\;\;\;(\Im(x)=\Im(s)=0)$$ I first defind the function $\Omega(x,s)$ : $$\Omega(x,s)=sE_{s}(x^{s})-s-(e^{x}-1)=\sum_{n=1}^{\infty}\frac{x^{ns}}{n\Gamma(ns)}-\frac{x^{n}}{n!}$$ The reason for the introduction of the term $e^{x}-1$ is to extend the domain of convergence of the Laplace transform of $\Omega(x,s)$ , which is given by : $$\int_{0}^{\infty}\Omega(x,s)e^{-zx}dx=\frac{s}{z(z^{s}-1)}-\frac{1}{z(z-1)}$$ Applying the Bromwich inversion formula, we obtain : $$\Omega(x,s)=\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}\left[\frac{s}{z(z^{s}-1)}-\frac{1}{z(z-1)}
\right ]e^{zx}dz\;\;\;\;(c>0)$$ Making the change of variables $z=e^{y}$ , we obtain : $$\Omega(x,s)=\frac{1}{2\pi i }\int_{\Gamma}\left(\frac{s}{e^{sy}-1}-\frac{1}{e^{y}-1} \right )e^{xe^{y}}dy$$ Where the path $\Gamma$ is the map from $\Re(z)=c\;$ by the log function. 
Using the fact that : $$e^{x(e^{y}-1)}=\sum_{n=0}^{\infty}\frac{\phi_{n}(x)}{n!}y^{n}$$ $\phi_{n}(x)$ being the nth order Bell polynomial We obtain : $$\Omega(x,s)=\frac{1}{2\pi i }\sum_{n=0}^{\infty}\frac{e^{x}\phi_{n}(x)}{n!}\int_{\Gamma}\left(\frac{s}{e^{sy}-1}-\frac{1}{e^{y}-1} \right )y^{n}dy
$$ Now, i am a bit confused on how to do the integrals above. Any help is highly appreciated.","['complex-analysis', 'laplace-transform', 'inverse-laplace']"
3268430,Buoyancy Nonlinear second order differential equation,"Working on equations of motion of an expandable gaz-filled body immersed uderwater, I have reached the following equation : $$ \beta^{2} z'' - \alpha(z')^{2} + \beta z z'' - z = 0 $$ Could you give me some advices on how to find and analytical solution, if it exists ? If not, do we have one if we forget the drag, that is if : $$ \beta^{2} z'' + \beta z z'' - z = 0 $$ Ultimately, what is really of interest for me is not really the entire solutions, but rather stability around the solution $z=0$","['differential', 'ordinary-differential-equations']"
3268438,Formula for (total) chern classes in presence of a exact sequence with finite number of terms,"Suppose we have a connected smooth manifold $M$ . And a short exact sequence of complex vector bundles on $M$ . $$0 \rightarrow V_{1} \rightarrow … \rightarrow V_{n} \rightarrow 0 .$$ Then I recall that the product of $c(V_{i})$ for $i$ even is equal to product of $c(V_{i})$ for $i$ odd. However I can only find the reference for $n=3$ , i.e. short exact sequences. Does anyone know a reference for this? I flicked through Milnor Stasheff and didn't see it.","['algebraic-topology', 'reference-request', 'vector-bundles', 'algebraic-geometry', 'characteristic-classes']"
3268506,Compute $\oint_{|z|=r}z^2 \sin(\bar z)dz$,As mentioned above I am interested in the value of $$\oint_{|z|=r}z^2 \sin(\bar z)dz$$ where $r>0$ although I'm somewhat helpless at the moment. What I got so far: $$z^2 \sin(\bar z)=z^2 \sum_{n=0}^\infty(-1)^n\frac{(\bar z)^{2n+1}}{(2n+1)!}=|z|^2\overline{\sum_{n=0}^\infty(-1)^n\frac{z^{2n-1}}{(2n+1)!}}$$ and therefore we can write the integral as $$\overline{\sum_{n=0}^\infty\oint_{|z|=r}|z|^2(-1)^n\frac{z^{2n-1}}{(2n+1)!}dz}$$ but this seems to just make matters worse. Any good approach to this?,"['complex-analysis', 'contour-integration', 'complex-integration']"
3268535,Does the Riemannian metric induced by a diffeomorphism $F$ exist for a reason other than the existence of vector field pushforwards?,"My book is Connections, Curvature, and Characteristic Classes by Loring W. Tu (I'll call this Volume 3), a sequel to both Differential Forms in Algebraic Topology by Loring W. Tu and Raoul Bott (Volume 2) and An Introduction to Manifolds by Loring W. Tu (Volume 1). Definition 1.5 gives the definition for Riemannian metric and Riemannian manifold. Example 1.9 says If $F : N \to M$ is a diffeomorphism and $< , >$ is a Riemannian metric on $M$ , then (1.3) defines an induced Riemannian metric $< , >'$ on $N$ . Here $N$ and $M$ are smooth manifolds that hopefully have dimensions . Note that the $F_*$ here indeed refers to the differential $F_*,p: T_pN \to T_{F(p)}M$ defined in Volume 1 Section 8.2 and not the latter half $F_*: TN \to TM$ of the bundle map $(F, F_*)$ , where $F_*$ is what would be known as $\tilde{F}$ in Volume 1 Section 12.3 . The following is my proof of Example 1.9 . Question 1: Is this proof correct? Question 2: If this proof is correct , then is there a way to do this without relying on pushforwards from Volume 1 or without injectivity of $F$ ? I guess we can come up with a similar proof for an embedding, but embeddings are injective. So we'll have to go with investigating local diffeomorphisms, local diffeomorphisms onto image, immersions, etc. I'm asking because the Example 1.10 seems to do similarly to Example 1.9 though the $F$ in Example 1.10 is not injective. If this proof is incorrect , then why? Proof: Notation from Volume 1 Section 2.4 : For a smooth manifold $N$ , let $\mathfrak X (N)$ be the set of smooth vector fields on $N$ , and let $C^{\infty}N$ be the set of smooth functions on $N$ (not germs ). We must show that A. (Not interested in proving this part, but I'm stating what is to be proven for completeness) For all $p \in N$ , the mapping $\langle , \rangle'_p: (T_pN)^2 \to \mathbb R$ is an inner product on $T_pN$ , where $\langle , \rangle'_p$ is given as follows: Let $u,v \in T_pN$ . Then $F_{*,p}u, F_{*,p}v \in T_{F(p)}M$ . Let $\langle , \rangle_{F(p)}: (T_{F(p)}M)^2 \to \mathbb R$ be the inner product on $T_{F(p)}M$ given by the Riemannian metric $\langle , \rangle$ on $M$ , at the point $F(p) \in M$ . Then $(\langle , \rangle'_p)(u,v) = \langle u, v \rangle'_p = \langle F_{*,p}u, F_{*,p}v \rangle_{F(p)}$ . B. $\langle X,Y\rangle' \in C^{\infty}N$ for all $X,Y \in \mathfrak X (N)$ , where $\langle X,Y\rangle': N \to \mathbb R$ , $\langle X,Y \rangle'(p)=\langle X_p,Y_p\rangle'_p$ $=\langle F_{*,p}X_p,F_{*,p}Y_p\rangle_{F(p)}$ . To prove B: Let $X,Y \in \mathfrak X (N)$ . Then, by Volume 1 Example 14.15 , $F_{*}X$ and $F_{*}Y$ are defined vector fields on $M$ . Hopefully, $F_{*}X$ and $F_{*}Y$ are smooth, i.e. $F_{*}X,F_{*}Y \in \mathfrak X (M)$ . (I ask about this step here .) $\langle A, B \rangle \in C^{\infty} M$ for all $A,B \in \mathfrak X(M)$ , by definition of $\langle , \rangle$ for $M$ ( Definition 1.5 ). $\langle F_{*}X,F_{*}Y \rangle \in C^{\infty}M$ , from (2) and (3). $\langle X,Y\rangle' = \langle F_{*}X,F_{*}Y \rangle \circ F$ , i.e. $\langle X,Y\rangle'$ is the pullback by $F$ of $\langle F_{*}X,F_{*}Y \rangle$ $\langle X,Y\rangle' \in C^{\infty}N$ , by Volume 1 Proposition 6.9 , by (4) and by smoothness of $F$ .","['riemannian-geometry', 'vector-fields', 'geometry', 'linear-algebra', 'differential-geometry']"
3268542,Pushfoward of smooth vector field is smooth?,"My books are Connections, Curvature, and Characteristic Classes by Loring W. Tu (I'll call this Volume 3), Differential Forms in Algebraic Topology by Loring W. Tu and Raoul Bott (Volume 2) and An Introduction to Manifolds by Loring W. Tu (Volume 1). Let $F : N \to M$ be a diffeomorphism of manifolds that have dimensions . Let $X$ be a smooth vector field on $N$ . Then the pushforward $F_*X$ is a defined vector field on $M$ by Volume 1 Example 14.15 Is $F_*X: M \to TM$ smooth? This is a step of a proof in another question . I think $F_*X$ is smooth because: 1.1. Let $F_{*,p}: T_pN \to T_{F(p)}M$ be the differential of $F$ at $p$ , defined in Volume 1 Section 8.2 . 1.2. Let $F_*: TN \to TM$ be the map given by $F_*(X_p) = F_{*,p}(X_p)$ . I think $F_*$ is the same as what would be known as $\tilde{F}$ in Volume 1 Section 12.3 . 1.3. $F_*X: M \to TM$ is actually $F_*X: M \to N \to TN \to TM$ , $F_*X = F_* \circ X \circ F^{-1}$ 1.4. $F_*$ is smooth because $F_*$ is a smooth embedding by this because $F$ is a smooth embedding (Hopefully the definitions there are the same as in Volume 1 Definition 11.11 ). Note: We might say $F_*$ is smooth by some other route. I ask about the other routes here . Note: I'm not sure Volume 1 Section 12.3 explicitly says $F_*$ , also known as $\tilde{F}$ , is smooth. (I think this might be proved in Volume 2, but I actually stopped Volume 2 at Section 6, and I did not study Sections 1-6 in too much detail because I noticed Volume 2 is not really a prerequisite of Volume 3 and because I was hoping to learn more of vector bundles from Volume 3 before continuing Volume 2.) 1.5 Therefore, $F_*X$ is smooth by (1.3), (1.4), smoothness of $F^{-1}$ , smoothness of $X$ and Volume 1 Proposition 6.9 . What can $F$ alternatively be if not a diffeomorphism for $F_*X$ to be smooth? Some guide questions: 2.1. Must $F$ be injective (and smooth) for $F_*X$ to be defined in the first place? (Answer must be the opposite of the answer of 2.2, I think.) 2.2. Can $F$ be a local diffeomorphism (defined in Volume 1 Section 6.7 and further described in Volume 1 Remark 8.12 )? 2.2.1 Can $F$ be a local diffeomorphism onto its image ? (I guess that $F$ is a local diffeomorphism onto its image is defined as that $F$ with restricted range, $\tilde F: N \to F(N)$ is a local diffeomorphism. I actually don't know and haven't yet thought of the relationship between $F$ local diffeo and $F$ local diffeo onto image) 2.3. Can $F$ be a smooth embedding (defined in Volume 1 Definition 11.11 )? I think yes because we would still have that $F_*X$ defined by $F$ 's injectivity and that $F_*$ smooth by this . The problem might be the $F^{-1}$ , but I think that's not too difficult to fix. Update: Indeed not a difficult (maybe) fix. Just use $\tilde F ^{-1}$ for $\tilde F: N \to F(N)$ . The fix is complete when we show $\tilde F ^{-1}$ is smooth. This may be by your definition of smooth embedding (not difficult) or by a property of your definition of smooth embedding (difficulty depends on your understanding of the proof of the property).","['vector-fields', 'manifolds', 'general-topology', 'differential-topology', 'differential-geometry']"
3268544,Taylor polynomials respect derivatives,"I want to prove that the derivative of the $n$ th order Taylor polynomial is the $n-1$ th order Taylor polynomial of the derivative. More specifically: Suppose $f: \mathbb{R} \to \mathbb{R}$ is $n$ times differentiable about $x_0$ and $T_n(x)$ a polynomail of degree at most $n$ .
Then if $$
\lim_{x\to x_0}\frac{f(x) - T_n(x)}{(x-x_0)^n}
= 0
$$ then $$
\lim_{x\to x_0}\frac{f'(x) - T'_n(x)}{(x-x_0)^{n-1}}
= 0
$$ $\textbf{I am looking for a proof of this fact that is as direct as possible}$ . The fact looks like a simple corollary of l'hopitals rule. However I don't think this is legitimate since l'hopitals rule assumes that the limit $\frac{f'}{g'}$ exists, and this is what we are trying to prove. I think this property should be true by the following argument:
The hypothesis implies $T_n(x)$ is the $n$ th order Taylor polynomial of $f$ about $x_0$ .
Hence $$
T_n(x)
= \sum_{k=0}^n \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k.
$$ This implies $$T'_n(x) = \sum_{k=0}^{n-1} \frac{f^{(k+1)}(x_0)}{k!}(x-x_0)^k = \sum_{k=0}^{n-1} \frac{g^{(k)}(x_0)}{k!}(x-x_0)^k$$ where $g(x) = f'(x)$ . Hence $T'_n(x)$ is the $n-1$ th order Taylor polynomial of $g(x) = f'(x)$ . Again it is well known that this implies $$\lim_{x\to x_0}\frac{f'(x) - T'_n(x)}{(x-x_0)^{n-1}} = 0$$","['taylor-expansion', 'limits', 'calculus', 'polynomials']"
3268573,$dxdy=rdrd\theta$,"I'm trying to show that $dx\,dy=r\,dr\,d\theta$ using differentials. $x=r\cos(\theta)$ and $y=r\sin(\theta)$ thus $dx=\cos(\theta)dr-r\sin(\theta)d\theta$ and $dy=\sin(\theta)dr+r\cos(\theta)d\theta$ $\begin{align}dx\,dy&=(\cos(\theta)dr-r\sin(\theta)d\theta)(\sin(\theta)dr+r\cos(\theta)d\theta)\\&
=\cos(\theta)\sin(\theta)
dr^2+r\cos^2(\theta)drd\theta-r\sin^2(\theta)d\theta dr-r^2\cos(\theta)\sin(\theta)d\theta^2\\&=\cos(\theta)\sin(\theta)
dr^2-r^2\cos(\theta)\sin(\theta)d\theta^2+rdrd\theta(1-\sin(\theta)^2-\sin(\theta)^2)\end{align}$ If my calculations are correct, $\cos(\theta)\sin(\theta)
dr^2-r^2\cos(\theta)\sin(\theta)d\theta^2-2 \sin(\theta)^2rdrd\theta=0$ but how am I suppose to show that?","['multivariable-calculus', 'calculus', 'trigonometry']"
3268591,Strongest topology that makes vector space locally convex,"Here is an exercise from Barvinok's ""A Course in Convexity"" (ex. III.3.3.3, p.119): Prove that the strongest topology that makes a vector space $V$ a locally convex topological vector space is the topology where $U \subseteq V$ is open if and only if it is a union of convex algebraically open sets. Isn't the discrete topology (all sets are open) also turning $V$ into a locally convex TVS? Indeed, every singleton set $\{x\}$ is convex and open, the operations are continuous, and every singleton set is also closed. Am I missing something or is there a problem with the exercise? If the statement is wrong, then any clues as to what should be the correct statement?","['topological-vector-spaces', 'convex-analysis', 'functional-analysis']"
3268623,Is the differential between tangent bundles $F_*: TN \to TM$ smooth?,"Let $F: N \to M$ be a smooth map of smooth manifolds (with dimensions ). Let $F_{*,p}: T_pN \to T_{F(p)}M$ be the differential at $p \in N$ . Let $F_*: TN \to TM$ be the map between tangent bundles given by $F_*(X_p)=F_{*,p}(X_p)$ . This says $F_*$ is a smooth embedding if $F$ is a smooth embedding. What are some sufficient conditions to say $F_*$ is smooth besides $F$ being a smooth embedding? I'm not really interested in deducing $F_*$ to be a smooth embedding or topological embedding. I'm just hoping for smooth for 1.4 here . Some guide questions: If $F$ were smooth but not a smooth embedding, then is $F_*$ no longer necessarily smooth? What if $F$ were smooth and injective? What if $F$ were a smooth non-injective local diffeo? What if $F$ were a smooth non-injective immersion but not local diffeo? What if $F$ were a smooth injective immersion but not a topological embedding (My understanding is smooth embedding = smooth injective immersion + topological embedding)? I think each $F_{*,p}$ is smooth as a map of manifolds, besides linear as a map of vector spaces . What does this mean for $F_*$ ?","['diffeomorphism', 'geometry', 'smooth-manifolds', 'vector-bundles', 'differential-geometry']"
3268658,Sequence of positive integers $n$ such that $n^2+n+1$ divides $4^n+2^n+1$ and $n$ is not power two,"If positive integer $n$ is not power two and $n^2+n+1 \mid 4^n+2^n+1$ , then what sequence of $n$ ? Source problem from Prove that there are infinitely many integers $n>0$ such that $n^2+n+1$ divides $4^n+2^n+1$ . We have two first term of sequence: 215,3692374808 . Let $m=n^2+n+1$ . For both first terms $m$ is prime. Question 1: can be $m$ is not prime for next terms? Suppose 1: $m$ is prime $\overset{FLT}{\implies} 2^{n(n+1)}\equiv 1 \pmod{m} \implies 2^{3n}\equiv 1 \pmod{m}$ . Question 2: how prove if $m$ is prime then $n\equiv2\pmod{3}$ ? Note: from post Modular arithmetic with Legendre symbol implies $n\not\equiv1\pmod3$ . Suppose 2: $n\equiv2\pmod{3} \implies 2^{\frac{n(n+1)}{3}}\equiv3^{\frac{n(n+1)}{3}}\equiv n^x\pmod{m}$ , where some integer $x\ge0$ . Question 3: what other conditions for $n$ we can seen for speedup find next terms?","['number-theory', 'modular-arithmetic', 'sequences-and-series']"
3268688,Criterion of Dahlquist and consistency of a process,"We have the linear multi-step process $-y_k-y_{k+1}+y_{k+2}+y_{k+3}=4hf(t_k,y_k)$ for the initial value problem $y'(t)=f(t,y(t)), y(0)=0$ Check the consistency of the process and the criterion of Dahlquist of the characteristical polynomial. Checking the criterion of Dahlquist is easy.
The characteristical polynomial of this process is given by: $\rho(x)=x^3+x^2-x-1=(x-1)(x+1)^2$ with the roots $\lambda_1=1$ and $\lambda_{2,3}=-1$ . So $|\lambda_i|\leq 1$ but we have a double root with $|\lambda_2|=1$ so the criterion of Dahlquist does not apply here. I struggle with the consistency of this process. I have to show that for $\tau_h(t,y(t))=\frac1h\sum_{j=0}^m \alpha_j y(t+jh)-\sum_{j=0}^m \beta_j f(t+jh,y(t+jh))$ it is $\lim_{h\to\infty} \tau_h =0$ Correct? Is there an easier way?
Thanks in advance.","['numerical-methods', 'ordinary-differential-equations']"
3268694,What does it mean when not every relationship expressed by a equation can also be expressed as a function with a formula?,"I'm studying a pre-calculus textbook and it mentioned this: ""It is important to note that not every relationship expressed by an
  equation can also be expressed as a function with a formula."" Can someone help me understand this by giving examples?","['algebra-precalculus', 'intuition']"
3268731,Brownian motion and Beta distribution,"I am interested in the distribution of the time that the standard Brownian $W_t$ motion on $[0,1]$ satisfies the following inequality: $$W_t \ge stW(1)$$ For different values of $s$ . I conjecture that the distribution is always a Beta distribution with both parameters equal (if they are Beta distributed they have to be equal because by symmetry the expected value of this time should be equal to $\frac{1}{2}$ . There are two special cases in which I can tell that the above is true: if $s=0$ then we have the usual question about the distribution of time BM spends above the $x$ -axis in which case the answer is the $B(\frac{1}{2},\frac{1}{2})$ distribution. If $s=1$ the inequality can be transformed into: $$B_t=W_t-tW(1) \ge 0$$ Which asks about the distribution of the time that the Brownian bridge spends above the $x$ -axis in which case the answer is $B(1,1)$ - the uniform distribution. From the simulation I have conducted it seems that the result is true in general with $1$ being the highest parameter value. However, I don't have any proof nor any clue how to proceed.","['probability-distributions', 'brownian-motion', 'probability-theory', 'probability']"
3268752,simplify the summation of harmonic cosines,"Is it possible to simplify the following summation of harmonic cosines eliminating the sum? \begin{equation}
\sum_{n=1}^{N-1} \left( 1 + \cos \left( \frac{\pi n}{N} \right) \right)^N
\end{equation} The graph shows it will be like an exponential.","['trigonometry', 'summation']"
3268791,Median of 2 sets and median of the sum of the 2 sets,"Suppose I have N individuals (N is odd for convenience).
Associated with these individuals, two  sets (S1 and S2) which contain integer numbers. 
E.g. S1 is the salary/hour and S2 is the bonus/hour: Individuals = {A,B,C,D,E} S1 = {A=9; B=11, C=13; D=15, E=20} S2 = {A=6; B=1, C=4; D=5, E=1} (Note that S1 is ordered while S2 is not).
The medians of each set are respectively 13 & 4. Suppose now, that for each individual I do the sum of the two sets: S3 = {A=15; B=12, C=17; D=20, E=21}. The median of S3 is equal to 17. So, in this case, median(S1+S2) = median(S1)+median(S2). My question is, in which conditions this relation is true ? By doing tests, I came to the conclusion that if the median individual in set1 is the same as in set2 then the relationship is true... Is there other conditions ? How to prove it ? Thank you,",['statistics']
3268806,Determine if there exist rational number a and irrational number A such that $A^3+aA^2+aA+a=0$.,"Determine if there exist a rational number a and irrational number A such that $A^3+aA^2+aA+a=0$ . If so, can we say something about them? Are there infinitely many of them?","['algebra-precalculus', 'irrational-numbers']"
3268826,UMP test for testing $f=f_0$ vs $f=f_1$ where $f$ is discrete,"As I was studying for my exam I came across the following problem: Let $X$ be a discrete random variable with probability mass function (pmf) given by $f(x) = P(X = x)$ . Further, consider the situation in which $f(x)$ can take on one of two forms which are given in the following table: Determine the uniformly most powerful (UMP) test for $H_0 : f = f_0$ vs. $H_1 : f = f_1$ at the $\alpha = 0.3$ level. I know that to find the UMP of a test you must start by setting up the likelihood ratio. However, I am not sure how to do so in this case. Any suggestions are appreciated. After receiving a hint from @StubbornAtom and doing some more reading, here my attempt to solve this problem.
Since our hypothesis test is a simple hypothesis test we can use Neymann-Pearson Lemma, which states the LRT is the UMP of such hypothesis tests. We let $\lambda(x)=\frac{f_1(x)}{f_0(x)}$ and we reject $H_0$ if $\lambda(x)>k$ . In our case the LRT is as follows: $\frac{f_1(1)}{f_0(1)}=3/2$ , $\frac{f_1(2)}{f_0(2)}=1/3$ , $\frac{f_1(3)}{f_0(3)}=3$ , $\frac{f_1(5)}{f_0(5)}=2/3$ , $\frac{f_1(7)}{f_0(7)}=1$ . From here we see that the greatest value of the LRT is $3$ and it happens when $x=3$ . Therefore, our critical region is $\{x=3\}$ . Thus, we reject $H_0$ if $X = 3$ . The significance of this test $\alpha=P(\text{reject } H_0\mid H_0)=P(X=3\mid f_0)=0.1$ . But we need it to be 0.3 I would appreciate a thumbs up or down for my attempt to solve this problem. Thank you!","['statistical-inference', 'statistics', 'hypothesis-testing']"
3268870,Proving a certain type of topology is discrete without the axiom of choice,"I came across the following exercise: suppose we have a topology on an infinite set $X$ which contains all infinite subsets of $X$ . Prove that the topology is discrete. Here's a way to approach this: pick two disjoint infinite subsets $A$ and $B$ of $X$ . For any $x\in X$ , $A\cup\left\{x\right\}$ and $B\cup\left\{x\right\}$ are open and so is their intersection, which is just $\left\{x\right\}$ . Hence all singletons are open and the topology is discrete. This proof is essentially the same as the one here . However, I don't quite like this argument, mainly because of the step where we say ""pick two disjoint infinite subsets of $X$ "". This isn't really a problem in ZFC since it's possible to prove that every infinite set has an infinite countable subset and after this is established, picking $A$ and $B$ is simple. But what if I'm working without the axiom of choice? So, my question is: can it be proved without AC that every infinite set contains two disjoint infinite subsets or is it perhaps possible to avoid this altogether by proving the topology is discrete in another way (not reliant on AC)?","['axiom-of-choice', 'general-topology', 'set-theory']"
3268895,"A distance over strings, and an embedding that perfectly captures it","Suppose we have an alphabet $\Sigma$ . We also define a set of operations on a string $s=s_1 s_2 \dots s_n\in\Sigma^\star$ (assuming $c\in\Sigma, i\in[n]$ : $$swap(s,i)=s_1 \dots s_{i-1} s_{i+1}s_{i} s_{i+2} \dots s_n$$ $$ins(s,i,c) = s_1 s_2 \dots s_{i-1}\; c \;s_i \dots s_n$$ $$del(s,i) = s_1 s_2 \dots s_{i-1} s_{i+1} \dots s_n$$ Moreover the costs associated with each operation is defined as: $$C_{swap(s,i)} = 2, C_{ins(s,i,c)} = |s|, C_{del(s,i)} = |s|-1$$ Now if we denote the space of all possible actions by $\mathcal{A}$ , we define the distance between two strings as the minimum cost set of operations that transform one string to antoher: $$d(s,s')=\min_{a_i\in\mathcal{A}, a_k(\dots a_2(a_1(s))\dots) = s'} \sum_{i} C_{a_i}$$ It is easy to see that the distance is symmetric, as any operation can be reversed with the same cost: $s'=swap(s,i)\rightarrow s=swap(s',i)$ , $s'=ins(s,i,c) \rightarrow s=del(s',i)$ and $s'=del(s,i) \rightarrow s=ins(s',i,s_i)$ , while the cost remains the same. Therefore any minimum cost list of operations could be reversed to prove $d(s,s') = d(s',s)$ . However, I have a guess that the distances have a very simple formula which is as follows:
For $s\in\Sigma^\star$ and arbitrary $a,b\in\Sigma$ we define $v_s$ as  the count of how many times letter $a$ appears before letter $b$ in the string $s$ . Or formally: $$v_s(a,b) = \#\{(i,j) \colon i<j, s_i=a, s_j=b\}$$ My guess is that: $$d(s,s') = \sum_{a,b\in\Sigma} |v_s(a,b)-v_{s'}(a,b)| \qquad (1)$$ If this is true, another way to view it is that we can embed strings into a $|\Sigma|^2$ dimensional space $s\in\Sigma^\star\rightarrow v_s\in \mathbb{N}^{|\Sigma|^2}$ , such that the $L_1$ distance in the embedding space corresponds exactly to the distance defined over strings: $d(s,s') = ||v_s - v_{s'}||_1$ (if we view $v_s,v_{s'}$ as vectors). It is easy to see that if we get $s'$ from $s$ by a single operation, the associated cost is captured by the equation (1). But in order to prove that for any set of optimal operations the equation holds some kind of induction must be used. But I am not sure how to construct such an induction. Any ideas?","['combinatorics', 'discrete-mathematics']"
3268918,"Finding a good Lyapunov function for $ \{ x'= y , y'= -4 x + 5x^3 - x^5 \}$","For the system: $$\begin{cases}x'= y \\y'= -4 x + 5x^3 - x^5 \end{cases} $$ I am trying to determine the stability of $(x,y)=(0,0)$ by means of a Lyapunov function. I am trying to find a good one, the regular $V(x,y)=ax^2 + by^2$ does not help me as I get odd-powered terms and products of $x$ and $y$ that do not cancel. Specifically: $$ \dot{V}(x,y) = 2axy + b xy(-1+5x^2-x^4)$$ Does someone have a better suggestion, what is the general approach in finding such a function for a given problem? I want to somehow use the fact that these odd powers of $x$ and $y$ appear in this system of equations, I haven't figured out how to do this in an effective manner.","['nonlinear-system', 'lyapunov-functions', 'ordinary-differential-equations']"
3268930,"Nakayama's Lemma, Stalks and Fibres (Hartshorne III.12.7.2)","I can't quite follow Chapter III, Example 12.7.2 in Hartshorne (I've written it in the case of affine varieties only here since I haven't worked with schemes in general yet and this is all I need). In it, he gives an alternative proof of a result I asked about in this question . Let $X$ be an affine variety over an algebraically closed field $k$ , $A=\Gamma(X,\mathcal{O}_X)$ , and $\mathcal{F}$ a coherent sheaf on $X$ . Let $x\in X$ , $\mathfrak{m}_x=\{f\in A\mid f(x)=0\}$ , and $k(x)=A/\mathfrak{m}_x$ . Then the function $$\varphi(x)=\dim_{k(x)}(\mathcal{F}\otimes_A k(x))$$ is upper semi-continuous. I'll go through his reasoning and my thoughts so far. Since $\mathcal{F}$ is coherent, I have taken an $A$ -module $M$ with $\mathcal{F}=\widetilde{M}$ . He starts by saying that by Nakayama's Lemma we have that $\varphi(x)$ is the minimum number of generators of the stalk $\mathcal{F}_x$ as an $\mathcal{O}_x$ -module. Here is my attempt to justify this: Suppose $x_1,\ldots,x_n$ generate $\mathcal{F}_x=M_{\mathfrak{m}_x}$ as an $\mathcal{O}_x=A_{\mathfrak{m}_x}$ module, with $n$ minimal. Then for any $m\in\mathcal{F}_x$ we can find $a_i\in A$ , $f\in A\setminus\mathfrak{m}_x$ such that $$m=\frac{a_1}{f}x_1+\cdots+\frac{a_n}{f}x_n$$ (we can assume a common denominator by taking terms into the $a_i$ ). Since $k(x)$ is a field we can find $g\in A$ with $fg-1\in\mathfrak{m}_x$ . Then for $b_i=a_ig$ we have $m=b_1x_1+\cdots+b_nx_n$ in $\mathcal{F}\otimes_A k(x)=M/\mathfrak{m}_xM$ and so $\varphi(x)\leq n$ . Conversely, suppose that $\varphi(x)=l$ and $x_1,\ldots,x_l$ generate $\mathcal{F}\otimes_A k(x)$ over $k(x)$ . Now, $\mathcal{F}\otimes_A k(x)=\mathcal{F}_x/\mathfrak{m}_x\mathcal{F}_x$ , so by Nakayama's Lemma there exists some $f\in A\setminus\mathfrak{m}_x$ such that the $x_i$ generate $(M_{\mathfrak{m}_x})_f$ as an $A_f$ -module. But $(M_{\mathfrak{m}_x})_f=M_{\mathfrak{m}_x}$ since $f\notin\mathfrak{m}_x$ , and $A_f\subseteq A_{\mathfrak{m}_x}$ , so they certainly generate $\mathcal{F}_x$ as an $\mathcal{O}_x$ -module. Then $n\leq\varphi(x)$ , so $\varphi(x)=n$ as desired. He goes on to say that if $x_1,\ldots,x_n$ form a minimal set of generators, then they generate $\mathcal{F}$ in some neighbourhood. From my justification of the first statement, it appears that this neighbourhood would be $D(f)$ . We know they generate $M_{\mathfrak{m}_x}$ as an $A_f$ -module, but I'm not sure how this would show they generate $M_f$ . I also can't see why we would need to use the minimum number of generators for this step in particular to be true. He concludes that if we take any $y$ in this neighbourhood, then $\varphi(y)\leq n$ . This is where I am particularly confused. As I understand it (and I may well have already misunderstood something), we would (hopefully) have that $x_1,\ldots,x_n$ generate $M_f$ as an $A_f$ -module, with $y\in D(f)$ . Then why does this imply that we can generate $\mathcal{F}_y=M_{\mathfrak{m}_y}$ as an $\mathcal{O}_y=A_{\mathfrak{m}_y}$ module using $n$ elements? Perhaps I'm not using Nakayama's Lemma in the way he intended, my justification seems very laboured in comparison to how it is presented, so I feel I'm really missing something here. Any help would be much appreciated.","['algebraic-geometry', 'commutative-algebra', 'sheaf-theory']"
3268999,Computing $\int_{-π/2}^{π/2} \frac{28\cos^2(θ)+10\cos(θ)\sin(θ)-28\sin^2(θ)}{2\cos^4(θ)+3\cos^2(θ)\sin^2(θ)+m\sin^4(θ)}\ dθ$,"I am studying the integral $$I=\int_{-\pi/2}^{\pi/2}
\frac{28\cos^2(\theta)+10\cos(\theta)\sin(\theta)-28\sin^2(\theta)}{2\cos^4(\theta)+3\cos^2(\theta)\sin^2(\theta)+m\sin^4(\theta)}d\theta,$$ where $m>0$ . In the problem I am working, it is very important to know what value of $m$ makes this integral positive, negative or equal to zero. I found that if $m=2$ , then the integral is zero (introducing it in Wolfram Alpha). However, I don't know how to prove it formally. On the other hand, I tried some values of $m$ in Wolfram and it seems that if $m<2$ , then the integral is negative, and if $m>2$ , the integral is positive. But again, I have no proof of this. Any ideas of how to approach this problem? Just in case, I found this alternative representation of the integral $$I=\int_{-\pi/2}^{\pi/2}
\frac{8[5\sin(2\theta)+28\cos(2\theta)]}{\cos(4\theta)+15+8(m-2)\sin^4(\theta)}d\theta.$$ Any help would be appreciated.","['integration', 'trigonometric-integrals', 'definite-integrals']"
3269065,Gambling Systems and Strong Convergence,"Say you're betting on ""red"" at roulette.  From one trial to the next, you vary your bet size between the house minimum and maximum based on the outcomes of previous trials.  Can you prove that you go broke with probability 1, or that if you have an unlimited bankroll to start, your long-term return rate (winnings per unit wagered) converges to the expectation of a single unit wager? Well, with probability 1, at least.  That seems plausible.","['gambling', 'probability']"
3269080,"How can you mathematically define a ""wobbly"" function?","There are a lot of functions that look wobbly. For example $x^4 + x^3$ looks a little wobbly when it gets near the x axis. The function $\sin(x)$ is extremely wobbly. The function $\sin(x) + x$ is also extremely wobbly. What is a mathematical expression that seems to calculate how ""wobbly"" a function $f(x)$ is? What I've done so far: At first I thought ""wobbly"" was just the slope changing quickly. To measure how fast the slope is changing, that would be the slope of the slope, and we don't care about direction, so we obtain: $$w_1(f; a, b) = \int_a^b | f''(x) | dx$$ where $w_1$ is the first definition I've come up with for the ""wobbliness"" of a function from $x = a$ to $x = b$ where $a < b$ . However, when I tested this on the function $f_1(x) = x^4 + x^3 - x^2 - x$ , it didn't seem right. $f_1$ seems to be wobbly from $-1$ to $1$ . However, $w_1(f_1) = \int_a^b |12x^2+6x-2|$ which seems to be largest for $a, b < -1$ or $1 < a, b$ , which is not what we want. My next thought was that maybe I'm counting how often a function is switching from a non-zero slope to a zero slope over a particular range. This would make $f_1$ be wobbly from $-1$ to $1$ , and would also make $\sin(x)$ be very wobbly as well. However, I didn't even attempt to come up with a mathematical formula for this definition (which I will call $w_2$ ), because I recognized that $f_2 = \sin(x) + 2x$ would be a counterexample. It's also very wobbly, but its slope is never 0. Interestingly enough, $w_1$ seems to do a good job of measuring where $f_2$ is wobbly. So, again, what mathematical function can be used to quantify how ""wobbly"" another function is? (It must work for at least $f_1$ and $f_2$ and hopefully generalize to other functions as well.) Here are graphs of $f_1$ , $f_2$ , $w_1(f_1)$ , and $w_1(f_2)$ in case they are helpful for understanding.","['definition', 'functions', 'visualization', 'terminology']"
3269091,Mascheroni Construction of the Heptadecagon,"Since Gauss proved that the heptadecagon is constructible with ruler and compass, there were found plenty of ways of constructing it, some of them are pretty clever (e.g. DeTemple and Ma Long ). On the other hand, there is a theorem due to Mascheroni which states that any polygon that is constructible with ruler and compass can be constructed with compass only (the ones called Mascheroni constructions). I found some interesting Mascheroni constructions for the pentagon, including a pretty amazing result showing the construction of the pentagon with only 7 circles (see it here ). However, in my research I didn't find any clever Mascheroni construction of the heptadecagon (besides the ones that are just translations of Mascheroni methods to some operations between segment and circles, such as finding the midpoint). So I was wondering: Which is the Mascheroni construction of the heptadecagon with the least number of circles that is known? Is there any work in this direction?",['geometry']
3269102,A strange result if $|G/\mathrm{Z}(G)|=p$,"I came across something strange, which I would like to share. Let's take a group $G$ such that $|G/\mathrm{Z}(G)|=p$ , where $p$ is a prime number. Then, we can show that $G$ is abelian $\iff \mathrm{Z}(G)=G$ . But then $|G/\mathrm{Z}(G)|=|G/G|=1$ and we have a contradiction. What do I miss? Thanks","['group-theory', 'abstract-algebra', 'p-groups']"
3269153,Riemannian Curvature and Levi-Civita Connection on Symmetric Positive Definite Matrix Manifold,"Let $\mathcal{S}$ be the Symmetric Matrices and $\mathcal{P}$ be the positive definite matrices. $\mathcal{S}$ naturally carries the structure of a vector space. Inner product on $\mathcal{S}$ is given by $\langle A , B \rangle =  trace(A B)$ . $\mathcal{P}$ is an open set in $\mathcal{S}$ . the map $$ log : \mathcal{P} \rightarrow \mathcal{S} $$ is a diffeomorphism between two manifolds. We can identify the tangent space at x $ T_{\text{x}}\mathcal{P} $ with $\text{x} \times \mathcal{S} $ .
Induced metric on the Tangent space is given by $$ \langle A , B \rangle_{x}  = \langle dlog(A) |_{x} , dlog(B) |_{x} \rangle  $$ ,where $$
dlog : T_x\mathcal{P} \rightarrow T_{log(x)}\mathcal{S} $$ $$
         A \mapsto A X^{-1}
  $$ Writing out explicitly the inner product on $\mathcal{P}$ is given by $$\langle A , B \rangle_{X} = \text{trace}( A X^{-1} B X ^{-1})$$ Length $L(\gamma)$ and Energy $ E(\gamma)$ of a curve $ \gamma : [0,1] \rightarrow \mathcal{P} $ is given by $$
   L(\gamma) = \int_a^b \| \dfrac{d\gamma}{dt} \|_{\gamma(t)} dt$$ $$E(\gamma) = \frac{1}{2} \int_a^b \| \dfrac{d\gamma}{dt}\|_{\gamma(t)}^2 dt $$ Geodesics are energy minimizing curves on a manifold. They allow us to introduce distance between two points on a manifold. To calculate them we can simply employ euler lagrange equations $$ \frac{d}{dt} \frac{d}{d\dot{\gamma}} f(t,\gamma(t), \dot{\gamma}(t)) = \frac{d}{d\gamma} f(t,\gamma(t), \dot{\gamma}(t))  $$ writing out explicitly we have $$ \frac{d}{dt} \frac{d}{d\dot{\gamma}}
   \text{trace}( \dot{\gamma} \gamma^{-1} \dot{\gamma} \gamma ^{-1}) = \frac{d}{d\gamma}
   \text{trace}( \dot{\gamma} \gamma^{-1} \dot{\gamma} \gamma ^{-1}) $$ Lefthand side of the equation reduces to $$ \frac{d}{dt} \gamma^{-1} \dot{\gamma} \gamma ^{-1}  $$ whereas the righthand side of the equation reduces to $$ - \gamma^{-1} \dot{\gamma} \gamma^{-1} \dot{\gamma} \gamma^{-1}  $$ Solving the differential equation we get two different expressions for the geodesics. $$ \gamma(t) = P exp(t P^{-1} S) $$ here P lies on the manifold and S lies on the tangent space. Intuitively $\gamma$ is the curve, which starts at P with direction S. $$ \gamma_{AB}(t) = A( A^{-1} B)^t $$ here gamma is the geodesic between the points on the manifold A and B. Now that the geodesics are defined, distance on the spd manifold may be defined via the length of the geodesic curve connecting two points. After some calculations we arrive at $$ d(X,Y) = \| log( X^{-1} Y ) \| $$ So those are my calculations so far. I am quite new to the differential geometry. My first question is do the arguments generally make sense? I am not really convinced that $ dlog = dX X^{-1} $ or that the inner product on $\mathcal{S}$ is $ trace(AB)$ . My ultimate goal is to read christoffel symbols from the geodesics eq. and calculate the riem. curvature. But i am not sure how to proceed or if the calculations so far makes sense. Edit: I tried to find another expression for dlog (and hoped it would be equivalent to $ AX^{-1}$ ) by taking the directional derivative of log-series . But generally the direction in which i take the derivative and the base point wont commute. That is why i dont think my expression for dlog is true.
It is somehow funny that a wrong expression still produces a valid metric.","['matrix-calculus', 'symmetric-matrices', 'manifolds', 'positive-definite', 'differential-geometry']"
3269159,Show that the set $S$ is not a submanifold,"The definition of submanifold in my class is as follows. Let $d$ and $n$ natural numbers, such that $0 \leq d \leq n$ , let $l \in \mathbb{N} \cup \{\infty \} $ , and let $X$ a normed vector space of dimension $n$ . A subset $M \subset X$ is a $d$ -dimensional $C^l$ -submanifold of $X$ if it satisfies: For all $p \in M$ exist a open subset $U \subset X$ whit $p \in U$ , a open $V \subset \mathbb{R}^n$ , and a $C^l$ -diffeomorphism $\phi:U \rightarrow V$ with $$\phi(U \cap M)=V \cap (\mathbb{R}^d \times\{0\}).$$ I have to prove that the set $S$ is not a submanifold of $\mathbb{R}^2$ , where $S:=\{(x,y) \in \mathbb{R}^2~|~y\neq 0 \Rightarrow 1/y \in \mathbb{N} \}$ . My problem is that I believe I have demonstrated that $S$ is a submanifold 1-dimensional of $\mathbb{R}^2$ . Then $S$ can be a submanifold of $\mathbb{R}^2$ ?","['manifolds', 'multivariable-calculus', 'submanifold', 'analysis']"
3269168,Exercise 3 in Section 7.11 of Apostol's Calculus (Vol. 1) little o-notation,"The problem is stated as: Find the polynomial $P(x)$ of minimal degree such that $$
\sin(x-x^2)=P(x)+o(x^6)\quad \textrm{as }x\to 0.
$$ and the answer in the book is $$
P(x)=x-x^2-\frac{x^3}{6}+\frac{x^4}{2}-\frac{59x^5}{120}+\frac{x^6}{8}
$$ I am wondering why the answer cannot be $P(x) = x-x^2$ Since we can use the fact that $\sin(x-x^2) = x-x^2 + o((x-x^2)^2)$ as $x \to 0$ And we know that $o((x-x^2)^2) = o(x^5) = o(x^6)$ as $x$ goes to zero. Then why is the answer from the back of the book not equal to $x-x^2$ ??","['calculus', 'functions', 'trigonometry', 'real-analysis']"
3269252,Closed orientable 4-manifolds with $H_2(M)\cong \mathbb{Z}$ do not admit free actions of $\mathbb{Z}/2$,"The questions asks us to show that if $M$ is a closed orientable 4-manifold such that $H_2(M)$ is rank $1$ , then $M$ does not admit a free action of $\mathbb{Z}/2$ . My attempt has been to suppose $M$ has a free action of $\mathbb{Z}/2$ . So there is a homeomorphism $\phi:M\rightarrow M$ satisfying $\phi^2=\textrm{id}$ . I've looked at the duality isomorphism $H^2(M)\rightarrow H_2(M)$ and played around with identities like $$
\phi_{\ast}(\phi^{\ast}\alpha\cap[M])=\alpha\cap\phi_{\ast}[M]=\pm\alpha\cap[M]
$$ trying to get at some kind of contradiction. But I suspect I need to incorporate the freeness assumption for the action $\mathbb{Z}/2$ . I understand that this action will be properly discontinuous and so if $M$ were path connected then the quotient map $M\rightarrow M/(\mathbb{Z}/2)$ would be a covering space and $M/(\mathbb{Z}/2)$ would inherit the structure of a manifold. The trouble is that $M$ isn't necessarily path-connected. Can anyone suggest a way of procedding?","['poincare-duality', '4-manifolds', 'geometry', 'algebraic-topology']"
3269261,Computing the differential of a function on manifolds using velocity vector,"I am studying manifolds using Loring Tu's book and am slightly confused about the expression of the differential using the velocity vector. Below is a snippet of the book. $T_pN$ is the tangent space of the manifold $N$ while $F_{*,p}$ is the differential. From what I understand, $F_{*,p}$ maps $X_p$ to an element in $T_{F(p)} M$ , the tangent space of the manifold M at $F(p)$ . However, the elements of the tangent spaces are derivations which maps $C^{\infty}(M)$ to $\mathbb{R}$ . In other words, if $f \in C^{\infty}(M)$ , then $F_{*,p}(X_p) f \in \mathbb{R}$ . Looking at this definition below in terms of the velocity, I am not sure where the "" $f$ "" would go in here. Would it be the case that $F_{*,p}(X_p)f = \frac{d}{dt} \big|_0 (f \circ F \circ c)(t)$ ? I am asking because the example presented after this proposition deals with the mapping $\ell_g: GL(n,\mathbb{R}) \rightarrow GL(n,\mathbb{R})$ given by $\ell_g(B) = gB$ for $g,B \in GL(n,\mathbb{R})$ (see snippet below). It then shows that the differential $(\ell_g)_*$ is also a left multiplication by $g$ . Now, if we have $f \in C^{\infty}(GL(n,\mathbb{R}))$ , the result derived by the example seems to suggest that $(\ell_g)_*(X) f = gX f$ . But, if I use my definition above, i.e. ${\ell_g}_{*}(X)f = \frac{d}{dt} \big|_0 (f \circ \ell_g \circ c)(t)$ , I don't seem to get $gXf$ ? Clarifications would be appreciated!","['manifolds', 'smooth-manifolds', 'differential-geometry']"
3269294,The double sum $\sum_{j=0}^{n} \sum_{i=0}^{m} (-1)^{i+j} {m \choose i} {n \choose j} {i+j \choose i} =0~ \mbox{or}~1$,"For non-negative integers $m$ and $n$ , the double sum $$\sum_{j=0}^{n} \sum_{i=0}^{m} (-1)^{i+j} {m \choose i} {n \choose j} {i+j \choose i}$$ can be checked to be 0 or 1. How can one show this by hand, along with the conditions on $m$ and $n$ ?","['summation', 'binomial-coefficients', 'sequences-and-series']"
3269321,Understanding full and faithful functors,"A functor $F:\mathscr A\to\mathscr B$ is faithful (resp., full ) if for each $A,A'\in Ob(\mathscr A)$ , the function $$\mathscr A(A,A')\to \mathscr B(F(A),F(A'
))\\ f\mapsto F(f)$$ is injective (resp., surjective). In the situation of the figure below, $F$ is faithful if for each $A, A'$ ,
  and $g$ as shown, there is at most one dotted arrow that $F$ sends to $g$ . It is full if
  for each such $A, A'$ ,
  and $g$ , there is at least one dotted arrow that $F$ sends to $g$ . 1) I don't quite understand why this explanation with the figure is the same as injectiveness. Injectiveness says that for all $A,A'$ , if there are two arrows $F(f):F(A)\to F(A')$ and $F(g):F(A)\to F(A')$ , then $f=g$ , right? The explanation cited above includes the case when no arrow maps to $g$ under $F$ , I don't see how this is accounted for in the definition of injectiveness I stated. 1') Is there an easy example when the map mentioned above is injective but there exists $g$ that doesn't come (via $F$ ) from any arrow in $\mathscr A$ ? 2) Is there an easy example when $F$ is faithful and there are distinct arrows $f_1,f_2$ in $\mathscr A$ with $F(f_1)=F(f_2)$ ?","['elementary-set-theory', 'examples-counterexamples', 'functors', 'category-theory']"
3269337,Why does cocycle condition imply a group?,"In group cohomology, the 2-cocycle condition emerges from associativity (see e.g. here ).
From the answer to a previous question we see (at least for normalized cocycles) that  the cocycle condition ensures invertibility too. But how do we know a priori , that associativity will ensure invertibility too? Edit We are talking about the algebraic structure $\Gamma = (A\times G,\bullet)$ where $A$ is an Abelian group, $G$ is a group, and $\bullet$ is the following binary operation: $$(a_1,g_1)\bullet(a_2,g_2) = (a_1+\varphi_{g_1}(a_2)+f(g_1,g_2),\,g_1g_2)\tag{1}$$ where $\varphi:(A\times G)\to A: (a,g)\mapsto \varphi_g(a)$ is a group action of $G$ on $A$ $f: G\times G\to A$ We can derive the $$ f(g_1,g_2g_3)+\varphi_{g_1}(f(g_2,g_3)) = f(g_1g_2,g_3) + f(g_1,g_2)\tag{8}$$ cocycle condition purely from the requirement of associativity of $\bullet$ . What is interesting, that this condition ensures automatically also The existence of an identity element in $\Gamma$ , that is, if the cocycle condition holds, then $\Gamma$ will be not only a semigroup, but also a monoid. The existence of a left inverse and a right inverse for every $\gamma\in \Gamma$ (better to say, 2. depends on the cocycle condition only through 1. If an identity element is already given, then we don't need the cocycle condition any more for 2.) Associativity, 1. and 2. together means that $\Gamma$ is a group, since in every monoid, left inverses are equal to the right inverses: $$x\bullet \gamma = e = \gamma\bullet y \implies x=y$$ due to the associativity: $$y=e\bullet y=(x\bullet\gamma)\bullet y=x\bullet(\gamma\bullet y) = x\bullet e = x$$","['abstract-algebra', 'group-cohomology', 'intuition', 'group-theory', 'soft-question']"
3269346,Trace($A$) = Trace($A^2$) = Trace($A^3$),"Suppose $A$ be an $n\times n$ matrix with real eigenvalues such that $\text{trace}(A)=\text{trace}(A^2)=\text{trace}(A^3)$ . What can we conclude about the eigenvalues of A? My attempts: Considered $A$ as a diagonal matrix and $\lambda_1,\lambda_2
,\ldots,\lambda_n$ to be its eigenvalues. So we get $$\lambda_1+\lambda_2+\cdots\lambda_n=\lambda_1^2+\lambda_2^2+\cdots+\lambda_n^2=\lambda_1^3+\lambda_2^3+\cdots+\lambda_n^3$$ From the first equality and using Cauchy–Schwarz inequality, we could get $\lambda_1+\lambda_2+\cdots\lambda_n\leq n$ . My guess is that all non-zero eigenvalues are to be 1(just an intuition). But can't proceed any further. Suppose $A$ is a $2\times 2$ matrix, then we could get trace( $A^2$ ) = (trace( $A))^2-2\det(A)$ and trace( $A^3$ ) = (trace( $A))^3-(3\det(A)\cdot\text{trace}(A))$ . here also couldn't figure out a way. Thank you in advance.","['systems-of-equations', 'eigenvalues-eigenvectors', 'trace', 'linear-algebra', 'algebra-precalculus']"
3269359,Generalizing a theorem from real analysis regarding strictly increasing functions,"This is a question of my own asking, originating from a misinterpretation of OP's question in this thread where I  accidentally proved the following: Theorem : A continuous function $f:[a,b] \to \mathbb{R}$ that is strictly increasing on $(a,b)$ is also strictly increasing on $[a,b]$ . Proof : Assuming $f:[a,b] \to \mathbb{R}$ is a continuous function, we'll have $f\Big( (a,b) \Big) = (c,d)$ for some $c,d \in \mathbb{R}$ because the continuous image of a connected set is connected .  Note that this fact also implies $f(b) = w$ for some $w \in [c, d]$ .  Now let's suppose $f(b) \neq d$ ; i.e. suppose $w \in [c, d)$ .  Consider the preimage of the interval $U = (w- \varepsilon, \ w + \varepsilon)$ , where $0 < \varepsilon < |d-w|$ .  It would look like $f^{-1}(U) = V \cup \ \{b\}$ , where $V$ is such that $\{b\}$ is isolated.  Due to this isolated point, $f^{-1}(U)$ cannot be open.  Because $U$ is an open set and $f^{-1}(U)$ is not, $f$ cannot be continuous.  Thus, continuity forces $f(b) = d$ , just as it does $f(a) = c$ by an analogous argument. Having done this, I wondered how easy it would be to adapt the underlying strategy to prove a more general topological statement, and I arrived at this hypothesis ( wrong: see Eric Wofsey's post ): Let $X$ be a Hausdorff space, $U \subset X$ an open set, and $f: \overline{U} \to Y$ a continuous function into a locally compact Hausdorff space where $f:U \to f(U)$ is a homeomorphism.  Then $f: \overline{U} \to f(\overline{U})$ is also a homeomorphism. Some thoughts : Per this fact , I know that it suffices to prove that the restriction of $f$ to the boundary $\partial U$ of $U$ is bijective.  This is why I have chosen the ""locally compact Hausdorff"" condition: I think it might help me guarantee injectivity.  To wit, let's suppose $f(p) = f(q)$ for $p, q \in \partial U$ .  Per Hausdorffness, we can separate $p$ and $q$ with disjoint open neighboorhoods $S_p$ and $S_q$ .  Next, the image of $S_p$ will be a neighborhood of $f(p)$ , which necessarily contains an open neighborhood of $f(p)$ per local compactness.  Then the preimage of this set will have $\{q\}$ as an isolated point, so it cannot be open and thus $f$ would be discontinuous (this feels hand-wavy, as if I'm missing something and don't know what). Questions : Which bits of the above are wrong? What is the most general statement one can make here? How can I tackle surjectivity?  I have a few vague ideas that could make this easier, such as requiring the boundaries of each connected component of $U$ to be connected, but these are largely unsubstantiated hunches, and I feel trying to justify them here would detract from the post. To encourage as much discourse as possible, I'm willing to both accept an answer and award a bounty on a second for substantial replies, assuming I get more than one.  Meaty partial answers encouraged.","['general-topology', 'monotone-functions', 'real-analysis']"
3269431,sum of series $\frac{1}{1\cdot 3}+\frac{1}{4\cdot 5}+\frac{1}{7\cdot 7}+\frac{1}{10\cdot 9}+\cdots $,The sum of series $$\frac{1}{1\cdot 3}+\frac{1}{4\cdot 5}+\frac{1}{7\cdot 7}+\frac{1}{10\cdot 9}+\cdots $$ My attempt $$\displaystyle \sum^{n}_{k=1}\frac{1}{(3k-2)(2k+1)}=\frac{1}{7}\sum^{n}_{k=1}\bigg[\frac{3}{3k-2}-\frac{2}{2k+1}\bigg]$$ $$=\frac{1}{7}\sum^{n}_{k=1}\int^{1}_{0}\bigg(3x^{3k-3}-2x^{2k}\bigg)dx$$ $$=\frac{1}{7}\int^{1}_{0}\bigg(\sum^{n}_{k=1}3x^{3k-3}-2x^{2k}\bigg)dx$$ $$=\frac{1}{7}\int^{1}_{0}\bigg[\frac{3(1-x^{3n})}{1-x^3}-\frac{2(1-x^{2n+2})}{1-x^2}\bigg]dx$$ How do i solve it Help me please,['sequences-and-series']
3269468,Laplace equation: What is the difference between divergence operator and gradient operator both represented by $\nabla$? (in wikipedia article),"Here is the beginning of the article of Laplace equation of wikipedia Laplace's equation is a second-order partial differential equation named after Pierre-Simon Laplace who first studied its properties. This is often written as $$
\nabla^2f = 0\quad\text{or}\quad\Delta f = 0
$$ where $\Delta= \nabla \cdot \nabla = \nabla^2$ is the Laplace operator and $\nabla$ is divergence operator (also symbolized ""div""), $\nabla$ is the gradient operator (also symbolized ""grad""), and $f(x,y,z)$ is a twice-differentiable real-valued function. The Laplace operator therefore maps a scalar function to another scalar function My question: In this definition, what is the difference between divergence operator and gradient operator both represented by $\nabla$ ?","['multivariable-calculus', 'harmonic-functions']"
3269483,Dominated convergence theorem applied to the convergence of measures,"In this answer there was used the dominated convergence theorem. However, I don't see how it works here. It was said that it can be used with respect to the counting measure because the function $f$ is bounded. Let me restate my question in more general terms: Let $M$ be a countable subset of $\Bbb R$ and $f$ be bounded and continuous. Let $(a(k))_{k\in M}$ and $(a_n (k) )_{k\in  M}$ be sequences of non-negative numbers for fixed $n$ , such that $\sum_{k\in M} a_n (k) = 1, \sum_{k\in M} a(k) = 1$ . Moreover, we assume that $a_n(k) \to a(k)$ for fixed $k\in M$ . As I understood the answer above we then want to infer that $$\sum_{k\in M} f(k) a_n (k) = \int_M g_n (k) \text d \chi (k) \to \int_M g (k) \text d \chi (k) = \sum_{k\in M} f(k) a (k)$$ where $g_n  (k) := f(k) a_n (k)$ and $g(k) := f(k)a(k)$ , and $\chi $ denotes the counting measure. However, the counting measure is not a finite measure, thus $\vert g  \vert \leq \vert f \vert$ is not useful here because $f$ is not integrable, though it is bounded. The integrability here comes from the sequences $a_n$ and $ a$ . But how to make use of it?","['measure-theory', 'probability-distributions', 'weak-convergence']"
3269487,"How to bound $\sum_{ \substack{\mathbf{x} \in \mathbb{Z}^n \\ \mathrm{dist}(\mathbf{x}, B) > \delta }} \frac{1}{\mathrm{dist}(\mathbf{x}, B)^m }$?","I am interested in bounding the following sum $$\sum_{ \substack{\mathbf{x} \in \mathbb{Z}^n \\ \operatorname{dist}(\mathbf{x}, B) > \delta }} \frac{1}{\operatorname{dist}(\mathbf{x}, B)^m },
$$ where $B$ is a compact subset of $\mathbb{R}^n$ and $\operatorname{dist}(x, B)  = \min_{\mathbf{y} \in B} \| \mathbf{x} - \mathbf{y}  \|_{\infty}$ and $\delta > 0$ . I am wondering for what values of $m$ will this sum converge, and how I can show it. Any comments would be appreciated.  Thank you.","['summation', 'elementary-number-theory', 'metric-spaces', 'real-analysis', 'multivariable-calculus']"
3269494,Finding $\lim_{n\rightarrow\infty }\frac{\frac{1}{2}+\frac{\sqrt 2}{3}+\dots+\frac{\sqrt n}{n+1}}{\sqrt n}$,Find $$\lim_{n\rightarrow\infty }\frac{\frac{1}{2}+\frac{\sqrt 2}{3}+\dots+\frac{\sqrt n}{n+1}}{\sqrt n}$$ My work $$\lim_{n\rightarrow\infty }\frac{\frac{1}{2}+\frac{\sqrt 2}{3}+\dots+\frac{\sqrt n}{n+1}}{\sqrt n}=\frac{\sum_{m=1}^n\frac{\sqrt m}{m+1}}{\sqrt n}$$ The series $$\sum_{m=1}^\infty \frac{\sqrt m}{m+1}$$ does not converge so can I say $\lim_{n\rightarrow\infty }\frac{\frac{1}{2}+\frac{\sqrt 2}{3}+\dots+\frac{\sqrt n}{n+1}}{\sqrt n}$ does not exist?,"['limits', 'convergence-divergence', 'sequences-and-series', 'real-analysis']"
3269574,How to get rotational invariance for non-Euclidean metrics?,For the Euclidean distance metric you have invariant length under common rotation. Is this something special to the Euclidean metric or can you define a new special rotation to make something like the Manhattan distance metric also have rotational invariance under the new special type of rotation?,"['geometry', 'metric-spaces']"
3269580,quadratic equation solving mistake,"I'm a student who started self learning quadratic equations for a youth university program. I'm busy at trying to solve such equation: $$
(1 - 4x)^2 + 9x + 7 = 2(x+3)(1-x) + (x+4)^2
$$ this is my current progress: \begin{align}
(1 - 4x)^2 + 9x + 7 &= 2(x+3)(1-x)+ (x+4)^2\\
(1 - 4x)(1 - 4x) + 9x + 7 &= (2x + 6)(1 - x) + (x + 4)(x + 4)\\
1 - 4x - 4x + 16x^2 + 9x + 7 &= 2x - 2x^2 + 6 - 6x + x^2 + 4x + 4x + 16\\
8 + 16x^2 + x &= 2x - x^2 + 6 - 6x + 8x + 16\\
8 + 16x^2 + x &= 4x - x^2 + 22\\
16x^2 + x &= 4x - x^2 + 14\\
16x^2 &= 3x - x^2 + 14\\
17x^2 &= 3x + 14
\end{align} The solutions to this equation are $x = 1,~x=-14/17$ .
So, where is my mistake? $x$ is negative, so I must be incorrect.","['algebra-precalculus', 'quadratics']"
3269617,Can sum of pairwise independent random variables be constant?,"If we consider a set of random variables $X_1$ up to $X_n$ that are independent, then their sum cannot be a constant (given that at least one of them is non-constant). That is not too hard to prove. Does this assertion still hold, if the random variables are just pairwise independent? The answer is yes, if the variances exist. Then the variance of the sum exists and is the sum of the individual variances, hence larger than zero and the sum cannot be constant. However, is it possible to construct a counterexample if we do not require finite variance (or even expectation) and only pairwise independence?","['independence', 'probability-theory', 'probability', 'random-variables']"
3269631,Counting dissimilar championship outcomes,"Let's say we have a football league with 16 teams. At the end of the tournament, we have the first three teams (the gold, silver and bronze medals), the fourth place (let's say this place is also important), the 13th and 14th places that will have to play a few more games to stay in the league, and finally the 15th and 16th places that leave the championship (in this case, the exact position doesn't matter). We consider tournament outcomes to be similar if the outcomes described above are the same. What is the number of dissimilar outcomes? I should note, however, that outcomes are considered similar if the 15th and 16th places are reversed because the order doesn't matter when both teams leave the championship. I know the answer is: $\frac{16!}{8!2!}$ My approach to the problem is that we should count the number of permutations of 16 items 8 of which are considered indistinguishable, as well as 2 that can be reversed. I am not sure that this is correct, but anyway I want to calculate the number of dissimilar outcomes directly. Probably, it makes sense to calculate the number of similar items first. We first count the number in which we can choose 6 teams from 16 (respecting the order) then multiply it by the number of ways to choose 2 more items from the remaining 10. This is the total number of ways to fix the ""important"" positions, which we should also multiply by $8!$ (the number of permutations for the non-important positions). As a result I get a huge number, which is obviously wrong. Seems like I need an explanation. Thanks","['combinatorics', 'discrete-mathematics']"
3269652,$T_pS \subseteq T_pM$: Are tangent spaces of submanifolds subsets (and not embedded) of tangent spaces of the original manifold?,"My book is An Introduction to Manifolds by Loring W. Tu. From Definition 8.1 and Remark 8.2 (and definitions from Section 2. see below), we have that A. $T_pM = T_pU$ B. and $C_p^{\infty}M = C_p^{\infty}U$ , where (B) implies (A). I believe both equalities are really equalities are not isomorphisms (see this question , my previous question and my other previous question ). This question says the differential of inclusion map of smooth manifolds is an inclusion map of tangent spaces. Question 1. If A and B are indeed equalities, then is it really that $T_pS \subseteq T_pM$ (this may or may not be vector subspace, but I think it is) for $S \subseteq M$ a regular/embedded submanifold and not merely that $T_pS$ is (vector space) isomorphic to a vector subspace of $T_pM$ (so $T_pS$ is embedded, in the vector space sense , but probably equivalent to the manifold sense , in $T_pM$ )? Question 2. If A and B are indeed equalities and the answer to (1) is yes, then, then how do we see this from Definition 8.1 and Remark 8.2 with $C_p^\infty S$ and $C_p^{\infty} M$ ? I think I can kind of see this geometrically with $S=S^1$ , $M=\mathbb R^2$ and $p=(1,0)$ with $T_pS^1$ , as the vertical line isomorphic to $\mathbb R$ with $p$ as origin, being a vector subspace of $T_p\mathbb R^2$ , as the plane isomorphic to $\mathbb R^2$ with $p$ as origin but I don't quite see how a map $D:C_p^{\infty}S \to \mathbb R$ is also a map $D:C_p^{\infty}M \to \mathbb R$ . I think we somehow do some kind of smooth extensions, but most of the smooth extensions I've encountered are from open submanifolds or open subsets are not arbitrary regular submanifolds. Maybe $C_p^{\infty} S \supseteq C_p^\infty M$ or something. Question 3. If (A) is merely an isomorphism and not equality, then why exactly? Is it actually that (B) is also merely an isomorphism and not equality, and if so, then why exactly? Note: Other definitions of tangent space of submanifold seem to be explicit in being subsets of tangent spaces (at the same point) of the original manifold. See the (embedded) submanifold part in this question (on immersed submanifolds) . Also: Exercise 11.1 seems to implicitly and casually assume that $T_pS^n \subseteq T_p \mathbb R^{n+1}$ (and so proceeds to discuss a condition on how certain elements of $T_p \mathbb R^{n+1}$ are also elements of $T_pS^n$ ) Section 2 definitions: page 11 , page 12 , page 13 , page 14","['geometry', 'tangent-spaces', 'smooth-manifolds', 'manifolds', 'differential-geometry']"
3269723,$\mathbb E[(X_s-K)^+]\geq\mathbb E[(X_t-K)^+]$ for a martingale with $t<s$,"In a paper the authors use the fact that for a martingale $(X_t)_{t\geq0}$ with $K\geq0$ and $0\leq t<s$ we have the inequality $$\mathbb E[(X_s-K)^+]\geq\mathbb E[(X_t-K)^+]$$ I'm trying to prove this result using Jensen's inequality, since the $(\cdot)^+$ operator is convex, but could show the following inequality: \begin{align}
\mathbb E[(X_s-K)^+]&\geq(\mathbb E[X_s]-K)^+ \\
&= (\mathbb E[\underbrace{\mathbb E[X_s|X_t]}_{=X_t\text{ due to martingality}}]-K)^+ \\
&=(\mathbb E[X_t]-K)^+ \quad(\leq\mathbb E[(X_t-K)^+])
\end{align} Therefore this approach fails. However, since the $\max$ operator is bounded from below by $0$ and it is increasing, we have that the difference between a driftless process and a costant must be increasing as well. Could somebody suggest how to formalize that, please?","['expected-value', 'stochastic-processes', 'probability-theory', 'martingales']"
3269758,Inverse of the fundamental theorem of calculus,"The fundumental theorem of calculus states: if : 1) $f$ was integrable over an interval like $[a,b]$ . 2) $f$ was continuous at $x=c$ , $a<c<b$ . 3) $F(x)= \int_a ^x{f(t)}$ . then: $F'(c)=f(c)$ I wonder if there is any function with following properties : 1) $f$ was integrable over an interval like $[a,b]$ . 2) $f$ was continuous over $[a,b]$ but at $x=c$ , where isn't continuous. 3) $F(x)=\int_a^x{f(t)}$ , and $F$ is differentiable over $[a,b]$ , and $F'(x)=f(x)$ Note: if there was any function like $f$ with above properties, then, $L_1$ and/or $L_2$ wouldn't exist ((event in the cases $L_1=\pm\infty$ and/or $L_2=\pm\infty$ )),  where: $$L_1=\lim_{x \rightarrow c^-} f(x) \quad L_2=\lim_{x \rightarrow c^+}f(x)$$ any response, would be appreciated.","['integration', 'calculus', 'derivatives']"
3269777,Definition of vector fields on submanifolds,"There is a definition in my lecture which I don't really understand: Let $\overline{M}$ be a manifold and $M$ a submanifold. Now I'm ""quoting"" (+translating) the lecture notes: Each vector field $X \in \mathfrak{X}(\overline{M})$ defines a vector field $X_{|M}$ along the inclusion $M \hookrightarrow \overline{M}$ . Define $\overline{\mathfrak{X}}(M)$ as the $C^{\infty}(M)$ module of vector fields along the inclusion $M \hookrightarrow \overline{M}$ . Also, it holds $\mathfrak{X}(M) \subset \overline{\mathfrak{X}}(M)$ . My interpretation: $X \in \mathfrak{X}(\overline{M})$ means that $X$ is a function $\overline{M} \rightarrow T\overline{M}$ . Now $X_{|M}$ is then a function $M \rightarrow \bigcup\limits_{p \in M} T_p \overline{M}$ right? A vector field $X \in  \mathfrak{X}(M) $ is a function $M \rightarrow TM$ . Thus $TM \subset \bigcup\limits_{p \in M} T_p \overline{M}$ , right? Now that's something I don't understand. Shouldn't it be $TM =\bigcup\limits_{p \in M} T_p \overline{M}$ ? I'm not quite sure, if I understand what $\bigcup\limits_{p \in M} T_p \overline{M}$ means. Sorry for my sometimes confusing explanations but maybe still somebody can explain this to me..","['vector-fields', 'submanifold', 'riemannian-geometry', 'differential-geometry']"
3269790,Proving isomorphism of vector fields on a smooth manifold with derivations,"This is problem 19.11 from Loring Tu's An Introduction to Manifolds [1 ed.]. Vector fields as derivations of $C^\infty$ functions. In Subsection 14.1 we showed that a $C^\infty$ vector field $X$ on a manifold $M$ gives rise to a derivation of $C^\infty(M)$ .
We will now show that every derivation of $C^\infty (M)$ arises from one and only one vector field. To distinguish the vector filed from the derivation, we will temporarily denote the derivation arising from $X$ by $\phi(X)$ . Thus, for any $f \in C^\infty(M)$ , $$(\phi(X)f)(p)=X_p f \; \text{for all } p \in M.$$ (a) Let $\mathscr{F} = C^\infty (M).$ Prove that $\phi: \mathfrak{X}(M) \to Der(C^\infty(M))$ is an $\mathscr{F}-$ linear map. (b) Show that $\phi$ is injective. (c) If $D$ is a derivation of $C^\infty(M)$ and $p \in M$ , define $D_p : C_p^\infty(M) \to C_p^\infty(M)$ by $$D_p[f]=[D\tilde{f}]\in C_p^\infty(M),$$ where $[f]$ is the germ of $f$ at $p$ and $\tilde{f}$ is a global extension of $f$ . Show that $D_p[f]$ is well-defined. (d) Show that $D_p$ is a derivation of $C_p^\infty(M)$ . (e) Prove that $\phi : \mathfrak{X} \to Der(C^\infty(M))$ is an isomorphism of $\mathscr{F}-$ modules. I proved (a)-(d), however, I can't figure out how to show the isomorphism in (e). How can we prove surjectivity of the linear map $\phi$ using (c) and (d)?","['smooth-manifolds', 'abstract-algebra', 'linear-algebra', 'manifolds', 'differential-geometry']"
3269796,Change of Base Formula for Exponents,"Most exponent rules have a corresponding log rule and vice versa. For example, $a^b a^c = a^{b + c}$ and $\log_a(bc) = \log_a(b) + \log_a(c)$ . Does the change of base formula $$
\log_a b = \frac{\log_c b}{\log_c a}
$$ have a corresponding exponent form? Edit I'm familiar with the fact that $$
a^b = c^{b\log_c a}
$$ This isn't what I'm looking for, though. In the log change of base formula, there is no mention of exponentiation, only logarithms and division. I'm looking specifically for an identity that allows you to transform an expression like $a^b$ to an exponential expression with a different base, say $c$ , that involves only exponentiation and elementary arithmetic operations.","['algebra-precalculus', 'exponential-function', 'logarithms']"
3269803,Existence of Topologically Transitive Maps on nice Metric Spaces,"Let $(X,d)$ be a separable metric space with no isolated points.  Recall that a continuous function $T:(X,d)\rightarrow (X,d)$ is called topologically transitive if Given $U,V$ non-empty open subsets of $(X,d)$ there is some positive integer $n$ such that $$
T^n(U)\cap V \neq \emptyset
.
$$ My questions are:  does there necessarily exist a topologically transitive function on $(X,d)$ ?  Is there a simple test (by simple I mean something easy to verify like Stone-Weierstrass for linear spaces) to verify if $T$ is topologically transitive of not? Note: If it makes it easier we can also assume that $X$ is a topological group.  (I know this helps when $X$ is the unit circle).","['chaos-theory', 'general-topology', 'topological-dynamics', 'dynamical-systems']"
3269812,Do equal angles necessarily mean a polygon is regular?,"In a polygon, if all the sides are equal, it doesn’t necessarily mean that the polygon is regular (eg. a rhombus). Is this also true for angles? Meaning can you draw a polygon whose interior angles are equal, but the shape is still not regular? I couldn’t think of any examples, but I’m sure there is one.",['geometry']
3269835,A riddle about guessing hat colours (which is not among the commonly known ones),"This is a riddle I heard recently, and my question is if someone happens to know the solution. I'm asking this out of curiosity more than anything else. So here it is. The riddle is one of the countless variations of the ""prisoners have to guess their hat colour"" puzzle. $n$ prisoners are put a hat on top of their head, which can be red or blue. The colours are chosen at random by $n$ independent fair coin tosses. Then each prisoner can guess their own hat colour (red or blue) or pass. The prisoners can see each other, but not hear each other's calls and of course they have no other means of communication. This means that each call can only depend on the other prisoners' hat colours. However, before the distributing of hats begins, the prisoners are told the rules and can agree on a strategy. The prisoners win iff no prisoner guesses wrong and at least one prisoner guesses right. Which strategy should the prisoners use so that the winning probability becomes maximal? Some remarks: A simple strategy is that one player just guesses and all other players pass, so that the maximal probabilty is at least 1/2. For $n=2$ this strategy is optimal. For $n=3$, there is a strategy that wins in 6 out of 8 cases: When a player sees (red,red) he guesses blue, for (blue,blue) he guesses red, and otherwise he passes. More generally this shows that the maximal probability is at least 3/4 for $n\ge 3$. It's possible to show that any strategy fails for at least 2 hat colour configurations (unless $n=1$), which shows that the above strategy is optimal for $n=3$. For $n=4$ there are more than $10^{15}$ strategies, and for $n=5$ it's about $10^{38}$ strategies, making it quite infeasible to just use a brute-force computer program (maybe for $n=4$ it's possible when exploiting the obvious symmetries). When changing the rules slightly by forbidding players to pass, then the maximal winning probability is always 1/2. This is a nice little exercise. Actually I heard the riddle only for $n=3$ and then thought about the general $n$. So it's entirely possible that there is no nice solution.","['puzzle', 'probability']"
3269869,Reference Request - Surface Area as the limit of a sequence of areas of polyhedral approximations,"What is a reference that explains surface area as the limit of a sequence of the areas of polyhedral approximations? (Ideally, it would also explain the Schwarz Lantern .)","['measure-theory', 'geometry', 'reference-request']"
3269894,Density of products of continuous bounded functions,"Let $C_b(X)$ denote the space of continuous and bounded real functions in a topological space $X.$ $C_b(X)$ is a real Banach space with the $\infty$ -norm $$\|f\|_{\infty} = \sup_{x \in X} |f(x)|.$$ Let $C_b(X) \otimes C_b(X)$ be the space of functions in $C_b(X \times X)$ of the form $$f(x, y) = \sum_{i = 0}^{N} g_i(x) h_i(y) \,\text{ for some } N \in \mathbb{N}, \ \,g_i, h_i \in C_b(X) \,\,\, (i = 1, \cdots, N).$$ For the particular case $X = (0, 1]$ with the subspace topology of $\mathbb{R},$ is it true that $C_b(0,1] \otimes C_b(0,1]$ is dense in $C_b((0,1]\times(0,1])$ in the $\infty$ -norm?","['c-star-algebras', 'functional-analysis']"
3269947,Divergence theorem: Simple solid region OR compact region and piecewise smooth boundary,"While searching for the statements of divergence theorem, I came across two different conditions: $(1)$ In wikipedia and proofwiki , it is said that the volume should be compact and boundary should be piecewise smooth. $(2)$ In Stewart's calculus book and this website and a number of websites, it is said that the volume must be simple solid and nothing is said about boundary. So why are there two statements? Which one is more general? Also what exactly is ""piecewise smooth boundary""? I guess it means that the surface $S$ can be broken up into finite number of surfaces $S_1,S_2,S_3,...$ or $S_n$ all of which (considered separately) have a unique tangent plane at every point on each of the surfaces $S_n$ .","['divergence-operator', 'definite-integrals', 'vector-fields', 'multivariable-calculus', 'calculus']"
3269951,Isn't this a trivial corollary?,"Let $U \subseteq \mathbb R^{n}$ be an open subset and let $M \subseteq U$ be a $k$ -dimensional submanifold of $\mathbb R^{n}$ . Consider a differentiable function $f: \ U \longrightarrow \mathbb R$ . There's a corollary that states, that if $f \big|_M$ takes on a local extremum at a point $p \in M$ , then the gradient $\nabla f(p)$ is normal to $M$ at $p$ , i.e. $\nabla f(p) \perp T_{p}M$ , where $T_{p}M$ is the tangent space. I've studied and understood the (short) proof, but isn't this statement absolutely trivial or have I got things mixed up? Let me explain: Assuming $p$ is an extremum, it follows that the differential vanishes, i.e. $\nabla f(p) = 0$ , since this is a necessary condition. But the zero vector is orthogonal to everything. So what's the point of this corollary?","['submanifold', 'orthogonality', 'tangent-spaces', 'derivatives', 'differential-geometry']"
3270000,Can this equation be solved? $x+\sin(x)=\frac{11\pi}{48}$,"So I was revisiting an older problem and seeing if I could solve it in a different way. I boiled the equation down to this: $$x+\sin(x)=\frac{11\pi}{48}$$ I can't imagine how to isolate x, and a number of computer solvers also broke down in the effort. Desmos can solve it, but does not give the precise value. Is there a way to do it? Thanks.",['trigonometry']
3270043,Probability to get twice as many heads as tails at some point in an infinite sequence of coin tosses,"Let consider an infinite sequence of tosses of a fair coin ( $p = 1/2$ to get head or tail). What is the probability to get, at least once, twice as many head as tails? In another words, what is the probability that, there is $n, k \in \Bbb N^*$ such as $H_{3n} = 2n, T_{3n} = n$ (where $H_n$ denote the number of heads, and $T_n$ the number for tails at the $n$ )? What I tried: I don't even know how to start... I tried a lot of things but nothing really worked...","['conditional-probability', 'probability']"
3270075,First-order Differential Equation on Exam Explanation,"I'm taking an elementary differential equations class and we got our first exam back and I don't understand why I was wrong on one of the questions. I got a 96, and the professor said there were quite a few d's and f's, so I didn't want to quibble about this. Anyway, the problem was $\dfrac{dy}{dx} = \dfrac{1}{x+y+2}$ and I chose the sub $u = x+y+2$ , with $ \dfrac{dy}{dx}=\dfrac{dy}{du}\dfrac{du}{dx}=\dfrac{dy}{du}\left(1+\dfrac{1}{u}\right)$ and then plugged in the expression for $\dfrac{dy}{dx}$ , separated the equation and solved for $y$ in terms of $u$ and then substituted back to get $y = \ln (x+y+3)+ c.$ The professor took issue with my expression for $\dfrac{dy}{dx}$ , saying that I couldn't differentiate $y$ w.r.t. $u$ if $y$ is part of $u.$ Is this correct?",['ordinary-differential-equations']
3270101,Why the existence and uniqueness of solution of ODE implies existence of $n$ independent solution of $\dot x=A(t)x$ where $A$ is periodic?,"Let $A(t)\in \mathcal M_{n\times n}(\mathbb R)$ periodic, i.e. $$\exists \quad T>0:\forall t\in \mathbb R, A(t+T)=A(t).$$ Consider the system $$ \dot x(t)=A(t)x(t),\quad x(t)\in \mathbb R^n.$$ It's written in my course that if $t\mapsto A(t)$ is continuous, the existence and uniqueness theorem for ODE implies the existence of $n$ linearly independents solutions. I don't understand in what this ""existence and uniqueness theorem for ODE"" implies existence of $n$ linearly independents solution. Could someone explain why ? This theorem says (more or less) : If $F:\mathbb R\times \mathbb R^n\to \mathbb R^n$ is locally Lipschitz w.r.t. the second variable, then the Cauchy problem $$\begin{cases}\dot x(t)=F(t,x(t))\\ x(0)=x_0\end{cases}$$ has a unique (local) solution. So indeed, we take $F(t,x)=A(t)x$ which is obviously globally Lipschitz. But in one case we have a Cauchy problem, and in the other case we have an ODE without initial condition.","['linear-algebra', 'ordinary-differential-equations', 'real-analysis']"
3270109,What is the fibered coproduct of abelian groups?,"From wikipedia: I am not sure I understand this. For example: Suppose we have $\alpha: \mathbb Z/(3) \to \mathbb Z/(6)$ where $$0\mapsto 0, \quad 1 \mapsto 2, \quad 2 \mapsto 4,$$ and we have $\beta: \mathbb Z/(3) \to \mathbb Z/(9)$ where $$0\mapsto 0, \quad 1 \mapsto 3, \quad 2 \mapsto 6.$$ Then we want the subgroup of $\mathbb Z/(6) \oplus \mathbb Z/(9)$ consisting of $(0,0), (2,-3), (4, -6)$ ? Why? Why $(\alpha(z), -\beta(z))$ ? Why the negative $\beta(z)$ ? How do we know the pairs consisting of $(f(z), -g(z))$ will always be a subgroup?","['group-theory', 'abstract-algebra', 'abelian-groups', 'category-theory']"
3270130,Use Fatou Lemma to show that $f$ takes real values almost everywhere.,"Let $(f_n)$ be a sequence in $L^p$ such that for each positive integer $n$ , $
\| f_{n+1}-f_n\|_{p}
<\frac 1{2^n} 
$ .
  Define $f: X \to [0,\infty]$ with $$
f(x)= \sum_{n=1}^\infty| f_{n+1}(x)-f_n(x)|.
$$ Use Fatou Lemma to show that $f$ takes real values almost everywhere. My thoughts: We must show the existence of $A$ such that $\mu(A)=0$ and for all $x\in A^C$ , $f\in\mathbb R$ using Fatous Lemma which states $$
\int_X\liminf_nf_n
\le\liminf_n\int_X f_n.
$$ My idea taking pieces of the completeness proof of $L^p$ is that we have that the series $f(x)=\displaystyle\sum_{n=1}^\infty\vert f_{n+1}(x)-f_n(x)\vert$ converges so $f(x)=\displaystyle\sum_{n=1}^\infty\vert f_{n+1}(x)-f_n(x)\vert<\infty$ and this holds for all $x\in X$ and then how will I define the set $A$ ? I am not using at all Fatou Lemma because I don't know how. [Added later:] I would also like to understand steps of the proof in Alex R.'s answer below. It is shown that $$\int_A|f(x)|^pd\mu\leq \liminf_m\int_A|F_m(x)|^p dx\leq\liminf_m\sum_{n=1}^m\frac{1}{2^{pn}}d\mu<\infty.$$ There are a lot of missing steps. I tried to fill. $\displaystyle\int_A\vert f(x)\vert^pdx
=\int_A|\liminf_mF_m(x)|^pdx=\int_A\liminf_m|F_m(x)|^pdx\le\liminf_m\int_A|F_m(x)|^pdx
=\liminf_m\int|\sum^m_{n=1}|f_{n+1}(x)-f_n(x)||^pdx
\fbox{=}\liminf_m\sum^m_{n=1}\int_A|f_{n+1}(x)-f_n(x)|^pdx
=\liminf_m\sum^m_{n=1}||f_{n+1}(x)-f_n(x)||_p^p\le\liminf_m\sum^m_{n=1}\frac{1}{2^{np}}\fbox=?$ Question1: Assuming the equalities and inequalities are correct, Why is the second equality, the boxed equality and what is equal in the last boxed equality? It is also shown that Taking $A$ to be $\mathbb{R}$ , it follows that $\int_A|f(x)|^pd\mu<\infty$ which implies $\mu(\{|f|=\infty\})=0$ . Question2: Should not have been written as Take $A$ to be $\mathbb R.$ From all the arguments above (and not only $A=\mathbb R$ ), it follows that $\int_A|f(x)|^pd\mu<\infty$ which implies $\mu(\{|f|=\infty\})=0$ ?? Seems like as it originally stands, the affirmation depends only on $A=\mathbb R$ . But it is independent of taking $A$ as $\mathbb R$ . Am I correct?","['measure-theory', 'proof-explanation', 'real-analysis', 'lp-spaces', 'functional-analysis']"
3270153,Is sample variance always less than or equal to population variance,"I was reading this wikipedia article on Bessel's correction: https://en.wikipedia.org/wiki/Bessel%27s_correction .  The article says that sample variance is always less than or equal to population variance when sample variance is calculated using the sample mean.  However, if I create a numpy array containing 100,000 random normal data points, calculate the variance, then take 1000 element samples from the random normal data, I find that many of my samples have a higher variance than the 100,000 element population. import numpy as np

rand_norm = np.random.normal(size=100000)

# save the population variance
pop_var = np.var(rand_norm, ddof=0)

# execute the following 2 lines a few times and and I find a variance of the 
# sample that is higher than the variance of rand_normal
samp=np.random.choice(rand_norm, 1000, replace=True)

# calculate the sample variance without correcting the bias (ddof = 0) 
# I thought that the variance would always be less than or equal to pop_var.
np.var(samp,ddof=0) Why am I getting sample variance which is greater than the population variance?","['statistics', 'python']"
3270157,Why is boundedness sufficient for well-definedness,"Let $p, q \in {]1,\infty[}$ where $\frac{1}{p}+\frac{1}{q}=1$ and define $J\colon L^{q} \to (L^{p})^{*}, f \mapsto \ell_{f}: L^{p} \ni g\mapsto \ell_{f}(g)=\int_{X}fg\,d\mu$ My question is related in general to the notion of well definedness for operators. In particular, why is it sufficient for an operator to be considered well-defined, when we can show that for any $f \in L^{p}$ that $\|\ell_{f}\|_{*}<\infty$ . In my previous, elementary versions of well-definedness, we defined it as for any $f \in L^{q}$ there exists exactly one $\ell\in (L^{p})^{*}$ so that $Jf=\ell$ . Now showing that $\| Jf\|_{*}<\infty$ definitely shows that $Jf \in (L^{p})^{*}$ but it does not show that there is a unique $\ell \in (L^{p})^{*}$ so that $Jf=\ell$ . In other words, there may exist another $m \in (L^{p})^{*}$ where $m\neq \ell$ so that $m = Jf$ and $\ell = Jf$ . I thought that this was the point of proving well-definition. Why is it always reduced to the idea that well-definition depends only on whether $\|\ell_{f}\|_{*}<\infty$ ? Any clarity on this topic will help me greatly.","['riesz-representation-theorem', 'real-analysis', 'lp-spaces', 'functional-analysis', 'dual-spaces']"
3270183,Concentration inequality for $k$-dependent Bernoulli r.v.s,"Given $X_1,X_2, \cdots$ are iid $Ber(p)$ , and we define $$Z_1 = X_1X_2\cdots X_k\\ Z_2 = X_2 X_3 \cdots X_{k+1}\\ \cdots$$ Is there a concentration inequality (like Hoeffding's inequality) for $$\mathbb{P}\bigg(\sum_{i=1}^n Z_i - \mathbb{E}\Big[\sum_{i=1}^n Z_i\Big]\geq t\bigg) \leq e^{(\cdots)}?$$","['concentration-of-measure', 'probability-theory', 'probability']"
3270210,Show that $\text{Spec }A^G$ is the quotient of the affine scheme $\text{Spec }A$ by a finite subgroup of automorphisms $G$,"Let $X=\text{Spec }A$ be an affine scheme, and $G$ a finite subgroup of automorphisms of $X$ . Show that $\text{Spec }A^G$ is $X/G$ , with $\pi: X\to X/G$ given by the natural inclusion. That is, we need to show $\text{Spec }A^G$ satisfies the universal property of the quotient, where $A^G$ is the fixed ring of automorphisms, and the universal property is that (A) $\pi\circ g=\pi$ for all $g\in G$ , and (B) If $Y$ is any scheme and $\phi :X\to Y$ a morphism of schemes such that $\phi\circ g=\phi$ for all $g\in G$ , then it factors through $\text{Spec }A^G$ . Now, if $Y$ is affine, I think the problem is easy. Since the (antiequivalent) fact is true at the level of rings, then it must be true at the level of affine schemes. That is, if $\psi:B\to A$ satisfies $g\psi(b)=\psi(b)$ for all $g$ , then there's a well-defined map $\theta:B \to A^G$ with $\theta(b)=\psi(b)$ that clearly commutes with the inclusion. However, I'm stuck for when $Y$ is non-affine. The question hints that you should use Prime avoidance, and I think this is used in showing that the fibres consist of the orbits, but I don't know exactly what I am supposed to show. I added this later, and I'd welcome any corrections, or plainly telling me if I am wrong: First let us investigate the fibres of the map $\pi$ . The inclusion $A^G\hookrightarrow A$ is integral, since every element of $z\in A$ satisfies an equation of the form $\prod_{g\in G}(x-gz)$ . Hence, each fiber is non-empty by the Lying Over Theorem. Now if we have two primes in the same fibre, that is $P\cap A^G=Q\cap A^G$ , then $P\subseteq \bigcup_{g\in G}gQ$ since if $p\in P$ , then $\prod_{g\in G} gu \in P\cap A^G=Q\cap A^G$ , so some factor $gu$ must be in $Q$ . By prime avoidance, $P\subseteq gQ$ for some $g$ , and again by integrality (or even by symmetry) we can conclude $P=gQ$ . Suppose $\phi:\text{Spec } A\to Y$ is a morphism of schemes satisfying $G$ -invariance as above. I think the most logical way is to define a map $\bar{\phi}:\text{Spec }A^G\to Y$ set theoretically as $\bar\phi(P)=\phi(P)$ . Then to show it is continuous, it would be enough to prove that $\pi$ is a closed map, since $\bar\phi^{-1}(C)$ for some closed set $C\subseteq Y$ is precisely ${\pi(\phi^{-1}(C))}$ . For this, it would be enough to show that, if $\phi^{-1}(C)=V(a)$ for some ideal $a\subseteq A$ , then $V(a\cap A^G)\subseteq\pi(V(a))$ , (since we have the equality $V(a\cap A^G)=\overline{\pi(V(a))}$ ). But this is true by the Lying Over theorem argument. Therefore $\bar\phi$ is continuous. Finally, notice that for $f\in A^G$ , we have that the localization $(A^G)_f=(A_f)^G$ , therefore $\mathcal O_{\text{Spec }A^G}=\pi_*(\mathcal O_{\text{Spec }A})^G$ . Hence the map $\mathcal O_Y\to \phi_*(\mathcal O_{\text{Spec }A})^G=\bar\phi_*\pi_*(\mathcal O_{\text{Spec }A})^G=\bar\phi_*\mathcal O_{\text{Spec }A^G}$ already exists and canonically gives a morphism of sheaves $\mathcal O_Y\to \bar\phi_*\mathcal O_{\text{Spec }A^G}$ that finishes our morphism of schemes.","['algebraic-geometry', 'schemes', 'quotient-spaces']"
3270231,Prove that $\hat{\sigma^2}=\frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2$ is not an efficient estimator.,"I am asked to show that the unbiased estimator $\hat{\sigma^2}=\frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2$ is not efficient. So far I was able to show that the Rao-Cramer Lower Bound is $\frac{2\sigma^4}{n}$ so I know that I need to find $Var[\hat{\sigma^2}]>RCLB$ . What I have tried here is to simply plug it in using the identity $$\sum_{i=1}^n (X_i-\bar{X})^2 = \sum_{i=1}^n X_i^2 - n\bar{X}^2$$ What makes me uncomfortable is that unlike expectation, I need to know whether these two terms are independent or not, and I do not know how to find $Var[\bar{X}^2]$ even if they were. I also tried to express the sum of square as $$\sum_{i=1}^n (X_i-\mu +\mu-\bar{X})^2 = \sigma^2 \left[ \sum_{i=1}^n\left(\frac{X_i-\bar{X}}{\sigma}\right)^2 - 2\left(\frac{X_i-\bar{X}}{\sigma}\right)\sum_{i=1}^n\left( \frac{X_i-\mu}{\sigma} \right) + n\left( \frac{\bar{X}-\mu}{\sigma} \right)^2 \right]$$ hoping that $\chi_{n}^2$ and $N(0,1)$ could come into play but I face the same issue again. I would appreciate your input.","['statistics', 'variance', 'parameter-estimation']"
3270233,Operator core of Dirichlet Laplacian,"I am reading Reed-Simon Vol. 4, page 274. We have the following situation:
Let $\Omega \subset \mathbb R^m$ be an $m$ -dimensional cube and consider the Dirichlet-Laplacian $-\Delta_D=\Delta_D^\Omega$ with quadratic form domain $H^1_0(\Omega)$ . $\textbf{Proposition. }$ The set $D_D := \{f: f\in C^\infty(\Omega),  f {\restriction}_ {\partial\Omega} = 0 \}$ is an operator core for $-\Delta_D$ and for all $f\in D_D$ , $$-\Delta_D f = -\sum_{i=1}^n \frac{\partial^2}{\partial x_i^2} f.$$ In the proof of this proposition they state the following: Let $A$ be the operator $-\Delta$ with domain $D_D$ . $A$ is clearly symmetric, and by separation of variables (multiple Fourier series) we can find a complete orthonormal basis of eigenfunctions $\{ \varphi_n \}$ for A. If $A\varphi_n = \lambda_n \varphi_n$ , it is easy to see that $\varphi \in D(\overline{A})$ if and only if $\sum \lambda_n^2 \lvert (\varphi_n, \varphi) \rvert^2 < \infty$ ; and from this we conclude that $\overline{A}$ is self-adjoint. Can someone explain this paragraph to me? Two pages later they explicitly give the eigenbasis so I'll count that as an explanation, but the next thing is what I don't see so easily. Why does the ""if and only if"" hold and why can one conclude that $\overline{A}$ is self-adjoint? Book excerpt (thanks to Keith McClary).","['operator-theory', 'spectral-theory', 'functional-analysis', 'partial-differential-equations']"
3270235,$\sin(\frac{\pi}{n})\sin(\frac{2\pi}{n})...\sin(\frac{(n-1)\pi}{n})=\frac{n}{2^{n-1}}$ [duplicate],This question already has answers here : Prove that $\prod_{k=1}^{n-1}\sin\frac{k \pi}{n} = \frac{n}{2^{n-1}}$ (3 answers) Closed 5 years ago . Prove that $$\sin\left(\frac{\pi}{n}\right)\sin\left(\frac{2\pi}{n}\right)\sin\left(\frac{3\pi}{n}\right).....\sin\left(\frac{(n-1)\pi}{n}\right)=\frac{n}{2^{n-1}}$$ Is there a proof without using complex numbers and $n-th$ roots of unity.,"['algebra-precalculus', 'trigonometry']"
3270253,Deriving Bachet's duplication formula,"Let $y^2-x^3 = c$ be Bachet's equation and pretend $(x,y)$ is a solution. The tangent at $(x,y)$ of Bachet's curve is going to intersect it in a unique new point whose coordinates are supposed to yield the so-called ""duplication formula"": $(\frac{x^4-8cx}{4y^2},\frac{-x^6-20cx^3+8c^2}{8y^3})$ I have not been able to re-derive this formula no matter how hard I try. It just won't work. Attempt: Let $f(x,y)=y^2-x^3-c$ , then the curve is implicitly parametrized by $f(x,y)=0$ .
The gradient of $f$ at $(x,y)$ , which is $(-3x^2,2y)$ , is orthogonal to the curve at $(x,y)$ . Therefore, the equation of the tangent is $-3x^2(X-x)+2y(Y-y) = 0$ (I'm looking at the only line orthogonal to the gradient at $(x,y)$ going through $(x,y)$ ) So, if $(X,Y)$ is the coordinates of the point of intersection I'm looking for, it should be the unique solution (different from $(x,y)$ ), of the following conditions: $-3x^2(X-x)+2y(Y-y) = 0$ and $Y^2 - X^3 - c = 0$ with the assumption that, of course, by hypothesis, $y^2 - x^3 = c$ Is my reasoning sound until now? Mathematica does not seem to agree with me, but it could be that the full-simplify function isn't sophisticated enough (it does not reduce to Bachet's formula) FullSimplify[Solve[{2*y*(Y - y) - 3*x^2*(X - x) == 0,
    Y^2 - X^3 - c == 0}, {X, Y}], y^2 - x^3 == c] I'm not expecting anybody to actually carry out the tedious calculations, though if somebody can manage to make Mathematica or some other software spit out the formula on its own I would be happy as I am trying to program an algorithm which automatically takes a curve in and finds the formula","['proof-verification', 'elliptic-curves', 'differential-geometry']"
3270265,Olympiad level | Similar Triangles,"The bisector of angle $BAD$ in parallelogram $ABCD$ intersects the lines $BC$ and $CD$ at the points $K$ and $L$ respectively. Prove that the center of the circle passing through the points $C$ , $K$ , and $L$ lies on the circle passing through the points $B$ , $C$ , and $D$ . I noticed there're three isosceles triangles that I could think of: $\triangle{ABK}$ , $\triangle{KCL}$ and $\triangle{ADL}$ . Now, to show that they're similar: $\angle{ABK}=\angle{ADL}$ as $ABCD$ is a parallelogram, furthermore, since $KC||AD$ , $\angle{ADL}=\angle{KCL}$ . 
Also, $\angle{BAK}=\angle{LAD}$ as $AK$ is angle bisector. Since $KC||AD$ , $\angle{LKC}=\angle{LAD}$ . Thus, $\triangle{ABK}\sim\triangle{LDA}\sim\triangle{LCK}$ by AA similarity. But I still haven't proven that the triangles are indeed isosceles and where do I go from here?","['contest-math', 'euclidean-geometry', 'quadrilateral', 'circles', 'geometry']"
3270317,"For sufficiently small arguments, why does change of function has the same sign as differential?","From I. M. Gelfand, S. V. Fomin - Calculus of Variations (2000) page 13: ""A necessary condition for the differentiable functional $J[y]$ to have an extremum for y = y_0 is that its variation vanishes for $y = y_0$ ,
i.e., that $\delta J[h] = 0$ for $y = y_0$ and all admissible $h$ ."" He proceeds proving the following theorem by the following argument. ""To be explicit, suppose $J[y]$ has a minimum for $y = y_0$ .
According to the definition of the variation $\delta J[h]$ , we have $\Delta J [h] = \delta J[h] + \epsilon ||h||$ , where $\epsilon \to 0$ as $||h|| \to 0$ . Thus, for sufficiently small $||h||$ the sign of $\delta J[h]$ will be the same as the sign of $\Delta J[h]$ . "" I have trouble understanding the last statement. I understand that for $J[y]$ to have a minimum we have by definition that there is some $\delta>0$ such that for all $||h|| < \delta$ we have $\Delta J[h] \geq 0$ . So I would like to find $\delta_2 > 0$ that would guarantee me that $\delta J[h] \geq 0$ for all $||h|| <$ min $(\delta_1, \delta_2)$ . Unfortunately, I don't see how. I feel like we have to assume continuity of $J[y]$ but I am not positive. Any help or suggestions are appreciated!","['limits', 'derivatives']"
3270346,interchanging limits in something like a Riemann sum,"I got this problem thats been bothering me. How can I interchange those limits D: $\lim_{n \to \infty} \sum_{k=1}^{\infty}\frac{n}{n^{2}+k^{2}}=\lim_{n \to \infty}[ \lim_{m \to \infty} \frac{1}{n}\sum_{k=1}^{m}\frac{1}{1+(\frac{k}{n})^{2}}]$ . Now I know that theres something wrong cause I need to interchange the limits but even if I could I'd get something with not so much sense cause, what do I do with that $m$ , I was thinking in creating a sequence but I couldnt see it. So, any help would be really appreciated! :D","['integration', 'measure-theory', 'real-analysis']"
3270426,How to show that $\pi^\pi$ is not a integer?,"This goes without saying, but, I can't use a calculator to evaluate $\pi^\pi$ . I think we need to find a integer $x$ such that $$x<\pi^\pi < x+1. \tag{1}$$ However, since I have no ideia what $\pi^\pi$ looks like, probably I will not find $x$ , but if I can prove that such integer $x$ exists, will be enough. But this seems like a difficult problem. I can use a calculator for other things, for example: evaluating $\pi,\pi^2,e^{27}$ or $\log,  \sin$ etc. I tried taking the $\log$ base $\pi$ in $(1)$ to simplify $\pi^\pi$ to just $\pi$ . Maybe this approach is a wrong one. This is not a ""homework problem"", is just something that I found it interesting to do and learn more. I'll appreciate any insight and improved tags. Thanks! Also, I don't think using a power series for $\pi^x$ is fair, because that's how calculators find the number in the first place. What about $\pi^{\pi^{{\pi}^{\pi}}}$ ? This is an open problem, so I wanted to see if there's a way to prove that $\pi^\pi$ is not integer in a more ""analytical way"" but also using mathematical softwares if needed, but thanks for the answers.","['number-theory', 'pi', 'elementary-number-theory', 'exponentiation']"
3270486,A small help needed in proving a smart part of a result - to show that we need at least 2r-3 vertices to construct a particular type of graph.,"I am given a graph $G$ with diameter two. I have to prove that I have to add minimum $2r-3$ vertices to $G$ to form a graph $H$ such that $H$ contains exactly two vertices with eccentricity $r+1$ (obviously peripheral vertices) and rest with eccentricity $r$ (central vertices), where $r\geq 4$ . Also, $G$ is induced in $H$ . I am stuck at a particular part of the proof. Since diameter of $G$ is two, $G$ can at the most contain one diametral vertex or at the most one vertex with eccentricity $r+1$ . I divided the proof in two cases. In first part, $G$ contains a vertex with eccentricity $r+1$ . This part has been proved by me. In second case, $G$ does not contain a vertex with eccentricity $r+1$ and I am stuck in this case. However, I tried to prove it, but I am feeling that it is not surely true. In the following attempt I consider a $z-w$ walk of length $r$ but I feel it is wrong as we already get a $z-w$ path of length $r$ lying on $x-y$ path since $z$ is adjacent to $x$ . MY ATTEMPT: Let $P$ be a diametral path in $H$ of length $r+1$ with end vertices $x$ and $y$ ( $x,y\notin G$ ). Since $diam(G) =2$ , at the most 3 vertices of $G$ can lie on $P$ and thus $P$ contains at least $r-1$ new vertices. Since $r\geq 4$ , $r+1\geq 5$ and $P$ contains at least six vertices. If $x$ and $y$ are  end vertices of $P$ which are not in $G$ then there exists $z\notin V(G)$ and $x\sim z$ or $y\sim z$ .
Without loss of generality, let $x\sim z$ . Since $e(z)=r$ , there exists a $z-w$ path $P_2$ such that $l(P_2)=r =d(z,w)$ . Now, the path $P$ can not be extended, otherwise $d(x,y)>r+1$ ,
and $P_2$ contains at most three vertices from $G$ . This follows that at least $r-2$ vertices in $P_2$ are not in $G$ .
This proves that we need to add at least $(r-1) +(r-2) = 2r-3$ new vertices. Is this proof correct? I feel this proof is still incomplete. Somewhere I feel that I am missing some part. Kindly help me. Thanks a lot for your time and help. P.S. It might be possible that $P$ and $P_2$ intersect at many vertices. In that case how to prove the result. ---------------------------------------------------- Added one more point in the proof (edited proof) $G$ does not contain any diametral vertex. Since $diam(G) =2$ , here also $P$ contains at least $r-1$ new vertices. Since $r\geq 4$ and $r+1\geq 5$ , $P$ contains at least six vertices. If $x$ and $y$ are  end vertices of $P$ which are not in $G$ then there exists $z\notin V(G)$ and $x\sim z$ or $y\sim z$ .
Without loss of generality, let $x\sim z$ . Since $e(z)=r$ , there exists a $z$ -- $w$ path $P_2: z,w_1,w_2,\ldots,w_r=w$ such that $l(P_2)=r =d(z,w)$ .
Now, the path $P$ can not be extended, otherwise $d(x,y)>r+1$ .
Now, the $P_2$ contains at most three vertices from $G$ since $diam(G) =2$ .
Further, if $P_2$ intersect vertices of the $P$ then $d(z,w)<r$ , which
is a contradiction because $e(z) = r$ . This follows that at least $r-2$ vertices in $P_2$ are not in $G$ .","['graph-theory', 'proof-writing', 'combinatorics', 'discrete-mathematics']"
3270504,Prove $\log|e^z-z|\leq |z|+1$,"Prove that $\log|e^z-z|\leq |z|+1$ where $z\in\mathbb{C}$ with $|z|\geq e$ . Background: This is from a proof that $e^z-z$ has infinitely many zeroes. The present stage is that we assumed in contradiction that $e^z-z$ hasn't any zero. My attampt: I assume that the meaning of $\log$ here is the principal branch of $\log$ . We know that $|w|\in\mathbb{R} ,\ \forall w\in\mathbb{C}$ . Because $\log$ is increasing in $\mathbb{R}^+$ and according to the triangle inequality we get $$\log|e^z-z|\leq\log(|e^z|+|z|)$$ But I'm not sure how to proceed. Thanks.","['complex-analysis', 'inequality', 'logarithms']"
3270506,continuity of a multivariable function at a point,"I want to know whether the function $\dfrac{x^2y}{x-y}$ is continuous at $(0,0)$ or not.
when I switch to polar coordinate i get the limit of : $\dfrac{(r \cos^2 \theta \sin \theta)}{\cos \theta - \sin \theta}$ when r is going to zero.
can I say that this limit does not exist because there are points where $\theta = \dfrac{\pi}{4}$ and then the denominator is zero, and therefore the function is not continuous at $(0,0)$ ?
the value of the function when x is equal to y is 0
thank you","['continuity', 'multivariable-calculus']"
3270526,Generating polygons with integer coordinates bounding a circle,"I've been trying to find an algorithm to generate polygons with integer coordinates bounding a circle from the inside and outside. I searched everywhere and couldn't find anything like this. For example in the picture below we have the red circle with a given radius, and ask for polygons with 8 points, and then the algorithm should generate the blue and green polygons. These polygons aren't exactly regular, and I don't think these polygons are uniquely defined either as there are probably different ways to ""best"" fit the circle. I'm not really looking for the absolute best solution for example I could try to minimize the maximum error, but that might make the problem much more complicated. Actually I tried expressing this as an integer programming problem with quadratic Diophantine inequalities but that seems to be overkill. Is this a problem that has been already studied/solved before? Am I missing a simple method?","['computational-geometry', 'discrete-geometry', 'geometry', 'algorithms']"
3270550,Unable to apply transformation of function $f(x)$ with $g(x)=-f(-x)$.,"The problem is taken from the chap. 1.1 of the book titled : Calculus Problems for the new century, by Robert Fraga. A function $f$ has values $f(0) =3, f(2)=1$ , is piecewise linear, & has the slope $-1$ if $x\lt 0$ and $1$ if $x\gt 2$ . Sketch the graph of the function $g$ defined by each of the following rules. a. $\,\,\,g(x)=f(x)$ b. $\,\,\,g(x)=-f(-x)$ c. $\,\,\,g(x)=f(x+2)$ d. $\,\,\,g(x)=f(2x)$ e. $\,\,\,g(x)=f(3x-6)$ I have prepared solutions, which are not matching in part (b) (& have confusion for part (e)) with the book's solutions, which are given in terms of graphs. The book's solutions are shown below: My solutions: I assume that the curve is connected between the points $x=0$ and $x=2$ . The equation of the curve will be given by : Part (a): (i) $y = -x+3,\,\,\, x\le 2$ (ii) $y = x-1,\,\,\, x\gt 2$ For Part (b), my graph is wrong, as per the solution given. Part (b): (i) $y=-(x+3),\,\,\, -(-x)\le -2$ $\implies y= -x-3,\,\,\, -x \ge 2$ $\implies y= -x-3,\,\,\, x \le -2$ (ii) $y = -(-x-1),\,\,\, -(-x)\gt -2$ $\implies y = x+1,\,\,\, -x\lt 2$ $\implies y = x+1,\,\,\, x\gt -2$ For Part (c), my graph is correct, as per the solution given; as the solution shows the ordinate axis starting from $y=1$ . Part (c): (i) $y = -(x+2)+3,\,\,\, x+2\le 2\implies y = -x+1,\,\,\, x\le 0$ (ii) $y = (x+2)-1,\,\,\, (x+2)\gt 2\implies y = x+1,\,\,\, x\gt 0$ For Part (d), my graph is correct, as per the solution given; as the solution shows the ordinate axis starting from $y=1$ . Part (d): (i) $y = -2x+3,\,\,\, 2x\le 2\implies y = -2x+3,\,\,\, x\le 1$ (ii) $y = 2x-1,\,\,\, 2x\gt 2\implies y = 2x-1,\,\,\, x\gt 1$ For Part (e), the solution given is not clear about minimum value of function being $1$ ; hence unsure. Part (e): (i) $y = -(3x-6)+3= -3x+9,\,\,\, 3x-6\le 2\implies y = -3x+9,\,\,\, x\le 2\frac 23$ (ii) $y = 3x-7,\,\,\,  3x-6\gt 2\implies y = 3x-7,\,\,\,  x\gt 2\frac 23$ Edit : Have found the correct solution in part (b) by only affecting the domain with change of $x$ by $-x$ to get equations: Part (b): (i) $y=-(x+3),\,\,\, (-x)\le 2$ $\implies y= -x-3,\,\,\, x \ge -2$ (ii) $y = -(-x-1),\,\,\, (-x)\gt 2$ $\implies y = x+1,\,\,\, x\lt -2$ But, seems like am missing theory as why for $g(x)=-f(-x)$ only the domain is affected by exchanging $x$ by $-x$ ; even though it means that the whole function is also negated.","['functions', 'graphing-functions']"
3270656,Do products preserve colimits in the category of locales?,"Does the functor $X\times-:\mathbf{Loc}\to\mathbf{Loc}$ preserve small colimits for all locales $X$ ? The reason that I'm interested in this question is that the same property fails in the category of topological spaces. If products preserve colimits in a total category then it must be cartesian closed. The category $\mathbf{Top}$ is total, but fails to be cartesian closed because products don't preserve colimits. So it would be curious if $\mathbf{Loc}$ failed to be cartesian closed for the complementary reason. It's not total, so maybe products do preserve colimits in $\mathbf{Loc}$ ? Another reason to ask this question is that the definition of ""locale"" requires precisely that products preserve colimits in its frame of opens. So it would be interesting if this property was mirrored at the category level.","['general-topology', 'limits-colimits', 'locales', 'category-theory']"
3270709,A finite union of infinite cyclic subgroups of a group $G$ is never a group.,"$\mathbf{Question}$ : Consider an infinite group $G$ . Let $\langle a_1\rangle , \langle a_2\rangle, \ldots, \langle a_m\rangle $ ( $\langle a_i\rangle =C_i$ ) be a finite collection of infinite cyclic subgroups of $G$ such that $C_i \not\subset C_j$ for $i \neq j$ . Then $\displaystyle\bigcup_{i=1}^mC_i$ is never a subgroup of $G$ . ( $m>1$ ) $\mathbf{A \ restricted \ version:}$ Consider an infinite commutative group $G$ . Let $<a_1>, <a_2>, ..., <a_m>$ ( $<a_i>=C_i$ ) be a finite collection of infinite cyclic subgroups of $G$ such that $C_j \not\subset \displaystyle\bigcup_{I \setminus \{j\}}C_i$ , $I=\{1,2,3,...,m\}$ . Then $\displaystyle\bigcup_{i=1}^mC_i$ is never a subgroup of $G$ . ( $m>1$ ) I don't know how to proceed. Any help would be appreciated.","['group-theory', 'cyclic-groups']"
3270711,Probability of passing the exam,"The exam consists of 5 questions. All of those 5 questions are randomly picked (without repetitions) from a pool of 41 questions. Knowing that I know answers to 35 out of 41 questions from the pool (that is: I don't know how to solve 6 out of 41 questions), what is the propability that I will fail the exam? (Assume that one must answer all 5 exam questions correctly to pass). I haven't been introduced to propability mathematics yet, I am just curious. My attempt: Chance that first question is ""good"" (I know how to answer the question) is $\frac{35}{41}$ . But the chance that the second question is ""good"" is either $\frac{34}{40}$ or $\frac{35}{40}$ depending whether the first question was good or not. How to tie up everything together? Is the propabiltiy of succeeding simply: $$p_{succ} = \frac{35}{41} \frac{34}{40} \frac{33}{39} \frac{32}{38} \frac{31}{37} = ~0.432$$ and therefore failure propability: $$p_{fail} = 1 - p_{succ} = ~0.568$$ ?","['proof-verification', 'discrete-mathematics']"
3270756,Cocycles and group extensions,"I'm trying to understand how elements in the second cohomology group with coefficients in some other group correspond to group extensions. This is what I understand: Suppose we have two (countable) abelian groups $G,H$ . The second cohomology group $H^2(G,H)$ is defined as the group of all functions (cocycles) $c:G\times G\rightarrow H$ with the property that for all $g_1,g_2,g_3\in G$ $$c(g_1+g_2,g_3)+c(g_1,g_2) = c(g_2,g_1+g_3)+c(g_1,g_3)$$ Modulo functions (coboundaries) of the form $c(g,h) = f(g+h)-f(g)-f(h)$ for any $f:G\rightarrow H$ . Now any element $c\in H^2(G,H)$ defines a group extension $G\times_c H$ which is defined as the cartesian product of $G$ and $H$ with the multiplication $$(g,h)+ (g',h') = (g+g',c(g,g')+h+h')$$ If $c$ is a coboundary then one can prove easily that $G\times_c H$ is isomorphic to $G\times H$ (the usual product) with the isomorphism $(g,h)\mapsto (g,f(g)+h)$ . Note moreover, that the extension is abelian if $c(g_1,g_2) = c(g_2,g_1)$ (in fact, if there exists a co-boundary $d$ such that $c+d$ satisfies the above). I have the following questions I showed that if $c$ is a coboundary then $G\times_c H\cong G\times H$ . More generally one can show that if $c-c'$ is a coboudnary then $G\times_c H \cong G\times_{c'} H$ . Is this an if and only if? I mean, if $G\times_c H \cong G\times_{c'} H$ does it mean that $c-c'$ a coboundary? [As far as I understand this should be true, but I don't manage to prove it] It is well known that the group $\mathbb{Q}$ is injective (because it is divisible). This means that any abelian extension of $\mathbb{Q}$ splits. In other words, if the answer for $1$ is yes, then this would imply that any abelian cocycle $c:G\times G\rightarrow \mathbb{Q}$ is a coboundary. Is there any explicit proof for that? I'm more interested in question number 2, which technically can be formulated without the notion of a cocycle. Is any function $c:G\times G\rightarrow \mathbb{Q}$ with $c(g_1,g_2)=c(g_2,g_1)$ and $$c(g_1+g_2,g_3)+c(g_1,g_2) = c(g_2,g_1+g_3)+c(g_1,g_3)$$ takes the form $c(g_1,g_2)=f(g_1+g_2)-f(g_1)-f(g_2)$ ?","['group-extensions', 'group-theory', 'group-cohomology']"
3270761,Generating function of a parametrized binomial coefficient,"Let be $m$ an integer and $A_p(m) = \binom{mp}{p}$ . I'd like to know more about $B_m(z) = \sum_{p \geq 0} A_p(m) z^p$ . At least, I'd love to be able to compute $B_m\left(\dfrac{1}{q}\right)$ for some $q$ integers. What I tried: Look at Fuss-Catalan numbers and its generating function to derive a relation with $B_m$ But as there is no closed form of the generating function, I cannot derive an interesting enough relation here. Intuitively, I could try to interpret $A_p(m)$ as something combinatorial and look for a recurrence relation to explicit $B_m$ , but I have no idea.","['catalan-numbers', 'binomial-coefficients', 'combinatorics', 'generating-functions', 'power-series']"
3270784,Injective map of abelian group and product of cyclic quotients,Let $A$ be an abelian group. We have a map from $A \to \prod{(A/I)}$ where $A/I$ varies over the cyclic quotients of $A$ . This map is given by sending $x$ to $\prod (x \text{ mod } I)$ . Is this map injective?,"['group-theory', 'abstract-algebra']"
3270786,Fixpoints of isometry is a totally geodesic submanifold,"I'm working on the proof for:
Let $(M,g)$ be a Riemannian manifold, $F:M \rightarrow M$ isometry, $N:=\{x \in M \vert F(x)=x\}$ . Now I want to show that $N$ is a totally geodesic submanifold. I know that this question has already been asked and I also tried to understand the following proof for this: but as far as I see it, this only proofs that $N$ is a submanifold and not that it is totally geodesic. Is this part of the proof somehow trivial? (If yes, can somebody maybe explain it to me..?)","['isometry', 'geodesic', 'riemannian-geometry', 'differential-geometry']"
3270789,Partial Derivative of a Dot Product with Respect to one of its Vectors,"Say we have a function \begin{cases}
f: \mathbb{R}^n \to \mathbb{R}\\
f(\mathbf{v}) = \mathbf{u}^\top \mathbf{v}
\end{cases} where $\mathbf{u} \in \mathbb{R}^n$ . Apparently taking the partial derivate of $f$ with respect to $\mathbf{v}$ yields $\mathbf{u}$ : $$\frac{\partial f}{\partial \mathbf{v}} = \mathbf{u}$$ Why is that? This makes no sense to me. As $f$ returns real numbers, the rate of change in $f$ should be a real number, I would have assumed. Why is the rate of change a vector? Vectors are not even part of co-domain of $f$ . Also, what subject do I need to look into for this? I just got confronted with that isolated claim that $\frac{\partial f}{\partial \mathbf{v}} = \mathbf{u}$ , here .","['calculus', 'linear-algebra', 'vector-analysis']"
3270824,Matrix of shape operator of the sphere,"Problem: Let $M$ be a sphere of radius $a$ in $\mathbb{R}^3$ , defined by $$ x^2 + y^2 + z^2 = a^2. $$ Parametrize the sphere using spherical coordinates $$x = a \sin \phi \cos \theta \\ y = a \sin \phi \sin \theta \\ z = a \cos \phi $$ where $0 \leq \phi < \pi, 0 \leq \theta < 2 \pi$ . Then for each $p \in M, e_1 = \partial/\partial\phi$ and $e_2 = \partial/ \partial \theta$ is a basis for the tangent space $T_p M$ for $p \in M$ . Let $N_p$ be the unit outward normal vector at $p$ on the sphere. Find the matrix of the shape operator of the sphere with respect to the basis $e_1, e_2$ . Attempt: I need to calculate $L(e_j) = - D_{e_j} N$ and then find the matrix $[a^{i}_{j}]$ such that $L(e_j) = \sum a^{i}_{j} e_i. $ Here $L$ denotes the shape operator. I know that in cartesian coordinates, a normal unit vector is $N = \frac{1}{a} (x, y, z)$ . But do I have to write this first in the $(\theta, \phi)$ basis? I would calculate e.g. $$ D_{\partial_{\phi}} \frac{1}{a} (a \sin \phi \cos \theta, a \sin \phi \sin \theta, a \cos \phi) \\ = ( \cos \phi \cos \theta, \cos \phi \sin \theta, - \sin \phi). $$ But I need to write this as a linear combination of the basis vectors $\partial_{\phi}$ and $\partial_{\theta}$ to find the matrix representation?","['surfaces', 'riemannian-geometry', 'differential-geometry']"
3270877,Limit of the composition function $\sin(\cos(x))/\cos(x)$ at $\pi/2$ in Apostol Exercises 3.8,"In Apostol calculus exercise there is a bunch of exercises where we need to find a limit of a composite function. One example is this: $\lim_\limits{x \rightarrow \frac{\pi}{2}} \frac{\sin(\cos(x))}{\cos(x)}$ Well, intuitively we simply take $\cos(x) \rightarrow 0$ as $x \rightarrow \pi/2$ . Then $\lim_\limits{x \rightarrow \frac{\pi}{2}} \frac{\sin(\cos(x))}{\cos(x)} = 1$ , since the limit of $\sin(x)/x$ is 1 as $x \rightarrow 0$ . Multiple online solutions suggest the same without any explanation. How to show this rigorously? In Apostol, there is a proof that composition of two continuous functions is continuous at any $x = p$ . However, there is no proof about general limits. Moreover, we know that $\sin(x)/x$ is not even defined at $0$ . How is it allowed to substitute $\cos(x) \rightarrow 0$ into this outer sine then? PS. L'Hopital rule has not been specified yet. The only available option is delta-epsilon arguments, and simplest limit rules: sum, difference, product, and division. Squeezing limit theorem can be used (proved before). Plus sin(x)/x limit at 0 has been proven with squeezing limit theorem.","['epsilon-delta', 'real-analysis', 'alternative-proof', 'calculus', 'limits']"
3270891,Prove that $f(n)=n^{2007}-n!$ is an Injective Map,"If $f: \mathbb{N} \to \mathbb{Z}$ defined as $f(n)=n^{2007}-n!$ Then Prove that it is an Injective function My try: According to the definition of Injective function: If $p,q \in \mathbb{N}$ and if $$f(p)=f(q)$$ Then we need to Prove that $p=q$ We have: $$p^{2007}-p!=q^{2007}-q!$$ $$p^{2007}-q^{2007}=p!-q!$$ Without loss of generality let $p \gt q$ and $p=q+m$ We have: $$(q+m)^{2007}-q^{2007}=q!\left((q+m)(q+m-1)(q+m-2)\cdots (q+1)-1\right)$$ By Binomial Theorem we have $$\binom{2007}{1}q^{2006}m+\binom{2007}{2}q^{2005}m^2+\cdots+m^{2007}=q!\left((q+m)(q+m-1)\cdots (q+1)-1\right)$$ Any way to proceed here?","['functions', 'factorial', 'binomial-theorem']"
3270913,Do we have $\mathcal O_X(1)(X)=S_1$?,"If $S$ is a graded ring which is generated by $S_1$ as an $S_0$ -algebra and $X=\operatorname{Proj}S$ , do we have $\mathcal O_X(1)(X)=S_1$ ?","['algebraic-geometry', 'graded-rings', 'graded-modules', 'sheaf-theory']"
3270924,Prove that $x_0$ is Lyapunov unstable,"Let $X : U \subset \mathbb R^n \to \mathbb R^n$ be a $C^1$ vector field and $x_0$ a singular point F $(i.e., X(x_0)=0)$ . Let $h : V \to \mathbb R$ be  a $C^1$ map defined on neighborhood $V \subset U$ of $x_0$ such that $h(x_0) = 0 $ and such that $\dot{h}(x) = \frac{d}{dt}h(\varphi(t,x))|_{t=0}>0$ for every $x \in V\setminus\{x_0\}$ (where by $\varphi(t,x)$ we denote the solution for $x'=X(x)$ , $x(0) = x$ ). Suppose that for every neighborhood $W \subset V$ of $x_0$ there is $\tilde x \in W$ such that $h(\tilde x)>0$ . Prove that $x_0$ is Lyapunov unstable. I'll show  what I've done so far: we suppose that $x_0$ is stable. We choose a compact neighborhood $V_0$ of $x_0$ , since it is stable, then there exists an neighborhood $x_0\in V_1\subset V_0$ such that for any $x\in V_1$ we have $\varphi(t,x)\in V_0$ for every $t\geq 0$ . By hypothesis we have $h(x)>0$ and since the positive semi-orbit of $x$ is such that $\varphi(t,x)\in V_0$ and $V_0$ is compact, then $\omega(x)\neq \emptyset$ , compact and it is invariant (ie, $y\in \omega(x) \implies \varphi(t,y)\in \omega(x))$ . Now how to proceed? I've tried to use the fact that $\omega(x)$ is compact and hence $h$ would have a maximum at $\omega(x)$ and that didn't work. Any ideas, any help?","['stability-in-odes', 'lyapunov-functions', 'ordinary-differential-equations', 'dynamical-systems']"
3270929,How to prove that is a Banach space,"Let $E=\{f\in C^1([0,\infty[, R), \lim_{t\to\infty}\frac{f(t)}{1+t}=\lim_{t\to\infty}f'(t)=0\}$ with the norm $$||f||=\max\left(\sup\limits_{t\geq 0}\dfrac{|f(t)|}{1+t}, \sup\limits_{t\geq 0}|f'(t)|\right). $$ Prove that $E$ is a Banach space. I started by let $(u_n)$ a Cauchy sequence that is $$\forall \varepsilon>0, \exists n_0\in \mathbb{N}, \forall p,q\in \mathbb{N}; p>q\geq n_0\Rightarrow ||u_p-u_q||<\varepsilon $$ that is $$\forall \varepsilon>0, \exists n_0\in \mathbb{N}, \forall p,q\in \mathbb{N}; p>q\geq n_0\Rightarrow \dfrac{|u_p(t)-u_q(t)|}{1+t}<\varepsilon \, \text{and}\, |u'_p(t)-u'_q(t)|<\varepsilon $$ that is $u_n'(t)$ and $\frac{u_n(t)}{1+t}$ are  a Cauchy sequences in the complete $(\Bbb R,|\cdot|)$ so $u_n'(t)$ converge to $v(t)$ . 
and $\frac{u_n(t)}{1+t}$ converge to $w(t)$ How to prove that $(1+t)w(t)$ is derivable?? Please","['banach-spaces', 'normed-spaces', 'analysis']"
3270997,Every infinite linearly ordered set has two disjoint infinite subsets,"According to the Wikipedia Page on amorphous sets , no amorphous set can be totally ordered. If I am correct, this states that every infinite totally ordered set has two disjoint infinite subsets, but I am not sure how to go about proving it in ZF (if it is even provable in ZF), although here's my attempt: Every infinite totally ordered set $S$ has either an infinitely decreasing or infinitely increasing subset, so I tried considering such a subset $A$ . Without loss of generality, suppose $A$ is increasing. Then, letting $a_{1}$ be an element in $A$ , the set $A_{1}:=\{a\in A\mid a>a_{1}\}$ is infinite and thus non-empty. Now, let $a_{2}$ be an element of $\{a\in A|a>a_{1}\}$ . Since $a_{2}\in A$ , the set $A_{2}:=\{a\in A\mid a>a_{2}\}$ is nonempty, and we can continue in this way to generate a sequence $\{a_{1},a_{2},\dots\}$ . My problem is that I rather suspect I just used the axiom of countable choice if not something stronger. Is there a way of proving this in ZF alone?",['elementary-set-theory']
3271054,( Proof Explanation ) Show that a certain system preserves the weighted area $ (dx \wedge dy)/xy$,"I already told few questions ago that I'm currently reading an abstract about the Lotka Volterra differential equations. But now I have a proof, where I need explanations. Consider: $$ \dot{x} = -xy\frac{\delta H}{ \delta y} , x(0) = \hat{x} $$ $$  \dot{y} = xy\frac{\delta H}{ \delta x} , y(0) = \hat{y} $$ where $H(x,y) = x + y - ln(x) -ln(y)$ . I have to show that this System preserve the weighted area $(dx \wedge dy)/xy$ .
I marked my Questions in the proof below. Proof : Let $\Omega_0$ be a subset of $\mathbb{R}^2$ at time $t_0$ and $ \Omega_1$ the set into which $\Omega_0$ is mapped by the system above at time $t_1$ . Preservation of $(dx \wedge dy)xy$ is equivalent to $$ \int_{\Omega_0} \frac{1}{xy}dxdy = \int_{\Omega_1} \frac{1}{xy} dxdy $$ first Question: why is this equivalent? We now look at the Domain $D$ in x,y,t space with bondary $\delta D$ given by $\Omega_0$ at $t_0$ , $\Omega_1$ at $t_1$ and the set of trajectories emerging from the boundary of $\Omega_0$ and ending on the boudnary of $\Omega_1$ . Consider the vector field $$ v := \frac{1}{xy}(\dot{x},\dot{y},1)^T $$ in $x,y,t$ space. Integrating this vector field over the boundary $\delta D$ of $D$ , we obtain $$ \int_{\delta D} v \cdot n = \int_{\Omega_0} v \cdot n_0 + \int_{\Omega_1} v \cdot n_1 = \int_{\Omega_0} \frac{1}{xy} dxdy - \int_{\Omega_1} \frac{1}{xy}dxdy $$ where $n_0 =(0,0,-1)^T$ denote the unit outward normal of $\Omega_0$ and $\Omega_1$ . Second question & Third question: Can you explain why we integrate $v \cdot n$ ? I thought we integrate $v$ and can you explain the first equation above? There is no other contribution to the surface integral, because the vector field $v$ is by contruction parallel to the trajectories, which form the rest of the bondary $\delta D$ . Forth question: Can you explain why vector field is parallel to the trajectories? Applying the divergence theorem to the left hand side of the same equation, we get $$ \int_{\delta D} v \cdot n = \int_D \nabla v = \int_D - \frac{\delta H^2}{\delta x \delta y} + \frac{ \delta H^2}{\delta x \delta y} + 0 = 0 $$ which concludes the proof. I hope that my questions are not to easy, but I'm a beginner.","['integration', 'proof-explanation', 'surface-integrals', 'vector-fields']"
3271067,Is there a noncommutative version of von Neumann's ergodic theorem.,"The two most celebrated ergodic theorems are Birkhoff's ergodic theorem and von Neumann's ergodic theorem. E. C. Lance in his remarkable work ( Ergodic Theorems for Convex Sets and Operator Algebras ) formulated that can be considered to be the noncommutative version of Birkhoff's ergodic theorem, for a von Neumann algebra, $T*$ -automorphism and a faithful $T$ -invariant normal state. I would like to know whether someone has done the same for von Neumann's ergodic theorem. In other words, is there a noncommutative version of von Neumann's ergodic theorem ?","['von-neumann-algebras', 'measure-theory', 'operator-algebras', 'ergodic-theory', 'functional-analysis']"
