question_id,title,body,tags
1427107,"Gronwall inequality for $Z_t \leq \int_0^t k(Z_s)\, ds$","In Ikeda and Watanabe, page 170 one reads I can't see why the relation $$Z_t \leq \int_0^t \kappa (Z_s)\, ds$$ implies that $Z_t = 0$ . How do we use the condition $$\int_{0+} \frac{1}{\kappa(u)}\, du = \infty\tag{*}$$ to get to the conclusion?","['analysis', 'ordinary-differential-equations', 'integral-inequality']"
1427201,Is a probable prime known larger than the largest known prime?,"According to Wikipedia, the largest known prime is $2^{57,885,161}-1$ with $17,425,170$ digits. Because a probable prime is usually easier to find than a proven prime
(although for the Mersenne-primes, there is an algorithm to prove primilaty
as fast as a probable prime test), I wonder if there is a larger known probable
prime. The same for twin primes, the largest known pair is $3,756,801,695,685\times 2^{666,669}\pm1$ with $200,700$ digits. Is there known a larger pair for which both entries are probable primes ?","['prime-numbers', 'number-theory', 'twin-primes', 'soft-question']"
1427212,Prove that $f(\mathbb R) = \mathbb R$. Partially solved.,"Let $f:\mathbb R\to \mathbb R$ and $f(f(x)) = x + f(x)$ , $x\in\mathbb R$ Prove that: a) $f$ is injective b) $f(0) = 0$ c) $f(\mathbb R) = \mathbb R$ My solution: a) Let $x_1, x_2 \in \mathbb R$ and $f(x_1) = f(x_2)$ then $f(f(x_1)) = f(f(x_2))$ $x_1 + f(x_1) = x_2 + f(x_2)$ $x_1 = x_2$ therefore $f$ is injective. b) Let $x=0$ then $f(f(x)) = x + f(x)$ $f(f(0)) = 0 + f(0)$ $f(f(0)) = f(0)$ but $f$ is injective therefore $f(0) = 0$ c) Here is the point where I get stuck. How do I solve this? I think I have to begin saying, let $y\in\mathbb R$ and prove that there is a $x\in\mathbb R$ for which $f(x) = y$ .","['functional-equations', 'functions']"
1427219,prove there is no rational r satisfying $2^r=3$,I first assumed that there exists a rational $r=\frac{a}{b}$ such that $2^r=3$. ..and I can't make a progress after this. can anyone help me out?,"['calculus', 'real-analysis']"
1427231,What is the probability that I will be dealt 2 or more diamonds when 5 cards are dealt?,"So assume we have a standard 52 cards deck that is shuffled fairly. If I am dealt 5 cards what is the probability that I will have 2 or more diamonds? My initial thought was to add the probability of getting exactly 2, 3, 4, and 5 diamonds. So I did that as follows: C(4,1) * C(13, 5) + C(4,1) * C(13, 4) + C(4,1) * C(13, 3) + C(4,1) * C(13, 2) But I know that this can't be right because I feel like I am duplicating possibilities. 
Isn't C(4,1) * C(13, 4) also including the possibility of getting all 5 diamonds? Any help would be appreciated.","['probability', 'statistics']"
1427275,Dedekind cuts: proof that $A=0_{\mathbb{R}}$ if and only if $-A = 0_{\mathbb{R}}$.,"Constructing the real numbers with Dedekind cuts we have the definition of $-A$ for a given $A\in \mathbb{R}$ as $$-A = \{p\in \mathbb{Q} : -p\in \mathbb{Q}\setminus A, \ \text{and there is} \ q\in \mathbb{Q}\setminus A \ \text{with} \ q < -p \}.$$ We define then $0_{\mathbb{R}}\in \mathbb{R}$ as the cut $0_{\mathbb{R}}= \{q\in \mathbb{Q} : q < 0\}$. In that case I'm trying to show that $A = 0_{\mathbb{R}}$ if and only if $-A = 0$. For the first part, supposing $A = 0$ we consider $p\in -A$. In that case $-p\in \mathbb{Q}\setminus A$ and since we are supposing $A = 0_{\mathbb{R}}$ this means $-p\geq 0$ so that $p \leq 0$. We want to show that $p\neq 0$ so that $p\in 0_{\mathbb{R}}$. For that suppose $ p = 0$, in that case since $p\in -A$ there is $q\in \mathbb{Q}\setminus A$ such that $q < -p$, but then we have $q < 0$ so  that $q\in A$ because $A$ is a cut. Since $q\in \mathbb{Q}\setminus A$ we must have $p\neq 0$ and so $p\in 0_{\mathbb{R}}$ showing $-A\subset 0_{\mathbb{R}}$. Analogously let $q\in 0_{\mathbb{R}}$, so that $q < 0$ and so that $-q > 0$. In that case $q\in \mathbb{Q}\setminus A$. But $0_{\mathbb{R}}$ is a cut, so thare is $r\in 0_{\mathbb{R}}$ with $q < r < 0$. In that case, setting $s = -r$ we have $s > 0$ so that $s\in \mathbb{Q}\setminus A$ and on the same time, $s < -q$. Because of that $q\in -A$ and so $0_{\mathbb{R}}\subset -A$. With that we have already that $A = 0$ implies $-A = 0$. Now we have to show that $-A = 0$ implies $A = 0$. I'm stuck with this one however. How can I finish this proof? I've been thinking for a while but couldn't find a good way to do it. Thanks very much in advance.","['real-numbers', 'elementary-set-theory', 'real-analysis']"
1427280,"Is there a rectangle with a maximum area which has two corners at the x axis, one corner at $y_1=e^x$ and one at $y_2=2e^{-x}$ .",The inverses of $y_1$ and $y_2$ are : $x_1=ln y$ and $x_2=-ln\frac{y}{2}$ we need them to to calculate the side $a$ of a rectangle. The area of a rectangle is defined as its one side multiplied by its other one. $P=a*b$ $a=x_2-x_1$ $b=y$ $P=y*(-ln\frac{y}{2}-ln y)$ We derive $P$. $P'> 0$ Is this method of solving that problem correct?,"['area', 'calculus', 'derivatives']"
1427288,How to sample a binomial random variable?,"Rather than using mathematical libraries, how would you sample from a binomial random variable efficiently? Given the binomial random variable X, where $k$ are the number of successes in $n$ trials with a success probability of $p$
$$
    P(X=k|n, p) = \binom{n}{k} p^k(1-p)^{n-k},
$$
how could I obtain $N$ number of samples of $X$? The naïve approach is to decompose $X$ into $X = Y_1 + Y_2 + ... + Y_n$, where $Y$ are the bernoulli experiments 
$$
Y_i = P(Y_i = 1) = p.
$$ Or, in other words, I can test $n$ times if some random value is above $p$ and count how many times this was a success. This is, however, terribly inefficient when $n$ is large. It is possible to sample a continuous random variable by finding the inverse CDF ($F^{-1}(x)$), sampling from the uniform distribution $ u = U(0,1)$ and calculating the value of the sample in the inverse CDF $F^{-1}(u)$. Given that this is a discrete distribution, how could I apply this? Which other methods are available?","['probability', 'binomial-distribution']"
1427300,Inverse Galois problem for function fields,"Books on Inverse Galois problem usually deal directly with the number field case. I am looking for a good reference for a proof of the following fact: Every finite group is realizable for any function field in one
  variable over a algebraically closed field of characteristic zero. It is ok if the reference is a research paper, but I would prefer a survey/textbook if possible.","['number-theory', 'galois-theory', 'algebraic-number-theory', 'reference-request']"
1427359,Positive measure,"Let $\mu$ positive measure over $(\mathbb{R},\mathcal{B}(\mathbb{R}))$. Prove that if $\mu$ is invariant translations and $\mu([0,1])=1$, then $\mu([0,\frac{1}{n}])\leq\frac{1}{n}$ I know that this measure is the Lebesgue measure, but I can´t prove that  $\mu([0,\frac{1}{n}])\leq\frac{1}{n}$","['lebesgue-measure', 'measure-theory']"
1427364,Prove that probability distribution function is continuous at a point,"Let $X$ be a random variable on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$. Show that $F_X(x)$ is continuous at $x = x_0$ if and only if $\mathbb{P}(X = x_0)= 0.$ $\underline{\mathrm{Proof}}$: ($\rightarrow$ direction) Suppose $F_X$ is continuous at $x = x_0$. Then, \begin{eqnarray}
\mathbb{P}(X = x_0) &=&F_X(x_0) - \lim_{y \rightarrow x_0^{-}} F_X(y), \\
&=& F_X(x_0) - F_X(x_0), \hspace{1cm} (\mathrm{since\ } F_X \mathrm{\ is\ continuous\ at\ } x=x_0), \\
&=& 0,
\end{eqnarray} as required. ($\leftarrow$ direction) Suppose $\mathbb{P}(X = x_0) = 0$. Then, \begin{eqnarray}
\mathbb{P}(X = x_0) &=& F_X(x_0) - \lim_{y \rightarrow x_0^{-}} F_X(y) \\
\implies \lim_{y \rightarrow x_0^{-}} F_X(y) &=& F_X(x_0)\hspace{1cm} (\mathrm{since\ } \mathbb{P}(X = x_0) = 0).
\end{eqnarray} This means that $F_X$ is left continuous $x_0$. Since $F_X$ is right continuous for all $x \in \mathbb{R}$ it is right-continuous at $x = x_0$. Thus $F_X$ is continuous at $x = x_0$. $\square$ Is this proof okay?","['probability-theory', 'probability-distributions', 'proof-verification', 'proof-writing', 'probability']"
1427383,Looking to solve an integral of the form $\int_1^\infty (y-1)^{n-1} y^{-n} e^{(\alpha -\alpha n)\frac{(y-1) }{y}} \; dy$,"Looking for a solution the following integral. With $n \geq2$, $\alpha>1$,
$$z(n,\alpha)=\frac{\left(\alpha  (n-1)\right)^n}{\Gamma (n)-\Gamma (n,(n-1) \alpha )} \int_1^\infty  (y-1)^{n-1} y^{-n} e^{(\alpha -\alpha  n)\frac{(y-1) }{y}} \; dy $$ I am adding the numerical integration for different values of $\alpha$. I am showing how the integral behaves (for $n=5$ and $\alpha = 3/2$ as one answer was that it does not converge: .","['gamma-function', 'calculus', 'improper-integrals', 'integration', 'numerical-methods']"
1427387,De Rham-Etale comparison isomorphism for elliptic curves,"I can't find anywhere a proof of the following comparison isomorphishm: $$H^1_{dR}(E)\otimes \mathbb{C}=H^1_{et}(E)\otimes \mathbb{C}$$ where $E$ is an elliptic curve over $\mathbb{C}$. Any reference would be appreciated. On a side note, is the isomorphism true for $n>1$?","['elliptic-curves', 'homology-cohomology', 'number-theory']"
1427399,Is there a proof of Bézout's theorem via residue theory?,"Let's define intersection numbers as follows. Consider a collection $f_1,\dots, f_n$ of holomorphic functions on some neighborhood of zero in $\mathbb C^N$ cutting out divisors $D_1$, all of which vanish at $0$. Define
$$\omega(f_1,\dots, f_n)=\frac{df_1}{f_1}\wedge\dots \wedge \frac{df_n}{f_n}.$$
We say the local intersection number is defined by 
$$(D_1,\dots, D_n)=\operatorname{Res}_{\{0\}}\omega(f_1,\dots, f_n).$$ Clearly this is a local definition and the obvious modifications give a definition of intersection number for hypersurfaces intersecting at nonzero points. I'm looking for a complex-analytic proof that this definition of intersection satisfies the general version of Bézout's theorem for $n$ hypersurfaces in $\mathbb P^n$ (as opposed to one that shows this is equivalent to the algebraic definition in terms of local rings and then uses a standard algebraic proof). Surely this is written down somewhere. Where can I find it?","['complex-geometry', 'algebraic-geometry', 'reference-request']"
1427414,"What is meant by ""the coefficients of a polynomial function $f(x)$ are symmetric functions of its roots""?","I am reading Rotman's Introduction to Group Theory . One of his first remarks is that: By the middle of the eighteenth
  century, it was realized that permutations of the roots of a polynomial $f(x)$
  were important; for example, it was known that the coefficients of $f(x)$ are
  ""symmetric functions"" of its roots. Aren't the coefficients of a polynomial function constants? How can they then be functions, let alone ""symmetric functions""?","['polynomials', 'group-theory']"
1427430,Modules with no basis?,"I was just reading a bit about modules on wikipedia, which, as I understood it, are generalizations of vector spaces. I read there exists some modules that do not have a basis, and I couldn't think of an example or why this happens (vs vector spaces: they all have some basis). Could someone explain this?","['abstract-algebra', 'modules']"
1427435,Connections on principal bundles: Local and Global Formulations.,"The standard definition of a connection on a principal $G$-bundle $\pi : P \to X$ is a smooth family of subspaces $H_{p}$ of $T_p P$ such that for every $p \in X$ we have a splitting of vector spaces $T_p P = H_p \oplus \mathrm{ker} (\pi_{*})_{p}$ and so that $H_{p g} = (R_{g})_{*} H_{p}$, where $R_g$ is the right action of $G$ on $P$. Equivalently, this is the same as specifying, for every $p \in X$, a right inverse $q_p : T_{\pi(p)} X \to T_p P$ for $(\pi_{*})_p$, or a left inverse $\theta_{p}: T_p P \to \mathrm{ker} (\pi_{*})_{p}$ for the inclusion, by standard theory for exact sequences of vector spaces. All of the above works `fibrewisely'; I would like to know what the global picture is: When will the pullback bundle $\pi^{*}(TX)$ and the kernel $T_V P$ of $\pi_{*}$ be subbundles of $TP$, so that we may write $TP  = T_{V}P \oplus \pi^{*}(TX) $, where this splitting is $G$-invariant? Will this only occur if we can find a $G$-invariant right bundle-morphism inverse for $\pi_{*}$, or a $G$-invariant left bundle-morphism inverse for the inclusion of $T_V P$? More generally, the transition between the local and fibrewise pictures in the category of vector bundles over smooth manifolds is unclear to me, in particular the theory for short exact sequences - is there some standard reference that explains this in detail?","['exact-sequence', 'principal-bundles', 'vector-bundles', 'connections', 'differential-geometry']"
1427458,"How to explain Clairaut-Schwartz's Theorem, $f_{xy}=f_{yx}$?","I am looking for a non-technical explanation of Clairaut's theorem which states that the mixed derivative of smooth functions are equal .
A geometrical, graphical, or demo that explains the theorem and its implications will be helpful. I am not looking for a proof!","['education', 'multivariable-calculus', 'real-analysis']"
1427472,How to prove SSE and SSR are independent,"Consider $Y=X\beta+\varepsilon$, where $X$ is n by p, $\beta$ is p by 1 and $\varepsilon$ is n by 1 with covariance matrix = var($\varepsilon$)=$\sigma^2 I$. Give expression for the regression and error sums of squares, find their expected values, and show that they are independent. My work:
One has $SSE=Y^{T}Y-\hat{\beta}^{T}X^{T}Y=Y^{T}(I-X(X^{T}X)^{-1}X^{T})Y$, and $SSR=Y^{T}(X(X^{T}X)^{-1}X^{T}-\frac{1}{n}J)Y$. For $SSE$, it is easy to get its distribution. But I have difficulty to get the distribution of $SSR$, I was trying to prove $X(X^{T}X)^{-1}X^{T}-\frac{1}{n}J$ is idempotent. But it seems not easy for me. Also I have difficulty to prove $(I-X(X^{T}X)^{-1}X^{T})(X(X^{T}X)^{-1}X^{T}-\frac{1}{n}J)=0$. Can someone help me here?","['regression-analysis', 'statistical-inference', 'statistics', 'regression', 'linear-algebra']"
1427473,Inclusion Exclusion Probability Proof Using a Partition of the Space,"Let $A_1, A_2, \dots, A_n \subset \Omega$ be arbitrary subsets of a probability space. Let $P$ be a probability measure on $(\Omega, \mathscr{P}(\Omega))$Denote:
  $$
s_1=\sum\limits_{i=1}^{\infty} P(A_i), \ s_2=\sum\limits_{1\leq i<j }^{\infty} P(A_i \cap A_j), \ s_3=\sum\limits_{1\leq i < j< k }^{\infty} P(A_i \cap A_j \cap A_k), \dots
$$ Prove the inclusion-exclusion formula:
  $$
P(A_1 \cup A_2 \cup \dots \cup A_n)=s_1 - s_2 + s_3 - \dots + (-1)^{n+1} s_n,
$$
  using the following. Partition $\Omega$ into sets $A_1'\cap A_2' \cap \dots \cap A_n'$ where each $A_i'$ is either $A_i$ or $A_i^c$. Then count the number of times a set in the partition occurs in an $s_i$. For example, if $n=2$ the set $A_1\cap A_2$ occurs twice in $s_1$ and once in $s_2$. The following identity will be useful in the proof:
  $$
\sum\limits_{i=0}^{k} (-1)^i {{n}\choose i} = (-1)^k {{n-1}\choose k}, 1\leq k \leq n.
$$ I've looked at a couple of proofs for inclusion-exclusion, but none of the ones that I have found seem to be similar to this approach. I am not sure how this partition could be helpful in calculating $P(A_1\cup A_2 \cup \dots \cup A_n).$ The idea I have so far is the following. $P(A_1 \cup A_2 \cup \dots \cup A_n)=\sum\limits_j P(A_j^*)$ where $A_j^*$ denotes a set in the collection of the partition that includes all the partition sets, but $A_1^c \cap A_2^c \cap \dots \cap A_n^c$. Now I believe I somehow want to count the number of times each of the partition sets appears in each $s_i$. I am not sure how to go about this for general $n$. Any help would be much appreciated.","['probability-theory', 'probability', 'measure-theory']"
1427536,How to solve when the limit equals 0?,"if position $s(t) = -16t^2 + 40t + 24$ and velocity is $$v(t) = \lim_{x \to t} \frac{s(x)-s(t)}{x-t},$$ when does the ball have velocity 0? If my calculations are correct, it always has 0 velocity (seems unlikely)
$$		v(t) = \lim_{x \to t} \frac{s(x)-s(t)}{x-t} \\
		0 = \lim_{x \to t} \frac{s(x)-s(t)}{x-t} \\
		0 = \frac{\lim_{x \to t} \left(s(x)-s(t)\right)}{\lim_{x \to t} \left(x-t\right)} \\
		0 \left(\lim_{x \to t} \left(x-t\right)\right) = \lim_{x \to t} \left[s(x)-s(t)\right] \\
		0 = \lim_{x \to t} \left[ s(x)-s(t)\right] \\
		0 = \lim_{x \to t} s(x) - s(t) \\
		s(t) = \lim_{x \to t} s(x)
$$ Can I multiply by $\lim_{x \to t} \left(x-t\right)$ in the fourth row? I'm guessing not, since everything else seems pretty standard. So then how do I solve this?",['limits']
1427553,Prove that $2\mid x$ and $5\mid x$ if and only if $10\mid x$,"I have to do it without using Fundamental Theorem of Arithmetic. Can someone check my work? Prove if $2\mid x$ and $5\mid x$, then $10\mid x$. Let $x \in \mathbb{Z}$. Suppose $2\mid x$ and $5\mid x$. Then, by definition of divisibility, there exists integers $m,n$ such that $2m = x = 5n$. Therefore $5\mid 2m$. Since the $\gcd(2,5) = 1$ it follows that $5\mid m$. Therefore there exists an integer $k \in \mathbb{Z}$ such that $5k = m$. Prove if $10\mid x$, then $2\mid x$ and $5\mid x$. Suppose $10\mid x$, then there exists an integer $a \in \mathbb{Z}$ such that $10a = x$. From here it follows that $2 \cdot 5 \cdot a = x$. I really don't feel like this encompasses the entire proof. Should I be using Euclid's Lemma instead?","['proof-verification', 'divisibility', 'discrete-mathematics']"
1427570,Using contraction mapping theorem to prove existence/uniqueness of solutions of Linear first order ODEs,"In class we used the contraction mapping theorem to prove the existence and uniqueness of solutions to a first order (not necessarily linear) ODE on some interval [0,h]. The method we used was this: First convert the linear ODE into an integral equation of the form $u=f(t)+\int_0^s k(t,s)g(t,u(s)) \ ds$. and define an operator $Tu=f(t)+\int_0^s k(t,s)g(t,u(s)) \ ds$. Then use the contraction mapping theorem to ensure $T$ has a fixed point (and thus the integral equation is uniquely solved) on some small enough interval $[0,h]$. My question is this: Suppose I restrict the ODE to be a linear ODE only. That is, the operator is now 
$T=f(t)+\int_0^s k(t,s)u(s) \ ds$. The above contraction mapping still gives us a unique solution on $[0,h]$. Using this fact, how can I show that there is a unique solution for $[h,2h]$ and, therefore, for all intervals $[0,k]$?",['ordinary-differential-equations']
1427589,Are Square and equilateral triangle the only convex regular ngons that can be composed to smaller versions of themselves?,"While I was trying to make an analogous question to Select $n^2 + 1$ points in the unit square. Show that at least two points are no more than a distance $\frac{\sqrt{2}}{n}$ apart , using equilateral triangles, I ended up with : Select $2^n + 1$ points in a unit equilateral triangle. Show that at least two points are no more than a distance $\frac{1}{2^n}$ apart. But then I got stuck! there was no other shape that the trick of decomposing a shape to smaller version of itself can be applied (short of fractals that is). So I had to ask this question: Are Square and equilateral triangle the only convex regular ngons that can be composed to smaller versions of themselves?","['pigeonhole-principle', 'geometry', 'fractals']"
1427598,Finding $\lim_{x \to 3} \frac{\sqrt{x-1} + 2}{x+3}$,"I'm having problems with this example. What are all the ways I can determine if the lim tends towards positive or negative infinity without using derivatives? EX: Evaluate each of the following. If the limit does not exists state
  so. If the limit is infinite then state whether the values tend
  towards positive or negative infinity. $$\lim_{x \to 3} \frac{\sqrt {x-1}+2}{x+3}$$","['calculus', 'limits']"
1427612,"Integrability of Thomae's Function on $[0,1]$.","Consider the function $f: [0,1] \to \mathbb{R}$ where
f(x)=
\begin{cases}
\frac 1q & \text{if } x\in \mathbb{Q} \text{ and } x=\frac pq \text{ in lowest terms}\\
0 & \text{otherwise}
\end{cases} Determine whether or not $g$ is in  $\mathscr{R}$ on $[0,1]$ and prove your assertion. For this problem you may consider $0= 0/1$ to be in lowest terms. Here's an attempt. I may have abused a bit of notation here, but the ideas are there. Proof: Let $M_i = \sup \limits_{x \in [x_{i-1},x_i]} f(x)$. Notice first that the lower Riemann sums are always $0$, since every interval contains an irrational number. Thus, to prove $f \in \mathscr{R}$, it suffices to prove that, given any $\epsilon >0$, $\sum \limits_{i \in P} M_i \Delta x_i < \epsilon$ for some partition. Let $\epsilon > 0 $ and $M  > \frac{2}{\epsilon}$. We first show that there exists $\eta(x,\frac{1}{M})$ so that $|f(x) - f(y)| < \frac{1}{M}$ if $|x-y| < \eta$. Fix $x \in (\mathbb{R} \setminus \mathbb{Q}) \cap [0,1]$. Now, consider the set $$R_{M} := \{ r \in \mathbb{Q} : r = \frac{p}{n}, n \leq M, p \leq n, p \in \mathbb{N} \}.$$ Clearly this set is finite, enumerate it as $\{q_1,\ldots, q_m\}$. So, let $$\eta(x,\frac{1}{M}) = \min_{i=1,\ldots, m} |x- q_i|.$$ We see then, $|f(x) - f(y)| < \frac{1}{M}$ on this $\eta$-neighborhood. After we choose that $\eta$ so that $x \in (\mathbb{R} \setminus \mathbb{Q}) \cap [0,1]$, is continuous in a $\eta$-neighborhood, we see 
$$ A:= [0,1] \setminus R_M \subset \left( \bigcup_{ x \in ( \mathbb{R} \setminus \mathbb{Q}) \cap [0,1]} B_{\eta(x)} (x) \right) \cap [0,1].$$ 
Since $A$ is compact, we may take finite sub-covering, and let $\delta = \min \limits_{i=1,\ldots,n} \{\eta(x_i)\}$. Take a partition $P_1$ of $A$ so that $\Delta x_i < \delta$. Since $R_M$ is non-empty, we can take a partition $P_2$ of $R_M$ so that $\Delta x_i < \frac{\epsilon}{2m}.$ Moreover, we see that,  on $[0,1]$, $f$ is at most $1$. Let $P = P_1 \cup P_2$. Thus, \begin{eqnarray*}
\sum_{i \in P} M_i \Delta x_i &=& \sum_{i \in P_1} M_i \Delta x_i + \sum_{i \in P_2} M_i \Delta x_i \\
&\leq& \frac{1}{M} \sum_{i \in P_1} \Delta x_i + \sum_{i \in P_2} \Delta x_i \\
&<& \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon 
\end{eqnarray*} Comments? EDITED I think I resolved the issue.","['proof-verification', 'real-analysis', 'riemann-integration', 'integration', 'analysis']"
1427629,What is the integral for this expression? (I tried complete the square),"But complete the square, doesn´t lead me to something coherent. I got this: $$\int\frac{x \, dx}{\sqrt{3-2x-x^2}}$$","['substitution', 'trigonometry', 'integration']"
1427630,Show that the piecewise defined function is continuous at $x=0$,"I am faced with the following problem: Determine whether the following function is continous, once differentiable, or twice differentiable: $f(x) = \begin{cases} x^3+x-1 &\text{if $x \leq 0$;} \\
x^3-x-1 &\text{if $x >0$}. \end{cases}$ So far, I have shown that $f$ is not once differentiable at $x = 0$, and since $C^{2}(\mathbb{R}) \subset C^{1}(\mathbb{R})$, it is also not twice differentiable. What I am having a little bit of difficulty with is showing that it is continuous at $x = 0$.  Here is what I've done so far: since each piece of the piecewise defined function is continuous on its domain of definition, all I need to do is check the point $x = 0$. For $x > 0$, I want to see if the right-hand limit exists. In this case, $|f(x) - f(0)| = |x^{3}-x-1 - (0^{3} + 0 - 1)| = |x^{3} - x| = |x(x^{2}-1)| = |x||x^{2}-1|$. Now, if $|x|<1$, then $|x^{2} - 1| = |x+1||x-1| \leq (|x|+1)(|x|+1) = 2(|x|+1)< 2(1+1) = 4$. So, I have that $|x||x^{2}-1|<4|x| < \epsilon$ if we take $|x|<\frac{\epsilon}{4}$. Therefore, I take $\displaystyle \delta = \min\left\{ 1, \frac{\epsilon}{4}\right\}$, and I have $\forall \epsilon > 0$ that $|f(x) - f(0)|<\epsilon$; i.e., the right-hand limit exists and is equal to $-1$. For $x < 0$, I want to see if the left-hand limit exists.  In this case, $|f(x) - f(0)| = |x^{3}+x-1 - (0^{3}+0-1)| = |x^{3}+x-1+1| = |x^{3} + x| \leq |x^{3}| + |x|$. If $|x|<1$, then $|x^{3}|<|x|$. So, I have that $|x^{3}|+|x| < |x| + |x| = 2|x| < \epsilon$ provided we take $\displaystyle |x| < \frac{\epsilon}{2}$. Therefore, I take $\delta = \min \left\{1, \frac{\epsilon}{2} \right\}$, and I have  $\forall \epsilon > 0$ that $|f(x) - f(0)|<\epsilon$; i.e., the left-hand limit exists and is equal to $-1$. Thus, $\lim_{x\to 0}f(x) = -1$, and since $f(0) = -1$, we have that $f$ is continuous at $x = 0$.  Thus, it is continuous $\forall \mathbb{R}$. I suppose what I would like to know is if I showed this correctly and, if not, how I might fix it. Thank you.","['continuity', 'limits', 'real-analysis', 'epsilon-delta']"
1427716,"A closet contains 10 pairs of shoes. If 8 shoes are randomly selected, what is the probability that there will be exactly 1 complete pair?","What I am getting is that there are 10 ways of choosing the 1 pair of shoes from the 10. Since the remaining shoes can't match, there are $\left( \begin{matrix} 9\\ 6\end{matrix} \right) $ ways to choose pairs from which to select the remaining shoes, $2^6$ ways to select individual shoes from the 6 pairs, and divided by$ \left( \begin{matrix} 20\\ 8\end{matrix} \right) $ ways of selecting 8 shoes from 20. This gives us $\dfrac {\left( \begin{matrix} 9\\ 6\end{matrix} \right)\times 10 \times 2^6 } {\left( \begin{matrix} 20\\ 8\end{matrix} \right) }$ This gives a probability of $\dfrac {1792} {4199}$. But that doesn't seem quite right, I think I am missing something. Any help would be appreciated.","['combinations', 'probability', 'combinatorics', 'permutations']"
1427736,"Is a finite group with any subgroup admitting a unique complement, cyclic?",Let $G$ be a finite group such that any subgroup $H \le G$ admits a unique complement $K$. Question : Is $G$ cyclic ?,"['group-theory', 'finite-groups']"
1427750,The numerical relation of the sum of two divergence series,"For these two series: $1 + 2 + 3 + 4 + 5 +...$ $2 + 4 + 6 + 8 + 10 +...$ For each of the two series, since these numbers progress with no end, and the sum increases,
it certainly cannot be finite. By this fact it becomes infinite. Hence, this quantity is so large
that it is greater than any finite quantity. Thus I think the sum could only be an ""infinite number"", which is
greater than any finite or assignable quantity. Moreover, every term of the second series is
twice as large as the corresponding term of the first series(1 to 2, and 2 to 4, and n to 2n), it is reasonable to believe that the
sum of the second series is twice as large as the first series, i.e. we get two infinite numbers
and one is twice as large as the other. so is there something wrong here?","['infinity', 'sequences-and-series', 'calculus', 'divergent-series']"
1427760,Conditional expectation given an event is equivalent to conditional expectation given the sigma algebra generated by the event,"This problem is motivated by my self study of Cinlar's ""Probability and Stochastics"", it is Exercise 1.26 in chapter 4 (on conditioning). The exercise goes as follows: Let H be an event and let $\mathcal{F} = \sigma H = \{\emptyset, H, H^c, \Omega\}.$ Show that $\mathbb{E}_\mathcal{F}(X) = \mathbb{E}_HX$ for all $\omega \in H.$ I'm not quite clear what I'm supposed to show, since when $\omega \in H$, then the $\sigma$-algebra is ""reduced"" to the event H, or am I misunderstanding something here?","['probability-theory', 'conditional-expectation', 'measure-theory']"
1427813,Existence of a monotone subadditive function with a jump on its values,"Let $f$ be a nonnegative function defined on the power of the set of positive integers for which: $f(X) \le f(Y) \le f(\mathbf{N})=1$ if $X\subseteq Y$; $f(X\cup Y)\le f(X)+f(Y)$; for each $X$ and each $y \in [0,f(X)]$ there exists $Y \subseteq X$ such that $f(Y)=y$. Fix a set $A$ such that $f(A)<1$. Does there exist a set $B$ containing $A$ such that 
$$
f(A)<f(B)<1 \,\,?
$$","['real-analysis', 'functions']"
1427886,To show that the function $f:M_n(\mathbb R) \to M_n(\mathbb R)$ given by $f(A)=AA^t$ is differentiable and evaluate its derivative,How to show that the function  $f:M_n(\mathbb R)  \to M_n(\mathbb R)$ given by $f(A)=AA^t$ is differentiable and how to find the total differential at a point  $X$ i.e. how to find $D f_A(X)$ ?,"['analysis', 'multivariable-calculus', 'matrix-calculus', 'derivatives']"
1427902,"If $X$ is finite and $f:X \rightarrow Y$ is a function, then $f(X)$ is a finite set with $|f(X)| \leq |X|$.","If $X$ is finite and $f:X \rightarrow Y$ is a function, then $f(X)$  is a finite set with $|f(X)| \leq |X|$. I have tried to prove this claim by contradiction. Since $X$ is finite, we shall assign an arbitrary cardinality $n$ to $X$ and so there exists a bijection $h:X \rightarrow \mathbb{N_n}$. Now suppose that $f(X)$ has cardinality $m$ where $m >n$, then there exists a bijection $g:f(X) \rightarrow \mathbb{N_m}$, from this we can deduce that $\forall z \in \mathbb{N_m} \exists y \in f(X) \text{ s.t } g(y) = z$ in particular there must exist a $y \in f(X)$ such that
$$g(y) = n+1 \implies g(f(x)) = n+1$$
$$\implies f(x) = g^{-1}(n+1)$$ I feel as though the next part of the ""proof"" is not correct and so $f(x)$ is the image of $x \in X $ such that $f(x)$ is the $(n+1)th$ element of $f(X)$. Since there are only $n$ elements in $X$ it must be the case that at least one element $x \in X$ has been mapped to two or more different elements in $f(X)$. but in that case  $f$ is not a function, by definition. Hence $m \leq n$ Now I have to show that if $f$ is injective then the inequality becomes equality. But I would like to make sure this guy is ok first.","['elementary-set-theory', 'set-theory', 'solution-verification', 'cardinals']"
1427904,“Smallness” of the set of Archimedean copulas in the set of all exchangeable copulas,"This is a little bit of a vague question I guess. Let us for simplicity consider bivariate copulas. We can think aboutset $\mathcal{C}$ of all exchangeable copulas: that is, these are copulas $C: [0,1]^2\rightarrow [0,1]$ that satisfy the following condition: 
$$C(u,v)=C(v,u).$$
We can also consider a subset $\mathcal{C}_0 \subset \mathcal{C}$ of Archimedean copulas $-$ these are copulas represented in the following form: 
$$C(u,v)=\phi^{[-1]}(\phi(u)+\phi(v)), \text{ where } $$
the generator $\phi:[0,1] \rightarrow [0,\infty)$ is a continuous, strictly decreasing and convex function such that $\phi(1)=0$. The pseudo-inverse $\phi^{[-1]}$ is defined as 
$$\phi^{[-1]}(t)=
\left\{
\begin{array}{l}
\phi^{-1}(t), \quad \text{if } 0\leq t \leq \phi(0),\\
0, \quad \text{if } \phi(0)<t.
\end{array}
\right. $$ My question is how “small” $\mathcal{C}_0$ is in larger $\mathcal{C}$. I am not sure what meaning and what notion of smallness would be appropriate here.","['probability-theory', 'real-analysis', 'functional-analysis', 'probability-distributions']"
1427905,Solution of second order linear ODE,"I consider a second order linear ODE : $$
x^{2\beta+2}\frac{\partial^2 V}{\partial x^2}+(a+x^{2\beta})x\frac{\partial V}{\partial x}+(b+x^{2\beta})V=0.
$$ I am expecting that the above equation can be reduced to Whittaker's equation. However, I couldn't. How can I solve the above equation? Thanks in advance.","['special-functions', 'functions', 'hypergeometric-function', 'ordinary-differential-equations', 'partial-differential-equations']"
1427957,Prove the inequality for $3$ numbers,"Given $x,y,z$ are reals such that $0<x<y<z<\frac{\pi}{2}$. Prove that $$\frac{\pi}{2}+2\sin x\cos y+2\sin y\cos z>\sin 2x+\sin 2y+\sin 2z$$ Since the inequality is not symmetric and equality too doesn't hold, I don't have many ideas. I tried using some rearrangement inequality, but it doesn't help. Thanks.","['inequality', 'trigonometry']"
1428021,Is it true that $e^{\sin(3.14)}e^{3.14} \le e^{\sin(3.15)}e^{3.15}$?,I have to determine whether is it true that $$e^{\sin(3.14)}e^{3.14} \le e^{\sin(3.15)}e^{3.15}$$ and whether it is a equality. I even don't know how to begin with it...,"['derivatives', 'inequality', 'exponential-function', 'trigonometry']"
1428097,"On average, how many friends would I need to have to have at least one friend's birthday every day? [duplicate]","This question already has answers here : Expected time to roll all $1$ through $6$ on a die (3 answers) Closed 8 years ago . I know that because of the birthday problem, even after 365 friends, you're going to have a lot of doubles and that there's also an infinitesimal chance that even with infinite friends that there's one day left out. But I was curious how many friends you'd need on average to have every day represented (this is ignoring leap day and assuming birthdays are equally distributed). Or to generalize it further, given n unique boxes and you're placing balls in them with an equal 1/n chance for the ball to go into any box, how many balls would you have to place on average before every box had at least one ball?","['coupon-collector', 'probability']"
1428108,"Sum $\sum\limits_{n,m=1}^\infty \frac{1}{(n+m)!},$","I am looking at: 
$$\sum_{n,m=1}^\infty \dfrac{1}{(n+m)!},$$ 
my task is to show that it is absolutely convergent and to find its sum. I have found the sum doing the following: $$\sum_{m,n=1}^\infty \frac{1}{(m+n)!}=\sum_{k=2}^\infty\left(\sum_{m+n=k}\frac{1}{(m+n)!}\right)
= \sum_{k=2}^\infty\left(\sum_{m+n=k}\frac{1}{k!}\right) =\sum_{k=2}^\infty \left(\frac{1}{k!}\left(\sum_{m+n=k}1\right)\right)$$
from which it seems that the sum equals $e-1-\frac{1}{e}$. I believe that this is correct, however when I try the ratio test I keep getting failed convergence. I am not sure how to approach the absolute convergence of this problem. Any hints would be great!","['summation', 'sequences-and-series', 'calculus', 'convergence-divergence']"
1428123,Differentiation of matrix exponential,"I'm with the following problem and I'd like to know if my answer makes sense. I'd appreciate any suggestion to improve it. Thanks :) Let $X(t)= \int_0^tA(t) dt$, where $A(t)$ is a continuous $n\times n$ matrix. Show that in general we can't conclude  \begin{align*}\frac{d}{dt} \exp(X(t))\not=A(t)\exp(X(t)) \tag{*}\end{align*}
  But if $[A(t),A(s)]=0$ for all $t$ and $s$ in $\mathbb{R}$, where $[\cdot,\cdot]$ is the commutator, then the equality in $(*)$ is true. Since $\exp(X(t))$ is absolutely and uniform convergent for any $t$, we can develop in a power series expansion and the derivative is element by element. Thus \begin{align*}\frac{d}{dt} \exp(X(t))= A(t)+\frac{1}{2}\big(A(t)X(t)+X(t)A(t)\big)+\frac{1}{3!}\big(A(t)X^2(t)+X(t)A(t)X(t)+X^2(t)A(t)\big)+\ldots+\end{align*} and not necessarily $[A(t),X(t)]=0$ for all $t$, therefore the equality in $(*)$ does not hold for all matrices. Now suppose that $[A(t),A(s)]=0$ for all $t$ and $s$ in $\mathbb{R}$. We will show that $[A(t),X(t)]=0$. Let $\mathscr{P}$ a tagged partition of the subinterval $[0,t]$, so let $\{a_k\}_{k=0}^n$ a finite sequence of points which are a partition of $[0,t]$ and let  $\{t_k\}_{k=1}^n$ be the tags of $\mathscr{P}$, that is, $a_{i-1}\le t_i\le a_i$ holds for each $i=1,\ldots, n$. Then we will show that $$A(t)\mathscr{R}(A(t),\mathscr{P})=\mathscr{R}(A(t),\mathscr{P})A(t)$$ where $\mathscr{R}(A(t),\mathscr{P})$ is the Riemann sum corresponding to $A(t)$ and the  partition $\mathscr{P}$. Then \begin{align*}A(t)\sum_{k=1}^n\bigg( (a_k-a_{k-1}) A(t_k)\bigg)&=\sum_{k=1}^n \bigg((a_k-a_{k-1}) A(t)A(t_k)\bigg)\\
&=\sum_{k=1}^n\bigg( (a_k-a_{k-1}) A(t_k)A(t)\bigg)=\sum_{k=1}^n\bigg( (a_k-a_{k-1}) A(t_k)\bigg)A(t) \end{align*} Now let $\mathscr{P}$ a tagged partition of $[0,t]$, such that $\|\mathscr{R}(A(t),\mathscr{P})-X(t)\|<\epsilon$, where $\|\cdot \|$ is the operator norm. Then \begin{align*}\|A(t)X(t)-X(t)A(t)\|&\le \|A(X-\mathscr{R})\|+\|\mathscr{R}A-A\mathscr{R}\|+\|(\mathscr{R}-X)A\|\\
&\le \|A\| \|X-\mathscr{R}\|+\|\mathscr{R}-A\|\|A\|\\
&<2\|A\|\epsilon\end{align*} Letting $\epsilon \downarrow 0$, gives us $[A(t),X(t)]=0$ as desired.Then using the above result, is clear that the equality on $(*)$ holds.","['proof-verification', 'ordinary-differential-equations']"
1428142,Sum of uniform random variables on simplex,"Let $X,X'$ be two independent uniform random variables on $n$-dimensional simplex $\Delta_n= \{(x_1,\ldots,x_n):x_i \geq 0, \sum x_i \leq 1\}$. I am trying to find the probability distribution of their sum 
$$
Y= X+X'
$$
More specifically I am interested in finding the differential entropy of their sum, $h(Y)$.
$$
h(Y)= -\int f_Y(y) \log(f_Y(y)) \ dy
$$ The convolution integrals are tending to be too messy. I couldn't find any other trick apart from convolution.","['probability', 'information-theory', 'probability-distributions']"
1428154,How to prove that a manifold with Self-Dual Riemann tensor is Ricci-flat,"By self-dual I mean that \begin{equation} *\mathcal{R}_{ab}=\mathcal{R}_{ab}\,, \end{equation}
where $\mathcal{R}$ is the curvature 2-form, related to the Riemann tensor $R$ by $\mathcal{R}_{ab}= (1/2) R_{abcd} \,\,e^c\wedge e^d$. By Ricci flat I mean that the Ricci tensor, which can be obtained as the 1-3 contraction of the Riemann tensor, vanishes. I know how to prove the statement in the title by explicit computation, using the symmetry properties of the Riemann tensor $R_{abcd}= - R_{bacd}$, $R_{abcd} = -R_{ab dc}$, $R_{abcd}=R_{cdab}$ , and the algebraic Bianchi identity $R_{a[bcd]}=0$. I would like to see a ""computation free"" proof of the statement in the title.","['differential-geometry', 'riemannian-geometry']"
1428163,Find the sum of the following series to n terms $\frac{1}{1\cdot3}+\frac{2^2}{3\cdot5}+\frac{3^2}{5\cdot7}+\dots$,Find the sum of the following series to n terms $$\frac{1}{1\cdot3}+\frac{2^2}{3\cdot5}+\frac{3^2}{5\cdot7}+\dots$$ My attempt: $$T_{n}=\frac{n^2}{(2n-1)(2n+1)}$$ I am unable to represent to proceed further. Though I am sure that there will be some method of difference available to express the equation. Please explain the steps and comment on the technique to be used with such questions. Thanks in advance !,"['summation', 'sequences-and-series']"
1428192,How to prove this limit?,"I have: $$V_n = \dfrac{1}{2^{n+1}} \cdot\dfrac{\sin{2x}}{\sin{\dfrac{x}{2^n}}}$$ How can I, using $\lim\limits_{x \to 0} \dfrac{\sin{x}}{x} = 1$, prove that: $$\lim_{x \to +\infty} V_n = \dfrac{\sin{2x}}{2x}$$ I have thought about saying that $h = \dfrac{x}{2^n}$, but I can't get it to work out","['sequences-and-series', 'limits']"
1428206,Set of n dice are thrown...,"I need help with this question: A set of n dice is thrown. All those that land on six are put aside and the others are again thrown. This is repeated until all the dice have landed on six. Let N denote the number of throws needed. Let $m_{n} = E[N]$. Let $X_{i}$ denote the number of dice rolled on the ith throw. Find $E[\sum_ {i=1}^{N} X_{i}]$. Here is a solution I was provided with but do not understand the reasoning behind it: $E[X_{i}] = E[E[X_{i}|X_{i-1}]] = E[X_{i-1} - (X_{i-1}*(1/6))] = (5/6)*E[X_{i-1}] = n(5/6)^{i-1}$ Then, $E[\sum_ {i=1}^{N} X_{i}] = \sum_ {k=1}^{n} ([1-(5/6)^{k}]/(1/6))(k)P(N=k)]$. Where, $P(N=1)=(5/6)^{n}$ and $P(N=2) = \sum_ {X=0}^{n-1} \binom {n}{x} (1/6)^{n} (25/36)^{n-x} = (31/36)^{n} - (1/6)^{n}$. Could someone please explain this too me? I appreciate any help. Thanks","['probability-theory', 'conditional-expectation', 'probability', 'dice']"
1428209,Is this intuition for the etale topology essentially correct?,"Suppose I have an etale morphism $f : X \to Y$. If $X$ and $Y$ are Riemann surfaces, then this means that $f$ is a local isomorphism, so at any $y \in Y$ I can find a local inverse $g : U \to X$ where $U \ni y$ is open in the Euclidean topology on $Y$. Now this is meaningless from the Zariski point of view, but since $g$ is the germ of an analytic function at $y$, I can take the entire Riemann surface $S$ associated to $g$, and consider the global analytic function $\widetilde{g} : S \to X$.  I consider this as an analogue of the map $g : U \to X$, and therefore as a partial analogue of the Euclidean open set $U$. Is this basically the right idea?","['etale-cohomology', 'algebraic-geometry']"
1428220,"How to evaluate $\tan20^\circ+\tan40^\circ+\sqrt3\tan20^\circ\tan40^\circ$ using trigonometric ratios of angles $0^o, 30^o, 45^o ,60^o, 90^o$","The question is Evaluate $$\tan20^\circ+\tan40^\circ+\sqrt3\tan20^\circ\tan40^\circ$$ using trigonometric ratios of angles $0^o,\ 30^o,\ 45^o,\ 60^o,\ 90^o$ I played with this problem for a while, but I still can't figure out how to solve it. All I could determine was, $$\tan20^\circ+\tan40^\circ+\sqrt3\tan20^\circ\tan40^\circ$$ $$=({\tan60^\circ})(1-\tan20^\circ\tan40^\circ) + \sqrt3\tan20^\circ\tan40^\circ$$ Now I don't know how to proceed.",['trigonometry']
1428221,Show that an integral domain with finitely many ideals is a field [duplicate],"This question already has an answer here : Commutative integral domain with d.c.c. is a field [duplicate] (1 answer) Closed 7 years ago . I know that an integral domain with finite number of elements is a field, but, how do relate this with the finitude of the number of ideals?","['abstract-algebra', 'integral-domain', 'ideals']"
1428246,How to sum up this series? $\sum_{n=1}^\infty\frac{(-1)^{n-1} B_n}{n}$,"I wonder what is the sum of this series? $$\sum_{n=1}^\infty\frac{(-1)^{n-1} B_n}{n}$$ where $B_n$ are Bernoulli numbers. Wolfram Alpha does not help. P.S. As this series diverges I am interested in generalized summation. Mathematica fails to find the sum using Abel, Borel, Dirichlet, Cesaro and Euler's regularizations.","['summation', 'sequences-and-series', 'bernoulli-numbers']"
1428284,Large prime gap between $10^{4999}-20777$ to $10^{4999}+22669$?,"According to my calculation, the numbers $10^{4999}-20777$ and $10^{4999}+22669$ are consecutive (very probable) primes. 1) Are the numbers really prime ? 2) Are the primes really consecutive ? I did not check all the numbers in one session, so I might have forgotten to
check some numbers.","['prime-gaps', 'prime-numbers', 'number-theory']"
1428337,Pointless Topology Text,"What's a good textbook I can use to learn more about pointless topology ?  Will I need more than a course in regular, old point-set topology and an algebra course which included some category theory to understand the subject?","['book-recommendation', 'reference-request', 'lattice-orders', 'general-topology']"
1428338,Is $(U \cap A \neq \emptyset) \Leftrightarrow (U \cap \overline{A} \neq \emptyset)$ only true in Hausdorff spaces?,"$A$ is a subset of a topological space $X$, in which $U$ is open. I'm asking because I was looking at these exercises (this is the last one), and it specifies that $X$ is Hausdorff. Here's my attempt of a proof: '$\Rightarrow$': $\emptyset \subseteq (U \cap A) \subseteq (U \cap \overline{A})$. '$\Leftarrow$': For any point $x\in U \cap \overline{A}$, every open set $U_x\ni x$ is such that $U_x \cap A \neq \emptyset$. As $U\ni x$, $U\cap A\neq \emptyset$ follows. I haven't used the fact that $X$ is Hausdorff though. Have I made any 'illegal' assumptions, or fallacious deductions?",['general-topology']
1428344,What is the derivation of the derivative of softmax regression (or multinomial logistic regression)?,"Consider the training cost for softmax regression (I will use the term multinomial logistic regression): $$ J( \theta ) = - \sum^m_{i=1} \sum^K_{k=1} 1 \{ y^{(i)} = k \} \log p(y^{(i)} =  k \mid x^{(i)} ; \theta) $$ according to the UFLDL tutorial the derivative of the above function is: $$ \bigtriangledown_{ \theta^{(k)} }J( \theta ) = -\sum^{m}_{i=1} [x^{(i)} (1 \{ y^{(i)} = k \} - p(y^{(i)} =  k \mid x^{(i)} ; \theta) ) ] $$ however, they didn't include the derivation. Does someone know what the derivation is? I have tried taking the derivative of it but even my initial steps seems to disagree with the final form they have. So I first took the gradient $\bigtriangledown_{ \theta^{(k)} }J( \theta )$ as they suggested: $$ \bigtriangledown_{ \theta^{(k)} } J( \theta ) =  - \bigtriangledown_{ \theta^{(k)} } \sum^m_{i=1} \sum^K_{k=1} 1 \{ y^{(i)} = k \} \log p(y^{(i)} =  k \mid x^{(i)} ; \theta) $$ but since we are taking the gradient with respect to $\theta^{(k)}$, only the term that matches this specific k will be non-zero when we taking derivatives. Hence: $$ \bigtriangledown_{ \theta^{(k)} } J( \theta ) =  -  \sum^m_{i=1} \bigtriangledown_{ \theta^{(k)} } \log p(y^{(i)} =  k \mid x^{(i)} ; \theta) $$ then if we proceed we get: $$  -  \sum^m_{i=1} \frac{1}{p(y^{(i)} =  k \mid x^{(i)} ; \theta)} \bigtriangledown_{ \theta^{(k)} } p(y^{(i)} =  k \mid x^{(i)} ; \theta) $$ however, at this point the equation looks so different from what the UDFL tutorial has plus the indicator function disappeared completely, that it makes me suspect that I probably made a mistake somewhere. On top of that it seems that the final derivative has difference, but I don't see any differences/subtractions on my derivation. I suspect a difference might come in when expressing the Quotient rule but the indicator function disappearing still worries me. Any ideas?","['optimization', 'multivariable-calculus', 'machine-learning']"
1428375,The maximum value of determinant,"Suppose we have a matrix $A_{3\times3} = (a_{ij})$, where $a_{ij}\in \mathbb{Z}$ and $|a_{ij}|\le 9$ for $1\le i,j\le 3$. What is the maximum value may take the value $\det (A)$? I'm looking for a reasonable solution without the use of brute-force.","['determinant', 'linear-algebra', 'matrices']"
1428382,A function with total differential 0 suffices $|f(p)-f(q)|\leq M\|p-q\|^2$,"Let $f$ be of class $C^2$ in the plane, and let $S$ be a closed and bounded set such that $f_1(p) = f_2(p) = 0$ for all $p\in S$. Show that there is a constant $M$ such that $|f(p)-f(q)|\leq M\|p-q\|^2$ for all points $p,q\in S$. So I get the function is locally constant on each point, given its differential is 0, so if $S$ is connected any $M$ works, but if it's made of more than 1 connected set, I'm only aware the $M$ I can find depends on both $\sup\{|f(p)-f(q)|:p,q\in S\}$ and the diameter of the set, but I still don't get how to get into it by using either second derivatives or chain rule (this problem comes from the chain rule section in my textbook).",['multivariable-calculus']
1428426,Greatest number of edges in a graph which does not contain even cycles. [duplicate],This question already has an answer here : Prove that the maximum number of edges in a graph with no even cycles is floor(3(n-1)/2) (1 answer) Closed 1 year ago . Suppose we have graph with $n$ vertices and no simple cycles of even length. What is the greatest number of edges in such a graph?,"['graph-theory', 'discrete-mathematics']"
1428430,Average weighted by inverse distance to median equal to median?,"Problem Statement I have a set of $N$ ordered elements such that $x = \{x_1, x_2, ..., x_q, x_p, ..., x_N\}$ where $x_q \le x_m \le x_p$ and $x_m$ is the median of the set $x$. I define a particular inverse weighted mean as $$\langle x\rangle_I \equiv \frac{\sum_{i=0}^N \frac{x_i}{|x_i-x_m|}}{\sum_{i=0}^N \frac{1}{|x_i-x_m|}}$$ Essentially this is just a weighted mean where the weight is the inverse distance each point is from the median. Prove that $\langle x \rangle_I = x_m$ Attempted Solution I ran across this problem because I found someone who had done such a weighted average and realized they were only getting back the median of their set. I then quickly showed with a few scripts that every example I could generate showed the above statement to be true. So I endeavored to rigorously prove it. Case N is odd My first approach was to consider the case when $N$ was odd. This case, I think is trivial since one of the terms, say $x_j$, is actually the median, in which case you get that this average becomes $$\langle x\rangle_I = \frac{\lim_{x_j\to x_m} \frac{x_j}{x_j-x_m} + \epsilon}{\lim_{x_j\to x_m} \frac{1}{x_j-x_m} + \epsilon}$$ where $\epsilon$ is the sum of all the remaining (insignificant) terms and thus they can be ignored. Then you have $$\langle x\rangle_I = \frac{\lim_{x_j\to x_m} \frac{x_j}{x_j-x_m}}{\lim_{x_j\to x_m} \frac{1}{x_j-x_m}} = \lim_{x_j\to x_m}\frac{\frac{x_j}{x_j-x_m}}{\frac{1}{x_j-x_m}} = \lim_{x_j\to x_m} x_j = x_m$$ General case Here is where I run into some difficulties. I don't think I can rely on the same tricks as I did when $N$ was exclusively odd. I can do the following chain though. $$\langle x\rangle_I = \frac{\sum_{i=0}^N \frac{x_i}{|x_i-x_m|}}{\sum_{i=0}^N \frac{1}{|x_i-x_m|}} = x_m \frac{\sum_{i=0}^N \frac{x_i/x_m}{|x_i-x_m|}}{\sum_{i=0}^N \frac{1}{|x_i-x_m|}}$$ If the statement $\langle x\rangle_I = x_m$ is true, then from the last step the fraction must be unity and then following must be true. $$\sum_{i=0}^N \frac{x_i/x_m}{|x_i-x_m|} = \sum_{i=0}^N \frac{1}{|x_i-x_m|}$$ It is at this point where I'm not sure where to go. I've written out this for a few specific cases ($N = 2, 3, ...$ etc.) and it was true for those cases. What's more generating random data sets and running a few quick scripts shows that these two terms are equal. I just want the rigorous proof now. I did think to remove the denominators by getting a common denominator in every term. I can do that by the following. $$\sum_{i=0}^N \Big(\frac{x_i/x_m}{|x_i-x_m|} \prod_{j\ne i}\frac{|x_j-x_m|}{|x_j-x_m|}\Big) = \sum_{i=0}^N \Big(\frac{1}{|x_i-x_m|} \prod_{j\ne i}\frac{|x_j-x_m|}{|x_j-x_m|}\Big)$$ $$\sum_{i=0}^N \frac{x_i/x_m \prod_{j\ne i}|x_j-x_m|}{\prod_{j=0}^N|x_j-x_m|} = \sum_{i=0}^N \frac{\prod_{j\ne i}|x_j-x_m|}{\prod_{j=0}^N|x_j-x_m|}$$ Now I cancel the denominators and I'm left with $$\sum_{i=0}^N \frac{x_i}{x_m} \prod_{j\ne i}|x_j-x_m| = \sum_{i=0}^N \prod_{j\ne i}|x_j-x_m|$$ I don't know if this statement is easier to prove that the one above. In any case, I've reached a point where I'm not sure on the best course of action. Can anyone point me towards a proof? Point to note I'm fairly certain the problem statement is only true if $x_m$ is the median of the set. If it is any other number, it is easy to show the statement is not true because you can readily find a counter-example. That implies to me that one must use the fact that $x_m$ is the median in the proof.","['summation', 'median', 'statistics', 'products']"
1428466,A limit involving a double sum of products of arctangent values,How to evaluate $$\lim_{n \to \infty} \left[ \dfrac{1}{n^2} \sum_{1 \leq i < j \leq n} \tan^{-1} \left ( \dfrac{i}{n} \right) \tan^{-1} \left ( \dfrac{j}{n} \right) \right] ?$$ Any hint would be really appreciated.,"['summation', 'sequences-and-series', 'limits', 'trigonometric-series']"
1428467,"How to show that ""most"" functions $f : [0,1] \to \Bbb R$ are discontinuous everywhere?","Consider the family of functions $\mathcal F$ consisting of all functions $f : [0,1] \to \Bbb R$. I think that most of these functions will be discontinuous everywhere, that is, if you were to pick a random function $f \in \mathcal F$ it will be everywhere discontinuous with probability $1$. How can one prove this statement? My first thought was to somehow prove that the set of $f$ that are continuous at any point $x \in [0,1]$ is countable, but that isn't true (e.g. the family of constant functions in $[0,1]$ is uncountable). Perhaps show that this set is $\aleph_1$ and the original set is $\aleph_2$? (I don't know if $|\mathcal F| = \aleph_2$ is true, it's just a thought).","['probability', 'real-analysis', 'functions']"
1428508,Some questions about generic points and regular points on a scheme,"Recently, I've been reading this paper about Brauer groups. I am not sophisticated with algebraic geometry, and got some confusions about the proof of lemma 3. These questions may be naive for experts. But I still thank to any commentary. Let me cite the Lemma 3 and part of the proof in the paper as following: Let $X$ be a separated noetherian scheme and $U$ an open subscheme of
  $X$. Assume that $U$ contains every generic point and every singular
  point of $X$. Then the restriction homomorphism
  $$H^2(X,\mathbb{G}_m)\rightarrow H^2(U,\mathbb{G}_m)$$ is injective. Let $i:U\rightarrow X$ be the inclusion and let $X^{(1)}$ be the set of points of codimension $1$ in $X$. $\forall x\in X$, let $i_{x*}: Spec(k(x))\rightarrow X$ be the inclusion of $x$ in $X$. Let $V \rightarrow X$ be any etale morphism and $W=V\times_XU$. Here are my confusions: Why any generic point $\eta \in V$ maps to a generic point $\xi  \in X$ ? Why every $y\in V^{(1)}\backslash W$ lies over some $x\in X^{(1)}\backslash U$ ? (i.e., the existence of $x$) By assumption, $x$ is regular. Thus $y$ is regular on $V$. Then Why a regular point $y\in V^{(1)}\backslash W$ defines a discrete rank $1$ valuation $v_y: \mathbb{G}_m(W)\rightarrow \mathbb{Z}$ ? It seems that after getting the discrete valuation $v_y$ we have the sheaf morphism $$\varphi : i_{*}\mathbb{G}_{m} \rightarrow \bigoplus _{x \in X^{(1)} \backslash U}i_{x*}\mathbb{Z}$$ and the last question is How to get $\varphi$ ? By the way, what does the symbol $i_{x*}\mathbb{Z}$'s meaning?","['algebraic-geometry', 'proof-explanation']"
1428518,Submanifold of a smooth manifold is closed iff the inclusion map is proper,I am studying manifolds and have come across Let $M$ be a smooth manifold. Show that a submanifold of $M$ is closed in $M$ if and only if the inclusion map is proper.,"['differential-geometry', 'manifolds']"
1428534,Fibonacci sequence and eigenvalues,"I'm learning about eigenvectors and values, and one of the excercises in my book tackles the fibonacci recursion from this angle. Let $F = \begin{bmatrix}1&1\\1&0\end{bmatrix}^n
\quad\text{ then }\quad \begin{bmatrix}x_{n+1}\\x_n\end{bmatrix} = F^n
\begin{bmatrix}x_1\\x_0\end{bmatrix}
$ To obtain a closed formula for $x_n$, I've obtained the eigenvalues and vectors of $F$, diagonalized it into $PDP^{-1}$ (where $P$ is the eigenvector matrix and $D$ is $\operatorname{diag}(\operatorname{eig}(F))$ and calculated the product of $PD^nP^{-1}$. I feel like I'm missing something.  The eigenvalues are there in the closed formula. Is there a way to deduce the formula from the eigenvalues without calculating  $P^{-1}$ and $PDP^{-1}$?","['eigenvalues-eigenvectors', 'linear-algebra', 'fibonacci-numbers']"
1428577,Sum of the series $\sum\limits_{n=1}^{\infty }\frac{n}{3^n}$,"I want to calculate the sum: $$\sum _{n=1}^{\infty }\:\frac{n}{3^n}\:$$
so $:\:\sum_{n=1}^{\infty}\:nx^n;\:x=\frac{1}{3}\:$ 
$$=x\sum_{n=1}^{\infty}\:nx^{n-1}=x\sum_{n=1}^{\infty}\:n\:\left(\int\left(x^{n-1}\right)dx\right)'=x\sum_{n=1}^{\infty}\:\left(x^n\right)'
$$ now from here I would continue: $x\:\left(\frac{x}{1-x}\right)'=\frac{x}{^{\left(1-x\right)^2}}\:\left(\frac{1}{3}\right)=\frac{3}{4}$ In the answer that I saw, there is another step, from which we get the same result, but I don't understand why it is correct to do so:
$$
x\sum_{n=1}^{\infty}\:\left(x^n\right)'=x\sum_{n=0}^{\infty} ({x^{n}})' =x\cdot \left(\frac{1}{1-x}\right)'=\frac{x}{^{\left(1-x\right)^2}}
$$ Is this just a spelling mistake ?","['power-series', 'sequences-and-series']"
1428602,Four $2$'s to make $7$ [duplicate],"This question already has answers here : Get the numbers from (0-30) by using the number $2$ four times (12 answers) Closed 8 years ago . So I'm trying to use four $2$'s to make the number $7$. I can use parenthesis, addition, subtraction, indicies, addition, division, multiplication edit: also have the same problem with $9$ but I'll try that myself if someone could help with $7$",['algebra-precalculus']
1428608,Why Fourier transform is tempered distribution?,"This question refers to the question Fourier transform in $L^p$ In the answer it is clearly written that ""If $s > 2$, this question quickly becomes technical and requires the theory of distributions. It is not hard to prove that any $f \in L^p$, $1 \le p \le \infty$ induces a tempered distribution $T_f$ and that the Fourier transform of $T_f$ is itself a tempered distribution."" However, I could not prove that both f and its Fourier transform is a tempered distribution.  Any help please?","['definition', 'functional-analysis', 'soft-question']"
1428650,Solving $(y'+1)\ln{\frac{x+y}{x+3}} = \frac{x+y}{x+3}$,"Hello everyone :) This is another task I'm trying to solve and can't seem to get the same result as Wolfram Alpha. Solve the following differential equation: $$(y'+1)\ln{\frac{x+y}{x+3}} = \frac{x+y}{x+3}$$ My attempt: Use substitution $$e^z = \frac{x+y}{x+3}$$
and 
$$y=e^z(x+3)-x$$
$$y=xe^z+3e^z-x$$ 
and
$$y'=e^z+z'xe^z+3z'e^z-1$$
Hence:
$$
(e^z+z'xe^z+3z'e^z)z = e^z
$$
Deviding by $e^z$
$$
z+zz'x+3zz' = 1$$
$$
1+z'x+3z' = \frac{1}{z}
$$
$$
z'(x+3)= \frac{1-z}{z}
$$
$$
\int \frac{z}{1-z}dz = \int \frac{1}{x+3} dx
$$
$$
-\ln{\frac{x+y}{x+3}} - \ln{\bigg|1-\ln{\frac{x+y}{x+3}} \bigg|=\ln{(x+3)}}
$$ EDIT: After fixing the solution, I got the above solution. But still, this solution does not correspond to that on Wolfram Alpha nor can i  find a way to transform them to be equal.","['real-analysis', 'ordinary-differential-equations']"
1428707,Weaker condition for determine if a function is measurable.,"I want to prove the following statement: If $f$ is a real function over a measure space $X$ such {$x$/ $f(x)$ $\ge$ $r$} is measurable for each rational , then $f$ is measurable. So far , this is what I have: Picking up a rational number sequence {$q_{1}$$>$$q_{2}$...$>$$q_{n}$$>$$r$} then lim {$q_{n}$}=$r$ as te sequence {$q_{n}$} is decreasing when $n$ is incresing and is also lower bounded by $r$ then this implies that ($r$ ,$\infty$)=$\bigcup_{n=1}^{\infty}$ [$q_{n}$ ,$\infty$) and I know that a sigma algebra is closed over countable unions How can I end up this proof and properly argue it in case my thought so far is OK.?? Thanks","['lebesgue-measure', 'real-analysis', 'general-topology', 'measure-theory']"
1428709,can't swing the proof for this inequality,"Let $p+p'=1$ and $q+q'=1$ . If $\log(p/q)>\log(q'/p')$ then $(p+q)\log(p/q)>(p'+q')\log(q'/p')$ . This looks deceptively simple to prove, but it's not. I couldn't crack it using Jensen's Inequality. However, it is surely true -- although very tight. I checked it out numerically. I asked a competent colleague, who was also stumped. It came up as I was meditating on asymmetry properties for the Kullback-Leibler divergence.","['probability-theory', 'information-theory', 'inequality']"
1428736,Throwing dice 10 times,"A fair dice was thrown 10 times, and it's been registered that all numbers 1-6 have appeared at least once. If this is true, what's the probability that at least 2 sixes have appeared? At first I thought I should calculate the amount of combinations of die throws that the 6 numbers that have definitely appeared as $\binom{10}{6}$, then dividing it by the amount of all possible outcomes, $6^{10}$, and then multiply it with the probability of throwing at least 1 six in the remaining 4 throws, since one has already been registered, $P(A)= 1-\left(\frac56\right)^4$. Then I began to have serious doubts, as $6^{10}$ is an insanely large number, and whether I'd even need the possible outcomes of the 6 numbers that were thrown, and the only solution I could think of is that the all that matters would be the 4 throws we don't know about, regardless of in which throw we got one of the numbers 1-6, and that the answer would be the already mentioned: $$P(A)= 1-\left(\frac56\right)^4$$ Now I'm having minor doubts about this approach, and don't have a solution to this problem, so I would really appreciate if someone could tell me if this way of thinking is right or wrong.","['dice', 'probability', 'combinatorics']"
1428739,Conditional Probability of Conditional Variance,"Question Let a random variable $X$ be defined on a probability space $\left(
\Omega ,\mathcal{F},P\right)$. For example, if $\Omega =\{a,b,c\}$, then the
a $\sigma$-field  $\mathcal{F}=\left\{  \varnothing ,\left\{
a\right\} ,\left\{ b\right\} ,\left\{ c\right\} ,\left\{ a,b\right\}, \left\{ a,c\right\} ,\left\{ b,c\right\} ,\Omega \right\}$. Consider a $\sigma$-field $\mathcal{H}$, such that  $\mathcal{H\subset F}$, then  I wonder how to compute $\Pr \left[ \operatorname{Var}\left[ X\mid\mathcal{F}\right] >0 \mid \mathcal{H}\right]$? Since $\operatorname{Var}\left[ X\mid\mathcal{F}\right]$ is a random variable the question should make sense. For example, how to evaluate: $\Pr \left[ \operatorname{Var}\left[ X\mid \mathcal{F}\right] >0\mid \{a\} \right] =?$ Current thoughts My line of thought is as follows: $$\Pr \left[ \operatorname{Var}\left[ X\mid\mathcal{F}\right] >0 \mid \{a\} \right] = \frac{1}{\Pr [\left\{ a\right\} ]}\Pr \left[ \left\{ \operatorname{Var}\left[ X\mid\mathcal{F} \right] >0\right\} \cap \{ a\} \right] $$ I conjecture that, the latter equals $\frac{1}{\Pr [\{ a\} ]}\Pr %
\left[ \operatorname{Var}\left[ X\mid\mathcal{F}\cap \{ a\} \right] >0\right] ,$
however, I am not sure. Any suggestions would be welcomed.","['probability-theory', 'conditional-expectation']"
1428744,Grothendieck and Segre's proof of the Hodge Index theorem,"On a field of positive characteristic we have the following well-known and important result: ( Hodge Index theorem ) Let $H$ be an ample divisor on a surface
  $X$, and suppose that $D$ is a divisor, $D \not \equiv 0$, with
  $D.H=0$. Then $D^2<0$. It was independently proven in: Beniamino Segre, Intorno ad un teorema di Hodge sulla teoria della base per la curve di una superficie algebraic (1937) Alexander Grothendieck, Sur une note de Mattuck-Tate (1958) My question is: Are those proofs essentially the same as the one on Hartshorne's Algebraic Geomtry book? (chapter V, section 1)","['algebraic-geometry', 'surfaces', 'divisors-algebraic-geometry']"
1428757,Proving $( A - B ) - C = A - ( B ∪ C )$ using set identities,"I have a list of set identities that I need to apply to prove the left-hand side is equal to the right-hand side. I am stuck on which rules to use. For all sets $A,B,C$,  show that
         $$( A - B ) - C = A - ( B ∪ C ).$$ I found this document of set identities and I see that $A - B$ is equal to $A \cap B^C$, but then I get stuck. I also do not know if I am going in the right direction.","['elementary-set-theory', 'discrete-mathematics']"
1428803,How to derive Clopper-Pearson interval's F and beta approximation?,"It is well-known that there is an approximation of the Clopper-Pearson exact Confident Interval for binomial test. Wiki It just simply claimed, without any reference that: Because of a relationship between the cumulative binomial distribution
  and the beta distribution, the Clopper-Pearson interval is sometimes
  presented in an alternate format that uses quantiles from the beta
  distribution. $$B\left(\frac{\alpha}{2}; x, n - x + 1\right) < \theta
< B\left(1 - \frac{\alpha}{2}; x + 1, n - x\right) $$ And later I found in C-P that this canbe regarded as an interpolation of the binomial c.d.f. due to the CI-belt discrete arguement. But I still have no clue about how it is derived. $$\left( 1 + \frac{n - x + 1}{x\,\,F\!\left[1 - \frac{1}{2}\alpha; 2x, 2(n - x + 1)\right]} \right)^{-1}< \theta < \left( 1 + \frac{n - x}{\left[x + 1\right]\,F\!\left[\frac{\alpha}{2}; 2(x + 1), 2(n - x)\right]} \right)^{-1} $$ And then Agresti also touched it in his Categorical Data Analysis, 3ed and leave it: ...from connections between binomial sums and the incomplete beta
  function and related cdf's of beta and F distributions, the confidence
  interval is... Now I want to ask for a reference which gives full details about the proof of this approximation form to Clopper-Pearson CI since I have already spent quite a while on it. FYI: Agresti and C-P did not solve the problem in their papers, I want a paper or a book which fully gives the arguement about the incomplete Beta function calculation since I myself is not familiar with this sort of manipulation. Thanks. The cross-validated link CrossValidated","['reference-request', 'statistics', 'beta-function', 'binomial-distribution']"
1428814,Combinatorics Locks Question,"A combination lock X number of positions. To open the lock, you move to a certain number in the clockwise direction, then to a number in the counterclockwise direction, and finally to a third number in the clockwise direction. Consecutive numbers in the combination cannot be the same.
If there are 1500 students at a high school, what is the smallest number for the number of positions (X), so that each student has a unique combination? How I did it: For the lock, how it goes is that if it has X positions, you have X numbers to choose from to go clockwise. In the counterclockwise position, you have X-1 positions to go to because of the consecutive numbers rule. For the third movement clockwise, you can also go X-1 because you can't move to the second number. Therefore, the number of combinations is (X) * (X-1) * (X-1).
So we can just test numbers until we get to 1500 or greater.
I tested a couple of numbers and got the answer of 13 positions. Thus, 13 * 12 * 12 = 1872. My textbook says the answer is 12 positions, but how can that be? 12 * 11 * 11 = 1452, which is less than 1500. There wouldn't be enough locks for the 1500 students. Thanks.",['combinatorics']
1428823,Growth of Fibonacci-Like Sequences,"Let $S = \left( a_n \right)_{n=0}^\infty$ be a (non-trivial) sequence of real numbers such that $a_n = a_{n-1} + a_{n-2}$ for $n \geq 2$. We (myself and a friend) are interested in the growth of the sequence $T = \left( |a_n| \right)_{n=0}^\infty$. In particular, which initial values $a_0, a_1$ will result in the slowest growth of the terms of $T$? Through experimentation, we've come to the conjecture that for a given non-zero value of $a_0$, setting $a_1 = a_0 \psi$ yields the slowest growth of $T$ (where $\psi = \frac{1-\sqrt{5}}{2}$).","['sequences-and-series', 'number-theory', 'combinatorics']"
1428824,Geometric\Graphical verification of $ads=vdv$?,"In my Engineering Dynamics class, I've encountered this equation $ads=vdv$.  I could not wrap my head around why it was true, but I was able to come up with a verification of it as such: $\mathrm{ds}=s'(t)\mathrm{dt}=v\mathrm{dt}$ and $dv=v'(t)\mathrm{dt}=a\mathrm{dt}$.  This yields $a*v\mathrm{dt}=v*a\mathrm{dt}$, ""proof"" (such as it is) complete.  However, I still have some issues.  I assume if I have $a(b\mathrm{dt})$, it is equal to $b(a\mathrm{dt})$ because either they are constants or to be evaluated $t$ must be taken consistently, but I can't prove it formally. Also, I can't really see intuitively why this is true.  I can see why $\frac{dy}{dx}$ is the derivative, and graphically so.  Simply draw the graph where we take a value of $f'(x)$ and multiply it by $\Delta x$ to get $\Delta y$ (of course, $dy$ only equals an arbitrarily chosen $\Delta y$ if $f(x)$ is linear.)  But I can't even figure out how to derive the first relationship. So I suppose the meat of my question is if someone would be so kind as to give a better (preferably graphical) description of why $ads=vdv$?","['differential-geometry', 'calculus']"
1428835,Proving two sets are equal,"Suppose we have a claim: $A = \bigcup_{k \in \mathbb N} [-k, \frac{1}{k}) = (-\infty,1)$ = B.
I aim to prove this by showing that the two sets are subsets of each other (i.e. $A \subset B$ and $B \subset A$). As for my strategy of showing this, I am going to grab an arbitrary element from the set A and show that this also belongs to B and vice versa. Now, my problem is that although I can easily show this in picture, I lack the mathematical argument that describes this picture in my head. Any suggestions?",['analysis']
1428875,Motivations for mapping class group representations,"I am new to mapping class groups for surfaces and representation theory. I would like to know why people care about representations of mapping class groups. I think in general representation theory reduces a problem into a problem in linear algebra so that we can attack the problem. But I don't know how this works. I want to know: When we talk about a mapping class group representation (of any kind), what do we expect to get? What are people trying to do with it? Is there any kind of representation that people still look for? What are the good results on mapping class groups obtained using a representation?","['algebraic-geometry', 'mapping-class-group', 'algebraic-topology', 'representation-theory']"
1428884,Show that $f$ is Gateaux differentiable,"Define a function $f:\mathbb{R}^2\rightarrow \mathbb{R}$ as follows
$$f(x,y)= \begin{cases} 
      \frac{2y \exp(-x^{-2})}{y^2+ \exp(-2x^{-2})} & x \neq 0 \\
      0 & \text{otherwise} 
   \end{cases}
$$
Show that $f$ is Gateaux differentiable at $(0,0)$ but that $f$ is not continuous there.
So I think I have to show that $f'((0,0),e_1)$ and $f'((0,0),e_2)$ exits and they are both linear. So far I have that $f'((0,0),e_1) =f'((0,0),e_2)=0$","['optimal-control', 'optimization', 'real-analysis', 'derivatives']"
1428889,"Round Robin ""King"" Style Tournament","I have spent too long trying to figure this out and cannot seem to get it just right, so here I am asking the Math gods.  This weekend I played in a volleyball tournament called ""King of the Beach"", where the tournament was structured with two pools of individual players.   The format was in such a way that each player would play every other player in their own pool, with a player from the second pool as their teammate (ie pool A-F and pool 1-6).  An example match would be the teams of A1 vs B2 or A1 vs C5. Under this format, all letters (A-F) would play all other letters with a number (1-6) partner, and all numbers would player all other numbers with a letter partner. I am trying to set up something similar for a team building exercise at work with 12 different people (needing two pools of 6).  My issue is that I end up with all letters playing all other letters and all numbers playing all other numbers, yet player A may end up playing against number 4 three different times. Maybe what I am trying to do is not even possible, but ideally I would take these two pools and make every letter play every other letter, while also only playing each number once.  I have looked this up online and fail to find anything that is much help, so any help someone may have would be greatly appreciated.  Thanks. Pool 1 A B C D E F Pool 2 1 2 3 4 5 6","['recreational-mathematics', 'combinatorics', 'combinatorial-designs']"
1428890,Uniform Probability Measure on $\mathbb{N}$?,"Hello this problem I am working on has four parts, and I have figured out the first three, but I am stuck on the fourth. For some clarification, the title of the problem I am working on is, Uniform Probability Measure on $\mathbb{N}$? That is why I titled my question so. In searching for a solution to this problem, I found out that such a thing does not exist so I am not asserting that I may have found one or anything like that. For each $A\subset \mathbb{N}$ define $$\rho_n(A)= \frac{1}{n}|A\cap[1,n]|,$$ and say that A has density $\rho(A)=\lim\limits_{n\rightarrow \infty}\rho_n(A)$ if that limit exists. Let $D=\{ A\subset\mathbb{N}:\rho(A) \text{exists}\}.$ 1) Show that $D$ is closed under complements. 2) Show that $D$ is closed under finite disjoint unions. 3) Show that $D$ is not closed under countable disjoint unions. 4) Show that $D$ is not closed under finite non-disjoint unions. For 1) I found that for any $A\in D,$ $\lim\limits_{n\rightarrow\infty} \rho_n(A^c)=1-\lim\limits_{n\rightarrow\infty} \rho_n(A)$ using the $\varepsilon$ definition of limit of a sequence. For 2) I get the answer to be the sum of the limits, again using the $\varepsilon$ definition and this time the triangle inequality. For 3) I defined a countable disjoint sequence so that the $\rho_n \text{'s}$ of their union oscillates between $3/4$ and $1/2$. I want to do something similar as 3) for 4), but I am a little stuck as to how to find a finite number of sets that will give me a nice oscillation like that (I would prefer to find 2 such sets). I do know that the only way to get the sequence to diverge is to make it oscillate in some way. Otherwise, we would get convergence because the sequence is bounded. Any help would be greatly appreciated.","['probability', 'real-analysis', 'measure-theory']"
1428904,Subtle difference between convergence in measure and almost uniform convergence?,"I am reading Terence Tao's post on convergence types . Consider the following two types: We say a sequence $f_n : \mathbb R \to \mathbb R$ converges in measure
  to a function $f$ if and only if for every $\varepsilon > 0$ $$\mu(\{x \in \mathbb R \mid |f_n(x) - f(x)|\ge \varepsilon \})\to 0$$ as $n \to \infty$. On the other hand, $f_n $ converges to $f$ almost uniformly if for every $\varepsilon >
 0$ there is a set $E$ such that $\mu(E) \le \varepsilon$ and outside
  $E$, $f_n\to f$ uniformly. To me these seem very similar. Concretely, the expression $\mu(\{x \in \mathbb R \mid |f_n(x) - f(x)|\ge \varepsilon \})\to 0$ could be rewritten to say that given any $\delta > 0$ then $\mu(\{x \in \mathbb R \mid |f_n(x) - f(x)|\ge \varepsilon \}) \le \delta$. Then the set $\{x \in \mathbb R \mid |f_n(x) - f(x)|\ge \varepsilon \}$ would be the set $E$ outside of which $|f_n - f |<\varepsilon$ that is, outside of which $f_n \to f$ uniformly. Question Please could someone elaborate on the difference of these two
  definitions? Perhaps with an example? I need some help gaining
  intuition.","['real-analysis', 'intuition', 'measure-theory']"
1428910,Counting $K_4$'s in a Paley Graph,"Let $p \equiv 1 \pmod{4}$ be prime, and let $G$ be a graph such that $|V(G)| = p$ and $\{u,v\} \in E(G) \Longleftrightarrow u-v \equiv x^2 \pmod{p}$ for some integer $x$. How many times does $G$ contain $K_4$ as a subgraph? Alternatively, one can ask for the number of subsets $S = \{u_1,\ldots,u_4\} \subset \mathbb{Z}_p$ such that $u_i - u_j$ is a quadratic residue for $i,j \in \{1,\ldots,4\}$, $i \neq j$.","['graph-theory', 'algebraic-graph-theory', 'combinatorics', 'finite-fields']"
1428982,Proving with completeness axiom,"Suppose we claim that if there is a set $E := \{a \in \mathbb{R} : a < \epsilon, \forall \epsilon \in \mathbb{Q}^{+} \}$, then it must be true that $a \leq 0$. I aim to prove this using only the ordered field axioms and the completeness axiom (as per the ""request"" by my professor). I am going to prove it by contradiction. So suppose $\exists a>0$ so that $0 < a < \epsilon, \forall \epsilon \in \mathbb{Q}^{+}$. Now since $a < \epsilon, \forall \epsilon \in \mathbb{Q}^{+}$, we have $a < \frac{\epsilon}{2}$ since $\frac{\epsilon}{2} \in \mathbb{Q}^{+}$. So $2a < \epsilon$. It follows that we can always find $a' \in E$ such that $a<a'$ for any $a \in E$. Now here is my problem. I know that the last sentence in the previous paragraph somehow contradicts the completeness axiom. But I cannot see why. Do you have any suggestions?",['analysis']
1429019,Cartesian product of bijective functions is bijective,"If $A, B, C, D$ are sets such that $A \sim B$ and $C \sim D$, $\exists$ bijections $f: A \to B$ and $g: C \to D$. Let $h: A \times C \to B \times D$ be $h(a,c) = (f(a), g(c))$. Show that $h$ is a bijection (and thus $A\times C \sim B \times D$). How can I solve this?","['elementary-set-theory', 'functions']"
1429057,Is it possible to construct an order on $\Bbb R^2$ that turns it into a set with the least-upper-bound property?,"What I already know: Any ordered field that has the l.u.b.p. is isomorphic to $\Bbb R$. However thing is a bit different in my question, I only request such an order that turns $\Bbb R^2$ into an ordered set with l.u.b.p., but not necessarily an ordered field . Below are two of my failed attempts: 1).$(a,b)<(c,d)$ if $a<c$ or if $a=c$ but $b<d$. Counter-example: the left-half plane $(x,y),x\le 0$. 2). In polar coordinate, with $r\le 0$ and $\theta\in[0,2\pi)$, and let $(0,0)\leftrightarrow (r=0,\theta=0)$. Then $(r_1,\theta_1)<(r_2,\theta_2)$ if $r_1<r_2$ or if $r_1=r_2$ but $\theta_1<\theta_2$. Counter-example: the unit circle. $(2,0)$ is one of its upper bounds but it has no l.u.p. of course. So I'm wondering is it possible for such an order to exist? Ps: I want such an order to be ""non-degenerate"": it should be able to distinguish distinct elements, that's to say, if $A, B$ are distinct , then exactly one of $A<B$ and $B<A$ is true.","['elementary-set-theory', 'real-analysis', 'order-theory']"
1429059,When can a differential be replaced with a gradient (del) operator?,"I'm going through some old engineering lecture notes. I've already spotted some errors in the notes. In an important part of a derivation, the lecturer did the following: $Tds = du + pd(1/\rho)$ can be rewritten as $T\nabla s = \nabla u + p\nabla(1/\rho)$ The equation is the second law of thermodynamics where s, u, p, and $\rho$ are the entropy, internal energy, pressure, and density: all scalars, and all state variables (that do not depend on the path taken to get from point a to point b). I've seen similar transformations done for the material derivative: $TDs/Dt = Du/Dt + pD(1/\rho)/Dt$ where $Dg/Dt = \partial g/\partial t + \vec{u}\bullet\nabla g$ My question is: When are these forms of taking a derivative interchangeable or not (for a scalar in 3D Cartesian space)? Or do you know of a handy online reference that explains it? Take a more general case (still scalar variables): If I can write, $dg = (\partial g/\partial a)da + (\partial g/\partial b)db$ I get the sense that I can't just swap ""d"" for $\nabla$... about notation: let's stick with x,y,z as spatial coordinates, t is time, everything else is an arbitrary scalar, and $\vec u$ is a vector.",['multivariable-calculus']
1429069,Complex Numbers and their relationship with higher Mathematics,"Let $z_1, z_2, \cdots, z_n$ be complex numbers satisfying
$$|z_1|+|z_2|+\cdots +|z_n|=1.$$
Prove that there is a non-empty subset of $\{z_1,z_2,\cdots,z_n\}$ the sum of whose elements has modulus at least $1/4.$ It was a problem from the Chinese Mathematical Olympiad and hence it has an elementary and beautiful solution. But the author also remarked that the bound $1/4$ can actually be improved to $1/\pi$ using higher mathematics. I tried to do it myself but have failed, can anyone help? I learned basic complex analysis, thanks.","['contest-math', 'complex-analysis', 'complex-numbers']"
1429075,Show by an example that in computer arithmetic a + (b + c) may differ from (a + b) + c,"Show by an example that in computer arithmetic a + (b + c) may differ from (a + b) + c Here is what I am thinking, but I am not really sure. Maybe someone can lead me in the right direction or tell me if my answer is sufficient. What I was thinking was it is true that: $a + (b + c) = (a + b) + c$ in normal arithmetic: For example: $5 + (-2 + 7) = 10$ & similarly $(5 - 2) + 7 = 10$ Yet in computer arithmetic this isn't the case..
For example: $\infty + (- \infty + 1) = 0$ But here we find that $(\infty + - \infty) + 1 = 1$ $\therefore$ in regards to computer arithmetic $a + (b + c) \ne (a + b) + c$","['computer-science', 'numerical-methods', 'discrete-mathematics']"
1429107,Hölder's Inequality and the Pigeonhole Principle,"I heard someone in my department claim that Hölder's inequality was just a continuous version of the pigeonhole principle.  It seemed reasonable, but I'm struggling to make their connection precise. Does anyone know of a precise connection between the two?  Are they related at all, or was my source confused? [Edit: Originally this post had ""Markov's inequality"" instead of Hölder's.  I suspect, given my answer below, that my source meant to say Hölder's inequality.]","['pigeonhole-principle', 'measure-theory']"
1429131,Find an equation of the plane perpendicular to vector v and passing through the tip of u,"The given vectors are $v = (3,0,1)$ and $u = (3,1,0)$. I have used the following formula and plugged in what I have been given using vector $v$ as the variables for $i,j,k$ and vector $u$ for $x_0,y_0,z_0$ and have worked out the solution as follows:
$$3(x-3) - 1(y-1) + 1(z-0) = 0$$
ultimately having $3x - y - 8 = 0$ as the equation of the plane. Have I understood this correctly? Any advice appreciated!","['vectors', 'linear-algebra']"
1429194,Probability of winning a game of craps,"The dice game craps is played as follows: The player throws 2 dice, and if the sum is 7 or 11, he/she wins. If the sum is 2, 3, or 12, he/she loses. If the sum is anything else, then he/she continues throwing until that number appears again, or throws a 7, where the game ends in a loss. What I do know is that $P(7) = 6/36$, $P(11)=2/36$. So P(winning) in first roll is $8/36$. Furthermore, the probability of having to roll again will be $1-[P($winning 1st roll$) +P($losing 1st roll$)]=24/36$. It's what happens if the game doesn't end in the 1st roll that's got me a bit confused, since it could go on and indeterminate number of rolls. But since it can't be 7,11,2,3,or 12, it depends on if they roll a 4,5,6,8,9, or 10. Note, this is not a homework problem, but an intriguing one I found in a different book ""Probability Models, Sheldon Ross""","['dice', 'probability', 'gambling']"
1429196,"Prove if {$a_n$} $\rightarrow$ $\infty$, then {$a_n$} is not bounded above. Give an indirect proof.","The book I am using for my Advance Calculus course is Introduction to Analysis by Arthur Mattuck. Prove if {$a_n$} $\rightarrow$ $\infty$, then {$a_n$} is not bounded above. Give an indirect proof. This is my rough proof to this question. I was wondering if anybody can look over it and see if I made a mistake or if there is a simpler way of doing this problem. I want to thank you ahead of time it is greatly appreciated.So lets begin: Proof:","['analysis', 'real-analysis']"
1429201,a conjecture of certain q-continued fractions,"Given the squared nome $q=e^{2i\pi\tau}$ with $|q|\lt1$, define, $$\begin{aligned}F(q)=\cfrac{1-q^2}{1-q^3+\cfrac{q^3(1-q)(1-q^5)}{1-q^9+\cfrac{q^6(1-q^4)(1-q^8)}{1-q^{15}+\cfrac{q^9(1-q^7)(1-q^{11})}{1-q^{21}+\ddots}}}}\overset{\color{red}{?}}=\prod_{n=1}^\infty\frac{(1-q^{12n-2})(1-q^{12n-10})}{(1-q^{12n-4})(1-q^{12n-8})}\\[1.5mm]&\end{aligned}$$
and
$$\begin{aligned}G(q)=\cfrac{1-q^4}{1-q^3+\cfrac{q^3(1-\frac{1}{q})(1-q^7)}{1-q^9+\cfrac{q^6(1-q^2)(1-q^{10})}{1-q^{15}+\cfrac{q^9(1-q^5)(1-q^{13})}{1-q^{21}+\ddots}}}}\overset{\color{red}{?}}=\prod_{n=1}^\infty\frac{(1-q^{12n-4})(1-q^{12n-8})}{(1-q^{12n-2})(1-q^{12n-10})}\\[1.5mm]&\end{aligned}$$ Q: How do we prove rigorously that the two q- continued fractions are equal to the q-series ? (if true, then the two q- continued fractions are reciprocals such that their product is unity , $F(q)\,G(q)=1$.)","['conjectures', 'q-series', 'number-theory', 'continued-fractions']"
1429273,Find $\mathop {\lim }\limits_{x \to \infty } (\sqrt[3]{{{x^3} + 5{x^2}}} - \sqrt {{x^2} - 2x} ) $,"$$\mathop {\lim }\limits_{x \to \infty } (\sqrt[3]{{{x^3} + 5{x^2}}} - \sqrt {{x^2} - 2x} )
$$ My try: $${a^3} - {b^3} = (a - b)({a^2} + ab + {b^2})
$$ $$\mathop {\lim }\limits_{x \to \infty } \frac{{(\sqrt[3]{{{x^3} + 5{x^2}}} - \sqrt {{x^2} - 2x} )(\sqrt[{\frac{3}{2}}]{{{x^3} + 5{x^2}}} + \sqrt[3]{{{x^3} + 5{x^2}}}\sqrt {{x^2} - 2x}  + {x^2} - 2x)}}{{(\sqrt[{\frac{3}{2}}]{{{x^3} + 5{x^2}}} + \sqrt[3]{{{x^3} + 5{x^2}}}\sqrt {{x^2} - 2x}  + {x^2} - 2x)}} = 
$$ $$\mathop {\lim }\limits_{x \to \infty } \frac{{{x^3} + 5{x^2} - {x^2} - 2x}}{{(\sqrt[{\frac{3}{2}}]{{{x^3} + 5{x^2}}} + \sqrt[3]{{{x^3} + 5{x^2}}}\sqrt {{x^2} - 2x}  + {x^2} - 2x)}}
$$ And what's next...? This task in first and second remarkable limits. I think i can replace variable, but how i will calculate it...","['calculus', 'limits']"
1429277,Infinite group with unique maximal subgroup,"If $G$ is a group, then by a maximal subgroup, we mean a proper subgroup, which is maximal w.r.t. subset(subgroup) relation. It is well known that a finite group with unique maximal subgroup must be cyclic. Is there an infinite group with unique maximal subgroup?",['group-theory']
1429287,Showing that right quasi regular elements are invertible,"I am trying to show that a right quasi regular element $(\neq 0$ or $1$) in a ring $R$, where all regular elements different from $1$ are right quasi regular, is invertible. I have managed to show that an element is regular iff invertible so was hoping to show that my element is regular, but can't see how to use this. Any hints? I'm also interested in what the meaning behind these properties are, they seem very arbitrary! (By regular I mean an element a in a ring $R$ such that $aba=a$ for some $b$ in $R$. By right-quasi regular I mean an element a such that $a + x -ax=0$ for some $x$ in $R$.)","['abstract-algebra', 'ring-theory']"
1429357,G has at least one cycle or exactly one cycle?,"Consider a simple connected graph $G$ with n vertices and n edges $(n>2)$.
 Then, which of the following statements are true? $G$ has no cycles The graph obtained by removing any edge from $G$ is not connected $G$ has at least one cycle The graph obtained by removing any two edges from $G$ is not connected My attempt : always false not always true true (since exactly one is subset of at least one !). always true Can you explain in formal way, please?","['eulerian-path', 'graph-theory', 'discrete-mathematics']"
