question_id,title,body,tags
218730,What is the probability distribution of a single genome base pair,"in the genome we have 4 nucleotides (A,T,C,G). Now given a nucleotide sequence like AGT CG TA CG ATCT CG , we can count the number of ""CG"" pairs. That's 3 in this case. (we count all the pairs so, ACT has pairs AC and CT) Now I would like to test the significance of my results, or how likely is it that I would get 3 CG pairs if that sequence was random. I could test that with a permutation test, but that's not completely accurate and might also take time. Now the question: What is the probability distribution of such CG pair, given the length of the sequence and the count of each element (A,C,T,G), so that I could calculate the exact probability that my result could come from a random sequence.","['probability-distributions', 'sequences-and-series', 'probability', 'combinatorics']"
218766,Prove the trigonometric identity $(35)$,"Prove that \begin{equation}
\prod_{k=1}^{\lfloor (n-1)/2  \rfloor}\tan \left(\frac{k \pi}{n}\right)=  \left\{
      \begin{aligned}
       \sqrt{n} \space \space \text{for $n$ odd}\\
       \\
        \ 1 \space \space \text{for $n$ even}\\
      \end{aligned}
    \right.
\end{equation} I found this identity here at$(35)$. At the moment I don't know where I should start from.
Thanks!",['trigonometry']
218767,Relation of Function Field of a scheme to the Local Ring of its Prime Divisor,"Refer to p. 130 in Hartshorne: Let $X$ be a noetherian, integral separated scheme, regular in codimension 1, and let $Y$ be a prime divisor of $X$, with generic point $\eta$. Let $\xi$ be the generic point of $X$ and $K=\mathcal{O}_{X,\xi}$ is the function field of $X$. I can see that $\mathcal{O}_{X,\eta}$ is an integral domain and that it can be injected into $K$. But why is $K$ the quotient field of $\mathcal{O}_{X,\eta}$?",['algebraic-geometry']
218770,When does a Square Matrix have an LU Decomposition?,"When can we split a square matrix (rows = columns) into it’s LU decomposition?  The LUP (LU Decomposition with pivoting) always exists; however, a true LU decomposition does not always exist.  How do we tell if it does/doesn't exist?  (Note: decomposition and factorization are equivalent in this article) From the Wikipedia article on LU decompositions : Any square matrix $A$ admits an LUP factorization. If $A$ is invertible, then it admits an LU (or LDU) factorization if and only if all its leading principal minors are non-zero. If $A$ is a singular matrix of rank $k$, then it admits an LU factorization if the first $k$ leading principal minors are non-zero, although the converse is not true. This implies that for a square matrix: LUP always exists (We can use this to quickly figure out the determinant). If the matrix is invertible (the determinant is not 0), then a pure LU decomposition exists only if the leading principal minors are not 0. If the matrix is not invertible (the determinant is 0), then we can't know if there is a pure LU decomposition. The problem is this third statement here. “If $A$ is a singular matrix of rank $k$, then it admits an LU factorization if the first $k$ leading principal minors are non-zero”, gives us a way to find out if LU decomposition exists for a singular (non-invertible) matrix.  However, it then says, “although the converse is not true”, implying that even if a leading principal minor is 0, that we could still have a valid LU decomposition that we can't detect. This leads us back to the question: is there a way of truly knowing whether a matrix has an LU decomposition?","['matrix-decomposition', 'matrices', 'algorithms']"
218776,How many distinct real root does the equation $x^{4}-x^{3}\cdot\sin(x)-x^{2}\cdot\cos(x)=0 $ have?,How many distinct real root does the equation $x^{4}-x^{3} \cdot \sin(x)-x^{2} \cdot \cos(x)=0 $ have? Is there any quick solution(less than 2 minutes)?,"['trigonometry', 'functions']"
218791,An intuitive vision of fiber bundles,"In my mind it is clear the formal definition of a fiber bundle but I can not have a geometric image of it. Roughly speaking, given three topological spaces $X, B, F$ with a continuous surjection $\pi: X\rightarrow B$, we ""attach"" to every point $b$ of $B$ a closed set $\pi^{-1}(b)$ such that it is homeomorphic to $F$ and so $X$ results a disjoint union of closed sets and each of them is homeomorphic to $F$. We  also ask that this collection of closed subset of $X$ varies with continuity depending on $b\in B$, but I don't understand why this request is formalized using the conditions of local triviality.","['general-topology', 'fiber-bundles', 'fibration']"
218805,The boundary of union is the union of boundaries when the sets have disjoint closures,"Assume $\bar A\cap\bar B=\emptyset$. Is $\partial (A \cup B)=\partial A\cup\partial B$, where $\partial A$ and $\bar A$ mean the boundary set and closure of set $A$? I can prove that $\partial (A \cup B)\subset \partial A\cup\partial B$ but for proving $\partial A\cup\partial B\subset \partial (A \cup B)$ it seems not trivial. I tried to show that for $x\in \partial A\cup\partial B$ WLOG, $x\in \partial A$ so $B(x)\cap A$ and $B(x)\cap A^c$ not equal to $\emptyset$ but it seems not enough to show the result.",['general-topology']
218813,Disjointifying sets if indexed by set that doesn't admit a well-order?,"I have a question about the following: I think this should say ""... if $I$ finite or if there exists a well-order ..."" because if $I$ is a set like this also lets one disjointify $A_i$ with $i \in \{a,b,c,d\}$. Or am I missing something? Thanks!","['elementary-set-theory', 'order-theory']"
218832,How to compute the values of this function ? ( Fabius function ),"How to compute the values of this function ? ( Fabius function )
It is said not to be analytic but $C^\infty$ everywhere.
But I do not even know how to compute its values. Im confused.
Here is the link : http://www.math.osu.edu/~edgar.2/selfdiff/","['ordinary-differential-equations', 'complex-analysis', 'taylor-expansion']"
218837,"short exact sequence of holomorphic vector bundles splits but not holomorphically, only $C^{\infty}$","If there is a short exact sequence of holomorphic vector bundles, $$0 \overset{a_1}{\to} W \overset{a_2}{\to} V \overset{a_3}{\to} F \overset{a_4}{\to} 0,$$ then one can expect a $C^{\infty}$ splitting $$V \cong W \oplus F$$ rather than a holomorphic splitting. I know that a s.e.s. needs consecutive maps to equal $1$, and that for exactness that $im(a_i) = ker(a_{i+1})$. I also know that a vector bundle is just a manifold with the fiber as a vector space (complex here). For a shorthand of notation of a vector bundle, I use $\pi: E \to B$ where $B \times V$ is the product space and $\pi$ is the fiber bundle. Written like a s.e.s., this is $$V \to E \overset{\pi}{\to} B.$$ Also $a_2$ is injective and $a_3$ is surjective. So is the reason why the splitting is only $C^{\infty}$, and not holomorphic, because the maps, either $a_2^{-1}$ or $a_3^{-1}$ are not injective?","['vector-spaces', 'differential-geometry']"
218846,"Showing that if $f''(x) = 0$, $f(x) = ax+b$ without integrating","Assume that $f : A \rightarrow \mathbb{R}$ is two times differentiable with $f''(x)=0$
  for all $x \in A$, with $A$ an interval. Show, (not by integration), that $f$ is of the form $f(x) = ax + b$ for some constants $a, b$. My answer:
I will use the Mean Value Theorem: Take $x,y \in A, x<y$. Applying the Mean Value Theorem on $[x,y]$ gives:
$$f''(c)=\frac{f'(y)-f'(x)}{y-x}$$ for some $c \in A$. If $f''(x)=0 $ for all $x \in A$, then $f''(c)=0$, wich means that $f''(c)=\frac{f'(y)-f'(x)}{y-x}= 0$, which implies that $f'(y)-f'(x)=0$. So $f'(y)=f'(x)$. Set $k$ equal to this common value. Because x and y are arbitrary, it follows that $f'(x)=a$ for all $x \in A$ We are now given that $f'(x)=a$ for all $x \in A$. This means that, if we take $x,y \in A, x<y, $, by applying the Mean Value Theorem on [x,y], 
$$f'(c)=\frac{f(y)-f(x)}{y-x}$$ for some $c \in A$. We know that $f'(x)=a$ for all $x \in A$, which means that $$f'(c)=\frac{f(y)-f(x)}{y-x}=a \implies f(y)-f(x)=a(y-x)$$ What's next? I could also use the definition of derivative, considering: $$f'(x)=a = \lim_{x \to c} \frac{f(x)-f(c)}{x-c}$$ How can I show that $f(x) = ax + b$ ?","['derivatives', 'real-analysis']"
218849,Rigorous definition of positive orientation of curve in $\mathbb{R}^n$,"When one formulates the Green Theorem the phrase ""curve positively oriented"" comes up. After a thorough google search the only description of the above phrase seems to be: ""A curve has positive orientation if a region $R$ is on the left when traveling around the outside of $R$, or on the right when traveling around the inside of $R$. 
(taken from http://mathworld.wolfram.com/CurveOrientation.html ) This is of course a not rigorous definition as the terms ""left,right,outside,inside"" are not (to my knowledge) properly defined in the language of mathematics. My question is, what is the rigorous definition of orientation of a curve in $\mathbb{R}^n$?","['multivariable-calculus', 'analysis']"
218854,What can we tell about a sequence of measurable functions on a finite measure space such that $\sup_n \int_X |f_n(x)|^2 d\mu < \infty$?,"I found this on a qualifier exam, and I think it will help me understand $L^p$ spaces better. Let $f_n$ be a sequence of measurable function on a finite measure space. Suppose that
$$\sup_n \int_X |f_n(x)|^2 d\mu < \infty$$
and that $\lim_{n\to \infty}f_n(x) =: f(x)$ exists $\mu$-almost everywhere. Which of the following are true (proving or providing a counterexample): (1) $\int_X |f(x)|^2 d\mu < \infty$ (2) $ \int_X |f(x)| d\mu < \infty$ (3) $\lim_{n\to\infty} \int_X |f_n(x) - f(x)|^2 d\mu = 0$ (4) $\lim_{n\to\infty} \int_X |f_n(x) - f(x)| d\mu = 0$","['lebesgue-integral', 'measure-theory', 'convergence-divergence', 'integration']"
218870,Does de Franchis' theorem hold over any base field,"Let $k$ be a field and let $X$ be a hyperbolic curve over $k$. Then, there are only finitely many hyperbolic curves $Y$ over $k$ dominated by $X$. I know this statement holds over $k=\mathbf{C}$. In particular, it holds over $k=\overline{\mathbf{Q}}$. Does it hold over any field $k$? What about a number field?","['arithmetic-geometry', 'riemann-surfaces', 'algebraic-geometry', 'algebraic-curves']"
218893,Dimension of local rings at closed points in an irreducible scheme,"Let $X$ be an irreducible separated scheme of finite type over an algebraically closed field $k$.
In the proof of Theorem 8.15 Hartshorne claims that for any closed point $x\in X$ we have $dim\mathcal{O}_{X,x}=dim X$. This is an exercise in Hartshorne in the case that X is integral, i.e. also reduced. But the proof i know does not work in this more general situation and i was not able to find this statement anywhere else.
Does anyone know how this works in this case ?",['algebraic-geometry']
218900,Average proportion for proportions with different denominators,"Say I have an experiment in which subjects are asked to respond to some stimulus. Their responses are transcribed and coded, first as ""Valid/Invalid"", and then for the valid responses, ""Correct/Incorrect"". I would like to compute the average of the proportion, $\frac{\text{number correct}}{\text{number valid}}$. There seem to be two different approaches to this. The first is I could 
use the total proportion correct, $\frac{\sum{Correct_n}}{\sum{Valid_n}}$. The second would be to find the actual average of the proportions. I cannot straightforwardly compute the average proportion by adding the subject proportions and dividing by the number of subjects, as each subject had a different number of valid responses, and therefore each proportion has a different denominator. So, I end up the the following expression: $\frac{n*[(Valid_2 \times Valid_3 \times...Valid_n)Correct_1 +  (Valid_1 \times Valid_3 \times ... Valid_n)Correct_2... ]}{Valid_1 \times Valid_2 \times...Valid_n}$ While the two approaches seem similar, I can't figure out if they are going to end up being the same thing, and further I can't decided which one makes more sense, or even if either of them do.","['statistics', 'average']"
218902,Proving a binomial sum with simple result,"In deriving a formula I've come up with an expression that I need to prove, specifically: $$(-1)^n = \sum_{j=1}^n (-1)^j \binom{n+1}{j+1} j^n$$ where $n$ is a positive integer. This seems remarkably simple to me, and considering that I'd never seen it before I didn't believe it, but upon checking numerically it seems true. If this is true, why is it true?","['binomial-coefficients', 'combinatorics']"
218928,Why are Prime Divisors on Curves just Closed Points?,"Why is it true that prime divisors on nonsingular curves (curve: integral separated scheme of finite type over an algebraically closed field, of dimension 1 with all local rings regular) are only the closed points? In particular, if $C$ is curve, then $dim(C)=1$. Now i can see that if $p$ is a closed point, then it is a prime divisor, since it is irreducible and it has codimension 1 (the codimension could not be higher than 1, otherwise we have a violation of $dim(C)=1$). But why can we not have a closed irreducible proper subset $Z$, which is not a point, such that $Z$ is a prime divisor? Intuition: if every closed, irreducible proper subset $Z$ of a curve $C$, contains a closed point $p$ of $C$, then $Z=\left\{p\right\}$, otherwise we would have a chain $\left\{p\right\} \subsetneq Z \subsetneq C$. Is that the case? Is it true that all points of a curve are closed?",['algebraic-geometry']
218929,"Showing that $f$ is differentiable at $x=0$, using the mean value theorem","The following exercise is again about the Mean Value Theorem :) Let $f : [0,1] \rightarrow \mathbb{R}$ be continuous and differentiable on $(0,1)$.
  Assume that $$ \lim_{x\rightarrow 0^+} f'(x)= \lambda.$$ Show that $f$ is differentiable (from the right) at $0$ and that $f'(0)=\lambda$. Hint : Mean Value Theorem. What exactly is 'differentiable from the right'? Do I have to show that the limit as $x$ approaches $0$ from the right side exists? How can I do that? How can I use the Mean Value Theorem to show that the derivative on $0$ equals $\lambda$? Mean Value Theorem: If $f:[a,b] \rightarrow \mathbb{R}$ is continuous on $ [a,b] $ and differentiable on $ (a,b)$, then there exists a point $ c \in (a,b)$ where $$ f'(c)= \frac{f(b)-f(a)}{b-a}.$$","['derivatives', 'real-analysis']"
218934,How do you sum PDF's of random variables?,"I have a question asking me to determine the PDF of $L=X+Y+W$, where $X$, $Y$ and $W$ are all independent. $X$ is a Bernoulli random variable with parameter $p$, $Y \sim \mathrm{Binomial}(10, 0.6)$ and $W$ is a Gaussian random variable with zero mean and unit variance (meaning is is a standard normal random variable). I know the PDF's of $X$, $Y$ and $W$ (sort of hard to type out, but I know them). Could I get some sort of hint as to how these are added together?",['probability']
218941,"A question on Newton's ""theorem about ovals""","This is a question about a result from Newton's Principia . It says, roughly, that the if you intersect lines $ax + by + c$ with a smooth, closed, convex curve, then the area of the curve that the line cuts off cannot be expressed as an algebraic function of $a, b$ and $c$. My question is regarding Newton's proof. There are a couple versions out there, but I'll summarize the one on Wikipedia. Fix a point $P$ inside the curve, and fix a line $L$ through $P$. Construct a spiral, $f$ as follows: draw another line $M$ through $P$, and let $\theta$ be the angle this makes with $L$. Thus $L$ and $M$ close off a sector of the curve, with some area $A(\theta)$. If we plot $(A(\theta), \theta)$ in polar coordinates, we get a spiral. Newton observes that this spiral intersects any line through $P$ infinitely many times. Thus the spiral cannot be algebraic, for if it were then there would be infinitely many solutions to a polynomial. Fine. I agree with Newton's argument that the spiral cannot be algebraic, but how does this imply the original statement? More specifically, the proof is only successful because we allow the spiral to continue infinitely. But why can't we make a periodic function $B(\theta)$ such that $B$ expresses the area of the sector with angle $\theta$ for $\theta \in [0, 2\pi]$?","['geometry', 'algebraic-curves']"
218949,Show uncountable set of real numbers has a point of accumulation [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Show that every uncountable set of real numbers has a point of accumulation.","['general-topology', 'real-analysis', 'analysis']"
218959,What is the cardinality of the set of all sequences in $\mathbb{R}$ converging to a real number?,Let $a$ be an real number and let $S$ be the set of all sequences in $\mathbb{R}$ converging to $a$. What is the Cardinality of $S$? Thanks,"['cardinals', 'elementary-set-theory']"
218960,Trace of an integral,"Given appropriate matrices $A$ and $B_x$, is $\,\,tr\left(\int A B_x dx\right) = \int tr\left(A B_x\right) dx\,\,?$ If so, is it true by the argument that it transfers from (discrete) sums?","['trace', 'matrices', 'calculus', 'integration']"
218971,Prove that the function$\ f(x)=\sin(x^2)$ is not uniformly continuous on the domain $\mathbb{R}$.,"If I want to prove that the function $\ f(x)=\sin(x^2)$ is not uniformly continuous on the domain $\mathbb{R}$ , I need to show that: $\exists\varepsilon>0$ $\forall\delta>0$ $\exists{x,y}\in\mathbb{R}\ : |x-y|<\delta$ and $|\sin(x^2) - \sin(y^2)|\geq\varepsilon$ . So let's take $\varepsilon = 1$ . Then I want $|\sin(x^2)-\sin(y^2)|\ge1$ . That's the case if $\sin(x^2)=0$ and $\sin(y^2)=\pm1$ . Thus $x^2=n\pi$ and $y^2=n\pi + \frac{1}{2}\pi$ . Now I'm stuck on expressing x and y, which I want to express in $\delta$ , to ensure that $|x-y|<\delta$ . Thanks in advance for any help.","['continuity', 'real-analysis', 'uniform-continuity']"
218991,"Prove that the function $\Phi :\mathcal{F}(X,Y)\longrightarrow Y$, is not injective.","Given Let $\mathcal{F}(X,Y)$ be the set of all functions $f:X\longrightarrow Y$, and let $x_0 \in X$. Given:
    $$\Phi :\,\mathcal{F}(X,Y)\longrightarrow Y$$
    Defined by $\Phi (f)=f(x_0)$ for $f\in\mathcal{F}(X,Y)$. Definition The function f is injective if $f(x)=f(y)$ implies $x=y$ for
    all $x,y\in Dom(f)$ The function f is surjective if for every $b\in Codom(f)$
    there exists some $a\in A$ such that $f(a)=b$ The function f is bijective if it is both injective and
    surjective Exercise Is $\Phi$ surjective, injective, bijective? My Solution $\Phi$ is surjective Proof :  let $y\in Y$. We will show that there exists some
element $x\in X$ such that $\Phi(f)=f(x)=b$. Define $f(x)=y, \forall
    x\in X$, We know $f\in\mathcal{F}(X,Y)$, because $\mathcal{F}(X,Y)$
is the set of all functions from $X$ to $Y$ therefore
$\Phi(f)=f(x_0)=y$, thus $\Phi$ is Surjective
$\hspace{15cm}$ ${\Large ▫}$ $\Phi$ is not injective: Proof :  Special case If $|X|=1$, then
$\Phi$ is injective. But when $|X|>1$, $\Phi$ is not injective. Ok here I get stuck. I
cant figure out how to define two functions such that $\Phi$ isn't
injective. My Question Is the surjective proof correct? How can I define two functions in $\mathcal{F}$ such that
  $\Phi$ is not injective? Can someone give me some hints/tips?","['elementary-set-theory', 'functions']"
218992,Solving the system of equations $\begin{cases} R \sin r = H \sin \theta \\ R \cos r = H \cos \theta \end{cases}$ for $R$ and $r$,"I am working on a program which will predict the tides, but have come across a problem when using the simplified harmonic method of tidal prediction, I understand the whole thing but cannot do the following, this is what I have so far: $$R\sin(r) = H\sin(\theta)$$ $$R\cos(r) = H\cos(\theta)$$ How do I obtain the values of just R and r alone? EDIT 2! it is slightly more complex than first explained, this is more like what I am trying to work with: $$R\sin(r) = A\sin(Y) + B\sin(Z)$$ $$R\cos(r) = A\cos(Y) + B\cos(Z)$$ Thanks.","['trigonometry', 'roots', 'algebra-precalculus', 'systems-of-equations']"
219027,Affine algebraic varieties defined over a [not necessarily algebraically closed] field,"Let $k$ be a field.
Let $\bar k$ be an algebraic closure of $k$.
Let $G = \mbox{Aut}(\bar k/k)$.
Let $n \ge 1$ be an integer.
$G$ acts on $\bar k^n$ in the obvious way.
Let $V$ be an irreducible algebraic set in $\bar k^n$.
Let $\sigma \in G$.
It is easy to see that $\sigma(V) = \{\sigma(x)\colon x \in V\}$ is an irreducible algebraic set.
Hence $G$ acts on the set of irreducible algebraic sets in $\bar k^n$. Is the following proposition true?
If yes, how do we prove it? Proposition. Let $\mathfrak p$ be a prime ideal of the polynomial ring $k[X_1, \dots, X_n]$.
Let $V$ be the algebraic set in $\bar k^n$ defined by $\mathfrak p$.
Let $V_1, \dots, V_r$ be the irreducible components of $V$.
Then $G$ acts transitively on the set $\{V_1, \dots, V_r\}$.
Moreover, $\dim V_i = \dim k[X_1, \dots, X_n]/\mathfrak p$ for all $i$. Conversely let $W$ be an irreducible algebraic set in $\bar k^n$.
Then the $G$-orbit $\{\sigma(W)\colon \sigma \in G\}$ is finite.
Let $V = \bigcup_{\sigma\in G} \sigma(W)$.
Then there exists a prime ideal $\mathfrak p$ of $k[X_1, \dots, X_n]$ such that
$V$ is the algebraic set defined by $\mathfrak p$.",['algebraic-geometry']
219041,"Partition of a set, definition not clear","From wikipedia: Equivalently, a set P is a partition of X if, and only if, it does not contain the empty set and: The union of the elements of P is equal to X. (The elements of P are said to cover X.) The intersection of any two distinct elements of P is empty. (We say the elements of P are pairwise disjoint.) I clearly understand that the intersection between partition is empty (point 2), but how can the union of a partition can be the all elements in the set? If it is a partition, shouldnt they be just a part? I imagine a set divided in 3 and the elements in the first part are not all the elements of the second part. How do you explain this?","['elementary-set-theory', 'set-partition', 'definition']"
219043,Fixed Point of a complex dynamical spiral system,"Last semester I finished my first class on complex variables and of course we had to show that $i^i$ was real. That got me wondering about quantities like $i^{i^i}$ and similar power towers. For my investigation, I let $f:\mathbb{C} \to \mathbb{C}$ where $f(z)=(ui)^z$ with $u \in \mathbb{R}$ and let $f_n(z)$ denote the quantity $f(f(\cdots f(z)$ where $f$ occurs $n$ times. I then plotted the points generated by $\{f(ui),f_2(ui),f_3(ui),\ldots,f_k(ui)\}$ for various values of $u$. The plots that I obtained are quite interesting! The top one is a plot of the points $\{f(ui),f_2(ui),f_3(ui),\ldots,f_{100}(ui)\}$ with the real axis on the horizontal and imaginary on the vertical, and $u$ going from .05 to 2.05 in increments of .1. Before .05 it blows up and after 2, the points seem to settle into 3 groups near $(0,u),(0,0)$, and $(1,0)$. The second picture is the same as the first, but with lines connecting $f_k(ui)$ to $f_{k+1}(ui)$. Just a note, the dots do spiral inward with successive nestings, so my inkling of convergence is well-founded, and $|f_k(ui)|$ seems to converge only for $0 < u <2$. Does anyone have any insights into the values of $u$ for which this system converges or if this has been written about before? Even reference to a method for determining the existence of a fixed point would be appreciated.","['dynamical-systems', 'fixed-point-theorems', 'complex-dynamics', 'complex-analysis']"
219067,Higher Dimensional analogue to translation and rotation.,"Is there a higher dimensional analogue to translation and rotation. Translation occurs along an axis, and rotations occurs along a plane. Is there some isometry that occurs along a 3-plane (hyperplane?) and does it have a name? Do these isometries generalize well? That is, are there $\binom{N}{n}$ different $n$-dimension isometries in $N$ space where a rotation would be a 2-dimension isometry?","['geometry', 'linear-algebra']"
219069,"Showing that if a subgroup is normal, it's surjective homomorphic image is normal","$\alpha : G \to H$ is a surjective homomorphism. And $U \subset G$ is a subgroup of $G$. Verfiy the claim - The image of $U$, ie $\alpha(U)$, is a subgroup of $H$, and if $U$ is normal in $G$, then $\alpha(U)$ is normal in $H$. Answer: Firstly, do I have to show $\alpha(U)$, is a subgroup of $H$ or is that statement just a statement of fact as part of the question? Anyway here is what I have done..taking it as a given that $\alpha(U)$, is a subgroup of $H$ - As $U$ is normal we have $U = gUg^{-1}$ $\alpha(U) = \alpha(gUg^1) =$ {applying homomorphic mapping into H} = $\alpha(g)\alpha(U)\alpha(g^{-1})$ Is that correct? I have a feeling I should take the $-1$ exponent outside the bracket as an extra final step or is that superfluous?",['group-theory']
219081,Calculus 1- Find directly the derivative of a function f.,The following limit represents the derivative of a function $f$ at a point $a$. Evaluate the limit. $$\lim\limits_{h \to 0 } \frac{\sin^2\left(\frac\pi 4+h \right)-\frac 1 2} h$$,"['calculus', 'derivatives']"
219098,integral of exponential divided by polynomial,"I would like to solve the integral $$A\int_{-\infty}^\infty\frac{e^{-ipx/h}}{x^2+a^2}dx$$
where h and a are positive constants.
Mathematica gives the solution as $\frac\pi{a}e^{-|p|a/h}$, but I have been trying to reduce my reliance on mathematica. I have no idea what methods I would use to solve it. Is there a good (preferably online) resource where I could look up methods for integrals like this fairly easily?","['definite-integrals', 'improper-integrals', 'calculus']"
219100,$Gr_2^+(\mathbb R^4) \cong S^2 \times S^2$,Let $Gr_2^+(\mathbb R^4)$ be the oriented Grassmanian of 2-planes in $\mathbb R^4$. How would one go about showing that this is diffeomorphic to $S^2 \times S^2$?,"['differential-topology', 'differential-geometry']"
219106,Inverse mapping theorem over a complete non-archimedean field,"Let $K$ be a complete field with respect to a non-trivial non-archimedean absolute value $|\cdot|$.
Let $E$ be a vector space over $K$.
A norm $||\cdot||$ on $E$ is a map $E \rightarrow \mathbb{R}$ satisfying the following properties. 1) $||x|| = 0$ if and only if $x = 0$. 2) $||\alpha x|| = |\alpha|||x||$ for all $\alpha \in K$ and all $x \in E$. 3) $||x + y|| \le max(||x||, ||y||)$ for all $x, y \in E$. Clearly $||x - y||$ defines a metric on $E$.
A vector space over $K$ equipped with a norm is called a normed vector space.
If $E$ is complete with respect to this metric, $E$ is called a Banach space. Let $E, F$ be normed vector spaces over $K$.
Let $U$ be an open subset of $E$.
Let $a \in U$.
Let $f\colon U \rightarrow F$ be a map.
Suppose there exists a continuous linear map $L\colon E \rightarrow F$ such that
$$\frac {||f(x) - f(y) - L(x - y)||}{||x - y||} \rightarrow 0$$ when $(x, y) \rightarrow (a, a)$.
Then $f$ is called strictly differentiable at $a$.
It is easy to see that $L$ is uniquely determined by $f$ and $a$.
We denote $L$ by $Df(a)$. The following proposition is stated without a proof in Bourbaki, Variete differentielles et analytiques.
How do we prove it? Proposition Let $E, F$ be Banach spaces over $K$.
Let $U$ be an open subset of $E$.
Let $a \in U$.
Let $f\colon U \rightarrow F$ be a map.
Suppose $f$ is strictly differentiable at $a$ and $Df(a)$ is an isomorphism $E \rightarrow F$.
Then there exist an open neighborhood $U_0$ of $a$ such that $U_0 \subset U$
and an open neighborhood $V_0$ of $f(a)$ with the following properties. 1) $f|U_0$ is a homeomorphism $U_0 \rightarrow V_0$. 2) Let $g$ be the inverse of $f|U_0$. Then $g$ is strictly differentiable at $f(a)$. 3) $Dg(f(a)) = Df(a)^{-1}$.","['functional-analysis', 'p-adic-number-theory']"
219108,An idempotent operator is compact if and only if it is of finite rank,Would you help me to solve this problem. Show that an idempotent operator on hilbert space is compact if and only if it has finite rank.,"['hilbert-spaces', 'functional-analysis']"
219109,Convergence of an infinite product $\prod_{k=1}^{\infty }(1-\frac1{2^k})$? [duplicate],"This question already has answers here : Is the product $\prod_{k=1}^\infty \frac{2^k-1}{2^k}$ necessarily $0$? [duplicate] (3 answers) Closed 9 years ago . Problem: I want to prove that the infinite product $\prod_{k=1}^{\infty }(1-\frac{1}{2^{k}})$ does not converge to zero. It doesn't matter to find the value to which this product converges, but I am still curious to know if anybody is able (if possible of course) to find the value to which this infinite product converges.  I appreciate any help. I tried the following trick: $\prod_{k=1}^{n}(1+a_{k})\geq 1+\sum_{k=1}^{n}a_{k}$ which can be easily proven by inudction, where $a_{k}>-1$ and they are all positive or negative. In this case, $a_{k}=-\frac{1}{2^{k}}$, but I get : the infinite product is greater than or equal to zero.","['sequences-and-series', 'infinite-product', 'real-analysis']"
219112,Yet another balls and bins problem,"If $p_n$ denote the probability that when $n$ balls are randomly put in $n$ bins then there is at least one bin with exactly one ball. Is there a simple (involving only little computation) reason for why $p_{n+1}>p_{n}$ if $n>3$ ? This simple looking problem turns out to be not too simple, perhaps because ${p_{n}}/{p_{n-1}}$ turns out to be approximately $e(1-{1}/{n})^{n-1}$ and hence whatever the difference is, it is extremely small. Thanks","['balls-in-bins', 'probability']"
219133,Non-Isomorphic Group Extensions,"This is a question from a problem set on group cohomology, a subject I've just begun to learn. Let $B$ be a finite group and $A$ be abelian. I am looking for two groups $G_1$ and $G_2$ such that $G_1$ and $G_2$ are isomorphic as groups but $$1\rightarrow A\rightarrow G_1\rightarrow B\rightarrow 1$$ and $$1\rightarrow A\rightarrow G_2\rightarrow B\rightarrow 1$$ are not isomorphic as extensions. It has been suggested that I use $A=C_3^2$ and $B=C_2$. However, since the orders of $A$ and $B$ are relatively prime in this case, doesn't the Shur-Zassenhaus Lemma guarantee that the sequence splits so that there is only one extension? If this is the case, then how could we produce two non-isomorphic extensions? If someone could point out where I'm confused, I'd be very grateful. Thanks.","['group-cohomology', 'group-extensions', 'abstract-algebra']"
219135,How many limit points in $\{\sin(2^n)\}$? How many can there be in a general sequence?,"Analysis question - given a sequence $\{a_n\}_{n=1}^\infty$, how many limit points can $\{a_n\}$ have? Initially I thought only $\aleph_0$, or countably many, because there are only countably many terms in such a sequence. But then I thought about the sequence where $a_n = \sin(2^n)$, which looks like this for the first 1000 terms. This sequence has no repeating terms, or else $\pi$ is rational. However I do not think every real number in $[0,1]$ appears in this sequence, as then the reals are countable, an absurd conclusion. It would not surprise me if this sequence has limit points, but how many? I do not immediately see any reason why $\sin(2^n)\notin (r-\epsilon,r+\epsilon)\subset[0,1]$, for $n$ large enough, because $r$ is arbitrary. This seems to imply that this sequence could have every point in $[0,1]\subset \mathbb R$ as a limit point, which slightly frightens me. So, How many limit points does $\{\sin(2^n)\}_{n=1}^\infty$ have? And in general, How many limit points can a sequence with countably many terms have? What is an example of a sequence with the maximum number of limit points? I would really like to see a proof of the answer to this last statement. I can easily come up with a sequence with $\aleph_0$ limit points, but I can't prove that is the upper bound. Thanks for any help and tips on this topic.","['convergence-divergence', 'real-analysis']"
219139,Prove that $\int_0^1|f''(x)|dx\ge4.$,"Let $f$ be a $C^2$ function on $[0,1]$ . $f(0)=f(1)=f'(0)=0,f'(1)=1.$ Prove that $$\int_0^1|f''(x)| \, dx\ge4.$$ Also determine all possible $f$ when equality occurs.","['inequality', 'calculus', 'definite-integrals', 'functional-inequalities', 'real-analysis']"
219148,Infinite-dimensional singular value decomposition,"Say, I have an $n\times n$ matrix $w_{ij}$ . I can perform a singular value decomposition such that $$ w_{ij}=\sum_l \sum_n u_{il}\lambda_{ln}v_{jn} $$ with $\lambda_{ln}$ diagonal.  Now, is there such a generalization so that, given a function of two variables $w(\theta_1, \theta_2)$ , $$ w(\theta_1 ,\theta_2)=\int dy \int dx \,u(\theta_1 ,x) \, \lambda(x,y) \, v(\theta_2 ,y) $$ where $\lambda$ plays a similar role like it did in the SVD?  For instance,  say I have the following $$ \exp {[\alpha \cos(\theta-\phi)]} $$ is it possible to find a decomposition such that $$ \exp {\alpha \cos(\theta-\phi)}=\iint dx \, dy \, u(\theta,x) \, \lambda(\alpha,x,y) \, v(\phi,y) $$","['linear-algebra', 'svd', 'functional-analysis']"
219149,A curious identity on sums of secants,"I was working on proving a variant of Markov's inequality, and in doing so I managed to come across an interesting (conjectured) identity for any $n\in\mathbb{N}$: $$\sum_{m=0}^{n-1} \sec^2\left(\dfrac{(2m+1)\pi}{4n}\right)=2n^2.$$ I tried to prove this via induction, averaging arguments, trig identities, etc., but to no avail. Are there any suggestions on where this identity may be proven or how I should proceed?","['trigonometry', 'summation', 'sequences-and-series']"
219150,Discrete Subgroups of $\mbox{Isom}(X)$ and orbits,"Let $X$ be a metric space, and let $G$ be a discrete subgroup of $\mbox{Isom}(X)$ in the compact-open topology. Fix $x \in X$. If $X$ is a proper metric space, it's not hard to show using Arzela-Ascoli that $Gx$ is discrete. However, is there an easy example of a metric space that is not proper so that $Gx$ is not discrete for a discrete $G \subset \mbox{Isom}(X)$? I thought about permutations of an orthonormal basis in $l^2(\mathbb{N})$, but no luck there.","['geometry', 'metric-spaces']"
219187,Numerical approximation of a complex integral with a nested exponential,"I've been working on a maths problem as part of my Physics PhD; but have been stumped by the following integral. All I need to know is a numeric approximation to the integral (along with an estimation of the error); but if an analytic solution exists, that would be fantastic. $$\int_{-\infty}^{\infty} G(x,\sigma) e^{(-i(\delta x - \nu \exp(-\kappa x)/\kappa))}dx$$ where $G(x,\sigma)$ is a Gaussian distribution in $x$ with standard deviation $\sigma$ and mean zero; and where $\delta$, $\nu$ and $\kappa$ are real constants. I have tried several approaches, including method of steepest descent/stationary phase and assymptotic expansions in $x$; but every method apart from a brute force ODE solver or polygon approach [both of which are extremely slow, such that I have not actually allowed them to complete] have proven to be very unreliable. I have considered contour integration also, but since this integral does not have any poles, I am not sure how helpful this would be. I have not found there to be any simplifying relationships between the real constants, but here are some typical values: $$
\begin{eqnarray}
\delta&\approx&5\times10^6\\
\nu&\approx&5\times10^6\textrm{ And slightly different from $\delta$}\\
\kappa&\epsilon& \mathbb{R^+}\\
\sigma&\gg&\frac{1}{\kappa}
\end{eqnarray}
$$ Anyway, if anyone has any ideas on how such an integral might be solved, I would be ever so grateful.","['physics', 'integration', 'complex-analysis']"
219190,Injective map on coordinate ring implies surjective?,"Suppose that $f:X\rightarrow Y$ is a morphism between two affine varieties over an algebraically closed field $K$. I believe that if the corresponding morphism of $K-$algebras, $f^\ast:K[Y]\rightarrow K[X]$ is injective, it is not necessarily true that $f:X\rightarrow Y$ must be surjective but I have yet to come up with a counterexample. Is there such a counterexample?","['algebraic-geometry', 'abstract-algebra', 'polynomials']"
219200,Number of ring homomorphisms from $\mathbb Z_{12}$ to $\mathbb Z_{28}$.,"Question: Find the number of non trivial ring homomorphisms from $\mathbb Z_{12}$ to $\mathbb Z_{28}$. ($f$ is not necessarily unitary, i.e., $f(1)$ need not be $1$.) Suppose $f$ is a ring homomorphism from $\mathbb Z_{12}$ to $\mathbb Z_{28}$. Consider $f$ as a additive group homomorphism.  Let $k= |\ker f|$ and 
$ t = |\operatorname{im}(f)|$. Then $k\mid 12$ and $t\mid 24$ and $kt=12$, by first isomorphism 
theorem of groups. There are two possibilities $k=3$, $t=4$   and $k=6$, $t=2$. For the first case $f$ should map $1$ to an element of the subgroup generated by $7$ as there is a unique subgroup of $\mathbb Z_{28}$ of order $4$ generated by $7$. For the second case $1$ has to map to $14$, for the same reasoning. So there are at most two ring homomorphisms from $\mathbb Z_{12}$ to $\mathbb Z_{28}$.
Question is how to check the possible maps which are ring homomorphisms. Thanks.","['ring-theory', 'abstract-algebra']"
219274,Dominated Convergence Theorem for Sets,"This was an interesting question, which gives the analog of the better known Dominated Convergence Theorem for Lebesgue integrable functions. Suppose $E_{n}\to E$ pointwise (e.g. the indicator functions $\chi_{E_{n}}\to\chi_{E}$ pointwise) and that $E_{n}\subset F$ for all $n$ where $m(F)<\infty$.  (Note, all sets in this exercise are assumed to be Lebesgue measurable on $\mathbb{R}^{d}$). Then show that $E$ is Lebesgue measurable, that $\lim_{n\to\infty}m(E_{n})=m(\lim_{n\to\infty}E_{n})=m(E)$, and finally that the hypothesis $m(F)<\infty$ cannot be dropped, even when $m(E_{n})<\alpha$ for some uniform bound. The first part is easy, since one just uses the definition of $\lim\sup$ or $\lim\inf$ to express $E$ as a countable intersection/union of Lebesgue measurable sets.  The third part is also clear, since one can just translate well-known examples for Riemann integrals into their set analogs.  For example, take the $E_{n}$ to be the regions in $\mathbb{R}^{2}$ bounded by $n\cdot\chi_{(0,\frac{1}{n})}$ and the x axis; then one has $\lim_{n\to\infty}m(E_{n})=1$, yet $m(\lim_{n\to\infty}E_{n})=0$.  The obvious problem is that the sets $E_{n}$ escape to ""vertical infinity"" near the origin; the dominated convergence shuts down this possibility.  But the example is helpful, since while the process of commuting limits (even in the Lebesgue theory; although at least in the Lebesgue theory, measurable sets and functions are closed under limits, unlike the Riemann/Jordan theory) is not generally permissible, the intuition that they should commute remains valid under the general blanket hypotheses of the convergence theorems, which is where you intuition comes from anyway. Anyway, here's my attempt to the solution of part (2). I have a feeling that it should be simpler than this massive computation; but even if it's not, I want to verify that mine is correct, since I haven't had much experience working with $\lim\sup$ and $\lim\inf$ operations of sets/sequences. Since $E_{n}\to E$, we have the equality of $\lim\sup$ and $\lim\inf$ of the sequence, and so
$$E=\bigcup_{j=1}^{\infty}\bigcap_{k=j}^{\infty}=\bigcap_{j=1}^{\infty}\bigcup_{k=j}^{\infty}E_{k}.$$
Thus, $E$ is the countable intersection and union of Lebesgue measurable sets, and so is itself a Lebesgue measurable set. The following computation
\begin{align*}
m(E)
&=m\left(\lim_{n\to\infty}E_{n}\right)\\
&=m\left(\lim\inf\limits_{n\to\infty}E_{n}\right)\\
&=m\left(\bigcup_{n=1}^{\infty}\bigcap_{k=n}^{\infty}E_{k}\right)\\
&=m\left(\lim_{n\to\infty}\bigcap_{k=n}^{\infty}E_{k}\right)\\
&=\lim_{n\to\infty}m\left(\bigcap_{k=n}^{\infty}E_{k}\right)\\
&=\lim_{n\to\infty}m\left(\inf_{k\geq n}E_{k}\right)\\
&\leq\lim_{n\to\infty}\inf_{k\geq n}m(E_{k})\\
&=\lim\inf\limits_{n\to\infty}m(E_{n})\\
&\leq\lim\sup\limits_{n\to\infty}m(E_{n})\\
&=\lim_{n\to\infty}\sup_{k\geq n}m(E_{k})\\
&\leq\lim_{n\to\infty}m\left(\sup_{k\geq n}E_{k}\right)\\
&=\lim_{n\to\infty}m\left(\bigcup_{k=n}^{\infty}E_{k}\right)\\
&=m\left(\lim_{n\to\infty}\bigcup_{k=n}^{\infty}E{k}\right)\\
&=m\left(\bigcap_{n=1}^{\infty}\bigcup_{k=n}^{\infty}E_{k}\right)\\
&=m\left(\lim\sup\limits_{n\to\infty}E_{n}\right)\\
&=m\left(\lim_{n\to\infty}E_{n}\right)\\
&=m(E)
\end{align*}
The computations are justified by the following observations.  First, $E_{n}\to E$ implies that $\lim\sup_{n\to\infty}E_{n}=\lim\inf_{n\to\infty}E_{n}=\lim_{n\to\infty}E_{n}=E$.  By definition $\lim\inf_{n\to\infty}=\bigcup_{n=1}^{\infty}\bigcap_{k\geq n}^{\infty}E_{k}=\lim_{n\to\infty}\bigcap_{k=n}^{\infty}E_{k}$, and if we define $G_{n}=\bigcap_{k\geq n}^{\infty}E_{k}$, we see that $G_{n}\subset G_{n+1}$ for all $n$.  Hence, the $G_{n}$ form an upward monotonic sequence of sets and so we may apply upward monotonic convergence theorem to establish the commutation of the first limit.  It is helpful to use the technically incorrect notation $G_{n}=\inf_{k\geq n}E_{k}$ (where the $\inf$ is understood to be with respect to set inclusion).  Then it becomes clear that $G_{n}\subset E_{k}$ for all $n\leq k$, so from monotonicity we have $m(G_{n})\leq m(E_{k})$ for all $k\geq n$, and so the above inequality holds.  The remaining statements follow from the definition of $\lim\inf_{n\to\infty}$ for a sequence of real numbers.  Justifications of the $\lim\sup$ computations are essentially the same as for the $\lim\inf$ case (though the computations are backwards since I wanted to combine everything into one inequality); except that we apply the downward monotone convergence theorem to the sequence defined by $G_{n}=\bigcup_{k\geq n}^{\infty}E_{k}$ to establish the commutation of the final limit.  This is valid since $G_{n}\supset G_{n+1}$ for all $n$, and since $E_{k}\subset F$ and $m(E_{k})<m(F)<\infty$ hold for all $k$, we see that each $G_{k}$ is bounded, and so any union of the $G_{k}$ is bounded with finite measure.  The inequality is of course obtained from monotonicity and noting that $G_{n}\supset E_{k}$ for all $k\geq n$.  Putting this together then gives us the inequality
$$\lim\inf_{n\to\infty}m(E_{n})\leq m\left(\lim_{n\to\infty}E_{n}\right)\leq\lim\sup\limits_{n\to\infty}m(E_{n}).$$
But since $E_{n}$ converges, it is clear that we have an equality, and so
$$\lim\inf_{n\to\infty}m(E_{n})=\lim\sup\limits_{n\to\infty}m(E_{n})=\lim_{n\to\infty}m(E_{n})=m\left(\lim_{n\to\infty}E_{n}\right)=m(E)$$
as required.","['measure-theory', 'analysis']"
219278,The role of dual space of a normed space in functional analysis,We have known that dual space of a normed space is very important in functional analysis. I would like to ask two questions related dual space of a normed space: What is the motivation of constructing dual space of a normed space? What is the main role of dual space of a normed space in functional analysis? Thank you for all your construction and comments.,"['normed-spaces', 'functional-analysis']"
219333,Homomorphisms from $S_4$ to $\mathbb Z_2$,"Suppose $\phi : S_4 \rightarrow \mathbb Z_2$ is a surjective homomorphism. Find $\ker\phi$. Determine all homomorphisms from $S_4$ to $\mathbb Z_2$. My solution: since $\phi$ is surjective, then by the first isomorphism theorem, $S_4/\ker\phi \cong \mathbb Z_2$. Therefore, by computation, $\ker\phi = A_4$. Now, for the second part, I have some trouble since they ask for all the possible homomorphisms. I know that the map that takes even permutations to $0$ and odd permutations to $1$ is a homomorphism. But, my question is: How to make sure this is the only one? thanks,","['finite-groups', 'group-theory', 'abstract-algebra']"
219335,Separated varieties and uniqueness of extension,"I would like to know if my solution to the following exercise is correct. If not, then I will be grateful for a correct argument. (I am working with varieties over an algebraically closed field, not schemes) Exercise: Suppose that $f,g:X \to Y$ are two morphisms, where Y is separated. If $f$ and $g$ agree on some dense open subset $U \subset X$ then $f = g$. My argument: Let $W = \{x \in X\:|\:f(x) = g(x)\}$. I know by assumption that $U \subset W$, and wish to show that $W = X$. Since $Y$ is separated, the graph of $f$ (call it $\Gamma_f$) is closed in $X \times Y$. So by continuity, the preimage $(\mathrm{id},g)^{-1}(\Gamma_f) = W$ is closed in $X$. But then $X = Cl_X(U) \subset Cl_X(W) = W \Rightarrow W = X$ as required.",['algebraic-geometry']
219366,Minimum of two stopping times is a stopping time.,"So far I've already shown that the sum and the maximum of two stopping times is a stopping time, but the minimum is giving me some problems which I just can't get around. This is what I've tried: Let $\mathbb{F}$ be a filtration, and $S, T$ be stopping times. Then:
\begin{align*}
\{S \wedge T\} &= \{\min(S,T) = n\} \\
&= \left(\bigcup_{i=n}^\infty \{S = i\} \cap \{T=n\}\right) \bigcup \left(\bigcup_{i=n}^\infty \{T = i\} \cap \{S=n\}\right)
\end{align*}
I thought we might be able to use the identity $\bigcup_{i=n}^\infty \{S=i\} = \left(\bigcup_{i=0}^{n-1}\{S=i\} \cup \{S=\infty\}\right)^c$ to convert this to the union/intersection/complement of $\mathcal{F}_n$ measurable sets, but the problem is that $\{TS= \infty\}$ is only $\mathcal{F}_\infty$ measurable, so it seems to be a dead end. Is it a stopping time? It seems since we are dealing with a union from $n$ to $\infty$ it shouldn't be. For clarification, these are stopping times for discrete martingales, so $T:\Omega \rightarrow \{0,1,\dots\}\cup \{\infty\}$ is a stopping time iff $\{T = n\} \in \mathcal{F}_n$ for all $n \in \mathbb{N}$.","['probability-theory', 'stopping-times']"
219377,"Show that $(f_n)$ is equicontinuous, given uniform convergence","Let $f_n: [a,b] \rightarrow, n \in \mathbb{N}$, be a sequence of functions converging uniformly to $f: [a,b] \rightarrow \mathbb{R}$ on $[a,b]$. Suppose that each $f_n$ is continuous on [a,b] and differentiable on (a,b), and that the sequence of derivatives $(f'_n)$ is uniformly bounded on (a,b). This means that there exists an $M>0$ such that $|f'_n(x)| \le M$ for all $x \in (a,b)$ and all $n \in \mathbb{N}$ Question: Show that $(f_n)$ is equicontinuous. Known definitions: A sequence of functions $(f_n)$ converges uniformly to a limit function $f$ on a set $A$, if, for every $\epsilon >0$ , there exists an $N\in \mathbb{N}$. such that$|f_n(x) - f(x)| < \epsilon$ whenever $n \ge N$ and $x \in A$ Cauchy Criterion for Uniform Convergence: A sequence of functions $(f_n)$ converges uniformly on a set $A$, if and only if, for every $\epsilon >0$ , there exists an $N\in \mathbb{N}$. such that$|f_n(x) - f_m(x)| < \epsilon$ for all $n,m \ge N$ and all $x \in A$ A sequence of functions $(f_n)$ defined on a set $E$, is called equicontinuous if for every $\epsilon >0$ , there exists a $\delta>0$ such that  $N\in \mathbb{N}$. such that$|f_n(x) - f_n(y)| < \epsilon$ for all $n \in N$ and $|x-y| \lt \delta$ in $E$ A sequence of derivatives $(f_n')$ is uniformly bounded on (a,b) if there exists an $M>0$ such that $|f_n'(x)|≤M$ for all $x∈(a,b)$ and all $n∈N$","['sequences-and-series', 'real-analysis']"
219384,What are the irreducible representations of the cyclic group $C_n$ over a real vector space $V$?,It suffices just to consider a linear transformation $f$ such that $f^n=id$ and require $V$ to have no proper subspace invariant under $f$. But I still don't have a picture of what's going on.,"['representation-theory', 'abstract-algebra']"
219434,is a one-by-one-matrix just a number (scalar)?,"I was wondering. Clearly, we cannot multiply a (1x1)-matrix with a (4x3)-matrix; However, we can multiply a scalar with a matrix. This suggests a difference. On the other hand, I was, for example, in an econometrics lecture today, where we had for a (Tx1)-vector $\underline{û}=\left(
\begin{array}{c}
û_1\\
\vdots\\
û_T\end{array}\right)$: $S_{ûû}:= \sum_{i=1}^T û_i^2$ shall be minimized. We see see that
  $S_{ûû}=\underline{û}^T\underline{û}$. Well, formally, shouldn't it be $(S_{ûû})=\underline{û}^T\underline{û}$ or $S_{ûû}=\det(\underline{û}^T\underline{û})$, to ensure that we stay in the space of matrices and not suddenly go to the space of scalars? So here, the professor (physicist) not only treats $\underline{û}^T\underline{û}$ like a scalar, but also calls it a scalar. Is this formally legit or a wrong simplification (though it does not seem to have any impact, and surely makes life easier)?","['matrices', 'complex-numbers']"
219447,Rank of the differential of a composition,"Let $U$ be an open subset of $\mathbb{R}^2$ and $f:U\to \mathbb{R}$ a differentiable function. Let $S=\{(x,y,f(x,y)): x\in U\}$ be the graph of $f$. Let $V$ be an open subset of $\mathbb{R}^2$ and $g:V\to \mathbb{R}^3$ be a one-to-one differentiable map such that $g(V)=S$. Assume that $dg$ is of rank 2 at each point of $V$. Let $\pi(x,y,z)=(x,y)$ be the projection. My question is: Must $\pi\circ dg$ be of rank 2 at each point of $V$?","['differential-geometry', 'multivariable-calculus', 'real-analysis']"
219449,Show that f is uniformly continuous and that $f_n$ is equicontinuous,"$f_n: A \rightarrow \mathbb{R}$,$n \in \mathbb{N}$ is a sequence of functions defined on $A \subseteq \mathbb{R} $. Suppose that $(f_n)$ converges uniformly to $f:  A \rightarrow \mathbb{R}$, and that each $f_n$ is uniformly continuous on $A$. 1.) Can you show that $f$ is uniformly continuous on A? 2.) Can you show that $(f_n)$ is equicontinuous? We are given that$(f_n)$ converges uniformly to $f$. This means that for every $\epsilon>0$ there exists an $N\in \mathbb{N}$, such that $|f_n(x)-f(x)| <\epsilon$ whenever $n \ge N$ and $x \in A$. We have to show that $f$ is uniformly continuous on $A$, which means that for every $\epsilon >0$ there exists a $\delta>0$ such that $|x-y|<\delta$ implies |$f(x)-f(y)|<\epsilon$ We need to show that for every $\epsilon>0$ there exists a $\delta>0$ such that $|f_n(x)-f_n(y)|< \epsilon$ for all $n\in \mathbb{N}$ and $\|x-y|< \delta$ in $A$","['sequences-and-series', 'continuity', 'real-analysis']"
219465,Balls in a box probabilities,"A box is filled out by $1,000$ balls. The box can be thought of as containing $V$ sites and $V$ balls, with $V=1,000$. The box is repeatedly shaken, so that each ball has enough time to visit all $1,000$ sites. The ball are identical, except for being uniquely numbered from $1$ to $1,000$. What is the probability that all of the balls labeled from $1$ to $100$ lie in the left hand side of the box? What is the probability that exactly $P$ of the balls labeled $1$ to $100$ lie in the left hand side of the box? Using Stirling's approximation, show that this probability is approximately Gaussian. Calculate the mean of $P$.  calculate the root mean square fluctuations of $P$ about the mean. Is the Gaussian approximation good? Any insight is greatly appreciated.",['statistics']
219489,Some Questions on Determinants and Geometry,"For real valued matrices, I know that the absolute value of the determinant is equivalent to the volume of the vectors forming the parallelepiped in the matrix. Suppose that $A$ and $B$ are real valued, $n \times n$ matrices with $det (A) = a$ and $det(B) = b$. So my questions are inspired by Wilks' Lambda : What happens in the geometric sense when adding $A+B$?  Vector-wise addition, sure, but is there a simpler (alternative) way of explaining the idea of what happens to the parallelepipeds defined by two matrices $A$ and $B$?  I guess I want a statement that says,  something along the lines of $$\\\\ \text{Given the parallelepiped defined by $A$ and parallelepiped defined by $B$,$\\$ then the parallelepiped defined by $A+B$ is ...}$$ Given $det (A) = a$ and $det(B) = b$, is there a way to describe $det(A+B)$ in terms of $a$ and $b$? for $n=2$ we know the 
$$\begin{array}{rcl}
a&=& a_{11} \cdot a_{22} - a_{12} \cdot a_{21}\\
b&=& b_{11} \cdot b_{22} - b_{12} \cdot b_{21}\\
det(A+B)&=& (a_{11} + b_{11}) \cdot (a_{22}+b_{22}) - (a_{12} + b_{12}) \cdot (a_{21} + b_{21})\\
&=& a_{11}\cdot a_{22}+b_{11}\cdot b_{22} + a_{11} \cdot b_{22}+b_{11}\cdot a_{22} - \left( a_{12}\cdot a_{21}+b_{12}\cdot b_{21} + a_{12} \cdot b_{21}+b_{12}\cdot a_{21}\right) \\
&=&\left( a_{11} \cdot a_{22} - a_{12} \cdot a_{21}\right) + \left(  b_{11} \cdot b_{22} - b_{12} \cdot b_{21}\right) + \left( a_{11} \cdot b_{22}+b_{11}\cdot a_{22} -  a_{12} \cdot b_{21}+b_{12}\cdot a_{21}\right)\\
&=& a+b+\left( a_{11} \cdot b_{22}+b_{11}\cdot a_{22} -  a_{12} \cdot b_{21}+b_{12}\cdot a_{21}\right)
\end{array}$$
The math gets ugly for $n=3$ and higher. Thanks.","['statistics', 'geometry', 'linear-algebra', 'determinant']"
219499,Geodesics on the torus,"[This is a follow-up to my question Is there a Möbius torus? ] Mark L. Irons' paper The Curvature and Geodesics of the Torus gives a concise overview of the geodesics on the torus: There are five clear-cut families of geodesics. Most of the geodesics are ""chaotic"": aperiodic and covering either the entire surface - by spiraling endlessly around the torus - or substantial parts of it. Some of the geodesics are ""boring"": the meridians, the inner and the outer equator A few of them are ""æsthetically pleasing"": returning to their starting point after just a few circuits around the z axis What I tried to ask in my previous question : Can the structure of geodesics on the torus change drastically when
  twisting the ""hose"" before gluing its ends? For example: There might be no equator anymore because after twisting the (two) equators lost their ""ends"". [I also posted this question at MO .]","['geometry', 'manifolds', 'differential-geometry']"
219505,How to Show $\log n = O(\sqrt{n})$,"I am trying to solve this issue but I do not know how to handle the division by $O(\sqrt{n})$. Prove the following using limits and L’Hôpital’s Rule: That $\log n$ is
$O(\sqrt{n})$. $$
\begin{align*}
\lim_{n \rightarrow \infty}\frac{\log n}{\sqrt{n}} &= \lim_{n \rightarrow \infty}\frac{\log n}{10^{1/2 \log n}}\\
\end{align*}
$$","['asymptotics', 'calculus', 'limits']"
219512,Continuous extension of a real function,"Related; Open set in $\mathbb{R}$ is a union of at most countable collection of disjoint segments This is the theorem i need to prove; ""Let $E(\subset \mathbb{R})$ be closed subset and $f:E\rightarrow \mathbb{R}$ be a contiuous function. Then there exists a continuous function $g:\mathbb{R} \rightarrow \mathbb{R}$ such that $g(x)=f(x), \forall x\in E$."" I have tried hours to prove this, but couldn't. I found some solutions, but ridiculously all are wrong. Every solution states that ""If $x\in E$ and $x$ is not an interior point of $E$, then $x$ is an endpoint of a segment of at most countable collection of disjoint segments."". However, this is indeed false! (Check Arthur's argument in the link above) Wrong solution Q4.5; http://www.math.ust.hk/~majhu/Math203/Rudin/Homework15.pdf Just like the argument in this solution, i can see that $g$ is continuous on $E^c$ and $Int(E)$. But how do i show that $g$ is continuous on $E$?","['general-topology', 'real-analysis']"
219519,Combinatorial properties of permutation groups,"Let $P_n$ denote the set of pairs $(x,y)$ of permutations on $S_{2n}$, where each permutation is a product of $n$ disjoint cycles of length two. Let i and j be two fixed elements of the set $\{1,2, \cdots,2n\}$. Select an element $(x,y)$ of $P_n$. What is the probability that the product $xy$ contains $i$ and $j$ in the same cycle?","['permutations', 'probability', 'combinatorics']"
219552,Probability that a sequence repeats itself,"Given an infinite sequence $a_n$ of uniformly random integers $0$ to $9$, what is the probability there exist an integer $m$ such that the sequence $a_1$ to $a_m$ is equal to that from $a_{m+1}$ to $a_{2m}$? What if we restrict to two symbols, or $k$ symbols?","['sequences-and-series', 'probability', 'random', 'combinatorics']"
219565,Number of matrices whose square is identity,"How many matrices are such that $A^2 =I$, where $A$ is a $2\times2$ matrix and $I$ is a $2\times2$ identity matrix? I can only think of the identity and it negative are they more? Is it an application of Cayley-Hamilton theorem. I have seen a similarly post by I cannot follow it. Could someone answer in simple and understandable terms.",['linear-algebra']
219592,Finding the min of an integral,"So I have to find the following $$\min_{a,b,c\in\mathbb{R}}\int_{-1}^{1} |x^3-a-bx-cx^2|^2dx$$ I have a hint at a solution which says to consider $X=\{\mbox{polynomials of degree} \leq 2\}$. So then we have $$\min_{a,b,c\in\mathbb{R}}\int_{-1}^{1} |x^3-a-bx-cx^2|^2dx=\inf_{g\in X} ||x^3-g||$$ for some $g\in X$ Where the norm $||.||$ is defined using the inner product $<f,g>=\int_{-1}^{1} f(x)\bar{g(x)}dx$ So then I think I'm supposed to use an orthogonal projection somehow I think (and maybe find some orthonormal basis?) but I'm a bit lost as to how to do any of this. Thanks for any help. For completeness I am putting my solution (from the answers below). The problem reduces to finding a basis for $X$ and then orthonarmalizing it. We then use the fact that the orthohgonal projection onto the space $X$ will give the minimal distance to it so we need to calculate:
$$||x^3-P(x^3)||$$ where $P(x^3)=\sum_{i=1}^{3} <x^3,e_i>e_i$ for an orthonormal basis $\{e_i\}$. Noting that the set $\{1,x,x^2\}$ spans the space $X$ we then apply the gram-schmidt process to this set to give a set of orthogonal vectors: $$\{1,x,(x^2-\frac{1}{3})\}$$. This basis now needs to be normalized but if we notice that in : $$\sum_{i=1}^{3} <x^3,e_i>e_i$$ The first and third terms will cancel as the integrand will be odd, so we only need to normailze the middle vector which gives $\{\sqrt{\frac{3}{2}\}}$. And so $$P(x^3)=<x^3,\sqrt{\frac{3}{2}}x>\sqrt{\frac{3}{2}}x=\frac{3}{5}x$$ So we now have $||x^3-\frac{3x}{5}||=\sqrt{\int_{-1}^{1} (x^3-\frac{3x}{5})^2dx}=\sqrt{\frac{8}{175}}$ Which is the desired distance","['hilbert-spaces', 'analysis']"
219602,Applying an inversion technique to Characteristic Functions,"I am struggling with this concept (self-study). Could someone show me how to explicitly apply the inversion formula for these examples? I am working through about 15 examples, but these 3 seemed sufficiently different to help me do the rest. $\phi_1(t)=(1-|t|)_+$ $\phi_2(t)=\sum_{n=-\infty}^{\infty}\phi_1(t+2n\pi)$ $\phi_3(t)=(1-\frac{t^2}{2})e^{-t^2/2}$ Work/Thoughts The only reference to the inversion formula that I have found is the following theorem: Assumptions: 1-$\phi$ is a characteristic function of a given probability distribution $F$ 2- $F$ has continuity points $a, b$ with $a<b$. $F(b)-F(a)=\lim_{n\to\infty}\frac1{2\pi}\int_{-\infty}^{\infty}\frac{e^{-ita}-e^{-itb}}{it}\phi(t)e^{-t^2/n}dt$ And I believe this simplifies to: $\lim_{n\to\infty}\frac1{2\pi}\int_{-n}^{n}\frac{e^{-ita}-e^{-itb}}{it}\phi(t)$ From here I am not sure what to do. Thanks for any help. more thoughts I have read about two kinds of invertible CFs- those that are integrable, and those that are periodic. $\phi_2(t)$ is obviously of the periodic nature. I also understand the following properties about characteristic functions: If $F$ and $G$ are probability distributions and $G$ is absolutely continuous, then $F*G$ has density $\int_{-\infty}^{\infty}g(u-x)F(dx)$ This this helpful at all, perhaps for number 3?","['probability-theory', 'measure-theory', 'characteristic-functions']"
219606,Combinations of i.i.d Inverse Chi-Square RVs and their characteristic functions,"I am working on a few self-study problems in probability/measure theory and am stuck on characteristic functions. I have the following problem: Given: $X_1,\ldots,X_n$ are iid inverse chi-square(1) random variables with PDF: $f(x;\nu)=\frac{2^{-\nu/2}}{\Gamma(\nu/2)}x^{-\nu/2-1}e^{-1/(2x)}$ What is the characteristic function for $\frac14(X_1-X_2)$ What is the characteristic function for $\frac1{n^2}(X_1+\cdots+X_n)$ Is the second example related to the normal distribution? Lastly, how do I verify that $E(X_1^r)<\infty$ if and only if $r<\frac12$ Ideas/attempts I found the CF of $X_1$ to be $\frac{2}{\Gamma\frac{\phi}{2}}\left(\frac{-it}{2}\right)^{\frac\phi4}K_{\frac\phi2}\left(\sqrt{-2it}\right)$ just by searching around, but I do not know/understand what $K$ represents. I am having trouble seeing what the sum or difference of two RVs with the above CF signify, and similarly a sum of them. For the third part, the ""if"" is fairly straightforward, but how do I approach showing/proving the ""only if""? More thoughts I have found the following results for combinations of CFs: $\phi_{aX+b}(t)=e^{ibt}\phi_X(at),\forall a,b,t\in\mathbb{R}$ If $X_1,...,X_n$ are independent, then $\phi_{X_1+...+X_n}(t)=\prod_{k=1}^n\phi_{X_k}(t)$ If $X_1,X_2$ are independent and have the same distribution, then $\phi_{X_1-X_2}(t)=|\phi_{X_1}(t)|^2$ These facts help get things started, but I'm at a loss of how to continue. Many thanks!","['probability-theory', 'measure-theory', 'characteristic-functions', 'random-variables']"
219651,Proving the trigonometric identity $\sin^4 \theta = \frac{3-4\cos2\theta+\cos4\theta}{8}$,"I've been working on this problem on and off for a couple hours and have not been able to find out how to go about it even after looking through the other questions and some google searching. Prove the following identity: $$
\sin^4 \theta = \frac{3-4\cos2\theta+\cos4\theta}{8}
$$ So I started off trying this $$\sin^4 = (\sin^2\theta)^2=(1-\cos^2\theta)^2$$ $$(1-\cos^2\theta)^2 = \left[1-\left(\frac 12\cos2\theta + 1\right)\right]^2$$ But that hasn't led me to anywhere. Trying it from the other side hasn't yielded much results for me either. $$\frac{(3-4\cos2\theta+\cos4\theta)}{8}= \frac18(3-4[2\cos^2\theta-1]+\cos4\theta)$$ $$\frac18(3-4[2\cos^2\theta-1]+\cos4\theta) = \frac18(3-4[2(1-\sin^2\theta)-1]+\cos4\theta)$$ From there I seem to have just hit a loop with $\sin^2$ and $\cos^2$ . I have A LOT of trouble with these types of problems in this section. I would greatly appreciate it if someone could help me out.","['trigonometry', 'algebra-precalculus']"
219669,How many ways can the letters of the word TOMORROW be arranged if the Os can't be together?,How many ways can the letters of the word TOMORROW be arranged if the Os cant be together? I know TOMORROW can be arranged in $\frac{8!}{3!2!} = 3360$ ways. But how many ways can it be arranged if the Os can't be together? And what is the intuition behind this process?,['combinatorics']
219680,Knopp's Lemma - Show T is ergodic,"Be $\beta > 1$ non-integer. $T_{\beta}: [0,1)\rightarrow[0,1)$ with $T_{\beta}x = \beta x$ mod$(1) = \beta x-\lfloor\beta x\rfloor$. Show with Knopp's Lemma that $T_{\beta}$ is ergodic with respect to $\lambda$ Lebesgue measure. (If $T_{\beta}^{-1}A = A$, then $\lambda(A)=0$ or $1$). $\underline{\textrm{Knopp's Lemma:}}$ $B$ Lebesgue set. $\mathscr{C}$ is class of subintervals of $[0,1)$ with a) $\forall$ open subinterval of $[0,1)$ is at most a countable union of disjoint elements from $\mathscr{C}$ b) $\forall A\in\mathscr{C}$: $\lambda(A\cap B)\geq \gamma\lambda(A)$ with $\gamma>0$ independent of A. Then $\lambda(B)=1$.","['measure-theory', 'ergodic-theory']"
219691,Any countable $A \subseteq \mathbb{R}$ satisfies $(x+A) \cap A = \emptyset$ for some $x$,"I have to prove that if $A \subseteq \mathbb{R}$ is countable, then 
  $\exists x \in \mathbb{R}\, (x+A) \cap A = \emptyset, $ where $x+A$ denotes the set $\{x + a \mid a \in A\}$. I can see why this is true for some specific subsets (like the set of rationals or the set of algebraic numbers), but the general approach eludes me. Any hints would be appreciated.","['elementary-set-theory', 'real-analysis']"
219699,Volterra Operator is compact but has no eigenvalue,"Volterra operator is defined as operator $V:L^2[0,1]\rightarrow L^2[0,1]$ by 
\begin{eqnarray}
(V)(f(x))=\int_0^xf(y)dy
\end{eqnarray}
Would you help me to prove that this operator is compact but has no eigenvalues.","['hilbert-spaces', 'functional-analysis']"
219706,Open subsets of a complete metric space.,"I've been going over previous exams, and I came across a question that I missed. It is as follows: Let $X$ be a complete metric space. Show that every open subset of $X$ is homeomorphic to a complete metric space. I am having difficulty showing this. Any help would be greatly appreciated.","['general-topology', 'metric-spaces']"
219725,"Can any continous,bounded function have a fourier series?","In particular, can an oscillatory function with some decay term ( i.e $e^{-t} \cos(kt)$) have a fourier series representation? All the articles I read said that the function has to be periodic,but this one is not.","['fourier-series', 'analysis']"
219731,Determinant of rank-one perturbations of (invertible) matrices,"I read something that suggests that if $I$ is the $n$ -by- $n$ identity matrix, $v$ is an $n$ -dimensional real column vector with $\|v\| = 1$ (standard Euclidean norm), and $t > 0$ , then $$\det(I + t v v^T) = 1 + t$$ Can anyone prove this or provide a reference? More generally, is there also an (easy) formula for calculating $\det(A + wv^T)$ for $v,w \in \mathbb{K}^{d \times 1}$ and some (invertible) matrix $A \in \Bbb{K}^{d \times d}$ ?","['matrices', 'linear-algebra', 'determinant']"
219736,rectifiable continuous function,"could you please help me with this question:
if $F:[a,b] \rightarrow \mathbb{R}^{m}$ is continuous and rectifiable,
then $ F ([a, b]) $ has $ m $ - measure zero.
Any suggestions are welcome.","['integration', 'real-analysis', 'analysis']"
219738,"Showing that $f = 0 $ a.e. if for any measurable set $E$, $\int_E f = 0$","Let $(X, \mathcal{B}, \mu)$ be a measure space and $f$ a measurable function on $X$ and suppose that $\forall E \in \mathcal{B}$ we have that $\int_E f = 0$.  Then I want to show that $f = 0$ almost everywhere (a.e.). Suppose for sake of contradiction that $f \ne 0$ a.e. Then $\not\exists E \in \mathcal{B}$ s.t. $\mu(E) = 0$ and $f(x) = 0$, $\forall x \in X - E$ Then $\{x : f(x) \ne 0\} = A$ is not measure zero so that either $\mu(A) > 0$ or $A \notin \mathcal{B}$. Now if $\mu(A) > 0$ then it is easy to see that $\int_A f \ne 0$ so that we have a contradiction of our original hypothesis that $\forall E \in \mathcal{B}, \int_E f = 0$. But if on the other hand $A \notin \mathcal{B}$, I cannot no longer appeal to $\int_A f \ne 0$ since $\int_A f$ is non-sense. So I'm having trouble with this part of the argument.",['measure-theory']
219747,If $F:\mathbb{R}^{m} \rightarrow \mathbb{R}^{m}$ if of class $C^{1}$ ...,"I'm studying differentiation and came across this question: If $F:\mathbb{R}^{m} \rightarrow \mathbb{R}^{m}$ is of class $C^{1}$ such that $\Vert f^{\prime}(x)v\Vert \geqslant 2\Vert v\Vert$. Then F is a diffeomorphism of  $\mathbb{R}^{m}$ in $\mathbb{R}^{m}$. I can not take the condition of $F$ to show that $F$ is injective. If you could help me, thanks.","['real-analysis', 'analysis']"
219755,Showing $\int_{0}^{\infty} \frac{\sin{x}}{x} \ dx = \frac{\pi}{2}$ using complex integration,"Recently I had to use the fact that the Dirichlet integral evaluates as $$\int_{0}^{\infty} \frac{\sin{x}}{x} \ dx = \frac{\pi}{2}$$ a couple of times. There already is a question that specifically ask for methods to show this result $\textbf{not}$ using complex integration. In this question I am interested in seeing the derivation via contour integration. ( I am aware of the wikipedia entry, but am looking for more detail )","['integration', 'complex-analysis', 'analysis']"
219759,Show that both mixed partial derivatives exist at the origin but are not equal,"$$f(x,y) = \begin{cases} \displaystyle \frac{xy(x^2-y^2)}{x^2+y^2} & \text{if } (x,y) \neq (0,0), \\ 0 & \text{if } (x,y) = (0,0). \end{cases}$$ I tried finding both mixed partial derivatives but they ended up being the same for that function. I must be failing to take into account something dealing with the fact that it is piece-wise. I still need to show the mixed partial derivatives exist. How can I do all of this?","['multivariable-calculus', 'calculus', 'derivatives']"
219762,$a+b=c \times d$ and $a\times b = c + d$,"There is a 'nice' relationship between the integers (1,5) and (2,3) as 
$$1+5=2 \times 3;$$
$$1\times 5 = 2 + 3.$$ So I tried to find all positive integers pairs $(a, b)$ and $(c, d)$ such that $$a+b=c \times d;$$ 
$$a\times b = c + d.$$ To find this, $a, b, c, d$ must satisfy $$(a+1)(b+1)=(c+1)(d+1).$$ However, this condition is only necessary but not sufficient.
Any idea?","['elementary-number-theory', 'algebra-precalculus', 'diophantine-equations']"
219768,Counterexample in uniform bounded principle,I would like to give counterexamples to show that the uniform boundedness principle fails if one relaxes the assumptions in any of the following ways: The given space is merely a normed vector space rather than a Banach space (i.e. completeness is dropped). The family of linear operators are not assumed to be continuous. The family of continuous operators are allowed to be nonlinear rather than linear. Thank you for all the comments.,['functional-analysis']
219769,A couple of GRE questions,"Look for help with the following GRE questions Question 1. If $C$ is the circle in the complex plane whose equation $|z|=\pi$, oriented counterclockwise, find the value of the integral $\oint_C(\cos z-z\cos\frac{1}{z})dz$. Question 2. How to show the sequence $\{x_n\}_{n=1}^\infty$ definted by $x_{n+1}=\frac{1}{2}(x_n+\frac{2}{x_n})$, $x_1\ne 0$ converge. Question 3. Let $L$ be the curve whose equation in the polar coordinates $r$ and $\theta$ is $r^2=4\cos 2\theta$. Fine the largest value of $y$ such that the point with rectangular coordinates $(x,y)$ is on $L$. Question 4. Consider the set $S$ of all real-valued functions defined on $[a, b]$, $a<b$. Is it true that if the inverse of $f$ is a constant function, then $f$ is a constant function?","['multivariable-calculus', 'sequences-and-series', 'gre-exam', 'polar-coordinates', 'complex-analysis']"
219771,$\cos^n x-\sin^n x=1$,"For $0 < x < 2\pi$ and positive even $n$, the only solution for $\cos^n x-\sin^n x=1$ is $\pi$. The argument is simple as $0\le\cos^n x, \sin^n x\le1$ and hence $\cos^n x-\sin^n x=1$ iff $\cos^n x=1$ and $\sin^n x=0$. My question is that any nice argument to show the following statement? 'For $0 < x < 2\pi$ and positive odd $n$, the only solution for $\cos^n x-\sin^n x=1$ is $\frac{3\pi}{2}$.'",['trigonometry']
219775,How to approach probability questions?,"I have four questions: The time that it takes to assemble a piece of machinery is well modeled by the normal distribution with mean of 72.9 minutes and standard deviation of 8.55 minutes. What is the probability that it will take less than an hour to assemble the next piece of machinery? What is the probability that it will take between 65 minutes and 75 minutes to assemble the next piece of machinery? What is the probability that it will take more than 80 minutes to assemble the next piece of machinery Find the 16th percentile of the random variable, time taken to assemble. This is the time that is exceeded 84% of the time I'm not sure how to approach these questions, can someone guide me through them possibly?","['statistics', 'probability']"
219776,prove that square root of 2 is irrational using sets,"There is a set $A$ with positive integers $x$ such that there exists $y$ s.t.$ x^2=2y^2$. Show that if A is non-empty, it violates the well ordering principle. I don't even know how to start this.","['discrete-mathematics', 'proof-writing']"
219780,"Prove that if X and Y are Normal and independent random variables, X+Y and X−Y are independent","Prove that if X and Y are Normal and independent random variables, X+Y and X−Y are independent. Note that X and Y also have the same mean and standard deviation. Note that this is a duplicate of Prove that if $X$ and $Y$ are Normal and independent random variables, $X+Y$ and $X-Y$ are independent , however, there isn't a complete solution to the answer given and I do not understand exactly what the hints are suggesting. My attempt was to check if $f_{x+y,x-y}(u,v) = f_{x+y}(u)f_{x-y}(v)$, however, this does not seem to be working out too nicely.","['probability-theory', 'probability']"
219809,Approximation of $\sum_{x \le k} \frac{\log(x)}{x}$,"Originally posted as a non-homework question. New to the site, and didn't know asking for homework advice was O.K. Anyways, here's what's going on: I'm trying to show there exists a constant $B$ such that $$
\sum_{x \le k} \frac{\log(x)}{x} = \frac{1}{2}\log^2(k) + B + O\left(\frac{\log(k)}{k}\right)
$$ I'm trying via partial summation to establish this. I think some of my trouble lies in understanding the question. If we're using the $O$ notation to bound an error term, and if we just need to show there exists a constant $B$ such that the above holds, why isn't $B$ absorbed into the error term?",['number-theory']
219833,"""Are there finitely or infinitely many Fermat primes?"": decidable?","Has anyone ever proven that there exists a proof or disproof that there are finitely many Fermat primes. I know that it's an unsolved problem whether there are finitely or infinitely many Fermat primes but my question is only whether it has been proven to be possible to prove or disprove it. If so, how can I access such a proof?","['logic', 'number-theory']"
219842,Is $Z(x^2-y^3)$ isomorphic to $Z(y^2-x^3-x^2)$ over the complex numbers?,"I'm having trouble determining if the algebraic sets $Z(x^2-y^3)\subset \mathbb{A}^2$ and $Z(y^2-x^3-x^2)\subset\mathbb{A}^2$ are isomorphic over $\mathbb{C}$. My guess is that this boils down to determining if $\mathbb{C}[x,y]/(x^2-y^3)$ is isomorphic to $\mathbb{C}[x,y]/(y^2-x^3-x^2)$ but then again, I'm stuck.","['algebraic-geometry', 'abstract-algebra', 'polynomials']"
219847,"Given $ax^2+by^2+cxy > 0$, what can I deduce about $a$, $b$, and $c$?","I know that for any nonzero $x,y\in\mathbf{R}$, $$ax^2+by^2+cxy > 0,$$ where $a,b,c\in\mathbf{R}$. What can I deduce about $a$, $b$, and $c$? For example, letting $x=1$ and $y=0$, I know that $\boxed{a>0}$. Letting $x=0$ and $y=1$, I know that $\boxed{b>0}$. Letting $x=y=1$, I know that $\boxed{c>-(a+b)}$. What else can I deduce about $a$, $b$, and $c$? How will I know when it's time to stop looking? (Is that last question even answerable?)",['algebra-precalculus']
219855,Relation involving the conductor of an elliptic curve,Consider an elliptic curve $E: y^{2} = x^{3} + ax + b$. Then the quadratic twist by a squarefree $d$ is given by $E^{d} : dy^{2} = x^{3} + ax + b$. What is the relationship between  the conductor of $E^{d}$ and $E$?,"['elliptic-curves', 'number-theory']"
219868,Does there exist a variation of Minkowski's inequality with differences instead of sum.,I seek something of the form $\|f-g\|_p \leq |\|f\|_p-\|g\|_p|$.,['analysis']
219896,Product of Sine: $\prod_{i=1}^n\sin x_i=k$,"From the article Products of Sines , we have $\sin 15^\circ\sin75^\circ=\sin 18^\circ\sin54^\circ=\frac{1}{4}$. We can rewrite this as $\sin \frac{\pi}{12}\sin\frac{5\pi}{12}=\sin \frac{\pi}{10}\sin\frac{3\pi}{10}=\frac{1}{4}$. Is there any good method to get $x,y$ such that $\sin x\sin y=\frac{1}{4}$ or more generally to get $x_i$ such that $$\prod_{i=1}^n\sin x_i=k$$ where $k$ is a rational number?","['trigonometry', 'algebra-precalculus', 'products']"
219924,"Function $\mathbb Z\times \mathbb Z \to \mathscr P(\mathbb Z)$ defined by $f(a,b) = \{a,b\}$. Show f is not one-to-one. Show f is not onto.","I have encountered this problem in my studies and to be honest with you, I am just having some trouble grasping the notation.
I have reread the section in my textbook and consulted a few of my peers, but I have yet to understand.
I figured I would just give a shot to posting it here to see if I gain any insight.
I apologize if this is not welcome, but I thought I would give it a try. Thank you much! Consider the function $f \colon \mathbb Z\times \mathbb Z \to \mathscr P(\mathbb Z)$ defined by $f(a,b) = \{a,b\}$ 
  As usual, $\mathscr P(\mathbb Z)$ denotes the power set of the integers $\mathbb Z$ a) Give a specific example to show $f$ is not one-to-one b) Give a specific example to show $f$ is not onto",['elementary-set-theory']
219928,Inductive Proof for Vandermonde's Identity?,"I am reading up on Vandermonde's Identity, and so far I have found proofs for the identity using combinatorics, sets, and other methods. However, I am trying to find a proof that utilizes mathematical induction. Does anyone know of such a proof? For those who don't know Vandermonde's Identity, here it is: For every $m \ge 0$, and every $0 \le r \le m$, if $r \le n$, then $$ \binom{m+n}r = \sum_{k=0}^r \binom mk \binom n{r-k} $$","['binomial-coefficients', 'summation', 'proof-writing', 'combinatorics']"
219937,Gerrymandering urns (redux),"This is a rehash of this question (and probably the intent of this , and several other similar questions), but I'd like: a more detailed answer that builds from the simplest cases to potentially higher order applications and more references to explanations, if possible. a proof of the optimality of the so-called gerrymandering solution . So here is a complete statement of the problem: Suppose that you are given 50 each of red and blue balls, and two
  urns. You place the red and blue balls in the urns (so that each is
  nonempty, and all the balls are allocated to some urn). Then you pick a jar at
  random and pick a ball at random. The objective is to distribute the
  red and blue balls in each of the urns so that the probability of
  picking a red ball is maximized. The so-called gerrymandering solution is given after the break below, and I am wondering if there is a systematic way of arriving at this solution, other than guesswork. Attempt 1 My first thought was to use calculus on this problem, so that if I denote the jars A and B, and denote the tuple $(x, y)$ as the number of red and blue balls in jar A. The the solution $(x^*, y^*)$ is the solution to the first-order conditions. (This is probably a red herring, since only nonnegative integer solutions are valid.) $$
\begin{alignat}{2}
&&p(x, y) &= \frac{1}{2}\left(\dfrac{x}{x+y}+ \dfrac{50-x}{100-x-y}\right) \\[1em]
&&\left. \dfrac{\partial p(x, y)}{\partial x}\right|_{(x,y)=(x^*, y^*)} &= 0 \\[1em]
&\implies\quad&\dfrac{2x^*+y^*}{(x^*+y^*)^2}-\dfrac{150-2x^*-y^*}{(100-x^*-y^*)^2} &=0 \\[1em]
&&\left. \dfrac{\partial p(x, y)}{\partial y}\right|_{(x,y)=(x^*, y^*)} &= 0 \\[1em]
&\implies\quad&  \dfrac{-x^*}{(x^*+y^*)^2} +\dfrac{50-x^*}{(100-x^*-y^*)^2} &= 0
\end{alignat}
$$ This involves finding the solution of cubic equations (which I am sure can be done, with the help of CAS, but it is not obvious that this yields the gerrymandering solution (does it?)). Is this the right way to think about the problem? What is? Attempt 2 Note however that the objective function is closed-form, so can easily be graphed, and then the solution becomes clear. The gerrymandering solution You place one red ball and no blue balls in one urn and all the other balls in the other urn. This leads to the probability of picking a red ball $>\tfrac{1}{2}$.","['discrete-mathematics', 'probability', 'discrete-optimization']"
219941,Is greatest common divisor of two numbers really their smallest linear combination?,"In a lecture note from MIT on number theory says: Theorem 5. The greatest common divisor of a  and b  is equal to the smallest positive linear combination of a  and b. For example, the greatest common divisor of 52 and 44 is 4. And, sure enough, 4 is a
linear combination of 52 and 44: 6 · 52 + (−7) 44 = 4 What about 12 and 6 their gcd is 6 but 0 which is less than 6 can be","['elementary-number-theory', 'gcd-and-lcm', 'number-theory']"
