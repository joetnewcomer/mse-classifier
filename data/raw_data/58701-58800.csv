question_id,title,body,tags
648229,Adjoint of multiplication by $z$ in a Hilbert Space (Bergman space),"I am learning Hilbert space theory from Halmos' ""Introduction to Hilbert space and the theory of spectral multiplicity"". While talking about understanding adjoints (p. 39), he calls special attention to this example, remarking that ""its adjoint is not what at first it might appear to be"": Let $\mathfrak H$ be the set of analytic functions defined in the interior of the unit disk ($D$), square integrable with respect to planar Lebesgue measure. Then $\mathfrak H$ –called a Bergman space – is a Hilbert space with the inner product $$\langle f,g \rangle= \int_D f\bar g d\lambda = \int_D f(x+iy)\bar g (x+iy) dxdy .$$ In $\mathfrak H$, consider the multiplication by $z$ opertator $A$, i.e. $(Af)(z)=zf(z).$ In the typical $L^2$ I think $A^*$ would simply be multiplication by $\bar z$, but that ruins the differentiability of $f$, so in this case it must be some other thing. I have thought that this multiplication operator works like the shift operator in sequence spaces if one identifies the function $f$ with its power series terms $(a_0, a_1, ..)$, mapping this sequence to $(0, a_0, a_1,..)$. I know that the usual right shift defined in $l^2$ has as adjoint the left shift when one considers the inner product $\langle \{a_n\},\{b_n\}\rangle = \sum a_n\bar b_n$, but I don't know how the inner product of $\mathfrak H$ would look like translated to the language of its corresponding sequence space, so this approach hasn't helped me much either. How can I construct this adjoint operator?","['examples-counterexamples', 'operator-theory', 'adjoint-operators', 'hilbert-spaces', 'complex-analysis']"
648237,Measure of image of critical points set is equal 0,"Let $f:\mathbb{R}\to \mathbb{R}$ be $C^1$ function and $K = \{x : f'(x) = 0 \} $.
  Show that $\mu \left(f\left(K\right)\right) = 0$, where $\mu$ is Lebesgue measure. My attempt was following: $$\mu \left(f\left(K\right)\right)= \int_{f(k)} 1 dy \stackrel{(*)}{=} \int_{K}f'(x) dx = \mu\left(K\right) \cdot 0 = 0$$
but we cannot substitute $y = f(x)$ at $(*)$ like that. I was told that there exists quite elementary proof (not using Sard's theorem) so I'm looking for it.","['measure-theory', 'lebesgue-measure', 'real-analysis']"
648243,Justifying the Normal Approx to the Binomial Distribution through MGFs,"Would absolutely love if someone could help me with this question, in a step by step way to help those who are uninitiated to Statistics and Mathematics. So, I am trying to ""prove/justify"" through MGFs how as n(the sample size) increases and goes to infinity, a standardized binomial distribution converges to the Standard Normal Distribution. So in the beginning we have $X_n $~$ Bin(n,p)$ then we standardize this $R.V.$ by subtracting the mean $E(X_n)=np$ and dividing by the $SD$ which is $np(1-p)$. After doing this, we get a new $R.V.$ with $mean=1$ and $variance=SD=1$. It is the distribution of this standardized quantity that converges to a fixed distribution, correct? Namely the Standard Normal Distribution. Let's call the standardized version of $X_n$, $Z_n$. I think what we need to do is to find the MGF of $Z_n$ and show that this MGF becomes the Standard Normal Distribution's MGF as the sample size $(n)$ heads toward infinity. Now $Z_n$ is a function of $X_n$ which we know the MGF of which is $(1-p+pe^t)^n$. Now I know that $Z_n$ is a linear transform and that we should be able to use this to simply the MGF but I don't understand how the course notes do it, mostly because they skip a lot of steps and it is difficult to follow. There is also a Taylor Series Expansion for the exponential that I am confused about although I do understand the concept of the series expansion. Help would be greatly appreciated! I would love assistant in exactly how we can prove this via MGF. Thanks so much in advance :)","['statistics', 'moment-generating-functions', 'calculus', 'statistical-inference']"
648292,Learning roadmap for p-adic modular forms and eigenvarieties.,"What are some good sources for breaking into the field of p-adic modular forms?  It was suggested to me to read Katz' paper ""P-adic Properties of Modular Schemes and Modular Forms"".  I have found this paper to be helpful, albeit difficult.  Where does one go from here?","['modular-forms', 'number-theory']"
648294,How prove this $a_{1}=a_{2}=\cdots=a_{p}=0$,"let $a_{1},\cdots,a_{p}$ be real numbers,and let $b_{1},b_{2},\cdots,b_{p}$ be distinct postive numbers with $b_{1}$ being the greatest of them,and such
$$\sum_{i=1}^{p}a_{i}b^k_{i}=0$$
for all natural numbers $k$. show that:
$$a_{1}=a_{2}=\cdots=a_{p}=0$$ my try: since
$\begin{cases}a_{1}+a_{2}+a_{3}+\cdots+a_{p}=0\\
a_{1}b_{1}+a_{2}b_{2}+\cdots+a_{p}b_{p}=0\\
a_{1}b^2_{1}+a_{2}b^2_{2}+\cdots+a_{p}b^2_{p}=0\\
\cdots\cdots\\
a_{1}b^n_{1}+a_{2}b^n_{2}+\cdots+a_{p}b^{n}_{p}=0\\
\cdots\cdots\cdots
\end{cases}$
then I can't prove $$a_{1}=a_{2}=\cdots=a_{p}=0$$",['ordinary-differential-equations']
648311,How prove this limit $\lim_{n\to\infty}\frac{1}{n}\sum_{i=1}^{n}\sum_{j=1}^{n}\frac{i+j}{i^2+j^2}=\frac{\pi}{2}+\ln{2}$,"show that: this limit
$$I=\lim_{n\to\infty}\dfrac{1}{n}\sum_{i=1}^{n}\sum_{j=1}^{n}\dfrac{i+j}{i^2+j^2}=\dfrac{\pi}{2}+\ln{2}$$ My try: 
$$I=\lim_{n\to\infty}\dfrac{1}{n^2}\sum_{i=1}^{n}\sum_{j=1}^{n}\dfrac{\dfrac{i}{n}+\dfrac{j}{n}}{\left(\dfrac{i}{n}\right)^2+\left(\dfrac{j}{n}\right)^2}=\int_{0}^{1}\int_{0}^{1}\dfrac{x+y}{x^2+y^2}dxdy?$$ This idea is true? and have other methods?","['definite-integrals', 'riemann-sum', 'real-analysis', 'summation', 'limits']"
648318,How find this limit$\lim_{n\to\infty}\frac{1}{n}\left(\frac{n}{\frac{1}{2}+\frac{2}{3}+\cdots+\frac{n}{n+1}}\right)^n$,"How  find this limit
$$\lim_{n\to\infty}\dfrac{1}{n}\left(\dfrac{n}{\dfrac{1}{2}+\dfrac{2}{3}+\cdots+\dfrac{n}{n+1}}\right)^n$$ My try: since
$$\dfrac{1}{2}+\dfrac{2}{3}+\cdots+\dfrac{n}{n+1}=\left(1-\dfrac{1}{2}\right)+\left(1-\dfrac{1}{3}\right)+\cdots+\left(1-\dfrac{1}{n+1}\right)=(n+1)-H_{n+1}$$ where
$$H_{n}=1+\dfrac{1}{2}+\dfrac{1}{3}+\cdots+\dfrac{1}{n}$$ then I can't.Thank you this problem is from a book,and only give this answer
$$e^{\gamma-1}$$
where $\gamma$ is denotes the Euler–Mascheroni constant.",['limits']
648321,What are the exact odds of getting a perfect NCAA bracket?,"With the NCAA March Madness Finals nearing, I thought it'd be appropriate to ask this. From everything that I've read and heard online, there seems to be varying opinions on the exact odds of getting a perfect NCAA bracket, especially from different sources.  That seems certainly strange, because I had originally thought there'd be only one way to calculate the odds of that. For example, this link seems to suggest the odds are 9.2 quintillion. Which seems odd that, compared with this , suggesting it's around 4 quadrillion.  Which leads me to being somewhat confused as to the exact number for the odds. What I'm far more interested is how do I calculate the chances of getting a perfect bracket? With 68 possible winners, I had originally thought it'd be a simple 68! , but I thought since there were a total possible of 68 slots, it could be 68 ^ 68 ?  Is my thinking off, or am I somewhere in the right court?",['probability']
648326,Sides of a triangle (square roots)?,"This is the exercise: Let $a,b,c\in \mathbb{R}^+$. Prove that the following propositions are equivalents: $a,b,c$ are sides of a triangle. $\sqrt{a},\sqrt{b},\sqrt{c}$ are sides of an acute triangle. I'd really appreciate your help in this exercise. :)","['geometry', 'number-theory']"
648362,Integral with respect to greatest integer function,"Assume $f$ is continuous on $[1,n]$. How would you go about taking the integral 
$$\int_1^n f(x)\,d\lfloor x\rfloor$$
where $\lfloor x\rfloor$ represents the greatest integer function?",['real-analysis']
648364,private solution after solving nonhomogenous euler equation,"Solve the equalation: $$x^2y''-3xy'+3y=\ln x$$ First I solved the homogeneous part and got $$y_h=c_1x+c_2x^3.$$ Then i wanted using variation of parameters writing that $$c_1' x'+c_2' (x^3)^\prime.$$ I solved the equations for $c_1,c_2$ and got a function which when i substitute in the equation, I get $x^2\ln x$ (not $\ln x$ ). I verified my answers with MuPaD and seems like the integration was correct. Am I using wrong method?",['ordinary-differential-equations']
648435,differential equation of a harmonic function,"Let $v$ be a smooth harmonic function on $R^n$. If $r^2=\sum_{i=1}^{n}|x_i|^2$, where $x=(x_1,x_2,....x_n) \in R^n$ and if $v$ is a radial function i.e $v(x)=v(r)$, write down the differential equation satisfied by $v$.",['ordinary-differential-equations']
648463,does the domain can be considered as subset of it image under 1 to 1 function?,Let $f\colon X \to X$ be a one-to-one function and let $A \subseteq X$. Does $A \subseteq f(A)$? I ask because I found a step which not clear to me in this paper http://www.maths.ed.ac.uk/~aar/papers/stong2.pdf page(328) proposition 8 .which is $f'(\tau)\supseteq \tau$.,"['general-topology', 'elementary-set-theory']"
648467,How find this limit $\lim_{x\to 1}\Gamma{(1-x)}\cos\left(\dfrac{\pi}{2}x\right)$,"Find this limit
$$I=\lim_{x \to 1}\Gamma\left(1 - x\right)\cos\left({\pi \over 2}\,x\right)$$ where 
$\Gamma{(x)}$ is http://en.wikipedia.org/wiki/Gamma_function My idea: let $u=1-x$,then
$$I=\lim_{u\to 0}\Gamma{(u)}\sin{u}$$
then I can't,Thank you",['limits']
648470,Does having a zero eigenvalue preclude a matrix from being indefinite?,"If a $3\times3$ matrix has a positive eigenvalue, a negative eigenvalue, and a zero eigenvalue, is it then, by definition, indefinite? I think so, since the matrix has both a positive and a negative eigenvalue. However, my optimisation lecture notes categorically claims that as a long as there is any zero eigenvalue, the stationary-point test fails. I am not including the details of the stationary-point test as it is tangential to the substance of my question.","['optimization', 'multivariable-calculus', 'nonlinear-optimization', 'linear-algebra', 'analysis']"
648514,"Preventing underflow, log sum exp trick","I have some difficulties with understanding the schema to prevent underflow, which is very  often mentioned as The log-sum-exp trick, the partial decription  is The log-sum-exp trick . In short, I will describe the general idea. Assume you need to calculate $w_i=\frac{\prod_{j}^{n}p_{ij}}{\sum_{i}^{n}\prod_{j}^{n}p_{ij}}$, where $p_{ij}$ might be very small value, therefore the overall product is very small and might cause underflow when calculating on computer. Let's apply $\log$ and $\exp$ to the enumerator and denominator and $z_i=\sum_{j}^{} \log p_{ij}$, then $w_i = \frac{e^{z_i}}{\sum_{j}^{n} e^{z_j}}$, of course, ensure that $p_i \neq 0$. The problem with resulting formula is still $e^{z_i}$ might have small value and might cause underflow. So far everything is ok. Then $m = \max_i(z_i)$ $w_{i} = \frac{e^{z_i}}{\sum_{j}^{}e^{z_j}}= \frac{e^{z_i-m}}{\sum_{j}^{}e^{z_j-m}}=$ $=0\ if\ z_i-m<-k$ $=\frac{e^{z_i-m}}{\sum_{j:z_j-m \geq -k}^{}e^{z_j-m}}$, otherwise ,when $k$ is some value such that $e^{-k}$ doesn't cause underflow. The  question is why do we need to use $m$ value. In my opinion, $w_{i} = \frac{e^{z_i}}{\sum_{j}^{}e^{z_j}}$ with the $k$ value, would work just fine, positive values of $z_j$ don't cause the problem, and the negative are filtered out by $-k$, what the reason to artificially decrease the value of $z_j$ by m.","['statistics', 'computer-science', 'machine-learning']"
648525,Way to find volume of the solid,A solid has a square base of side $s$ . The upper edge is parallel to the base and has length $2s$. All other edges have length $s$ . What is the volume of the solid ? NB : The volume of the tetrahedron with all sides length l is $ V = \dfrac{\sqrt2}{12}l^3$,['geometry']
648536,Does there exist any continuous but not uniformly continuous function $f(x)$ such that $\sin(f(x))$ is uniformly continuous?,Does there exist any continuous but not uniformly continuous function $f(x)$ such that $\sin(f(x))$ is uniformly continuous? Actually all the examples I am taking for $f$ makes the composite function non uniformly continuous. I am not sure enough.,"['real-analysis', 'uniform-continuity']"
648540,Two definitions of Taylor polynomials,"I'm studying a book which states Given a function $f:I\to \mathbb R$, $n$ times derivable in the point
  $a\in I$, the Taylor polynomial of order $n$ of $f$ in the point $a$
  is the polynomial: $$p(h)=f(a)+f'(a)\cdot h+\frac{f''(a)}{2!}\cdot
 h^2+\ldots+\frac{f^{(n)}(a)}{n!}\cdot h^n$$ This is the only polynomial of degree $\le n$ whose derivatives (from
  the order $0$ to the order n) in the point $0$ coincide with the
  corresponding derivatives of $f$ in the point $a$ However, I saw in another sources ( this and this ) that the Taylor polynomial is given by: $$p(x)=f(a)+f'(a)\cdot (x-a)+\frac{f''(a)}{2!}\cdot (x-a)^2+\ldots+\frac{f^{(n)}(a)}{n!}\cdot (x-a)^n$$ I would like to know why these polynomials are equivalent, i.e., why we can call both of Taylor polynomial, I'm really confused. Thanks.","['calculus', 'real-analysis', 'analysis']"
648541,Invariance of the Lebesgue integral.,"Problem Let $f\in L^1(\mathbb{R})$. Show that $\int_{\mathbb{R}}f(x)dx=\int_{\mathbb{R}}f(x-\frac{1}{x})dx$. Discussion I know the Lebesgue integral is translation invariant (as the Lebesgue measure is), but I have never encountered the above invariance. I thought maybe if I rewrote both integrals as the measure of a set I could show both sets had the same measure, or I could use a change of variables, but nothing has worked yet. The question is a small part of a bigger problem related to fourier transforms.","['lebesgue-integral', 'lebesgue-measure', 'real-analysis']"
648551,Probability problem ( shuffling cards ),"Suppose we shuffle a deck of 10 cards, each bearing a distinct number from 1 to 10, to mix the cards thoroughly. We then remove three cards, one at a time, from the deck. What is the probability that we select the three cards in sorted (increasing) order?",['probability']
648572,Geodesics Through a Singularity,"A singularity on a manifold with metric is defined to be a point at which some geodesic cannot be continued through. For example in Schwarzchild spacetime, $r=0$ defines such a point. Is it the case that any geodesic which hits a singularity cannot be continued past it? This is obviously true for the Schwarzchild solution. However I worry that perhaps that's just an artifact of the symmetry of the situation. There's nothing in the definition of a singularity that refers to an arbitrary geodesic through that point. I've tried to think about this myself, but I'm not sure I have the requisite differential geometry to solve it. I can't see how (say) the Hopf-Rinow theorem, or any related results would help! It would be great to get a mathematician's perspective on this question. Apologies if the solution if obvious and I'm just missing something!","['mathematical-physics', 'general-relativity', 'differential-geometry', 'geodesic']"
648589,"The equation $\,\,\Delta u+\cos u=0\,\,$ possesses a weak solution in $\,W^{1,2}_0(D)$","Let $D$ be an open bounded subset in $\mathbb{R}^{n}$, with sufficiently smooth boundary. Prove that there is a weak solution in $W^{1,2}_0$$(D)$ to following equation
$$\Delta u+\cos u=0.$$ Help me some hints to start. Thanks in advanced.","['sobolev-spaces', 'partial-differential-equations', 'real-analysis', 'analysis', 'functional-analysis']"
648624,Existence of a continuous function.,"Question is to check Which of the following statements are true? There exists a continuous function  $f: \{(x,y)\in \mathbb{R}^2 : 2x^2+3y^2=1\}\rightarrow \mathbb{R}$ which is one-one. There exists a continuous function $f: (-1,1)\rightarrow (-1,1]$ which is one one and onto. There exists a continuous function  $f: \{(x,y)\in \mathbb{R}^2 : y^2=4x\}\rightarrow \mathbb{R}$ which is one-one. There exists a continuous function  $f: \{(x,y)\in \mathbb{R}^2 : x^2+y^2=1\}\rightarrow \mathbb{R}$ which is Onto. There exists a continuous function $f : S^1=\{(x,y)\in \mathbb{R}^2 : x^2+y^2=1\} \to \mathbb{R}$ which is one-one. What i have done so far is : Solution for $1$ : we see that $\{(x,y)\in \mathbb{R}^2 : 2x^2+3y^2=1\}$ is connected and compact... Suppose we have continuous function $f :S \rightarrow \mathbb{R}$ which is one one then we would see that $S$ is homeomorphic to $f(S)$* Now, $S$ is connected so is $f(S)$ and $S$ is compact so is $f(S)$.Thus $f(S)=[a,b]$ for some $a,b\in \mathbb{R}$ suppose I remove a point $c\in(a,b)$ then $f(S)$ would have two connected components where as the corresponding subset of $S$ obtained by removing $f^{-1}(c)$ is connected which is absurd. Thus there exist no continuous one one map $f :S \rightarrow \mathbb{R}$ Solution for $2$ : Suppose we have continuous bijection $f: (-1,1)\rightarrow (-1,1]$ then we have $t\in(-1,1)$ such that $f(t)=1$. Now, any continuous injection has to be such that $a<b$ implies $f(a)\leq f(b)$ or $f(a)\geq f(b)$ for all $a,b$ (I do not how does one call this property as) Assuming $f$ is increasing and  $f(t)=1$ then $f(m)\geq 1$ for all $m\in (t,1)$ which is a contradiction to $f$ being injective... Assuming $f$ is decreasing and  $f(t)=1$ then $f(m)\geq 1$ for all $m\in (-1,t)$ which is a contradiction to $f$ being injective... Thus there is no continuous bijection from $(-1,1)$ to $(-1,1]$ Solution for $3$ : we see that $\{(x,y)\in \mathbb{R}^2 : y^2=4x\}$ is connected (Not Compact. sorry for my laziness and thanks to gaoxinge :D )... Suppose we have continuous function $f :S \rightarrow \mathbb{R}$ which is one one then we would see that $S$ is homeomorphic to $f(S)$* Now, $S$ is connected so is $f(S)$ and $S$ is compact so is $f(S)$.Thus $f(S)=[a,b]$ for some $a,b\in \mathbb{R}$ I though of applying same idea as i have done to check First question but then i am not getting any negative result. Moreover I guess that such a map exists and i can actually find a homeomorphism to $\mathbb{R}$. I am unable to write explicitly but What i would do is i would bend the parabola so that it would coincide with real line (I am not able to express it precisely please try to understand something from this). But how would i write ""bending"" as a function and how would i show that this is a homeomorphism. Please help in that case and more over is my intuition correct? Solution for $4$ : Continuous image of compact space is compact but $\mathbb{R}=f(S)=f(\{(x,y)\in \mathbb{R}^2 : x^2+y^2=1\})$ is not compact though $S=\{(x,y)\in \mathbb{R}^2 : x^2+y^2=1\}$ is compact. Solution for $5$ : for the same reason that i have treid to explain in First question there is no continuous function $f : S^1=\{(x,y)\in \mathbb{R}^2 : x^2+y^2=1\} \to \mathbb{R}$ which is one-one. Please see if this justification is sufficient and if it is please let me know if there are any other ways of seeing these things. Thank you. P.S: I have used one result which i feel is worth sharing : continuous bijection from a compact space to Hausdorff space is homeomorphism","['general-topology', 'continuity', 'real-analysis']"
648633,What is the coordinate ring of $G/U$?,"Let $G$ be an algebraic group and $U$ its subgroup consisting all upper triangular matrices. For example, $G=GL_n(k)$ and $U$ the subgroup consisting of all upper triangular unipotent matrices in $GL_n(k)$, where $k$ is an algebraically closed field. It is said that the coordinate ring of $G/U$ is $k[G/U]= k[A]$, where $A$ is the set consisting of all minors of a matrix which contains continuous rows of the first column. This is because these minors are invariant under the action of multiply elements in $U$ from the right to a matrix in $G$. I am trying to understand this statement. Let $$G=GL_3(k)=\left\lbrace\left(\begin{matrix} x_{11} & x_{12} & x_{13} \\ x_{21} & x_{22} & x_{23} \\ x_{31} & x_{32} & x_{33}  \end{matrix}\right) : x_{ij} \in k, \det(x_{ij}) \neq 0 \right\rbrace.$$, 
$$
U=\left\lbrace\left(\begin{matrix} 1 & a & b \\ 0 & 1 & c \\ 0 & 0 & 1  \end{matrix}\right) : a, b, c \in k \right\rbrace.
$$ 
Now we want to verify that $$k[G/U] = k[x_{11}, x_{21}, x_{31}, x_{11}x_{22}-x_{12}x_{21}, x_{11}x_{23}-x_{21}x_{13}, x_{21}x_{32}-x_{31}x_{22},x_{21}x_{33}-x_{23}x_{31}, \det(x_{ij})] \quad (1)$$. Is this correct? In general, for an affine variety $X$, $k[X] = k[A^n]/I = k[x_{i}: i\in\{1, \ldots, n\}]/I$, where $I = \{f: f(x)=0, \forall x \in X\}$. I think that the coordinate ring of $GL_n(k)$ is $k[x_{ij}, y: i,j\in\{1, \ldots, n\}]/(y\det(x_{ij})-1)=k[x_{ij}, \det(x_{ij})^{-1}: i,j\in\{1, \ldots, n\}]$. Thank you very much. Edit: Maybe the statement should be as follows. The coordinate ring of $G/U$ is $k[G/U]= k[x_{ij}, A]$, where $A$ is the set consisting of the inverse of minors of a matrix which contains continuous rows of the first column. This is because these minors are invariant under the action of multiply elements in $U$ from the right to a matrix in $G$. Let $$G=GL_3(k)=\left\lbrace\left(\begin{matrix} x_{11} & x_{12} & x_{13} \\ x_{21} & x_{22} & x_{23} \\ x_{31} & x_{32} & x_{33}  \end{matrix}\right) : x_{ij} \in k, \det(x_{ij}) \neq 0 \right\rbrace.$$, 
$$
U=\left\lbrace\left(\begin{matrix} 1 & a & b \\ 0 & 1 & c \\ 0 & 0 & 1  \end{matrix}\right) : a, b, c \in k \right\rbrace.
$$ Now we want to verify that $$k[G/U] = k[x_{ij}, i, j \in \{1, \ldots, n\}, x_{11}^{-1}, x_{21}^{-1}, x_{31}^{-1}, (x_{11}x_{22}-x_{12}x_{21})^{-1}, (x_{11}x_{23}-x_{21}x_{13})^{-1}, (x_{21}x_{32}-x_{31}x_{22})^{-1},(x_{21}x_{33}-x_{23}x_{31})^{-1}, (\det(x_{ij}))^{-1}]\,. \quad (2)$$ Is this correct?","['lie-groups', 'algebraic-geometry', 'algebraic-groups', 'group-theory']"
648649,What is the probability no slots contain more than two balls given I am trying to sort 5 balls into 6 slots?,"I am having a difficult time understanding how to approach this problem.  Suppose I have $6$ total slots and $5$ balls. Now, I assign the balls at random to the slots. What is the probability that no slot will contain more than two balls? My approaches so far: I recognized that $\binom{5+(6-1)} 5$ ($10$ choose $5$) represents the total combinations per the combinations with repetitions formula. Next, I realized that maybe I can find the probability a slot has exactly $5$, $4$, $3$ balls in one spot, then take $1$ - the sum of those probabilities. The correct answer is around $80\%$ so I am way off with this approach. Do you guys have any idea? Thanks!","['statistics', 'permutations', 'probability', 'combinatorics']"
648652,If $\lim_{x\to\infty}(f(x)+f'(x))=L$ show that $\lim_{x\to\infty} f(x) = L$ and $\lim_{x\to\infty} f'(x) = 0$ [duplicate],"This question already has answers here : If $\lim\limits_{x\rightarrow\infty} (f'(x)+f(x)) =L<\infty$, does $\lim\limits_{x\rightarrow\infty} f(x) $ exist? (2 answers) Closed 6 months ago . Let $f:(0,\infty) \to R$ be differentiable. Suppose that $\lim_{x\to\infty}(f(x)+f'(x))=L$. Show that $\lim_{x\to\infty} f(x) = L$ and $\lim_{x\to\infty} f'(x) = 0$. (Hint: Write $f(x) = e^xf(x)/e^x$ and use l’Hopital’s Rule.) My working for $\lim_{x\to\infty}f'(x)=0$: For $\lim_{x\to\infty}f'(x) = 0$, I let $f(x) = e^xf(x)/e^x$ and applied quotient rule which then cancels off $e^{2x}$ and I'm left with $\lim_{x\to\infty}(f(x)+f'(x)-f(x))$. Can I then equate this with $\lim_{x\to\infty} \left(f(x)+f'(x)\right) - \lim_{x\to\infty}f(x)$ which then gives $L-L=0$? Is this step correct?",['analysis']
648665,$1 + 1 + 1 +\cdots = -\frac{1}{2}$,"The formal series $$
\sum_{n=1}^\infty 1 = 1+1+1+\dots=-\frac{1}{2}
$$ comes from the analytical continuation of the Riemann zeta function $\zeta (s)$ at $s=0$ and it is used in String Theory. I am aware of formal proofs by Prof. Terry Tao and Wikipedia , but I did not fully understand them. Could someone provide an intuitive proof or comment on why this should be true?","['divergent-series', 'sequences-and-series', 'riemann-zeta']"
648689,Prove that there is a real number $r>0$ such that...,"Prove that there is a real number $r>0$ such that: There is no point in $\mathbb{R}^3$ with 3 rational coordinates, whose distance from $(0,0,0)$ equals $r$. In other words, if we build a sphere with radius $r$ and center in $(0,0,0)$, it will contain no points with 3 rational coordinates. It sounds logical, and I think there are a couple of such numbers, but how can I write a fully formal proof of this? I guess it'll be sufficient to prove just one example, and that's what I tried: for $r=\sqrt[4]{2}$ $x^2+y^2+z^2=\sqrt{2}$ A sum of three rational numbers can't be irrational. But is this enough of a proof? If not, can someone point me in the right direction? Also, this is a homework for elementary math (elementary set theory, relations, orders etc), so I fear it can't be that simple... Thanks!",['algebra-precalculus']
648692,Showing that an algebraic set is not isomorphic to $\mathbb{A}^1$,"(For convenience, I'm assuming $\mathbb{K} = \mathbb {C}$.) I'm trying to show that the algebraic set $\mathbb{V}(xz-y^2,x^3-yz,z^2-x^2y) \subseteq \mathbb{A}^3$ is not isomorphic to $\mathbb{A}^1$. I already know that $X = \{(t^3,t^4,t^5) \in \mathbb{A}^3 \;|\; t \in \mathbb{A}^1 \} $, and that $\mathbb{I}(X) = \langle xz-y^2,x^3-yz,z^2-x^2y \rangle$. If there were an isomorphism between the $\mathbb{A}^1$ and $X$, then $\mathbb{K}[\mathbb{A}^1] \cong \mathbb{K}[X]$. But $\mathbb{K}[\mathbb{A}^1] \cong \mathbb{K}[t]$, whereas $\mathbb{K}[X] \cong \mathbb{K}[t^3,t^4,t^5]$ by considering the homomorphism $$\mathbb{K}[x,y,z] \rightarrow \mathbb{K}[t], \; x\rightarrow t^3, \; y\rightarrow t^4, \; z\rightarrow t^5$$ which has kernel $\mathbb{I}(X)$ and image $\mathbb{K}[t^3,t^4,t^5]$, so $$\mathbb{K}[X] \cong \mathbb{K}[x,y,z]/\mathbb{I}(X) \cong \mathbb{K}[t^3,t^4,t^5]$$ Thus we would have that $\mathbb{K}[t] \cong \mathbb{K}[t^3,t^4,t^5]$, but this is not the case since the former is a UFD, whilst the latter is not, since for example $t^8 = t^3t^5 = (t^4)^2$ has two factorisations. Hence, $\mathbb{A}^1 \ncong X$. Is this line of reasoning correct? Is there an easier way I could have gone about it?","['commutative-algebra', 'algebraic-geometry', 'proof-verification']"
648706,Should $f(x) \equiv 0$ if $0\le f'(x)\le f(x)$ and $f(0)=0$?,"Assume $f(x)$ is a real-function defined on $[0,+\infty)$ and satisfies the followings: $f'(x) \geq 0$ $f(0)=0$ $f'(x) \leq f(x)$ Should we always have $f(x) \equiv 0$ ? Thanks for any solution.",['calculus']
648714,Example of a Short Exact Sequence,"I know that $A$ is a $\mathbb{Z}$-module. And I have a short exact sequence of the form $0 \rightarrow \mathbb{Z}/2\mathbb{Z} \rightarrow A \rightarrow \mathbb{Z}/2\mathbb{Z} \rightarrow 0$ is there anything to be said about $A$ ? That is to say, Can I find $A$? I recall that $\mathbb{Z}/2\mathbb{Z}$ is neither projective nor injective as a $\mathbb{Z}$-module so the sequence probably doesn't split. Or does it?","['modules', 'abstract-algebra']"
648728,Which of the following sets are compact? [duplicate],"This question already has an answer here : Which of the following sets are compact in $\mathbb{M}_n(\mathbb{R})$[NBHM_PhD Screening Test-2013, Topology] (1 answer) Closed 8 years ago . The set of all upper triangular matrices in $\mathbb M(n,\mathbb R)$ such that all their eigenvalues satisfy $|\lambda| \leq 2$. The set of all real symmetric matrices in $\mathbb M(n,\mathbb R)$ such that all their eigenvalues satisfy $|\lambda| \leq 2$. The set of all diagonalisable matrices in $\mathbb M(n,\mathbb R)$ such that all their eigenvalues satisfy $|\lambda| \leq 2$.","['matrices', 'real-analysis']"
648730,$f(x) = |\cos x|$ prove that f is differentiable at these points and not differentiable at all other points.,"Define $f : \mathbb R → \mathbb R$ by $f(x) = |\cos x|$. Determine the set of points where f is differentiable and calculate the derivative of f on this set. Also prove that $f$ is differentiable at these points and not differentiable at all other points. My working: 
from the graph of $|\cos x|$, we can see that the $|\cos x|$ is differentiable everywhere except at 
points where $x=(k+\frac{1}{2})\pi$, where $k$ is an integer, but this is intuitive, i'm having difficulty giving a proper proof of $|\cos x|$ being differentiable at these points.","['derivatives', 'analysis']"
648762,Properties of Dedekind zeta function,"Suppose $K$ is a quadratic field and $a_K(n)$ denotes the number of ideals in the ring of integers of $K$ whose norm is equal to $n$. Then I need to show that $$\sum_{n\leq x} a_K(n)=O(x).$$
Clearly the above claim will imply that the Dedekind zeta function $\zeta_K(z):=\sum_{n\geq 1}\frac{a_K(n)}{n^z}$ converges for $\mathrm{Re}(z)>1$. Is there an analytic continuation of $\zeta_K$ so that it can be defined in some punctured disc around $1$ and does this analytic continuation have a simple pole at $z=1$ like Riemann zeta function? If the proofs are technical and long, I only need some easy intuitions and ideas to see why the above statements should hold true, instead of complete proofs.","['zeta-functions', 'algebraic-number-theory', 'number-theory']"
648764,How do I show a set $A = (A\setminus B)\cup (A\cap B)$ for discrete math?,"How would I go about showing that for any set A and B, $$A = (A\setminus B)\cup (A\cap B)?$$ I don't really understand how to show this. Here's my interpretation: $$A = (A\setminus B)\text{ or } (AB)?$$ $\cup$ means either or both sides? $\cap$ means both $A$ and $B$? How do I show that
$$A = (A\setminus B) \cup (A\cap B)?$$ Thanks!","['discrete-mathematics', 'elementary-set-theory']"
648781,Proof that the equation $x^2 - 3y^2 = 1$ has infinite solutions for $x$ and $y$ being integers,"I have seen the Pell's equation wiki page but I need to prove this from scratch without mentioning any formula. I have also seen multiple answers on this site but the answers tend to skip over and assume formulas. This is what people do -> $x^2 - 3y^2 = 1$ has solution 1, 0. Next they say we ""observe"" that $$(x',y') = (2x + 3y, x + 2y)$$ is also a solution. What I'm asking is how they get this value. Can someone help?","['algebra-precalculus', 'diophantine-equations']"
648804,Expected sum of all the n-sided dice rolls until we get n,"So the problem is the following.
We have an $n$-sided die. We throw it until we get $n$. What's n, if the expected sum of all the throws including the $n$ one is $21$. Now, I did manage to solve it by assuming we throw the dice m times, then getting the expected value of a single throw and multiplying it with m to get the expected sum of all the throws. Then I just needed to get the expected m for an n sided die. However, the solution provided with the problem seems to be much shorter and I don't really understand how it works. It goes like this: Let X be a random variable representing the sum. Let Y be a random variable representing the value of the first throw. Then we can write the expected value of X using the law of total expectation like this: $EX=E(X|Y=1)P(Y=1) + ...+E(X|Y=n)P(Y=n)$ So far so good I thought. But then they substitute $EX$ with $21$ and do this: $21 = (21+1)\frac{1}{n}+...+(21+n-1)\frac{1}{n}+1$ Solving it for $n$ does produce the correct result ($6$), but I don't understand the reasoning behind $E(X|Y=a)=(21+a)$ Surely the expected value of $X$ already takes into account that the first throw will add something into the sum, right? So how is the expected value of $X$ GREATER than $21$ if the first throw gave the lowest possible amount? Using the same logic I tried to solve it by calculating the expected value for each throw ($\frac{n+1}{2}$) and then replacing $E(X|Y=a)$ with $(21+a-\frac{n+1}{2})$ my logic being that if we get $a$ and we expect $\frac{n+1}{2}$, the sum goes up or down by the same amount that $a$ differs from the expected value. Solving it like that, however, produces a wrong result ($-41$). So, where did I make a mistake?","['dice', 'probability', 'expectation']"
648809,How to find closest positive definite matrix of non-symmetric matrix?,I have a matrix $A$ given and I want to find the matrix $B$ which is closest to $A$ in the Frobenius norm and is positive definite. $B$ does not need to be symmetric. I found a lot of solutions if the input matrix $A$ is symmetric. Are they any for a non-symmetric matrix $A$ ? Is it possible to rewrite the problem as a minimization of a convex problem?,"['matrices', 'convex-optimization']"
648823,Strategy for tackling the $\lim_{n\to+\infty}\frac{(-1)^nn}{(1+n)^n}$,What strategy should I use to calculate this limit? Can I avoid using Hopital? $$\lim_{n\to+\infty}\frac{(-1)^nn}{(1+n)^n}$$ Thank you in advance.,['limits']
648834,Estimate $\int_0^{\infty} 1/\sqrt{1+x^4} \mathrm{d}x$,I need an analytical estimation of the following integral: $$\int\limits_0^\infty \frac{{\mathrm{d} x}}{\sqrt{1 + x^4}}$$ It has a root in the denomenator -- so I can't make use of complex residues technique. Edit : Since CAS can do it symbolically -- there's certainly a solution. However I did this analytically a couple of years ago and obtained $$    \frac{\pi}{2^{3/4}}$$ estimation. I remember it was easy and fast estimation. I'm trying to recover it.,"['definite-integrals', 'improper-integrals', 'integration']"
648856,How to prove that the inverse of a persymmetric matrix is also persymmetric?,"An exercise in a textbook I'm using to brush up on my linear algebra asks to prove that the inverse of a persymmetric matrix is also persymmetric. I have a colleague's old notes in front of me with a solution, but I can't understand his reasoning. It states: Let $A_S$ denote the persymmetric matrix. Then $A = SA_S = A_SS$, where $A$ is the anti-diagonal identity matrix (i.e.: the identity matrix rotated 90°). $$(SA_S)^{-1} = A_S^{-1}S^{-1}$$ In a previous question, we have proven that $A = A^{-1}$ ($A^2 = I$, where $I$ is the identity matrix, and thus $A^2 = AA = I$, and so multiplying both sides by the inverse $A^{-1}$ we have $A = A^{-1}$). Thus: $$(SA_S)^{-1} = A_S^{-1}S^{-1} = A_S^{-1}S$$ Therefore we need only prove $A_S^{-1}$ is symmetric. In a previous question we proved the transpose of the inverse of a matrix is equivalent to the inverse of its transpose, so $(A_S^{-1})^T = (A_S^T)^{-1}$. Since we know $A_S^T = A_S$, $(A_S^T)^{-1} = A_S^{-1}$, therefore $A_S^{-1}$ is symmetric. QED. I can't follow several bits of reasoning in this answer. First of all, I don't see how the second equation follows from the setup--how does $A = A^{-1}$ tell us that $A_S^{-1}S^{-1} = A_S^{-1}S$? Why is proving $A_S^{-1}$ to be symmetric sufficient to prove $A_S^{-1}$ is persymmetric? The author claims $A_S^T = A_S$, which would be true for a symmetric matrix, but not a persymmetric one (it is true that the transpose of a persymmetric matrix is also persymmetric). What is the basis for this claim? It's also possible that my colleague's answer is incorrect. I have an idea that perhaps using the facts that $A$ rotated by 90° is $I$ and $A_S$ rotated by 90° is a symmetric matrix in order to tackle the proof, but I'm stuck on the specifics. Can someone either explain my colleague's answer, give me a hint on how to prove this statement, or provide a proof of their own?","['matrices', 'linear-algebra', 'proof-verification', 'alternative-proof']"
648862,Why do we consider Lebesgue spaces for $p$ greater than and equal to $1$ only?,Why do we consider Lebesgue spaces for $p$ greater than and equal to $1$ only and not for $p$ any real number?,"['measure-theory', 'functional-analysis', 'analysis']"
648887,Extending weak solution to global weak solution of parabolic PDE,"Fix $T > 0.$ Let $V \subset H \subset V^*$ be a Gelfand triple. Consider the linear parabolic PDE
$$u_t - Au = f\quad\text{in $L^2(0,T;V^*)$}$$
$$u(0) = u_0$$
where $u_0 \in H$ and $f \in L^2(0,T;V^*)$ and $A$ is some elliptic smooth operator. we know that this problem has a unique solution 
$$u \in L^2(0,T;V), u_t \in L^2(0,T;V^*)$$
by using a Galerkin method for example. Questions: What exactly does it mean to say that we can extend $u$ to a global solution? I assume this means we can write $u \in L^2(0,\infty;V)$ and that $u$ solves the PDE I wrote above on $[0,\infty)$. How is $f$ extended from $[0,T]$ -- do we assume we are given such an extension. Under what conditions does one obtain a global solution? (I tried all the other threads). Any reference to source that talks about this in detail would be appreciated too. Thanks. Edit : This is confusing. Some papers consider a PDE and say that ""because we have existence of $u \in L^2(0,T;V)$ for any $T>0$, we have global existence"". other papers say solve the IVP, and then solve another IVP with $\tilde u(0) = u(T)$ and in this way extend the solution Please someone give me authoritative reference on this topic.","['reference-request', 'sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
648899,Ways to calculate $\int_0^1 \frac{-\log x}{1+x}\ \mathrm dx$,"I came across the integral
$$
\int_0^1 \frac{-\log x}{1+x}\ \mathrm dx = \frac{\pi^2}{12},
$$
which can be calculated as $\frac 1 2 \zeta(2)$ using analytic number theory. I'm interested if this integral can be calculated in any other interesting, possibly more elementary ways?","['definite-integrals', 'analytic-number-theory', 'riemann-zeta', 'integration']"
648903,What is the expectation of the product of two random variables of Dirichlet distribution?,"I understand that the expectation of a random variable $X_i$ a Dirichlet distribution is $E[X_i] = \frac{\alpha_i}{\sum_k \alpha_k}$ and $E[\ln(X_i)] = \psi(\alpha_i) - \psi(\sum_k \alpha_k)$ I read a great paper ""Distribution of Mutual Information from Complete and Incomplete Data"" that states that $E[X_i\ln(X_i)] = \sum_{i} \frac{\alpha_i}{\sum_k \alpha_k} \{\psi(\alpha_i) - \psi(\sum_k \alpha_k)\}$ I was wondering what is $E[X_i X_j]$? Can I use the property $\operatorname{Cov}(X_i X_j) = E[X_i X_j] - E[X_i] E[X_j]$ to get $E[X_i X_j] = \operatorname{Cov}(X_i X_j) + E[X_i] E[X_j]$? What about $E[X_i \ln(X_j)]$? Can I also use the $\operatorname{Cov}$ to derive it? Latest update: I believe that $E[X_i \ln(X_j)]$ can be derived using $\operatorname{Cov}[X_i, \ln(X_j)]$ I found that $\mathrm{Cov}[X_i,X_j] = \frac{- \alpha_i \alpha_j}{\alpha^2 (\alpha+1)} \ \ \ $ where    $\alpha = \sum_{i=1}^K\alpha_i$ and $\operatorname{Cov}[\log(X_i),\log(X_j)] = \psi'(\alpha_i) \delta_{ij} - \psi'(\alpha_0)$ where $\psi$ is the digamma function, $\psi'$ is the trigamma function, and $\delta_{ij}$ is the Kronecker delta Is there a form for $\operatorname{Cov}[X_i,\log(X_j)]$? If so, we can use it to derive $E[X_i \ln(X_j)]$.","['probability-distributions', 'probability']"
648957,What is $\operatorname{arccot}(-1)$?,"According to me $\operatorname{arccot}(-1)$ should be equal to $3\pi/4$ because 
$\operatorname{arccot}(-x) = \pi - \operatorname{arccot}(x)$. But in my book it is given to be $-\pi$/4...
also on wolfram alpha $\operatorname{arccot}(-1)$ is given as $-\pi/4$...
Please help!","['trigonometry', 'calculus', 'algebra-precalculus']"
648974,Evaluating the alternating hyperbolic series $\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k \sinh (\pi k)}$,"You can evaluate the alternating hyperbolic series $$\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{2n-1} \sinh (\pi k)}$$ for any positive even value of $n$ by integrating the function $$\frac{\pi \csc (\pi z)}{z^{2n-1} \sinh (\pi z)}$$ around a square contour that avoids the poles on both the real and imaginary axes. For example, $$\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{3} \sinh (\pi k)} = - \frac{\pi^3}{360} $$ and $$\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{7} \sinh (\pi k)} = - \frac{13 \pi^7}{453,600}. $$ However, if you try that same thing for a positive odd value of $n$ ,  the residues inside of the contour cancel each other, and you're left with the trivial equation $0=0$ . So what would be a way to show that $$\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k \sinh (\pi k)} = \frac{\pi}{12} - \frac{\log 2}{2} \,  ?$$ Furthermore, do closed form expressions for $\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{5} \sinh (\pi k)} $ , $\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{9} \sinh (\pi k)} $ , etc. exist? It seems like the best way to evaluate the case $n=1$ is to express the series in terms of the lattice sum $$\sum_{i=-\infty}^{\infty} \sum_{j=-\infty}^{\infty}   \frac{(-1)^{i+j}}{i^{2}+j^{2}}, \quad (i,j) \ne (0,0), $$ as explained here , and then use the Lambert series $$\theta_{4}^{2}(0,q) =  1 + 4 \sum_{m=1}^{\infty} \frac{(-1)^{m}q^{m}}{1+q^{2m}} $$ to evaluate the lattice sum (as explained here ).","['theta-functions', 'sequences-and-series', 'complex-analysis']"
649003,"Bounding a Bilinear Map $||A(v,w)||\leq M||v||||w||$","In a normed vector space I know that for a linear map $L:E\rightarrow F$ that there exists an $M\in \mathbb{R}$ such that $\forall x\in E$
$||L(x)||\leq M||x||$. The proof is this is quite straightforward but I am unsure how to generalize to a bilinear map. Let $A:E\times F\rightarrow G$. I would like to show that $\exists N \in \mathbb{R}$ such that $\forall x\in E,y\in G$ that $||A(x)(y)||\leq N||x||||y||$. I am unsure if my generalization is permissible: Attempt:
$A(x):F\rightarrow G$, $A(x)$ linear, so $\exists B$ such that $||A(x)(y)||\leq B||y||$. Let $N=\frac{B}{||x||}$, it then follows that
$||A(x,y)||\leq N||x||||y||$
but this isn't right because N shouldn't depend on $||x||$. Edit: I guess i should say that I am considering only finite dimensional spaces.",['analysis']
649023,Integer solutions to an ellipsoid surface,"Given the equation $$x^2+2y^2+5z^2+xz =n$$ where $n$ is any positive integer, what is the smallest odd integer for which no integer solution $(x,y,z)$ exists (i.e. $x,y,z$ are integers)? I know that for $n=10$ that no integer solution exists, but locating an odd number $n$ that has no integer solution has proven to be quite difficult. Computer approaches seem to indicate that the number of integer solutions for odd $n$ grows as $n \to \infty$. It seems to me that in fact there are no integer solutions for any positive odd $n$. Do we see any proofs as to impossibilty (or can we find an odd $n$ that has no integer solution?)","['algebraic-geometry', 'analytic-number-theory', 'real-analysis']"
649028,Assume that $\mathop {\lim }\limits_{x \to \infty } f(x) + f'(x) = 0$. Prove: $\mathop {\lim }\limits_{x \to \infty } f(x) = 0$,"Let $f:\mathbb{R}\rightarrow \mathbb{R}$ differentiable everywhere. Assume that  $\mathop {\lim }\limits_{x \to \infty } f(x) + f'(x) = 0$. Prove: $\mathop {\lim }\limits_{x \to \infty } f(x) = 0$ I've seen a suggestion for a solution defining $g(x)=e^xf(x)$ and taking its derivative. Personally, I don't like this trick. Can you suggest a more conservative way to solve it? Thanks!","['functions', 'derivatives', 'real-analysis', 'limits']"
649034,Finding volumes — when to use double integrals and triple integrals?,"This is not a technical question at all, but I'm quite confused about what should I use to compute volumes in $\mathbb{R}^3$ with integration. I've read somewhere that a double integral gets the volume swapping across the $x$ and $y$ axis while a triple integral just integrate the whole thing at once, how accurate is this? Can a volume expressed by a double integral be expressed by a triple integral?, And can a triple always be expressed by a double? This one doesn't seem true, but I don't have a good answer to why. I also found this comments while reading openstudy.com made by someone named  KingGeorge one year ago: For a double integral you have to integrate some function, for a triple integral, you integrate 1. Does this mean that using an integral to get a volume always should look like $\iiint  dxdydz$ without any function? Geometrically, there are a few things you can be looking at. One, you're finding a 4-volume. That is, the 4-dimensional equivalent of volume. Two, if the volume in the region you're integrating in has a changing density, you could be finding the total mass. I'm not sure if I understand correctly, but this means that a triple integral does not compute exactly the volume I want but a 4-D equivalent?.","['multiple-integral', 'multivariable-calculus', 'volume', 'integration']"
649041,Extending a holomorphic function defined on a disc,"Suppose $f$ is a non-vanishing continous function on $\overline{D(0,1)} $ and holomorphic on ${D(0,1)} $ such that $$|f(z) | = 1$$ whenever $$|z | = 1$$ Then I have to prove that f is constant. We can extend $f$ to all $\mathbb{C}$ by setting $$f(z) = \frac{1}{\overline{f(\frac{1}{\bar{z}})}}$$ and the resulting function is holomorphic on ${D(0,1)} \ $, $\mathbb{C} - \overline{D(0,1)}$ and continous on $\partial D(0,1)$. But how can we say that the resulting function is holomorphic in $z \in \partial D(0,1)$ ?","['complex-analysis', 'analysis']"
649073,Stuck with a tricky existence proof,"Show that there exists a continuous function $f: [-1, 1] \rightarrow \mathbb{R}$ such $f(0) = 1$ and $f(x) = \frac{2-x^2}{2} \cdot f(\frac{x^2}{2-x^2})$ $\forall x \in [-1, 1]$ I tried putting in $x = 1$ and $x = -1$ in the second condition to find that $f(1) = f(-1) = 0$. 
I also took the derivative of the second equation to find that: $f'(x) = x (f'(\frac{x^2}{2-x^2})\frac{2}{2-x^2}-f(\frac{x^2}{2-x^2}))$ This gives me $f'(0) = f'(1) = f'(-1) = 0$ but now I'm stuck. Anybody see a way?","['calculus', 'proof-writing', 'real-analysis', 'analysis']"
649110,Is it possible to construct $20^\circ$ angle with the help of a compass?,Once my brother told me that construction of a $20^\circ$ angle with the help of a compass is impossible. I searched for it on the net but I did not find anything about how to prove it. Kindly prove or disprove the problem (and remember that I am asking for a $20^\circ angle$ exactly).,['geometry']
649115,Analyzing $n_{i+1} = n_i - n_i^{3/4}$,"I have a non-linear recurrence given by $$n_0 = N \\ n_{i+1} = n_i - n_i^{3/4}$$ Are there any techniques to solve this for an exact closed form? Or in lieu of that, an asymptotic estimation? I'm mostly interested in how far I need to go to ensure $n_i = O(N^{3/4})$, and I conjecture that $O(\log (N))$ is necessary. But I hope that it can be done in $O(1)$ steps.","['asymptotics', 'recurrence-relations', 'discrete-mathematics']"
649121,Solving the quadratic equation for matrices,"Suppose that $A,\;B,\;C,\;$and $X$ are all real commuting matrices. I am curious how to solve $$AX^2+BX+C=0$$ for $X$. In addition what properties do we need on $A,\;B,$ and $C$ for the solution to exist? Last is this possible for non-commuting matrices?","['matrix-equations', 'matrices', 'linear-algebra', 'quadratics']"
649142,How a principal bundle and the associated vector bundle determine each other,"It seems to me that given a vector bundle, the associated principal bundle is univocally determined. In fact one has to construct a principal bundle given the base, the fibre (the group $G$ in which the transition functions of the vector bundle take values) and a local trivialization whose associated transition functions satisfy the cocycle condition. On the other hand, it seems to me that given a principal bundle, the associated vector bundle is far from unique: first one has to specify what is the vector space $V$ constituting the typical fibre, second one has to give a representation of $G$ on $V$. Even if the principal bundle is nontrivial, by taking the trivial representation the associated vector bundle is trivial. If what I say is correct, why is the terminology ""\emph{the} associated vector bundle"" so widely use when there is no such an object, even if the vector space itself is specified?","['principal-bundles', 'vector-bundles', 'differential-geometry']"
649144,Bijection from a set of functions to a Cartesian product of sets [duplicate],"This question already has an answer here : Bijection Contruction (1 answer) Closed 10 years ago . Let S be an arbitrary set. Let $F=\{f:\{0,1\}\to S\}$ be the set of functions from $\{0,1\}$ to S. Construct a bijection $F→S \times S$. I think I would define the function $a(f)=(f(0),f(1))$ because we know that both $f(0)$ and $f(1)$ are in $S$, but I don't know where to go from there.",['elementary-set-theory']
649146,An ideal whose radical is maximal is primary,"I've got to prove that an ideal $Q$ whose radical is a maximal ideal is a primary ideal. That is, I want to prove that if $xy\in Q$, then $x\in Q$ or $y^n\in Q$ for some $n>0$. I've been trying for a while and I'm not sure where to begin. All I've got is that if $\text{Rad}(Q)$ is maximal and by definition it's the intersection of all prime ideals $P_i$ containing $Q$, then it must be equal to each of these $P_i$. So there is only 1 prime ideal containing $Q$, namely $\text{Rad}(Q)$. Could anyone point me in the right direction? Thanks for any replies.","['commutative-algebra', 'ideals', 'abstract-algebra']"
649152,Prove that the function is uniformly continuous,"Let $f(x)$ be a continuous function in $[0,\infty)$ there are $a,b \in \mathbb{R}$ such that $\lim_{x\to\infty} [f(x) - (ax +b)] =0$ prove that $f(x)$ is uniformly continuous in $[0,\infty)$ how i started: using that function limit definition:
let $\epsilon >0$ there is a $M>$ such that for every $x>M, |f(x) - (ax +b)|<\epsilon$ in the interval $[0,M]$ the function is uniformly continuous (by weierstrass theorem). this is there part i got stuck in, i know that f(x) ""Converges"" with the $(ax+b)$ ,
but i cant find a $\delta$ that will prove what i need","['calculus', 'limits', 'continuity', 'analysis', 'uniform-continuity']"
649167,"If $σ^2$ is the identity map from $G$ to $G$, prove that $G$ is abelian.","Let $G$ be a finite group which possesses an automorphism $σ$ such that $σ(g)=g$ if and only if $g=1$. If $σ^2$ is the identity map from $G$ to $G$, prove that $G$ is abelian. This is what I got Let $G$ be a finite group which possesses an automorphism $σ$ such that $σ(g)=g$ if and only if $g=1$. 
Assume that $σ^2$ is the identity map from $G$ to $G$, we will show that $G $is abelian.
Let $g,h∈G$, since $σ^2$ is the identity map from $G$ to $G$ $σ^2 (g)=g$ $σ^2 (h)=h$ And $σ^2 (gh)=gh=σ^2 (g) σ^2 (h)$ Since $σ∈Aut(G)$, $σ$ is isomorphism (homophism and bijective) , so  $σ(gh)=σ(g)σ(h)=gh$. Thus, $gh=1=hg$. Hence, $G$ is abelian. Did I do it correctly, I keep feeling I missed something.","['finite-groups', 'abstract-algebra', 'abelian-groups']"
649197,How can I show that three statements are not logically equivalent to another?,"I am given three premises and a conclusion. The premises are: \begin{gather}
p \lor q \\
p \to \mathord{\sim}q \\
p \to r
\end{gather} and the conclusion is $$ r $$ I used a truth table and showed that this is logically incorrect. However, how would I go about this without a truth table?","['logic', 'propositional-calculus', 'discrete-mathematics']"
649219,finding the value of the sum $\sum _{n=1}^{\infty} \frac{7^{n}}{8^{n}+2^{n}}$,"I am concerned with finding the value of the sum $\sum _{n=1}^{\infty}  \frac{7^{n}}{8^{n}+2^{n}}$. There may be some easy way to do this, but I have not found a way to compute this sum, and ones like it. I cannot figure out how to turn it into a single easy-to-calculate exponential, but I am wondering if there is another way. I already know that this sum is convergent, but I want to know exactly how to calculate its value. Any help would be appreciated.","['calculus', 'limits']"
649224,How do I determine between positive and negative inflection,"Is it possible to identify whether an inflection point such as this example, contained in y = x^3 from the wikipedia: Is positive or negatively oriented (i.e. the gradient leading up to, and away, from it) without visualising it or taking a point from either side? We went over determining between maximum, minimum and inflection points using second derivatives in AS mathematics today, and I felt that the method of taking a point on either side wasn't a very conclusive (Since, in theory, there could be a turning point very close to it, couldn't there? Which could affect this) or pure way of going about it, although I could well be wrong. I enquired about it to my lecturer but she stated that there's no method that's in the specification for our exam and that if there is one it's probably higher level. I did look around for information but it seems my vocabulary is too basic to find any relevant questions. I did find this on the Wikipedia: If x is an inflection point for f then the second derivative, f″(x), is equal to zero if it exists, but this condition does not provide a sufficient definition of a point of inflection. Source Which basically sums up what I already knew about second derivatives. It goes on to explain about determining between undulation and inflection points, however I found little resources on-line to explain what an undulation point is, and therefore am not sure if this is relevant to my question. Thanks very much, again, sorry if this question seems too basic to present here-- I'm just intensely curious about mathematical methods, and will be thinking about this for weeks otherwise. Note that I am only interested in 2D Cartesian geometry.","['geometry', 'derivatives', 'polynomials']"
649240,Examples of Talagrand's inequality,I am trying to understand Talagrand's inequality and when it gives better results than Markov/Chebyshev/Chernoff.  However I find the formal definition hard to understand. Are there any nice simple examples using discrete random variables that shows its purpose?,"['self-learning', 'probability']"
649271,into function vs injective function,"In many mathematical books that I have read and from lectures from professors, the words 'into' and 'injective' were used interchangeably, but in Patrick Suppes book Axiomatic Set Theory he gives a percise definition of what it means for a function to be 'into': $f$ is a function from $\:A$ into $\:B \leftrightarrow\: f$ is a function & $D(f) = A$ & $R(f) \subseteq B$ where $D(f)$ is the Domain of $f$ and $R(f)$ is the Range of $f$. Is the definition given by Suppes the correct meaning of 'into', or is 'into' simply a synonym for 'injective'","['terminology', 'elementary-set-theory', 'functions']"
649285,Show Pascal triangle properties,I need to prove two pascal triangle properties: 1)  $\sum_{k=0}^{n}\binom{p+k}{k}=\binom{p+n+1}{n}$ 2) $\sum_{k=0}^{n}\binom{k}{p}=\binom{n+1}{p+1}$ I need some advice on how to approach to this kind of summatorial problems involving binomial coefficients.,"['discrete-mathematics', 'combinatorics']"
649290,Is every fibre bundle a G-bundle?,"By definition of a fibre bundle $F\hookrightarrow E\xrightarrow \pi B$ every point $p\in B$ has a neighbourhood $U$ such that there exists a diffeomorphism (local trivialization)  $\phi: \pi^{-1} (U)\rightarrow U\times F$. Looking at local trivializations over overlapping open sets $U_i$, $U_j$ one can consider the map $\phi_j\circ\phi_i^{-1}:U_i\cap U_j\times F\rightarrow U_i\cap U_j\times F$, $\phi_j\circ\phi_i^{-1}(x,u)=(x,t_{ji}(x,u))$, with $t_{ji}(x,\cdot):F\rightarrow F$ a diffeomorphism. It follows from the definitions that $t_{ij}(x,t_{ji}(x,u))=u$. Similarly by considering triple intersections one has 
$t_{ij} (x,t_{jk}(x,u))=t_{ik}(x,u)$. Usually in the literature a fiber bundle is called a $G$-bundle, or said to have structure group $G$, if it exists a group $G$ such that $t_{ij}(x,u)=\tau_{ij}(x)\cdot u$ with $\tau_{ij}(x)\in G$ and $\cdot$ denoting a left action of $G$ on $F$. Take $G=\mathrm{Diff}(F)$, the group of diffeomorphisms of $F$, acting on $u\in F$ as $(\phi,u)\in \mathrm{Diff}(F)\times F\mapsto \phi(u)$. If $t_{ij}(x,u)=u^\prime$, define $\tau_{ij}(x)=\phi$, where $\phi$ is any element of $\mathrm{Diff}(F)$ such that $\phi(u)=u^\prime$. Doesn't this give $F\hookrightarrow E\xrightarrow \pi B$ the structure of a $G$-bundle? In other words, isn't every fiber bundle a $G$-bundle if I take $G$ to be the group of diffeomorphisms of the fibre?","['fiber-bundles', 'differential-geometry']"
649294,Uncountable collection [duplicate],This question already has answers here : Uncountable family of uncountable compact subsets of $\mathbb{R}$ (2 answers) Closed 10 years ago . Is there an uncountable collection of compact disjoint subsets of the real line such that each element of the collection is uncountable? Thanks.,"['general-topology', 'real-analysis']"
649343,Proving uniqueness (basics of group theory) [duplicate],"This question already has answers here : Prove that identity is unique in a group (2 answers) Closed 9 years ago . If $(G,*)$ is a group, prove that the identity and the inverse elements are unique. What I did for the first one is: Suppose $\exists e,g\in G$ such that $\forall a\in G a*e=e*a=a$ and also that $\forall a\in G a*g=g*a=a$, then $g=g*e=e$, hence $g=e$. The first equallity happens because $e$ is an identity, and the second happens because $g$ is an identity. Is this right? I checked some notes of another class and their proof is much more longer and complicated (although I understand every step), what am I doing wrong? For the second one, can I use that if $a$ is the inverse of $b$, then $b$ is the inverse of $a$? I feel that I shouldn't, but I'm not sure why.","['self-learning', 'group-theory']"
649351,Finding a volume,"Find the volume of $D\{(x,y,z)\in \mathbb{R}^3:\frac{x^2}{a^2} +\frac{y^2}{b^2}\leq z\leq 1 \}$ It looks like (1) I believe this could be solve with a double integral an considering the function $f(x,y) = \displaystyle\frac{x^2}{a^2} + \displaystyle\frac{y^2}{b^2}$ as the height and then substracting this from the volume of the rectangle that contains the volume. Then I should integrate between $0\leq \displaystyle\frac{x^2}{a^2}+\displaystyle\frac{y^2}{b^2}\leq 1$ (2) Another way may be defining g(x,y) = 1- f(x,y), I believe this should give the same answer as (1). I'm not sure wheter I should use polar coordinates or spherical coordinates instead -or a similar change, since the symmetry the the volume isn't exactly spheric-. But after the changes $x=r\cos\theta$ and $y=r\sin\theta$ doesn't seem wasy to determine the limits of $r$ and $\theta$ because would lead to the inequality $0\leq b^2r^2\cos^2\theta+a^2r^2\sin^2\theta\leq a^2b^2$ and I would conclude -probably wrong- $0\leq r \leq \left(\displaystyle\frac{cos^2\theta}{a^2} +\displaystyle\frac{\sin^2\theta}{b^2} \right)^{-1}$ which seems odd and also would give me some troubles if I try to compute the integral with that limit -because I'd be integrating $\displaystyle\int\int \displaystyle\frac{r^3\cos^2\theta}{a^2}+\displaystyle\frac{r^3\sin^2\theta}{b^2}\;drd\theta$-. Probably my approach is wrong and I don't get how to do this, but there is another way or it must be done as I said?.","['definite-integrals', 'multivariable-calculus', 'volume', 'integration']"
649361,"If $f$ is twice differentiable, $\big(f(y) - f(x)\big)/(y-x)$ is differentiable","Suppose $f: \mathbb{R} \to \mathbb{R}$ is a $C^{1}$ function. Then, define a new function $F: \mathbb{R}^{2} \to \mathbb{R}$ by:
$$
F(x,y) = \begin{cases}
  \displaystyle \frac{f(y) - f(x)}{y - x} &\text{ if } x \neq y \\
  \displaystyle f'(x) &\text{ otherwise.}
\end{cases}
$$
Then, if $f''(x)$ exists, $F$ is differentiable. I can prove that $F$ is differentiable if $x \neq y$, since under these conditions $F_{x}$ and $F_{y}$ are $C^{1}$. So it's left to prove $F$ is also differentiable if $x = y$. At first, I conjectured that, for example, $F_{x} (a,a)$ would be $f''(a)/2$, but I'm having a hard time proving it. I started using the definition $\lim_{h \to 0} (F(a+h, a) - F(a,a)) / h$ and applying the MVT found $\bar{a}$ between $a$ and $a + h$ s.t. this difference quotient is:
$$
\frac{1}{h}(f'(\bar{a}) - f'(a))
$$
so I tried dividing and multiplying by $\bar{a} - a$, thinking it would be possible to prove that $\lim_{h \to 0} (\bar{a} - a)/h = 1$, but so far I've only been able to bound it above by $1$. Is it true? Does this conjecture even makes sense? I'm lost in thinking about any other candidates for the differential in these points. Any help would be appreciated!","['multivariable-calculus', 'partial-derivative', 'derivatives']"
649371,Find greatest value of $y(x) = (0.9^x)(300x + 650)$,"Question and attempt $y(x) = (0.9^x)(300x + 650)$ Estimate at what x value that y reaches its maximum value The only way I could think of would be to use derivatives, so I tried it: $y'(x) = (0.9^x)' \times (300x + 650) + 0.9^x \times (300x + 650)'$ $=$ [$\ln(0.9) \times 0.9^x \times 1$] $\times  (300x + 650) + 0.9^x \times 300$ So then I subbed in 0 to find where the turning point is: $y(0) =\ln0.9 \times 0.9^0 \times (300(0) + 650) + 0.9^0 \times 300$ $=\ln0.9 \times 650 + 300$ ~ $231.51$ The problem is that $231.51$ is not the correct answer. The real answer This is a table of values of the answer (see that it increases up to in between x = 7 and 8, then decreases): x = 5: 1269.5535
x = 6: 1302.03045
x = 7: 1315.316475
x = 8: 1312.9249905
x = 9: 1297.85863815 Here is what the graph actually looks like (which tells me there is a turning point): And here is the picture of the vertex: So the x value at which the y value is at its maximum value is $7.3$ I'd like to know where I went wrong with the derivative idea, but I still would encourage answers describing any other way to solve the problem.","['calculus', 'derivatives']"
649377,Egorov's theorem for this Lebesgue integral,"I want to prove Egorov's theorem using this Lebesgue integral defined by the upper integral
$$\int^*f:=\left\{\int h ; h \ge f \text{ and h upper-continuous }\right\}$$ $$\int_*f:=\left\{\int h ; h \le f \text{ and h lower-continuous }\right\}$$ So a Lebesgue integral of a function $ f : \mathbb{R}^n \rightarrow \mathbb{R}$ exists $\int f \Leftrightarrow \int^*f = \int_*f$. I am also allowed to use the following theorems: $L^p$ is a Banach space; Dominated convergence theorem; Monotone convergence theorem; $C^{\infty}$ is dense in the Lebesgue-functions. But the huge problem is: We don't know what Borel-sets are and we don't have anything like measures so far. Therefore, all standard proofs of this theorem are not applicable to this situation. Hence, I wanted to find out whether anybody here knows a way how to do it? Maybe I should say more about how this integral is defined: Every semincontinuous function is the limit of a monotone sequence of continuous functions with finite support $g_n$. The integral over these kind of functions is defined via n-times 1 dimensional integration over all variables and then $\int h:= \lim_{n \rightarrow \infty} \int g_n$. (But this is probably not that relevant to this proof). If anything is unclear, please let me know","['calculus', 'integration', 'measure-theory', 'real-analysis', 'lebesgue-integral']"
649378,How come complex numbers represent coordinates?,"I'm wondering why complex numbers represent coordinates without being on the form of a tuple (a,b). The complex numbers come in the form: $a+bi$ where $a$ denotes the real part and $bi$ denotes the imaginary part. This doesn't represent an ordered pair in my eyes, but more like a sum. How does it represent coordinates on a grid?","['complex-numbers', 'complex-analysis', 'calculus', 'real-analysis']"
649420,What is the line of thinking to get $[(n^2+3n+1)^2-5n(n+1)^2]$ from $(n^4+n^3+n^2+n+1)$?,"There is this one little tiny step along the working that I don't quite understand, but I think it is better if I write the whole problem and solution for clarity. Problem : Factorize $5^{1995}-1$ into the product of $3$ integers, and every integer must be greater than $5^{100}$ . Solution : Let $5^{399}=n$ . So, \begin{align}
5^{1995}-1 &= (5^{399})^5 - 1\\
&= n^5-1\\  
&= (n-1)(n^4+n^3+n^2+n+1)\\
&= (n-1)[(n^2+3n+1)^2-5n(n+1)^2]\\ 
&= (n-1)[(n^2+3n+1)^2-5\times5^{399}\times(n+1)^2]\\
&=(n-1)[(n^2+3n+1)^2-5^{400}\times(n+1)^2]\\
&=(n-1)[n^2+3n+1+5^{200}(n+1)][n^2+3n+1-5^{200}(n+1)]\\ 
&=(5^{399}-1)(5^{798}+3\times5^{399}+5^{599}+5^{200}+1)((5^{798}+3\times5^{399}-5^{599}-5^{200}+1)
\end{align} It is obvious that $5^{798}+3\times5^{399}+5^{599}+5^{200}+1>5^{100}$ , since $5^{399}-5^{100}=5^{100}\times(5^{299}-1)>5-1=4>1$ , so $5^{399}-1>5^{100}$ . And since $(5^{798}+3\times5^{399}-5^{599}-5^{200}+1)-(5^{100}+1)$ $=5^{798}+3\times5^{399}-5^{599}-5^{200}-5^{100}$ $=(5^{798}-5^{599})+(5^{399}-5^{200})+(5^{399}-5^{100})+5^{399}>0$ so, $(5^{798}+3\times5^{399}-5^{599}-5^{200}+1)>5^{100}+1>5^{100}$ . So all the three factors are greater than $5^{100}$ . I understand the overall working, but I am wondering how can it get from $(n^4+n^3+n^2+n+1)$ to $[(n^2+3n+1)^2-5n(n+1)^2]$ ? Going backward is easy, but how about going forward? Does it use any formula or any tricks such as substitution or completing the square etc? In other words, what is the line of thinking? Or maybe are there any other alternatives? Thanks so much! Helps are greatly appreciated.","['algebra-precalculus', 'elementary-number-theory', 'polynomials', 'factoring', 'exponentiation']"
649442,"$A(x) = \int_a^x f(t) dt$ in [a,b],let c in (a,b),if $f'$ is continuous at c then A' is continuous at c?","this is an exercise in Apostol calculus I page 210. Given a function $f$ such that the integral $A(x) = \int_a^x f(t)dt$ exists for each $x$ in an interval $[a,b]$.Let $c$ be a point in $(a,b)$.Prove that if $f'$ is continuous at $c$.then $A'$ is continuous at $c$. Attempt: f' is continuous at c,so there's a interval $c- \delta<x<c+ \delta$ such that $f'(x)$ exists and  $|f'(x)-f'(c)|<\epsilon$, this imply $f$ is continuous in the interval.By the first fundamental theorem of calculus.$A'(x)=f(x)$ in $(c- \delta,c+ \delta)$.because $f(x)$ is continuous at $c$. So does A'. I feel my statement is quite strange and may have  something wrong.Hope someone could give a clear explaination to me.","['calculus', 'real-analysis', 'analysis']"
649443,Does an element of a group to the 0th power equal the identity?,"My textbook doesn't explain this well at all. I was thinking about how a group follows the axiom that $xx^{-1} = x^{-1}x = 1$, where $x$ is some element of the group, $1$ is the identity and $x^{-1}$ is $x$'s inverse. The book says that the powers of some $x$ work with the binary operation on itself. For example I think for $(\mathbb{Z} , + )$, $1^5$ would be $1 + 1 + 1 + 1 + 1 = 5$. It then goes to say that you can manipulate exponents as usual... which makes me wonder. Since $xx^{-1} = x^{1-1} = 1 = x^0$, does that mean that an element of a group to the power of $0$ will always be the identity of that group?",['abstract-algebra']
649452,Stuck on derivation of divergence in cylindrical coordinates,"I'm having a hard time trying to derive the divergence in cylindrical coordinates from its expression in cartesian coordinates $\dfrac {\partial F_{x}} {\partial x}+\dfrac {\partial F_{y}} {\partial y}+\dfrac {\partial F_{z}} {\partial z}$. I'm trying to proceed as follows: from the cartesian coordinate system $(x,y,z)$, defining \begin{align}
r&=\sqrt{x^2+y^2} \\
\theta&=\arctan \frac y x
\end{align} With the chain rule, we have: \begin{align}
\frac \partial {\partial x}&=\left( \frac {\partial r} {\partial x} \frac {\partial} {\partial r} + \frac {\partial \theta} {\partial x} \frac {\partial } {\partial \theta} \right) = \left( \cos \theta \frac {\partial} {\partial r} - \frac {\sin \theta} r \frac {\partial } {\partial \theta} \right) \\
\frac \partial {\partial y}&=\left( \frac {\partial r} {\partial y} \frac {\partial} {\partial r} + \frac {\partial \theta} {\partial y} \frac {\partial } {\partial \theta} \right) = \left( \sin \theta \frac {\partial} {\partial r} + \frac {\cos \theta} r \frac {\partial } {\partial \theta} \right)
\end{align} As $F_{x}=F_{r} \cos F_{\theta}$ and $F_{y}=F_{r} \sin F_{\theta}$: \begin{align}
\frac {\partial F_{x}} {\partial x} &= \cos \theta \cos F_{\theta} \frac {\partial F_{r}} {\partial r} - F_{r} \sin F_{\theta} \cos \theta \frac {\partial F_{\theta}} {\partial r} - \frac {\cos F_{\theta} \sin \theta} r \frac {\partial F_{r}} {\partial \theta} + \frac {F_{r}} r \sin \theta \sin F_{\theta} \frac {\partial F_{\theta}} {\partial \theta} \\
\frac {\partial F_{y}} {\partial y} &= \sin \theta \sin F_{\theta} \frac {\partial F_{r}} {\partial r} + F_{r} \cos F_{\theta} \sin \theta \frac {\partial F_{\theta}} {\partial r} + \frac {\sin F_{\theta} \cos \theta} r \frac {\partial F_{r}} {\partial \theta} + \frac {F_{r}} r \cos \theta \cos F_{\theta} \frac {\partial F_{\theta}} {\partial \theta}
\end{align} However, this sum leads to a weird combination of trigonometric sums and differences of $F_{\theta}$ and $\theta$. It seems to me that if I suppose $F_{\theta}=\theta$. I'll get the usual formula, but I can't see how this is true. edit: I've used a wrong definition for a vector field on cylindrical coordinates. The correct definition is $\vec F=F_{r}\hat r+F_{\theta} \hat \theta + F_{z} \hat e_{z}$, where $\hat r=\cos \theta \hat i + \sin \theta \hat j$ and $\hat \theta=-\sin \theta \hat i + \cos \theta \hat j$. With this definition, the deduction above works.",['multivariable-calculus']
649482,$\pi$ Monte-Carlo - Probability that O-Lock hit a Spoke?,"(Edit: can someone please help me migrate this to physics stack? I think they would be more interested in helping me out with this problem. Thanks.) I have a bicycle with one of those O-locks on it and too often when I park the bike and I want to lock it, the lock hits one of the spokes of the rim. This can be frustrating and surprises me that it occurs so often. I mean, the spokes are so thin and not that many really so one would think that this should not happen that often (like every day or so). And so every time this happened I reminded myself to calculate the probability of this happening . I just did it (after a year) and now I want to know what you guys think about my calculation, is it OK? This is not a textbook example so there is no answer to look up or anything, that's why I need your feedback. I have modeled the situation as shown in the figure below, where I have included one spoke only. Let the O-lock have diameter $d_{L}$ and the spoke have a diameter $d_S$. Let $R$ denote the ""radius"" from center of wheel to the point where the O-lock comes and goes (this is approximately equal to the radius of the rim). Then, we have that the corresponding angles are given by $w_S=d_S/R$ and $w_L = d_L/R$ so that the spoke will hit the lock (the shaded disk in figure below) when $\theta$ is in the interval $[0, w_L+w_S]$ modulo $2\pi$ (See figure: $R$ is fixed so the point $(R,\theta)$ is on a circle). Then the probability for hit (wheel with one spoke) is given by 
$$ P(1) = \frac{w_L+w_S}{2\pi}\times 1 = \frac{1}{2\pi R}(d_L+d_S).$$ Generalizing to $N$ equally spaced spokes we get 
$$ P(N) = \frac{N}{2\pi R}(d_L+d_S). $$ Example: plugging in some typical numbers; $N=36, R\approx 0.3$m, $d_S\approx 2\times 10^{-3}$m , $d_L\approx \times 10^{-2}$m we find $$P(36) \approx 0.23$$ which kind of agrees with my everyday experience of this problem. I guess one could obtain a (Monte-Carlo)-value for $\pi$ this way. Could someone tell me what I have done wrong above? Or perhaps derive the correct expression for the probability?","['pi', 'monte-carlo', 'probability']"
649484,Proving the Limit of a Sequence of without the Dominated Convergence Theorem,Show: $$ \lim_{n\to \infty} \int_{0}^{\frac{\pi }{2}} \sin^n(x) = 0. $$ I showed this using the dominated convergence theorem . I want other methods to prove it. Thank you.,"['real-analysis', 'limits']"
649498,What does it mean for two functions to be equivalent? [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question What does it mean rigorously for two functions $f: \mathbb{R} \to \mathbb{R}$ and $g: \mathbb{R} \to \mathbb{R}$ to be equivalent? Does $f = g$ if and only if $\forall x \in \mathbb{R} \ \ f(x) = g(x)$?,['functions']
649500,How do people define flop?,"Let $f:Y \to X$ be a small contraction morphism of projective normal varieties. Then what is the usual way (if any) to define the flop $f^+: Y^+ \to X$ ? I could find a clear and uniform way to define flips in the literature, however, for flops things become very confusing. In the paper ""Flops"" by Kollár, it defines (Def 2.1) the $D$-flop of $f$, which is the small map $f^+ : Y^+ \to X$ such that $D^+$ (the proper transform of $D$) is $f^+$-ample (there are some other assumptions in the definition which I omit). However, something must be missing in that definition, because by that definition, $f$ itself is the flop of $f$. Moreover, this is the definition of $D$-flop, then what is the definition of flop? Is it the case $D = K_Y$? In Debarre's ""Higher-Dimensional Algebraic Geometry"" (see footnote in page 173), the flop is ""defined"" by a small map which ""removes the curve on which the canonical divisor has degree 0 and replaces it with another curve with the same property. However, there is a Cartier divisor that is negative on the first curve and positive on the second"". Last, in Bridgeland's paper ""Flops and derived categories"", flop is ""defined"" as ""if $D$ is a divisor such that $-D$ is $f$-nef, then its proper transform $D'$ is $f^+$-nef"" (See page 12 (4.6)). Then what are the relations between these definitions? Are they all the same? Besides, are the flops special case of flips? --- I always confused by this!","['algebraic-geometry', 'birational-geometry']"
649502,"Difference between a ""topology"" and a ""space""?","What do we mean when we talk about a topological space or a metric space ?  I see some people calling metric topologies metric spaces and I wonder if there is some synonymity between a topology and a space?  What is it that the word means, and if there are multiple meanings how can one distinguish them?","['general-topology', 'metric-spaces']"
649503,"Mystified by construction of ""group extension"" $\{G, T\}$ in Herstein's ""Topics in Algebra""","On page 69 of my (ancient) copy of his Topics in Algebra , I. N. Herstein describes a baffling construction by way of example, and moves on without further comment (FWIW, note that Herstein applies automorphisms ""on the right""; i.e. his $xT$ is what others would write as $Tx$ or even $T(x)$): Generally, if $G$ is a group, $T$ an automorphism of order $r$ of $G$ which is not an inner automorphism, pick a symbol $x$ and consider all elements $x^ig$, $i = 0, \pm 1, \pm 2,\dots,\; g\in G$ subject to $x^i g = x^{i^{\,\prime}}\!\!g^{\,\prime}$ if and only if $i \equiv i^{\,\prime} \!\!\! \mod r, g = g^{\,\prime}$ and $x^{-1}g^i x = g\,T^i$ for all $i$.  This way we obtain a larger group $\{G, T\}$; $G$ is normal in $\{G, T\}$ and $\{G, T\}/G\approx$ group generated by $T=$ cyclic group of order $r$. OK, I get it (although just barely) that this $\{G, T\}$ is a group, etc., but what's the point? I remember being similarly mystified, a long time ago, when I first came across the construction of a quotient group.  Now, with a lot more exposure to this sort of thing under my belt, it is not such a mystifying concept...  So, given this experience, I now have to wonder if the construction above is pointing at some workhorse maneuver in algebra.  Is it just some idiosyncratic hiccup of the author's, one that can safely be ignored?  Or is it worth my while to try to understand it better?  And if so, how?  When learning about quotient groups, it was very helpful for me to see how quotient groups generalized the notion of a projection of vector space onto a subspace.  Is there a similarly illuminating illustration of what the construction above is aiming at?","['group-theory', 'abstract-algebra']"
649524,Book with color pictures of algebraic surfaces,I have a pretty specific question: I'm looking for a book with color pictures of algebraic surfaces. Could anyone point me in the right direction?,"['algebraic-geometry', 'reference-request', 'surfaces']"
649546,How prove there exists a real number $y$ with $0<y<1$ such that $a_0+a_1y+\cdots+a_ny^n=0.$,"Suppose that the real numbers $a_0,a_1,\dots,a_n$ and $x,$ with $0<x<1,$ satisfy $$\frac{a_0}{1-x}+\frac{a_1}{1-x^2}+\cdots+\frac{a_n}{1-x^{n+1}}=0.$$Prove that there exists a real number $y$ with $0<y<1$ such that $$a_0+a_1y+\cdots+a_ny^n=0.$$ My try: let
$$f(x)=a_{n}x^n+a_{n-1}x^{n-1}+\cdots+a_{1}x+a_{0}$$
then 
$$f(0)=a_{0}$$
$$f(1)=a_{0}+a_{1}+\cdots+a_{n}$$ But How can prove 
$$f(0)f(1)<0?$$ Thank you",['analysis']
649548,Find three $10\times10$ orthogonal Latin squares.,"Can one find three $10\times 10$ mutually orthogonal Latin squares? Does anyone know if there is a mathematical ""trick"" in finding mutually orthogonal Latin squares? Or is it basically trial and error?","['matrices', 'latin-square', 'combinatorics']"
649567,Parity of Binomial Coefficients,"Do $\binom nr$ and $\binom {2n}{2r}$ always have the same parity? I can see that it's true for $r=1$ since $\binom {n}{1}=n$ and $\binom{2n}{2}=n(2n-1)$, but what about for bigget $r$?",['combinatorics']
649570,On solving $\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+x}}}}=\sqrt[3]{6+\sqrt[3]{6+\sqrt[3]{6+\sqrt[3]{6+x}}}}$,"How do we show that there is only one solution to,$$\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+x}}}}=\sqrt[3]{6+\sqrt[3]{6+\sqrt[3]{6+\sqrt[3]{6+x}}}}$$ I guess it is only $x=2$.
Please help.","['radicals', 'algebra-precalculus']"
649582,Why is the restricted holonomy the identity component of the holonomy group?,"Let $M$ be a connected smooth paracompact manifold, $E$ a vector bundle over $M$ with fibre $\mathbb R^k$, and $\nabla$ a connection on $E$. It is known that Hol$^0(\nabla)$ is a connected Lie subgroup of $GL(k,\mathbb R)$. How can we show Hol$^0(\nabla)$ is an identity component of Hol$(\nabla)$? It seems to me that there are two ways to understand this. The first way is to regard Hol$^0(\nabla)$ and Hol$(\nabla)$ as topological subspaces of $GL(k,\mathbb R)$. Another way is to make Hol$(\nabla)$ a Lie subgroup of $GL(k,\mathbb R)$ by left translating the differential structure of Hol$^0(\nabla)$. But to prove Hol$(\nabla)$ is a Lie group, one has to prove for any $a\in$ Hol$(\nabla)$, the mapping from Hol$^0(\nabla)$ to Hol$^0(\nabla)$ defined by $x \rightarrow axa^{-1}$ is differentiable. I am stuck here.","['holonomy', 'vector-bundles', 'differential-geometry']"
649587,Time complexity of finding nullspace of a matrix,"The problem is finding the nullspace of a singular $n \times n$ square matrix $A$
(or alternatively computing the eigenvectors corresponding to the eigenvalue 0). What is the algorithm with the lowest time complexity of finding the nullspace. e.g. for SVD this is $O(n^3)$","['linear-algebra', 'svd', 'eigenvalues-eigenvectors']"
649588,Equicontinuity on a compact metric space turns pointwise to uniform convergence,"I know that If $\{f_n\}$ is an equicontinuous sequence,  defined on a compact metric space $K$, and for all $x$, $f_n(x)\rightarrow f(x)$, then $f_n\rightarrow f$ uniformly. I'm having trouble proving this.  I see the same problem here but am having trouble following the proof, particularly with part (3). Can someone guide me through a proof of this result?","['convergence-divergence', 'general-topology', 'continuity', 'real-analysis', 'functional-analysis']"
649640,"A ""Paradoxist Geometry""","This question is about ""how badly can we 'break' the laws of geometry and still have something which is deserving of the name geometry ?"". It is named after something else I saw of the same name which also gives strange contortions of the laws of geometry. But here goes. I am interested in two ideas from Euclidean geometry: all right angles are equal there is exactly one parallel to a line through a point not on that line In particular, I'm curious to see how far one can push the failure of these principles. With regard to the first one, an example of a space in which it would fail would be a cone. In this case, the axiom fails when dealing with lines through the cone point. But is it possible for it to fail more dramatically? Is there anything that could deserve to be called a geometry in which no right angles are equal? If not that, a geometry in which in every neighborhood of the vertex of a right angle you could find another right angle which is not equal to it? What about the second one? One geometry where it fails is hyperbolic geometry, in which there are infinitely many parallels through a point. Another is elliptic, and the related spherical, geometry, in which there are no parallels. In the elliptic and related geometries, other axioms of Euclidean geometry, besides the parallel postulate, have to give out in order for it to fail with no parallels through a point. This makes me wonder: could there be some kind of geometry in which there are exactly two parallels through a point? Exactly three? Countably many? What else must go to allow for this? Could you have a ""geometry"" in which both of these properties fail? E.g. not all right angles are equal, and furthermore there are exactly two parallels through a point?",['geometry']
649654,What consistent rules can we use to compute sums like 1 + 2 + 3 + ...?,"$
\newcommand{ifelse}[3]{
\left(
\begin{cases}
#1\text{ if }#2 \\
#3\text{ otherwise}
\end{cases}
\right)
}
$
A recent Numberphile video on 1+2+3+... has made this question (""Why?"") popular again, as can be seen in the many related and duplicate questions . But after puzzling a bit with this, it seems that the rules that they use in that video are inconsistent... As far as I can see, they assume the existence of a sequence summation operator $\sum_n a_n$ which is just standard summation for convergent series, and which additionally obeys the following rules:
\begin{align}
& \sum_n (a\text{ with all zeroes removed})_n = \sum_n a_n \tag{0} \\
& \sum_n (c \times a_n + b_n) = c \times \sum_n a_n + \sum_n b_n \tag{1} \\
\end{align} However, if I am not mistaken, these rules quickly lead to an inconsistency:
\begin{alignat}{2}
0
&= \sum_n 1 - \sum_n 1
&&\text{(arithmetic, assuming $\;\sum_n 1\;$ exists)} \\
&= \sum_n 1 - \sum_n \ifelse{0}{n=0}{1}
\quad &&\text{(inserting a 0 does not change the sum)} \\
&= \sum_n \ifelse{1}{n=0}{0}
&&\text{(from (1))} \\
&= 1
&&\text{(convergent series)} \\
\end{alignat}
Therefore my question is: Is there a set of consistent rules for a summation operator that allows us to compute $\;\sum_n n\;$ (""$1 + 2 + 3 + \dots$"")?  Does that work on all sequences, or do we have to exclude some (like perhaps $\;\sum_n 1\;$), and if so, which exactly?","['divergent-series', 'ramanujan-summation', 'summation', 'sequences-and-series']"
649661,Group presentations: What's in the kernel of $\phi$?,"I have a question about group presentations (in terms of generators and relations). It's been really bugging me for ages. Would really appreciate any thoughts on this. Cheers, Michael You are 'given' a group $G$. First, we find a list of generators for the
group. Let's be lazy and take all of the elements as generators. We
know how to explicitly construct the free group on this set of
generators. Denote this free group $F$. Now we know there is a
homomorphism, call it $\phi$, from the free group $F$ onto our group $G$.
By the first isomorphism theorem we know that G is isomorphic to the
quotient group $F / \ker\phi$. To define my group $G$, I could therefore state what the generators are,
and also a set of generating elements of $\ker\phi$. So the question now
is this: What's in the kernel of $\phi$? We could take all the relations from
the Cayley table and rewrite them in 'standard form', i.e., rewrite
$g_1*g_2 = g_3$ as $g_1*g_2*g_3^{-1} = e$. All such expressions must be elements
of $\ker\phi$. Let's denote this set of elements $R$. Let's also denote
the normal subgroup generated by $R$ as $N$. We know that $\ker\phi$ is a normal subgroup of $F$ which contains the set
$R$. Because $N$ is the smallest normal subgroup of $F$ which contains the
set $R$, it is obvious that $\ker\phi$ contains $N$. However textbooks always
assert more than this, namely that $\ker\phi = N$. I know how to prove that $\ker\phi=N$ for specific examples. For
example, I attach below a proof for $G=D_4$. However I can't construct a general proof to understand properly why this
works for any group. It makes intuitive sense, but that never satisfies!","['group-theory', 'group-presentation']"
649667,How many points you should draw in the square at least？,"There is a square, which side length is $2$,
To ensure there exists a triangle in the square, with an area less than $0.5$,
how many points should you draw in the square at least. the goal is for all quantification of possible point arrangements, there must exist a triple of points, which triangle area less than $\frac{1}{2}$. use pigeonhole principle，it's easy to prove the ceiling is 10;
I think 9 points is the answer, but i can't prove it.
Please give your answer and proof to help me, thank you.","['geometry', 'puzzle', 'combinatorial-geometry']"
649678,How do you differentiate the likelihood function for the uniform distribution in finding the M.L.E.?,"There is a classic problem: Suppose that $X_1,\ldots,X_n$ form an i.i.d. sample from a uniform distribution on the interval $(0,\theta)$, where $\theta>0$ is unknown. I would like to find the MLE of $\theta$. The pdf of each observation will have the form:
$$
f(x\mid\theta) = 
\begin{cases}
1/\theta\quad&\text{for }\, 0\leq x\leq \theta\\
0 &\text{otherwise}.
\end{cases}
$$
The likelihood function therefore has the form:
$$
L(\theta) =
\begin{cases}
1/\theta^n \quad&\text{for }\; 0\leq x_i \leq \theta\;\; \text{for all }i,\\
0 &\text{otherwise}.
\end{cases}
$$
The general solution is usually that the MLE of theta must be a value of $\theta$ for which $\theta \geq x_i$ and which maximizes $1/\theta^n$ among all such values. The reasoning is that since $1/\theta^n$ is a decreasing function of $\theta$, the estimate will be the smallest possible value of $\theta$ such that $\theta\geq x_i$. Therefore, the mle of $\theta$, $\hat{\theta}$, is $\max(X_1,\ldots,X_n)$. Here, I do not understand why we cannot just differentiate the likelihood function with respect to theta and then set it equal to $0$? Thanks!","['statistics', 'probability']"
649702,Proving that Spec(α) and Spec(ß) partition positive integers iff α and ß are irrational and 1/α + 1/ß = 1,"From Concrete Math, problem 3.13 asks: ""Let α and ß be positive real numbers. Prove that Spec(α) and Spec(ß) partition positive integers if and only if α and ß are irrational and 1/α + 1/ß = 1"" The solution claims: ""If they form a partition, the text's formula for N(α,n) implies that 1/α + 1/ß = 1, because the coefficients of n in the equation N(α,n) + N(ß,n) = n must agree if the equation is to hold for large n"" (it goes on to the next part of the proof but I only care about this part) In this chapter, they define Spec(α) to mean an infinite multiset of integers: $\{\lfloorα\rfloor,\lfloor2α\rfloor, ...\}$, and define N(α,n) to be the number of elements in Spec(α) that are $\le$ n. They show that N(α,n) = $\lceil(n+1)/α\rceil - 1$. They also show that a necessary condition for Spec(α) and Spec(ß) to partition the positive integers is N(α,n) + N(ß,n) = n I can write out the equation N(α,n) + N(ß,n) = n by substituting that equation:
$$\lceil(n+1)/ß\rceil + \lceil(n+1)/α\rceil - 2 = n$$
then converting to floor
$$\lfloor (n+1)/ß\rfloor + \lfloor (n+1)/α\rfloor = n$$
then splitting the floor into the fractional and actual part of its arguments
$$n(1/ß + 1/α) + 1/α + 1/ß - \{(n+1)/ß\} - \{(n+1)/α\} = n$$
...but, at that point, I don't see how I can conclude that 1/α + 1/ß = 1. I see that 1/α + 1/ß appears as a coeffecient of n, but there's the problem of the fractional stuff on the right. For their claim to be correct, the fractional parts would have to add up to 1 to cancel out the 1 from  1/α + 1/ß. I know that the fractional parts both have values less than one (since they are fractional parts of real numbers), but I don't see how to conclude that they sum to 1. Can I just claim that, since n appears on the right hand side with a coefficient of 1, that the coefficient for n on the left must be 1?","['discrete-mathematics', 'proof-writing', 'ceiling-and-floor-functions']"
