question_id,title,body,tags
2610399,Having difficulty understanding probabilities in this question,"Question: Given $5$ people in an elevator on the ground floor, and the buttons for the second, third, and forth floors are lit, what is the probability that two people will exit the elevator at floor $3$? Maths noob here. I have spent about $10$ minutes trying to come up with a solution to this question. I intuitively think the answer is $0.6$ but I lack the tools to reason about it properly. Any help? Apologies for the ""please do my work for me"" question.",['probability']
2610435,"If $X_n \overset{a.s.}\to X$,$Y_n\overset{a.s.}\to Y$, when are $X$ and $Y$ independent?","Consider two sequences of r.v's $\{X_n\}$ and $\{Y_n\}$. Suppose $X_n$ and $Y_m$ are independent for any $m,n\in\mathbb{N}$. Suppose $X_n\overset{a.s.}\to X$ and $Y_n\overset{a.s.}\to Y$. Is it true that $X$ and $Y$ are independent? What if we weaken the condition from a.s. convergence to convergence in probability? I can show that for any continuous bounded function $f$ and $g$, $\mathbb{E}\left[ f(X) g(Y)\right] = \mathbb{E}\left[f(X)\right] \mathbb{E}\left[g(Y)\right]$. But I don't know how to proceed from here (since identity function is not bounded).","['probability-theory', 'probability']"
2610437,On reducibility over $\mathbb{Z}$ of a special class of polynomials .,"Definitions Let positive integer number $n$ be referred to as $p$-composite if there exist such positive integer numbers $k_1$ and $k_2$ that
$$
n=k_1+k_2+2k_1k_2\equiv k_1*k_2.
$$ Let $\mathbb{K}_n$ be the set of all distinct ordered pairs $(k_1,k_2)$, such that $n=k_1*k_2$. Let the cardinality of the set $\mathbb{K}_n$ incremented by 1 be referred to as composition index ${\cal I}_n$ of the number $n$. Based on numerical evidence I propose the following Conjecture The polynomial
$$
P_n(x)=\sum_{i=0}^n(-1)^{\left\lfloor\frac{i+1}{2}\right\rfloor}\binom{\left\lfloor\frac{n+i}{2}\right\rfloor}{i}x^i
$$ 
is reducible to product of exactly ${\cal I}_n$ irreducible polynomials over $\mathbb{Z}$. Particularly this means that if $n$ is not $p$-composite $({\cal I}_n=1)$ the polynomial $P_n(x)$ is irreducible. I would be thankful for any hint on proving or disproving the conjecture. The following information may appear useful: $P_n$ is characteristic polynomial of $n\times n$ dimensional integer matrix $M$ introduced in my previous question . (based on numerical evidence) The polynomial $P_{k_1}((-1)^{k_2}x)$
divides the polynomial $P_{k_1*k_2}(x)$. Notes added: The first $p$-composite number is $\small 4$ with $\small {\cal I}_4=2$, the next $\small7$ with $\small{\cal I}_7=3$ and so on. As pointed out by Ewan Delanoy, $\small {\cal I}_n$ is just the decremented by 1 number of all distinct divisors of $\small 2n+1$. More generally if $\small d | 2n+1$, $\small k=\frac{d-1}{2}$ is ""$\small p$-divisor"" of $\small n$.","['matrices', 'irreducible-polynomials', 'polynomials', 'elementary-number-theory']"
2610459,"Derive unbiased estimator for $\theta$ when $X_i\sim f(x\mid\theta)=\frac{2x}{\theta^2}\mathbb{1}_{(0,\theta)}(x)$","Exercise: Let $X_1,\ldots,X_n$ be a random sample from the distribution with density $$f(x\mid\theta) = \dfrac{2x}{\theta^2}\mathbb{1}_{(0,\theta)}(x)$$ w.r.t. the Lebesgue measure. Derive an unbiased estimator for $\theta$ . What I've tried: I need to find an estimator $\delta(X_1,\ldots,X_n)$ such that $\operatorname{E}\big[\delta(X_1,\ldots,X_n)\big] = \theta$ . I tried the maximum likelihood estimator but that got me nowhere. The log-likelihood would be equal to $\log L = \log\prod\limits_{i = 1}^n\dfrac{2x_i}{\theta^2}\mathbb{1}_{(0,\theta)}(x_i) = \sum\limits_{i= 1}^n2x_i - 2n\log\theta$ (I'm not sure if I can leave the indicator function like this btw). If I now take the derivate w.r.t. $\theta$ and set it to zero I get that $\hat{\theta}_{ML} = 0$ , which is not an unbiased estimator. Question: How do I solve this exercise? In general; what would a efficient approach be to find an unbiased estimator in exercises like this one? Thanks in advance!","['parameter-estimation', 'statistics', 'statistical-inference', 'probability-distributions']"
2610470,Function of bounded variation which is differentiable except on countable set,"Consider a function $g\in {\rm L}^1(0,1)$ such that $g\in {\rm BV}(0,1)$. I have two questions: Q1: If the classical derivative $g'$ exists almost everywhere on $(0,1)$, and if $g'=1$ almost everywhere on $(0,1)$, is it true that $g$ almost everywhere agrees with piece-wise affine function (with finitely many pieces) with slope $1$? Q2:  If the classical derivative $g'$ exists everywhere on $(0,1)$ except at countably many points in $(0,1)$, and if $g'=1$ except at countably many points in $(0,1)$, is it true that $g$ almost everywhere agrees with piece-wise affine function (with finitely many pieces) with slope $1$? I think the answer to Q1 is no. For instance, the counterexample in the case $g'=0$ almost everywhere is well-known Cantor's function or devil's staircase function, which is strictly increasing on $(0,1)$, and therefore belongs to ${\rm BV}(0,1)$, but such function is not piece-wise constant (with finitely many pieces). But I think that the answer to Q2 is yes. This would imply that such BV-functions allow at most finitely many jump-discontinuities. Is this really true? I do not know how to prove this. Remark. One of the issues is that we probably need to be specific when we introduce the space of BV-functions, and there are two approaches. One approach is to define that BV-function is a function with finite pointwise variation $V_0^1(g):={\rm sup}\{\sum|g(t_{j+1})-g(t_j)|\}$, where the supremum is taken over all finite sums with respect to finite partitions $0<t_1<...t_{j}<t_{j+1}<..<1$. Another approach is to require that points $(t_j)$ are points of approximate continuity of $g$, in which case we get the notion of essential variation ${\rm ess}V_0^1(g)$, so then BV-functions are defined as functions with finite essential variation. The latter definition is probably more convenient for $g\in {\rm L}^1(0,1)$, and the former for $g\in {\rm C}(0,1)$. But I do not know how to work with essential variation. In any case, I am interested in finding out if the answer to Q2 is yes, and why. Thanks in advance.","['functional-analysis', 'real-analysis', 'bounded-variation']"
2610476,Duhamel's principle for heat equation.,"A solution to the nonhomogeneous heat equation with $0$ initial data is $u:\Bbb R^n\times [0,\infty)\to \Bbb R$ solving
  $$\begin{align}
\partial_t u(x,t) - \Delta_xu(x,t) &= f(x,t) \\
u(x,0) &\equiv 0.
\end{align}$$
  The regularity of $f$ is unspecified for now. Recall the heat kernel $\Phi(x,t)=\frac 1{(4\pi t)^{n/2}}e^{-|x|^2/4t}$. The Duhamel's principle states that
  $$
u(x,t)=\int_0^t\int_{\Bbb R^n} \Phi(x-y,t-s)f(y,s)dyds
$$
  solves our equation. In books I've read, e.g. Evans' PDE, assume quite a strict condition on the regularity of $f$. For example, in Evans' book he assumed that $f\in C^2_1(\Bbb R^n\times[0,\infty))$ and is compactly supported. Then the proof that $u$ really solves the heat equation or the smoothness of $u$ is shown by rewriting the formula as
$$
u(x,t)=\int_0^t\int_{\Bbb R^n} \Phi(y,s)f(x-y,t-s)dyds
$$
and differentiate under integral sign, e.g.
$$
\partial_t u(x,t)=\int_0^t\int_{\Bbb R^n} \Phi(y,s)\partial_t f(x-y,t-s)dyds+\int_{\Bbb R^n}\Phi(y,t)f(x-y,0)dy.
$$
To show smoothness of $u$, some even assume $f$ to be smooth. I can't help but feeling that this is a massive overkill. Some integrability condition on $f$ should suffice. What are some reasonable integrability conditions we can put on $f$ so that 
  $$
u(x,t)=\int_0^t\int_{\Bbb R^n} \Phi(x-y,t-s)f(y,s)dyds
$$
  works? What should we impose further to get higher regularity of $u$? Of course, if $f$ is really irregular we cannot expect $u$ to be regular. I just want to know how much regularity do we gain from the fact that $u$ solves heat equation.","['partial-differential-equations', 'heat-equation', 'convolution', 'functional-analysis', 'sobolev-spaces']"
2610501,"Sum of all numbers formed by digits 1,2,3,4 & 5. [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question A five digit number has to be formed by using the digits $1,2,3,4$ and $5$ without repetition such that the even digits occupy odd places. Find the sum of all such possible numbers. This question came in my test where you literally get $2$ minutes to solve one problem. I want to how to solve this problem more ""mathematicaly"" instead of listing all the $36$ cases.","['permutations', 'combinatorics', 'combinations']"
2610802,Are there any interesting examples of functions on Abelian groups that are not homomorphisms?,"It seems that most maps on (abelian) groups $G$ studied are homomorphisms, that is they obey $\phi(ab)=\phi(a)\phi(b)$ for $a,b\in G$. Are there any interesting examples of maps $\phi:G\to H$ in the literature that are not homomorphisms (but still have some structure)? (I am mostly interested in abelian groups. Hence that rules out the ""antihomomorphism"" $\phi(ab)=\phi(b)\phi(a)$ in the case of abelian groups.) Thanks.","['abelian-groups', 'abstract-algebra', 'group-theory']"
2610807,Second Zariski cohomology of the multiplicative group,"Let $X$ be a scheme, then $H^2_{et}(X, \Bbb G_m)$ is defined as the Brauer group of $X$ and people always say that Zariski topology is so coarse that we need to consider etale cohomology in practice. However, we have $H^1_{et}(X, \Bbb G_m) \cong H^1_{Zar}(X, \Bbb G_m)$ by using the standard spectual sequence from zariski cohomology to etale cohomology, Cech cohomology and f.f descent for line bundles. Therefore, what is known about $H^2_{Zar}(X, \Bbb G_m)$ for good schemes (i.e a regular proper scheme over $\Bbb Z$ or a field)? Must it be zero in all cases? What about higher zariski cohomologies?",['algebraic-geometry']
2610828,How can I be sure that two given sets A and B are truly equal sets?,Let's say we have given two sets: $A$ and $B$. I thought about two possible statements: 1st: $A = B$ iff $|A| = |B|$ and $(\forall x \in A: x \in B)$ and $(\forall y \in B: y \in A)$ 2nd: $A = B$ iff $|A \setminus (A \cap B)| = 0$ and $|B \setminus (A \cap B)| = 0$ Now I am curious if this statements are true and how I can prove them (or are they already fundamental/trivial). Also are there other possible true statements?,['elementary-set-theory']
2610848,"What does ""maximum value"" of a set of random variables mean?","In our statistical mechanics lecture the professor said something along the lines of: If we have some independent random variables $x_1,x_2,x_3,...,x_n$ having identical distributions: Suppose $M_{n}=\text{max}(x_1,x_2,x_3,...)$, then we say that
  probability that $M_{n}<x$ is $\text{$\text{Pr}(M_{n}<x$)}$ (say). In such a case
  $\text{$\text{Pr}(M_n<x$)}=\text{$\text{Pr}(x_1<x,x_2<x,x_3<x,...$)}=(\text{Pr}(x))^{n}$ Now, first of all I don't understand what he meant by $M_{n}=\text{max}(x_1,x_2,x_3,...)$. What does maximum of a set of random variables even mean? Does it refer to the random variable which can take the highest value? Secondly I don't understand the step $\text{$\text{Pr}(M_n<x$)}=\text{$\text{Pr}(x_1<x,x_2<x,x_3<x,...$)}=(\text{Pr}(x))^{n}$","['statistics', 'probability']"
2610854,Trigonometry: Finding the lengths of a right triangle,"I am currently working on a problem that was on a test of mine that I took recently.  I got the result back and am working on test corrections to make my grade better! But, I am currently stuck on a problem so I thought I would seek help. Before telling the question and what I have been doing I need to say that I am in High School and this is part of my Honors Pre-calculus class. And I am just starting to learn about trigonometry. Alright here is the question! A tourist looks out from the observation deck of the Space Needle in Seattle. The deck is at a height of 520 feet. She sees her friend on the ground below at an angle of depression of 85.6 degrees. What is the distance between the two? Round your answer to the nearest tenth of a foot. From taking the test I know the correct answer is 521.5 ft. Here is what I did on the test: Click here for my work I am really stuck and I do not know what to do not know what to do. Some help would would be really appreciated. Thanks in advance!","['trigonometry', 'triangles']"
2610870,"Calculate limit of $(1 + x^2 + y^2)^\frac{1}{x^2 + y^2 + xy^2}$ as $(x,y) \rightarrow (0,0)$","I'm trying to calculate the limit of 
$(1 + x^2 + y^2)^\frac{1}{x^2 + y^2 + xy^2}$ as $(x,y) \rightarrow (0,0)$. I know that the limit is supposed to be $e$, and I can arrive at this answer if I study the univariate limit by, for instance, setting $x=t, y=0$ and letting $t \rightarrow 0$ or vice versa. I'm not sure how to calculate it for the multivariate case. I tried using polar coordinates $(x= r \cos{\theta}, y = r \sin{\theta})$ which gets me $$ (1 + r^2)^{\frac{1}{r^2(1 + r \cos{\theta}\sin^2{\theta})}} $$, after symplifying the expression, but I don't know how to proceed from there. I assume that I am supposed to end up with an expression similar to $(1 + n)^\frac{1}{n} \rightarrow e$ as $n \rightarrow 0$.","['multivariable-calculus', 'limits']"
2610891,Lipschitz continuous function whose derivative is not continuous almost everywhere,"I want to disprove the following statement. Every Lipschitz-Continuous function is almost everywhere continuous differentiable. From Whitney-Extension theorem, we know that the derivative of a Lipschitz-continuous function is continuous on a set being arbitrary close to a co-nullset. Does there exist a counter-example for the statement on a co-null set? (Everything on the space with lebesgue measure) My idea is to consider a nowhere continuous function $g(x)$ on a non-lebesgue null set, which is bounded $|g(x)|\leq M$ . Then, setting $$f(y)=\int_0^yg(x)dx$$, the function $f(x)$ is Lipschitz continuous. Using Rademacher-theorem, the derivative of $f$ is g. However, it is not obvious to me if such $g(x)$ exists and how does it looks like.","['geometric-measure-theory', 'measure-theory']"
2610941,What is the precise value of the expression $\frac{\cos 25^{\circ}+\sin (-5^{\circ})}{\sin 25^{\circ}+\cos 5^{\circ}}$,"The values are in degrees. I did various manipulations of the expression but the best I could was to end up with an expression in $\sin 20^\circ$ and $\cos 20^\circ$ which are hard to compute.
As this was an exam question I think it must be a quick elegant solution.","['trigonometry', 'fractions']"
2610952,Finding all reflexive binary relations of a set,"Let A = $\{1,2,3\}$. What is the total number of reflexive binary relations on $P(A)$? What I've tried to do is: Let $R$ a relation on $P(A)$. For it to be reflexive, the following must be true: $$\forall a \in A , (a,a) \in R$$ There are ${{2^{2}}^3}^2$ total possible relations on $P(A)$. I just can't seem to understand what do I need to subtract from that value to get the answer.","['relations', 'elementary-set-theory', 'discrete-mathematics']"
2610989,"Skewes' number, and the smallest $x$ such that $\pi(x) > \operatorname{li}(x) - \tfrac1n \operatorname{li}(x^{1/2})$?","We know that Skewes' number is a yet unknown huge integer $x$ such that, $$\pi(x) > \operatorname{li}(x)\tag1$$ where $\pi(x)$ is the prime counting function and $\operatorname{li}(x)$ is the logarithmic integral function . We also know that the $\text{RHS}$ is just the first term of an infinite series as stated by Ramanujan and Riemann, $$\pi(x) = \operatorname{li}(x) -\tfrac12\operatorname{li}(x^{1/2})-\tfrac13\operatorname{li}(x^{1/3})-\tfrac15\operatorname{li}(x^{1/5}) +\dots$$ Q: What if we also use and modify the second term,
  $$\pi(x_n) > \operatorname{li}(x_n) - \tfrac1{\color{blue}n} \operatorname{li}(x_n^{1/2})\tag2$$
  and for a given $n$, find the smallest integer $x>8$ that satisfies the inequality? For $n=2,3,4,5$, we have, $$x_2 = 19$$
$$x_3 = 59753$$
$$x_4 = 30902129$$
$$x_5 = 110087953$$ with $2,5,8,9$ digits and $x_5$ found by DanaJ . Of course, as $n$ climbs ever higher and $x_n$ reaches $317$ digits, it will then reach Skewes' number which is true for all $n$. So what is $x_6$ and higher?","['number-theory', 'computational-mathematics', 'prime-numbers', 'experimental-mathematics']"
2611007,Relation between two polynomials,"I am stuck on the following exercise.
Let $P \in \mathbb{C}[X]$ be a polynomial of degree $n \in \mathbb{N}$, $n > 0$. We write : $$ P(X) = \sum_{k=0}^{n} a_k X^k $$ with $a_0, \ldots, a_n \in \mathbb{C}^{n+1}$.
I would like to prove that : $$ \sum_{k=0}^{n} (-1)^{n-k} \begin{pmatrix} n \\ k \end{pmatrix} P(k) = n! ~ a_n. $$ Could someone, please, suggest me ways/ideas to prove this equality ?","['algebra-precalculus', 'combinatorics', 'polynomials']"
2611083,Vectorization and transpose: how are $\text{vec}(W^T)$ and $\text{vec}(W)$ related?,"In solving for a gradient, I ended up with a differential that looks similar to:
$$
dT = (a^T \otimes b^T)\ \text{vec}[d[W]^T] + (b^T \otimes c^T)\ \text{vec}[d[W]]
$$
and I am trying to solve for $\frac{\partial T}{\partial \text{vec}W}$. The second term isn't a big problem, since we can just flip-flop the vec and d operators, but the first term needs to handle the transpose and I wasn't sure how to do it. Note: Although I hope it isn't nessesary, the actual equation I am solving for is $\frac{\partial T}{\partial \text{vec}W}$ with $T$ defined below:
$$ T = (y - f_1(W_1f_0(W_0x)))^TB_0^Tf_0(W_0x) $$
using elementwise differentiable functions $f_i$, and non-square matricies $W_i$, and static vector $y$. Edit : Based on numerical experiments it seems that this relationship is true:
$$
T = b^TW^Ta + c^TWb\\
dT_0 = (a^T \otimes b^T)\text{vec}[d[W]^T] \implies \nabla_{\text{vec} W} T_0 = (a^T \otimes b^T)\\
dT_1 = (b^T \otimes c^T)\text{vec}[d[W]] \implies \nabla_{\text{vec} W} T_1 = (c^T \otimes b^T)\\
$$
But this doesn't make any sense to me. Why would the non-transposed version flip the order of the kronecker product?","['matrices', 'transpose', 'vectorization', 'linear-algebra']"
2611097,Finding the general solution of an equation.,"Write the equation $f_{xx}-f_{yy} = 0$ in terms of the variables $u=x+y$, $v=x-y$ and calculate the general solution. We define $g(u,v)=f(x,y)$, then, by the chain rule: $$f_x=g_u+g_v,f_y=g_u-g_v$$
Using the chain rule again $$f_{xx}=g_{uu}+g_{vu}+g_{uv}+g_{vv},f_{yy}=g_{uu}-g_{uv}-g_{vu}+g_{vv}$$ Therefore $$f_{xx}-f_{yy}=4g_{uv}$$
 $$0=4g_{uv}$$ This means $g_u$ doesn't depend on $v$ and $g$... I understand everything up until this point: ... has the form $\phi(u)+\psi(v)$ with $\phi$, $\psi$ functions of one variable. Therefore the general solution of $f_{xx}-f_{yy}=0$ is $$f(x,y)=\phi(x+y)+\psi(x-y)$$ I don't understand why $g$ has the form $\phi(u)+\psi(v)$ and how $g_u$ not depending on $v$ reflects on that solution","['multivariable-calculus', 'wave-equation', 'partial-differential-equations']"
2611173,"Normed bounded sequence of $L^2[0,1]$","I was working for my final exam in analysis from Aliprantis and Burkinshaw's Principles of Real Analysis . I got stuck at this problem. Any help is appreciated. If $\{f_n\}$ is a norm bounded sequence of $L^2[0,1]$, then show that $\dfrac{f_n}{n} \overset{\text{a.e.}}{\longrightarrow}0$.","['almost-everywhere', 'lp-spaces', 'lebesgue-measure', 'measure-theory']"
2611204,Can this function be anything but a polynomial function?,"If $f\in\mathcal{C}^\infty((0,1),\mathbb{R})$ verifies the following:
\begin{equation}
\forall x\in(0,1),\,\exists n\in\mathbb{N},\quad f^{(n)}(x)=0
\end{equation}
Can $f$ be anything but a polynomial function?",['analysis']
2611243,Is $A-B$ never normal?,"Let $A,B \in M(3,\Bbb R)$, $A$ non-singular and symmetric, $B \neq 0$ such that $B^2=0$. Is $A-B$ never normal? 
So far i noticed that: 
$$(A-B)^*(A-B) = A^2 -AB-B^tA+B^tB$$
$$(A-B)(A-B)^*=A^2-BA-AB^t+BB^t$$
So if $B$ were symmetric $A-B$ would be normal but $B$ is nilpotent so it can't be symmetric (Symmetric matrices are diagonalizable for the spectral theorem and nilpotent matrices are not). $B$ is also different from $0$ so i believe that the statement is true but i can't demonstrate it. Thank you in advance for your help!","['matrices', 'symmetric-matrices', 'linear-algebra', 'nilpotence']"
2611248,Replace $X$ with $\mbox{diag}(x)$ in trace matrix derivative identity,"There is a scaler-by-matrix derivative identity: $$\frac{\partial}{\partial X}trace\left(AXBX'C\right)=B'X'A'C'+BX'CA$$ How does this change if instead I am trying to find $$\frac{\partial}{\partial x}trace\left(Adiag(x)Bdiag(x)'C\right)$$ where $x$ is a vector rather than a matrix. My thinking is that all I have to do is multiply the original identity by a vector of ones as that would be the derivative of $diag(x)$. However, I'm not sure how the chain rule interacts with traces. I ask as I am trying to calculate.
$$\frac{\partial}{\partial w}trace\left(Ddiag(w)\Omega diag(w)D'\right)$$ where $w \mathbb{\in R^{N}}$, $D\mathbb{\in R^{M\times N}}$, and $\Omega\mathbb{\in R^{N\times N}}$. Also $\Omega$ can be assumed to be positive definite. This implies the result would be $$\left(2\Omega diag(w)D'D\right)e$$ where $e \mathbb{\in R^{N}}$ is a vector of ones.","['derivatives', 'matrices', 'matrix-calculus', 'scalar-fields', 'trace']"
2611250,How many independent measurement of CPU-time are required such that the difference $|\bar{X} - \mu|<0.1$ with probability $0.9$ at least?,"The actual required CPU-time of a workstation session is assumed (due to a long-term study) as a
  random variable with unknown expected value $\mu$ and known variance
  $\sigma^2=6.25[s^2]$. How many independent measurement of CPU-time
  are needed such that with probability of at least $0.9$, you have that
  the difference $|\bar{X}-\mu|$ is less than $0.1$? This is task from old exam with different teacher. I ask my teacher and he say he don't show this example in class but give me two method for solve it: Central limit theorem and Chebyshev's inequality . This already help me much and I try solve like this: I use central limit theorem: We have that $$\sqrt{n} (\bar{X}-\mu) \text{ for } n \rightarrow \infty \text { is approximately standard normally distributed}$$ Now assume we have very big $n$ such that approximation mistake is very small so we don't need to keep it in mind. Then we can do $$P(|\bar{X}-\mu|) < \varepsilon) = P(\sqrt{n}|\bar{X}-\mu|<\sqrt{n} \varepsilon)=P(-\sqrt{n}\varepsilon< \sqrt{n}(\bar{X}-\mu)< \sqrt{n} \varepsilon) \\ \approx \Phi(\sqrt{n} \varepsilon)- \Phi(-\sqrt{n}\varepsilon) = 2\Phi(\sqrt{n}\varepsilon)-1$$ Now insert $\varepsilon= 0.1$ in inequality $P(|\bar{X}-\mu|<\varepsilon)\geq 0.9$ then we have $$2\Phi(0.1 \cdot \sqrt{n})-1 \geq 0.9 \Leftrightarrow \Phi(0.1 \cdot \sqrt{n}) \geq 0.95$$ And from this step I don't know how finish it :/ Can you tell me if this is correct till here and how to finish it? I really think I almost got it but something is missing.. But actually I'm more interested to know how you would do this with Chebyshev? I tried it already but also not sure if correct (see my comment of karakfa 's answer).","['probability-theory', 'probability-distributions', 'statistics', 'probability', 'discrete-mathematics']"
2611281,Consider the metric space of infinite sequences of 0s and 1s under this metric.,"For $x, y ∈ \{0, 1\}^\mathbb{N}$, define $d(x, y) = 2^{-n}$ where $n$ is the first position where the sequences $x$ and $y$ are different. Show that ($\{0,1\}^\mathbb{N}, d$) is compact. Show that the set P of periodic elements (sequences where there exist $m>0$ such that $x_i = x_{m+i}$ for all $i$) is countable and dense. What I tried For part 1, I have been trying to use the fact that a set is compact if every sequence has a convergent subsequence. But I keep confusing myself with the fact that the elements are sequences and then if I’m supposed to take sequences of those sequences. For part 2, I’m really not sure where to start. With regards to countability, my initial thought is that if an element is periodic then there is a finite number of elements that get repeated. And since there are only 2 possible options for any given entry, we are arranging a finite number of elements in finite ways? But I am not sure about density.","['real-analysis', 'metric-spaces', 'sequences-and-series', 'compactness']"
2611305,An alternative way to find the sum of this series? [duplicate],"This question already has answers here : Calculating $1+\frac13+\frac{1\cdot3}{3\cdot6}+\frac{1\cdot3\cdot5}{3\cdot6\cdot9}+\frac{1\cdot3\cdot5\cdot7}{3\cdot6\cdot9\cdot12}+\dots? $ (7 answers) Closed 5 years ago . $\displaystyle \frac{4}{20}$+$\displaystyle \frac{4.7}{20.30}$+$\displaystyle \frac{4.7.10}{20.30.40}$+... Now  I  have  tried  to  solve  this  in  a  usual  way,  first  find  the  nth  term  $t_n$. $t_n$=  $\displaystyle \frac{1}{10}$($\displaystyle \frac{1+3}{2}$)  +  $\displaystyle \frac{1}{10^2}$($\displaystyle \frac{1+3}{2}$)($\displaystyle \frac{1+6}{3}$)  +  ...+  $\displaystyle \frac{1}{10^n}$($\displaystyle \frac{1+3}{2}$)($\displaystyle \frac{1+6}{3}$)...($\displaystyle \frac{1+3n}{n+1}$) =$\displaystyle \frac{1}{10^n}\prod$(1+$\displaystyle \frac{2r}{r+1}$)  ,  $r=1,2,..,n$ =$\displaystyle \prod$($\displaystyle \frac{3}{10}-\displaystyle \frac{1}{5(r+1)}$)
thus,  $t_n=$ (x-$\displaystyle \frac{a}{2}$)(x-$\displaystyle \frac{a}{3}$)...(x-$\displaystyle \frac{a}{n+1}$),  x=$\displaystyle \frac{3}{10}$,  a=$\displaystyle \frac{1}{5}$ Now  to  calculate  $S_n$,  I  have  to  find  the  product  $t_n$,  and  then  take  sum  over  it.  But  this  seems  to  be  a  very  tedious  job.  Is  there  any  elegant  method(may  be  using  the  expansions  of  any  analytic  functions)  to  do  this?","['real-analysis', 'sequences-and-series']"
2611348,Every locally closed irreducible subset $Z$ of $X:=\text{Spec}A$ contains a unique generic point.,"Here $A$ is a commutative ring. I am confused about the problem statement. I believe that the question is referring to a generic point of $Z.$ This would correspond to a minimal prime ideal of $A$ contained in $Z.$ However, since $Z$ is irreducible, it is of the form $Z = V(\mathfrak p) :=\left\{x \in X: \mathfrak p \subseteq \mathfrak p_x \subseteq A\right\}$ for a prime ideal $\mathfrak p$ of $A.$ It seems that $\mathfrak p$ would be the unique generic point of $Z.$ My concern is that I haven't used the locally closed condition anywhere, so I suspect there is an error in my reasoning. I believe that I am somehow misunderstanding the problem statement. Could anyone shed some light on this? EDIT --
For context, this is exercise 2.8 in Algebraic Geomtery I: Schemes, with examples and exercises by Ulrich Görtz and Torsten Wedhorn Update : I believe that I have come up with a correct proof that I am posting below for future users to reference. Please let me know if there are errors that I haven't caught. Proof. Let $Z$ be a nonempty (this condition is necessary, as the $\emptyset = X \cap \emptyset$ clearly doesn't contain any generic points) locally closed irreducible subset of $X.$ As $Z$ is locally closed, it is the intersection of an open subsetset $V(\mathfrak a)^c$ and a closed subsetset $V(\mathfrak b)$ of $X.$ Since $Z$ is nonempty, we have that $\mathfrak a \not\subseteq \mathfrak b.$ Hence it suffices to show that $\mathfrak b$ is prime.This would clearly make $x_\mathfrak b \in Z$ the unique generic point. To this end we note that those subsets $V$ of $Z$ which  are of the form $F\cap V(\mathfrak a)^c,$ where $F\subseteq V(\mathfrak b)$ is closed are closed in $Z.$ That $Z$ is irreducible implies $V(\mathfrak b)$ is as well. As $V(\mathfrak b)$ is closed by assumption, we conclude that $\mathfrak b$ is prime.","['abstract-algebra', 'ring-theory', 'algebraic-geometry', 'commutative-algebra']"
2611382,Solve $\sin^{-1}x+\sin^{-1}(1-x)=\cos^{-1}x$ and avoid extra solutions while squaring,"Solve the equation, $$
\sin^{-1}x+\sin^{-1}(1-x)=\cos^{-1}x
$$ My Attempt: $$
\cos\Big[ \sin^{-1}x+\sin^{-1}(1-x) \Big]=x\\
\cos\big(\sin^{-1}x\big)\cos\big(\sin^{-1}(1-x)\big)-\sin\big(\sin^{-1}x\big)\sin\big(\sin^{-1}(1-x)\big)=x\\
\sqrt{1-x^2}.\sqrt{2x-x^2}-x.(1-x)=x\\
\sqrt{2x-x^2-2x^3+x^4}=2x-x^2\\
\sqrt{x^4-2x^3-x^2+2x}=\sqrt{4x^2-4x^3+x^4}\\
x(2x^2-5x+2)=0\\
\implies x=0\quad or \quad x=2\quad or \quad x=\frac{1}{2}
$$
Actual solutions exclude $x=2$.ie, solutions are $x=0$ or $x=\frac{1}{2}$.
I think additional solutions are added because of the squaring of the term $2x-x^2$ in the steps. So, how do you solve it avoiding the extra solutions in similar problems ? Note: I dont want to substitute the solutions to find the wrong ones.","['radicals', 'trigonometry', 'inverse-function', 'quadratics']"
2611399,Convergence of Maximum of Cauchy Random Variables,"Suppose $\{P_n\}$ and P are probability measures on the real line with corresponding distribution functions $\{F_n\}$ and $F$, respectively.
$P_n$ converges weakly to P if and only $$\lim_{n \rightarrow \infty} F_n(x) = F(x)$$
at every point x where F is continuous (this can be seen from Portmanteau theorem). How can we use this fact to prove the following. Let $X_1,X_2,...$ denote i.i.d. Cauchy random variables with parameter $a>0$. More clearly, the density of $X_i$ is 
$$P(X_i \in dx) = \frac{adx}{\pi(a^2+x^2)}, x \in \mathbb{R}$$
Prove that 
$$\frac{1}{n}\max_{1\leq i \leq n}X_i$$ converges in law to $\frac{1}{T}$ where $T$ is an exponential random variable. What is the rate of $T$ as a function of $a$?","['real-analysis', 'probability-theory', 'functional-analysis', 'weak-convergence', 'measure-theory']"
2611400,Generalizing the concept of ODE,"An ODE is a relationship such as $F(t,y(t),\dots,y^{(n)}(t))=0$ with $F:\Omega \subset R \times R^n \to R^n$, $\Omega$ open set not empty.
What happens if $F$ is similar, but  contains derivative of $y$ arbitrary large?
Does anyone know where I can find some material that talks about this theme? For example, the easiest thing that bumps in my mind:
$\sum_{i=0}^{\infty} y^{(i)}=0$
Now, lets put initial conditions : $y^{(n)}(0)=n^2$ for all $n\in N$ What can I say about the solutions of this equation?
I don't expect to calculate them analitically, but can I get some info? (Existence, unicity, global existence...)",['ordinary-differential-equations']
2611424,"Existence of $V \subset \mathbb{R}^n : V, V^\perp \cap \mathbb{R}_{\geq0}^n = 0$","Is there a subspace $V \subset \mathbb{R}^n$ with $V \cap \mathbb{R}_{\geq0}^n = V^\perp \cap \mathbb{R}_{\geq0}^n = 0$?
My geometric intuition tells me that there is no such $V$ but i'am completely stuck on proof.","['inequality', 'linear-algebra']"
2611435,Looking for references about a graphical representation of the set of roots of polynomials depending on a parameter,"Answering, some time ago, to this question : Change in eigenvalues on changing one entry of a matrix , I had the idea of a graphical representation of roots of polynomial equations $$P(x,a)=P_{a}(x) \in \mathbb{R}[a,x]=\mathbb{R}[a][x],$$ such as $$x^3+a x^2+(2a+1)x-3a=0.$$ [In fact, I will use notation $\lambda:=x$ , because we can assume WLOG that such polynomials can always be considered as characteristic polynomials of certain matrices whose coefficients are polynomials in $a$ (companion matrix for example).] The idea I have had is to build a simultaneous graphical representation of real and complex roots $\lambda_1,\lambda_2 ... \lambda_n$ of $P_a(\lambda)=0$ displaying their global dependency on real parameter $a$ (see Fig. 2). This representation will be explained through an example [with a certain similarity with the example given in the reference] in order to convey easily the underlying ideas. Let us consider the characteristic polynomial of the following matrix with one of its entries considered as a variable, here the bottom left entry (it is a particular case of what is called a pencil of matrices ) : $$A=\left(\begin{array}{rrrr}1&  3&  0& -2\\
 -1& -2&  0&  3\\
-1&  2& -2& -2\\
   \color{red}{a} & 3 & 0 & 0 \end{array}\right).\tag{1}$$ The real roots of characteristic polynomial $\det(A-\lambda I)=0$ are graphically represented on Fig. 1 : for a given value of $a$ , the plotted points are $(a, \lambda_k)$ . We see regions with two or four real roots, exceptionnaly 3. The eye is attracted by the generated ""interweaved"" curves that will be analyzed later on. Fig. 1 : The ""3 roots"" case corresponds to places of bifurcation (little red circles) where 2 formerly distinct real roots coalesce, then ""disappear"" ; or, in a reverse way, appear ""from scratch"". Let us proceed by showing how these appearances/disappearances (coalescence of real roots into a pair of complex conjugate roots) can be made visible. Take a look at (3D) Fig. 2, and compare it with (2D) Fig. 1. Instead of having a real-valued axis for $\lambda$ , we switch to a ""complex valued axis"", more precisely, we replace a single axis by two of them, one for the real part, the other one for the imaginary part. As complex eigenvalues come by conjugate pairs (the polynomials we consider have real coefficients),  Fig. 2 is symmetrical with respect to the horizontal plane defined by $a$ and $\Re(\lambda)$ axes. In this way, we can ""track"" the roots and understand in a finer way what happens for certain values of the parameter. Our understanding of Fig. 1 can be refined : see Appendix below. Fig. 2. ""Complexification"" of Fig. 1. In order to gain a better 3D perception, here is a chinese poetic interpretation : imagine the blue lines as borders of a lake connected by a red bridge with a leaning weeping willow trunk and their magenta reflections on the lake... Here is a second example (Fig. 3), associated with matrix : $$A=\left(\begin{array}{rrrr}0&  1&  0& \color{red}{-a}\\
 1& 0&  1&  0\\
0&  1& 0& 1\\
   \color{red}{a} & 0 & 1 & 0 \end{array}\right).$$ Fig. 3. I have willingly taken simple examples with at most first degree entries in parameter $a$ in order to demonstrate the interest of this approach. I have tried different cases, some of them with higher degrees. Representations analogous to Fig. 2 and Fig. 3 display, rather often, features with heuristical/pedagogical interest. Question : This representation is very likely to be found elsewhere and/or linked to a certain already developed theory (differential geometry, Galois theory...). Can somebody give me an answer or at least a track ? Remark : this representation is in fact very natural if one considers  ""level slices"" at $a$ = constant has the representation of the roots' position in the complex plane (see the comment of @Andrea Marino). Edit: another pretty example is displayed on Fig.4. Fig. 4. Interweaving of a family of cubic curves with its own copy, one in a horizontal plane, the other one in a vertical plane. It deals with the complex cubic equation under one of its standard forms (see the article by Milnor here ): $$z_2^2-z_1^3+z_1=t\tag{*}$$ where $$z_1=x_1+iy_1, z_2=x_2+iy_2 \in \mathbb{C}, t \in \mathbb{R}.$$ Let us consider the ""slice"" of this locus defined by $y_1=0$ Relationship (*) is equivalent in this case to the 2 equations $$\begin{cases}-x_1^3+x_1+x_2^2-y_2^2-t&=&0\\x_2y_2&=&0\end{cases}$$ Considering the two cases $x_2=0$ or $y_2=0$ , we get two cubic curves equations: $$\begin{cases}\text{if} \  y_2=0 : & -x_1^3+x_1-t=-x_2^2\\\text{if} \  x_2=0: & -x_1^3+x_1-t=y_2^2\end{cases}$$ represented in Fig. 4 wrt axes $x_1,x_2,y_2$ for different values of $t$ . We find here once again this connexion between horizontal and vertical branches. The bifurcation occurs when $ -x_1^3+x_1-t$ has a sign change. Besides, limit cases corresponding to double points occur when $t=\pm \frac{2 \sqrt{3}}{9}$ . Edit : Meanwhile, I have found some references: ""Coupling of eigenvalues of complex matrices at diabolic or exceptional points"" A.A. Mailybiev, O.N. Kirillov, A.P. Seyranian, https://arxiv.org/pdf/math-ph/0411024.pdf (to be found as well here ). See as well here . ""Complex Bifurcation from Real Paths""
by M. E. Henderson and H. B. Keller, SIAM J. Appl. Mat. Vol. 50, No. 2, pp. 460-482, April 1990, that can be uploaded here . And this special approach. . This one : Visualising Complex Polynomials A Parabola Is but a Drop in the Ocean of Quadratics, by H. Wiggins, A. Harding, J. Engelbrecht. I mention also ""Eigenvalue attraction"" by R. Movassagh ( https://arxiv.org/pdf/1404.4113.pdf ), with a different point of view. Appendix : A deeper understanding of Fig. 1: The two ""complex domain curves"" (red, and magenta for their complex conjugate parts) are on the right, a parabolic arc, thus planar, whereas, on the left, the ellipse-looking curve is not planar. Consider now the (blue) real components (the straight line, and the two curves of the horizontal plane); let us play a game of anticipation: for the straight line, we guess the presence of a root $\lambda=-2.$ for the two curves, it is natural to consider them together as having the same equation with a common horizontal asymptote for a certain value (of course never reached) of $\lambda$ .  Zooming, one can guess that this asymptote is characterized by $\lambda_{\infty}=2.5$ , Besides, a little observation makes evident a parabolic envelope ; gathering these observations, a possible equation for $a$ as a function of $\lambda$ is as follows : $$\tag{1}a = p\lambda^2+ q\lambda +r+\dfrac{s}{\lambda-2.5}.$$ for certain coefficients $p,q,r,s$ . It remains to check (1) by examining the factorization of the characteristic polynomial of $A$ and then its roots. Using a CAS, or by hand calculation, we obtain: $$\tag{2}\det(A-\lambda I)=(\lambda+2)P(\lambda) \ \ \ \ \text{with} \ \ \ \ P(\lambda):=\lambda^3+\lambda^2-8\lambda+2a \lambda+3-5a$$ Equating (2) to zero, we obtain $\lambda=-2$ , as awaited, or $P(\lambda)=0$ , which can be written in the following equivalent way : $$a=\dfrac{-\lambda^3-\lambda^2+8\lambda-3}{2 \lambda -5}$$ in full conformity with form (1).","['polynomials', 'reference-request', 'roots', 'bifurcation', 'differential-geometry']"
2611504,Finding a recursive relation from a differential equation.,"We consider the following differential equation: $$(1-x)\psi'(x) - 1 = 0$$
We then define:  $\psi(x) = \sum_{n = 0}^{\infty}a_nx^n$.(power series) Plugging it into the formula we get to this step: $$\sum_{n=0}^{\infty}a_nn(x^{n-1}-x^{n}) - 1= 0$$ How can we then identify the recursive relation between the summands thus determine $a_{n+1}$ ?","['recursion', 'summation', 'ordinary-differential-equations']"
2611513,Why is the quintic in $\mathbb{CP}^4$ simply connected?,"I am reading some notes on mirror symmetry that discusses Calabi-Yau manifolds, which are defined as compact, connected, simply connected Kähler manifold whose canonical bundle is trivial. The main example of a Calabi-Yau (and mirror pairs) is given by a smooth quintic in $\mathbb{P}^4$, i.e. a zero set of a degree $5$ homogeneous polynomial. However, I am having trouble understanding why this example must be a Calabi-Yau in our definition. Compactness seems okay, and it is Kähler as a smooth complex projective variety. Its first Chern class can be shown to be zero so the Calabi-Yau condition seems to hold too. What bugs me is the simply connected assumption. For the notes do not provide an explanation, I guess that it must be some easy argument or a general, well-known fact that such a variety must be simply connected. Can someone provide such an argument or a reference?","['algebraic-topology', 'complex-geometry', 'algebraic-geometry']"
2611524,EPIC sets in group theory,"The following is well known and easy to prove. If $G$ is a group and for all $x,y$ in $G$ we have $(xy)^2=x^2y^2$ , then $G$ is abelian. The following is fairly well known and fairly easy to prove. If $G$ is a group and $k$ is an integer and for all $x,y$ in $G$ we have $(xy)^k=x^ky^k$ and $(xy)^{k+1}=x^{k+1}y^{k+1}$ and $(xy)^{k+2}=x^{k+2}y^{k+2}$ , then $G$ is abelian. Definition .  Let $S$ be a set of integers such that the following is true. If $G$ is a group and for all $x,y$ in $G$ , all $n$ in $S$ we have $(xy)^n=x^ny^n$ , then $G$ is abelian. Then $S$ is called an Equality-of-Powers-Implies-Commutativity set, or an EPIC set for short. Problem .  Determine all EPIC sets. Examples . From above, $\{2\}$ is an EPIC set.  It's also easy to show that $\{-1\}$ is an EPIC set. From above, any set consisting of three consecutive integers is an EPIC set. If $k,m$ are coprime then $\{k,k+1,m,m+1\}$ is an EPIC set.  This is a generalisation of the previous example. It's clear that if $S$ is an EPIC set and $S\subseteq T$ , then $T$ is an EPIC set.  So we may as well just look for minimal EPIC sets.",['group-theory']
2611530,Number of different k-coloring of an $n\times m$ grid up to rows and columns permutations,"To be more precise, consider $X=Mat(n,m;\mathbb{Z}_k)$ to be the set of $n\times m$ matrices with coefficients in $\mathbb{Z}_k$. Let $G=S_n\times S_m$ act on $X$ by permuting the $n$ rows and the $m$ columns. I want to know the cardinality of the set of the orbits $|X/G|$. I know that by Burnside's Lemma the following hold
$$|X/G|=\frac{1}{|G|}\sum\limits_{g\in G}|X^g|$$ where $X^g=\{x\in X\mid gx=x\}$, but I don't know how to compute $|X^g|$ for a general $g\in G$. Any help would be appreciated.","['group-actions', 'combinatorics', 'discrete-mathematics']"
2611585,Can one apply LHopitals' rule to differentiable functions defined over the naturals?,"For e.g, if we have $\lim_{n \rightarrow \infty} \frac {f(n)}{g(n)}$= $\frac 00$, $f:\mathbb {R} \rightarrow \mathbb {R}$ and $g:\mathbb {R} \rightarrow \mathbb {R}$ (note that $f$,$g$ are defined on $R$ so the derivative makes sense)  so in essence, we're considering sequences.","['derivatives', 'real-analysis', 'indeterminate-forms', 'calculus']"
2611736,"How to compute group cohomology $H^2_\sigma(\mathbb{Z}\times \mathbb{Z}, \mathbb{Z}_2\times \mathbb{Z}_2)$ with nontrivial $G$-module","How to compute group cohomology $H^2_\sigma(\mathbb{Z}\times \mathbb{Z}, \mathbb{Z}_2\times \mathbb{Z}_2)$ with nontrivial group action $\sigma$. $$\mathbb{Z}\times \mathbb{Z}= \langle a,b| a b =ba\rangle$$
$$\mathbb{Z}_2\times \mathbb{Z}_2= \langle c,d| c^2=1=d^2,c d =dc\rangle$$ If I require the group action is $\sigma(a): c\rightarrow d$, $\sigma(a): d\rightarrow c$, $\sigma(b): c\rightarrow d$, $\sigma(b): d\rightarrow c$ My questions: how to compute group cohomology $H^2_\sigma(\mathbb{Z}\times \mathbb{Z}, \mathbb{Z}_2\times \mathbb{Z}_2)$? What's the group  $(\mathbb{Z}_2\times \mathbb{Z}_2) \rtimes_\sigma (\mathbb{Z}\times \mathbb{Z} )$ ?","['group-cohomology', 'homological-algebra', 'group-theory', 'gap']"
2611746,Prove that the two sums involving $\tau$ are equal.,"Question: Prove that $\displaystyle \sum_{d|n} \tau ^3 (d) = \left( \sum _{d |n} \tau (d) \right)^2$. (Hint: First show that both sides are multiplicative functions.) [$\tau$ is the number of positive divisors of the input.] Attempt: LHS: $\tau$ multiplicative $\implies$ $\tau ^3$ multiplicative $\implies$ $\displaystyle \sum_{d|n} \tau ^3 (d)$ multiplicative. RHS: $\tau$ multiplicative $\implies$ $\displaystyle \sum_{d|n} \tau (d)$ multiplicative $\implies$ $\left( \sum _{d |n} \tau (d) \right)^2$ multiplicative. This is where I do not know how to proceed. I think it suffices to show that $\displaystyle \sum_{d|p^e} \tau ^3 (d) = \left( \sum _{d |p^e} \tau (d) \right)^2$. Is this the right step? If so, how would I continue this? EDIT: I have tried continuing the problem with Shark's suggestion. I will post it below: Note that $\tau (p^k) = k+1$ and $\tau ^3 (p^k) = (k+1)^3$. It suffices just to prove the identity for $n=p^k$ a prime power. $$\left(\sum_{d\mid p^k}\tau(d)\right)^2=\left(\sum_{j=0}^k\tau(p^j)\right)^2=\left(\sum_{j=0}^k(j+1)\right)^2$$ $$\sum_{d\mid p^k}\tau(d)^3=\sum_{j=0}^k\tau(p^j)^3=\sum_{j=0}^k(j+1)^3$$. After some algebra, $\text{LHS} = \frac{1}{4}(k^4 + 6k^3 + 13k^2 + 12k + 4) = \frac{1}{4}(k^4 + 6k^3 + 13k^2 + 12k + 4) = \text{ RHS}$, which finishes the proof. Some properties involving $\tau :$ $\displaystyle \tau (n) = \sum_{d|n} 1$. $\tau (p^e) = e+1$. $\tau$ is multiplicative. If $f$ is multiplicative then $\displaystyle F(n) = \sum_{d|n} f(d)$. If $f$ is multiplicative and $n = p_1^{e_1} \cdots p_r^{e_r} $ then $f(n) = f(p_1^{e_1} \cdots p_r^{e_r}) = f(p_1^{e_1})\cdots f(p_r^{e_r})$",['number-theory']
2611748,Generalization of chain rule to tensors,"Are there any generalization of chain rule of differentiation to tensors? For example, how can I differentiate f(g(X)) where:
$g: Matrix(d_1, d_2) \to Matrix(d_3, d_4)$ and $f: Matrix(d_3, d_4) \to Matrix (d_5, d_6)$. P.S. I understand how to compute derivative, I want a rule which takes a tensor derivative of f and a tensor derivative of g and combines them in a short step.","['matrices', 'tensors', 'multivariable-calculus']"
2611822,Finding all outer measures on a finite set,"I have to find all the outer measure on a set $X$ with a finite number of elements. I can find a family of functions that satisfy the outer measure definition, however how can I be sure that is are all the outer measures we can have on such a set? Or in general, once we have found a number of outer measures, how do we make sure these are all the possible ones?","['outer-measure', 'real-analysis', 'measure-theory']"
2611835,Proving $(Î»^d + (1-Î»^d)e^{(d-1)s})^{\frac{1}{1-d}}\leq\sum\limits_{n=0}^\infty\frac1{n!}Î»^{\frac{(d^n-1)d}{d-1}+n}s^ne^{-Î»s}$,"Question Let $\lambda \in (0,1), s \in (0,\infty), d \in \{2,3,\dots\}$ and show that in this case the following inequality holds:
$$(\lambda^d + (1-\lambda^d) e^{(d-1)s})^{\frac{1}{1-d}} \leq \sum_{n=0}^\infty \frac{\lambda^{\frac{(d^n-1)d}{d-1}+n}s^n}{n!} e^{-\lambda s},$$ Thoughts My first intuition was to try and write the left hand side as some taylor series but this seems like a bad idea as the only part to write as a Taylor series is $e^{(d-1)s}$ and if we ""ignore"" the $\lambda^d$ this part is what gives $e^{-s}$ which is bounded by $e^{-\lambda s}$. Maybe there is some formula for a convex expression of the form $\lambda^d a + (1-\lambda^d) b$ which can be used here? Applying convexity I can write the right hand side as $e^{-(1-\lambda^d)s}$ which, unfortunately, is not smaller than the right hand side (for large values of $s$ the inequality fails, which is logical as convecity inequality is increasingly inaccurate as $s$ increases). I might be able to show it using the Taylor expansion of $f(x) := \frac{1}{(1+x)^{1/n}}$ as I can write the right hand side as:
$$
(1 + (1-\lambda^d) (e^{(d-1)s}-1))^{1/(1-d)},
$$
for this I can take the taylor series at $0$ for $|x|=|(1-\lambda^d) (e^{(d-1)s}-1)| < 1$ and at $\infty$ for $|x| > 1$. It seems to me that I need something like the binomial approximation but for large values of $x$ rather than small values of $x$. Promising technique I can write the left hand side as 
$$e^{-s} (1 + \lambda^d (e^{(1-d)s} - 1))^{1/(1-d)}$$
as $|\lambda^d (1-e^{(1-d)s})| < 1$ we can use the Taylor expansion of $1/(1+x)$ at $0$. This allows us to reduce the inequality to showing:
$$
e^{-s} \sum_{n=0}^{\infty} \frac{1}{n!} \frac{\Gamma(1 - 1/(d-1))}{\Gamma(1 - 1/(d-1) - n)} \cdot \lambda^{nd} (e^{(1-d)s}-1)^n
\leq 
\sum_{n=0}^{\infty} \frac{\lambda^{((d^n-1)d)/(d-1)+n}s^n}{n!}e^{-\lambda s}.
$$
The separate terms in the sum on the right hand side drops to zero much faster than the sum on the left hand side, but the first couple of terms of the right hand side are a lot larger than those on the left hand side. It seems to me that this corresponds to the fact that the Taylor series on the left hand side converges very slowly to the function, maybe we can take a better Taylor series which converges faster.","['real-analysis', 'inequality', 'calculus', 'summation', 'upper-lower-bounds']"
2611902,Conic in projective plane isomorphic to projective line,"I've got to show that any irreducible conic in $\mathbb{P^2(\mathbb{K})}$ where $\mathbb{K}$ is algebraically closed is isomorphic as a quasiprojective variety to the projective line.
I wrote the conic as equivalent to the zero locus of $ x^2 +y^2+z^2$ in $\mathbb{P^2(\mathbb{K})}$. I tried to use the standard affine charts to cover this simpler variety and parametrize it but i didn't manage to do that.
What am i missing?","['algebraic-curves', 'projective-geometry', 'algebraic-geometry']"
2611912,Show that the statistic $T(X)$ is complete.,"Exercise: Let $X_1,\ldots,X_n$ be a sample from the distribution with density $$f(x|\theta) = \dfrac{2x}{\theta^2}\mathbb{1}_{(0,\theta)}(x)$$ w.r.t. the Lebesgue measure. Show that the statistic $T(X) = \max(X_1,\ldots,X_n)$ is complete. What I've tried: I know that a statistic $T$ is said to be complete for $\theta\in\Omega$ if for any Borel function $f$, $\operatorname{E}_\theta f(T) = 0$ for all $P_\theta \in \Omega$, implies that $f(T)=0$, $P_\theta$-a.s. for all $\theta$. So what I want to do is take $\operatorname{E}_\theta f(T)$ and show that this is only equal to zero when $f(T) = 0$. If I'm correct, that means that I need to show that $$\displaystyle\int f(T(X))\dfrac{2x}{\theta^2}\mathbb{1}_{(0,\theta)}(x)dx = 0$$ implies $f(T(X)) = 0$. I'm not sure how to proceed from here though. Question: How do I solve this exercise? Thanks in advance!","['statistics', 'statistical-inference', 'probability-distributions']"
2611960,Find the greatest and least values of $(\sin^{-1}x)^2+(\cos^{-1}x)^2$,"Find the upper and lower limit of $$
(\sin^{-1}x)^2+(\cos^{-1}x)^2
$$ My Attempt: $$
\frac{-\pi}{2}\leq\sin^{-1}x\leq \frac{\pi}{2}\quad\&\quad0\leq\cos^{-1}x\leq\pi\\(\sin^{-1}x)^2\leq\frac{\pi^2}{4}\quad\&\quad(\cos^{-1}x)^2\leq\pi^2\\
0\leq(\sin^{-1}x)^2+(\cos^{-1}x)^2\leq\frac{\pi^2}{4}+\pi^2=\frac{5\pi^2}{4}
$$ Here, I can see the upper limit is $\frac{5\pi^2}{4}$ which is fine. But, $0$ is one lower limit not the lower limit. Why am I not getting the lower limit in my approach ? How do I approach similar problems involving max and min, when you don't get the lower or upper limits ?","['optimization', 'trigonometry', 'cauchy-schwarz-inequality', 'inverse-function', 'maxima-minima']"
2611974,How to evaluate $\lim_{x\rightarrow 0^-} \sec^{-1}(1+x)$?,"How to do the following $$\lim_{x\rightarrow 0^-} \sec^{-1}(1+x)$$ I am confused that it seems now $(1+x)<1$ when $x\rightarrow 0^-$, which is not valid for the domain of $\sec^{-1}$. Can anyone give me kick on this?","['trigonometry', 'limits']"
2611996,Mean and variance of a scaled Poisson random variable,"Suppose I have a variable, $Y$, that is a scaled Poisson random variable. That is: $$ Y = kX $$ and $$ X \sim \mathrm{Poisson}(\mu) $$ This means that PMF of $Y$, $P(y)$, is given by: $$ P(y) = e^{-\mu} \frac{\mu^{\frac{y}{k}}}{\left(\frac{y}{k}\right)!} $$ What would the mean and variance of $Y$ be in this situation? (Of course, the mean and variance of $X$ is just $\mu$.)","['statistics', 'poisson-distribution']"
2612080,How to prove this Dirac delta limit representation is correct?,"According to the 7th representation in this site : $$\lim_{M\to \infty} \frac{1}{2\pi\sin(\omega/2)}\sin\left(\omega\left(M+\frac12\right)\right) = \delta(\omega)$$ I'm trying to understand why this is true. I haven't been able to find anything on the Internet. I must state that I have a very shallow knowledge about distribution theory, so the simpler the explanation, the better. If there is no way to show why that limit is correct without using complicated arguments, go ahead anyway, I'll try to follow up.","['dirac-delta', 'proof-writing', 'distribution-theory', 'limits']"
2612084,Bound on the derivatives of heat kernel.,"Let the heat kernel $\Phi:\Bbb R^n\times (0,\infty)$ be defined as
$$
\Phi(x,y):=\frac 1{(4\pi t)^{n/2}}e^{-\frac{|x|^2}{4t}}.
$$ From calculation, I have a feeling the the following should be true: $$
|\nabla^k \Phi(x,t)|\le \frac {C(n,k)}{t^{k/2}} \left( 1+\frac{|x|^2}t \right)^{k/2} \Phi(x,t).
$$ At least for even  $k$ this seems to be the case. Is this estimate well-known? Is it even true? I'm trying to prove this but induction seems painful to me (or maybe I'm just bad at calculation). If it is true does anyone have a nice proof of it? A hint is also appreciated.","['real-analysis', 'partial-differential-equations', 'heat-equation', 'complex-analysis', 'ordinary-differential-equations']"
2612101,Conditions on a Lipschitz function $f:U\subset \Bbb R^m\to \Bbb R^n$ which guarantees differentiability at a point $a\in U$,"Let $f:U\to \Bbb R^n$ be Lipschitz in the open $U\subset \Bbb R^m$. Given $a\in U$, suppose that, for all $v\in \Bbb R^m$, there exists the directional derivative $\dfrac{\partial f}{\partial v}(a)$ and it depends linearly on $v$. Prove that, for all path $g:(-\epsilon,\epsilon)\to U$, with $g(0)=a$, differentiable in $t=0$, there exists the velocity vector $(f\circ g)'(0)$. Conclude that $f$ is differentiable in the point $a$. I was able to show the existence of such $(f\circ g)'(0)$'s (in the proof I didn't use the linearity of the directional derivatives), however, I couldn't do the final conclusion. I can define $T:\Bbb R^m\to \Bbb R^n$ as
$$T(v)=\dfrac{\partial f}{\partial v}(a)$$
which is linear, by hypothesis. I wished that $T=f'(a)$, that is, I need to show that
$$\lim_{h\to 0} \dfrac{r(h)}{|h|}=0$$
with $r(h)=f(a+h)-f(a)-T\cdot h=f(a+h)-f(a)-\dfrac{\partial f}{\partial h}(a)$, but I don't know how to work with this $\dfrac{}{\partial h}$ when $h\to 0$...","['multivariable-calculus', 'derivatives', 'calculus', 'analysis']"
2612134,explicit description of eigenvector of a rotation,"One of the exercise in Artin's algebra gives an eigenvector of an element of $SO(3)$, in one possible case. Namely, it is asked to show that If $A=[a_{ij}]$ is a rotation in $SO(3)$, then the vector 
  $$v=\begin{bmatrix} (a_{23}+a_{32})^{-1}\\ (a_{13}+a_{31})^{-1} \\ (a_{12}+a_{21})^{-1}\end{bmatrix}$$
  is an eigenvector of $A$, whenever these entries of the vector are well-defined in $\mathbb{R}$. I couldn't get any way to proceed to prove this. What I tried was, consider $A$ as sum of symmetric and skew-symmetric- $\frac{1}{2}(A+A^t)+\frac{1}{2}(A-A^t)$ and show that $v$ is an eigenvector of both with eigenvalues $1$ and $0$ respectively; but, this was not working beyond long algebraic/symbolic computations. Any hint for this?","['eigenvalues-eigenvectors', 'rotations', 'matrices', 'abstract-algebra', 'linear-algebra']"
2612141,Solve $ \int_\frac{-π}{3}^{\frac{π}{3}}\frac{\cos^2(x)-\sin^2(x)}{\cos^2(x)}dx$,"I came across this question in my textbook and have been trying to solve it for a while but I seem to have made a mistake somewhere. $$ \int_\frac{-π}{3}^{\frac{π}{3}}\frac{\cos^2(x)-\sin^2(x)}{\cos^2(x)}dx$$ and here is what I did. First I simplified the equation as $$ \int_\frac{-π}{3}^{\frac{π}{3}}(1-\tan^2(x))dx=x|_{\frac{-π}{3}}^{\frac{π}{3}}-\int_\frac{-π}{3}^{\frac{π}{3}}(\tan^2(x))dx$$ Then I simplified $\tan^2(x)\equiv\frac{\sin^2(x)}{\cos^2(x)}, \sin^2(x)\equiv1-\cos^2(x)$ so it becomes,  $\tan^2(x)\equiv\frac{1-\cos^2(x)}{\cos^2(x)}=\frac{1}{\cos^2(x)}-1$ making the overall integral $$\int_\frac{-π}{3}^{\frac{π}{3}}(1-\tan^2(x))dx=x|_{\frac{-π}{3}}^{\frac{π}{3}}-\int_\frac{-π}{3}^{\frac{π}{3}}(\frac{1}{\cos^2(x)}-1)dx$$
$$=x|_{\frac{-π}{3}}^{\frac{π}{3}}-\int_\frac{-π}{3}^{\frac{π}{3}}\frac{1}{\cos^2(x)}dx-\int_\frac{-π}{3}^{\frac{π}{3}}1dx=x|_{\frac{-π}{3}}^{\frac{π}{3}}-x|_{\frac{-π}{3}}^{\frac{π}{3}}-\int_\frac{-π}{3}^{\frac{π}{3}}\frac{1}{\cos^2(x)}dx$$
I know that $\int\frac{1}{\cos^2(x)}dx=\tan(x)+c$ but that's off by heart and not because I can work it out. Since $x|_{\frac{-π}{3}}^{\frac{π}{3}}-x|_{\frac{-π}{3}}^{\frac{π}{3}}=0$, the final equation becomes 
$$\int_\frac{-π}{3}^{\frac{π}{3}}\frac{\cos^2(x)-\sin^2(x)}{\cos^2(x)}dx=\tan(x)|_{\frac{-π}{3}}^{\frac{π}{3}}=2 \sqrt3$$ Is what I did correct because I feel like I've made a mistake somewhere but can't find it. Also why does $\int\frac{1}{\cos^2(x)}dx=\tan(x)+c$. EDIT - Made an error in $\int\frac{1}{\cos^2(x)}dx=\tan^2(x)+c$, it's actually $\int\frac{1}{\cos^2(x)}dx=\tan(x)+c$.","['definite-integrals', 'integration', 'trigonometry', 'calculus']"
2612149,"Example function which is partial, injective, and surjective","Can somebody give an example of a function $f : \mathbb{N} → \mathbb{N}$ which is partial, injective, and surjective.  I was thinking about $f(x)=x-1$, but I am not sure if it is surjective.","['partial-functions', 'elementary-set-theory', 'discrete-mathematics']"
2612157,Relation between profinite abelian groups and $\hat{\Bbb{Z}}$ modules,"Suppose we have a profinite abelian group $A$, then we can define a $\hat{\Bbb{Z}}$-module structure on $A$. However, not every $\hat{\Bbb{Z}}$-module is a profinite group, as one can see for example with $\Bbb Q/\Bbb Z$. So my question is, what is the relation between profinite abelian groups and $\hat{\Bbb{Z}}$-modules? Since this question is quite vague, here are some more precise questions: If we have two profinte abelian groups $A$ and $B$ and a homomorphism of abstract groups $f:A \to B$ is there some relation between the continuity of $f$ and the $\hat{\Bbb{Z}}$-linearity? Does the $\hat{\Bbb{Z}}$-module structure on a profinite abelian group determine its topology? Given a $\hat{\Bbb{Z}}$-module $A$ is there some non-obvious criterion that decides whether the $\hat{\Bbb{Z}}$-module structure comes from a profinite topology on $A$?","['abelian-groups', 'modules', 'profinite-groups', 'group-theory']"
2612239,"How is the covariant derivative of a metric, $\nabla g$, defined?","The Levi-Civita Connection $\nabla$ on a Riemannian manifold $(M,g)$ , satisfies the equation $$ X(g(Y,Z))=g(\nabla_X Y,Z)+g(Y,\nabla_X Z) $$ where $X,Y,Z$ are vector fields on $M$ . It might be a ridiculous question, but I do not understand in what way we say that $\nabla g=0$ , if the arguments of $\nabla$ are vector fields, and $g$ can be viewed either as a 2-tensor or as a real-valued function $g_{X,Y}(p)=g|_p(X(p),Y(p))$ .","['connections', 'riemannian-geometry', 'differential-geometry']"
2612281,When does $\lim_{n\to\infty}f(x+\frac{1}{n})=f(x)$ a.e. fail,"We know that if $f\in L^1(\mathbb{R})$, then $\|f(\cdot+1/n)-f(\cdot)\|_{L^1}\to 0$ as $n\to \infty$, which implies that there exists a subsequence $f_{n_k}=f(x+\frac{1}{n_k})$ such that $f_{n_k}\to f$ a.e. My problem is that Is there any $f\in L^1(\mathbb{R})$  function such that the almost convergence result 
$$
f(x)=\lim_{n\to\infty}f(x+1/n)\quad \text{a.e.}
$$ 
is NOT valid? I intend to believe that there exits such function. Otherwise, there would be a beautiful statement such that $f(x)=\lim_{n\to\infty}f(x+1/n)$ a.e. for any $f\in L^1(\mathbb{R})$. Thank you for the long commenting below @David C. Ullrich. This question has been reduce to find a compact set $K$ such that for any $x\in K$, there are infinite $n$ such that $x+\frac{1}{n}\not\in K$.","['harmonic-analysis', 'real-analysis', 'lebesgue-measure', 'measure-theory']"
2612292,$\lim_{n\to \infty} {1\over n}\sqrt[n]{(n+1)(n+2)\cdots(2n)}$ [duplicate],"This question already has answers here : How to prove that $\lim \frac{1}{n} \sqrt[n]{(n+1)(n+2)... 2n} = \frac{4}{e}$ (5 answers) Closed 6 years ago . $$\lim_{n\to \infty} {1\over n}\sqrt[n]{(n+1)(n+2)\cdots(2n)}$$ My attempt: \begin{align}
\lim_{n\to \infty} {1/ n}\sqrt[n]{(n+1)(n+2)\cdots(2n)} &= \lim_{n\to \infty} \sqrt[n]{(1+{1/ n})(1+{2/ n})\cdots(1+{n/ n})}\\
 &= \lim_{n\to \infty}(1+{1/ n})^{n*{1/ n^2}}(1+{2/ n})^{n*{1/ n^2}}\cdots(1+{n/ n})^{n*{1/ n^2}}\\
 &=\lim_{n\to \infty}e^{{1/ n^2}}e^{{2/ n^2}}\cdots e^{{n/ n^2}}\\
  &= \sqrt{e}
\end{align} I know that this is wrong answer. Could you please show me where my mistake is? EDIT I know the right solution, I just wanted to see where my mistake is. Thanks for your answers anyway! EDIT 2 5 beautiful answers received already, but I dont think I can accept any of them, because my question was to show mistake in my own derivations. Anyway I learnt a lot especially that $\lim_{n\to \infty} \frac{b_{n+1}}{b_n}=\lim_{n\to \infty} \sqrt[n]b_n$. Thanks for everyone!","['real-analysis', 'limits', 'definite-integrals', 'sequences-and-series', 'analysis']"
2612306,How to determine the integration boundaries of the following double integral?,"Calculate the following double integral: $\int\limits$$\int\limits_T$  $[xsen(x) + ysen(x+y)]$ $dxdy$ Where the region $T$ is the triangle of vertices $(1,0)$, $(0,1)$ y $(3,3)$. To could determine the boundaries of the integral  I did the following: I made a graph of the triangle I found the equations that describe the three lines of the triangle: The one which goes from $(0,1)$ to  $(3,3)$ is $y=2/3x+1$ The one which goes from $(0,1)$ to  $(1,0)$ is $y=-x+1$ The one which goes from $(1,0)$ to  $(3,3)$ is $y=3/2x-3/2$ Now, I'm stuck from here. I don't know how to establish the boundaries for $x$ and $y$ given the restriction named $T$. Any hint?","['calculus', 'algebra-precalculus', 'multivariable-calculus', 'integration', 'definite-integrals']"
2612319,There is no such regular polyhedron whose volume is equal to the difference between the volumes of its circumsphere and its insphere,"Based on my previous two questions ( here and here ) I found it safe to conjecture that: There is no such regular polyhedra whose volume is equal to the difference between the volumes of its circumsphere and its insphere. Now this should be pretty much straightforward to prove (or disprove) as there are only $5$ regular polyhedra. I have verified it myself for the cube but the others seem to be a bit too daunting, especially the icosahedron and the dodecahedron. I assume that the inspheres and circumspheres of the $5$ platonic solids are concentric spheres and it was true for the cube but that is as far as I have been able to go. My imaginative powers are incredibly weak and I would probably slap my head once I see how the parts of the proof involving the icosahedron and the dodecahedron are done. By the way, is it necessary to try out all $5$ platonic solids or can it be proved by showing that the $n$ (denoting number of edges) required for this to be true is not a positive integer? Thanks in advance! Bonus: I am almost sure that one or the other irregular polyhedra will not obey this conjecture (pardon my terminology if it is wrong). Can anyone find (at least) one such polyhedron? Rules: $(1)$ The circumsphere must pass through all the vertices of the polyhedron. $(2)$ The insphere must be tangent to all the faces of the polyhedron. $(3)$ The polyhedron can not be a spherical polyhedron. I personally believe that a truncated pyramid will suffice easily. Can anyone find other counter-examples?  Good luck!",['geometry']
2612363,Cohomological Interpretation of Modular Forms on a Modular Curve,"I'm currently taking a class on modular forms, and I'm doing a presentation on how you can write the space of modular forms with coefficients in a $K$-algebra $A$ as the group cohomology ring $H^{1}(\operatorname{SL}_{2}(\mathbb{Z}),\Omega^1_{A/K})$ where $\Omega^1_{A/K}$ is the space of Kähler $K$-differentials on $A$. However, I cannot seem to find any references for this fact, and I was just wondering if anyone knew of any references where I can find this fact, or places where I can find stuff related to this? Thanks in advance!","['homology-cohomology', 'algebraic-geometry', 'reference-request', 'modular-forms', 'group-cohomology']"
2612424,Evaluating the improper double integral $\int_{D} \frac{dxdy}{\sqrt{1-a\cdot x-b\cdot y}}$,"I'm given the following improper integral: $\int_{D} \frac{dxdy}{\sqrt{1-a\cdot x-b\cdot y}}$ where $D$ is the open unit disk, assuming $a^2 + b^2 = 1$. I should decide whether it converges or not, and if it does, I should find the limit. I've found that the integrand is well defined on $D$ (using Cauchy-Schwarz lemma) and by using this lemma I was able to upper-bound the integral by another and show that it converges. However, I cannot evaluate this integral, i.e. find its exact value. I'm quite sure I should integrate by substitution, but it is just not working... How can I do it? Thanks in advance!","['multivariable-calculus', 'multiple-integral', 'improper-integrals', 'integration']"
2612446,Does $\sum\limits_{n=1}^\infty\frac{1}{n^2}(a_1+\cdots+ a_n)$ converges when $a_n$ converges?,"Let $(a_n)_{n\in\mathbb{N}}\subseteq \mathbb{R}_{>0}$ be a convergent sequence.
  Is $$\sum\limits_{n=1}^\infty\frac{1}{n^2}(a_1+\cdots+ a_n)$$ convergent? I don't know if this is correct or not and tried to find a counterexample so far, unsuccessfully, but I think it doesn't converge in general. If one can choose $(a_n)_n$ as in this question Prove $a_1+\cdots+a_n=\dfrac{(a_1+a_n)n}{2}$ inductively. , then $\sum\limits_{n=1}^\infty\frac{1}{n^2}(a_1+\cdots+ a_n)$ does not converge  due to the divergence of the harmonic series. But I would like to have a more concrete counterexample. I am happy about any hint and help. Thank you","['real-analysis', 'sequences-and-series', 'calculus', 'algebra-precalculus', 'convergence-divergence']"
2612461,A Problem on Beta distribution .,"In this problem i know that $X\sim B(m,n)$ and $(1-X)\sim B(n,m)$
After putting values in $Y_i$ i got this $\dfrac{x^2}{1-x^2}$  I have not idea what do further . I am confused.","['statistics', 'probability', 'probability-distributions']"
2612523,Does sheafification preserve surjectivity?,"Let $\mathcal{F}$ and $\mathcal{G}$ be presheaves over a topological space X and $f$ be a surjective morphism of presheaves, meaning for every open subset $U\subset X$ the homomorphism $\mathcal{F}(U)\to\mathcal{G}(U)$ is surjective. Then we know there is corresponding sheaf morphism of the sheafifications $f^{+}: \mathcal{F}^+\to \mathcal{G}^+$ and $f^+$ is surjective morphism of sheaves, i.e. surjective of every stalk. My question is whether $f^{+}$ is surjective in the sense of presheaves, i.e. whether for every open subset $U\subset X$, whether $\mathcal{F}^+(U)\to\mathcal{G}^+(U)$ is still surjective. I cannot prove it and my guess is not but I couldn't figure out a counterexample. The question partly come from the feather that injectivity (as presheaves) is preserved after sheafification so how about surjectivity. Any help is appreciated. Thanks! PS: First time posting a question so welcome to pointing out any mistake or improperness in format!","['sheaf-theory', 'algebraic-geometry']"
2612561,"Prove that $(X \setminus Y)\cap Z=Z \setminus(Y \cap Z)$ where $Y,Z$ are subsets of $X$.","The problem I am given is: Let $Y$ and $Z$ be subsets of $X$. Prove that $(X \setminus Y)\cap Z=Z \setminus(Y \cap Z)$ Things I have tried: Drew pictures. Looked up how to show set equality and it said the standard way is to show that each side is a subset of the other. The source I have been using is: https://www.people.vcu.edu/~rhammack/BookOfProof/SetProofs.pdf Proof: We must show that: $(X \setminus Y)\cap Z \subset Z \setminus(Y \cap Z)$ $Z \setminus(Y \cap Z) \subset (X \setminus Y)\cap Z$ First, showing that $(X \setminus Y)\cap Z \subset Z \setminus(Y \cap Z)$: Suppose $x \in \left( (X \setminus Y) \cap Z\right)$. Then $x \in X, x \notin Y, $ and $x \in Z$. (This is where I get stuck. Not sure what to do next.)",['elementary-set-theory']
2612598,What's the probability that at least one passenger gets no seat?,"Two airplane companies respectively use one airplane (to go from
  country A to country B). There are in total $1000$ people randomly
  choose the airplane, respectively with probability $\frac{1}{2}$. The company offers planes with $510$ seats for passengers. What's the
  probability that at least one passenger gets no seat? I think theorem of De Moivre Laplace is good to use here: First of we have $P(X \geq 510 +1) = p$ Then $$\lim_{n \rightarrow \infty}\mathbb{P}\left(\frac{X-np}{\sqrt{np(1-p)}}\leq x\right) = \Phi(x)$$ $$P(X \geq 510+1) = 1-P(X \leq 510) = 1-\mathbb{P}\left(\frac{X-np}{\sqrt{np(1-p)}} \leq \frac{510}{\sqrt{1000 \cdot \frac{1}{2}(1-\frac{1}{2})}}\right)  \\ = 1-\mathbb{P}\left(\frac{X-np}{\sqrt{np(1-p)}} \leq \frac{510}{5\sqrt{10}}\right) \approx 1-\Phi\left(\frac{510}{5\sqrt{10}}\right) \leq p$$ But from here I don't know how continue and if correct till here? I need read value from table but I don't know how and find it for this high value?","['statistics', 'probability-distributions', 'probability', 'discrete-mathematics']"
2612655,"If $\sum\limits_{i=1}^na_i=\prod\limits_{i=1}^na_i$ for every $n$, identify $\lim\limits_{n\to \infty}a_n$","Let $\left(a_n\right)_{n \in\mathbb{N}} $ denote a sequence of real numbers such that, for every $n\geqslant1$, $$\sum_{i=1}^na_i=\prod_{i=1}^na_i$$ Identify the limit $$\lim_{n\to \infty}a_n$$ What I have done: $$a_1-a_1=0 \\a_1+a_2-(a_1a_2)=0 \to  a_1\cdot a_2(\dfrac{a_1}{a_2}+\dfrac{a_2}{a_1}-1)=0\\.\\.\\.\\a_1\cdot a_2\cdot \cdot \cdot a_n(\dfrac{a_1}{a_2\cdot \cdot \cdot a_n}+\dfrac{a_2}{a_1\cdot \cdot \cdot a_n}+...+\dfrac{a_n}{a_2\cdot \cdot \cdot a_{n-1}}-1)=0$$
Now what do I do ?",['sequences-and-series']
2612688,A discrete problem about coordinates or angle?,Suppose there are two straight lines. We call one of them line $a$ and another one line $b$ and they make a $60$ degree angle. Now we start from one point on $b$ and draw a line from that point to line $a$; we let this line be $d$ units long. Now from that new point on line $a$ we draw it back to line $b$ with the same distance $d$(can't take the same path that is used to come to the point). Now continue this process until we get back to the original point. A diagram of how it is done is shown below:( p0 is the original point) Prove or disprove: no matter where we start on line $b$ we will get back to the original point. So I have tried to use trigonometry to bash out the coordinates but it quickly turns to hard and complicated to advance. I am just really confused where to start this off. Some hints will be appreciated. Thank you!,"['angle', 'trigonometry', 'analytic-geometry']"
2612698,What is the number of ways to put 40 identical balls in 6 boxes while no box contains more than 14 balls.,"I believe that I have to use the Inclusion–exclusion principle but I am not sure how. I tried to use this formula: $\binom{n+k-1}{n-1}$ for every step of the inclusion–exclusion solution but it didn't work out. 
Thank you!!","['combinatorics', 'discrete-mathematics']"
2612707,Three touching circles inscribed in a rectangle,"'Three equal circles, with radius r, are inscribed in a rectangle in a way that all three of them touch each other only once. Find the area of rectangle.' The thing i can't understand is that the arrangement of circles seem limitless to me,  do they need to be touching the sides of the rectangle or not ?","['circles', 'rectangles', 'geometry']"
2612732,"The kernel of Veronese Embedding $\phi: k[w,x,y,z]\to k[a^3,a^2b,ab^2,b^3]$ is $(wz−xy, wy−x^2, xz−y^2)$.","I want to rigorously prove the kernel of Veronese Embedding $\phi: k[w,x,y,z]\to k[a^3,a^2b,ab^2,b^3]$, where $w \mapsto a^3$, $x \mapsto a^2b$, $y \mapsto ab^2$, $z \mapsto b^3$, is the ideal $I=(wz−xy, wy−x^2, xz−y^2)$. Clearly $I\subset \operatorname{ker}\phi$. But I can't figure out the opposite containment. There must be some tricks that I am not familiar with.","['abstract-algebra', 'polynomials', 'algebraic-geometry']"
2612791,"Show that there is a unique polynomial of degree at most $2n+1$ such that $q^{[k]}(x_1)=a_k,$ $q^{[k]}(x_2)=b_k$ for $k=0, \dots, n$.","Let $x_1, x_2 \in \mathbb R$ and let $(a_0, a_1, \dots, a_n), (b_0, b_1, \dots, b_n)$ be $(n+1)$-tuples of real numbers. Show that there is a unique polynomial of degree at most $2n+1$ such that $$q^{[k]}(x_1)=a_k,$$$$q^{[k]}(x_2)=b_k$$ for $k=0, \dots, n$. Any hints on how to get started with this exercise?","['real-analysis', 'polynomials', 'interpolation', 'calculus', 'analysis']"
2612795,4-point-like central finite difference for second partial derivatives,"To numerically approximate the second partial derivatives, and get the Hessian matrix, one may use ""2-point"" central finite difference formulas:
$$H_{xy}(x,y) \approx \frac{f(x+h,y+h)-f(x+h,y-h)-f(x-h,y+h)+f(x-h,y-h)}{4h^2}\tag{1}$$
for the off-diagonal elements, and
$$H_{xx}(x,y) \approx \frac{f(x+h,y)-2f(x,y)+f(x-h,y)}{h^2}\tag{2}$$
formulas for the diagonal elements. (I am simplifying here, this generalizes for any number of dimensions, and uses the same displacement for all variables) It may be sometimes desirable to further improve the accuracy of these central difference formulas. For univariate functions this is conveniently done via the 4-point formula (aka. 5-point stencil in one dimension):
$$f''(x)     \approx \frac{-f(x+2 h)+16 f(x+h)-30 f(x) + 16 f(x-h) - f(x-2h)}{12 h^2}$$ However, I have been unable the find the ""4-point"" equivalent of $(1)$ and $(2)$ anywhere online.","['derivatives', 'numerical-methods', 'partial-derivative', 'finite-differences']"
2612814,Zero function implies zero polynomial.,"I'm trying to help someone with a problem in Apostol's book (Chapter 1 BTW, so before basically any calculus concepts are covered) at the moment and I'm stumped on a question. I'm trying to prove that if $p$ is a polynomial of degree $n$, that is where
$$p(x) = a_0 + a_1x + \cdots + a_nx^n$$
for some real numbers $a_0, \dots, a_n$, and if $p(x) = 0$ for all $x\in \Bbb R$, then $a_k = 0$ for all $k$. Looking through the site, I find this question , but the solution given uses the derivative.  But this before the definition of the derivative in Apostol's book, so I can't use that to prove this.  I also know that we can use linear algebra to solve this, but pretend I don't understand the concept of linear independence either as Apostol's book doesn't presuppose that.  Then what can we do to prove this?  It feels like there should be a proof by induction possible, but I'm not seeing how to do the induction step. My Attempt: Proving that $a_0 = 0$ is trivial by evaluating $p(0)$.  But then I'm left with
$$p(x) = x(a_1 + \cdots +a_nx^{n-1})$$
Here I see that for all $x\ne 0$, $a_1 + \cdots a_nx^{n-1}=0$.  But because of that $x\ne 0$ part, that means I can't use the same trick to show that $a_1 = 0$. Any ideas?","['algebra-precalculus', 'polynomials', 'calculus']"
2612843,Equivalent Statements for a Coherent Sheaf,"Let $C$ be a curve and $f:C \to \mathbb{P}^1$ a finite morphism. I know that the induced sheaf $\mathcal{A}= f_*(\mathcal{O}_C)$ is coherent. I want to know why following statements are equivalent: 1) $\mathcal{A}= f_*(\mathcal{O}_C)$ is locally free; therefore therefore for every $u \in \mathbb{P}^1$ there exist an open affine neghboerhood $U= Spec(R) \subset \mathbb{P}^1$ such that $\Gamma(U, f_*{O}_C) \cong R^n$. 2) $C$ don't has any embedded components, where the embedded components are defined as $Emb(\mathcal{O}_C):= \{c \in C \ | \  m_c \in Ass_{\mathcal{O}_{C,c}}(\mathcal{O}_{C,c}) $and $c$ not generic$\} $",['algebraic-geometry']
2612844,Understanding how to arrive at the identity $2 \sin(x) \cos(n x) = \sin((n + 1) x) - \sin((n - 1) x)$,"Apologies, I'm a bit rusty on my trig. I am trying to manipulate the LHS side of the equation below to arrive at the RHS. $$2 \sin(x) \cos(n x) = \sin((n + 1) x) - \sin((n - 1) x)$$ I've tried using the double angle formula to rewrite the cos(nx) but I'm not getting anywhere with it. Thanks in advance.","['proof-writing', 'trigonometry']"
2612845,Ergodicity of a skew product,"Let $a \in \Bbb{R}$ and $f:[0,1) \to \Bbb{R}$ a Lebesgue measurable function. We define the transformation $T:[0,1)^2 \to [0,1)^2$ such that $$T(x,y)=(x+a,y+f(x))mod1=(\{x+a\},\{y+f(x)\})$$ Prove that the dynamical system $([0,1)^2,\mathcal{B},m_{[0,1)}\times m_{[0,1)},T)$ ,where $\mathcal{B}$ is the Borel sigma algebra on $[0,1)^2$ , is $\text{ergodic}$ if and only if: $a \in \Bbb{R}\setminus \Bbb{Q}$ and $\forall m\in \Bbb{N}$ ,the functonal equation $$mf(x)=h(x+a)-h(x)  (mod1)$$ does not have a measurable solution $h: [0,1) \to \Bbb{R}$ . My first though was to use Fourier expansions for the equation $$g(T(x,y))=g(x,y)$$ where $g$ is an arbitrary function in $L^2([0,1)^2)$ to check ergodicity. In other words to show under which conditions the function $g$ is constant. Also i was given a hint to consider expansions of the form $$\sum_{k \in \Bbb{Z}}a_k(x)e^{2\pi iky}$$ . But unfortunately i cannot reach the desired conclusion. I would appreciate some help in this problem. Thank you in advance.","['fourier-series', 'dynamical-systems', 'fourier-analysis', 'ergodic-theory', 'measure-theory']"
2612860,Derivative of $n!$ (factorial)? [duplicate],This question already has answers here : Derivative of a factorial (5 answers) Closed 6 years ago . I have a theory that uses the gamma function: $$\Gamma(n)=\int_0^\infty x^{n-1}e^{-x} \space dx$$ Then I was inclined to think that perhaps the derivative is: $$x^{n-1}e^{-x}$$ But I'm not sure we can just drop the integral along with the bounds to get the derivative. Then I thought about taking the limit: $$\lim_{x\to\infty}x^{n-1}e^{-x}$$ But now we can't specify at what $x$ value we want to get the rate of change of. At this point I feel like I can't get any further on my own and would appreciate some insight. EDIT: Looking for derivative in terms of $n$ actually.,"['derivatives', 'definite-integrals', 'calculus']"
2612883,What is the degree of $(y')^{-2}+5y'=0 $?,"In the video(time stamp present) https://youtu.be/L61hIm_WoC8?t=2944 , the differential equation  $(y')^{-2}+5y'=0$ is said to have no degree referring that it is not polynomial in derivative(y'), ""The teacher says that the equation is not polynomial in derivative so the degree can't be calculated and puts a cross on the right side of the equation."" but I guess multiplying the equation with $(y')^2$, it becomes $1+5(y')^3=0$ which is polynomial in derivative(y'), it has degree 3. So, which one is correct?","['ordinary-differential-equations', 'calculus']"
2612888,Is the usage of unbiased estimator appropriate?,"Sometimes I find the usage of unbiased estimator quite confusing. For example, the unbiased estimator of variance:$$S^2=\frac{\sum (X_i-\bar{X})^2}{n-1}\,.$$ True, it is the expectation of variance. But when should we use it? I mean, there are other ways to estimate $\sigma^2$, such as MLE. How can I know when I should use MLE and when I should use unbaised estimator? Secondly, some books(such as A-level and AP syllabus and textbooks) uses $S$ as an estimation of standard deviation. However, $S$ is NOT an unbiased estimation. This perplexes me a lot because I don't know what they are trying to do. Why don't they use an unbiased estimator of standard deviation instead? Here are some unbiased estimators of standard deviation. https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation#Background So I have two questions: When should we use unbiased estimator? How can I choose between Maximum Likelyhood Estimation and Unbiased Estimation? Why in some books, unbiased estimator are used in such a way that it end up with bias?","['statistics', 'estimation', 'standard-deviation', 'variance']"
2612912,Holonomy group is closed or not?,"Let $P\to M$ be a $\mathrm{SU}(2)$-principal bundle over a closed connected manifold $M$. Let $A$ be a flat connection on $P$, fix $x\in M$ and let $H:=\mathrm{Hol}_{x,A}(\pi_1(M,x))<\mathrm{Aut}(P_x)\cong \mathrm{SU}(2)$ be $A$'s holonomy based at $x$ where $\mathrm{Hol}_{x,A}$ is the holonomy map from the based loop space to $\mathrm{Aut}(P_x)$. Since $\pi_1(M,x)$ is countable, $H$ is countable and hence a proper subgroup of $\mathrm{SU}(2)$. Question : Is $H$ necessarily closed in $\mathrm{SU}(2)$ ? • According to [DK] at top of p.132, $H$ is necessarily closed. Why ? • According to [KN-I] at p.73, thm. 4.2, $H$ is a Lie subgroup of $\mathrm{SU}(2)$, and hence $H$ is necessarily closed. • According to this link at middle of p.14, the restricted holonomy group (which here is trivial since $A$ is flat) is necessarily closed but the (non restricted) holonomy group $H$ is not necessarily closed. Why ? Is there a problem with thm. 4.2 in [KN-I] ? Remark 1 : Since $H$ is proper in $\mathrm{SU}(2)$, we know that ""if $H$ is dense in $\mathrm{SU}(2)$, then $H$ not a closed subgroup of $\mathrm{SU}(2)$"" . I already know that proper dense subgroups of $\mathrm{SU}(2)$ exist ; can $H$ be one of them ? Remark 2 : The aim of this question is to clarify what is an irreducible flat connection . I found many different definitions : ""$A$ is reducible if $H$ lies in some proper subgroup of $\mathrm{SU}(2)$"" . See [DK] at bottom of p.131. ""$A$ is reducible if the set $Q\subset P$ corresponding to all points in $P$ horizontally joinable from a fixed $p_0\in P_x$ is a (strict) structural reduction $Q\to M$ with structural group $H<G$ of the $G$-bundle $P\to M$"" (here $G=\mathrm{SU}(2)$). See [KN-I] at top of p.82. ""$A$ is reducible if the centralizer $C_G(H)$ is strictly bigger than the center $Z(G)$"" (here again $G=\mathrm{SU}(2)$, so $Z(\mathrm{SU}(2)) = \{-1,1\}$). Since $C_G(H)$ is isomorphic to the stabiliser $\mathcal{G}_A$ of $A$ in the gauge group $\mathcal{G}$, this present definition of reducibility is equivalent to ""A is reducible if $\mathcal{G}_A$ is strictly bigger than $Z(G)$"" . Then, since the only possible discrete centralizer $C_G(H)$ is minimal $\{-1,1\}$, for $G=\mathrm{SU}(2)$, this present definition of reducibility is also equivalent to ""A is reducible if the kernel $\ker \mathrm{d}_A$ of the exterior covariant derivative $\mathrm{d}_A:\Omega^0(M;\mathrm{Ad}P)\to \Omega^1(M;\mathrm{Ad}P)$ on the space of $\mathrm{Ad}P$-valued differential 0-forms is not injective"" . Lastly, this present definition of irreducibility is equivalent to ""A is reducible if $H$ acts reducibly on $\mathbb C^2$"" . These equivalent definitions of $A$ being reducible ($C_G(H)\ne Z(G)$, $\mathcal{G}_A \ne Z(G)$, $\ker \mathrm{d}_A|_{\Omega^0}\ne 0$ and $H$ acts reducibly on $\mathbb{C}^2$) seem to be the mainstream definitions of reducibility. According to definition (1), since $H$ lies in itself which is proper in $\mathrm{SU}(2)$, every flat connection is reducible. This is problematic (because of the amount of papers about moduli spaces of irreducible $\mathrm{SU}(2)$ flat connections). So definition (1) is not a good one. Is [DK] wrong then ? Yes and no, because they start their ""definition"" with ""In general..."" which is certainly not ""always"" . Now, if $H$ can be, and is, a dense subgroup of $\mathrm{SU}(2)$ (i.e. $H$ not closed), then : $A$ would be irreducible according to definition (2) because a dense submanifold $Q\subset P$ is not a submanifold and hence not a structural reduction in the classical way. Or maybe $A$ could be reducible if we extend the notion of structural reduction to dense subgroups of the structural group. I don't know if this notion exists or not. $A$ would be irreducible according to definition (3) (because $C_G(H)$ is minimal for $H$ dense in $\mathrm{SU}(2)$). If $H$ cannot be, and hence is not, a dense subgroup of $\mathrm{SU}(2)$, then : $A$ is reducible, according to definition (2), to a $H$-bundle $Q$ inside $P$. $A$ could be reducible or not according to definition (3). Indeed, if $H=\{1,-1\}$, then $C_G(H)=G=\mathrm{SU}(2)$ which is strictly bigger than the center $Z(G) = \{1,-1\}$, then $A$ would be reducible. But if $H$ is the binary icosahedral group inside $\mathrm{SU}(2)$, then $C_G(H)=\{1,-1\}$, and hence $A$ would be irreducible. p.s. this question is a sequel to this question . p.p.s maybe the answer to my question lies in the details of the proof of thm 4.2 in [KN-I]. Still, there seems to be a bit of confusion around the notion of flat irreducible connections. [DK] : The Geometry of Four-Manifolds (Donaldson, Kronheimer) [KN-I] : Foundations of Geometry, Vol. I (Kobayashi, Nomizu) Conclusion : According to the answers I got to my question, it seems that $H$ can be dense in $\mathrm{SU}(2)$. This is what I thought, but was unsure because it would contradict both Kobayashi-Nomizu and Donaldson-Kronheimer. Now, what happens to the definitions of reducibility of connections ? Definition (1) from [DK] is out of the game, may $H$ be dense or not in $\mathrm{SU}(2)$. Definitions (2) from [KN-I] and definition (3) tells us that $""H$ dense implies $A$ irreducible"" . I'm fine with that. But there is still an ambiguity between (2) and (3) where if $H$ is the binary icosahedral group, then $A$ is reducible according to (2) but irreducible according to (3). That's another story and leads to a new question (that you can find here ).","['gauge-theory', 'differential-geometry']"
2612975,Can we prove the same cardinality of the sets $\mathbb{N}$ and $\mathbb{N^2}$ this way?,"I tried  to prove that the sets $\mathbb{N}$ and $\mathbb{N^2}$ have the same cardinality and I concluded the following: Consider the function $f:\mathbb{N}\rightarrow \mathbb{N^2}$ that achieves the mapping: $ \begin{cases} 1 \rightarrow (0,0) \end{cases} \\ 
\begin{cases} 2 \rightarrow (1,0) \\ 
3 \rightarrow (1,1) \\ 
4 \rightarrow (0,1) \end{cases} \\ 
\begin{cases} 5 \rightarrow (2,0) \\ 
6 \rightarrow (2,1) \\ 
7 \rightarrow (2,2) \\ 
8 \rightarrow (1,2) \\ 
9 \rightarrow (0,2) \end{cases} \\ 
\quad \vdots$ This way $\forall k \in \mathbb{N}\cup\{0\}$ we construct the function: $f(n) = \begin{cases} \begin{aligned} 
&(\sqrt{n-1},0) \\
&(\sqrt{n-1},1) \\ \vdots \\ 
&(\sqrt{n-1},\sqrt{n-1}-1) \\ 
&(\sqrt{n-1},\sqrt{n-1}) \\ 
&(\sqrt{n-1}-1,\sqrt{n-1}) \\ \vdots \\ 
&(1,\sqrt{n-1}) \\ 
&(0,\sqrt{n-1}) 
\end{aligned} 
&& 
\begin{aligned} 
&, n=k^2+1 \\ 
&, n=k^2+2 \\ \\ 
&, n=k^2+k \\ 
&, n=k^2+k+1 \\ 
&, n=k^2+(k+1)+1 \\ \\ 
&, n=k^2+(2k-1)+1 \\ 
&, n=k^2+2k+1=(k+1)^2 
\end{aligned} \end{cases}$ Is the above mapping correct? If not then why? If yes then how can I prove rigorously that this function is bijective?","['proof-writing', 'elementary-set-theory']"
2613010,Confusion about the rephrase of Recursion Theorem,"From textbook A Course in Mathematical Analysis by Prof D. J. H. Garling, I'm confused about how he rephrases the Recursion Theorem . First, he states the theorem: Then he says: Finally, he expresses the theorem in a more general term: My question is: the author says ""there exists a unique mapping $f^{n}: A → A$"", but I feel like there are more than one mappings: $f^{0} : A → A, f^{1} : A → A, f^{2} : A → A,...$. Many thanks for clarifying my doubt!",['elementary-set-theory']
2613014,Express a linear map in matrix form,"Is there anyway to express the linear map $x\mapsto (a^Tx)b, \, a,b,x\in\Bbb R^n$ in matrix form $x\mapsto Ax$? Context: I'm trying to solve an equation in $x\in\Bbb R^n$:
$$ab^Tx-(a^Tx)b=c$$
If I'm able to express $(a^Tx)b$ in martrix form $Ax$ I'm done (we don't need to care about existence or uniqueness of solutions since from other aspects it's guaranteed $(ab^T - A)$ will be invetible. Best regards.","['matrices', 'linear-algebra']"
2613116,"How to evaluate this $\int_{0}^{\pi/2}(\cos x)^{a+b}\cos {(b-a)x}\, dx$","Evaluate: $$\int_{0}^{\pi/2}(\cos x)^{a+b}\cos (b-a)x\, dx,0<a<1,a+b>1$$ This integral looks very simple, but I can't solve it. Any help is appreciated.","['integration', 'trigonometry', 'calculus']"
2613127,Use Stokes' Theorem to evaluate line integral,"For the vector field $\mathbf{F}(x,y,z) = \langle 5y+\sin x, z^2+\cos y, x^3\rangle$, I need to find the integral using Stokes' Theorem $\int_C\mathbf{F}\cdot\mathrm{d}\mathbf{r}$ where $C$ is the curve $\mathbf{r}(t)=\langle \sin t, \cos t, 2\sin t\cos t\rangle, t\in[0,2\pi]$. I have gotten the curl as $\langle -2z,-3x^2,-5\rangle$. But I was troubled in parametrising the surface. When I suggest that the curve is contained in the surface parametrised by $\mathbf{r}(u,v)=\langle u\sin v, u\cos v, 2u\sin v\cos v\rangle$, 
 I have $\mathbf{r}_u\times\mathbf{r}_v=\langle 2u\cos^3 v, 2u\sin^3 v,-u\rangle$ which changes direction in the domain of $v\in[0,2\pi]$. How should I correctly parametrise the surface? Thank you very much.",['multivariable-calculus']
2613153,A question about real-analytic functions vanishing on an open set,"Real analytic functions are defined as functions on the Euclidean spaces with convergent power series at each point. My question is that, is there some kind of identity theorem for real analytic functions? My book (John Lee's smooth manifolds) says on p.46 that a real-analytic function defined on a connected domain and vanishes on an open set is identically zero. But I have the impression that this kind of fact holds for holomorphic functions only. Am I missing something?","['analyticity', 'real-analysis', 'analytic-functions', 'functions']"
2613161,conditional probability on two variables,"How can you express p(x1|x2,x3) in terms of p(x2|x1,x3) and p(x1|x3) and p(x2|x3) with the help of the chain rule ? Source: https://www.hackerearth.com/practice/machine-learning/prerequisites-of-machine-learning/bayes-rules-conditional-probability-chain-rule/tutorial/ what I tried: 
$p(x1|x2,x3) = \gamma* p(x1,x2,x3) = \gamma*p(x3|x1,x2)*p(x1,x2) = \gamma*\tau*p(x3|x1,x2)*p(x2|x1)*p(x1) $ ... but the result should be:
$$p(x1|x2,x3)=p(x1|x3,x2)=p(x2|x1,x3)*p(x1|x3)/p(x2|x3)$$",['probability']
2613178,Integral of $\int_0^{\infty} \ln\left|\frac{x+A}{x+B}\right|\frac{x}{e^{C x}\pm 1}dx$,"so I have this integral to try and evaluate $$(*)=\int_0^{\infty} \ln\left|\frac{x+A}{x+B}\right|\frac{x}{e^{C x}\pm1}dx$$ So far, I have managed to evaluate a very similar integral $$\int_0^{\infty} \ln\left|\frac{x+A}{x+B}\right|\frac{x}{e^{C x}}dx =-\frac{\partial }{\partial C}\int_0^{\infty} \ln\left|\frac{x+A}{x+B}\right|\frac{1}{e^{C x}}dx=\frac{1}{C^2}\ln\left(\frac{A}{B}\right) + \left(\frac{A e^{AC}}{C}-\frac{e^{AC}}{C^2}\right)\text{Ei}(-CA) + \left(\frac{Be^{BC}}{C}-\frac{e^{BC}}{C^2}\right)\text{Ei}(-BC)$$ But as soon as I introduce the $\pm 1$ in the denominator, the standard techniques I am trying are not working as effectively as in the simplified case. Does anyone know how to solve it? Already you can see the presence of the exponential integral function $\text{Ei}(x)$ so I'm sure this integral is going to you some non standard functions.
Having thought about it, it greatly depends on the sign of $A,B$ and $C$ . Singularities pop up at the origin also when the denominator has the minus sign. Thanks for any help/guidance in advance. Update: So after playing around a bit further with things I managed to massage the positive denominator expression into the following form: $$(*) = \left[\log\left(\frac{x+A}{x+B}\right)\left\{\frac{-1}{C^2}\text{Li}_2(-e^{Cx}) -\frac{x\log (e^{Cx}+1)}{C}+\frac{1}{2}x^2\right\} -\left(\frac{1}{2}x + \frac{B^2 \log(x+B)-A^2\log(x+A)}{2}\right)\right]^{\infty}_0 $$ $$ +\frac{(B-A)}{C^2}\int_0^\infty \left(\frac{\text{Li}_2(-e^{Cx})}{(x+A)(x+B)}+\frac{Cx \log(e^{Cx}+1)}{(x+A)(x+B)}\right)
$$ $\text{Li}_2(x)$ being the Dilogarithm. A little unsure of how to deal with the final two integrals. Update: Perhaps it is useful to use the expansion of the Dilogarithm for $x\leq -1$ as found here : $$\text{Li}_2(x) = -\frac{\pi^2}{6}-\frac{1}{2}\log(-x)^2-\sum_{k=1}^\infty \frac{1}{k^2 x^k}
$$ Update: Ok, so I've been playing around with it for a while, and this seems to be the final expression: \begin{equation}
\begin{aligned}
&\log\left(\frac{x+A}{x+B}\right)\left[\frac{-1}{C^2}\text{Li}_2(-e^{Cx})-\frac{x\log(e^{Cx +1})}{C} + \frac{x^2}{2}\right]^\infty_0 + \frac{(B-A)}{2}\left[x+ \frac{B^2 \log(x+B)-A^2\log(x+A)}{(A-B)}\right]^\infty_0 \\
&+ \left.\frac{(B-A)}{C^2}\left(\frac{-\pi^2}{6}\right) \frac{1}{(A-B)}\log\left(\frac{x+B}{x+A}\right)\right|^\infty_0 \\
&-\frac{(B-A)}{2C^2}\left[-Cx\left\{C(A+2x) - 2 \log(e^{Cx})\right\} + \log{(x+A)}\left[\log (e^{Cx})-C(x+A)\right]^2+\frac{C^2 x^2}{2}\right]^\infty_0\\
&-\frac{(B-A)}{C^2}\sum_{k=1}^\infty \frac{1}{k^2}\left[\frac{e^{BCk}\text{Ei}(-Ck(x+B))-e^{ACk}\text{Ei}(-Ck(x+A))}{A-B}\right]^\infty_0
\end{aligned}
\end{equation} Provided the previous update was right, and human error is not involved! Now it is just a matter of trying to simplify and evaluate this beast, and rerun with the negative denominator... Update: So I ran the calculation with the negative denominator, and used the expansion as explained in the link above, and I've stumbled across a red flag. If anyone is able to explain it I'd be really grateful! \begin{equation}
\begin{aligned}(*) =& \left.\left\{\frac{\text{Li}_2(e^{Cx}}{C^2} + \frac{x\log(1-e^{Cx})}{C}-\frac{x^2}{2}\right\}\frac{B-A}{(x+A)(x+B)}\right|^\infty_0 + 2\frac{B-A}{2}\left[x+ \frac{B^2 \log(x+B) - A^2\log(x+A)}{A-B}\right]^\infty_0 \\
&- \left.\frac{B-A}{2}\left(\frac{\pi^2}{3(A-B)}\right)\log\left(\frac{x+B}{x+A}\right)\right|^\infty_0 + \frac{B-A}{C^2}\sum_{k=1}^{\infty}\frac{1}{k^2}\left[\frac{e^{BCk}\text{Ei}(-Ck(x+B)) - e^{ACk}\text{Ei}(-Ck(x+A))}{A-B}\right]^{\infty}_0\\
&+\frac{i\pi (B-A)}{C}\left[\frac{A\log(x+A)-B\log(x+B)}{A-B}\right]^\infty_0
\end{aligned}
\end{equation} The potential red herring is the imaginary term! The integral should be real (considering all the functions are, though I can imagine convergence issues from the denominator and logarithm), so I guess I haven't correctly used the absolute value of the logarithm correctly: I'm attaching hand working if someone can spot the mistake, or justify why there should be such an imaginary term; I'm attaching the working too.","['integration', 'definite-integrals', 'calculus']"
2613220,Possible typos in the proof of Recursion Theorem,"Below is the proof I took from textbook A Course in Mathematical Analysis by Proof D. J. H. Garling. I think there are some typos, which I highlighted in the attached picture. $g(s(n))= f(n)$ Since the theorem states $a_{s(n)}=f(a_{n})$, I think the right version should be: $g(s(n))=f(g(n))$, not $g(s(n))= f(n)$. 2.$(n,a)\in P$ and $(n,a')\in P$ I think the right version should be: $(n,a)\in g$ and $(n,a')\in g$ 3.$(s(m),f(b))\in g$ Since the author is trying to prove $g'\in S$, I think the right version should be: $(s(m),f(b))\in g'$, not $(s(m),f(b))\in g$. 4.$(s(m),f(b))\notin g$ As in 3., I think the right version should be: $(s(m),f(b))\notin g'$, not $(s(m),f(b))\notin g$. Please check whether I am right or wrong about these typos!",['elementary-set-theory']
2613238,Finding $f$ from $f'$,"I have a function $f:(1,+\infty)\rightarrow(0,+\infty)$ that derives and for which is true that:
$x\cdot\ln(x)\cdot f'(x)=f(x)+x\cdot\ln(x)\cdot f(x)$ and $f(e)=e^e.$ I want to find $f$ so from the given equality I reach at this point:
$$x\cdot\ln(x)\cdot f'(x)=f(x)+x\cdot\ln(x)\cdot f(x)\iff\frac{f'(x)}{f(x)}=\frac{(\ln(x))'}{\ln(x)}\iff(\ln(f(x)))'=(\ln(\ln(x)))'$$
but how can I continue?","['integration', 'ordinary-differential-equations', 'functions']"
2613280,Strength of $\sf ZF$+The weak topology on every Banach space is Hausdorff,"Most functional analysis books prove that Zorn's Lemma$\implies$Hahn-Banach$\implies$""The weak topology on every Banach space is Hausdorff"", however it is known that the Hahn-Banach theorem can be proved from the Boolean Prime Ideal theorem, which is strictly weaker than $\sf ZL$, and that $\sf ZF+HB$ is strictly weaker than $\sf ZF+BPI$. Let $\sf WH$ be the assertion ""The weak topology on every Banach space is Hausdorff"", what's the relation between $\sf ZF$,$\sf ZF+WH$ and $\sf ZF+HB$?","['functional-analysis', 'set-theory', 'axiom-of-choice']"
2613282,"$\triangle ABC$ has $AC=BC$, and $\angle ACB=96^\circ$. $D$ is a point such that $\angle DAB=18^\circ, \angle DBA=30^\circ$. What is $\angle ACD$?","$\triangle ABC$ has $AC=BC$, and $\angle ACB=96^\circ$.  $D$ is a point in $\triangle ABC$, such that $\angle DAB=18^\circ, \angle DBA=30^\circ$.  What is $\angle ACD$? My attempt: $$\angle ABC=\angle BAC=\frac{(180^\circ-96^\circ)}{2}=42^\circ.$$ $$\angle ADB=180^\circ-18^\circ-30^\circ=132^\circ.$$ From here onwards, I have no idea how to carry on.  Can anyone help?","['trigonometry', 'euclidean-geometry', 'triangles', 'geometry', 'contest-math']"
2613302,"Deriving inequality from a Lyapunov test of $x' = -x + y^3, \space y' = -y + ax^3$","Exercise : Consider the dynamical system :
  $$x' = -x +y^3$$
  $$y' = -y+ax^3$$
  with $(x,y) \in \mathbb R^2$. Find the stationary point of the system and study their stability for every value of $a$. Show that if $a=1$ and $V(x,y) \leq R$, where $R>0$ is a constant and $V(x,y) = \frac{1}{2}x^2 + \frac{1}{2}y^2$, then the derivative $V'(x,y)$ along the solutions of the dynamical system, satisfies the inequality $V'(x,y) \leq -2(1-R)V(x,y)$ and finally, estimate a stability area of $(0,0)$ for the case of $a=1$ using the Lyapunov Functional given. Attempt / Question : For the first part, I've elaborated a complete solution, as one can easily find the stationary points from solving the system : $$\begin{cases} -x+y^3 \space\space=0\\ -y + ax^3=0\end{cases}$$ which yields $3$ different stationary points $(x,y)$. For the stability and the kind of the stationary points, it's enough to find the eigenvalues for each stationary point for the linearisation matrix (jacobian), which is : $$J(x,y) = \begin{bmatrix} -1 & 3y^2 \\ 3ax^2 & -1 \end{bmatrix}$$ For the part of the question in which I have an issue now, regarding the next segment of the problem : The functional derivative, is given as : $$\dot{V}(x,y) = \nabla V(x)f(x,y) = V_xf_x + V_yf_y = 2x(-x+y^3)+2y(-y+x^3) $$ $$\Leftrightarrow$$ $$\dot{V}(x,y) = -2x^2 + 2xy^3 - 2y^2 + 2yx^3$$ $$\Leftrightarrow$$ $$\dot{V}(x,y) = -2x^2 - 2y^2 + 2xy(y^2 + x^2)=-4V(x,y) + 4xyV(x,y)= 4V(x,y)(xy-1)$$ From this point on though, how would one proceed to show the inequality asked ? $$\dot{V}(x,y) \leq -2(1-R)V(x,y)$$ For the final part, I guess you just want to set a domain for the constant $R$ such that the functional is negative, but correct me if I'm wrong.","['dynamical-systems', 'stability-theory', 'lyapunov-functions', 'stability-in-odes', 'ordinary-differential-equations']"
2613328,Young Tableaux generating function,"The number of young tableaux of $n$ cells is known to satisfy the recurrence $a_{n+1} = a_{n} + na_{n-1}$. I am trying to find the generating function but I keep getting something dependent on $n$. Here's what I did so far: Denote by $f(x) = \sum_{n\geq 1}a_nx^n$. We have $\sum_{n \geq 1} a_{n+1}x^n = f(x) + nxf(x)$ (if we assume $a_1 = 1, a_2 = 2$). We can infer that $\sum_{n \geq 1} a_{n+1}x^n = \frac{f(x)}{x} - 1$.","['generating-functions', 'combinatorics', 'recurrence-relations']"
2613329,Is the exterior/wedge product of differential forms injective?,"Is the exterior wedge product of differential forms $$
\begin{align*}
\Omega(X) \otimes_{\mathbb{R}} \Omega(Y) &\longrightarrow \Omega(X\times Y) \\
\alpha \otimes \beta &\longmapsto \pi_X^*\alpha \wedge \pi_Y^*\beta
\end{align*}
$$ injective? UPDATE 1: I think I got it locally: Suppose 
$$\sum_{i=1}^n \alpha^i(x)\wedge \beta^i(y) = 0$$ 
for all $(x,y)\in X\times Y$.
If $X=\mathbb{R}^N$, $Y=\mathbb{R}^M$ we write 
$$ \alpha^i(x) = \sum_I \alpha^i_I(x) \mathrm{d}x^I,\quad \beta^i(y) = \sum_J \beta^i_J(y) \mathrm{d}y^J $$
for $i=1,\ldots,n$. The equation is equivalent to
$$ \alpha_I(x) \cdot \beta_J(y) = 0 $$
for all $I$, $J$ and $x,y$, where we collected $\alpha^i_I$'s and $\beta^i_J$'s in vectors $\alpha_I(x), \beta_J(x) \in \mathbb{R}^n$ and used the dot product. It follows that there is an orthonormal basis $v_1, \ldots, v_{k}, w_1, \ldots, w_l\in \mathbb{R}^n$, $k + l =n$ and smooth coefficients $a_I^u(x)$, $b_J^v(y)$ such that
$$ \begin{aligned}
\alpha_I(x)&= a_I^1(x) v_1 + \ldots + a_I^k(x) v_k \\
\beta_J(y) &= b_J^1(y) w_1+\ldots + b_J^l(y) w_l
\end{aligned}
$$
for all $I, J$ and $x,y$. Now we have 
$$ \sum_{i=1}^n \alpha^i \otimes \beta^i = \sum_{I,J,u,p} \bigl(\sum_{i=1}^n v^i_u w^i_p\bigr) (a^u_I (x) \mathrm{d}x^I)\otimes (b^v_J(y) \mathrm{d}x^J) = 0 $$
because $v_u \perp w_p$. UPDATE 2: For $X$, $Y$ compact we pick coordinate coverings $(U_1,x_1),\ldots,(U_A,x_A)$ of $X$ and $(V_1,y_1),\ldots,(V_B,y_B)$ of $Y$. We pick subordinate partitions of unity $(\lambda_a)$ and $(\mu_b)$ respectively. We do it in such a way that the collections $(\lambda_a\mathrm{d}x^I_a)_{a,I} \subset \Omega(X)$ and $(\mu_b \mathrm{d}y_b^J)_{b,J} \subset \Omega(Y)$ are $\mathbb{R}$-linearly independent. It follows that the collection $\bigl((\lambda_a\mathrm{d}x^I)\otimes(\mu_b \mathrm{d}y^J)\bigr)_{a,I,b,J}$ is linearly independent in $\Omega(X)\otimes_{\mathbb{R}}\Omega(Y)$. We write $\alpha^i$ and $\beta^i$ as linear combinations (with functions as coefficients) of $(\lambda_a\mathrm{d}x^I)$ and $(\mu_b \mathrm{d}y^J)$ respectively and apply exactly the same argument as above replacing $(\mathrm{d}x^I)_I$ by $(\lambda_a\mathrm{d}x^I)_{a,I}$ and $(\mathrm{d}y^J)_J$ by $(\lambda_b\mathrm{d}y^J)_{b,J}$. We see that the exterior wedge product for compact $X$, $Y$ is injective. UPDATE 3 (reaction to a comment): It is never an isomorphism since e.g. $e^{xy}$ is not equal to a finite sum of products $f(x)g(y)$. UPDATE 4: I think I got it for non compact $X$, $Y$ as well: 
Let $U_i$, resp. $V_j$ be exhaustions of $X$, resp. $Y$ by relatively compact open sets. Each of these have a finite atlas, and hence, modifying the proof above, the exterior wedge product $\Omega(U_i)\otimes \Omega(V_j) \rightarrow \Omega(U_i\times V_j)$ is injective. For fixed $i$ the exterior wedge product induces an injection 
$$\varprojlim_j \Omega(U_i)\otimes \Omega(V_j) \simeq \Omega(U_i) \otimes \varprojlim_j(\Omega(V_j)) \longrightarrow \varprojlim_j \Omega(U_i \times V_j)$$ where we used that the inverse limit commutes with tensor product and preserves exactness. Taking the inverse limit over $i$ we get similarly an injection $$ \varprojlim_i(\Omega(U_i))\otimes \varprojlim_j(\Omega(V_j)) \longrightarrow \varprojlim_i \varprojlim_j \Omega(U_i\times V_j) $$
It is easy to check that the restrictions from $X$ to $U_i$, resp. $Y$ to $V_j$, resp. $X\times Y$ to $U_i\times V_j$ induce embeddings of $\Omega(X)$, resp. $\Omega(Y)$, resp. $\Omega(X\times Y)$ into $\varprojlim_i(\Omega(U_i))$, resp. $\varprojlim_j(\Omega(V_j))$, resp. $\varprojlim_i \varprojlim_j \Omega(U_i\times V_j)$ and that the induced injection restricts to the exterior wedge product $\Omega(X)\otimes \Omega(Y) \rightarrow \Omega(X\times Y)$. Consequently it is injective. QUESTION LEFT: Is the above proof correct? Shall I close the question?","['differential-geometry', 'exterior-algebra']"
2613379,Writing Differential equations to describe a system,"I have a system that models the interaction between a pathogen an the immune response. If $P$ is the pathogen and $I$ represents immune response, the differential equations of the system are: $$
\begin{alignat*}{1}
{\mathrm{d}P\over \mathrm{d}t} &= r_1P \left(1-{P\over k}\right)-d_1P \left({I\over I+\sigma}\right)\\
{\mathrm{d}I\over \mathrm{d}t} &= r_2I \left({P \over P+\sigma_2}\right)-d_2I
\end{alignat*}
$$ This is somewhat similar to this article . $r_i$, $k$, and $\sigma$ are constants. $\sigma$ represents the pathogen density when the immune response is at half its maximal capacity. $d_i$ is the killing rate through immune response. I want to change these equations so that some of the pathogens that interact with the immune response do not get killed. So I want it to be modelled such that immune-system cells will engulf pathogens, but a portion of pathogens can survive within the immune-system cells and will not get killed. If $P_S$ represents the population that survives and if $\alpha$ the proportion of the pathogen that interacts with the immune system and can survive killing, if I change the equations in the following way will it be correct? $$
\begin{alignat*}{1}
{\mathrm{d}P\over \mathrm{d}t} &= r_1P\left(1-{P\over k}\right)-(1-\alpha)d_1P\left({I\over I+\sigma}\right)\\
{\mathrm{d}I\over \mathrm{d}t} &= r_2I\left({P \over P+\sigma_2}\right)-d_2I  \\
{\mathrm{d}P_s\over \mathrm{d}t} &= \alpha d_1 P\left({I\over I+\sigma}\right)   
\end{alignat*}
$$ But I am not sure if I should use the death rate $d_1$ for the surviving population $P_s$? Or is there any other way to show that a proportion of the pathogens that interact with the immune response move into a different compartment that includes surviving pathogen?","['mathematical-modeling', 'ordinary-differential-equations', 'dynamical-systems']"
2613388,"Form an equation whose roots are $(a-b)^2,(b-c)^2,(c-a)^2.$","If $a,b,c$ are the roots of the equation $x^3+x+1=0,$ Then the equation whose roots are $(a-b)^2,(b-c)^2,(c-a)^2.$ Try: $a+b+c=0,ab+bc+ca=1,abc=-1$ Now $(a-b)^2+(b-c)^2+(c-a)^2=2(a+b+c)^2-6(ab+bc+ca)=-6$ Could some help me to explain short way to calculate product,Thanks","['polynomials', 'roots', 'algebra-precalculus', 'symmetric-polynomials', 'cubics']"
2613395,When are $\alpha$ and $\cos\alpha$ both rational?,"I've seen a bunch of related questions, but none lead me to a solution to this problem: Is there any ""easy"" characterisation of $\alpha\in\mathbb Q$ such that $\cos\alpha\in\mathbb Q$? It feels like there should be only ""few"" such numbers. Are there only finitely many?","['trigonometry', 'rational-numbers']"
