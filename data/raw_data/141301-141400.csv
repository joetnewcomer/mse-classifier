question_id,title,body,tags
2284528,Simplifying $\lim_{h\to 0} f'(\frac{(f(a)-f(a+h))(a^2+ah)}{f(a)(a+h)-f(a+h)a)})=\frac{-f(a)}{a}$,"I'm working on a personal for fun project that you can look at the broader question of here if you feel the need for context, but the gist of it is that I've reached a blockade where the only thing left for me to solve is:
 $$\lim_{h\to 0} f'(\frac{(f(a)-f(a+h))(a^2+ah)}{f(a)(a+h)-f(a+h)a)})=\frac{-f(a)}{a}$$
honestly the entire thing is a mess, an easy way to start would probably to move to
$$\lim_{h\to 0}f(\frac{(f(a)-f(a+h))(a^2+ah)}{f(a)(a+h)-f(a+h)a)})=\int_0^x \frac{-f(a)}{a} \,da$$
but from there I would need to simplify all of $\frac{(f(a)-f(a+h))(a^2+ah)}{f(a)(a+h)-f(a+h)a)}$, but any way of doing that is beyond me. If it is impossible to outright simplify it all, any simplification would be appreciated. Please excuse me for any errors that I make, or stupid questions, I am basically swinging blind at this point and learning as I go.","['algebra-precalculus', 'multivariable-calculus', 'calculus']"
2284559,Limit with sin indeterminate,How do I calculate the following limit $$\lim_{x\to\infty} \frac{3x-\sin x}{x+\sin x}$$ It's an indeterminate limit but how can I solve it? Does it help if I split it?The answer I got is $-1$ but it's $3$.,['limits']
2284577,How many 5-letter words from ABRACADABRA,"How many different 5-letter strings can be formed using the letters from the word ABRACADABRA if duplicated letters are allowed but no letter can be used more times than it occurs in the word? Though this seems like a duplicate, there is a nuance in my question in which i am about to explain: According to an answer key it is 1271 because if we set the variables vwxyz, there are 5! ways, which i understand, but if there is a repeated letter vvxyz, then there are $3*4*(5!/2!)$ many ways and so on and so forth, But why is it $3*4*(5!/2!)$ ? why do you multiply the 4 and the 3? I was wondering that there are 5 ! configurations with 2! repeated letters so wouldnt that just be $\frac{5!}{2!}?$",['combinatorics']
2284582,Sequence of isometries with mutually orthogonal ranges,"Let $(W_n)_{n\in \Bbb {N}} $ be a sequence of isometries in $B (H ) $ with pairwise orthogonal ranges, i.e. $W_n^*W_m=0$ for all $n\neq m $. I want to show that if $F $ is a finite rank operator then there exists $n_0$ sufficiently large so that for all $n\geq n_0$ we have $FW_n=0$. I think that this should be equivalent to the claim that $W_n $ converges SOT to zero. However, I don't know how to show it.","['functional-analysis', 'spectral-theory', 'von-neumann-algebras']"
2284608,Contour Integral Relating to the Gamma Function,"Consider $\oint e^{-|a|z}z^{s-1}$, taken around the contour consisting of the line from $\epsilon$ to $R$, the circular arc of radius $R$ where $arg(z)$ goes from $0$ to $arg(a)$, the line defined by $te^{iarg(a)}$, where $t$ goes from $R$ to $\epsilon$, and the circular arc of radius $\epsilon$ required to close the contour. I want to use this integral to show that $\int_{0}^{\infty}e^{-at}t^{s-1}dt=a^{-s}\Gamma(s)$, where $a$ is in general complex and we have $Re(a)>0$ and $Re(s)>0$. Now, the segment on the real axis tends to the integral equired as $\epsilon$ vanishes and $R$ tends to infinity. The segment on the arc of radius $\epsilon$ is bounded by $K|arg(a)|\epsilon ^{Re(s)}$, where $K$ is constant (by application of the ML bound), and so vanishes as $\epsilon$ vanishes. The integral along the straight segment can be easily evaluated as $-|a|^{s-1}\Gamma(s)$ Also, as this contour encloses no singularities, the total integral is $0$ by Cauchy's Theorem. My issue is that I can't seem to show that the integral along the arc of radius $R$ vanishes. Clearly, to give the correctresult this must be the case, but I just can't seem to show it. It's been suggested to me to use an analog of Jordan's Lemma, but still I can't seem to figure it out.
I can't seem to express the integrand in the form $e^{i\alpha z}f(z)$, with $\alpha>0$ as required by the Lemma. I'm also a bit worried about the fact that this isn't a full semicircular arc, and we don't know whether $a$ lies in the upper or lower half plane. Any help would be much appreciated, thanks!","['complex-analysis', 'contour-integration']"
2284609,Evaluating Definite Integral $\int_0^\infty\frac{x}{e^x-1}dx$,"I am looking for alternative ways to solve the Basel problem using only real analysis and without using the infinite product for sine. I have transformed the summation into the given integral below. It looks like a deceivingly simply integral to evaluate, but none of the websites that I have plugged it into have been able to solve it. One of them even claimed that it was a divergent integral. Through numerical integration I have verified that the integral is equal to $\frac{\pi^2}{6}$. I am hoping that someone will be able to prove the integral is equal to its known closed form. For the purposes of this proof, start with the integral, and do not revert to the initial summation.
$$\sum_{n=1}^\infty \frac{1}{n^2} = \int_0^\infty \frac x {e^x-1} \, dx = \frac{\pi^2} 6$$ $$\text{Transform Explanation:}$$ $$a(x)=\sum_{n=1}^\infty \frac{x^n}{n^2}$$
$$a(0)=0 \space\space\space\space\space\space\space\space a(1)=\sum_{n=1}^\infty \frac 1 {n^2}$$
$$a(1)=\int_0^1{a'(x)dx}$$
$$a'(x)=\frac{1}{x}{\sum_{n=1}^{\infty}{\frac{x^n}{n}}}$$
$$b(x)={\sum_{n=1}^{\infty}{\frac{x^n}{n}}} \space\space\space\space\space\space\space\space a'(x)=\frac{b(x)}{x}$$
$$b(0)=0 \space\space\space\space\space\space\space\space b(x)=\int_0^x{b'(t)dt}$$
$$b'(x)={\sum_{n=0}^{\infty}{x^n}}=\frac{1}{1-x} \space\space\space\space\space For \space\space -1<x<1$$
$$b(x)=\int_0^x{\frac{dt}{1-t}}=-\ln|1-x|$$
$$a'(x)=\frac{-\ln|1-x|}{x}$$
$$a(1)=\int_0^1{\frac{-\ln|1-x|}{x}dx}=\int_0^1 \frac{-\ln(1-x)} x \, dx$$
$u=-\ln(1-x) \space\space\space\space -u=\ln(1-x) \space\space\space\space e^{-u} = 1-x \space\space\space\space x=1-e^{-u} \space\space\space\space dx=e^{-u} \, du$
$u(x)=-\ln(1-x) \space\space\space\space u(0^+)=0 \space\space\space\space u(1^-)=\infty$
$$\int_0^1 \frac{-\ln(1-x)}{x} \, dx =\int_0^\infty \frac{ue^{-u}}{1-e^{-u}} \, du$$
$$a(1)=\int_0^\infty\frac{x}{e^x-1}\,dx=\sum_{n=1}^\infty \frac 1 {n^2}$$
Thank you for your time!","['improper-integrals', 'definite-integrals', 'sequences-and-series', 'calculus']"
2284627,How to evaluate inverse trigonometric functions in exponents?,"I recently started working on inverse trigonometry, I have done many problems that include conversion of inverse functions and many more formulas but how should we approach a question when the inverse functions are given in exponents.
For example, I came to a question, $12^{\arcsin(x)} + 12^{\arccos(x)} + 12^{\arctan(x)} >3\cdot k^{\pi/k}$ Find $k$? Can you please provide me a start. I will solve the rest on my own.
Thanks.","['inequality', 'trigonometry']"
2284630,Evaluate $\prod_{n=1}^{\infty}\left(1+\frac{1}{n^2}+\frac{1}{n^4}\right)$,"How do you evaluate $$\prod_{n=1}^{\infty}\left(1+\frac{1}{n^2}+\frac{1}{n^4}\right)$$ using the identity $$\sin(\pi z)=\pi z\prod_{n=1}^{\infty}\left(1-\frac{z^2}{n^2}\right)?$$ I assume I'll have to express $1+\frac{1}{n^2}+\frac{1}{n^4}$ as $\left(1+\frac{a}{n^2}\right)\left(1+\frac{b}{n^2}\right)$ for some $a,b\in\mathbb{C}$ so that I could use the identity given, but I can't seem to factor the above appropriately.","['complex-analysis', 'infinite-product']"
2284650,Number of solutions of the linear equation,"There are two positive integers $a$ and $b$ such that $a \mod b$ is not zero. We find a value $n=\lfloor a/b \rfloor+1$ where $\lfloor .\rfloor$ is the block function. We are supposed to find the number of solutions of the following equation:
$$x_1+x_2+x_3+....x_n=a;\text{ where }1\le x_i \le b \text{ and } 1 \le i \le n.$$ Example: Given: $a=7;b=3$. We get $n =\lfloor a/b \rfloor + 1 = \lfloor 7/3 \rfloor +1 =2+1=3.$ Thus, we need to find the number of solutions of the following equation:
$$x_1+x_2+x_3=7; \text{ where } 1 \le x_i \le 3 \text{ and } 1\le i\le 3.$$ This equation has 6 solutions: $$x_1=1;x_2=3;x_3=3.$$
$$x_1=3;x_2=1;x_3=3.$$
$$x_1=3;x_2=3;x_3=1.$$
$$x_1=2;x_2=2;x_3=3.$$
$$x_1=2;x_2=3;x_3=2.$$
$$x_1=3;x_2=2;x_3=2.$$ Hence for $a=7;b=3$, the answer is $6$. I could find this manually because the values of $a$ and $b$ are small. But for large values of $a$ and $b$ in the order of 100s or 1000s, I need to generalise this.","['linear-algebra', 'systems-of-equations']"
2284662,Find the minimum number of solutions of $g'(x)=0$,"I repeatedly tried to solve it but by no means I could match my answer with the given answer: $5$ The problem goes like this: $y=f(x)$ is differentiable function and $g(x)= f(x - x^2).$ If $y=g(x)$ has local maxima at $x=1/2,$ but the absolute maximum exists at some other point, then minimum number of solutions of $g'(x)=0$ is ________","['maxima-minima', 'calculus', 'functions']"
2284672,Smoothness of $O(n)$-equivariant maps of positive-definite matrices,"$\def\sp{\mathrm{Sym}^+}$Let $\sp \subset GL(n,\mathbb R)$ denote the manifold of positive-definite symmetric $n \times n$ matrices. I am interested in functions $A : \sp \to \sp$ that are equivariant under the natural conjugation action of $O(n)$; i.e. such that$$A(R^T X R) = R^T A(X) R$$ for all $X \in \sp, R \in O(n)$. By choosing $R \in O(n)$ to diagonalize $X$ and then letting $R$ range over reflection and permutation matrices, one can characterize these $A$ as exactly those of the form $$A(X) = \sum_{k=1}^n a(\lambda_k; \lambda_1, \ldots, \widehat{\lambda_k}, \ldots, \lambda_n)e_k \otimes e_k$$ where $\lambda_k>0$ are the (repeated) eigenvalues of $X$ with corresponding (orthonormal) eigenvectors $e_k$ and $a : (0,\infty)^n \to (0,\infty)$ is symmetric in its last $n-1$ arguments. (The $\widehat \lambda_k$ denotes omission.) Since $a(\lambda_1;\lambda_2,\ldots,\lambda_n) = A^{11}(\mathrm{diag}(\lambda_1,\ldots,\lambda_n))$, we know that $A \in C^\infty \implies a \in C^\infty$. My question is: Does the converse hold; i.e. if $a$ is smooth can we conclude that $A$ is smooth? In the analogous problem for $O(n)$-invariant maps $A : \sp \to \mathbb R$ (which reduce to symmetric functions $a : (0,\infty)^n \to \mathbb R$ of the eigenvalues), we can solve this problem using Glaeser's ""differentiable Newton's theorem"" - we get that a smooth symmetric function of the eigenvalues is a smooth function of the symmetric matrix invariants , which are in turn smooth functions of the matrix itself. However, I'm unsure how to transfer this kind of idea to the matrix-valued setting - all I can find are references about invariant scalars (e.g. Schwarz is a nice generalization of Glaeser's result, but still not obviously of use to me). I guess my issue is that I don't know how to retain any regularity when ""packing the eigenvalues back in"", since the eigenspaces are not smooth functions of the matrix. I guess one way you could think of this is as a generalization of functional calculus - if we restrict to $a$ that depend only on their first argument, then (from what I understand) functional calculus is exactly the construction of $A$ from $a$. Some progress: I have managed to prove the polynomial version by finding a recurrence relation of equivariant matrices that induces Newton's identities on the eigenvalues: If $a : (0,\infty)^n \to (0,\infty)$ is a polynomial symmetric in its last $n-1$ arguments, then the output components of the corresponding map $A : \sp \to \sp$ are polynomials in the input components. However, in retrospect I'm not sure if this helps at all in attaining the smooth version. Any input from someone more familiar with this kind of stuff would be greatly appreciated - my representation/invariant/????? theory background is lacking.","['functional-calculus', 'matrix-calculus', 'invariant-theory', 'representation-theory', 'differential-geometry']"
2284686,When does a 2D metric have a 3D-surface representation?,"Certain non-flat, 2D metrics can be visualized as a 3D surface.  The metric for the surface of the unit sphere, $$ds^2 = d\theta^2+\sin^2\theta\,d\phi^2,$$ would be the most familiar example.  Others are more esoteric: in Martin's General Relativity: A Guide ... , he visualizes the following metric as a infinitely long trumpet-shaped surface: $$ds^2=\frac{1}{r^2}dr^2 + r^2d\phi^2,$$ What determines whether or not a 2D metric can be described by a 3D surface?",['differential-geometry']
2284693,Real polynomial is harmonic iff it is real part of complex polynomial,"Exercise 27 (iii): $u:U \rightarrow \mathbb{R}$ is a real polynomial, $\sum _{n,m \ge 0 ; n+m \le d } a_{n,m}x^ny^m $ in $x$ and $y$ for some real coefficients $a_{n,m}$ : Show $u$ is harmonic iff it is real part of polynomial $f(z)$ of one complex variable. I am stuck on $(\Rightarrow)$ . For $(\Rightarrow)$ ,We can substitute $x=\frac{z+\bar{z}}{2}, \, y = \frac{z-\bar{z}}{2i}$ , to obtain $$ u(z) = \sum_{n,m \ge 0 , n+m \le d} c_{n,m} z^n \bar{z}^m \stackrel{*}= \sum_{0 \le k \le d} a_k z^k +b_k \bar{z}^k , \quad c_{n,m}, a_k,b_k \in \mathbb{C} $$ where $(*)$ follows by Exercise 27(ii) as $u(z)$ is harmonic. EDIT: I end the proof as follows: $u(z) = \bar{u}(z)$ for all $z$ , so $$ \sum_{0 \le k \le d} (a_k - \bar{b_k}) z^k + (b_k-\bar{a}_k)\bar{z}^k = 0 $$ for all $z$ . Regarding this as a polynoial in $x,y$ in both real and complex components, we have $a_k - \bar{b}_k = 0 $ for all $k$ . So, $f(z) := \sum_{0 \le k \le d } 2 a_k z^k $ , yields $u = \frac{f+\bar{f}}{2} = Re\,  f(z)$ . Is above proof correct?","['complex-analysis', 'harmonic-functions', 'polynomials']"
2284708,Why probability cannot be defined on the whole power set?,"I'm studying probability. After dealing with discrete probability, my book states that we cannot define such function on an uncountable set, but we need to focus on a subset of it, thus introduces sigma algebras.
But why do we need them in the first place? Why isn't the power set a sigma algebra itself? I cannot see where it does not follow the axioms.
Can you list some examples please?","['probability', 'measure-theory', 'elementary-set-theory']"
2284749,Integer solutions of $x^2+5y^2=231^2$,"I want to find the integer solutions of the equation
$$x^2+5y^2=231^2.$$ My attempt (a sketch): we can use the unique factorisation of ideals in $\mathbb{Z}[\sqrt{-5}]$. Indeed, we have $231=3\cdot 7\cdot 11$.  One can easily show that $3$ and $7$ split in the product of two prime conjugate ideals each, say $\mathfrak{p}$ and $\mathfrak{q}$, where $(3)=\mathfrak{p}\overline{\mathfrak{p}}$ and $(7)=\mathfrak{q}\overline{\mathfrak{q}}$; whereas $11$ remains inert, i.e. $(11)=\mathfrak{r}$ for some self-congugate prime ideal $\mathfrak{r}$.
Then one has $(x+y\sqrt{-5})(x-y\sqrt{-5})= \mathfrak{p}^2\overline{\mathfrak{p}}^2 \mathfrak{q}^2\overline{\mathfrak{q}}^2 \mathfrak{r}^2$. Since $(x+y\sqrt{-5})$ and $(x-y\sqrt{-5})$ are conjugate, we deduce that 
$(x+y\sqrt{-5})= \mathfrak{p} \overline{\mathfrak{p}}\mathfrak{q} \overline{\mathfrak{q}} \mathfrak{r}=(3)(7)(11)=(231)$. Thus the unique integer solutions are $x=231,y=0$, $x=-231,y=0$. Is this correct, or I am missing something?","['number-theory', 'diophantine-equations', 'algebraic-number-theory']"
2284774,Diferential Equation by Laplace: $y'=-\frac{y}{ay+b}+S$,"Hello and thanks for reading. I wish to check the stability of the ODE $$
y'=-\frac{y}{ay+b}+S
$$ by applying the limit theorem of Laplace, where $a$, $b$ and $S$ are real. After some algebra I have: $$
ay'y+by'-aSy-bS+y=0.
$$ When I do Laplace transformation then I have to $L(y'y)$ and can't go on. I need the Laplace expression of $y$. Thanks for your time.","['stability-in-odes', 'ordinary-differential-equations']"
2284792,Binomial expansion of negative exponents.,"Let's say I have to expand $(1+x)^{-1}$ using binomial expansion. Using the theorem, I get: $$(1+x)^{-1} = 1-x+x^2-x^3+x^4-x^5+x^6+....+{\infty}$$ Substituting $x$ for $1$, I get: $$\frac{1}{2}= 1-1+1-1+1-1+1+....+{\infty}$$ A similar result arises with higher power of the exponent For $(1+x)^{-2}$ we get: $$(1+x)^{-2} = 1-2x+3x^2-4x^3+5x^4-6x^5+7x^6+....+{\infty}$$ Substituting $x$ for $1$, I get: $$\frac{1}{4}= 1-2+3-4+5-6+7+....+{\infty}$$ How does this makes sense? Help please!","['binomial-theorem', 'sequences-and-series', 'negative-binomial']"
2284815,How do you actually calculate the conditional expectation in this question?,"I'm taking a course in probability theory and I've come across the following question: Let $\Omega = (0,\infty)$ and $\mathscr{F} = \mathscr{B}((0,\infty))$. Given some $\lambda > 0$ let $\mathbb{P}$ be defined such that $\mathbb{P}((a,b]) = e^{-\lambda a} - e^{-\lambda b}$ (for $0<a<b$). Let: $$X(\omega) = \omega, \ \ Y(\omega) = \text{min}\{\omega, k\}$$ For some $k > 0$. Q. Calculate $\mathbb{E}[X | \sigma(Y)]$ The issue is that I only know what conditional expectation is in terms of its theoretical definition, as a random variable (the same goes for the sigma algebra generated by a variable, such as $Y$ as above). One of my friends has communicated to me the following idea: $$\mathbb{E}[X | \sigma(Y)] = Y\mathbb{1}_{\{Y < k\}} + \dfrac{1}{e^{\lambda k}} \int_k^{\infty} \omega d(1 - e^{-\lambda \omega})\mathbb{1}_{\{Y = k\}}$$ However, I do not understand how one arrives at the expression on the right via the expression on the left. Could somebody help me out and perhaps show me the slower version of how we go from left to right here?","['probability-theory', 'measure-theory']"
2284853,Is hyperbolic $n$-space $\mathbb{H}^n$ the universal cover of every hyperbolic manifold?,"I was under the impression that any hyperbolic manifold (finite volume or not) had $\mathbb{H}^n$ as its universal cover, but on wikipedia it is suggested that this only true for closed hyperbolic manifolds. In that case, what is the universal cover of a noncompact hyperbolic manifold, such as an infinite volume hyperbolic manifold?","['hyperbolic-geometry', 'general-topology', 'covering-spaces', 'differential-geometry']"
2284965,Why is the Jacobian matrix so useful? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 5 years ago . The community reviewed whether to reopen this question 2 years ago and left it closed: Original close reason(s) were not resolved Improve this question I am a first year undergraduate and I always see the Jacobian crop up in some many places, e.g., integration, solving systems of equations, analysis and so many more places. I was wondering, what makes it so useful?","['multivariable-calculus', 'vector-fields', 'jacobian']"
2284996,Cubic formula gives the wrong result (triple checked),"I'd like to solve $ax^3 + bx^2 + cx + d = 0$ using the cubic formula. I coded three versions of this formula, described in three sources: MathWorld , EqWorld , and in the book, ""The Unattainable Attempt to Avoid the Casus Irreducibilis for Cubic Equations"". While I get identical results across all versions, these results are incorrect. For example, for $a=1$, $b=2$, $c=3$, $d=4$, I find incorrect roots: $x_1 = -0.1747 - 0.8521i$, $x_2 = 0.4270 + 1.1995i$, $x_3 = -2.2523 - 0.3474i$. The correct roots are: $x_1 = -1.6506$, $x_2 = -0.1747 + 1.5469i$, $x_3 = -0.1747 - 1.5469i$ In case you're interested, the actual code is below.
Thank you for your help! %% Wolfram version

Q = (3*c - b^2) / 9;
R = (9*b*c - 27*d - 2*b^3) / 54;

D = Q^3 + R^2;
S = (R + sqrt(D))^(1/3);
T = (R - sqrt(D))^(1/3);

x1 = - b/3 + (S + T);
x2 = - b/3 - (S + T) / 2 + sqrt(-3) * (S - T) / 2;
x3 = - b/3 - (S + T) / 2 - sqrt(-3) * (S - T) / 2;

%% Book version

omega1 = - 1/2 + sqrt(-3)/2;
omega2 = - 1/2 - sqrt(-3)/2;

p = (3*a*c - b^2) / (3*a^2);
q = (2*b^3 - 9*a*b*c + 27*(a^3)*d) / (27*a^3);

r = sqrt(q^2/4 + p^3/27);
s = (-q/2 + r)^(1/3);
t = (-q/2 - r)^(1/3);

x1 =        s +        t - b/(3*a);
x2 = omega1*s + omega2*t - b/(3*a);
x3 = omega2*s + omega1*t - b/(3*a);

%% Eqworld version

p = - 1/3  * (b/a)^2 + (c/a);
q =   2/27 * (b/a)^3 - (b*c)/(3*a^2) + d/a;

D = (p/3)^3 + (q/2)^2;
A = (-q/2 + sqrt(D))^(1/3);
B = (-q/2 - sqrt(D))^(1/3);

y1 = A + B;
y2 = - 1/2 * (A + B) + sqrt(-3)/2 * (A - B);
y3 = - 1/2 * (A + B) - sqrt(-3)/2 * (A - B);

x1 = y1 - b / (3*a);
x2 = y2 - b / (3*a);
x3 = y3 - b / (3*a);","['algebra-precalculus', 'cubics', 'roots', 'polynomials']"
2285075,Examples of continuous and bounded Frechet derivatives,"Let $C_b^m(U, V)$ denote the space of not necessarily bounded mappings $g\colon U \to V$ that have $m\ge 1$ continuous and bounded Fréchet derivatives of order $1,\dots,m$. I see $C_b^m(U, V)$ reasonably often, which is endowed with the seminorm $|\cdot|_{C_b^m}$ defined as the smallest constant $C\ge0$ such that
$$
\sup_{u\in U}\|D^m g(u)(x_1,\dots,x_m)\|_{V}\le C \|x_1\|_U\dotsb\|x_m\|_U\text{ for }x_1,\dots,x_m\in U.
$$ Naive examples would be Nemytskii operators. I see if $U$ is a Banach space like $C_b(\overline{\Omega})$, then Nemytskii operator would do. But if $U$ is a Hilbert space, e.g., $L^2$ then differentiability implies that the Nemytskii operator must be generated by affine functions (e.g., Appell--Zabreiko's book, nonlinear superposition operators), which are not interesting. For smooth Sobolev spaces that are Banach algebras, the differentiability is fine but they won't be bounded? I wish to know what are examples of non-trivial (or non-affine) elements in $C_b^m(H,H)$ with $H$ being an (infinite dimensional) Hilbert space.","['functional-analysis', 'reference-request', 'nonlinear-analysis', 'analysis']"
2285076,Does the infinite series $1/(n+1)$ diverge?,"If so, how would one go about showing this? I'm playing around with comparison proofs and wondering if theres a way to show this either diverges or converges (due to it's very close relation to 1/n). Would it be correct to say it diverges due to the fact that as n approaches infinity, the +1 becomes negligible?","['harmonic-numbers', 'divergent-series', 'sequences-and-series', 'convergence-divergence']"
2285105,Find the limit of $\lim_{x\to\infty}\left(\frac{2^{\frac{1}{x}}+3^{\frac{1}{x}}}{2}\right)^{3x}$,"$$\lim_{x\to\infty}\left(\frac{2^{\frac{1}{x}}+3^{\frac{1}{x}}}{2}\right)^{3x}$$ I only managed to show that: $$8=\left(\frac{2^{\frac{1}{x}}+2^{\frac{1}{x}}}{2}\right)^{3x}\leq\left(\frac{2^{\frac{1}{x}}+3^{\frac{1}{x}}}{2}\right)^{3x}\leq\left(\frac{3^{\frac{1}{x}}+3^{\frac{1}{x}}}{2}\right)^{3x}=27$$ I don't know how to bound it better, or maybe there is so simpler way?",['limits']
2285108,"Show that for any $n \in \mathbb N$, $(n^2)!$ is divisible by $(n!)^{n+1}$","I'd like to see if I understand what's discussed in the thread below: prove that $(n^2)!$ is divisible by $(n!)^{n+1}$, where $n\in \mathbb{N}$ Here's what I think: Let $n^2, n^2 - 1, n^2 - 2, \ldots, 1$ stand for balls. We can distribute the balls into $n+1$ distinct boxes $n!$ at a time. Then the number of such distributions is $\binom{(n^2)!}{n!, n!,\ldots,n!}.$ This overcounts the number of partitions of $\{n^2, n^2 - 1, n^2 - 2, \ldots, 1\}$ into $n+1$ sets $n!$ at a time by a factor of $(n+1)!$ Thus, $\frac{1}{(n+1)!}\binom{(n^2)!}{n!, n!,\ldots,n!}$ is the number of partitions of $\{n^2, n^2 - 1, n^2 - 2, \ldots, 1\}$ into $n+1$ sets $n!$ at a time. Since $\frac{1}{(n+1)!}\binom{(n^2)!}{n!, n!,\ldots,n!}$ is an integer, $(n^2)!$ is divisible by $(n!)^{n+1}$. Does that make sense?","['combinatorics', 'multinomial-coefficients', 'set-partition', 'discrete-mathematics']"
2285180,Prove $\frac{1}{r} = \frac{1}{a} + \frac{1}{b}$ for a semicircle tangent within a right triangle,"I have a right angled triangle with the sides which are not hypotenuses $a$ and $b$ . There is also a semi-circle radius $r$ whose diameter lies on the hypotenuse of the right angles triangle, and sides $a$ and $b$ are tangents of the semicircle. Prove that $$\frac{1}{r} = \frac{1}{a} + \frac{1}{b}$$ My attempt: First I drew the diagram: I marked all areas of significance: The vertices opposite side $a$ is $A$ , $b$ to $B$ and $r$ to $C$ . Where the semi circle touches $a$ , I called $P$ , and where it touched $b$ I called $Q$ . The centre of the semicircle I call $O$ . But then, I couldn't proceed. What do I do after this?",['geometry']
2285213,Is the number of dimensions in Hilbert Space countable infinity or uncountable infinity?,"Hilbert Space is an ""infinity"" dimensional vector space. Does the ""infinity"" means $\aleph^0$ or $\aleph^1$ ? Or it does not matter at all? Math newbie thanks you. Could you please up vote for once so I could comment on others' posts?","['functional-analysis', 'infinity', 'hilbert-spaces']"
2285219,$G$- invariant part of push forward,"Let $C$ be a smooth projective curve. Let $G$ be a finite group which acts on $C$. Let $C'=C/G$ the quotient of the action, which is a smooth curve. Then $f:C\rightarrow C'$ is a finite, possibly ramified morphism. 1) Let $L$ be a line bundle on $C$ which admits a $G$-action. What is $(p_*L)^{G}$? Suppose $L=p^*L'$ for some line bundle $L'$, then $(p_*L)^{G}=L'$. 2) Suppose $L$ does not come from below, is $(p_*L)^G$=0? Do we have a characterization as to when $(p_*L)^G=0$? I would like to understand what happens both when $f$ is unramified and $f$ is ramified. Edit: 
It looks like $p^*(p_*L)^G\subset L$. Also that $(p_*L)$ and $(p_*L)^G$ are locally free. By the above inclusion, $(p_*L)^G$ can be at most of rank one. 3) Consider the quotient $p_*L/(p_*L)^G$, is that locally free as well? It would be great if someone can direct me to a reference where such things are explained.",['algebraic-geometry']
2285244,"If $e^\lambda$ is an eigenvalue of $e^A$, then $\lambda$ is an eigenvalue of $A$","Let $A$ be an $n\times n$ matrix. I want to show that if $e^\lambda$ is an eigenvalue of $e^A$, then $\lambda$ is an eigenvalue of $A$. I know the converse is true, but I'm not sure how to go the other way. Our assumption seems to be equating power series to each other, which seem more difficult to work with. Thanks!","['matrix-exponential', 'linear-algebra']"
2285253,Tail Probability for Student's t-Distribution,"Let $n$ be a positive integer, $t < 0$, and let $F_n$ the cumulative distribution function of Student's t-distribution with $n$ degrees of freedom. Then it is a well known fact (which I always found stated without proof) that the sequence $(F_n(t))_{n=1}^{\infty}$ is strictly decreasing. Do you know some proof of the fact that $(F_n(t))_{n=1}^{\infty}$ is a strictly decreasing sequence? NOTE. Note that since we have $F_n(t) \rightarrow \Phi(t)$ as $n \rightarrow \infty$, where $\Phi$ is the cumulative distribution function of the standard normal distribution, from the proof of the monotonicity property above we would get the well known inequality $F_n(t) > \Phi(t)$ for all $n$ (which I found always quoted without proof, too).","['statistical-inference', 'probability-theory', 'statistics', 'probability', 'special-functions']"
2285304,Simplification on stokes theorem problem,"we have a problem , but is more conceptual , than getting the answer, is from larson calculus 9, 15.8.11 and says: $\ F(x,y,z) = 2y\mathbf{i} + 3z\mathbf{j} + x\mathbf{k}$ $\ C: triangle\ with\  vertex\ (2,0,0)\ (0,2,0)\ (0,0,2)$ the answer is not the problem, cause it is -12, the problem is here given that: $\ \int_c \mathbf{F}\cdot d\mathbf{r} = \int_s\int (curl\ \mathbf{F})\cdot \mathbf{N}\ dS $ so $\ curl\ F =\ <-3,-1,-2> $ given the points, we can find two vector, in order to find  $\ \mathbf{N} $ $\ \vec{A} = (2,0,0)-(0,2,0) $ $\ \vec{A} =\ <2,-2, 0 > $ $\ \vec{B} = (2,0,0)-(0,0,2) $ $\ \vec{B} =\ <2,0, -2 > $ $\ \textbf{N} = \vec{A} \times \vec{B}  = <4,4,4>$ how ever if we divide it by 4, we also have $\   \textbf{N}_{1}  = <1,1,1>$ since $\ \textbf{N},  \textbf{N}_{1} $ has to be an unit vector we divide by his magnitude $\  || \textbf{N} || \ = 4 \sqrt 3  $ $\ \frac{\textbf{N}}{|| \textbf{N} ||} = \  \frac{1}{4\sqrt 3} \cdot <4,4,4> $ $\  || \textbf{N}_{1} || \ = \sqrt 3  $ $\ \frac{\textbf{N}_{1}}{|| \textbf{N}_{1} ||} = \  \frac{1}{\sqrt 3} \cdot <1,1,1> $ here is the problem $\ dS = || r_{u} \times r_{v}  || dA $ $\  \textbf{N} =  r_{u} \times r_{v}  $ $\  dS = || \textbf{N} ||dA  $ $\ \int_{D}\int <-3,-1,-2> \cdot\  \frac{1}{4 \sqrt 3} \cdot <4,4,4> \cdot\ 4 \sqrt 3\   dA  = -24 $ $\ \int_{D}\int <-3,-1,-2> \cdot\  \frac{1}{\sqrt 3} \cdot <1,1,1> \cdot\  \sqrt 3\  dA = -12 $ I dont know why the answer is different if mathematically both are the same D = projection in the xy plane, but is not necessary because is the shape that is reflexed on the xy plane is a triangle","['multivariable-calculus', 'stokes-theorem', 'vector-fields']"
2285305,Construct a real function with is exactly $C^2$ such that its first derivative does not vanish everywhere,"I need to construct a real function with is exactly $C^2$ (that is, it is continuous and two times differentiable but it is not three times differentiable) such that its first derivative never vanishes. I tried $x^5 \sin(\frac{1}{x}) + \exp(x)$ $x^{\frac{5}{2}} + \exp(x)$ ${|x|}^3 + \exp(x)$ all these functions are exactly $C^2$, but their first derivatives vanish in some point(s). :(",['functions']
2285346,Check if antiderivative is elementary,"I was experimenting with various integration techniques, and I stumbled upon the integral: $$ \int{\frac{\tan{x}}{x} dx} $$ I tried using a number of methods, but I could not solve it. Checking on WolframAlpha, I found that the integral does not have an elementary antiderivative. However, I am not satisfied with simply assuming it's non-elementary if I have difficulty in solving it. My question: Is there a test to determine if an antiderivative is elementary or not?","['integration', 'calculus']"
2285366,Is there a branch of mathematics that focuses on finding relationship between pairs?,"Lets say you are given a bunch of pairs like
(3, 9),
(4, 16),
(5, 25) The relation between them is that n^2 = m
This one is pretty easy but is there a branch of math that talks about this subject with algorithms to find the simplest relations and theory about the complexity of these relations how much examples you would need to guarantee you found the right one. I don't know anything except basic algebra and calculus but I am interested in this subject so if you can point me in the right direction I would be eternal grateful.","['statistics', 'relations']"
2285392,"Proving by definition $\lim_{(x,y)\to(-1,8)} xy = -8$","I need to prove by definition the following limit: $$\lim_{(x,y)\to(-1,8)} xy = -8$$ I've reached a point where I don't know how to proceed. So given an $\epsilon > 0$ I need to find a $\delta>0$ such that $|f(x,y)+8|<\epsilon$ when $\left\lVert (x,y)-(-1,8)\right\rVert<\delta$. Knowing the distance from $(x,y)$ to the point $(-1,8)$ is less than delta I also know that $|x+1|<\delta$ and $|y-8|<\delta$. So I try to use that in the inequation involving $\epsilon$. $|xy + 8|<\epsilon$ $|xy + 8+1-1+x-x+y-y|<\epsilon$ $|2(x+1)+(y-8)+y(x+1)| \leq 2|x+1| + |y-8| + |y| |x+1|<\epsilon$ $|2(x+1)+(y-8)+y(x+1)| \leq 2|x+1| + |y-8| + |y| |x+1|< 3 \delta + |y| \delta < \epsilon$ So pretty much I don't know what to do with the $|y| \delta$ in $3 \delta + |y| \delta < \epsilon$ Any hints? Thanks!!","['epsilon-delta', 'limits', 'calculus', 'analysis']"
2285412,Defining a repeating series with a simple expression.,"I'm looking for a simple expression with which I can define a repeating series. $$f(0)=0$$ $$f(1)=1$$ $$f(2)=2$$ $$f(3)=3$$ $$f(4)=f(n-4)$$ So, the series goes $0, 1, 2, 3, 0, 1, 2, 3...$ and on and on. I feel like this should have something to do with exponents because in Discrete Math we figured out how to define a series that goes $1, -1, 1, -1...$ but I'm not sure how to even begin defining this. I don't want anything recursive if I can possibly avoid it. Not sure if that will be a problem. Thanks a bunch! EDIT: Spoke to a professor about how to solve this and he says there is a way to do it involving only +/-/*/^/÷, but it involves complex numbers.","['functions', 'closed-form', 'algebra-precalculus', 'sequences-and-series', 'discrete-mathematics']"
2285442,Prove properties of a standard n-simplex,"I would like to prove the following properties for the standard $n$ -simplex whose vertices are $e_i$ in $\mathbb{R^{n+1}}$ and then use the properties of an affine transformation $T$ to generalize to any simplex.  Can you help me simplify the more general proof (in the answer section) and prove the existence of $T$ ? Let the set $S=\left \{ a_{0}, a_{1}, a_{2}, ..., a_{n} \right \} \in \mathbb{R}^{n+1}$ be a geometrically independent set and let $\sigma$ be the simplex spanned by $S$ . Prove The n-simplex $\sigma$ is the union of all line segments joining $a_0$ to points of the simplex $s$ spanned by $\left \{ a_{1}, a_{2}, ..., a_{n} \right \}$ .  Two such line segments intersect only at $a_0$ . The $n$ -simplex $\sigma$ is a compact, convex set in $\mathbb{R}^{n+1}$ which equals the convex hull of $\left \{ a_{0}, a_{1}, a_{2}, ..., a_{n} \right \}$ . Given $\sigma$ , there exists a unique set of geometrically independent points (vertices) spanning $\sigma$ . The interior of $\sigma$ is convex and is open in the plane $P$ ; its closure is $\sigma$ . $Interior(\sigma)$ is the union of all open line segments joining $a_0$ to the points of $Interior(s)$ where $s$ is the face of $\sigma$ opposite $a_0$ .","['algebraic-topology', 'simplex', 'general-topology']"
2285471,Does Chaitin's constant have infinitely many prime prefixes?,"Define $f(n) = \lfloor 2^n \cdot \Omega \rfloor$, that is, $f(n)$ is the first $n$ bits of Chaitin's constant interpreted as a number written in binary. I am trying to figure out if $f(n)$ can have infinitely many prime values.  To show that it cannot, it would suffice to find a way of compressing these prime values to descriptions arbitrarily shorter than $ \log_2{p}$ bits.  This seems to be a tricky task as it runs up against the edge cases of the definitions. Let $L(x) = \lfloor \log_2{x} \rfloor + 1$.  Any number $n$ can be encoded in a prefix-free fashion by first emitting the length of the length of its length in unary, then the length of its length in binary, then its length in binary, then the number itself in binary.  This uses $2 \cdot L(L(L(n))) + L(L(n)) + L(n)$ bits. If we have a prime number $p$, we can improve on this by encoding its index $\pi(p)$, and decoding it with a program that finds the $\pi(p)^{th}$ prime.  By the prime number theorem, we save $L(L(p)) + O(1)$ bits this way.  But the pesky $2 \cdot L(L(L(p)))$ term remains. There is more information we can take advantage of: the $k^{th}$ prime prefix of $\Omega$ is a special type of prime, because it itself has $k-1$ prime prefixes.  So we can count only those primes when decoding it, and heuristically this gives an encoding of size $2 \cdot L(L(L(p))) + L(p) - O(k)$ bits.  Or roughly, prime prefixes of $\Omega$ must be triply-exponentially sparse, as long as for some $c \gt 1$ there are always $O(\frac{n}{c^k \cdot \log{n}})$ primes less than $n$ with exactly $k$ prime prefixes. (I still believe something like this is true but my reasoning here is a bit off.) This approach succeeds on sets with less density than the primes: only a finite number of prefixes of $\Omega$ are primes with prime index (we save $2 \cdot L(L(p))$ bits, bringing the total description length under $L(p)$ by an increasing margin), and similarly only a finite number of prefixes of $\Omega$ are part of a twin prime pair (using Brun's theorem).  Generally, any computable set with density $O((\log{n})^{-1-\epsilon})$ for $\epsilon \gt 0$ has a finite intersection with the prefixes of $\Omega$. What else can be said about this problem? [EDIT: I realized that I asked a very similar question three years ago, but it has gone unanswered and I've made more progress since then which I've explained above.]","['kolmogorov-complexity', 'number-theory', 'logic', 'computability', 'prime-numbers']"
2285524,Is the maximum likelihood estimator an unbiased estimator?,"Given is a random sample $X_1, .., X_n$ drawn from a distribution with the pdf $$ f(x; \theta) = \left\{
\begin{array}{ll}
      \dfrac{1}{4} e^{-\dfrac{1}{4}(x-\theta)} & \theta < x \\
      0 & \text{otherwise} \\
\end{array} 
\right.  $$ with an unknown paramter $\theta$ $(0 < \theta)$. Find the maximum likelihood estimator (MLE) and determine whether or not it's unbiased. So for the MLE I found $X_{1:N}$, since the derivative of the likelihood function is $\dfrac{n}{4}$ with $n>0$, which is always positive so the likelihood function is increasing, which means we should choose the maximum value of $\theta$ possible to maximise the function. Our restriction is $\theta < x$, so the maximum we can choose is $X_{1:n}$. However, for determining its unbiasedness I'm not completely sure. We want to show I guess that $E[X_{1:n}] = \theta$, but I don't really know what to do with the expression $E[X_{1:n}]$ to be able to write it in an appropriate form including $\theta$. How should this be done?","['maximum-likelihood', 'statistics']"
2285531,A geometric construction related to an equidistributed sequence,"Context: I was reading a book when I encountered the following geometric construction in a chapter about equidistributed sequence. Let's construct a series of $N$ points $A_1,\ldots,A_N$ of the plane, where $A_n$ has coordinates $$\left(\mathrm{Re}\left(\sum_{k\leqslant n} e^{2\sqrt 2 i \pi k\log k}\right),\mathrm{Im}\left(\sum_{k\leqslant n} e^{2\sqrt 2 i \pi k\log k}\right)\right).$$ Then let's drawn the lignes $[A_n,A_{n+1}]$ for all $n\in\{1,\ldots,N-1\}$ . Here is what it looks for $N=200$ , $N=1500$ , $N=10^4$ and $N=10^5$ respectively. My questions are the following. What is it behaving like this? What causes those spirals? Can we predict the coordinates of the center of each spiral? Can we predict for which value of $n$ $A_n$ will be at the center of a spiral?","['logarithms', 'sequences-and-series', 'geometry']"
2285559,What is the meaning of non-reduced structure of null-cone for a finite group action. (Related to derived equivalence?),"Suppose $G$ is a finite group acting on a finite dimensional vector space $W$. The null cone is the vanishing of the ideal of the $G$-invariant polynomials that vanish at $0$. Symbolically - $I = \{ f \in S^k(V^) : f(0) = 0, gf = f\}$, and $N = V(I)$. The structure sheaf of the null cone is supported at the origin. This subscheme doesn't have to be reduced. For example, if $C_2$ acts on $\mathbb{C}^2$ by $-1 \to -I$ then the nullcone is the vanishing of $(x^2,xy,y^2)$. If it acts by $\rho(-1)x_1 = -x_1$, $\rho(-1)x_2 = x_2$, then the nullcone is $V(x_1^2,x_2)$. Is there any interesting interpretation of this scheme, or its structure sheaf, relating it to the representation of $G$? For instance, does it determine the representation? Fancily put ... maybe the map from $Rep(G)$ to the Hilbert scheme of points is injective? (Weirdly, this seems to give a natural scheme structure to $Rep(G)$ (each point in $Rep(G)$ gets the structure sheaf of its nullcone). Most groups I know have discrete families of representations, though.) I am vaguely aware that there is some equivalence of (derived?) categories between coherent sheaves supported at the origin and $G$-equivariant coherent sheaves. Or maybe $G$-equivariant local systems?  Or something like that (hazy memory of someone saying something I didn't understand). Is it related?","['derived-categories', 'representation-theory', 'algebraic-geometry']"
2285573,confusion about definition of orbifold,"Here is the definition of an orbifold, from Fulton's The Geometry and Topology of 3-Manifolds : An orbifold $O$ consists of a Hausdorff space $X_O$, with some additional structure. $X_O$ is to have a covering by a collection of open sets $\{U_i\}$ closed under finite intersections.  To each $U_i$ is associated a finite group $\Gamma_i$, an action of $\Gamma_i$ on an open subset $\tilde U_i$ of $\mathbb{R}^n$ and a homeomorphism $\varphi_i\colon U_i \cong \tilde U_i / \Gamma_i$. Whenever $U_i \subset U_j$, there is to be an injective homomorphism $f_{ij}\colon\Gamma_i \hookrightarrow \Gamma_j$ and an embedding $\tilde\varphi_{ij}\colon \tilde U_i \hookrightarrow \tilde U_j$ equivariant with respect to $f_{ij}$ such that the two compositions $U_i \simeq \tilde U_i / \Gamma_i \to \tilde U_j/\Gamma_i \to \tilde U_j/\Gamma_j$ and $U_i \subset U_j \to \tilde U_j/\Gamma_j$ agree. I want to construct a ""spindle"", whose underlying space is $S^2$, with an 2-fold orbifold point at the north pole and an 3-fold orbifold point at the south pole -- but I can't seem to make the construction work, can someone help me? Here's what I've got: define $U_N$ resp. $U_S$ to be neighborhoods of the north resp. south poles, and $V := U_N \cap U_M$ to be the collar where they overlap.  Define $\tilde U_N$ to be the unit disk, acted upon by $\Gamma_{U_N} := \mathbb{Z}/2\mathbb{Z}$ (which acts by rotations by $\pi$); define $\tilde U_S$ and $\Gamma_{U_S}$ similarly.  What should $\tilde V$ and $\Gamma_V$ be?  We have to have inclusions $V \hookrightarrow U_N$ and $V \hookrightarrow U_S$, so $\Gamma_V$ has to be the trivial group.  So $\tilde V = V$.  But now I don't see how the embeddings $\tilde \varphi_{VU_N}, \tilde \varphi_{VU_S}$ can be defined.  (It seems like maybe this would all work if we didn't require $f_{ij}$ to be a monomorphism -- then maybe we could take $\tilde V$ to be a 6-fold cover of $V$.) Help please!","['geometric-topology', 'general-topology', 'differential-geometry', 'geometry']"
2285575,What about the asymptotic behaviour of $\sum_{n=1}^N\frac{\log\operatorname{rad}(n)}{n}$ as $N\to\infty$?,"Motivation. Let $\mu(n)$ the Möbius function and we denote with $$\operatorname{rad}(n)=\prod_{p\mid n}p$$ the radical of an integer $n\geq 1$, see this Wikipedia . Fact. Using that $\mu(n)=0$ iff $\operatorname{rad}(n)<n$, and thus $$\sum_{n=1}^\infty\frac{\mu(n)}{n}\log\frac{n}{\operatorname{rad}(n)}=0+0+\ldots=0,$$ or well seeing the identity $(11)$ from this MathWorld , (by cases 1) $\mu(n)=0$, 2) $\operatorname{rad}(n)=n$ with $\mu(n)=1$ and 3)$\operatorname{rad}(n)=n$ with $\mu(n)=-1$ ) one can to prove $$\sum_{n=1}^\infty\frac{\mu(n)}{n}\log\operatorname{rad}(n)=-1.$$ Since series involving $\operatorname{rad}(n)$ are interestings, I've thought this exercise: Question. We know Chebyshev's result about the asymptotic behaviour of $\sum_{p\leq n}\frac{\log p}{p}$ and since the series  $$\sum_{n=1}^\infty\frac{\log\operatorname{rad}(n)}{n}$$ has positive terms, I know that it diverges. But, is it possible to deduce some more precisely about the asymptotic behaviour of the partial sums $$\sum_{n=1}^N\frac{\log\operatorname{rad}(n)}{n}$$ as $N\to\infty?$ Provide hints, or a detailed answer, as you prefer. Or references if it is well known. Many thanks.","['asymptotics', 'prime-numbers', 'sequences-and-series', 'analytic-number-theory']"
2285597,"In the Collatz conjecture, why are $\max(\textrm{collatz}(n))$ and $\textrm{var}(\textrm{collatz}(n))$ so closely related?","Like the question title reads, in the Collatz conjecture, why are $\max(\textrm{collatz}(n))$ and $\textrm{var}(\textrm{collatz}(n))$ so closely related? See the Figure below for a log-log plot. I refer with $\textrm{collatz}(n)$ to a sequence starting from $n$ (so $\max(\textrm{collatz}(n))$ is the maximum value of the sequence etc). EDIT: oops, I just noticed thet x- and y-labels are in wrong order. Maximum value is on the x-axis. The plot shows the data for sequences starting with $n = 1, ..., 100000$.","['collatz-conjecture', 'variance', 'number-theory', 'sequences-and-series', 'linear-algebra']"
2285600,Can $\mathbb{R}^{+}$ be divided into two disjoint sets so that each set is closed under both addition and multiplication?,"Can $\mathbb{R}^{+}$ be divided into two disjoint nonempty sets so that each set is closed under both addition and multiplication? I know if we only require both sets to be closed under addition then this can be done. For example, this post gives an answer. Thank you very much!","['abstract-algebra', 'real-numbers', 'set-theory', 'axiom-of-choice']"
2285692,Is every Riemann integrable function a uniform limit of step functions?,"Is there a way to prove that every Riemann integrable function is a uniform limit of step functions? If not, does there exist a function that contradicts this?","['real-analysis', 'riemann-integration']"
2285707,An ordinary generating function involving the gamma function,"Is there anything known about ordinary generating functions of the form
$$
S(z;a) = \sum_{n=1}^\infty \Gamma(ani)z^n,
$$
for $z \in \mathbb{C}$ and $a \in \mathbb{R}$, $a \neq 0$. Here $i$ is the imaginary unit. Is there a nice expression for it, or good bounds, in terms of $z,a$? Thanks. Edit 1: An application of the root test and the fact that $|\Gamma(\sigma + it)| \sim \sqrt{2\pi}|t|^{\sigma - 1/2}e^{-\pi |t|/2}$ as $|t| \to \infty$, for $\sigma$ fixed (see for instance Corollary 16 here ) shows that $S(z;a)$ has radius of convergence $e^{\pi|a|/2}$. Edit 2: I have also posted this question here","['generating-functions', 'gamma-function', 'analysis']"
2285726,"Justifying ""determinant"" of second fundamental form using the definition of sectional curvature","Question: if $M\subseteq \widetilde{M}$ is a non-degenerate hypersurface in a pseudo-Riemannian manifold $M$, then is it true that $$\langle X, \widetilde{\nabla}_XN\rangle =\langle Y, \widetilde{\nabla}_YN\rangle $$for all $X,Y$ tangent to $M$, where $N$ is a unit normal to $M$? Context: Today I saw in class the definition of sectional curvature and I thought that I might check as a self-posed exercise that the Gaussian curvature of a non-degenerate surface in Minkowski space is really given by the ""determinant"" $$K = \frac{\langle {\rm II}(X,X), {\rm II}(Y,Y) \rangle - \langle {\rm II}(X,Y), {\rm II}(Y,X)\rangle }{\langle X,X\rangle\langle Y,Y \rangle - \langle X,Y \rangle^2},$$as in page $118$ of Kühnel's Curves, Surfaces, Manifolds book, where ${\rm II}$ is the vector-valued second fundamental form and $X$ and $Y$ form a basis of the tangent plane to the surface. This always bothered me, so let's get on to it. Assume that $M$ is a non-degenerate submanifold of a pseudo-Riemannian manifold $\widetilde{M}$ (with induced metric), with Levi-Civita connections $\nabla$ and $\widetilde{\nabla}$. Then $$\nabla_XY = \widetilde{\nabla}_XY - {\rm II}(X,Y),$$where ${\rm II}$ is the second fundamental form, normal to $M$. Terms in blue below are normal, so they die in the process. Great, then $$\begin{align} K^\nabla_{{\rm span}(X,Y)} &= \frac{\langle R^\nabla(X,Y)Y,X\rangle}{\langle X,X\rangle\langle Y,Y \rangle - \langle X,Y \rangle^2} \\ &= \frac{\langle \nabla_X\nabla_YY - \nabla_Y\nabla_XY - \nabla_{[X,Y]}Y,X\rangle}{\langle X,X\rangle\langle Y,Y \rangle - \langle X,Y \rangle^2} \\ &= \frac{\langle \widetilde{\nabla}_X\nabla_YY - \color{blue}{{\rm II}(X,\nabla_YY)} - \widetilde{\nabla}_Y\nabla_XY + \color{blue}{{\rm II}(Y,\nabla_XY)} - \widetilde{\nabla}_{[X,Y]}Y+\color{blue}{{\rm II}([X,Y],Y)},X\rangle}{\langle X,X\rangle\langle Y,Y \rangle - \langle X,Y \rangle^2} \\ &= \frac{\langle \widetilde{\nabla}_X\nabla_YY  - \widetilde{\nabla}_Y\nabla_XY  - \widetilde{\nabla}_{[X,Y]}Y,X\rangle}{\langle X,X\rangle\langle Y,Y \rangle - \langle X,Y \rangle^2} \\ &= \frac{\langle \widetilde{\nabla}_X\widetilde{\nabla}_YY - \widetilde{\nabla}_X({\rm II}(Y,Y))  - \widetilde{\nabla}_Y\widetilde{\nabla}_XY +\widetilde{\nabla}_Y({\rm II}(X,Y)) - \widetilde{\nabla}_{[X,Y]}Y,X\rangle}{\langle X,X\rangle\langle Y,Y \rangle - \langle X,Y \rangle^2} \\ &\color{darkred}{\stackrel{!!!}{=}\frac{\langle R^\widetilde{\nabla}(X,Y)Y+  \widetilde{\nabla}_Y({\rm II}(X,Y)) - \widetilde{\nabla}_X({\rm II}(X,X)), X\rangle}{\langle X,X\rangle\langle Y,Y \rangle - \langle X,Y \rangle^2}}\\ &= K^\widetilde{\nabla}_{{\rm span}(X,Y)}+ \frac{\langle \widetilde{\nabla}_Y({\rm II}(X,Y)) - \widetilde{\nabla}_X({\rm II}(X,X)),X\rangle}{\langle X,X\rangle\langle Y,Y \rangle - \langle X,Y \rangle^2}\end{align}$$This seems nice in general, so now assume $\widetilde{M} = \Bbb R^3_1$ (hence $K^\widetilde{\nabla}_{{\rm span}(X,Y)}=0$) and that $M$ is a surface. If $\epsilon = \langle N,N\rangle$, where $N$ is a unit (hence non-lightlike) normal field to $M$, we have that $${\rm II}(X,Y) = -\epsilon \langle Y, \widetilde{\nabla}_XN\rangle N.$$ Discarding normal components, we have: $$\begin{align} \langle \widetilde{\nabla}_Y({\rm II}(X,Y)) - \widetilde{\nabla}_X({\rm II}(X,X)),X\rangle &= \langle \widetilde{\nabla}_Y(-\epsilon \langle Y, \widetilde{\nabla}_XN\rangle N) - \widetilde{\nabla}_X(-\epsilon \langle X, \widetilde{\nabla}_XN\rangle N),X\rangle \\ &= \epsilon \left( \langle X, \widetilde{\nabla}_XN\rangle \color{red}{\langle X, \widetilde{\nabla}_XN\rangle} - \langle Y, \widetilde{\nabla}_XN\rangle\langle X, \widetilde{\nabla}_YN\rangle\right). \end{align}$$On the other hand: $$\begin{align} \langle {\rm II}(X,X), {\rm II}(Y,Y) \rangle - \langle {\rm II}(X,Y), {\rm II}(Y,X)\rangle &= \langle \langle X, \widetilde{\nabla}_XN\rangle N, \langle Y, \widetilde{\nabla}_YN\rangle N \rangle - \langle \langle Y, \widetilde{\nabla}_XN\rangle N, \langle X, \widetilde{\nabla}_YN\rangle N\rangle \\ &= \epsilon \left( \langle X, \widetilde{\nabla}_XN\rangle \color{red}{\langle Y, \widetilde{\nabla}_YN\rangle} - \langle Y, \widetilde{\nabla}_XN\rangle\langle X, \widetilde{\nabla}_YN\rangle
 \right)\end{align}$$ Did I screw up somewhere in the end, or do we have $\langle X, \widetilde{\nabla}_XN\rangle =\langle Y, \widetilde{\nabla}_YN\rangle $?","['semi-riemannian-geometry', 'riemannian-geometry', 'differential-geometry', 'curvature']"
2285755,Find a sufficient statistic for $\theta$ and show that a UMP test of $H_0: \theta = 6$ against $H_1:\theta <6$ is based on this statistic. [duplicate],"This question already has an answer here : (Uniformly) Most Powerful test (1 answer) Closed 7 years ago . (20%) Let $X_1, \dotsc, X_n$ be an iid sample from a distribution with pdf $f(x;\theta) = \theta x^{\theta-1}, 0< x< 1$, zero elsewhere, where $\theta >0$. Find a sufficient statistic for $\theta$ and show that a UMP test of $H_0: \theta = 6$ against $H_1:\theta <6$ is based on this statistic. I used the exponential family form to get that the summation of $\ln(x)$ is a sufficient statistic for $\theta$, but I do not know how to find a UMP Test based on this statistic. I believe it has something to do with likelihood ratios. Thanks in advance for your help. My question is different from that question because I do not already have a MP test, these are different numbers, the pdf is different, the significance level is not given, and the alternative hypothesis is an inequality.","['statistics', 'hypothesis-testing', 'probability-distributions']"
2285761,Is there some approach to make functional integrals rigorous?,"Quantum Mechanics and Quantum Field Theory can both be formulated in terms of the so-called functional integrals. The point is that intuitively it is an ""integral over all possible paths"" or rather ""integral over all possible field configurations"", traditionaly denoted as $$\int A[\gamma(t)]\mathcal{D}\gamma(t)$$ $$\int A[\phi(x)]\mathcal{D}\phi(x)$$ for respectively paths and fields. It seems however that this is not well defined. I really don't understand how can one manipulate something that isn't defined, so I'm searching for the right way to understand these things. Is there some way to make sense of these objects? I heard that as traditional measures it is not possible, but is there any other alternative way to make this be defined? If there is no way, how can someone work with one object that has no meaning associated with it and compute things with it?","['functional-calculus', 'mathematical-physics', 'functional-analysis', 'quantum-field-theory', 'measure-theory']"
2285779,Subsets of a vector space that are convex and have convex complement.,"Let $V$ be a vector space over some field $F$. Is there a characterization of the subsets $A$ that are convex and also have convex complement? Maybe when the dimension is finite it is possible? I think that in $\mathbb R^n$ we can define it recursively, by using nested semihyperplanes.","['general-topology', 'convex-geometry', 'real-analysis', 'geometry']"
2285795,Are complex conjugate gaussian integers always relatively prime?,"Trying to find general formulas for gcd of gaussian integers. I noticed that there seems to be a pattern where the factorization of $(a+bi)=(1+i)(\frac{a+b}{2} + \frac{b-a}{2}i)$ and $(b+ai)=(1+i)(\frac{a+b}{2} - \frac{b-a}{2}i)$ if a and b are relatively prime odd integers. My question is, will $(\frac{a+b}{2} + \frac{b-a}{2}i)$ and $(\frac{a+b}{2} - \frac{b-a}{2}i)$ always be relatively prime?","['number-theory', 'gaussian-integers', 'gcd-and-lcm']"
2285796,"If a family of functions has an unbounded derivative, is it necessarily not uniformly equicontinuous?","I'm having trouble wrapping my head around uniform equicontinuity for a family of functions. I can often spot if a family is uniformly equicontinuous, but have trouble telling when they're not, and I was wondering if there are any signs which would allow me to spot the non-uniformly equicontinuous families. Intuitively, it seems to me that if the derivative of a family of functions is unbounded then it can't be uniformly equicontinuous. For example, if the family is given by $F=\{f_n:n\in\mathbb N\}$ and $\forall n \in \mathbb N$,  $|f_n'(x)|=|e^{n}|$, then it seems to me that the family cannot be uniformly equicontinuous. Since this isn't a common theorem, I'm guessing my intuitiong is wrong, but a proof or a counter example would be very helpful, thanks! Note: my definition of uniform equicontinuity is the following: A family of functions, $F$, consisting of functions $f:(X,d)\to (Y,\rho)$ is uniformly equicontinuous on $X$ if for every $\epsilon >0 $ there exists $\delta >0$ such that $$d(x,y)<\delta \implies \rho(f(x),f(y))<\epsilon$$
for all $x\in X$ and $f \in F$. The key here is that $\delta$ depends on $\epsilon$, but not on $x$ or $f$.","['uniform-continuity', 'real-analysis', 'equicontinuity', 'analysis']"
2285893,Jacobian question -,"I am stuck on a question in my calc III class which is shown above (part a). I completely understand how to find the Jacobian; however I don't understand why the relationship shown is true. How do I find the inverse transformation? In terms of the Jacobian, I got $$J = \frac{1}{2u}$$. Thanks for your time.","['multivariable-calculus', 'calculus']"
2285907,$f^{(n)}(0)=0$ and $|f^{(n)}(x)|\leq n!$ implies $f=0$,"Let $f$ be a $C^\infty$ function such that $f^{(n)}(0)=0$ and $|f^{(n)}(x)|\leq n!$ for all integer $n$ and real $x$.
How to prove that $f(x)=0$ for all real $x$. I proved this only for $x\in(-1,1)$ using Taylor-Lagrange Formula by showing that $$|f(x)|\leq x^{n+1}$$ for all integer $n$ and real $x$.","['derivatives', 'real-analysis', 'taylor-expansion']"
2285910,Closed-form solution of a nonlinear system of differential equations,"I've come up with a nonlinear system of differential equations while analyzing a system approaching chemical equilibrium. This is the equation.
$$
\left\{\begin{aligned}
\frac{dx}{dt}&=px-qx(y+z)-rx(x+y+z)\\
\frac{dy}{dt}&=py-qy(z+x)-ry(x+y+z)\\
\frac{dz}{dt}&=pz-qz(x+y)+r((x+y)^2-z^2)\\
\end{aligned}\right.$$
$x(0)=x_0$, $y(0)=y_0$, $z(0)=0$, $p,q,r$ arbitrary constants I've tried solving the equations using Wolfram Mathematica and Wolfram|Alpha, yet neither could find a closed-form solution to them. Is it that such solution doesn't exist, or is there a way of finding one, given enough time and computation power? Btw, I've tried setting $p = 50$, $q = 5$, $r = 5$ and have obtained numerical graphs of the equations. The curve at the bottom apparently converging to 0 is a plot of $y(t)$, with the one immediately next to it (also converging to 0) being a plot of $x(t)$. The curve that appears to converge to somewhere near 4 is a plot of $z(t)$. However, zooming in a bit more into the curve corresponding to $z(t)$, we find that the function actually is still undergoing oscillation, even for a value of t as high as t = 2.3. Thanks!",['ordinary-differential-equations']
2285916,"Calculate $\lim_{n\to\infty}\int_{[0,n]}(1+\frac{x}{n})^ne^{-2x}dx$ .","It is required to calculate $\lim_{n\to\infty}\int_{[0,n]}(1+\frac{x}{n})^ne^{-2x}dx$. The following is my attempt. $\int_{[0,n]}(1+\frac{x}{n})^ne^{-2x}dx=\int_{[0,\infty)}(1+\frac{x}{n})^ne^{-2x}\chi_{[0,n]}dx$ for each $n\in\mathbb{N}$. Let $g_n(x)=(1+\frac{x}{n})^ne^{-2x}\chi_{[0,n]}dx$ for each $n\in\mathbb{N}$ and $x\in[0,\infty) $.Then $g_n(x)\leq e^{-x}$ for each $x\in[0,\infty)$ and $n\in\mathbb{N}$. $\int_{[0,\infty)}e^{-x}dx$ exists. Moreover $g_n(x)$ converges to $g(x)=e^{-x}$ for each $x$. Then by Dominated Convergence theorem $\lim_{n\to\infty}\int_{[0,n]}(1+\frac{x}{n})^ne^{-2x}dx=\int_{[0,\infty)}e^{-x}dx$. Could someone please tell me if my solution is alright? Thanks.","['self-learning', 'lebesgue-integral', 'measure-theory', 'proof-verification']"
2285972,Probability problem gives different answers with different methods,"In a box there are $4$ red ball, $5$ blue balls and $6$ green balls.$4$ balls are picked at random. What is the probability the at least one ball is green and at least one ball red $?$ Method $1$: Now,in how many ways can this be done $?$ $1.$ $1$ red,$1$ green,$2$ blue. $2.$ $2$ red,$1$ green,$1$ blue. $3.$ $1$ red,$2$ green,$1$ blue. $4.$ $2$ red,$2$ green,$0$ blue. $5.$ $3$ red,$1$ green,$0$ blue. $6.$ $1$ red,$3$ green,$0$ blue. So the all possible cases are obtained by adding these cases,i.e. , $${^6C_1} \times {^5C_2} \times {^4C_1} + {^6C_2} \times {^5C_1} \times {^4C_1} + {^6C_1} \times {^5C_1} \times {^4C_2} + {^6C_2} \times  {^4C_2} + {^6C_3} \times {^4C_1} + {^6C_1}  \times {^4C_3} \\= 914.$$ So the probability is ${914\over {({_{15} C_4})}}={914\over 1365}$ Method $2$: Probability of at least $1$ red ball and at least $1$ green ball = $1$- Probability of no red or green ball, i.e. all balls are blue =$1-{5\over 1365} = {1360\over 1365}.$ Why these two methods give different answers? Are one or both of them wrong $?$ How?","['probability-theory', 'probability', 'proof-verification']"
2285983,A $H^{-1}$ norm of a $L^2$ function,"Let $P\in L^2(\Omega)$ (where $\Omega=[0,2\pi]^n$),  be a function such that : $\forall x=(x_1,...,x_n)\in \Omega,\;P(x)=\sum_{j_1=-\infty}^{+\infty}...\sum_{j_n=-\infty}^{+\infty}a_{j}e^{ij.x}$ with $j.x=j_1x_1+...+j_nx_n$. How can I figure out $$\left \| P \right \|_{H^{-1}(\Omega)}\; \text{and}\;\; \left \| \nabla P \right \|_{(H^{-1}(\Omega))^n}\;,$$ 
I will appreciate if you could help me . Thanks. PS: I want to prove that: $$\left \| P \right \|_{L^{2}(\Omega)}\; \leq c\big(\left \| P \right \|_{H^{-1}(\Omega)}+\; \left \| \nabla P \right \|_{(H^{-1}(\Omega))^n}\;\big).$$ Directly using the calculations, and without using any particular inequality (in particular the inequality of $Ne\check{c}as$.) Here what I did: This is not an answer but it's the idea that i have, if some one can complete it: Let's try to characterize $\left \| P \right \|_{H^{-1}(Q)}$ and $\left \| \nabla P \right \|_{(H^{-1}(Q))^d}$.
We have :
$$\left \| P \right \|_{H^{-1}(Q)}\geqslant \frac{\left \langle P,\phi \right \rangle}{ \left \| \phi \right \|_{H^1(Q)}}\;,\:\: \forall \phi \in H_0^1(Q)$$ 
In particular for each $N\in \mathbb N$, Let $$\phi_N(x)=\sum_{j\in[-N,N]^d} (1+\left | j \right |^2)^{-1}\;\overline{a_j}\;e^{i\,j.x} \;,\;\forall x\in Q$$ 
We have:
\begin{align*}
   \left \| \phi_N \right \|_{H^1(Q)}&=(\sum_{j\in[-N,N]^d }\; (1+\left | j \right |^2)(1+\left | j \right |^2)^{-2}\;\left | a_j \right |^2)^\frac{1}{2} \\
    &=  (\sum_{j\in[-N,N]^d}\; (1+\left | j \right |^2)^{-1}\;\left | a_j \right |^2)^\frac{1}{2}
\end{align*}
So,
\begin{align*}
\left \| P \right \|_{H^{-1}(Q)} &\geqslant \frac{\left \langle P,\phi_N \right \rangle}{ \left \| \phi_N \right \|_{H^1}}\\
&=\frac{\sum_{j\in[-N,N]^d}\; (1+\left | j \right |^2)^{-1}\;\left | a_j \right |^2}{(\sum_{j\in[-N,N]^d}\; (1+\left | j \right |^2)^{-1}\;\left | a_j \right |^2)^\frac{1}{2}}\\
&=(\sum_{j\in[-N,N]^d}\; (1+\left | j \right |^2)^{-1}\;\left | a_j \right |^2)^\frac{1}{2}\;,\;\forall N\in\mathbb N
\end{align*}
So, $\left \| P \right \|_{H^{-1}(Q)} \geqslant (\sum_{j\in\mathbb Z^d}\; (1+\left | j \right |^2)^{-1}\;\left | a_j \right |^2)^\frac{1}{2}$ I want to use the same idea (Find $\phi _N$) to prove that: $\left \| \nabla P \right \|_{(H^{-1}(Q))^d} \geqslant (\sum_{j\in\mathbb Z^d}\; \left | j \right |^2(1+\left | j \right |^2)^{-1}\;\left | a_j \right |^2)^\frac{1}{2}$
Can you help me?","['real-analysis', 'normed-spaces', 'calculus', 'functional-analysis', 'sobolev-spaces']"
2286058,Why does this numerical overflow error result in vectors with smaller sums?,"This is, I think, a math puzzle, but it will take a bit to explain. I wanted to create a subset of loosely defined ""similar"" digits from the MNIST dataset . MNIST is a dataset of grayscale, handwritten digits, 0-9. They are represented as ($32 \times 32$)-dimensional integer vectors with the values 0 (black) to 255 (white). To find clusters of similar digits, for each class of digit I selected the 200 most similar digits as measured by the cosine distance with respect to a randomly selected base digit. The only problem is, my data was loaded into NumPy as an 8-bit integer array. The result is that I miscomputed the cosine distance as can be seen here . Here's the weird thing: my script sort of worked. After realizing that the cosine distance was being incorrectly computed due to an overflow error, I did a sanity check. For every digit in the original MNIST dataset, I computed its sum, and then took 200 digits from each class with the smallest sums. When I compared the overlap, 26% of the digits in the faux-cosine-distance dataset were in the smallest-sums dataset. Is there any reasonable hypothesis as to why this seems to work?",['discrete-mathematics']
2286094,Concave function of Weingarten operator and convex cone of matrices,"Picture below is from 143 page of Huisken, Gerhard; Sinestrari, Carlo , Mean curvature flow with surgeries of two-convex hypersurfaces , Invent. Math. 175, No. 1, 137-221 (2009). ZBL1170.53042 . $A=\{h_{ij}\}$ is the second fundamental form . Weingarten operator is $W=\{h^i_j\}$. Denote by $\lambda_1\le\cdot\cdot\cdot\le\lambda_n$ the principal curvature. First, I understand Weingarten operator as a matrix or a linear map from tangent space to tangent space. So, how the Weingarten operator applied to two tangent vectors? Second, why $\lambda_1 +\lambda _2$ is concave function of the Weingarten operator ? I just know what is concave function, but don't know what is concave function of a operator. Third, what is the convex cone of matrices ? I just know convex cone is a subset of a vector space that is closed under linear combination.","['mean-curvature-flows', 'riemannian-geometry', 'differential-geometry', 'vector-spaces']"
2286098,Is the Fourier transform of a compactly supported $L^1$ function $C^{\infty}$,My professor often hints that the Fourier Transform of a compactly supported $L^1$ function is of class $C^{\infty}$. Is this always true? How can I see this?,"['complex-analysis', 'lebesgue-integral', 'fourier-transform']"
2286099,"What really is the difference between $\mathbf{v}=(2,3) $ and $\mathbf{u}=(2,3,0)$?","I used to believe that there is no difference between $\mathbf{v}=(2,3)$ which is a vector lying in $xy$ plane and $\mathbf{u}=(2,3,0)$ which is a three dimensional vector but still lying in $xy$ plane. So, for me both the vectors $\mathbf{v}$ and  $\mathbf{u}$ were same. The analogy I used was that both the tail and head coincide for $\mathbf{v}$ and $\mathbf{u}$. But on the second page of the textbook I am using as reference (Gilbert Strang-Introduction to linear algebra), I found something different . The author says, The vector $(x,y)$ in a plane is different from vector $(x,y,0)$ in $3-$space . That's it. Since this statement is not well explained there so I am here. Hoping for help. Since I am beginning the Linear algebra course so Please show some tolerance. Thanks.",['linear-algebra']
2286111,Is this question about differentiability wrong?,"In my textbook, I found the following exercise: Show that the following vector field is differentiable at $(0,0,0)$:
  $$G(x,y)=\left(\frac {x^3 + y^3}{\sqrt{x^2 + y^2}},\frac {1}{x^2 + y^2 + 1}\right)$$ However, I see that it is not even continuous at the origin, so it cannot be, in any way, differentiable. Is this right or am I missing something? All help will be greatly appreciated.","['derivatives', 'continuity', 'vector-analysis']"
2286115,How to find closed form for $\int_{0}^{1}\ln^k{x}\ln(1+x+x^2+\cdots+x^n){\mathrm dx\over x}=F(k)\zeta(k+2)?$,Proposed: $$\int_{0}^{1}\ln{x}\ln(1+x+x^2+\cdots+x^n){\mathrm dx\over x}=-{n(n+2)\over (n+1)^2}\zeta(3)\tag1$$ and $$\int_{0}^{1}\ln^k{x}\ln(1+x+x^2+\cdots+x^n){\mathrm dx\over x}=F(k)\zeta(k+2)\tag2$$ My try: $$\int_{0}^{1}\ln^k{x}\ln\left({x^{n+1}-1\over x-1}\right){\mathrm dx\over x}=\tag3$$ $$\int_{0}^{1}\ln^k{x}\ln(x^{n+1}-1){\mathrm dx\over x}-\int_{0}^{1}\ln^k{x}\ln(x-1){\mathrm dx\over x}\tag4$$ How do we evaluate the closed form for $(2)?$,"['integration', 'definite-integrals', 'calculus']"
2286167,Show an operator on $L^2$ is compact,"Let $X$ be the complex Lebesgue space $L^2(0,1)$. Let $T:X\to X$ be $(Tf)(x)=x\int_0^1 \int_0^r f(s)\ ds\ dr-\int_0^x\int_0^r f(s)\ ds\ dr$ Prove that $T$ is compact. Given a bounded sequence $\{f_n\}$ in $X$, we want to show $\{Tf_n\}$ has a convergent subsequence. I have shown that $|Tf(x)|\leq 2\lVert f \rVert$. Hence $\lVert Tf_n \rVert \leq 2 \lVert f_n \rVert$. Since $\{f_n\}$ is bounded, then $\{Tf_n\}$ is bounded. Hence there is a weakly convergent subsequence $\{Tf_{n_k}\}$. Then I don't know how to go from weakly convergent to strong convergent.","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
2286180,Visualizing the 4th dimension.,"In a freshers lecture of 3-D geometry , our teacher said that 3-D objects can be viewed as projections of 4-D objects. How does this helps us visualize 4-D objects?
I searched that we can at least see their 3-D cross-sections. A Tesseract hypercube would be a good example. Can we conclude that a 3-D cube is a shadow of a 4-D tesseract? But,  how can a shadow be 3-D ? Was the screen used for casting shadow also 3-D ; or else, what way is it different from basic physics of shadows we learnt? edit: The responses are pretty good for 4th dimensional analysis, but can we generalize this projection idea for n dimensions, i.e. all n dimensional objects will have n-1 dimensional projections? This makes me think about higher dimensions discussed in string theory . What other areas of Mathematics will be helpful?","['visualization', 'geometry']"
2286194,An Integral Inequality for $C_c^{\infty}(\mathbb{R}^3)$,"I stumbled upon the following inequality where $f \in C_c^{\infty}(\mathbb{R}^3)$: $$
\left( \int \int_{\mathbb{R}^6} \frac{\overline{f(x)} f(y)}{\vert x-y \vert}dxdy \right) \Vert\nabla f\Vert_2^2 \geq 4 \pi \Vert f\Vert_2^4
$$ where $\overline{f(x)}$ denotes complex conjugation. Unfortunately, I have no idea how to prove it. I don't even know why the left-hand side should be non-negative. The symmetry of the left-hand side and the $4 \pi$ on the right suggests some kind of transformation into a polar coordinates or use of the co-area formula. I'm also curious about generalizations to $\mathbb{R}^d$, i.e. if something like $$
\left( \int \int_{\mathbb{R}^{2d}} \frac{\overline{f(x)} f(y)}{\vert x-y \vert}dxdy \right) \Vert\nabla f\Vert_2^2 \geq \omega_n \Vert f\Vert_2^4
$$ holds for $f \in C_c^{\infty}(\mathbb{R}^d)$, where $\omega_n$ is the surface area of the $d$-dimensional sphere.","['inequality', 'fourier-analysis', 'integral-inequality', 'integration', 'analysis']"
2286252,Baby Rudin Chapter 1 Problem 16,"I am attempting to self-study through Baby Rudin and I have done every exercise in chapter 1 except for problem 16. Every solution I find on the internet for this problem uses theorems from linear algebra which I have no background in. I don't want to go on to chapter 2 without completing chapter 1. Can anyone provide an explanation of this problem that does not assume prerequisite knowledge of linear algebra? Suppose $k \geq 3$, $x, y \in R^k$, $|x-y| = d>0$, and $r>0$. Prove: (a) If $2r>d$ there are infinitely many $z \in R^k$ such that $|z-x| = |z-y| = r $ (b) If $2r = d $ there is exactly one such $z$. (c) If $2r < d$ there is no such $z$. My work so far: (c) is a trivial consequence of the triangle inequality. In about 2 weeks I have been unable to make any progress on (a) or (b).","['real-analysis', 'linear-algebra']"
2286261,How can we write the product of $n$ cosines?,"We know that 
$$2\cos k _1 x \cdot\cos k_2x = \cos(k_1+k_2)x + \cos (k_1-k_2)x$$ How can we write the product of $n$ cosines? $$4 \cos k _1 x \cdot\cos k_2x \cdot \cos k_3 x =\cos(k_1+k_2+k_3)x \\+\cos(-k_1+k_2+k_3)x +\cos(k_1-k_2+k_3)x \\+\cos(k_1+k_2-k_3)x $$ $$8 \cos k _1 x \cdot \cos k_2x\cos k_3 x\cdot \cos k_4x=\cos(k_1+k_2+k_3+k_4)x\\+\cos(-k_1+k_2+k_3+k_4)x+\cos(k_1-k_2+k_3+k_4)x\\+\cos(k_1+k_2-k_3+k_4)x+\cos(k_1+k_2+k_3-k_4)x\\+\cos(-k_1+k_2+k_3-k_4)x+\cos(k_1-k_2+k_3-k_4)x\\+\cos(k_1+k_2-k_3-k_4)x$$ $$2^n \cos k _1 x \cdot\cos k_2x\cdots  \cos k_n x=?$$","['number-theory', 'trigonometry', 'linear-algebra', 'trigonometric-series']"
2286266,Difference between Measurable and Borel Measurable function,"Definition of measurable function : 
If $X$ is measurable space, $Y$ is topological space, then $f:X\to Y$ is measurable provided that $f^{-1}(V)$ is measurable set in $X$ for every open set $V$ in $Y$. Definition of Borel measurable function : If $f:X\to Y$ is continuous mapping of $X$, where $Y$ is any topological space, $ (X,\mathfrak B)$ is measurable space and $f^{-1}(V)\in\mathfrak B$ for every open set $V$ in $Y$, then $f$ is Borel measurable function. Both functions are mapping from measurable space to topological space what's the difference between the two definition?","['functional-analysis', 'measure-theory']"
2286298,"Proving that $GL(n,\mathbb R)$ is an open subset of $M_n(\mathbb R)$ [the direct way]","Definition: $GL(n,\mathbb R)$ is the set of all $n \times n$ invertible matrices like $A$ such that $det(A)\neq 0$. $M_n(\mathbb R)$ is simply the set of all $n\times n$ matrices. Question: Prove that $GL(n,\mathbb R)$ is an open subset of $M_n(\mathbb R)$ using the definition of an open set Note: I know the proof that gets help from the continuity of $det$ function and the fact that $\mathbb R - \{0\}$ is open. But, I want a proof which works just with the direct definition of open subsets (which can be found here ). Any idea?",['general-topology']
2286305,Differentiability of the remainder in Taylor's theorem (1D vs 2D),"I am interested in the Lagrange's form of the remainder for $C^1$ function $f$ defined in a convex neighborhood of the origin. One dimension case. Let $f:\Omega\to\mathbb{R},$ where $0\in\Omega\subset\mathbb{R}.$ Then
$$f(x)=f(0)+\overbrace{x\int_0^1\frac{\partial f}{\partial x}(tx)dt}^{R(x)}.$$
Two dimensions case. Let $f:\Omega\to\mathbb{R},$ where $(0,0)\in\Omega\subset\mathbb{R}^2.$ Then
$$f(x,y)=f(0,0)+\overbrace{x\int_0^1\frac{\partial f}{\partial x}(tx,ty)dt}^{R_x(x,y)}+\overbrace{y\int_0^1\frac{\partial f}{\partial y}(tx,ty)dt}^{R_y(x,y)}.$$
Some people may call above formulas Hadamard's lemma, but I will stick to Taylor's formula. Clearly $R$ is $C^1$ cause $R(x)=f(x)-f(0).$ However we cannot use the same argument for multivariable case. Question. Are $R_x,R_y$ also $C^1$?","['multivariable-calculus', 'taylor-expansion', 'calculus', 'derivatives']"
2286309,Writing a function as a sum of its odd and even parts,"I have the following question and the solution along with it but I can't get my head around what's been done. The aim is to write the following function as a sum of even and odd functions: $h(x) = 
\begin{cases}
1,  & \text{if $x<0$} \\
e^x, & \text{if $ x\geq 0$}
\end{cases}
$ I am aware that any function $f(x)$ can be written as: $f(x) = \underbrace{\frac{1}{2}(h(x)+h(-x))}_{f_{even}(x)}+ \underbrace{\frac{1}{2}(h(x)-h(-x))}_{f_{odd}(x)}$ I attempted to do it myself but it was incorrect. The correct method was to find the following: We have $h(-x) = 
\begin{cases}
1,  & \text{if $x>0$} \\
e^{-x}, & \text{if $ x\leq 0$}
\end{cases}
$ Hence: $h_{even}(x) = 
\begin{cases}
\frac{1}{2}(1+e^{-x}),  & \text{if $x<0$} \\
\frac{1}{2}(1+e^{x}), & \text{if $ x> 0$} \\
\ 1,  & \text{ if $x=0$}\end{cases}
$ $h_{odd}(x) = 
\begin{cases}
\frac{1}{2}(1-e^{-x}),  & \text{if $x<0$} \\
\frac{1}{2}(e^{x}-1), & \text{if $ x> 0$} \\
\ 0,  & \text{ if $x=0$}\end{cases}
$ My problem is I have no idea how these functions were found.. I'm sure it's as simple as applying the formula I stated above but I think perhaps because they are piece wise functions I am not entirely sure how this happened. Any explanation is greatly appreciated. Further Info: I think I understand the formula but applying it to examples particularly is where I struggle, as in the actual calculation is what I don't understand. For example, to calculate $h_{even}(x)$ we should do the addition of the following functions, if I am correct: $
\frac{1}{2}h(x) = 
\begin{cases}
\frac{1}{2},  & \text{if $x<0$} \\
\frac{1}{2}e^x, & \text{if $ x\geq 0$}
\end{cases} $ $\frac{1}{2}h(-x) = 
\begin{cases}
\frac{1}{2},  & \text{if $x>0$} \\
\frac{1}{2}e^{-x}, & \text{if $ x\leq 0$}
\end{cases}$ But my issue is, how do you combine these? How can you deduce that for example $h_{even}(x)=1$, if $x=0$ purely from this addition. I guess my question is quite simple really as in just how to add piece wise functions when the conditions are different.",['functions']
2286337,About the dual space of $V=\{u\in H_0^1(\Omega): \text{div}u=0 \}$ and its relations to $H^{-1}(\Omega)$.,"I read about some things about $V=\{u\in H_0^1(\Omega): \text{div}u=0 \}$ and its dual space and I began to mix some of these things together. As a result: irritation. I hope you can help me out. First off, $V$ has the same topology as $H_0^1$ hence it is a Hilbert space with the scalar product $(u,v)_V=\int_\Omega \nabla u \cdot \nabla v dx$. Of course $V \subset H_0^1$ and $V$ is continuously embedded in $H_0^1$ as $\|v\|_{H_0^1}=\|v\|_V$ for all $v \in V$. Hence we also know that $H^{-1}$ is a subspace of $V'$. Girault & Raviart use in their book [Finite Element Approximation of the Navier-Stokes Equations] in Theorem 1.2 on page 158 that $f \in L^2(0,T;V')$, but by assumption we only know $f \in L^2(0,T;H^{-1})$. Hence they seem to use $L^2(0,T;H^{-1})\subset L^2(0,T;V')$. But for this wouldn't I need that $H^{-1}$ is continuously embedded in $V'$? To have the existence of a constant $C>0$ such that
$$\|u\|_{L^1(0,T;V')}=\int_0^T \|u\|_{V'} dt \leq \int_0^T C \|u\|_{H^{-1}} dt =\|u\|_{L^1(0,T;H^{-1})}.$$ J. Simon proves in his paper [On the existence of the Pressure for Solutions of the Variational Navier-Stokes Equations]: '$H^{-1}(\Omega)^d$ and $V'$ themselves cannot be imbedded in the same Hausdorff space'. (p.226, 4th line) Now, I see a contradiction between [2.] and [3.]. If we have [2.] then $H^{-1}$ is continuously embedded in $V'$. Hence $H^{-1}$ and $V'$ can both be embedded in a Hausdorff-space, namely $V'$ (which is even a Banach space as it is the dual of a Hilbert space I thought). EDIT: After the great help in the comments, I know that $H^{-1}$ is continuously embedded in $V'$. Hence, Girault and Raviart can of course use the fact $L^2(0,T;H^{-1})\subset L^2(0,T;V')$. Now I look again at the paper of J. Simon and try to find out what he means. I will edit it here if I find something. Otherwise, I am always thankful for comments, answers and hints. EDIT2: Okay, I think I know the answer. The problem lies in the word ""embedding"" that I totally mixed, duh. Girault and Raviart only use that the restriction operator from $H^{-1}$ to $V'$ is continuous - nothing more! But Simon includes injectivity in his definition of imbedding. But, since $V$ is not dense in $H_0^1$, $H^{-1}$ can't be injective in $V'$ (with the restriction operator). If there are no objections in the next few days, I will post EDIT2 as an answer.","['functional-analysis', 'bochner-spaces', 'sobolev-spaces', 'dual-spaces']"
2286339,"For Hilbert-Schmidt operator, $\sum\lVert Te_n\rVert^2 = \lVert k \rVert^2$","Let $X = L^2(0,1)$ and $k \in L^2( (0,1) \times (0,1))$. Therefore we have a Hilbert-Schmidt integral operator: $Tf(t)=\int_0^1 k(s,t)f(s)ds$ Let $\{e_n\}$ be an orthonormal basis of $X$, how to show $\sum_n \lVert Te_n \rVert^2=\lVert k \rVert^2_{L^2(0,1)\times(0,1)}$? $\lVert Te_n \rVert^2=\sum_k |\langle Te_n,e_k\rangle|^2$ and $\sum_n\lVert Te_n \rVert^2=\sum_n \sum_k |\langle Te_n,e_k\rangle|^2$. On the other hand, $\lVert k \rVert^2=\int_0^1 \int_0^1 |k(t,s)|^2\ dt \ ds$ and I cannot see any relationship between them.","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
2286357,Relation between Events and Borel field in Probability theory,"In Probability,Random Variables book by Athanasios Papoulis, this is given Borel fields . Suppose that $A_1$,...$A_n$,.... $\;$ is an infinite sequence of sets in $F$.If the union and intersection of these sets also belongs to $F$,then $F$ is called a Borel Field . The class of all subsets of a set $S$ (the sample space) is a Borel field . Suppose that $C$ is a class of subsets of $S$ that is not a field. It can be shown that there exists a smallest Borel field containing all the elements of $C$. Example: Suppose that $S$ consists of the four elements a,b,c,d and $C$ consists of the sets {a} and {b}. Attaching to $C$ the complements of {a} and {b} and their unions and intersections, we conclude that the smallest field containing {a} and {b} consists of the sets {$\emptyset$}$\quad${a}$\quad${b}$\quad${a,b}$\quad${c,d}$\quad${b,c,d}$\quad${a,c,d}$\quad$$S$ Events. In probability theory, events are certain subsets of $S$ forming a Borel field. I do understand what a field is, but i am unable to understand the above paragraph on Borel fields and its connection to probability theory. I am not too familiar with set theory, please help me understand what the above paragraph means. Thanks in advance","['probability-theory', 'borel-sets']"
2286385,How do we show that $\int_{0}^{1}{\ln^k(x)\over x}\ln\left(1-\sqrt[n]{x}\right)\mathrm dx=(-n)^{k+1}k!\zeta(k+2)?$,"Proposed: A simple closed form $$\int_{0}^{1}{\ln^k(x)\over x}\ln\left(1-\sqrt[n]{x}\right)\mathrm dx=(-n)^{k+1}k!\zeta(k+2)\tag1$$ Where $n,k=1,2,3,\cdots$ My try: $u=\sqrt[n]{x}\implies {nx\over u}du=dx$, $x=u^n$, then $(1)$ becomes $$n^{k+1}\int_{0}^{1}{\ln^k(u)\over u}\ln(1-u)\mathrm du\tag2$$ $$-n^{k+1}\sum_{v\ge1}{1\over v}\int_{0}^{1}u^v\ln^k(u)\mathrm du\tag3$$ $$-n^{k+1}\sum_{v\ge1}{1\over v}\cdot{(-1)^kk!\over (v+1)^{k+1}}\tag4$$ $$(-n)^{k+1}k!\sum_{v\ge1}{1\over v(v+1)^{k+1}}\tag5$$ How may we prove $(1)?$","['integration', 'definite-integrals', 'sequences-and-series', 'calculus']"
2286391,Functions that are their own inverse.,"What are the functions that are their own inverse? (thus functions where $ f(f(x)) = x $ for a large domain) I always thought there were only 4: $f(x) = x , f(x) = -x , f(x) = \frac {1}{x} $ and $ f(x) = \frac {-1}{x} $ Later I heard about a fifth one $$f(x) = \ln\left(\frac {e^x+1}{e^x-1}\right) $$ (for $x > 0$) This made me wonder are there more? What are conditions that apply to all these functions to get more, etc.","['algebra-precalculus', 'functions', 'inverse']"
2286399,Counting sets which can be partition in two subsets satisfying certain criterion,"I have a question that involves some ability in combinatorics that I don't have. Any hint could be extremely appreciated. Take $n>1$ with $n\in \mathbb{N}$. Let $\mathcal{G}$ be the set of all possible binary matrices of dimension $n\times (n-1)$. $\mathcal{G}$ has cardinality $|\mathcal{G}|=2^{n(n-1)}$. For example, if $n=2$, then $\mathcal{G}:=\{\begin{pmatrix}
1\\
1
\end{pmatrix},\begin{pmatrix}
1\\
0
\end{pmatrix}, \begin{pmatrix}
0\\
1
\end{pmatrix} , \begin{pmatrix}
0\\
0
\end{pmatrix}\}$ with $|\mathcal{G}|=4$. Question: For $M=2,...,|\mathcal{G}|-1$, I want to count all possible sets $C\subset \mathcal{G}$ with cardinality $M$ such that: there exists a non-empty set $D\subset C$ such that for every pair of matrices, one taken from $D$ and the other taken from $C-D$, the two matrices in the pair considered differ for at least two rows. Is this counting possible? If not, is there any known upper bound or lower bound? I have looked at this question whose comments link to bounds for binary constant weight codes , but it does not seem to help. [$C-D$ denotes the complement of $D$ in $C$]. For example: when $n=2$ the result is $2$. Indeed, for $M=2$, we can have
$$
C=\{\begin{pmatrix}
1\\
1
\end{pmatrix}, \begin{pmatrix}
0\\
0
\end{pmatrix}\} 
$$
where $D=\{\overbrace{\begin{pmatrix}
1\\
1
\end{pmatrix}}^{d_1}\}$, $C-D=\{\overbrace{\begin{pmatrix}
0\\
0
\end{pmatrix}}^{c_1}\}$, row $1$ of $d_1$ $\neq $ row $1$ of $c_1$, and row $2$ of $d_1$ $\neq $ row $2$ of $c_1$
and
$$
C=\{\begin{pmatrix}
0\\
1
\end{pmatrix}, \begin{pmatrix}
1\\
0
\end{pmatrix}\} 
$$
where $D=\{\overbrace{\begin{pmatrix}
0\\
1
\end{pmatrix}}^{d_1}\}$, $C-D=\{\overbrace{\begin{pmatrix}
1\\
0
\end{pmatrix}}^{c_1}\}$, row $1$ of $d_1$ $\neq $ row $1$ of $c_1$, and row $2$ of $d_1$ $\neq $ row $2$ of $c_1$ For $M=3$, there is no $C$ satisfying the considered criterion. Remark: Notice that the order of the rows matter.","['combinations', 'combinatorics', 'elementary-set-theory']"
2286468,$K$-functional between $\ell_1$ and $\ell_2$ for a specific sequence,"Short version: For any $n\in\mathbb{N}$, Let $$
p_n(k) \stackrel{\rm def}{=} \frac{1}{(k+1)\ln(k+1)}, \qquad 1\leq k\leq n-1
$$
and consider $$
\kappa_{p_n}(t) = \inf\{ \lVert u\rVert_1+t\lVert v\rVert_2 : u\in\ell_1, v\in\ell_2\text{ s.t. } u+v=p_n\}
$$
For a fixed small constant $\varepsilon\in(0,1)$, what is the asymptotic expression (as $n\to\infty)$ of $t=t(n,\varepsilon)$ such that
$$\kappa_{p_n}(t) =(1-2\varepsilon)\sum_{k=2}^n \frac{1}{k\ln k} \tag{$\dagger$}
$$? Long version: Recall that for any sequence $a\in\ell_1+\ell_2$, we can defined the K-functional (between $\ell_1$ and $\ell_2)$ as the concave, non-decreasing function $\kappa_p\colon(0,\infty)\to(0,\infty)$
$$
\kappa_p(t) = \inf\{ \lVert u\rVert_1+t\lVert v\rVert_2 : u\in\ell_1, v\in\ell_2\text{ s.t. } u+v=p\}
$$ (see e.g. this previous question for more properties). It is also known (for the continuous case $L_1+L_2$, but I am pretty sure the proof extends to the discrete case) that for any given $t>0$ an optimal decomposition $(u_t,v_t)$ yiedling the value $\kappa_p(t)$ is of the form (assuming wlog that $a\geq 0$)
$$
v_t = \min(a, \lambda_t), \qquad u_t = a-v
$$
for some threshold $\lambda_t \geq 0$. This being said, I have been repeatedly failing to find a tight enough (possibly asymptotic with regard to $n$) expression for $\kappa_{p_n}(t)$, where $(p_n)_n$ is a sequence of probability distributions defined as
$$
p_n(k) \stackrel{\rm def}{=} \frac{1}{c_n}\cdot \frac{1}{(k+1)\ln(k+1)}, \qquad 1\leq k\leq n-1
$$
and $0$ for $k\geq n$; where $c_n \stackrel{\rm def}{=}\sum_{k=2}^n \frac{1}{k\ln k}$ is a normalizing constant satisfying
$c_n = \ln\ln n - K+o(1)$ for some constant $K$ (which can be found, e.g., via Euler—MacLaurin). More specifically, my end goal would be to find an asymptotic equivalent (or even expansion to lower order terms) to the value $t^\ast(n,\varepsilon)$ solution of the equation
  $$
 \kappa_{p_n}(t) = 1-2\varepsilon \tag{1}
$$
  where $\varepsilon \in (0,1/2)$ is to be thought of as a small constant. I tried to tackle that by (i) finding an expression or sufficiently good asymptotic expansion of $\lVert u_\lambda\rVert_1+t\lVert v_\lambda\rVert_2$ (for fixed $t$, as a function of $\lambda$), (ii) minimizing this w.r.t. $\lambda$ to find an expression (or sufficiently good asymptotic expansion) of $\kappa_{p_n}(t)$; and (iii) solve (1) approximately using the expression of (ii) in lieu of $\kappa_{p_n}(t)$. However, I was stuck at (i) for the discrete case; trying to consider the $L_1+L_2$ analog instead (continuous case) for a start, I got stuck at either (ii) or (iii) -- I am unclear which, as repeating the computations kept giving me either different results or nonsense. Any clue, idea, or suggestion on what I could do (or what the ""right"" approach and answer are)? Additional: The answer to $(\dagger)$ (and of (1)), even though not to the more general question of the asymptotic of $\kappa_{p_n}(t)$, should satisfy
$$
e^{(\ln n)^{\frac{1}{2}-c'\varepsilon}} \leq \kappa_{p_n}^{-1}(1-2\varepsilon) \leq e^{(\ln n)^{\frac{1}{2}-c\varepsilon}} \tag{2}
$$
where $c,c'>0$ are absolute constants; leading me to conjecture that $\kappa_{p_n}^{-1}(1-2\varepsilon) = e^{(1+o(1))(\ln n)^{\frac{1}{2}-c\varepsilon}}$ for asome absolute constant $c>0$. The reason for (2) is rather long-winded, but basically follows from a distribution testing question. [VV14] and [BCG17] both established bounds on the complexity $\Phi$ of a specific problem (""identity testing""), which for arbitrary discrete distribution $p$ and $\varepsilon \in(0,1]$ are respectively
$$
\Omega\left(\frac{\lVert p^{-\max}_{-\varepsilon}\rVert_{2/3}}{\varepsilon^2}\right)\leq \Phi(p,\varepsilon) \leq O\left(\frac{\lVert p^{-\max}_{-\varepsilon/16}\rVert_{2/3}}{\varepsilon^2}\right) \tag{3}
$$ and
$$
\Omega\left(\frac{\kappa_{p_n}^{-1}(1-2\varepsilon)}{\varepsilon}\right)\leq \Phi(p,\varepsilon) \leq O\left(\frac{\kappa_{p_n}^{-1}(1-\frac{\varepsilon}{9})}{\varepsilon^2}\right). \tag{4}
$$ 
Without delving into exactly what the functional $p\mapsto \lVert p^{-\max}_{-\varepsilon}\rVert_{2/3}$ in (3) is (it is the $2/3$-norm of a vector obtained from $p$), computing its asymptotics for $(p_n)_n$ is easier than that of $\kappa_{p_n}^{-1}(1-2\varepsilon)$. By doing so (assuming I didn't make a mistake in the computation), and putting together the inequalities (3) and (4), we get the inequalities from (2). [VV14] Gregory Valiant and Paul Valiant. An automatic inequality prover and instance optimal identity testing. In Proceedings of FOCS, 2014. [BCG17] Eric Blais, Clément L. Canonne, and Tom Gur. Distribution testing lower bounds via reductions
from communication complexity. In IEEE Conference on Computational Complexity (CCC), 2017.","['functional-analysis', 'asymptotics', 'sequences-and-series']"
2286473,Does a one tailed test statistic will always fail to reject the null if observed value is in the tail opposite to the alternative hypothesis?,"Suppose: $H_0: \beta \le 0.5$ $H_1: \beta > 0.5$ $\widehat \beta = 0.49$ If $\widehat \beta = 0.49$ and I want to test the alternative hypothesis that $\beta > 0.5$ (versus the null that $\beta \le 0.5$). Won't it be the case that a one tailed t statistic will always fail to reject the null, given that the t-stat will be negative and to reject the null, the t-stat would need to be positive? This seems counterintuitive that we would never reject the null even if $\widehat\beta$ had a high standard error. Furthermore wouldn't a constructed confidence interval then suggest there are null hypotheses where beta $> 0.5$, which we would fail to reject (contrary to the calculated t-value)?",['statistics']
2286476,How is the action of a vector field on a function defined?,"Questions of definition: 1) How do we make sense of $X(f)$ with $X$ a vector field on $M$ and $f$ a smooth function on $M$? One idea I have is that it is not actually $X(f)$ where we apply the vector field on $f$ but actually the canonically associated derivation. That is $X(f)$ is the following function $$ X(f):M\rightarrow \mathbb{R}:x\rightarrow X_x(f)$$ 2) How do we make sense of $Xg(Y,Z)$ where $g$ is a riemanian metric and $X,Y,Z$ vector fields. One idea is that $Xg(Y,Z)$ is the fonction defined as follows $$ Xg(Y,Z):M\rightarrow \mathbb{R}:x\rightarrow X_x\cdot g_x(X_x,Y_x)$$","['riemannian-geometry', 'differential-geometry', 'definition']"
2286496,"Heat kernel, connection on fibre bundles: reference request","At the moment I'm trying to read Getzler/Berline ""Heat kernels and Dirac operators"", but I'm having a hard time to follow the rather brief outline of connections (of fibre bundles, principal bundles) etc. in the first chapter. Can anyone recommend me a more detailed (modern) reference with careful explanation. (not Nomizu/Kobayashi). I'm comfortable with connections, curvature etc in the context of Riemannian geometry, also with the topological theory of fibre bundles. If you have a reference in mind, which does these things for general vector bundles, I'd be glad as well","['reference-request', 'connections', 'fiber-bundles', 'differential-geometry']"
2286558,Probability describing how many adjacent hexagons overlap a circle of a given radius,"In a simulated landscape comprised of tiled hexagons of a uniform size, if I were to drop a circle in this landscape at a random location, how could I determine a probability distribution function which describes the  many hexagons would overlap (including partial overlaps) the randomly placed circle. The example image shows 22 hexagons at least partially overlapping the circle.  So the question would be what is the probability that I'd get this value (or alternate values) if the circle was randomly placed on this landscape? For a bit of context here, I'm interested to see if I can get some probability distribution function for species distribution mapping which accurately represent the life history of a particular species.  In this case, I'm interested in a probability distribution function describing how many bird territories are within an observers sampling area. I currently just use simulations to get a distribution resembling this, but I'm sure there's a cleaner, more efficient way to derive this distribution from geometric proofs.  My question is somewhat similar to this . Note:  My math is pretty amateur, so if please let me know if my question is unclear. Edit 1: Perhaps to make this easier (maybe?), I'm happy with an approximation to the solution, so perhaps using slightly overlapping circles rather than hexagons makes the problem more feasible?","['probability-distributions', 'geometry']"
2286568,Show that a function is in Bergman space,"Consider the Bergman space $A^2(\mathbb{D})$, where $\mathbb{D}$ is the open unit disk in $\mathbb{C}$. Show that if $\sum_{n=0}^\infty |a_n|^2$ converges, then $\sum_{n=0}^\infty (n+1)^{1/2} a_n z^n$ is holomorphic in $\mathbb{D}$. I want to show $f(z)=\sum_{n=0}^\infty (n+1)^{1/2} a_n z^n$ is also in $A^2(\mathbb{D})$. I know that $\{e_n=\sqrt{\frac{n+1}{\pi}}z^n\}_{n\geq0}$ is an orthonormal basis of $A^2(\mathbb{D})$. Therefore I want to show that $f =\sum_{n=0}^\infty \langle f, e_n\rangle e_n$ $\langle f,e_n \rangle=\int_0^1 f \overline{e_n}dz = \int_0^1 \overline{\sqrt{\frac{n+1}{\pi}}z^n}\sum_{k=0}^\infty (k+1)^{1/2} a_n z^k dz$ Is this approach correct? I feel like I am complicating the problem. Why do we need $\sum |a_n|^2$ converges?","['functional-analysis', 'bergman-spaces']"
2286600,Find the derivative of $y=x^x$. [duplicate],"This question already has answers here : Finding the derivative of $x^x$ [duplicate] (3 answers) Closed 7 years ago . Find the derivative of $y=x^x$. My Attempt:
$$y=x^x$$
Taking $\textrm {ln}$ on both sides, we get:
$$\textrm {ln} y= \textrm {ln} x^x$$
$$\textrm {ln} y = x \textrm {ln} x$$ How do I procees further?","['derivatives', 'calculus']"
2286628,Canonical Pyramid Polynomials,"In a canonical polyhedron , all edges are tangent to a unit sphere with the origin at the center of gravity of the points of tangency. I've been working on exact forms of canonical polyhedra, and the regular pyramid turned out to be an interesting case. For a base with $n$ sides, that polygon has $z$ coordinates of $-tan(\frac{\pi}{2n})$, and the apex is at $(0,0,cot(\frac{\pi}{2n}))$. Here are some examples, each pyramid with its dual. The edges are perpendicular to each other at points tangent to the unit sphere. The base regular polygon needs a scaling factor that is the root of a particular polynomial.  For bases with 3 to 12 sides, here are the roots and their polynomials. $\begin{array}{ccc}
 3 & 1.6329931618554520655 & 2 \sqrt{\frac{2}{3}} \\
 4 & 1.2871885058111652495 & x^4+8 x^2-16 \\
 5 & 1.1690009178779524258 & 5 x^4+40 x^2-64 \\
 6 & 1.1124766546017998270 & 3 x^4+48 x^2-64 \\
 7 & 1.0806190099881630969 & 7 x^6-448 x^2+512 \\
 8 & 1.0607630605786609417 & x^8+32 x^6+64 x^4-1024 x^2+1024 \\
 9 & 1.0475038619623609305 & 3 x^6+72 x^4+384 x^2-512 \\
 10 & 1.0381901644398379801 & 5 x^8+240 x^6+960 x^4-5120 x^2+4096 \\
 11 & 1.0313884014418166375 & 11 x^{10}+88 x^8-2112 x^6-11264 x^4+45056 x^2-32768 \\
 12 & 1.0262650635674814921 & x^8+64 x^6+128 x^4-4096 x^2+4096 \\
\end{array}$ Here's code for calculating the pyramids. pyramid[basesides_] := Module[{k = Abs[basesides], poly, 
  sign = Sign[basesides], g},
  poly = RootReduce[g /. Last[Solve[myNorm[Mean[Table[{g Cos[2 Pi n/k], 
        g Sin[2 Pi n/k], -Tan[Pi/(2 k)]}, {n, 0, 1}]]] == 1]]];
  {Append[Table[{RootReduce[poly Cos[2 Pi n/k + (sign - 1) Pi/k/2]], 
  RootReduce[poly Sin[2 Pi n/k + (sign - 1) Pi/k/2]], -sign Tan[
    Pi/(2 k)]}, {n, 0, k - 1}], {0, 0, sign Cot[Pi/(2 k)]}],
  Polygon[Prepend[Sort[Append[RotateLeft[Append[Reverse[#], k + 1], 1] & /@ 
    Partition[Range[k], 2, 1], {1, k, k + 1}]], Range[k]]]}] I use Solve in that.  Is there a more direct way for generating these polynomials?  Is it a known class? Here are factored forms of the coefficients.","['polyhedra', 'polynomials', 'solid-geometry', 'geometry']"
2286636,Find the derivative of $y^3-xy^2+\cos xy=2$,"Find the derivative of $y^3-xy^2+\cos xy=2$ My Attempt:
$$y^3-xy^2+\cos xy=2$$
$$\dfrac {d}{dx} [y^3-xy^2+\cos xy]=\dfrac {d}{dx} [2]$$
$$3y^2.\dfrac {dy}{dx} -[1.y^2+2xy\dfrac {dy}{dx}] + (-\sin xy) \dfrac {dy}{dx}(xy)=0$$
$$3y^2 \dfrac {dy}{dx} - y^2 - 2xy\dfrac {dy}{dx} - \sin xy (y+\dfrac {dy}{dx} x)=0$$ How do I proceed further?","['derivatives', 'calculus']"
2286641,Diffeological isomorphisms between irrational tori.,"This is exercise 4 from chapter 1 of the book "" diffeology "" by Patrick Iglesias-Zemmour. Let $\alpha \in \mathbb{R}$ and $\beta \in \mathbb{R}$ be irrational numbers. Define the irrational (non-commutative) torus $T_{\alpha} = \mathbb{R}/(\mathbb{Z}+ \alpha \mathbb{Z})$, and define $T_{\beta}$ analogously. Let $\pi_{\alpha}: \mathbb{R} \rightarrow T_{\alpha}$ be the canonical projection, and likewise for $\pi_{\beta}$. A diffeology on $T_{\alpha}$ is collection of maps $P: U \rightarrow T_{\alpha}$, where $U$ is an open subset of $\mathbb{R}^{n}$ for some $n$. The members of the diffeology are called plots. The diffeology we would like to consider is the following. A map $P: U \rightarrow T_{\alpha}$ is a plot if for any $r \in U$, there exists an open neighborhood $V_{r}$ of $r$, and a smooth map $Q: V_{r} \rightarrow T_{\alpha}$ such that $\pi_{\alpha} \circ Q = P|_{V_{r}}$. In other words, the plots are the maps that locally factor through a smooth map $Q: V \rightarrow \mathbb{R}$. We can endow $\mathbb{R}$ with a diffeology: the plots are the smooth maps. A map between diffeological spaces is smooth if it sends plots to plots. Claim: if $f: T_{\alpha} \rightarrow \mathbb{R}$ is smooth, then $f$ is constant. Let me sketch a proof. If $f$ is to be smooth, then $f \circ \pi_{\alpha}: \mathbb{R} \rightarrow \mathbb{R}$ must be smooth. (This follows from the fact that $\pi_{\alpha}$ is a plot, and hence $f \circ \pi_{\alpha}$ must be a plot). If $f$ is non-constant, then $f \circ \pi_{\alpha}$ is non-continuous. This can be seen directly as follows. Let $t,t' \in T_{\alpha}$ such that $f(t) \neq f(t')$. Then we choose $\epsilon = |f(t) - f(t')|/2 > 0$. Now if $\delta > 0$, then there exist $x, x' \in \mathbb{R}$, with $|x - x'| < \delta$ and $\pi_{\alpha}(x) = t$ and $\pi_{\alpha}(x') = t'$, (this is because $\mathbb{Z} + \alpha \mathbb{Z}$ is dense in $\mathbb{R}$). Finally, we see $|f \circ \pi_{\alpha}(x) - f \circ \pi_{\alpha}(x')| = |f(t) - f(t')| > \epsilon$. Now comes the part that troubles me. Problem: Let $f: T_{\alpha} \rightarrow T_{\beta}$ be smooth. Then there exists some interval $J \subset \mathbb{R}$ and an affine map $F:J \rightarrow \mathbb{R}$, such that $\pi_{\beta} \circ F = f \circ \pi_{\alpha}|_{J}$. Furthermore $F$ can be extended affinely to $\mathbb{R}$. I have some progress. Like before, if $f$ is smooth, then $f \circ \pi_{\alpha}: \mathbb{R} \rightarrow T_{\beta}$ is a plot. This means there exists an open interval $I$ and a smooth map $Q:I \rightarrow \mathbb{R}$, such that
\begin{equation}
f \circ \pi_{a}|_{I} = \pi_{\beta} \circ Q.
\end{equation}
My suspicion is that the map $Q$ is the map $F$ that we are after. However, I don't know how to show that $Q$ is an affine map. The exercise hints that I should use the fact that $\mathbb{Z} + \alpha \mathbb{Z}$ is dense in $\mathbb{R}$, but I don't really see how to apply this. I had the thought of showing that the derivative of $Q:I \rightarrow \mathbb{R}$ is constant, but I didn't really make any progress.","['diffeomorphism', 'smooth-manifolds', 'differential-geometry', 'noncommutative-geometry']"
2286670,Evaluating the integral $\int \frac{x-1}{(x+1) \sqrt{x^3+x^2+x}}dx$,"The integral to be evaluated is  $$\int \frac{(x-1)}{(x+1) \sqrt{x^3+x^2+x}}dx$$ I split the integral to obtain
$$\int \frac{\sqrt x}{(x+1) \sqrt{x^2+x+1}}dx - \int \frac{1}{(x+1)\sqrt{x^3+x^2+x}}dx$$ But I could not proceed any further, as I am not able to find any substitution, nor could I find any further simplification. I tried by multiplying the numerator and denominator with $\sqrt {x-1}$ so as to obtain $ x^3-1$ inside the radical, but that didn't help either. How should I proceed to evaluate this integral?","['indefinite-integrals', 'integration', 'calculus']"
2286733,$\frac{(10^4+324)(22^4+324)\cdots(58^4+324)}{(4^4+324)(16^4+324) \cdots (52^4+324)}$,"From AIME 1987, compute $$\frac{(10^4+324)(22^4+324)\cdots (58^4+324)}{(4^4+324)(16^4+324) \cdots (52^4+324)}$$ So basically the way used to solve this is by Sophie Germain's Identity which is $a^4+4b^4=(a^2+2b^2-2ab)(a^2+2b^2+2ab)$ My question is , how is possible a student to solve this question without knowing this identity? Is there another way to solve this?","['algebra-precalculus', 'contest-math']"
2286735,Question about the proof of General Sobolev Inequality in P.D.E. by Evan,"I have been reading the chapter of Sobolev Space in Partial Differential Equations by Lawrence C. Evan, and I came across the General Sobolev Inequality stated as follows: Theorem (General Sobolev Inequality) Let $U\subset\mathbb{R}^n$ be a bounded open set, with $C^1$ boundary. Assume $u\in W^{k,p}(U)$. (i) If $k<\frac{n}{p}$ then $\|u\|_{L^q\left(U\right)}\le C\|u\|_{W^{k,p}\left(U\right)}$ with $\frac{1}{q}=\frac{1}{p}-\frac{k}{n}$ (ii) If $k>\frac{n}{p}$ then$$\|u\|_{C^{k- \left\lfloor{\frac{n}{p}}\right\rfloor - 1,\gamma}\left(\bar{U}\right)}\le C\|u\|_{W^{k,p}\left(U\right)}\text{, with } \: \gamma=\begin{cases}\left\lfloor{\frac{n}{p}}\right\rfloor + 1 -\frac{n}{p},\;\text{if $\frac{n}{p}\notin \mathbb{Z}$}\\ \text{any positive number}<1,\;\text{if $\frac{n}{p}\in \mathbb{Z}$}\end{cases}$$ My question is about the case when $\frac{n}{p}\in\mathbb{Z}$ in (ii). In the book, Evan provided the proof for this case as follows: Suppose $k>\frac{n}{p}$ and $\frac{n}{p}\in\mathbb{Z}$. Set $l=\left\lfloor{\frac{n}{p}}\right\rfloor-1=\frac{n}{p}-1$. Consequently, we have as above $u\in W^{k-l,r}\left(U\right)$ for $r=\frac{pn}{n-pl}=n$. Hence the Gagliardo-Nirenberg-Sobolev inequality shows $D^\alpha u\in L^q(U)$ for all $n\le q<\infty$ and all $\lvert \alpha\rvert \le k-l-1=k-\left\lfloor{\frac{n}{p}}\right\rfloor=k-\frac{n}{p}$. Therefore Morrey's inequality further implies $D^\alpha u\in C^{0,1-\frac{n}{q}}\left(\bar{U}\right)$ for all $n<q<\infty$ and all $\lvert \alpha\rvert \le k-\left\lfloor{\frac{n}{p}}\right\rfloor-1$. Consequently $u\in C^{k- \left\lfloor{\frac{n}{p}}\right\rfloor - 1,\gamma}\left(\bar{U}\right)$ for each $0<\gamma<1$. As before, the stated estimate follows as well. I understand the way he gets $u\in W^{k-l,r}\left(U\right)$ for $r=n$ by iterating the Gagliardo-Nirenberg-Sobolev inequality. But what I don't understand is how he used the Gagliardo-Nirenberg-Sobolev inequality on $u\in W^{k-l,n}\left(U\right)$ to obtain that $D^\alpha u\in L^q(U)$ for all $n\le q<\infty$ and all $\lvert \alpha\rvert \le k-l-1=k-\frac{n}{p}$. Isn't the Gagliardo-Nirenberg-Sobolev inequality only valid when $1\le r<n$? Or am I missing some extra steps he skipped? Any help would be very much appreciated!","['inequality', 'partial-differential-equations', 'functional-analysis', 'functional-inequalities', 'sobolev-spaces']"
2286741,On a function from a group with values lying in an inner product space,"Let $(G,+)$ be a group and $V$ be an inner product space (over $\mathbb R$ , or $ \mathbb C $ ) ; let $f:G \to V$ be a function such that $||f(x+y)||\ge ||f(x)+f(y)|| , \forall x,y\in G$ , then how to prove that $f(x+y)=f(x)+f(y),\forall x,y \in G$ ? If $(S,+)$ is a semigroup and $V$ be an inner product space (over $\mathbb R$ , or $ \mathbb C $ ) ; let $f:S \to V$ be a function such that $||f(x+y)||= ||f(x)+f(y)|| , \forall x,y\in S$ , then I can prove that  $f(x+y)=f(x)+f(y),\forall x,y \in S$ . But I don't know how to do the the aforementioned problem. Please help . Thanks in advance","['group-homomorphism', 'semigroups', 'inner-products', 'group-theory', 'linear-algebra']"
2286753,Double summation involving complex numbers,"I have come across this complex number problem which stated as follows. 
If $\alpha=e^{\frac{2\pi i} {7}}$ and $$f(x) = A_0 + \sum_{k=1}^{20} A_k x^k$$ then find $$\sum_{r=0}^{6} f\left(\alpha^r x\right) =? $$
I then plugged in the function in the summation which I am required to find. $$\sum_{r=0}^{6} f\left(\alpha^r x\right) = 7A_0 + \sum_{r=0}^{6} \sum_{k=1}^{20} A_k x^k e^{\frac{2\pi i} {7} rk} $$ Now I am stuck. Let us call that double summation term as U. So I thought $$ U= \sum_{k=1}^{20} A_k x^k \sum_{r=0}^{6} e^{\frac{2\pi i}{7} k(r)} $$ Can I write it this way? If so how can I simplify it further? Thank you in advance..","['summation', 'complex-numbers', 'functions']"
2286766,Show you can't fit a more expensive box into a cheaper one,"Suppose you want to send a package (a box (an orthohedron)). The delivery company tells you the price of the package will be the sum of the dimensions of the box, i.e., if it has sides $a \times b \times c$ then it will cost $a+b+c$ $ to send. Show you can't fit a more expensive box into a cheaper one. NOTE : I have tried a few different approaches and I think I have a proof for the planar case, though rather complicated, but still should be adaptable to the 3D case. What I'm looking for (mostly) are elegant solutions or ideas that don't involve a lot of computations / analysis tricks. NOTE 2 : It's easy to show, however, that you can achieve a better price for your mailing with several packages. This is not the case here, we just consider exactly one inner box.","['optimization', 'analytic-geometry', 'euclidean-geometry', 'geometry', 'puzzle']"
2286795,Find $\theta$ for which $\sin m \theta = \cos n \theta$,"Question: Find $\theta$ for which $\sin m \theta = \cos n \theta$ My attempt: $$\cos(m\theta)=\sin(\pi/2 - m\theta)$$
$$=\sin\big[k\pi + (-1)^k (\pi/2-m\theta)\big]$$
Since $\cos(m \theta)=\sin(n \theta)$, therefore:
$$\big[k\pi + (-1)^k (\pi/2-m\theta)\big]=n\theta$$
And hence we get $$\theta = \frac{\pi\Big[k+\frac{(-1)^k}{2}\Big]}{n+(-1)^km}$$ $m,n,k$ can be any number $\in \mathbb{R}$ as in my case. But is there any better representation of $\theta$ instead of what I've shown? I know I'm not wrong anywhere, but still if there's a shorter representation of the value of $\theta$ in terms some real number (positive, negative or zero), do write an answer. Regards,
Mathbg",['trigonometry']
2286805,How can one show that $\int_{0}^{\pi/4}{\sqrt{\sin(2x)}\over \cos^2(x)}\mathrm dx=2-\sqrt{2\over \pi}\cdot\Gamma^2\left({3\over 4}\right)?$,Proposed: $$\int_{0}^{\pi/4}{\sqrt{\sin(2x)}\over \cos^2(x)}\mathrm dx=2-\sqrt{2\over \pi}\cdot\Gamma^2\left({3\over 4}\right)\tag1$$ My try: Change $(1)$ to $$\int_{0}^{\pi/4}\sqrt{2\sec^2(x)\tan(x)}\mathrm dx\tag2$$ $$\int_{0}^{\pi/4}\sqrt{2\tan(x)+2\tan^3(x)}\mathrm dx\tag3$$ Not sure what substitution to use How may we prove $(1)?$,"['integration', 'definite-integrals', 'calculus']"
2286837,"equivalent norm on $C^2([0,1])$","I would like to know if the norm 
$$\left\lVert f \right\rVert_{\infty}+ \left\lVert f' \right\rVert_{\infty}+\left\lVert f'' \right\rVert_{\infty}$$
is equivalent to the norm
$$\left\lVert f \right\rVert_{\infty}+\left\lVert f'' \right\rVert_{\infty}$$ on $C^2([0,1])$ It is clear to me that the only non-trivial question is whether we can bound $f'$ in terms of $f$ and $f''.$","['functional-analysis', 'real-analysis', 'operator-theory', 'analysis']"
2286860,Iteration of $x_{n+1} = \tan (e^{x_n})$,Consider the following recursive formula: $$x_{n+1} = \tan (e^{x_n})$$ I have tried iterating this (using a calculator) and it seems to approach the cycle $$1.5574\ \ -29.3038 \ \ 1.8773 \cdot 10^{-13}$$ Does this iteration actually approach that cycle or is this due to rounding errors?,"['recursion', 'trigonometry', 'limits']"
