question_id,title,body,tags
79473,$\lim\limits_{x\to\infty}f(x)$ exists but $\lim\limits_{x\to\infty}f'(x)$ does not,"The following problem is from Calculus by Spivak: Give an example of a function $f$ for which $\lim\limits_{x\to\infty}f(x)$ exists, but $\lim\limits_{x\to\infty}f'(x)$ does not exist. Presumably, $f$ should also be differentiable. I manage to visualize such a function, but the definition is rather messy: Let $s_0=0$ and $s_n=\sum\limits_{i=1}^n\frac1n$ for any positive integer $n$. Define $$f(x)=\begin{cases}x&\text{if }x<0\\(-1)^{n+1}\frac{\sin n(x-s_{n-1})}n&\text{if }x\in[s_{n-1},s_n)\end{cases}$$ I'm looking for simpler functions that satisfy the conditions. Feel free to give more than one example.","['calculus', 'limits']"
79474,Why do the elements of finite order in a nilpotent group form a subgroup?,"I would like to prove the following statement: Let $G$ be a nilpotent group. Then the set of elements of $G$ of finite order is a subgroup of $G$. I have no idea but the straightforward approach by induction: We choose a central subgroup $A$ of $G$ and can assume that the elements of finite order of $G/A$ form a group. So, for $x,y\in G$ of finite order, there exists $n\in\mathbf{N}-\{0\}$ such that $(xy)^n\in A$. But what now? Is this the right track? I've actually found a proof or two on the web, but they use a lot of theory with which I'm not familiar, e.g. tensor products and Sylow theory for infinite groups. It would be great if someone could link to or sketch a proof that avoids or minimizes the use of these tools.",['group-theory']
79483,Taylor expansion of Christoffel symbols,"I would like to show that in geodesic coordinates with origin $p$ $$\Gamma_i = -\frac 12 \sum_j \mathrm{R}_p(\partial_i, \partial_j) x^j,$$ where $\Gamma_i = \Gamma_{ij}^k \partial_k \otimes \mathrm{d}x^j$ and $\mathrm{R}_p$ is the Riemann tensor at $p$. I tried some calculations, but I didn't get anywhere. Is it true that $\nabla_j \Gamma_i = -\frac12 \mathrm{R}(\partial_i, \partial_j)$? Then the result would follow...",['differential-geometry']
79484,"Expressing ""Probability that #successes is an even number"" mathematically","Needing a little help with my probability concept. Here's the question: An urn contains $10$ red balls, $20$ green balls and $30$ blue balls. Each trial consists of drawing a ball from the urn with replacement. If either red or blue ball is drawn, the trial is called a success . Suppose that $n$ independent trials are performed and let $P_n$ be the probability that the total number of successes that result is an even number. Find $P_n$ and $\lim \limits_{n \to \infty} P_n$. My Solution: $$ P (\text{success}) = \frac{\binom{40}{1}}{\binom{60}{1}} = \frac {2}{3} .$$ Then it is a binomial r.v with parameters $(n, \frac 2 3)$. How do I express the idea ""total number of successes that result is an even number"" mathematically? Thanks for looking at my question.","['statistics', 'probability']"
79502,Proofs involving stereographic projection,"Can someone please help me finding references in which one has used following homeomorphism to solve general topology problems? $S\colon S_{0}^{n}\to \mathbb{R}^n$ is defined by for any $x=(x_1,...,x_{n+1})$, $$ S(x) = \left(\frac{x_1}{1-x_{n+1}},\ldots,\frac{x_n}{1-x_{n+1}} \right) ,$$ where $S_{0}^{n}$ is the $n$-sphere in $\mathbb{R}^{n+1}$ with north pole $(0,0,\ldots,1)$ deleted. Note that $S$ is just a stereographic projection.",['general-topology']
79503,Why do we treat $\mathrm{d}x$ in the indefinite integral as if $f(x)$ were multiplied by it?,"The first explanation I heard for the $\mathrm{d}x$ - it just shows by which variable we are integrating. Which made sense because $(F(x)+C)^\prime=f(x)$, not $f(x)\mathrm{d}x$. Now, some time later, the $\mathrm{d}x$ has become a source of confusion again. If there's $\int \frac{x}{x^2+1} \mathrm{d}x$, then why can we solve it like that: $\int \frac{1}{x^2+1} x \mathrm{d}x= \frac{1}{2}\int\frac{1}{x^2+1} 2 x \mathrm{d} x=\frac{1}{2}\int \frac{1}{x^2+1} \mathrm{d}(x^2+1)$ ? The other parts seem more or less normal but the transition from $\int\frac{x}{x^2+1} \mathrm{d}x$ to $\int \frac{1}{x^2+1} x \mathrm{d}x$ seems very strange. It works but why does it? If $\mathrm{d}x$ just shows by which variable we are integrating $f(x)$ then we cannot treat it as if $f(x)$ were multiplied by it. And on the other hand, if $f(x)$ IS actually multiplied by $\mathrm{d}x$ then why can we do it? I know there's simple explanation for it when we calculate the definite integral, that we break up some line or surface or volume into infinitely little pieces and then add up those infinitely little pieces to get the whole thing, so it makes sense. But why do we treat $\mathrm{d}x$ in the indefinite integral as if $f(x)$ were multiplied by it? Thanks.","['notation', 'calculus', 'integration']"
79509,The equation $(1+x)^2\frac{dy}{dx}-xy=x^2y^2$,"I am very grateful for all your comments and answers to my previous question concerning ODEs ( The equation $(x-2xy-y^2)\frac{dy}{dx}+y^2=0$ ). Now I am struggling with this one $$(1+x)^2\frac{dy}{dx}-xy=x^2y^2.$$ It seems not to be hard but nevertheless all the tricks I know fail in this case. Best regards,
D.",['ordinary-differential-equations']
79538,Annihilator of quotient module M/IM,"Let $A$ be a commutative ring, $I$ an ideal of $A$ and $M$ an module over $A$. Is it true that $\operatorname{Ann}(M/IM) = \operatorname{Ann}(M) + I$? One inclusion is certainly true, but I don't know about the other one. If the above statement does not hold in general, does it perhaps for finitely generated modules?","['modules', 'commutative-algebra', 'ideals', 'abstract-algebra']"
79540,About the Stirling number of the second kind,"Find the exponential generating function for $s_{n,r}$, the number of ways to distribute $r$ distinct objects into $n$ distinct boxes with no empty box, and determine $s_{n,r}$. My solution is 
$$\left(x+\frac{x^2}{2!}+\frac{x^3}{3!}+\cdots\right)^n=(e^x-1)^n$$
$$=\sum_{k=0}^n(-1)^k\binom{n}{k}e^{kx}=\sum_{k=0}^n(-1)^k\binom{n}{k}\sum_{r=0}^{\infty}k^r\frac{x^r}{r!}$$
Thus, $s_{n,r}$ is the coef. of $\frac{x^r}{r!}$, which is $\sum_{k=0}^n(-1)^k\binom{n}{k}k^r$. However, I found it in another book that $s_{m,n}=\frac{1}{n!}\sum_{k=0}^{n}(-1)^k\binom{n}{k}(n-k)^m$, where $s_{m,n}$ denotes the  Stirling number of the second kind. I was wondering what's wrong with my solution.","['stirling-numbers', 'generating-functions', 'discrete-mathematics', 'combinatorics']"
79554,Can the pole of a analytic function be of rational order,Can a pole of an analytic function have a rational number as its order?,['complex-analysis']
79556,How does the pointwise ergodic theorem generalize the strong law of large numbers?,"I've heard (e.g. here ) that the pointwise ergodic theorem (PWET) generalizes the strong law of large numbers (SLLN). How exactly does the PWET generalize the SLLN? The PWET requires a measure-preserving (and ergodic for a stronger conclusion) transformation. What is the measure preserving (and maybe ergodic) transformation in the SLLN? I've also heard it said (though I don't recall where) that the PWET's generalization of the the SLLN is essentially because the PWET only requires ""independence in the limit"", whereas the SLLN requires the sequence to be i.i.d. What is meant by ""independence in the limit""?","['probability-theory', 'ergodic-theory']"
79566,Proof: If $f'=0$ then is $f$ is constant,"I'm trying to prove that if $f'=0$ then is $f$ is constant WITHOUT using the Mean Value Theorem. My attempt [sketch of proof]: Assume that $f$ is not constant. Identify interval $I_1$ such that $f$ is not constant. Identify $I_2$ within $I_1$ such that $f$ is not constant. Repeat this and by the Nested Intervals Principle, there is a point $c$ within $I_n$ for any $n$ such that $f(c)$ is not constant... This is where I realized that my approach might be wrong. Even if it isn't I don't know how to proceed. Thanks for reading and any help/suggestions/corrections would be appreciated.",['calculus']
79574,"In a group, does $[G:H] \leq |N|$ always imply $[G:N] \leq|H|$?",Let $G$ be a group and let $H$ and $N$ be subgroups of $G$. Suppose that $[G:H] \leq |N|$. Does this always imply that $[G:N] \leq |H|\ $? Lagrange's theorem tells us that this is true in the finite case. What about in general?,"['group-theory', 'abstract-algebra']"
79580,Law of Large Numbers Corollary,"I've been studying Probability Theory on my own and I've come across the Law of Large numbers but it doesn't address what happens when $E(X_{i})=\infty$. Essentially, if $X_1, X_2,...$ are i.i.d. random variables and $E(X_{i})=\infty$, then is $\limsup_{n \to \infty }|\frac{S_n}{n}|$ necessarily equal to $\infty$, or can it be finite?",['probability-theory']
79583,The probability density function of the ratio of two normal R.V.s,"I'm looking for some help with this probability problem. Here's the question: Suppose that $X$ and $Y$ are independent standard normal random variables. Show that the probability density function of $Z = X / |Y|$ is given by
  $$
f(t) = \frac{1}{\pi(1+t^2)}, \quad (-\infty < t < \infty).
$$ Thanks for looking through my question. -updated-
Hi guys, I've looked through the solution and am still thinking, i'm also thinking if its possible to log the expressions and apply convolution theorem... thanks for the answers once again. -updated-
tried the solution using first method but couldn't figured out how to complete the last step. Heres how i did it: $f(x,y) = f_{x}(x)f_{y}(y) = \frac{1}{2\pi}e^{-\frac{1}{2}(x^2 + y^2)}$ let Z = X/|Y|, V = X then x = v, y = v/z the Jacobian J = $x_{z}y_{v}-x_{v}y_{z} = \frac{v}{z^2}$ by Transformation theorem, $w(z,v)=f(v,\frac{v}{z})|J| = ???$ Will someone please point out to me how do i proceed from here to obtain f(t)? thanks a lot! -update 3- this is actually a Cauchy density!! thanks guys, i think i got it figured out.","['normal-distribution', 'probability']"
79584,Can all continuous linear operators on a function space be represented using integrals?,"A linear functional $\omega:v\mapsto\omega(v)$ on a finite dimensional vector space $X$ of dimension $N$ with an inner product $(·\ ,·)$  is an element of the dual vector space $X'$, and a couple of isomorphisms later I'll find 
$$\omega(v)=(\omega,v).$$ Now the Riesz representation theorem for $L^p(\Omega)$, $1\le p<\infty$, says that for some $\omega\in L^p(\Omega)'$, there is an $u\in L^q(\Omega)$ with $$\omega(v)=\int_\Omega u(x)v(x) \mathbb{d}x.$$ Secondly, a continuous endomorphism $A: v\mapsto A(v)$ of a finite dimensional vector space can naturally be represented by a matrix with $N^2$ coefficients $A_n^{p}$, which acts on the vectors as $$(A(v))_n=\sum_{p=1}^NA_n^{p}v_p.$$ My question now is if every linear map $A: f\mapsto A(f)$ on function spaces can represented similar to the matrixes operation, i.e. as $$(A(f))(x) = \int_\Omega A(x,p)f(p) \mathbb{d}p,$$ even if this might only be true in a distributional sense. Clearly $f(x) \mapsto \int A(x,p)f(p) \mathbb{d}p$ is a linear map and besides the regular examples where $A(x,p)$ is really just a nice function itself (like for the Fourier transformation with $A(x,p)=e^{\mathbb{i}xp}$), I am aware of distributions like the Dirac delta $``A(x,p)=\delta(x-p)´´$, which for example represents the identity $f(x) \mapsto \int \delta(x-p)f(p) \mathbb{d}p = f(x)$. But do i get everything this way? Can I write all operators using an integral which a priori gathers information of the function $f(x)$ on its whole domain? The question arose when I ask for an ``matrix-like´´ representation of common linear operators like 
$$D\equiv\frac{\partial}{\partial x}: f(x)\mapsto f'(x).$$ 
I guess $``D=-\delta'\ ´´$ works since
$$f(x)\mapsto(D(f))(x)=\int (-\delta'(x-p))f(p) \mathbb{d}p=\int \delta(x-p)f'(p) \mathbb{d}p=f'(x).$$
But are there even integral representations for, say, $\Delta=\sum_i\frac{\partial^i}{\partial x^i}$ or even the Laplace–Beltrami operator? Maybe using nesting of delta-distributions and metric-coefficient functions? Is this possible, is it useful in any sense, and are there more difficult linear operators than that? And if not, why? Is it advantageous to view the linear operators on function spaces like that?",['functional-analysis']
79585,The reciprocal condition of an equality,"It is well known that 
$$\left(\sum_{k=1}^n k\right)^2 = \sum_{k=1}^n k^3.$$ Now given $n$ integers $a_1,a_2,\ldots,a_n > 0$, is it possible to show that if $$\left(\sum_{k=1}^n a_k\right)^2 = \sum_{k=1}^n a_k^3,$$
then $\{a_1,\ldots,a_n\} = \{1,\ldots,n\}$? If it is false, for which $a_1,\ldots,a_n$ does this equality hold? Thanks for your responses.","['algebra-precalculus', 'combinatorics']"
79591,Manipulating this Inequality,"What's wrong with this method of trying to find the set of positive values of $x$ that satisfy the following inequality: $$\dfrac{1}{x}-\dfrac{1}{x-1} > \dfrac{1}{x-2}$$ Find a common denominator on the left hand side: $\dfrac{-1}{x(x-1)}>\dfrac{1}{x-2}\Leftrightarrow$ $2-x > x(x-1)\Leftrightarrow$ $2 > x^2$ Which is satisfied whenever $0 < x < \sqrt{2}$ (we only want positive $x$). From our original inequality, we throw out the points $x=0, x=1, x=2$. But for $\sqrt{2} < x < 2$ we don't satisfy $x^2 < 2$, so I thought it should be $(0,1)\cup(1,\sqrt{2})$. This is wrong though... answer is $(0,1)\cup(\sqrt{2},2)$. Hope someone can help explain to me what steps were wrong. Maybe tell me explicitly which of the if and only if implications don't hold. Thanks a lot.","['inequality', 'algebra-precalculus']"
79594,Which sequences converge in a cofinite topology and what is their limit?,"This is an exercise from an earlier calculus 1 reading at my university: Let $X$ be a space containing infinitely many elements. In the cofinite topology, a set $\Omega$ is open iff $\Omega = \emptyset$ or $\Omega^c$ only contains finitely many elements. Which sequences converge and what is their limit? As I had absolutely no idea how to approach this exercise, I looked up the solution and I found it quite frustrating that I didn't even understand the solution. The writer of the solution states that for any sequence $(a_n)$ in $X$ , there are three possible cases: a) There exists no value which the sequence takes infinitely many times. b) There exists exactly one value which the sequence takes infinitely many times. c) There exist two or more values which the sequence takes infinitely many times. In the first case, the writer further states that the sequence converges to any value $a \in X$ , in the second case, the sequence only converges to the value taken infinitely many times and in the last case, the sequence diverges. Obviously, the writer left out a proof or even a reasoning which might help a reader to understand why this is correct. Can anyone help me out by explaining why this holds true? Thank you very much in advance.","['general-topology', 'convergence-divergence']"
79613,What was the notation for functions before Euler?,"According to the Wikipedia article, [Euler] introduced much of the modern mathematical terminology and notation, particularly for mathematical analysis, such as the notion of a mathematical function. — Leonhard Euler , Wikipedia What was the notation for functions before him?","['notation', 'math-history', 'functions']"
79614,"linear ODE with constant coefficients, proof","Let $
\sum\limits_{k = 0}^n {y^{\left( k \right)} a_k }  = 0
$ an homogeneous ODE, where $a_k$ are constants. How can I solve the equation when the roots are repeated?  One way, that I saw in wikipedia, is using the fact that if $ e^{cx} $ is a solution, then $ (x^r)(e^{cx}) $ is also too, How can I prove this? It´s difficult to me, to evaluate the sum, because i want to show that $
\sum\limits_{k = 0}^n {\left( {x^r e^{cx} } \right)^{\left( k \right)} a_k }  = 0
$ but I need to evaluate $
{\left( {x^r e^{cx} } \right)^{\left( k \right)} }
$ and I don´t know how to do it Dx",['ordinary-differential-equations']
79632,No group of order 400 is simple,"I've been given the question of showing that no group of order $400$ is simple. I've tried to attack it via the Sylow theorems for about a week now, but all the tricks and methods I know seem to be failing horribly. Things I've tried: Trying to produce a contradiction by giving a map into $S_n$ by elements acting by conjugation on Sylow 5-subgroups doesn't work, since there are 16 such Sylow 5-subgroups, and 400 divides $16!$, so it might very well be an injection and therefore we can't obviously find a nontrivial kernel. Trying element counting is messy and I can't get it to come out the way I want- for instance, we can show that each of the Sylow 5-subgroups is isomorphic to $\mathbb{Z}_5\times \mathbb{Z}_5$, so there should be at least 125 elements of order divisible by only 5, but I can't see this producing a contradiction with any of the  things I can find out about Sylow 2-subgroups. Anyways, I'm probably missing something fairly obvious, and I would appreciate any hints, solutions, or other help that you could give.","['finite-groups', 'group-theory', 'abstract-algebra']"
79643,How can we approximate $\sum_{j=0}^n{\sum_{k=0}^j{c^j k^{1/2}}}$ by integrals?,"""Difference Equations"" by Walter G. Kelley and Allan C. Peterson, 2nd Edition, gives an example on how to approximate $\sum_{k=1}^n{k^{1/2}}$ using integrals and Bernoulli numbers. I'm interested in nesting summations and using integrals to approximate them.  So I cooked up a relatively simple example: $$\sum_{j=0}^n{\sum_{k=0}^j{c^j k^{1/2}}}$$ I'm mainly interested in knowing how to include an estimate from nested integrals.  The book gives the Euler summation formula: $$\displaystyle\sum_{k=1}^n{f(k)} = $$ $$\displaystyle\int_1^n{f(t)dt}+\frac{f(n)+f(1)}{2} + $$
$$\displaystyle\sum_{i=1}^m{\frac{B_{2i}}{(2i)!}\left(f^{(2i-1)}(n)-f^{(2i-1)}(1)\right)} - $$
$$\displaystyle\frac{1}{(2m)!}\int_1^n{f^{(2m)}(t)B_{2m}(t-\lfloor t \rfloor)dt}$$ where $B_i$ represents the $i$th Bernoulli number.  This formula allows one to estimate a summation by using integrals and Bernoulli numbers.  More information can also be found here, in Wikipedia's entry on it . I'm gussing what I can do is start with $\sum_j \sum_k f(j,k)$ and plug in $\sum_k f(j,k)$ into the Euler summation formula to get half of a big formula.  Then plug that in, along with $\sum_j$, into a second Euler summation formula. QUESTION Can someone please show me how I can approximate the solutions by using Euler summations?  It would help me a great deal, so I'd be very greatful!  Thanks for reading.","['approximation', 'recurrence-relations', 'bernoulli-numbers', 'integration']"
79649,How to prove $\sin(1/x)$ is not uniformly continuous,"How do I go about proving $f(x)=\sin(1/x)$ is not uniformly continuous? (Or: different question, but same intention* how do I prove that $x\sin(x)$ is not uniformly continuous) *I'm trying to grasp how one would prove $f$ is not uniformly continuous for functions other than the simple $x^n$. I have seen one technique being to set an $\epsilon$ and set $x, y$ in the form of $\delta$ (e.g. $\delta/2$, etc.) then subsequently proving that $f(x)-f(y)\ge\epsilon$",['calculus']
79674,Rigorous Text in Multivariable Calculus and Linear Algebra,"So I'm wanting a solid math book for Christmas.  I have a solid background in Calculus and am currently working through baby Rudin.  I really want a rigorous book dealing with multivariable calculus and linear algebra.  How well does Apostol II do this?  Would this be a good continuation book from my current study?  If not, what book would you suggest? EDIT:  I really like Apostol's Multivariable Calculus and Linear Algebra book and its format.  Will this book accomplish my purpose?  Do you think it is a good book?","['linear-algebra', 'self-learning', 'reference-request', 'analysis']"
79684,Absolute continuity of a distribution function,"This appeared on an exam I took. $Z \sim \text{Uniform}[0, 2\pi]$, and $X  = \cos Z$ and $Y = \sin Z$. Let $F_{XY}$ denote the joint distribution function of $X$ and $Y$. Calculate $\mathbb{P}\left[X+ Y \leq 1\right]$. So this was easy - $$\begin{align}
 \mathbb{P}\left[X+Y \leq 1\right] &= \mathbb{P}\left[\sin Z+ \cos Z \leq 1\right] \\
&=\mathbb{P}\left[\sqrt{2}\sin\left(Z+\frac{\pi}{4}\right)\leq 1\right] \\
&= \mathbb{P}\left[Z \leq \arcsin\frac{1}{\sqrt{2}} - \frac{\pi}{4} \right] \\
&= \dfrac{\arcsin\frac{1}{\sqrt{2}} - \frac{\pi}{4}}{2\pi}
\end{align}
$$ But then, the question asked if $F_{XY}$ was absolutely continuous. I don't think so, but how would I prove it? I thought about proceeding like this $$ 
\begin{align}
F_{XY}(x, y) &= \mathbb{P}\left[X \leq x, Y \leq y\right],\; x, y \in [0, 1] \\
&= \mathbb{P}\left[Z \leq \min(\arccos x, \arcsin y)\right]
\end{align}
$$
This is definitely continuous, but is it absolutely continuous? Thanks!","['probability-theory', 'measure-theory', 'probability-distributions', 'probability']"
79685,How to find the sum of all possible values of $\lfloor {k} \rfloor$ of the quadratic equation $x^2-2kx+k^2-1=0$?,"If the roots of the quadratic equation $x^2-2kx+k^2-1=0$  lie in the
  interval $(–4, 5)$, how to find the sum of all possible values of $\lfloor {k} \rfloor$? Attempt: $$ x^2-2kx+k^2-1=0$$ $$\Rightarrow (x-k)^2=1 $$ $$\Rightarrow k=x \mp 1$$ From this we could say that $k \in (-3,6)$ when $k=x+1$ and $k \in (-5,4)$ when $k=x-1$, but then how to do the rest?","['quadratics', 'algebra-precalculus', 'roots']"
79690,Question about how linear independence of module elements gives conditions on the determinant of a matrix,"I have been trying to prove linear independence of rows implies linear independence of columns in kind of an abstract setting of modules following some exercises and notes from an old course.  The following fact is something I think we are supposed to use but I did not see any way to prove it so I would like to understand the proof so I can potentially adapt it to a couple of similar problems. Let $A = (a_{i,j})$ be a square matrix with $n$ rows and columns and with entries in a commutative ring with identity $R$ and let $M$ be an $R$-module. Let $x_1, \ldots ,x_n \in M$ and suppose that$\sum_{j=1}^{n}a_{i,j} x_j = 0$ for $1  \leq i \leq n$ . Then how do you show $\det(A)x_i = 0$ for every $i = 1, \ldots, n$.","['modules', 'matrices', 'linear-algebra', 'abstract-algebra']"
79693,Counterexample to Jensen's inequality,"This appeared in an exam I took. The question asked us to give an example of a convex function $g: \mathbb{R} \longmapsto \mathbb{R}$ and a measure $\mu$ on $\left(\mathbb{R}, \mathscr{B}(\mathbb{R})\right)$ such that $g\left(\int x \, d\mu(x)\right) > \int g(x)\, d\mu(x)$. I am assuming that such an example can be constructed by violating the finiteness of the measure, but I have no idea how I would construct such an example. I guess the Lebesgue measure can be used, but am having trouble finding a function that is convex and gives this result.","['probability-theory', 'measure-theory', 'probability']"
79699,Matrix non-identity,"Let $M,N$ be $n\times n$ matrices. Then why is it that $MN-NM=I_n$ cannot be true, where $I_n$ is the $n\times n$ identity matrix? I am thinking of perhaps there is an argument using determinants? (Of course I am probably way out.) Thanks.",['matrices']
79703,Prove a theorem by using the direct method,"I am having trouble proving the theorem below: $A \cup (B - C) = (A \cup B) - (C - A)$ Using the direct method I am to assume that the hypothesis is true. So that is where I start: $\begin{array}{ccl}
    A \cup (B-C) & = & \{x \;|\; x\in A \vee x \in (B-C) \} \\
                 & = & \{x \;|\; x \in A \vee (x \in B \wedge x \not\in C)\} \\
                 & = & \{x \;|\; (x \in A \vee x \in B) \wedge (x \in A \vee x \not\in C)\}
   \end{array}$ But I don't know where to go from here. I have $(A \cup B)$ on the right side but how do I derive ""$- (C - A)$""?","['proof-writing', 'elementary-set-theory']"
79724,Visualizing Second Derivative,"Given a graph of a simple function $f$ (continuous, no oscillation, smooth). We can roughly tell how big $f'(a)$ is for any point $a$, i.e. by looking at the steepness of the graph at that point. Is there any way to estimate $f''(a)$? Determining its sign is quite easy by checking the convexity of $f$ at that point. But how do we know how big $f''(a)$ is?",['calculus']
79726,Cardinality of a minimal generating set is the cardinality of a basis,"Let $R$ be a commutative ring with unity. Let $M$ be a free (unital) $R$-module. Define a basis of $M$ as a generating, linearly independent set. Define the rank of $M$ as the cardinality of a basis of $M$ (as we know commutative rings have IBN, so this is well defined). A minimal generating set is a generating set with cardinality $\inf\{\#S:S\subset M, M=\langle S \rangle\}$. Must a minimal generating set  have cardinality the rank of $M$?","['modules', 'abstract-algebra']"
79728,"Closed formula for entries of ""Pascal's half triangle""","Rather than come up with a cumbersome explanation of what I mean, here is a picture of the beginning of the triangle: $$\begin{matrix}
1 & & &  \\
0 & 1 \\
1 & 0 & 1 \\
0 & 2 & 0& 1\\
2 & 0 & 3 & 0 & 1
\end{matrix}
$$ So, as I've suggested in the title, it is similar to Pascal's triangle, but we ignore any entries to the left of the center, and don't let them contribute to subsequent entries. I'm looking to find a closed formula for the entries. Let's call the entry in the $n^{th}$ row and $k^{th}$ column $a_{n,k}$. Then it's clear that if $2\nmid n+k$, we have that $a_{n,k}=0$. I was trying to think of a combinatorial interpretation of this, based on the fact that we can think of the $n,k$ entry of Pascal's triangle as the coefficient of $x^ky^{n-k}$ in $(x+y)^n$. Our $a_{n,k}$ correspond to the number of ways of writing $x^k$ from $(x+1/x)^n$ where if we think of choosing what we multiply out one by one, at each step we have chosen more $x$'s than $1/x$'s. This didn't lead me anywhere however. Any suggestions are appreciated. Admittedly it's been quite a while since I've done any combinatorics.","['generating-functions', 'combinatorics']"
79734,What's an easy way of proving a subgroup is normal?,"I think in most situations(for example, in $S_n$ or $D_n$), proving by definition is too complicated because you have to calculate $gng^{-1}$ for every $n$ in $N$ and $g$ in $G$. To prove that all the left cosets are also right cosets is also too complicated because you have to find all those cosets. I wonder if there's a way to do this without having to calculate everything by hand.","['group-theory', 'abstract-algebra']"
79748,Deformation of the Kähler structure on $CP^n$,"Using the homogeneous coordinate on $CP^n$, we consider the open set $U_0:=\{[1, \ldots, z_n]\}$. Then the standard Kähler form of $CP^n$ can be written as $$
\omega_0=\frac{\sqrt{-1}}{2}\partial\bar{\partial}\log(1+|z_1|^2+\cdots+|z_n|^2)
$$ The compatability of this form can be easily checked for other chart $U_i$. My question is, if I want to deform this Kähler form, an easy way to do this is introducing a function say $\rho: \mathbb R\to \mathbb R$ and write the new Kähler form on $U_0$ as $$
\omega_\rho=\frac{\sqrt{-1}}{2}\partial\bar{\partial}\log(1+\rho(|z_1|^2+\cdots+|z_n|^2))
$$ Then what are the restrictions on $\rho$ and how to write the form $\omega_\rho$ in other coordinate charts, say $U_1$?","['complex-geometry', 'differential-geometry', 'kahler-manifolds', 'riemannian-geometry', 'reference-request']"
79759,Calculating probabilities (Markov Chain),"Let $\mathcal{X}=(X_n:n\in\mathbb{N}_0)$ denote a Markov chain with state space $E=\{1,\dots,5\}$ and transition matrix $$P=\pmatrix{1/2&0&1/2&0&0\\1/3&2/3&0&0&0\\0&1/4&1/4&1/4&1/4\\0&0&0&3/4&1/4\\0&0&0&1/5&4/5}$$ Compute the probabilities $\mathbb{P}(X_2=5|X_0=1)$ and $\mathbb{P}(X_3=1|X_0=1)$. Given an initial distribution $\pi=(1/2,0,0,1/2,0)$, compute $\mathbb{P}(X_2=4)$. I've got the transient states as $1,2,3$. And the recurrent states as $4,5$, and the communication classes I think are $\{1,2,3\}$ and $\{4,5\}$. 1) To calculate $\mathbb{P}(X_2 = 5|X_0 = 1)$, is it just finding $P^2_{(1,5)}$? Which equals $1/8$? 2) For $\mathbb{P}(X_3 = 1|X_0=1)$, I tried finding $P^3_{(1,1)}$ which I got $1/24$. Is that correct? 3) For finding $\mathbb{P}(X_2=4)$, do I just take $π(P^2)$?","['probability-theory', 'markov-chains']"
79762,What is the lowest dimension $d$ for which the simple random walk on $\mathbb Z^d$ is transient?,"By ""transient"" I think they mean that the probability of returning to the initial point is $<1$.","['probability-theory', 'random-walk']"
79765,Prove this determinant identity combinatorially,"This is for those of you who understand the Lindstrom-Gessel-Viennot lemma. I am looking for a proof of the following identity using paths and such: Let $A$ be an $n\times n$ matrix, and for $i,j\in\{1,\ldots,n\}$, let $A^{ij}$ denote the matrix resulting from $A$ after removing row $i$ and column $j$, then: $$\det\left(\begin{array}{cccc}\det(A^{11})&\det(A^{12})&\cdots&\det(A^{1n})\\ \det(A^{21})&\det(A^{22})&\cdots&\det(A^{2n})\\ \vdots &\vdots &\ddots &\vdots\\ \det(A^{n1})&\det(A^{n2})&\cdots &\det(A^{nn})\end{array}\right)=\det(A)^{n-1}$$ Read this for the algebraic proof: Is this a well known determinant identity? Are there any generalizations?","['determinant', 'combinatorics']"
79773,How does one prove that Lindeberg condition is satisfied?,"I have a sequence of $n$ random variables, each drawn from a different distribution $X_1\sim A_1, X_2\sim A_2, \ldots, X_n\sim A_n$.  The distributions $A_1, A_2, \ldots, A_n$ have nice properties: finite mean, variance, as well as third and fourth moments; all of them are defined over the support $\mathbb{R}$.  Unfortunately, besides the moments and support, I am not given any more information about $A_1,A_2,\ldots,A_n$. I am interested in studying the convergence of the normalized sum of these random variables: $$\sum_{i=1}^n(X_i-\mu_i)$$ in particular, I would like to know if knowledge of moments of $X_i$'s is sufficient to show so that the sequence satisfies Lindeberg's condition .  If it satisfies the condition, then CLT applies to the summation. I think that I understand the formula for the condition: $$\lim_{n\rightarrow\infty}\frac{1}{s_n^2}\sum_{k=1}^n\int_{\{|X_k-\mu_k|>\epsilon s_n\}}(x-\mu_k)^2f_k(x)dx=0$$ where $s_n^2=\sum_{k=1}^n\sigma_k^2$. (I wrote the formula as a Riemann integral, please let me know if I made a mistake -- the wikipedia article uses Lebesgue integral but I am not as comfortable with those.) If moments are not sufficient than what additional information about $X_i$'s do I need?  If they are sufficient, how do I use their properties to prove that condition is satisfied?  I think I understand the intuition behind the condition: no single random variable in the sequence can ""overwhelm"" the variance of the sum -- is that correct intuition?",['probability-theory']
79779,Properties of zero-diagonal symmetric matrices,"I'm interested in the properties of zero-diagonal symmetric (or hermitian) matrices, also known as hollow symmetric (or hermitian) matrices. The only thing I can come up with is that it cannot be positive definite (if it's not the zero matrix): The Cholesky decomposition provides for positive definite matrices $A$ the existence of a lower triangular $L$ with $A=LL^*$. However the diagonal of $LL^*$ is the inner product of each of the rows of $L$ with itself. Since the diagonal of $A$ consists of zeros, so $L$ (and thus $A$) must be the zero matrix. The sorts of questions that interest me are: which symmetric matrices can be transformed orthogonally into a zero-diagonal matrix? what can we say about the eigen-values of a zero-diagonal symmetric matrix?. any other interesting known properties??","['symmetric-matrices', 'matrices', 'linear-algebra', 'hermitian-matrices']"
79800,"Looking to find the largest rectangle, by area, inside a polygon","I'm looking to print text inside a polygon, programmatically.  I'd like to find the largest rectangle to position the text inside the polygon out of a sub set of rectangles, ie those oriented with their longest axis along 45° increments, eg 0°, 45°, 90° etc. I'm not even 100% sure if I've even asked this question correctly, but the point of it is to get a sensible default position and orientation for text within a polygon.  I'm open to all sensible alternative suggestions, but I guess ideally would like an algorithm to work out this rectangle. I'm also aware that it's possible to contrive a polygon which would make most algorithms useless which would include as part of the polygon an extremely long thin rectangular section, resulting in illegible text, if it's not possible to account for this some way, I'm fine with assuming this will not occur in my situation as there will be a manual override for position and orientation in my scenario. EDIT:
Thinking about how complicated this is, it might be easier to remove the angular restriction, then rotate and shrink the rectangle to one of those orientations after calculating it as a simplification.  Also I guess the length of the text is quite important, so the algorithm would have to be adaptable to a rectangle of a specific ratio... Feel free to throw ideas out, I'm happy to bounce back and forth with people about the best way to do this. EDIT2:
Suggested by a friend: Calculate the longest line inside the polygon, then use that as an axis for a rectangle.  So I will enumerate all lines going through 2 vertexes till I find the longest, then rectangularise each line starting at the longest, into the largest rectangle with the correct ratios. Then the largest one of these should be quite close to what I want.  Any feed back on this approach? EDIT3:
I ended up drawing the ""biggest"" rectangle by subdividing my problem area up into a grid of n by n squares (where n was a relatively large, yet sensible for my problem domain, size), checking if the four corners were all inside the poly.  If they were I'd increase the size of the square by n, interating this until it was outside the poly, then increase it by n length wise and repeat the width increase (keeping a record of the largest area rectangle as I went) until I'd found the biggest rectangle for that size subdivision.  I'd then half n and starting from my current largest rectangle, repeat the process. Repeating everything until I reached a suitable small value of n.","['optimization', 'geometry', 'computational-geometry', 'second-order-cone-programming']"
79809,Proving two sequences identical,"I found something quite interesting while browsing around the OEIS yesterday. I have no idea how to prove this (I don't even know if it's true in general, but Mathematica tells me that it holds up to at least 50 000.) Can we prove that this sequence , that is
$$
\text{A095112}(n) = \sum_{\substack{p \text{ prime, } k>0 \\ p^k \mid n}} \frac{n}{p^k} \quad \overset{\underset{\mathrm{?}}{}}{=} \quad \sum_{d \mid n} \varphi(d) \Omega \left( \frac{n}{d} \right),
$$
where the double sum on the left is ""sum of $n/k$ over all prime powers $k>1$ which divide $n$"" . On the right $\varphi(n)$ denotes Euler's totient function and $\Omega(n)$ is total number of prime factors of $n$. Looking at an example we see that
$$
\sum_{\substack{p \text{ prime, } k>0 \\ p^k \mid 12}} \frac{12}{p^k} = \frac{12}{2} + \frac{12}{2^2} + \frac{12}{3} = 6 + 3 + 4 = 13,
$$
and
$$
\begin{align*}
\sum_{d \mid 12} \varphi(d) \Omega \left( \frac{12}{d} \right) &=  \varphi(1)(3)+\varphi(2)(2)+\varphi(3)(2)+\varphi(4)(1)+\varphi(6)(1)+\varphi(12)(0) \\\
&= 3+2+4+2+2=13.
\end{align*}
$$
How do we attack a problem like this? Is this obvious or hard? Any light shed on this would be nice!","['analytic-number-theory', 'sequences-and-series', 'number-theory']"
79816,Multiplicative functionals for Markov process: discrete time,"I read a theorem, stating Let $X_t$ be a Markov process w.r.t. to its natural filtration $(\mathcal F_t)$ on the space of cadlag functions on $\mathbb R_{\geq 0}$ and $(Z_t)_{t\geq 0}$ be a non-negative martingale s.t. $\mathsf E_xZ_t = 1$ for all $x,t$. Let $ \mathsf{\tilde{P}}$ be such that 
  $$
\mathsf{\tilde{P}}_x(A):=\mathsf E_x[1_A\cdot Z_t]
$$
  for any $A\in \mathcal F_t$, then the family $(\mathsf{\tilde{P}}_x)$ defines a time-homogeneous Markov process iff $Z_t$ is multiplicative functional, i.e.
  $$
Z_{t+s} = Z_t\cdot(Z_s\circ \theta_t)
$$
  where $\theta_t$ is the shift operator. I wonder which form can $Z$ take for a discrete time Markov process. The motivation is that for random walks $Y$ there is closed form for $Z$ given by
$$
Z_n = h(Y_1)\cdot h(Y_2)\cdot\dots\cdot h(Y_n)
$$
where $\mathsf E h(Y_1) = 1$.","['probability-theory', 'stochastic-processes']"
79822,Locally Free Sheaves,"If $X$ is a locally noetherian scheme and $F$ is a coherent sheaf, I want to show the following equivalence: $F$ is locally free iff its stalk is a free $O_{X,p}$-module for every $p$ in $X$. => follows from the definition of locally free. <= is difficult for me: I don't see how to combine finite-type condition on $F$ with locally noetherian property.",['algebraic-geometry']
79835,Counting ordered triples of non-negative integers not greater than 100,"Can we find the number of ordered triples $(x,y,z)$ of non-negative integers satisfying
(i) $x \leq y \leq z$
(ii) $x + y + z \leq 100$?
Source:Regional Mathematics Olympiad India (2003)
Thank you.I have an ugly solution.But I am hoping for some insightful/elegant solutions.","['recreational-mathematics', 'problem-solving', 'contest-math', 'combinatorics']"
79842,Is an ellipse a circle transformed by a simple formula?,"Does any ellipse $E$ have a circle $C$ such that you can obtain $E$ by transforming $C$ by a simple formula $F$?
In details , both $E$ and $C$ have the same center and the axes of $E$ are the XY axes.
And F moves $(x,y)$ to  $( m*x , y)$ . Where m is a real number. Thank you in advance.","['geometry', 'conic-sections', 'circles']"
79852,Does $G\cong G/H$ imply that $H$ is trivial?,"Let $G$ be any group such that $$G\cong G/H$$
where $H$ is a normal subgroup of $G$. If $G$ is finite, then $H$ is the trivial subgroup $\{e\}$. Does the result still hold when $G$ is infinite ? In what kind of group could I search for a counterexample ?","['examples-counterexamples', 'quotient-group', 'group-theory', 'hopfian']"
79857,"Is $\frac{1}{\sqrt{2\pi t}} \int_{\mathbb{R}} e^{-\frac{(x-iut)^2}{2t}} \, dx=1$?","$i$ is such that $i^2=-1$. I am not familiar with complex integral. Is
$$
\frac{1}{\sqrt{2\pi t}} \int_{\mathbb{R}}  e^{-\frac{(x-iut)^2}{2t}} \, dx=1
$$
as if computing the probability of a normal density function despite the mean is imaginary. . Thanks!",['integration']
79861,Is ArcTan(2) a rational multiple of $\pi$?,"Consider a $2 \times 1$ rectangle split by a diagonal.  Then the two angles
at a corner are ArcTan(2) and ArcTan(1/2), which are about $63.4^\circ$ and $26.6^\circ$.
Of course the sum of these angles is $90^\circ = \pi/2$. I would like to know if these angles are rational multiples of $\pi$.
It doesn't appear that they are, e.g., $(\tan^{-1} 2 )/\pi$ is computed as 0.35241638234956672582459892377525947404886547611308210540007768713728\
  85232139736632682857010522101960 to 100 decimal places by Mathematica.  But is there a theorem that could be applied here to
prove that these angles are irrational multiples of $\pi$?  Thanks for ideas and/or pointers! (This question arose thinking about Dehn invariants.)","['trigonometry', 'reference-request', 'irrational-numbers']"
79864,Relative entropy between singular measures,"Usually, to define relative entropy between two probability measures, one assumes absolute continuity. Is it possible to extend the usual definition in the non absolutely continuous case?","['singular-measures', 'probability', 'entropy']"
79865,Difficulty level of Courant's book,"I am currently studying Introduction to Calculus and Analysis by Richard Courant and Fritz John. I would like to compare Courant's book with Apostol's and Spivak's in terms of difficulty of the problems provided. After reading that book, should I go for one of the two above or should I study something else like Rudin? My focus is on being rigorous and also adept at problem solving.","['reference-request', 'soft-question', 'analysis']"
79869,Exponential generating function for restricted compositions,"I wanted to know if it is possible to use exponential generating functions to evaluate composition of N using K distinct numbers (where the supply of numbers is infinite)? For e.g if N=10 and a1=2,a2=3,a3=5 then number of solutions would be (2,3,5),(2,5,3),(3,2,5),(3,5,2),(5,2,3),(5,3,2),(2,2,2,2,2),(3,3,2,2),(3,2,2,3),(2,2,3,3),(2,3,2,3),(3,2,3,2),(2,3,3,2) I tried with writing generating functions for 2,3 and 5 but was not able to deduce anything.","['integer-partitions', 'generating-functions', 'combinatorics']"
79875,"Laws of $(B_t)_{t\in [0,T]}$ and $(2B_t)_{t\in [0,T]}$ : singular?","Are the laws of  $(B_t)_{t\in [0,T]}$ and $(2B_t)_{t\in [0,T]}$ mutually singular ? More precisely, I know that the laws of two diffusion processes are mutually absolutely continuous if they share a common diffusion coefficient (application of Girsanov theorem). However, I cannot understand why it is no more the case when they have different diffusion coefficients. This is why I ask the question about $(B_t)_{t\in [0,T]}$ and $(2B_t)_{t\in [0,T]}$. If their laws are not mutually continuous, that would mean that one can find a measurable set of trajectories $\mathcal{A}$ for which $\mathbb{P}[(B_t)_{t\in [0,T]} \in \mathcal{A}]>0$ while $\mathbb{P}[(2B_t)_{t\in [0,T]} \in \mathcal{A}]=0$. The problem is : I don't know how to find such a set $\mathcal{A}$. Can anyone help me to understand this point ? Thank you folks !",['probability-theory']
79881,Cyclic group of order 15,"I'm reviewing for the math GRE (it's been 8+ years since I took abstract algebra) and came across this question: A cyclic group of order 15 has an element $x$ such that the set $\{x^3, x^5, x^9 \}$ has exactly two elements. The number of elements in the set $\{x^{13n}: n \text{ a positive integer } \}$ is what? Can someone show me how to approach this problem, and what concepts are in play here?","['gre-exam', 'finite-groups', 'abstract-algebra']"
79896,Ext groups of a point on a scheme,"Given a scheme $X$ over a field $k$ and a closed point $x$ with residue field $k(x)$ and inclusion $i:{x}\rightarrow X$ one can consider the following abelian groups (1)$Ext^1_{\mathcal O_X}(i_*k(x),i_*k(x))$ and (2)$Ext^1_{\mathcal O_{X,x}}(k(x),k(x))$. The second one is just seen as Ext-group in the sense of modules over a ring. Are they isomorphic? I would define a map from (1) to (2) by just taking stalk in $x$, but I dont really see how one would come from (2) to (1). Addition: And is there a structure of a $k-$ vector space on (2) such that the iso is also one of $k-$spaces? (1) surely has a $k-$vector space structure as the scheme is defined over $k$.","['algebraic-geometry', 'schemes']"
79911,Finding $\lim_{n \to \infty }\sqrt[n]{b^{2^{-n}}-1}$ without L'hopital,"I found the limit $\lim_{n \to \infty }\sqrt[n]{b^{2^{-n}}-1}$ by first defining $f(x)=\sqrt[x]{b^{2^{-x}}-1}$ above $R$ and then finding the limit of $ln(f)$ (to cancel the nth root). This worked (the result is $1/2$), but I ended up having to find the derivative of rather complex functions when I used L'hopital (twice). My worry is that if I have to solve something like this in a test I'll easily make a technical error. I was wondering if there is a simpler way to find this limit? I know most basic techniques of finding limits in $R$ and a bit (Stoltz, Cantor's lemma, ...) about finding limits of sequences. Thank you for your help!","['limits-without-lhopital', 'calculus', 'limits']"
79913,Determining the minimal polynomial,"How do you find the minimal polynomial, $\mu_{M^{-1}}(x)$ given  $\mu_{M}(x)$? My guess is since if $\lambda$ is an eigenvalue of $M$, then $1\over \lambda$ is an eigenvalue of $M^{-1}$, we might have something like $\mu_{M^{-1}}(x)=\mu_{M}({1\over x})$? But then I am not sure that that is the minimal polynomial... Thanks","['matrices', 'linear-algebra']"
79926,How to evaluate this determinant?,"Can someone give me a hint how to solve $$\left|\begin{array}{ccccc}
1 & 1 & \ldots &  & 1\\
2x_{1} & 2x_{2} &  &  & 2x_{n}\\
\vdots\\
nx_{1}^{n-1} & nx_{2}^{n-1} & \ldots &  & nx_{n}^{n-1}\\
\\
\end{array}\right|$$ ? I know that I somehow have to use the Vandermonde determinant to do this, but I can't figure out how to get rid of the coefficients. Can someone give me a hint please ?","['linear-algebra', 'determinant']"
79935,Do we need to use the Ratio/Root test to determine divergence of a series?,"From the proofs of the Root and Ratio tests for a series, one deduces that if one of these tests shows divergence, then the terms of the series in question do not tend to zero. I am therefore interested in finding  an example of a divergent series (accessible to Calc II students) for which the Ratio or Root test is substantially easier to apply that the $n^{\rm th}$-term test (the Divergence Test). Does anyone know of one? Thank you for any help, and I apologize in advance for the vague requirement ``substantially easier''.","['sequences-and-series', 'calculus']"
79937,"$ \int_\mathbb{R} y \left( \int_\mathbb{R} I_B(x) f_{X,Y}(x,y) \,dx \right) \, dy = \int_\Omega Y I_{X^{-1}(B)} \, dP \quad ? $","Suppose $X$ and $Y$ are two random variables defined on a probability space $(\Omega, \mathcal{F},P)$ with joint density function $f_{X,Y}$. For any $B \in \mathcal{B}(\mathbb{R})$, why is it that
$$
 \int_\mathbb{R} y \left(  \int_\mathbb{R} I_B(x) f_{X,Y}(x,y) \,dx \right) \, dy
= \int_\Omega Y I_{X^{-1}(B)} \, dP \quad ?
$$
Note:
This is one step needed in my attempt to prove that the elementary definition and theorectical definition of $E(Y|X)$ agree a.e. after applying Fubini's Theorem. Thanks!",['probability-theory']
79940,When did Fubini's name get applied to the theorem without measures?,"Fubini's theorem, from 1907, expresses integration with respect to a product measure in terms of iterated integrals. The simpler version of this theorem for multiple Riemann integrals was used long before Fubini was around and of course was not known by his name. Nowadays it is common for the relation between multiple Riemann integrals and iterated integrals to be called Fubini's theorem in books. A colleague of mine asked me when the label ""Fubini's theorem"" was first applied to this theorem about multiple Riemann integrals. (He considers it something of a travesty to use Fubini's name for this result in multivariable calculus books, where there is no measure theory content. As an example, in the 4th edition of Calculus (1990) by Larson, Hostetler, and Edwards the authors write ""The following theorem was proved by the Italian mathematician Guido Fubini"" and then they give a theorem on double integrals of continuous functions which certainly was not proved by Fubini.) I found this theorem does not have Fubini's name in some calculus and analysis books written decades ago: Whittaker and Watson's Modern Analysis (4th ed., 1927), Volume II of Apostol's Calculus (1962), Rudin's Principle of Mathematical Analysis (3rd ed., 1964), Thomas's Calculus and Analytic Geometry (4th ed., 1969), Bers's Calculus (1969), Loomis's Calculus (1974), Sherman Stein's Calculus and Analytic Geometry (2nd ed., 1977), George Simmons's Calculus with Analytic Geometry (1985), Marsden and Weinstein's Calculus III (1985), and Leithold's The Calculus with Analytic Geometry (5th ed., 1986). They all call this result something like ""the theorem on iterated integrals"". I found the name ""Fubini's theorem"" used for multiple Riemann integrals in Spivak's Calculus on Manifolds (1965). Does anyone know of an earlier usage of the label ""Fubini's theorem"" for multiple Riemann integrals?","['multivariable-calculus', 'math-history', 'reference-request']"
79944,How can we evaluate $\int_{0}^{\infty}e^{-xt}\sin(t)dt$ without using Laplace transforms?,"Without using Laplace transforms, how do I show that for every positive number $x$ the following equation is valid? $$\int_{0}^{\infty}e^{-xt}\sin(t)dt=\frac{1}{x^2+1}. $$","['integration', 'complex-analysis']"
79946,"Show $X_n {\buildrel p \over \rightarrow} X$ and $X_n \le Z$ a.s., implies $X \le Z$ a.s.","Suppose $X_n  {\buildrel p \over \rightarrow} X$ and $X_n \le Z,\forall n \in \mathbb{N}$. Show $X \le Z$ almost surely. I've try the following, but I didn't succeed. By the triangle inequality, $X=X-X_n+X_n \le |X_n-X|+|X_n|$. Hence, $P(X \le Z) \le P(|X_n-X| \le Z) + P(|X_n| \le Z)$. I know that, since $X_n  {\buildrel p \over \rightarrow} X$ then $P(|X_n-X| \le Z) \to 1$, and we have $P( |X_n| \le Z)=1$. I can't go further.",['probability-theory']
79965,Subset of the preimage of a semicontinuous real function is Borel,"I'm in a jam with this problem: Let $ f: \mathbb{R} \to [-\infty,\infty] $ be lower semicontinuous, and let $ A = \{ x:f(x)\ge a \}  $. Is $A$ necessarily a Borel set in $ \mathbb{R} $? I've actually managed to prove that if $A$ has no excluded points, then it is Borel, and it's easy to use that to show that it's also Borel if there are only countably many such points, but I wasn't able to do so, so I guess a hint in this direction would be appreciated. I do feel, however, that there's a much less roundabout way to resolve this problem, so if someone could gently hint me to the right direction I would be most grateful.","['borel-sets', 'measure-theory', 'semicontinuous-functions', 'real-analysis']"
79969,Is my reasoning/understanding of definitions right?,"Does the following reasoning make sense? I have an $n\times n$ matrix $M$ acting on $\mathbb C^n$, Then, The eigenspace of matrix $M$ is $\ker(M-\lambda I)$. The eigenvalues of  $M^2$ are $\lambda^2$, where $\lambda$ are eigenvalues of $M$. $Mv=\lambda v \implies M^2 v=\lambda^2v \implies$ eigenvectors of $M$ are eigenvectors of $M^2$ Now $M^2v=\lambda^2 v\implies Mv=\pm\lambda v$ so eigenvectors of $M^2$ are also eigenvectors of $M$ Hence the eigenspaces of $M$ and $M^2$ are the same? (Check: To have the same eigenspace does that mean just having the same set of eigenvectors?) Thanks.","['matrices', 'eigenvalues-eigenvectors']"
79970,Finding eigenvalues by inspection?,"I need to solve the following problem, In this problem, the eigenvalues of the coefficient matrix can be
  found by inspection and factoring. Apply the eigenvalue method to find
  a general solution of the system. $x'_1=2x_1+x_2-x_3$ $x'_2=-4x_1-3x_2-x_3$ $x'_3=4x_1+4x_2+2x_3$ Now I know how to find the eigenvalues by using the fact that $|A-\lambda I|=0$, but how would I do it by inspection? Inspection is easy for matrices that have the sum of their rows adding up to the same value, but this coefficient matrix doesn't have that property. EDIT: Originally I didn't understand what inspection meant either. After googling it this is what I found. Imagine you have the matrix,
$A = \begin{pmatrix} 2 & -1 & -1 \\ -1 & 2 & -1 \\ -1 & -1 & 2 \end{pmatrix}$ By noticing (or inspecting) that each row sums up to the same value, which is 0, we can easily see that [1, 1, 1] is an eigenvector with the associated eigenvalue of 0.","['ordinary-differential-equations', 'eigenvalues-eigenvectors']"
79973,Is an algebraic formula for the number of cyclic compositions of n known?,"From Wikipedia : In January 2011, it was announced that Ono and Jan Hendrik Bruinier, of the Technische Universität Darmstadt, had developed a finite, algebraic formula determining the value of p(n) (number of partitions of n) for any positive integer n. Is such a formula known for the number of cyclic compositions of n (i. e., cyclically ordered partitions of n - where (1,2,3), (2,3,1), and (3,1,2) are considered the same, but not (1,3,2))? If so, what about the number of cyclic compositions of n with parts at least equal to 2?","['fibonacci-numbers', 'integer-partitions', 'factoring', 'number-theory']"
79978,Linear combination of natural numbers with positive coefficients,"I'm searching for a reference for the following result, so as to avoid writing a full proof in a paper.  Alternatively, if a one-liner exists, I'd be glad to know it! Theorem: Let $a, b$ be two positive integers.  Then there is a finite set $N$ of positive integers smaller than $\mbox{lcm}(a, b)$ such that:
$$\{k_1a + k_2b \mid k_1, k_2 \in \mathbb{N}\} = \{\mbox{lcm}(a, b) + k\times\gcd(a, b) \mid k \in \mathbb{N}\} \cup N.$$ I'm also interested in its generalization to any number of integers: Say a set of integers is a linear set with $n$ periods if it can be written as:
$$\{c_0 + \sum_{i=1}^n k_i \times c_i \mid k_i \in \mathbb{N}\}.$$
Then: Theorem: Any linear set is the union of a finite set and a linear set with one period. Thanks!","['linear-algebra', 'reference-request']"
79987,Limits at infinity,"$f(z), g(z)$ are two entire functions, both have no zeros in the closed upper half plane. What does it mean/imply that $$\bigg| \lim_{y\rightarrow \infty}\frac{f(z)}{g(z)}\bigg|=c$$
($z=x+iy$)
i.e. after taking the limit inside the modulus the resulting function -depends on x- have modulus c. (In fact what I have is like: $|\lim_{y\rightarrow \infty} (\dots)|=|..ce^{ix}|=c$) (I think it implies that $|f(z)|\leq c|g(z)|$ for all $z$  in the upper half plane, is that correct, and if so how to prove it!) Also, what does it mean/imply that $$\bigg|\lim_{y\rightarrow 0}\frac{f(z)}{g(z)}\bigg|=d$$ EDIT: $c$ and $d$ are non zero.","['complex-analysis', 'limits']"
79999,Fundamental group of a compact manifold,"In an article I am currently reading, the author tells us that for compact (finite dimensional topological) manifolds X and finite groups $\Gamma$, the set $$\mathrm{Hom}(\pi_1X,\Gamma)/\Gamma$$ where $\Gamma$ acts on the set $\mathrm{Hom}(\pi_1X,\Gamma)$ via $(\varphi\cdot\gamma)([c]):=\gamma^{-1}\varphi([c])\gamma$, is finite . This quotient space is naturally in bijection with the isomorphism classes of principal bundles over $X$ with structure group $\Gamma$. How do you show that $\mathrm{Hom}(\pi_1X,\Gamma)/\Gamma$ is finite? I can see one pathway which would be to show that the fundamental group of $X$ is finitely generated, which would entail that the set $\mathrm{Hom}(\pi_1X,\Gamma)$ itself is finite. I thought I remembered a proof of this fact from John M. Lee's Introduction to Topological Manifolds , and I tried in vain to reproduce it. He actually shows that the fundamental group is countable. I have two ""proofs"" or rather ""plausible arguments"" that work in the differentiable setting. The first uses Morse theory : $X$ is homotopy equivalent/homeomorphic (which one is it?) to a finite CW-complex, and those have finitely generated fundamental groups. The other one uses a riemannian metric on $X$ and a (finite) cover $\mathcal{O}_1,\dots,\mathcal{O}_N$ by geodesically convex open sets. I recall reading in Bott and Tu's Differential Forms in Algebraic Topology (where it is cited without proof but with a reference) that those exist. It seems plausible that such open sets $\mathcal{O}$ should be contractible : you can take some fixed point $x\in\mathcal{O}$ and define $$C:\mathcal{O}\times[0,1]\to\mathcal{O},~(y,t)\mapsto c_{x,y}(1-t)$$ where $c_{x,y}:[0,1]\to\mathcal{O}$ is the (unique) shortest geodesic that joins $x\rightarrow y$. By definition of being geodesically convex, there is indeed a unique shortest geodesic between any two points in $\mathcal{O}$ and it stays inside $\mathcal{O}$ at all times, and so $C$ is well defined (and smooth). The next step copies a proof of Van Kampens's theorem : fix a basepoint $x_0\in X$. For any $i,j$, $\mathcal{O}_i\cap\mathcal{O}_j$ is either empty or non empty and geodesically convex. Pick points $x_{ij}\in\mathcal{O}_i\cap\mathcal{O}_j$ and paths $c_{ij}$ that link $x_o\rightarrow x_{ij}$. Also, for any $i,j,j'$ with $\mathcal{O}_i\cap\mathcal{O}_j\neq\emptyset$ and $\mathcal{O}_i\cap\mathcal{O}_{j'}\neq\emptyset$ define a path $$c_{j,i,j'}:x_0\underbrace{\longrightarrow}_{c_{ij}} x_{i,j}\underbrace{\longrightarrow}_{*} x_{ij'}\underbrace{\longrightarrow}_{\overline{c_{ij'}}} x_0$$ where $*$ is any path inside $\mathcal{O}_i$ that links $x_{ij}\rightarrow x_{ij'}$ and $\overline{c_{ij'}}$ is $c_{ij'}$ in reverse. The $c_{j,i,j'}$ should span $\pi_1X$, thus showing that it is finitely generated (contractability of $\mathcal{O}_i\cap\mathcal{O}_j$ is key). My worry with both proofs is that I don't really know Morse theory, and I don't know why geodesically convex open sets exist around every point in a riemannian manifold. Of course, this could be remedied by studying the subjects, but I wonder : Are there more elementary proofs of the fact that compact (possibly smooth) manifolds have finitely generated fundamental group? Also, is it true that compact topological manifolds have finitely generated fundamental groups?","['manifolds', 'group-theory']"
80001,Quadratic variation of a Brownian motion up to time $T$ converges to $T$ in $L^2$?,"In Stochastic Calculus for Finance II: Continuous-time Models by Steve Shreve, Theorem 3.4.3. Let $W$ be a Brownian motion. Then $[W, W](T) = T$ for
  all $T > 0$ almost surely. where $[W, W](T)$ is the quadratic variation of $W$ up to time T
$$
[W, W](T): = \lim_{||\Pi|| \to 0} \sum_{j=0}^{n-1} [W(t_{j+1}) - W(t_j)]^2
$$
where $$\Pi=[t_0, t_1, \dots, t_n] \text{ and } 0 \leq t_0 < t_1 < \cdots  < t_n = T$$
and
$$||\Pi||= \max_{j=0,\dots, n-1} (t_{j+1} -t_j).$$ One fellow student also says a stronger conclusion is also true, i.e. $[W, W](T)$ converges to $T$  in $L^2$ or in $L^p, p>1$, for all $T > 0$. By ""stronger"", I mean I heard it implies the original theorem for convergence a.e.. I wonder if there are some texts or online tutorials for proving this stronger conclusion, and/or if you could kindly provide the proof here? Thanks!","['probability-theory', 'stochastic-processes', 'quadratic-variation', 'brownian-motion']"
80003,Prove variant of triangle inequality containing p-th power for 0 < p < 1,"Sorry if this is a trivial question, but I am kind of stuck with proving the following inequality and have been searching for a while: $\rho \left( \sum\limits_i^n d_i \right) \leq \sum\limits_i^n \;\rho(d_i)\;$ with $\rho(d_k) := |d_k|^p, \quad 0 < p < 1 $ and $ d_i \in \mathbb{R}$. I encountered this situation while dealing with an energy-based regularization approach. While I do not expect this inequality to hold for $p > 1$, I basically believe that it does so for $0 < p < 1$, implying that the energy $\rho$ for the sum of all $d_i$ is lower than the sum of energies of the individual $d_i$, under such a quasi-norm. I attempted to show this for the less general case where $p := \frac{q}{r}$ is a rational number, by raising both sides to the $r$-th power: $\mid\sum\limits_i^n d_i\mid^p \leq \sum\limits_i^n \mid d_i \mid^p \; \Leftrightarrow \; \mid\sum\limits_i^n d_i\mid^q \leq \left( \sum\limits_i^n \mid d_i \mid^p \right)^r = \sum\limits_i^n  \mid d_i \mid^{pr} + u  = \sum\limits_i^n  \mid d_i \mid^{q} + u$, where $u$ contains a sum of mixed terms. Next, I tried to get rid of the $q$ exponent in order to somehow make use of the triangle inequality. However, it seems like I am going in circles here. Could somebody give me a hint on how to better approach this? Is there an existing inequality that I could use in proving this? I guess these are basics that have been studied before, I am just not sure what keywords to search for. Thank you very much!","['exponentiation', 'absolute-value', 'inequality', 'real-analysis']"
80006,Gambler's ruin (calculating probabilities--hitting time),Im meant to produce the transition matrix which I've already done (in the picture) and list the communication classes. But Im not sure how to find the probability regarding the hitting times (see question). Any suggestions? Cheers.,"['probability-theory', 'stochastic-processes', 'markov-chains']"
80010,"Finding the slope of the tangent line to $\frac{8}{\sqrt{4+3x}}$ at $(4,2)$","In order to find the slope of the tangent line at the point $(4,2)$ belong to the function $\frac{8}{\sqrt{4+3x}}$, I choose the derivative at a given point formula. $\begin{align*} 
\lim_{x \to 4} \frac{f(x)-f(4)}{x-4} &= 
\lim_{x \mapsto 4} \frac{1}{x-4} \cdot \left (\frac{8}{\sqrt{4+3x}}-\frac{8}{\sqrt{4+3 \cdot 4}} \right ) 
\\ \\ & = \lim_{x \to 4} \frac{1}{x-4} \cdot \left ( \frac{8}{\sqrt{4+3x}}-\frac{8}{\sqrt{16}} \right ) \\ \\ & = \lim_{ x \to 4} \frac{1}{x-4} \cdot \left ( \frac{8}{\sqrt{4+3x}}-2\right) 
\end{align*}$ But now I can't figure it out, how to end this limit.
I know that the derivative formula for this function is $-\frac{12}{(4+3x)\sqrt{4+3x}}$. Thanks for the help.",['limits']
80011,Only a solvable group can have 3 Sylow p-subgroups,"Is there an easy proof that amongst finite groups, only a solvable group can have exactly 3 Sylow p -subgroups? I have a proof, but it is a bit complex, and I'm looking to use this as an easy first example of how counting can influence global structure. It also appears to be somewhat uniquely dramatic.  If the first question is too easy, then: Is n = 3 the only positive integer such that every finite group with exactly n Sylow p -subgroups is solvable? (where p depends on the group, and where there is at least one finite group with n Sylow p -subgroups) I haven't found another n , even fixing p = 2. Of course, there are n such that no group has n Sylow p -subgroups, but I am not asking about such vacuous n .","['finite-groups', 'group-theory']"
80016,Product of two Lebesgue integrable functions not Lebesgue integrable,"I have a homework problem that says; Give Borel functions $f,g: \mathbb{R} \to \mathbb{R}$ that are Lebesgue integrable, but are such that $fg$ is not Lebesgue integrable. I saw this page too: Product of two Lebesgue integrable functions , but the question does not mention boundedness. I also am not sure what to do with the fact that the functions are Borel. (Any help on this would be especially appreciated) I know that if $fg$ were Lebesgue integrable then both $\int (fg)^+\,d\mu$ and $\int (fg)^-\,d\mu$ would be finite. This could lead to utilizing the finiteness of their difference (the function's integral) or their sum (the absolute value). I also know that $f+g$ are Lebesgue integrable if $f$ and $g$ are so I thought of using $$fg = \frac{1}{4}\,\big( (f+g)^2 - (f-g)^2 \big)\longrightarrow \int (fg)\,d\mu = \frac{1}{4}\,\int (f+g)^2\,d\mu - \frac{1}{4}\,\int (f-g)^2\,d\mu,$$ assuming linearity of the integral etc. I also thought of the Hölder inequality, $$\int \mid fg \mid d\mu \leq \bigg( \int \mid f \mid^p d\mu \bigg)^{(1/p)}\,\bigg( \int \mid g \mid^q d\mu \bigg)^{(1/q)},$$ but there was no mention in the question of what $L^p$-space this was in. Maybe by the definition I gave it is such that $p=1$ and $q=1$? Then $$\int \mid fg \mid d\mu \leq \bigg( \int \mid f \mid d\mu \bigg)\,\bigg( \int \mid g \mid d\mu \bigg).$$ However, I still can't seem to think of an approach to show that $fg$ is not Lebesgue integrable, while $f$ and $g$ are. Thanks for any guidance!",['real-analysis']
80025,A question about the definition of a neighborhood in topology,"Let $X$ be a topological space, and $x \in X$ be a point. There are two prevalent conventions on how to define a neighborhood of $x$: Alternative Definitions (Neighborhood): 1) A neighborhood of $x$ is any open subset $W \subset X$ such that $x \in W$. (This convention is used in Munkres's book for example.) 2) A neighborhood of $x$ is a subset $W \subset X$ such that there exists an open set $A$ such that $x \in A \subset W$. (For example this is the definition in Bourbaki's or Willard's ""General Topology"") Thus, every neighborhood in the sense of (1) is a neighborhood in the sense of (2), but not vice-versa. One often needs to show that a neighborhood of a point $x$ in the sense of (2) is actually open, and often this is a non-trivial verification from the given context. An example that I can come up with now (and this example was a motivation for asking this question) is the following: Let $G$ be a topological abelian group, and $H$ a subgroup of $G$ which is also a neighborhood of $0 \in G$ in the sense of 2). Then one can show that $H$ is in fact an open set. [The trick is to observe that for a given $g \in G$, the map $\phi_{g} :G \rightarrow G$ given by for $x \in G, \phi_{g}(x) = g + x$ is a homeomorphism, and so any neighborhood of a point $g \in G$ is of the form $g + U$, where $U$ is a neighborhood of $0$. Thus, for an $h \in H$, $h + H$ is a neighborhood of $h$, and moreover, $h + H \subset H$ because $H$ is a subgroup.] The above proof shows that sometimes proving that a neighborhood in the sense of (2) is open is not completely trivial, while a neighborhood in the sense of (1) is always open. At times like these, I wonder why the second definition of a neighborhood is used at all. But I have learned topology primarily from Munkres, and so I might be ignorant of the advantages of definition (2). So, what do you think are some of the advantages of using (2) as a definition for a neighborhood of a point $x \in X$, where $X$ is a topological space? (This might be a duplicate question. But I searched a little bit and could not find a question that was exactly similar to this one. So, excuse me if I have asked something that was already asked.)","['general-topology', 'soft-question']"
80043,Help deriving that $\mathrm{sign} : S_n\to \{\pm 1\}$ is multiplicative,"$\def\sign{\operatorname{sign}}$ For homework, I am trying to show that the map $\sign:S_n \to \{\pm 1\}$ is multiplicative, i.e. that for any permutations $\sigma_1,\sigma_2$ in the symmetric group $S_n$ , we have $$\sign(\sigma_1 \sigma_2) = \sign\sigma_1 \sign\sigma_2.$$ The definition for $\sign$ that I am using is that if $\sigma = \gamma_1\cdots \gamma_k$ is the cycle decomposition of $\sigma \in S_n$ and $\ell_1,\ldots,\ell_k$ are the cycle lengths of $\gamma_1,\ldots,\gamma_k$ respectively, then $$\sign(\sigma):= (-1)^{\ell_1-1}\cdots(-1)^{\ell_k-1}.$$ I showed first that the formula holds for two transpositions.
Then I showed that it holds for a transposition and a cycle. However, I got stuck trying to show that the formula holds for a transposition and a product of two cycles, i.e. $\sigma_1 = \tau$ and $\sigma_2 = \gamma_1\gamma_2$ . I feel like this case is much more complicated than the others which makes me think I am taking the wrong approach. If $\tau,\gamma_1,\gamma_2$ are all disjoint then the formula holds trivially because then $\gamma_1\gamma_2\tau$ is the cycle decomposition of $\sigma_1\sigma_2$ . Otherwise they are not all disjoint, at which point it seems to get complicated very quickly and I don't know how to proceed. Would someone please help me understand the best approach to this proof?","['permutations', 'symmetric-groups', 'multilinear-algebra', 'group-theory', 'determinant']"
80053,Top 3 of 4 Dice Rolls,"I'm trying to prove why the mean of the distribution of sums of the top 3 out of 4 fair 6 sided dice is rolls 12.25.  Anybody who's rolled a D&D character knows the idea. $r_n = Rand([1,6])$ $x = \frac{\sum_{i=1}^4{r_i} - min(r_i)}{3}$ Pardon the notation, I wasn't sure how to properly define the problem. So, I came to derive 12.25 with a computer program that just does several million iterations and comes up with something that's approaching 12.25.  I just don't know why or how to prove it.  I thought of splitting the interval [1,6] into 4 equal subsets and add the midpoint of the top 3.  But that didn't work.  Can someone explain why it's 12.25 and how to prove it?","['probability-theory', 'probability-distributions', 'probability']"
80062,Replacing two cross-caps by a handle,"For a non-orientable surface, we can replace a handle by two cross-caps.  Can we do the opposite i.e replace any two cross-caps by a handle? Any help is appreciated!!","['general-topology', 'algebraic-topology', 'surfaces']"
80074,What is a canonical version of conditional expectation?,"In David Williams's Probability with Martingales , there is a remark regarding conditional expectation of a random variable conditional on a $\sigma$-algebra: The 'a.s.' ambiguity in the definition of conditional expectation is
  something one has to live with in general, but it is sometimes
  possible to choose a canonical version of $E(X| \mathcal{Q})$. What is ""canonical version of $E(X| \mathcal{Q})$"", and what are some cases when it is possible to choose it? I don't want to be misleading, but is it referring to elementary definitions of conditional distribution and conditional expectation when they exist i.e. when the denominators are not zero? Thanks and regards!",['probability-theory']
80078,Taking the derivative of $\frac1{x} - \frac1{e^x-1}$ using the definition,"Given $f$: $$
f(x) = \begin{cases}
        \frac1{x} - \frac1{e^x-1} & \text{if } x \neq 0 \\
        \frac1{2}                 & \text{if } x = 0
\end{cases}
$$ I have to find $f'(0)$ using the definition of derivative (i.e., limits). I already know how to differentiate and stuff, but I still can't figure out how to solve this. I know that I need to begin like this: $$
f'(0) = \lim_{h \to 0} \frac{f(h)-f(0)}{h} = \lim_{h \to 0} \frac{\frac1{h} - \frac1{e^h-1}-\frac1{2}}{h}
$$ But I don't know how to do this. I feel like I should, but I can't figure it out. I tried distributing the denominator, I tried l'Hôpital's but I get $0$ as the answer, while according to what my prof gave me (this is homework) it should be $-\frac1{12}$. I really don't know how to deal with these limits; could someone give me a few tips?","['calculus', 'limits']"
80105,Notation on proving injectivity of a function $f:A^{B\;\cup\; C}\to A^B\times A^C$,"I'm trying to prove that for any cardinal numbers $a,b,c$, the following holds:
$a ^ {b + c} = a ^ b a ^ c$ i.e. that there exists a bijective function $ f : A ^ {B \:\: \cup \:\: C} \rightarrow A^B \times A^C $ This is only part of the proof sketch I have (proving $f$ is injective), and I'd like to know if is well written, since I believe it has flaws. Let $f: \{ g \:\:\: | g:B \cup C \rightarrow A \} \rightarrow \{ \langle g,h\rangle  | \:\:\: g: B \rightarrow A \wedge h : C \rightarrow A \}$ such that $f ( g_{b} \cup g_{c}) = \langle g_{b},g_{c}\rangle$. Now, $f( g_{b1} \cup g_{c1}) = f ( g_{b2} \cup g_{c2} ) \implies \langle g_{b1},g_{c1}\rangle = \langle g_{b2},g_{c2}\rangle$ and therefore $f$ is injective. Questions: Does that prove that $f$ is injective? I think it does not, since 
$f ( g_{b} \cup g_{c} ) = f ( g_{c} \cup g_{b}) \implies \langle g_{b},g_{c}\rangle  = \langle g_{c},g_{b}\rangle (\bot)$ Is there an alternative way to define $f$? It's difficult for me to define it in terms of properties of elements of its domain. Side note: The title says ""kinds"" because the function domain and image sets are sets of sets, but I may be mistaken using that word, if so, please edit accordingly.","['notation', 'elementary-set-theory', 'functions']"
80109,expected value of product of stochastic processes,"Let $X_t=\sigma \int_0^t e^{-a(t-s)} dW_s$, where $\sigma , a $ are constants. How can I find the expected value of the product of $X_t, X_s$ For t>s,  $\mathbb{E}[X_t, X_s]$, and $\mathbb{E}[X_t, W_s]$ where $W_s$ is brownian. I am not sure how i can modify ito's isometry so that i can find a simple solution.
Thanks","['probability-theory', 'stochastic-processes', 'stochastic-integrals']"
80113,How to find $\beta$ and $\alpha$?,"$\mathbb{P}$ is the prime numbers set. $p \in \mathbb{P}$ $a,b,c \in \mathbb{N}$ $n=a p^b+c$ where $c= n\bmod p$ $b$ is the highest power of $p$ who divides $n-c$ How to find $\beta$ where $\beta$ is the highest power of $p$ who divides $n!$? And how to find $\alpha$ where $\alpha$ is $\dfrac{n!}{p^\beta}\bmod p$? $n!=\alpha p^\beta$ Probably the answer will appear $a$, $b$, $c$, $p$ and factorials. Obs.: $x = y\bmod z \iff x \equiv y \pmod{z}$ and $0 \leq x \leq z-1$ $x,y,z \in \mathbb{N}$","['prime-numbers', 'factorial', 'discrete-mathematics', 'number-theory']"
80118,Solution to the stochastic differential equation,"Let $X_o=x$, $dX_t=\frac{1}{X_t}dt+X_tdW_t$, $W_t$ is a brownian motion i am thinking of trying $Y_t=\frac{X_t^2}{2}$ and apply ito's lemma on $Y_t$","['probability-theory', 'stochastic-processes', 'stochastic-integrals']"
80124,Questions about regular conditional probabilities,"In Section 9.9. Regular conditional probabilities and pdfs of David Williams' Probability and Martingales : By linearity and (cMON), we can show that for a fixed sequence $(F_n)$
  of disjoint elements of $\mathcal{F}$, we have $$ (a) P(\cup F_n |
 \mathcal{G}) = \sum P(F_n | \mathcal{G}) $$ a.s.. Except in trivial
  cases, there are uncountably many sequences of disjoint sets, so we
  cannot conclude from (a) that there exists a map $$P(.,.) : \Omega
 \times \mathcal{F} \to [0,1)$$ such that (b1) for $F \in \mathcal{F}$, the function $P(.,F)$ is a version of
  $P(F| \mathcal{G})$; (b2) for almost every $\omega$, the map $P(\omega, .)$ is a
  probability measure on $\mathcal{F}$. I wonder why ""there are uncountably many sequences of disjoint sets, so we cannot conclude from (a) that ...""? How do ""a fixed sequence"" or ""uncountably many sequences"" of disjoint sets have different effect on whether ""$P(\omega, .)$ is a probability measure on $\mathcal{F}\,$"", given that a measure is defined to be additive for countably many disjoint sets? Thanks and regards!",['probability-theory']
80128,$L^p$ function that has no compact support,"I understand an $L^p$ function have in them as a dense subset the set of functions with compact support. But do there exist $L^p$ functions that do not  have compact support. What are some examples for elementary cases like $p=1,\ldots$? I hope I am not going in circles here, but I think my question is sensible. Although rationals are dense in reals, the two are still distinct. In the same way, although functions with compact support are dense in $L^p$ space, there should exist $L^p$ functions without compact support. Thanks!","['functional-analysis', 'lp-spaces']"
80129,Is this closed interval measurable?,"A common example of a semiring of sets is the family of half open interals $(a,b]\subseteq\mathbb{R}$. Also, the premeasure $\rho((a,b])=b-a$ is well known to extend to a measure on a $\sigma$-algebra. With a little tinkering, I believe the ""mirror images"" across the origin of these intervals also form a semiring. That is, the sets of form $[-b,-a)\cup(a,b]$ for $0<a<b$ are also a semiring. Say $I_{a,b}=[-b,-a)\cup(a,b]$. If I put nearly the same premeasure $\rho(I_{a,b})=b-a$ on this semiring, then I think that $\rho$ can be extended to a measure on a $\sigma$-algebra by taking the measure which sends a set $A$ to $\mu(A)/2$ for the usual Lebesgue measure $\mu$ on $\mathbb{R}$. (I hope this is correct?) Is there a way to tell if a closed interval $[a,b]$ is $\rho^*$ measurable? I'm interested in seeing maybe an example first to figure this out. Take an interval $[1,2]$ for example. I know that $[1,2]$ is $\rho^*$ measurable if for any $I\subseteq\mathbb{R}$, then $$\rho^*(I)=\rho^*(I\cap[1,2])+\rho^*(I\setminus[1,2]).$$ My feeling is that $[1,2]$ is $\rho^*$ measurable just by testing it with a few subsets $I$ of the real line. Is there a way to prove or disprove whether this is true? Thank you.","['measure-theory', 'analysis']"
80134,Using the notation of wedge product to solve a linear system of equations,I am trying to solve a problem that seems like a standard idea from linear algebra but with a the notion of wedge product and exterior algebra added it gets more complicated  for someone who isn't very comfortable using the wedge product notation.  Any explanation of the following problem would be greatly appreciated. Let $\sum_{j=1}^{n} a_{ij} v_j  = b_i$ for $1 \leq i \leq m$ where the system of linear equations is given over an arbitrary commutative ring $R$.  Let $c_j$ be columns of the matrix $(a_{ij}) $. Suppose that the all minors of the matrix $(a_{ij})$ of order greater than $p$ are zero but that $c_1 \wedge c_2 \wedge \ldots \wedge c_p \neq 0$. If we let $b = ( b_i)$ then why is it true that for $\sum_{j=1}^{n} a_{ij} v_j  = b_i$ to have a solution for $1\leq i \leq m$ then it is necessary that $c_1 \wedge c_2 \wedge \ldots \wedge c_p \wedge b = 0$?,"['tensor-products', 'linear-algebra', 'abstract-algebra', 'exterior-algebra']"
80139,Why is the  $L_p$ norm strictly convex for $1<p<\infty?$,"Let $x,y \in L_p$   such that  $\|x\|_p=\|y\|_p=1$ , $1< p<\infty$ and $x\neq y.$
Why is $\|x+y\|_p<2$  ? I'm not sure how to start the proof.. I don't know how to handle integral of $(x+y)^p$ and it seems that using the binomial theorem won't be a great success.",['functional-analysis']
80146,A question about composition of trigonometric functions,"A little something I'm trying to understand: $\sin(\arcsin{x})$ is always $x$, but $\arcsin(\sin{x})$ is not always $x$ So my question is simple - why? 
Since each cancels the other, it would make sense that $\arcsin(\sin{x})$ would always
result in $x$. I'd appreciate any explanation. Thanks!","['trigonometry', 'functions']"
80148,"How could we find the largest number in the sequence $ \sqrt{50},2\sqrt{49},3\sqrt{48},\cdots 49\sqrt{2},50$?","How to find the largest number in the sequence$$ \sqrt{50},2\sqrt{49},3\sqrt{48},\cdots 49\sqrt{2},50$$ I am interested in a ""calculus-free"" approach.
Thanks,","['elementary-number-theory', 'sequences-and-series', 'algebra-precalculus']"
80154,Showing whether two numbers are equal or not,"$\dfrac{\sin (2x+y)}{\sin (2x)} =\dfrac{\sin (x+2y)}{\sin (2y)}$,where $0<x,y\le\dfrac{\pi}{4}$ . Can I show that $x=y $ or find two numbers $x,y$ such that $x\not=y$?","['trigonometry', 'triangles']"
80155,Matrix properties,"What can one conclude about a matrix, $M$, if its single eigenvalue is 1? (I think the question is trying to demonstrate a contrast with the case where it is 0 instead of 1, in which we could conclude that the matrix is nilpotent.) Can I conclude that the matrix is the identity matrix? Since $(M-I)^n=0$ by the Cayley-Hamilton theorem? Is there anything else? Thanks.",['matrices']
80168,"If the composition of two maps is continuous and one of the maps is also continuous, then is the other continuous","Let $f:X\to Y$ and $g:Y\to Z$ be maps of topological spaces. Assume that the composition $g\circ f$ is continuous and that $f$ is continuous. Is $g$ necessarily continuous? If this is not true in general, is it true under some hypotheses on $X$, $Y$ or $Z$? Reversely, assume that $g\circ f$ is continuous and $g$ is continuous. Is $f$ continuous? This is not homework. It's just something I was wondering about.",['general-topology']
80181,Graphs with eigenvalues of large multiplicity,"For a strongly regular graph, there are exactly 3 eigenvalues, all nonzero (I believe).  One has multiplicity 1, which means the other two have pretty high multiplicities.  There are tables that give these eigenvalues and multiplicities: http://www.win.tue.nl/~aeb/graphs/srg/srgtab1-50.html For example, the Schlaefli graph is order 27 but has an eigenvalue of order 20. My question is, are there other known graphs (families, types, or just single graphs) that have large multiplicities of eigenvalues?  When I check a random graph in Sage, it seems the max multiplicity is mostly 1.","['graph-theory', 'linear-algebra', 'eigenvalues-eigenvectors', 'algebraic-graph-theory']"
80185,"Is there a technical name for $f$ such that $(g \circ f)(a_1, a_2,\cdots)$ yields $g(a_1, a_2, \cdots)$?","Is there a technical name for a function $f$ such that $(g \circ f)(a_1, a_2,\cdots) \rightarrow g(a_1, a_2, \cdots)$? That is, is there a name for a function $f$ such that the result of composing $g$ with $f$ is $g$ invoked with $f$'s arguments? EDIT: Accidentally reversed the order of operations and put $f \circ g$ when I meant $g \circ f$ (i.e. $g(f(\cdots)$).",['functions']
80198,Area of Triangle via Vectors,I don't understand the formula given by a book that $$\text{Area of }\triangle ABC = \frac{1}{2}|CA \times CB|$$ How is this derived? The explanation given by the book was: $$\text{Area of } \triangle ABC = \frac{1}{2}ab \sin{C} = \frac{1}{2}|CA||CB| \sin{C}$$ I think C refers to $\angle ACB$,['geometry']
