question_id,title,body,tags
889003,Is a Lebesgue measurable subset a null set if each compact subset is a nullset?,"If $A \subset \Bbb{R}$ is Lebesgue measurable.($m$ is Lebesgue measure) and for every compact $K \subset A$, $m(K)=0$; is it true that $m(A)=0$?","['measure-theory', 'lebesgue-measure', 'real-analysis']"
889009,generalized way of finding minimum value of a function?,"$f(x)=\frac{x^{2}-1}{x^{2}+1}$ for every real number for $x$, the minimum value of $f$ is what? How  can I find the minimum value of this function.I only know trial and error method, but it's not a generalized way. Please tell me a generic way to solve this type of problem","['algebra-precalculus', 'functions']"
889043,Is the sequence $u_n=n\sum_{i=1}^\infty2^{-i}(1-2^{-i})^n$ convergent when $n\to \infty$?,"Problem Is the sequence $u_n=n\sum_{i=1}^\infty2^{-i}(1-2^{-i})^n$ convergent when $n\to \infty$ ? Progress If $i\leq \log n$ then $(1-2^{-i})^n<e^{-\frac{n}{2^i}}$ . Unfortunately, I do not know what to do next","['sequences-and-series', 'real-analysis']"
889053,Problem about Eisenstein series on $\Gamma_1(N)$,"I'm learning about Eisenstein series on $\Gamma_1(N)$ and it seems to me that I have misunderstood something. I imagine the following situation : Let $\nu$ be a function on $(\mathbb{Z}/ N \mathbb{Z})$ to $\mathbb{C}$. One can define an ""Eisenstein form"" for $k\geq 3$, $$G_k(\nu,\tau)=\frac{(k-1)!}{2(2i\pi)^k}\sum_{m,n}{\frac{\nu(\bar{m})}{(m\tau +n)^k}}$$
Since 
\begin{align}
G_k\left(\nu,\frac{a\tau+b}{c\tau +d}\right) &= (c\tau+d)^k\frac{(k-1)!}{2(2i\pi)^k}\sum_{m,n}{\frac{\nu(\bar{m})}{((am+cn)\tau +(bm+dn))^k}} \\ &=(c\tau+d)^k\frac{(k-1)!}{2(2i\pi)^k}\sum_{u,v}{\frac{\nu(\overline{du-cv})}{(u\tau +v)^k}} \\ &=(c\tau+d)^k G_k(\nu,\tau)
\end{align}
when $ad-bc=1$, $c\equiv 0 \pmod{N}$, $d\equiv 1 \pmod N$, $G_k(\nu,\cdot)$ is a modular form of weight $k$ on $\Gamma_1(N)$. But we also have the Fourier serie :
$$G_k(\nu,\tau)=-\frac{B_k}{2k}+\sum_{n=1}^{+\infty}{\sigma_{k-1}(\nu,n)q^n} \quad \quad q=e^{2i\pi \tau}$$
where $$\sigma_{k-1}(\nu,n)=\sum_{d|n}{\nu(\bar{d})\left(\frac{n}{d}\right)^{k-1}}$$
So $G_k \in E_k(\Gamma_1(N))$ - the space of Eisenstein series - when $k$ is even. Then for $k\geq 4$ even and $N=4$, since $\dim(E_k(\Gamma_1(4)))=3$, one can find $(a,b,c,d) \in \mathbb{C}^4$ such that
$$aG_k(\alpha,\tau)+bG_k(\beta,\tau)+cG_k(\gamma,\tau)+dG_k(\delta,\tau)=0$$
but it's false in general (for instance, try $(\alpha,\beta,\gamma,\delta)=(\nu_0,\nu_1,\nu_2,\nu_3)$ where $\nu_i(\bar{m})$ is $1$ if $m\equiv i \pmod 4$ and $0$ otherwise). So where am I wrong ? Thanks a lot for your help !","['vector-spaces', 'number-theory', 'congruences', 'modular-forms', 'complex-analysis']"
889066,Elementary ways to calculate the arc length of the Cantor function (and singular function in general),"Cantor's function: http://en.wikipedia.org/wiki/Cantor_function There is an elementary way to prove that the arc length of the Cantor function is 2? In this article ( http://www.math.helsinki.fi/analysis/seminar/esitelmat/stat0312.pdf ) they use the following result: If $f:[a,b] \rightarrow \mathbb{R}$ is a continuous monotone function, then $f$ is singular if and only if
  $$L_a^b = |f(a)-f(b)|+|a-b|$$ But, there is a way for calculate the arc length of singular function without using this property? like using the arc length definition If $X$ is a metric space with metric $d$, then we can define the ''length'' of a curve $\!\,\gamma : [a, b] \rightarrow X$ by $$\text{length} (\gamma)=\sup \left\{ \sum_{i=1}^n d(\gamma(t_i),\gamma(t_{i-1})) : n \in \mathbb{N} \text{ and } a = t_0 < t_1 < \cdots < t_n = b \right\}. $$ where the sup is over all $n$ and all partitions $t_0 < t_1 < \cdots < t_n$ of $[a, b]$.","['real-analysis', 'arc-length']"
889076,Prove that $\int_0^1\frac{\ln(1-x)\ln^2x}{x-1}dx=\frac{\pi^4}{180}$,"Prove that ( please ) $$\int_0^1\frac{\ln(1-x)\ln^2x}{x-1}dx=\frac{\pi^4}{180}$$ I've tried using Taylor series and I ended up with
$$-\sum_{m=0}^\infty\sum_{n=1}^\infty\frac{2}{n(m+n+1)^3}$$
I am stuck there and I couldn't continue it using partial fraction to get any familiar sum of series. Could anyone here please help me to prove the integral preferably ( if possible ) with elementary ways (high school methods)? Any help would be greatly appreciated. Thank you.","['improper-integrals', 'integration', 'definite-integrals', 'harmonic-numbers', 'real-analysis']"
889098,Blowup of cone over Veronese surface,"Consider the affine cone $X \subset \mathbb A^6$ over the Veronese surface $V \cong \mathbb P^2 \subset \mathbb P^5$. After blowing up the cone point we get a resolution $Y \rightarrow X$, with exceptional divisor $E \cong \mathbb P^2$. How do you see that $\mathcal O_E(-E) = \mathcal O(2)$?",['algebraic-geometry']
889109,Measure and additivity,"I am learning Measure Theory on my own, so please forgive me if my question is naive. Finitely additive and $\sigma$-additive measures are defined in a natural way on finite algebras and $\sigma$-algebras, respectively. I know that every $\sigma$-additive function is additive, and that every $\sigma$-algebra is an algebra. Hence, we can safely define a $\sigma$-additive measure on a finite algebra. More, the finite measure and the $\sigma$-additive measure coincide. I can see two ways of doing it: 1) Add infinitely many empty sets to satisfy the requirement of denumerability.
For example, $$\mu(E\cup F)=\mu(E\cup F\cup\emptyset\cup\emptyset\cup\ ...)=\mu E+\mu F+\mu 0+\mu 0+\ ...=\mu E+\mu F$$ 2) Simply restrict the the $\sigma$-additive measure $\mu$ to the finite algebra $\mathcal{A}$. Say, $\nu=\mu{\left|\mathcal{A}\right.}$. My question is the following: Can we define a finitely additive measure on a $\sigma$-algebra? Maybe, partitioning our $\sigma$-algebra into finitely many equivalence classes could be a good start. But, still, at least one cell will be infinite... So the question is still pending, and I was wondering if somebody could help me to understand that point. Thanks.",['measure-theory']
889110,"Prove that $\int_0^1\frac{1-x}{1-x^6}\ln^4x\,dx=\frac{16\sqrt{3}}{729}\pi^5+\frac{605}{54}\zeta(5)$","This integral comes from a well-known site (I am sorry, the site is classified due to regarding the OP.) $$\int_0^1\frac{1-x}{1-x^6}\ln^4x\,dx$$ I can calculate the integral using the help of geometric series and I get the answer
\begin{align}
\sum_{n=0}^\infty\left(\frac{24}{(6n+1)^5}-\frac{24}{(6n+2)^5}\right)
&=\frac{1}{6^5}\left(\Psi^{(4)}\left(\frac{1}{3}\right)-\Psi^{(4)}\left(\frac{1}{6}\right)\right)\\
&=\frac{16\sqrt{3}}{729}\pi^5+\frac{605}{54}\zeta(5)
\end{align}
To be honest, I use Wolfram Alpha to calculate the sum of series. The problem is I don't think this is the correct way to calculate the integral because I use a machine to help me. I tried another way, I used partial fraction to decompose the integrand as
$$\frac{\ln^4x}{3(x+1)}+\frac{\ln^4x}{2(x^2+x+1)}-\frac{2x-1}{6(x^2-x+1)}\ln^4x$$
but none of them seemed easy to calculate. Could anyone here please help me to calculate the integral preferably ( if possible ) with elementary ways (high school methods)? Any help would be greatly appreciated. Thank you.","['improper-integrals', 'sequences-and-series', 'calculus', 'integration', 'real-analysis']"
889117,Find a closed form for this infinite sum: $ 1+\frac 1 2 +\frac{1 \times2}{2 \times 5}+\frac{1 \times2\times 3}{2 \times5\times 8}+ \dots$,"How to find a closed form for the expression?? $$ 1+\frac 1 2 +\frac{1 \times2}{2 \times 5}+\frac{1 \times2\times 3}{2 \times5\times 8}+\frac{1\times 2\times 3\times 4}{2 \times 5\times 8\times 11}+ \cdots$$ Wolfram alpha gives, $$\frac{3}{2}+\frac{\ln(\sqrt[3]{2}-1)}{4\sqrt[3] {2}}+\frac{\sqrt{3}}{2\sqrt[3]{2}}\arctan\frac{\sqrt{3}}{2\sqrt[3]{2}-1}$$",['sequences-and-series']
889127,Tough limit to evaluate,I am trying to solve this limit problem $$\lim_{x\to 1} {(1-x)(1-x^2)....(1-x^{2n})\over[(1-x)(1-x^2)....(1-x^n)]^2}$$ I am not able to figure how to to convert it to a compact form. Any tips?,['limits']
889130,Contrasting definitions of bimodules? An illusion?,"Recently my definition of a bimodule over a $k$-algebra has been challenged and I believe both definitions to be equivalent, am I wrong? Notation: $k$ is a commutative ring and $A$ is a (unital associative) $k$-algebra. Definition 1: An $(A,A)$-bimodule $M$ is an abelian group together with a left and right $A$-module structure such that: \begin{equation}
(\forall m \in M) (\forall a,b \in A) (a \cdot m) \cdot b = a \cdot (m \cdot b)
\end{equation} Definition 2: An $(A,A)$-bimodule $M$ is an $k$-module together with a left and right $A$-module structure such that: \begin{equation}
(\forall m \in M) (\forall a,b \in A) (a \cdot m) \cdot b = a \cdot (m \cdot b)
\end{equation} Reasoning $A$ is a $k$-algebra then the inclusion of $k$ into $A$ induces an action of $k$ on $M$; whence $M$ must also be a $k$-module if it satisfies definition $1$, conversely if $M$ satisfies definition $2$ then it satisfies definition 1 by definition of a $k$-module. Apparently my logic is flawed but I don't see why...","['modules', 'noncommutative-algebra', 'ring-theory', 'abstract-algebra']"
889172,"Showing that if the intersection of all subgroups other than $\langle e \rangle$ is not $\langle e \rangle$, then every element is of finite order",This is problem 2 on page 46 of I. N. Herstein's Topics in Algebra . Let $G$ be a group such that the intersection of all its subgroups which are different from $\langle e\rangle$ is a subgroup different from $\langle e\rangle$ . Prove that every element in $G$ has finite order.,['group-theory']
889174,Characterizing a circle.,"Is it correct to characterize a circle by saying that it is a closed curve in $\mathbb{R}^2$ such that all points on the curve are equidistant from a single fixed point? I am familiar with shapes such as reuleaux polygons, so this isn't what I am getting at (that is shapes of constant width). My gut feeling tells me that one can construct a (convoluted) curve in $\mathbb{R}^2$ with this property that wouldn't be geometrically (or even topologically) a circle. I particularly would like to stick with closed curves in $\mathbb{R}^2$ and comparing them with $S^1$. I am sure this question might have different answers for higher dimensions, but I am not concerned with these. I mean formally we would write down that the circle is $S^1 = \{ (x,y) \in \mathbb{R}^2 \, | \, x^2 + y^2 = r \}$, but does this bi-conditionally translate to my first statement? Edit to this original question: The way I phrased the question was poor in hindsight partly because I hadn't quite pinned down what exactly what I wanted to ask. The more precise statement I am trying to make is the following, For the metric space $(\mathbb{R}^2 , d)$ where $d$ is the standard Euclidean metric, we define the circle centered at the point $(a,b) \in \mathbb{R}^2$ to be the set $S^1 = \{ (x,y) \in \mathbb{R}^2 \, | \, (x-a)^2 + (y-b)^2 = r^2 \}$, where we say that $r$ is the radius of the circle. Is this definition equivalent to saying a circle is a closed curve in $\mathbb{R}^2$ such that all points on the curve are equidistant from a single fixed point? I do not care for the single point to be the origin and the distant to be $r$ Again, my gut feeling says that one might be able to construct a (convoluted) curve that has this property which is not the same realization as $S^1$.","['geometry', 'definition']"
889175,Conditional return time of simple random walk,"Consider a simple symmetric random walk on $\mathbb{Z}$, $(S_t)_{t \geq 0}$. Call $\tau_k = \min\{t \in \mathbb{N}\, : \, \, S_t =k \}$, the hitting time of $k \in \mathbb{N}$. Call $\tau^* = \min\{t >0\, : \, \, S_t =0 \}$, the return time to the origin. Let $c<1$ be a positive constant. Is there a way to compute the next formula explicitly? $$\sum_{k=1}^{\infty} \sum\limits_{j=1}^{\infty} P ( \tau_k = j \, | \, \tau_k < \tau^*) \cdot c^{j-1}$$","['random-walk', 'markov-chains', 'random-variables', 'probability-distributions', 'probability']"
889203,$AB=z \mathrm{Id}_n$ implies $z^m BA = z^{m+1} \mathrm{Id}_n$ for what $m$?,"This question builds on a series of questions looking for elementary proofs that $AB=\mathrm{Id}$ implies $BA=\mathrm{Id}$, for $A$ and $B$ both $n \times n$ matrices over a commutative ring. First the question, then motivation, then a small bit of progress. Let $R$ be a commutative ring. Let $A$ and $B$ be $n \times n$ matrices with entries in $R$ satisfying $AB=z \mathrm{Id}_n$ for some $z \in R$. We cannot conclude that $BA = z \mathrm{Id}_n$: Take $R=\mathbb{Z}$, $z=0$, $A = \left( \begin{smallmatrix} 0 & 1 \\ 0 & 0 \end{smallmatrix} \right)$ and $B = \left( \begin{smallmatrix} 1 & 0 \\ 0 & 0 \end{smallmatrix} \right)$. However, we can conclude $z^n BA = z^{n+1} \mathrm{Id}$ (proof below). What is the smallest $m$ (as a function of $n$) for which we can conclude $z^m BA = z^{m+1} \mathrm{Id}$? Motivation Suppose that we can do this for some particular $m$ and $n$. Let $k[a,b,z]$ be the polynomial ring in $2n^2+1$ variables, $a_{ij}$, $b_{ij}$ and $z$ (over some field $k$). Let $S$ be the quotient of $k[a,b,z]$ by the $n^2$ relations gotten by expanding the matrix product $AB=z \mathrm{Id}_n$. Since this question is framed for an arbitrary commutative ring, it applies in particular to $S$. So, if the answer is ""yes"" for some $(m,n)$, then the entries of $z^m BA - z^{m+1} \mathrm{Id}_n$ are zero in $S$. In other words, they lie in the ideal of $k[a,b,z]$ generated by the entries of $AB-z \mathrm{Id}_n$. I.e. we must have polynomial relations
$$z^m \left( \sum_r B_{ir} A_{rj} - z \delta_{ij} \right) = \sum_{k, \ell} P_{ij}^{k \ell}(a, b, z) \left( \sum_s A_{ks} A_{s\ell} - z \delta_{k \ell} \right) \quad (\ast)$$
for some polynomials $P_{ij}^{k \ell}(a, b, z)$. Put a grading on $k[a,b,z]$, where $\deg a_{ij} = \deg b_{ij}=1$ and $\deg z=2$. Then we may assume that the $P_{ij}^{k \ell}$ have degree $m$. Plugging in $z=1$ to $(\ast)$, we get a high school algebra proof that $AB=\mathrm{Id}_n$ implies $BA = \mathrm{Id}_n$ involving polynomials of degree $\leq m$. Conversely, if we have a proof that $AB=\mathrm{Id}_n$ implies $BA = \mathrm{Id}_n$  by pure high school algebra (adding, multiplying and dividing polynomials and substituting in the equations $AB = \mathrm{Id}_n$) then we can take every formula in that proof in replace each $1$ by an appropriate power of $z$ to make the equations homogenous. The result will be a proof of $(\ast)$ for some $m$ and, again, the size of $m$ is a measure of the complexity of the proof. Minor progress It is good enough to take $m=n$. Proof: simplify $(\det B) \mathrm{Ad}(A) A B A$ in two ways. One way gives
$$(\det B) {\Big (} \mathrm{Ad}(A) A {\Big )} B A = (\det B) (\det A) BA = (\det A) ( \det B) BA = \det(AB) BA = z^n BA$$
the other gives
$$(\det B) \mathrm{Ad}(A) {\Big (}  A  B {\Big )} A =(\det B) \mathrm{Ad}(A) z A = z (\det B) (\det A) = z \det(AB) = z^{n+1}.$$ When $n=1$, we can take $m=0$, as $R$ is commutative. For $n=2$, the above example of $z=0$, $A = \left( \begin{smallmatrix} 0 & 1 \\ 0 & 0 \end{smallmatrix} \right)$ and $B = \left( \begin{smallmatrix} 1 & 0 \\ 0 & 0 \end{smallmatrix} \right)$ shows we need $m \geq 1$ and it is easy to adapt this to show that we need $m \geq 1$ for any $n \geq 1$. This is all I know! I don't even have an example to show that $m \geq 2$ is necessary for any $n$, although my gut says $m$ should grow linearly with $n$.","['matrices', 'algebraic-geometry', 'commutative-algebra']"
889232,Introductory Induction proof that $n(n^2 +5)$ is divisible by $6$,"I am in currently in a discrete mathematics class, and I've done well on every problem I've encountered. Unfortunately, I find myself weak at some of the seemingly straight forward induction problems. As is the case of the following corollary. I will attempt to show as far as I've gotten in the problem and where I have hit a road block. Theorem: $n(n^2 +5)$ is divisible by 6 for every integer $n\ge0$ Proof: Let the property $P(n)$ be the sentence ""$n(n^2 +5)$ is divisible by 6."" For our base case we will show that $P(0)$. That is, $0(0^2 +5)$ is divisible by 6. But, $0(0^2 +5)=0$ so $P(0)$ says that $0$ is divisible by 6 which is clearly true because $0$ is divisible by all integers as was previously shown in our text. Now, for our inductive step we must show that $P(k) \Rightarrow P(k+1)$. Now, by definition of divisibility, $P(k)$ says that $k(k^2 +5) =6r$ for some $r\in \mathbb Z$ (EDIT AFTER HINT). Also, $P(k+1)$ says that $(k+1)[(k+1)^2 +5]=6p$ for some $p\in \mathbb Z$. After expansion and substitution $(k+1)[(k+1)^2 +5 = k^3 + 3k^2 +8k +6 = (k^3 +5k)+3k^2 +3k +6 = 6r +3k^2 +3k + 6= 3(2r +k^2 + k +2)=3(2r+k(k+1)+2)$ However, note that $k(k+1)$ represents the pruduct of two consecutive integers and is thus even. That is, $k(k+1)=2q$ for some $q\in \mathbb Z$. Now, $2r+k(k+1)+2 = 2r+2q+2$, but this is simply the sum of three even numbers and is thus an even number itself. That is, $2r+2q+2 = 2p$ for some $p\in\mathbb Z$. Therefore, $(k+1)[(k+1)^2 +5] =6q$. EDIT:PROBLEM SOLVED - This is where I get stuck I've tried to expand $(k+1)[(k+1)^2 +5]$ which gives me $k^3 + 3k^2 +8k +6$. I've tried to manipulate it so that $k^3 + 3k^2 +8k +6=(k^3 +5k)+3k^2 +3k +6 = 6r +3k^2 +3k + 6= 3(2r +k^2 + k +2)$. However, this only shows divisibility by 3. Any help would be much appreciated. Thank you!","['induction', 'elementary-number-theory', 'discrete-mathematics']"
889241,A consequence of Wilson's Theorem,"By Wilson's Theorem we know that $$(p-1)! \equiv -1 \mod p.$$ A consequence of this is apparently  $$(p-(k+1))!k! \equiv (-1)^{k+1} \mod p$$ where $0 \leq k \leq p-1$. I was told to think of it like so, Let $0 \leq i \leq p-1$.  Then $(p-i)\equiv -i \mod p.$ I'm interested in proceeding in the above way, but I'm not sure how to.","['elementary-number-theory', 'congruences', 'combinatorics']"
889260,quotient by a group that acts almost freely,"How can I show that if a compact lie group G acts almost freely  and smoothly on a manifold M, then M/G is Hausdorff? (an action is almost free if $G_x$ is finite for all x $\in$ M)","['group-actions', 'manifolds', 'lie-groups', 'differential-geometry']"
889299,Conjecture for product of binomial coefficient,"Is it true that for any $n, k\in\mathbb N$
$$\frac{(kn)!}{k!(n!)^k} = \prod_{l=1}^k {{ln-1}\choose{n-1}} \quad?$$ I tested it for some small $k$ and $n$, but I don't know how to prove that it is true (or find example showing that it is not).","['arithmetic', 'binomial-coefficients', 'combinatorics']"
889310,Central Limit Theorem exercise question,"Let $ (X_n)_{n \in \mathbb{N}}$ be i.d.d. random  variables  with  $E{X_1}=0$,  $Var(X_1)=1$ and $ S_n = X_1 + X_2 +...+  X_n $. Calculate $ \lim_{n \to +\infty}\Pr(S_n>\sqrt{n})$. On the back page, it has as a solution that the limit equals to $\frac{1}{2}$ but I can't understand why. What I did is to use the central limit theorem so i can show that
$\frac{S_n -nE(X_1)}{\sqrt{nVar(x_1)}} = \frac{S_n}{\sqrt{n}}$ converges to $ Z \sim \mathcal{N}(0,1)$. Then,
 $ \Pr(\frac{S_n}{\sqrt{n}}>1) $ converges to $\Pr(Z>1) = Φ(-1)$, where Φ the cumulative distribution function. Is there any fault on my solution that i cannot see?","['probability-theory', 'central-limit-theorem']"
889341,Geometry Question - length ratio in a triangle,"In the figure, CD=2AB=2BC and FE = ED Find AG: HE This is an Olympic question in China, I tried, still can't figure it out. Please.",['geometry']
889381,Proof of rank-nullity via the first isomorphism theorem,"I was thinking about the proof of the rank-nullity theorem and I thought about proving it as follows. I just wondered whether this proof worked? Lemma. If $V$ is a finite-dimensional $F$-vector space and $U\leq V$, then $V/U$ is finite dimensional. $\hspace{16.5mm}$ Moreover, we have that $\dim{V/U}=\dim{V}-\dim{U}$. Theorem (Rank-Nullity). If $\alpha:V\to W$ is linear with $V$ finite-dimensional, then
$$\dim{V}=\dim(\text{im }\alpha)+\dim(\ker \alpha)$$ Proof. By the first isomorphism theorem we have
$$V/\ker{\alpha} \cong \text{im }{\alpha}.$$
Taking dimensions and applying the lemma we get
$$\dim V - \dim(\ker\alpha)=\dim(\text{im }\alpha)$$
which on rearrangement yields the result. //",['linear-algebra']
889386,Entire function bounded below by a polynomial,"Let $f$ be an entire function such for some $N \in \mathbb{N}$ and $R >0$ , the following property holds: $|f(z)| \geq |z|^N$ $\forall z \in \mathbb{C}$ with $|z| \geq R$ . Show that $f$ is a polynomial of degree greater than or equal to $N$ . Progress thus far: Clearly, $f$ is not identically zero. Case 1) If $f$ is also nowhere 0, it's not hard to show $f$ is bounded and therefore, by Louisville's Theorem, a constant. Case 2) If $f$ is neither identically zero nor nowhere 0, then we can show that it has a finite number of zeros in the ball $B(0,R)$ .  From these zeros we can get a polynomial $p$ , whose zeros are exactly those of $f$ , and an entire function $g$ such that $f = pg$ .  Consequently, $g$ is nowhere zero. At this point, I'd like to show $g \equiv c$ , where $c$ is some complex constant. A more general problem has been solved here , but I'm trying to avoid using big hammers like Casorati-Weierstrass.  (When this problem was assigned, we hadn't covered it yet.)",['complex-analysis']
889408,"How do I solve $\int_{\frac{\pi}{6}}^{\frac{\pi}{4}}\frac{4\,dx}{\sin^2(x)\cos^2(x)}$?","Alright so I have $$\int_{\pi/6}^{\pi/4}\frac{4\,dx}{\sin^2(x)\cos^2(x)}.$$ And I am not completely sure on how to tackle this problem. All I have done thus far is $$4\int_{\pi/6}^{\pi/4}\frac{1}{\sin^2(x)}\frac{1}{\cos^2(x)}dx$$ and I don't know how to approach this problem. Help would be greatly appreciated, thanks in advance!","['definite-integrals', 'trigonometry', 'calculus', 'integration']"
889411,A question on the automorphism of simple graph with distinct eigenvalues of adjacency matrix,"Let G be a graph. If G is simple(i.e no loops), and the eigenvalues of adjacency matrix A are distinct, then the automorphism of G is abelian. It seems that the automorphism from G to G itself is only permutation upon the vertex with incidence function composing with this permutation. But I do not know how to show this permutation(cyclic group) is the whole automorphism. Any hints will be helpful.","['graph-theory', 'permutations', 'group-theory']"
889415,Probability that shuffled deck contains no two consecutive cards of the same suit,"If a deck of 52 standard cards is completely randomly shuffled, what are the odds that not once do two cards of the same suit end up right next to each other? Rephrasing:
If I have a bag of 13 red balls, 13 blue balls, 13 yellow balls, and 13 white balls, and I keep pulling out balls without replacement, then what are the odds that I never pull a ball of the same color twice consecutively? I've tried doing this for small sets, and looking for a rule (2 of each suit, and 3 of each suit) I've tried to find a statistical significance to get a good estimate, or a certain pdf, or cdf to use, but I could find none. Is there any way of finding this without massive computations?","['probability-distributions', 'probability']"
889425,What does Determinant of Covariance Matrix give?,"I am representing my 3d data using its sample covariance matrix. I want to know what the determinant of covariance Matrix represents. If the determinant is positive, zero, negative, high positive, high negative, what does it mean or represent? Thanks EDIT: Covariance is being used to represent variance for 3d coordinates that I have. If my covariance matrix A determinant is +100, and the other covariance matrix B determinant is +5. Which of these values show if the variance is more or not. Which value tells that data points are more dispersed. Which value shows that readings are further away from mean.","['matrices', 'covariance']"
889427,Interior product between differential forms and vector fields,"I don't understand what is meant when someone writes that forms (or form fields) ""eat"" vectors (or vector fields). For example when I have a one form field ω=3dx+5dy+3xdz and a vector field X=3x∂x+5y∂y+3∂z, then their interior product $\iota_{X}\omega=\omega(X)= (3dx+5dy+3xdz)(3x\partial_{x}+5y\partial_{y}+3\partial_{z})=6x(\partial_{x}dx)+25y(\partial_{y}dy)+6x(\partial_{z}dz)=9x+25y+6x=15x+25y$ I think this is right. So in this case ω(X) doesn’t mean that ω is function of X, it just means multiplication. Now how does this work with two forms? For example X=y∂x+2z∂y+3xy∂z and the two form ω=3dx∧dy−(14zx+2)dx∧dz $\iota_{X}\omega=\omega(X,V)=(3dx\wedge dy-(14zx+2)dx\wedge dz)(y\partial_{x}+2z\partial_{y}+3xy\partial_{z}, V)$ Now how do I proceed from here?","['differential-forms', 'linear-algebra', 'differential-geometry']"
889442,What is asymmetry index in an array of numbers?,"Someone gave me this question , and I cannot find any source that can be helpful. Find the asymmetry index given an array of numbers and an integer ->
  find asymmetry index of the array Note: I posted this question at stackoverflow, and I have been told it is related to statistic. Can any one have some thoughts or how to answer this question?",['statistics']
889447,Rellich's theorem for Sobolev space on the torus,"From John Roe: Elliptic operators, topology and asymptotic methods , page 73: Let $H^{k}$ be the Soblev space defined on the torus $\mathbb{T}^{n}$ with the discrete $k$-norm:
$$
\langle f_{1}, f_{2}\rangle_{k}=(2\pi)^{k}\sum_{v\in \mathbb{Z}^{n}}\tilde{f}_{1}(v)\overline{\tilde{f}_{2}}(v)(1+|v|^{2})^{k}
$$ John Roe claimed that there is a Rellich type compact embedding theorem available. If $k_{1}<k_{2}$, then the inclusion operator $H^{k_{2}}\rightarrow H^{k_{1}}$ is a compact linear operator. The proof goes with the following steps: Let $B=\{x:|x|=1,x\in H^{k_{2}}\}$. Let $\epsilon>0$, choose subspace $Z\subset H^{k_{2}}$ such that $\dim (H^{k_{2}}/Z)<\infty$, and for all $f\in B\cap Z$, $|f|_{k_{1}}<\epsilon$. The unit ball of $H^{k_{2}}/Z$ is compact, so can be covered by finitely many balls of radius $\epsilon$. Hence $B$ can be covered by finitely many balls of radius $2\epsilon$ in $H^{k_{1}}$ norm. Since $\epsilon$ is arbitrary, $B$ is totally bounded and compact in $H^{k_{1}}$. Therefore the inclusion map is compact. Here $Z$ can be explicitly constructed by taking it to be the space
$$
\{f:\tilde{f}(v)=0,\forall v>N \}
$$
where $N$ is some large enough constant. I am fine with the strategy, but I am a little disturbed by $Z$'s construction at here. It is not clear to me that give $N$ large enough, I would be able to force all $f\in B\cap Z$ to have small enough norm. Can someone give me a hint? Thinking this in terms of Fourier series in the circle, it seems the terms $\tilde{f}(v)$ for $v>N$ can be arbitrarily close to $1$ and $|f|$ would also be quite large. For example if $k_{2}=3, k_{1}=2$, then there seem to be no reason $\tilde{f}$'s $H^{2}$ norm should be really small if the first $N-1$ terms are zero. I do not really know otherwise how to construct $Z$.","['sobolev-spaces', 'compact-operators', 'functional-analysis']"
889480,"Multivariable limit $\lim_ {{(x,y)} \to {(0,0)}} \frac{xy^2\ln\frac{|x|}{|y|}}{{(x^2+y^2)}^{\frac 12}}$","I have to prove that the limit $$\lim_ {{(x,y)} \to {(0,0)}} \frac{xy^2\ln\frac{|x|}{|y|}}{{(x^2+y^2)}^{\frac 12}}$$ does not exist. I've tried to find two different paths that show that the limit is divergent, but I couldn't find any. I've also tried to bound it, and it didn't work. Can somebody explain me how to do this? Thank you! PS: This is part of a much larger excercise, I didn't include it because it was irrelevant. I just need to prove that it does not converges to zero.","['multivariable-calculus', 'limits']"
889485,Finding the instantaneous rate of change of the function $f(x)=-x^2+4x$ at $x=5$,"Finding the instantaneous rate of change of the function $f(x)=-x^2+4x$ at $x=5$, I know the formula for instantaneous rate of change is $\frac{f(a+h)-f(a)}{h}$ I think it's the negative in front of the x that is throwing me the most. $$\frac{f(h+5)-f(5)}{h}$$ $$\frac{-(h+5)^2+4(h+5)-(-5)}{h}$$ $$\frac{-(h^2+10h+25)+(4h+20)+5)}{h}$$ $$\frac{(-h^2-10h-25)+4h+20+5}{h}$$ $$\frac{-h^2-6h}{h}$$ $$\frac{h(-h-6)}{h}$$ $$-h-6$$ $0-6=-6$; The instantaneous rate of change is $-6$ Have I done this correctly? I've just started with this stuff and want to make sure I'm not making errors before continuing.","['calculus', 'algebra-precalculus']"
889497,sheafification definition?,"I came across two different definitions of sheafification and I'm not sure how they are equivalent. One of them is here: About the sheafification Another one is from Tennison's sheaf theory: Given a presheaf $F$ over $X,$ we construct the sheaf space $LF:=\sqcup_{x\in X}\mathscr{F_{x}}$ which is a disjoint union of stalks and the continuous map is the natural projection $p:LF\rightarrow X $. The open sets are $s[U]=${ $s_{x}\in LF: x\in U$}. Then the sheafification is $\Gamma LF,$ where we construct the sheaf of sections on the sheaf space $LF.$  $\Gamma LF(U)=${$\text{continuous maps} \ \ \sigma :U\rightarrow LF \ \ \text{s.t.} \ \ p(\sigma)=id_{U} $}. So for example, the map $\hat{s}:U\rightarrow LF(U)$ where $x \mapsto s_{x}\in \mathscr{F_{x}}$ would be in  $\Gamma LF(U)$. Can someone explain how they are equivalent?","['sheaf-theory', 'algebraic-geometry', 'abstract-algebra', 'definition']"
889502,Is there a mathematical concept of fractions using transfinite numbers as numerators and denominators?,"http://de.wikipedia.org/wiki/Cantors_erstes_Diagonalargument (German) http://en.wikipedia.org/wiki/Cantor%27s_diagonal_argument (English) While looking at Cantors method of proof, which he used to show that the set of the rational numbers is countable and that it has got the same cardinality (Aleph-naught) as the set of the natural numbers, I recognized that if there were fractions that used transfinite numbers as their numerators and denominators, then those infinitely precisely defined fractions could be used within Cantors zizag-counting-grid to address not only all the rational numbers but all the real numbers (of course only in theory because transfinite numbers usually cannot be written down or spoken out very easily). So my question is as stated above:
Is there a mathematical concept of fractions using transfinite numbers as numerators and denominators? If yes, what is the name for these kind of fractions? Or is there a reason why one shouldn't use something like this. A simple example of such a fraction would be a fraction where the numerator is an infinte sequence of 1s and the denominator is an infinte sequence of 2s. A more complex example would be a fraction where the numerator would consist of the decimal places of Pi and the denominator would consist of the decimal places of 2^0.5.","['fractions', 'infinity', 'elementary-set-theory']"
889536,Convergence in measure and $L_p$ implies product converges in $L_p$,"This was given on an old comp as a true or false problem: If $1<p<\infty$, $|f_n|\leq 1$, $f_n\rightarrow f$ in measure, and $g_n\rightarrow g$ in $L_p$, then $f_ng_n\rightarrow fg$ in $L_p$. I could not think of a counter example right away so here is my attempt: Since convergence in $L_p$ implies convergence in measure $g_n\rightarrow g$ in measure. Let $E_1=\{x \in X:|f_n(x)-f(x)|>\epsilon_1\}$, $E_2=\{x \in X:|g_n(x)-g(x)|>\epsilon_2\}$ and $E=E_1\cup E_2$. Then $\mu(E)=0$ (warning this is incorrect usage of convergence in measure! I'll try to post a correct version in the answers) and
$$\int_X|f_ng_n-fg|^pd\mu=\int_{X\backslash E}|f_ng_n-fg+f_ng_n-f_ng_n|^pd\mu\leq\\\int_{X\backslash E}|f_n|^p|g_n-g|^pd\mu+\int_{X\backslash E}|g|^p|f_n-f|^pd\mu$$ The integral in the first part of the sum goes to zero but I'm not sure what to do with the second integral? Is the fact that $g$ is in $L_p$ and $|f_n-f|^p<\epsilon_2^p$ enough?
Since
$$\int_{X\backslash E}|g|^p|f_n-f|^pd\mu\leq\epsilon_2^p\int_{X\backslash E}|g|^pd\mu=M\epsilon_2^p\rightarrow0$$
when $\epsilon_2\rightarrow0$ and $M=\int_{X\backslash E}|g|^pd\mu$.",['measure-theory']
889538,probability of collision with randomly generated ID,"Reworded: If 10,000 events occur each second, and each event needs a unique ID, how many random bits does each ID require to insure collisions are minimized? $10,000$ events could occur near the same time, so the time stamp is not sufficient for a unique ID.  I want to add a number of random bits (but not too many) to make collisions unlikely.  This sounds like the birthday paradox problem. If I add $12$-bits of randomness, that too low because $10,000$ events into $4096$ boxes must have some duplicates. If I add $18$-bits of randomness, $$p()=1-\left(\frac{262143}{262144}\right)^{(10000(10000-1))/2)} = 100 \%$$ If I add $24$-bits of randomness, $$p()=1-\left(\frac{16777215}{16777216}\right)^{10000(10000-1))/2} = 94.9 \%$$ Did I do this right? My math sense expects this to be more than enough, since each event has $1677$ possible places to go without collision. At $32$ bits, there is a $1.1\%$ chance, and at $36$ bits the probability of a collision is $727$ parts per million. I am starting to understand why the standard UUID generators use $128$ bits. What do you think?",['probability']
889539,Rectangular to polar form using exact values.,"I'm in a first year math course at university, and we've been asked to convert a rectangular form complex number into polar form, using exact values only. I have the modulus, that's all good. But I now have $\tan\theta=2-\sqrt{3}$ for the argument. I plugged this into my calculator and it spat out $15^{\circ}$ which I know can be represented as $\frac{\pi}{3}-\frac{\pi}{4}$ but I can't for the life of me figure out how we are supposed to be able to get from $\tan\theta=2-\sqrt{3}$ to $\theta=\frac{\pi}{3}-\frac{\pi}{4}$ without using a calculator! Am I missing some elementary step? Many thanks.","['trigonometry', 'complex-numbers']"
889546,First order differential equation involving inverse function,"I am wondering if there is a way to solve a differential equation of the following form: $$\displaystyle \frac{f'(x)}{x} = \frac{1}{f^{-1}(x)} + \frac{1}{k}$$ We can assume that $f(x): [0,T] \to (-\infty,T]$ is a monotone non-decreasing function with $f(T) = T$. Moreover, $f(x) \le x$ for all $x \in [0,T]$, and $0<k<\infty$. To clarify the context, the differential equation comes from the following problem: Find the value of $f(x)$ such that $$\int_{f(x)}^x k dt + \int_x^T k\left(1-\frac{t}{f^{-1}(t)}\right) = \int_x^Tt\ dt$$ As we can clearly see, when $x$ is very close to $T$. the value of $f(x)$ must be close to the value of $x$ since we know that $f^{-1}(x) \ge x$ and the second integral on the LHS is close to zero. Since the right integral is also close to zero, we must have $x$ close to $f(x)$. In fact, we can show $f(T)=T$. The problem was originally stated in a more general form with $g(x)$ an increasing function on $[0,T]$.
$$\int_{f(x)}^x k dt + \int_x^T k\left(1-\frac{g(t)}{g(f^{-1}(t))}\right) = \int_x^Tg(t)\ dt$$","['ordinary-differential-equations', 'functional-equations']"
889549,Understanding trigonometric identities,"Can someone help me understand trigonometric identities? For example, it is known that $\cos(90-\theta)$ is equal to $\sin \theta$, and vice versa. But why? Is it something to do with the unit circle? Is it visual?","['trigonometry', 'algebra-precalculus']"
889561,Entire function such that $|f(z)| = 1$ on the real line,"Let $f: \mathbb{C} \rightarrow \mathbb{C}$ be an entire function such that $|f(z)| = 1$ for all $z \in \mathbb{R}$. The problem is to show that $f$ does not vanish on $\mathbb{C}$. Here's my attempt: Note that $1/\overline{f(\overline{z})}$ is holomorphic in the open set $U = \{z \in \mathbb{C}: f(\overline{z}) \neq 0\}$. Furthermore, for $z \in\mathbb{R}$, $1/\overline{f(\overline{z})} = 1/\overline{f(z)} = f(z)$. Since $f$ is holomorphic on $U$, $1/\overline{f(\overline{z})} = f(z)$ for all $z \in U$. Thus $1/\overline{f(\overline{z})}$ extends to an entire function. For $z \not\in U$, then $f(\overline{z}) = 0$. Since zeros are isolated, there exists a sequence $z_{n} \in U$ such that $z_{n} \rightarrow z$. Then $f(\overline{z_{n}}) \rightarrow f(\overline{z}) = 0$. Does this imply that $1/\overline{f(\overline{z_{n}})} \rightarrow \infty$ as $n \rightarrow \infty$? More specifically, is the function $F(z)$ defined by 
$$F(z) = \begin{cases}1/\overline{f(\overline{z})} & \text{ if } z \in U\\f(z) & \text{ if }z \not\in U\end{cases}$$ entire?",['complex-analysis']
889570,Proof of trigonometric identity $\cot \theta \sec\theta= 1/ \sin\theta$,Is this trigonometric identity provable? $$\color{red}{}\;\color{navy}{\cot \theta \sec \theta = \dfrac 1 {\sin \theta}}$$ I can't seem to get passed: $\dfrac{1}{\tan\theta \cos\theta}$,['trigonometry']
889575,Division algorithm for the natural numbers.,"I am trying to prove the following statement from Terence Tao's Analysis 1 book. Definition of multiplication $ab{+\!+} = ab+b$ . Definition of addition $(a{+\!+})+b=(a+b){+\!+}$ . Let $n$ be a natural number, and let $q$ be a positive number. Then there exists natural numbers $m$ , $r$ such that $0 \le r \lt q$ and $n=mq+r$ . Now I attempted to prove the statement by inducting on $n$ . So for the base case $n=0$ $$0=mq+r$$ Since $q$ is positive $m$ and $r$ must be $$m=0$$ $$r=0$$ and we have $$0\le r \lt q$$ as desired. Now assume true for $P(n)$ i.e. $$n=mq+r$$ and $$0\le r \lt q.$$ Now for $n{+\!+}$ (the successor to n) case. Need to show $$n{+\!+}=mq+r.$$ Then using the induction hypothesis we have on the left hand side $$n{+\!+}=(mq+r){+\!+}=(mq{+\!+})+r=mq+q+r.$$ Then we use cancellation to arrive at $$mq+q+r=mq+r$$ $$q=0.$$ Which is not possible cause we assumed q is positive.  So clearly I have done something wrong because the division algorithm is true.","['elementary-number-theory', 'number-theory', 'analysis']"
889585,Converting a polar integral to spherical,"$$\int_0^{2\pi} \int_0^{\sqrt{2}}\int_r^{\sqrt{4-r^2}}\mathrm{d}z \, r \, \mathrm{d}r \, \mathrm{d}\theta$$ So in spherical this would become: $$\int_0^{2\pi} \int_0^{\pi/4}\int_0^2 \rho^2\sin\phi \, \mathrm{d} \rho \, \mathrm{d}\phi \, \mathrm{d}\theta,$$ correct?","['multivariable-calculus', 'spherical-coordinates']"
889587,Trigonometric identity expressing $\sec \theta+\text{cosec } \theta$ in terms of sine and cosine,"$\large{\text{cosec }\theta+\sec{\theta}=\dfrac{\sin\theta+\cos\theta}{\sin\theta\,\cos\theta}}$ I know that cosecant is the inverse of sine, and secant is the inverse of cosine. However, that does not equal the right hand side of the equation. I know nothing about what to do next.",['trigonometry']
889606,About the Chern class of infinite complex Grassmannian,"I learned that any characteristic class of rank-$k$ complex vector bundles on paracompact spaces is determined bijectively by a cohomology class in $H^*(Gr_k^\infty(\mathbb C))$, the cohomology ring of k-th infinite Grassmannian. So the $n$-th Chern classes should be able to defined just by an element of $H^{2n}(Gr_k^\infty(\mathbb C))$, which is a linear combination of certain Schubert cycles (or Young diagrams, equivalently). Is there a direct combinatorial way to define what the Chern classes are?","['schubert-calculus', 'algebraic-geometry', 'algebraic-topology', 'complex-geometry']"
889631,How to solve equations involving modulus function of the type $|x+1| - |1-x|=2 $ and $ |x-1|=|x|+a$?,I am able to solve equation of the type $ |5x+1|=|11-2x|$. I square both the side and my equation becomes $ (5x+1)^2=(11-2x)^2 $ further simplification gives me $ (5x+1)=\pm (11-2x)$. I get  have difficulties in solving equation of the type $|x+1| - |1-x|=2~~$   and $~~|x-1|=|x|+a$ Any steps and or links that could be of help will be greatly appreciated.,"['absolute-value', 'algebra-precalculus']"
889633,Measure of set of rational numbers,"I find it difficult to understand why the 'size' of the set of rational numbers in an interval such as [0,1] is zero. I know that there are way more irrational numbers than rational numbers such that m(set of irrational numbers) = 1 and as such m(set of rational numbers)=0. But I still find it difficult to reconcile with the fact that there are infinitely many rational numbers in the interval [0,1]. Can someone provide an explanation for this?","['measure-theory', 'real-analysis', 'real-numbers']"
889636,"Is $<\mathbb Q^+, \times>$ the free abelian group on countably infinitely many generators?","It seems to make sense to me that it should be, with the generators being the set of primes. However, I'm not sure that my intuition is right. Additionally, would this not be contradicted by the fact that $2\times3\times5\times7\times11\times13...$ is not a positive rational?","['group-theory', 'abelian-groups']"
889687,"How many $3$ digit numbers with digits $a$,$b$ and $c$ have $a=b+c$","My question is simple to state but (seemingly) hard to answer. How many $3$ digit numbers exist such that $1$ digit is the sum of the other $2$. I have no idea how to calculate this number, but I hope there is a simple way to calculate it. Thank you in advance. EDIT: The first digit should not be $0$","['combinations', 'discrete-mathematics', 'combinatorics']"
889712,The fastest way to count prime number that smaller or equal N,I want to count all prime numbers that existing in N but I don't know how to count. Can any one tell me how to count prime numbers that are smaller than or equal to N in mathematics formal?,"['number-theory', 'elementary-number-theory', 'algorithms', 'computational-complexity', 'prime-numbers']"
889719,Why does $S^n$ satisfy the local $n$-slice condition? (From Lee's Smooth Manifolds),"Example $5.9$ on page $103$ of John Lee's Smooth Manifolds says the following: The intersection of $S^n$ with the open subset $\{x:x^i>0\}$ is the graph of the smooth function
$$
x^i=f(x^1,\dots,x^{i-1},x^{i+1},\dots,x^{n+1})
$$
where $f\colon B^n\to\mathbb{R}$ is $f(u)=\sqrt{1-|u|^2}$. The intersection of $S^n$ with $\{x:x^i<0\}$ is the graph of $-f$. Since every point in $S^n$ is in one of these sets, $S^n$ satisfies the local $n$-slice condition, this is an embedded submanifold. The terminology is that if $M$ is a smooth manifold, and $S\subset M$ a subset, then $S$ satisfies the local $k$-slice condition if each point of $S$ is contained in the domain of a smooth chart $(U,\varphi)$ for $M$ such that $S\cap U$ is a single $k$-slice in $U$. I don't see how this makes $S^n$ satisfy the local $n$-slice condition. Presumably the chart on $\mathbb{R}^{m+1}$ is $(U=\{x:x^i>0\},\mathrm{id})$, so that $S^n\cap\{x:x^i>0\}$ is an $n$-slice of $U$? But this doesn't seem right since $\mathrm{id}(S^n\cap U)$ is a hemisphere of $S^n$, but that's not a $n$-slice in the corresponding half-place $\mathrm{id}(U)$?","['differential-topology', 'smooth-manifolds', 'differential-geometry']"
889734,Can a set be infinite and bounded?,"I don't understand a statement in my math book course, I was restudying the compact sets part of the chapter when at a certain moment there is a corollary saying : 'every infinite and bounded part of $\mathbb{R^n}$ admit at least one accumulation point' because for me a set is either bounded so finite or infinite so unbounded. I don't really understand because I can accept the fact that without a metric, bounds make no sense in topology but here $\mathbb{R^n}$ is clearly known as a metric space. thank you for your help","['general-topology', 'infinity', 'analysis']"
889760,Convex weak* sequentially closed subset of the dual of a separable Banach space is weak* closed,"I'm studying Conway's a course in Functional Analysis by myself. The following is  corollary 6.12.7 of this book. If $X$ is a separable Banach space and $A$ is a convex subset of $X^*$ that is weak* sequentially closed, then $A$ is weak* closed. Proof: Because X is separable, $r(ball X^*)$ is weak* metrizable for every $r>0$. So if A is weak* sequentially closed, $A\cap (r(ball X^*))$ is weak* closed for every $r>0$. Hence the Krein-Smulian theorem applies. My problem: I do not know how A is weak* sequentially closed implies $A\cap (r(ball X^*))$ is weak* closed for every $r>0$.","['normed-spaces', 'functional-analysis', 'banach-spaces']"
889765,Zero point when $f'(x)\gt c$,"Suppose that the function $f:\mathbb R\to\mathbb R$ is continuously differentiable and that there is a positive number $c$ such that $f'(x)\ge c$ for all points $x$ in $\mathbb R$. Prove that there is exactly one number $x_0$ at which $f(x_0)=0$. This question border me since it seems easy and obvious. I can prove the uniqueness of $x_0$ (since by mean value thm, if there are two zero points, there must be a point such that $f'(x)=0$). However, I cannot prove the existance of such $x_0$.","['derivatives', 'analysis']"
889780,"Throwing dice twice, with unlike probability of occourence?","A loaded dice has the property that when the dice is thrown the probability of showing a given number is proportional to the number. For example $2$ is twice as likely to show up compared to $1$ and $3$ is thrice as likely to show up compared to $1$, And so on. What is the probability that when the dice is thrown twice the sum is $4$ or less.
$$
    P =  \frac 36 \cdot \frac 16 +\frac 16 \cdot \frac 36 + \frac 26 \cdot \frac 26 + \frac 16 \cdot \frac 26 + \frac 26 \cdot \frac 16 + \frac 16 \cdot \frac 16  =
    \frac{15}{36} 
$$
Where I am getting it wrong?","['dice', 'probability']"
889807,Jordan Measure and Lebesgue Measure,"The Jordan outer measure $J^*(E)$ of a set $E\subseteq \mathbb{R}$ is defined as infimum of $\sum_{i=1}^n (b_i-a_i)$ where $(a_i,b_i)$ are open intervals whose union contains $E$ . The Jordan inner measure $J_*(E)$ of a set $E\subseteq \mathbb{R}$ is defined as supremum of $\sum_{i=1}^n (b_i-a_i)$ where $(a_i,b_i)$ are open intervals, whose union is contained in $E$ . A set is $E$ Jordan measurable if $J^*(E)=J_*(E)$ . Lebesgue measure of a set $E\subseteq \mathbb{R}$ is defined in a similar way by defining Lebesgue outer measure and inner measure, where the sums/unions in above definition are allowed to be countable. Question: What properties of functions can be characterized by the Lebesgue measure but not the Jordan measure? (I want a motivation of Lebesgue measure with some drawback/disadvantages of Jordan measure. I didn't find theory of Jordan measure in many books of Measure theory, although it was a motivational point towards development of Lebesgue measure and Integration.)",['measure-theory']
889813,Proof of the Borsuk-Ulam Theorem,"The Borsuk-Ulam Theorem says the following: For any continuous map $g: S^n \rightarrow \mathbb{R}^n$ there exists $x \in S^n$ such that $g(x)=g(-x)$. I'm trying to work through the proof given in Allen Hatchers ""Algebraic Topology"" but I don't understand the very last step. His proof goes like this: Let $f(x)=g(x)-g(-x)$ with $g$ as above. So $f(-x)=-f(x)$. We need to show that $f(x)=0$ for some $x$. If this is not the case we can replace $f(x)$ by $\frac{f(x)}{|f(x)|}$ to obtain a new map $f: S^n \rightarrow S^{n-1}$. Now, if we can show that the restriction of this $f$ to the equator $S^{n-1}$ is nullhomotopic, then we're done by previous propositions. But this is exactly the step that I don't understand: Why is $f|_{S^{n-1}}$ nullhomotopic? Hatcher simply says that it is nullhomotopic via the restriction of $f$ to one of the hemispheres bounded by $S^{n-1}$. What does he mean by that and why is it true?","['general-topology', 'homotopy-theory', 'algebraic-topology']"
889815,How to find adjoint of linear operator T on inner product space V,"Let $V$ be an inner product space and $T$ a linear operator with $T(\alpha) = (\alpha,\beta)\gamma$ for fixed elements $\beta,\gamma \in V$. I now that $T$ is linear operator. How we can show that adjoint of $T$ ($T^*$) exist and what is it?",['linear-algebra']
889903,"show that $f^{(3)}(c) \ge 3$ for $c\in(-1,1)$","Let $f:I\rightarrow \Bbb{R}$, differetiable three times on the open interval $I$ which contains $[-1,1]$. Also: $f(0) = f(-1) = f'(0) = 0$ and $f(1)=1$. Show that there's a point $c \in (-1, 1)$ such that $f^{(3)}(c) \ge 3$ I'd be glad to get a guidace here how to start.","['functions', 'calculus', 'derivatives', 'real-analysis']"
889910,Why use regularization to reduce over-fitting,"I'm having trouble understanding why should we use regularization for over-fitting when we can simply reduce the number of order to our polynomial function? Is it because it saves us time from having to come up with a polynomial function of lower order? For linear regression most of the work in figuring out a fit comes from figuring out our coefficients b0, b1, etc which we can simply find with a closed form equation(sometimes known as the normal equations). If we use regularization we have to come up with a lambda that makes sense. Please give me some example or insight on the benefits of using regularization.","['regularization', 'machine-learning', 'statistics', 'polynomials', 'regression']"
889912,Prove that the function $f^2+f^3$ attains every complex value.,"If $f$ is a nonconstant entire function, prove that the range of $f^2+f^3$ is the entire complex plane. I tried to solve the exercise by using the Little Picard's theorem. Specifically, i assumed that $\exists w_0 : f^2(z)+f^3(z) \neq w_0, \forall z \in \mathbb{C}$, and using this assumption to show somehow that $f$ ommits two complex values, hence it is constant. However i can't find any way to show it.",['complex-analysis']
889920,Convergence in $C(X)$ is uniform convergence.,"I read this the convergence in $C(X)$ is uniform convergence. Where $X$ is compact hausdorff topological space and $$C(X)=\{f:X\to\mathbb{C}\;\mid \; f\ \text{is continuous}\}$$ And 
$$\|f\|=\sup\{|f(x)|:x\in X\}$$ What I have done: I suppose $f_n\to f $ pointwise, then for every $\varepsilon>0$ and for every $x\in X$ there exists a positive integer $N$ such that $\forall n\geq N$ we have $$d(f_n(x),f(x))=\|f_n(x)-f(x)\|<\varepsilon$$ then $$\sup_{x\in X}\|f_n(x)-f(x)\|<\varepsilon$$ Then further what I should do? Edited:My question is how to prove that convergence in C(X) is uniform convergence and also  is this because of compactness of $X$ or because of supremum norm?","['uniform-convergence', 'functional-analysis', 'real-analysis']"
889923,"About the rigorous $(\epsilon,\delta)$ definition of limit","I have questions about the complete and rigorous $(\epsilon,\delta)$ definition of two sided limits. The definition of the two sided limit in http://en.wikipedia.org/wiki/(%CE%B5,_%CE%B4)-definition_of_limit says that for a function $f(x)$ which is defined on an open interval containing $c$, possibly excluding $c$, it is $\lim_{x \to c} f(x)=L$ iff there is some $\delta > 0$ for every $\epsilon > 0$ such that for every $x$ which provides $0 < |x - c| < \delta$ it is $|f(x) - L| < \epsilon$. My first question is about the ""open interval"" which is stated at the beginning. If we assume that $f(x)$ is defined on an open interval $I$ which contains $c$, shouldn't the definition state that ""for every $x \in I$ which provides $0 < |x - c| < \delta$"" instead of just saying ""for every $x$ which provides $0 < |x - c| < \delta$"" in order to limit $x$ with interval $I$ of our selection? My second question is about the interpretation of the above definition. Let's say we the $f(x)$ as in the following sketch: Here, the function is continuous, defined on an open interval $(A,B)$ with $a \in (A,B), c \in (A,B)$ and $b \in (A,B)$ and $|a-c|>|c-b|$. A valid selection for $\delta $ is $\delta = |c-b|$ such that for every $x$ with $0 < |x-c| < |c-b|$ it is $|f(x) - f(c)| <\epsilon$. But if we have the following $f(x)$ instead: which is the same as the first one, but the the domain of $f$ is $(A,a)$ this time and it is $|c-b| > |a-c|$. My question is, in this case, can $|b-c|$ again be a valid $\delta$ value, since again for every $x$ which provides $0 < |x-c| < |b-c|$ we have $|f(x) - f(c)| < \epsilon$. I ask this because I used to think this definition always for functions defined on the whole real line and this makes one to believe that we should have intervals of the same length around $c$ which provides $|f(x)-L|$ where $L$ is a general limit value. But in the second sketch, this is not the case.","['calculus', 'real-analysis', 'limits']"
889948,"Example of a function $F(x,y)$","I'm trying to find a non trivial function $F(x,y)$ such that $div F(x,y)=0$ everywhere and $F(x,y)=0$ on the unit square. I know that there are some books that provide such example but I didn't find anything. Thanks for your help","['multivariable-calculus', 'examples-counterexamples', 'functions']"
889949,Global sections on non-reduced proejctive schemes,"Suppose $X$ is a non-reduced finite type seperated projective scheme over a field $k$, can it happen that $\Gamma(X,O_X)=k$?",['algebraic-geometry']
889971,Prove $\tan 54^\circ=\frac{\sin24^\circ}{1-\sqrt{3}\sin24^\circ}$,"How to prove this identity without using the actual values of $\tan54^\circ$ and $\sin24^\circ$ $$\tan 54^\circ=\dfrac{\sin24^\circ}{1-\sqrt{3}\sin24^\circ}$$ Edit: I still don't get it, I am stuck at: $$\dfrac{\cos 24^\circ+\sqrt{3}\sin 24^\circ}{\sqrt{3}\cos 24^\circ-\sin 24^\circ}$$ P.S. : Is this coincidence or a more general form can be obtained?","['trigonometry', 'algebra-precalculus']"
889986,Rudin's proof of the change of variable theorem,"I am having trouble with Rudin's proof of the change of variable theorem for multiple integrals. The theorem is for 1-1 $\mathscr{C'}$ mappings from $R^k$ into $R^k$. In theorem 10.7 just before the change of variable theorem, he proves that if $\mathbf{F}(\mathbf{x})$ is a $\mathscr{C'}$ mapping of an open set $E\subset{R^k}$ into $R^k$ with $0\in{E}$, with $\mathbf{F}(\mathbf{0})=0$ and $\mathbf{F'}(0)$ invertible, then there is a neighborhood of $\mathbf{0}$ in which the representation $$\mathbf{F}(\mathbf{x})=B_1\cdots B_{n-1}\mathbf{G}_n\circ \cdots \mathbf{G}_1(\mathbf{x})$$ is valid, with each $\mathbf{G}_i(\mathbf{x})$ being a primitive $\mathscr{C'}$ mapping in some neighborhood of zero, $\mathbf{G}_i(\mathbf{0})=0$, and $\mathbf{G'}_i(0)$ is invertible, and each $B_i$ is either a flip or the identity operator. In the change of variable theorem, he claims that we can write $T(\mathbf{x})$, our 1-1 $\mathscr{C'}$ on $R^k$ mapping, as $$\mathbf{T}(\mathbf{x})=\mathbf{T}(\mathbf{a})+B_1\cdots B_{k-1}\mathbf{G}_k\circ \cdots \mathbf{G}_1(\mathbf{x-a})$$ If $\mathbf{T}(\mathbf{x})$ is linear, I understand how theorem 10.7 applies, because $\mathbf{T}(\mathbf{0})=\mathbf{0}$ for all linear transformations and we can apply the theorem to $\mathbf{T}(\mathbf{x-a})$. But if T is not linear, how does he arrive at this equation? Secondly, even if the equation does hold, clearly $\mathbf{T}(\mathbf{x-a})$ is composition of primitive $\mathscr{C'}$ mappings and flips, but why is $\mathbf{T}(\mathbf{x})$. Doesn't the addition of the constant term $\mathbf{T}(\mathbf{x})$ change things?",['analysis']
890009,Solve $(1+z)^8=(1-z)^8$,"My guess is to write this as $$\left(\frac{1+z}{1-z}\right)^8=1.$$ We can then find 8 possibilities for $\frac{1+z}{1-z}$, namely $\cos(k\pi/4)+i\sin(k\pi/4)$, $k=1,\ldots,8$. For each $k$ we can then deduce 2 equations by putting $z=x+iy$, for example for $k=1$ we get: $$\frac{1+x+iy}{1-x-iy}=\frac12 (1+i).$$ Now we find two equations for $x$ and $y$, by noting both the real and imaginary parts of the equations should be equal, and can thus find $z$. However, doing this for $k=1,\ldots,8$ seems somewhat cumbersome. Does anyone know of a faster way to find the $z$? Thans in advance.","['complex-analysis', 'polynomials']"
890014,What is the maximum y-value of the following function?,"What is the maximum y-value of the following function? $$y=8t - \frac{t^2}{2} -24 $$ It can be done by using the parabolic equation , setting the equation is equal zero. But is there any other straight forward or  shortest method to do this?",['algebra-precalculus']
890035,Trigonometric functions and inverse functions,Can we write $\sin x > a$ as $x > \arcsin a$. Please explain the process. Is it possible for all ratios with any inequality sign.,['trigonometry']
890039,"How to count the $r$-tuples of subsets of $\{1,\dots,n\}$ that are cyclically disjoint?","I want to count the following, $$\#\{S_1,S_2,\dots, S_r\subseteq[n]\;|\;  S_i\cap S_{i+1}=\emptyset \text{ for } 1\leq i\leq r-1 \mbox{ and } S_1\cap S_r=\emptyset\}=A_{n,r},$$ Then $A_{n,1}=2^n$, $$A_{n,2} =\sum_{a_1=0}^{n}\binom{n}{a_1}\sum_{a_2=0}^{n-a_1}\binom{n-a_1}{a_2}=\sum_{a_1=0}^{n}\binom{n}{a_1}2^{n-a_1}=3^n$$ \begin{align*}
A_{n,3} &=\sum_{a_1=0}^{n}\binom{n}{a_1}\sum_{a_2=0}^{n-a_1}\binom{n-a_1}{a_2}\sum_{a_3=0}^{n-a_2-a_1}\binom{n-a_2-a_1}{a_3}\\
        &=\sum_{a_1=0}^{n}\binom{n}{a_1}\sum_{a_2=0}^{n-a_1}\binom{n-a_1}{a_2}2^{n-a_2-a_1}\\
        &=\sum_{a_1=0}^{n}\binom{n}{a_1}3^{n-a_1}\\
        &=4^n.
 \end{align*} when counting $A_{n,4}$, the problem comes, I cannot do it like following, $$A_{n,4} =\sum_{a_1=0}^{n}\binom{n}{a_1}\sum_{a_2=0}^{n-a_1}\binom{n-a_1}{a_2}\sum_{a_3=0}^{n-a_2}\binom{n-a_2}{a_3}\sum_{a_4=0}^{n-a_3-a_1}\binom{n-a_3-a_1}{a_4}$$ instead, for the last term, I need to choose $a_4$ from n- union of $a_1$ and $a_3$ How can I do it? or is there any other method to do it?","['summation', 'combinatorics']"
890052,A nice trignometric identity,"How to prove that: $$\cos\dfrac{2\pi}{13}+\cos\dfrac{6\pi}{13}+\cos\dfrac{8\pi}{13}=\dfrac{\sqrt{13}-1}{4} $$ I have a solution but its quite lengthy, I would like to see some elegant solutions. Thanks!",['trigonometry']
890062,Inequality involving traces and matrix inversions,"The following question kept me wondering for some weeks: Given the symmetric matrices $A,B,C\in\mathbb{R}^{n\times n}$ where $A$ and $C$ are positive definite (hence invertible), and $B$ is positive semidefinite (hence not necessarily invertible) with $\operatorname{trace}(B)\neq 0$, prove that $$\operatorname{trace}\left\{C^{-1/2}BC^{-1/2}(A^{-1}+C^{-1/2}BC^{-1/2})^{-1}(A+\frac{n}{\operatorname{trace}(B)}C)^{-1}\right\}\geq
\operatorname{trace}\left\{(A+\frac{n}{\operatorname{trace}(B)}C)^{-2}A    \right\}.$$ If it would help, one can also consider the simpler version with $C=I$: prove that $$\operatorname{trace}\left\{B(A^{-1}+B)^{-1}(A+\frac{n}{\operatorname{trace}(B)}I)^{-1}\right\}\geq
\operatorname{trace}\left\{(A+\frac{n}{\operatorname{trace}(B)}I)^{-2}A    \right\}.$$ Please note that the matrix inversion lemma is not applicable at first as $B$ is positive semidefinite. Although I'm not sure, it seems like $\operatorname{trace}(B)=\operatorname{trace}\{(\operatorname{trace}(B)/n)I\}$ should be utilized in some way, and it may also help to interpret the trace operator in terms of the Frobenius norm. I would highly appreciate if anyone can provide some help or suggestions on this.","['matrices', 'linear-algebra', 'inequality']"
890075,Existence of families of sets whose elements are incomparable in terms of $\in$,"There exist families of sets whose elements are comparable in terms of $\in$, like for example the set of finite von Neumann ordinals, there exist such that their elements are incomparable in terms of $\in$ (in the sense that for no two elements $x$ and $y$: $x\in y$ or $y\in x$), like for example $\{\{1\},\{2\},\{3\},\ldots\}$. My question is: can we construct for an arbitrary cardinality $\kappa$, a family $\mathcal{A}$ of sets of cardinality $\kappa$, whose elements are pairwise incomparable in terms of $\in$:
\[
(\forall {x,y\in\mathcal{A}})\,(x\notin y\wedge y\notin x)\ ?
\]",['elementary-set-theory']
890080,"Using expressions like $ \langle x,y \rangle$ in predicate logic formulas","I don't like how books on set theory write logic formulas when describing complex sets. For example that is how a regular book can show that some set $s$ is not a pair: $$\forall x \forall y (\langle x,y \rangle \neq s)$$ Or by this way a book can show that some set $s$ is a relation:
$$\forall p (p \in s \implies \exists x \exists y (\langle x,y \rangle = p))$$ The expression $\langle x,y \rangle$ when used in formulas confuses me. It is like you create an object on the fly . If the object $\langle x,y \rangle$ were constant, it would be fine, but it depends on the quantifiers $x$ and $y$, and outside of the formula doesn't make sense. And the books do it all the time. I haven't learned logic deeply but it seems to me that the given formulas are not formulas of predicate logic. In predicate logic you have simple quantifiers like $\forall x$ that range over objects and you have predicates that evaluate either to true or false, not to other objects. But in these formulas it is like you can use a complex quantifier: $\forall \langle x,y \rangle$ that ranges over all pairs. The authors of the books on set theory start using this way of writing without any explanation what they are doing. It is like they were saying: ""you will understand it when you take a course on logic, and now watch what we do and do the same."" But, alas, they don't even make this clear. I see only two possibilities: 1) these are legitimate formulas in predicate logic, and my confusion is due to not knowing logic well, or 2) this is just an informal way to express complex ideas, and we can always translate any formula written in this informal way to a legitimate predicate logic formula. That's how I would express that some set $s$ is not a pair. Let's create a property $P(x,y,z)$ which is true iff $\langle x,y \rangle = z$: $$P(x,y,z) \iff \exists a ( x \in a \land \forall v (v \in a \implies v =x) \land \exists b(x \in b \land y \in b \land \forall v (v \in b \implies v = x \lor v = y)) \land a \in z \land b \in z \land \forall v (v \in z \implies v = a \lor v = b)))  $$ Given that property we can express that some set $s$ is not a pair: $\forall x \forall y (\lnot P(x,y,s))$. Here if we substitute $P(x,y,s)$ with the big formula given above, we would get a legitimate predicate logic formula. We can also express that some set $f$ is a function: $$\forall p (p \in f \implies (\exists x \exists y P(x,y,p) \land \lnot \exists y' \exists p'(y \neq y' \land P(x,y',p') \land p' \in f)))$$","['predicate-logic', 'elementary-set-theory']"
890106,Discriminant of $x^n-1$,"Question is to find discriminant of polynomial $x^n-1$ I consider $f(x)=x^n-1=(x-a_1)(x-a_2)(x-a_3)\cdots(x-a_n)$ Now, $$f'(x)=[(x-a_2)(x-a_3)\cdots(x-a_n)]+\cdots+[(x-a_1)(x-a_2)\cdots(x-a_{n-1})]$$ $f'(a_1)=(a_1-a_2)(a_1-a_3)\cdots(a_1-a_n)$ $f'(a_2)=(a_2-a_1)(a_2-a_3)\cdots(a_2-a_n)$ $f'(a_3)=(a_3-a_1)(a_3-a_2)\cdots (a_3-a_n)$ and so on.. Now i need to know how many sign changes do i need to get something which looks like discriminant I would write this in a matrix form to get some idea...
$$\begin{bmatrix}12&13&14&15&\cdots&1n\\21&23&24&25&\cdots&2n\\31&32&34&35&\cdots&3n\\\\n1&n2&n3&n4&\cdots&n(n-1) \end{bmatrix}$$ See that i first row every element is in correct position i mean of the form $ij$ for $i<j$ In second row only one element is odd of the form $ij$ with $i>j$ but i want $i<j$ in discriminant so i would change this.. So my count starts... change sign 1 In third row there are two elements which are not behaving properly... So, I should change them also.. So, Now another  two changes... On the whole $1+2$ changes... In fourth row there would be $3$ misbehaving children so my count is $1+2+3$ In last row every body is behaving badly so i have to make $n-1$ changes in that.. On the whole i have to make $1+2+3+\cdots +n-1=\dfrac{n(n-1)}{2}$ changes.. So, $f'(a_1)f'(a_2)\cdots f'(a_n)=(-1)^{\dfrac{n(n-1)}{2}}(a_1-a_2)^2(a_1-a_3)^2\cdots (a_{n-1}-a_n)^2=(-1)^{\dfrac{n(n-1)}{2}} Disc(f)$ But then $f'(x)=nx^{n-1}$ This tells me that $f'(a_i)=n(a_i)^{n-1}$ So, $$Disc (f)=(-1)^{\dfrac{n(n-1)}{2}}  n^n(a_1a_2\cdots a_n)^{n-1}=(-1)^{\dfrac{n(n-1)}{2}}  n^n(-1)^{(n-1)^2}=(-1)^{\dfrac{n(n-1)}{2}+(n-1)^2}$$ As $(-1)^{n-1}=(-1)^{(n-1)^2}$ i would replace my $(-1)^{(n-1)^2}$ with $(-1)^{n-1}$ $$Disc (f)=(-1)^{\dfrac{n(n-1)}{2}}  n^n(a_1a_2\cdots a_n)^{n-1}=(-1)^{\dfrac{n(n-1)}{2}}  n^n(-1)^{n-1}=(-1)^{\dfrac{n(n-1)}{2}+n-1}n^n$$ i.e., $$Disc(x^n-1)=(-1)^{\dfrac{(n-1)(n+2)}{2}}n^n$$ As nobody was giving answer to my question i was trying my best and started editing this when ever i thought i find some thing and this is its final stage... This is fully solved now... Thank you.. Any other ways of approaches would be appreciated.. Thank you :)","['roots-of-unity', 'abstract-algebra', 'polynomials']"
890111,Find a linear differential equation for a given function,"Is there any general method for finding a linear differential equation with polynomial coefficients that is satisfied by a given elementary function (or prove that no one exists)? Example: If $f(x) = e^{\sqrt{x}}$, then
$$ 4xf''(x)+2f'(x)-f(x) = 0$$
Clearly, a first order linear differential equation with polynomial coefficients exists only for a given function $f(x)$ if $\frac{f'(x)}{f(x)} \in \mathbb{Q}(x)$, that is $f(x) = Ce^{\int{\frac{p(x)}{q(x)}}{dx}}$ for $p(x), q(x) \in \mathbb{Q}[x]$.
Can you generalize this condition to arbitrary elementary functions with high order DEs?","['ordinary-differential-equations', 'calculus']"
890125,What meaning did Riemann assign to $dx$?,"Detlef Laugwitz wrote a monumental biography of Riemann. The book was translated into English by Shenitzer. Laugwitz discusses Riemann's fundamental essay Uber die Hypothesen, welche der Geometrie zu Grunde liegen (On the Hypotheses
which lie at the Foundations of Geometry) of 1854 on the foundations of what has since become Riemannian geometry. Laugwitz writes: ""In the lecture, Riemann pushed to extremes his tendency to use as few formulas as possible."" Unfortunately Laugwitz does not elaborate, but the unique formula contained in Riemann's essay is the formula $$\frac{1}{ 1+\frac{\alpha}{ 4}\sum x^2}\sqrt{\sum dx^2}$$ expressing the length element of a metric of constant (sectional) curvature $\alpha$. What is puzzling here is Riemann's notation. This is of course before dual spaces and tensor calculus. What meaning did Riemann attach to $dx$? It is hard to say it was infinitesimal because Riemann is known for giving a rigorous treatment to the, well, Riemann integral. I see now that there is also a book by Monastyrsky Riemann, topology, and physics that might be relevant. Does anyone have a reference that would comment on this? Note 1. Spivak's Differential geometry , third edition, volume 2, chapter 4 contains an English translation of Riemann's essay.  Here on page 155 Riemann speaks of the line as being made up of the $dx$, describes $dx$ as ""the increments"", and speaks of infinitesimal displacements. On page 156 he speaks of infinitely small quantities $x_1dx_2-x_2dx_1$, etc., as well as of infinitely small triangles.","['integration', 'math-history', 'infinitesimals', 'riemannian-geometry', 'reference-request']"
890140,Nullhomotopic map extended,"I have troubles understanding this proof: Let $h:S^1 \rightarrow X$ be a continuous map, then we have that if $h$ is nullhomotopic, $h$ can be extended to a continuous map $k:B^2 \rightarrow X.$ Proof: Since $h$ is nullhomotopic, there exists a homotopy $H: S^1 \times I  \rightarrow X$ between $h$ and a constant map.(This is clear). Now we define a map $\pi:S^1 \times I \rightarrow B^2$ by $\pi(x,t)= (1-t)x$.
Then $\pi$ is continuous, onto and closed. Now, I am not sure why we know that this map is closed.  Alright so far. Now we notice that this is a quotient map with $\pi(S^1 ,1)=0 \in B^2$ and otherwise this map is injective. It is concluded from this that we can extend $h$ to a map $k$, but it is not sad: HOW?! Does anybody know why this is possible now?","['general-topology', 'algebraic-topology', 'real-analysis', 'analysis']"
890180,"Having fun integral $\int_0^{\pi/4} \cos x \arctan(\cos x)\, dx$","Playing around with the inverse trigonometric function integration, I found a nice closed-form of the following integral $$\int_0^{\pi/4} \cos x \arctan(\cos x)\, dx=\frac{3\sqrt{2}-1}{4}\pi-\frac{3\sqrt{2}}{2}\arctan\sqrt{2}$$ which numerically agrees with output of Wolfram Alpha. I am wondering, what is the nicest way ( or the most complicated way) to obtain the given result. I would love to see how Mathematics SE users prove it. Any method is welcome. Thank you. (>‿◠)✌","['calculus', 'integration', 'definite-integrals', 'trigonometry', 'alternative-proof']"
890207,Show that $\lim_{x\rightarrow 1}\sum_{n=1}^\infty \frac{(-1)^{n-1}}{n^x}=\ln2$.,"Prove $$\lim_{x\rightarrow 1}\sum_{n=1}^{\infty}\frac{{(-1)}^{n-1}}{{n}^{x}}=\ln2.$$ Of course  $$\sum_{n=1}^{\infty}\frac{{(-1)}^{n-1}}{{n}}=\ln2,$$
but we can not use the Proposition : If a sequence of functions that are continuous on a set converges uniformly on that set ,then the limit function is continuous on the set. because for $\forall\delta >0$,we have $\sum_{n=1}^{\infty}\frac{{(-1)}^{n-1}}{{n}^{x}} $converges on$\left(1-\delta ,1+\delta  \right), $but nonuniformly . In fact ,for every ${x}^{'},{x}^{""}\in \left(1,1+\delta  \right)，$in other words $\left| {x}^{'}-{x}^{""}\right|<\delta  $,fixing  the point $ {x}^{'}, $let ${x}^{""}\rightarrow {1}^{+},$we can get paradox:$$1\geq |\sum_{n=1}^{\infty}\frac{{(-1)}^{n-1}}{{n}^{{x}^{'}}}-(+\infty)|=+\infty>1.$$
So $\sum_{n=1}^{\infty}\frac{{(-1)}^{n-1}}{{n}^{x}}$ converge nonuniformly on $\left(1-\delta  ,1+\delta  \right)$. My question is how can we get $\lim_{x\rightarrow 1}\sum_{n=1}^{\infty}\frac{{(-1)}^{n-1}}{{n}^{x}}=\ln2.$","['convergence-divergence', 'sequences-and-series', 'continuity', 'real-analysis']"
890210,Proof of $\int_0^\infty \frac{x^{\alpha}dx}{1+2x\cos\beta +x^{2}}=\frac{\pi\sin (\alpha\beta)}{\sin (\alpha\pi)\sin \beta }$,I found a nice formula of the following integral here $$\int_0^\infty \frac{x^{\alpha}dx}{1+2x\cos\beta +x^{2}}=\frac{\pi\sin (\alpha\beta)}{\sin (\alpha\pi)\sin \beta }$$ It states there that it can be proved by using contours method which I do not understand. It seems that the RHS is Euler's reflection formula for the gamma function but I am not so sure. Could anyone here please help me how to obtain it preferably ( if possible ) with elementary ways (high school methods)? Any help would be greatly appreciated. Thank you.,"['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
890215,Trouble understanding Sum of Subspaces,"I started reviewing linear algebra, from a different textbook (Axler's), after taking a fast paced summer class. Unfortunately, I've become confused with a concept that is introduced at the end of chapter one. That is, sum of subspaces. Axler's text defines the sum of subspaces as follows. Let $U_1,U_2,...,U_m$ be subspaces of a vectorspace $V$. Then we say $U_1+U_2+...+U_m=\{u_1+...+u_m:u_1\in U_1,...,u_m\in U_m\}$ I thought I understood this concept, but I'm afraid I don't because I am having trouble answering the following assertions he asks us to verify. First that if we let $U_1,U_2,...,U_m$ be subspaces of a vectorspace $V$, then the sum of those subspaces is a subspace of $V$. Also, this is what really had me tricked to thinking I understood it. Let $U=\{(x,0,0)\in \mathbb R^3: x\in \mathbb R\}$ and $W=\{(0,y,0)\in \mathbb R^3:y\in \mathbb R\}$, then $U+W= \{(x,y,0):x,y\in \mathbb R\}$. So this example made me think it was pretty straight forward and that I understood it, but in the next few lines he says let $Z= \{(y,y,0)\in \mathbb R^3:y\in\mathbb R\}$. Then $U+W=U+Z$ (which I am asked to verify). Could someone please help me understand the definition and the verifications? EDIT: I currently see the definition to say that when we take a collection of sets that are subspaces the sum of the sets is a set which consists of the sum  of all their elements. However when I say that it seems to me the summed set consists of just one elements (the total sum of all the elements). Thank You","['vector-spaces', 'linear-algebra']"
890218,Disconnected Topoological Space with Intermediate Value Property,"Does There exist a disconnected topological space with intermediate value property? Intermediate Value Property states that 'a topological space X is said to have intermediate value property if for every continuous function f: X to Y (where Y is ordered set with order topology) the following is true: If a, b belongs to X and there exist r in Y s.t. r lies between f(a) and f(b) then there exist c in X s.t. f(c) = r.","['general-topology', 'analysis']"
890226,Central Limit Theorem vs. Weak Law of Large Numbers,"So, just to begin with I feel like this is a problem I am massively overthinking, and the solution is very simple. That said, it has been a while since I've taken a math class, and so some of my fundamentals are a little fuzzy. In addition, it seems that my probability theory class that covered this topic was taught in a somewhat idiosyncratic fashion ... Anyway, background aside, let's get to my question. Say we have a sequence of independent, identically distributed random variables, $X_1,...,X_n$ with $E(X_i)=0$ and $Var(X_i)=1$. It is trivial to show that by the central limit theorem, $\sqrt{n}\bar{X}_n\xrightarrow[]{d}N(0,1)$; more rigorously of course this is $\sqrt{n}\frac{\bar{X}_n-0}{\sqrt{1}}\xrightarrow[]{d}N(0,1)$. But by the weak law of large numbers, we also have $\bar{X}_n\xrightarrow{p}\mu$, where in this case $\mu=0$. Convergence in probability implies convergence in distribution, so then we have $\bar{X}_n\xrightarrow{d}0$. By the continuous mapping theorem, if $g$ is a continuous function, then $X_n\xrightarrow[]{d}X$ implies $g(X_n)\xrightarrow[]{d}g(X)$. So applying that we would say $g(y)=\sqrt{n}y$, and thus $g(\bar{X}_n)\xrightarrow{d}g(0)$; so $\sqrt{n}\bar{X}_n\xrightarrow{d}0$. Which is NOT equivalent to saying that $\sqrt{n}\bar{X}_n\xrightarrow[]{d}N(0,1)$, the result we get from applying the central limit theorem. So for this question, am I applying one (or both) of these theorems incorrectly? Which is the correct interpretation in this situation, or is there another interpretation entirely I am missing? EDIT: It occurs to me that my problem may be that $\sqrt{n}y$ may not be a continuous function, and so it is inappropriate to invoke the continuous mapping theorem in that context. All the same, I am having some trouble reconciling the predictions made by the CLT and WLLN, respectively.","['probability-theory', 'law-of-large-numbers', 'central-limit-theorem']"
890228,Two and Three Variable Limit Questions,"Find the following limits, if they exist. $$\lim_{x,y\rightarrow 0,0}\frac{x^2 + \sin^2 y}{\sqrt{x^2+y^2}}$$ I believe we're suppose to use the squeeze theorem on this first one above. Possibly utilizing the fact that sin(y) is always between -1 and 1? I know the end result is suppose to be zero, but I'm having a hard time getting there. $$\lim_{x,y,z\rightarrow 0,0,0}\frac{x^2 yz}{x^8 + y^4 + z^2}$$ I know the end result is suppose to be a DNE. I attempted to set multiple variables equal to zero to see what it would come out to, and got differing values. So, when $y,z = 0$, the limit $= 0$, when $y,z = x$, the limit $= \infty$. Since these values are different -> DNE. However I'm quite sure I'm not getting the full picture here either. If someone could go over the process and logic associated with these problems, I'd greatly appreciate it. This is NOT homework, this is test prep.","['multivariable-calculus', '3d', 'calculus', 'limits']"
890237,"Are there any ""nontrivial"" sets with small difference sets?","I'm trying to find finite sets $S$ of natural numbers with ""small"" difference sets. One option is just taking an arithmetic progression $S = \{0, , \ldots, n-1\}$ . Then $|S - S| = 2 |S| - 1$ , which is, I think, the smallest possible difference set. However, I'm not able to find examples that stray too far from that mold. According to some computer tests, all the subsets $S \subset \{0, \ldots, 20\}$ that have difference sets with $|S - S| \leq 2.1 |S|$ that are not arithmetic progressions look like $$
\{0,1,2,3,4,5,6,7,8,9,11\}
$$ and there are no such subsets with $|S - S| \leq 2.05 |S|$ . I've run some subsets of $\{0, \ldots, 30\}$ and am getting similar results. When I chance my criterion to be, for instance, $|S - S| \leq 2|S|^{1.1}$ (or some other polynomial of degree $< 2$ ), I get basically the same sets: ones that look like arithmetic progressions. My question is then, is it possible to find large sets with small difference sets that are not very similar to arithmetic progressions? Or, is there a theorem relating the size of $|S - S|$ to how ""close"" $S$ must be to an arithmetic progression? I'm aware of Freiman's theorem. Ideally there would be a version that instead of working with $|A + A| < K|A|$ , worked with $|A + A| < K|A|^r$ for $1 \leq r < 2$ . Freiman's theorem states that (roughly) that letting $n = |A|$ , if $|A - A| \leq \alpha n$ , then $A$ is contained in a generalized arithmetic progression of dimension $d = O(e^\alpha)$ and length $C = O\left(e^{e^{\alpha}}n\right)$ . Rusza stated, and Tao implied, that the correct bounds should be about $d \sim \alpha$ and $C \sim e^{\alpha}$ , for a progression of dimension $\alpha$ and length $e^\alpha n$ . So I'm revising my question to make it a little more precise: Are there ""very large"" finite sets $A \subset \mathbb{Z}$ of size $n = |A|$ such that $|A - A| \leq 4|A|$ (for instance) such that the smallest generalized progression containing $A$ has size at least $e^4n$ ?","['additive-combinatorics', 'difference-sets', 'combinatorics']"
890287,Unit circle can't be covered by one chart,"I am hoping that someone can give me a proof showing why the unit circle cannot be covered by one coordinate chart, or a reference where I can find a proof.","['manifolds', 'reference-request', 'differential-geometry', 'circles']"
890294,Differentiation of the Beta function,"I suppose that
\begin{align*}
\frac{\partial}{\partial x}\left[B\left(x,y\right)\right]=&\frac{\partial}{\partial x}\left[\int_0^1t^{x-1}(1-t)^{y-1}dt\right]\\
=&\left[\int_0^1\frac{\partial}{\partial x}\left(t^{x-1}(1-t)^{y-1}\right)dt\right]\\
=&\left[\int_0^1(x-1)t^{x-2}(1-t)^{y-1}dt\right]\\
=&(x-1)\left[B(x-1,y)\right]
\end{align*}
and computing it by Matlab Mupad results in
\begin{align*}
-\beta(x,y)\left(\Psi(x+y)-\Psi(x) \right)
\end{align*}
where $\Psi(x)$ is the digamma function. Working with digamma function is not such easy. Can anyone prove that they two are equal or mine is false?","['special-functions', 'calculus', 'functions', 'partial-derivative', 'matlab']"
890303,"Show that the set $\left\{\sin\frac{1}{2}x,\sin\frac{3}{2}x,\sin\frac{5}{2}x,\ldots\right\}$ is complete on $[0,\pi]$","Show that the set $$\left\{\sin\frac{1}{2}x,\sin\frac{3}{2}x,\sin\frac{5}{2}x,\ldots\right\}$$ is complete on $[0,\pi]$ I think I can change it to $\left\{\sin\left(\frac{2n-1}{2}x\right)\right\}_{n=1}^\infty$ Now I think I'm supposed to show that Parseval's equality holds for every $f \in R[0,\pi]$ which is
$$\frac{2}{\pi}\int_0^\pi f^2(x)\,dx = \sum_{n=1}^\infty b_n^2$$ $$b_n = \frac{2}{\pi}\int_0^\pi f(x)\sin(nx)\,dx$$
Now I'm not sure what to do. Edited. So let $f_0$ denote the odd extensions of $f$ to $[-\pi,\pi]$. We know that $\left\{1, \cos nx, \sin nx\right\}_{n=1}^\infty$ is complete on $[-\pi,\pi]$. So now we have $$\sum_{n=1}^\infty b_n^2 = \frac{1}{\pi}\int_{-\pi}^\pi f_0^2(x)dx = \frac{2}{\pi}\int_0^\pi f^2(x)dx$$ $$\frac{1}{\pi}\int_{-\pi}^\pi f_0^2(x)dx = \frac{1}{\pi}\int_{-\pi}^\pi \sin\left(\frac{2n-1}{2}x\right) dx = \frac{1}{\pi} \left[\frac{-2\cos(nx - \frac{x}{2})}{2n-1}\right]_{-\pi}^\pi$$ $$= \frac{1}{\pi}\left[\frac{-2\sin(n\pi)}{2n-1} - \frac{-2\sin(n\pi)}{2n-1}\right] = 0$$ Would this be right?","['real-analysis', 'analysis']"
890313,Expected value of n trials where probability of an event occuring is 1/n,"Say the probability of an event occurring is 1/1000, and there are 1000 trials. What's the expected number of events that occur? I got to an answer in a quick script by doing the above 100,000 times and averaging the results. I got 0.99895, which seems like it makes sense. How would I use math to get right to this answer? The only thing I can think of to calculate is the probability that an event never occurs, which would be 0.999^1000, but I am stuck there.","['statistics', 'probability']"
890319,Convergence of tetration sequence.,"This question arose from here . I am interested to find a nice proof about the convergence of $${^n}a=\underbrace{a^{a^{\ .^{\ .^{\ .^a}}}}}_{n\ \text{times}}.$$
I find with google a necessary and sufficient condition to have the convergence is $\frac{1}{e^e} \leq a \leq e^{1/e}$ but the part for $a\le1$ need some ugly work. Does anyone have an elegant/slick proof ?","['sequences-and-series', 'convergence-divergence', 'calculus']"
890353,"Finding the ""canonical decomposition"" of a function -- I don't know if I'm doing it right","I've been told to identify the terms in the canonical decomposition of the function r |-> exp(2*pi*i*r) from R -> C. I've been able to give an answer, but I think i might have misinterpreted the question, because it doesn't feel like i did anything. This is my answer: -- A is R (reals) Z is C (complex) let f: R -> C be r |-> exp(2*pi*i*r) Pick = as the equivalence relation ~ then A/~ is the set of singletons {{x} | x in R} the function q: A -> A/~ can be written as q(x) = {x} by definition, f~([a]~) = f(a) where f~ is the function from A/~ to im f we know [a]~ = {a}, therefore, f~([a]~) = f~({a}) = f(a) = exp(2*pi*i*a), f~({a}) = exp(2*pi*i*r) the third function is the inclusion v: im f -> B, v(x) = x -- The reason i think I'm missing something is because i could have replaced the function r |-> exp(2*pi*i*r) with pretty much anything else, and just substituted that expression in two places without changing the answer. Am I missing something? I've searched around for more about 'canonical decomposition', but it doesn't seem to be a widely used term at all.","['elementary-set-theory', 'functions']"
890373,log-trig integral $\int_{0}^{\frac{\pi}{2}}\ln(1+\sin x)\ln(1+\cos x)\tan x\ dx$,Here is another log-trig integral you may find challenging/fun. Or not :) $$\int_{0}^{\frac{\pi}{2}}\ln(1+\sin(x))\ln(1+\cos(x))\tan(x)dx=\frac{\pi^{2}}{8}\ln(2)-\frac{5}{16}\zeta(3)$$,"['definite-integrals', 'trigonometric-integrals', 'integration']"
890379,Symmetry group of the vector field $V=x \partial /\partial x + y \partial /\partial y$,"I was trying to solve an exercise in one of Arnold's book that asks for the symmetry group of the vector field $V=x \partial /\partial x + y \partial /\partial y$, that is the diffeomorphisms $g$ of $\mathbb{R}^2$ such that $g_*V = V$.
I can see that the dilations and rotations are in this group and in general all the linear isormorphisms of $\mathbb{R}^2$. For the general solution I guess I have to look for the $g$ such that
$Jg|_p V_p = V_{g(p)}$ but this is a PDE and I guess there should be another way to do it.","['ordinary-differential-equations', 'vector-fields', 'differential-geometry']"
890397,Finding the derivative using the definition?,"Calculate the derivate of the given function directly from the definition of derivative, and express the result using differentials $$\lim_{h\to 0} \frac{f(x+h)-f(x)}{h}$$ when $f(x)= 1/\sqrt{1+x^2}$ any tips/solutions on how to get started on this one? I am able to do more basic problems, but not with root etc! thanks for tips/advice/solutions!","['calculus', 'algebra-precalculus', 'derivatives']"
890421,Closed form of a sum of binomial coefficients?,"I have the following function: $T_n(d)=\sum\limits_{k=\frac{n-d}{2}}^{\lceil \frac{n}{2} \rceil}{k\choose \frac{n-d}{2}}$
  ${n \choose 2k}$, where $n,d\in \mathbb{N}^0$, and $n,d$ have the same parity. Looking at the sequences for various $d$, it seems that the formula is a polynomial of degree $d$ in $n$. This is speculation, but for example, where defined, it would appear that: $T_{n}(1)=n$, $T_{n}(2)=\frac{1}{2}n^2$, $T_{n}(3)=\frac{1}{6}n^3-\frac{1}{6}n$, and $T_{n}(4)=\frac{1}{24}n^4-\frac{1}{6}n^2$ In fact, after further numerical testing, it seems that $T_n(d)=\frac{n}{d!}\prod\limits_{j=1}^{d-1}(n-(2j-d))$ So my question is, is there a way to confirm the above results and show whether or not $T_n(d)$ is a polynomial of degree $d$ in $n$? If so, is there an intuitive reason why it is a polynomial with evenly spaced integer roots? The result seems rather elegant, if it's true. EDIT: Simplifying the above expression, we have $$T_n(d)=\frac{n}{d!}\prod\limits_{j=1}^{d-1}(n-(2j-d))=\frac{n}{d!}\frac{(n-1+(d-1))!!}{(n-1-(d-1))!!}=\frac{2^d n}{n+d}\cdot {\frac{n+d}{2} \choose d}$$ The third and fourth expressions in particular, seem like they would be very useful for a combinatorial proof. $n!!$ is the standard double factorial.","['polynomials', 'sequences-and-series', 'binomial-coefficients', 'combinatorics']"
890425,Proof of the formulas for the the area of a rectangle and volume of a rectangular prism,How do we prove that the area of a rectangle and the volume of a rectangular prism are the product of the measure of their sides?,['geometry']
890431,A finite divisible group is trivial,I am having trouble seeing why a finite divisible group is necessarily trivial.  Why does this have to be the case?,"['finite-groups', 'group-theory', 'abstract-algebra']"
