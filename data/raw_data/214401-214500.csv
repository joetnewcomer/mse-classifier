question_id,title,body,tags
4344297,Contests with Calculus Questions,"I am self studying Thomas's Calculus , a popular Calculus textbook in the US and a few other countries. It covers the standard theorems and properties, the easier proofs, standard numericals and some simple applications. In non-calculus maths, I have seen that contest math questions tend to be more difficult, require more creativity, and better test understanding of concepts in a larger context. A couple of contests that I know have Calculus questions include: Mu Alpha Theta : Some nice questions which assume the same concepts that Thomas does, but more creative applications. Putnam Some very difficult questions (possibly too difficult to be done immediately after Thomas). Are there any other sources from where I can get questions for Calculus?
Also, what books would be recommended after finishing Thomas? Having solutions for the problems is very important, since I am self-studying. I will almost always go with a source that has solutions which can be checked when I can get stuck, or make the inevitable mistake.","['contest-math', 'multivariable-calculus', 'calculus', 'soft-question']"
4344332,Decay of linear system with damping,"Let us consider the following linear system with damping: $$
\begin{cases}
u_t - u_x = -\frac{1}{2} a(x) (u+v)\\
v_t + v_x = -\frac{1}{2} a(x) (u+v)
\end{cases}
$$ where $a(x) = \mathbf{1}_{(-\infty,-1)\cup(1,\infty)}(x)$ . Let's write the solution as $w=(u,v)$ corresponding to initial data $w_0 := w(0,\cdot) \in L^1(\mathbb R) \cap L^2(\mathbb R)$ . If $a \equiv 1$ , we can prove that $$w=w_1+w_2$$ where $$\|w_1\|_{L^2} \lesssim e^{-\alpha t}\|w_0\|_{L^2}, \qquad \|w_2\|_{L^\infty} \lesssim t^{-1/2}\|w_0\|_{L^1}$$ using Fourier transform. Can we prove something similar also for the choice of $as$ as $a(x) = \mathbf{1}_{(-\infty,-1)\cup(1,\infty)}(x)$ ?","['calculus', 'systems-of-equations', 'ordinary-differential-equations', 'partial-differential-equations']"
4344363,"If a compact set is not convex, some ball is tangent to it at several points.","Let $K\subseteq\mathbb{R}^n$ be compact (probably $K$ being closed will be enough). If $K$ is not convex, is there necessarily an open ball disjoint with $K$ but tangent to it at more than one point? Edit: I found a solution (it works with $K$ closed), although it is more complicated than I expected, simpler proofs would be welcome.","['euclidean-geometry', 'convex-geometry', 'geometry', 'geometric-topology', 'general-topology']"
4344401,Why does the conditional independent rule of INTERSECTION require STRICT POSITIVE DISTRIBUTION?,"Recently, I was confused with the proofs of some conditional independent rules (decomposition, weak union, contraction, intersection), particularly the conditional independent rule of INTERSECTION . In the book Probabilistic Graphical Models Principles and Techniques , Page25 mentioned that the STRICT POSITIVE DISTRIBUTION is necessary for INTERSECTION rule. INTERSECTION rule states: For positive distributions, and for mutually disjoint sets X, Y, Z, W: (X⊥Y|Z,W)&(X⊥W|Z,Y) ⇒ (X⊥Y,W|Z). (2.11) But according to definition (2.3) in the same book on Page24, the right side of (2.11) is trivially established for some events {y1, w1, z1} which leads P(Y=y1, W=w1, Z=z1)=0, it seems STRICT POSITIVE DISTRIBUTION is not necessary for INTERSECTION rule. Definition (2.3) states: We say that an event a is conditionally independent of event b given event r in P, denoted P ⊨ (a⊥b|r), if P(a|b ∩ r) = P(a|r) or if P(b ∩ r) = 0. So, why the book mentioned the STRICT POSITIVE DISTRIBUTION as necessary for INTERSECTION rule?","['graph-theory', 'bayesian-network', 'conditional-probability', 'independence', 'probability-theory']"
4344411,Can a figure be divided into 2 and 3 but not 6 equal parts?,"Is there a two dimensional shape (living in a plane) that can be divided into $2$ and $3$ but not $6$ equal parts of same size and shape? This question is a simpler take on this puzzling.SE question . If such a shape exists, the $3$ parts can't be symmetric and the $2$ parts can't be divisible into $3$ equal parts. I'm not sure how to formalize this, but I feel that group theory could have a result about this.","['symmetric-groups', 'group-theory', 'dissection', 'geometry']"
4344512,$\mathbb E[ |X| ] < \infty \iff \forall \epsilon : \mathbb E[ |X / \epsilon | ] < \infty$,"$X$ is a random variable. $$ \mathbb E ( | X | ) < \infty \implies \forall \epsilon > 0, \sum_n \mathbb P ( | X | \geq n \epsilon ) < \infty. $$ Any help to prove this? (This amounts to prove that $\mathbb E[ |X| ] < \infty \iff  \forall \epsilon :  \mathbb E[ |X / \epsilon | ] < \infty$ ). ---------------------------------------------------- original post Since I know that $$X \in L^1 \iff \sum \mathbb P ( | X | \geq n) < \infty$$ I was given the hint to try to prove the statement hereinafter: Let us say that $X$ is a random variable. $$\forall \epsilon > 0, \exists K>0, \forall n \in \mathbb N: \mathbb P( X \geq n \epsilon ) \leq K \mathbb P ( X \geq n), $$ is a useful fact that I need in some proof of my probability lecture, however I am quite unsure about how to prove such statement. Any idea? ---------------------------------------------------- comment I guess that the original post is completly wrong because one cannot bound each term (cf. Ian comment), however bounding the whole sum is doable somehow.","['expected-value', 'probability-theory', 'random-variables']"
4344518,Concentration result from Delta method?,"Let $X_1,X_2, \cdots$ be iid random variables with finite second moment.
Let $\bar{X_n} = (1/n)\sum_{i=1}^{n} X_i$ and $\bar{X^2_n} = (1/n)\sum_{i=1}^{n} X_i^2$ . Define $S_n = \bar{X^2_n} - (\bar{X_n})^2$ . From Statistics literature (application of WLLN and continuous-mapping theorem), we know that $$ S_n \rightarrow^P E X_1^2 - (E X_1)^2 = Var(X_1). $$ Question: Can we get a concentration bound? That is, something like for some constant $c>0$ $$ Pr(|S_n - Var(X_1)| \geq \epsilon) \leq e^{-c \epsilon^2} $$ or $$  Pr(|S_n - Var(X_1)| \geq \frac{\sqrt{\log(n)}}{\sqrt{c}} ) \leq \frac{1}{n} ? $$ From this question thread , I am confident that the asymptotic rate is in fact $\sqrt{n}$ from Delta method. But I am not sure how to proceed with for getting a concentration bound. I'll be really grateful for any kind of help to address this!","['concentration-of-measure', 'probability-distributions', 'asymptotics', 'inequality', 'probability-theory']"
4344540,"Definition of Developing Map of $(G,X)$-Manifold in Wikipedia","I was reading Wikipedia about $(G,X)$ -manifolds, and I do not understand well the developing map part. https://en.wikipedia.org/wiki/(G,X)-manifold#Developing_map Here is what Wikipedia says. Let $M$ be a connected $(G,X)$ -manifold, and let $\pi : \tilde{M} \to M$ be the universal covering. A developing map $\varphi : \tilde{M} \to X$ is defined as follows. Fix $p \in \tilde{M}$ . Let $q \in \tilde{M}$ be given. Fix a chart $\varphi : U \to X$ near $p$ . Consider a path $\gamma$ from $p$ to $q$ . We may use analytic continuation along $\gamma$ to extend $\varphi$ so that its domain includes $q$ (maybe $\gamma$ ?). Since $\tilde{M}$ is simply connected, $\varphi(q)$ does not depend on the choice of $\gamma$ . (The monodromy theorem ensures the well-definedness of $\varphi : \tilde{M} \to X$ .) At the step 3, why does the analytic continuation exist? How do we extend $\varphi$ along $\gamma$ ? Thank you.","['manifolds', 'holonomy', 'differential-geometry']"
4344555,Prove that certain subset $M$ of $\mathbb R^4$ is a smooth manifold,"Consider the subset $M\subset\mathbb R^4$ given by the equations: $$M\equiv \left\{\begin{array}{ll}
x^2+y^2-z^2-t^2=1\\
-xt+yz=1
\end{array}\right.$$ Prove that $M$ is a smooth manifold. My idea is to define the smooth map $f:\mathbb R^4\to\mathbb R^2$ given by: $$f(x,y,z,t)=(x^2+y^2-z^2-t^2-1,-xt+yz-1)$$ It is well know that if $J(f)$ has rank $2$ in $M=F^{-1}(0,0)$ then $M$ must be a 2-dimensional smooth manifold. Unfortunately, I am not able to find a regular submatrix of: $$J(f)=\left(\begin{array}{cccc}
2x & 2y&-2z&-2t\\
-t&z&y&-x
\end{array}\right)$$ taking in count that $(x,y,z,t)\in M$ . Any help?","['jacobian', 'submanifold', 'smooth-manifolds', 'differential-geometry']"
4344577,How strong is Sierpiński theorem about continua?,"I've just learned about a theorem by Sierpiński, that a continuum can't be partitioned into countably many non-empty closed sets. Can we partition some continuum into $\aleph_1$ non-empty closed sets without assuming things like the continuum hypothesis?","['general-topology', 'continuum-theory', 'set-theory']"
4344586,Concerning $\kappa+\kappa=\kappa$ for any infinite cardinal $\kappa$,"In Introduction to Set Theory by Hrbacek and Jech, on page 94, the authors state that $\aleph_0+\aleph_0=\aleph_0$ , and the Axiom of Choice implies that $\kappa+\kappa=\kappa$ for any infinite cardinal $\kappa$ . To me, it is clear that $\aleph_0+\aleph_0=\aleph_0$ , as the (disjoint) union of two countable sets is countable, but I am not sure about the latter statement. In particular, I'm not sure how the Axiom of Choice is used. Can someone please explain this to me?","['elementary-set-theory', 'axiom-of-choice', 'cardinals']"
4344616,Does tangent line of inflection point always passes through the curve?,"I saw many functions on my book and all of the tangent line of inflection point always pass through the curve, Here are examples : Example 1 : $$f(x) = x^3 \quad (x=0)$$ Tangent line at $x = 0$ , $l:y=0$ Then we know that $l$ passes through the $f(x)$ . Example 2 : $$f(x)=\sin x\quad (x=0)$$ Tangent line at $x = 0$ , $l: y = x$ We know $l$ passes through the $f(x)$ . I got a curiosity about this, so my question is : Let $f$ is differentiable function and $f$ is not a constant, linear function. If a line $l$ is a tangent line of inflection point, $l$ passes through $f$ near of inflection point? I think this is true, but I have no idea to prove this. Thanks for help.","['calculus', 'functions', 'tangent-line']"
4344624,"$L^1_{\text{loc}}$, Frechet Space and norm-distance","I was talking with a professor of mine, last week, and he started talking about the fact that ""the space $L^1_{\text{loc}}$ is a Frechet Space, and hence you cannot put a norm into it. At most you can put a distance."" Can someone please clarify this passage to me a bit? Maybe with some example?
Or please give me some good reference where to read about those questions too.","['lp-spaces', 'normed-spaces', 'functional-analysis']"
4344635,"Why are 1,0 differential forms $\mathbb C$-linear?","I am struggling to understand a passage from Claire Voisin’s book on Hodge Theory. In page 53, at the beginning of the section 2.3.1, there is the following assertion: “…the bundle $\Omega_X^{1,0}$ of complex differential forms of type 1,0, i.e. $\mathbb C$ -linear forms…” I don’t see why forms of type 1,0 should be C-linear. Maybe I don’t understand correctly what $\Omega_X^{1,0}$ is. To me it is supposed to be $\hom_\mathbb R(T^{1,0}_X, \mathbb C)$ . Am I wrong here?
If not, why is $\hom_\mathbb R(T^{1,0}_X, \mathbb C)$ equal to $\hom_\mathbb C(T^{1,0}_X, \mathbb C)$ ? UPDATE: In Page 64/65 of the same book the author mentions the same result but with vectors spaces instead of vector bundles, and there is explicit that $\hom_\mathbb R (V,\mathbb C)$ splits as a sum of $\mathbb C$ -linear forms and $\mathbb C$ -antilinear forms, that correspond to the forms of type 1,0; 0,1.","['hodge-theory', 'complex-geometry', 'complex-analysis', 'algebraic-geometry', 'linear-algebra']"
4344645,"Finding the normalizer of $\left\{ \left(\begin{matrix} x &0 \\0 & y \end{matrix}\right) : x,y\in \mathbb R\setminus\{0\} \right\}$","I'm having some trouble with the following question: Let $G=\text{GL}_2(\mathbb R)$ . What are the elements of the set: $$N_G \left( \underbrace{\left\{
\left(\begin{matrix} x &0 \\0 & y \end{matrix}\right) : x,y\in \mathbb R\setminus\{0\} \right\}}_S\right)$$ I tried solving this using the fact that if $A = \left(\begin{matrix} a &c \\b & d \end{matrix}\right) \in N_G(S)$ then: $$ASA^{-1} = S$$ And I arrived at the following conditions: $xbd=ycd$ $yac=xba$ $axd \neq yc^2$ $yad \neq xb^2$ Where $x,y \in \mathbb R \setminus \{0\}$ are fixed constants. I'm not being able to find all the values of $(a,b,c,d)$ that follow these conditions and this docent's seem like the best approach to me. Is there a better way to solve this?","['linear-groups', 'matrices', 'abstract-algebra', 'group-theory', 'similar-matrices']"
4344652,"Investigating the recurrence relation $x_{n+1}=\frac{x_{n}+x_{n-1}}{(x_{n},\,x_{n-1})}+1$","Let $x_{n} \in \mathbb Z$ be the $n$ -th term of the recurrence relation $$ x_{n+1} = \frac{x_{n} + x_{n-1}}{(x_{n},x_{n-1})} + 1$$ where $(x_{n},x_{n-1})$ is the gcd of $x_{n}$ and $x_{n-1}$ . Some examples: $1, 1, 3, 5, 9, 15, 9, 9, 3, 5, 9, 15,\dots \qquad $ (periodic sequence) $1, 12, 14, 14, 3, 18, 8, 14, 12, 14, 14, 3, \dots \qquad$ (periodic sequence) $3, 1, 5, 7, 13, 21, 35, 9, 45, 7, 53, 61, 115, 177, 293, 471, 765, 413, \dots \qquad$ (not periodic?) If $x_{0}$ is even or $x_{1}$ is even, the sequence seems to be always periodic: how to prove it? More difficult, I suppose, is to predict the character of the sequence (periodic or not periodic), given its initial values $x_{0}$ and $x_{1}$ . Addendum The recurrence relation $$ x_{n+1} = \frac{x_{n} + x_{n-1}}{(x_{n},x_{n-1})} + 3$$ admits the following periodic sequence (period equal to 81): $2, 5, 10, 6, 11, 20, 34, 30, 35, 16, 54, 38, 49, 90, 142, 119, 264, 386, 328, 360, 89, 452, 544, 252, 202, 230, 219, 452, 674, 566, 623, 1192, 1818, 1508, 1666, 1590, 1631, 3224, 4858, 4044, 4454, 4252, 4356, 2155, 6514, 8672, 7596, 4070, 5836, 4956, 2701, 7660, 10364, 4509, 14876, 19388, 8569, 27960, 36532, 16126, 26332, 21232, 11894, 16566, 14233, 30802, 45038, 37923, 82964, 120890, 14564, 6160, 474, 3320, 1900, 264, 544, 104, 84, 50, 70, 15, 20, 10, 6, 11, 20, \dots$ The recurrence relation $$ x_{n+1} = \frac{x_{n} + x_{n-1}}{(x_{n},x_{n-1})} + 17$$ with $x_0=1$ and $x_1=4$ produces the following periodic sequence (period equal to 422): The recurrence relation $$ x_{n+1} = \frac{x_{n} + x_{n-1}}{(x_{n},x_{n-1})} + 199$$ with $x_0=1$ and $x_1=2$ produces the following periodic sequence (period equal to 2920): I made some numerical experiments. The following screenshots show some of the obtained results. Each image consists of a 20x20 matrix $T(c)$ , depending on the value of $c$ , in which $x_0$ is the row index; $x_1$ is the column index; $t_{\,x_0,\,x_1}(c)$ represents the period of the sequence generated by the recurrence relation starting with the initial conditions $x_0,\,x_1$ (the symbol ""+"" stands for a not periodic sequence that diverges). Results for $\,c=1$ : Results for $\,c=2$ : Results for $\,c=3$ : Results for $\,c=4$ : Results for $\,c=5$ : Here it seems that we have only two possible periods: one of lenght 17, the other of lenght 63. Notice that if we focus on the sequences of period equal to 17 and plot them for the following initial values $(x_0,x_1)=(2,2),\,(3,8),\,(7,12)$ , we obtain the same ""wave form""! I conjecture that this fact is always true. The wave form for the period of lenght 63 is completely different: for $(x_0,x_1)=(3,10)$ we have for $(x_0,x_1)=(13,6)$ we have Results for $\,c=6$ : Results for $\,c=7$ : Results for $\,c=8$ : Results for $\,c=9$ : Results for $\,c=10$ : Results for $\,c=11$ : Results for $\,c=13$ : Results for $\,c=15$ : Results for $\,c=17$ : Results for $\,c=19$ :","['number-theory', 'gcd-and-lcm', 'elementary-number-theory', 'recurrence-relations', 'sequences-and-series']"
4344655,Product measure and its marginals,"I have this question that's bothering me. The answer (I think) should be trivial but I am new in measure theory. Let $m$ be Radon measure on a compact product space $\Omega=X\times X$ such that $m$ is symmetric (I guess this means that $m(dx,dy)=m(dy,dx)$ and let $\lambda$ be a symmetric strictly positive function $\lambda:X\times X \rightarrow \mathbb{R}$ . The question is the following: does it always exist a measure $\mu$ defined on $X$ such that $$\mu(dx)\mu(dy)= c\frac{m(dx,dy)}{\lambda(x,y)},$$ where $c$ is a positive constant?
How do you find it? Is it possible to say that it is a probability measure? My immediate answer would be yes and $$\mu(dx)=\int \frac{m(\cdot,dy)}{\lambda(x,y)}$$ and it is a probability measure just because it can be rescalated (being $X$ a compact set) Am I wrong? If so, can you give me a counterexample? Thanks in advance","['measure-theory', 'probability']"
4344691,Under what conditions does the limit f(g(x)) exist?,"Under what conditions does $$
\lim_{x \to a} f(g(x))
$$ exist? I've seen examples like this from Khan that show you can use one-sided limits and discontinuities to break a lot of expectations around limits and still have an answer: So what's the rule for when this composite limit exists?","['limits', 'calculus', 'continuity']"
4344756,Contradiction with the dimension of shape operator matrix,"Context My question is about the matrix dimension of the shape operator. In order to avoid misunderstanding let $S \subset \mathbb{R}^3$ be a regular surface and $$\psi(u,v)=(x(u,v),y(u,v),z(u,v))$$ be a chart on a open subset $W\subset S$ . So, we have the induced basis of $T_pM$ given by $\left\{\frac{\partial \psi}{\partial u},\frac{\partial \psi}{\partial v}\right\}$ which allow us to define the Gauss map $$p \mapsto N(u,v)=\frac{\frac{\partial \psi}{\partial u}\land \frac{\partial \psi}{\partial v}}{\big\vert\big\vert \frac{\partial \psi}{\partial u}\land \frac{\partial \psi}{\partial v}\big\vert\big\vert}$$ Now we can finally define the shape operator $S:\mathfrak X(W)\rightarrow \mathfrak X(W)$ ; $S(X)=- D_XN$ Question The matrix that represents the linear operator $D_XN$ lies on the space of $3\times 2$ matrices ( here we have a very good derivation about this fact), so by definition of $S$ , its matrix representation should also lies on the space of $3\times 2$ matrices. But at the same time when I'm looking on textbooks I only find that this matrix is a $2\times 2$ matrix whose entries are given by the the one and second fundamental forms coefficients ( here gives the formula I'm talking about and here we have an example). How can I should understand whats going on and how can I interpret this conceptual difference envolved ? Thank you in advance for any hint about this question :)","['surfaces', 'geometry', 'differential-geometry']"
4344760,Is the series $\sum_{n=1}^\infty\frac{1}{n}\left(\sum_{k=1}^n\frac{1}{k}\left(\frac{1}{2}\right)^{n-k}\right)$ convergent?,"$$
\sum_{n = 1}^\infty\dfrac{1}{n}\left(\sum_{k = 1}^n\dfrac{1}{k}\left(\dfrac{1}{2}\right)^{n - k}\right)
$$ Does the series converge? I calculate it using Matlab, and it seems that the sum converges to 2.4673. I also tried to use the ratio test to prove the convergent, but stopped at to calculate the sum $\sum_{k = 1}^n\dfrac{1}{k}(1/2)^{n - k}$ .","['sequences-and-series', 'real-analysis']"
4344790,Local Existence for Heat equation with Lipschitz nonlinearity,"Let's say we have $x\in [0,1]$ and we have the heat equation $$\frac{d}{dt}u(x,t) = \Delta u(x,t) + f(u)$$ with $u(0,t) = u(1,t) = 0$ and $u(x,0)\in L^2$ . $f$ is lipschitz continuous. I want to show local existence of the weak solution in $L^2$ . Here's what I did: $$u(x,t) = S(t)u_0 + \int_0^t S(t-s)f(u)ds$$ is the weak solution where $S(t)$ is the heat semigroup $(u_0 = u(x,0))$ . Define $$\mathcal{K}(v):= S(t)v_0 + \int_0^t S(t-s)f(v)ds$$ Then for $v, w\in L^2$ with $v_0 = w_0$ we consider \begin{align}
\sup_{t\in [0,T]}\left\| \mathcal{K}v - \mathcal{K}w \right\|_2 &= \sup_{t\in [0,T]}\left\|\int_0^T S(t-s)[f(v)-f(w)]\,ds\right\|_2\\
&\leq \sup_{t\in [0,T]}\int_0^T\left\|S(t-s)[f(v)-f(w)]\right\|_2\,ds\\
&\leq \sup_{t\in [0,T]}\int_0^T e^{-\omega_1(t-s)}C\left\|v-w\right\|_2 \,ds\\
&\leq T*1*C*\sup_{t\in [0,T]}\left\|v-w\right\|_2.
\end{align} In the last two steps, $C$ is the Lipschitz constant for $f$ and $\omega_1$ is the principal eigenvalue of the Laplace operator. Pick $T$ small enough and we have a contraction mapping, so that implies the existence of a local solution.  Does this argument work? Can I tweak it slightly to also work for $f$ locally Lipschitz?  I was thinking for the locally Lipschitz case of maybe considering the ball in $L^2$ of radius $M$ , and only choosing $v$ and $w$ in that ball.","['heat-equation', 'contraction-operator', 'ordinary-differential-equations', 'partial-differential-equations']"
4344820,"Maximiser of $W_1(\mu, \nu)$ can be changed outside of $\text{conv}(\text{supp}(\mu) \cap \text{supp}(\nu))$ (under additional assumptions)","Let $(X, \| \cdot \|)$ be a reflexive Banach space and $\mathbb{P}_n$ , $\mathbb{P}_r$ be measures on $X$ .
Let the support of $\mathbb{P}_r$ , $M := \text{supp}(\mathbb{P}_r)$ be a weakly compact set and $$P_M \colon D \to M, \qquad x \mapsto \text{argmin}_{y \in M} \| x - y \|$$ be the projection onto $M$ and $D \subset X$ the set of points for which the projection is unique (and thus the map $P_M$ is well-defined).
Assume further that $\mathbb{P}_n(D) = 1$ and $(P_M)_{\#} \mathbb{P}_n = \mathbb{P}_r$ . (As $M$ is weakly compact, the projection always exists, but it need not be unique, as $M$ need not be convex.) The Wasserstein-1 distance for measures is $$
W_1(\mathbb{P}_r, \mathbb{P}_n)
= \sup_{f \in 1\text{-Lip}} \int_{X} f(x) \; \text{d}(\mathbb{P}_n - \mathbb{P}_r)(x),
$$ where $1$ -Lip denotes the set of 1-Lipschitz-continuous functions $f \colon X \to \mathbb{R}$ . Remark 2 in the paper Adversarial Regularizers in Inverse Problems by Lunz et al. states that the maximiser $f$ in the above formula is not unique: it can be changed to an arbitrary 1-Lipschitz function outside of $\text{conv}(\text{supp}(\mathbb{P}_r) \cap \text{supp}(\mathbb{P}_n))$ . But the statement is wrong (see below) but does somebody know what could be meant instead? If we replace the $\cap$ by a $\cup$ do we even need the convex hull anymore? Counterexample (thanks to @MaoWao) But taking $X = \mathbb{R}$ and $\mathbb{P}_r := \delta_0$ we have $M = \text{supp}(\mathbb{P}_r) = \{ 0 \}$ , which is weakly compact and the projection is $$
P_M \colon \mathbb{R} \to \{ 0 \}, \qquad
x \mapsto 0.
$$ Choosing $\mathbb{P}_n := \delta_1$ , we have $\text{supp}(\mathbb{P}_n) \cap \text{supp}(\mathbb{P}_r) = \emptyset$ .
Furthermore, for any measurable set $A \subset \mathbb{R}$ we have $$
\mathbb{P}_n(P_M^{-1}(A))
= \begin{cases}
\mathbb{P}_n(\emptyset) = 0, & \text{if } 0 \notin A, \\
\mathbb{P}_n(\mathbb{R}) = 1,& \text{if } 0 \in A.
\end{cases}
= \mathbb{P}_r(A),
$$ so $(P_M)_{\#} \mathbb{P}_n = \mathbb{P}_r$ .
But $$
W_1(\mathbb{P}_r, \mathbb{P}_n)
= \sup_{f \in 1\text{-Lip}} f(1) - f(0) 
= 1
$$ for e.g. $f(x) = x$ .
But if we are allowed to change $f$ to on the complement of $\emptyset$ , that is, anywhere, (such that it remains 1-Lipschitz) we can instead consider $\tilde{f}(x) = - x$ , for which the objective function takes the value $- 1 \ne 1$ .","['measure-theory', 'convex-optimization', 'optimal-transport', 'optimization', 'wasserstein']"
4344823,Exterior tensor product of structure sheaves,"I am reading the book ""Fourier-Mukai transforms in algebraic geometry"" by Daniel Huybrechts and to solve one of its questions, I came up to show that $$\mathcal{O}_{X_1}\boxtimes\mathcal{O}_{X_2}=\mathcal{O}_{X_1\times X_2}$$ i.e. $${\pi_{X_1}}^*\mathcal{O}_{X_1}\otimes{\pi_{X_2}}^*\mathcal{O}_{X_2}=\mathcal{O}_{X_1\times X_2}$$ where here $\pi_{X_1}$ (resp. $\pi_{X_2}$ ) is the projection from $X_1\times X_2\to X_1$ (resp. $X_1\times X_2\to X_2$ ) and I am looking at $\mathcal{O}_{X_1}$ , $\mathcal{O}_{X_2}$ and $\mathcal{O}_{X_1\times X_2}$ as objects in $D^b(X_1)$ , $D^b(X_2)$ and $D^b(X_1\times X_2)$ , respectively. My question is that is this equality true and if yes, why?","['derived-categories', 'algebraic-geometry']"
4344852,Can the Noetherian topological spaces be distinguished by looking at the category of topological spaces only?,"A Noetherian topological space is one where every infinite descending sequence of closed sets $X_0 \supset X_1 \supset X_2 \cdots$ is eventually constant (paraphrased from Hartshorne page 5). Assessing the Noetherianness of a given space $(X, \tau)$ using this definition, though, requires us to peer inside and look at $\tau$ specifically. I'm curious whether we can identify which topological spaces are Noetherian by examining just the categorical structure of $\mathsf{Top}$ . I don't know very much about category theory or topology; the following is just an idea I had about how one might answer this. I can sort of see the extremely vague beginnings of an argument where we look at ascending chains of open sets $B_0 \subset B_1 \cdots$ and we note that each open set can be thought of as a topological space $(B_i, \{z \cap B_i : z \in \tau\})$ ... and then we can talk about ascending chains of topological spaces that are subspaces of the original space $(X, \tau)$ . I think the language of category theory gives me enough tools to talk about being a subspace, since I can talk about whether morphisms compose to the identity morphism and therefore I can talk about an inclusion map. However, I don't know enough about category theory to know whether this idea will eventually succeed or whether it's inconsistent with the spirit of ""examining a property of an individual thing by looking at the category it's in"". Also, there might be a simpler way to characterize Noetherianness categorically.","['general-topology', 'category-theory', 'noetherian']"
4344860,Rotman's Algebraic Topology Theorem 8.24,"I'm trying to understand the proof of Theorem 8.24 of Rotman's Introduction to Algebraic Topology. Two steps in his proof don't seem very obvious to me: (blue highlight) Why do we need the ""X is Hausdorff"" statement to show that $\bar{e} = \Phi^n_{\alpha}(D^n)$ for some $\alpha$ ? (green highlight) The inductive hypothesis says that $X^{n-1}$ has a weak topology determined by $\{\bar{e}: dim(e) \leq n-1\}$ , but I am not sure how I can proceed onward by applying Lemma 8.16. Thanks everyone in advance! Here is the main theorem: and here is his proof: Lemma 8.15: Lemma 8.16:","['abstract-algebra', 'algebraic-topology']"
4344863,Each atom of the measure μ is equivalent to a singleton.,"I am trying to prove the following theorem from A Course in Functional Analysis and
Measure Theory by Kadets: Theorem: Suppose $X$ is a separable metric space, the $\sigma$ -algebra $\mathscr{A}$ contains all
the Borel sets, and $\mu$ is a countably additive measure on $\mathscr{A}$ . Then each atom of the measure $\mu$ is equivalent to a singleton. That it is equivalent to a singleton means that there exists $x\in X$ such that $\mu(A\triangle \{x\}) = 0$ Under this, since $A$ is an atom and $A\setminus {x}\subseteq A$ then $\mu(A\setminus \{x\}) = 0$ ,and ${x}\setminus A \subseteq \{x\}$ then $\mu(\{x\}\setminus A) = 0$ . This proves that they are equivalent Sounds like no to me, but does this prove the theorem? If not, can you help me?","['proof-explanation', 'measure-theory', 'solution-verification', 'probability-theory']"
4344864,"How far can I go with the integral $\int \frac{\sin ^{n} x \cos ^{n} x}{1-\sin x \cos x} d x, $ where $n\in N$?","Latest Edit By the aid of my recent post , a closed form for its definite integral is obtained as below: $$
\int_{0}^{\frac{\pi}{2}} \sin ^{k} \theta d \theta= \frac{\sqrt{\pi} \Gamma\left(\frac{k+1}{2}\right)}{k \Gamma\left(\frac{k}{2}\right)}
$$ Hence \begin{aligned}
\int_{0}^{\frac{\pi}{2}} \frac{\sin ^{n} x \cos ^{n} x}{1-\sin x \cos x} d x&=\frac{2}{\sqrt{3}}\left[\tan ^{-1}\left(\frac{2 \tan x-1}{\sqrt{3}}\right)-x\right]_{0}^{\frac{\pi}{2}} -\sum_{k=1}^{n-1} \frac{1}{2^{k}} \cdot \frac{\sqrt{\pi} \Gamma\left(\frac{k+1}{2}\right)}{k \Gamma\left(\frac{k}{2}\right)}\\&=\frac{\pi}{3\sqrt3}- \sum_{k=1}^{n-1} \frac{1}{2^{k}} \cdot \frac{\sqrt{\pi} \Gamma\left(\frac{k+1}{2}\right)}{k \Gamma\left(\frac{k}{2}\right)}
\end{aligned} In my answer , I have found the integral $$\int \frac{d x}{1-\sin x \cos x} =\frac{2}{\sqrt{3}} \tan ^{-1}\left(\frac{2 \tan x-1}{\sqrt{3}}\right)+C_0 
$$ Next, $$
\begin{aligned}
& \int \frac{\sin x \cos x}{1-\sin x \cos x} d x \\
=& \int \frac{d x}{1-\sin x \cos x}-\int 1 d x \\
=& \frac{2}{\sqrt{3}} \tan ^{-1}\left(\frac{2 \tan x-1}{\sqrt{3}}\right)-x+C_{1}
\end{aligned}
$$ and $$
\begin{aligned}
& \int \frac{\sin ^{2} x \cos ^{2} x}{1-\sin x \cos x} d x \\
=& \int \frac{1-\left(1-\sin ^{2} x \cos ^{2} x\right)}{1-\sin x \cos x} d x
\\
=& \int \frac{d x}{1-\sin x \cos x}-\int(1+\sin x \cos x) d x \\
=& \frac{2}{\sqrt{3}} \tan ^{-1}\left(\frac{2 \tan x-1}{\sqrt{3}}\right)-x+\frac{\cos 2 x}{4}+C_2
\end{aligned}
$$ Now I want to go further, $$
\begin{aligned}
& \int \frac{\sin ^{3} x \cos ^{3} x}{1-\sin x \cos x} d x \\
=& \int \frac{1-\left(1-\sin ^{3} x \cos ^{3} x\right)}{1-\sin x \cos x} d x \\
=& \int \frac{d x}{1-\sin x \cos x}-\int\left(1+\sin x \cos x+\sin ^{2} x \cos ^{2} x\right) d x \\
=& \frac{2}{\sqrt{3}} \tan ^{-1}\left(\frac{2 \tan x-1}{\sqrt{3}}\right)-x+\frac{\cos 2 x}{4}-\int \frac{\sin ^{2} 2 x}{4} d x \\
=& \frac{2}{\sqrt{3}} \tan ^{-1}\left(\frac{2 \tan x-1}{\sqrt{3}}\right)-x+\frac{\cos 2 x}{4}-\frac{1}{4}\int\frac{1-\cos 4 x}{2} d x\\
=& \frac{2}{\sqrt{3}} \tan ^{-1}\left(\frac{2 \tan x-1}{\sqrt{3}}\right)-x+\frac{\cos 2 x}{4}-\frac{1}{8}\left(x-\frac{\sin 4 x}{4}\right) +C\\=& \frac{2}{\sqrt{3}} \tan ^{-1}\left(\frac{2 \tan x-1}{\sqrt{3}}\right)-\frac{9}{8}  x+\frac{\cos 2 x}{4}+\frac{\sin 4 x}{32} +C_3
\end{aligned}
$$ Then I discovered that the integral $$
I(n)=\int \frac{\sin ^{n} x \cos ^{n} x}{1-\sin x \cos x} d x
$$ has a telescoping series $$I(k+1)-I(k)=-\int \sin ^{k} x \cos ^{k} x d x$$ Hence $$
I(n)-I(1)=-\sum_{k=1}^{n-1} \frac{1}{2^{k}} \int\sin ^{k}(2 x) d x
$$ We can conclude that $$
I(n)=\frac{2}{\sqrt{3}} \tan ^{-1}\left(\frac{2 \tan x-1}{\sqrt{3}}\right)-x-\sum_{k=1}^{n-1} \frac{1}{2^{k}}\int\sin ^{k}(2 x) d x
$$ Then I was stuck with the last sum . My question is whether we can find a closed form for the last sum.","['integration', 'trigonometry']"
4344872,Proving Renyi's result on the order statistics of the exponential distribution,"The Wikipedia article on order statistics mentions the following result on the order statistics of an exponential distribution with rate parameter, $\lambda$ : $$X_{(i)} = \frac{1}{\lambda}\sum\limits_{j=1}^i \frac{Z_j}{n-j+1} \tag{1}$$ It provides no proof of this. How do I prove it? My attempt: We know that to get X_{(i)} for a distribution with inverse CDF $F_X^{-1}(x)$ , we first get the corresponding order statistic of the uniform ( $U_{(i)}$ ) and then apply the inverse CDF to it. We know that $U_{(i)} \sim B(i,n-i+1)$ . And the inverse CDF of the exponential distribution is: $F_X^{-1}(x) = -\frac{\log(1-x)}{\lambda}$ . This means that the distribution of $X_{(i)}$ should be: $-\frac{\log(1-U_{(i)})}{\lambda}$ Also, $1-U_{(i)} \sim U_{(n-i)}$ . So, the distribution of the order statistic becomes: $$X_{(i)}\sim -\frac{\log(U_{(n-i)})}{\lambda}$$ We have a Beta inside a logarithm. Don't see a path to equation (1) except maybe expressing the Beta as a Gamma and then noting that the Gamma is a sum of exponentials?","['beta-function', 'exponential-distribution', 'probability']"
4344878,A proof of $|\mathbb{N}| = |\mathbb{N} \times \mathbb{N}|$,"$\newcommand{\N}{\mathbb{N}}$ There are various versions of proof of 'there is a bijection from $\N$ to $\N \times \N$ .' But only one of them suits my taste: Make a list $$
\begin{aligned}
&(1,1),\\
&(1,2), (2,1)\\
&(1,3), (2,2),...
\end{aligned}
$$ and index them by $\N = \{1,2,\cdots\}$ . The sum of the elements of each pair equals the index of the corresponding layer plus $1$ . It provides the key idea, but I feel I need to explicitly show that it really works. Please check if the followings are valid. First, let us restrict the domain of discourse to natural numbers. I defined a function $f: \N \to \N^2$ with $$
\forall m :\forall n \le m:f\left(\frac{(m-1)m}{2} + n\right) = (n,m-n+1)
$$ where $m$ is the index for each layer of the list and $n$ is the column index. $(m-1)m/2$ can be thought of as the accumulated number of elements from the first layer and the layer $m-1$ . Now, we have to show $f$ is bijective. (surjective) I am going to show that $\forall a, b: \exists k:f(k) = (a,b)$ . Let $n = a$ , and $m-n+1 = b$ . Then, $$
m = n + b - 1 \ge n
$$ Letting $ k = (a + b - 2)(a + b - 1)/2 + a$ shows $f$ is subjective. (uniqueness of $m$ and $n$ for each argument $k$ of $f$ ) First, we show that $$
\forall k: \exists!m,n: \left(n \le m \land k = \frac{(m-1)m}{2} + n\right)
$$ It is easy to show that $$
\left\{\left.\left(\frac{(m-1)m}{2}\right.,\left.\frac{m(m+1)}{2}\right]\cap\N ~\right|~m\in\N \right\}
$$ partitions $\N$ . Therefore, for arbitrary $k$ , there is unique $m$ such that $$
\frac{(m-1)m}{2} < k \le \frac{m(m+1)}{2}
\text{ or equivalently, }
0 < k - \frac{(m-1)m}{2} \le m
$$ Using the result, let $n = k - {(m-1)m}/{2} $ . (injective) It follows from 2) that for each $a, b \in \N$ there is unique $k$ such that $f(k) = (a,b)$ . The proof is a lot verbose, but I could be content only with such details.","['elementary-set-theory', 'solution-verification']"
4344908,"If $B-A=ww^{\top}$ for symmetric and orthogonal matrices $A$ and $B$, how to show that $w$ has two nonzero entries?","Suppose that $A$ and $B$ are binary square matrices of same dimension and that $A=A^{\top}=A^{-1}$ (same for $B$ ), i.e. they are symmetric and orthogonal. In addition, suppose $\text{rank}(B-A)=1$ so that $B-A=uv^{\top}$ for nonzero vectors $u$ and $v$ . I want to show that $B-A$ has the form $ww^{\top}$ , where $w$ is a column vector with only two nonzero entries whose values are $\pm 1$ . Since $B-A$ is symmetric (can be easily verified), then $B-A=ww^{\top}$ for some nonzero vector $w$ . I know this part follows because the row space and column space of $B-A$ are the same, but I didn't think yet how to prove it rigorously. Since $w$ is nonzero, some entry of $w$ , say $w_i$ , is not zero. Now, let $e_i$ be a column vector such that the $i$ -th entry is $1$ and is the only nonzero entry. Then: $$
e_i^{\top}(B-A)e_i=e_i^{\top}(ww^{\top})e_i=(e_i^{\top}w)(w^{\top}e_i)=w_i^2,
$$ where $w_i$ is the $i$ -th nonzero entry of $w$ . Since the entries of $B-A$ are in $\{-1,0,1\}$ because $A$ and $B$ are binary and $w_i \neq 0$ , then $w_i^2=1$ , which implies $w_i=\pm 1$ . With the above reasoning, I know that the nonzero entries of $w$ are either $-1$ or $1$ . Now, I just need to figure out how to prove that there are only two of these nonzero entries. If I could show that $w^{\top}w=2$ , I'd know that there are only two nonzero entries, although I'd not be able to tell their sign. But it'd be a start. I don't expect to get a complete solution from you (although this'd be nice). I just need some insight from more experienced people in linear algebra to go forward. Would you be able to give me some directions to follow? Maybe some properties of $B-A$ that I'm not seeing?","['matrices', 'orthogonal-matrices', 'linear-algebra', 'symmetric-matrices']"
4344959,Show convergence of measure of a sequence of sets,"Let $\lambda$ denote the Lebesgue measure on $\mathcal B(\mathbb R)$ and $(E,\mathcal E,\alpha)$ be a measure space. Moreover, let $B\in\mathcal B(\mathbb R)\otimes\mathcal E$ and $$\lambda_{s,\:t}:=(\lambda\otimes\alpha)(B\cap((s,t]\times E))$$ for $t\ge s\ge0$ . Let $T>0$ . Are we able to show that $$\sum_{i=1}^{kT}\left[1-\left(1+\lambda_{\frac{i-1}k,\:\frac ik}\right)e^{-\lambda_{\frac{i-1}k,\:\frac ik}}\right]\xrightarrow{k\to\infty}0?\tag2$$ We've clearly got $$\lim_{x\to0}\frac{1-(1+x)e^{-x}}x=\lim_{x\to0}xe^{-x}=0\tag3,$$ but the situation in $(2)$ is slightly different. Using $(1)$ , we have $$1-\left(1+\lambda_{\frac{i-1}k,\:\frac ik}\right)e^{-\lambda_{\frac{i-1}k,\:\frac ik}}\le1-\left(1+\lambda_{\frac{i-1}k,\:\frac ik}\right)e^{-\frac\alpha k}\tag4,$$ but this is obviously not sharp enough (just consider $B=\emptyset$ ). Note that the claim is easy to establish (using $(3)$ ) when $B$ is of the form $B=\mathbb R\times A$ for some $A\in\mathcal E$ .","['measure-theory', 'exponential-function', 'real-analysis']"
4344971,Which trigonometric polynomials are identically zero?,"There are a number of elementary polynomial relations between functions of the form $\cos(nθ)$ and $\sin(nθ)$ . For instance, $\cos^{2}(nθ) + \sin^{2}(nθ) - 1 = 0$ , or $\sin(2nθ)-2\sin(nθ)\cos(nθ) = 0$ . Such identities can be thought of as polynomials in $\cos(θ), \sin(θ), \cos(2θ), \sin(2θ), ...$ Is there a neat enumeration of all (or many) such polynomials? In other words, which trigonometric polynomials are identically zero?","['trigonometry', 'polynomials']"
4344974,We call a coloring of $3$-regular graph with $3$ colors good if for every $3$ edges incident with a vertex ...,"Let $G$ be a $3$ -regular graph with $n$ vertices. Color each edge with red, blue or yellow. Now, we call a coloring of graph as good if any three edges incident with any vertex have one color or three colors. Prove that the number of good coloring of $G$ must be a power of $3$ . I have very short solution using linear algebra: If $M$ is an incidence matrix of this graph and we color each edge with colors $0,1,2$ then we have to find a number of vectors $\vec{c}\in \mathbb{Z}_3^{\varepsilon}$ such that $M\vec{c} =\vec{0} \in \mathbb{Z}_3^{n}$ where $\varepsilon$ is a number of edges $G$ . So we are interested in $|\ker(M)|$ , but $\ker(M)\leq  \mathbb{Z}_3^{\varepsilon}$ and thus $|\ker(M)| = 3^{d}$ where $d=\dim (\ker(M))$ . Even more, we can find exact number of colorings. By handshake lemma we have $\varepsilon = 3n/2$ so $n$ is even and by
 rank-nullity theorem we have $$ d=\varepsilon -{\rm rank} (M) $$ There is a theorem that says if $G$ is connected then: $${\rm rank}(M)=\cases{n-1;\;{\rm if\;}G\;{\rm is\;bipartite}\\ \;\;n\;\;\;\;;\;{\rm else}}$$ So $d={n\over 2}+1$ if $G$ is bipartite and $d={n\over 2}$ else. Clearly we can extend this results to all graphs, not just connected. But I'm unable to get an elementary solution.","['contest-math', 'coloring', 'graph-theory', 'linear-algebra', 'combinatorics']"
4344985,"Prove that if $\mathcal{O}$ is open, then the interior of $\bar{\mathcal{O}} - \mathcal{O}$ is empty","I am trying to show the following: Let $\mathcal{O}$ be an open subset of a metric space $X$ . Show that $\text{int} \, (\bar{\mathcal{O}} - \mathcal{O}) = \emptyset$ . Here, for $E \subset X$ , $\text{int} \, E$ denotes the interior of a set and $\bar{E}$ denotes its closure in $X$ . My attempt: For the sake of contradiction, suppose $\bar{\mathcal{O}} - \mathcal{O}$ has non-empty interior, so there is $x \in \text{int} \, (\bar{\mathcal{O}} - \mathcal{O})$ . This means there is $r > 0$ such that $B(x, r) \subset \bar{\mathcal{O}} - \mathcal{O}$ . However, since $x$ is a point of closure of $\mathcal{O}$ , for every $t > 0$ , $B(x, t) \cap \mathcal{O} \neq \emptyset$ . This contradicts with $B(x, r) \subset \bar{\mathcal{O}} - \mathcal{O}$ . Hence $\text{int} \, (\bar{\mathcal{O}} - \mathcal{O})$ is empty. $\blacksquare$ The problem I have with my attempt is that the assumption of $\mathcal{O}$ being open is not used. The argument seems to work for any subset of $X$ , or in other words, it suggests that if $E$ is any subset of $X$ , then $\text{int} \, (\bar{E} - E) = \emptyset$ . I do not think this is true, but I have not came up with a counter-example to debunk it. Please help by: spotting any mistakes in my attempt; answering the question "" for $E \subset X$ , does $\text{int} \, (\bar{E} - E) = \emptyset$ holds for all $E \subset X$ ""? Any help is appreciated. Here are the definitions I used: For $E \subset X$ , $x \in X$ and $r > 0$ , $B(x, r)$ : open ball centered at $x$ with radius $r$ . $\text{int} \, E$ : interior of $E$ , the points in $E$ which there is an open ball centered at $x$ covered by $E$ , i.e. $$
  \text{int} \, E = \{ x \in E : \exists r > 0 \, , B(x, r) \subset E \} \ .
$$ $\bar{E}$ : closure of $E$ , the points in $X$ which every open set containing $x$ also contains a point in $E$ , i.e. $$
  \bar{E} = \{ x \in X: \forall \text{ open set } O \subset X \text{ such that }x \in O \, , O \cap E \neq \emptyset\} \ .
$$","['general-topology', 'metric-spaces']"
4345049,What is the smallest number of roads in a country?,"There are $300$ cities in the country. Some pairs of them are
connected by roads. It turned out that if you close any $150$ cities,
then there will be at least $150$ roads. What is the smallest number
of roads in a country? My solution : We take a graph with $2n$ vertices such that each $n$ -vertex subgraph of it contains at least $n$ edges. Let us sum this number over all possible $n$ -vertex subgraphs. The resulting number will be greater or equal to $nC_{2 n}^{n}$ . Note that for each edge there are exactly $C_{2 n-2}^{n-2}$ $n$ -vertex subgraphs containing it. So each existing edge appears in the sum exactly $C_{2 n-2}^{n-2}$ times. Thus, the number of roads (edges of the original graph) is greater than or equal to $\dfrac{2 n(2n-1)}{n-1}$ . Therefore, the answer is $603$ . However, this is an estimate, but is there an example of such a graph with $300$ vertices? For $4$ vertices this is an impossible situation (one cannot draw $2$ edges between $2$ vertices). For $6$ vertices, the inequality will exactly give the number of edges in the complete graph. For $8$ , the inequality will give: ( $⩾8\cdot7/3=18.6666$ ). I think we can try to build a graph with $8$ vertices and $19$ edges that satisfies the properties that any $4$ -vertex subgraph has at least $4$ edges. But how to do this is another question. Any ideas?","['graph-theory', 'extremal-graph-theory', 'discrete-mathematics']"
4345065,Why is the space of differential forms $\bigoplus_{p=0}^n \Lambda_x^p$?,"In Wald's book ""General Relativity"", the space $\Lambda_x$ of differential forms at a point $x$ is worked out in the following manner: Let $M$ be an $n$ -dimensional manifold. The vector space of all $p$ -forms at a point $x \in M$ is given by $\Lambda_x^p$ . The vector space $\Lambda_x$ of all differential forms (not limited to a specified degree $p$ ) is given by the direct sum: $$
\Lambda_x =\bigoplus_{p=0}^n \Lambda_x^p
$$ However, from my understanding, the direct sum $A \oplus B$ of two spaces $A$ and $B$ consists of all ordered pairs $(a,b)$ where $a \in A$ and $b \in B$ , with the additional structure: $$(a_1, b_1) + (a_2, b_2) = (a_1 + a_2, b_1 + b_2)$$ Wouldn't this mean that an element from $\omega \in \Lambda_x$ would take the form: $$
\omega = (\omega_1, \omega_2, \dots , \omega_n)
$$ where $\omega_1$ is a 1-form, $\omega_2$ a 2-form, and so on? This to me doesn't seem to be the space of all differential forms at $x$ , unless all $\omega_i$ are 0 except one for each $\omega$ . In fact, it seems to be a much larger space, since it can contain multiple differential forms of different degrees. My first guess was that a $p$ -form and a $q$ -form would be combined via the map $ \bigwedge: \Lambda^p_x \times \Lambda^q_x \mapsto \Lambda^{p+q}_x $ , but then we are no longer limited to the degree $n$ . Why is this written as a direct sum rather than, for example, a union? $$
\Lambda_x = \bigcup_{p=0}^n \Lambda_x^p
$$","['direct-sum', 'differential-forms', 'differential-geometry']"
4345094,Uniqueness of non-autonomous ODE,"From Picard-Lindelöf Theorem it is well known that, roughly speaking, an ODE $\dot x= f(x)$ , with continously differentiable or Lipschitz continous right-hand side (RHS) has a unique solution (in some interval). What I struggle with is the following: For a given non-autonomous RHS $f(x,d)$ , e.g. $f=d(t)x^2+1$ with continous function $d(\cdot)$ , I can locally obtain the following: $|f(x,d)-f(y,d)|\leq L |d(t)||x-y|$ .Is the assertion about uniqueness of the solution still valid for a non-uniform Lipschitz constant $L d$ ?","['functional-analysis', 'ordinary-differential-equations']"
4345095,Some (potentially) really simple algebra I can't figure out,"Okay so, I couldn't be more specific in the title because honestly I can't make it fit in a way that makes sense. We've been told that: $$A + B = C + D \tag{1}$$ and $$ik_1A - ik_1B = ik_2C-ik_2D  \tag{2}$$ I'm trying to show that: $$\frac{A+B}{A-B} = \frac{k_1}{k_2}\frac{C+D}{C-D} = \frac{k_1^2}{k_2^2} $$ So basically I've rearranged equation $(2)$ to show that $$ A-B=\frac{k_2}{k_1}(C-D) $$ and so we can take equation $(1)$ , divide both sides by $A-B$ and then substitute in the expression for $A-B$ we just found, at which point we get $$ \frac{A+B}{A-B} = \frac{C+D}{A-B} = \frac{k_1}{k_2}\frac{C+D}{C-D} \\$$ This is where I hit a dead end. I can show that $\dfrac{k_1}{k_2} = \dfrac{C-D}{A-B},\quad$ but I can't  show $\quad\dfrac{C+D}{C-D}
= \dfrac{k_1}{k_2}$ (which would give me the last part) and honestly I've been banging my head against this all morning and just making more of a mess. Can someone nudge me and put me out of my misery? This isn't even a real part of the question it's like the preamble bit 🤔 (The question overall is to do with tunnelling and scattering in Quantum Mechanics)",['algebra-precalculus']
4345152,$k=1$ instantons on $S^4$,"In the book Instantons and four-manifolds written by Uhlenbeck and Freedman, they say that: We identify $\mathbb{R}^8$ as $\mathbb{H}^2$ with the standard inner product of $\mathbb{R}^8$ , suppose $(q_1,q_2) \in S^7$ ,here $q_i$ lie in $\mathbb{H}$ satisfied $|q_1|^2+|q_2|^2=1$ . Then $S^7 \to S^4:(q_1,q_2)\to [q1,q2]\in \mathbb{HP}\cong S^4$ defines a principal bundle with fiber $\mathrm{SU}(2)$ . If
we view $\mathfrak{su}(2)$ as $\mathrm{Im}\mathbb{H}$ , then we can define connection form as $\omega:\mathrm{Im}(q_1d\bar{q}_1+q_2d\bar{q}_2)$ with vertical
part $(gq_1,gq_2)$ , here $g \in \mathrm{SU(2)}$ . I find that I can not check the property that $\mathrm{Im}(q_1d\bar{q}_1+q_2d\bar{q}_2)$ is identity on the vertical direction. I try to write vertical vector as $(\frac{d}{dt}g(t)q_1,\frac{d}{dt}g(t)q_2)$ but I have no idea to do more calculate, maybe I miss something fundamental. For the second part of my question, consider the scaling map $\omega:\lambda:\mathbb{H} \to \mathbb{H}:x \to \lambda x$ , here $\lambda$ a positive real number and a section $\mu$ on $\mathbb{H} \subseteq S^4 \cong \mathbb{HP}$ , in coordinate is $[x,1]$ .We pullback $\mathrm{Im}(q_1d\bar{q}_1+q_2d\bar{q}_2)$ by $\mu$ and obtain a connection $\mathrm{Im}(\frac{xd\bar{x}}{1+|x|^2})$ on $\mathbb{H}$ . And the pullback connection $\mu^*\lambda^*\omega$ can be read as $\mathrm{Im}\frac{xd\bar{x}}{\lambda^2+|x|^2}$ (Why?). Since $\lambda$ not a map from $S^7$ to $S^7$ , I think here they mean that pullback $\omega$ by the bundle map induced by $\lambda$ . The map $\lambda:\mathbb{H}\to \mathbb{H}:x \to \lambda x$ and we can view it inside $\mathbb{HP}:[x,1] \to [\lambda x,1]$ , this map induces the bundle map $S^7 \to S^7:(q_1,q_2)\to (\frac{\lambda q_1}{((\lambda q_1)^2+q_2^2)^{\frac{1}{2}}},\frac{q_2}{((\lambda q_1)^2+q_2^2)^{\frac{1}{2}}})$ .
Now for any tangent vector in $T_{(q_1,q_2)}P$ , $\lambda^*\omega|_{(q_1,q_2)}(v)=\omega|_{(\frac{\lambda q_1}{((\lambda q_1)^2+q_2^2)^{\frac{1}{2}}},\frac{q_2}{((\lambda q_1)^2+q_2^2)^{\frac{1}{2}}})}(\lambda_* v)=\mathrm{Im}\frac{\lambda q_1}{((\lambda q_1)^2+q_2^2)^{\frac{1}{2}}}d\bar{\frac{\lambda q_1}{((\lambda q_1)^2+q_2^2)^{\frac{1}{2}}}}+\frac{q_2}{((\lambda q_1)^2+q_2^2)^{\frac{1}{2}}} d\bar{\frac{q_2}{((\lambda q_1)^2+q_2^2)^{\frac{1}{2}}}}(\lambda_* v)$ . But it's too complicated to compute, I think I must
get in a wrong way.","['gauge-theory', 'differential-geometry']"
4345157,Every closed set is a boundary [duplicate],"This question already has answers here : Closed set $F$ is the boundary of any subset of $\mathbb{R}^n$ (4 answers) Closed 2 years ago . Prove/Disprove : for all closed $S\subseteq\mathbb{R}^n$ , there exists some $A\subseteq\mathbb{R}^n$ s.t $$\partial A=S$$ I've tried defining $$A=\partial S\uplus\left(\mathbb{Q}^{n}\cap\text{int}(S)\right)$$ because intuitively it feels to me like it would satisfy the equality, but i did not succeed in proving that $\partial A=S$ .","['real-numbers', 'general-topology', 'metric-spaces']"
4345194,"Let $X, Y$ be vector fields on a manifold $M$. Show, that $XY$ is not a vector field","Let $X, Y$ be vector fields on a manifold $M$ . Show, that $XY$ is not a vector field My attempt My idea would be to directly show, that $$XY (fg) \neq (XY f)g + f(XY g) \quad \lor \quad XY (\alpha f + \beta g) \neq \alpha XY f + \beta XY g$$ I am not sure at writing out $XY (fg)$ $$XY (fg) = X ( Y (fg)) = X ((Yf)g + f(Yg)) = X((Yf)g) + X(f(Yg)) = $$ $$ = (X (Y f))g + (Yf)Xg + (Xf)(Yg) + f (X(Yg)) = (XYf)g + (Yf)Xg + (Xf)Yg + f(XYg)$$ So we get an additional $(Yf)Xg + (Xf)Yg$ , thus $XY (fg) \neq (XY f)g + f(XY g)$ Which is enough to show that $XY$ is not a vector field. Are my calculations alright? I'm not sure especially because at the end, I simply ignore the brackets i.e. $(X(Yf))g$ becomes $(XYf)g$ so it can fit into our first assumption. I don't know if we can do that","['manifolds', 'vector-fields', 'differential-geometry']"
4345228,"Given $T_2((0,0),(h_1,h_2))=1+2h_1^2-3h_2^2$ and $g_h(t)=f(th),$ what are possible values of $g_h'(0)$ and $g_h''(0)$?","Let $f:\Bbb R^2\to\Bbb R$ be a function of the class $C^2$ whose Taylor polynomial of degree $2$ at $(0,0)$ is given by $$T_2((0,0),(h_1,h_2))=1+2h_1^2-3h_2^2.$$ For a unit vector $h\in\Bbb R^2$ define a function $g_h:\Bbb R\to\Bbb R$ by $g_h(t):=f(th).$ What are possible values of $g_h'(0)$ and $g_h''(0)$ ? My attempt: Since $h_1,h_2\in\Bbb R$ are independent, I think we can write down $T_2((0,0),(h_1,h_2))$ by definition and compare the coefficients of the polynomial on the $LHS$ with those on the $RHS$ to find the $\nabla f(0,0)$ and $H_f(0,0):$ $$\begin{aligned}
&f(0,0)+Df(0,0)(h_1,h_2)+ \frac1{2!}D^2f(0,0)((h_1,h_2),(h_1,h_2))\\
=&\ f(0,0)+\frac{\partial f}{\partial x_1}(0,0)h_1+\frac{\partial f}{\partial x_2}(0,0)h_2\\
&+\frac1{2!}\left(\frac{\partial^2 f}{\partial x_1^2}(0,0)h_1^2+\frac{\partial^2f}{\partial x_1\partial x_2}(0,0)h_1h_2+\frac{\partial^2f}{\partial x_2\partial x_1}(0,0)h_1h_2+\frac{\partial^2 f}{\partial x_2^2}(0,0)h_2^2\right)\\
=&\ f(0,0)+\frac{\partial f}{\partial x_1}(0,0)h_1+\frac{\partial f}{\partial x_2}(0,0)h_2\\
&+\frac1{2!}\frac{\partial^2 f}{\partial x_1^2}(0,0)h_1^2+\frac{\partial^2f}{\partial x_1\partial x_2}(0,0)h_1h_2+\frac1{2!}\frac{\partial^2 f}{\partial x_2^2}(0,0)h_2^2
\end{aligned}$$ $$\frac{\partial f}{\partial x_i}(0,0)=0,
\quad
\frac{\partial^2f}{\partial x_1\partial x_2}(0,0)=0,
\quad 
\frac{\partial^2f}{\partial x_1^2}(0,0)=4,
\quad
\frac{\partial^2 f}{\partial x_2^2}(0,0)=-6$$ $$\operatorname{grad}f(0,0)=(0,0), H_f(0,0)=\begin{bmatrix}4&0\\0&-6\end{bmatrix}$$ So, $(0,0)$ is a stationary point, but $H_f(0,0)$ is indefinite, so $(0,0)$ isn't a point of the extreme, otherwise, $H_f(0,0)$ would be positive or negative semidefinite. Next, $$g_h'(0)=\lim_{t\to 0}\frac{f(th)-f(0,0)}t=\frac{\partial f}{\partial h}(0)=Df(0)h=0.$$ Now, let $\gamma:\Bbb R\to\Bbb R^2,\gamma(t)=th.$ Then $g_h''(0)=(f\circ\gamma)''(0).$ I tried computed it in a more general setting when $f:\Bbb R^n\to\Bbb R$ and $\gamma:\Bbb R\to\Bbb R^n$ : $$\begin{aligned}(f\circ\gamma)'(c)=Df(\gamma (c))\gamma'(c)&=\begin{bmatrix}\frac{\partial f}{\partial x_1}(\gamma(c))&\ldots&\frac{\partial f}{\partial x_n}(\gamma(c))\end{bmatrix}\cdot\begin{bmatrix}\gamma_1'(c)\\\vdots\\ \gamma'_n(c)\end{bmatrix}\\&=\sum_{j=1}^n\frac{\partial f}{\partial x_j}(\gamma(c))\gamma_j'(c)
\end{aligned}$$ $$\begin{aligned}D\left(\frac{\partial f}{\partial x_j}(\gamma(c))\right)&=D\frac{\partial f}{\partial x_j}(\gamma(c))\gamma'(c)\\&=\begin{bmatrix}\frac{\partial^2 f}{\partial x_1\partial x_j}(\gamma (c))&\ldots&\frac{\partial^2f}{\partial x_n\partial x_j}(\gamma(c))\end{bmatrix}\cdot\begin{bmatrix}\gamma_1'(c)\\\vdots\\\gamma_n'(c)\end{bmatrix}\\&=\sum_{i=1}^n\frac{\partial^2f}{\partial x_i\partial x_j}(\gamma(c))\gamma_i'(c)\end{aligned}$$ $$\begin{aligned}(f\circ\gamma)''(c)&=\sum_{j=1}^n\left(\sum_{i=1}^n\frac{\partial^2f}{\partial x_i\partial x_j}(\gamma(c))\gamma_i'(c)\gamma_j'(c)+\frac{\partial f}{\partial x_j}(\gamma(c))\gamma_j''(c)\right)\\&=\sum_{i,j=1}^n\frac{\partial^2 f}{\partial x_i\partial x_j}(\gamma(c))\gamma_i'(c)\gamma_j'(c)+\sum_{j=1}^n\frac{\partial f}{\partial x_j}(\gamma(c))\gamma_j''(c)\\&= Hf(\gamma(c))(\gamma'(c),\gamma'(c))+\nabla f(\gamma(c))\gamma''(c)\end{aligned}$$ So, $$\begin{aligned}g_h''(0)&=H_f(0,0)((h_1,h_2),(h_1,h_2))+\nabla f(0,0)\cdot(0,0)^T\\&=\begin{bmatrix}4&0\\0&-6\end{bmatrix}\cdot\begin{bmatrix}h_1\\h_2\end{bmatrix}\cdot\begin{bmatrix}h_1\\h_2\end{bmatrix}\\&=4h_1^2-6h_2^2\\&=4(h_1^2+h_2^2)-10h_2^2\\&=4-10h_2^2\end{aligned}\\\implies g_h''(0)\in[-6,4]$$ because $h_2\in[-1,1]\implies h_2^2\in[0,1]$ Is my answer correct? Is there any other way of solving this?","['multivariable-calculus', 'solution-verification', 'derivatives', 'real-analysis']"
4345243,Asymptotic Distance Between First Occurrences of Distinct Letters in Multiset Permutations,"Consider a multiset consisting of $h$ copies of each of $n$ distinct letters. To each permutation, we assign a label, $\vec{T}$ , whose components, $t_i$ are the positions (1-indexed) in the permutation of the first occurrence of the $i^{th}$ distinct letter. Further, consider the label $\vec{\Delta}$ defined by $\Delta_1 = t_1$ , $\Delta_i = t_i-t_{i-1}$ for $i>1$ . For example, take $n=3$ , $h=2$ , and call our letters $a,b,c$ . The permutation $aabcbc$ would be given the labels $\vec{T}=\langle 1, 3, 4 \rangle$ and thus $\vec{\Delta} = \langle 1, 2, 1 \rangle$ . My question is about the average $\vec{\Delta}$ label. That is, if we considered all of the distinct (there will be repeats) $\vec{\Delta}$ 's over all possible permutations of our multiset, added them component by component and divided by the total number of distinct $\vec{\Delta}$ 's. Note it is not really fair to call this an average because a true average would weight each $\vec{\Delta}$ by the number of times it is repeated over all permutations, and divide by the total number of permutations, but for lack of better language, we will continue to refer to it as an ""average"". Specifically, if we fix $n$ and let $h\rightarrow \infty$ what is the asymptotic average $\vec{\Delta}$ . Numerical calculations lead me to believe that such an answer exists. For $n=3$ , and for large $h$ (I've calculated as large as $h=300$ ) the average $\vec{\overline{\Delta}}\approx\langle 1, .45h, .78h\rangle$ , and for $n=4$ , $\vec{\overline{\Delta}}\approx\langle 1, .43h, .67h, .95h\rangle$ . This question is, while not obviously, related to the Coupon Collector's problem. I was wondering what mathematical machinery would be useful for dealing with this problem. My hope is some closed form expression for the coefficients of $h$ in the $\vec{\overline{\Delta}}$ 's. Immediately generating functions came to mind, but I'm unsure how to apply them to these odd $\vec{\Delta}$ sequences. Any guidance is greatly appreciated.","['asymptotics', 'coupon-collector', 'combinatorics', 'discrete-mathematics', 'probability']"
4345325,"Show that the points $(9,1), (7,9), (-2,12), (6,10)$ are concyclic.","Show that the points $(9,1), (7,9), (-2,12), (6,10)$ are concyclic. How can we prove that the given points are con-cyclic? I know the fact the points are said to be concyclic if they lie on the same circle. I substituted the coordinates in the equation of circle and got $4$ equations:- $(9-h)^2 + (1-k)^2 = r^2$ $ (7-h)^2 + (9-k)^2 = r^2$ $(-2-h)^2 + (-12-k)^2 = r^2$ $(6-h)^2 + (10-k)^2 = r^2$ Now, here picking the first three equations, I got the centre of circle as $(-8,1)$ and radius = $17$ units. I'm getting no idea what to do further. Is there any short method to solve the question? Please help me here.","['analytic-geometry', 'circles', 'geometry']"
4345338,Spectral integral: reference request,"Consider the following fragment from Takesaki's book ""Theory of operator algebra I"": In this proof, we encounter expressions like $$x = \int_{-\|x\|}^{\|x\|}\lambda de(\lambda).$$ Can someone explain me how to understand this integral or give me an 'accessible' reference where I can read more about these kinds of integrals?  Is this related to the ""Borel functional calculus""?","['integration', 'operator-algebras', 'reference-request', 'functional-analysis', 'spectral-theory']"
4345389,Doubts in finding an example of a bijective function $f:\mathbb{N} \to \mathbb{Z}$,"Give an example of a bijective function $f:\mathbb{N} \to \mathbb{Z}$ . I consider the function $f:\mathbb{N} \to \mathbb{Z}$ defined as $$f(n):=\begin{cases} n/2, \ \text{if} \ n \ \text{is even} \\ -(n+1)/2, \ \text{if} \ n \ \text{is odd}\end{cases}$$ I have two questions: one on my work and one more general. For my work: about injectivity, is easy to show that if $n_1$ and $n_2$ are both even or both odd then the implication $f(n_1)=f(n_2) \implies n_1=n_2$ holds; if, without loss of generality, it is $n_1$ even and $n_2$ odd I get that $f(n_1)=f(n_2) \iff n_1=-n_2-1$ which is absurd because $n_1 \ge 0$ and $-n_2-1 <0$ . So I deduced that this case can't occur, because it leads to a contradiction. So, since all the comtemplable cases implies that $f$ is injective, I deduced that $f$ is overall injective. Is this correct? Moreover, I have a ""logic"" doubt: I am not fully convinced why the fact that the case $n_1$ even and $n_2$ odd leads to a contradiction allow us to conclude that $f$ is injective and not to the conclusion that that $f$ is not injective. Is this related to the fact that injectivity is defined as an implication and so we assume $f(n_1)=f(n_2)$ true and it is not that we already know that $f(n_1)=f(n_2)$ is true, and so any contradiction obtained from that the assumption means that $f(n_1)=f(n_2)$ cannot occur and so it is not a contemplable case, so it must be excluded in the study of the injectivity and so, consequently, it doesn't give any information about the injectivity or not injectivity of the function and so this information is only related to all the other possible cases? For the general theory: some authours define $\mathbb{N}$ as the set of positive integers, hence for some authors $0 \notin \mathbb{N}$ ; how things work in this cases? I tried to use a similar function $$g(n):=\begin{cases} n/2, \ \text{if} \ n \ \text{is even} \\ -(n-1)/2, \ \text{if} \ n \ \text{is odd}\end{cases}$$ All works for the most part the same, except for the fact that I get a similar contradiction for $n_1$ even and $n_2$ odd given by the fact that $f(n_1)=f(n_2) \iff n_1+n_2=1$ and, since $n_1$ is even and $n_2$ is odd, this is possible only if $n_1=0$ and $n_2=1$ but $n_1$ can't be $0$ because, in this convention, $0 \notin \mathbb{N}$ . Could this be correct? If this is correct, it is normal that if some mathematical object (like functions) has a property (like injectivity) then this property could be independent of the way we define a certain set like the positive/nonnegative integers? Or this was just a lucky situation?","['functions', 'analysis']"
4345425,Proving $\forall A \subset X: f(A)\cap f_{\text{ess}}(X)=\emptyset \implies \mu(A)=0$ & How to think about proofs with essential range.,"I have had a very quick introduction to measure theory and haven't built up much intuition to guide the proofs I attempt. I have been struggling for a while now to prove the following result which appears on the wiki page of essential range. For a measurable function $f:(X,\mu)\to \mathbb{C}$ we have the following : $\forall A \subset X: f(A)\cap f_{\text{ess}}(X)=\emptyset \implies \mu(A)=0$ I'd like help in proving the above lemma, I suspect the above lemma is somewhat elementary but I just can't seem to draw any intuition from the symbolic definition of essential range. $$
f_{\text{ess}}(X):=\bigg\{\omega \in \mathbb{C}: \forall \epsilon>0, \quad \mu\big(\{x\in X:|f(x)-\omega|<\epsilon\}\big)>0\bigg\}
$$ Also I would really appreciate any advice given on how one typically tackles these types of proofs in measure theory and/or how to think about proofs involving the essential range of a function. In fact the wikipedia page linked above mentions that the essential range is the smallest closed subset such that the above theorem holds. I think this is a very nice way to conceptualise the essential range. As always thank you for any input given.","['measure-theory', 'intuition']"
4345480,"Colored ball problem with $2$ colors, but each ball is always replaced with $1$ color","I'm trying to find a solution to this problem but I'm having a hard time thinking through how to solve it: You have one bag with $N$ balls, each being red or white. You draw some number of balls, each time replacing the ball with a red ball. IE both red and white balls are always replaced with red balls regardless of the color drawn. How do you solve for an expected number of red/white balls? Example: $100$ balls, $70$ red and $30$ white. You draw $15$ balls. How many red balls do you expect to draw? It would be pretty straightforward if the balls were replace with their own color, but I'm stumped here. Ideally I'd love to have something I could punch into a cell formula in Google Sheets, but if that's not possible then I'd be happy to have any kind of explanation.","['statistics', 'combinatorics', 'balls-in-bins', 'probability']"
4345484,$\sigma(T)$ is finite $\iff \exists p\in P: p(T) = 0$,"The following is an old exam problem and I can not figure out how to solve it. I have been gathering some facts related to the problem, see below. Problem Let $H$ be a separable Hilbert space and let $T: H \to H$ be a compact symmetric linear map. Let $\sigma(T)$ denote the spectrum of $T$ and $P$ the set of polynomials. Prove: $\sigma(T)$ is finite $\iff \exists p\in P: p(T) = 0$ Find a separable Hilbert space $H$ and a compact linear map $C:H\to H$ with finite spectrum such that there is no $p\in P$ with $p(C) = 0$ What I know There exists an orthonormal base $\{z_1,z_2,..\}$ for $H$ , where $z_i$ are eigenvectors of $T$ corresponding to real eigenvalues. $\sigma(T) \subset \{ \lambda : |\lambda| \le |||T||\}$ For any $p \in P, \sigma(p(T)) = p(\sigma(T)) $ The eigenspace corresponding to any $\lambda \neq 0$ is finite dimensional. For $\lambda \neq 0$ , the null spaces of $T_\lambda, T_\lambda^2, T_\lambda^3, ..$ are finite dimensional. ( $T_\lambda = T - \lambda I$ )","['hilbert-spaces', 'functional-analysis', 'eigenvalues-eigenvectors']"
4345543,Inequality on the moment generating function of a centered random variable which is bounded above,"I am stuck in the first part of problem 2 of the chapter 8 (error estimation) of the book ""A probabilistic theory of pattern recognition"" by Devroye: Show that for any $s>0$ , and any random variable $X$ with $\mathbf EX=0,\mathbf EX^2=\sigma^2, X\le c$ , $$\mathbf E\left\{e^{sX}\right\}\le e^{f(\sigma^2/c^2)}\,,$$ where $$f(u)=\log\left(\frac1{1+u}e^{-csu}+\frac{u}{1+u}e^{cs}\right).$$ The purpose of the problem is to prove Bennett's inequality. I've searched for how Bennett's is usually proved, and it seems like the usual trick is to expand $\mathbb{E}[e^{sX}]$ with the Taylor series, followed by applying an inequality on the terms in $\mathbb{E}[X^k], k \geq 3$ . However, this is not what the author has in mind here, and I cannot figure out any way to invoke the term $e^{-csu}$ in any inequality.","['moment-generating-functions', 'statistics', 'probability-theory']"
4345552,Why can't I use $\sum_{x\in\mathbb{R}} |x|$ instead of Cantor's diagonal?,"I know Cantor's diagonal argument works through a proof by contradiction (assume a set is countable which means there's a bijection between the natural numbers and then use diagonalization to create a new different number). This argument makes sense to me but I get confused when I think of similar arguments that do not work. For example, instead of using diagonalization, what happens if I take the sum of the absolute values of everything in the set? Wouldn't that produce a new number that is larger (and therefore different) than everything else? However, I know this is not valid since it would offer a disproof of the bijection between natural numbers and even natural numbers. I think my mistake is probably that I think of infinity too naively, but I can't pinpoint exactly how my thinking is wrong.","['elementary-set-theory', 'real-numbers']"
4345561,Confidence Interval for the product of heads and tails in 100 coin flips,"If I flip 100 fair coins and then multiply the number of heads by the number of tails. Can you give a double-sided 95% confidence interval on the product of the number of heads by the number of tails? Let $T$ denote the number of tails, and let $P$ denote the product. So $P = T(100-T)$ . I am trying to apply the central limit theorem. I already calculated that $E[P] = E[100T] - E[T^2] = 5000 - 2525 = 2475$ . Is there a faster way to calculate the variance of $P$ other than brute forcing the value of $E[T^3]$ and $E[T^4]$ ? I am on the wrong track?","['statistics', 'confidence-interval', 'binomial-distribution', 'combinatorics', 'probability']"
4345565,Argue that $\gamma_0$ cannot be a maximum of the action,"We consider once more the one-dimensional harmonic oscillator with the Lagrangian given by: $$L(x,v)=\frac{m}{2}v^2-\frac{k}{2}x^2,k>0$$ and the corresponding action on trajectories $\gamma$ given by the functional: $$S(\gamma)=\int_{t_1}^{t_2}L(\gamma(t),\dot{\gamma(t)})dt.$$ I have found the Euler-Lagrange equation of the system to: $$-kx=m \ddot{x}$$ And the solution to: $$x(t) = c_1 \cos(\sqrt{\frac{k}{m}} t ) + c_2 \sin(\sqrt{\frac{k}{m}} t)$$ We assume that $\gamma_0(t)$ solution of the Euler-Lagrange-equation satisfying $\gamma_0(t_1 = 0) = \xi$ and $\gamma_0(t_2 = T) = \eta$ .  And variation of the trajectory $\gamma_0$ given as $\gamma(t) = \gamma_0(t) + \nu(t)$ with $\nu$ some
curve satisfying $\nu(0) = \nu(T) = 0$ . We have that $S(\gamma)$ and $S(\gamma_0)$ is given by: $$\Delta S=S(\gamma)-S(\gamma_0)=\frac{1}{2} \int_0^T m \dot \nu^2(t)-k\nu^2(t)dt$$ We have to use this to argue that that $\gamma_0$ cannot be a maximum of the action. Can anyone help me what that argue could be? I'm a bit lost","['mathematical-physics', 'geometry', 'analysis', 'partial-differential-equations']"
4345581,Relative Cartier divisor scheme,"This is question 1.14.1.2 in Kollar's book Rational Curves on Algebraic Varieties . Let $f:X\rightarrow S$ be a flat and projective morphism with integral fibres such that $H^1(X_s,O_{X_S})=0$ for every $s\in S$ . Assume that $S$ is reduced and connected. Let $L$ be a line bundle on $X$ such that $h^0(X_s,L_s)$ is independent of $s\in S$ . Then obviously $f_*L$ is locally free and $Proj_S(f_*L)$ is embedded in $CDiv(X/S)$ . However, I cannot show that $Proj_S(f_*L)$ is a connected component. Here $CDiv(X/S)$ is the representable scheme of relative effective Cartier divisor: $$CDiv(X/S)(Z)=\{\mathrm{Relative\; effective\; Cartier\; divisors\; of\; }V\subset X\times_S Z\}.$$","['divisors-algebraic-geometry', 'algebraic-geometry']"
4345607,Convergence of $ \sum_{n=1}^{\infty} \frac{\cos (2n+\sqrt{n})}{\sqrt{n}} $,"As you undestand from the topic title, I am wondering how to determine whether the series $$ \sum_{n=1}^{\infty} \frac{\cos (2n+\sqrt{n})}{\sqrt{n}}  $$ converges or not. Previously there have been many similar problems and I tried them all did not work. [Link1]:( Convergence of $\sum \frac{ \cos\sqrt n} {\sqrt n}$ ) Estimating the number of n to identify a Cauchy lower bound is a good approach, but  when inside the $\cos$ is $2n+\sqrt{n}$ , the range of $n$ is not as much as expected failed to estimate the lower boundary. [Link2]:( Does $\sum_{n=1}^\infty \frac{\cos{(\sqrt{n})}}{n}$ converge? )I followed the idea of Robert Z's answer. Although its corresponding integral is convergent, the summation does not converge due to the 1st order term in the first step of estimating $|f(n)-f(x)|$ . Any help may yield help and look forward to your reply.","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
4345621,"A ""generalization"" of Fermat's little theorem using group action?","We already know that: Let $X$ a finite set of size $n>0$ and $p$ a prime number. Let $\sigma$ be the circular permutation $(1,2,...,p)\in \mathfrak{S}_p$ . If we consider the following group action: $\mathbb{Z}/p\mathbb{Z} \times
 X^p\longrightarrow X^p, \ (\bar{k},(a_1,...,a_p)) \mapsto
 (a_{\sigma^k(1)},...,a_{\sigma^k(p)})$ then by counting orbits under this action we can deduce that $p \mid (n^p-n)$ . But now I was wondering what would happen if we wanted $p^k \mid (n^{p^k}-n^{p^{k-1}})$ with $k>1$ ? Maybe I could consider the same set $X$ of size $n>0$ and $\sigma$ the circular permuation $(1,2,...,p^k)\in \mathfrak{S}_{p^k}$ . Then I could consider the following group action : $\mathbb{Z}/p^k\mathbb{Z} \times
 X^{p^k}\longrightarrow X^{p^k}, \ (\bar{k},(a_1,...,a_{p^k})) \mapsto
 (a_{\sigma^k(1)},...,a_{\sigma^k(p^k)})$ . If I reproduce the same method by counting orbits under that action, will I obtain the conclusion? Are there other alternatives which use a different group action? Also, could we find the Euler's theorem with that method? Thanks in advance!","['elementary-number-theory', 'alternative-proof', 'solution-verification', 'group-theory', 'group-actions']"
4345636,Is it easy to evaluate the integral $\int \frac{\sin ^{5} x+\cos ^{5} x}{\sin ^{3} x+\cos ^{3} x} d x$,"Splitting the integral into two by division: $$
I:=\int \frac{\sin ^{5} x+\cos ^{5} x}{\sin ^{3} x+\cos ^{3} x} d x=\int\left(\sin ^{2} x+\cos ^{2} x-\frac{\sin ^{2} x \cos ^{2} x(\sin x+\cos x)}{\sin ^{3} x+\cos ^{3} x}\right)dx
$$ Simplifying gives $$
I=x-\int \frac{\sin ^{2} x \cos ^{2} x}{1-\sin x \cos x} d x
$$ By my answer , $$\int \frac{\sin ^{2} x \cos ^{2} x}{1-\sin x \cos x} d x=\frac{2}{\sqrt{3}} \tan ^{-1}\left(\frac{2 \tan x-1}{\sqrt{3}}\right)-x+\frac{\cos 2 x}{4}+C_2$$ Now we can conclude that $$I=2x+\frac{2}{\sqrt{3}} \tan ^{-1}\left(\frac{1-2 \tan x}{\sqrt{3}}\right)-\frac{\cos 2 x}{4}+C$$ *checked by wolframalpha . How about when the power 5 is replaced by a higher one ?","['integration', 'trigonometry']"
4345657,Find the solution of the sistem $x''=2x+y$ and $y''=x+2y$,"I have to find the solution of the sistem $x''=2x+y$ and $y''=x+2y$ to which it applies $x(0)=0$ , $x'(0)=2$ , $y(0)=0$ and $y'(0)=0$ . First I wrote this two formulas in matrix like this $$\begin{bmatrix}
x'' \\
y''
\end{bmatrix}=\begin{bmatrix}
2 & 1 \\
1 & 2
\end{bmatrix}\begin{bmatrix}
x\\
y
\end{bmatrix}$$ Then I calculate eigenvalues of the matrix $\begin{bmatrix}
2 & 1 \\
1 & 2
\end{bmatrix}$ where I get $\lambda_{1}=1$ and $\lambda_{2}=3$ For each eigenvalues we got eigenvectors $v_{1}=\begin{bmatrix}
1\\
-1
\end{bmatrix}$ and $v_{2}=\begin{bmatrix}
1 \\
1
\end{bmatrix}$ For that we get the solution $$\begin{bmatrix}
x'\\
y'
\end{bmatrix}=\begin{bmatrix}
e^{t} & e^{3t} \\
-e^{t} & e^{3t}
\end{bmatrix} \begin{bmatrix}
C_{1} \\
C_{2}
\end{bmatrix}$$ We use $x'(0)=2$ and $y'(0)=0$ and we get $C_{1}=C_{2}=1$ Now I have to find solution for $$\begin{bmatrix}
x'\\
y'
\end{bmatrix}=\begin{bmatrix}
e^{t} & e^{3t} \\
-e^{t} & e^{3t}
\end{bmatrix} \begin{bmatrix}
x \\
y
\end{bmatrix}$$ I tried to find eigenvalues for that matrix but I can not find them. Any help?","['eigenvalues-eigenvectors', 'ordinary-differential-equations', 'real-analysis']"
4345667,Deriving surface area of a sphere using triangles,"I was trying to derive surface area of a sphere myself.
I started with a hemi-sphere, sliced it into infinite triangles and then added the area of all the triangles and finally doubled it to get area of a sphere.
I'm getting π²R² as final result. I could not understand what's wrong with my logic.","['area', 'geometry']"
4345689,How many squares with vertices on $x^2y^2 =1$ are possible? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question We can form a square with vertices on the curve $x^2 y^2 = 1$ and which does not intersect this curve. Can we get any other square with vertices on $x^2 y^2 = 1$ and which does not intersect this curve? Can anyone please tell me elaborately?","['geometry', 'plane-geometry']"
4345737,Reference for the analytic valuative criterion of properness,"According to this note : Claim: It can be shown that when $X$ is the “analytification” of
a separated $\mathbb{C}$ -scheme of finite type then a sufficient condition for $X$ to be proper is that any holomorphic map $h\colon \Delta^∗ \to X$ extends to a holomorphic map $\Delta\to X$ . This seems to be an analytic version of the valuative criterion of properness. I have seen papers, math.stackexchange questions and even Wikipedia articles where similar results are applied or discussed. Nevertheless, I have not been able to find a reference where something like the claim stated above is actually proved. I would appreciate it if someone could give me a reference.","['algebraic-geometry', 'reference-request']"
4345750,"$f$ is entire, prove that $\{f_n = f(nz) | n \in \mathbb{N}\}$ is normal on the annulus iff $f$ is constant","I am studying for my exam and came across this question: Suppose $f$ is entire and $r<R$ . Prove that the family $\mathcal{F} = \{f_n = f(nz) | n \in \mathbb{N}\}$ for $z \in \mathbb{C}$ is normal on the annulus $r< |z|<R$ iff $f$ is constant. This is my attempt: $\Leftarrow$ If $f$ is constant, then $f(z) = z_0, \, \forall z \in \mathbb{C}$ . Then since $f_n = f$ for all $n \in \mathbb{N}$ . Thus $\mathcal{F} = \{f\}$ , and therefore every sequence of $\mathcal{F}$ is the sequence of function $f$ , and therefore wil converge uniformly on every compact subset, and thus is a normal family.
Or I could also use Montels theorem and see that since $f_n(z) = f(z) = z_0$ for all $n \in \mathbb{N}$ and all $z \in \mathbb{C}$ , we know that $\mathcal{F}$ is uniformly bounded by $z_0$ and therefore it is a normal family. $\Rightarrow$ We know that $f$ is entire, therefore we only need to prove that it is bounded (and then can use Louiville's theorem to conclude that it is constant). Let $D_k(0)$ be a disk, then since it is compact we know that there exists a $B_k$ such that $|f_n(z)| \leq B_k$ for all $z \in \mathbb{C}, n \in \mathbb{N}$ . I want to use the following theorem: Corollary 4.6 Stein and Shakarchi: Suppose that $\Omega$ is a region with compact closure $\overline{\Omega}$ . If $f$ is holomorphic on $\Omega$ and continuous on $\overline{\Omega}$ then $$sup_{z\in\Omega}|f(z)| \leq sup_{z \in \delta \Omega} |f(z)|.$$ But I am not sure how to since I don't know if on $D_R(0)$ it holds that $\mathcal{F}$ is uniformly bounded on $D_R$ since I am only given it is normal on $r<|z|<R$ . Can someone tell me if my attempts are correct and how I should go further in my second attempt?","['complex-analysis', 'entire-functions']"
4345769,"Let $p_n\ $ be the $n-$th prime. Is there a decreasing positive real sequence $(a_n)$ such that $\sum a_n$ diverges, but $\sum a_{p_n}$ converges?","Let the $\ n-$ th prime be denoted by $\ p_n.\ $ Is there a (not
necessarily strictly) decreasing sequence of positive real numbers $\
(a_n)_{n\in\mathbb{N}}\ $ such that $\ \sum a_n\ $ diverges, but $\
\sum a_{p_n}\ $ converges? Remarks/thoughts: $\ a_n = \frac{1}{n}\ $ fails because $\ \sum\frac{1}{n}\ $ diverges but so does $\ \sum \frac{1}{p_n}.$ If $\ \sum a_n\ $ diverges and $\ k\in\mathbb{N}\ $ then any subseries of the form $\ \sum a_{kn}\ $ also diverges. To see this, consider the contrapositive of this statement. However, there is no $\ k\ $ to compare to prime numbers because the $\ n-$ th prime is approximately $\ n\ln(n) \gg n\ $ for large $\ n.$ Maybe there are arguments you can make based on the asymptotic behaviour of the primes - but I am not very good at these, so would be interested to see some. Or maybe there are other, easier methods, which again I don't see.","['convergence-divergence', 'sequences-and-series', 'prime-numbers', 'real-analysis']"
4345806,Evaluate some integrals with hypergeometric function,"There are some interesting integral problems: $$\int_{0}^{\infty} \cos\left (\frac{x}{2}  \right ) \left ( \cosh(x)-\frac{4x^{3/2}{}_1F_2\left ( 1;\frac{5}{4},\frac{7}{4};\frac{x^2}{4}    \right ) }{3\sqrt{\pi} }  \right )\text{d}x
=\frac{4}{5}.$$ $$\int_{0}^{\infty} e^{-x} \left ( \cosh(x)-\frac{4x^{3/2}{}_1F_2\left ( 1;\frac{5}{4},\frac{7}{4};\frac{x^2}{4}    \right ) }{3\sqrt{\pi} }  \right )\text{d}x
=\frac{3}{4}.$$ Where ${}_1F_2$ is generalized hypergeometric function . My question is that : How to prove these closed expressions? Are there any generalizations?","['integration', 'improper-integrals', 'definite-integrals', 'contour-integration', 'closed-form']"
4345812,"Make $2$ cubes out of $1729$ unit cubes, expected number of times you have to paint","I'm trying to solve question 6 from the PuMac 2007 Combinatorics A competition: Joe has $1729$ randomly oriented randomly arranged unit cubes, which are initially unpainted. He makes two cubes of sidelengths $9$ and $10$ or of sidelengths $1$ and $12$ (randomly chosen). These cubes are dipped into white paint. Then two more cubes of sidelengths $1$ and $12$ or $9$ and $10$ are formed from the same unit cubes, again randomly oriented and randomly arranged, and dipped into paint. Joe continues this process until every side of every unit cube is painted. After how many times of doing this is the expected number of painted faces closest to half of the total? Here's what I got so far: ${1\over2}$ chance of this happening: If you make two cubes of side lengths $9$ and $10$ , then $16$ cubes will have $3$ faces sharing a vertex painted, $12(8 + 7) = 180$ cubes will have $2$ faces sharing an edge painted, $6(8^2 + 7^2) = 678$ cubes will have $1$ face painted, and the remaining $7^3 + 8^3 = 855$ cubes will have no faces painted. ${1\over2}$ chance of this happening: If you make two cubes of side lengths $1$ and $12$ , then $1$ cube will have all $6$ faces painted, $8$ cubes will have $3$ faces sharing a vertex painted, $12(10) = 120$ cubes will have $2$ faces sharing an edge painted, $6(10^2) = 600$ cubes will have $1$ face painted, and the remaining $10^3 = 1000$ cubes will have no faces painted. But I'm stuck as this point, and don't know what to do next. Any help would be well-appreciated.","['contest-math', 'expected-value', 'combinatorics', 'algebra-precalculus', 'probability']"
4345877,The Triple Pendulum,"Triple Pendulum Consider the triple pendulum made out of three masses $m_1 = 2m$ and $m_2 = m_3 = m$ and attached on rods of negligible mass and the same length $\ell$ as depicted in the figure below and parameterized with the angles $\theta$ , $\phi$ and $\chi$ . For small angles $\mid \theta \mid, \mid \phi \mid, \mid \chi \mid\ll 1$ the Lagrangian is given (up to an irrelevant constant) by, $$L=\frac12 m \ell^2\left(2{\dot{\theta}}^2+\left({\dot{\theta}}+{\dot{\phi}}\right)^2+\left({\dot{\theta}}+{\dot{\chi}}\right)^2\right)-\frac12gm\ell\left(4\theta^2+\phi^2+\chi^2\right)\tag{1}$$ Show that we can perform a change of coordinates $(\theta, \phi, \chi)\to(q_1,q_2,q_3)$ so that the kinetic term is diagonalized and normalized, $T=({\dot q_1}^2+{\dot q_2}^2+{\dot q_3}^2)$ .
In terms of the vector ${\bf {q}}=(q_1, q_2, q_3)$ , show that the Lagrangian can be expressed as follows, $$L=\frac12{\bf{\dot q}\cdot\bf{\dot q}}-\frac12{\bf qkq}\tag{2}$$ and find an expression for the matrix $\bf k$ . So in $(1)$ , I will let ${\dot{q_1}}^2=2m{\ell}^2{\dot{\theta}}^2$ , ${\dot{q_2}}^2=m{\ell}^2(\dot{\theta}+{\dot{\phi}})^2$ & $\,{\dot{q_3}}^2=m{\ell}^2(\dot{\theta}+{\dot{\chi}})^2$ . Inverting these in favour of the angles gives $$\dot \theta=\frac{\dot{q_1}}{\sqrt{2m}{\ell}}\tag{a}$$ $$\dot \theta +\dot \phi=\frac{\dot{q_2}}{\sqrt m\ell}\tag{b}$$ $$\dot \theta +\dot \chi=\frac{\dot{q_3}}{\sqrt m\ell}\tag{c}$$ Insertion of $(\mathrm{a})$ , $(\mathrm{b})$ & $(\mathrm{c})$ into the first (kinetic) term of eqn $(1)$ gives $$T=\frac12m\ell^2\left[2\frac{{\dot{q_1}}^2}{2m\ell^2}+\frac{{\dot{q_2}}^2}{m\ell^2}+\frac{{\dot{q_3}}^2}{m\ell^2}\right]=\frac12\left[{\dot{q_1}}^2+{\dot{q_2}}^2+{\dot{q_3}}^2\right]=\frac12{\bf{\dot q}\cdot\bf{\dot q}}\tag{3}$$ So I can correctly get the kinetic, ( $T$ ) part of eqn $(2)$ , now using the same method to get the potential part ( $V$ ), from $(\mathrm{a})$ , $(\mathrm{b})$ & $(\mathrm{c})$ it follows that $$\theta=\frac{{q_1}}{\sqrt{2m}{\ell}}\tag{d}$$ $$\phi=\frac{{q_2}}{\sqrt{m}{\ell}}-\frac{{q_1}}{\sqrt{2m}{\ell}}=\frac{1}{\sqrt{m}\ell}\left(q_2-\frac{q_1}{\sqrt2}\right)\tag{e}$$ $$\chi=\frac{{q_3}}{\sqrt{m}{\ell}}-\frac{{q_1}}{\sqrt{2m}{\ell}}=\frac{1}{\sqrt{m}\ell}\left(q_3-\frac{q_1}{\sqrt2}\right)\tag{f}$$ From $(\mathrm{d})$ , $(\mathrm{e})$ & $(\mathrm{f})$ it follows that $$\theta^2=\frac{{{q_1}^2}}{2m{\ell^2}}\tag{g}$$ $$\phi^2=\frac{1}{m{\ell^2}}\left(q_2-\frac{q_1}{\sqrt2}\right)\left(q_2-\frac{q_1}{\sqrt2}\right)=\frac{1}{m\ell^2}\left({q_2}^2-\sqrt 2q_1q_2+\frac12{q_1}^2\right)\tag{h}$$ $$\chi^2=\frac{1}{m{\ell^2}}\left(q_3-\frac{q_1}{\sqrt2}\right)\left(q_3-\frac{q_1}{\sqrt2}\right)=\frac{1}{m\ell^2}\left({q_3}^2-\sqrt 2q_1q_3+\frac12{q_1}^2\right)\tag{i}$$ Now, insertion of $(\mathrm{g})$ , $(\mathrm{h})$ & $(\mathrm{i})$ into the second term of $(1)$ , $V=\frac12gm\ell\left(4\theta^2+\phi^2+\chi^2\right)$ , transforms to $$\begin{align}V&=\frac{gm\ell}{2m{\ell}^2}\left(4\frac{{q_1}^2}{2}+{q_2}^2-\sqrt 2q_1q_2+\frac12{q_1}^2+{q_3}^2-\sqrt 2q_1q_3+\frac12{q_1}^2\right)\\&=\frac12\frac{g}{\ell}\left(2{q_1}^2+{q_1}^2+{q_2}^2+{q_3}^2-\sqrt 2q_1q_2-\sqrt 2q_1q_3\right)\\&=\frac{g}{2\ell}\left(3{q_1}^2+{q_2}^2+{q_3}^2-\sqrt 2q_1\left(q_2+q_3\right)\right)\tag{4}\end{align}$$ I have really laboured the point with the algebra here, but I did so on purpose so it would be easy to identify errors.
This is as far as I can get, and it doesn't look anything like the second term of eqn $(2)$ - $\frac12{\bf qkq}$ . But I can tell you that the last expression (for $V$ ) is correct as I have the author's solution below: I have some questions regarding this solution. Why is the authors eqn $(29)$ different from my eqn $(3)$ and what is meant by ""the kinetic term is diagonal""? My equation $(4)$ matches with the author's equation $(33)$ which is good. But how on earth do you deduce the kinetic matrix (sometimes known as 'mass matrix'), $\bf k$ from this? Taking the matrix $\bf k$ as given for a moment, if ${\bf {q}}=(q_1, q_2, q_3)$ is a row vector, then the only way to compute $\bf qkq$ as matrix multiplication is to write it as ${\bf q}{\bf k}{\bf q}^T$ because $${\bf q}{\bf k}{\bf q}^T=\frac{g}{\ell}\begin{pmatrix}q_1 & q_2 &  q_3\end{pmatrix}\begin{pmatrix}
3 & -1/\sqrt2 & -1/\sqrt2 \\
-1/\sqrt2 & 1 & 0 \\
-1/\sqrt2 & 0 & 1 \\
\end{pmatrix}\begin{pmatrix}q_1 \\ q_2 \\  q_3\end{pmatrix}
$$ Which is in the format required for matrix multiplication (row times column) as from left to right we have matrices with (1x3) times (3x3) times (3x1) with the result being a (1x1) matrix (scalar) as required by equation $(33)$ or my $(4)$ . So why is $(2)$ not being written as ${\bf q}{\bf k}{\bf q}^T$ ?","['matrices', 'classical-mechanics', 'mathematical-physics']"
4345904,"Let $E$ be a t.v.s. and $A, B \subseteq E$ with $A$ compact and $B$ closed. Then $A+B$ is closed","I'm trying to prove below theorem. My proof is much simpler than this one. I'm afraid that I made some subtle mistake. Could you have a check on it? Let $E$ be a topological vector space, and $A, B \subseteq E$ with $A$ compact and $B$ closed. Then $C :=A+B$ is closed. My attempt: Let $(c_d)_{d\in D}$ be a net in $C$ that converges to $c\in E$ . By axiom of choice, we can write $c_d = a_d+b_d$ for some $a_d \in A$ and $b_d \in B$ . Because $A$ is compact, the net $(a_d)_{d\in D}$ has a convergent subnet $(a_{\psi (d)})_{d \in D}$ such that $a_{\psi (d)} \to a$ for some $a \in A$ . By definition of net convergence, $c_{\psi (d)} \to c$ . Then $b_{\psi (d)} = c_{\psi (d)} - a_{\psi (d)} \to c-a$ . Because $B$ is closed, $c-a \in B$ and thus $c = a + (c-a) \in A + B= C$ . This completes the proof.","['general-topology', 'solution-verification', 'topological-vector-spaces']"
4345909,Question about the limit $\lim\limits_{+\infty} \tfrac{x^4}{1+x^4(\cos(x))^2}$ and result given by walpha,"I have a problem evaluating this limit $$\lim\limits_{x\to +\infty} \dfrac{x^4}{1+x^4(\cos(x))^2}$$ I'm still not able to get value Wolframalpha gives : $2$ . but if this was true then the reciprocal of this function should tend to $\dfrac 1 2$ but the reciprocal is $$\dfrac{1}{x^4} + \cos^2(x)$$ which has no limit since first term tends to $0$ and second has no limit. Where am I mistaken ?
thanks for help.","['limits', 'calculus']"
4345910,"In an equation like $\sin(2x) = 3\cos(2x)$ for $0\leq x \leq \pi$, why can I divide by $\cos(2x)$?","For every solution I see of $\sin(2x)$ = $3\cos(2x)$ for $0\leq x \leq \pi$ they divide by $\cos(2x)$ to get $\tan(2x) = 3$ and then solve from there. But I have always been told not to divide by $0$ , and surely $\cos(2x)$ can $= 0$ if $x = \pi/4$ . So why is this allowed?",['trigonometry']
4345918,Showing that a random process is a martingale,"Let $(M_n)$ be a $(\mathcal{F}_n)$ -martingale with $M_0=0$ and note $D_n = M_{n+1}- M_n$ .
Let $s>0$ and for $n\ge 0$ : $$N_n = \exp \left( sM_n-\sum_{i=1}^n \log \mathbb{E}(e^{sD_i} |\mathcal{F}_i) \right) $$ Show that $(N_n)$ is a positive martingale for $(\mathcal{F}_n)$ . My take : $$\mathbb{E}(N_{n+1}|\mathcal{F}_n) = \mathbb{E} \left( \frac{e^{sM_{n+1}}}{\prod_{i=1}^{n+1}\mathbb{E}(e^{sD_i} |\mathcal{F}_i)} \bigg| \mathcal{F}_n \right) = \frac{\mathbb{E} \left( \frac{e^{sM_{n+1}}}{\mathbb{E}(e^{sD_{n+1}} |\mathcal{F}_{n+1})} \bigg| \mathcal{F}_n \right)}{\prod_{i=1}^{n}\mathbb{E}(e^{sD_i} |\mathcal{F}_i)}$$ Now it would be nice if we could show that : $$\mathbb{E} \left( \frac{e^{sM_{n+1}}}{\mathbb{E}(e^{sD_{n+1}} |\mathcal{F}_{n+1})} \bigg| \mathcal{F}_n \right) = e^{sM_n} $$ but how ?","['stochastic-processes', 'probability-theory', 'martingales']"
4345923,Galois group of $\mathbb{Q}(\underset{n\geq 1}{\bigcup}\mu_n)/\mathbb{Q}$,"I was trying to formalise the fact that $G_{\mu_\infty}:=Gal(\mathbb{Q}(\underset{n\geq 1}{\bigcup}\mu_n)/\mathbb{Q})\simeq \underset{n}{\varprojlim}\ (\mathbb{Z}/n\mathbb{Z})^{\times}=\hat{\mathbb{Z}}^{\times}$ . When I was done I tried finding something on this problem online to check my argument. The only things I was able to find are these two ancient posts here and here and the last page of these notes . The two posts only deal with the isomorphism $\underset{n}\varprojlim\ Gal(\mathbb{Q}(\mu_n)/\mathbb{Q})\simeq\underset{n}\varprojlim\ (\mathbb{Z}/n\mathbb{Z})^{\times}$ which is in my opinion the most trivial part of this problem whereas the short notes on infinite Galois theory do mention a subtlety involved but fail to make it precise. The subtelty here is that the isomorphism $G_{\mu_\infty}\simeq\underset{n}\varprojlim\ Gal(\mathbb{Q}(\mu_n)/\mathbb{Q})$ is not immediately obvious. Here is my attempt to formalise this Claim 1: The extenstion $\mathbb{Q}(\underset{n\geq 1}\bigcup\mu_n)/\mathbb{Q}$ is normal. Proof: Let $p(x)\in\mathbb{Q}[x]$ be an irreducible polynomial with a root $a\in\mathbb{Q}(\underset{n\geq 1}\bigcup\mu_n)$ Then $a$ is some finite expression in $\mu_{n_1},\dots,\mu_{n_i}$ for some $i\geq 1$ , involving field operations. Then letting $m:=lcm(n_1,\dots,n_i)$ we have that $a\in\mathbb{Q}(\mu_m)$ which is normal over $\mathbb{Q}$ . Hence $p(x)$ splits in $a\in\mathbb{Q}(\mu_m)$ and hence in $\mathbb{Q}(\underset{n\geq 1}\bigcup\mu_n)\ \ \ \blacksquare$ Remark: We immediately get that $\mathbb{Q}(\underset{n\geq 1}\bigcup\mu_n)/\mathbb{Q}$ is Galois since seperability is automatic. Hence we have that $\mathbb{Q}(\underset{n\geq 1}\bigcup\mu_n)=\underset{K}\bigcup K$ where $K$ runs over all Galois number fields contained in $\mathbb{Q}(\underset{n\geq 1}\bigcup\mu_n)$ . But we can actually improve this as follows. Claim 2: It suffices to have $K$ run over all abelian, Galois number fields contained in $\mathbb{Q}(\underset{n\geq 1}\bigcup\mu_n)$ . Proof: One containment is trivial. To see the other one, if $K$ is a Galois number field contained in $\mathbb{Q}(\underset{n\geq 1}\bigcup\mu_n)$ , write $K=\mathbb{Q}(\alpha)$ . Then by the above remark and the proof of the first claim we see that $\alpha\in\mathbb{Q}(\mu_m)$ for some $m$ . Hence $K\subset\mathbb{Q}(\mu_m)$ and since $K$ is Galois, we have by Galois theory that $Gal(K/\mathbb{Q})$ is isomorphic to a quotient of the abelian group $Gal(\mathbb{Q}(\mu_m)/\mathbb{Q})$ and hence is itself abelian. $\blacksquare$ Because of this we get an isomorphism $$G_{\mu_\infty}\simeq\underset{K}\varprojlim\ Gal(K/\mathbb{Q})$$ where now $K$ runs over all abelian Galois number fields contained in $\mathbb{Q}(\underset{n\geq 1}\bigcup\mu_n)$ and the inverse limit is with respect to inclusions of number fields. We now define the group homomorphism $$\phi:\underset{K}\varprojlim\ Gal(K/\mathbb{Q})\longrightarrow\underset{n}\varprojlim\ Gal(\mathbb{Q}(\mu_n)/\mathbb{Q})$$ where we just forget all non cyclotomic number fields and the inverse limit on the right is taken with respect to projections, for $m|n$ , $Gal(\mathbb{Q}(\mu_m)/\mathbb{Q})\longrightarrow Gal(\mathbb{Q}(\mu_n)/\mathbb{Q})$ . Claim 3: $\phi$ is an isomorphism. Proof : Let $(\sigma_K)\in\ker(\phi)$ , then $\sigma_{\mathbb{Q}(\mu_n)}=id, \forall n$ . Now from claim number 2 and its proof we see that given any abelian Galois number field $K$ contained in $\mathbb{Q}(\underset{n\geq 1}\bigcup\mu_n)$ , we have that $K\subset\mathbb{Q}(\mu_m)$ for some $m$ . Hence by the inverse system of $\underset{K}\varprojlim\ Gal(K/\mathbb{Q})$ we have that $\sigma_K=id$ , for all such $K$ . Hence $\phi$ injects. Now let $(\sigma_n)$ be any element of $\underset{n}\varprojlim\ Gal(\mathbb{Q}(\mu_n)/\mathbb{Q})$ . We define the element $(\sigma_K)\in\underset{K}\prod Gal(K/\mathbb{Q})$ as follows $$\sigma_K:=\sigma_m|_K, \text{if}\ K\subset\mathbb{Q}(\mu_m)\ \text{for some}\ m$$ Where again we've implicitly used claim number 2 for this definition. To see that this is well defined, suppose we have $K\subset\mathbb{Q}(\mu_n)\bigcap\mathbb{Q}(\mu_m)=\mathbb{Q}(\mu_d)$ , where $d=gcd(n,m)$ . Then since $d$ divides both $n$ and $m$ , we have by the inverse system of $\underset{n}\varprojlim\ Gal(\mathbb{Q}(\mu_n)/\mathbb{Q})$ that $\sigma_n|_K=\sigma_d|_K=\sigma_m|_K$ as required. We also have by construction that $(\sigma_K)\in\underset{K}\varprojlim\ Gal(K/\mathbb{Q})$ and maps to $(\sigma_n)$ under $\phi$ . Hence $\phi$ surjects $\blacksquare$ Hence indeed, in order to compute $G_{\mu_\infty}$ , it suffices to compute $\underset{n}\varprojlim\ Gal(\mathbb{Q}(\mu_n)/\mathbb{Q})$ .
Also note that in place of claim number 2 we could have also used Kronecker-Webber but that would be a bit of an overkill?
What i'd like to know is whether everthing here makes sense? Is it necessary? Can it be made shorter and/or more precise?","['galois-theory', 'algebraic-number-theory', 'abstract-algebra', 'profinite-groups']"
4345931,Convergence in distribution for sum of products of random variables,"Given a martingale difference sequence $X_i$ with $\frac{1}{\sqrt n}\sum_{i=1}^n X_i \implies N(0,\Sigma)$ , where $\implies$ denotes convergence in distribution, and $\Sigma$ is some covariance matrix. Let $Y_i$ be a sequence of i.i.d. random variables with mean 0, variance 1, independent of $X_i$ . Is it true that $\frac{1}{\sqrt n}\sum_{i=1}^n X_i Y_i \implies N(0,\Sigma)$ ?","['martingales', 'probability-limit-theorems', 'probability-theory']"
4345979,Limit of series with infinite product,"In our Calc 1 class this is one of the proposed series: $\displaystyle\sum_{n\geqslant 1}\frac1{n}\prod_{k=1}^n \left(1-\frac{\pi}{k}\right)$ .
We have only been taught basic criteria, so no integration, just comparison test, quotient test, etc... Any way to tell this series diverges? (Because that is my intuition but I am unable to prove it)",['sequences-and-series']
4345982,Exterior derivative of wedge product [duplicate],"This question already has an answer here : Computing the exterior derivative of a wedge product (1 answer) Closed 7 years ago . How can I show that $$
\mathrm d(a\wedge b)=(\mathrm d\,a)\wedge b + (-1)^{q}a\wedge(\mathrm d\,b)
$$ for a $q$-form $a$ and an $r$-form $b$?","['differential-forms', 'differential-geometry']"
4346008,Question About Basic Rules of Elementary Algebra,"I am attempting to learn linear algebra in a very thorough manner. The more questions I ask, the more I realize there are some fundamental issues I don't understand. Here is one. For $x\in{}\mathbb{R}$ , we learn to solve an equation like $5x=15$ by multiplying both sides of the equation by the multiplicative inverse of $5$ , i.e., $\frac{1}{5}$ . Someone tells us that this operation does not change the solution set of the equation, and most people will accept this. Thus we find that the solution set is $S=\{3\}$ However, multiplying both sides of the equation by 0 yields an equation $0=0$ with solution set $S=\mathbb{R}$ . Why the discrepancy?","['systems-of-equations', 'logic', 'linear-algebra', 'elementary-set-theory', 'algebra-precalculus']"
4346044,What is the theoretical justification for alternatives to MSE minimalisation?,"I'm trying to wrap my head around the connection between statistical regression and its probability theoretical justification. In many books on statistics/machine learning, one is introduced to the idea of the loss function, which is then typically followed by a phrase of the flavour 'a popular choice for this function is mean squared loss'. As far as I understand, the justification for this choice stems from the theorem that $$ \arg\min_{Z \in L^2(\mathcal{G})} \ \mathbb{E} \left[ (X - Z)^2 \right] = \mathbb{E} \left[ X \Vert \mathcal{G} \right] \tag{*} $$ where $X$ is the random variable to be estimated based on the information contained in $\mathcal{G}$ . As far as I understand, probability theory teaches us that the conditional expectation $\mathbb{E}[X \Vert \mathcal{G}]$ is the best such estimate. If that's the case, why should our loss function still be a choice? Clearly we should be statistically estimating $\mathbb{E}[X \Vert \mathcal{G}]$ , which by (*) implies minimizing the MSE. You could argue that such reasoning is circular because we define the conditional expectation to satisfy (*), but that's doesn't seem true, as we have conditional expectations for any random variable in $L^1$ , and moreover there have been many eloquent posts on this website explaining how the $L^1$ definition can be intuitively interpreted in terms of the measurability capturing the information contained in $\mathcal{G}$ , etc. I would greatly appreciate it if someone could clear up my confusion.","['statistics', 'probability-theory']"
4346065,Is there an injective homomorphism between $\mathbb{Z_4} \times \mathbb{Z_4}$ and $S_7$?,"I've been working on solving the following problem: Is there an injective homomorphism between $G:=\mathbb{Z_4} \times \mathbb{Z_4}$ and $S_7$ ? I am at a loss as to how to solve this. I've considered a few things: (trying to refute the claim): If there were a homomorphism $\phi$ between $\mathbb{Z_4} \times \mathbb{Z_4}$ and $S_7$ , then for all $g \in  \mathbb{Z_4} \times \mathbb{Z_4}$ we would have $o(\phi(g)) \mid o(G)=16$ . In particular, there must be a permutation $a\in S_7$ such that $o(a) \mid 16$ . Indeed there is - e.g. $(1 2)(34)(56)(7)$ is of order $2$ (that's the ${\rm lcm}$ ). Using Cayley's theorem somehow (e.g. by showing that there's a subgroup $H\leq G$ such that $[G:H]=7$ and then by Cayley we get a homomorphism, but: a. I don't see how this can be true and b. still not injective). Something to do with the kernel since injective means the kernel is trivial: $K=\{(0,0)\}$ , but I don't immediately see why this is helpful. Any advice? What am I missing? Thanks.","['symmetric-groups', 'group-homomorphism', 'group-theory', 'abstract-algebra']"
4346082,Show that for all $X \in \mathscr{M}_n(\mathbb{C})$ we have that: $\lim\limits_{n \rightarrow \infty}{\left(I + \frac{1}{m}X\right)}^{m} = \exp{X}$,"Show that for all $X \in \mathscr{M}_n(\mathbb{C})$ we have that: $$\lim_{n \rightarrow \infty}{\left(I + \frac{1}{m}X\right)^{m}} = \exp{X}$$ Note that for matrices, the $e^X$ is defined by using the series expansion of the exponential function: $$\exp{X} = I + X + \frac{1}{2!}X + \frac{1}{3!}X + \cdots$$ I expanded out $\left(I + \frac{1}{m}X\right)^{m}$ , which I figured I could do since powers of $X$ commute with each other: $$\left(I + \frac{1}{m}X\right)^{m} = \sum_{k=0}^{m}{\binom{m}{k}\left(\frac{1}{m}X\right)^{k}} = \sum_{k=0}^{m}{\frac{m!}{k!\left(m-k\right)!}\left(\frac{1}{m^{k}}X^{k}\right)}$$ The $k$ 'th term in this expansion is can be simplified to: $$\frac{m\left(m-1\right)\left(m-2\right)\cdots\left(m-k+1\right)}{m^{k}}\frac{1}{k!}X^{k}$$ (edited) Thus, as $m \rightarrow \infty$ , the identity will hold since $\frac{m\left(m-1\right)\left(m-2\right)\cdots\left(m-k-1\right)}{m^{k}} \underset{m\to \infty}{\longrightarrow} 1$","['analysis', 'matrices', 'solution-verification', 'linear-algebra', 'matrix-calculus']"
4346095,Spectral decomposition of compact self-adjoint operator,"Consider the following fragment from Takesaki's book ""Theory of operator algebra I"": I can't quite figure out rigorously why the boxed part of the proof is true. Note that I want to make sure that $n \mapsto \xi_n$ is injective (of course, for distinct $n$ the same $\alpha_n$ may occur). I tried to write $e_0 := 0$ . Then we have the convergence $$x = \sum_{n=1}^\infty x(e_n-e_{n-1})$$ in the norm-topology and $xe_n-xe_{n-1}$ is a linear combination of $\alpha_n$ 's and $t_{\xi_n, \xi_n}$ 's, so at best we can write something like $$x= \sum_{n=1}^\infty \sum_{k=1}^{z_n} \alpha_{k,n} t_{\xi_{k,n}, \xi_{k,n}}.$$ Of course, we still need to eliminate the second sum (depending on $n$ ) and somehow absorb it in the large sum and we also need to ensure that $n \mapsto \xi_n$ is injective in the end product. I can't get these technical details right. Any help will be greatly appreciated!","['spectral-theory', 'compact-operators', 'functional-analysis', 'operator-algebras']"
4346156,Canonical map for algebraic curve is nondegenerate,"Let $X$ be a smooth projective curve over an algebraically closed field $k$ . Let $\Omega_X$ be the canonical bundle. Then $\Omega_X$ is a line bundle of degree $2g-2$ , where $g$ is the genus of $X$ , and for $g>1$ it is base point free and determines a map $X\to\Bbb P^{g-1}$ called the canonical map. When $X$ is hyperelliptic, the image is a rational normal curve and the map is the 2-to-1 cover $X\to\Bbb P^1$ followed by the $(g-1)$ -uple embedding; when $X$ is not hyperelliptic, the map is a closed immersion. In the first case, it follows from the properties of rational normal curves that the image of the canonical map is nondegenerate (not contained in a hyperplane). I feel like this should also hold in the second case, so that we can say the image of the canonical map is always nondegenerate. But I don't know how to justify this when the canonical map is a closed immersion (and I feel a little silly for not immediately knowing the answer). Can you help me prove this (or provide a counterexample in case it's not true)?","['algebraic-curves', 'algebraic-geometry']"
4346163,The shortest path in number theory [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 2 years ago . Improve this question Given non-negative integers $a$ and $b$ that are smaller than $1\,000\,000$ , find the shortest path between them in the sense of $\text{mod}$ . Let's measure the length of the path by how much steps it take. Starting from number $a$ , in each step we can choose from $(1)$ to $(4)$ : $(1)$ add $1$ , $(2)$ add $-1$ , $(3)$ add $1000$ , $(4)$ add $-1000$ . And after that, $\text{mod}$ $1\,000\,000$ . My question is, how to write a concise expression to calculate the length of the shortest path (i.e., the distance) between $a$ and $b$ , by using  some $\min\left\{\right\}$ and $\text{mod}$ ?
I encountered this question when I am programming. It's kind of like measuring the distance between two points on a ball. But here we don't have the great circle.
I can duplicate the ""ball"" and put them in a plane to illustrate them. Maybe it could help?","['elementary-number-theory', 'discrete-mathematics']"
4346165,Logarithm of complex numbers,"I am studying complex analysis and in our class we took the following identities: $$\lim_{\epsilon \rightarrow 0^+}\log(-x + i\epsilon)= \log(x) + i\pi$$ $$\lim_{\epsilon \rightarrow 0^+}\log(-x - i\epsilon)= \log(x) - i\pi$$ where $x>0$ and the following commentary it is said: An important property of the logarithm was used in the complex. If one approaches the branching section along the negative real axis from above or below, then the imaginary part of the function value jumps by $2\pi$ . Can someone explain to me these identities and this comment that was said?",['complex-analysis']
4346173,Computing an Exponential Moving Average Via Convolution,"According to the Wikipedia page on moving averages, ""This is also why sometimes an EMA is referred to as an $N$ -day EMA.  Despite the name suggesting there are $N$ periods, the terminology only specifies the $\alpha$ factor. $N$ is not a stopping point for the calculation in the way it is in an SMA or WMA."" I was very shocked to read this. It seems to be suggesting that the sequence of weights used to compute the Exponential Moving Average via discrete convolution with, i.e., historical market price data goes on forever. I understand that the sum of an infinite number of weights can converge to $1$ , but not how an infinite weight function sequence could be convolved with a finite sequence of historical market price data. How is an $N$ -period Exponential Moving Average computed as the convolution of a weight function and historical data? Is the weight function sequence indeed infinite, or does it only contain $N (\pm 1?)$ elements, or does it contain as many elements as historical data points are available $(\pm 1?)$ which is usually greater than $N$ ? This distinction seems important because adding additional elements will re-normalize the significant elements given that all elements sum to $1$ .  What is a typical example of how this convolution product would be formulated?","['statistics', 'convolution', 'stochastic-processes', 'time-series', 'average']"
4346198,Maxima CAS: How to differentiate w.r.t. an expression?,"Is there a way to differentiate with respect to an expression, instead of a single variable in Maxima CAS ? Here is a toy example, which should give $\frac{\partial}{\partial x^2}x^2=1$ : diff(x^2,x^2); with an error in wxMaxima 20.06.6 diff: second argument must be a variable; found x^2 For clarity, I meant first derivative with respect to an expression of $x$ , not a second derivative with respect to $x$ itself. Note that the latter gives $\frac{\partial^2}{\partial x^2}x^2=2\ne 1$ and can be easily computed as diff(x^2,x,2)","['computer-algebra-systems', 'maxima-software', 'derivatives']"
4346226,Proving that implicit midpoint method for Hamiltonian systems is symplectic using a criterion,"The implicit midpoint rule is defined as $$y_{n+1}=y_n+hJ^{-1}\nabla H\left(\frac{y_{n+1}+y_n}{2}\right).$$ where $y=(p,q)$ . I know how to prove that this method is symplectic by hand, using the definition of symplecticity and very lengthy computation. But in this note , it says that we only have to use the following critierion ( Theorem 5 on page 11 ): Let $(p,q)\rightarrow (P,Q)$ be a smooth mapping, close to the
identity. It is symplectic if and only if one of the following
conditions holds locally: $$(Q-q)^T d(P+p)-(P-p)^Td(Q+q)=2dS \mbox{ for some function } S((P+p)/2,(Q+q)/2).$$ I tried to prove the symplecticity of the method using this criterion but I was not able to, even for the most simple case where $p$ and $q$ has only one dimension. This is what I tried: $$Q=q+h\frac{\partial H}{\partial p}\left(\frac{q+Q}{2},\frac{p+P}{2}\right)$$ $$P=p-h\frac{\partial H}{\partial q}\left(\frac{q+Q}{2},\frac{p+P}{2}\right)$$ So that \begin{align*}
&\quad(Q-q)^T d(P+p)-(P-p)^Td(Q+q)\\
&=h\frac{\partial H}{\partial p}\left(\frac{q+Q}{2},\frac{p+P}{2}\right) d\left(2p-h\frac{\partial H}{\partial q}\left(\frac{q+Q}{2},\frac{p+P}{2}\right)\right)\\
&\quad h\frac{\partial H}{\partial q}\left(\frac{q+Q}{2},\frac{p+P}{2}\right) d\left(2q+h\frac{\partial H}{\partial p}\left(\frac{q+Q}{2},\frac{p+P}{2}\right)\right)
\end{align*} I continued to expand the terms, but I don't see how to find the function $S((P+p)/2,(Q+q)/2)$ so that the above is equal to $2dS$ . But in the notes, it sounds like that it should be easy.
Could you help? Thanks in advance!","['numerical-methods', 'symplectic-geometry', 'hamilton-equations', 'analysis']"
4346245,"Bounded convex sets $A,B\subseteq\Bbb R^n,n\ge 2$ with a common point, but disjoint boundaries","Motivation of my question is this answer . Let $A,B\subseteq\Bbb R^n,n\ge 2$ be bounded convex sets such that $\exists a\in A,$ and $a\in B,$ too and $\partial A\cap\partial B=\emptyset.$ Does it hold that $A\subset B$ or $B\subset A$ ? I assumed: $n\ge 2$ because, in $\Bbb R,$ segments $[0,2]$ and $[1,3]$ have disjoint boundaries, yet $2$ is an element of both. In $\Bbb R^2,$ however, their boundaries aren't disjoint. $A,B\subseteq\Bbb R^2$ bounded because the stripes $A=\{(x,y)\in\Bbb R^2\mid 0\le x\le 2\}$ and $B=\{(x,y)\in\Bbb R^2\mid 1\le x\le 3\}$ is a counterexample. $A,B\subseteq\Bbb R^2$ convex because $A=\{x\in\Bbb R^2\mid 0\le\|x\|\le 2\}$ and $B=\{x\in\Bbb R^2\mid 1\le\|x\|\le 3\}$ is a counterexample. Now, if I'm not wrong, a convex set with more than $3$ non-collinear points (possible in $\Bbb R^n,n\ge 2$ ) should have a non-empty interior. Therefore one might consider two open balls of sufficiently smal radii (which are again convex) contained in $A$ and $B$ which the initial problem might boil down to, but I couldn't solve the problem that way. I then tried to employ the boundedness of the boundaries (which with closedness make them compact) and try something with their distance, but to no avail. Under what conditions does the statement hold and how can we prove it? Edit: I'm not sure if this is relevant to the question, but according to this ResearchGate post boundary $\partial A$ of a bounded convex set $A\subseteq\Bbb R^n$ is homeomorphic to the unit sphere $\Bbb S^{n-1}$ , hence connected (because it is the image of the connected set $\Bbb S^{n-1}$ under the continuous inverse of a map $f:\partial A\to\Bbb S^{n-1}, f(x)=\frac{x}{\|x\|}$ ?)","['convex-geometry', 'general-topology', 'examples-counterexamples', 'real-analysis']"
4346285,Asymmetric confidence intervals,"Suppose we have iid data $X_i$ with known variance $\sigma^2$ , and wish to write an asymptotic $1-\alpha $ coverage CI for the population mean $\mu$ . CLT implies that if $z_q$ represents the $q$ quantile of a standard normal, $$z_{\alpha/2}=-z_{1-\alpha/2}\leq \frac{\bar X-\mu}{\sigma/\sqrt  n}\leq z_{1-\alpha/2}$$ occurs (asymptotically) with probability $1-\alpha$ and thus implies a CI for $\mu$ of $\bar X\pm z_{1-\alpha/2}\frac{\sigma}{\sqrt n}.$ Any particular reason we take symmetric bounds, or is this just a matter of simplicity? For instance, it seems to me we could have also used $$ z_{q_1}\leq \frac{\bar X-\mu}{\sigma/\sqrt  n}\leq z_{q_2}$$ for any $q_2-q_1=1-\alpha.$ Update: By ""symmetric,"" I mean using $q_2=1-q_1.$","['statistical-inference', 'statistics', 'confidence-interval']"
4346289,What does partial differentiation give for a second degree equation which doesn't represent a conic?,"Question says:
Find real solution to the equation $$3x^{2}+3y^{2}-4xy+10x-10y+10=0.$$ My first thought was to treat it as a general conic ( $ax^2 + 2hxy + by^2 + 2gx + 2fy + c=0 $ ) but when I do so, its discriminant is lesser than $0$ . And on plotting on geogebra, also it only shows a point. And this is the same point we get after doing partial differentiation and solving for $x,y$ . Generally for a conic, this $(x,y)$ represents the center of the conic. But for equations like these which don't represent a conic, how does doing partial differentiation and then solving, gives us the integer solution to it. If it is center, then there should be a conic too. My friends told that conic is in a complex plane, but shouldn't center should also be in complex plane? Sorry Idk much about conics which exist in both planes, so maybe what I wrote in last 2 lines is completely wrong. Pardon me for that.","['conic-sections', 'algebra-precalculus', 'functions', 'quadratics']"
4346334,Spectral integral: verification of my conceptual understanding,"Let $t \in B(H)$ be a positive operator. Let $E$ be the unique spectral measure relative to $(\sigma(t), H)$ such that $$t = \int \lambda d E(\lambda)$$ (see e.g. Murphy theorem 2.5.6). Recall that $E_{\xi, \eta}$ is by definition a regular Borel measure defined by $E_{\xi, \eta}(S) = \langle E(S)\xi, \eta\rangle$ and that $$\left\langle \left(\int f(\lambda) dE(\lambda)\right) \xi, \eta\right\rangle = \int_{\sigma(t)} f(\lambda) d E_{\xi, \eta}(\lambda).$$ In the proof of lemma 1.5 (p62) in Takesaki's book ""Theory of operator algebra I"", the following is claimed: If $\epsilon > 0$ and $E(\epsilon):= \int \chi_{[0, \epsilon]}(\lambda)dE(\lambda)$ , then $$\langle t\xi, \xi\rangle \ge \epsilon \|\xi\|^2$$ for every $\xi \in \operatorname{Im}(1-E(\epsilon))$ . I want to verify that my proof is correct, and thus verify that my understanding of the spectral integral is correct. Given $\xi \in H$ , we have using the fact that $E(\epsilon)$ and $t$ commute and $1-E(\epsilon)$ is a projection: \begin{align*}\langle t(1-E(\epsilon))\xi, (1-E(\epsilon))\xi\rangle &= \langle t(1-E(\epsilon))\xi, \xi\rangle\\
&= \left\langle\left( \int\chi_{]\epsilon, \infty[\cap \sigma(t)}(\lambda) \lambda dE(\lambda)\right)\xi, \xi\right\rangle\\
&= \int_{]\epsilon, \infty[\cap \sigma(t)} \lambda dE_{\xi, \xi}(\lambda)\\
&\ge \epsilon \int_{\sigma(t)}dE_{\xi, \xi}(\lambda) \\
&=  \epsilon E_{\xi, \xi}(\sigma(t))\\
&= \epsilon \|\xi\|^2\end{align*} Hence, if $\xi \in \operatorname{Im}(1-E(\epsilon))$ , we get \begin{align}\langle t\xi, \xi\rangle &= \langle t (1-E(\epsilon))\xi, (1-E(\epsilon))\xi\rangle \ge \epsilon \|\xi\|^2\end{align} as desired. Is this correct? Please spare no criticism.","['c-star-algebras', 'functional-calculus', 'operator-algebras', 'functional-analysis', 'spectral-theory']"
4346335,Two definitions of a degree of map $f: S^n \to S^n$ equivalent?,"Given a smooth map $f: S^n \to S^n$ , I have seen at least two ways of defining the degree. Definition 1: $\deg f$ is an integer satisfying, for every $\omega \in \Omega^n(S^n)$ , $$\int_{S^n} f^*\omega = (\deg f) \int_{S^n} \omega.$$ This definition comes from the theory of de Rham cohomology. Definition 2: Since $\pi_n(S^n)\simeq \mathbb Z$ , the induced map $f_*: \pi_n(S^n) \to \pi_n(S^n)$ is a multiplication by constant, which is defined as $\deg f$ . Does the two definitions equivalent?","['de-rham-cohomology', 'algebraic-topology', 'differential-geometry']"
4346337,What indicated that order matters in this question?,"A journalist from the local newspaper interviews a randomly selected group
of 3 medal winners. (d) Find the exact probability that there is at least one gold medal winner in the group. Background; International A-Level S1 June 2020 Q3. The question was about a contest where if you jump some distance, you get a medal. Further, 1/3 of those people who got a medal and jumped past a larger distance, got a gold medal. Therefore $$P(G)=\frac{1}{3} \text{ and } P(G')=\frac{2}{3}$$ *within the set of people who already got a medal which is what part d) considers. For the possible combinations to part d), I wrote out $$\text{GG'G'}\\\text{GGG'}\\\text{GGG}$$ And thought that order in which G or G' in the first two combinations was placed was irrelevant, because, when you pick a group of 3, as long as there is one person with gold, then it doesn't matter where that person ""stands"" in the order; the important bit is just that they are there . But the MS takes into account the order. Well, they do $$1-P(\text{G'G'G'})$$ which is a lot easier, yes... but I want to know, given that I'm writing out all the combinations, What indication is there in the question that involved taking into account order? *part d) is copied word-to-word from the past paper; that is all that is asked.","['statistics', 'probability']"
4346376,Finding a closed form for an integral [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I am trying to find a closed form for the following integral: $$\int_0^{k\pi}\left(y(x)+y''(x)\right)\sin xdx$$ And I know that $y(k\pi)=a$ and $k$ is a positive integer.","['integration', 'definite-integrals', 'real-analysis', 'calculus', 'derivatives']"
4346417,Is this series known? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I encountered the following series and was wondering if it can be expressed using a known value? $$\sum_{a,b=1}^{\infty} \frac{(-1)^a+1}{a^3-a^2+ab^2+b^2},$$ where all terms in the sum for which $a$ is odd are interpreted as zero.","['special-functions', 'analysis', 'real-analysis', 'calculus', 'sequences-and-series']"
4346423,Is this a sufficiently rigorous proof of the multivariable integral substitution rule?,"$\newcommand{\d}{\mathrm{d}}$ I came up with this myself, but my proof will appear fairly brief, so I suspect it is not fully rigorous - although I do not see any mistakes, hence the question. First I would like to show that: $$\tag{1}\int_{\Omega}(g\circ f)(x)\,\d\mu(x)=\int_{f(\Omega)}g(x)\,\d(\mu\circ f^{-1})(x)$$ Where $\Omega,f(\Omega),(g\circ f)(\Omega)$ are measurable spaces, with $\mu$ the measure on $\Omega$ and $g,f$ measurable functions w.r.t the relevant sigma algebras.
I think this is called ""push-forward"", but I have not seen a proof of it. My attempt: Assuming $g$ and $f$ measurable, both integrals in the LHS and RHS make sense, where $f^{-1}$ is understood as preimage rather than a functional inverse, as $\mu\circ f^{-1}$ is a measure as $f^{-1}(A)$ is measurable in $\Omega$ if $A$ is measurable in $f(\Omega)$ , and $f^{-1}(A\cup B)=f^{-1}(A)\cup f^{-1}(B)$ so the additivity requirements on a measure are satisfied, etc. Use the definition of Lebesgue integral by simple functions: if $\phi\in S^+({g^+})$ defined on $(\mu\circ f^{-1})$ -measurable sets $A_k$ then: $$\begin{align}\int_{f(\Omega)}g^+\,\d(\mu\circ f^{-1})&\ge\int_{f(\Omega)}\phi\,\d(\mu\circ f^{-1})\\&=\sum_{k}c_k\cdot(\mu\circ f^{-1})(A_k)\\&=\sum_kc_k\cdot\mu(E_k)\\&\le\int_{\Omega}(g\circ f)^+\,\d\mu\end{align}$$ Where $E_k=f^{-1}(A_k)$ . We find that a simple function in $f(\Omega)$ is a lower bound to $g^+$ iff and only if it is a lower bound to $(g\circ f)^+$ in $\Omega$ , and it has the same integral in both spaces. Since the two spaces $S^+(g^+,\mu\circ f^{-1})=S^+((g\circ f)^+,\mu)$ are equal in integration, the limit-from-below definition of Lebesgue integral finds that: $$\int_{f(\Omega)}g^+\,\d(\mu\circ f^{-1})=\int_{\Omega}(g\circ f)^+\,\d\mu$$ From which it follows that the integrals in $(1)$ are indeed the same. Note - that was very, very brief. The equality of the two integrals felt obvious to me, but perhaps a true proof is more difficult than this. I'll now move on to substitution: Let $\Omega,f(\Omega),(g\circ f)(\Omega)$ all be measurable spaces, and suppose that $f(\Omega)$ forms a $\sigma$ -finite measure space with the measure $\mu$ , where $g,f$ are measurable functions. Now suppose that $f$ is bijective, with functional inverse $\psi$ , and that $\psi:f(\Omega)\to\Omega$ is measurable. It follows from the measurability of $f$ that $\Omega$ is $\sigma$ -finite w.r.t the measure $\mu\circ f$ , but suppose also that $\Omega$ forms a sigma-finite measure space with the measure $\nu$ . Then: $$\int_{f(\Omega)}g(x)\,\d\mu=\int_{f(\Omega)}(g\circ f)(\psi(x))\,\d\mu=\int_{\Omega}(g\circ f)(x)\,\d(\mu\circ \psi^{-1})=\int_{\Omega}(g\circ f)(x)\,\d(\mu\circ f)$$ Where $(1)$ was used. By the $\sigma$ -finiteness, we can take the Radon-Nikodym derivative of $(\mu\circ f)$ w.r.t $\nu$ , and find: $$\tag{2}\int_{f(\Omega)}g(x)\,\d\mu=\int_{\Omega}(g\circ f)(x)\cdot\frac{\d(\mu\circ f)}{\d\nu}\,\d\nu$$ Let $\Omega\subset\Bbb R^n,f(\Omega)\subset\Bbb R^n$ , $\mu=\mu_n$ the Lebesgue measure on $\Bbb R^n$ , and $\nu=\mu_n$ also. Suppose $g$ is a measurable function, and suppose $f$ is $C^1$ in $\Bbb R^n$ and $\det J_f\neq 0$ everywhere in $\Omega$ . Then the inverse function theorem gives that $\psi$ exists as a $C^1$ map everywhere in $f(\Omega)$ , and is therefore measurable. As the reals are sigma finite w.r.t these measures, we can employ $(2)$ , so must find the measurable function $\varphi$ such that: $$\mu_m(f(A))=\int_A\varphi(x)\,\d\mu_n(x)$$ For all Lebesgue measurable $A$ in $\Bbb R^n$ . Assume $A$ to not be a null set, which is fine since if it were a null set both LHS and RHS would be zero regardless of $\varphi$ ; indeed, take $A$ w.l.o.g (as $\varphi$ is guaranteed to be unique up to a.e. equivalence) to be a ball $B(r)$ centred about any point $x$ in $\Omega$ . Then the Lebesgue differentiation theorem gives that, a.e.: $$\lim_{r\to0^+}\frac{(\mu_n\circ f)(B_r(x))}{\mu_n(B_r(x))}=\varphi(x)$$ Let $\epsilon\gt0$ be fixed. As $f$ is $C^1$ , we can write $f(x+h)-f(x)=J_f(x)\cdot h+o(\epsilon)$ when $\|h\|$ is small, say $0\lt\|h\|\lt\delta$ . Suppose $r\lt\delta$ ; then, by translational invariance of Lebesgue's measure and subadditivity: $$\begin{align}\mu_n(f(B_r(x)))&=\mu_n\{f(x+h):h\in\Bbb R^n,\,\|h\|\lt r\}\\&=\mu_n\{f(x+h)-f(x):h\in\Bbb R^n,\,\|h\|\lt r\}\\&\le\mu_n\{J_f(x)\cdot h:h\in\Bbb R^n,\,\|h\|\lt r\}+\mu_n(B_{r+|o(\epsilon)|}(x)\setminus B_r(x))\end{align}$$ Lebesgue's measure has the nice property that it scales by $|\det T|$ for any $T$ a linear map, so this becomes: $$\begin{align}0&\le(\mu_n\circ f)(B_r(x))\\&\le|\det J_f(x)|\mu_n(B_r(x))+\mu_n(B_{r+|o(\epsilon)|}(x)\setminus B_r(x))\\&=|\det J_f(x)|\mu_n(B_r(x))+o(\epsilon^n)\end{align}$$ In division by $\mu_n(B_r(x))$ , the limit becomes: $$\varphi(x)=\lim_{r\to0^+}|\det J_f(x)|+\frac{o(\epsilon^n)}{\mu_n(B_r(x))}=|\det J_f(x)|$$ Therefore $|\det J_f(x)|$ is the desired R-N derivative, and using $2$ we finally have: $$\int_{f(\Omega)}g(x)\,\d\mu_n(x)=\int_{\Omega}(g\circ f)(x)|\det J_f(x)|\,\d\mu_n(x)$$ Is this a complete proof? I'm worried it's too simple...","['integration', 'measure-theory', 'pushforward', 'lebesgue-integral', 'multivariable-calculus']"
4346435,Existence of closed form solution of an ODE,"I am looking for a solution of an ODE $$y''+4yy'+y^3=0.$$ I tried several standard strategies but could not come out with any result. Numerical calculation gives somewhat converging solution (depends on the initial value) $y\rightarrow 0$ as $x\rightarrow \infty$ , but this is the best I can tell. Now I started to suspect if there is no closed form expression for the solutions of this ODE. Is there any way to show/disprove if there is a closed form solution to this ODE?",['ordinary-differential-equations']
4346436,Examples of Isomorphic Real and Complex Lie Groups,"Are there any examples of common (for example SL, SO, SU, GL groups of varying dimension) real and complex Lie groups which are isomorphic? I'm aware that many Lie groups are of odd dimension which would stop an argument being made by taking a real manifold and showing it's equivalent to a complex one but writing about some of these groups (e.g. SO and SU) often it isn't explicitly stated whether they are real or complex Lie groups. In the case of $GL(\mathbb{C},n)$ and $GL(\mathbb{R},n)$ as the former is of dimension $2n^2$ and the latter $n^2$ assume no GL groups can be isomorphic as they cannot have the same dimension. I'm not sure however if dimension stops something being isomorphic as a group (certainly they are not isomorphic as manifolds).","['group-theory', 'soft-question', 'lie-groups', 'smooth-manifolds']"
4346437,Showing ${\rm Aut}(D_{2^n})\cong{\rm Aut}(Q_{2^n})$ for $n\ge 4$.,"In this comment from back in 2013, it is claimed that $${\rm Aut}(D_{2^n})\cong{\rm Aut}(Q_{2^n})$$ for $n\ge 4$ , where $$D_{2^n}\cong \langle r,s\mid r^{2^{n-1}}, s^2, srs=r^{-1}\rangle$$ is the dihedral group of order $2^n$ and $$Q_{2^n}\cong\langle x,y\mid x^{2^{n-1}}, y^2=x^{2^{n-2}}, y^{-1}xy=x^{-1}\rangle$$ is the generalised quaternion group of order $2^n$ (defined for $n\ge 3$ ). (For a question of mine on generalised quaternion groups, see here .) I would like to prove that claim. Please would you help me? I know that automorphisms are determined by how they behave on generators. Since the presentations above are very similar, I'm not surprised by the theorem. Perhaps we could use the $N/C$ theorem. Here is the statement: Theorem: Let $H\le G$ as groups. Then $N_G(H)/C_G(H)$ is isomorphic to a subgroup of ${\rm Aut}(H).$ For a proof, see Gallian's ""Contemporary Abstract Algebra (Eighth Edition)"" , Example 15 , page 217. Here $$N_G(H)=\{ x\in G\mid xHx^{-1}=H\}$$ and $$C_G(H)=\{ x\in G\mid xhx^{-1}=h\text{ for all }h\in H\}.$$ So if we let, say, $G=S_{2^n}$ , we have some $K,L\le G$ such that $K\cong D_{2^n}$ and $L\cong Q_{2^n}$ . The $N/C$ theorem requires that we find $N_G(K), N_G(L), C_G(K), C_G(L)$ . If they're all suitably compatible (for lack of a better phrase), then it might follow that $${\rm Aut}(K)\cong {\rm Aut}(L).$$ I have one condition I would like to add: please do not use the holomorph $${\rm Hol}(\Bbb Z_{2^{n-1}})$$ because I aim to use the result in question to better understand the fact that $${\rm Aut}(Q_{2^n})\cong {\rm Hol}(\Bbb Z_{2^{n-1}})$$ for $n>3$ . (Proving that isomorphism is Exercise 5.3.4 of Robinson's ""A Course in the Theory of Groups (Second Edition)"" .)","['automorphism-group', 'group-isomorphism', 'dihedral-groups', 'group-theory', 'quaternions']"
4346448,Calculate the area of an triangle that is inscribed into an ellipse such that the elliptical sectors are of equal size.,"Let us inscribe a triangle $ABC$ into a ellipse such that the sectors $S_1$ , $S_2$ and $S_3$ have an equal sized area. This situation is depicted by the figure below. How we can calculate the triangle's area by the semimajor axis $a$ and semiminor axis $b$ of this ellipse? My ideas / what I know so far: The are of the ellipse is $\pi\cdot a\cdot b$ and we can express it as the sum of the triangle's area $T_{\triangle ABC}$ and the three equally sized areas of the elliptical sectors $A_{S_1}+A_{S_2}+A_{S_3}=3\cdot A_{S_1}$ . Althought this problem seems to be an elementary geometrical one, it does not seem to be so trivial, and I would appreciate any help.","['triangles', 'conic-sections', 'geometry']"
4346457,The Entropy of the quantization symbols and the smallest number of bits that is required for representing source symbols.,"Considering $N_s$ source symbols $v$ with PDF given as, $p(v)= e^{-v}I_{[0,\infty]}(v)$ The $k$ -bits quantizer $Q$ maps the $N_s$ source symbols $v$ to symbols $s$ , $s \in \{0,..., 2^k-1\}$ The quantization interval is equally spaced at $ln(2)\cdot s$ . I tried to find the entropy of the quantization symbols s given k as following, $H_k= -\sum_{s=0}^{2^k-1}p(s)log_2(p(s))$ I defined $p(s) = 0.5 e^{-ln(2)s}$ for $s \in \{ 0,...,2^k-2\}$ and $p(s) = e^{-ln(2)s}$ for $s = 2^k-1$ $H_k= -\sum_{s=0}^{2^k-2} 0.5 e^{-ln(2)s}log_2( 0.5 e^{-ln(2)s}) + e^{-ln(2)2^k-1}log_2(e^{-ln(2)2^k-1})$ then I plot $H_k$ as a function of $k \in[1,100]$ and got this image of H_k the entropy plot shows that $H_k$ become constant = 2 efter around k=10. How do I interpret this result. Why do the entropy become a constant, is the entropy the lower bound of bits that is required for representing source symbols?
does this means that as we increasing number of k it does'nt effeckt the redundancy?
or did i make any mistake in my calculation?","['coding-theory', 'discrete-mathematics', 'probability', 'information-theory']"
4346516,Integration by parts with $\Delta^{-1}$ and $\nabla^{-1}$,"Let $u:\mathbb R^n \to \mathbb R$ be smooth and $A:\mathbb R \to \mathbb R^n$ be Lipschitz. How can we estimate the quantity $$\int_{\mathbb R^n} \nabla \cdot (A(u)) \Delta^{-1}udx$$ from below in terms of $\|\nabla^{-1}u\|_{2}$ and the Lipschitz norm of $A$ ? Is an estimate from above also available? In the simpler case when we replace $A(u)=a(x)u$ with a Lipschitz function $a:\mathbb R^n \to \mathbb R^n$ with $\mathrm{div}(a) = 0$ ,
I already know how to do it: let $\phi=\Delta^{-1} u$ and compute \begin{align*}
\begin{aligned}
\int a \cdot \nabla u \Delta^{-1} u d x &=\int \nabla \cdot(a u) \Delta^{-1} u \\
&=\int \nabla \cdot(a \Delta \phi) \phi \\
&=-\int \sum_{i, j} \partial_{i}\left(a^{i} \partial_{j j} \phi\right) \phi \\
&=-\int \sum_{i, j} a^{i} \partial_{j j} \phi \partial_{i} \phi \\
&=\int \sum_{i, j} \partial_{j}\left(a^{i} \partial_{i} \phi\right) \partial_{j} \phi \\
&=\int \sum_{i, j} \partial_{j} a^{i}\left|\partial_{i} \phi\right|^{2}+\int u^{i} \partial_{i} \frac{\left|\partial_{j} \phi\right|^{2}}{2} d x \\
&=\int \nabla^{-1} u\cdot \nabla a \cdot \nabla^{-1} u d x
\end{aligned}
\end{align*} which gives the required estimate in terms of $\|\nabla^{-1}u\|_{2}$ and $\|\nabla a\|_\infty$ , that is $... \ge - \|\nabla^{-1}u\|_{2}^2\|\nabla a\|_\infty$ and $... \le \|\nabla^{-1}u\|_{2}^2\|\nabla a\|_\infty$","['integration', 'definite-integrals', 'lebesgue-integral', 'multivariable-calculus', 'calculus']"
