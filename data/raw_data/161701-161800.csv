question_id,title,body,tags
2803460,Mistake in proof of $\overline{C_c(X)} = C_0(X)$..,"Usually one employs Urysohn's Lemma to proof the above identity. See for example here in the first answer: Show that the closure of $C_c(X)$ is $C_0(X)$. I find that proof rather complicated compared to the following one. Additionally in the proof in the link we need $X$ to be Hausdorff. Now I've seen the following proof which does not use any property of $X$ and is quite simple aswell. It doesn't even have to be a Hausdorff-space. This is weird to me and I think there must be a mistake in it but I can't find it. $f\in C_0(x)$. Define $f_\epsilon(x) = \begin{cases}0\quad &\text{if }|f(x)|< \epsilon\\ f(x)-\epsilon\frac{f(x)}{|f(x)|}\quad &\text{if }|f(x)|\geq \epsilon.\end{cases}$ $f_\epsilon \to f$ uniformly follows immidiately by distinguishing cases if $|f(x)|$ is bigger or smaller than $\epsilon$. Additionally $f_\epsilon$ has compact support because $\{|f|\geq \epsilon\}$ is compact. By the https://en.wikipedia.org/wiki/Pasting_lemma $f_\epsilon$ is continuous. If this really would be correct, I wonder why this simple and more general proof isn't the one one usually sees. Edit: As requested, more details: 1) $f_\epsilon\to f$ uniformly: Let $x\in X$. If $|f(x)|<\epsilon$, then $|f(x)-f_\epsilon(x)| = |f(x)|<\epsilon$. If $|f(x)|\geq \epsilon$ then $|f(x)-f_\epsilon(x)| = \epsilon\left|\frac{f(x)}{|f(x)|}\right| = \epsilon$, hence $\|f-f_\epsilon\|_\infty\leq \epsilon$. 2) $\{|f|\geq \epsilon\}$ is compact: Since $f\in C_0(X)$, there is compact $A\subset X$ with $|f(x)|<\epsilon$ if $x\notin A$, therefore $\{|f|\geq \epsilon\}\subseteq A$ and $\{|f|\geq \epsilon\}$ is a closed subset of a compact set and therefore compact.","['continuity', 'general-topology']"
2803486,Wilcoxon test statistic,"I learned WSR (Wilcoxon signed rank test) several years ago, and today one of my friends suggest different test statistics on WSR. At first, I thought he was wrong; however, I did found some sources which were citing the positive rank sum as W test statistic. Such as these links suggests: http://courses.wcupa.edu/rbove/Berenson/CD-ROM%20Topics/topice-10_5.pdf http://www.stat.umn.edu/geyer/5601/notes/wilcox.pdf According to my undergrads stat, we choose the min(W+,W-) as the test statistic. for example: http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Nonparametric/BS704_Nonparametric6.html On wiki, it suggest that W = abs(W+ minus W-) . https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test#Test_procedure Why does WSR test has so many ""alternative"" test statistics? Is there many versions of WSR? When to use which test statistics? I am confused now. Please share any insights with me, many thanks. # I would like to edit this question. I just tried to write functions to calculate z scores in r. using two equations below, I was able to get same absolute z-scores using Negative rank sum, Positive rank sum, or absolute rank sum: these data were replicates from an online source https://www.youtube.com/watch?v=TqCg2tb4wJ0 n =non-zero ranking sample size w+ = 75 w- = 16 |w| = 75-16=59 n = 13 for neg or pos z <- function(w,n){
    (w-(n*(n+1)/4))/(sqrt((n*(n+1)*(2*n+1)/24))) } for absolute z1 <- function(w,n){
    (w)/sqrt((n*(n+1)*(2*n+1))/6)
  } z(75,13)
  [1] 2.061627 z(16,13)
  [1] -2.061627 z1(59,13)
  [1] 2.061627 But I'm still confused with it...
Should it considered to be irresponsible for articles and papers to use positive rank sum as w test statistics? Usually people use critical values sheet of w to determine the result right? http://users.stat.ufl.edu/~winner/tables/wilcox_signrank.pdf On the case above(the youtube link), if we use positive rank sum, the result would be completely opposite. Please let me know if I was thinking in the right direction.","['statistics', 'hypothesis-testing']"
2803488,If $\int_{1}^{\infty}f\left(x\right)dx$ converges absolutely then $\int_{1}^{\infty}f^{2}\left(x\right)dx$ converges?,"Let $f:[0,\infty)\to\mathbb{R}$ be a continuous function. I was asked to prove/disprove the following statement: If $\int_{1}^{\infty}f\left(x\right)dx$ converges absolutely then $\int_{1}^{\infty}f^{2}\left(x\right)dx$ converges as well. I figure that my only way of proving this is by direct comparison. However, for that to work I need $f(x)\leq1$ for sufficiently large $x$ , but $\int_{1}^{\infty}f\left(x\right)dx$ converging (Even absolutely) does not guarantee this. If the statement is false I'd appreciate a hint on how to construct a counter example, rather then one pulled out of thin air.","['improper-integrals', 'integration', 'calculus']"
2803489,What are the eigenvalues of this $6 \times 6$ matrix?,"What are the eigenvalues of the following matrix? $$A=\left(\begin{matrix} 
  0 & 0 & 0 & 1 & 0&0\\
  0 & 0 & 0 & 0 & 1&0\\
  0 & 0& 0 & 0 & 0&1\\
  1 & 0 & 0 & 0 & 0&0\\
  0 & 1 & 0 & 0 & 0&0\\0&0&1&0&0&0
\end{matrix}\right)$$ My attempt: I know how  to find the eigenvalues of a $2 \times 2$ matrix and of a $3 \times 3$ matrix. But here I am very confused, as I don't know how to find the eigenvalues of a $6 \times 6$ matrix. Is there any easy method or some tricky method?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2803529,rank inequality for Hadamard product,"How I can show that $$
\operatorname{rank}(A\circ B) \leq \operatorname{rank}(A)\operatorname{rank}(B)
$$ where $A,B$ are rectangular matrices and $\circ$ is the Hadamard product between the two. Similarly, how can we show that  if $A$ has rank d, then $\operatorname{rank}(A\circ A)$ is at most $d+1 \choose 2$ ?","['matrices', 'matrix-rank', 'hadamard-product']"
2803550,Equivalent of $\sin(x)/x = \operatorname{sinc}(x)$ for $(\cos(x)-1)/x$,"In a work calculation I have come across an expression that involves $\sin(x)/x$ which is undefined for $x=0$, even though for my problem, in the $x=0$ case, $\sin(x)/x$ should naturally be $1$ from the context of the problem. This is handily fixed by substituting $\sin(x)/x = \operatorname{sinc}(x)$, which is defined as $\operatorname{sinc}(x) = \sin(x)/x$ for all nonzero $x$, and $\operatorname{sinc}(0) = 1$. However, my work calculation also has an expression $(\cos(x)-1)/x$, which has an analogous problem; for $x=0$, it should simplify to $0$ (which is the limit for $x\to0$) but it is, of course, undefined. As in the $\operatorname{sinc}$ case, my goal is to obtain an expression that's defined everywhere, with no inconvenient 'special case' for $x=0$. Is there, perhaps, an obvious way to write $(\cos(x)-1)/x$ in terms of $\operatorname{sinc}(x)$ that I am missing? Or, alternatively, is there an analogous function defined for this case?","['real-analysis', 'trigonometry', 'calculus']"
2803555,More understanding of Schur's Lemma (representation theory),"One of the famous theorem from Schur's Lemma is the following: Let $\vartheta$: $s \rightarrow D(s)$ be an irreducible representation of the finite group $G$ in the representation space $V$, and let $Q$ be a linear operator $V\rightarrow V$ habing the symmetry of $\vartheta$; i.e., $QD(s) = D(s)Q$ for all $s\in G$. Then $Q = \lambda\cdot I$, where $I$ is the identity matrix.  This $\lambda$ is the eigenvalue of $Q$. My question is: Does this theorem say that if any square matrix $Q$ satisfying the above requirements, then this $Q$ can be written as $\lambda\cdot I$, for any eigenvalue $\lambda$? Is $Q = \lambda\cdot I$ based on a special basis? (I think this is like a basis transformation or similar transformation). If it is, how to find such transformation? thanks","['matrices', 'representation-theory', 'group-theory', 'finite-groups']"
2803583,Metric induced by submersion,"If $(N,h)$ is a Riemannian manifold and $F:M\to N$ is an immersion, we can trivially make $F$ into an isometric immersion by placing the induced metric on $M$. My question concerns the analogous procedure for submersions. Let $f:M\to N$ be a submersion and let $g$ be a Riemannian metric on $M$. Let $\mathcal{V,H}$ be the vertical and horizontal distributions, respectively, i.e. the tangent space of $M$ at $p$ decomposes as $T_p M=\mathcal{V}_p\oplus \mathcal{H}_p$ for all $p\in M$. The restriction $\varphi_p:=(d\pi_p)|_{\mathcal{H}_p}:\mathcal{H}_p\to T_{f(p)}N$ of the differential is an isomorphism for all $p\in M$. Is there a way to construct a metric on $N$ so that $f$ becomes a Riemannian submersion ? My idea is to define a metric $h$ on $N$ by $$h_{f(p)}(X,Y)=g_p(\varphi_p^{-1}(X),\varphi_p^{-1}(Y))?$$ Does this work?","['riemannian-geometry', 'differential-geometry']"
2803617,Trouble proving the trigonometric identity $\frac{1-2\sin(x)}{\sec(x)}=\frac{\cos(3x)}{1+2\sin(x)}$,"I have become stuck while solving a trig identity. It is: $$\frac{1-2\sin(x)}{\sec(x)}=\frac{\cos(3x)}{1+2\sin(x)}$$ I have simplified the left side as far as I can: \begin{align}
\frac{1-2\sin(x)}{\sec(x)}
&=\frac{1-2\sin(x)}{1/\cos(x)}=(1-2\sin(x))\cos(x)\\
&=\cos(x)-2\sin(x)\cos(x)=\cos(x)-\sin(2x)
\end{align} However, I'm not sure what to do on the right side. I know I can use a compound angle formula to break $\cos(3x)$ into $\cos(2x)\cos(x)-\sin(2x)\sin(x)$; however, I do not know where to go after that. My main problem is with the denominator of the right side, I can't figure out how to get rid of it, either by multiplying, or by using a trig identity. Any help in solving this identity would be greatly appreciated!",['trigonometry']
2803630,Is the space of continuous local martingales equipped with the topology of uniform convergence on compact sets complete?,"Let $(\Omega,\mathcal A,\operatorname P)$ be a probability space $(\mathcal F_t)_{t\ge0}$ be a filtration on $(\Omega,\mathcal A)$ $M_{c,\:\text{loc}}(\mathcal F,\operatorname P)$ denote the set of continuous local $\mathcal F$-martingales on $(\Omega,\mathcal A,\operatorname P)$ Is $M_{c,\:\text{loc}}(\mathcal F,\operatorname P)$ equipped with the topology of uniform convergence on compact sets$^1$ complete? $^1$ i.e. If $(M^n)_{n\in\mathbb N}\subseteq M_{c,\:\text{loc}}(\mathcal F,\operatorname P)$ and $M\in M_{c,\:\text{loc}}(\mathcal F,\operatorname P)$, then $M_n\xrightarrow{n\to\infty}M$ in $M_{c,\:\text{loc}}(\mathcal F,\operatorname P)$ if and only if $$\sup_{0\le s\le t}\left|M^n_s-M_s\right|\xrightarrow{n\to\infty}0\;\;\;\text{in probability for all }t\ge 0\tag1.$$","['stochastic-processes', 'probability-theory', 'local-martingales']"
2803637,An interesting series converging to a constant,"Let $K>0$ be a constant. Suppose $\{z_n\}_{n=1}^\infty$ is a non-decreasing positive sequence. Then the series $$\sum_{n=1}^\infty\frac{z_n}{(K+z_1)(K+z_2)\cdots(K+z_n)}K^n=K$$ This is a quite interesting result as the series is convergent and the limit doesn't depend on the choice of $\{z_n\}_{n=1}^\infty$, as long as it is non-decreasing and positive I have run computer simulations and this result seems to hold. However, I am not sure how to prove it.","['number-theory', 'combinatorics', 'sequences-and-series']"
2803652,How often does the fundamental Pell solution satisfy a certain congruence?,"I'm fiddling with a question . I found a surprise. Given positive $n$ integer that is not a square, and fundamental solution
$$ u^2 - n v^2 = 1  $$
with minimal integers $u \geq 1, v \geq 1,$
it is very frequent that $u \equiv -1 \pmod n$ This does fail, for $n=k^2$ it is nonsense, for $n=k^2 - 2$ we get $u=n+1,$ for $n=k^2 - 1$ we get $u = \sqrt {n+1}.$ The successes start: 2,3,5,6,10,11,13,17,18,19,22,26,27,29,37,38,41,43,50,51,53,54,58,59,61,65,66,67,73,74,82,83,85,86,89,97,101. I have no idea why, but it appears that this works for primes $q \equiv 3 \pmod 8.$ Meanwhile, fails for primes $r \equiv 7 \pmod 8.$ Who knew? ADDED: Probably have this. Legendre showed (DICKSON's HISTORY, volume II, page 365) that a prime $q \equiv 3 \pmod 8$ gives $r^2 - q s^2 = -2.$ Then $r^2 \equiv  -2 \pmod q,$ after which $$ \left( \frac{r^2 + q s^2}{2} \right)^2 - q (rs)^2 = 1  $$
with the first term $-1 \pmod q.$ In contrast, when prime $q \equiv 7 \pmod 8$ we get $r^2 - q s^2 = 2,$ so the first term comes out $1 \pmod q.$ Alright, there is one predictable family of successes, whenever there is an integer solution to $a^2 - n b^2 = -1,$ then $a^2 \equiv -1 \pmod n,$ after which we $(a^2 + n b^2)^2 - n(2ab)^2 = 1$ with $a^2 + n b^2 \equiv -1 \pmod n.$ This includes $n \equiv 1 \pmod 4$ prime, also  $n = pq$ primes $p,q \equiv 1 \pmod 4$ with $(p|q)= (q|p) = -1.$ So, question is, How often does this happen?","['number-theory', 'quadratic-forms', 'algebraic-number-theory']"
2803662,The $n^{th}$ root of the geometric mean of binomial coefficients. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question $\{{C_k^n}\}_{k=0}^n$ are binomial coefficients. $G_n$ is their geometrical mean. Prove 
$$\lim\limits_{n\to\infty}{G_n}^{1/n}=\sqrt{e}$$","['binomial-coefficients', 'calculus', 'limits']"
2803727,"If $n^s\in \mathbb{N}$ for all $n\in\mathbb{N}$, must $s\in\mathbb{N}?$ [duplicate]","This question already has an answer here : If $n^c\in\mathbb N$ for every $n\in\mathbb N$, then $c$ is a non-negative integer? (1 answer) Closed 6 years ago . My friend and I were discussing this, and while it looks obviously true, weren't very successful in getting anywhere with it. I'm not sure whether I lack the tools to solve this or whether I am missing something obvious. Any insight would be much appreciated.","['number-theory', 'elementary-number-theory']"
2803741,Circumference inscribed in a square,"What is the area of the hatched region, knowing that the arc AC is 1/4 of the circumference with a center in D? I've tried using algebra to solve this but it seemed insufficient, I thought of using integrals to find the area, by finding the analytic geometry equations for the circles but it went nowhere.","['circles', 'geometry']"
2803762,Irrationality of $\sqrt{2m}$,"I have this problem: If $\sqrt{m}$ is irrational, and $m$ is odd, so: Is $\sqrt{2m}$ always irrational ? My thought was: I have a $m$ number, that can be of the form $(2n \pm 1)$ , that is square is irrational. To find a counterexample, I need this: $2m = x^2$ , then I need an integer, that have perfect square, divided in $2$ is an odd number, that is equal to: Lets $x$ any integer: $\frac{x^2}{2} = k$ Then, $k$ must be an integer, since it is divisible by 2 and must be a number of form $(2n \pm1)$ that is $m$ . With these conclusions, I can reform my problem to: Is there an perfect square, which is divisible by $2$ , and this
division is an odd number? I do not ask this directly, because there may be an easier approach, but still this form seems very interesting to me. PS: I have tested it in programming between $[1, 1000]$ and there is no perfect square, with these characteristics.",['number-theory']
2803778,Is the solution of $ u_{tt}=c^2u_{xx}+xt $ correct?,"Consider the following $ u_{tt}=c^2u_{xx}+xt,\\ u(x,0)=0,\\ u_t(x,0)=\sin (x)$ and find the solution. Solution. We have that $u(x,t)$ is given by $$u(x,t)=\frac{1}{2}(g(x+ct)+g(x-ct))+\frac{1}{2c}\int_{x-ct}^{x+ct}h(u)du+\frac{1}{2c}\iint_\Delta f(y,s)dA,\cdots\cdots (1)$$ where $\Delta $ is a triangle with vertex $(x-ct,0),(x+ct,0),(x,t)$. Thus in our case, $u(x,t)=\frac{1}{2c}\int_{x-ct}^{x+ct}\sin(u)du+\frac{1}{2c}\iint_\Delta xt \ dA.$ Using Green Theorem we have that $\frac{1}{2c}\iint_\Delta xt \ dA=\frac{1}{2}[\cos(x_0+ct)-\cos(x_0-ct)-2cu(x_0,t_0)],$ where I took a point $(x_0,t_0)$ to be able to integrate  using the theorem. and $\frac{1}{2c}\int_{x-ct}^{x+ct}\sin(u)du=\frac{1}{2}[-\cos(x_0+ct_0)+\cos(x_0-ct_0)]$ Hence the final solution is $u(x,t)=\frac{1}{2}[\cos(x_0+ct_0)-\cos(x_0-ct_0)]+\frac{1}{2}[\cos(x_0+ct)-\cos(x_0-ct)-2cu(x_0,t_0)]$ Is it correct? This is the first time I use formula (1), so if something can be improved don't hesitate to suggest. Edit Apparently the solution is wrong because I had to calculate the double integral over the area of the triangle and not the contour integral, that's what my professor said, but I don't know why, I didn't understand why. Could someone explain why is that? I still don't see why application of Green theorem it's not correct in the double integral.","['alternative-proof', 'partial-differential-equations', 'greens-theorem', 'ordinary-differential-equations', 'initial-value-problems']"
2803788,Method of Frobenius Why is There a Logartihmic Solution?,"When solving a problem with the method of Frobenius, if the difference of the roots of the indicial equation differ by a natural number, the smaller root of the indicial equation does not produce a solution because there is no value of its $N$th term that will work where N is the natural number difference between the roots. However, there is another solution in the form 
$$y_2(x) = u(x) -b_N y_1(x)\log x$$ where $y_1$ is the first solution, $u(x)$ is a Frobenius series with obtained with the smaller root, and $b_N$ is the Nth term of $u(x)$. (Ordinary Differential Equation by Morris Tenenbaum and Harry Pollard). I tried to use Reduction of Order, but couldn't figure out how that would work.",['ordinary-differential-equations']
2803832,What's the intuition behind a split exact sequence?,"I've learned the following definition for a split exact sequence: A short exact sequence of $R$-module homomorphisms $0\to A \stackrel{f}{\to} B \stackrel{g}{\to} C \to 0$ is split if there exists a homomorphism $\alpha:B\to A$ such that $\alpha\circ f = 1$ or a homomorphism $\beta:C\to B$ such that $g\circ \beta = 1$. I can never remember whether the definition requires $\alpha\circ f = 1$ or $f \circ \alpha = 1$, and similarly for the other mapping, $\beta$. I suspect that my inability to remember this stems from an underlying lack of understanding about what split exact sequences are for, what a sequence being split really tells us about the modules and morphisms involved, and what concept split exact sequences are meant to capture or generalize. Is there a good way to remember the directions of composition for these definitions? What is the intuition, utility, and underlying meaning behind a split exact sequence?","['abstract-algebra', 'modules']"
2803833,How could a logarithmically changing graph be made that exists only between asymptotes at x= 0 and 1?,"I came up with this problem as a simple thought experiment, but quickly found that it would not be so easy to solve. I managed to come up with these four separate functions that showed some of the properties I wanted, put together making the whole graph. I noticed that each function is very similar to the others, and am convinced that there must be a way to write the four functions as one.
$$
f(x) =
\begin{cases}
-10^{\log_2 (0.5/x)-1},  & 0\le x\le 0.25 \\
-10^{\log_2 (-8(x-0.5))-1},  & 0.25\le x\le 0.5 \\
10^{\log_2 (8(x-0.5))-1},  & 0.5\le x\le 0.75 \\
10^{\log_2 (-0.5/(x-1))-1},  & 0.75\le x\le 1
\end{cases}
$$
The only parameters are, there must be vertical asymptotes at $x=0$ and $x=1,$ when $x=0.5,$ $y=0,$ the $y$ value must increase/decrease multiplying by ten each time the x value becomes $50\%$ closer to $1$ and $0$ respectively. It should also approach $(0.5,0)$ from both directions in a similar manner. Graph Image Corresponding Equations","['algebra-precalculus', 'functions', 'graphing-functions']"
2803840,How to derive the representation formula from $\mathbb R^3$ to $\mathbb R^2$?,"Prove that in $\mathbb R^2$, we have the following representation formula for harmonic function $u$:$$u(\vec x_0)=\frac{1}{2\pi}\int_{\partial D}\left(u(\vec x)\frac{\partial}{\partial \vec n}(\ln|\vec x-\vec x_0|)-\ln|\vec x-\vec x_0 |\frac{\partial u}{\partial \vec n}(\vec x)\right)\,\mathrm ds.$$ In class we  found the representation formula in $\mathbb R^3$, which is
$$u(\vec x_0)=\frac{1}{4\pi}\iint_{\partial D}\left(-u(\vec x)\frac{\partial}{\partial \vec n}\left(\frac{1}{| \vec x-\vec x_0|}\right)+\frac{1}{|\vec x-\vec x_0 |}\frac{\partial u}{\partial \vec n}(\vec x)\right)\,\mathrm dA.$$ In the process we did not use at all the Dirac delta function. I have seen a proof * for the representation formula in $\mathbb R^2$ using that function and Heavyside-function as well, but I did not understand this part: $$v(x)=\frac{1}{2\pi}\log| x- x_0|$$ satisfies the identity $$\Delta v=\delta(x-x_0).$$ Could someone explain with details that part? Alternatively, how to use the representation formula in $\mathbb R^3$ to prove in $\mathbb R^2$? If you see Chee Han comment, maybe could help although I did not understand his comment. Please help me with the proof. Proof *","['harmonic-functions', 'ordinary-differential-equations', 'proof-explanation', 'partial-differential-equations']"
2803878,Proving a combinatorial identity: $\sum_{i=0}^m \binom{l}{i}\binom{m+n-l}{m-i} = \binom{m+n}{m}$,"I came across the following identity while computing certain expressions:
$$\sum_{i=0}^m \binom{l}{i}\binom{m+n-l}{m-i} = \binom{m+n}{m}.$$
Here, $m,n,l \geq 0$ are fixed and $l \leq m+n$. Also assume that $\binom{x}{y} = 0$ whenever $x < y$. I verified this identity for small values of $m$, $n$ and $l$, and I think I have come up with a combinatorial argument for why this identity is true. Can someone please verify it for me? Proof. The RHS is the number of ways of choosing $m$ objects out of a collection of $m+n$ distinct objects. We can make this selection in the following way as well. Divide the collection into two distinct bunches of $l$ objects and $m+n-l$ objects. We can select $m$ objects out of our $m+n$ objects by selecting $i$ objects from the $l$-bunch and the remaining $m-i$ from the $(m+n-l)$-bunch, for each possible value of $i$ between $0$ and $m$ (in the sense that we don't try to select more than $l$ objects out of our first bunch, or more than $m+n-l$ objects out of our second bunch). But, this is nothing but the expression on the LHS. Is my proof valid? I would be grateful if someone can provide alternative proofs of this identity as well. Thanks in advance!","['combinatorics', 'binomial-coefficients', 'alternative-proof', 'proof-verification']"
2803923,Attaching prime numbers,"Yesterday, I was playing around with prime numbers just for amusement and thus became aware that sometimes 'attaching' two prime numbers will result in another prime number. Let me explain my idea by an example. The numbers $3$ and $7$ are prime numbers, and when we write them in succesive order, we obtain the prime number $37$. Similarly, $7$ and $19$ are prime numbers, as well as $719$. There can be found many more such examples. I am wondering if there is some kind of pattern or rule, by which one can see whether attaching two given prime numbers will result in a prime number or not? Does anyone know something in this direction? Best wishes","['number-theory', 'prime-numbers', 'arithmetic']"
2803956,What is the lie algebra of the group of automorphisms of a lie algebra?,"Let $\mathfrak{g}$ be a Lie algebra. Then its automorphism group $Aut(\mathfrak{g})$ is a Lie group, and hence we may take its Lie algebra $Lie(Aut(\mathfrak{g}))$. I'd like to say that this is equal to the Lie algebra of derivations $Der(\mathfrak{g})$. Is this true? Where can I find a reference?","['group-theory', 'geometry', 'differential-geometry', 'lie-algebras', 'lie-groups']"
2803972,Which integers can be written as $x^2+2y^2-3z^2\ $?,"For which integers $n$ has the diophantine equation $$x^2+2y^2-3z^2=n$$ solutions ? These theorems https://en.wikipedia.org/wiki/15_and_290_theorems do not apply because the given quadratic form is not positive (or negative) definite. It seems that the quadratic form is universal (for every integer $n$ a solution exists) , but I have no idea how this can be proven.","['number-theory', 'diophantine-equations', 'representation-theory', 'elementary-number-theory']"
2803973,probability that a candidate comes with all $3$ pens having the same colour is $?$,"Question I know this is a duplicate of this , i am still posting it because i want to know flaw in my approach. Candidates were asked to come to an interview with $3$ pens each. Black, blue, green and red were the permitted pen colours that the candidate could bring. The probability that a candidate comes with all $3$ pens having the same colour is $?$ My Approach Let $E=\text{chossing all three pen of same colour}=\binom{4}{3} \times 1 \times 1 \times 1=4$ i.e select which colour among red,blue,green and black and then there will be only $1$ choice Let $F=\text{possible way of selecting 3 pen}=4 \times 4 \times 4$ As there are $4$ ways to select colour of the pen and we have to choose for $3$ pens. Hence reqd probability $$=\frac{E}{F}$$ $$=\frac{4}{4 \times 4 \times 4}=\frac{1}{16}=0.0625$$ Where am i wrong?
Please help!","['probability', 'discrete-mathematics']"
2804007,Is image of ball of finite rank linear operator compact?,"Let $X$ be a complex Banach space and $A:X\to \mathbb{C}^{n}$ be a continuous linear map. If $B_{X} = \{x\in X\,:\, ||x||\leq 1\}$ is a closed unit ball in $X$, is it true that $A(B_{X})$ is compact in $\mathbb{C}^{n}$? 
Since every finite rank operator is compact operator, we know that the closure $\overline{A(B_{X})}$ is compact, but I can't verify that the image $A(B_{X})$ itself is compact, although it seems true.",['functional-analysis']
2804009,How to Show that an $n$-finned Hyperplane is not Homeomorphic to $\mathbb{R}^m$,"This question came up again in an algebraic topology course, so I'm placing a bounty on it.  The answers below use algebraic topology - I am asking for a proof that does not use algebraic topology, e.g. homology, higher homotopy groups, or the Jordan Curve/Separation Theorem.  No smooth structures, just point-set stuff. Original question: Suppose that $X_n$ is the union of $n$ half closed, straight line segments, all joined at a common point (their boundary point).  So $X_2$ is just an open interval, and otherwise is an $n$ -pointed asterisk with open ends.  How can one show that for $n \geq 2$ all the spaces $X_n \times \mathbb{R}$ are topologically distinct? These spaces are like $n$ sheets attached along a copy of $\mathbb{R}$ . More generally if we take $n$ copies of the $k$ -dimensional closed half-space $\mathbb{H}^k$ and identify them along a $(k-1)$ -plane, how do we show that this space is not homeomorphic to $\mathbb{R}^k$ for $n > 2$ ? Discussion: In the more general form, the $n=1$ case is known to be equivalent to the Invariance of Dimension Theorem, but for $n > 2$ it seems more geometrical that the spaces aren't homeomorphic. Be careful trying to use a fact like ""a homeomorphic image of a hyperplane disconnects Euclidean space into two pieces.""  This may be the key ingredient, but would need a point-set proof; I only know of algebraic ones. There is a theorem of Moore, simplified by Bing, that there is no uncountable collection of copies of a simple triod (three arcs attached at a common vertix, i.e. a three-legged asterisk) contained in the plane.  There is a Cantor Set of them along the spine of our three-finned 'plane.'  However, the proofs of this theorem depend crucially on the Jordan Curve Theorem and its corollaries.  It has higher-dimensional analogues, but they also depend on the higher-dimensional form of the Jordan Separation Theorem. Similarly, evaluating the simplicial complex structures could differentiate them, but that is a lot of theory.  If we look at neighborhoods on, say, $X_3 \times \mathbb{R}$ of the points along the 'spine' we will get connected neighborhoods whose boundaries are the theta curve.  It can be shown that no connected set has boundary of a theta curve in $\mathbb{R}^2 = X_2 \times \mathbb{R}$ and this method also generalizes inductively, but again the details are not trivial and we are depending on at least the polygonal version of the Jordan Curve Theorem.  Putting a circle into one of the legit-planes doesn't separate an $n$ -finned plane; similarly (equivalently, as an aside), the complete bipartite graph $K_{3,3}$ embeds in it. Yet another method would be counting the number of components that removing the spine creates, which could distinguish $X_2$ from the others but seems harder to generalize.  This is one of the classic separation theorems, that a hyperplane cuts Euclidean space into two components, but we can't assume it. And generalizing any of these methods (except for analyzing as complexes) to higher dimensions seem to have even more difficulties, for example by attaching three copies of threespace to a plane.  There is also the possibility of using symmetry groups and relating those to the bundle structure, but again it would use a lot of theory. What is the point-set way to prove this?  Or is it equivalent to Jordan Curve Theorem, which would be really interesting?","['continuum-theory', 'euclidean-geometry', 'algebraic-topology', 'geometric-topology', 'general-topology']"
2804086,Abuse of notation with distributions,"A distribution is an element of the continuous dual space of some function space. Let us take the Schwartz space $\mathcal{S} := \mathcal{S}(\mathbb{R}^n)$ just as an example. A distribution $\phi \in \mathcal{S}'$ is then a map
$$ \phi: \mathcal{S} \rightarrow \mathbb{C}.$$ My question is this: how do I interpret $\phi(x)$? I see this written a lot, but I don't understand how to work with it. What does for example $\phi(x) = \phi(-x)$ mean? The only thing I can think of is that $\phi(f) = \phi(\hat{f})$, where $\hat{f}(x) = f(-x)$. And more specifically for the problem I'm working on: I have a distribution
$$ \mathcal{W} : \mathcal{S}(\underbrace{\mathbb{R}^4 \times \dots \times \mathbb{R}^4}_{n \text{ times}}) \rightarrow \mathbb{C} $$ and then they say that $\mathcal{W}$ is translation invariant, i.e.
$$\mathcal{W}(x_1 +a,\dots, x_n + a) = \mathcal{W}(x_1,\dots,x_n)$$
so it can be writthen as a distribution $\mathfrak{W}$ that only depends on the differences $x_1-x_2,\dots,x_{n-1} - x_n$:
$$\mathcal{W}(x_1,\dots,x_n) = \mathfrak{W}(x_1-x_2,\dots,x_{n-1}-x_n).$$ How do I interpret this last line?","['functional-analysis', 'distribution-theory', 'schwartz-space', 'notation']"
2804129,To Evaluate the Limit $\lim_{n \to \infty}\left(1+\sum_{k=1}^{n} \frac{1}{\binom{n}{k}}\right)^n$,To Evaluate the Limit $$L=\lim_{n \to \infty}\left(1+\sum_{k=1}^{n} \frac{1}{\binom{n}{k}}\right)^n \tag{1}$$ My try: I tried to use $$\frac{1}{\binom{n}{k}}+\frac{1}{\binom{n}{k+1}}=\frac{n+1}{n} \frac{1}{\binom{n-1}{k}} $$ taking summation both sides from $k=1$ to $k=n$ we get $$\sum_{k=1}^{n} \frac{1}{\binom{n}{k}}+\sum_{k=1}^{n} \frac{1}{\binom{n}{k+1}}=\frac{n+1}{n} \sum_{k=1}^{n} \frac{1}{\binom{n-1}{k}} \tag{2}$$ Now let $$S=\lim_{n \to \infty} \sum_{k=1}^{n} \frac{1}{\binom{n}{k}}$$ we have from $(2)$ $$S+S=S$$ hence $$S=0$$ Now $(1)$ is in form of $1^{\infty}$ Indeterminate form whose limit is given by $$L=e^\left({\lim_{n \to \infty}}n \times \sum_{k=1}^{n} \frac{1}{\binom{n}{k}}\right)$$ How to proceed now?,"['derivatives', 'limits', 'algebra-precalculus', 'convergence-divergence', 'sequences-and-series']"
2804155,The Fourier transform is unbounded from $L^{p}$ to $L^{p^{\prime}}$ when $2<p\leq \infty$?,"I previously asked this question here Haussdorff-Young inequality optimal Lebesgue exponents range and got a comment that referred me to the answer here Fourier transform in $L^p$ but I did not find the answer to my specific question: What (where can one find) argument/counterexamples  that shows 
the discontinuity of the Fourier transform from $L^{p}$ to $L^{p^{\prime}}$ when $2<p\leq \infty$ ?","['real-analysis', 'fourier-analysis', 'harmonic-analysis', 'dispersive-pde', 'analysis']"
2804185,Proof of trig identity using t-formulae,"Show that $$2\arctan x = \arccos\frac{1-x^2}{1+x^2}$$ if $ x > 0$, and 
$$2\arctan x = -\arccos\frac{1-x^2}{1+x^2}$$ if $x <0.$ I have been able to equate the expressions by letting $x=\tan(y/2)$, but I do not know how to show the different signs of the equation for $x>0$ and $x<0$.","['algebra-precalculus', 'trigonometry']"
2804186,PDE : $x^2 z_x + y^2 z_y = z(x+y)$,"Solving the PDE $$x^2 z_x + y^2 z_y = z(x+y)$$ I came across an error in my calculations which I cannot find : $$\frac{\mathrm{d}x}{x^2}=\frac{\mathrm{d}y}{y^2}=\frac{\mathrm{d}z}{z(x+y)}$$ The first integral curve is given as : $$\frac{\mathrm{d}x}{x^2}=\frac{\mathrm{d}y}{y^2}\implies z_1 = \frac{1}{x} - \frac{1}{y}$$ Now, for the second integral curve, I use the following differential subtraction trick to get rid of the $(x+y)$ term : $$\frac{\mathrm{d}x-\mathrm{d}y}{x^2-y^2}=\frac{\mathrm{d}z}{z(x+y)}$$
$$\Rightarrow$$
$$\frac{\mathrm{d}(x-y)}{x-y} = \frac{\mathrm{d}z}{z}$$
$$\implies$$
$$z_2 = \frac{z}{x-y}$$ And thus the general solution is :
$$z_2=F(z_1)\Rightarrow z(x,y)=(x-y)F\bigg(\frac{1}{x}-\frac{1}{y}\bigg)$$
where $F$ is a $C^1$ function of $x$ and $y$. Wolfram Alpha though, states that the solution is $z(x,y)=xyF(1/x-1/y$), which means that I have found the integral curve $z_2$ wrong. I cannot find any fault in my calculations though. The correct integral curve should be :
$$z_2 = \frac{z}{xy}$$
How would one come to this calculation though ? I would really appreciate your help","['multivariable-calculus', 'integration', 'ordinary-differential-equations', 'partial-differential-equations']"
2804236,Integral $I=\int_0^1 \frac{\ln x\arctan(ax)}{1+b^2x^2}dx$,"Greetings I am trying to evaluate  $$I=\int_0^1 \frac{\ln x\arctan(ax)}{1+b^2x^2}dx$$ Where $a$ and $b$ are positive numbers. My try was to derivate the integral with respect to $a$ in order to get: $$I'(a)=\int_0^1 \frac{\ln x}{(1+a^2x^2)(1+b^2x^2)}dx=\frac{1}{a^2-b^2}\left(\int_0^1\frac{a^2\ln x}{1+a^2x^2}dx-\int_0^1\frac{b^2\ln x}{1+b^2x^2}dx\right)$$  expanding into geometric series using: $$\frac{1}{1+x}=\sum_{n=0}^{\infty}(-1)^nx^n$$ $$I'(a)=\frac{1}{a^2-b^2}\left(a^2\sum_{n=0}^{\infty}(-1)^na^{2n}\int_0^1x^{2n}\ln xdx-b^2\sum_{n=0}^{\infty}(-1)^nb^{2n}\int_0^1x^{2n}\ln xdx\right)$$ Using the following relation:$$I(k)=\int_0^1x^{2k}dx=\frac{1}{2k+1}\rightarrow I'(k)=\int_0^1 x^{2k}\ln xdx=\frac{-2}{(2k+1)^2}$$ gives: $$I'(a)=\frac{1}{a^2-b^2}\left(-2a\sum_{n=0}^{\infty}(-1)^n\frac{a^{2n+1}}{(2n+1)^2}+2b\sum_{n=0}^{\infty}(-1)^n\frac{b^{2n+1}}{(2n+1)^2}\right)$$ $$I'(a)=\frac{2}{a^2-b^2}\left(b\sin b-a\sin a\right)$$ And finally $$I=I(a)=2\int \frac{b\sin b- a\sin a}{a^2-b^2}da$$ Now I am stuck, could you help me finish this? And do I have any mistakes? Edit: With the mistake pointed in the comments it yields to: $$I'(a)=\frac{2}{a^2-b^2}\left(\sum_{n=1}^{\infty}(-1)^n\frac{a^{2n}}{(2n)^2}-\sum_{n=1}^{\infty}(-1)^n\frac{b^{2n}}{(2n)^2}\right)=\frac{1}{2}\frac{1}{a^2-b^2}(Li_2(-a^2)-Li_2(-b^2))$$","['integration', 'proof-verification', 'closed-form']"
2804241,General term of a sequence.,"So i have the following sequence: ${1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, ...}$ Where the number $i$ appears $i + 1$ times. I would like to know the $n$-th term of this sequence. I tried to analise certain patterns within the sequence, but wasn´t able to conclude anything so far.",['sequences-and-series']
2804261,Existence of Riemannian Metric,"How can we show using coordinate transformations that every smooth manifold $M$ has at least one Riemannian Metric? This is one of the problems in my past finals on Calculus on Manifolds, and it seems very puzzling to me as I do not even know where to start. Can anyone at least give me some hints or some start so I can try to finish it? My Solution: Using the hints and applying the idea of partitions of unity, first let us define the local parametrisation $\Lambda=\{F_{\alpha}:U_{\alpha}\rightarrow O_{\alpha}\}$ which covers some smooth manifold $M,$ and let the partitions of unity subordinate to $\Lambda$ be denoted by $\{\rho_{\alpha}:U_{\alpha}\rightarrow [0,1]\}$. Now we can denote the $(2,0) -$ tensor as :
$$\delta_{\alpha}=\sum^n_{j=1}du^j_{\alpha}\otimes du^j_{\alpha}$$
Then it remains to show that the below expression is smooth and symmetric and positive definite:
$$\mathcal{M}=\sum_{\alpha}\rho_{\alpha}\delta_{\alpha}$$
Now it is not hard to see that it indeed is symmetric and smooth, so we just need to check the positive definite condition. Let us introduce some vectors for computations, notably $X=\sum_i X^i_{\beta}\frac{\partial}{\partial u^i_{\beta}}$, then we simply compute the metric using this vector which can be done in the following way: $$\mathcal{M}(X,X)=\sum_{\alpha}\sum^n_{j=1}\rho_{\alpha}du^j_{\alpha}\otimes du^j_{\alpha}\big(\sum_i X^i_{\beta}\frac{\partial}{\partial u^i_{\beta}},\sum_k X^k_{\beta}\frac{\partial}{\partial u^k_{\beta}}\big)$$
$$=\sum_{\alpha}\sum_{j,p,q}\rho_{\alpha}\frac{\partial u^{j}_{\alpha}}{\partial u^{p}_{\beta}}\frac{\partial u^{j}_{\alpha}}{\partial u^q_{\beta}}du^p_{\alpha}\otimes du^q_{\alpha}\big(\sum_i X^i_{\beta}\frac{\partial}{\partial u^i_{\beta}},\sum_k X^k_{\beta}\frac{\partial}{\partial u^k_{\beta}}\big)$$
$$=\sum_{\alpha}\sum_{i,j,k}\rho_{\alpha}\frac{\partial u^{j}_{\alpha}}{\partial u^{p}_{\beta}}\frac{\partial u^{j}_{\alpha}}{\partial u^q_{\beta}}X^i_{\beta}X^k_{\beta}$$
$$=\sum_{\alpha}\rho_{\alpha}\sum_{j}\bigg(\sum_{i}X^i_{\beta}\frac{\partial u^{j}_{\alpha}}{\partial u^i_{\beta}}\bigg)^2\ge 0$$ Hence it is positive definite and we are done. Is this how you do it?","['riemannian-geometry', 'differential-geometry']"
2804281,"If $\exists f''(0)$, show $\lim _{h \rightarrow 0} \frac{f(h)-2f(0)+f(-h)}{h^2}=f''(0)$","Suppose $f$ is differentiable and $\exists f''(0)$ .
I want to show $$\lim _{h \rightarrow 0} \frac{f(h)-2f(0)+f(-h)}{h^2}=f''(0)$$ not using the L'hospital rule. I know how to calculate with L'hospital rule, but I cannot see how otherwise.","['derivatives', 'analysis', 'calculus', 'limits']"
2804314,${3^n\choose k}$ is divisible by $3$?,How can I prove that ${3^n\choose k}$ is divisible by $3$ for all positive integer values of $n$? (where $k$ is any positive integer smaller than $3^n$) Can you use induction? Thanks.,"['combinatorics', 'binomial-coefficients', 'induction', 'divisibility']"
2804319,Smooth Logarithm at zero/one with special conditions,"As part of a bigger problem it turned out that the function $$V: \Bbb R \rightarrow [0,\infty ), \,  V(x) := \begin{cases} 0 &:  x \leq 1 \\ \log(x) &: x > 1 \end{cases}$$
would help me alot if it was smooth or rather $C^2$. There would be a way out of this by taking/searching a new function $\varphi: \Bbb{R} \rightarrow [0,\infty) $ instead of $V$ with the following conditions for a $\varepsilon > 0$: $\varphi|_{(-\infty,1-\varepsilon] \cup [1+\varepsilon,\infty)} = V$ $\varphi \geq V $ $\varphi \in C^2(\Bbb R)$ How can I show the existence of such an $\varphi$?","['derivatives', 'real-analysis', 'analysis', 'logarithms']"
2804321,Infinitely many $n$ such that $2^n$ in base $10$ starts with $7777777$,"I'm attempting to prove that there are infinitely many $n$ such that the first $7$ digits in the base $10$ expressions of $2^{n}$ are $7777777$. However, I don't even know where to start. Apparently I'm supposed to use the fact that the set
$$\{x_{n} = n\alpha-\lfloor n\alpha \rfloor \mid n \in \mathbb{N}\}$$
is dense in $[0,1]$, for a fixed irrational $\alpha \in \mathbb{R}$ (I've already proven this).  Any help would be appreciated! (I'm more looking for a hint not a solution)","['real-analysis', 'irrational-numbers', 'ceiling-and-floor-functions']"
2804327,Sum of Discrete Uniform Variables times extraction index,"Let $X_i$ be the $i-th$ extraction from an urn with $N$ balls numbered from $1$ to $N$.
Let's make $N$ extractions without replacement, so that that the urn is left without balls. Let $Y_i = X_i \cdot i$ basically multiplying the number written on the extracted ball by the index of the extraction. Obviously $\Bbb E(Y_i) = i \cdot \frac{N+1}{2}$ You can get $Var(Y_i) = \frac{i^2(N^2-1)}{12}$ My question is $Var(\sum_{i=1}^N Y_i)$ Expected value of the sum is quite easy to find so let's assume we have it, any idea guys?","['probability-theory', 'probability', 'statistics', 'variance']"
2804334,"Is the dual to $C^1[0,1]$ separable?","$C^1[0,1]$ is endowed with the norm $\|f\| = \sup_{t \in [0,1]}|f| + \sup_{t \in [0,1]}|f'| $. I need to check if its dual $(C^1[0,1])^*$ is separable (I hope it is not). I am asking for the answer and the idea of proof.","['functional-analysis', 'separable-spaces', 'dual-spaces']"
2804340,"Number of functions from $A=\left\{1,2,3,4,5\right\}$ to $B=\left\{0,1,2,3,4,5\right\}$ such that $f(i) \ne i$","Find Number of functions from $A=\left\{1,2,3,4,5\right\}$ to $B=\left\{0,1,2,3,4,5\right\}$ such that $f(i) \ne i$ My try: I introduced fictitious element $x=0$ in set $A$ and now counted number of derangements which is $d_6=265$ In all these $265$ functions i will remove the mapping of zero which is Fictitious. Also number of functions in which $0$ maps to $0$ and $f(i) \ne i$ is $d_5=44$ Hence Total number of functions is $309$","['combinatorics', 'functions']"
2804360,Number of oscillations of a Gaussian convolution,"Let $f(x)=e^{-x^2/2}$ and $g(t)$ be some symmetric, positive and  bounded function and let the convolution of $f(x)$ and $g(x)$ be defined as follows:
\begin{align}
h(x)= \int f(x-t)g(t)\, dt.
\end{align} My questions is: Suppose we choose some value of $y=c$.  How many times does the function $h(x)$ equals $c$ on some interval $[-a,a]$? In other words, can we say something about the number of zeros of the function  on $[-a,a]$
\begin{align}
F(x)= h(x)-c. 
\end{align}
Let $S_a(F)$ denote the set of zeros of $F$ on $[-a,a]$. Partial Answer: Because convolution ""increases"" analyticity we have that $h(x)$ and  $F(x)$ are analytic. Therefore, by the standard identity theorem argument, we have that   $F(x)$ can have finitely many zeros on any interval $[-a,a]$. So, $S_a(F)$ is a finite set. My question: Can we say more about the cardinality of the set of zeros $S_a(F)$? In particular, can we give a bound on it? Most likely a uniform bound is impossible. However, I think we can give a bound that depends on $h(x)$. Comment I would also appreciate a reference if this question been addressed before.  Also, if you can think of some keywords that would be great too.","['gaussian-integral', 'complex-analysis', 'real-analysis', 'convolution']"
2804396,Which estimator is better here?,"Let $X_1, X_2, \ldots, X_n$ be a random sample from a population with pmf
$$P_\theta(X=x)=\theta^x(1-\theta)^{1-x}, \quad x=0,1; \qquad 0 \leq \theta \leq \frac{1}{2}$$
Compare the method of moment estimator (MME) and the maximun likelihood estimator (MLE), which one is preferred? Since $E(X)=\theta$, so $\hat{\theta}_\text{MME}=\bar{X}$ anyway (what if $\bar{X} > \frac{1}{2}$?). And by writing out the likelihood function and taking derivative I got
$$\hat{\theta}_\text{MLE}=\begin{cases}\bar{X} & \text{ if }0\leq \bar{X} \leq \frac{1}{2}\\ \frac{1}{2} & \text{ if } \bar{X}>\frac{1}{2}\end{cases}$$
It seems the MLE is better, but is there a justification here?","['parameter-estimation', 'statistics', 'mean-square-error', 'statistical-inference']"
2804398,let $G$ be a simple $n$-vertex graph with at least $2n−3$ edges. Prove that $G$ has two cycles of equal length.,"Show that if G is a simple graph with at least 4 vertices and 2n-3 edges, it must have two cycles of the same length. I'm really confused about the answer here, from the part that : 
Each of these edges creates a cycle of length between 3 and |V(cj)| when joined with T.... thank you !!","['graph-theory', 'trees', 'discrete-mathematics']"
2804404,Show measure zero: application of Theorem 1 in Lang (1986)?,"Suppose I have a random variable $Y$ with support $\{1,2,..., M\}$. Consider a random vector $V\equiv (V_1, V_2,..., V_M)$ with support $\mathcal{V}\subseteq \mathbb{R}^M$ with positive Lebesgue measure. By definition of support we know that $\mathcal{V}$ is a closed set (see here for example). All random variables/vectors are defined on the probability space $(\Omega, \mathcal{F}, \mathbb{P})$. For any $j\in \{1,...,M\}$, let $$\mathcal{V}_j\equiv \{v\equiv (v_1,..., v_M)\in \mathcal{V} \text{ s.t. } v_j\geq v_k \text{ }\forall k\in \{1,...,M\} \text{ with } k\neq j\}$$ Hence, $\{\mathcal{V}_1, ..., \mathcal{V}_M\}$ constitutes a partition of $\mathcal{V}$. Assumption A1: $V$ has a distribution absolutely continuous with respect to Lebesgue measure on $\mathcal{V}$ Assumption A2: $Y\in argmax_{k\in \{1,...,M\}} V_k$ with probability 1. Question 1: Is it true that $\mathcal{V}_j$ is closed and convex? Question 2: Under which sufficient conditions I can claim $$\mathbb{P}(Y=j)=\mathbb{P}(V\in \mathcal{V}_j)$$ $\forall j\in \{1,..., M\}$. Attempted answer 1: we know that if $\mathcal{V}=\mathbb{R}^M$, then $\mathcal{V}_j$ is closed and convex (see here , for example). When $\mathcal{V}\subset \mathbb{R}^M$, I think (can you confirm?) we can generalise the same results for any closed $\mathcal{V}\subset \mathbb{R}^M$. Attempted answer 2: by A1 , I am tempted to naively set up the following proof: wlog take $M=2$; for any $v\in \mathcal{V}$, suppose there exists $\{y,y'\}\subseteq argmax_{k\in \{1,2\}} v_k$ with $y\neq y'$. This can be the case if and only if 
$$
v_{y '}-v_y=0
$$
which is an event happening with probability measure zero, by A1, i.e.,
$$
\mathbb{P}(V \in \{v\in \mathcal{V} \text{ s.t. } v_1=v_2\} )=0
$$
Therefore, $argmax_{k} V_k$ is a singleton set almost surely. This implies (not sure!)
$$\mathbb{P}(Y=j)=\mathbb{P}(V\in \mathcal{V}_j)$$ $\forall j\in \{1,2\}$. Doubts on the attempted answer 2: my attempted proof does not use the fact that $\mathcal{V}$ is closed or the fact that $\mathcal{V}_j$ is closed-convex. However, I am confused by Theorem 1 in Lang (1986) , which claims that under A1 and if $\mathcal{A}$ is a convex subset of $\mathcal{V}$ , then $\mathbb{P}(V \in\partial \mathcal{A})=0$, where $\partial \mathcal{A}$ denotes the boundary of $\mathcal{A}$. Any help to clarify? Is this Theorem relevant for my case? Referring to the case $M=2$, is $\partial \mathcal{V}_1\neq  \{v\in \mathcal{V} \text{ s.t. } v_1=v_2\}$?","['absolute-continuity', 'convex-analysis', 'probability', 'measure-theory', 'general-topology']"
2804424,"Evaluate indefinite integral $\int \tan(\frac{x}{3}) \, dx$","I need help verifying why I am getting an incorrect answer for the question evaluate the integral 
$$\int \tan\left(\frac{x}{3}\right) \, dx$$ I simplify the above equation using trig identities to get
$$\int \frac {\sin \left(\frac{x}{3}\right)}{\cos\left(\frac{x}{3}\right)} \, dx$$ I use the substitution method to find 
$$ du = -\frac{1}{3} \sin(x/3) \, dx$$ and so $dx = \frac{-3\,du}{\sin\frac{x}{3}}$ I plug the $u$ back into equation
$$ \int \frac {\sin\left(\frac{x}{3}\right)}{u} \cdot\frac {-3\,du}{\sin \left(\frac{x}{3}\right)}$$ I cross out the $\sin \left(\frac{x}{3}\right)$ and (this is where I may be going wrong), I pull out the $-3$ to be in front of the integral sign since it is a constant and solve for
$$-3 \int \frac{1}{u} \, du$$ and get the final answer $$ -3 \biggl|\,\ln \, \cos \frac{x}{3}\biggr| + C $$ But the answer in the back of the book is $ -\frac{1}{3} |\ln \, \cos \frac{x}{3}| + C $","['indefinite-integrals', 'integration', 'calculus', 'proof-verification']"
2804445,Differentiability of the Riemann function,"I have defined the function $\zeta : (1, +\infty) \longrightarrow \mathbb{R}$ defined as: $$\zeta(x) = \sum_{n=1}^{+\infty} \frac{1}{n^x}$$ I have to study the differentiability of this function. I have tried to use the theorem that allows you to swap summation and derivative, but I don't know how to prove that $\sum_{n=1}^{+\infty} g'(x)$ converges uniformly, necessary to use the theorem, where $g(x) := \frac{1}{n^x}$","['derivatives', 'real-analysis', 'riemann-zeta', 'riemann-integration']"
2804455,The maximum light intensity coming from two light bulbs on the $xy$-plane,"There is two light bulbs, one on $(-a,0,2)$ and the other on $(a,0,2)$, where $a>0$. The light intensity coming from two light bulbs on the $x$-axis and $y$-axis (where $z=0$) can be calculated using the following equation:
$$f(x,y) = \frac{1}{(x+a)^2+y^2+2^2} + \frac{1}{(x-a)^2+y^2+2^2}.$$
My question is, how to find the maximum point(s) (or critical points) of $f$. Notes: There can be one or two critical points, depending on $a$.","['multivariable-calculus', 'calculus']"
2804457,Simplify $\Gamma\left(\frac27\right) \Gamma\left(\frac{11}{42}\right)/\;\Gamma\left(\frac1{21}\right)$ to elementary terms,"How can we prove the following identity?
$$\large \frac{\Gamma\left(\frac27\right) \Gamma\left(\frac{11}{42}\right)}{\Gamma\left(\frac1{21}\right)} = \frac{8 \sin\left(\frac\pi7\right) \sqrt{\pi \, \sin\left(\frac\pi{21}\right) \sin\left(\frac{4\pi}{21}\right) \sin\left(\frac{5\pi}{21}\right)}}{\sqrt[42]2 \; \sqrt[3]7 \; \sqrt[28]{19683}}$$
I guess we could use the Gauss multiplication formula , but how?","['special-functions', 'trigonometry', 'gamma-function', 'calculus']"
2804495,Puzzling Double integral,"I was asked to solve this double integral:
Compute the area between $y=2x^2$ and $y=x^2$ and the hyperbolae $xy=1$ and $xy=2$ in $$ \iint dx \,dy$$ I tried to solve it starting with considering that $$x^2 \leq y \leq 2x^2 $$ suitabile for integration interval in $y$, obtaining the incomplete form $$ \int^{x^2}_{2x^2} \int_\ldots^\ldots dx \,dy$$ but I also have
$$1 \leq xy \leq 2$$ and I would obtain a result in which I still have one independent variabile. Please, can anyone help me? Thanks in advance.","['lebesgue-integral', 'integration', 'definite-integrals', 'analysis']"
2804558,"Is there a way to phrase ""continuous"" in terms of ""connected""?","This is something of a pedagogical question. Most of us have scratched our heads at some point as to why the definition of ""$f$ is continuous"" requires that the pre image of any open set under $f$ is open, then done a bunch of examples, then convinced ourselves. I think our confusion comes because when we first encounter ""continuity"" we are generally expecting a statement about what $f$ does to the images of sets, and get frustrated when we see a statement about what $f$ guarantees about the preimages of sets. I think that we might be able to restore this by instead looking at subspaces of the topological space and whether they are connected according to their subspace topology. Let's call a subset of a topological space which is connected according to its subspace topology a ""connected subset"". Connectedness is inherently a negative notion (""there does not exist two open sets..."") and thus one is naturally induced to look at a contrapositive -- at images rather than preimages. So I think there might be a way to start from a more-intuitive definition, for example: ""$f: X \to Y$ is continuous iff $X$ and $Y$ are topological spaces and the image of any connected subset of $X$ is a connected subset of $Y$."" This would seem immediately intuitive to a student, I feel. And if we start from there, then immediately the contrapositive accomplishes the reversal: ""$f: X \to Y$ is continuous iff the preimage of any disconnected subset of $Y$ is a disconnected subset of $X$."" Now it's clear that the latter is necessary for $f$ to be continuous according to the conventional definition. If $f$ is conventionally-continuous  then when we factor a disconnected subset of $Y$ into two disjoint open subsets, the preimage of each subset is open and the preimages of two disjoint sets must also be disjoint, proving that the subset of $X$ was disconnected, too. However I am struggling with rigorously proving sufficiency and thereby deriving the conventional definition from the intuitive one. The existential quantifiers of disconnectedness seem to really get in my way: for example even if I could somehow state ""for every nonempty open set there exists some other disjoint nonempty open set"" (which is false for the trivial topology but maybe that's not such an issue) the above definition seemingly does not guarantee that the corresponding preimages of the two are open -- maybe this partition of the $Y$-subset has very little to do with the partition of the $X$-subset, for example. So it's not clear to me how to push past these weird existentials and come to ""the preimage of any open set is open"" again. Am I missing some obvious counterexample that shows this whole enterprise is a mistake, or clarifies some extra assumptions I'll need in my definition to make it work? If not, what technique might I use to finish the sufficiency side of the proof?","['continuity', 'general-topology', 'education', 'connectedness']"
2804569,Is the set $\{X \in \mathcal{M}({m \times n}) : \rho(M-NX) < 1\} $ connected?,"Suppose $M \in \mathcal M(n \times n; \mathbb R)$ and $N \in \mathcal M(n \times m; \mathbb R)$ are fixed with $N\neq 0$. Let
\begin{align*}
  E =  \{X \in \mathcal{M}(m \times n; \mathbb R) : \rho(M-NX) < 1\},
\end{align*}
where $\rho(\cdot)$ denotes the spectral radius of a square matrix. We assume $E$ is not empty. This set is open. (see my other question concerning the closure). I would also like to know whether it is connected. In this case, equivalently, is the set path-connected?","['general-topology', 'linear-algebra', 'path-connected', 'connectedness']"
2804571,Monomial characters of direct product,"Let $G$ be a finite group and let $\text{Irr}(G)$ be the set of irreducible complex characters of $G$ . A character $\chi\in\text{Irr}(G)$ is monomial if there exists a subgroup $H\leq G$ and a linear character $\lambda\in\text{Lin}(H)$ such that $\chi=\lambda^G$ . Let $\text{Irr}_m(G)$ be the set of irreducible monomial characters of $G$ . Then a group $G$ is monomial if $\text{Irr}(G)=\text{Irr}_m(G)$ . I'm interested in solvable groups even if probably this is not necessary. My question is : given two finite solvable groups $G$ and $H$ is it true that $$\text{Irr}_m(G\times H)=\{\varphi\times \psi\mid \varphi\in\text{Irr}_m(G),\psi\in\text{Irr}_m(H)\}$$ Using GAP I checked some (really small) cases and this always works. What is this useful for? I'm interested in this question because a positive answer will give an easy way to construct a family of solvable groups $(G_n)_{n\in\mathbb{N}}$ such that $$\lim\limits_{n\to \infty} \frac{|\text{Irr}_m(G_n)|}{|\text{Irr}(G_n)|}=0$$ To construct such a family fix a solvable nonmonomial group $G$ (e.g. $\text{SL}_2(3)$ ) and define $G_n$ to be the direct product of $n$ -copies of $ G$ . Update: The above question has a negative answer, in general, by work of van der Waall ""Direct products and monomial characters"". However, a positive answer is given when at least one of the factors, say $G$ , satisfies the following property: either $G=1$ or every maximal subgroup $M$ of $G$ has a normal subgroup $N\unlhd M$ with only abelian Sylow subgroups (for every prime) and such that $M/N$ is nilpotent. In particular, the above family can be constructed considering $G=\text{SL}_2(3)$ .","['finite-groups', 'representation-theory', 'group-theory', 'characters']"
2804632,Are infinite groups permutation groups?,"I have known Cayley's Theorem for some time now, which shows that all finite groups are permutation groups ( secretly , as a previous mathematics teacher of mine might have put it). However, the thought occurs to me whether we can prove that this is true for infinite groups. In this amazing MO answer , they show what appears to a construction of what I now call the Mother Class-Group, but only implicitly suggest that this contains all other groups as sub-groups. Why is it? Is it to do with the fact that all finite groups are linear?","['permutations', 'infinite-groups', 'group-theory', 'elementary-set-theory']"
2804754,Trigonometric equation: $2\arcsin \left(\frac{2x}{1+x^2}\right)- \pi x^3 = 0$,The number of solutions of the equation $$2\arcsin \left(\dfrac{2x}{1+x^2}\right)- \pi x^3 = 0$$ is? Let $x= \tan \theta$ $\implies \sin 2\theta = \sin(\dfrac \pi 2 \tan^3\theta)$ I had to delete the rest of my attempt because it was totally wrong. What are the methods to solve this problem?,"['trigonometry', 'calculus']"
2804788,How many ways can a row of lights be turned on and off,"Say you have a row of 4 lights. Each light-bulb can be turned on/off independently.  How many lighting combinations could you come up with? My research: Before asking this question I searched the forum to make sure this wasn't a duplicate. I found similar questions, but they had restrictions which I'm not imposing. For example this question required that a number of lights always be left on, and this question imposed a lighting pattern. I simply want to know without restrictions how many combinations there could be. Reading the answers to the linked questions above I learned about Pascals triangle . Studying the triangle it appeared to me that the number of combinations possible for N (the number of lights in a row) is the sum of all the numbers in the row of pascal's triangle that has the same amount of numbers as n+1. For example if I had 1 light, there are 2 combinations, on or off. Pascals second row (the number of lights + 1) the sum of that row adds up to 2. Thus representing the total number of combinations. Is that correct, and if it is, is there a more formal algorithm to represent this sort of problem without having to draw out a pascal triangle for large data-sets?",['combinatorics']
2804816,Why isn't Fourier Series taught in calculus 2? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 6 years ago . Improve this question I am self taught and have read the book ""Essential Calculus ETF"" by Larson and Hosteller from cover to cover and have since been evaluating the more difficult problems in calculus. During my venture in solving difficult integrals using series expansions via the monotone convergence theorem, I noticed that some integrals were tackled easily with the Fourier series. Now, why isn't this topic included in the same sections where power, taylor and maclaurin series are being discussed? Not that I'm complaining (though I
favor maclaurin and this is my hobby, so I'm learning something new), but shouldn't this series also be included in Calculus 2?","['self-learning', 'fourier-series', 'calculus']"
2804831,Is it possible to answer this problem with standard Central Limit Theorem or should we use Lindeberg-Feller CLT?,"I have the following problem on my Statistics I problem set: Suppose that $X_t = \mu + U_t$, where $U_t = V_t + \rho V_{t-1}$ and
  $V_t$ are iid standard normal variables. Apply a CLT to find the limiting distribution of $\sqrt{n} (\bar{X}_n -\mu)$ Let $\hat{\theta}_n = (\hat\mu_n, \hat\rho_n)$ be the MLE for $\theta = (\mu, \rho)$. Find the asymptotic distribution of
  $\sqrt{n}(\hat{\theta}_n - \theta)$. Compare the asymptotic distributions of $\sqrt{n}(\hat\mu_n - \mu)$ and $\sqrt{n}(\bar{X}_n - \mu)$. Explain your answer. I cannot prove part 1, since $X_{t}$ variables are not iid, as required by the standard CLT. I understand that we should use Lindeberg-Feller CLT or something stronger to prove this result. Can anyone do it with standard CLT?","['probability-theory', 'statistics', 'central-limit-theorem', 'convergence-divergence', 'parameter-estimation']"
2804850,Finding a mapping which is conditional distribution,"Let $(\Omega, \mathcal{A},P)$ be a probability space, $\mathcal{F} \subseteq \mathcal{A}$ a $\sigma$-algebra and $X:\Omega \rightarrow \mathcal{X}$ a random variable which takes values in a countable set $\mathcal{X}=\{x_1,x_2,\dots\}$. Show that there exists a mapping $P_{\mathcal{F}}:\mathcal{P}(\mathcal{X}) \times \Omega \rightarrow [0,1]$ so that i) $P_{\mathcal{F}}(\cdot,\omega)$ is a probabilty measure on $\mathcal{P}(\mathcal{X})$ for every $\omega \in \Omega$. ii) $P_{\mathcal{F}}(A,\cdot)$ is a conditional expectation of $\mathbb{1}_{\{X\in A\}}$ given $\mathcal{F}$ for every $A \in \mathcal{P}(\mathcal{X})$. I am struggling so far with this exercise and am in need of some help. I was given the hint to show that $E[\mathbb{1}_{\{X=x_i\}} \vert \mathcal{F}],i \in \mathbb{N}$ is a probabilty sequence and then construct the probabilty measure with this sequence. But to be honest I don't know how to proceed. Any help would be appreciated, thanks in advance.","['probability-theory', 'conditional-expectation', 'probability', 'measure-theory']"
2804865,Solving $f\left(x\right)+f\left(1/x\right)=K$,"I would like to know if there's a way to solve
$$
\forall x \in \mathbb{R}^{*+}, \ K \in \mathbb{R}, \ f\left(x\right)+f\left(\frac{1}{x}\right)=K
$$
We know that for $\displaystyle K=\frac{\pi}{2}$ we have ( $x \in \mathbb{R}^{*+}$ )
$$
\text{arctan}\left(x\right)+\text{arctan}\left(\frac{1}{x}\right)=\frac{\pi}{2}
$$
And for $K=0$
$$
\ln\left(x\right)+\ln\left(\frac{1}{x}\right)=0
$$
Only thing i've found is that it implies
$$
-f'\left(\frac{1}{x}\right)+x^2f'\left(x\right)=0 \text{ and }f\left(1\right)=\frac{K}{2}
$$","['ordinary-differential-equations', 'functional-equations']"
2804888,"Showing that $\sum_{i = 1}^m \frac{1}{\prod_{j = 1, j \neq i}^m (a_j - a_i)}$ is zero","Question: How can I prove, for $m \geq 2$ and reals $a_1 < a_2 < \dots < a_m$ that $$\sum_{i = 1}^m \frac{1}{\prod_{j = 1, j \neq i}^m (a_j - a_i)} = 0?$$ Context: In Gamelin's text on Complex Analysis, exercise VII.6.4 asks to prove that $$\text{PV}\int_{-\infty}^\infty \frac{1}{\prod_{k = 1}^m (x - a_k)} dx = 0,$$ which can be done using a contour integral around a half disk $\partial D$ (of radius $R$) in the upper half-plane, with small semicircular indents (of radius $\varepsilon$) above the singularities $a_1, a_2, \dots, a_m$ on the real axis. The method is straightforward, but when applying the fractional residue theorem to the semicircle indents $\gamma_b$, the sum of their contributions becomes $$\sum_{b = 1}^m \lim_{\varepsilon \rightarrow 0} \int_{\gamma_b} \frac{1}{\prod_{k = 1}^m (x - a_k)} dx = \sum_{b = 1}^m \frac{-\pi i}{\prod_{j = 1, j \neq b}^m (a_j - a_b)},$$ and it is easy to show (using the ML-estimate) that the contribution of the integral over the semicircumference is negligible as $R \to \infty$. Thus, by Cauchy's Theorem, we have that $$\lim_{\varepsilon \to 0, R \to \infty}\int_{\partial D} \frac{1}{\prod_{k = 1}^m (x - a_k)} dx = \sum_{b = 1}^m\frac{-\pi i}{\prod_{j = 1, j \neq b}^m (a_j - a_b)} + \text{PV} \int_{-\infty}^\infty \frac{1}{\prod_{k = 1}^m (x - a_k)} dx = 0,$$ which gives the result the question wants, if the identity I am trying to prove is true. I convinced myself the identity holds by trying for small values of $m$, but I have yet to come up with any rigorous proof. I have attempted an induction argument, but I am having trouble constructing the inductive step. Any hints/advice would be greatly appreciated.","['algebra-precalculus', 'complex-analysis']"
2804941,some question about weyl's law,"Let $\Omega\subset\mathbb{R}^n$ be a bounded domain with smooth boundary, consider the following Dirichlet eigenvalue problem.
\begin{equation}\label{1}
  \left\{
         \begin{array}{ll}
           -\Delta u=\lambda u, & \hbox{in $\Omega$;} \\[3mm]
           u=0, & \hbox{on $\partial\Omega$.}
         \end{array}
       \right.
\end{equation}
The Weyl's law shows that 
$$ N(\lambda)=\#\{k\mid 0<\lambda_k \leq \lambda\}\sim \frac{\omega_n}{(2\pi)^n} |\Omega| \lambda^{\frac{n}{2}},\qquad \lambda\to +\infty.
$$
and it means that 
$$ \lambda_k\sim \frac{(2\pi)^2}{(\omega_n|\Omega|)^{\frac{2}{n}}} k^{\frac{2}{n}},\qquad k\to +\infty.$$ I feel confused about how can we prove the second conclusion from the first conclusion. It seems we only know that $N(\lambda_k)\geq k$. I found in some books that use the fact $N(\lambda_k)=k$, I don't know how to get this since $\lambda_{k}$ may has multiplicty. For example, if $0<\lambda_{1}<\lambda_2=\lambda_3=\lambda_4<\lambda_5<\cdots$, then we have $N(\lambda_2)=N(\lambda_4)=4$. Can some one help me with this question? Thanks a lot!","['spectral-theory', 'calculus', 'partial-differential-equations']"
2804942,"Intuition: 5 regular polyhedra, 6 regular 4-polytopes, and then 3 regular d-polytopes","This question was posted on MathEducators a few days ago.
Users there suggested I post on MSE. I am seeking an intuitive explanation 
(that would make sense to U.S. college students)
why the number of regular polytopes in dimension $d$ is: $d=2$, number: $\infty$. $d=3$, number: $5$, the five Platonic solids. $d=4$, number: $6$, with the $24$-cell the polytope with no clear $\mathbb{R}^3$ analog. $d \ge 5$, number: $3$, the simplex, hypercube, and its dual the cross-polytope (or orthoplex). The derivations (Diophantine equations) are convincing without providing clear intuition.
Is there some intuitive explanation, perhaps some explanation about
how much ""room"" there is in $\mathbb{R}^d$?
I've wondered if there is a connection
to the maximum volume
of a unit-ball achieved in dimension $5$, Plot: Dave Richeson's blog , 2010. but see Bill Thurston's remarks on the unit-ball volume .","['intuition', 'polyhedra', 'polytopes', 'geometry']"
2805010,Integrating $\frac{\arctan x}{x\sqrt{\smash[b]{1-x^2}}}$,"How to evaluate
$$\int_0^1\frac{\arctan x}{x\sqrt{1-x^2}}\,\mathrm dx\text{?}$$
The steps I can think of is integration by parts as
$$\int_0^1\frac{\arctan x}{x\sqrt{1-x^2}}\,\mathrm dx=\int_0^1\frac{\arctan x}{x}\,\mathrm d(\arcsin x)$$
or integration by substitution using $x=\sin t$ as
$$\int_0^1 \frac{\arctan x}{x\sqrt{1-x^2}}\,\mathrm dx = \int_0^{\frac{\pi}{2}}\frac{\arctan(\sin t)}{\sin t}\,\mathrm dt,$$
but both seems to make the problem more complicated. Thanks a lot.","['definite-integrals', 'calculus']"
2805024,Book recommendation for real numbers construction and set theory?,"Here, particularly I'm looking for a book which starts with set theory and constructs real numbers on that basis (it should include Dedekind cut). Other than Landau's book. Edit: Thank you all in comments for your suggestions. I found this book 'From natural numbers to quaternions' by Kramer and Pippich (thought bit advanced atleast for me but very readable), Elementary Set theory by Enderton (Thanks to Asaf Karagila), Goldrei's book is also really good (Thanks to palmpo). Last two books I mentioned do both jobs of constructing numbers and introducing set theory really well.","['real-numbers', 'elementary-set-theory']"
2805052,What is Taylor's Inequality about? [duplicate],"This question already has answers here : What does the Taylor's Inequality mean? (2 answers) Closed 6 years ago . I am confused by the Taylor's Inequality formula:
$$|R_n(x)| \le \frac M{(n+1)!}|x−a|^{n+1}$$ What do $R_n$, $M$, $n$, $x$, $a$, stand for i.e. what to substitute inside each variable? What purpose does this formula serve/How to apply it in situations/problems?","['derivatives', 'sequences-and-series', 'calculus', 'analysis']"
2805065,Proving $\int_0^\infty\frac{e^x-1}{x(e^x+1)^2}dx=6\ln A-\frac12-\frac16\ln2-\frac12\ln\pi$,"I want to prove $$I=\int_0^\infty\frac{e^x-1}{x(e^x+1)^2}dx=6\ln A-\frac12-\frac16\ln2-\frac12\ln\pi$$
where $A$ denotes the Glaisher's constant. My attempt: Knowing that $$\int_0^\infty\frac{e^{-ax}-e^{-bx}}{x}dx=\ln b-\ln a$$
So I tried $$I=\int_0^\infty\frac{e^x-1}x\sum_{n=0}^\infty(-1)^{n+1}ne^{-(n+1)x}dx$$
But unfortunately $f_n(x)=(-1)^{n+1}ne^{-(n+1)x}$ does't uniform converge in $[0,+\infty)$ and I can't go further. (I also noticed the relation between integrals containing $e^x\pm1$ and $\zeta$ function. $\zeta'(-1)=\frac1{12}-\ln A$. So I added ""riemann-zeta"" in the tags)","['riemann-zeta', 'integration', 'definite-integrals', 'calculus']"
2805133,"Searching for examples of ""graph algebras""","This question is related to the question https://mathoverflow.net/questions/301626/what-is-known-about-graph-algebras but is not a duplicate, since here I am searching for examples of graph algebras. It seems that ""graph algebras"" are not known in the literature, hence I am collecting examples of graph algebras. I call a ""graph algebra"" a simple undirected graph $G=(V,E)$ and a binary mapping $+:E \rightarrow V$ such that: (1) For all edges $(a,b)$ we have: $a+b \in N(a) \cap N(b)$, $N(a) = $ neighbors of $a$. (2) $a+b=b+a$ for all edges (3) $a+(b+c) = (a+b)+c$ for all edges $(a,b),(b,c)$ for which $(a,b+c),(a+b,c)$ are also edges. [(4) if $a+b=a+c$ then $b=c$.] I am collecting examples of such graph algebras.
Examples of such ""graph algebras"" are: a) infinite graph algebra: $V=\mathbb{N}$, $a \sim b : \leftrightarrow \gcd(a,b)=1$, $+:=+$ in $\mathbb{N}$ b) Let $H$ be a not necessarily finite or abelian group. Then $V=H$ and $a\sim b : \leftrightarrow a \cdot b = b \cdot a$, $+ := \cdot $ in $H$. c) Let $G$ be a finite graph such that two adjacent vertices belong to an unique triangle and two non-adjacent vertices belong to an unique quadrilateral. Then if $(a,b)\in E$ there exists a unique $\phi(a,b)=\phi(b,a) \in V$ such that $(a,\phi(a,b)),(b,\phi(a,b))\in E$. Set $a+b := \phi(a,b)$. This makes the graph $G$ to a graph algebra. d) Let $X$ be a topological space. $V:=\{ U \subset X | U \text{ is open set} \}$. Then $U \sim U' :\leftrightarrow U \cap U' \neq \emptyset$ and $U+U' := U \cup U'$. This defines a abelian graph algebra on the open sets of $X$ for which the cancellation law (4) does not necessarily hold. e) Let $V:=H$ be a non-abelian group. Define $a\sim b : \leftrightarrow a\cdot b \neq b \cdot a$. And let $a * b := a \cdot b$ This defines a non abelian graph algebra for which the cancellation law (4) holds. f) Let $V:=H$ be a real Hilbert space. Define $x\sim y : \leftrightarrow ( x,y) >0$, where $(x,y)$ is the dot-product. This defines a graph-algebra on the Hilbert space $H$, with $x \oplus y := x+y$. g) Let $R$ be a commutative ring with $1$. Let $V:=$ zero divisors of $R$. Suppose that $R$ has the property (for example $\mathbb{Z}/(6 \mathbb{Z})$ has) that:
$$ a,b,a-b \in V \rightarrow a+b \in V$$
Define $a\sim b :\leftrightarrow a-b \in V$ and $a+b:= a+b$ in $R$. This defines a abelian graph algebra on the zero divisors of $R$. h) V=2-elements subsets of a set S, E : just one element in common, + : union minus the common element. If somebody knows of other examples of graph algebras, that would be fine. For example let $H:=D_4=$ dihedral group with $8$ elements. Then the corresponding graph in (b) is given by the picture below: Another example:
Let $R := \mathbb{Z} / ( 12 \mathbb{Z})$ and $V:= $ zero divisors of $R$. Then the graph of the graph algebra defined in g) is given by the picture below:","['graph-theory', 'hilbert-spaces', 'ring-theory', 'general-topology', 'group-theory']"
2805155,Other methods for solving homogeneous differential equation,"I want to find a general solution of the following homogeneous equation $$\frac{dy}{dt}=\frac{3t+12y}{t+14y}$$ I have tried using the substitution $z = y/t$ to make the equation separable, but then it gets a little bit tedious to solve. $$\frac{dy}{dt}=\frac{3+12z}{1+14z}=z+\frac{dz}{dt}t$$ $$\int \frac{1+14z}{-14z^2+11z+3} dz = \ln(t)+c_1$$ So I'm wondering if there's another way to solve it?",['ordinary-differential-equations']
2805160,Solving the polynomial that doesn't have all the degrees up to the highest one,"How can I solve
$$-q^5+2q^4-q+2=0$$
I guess I need to unfold, but I don't know how to do that in this example. Symbolab says that the solution is $q=2$, but I don't quite understand how it arrives at that solution. Only the solutions from the set of real numbers are accepted.","['algebra-precalculus', 'polynomials']"
2805249,Finding a Jordan basis of a $3\times 3$ matrix,"Find a Jordan basis for the following matrix: $$A=
    \begin{pmatrix}
    1 & -3 & 4 \\
    4 & -7 & 8 \\
    6 & -7 & 7 \\
    \end{pmatrix}
$$ Hey everyone. First I have found the characteristic polynomial which is $(x-3)(x+1)^2$. Then i've found a basis for: $$\ker(3I-A)=\ker\begin{pmatrix}2 & 3 & -4 \\-4 & 10 & -8 \\-6 & 7 & -4 \\\end{pmatrix}$$ $B_1= \{(\frac{1}{2},1,1)^T\} $. Then, for the next Jordan block I've calculated $\ker(-I-A)=\ker \begin{pmatrix}
    -2 & 3 & -4 \\
    -4 & 6 & -8 \\
    -6 & 7 & -8 \\
    \end{pmatrix}
$ and found a basis for this subspace- $B_2= \{(1,2,1)^T\}. \dim(\ker(-I-A))=1\neq a_m(\lambda)=2$ so we find a basis for $\ker(-I-A)^2 \Rightarrow B_3=\{(1,1,0)^T,(0,1,1)^T\}$ and choose $e_1=(1,0,0)^T \ (e_1 \notin Sp(B_2)) $ to complete $B_3$ to a basis of $\mathbb{R^3}$. Hence, our first chain is the vector $v_1= \{(\frac{1}{2},1,1)^T\}$, and the second chain is $\{(-I-A)e_1, e_1\}=\{(-2,-4-6)^T, (1,0,0)^T\} $ therefor our basis is $B= \{(\frac{1}{2},1,1)^T, (-2,-4-6)^T, (1,0,0)^T \} $ But $P^{-1}AP $ where $P=\begin{pmatrix}
    \frac{1}{2} & -2 & 1 \\
    1 & -4 & 0 \\
    1 & -6 & 0 \\
    \end{pmatrix}$ equals $\begin{pmatrix}
    3 & -32 & 0 \\
    0 & -1 & -1 \\
    0 & 0 & -1 \\
    \end{pmatrix} \neq \begin{pmatrix}
    3 & 0 & 0 \\
    0 & -1 & 1 \\
    0 & 0 & -1 \\
    \end{pmatrix}$ I've done numerous tries with different vectors other than $e_1$ yet I did not achieve the matrix' Jordan form. I would be happy if you could help me find my mistakes. Thanks in advance :)","['matrices', 'jordan-normal-form', 'linear-algebra']"
2805275,Limit of $\sin(kx)$ as k tends to infinity,"I am have been thinking lately of the sequence of functions
$$
f_n = \sin nx
$$ and its limit as n tends to infinity. I am quite comfortable with the fact that viewing this sequence in $\mathcal{C}([a,b],\mathbb{R})$ this has no limit. However I have recently finished a course at on Hilbert Spaces, where we were teased with function spaces like $L^2([-\pi,\pi])$ and $L^1([a,b])$. Now we were not given any rigorous definitions of these spaces but I am wondering if this sequence does have a limit in a more abstract space. I am mainly wondering about its limit in $L^2([-\pi,\pi])$.  The reason I am wondering about this space in particular is because to me it seems to the limit of this function sequence, if it exists, will be 1 and -1 at an infinite number of points in the interval $[-\pi,\pi]$, however the set of these points seems countable and therefore the set of such points have a measure of zero. If this seems a little like a waffle session, I apologise, I do not have a lot of experience in measure and integration theory just yet. (I will be doing that next year)","['functional-analysis', 'sequence-of-function', 'lebesgue-measure', 'measure-theory']"
2805325,Smiths normal form is similar to $xI-A.$,"I am reading Rational Canonical form from The Abstract Algebra book by Dummit and Foote. I have some doubt in Smith normal form. Smiths normal for says for any $n\times n$ square matrix $A$ over an arbitrary field $F,$ $xI-A$ is equivalent to diagonal matrix in $F[x]$ whose diagonal elements are either $1$ or the invariant factors of the pair $(F^n,A)$. But after looking at other references it seems to me that $xI-A$ is not only equivalent but Similar to such diagonal matrix in $F[x].$  I can't understand how they are similar. I need some help to understand the similarity. And also I want to know if there are references for the Canonical form in the modern approach by what I mean using the results of modules over PID. Thank you.","['smith-normal-form', 'modules', 'matrices', 'abstract-algebra', 'linear-algebra']"
2805359,Proof that $1729$ is the smallest taxicab number,"For homework I have to produce the proof (algebraic or otherwise) to show that $1729$ HAS to be the smallest taxi cab number . A taxicab number means that it is the sum of two different cubes and can be made with $2$ sets of numbers. I have the list of the next ones and I was wondering if it was linked with the fact that it would have to be $0$ cubed if it got any lower which obviously wouldn't work. Any help appreciated,
thanks in advance!","['proof-writing', 'elementary-number-theory']"
2805372,Ring of integers modulo $n$ with a property for the zero divisors.,"This is a follow-up of Is $a+b$ a unit if $a,b,a-b$ are zero divisors? Let $n$ be a natural number such that the ring $R:=\mathbb{Z}/(n \mathbb{Z})$ has the following property:
$$a,b,a-b\in Z \implies a+b \in Z$$
where $Z$ are the zero-divisors of $\mathbb{Z}/(n \mathbb{Z})$. User @lhf made the observation that $R$ seems to have this property exactly when $n$ has less than three prime divisors.
I am interested if this can be made into a proof. Edit :
Here is a partial result if $\omega(n)=1$, hence $n=p^\alpha$  is a prime power:
If $a,b,a-b\in Z$ then we must have:
$p^{a_0} = \gcd(a,n)>1$,$p^{b_0} = \gcd(b,n)>1$,$p^{c_0} = \gcd(a-b,n)>1$
for $a_0,b_0,c_0\ge 1$. From this it follows that:
$$a = x p^{a_0}, b = y p^{b_0}, a-b=zp^{c_0}$$
and we get:
$$a+b = (a-b)+2b = zp^{c_0} + 2yp^{b_0} = p^{d_0}(zp^{c_0-d_0}+2yp^{b_0-d_0})$$ 
with $d_0 = \min(c_0,b_0) \ge 1$ since $b_0,c_0 \ge 1$.
Hence $\gcd(a+b,n)>1$ and $a+b \in Z$.","['number-theory', 'abstract-algebra', 'ring-theory']"
2805429,Diagonal elements of a symmetric matrix and positive definiteness,"Let $A = (a_{ij}) \in \mathbb{R}^{n \times n}$ be a symmetric matrix with $$a_{ii}>\sum\limits_{j\neq i} |a_{ij}|$$ for $i=1,\dots,n$. Show that $A$ is positive definite. I tried to work this out algebraically starting from the definition of a real matrix being positive definite $x^{T}Ax > 0$ for every $x \in \mathbb{K}^{n}$ but this got me stuck in the sense that I couldn't really utilize the given precondition. I would appreciate some hints.","['matrices', 'symmetric-matrices', 'positive-definite', 'linear-algebra']"
2805461,Fast arbitrary decomposition of a positive-definite matrix,"Given a positive-definite $n\times n$ matrix $\mathbf{A}$, my goal is to present it as a product of the form $\mathbf{H^TH}$, where $\mathbf{H}$ is an arbitrary $n\times n$ matrix. Cholesky decomposition does this with $\mathbf{H}$ upper-triangular. However, its complexity is of the order $O(n^3)$. The question is whether it is possible to do this quicker if we remove all the constraints on $\mathbf{H}$.","['matrix-decomposition', 'algorithms', 'computational-complexity', 'linear-algebra']"
2805471,topologies defined on $B(H)$,"If $H$ is a Hilbert sapce,there are many topologies can be defined on $B(H)$:norm topology, strong operator topology,weak operator topology, σ-strong topology,σ-weak topology.... If $H$ is finite dimensional ,Can we deduce that all these topologies are the same?","['functional-analysis', 'operator-algebras', 'operator-theory']"
2805521,Does $\sum _{n=1}^{\infty }\frac{\left|\sin\left(n\right)\right|}{n}$ converge?,"I'm not sure whether the following series converges or diverges:
$$\sum _{n=1}^{\infty }\frac{\left|\sin (n)\right|}{n}$$ I proved that the series $\sum _{n=1}^{\infty }\frac{\sin^2 (n )}{n}$ converge. Is there a way I can use that? I've tried using Dirichlet series test with the latter but didn't got nowhere since $\frac{1}{\left|\sin x\right|}$ is not monotone decreasing.","['real-analysis', 'sequences-and-series', 'convergence-divergence']"
2805524,Are uncountable dense subsets of $\mathbb{R}$ with the same cardinality homeomorphic?,"I know that if $A,B\subseteq\mathbb{R}$ are two dense countable subsets of reals they are homeomorphic, indeed there exists a homeomorphism $f:\mathbb{R}\to\mathbb{R}$ such that $f(A)=B$ . I was wondering what happens for cardinalities different from $\aleph_0$ , i.e. if I have two dense sets $A,B\subseteq\mathbb{R}$ of the same cardinality $\kappa$ , then is true that there exists a homeomorphism $f:\mathbb{R}\to\mathbb{R}$ such that $f(A)=B$ ? To avoid trivialities, $\kappa$ must be infinite because the sets are dense; and clearly a necessary condition is that holds $\kappa<\mathfrak{c}$ , because otherwise $A=\mathbb{R}\setminus\{0\},B=\mathbb{R}\setminus\mathbb{Q}$ form a counterexample. Then if the continuum hypothesis is assumed, we already know the answer; but without it the question is interesting and I don't know the answer.","['general-topology', 'set-theory']"
2805526,Kissing points of circle packing *on a circle*?,"Recently, when playing about with circle packings while looking at Kleinian groups and this proof of the Fold and Cut Theorem with a friend, we noticed something intriguing. It seemed that when we drew four circles (of potentially different sizes), such that they touched each other at 4 points in a ""ring-like"" formation (like in the image below), that the kissing-points made a cyclic quadrilateral. We then put this into GeoGebra and observed that this was true, seemingly, no matter the sizes of the various circles. Thus, I have multiple questions: Is this true? What's the proof? Is this true for ""ring-like"" formations of 5, 6 or $n$ circles? If the above are true, as I suspect, then one might observe that for every circle packing we can naturally construct the inverse circle packing , by replacing each ""ring-like formation"" in the original circle packing with a single new circle going through their kissing-points. Does this inverse circle packing have any interesting properties?","['circles', 'euclidean-geometry', 'geometry']"
2805581,Examples of moduli space $J$-holomorphic curves,"I'm reading McDuff and Salamon's book on $J$-holomorphic curves and am curious about some examples. They say that if $(M^{2n},J)$ is an almost complex manifold, $(\mathbb{CP}^1,j)$ the Riemann sphere, $A\in H_2(M;\mathbb{Z})$ a homology class, and $G=PSL(2,\mathbb{C})$ the group of Moebius transformations of $\mathbb{CP}^1$, then the space $\mathcal{M}(A,J)/G$ of $(j,J)$-holomorphic curves $u:(\Sigma,j)\to (M,J)$ in the homology class $A$, modulo the action of $G$, is a manifold of dimension $$\dim \mathcal{M}(A,J)/G=2n+2c_1(A)-6.$$ As an example, suppose $(M,J)$ is $\mathbb{CP}^n$ with the standard Kaehler structure and $A$ is the homology class of linear embeddings of $\mathbb{CP}^1$ in $\mathbb{CP}^n$. Note that in this case $c_1(A)=n+1$, so $\mathcal{M}(A,J)/G$ has real dimension $4(n-1)$. Is this moduli space compact? What are its other topological properties, like CW structure, homology, homotopy, etc. Is it a ""familiar"" compact manifold? I would also appreciate other examples where $\mathcal{M}(A,J)/G$ has been ""determined"", and references to where they have been computed.","['complex-geometry', 'differential-geometry', 'algebraic-geometry', 'symplectic-geometry']"
2805604,Does Bounded Closed Subset of Banach Space Attain Suprermum?,"Let $B$ be a Banach space and $A$ be a bounded closed convex subset of $B$. I wonder if every $x^*\in B^*$ attains its supremum in $A$. In detail, I wonder if there is a point $x\in X$ such that
$$
x^*(x)=\sup_{y\in A} x^*(y).
$$ By Uniform Bounded Principle, I know that $\sup_{y\in A}x^*(y)=\alpha < \infty$. Hence I can find a sequence $\{x_n\}$ with the following property:
$$
\alpha-\frac{1}{n} < x^*(x_n) \leq \alpha.
$$ Problem is that $x_n$ may not converge. Maybe I can regard $\{x_n\}$ as a sequence in $B/\textrm{Ker} x^*$, but even if it converges, I am not sure that the limit is in $A$. By Alaogu Theorem, for each $x\in A$, I also have $x^*$ with $\|x^*\|=1$ and
$$
\|x\| = \sup_{\|y^*\|=1}|y^*(x)|= |x^*(x)|
$$but I am not sure this will help in any way. Is there any counter example? Thank you in advance.","['functional-analysis', 'banach-spaces']"
2805661,Is there a formula that generalizes $\sin A+\sin B+\sin C = 4\cos\frac{A}{2}\cos\frac{B}{2}\cos\frac{C}{2}$ (where $A+B+C=\pi$) to four angles?,If $A+B+C=\pi$ then we have $$\sin A+\sin B+\sin C = 4\cos\left(\frac{A}{2}\right)\cos\left(\frac{B}{2}\right)\cos\left(\frac{C}{2}\right)$$ If $A+B+C+D=\pi$ is there a similar formula?,['trigonometry']
2805666,Why is this compact operator a Fredholm operator?,"Let $X$ be a Banach space with the $L^{\infty}$ norm and let $A$: $X \rightarrow X$ be an integral operator of the following form, \begin{equation}
Ax(s) = \lambda\int^{b}_{a}K(s,t)x(t)dt,
\end{equation}
where $K$: $[a,b] \times [a,b]\rightarrow \mathbb{R}$ is a continuous map such that $K \neq 0$ and where $\lambda$ is a constant. I know that due to the continuity of $K$, Arzelà–Ascoli theorem implies that $A$ is compact. But in the uploaded image they say $A$ is Fredholm as well. I fail to see why, could someone help me out?","['functional-analysis', 'compact-operators', 'spectral-theory']"
2805683,Find the coefficient of $z$ in the Laurent series expansion of $\frac{e^z}{z-1}$ in ${|z| > 1}$,"I've found this duplicate from '15: Find the coefficient of $z$ in the Laureant Series expansion of $\frac{e^z}{z-1}$ , but I think it's wrong, since it looks for the Laurent expansion in ${|z-1|>1}$. After developing it by myself, I've reached the following: $$f(z)=\frac{e^z}{z-1}=\frac{1}{z-1}\cdot e^z$$ Then, $e^z=\sum_{n\geq 0} \frac{z^n}{n!}$ and $$\frac{1}{z-1}=\sum_{n \geq 0} \frac{1}{z^{n+1}}$$. Here I thought of using the Cauchy Product, but I end up with $$f(z)=\sum_{n \geq 0} \sum_{k=0}^n \frac{z^{2k-n-1}}{k!}$$ (How can I make this font bigger? The exponent is too small. Sorry about that. The exponent would be $2k-n-1$). So I have to sum whenever $2k-n-1 = 1$ If I'm not getting it wrong, this means that I have to calculate $$\sum_{n \geq 0} \frac{1}{(1+2n)!}$$ (I'm not sure how to show it better, but I've put the first 3 terms and were $\frac{1}{1!}, \frac{1}{3!}$ and $\frac{1}{5!}$. I'm not sure how to calculate that. The nearest thing I thought was that $$\sum_{n \geq 0} \frac{1}{n!}=e $$. Maybe what I found before could be considered as an answer, but I think I can go one step further. Thanks","['laurent-series', 'complex-analysis']"
2805697,Find $x$ if $\cot^{-1}\left(\frac{1}{x}\right)+\cos ^{-1}(-x)+\tan^{-1}(x)=\pi$,if $x \lt 0$ Then Find value of  $$\frac{(1-x^2)^{\frac{3}{2}}}{x^2}$$ if $$ \cot^{-1} \left(\frac{1}{x}\right)+\cos^{-1}(-x)+\tan^{-1}(x)=\pi$$ My try: Since $x \lt 0$ we have $$ \cot^{-1}\left(\frac{1}{x}\right)=\pi +\tan ^{-1}x$$ Also $$\cos^{-1}(-x)=\pi -\cos ^{-1}x$$ Hence the given equation becomes $$\pi +2 \tan^{-1} x+\pi -\cos^{-1}{x}=\pi$$ $$\pi+2 \tan^{-1}x=\cos^{-1}x$$ taking $\cos$ both sides we get $$\frac{x^2-1}{x^2+1}=x$$ Now how to proceed further?,"['algebra-precalculus', 'roots', 'trigonometry', 'inverse-function']"
2805700,Right continuous and monotone function must exist right derivative?,"Right continuous and monotone function must exist right derivative? Suppose $f:R\rightarrow R$ is a right continuous and monotone function, i.e. $f(x+)=f(x),\forall x\in R$ and $f(x)$ is monotone, say non-decreasing. Does the limit exist $\lim_{\delta \searrow 0 }\frac{f(x+\delta)-f(x)}{\delta}$ everywhere ?","['derivatives', 'real-analysis', 'continuity', 'analysis']"
2805733,"Is $F(x)=\int _{\sqrt x}^{1}\arcsin(t^2) \,dt$ differentiable?","Let $F:[0,1]\rightarrow \mathbb{R} $
$$F(x)=\int _{\sqrt x}^{1}\arcsin(t^2)  \,dt$$ Is $F$ differentiable? The function $f(t)=\arcsin(t^2)$ is continuous on $[0,1]$  so is  integrable on $[0,1]$ and
$$ \frac{d}{dx}\sqrt x=\frac{1}{2\sqrt x}$$ So $F$ is differentiable and by the F.T.C $$ F'(x)=-\frac{\arcsin(x)}{2\sqrt x}$$ Is correct my answer?","['derivatives', 'indefinite-integrals', 'real-analysis', 'integration']"
2805735,Inverse of Bhāskara I's sine approximation [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question Bhāskara I's approximation of $\sin x$ , for $x$ in radians, is $$\sin x = \frac{16x\left(\frac{\tau}{2}-x\right)}{5\left(\frac{\tau}{2}\right)^2-4x\left(\frac{\tau}{2}-x\right)}$$ where $\tau := 2\pi$. I now need the inverse of this formula in order to approximate the inverse sine. (I'd figure out how to ""crop"" it once I can visualise it in Desmos.) Wolfram Alpha suggests $$\arcsin x = \frac{x}{4}+\frac{\sqrt{\left(\tau^2+3\tau-4\right)\left(-x^2\right)}}{2\left(\tau+4\right)}$$ Yet Desmos fails to show any points (except possibly one at the origin). See https://www.desmos.com/calculator/w0us6zngaq . Thanks in advance!","['trigonometry', 'inverse-function', 'approximation']"
2805746,How to get Riemann form on complex tori,"Let $X$ be a closed compact Riemann surface of genus $g$. Then I can get $\operatorname{Jac}(X)$, Jacobian of the $X$ by Abel-Jacobi mapping. $\operatorname{Jac}(X)=C^g/\Lambda$ admits non-trivial $\theta$ function(i.e. a function defined on $C^g$ surely vanishes somewhere or equivalently, $\operatorname{Jac}(X)$ admits non-trivial meromorphic section) iff $\Lambda\otimes_RR\cong C^g$  admits a positive semi-definite Riemann form. $\textbf{Q:}$ How do I get this Riemann form from lattice $\Lambda$? It seems I could not see any direct prescription without constructing $\theta$ function. For $g=1$, it is clear. For $g>1$, it is very unclear why I should even have a positive semi-definite Riemann form. $\textbf{Q:}$ In general there is no reason to expect a tori having meromoprhic section. When tori admits meromorphic section and suppose one knows only it admits a meromorphic section, do I even know this riemann form is determined by lattice?","['complex-analysis', 'several-complex-variables', 'complex-geometry', 'algebraic-geometry']"
2805803,Estimating the Length of the Groove on an LP,"The question is as follows: A typical long-playing phonograph record (once known as an LP) plays for about $24$ minutes at $33 \frac{1}{3}$ revolutions per minute while a needle traces the long groove that spirals slowly in towards the center. The needle starts $5.7$ inches from the center and finishes $2.5$ inches from the center. Estimate the length of the groove. Based on the given information, I was able to calculate the total number of revolutions -- which is $800$ revolutions ($24 \times \frac{100}{3}$). I don't know how to go further than that. Any help will be greatly appreciated.",['algebra-precalculus']
2805862,Lemma 2.3 - Lectures on Mean Curvature Flow,"I'm self-study Mean Curvature Flow and I'm stuck on item $(ii)$ of the lemma below My doubts are referent the equalities marked with a red rectangle Why $|A|^2 = \langle h_{ij}, h_{ij} \rangle$ ? I know that $|A|^2 = g^{ij}g^{kl}h_{ik}h_{jl}$, but I can't see how $|A|^2 = \langle h_{ij}, h_{ij} \rangle$ What is the definition of $\nabla A$? The closer I got to the definition was on the proof of Lemma 2.2 of this article by Huisken . I think the second equality marked is just by definition, but I would like to know what is the definition of $\nabla A$. Why $\text{tr} (A^3) = \langle h_{ij}, h_{ik} h^k_j \rangle$? Thanks in advance! $\textbf{EDIT:}$
I finally understood why $\text{tr} (A^3) = \langle h_{ij}, h_{ik} h^k_j \rangle$. I will post how to develop $\langle h_{ij}, h_{ik} h^k_j \rangle$ to arrive at this. By the definition of inner product of tensors (see this topic as well as the comments that I did in Lee's answer for the definition and for a motivation of it), $\langle h_{ij}, h_{ik} h^k_j \rangle = g^{ii} g^{jj} h_{ij} h_{ik} h^k_j = g^{ii} g^{jj} g^{lk} h_{ij} h_{ik} h_{lj}$ and, as pointed by Anthony on his answer, I can consider an orthonormal frame (it's just assume a local chart with normal coordinates), then $\langle h_{ij}, h_{ik} h^k_j \rangle = g^{ii} g^{jj} g^{lk} h_{ij} h_{ik} h_{lj} = h_{ij} h_{ik} h_{kj} = h_{ij} h_{jk} h_{ki} = \text{tr} (A^3)$.","['mean-curvature-flows', 'riemannian-geometry', 'differential-geometry']"
2805876,How to calculate unique combinations,"Let's suppose that we have three variables: $xyz (n=3)$ . We need to calculate how many unique combinations we can make. So in this case, you can simply get the answer without using any formulas: $xy, xz, yz, xyz$ . So there are $4$ unique combinations. But how do you calculate it with some kind of formula when it gets more complicated? So for example, $4$ variables $wxyz$ . Now you have $wx, wy, wz, xy, xz, yz, wxy, wxz, wyz, xyz, wxyz$ ( $11$ combinations). And how do you do this when you have even $10$ variables? How do you do this?",['combinatorics']
2805927,"Does the $0$ element of a stalk have to $0$ only at the point, or does it also have to be $0$ in a neighborhood containing the point?","For a prime ideal $p$ in Spec $A$, consider the $0$ element of the stalk $\mathcal{O}_p$, where $\mathcal{O}$ is the structure sheaf. If $f$ is equivalent to the $0$ element of the stalk, then does it have to be $0$ in a neighborhood containing $p$, or does it have to be $0$ only at $p$? I thought that it has to be $0$ in a neighborhood, but reading a proof in Hartshorne is making me think otherwise.","['schemes', 'algebraic-geometry']"
2805939,Is it always possible to transform one arithmetic progression into another?,"Suppose we are given two arithmetic progressions $a, a+h, a+2h, ...$ and $c, c+l, c+2l, ...$ Is it always possible to find a linear function $y=kx+b$ which transforms the first progression into the second? From ""Functions and Graphs"", Gelfand In the book we learned that a linear function converts one arithmetic progression into another. And examples involvig numbers also make sense for me. However, I can't figure out how to approach the above problem. How do we show if it's possible to tranform one arithmetic progression into another?","['coordinate-systems', 'functions', 'graphing-functions']"
2805941,"If $f'(a):\mathbb R^m\to \mathbb R^m$ is not an isomorphism, then","Let $U\subset \mathbb R^m$ be an open set and $f:U\to \mathbb R^m$ a function of class $C^1$. Suppose there is  $a\in U$ such that $f'(a):\mathbb R^m\to \mathbb R^m$ is not an isomorphism. then $$\lim_{r\to 0}\frac{\operatorname{vol}f(B(a;r))}{\operatorname{vol}B(a;r)} = 0$$ I have previously shown that if $f'(a)$ for isomorphism, then $\lim_{r\to 0}\frac{\operatorname{vol}f(B(a;r))}{\operatorname{vol}B(a;r)} = |det f'(a)|$, the only thing I know, is that I can not use the change of variables theorem. 
Any suggestions on how to solve this problem?","['change-of-variable', 'real-analysis', 'integration', 'analysis']"
2806007,Intuitive understanding of conditional density $f_{X \mid Y}(x \mid y)$,"Let $X$ be a continuous random variable with probability density function $f_X$. The way that I think about the meaning of $f_X$ is this: if $\Delta x$ is a small positive number then
$$
P(X \in [x,x+ \Delta x]) \approx f_X(x) \,\Delta x.
$$ Now suppose that $Y$ is also a continuous random variable. Is there a similar way to think about the conditional probability density function $f_{X \mid Y}(x \mid y)$? Notice that I cannot write
$$
\tag{1} P(X \in [x,x + \Delta x] \mid Y = y) \approx f_{X \mid Y}(x \mid y) \,  \Delta x
$$
because the event $Y = y$ has probability $0$, and I can't condition on an event with probability $0$. Question: Since equation (1) does not make sense, how should I think about $f_{X \mid Y}(x \mid y)$? By the way, Bertsekas's book Introduction to Probability defines $f_{X\mid Y}$ like this:
$$
f_{X \mid Y}(x \mid y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}.
$$
However, I do not find this formula to be intuitive, despite the formula's superficial similarity with the formula
$$
P(A \mid B) = \frac{P(A \cap B)}{P(B)}.
$$",['probability']
