question_id,title,body,tags
2642368,Is there a name for $\max \| A x \|$ for all $\|x\|=1?$,"Is there a name for $\max \| A x \|$ for all $\|x\|=1?$ ($A$ is a matrix, and $x$ is a vector) One might be inclined to guess that it's the spectral radius of $A$, but that's not true. I'm wondering if there is a special term for this property of $A$.","['matrices', 'linear-algebra']"
2642390,Most general solution of an ODE,"Consider $y''(x)=0$. It seems obvious that the most general solution to this equation is given by $y=Ax+B$, where $A, B \in \mathbb{R}$, which can be confirmed through integration. But how do we know that this is indeed the most general solution to this equation, and that no other had been omitted? I know there are ODE's where some solution may be omitted when standard methods are used, e.g the trivial division by zero, so how do we know if a solution to an ODE is the most general one?",['ordinary-differential-equations']
2642392,Geometric (or Intuitive) proof of the improper integration of $\frac1x $,"From a mathematical standpoint, I understand and I can solve the following:
$$ \lim_{M\rightarrow\infty} \int_1^M \left({1 \over x}\right) \rightarrow \infty $$
Additionally,
$$ \lim_{M\rightarrow\infty} \int_1^M \left({1 \over x^2}\right) \rightarrow 1 $$ This all makes mathematical sense to me. It's the geometric parts that confuse me. 
The family of of $ 1/x^p $ graphs look very similar to me, so it makes me wonder why $ 1/x $ doesn't converge to some value as well. Especially considering the fact when you rotate $ 1/x $ and calculate the volume of that shape; it converges to some value. Again, mathematically, this makes sense because: $$ \lim_{M\rightarrow\infty}\int_1^M \left({1 \over x}\right) dx > \lim_{M\rightarrow\infty} \int_1^M \pi\left({1 \over x^2}\right) dx $$ But the geometric implications of this are that a cross-section of such an object has an infinite area but the volume is some finite value. My questions: Using an intuitive or geometric explanation, why doesn't $ 1\over x $ converge to some value? Why is the volume described above finite while the cross-section is infinite? Edit: Changed $[]$ to $()$","['volume', 'improper-integrals', 'integration', 'calculus']"
2642394,"General formula for Evaluating $\sum_{n=0}^\infty n^ar^n$ where $ |r|<1 , a\ge0$","I'm trying to derive a general formula for $$\sum_{n=0}^\infty n^ar^n$$ where $a\ge0$ and $|r|<1$ I know the first couple a: $$I(0)=\sum_{n=0}^\infty r^n=\frac{1}{(1-r)}$$ $$I(1)=\sum_{n=0}^\infty nr^n=\frac{r}{(1-r)^2}$$ $$I(2)=\sum_{n=0}^\infty n^2r^n=\frac{-r(r+1)}{(r-1)^3}$$ $$I(a)=\sum_{n=0}^\infty n^ar^n=???$$
assuming my math was correct. I got these by differentiating the general summation formula for geometric series. After doing it a couple more times, I can't seem to discern a pattern.","['derivatives', 'summation', 'sequences-and-series', 'calculus']"
2642423,"$\sin(2x-60 ^{\circ}) = 0.5 $ for $x\in [0^\circ, 360^\circ]$","I have worked out the answers $45^\circ$, $135^\circ$, $225^\circ$, $315^\circ$; although some of these may be wrong. Where have I gone wrong (if I have)? And are there any other answers (between $0^\circ$ and $360^\circ$ inclusive) that I have missed out?",['trigonometry']
2642478,Proof of e as a limit,"I'm reading this text: A few questions: What's the importance of them going from $h$ to $x$ in the first line? What is the difference? How did they go from 
$$\lim_{x \to 0} \frac{\ln(1+x) - \ln(1)}{x}$$
to
$$\lim_{x \to 0} \left[\frac{1}{x} \cdot \ln(1+x)\right]$$ And then right before the blue 5 box... how did they go from:
$$e^{\lim_{x \to 0} \ln(1+x)^{1/x}}$$
to
$$\lim_{x \to 0} e^{\ln(1+x)^{1/x}}$$
How did they just pull out the limit sign?",['calculus']
2642523,Union of disjoint sets : Equivalence relations,"I'm not exactly sure how to go about doing this question. I've attempted it but I'm not exactly sure if it's correct. Question : Let $S$ be the union of disjoint sets $A_1, \cdots, A_k$. Let $R$ be the relation consisting of pairs $(x, y) \in S \times S$ such that $x, y$ belong to the same member of $\{A1, \cdots, A_k\}$. Prove that $R$ is an equivalence relation on $S$. The three axioms are: reflexivity, symmetry, transitivity, I have a brief idea of how to do the first 2, however, for transitivity, I don't have any ideas. Could anyone help out on this please?","['equivalence-relations', 'elementary-set-theory', 'discrete-mathematics']"
2642525,Bayes’ formula conditions,"I was just wondering if given Bayes’ formula, 
$P(A|B) = \frac{ P(B|A) P(A)}{P(B)}$ can one always claim that $0 < \frac{P(B|A)}{P(B)} < 1$? Can a proof be given? Note: A and B are different events. Thanks.","['bayes-theorem', 'probability-theory']"
2642530,Proof by contradiction that there are no periodic solutions to $\dot x =f(x)$,"I need to finish the proof (by contradiction) that there do not exist any periodic (oscillating) solutions to the system $\dot x =f(x)$. The proof starts out as follows: Suppose on the contrary that $x(t)$ is a nontrivial periodic solution - I.e., that $x(t)=x(t+T)$ for some $T>0$ and $x(t)\neq x(t+s)$ for all $0<s<t$. I'm supposed to derive a contradiction by considering $$ \int_{t}^{t+T}f(x)\frac{dx}{dt}dt$$ I saw a solution where the person said that $$\int_{t}^{t+T}f(x)\frac{dx}{dt}dt = \int_{x(t)}^{x(t+T)}f(x)dx=0$$ and i do not understand why that's true. Next, they said that $$\int_{t}^{t+T}f(x)\frac{dx}{dt}dt=\int_{t}^{t+T}f(x)^2 dt \geq 0, \quad \text{for}\, t^{*}\in (t, T+t)$$ which I also don't understand. And finally, they said that this tells us that $f(x(t^{*}))=0$, which implies that the only solution is the trivial solution. Now, I am not sure how those two things imply that $f(x(t^{*}))=0$, and then how that in turn implies that the only solution is the trivial solution. Im assuming that all of these steps come perhaps from some form of the fundamental theorem of calculus, but I'm not exactly sure how it allows us to do these things. So, if someone could please explain these steps to me, I would appreciate it very much. Note : I am not at all interested in alternative proofs for this result. They exist already aplenty on MSE for someone who is interested to find them. I am interested only in finishing/understanding the proof the way it is presented here.","['ordinary-differential-equations', 'dynamical-systems', 'calculus', 'proof-explanation']"
2642566,Formally Evaluating a Limit,"The epsilon-delta definition of the limit says that $\lim_{x \to a}f(x)=L$ if for every number $\epsilon >0$ there is some number $\delta>0$ such that $|f(x)-L|<\epsilon$ whenever $0<|x-a|<\delta$. Using this definition I've seen many examples asking to prove a limit is true. But, how would you use this to evaluate a limit? Question: Ascertain $\lim_{x \to 3} x^2$ using the epsilon-delta definition of the limit (not prove that the limit is 9, but arrive at the limit is 9 without postulating).","['epsilon-delta', 'calculus', 'limits']"
2642575,Questions about membership relation and ordinal definition,"This post follows the approach of Kelley General topology . I ask three questions about $\in$ relation and definition of the ordinal . I think they are related and can be asked in the same post. If you don't think so please feel free to add a comment and I'll create new posts. 1.- We say that a set (class) $X$ is transitive (complete, saturated) if every element of $X$ is also a (sometimes proper) subset of it. Namely, $$X\subseteq \{x:x\subset X\}.$$ 2.- We refer as the epsilon class to the class $$\mathcal E = \{(x,y):x\in y\}.$$ Now, an ordinal is defined as a transitive class $\alpha$ such that $\mathcal E$ is trichotomic on $\alpha$. My first question is: How can I prove that $\mathcal E$ is transitive on an ordinal $\alpha$? Because $x\in y\in z$ doesn't imply, a priori, that $x\in z$. My second question is about the epsilon class: To define ordinals, is $\mathcal E$ valid or we should consider
$$ \mathcal E_\alpha =\{(x,y)\in \alpha\times \alpha : x\in y\} $$
(as Enderton does)? And finally, if our theory is allowed to work with proper classes, should we add the condition be a set in the definition of ordinal ? Because later we consider the class 
$$ \mathbf {Ord}=\{\alpha:\alpha\mbox{ is an ordinal}\}, $$
but if ordinals aren't sets this class doesn't exist. Moreover, Kelley proves that $\mathbf{Ord}$ is an ordinal, but then $\mathbf{Ord}$ should be an element of itself, which violates the Axiom of Regularity. Thanks","['elementary-set-theory', 'ordinals']"
2642593,$X$ is the space of all continuous functions with the norm $||f||=\sup_{t\ge0}e^{kt}|f(t)|<\infty.$ Is $X$ a Banach space?,"Fix $k\in \mathbb{R}$ and let $X$ be the space of all continuous functions $f:[0,\infty) \to\mathbb{R}$ s.t.
$$\|f\|=\sup_{t\ge0}e^{kt}|f(t)|<\infty.$$ Is $X$ a Banach Space? I think $X$ is Banach if $k\ge0$ and I had a brief proof. But I have no idea whether $X$ is Banach when $k<0$. Can someone give a brief proof or a counterexample?","['functional-analysis', 'real-analysis', 'banach-spaces', 'analysis']"
2642601,Addition Rule for Expectations,"Why does the addition rule for expectations work no matter if the sub-events involved is independent or dependent? For example: Let $X$ be the number of aces in a 5-card poker hand. The probability
  that any particular card is an ace is $\frac{4}{52}$, so the expected
  number of aces among 5 cards dealt from a well-shuffled deck is $E(X) = \frac{4}{52} + \frac{4}{52} + \frac{4}{52} + \frac{4}{52} + \frac{4}{52} = 5/13$ Considering the draws are without replacement, why are the probability constant here? Reference:",['statistics']
2642603,Are the elements $c$ and $\{c\}$ the same in a set?,"I have a problem that asks me this: If $A = \{a, b, c\}$ and $B = \{b, \{c\}\}$, is $B$ a subset of $A$? What I'm confused about is if you treat $\{c\}$ and $c$ as the same elements. I'm sort of confident that $\{c\}$ is distinct from $c$ and this would not be a subset, but I want to make sure.","['elementary-set-theory', 'discrete-mathematics']"
2642776,Find all $f$ that satisfies $f:\mathbb{R}\rightarrow\mathbb{R};f(x+y)+f(x)f(y)=(1+x)f(y)+(1+y)f(x)+f(xy)$,"Find all $f$ that satisfies:
$1, ~f:\mathbb{R}\rightarrow\mathbb{R};\\
2,\forall x,y\in\mathbb{R},f(x+y)+f(x)f(y)=(1+x)f(y)+(1+y)f(x)+f(xy);
$ Maybe we can prove it's derivable or it's a linear function. Any idea?","['real-analysis', 'functional-equations']"
2642791,Determine the value of $p(1) + q(1)$,"Let $p(z)$ and $q(z)$ ($z$ here is a complex number)  both as polynomial so that
$$p(z) \sin^2 z + q(z) \cos^2 z = 2. \quad \forall z \in \mathbb{C}$$
Determine the value of $p(1) + q(1)$. My attempt:
First I tried to manipulate the equation by using trigonometric identity to make $\tan z$ appear in it, but seems lead no result. Factorizing also gives no result, I think. So, do you have any idea? Please, help.","['complex-analysis', 'trigonometry']"
2642805,Mathematical proof that $m^4+8$ is not a cube of an integer if $13$ does not divide $m$ (Table proof provided),"My question is how to express my solution to $m^4+8$ is not a cube of an integer if $13$ does not divide $m$ as a mathematical proof. I understand that to prove by contradiction, the result is to be a cube of an integer: \begin{align}
 m^4 + 8 & = n^3 \\
 m^4 &= n^3 - 8 \\
 \therefore m^4 &\equiv n^3-8\pmod{13}\\
  \\
\end{align} That equivalence is however impossible, because of the following table: We see that $m^4 \equiv n^3-8\pmod{13}$ can only occur when m $\equiv 0 \pmod{13}$ and n = 2, 5 or 6. This shows that since $13$ can not divide $m$, $m^4+8$ is not a cube of an integer. I am now sure how to express this mathematically. Any help would be appreciated!","['number-theory', 'proof-writing', 'elementary-number-theory']"
2642835,Minimum length of axes intercept of a line passing through a fixed point,"I encountered this problem: A straight line passes through a fixed point $(h,k) \ (h,k>0)$ and intersects the coordinate axes at $P(a,0)$ and $Q(0,b)$. Show that the minimum length of $PQ$ is $(h^{2/3}+k^{2/3})^{3/2}$. Now, I proceeded like this: If a line passes through $(h,k)$ then its equation is $$\frac{y-k}{x-h}=m.$$ If it passes through $(a,0)$ and $(0,b)$ then we have $a=h-\frac{k}{m}$ and $b=k+mh$. Length of $PQ$ is $\sqrt{a^2+b^2}$. We can put the value of $a$ and $b$ in the expression and then differentiate w.r.t. $m$, to find out the minimum value. But after equating the first differential to $0$, I found two roots of $m$. As the values of $h$ and $k$ can be positive or negative, I cannot put them in the second differential to find out which one is minimum and which one is maximum. What am I doing wrong? and, Is there any other, simpler method that can be used?","['derivatives', 'geometry']"
2642862,"If integrals of pullbacks of a form only depend on the boundary values, is it exact?","Let $N$ be a smooth manifold with boundary, and let $\omega \in \Omega^m(N)$. Suppose that for every smooth $m$-dimensional manifold $M$ with boundary, and for every smooth maps $f_0,f_1:M \to N$ such that $f_0|_{\partial M}=f_1|_{\partial M}$, we have $\int_M f_0^* \omega=\int_M f_1^* \omega$. Is it true $\omega$ is exact? Does anything change if we only assume $\int_M f_0^* \omega=\int_M f_1^* \omega$ for arbitrary maps $f$ from a fixed manifold $M$? I am quite sure $\omega$ must be closed. The argument should be similar to the one given here . Note that in dimension $1$, this is a classic result, and that the converse direction is immediate: Let $f:M \to N$ be smooth.
By assumption, $\omega=d\eta$ for some $\eta \in \Omega^{m-1}(N)$. Thus
$$
\int_{M}f^*\omega=\int_{M}f^*d\eta=\int_{M}df^*\eta=\int_{\partial M}f^*\eta
$$
depends only on $f|_{\partial M}$.","['homology-cohomology', 'differential-forms', 'differential-geometry', 'differential-topology']"
2642880,Matrix permutation-similarity invariants,"https://en.wikipedia.org/wiki/Matrix_similarity https://en.wikipedia.org/wiki/Permutation_matrix The determinant and trace (and characteristic polynomial coefficients) are well-known similarity invariants of a matrix. There are more if we only allow permutation similarities (swapping a pair of rows, and swapping the corresponding pair of columns). How many independent invariants does an $n \times n$ matrix have? I assume it would be $n^2$. How many invariants (polynomials of the matrix's elements) must be known to determine the matrix up to permutation-similarity? I don't know if it's too much to ask for a general formula for all the polynomials. (This is related to graph isomorphism , by the adjacency matrix.) A $2 \times 2$ matrix has only one other matrix that is permutation-similar: $$\begin{bmatrix} a & b \\ c & d \end{bmatrix} \sim \begin{bmatrix} d & c \\ b & a \end{bmatrix}$$ The following quantities are invariant with respect to this similarity: $$p_1 = a + d$$
$$p_2 = ad$$
$$q_1 = b + c$$
$$q_2 = bc$$
$$r_2 = (a-d)(b-c)$$ Knowing the $p$'s and $q$'s almost determines the matrix; it's either one of the two shown above, or one of their transposes. The transposes are eliminated if we are also given $r_2$. There are 5 equations here, but only 4 unknowns, so the system is over-determined. It has a solution (in Complex Numbers) if and only if $$(p_1^2 - 4p_2)(q_1^2 - 4q_2) = r_2^2$$
(If the system is restricted to Real Numbers, we also need $(p_1^2 - 4p_2) \ge 0$, and $(q_1^2 - 4q_2) \ge 0$ .) This equation cannot be used, in general, to reduce the system to 4 equations, because of the possibility that one factor on the left is zero, putting the other factor out of reach. (This is similar to the equation of a line, $Ax + By = C$; there are 3 parameters, but only 2 degrees of freedom. This is fixed by $x \cos\alpha + y \sin\alpha = D$, but I don't want to use trig functions in the matrix context.) So all 5 invariants are necessary to determine the matrix. For a $3 \times 3$ matrix $A$, I've found at least a dozen invariants, such as $$p_3 = A_{11}A_{22}A_{33}$$
$$q_3 = A_{12}A_{23}A_{31} + A_{13}A_{21}A_{32}$$
$$r_3 = A_{11}A_{23}A_{32} + A_{12}A_{21}A_{33} + A_{13}A_{22}A_{31}$$
$$p_5 = (A_{12}A_{13}A_{21}A_{23}A_{31} + A_{12}A_{13}A_{21}A_{23}A_{32} + A_{12}A_{13}A_{21}A_{31}A_{32} + A_{12}A_{13}A_{23}A_{31}A_{32} + A_{12}A_{21}A_{23}A_{31}A_{32} + A_{13}A_{21}A_{23}A_{31}A_{32})$$ In the $n \times n$ case, $n$ invariants will be the elementary symmetric polynomials of the matrix's diagonal elements, others will depend only on the off-diagonal elements, and others will be mixed. This is one way of classifying the invariants. We could refine this classification by specifying the number of on-diagonal and off-diagonal factors in each term. So, what invariants will guarantee that two matrices are permutation-similar? (There may be a better type of invariant to tell whether they're similar, such as a canonical/normal form of the matrix. But that's not what this question is about.)","['matrices', 'invariance', 'permutations', 'systems-of-equations']"
2642884,Determine the value of summation form. [duplicate],"This question already has answers here : How to show $\sum_{k=0}^{n}\binom{n+k}{k}\frac{1}{2^k}=2^{n}$ (16 answers) Closed 4 years ago . Determine the value of
$\displaystyle \sum_{k=n}^{2n} \binom{k} {n} 2^{-k}$ for $n \geq 1$ My attempt:
I have asked this question before in another math forum but it leads no solution. My friend suggested me to search for something like series-k. I also looked at my textbook in combinatoric section (which apparently leads to Binomial Theorem), but really I don't have any idea for this one. 
Could you help me?","['combinatorics', 'summation']"
2642925,Discretization for $\partial_tu = \partial_x[g\times\partial_xu]$,"In paper Efficient and Reliable Schemes for Nonlinear Diffusion Filtering i have difficulty to understand the following step. We have equation and its discretization in 1D case: $$\partial_tu = \partial_x[g\times\partial_xu]$$ $$\frac{u_i^{k+1}-u_i^k}{\tau} = \sum_{j\in \mathcal N(i)}\frac{g_j^k+g_i^k}{2h^2}(u_j^k-u_i^k), $$ where $\mathcal N(i)$ is the set of the two neighbors of pixel $i$. I don't get how did the authors get this discretization.","['finite-differences', 'ordinary-differential-equations']"
2642936,Why is it so difficult to sample from a Boltzmann distribution?,"I am studying simulated annealing, and simulated annealing involves a Boltzmann distribution. Typically I see the Boltzmann distribution written like: $P(E_i) = e^{-E_i/(kT)}/Z$ where $Z$ is the sum of all of the energy in all of the states, and $P(E_i)$ is the energy in just one of the states. The thing is in simulated annealing I see the pdf written with an integral: $P(x) = \frac{e^{-f(x)/T}}{\int_{S}e^{-f(z)/T}dz}$ I understand from many sources that the Boltzmann distribution is reportedly very difficult to sample from because it involves this $f(z)$ as you can see above.  I have two questions about that: 1) Why does the $f(z)$ not appear in the first equation I gave for the Boltzmann distribution?  (e.g., it does not appear here on wikipedia: https://en.wikipedia.org/wiki/Maxwell –Boltzmann_distribution) 2) I'm able to fire up python and use scipy to easily sample from a Boltzmann distribution just by doing import scipy
from scipy import stats
import numpy as np
import matplotlib.pyplot as plt
r = scipy.stats.boltzmann.rvs(lambda_=1.4, N=4, size=10) without trouble.  (source: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.boltzmann.html#id23 ) So what is the big deal with sampling from a Boltzmann distribution?  There are all these fancy methods in Simulated Annealing like Hit and Run, Metropolis sampling, etc. Why are they necessary when I was able to sample from a Boltzmann distribution with ease?","['sampling', 'statistical-mechanics', 'mathematical-physics', 'probability-distributions', 'statistics']"
2642954,Limits without L'Hopital $\lim\limits_{x\to 0} \frac{e^{3x}-e^{-4x}}{\sin5x}.$,"I have a problem finding $$\lim_{x\to 0} \frac{e^{3x}-e^{-4x}}{\sin5x}.$$ I know that L'hopital's rule can be used to get the answer of $\dfrac{7}{5}$, but I tried to do it without the L'hopital. I tried to solved it by using series expansion and got the correct answer, but the method took so much time. I want to know that if there is any other method to solve the problem?","['real-analysis', 'limits', 'calculus', 'algebra-precalculus', 'limits-without-lhopital']"
2642963,How can a undergraduate student start learning geometry?,"I have finished all undergraduate course on analysis and abstract algebra. However, I know little about modern geometry, such as riemann geometry, conformal geometry, and general relativity. Where should I start my self study of geometry?","['riemannian-geometry', 'algebraic-geometry', 'geometry', 'conformal-geometry', 'differential-geometry']"
2642971,The product of the commutator subgroup with any subgroup,"Let $G$ be a group and let $G'$ be its commutator subgroup. If $H$ is any subgroup of $G$ , is the subgroup $G'H$ normal in $G$ ? I know that $G'H$ is a subgroup, as the product of a normal subgroup with any other subgroup is itself a subgroup. It's just the ""normality"" bit which I am struggling with.","['abstract-algebra', 'group-theory']"
2643022,Homogeneous C*-algebras,"In a C*-algebras paper I've read recently, they state that every irreducible representation of the C*-algebra $C(X,\mathbb{C})$, where X is compact topological space, is 1-dimensional. They also state that every irreducible representation of $C(X,M_{n}(\mathbb{C}))$ is n-dimensional. (where again X is compact and $M_{n}(\mathbb{C})$ is C*-algebra of complex n*n matrices) They state these without proofs. Could you please help me how to prove these things, or tell me literature in which I can find proof/insight? Thanks.","['functional-analysis', 'c-star-algebras', 'operator-algebras']"
2643036,"Dividing a rectangle into 4 parts in the ratio 1:2:3:4, with only 2 lines","I have a rectangle made up of 30 identical squares (5 tall and 6 wide). By only drawing two lines on the rectangle, split the rectangle into 4 parts where the areas are in the ratio 1:2:3:4. How would one go around doing this? I tried for a solid hour or two; but to no avail. Disclaimer: This question is NOT created by me.","['puzzle', 'ratio', 'geometry']"
2643094,"Show that if $\lim\limits_{x \to \infty} f(x)$ exists and $f''$ is bounded, then $\lim\limits_{x \to \infty} f'(x)=0$. [duplicate]","This question already has answers here : If $f(x)\to 0$ as $x\to\infty$ and $f''$ is bounded, show that $f'(x)\to0$ as $x\to\infty$ (4 answers) Proving that $\lim\limits_{x\to\infty}f'(x) = 0$ when $\lim\limits_{x\to\infty}f(x)$ and $\lim\limits_{x\to\infty}f'(x)$ exist (6 answers) Closed 6 years ago . I'm trying to answer the following exercise: Suppose that $f$ is twice differentiable on $[0,+\infty)$. Show that if $\lim\limits_{x \to \infty} f(x)$ exists and $f''$ is bounded, then $\lim\limits_{x \to \infty} f'(x)=0$.
  If $\lim\limits_{x \to +\infty} f'(x)$ exists then I know how to prove that this limit is equal to 0 (by using the mean value theorem). But how can I show that this limit exists? Counterexample: Let us consider  $f(x) = x \sin\frac{1}{x}$. Then $$f'(x) = \sin\frac{1}{x} - \frac{1}{x} \cos\frac{1}{x}$$ and $$f''(x) = -\frac{1}{x^2}\cos\frac{1}{x} + \frac{1}{x^2}\cos\frac{1}{x} - \frac{1}{x^3} \sin\frac{1}{x}.$$ This example shows that the hypothesis that there exists $\lim\limits_{x \to \infty} f(x)$ is essential.","['real-analysis', 'limits', 'calculus', 'algebra-precalculus', 'analysis']"
2643102,"Points moving towards the nearest point, where will they meet?","Consider an arbitrary number of distinct points in some $n$
  dimensional space whose locations are exactly known. Every point is
  moving towards its nearest point simultaneously, at constant speed. If
  multiple points meet in a point, that's the new single point and the
  game continues.  What will be the final point where all the points
  will eventually meet? What are the methods to finding the final meeting point? What if a point is equidistant to multiple points? Then it moves towards all of them : If a point is equally distant from two points, it moves towards the line determined by those two points. If a point is equally distant from three points, it moves towards the plane determined by those three points. Similarly for more equidistant points in some $n$-space. $(n=1)$ If we are observing points on a line, then if $T(x_1)$ and $T'(x_2)$ are the outmost points (all other points are on the line segemtn $TT'$), then the final point will always be in the midpoint $P(\frac{x_1+x_2}2)$, no matter how many points and where are located on that line segment. For the cases when a point is equally distant from two closest points, it simply won't move as it is already on the line determined by those two points, which now will meet at it. $(n>1)$ If we are observing points on a plane, if three points are equally distant from one another, then they will end up in the center of that equilateral triangle, made of those three points. (Since each is moving towards opposing side) But already at three points on a plane, if we have a pair of points meeting in the middle, and a third point far away gravitating towards one of those two points, its path will be a curve until the two distant points meet, and then its path will continue in a straight line towards the merged point. I'm not sure how to show where exactly the final point will end up relative to the triangle. (white point on the picture is the meeting point; blue points are the starting points.) However, if the third point $C$ is equally distant from the two paired points $A,B$, then it is simple to find the ending point as we don't have curved paths. The paired points will meet at the midpoint $P$ of $AB$, and $C$ would've traveled distance $AB/2$ towards $P$ by this point, to $C'$. Now final point is at the midpoint of $PC'$. But I'm just observing certain cases and not sure how to approach this
  generally; as I'm already not sure how to handle arbitrary amount of points on arbitrary locations in the plane. Example of paths; Random $20$ points on a plane, where red point is $(0,0)$ and white point is the point where all points eventually meet:","['dynamical-systems', 'geometry']"
2643121,"Find $xy+yz+zx$ given systems of three homogenous quadratic equations for $x, y, z$","This is a question from Math Olympiad. If $\{x,y,z\}\subset\Bbb{R}^+$ and if $$x^2 + xy + y^2 = 3 \\ y^2 + yz + z^2 = 1 \\ x^2 + xz + z^2 = 4$$ find the value of $xy+yz+zx$. I basically do not know how to approach this question. Please let me know how to approach this question, and if you attach full explanation, I will appreciate it. Thanks.","['algebra-precalculus', 'contest-math', 'polynomials', 'systems-of-equations']"
2643127,Is the gradient of a vector product a row or a column?,"I am trying to define the gradient of $x^Ty$ with respect of $x$ where both $x, y$ are column vectors $\in \mathbb{R}^m$. $\frac{\partial x^Ty}{\partial x} = [\frac{\partial x^Ty}{\partial x_1} , \frac{\partial x^Ty}{\partial x_2} , ... , \frac{\partial x^Ty}{\partial x_m}] = [y_1, y_2, ..., y_m] = y^T$ or is it = $[\frac{\partial x^Ty}{\partial x_1} , \frac{\partial x^Ty}{\partial x_2} , ... , \frac{\partial x^Ty}{\partial x_m}]^T = [y_1, y_2, ..., y_m]^T = y$ I am quite confused since I haven't been exposed to multivariate calculus before.","['multivariable-calculus', 'matrix-calculus', 'derivatives']"
2643202,Restriction of domain of bijective function,"Is always true that if $f$ is a bijection from two sets $A$ and $B$, and $C \subset A$, then the restriction $f{\restriction_{C}}$ must be injective? I've tried proving it by noticing that saying this, is the same as saying that if $f$ is our bijection, and $\iota_{C} : C \to A : x \mapsto x$ is the inclusion application of $C$ in $A$, then $f \circ \iota_{C}$ is injective, but i didn't gone too far, and I'm not even sure of the correctness of the last result.","['elementary-set-theory', 'functions']"
2643256,Solving the integral $\int_0^1\int_0^1\frac{1}{(1-\alpha x^\beta y^\gamma)^2}dxdy$,"How to solve $$\int_0^1\int_0^1\frac{1}{(1-{\alpha}x^{\beta}y^{\gamma})^2}dxdy$$ where $0\leq\alpha<1$ , $\beta\geq0$ , and $\gamma\geq0$ ? Does it have any closed-form? I'm not getting any method to solve this integral. Any hint is appreciated.","['integration', 'definite-integrals']"
2643259,Proof of Maschke’s theorem: Why is $\hat{p}$ again a projection?,"Question : In the proof of Maschke’s theorem we construct for every subrepresentation $U \subseteq V$ a $G$-equivariant projection onto $U$.
  How can we abstractly see that for any $k$-linear projection $p \colon V \to V$ onto $U$, the resulting $G$-equivariant map $\hat{p} = \frac{1}{|G|} \sum_{g \in G} (g.\!p) \colon V \to V$ must again be a projection onto $U$? Setup :
Let $G$ be a finite group and $k$ a field with $\operatorname{char} k \nmid |G|$.
Then for every representation $V$ of $G$ the map
$$
          V
  \to     V
  \quad   v
  \mapsto \hat{v}
  :=      \frac{1}{|G|} \sum_{g \in G} g.\!v
$$
is a projection onto the subspace $V^G \subseteq V$ of $G$-invariants.
We will refer to this as the projection onto invariants . This is famously used in (one of) the proofs of Maschke’s theorem:
Let $V$ be a representation of $G$ over $k$ and let $U \subseteq V$ be a subrepresentation.
Starting off with any $k$-linear projection $p \colon V \to V$ onto $U$, one can apply the projection onto invariants to the representation $\operatorname{Hom}_k(V,V)$ to get a new map
$$
    \hat{p}
\in \operatorname{Hom}_k(V,V)^G
=   \operatorname{Hom}_G(V,V) \,.
$$
One can then check that this $G$-endomorphism $\hat{p}$ is again a projection onto $U$, e.g. by checking that $\operatorname{im} \hat{p} \subseteq U$ and that $\hat{p}(u) = u$ for every $u \in U$. While the projection onto invariants nicely explains how to translate the $k$-linear projection $p$ into a $G$-endomorphism $V \to V$, I have not yet found an explanation for why $\hat{p}$ will again be a projection onto $U$.
(“Checking on elements” proves that it works, but doesn’t explain why it works.) How can we abstractly see that by applying the projection onto invariants to $p$, the resulting $G$-endomorphism $\hat{p}$ must again be a projection onto $U$? This is what I tried/figured out so far: Suppose that $W \subseteq V$ is a $k$-linear subspace which is not a subrepresentation, and let $q \colon V \to V$ be a projection onto $W$. Then $\hat{q} \colon V \to V$ doesn’t have image $W$ since $\hat{q}$ is $G$-equivariant and $\operatorname{im} \hat{q}$ is therefore a subrepresentation of $V$.
But $\operatorname{im} \hat{q}$ is contained in the subrepresentation generated by $W$. $\hat{q}$ is not necessarily a projection.
(Example:
Let $\mathbb{Z}/4$ acts on $V = \mathbb{R}^2$, let $W$ be the $x$-axis and $q$ the orthogonal projection.
Then $\hat{q}(x) = x/2$ for every $x \in W$, so that $\hat{q}^2 \neq \hat{q}$.) So it seems pretty important for $U$ to be a subrepresentation of $V$. For every $G$-homomorphism $f \colon V \to W$ one has that $f(\hat{v}) = \widehat{f(v)}$.
In fancy language we may regard $\widehat{(-)}$ as a natural transformation from the identity functor to the taking-invariants functor $(-)^G$.
Since $\widehat{(-)}_V$ is a projection for every representation $V$, this generalizes to a natural decomposition $V = V^G \oplus V^{\text{non-triv}}$. Given $k$-linear maps $f \colon U \to V$, $g \colon V \to W$ the first point shows that it does not always hold that $\widehat{f \circ g} = \hat{f} \circ \hat{g}$ (otherwise $\hat{q}$ would again be a projection).
But it follows from the second point that
$$
  \widehat{\hat{f} \circ g}
= \hat{f} \circ \hat{g}
= \widehat{f \circ \hat{g}}
  $$
since $\operatorname{Hom}_k(U,V) \to \operatorname{Hom}_k(U,W)$, $h \mapsto \hat{g} \circ h$ and $\operatorname{Hom}_k(V,W) \to \operatorname{Hom}_k(U,W)$, $h \mapsto h \circ \hat{f}$ are $G$-homomorphisms (which holds because $\hat{g}$ and $\hat{f}$ are $G$-homomorphisms). One can use the projection onto invariants to give different, more abstract proofs of Maschke’s theorem (e.g. section 3.2 here , which uses the natural decomposition from the second point).
But I have not yet found such an abstract proof which better explains the “classical” proof. Any help is appreciated.","['finite-groups', 'abstract-algebra', 'representation-theory', 'proof-explanation', 'group-theory']"
2643279,Homotopy invariance of de Rham cohomology,"Let $M,N$ be smooth manifolds which are homotopy equivalent i.e., there exists smooth maps $F:M\rightarrow N$ and $G:N\rightarrow M$ such that $F\circ G$ is homotopic to identity map on $N$ and $G\circ F$ is homotopic to identity map on $M$. Then, Homotopy invariance of deRham cohomology says that the de Rham cohomology groups of $M$ and $N$ are isomorphic. I am not able to understand the construction given in Lee's Intoduction to Smooth manifolds. What is the rough idea behind this proof (or any other proof) of homotopy invariance of de Rham cohomology. EDIT : Given that $M,N$ are homotopy equivalent as above, we need to prove that $H^p_{dR}(M)$ and $H^p_{dR}(N)$ are isomorphic. we expect this to come from $F^*:H^p_{dR}(N)\rightarrow H^p_{dR}(M)$ and $G^*:H^p_{dR}(M)\rightarrow H^p_{dR}(N)$. I do not understand the idea behind proof of two homotopic maps have induce same deRham cohomology maps . Once we prove this, then $F\circ G$ and $1_N$ induce same deRham cohomology maps i.e., the composition $H^p_{dR}(N)\xrightarrow{F^*} H^p_{dR}(M)\xrightarrow{G^*} H^p_{dR}(N)$ is same as the identity map on $H^p_{dR}(N)$ and similarly the composition $H^p_{dR}(M)\xrightarrow{G^*} H^p_{dR}(N)\xrightarrow{F^*} H^p_{dR}(M)$ is same as the identity map on $H^p_{dR}(M)$. This says that $F^*\circ G^*=1$ and $G^*\circ F^*=1$. Thus,  $F^*,G^*$ are isomorphisms, inverses to each other, conlcuding that deRham cohomology groups  $H^p_{dR}(M)$ and $H^p_{dR}(N)$ are isomorphic. How do we prove that two homotopy maps induce same deRham cohomology maps. Let $f:M\rightarrow N$ and $g:M\rightarrow N$ be two homotopy maps, we want to prove that $f^*=g^*:H^p_{dR}(N)\rightarrow H^p_{dR}(M)$ i.e., $f^*(\omega)=g^*(\omega)+\text{closed p-form on }M$ when seen as maps $\Omega^p(N)\rightarrow \Omega^p(M)$. This means, we are expected to have $$f^*(\omega)=g^*(\omega)+d\eta$$ where $\eta$ is a smooth $p-1$ form. This gives question of defining a map $h:\{\text{closed p-forms on }N\}\subseteq \Omega^p(N)\rightarrow \Omega^{p-1}(M)$ assigning to each closed $p$ form $\omega$ on $N$ a $p-1$ form $\eta$ on $M$ such that  $f^*(\omega)=g^*(\omega)+d\eta$. Then author says it turns out to be far simpler to define $h:\Omega^p(N)\rightarrow \Omega^{p-1}(M)$ not with the condition $f^*(\omega)=g^*(\omega)+d(h\omega)$ for every closed form $\omega$ but with a more general condition that $$f^*(\omega)-g^*(\omega)=d(h\omega)+h(d\omega)$$
for every smooth $p$ form. Suppose $\omega$ is closed then $d\omega=0$ and we get the required condition that $f^*(\omega)-g^*(\omega)=d(h\omega)$. So, now the question is to define a map $h:\Omega^p(N)\rightarrow \Omega^{p-1}(M)$ satisfying the condition as above. How can we think of constructing such map? If we are thinking of going from a $p$ form to a $p-1$ form one obvious thing is to some how integrate this $p$ form. What $p$ form can we integrate here? It is natural to some how integrate the $p$ form $f^*(\omega)-g^*(\omega)$ to get a $p-1$ form $h\omega$. So, when you reverse the process i.e., when you differentiate you get $f^*(\omega)-g^*(\omega)=d(h\omega)$. This idea is vague and I can not make it any better. This $h$ is called a homotopy operator in this book. Any suggestions on how would you think about producing this operator is welcome.","['de-rham-cohomology', 'smooth-manifolds', 'differential-geometry', 'homotopy-theory']"
2643327,Where do the values in a z-table come from?,"I understand the purpose of a z-score and how you calculate $z_1$ and $z_2$ , given $x_1$ and $x_2$ for some normal random variable $X$ : $$Z = \frac{x-\mu}{\sigma}.$$ If $x-\mu = \sigma$ , then $Z = 1.00$ , which tells us that the sample point $x$ is precisely one standard deviation ( $\sigma$ ) to the right of its mean ( $\mu$ ). Likewise, if $x-\mu = -\sigma $ , then $Z = -1.00$ , which tells us that the sample point $x$ is precisely one standard deviation ( $\sigma$ ) to the left of its mean ( $\sigma$ ). However , what all sources I've come across fail to properly explain is where the values listed in a $z$ -table come from. I am interested in calculating: $$P(z_1<Z<z_2)$$ by hand. No matter what I've read online, everything tells me to just look up the value in a table.  Wwhere do those values come from? How is the above probability computed? And how is it any simpler than $P(x_1 < X < x_2)$ ?","['statistics', 'normal-distribution']"
2643328,"Pointwise and uniform convergence of $\sum_{n=0}^\infty \frac{x^n}{e^{nx}}, n \in \mathbb{N}$","$$\sum_{n=0}^\infty \frac{x^n}{e^{nx}}, n \in \mathbb{N}, D=[0, +\infty) \rightarrow \mathbb{R}$$ I tried using Weierstrass M-test $\frac{x^n}{e^{nx}} =({\frac{x}{e^{x}}})^n \le (\frac{1}{e})^n$ and $|\frac{1}{e}|\lt1$, so I thought because $(\frac{1}{e})^n$ converges (geometric series), that $\sum_{n=0}^\infty \frac{x^n}{e^{nx}}$ converges absolutely and uniformly and therefore pointwise. Is that correct and if not, where are my mystakes?","['sequences-and-series', 'calculus', 'analysis']"
2643363,On a cyclic cover of genus 5 of a curve of genus 1,"Consider a curve $C$ of genus $5$ endowed with an automorphism $\sigma\colon C \rightarrow C$ of order $4$, such that the quotient of $C$ by $\sigma$ is an elliptic curve $E$ and the isotropy of any point is at most of order $2$. Let $f\colon C \rightarrow E$ be the quotient morphism. The branch locus on $E$ consists of four points $p_1,\ldots,p_4$. Prove that there exists an invertible sheaf $\mathcal L$ on $E$ such that $\mathcal L ^4 \cong \mathcal O_E(p_1 + \ldots + p_4)^2$, $\mathcal L^2 \not \cong \mathcal O_E(p_1 + \ldots + p_4)$ and
  $$f_*\mathcal O_C \cong \mathcal O_E \oplus \mathcal L^{-1} \oplus \mathcal M \oplus \mathcal L^{-1}\otimes \mathcal M,$$
  where $\mathcal M = \mathcal L^{-2}\otimes \mathcal O_E(p_1 + \ldots + p_4).$ Since $f$ is finite and flat, $f_*\mathcal O_C$ is locally free of rank $4$. From this answer I understand that $f_*\mathcal O_C$ should split into the sum of 4 invertible sheaves. Still, I have little clue why the invertible sheaves should look like that, although I know that this is connected to the fact that $f_*\mathcal O_C$ has the structure of an $\mathcal O_E$-algebra. These statements were found on a paper by Kapil Paranjape, ""Abelian varieties associated to certain $K3$ surfaces"", Compositio Mathematica 68: 11-22 (1988), which I assume to contain some typos.","['algebraic-curves', 'coherent-sheaves', 'algebraic-geometry']"
2643414,Prove that operator is Zero operator.,"Let $H$ be the Hilbert space and $T$ be bounded linear operator on $H$. If $$\langle T^2x,x\rangle =0, \forall x \in H \quad \text{and} \quad \langle Tx,x\rangle =0, \forall x \in H, $$
then $T=0$. I thought so much about this problem but could not get any clue to tackle this problem. Someone give the hint to solve this one thank you..!!","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
2643518,How to prove that $ \int_{0}^{\infty} x^n e^{-xt} \sin x\frac{dx}{x} =\frac{i(n-1)!}{2(1+t^2)^n}\left((t-i)^n-(t+i)^n\right)$,"Let $n\ge 1$ How to prove that $$I_n(t)=  \int_{0}^{\infty} x^n e^{-xt} \sin x\frac{dx}{x} =\frac{(n-1)!}{(1+t^2)^n}\frac{\left((t+i)^n-(t-i)^n\right)}{2i}$$ I have manage to prove that one can apply Lebesgue theorem for differentiability and I came across the following relation 
  $$I'_n(t)=-I_{n+1}(t)$$ But this seems does not helps me so far using induction. Can one helps me form here or Is there possible way to derive directly this integral?","['real-analysis', 'calculus', 'closed-form', 'integration', 'analysis']"
2643540,convergence of sum of i.i.d random variables,"(Durrett 3.3.21)
I want to show the following; Let $X_1,X_2,...$ be i.i.d random variables. If $S_n=X_1+X_2+...+X_n$ converges in distribution, then it converges in probability. I have a hint saying that if $m, n \rightarrow\infty,$ then $S_m-S_n\rightarrow0$ in probability. -(1) Now use Exercise 2.5.11 in Durrett's Probability: Theory and Examples . -(2) 'Let $X_1,X_2,...$ be i.i.d random variables and $S_n=X_1+X_2+...+X_n$. If $S_n/n \rightarrow 0$ in probability, then $\max_{1\le m\le n}(S_m)/n \rightarrow 0$ in probability. (Durrett ex 2.5.11)' I have proved hint (1), but couldn't connect it with hint (2).","['probability-theory', 'convergence-divergence']"
2643552,Simple singularly perturbed systems,"I'm an engineer looking for math insights into an engineering problem. I have a simple first order ODE:  $$\dot x(t)=k\Big(-x(t)+f(t)\Big).$$ As you can see, this system behaves like a low-pass filter with $k$ acting as the filter bandwidth. The higher the filter bandwidth, the higher frequency can pass through the filter. So by hand waving, I thought when the bandwidth is very very high, almost everything passes through the filter and $x(t)$ will behave like $f(t)$. I did many Simulink runs as well as experiments with an RC circuit and a function generator that produces different signals $f(t)$. My hand-waving statement seems to be true. My questions are: 1) How do I rigorously show that as $k\to \infty,$ $x(t)$ behaves like $f(t)$? 2) I did some literature review and figured that the statement is true if $f(t)$ is constant in light of Tikhonov's result [1]. I wanted to dig deeper into the literature, but my background in maths is too limited to understand deeper results. If the statement is not true in general, what is the condition on $f(t)$ for the statement to be true? Any ideas or discussions are greatly appreciated. Thank you! [1] A.N. Tikhonov, Systems of differential equations containing a small parameter multiplying the derivative, Mat. Sb. 31 (1952) pp. 575-586","['real-analysis', 'dynamical-systems', 'functional-analysis', 'perturbation-theory', 'ordinary-differential-equations']"
2643601,Showing that $ 1 + 2 x + 3 x^2 + 4 x^3 + \cdots + x^{10} = (1 + x + x^2 + x^3 + x^4 + x^5)^2$,"I was studying a polynomial and Wolfram|Alpha had the following alternate form: $$P(x) = 1 + 2 x + 3 x^2 + 4 x^3 + 5 x^4 + 6 x^5 + 5 x^6 + 4 x^7 + 3 x^8 + 2 x^9 + x^{10} = (1 + x + x^2 + x^3 + x^4 + x^5)^2$$ Of course, we can verify this through expansion, but if I were a mathematician without access to CAS, how might I notice that this is the case? I suppose what I'm asking is how one should ""see"" that $P$ can be simplified to $(1 + x + x^2 + x^3 + x^4 + x^5)^2$? Is it a multinomial thing (which seems a bit too complicated for someone to ""notice""), or is there something simpler about the polynomial that one could use to factor it?","['algebra-precalculus', 'polynomials', 'factoring']"
2643609,Nullity and rank bounds for a nilpotent matrix,"Let $A=\mathbb R^{11}\to \mathbb R^{11}$ be a linear transformation such that $A^5=0$ and $A^4\neq 0$. Which of the following is true? a) $\operatorname{null}A\le7$ b) $2\le\operatorname{null}A$ c) $2\le\operatorname{rk}A\le9$ I don't know how i think about $A$ from this information. I think construct such as example where this hold but I can't construct any such of type example which satisfies $A^5=0$ but $A^4\ne0$. I have an idea now: consider $T:\mathbb R^{11}\to\mathbb R^{11}$ such that $$T(x_1,x_2,...,x_{11})=(x_2,x_3,x_4,x_5,0,0,..,0)$$ $\Rightarrow T^5(x_1,x_2,...,x_{11})=(0,0,...,0)$. So we can say $\operatorname{null}T\le11-\operatorname{rk}T=7$",['linear-algebra']
2643617,Evaluation of $\int_{0}^\infty \frac{\sin(x)}{x}e^{- x²} dx$,"I have tried to evaluate the integral
$$\int_{0}^\infty \frac{\sin(x)}{x}e^{- x^2} dx.$$
I used integration by parts but I did not succeed. Wolfram Alpha says that is convergent and it is equal to: $\frac \pi 2 \text{erf}({\frac 12})$ . Is there any simple way for evaluate it?","['improper-integrals', 'integration', 'trigonometric-integrals', 'error-function']"
2643622,Solve the equation $ { \sqrt{4+\sqrt{4+\sqrt{4-x}}}}=x $ [duplicate],"This question already has answers here : Something strange about $\sqrt{ 4+ \sqrt{ 4 + \sqrt{ 4-x}}}=x$ and its friends (2 answers) Closed 6 years ago . Prove that one root of the Equation 
$${ \sqrt{4+\sqrt{4+\sqrt{4-x}}}}=x $$ is $$x=2\left(\cos\frac{4\pi}{19}+\cos\frac{6\pi}{19}+\cos\frac{10\pi}{19}\right) $$ My progress: After simplyfying the given Equation I got 
$$ x^8-16x^6+88x^4-192x^2+x+140=0$$ Then I tried to factorise it, got this $ x^8-16x^6+88x^4-192x^2+x+140=(x^3+x^2-6x-7)(x^5-x^4-9x^3+10x^2+17x-20)$ $ x^8-16x^6+88x^4-192x^2+x+140=(x^3+x^2-6x-7)(x^3-2x^2-3x+5)(x^2+x-4)$
 Should I now solve cubic?","['algebra-precalculus', 'polynomials', 'trigonometry', 'complex-numbers']"
2643725,leading coefficient of Hilbert polynomial,"Let $R=\mathbb{C}[x_0,x_1,...,x_n]$ and $I$ be a homogeneous $J$- primary ideal, where $J=\sqrt{I}$ and $J$ is a homogeneous prime ideal. Assume $V(J)$ is a $d$-dim projective subvariety inside $\mathbb{P}^n$. I have a few questions concerning the Hilbert polynomials of $I$ and $J$ which I will call them $h_I$ and $h_J$. The degree of polynomial $h_I$ and $h_J$ should be $d$. Let the leading coefficient of $h_I$ and $h_J$ be $\frac{a_I}{d!}$ and $\frac{a_J}{d!}$. How to show that $a_J$ divides $a_I$ or is there any counterexample that this is not true?","['modules', 'algebraic-geometry', 'hilbert-polynomial', 'abstract-algebra', 'commutative-algebra']"
2643757,Groups of order $2520$,"Suppose that $G$ is a group of order $2520 = 2^3 \cdot 3^2 \cdot 5 \cdot 7$. The property that I want to check is this: Must $G$ contain an abelian subgroup of order at least $12$? If $G$ is soluble then, yes. A Hall $\{5,7\}$-subgroup of $G$ (which exists by Hall's theorem) is necessarily abelian. On the other hand, if $G$ is simple, then $G \cong A_7$, since $A_7$ is the only simple group of that order (in fact, it is the only perfect group of that order). Also, $A_7$ has an abelian subgroup of order $12$. Some further observations: If $G$ is a candidate counterexample to the (implicit) assertion, then for $p \in \{3,7\}$ a Sylow $p$-subgroup of $G$ must be self-centralising. Using the $N/C$ theorem and the standard $n_p \equiv 1\,(\operatorname{mod} p)$, we arrive at the only possibilities $n_7 = 2^3 \cdot 3 \cdot 5$ and $n_3 = 2 \cdot 5 \cdot 7$. For $p=5$ we cannot argue that a Sylow $5$-subgroup of $G$ must be self-centralising, because the possibility that its centraliser has order $2 \cdot 5$ cannot be excluded. At least not immediately. In any case though, $|C_G(P):P| \in \{1,2\}$ and $n_5 = 2 \cdot 3^2 \cdot 7$. Here $P$ is a Sylow $5$-subgroup of $G$. Since $G$ cannot be soluble, it must have a composition factor isomorphic to one of $\{A_5, \operatorname{PSL}_3(2), \operatorname{PSL}_2(8), A_6\}$. (We have already argued the case $G \cong A_7$.) That composition factor, however, cannot be direct. Thoughts? MatheinBoulomenos notices that I had missed one possibility for a non-abelian composition factor of $G$, namely $\operatorname{PSL}_2(8)$. I have now included this in the list.","['finite-groups', 'group-theory']"
2643794,The du Sautoy nilpotent group for an elliptic curve.,"I am reading the paper A nilpotent group and its elliptic curve: Non-uniformity of local zeta functions of groups by du Sautoy. In this paper he defines the nilpotent group
$$
G=\left\langle x_1,x_2,x_3,x_4,x_5,x_6,y_1,y_2,y_3\Big\rvert 
\begin{matrix}
[x_1,x_4]=y_3,[x_1,x_5]=y_1,[x_1,x_6]=y_2, [x_2,x_4]\\=y_1, [x_2,x_5]=y_3, [x_3,x_4]=y_2,[x_3,x_6]=y_1
\end{matrix}
\right\rangle
$$
where all other commutators are 1. He proceeds to claim that this group is related to the elliptic curve $Y^2=X^3-X$. This should become clear by computing the following determinant:
$$
\begin{vmatrix}
[x_1,x_4] & [x_2,x_4] & [x_3,x_4] \\
[x_1,x_5] & [x_2,x_5] & [x_3,x_5] \\
[x_1,x_6] & [x_2,x_6] & [x_3,x_6] \\
\end{vmatrix}
=
\begin{vmatrix}
y_3 & y_1 & y_2\\
y_1 & y_3 & 1 \\
y_2 & 1 & y_1 \\
\end{vmatrix}.
$$
Unfortunately, I don't know how to compute the determinant when the values of the matrix are elements of some non-abelian group. I naively tried to compute it as if it was a 'normal' matrix, yielding $y_3^2y_1+y_1y_2+y_2y_1-y_2y_3y_2-y_3-y_1^3$. I am sure this is not the correct expression. Nevertheless, I don't see how an expression in three variables will give me insight in the relation of this group to $Y^2=X^3-X$ (two variables). Does anyone know how to see this relation? Thanks in advance.","['number-theory', 'abstract-algebra', 'group-theory']"
2643798,Why is any arbitrary directional derivative always recoverable from the gradient?,"I understand what partial derivatives, directional derivatives, and the gradient are. I can even follow symbolically from their definitions why: $$D_\mathbf{u} f = \nabla f \cdot \mathbf{u}$$ But nonetheless I find it surprising that knowing the derivative in just 3 directions at a point (the gradient) is sufficient to figure out what it must be in any direction. The equation states it must be the case that the derivative in an arbitrary direction must be a weighted combination (dot product) the gradient with the weights determined by how x-axis'y and how y-axis'y the direction u is. What prevents me from constructing a function where this isn't true? Why can't a simultaneous increase in x and y give a dramatically different result than either alone? (e.g. a function that rises in the x+ direction and the y+ direction, but falls dramatically along the diagonal?)","['multivariable-calculus', 'partial-derivative', 'calculus']"
2643856,"Show that a set of functions is dense in $L^2(0,2)$","Show that a set of functions 
$$A=\{f\in C^0([0,2]):\ f(0)=f(1)=f(2)=0\}$$
is dense in $L^2(0,2)$. I know the following theorem: Let $1\le p<\infty$, $\ \Omega\ $ be an open set of $\mathbb{R}^n$. Then continuous functions with compact support are dense in $L^p(\Omega)$. In my case the functions are defined on $[0,2]$ that is closed. The definition of support is
$$supp\ f:=\overline{\{x\in X : f(x)\ne 0\}}$$
that is a closed set. Now for a function in $A$ I can write the support like this (tell me any mistakes)
$$supp\ f=\overline{(0,1)\cup (1,2)}$$
that I think it's equal to $[0,2]$. Can I apply the previous theorem being my domain closed? Or maybe there is a different way to solve this?","['functional-analysis', 'general-topology', 'analysis']"
2643861,"Computing $\lim\limits_{n \to \infty} \int_0^{\frac{\pi}{2}}{\frac{(\sin(x))^{n}}{1-\sin{(x)}}\,\mathrm{d}x} $","$\def\d{\mathrm{d}}$I would like to compute the following limit,  $$\displaystyle{\lim_{n \to \infty} \int_0^{\frac{\pi}{2}} \frac{(\sin(x))^{n}}{1-\sin{(x)}}\,\d x} .$$ I am looking for a high school answer. I tried writing $$\lim_{n \to \infty} \int_0^{\frac{\pi}{2}}{\frac{(\sin(x))^{n}}{1-\sin{(x)}}\,\d x = \lim_{n \to \infty} \lim_{ε \to \frac{\pi}{2}}\int_0^ε{\frac{(\sin(x))^n}{1-\sin(x)}}\,\d x},$$ but it doesn't help me, since $1 - \sin(x) \leq 1, \forall x \in \left[0,  \dfrac{\pi}{2}\right]$.","['real-analysis', 'limits', 'improper-integrals', 'definite-integrals', 'trigonometric-integrals']"
2643918,"Right triangle where all sides are integer lengths, and the two smaller sides differ by 1","Background I'm currently taking a course in number theory and the following problem came up. Problem Find all the right triangles where the small sides differ by one. My Attempt Let $\Delta ABC$ be my triangle with sides $a,b,c\in\Bbb N$ and $a^2+b^2=c^2$.  Without loss of generality we can assume $a<b$, and thus $b=a+1$. This gives the following equation: $2a^2+2a+1=c^2$, which I yet can't use. When reading another question on the site, a user gets to $a=\sqrt{b+c}$ when they assume $b=a+1$. They don't explain what is the process to get there. I tried to obtain a solution, but could't get around the equations. The most I got to was $b^2-a^2=a+b$. Now parametrizing the sides I get: $
\begin{align}
    (a,b,c)  &= (m^2-n^2,2mn,m^2+n^2)  \\ 
    &= (m^2-n^2,m^2-n^2+1,m^2+n^2) \\
    & =(2mn-1,2mn,m^2+n^2)
\end{align}
$ When I plug this solutions into the Pythagorean identity, I get curves with degree $4$ which I can't solve for any of the two variables. Even if I plug them into Mathematica, I get solutions with irrational numbers. How can I find a solution to the equations? For example one of the curves is $$m^4+n^4+6(mn)^2-4mn+1=0$$ When solving, I get a radical solution and I don't know how to make sure that it is an integer. Any hints or comments are very much appreciated.","['elementary-number-theory', 'triangles', 'geometry']"
2643945,What is the intuition behind $x^T A x$?,"Consider an $N$-dimensional vector $x$, and a $N \times N$ matrix $A$. Throughout linear algebra, I find the expression $x^T A x$ to be extremely common. Is there some fundamental intuition or geometric meaning behind it?","['matrices', 'linear-algebra']"
2643994,Beginner questions about how functions work,"Background First I apologize because the following are very elementary and annoying questions about functions. But I could sure use help. It's distressing to me that I'm trying to get better at math but I don't even understand a fundamental concept like functions... please explain very pedantically because I am a little slow. Statement in question Let's say: $\forall x,y \quad f(x) = g(x+y)$ My questions Is it correct to say that $g(x+y)$ is a function of one variable or two variables? My attempt: It's clear to me that $g(x)$ is a function of one variable and $g(x,y)$ is a function of two variables. But I'm not sure about $g(x+y)$. I would guess $g$ is a function of a function and the inner function can be thought of as ""one variable"" that has ""two variables."" That seems really convoluted... What are some trivial examples of the statement above? My attempts: My trivial example A: $f(x)=C$ and $g(x+y) = x+y$ My trivial example B: $f(x)=C$ and $g(x+y) = (x+y)^{30} + y^{x} - x$ My trivial example C: $f(x) = 42$ and $g(x+y) = 42$ My trivial example D: $f(x) = 11$ and $g(x+y) = 5u - u$ Are those acceptable trivial examples? In my last example I switched it up to $u$ on purpose... kind of shooting in the dark. Can you give me some trivial examples if mine are wrong? Is it true that $\forall x,y \quad$ if $f(x) = g(x,y)$ then the LHS must be a constant? I know how to prove it if it's $g(x+y)$ but not for $g(x,y)$. If this is not true can you give me a trivial counter example? Let's say that $h(x,y)$ is a function of distance. Then you can say $h(x,y) = k(x^{2}+y^{2})$. You don't have to put the square root part of the distance function into $k$ because that can be part of the function $k()$ itself. But I don't think you can ""simplify"" it further from $x^{2}+y^{2}$. Correct? It's interesting to me that $k((x^{2}+y^{2})^{50})$ can be called a ""function based on distance"" even though it is powered to the 50 and the distance formula is powered to 0.5... Thank you for your help and patience!",['algebra-precalculus']
2644022,Proving that two curves in $\mathbb{R^3}$ with the same binormal vector are congruent,"Let $\alpha, \bar{\alpha}: I \mapsto \mathbb{R^3}$ be two regular unit speed curves with non vanishing curvature and torsion. Prove that if the binormal vectors of the curves coincide, i.e $B(s) = \bar{B}(s)$, they are congruent. I know there is a unique isometry that takes the orthonormal frenet frame of $\alpha$ to that of $\bar{\alpha}$, but I don't know how to prove what the exercise is asking me. I  tried a proof by contradiction but that led nowhere. I'd be grateful for any help.","['curves', 'isometry', 'frenet-frame', 'differential-geometry']"
2644054,"Inclusion-exclusion, Injections, Surjections","If $X = \{1, 2, 3\}$ and $Y = \{1, 2, 3, 4, 5, 6\}$, how many injections are there from $X$ to $Y$? How many surjections are there from $Y$ to $X$? For the injections from $X$ to $Y$ there should be $6$ functions for $1$, $5$ functions for $2$ and $4$ functions for $3$. So $6*5*4 = 120$ injections from $X$ to $Y$. But I am a little confused for the second part. How exactly will I be able to find what the total number of functions (both injective and surjective) are? I can't use the same method as before because $|Y|$ is greater than $|X|$. I think I need to find the number of injections and then subtract it from the number of total functions to get the number of surjections. But I am a little confused about how I would apply the principle of inclusion-exclusion here to do that. Any help?","['inclusion-exclusion', 'combinatorics', 'functions', 'discrete-mathematics']"
2644057,Show that continuous functions with limits equal are neither 1-1 nor onto.,"Context: So I am given the problem, "" Show that $f:\mathbb R\to\mathbb R$ is neither 1-1 nor onto when $f$ is defined as $f(x) = x^2+ax+b$ ."" I can do this easily enough using some tricks from basic calculus and whatnot, but it got me thinking that this neither 1-1 nor onto was something that should be true for quite a lot more functions. Question Now my idea is that for any function continuous $f:\mathbb R\to\mathbb R$ for which $$\lim_{x\to-\infty}f(x) = \lim_{x\to\infty}f(x)$$ then $f$ should be neither 1-1 nor onto . This seems straightforward enough, but I am not sure how to go about proving such a thing. I'm pretty certain that I can show that it isn't 1-1 with some fancy use of the intermediate value theorem, but I'm fairly stumped on surjectivity, in fact I'm wondering if the function could do something odd where it keeps bouncing up and down in some weird way if it's able to cover all values in $\mathbb R$ in a finite space. Note: $\lim_{x\to-\infty}f(x) = \lim_{x\to\infty}f(x)$ is intended to imply that both these limits exist, or are $\pm\infty$","['real-analysis', 'functions']"
2644071,Suppose $V$ is finite-dimensional and $E$ is a subspace of $\mathscr L(V)$,"Suppose $V$ is finite-dimensional and $E$ is a subspace of $\mathscr L(V)$ such that $ST\in E$ and $TS \in E$ for all $S \in \mathscr L(V)$ and all $T\in E$. Prove that $E = \{0\}$ or $E=\mathscr L(V)$. I have started the proof, but I get lost and am not sure how to finish out what I have: Suppose $v_1,\ldots,v_n$ is a basis of $V$. If $E=\{0\}$, we are done. Suppose $E\neq\{0\}$, then there exists a nonzero $T\in E$, which means there exists some $v_k\in\{v_1,\ldots,v_n\} $ such that $T(v_k)\neq0$. Let $a_1,\ldots,a_n\in \Bbb F$ such that $T(v_k)=a_1v_1+\cdots+a_nv_n\neq0$ meaning there exists some $a_l\in \{a_1,\ldots,a_n\}$ such that $a_l\neq0$. Clearly, I'll need to incorporate the fact that $ST$ and $TS$ are in $E$, and hopefully get to the point that $I\in E$.",['linear-algebra']
2644076,How is $y' = x^2$ a differential equation if it doesn't contain a function $y$?,"The way I learned differential equations is in the form $$y' = y$$ for example. So for example, $y' = x$ or $y'' = 0$ was never given as examples as differential equations. However, according to my new textbook $y' = x^2$ is given as an example of a differential equation. Can someone explain what's going on here?","['derivatives', 'ordinary-differential-equations']"
2644104,"If $\tan^{-1} \left(\frac {\sqrt {1+x^2} - \sqrt {1-x^2}}{\sqrt {1+x^2} + \sqrt {1-x^2}}\right) = \alpha$, then prove $x^2=\sin(2\alpha)$","If $\tan^{-1} \left(\dfrac {\sqrt {1+x^2} - \sqrt {1-x^2}}{\sqrt {1+x^2} + \sqrt {1-x^2}}\right)  = \alpha$ then prove that: $x^2= \sin (2\alpha) $ My Attempt:
$$\tan^{-1} \left(\dfrac {\sqrt {1+x^2}-\sqrt {1-x^2}}{\sqrt {1+x^2} + \sqrt {1-x^2}}\right) =\alpha$$
$$\dfrac {\sqrt {1+x^2}-\sqrt {1-x^2}}{\sqrt {1+x^2} + \sqrt {1-x^2}}=\tan (\alpha )$$
$$\dfrac {1+x^2-2\sqrt {1+x^2}.\sqrt {1-x^2}+ 1 - x^2}{1+x^2-1+x^2}=\tan (\alpha)$$
$$\dfrac {1-\sqrt {1+x^2}.\sqrt {1-x^2}}{x^2}=\tan (\alpha)$$","['trigonometry', 'inverse-function']"
2644133,Name for a function that can handle arbitrary number of arguments,"I am writing a proof, which uses functions that can handle an arbitrary number of parameters like summing, or averaging. In other words, I'm referring to functions like: $f(x_1, ... x_n) = \sum_i x_i$, or $f(x_1, ... x_n) = 1/n \sum_i x_i$, or even $f(x_1, ... x_n) = \sum_i i \cdot x_i$ Clearly, $n$ can be arbitrary and these definitions would still make sense. I'd like to call these functions a name. Is there an existing name for such functions? As an example, I'd like to be able to say: ""Let $f$ be a ______ function that acts on some (or all) of the elements of $S$"" (So here $f$ would be any function that accepts any number of elements from $S$ as arguments"". What's the right way to word this?","['elementary-set-theory', 'proof-writing', 'functions']"
2644167,How to interpret probability density function of transformed variable?,"I am currently reading digital image processing by Rafael c. Gonzalez (pdf link page 92 in page and 103 in pdf, equation 3.3-3). 
Basically what it says is if: r : denotes the intensities of an image and has range  [ $0$ - ($L-1$)]. s = $T(r)$ Let $p_s$(r) and $p_s$(s)  denote the PDFs of r and s. A fundamental result from basic probability theory is that if $p_s$(r) and $p_s$(s) are known and $T(r)$ is continuous and differentiable over the range of values of interest then the PDF of the transformed (mapped) variable $s$ can be obtained using simple formula. $p_s$(s) = $p_s$(r)$|$$\frac{dr}{ds}$$|$ Where did this simple formula came from? I am trying to wrap my head around where did $|$$\frac{dr}{ds}$$|$  came from?","['derivatives', 'image-processing', 'probability']"
2644179,Minimal ideal in commutative finite rings,"Let $R$ be a commutative finite ring with identity, and let $I$ be a minimal ideal of $R$, that is, a non-zero ideal that there is no ideal strictly between $I$ and $0$. Now let $\{I_i\}_{i\in A}$ be a family of ideals of $R$ such that $I\subseteq \sum_{i\in A} I_i$. How can we show that there exists $j\in A$ such that $I\subseteq I_j$? If the statment is not true is there any condition under which it is true?","['abstract-algebra', 'finite-rings', 'ideals', 'commutative-algebra']"
2644218,"Is the cartesian product of a finite amount of countable sets, countable?","I would assume so. I know that the product of two countable sets is countable, but what about a finite number?",['elementary-set-theory']
2644242,Evaluate a sum which almost looks telescoping but not quite:$\sum_{k=2}^n \frac{1}{k(k+2)}$ [duplicate],"This question already has answers here : Help with telescoping sum $\sum_{i=3}^n \frac{1}{i(i+3)} $ (2 answers) Closed 6 years ago . Suppose I need to evaluate the following sum: $$\sum_{k=2}^n \frac{1}{k(k+2)}$$ With partial fraction decomposition, I can get it into the following form: $$\sum_{k=2}^n \left[\frac{1}{2k}-\frac{1}{2(k+2)}\right]$$ This almost looks telescoping, but not quite... so at this point I am unsure of how to proceed.  How can I evaluate the sum from here?","['algebra-precalculus', 'telescopic-series', 'summation', 'discrete-mathematics']"
2644277,Calculate $\text{div} (f)$,"Let $A=(a_{ij})$ be a positive definite real Hermitian $N\times N$-matrix. Consider
$$f(x)=\frac{x}{|x|^2}e^{{-\frac{1}{2}}\langle Ax,x\rangle },\;\forall x\in \mathbb{R}^N\backslash\{0\}.$$ Why
  $$\text{div} (f)(x)=\left(\frac{(N-2)}{|x|^2}-\frac{\langle Ax,x\rangle}{|x|^2} \right)e^{{-\frac{1}{2}}\langle Ax,x\rangle}?$$ Notice that $$\text{div} (f)(x)=\sum_{i=1}^N \frac{\partial f}{\partial x_i}(x).$$","['multivariable-calculus', 'partial-derivative', 'vector-analysis']"
2644294,"How many trees on $\{1,2,3,4,5,6,7\}$ have a vertex of degree 2?","How many trees on $\{1,2,3,4,5,6,7\}$ have a vertex of degree 2 ? Attempt - It feels like an inclusion exclusion problem (using kailey's code) , let's define $|A_i| \Rightarrow $ vertex $i$ is of degree $1$. $|Ai\, \cup A_j$| - vertices $i,j$ are of degree $1$ and so on. So following my calculation we might get - $7 \cdot 5\cdot  6^4 - \binom{7}{2}\binom{5}{2}\cdot2\cdot5^3+ \binom{7}{3}\binom{5}{3}\cdot3!\cdot4^2 - \binom{7}{4}\binom{5}{4}\cdot4!\cdot3 + \binom{7}{5}5!$ What do you think? thank you !","['inclusion-exclusion', 'combinatorics', 'graph-theory']"
2644300,What are the most fundamental applications of probability theory outside pure math?,"What are the most important / fundamental / classical applications of probability theory outside of pure math? What were some of the original ""home runs"" of probability theory -- things that we could not do before, but which were very useful. Things that would make people say, ""Gosh, we've hit on a big idea here."" One example would be that probability is used in Quantum Mechanics. That's a good one, but I believe probability had already proved to be very useful even before QM came along.",['probability']
2644316,"Given $f'(x)\leq 1-f(x)^2$, prove $|f(x)|\leq 1$","Let $f$ be $C^1$ function on $\mathbb{R}$. Suppose that $$f'(x)\leq
 1-f(x)^2$$ Prove that $|f(x)|\leq 1 \: \forall x$. I suppose that such a function can be bounded by a solution to the ODE: $y'=1-y^2$
with the same initial value, but I don't know by which theorem, if at all. Trying to solve this ODE gives:
$$\frac{dy}{1-y^2}=dx \Rightarrow \int\frac{dy}{1-y^2}=\int dx=x+c$$
but now another problem arises: $\frac{1}{y^2-1}=\frac{1}{2}\left ( \frac{1}{y-1}-\frac{1}{y+1} \right )$
 and so taking anti-derviative depends whether $|y|\leq 1$ or not, which makes me even more confused. Can someone please make me some sense of all this mess?","['ordinary-differential-equations', 'upper-lower-bounds']"
2644355,Is it true that $0\in 1$?,"From Zermelo–Fraenkel set theory and Peano axioms, we have $0=\varnothing$ and $1=\varnothing\cup{\{\varnothing\}}\implies0\in 1$. Many thanks for your help!","['axioms', 'elementary-set-theory', 'peano-axioms']"
2644377,Canonical metric when $-K_X$ is nef?,"Let $X$ be a smooth projective variery. Let $-K_X$ be nef , then which type of Canonical metric In the sense of Einstein type metric is suitable for it. In fact when $K_X$ or $-K_X$ is ample WE know that WE have $ Ric(\omega)=-\omega$, and $ Ric(\omega)=\omega$,  when X is K-stable. In my opinion when $-K_X$ be nef then WE know that the Albanese map is surjective, I.e $\pi:X\to Alb(X)$ is surjective and the best Canonical metric is the relative Kahler Einstein metric along Albanese map $$Ric_{X/S}(\omega)=-\xi(s)\omega$$
As soon as the relative tangent sheaf $T_{X/S}$ is stable In the sense of Mumford. Where here $S=Alb(X)$ is Albanese variety  and $\omega$ is the relative Kahler form and $\xi(s)$ is fiberwise constant. In this case the right flow is the following Hyperbolic Relative Kahler Ricci flow. $$\frac{\partial^2\omega}{\partial s'\partial t}=-Ric_{X/S}\omega(s',t)-\xi(s)\omega_{s'}(t)$$ Where here $s'=\frac{1}{s}$ and $s\to 0$ See here the definition of relative Kahler form see my answer to this post What is a Kählerian variety? Also about Albanese map see my answer to this post What is the Albanese map good for? For nef Line bundle see my answer to this post nef Line bundles over Kähler manifolds When Tangent sheaf of a Fano Variery is nef see JPD paper https://arxiv.org/abs/1712.03725 My motivation is that let $\pi:X\to \Delta$  be a surjective holomorphic fibre space from a projective variery to a holomorphic disc. Let $K_{X_t}$ is ample then the Canonical divisor $K_{X_0}$ is nef and finding a type of Canonical metric on central fiber is an open question and it may admits several différent type of Canonical metrics including twisted KE See my post about Beauville-Bogomolov decomposition by using relative Kahler Ricci flow along Albanese map https://mathoverflow.net/questions/277561/kähler-ricci-flow-approach-for-beauville-bogomolov-type-decomposition Hassan Jolany","['moduli-space', 'kahler-manifolds', 'differential-geometry', 'algebraic-geometry']"
2644388,Computing $\lim_{n \rightarrow \infty} \int_{0}^{\pi/3} \frac{\sin^{n}x}{\sin^{n}x+\cos^{n}x}dx$ using Dominated Convergence Theorem,"So recently I found this integral: 
  $$\lim_{n \rightarrow \infty} \int_{0}^{\pi/3} \frac{\sin^{n}x}{\sin^{n}x+\cos^{n}x}dx$$ I know the answer should be $ \frac{\pi}{12} $ and I saw it can be solved using the Dominated Convergence Theorem. I managed to get the integral to this form:
$$\lim_{n \rightarrow \infty} \frac{\pi}{3}- \int_{0}^{\pi/3} \frac{1}{1+\operatorname{tg}^{n}x}dx$$ The new integral should be  $ \frac{\pi}{4} $. But I can't find the function which bounds the function inside the integral. 
Can you explain me how can I find the answer using DCT? Thanks in advance.","['real-analysis', 'limits', 'calculus', 'convergence-divergence', 'trigonometric-integrals']"
2644393,"Given $a_1 \leq a_2 \leq \dots \leq a_n$, how many possible orders are there for $\{a_i + a_j\}$?","Suppose we have $n$ variables $a_1 \leq a_2 \leq \dots \leq a_n$. If the values of the variables are not known, in how many ways could $\{a_i + a_j\}_{\{i,j\} \in {[n] \choose 2}}$ be ordered using $<$ and $=$? For example, if $n=4$, we would have $a_1, a_2, a_3, a_4$. If we assign $a_1 = 0, a_2 = 1, a_3 = 5, a_4 = 12$, then $a_1+a_2 < a_1 + a_3 < a_2 + a_3 < a_1 + a_4 < a_2 + a_4 < a_3 + a_4$. However, if we assign $a_1 = 1, a_2 = 4, a_3 = 5, a_4 = 6$, then $a_1 + a_2 < a_1+a_3 < a_1 + a_4 < a_2 + a_3 < a_2 + a_4 < a_3 + a_4$, which is a different ordering of $\{a_i + a_j\}$. This means that for $n=4$, we have at least two orderings of $\{a_i + a_j\}$. Of course there are many more. For $n$ variables, how many of these orderings of $\{a_i + a_j\}$ are possible? I'd like $a_{i_1} + a_{j_1} < a_{i_2} + a_{j_2}$ to be distinct from $a_{i_1} + a_{j_1} = a_{i_2} + a_{j_2}$. Would anything preserving the natural partial ordering work? I'd appreciate any help or suggestions. Thank you.",['combinatorics']
2644442,"$\min\left\lbrace a, \max \left\lbrace b, c \right\rbrace \right\rbrace$ =?","I have been studying Fuzzy Set Theory and in that, we come across standard fuzzy union ($\cup$) and intersection ($\cap$) defined as the maximum and minimum of membership values respectively. In some proof regarding distributive laws, I came across the expression, $$\min \left\lbrace A(x), \max \left\lbrace B(x), C(x) \right\rbrace \right\rbrace$$
where these $A(x), B(x) \text{ and } C(x)$ are membership values of $x$ in $\left[ 0, 1 \right]$. However, to prove the distribution of intersection over addition, i.e., $A \cap \left( B \cup C \right) = \left( A \cap B \right) \cup \left( A \cap C \right)$, I will need to prove $$\min \left\lbrace A(x), \max \left\lbrace B(x), C(x) \right\rbrace \right\rbrace = \max \left\lbrace \min \left\lbrace A(x), B(x) \right\rbrace, \min \left\lbrace A(x), C(x) \right\rbrace \right\rbrace$$. Any insights about how to prove this will be useful!","['elementary-set-theory', 'analysis']"
2644457,What are the finite subgroups of isometries of a flat triangular torus?,"Let $\mathbb{Z}^2$ act on $\mathbb{R}^2$ as follows: $(1,0)$ acts by translating the plane by $(1,0)$, and $(0,1)$ acts by translating plane by $(1/2, \sqrt{3}/2)$. Now consider the torus $\mathbb{R}^2 / \mathbb{Z}^2$. What are the finite subgroups of the group of isometries? It seems like such a classification should be possible, from the classification of wallpaper groups. I see that the following groups are possible: (1) Any group $G \times H$ where $G$ and $H$ are cyclic or dihedral,
(2) or any subgroup of $D_{12}$, the dihedral group of order $12$. Are there any other finite groups of isometries of this torus?","['finite-groups', 'symmetry', 'group-theory']"
2644479,Can this closed form for $\sum_{n=1}^\infty \arctan \frac{a^2}{n^2}$ be proved directly by contour integration?,"The general closed form for $$\sum_{n=1}^\infty \arctan \frac{a^2}{n^2}= \arctan \left( \frac{\tan \frac{\pi a}{\sqrt{2}}-\tanh \frac{\pi a}{\sqrt{2}}}{\tan \frac{\pi a}{\sqrt{2}}+\tanh \frac{\pi a}{\sqrt{2}}} \right)$$ is shown here and here by referring to the infinite product for the sine. However, by using the series for the arctangent and the integral form of the zeta function, we can write the integral form for the series: $$\sum_{n=1}^\infty \arctan \frac{a^2}{n^2}=2 \int_0^\infty \sin \frac{a x}{\sqrt{2}} ~\sinh \frac{a x}{\sqrt{2}} ~\frac{dx}{x(e^x-1)}$$ This integral is quite complicated, but I believe contour integration can be used to evaluate it directly, without getting back to the series. Can the closed form for the integral be proved with the use of contour integration (or some other integration methods, without using the series and the sine product)? I am still bad with contour integration, so this problem is beyond my level. I would be grateful for an outline of the solution.","['contour-integration', 'definite-integrals', 'sequences-and-series']"
2644489,Continuity of a real function defined on an orbit space,"I am reading some paper, where they claim the following: Let $G$ be a compact (Hausdorff) group and let $X$ be a locally, compact, Hausdorff space. Assume that $G$ acts on $X$ continuously. Denote by $C_0(X)$ the continuous functions on $X$ with complex values. Denote by $X/G$ the orbit space (it is Hausdorff as well), and let $\pi: X\to X/G$ be the canonical quotient map. claim: Let $f\in C_0(X)$. The map $\pi(x)\mapsto sup_{g\in G}|f(g\cdot x)|$ is a continuous map $X/G\to \mathbb{R}$. The proof starts like that: Let $f\in C_0(X)$, let $\epsilon>0$ and let $x\in X$. Use continuity of $f$ to find, for every $g\in G$, an open neighborhood $W_g$ of $g\cdot x$ such that $|f(g\cdot x)-f(y)|<\epsilon$ for all $y\in W_g$. By compactness of $G$, there exists an open neighborhood $W$ of $x$ such that $g\cdot W\subseteq W_g$ for all $g\in G$. I can not see why the last claim is true or why it follows from compactness... it seems like they actually claim that $\bigcap\limits_{g\in G}g^{-1}\cdot W_g$ is open (of course, it contains $x$, but I don't see why should it be open...). An alternative approach to the proof or counter example for the claim would be appreciated as well. Thank for any help!","['topological-groups', 'continuity', 'group-actions', 'general-topology', 'group-theory']"
2644506,Sanity check regarding Galois group of $X^8 - 3$,"This is more to check if what I'm doing is correct. Let $P(X) = X^8 - 3$. I know that the splitting field of $P(X)$ is $\Bbb Q(\zeta_8, \sqrt[8]{3}) = \Bbb Q(i, \sqrt{2}, \sqrt[8]{3})$ and so I can describe the elements of the Galois group by automorphisms \begin{align}
i &\longmapsto \pm i\\
\sqrt{2} &\longmapsto \pm \sqrt{2}\\
\sqrt[8]{3} &\longmapsto \zeta_8^a\sqrt[8]{3},\ \ a \in \lbrace 0, 1, \dots, 7\rbrace.
\end{align} I'm not sure if this is a silly question, but does the action on $i$ and $\sqrt{2}$ affect the action on $\sqrt[8]{3}$? That is, for example, if I have \begin{align}
\sigma:\ i &\longmapsto -i\\
\sqrt{2}  &\longmapsto \sqrt{2}\\
\sqrt[8]{3} & \longmapsto \zeta_8^2\sqrt[8]{3}
\end{align} and \begin{align}
\tau:\ i &\longmapsto i\\
\sqrt{2}  &\longmapsto -\sqrt{2}\\
\sqrt[8]{3} & \longmapsto \zeta_8^3\sqrt[8]{3}
\end{align} then $\sigma(\sqrt[8]{3}) = \zeta_8^2\sqrt[8]{3}$, and now, since $\zeta_8 = \frac{1}{\sqrt{2}}(1+i)$, does $\tau$ applied to this give $$\tau(\sigma(\sqrt[8]{3})) = \tau(\zeta_8)^2\tau(\sqrt[8]{3}) = (\zeta_8^5)^2 \cdot\zeta_8^3\sqrt[8]{3} = \zeta_8^5\sqrt[8]{3}$$ so that \begin{align}
\tau \circ \sigma :\ i &\longmapsto -i\\
\sqrt{2}  &\longmapsto -\sqrt{2}\\
\sqrt[8]{3} & \longmapsto \zeta_8^5\sqrt[8]{3}\ \ ?
\end{align}","['abstract-algebra', 'galois-theory', 'field-theory']"
2644531,Show that uniform limit of sequence of Baire $1$ functions is Baire $1$,"Let $a<b.$
We say that a function $f:[a,b]\to\mathbb{R}$ is Baire $1$ if it is a pointwise limit of some sequence of real-valued continuous functions. Given a sequence $(g_n)_{n=1}^\infty$ on $[a,b],$ we say that $(g_n)_{n=1}^\infty$ converges to $f$ uniformly if for every $\varepsilon>0,$ there exists $N\in\mathbb{N}$ such that for any $n\geq N$ and any $x\in [a,b],$ we have 
$$|g_n(x)-f(x)|<\varepsilon.$$ Theorem: If $(g_n)_{n=1}^\infty$ is a sequence of real-valued Baire $1$ functions on $[a,b]$ that converges to $f$ uniformly, then $f$ is also Baire $1.$ My attempt:
For each $n\in\mathbb{N},$ since $g_n$ is Baire $1,$ there exists a sequence of continuous functions $(g_n^m)_{m=1}^\infty$ that converges to $g_n$ pointwise. 
Let 
$$f_n=g_n^n,$$
that is, choose $f_n$  'diagonally' from the pool of $g_n^m.$
However, I notice that such $(f_n)_{n=1}^\infty$ may not converge to $f$ pointwise, as for any $x\in [a,b]$ and $\varepsilon>0,$ by uniform convergence, there exists $N\in\mathbb{N}$ such that 
$$|g_N(x)-f(x)|<\frac{\varepsilon}{2}.$$
By pointwise limit of $g_N,$ there exists $M \in \mathbb{N}$ such that for any $n\geq M,$ we have 
$$|g_N(x) - g_{N}^m(x)|<\frac{\varepsilon}{2}.$$
However, it may be the case that $N< M,$ that is, $f_N=g_N^N$  may not be 'captured' by pointwise convergence. But I cannot change my $f_N$ as this will make the argument circular. Any hint to fix this problem? 
If someone wants to provide another shorter proof, I would be glad to have a look.","['real-analysis', 'sequences-and-series', 'uniform-convergence']"
2644542,Defining holomorphic functions on Riemann sphere,"I am reading the book on Riemann surfaces by Miranda as a part of my reading course. I am facing this (maybe elementary) confusion. Let $S^2$ denote the unit sphere in $\mathbb{R}^3$. This is given a Riemann surface structure by means of charts:
$$\phi:S^2-\{(0,0,1)\}\rightarrow \mathbb{C} : \phi(x,y,z)=(x+iy)/(1-w)\text{ and}$$
$$\psi:S^2-\{(0,0,-1)\}\rightarrow \mathbb{C} : \psi(x,y,z)=(x-i y)/(1+w).$$
Here, the point $(0,0,1)$ is identified with the point at $\infty$. These charts are compatible because $\phi\circ\psi^{-1}(z)=1/z=\psi\circ\phi^{-1}(z)$, which is holomophic in the domain of definition. Now, a complex valued function $f$ defined in a neighbourhood of a point $p$ of a Riemann surface $X$ is defined to be holomorphic at $p$ if there is a chart $\tau:U\rightarrow V$ such that $f\circ\tau^{-1}$ is holomorphic at $\tau(p)$. Now he states the following in which I have a doubt. Let $f$ be a complex valued function defined in a neighbourhood of $\infty$ in the Riemann sphere. The claim is that $f$ is holomorphic at $\infty$ iff $f(1/z)$ is holomorphic at $z=0$. I am trying to write this out using definitions and getting stuck. Since $(0,0,1)$ is identified with $\infty$, the chart about $\infty$ is $\psi$ above. Now $ f$ is holomorphic at $(0,0,1)\ \iff\ f\circ\psi^{-1}(z)$ is holomorphic at $\psi(0,0,1)=0$. How do I get $f(1/z)$ from this. Also technically $1/z$ is function which is defined on the punctured complex plane right. So what is $f(1/z)$? The closest I can think of is $f\circ\psi^{-1}(z)=f\circ\phi^{-1}\circ\phi\circ\psi^{-1}(z)=f\circ\phi^{-1}(1/z)$ on $\mathbb{C}^*$. Is this what he means? But this function is not even defined at zero. I think I am getting caught in pedantic details. But it would be great if some can help by indicating a proof of the above claim.","['riemann-surfaces', 'complex-analysis']"
2644611,Question about linear bounded operator in Banach spaces.,"Let $T:X\to Y$ a linear bounded operator between Banach spaces. Let $U$ a neighbourhood of $0\in Y$, $t\in(0,1)$ and suppose that $\forall u\in U$ $\exists \bar x\in X$ with $\|\bar x\|\le1$ and $\bar u\in U$ such that $$u=T\bar x +t\bar u.$$
Then if I take $u\in U$, I can write $$u=T\left(\sum_{i=0}^{\infty} t^ix_i\right), \ \ \ \|x_i\|\le1$$ and that series has sense since $$\|\sum_{i=0}^{\infty} t^ix_i\|\le \sum_{i=0}^{\infty} t^i=C<+\infty.$$ In this way I obtain that $$U\subset T\left(B_X(0,C)\right).$$ Is it correct?","['functional-analysis', 'banach-spaces']"
2644638,Question about a technique used to find extremum of a polynomial function,"Someone told me to find extremum of a function in form of $f(x) = (x-a)^n (x-b)^m$ we can use this method: (this a method so that we can find the extremum without using the derivative) ($n$ and $m$ are not necessarily natural numbers and can be any real number)
$$x_{ext} = \frac{ma+nb}{m+n}$$
i.e. we calculated the weighted mean of roots where their weights are the degree of the other term. I want to know that does this method have any name for example name of a mathematician or something else? And I also want to know can this method 
be somehow generalized into polynomial functions with more than two roots i.e. $(x-a)^n(x-b)^m(x-c)^p ...$ ? If yes, how?","['derivatives', 'polynomials', 'maxima-minima', 'calculus']"
2644640,Calculating derivatives of the Weierstrass $\wp$-function in terms of $\wp$ and $\wp '$,"This is probably a very standard question in complex analysis, but it doesn't seem to have been asked here yet. If we have two $\mathbb{R}$-linearly independent non-zero complex numbers $\omega_{1}$ and $\omega_{2}$, and we let $\Omega = \{m\omega_{1} + n\omega_{2}: m, n \in \mathbb{Z}\}$ and $\Omega^{*} = \Omega - \{0\}$, then my definition of the Weierstrass $\wp$-function is $$\wp (z) = \frac{1}{z^2} + \sum_{\omega \in \Omega^{*}} \bigg( \frac{1}{(z-\omega )^2} - \frac{1}{\omega ^2}\bigg).$$ Working from this page: http://mathworld.wolfram.com/WeierstrassEllipticFunction.html , we let $f(z) = \wp (z) - \frac{1}{z^2}$, so that $f(0) = 0$ and $f$ is an even function. Thus all of its odd-order derivatives are $0$ at $z=0$. Expanding $f$ as a Maclaurin series, bearing in mind that all the odd terms are $0$, we get $$f(z) = \frac{z^2}{2!}f''(0) + \frac{z^4}{4!}f^{(4)}(0) + \cdots.$$ That's perfectly OK, but the MathWorld page then goes on to say that we can calculate the derivatives of $f$ from this, and then from there we can get derivatives of $\wp$. This is difficult to work out. Also, it's easy to show that $\wp ' = \sum_{\omega \in \Omega}\frac{-2}{(z-\omega )^3}$, and getting explicit expressions for higher derivatives of $\wp$ is also easy. However, getting them in terms of just $\wp$ and $\wp '$ isn't so easy, so my question is, are we on the right track to get these by finding $f$ and its Maclaurin series as above? In the post High-order antiderivatives of the Weierstrass P-function , it says that $\wp '' = 6(\wp)^2 - \frac{1}{2}g_{2}$, which might be what I'm after, but what is $g_2$? Basically, I'm looking for the simplest method of getting $\wp ^{(n)}$ in terms of $\wp$ and $\wp '$. Thanks for any help.","['complex-analysis', 'elliptic-functions']"
2644649,Prove that $a_n=\sqrt[n]{f\left(\frac{1}{n} \right)^n+f\left(\frac{2}{n} \right)^n+\dots+f\left(\frac{n}{n} \right)^n}$ is convergent,"$f$ takes positive values and is uniformly continuous. Prove that $$a_n=\sqrt[n]{f\left(\frac{1}{n} \right)^n+f\left(\frac{2}{n} \right)^n+\dots+f\left(\frac{n}{n} \right)^n}$$
  is convergent By uniform continuity, for large enough $n$ we have $|f\left(\frac{k}{n}\right)-f\left(\frac{k+1}{n} \right)|<\epsilon$. I tried to use this in order to bound the sum, but that power $n$ makes it too large...","['continuity', 'real-analysis', 'sequences-and-series', 'uniform-continuity']"
2644700,What's new in higher dimensions?,"This is a very speculative/soft question; please keep this in mind when reading it. Here ""higher"" means ""greater than 3"". What I am wondering about is what new geometrical phenomena are there in higher dimensions. When I say new I mean phenomena which are counterintuitive or not analogous to their lower dimensional counterparts. A good example could be hypersphere packing . My main (and sad) impression is that almost all phenomena in higher dimensions could be thought intuitively by dimensional analogy. See for example, this link : What this implies (for me) is the boring consequence that there is no new conceptual richness in higher dimensional geometry beyond the fact than the  numbers are larger (for example my field of study is string compactifications and though, at first sight, it could sound spectacular to use orientifolding which set a loci of fixed points which are O3 and O7 planes; the reasoning is pretty much the same as in lower dimensions...) However the question of higher dimensional geometry is very related (for me) to the idea of beauty and complexity: these projections to 2-D of higher dimensional objects totally amazes me (for example this orthonormal projection of a 12-cube ) and makes me think there must be interesting higher dimensional phenomena... I would thank anyone who could give me examples of beautiful ideas implying “visualization” of higher dimensional geometry…","['big-list', 'visualization', 'soft-question', 'geometry', 'manifolds']"
2644731,Heat equation - Step function initial condition,"Suppose you want to solve the usual heat equation on the real line $[-\infty ,+\infty ]$
\begin{equation}
\begin{cases}
 \partial_t u(x,t)= \partial_{xx} u(x,t)\\
 u(x,0)=f(x)\\
\end{cases},
\end{equation}
where the initial condition is given by a step function
\begin{equation}
f(x)= 
\begin{cases}
0 \ \ \ \ \text{if} \ \ x<0\\
1 \ \ \ \ \text{if} \ \ x>0\\
\end{cases}.
\end{equation}
By solving the equation using Green's function method it's possible to find a solution of the form
\begin{equation}
u(x,t)=\frac{1}{2}\left( 1+\mathrm{erf} \left( \frac{x}{\sqrt{4t}} \right) \right)
\end{equation}
A short derivation of this result can be found at this link . It seems to me that the limit $(x,t)\to (0,0)$ of this function does not exist (in the sense of limit of functions); this is of course in conflict with the IC imposed. Why is this happening? Am I forgetting something while calculating the solution? Or am I misinterpreting the word ""limit"" for this particular case?","['real-analysis', 'partial-differential-equations']"
2644775,Closed algebraic form of $\cos(\frac{\pi}{7})$,"We all know that $\cos(\frac{\pi}{6})=\frac{\sqrt 3}{2}$, $\cos(\frac{\pi}{4})=\frac{\sqrt 2}{2}$ and $\cos(\frac{\pi}{3})=\frac{1}{2}$. One can also prove  that $\cos(\frac{\pi}{5})=\frac{\sqrt 5+1}{4}$. But it seems that $\cos(\frac{\pi}{7})$ cannot be put in a closed form algebraic expression. Is there a proof of such a claim? I feel like this has to do with the Abel–Ruffini theorem . The same for $\cos(\frac{\pi}{8})$ and $\cos(\frac{\pi}{9})$. But $\cos(\frac{\pi}{10})=\sqrt{\frac{5}{8}+\frac{\sqrt{5}}{8}}$.","['irreducible-polynomials', 'polynomials', 'abstract-algebra', 'trigonometry', 'algebra-precalculus']"
2644796,Tail Sum Formula: Expected Maximum,"Tail Sum Formula states that: For $X$ with possible values $\{0, 1, 2, \ldots , n\}$,
$$\operatorname E(X) = \sum_{j=1}^n P(X \ge j)$$ Suppose that 4 dice are rolled. Find the expected maximum $\operatorname E(M)$ of the
  4 rolls. $M$ has possible values $\{1, 2, \ldots, 6\}$ all consecutive. Thus, we can use the Tail Sum Formula. \begin{align}
\operatorname E(M) & = \sum_{j=1}^{6}P(M \ge j) \\[10pt]
& = P(M \ge 1) + P(M \ge 2) + P(M \ge 3) + P(M \ge 4) + P(M \ge 5) + P(M \ge 6) \\[10pt]
& = \left(\frac 6 6 \right)^4 + \left(\frac 5 6 \right)^4 + \left(\frac 4 6 \right)^4 + \left(\frac 3 6 \right)^4 + \left(\frac 2 6 \right)^4 + \left(\frac 1 6 \right)^4 \\[10pt]
& = 1.755
\end{align} But the expected minimum is also $1.755$! Edit 1: Let $X_i$ be the value obtained on roll $i$, $1 \le i \le 4$. $P(M \ge j) = $ Probability that the maxium of these 4 rolls is $\ge$ j $= 1 - P(M \lt j)$ $= 1 - P(M \le j-1)$ Probability that the maxium of these 4 rolls is $\le$ j $= 1 - P(X_1 \le j - 1, X_2 \le j - 1, ..., X_6 \le j - 1)$ Since each roll is independent... $= 1 - P(X_1 \le j - 1) P(X_2 \le j - 1) ... P(X_6 \le j - 1)$ $= 1-(\frac{j-1}{6})^4$ \begin{align}
\operatorname E(M) & = \sum_{j=1}^{6}P(M \ge j) \\[10pt]
& = P(M \ge 1) + P(M \ge 2) + P(M \ge 3) + P(M \ge 4) + P(M \ge 5) + P(M \ge 6) \\[10pt]
& = \left(1- (\frac 0 6)^4 \right) + \left(1- (\frac 1 6)^4 \right) + \left(1- (\frac 2 6)^4 \right) + \left(1- (\frac 3 6)^4 \right) + \left(1- (\frac 4 6)^4 \right) + \left(1- (\frac 5 6)^4 \right) \\[10pt]
& = 5.244598765
\end{align}","['statistics', 'probability', 'expectation', 'dice']"
2644861,Why aren't the sample paths of this stochastic process defined?,"I read this in a course but I don't understand why. ""As the stochastic integral of an integrand $\xi \in L^1(X)$ with respect to a semimartingale $X$ exists up to all times $t\ge 0$ , it defines a new stochastic process $Y(t)\equiv\int_0^t\xi\,dX$ . However, the integral takes values in the space $L^0$ of random variables defined up to almost sure equivalence, which is not enough for the samples paths $t\mapsto Y(t)$ to be defined (even on a set of probability one)."" They say if we take a cadlag version of $Y$ , then the sample paths are defined. Can you give an explicit example or a proof to help me understand why the sample paths aren't defined ? And why taking a cadlag version is enough for the sample paths to be defined ?","['stochastic-processes', 'probability-theory', 'measure-theory', 'stochastic-integrals', 'stochastic-calculus']"
2644864,How to calculate the value of $\sum\limits_{k=0}^{\infty}\frac{1}{(3k+1)\cdot(3k+2)\cdot(3k+3)}$?,How do I calculate the value of the series $$\sum_{k=0}^{\infty}\frac{1}{(3k+1)\cdot(3k+2)\cdot(3k+3)}= \frac{1}{1\cdot2\cdot3}+\frac{1}{4\cdot5\cdot6}+\frac{1}{7\cdot8\cdot9}+\cdots?$$,"['real-analysis', 'fractions', 'definite-integrals', 'summation', 'sequences-and-series']"
2644888,Cohomology of projective bundle only depends on base and fiber?,Let $P\to X$ be a $\mathbb P^n$ bundle. Is it true that all the (co)homology group only depends on $X$ and $n$ (and independent of the transform funcions) ?,"['algebraic-topology', 'homology-cohomology', 'fiber-bundles', 'algebraic-geometry']"
2644901,Connecting conjugation in the symmetric group to a more general intuition of conjugation through Cayley's theorem,"I would like some feedback as to whether this intuition is correct. Conjugation in the symmetric group amounts to relabeling of the domain and codomain, preserving the cycle structure. For example, Conjugating sigma by tau, $\tau\sigma\tau^{-1},$ preserves the original cycle structure (in colors) of the $(153)(24)$ permutation in $S_5,$ which essentially is $\Big(\tau(1)\tau(5)\tau(3)\Big)\Big(\tau(2)\tau(4)\Big)=(123)(45):$ or the result of composing $\tau(\sigma(\tau^{-1})):$ -i.e. a 3-cycle / 2-cycle permutation. Since it is henceforth clear that conjugacy classes of $S_5$ will correspond to permutations that share the same cycle structure, and Cayley's theorem states that every group G is isomorphic to a subgroup of the symmetric group acting on G, what can we say that conjugacy preserves in a generic fashion for any type of (finite) group?","['abstract-algebra', 'group-theory']"
2644939,American call option is a submartingale,"Consider a complete, arbitrage-free $T$-period market $(S^0_t,...,S^d_t)_{t=0,\dots,T}$ on a filtered probability space with risk-neutral measure $\mathbb P^*$. Furthermore, $S^0_{t+1}\ge S^0_t$ $\mathbb P^*$-almost surely. We are interested in the american call-option $C_t=(S^1_t-K)^+$ (With strike $K>0$) Show the following: 1) The discounted option $H=\frac C {S^0}$ is a $\mathbb P^*$-submartingale 2) The Snell envelope $U^{\mathbb P^*}$ of $H$ is a $\mathbb P^*$-martingale. I need some help with these questions. \ So far I tried the following: Regarding 1): I know that I need to show that for all $t$ we have $E_{\mathbb P^*} [H_{t+1}|\mathcal F_t] \le H_t$. But with that few information given, I don't know how to start. Of course we could directly use $S^0_{t+1}\ge S^0_t$, but then, we are still left with $E_{\mathbb P^*} [C_{t+1}|\mathcal F_t]\le C_t.$ Regarding 2): I know that the Snell envelope is a supermartingale, so it suffices to show that in this case is also a submartingale. I tried the following induction argument, but i am sceptical if that is true: (I am sceptical about the second line) $$ E_{\mathbb P^*}[U^{\mathbb P^*}_t|\mathcal F_{t-1}]=  E_{\mathbb P^*}[E_{\mathbb P^*}[U^{\mathbb P^*}_{t+1}|\mathcal F_t] \vee H_t|\mathcal F_{t-1}] \\
\ge  E_{\mathbb P^*}[E_{\mathbb P^*}[U^{\mathbb P^*}_{t+1}|\mathcal F_t]|\mathcal F_{t-1}] \vee  E_{\mathbb P^*}[H_t|\mathcal F_{t-1}] \\
\ge E_{\mathbb P^*}[U^{\mathbb P^*}_{t}|\mathcal F_{t-1}] \vee H_{t-1} = U^{\mathbb P^*}_{t-1}
 ,$$ where in the last line we used the induction hypothesis that the Snell envelope has the sub-martingale property for $t>t-1$ and that $H$ is a submartingale. Also the  Induction start $t=T$ should simply follow from $H$ being a submartingale..","['martingales', 'finance', 'measure-theory']"
2644956,The difference of two set differences $(A-C) - (B-C)$,"I am trying to write the statement above using logic. I managed to break up the first difference sign using the definition of set difference and get: Suppose $$x\in (A-C) \land x\notin(B-C),$$ but I have no idea how to break it further.","['elementary-set-theory', 'discrete-mathematics']"
2644997,"Number of set, say $A$, of subset such that $\sum |A_i|=|\xi|$ and that $A_{ij}=A_{\ell k}\iff \ell=i\land k=j$","My little brother asked me a question that I cannot answer and I would love to get some help with it. Background My brother tried to understand what ${n\choose k}$ means and came to conclusion that it gives you the number of sets that have exactly $k$ distinguish elements. After proving that ${n\choose k}={n!\over k!(n-k)!}$ he tried to find extension to this formula His Question He tried to find a formula for ${(n)\choose (k)}$ $${(n)\choose (k)}=\text{number of sets of subsets of $n$ elements set such that the combined size of the }\\\text{subsets is $k$ and the subsets in each set has 
 no repeating elements}$$ For example: For $(4)\choose(3)$ we construct the following set: $A=\{1,2,3,4\}$ I search how many sets of subsets of $A$, let's call the subsets $B_i$, there is such that the sum of $B_i$ in each set is equal $3$ and there is no repeated element from $A$. In this example we have the following sets: $$\{\{1,2,3\}\},\\\{\{1\},\{2,3\}\},\\\{\{2\},\{1,3\}\},\\\{\{3\},\{1,2\}\},\\\{\{1\},\{2\},\{3\}\},\\
\{\{1,2,4\}\},\\\{\{1\},\{2,4\}\},\\\{\{2\},\{1,4\}\},\\\{\{4\},\{1,2\}\},\\\{\{1\},\{2\},\{4\}\},\\\{\{1,3,4\}\},\\\{\{1\},\{3,4\}\},\\\{\{3\},\{1,4\}\},\\\{\{4\},\{1,3\}\},\\\{\{1\},\{3\},\{4\}\},\\\{\{1,2,3\}\},\\\{\{2\},\{3,4\}\},\\\{\{3\},\{2,4\}\},\\\{\{4\},\{2,3\}\},\\\{\{2\},\{3\},\{4\}\}$$Overall there is exactly $20$ sets, so we say ${(4)\choose(3)}=20$ What he tried ${(n)\choose(k)}={n\choose k}\times {(k)\choose(k)}$ Proof: The number of sets of $k$ unique elements from a set with $n$ unique elements is by definition $n\choose k$, and by definition for each such set we have exactly ${(k)\choose(k)}$ ways to create it using subsets of the set, thus ${(n)\choose(k)}={n\choose k}\times {(k)\choose(k)}$ What I tried Here he came to me, asking if I know a way to calculate ${(k)\choose(k)}$, I thought about some kind of recurrence relation: $${(k)\choose(k)}=1+\sum_{i=1}^{\lfloor\frac k2\rfloor}\left({k\choose i}\left[{(k-i)\choose(k-i)}-a_i^{(k)}\right]+b_i^{(k)}\right)$$
Where $a_i^{(k)}$ is the number duplicates I get from a single case of ${k\choose i}{(k-i)\choose(k-i)}$, I know it is not so clear, so here is an example: With $k=4,i=2$ I have ${4\choose2}(=6)$ ways to create a set with $2$ elements, and I have ${(4-2)\choose(4-2)}(=2)$ ways to complete it to have $4$ elements. Here is the list of cases: $$\overbrace{\{1,2\}\begin{cases}\{1,2\},\{3,4\}\\\{1,2\},\{3\},\{4\}\end{cases}}^{{4\choose2}\times{(4-2)\choose(4-2)}=12}\\\{1,3\}\begin{cases}\{1,3\},\{2,4\}\\\{1,3\},\{2\},\{4\}\end{cases}\\\{1,4\}\begin{cases}\{1,4\},\{2,3\}\\\{1,4\},\{2\},\{3\}\end{cases}\\\{2,3\}\begin{cases}\{2,3\},\{1,4\}\\\{2,3\},\{1\},\{4\}\end{cases}\\\{2,4\}\begin{cases}\{2,4\},\{1,3\}\\\{2,4\},\{1\},\{3\}\end{cases}\\\{3,4\}\begin{cases}\{3,4\},\{1,2\}\\\{3,4\},\{1\},\{2\}\end{cases}$$We can see that in each case we have exactly one case that appear in other case, hence $a_2^{(4)}=1$. And $b_i^{(k)}$ is the number of duplicates, in the example above we have exactly $3$ elements that appear more than once: $\{\{3,4\},\{1,2\}\},\{\{2,3\},\{1,4\}\},\{\{2,4\},\{1,3\}\}$, hence $b_2^{(4)}=3$ But this doesn't work because when we look on other $i$ we will find more duplicates, for example for $k=4,i=1$ I have the case of $\{1\},\{2,4\},\{3\}$, this is duplicate of the third from last case from when $k=4,i=2$. Here we both are stuck, can someone please help us? Thanks Edit: @saulspatz point out that ${(k)\choose (k)}=B(k)$, where $B(k)$ is bell number of $k$. From Wikipedia I found that $B(k)=\sum_{j=0}^k\left\{{k\atop j}\right\}$, where $\left\{{k\atop j}\right\}$ is Stirling numbers of second kind$=S(k,j)$. With this I get that $$\boxed{{(n)\choose (k)}={n\choose k}{(k)\choose (k)}={n\choose k}B(k)={n\choose k}\sum_{j=0}^k\left(\left\{{k\atop j}\right\}\right)={n\choose k}\sum_{j=0}^k\left(\frac1{j!}\sum_{i=0}^j\left((-1)^{j-i}{j\choose i}i^k\right)\right)}$$","['binomial-coefficients', 'elementary-set-theory']"
2645015,Martingale and Stopping Time with Finite Expectation,"Let $(M_t, \mathcal{F}_t, 0 \leq t < \infty)$ be a martingale. For bounded stopping time $T$ , we can deduce from Doob's Optional Sampling that $\mathbb E(M_T)=\mathbb E(M_0)$ . Now let $T$ be a stopping time with finite expectation, i.e. $\mathbb E(T)<+\infty$ . Can we deduce using $T\wedge n$ and perhaps Lebesgue's Dominated Convergence Theorem that $\mathbb E(M_T)=\mathbb E(M_0)$ ? If not, is there a sufficient condition for this to be true? This question arose in studying Brownian motion. For $\tau:=\inf\{t>0:B_0=a,\,B_t=-b\}$ stopping time, we wish to show $\mathbb E(\tau)=ab$ . One solution suggests $\mathbb E(B_\tau^2-\tau)=0$ by Doob's Optional Sampling Theorem. I wish to justify this claim with the above.","['stochastic-processes', 'probability-theory', 'stopping-times', 'martingales', 'brownian-motion']"
2645056,What 'uniform' shapes can be used to build an approximated spherical object?,"For the purpose of game development, I'm trying to figure out what uniform shapes can be used to create a approximated spherical object. To give an example of a shape that does not fit my criteria, consider the shapes that compose a soccer ball: Because the soccer ball has 12 regular pentagonal faces (5 sides) and 20 regular hexagonal faces (6 sides), the shapes are not uniform (they have a different number of sides and a different geometric area). After a few hours of research online (both here on math.stackoverflow.com and on Google / Wikipedia)
the only shape I was able to come across that does match my criteria is the "" regular dodecahedron "" because it is a sphere-like object composed of only pentagonal faces (5 sides) each with an equal geometric area. How can I find more geometric shapes that fit my criteria, or what terms could I use to research more in this area?",['geometry']
2645129,Is $\approx$ actually an entourage?,"I was looking at applying the ideas in the paper On Nonstandard Topology to Uniform spaces . Given a uniform space $(X,\Phi)$, we can define the relation $\approx$ on ${}^*X$ as follows $$\approx \, = \bigcap \{{}^*U:U \in \Phi \}$$ For example, if $(X,\Phi)$ is the real numbers with their ordinary uniform structure, then $x \approx y$ iff $x-y$ is an infinitesimal in the hyperreal numbers. If we use the metric $|x^3 - y^3|$ instead of the real numbers ordinary $|x - y|$ metric, then $H + \frac 1H \not \approx H$ for infinite $H$ (although $H + \frac 1{H^3} \approx H$). In fact, it appears that we can prove that $\approx$ is an entourage (i.e. $\approx \, \in {}^*\Phi$). Take the following statements The statement ""$V \in \Phi$"" The statement ""$V \subseteq U$"" for each $U \in \Phi$. By the third property of entourages, any finite number of these statements is satisfiable. Therefore, by the Saturation property, there is nonstandard $V$ that satisfies the transfer of all these statements. In particular, $V \in {}^* \Phi$. Additionally, $V \subseteq \, \approx$. By the second property of entourages, $\approx$ is therefore an entourage. Is my proof correct though? The issue is that, going back to the real line with its usual uniform structure, we can assign each entourage a $V$ ""diameter"", defined as the supremum of the distances between points $x$ and $y$ such that $(x,y) \in V$. Therefore, we should be able to assign either a hyperreal number of $\infty$ to $\approx$ like this, but we can't really. It is less than every positive non-infinitesimal (so in particular is not $\infty$), but greater than every infinitesimal. So, what's going on? Is $\approx$ actually an entourage?","['nonstandard-analysis', 'uniform-spaces', 'proof-verification', 'general-topology', 'paradoxes']"
