question_id,title,body,tags
157971,How do mathematicians think about high dimensional geometry?,"Many ideas and algorithms come from imagining points on 2d and 3d spaces. Be it in function analysis, machine learning, pattern matching and many more. How do mathematicians think about higher dimensions? Can intuitions about the meaning of dot-product, angles and lengths transfer from 2d geometry to a 100d? If so, would it be enough to fully understand the higher dimesions, namely, could the same problem in 100d have properties\behaviours that are not seen in 2d\3d?","['general-topology', 'geometry', 'algebraic-geometry', 'intuition']"
157972,proving facts about $\alpha$-Hölder-continuous functions,"I am studying myself some facts about $\alpha$-Hölder-continuous functions but I don't get any further by proving the following: $(1)$ $\forall\alpha\in ]0,1]$ is $C^{0,\alpha}$ dense in $C^0(D)$ concerning the uniform norm and $D\subset\mathbb R^n$. $(2)$ $\forall\alpha\in ]0,1]$ and compact set $K\subset\mathbb R^n$ is $(C^{0,\alpha}(K),||\cdot||_{C^{0,\alpha}(K)})$ a complete space (with
$||u||_{C^{0,\alpha}(K)}:=||u||_{\sup}+\sup\limits_{{x,y\in K\space\&\space x\ne y}}\frac{|u(x)-u(y)|}{|x-y|^\alpha}$ and $C^{0,\alpha}(K)$ the space of all $\alpha$-Hölder-continuous functions) $(3)$ All bounded closed subsets of $(C^{0,\alpha}(K),||\cdot||_{C^{0,\alpha}(K)})$ are compact. So how do you prove one $(1),(2),(3)$ ?","['functional-analysis', 'real-analysis', 'analysis']"
157976,Rigorous proof that $\frac{1}{3} = 0.333\ldots$,"I'm a PreCalculus student trying to find a rigorous proof that $\displaystyle\frac{1}{3} = 0.333\ldots$, but I couldn't find it. I think (just think) that this proof would start by proving that $\displaystyle\sum_{i=1}^{\infty}3\cdot10^{-i} = \frac{1}{3}$. My guesses (assuming that proving that $\displaystyle\sum_{i=1}^{\infty}\left(\frac{1}{10}\right)^i$ converges is trivial): $\displaystyle\sum_{i=1}^{\infty}3\cdot10^{-i} = 3\cdot\sum_{i = 1}^{\infty}10^{-i} = 3\cdot\sum_{i=1}^{\infty}\left(\frac{1}{10}\right)^i = 3\cdot\left(\frac{1}{1 - \frac{1}{10}}-1\right) = 3\cdot\left(\frac{10}{9}-1\right) = \frac{1}{3}$. Questions: is this completely rigorous? Which flaws could be found in this proof? How can I improve it? PS. I'm not sure how to tag this. Feel free to edit, if necessary.","['sequences-and-series', 'algebra-precalculus']"
157984,Cauchy-Binet formula for squares,"Using the convention of the wikipedia article, Cauchy-Binet formula states that --for $A, \, n\times m$ and $B, \, m\times n$ matrices-- $$ 
\det(AB) = \sum_{S\in\tbinom{[n]}m} \det(A_{[m],S})\det(B_{S,[m]})
$$ My question is, is there a formula for the ""squares"" i.e. $$ 
\sum_{S\in\tbinom{[n]}m} \det(A_{[m],S})^2 \det(B_{S,[m]})^2 = ?
$$ Many thanks","['linear-algebra', 'combinatorics']"
157993,Finding an invariant under Group operations,"Context: I am trying to answer this question about solving the peg solitaire, and I already posted as an answer some code devised for treating the board as a graph. The algorithm in Mathematica for solving the problem I implemented there (please don't care to read the code) is a first try brute force approach which I want to refine. One way for doing this is aborting the calculation of the branches already explored, and those symmetrically equivalent. AFAIK, the symmetry of the problem is represented in the Dihedral D4 group. So my problem: I have a vector with the occupancy state of the board $S =\{o_1, ...,o_{33}\}$ $(o_i \in \{ True, False \})$ and I want to find a function that when applied to an occupancy state vector returns the same Real number for all eight symmetric states (and of course bijective, returning a different value for any other input). Any suggestions? Edit For example, the following program in Mathematica calculates a bijective bilinear invariant under D4 for the easy board: x1

  x4        x2

       x3 > bl = Times @@@ Union[Sort /@ Tuples[{x1, x2, x3, x4}, 2]];
coef = Array[a, Length@bl];

(* This is the first nuance, I've to write down the one member 
   for each symmetry class*)
base = {{1, 0, 0, 0}, {1, 1, 0, 0}, {1, 0, 1, 0}, 
        {1, 1, 1, 0}, {1, 1, 1, 1}, {0, 0, 0, 0}};

f[{x1_, x2_, x3_, x4_}] := Evaluate[coef.bl];

(*This is the second problem: I calculate all members of each 
  class (in this case by rotations)*)
g[x_] := Table[RotateRight[x, i], {i, 4}];

fi = FindInstance[
        Unequal @@ (f /@ base) &&
        And @@ Equal @@@ (f /@ g /@ base)
   , coef, Integers];

-f[{x1, x2, x3, x4}] /. fi[[1]] And the result is $f(x_1,x_2,x_3,x_4) = x_1^2 + x_1 x_2 + x_2^2 + x_2 x_3 + x_3^2 + x_1 x_4 + x_3 x_4 + x_4^2$ f value  .......... Equivalent boards I am sure there must be a better way ...",['group-theory']
157996,Easiest way to prove that $\int_{\pi/6}^{\pi/2} \sin(2x)^3\cos(3x)^2 \mathrm{d}x=\left(3/4\right)^4$,"I have been trying to evaluate this integral a few times. And my best attempt has been to rewrite is as a sum of linear combination of sine and cosine terms. Alas, this takes a couple of handwritten pages to accomplish. Is there any easier/faster/neater way to evaluate? $$ \int_{\pi/6}^{\pi/2} \sin(2x)^3\cos(3x)^2\,\mathrm{d}x=\left(\frac{3}{4}\right)^4 $$ Thanks in advance =)","['definite-integrals', 'trigonometry', 'integration']"
158011,$f\colon M\to N$ continuous iff $f(\overline{X})\subset\overline{f(X)}$ [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Continuity and Closure $f\colon M\to N$ is continuous iff for all $X\subset M$ we have that $f\left(\overline{X}\right)\subset\overline{f(X)}$. I only proved $\implies$. If $f$ is continuous then for any $X\subset M$, $$X\subset f^{-1}[f(X)]\subset f^{-1}\left[\overline{f(X)}\right]=\overline{f^{-1}\left[\overline{f(X)}\right]}$$ therefore $$\overline{X}\subset f^{-1}\left[\overline{f(X)}\right]\implies f\left(\overline{X}\right)\subset \overline{f(X)}.$$ The other side must be the same idea but I don't know why I can't prove it. Added: With exactly same idea when I proved $\implies$ I did proved $\Longleftarrow$, Let $F\subset N$ any closed set then: $$f\left[f^{-1}(F)\right]\subset f\left[ \overline{f^{-1}(F)}\right]\subset \overline{f\left[ f^{-1}(F)\right]}\subset \overline{F}=F$$ in particular $$f\left[ \overline{f^{-1}(F)}\right]\subset F\implies f^{-1}(F)\supset\overline{f^{-1}(F)}$$ then $f^{-1}(F)=\overline{f^{-1}(F)}$ and $f$ is continuous.","['general-topology', 'continuity', 'solution-verification']"
158013,Differential equation of $y = e^{rx}$,"I am trying to find what values of r in $y = e^{rx}$ satsify $2y'' + y' - y = 0$ I thought I was being clever and knew how to do this so this is how I proceeded. $$y' = re^{rx}$$
$$y'' = r^2 e^{rx}$$ $$2(r^2 e^{rx}) +re^{rx} -e^{rx} = 0 $$ I am not sure how to proceed from here, the biggest thing I am confused on is that I am working with a variable x, with no input conditions at all, and a variable r (the constant) so how do I do this?","['ordinary-differential-equations', 'calculus']"
158015,circles and linear fractional transformations,"I'm realizing how little (in some respects) I know about circles.  Here's something that emerged out of something I was fiddling with. My question is whether this is ""well known"" in the way that $229\times983=225107$ is ""well known"" (don't publish it unless you're publishing a table); or well known in the sense that every book includes it (for suitable values of ""every""); or well known in the sense that everybody knows it (for at least moderately reasonable values of ""everybody""). I'm looking at the circle $|z|=1$ in $\mathbb{C}$.  Let $$f(z)=\dfrac{-3z+1}{z-3}.\tag{This is $f$.}$$  This of course fixes $\pm 1$ and leaves the circle invariant, and maps $\pm i$ to $\dfrac{-3\pm4i}{5}$.  If we draw a circle through those two images of $\pm i$ meeting the unit circle at a right angle, it is centered at $-5/3$ and has radius $4/3$.  That circle meets the real axis at $-1/3$.  So look at the line $\operatorname{Re}=-1/3$.  Look at the point on that line where $\operatorname{Im} = y$.  Draw the line through that point and the aformentioned center $-5/3$.  That line crosses the circle twice.  It would seem that those two points are $f(z)$ and $f(-\bar z)$, where $z$ and $-\bar z$ are the two points on the unit circle with imaginary part $y$. This gives us a simple geometric picture of how $f$ behaves.  That allows us to use routine Euclidean geometry to show that $\theta\mapsto f(e^{i\theta})$ satisfies the differential equation
$$
\left|\dfrac{dg}{d\theta}\right| = \text{constant}\cdot\operatorname{Re}\left(g-\left(-\dfrac 5 3\right)\right)
$$
subject to the constraint that the values of $g$ are on the unit circle.  (The equation says the rate at which $g$ moves along the circle is proportional to a certain affine function of the real part.)","['ordinary-differential-equations', 'linear-fractional-transformation', 'conformal-geometry', 'circles', 'complex-analysis']"
158021,expansion for $1-|t|$,"Let $f$ be a continuous function on $\mathbb{R}$ with compact support with exactly one maximum.  Form the functions 
$$
f_{m,k}(x)=f^m\left(x-\frac{k}{2^m}\right)
$$ I am wondering if one can expand function $B(t)=1-|t|$, $t \in \mathbb{R}$ (this function called $B_1$ -spline) in terms of $f_{m,k}$, i.e. something like $1-|t|=\sum_{k,m}c_kf_{m,k} $ Thank you.","['wavelets', 'fourier-series', 'sequences-and-series', 'functions']"
158029,Measure of image of Lipschitz function is bounded?,"I recently watched some measure theory lectures online. They didn't post lecture notes and I can't find which video exactly it was. I think there was a theorem that goes something along the lines of: If $f:\mathbb{R^N} \to \mathbb{R^N}$ is Lipshitz with Lipschitz constant $L$, and $\lambda$ stands for Lebesgue measure, then $\lambda(f(A)) \leq L\lambda(A)$ for $A$ measurable. Is this correct, or is there a similar looking theorem that I might be thinking of? Thanks.",['measure-theory']
158041,Dimensionality of null space when Trace is Zero,"This is the fourth part of a four-part problem in Charles W. Curtis's book entitled Linear Algebra, An Introductory Approach (p. 216).  I've succeeded in proving the first three parts, but the most interesting part of the problem eludes me.  Part (a) requires the reader to prove that $\operatorname{Tr}{(AB)} = \operatorname{Tr}{(BA)}$, which I was able to show by writing out each side of the equation using sigma notation.  Part (b) asks the reader to use part (a) to show that similar matrices have the same trace.  If $A$ and $B$ are similar, then $\operatorname{Tr}{(A)} = \operatorname{Tr}{(S^{-1}BS)}$ $= \operatorname{Tr}(BSS^{-1})$ $= \operatorname{Tr}(B)$, which completes part (b).  Part (c) asks the reader to show that the vector subspace of matrices with trace equal to zero have dimension $n^2 - 1$.  Curtis provides the hint that the map from $M_n(F)$ to $F$ is a linear transformation.  From this, I used the theorem that $\dim T(V) + \dim n(T) = \dim V$ to obtain the dimension of the null space.  Part (d), however, I'm stuck on.  It asks the reader to show that subspace described in part (c) is generated by matrices of the form $AB - BA$, where $A$ and $B$ are arbitrary $n \times n$ matrices.  I tried to form a basis for the subspace, but wasn't really sure what it would look like since an $n \times n$ matrix has $n^2$ entries in it, but the basis would need $n^2 - 1$ matrixes.  I also tried to think of a linear transformation whose image would have the form of $AB - BA$, but this also didn't help me.  I'm kind of stuck... Many thanks in advance!","['matrices', 'linear-algebra']"
158049,$L^p$ norm and integral equality prove [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Integrate and measure problem. Assume $\mu(X)=1$, $f \in L^{p} (X,M,\mu)$ for some $0<p \le \infty$ I want to prove that:
$$\lim_{p\to 0}||f||_p = e^{\int_X \log|f|d \mu}$$ I'm going to prove $\ge$ part using Jensen inequality, but I cannot go opposite side. How can I make it?",['measure-theory']
158054,Complex matrices with null trace [duplicate],This question already has an answer here : If $\mathrm{Tr}(A)=0$ then $T=R^{-1}AR$ has all entries on its main diagonal equal to $0$ (1 answer) Closed 9 years ago . I'm trying to prove the following: Let $A\in \mathbb{C}^{n\times n}$ be a matrix with null trace; then $A$ is similar to a matrix $B$ such that $B_{jj}=0$ (i.e. it has zeroes on its diagonal). Any ideas? Induction on $n$ sounded feasible but I wasn't able to put together anything.,['linear-algebra']
158055,Recommendations for real analysis,"I have completed two courses in real analysis that covered up to chapter 9 in Rudin's Principle of Mathematical Analysis (and one on complex analysis). So if I am interested in continuing on in analysis (real analysis and not complex analysis), what would be a good direction to go from here? What would be a good book to learn from? As my interest is primarily number theory I was wondering if there is a direction in analysis that would be helpful in this aspect.","['advice', 'reference-request', 'real-analysis']"
158069,Find the imaginary part of this sum,"Let $$S = e^{i\alpha} + \frac{e^{i3\alpha}}{3} +
 \frac{e^{i5\alpha}}{3^2} + \cdots$$ Find Im$(S)$ and show that it is equal to the sum $$I = \sin(\alpha) + \frac{\sin(3\alpha)}{3} + \frac{\sin(5\alpha)}{3^2} + \cdots$$ So, I found that $S = \frac{3(3e^{i\alpha} - e^{-i\alpha})}{10 - 6\cos(2\alpha)}$ using the formula for geometric series. I have a provided answer of $\frac{6\sin(\alpha)}{5 - 3\cos(2\alpha)}$ which I can see that I get if I just take the $\sin(\alpha)$ terms out of the $e$ terms in my numerator; however, why don't I have to change the $\cos(2\alpha)$ term in the denominator? Isn't this part of Re$(S)$? I was confused about his part and was trying to change this term before I looked at the answer.","['complex-numbers', 'sequences-and-series']"
158077,Finding the topological complement of a finite dimensional subspace,"I know that for any finite dimensional subspace $F$ of a banach space $X$, there is always a closed subspace $W$ such that $X=W\oplus F$, that is, any finite dimensional subspace of a banach space is topologically complemented. However, I wonder whether we can put some condition on the complemented subspace. The problem I am working on is the following: Let $X$ be an infinite dimensional subspace. Suppose we have
\begin{equation*}
X=\overline{F_1\oplus F_2\oplus F_3\oplus\cdots}
\end{equation*} 
where all $F_j$'s are finite dimensional subspaces of $X$ with dimensions larger than 1. Can we find a closed subspace $W$ such that $X=F_1\oplus W$ and $W\supset \overline{F_2\oplus F_3\oplus\cdots}$? Or equivalently, can we find a vector $x\in F_1$ such that it lies outside the closed linear span of $F_j$ $(j\neq 1)$? Thanks!","['topological-vector-spaces', 'functional-analysis', 'banach-spaces']"
158089,Infinite products - reference needed!,"I am looking for a small treatment of basic theorems about infinite products ; surprisingly enough they are nowhere to be found after googling a little. The reason for this is that I am beginning to read Davenport's Multiplicative Number Theory, and the treatment of L-functions in there requires to understand convergence/absolute convergence of infinite products, which I know little about. Most importantly I'd like to know why $$
\prod (1+|a_n|) \to a < \infty    \quad \Longrightarrow \quad \prod (1+ a_n) \to b \neq 0.
$$ I believe I'll need more properties of products later on, so just a proof of this would be appreciated but I'd also need the reference. Thanks in advance,","['products', 'infinite-product', 'reference-request', 'complex-analysis']"
158091,Continuous with respect to weak convergence implies affine,"Let $\phi : \mathbb R \rightarrow \mathbb R$ be a continuous function such that whenever $f_n \rightarrow f$ weakly in $L^2[0,1]$, we have $\phi\circ f_n \rightarrow \phi\circ f$ weakly in $L^2[0,1]$. I am trying to prove that $\phi$ must be an affine map, $\phi(x)  = ax+b$ for some $a,b \in \mathbb R$. So far I've tried proving the contrapositive, or trying to show that $\phi'$ exists and is constant, but have had no success. Any suggestions?",['functional-analysis']
158096,Relation between defining polynomials and irreducible components of variety,"I've been puzzled about some basic facts in (classical) algebraic geometry, but I cannot seem to find the answer immediately: Let $V=V(f_1,\ldots,f_n)$ be a variety over some field $k$, and let $n > 1$. Suppose that $V$ turned out to be reducible, i.e. it is the union of irreducible varieties $V_1,\ldots,V_m$ for some $m > 1$. Must it be the case that at least one of the $f_i$s are reducible polynomials? Take one of the irreducible components, $V_1$, say. Do the defining equations for $V_1$ have anything to do with the polynomials $f_1,\ldots,f_n$? Suppose varieties $V = V(f_1,f_2)$ and $W = V(f_3)$ shared a common component. Does that mean that $f_3$ shares a factor with either one of $f_1$ or $f_2$? If not, what's a counterexample? Thanks so much!",['algebraic-geometry']
158130,"Permuting 15 books about 2 shelves, with at least one book on each shelf.","From Discrete and Combinatorial Mathematics: An Applied Introduction : Pamela has 15 different books. In how many ways can she place her books on two selves so that there is at least one book on each shelf? (Consider the books in each arrangement to be stacked one next to the other, with the first book on each shelf at the left of the shelf.) Initially, I thought that this would be fairly straight forward. There are two cases where either shelf could be empty and so we would subtract 2 from the total number of permutations which is obviously $15!$. It is obvious now that both of these statements are false. My previous thoughts didn't take into account the fact that there are two shelves and that the books could be stacked in such a way that 5 are on the top shelf and 10 are on the bottom, or 8 on top with 7 on bottom, or any number of other ways. I believe there are $2^{14}$ ways the books can be distributed amongst the two shelves (keep in mind that each shelf has to have at least one book, $15 - 1 = 14$) if the ordering of the books didn't matter, but it does. Is this correct? My book also talks about the rule of product: If a procedure can be broken down into first and second stages, and if there are $m$ possible outcomes for the first stage and if, for each of these outcomes, there are $n$ possible outcomes for the second stage, then the total procedure can be carried out, in designated order, in $mn$ ways. If we consider that the top shelf represents the first ""stage"" and the bottom represents the second and that $b_{top}$ represents the number of books on the top shelf and $b_{bottom}$ represents the number of books on the bottom shelf, then, for each of the $2^{14}$ ways the books can be distributed amongst the shelves, there are $b_{top}! * b_{bottom}!$ ways the books can be ordered, where $b_{top} + b_{bottom} = 15$. However, I can't find a way to turn this into a number. This leads me to believe that there is a formula that I should be using that I'm overlooking. What am I missing? Please keep in mind that I'm in the very early stages of this book (page 12, to be precise), so nothing too advanced. :)","['permutations', 'discrete-mathematics', 'combinatorics']"
158141,Why should a topological space itself be open?,"For convenience, let $X$ be our space. Specifically, can anyone name a few desirable properties or theorems that would fail if $X$ weren't required to be open? More generally, is there a part of topology that would completely fall apart? It seems to me that we mainly want closure under arbitrary unions and finite intersections, which appears to be the more natural part of the definition (unlike ""forcing"" $\varnothing$ and $X$ to be open, which feels rather contrived). Of course, we get the empty set for free if we take an arbitrary union of nothing ($\bigcup \varnothing = \varnothing$), so that part really doesn't need to be in the definition. Let's define a new word: A tolology on $X$ is a subset of $\mathcal P(X)$ that is closed under arbitrary unions and finite intersections. By the to(p/l)ological closure of a set I'm referring to the smallest to(p/l)ology containing it. Let $\mathscr T$ be a topology on $X$ and consider $\mathscr T' = \mathscr T \setminus \{X\}$. If $\bigcup \mathscr T' = X$, then closure under arbitrary unions forces us to throw $X$ back in anyway, so the topological closure coincides with the tolological closure, nothing interesting here. Otherwise (this is what bothers me), we have $\bigcup \mathscr T' \subsetneq X$, then $\mathscr T'$ is still closed under arbitrary unions and finite intersections, so it's a tolology but not a topology. But throwing in $X$ adds nothing to the richness of the to(p/l)ology at all. In fact, let's say $\bigcup \mathscr T' \subsetneq X$. Then the topological closure of $\mathscr T'$ is $\mathscr T$, but we still have a pretty boring space. For, if $\left|X \setminus \bigcup \mathscr T' \right| = 1$, then our space is not $T_1$, and if $\left|X \setminus \bigcup \mathscr T' \right| \geq 2$, then it's not even $T_0$. (Actually, any $T_1$ space must satisfy $\bigcup \mathscr T' = X$ by definition, and that probably covers just about every theorem in topology.) Since un-requiring $X$ to be open doesn't give us any fewer theorems than we already have, and those spaces whose topology and tolology are different are as uninteresting as it gets, why can't we replace the definition of topology with that of tolology for simplicity's sake? The only argument I can think of against this is that the first Kuratowski closure axiom says $\overline \varnothing = \varnothing$, so $\varnothing$ is closed, which means $X$ is open. But why do we need that first axiom?",['general-topology']
158160,Solving a differential equation,"I am trying to find the solution of the equation
t $y''-(\cos x) y'+(\sin x )y = 0$. I need help urgently.Thanks",['ordinary-differential-equations']
158161,Infimum of a union,"I have a set $X$ and a function
\begin{equation}
f: X \rightarrow \mathbb{R}
\end{equation}
and I am interested in the value
\begin{equation}
\inf\limits_{x \in X} f(x) \,.
\end{equation}
I can represent $X$ as
\begin{equation}
X = \bigcup\limits_{i \in I} X_i \,,
\end{equation}
where the index set $I$ is uncountable. Now I wonder whether
\begin{equation}
\inf\limits_{x \in X} f(x) = \inf\limits_{i \in I} \left( \inf\limits_{x \in X_i} f(x) \right) \,.
\end{equation}
Is this true? If so, how can I see this?","['limits', 'analysis']"
158168,How to show that $f$ is an odd function?,"An entire function $f$ takes real $z$ to real and purely imaginary to purely imaginary. We need to show that $f$ is an odd function.
well, $f=\sum_{n=0}^{\infty}a_nz^n$ what I can say is $f(\mathbb{R})\subseteq\mathbb{R}$ and $f(\mathbb{iR})\subseteq\mathbb{iR}$ How to proceed, please give me hint.",['complex-analysis']
158173,Linear dependence of linear functionals,"Problem: Let V be a vector space over a field F and let $\alpha$ and $\beta$ be linear functionals on $V$. If $\ker(\beta)\subset\ker(\alpha)$, show $\alpha = k\beta$, for some $k\in F$. A proposed solution is in the answers below.",['linear-algebra']
158176,Finding the Laplace transform of $f(x)=|\cos(x)|$,"I have function $f(x)=|\cos(x)|, x≥0$ and like to derive its Laplace transform. I am told that $f(x+\pi)=f(x)$. Help me please.","['ordinary-differential-equations', 'laplace-transform']"
158177,Composition of Analytic Functions,"I have a basic question in my mind and wish to consult your ideas: Suppose $\Omega_1$ and $\Omega_2$ are regions, $f$ and $g$
are nonconstant functions defined in $\Omega_1$ and $\Omega_2$, 
respectively, and $f(\Omega_1) \subset \Omega_2$. Define $h=g \circ f$.
What can we say about the third function if (a) both $g$ and $f$ are analytic; (b) both $g$ and $h$ are analytic; (c) both $h$ and $f$ are analytic. Here I consider all possible cases. I think in part (a) $h$ is analytic being 
the composition of two differentiable functions. Actually to my mind, analyticity of $g$ 
implies analyticity of $h$, am I correct ? Otherwise, I can't find counterexamples on each cases.
What is your suggestion? Thank you.",['complex-analysis']
158180,Question on Topological vector space 1,"I have numbered this question as (1) because I will be posting series of questions where I don't understand. I hope its allowed. 
I want to prove the following : If $X$ is a topological vector space then :  If $A\subset X $ then
  $\bar A = \cap(A+V)$, where $V$ runs through all nbd of $0$. I tried like this : 
 $x\in \bar A\subset A+V$ $\implies x\in A+V $ for all V. 
The other way , $x\in A+V$ $\implies$ $x\in A$ which means $x\in \bar A$. Is my argument correct? If it fails what should I take care of? Thank you very much.","['general-topology', 'topological-vector-spaces', 'functional-analysis']"
158190,Show trace is zero,"Problem : We are given $n\times n$ square matrices $A$ and $B$ with $AB+BA=0$ and $A^2+B^2=I$. Show $tr(A)=tr(B)=0$. Thoughts : We have $tr(BA)=tr(AB)=-tr(BA)=0$. We also have the factorizations $(A+B)^2=I$ and $(A-B)^2=I$ by combining the two relations above. Let $\alpha_i$ denote the eigenvalues of $A$, and $\beta_i$ the eigenvalues of $B$. We have, by basic properties of trace, $\sum \alpha_i^2 +\sum \beta_i^2=n$ from $A^2+B^2=I$. I'm not sure where to go from here. I would prefer a small hint to a complete answer.",['linear-algebra']
158191,How to solve motion question?,A particle is moving at $x=3\cos\left(2t\right)$. Find the expression for velocity in terms of $x$. I'm not sure where to start.,['trigonometry']
158219,Is a matrix multiplied with its transpose something special?,"In my math lectures, we talked about the Gram-Determinant where a matrix times its transpose are multiplied together. Is $A A^\mathrm T$ something special for any matrix $A$?",['matrices']
158233,Probability that a random weight function on $K_n$ satisfies the triangle inequality,"On a complete graph $K_n$, every edge is assigned a random real weight in $[0, 1]$. I am trying to calculate the probability that the weights satisfy the triangle inequality or even bounds on this probability. How about the discrete version where the weights are integers in $[0, k]$? EDIT : the question was asked and answered here .","['graph-theory', 'probability']"
158236,An inequality involving integrals,"Let be $f:[0,1] \longrightarrow R $, $f$ is an integrable function such that: $$\int_{0}^{1} f(x) \space dx = \int_{0}^{1} xf(x) \space dx=1$$ I need to prove that: $$\int_{0}^{1} f^2(x) \space dx\geq4$$","['integration', 'real-analysis', 'analysis']"
158243,Modules over a functor of points,"I have a question on the ''functor of points''-approach to schemes and $\mathcal{O}_X$-modules. Please let me first write up a defintion. Let $Psh$ denote the category of presheaves on the opposite category
of rings $Rng^{op}$. So $Psh$ is the category of functors from the
category of rings $Rng$ to the category $Set$ of sets. Fix an $X\in Psh$. Demazure and Gabriel define in their book
''Introduction to Algebraic Geometry and Algebraic Groups"" (page 58,
I.2.4.1) an $X$-module $M$ to be an object $M\in Psh$ and a morphism $f:M\to
   X$ in $Psh$ (a natural transformation $f:M\to X$, that's what they call
an $X$-functor) such that for every ring $R$ and every map $p:*\to
   X(R)$ the set $M(R,p):=*\times_{X(R)}M(R)$ has an $R$-module
structure with the property that for any ring map $\phi:R\to S$ the
induced map $\psi:M(R,p)\to M(S,\phi(p))$ is additive and satisfies
\begin{equation} \psi(\lambda m)= \phi(\lambda)\psi(m) \end{equation}
for all $m\in M(R,p)$ and $\lambda\in R$. They call $M$ quasicoherent if for any ring map $\phi:R\to S$, the
induced map \begin{equation} M(R,p)\otimes_R S\cong M(S,\phi(p))
   \end{equation} is an isomorphism. I want to understand an $X$-module $M$ as a morphism $f:M\to X$ in $Psh$ for which some conditions are required to hold ''locally'', like a bundle, but let me more precise in what I mean: The map $p$ in the definition above corresponds by the Yoneda lemma to a map $p:R\to X$ (Here, I use the same notion for $R$ and its associated presheaf $\hom(R,-)$). Let the object $M_p'$ of $Psh$ be defined by the cartesian diagram
\begin{eqnarray}
M_p'&\to & M\\
\downarrow && \downarrow f\\
R&\xrightarrow{p} & X
\end{eqnarray}
in $Psh$. I want to formulate conditions on $M_p'$ (and not on $M(R,p)=*\times_{X(R)}M(R)$ as above) such that $M$ is an $X$-module. The set $M(R,p)$ is contained in the set $M_p'(R)$ but there are not equal, unfortunately. My question is thus: What are the conditions on the $M_p'$ such that $M$ (together with $f$) defines an $X$-module? How is quasicoherence defined in this situation? To be more precise, I would like the above definition of a quasicoherent $X$-module to be the same as something like this: An object $M\in Psh$ and a morphism $f:M\to
   X$ in $Psh$ such that for every ring $R$ and every map $p:R\to
   X$ the set $M_p'(R)=(R \times_X M)(R)$ has an $R$-module
structure with the property that for any ring map $\phi:R\to S$ the
induced map $\psi'(R):M_p'(R)\to M_{\phi(p)}'(R)$ is additive and satisfies $\psi'(R)(\lambda m)= \phi(\lambda)\psi'(R)(m)$ for all $m\in M_p'(R)$ and $\lambda\in R$ and $M_p'(R)\otimes_R S\cong M_{\phi(p)}'(S)$ is an isomorphism. I hope that I was able to clarify my question. Thank you in advance for any hints.","['sheaf-theory', 'quasicoherent-sheaves', 'algebraic-geometry']"
158250,$\wp^{(\omega)}(A)=?$,"Let $A$ be a set, $$\wp^{(0)}(A)=A$$
$$\wp^{(n+1)}(A)=\wp(\wp^{(n)}(A))$$
But what sense does $\wp^{(\alpha)}(A)$ make where $\alpha$ is a limit ordinal number?
The most natural way is let
$$\wp^{(\alpha)}(A)=\lim_{\xi \uparrow \alpha}\wp^{(\xi)}(A),$$ but what is this 'limit' means? Note that $\wp^{(n)}(A)$ probably not the subset of $\wp^{(n+1)}(A)$.","['induction', 'ordinals', 'elementary-set-theory', 'exponentiation']"
158281,Pattern of orders of elements in a cyclic group,"Doodling as I was contemplating another recent question, I picked out the orders of elements of the cyclic group $Z_{15}$ namely: 1 element of order 1 2 elements of order 3 4 elements of order 5 8 elements of order 15 In a group of order 3 you have 1 element of order 1 and two elements of order 3. Are there other examples of this same pattern (powers of 2), and can anyone show and prove a general rule.",['group-theory']
158291,Required reading on the Collatz Conjecture,"I am currently writing a paper on 3x+1 and realized that despite having enough knowledge to work on a singular facet of the problem I lack a more broad understanding of the problem.  I have seen the thorough annotated bibliographies by Jeffrey C. Lagarias but I do not have the time to read most of them and I imagine plenty of them would not teach me much about the problem itself, even if I did take the time to dissect them.  So what are the papers people feel I should read with my limited time to gain the best possible understanding of the Collatz Conjecture?","['collatz-conjecture', 'big-list', 'number-theory']"
158293,Density of odd numbers in a sequence relating base 2 and base 3 expansion,"Define the function
$$f(4n)=6n+1\\
f(4n+1)=6n+2\\
f(4n+2)=6n+3\\
f(4n+3)=6n+5$$
and the sequence $u_0=2$, $u_{k+1}=f(u_k)$. Let $d_1\le d_2$ be the lower and upper asymptotic density of odd numbers in $u_k$. Since $f(n)$ is odd for even $n$, no two consecutive terms can be even so obviously $d_1\ge 1/2$. Experimentally, it seems reasonable to conjecture $d=d_1=d_2=2/3$. Heuristically, when $n$ is odd, $f(n)$ has ""probability 1/2"" to be even, so we get this Markov chain: which is consistent with $d=2/3$. But can we prove rigorously that the heuristic works, that is that $u_k$ is ""random enough"" for this to be true? Failing that, a sharper lower bound on $d_1$ could still be an interesting result. (One approach could be to let $a_k=1$ if $u_k$ is even and $0$ otherwise, and examine the probabilities of the $p$-bit subwords $(a_k,\dots,a_{k+p-1})$. Unfortunately every Fibonacci word, that is one not containing the pattern 11, seems to appear infinitely frequently in $a_k$. This is consistent with the Markov chain model.) PS: If you're wondering, the problem arose from this question . Response to comments: Someone suggested to work modulo some larger number, such as 12. The problem with this approach is that if the input is considered mod $2^a 3^b$, the output will only be known mod $2^{a-1} 3^{b+1}$ so you're not going to be able to say much about the behavior of $f$ when iterating more than $a$ times. And it seems that $010101\dots$ can always appear as a subword of $a_k$, so you won't be able to prove anything non-trivial about the density by proving something about the density after $k$ iterations starting from an arbitrary state (that is, by examining $f^k$ for bounded $k$). The first few terms are 2, 3, 5, 8, 13, 20, 31, 47, 71, 107, 161, 242. The sequence grows as $\Theta((3/2)^n)$. Interestingly, notice how closely the first few terms match the Fibonacci sequence (which can be explained by how close $3/2$ is to the golden ratio and by the fact that modulo 2, neither sequence contains the pattern 00).","['conjectures', 'sequences-and-series', 'probability', 'number-theory']"
158311,Visibility of the surface of a sphere,"If you are $N$ radii above a sphere, what fraction of the hemisphere below you can you see? The answer is so nice that it prompted another question: is there an intuition behind it, in the sense that one might have guessed it before going into the details of the computation? I'll be content with the answer, but I'm really after the intuition, if any springs to mind.","['geometry', 'intuition']"
158312,Proving a statement regarding a  Diophantine equation,"FINAL EDIT : Prove that if $p^z|n^2-1$ $$p^{x-z}(p^{z}-1)=\dfrac{ n^2-1}{p^z}-3$$ doesn't hold for any chosen values of $p,x,n$ and $z$. Here $p>3$ is an odd prime , $x=2y+z, \ \{\{x,y,z\}>0\} \in \mathbb{Z}$ . There  $n$ is an even number. If the above statement is prove it  will lead to a contradiction$^*$ $^*$: to understand the contradiction you need to read this : EDIT : [History] : If anybody remembered the previous question of mine, I asked to prove $(p^x+3)(p^z-1)+4$ is not a perfect square. So I tried this 
$$p^{x+z}-p^x+3p^z+1=l^2$$
$$p^{x+z}-p^x+3p^{z}=l^2-1$$
$$p^z(p^{x}-p^{x-z}+3)=(l+1)(l-1)$$ Here its evident that $p^z$ divides either of $(l-1)$ or $(l+1)$. So let us assume as case (i) the $p^z|(l-1)$. So let $k=\large \frac{l-1}{p^z}$, so when $k$ is decimal ( clearly $l-1$ is odd and $p^z$ is odd, so all the time the $k$ is not a integer ) ignore the case as it leads to a contradiction and proves it. 
Now look when $k$ is integer so the equation $$p^z(p^{x}-p^{x-z}+3)=(l+1)(l-1)$$ can be written as $$(p^{x}-p^{x-z}+3)=k(l+1)$$
$$p^{x}-p^{x-z}=k(l+1)-3.$$
 After working on many examples, I have found an interesting pattern between the differences between the same odd number raised to different powers. For suppose we take an odd number $5$ and then work on the difference of the powers of it. So the difference seems to be of the form $O^n-O^{m}(n>m)$ ( where $O$ is an odd number ) .  So let us call the set of all such differences $\mathfrak{D}^{n}_{O}$ set of all $\left\{O^n-O^{m}\right\}$ such that the integer $m$ runs from $0$ to $n-1$ . Here  For example we can start writing all such differences to see an interesting property. Fix $O=5$. 
 Let us take and $n=1$ and $\mathfrak{D}^{1}_{5}$ is nothing but the set of 1 element $\left\{5^1-5^0=4\right\}$ 
 Let us now take $n=2$ and  $\mathfrak{D}^{2}_{5}$ is nothing but only 2 elements $\left\{5^2-5=20,5^2-5^0=24\right\}$. 
 Let us now take $n=3$. So the $\mathfrak{D}^{3}_{5}$ is nothing but set of 3 elements $\left\{5^3-5^2=100,5^3-5=120,5^3-5^0=124\right\}$ \( Since for $n=3$ there are only two possible $m=1,2 (3-1=2)$. 
 Let us now take $n=4$. So the $\mathfrak{D}^{4}_{5}$  is nothing but the set of 3 elements $\left\{5^4-5^3=500,5^4-5^2=600,5^4-5=620,5^4-5^0=624\right\}$.
 Let us now take $n=5$. So the $\mathfrak{D}^{5}_{5}$ is nothing but the set of 4 elements $\left\{5^5-5^4=2500,565-5^3=3000,5^5-5^2=3100,5^5-5=3120,5^5-5^0=3124\right\}$. And so on for different values of $n$. If we observe we find that the elements of the sets follow a good pattern. After trying for many such numbers I came to know the pattern. Let me explain it sir. So let us write down all such $\mathfrak{D}^{n}_{5}$ 
 $$\mathfrak{D}^{1}_{5}=\left\{4=5^0*(5-1)\right\}$$
 $$\mathfrak{D}^{2}_{5}=\left\{20=5^1*(5-1),24=5^1*(5-1)+5^0*(5-1)\right\}$$
 $$\mathfrak{D}^{3}_{5}=\left\{100=5^2*(5-1),120=5^2*(5-1)+5*(5-1),124=5^2*(5-1)+5^1*(5-1)+5^0(5-1)\right\}$$ $$\mathfrak{D}^{4}_{5} = \{500,600,620,624\}$$ Here each element can be written as $\{500=5^3*(5-1),600=5^3*(5-1)+5^2*(5-1),620=5^3*(5-1)+5^2*(5-1)+5^1*(5-1),624=5^3*(5-1)+5^2*(5-1)+5^1*(5-1)+5^0*(5-1)  \}.$\
 Similarly $$\mathfrak{D}^{5}_{5} = \{2500,3000,3100,3120 \}.$$\ Here also each element can be written as 
 $\{ 2500=5^5*(5-1),3000=5^5*(5-1)+5^2*(5-1),3100=5^5*(5-1)+5^4*(5-1)+5^3*(5-1),120=5^5*(5-1)+5^4*(5-1)+5^3*(5-1)+5^2*(5-1)+5^1*(5-1),3124=5^5*(5-1)+5^4*(5-1)+5^3*(5-1)+5^2*(5-1)+5^1*(5-1)+5^0*(5-1) \} $ Any pattern ?? . Yes there is a pattern sir. For any $O^{n}-O^{m}$ for any odd number $O$ and any integers $n,m (m<n)$ can be expressed as : \begin{equation}
  O^{n}-O^{m}=\sum^{n-1}_{i=m} O^{i}*(O-1)
  \end{equation} Now we can write the R.H.S of equation $$(p^{x}-p^{x-z}+3)=k(l+1)$$ as $$p^{x}-p^{x-z}= \sum^{x-1}_{x-z} p^i.(p-1)$$
After expanding the series and simplyifying we obtain 
$$p^{x-z}(p-1).\large\frac{p^x-1}{p-1}$$
$$p^{x-z}(p^z-1)$$ So we can equate to get $$p^{x-z}(p^z-1)=k(l+1)-3.$$ So we need to prove that both sides of the equation don't yield the same even number leading to a conrtradiciton. Hence I am trying that. I am here with a question again. Suppose we have an equation of this form $$p^{x-z}(p^{z}-1)=k(l+1)-3$$ where $p$ is an odd-prime, $z,y$ are integers and $y>0$ always ($x=2y+z, $ for some integer $x$ ) , $k$ is an odd number and $l$ is an even number. So given such constraints and for any $p>3$ its well known that after substituting values of all variables its clear that both sides of the equation don't yield the same even number ( for any values ) . So how can we prove it ?. I have been trying to  prove it using congruences, but that didn't take me anywhere. So I wanted to ask it here. Thank you.","['number-theory', 'parity', 'elementary-number-theory', 'prime-numbers', 'diophantine-equations']"
158316,In which case $M_1 \times N \cong M_2 \times N \Rightarrow M_1 \cong M_2$ is true?,"Usually for modules $M_1,M_2,N$
$$M_1 \times N \cong M_2 \times N \Rightarrow M_1 \cong M_2$$
is wrong. I'm just curious, but are there any cases or additional conditions where it gets true? James B.","['modules', 'abstract-algebra']"
158318,Given pairwise distances of $N$ data points and find the minimal dimenion of space can fit the data,"Given a set $D$ consist of all pairwise distance of $N$ unknown dimension points. e.g. If there is 3 points, ${x_a,x_b,x_c}$ $$D=\{||x_a-x_b||,||x_b-x_c||,||x_a-x_c||\}$$ How can I find the minimum dimension of space which can place all these $N$ points on it and satisfy the distance constraints?","['geometry', 'metric-spaces']"
158321,Fastest convergence Series which approximates function,"The question is the following: Is there any proof that shows that the Taylor series of an analytical function is the series with the fastest convergence to that function? The motivation to this question comes from numerically calculate $\exp(x)$ with arbitrary precision on the result. Suppose one can only calculate it using simple multiplications, division, sum and subtraction. One approach would be to calculate the Taylor series centered on a particular known value (for instance, for the $\exp$, centered at $0$), and stop when the next term of the series has the desired precision. I.e. considering $$y_n = \sum_{i=0}^n \frac{x^n}{n!}$$ we can call the error of the approximation of $y_n$ as $$\epsilon_n = |y_n - e^x|\simeq \frac{x^{n+1}}{(n+1)!}$$ It is not obvious to me that the Taylor series is the fastest way of approaching $\exp(x)$ (in the sense that the Taylor Series is the one that leads to the n required to achieve a given precision is the minimum). I think the problem can also be stated in the following way: on the set of all series that converge to $e^x$, which converges faster in the sense that it requires the minimum number of terms (and only requires $+,-,\cdot,/$)? Generically, I would like to extent this results to less trivial functions, like $\cos, \arcsin, \log$, etc. So, first I would like to understand which series (or other things like Padé approximants, as Cocopuffs pointed out) should I use...","['sequences-and-series', 'calculus', 'taylor-expansion']"
158329,How do I solve this problem?,"Exercise: If $a+2b=125$ and $b+c=348$, find out $2a+7b+3c$. Here $a$, $b$, $c$ are natural numbers. The answer is: $2a+7b+3c = 1294$ I tried but just can't figure out how to get to this answer. I have a lot of exercises similar to this one but don't know how to aproach them. Can anyone write the steps in order to get to the answer above? Also  it would be great if you can write in a general way so I can apply it to other exercises similar to this.",['algebra-precalculus']
158332,Comparison theorem for systems of ODE,"Let vector-function $x(t)$ satisfy a differential equation
$$
  \dot x = f(x),
$$
and a vector-function $y($t) satisfy a differential inequality
$$
   \dot y \leq f(y)
$$
with starting positions $y(0) < x(0)$. If a function $f(x)$ satisfies the property: 
$$
  f_{i}(x_1+\alpha_1,\ldots,x_{i-1}+\alpha_{i-1},x_i,x_{i+1}+\alpha_{i+1},\ldots,x_{n}+\alpha_{n}) \geq f_{i}(x_1,\ldots,x_n)
$$
for any $\alpha_{1} \geq 0, \ldots, \alpha_{n}  \geq 0$ (i.e. it is quasimonotone), then $y(t) \leq x(t)$ for any $t>0$. Function $f(x)$ is smooth. Is there a name for such theorem? Please help me to proof it or give me a reference.","['ordinary-differential-equations', 'reference-request']"
158357,Calculate alpha from $\alpha + \sin(\alpha)$ = K,"Sorry for the dumb question, but I'm not involved in math.
I need to reverse the following formula, to calculate $\alpha$: $$a = b(\alpha + \sin \alpha)/c$$ So I have: $$(\alpha + \sin \alpha)=ac/b = K$$ Since $a$, $b$, $c$ are constant, I put equal to $K$. $\alpha$ is measured in radians. I need to find the value of $\alpha$ (in radians or degree). Thanks to all!!",['trigonometry']
158364,questions on convolutors on $L^p(G)$,"Let $G$ be a locally compact group. Suppose $1<p<\infty$. We denote by $CV_p(G)$ the space of operators $T$ on $L^p(G)$ such that $T(f*g)=(Tf)*g$. 1) In the book ""Amenable locally compact groups"" of Pier, Proposition 9.2 (page 83), the author asserts that each operator of $CV_p(G)$ is a convolution operator with a measure on $G$. This proposition seems false to me. Does is it true? 2) (If the proposition 9.2 of Pier is false) Suppose that $G$ is a discrete group. Let $T\in CV_p(G)$. Does there exist a measure $\mu$ on $G$ such that $T(g)=\mu*g$ for any continuous function $g$ with compact support? 3) Let $G$ be an abelian locally compact group. We denote $\varepsilon_a$ the Dirac measure in the point $a\in G$. If $|\lambda|=1$, the operator $\lambda(\varepsilon_a*\cdot)$ is a extremal point of the closed unit ball of $CV_p(G)$. Does there exist other known exemples of extremal points of this ball? 
Does there exist references on this subject?","['functional-analysis', 'reference-request', 'group-theory', 'operator-theory']"
158365,"How do modules,vector spaces, algebras,fields,rings, groups, relate to one another?","Modules, vector spaces, algebras, fields, rings, groups... How do these basic algebraic objects relate to each other via tensor products? Is there a way to go from one object to its generalization via a tensor product construction? I think this is an interesting question...but I can't find many resources on the subject. For e.g. I've seen people use the phrase 'tensoring up'. Your answer should describe how tensor products are used to relate algebraic objects? (I'm basically looking for tricks of the trade that every mathematician should know about this)",['abstract-algebra']
158389,"Can I benefit from directly using analysis textbooks to self-learn calculus, instead of calculus textbooks?","My purpose is self-learning, neither for exam nor degree courses. My goal is to research dynamic System, theoretically oriented. Question Description: I've been reading  calculus books by Weinstein & Marsden, UTM, Springer for weeks. I solved 90% of text, 30%-40% of exercises.  UTM seems engineering-oriented (not theoretical/rigorous-oriented), compared with others within series. Their advantages are: they suitably explain concepts, in clear Structure. Their disadvantages are: not  enough theorems, too many exercises in formula-calculation/real application, too little deep/proof exercises. They total approximately 8000 exercises, 300-400 exercises/chapter, but 80% is simple-formula-calculation/realistic application. My question :   Will I benefit from starting with the analysis textbooks below now, instead of continuing with the aforementioned calculus books? I think so, for 3 reasons: (1) Most good EU bachelor in maths, they use analysis directly in first semester instead of calculus. (e.g. Bonn University/ETH Zurich) (2) Since the aforementioned books contains too many exercises of formula-using/real application ones but not deep/proof, if I continue to work with it (solve all exercises/ second time reading), books will still cost several months. (3) Will the analysis textbooks below  also contain needed  intuition, calculation skills for calculus? If it's the case that these analysis books train both theory and calculation ( compute derivatives/integrals which are useful later such as ODE, PDE), then there'd be no need to read calculus books. Rose, Elementary Analysis, UTM, Springer. Serge Lang, A First Course in Calculus/Calculus of Several Variables, UTM, Springer(Even though it's still calculus, but Lang's book is more abstract-oriented) Zorich, Analysis, Universitext, Springer. As @nbubis said, analysis needs intuition. Zorich's analysis seems to contain many physical problems, will it works for teaching intuition? Courant, Introduction to Calculus and Analysis I&II, Springer","['soft-question', 'calculus', 'real-analysis', 'learning']"
158403,Solving $\frac{dy}{dx} = xy^2$,"This problem appears to be pretty simple to me but my book gets a different answer. $$\frac{dy}{dx} = xy^2$$
For when y is not 0
$$\frac{dy}{y^2} = x \, dx$$
$$\int \frac{dy}{y^2} = \int x \, dx$$ $$\frac{-1}{y^1} = \frac{x^2}{2}$$ $$\frac{-2}{x^2} = y$$ Is there anything wrong with this solution? It is not what my book gets but it is similar to how they do it in the example.","['ordinary-differential-equations', 'calculus']"
158425,Integrating Factor: How to solve it,"Verify that:
$$\frac12(Mx+Ny)d(\ln(xy))+\frac12(Mx-Ny)d(\ln(x/y))=Mdx+Ndy$$ Hence show that, if the de $Mdx+Ndy=0$ is homogenous, then $Mx+Ny$ is an integrating factor unless $Mx+Ny=0$ Note: Verification is trivial, hence nothing much to be done there, but I couldnt solve the second part of the question ""Hence..."" so for the completeness of the problem I added it.
Further on, isnt the statement "" $Mdx+Ndy=0$ is homogenous "" superfluous as RHS is already zero, so why add the word homogenous. Perhaps I am being pedantic?
And lastly I would like to have some hints in solving the INTEGRATING Factor part. EDIT: My approach I approached like this: I multiplied the function $Mx+Ny$ to both sides of the equation $Mdx+Ndy=0$ and tried to show, that $d(u(x,y))=0$ but I couldnt prove it. Soham","['ordinary-differential-equations', 'calculus']"
158430,Why is $X_1 + X_2 +\ldots + X_n$ a martingale?,"If we have $X_k$ random variables with average $0$ and independent, why is the $\sum_{k=1}^n X_k$ a martingale for the sigma algebra $\mathcal F_n$ generated by $\{X_1,\ldots, X_n\}$? I basically only have to prove that the expected value of $X_{n+1}$ knowing $\mathcal F_n$ is $0$,  but somehow this isn't intuitive to me at all.
Could anyone give me pointers on this?","['probability-theory', 'martingales', 'probability']"
158432,Expressing $\sin(2x)-8\cos(2x)$ as a single sine function,I am asked as a part of a question to express $\sin(2x)-8\cos(2x)$ as a single sine function. I know it has something to do with the trigonometric identity $$\sin(a-b)=\sin(a) \cos(b)-\cos(a)\sin(b)$$ but I can't get my head around it because of that $8$ in front of $\cos2x$. Any tips on how I can move on?,['trigonometry']
158438,Why is there no functor $\mathsf{Group}\to\mathsf{AbGroup}$ sending groups to their centers?,"The category $\mathbf{Set}$ contains as its objects all small sets and arrows all functions between them.  A set is ""small"" if it belongs to a larger set $U$, the universe. Let $\mathbf{Grp}$ be the category of small groups and morphisms between them, and $\mathbf{Abs}$ be the category of small abelian groups and its morphisms. I don't see what it means to say there is no functor $f: \mathbf{Grp} \to \mathbf{Abs}$ that sends each group to its center, when $U$ isn't even specified.  Can anybody explain?","['category-theory', 'group-theory']"
158440,existence of a harmonic function,"Let $\Omega\subset\mathbb R^n$ open, not bounded and $n\ge3$. Let $\partial\Omega$ bounded and regular concering the laplace operator. Given a continuous function $\phi:\partial\Omega\rightarrow\mathbb R$ and $\gamma\in\mathbb R$ there exists a  harmonic function $u\in C^2(\Omega)\cap C^0(\overline\Omega)$ with $u=g\space\space\text{on}\space\partial\Omega$ and $\lim\limits_{|x|\rightarrow\infty}u(x)=\gamma$ How can you prove the existence?","['partial-differential-equations', 'real-analysis', 'analysis']"
158442,Finite groups of functions under function composition,"Over the years I have done many questions along the lines of the following: ""Given functions $\phi, \theta$ (usually defined on $\mathbb{R}$ or $\mathbb{C}$, or a suitable subset of $\mathbb{R}$ or $\mathbb{C}$) prove that the collection of all functions obtained from $\theta$ and $\phi$ by function composition form a group G."" (Frequently G is $\mathbb{Z}/4 \mathbb{Z}$ or $S_3$.) A typical example might be functions $\theta:x\mapsto 1-x$ and $\phi:x\mapsto \frac{1}{x}$, (defined on the set of non-zero reals) generating a group isomorphic to $S_3$. When I have been inventing questions for my students, rather than simply copying examples from previous exam papers, I have sometimes wondered if it is possible to create a similar example with a function $\psi$ which has order 5 in the group - just for a bit of variety! However a crucial restriction is that I need the functions to be simple algebraic functions (something like $x\mapsto \frac{ax+b}{cx+d}$ with $a, b, c, d\in \mathbb{Z}$), which rules out things like rotations of $\mathbb{C}$ through an angle of $2\pi/5$. My question is then: does anyone know of such a function, or has anyone come across a similar exam question which gives an element of order 5 (or 7 for that matter ...) arising from such a simple type of function? I have tried investigating the possibilities at various times, and have easily found functions which have order 2, 3, 4, but never one of order 5 or 7. PS There is no great urgency here, as I have now retired from teaching this sort of stuff.","['finite-groups', 'functions']"
158448,Borel functions and their equivalence to sets.,"Let $(\Omega,\mathcal{F})$ be a measurable space. The following are equivalent: $\ X:\Omega \to \mathbb{R} $ is a Borel function. $\{\omega\in\Omega:X(\omega)>a\}\in\mathcal{F}$ for all $a\in\mathbb{R}$. $\{\omega\in\Omega:X(\omega)< a\}\in\mathcal{F}$ for all $a\in\mathbb{R}$. $\{\omega\in\Omega:X(\omega) \in B\}\in\mathcal{F}$ for all open subsets $B\subset\mathbb{R}$. $\{\omega\in\Omega:X(\omega) \in B\}\in\mathcal{F}$ for all closed subsets $B\subset\mathbb{R}$. How on earth would I prove this? I have no idea where to start. Any help would be very much appreciated.
Thanks","['probability-theory', 'measure-theory']"
158449,Proving that the magnitude of the sample correlation coefficient is at most $1$,"How can you show that the magnitude of the sample correlation coefficient is at most $1$? The formula is huge, I'm not even sure how to approach this. Can anyone point me in the right direction? Note that this is the sample correlation coefficient: $$r_{xy} = \dfrac{\displaystyle \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{(n-1)s_xs_y} = \dfrac{\displaystyle \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\displaystyle \sum_{i=1}^{n} (x_i - \bar{x})^2 \displaystyle \sum_{i=1}^{n} (y_i - \bar{y})^2}}$$","['statistics', 'correlation']"
158460,Is the complement of a finite dimensional subspace always closed?,"Let $F$ be a finite dimensional subspace of an infinite dimensional Banach space $X$, we know that $F$ is always topologically complemented in $X$, that is, there is always a closed subspace $W$ such that $X=F\oplus W$. I am thinking about the converse. Suppose $W$ is a subspace of $X$ such that $X=F\oplus W$ for some finite dimensional subspace $F$. Is $W$ necessarily closed? I guess the answer should be negative but I cannot find such an example. Can somebody give a hint? Thanks!","['general-topology', 'functional-analysis', 'banach-spaces']"
158462,Basic probability problem,"Problem states: Consider two events $A$ and $B$, with $P(A) = 0.4$ and $Pr(B) = 0.7$. Determine the maximum and the minimum possible values for $P(A \& B)$ and the conditions under which each of these values is attained. To solve, I considered the event with the lowest probability $A$ to be a subset of the other, so maximum value is attained under that circumstance giving a probability of $0.4$.
But the book states that the minimum is $0.1$, if $P(A \cup B) = 1$. I don't understand why! Because I thought that the minimum value is get when the two events are disjoint... So the minimum value must be $0$...",['probability']
158487,Function that magnifies small changes and compresses large changes,"I need a function (for a heatmap algorithm) that takes a percentage difference between two values, and returns a number between 0 and 1. The output will be used in coloring parts of the screen. The output will be passed to an alpha channel. The catch is, most of the time the percentage value I want to plot will be small and it will be hard to discern the difference between the colors. That's why I want to magnify small values and compress the large ones. The output should be something like this: f(0) = 0 f(1) = 1 f(0.001) = 0.1 f(0.002) = 0.2 f(0.7) = 0.75 f(0.8) = 0.78 ... Do you see the pattern? I've tried log, but I need the function to be defined at f(0). I've also tried x^a where a < 1, but in order to get the magnification I need I need to use a << 1 and that makes all the output so small it can't be discerned or the resolution is so small that the graphics assume it's the same color.","['functions', 'algorithms']"
158497,Analyzing a mixture issue.,"I am having a problem with this question: Coffee A costs $75$ cents per pound and coffee B costs $80$ cents per pound to form a mixture that costs $78$ cents per pound.IF there are $10$ pounds of Mixture how many pounds of Coffee A are used? According to the text the answer is 4. I don't know how they came up with this answer since they haven't given the clue or percentage of the how much of each coffee is used in the mixture. Maybe I am missing something here. Any suggestions? Here is what I could think of: $\$0.75 + \$0.80 = 155$
so $75$ is $\left(\frac{7500}{155}\right)$% of $155$ cents Now taking $\left(\frac{7500}{155}\right)$% of $78$ cents (Price of the mixture) we get $\frac{1170}{31}$ cents. Now if $75$ cents is $1$ pound $\frac{1170}{31}$ would be $\frac{78}{155} pound. So for ten pounds it would be $\frac{780}{155}$ which is still not the answer.","['word-problem', 'algebra-precalculus', 'solution-verification']"
158511,A convex programming problem involving sum of logarithms of linear functions,"Here is a convex programming problem I encountered while working on an estimation problem for a mixture of multinomial distributions. We have a matrix $A_{m \times n}$ containing non-negative real numbers. We seek to maximize $$
\sum_{i=1}^m \log (\sum_{j=1}^n a_{ij} \theta_j)
$$ such that $$
\sum_{j=1}^n \theta_j = 1, \theta_j\geq 0
$$ I'm not sure if this has been studied extensively before, and I'd like to have some analytic results about this convex programming problem.","['optimization', 'statistics', 'nonlinear-optimization', 'convex-optimization', 'reference-request']"
158518,"""Fully correlated"" definition","Really sorry to be a noob, but I'm a programmer, not a mathematician, and all of my knowledge about statistics come from this book ""Schaum's Outline of Theory and Problems of Probability, Random Variables, and Random Processes"". I'm implementing an UKF for target tracking using C++. Everything went well until an error about covariance matrix of state is not positive definite happened. After a little research, I found this link Under what circumstance will a covariance matrix be positive semi-definite rather than positive definite? which  almost answer everything I need. Only one thing I don't understand: The answer says "" This happens if and only if some linear combination of X is ‘ fully correlated ’ "". Can anyone explain for me what does "" fully correlated "" mean? And example would be great. I have search Google about its definition but there is no luck at all.","['statistics', 'matrices']"
158524,What is the underlying function?,"I have some value pairs. They are inversely proportional. I want to have a formula to get the second value from the first value. Speed Delay
10    0.142
15    0.087
20    0.064
25    0.049
30    0.036
37    0.03
45    0.017
68    0.016 I guess there have to be an offset and a factor. Is it necessary to have min and max values?","['algebra-precalculus', 'mathematical-modeling', 'functions']"
158527,"The function $f(x) = \int_0^\infty \frac{x^t}{\Gamma(t+1)} \, dt$","Does anyone know if this function has a name? I came up with it by looking at the power series for $e^z$, changing the summation to an integral, and substituting the gamma function for the factorial function.","['special-functions', 'integration', 'analysis']"
158533,Is there a distributive law for ideals?,"I'm curious if there is some sort of distributive law for ideals. If $I,J,K$ are ideals in an arbitrary ring, does $I(J+K)=IJ+IK$? The containment ""$\subset$"" is pretty clear I think. But the opposite ontainment doesn't feel like it should work. I couldn't work out a counterexample with ideals in $\mathbb{Z}$ however. So does such an equality always hold or not?","['ideals', 'abstract-algebra']"
158541,Fourier dimension of sets of positive Lebesgue measure,"Let $K$ be a compact set in $\mathbb{R}$ with positive Lebesgue measure. My question is whether there exists a probability measure $\mu$ supported on $K$ such that $\hat{\mu}(\xi)$, the Fourier-Stieltjes transform of $\mu$, has decay $O(|\xi|^{-1})$? Note that when $K=[0,1]$, we can simply take $\mu=\chi_{[0,1]}dt$, see this post . Generally, if $K$ contains an interior point, then by the same token such a probability measure trivially exists. But things become unclear to me when $K$ is a general set. Thanks!","['measure-theory', 'fourier-analysis', 'examples-counterexamples', 'real-analysis']"
158549,Can such a function exist?,"Denote by $\Sigma$ the collection of all $(S, \succeq)$ wher $S \subset \mathbb{R}$ is compact and $\succeq$ is an arbitrary total order on $S$. Does there exist a function $f: \mathbb{R} \to \mathbb{R}$ such that for all $(S, \succeq) \in \Sigma$ there exists a compact interval $I$ with the properties that $f(I) = S$ $x \geq y$ implies $f(x) \succeq f(y)$ for all $x,y \in I$? If so, how regular can we take $f$ to be? The motivation is that basically, I am trying to construct the analogue of a normal sequence but on $\mathbb{R}$ instead of $\mathbb{N}$. EDIT: As Brian M. Scott points out, this is not possible if the orderings have no greatest and least elements. However, since adding this assumption doesn't go against the intuition of generalizing normal sequences, I am still interested in the answer if we restrict the various total orders to have minimal and maximal elements. Thanks in advance.","['general-topology', 'functions', 'order-theory']"
158557,Do multiplicative maps of matrices factor through determinants?,"Given a map $f:M_n(k)\to k$ (with $k$ some field) such that $f(AB)=f(A)f(B)$ for all matrices $A$ and $B$, is it necessarily the case that $f$ factors through the determinant, i.e. does there exist a multiplicative map $g:k\to k$ such that $f=g\circ\det\,$? Are constraints on $k$ necessary? A simple corollary would be that nonzero multiplicative maps on subgroups of the general linear group $GL_n(k)$ factor through multiplicative maps on the units $k^\times\to k^\times$. Two definitions of $\det$ I'm aware of (written with our setting in mind): The unique alternating mulilinear map (of column vectors in a matrix) sending $I$ to $1_k$. The trace of the map induced by $A$ on the $n$th exterior power $\mathrm{Alt}^nk^n$. By Gaussian elemination, any multiplicative map $f$ from matrices to the base field is determined by its values on the matrices representing elementary row operations and upper triangular matrices. One stumbling block is that it seems hard, in general, to fully characterize the multiplicative maps on the base field $k$. With a finite field it would just be integer powers and the zero map, but with the reals you get all (positive) real powers too, and some funky stuff may occur with other fields.","['linear-algebra', 'abstract-algebra', 'determinant']"
158566,"Is it wrong to say $ \sqrt{x} \times \sqrt{x} =\pm x,\forall x \in \mathbb{R}$?","Is it wrong to say $$ \sqrt{x} \times \sqrt{x} =\sqrt{x^2}= \pm x$$
I am quite sure that  $\sqrt{(x)^2} = \pm(x)$ But, does $\sqrt{x } \times \sqrt{x} =- (x)$ doesn't holds in $\mathbb{R}$ but if we assume $\mathbb{C}$ it holds right?","['algebra-precalculus', 'fake-proofs']"
158568,Bessel differential equation with random parameter,"I know that the following differential equation:
$$x^2\frac{d^2y(x)}{dx^2}+x\frac{dy(x)}{dx}+(x^2-\alpha^2)y(x)$$
has the solution:
$$y(x)=C_1\cdot J_\alpha(x)+C_2\cdot Y_\alpha(x)$$
In my case, the differential equation is of the same form, but the parameter $\alpha$ is a random variable having a Gaussian distribution with zero mean and variance $\sigma$.
I have problems to find the distribution of the solution $y(x)$. Can someone give me a hint?
Thanks.","['stochastic-calculus', 'ordinary-differential-equations']"
158575,Notation in Munkres' $\textit{Analysis on Manifolds}$,"I am trying to understand Theorem 9.1 of 1991 copy of Munkres' Analysis on Manifolds. I have stated what I don't understand below; there is a heading in bold. This theorem is a precursor to the implicit function theorem and on my copy of the book is on page 73. Now on page 72 he states the following definition: Let $A$ be open in $\Bbb{R}^m$; let $f : A \rightarrow \Bbb{R}^n$ be differentiable. Let $f_1,\ldots,f_n$ be the component functions of $f$. We sometimes use the notation 
    $$Df = \frac{\partial(f_1,\ldots,f_n)}{\partial(x_1,\ldots,x_m)}$$
    for the derivative of $f$. On occasion we shorten this to the notation $Df = \partial f /\partial \Bbb{x}$. This is all good, so now on to theorem 9.1 (which is where my confusion lies). Theorem 9.1: Let $A$ be open in $\Bbb{R}^{k+n}$; let $f : A \rightarrow \Bbb{R}^n $ be differentiable. Write $f$ in the form $f(\Bbb{x},\Bbb{y})$, for $\Bbb{x} \in \Bbb{R}^k$ and $\Bbb{y} \in \Bbb{R}^n$; then $Df$ has the form
    $$Df = \Big[ \partial f/\partial \Bbb{x} \hspace{5mm} \partial f / \partial \Bbb{y}\Big].$$
    Suppose there is a differentiable function $g : B \rightarrow \Bbb{R}^n$ defined on an open set $B$ in $\Bbb{R}^k$, such that 
    $$f(\Bbb{x},g(\Bbb{x})) = 0$$
    for all $\Bbb{x} \in B$. Then for $\Bbb{x} \in B$, 
    $$ \frac{\partial f}{\partial \Bbb{x}}(\Bbb{x},g(\Bbb{x})) + \frac{\partial f}{\partial \Bbb{y}}(\Bbb{x},g(\Bbb{x}))\cdot Dg(\Bbb{x}) = 0.$$ The dot just before $Dg(\Bbb{x})$ means matrix multiplication. Now the proof of this goes as follows, given $g$, we can define $h : B \rightarrow \Bbb{R}^{k+n}$ by the equation $$h(\Bbb{x}) = (\Bbb{x},g(\Bbb{x})).$$ The hypotheses of the theorem then imply that the composite function $f(h(\Bbb{X})) = f(\Bbb{x},g(\Bbb{x}))$ is defined and equals zero for all $\Bbb{x} \in B$. The chain rule then implies that $$\begin{eqnarray*} 0 &=& Df(h(\Bbb{x}))\cdot Dh(\Bbb{x})\\
&=& \Big[\frac{\partial f}{\partial \Bbb{x}}(h(\Bbb{x})) \hspace{4mm}  \frac{\partial f}{\partial \Bbb{y}}(h(\Bbb{x}))    \Big] \cdot \left[\begin{array}{c} I_k \\ Dg(\Bbb{x}) \end{array}\right]
\end{eqnarray*}.$$ What I don't understand: In the last row above, I get the second matrix on the right hand side, the one involving the identity matrix. However for the first matrix, I can see the notation means that it is formed by concatenating two matrices together, one from $\frac{\partial f}{\partial \Bbb{x}}(h(\Bbb{x}))$ and the other from $\frac{\partial f}{\partial \Bbb{y}}(h(\Bbb{x}))$. My problem now is I don't even no what these matrices look like. I have tried several ways to interpret them, but keep getting tied up. Also, for the second matrix on the right it is of dimensions $$(n + k) \times k$$ yes? But if this were so, then how can $Df(h(\Bbb{x}))$ be a map from $\Bbb{R}^{k+n}$ to $\Bbb{R}^n$? Thanks.","['notation', 'multivariable-calculus']"
158588,Primitivity implies transitivity?,"I am noting a simple problem about a permutation group from ""Permutation Group"" By J.Dixon, its answer and my attempt to understand it in details: Q: A primitive permutation group $G(≠1$ ) is transitive. A: If $G$ is an intransitive group ( $≠1$ ), then it has an orbit of length at least $2$ . This orbit is a nontrivial block for $G$ . This is clear that any intransitive group ( $≠1$ ) can possess an orbit $B$ of length at least $2$ . Let $G$ is acting on a set $\Omega$ . Since $∅≠B≠\Omega$ and it has at least two elements, it is enough to show that $B$ is a block. If for example $B$ ={ $\alpha$ , $\beta$ } then I shuold check $B^g∩B=∅$ or $B^g=B$ for any $g\in G$ . $B^g$ ={ $\alpha^g$ , $\beta^g$ } and if $g\in G_{\alpha,\beta}$ then $B^g=B$ clearly. If $g∉G_{\alpha,\beta}$ then we get $B^g∩B=∅$ . Honestly, I cannot go for the rest. If my approach is not wrong, please help me to complete the answer. Thanks","['permutations', 'finite-groups', 'group-theory']"
158591,Evaluting: $\int\frac{1}{(1+\tan x)^2} dx$,"I can solve this integral 
$$
\int\frac{1}{(1+\tan x)^2} dx
$$
using the substitution $t=\tan x$ i.e $x=\arctan t$. Does anyone know another way to solve this integral?","['calculus', 'integration']"
158594,My first course in algebraic geometry: two simple questions,"I'm attending my first course in algebraic geometry, and my professor has chosen an approach which is a middle-way between the basic algebraic geometry done in $\mathbb A^n_k$ and the approach with schemes, so substantially like in Milne's notes . I have for you some simple question and I hope that the answers will not involve scheme theory: 1) Let $(X,\mathcal O_X)$ an affine variety, so it is isomorphic as ringed space to $(V,\mathcal O_V)$ where $V$ is an affine algebraic set and $\mathcal O_V$ is the sheaf of regular functions. When one says ""take the covering of $X$ with standard open sets"", it means that we consider the covering of $X$ done with those open sets of $X$  which are homeomorphic to the standard open sets $D(f)\subseteq V$? 2) In class we have defined a quasi-coherent sheaf on $(V,\mathcal O_V)$ (we are in $\mathbb A^n_k$) as the sheaf $\widetilde M $ uniquely associated to the assignment $\widetilde M(D(f))=M_f$ where $M$ is a $\Gamma(V,\mathcal O_V)$-module. When we talk about a quasi-coherent sheaf defined on a abstract affine variety $(X,\mathcal O_X)$ so isomorphic to  $(V,\mathcal O_V)$, do we intend a sheaf $\mathcal F$ on $X$ with an isomorphism $\mathcal F\cong f_{\ast}\widetilde M$ (assuming that $f$ is the omeomorphism between $V$ and $X$)?","['sheaf-theory', 'algebraic-geometry']"
158595,Prime as sum of three numbers whose product is a cube,"Good evening! 
I am very new to this site. I would like to put the following material from Prof. Gandhi's note book and my observations. Of course it is little long with more questions. But, with good belief on this site, I am sending for good solutions/answers. If we take other than primes $2$, $5$ and $11$, every prime can be written as $x + y + z$, where $x$, $y$ and $z$ are some positive numbers. Interestingly, $x \times y \times z = c^3$, where $c$ is again some positive number.
Let us see the magic for primes $3,7,13,31,43,73$
$$
\begin{align}
3 = 1 + 1 + 1 &\Longrightarrow 1 \times 1 \times 1 =  1^3\\
7 = 1 + 2 + 4 &\Longrightarrow  1 \times 2 \times 4 = 2^3\\
13 = 1 + 3 + 9 &\Longrightarrow 1 \times 3 \times 9 = 3^3\\
31 = 1 + 5 + 25 &\Longrightarrow 1 \times 5 \times 25 = 5^3\\
43 = 1 + 6 + 36 &\Longrightarrow 1 \times 6 \times 36 = 6^3\\
73 = 1 + 8 + 64 &\Longrightarrow 1 \times 8 \times 64 = 8^3\\
\end{align}
$$
Can you justify the above pattern?  How to generalize the above statement either mathematically or by computer? But, I observed that it is true for primes less than $9500$. Can your provide a computational algorithm to describe this? Also, prove that, we conjecture that except $1, 2, 3, 5, 6, 7, 11, 13, 14, 15, 17, 22, 23$, every positive number can be written as a sum of four positive numbers and the product is again can be expressible in 4th power.  Now, can we generalize this? Also, I want to know that, is there any such numbers can be expressible as some of $n$-integers with their product is again in $n$-th power? Thank you so much. edit Concerning this cubic property : Notice that this can be extended to hold for almost all squarefree positive integers $> 2$, not just the primes. for instance : 
we know for the prime $7$ : $7=1+2+4$ so we also get $7A = 1A + 2A + 4A$ and $1A * 2A * 4A$ is simply equal to $8A^3$. In fact this can be extended to all odd positive integers $>11$ if $25,121$ have a solution. Hence I am intrested in this and I placed a bounty. I edited the question because its to much for a comment and certainly not an answer. Btw Im curious about this Ghandi person though info about that does not get the bounty naturally. I would like to remind David Speyer's comment : Every prime that is $1 mod 3$  is of the form $a^ 2 +ab+b^ 2$  , so that covers half the primes immediately. So that might be a line of attack.",['number-theory']
158598,Compute operator norm by image on orthonormal basis,"Let $e_n$ a orthonormal basis for a Hilbert space and $T$ a bounded linear operator. Is the following correct? $$\lVert T \lVert^2 \leq \sup_{n \in \mathbb{N}} \sum_{k \in \mathbb{N}} |\langle e_n,Te_k\rangle|^2$$","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
158613,Basic calculation of an expectation,"We define $J_{k,n}:=((k-1)2^{-n},k2^{-n}]$ for $n\in \mathbb{N}_0$ and $k=1,\dots,2^n$. Let $W$ be a Brownian Motion. Let $n\ge m$ and we assume $J_{k,n}\subset J_{l,m}$. W.l.o.g $J_{k,n}$ lies in the left half of $J_{l,m}$. Moreover we set $\Delta W([a,b])=W_b-W_a$, which is by definition normal distributed. Hence I know $\Delta W (J_{2k-1,n+1})-\Delta W(J_{2k,n+1})$ and $\Delta W(J_{2l,m+1})$ are independent, since $J_{k,n}$ lies in the left half of $J_{l,m}$. Furthermore, $(l-1)2^{-m}\le (k-1)2^{-n}\le k2^{-n}\le(2l-1)2^{-(m+1)}$. 
Why is the following computation true? $$E[(\Delta W (J_{2k-1,n+1})-\Delta W(J_{2k,n+1}))\Delta W(J_{2l-1,m+1})]=2^{-(n+1)}-0-2^{-(n+1)}+0=0$$ They argue that all sub intervals of a dyadic partition have the same length. EDIT: Here is what I did so far: $\Delta W (J_{2k-1,n+1})=W_{(2k-1)2^{-(n+1)}}-W_{(k-1)2^{-n}}$ $\Delta W(J_{2k,n+1}) = W_{k2^{-n}}-W_{(2k-1)2^{-(n+1)}}$ $\Delta W(J_{2l-1,m+1}) = W_{(2l-1)2^{-(m+1)}}-W_{(l-1)2^{-m}}$ $\Delta W (J_{2k-1,n+1})-\Delta W(J_{2k,n+1})=2W_{(2k-1)2^{-(n+1)}}-W_{(k-1)2^{-n}}-W_{k2^{-n}}$ From here, I do not know how to proceed. hulik","['probability-theory', 'probability']"
158617,"About the Wasserstein ""metric""","I've just encountered the Wasserstein metric , and it doesn't seem obvious to me why this is in fact a metric on the space of measures of a given metric space $X$ . Except for non-negativity and symmetry (which are obvious), I don't know how to proceed. Do you guys have any advices or links to useful references? Thanks in advance!","['probability-theory', 'measure-theory', 'metric-spaces']"
158630,Relationship Between The Z-Transform And The Laplace Transform,"Below I've quoted Wikipedia's entry that relates the Z-Transform to the Laplace Transform.  The part I don't understand is $z \ \stackrel{\mathrm{def}}{=}\ e^{s T}$; I thought $z$ was actually an element of $\mathbb{C}$ and thus would be $z \ \stackrel{\mathrm{def}}{=}\ Ae^{s T}$ (but then it would be different to the Laplace Transform...).  I don't understand why the Z-Transform is not defined as:
$$
X(z) = \mathcal{Z}\{x[n]\} = \sum_{n=-\infty}^{\infty} x[n] e^{-\omega n}
$$
or something like that. Z-transform The unilateral or one-sided Z-transform is simply the Laplace transform of an ideally sampled signal with the substitution of $$
    z \ \stackrel{\mathrm{def}}{=}\ e^{s T} \  $$
    where $T = 1/f_s \ $is the sampling period (in units of time e.g., seconds) and $f_s \ $is the sampling rate (in samples per second or hertz) Let $$
    \Delta_T(t) \ \stackrel{\mathrm{def}}{=}\ \sum_{n=0}^{\infty} \delta(t - n T)  $$ be a sampling impulse train (also called a Dirac comb) and $$
    \begin{align} x_q(t) & \stackrel{\mathrm{def}}{=}\ x(t) \Delta_T(t) = x(t) \sum_{n=0}^{\infty} \delta(t - n T) \\ & = \sum_{n=0}^{\infty} x(n T) \delta(t - n T) = \sum_{n=0}^{\infty} x[n] \delta(t - n T) \end{align}  $$ be the continuous-time representation of the sampled x(t) \
$$
    x[n] \ \stackrel{\mathrm{def}}{=}\ x(nT) \ $$ are the discrete samples of x(t) The 
Laplace transform of the sampled signal x_q(t) \ is $$
    \begin{align} X_q(s) & = \int_{0^-}^\infty x_q(t) e^{-s t} \,dt \\ & = \int_{0^-}^\infty \sum_{n=0}^\infty x[n] \delta(t - n T) e^{-s t} \, dt \\ & = \sum_{n=0}^\infty x[n] \int_{0^-}^\infty \delta(t - n T) e^{-s t} \, dt \\ & = \sum_{n=0}^\infty x[n] e^{-n s T}. \end{align}  $$ This is precisely the definition of the unilateral Z-transform of the discrete function $x[n] \ $. $$
    X(z) = \sum_{n=0}^{\infty} x[n] z^{-n}  $$ with the substitution of $z \leftarrow e^{s T} \ $. Comparing the last two equations, we find the relationship between the unilateral Z-transform and the Laplace transform of the sampled signal: 
$$
    X_q(s) = X(z) \Big|_{z=e^{sT}}
$$ The similarity between the Z and Laplace transforms is expanded upon in the theory of time scale calculus. (Source: http://en.wikipedia.org/wiki/Laplace_transform#Laplace.E2.80.93Stieltjes_transform ) Here: http://en.wikipedia.org/wiki/Z-transform it says that $z \in \mathbb{C}$.","['laplace-transform', 'discrete-mathematics', 'integral-transforms']"
158631,Summation of a series.,"I encountered this problem in Physics before i knew about a thing called Taylor Polynomials My problem was that i had to sum this series : $$\sum^\infty_{n=1}\frac{(-1)^{n+1}}{n}$$
basically $$1,-\frac{1}{2},\frac{1}{3},-\frac{1}{4},\frac{1}{5},-\frac{1}{6},\frac{1}{7}.....$$ So now i know that there is something called a taylor polynomial that says that $$\ln(1+x)=x-\frac{x^2}{2}+\frac{x^3}{3}-\frac{x^4}{4}+\frac{x^5}{5}-\frac{x^6}{6}+\frac{x^7}{7}....$$ So the above summation boils down to $\ln 2$. What if i never knew the exansion then how would I calculate it? Earlier I tried solving it like so , divide it into two different sets i.e. $$\text{1 and $\dfrac{1}{3}+\frac{1}{5}+\frac{1}{7}+\frac{1}{9}+\frac{1}{11}+\frac{1}{13} \ldots$ and $-\dfrac{1}{2}-\frac{1}{4}-\frac{1}{6}-\frac{1}{8}-\frac{1}{10}\ldots$}$$ I said Hey! the first set would contain stuff like, $$\frac{1}{3^n},\frac{1}{5^n},\ldots$$ each of them would probably be reduced to a sum like so $$\sum^\infty_{n=1}\frac1{a^n}=\frac1{a-1}$$ and further become $$\sum^\infty_{a=3}\frac1{a-1}$$ which would subtract all the numbers in the other even set giving 1 as the answer which is wrong . Where did I go wrong and how could I proceed even without knowing Taylor polynomials","['logarithms', 'sequences-and-series', 'taylor-expansion']"
158656,Transcendental extension that is not simple,"Let $K$ be a field and $x, y$ be independent variables. How can I show that $K(x, y)/K$ is not a simple extension?","['extension-field', 'abstract-algebra', 'field-theory']"
158686,does there exist an analytic function such that,If $f$ is analytic in a nbd $\Delta_{\delta}$ of $0$ and $f(z)=-f(-z)\forall z\in\Delta_{\delta} $ Then there exist an analytic function $g\in \Delta_{\delta}$ such that $f(z)=zg(z^2)\forall z\in \Delta_{\delta}$,['complex-analysis']
158710,The definition of $f(z)$ being analytic at point $\infty$,"Consider this function $f(z) = \frac{1}{1+z}$. We can define $f(\infty) = \lim_{z \rightarrow \infty}{f(z)}$, which is zero for this case. Since $f(\frac{1}{t}) \rightarrow \frac{t}{t+1}$ is analytic at point $t=0$, we can deduce that $f(z)$ is analytic at $z=\infty$. On the other hand, if we consider the type of singularity at $t=0$ of $f(\frac{1}{t})$. There is singularity because of the existence of $\frac{1}{t}$ but the singularity is removable. So the singularity at $z=\infty$ is removable. The definition is $f(\infty) = \lim_{z \rightarrow \infty}{f(z)}$. So how we discuss the singularity and think of it as removable if the value of $f(\infty)$ is taken from the limit?",['complex-analysis']
158716,Repeatedly rolling a die and the tails of the multinomial distribution.,"For $1\leq i\leq n$ let $X_i$ be independent random variables, and let each $X_i$ be the uniform distribution on the set ${0,1,2,\dots,m}$ so that $X_i$ is like an $m+1$ sided die.  Let $$Y=\frac{1}{n}\sum_{i=1}^n \frac{1}{m} X_i,$$ so that $\mathbb{E}(Y)=\frac{1}{2}$.  I am interested in the tails of this distribution, that is the size of $$\Pr\left( Y \geq k\right)$$ where $\frac{1}{2}< k\leq 1$ is a constant. In the case where $m=1$, we are looking at the binomial distribution, and $$\Pr\left( Y \geq k\right)= \frac{1}{2^n}\sum_{i=0}^{(1-k) n} \binom{n}{i}$$ and we can bound this above by $(1-k)n \binom{n}{(1-k)n}$ and below by $\binom{n}{(1-k)n}$ which yields $$\Pr\left( Y \geq k\right)\approx \frac{1}{2^n} e^{n H(k)}$$ where $H(x)=-\left(x\log x+(1-x)\log (1-x)\right)$ is the entropy function.  (I use approx liberally) What kind of similar bounds do we have on the tails of this distribution when  $m\geq 2$?  I am looking to use the explicit multinomial properties to get something stronger than what you would get using Chernoff of Hoeffding.","['distribution-tails', 'inequality', 'probability-theory', 'probability-distributions', 'probability']"
158722,Linear independence of $n$th roots over $\mathbb{Q}$,"I know that the set of square roots of distinct square-free integers is linearly independent over $\mathbb{Q}$. To generalize this fact, define $R_n = \{ \sqrt[n]{s} \mid s\text{ integer with prime factorization }s = p_1^{a_1} \ldots p_k^{a_k}, \text{ where } 0 \leq a_i < n \}$ For example, $R_2$ is the set of square roots of square-free integers. Question: Is $R_n$ linearly independent over $\mathbb{Q}$ for all $n \geq 2$? Harder (?) question: Is $\cup_{n\geq2}R_n$ linearly independent over $\mathbb{Q}$?","['linear-algebra', 'elementary-number-theory', 'abstract-algebra']"
158731,Creating Unique Values based off Two Sets of Sequential Integers,"First off, I apologize if this is the wrong board. I'm a heavy StackOverflow user, and this is technically a programming question (or at least serves programming use), but I find it to be based moreso in math. I have two sets of sequential integers that relate to each other, for the sake of example, defined as such: Set A: [1..50]
Set B: [1..150] I need to generate a third set from a combination of these two sets, with unique values. All integers from Set A must be programmatically paired with all integers from Set B to create Set C , which will contain unique integers. Jumping right into it, I thought ""Well, just add the two to together!"" I found quickly that such an idea wasn't even close to feasible. Set A   Set B   Set C
-----   -----   -----
1       1       2
1       2       3 *
1       3       4 *
2       1       3 *
2       2       4 *
2       3       5

*Non-unique Values Multiplication didn't go so well either... Set A   Set B   Set C
-----   -----   -----
1       1       1
1       2       2 *
1       3       3 
2       1       2 *
2       2       4 
2       3       6

*Non-unique Values So I'm looking for an operator or small formula to put between Set A and Set B to generate a unique, integral Set C . EDIT Both sets will have values added to them over time, so I need a solution that could handle an infinitely large Set A and Set B","['matrices', 'sequences-and-series']"
158739,Things related to the Preissman Theorem,"I'm reading the proof of the Preissman Theorem, in Do Carmo's book of Riemannian Geometry.  A crucial step in this demonstration is the following lema, Lema : Let $M$ be a compact riemannian manifold, and $\alpha$ a non trivial deck transformation of  the universal covering $\widetilde{M}$, where we are considering $\widetilde{M}$ with  a  covering metric. So the statement is that $\alpha$ leaves invariant a geodesic $\widetilde{\gamma}$  of    $\widetilde{M}$, in this sense $$\alpha(\widetilde{\gamma}(-\infty,\infty))=\widetilde{\gamma}(-\infty,\infty).$$ Sketch of proof : Let $\pi:\widetilde{M}\to M$ be the  covering  transformation. Let $\widetilde{p}\in \widetilde{M}$ and $p=\pi(\widetilde{p}).$ Let $g\in \pi_1(M,p)$ be the element corresponding to $\alpha$  by the known isomorphism $\pi_1(M,p)\simeq Aut(\widetilde{M}).$ By the Cartan Theorem, there is a closed geodesic $\gamma$ in the  class of free homotopy $M$ given by $g.$ The main idea now is to show that, $\alpha$  fixes the extension of a lifting of $\gamma.$ For this, we obtain a deck tranformation that clearly fix the lifting of $\gamma$ (just take a deck  transformation $\beta$ associated to the class of homotopy of $\gamma$ with a base point $q\in \gamma$). And then show that they coincide in one point and therefore must be the same, $\alpha=\beta$. My Question : Is there any reason to believe that the geodesic wich will be fixed by $\alpha$  is precisely the lifting  of a geodesic  given by the Cartan Theorem? 
Or was that just an insight wich the person who'd demonstrated the theorem have? For those who do not remember this is the statement of the theorem cartan Cartan Theorem : Let $M$ be a compact riemannian manifold. Let $\pi_1(M)$ be the set of all the classes of free homotopy of $M.$ Then in each non trival class there is a closed geodesic. (i.e a closed curve which is geodesic in all of its points.)","['riemannian-geometry', 'algebraic-topology', 'differential-geometry']"
158747,Bloch-Kato conjecture and Wiles' numerical criterion,"In the introduction (p. 14) of this paper on FLT the authors say that a numerical criterion found by Wiles as part of his proof of FLT ""seems to be very close 
to a special case of the Bloch-Kato conjecture"". Can someone explain how this numerical criterion is related to a (which ?) special case of the Bloch-Kato conjecture (which is now a theorem) ? The numerical criterion is Theorem 5.3 (p. 139) in the linked paper.",['number-theory']
158751,A question about Euclidean Domain,"This is a problem from Aluffi's book, chapter V 2.17. ""Let $R$ be a Euclidean Domain that is not a field. Prove that there exists a nonzero, nonunit element $c$ in $R$ such that $\forall a \in R$, $\exists q$, $r \in R$ with $a = qc + r$, and either $r = 0$ or $r$ a unit."" Ok, I know that if $c\mid a$ then $r=0$, but if $c\nmid a$, not sure about what to do. I took the classic Euclidean Domain $\mathbb{Z}$ as example, and in $\mathbb{Z}$ I know that $c = 2$ ( also $-2$). Then I tried to generalize this. I did $c = unit + unit$, but this didn't help and exercise 2.18 showed me that $c$ is not always $unit+unit$. I'm out of ideas, need some help. Thanks.","['euclidean-domain', 'ring-theory', 'abstract-algebra']"
158755,How to know if its permutation or combination in a specific exercise?,"I have a question, In how many ways can $6$ tosses of a coin yield $2$ heads and $4$ tails? Now, to me, the question clearly seems to be of a permutation, as they have asked for the number of ways (they have mentioned nowhere that we have to choose. ) But the actual solution tells that the question is solved by a combination. Why is it a question of combination and not of permutation?","['permutations', 'combinatorics']"
158758,What is the result of sum $\sum\limits_{i=0}^n 2^i$ [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: the sum of powers of $2$ between $2^0$ and $2^n$ What is the result of 
$$2^0 + 2^1 + 2^2 + \cdots + 2^{n-1} + 2^n\ ?$$ Is there a formula on this? and how to prove the formula? (It is actually to compute the time complexity of a Fibonacci recursive method.)","['geometric-progressions', 'summation', 'algebra-precalculus']"
158764,Radius of convergence of the inverse of a power series,"Let $a = \sum_k a_k X^k \in \mathbb C [\![ X ]\!]$ with $a_0 = 1$ and convergence radius $\rho_a > 0$.
I want to show that the convergence radius of the inverse $b = \sum_k b_k X^k \in \mathbb C [\![ X ]\!]$ is also greater than 0.
How can I do that?","['calculus', 'analysis']"
158787,Difference between calculus and analysis,"It's somthing I always want to figure out, when did calculus start to be extended to analysis(I reformulate the question, the previous one""where one can draw a line to distinguish calculus and analysis, or there does not even exist such a line."" was quite misleading). As mentioned a lot in comments, analysis is a much border field than calculus, but the root could be traced back to the calculus in 19th century. Besides, indeed infinitesimal calculus was proved in non-standard analysis, but it was invented until 1960s I think. And I don't know if it can replace all arguments in the theories developed after $\varepsilon-\delta$-definition and before the invention of non-standard analysis. I will explain what I understand, please point out my mistakes. The early stage (Newton and Leibniz) They used infinitesimal, say $\mathrm{d}(\cdot)$ to describe change such as $\mathrm{d}x$ and $\mathrm{d}y$.
And use
$$\frac{\mathrm{d}y}{\mathrm{d}x}=\frac{y(x+\mathrm{d}x)-y(x)}{\mathrm{d}x}$$
to compute derivatives. And let $y'$ be a shorthand notation for $\frac{\mathrm{d}y}{\mathrm{d}x}$, they defined integral as sum over infinitesimals
$$\int y' \mathrm{d}x. $$
(I do not know how Newton and Leibniz defined integral. Maybe as $\approx\sum y(x_i)\Delta x$?) 19th century People started worrying about the precision of infinitesimals. And the ratio of infinitesimals was replaced by limit (the '$\varepsilon-\delta$' definition). In shorhand notation 
$$\frac{\mathrm{d}y}{\mathrm{d}x}:=\lim_{t\rightarrow 0}\frac{y(x+t)-y(x)}{t}.$$ 
$$$$ While the notation was inherited, it did no longer hold the original meaning. And Riemann established his formalization of integration. Based on these, people started to work on functions defined in real number system (real analysis). And in the meantime, the properties of real number were intensively explored (set theory, continuum, etc.). Later the concept of limit was further extended to more general spaces, such as metric spaces(generalized distance), normed spaces(generalized length). So many branches of analysis such as measure theory(it's a part of real analysis. I put it here simply because I feel it is so important.), functional analysis, differential equations emerged. Hence, roughly speaking, changing from infinitesimal approach to limit approach can be considered as the line separating calculus and analysis. Interestingly, in modern calculus textbooks, they in fact loosely use analysis approach while they remain name themself as Calculus. Is this because they do not discuss real number system, which is the very base for the rest. And they only loosely argue 'taking limit by $\Delta x\rightarrow 0$'? I really get confused here. Updates: Can I state that calculus is a study on real-valued functions with $\mathbb{R}^d$-valued argument?
So one can loosely conclude that
$$\text{infinitesimal and integral calculus} \subsetneq \text{real analysis}\subsetneq \text{analysis}.$$ Update again: The question is much clear now.
If calculus is understood as art of calculation, there is no more confusions. Thanks for all dedications on this topic! Since most of answers pointed out the linchpin for the question, I hope it won't cause any misunderstanding if I do not accept any of them. At the end, I hope this post will help others in future. Cheers.","['math-history', 'analysis']"
158788,Simple question regarding continuous functions on $\mathbb{Q}$,"I am a self-studying masochist and I came across an interesting example (to me), that I think will help me with further results. I have little experience writing rigorous proofs, so any explicit help is appreciated. What I am trying to prove is the following: Find a measurable indicator function that cannot be approximated by a sequence of continuous functions (demonstrate). For this I believe the ""answer"" is some form of $1_{\mathbb{Q}}$ on a finite interval. I believe this function is both measurable and not a pointwise limit of continuous functions. How can I show that if I have a continuous function arbitrarily close to 1 on the rationals, it cannot also be arbitrarily close to 0 on the irrationals? I do know that continuous functions are uniformly continuous on finite intervals, but I cant seem to put all the pieces together. Any detail would be greatly appreciated.
Thanks!","['measure-theory', 'real-analysis']"
158803,Details on the Hopf Foliation,"I am trying to understand the Hopf foliation better....that is, the foliation of the 3-sphere induced from the Hopf fibration. Start with the 3-sphere $\mathbb{S}^3=\{(z_1,z_2)\in \mathbb{C}^2:|z_1^2|+|z_2^2|=1\}$ The Hopf foliation (as I understand it) can be parameterized as the action $\phi_t(z_1,z_2)=(z_1e^{it},z_2e^{it}).$ This is a codimension-1 foliation of the 3-sphere, but I don't see how the leaves can be 2-dimensional. I kinda still see a 3-sphere since for fixed $t$ since it would seem $(z_1,z_2)$ can still vary independently under the condition $|z_1^2|+|z_2^2|=1$. The second question is that the leaves are supposed to be tori, $\mathbb{T}^2=\mathbb{S}^1\times \mathbb{S}^1$, and I'm not sure I see that since $z_1e^{it}=re^{i(t+\theta)}$ where $(r,\theta)$ coordinize $\mathbb{C}^2$. Seems like that's just a shift of the angular coordinates and those are still the coordinates of $\mathbb{C}^2$. Can someone explain this to me? I suspect an explaination of one question will probably solve the other as well. Thanks!","['general-topology', 'differential-topology']"
158818,"Integral of $\int 2\,\sin^{2}{x}\cos{x}\,dx$","I am asked as a part of a question to integrate $$\int 2\,\sin^{2}{x}\cos{x}\,dx$$ I managed to integrate it using integration by inspection:
$$\begin{align}\text{let } y&=\sin^3 x\\
              \frac{dy}{dx}&=3\,\sin^2{x}\cos{x}\\
              \text{so }\int 2\,\sin^{2}{x}\cos{x}\,dx&=\frac{2}{3}\sin^3x+c\end{align}$$ However, looking at my notebook the teacher did this:
$$\int -\left(\frac{\cos{3x}-\cos{x}}{2}\right)$$
And arrived to this result:
$$-\frac{1}{6}\sin{3x}+\frac{1}{2}\sin{x}+c$$ I'm pretty sure my answer is correct as well, but I'm curious to find out what how did do rewrite the question in a form we can integrate.","['trigonometry', 'integration']"
158834,Does this equation have infinitely many solutions?,"I was considering some number theory problems which inspired me to write the following conjecture, which bears some resemblance to the Catalan problem, but is in fact different: Fix two distinct sequences of primes $p_{1}, ..., p_{n}$ and $q_{1}, ..., q_{m}$. Do there exist infinitely many sequences of naturals $a_{1}, ..., a_{n}$, $b_{1}, ..., b_{m}$ such that: $p_{1}^{a_{1}} ... p_{n}^{a_{n}} - q_{1}^{b_{1}} ... q_{m}^{b_{m}} = 1$?","['diophantine-equations', 'number-theory']"
