question_id,title,body,tags
1337678,My brother asked me to explain a algebra problem. How should I explain it?,"So the problem is: $$\frac{4}{x}+\frac{6}{2}=x$$
And we solved it using the pq formula. But than he asked me: How do I know when I should apply pq to similar equations like this
  and not just: $$4 + 3 = x^2$$ $$x = \sqrt{7}$$ ? Do I have to just test to find out if its wrong, and than just try all
  possible solutions until I find the correct one or can I see it some
  how? I saw right away how to solve it but I do not really know why, so long ago I dealt with problems like this. Anyone have a idea how to explain it?","['quadratics', 'algebra-precalculus']"
1337703,why does Lie bracket of two coordinate vector fields always vanish?,"This is really puzzling me. Say we are dealing with a Riemannian manifold $(M,g)$ . Suppose $\nabla$ is the unique torsion free connection on $M$ that is compatible with $g$ . Suppose we are in a neighbourhood $U$ with coordinate map $(x^1,\cdots, x^m )$ . Since the connection is torsion free, $$\left[\frac{\partial}{\partial x_i},\frac{\partial}{\partial x_j}\right]=\nabla_{\frac{\partial}{\partial x_i}}{\frac{\partial}{\partial x_j}}-\nabla_{\frac{\partial}{\partial x_j}}{\frac{\partial}{\partial x_i}}.$$ And since the $\Gamma_{i,j}^k$ is symmetric on $i,j$ , the right hand side of the above equation will vanish. So the Lie bracket will be $0$ . Now here is my confusion. If I start out with $m$ linearly independent vector fields $Y_1, \cdots, Y_m$ , then I can find a coordinate system $(y_1,\cdots, y_m)$ such that $Y_i = \frac{\partial }{\partial y_i}$ (Correct me if I am wrong, because I am not sure about this) . Then arguing as above, I can show that the Lie bracket of $Y_i$ and $Y_j$ vanishes. I know Lie bracket shouldn't vanish on any two random vector fields I pick. So there must be something wrong with my argument here. Thank you in advance!","['differential-geometry', 'riemannian-geometry']"
1337704,Two different trigonometric identities giving two different solutions,"Using two different sum-difference trigonometric identities gives two different results in a task where the choice of identity seemed unimportant. The task goes as following: Given  $\cos 2x =-\frac {63}{65} $ , $\cos y=\frac {7} {\sqrt{130}}$, under the condition $0<x,y<\frac {\pi}{2}$, calculate $x+y$. The first couple of steps are the same: finding  $\sin$ and $\cos$ values for both $x$ and $y$. From $\cos 2x$ we have: \begin{align*}
\cos 2x &=-\frac {63}{65} \\
\cos2x &= \cos^2x-\sin^2x = \cos^2x - (1-\cos^2x)=2\cos^2x -1 \\
2\cos^2x -1 &= -\frac {63}{65} \\
2\cos^2x &=\frac {-63+65}{65} \\
\cos^2x &=\frac {1}{65} \\
\cos x &=\frac {1} {\sqrt{65}} 
\end{align*}
(taking only the positive value of $\cos x$ because $\cos x$ is always positive under the given domain) \begin{align*}
\sin^2x &=1-\frac {1}{65} \\
\sin^2x &=\frac {64}{65}   \\
\sin x &=\frac {8} {\sqrt{65}} 
\end{align*}
(again, only positive value) From $\cos y$ we have: \begin{align*}
\cos y &=\frac {7} {\sqrt{130}} \\
\cos^2y &=\frac {49} {130} \\
\sin^2y &=1-\frac {49} {130} \\
\sin^2y &=\frac {81} {130} \\
\sin y &=\frac {9} {\sqrt{130}}
\end{align*} Now that we've gathered necessary information, we proceed to calculate value of some trigonometric function of $x+y$, hoping we will get some basic angle: sin(x+y) :
\begin{align*}
\sin(x+y) &=\sin x \cos y + \sin y \cos x =\frac {8} {\sqrt{65}} \frac {7} {\sqrt{130}} + \frac {9} {\sqrt{130}}\frac {1} {\sqrt{65}} \\
\sin(x+y) &=\frac {65} {\sqrt{65}\sqrt{130}} \\
\sin(x+y) &=\frac {\sqrt{2}}{2} 
\end{align*}
Thus,
$x+y =\frac {\pi}{4}+2k{\pi}$  OR  $x+y =\frac {3\pi}{4}+2k{\pi}$ Since $x$ and $y$ are in the first quadrant, their sum must lie in first or second quadrant. Solutions are: $x+y= \{\frac {\pi}{4}, \frac {3\pi}{4} \}$ cos(x+y) :
\begin{align*}
\cos(x+y) &= \cos x \cos y - \sin x \sin y =\frac {1} {\sqrt{65}} \frac {7} {\sqrt{130}} - \frac {8} {\sqrt{65}}\frac {9} {\sqrt{130}} \\
\cos(x+y) &=-\frac {65} {\sqrt{65}\sqrt{130}} \\
\cos(x+y) &=-\frac {\sqrt{2}}{2}
\end{align*}
Thus,
$x+y =\frac {3\pi}{4}+2k{\pi} $   OR   $x+y =\frac {5\pi}{4}+2k{\pi}$ Now we can only have one solution: $x+y=\{\frac {3\pi}{4}\}$ Similar happens with $\cos(x-y)$. My question is: why do these two formulas give two different solutions? General insight would be great, since I found a lot of examples with similar problems. Thank you in advance.",['trigonometry']
1337734,What can we say about the graph when many eigenvalues of the Laplacian are equal to 1?,"The Laplacian of the graph has all the eigenvalues real and non-negative, the smallest being 0. I have a graph where the second smallest eigenvalue (the so called algebraic connectivity) is equal to $1$ . In fact, the multiplicity of this eigenvalue is quite high: in other words, many eigenvalues of the Laplacian are equal to $1$ . What can we say about the graph when many eigenvalues of the Laplacian are equal to 1? For example, eigenvalue $0$ implies that the row sum is $0$ . What about eigenvalue $1$ with high multiplicity? In my case, the Laplacian is defined as $L = D - A$ , where $D$ is the degree matrix (diagonal matrix with degree values on the diagonal) and $A$ is the adjacency matrix of the graph.","['matrices', 'graph-theory', 'eigenvalues-eigenvectors', 'graph-laplacian', 'spectral-graph-theory']"
1337737,Calculating limit of a particular product series,"How to find 
$$\lim\limits_{n\to\infty} \left(1+\frac{ 1 }{ a_{ 1 } }  \right) \left( 1+\frac { 1 }{ a_{ 2} }  \right)\cdots\left( 1+\frac { 1 }{ a_{ n } }  \right) $$ 
where 
$$a_1=1$$ 
$$a_n=n(1+a_{n-1})$$ 
for all $n \geq 2$?",['limits']
1337772,"Homotopy equivalences between some sphere-based spaces (quotient of spheres, bouquet of spheres, difference of spheres)","I'd like to prove the following equivalences ($k < n$): $S^n / S^k \sim S^n \vee S^{k+1}$; $S^n \backslash S^k \sim S^{n-k-1}$. Low-dimension cases (e.g. $S^2 / S^0$, $S^2 / S^1$, $S^n / S^1$, $S^2 \backslash S^1$) are completely obvious. Is there any way to prove that for arbitrary dimensions? I have been trying to develop approaches based on mathematical induction (for $k = 0,1,\dots$) and representation spheres as quotient spaces ($S^n \sim D^n / S^{n-1}$). Unfortunately, all these attempts failed for me: I could not achieve any significant simplification bringing me closer to the solution. Any suggestions?","['homotopy-theory', 'general-topology']"
1337774,Finite Difference for Hamilton-Jacobi-Bellman without boundary conditions,"Let $t\in\mathbb{R}_+$ denote time, $x \in X$ is the state and $u \in U$ the control. The objective function is $F:X \times U \to\mathbb{R}$ and $f:X \times U \to\mathbb{R}$ is the law of motion for the state, i.e. 
\begin{align}
\dot{x}(t) = f(x(t),u(t))
\end{align}
Define the value function $v:X\to\mathbb{R}$ by 
\begin{align}
v(x_0):=\max_{\{u(t)\}_{t \geq 0}}\left[\int^\infty_0{e^{-\rho t}F(x(t),u(t))dt}\right]
\end{align}
where $x_0:=x(0)$ is a given initial condition and $\rho\in\mathbb{R}_{++}$
is a parameter (time preference rate). The Hamilton-Jacobi-Bellman equation in current time reads
\begin{align}
\rho v(x) = \max_u[F(x,u) + v'(x)f(x,u)]
\end{align}
which is an ODE. If one can solve for $v(\cdot)$ we can recover the optimal path \begin{align}
\{u^*(t):t\in\mathbb{R}_+\}  = \arg\max_{\{u(t)\}_{t \geq 0}}\left[\int^\infty_0{e^{-\rho t}F(x(t),u(t))dt}\right]
\end{align}
I try to solve the HJB equation by value function iteration. That is guessing an initial value function and then iterate until it converges to the true value. I update via an implicit method a la
\begin{align}
\frac{v_{j+1}(x_n)-v_j(x_n)}{\Delta} + \rho v_j(x_n) = F(x_n,u^*_n) + v'_{j+1}(x_n)f(x_n,u^*_n)
\end{align}
where $\Delta$ is a scaling paramter, $j=0,1,2,\ldots$ the number of iterations and $x_n$ an element of the grid of the state space
\begin{align}
\mathbf{x} := [x_n]_{n=1}^N\in X^N
\end{align}
and $u_n$ is the solution of
\begin{align}
u^*_n = \arg\max_u [F(x_n,u_n) + v'_{j+1}(x_n)f(x_n,u_n)]
\end{align} To get an expression for $v'(\cdot)$ we shall define slope coefficients by
\begin{align}
v'(x_n) :\approx
\begin{cases}
\displaystyle\frac{v(x_{n+1}) - v(x_n)}{\Delta x}\quad&\text{forward difference}\\[2mm]
\displaystyle\frac{v(x_{n+1}) - v(x_{n-1})}{2\Delta x}\quad&\text{central difference}\\[2mm]
\displaystyle\frac{v(x_n) - v(x_{n-1})}{\Delta x}\quad&\text{backward difference}\\
\end{cases}
\end{align} where $\Delta x$ denotes the equidistance between the elements of $\mathbf{x}$, i.e.
\begin{align}
\Delta x:=x_{n+1} - x_n = x_n - x_{n-1}~\forall n 
\end{align} Problem It's known that for forward and backward difference one derivative is missing and for central difference two. We can deal with this issue by a boundary condition on either side. However, consider that there is no boundary condition given. I can still approx $v'(x)$ by a combination of forward, backward and central difference. For instance (case 1)
\begin{align}
v'(x_n) \approx
\begin{cases}
\displaystyle\frac{v(x_{n+1}) - v(x_n)}{\Delta x}\quad&n=1\\[2mm]
\displaystyle\frac{v(x_{n+1}) - v(x_{n-1})}{2\Delta x}\quad&1 < n <N\\[2mm]
\displaystyle\frac{v(x_n) - v(x_{n-1})}{\Delta x}\quad&n=N
\end{cases}
\end{align} or (case 2) \begin{align}
v'(x_n) \approx
\begin{cases}
\displaystyle\frac{v(x_{n+1}) - v(x_n)}{\Delta x}\quad&1\leq n <N\\[2mm]
\displaystyle\frac{v(x_n) - v(x_{n-1})}{\Delta x}\quad&n=N
\end{cases}
\end{align}
Note that in the second case $v'(x_{N-1})=v'(x_N)$. I was wondering what's common practice in the math profession. I'm asking because I get significant different results for the different cases (irrespective of $N$). PS: Note that I'm neither a mathematician nor a native english speaker. So I apologize for misunderstandigs.","['optimal-control', 'finite-differences', 'reference-request', 'numerical-methods', 'ordinary-differential-equations']"
1337808,base change of an equivalence relation of fppf sheaves,"Let $S$ be a scheme, $R,U$ be $S$-schemes and $s,t : R \to U \times_S U$ be an equivalence relation i.e. it's a monomorphisme such that for every $S$-scheme $T$, $R(T) \to U(T) \times U(T)$ is and equivalence relation in the usual sense. We denote by $Q$ the $fppf$ sheaf associated to the presheaf
$$T \mapsto U(T)/\sim_{R(T)}
$$ The arrow $\pi : U \to Q$ is the coequalizer, in the category of $fppf$ sheaves, of the maps $s,t : R \to U$ seen as maps of $fppf$ sheaves. Note that as such it is an epimorphism. Let $\pi : Q' \to Q$ be any morphism. We define $R' = R \times_Q Q'$ and $U' = U\times_Q Q'$. I want to show that $Q'$ is the coequalizer of the maps $(s',t') : R' \to U' \times_{R'} U'$. So what I want to show is that the formation of quotients of equivalence relations commutes with base change in the category of $fppf$ sheaves I know that $(s,t) : R \to U \times_Q R$ is an isomorphism of $fppf$ sheaves (it isn't absolutely obvious but it's not very hard to see). This implies very easily that $R' \cong U' \times_{Q'} U'$. So the question becomes to show it that $U' \to Q$ is the equalizer of $p_1,p_2 : U' \times_{Q'} U' \to U'$. My idea was to show that $U' \to Q$ is an epimorphism because I've already shown that this implies the result, but I haven't been able to show this. So another (and maybe clearer) question would be : in the category of $fppf$ sheaves, are epimorphisms stable by base change ? Let me remind you that a morphism $\alpha : F \to G$ of $fppf$ sheaves (on the category of $S$-schemes) is an epimorphism if for every $S$-scheme $T$ and for every section $s \in G(T)$ there exists and $fppf$ covering $\{T_i \to T\}_{i \in I}$ such that $s_{|T_i}$ is in the image of $F(T_i) \to G(T_i)$. It is certainly true in the category of sets that epimorphisms are stable by base change so I imagine the result would be true for epimorphisms of sheaves over any site. Anyway, if it is not the case, then how can one show that $Q'$ is the co-equalizer of $(s',t')$ ?","['algebraic-geometry', 'topos-theory', 'category-theory']"
1337814,Breaking probability measure into conditional probability measure and marginal probability measure.,"I would like to know under what conditions on $\rho$  - borel probability measure on $ X \times Y$ - the following statement holds true $$ \int_{X \times Y} \varphi(x,y) \, d\rho = \int_X \left( \int_Y \varphi(x,y) \, d\rho(y|x) \right )d\rho_X \, ,$$ where $X$ is a compact domain or manifold in Euclidian space, 
$Y = \mathbb{R} $, $ \varphi : X \times Y \rightarrow \mathbb{R}$ is an integrable function,  $\rho(y|x)$ denotes conditional probability measure w.r.t $x$ on $Y$ and $\rho_X$ marginal measure on $X$? While this equation is intuitively understandable for me I do not know what assumptions are necessary to made. I also have trouble how to formally define $\rho(y|x)$ in the setting above.",['measure-theory']
1337820,a Maximum of Discrete Function,"Define a set
$$X=\{(x_1,\ldots ,x_n)\mid x_i=\pm 1,1\leq i\leq n\}$$ Fix $a$, $b\in X$. Consider the discrete function
$$F(x_1,\ldots,x_n)=(x_1a_1+\cdots+x_na_n)^2+(x_1b_1+\cdots+x_nb_n)^2$$
$(x_1,\ldots,x_n)\in X$. I want to find when the function reaches the maximum. Is it at $x=a$? And how to prove it? Thank you.",['discrete-mathematics']
1337832,How to evaluate $\frac{2^{f(\tan x)}-2^{f(\sin x)}}{x^{2}f(\sin x)}$ as $x \to 0$?,"If $f(x+y)=f(x)+f(y)$ for all real values of $x,y$.
Given $f(1)=1$ How to evaluate $$\lim_{x \to 0} \frac{2^{f(\tan x)}-2^{f(\sin x)}}{x^{2}f(\sin x)}$$",['limits']
1337833,Definition of lebesgue integral with respect to measure $\mu$ [duplicate],"This question already has answers here : Lebesgue Integral of Non-Measurable Function (2 answers) Closed 9 years ago . In Rudin's Real and Complex Analysis, the Lebesgue integral is defined as: L et $(X,m,\mu)$ be a measure space, where $X$ is a set, $m$ is a $\sigma$ algebra on $X$ and $\mu$ is a measure.
Then, if $f:X \to [0,\infty]$ and $E \in m$, we define
$$\int_E f d\mu  = \sup \int_E s d\mu \tag{1}$$ where the supremum is taken over all simple functions $s, 0 \leq s \leq f$ I do not have much background in measure theory, and I am wondering why we assume $f$ to be measurable to define its integral. EVEN IF $f$ is not a measuarable function, the above definition (1) would still be well-defined. Why do we define integral only for measurable $f$?","['lebesgue-integral', 'measure-theory']"
1337834,An example of a module that is not injective,I know that since $\mathbb Z$ is a PID every free module is projective and conversely. Hence since $\mathbb Q$ is not free as a $\mathbb Z$ -module then it is not projective. But is $\mathbb Q$ an injective $\mathbb Z$ module? Does there exist some similar result like above to prove this fact? If not then what is an example of a module that is not injective?,"['abstract-algebra', 'injective-module', 'modules']"
1337835,"Almost sure convergence of $\max(X_1, X_2,\ldots,X_n)$.","$X_1, X_2,\ldots, X_n$ are independent with uniform distribution on $[0,a]$. Prove that $\max(X_1, X_2,\ldots,X_n) \rightarrow a$ almost surely. Ar first I look for the probability distribution i.e. $$F_\max(t)=P(\max(X_1, X_2,\ldots,X_n)<t)=P(X_1<t)^n=(F_{X_1}(t))^n=\left(\frac{t}{a}\right)^n.$$ So if $t<a$ it converges to $0$ and if $t\geq a$ it converges to $1$. How can I say that $\max(X_1, X_2,\ldots,X_n) \rightarrow a$ almost surely. Is there a better way to do it?","['probability-theory', 'convergence-divergence']"
1337839,Is my answer correct? Expected number of coin flips to get 5 consecutive heads,"I found this puzzle online. Before my question gets flagged or on hold, I know the question has already been answered here but since I tried to solve it on my own I want to check if it's correct or not. The puzzle is ""What is the expected Number of Coin Tosses to Get Five Consecutive Heads"". My answer is the following: Because a coin has two sides, one for tails and one for heads, let $p$ be the probability of getting heads. Then the probability of getting tails is $1-p$ . For obvious reasons I shall assume that the coin is fair, thus the probability of getting heads is $\dfrac{1}{2}$ and tails $\dfrac{1}{2}$ as well. Let $X_i$ be a random variable indicating the number of flips required to get heads, when $i-1$ was heads. What we are looking for is the number of tries for a single success, thus we shall assume the random variable $X_i$ is following the Geometric Distribution with Probability $P(X_i = x) = p (1-p)^{x-1}$ . The expected number of coin flips to get 5 consecutive heads is given by the expected average $E(X) = \dfrac{1}{p}$ . The probability of the random variable $X_i$ is $\dfrac{1}{2^{i}}$ since the coin is fair. Thus for $5$ consecutive heads $E(X) = E(X_1) + ... + E(X_5) = \sum_{i=1}^{5}E(X_i) = \sum_{i=1}^{5}2^i = 62$ So the expected number of coin flips to get $5$ consecutive heads is $62$ .","['puzzle', 'probability', 'statistics']"
1337876,proof that power set A union B doesnt equal powerset A union powerset union B,"Why is this equation: \begin{equation}
\mathbb{P}(A \cup B) = \mathbb{P}(A) \cup \mathbb{P}(B)
\end{equation} false with: $A = \{0\}$ and $B = \{1\}$? Are they not both $\{ \emptyset,0,1\}$?","['logic', 'discrete-mathematics']"
1337882,"$T: V \to \Bbb{R^2}$ by $T(f)=(f'(0),f(0))$.","Let V be the space of twice differentiable function on $\Bbb{R}$ such that $$f''-2f'+f=0.$$ Define $T: V \to \Bbb{R^2}$ by $$T(f)=(f'(0),f(0)).$$ The I could see that $T$ is one-one, but is $T$ onto? How can I prove/disprove it?","['linear-algebra', 'ordinary-differential-equations', 'linear-transformations']"
1337905,Is the ring of Laurent polynomials in $n$ noncommuting variables Noetherian?,"Suppose we have a Noetherian ring $R$. Is it true that the ring of Laurent polynomials $R\langle x_1,\,x_1^{-1},\ldots,\,x_n,\,x_n^{-1}\rangle$ in $n$ noncommuting variables is also Noetherian? If so, why?","['abstract-algebra', 'noetherian', 'ring-theory']"
1337910,Homeomorphisms of the Open Disk,"Does there exist a homeomorphism $\phi$ of the open unit disk in the plane such that $\phi$ has no fixed point but there exists $n$ such that the $n$-fold composition $\phi^n$ is the identity? (To save some of you the bother of asking what I've done so far: nothing. Seems clear the answer is no; it's also clear to me that I simply don't have the tools to try to answer a question like this. If it helps I can say how the question arises: If the answer is no, as I suspect, then any non-trivial covering map $f:\mathbb D\to X$ is infinitely sheeted - this would say that holomorphicity is irrelevant to something that came up yesterday.)","['algebraic-topology', 'general-topology']"
1337914,How do I prove this combinatorial identity using inclusion and exclusion principle?,"$$\binom{n}{m}-\binom{n}{m+1}+\binom{n}{m+2}-\cdots+(-1)^{n-m}\binom{n}{n}=\binom{n-1}{m-1}$$
Note that we can show this with out using inclusion and exclusion principle by using Pascal's Identity i.e. $C(n,k)=C(n-1,k)+C(n-1,k-1)$.","['discrete-mathematics', 'inclusion-exclusion', 'summation', 'combinatorics', 'binomial-coefficients']"
1337920,Computing the sheaf of 1-forms on a toric variety,"Consider projective space $P^{2}$ and its corresponding fan. We have the affine opens defined by $U_{\sigma_{0}} = Spec(\mathbb{C}[x,y])$, $U_{\sigma_{1}} = Spec(\mathbb{C}[x^{-1},x^{-1}y])$ and $U_{\sigma_{2}} = Spec(\mathbb{C}[xy^{-1},y^{-1}])$ cf (Example 3.1.9 Cox, Little, and Schenck). Given these affine opens, how would one compute the sheaves $\Omega^{1}_{\mathbb{P}^{2}}(U_{\sigma_{i}})$ and the transition functions on the intersections $U_{\sigma_{i}} \cap U_{\sigma_{j}}$? (cf Exercise 8.2.4 Cox, Little, and Schenck). I understand the construction via using the transformation of the differential forms with the Jacobian matrix, but I'm not sure how to work using the above approach. My main issue is that I'm not sure how to compute $\Omega^{1}_{\mathbb{P}^{2}}(U_{\sigma_{i}})$. Thanks","['differential-forms', 'algebraic-geometry', 'sheaf-theory', 'coherent-sheaves', 'toric-geometry']"
1337930,Is there an integral representation for $\frac{1}{n!}$?,"I know that $n!$ has various integral representations, for instance the $\Gamma$ function. I was wondering if $\frac{1}{n!}$ has an integral representation.","['factorial', 'special-functions', 'functions']"
1337951,Prove or disprove $\frac{\sqrt{1+\tan x}}{\cot x} = \frac{1+\sin x}{\cos x}$,"I have tried to prove the identity \begin{equation}
\frac{\sqrt{1+\tan x}}{\cot x} = \frac{1+\sin x}{\cos x}
\end{equation}
by $t$-substitution but seem not to work. Please don't solve(don`t post the answer on this site) this question for me just try it and give me hints on how I should go about it. Or if you like you can post but I wanted to try using some hints that you would give first.",['trigonometry']
1337968,Reconciling two different definitions of constructible sets,"This question is really about sets and topology, but it is motivated from commutative algebra, hence the tag. Setup: Let $X$ be a set and let $\{U_\lambda\}_{\lambda\in\Lambda}\subset 2^X$ be a family of subsets of $X$ ( $\Lambda$ is just an index set for the family) closed under finite intersection. Then the $U_\lambda$ 's form the base of a topology; call it $\mathscr{T}$ . Let $\mathscr{F}\subset 2^X$ be the smallest family of subsets of $X$ containing $\mathscr{T}$ and closed under finite intersection and complementation. Meanwhile, let $\mathscr{G}\subset 2^X$ be the coarsest topology in which every $U_\lambda$ is clopen. It seems to me, though I haven't written down the proof to my satisfaction yet, that if it happens that $(X,\mathscr{T})$ is a noetherian space, then $\mathscr{F}=\mathscr{G}$ . However, it seems to me that in general, without the noetherian hypothesis, they should not be equal and neither can be guaranteed to contain the other. E.g. it seems to me that $\mathscr{F}$ needn't be a topology, and that $\mathscr{G}$ needn't be closed under complementation. Also, in principle, while $\mathscr{F}$ clearly depends only on $\mathscr{T}$ , $\mathscr{G}$ might actually depend on the base $\{U_\lambda\}_{\lambda\in\Lambda}$ chosen for $\mathscr{T}$ . But my attempts to give examples of all this haven't been successful so far. So my questions are: Is it true that $\mathscr{F}$ needn't contain $\mathscr{G}$ ? If so, what's an example? If $\mathscr{F}$ must contain $\mathscr{G}$ , what's the proof? Same question with the roles of $\mathscr{G}$ and $\mathscr{F}$ reversed. Is it true that $\mathscr{G}$ may depend on the base $\{U_\lambda\}_{\lambda\in\Lambda}$ chosen for $\mathscr{T}$ ? If so, what's an example? If not, what's the proof that it is determined entirely by $\mathscr{T}$ ? Context: $\mathscr{F}$ and $\mathscr{G}$ are two different definitions of the constructible sets given in Atiyah-MacDonald. ( $\mathscr{F}$ is in exercises 20-23 of chapter 7; $\mathscr{G}$ is in exercises 27-30 of chapter 3.) It seems to me that in the case of the Zariski topology on the Spec of a noetherian ring, they will coincide, but not in general. I could be totally wrong; this is what I'm trying to probe here.","['examples-counterexamples', 'general-topology', 'commutative-algebra']"
1338011,"Does this product over the primes converge, and if so, to what?","I've been trying to play around with the product:
$$\prod_{p \text{ prime}}\frac{1}{1-(-p)^{-1.5}}$$
Where the product runs over all the prime numbers.
The product is similar in appearance to the famous Euler product for the zeta function, evaluated at $1.5$:
$$ \prod_{p \text{ prime}}\frac{1}{1-p^{-1.5}}=\zeta(1.5)$$ However, the sign of $p$ is switched, so instead of staying in the reals, as the zeta function does, this new product enters the complex numbers. I have tried approaching it in an interesting way, however my results seem to differ greatly from numerical data, so I would like to know where the issue is and if an answer is known. My work is very largely based off the derivation of Euler's product formula: We begin by defining:
$$\zeta_{\mathbb{Z}}(s)=\ldots+(-3)^{-s}+(-2)^{-s}+(-1)^{-s}+1^{-s}+2^{-s}+3^{-s}+\ldots$$
Now, if we multiply by $(-2)^{-s}$, we get:
$$ (-2)^{-s}\zeta_{\mathbb{Z}}(s)=\ldots+6^{-s}+4^{-s}+2^{-s}+(-2)^{-s}+(-4)^{-s}+(-6)^{-s}+\ldots$$
$$=  \ldots+(-6)^{-s}+(-4)^{-s}+(-2)^{-s}+2^{-s}+4^{-s}+6^{-s}+\ldots$$
And by subtracting, we get:
$$ \left( 1-(-2)^{-s} \right)\zeta_{\mathbb{Z}}(s)=\ldots+(-5)^{-s}+(-3)^{-s}+(-1)^{-s}+1^{-s}+3^{-s}+5^{-s}+\ldots$$
Similarly, by multiplying by $\left(1-(-p)^{-s} \right)$, we remove all the multiples of $p$, so by multiplying by $\left(1-(-p)^{-s} \right)$ for all prime numbers, we get rid of everything except for $(-1)^{-s}+1^{-s}$. Thus we have:
$$ \prod_{p \text{ prime}}\left( 1-(-p)^{-s} \right) \cdot \zeta_{\mathbb{Z}}(s)=(-1)^{-s}+1^{-s}=(-1)^{-s}+1$$
Thus, whenever $(-1)^{-s}+1$ is not equal to zero, we can say:
$$ \prod_{p \text{ prime}}\left(\frac{1}{ 1-(-p)^{-s} }\right)=\zeta_{\mathbb{Z}}(s)\cdot \frac{1}{(-1)^{-s}+1}$$ Now, on the other hand, by definition, we have:
$$ \zeta_{\mathbb{Z}}(s) = \sum_{n=1}^{\infty}{n^{-s}}+\sum_{n=1}^{\infty}{(-n)^{-s}} =\sum_{n=1}^{\infty}{n^{-s}}+(-1)^{-s}\sum_{n=1}^{\infty}{n^{-s}}$$
$$ =\left( 1+(-1)^{-s} \right)\sum_{n=1}^{\infty}{n^{-s}}=\left( 1+(-1)^{-s} \right)\zeta(s)$$ Therefore we have:
$$ \prod_{p \text{ prime}}\left(\frac{1}{ 1-(-p)^{-s} }\right)=\zeta_{\mathbb{Z}}(s)\cdot \frac{1}{(-1)^{-s}+1}= \left( 1+(-1)^{-s} \right)\zeta(s)\cdot \frac{1}{(-1)^{-s}+1}=\zeta(s)$$ By plugging in $s=1.5$, we get:
$$\prod_{p \text{ prime}}\left(\frac{1}{ 1-(-p)^{-1.5} }\right)=\zeta(1.5)$$ The reason I don't believe this result is because it is an entirely real number, and also WolframAlpha tells me that the product over the first $50,000$ primes is approximately $0.62+0.68i$. My question also extends to values of $s$ other than $1.5$. When $s$ is an even integer, the product formula is identical to the Euler product formula, so it is clear that the product is equal to the zeta function. When $s$ is an odd integer, my technique of analysis does not apply because $(-1)^{-s}+1$ does equal zero in this case, and in fact the product certainly is not equal to the zeta function. For example (according to WolframAlpha):
$$ \prod_{p \text{ prime}}\left(\frac{1}{ 1-(-p)^{-3} }\right) = \frac{\pi^6}{945 \zeta(3)}\neq \zeta(3) $$ My question is, what about all the non-integer values (for example $1.5$)? I cannot find an issue with my work, however much of it is informal and I have never actually taken a course in complex analysis (which I assume would help). None of this is any sort of homework; it is just a piece of curiousity. Any help is appreciated.","['number-theory', 'complex-analysis', 'riemann-zeta']"
1338025,Why does a differential form represent a vector field?,"I'm trying to learn the Divergence/Stoke's theorem and I can't wrap my head around the meaning of a differential form in this context. What does it mean that a differential form represents a vector field? What does it mean to derive a differential form? Why do we sometimes take an integral wherein of the inner product of a form and its derivative? What does it mean to integrate over a form? Lastly, sometimes in the context of a form I see dx ^ dy . What does the ^ mean? Can anyone give me some intuition about this? I've gone over my class notes and it all goes straight to formalities and I'm having trouble grasping these concepts. 
Any help would be welcomed!","['analysis', 'vector-spaces', 'calculus', 'differential-forms']"
1338044,Simplify $7\arctan^2\varphi+2\arctan^2\varphi^3-\arctan^2\varphi^5$,"Let $\varphi=\frac{1+\sqrt5}2$ (the golden ratio).
How can I simplify the following expression?
$$7\arctan^2\varphi+2\arctan^2\varphi^3-\arctan^2\varphi^5$$","['golden-ratio', 'trigonometry']"
1338059,Why are there palindromic subsequences at random among this sequence?,"So I was thinking about the Goldbach conjecture and I rephrased it to myself as the following: Prove that every number N is either prime or else lies halfway between two primes A and B, where A < N and N < B < 2N . This is equivalent, because if it were true, then the following would apply: For any even number X where X/2 is prime, you know X is expressible by the sum of two primes: X/2 + X/2. (e.g. for 10, 10/2 is 5 and 5+5=10) For any even number X where X/2 is NOT prime, you know X is expressible by the sum of two primes: A + B, where A and B are whichever two primes X/2 lies between. (e.g. for 12, 12/2 is 6 and 6 is halfway between 5 and 7, and 5+7=12) And thus the Goldbach Conjecture would be proven true, because all even numbers are proven to be expressible as the sum of two primes. So then I went and generated the first 400 values for N of the sequence where N is ""the shortest distance  from X to the nearest prime number both above and below it"" where X is the natural numbers 1, 2, 3, etc. If X is prime, N is 0. Example: 2 yields 0 because it is prime. 3 yields 0 because it is prime. 4 yields 1 because it is 1 away from both 3 and 5. 5 yields 0 because it is prime. 6 yields 1 because it is 1 away from both 5 and 7. .... 10 yields 3 because it is 3 away from  7 and 13. 11 yields 0 because it is prime. 12 yields 1 because it is 1 away from 11 and 13. So, the sequence starts off: 001 010 323 010 323 010. Already tantalizing, like everything with primes. But then, that segues into this: 23 010 32 9056349 010 9436509 23 010 32 A palindrome! (They're all single digit numbers, grouped to help make the palindromic nature more visually evident.) Further in you'll see: 10 9 0 1 0 15 4 3 18 7 0 9 8 3 12 5 0 15 2 15 0 5 12 3 8 9 0 7 18 3 4 15 0 1 0 9 10 Another palindrome. (This time with all numbers separate since some are two digits long. Also bolded the center of the palindrome.) These are just the ones I've spotted, I think there are others. And there are many others I've seen that are one value away from being palindromic. Is there any explanation for this? I'm trying to find a pattern here.","['prime-numbers', 'number-theory', 'palindrome']"
1338066,"""Complement"" of Kempner Series","It is a long time since I summed any series. I was aware that the harmonic series diverged, (if I recall you can keep making groups that are greater than a half). Then today I saw SMBC and it blew my mind. http://smbc-comics.com/index.php?id=3777 A quick google, and Wikipedia has an article on the Kempner series, although apparently it is normally nameless. https://en.wikipedia.org/wiki/Kempner_series This has an outline of the proof of convergence. My question is, isn't the ""Kempner"" series, which is the harmonic series excluding numbers with the digit 9 in the denominator (in base 10), bigger than the series of numbers it excludes? (Surely it can't be smaller?)
$$\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+\frac{1}{8}>  \frac{1}{9}$$ But if you add them together you get infinity? Can you explain why? Is it just infinity messing with my intuition? A proof of the convergence or divergence of the sequence of omissions would be awesome.",['sequences-and-series']
1338071,Is this a way to construct mathematics?(logic vs. set theory),"I recently asked a question about the fact that logic and set theory seems circular. link I got a lot of good and thoughtful answers, that probably explain everything, but I must admit I did not understand them all (not the fault of any of the people who answered). 
So I am wondering if someone can check the ""recipe"" I have below, and if this is a sufficient or ok way to view the construction of mathematics? Before creating mathematical logic we just have to know what some something means. We assume we know these things: 1.1 We know what a string is, and we know what symbols is. We also know what ordered sequences of symbols is, even though we have not formalized what it is. 1.2 We can talk about function symbols and relation symbols, and we know that there are rules when writing these things. But we have not yet made a formal definition of functions and symbols. 1.3 We know what the equality symbol is, and we create rules on how to use it in our logic language. But we do not have any more precise definition of what it is, other than a symbol, and our own intuitive meaning. 1.4 We have an idea about the natural numbers, and we are allowed to use these as symbols, even though we have not created them. 1.5 We can use the induction principle on proving things about our logical language. We assume that if something holds for ""the base""-object, and if something should hold for an arbitrary object then it also also for its ""successor"", then it must hold for all the objects starting with the base-object and all the successors. We just assume that this holds, and that we can use it? We then create the language of mathematical logic. We create set-theory: 3.1 Here we formalize ordered pairs in terms of sets. 3.2 We formalize what a function and a relation is in terms of sets (cartesian-product etc.). 3.3 We formalize equality as a particular relation. 3.4 We define and create the natural numbers in terms of sets. 3.5 We create an axiom of mathematical induction in terms of the natural numbers? In other words, we assume that induction holds, just as we did before we created the logical language? And hence we do not have any circularity in using set theory before it was created? Is this a correct way to view the construction of mathematics? If it is wrong I would love answers, but I would very much love answers in a list form, where it is explicitly stated what we do from the start and where we end up etc..","['foundations', 'elementary-set-theory', 'logic']"
1338087,Is Keno a fair game?,"This is a very interesting word problem that I came across in an old textbook of mine. So I know its got something to do with probability, which perhaps yields the shortest, simplest proofs, but other than that, the textbook gave no hints really and I'm really not sure about how to approach it. Any guidance hints or help would be truly greatly appreciated. Thanks in advance :) So anyway, here the problem goes: In the game of Keno, from the numbers $1-80$ , a player chooses three, and makes a $\$1$ bet. Then twenty numbers are drawn. If all three of his numbers are among the twenty, he is paid $\$42$ (gain of $\$41$ ). If two of his numbers are among the twenty, he is paid $\$1$ (break even). If fewer than two of his numbers are among the twenty, he loses. What are his chances ? How can this be made a fair game ? My thoughts: A player's entry can be any of $C(80,3)$ combinations $= 82160$ From the the $20$ numbers there are $C(20,3)$ winning combinations $= 1140$ $\frac{1140}{82160} = .0138753 =$ Probability of having three winning numbers. But now I am stuck.","['probability-theory', 'probability', 'gambling', 'soft-question']"
1338097,Expected number of times Random Walk crosses 0 line.,"Suppose we have a simple random walk: $$
x_t = x_{t-1} + \epsilon_{t}
$$ Where $$
\epsilon_{t} =  iid\  \mathcal{N} (0,1)
$$ Assume that x starts at 0 what is the expected number of times x will cross the 0 point for N number of periods? I am more interested in the method of obtaining the answer than the answer  itself. What I have so far: I was looking at simple case where N = 2, and in this case expected number of crosses seems to be 0.25 . Intuitively, this makes sense, in the first period we moved somewhere, and on the second the probability that we move in the right direction is 0.5, and of that 0.5, the probability (on average) that we move back far enough to cross is 0.5, so 0.5 * 0.5 => 0.25. I validated this with simulation: import numpy as np

def simulations(n, n_iterations):
    return sum(my_one_run(n) for _ in xrange(n_iterations)) / float(n_iterations)

def my_one_run(n):
    path = [0]
    n_crosses = 0
    for i in xrange(n):
        prev = path[-1]
        new_x = prev + np.random.normal(0,1)
        path.append(new_x)
        if prev * new_x < 0:
            n_crosses += 1
    return n_crosses And my results have been confirmed: In [66]: simulations(2, 1000000)
Out[66]: 0.250249 However, I don't see how to proceed for a more complicated case, even more general case. (This is not a homework question, if this matters. I am just trying to explore something in this area and wanted to start with a basic case.).","['probability', 'random-walk']"
1338125,Substituting a value of sine function in a trigonometric equation,"I am trying to really understand trigonometric equations and I've stumbled upon a rather confusing example. Solve the following equation: $\sin x= 2|\sin x|+ {\sqrt{3}}\cos x$ First step is to define the absolute $\sin x$:
$$|\sin x| = 
\begin{cases}
\sin x & \sin x \in [0, 1]\\
-\sin x & \sin x \in [-1, 0)
\end{cases}
$$ Let's see what happens in the first case: $$\sin x \in [0,1] \Rightarrow\, x \in {[2k{\pi}, (2k+1){\pi}]}$$ which means x is in the first or second quadrant. Bringing everything to the right side: $$\sin x+{\sqrt{3}}\cos x=0$$ Now we notice terms ${\sqrt{3}}$ with $\cos x$ and $1$ with $\sin x$ and do the following: \begin{align*}
\sin x+{\sqrt{3}}\cos x& =0 \quad /:2\\ 
\frac{1}{2}\sin x+{\frac{\sqrt{3}}{2}}\cos x& = 0
\end{align*} Now, the goal is to try and substitute integer terms with trigonometric functions they are solutions to, in order to apply one of the trigonometric identities for solving the problem. Let's aim at the following formula: $\sin(x+y)=\sin x\cos y + \sin y\cos x$ .We have several options: $\frac {1}{2} $is value of $\cos$ for either $x=\frac {\pi}{3} + 2k\pi$ OR $x=\frac {5\pi}{3} + 2k\pi$. Of all of these angles, only $x=\frac {\pi}{3} $ falls under our domain. ${\frac {\sqrt{3}}{2}} $is value of $\sin$ for either $x=\frac {\pi}{3} + 2k\pi$ OR $x=\frac {2\pi}{3} + 2k\pi$. Out of all of these angles, there are two of them that fall under our domain. $x=\frac {\pi}{3}$ and $x=\frac {2\pi}{3}$. This is where the problem is. I feel I should consider both of the $\sin$ values and solve two different versions of the equation. The first one is by substituting $\frac {1}{2} = \cos\frac {\pi}{3}$ and $\frac {\sqrt{3}}{2} = \sin\frac {\pi}{3}$, which is easily solved using the identity mentioned above. The second case is when substituting $\frac {\sqrt{3}}{2} = \sin\frac {2\pi}{3}$. This does not conform to any trig. identity. I tried treating $\sin\frac {2\pi}{3}$ as $\sin$ of double angle, but ended up at the beginning. I typed this equation into Symbolab and examined their step-by-step solution. It turns out that at some point they divided the equation with $\cos x$. Even when $\cos x$ is definitely not zero, I was taught dividing a trigonometric equation with anyting other than integers was a risky move very likely to result in a loss of solutions. So, my questions are: Should you just ignore possible angles that won't make you a simple trigonometric identity? Can you divide trigonometric equation with some trigonometric function and when? I hope I explained myself clearly enough. Thank you in advance.",['trigonometry']
1338133,"Double integral problem $\iint e^{\frac{x}{x+y}}\,dx\,dy$","I'm trying to integrate $$\iint e^{\frac{x}{x+y}}\,dx\,dy$$ where $y \leq (1-x)$ and $0 \leq x,y \leq 1$ . I tried to define new variables as $u=x$ and $v=x+y$ , but I can't solve this either. I have notice $\int e^{\frac{1}{x}}dx$ is not elementary function. so it really confuses me..","['multiple-integral', 'multivariable-calculus', 'integration']"
1338147,Solve infinite series equation with logarithmic terms.,Solve logarithmic equation: $$\frac{\log x^2}{\log^{2}x}+\frac{\log x^3}{\log^{3}x}+\cdots+\frac{\log x^k}{\log^{k}x}+\cdots=8$$ here $\log$ is assumed to have base $10$. So far I managed to rewrite it as: $$\sum_{n=2}^{\infty} \frac{n}{\log^{n-1}{x}}=8 \iff \sum_{n=2}^{\infty} n\log_{x}^{n-1}{10}=8$$ But I don't know how to find the infinite sum.,"['summation', 'sequences-and-series']"
1338148,Generalized linear combination of probability density functions,"I am working with linear non-unity combinations of independent variables in the equation form of:
$$Y_i=\sum_{j=1}^N a_{ij} X_j ~~~~\forall~ a_{ij} \in \mathbb{R}, a_{ij}\neq 1$$
I am aware of the convolution solution for the simplified unity case:
$$Y=X_1+X_2 \rightarrow f_Y(z)=\int_{-\infty}^{\infty}f_{X_1}(x)f_{X_2}(z-x)dx$$
Since convolution is a linear operation, I could conceivably extend this solution to any number of unity weights. My question is this, how do I handle the non-unity weighting factors? I have some sample plots showing how the solution obviously shifts. I'm using a normal distribution and an f-distribution. Below is the equation example showing the non-unity weighting factor. $$Y=5\cdot f(x,dfn=5,dfd=18)+1\cdot \mathrm{norm}(x,\mu=0,\sigma=0.1)$$ For the record, I don't want a specific case solution (as in, don't solve the above). I am content with sets of integrals and related, since I know that there cannot be a single analytic form. Thanks a lot for the help, and if I missed something on here that deals with the non-unity weights, please let me know. I have found several on unity weights, but those don't seem to help. By the way, this is my first question, LOL. :)","['statistics', 'calculus']"
1338151,A sequence of positive finite measures has a positive measure in the weak limit.,"I think the statement in the header is true, but I haven't been able to find a proof for it. Consider the measurable space $(\mathbb{R},\mathcal{B})$, i.e. the real number line with the Borel $\sigma$-algebra. Let $(\nu_n)_n$ be a sequence of positive finite measures on $(\mathbb{R},\mathcal{B})$, having the weak limit $\nu$. In symbols \begin{align}
\lim_{n \rightarrow\infty}\bigg|\int_\mathbb{R} f(y) (\nu_n - \nu)(dy) \bigg| = 0
\end{align} for each bounded continuous function $f$. I want to prove that $\nu$ is a positive measure (yes, I have assumed that $\nu$ is in fact a measure. Is this true?), namely that \begin{align}
\nu(B) \geq 0
\end{align} for each $B \in \mathcal{B}$. Solution idea: Aiming for a contrdiction, assume that there is a Borel set $B$ such that $\nu(B) < 0$. Find a continuous function $f_K$ with $B$ in its support such that $f_K = K$ in $B$ and $f_K = 0$ except on $\mathcal{N}_B$, some neighbourhood of $B$. Then use the definition to show that for each $\epsilon > 0$ one can find $K$ such that \begin{align}
\lim_{n \rightarrow\infty}\bigg|\int_\mathbb{R} f_K(y) (\nu_n - \nu)(dy) \bigg| = \lim_{n \rightarrow\infty}\bigg|\int_{\mathcal{N}_B} f_K(y) (\nu_n - \nu)(dy) \bigg| \geq \epsilon.
\end{align} This would contradict the weak convergence, and hence settling the statement. Problems I need $f_K$ to go to zero ''fast enough'' outside $B$, while still being continuous. It seems difficult to show explicitly that the above inequality holds.","['weak-convergence', 'measure-theory']"
1338152,A function on a space of symplectic forms,"Let $M$ be a smooth manifold and $\text{symp}(M)$ be the set of all symplectic forms on $M$.
Let $\text{Diff}_{ 0}(M)$ be a connected component of difeomorphisms of $M$.
Then, is there an explicit function (or a invariant) on $\frac{\text{symp}(M)}{\text{Diff}_{\ 0}(M)}$ which is not determined by a second cohomology class represented by a symplectic form $\omega$? I want to know the difference between $\frac{\text{symp}(M)}{\text{Diff}_{\ 0}(M)}$ and the space of classes represented by symplectic forms.","['differential-geometry', 'symplectic-geometry']"
1338175,Second Mean Value Theorem for Integrals Meaning,"The Second Mean Value Theorem for Integrals says that for $f (x)$ and $g(x)$ continuous on $[a, b]$  and $g(x)\ge 0$
$$\int_a^bf(x)g(x)\,dx=f(a)\int_a^cg(x)\,dx+f(b)\int_c^bg(x)\,dx$$ I have a difficult time understanding what this means, as opposed to the first mean value theorem for integrals, which is easy to conceptualize. Is there a graphical or 'in words' interpretation of this theorem that I may use to understand it better?",['calculus']
1338200,Shortest abstract algebra book,"I'm familiar with rigorous linear algebra, and I've had a very elementary course on modern algebra. I'm not interested in algebra but I need to learn more about it. Hence I'm looking for a concise and self-contained book on abstract algebra which covers what is needed for applications in the parts of mathematics relevant to physics, esp. differential geometry (incl. Lie theory and de Rham cohomology) and operator algebras. I'm not sure what topics exactly the book needs to cover, but probably someone here does. I'm also not sure if such a book exists: perhaps these areas are too broad. It doesn't have to literally be a book: it could be a chapter or appendix in another book, or lecture notes, but it should include nontrivial proofs. It would be best if the book assumes a knowledge of linear algebra so that the general linear group, etc. can be used as examples. To clarify: of course I'll have to look up specialized topics in one of the encyclopedic books, but I'm trying to find something that quickly covers the basics.","['abstract-algebra', 'reference-request', 'book-recommendation']"
1338210,How many ways to add to 32?,"I have been presented with a rather complex combination problem. Using only the numbers 2, 4, 6 and 8, how many possible ways can you add up to 32 if the number 4 may only be used no more than once in any solution? Also including solutions that do not use the number 4, I can find 29 unique solutions when the order doesn't matter. Solution 1:     8   8   8   8 Solution 2:     8   8   8   4   2   2 Solution 3:     8   8   8   2   2   2   2 Solution 4:     8   8   6   6   4 Solution 5:     8   8   6   6   2   2 Solution 6:     8   8   6   4   2   2   2 Solution 7:     8   8   6   2   2   2   2   2 Solution 8:     8   8   4   2   2   2   2   2   2 Solution 9:     8   8   2   2   2   2   2   2   2   2 Solution 10:    8   6   6   6   6 Solution 11:    8   6   6   6   4   2 Solution 12:    8   6   6   6   2   2   2 Solution 13:    8   6   6   4   2   2   2   2 Solution 14:    8   6   6   2   2   2   2   2   2 Solution 15:    8   6   4   2   2   2   2   2   2   2 Solution 16:    8   6   2   2   2   2   2   2   2   2   2 Solution 17:    8   4   2   2   2   2   2   2   2   2   2   2 Solution 18:    8   2   2   2   2   2   2   2   2   2   2   2   2 Solution 19:    6   6   6   6   6   2 Solution 20:    6   6   6   6   4   2   2 Solution 21:    6   6   6   6   2   2   2   2 Solution 22:    6   6   6   4   2   2   2   2   2 Solution 23:    6   6   6   2   2   2   2   2   2   2 Solution 24:    6   6   4   2   2   2   2   2   2   2   2 Solution 25:    6   6   2   2   2   2   2   2   2   2   2   2 Solution 26:    6   4   2   2   2   2   2   2   2   2   2   2   2 Solution 27:    6   2   2   2   2   2   2   2   2   2   2   2   2   2 Solution 28:    4   2   2   2   2   2   2   2   2   2   2   2   2   2   2 Solution 29:    2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2 That in itself was rather challenging, but there are additional restrictions: A. Order DOES matter. That is to say, something like [8,8,6,6,4] is indeed considered a different solution than [8,8,6,4,6]. B. Any solution that does use the number 4, must BEGIN with the number 4. If I treat any elements that have the same value as other elements within a given solution as unique, I can take n ! where n is the number of elements within each solution. Naturally, for those solutions that contain the number 4, I use ( n -1)! instead. That provides me with a whopping 21,104,423,119,848 solutions. Taking repeating elements as non unique, using n!/(n1! x n2! x n3! x ... x nk!) for all solutions that don't contain the number 4, and the same but using (n-1)! in the numerator for solutions that do contain the number 4, I find a greatly reduced 1,577 solutions. Now here's the part I'm struggling with. C. There are two unique ways to include the value 2 in a solution. D. There are four unique ways to include the value 8 in a solution. E. There are five unique ways to include the value 6 in a solution. That is to say there are different ""versions"" of each value. F. No versions of 6 or 8 may be repeated within any single solution For clarity, assume we have [8,8]. There are 4 ""versions"" of 8 that may be used, but not repeated within a solution. [8a,8a] for instance is not valid. This could be [8a,8b] or [8a,8c] or [8a,8d] or [8b,8a] or [8b,8c] etc. Assume you had [2,2]. Because you CAN repeat ""versions"" of 2, you could use [2a,2b] or [2b,2a] or [2a,2a] or [2b,2b]. There you have it. Following all of the restrictions, how many different ways can you add up to 32?","['combinations', 'combinatorics', 'permutations']"
1338257,An effective way of finding the order of the zero $z=0$ of $e^{\sin z}-e^{\tan z}$,"An effective way of finding the order of the zero $z=0$ of $f(z)=e^{\sin z}-e^{\tan z}$? What I tried is developing both exponentials by their Taylor series around $z=\sin z$ and $z=\cos z$, getting eventually $$f(z)=\sin z [(1+\frac{\sin^2}{2!}+..)-(\frac {1}{\cos z}+\frac {\sin z}{\cos^2 z}+...)]$$ By developing again $\sin z$ I can extract $z$, but I still have a function which is $0$ at $z=0$. The order should be 3. Any hints on how to continue will be very appreciated!","['complex-analysis', 'derivatives']"
1338264,"Proving $1-\cos(k)\geq\frac{2}{\pi^{2}}k^{2}$ for $k\in(-\pi,\pi)$","I am trying to prove the following: $$1-\cos(k)\geq\frac{2}{\pi^{2}}k^{2}\quad\hbox{for}\quad k\in(-\pi,\pi]$$ So far, I have tried using some Maclaurin expansion arguments, but when that didn't work out (I couldn't figure out how to get the $\pi^{2}$ involved), I tried some calculus arguments.  Specifically, I set up a function as the difference of the left and right sides and tried to show that it's global min was 0, following the process of proofs I have done for bounds on sine, to no avail. Any help would be greatly appreciated!","['inequality', 'trigonometry']"
1338278,Homotopy equivalence of $S^{2} \vee S^1$ to $S^{2} \cup A$ where A is a line segment joining noth and south poles,I have some problems trying to show homotopy equivalence of $S^{2} \vee S^1$(one-point union) to $S^{2} \cup A$ where $A$ is a line segment joining north and south poles of a sphere. I understand the general flow of the argument but can't actually construct the maps between the two spaces. This question can be found in Bredon's Topology and Geometry Book Chapter 14 Exercise 1 Thanks!,"['homotopy-theory', 'general-topology']"
1338286,Isometry between $X^\ast/M^\perp$ and $M^\ast$.,"Let $X$ be a normed linear space, $M \subset X$ be a subspace, $M^\perp = \{x^\ast \in X^\ast \mid x^\ast\big|_M = 0\}$ be the annihilator of $M$, $X^\ast$ the topological dual of $X$, and let's define $\Phi: X^\ast/M^\perp \to M^*$ by $\Phi(x^\ast+M^\perp) = x^\ast\big|_M$. I have already proved that $M^\perp$ is closed, and that $\Phi$ is well-defined, linear, and surjective. I finally want to prove that $\Phi$ is an isometry. On one hand, we take $y^\ast \in M^\perp$ and now: $$\begin{align} \|\Phi(x^\ast+M^\perp)\| &= \|x^\ast\big|_M\| = \|x^\ast\big|_M+y^\ast\big|_M\|  \\  &=\|(x^\ast+y^\ast)\big|_M\| \leq \|x^\ast+y^\ast\|,\end{align}$$and taking the infimum on $y^\ast$ gives $\|\Phi(x^\ast+M^\perp)\| \leq \|x^\ast+M^\perp\|$. I'm having trouble on the other inequality. One first attempt was to fix $m \in M$, take any $y^\ast \in M^\perp$ and do: $$\|(x^\ast+y^\ast)(m)\| \leq \|x^\ast(m)\|+\|y^\ast(m)\| = \|x^\ast(m)\| \leq \|x^\ast\big|_M\|\|m\|,$$and this gives $\|x^\ast\big|_M  + y^\ast\big|_M\| \leq \|x^\ast\big|_M\|$ instead of the $\|x^\ast  + y^\ast\|\leq \|x^\ast\big|_M\|$ that I wanted. Can someone help?","['isometry', 'linear-algebra', 'functional-analysis', 'analysis', 'quotient-spaces']"
1338306,Evaluate $\lim\limits_{\alpha \to \infty} e^{-t\sqrt{\alpha}}(1-\frac{t}{\sqrt{\alpha}})^{-\alpha}$ [duplicate],"This question already has an answer here : Proof for $e^z = \lim \limits_{x \rightarrow \infty} \left( 1 + \frac{z}{x} \right)^x$ (1 answer) Closed 6 years ago . How does one show $$\lim_{\alpha \to \infty} e^{-t\sqrt{\alpha}}\left(1-\frac{t}{\sqrt{\alpha}}\right)^{-\alpha} = e^{t^2 / 2}?$$ Not homework, this is from this proof that the gamma distribution has a limiting distribution of the standard normal as $\alpha \to \infty$. It suggests using numerical techniques to find the limit of the above, but I would like to know if there is a good way to solve this manually. I tried L'Hopital's rule but got $e^t$, which is obviously incorrect.","['calculus', 'limits', 'gamma-distribution', 'probability', 'moment-generating-functions']"
1338356,a Maximum of Discrete Function 2,"I have asked a question about a maximum of discrete function yesterday at a Maximum of Discrete Function . I want to generalize the question. Let $X=\{(x_1,\ldots ,x_n)\mid x_i=\pm 1,1\leq i\leq n\}$. Fix $\vec{a}_1,\cdots,\vec{a}_m\in X$. Consider the discrete function
$$F(\vec{x})=\sum_{i=1}^{m}(\vec{x}^T\vec{a}_i)^2,~~~~~~~\vec{x}\in X$$ I want to find when the function reaches the maximum. Is it at $\vec{x}=\vec{a}_i$, for some $i$? And how to prove it? Thank you.",['discrete-mathematics']
1338403,"When I prove two topologies are same, is it sufficient to prove they have same basis? If so,Why?","$(X, \mathcal{T}_X), (Y,\mathcal{T}_Y)$ be topological space, and let
  $A, B$ be subset of $X,Y$ respectively. Now, $(X \times Y, \mathcal{T}_{X \times Y})$ be product topology. $A
 \times B \subset X \times Y$. Consider subspace topology
  $\mathcal{T}_1$ on $A \times B$ Also, $(A, \mathcal{T}_A), (B, \mathcal{T}_B)$ where $\mathcal{T}_A$
  and $\mathcal{T}_B$ are subspace topologies on $A, B$
  respectively,consider product topology $\mathcal{T}_2$ on $A \times B$ Prove $\mathcal{T}_1 = \mathcal{T}_2$ My idea is to show that the bases of $\mathcal{T}_1$ and $\mathcal{T}_2$ are same.
where $\mathcal{T}_1$ basis is {$(A \times B) \cap (U \times V)  | (U \times V) \in \mathcal{T}_{X \times Y}$} and $\mathcal{T}_2$ basis is {$U_0 \times V_0 | U_0 \in \mathcal{T}_A,  V_0 \in \mathcal{T}_B$}. I know how to show these two bases are equal. However, I don't if this is sufficient to prove two topologies are equal.",['general-topology']
1338405,Equivalent Definitions of Prime Subfield,"I found two definitions for a prime subfield $K$ of a field $F$. 1. Wolfram $-$ $K$ is the subfield of $F$ generated by the multiplicative identity $1$ of $F$. 2. ProofWiki $-$ $K$ is the intersection of all the subfields, say $\{ K_c \}$, of $F$. I am aware that in the first definition, $\langle 1 \rangle = \{ n \cdot 1 : n \in \mathbb Z \}$.  Since $1$ is in each $K_c$, $\langle 1 \rangle \subset K$.  But, how are they equal?  I tried two approaches and they ran into the same problem. One, prove directly that $K \subset \langle 1 \rangle$.  But how do I know each $x \in K$ is of the form $1 + 1 ... +1$?  Another approach is to show that $\langle 1 \rangle$ is a subfield of $F$, ie an element in $\{ K_c \}$.  But how do I show that the inverse, $x^{-1}$, of each $x \in \langle 1 \rangle$ is also of the form $1 + 1 ... +1$?","['abstract-algebra', 'field-theory']"
1338409,Concrete example of vector field along a map,"In this book the definition of a vector field along a map $f: M \to N$ is given as follows: I am currently trying to understand this definition. For this purpose I wanted to work out a concrete example. But I need some help. Here is the example: Let $f: \mathbb R^2 \to \mathbb R^3$ be define by $f(t,s) = (t^2 + 2s, t^3 + 3ts, t^4 + 4t^2 s)$. To find a vector field along it I first calculated the derivatives $f_t$ and $f_s$ and then noticed that $$ f_t = t f_s + s (0,3,8t)$$ I then let $v_1 (t,s) := f_s$ and $v_2(t,s) := (0,3,8t)$. And then I wanted to check if $\pi_{T\mathbb R^2} \circ v_i = f$ but this is where I am stuck at the moment. I believe that $\pi_{T\mathbb R^2} \circ v_1 = v_1 (t,s)$ and $\pi_{T\mathbb R^2} \circ
 v_2 = v_2( t,s)$. But by how we defined these vectors we would then have $$ \pi_{T\mathbb R^2} \circ v_1 = v_1 (t,s) = f_s$$ when we want to have $$ \pi_{T\mathbb R^2} \circ v_1  = f$$ Is $v_1$ really not a vector field along $f$ or am I missing
  something?",['differential-geometry']
1338411,Why doesn't using the approximation $\sin x\approx x$ near $0$ work for computing this limit?,"The limit is
$$\lim_{x\to0}\left(\frac{1}{\sin^2x}-\frac{1}{x^2}\right)$$
which I'm aware can be rearranged to obtain the indeterminate $\dfrac{0}{0}$, but in an attempt to avoid L'Hopital's rule (just for fun) I tried using the fact that $\sin x\approx x$ near $x=0$. However, the actual limit is $\dfrac{1}{3}$, not $0$. In this similar limit , the approximation reasoning works out.","['calculus', 'limits', 'limits-without-lhopital', 'indeterminate-forms', 'trigonometry']"
1338428,Help with proof that that affine plane curves in $\mathbb{C}^2$ are not compact,"This is a problem from Kirwan's Complex Algebraic Curves that I'm stuck on. She gives a hint suggesting that for $C = \{(x,y)\in\mathbb{C}^2: P(x,y) = 0\}$, show that at all but finitely many points $a\in\mathbb{C}$ there is a $b$ such that that $P(a,b) = 0$. I know appealing to the Heine-Borel theorem finishes the argument if I can show the hint. It's also pretty obvious that if $g(y) = P(a,y)$ is non-constant, then we can factorize $g$ by the Fundamental Theorem of Algebra and let $b$ be one of the roots to conclude. I don't understand why we can do this at all but finitely many $a$ though. It seems like having $g(y) = k_a$ where $k_a\in\mathbb{C}$ for infinitely many $a\in \mathbb{C}$ should give some kind of contradiction. It would be easy if it were the same constant $k_a$ every time, since we could factorize $g(y) - k_a$ as a polynomial of $a$ to show that the number of $a$'s where this occurs is bounded by the polynomial degree. But $k_a$ should vary with $a$, right? Do I need to appeal to some kind of complex-analytic argument? I might just be missing something obvious. Any help explaining this would be appreciated!","['abstract-algebra', 'complex-analysis', 'algebraic-curves']"
1338437,Space Geometry: lines in a plane,"If $d$ and $d'$ are two intersecting lines in a plane $P$, and $D$ is a line orthogonal to both $d$ and $d'$, then any line $\delta$ in $P$ is orthogonal to $D$ as well. How could this be proven using only the tools of Euclidean geometry? I tried to do that by contradiction, but this seems to be an unfruitful approach. Thank you.","['euclidean-geometry', 'geometry']"
1338452,Complex Inequalities,"Let $\mathbb{H}=\{z\in \mathbb{C} | \ \Im(z)>0\}$ and $f:\mathbb{H} \to \mathbb{H}$ analytic. Prove that for every $z_1, z_2 \in \mathbb{H}$, it must happen that 
$$
\frac{|f(z_1)-f(z_2)|}{|f(z_1)-\overline{f(z_2)}|} \leq \frac{|z_1-z_2|}{|z_1-\overline{z_2}|}
$$ What I tried to do is fix a $z_2 \in \mathbb{H}$ and use the function 
$$
g(z)=\frac{f(z)-f(z_2)}{f(z)-\overline{f(z_2)}}
$$
Clearly $|g(z)|=1$ but I dont see whats the next step to do. Since this exercise appears in Ahlfors Complex Analysis after proving Schwarzs lemma, I think we must use it, but it dont seems to apply for $g$, perhaps involving a Mbius map  can help? Please any help will be strongly appreciated.","['mobius-transformation', 'complex-analysis', 'inequality']"
1338493,Uses of stalks of sheaves and germs,"I am trying to understand the motivation behind defining stalks of sheaves, but I suppose my complex geometry is a little weak. I know they are meant to represent germs of holomorphic functions at a point, but generalized to any sheaf. Here is what I have in mind currently: holomorphic functions are complex differentiable locally, so it doesn't make sense to talk about holomorphic functions at a point $z \in \mathbb{C}$. However, we can talk about the germs of holomorphic functions at $z$ (so identify all those functions that agree on some arbitrarily small neighborhood of $z$). In this way, it seems we can try to talk about complex functions ""holomorphic at a point"" by just using direct limits. So my question is, why do we use germs/stalks at all? How can they reveal (geometric/local) structure that cannot be deduced by simply looking at small neighborhoods (which is what I think of when I think local). Are there any theorems that become easy to prove using germs (or maybe almost impossible/unclear without using germs)? Also, why do we want morphisms of sheaves to induce maps on the stalks? Is this just a convenient bookkeeping mechanism, or is there some genuine geometric meaning to it all?","['intuition', 'algebraic-geometry', 'soft-question', 'complex-geometry']"
1338507,Computation of a certain integral,"Assume that $\alpha>0, t \in R$. Compute the integral $\int_0^1(-1)^xx^{-\alpha-it}dx.$",['complex-analysis']
1338524,Some possible mistakes in Bott and Tu [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 5 years ago . Improve this question I've been reading Bott and Tu's book ""Differential Forms in Algebraic Topology"" and it seems that this book has an enormous list of errors. Therefore I would like to confirm if the parts that I will cite are, in fact, wrong and, if I'm correct, I would like to know how to solve these problem. Here is a link to the edition of the book that I'm using http://www.maths.ed.ac.uk/~aar/papers/botttu.pdf . 1) In page 43 (proof of theorem 5.1), they claim that finite intersections of geodesically convex open sets are geodesically convex. However choosing two open sets covering the circle, would give a counterexample to this. Maybe the correct notion of good cover (in page 42), should be a covering such that finite intersections are diffeomorphic to finite disjoint copies of $\mathbb{R}^n$ . (As noted by Kevin Carlson and Mariano Surez-Alvarez the geodesics must be minimizing, therefore I was wrong) 2) In page 65, they define a sequence of vector bundles to be exact if they're fiberwise exact. This is not the correct definition, since the kernel of a morphism that collapse some fiber will be $0$ . 3) In page 69, there is a diagramm and they claim it's commutative, but there's no reason at all. And just above the diagram they say: ""If $f: M \rightarrow M'$ is an orientation preserving map of oriented manifolds, $T$ is a tubular neighborhood of the closed oriented sub manifold $S$ in $M$ , and $f(M')$ is transversal to $S$ and $T$ , then $f^{-1}T$ is a tubular neighborhood of $f^{-1}S$ in $M$ ."". However $T$ has always codimension $0$ , so how can $f(M')$ not be transversal to $T$ , clearly, there's something wrong going on here. Furthermore there is no reason (beyond the intuition) to $f^{-1}T$ be a tubular neighborhood of $f^{-1}S$ . So this part, clearly, needs some clarifications. 4) In page 70, execise 6.32 may not be right for any deformation retract, since the composition $(ir)^* \in \text{End}(\Omega(\mathbb{R}^n\setminus  \{0 \}))$ (for some retraction $r$ and an inclusion $i$ ) is not the identity. Therefore $dr\wedge r^{*}(d\theta|_{S^2})$ may not be positive, for instance. 5) In page 79  (just before the beginning of the section 7), they claim that $s\pi: E_0 \rightarrow E$ is clearly homotopic to the inclusion $i: E_0 \rightarrow E$ , where $E_0$ is the complement of the zero section, $s$ is the zero section and $\pi: E \rightarrow M$ is the vector bundle. This looks like very weird. For instance, consider $M = *$ (a point), then they are claiming that the map $\mathbb{R}^n \setminus \{0\} \rightarrow \{0 \}$ is homotopic to the inclusion $i: \mathbb{R}^n \setminus \{0 \} \rightarrow \mathbb{R}^n$ , so the sphere would be homotopic to a point! (As noted by Kevin Carlson, in fact, this is equivalent to the contractibility of $\mathbb{R}^n$ , therefore I was wrong. I don't know why, but I was thinking about isotopies fixing the circle) 6) In page 102 and 103, they claim that the collating formula (page 102) is a morphism $f: C(\mathcal{U}, \Omega) \rightarrow \Omega(M)$ that induces an isomorphism in level of cohomology by using a a homotopy operator (in the beginning go the page 103). However the collating formula is not well defined since in the second sum $\sum_{i=0}^{n+1}K(-D''K)^{i-1} \beta_i$ the term $K(-D''K)^{-1}$ is not well defined. I tried to exclude this term, but then everything goes wrong (for instance, the first computations in page 104 does not hold). 7) In page 104 (proposition 9.8), they claim to have created an explicit isomorphism between \v{C}ech cohomology and de Rham cohomology $f(\eta) = (-D''K)^n \eta$ by using the collating formula. However as stated above (in 6), the collating formula is ill defined, so this explicit isomorphism may not be true. However, in page 120-122, they use this isomorphism to prove that the Euler class and the global angular form coincides with their previous definition. So, again, this may not be right, since the collating formula was ill defined. 8)In page 108 (example 9.14), they claim that for $M = \mathbb{Z}^{+}$ and $F = \mathbb{Z}^{+}$ the Kunneth formula does not hold by claiming that $H^{0}(M) \otimes H^{0}(F)$ consist of finite sums of integer matrices of rank one. However $H^{0}$ is contravariant, so $H^{0}(F) = H^{0} (M) = H^{0} (\mathbb{Z}^+) = H^{0} (\coprod^{0 <i < \aleph_0} *) = \prod_{0<i< \aleph_0} \mathbb{R}$ , hence $H^{0} (M) \oplus H^{0} (F)$ is not isomorphic to $\bigoplus_{0<i< \aleph_0}\mathbb{R}$ as they claim. 9)In page 109, the definition of a constant presheaf is wrong. They define a presheaf $\mathscr{F}$ to be constant with abelian group $G$ if for every connected open set $U$ and any open set $V \subset U$ the restriction $\mathscr{F}(U) \rightarrow \mathscr{F}(V)$ is the identity. This is clearly wrong, since when $V$ is disconnected $\mathscr{F} (V) = G^{\pi_0 (V)}$ when $\mathscr{F}$ is a constant sheaf. The correct definition should be that $\mathscr{F}(U) \rightarrow \mathscr{F}_x$ is the identity for every connected set $U$ and $x \in U$ . (As noted by Kevin Carlson, they intended to define just a pre sheaf. I thought that they wanted to define a constant sheaf without talking about equalizers. Anyway, the requirement for $U$ to be connected still weird, since there would be no locally constant presheaves on a totally disconnected space, but this is just an unfortunate choice made by the authors) (I've double checked the book and they really use the constant SHEAF instead of the constant presheaf as they've defined. There are a lot of occurrences where this is problematic. For instance, in page 189 (Remark), they claim that the zeroth \v{C}ech cohomology has dimension equal to the number of connected components. Furthermore, in page 97, they define the constant ""presheaf"" $\mathbb{R}$ as the sheaf of locally constant functions. So, clearly, there's a problem here) 10)In page 133 (remark 12.4.2), they claim that a section of an oriented vector bundle $s^{*}: H_{cv}(E) \rightarrow M$ ( $s: M \rightarrow E$ ) must factorize through the inclusion $i: H_{cv} (E) \rightarrow H(E)$ . However this is not always true, since $i$ may not be injective. 11)In page 135 (proof of proposition 12.8), they claim that $\int_{S_x}\Phi = \int_{E_x} \Phi$ because $E_x$ is homotopic to $S_x$ modulo the region in $E$ where $\Phi$ is zero. However this makes no sense, since the integral is not invariant under homotopy of the domain. Although homotopic maps have the same integral. 12)In page 140 (exercise 12.12.1), the index of the sum should start at $0$ and not at $1$ . 13)In page 147 (the extension principle), they claim that a map $\partial I^k \rightarrow X$ may be extended to $I^k \rightarrow X$ if $\pi_q (X) \cong 0$ for $q \leq k-1$ . However they provide no references for this result and, since this book has so many errors, I'm starting to doubt if this is true. 14)In page 177 (""The Gysin Sequence""), they claim that in an oriented sphere bundle every locally constant pre sheaf has no monodromy and, therefore, is constant. However I could not see why this is true (by using the already introduced machinery). I think they're confusing it with the fact that a locally constant presheaf in an oriented vector bundle is constant (by using the argument in page 131-132 that restrict the Thom class). Maybe it's possible conclude this for sphere bundles coming from vector bundles (by using the fact for vector bundles), however not every sphere bundle may have its structure group (as a $G$ -bundle) reduced to $O(k)$ . 15)In page 178 (in the bottom of the page), they claim that an element of $H^{n-k}(M) \otimes H^k(S^k)$ may be represented by $\pi^{*}\omega \wedge (-\psi)$ where $\omega \in H^{n-k} (M)$ and $\psi$ the global angular form. However this is not, in general, true since Leray-Hirch theorem does not hold in this case and $\psi$ is not closed (though it's locally closed). 16)In page 183, the face operator is not defined correctly. The correct definition should be $\partial_q^i (\sum_{j = 0}^{q-1} t_j P_j) = \sum_{j = 0}^{i-1}t_jP_j + \sum_{j = i+1}^{q}t_{j-1}P_j$ . 17)In page 189 (in the bottom of the page), the exact sequence for singular cohomology is wrong. Instead of direct sums, it should be products since the functor $\text{Hom}(-, \mathbb{Z})$ is left exact (in the opposite category), hence it sends colimits to limits. Sorry for the long list. If someone know about any other possible mistakes in the book, please, let me know. Thanks in advance. EDIT I've checked the new edition of the book and some mistakes were corrected. More specifically, 6, 7, 9, 12, 16 and 17 were corrected. I should mention too that, as commented above, 1, 5 and 13 are not mistakes.","['differential-geometry', 'algebraic-topology']"
1338540,Graham scan with collinear points,"I'm having some trouble understanding the Graham scan algorithm as described in Wikipedia . Particularly, I don't understand how to handle collinear points. Consider these points as a simple example: (3, 1)
(2, 3)
(2, 4)
(2, 5)
(3, 7)
(1, 2)
(1, 6) Plotted into a coordinate system, they look like this: According to my interpretation of the Graham scan, I first need to find the point P with the lowest y coordinate (and lowest x in case of identical y coordinates). As far as I can tell, that point is (3, 1) . Next, I need to order the other points ""in increasing order of the angle they and the point P make with the x-axis"". As far as I can tell, the correct order should be: (3, 1)
(3, 7)
(2, 5)
(2, 4)
(1, 6)
(2, 3)
(1, 2) The next step is to consider whether triplets of points constitute a left or right turn. Starting with (3, 1), (3, 7), (2, 5), these make a left turn, so I should keep all three: (3, 1), (3, 7), (2, 5) Moving on to (3, 7), (2, 5), (2, 4), they also make a left turn, so keep all four: (3, 1), (3, 7), (2, 5), (2, 4) Next: (2, 5), (2, 4), (1, 6): Right turn, so discard (2, 4). Current points: (3, 1), (3, 7), (2, 5), (1, 6). This isn't right. (2, 5) isn't part of the convex hull - not even of the current subset of points considered so far. Anyway, for good measure, I'll continue with (2, 5), (1, 6), (2, 3): Left turn, so keep all three: (3, 1), (3, 7), (2, 5), (1, 6), (2,  3). Moving on: (1, 6), (2, 3), (1, 2): Right turn, so discard (2, 3): Result so far: (3, 1), (3, 7), (2, 5), (1, 6), (1, 2). There are no further points to consider, so (3, 1), (3, 7), (2, 5), (1, 6), (1, 2) is the result I get. However, I would have expected the result to be (3, 1), (3, 7), (1, 6), (1, 2) - that is, not including (2, 5). As far as I've been able to tell so far, this happens when some points are collinear. Is my interpretation of the Graham scan incorrect? Am I doing something wrong?","['geometry', 'coordinate-systems', 'algorithms']"
1338565,Jacobian Transformation p.d.f,"Suppose $X$ and $Y$ are continuous random variables with joint p.d.f. $$f(x,y) = e^{-y},\,\, 0<x<y <\infty$$ (a) Find the joint p.d.f. of $U=X+Y$ and $V=X$ . Be sure to specify the support of $(U,V)$ . (b)  Find the marginal p.d.f. of $U$ and the marginal p.d.f. of $V$ . Be sure to specify their support. I can't figure out what I am doing wrong with this question. So far, I have gotten that the support for $U$ and $V$ is $0<v<u<\infty$ , the Jacobean matrix has determinant $-1$ and that the joint p.d.f for part a) is $e^{v-u}$ but this p.d.f doesn't make sense when I try to find the marginals. Could someone help guide me in the right direction?","['statistics', 'probability-distributions', 'bivariate-distributions']"
1338616,Why the complex number system is not an ordered field [duplicate],"This question already has answers here : Total ordering on complex numbers (3 answers) Closed 9 years ago . In high school, we are taught that we do not have $2i < 3i$, i.e., the complex number system is not an ordered field. (Real number, for example, is an ordered field. For example, $2 < 3$). Why? My comment to this is because in the complex corrdinate, in $Re-Im$ coordinate, the concept of complex number is somewhat a rotation around the origin.","['field-theory', 'complex-analysis']"
1338617,Expectation of an integral with a random variable on its borne,"Having a random variable $T$ with a known distribution: Is it correct to say that $E\left[\displaystyle\int_{0}^{T}a\,dt\right]=a\times E[T]$ ? How can we calculate $E\left[\displaystyle \int_{0}^{T}f(t)\,dt\right]$  with $f(t)$ a known function of $t$ ?","['probability', 'statistics']"
1338660,Conditional Probability Cupcakes,"This is a very interesting word problem that I came across in an old textbook of mine. So I know its got something to do with conditional probability, which yields the shortest, simplest proofs, but other than that, the textbook gave no hints really and I'm really not sure about how to approach it. Any guidance hints or help would be truly greatly appreciated. Thanks in advance :) So anyway, here the problem goes: Two boxes each contain $4$ cupcakes. One box has $3$ chocolate and $1$ vanilla, and the other box has $2$ chocolate and $2$ vanilla. A box is randomly selected, opened, and a cupcake is randomly selected. This first cupcake is vanilla. If one more cupcake is randomly selected from the same box, what is the probability that it will be vanilla ? My working so far: If we pick a box at random, and pick a vanilla cupcake,
then there is a $\frac23$ probability we picked the second box.
( $2$ chances for having picked vanilla from there, against $1$ from $1$ ), and $\frac13$ for the first box. If we DID pick the first box, the chances of $2nd$ vanilla are $0$ , since
there isn't one, so $\frac13  0$ for that. Now I am stuck.","['probability-theory', 'probability']"
1338662,Roots addition.,"$$\sqrt{\frac{a+x^2}{x}-2\sqrt{a}}+\sqrt{\frac{a+x^2}{x}+2\sqrt{a}}=Q $$
  One is expected to find $Q$ respecting $a>0$, $x>\sqrt{a}$ . I'd like to have my solution checked; namely the correct answer is $2\sqrt{x}$ but I simply fail to see where I made a mistake. And it'd be nice to hear if there is any smoother solution, or any other way to solve this. I introduced two subsequent substitutions. $\frac{a+x^2}{x}=A, \;\;\;2\sqrt{a}=B \; \Rightarrow \; \sqrt{A-B}+\sqrt{A+B}=Q$ $\sqrt{A-B}=k, \;\;\; \sqrt{A+B}=n$ Now I have: $ \;\;\;$
$k+n=Q, \;\;\; k^2+n^2=2A, \;\;\; kn=\sqrt{A^2-B^2}$ $$k^2+n^2+2kn=\left ( k+n \right )^2=Q^2$$
$$Q^2=2A+2\sqrt{A^2-B^2}=\frac{2(a+x^2)}{x}+2\sqrt{\frac{\left (a+x^2 \right )^2}{x^2}-\left ( 2\sqrt{a} \right )^2}=$$
$$=\frac{2(a+x^2)}{x}+2\sqrt{\frac{a^2+2ax^2+x^4-4ax^2}{x^2}}=$$
$$=\frac{2(a+x^2)}{x}+2\sqrt{\frac{a^2-2ax^2+x^4}{x^2}}=$$
$$=\frac{2(a+x^2)}{x}+2\sqrt{\frac{\left ( a-x^2 \right )^2}{x^2}}=\frac{2(a+x^2)}{x}+\frac{2\left (a-x^2 \right)}{x}=\frac{4a}{x}$$
And as a result: $$Q=2\sqrt{\frac{a}{x}}$$","['radicals', 'algebra-precalculus']"
1338666,Integral of Laplace-Beltrami operator over a manifold,"Consider an equation 
$$\Delta u=-he^{u}$$
over a compact 2-manifold $M$, where $u\in C^{\infty}(M)$. In paper ""Curvature functions for Compact 2-Manifolds"" by Kazdan&Warner it is said that integration of the above equation over the manifold $M$ leads to the identity: $$\int_{M}he^udA=0,$$
where $dA$ is an area element. The paper is not the only place I find this conclusion, but I cannot trace from what kind of argument would this follow. But to have this conclusions, means that $\int_M\Delta udA=0$. But why is that so?","['laplacian', 'differential-geometry', 'compactness']"
1338685,Checking the Lindeberg condition (central limit theorem),"Problem. Let $W_1, W_2,...$ be independent and identically distributed random variables such that $E(W_1)=0$ and $\sigma^2 := V(W_1) \in (0,\infty)$. Let $T_n = \frac{1}{\sqrt{n}} \sum_{j=1}^n a_j W_j$ where $a_j\neq 0$ for all $j\in \Bbb{N}$. If $$\lim_{n\to \infty} \frac{\max_{j=1,...,n}|a_j|}{\sqrt{\sum_{j=1}^na_j^2}}=0,$$ then $$\frac{T_n}{\sqrt{V(T_n)}} \longrightarrow_d N(0,1) \quad\text{(convergence in distribution}).$$ Here is my attempt:
If we define $X_{nj}= \frac{a_j}{\sqrt{n}}W_j$ for $j=1,...,n$, then $T_n=\sum_{j=1}^n X_{nj}$. So if we can check that the Lindeberg condition holds for this triangular array, then the central limit theorem of Lindeberg-Feller implies the claim that $\frac{T_n}{\sqrt{V(T_n)}} \longrightarrow_d N(0,1)$.
To this end, we need to show that for any $\varepsilon>0$ $$\lim_{n\to \infty} \frac{1}{\sigma_n^2} \sum_{j=1}^n E( X_{nj}^2 \cdot \mathbf 1\{ |X_{nj}|\gt \varepsilon \sigma_n \})=0$$ where $\sigma_n^2=\sum_{j=1}^n V(X_{nj}) = \frac{\sigma^2}{n}\sum_{j=1}^n a_j^2$. I have not been able to prove this and would be very thankful for any help.","['probability-theory', 'probability-distributions', 'central-limit-theorem', 'normal-distribution', 'probability-limit-theorems']"
1338704,Stereographic projection and lengths,"We know the Stereographic Projection doesn't preserve areas except for the points on the plane such that $x^2+y^2=1$, because that's where $dA=dxdy$.  I was wondering what would happen with lengths: is there a set of points where lengths on the sphere are equal to lengths on the plane?","['spherical-geometry', 'geometry', 'spheres', 'differential-geometry']"
1338708,Volume of the intersection of two cylinders,"I have two infinite cylinders of unit radius
in $\mathbb{R}^3$, whose axes are skew lines.
Say that the axis of one is centered on the $x$-axis, and the axis of the
other is determined by the two points $a$ and $b$. Is there a formula for the
volume of their intersection, as a function of $a$ and $b$?","['calculus', 'volume', 'geometry', 'faq', 'multivariable-calculus']"
1338731,"If a tesseract is to a cube what a cube is to a square, what is to a sphere as a sphere is to a circle? What about rectangle, ring, triangle?","I'm trying to come up with sensible names for a programming library I'm putting together. One minor part of this library is the generation of shapes of varying dimensions. Basically I'm just trying to fill in the blanks below but I'm having awful trouble finding answers as it seems I need to know the name of the shape to find anything about it. The last column is the name I'm giving each group at the moment. ____________________________________________________
|    2D    |      3D     |      4D     |     Name    |
|----------------------------------------------------|
|  Square  |     Cube    |  Tesseract  |   Hypercube |
|  circle  |    Sphere   |    Glome    |   n-Sphere  |
|  Ring    |     Torus   |             | Hypertorus? |
| Triangle | Tetrahedron |             |   Simplex   |
|   Bar    |   Cylinder  | Duocylinder |             |
------------------------------------------------------ On the chance that these dimensional shapes don't exist, or maybe they don't have names, any suggestions on what to actually name each group would be appreciated.","['geometry', 'terminology']"
1338736,Prove that $A_{100} \gt 14$ where $A_{n}=A_{n-1}+\frac{1}{A_{n-1}}$ and $A_1=1$,"I tried attempting the question, and the best upper bound I could obtain was $1+\ln{98}$. I tried using $A_{n}\le n$ to form a harmonic series, but that wasn't strong enough. Any help would be appreciated, Thanks.","['recurrence-relations', 'sequences-and-series', 'inequality']"
1338738,"$f,g$ diffirentiable function at point $(x_0, y_0)$ how to show that $fg$ diffirentiable function at point $(x_0, y_0)$?","I guess there is pretty simple way of showing the statement below.. I tried using definition but it seem complicated. Suppose $f, g: \Bbb R^{2} \to \Bbb R$.  Prove if $f, g$ are differentiable at $(x_{0}, y_{0})$, then the product, $fg$, is differentiable at $(x_{0}, y_{0})$.","['calculus', 'multivariable-calculus']"
1338772,Verify my solution of $y'=(1-y)\sqrt{y}$,"I have to solve $$y'=(1-y)\sqrt{y},\ \ \  y(0)=y_0$$ My approach:
$$\begin{align}
\int{\frac{1}{(1-y)\sqrt{y}}dy}=x+c\\
2\int{\frac{1}{1-w^2}dw}=x+c\\
2\text{arctanh}\sqrt{y}=x+c\\
y=\tanh^2{\frac{x+c}{2}}
\end{align}$$ So that
$$y(0)=y_0=\tanh^2{\frac{c}{2}},\  \ \ c=2 \text{arctanh}\sqrt{y_0}$$ And so the solution is
$$y=\tanh^2(\text{arctanh}\sqrt{y_0}+\frac{x}{2})$$
However, I'm a bit uncomfortable with the fact that for $|y_0|>1$  the $\text{arctanh}\sqrt{y_0}$ will be imaginary. It is not quite clear to me why (or even IF) the solution will be real?",['ordinary-differential-equations']
1338787,Number of subsets with even number of elements [duplicate],This question already has answers here : Exactly half of the elements of $\mathcal{P}(A)$ are odd-sized (8 answers) Closed 8 years ago . Let $|X|=n$. How to find all number of subsets $X$ consisting of an even number of elements?,['combinatorics']
1338798,"Examples of calculus on ""strange"" spaces","I am interested in examples of calculus on ""strange"" spaces. For example, you can take the derivative of a regular expression[1][2]. Also the concept extends past regular languages, to more general formal languages[3]. You can also do calculus on abstract data types, here is an example in Haskell[4]. Differential equations are type-inference equations. You can also taylor-expand types[5]. I am looking at more examples of this. Note that I am interested where calculus is similar enough to ""normal"" calculi (e.g. calculus on functions of complex variables, functional calculus, etc). At least operators must be linear, for example the arithmetic derivative is not interesting to me because the operators are not linear. The examples I gave are all from computer-science, but I am interested in more general answers. Brzozowski: Derivatives of Regular Expressions Owens: Regular-expression derivatives reexamined Might: Parsing with Derivatives The Algebra of Algebraic Data Types, Part 3 The Algebra of Algebraic Data Types, Part 2","['computer-science', 'soft-question', 'abstract-algebra', 'analysis', 'recreational-mathematics']"
1338801,How to prove Raabe's Formula [duplicate],"This question already has answers here : Integral $\int_0^1 \log \left(\Gamma\left(x+\alpha\right)\right)\,{\rm d}x=\frac{\log\left( 2 \pi\right)}{2}+\alpha \log\left(\alpha\right) -\alpha$ (4 answers) Closed 9 years ago . For quite some time, I've been trying to prove Raabe's Formula, or in other words: $$\int_a^{a+1} \ln\bigg(\Gamma(t)\bigg)dt=\dfrac{1}{2}\ln(2\pi)+a\ln(a)-a$$ This is how I tried:
$$I(s)=\int_a^{a+1}\ln\bigg(s\Gamma(t)\bigg)dt$$Differentiating with respect to $s,$
$$I'(s)=\int_a^{a+1}\dfrac{\Gamma(t)}{s\Gamma(t)}dt=\int_a^{a+1} \dfrac{dt}{s}$$
However, at this point I stopped thinking I must have made a mistake because I was told that proving Raabe's Formula was really difficult, and this seemed too simple a method to prove Raabe's Formula. $$$$
I would be grateful if somebody would be so kind as to tell me how to prove this result, as well as what went wrong with my method. Many, many thanks in advance!","['gamma-function', 'calculus', 'definite-integrals', 'integration']"
1338831,Topological information from metric tensor,"Suppose I am working with a Riemannian manifold $(M,g)$, and I have a particular coordinate expression for the metric $g$. What topological information can I infer about the manifold $M$? For example ($S^3$ with Hopf coordinates ), suppose I have coordinates $(\eta, \xi_1 , \xi_2 ) $ in which the metric takes the form: $ds^2 = d \eta^2 + \sin^2(\eta) d \xi_1^2 + \cos^2(\eta) d\xi_2^2$ for $0 < \eta < \pi/2$, and $0 < \xi_1 , \xi_2 < 2 \pi$. If I didn't already know this was a metric for $S^3$, how could I work that out? How do I know this isn't a metric for another three manifold, say $S^2 \times S^1$? Are there topological invariants I can compute from the metric to distinguish between, say, these two possibilities? EDIT: Changed the inequalities to be strict so that the metric in my example doesn't degenerate.","['differential-geometry', 'geometric-topology']"
1338840,Why is '1' the multiplicative identity of complex numbers and quaternions?,I am not a mathematician. I studied electrical engineering. I encountered quaternions while trying to understand motion of mobile robots and how rotations are achieved. This question occurred to me when I got to know of the inverse of a quaternion.,"['quaternions', 'complex-analysis', 'real-analysis', 'complex-numbers']"
1338845,Sample median of Cauchy distribution is consistent. How?,"When we use chebyshev's inequality to show whether an estimator is consistent or not, we require the mean square error of the estimator and I do not know sample median's probability distribution. So please advice how this can be shown.","['quantile', 'statistics', 'statistical-inference']"
1338880,Local parametrizations and coordinate charts on manifolds,"I have recently had discussions on related questions about coordinate charts on here which has started to clear up some issues in my understanding of manifolds. Apologies in advance for the long-windedness of this post, but there are several points that I feel are crucial for me to understand to further my studies of differential geometry, and as they are fairly closely related I thought it better to ask/check them in one post. Several of the notes/textbooks that I've been reading on the subject have mentioned about the inverse map of a coordinate map as giving a local parametrization to a point in a given patch on a manifold. By this is it meant that, given an $n$-dimensional manifold $M$ and a homeomorphism $\phi:U\subset M\rightarrow V\subset\mathbb{R}^{n}$ from a patch on the manifold $U\subset M$, then we can parametrize a point $p\in U$ via the inverse map $\phi^{-1}:V\subset\mathbb{R}^{n}\rightarrow U\subset M$? More explicitly, if $\phi (p)=(x^{1},\ldots,x^{n})$ are the coordinates labelling $p$ in $\mathbb{R}^{n}$, then is it correct to say that one can describe a point in a given patch on the manifold directly via its parametrization with respect to its coordinates, i.e.
$$p=(\phi^{-1}\circ\phi)(p)=\phi^{-1}(\phi(p))=\phi^{-1}(x^{1},\ldots,x^{n})=(u^{1},\ldots,u^{n})$$
where $(u^{1},\ldots,u^{n})$ is the local parametrization of $p$ on $M$, and $u^{i}=u^{i}(x^{1},\ldots,x^{n})$ are functions whose domain is $\mathbb{R}^{n}$. If so, what really is the difference between parametrizations of points and their corresponding coordinates? (Is it simply that the coordinates are labels that allow one to distinguish individual points in a patch on the manifold, and then we can use these to parametrize the patch such that each value of the coordinates describes a given point on the manifold (in terms of the parametrization)). If I have understand this notion of parametrization correctly, then is the following discussion correct? If we take the example of a 2-sphere $S^{2}\subset\mathbb{R}^{3}$, then is the 2-tuple $(\theta,\phi)\in\mathbb{R}^{2}$ the coordinates of a point on the manifold (with the mapping defined by $p\mapsto (\theta,\phi)$) and its corresponding local parametrization on the manifold, $(\sin(\theta)\cos(\phi),\sin(\theta)\sin(\phi),\cos(\theta))\in S^{2}\subset\mathbb{R}^{3}$ (with the inverse mapping defined by $(\theta,\phi)\mapsto (\sin(\theta)\cos(\phi),\sin(\theta)\sin(\phi),\cos(\theta))$) ? From reading John Lee's books on smooth manifolds and Riemannian geometry (and from a previous discussion on here), I think it is correct to say that (when a metric is defined on the manifold) one can only use local Cartesian coordinates (or local Euclidean coordinates) to label points in a patch on a manifold if the curvature of the manifold is zero (i.e. it is ""locally flat"") as then there will exist a local isometry between the manifold between the manifold and flat Euclidean space. Mathematically, if $(M,g)$ is locally flat (i.e. has vanishing local curvature) then there will be an isometry $\psi$ to an open set in $(\mathbb{R}^{n},\bar{g})$(where $g$ is the metric defined on the $n$-dimensional manifold $M$, and $\bar{g}$ is the Euclidean metric defined on $\mathbb{R}^{n}$). (Would it also be correct to say that the Cartesian coordinate system is the identity map $\text{id}:\mathbb{R}^{n}\rightarrow\mathbb{R}^{n}$ defined by $(x^{1},\ldots,x^{n})\mapsto (x^{1},\ldots,x^{n})$, such that the parametrization of each point is simply given by $(x^{1},\ldots,x^{n})$?) Apologies for the lack of rigour, I am coming from a Physics background and I'm self-teaching myself differential geometry in order to gain a better understanding of general relativity.","['smooth-manifolds', 'differential-geometry', 'coordinate-systems']"
1338881,Zero-section as homomorphism of rings,"Let $s : X \to E$ be the zero section of a vector bundle $E$ over a scheme $X$. Zariski-locally this corresponds to a homomorphism $Sym_A(M) \to A$ of $A$-algebras where $M$ is a finitely generated projective $A$-module. What is this homomorphism? By adjunction it corresponds to a homomorphism $M \to A$ of $A$-modules. Is this just the zero morphism $M \to 0 \to A$? Stupid question I know, but I'm not an algebraic geometer, and I couldn't find the answer in any scheme theory book.","['algebraic-geometry', 'schemes', 'category-theory']"
1338892,How to solve this combinatorics problem?,"As a tourist in NY, I want to go from the Grand Central Station (42nd street and 4th Avenue) to Times Square (47th street and 7th Avenue). I needed my morning coffee, and wanted to go to a Starbucks that's located at 44th street and 5th avenue. If I only walk West and North, how many ways are there for me to get there?",['combinatorics']
1338900,Help to solve this geometry problem,How to find the length of $BG$ and $EC$ using $\alpha$ and $\beta$ ?,['geometry']
1338922,How to perform nonlinear regression with regressors affected by gaussian error?,"I am trying to calibrate a sensor and I have a data set consisting of several observations of a 3-dimensional vector $X_i$, with $X_i=w_i + \epsilon_i$ where $w_i$ is the value that the sensor should measure (if uncalibrated but unaffected by noise) which is fixed for each $i$ and unobservable, and $\epsilon_i$ is gaussian error vector with zero mean and a known diagonal covariance matrix, which is the same for all $i$. The error vectors $\epsilon_i$ are uncorrelated for different $i$. The response variable is $Y_i=\|C(w_i-B)\|=1$ for all $i$. $C$ is a 3x3 matrix that can be eigendecomposed by $C=R(\psi,\theta,\phi)\,E\,R(\psi,\theta,\phi)^T$, where $R$ is a rotation matrix parametrized by the three angles $\psi,\theta,\phi$. $E$ is a diagonal matrix where each entry in the diagonal is positive and bounded from above by a known value. $B$ is a 3x1 vector. This is a typical nonlinear regression with additive measurement error, but without additional additive error in $Y$ (as opposed to the traditional setting of this problem that I have seen so far). Is it possible to obtain an unbiased estimate of the model parameters $p$ (the three attitude angles that parametrize $R$, the three diagonal entries of $E$ and the vector $B$) from the observations $X_i$? Alternatively, is there a way to find out if solving the nonlinear least squares problem $\hat{p}= \min_p \sum_{i=1}^n (\|C(X_i-B)\|-1)^2$ yields an unbiased estimate of $p$?","['statistics', 'regression']"
1338924,One Equation Implying The Another .,"Suppose that $\{W_t\}$ and $\{Z_t\}$ are independent and identically distributed sequences , with 
$$P(W_t=0)=P(W_t=1)=.5$$ 
$$P(Z_t=-1)=P(Z_t=1)=.5$$ . Define $$X_t=W_{t}(1-W_{t-1})Z_t$$ Now it is written that : $X_{t-1}=1$ implies that $W_{t-1}=1$ , which implies that $X_t=0$ . I have not understood how does $X_{t-1}=1$ imply $W_{t-1}=1$ and that imply $X_t=0$ ? Also it is written : $P(X_{t-1}=1,X_t=1)=0$ . How is the probability  derived ?","['probability', 'algebra-precalculus']"
1338925,Looking for a bound on a function involving $\sinh$,"Fix $T > 0$ and let $t \in (0,T)$ let $c > 1$ be a constant (which may be bigger than $T$). Consider the function $$f(c,t,T) = \frac{\sinh ((T-t)c)}{\sinh (Tc)}.$$
I am looking for a bound of the form
$$f(c,t,T) \leq {K(t,T)}{c^{-\frac 12}} \qquad \text{for $t \in (0,T)$}$$
where $K(t,T)$ is a constant that depends on $t$ and $T$ (preferably in a continuous or a nice way). Can such a bound be possible? By using half-angle formula, we can write 
$$f(c,t,T)=\cosh(tc)-\coth(Tc)\sinh(tc)$$
but I just don't see how to estimate it.","['hyperbolic-functions', 'functional-analysis', 'functions']"
1338941,Degree of minimal polynomial of the sum of two algebraic elements over $\mathbb Q$,"The minimal polynomial of $a$ over $\mathbb{Q}$ is quadratic. The minimal polynomial of $b$ over $\mathbb{Q}$ is cubic. Is the minimal polynomial of $a+b$ necessarily of degree $6$? If so, what is the shortest/most elegant proof of this?","['extension-field', 'abstract-algebra', 'polynomials', 'field-theory']"
1338945,Difficult problem in Riemann integrals,"Could anyone help me with the following problem? Because i have stuck. Let $f:[a,b]\rightarrow [0,\infty)$ be continuous and not the zero function. Prove that $$\lim_{n\to \infty} \frac{\int\limits_a^b f^{n+1}(x)\, \mathrm{d}x}{\int\limits_a^b f^n(x)\, \mathrm{d}x}=\sup_{x\in[a,b]}f(x)$$ Some of my thoughts: Let $\displaystyle M=\sup_{x\in[a,b]}f(x)$ and $\displaystyle m=\inf_{x\in[a,b]}f(x)$ . Moreover define the sequences $\{I_n\}_{n=0}^{\infty}$ and $\{a_n\}_{n=0}^{\infty}$ , So, $\displaystyle I_n=\int\limits_a^b f^{n}(x)\, \mathrm{d}x$ and $\displaystyle a_n=\frac{I_{n+1}}{I_n}$ . It easy to prove that $$m(b-a)\leq I_n \leq M(b-a)$$ and $$a_n \leq M\left(\frac{M}{m}\right)^n.$$ First I tried to use the above inequalities to prove it by definition or somehow with the squeeze theorem, but unfortunately $\displaystyle M\left(\frac{M}{m}\right)^n \xrightarrow[ n \to \infty]{} \infty$ Then I thought about the integral mean value theorem , but again nothing new came up. So do you have any suggestions, thoughts, hints or\and solutions?","['calculus', 'real-analysis', 'integration']"
1338946,Existence of a bounded ball,"Lets define:
$$F(X) :=\{A \subseteq X \mid A \neq \emptyset , A = \overline{A}\}.$$ For $A, B \in F(X)$ and $p \in X$ define
$$d_p(A,B) = \sup_{x \in X} \{ | \operatorname{dist}(x,A) - \operatorname{dist}(x,B) | e^{- \rho(p,x)} \}.$$
This function is called Busemann metric. Now we can also define:
$$ B(X) := \{ A \in F(X)  \mid  A \text{ bounded} \}.$$
For $A, B \in B(X)$ lay:
$$d(A,B) = \max \{ \sup_{x \in X} \operatorname{dist} (x,A), \sup_{x \in X} \operatorname{dist} (x,B)  \}. $$
This one is called Hausdorff metric.
$$ $$ I am trying to prove the following theorem: If $(X, \rho )$ is a metric space, then $d_p$ and $d$ are equivalent over $B(X)$. To attain that, I need to show, that there exists (for $A \in B(X) $) $r>0$ s.th. $ \bigcup K_p (A,r) $ is bounded in $X$. Does anyone know what can I do to achieve that?","['metric-spaces', 'general-topology']"
1338957,Prove that $\sin{\frac{2\pi x}{x^2+x+1}}=\frac{1}{2}$ has no rational roots.,"Show that the following equation has no rational roots.
  $$\sin{\frac{2\pi x}{x^2+x+1}}=\frac{1}{2}$$ This is what I've tried: $$\left ( \frac{2\pi x}{x^2+x+1}=\frac{\pi}{6}+2k\pi \right)\lor\left (\frac{2\pi x}{x^2+x+1}=\frac{5\pi}{6}+2l\pi \right ), \; \left (k,l \in \mathbb{Z} \right ) $$
First case only:
$$ \frac{2\pi x}{x^2+x+1}=\frac{\pi}{6}+2k\pi \iff \frac{2\pi x}{x^2+x+1}=2\pi \left ( \frac{1}{12}+k \right )$$
$$\left ( 12k+1 \right )x^2+\left (12k-11 \right)x+(12k+1)=0 \tag{$\bigstar$}$$
Now $$\Delta=96k^2-316k+117\geqslant 0 $$
For case $\Delta=0$:
$$k_{1,2}=\frac{316\pm \sqrt{54928}}{2\cdot96} \notin \mathbb{Z}$$
But it means nothing 'cause I still have entire interval $\left ( -\infty,k_{-} \right ) \cup \left ( k_{+}, +\infty\right )$ to check. I've rewritten $\left ( \bigstar \right )$:
$$x^2+x\left (\frac{12k-11}{12k+1} \right)+1=0$$
By using Vieta's formulas: $$x_{1}+x_{2}=\frac{11-12k}{12k+1} \qquad \land \qquad x_{1}x_{2}=1$$
Since I have to prove that there are no rational roots, I wanted to give it a shot with contradiction, so I assumed:
$$x_{1}=\frac{p}{q}, \;\; x_{2}=\frac{r}{s}, \;\; \left (p,q \right)=\left (r,s \right)=1$$ Since $\left (p,q \right)=\left (r,s \right)=1$ we obtain from $x_{1}x_{2}=1$ that $p=s$ and $q=r$. Now we have: $$x_{1}+x_{2}=\frac{p}{q}+\frac{r}{s}=\frac{p}{q}+\frac{q}{p}$$
$$x_{1}+x_{2}=\frac{p^2+q^2}{pq}=-\frac{12k+1-12}{12k+1}=\frac{12}{12k+1}-1$$ Now if I could prove: $$\left (p,q \right)=1 \implies \frac{p^2+q^2}{pq}\in \mathbb{Z}$$
...then I would show that my assumption is wrong i.e. there are no rational roots of the given equation. But even if that is true, I'd rather hear some solution that doesn't involve number theory, not even elementary one.","['elementary-number-theory', 'algebra-precalculus', 'trigonometry']"
1338971,Study this function $f(x) = \frac{\sqrt[3]{x-1}}{(x+2)^2}$,"I need to study this function: $$f(x) = \frac{\sqrt[3]{x-1}}{(x+2)^2}$$ and I need to show Max and Min point. The first thing is define the Domain, so: $$\left\{\begin{matrix}
\sqrt[3]{x-1} > 0\\ 
(x+2)^2 \neq 0
\end{matrix}\right.$$ $$\left\{\begin{matrix}
x > 1\\ 
x \neq -2
\end{matrix}\right.$$ So my domain is: $$(1, +\infty )$$ Now I check the intersection with x and y : $$\frac{\sqrt[3]{x-1}}{(x+2)^2} = 0$$ and I get $$ N: x = 1 $$
$$ D: x = -2 $$ And I have no intersection with y .
I have checked the limit in $1$ and $+\infty$: $$ \lim_{x \rightarrow +\infty} \frac{\sqrt[3]{x-1}}{(x+2)^2} = 0$$
$$ \lim_{x \rightarrow 1^+} \frac{\sqrt[3]{x-1}}{(x+2)^2} = 0$$
$$ \lim_{x \rightarrow 1^-} \frac{\sqrt[3]{x-1}}{(x+2)^2} = 0$$ I have calculated the first derivative as suggested here , the result is: $$ f'(x) = \frac{8-5x}{3\sqrt[3]{(x-1)^2}(x+2)}$$ Now how should I precede to study Max and Min? Are my steps correct?",['functions']
1338980,Curve fitting of a set of data,"Suppose you have a set of data $\{x_i\}$ and $\{y_i\}$ with $i=0,\dots,N$. In order to find two parameters $a,b$ such that the line 
$$
y=ax+b,
$$
give the best linear fit, one proceed minimizing the quantity
$$
\sum_i^N[y_i-ax_i-b]^2
$$
with respect to $a,b$ obtaining well know results. Imagine now to desire a fit with a function like
$$
y=ax^p+b.
$$
After some manipulation one obtain the following relations
$$
a=\frac{N\sum_i(y_ix_i^p)-\sum_iy_i\cdot\sum_ix_i^p}{(\sum_ix_i^p)^2+N\sum_i(x_i^p)^2},
$$
$$
b=\frac{1}{N}[\sum_iy_i-a\sum_ix_i^p]
$$
and
$$
\frac{1}{N}[N\sum_i(y_ix_i^p\ln x_i)-\sum_iy_i\cdot\sum_ix_i^p\ln x_i]=\frac{a}{N}[N\sum_i(x_i^p)^2\ln x_i-\sum_ix_i^p\cdot\sum_ix_i^p\ln x_i.
$$
To me it seems that from this it is nearly impossible to extract the exponent $p$. Am I correct?","['statistics', 'numerical-methods']"
1338984,Limit of a binomial probability,"I am doing some self-study on measure theory and probability. This question is taken from Jacod and Protter's Essentials of Probability, Chapter 5 (Q15): Let $X$ be a binomial random variable, $X\sim \mathrm{Binomial}(p=\frac{1}{2}, n)$, where $n=2m$. Let $a(m,k)=\dfrac{4^{m}}{2m \choose m} P(X=m+k)$. Show that $\lim_{m\to \infty} (a(m,k))^{m}=e^{-k^{2}}$. So far I have been able to get: \begin{align*}
[a(m,k)]^{m}&=\left[ \frac{4^{m}}{2m \choose m} P(X=m+k) \right]^{m}\\
&=\left[ \frac{4^{m}}{2m \choose m} {2m \choose (m+k)}p^{m+k}(1-p)^{2m-(m+k)} \right]^{m}\\
&=\left[ 4^{m} \frac{(m!)^2}{(m-k)!(m+k)!}\left(\frac{1}{2}\right)^{m+k} \left(\frac{1}{2}\right)^{m-k} \right]^{m}\\
&=\left[\frac{(m!)^2}{(m-k)!(m+k)!}\right]^{m}\\
&\approx\left[\left(\frac{m}{\sqrt{(m-k)(m+k)}}\right)\left(\frac{m}{e}\right)^{2m}\left(\frac{e}{m-k}\right)^{m-k}\left(\frac{e}{m+k}\right)^{m+k}\right]^{m}\text{, by stirling}\\
&=\left[\frac{m^{2m+1}}{(m-k)^{m-k+0.5}(m+k)^{m+k+0.5}}\right]^{m}\\
\end{align*}
However, I am unable to get the answer from here. I think I am close, but have been working with it for a while and can't get anywhere. I hate moving on without understanding where I am making a mistake (especially with self-study). If anyone feels up to the challenge any help would be greatly appreciated.","['probability', 'limits', 'binomial-distribution']"
1338990,Show: An entire function $g$ with $\vert g(x) \vert \to \infty$ for $|x| \to \infty$ is a polynomial.,This is part of an exercise sheet in complex analysis. It should by solvable by rather elementary methods like the main theorems of complex analysis. I succeded to show that $g$ has only finitely many zeros by using Bolzano-Weierstra's theorem. If you divide $g$ by all its zeros you get a holomorphic function without zeros. I now fail to show that this new function is constant.,['complex-analysis']
1338996,Describe the space of solutions of the matrix equation $UV^T=VU^T$,"I would like to describe the space of solutions to the following matrix equation. Here $U$ and $V$ are two unknown real matrices with $n$ lines and $p$ columns (i.e. they belong to $M_{n,p}(\mathbb{R})$) : $$ U V^T - V U^T = 0$$ Note : The result is a square matrix with $n$ lines and $n$ columns. What I found up to now : if $p=1$ then the equations are equivalent with the statement $U$ and $V$ are colinear. The system can be rewritten under the following form : Let $X$ be the following matrix with $2p$ lines and $n$ columns (the unknown) :
$$ X = \left[ \begin{matrix}U^T\\V^T\end{matrix}\right]$$
Let $\Omega$ be the following square matrix with $2p$ lines and $2p$ columns : 
$$ \Omega = \left[ \begin{matrix}0_{p \times p} & I_{p \times p}\\-I_{p \times p} & 0_{p \times p}\end{matrix}\right]$$
Then my equations can be re-written like this :
$$ X^T \Omega X = 0$$ This formal similarity with isotropic spaces in symplectic geometry makes me think that there is some litterature on the subject (the difference with symplectic geometry is that we do not have a ""form"" since the result is not a scalar when $n \neq 1$). I however cannot find anything relevant yet. Any hint or partial answer is most welcome. Edit : Trying to generalize the special $p=1$ case to general $p$, I found the following sufficient condition : 
If there exists a symmetric $p\times p$ matrix $P$ such that $U=VP$ then $(U,V)$ is a solution to the equation. Is this condition sufficient ? Can it be re-written so that it highlights the symmetric role of $U$ and $V$ ?","['matrices', 'bilinear-form', 'matrix-equations', 'symplectic-linear-algebra', 'symplectic-geometry']"
1339003,"integral of $\sin(\ln(x))\,dx$","I tried to calculate this integral:  $$\int \sin(\ln(x))\,dx$$ but it seems my result is wrong. My calculation is:
 $$\int  \sin(\ln(x)) \,dx = \left| \begin{array}{c} u=\ln x \\  du=(1/x)dx\\  
dx=xdu \end{array}  \right|$$
with integration by parts:
 $$-\cos(u)x-\int -\cos(u) dx$$
 $$-\cos(u)x+\sin(u)$$
 $$\sin(ln|x|)-\cos(\ln|x|)x +C$$ 
The answer in the website is:
$$0.5[\sin(\ln(x))x-\cos(\ln(x))x]$$ What did I do wrong?","['calculus', 'integration']"
1339012,what does `ensemble average` mean?,"I'm studying this paper and somewhere in the conclusion part is written: ""Since this rotation of the coherency matrix is carried out based on the ensemble average of polarimetric scattering characteristics in a selected imaging window, we obtain the rotation angle as a result of second-order statistics."" Also I've seen the term ensemble average in several other papers of this context. Now I want to understand the exact mathematical or statistical definition of ensemble averaging not only in this context but the exact meaning and use of ensemble averaging in statistics and mathematics. I googled the term ensemble average and here in wikipedia we have the definition as ""In statistical mechanics, the ensemble average is defined as the mean of a quantity that is a function of the microstate of a system (the ensemble of possible states), according to the distribution of the system on its microstates in this ensemble."" But I didn't understand this definition because I don't even know what does the microstate of a system or possible states of system mean in mathematics. Could you please give me a simple definition with some examples for ensemble averaging ? Compare time averaging and ensemble averaging ? And also introduce me some good resources to study more especially resources that can be helpful in image processing too?","['average', 'order-statistics', 'statistics', 'stochastic-processes']"
1339030,Can anyone prove D'Alembert Criterion (Dalambert) criterion for converging positive sequences?,"This will most likely be on the exam,  but it is not given in the text book. In my notebook I have this proof which I will type out, but it makes no sense. Here it goes: $$\text{D'Alembert  Criterion}$$ Let $\sum_{n=1}^{\infty}a_n$ with $a_n > 0$. 1.) If $\exists N$ such that $\forall n >N$, $\frac{a_{n+1}}{a_n}\leq q < 1$ then $\sum_{n=1}^{\infty}a_n$ converges. 2.) If $\exists N$ such that $\forall n >N$, $\frac{a_{n+1}}{a_n}> 1$ then $\sum_{n=1}^{\infty}a_n$ diverges. Proof:
$$  \forall n >N \ \ \  \frac{a_{n+1}}{a_n}\leq q < 1 \\ 
For \ \ \  n=1: \frac{a_{2}}{a_1} \leq q \implies a_2 \leq qa_1 
\\ 
For \ \ \  n=2: \frac{a_{3}}{a_2} \leq q \implies a_3 \leq q^2a_1
\\ 
For \ \ \  n=2: \frac{a_{3}}{a_2} \leq q \implies a_4 \leq q^3a_1$$
$$\\ .... \\
\\ 
For \ \ \  \frac{a_{n+1}}{a_{n}} \leq q \implies a_3 \leq q^{n-1}a_1=\frac{a_1}{q}q^n
$$ So if $\sum_{n=1}^{\infty}q^n = \frac{q}{1-q}$ for $|q|<1 \implies a_n conv.???$","['analysis', 'sequences-and-series', 'convergence-divergence', 'real-analysis']"
1339045,$\int \limits_0^{\infty} x^2 \exp(-2x^2) dx$,"How to evaluate this integral? $$\int \limits_0^{\infty} x^2 \exp(-2x^2) dx$$ I found similar problem, but don't know how to apply them here. What do I have to substitute?","['calculus', 'integration']"
1339075,Is it possible to work out the derivative of $e^x$ using the summation definition of $e = \sum_n 1/n!$?,"So I know this question is a bit obtuse because usually we define $e$ in terms of the $\lim_{n \to \infty} (1 + 1/n)^n$ definition, and then compute derivatives of $e^x$ from there appealing to the limit definition of $e$, and then appeal to Taylor series of $e^x$ to finally arrive at $e = \sum_n 1/n!$. However, how hard would it be to do the other way around, to compute the derivative of $e^x$? I.e., is it possible to show the derivative of $(\sum_n 1/n!)^x$ with respect to $x$ is equal to itself, somewhat ""directly"", without showing the summation formulation of $e$ is equivalent to the typical limit definition of $e$?","['sequences-and-series', 'real-analysis', 'derivatives']"
1339102,Interplay of Hausdorff metric and Lebesgue measure,"Consider the space $\mathcal{K}(\mathbb{R}^{n})$ of compact subsets of $\mathbb{R}^{n}$ endowed with the Hausdorff metric $\rho$, and let $\lambda$ denote the $n$-dimensional Lebesgue measure on $\mathbb{R}^{n}$. Now, I understand that $\lambda$ is not continuous with respect to $\rho$, i.e. that $[ \lim_{k \to \infty} \rho(K, K_{k}) = 0 ] \not \Rightarrow [ \lambda(K) = \lim_{k \to \infty} \lambda(K_{k}) ]$. But my question is: Suppose $\lambda(K_{i}) = \lambda(K_{j}) = C$ for every $i, j \in \mathbb{N}$, i.e. the sequence $k \mapsto \lambda(K_{k})$ is constant; does this imply that $\lambda(\lim_{k \to \infty} K_{k}) = C$? If not, I'm interested to see a counterexample. Thanks.","['lebesgue-measure', 'measure-theory']"
1339124,"What is the combinatorial proof for the formula of $S(n,k)$ - Stirling numbers of the second kind?","What is the combinatorial proof for the formula of Stirling numbers of the second kind ? $${n\brace k}=\frac1{k!}\sum_{j=0}^k(-1)^{k-j}\binom{k}jj^n$$ where ${n\brace k} = S\left(n,k\right)$ is the number of set partitions of a fixed $n$ -element set into $k$ parts.","['combinatorial-proofs', 'discrete-mathematics', 'combinations', 'combinatorics', 'stirling-numbers']"
