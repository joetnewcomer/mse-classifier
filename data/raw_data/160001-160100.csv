question_id,title,body,tags
2760020,What is up with the antiderivative of $\arctan^2(x)$?,"Integrating $\arctan^2(x)$ has been a mystery to me since I first learned to compute indefinite integrals. When I plug it into integral calculator or WolframAlpha, I get a primitive written in terms of complex numbers and polylogarythms; but $\arctan^2(x)$ is continuous and defined $\forall\space x\in\mathbb{R}$, the area under the curve $(x,\arctan^2(x))$ is well-defined and obvioulsy real. In fact, I can integrate that function numerically and get the area without using Barrow's Rule at all. I thought maybe the complex part of that expression is constant, therefore applying Barrow's Rule always yields a real number anyway, but then I could subtract a constant equal to its imaginary part times $i$ and get a real and still valid antiderivative. Anyway, I have no idea of how to compute that antiderivative in the first place, so I can't check for myself. Can a real, continuous function have a complex primitive but not a real primitive? And, can anyone give me a hint to help me compute its antiderivative by myself?","['indefinite-integrals', 'integration', 'calculus']"
2760031,A cohomology or homology associated to a Riemannian manifold or a dynamical system,"I  would  like  to know  whether  the  following co boundary or  boundary maps can  introduce some new kinds of cohomology or  homology which contains  some  non trivial, new,  finite  dimensional  and  helpful information  about the  manifold or  the  dynamics of  a vector  field on it. All maps $\phi$  described below are  defined on the chain of  differential  forms on a  manifold $M$  which obviously   satisfy $\phi \circ \phi=0$. In this  question, to sake finite  dimensionality of  resulting cohomology or  homology, instead of  consideration of  the  whole  complex $\Omega^*(M)$,  we are flexible  to consider   an appropriate sub complex of $\Omega^*(M)$. Each operator  $\phi$ listed below    can  suggest  some  subcomplex  as  domain of definition of  $\phi$. Let  $M$  be  a  Riemannian  manifold with  Laplace operator $\Delta$ and  $X$ be a  vector  field  on $M$. Our differential  maps(coboundary or  boundary maps) are  the  following maps. The first $2$  maps  depends  on the  Riemannian structure  and  the last $2$  maps, which decrease the degree by 2,   depend  on the  vector  fields $X$. Suggestion for  $\phi:$ The  map $\phi$ is: 1)$d\circ \Delta$ 2)$d^* \circ \Delta$ 3)$d^*\circ L_X \circ d^*$ 4)$i_X\circ \Delta \circ i_X$ The operator  $L_X$ is the  Lie derivative operator. The operator $i_X:\Omega^i(M) \to \Omega^{i-1}(M)$ is the  interior product and  $d^*$ is  the  codifferential operator.","['homology-cohomology', 'riemannian-geometry', 'dynamical-systems', 'smooth-manifolds', 'differential-geometry']"
2760066,moment of iid sums,"Let Let $X_1,X_2,X_3,X_4$ be a sequence of independent, identically distributed random variables
with:
$$ E(X) = 0 $$
$$ E(X^2)=1$$
$$E(X^3) = 1$$
$$E(X^4) = 6 $$
Let:
$$S_1 =X_1$$
$$S_2 =X_1+X_2$$
$$S_3 = X_1+X_2+X_3$$
and so on. Show that 
$$\sum_{r=1}^{n} \frac{E(S_r^4)}{r^2(r+1)^2} = \frac{3n}{n+1}$$ Using central moments of iids
I have found the 4th central moment of $S_n$ to be
$$E(S_n^4) = n(6-3n^2)$$
putting this into the sum i have $$\sum_{r=1}^{n}\frac{r(6-3r^2)}{r^2(r+1)^2}$$ not really sure where to go from here in order to get the expression needed",['statistics']
2760133,two intersection of affine open subsets,let $ X $ be a separated scheme over an affine scheme $ S$. let $U$ and $V$ be open affine subsets of $X$.Then $U\cap V$ is also affine.and Give an example to to show that this is fails if $X$ is not separated. This is an exercise  4.3(Chapter 2)of Hartshorne. I know that closed subschme of an affine scheme is affine. But I don't know how to use this when $S$ is affine scheme. Thank you in advance!,"['schemes', 'affine-schemes', 'algebraic-geometry']"
2760167,prove that $\tan2x=\frac{2\sin x\cos x}{1-2\sin^2x}$,Prove that $$\tan2x=\frac{2\sin x\cos x}{1-2\sin^2x}$$ I thought that I could simply write $\sin2x$ divided by $\cos 2x$ gives $\tan 2x$ but the question carries 3 marks. Is there a descriptive proof to solve this?,['trigonometry']
2760176,Why does logarithmic differentiation work even if logs are not defined for negative numbers?,"Say for instance, we have a function $y = x^3$, the derivative of which is $\frac{\mathrm{d}y}{\mathrm{d}x} = 3x^2$. Now, say I want to do a logarithmic differentiation:
$$
\ln(y) = \ln(x^3) \hspace{10pt}\implies\hspace{10pt} \ln(y) = 3\ln(x),
$$
so by implicit differentiation with respect to $x$,
$$
\frac{1}{y}\frac{\mathrm{d}y}{\mathrm{d}x} = 3\cdot\frac{1}{x} \implies \frac{\mathrm{d}y}{\mathrm{d}x} = y\cdot 3 \cdot \frac{1}{x} = x^3\cdot \frac{3}{x} = 3 x^2. 
$$ Why does this work, even though $\ln(x)$ function is not defined for negative values of $x$? Or does doing differentiation using logarithms limit the result to positive values for $x$ only which in this case is yielding the correct result nonetheless? For some reason, the authors of articles I found regarding the same, don't seem to be too concerned regarding this  problem. Any help would be appreciated, Thankyou.","['derivatives', 'logarithms', 'calculus']"
2760217,Serre duality in derived category,"Let $X$ be a smooth projective variety over a field $k$ , and $\omega_X$ its canonical bundle. Denote by $D^b(X):=D^b(\mathbf{Coh})$ the bounded derived category of coherent sheaves on $X$ . Theorem: For any two comples $\mathcal{E}^\bullet,\mathcal{F}^\bullet$ in $D^b(X)$ there exists a functorial isomorphism $$\eta : Ext^i(\mathcal{E}^\bullet,\mathcal{F}^\bullet) \to Ext^{n-i}(\mathcal{F}^\bullet,\mathcal{E}^\bullet\otimes \omega_X)^*,$$ where $^*$ denotes the vector space dual. This theorem can be found in D. Huybrechts's Fourier-Mukai Transforms in Algebraic Geometry (theorem 3.12). It basically says that the exact functor $$\cdot\otimes\omega_X[n] : D^b(X) \to D^b(X)$$ is a Serre functor in the sense of Bondal and Kapranov (see here for instance). Now my question is: how can we prove this theorem? I know that this is a particular case of Grothendieck-Verdier duality, but is it possible to avoid it? My attempts: I know the classical Serre Duality (Harthorne's Algebraic Geometry , III.7), which in particular says that the theorem is true when $\mathcal{E}^\bullet = \mathcal{E}$ is a locally free sheaf and $\mathcal{F}^\bullet=\mathcal{F}$ is any coherent sheaf. For the general case, I tried to use the definition: $$Ext^i(\mathcal{E}^\bullet,\mathcal{F}^\bullet) = H^i(RHom^\bullet(\mathcal{E}^\bullet,\mathcal{F}^\bullet)),$$ where $Hom^n(A^\bullet,B^\bullet)=\bigoplus Hom(A^k,B^{k+n})$ with $d(f)=d_B\circ f - (-1)^nf\circ d_A$ . I tried to replace $\mathcal{F}^\bullet$ by a quasi-isomorphic complex of injectives (of quasi-coherent sheaves) and $\mathcal{E}$ by a quasi-isomorphic complex of locally free sheaves so I can use the classical Serre duality on each summand of the direct sum, but I'm not sure this is a way to start. If someone could give me some help I would really appreciate. EDIT: Thanks to the answer of @mayer_vietoris, I tried the following. Suppose $\mathcal{E}^\bullet$ is a complex of locally free sheaves and $\mathcal{F}$ is a complex of injectives so that $RHom^\bullet(\mathcal{E}^\bullet,\mathcal{F}^\bullet)=Hom^\bullet(\mathcal{E}^\bullet,\mathcal{F}^\bullet).$ $$\begin{align*}
Hom^i(\mathcal{E}^\bullet,\mathcal{F}^\bullet) &= \bigoplus_k Hom(\mathcal{E}^k,\mathcal{F}^{k+i}) \\
&= \bigoplus Ext^0(\mathcal{O}_X,(\mathcal{E}^k)^ \vee\otimes\mathcal{F}^{k+i})\\
&\simeq \bigoplus Ext^n(\mathcal{F}^{k+i},\mathcal{E}^k\otimes\omega_X)^* & \text{(by Serre Duality)}\\
&\simeq \bigoplus Hom(\mathcal{F}^{k+i},\mathcal{E}^k\otimes\omega_X[n])^*\\
&\simeq Hom^{n-i}(\mathcal{F}^\bullet,\mathcal{E}^\bullet\otimes\omega_X)^*.
\end{align*}$$ Up to a replacement of $\mathcal{E}^\bullet\otimes\omega_X$ by a complex of injectives, I would like to conclude by replacing $Hom^i(\dots$ by $H^i(Hom^\bullet(\dots$ and similarly with $Hom^{n-i}$ . Thus I obtain the desired equality. Am I wrong somewhere?","['derived-categories', 'algebraic-geometry', 'duality-theorems']"
2760228,What shape is the locus of a 3D corner with a circular ring that touches the sides of the corner?,"Hard for me to draw this, but I happen to have my wedding ring, and the corner of a table. I can put the ring over the corner, the ring touching the three edges of the table, with the apex of the corner sticking through. If I slide the ring around while three points on it touch the edges, the apex moves around and there's a locus of points that the apex can be on. Relative to the circle, is it part of a sphere? Also, is there another name for this problem?",['geometry']
2760285,Find all elements in a cyclic group of a specific order?,"I am looking for the number of elements of order 4 in a cyclic group with $4k$ elements. I have tried everything I could think of.  I know that the number of order 4 elements is divisible by $\varphi(4) =2$ and I found something online that said the number of $x$ such that $x^4 =1$ is given by the possible values for $\operatorname{ord}(x^4) = \frac{\operatorname{ord}(x)}{\gcd(4,4k)}$ which gives $\gcd(4,4k) = 4$, but I'm lost.","['finite-groups', 'abstract-algebra', 'group-theory']"
2760326,Is this proof of Euler's formula correct?,"Let 
$$y=\cos \phi+i\sin \phi  \tag{1}$$ Differentiating both sides of equation (1) with respect to $\phi$, we get, $$\begin{align}
\frac{dy}{d\phi} &=-\sin \phi+i\cos \phi \\
&=i(\cos \phi-\frac{1}{i}\sin \phi) \\
&=i(\cos\phi+i\sin \phi) \\
&=iy \\
\implies\frac{1}{y}dy &=i\;d\phi \tag{2}
\end{align}$$ Integrating both sides of equation (2), we get, $$\begin{align}
\int\frac{1}{y}dy&=\int i\;d\phi \\
\implies \ln(y)&=i\phi+c \tag{3}
\end{align}$$ Substituting $\phi=0$ in equation (1), we get, $$y=\cos 0+i\sin 0 \implies y=1 \tag{4}$$ Substituting $\phi=0$ and $y=1$ in equation (3) we get, $$\ln(1)=c \implies c=0 \tag{5}$$ Substituting $c=0$ in equation (3) we get, $$\begin{align}
\ln(y)&=i\phi \tag{6}\\
\implies e^{i\phi}&=y \tag{7}\\
\therefore e^{i\phi}&=\cos \phi+i\sin \phi \tag{8}
\end{align}$$ I found this proof in a book. I think that there is a problem. In $(3)$ and $(6)$, shouldn't $\ln(y)$ be $\ln|y|$ instead? Or is it that, for complex numbers, we do not take the absolute value of the number within the $\ln$?","['derivatives', 'complex-numbers', 'calculus', 'complex-analysis', 'integration']"
2760329,When is a homomorphism between two group presentations an isomorphism?,"Because this is an assignment for a class I'm taking I won't specify the groups, but I will abstract the question a little bit since I can't find an answer to this online or in my recommended text. I have two groups on two generators each with a single relation, say $\langle\ a,b\ |\ r_1\ \rangle$ and $\langle\ x,y\ |\ r_2\  \rangle$. I have defined a homomorphism between these two groups that sends the relation $r_1$ to $r_2$, but I'm struggling to show that this is injective and surjective. Is there a common method to solving this sort of problem? (Edit: The homomorpism is defined by sending a word $w=w_1\cdots w_n$ to $\eta(w)=\eta(w_1)\cdots\eta(w_n)$)",['group-theory']
2760341,"If we have infinite variance, can the expectation 'mean' anything?",If we have a random variable $X$ with infinite variance $Var(X)$ then how can the expectation $E(X)$ be useful to us? In the sense that our values vary so much from it that it holds no relevance. Maybe an example would clear things up?,"['expectation', 'probability', 'variance']"
2760360,"How many permutations of $\{1, \ldots, n\}$ exist such that none of them contain $(i, i+1)$ (as a sequence) for $i \in {1,...,(n-1)}$?","How many permutations of $\{1, \ldots, n\}$ exist such that none of them contain $(i, i+1)$ (as a sequence of two consecutive entries) for $i \in \left\{1,...,(n-1)\right\}$ ? First thing that comes to my mind is to find all that have $(i, i+1)$ , then subtract that from all permutations. But then we can have $(i, i+1, i+2)$ which we subtracted twice, once in $(i, i+1)$ and once in $(i+1, i+2)$ . And so on for $3$ and more. How do I calculate this?","['permutations', 'combinatorics']"
2760371,Why do I care that smooth vector fields over a smooth manifold have a Lie algebra?,"So, I know the following facts: A Lie group is a group and a Manifold, whose group structure is continuous with respect to the Manifold structure The Lie algebra is a vector space with a Lie bracket structure on it. Every Lie group has a corresponding Lie algebra. The Lie algebra represents the ""infinitesimal behaviour"" of the Lie group. Till here, stuff makes sense. However, this is where I lose it: The Vector space of all Vector fields over a Manifold form a Lie algebra with the Lie bracket of vector fields structure. Why do I care about fact 5? Is it because it is ""cute"" that the Lie bracket exists? What do I gain by showing that vector fields have a lie bracket structure?","['lie-algebras', 'differential-geometry', 'differential-topology', 'lie-groups']"
2760385,"What is the Probability Generating Function (PGF) for the ""Matching Problem""?","I've been working on a set of questions that ask me to prove various results regarding probabilities concerning the classic ""matching problem"". There are $n$ letters written to different people, and envelopes correspondingly addressed. The letters are shuffled such that any particular letter-envelope allocation is equally likely as any other. Define a ""match"" if a particular letter is placed in its correct envelope. The question began by letting the notation $M_{n,j}=n!P(A_{n,j})$ represent the number of permutations resulting in $j$ matches out of $n$ letters, where $A_{n,j}$ is the event that $j$ matches have occurred out of $n$ letters. Part a) of the question asked me to show that: $$M_{n,j}={j+1\over n+1}M_{n+1,j+1}$$ I found this easy enough. The next question defined the generating function for the probability of receiving $j$ matches out of $n$ letters: $G_n(z)=\sum_{j=0}^nP(A_{n,j})z^j$, and asked me, using part a) to prove that: $$G_{n+1}(z)=1+\int_{1}^zG_n(w)dw$$ Once again, I had no trouble doing this using the first result. It was the third part of the question, however, that confused me. It read ""hence find the pgf (probability generating function) $G_n(z)$"". The result of the next question leads me to believe that the solution is: $$G_n(z)=\sum_{k=0}^n{(z-1)^k\over k!}$$ That said, I have no idea how to actually reach this conclusion, and would appreciate some help getting there, preferably using properties of generating functions. It would be preferable to avoid using the formula for number of derangements, as we have not covered this in class and therefore is likely not involved in the expected solution. Thanks!","['generating-functions', 'statistics', 'probability', 'combinatorics', 'sequences-and-series']"
2760397,Group action defined on generators.,"In a question for an assignment (specific group but I've abstracted the question for academic integrity). I was given a group $G=\langle\ a,b \mid R\ \rangle$ where $R$ is some set of relations. Then, the question defines a group action on $X$ for each generating element. The first question is then ""Verify that this gives a group action on $X$"". My problem is that it seems like by defining a group action on generators inherently assumes that $e(x)=x$ and $a(b(x))=ab(x)$ from the beginning, so it seems like there is nothing left to show? Since the question only defined the functions $a(x)=?$ and $b(c)=?$, I can't verify that $ab(x)=a(b(x))$, since I wasn't given the action defined by $ab$. Is this a misunderstanding on my part, or do you think it is likely that the question itself is ambiguous?",['group-theory']
2760468,Finding the distribution of the reciprocal of a random variable,"Let $X\sim \text{Exp}(\lambda)$ be an exponentially distributed random variable. 
That is it has the probability density function
$f(x)=\lambda e^{-\lambda x}1_{[0,\infty)}(x)$ and cumulative distribution function
$$F_X(x)=\int_ {0}^x\lambda e^{-\lambda x}=[-e^{-\lambda x}]_{0}^x=1-e^{-\lambda x}$$ Let $Y:= \frac{1}{X}$. We have for $F_Y(x)$:
$$F_Y(x)=\mathbb{P}({Y \leq x})=\mathbb{P}\left(\frac{1}{X}\leq x\right )=\mathbb{P}\left(X\geq\frac{1}{x}\right )=1-\mathbb{P}\left(X < \frac{1}{x} \right)=^!1-F_X\left(\frac{1}{x}\right)$$ The problem at $!$ is that definition of cumulative density function requires a non strict inequality so I don't know why this holds.
Aside from that, how does one get the distribution of $Y$ from the cumulative density function/probability density function? How do we deal with $Y$ at $X=0$ (does $X$ attain $0$ as a value even)","['exponential-distribution', 'inequality', 'probability', 'probability-distributions']"
2760483,Certain types of tangent values,"I was messing around with values of the tangent function and came across something interesting. For example, we have
$$\tan^2(\frac{\pi}{4\cdot2}) = \dfrac{\sqrt{4} - \sqrt{2}}{\sqrt{4} + \sqrt{2}}, \tan^2(\frac{\pi}{3\cdot4}) = \dfrac{\sqrt{4} - \sqrt{3}}{\sqrt{4} + \sqrt{3}}, \tan^2(\frac{\pi}{1\cdot1}) = \frac{\sqrt{1} - \sqrt{1}}{\sqrt{1} + \sqrt{1}}.$$ All of these values satisfy
$$\tan^2(\frac{\pi}{m\cdot n}) = \dfrac{\sqrt{m} - \sqrt{n}}{\sqrt{m} + \sqrt{n}}.$$ How could I go about to find all pairs $(m,n)$ which satisfy the equation?",['trigonometry']
2760510,"How many injective functions from $\{5,6,7,8,9\}$ to itself map $5$ and $6$ to another number?","How many injective functions from $\{5,6,7,8,9\}$ to itself map $5$ to any number other than $5$ and $6$ to any other number than $6$? Let $B=\{5,6,7,8,9\}, f:B\to B$. I think we can solve this by inverting the problem, that is counting the number of injective functions where $5$ maps to $5$ and $6$ maps to $6$. First there're $5!$ injective functions without restrictions. There're $4!$ functions where either $5\to 5$ or $6\to 6$ so there're $2\cdot 4!$ such functions in total. Lastly, there're $3!$ functions where both $5\to 5$ and $6\to 6$. Therefore with restrictions the number of functions is:
$$
5! - 2\cdot 4! + 3!
$$ I'm not sure whether I'm using the inclusion/exclusion principle correctly here.","['relations', 'combinatorics', 'proof-verification']"
2760550,Computing a derivative from a function that involves an integral,"Let $f$ be a function such that
$$f(t)=\int_0^\infty \frac{\sin(x^2)e^{-tx^2}}{x^2}\,dx,\;t>0:$$
find $f'(t)$. My attempt:
$$\begin{align}
f(t)&=\int_0^\infty\frac{\sin(x^2)e^{-tx^2}}{x^2}\,dx\\
\frac{df}{dt}&=\frac{d}{dt}\int_0^\infty\frac{\sin(x^2)e^{-tx^2}}{x^2}\,dx\\
&=\int_0^\infty\frac{d}{dt}\frac{\sin(x^2)e^{-tx^2}}{x^2}\,dx\\
&=\int_0^\infty\frac{\sin(x^2)}{x^2}\frac{d(e^{-tx^2})}{dt}\,dx\\
&=-\int_0^\infty\sin(x^2)\,e^{-tx^2}\,dx.
\end{align}$$
Then I used that $2i\sin(x)=e^{ix}-e^{-ix}$ and $\displaystyle\int_{-\infty}^{+\infty}e^{-ax^2}\,dx=\sqrt{\frac{\pi}{a}}$ to achieve
$$\begin{align}
\int_0^\infty\sin(x^2)\,e^{-tx^2}\,dx&=\int_0^\infty\frac{e^{ix^2}-e^{-ix^2}}{2i}\,e^{-tx^2}\,dx\\
&=\frac{1}{2i}\int_0^\infty\left[e^{(i-t)x^2}-e^{-(i+t)x^2}\right]\,dx\\
&=\frac{1}{2i}\left[\int_0^\infty e^{(i-t)x^2}\,dx-\int_{0}^{\infty}e^{-(i+t)x^2}\,dx\right]\\
&=\frac{\sqrt{\pi}}{4i}\left(\sqrt{\frac{1}{t-i}}-\sqrt{\frac{1}{t+i}}\right).
\end{align}$$
Is my answer correct? And how can I approach this problem?","['improper-integrals', 'definite-integrals', 'calculus']"
2760558,Verify language that i found of this automata,"Sorry for my bad english. Automata: My answer:
$$L = \{0^n, 0^n1X \mid n = 1,2,3\dots\}$$ X is any strings that is not empty.","['automata', 'discrete-mathematics']"
2760572,What's the Probability of a drunk man open a door with $n$ possible keys?,"I have this following problem in my problem set and I would like to check if my work is in the right directio. A drunk man with $n$ keys wants to open his door and tries the keys at random. Exactly one key will open the door. Find the mean number of trials if a) unsuccessful keys are not eliminated from further selections; b) unsuccsesful keys are eliminated It seems clear to me that in the first case we have a Geometric distribution with parameter $1/n$ , so the expected number of trials is just $n$ . For the second case, my reasoning follows. Let $X$ denote the number of trials until he opens the door. $P(X = 1) = 1/n$ $P(X = 2) =(n-1)/n \cdot 1/n-1 = 1/n$ $P(X = 3) = (n-1)/n \cdot (n-2)/(n-1) \cdot 1/(n-2) = 1/n$ , and so on. I'm inclined to say that, in the second case, the probabilities over the possible $n$ values of $X$ are uniformly distributed. If this is case, then the average number of trails should be $(n+1)/2$ . Does it seem correct? If not, how to do it? Thanks in advance!!","['probability', 'proof-verification', 'probability-distributions']"
2760589,Uniform convergence of ${(1-\frac{x^2}{n})^n}$,"Uniform convergence of: $$f_n(x):={(1-\frac{x^2}{n})^n}$$ (a) In a closed interval $[-L, L]$ as $L>0$ . (b) In $\mathbb{R}$ . My try: There is a pointwise convergence to $e^{-x^2}$ . Obviously, there is no uniform convergence in $\mathbb{R}$ as $\lim\limits _{x\to \infty }|f_n(x)|=\infty$ . $\;$ Thus, $\sup \limits _{x\in\mathbb{R}}|f_n(x)-e^{-x^2}|= \infty$ Can anyone give a direction for a closed interval?","['uniform-convergence', 'real-analysis', 'sequences-and-series', 'calculus']"
2760603,Prove that $\lim_{n \to \infty} \frac{n}{(n!)^\frac{1}{n}} = e $ [duplicate],"This question already has answers here : Finding the limit of $\frac {n}{\sqrt[n]{n!}}$ (11 answers) Closed 5 years ago . I have solved the problem in just 2 lines using a theorem which asserts that ""Let ${u_n}$ be a real sequence such that $u_n > 0 \forall n \in \mathbb{N}$ and $\lim_{n \to \infty} \frac{u_{n+1}}{u_n} = \ell$ (finite of infinite). Then $\lim_{n \to \infty} (u_n)^{1 \over n} =\ell$ "" To prove the aforesaid limit, I fix $u_n={n^n \over n!}$. Then $u_n>0 \forall n \in \mathbb{N}$ and $\lim_{n \to \infty}\frac{u_{n+1}}{u_n}= \lim_{n \to \infty}(1+{1 \over n})^n=e$. Then it follows from the above theorem that $\lim_{n \to \infty} (u_n)^{1 \over n} =e$  i.e. $ \lim_{n \to \infty} \frac{n}{(n!)^\frac{1}{n}} = e $. (Proved) But I am trying to prove it without using the theorem. I am trying to get a generic proof. Can anyone provide a proper wayout for this? Thanks for your help in advance.","['real-analysis', 'exponential-function', 'sequences-and-series']"
2760660,Connected semi-riemannian manifold is an Einstein manifold.,"I'm reading the proof of the next proposition: A semi-riemannian manifold $M$ is an Einstein manifold provided $Ric=cg$ for some constant $c.$ If $M$ is connected, $n=dim(M)\geq 3$ and $Ricfg=fg,$ then $M$ is Einstein. The proof is the next: Suposse $Ricfg=fg.$ Because of contraction $S=nf.$ Then, for the second Bianchi identity $dS=2divRic,$ so $ndf=2df.$ Then $f$ is constant. I have two doubts: How the contraction gives the equality $S=nf?$ I don't get it. I've tried utilizing the second identity of Bianchi to get $dS=2divRic,$ but I don't get any useful. If the previous holds, because of $M$ is connected and $n\geq 3$ the equality $ndf=2df$ implies $df=0.$ Then $f$ is constant and the proof is done. Any kind of help is thanked in advanced.","['semi-riemannian-geometry', 'differential-geometry']"
2760711,Find the universal covering of $\mathbb{R}P^2\vee\mathbb{R}P^2$,"Find the universal covering of $\mathbb{R}P^2\vee\mathbb{R}P^2$ I know that $\mathbb{R}P^2\cong \mathbb{S}^2/\sim$ for antipodal action and that $\pi_1(\mathbb{R}P^2)=\mathbb{Z}_2$, with which $\pi_1(\mathbb{R}P^2\vee\mathbb{R}P^2)=\mathbb{Z}_2*\mathbb{Z}_2$, so the universal covering of $\mathbb{R}P^2\vee\mathbb{R}P^2$ corresponds to the trivial subgroup of $\mathbb{Z}_2*\mathbb{Z}_2$, I know that $\mathbb{R}P^2\vee\mathbb{R}P^2$ has infinite covering spaces like for example: $\mathbb{R}P^2\vee\mathbb{R}P^2, \mathbb{S}^2\vee\mathbb{S}^2, \mathbb{S}^2\vee\mathbb{S}^2\vee\mathbb{S}^2$ and besides I know that an infinite chain of $\mathbb{S}^2$ glued tangent is the universal covering space but I do not know how to prove this formally in a precise way, I know that the universal covering space fulfills that it is covering space and that it is also simply connected, but my doubt is that why the space Universal covering is not $\mathbb{S}^2\vee\mathbb{S}^2$? Is it simply connected? Why is an infinite chain of spheres stuck tangentially simply connected?","['abstract-algebra', 'covering-spaces', 'fundamental-groups', 'algebraic-topology', 'general-topology']"
2760727,Max area: Quadrilateral with fixed perimeter and interior angle,"Edit (May 1, 2018): There appears to be an implicit assumption related to convexity in several of the answers posted thus far; see the answer and image posted here . So: Let us restrict to the case in which the quadrilateral is convex. My post is based on a tweet linking to a blog post where the following problem is posed: A [convex] quadrilateral has perimeter $60$ and a $30^{\circ}$ angle. What is the maximum possible area? In the comments, there is a link to a GeoGebra applet for exploring this problem. Tinkering with the applet led me to believe that the maximization occurs when the other three angles are each $110^{\circ}$, but I neither possess a proof that this is optimal, nor have computed the exact area (in closed form) for this case. I would appreciate an answer that broaches the above special case, although I think it is reasonable to ask about a natural generalization for quadrilaterals; in either scenario, a proof or a link to an already existing one would be great. Generalization: A [convex] quadrilateral has perimeter $N$ and a $d^{\circ}$ angle. What is the maximum possible area? (So, as a well-known example, for the case in which $d = 90$, the maximum possible area occurs for a square with side-length $N/4$; therefore, the max area is $N^2/16$.)","['optimization', 'reference-request', 'trigonometry', 'convex-optimization', 'geometry']"
2760771,How do I prove the number of derangements formula $nD_{n - 1} + (-1)^n$ intuitively?,"I found that the series of number of derangements follows a certain sequence that can be expressed as such : $nD_{n-1} +(-1)^n$ . Now, I found others saying it can be expressed as follows $(n-1)(D_{n-1}+D_{n-2})$ . I have seen some people explaining the second formula intuitively. What I am curious about is , whether there is a way to explain the FIRST formula intuitively. I want an explanation for the first  formula. Meaning, I am trying to find the logic for it in such a way that the expression as it's written would be understood. I started somewhat by saying that there is some logic behind the number of derangements of $D_{n-1}$ to be multiplied by $n$ because the new object has $n$ places to be placed in while $n-1$ objects are placed as was ordered in $D_{n-1}$ . But I can't seem to find the logic behind the $-1^n$ . I started to think that maybe for odd numbers I have to reduce one due to the middle? But I am not sure. I want a logical/intuitive proof that would prove MY (first) formula and I want it to be followed somehow in the way I started. I don't want completely different proofs. But can someone please make some sense of my proof or show why it's wrong? Or show other intuitive thing to my formula?","['combinatorics', 'derangements', 'discrete-mathematics']"
2760786,find the minimum value given constraints,"Let $z$ be a complex number such that $\dfrac{z-i}{z-1}$ is purely imaginary. Find the minimum value of $|z-(2+2i)|$ . Source: ISI 2017 BMATH UGA $$$$ Attempt: Since $\dfrac{z-i}{z-1}$ is purely imaginary, $$$$ $$\dfrac{z-i}{z-1}+\overline{\left(\dfrac{z-i}{z-1}\right)}=0$$ This reduces to $$|z|^2=\Re(z)+\Im(z)$$ This represents the locus of $z$ on the Argand Plane. The minimum value of $|z-(2+2i)|$ will be the shortest distance between any point $z$ lying on $|z|^2=\Re(z)+\Im(z)$ and the point $(2,2)$ on the Argand Plane. $$$$ Unable to recognize the locus represented by $|z|^2=\Re(z)+\Im(z)$ . How to identify locus represented by $|z|^2=\Re(z)+\Im(z)$ without reducing to Cartesian Coordinates?",['algebra-precalculus']
2760799,"Showing that $(\frac{\mathrm d}{\mathrm dx}+1)^{-1}$ is bounded on $L^2(0,\infty)$","I wish to show that if we consider the symmetric operator $L= i\frac{\mathrm d}{\mathrm dx}$ on $L^2((0,\infty))$, then the resolvent $R(-i) = (L+i)^{-1}$ is everywhere defined on $L^2(0,\infty)$. This reduces to showing that for any $v\in L^2(0,\infty)$, we can solve for $u\in L^2(0,\infty)$ such that 
$$
\frac{\mathrm d u}{\mathrm dx}(x)+u(x)=v(x).
$$
It is easy to see that we can use Duhamel's formula to get the formula
$$
u(x)=\int_0^x\! e^{y-x}v(y)\,\mathrm dy.
$$
so I wish to show that $T:v\mapsto u$ is bounded on $L^2$. I would like to apply Hilbert-Schmidt type bounds here, but unfortunately, the kernel $K(x,y)=1_{0\le y\le x}e^{y-x}$ does not lie in $L^2((0,\infty)^2)$. How would one prove that $T$ is bounded?","['functional-analysis', 'operator-theory', 'partial-differential-equations']"
2760805,Product Measures and Cartesian Products,"I'm using Royden & Fitzpatrick's Real Analysis , and I came across something that, for the life of me, I cannot make sense of.  Background: Start by letting $(X,\mathcal{A},\mu)$ and $(Y,\mathcal{B},\nu)$ be two reference measure spaces.  A measurable rectangle is a subset $A\times B \subseteq X\times Y$ where $A\in \mathcal{A}$, $B\in\mathcal{B}$, and $\mu(A)<\infty$, $\nu(B)<\infty$. Now for the issue: Lemma 1 $\quad$Let $\{A_{k}\times B_{k}\}_{k=1}^{\infty}$ be a countable disjoint collection of measurable rectangles whose union also is a measurable rectangle $A\times B$.  Then $$\mu(A)\times \nu(B) = \sum_{k=1}^{\infty}\mu(A_{k})\times\nu(B_{k}).$$ Okay fine, the lemma seems reasonable in and of itself. As does most of the proof, except for this step in the beginning: Proof $\quad$ Fix a point $x\in A$. For each $y\in B$, the point $(x,y)$ belongs to exactly one $A_{k}\times B_{k}$. Therefore we have the following disjoint union: $$B=\bigcup_{\{k\,:\,x\in A_{k}\}}B_{k}\qquad\qquad(1)$$
... This doesn't quite make sense to me. Take for example the disjoint rectangles with $m$ the Lebesgue measure on $\mathbb{R}$:  $A_{1}\times B_{1} = [1,3]\times [1,3]$ and $A_{2}\times B_{2} = [4,5]\times [1,4]$ (see picture -- Note that I've done the natural thing and $A_{1},A_{2}$ are on the $x$-axis and $B_{1},B_{2}$ are on the $y$-axis.) Now say I start by fixing a point, say $2\in A$. Interpreting the union (1) as written, the only set involved in the union is $B_{1}$, since $2$ is only in $A_{1}$. Interpreting the union this way, I don't get all of $B$, as clearly $B$ contains the point $y=4$ for instance, and $4\notin B_{1}$. On the other hand, if I interpret the $x$ as not really ""fixed"" as they say, but rather as moving along with $k$, then the union is not disjoint as claimed, because then $B=B_{1}\cup B_{2}$ yet $B_{1}\cap B_{2}\neq\emptyset$. Now, I am aware that $(A_{1}\times B_{1})\cup (A_{2}\times B_{2}) \subseteq (A_{1}\cup A_{2})\times (B_{1}\cup B_{2})$. But basically my questions are: (1) How should I interpret this union?  Am I interpreting this wrong or is there some issue with the notation? 
(2) Is there a better way to denote this that gets the point across, i.e., the expression of $B$ as a countable disjoint union? If so, what is it, and how can I transform that into what is given here? I suspect I am missing something fundamental here, but I am not sure.  Any commentary or intuition is welcome, and thank you in advance.","['real-analysis', 'measure-theory', 'elementary-set-theory']"
2760888,When ODE tells more than the explicit solution.,"""ODE is not just about 'solving' an equation and spitting out a (probably nasty) formula"" -- this is what I want my (undergraduate) students to learn from my course this summer. One example I am looking for is a scenario where one extracts info about a function from the ODE it satisfies much more easily than from the solution's explicit formula. There are easy example to see this. For instance, the IVP $y'=y; y(0)=1$ tells us that the function will be increasing on zero to infinity, by taking another derivative that it will be concave up, etc. However, one may rightly argue that $e^x$ which is the solution easily gives these properties. So, I am looking for a less trivial, yet, interesting example where it is much easier to understand a function from its ODE than from its explicit formula . Do you have such examples? I will appreciate them. **The example may be important from computational/numerical point of view.""","['numerical-methods', 'real-analysis', 'ordinary-differential-equations']"
2760910,What is the probability that it takes more than seven rolls of a fair $6$-sided die to roll a six?,"What is the probability that it takes more than seven rolls of a fair $6$-sided die to roll a six? The probability of rolling a six per roll is $1/6$. Therefore, the probability of rolling something other than a 6 is $5/6$. So wouldn't the probability that you don't roll a six within the first $7$ rolls just be $(5/6)^7$?",['probability']
2760933,How can it be true that $|z|^2 = 1$ for every complex number $z$?,"$$z=x+iy$$
$$\frac{z}{1+z}=\frac{z\bar{z}}{\bar{z}+z\bar{z}}=\frac{|z|^2}{|z|^2+\bar{z}}$$
$$z\bar{z}=|z|^2\implies\bar{z}=\frac{|z|^2}{z}$$
$$\Rightarrow \frac{|z|^2}{|z|^2+\bar{z}}=\frac{|z|^2}{|z|^2+\frac{|z|^2}{z}}=|z|^2\Bigg(\frac{1}{1+\frac{1}{z}}\Bigg)=|z|^2\Bigg(\frac{1}{\frac{z+1}{z}}\Bigg)=|z|^2\Bigg(\frac{z}{z+1}\Bigg)$$
$$\boxed{\therefore \Bigg(\frac{z}{1+z}\Bigg)=|z|^2\Bigg(\frac{z}{1+z}\Bigg)}$$ This implies that $|z|^2=1$. Everything checks out but the result seems strange, in the sense that is the following correct, then? 
$$|z|=1 ; \,x,y\in â„$$","['algebra-precalculus', 'complex-numbers']"
2760951,Central Limit Theorem for Non-degenerate U-Statistics,"Let $X_1,X_2,...$ be i.i.d. random variables and $f\colon\mathbb R^{r} \rightarrow \mathbb R$ be a symmetric function of $r$-variables. For each $n \ge r$, the associated U-statistic is defined as, $$U_n := {n \choose r}^{-1}\sum_{1\le i_1<i_2<...<i_r\le n}f(X_{i_1},X_{i_2},...X_{i_r}),$$ 
which is clearly a symmetric function of $X_1,X_2,...X_n$. Assume, 
$$Ef(X_1,X_2,...X_n) = 0,\quad E{f(X_1,X_2,...X_n)}^2 < \infty$$
and for $g(x):= Ef(x,X_2,...X_n)$ we have 
$$\eta^2 := Eg(X^2_1)>0$$
$$\text{Show that} \quad \frac{\sqrt{n}U_n}{r\eta} \rightarrow N(0,1) \quad \text{in distribution} \quad \text{as} \; n\rightarrow \infty $$ Is this the central limit theorem for non-degenerate U-statistics? Is there any reference for this type of CLT for U-statistics? $\textbf{My initial idea is that}$ Maybe I can firstly prove $\sqrt{n}\big|\big|U_n -\frac{r}{n}\sum^n_{i}g(X_i)\big|\big|_2 \rightarrow 0$ and use some classical central limit theorem. But I am stuck in proving the first part. $\textbf{So my question is }$ how to prove $\sqrt{n}\big|\big|U_n -\frac{r}{n}\sum^n_{i}g(X_i)\big|\big|_2 \rightarrow 0$ ?? Could you please give me some details about that? Thank you!","['probability-theory', 'asymptotics', 'central-limit-theorem', 'statistics', 'probability']"
2760952,Converse Lagrange's Theorem for abelian groups,"I just came up with a very simple proof of the converse Lagrange's Theorem for abelian groups. Here is a sketch: First, denote by $\pi_p$ the quotiening out by (some) element of order $p$. Now, if $A$ is an abelian group of order $n$ and $d\mid n$, with $d =p_1 p_2 ...p_k$ (not necessarily distinct primes), then we can construct a chain of homomorphisms
\begin{array}{lclcl}
A \stackrel{\pi_{p_1}} \longrightarrow A_1 \stackrel{\pi_{p_2}} \longrightarrow A_2 \stackrel{\pi_{p_3}} \longrightarrow ... \stackrel{\pi_{p_k}} \longrightarrow A_k
\end{array}
Such homomorphisms exist by the Cauchy's theorem. So, if $\pi=\pi_{p_k}\circ\pi_{p_{k-1}}\circ ...\circ\pi_{p_1}$, then $\mid\operatorname{im}\pi|=n/d$, therefore $\mid\ker\pi\mid$=d. It looks simpler than what I have seen before, so I am wondering if I am fooling myself here.","['abelian-groups', 'group-theory']"
2761022,"Characterizing derivatives and other functions as ""best local approximations""","People often say that the derivative of a function at a point is its ""best"" linear (or affine) approximation around that point. This seems like a good intuition, but I've never seen it made precise. What I'd hope for is a sort of universal property, given a class of possible approximations, that specifies which approximation is the best one, if it exists. I'd want to get continuity from the class of constant functions, derivatives from the class of affine functions, and in general the kth-order Taylor polynomial from the class of polynomials of degree up to k. One possible definition of one approximation being better than another might be that its error is smaller at every point in some neighborhood. That is: Given some class $G$ of functions $: X \to Y$, $f : X \to Y$, and $x \in X$, The best $G$-approximation of $f$ at $x$ is a function $g_0 \in G$ such that for all $g \in G$, there's a neighborhood $A$ of $x$ such that for all $x' \in A$, $d(g_0(x'), f(x')) \le d(g(x'), f(x'))$. (In particular, if we say that a function is continuous if it can be approximated by a constant function, we get this somewhat unusual definition of continuity: $f : X \to Y$ is continuous at $x \in X$ if for all $y \in Y$, there's a neighborhood $A$ of $x$ such that for all $x' \in A$, $d(f(x'), f(x)) \le d(f(x'), y)$.) Does this definition do what I want? Can it be generalized to non-metric spaces? Or is there another definition of ""best approximation"" that works better?","['derivatives', 'general-topology', 'metric-spaces', 'universal-property']"
2761047,"Calculate $\int_0^{\infty } \left(x-\log \left(e^x-x\right)\right) \, dx$","Calculate the following integral:
$$\int_0^{\infty} \left(x-\log \left(e^x-x\right)\right) \ \mathrm{d}x.$$ For recreational purposes, I calculate several interesting integrals, and I came across this case that blocks me. One can immediately notice that $\log \left(e^x-x\right)\sim_{+\infty} x$ (since $\lim_{x\to +\infty}\frac{x}{\log(e^x-x)}=1$). But I am unable to calculate the indefinite integral of this function or to establish the value of this improper integral in any other way. Nevertheless, it is of course possible to calculate the result numerically ($\approx 1.15769475$) to an arbitrary precision, but I am more interested in the exact value and the method to get it.","['improper-integrals', 'integration', 'definite-integrals', 'calculus']"
2761053,Difference between $G$-module homomorphisms and $G$-linear maps,"What is the difference between a $G$-module homomorphism and a $G$-linear map?  My understanding is that both are linear maps between vector spaces (say, from $V$ to $W$) and both preserve the action of the group $G$ (i.e., for all $g$ in $G$, $\rho(g*v)=g*\rho(v)$ for all $v$ in $V$).","['representation-theory', 'abstract-algebra', 'group-theory']"
2761091,Determining whether a sequence of coin flips is random,"Say we have observed a finite sequence of coin flips. Is there a metric for how likely this sequence is generated by a truly random coin flip. For example, if we flip a coin 1000 times presumably seeing 500 heads and then 500 tails is less likely than a random assortment of Heads and Tails. Also, presumably we would not see every even flip be a tails and every odd flip to be a heads.","['probability', 'sequences-and-series', 'probability-distributions']"
2761178,Check or falsify: there is a $C^\infty$ surjective map $S^1 \to S^1 \times S^1$. [duplicate],"This question already has answers here : No Smooth Onto Map from Circle to Torus (2 answers) Closed 4 years ago . Check or falsify: There is a $C^\infty$ -map $S^1 \to S^1 \times S^1$ that is surjective. Comments: I think it's not true, because $\dim S^1 = 1$ and $\dim S^1 \times S^1 = 2$ but I do not know how to justify.","['manifolds', 'differential-geometry', 'geometry']"
2761193,How to prove that the categorical definition of subgroup generated by a subset in Aluffi's book is well-defined?,"In Aluffi's book ""Algebra: Chapter 0"", he uses the categorical definition of free group in pp. 71 , also see in wiki . This defines the free group up to group isomorphism. This is easy to get through. Now the problem is, he also use this to define the subgroup generated by a subset in pp. 81 . I put it here: Definition (Subgroup generated by a subset). Let $G$ be a group. If $A\subset G$ is any subset, we have a unique group homomorphism
  $$\varphi_A: F(A)\to G,$$
  by the universal property of free group. The image of this homomorphism is a subgroup of $G$, the subgroup generated by $A$ in $G$, ofter denoted $\langle A\rangle$. This will naturally lead to a doubt of the well-definedness, i.e., does this definition depend on the choice of the free group $F(A)$ that is unique up to group isomorphism? I don't know how to prove it to be well-defined. What I know is that if one can prove the well-definedness, then it's easy to prove that the categorical definition of generated subgroup is equivalent to other two definitions which just follows the categorical one in Aluffi's book, see also here . Can anyone give some clues or hints on the well-definedness? TIA!","['category-theory', 'abstract-algebra', 'group-theory']"
2761206,About the relation $\tan^{-1} x= 2\tan^{-1}\left(x+\sqrt{1+x^2}\right)-\frac\pi2$,"It is well known that 
$$\int\frac{1}{1+x^2}\,\mathrm{d}x=\tan^{-1}x+C \tag{1}$$ However, I integrated this differently and got an unusual result. Suppose we make the substitution $x=\sinh\theta$ and $\mathrm{d}x=\cosh\theta\,\mathrm{d}\theta$ so the integral becomes $$\int\frac{\cosh\theta}{\cosh^2\theta}\,\mathrm{d}\theta=\int\frac{1}{\cosh\theta}\,\mathrm{d}\theta \tag{2}$$ By the definition of $\cosh\theta$, we can rewrite this as $$\int\frac{2e^\theta}{e^{2\theta}+1}\,\mathrm{d}\theta=2\tan^{-1}e^\theta+C \tag{3}$$ Using the fact that $e^\theta=\cosh\theta+\sinh\theta$, we get $e^\theta=x+\sqrt{1+x^2}$, so the answer is then $$2\tan^{-1}\left(x+\sqrt{1+x^2}\right)+C \tag{4}$$ Equating $(4)$ with $(1)$, we have $$2\tan^{-1}\left(x+\sqrt{1+x^2}\right)+C=\tan^{-1}x \tag{5}$$ Plugging in $x=0$, we find $C=-\frac\pi2$. We now have the following strange relationship $$\tan^{-1} x= 2\tan^{-1}\left(x+\sqrt{1+x^2}\right)-\frac\pi2 \tag{$\star$}$$
  This leads me to wonder: Why is this true geometrically, and does this relationship extend into the complex plane?","['integration', 'trigonometry', 'trigonometric-integrals', 'calculus']"
2761212,Solving given initial value problem using the method of Laplace Transforms $y''+y=f(t)$ where $y(0) = 0$ and $y'(0) = 1$,"I have the problem asking me to solve the initial value problem using the method of Laplace Transforms given
$$ y''+y=f(t); \ \ \ \ \ y(0) = 0, y'(0)=1 $$
where
$$ f(t)=\begin{cases} 0,&  0<t<1 \\
 1,& 1< t < 2 \\
 0,&  2 < t 
\end{cases}
$$ I took the Laplace of both sides
$$ L(y'') + L(y)=L(f)$$
I didn't bother to include the 2 other parts of the right side of the equation since they are both multiplied by 0. The result came out to be:
$$ (s^2Y(s)-(s)(0)-(1)) + Y(s) = \frac{e^{-s}-e^{-2s}}{s} $$
then
$$ Y(s)(s^2+1)= \frac{e^{-s}-e^{-2s}}{s}+1$$
then
$$ Y(s)= \frac{e^{-s}-e^{-2s}}{s(s^2+1)}+\frac{1}{s^2+1} $$ From here, I believe I need to take the inverse Laplace to get my final answer. While I know that the 2nd term will come out to be sin(t) once I take the inverse Laplace, I'm unsure of how to go about the first one. Any help would be greatly appreciated!",['ordinary-differential-equations']
2761229,"Use residues to solve this real integral:$\int_0^{2\pi}\arctan\left[\frac{\sin\left(\theta\right)}{\cos\left(\theta\right)+3}\right]\,d\theta$","I came across the following integral
$$\int_0^{2\pi}\arctan\left[\frac{\sin\left(\theta\right)}{\cos\left(\theta\right)+3}\right]\,d\theta$$
in my Complex Analysis book regarding the evaluation of integrals of the form
$$\int_0^{2\pi}F(\sin(\theta),\cos(\theta))\,d\theta.$$ I noticed that, using the subsitution $u=\theta-\pi$, we can express the integral as
$$\int_{-\pi}^{\pi}\arctan\left[\frac{-\sin\left(u\right)}{3-\cos\left(u\right)}\right]\,du$$
which is an odd function being integrated in a symmetrical interval about zero, so the value of the integral is $0$. Now, even though this solution is much quicker, I was interested in the use of residues and contour integration. Using the subsitution $z=e^{i\theta}$, I was able to write it as 
$$\int_Ciz^{-1}\arctan\left[\frac{i(z^2-1)}{z^2+6z+1}\right]dz$$
where $C$ is the circle of radius $1$ centered at the origin. So if we set
$$f(z)=\frac{i\arctan\left[\frac{i(z^2-1)}{z^2+6z+1}\right]}{z}$$
one can see that $z=0$ is the only possible singularity inside $C$. However, both numerator and denominator are not defined at such point. So how would I go about solving this integral with the aid of residues?","['complex-analysis', 'integration', 'residue-calculus']"
2761248,How to show that the space 'line with two origins' is path connected?,"Consider the equivalence relation on $\mathbb R \times \{0,1\}$ that identifies $(x,0)$ with $(x, 1)$ whenever $x \neq 0$. Let $L$ be the quotient space. This space is called line with two origins. From the picture of it, I understand that it is path connected but analytically how can we show it? Any help is appreciated.  Thank you.","['algebraic-topology', 'general-topology']"
2761253,find the integral $\int ^\infty_0e^{-xu}\frac{\sin u}{u}du$,"Find the integral $$\int ^\infty_0e^{-xu}\frac{\sin u}{u}du$$ my idea $L\left(\frac{1}{t}f(t)\right)=\int_{s}^{\infty}L(f(t))dt$ $L(\sin bt)=t=\frac{1}{1+s^2}$ $\int ^\infty_0e^{-xu}\frac{\sin u}{u}du$ 
??  how  we processed","['real-analysis', 'integration']"
2761359,"Why are $\lfloor\zeta(\zeta(n))\rfloor$,$\left\lfloor\frac{1}{\zeta(n)-1}\right\rceil$, and $\lceil\Gamma(\zeta(n)-1)\rceil$ so similar?","I was first investigating the sequence ( A111000 ) defined by the function
$$a_n = \lfloor\zeta(\zeta(n))\rfloor$$
where $\zeta(n)$ is the Riemann Zeta Function and
$$\lfloor x \rfloor = \max\{m \in \mathbb{Z} \mid m \leq x\}$$
also known as the floor function. The sequence begins, $a_n = 2, 5, 12, 27, 58, 120, ... \text{ for } n = 2, 3, 4, 5, 6, 7, ...$ I then tried investigating other functions relating to the Zeta Function that would satisfy the requirement that the positive infinite limit would tend toward infinity. This led me to
$$b_n = \left\lfloor\frac{1}{\zeta(n)-1}\right\rceil$$
where $\lfloor x \rceil = \left\lfloor x + \frac{1}{2} \right\rfloor$. And secondly,
$$c_n = \lceil\Gamma(\zeta(n)-1)\rceil$$
where $\Gamma(n)$ is the Gamma Function and
$$\lceil x \rceil = \min\{n \in \mathbb{Z} \mid n \geq x\}$$
I found that for some reason, the generated sequences were very similar.
$$a_n = 2, 5, 12, 27, 58, 120, 245, 498, 1006, 2024, 4064, 8149, 16327, 32692, ...$$
$$b_n = 2, 5, 12, 27, 58, 120, 245, 498, 1005, 2024, 4064, 8149, 16327, 32692, ...$$
$$c_n = 2, 5, 12, 27, 58, 120, 245, 498, 1005, 2023, 4064, 8149, 16327, 32692, ...$$
The seemed to be the same for almost all $n$. I tested this up to $n = 1000$ and found the following observations to be true up to that point.
$$a_n \geq b_n \geq c_n \text{, and by Squeeze Theorem, if } a_n = c_n \text{ then } a_n = b_n = c_n$$
$$a_n - c_n \leq 1$$
I am curious why these values are so similar. Is there some equality or near equality I do not know about. Is it possible to prove my observations? How?","['complex-analysis', 'riemann-zeta', 'sequences-and-series', 'gamma-function']"
2761378,About the sequence $a_n=\{\pi^n\}$,"Is the sequence $\{\pi^n\}=\pi^n-\lfloor\pi^n\rfloor$ dense? In other words for any given $\varepsilon>0$ and $t\in[0,1]$ is there a proper $n\in\mathbb{N}$ satisfying $|\{\pi^n\}-t|<\varepsilon$ ? (*) What is the condition on $q$ to make the sequence $\{q^n\}$ dense? I know the necessary and sufficient condition for $\{nq\}$ is $q\not\in\mathbb{Q}$. Also, to make the question * nicer, extend it for all (positive and negative) integers.",['analysis']
2761385,Verify MCQ options $|f(x)-f(y)|<7|x-y|^{201}$,"Let $f:\mathbb{R}\to\mathbb{R}$ be a continuous function such that for any reals $x$ and $y$, 
$$|f(x)-f(y)|\le7|x-y|^{201}$$ We have options $$a)f(101)=f(202)+8\\b)f(101)=f(201)+1\\c)f(101)=f(200)+2\\d)\text{None of the above}$$ My attempt: $$\left|{f(x)-f(y)\over x-y}\right|\le7(x-y)^{200}\\\text{let $x=y+h$}\\\implies |f'(x)|\le0\\\implies f'(x)=0\\\implies f(x)=k, k\in\mathbb{N}$$ Thus d is the correct answer. Is my reasoning correct or am I missing something?","['derivatives', 'functions', 'proof-verification']"
2761455,"How to know the singular points of non-linear, second order ODEs?","I am interested in learning whether there is a standard, systematic way of determining the singular points of non-linear, second degree ODEs. Particularly, I am interested in determining at what time this autonomous equation will blow-up, without actually having to solve the equation:
$$ x''(t)=\frac{(x'(t))^2}{3}+e^{x(t)}\quad;\quad x(0)=0,\quad x'(0)=0~~.\tag{1}$$
Equation (1) is actually solvable by very clever substitutions (see here, in eqworld ), but I am interested more in the theory and more flexible procedures -- or useful theorems. I know Equation (1) will blow-up, because the solution to the related equation $$\chi''=e^\chi\quad;\quad \chi(0)=0,\quad \chi'(0)=0~~.\tag{2}$$ diverges at $t=\pi/\sqrt{2}$. Right side of Equation (1) grows even faster than (1), so it should blow-up at $t<\pi/\sqrt{2}$ as well, as numerical exploration indicates. We can prove that Equation (2) blows-up by noting that $$ (\chi')^2=2(e^\chi-1)~~.$$ Then, we calculate the integral $$\int_0^\infty \frac{dz}{\sqrt{2(e^z-1)}}=\frac{\pi}{\sqrt 2}~~,$$ from where we can deduce that solution to Eq. (2) blows-up at $\pi/\sqrt{2}$ without actually having to solve (2). Can we maybe adapt something like this to second order? It goes without saying: any help, comment, question, or thought will be very appreciated.",['ordinary-differential-equations']
2761479,Finding the expected value of martingale increments on conditioned on brownian bridge,"I want to show that $\mathbb{E}[W_t - W_s | \mathcal{G}_s] = \frac{t-s}{1-s}(W_1 - W_s)$ for $0 \leq s \leq t$, where $W_t$ is the Weiner process, and $\mathcal{G}_s = \sigma(\mathcal{F}_t^W, \sigma(W_1))$, where $\mathcal{F}_t^W$ is the filtration of $W_t$. This is driving me crazy, I just keep getting the wrong answer. Using the linearity of expectation, we have $\mathbb{E}[W_t - W_s | \mathcal{G}_s] 
 = \mathbb{E}[W_t| \mathcal{G}_s] - \mathbb{E}[W_s| \mathcal{G}_s]$.  It seems to me that since $\mathcal{F}_s^W \subset \mathcal{G}_s$, we should have $\mathbb{E}[W_s| \mathcal{G}_s] = W_s$ (is this part wrong?) Now we are left with $\mathbb{E}[W_t| \mathcal{G}_s]$. I already know from this post: conditional expected value of a brownian motion that $\mathbb{E}[W_t|W_s] = \frac{t}{s}W_t$ for $0 <t <s$, so since $\sigma(W_1) \subset \mathcal{G}_s$, we have $\mathbb{E}[W_t| \mathcal{G}_s] = tW_1$. But then this gives $\mathbb{E}[W_t - W_s | \mathcal{G}_s] = tW_1 - W_s$, which is wrong. How do I properly deal with the fact that the sigma algebra gives us information about the future and past? Am I supposed to somehow use the fact that the question is only asking about the difference? Hints would be appreciated!
Thanks very much in advance.","['stochastic-processes', 'brownian-motion', 'conditional-expectation', 'probability']"
2761488,Where is the mistake in the argument? (And two conjectures),"Let $n$ be a natural number. $\Omega = \{ d : d | n \}$, For $A\subset \Omega$ define the probability for $A$ as :
$$P(A) = \frac{1}{\sigma(n)}\sum_{d\in A}{d}$$
Consider the set $B = \{d \in \Omega |d \equiv 0 (2) \}$. Let $a = v_2(n)$. Then (first conjecture)
$$P(B) = \frac{2^{a+1}-2}{2^{a+1}-1}$$
We have $E(d) = \sum_{d|n} {d \cdot P(d)} = \sum_{d|n} { d \cdot \frac{d}{\sigma(n)}} = \frac{\sigma_2(n)}{\sigma(n)}$
Second conjecture: $|B| = a \cdot b$, where $n = 2^a \cdot p_1^{a_1}\cdots p_r^{a_r}$ is the factorization of $n$, with $a$ possibly $=0$ and $b = (a_1+1)\dots(a_r+1)$.
Consider $Z = \sum_{d \in B} {d}$ and consider the random variable: $Y_d = 1$ if $d \equiv 0 ( 2) $, otherwise $= 0$. Then $Z = \sum_{d|n} Y_d d$ is a random variable.
Then on the one hand we have:
$E(Z) = \sum_{d \in B}{E(d)} = \sum_{d \in B}{\frac{\sigma_2(n)}{\sigma(n)}} = a b \frac{\sigma_2(n)}{\sigma(n)}$
On the other hand we have
$P(B) = \frac{Z}{\sigma(n)}$ hence solving for $Z$ we get:
$$Z = \sum_{d|n}{d} \cdot \frac{2^{a+1}-2}{2^{a+1}-1}$$
From this it follows that:
$$E(Z) =  \frac{2^{a+1}-2}{2^{a+1}-1} \sum_{d|n}{E(d)} =  \frac{2^{a+1}-2}{2^{a+1}-1} \sum_{d|n}{\frac{\sigma_2(n)}{\sigma(n)}} = \frac{2^{a+1}-2}{2^{a+1}-1} \tau(n) \cdot \frac{\sigma_2(n)}{\sigma(n)}$$
Hence we get:
$$a b \frac{\sigma_2(n)}{\sigma(n)} = \frac{2^{a+1}-2}{2^{a+1}-1} \tau(n) \cdot \frac{\sigma_2(n)}{\sigma(n)}$$
from which it follows:
$$ab = \tau(n) \cdot \frac{2^{a+1}-2}{2^{a+1}-1}$$
But for example for $n=6$ this is wrong, so where is the mistake in the argument? If you happen to have a proof for one of the conjectures, that would also be fine.","['conjectures', 'expectation', 'proof-verification', 'probability', 'divisor-sum']"
2761495,Naive questions on double duals of von Neumann algebras,"Let $M$ be a von Neumann algebra. I try to understand the double dual $M^{**}$ which is also an ""abstract"" von Neumann algebra. I denote by $i_M \colon M \to M^{**}$ the canonical map. It seems to me that there exists a central projection $e \in M^{**}$ such that $M=eM^{**}$. 1) Is $i_M$ a unital normal injective $*$-homomorphism ? My feeling is that the answer is no. But what are the correct algebraic properties of this map? 2) Sometimes in the litterature, I see the map $Q \colon M \to M^{**}$, $x \mapsto ex$. What is the connection between $Q$ and $i_M$? I believe that $Q(x)=ei_M(x)$ and that $Q(x)\not= i_M(x)$. 3) In the litterature, I see the formula $M^{**}=M \oplus M_*^\perp$. It seems to me that the identification of $M$ in $M^{**}$ is not for the map $i_M$. Can you confirm ?","['functional-analysis', 'operator-algebras', 'von-neumann-algebras', 'dual-spaces']"
2761497,Writing mathematical expressions for selections and arrangements,"Am I on the right track with these questions? Find expressions for each of the following. (Leave your answer as a mathematical expression
rather than a number.) 1) The number of strings of $7$ lower case letters (aâ€“z) that do not contain any letter twice or more. I believe 1 is an ordered selection without repetition that is represented by $$\frac{26!}{(26-7)!}$$ 2) The number of binary strings of length $50$ that contain at most three 1s. I believe 2 is an unordered selection with repetition that is represented by $$\frac{(50 + 3 - 1)!}{3!(50 - 1)!}  +  \frac{(50 + 2 - 1)!}{2!(50 - 1)!}  +  \frac{(50 + 1 - 1)!)}{1!(50 - 1)!}$$ 3) The number of ternary strings of length $10$ (strings of 0s, 1s and 2s) containing exactly one 1 and exactly four 2s. I believe this is ordered with repetition but I am not sure how I would represent this. Is my way of thinking correct?","['permutations', 'combinatorics', 'combinations', 'discrete-mathematics']"
2761507,Why is $\lim\frac{x^2\sqrt{1-x}-18}{(x^2-9)\log(x+4)}$ different for $x\to -3^{+}$ and $x\to -3^{-}$?,"$$\lim_{x\to-3}\frac{x^2\sqrt{1-x}-18}{(x^2-9)\log(x+4)}$$
I used Taylor expansion of $\sqrt{1-x}$ and $\log(x+4)$ centered in $x=-3$:
$$\lim_{x\to-3}\frac{x^2(2)-18}{(x^2-9)(x+3)}=\lim_{x\to-3}2\frac{x^2-9}{(x^2-9)(x+3)}=\frac2{x+3}=+\infty$$ I thought that the two-sided limit $=+\infty$, but Wolfram Alpha gives:
$$\lim_{x\to-3^-}f(x)=-\infty,\qquad \lim_{x\to-3^+}f(x)=+\infty$$ I thought of the following as an explanation for the different values:
$$\text{if } x\to-3^-, x=-3-\varepsilon\implies \frac2{-3-\varepsilon+3}=-\frac2{\varepsilon}=-\infty\\\text{if } x\to-3^+, x=-3+\varepsilon\implies \frac2{-3+\varepsilon+3}=+\frac2{\varepsilon}=+\infty$$
where $\varepsilon$ is an infinitesimal. Is my explanation correct?","['real-analysis', 'calculus', 'limits']"
2761553,Double Integral in Polar Coordinates - Confused by angle,"I need to compute the integral $$\int_{-1}^{0} \int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2} }x dy dx $$ by converting to polar coordinates. Now, since $-\sqrt{1-x^{2}}\leq y \leq \sqrt{1-x^2}$, we are integrating over the unit circle. However, since $-1 \leq x \leq 0$ - i.e., $-1 \leq \cos \theta \leq 0$, I was under the impression that $\theta$ should range from $\displaystyle \frac{\pi}{2}$ to $\pi$. But, in fact, I was informed that in this problem, we are integrating over the left half of the unit circle (so $\theta$ should range from $\pi/2$ to $3 \pi/2$ [and backwards??]), and not just the upper left-hand corner of the circle. Could somebody please explain to me why that is/how I should be able to tell that from the integral? Thank you.","['polar-coordinates', 'multiple-integral', 'calculus', 'multivariable-calculus', 'integration']"
2761555,What does a confidence interval tell you about the relationship between two things?,"So I have found a 95% confidence interval for the odds ratio of  developing cancer with vitamin A intake. My sample odds ratio was 1.1667 with a 95% confidence interval of (0.5394, 2.5227). I am then asked what this interval can tell me about the relationship between vitamin A intake and cancer death. But I am unsure what I could say and what it is actually telling me. Is there is a strong relationship between the two? A weak one? Nothing?","['ratio', 'statistics', 'confidence-interval', 'statistical-inference']"
2761561,What is the correct function expression for the given graph and it's Fourier series?,"I first thought it was $$x\left(t\right)=\frac{4}{T}t$$ for $$0<t<T/4$$ But that would be the case if it wasn't periodic, then i thought that it was: $x\left(t\right)=\frac{4}{T}\left(t-T\right)$ But i'm not sure, and don't know how to plot it on graphing software to test it out. Can someone help me out? EDIT: The problem I had at hand is to find the Fourier series for this function and I tried for both the functions I had written here earlier, but neither got me the right solution, so I'm not sure now. Here is what I did so far:","['periodic-functions', 'functions', 'graphing-functions']"
2761563,Maximum Likelihood Estimation for Zero-inflated Poisson distribution,"I am trying to do exactly what the title says. What I have is the log-likelihood function as follows: Likelihood function , where $I_i = 1$ when $X_i = 0$, and $I_i = 0$ otherwise. Then I took the partial derivatives of that like this . I tried simplifying this expression to get an equation, but I keep getting nonsense. After searching the web, I found this book but I don't understand how the author arrived at ML equations just from looking at the PGF, can someone help explain that please? There is also this entry but they use a different model from mine (p = probability of Poisson, 1-p = probability of 0, whereas both the first book and my model use p = probability of 0, 1-p = probability of Poisson) and again they don't show the simplification steps so I can't really use that. Thanks for any help.","['maximum-likelihood', 'statistics', 'estimation', 'parameter-estimation']"
2761566,Computing dimension of subspaces of cubics,"Let $L,M,N \in \mathbb{P}^5$ $3$ general subspaces of codimension $3$, and let $l_i$ (resp $m_i,n_i)$, $i=1,2,3$ be three general points on $L_i$ (resp. $M_i,N_i)$. I can't understand why $I_{L\cup M\cup N}(3)$, (i.e. the space of all cubics through these subspaces with all first partial derivatives vanishing at this $9$ points), has dimension $26$. I really can't figure out how to attack the problem, so any hint would be appreciate!","['projective-geometry', 'algebraic-geometry']"
2761577,Surface Integrals - Parametric Representation,"Find the parametric representation for the parts of the plane $$2x+3y+z=4$$ where $$1\leq x+y+z\leq 7$$ and $$2\leq x-y\leq4$$. My attempt:
I thought to let $u=x+y+z$ and $v=x-y$ such that $1\leq u \leq 7$ and $2\leq v\leq4$. But I'm unable to find a suitable parametric representation.","['multivariable-calculus', 'vector-analysis']"
2761600,"If $F:[a,b] \rightarrow \mathbb{R}$ is not Lipschitz on $[a,b]$ , then there is a point $x_0 \in [a,b]$ with certain properties.","Suppose that  $F:[a,b] \rightarrow \mathbb{R}$ is not Lipschitz in $[a,b]$, then there exists $x_0 \in  [a,b]$ such that for any $\delta(x_0)>0$(delta neighbourhood of $x_0$) there is a sequence $(x_n)$ in $(x_0-\delta(x_0),x_0+\delta(x_0))$ such that $x_n \rightarrow x_0$ and the sequence $\frac{|F(x_0)-F(x_n)|}{|x_0-x_n|}$ does not converge to any real number $L$. Can somebody help me proving this? I need this to prove something. I have examples: $\sqrt{x}$ for $x \in [0,\infty]$ is not Lipschitz on $[0,\infty]$  and for any $\delta > 0$ neighbourhood of $0$, we can find a sequence $(x_n)$ that converges  to $0$, and the sequence $\frac{|F(x_0)-F(x_n)|}{|x_0-x_n|}$ does not converge to any real number $L$. but, I have trouble in the function $F(x)={xsin(\frac{1}{x})}\, \text{for} \,  0<x\leq 1;F(x)=0\, for \, x=0$. I know that $F(x)$ is not Lipschitz in $[0,1]$ maybe because of $0$. But, I can't find a sequence that converges to $0$ and $\frac{|F(x_0)-F(x_n)|}{|x_0-x_n|}$ does not converge to any real number $L$.","['real-analysis', 'calculus', 'analysis']"
2761606,How to construct a certain covering of $\mathbb P^1_{\mathbb C}$ in a weighted projective space,"Let $b_1, ..., b_n \in \mathbb C$ be $n \geq 2$ distinct points and $p(x) = \prod_{i=1}^n (x-b_i)$. To $p$ corresponds a $d$-fold cyclic covering $\pi\colon X \to \mathbb P^1_{\mathbb C}$. Briefly speaking, my question is: How do I get/construct $X$? More precisely: To complete to a covering of $P^1_{\mathbb C}$, I should homogenize the equation $y^d = p(x)$, i.e., I get an equation $$y^d = \prod_{i=1}^n (x-b_iz)z^a$$
for some $a \in \mathbb Z$. Now, such a curve is singular, so I have to normalize it to make it smooth. From the theory of hyperelliptic curves I know that such a normalization lives in a weighted projective space. Concretely, if $d = 2, n = 2g+2, g \geq 2, a = 0$, the above equation gives a smooth curve in the weighted projective space $\mathbb P (x,y,z) = \mathbb P (1,g+1,1)$. Similary, if $d = 2, g \geq 2$ but $n = 2g+1$, I choose $a = 1$ and obtain again a smooth curve in $\mathbb P (1,g+1,1)$. I've always used this as a black-box, but now I want to understand if this is a principle of greater generality. So my questions are: Can a similar thing as for hyperelliptic curves be done in the greater generality described above? The next two questions assume that the answer to question 1 is positive, which I expect it to be. How do I choose $a$? When $a$ is chosen, is the normalization of the curve $\{y^d = \prod_{i=1}^n (x-b_iz)z^a\} \subset \mathbb P^2_{\mathbb C}$ obtained by the same equation in some weighted projective space? If so, what are the weights (I feel like $x$ and $z$ should have the same weights)? Thanks in advance for any answers and help, it is really appreciated.","['riemann-surfaces', 'algebraic-geometry', 'covering-spaces', 'projective-space', 'algebraic-curves']"
2761630,Number of password number-letter combinations given constraints,"A password is constructed from the numbers 1-9 and the uppercase letters A,B,C,D,E,F,G,H. How many passwords can be constructed which consist of four numbers and 3 letters, if (a) repetition is allowed? (b) repetition is not allowed? (c) no two digits can be next to each other, and no repetition allowed? Attempt (a) Number of placements of the three letters $={  7 \choose 3} = 35$, number of combinations of the letters $=8^3 = 512$, number of combinations of the numbers $=9^4 = 6561$, total combinations =  $35\times 512 \times 6561 = 117573120$ (b) Number of placements of the three letters $={  7 \choose 3} = 35$, number of combinations of the letters $={}^8\mathrm P_6 = 336$, number of combinations of the numbers $=9\times 8\times7\times 6 = 3024$, total combinations =  $35\times 336 \times 3024 = 35562240$ Are my approaches for parts (a) and (b) correct? I am not sure how to approach part (c) - any suggestions would be greatly appreciated.",['combinatorics']
2761650,Upper bound relating number of edges of a graph to it's chromatic number,"So I am curious if there is an upper bound relating number of edges of a graph to it's chromatic number. More specifically, Given a graph $G$ where $\chi(G) = k$, then can we deduce an upper bound for the number of edges $G$ must possess ? There are posts that deduce the lower bound, ($k $ choose 2 many). Cheers","['graph-theory', 'discrete-mathematics']"
2761669,Showing Bernstein polynomial is a basis,"Hello I want to show that the Bernstein polynomial $$B_{n,k}=\binom{n}{k}x^k(1-x)^{n-k}\,$$ is a basis. For linear independence I got a hint from my teacher to expand the binom $(1-x)^{n-k}$ This way I get: $$B_{n,k}=\binom{n}{k}x^k\sum_{j=0}^{n-k}\binom{n-k}{j}(-1)^jx^j$$ And changing the index of summation gives: $$B_{n,k}=\sum_{j=k}^{n}\binom{n-k}{j-k}\binom{n}{k}(-1)^{j-k}x^{j-k+k}=\sum_{j=k}^{n}\binom{n}{j}\binom{j}{k}(-1)^{j-k}x^j$$ Now I have to show  that $\alpha_i$ are $0$ in the relation $\sum_{i=0}^{n}\alpha_iB_{i,n}=0\,$ or $$\alpha_0\sum_{j=0}^n(-1)^j\binom{n}{j}\binom{j}{0}x^j+\alpha_1\sum_{j=1}^n(-1)^{j-1}\binom{n}{j}\binom{j}{1}x^j+...+\alpha_{n}\sum_{j=n}^n(-1)^{j-n}\binom{n}{j}\binom{j}{n}x^j=0$$ Now what can I  do and how  can I finish this problem? Thanks in advance!","['polynomials', 'linear-algebra', 'hamel-basis']"
2761678,P-Value from Sign Test,"I'm so confused with this question and its answer provided as following: The Question The Answer provided I totally don't understand why when we calculate the P-value, we need to calculate as $P(X \ge 1) = 1-P(X=0).$ Since we set the data less than 2 as positive sign here, then we only have 1 positive sign in the data set. Then what does $P(X=0)$ represent? And what does $P(X \ge 1)$ stand for? Thank you for your help, I really can't get any answer directly from Google.","['statistics', 'hypothesis-testing']"
2761704,the upper bound of the supremums of the sequence,"Let $f_{n}:S\to R$ be the sequence of uniformly continuous non-negative functions, $S$ is some normed space, such that for every $n$
$$
\underset{s\in C}{\sup} f_{n}(s) < \infty.
$$ Next, assume that for every $s$ in some subset $C \subset S$, with $S$ compact or only bounded) 
$$
\underset{n\to\infty}{\limsup}f_{n} (s) \leq g(s),
$$
where $g(s)$ is continuous and assume $\underset{s\in C}{\sup} g(s) < \infty$, if $S$ is not compact. Is the following true
$$
\underset{n\to\infty}{\limsup} \underset{s\in C}{\sup} f_{n} (s) < \infty
$$
?","['uniform-convergence', 'calculus', 'functional-analysis', 'measure-theory', 'convergence-divergence']"
2761740,Abelianity and quotients,"Hello all I have a question on group theory. Let $G$ be any group and $H$ a finite normal subgroup of $G$. Suppose that the quotient $G/H$ is abelian. Is it true then that $G$ is abelian? If not, do you have a counterexample? My attempt: I think the answer is positive, as taking only a finite piece of $G$ does not affect very much on its behavior. Thanks in advance! *Edit: I edit my question as I received counterexamples with finite groups (which I really appreciate). What if we add the assumption that $G$ is infinite?","['abelian-groups', 'examples-counterexamples', 'group-theory', 'quotient-group']"
2761777,How to count number of integer solutions of this inequality $(x - 1)^2 + (y - 2)^2 + (z - 3)^2\leqslant 81$?,"I have inequality $$(x - 1)^2 + (y - 2)^2 + (z - 3)^2 \leqslant 81$$ and want to count all number of integer solutions. I tried
$$(x - 1)^2 \leqslant 81 \Leftrightarrow -8\leqslant x\leqslant 10,$$
$$(y - 2)^2 \leqslant 81 \Leftrightarrow -7\leqslant y\leqslant 11,$$
$$(z - 3)^2 \leqslant 81 \Leftrightarrow -6\leqslant y\leqslant 12.$$
Therefore, there are $19 \cdot 19 \cdot 19 = 6859 $. This result is not correct. The correct answer is 3071. I found 102 triples $(a,b,c)$ so that  $a^2 + b^2 + c^2 = 81 $ are:
$(-9, 0, 0)$, $(-8, -4, -1)$, $(-8, -4, 1)$, $(-8, -1, -4)$, $(-8, -1, 4)$, $(-8, 1, -4)$, $(-8, 1, 4)$, $(-8, 4, -1)$, $(-8, 4, 1)$, $(-7, -4, -4)$, $(-7, -4, 4)$, $(-7, 4, -4)$, $(-7, 4, 4)$, $(-6, -6, -3)$, $(-6, -6, 3)$, $(-6, -3, -6)$, $(-6, -3, 6)$, $(-6, 3, -6)$, $(-6, 3, 6)$, $(-6, 6, -3)$, $(-6, 6, 3)$, $(-4, -8, -1)$, $(-4, -8, 1)$, $(-4, -7, -4)$, $(-4, -7, 4)$, $(-4, -4, -7)$, $(-4, -4, 7)$, $(-4, -1, -8)$, $(-4, -1, 8)$, $(-4, 1, -8)$, $(-4, 1, 8)$, $(-4, 4, -7)$, $(-4, 4, 7)$, $(-4, 7, -4)$, $(-4, 7, 4)$, $(-4, 8, -1)$, $(-4, 8, 1)$, $(-3, -6, -6)$, $(-3, -6, 6)$, $(-3, 6, -6)$, $(-3, 6, 6)$, $(-1, -8, -4)$, $(-1, -8, 4)$, $(-1, -4, -8)$, $(-1, -4, 8)$, $(-1, 4, -8)$, $(-1, 4, 8)$, $(-1, 8, -4)$, $(-1, 8, 4)$, $(0, -9, 0)$, $(0, 0, -9)$, $(0, 0, 9)$, $(0, 9, 0)$, $(1, -8, -4)$, $(1, -8, 4)$, $(1, -4, -8)$, $(1, -4, 8)$, $(1, 4, -8)$, $(1, 4, 8)$, $(1, 8, -4)$, $(1, 8, 4)$, $(3, -6, -6)$, $(3, -6, 6)$, $(3, 6, -6)$, $(3, 6, 6)$, $(4, -8, -1)$, $(4, -8, 1)$, $(4, -7, -4)$, $(4, -7, 4)$, $(4, -4, -7)$, $(4, -4, 7)$, $(4, -1, -8)$, $(4, -1, 8)$, $(4, 1, -8)$, $(4, 1, 8)$, $(4, 4, -7)$, $(4, 4, 7)$, $(4, 7, -4)$, $(4, 7, 4)$, $(4,8, -1)$, $(4, 8, 1)$, $(6, -6, -3)$, $(6, -6, 3)$, $(6, -3, -6)$, $(6, -3, 6)$, $(6, 3, -6)$, $(6, 3, 6)$, $(6, 6, -3)$, $(6, 6, 3)$, $(7, -4, -4)$, $(7, -4, 4)$, $(7, 4, -4)$, $(7, 4, 4)$, $(8, -4, -1)$, $(8, -4, 1)$, $(8, -1, -4)$, $(8, -1, 4)$, $(8, 1, -4)$, $(8, 1, 4)$, $(8, 4, -1)$, $(8, 4, 1)$, $(9, 0, 0)$. How to count number of integer solutions of that inequality?",['discrete-mathematics']
2761814,Are notations in ZF conservative?,"In first-order logic with the Zermelo-Fraenkel axioms, it is convenient to introduce notations for sets that we prove exist and are unique. For example the union of two sets, ZF proves that:
$$\forall a \forall b\; \exists! u \;\forall t, \; t\in u \Leftrightarrow (t \in a \lor t \in b) $$
So we note $u = a \cup b$. That means we introduce a binary operator symbol $\cup$ with an axiom derived from the theorem above. It is easy to show that any model of ZF can be extended to a model of ZF $+\cup$, by interpreting $\cup$ as a function that maps $(a,b)$ to the unique $u$ above. However there is a glitch in the replacement axiom scheme. With the newly introduced symbol $\cup$, there are more formulas that can go into the replacement scheme, to produce more axioms. The previous reasoning didn't check that these new axioms are satisfied by the extended model. If we drop the unicity and start with this other ZF theorem : $\forall a, \; a\neq \emptyset \Rightarrow \exists u, u \in a$, then introduce the associated symbol Choice$(a)$ with the following axiom,
$$ \forall a, \; a\neq\emptyset \Rightarrow \text{Choice}(a) \in a $$
it is easy to derive the axiom of choice from that. Adding the symbol Choice and its axiom to ZF is consistent, but not conservative. Is there a proof that ZF plus usual operations (empty set, union, intersection, powerset, pairs of sets, tuples, cartesian products, ...) is a conservative extension of ZF with only the membership symbol $\in$ ?","['first-order-logic', 'elementary-set-theory']"
2761860,Completing A proof of a question related to Radon-Nikodym,"Let $\nu$ be a absolutely continous with respect to the measure $\mu$, where both of them are $\sigma$ finite and are on $( \omega , X)$. Prove that then. $\forall$ $\epsilon>0$ $\exists$ $\delta>0$ such that $\mu(A)<\delta$ $\implies$ $\nu(A)<\epsilon$, $\forall A \in X$ I want to prove this directly (its rather easy if we go from converse). Given $\epsilon >0$, for arbitrary $A\in X$, $\nu(A)=\int_{A} fd\mu<\epsilon$ where $f$ is the Radon-Nikodym derivative. Then by using simple functions we can write this as $\sum_{k=1}^{n}a_{k}\mu(A_{k})$ where $A_{k}$'s are partition of $A$.Hence for any $k<n+1$, $a_{k}\mu(A_{k})<\epsilon$. How we can find the $\delta$ from ther? Or how we can prove this direclty, if this proof doesn't work.","['real-analysis', 'measure-theory']"
2761887,Why is there no matrix representation of a linear operator,"If a Hilbert space, $H$ , has orthonormal basis $\{e_i\}$ , then a linear operator $A:H \to H$ can only be defined by a matrix (i.e., $\{a_{i,j} : \langle Ae_i,e_j \rangle = a_{i,j}\}$ if the operator is bounded. 
I can't fully understand why we need this condition. I don't need an explicit counter-example, since it is seems to be hard to construct unbounded linear operators , but I would like an explanation of what exactly it means for a linear operator to be unbounded. Thanks! Edit: sorry, I worded my question badly. when I said 'I would like an explanation of what exactly it means for a linear operator to be unbounded' I meant in the context of this matrix representation. I.e., if we have a discontinuous linear operator on an infinite dimensional Hilbert space, why does this matrix representation fail? To help you understand my confusion better, given this matrix representation, it's easy to see that for any $x = \sum_i x_i e_i \in H$ , $Tx = \sum_k (\sum_i x_i a_{i,j}) e_k$ . I believe this is ill-defined when $T$ is either unbounded (or discontinuous), but why is this? Is it because these infinite sums might be conditionally convergent? I can't construct any nice examples, thanks in advance!","['functional-analysis', 'hilbert-spaces', 'linear-transformations']"
2761892,"Designing a FIR filter in frequency domain: Paley-Wiener ""the other way around"".","This question is about designing a FIR filter in Paley-Wiener space by specifying its behaviour with respect to a finite set of frequencies. From the classical Paley-Wiener theorem(s) we get the following conditions sufficient for a function $h(t)$ to be real-valued with compact support in the interval $[0,A]$: Let $A>0$ and let $\hat{h}\left(z\right):\;\mathbb{C}\to\mathbb{C}$ be a function with the following properties: 1.) $\hat{h}$ is an entire function. 2.) For $x\in\mathbb{R}$ the function $\Re\left(\hat{h}\left(x\right)\right)$ is even. 3.) For $x\in\mathbb{R}$ the function $\Im\left(\hat{h}\left(x\right)\right)$ is odd. 4.) $\exists c<\infty\;:\;\sup_{y>0}\intop_{-\infty}^{\infty}\left|\hat{h}\left(x+i\cdot y\right)\right|^{2}\mathtt{d}x\leq c$ 5.) $\exists\tilde{c}<\infty\;\forall z\in\mathbb{C}\;:\;\left|\hat{h}\left(z\right)\right|\leq\tilde{c}\cdot e^{A\left|z\right|}$ Then $h\left(t\right)=\intop_{-\infty}^{\infty}\hat{h}\left(x\right)e^{-itx}\mathtt{d}x$ is a real-valued function with compact support $\mathtt{supp}\,h\subseteq\left[0,A\right]$. The idea is now to specify the behaviour of $h$ with respect to a finite set of frequencies by requiring $\hat{h}$ to take certain values at those frequencies:
For $j\in\left[0,N-1\right]$, $\;f_{j}\in\mathbb{R}_{+}$ and $k_{j}\in\mathbb{C}$, we require that $\hat{h}\left(f_{j}\right) = k_{j}$. In order to construct such a $\hat{h}$, a Riesz-basis for the Paley-Wiener space would be helpful. Unfortunately, most of the Paley-Wiener theory applied to filter design deals with the opposite setting of band-limited functions, where only a real-valued and even Riesz-basis of the subspace of real-valued and even functions of frequency is used in order to receive a IIR filter.
We do however require a Riesz-basis for the whole PW-space. While obviously only its values along the real axis are of practical interest, we still need the theoretical properties of that basis as a set of complex-valued functions of a complex variable so that 1.-5. will hold. I would appreciate any hints to readings relevant to the setting described here and on how to obtain such a basis. Thank you! Edit:
In order not to bloat this question, I will collect any progress I make on this issue in my own answer below.","['functional-analysis', 'complex-analysis', 'signal-processing']"
2761903,Solve for x in the equation: $3^x + 9^x = 27^x$,"Solve for x in the equation: $3^x + 9^x = 27^x$ Via calculator, the x is = 0.438 which is correct as it is in the choices. However I want to know how to solve it manually, hence the question. I'm stuck at : $3^x + 3^{2x} = 3^{3x}$ I don't know what to do next. Any help would be appreciated.",['algebra-precalculus']
2761909,Are theories in standard mathematics defined on sets or on collections?,"Generally, the structures that people study in every-day modern mathematics can be seen as defined on sets, so far as I know. (In the sense that they are collections of objects that don't give rise to russel's paradox). E.g. the collection of real numbers, or of $5$-dimensional manifolds or of symmetry maps on the unit circle or whatever, are all sets. However, I recall that sometimes structures cannot be assumed to be sets. E.g. we cannot speak of the Category of Categories apparently (unless we mean the category of small categories), since this would not be a set, and would give rise to russel's paradox (if I underatand correctly) My question is: is it generally required for any mathematical theory that the domain of any arbitrary structure that satiafies it is a set, rather than generally a collection? E.g. do we require that a group not only satiafies the axioms, but implicitly require also that the domain of a particular group is a set?","['axioms', 'elementary-set-theory']"
2761936,How can we calculate the sum of sines or cosines where the angles are in geometric progression?,"For example: $$\cos\frac{\pi}{7} + \cos\frac{3\pi}{7} + \cos\frac{9\pi}{7}$$ In this example, there are only a few terms, and we can use things like $\cos(9\pi/7) = -\cos(2\pi/7)$ and complex numbers to solve it. I am trying to find if there is a closed formula to a generic case $$\cos(x) + \cos(x\cdot q) + \cos (x\cdot q^2) + \cdots + \cos(x\cdot q^n)$$","['angle', 'trigonometry', 'geometric-progressions']"
2761966,Range of the Gelfand transform on a non-unital Banach algebra,"Let $\mathcal{A}$ be a non-unital commutative Banach algebra. Consider the Gelfand transform
\begin{align*}\Gamma_{\mathcal{A}}:\mathcal{A}&\to C(\sigma(\mathcal{A}))\\
x&\mapsto \hat{x}
\end{align*}
where
\begin{align*}\hat{x}:\sigma(\mathcal{A})&\to \mathbb{C}\\
h&\mapsto \hat{x}(h)=h(x)
\end{align*}
In Folland's A course in Abstract Harmonic Analysis it is stated that in fact $\Gamma_{\mathcal{A}}(\mathcal{A})\subset C_0(\sigma(\mathcal{A}))$, i.e. if $x\in \mathcal{A}$ then for all $\varepsilon>0$ there is a compact $K\subset \sigma(\mathcal{A})$ such that $|\hat{x}(h)|\leq \varepsilon$ for all $h\in \sigma(\mathcal{A})\setminus K$. It is not well explained why this is true. The basic idea would be to try to get back to the unital case. We can consider the unital extension $\tilde{A}=\mathcal{A}\times \mathbb{C}$ of $\mathcal{A}$, where $\mathcal{A}\cong \mathcal{A}\times \left\{0\right\}\subset \tilde{A}$. We then have a homeomorphism (I think) \begin{align*}\sigma(\tilde{\mathcal{A}})&\cong \sigma(\mathcal{A})\cup \left\{0\right\}\\
0&\mapsto \tilde{0}:(x,\lambda)\mapsto 0\\
\sigma(\mathcal{A})\ni h&\mapsto \tilde{h}:(x,\lambda)\mapsto h(x)+\lambda 
\end{align*}
both are compact Hausdorff spaces in the weak*-topology induced by $\mathcal{A}^*$ and $\mathcal{A}$ respectively, while $\sigma(\mathcal{A})$ is only locally compact in general. The above homeomorphism in turn induces a Banach algebra isomorphism $C(\sigma(\tilde{\mathcal{A}}))\cong C(\sigma(\mathcal{A})\cup\left\{0\right\})$. With this identification we have $\Gamma_{\mathcal{A}}=r\circ \left.\Gamma_{\tilde{\mathcal{A}}}\right|_{\mathcal{A}}$ where $r:C(\sigma(\mathcal{A})\cup\left\{0\right\})\to C(\sigma(\mathcal{A}))$ is the restriction map.
Now I would like to use the topological/algebraic properties I know about $r$ and $\Gamma_{\tilde{\mathcal{A}}}$ to show that $\Gamma_{\mathcal{A}}(\mathcal{A})\subset C_0(\sigma(\mathcal{A}))$. I am aware that $\mathcal{A}$ is a closed maximal ideal of $\tilde{A}$ so since $\tilde{\mathcal{A}}$ is unital, $\Gamma_{\tilde{\mathcal{A}}}(\mathcal{A})$ is itself a closed non-trivial subalgebra of $C(\sigma(\mathcal{A})\cup\left\{0\right\})$.","['functional-analysis', 'gelfand-representation', 'banach-algebras']"
2762030,Zeros of Holomorphic Functions,"I am studying theory on the zeros of a function; in particular the the zeros of some order $m$ of a holomorphic function. However I do not understand the following proof presented to me in proving that: A function $f(z)$ has a zero of order $m$ $\iff$ $f(z)=g(z)(z-z_0)^m$ where g(z) is holomorphic at $z_0$ and $g(z_0)\neq0$. I define a zero of a function of order $m$ at $z_0$ to mean that the first $0,\dots m-1$ derivatives evaluated at $z_0$ are zero and the $m$th derivative is non-zero at $z_0$. The only if part of the prove leaves me a little unsure as to why the function $g(z)$ as I shall show below is holomorphic. I have searched online but it has mostly been stated that this function is holomorphic so maybe I'm missing something obvious? The proof goes like this: The Taylor series for $f(z)$ is:
\begin{align*}
f(z)&=0+\dots+0+\frac{f^{(m)}(z_0)}{m!}(z-z_0)^m+\frac{f^{(m+1)}(z_0)}{(m+1)!}(z-z_0)^{m+1}+\dots \\&=(z-z_0)^m \Big\{ \frac{f^{(m)}(z_0)}{m!}+\frac{f^{(m+1)}(z_0)}{(m+1)!}(z-z_0)+\dots\Big\}
\end{align*} and now the function in the curly parenthesis is denoted as $g(z)$, which is claimed to be the holomorphic function. It is clear $g(z_0)\neq0$ but could it be pointed out why the function is also a convergent power series ie analytic/holomorphic etc.","['roots', 'complex-analysis', 'analytic-functions', 'proof-explanation', 'power-series']"
2762034,Solving $u(t)=f(t)+a\int_0^t u(s)ds$ by assuming $f$ is differentiable,"Original Let $a\in\mathbb R$ and $f\colon [0,1]\to\mathbb R$ a continuous
  function. Solve the integral equation $$u(t)=f(t)+a\int_0^t
 u(s)\mathrm ds,\quad t\geq 0$$ and find an explicit formula for the
  solution. First assume $f$ is differentiable. Then $$u'(t)=f'(t)+au(t)$$ $$\to u'(t)-au(t)=f'(t)$$ $$\to u'(t)e^{-at}-au(t)e^{-at}=f'(t)e^{-at}$$ $$\to (u(t)e^{-at})'=f'(t)e^{-at}$$ $$\to (u(t)e^{-at})=\int f'(t)e^{-at} dt$$ $$\to u(t)=e^{at}\int f'(t)e^{-at} dt$$ $$\to u(t)=e^{at}[e^{-at}f(t)+a\int f e^{-at} dt]$$ $$\to u(t)=f(t)+ae^{at}\int f e^{-at} dt$$ Second, use the above as an Ansatz to show that the solution for when $f$ is differentiable is the same as when $f$ isn't . Is this merely coincidence? Or is there some rule like in solving integral equations with conditions of blah blah blah, the Ansatz is of when $f$ is differentiable under the conditions of blah blah blah, is right?","['derivatives', 'real-analysis', 'calculus', 'integration', 'ordinary-differential-equations']"
2762096,Prove that finite and infinite presentations of Thompson group $F$ are isomorphic.,"Let $$
G=\langle x_0,x_1,\dots\mid x_jx_i=x_ix_{j+1}\text{ for }i<j\rangle,
$$ $$
H=\langle a,b\mid [ab^{-1},a^{-1}ba],[ab^{-1},a^{-2}ba^2]\rangle,
$$ where $[x,y]$ is commutator. These are both presentations of Thompson group $F$ and I want to show that they are indeed isomorphic. I can prove that $\phi:H\to G$ when $\phi(a)=x_0$ and $\phi(b)=x_1$ is homomorphism. I define inverse as $$\psi(x_0)=a,\psi(x_1)=b,\psi(x_n)=a^{1-n}ba^{n-1}.$$ And here I have problem. It is easy to show that it works for $i=0$ . Having that we can always assume that $i=1$ , so all we need is to check that homomorphism works for all $j$ . It is easy to check that it works for $j=2,3$ because $$\psi(x_1^{-1})\psi(x_j)\psi(x_1)(\psi(x_{j+1}))^{-1}$$ is one of the relators of $H$ . But I do not know how to work out induction for any larger $j$ . I would be thankful for help or recommending some source where it is proved.","['combinatorial-group-theory', 'group-presentation', 'group-theory', 'group-isomorphism']"
2762109,Convolution of two Schwartz functions is Schwartz,"I am trying to show directly (i.e., not using the Fourier transform) that if $S=S(\mathbb{R}^n)$ is the class of Schwartz functions then $f,g \in S$ implies $f*g \in S$. The definition I have is $f \in S$ iff for all $N$, $\|f\|_N:=\sup_{x \in \mathbb{R}^d, |\alpha|,|\beta| \leq N} |x^\beta\partial_x^\alpha f(x)|<\infty$. I have shown that $\|f\|_N<\infty$ is equivalent to: for all $|\alpha|,|\beta| \leq N$, there exists a constant $C_N$ such that $|\partial_x^\alpha f(x)| \leq \frac{C_N}{\prod_{i=1}^n (1+|x_i^{\beta_i}|)}$. I also know that $\partial_x^\alpha (f*g)(x) = \int_{\mathbb{R}^n} \partial_x^\alpha f(x-t) g(t) \ dt$. Since $\partial_x^\alpha f \in S$, I believe it suffices to show that for all $f,g \in S$, all $N$, and all $|\beta| \leq N$, we have $|(f*g)(x)| \leq \frac{C_N}{\prod_{i=1}^n (1+|x_i^{\beta_i}|)}$. I can prove this in the case $\mathbb{R}^n=\mathbb{R}$ as follows: Let $C_N$ be such that for all $b \leq N$, $|f(x)|,|g(x)| \leq \frac{C_N}{1+|x|^b}$. Then \begin{align*}
\left| \int_{\mathbb{R}} f(x-t)g(t) \ dt \right| & \leq \int_{\mathbb{R}} \left| f(x-t)g(t)\right| \ dt\\
&= \int_{|x-t| \geq |x|/2} \left| f(x-t)g(t)\right| \ dt + \int_{|x-t| < |x|/2} \left|f(x-t)g(t)\right| \ dt\\
&\leq \sup_{|x-t| \geq |x|/2} |f(x-t)|\int_{\mathbb{R}}|g(t)| \ dt + \sup_{|t| \geq |x|/2} |g(t)| \int_{\mathbb{R}} |f(x-t)| \ dt\\
&\leq \sup_{|x-t| \geq |x|/2}\frac{C_N}{1+|x-t|^b} \|g\|_{L^1} + \sup_{|t| \geq |x|/2}\frac{C_N}{1+|t|^b} \|f\|_{L^1}\\
&\leq \frac{C_N(\|g\|_{L^1}+\|f\|_{L^2})}{1+(|x|/2)^b}\\
& \leq \frac{2^NC_N(\|g\|_{L^1}+\|f\|_{L^2})}{1+|x|^b}. 
\end{align*}
(Note that $|x-t|<|x|/2$ implies $|t|>|x|/2$.) However, I am struggling with how to split up the integral in $\mathbb{R}^n$. In order to do the step  $\frac{C_N}{\prod_{i=1}^n (1+|x_i-t_i|^{\beta_i})} \leq \frac{C_N}{\prod_{i=1}^n (1+(|x_i|/2)^{\beta_i})}$ I need $|x_i-t_i| \geq |x_i|/2$ for all $i$. But in order to do the step $\frac{C_N}{\prod_{i=1}^n (1+|t_i|^{\beta_i})} \leq \frac{C_N}{\prod_{i=1}^n (1+(|x_i|/2)^{\beta_i})} $ I need $|t_i| \geq |x_i|/2$ for all $i$. However these two sets do not encompass all of $\mathbb{R}^n$ (in particular, we miss all $t$ such that $|x_i-t_i| < |x_i|/2$ for some $i$ and $|t_j| < |x_j|/2$ for some $j$). I have tried integrating over one copy of $\mathbb{R}$ at a time, but as soon as we replace $f$ and $g$ by their upper bounds in the innermost integral, they are no longer guaranteed to have finite $L^1$ norm, so I cannot continue. (Note: I can show the inequality holds for $N=1$, i.e., $x^\beta = x_i$ for some $i$. Is that enough?) Any suggestions would be greatly appreciated.","['functional-analysis', 'convolution']"
2762113,Proving divergence of $\int_1^{\infty}e^{-\arctan(x)}\ \mathrm{d}x$,"I wish to show that the integral: 
$$\int_1^{\infty}e^{-\arctan(x)}\ \mathrm{d}x$$ diverges. I tried to use the different comparison tests but couldn't get to anything. I would like to get a hint, and hopefully continue from there on my own.","['improper-integrals', 'convergence-divergence', 'calculus']"
2762116,"Lemma: Let $b,c \in \mathbb{Q}-\{0\}$. Then $\mathbb{Q}(\sqrt2,\sqrt3) =\mathbb{Q}(b\sqrt2+c\sqrt3+\sqrt6)$.","I am attempting to prove that $\mathbb{Q}(\sqrt2,\sqrt3)=\mathbb{Q}(Î±)$ iff $Î±=a+b\sqrt2+c\sqrt3+d\sqrt6$ where $a,b,c,d\in \mathbb{Q}$ and two or more of $b,c,d$ are nonzero. The forward direction is easy, but I am having some trouble with the backward direction. Let $Î±=a+b\sqrt2+c\sqrt3+d\sqrt6$, where $a,b,c,d\in \mathbb{Q}$ and at least two of $b,c,d$ are nonzero. I see that, without loss of generality, we can assume $a=0$. Now, the problem splits in two cases. Either exactly two of $b,c,d$ are nonzero OR all three of $b,c,d$ are nonzero. I think I can tackle the former case on my own, but I could use some help on the latter. Assume $b,c,d$ are all nonzero. WLOG, we can take $d=1$ so $Î±=b\sqrt2+c\sqrt3+\sqrt6$. I see that $\mathbb{Q}(\sqrt2,\sqrt3) \supseteq \mathbb{Q}(Î±)$, but I need some help proving $\subseteq$. An elementary, straightforward, complete proof without gaps is what I'm looking for. I desire to prove the following Lemma: Let $b,c \in \mathbb{Q}-\{0\}$. Then $\mathbb{Q}(\sqrt2,\sqrt3)=\mathbb{Q}(b\sqrt2+c\sqrt3+\sqrt6)$.","['abstract-algebra', 'field-theory']"
2762201,Complex Analysis: Sketch the image of a domain under the mapping $f(z)=\sqrt{z^2+1}$,"I'm having some trouble solving the following: Suppose $D=\{z: Re(z)>0\}$ and suppose $f(z)=\sqrt{z^2+1}$ where we mean the principal branch of the squared root. Find and sketch the image of $D$ under $f$. I've tried to rewrite $f(z)=w=u+iv$ in terms of $x$ and $y$ to determine a $u$- and $v$-part which I could try to sketch. So I got this: $w=\sqrt{z^2+1}=\sqrt{(x+iy)^2+1}=\sqrt{x^2+i2xy-y^2+1}$. But this is where I'm stuck. I can't seem to get rid of the squared root. Also, I have yet to see how to proceed after rewriting. Can anyone help me out?","['complex-analysis', 'conformal-geometry']"
2762206,Find continuos function $x$ with $x(0)=0$ such that $\|x-y\| \geq 1$ where $y(0)=0$ and $\int_0^1 y(t) dt = 0$,"Consider $C[0,1]$ space of continuos functions with the uniform norm. Let $X = \{ x \in C[0,1]: x(0)=0\}$ and $Y = \{ y \in X: \int_0^1 y(t) dt = 0 \}$ subspaces of  $C[0,1]$. How can I show that $\exists x \in X$, $\|x\|=1$, such that $$\|x-y\| \geq 1 ~~\forall y \in Y?$$ Edit: Sorry guys, the question is: How can I prove that doesn't exists $x \in X$, such that $||x||=1$ and $||x-y|| \geq 1 ~~\forall y \in Y$",['functional-analysis']
2762210,Commutator Group of $\operatorname{GL}_2(\mathbb{R})$ is $\operatorname{SL}_2(\mathbb{R})$,"Let $\operatorname{GL}_2(\mathbb{R})$ be the general linear group of $2\times2$ matrices and $\operatorname{SL}_2(\mathbb{R})$ the special linear group of $2 \times 2$ matrices. Show that the commutator subgroup of $\operatorname{GL}_2(\mathbb{R})$ is $\operatorname{SL}_2(\mathbb{R})$ . I can show that the commutator subgroup is contained in $\operatorname{SL}_2(\mathbb{R})$ as if $A,B \in \operatorname{GL}_2(\mathbb{R})$ then $$
 \det(ABA^{-1}B^{-1}) = \det(A)\det(B)\det(A^{-1})\det(B^{-1}) = 1.
$$ But how can I show the reverse inclusion? That is, that $\operatorname{SL}_2(\mathbb{R})$ is contained in the commutator subgroup of $\operatorname{GL}_2(\mathbb{R})$ . Any help will be appreciated.","['normal-subgroups', 'group-theory', 'linear-groups']"
2762230,"Let $\gamma\in C(I,\Bbb R^n)$. Show that $\dim_H(\Gamma)=1$","Let $I:=[a,b]$ a perfect interval and $\gamma\in C(I,\Bbb R^n)$ an injective path such that $\Gamma:=\gamma(I)$ is rectifiable. Show that $\dim_H(\Gamma)=1$. Here $\dim_H$ is the Hausdorff dimension. My work so far: Note that the canonical projections $\pi_k$ are Lipschitz, and because $\gamma$ is continuous and it domain is compact and connected then $\Gamma$ is also compact and connected, thus $\pi_k(\Gamma)\subset\Bbb R$ is compact and connected. Because $I$ is perfect and $\gamma$ injective then $\Gamma$ is not a singleton, so there is some $k\in\{1,\ldots,n\}$ such that $\pi_k(\Gamma)$ is a perfect closed interval, thus setting
$$
f:\Gamma\to\Bbb R^n,\, x\mapsto (\pi_k(x),0,\ldots,0)\tag1
$$
we can see that $f$ is also Lipschitz and we find that $\dim_H(\pi_k(\Gamma))=\dim_H(f(\Gamma))=1\le\dim_H(\Gamma)$ by some elementary identities of the Hausdorff outer measures. However Im unable to find a way to show that $\dim_H(\Gamma)\le 1$. I dont have a clue about how to do it. Some random ideas that I had: I tried to relate that $\gamma$ have a continuous inverse in $\Gamma$, or some uniform polynomial approximation to $\Gamma$, or the fact that $\Gamma$ is rectifiable and compact with the definition of Hausdorff outer measure, but I dont found something. Some help will be appreciated, thank you.","['hausdorff-measure', 'real-analysis', 'measure-theory', 'analysis']"
2762280,"Prob. 1, Sec. 3.7, in Bartle & Sherbert's INTRO. TO REAL ANALYSIS: Removal of the zero terms of a convergent series does not affect the sum?","Here is Prob. 1, Sec. 3.7, in the book Introduction to Real Analysis by Robert G. Bartle and Donald R. Sherbert, 4th edition: Let $\sum a_n$ be a given series and let $\sum b_n$ be the series in which the terms are the same and in the same order as in $\sum a_n$ except that the terms for which $a_n = 0$ have been omitted. Show that $\sum a_n$ converges to $A$ if and only if $\sum b_n$ converges to $A$. My Attempt: In order to have a series at all for $\sum b_n$, we must of course assume that there are non-zero terms in $\sum a_n$; rather, we must also assume that there are infinitely many non-zero terms of the series $\sum a_n$, for otherwise both $\sum_{n=1}^\infty a_n$ and $\sum_{n=1}^\infty b_n$ be finite sums having the same non-zero terms and will thus be equal. Am I right? For the sake of definiteness, let us assume that $a_n = 0$ whenever $n$ is a prime number and that $a_n$ is non-zero otherwise. Let $\left( s_n \right)_{n \in \mathbb{N}}$ and $\left( t_n \right)_{n \in \mathbb{N}}$ be the sequences of the partial sums of $\sum a_n$ and $\sum b_n$, respectively.  Then we note that 
  $$
\begin{align} 
t_1 &= s_1 = s_2 = s_3, \\ 
t_2 &= s_4 = s_5, \\
t_3 &= s_6 = s_7, \\ 
t_4 &= s_8, \\ 
t_5 &= s_9, \\ 
t_6 &= s_{10} = s_{11}, \\
t_7 &= s_{12} = s_{13}, \\
t_8 &= s_{14}, \\
t_9 &= s_{15}, \\
t_{10} &= s_{16} = s_{17},
\end{align}
$$
  and so on and so forth. In this way, we observe that $\left( t_n \right)_{n \in \mathbb{N}}$ is a subsequence of $\left( s_n \right)_{n \in \mathbb{N}}$ and therefore the former sequence has the same limit as the latter. Is this kind of ""proof"" satisfactory enough, I wonder? I would like to make it more general and rigorous though. Reading off the above array from the right to left, we observe that the terms of the sequence $\left( s_n \right)_{n \in \mathbb{N}}$ also appear in the sequence $\left( t_n \right)_{n \in \mathbb{N}}$ and the predecessor-successor relationship between terms is preserved in passing from the latter sequence to the former. Thus (intuitively at least) the former sequence cannot have any limit different from the limit of the latter sequence. How to make this part of my argument more precise and rigorous, employing only what has preceded this particular exercise problem in the book? In general, how to give a proof of each one of the two parts in the full level of generality, rigor, and detail?","['real-analysis', 'sequences-and-series', 'calculus', 'convergence-divergence', 'analysis']"
2762286,Riemannian metric and geodesics on a cone,"If we are given a surface S given by $z^2 = a(x^2 + y^2)$ , $z>0$ . I want to find the Riemannian metric of the cone and an explicit formula for the geodesics. I parametrise it by $\sigma \colon U \to S$ where $U$ is an open subset of $\mathbb{R}^2$ . $U = \{(u,v): 0<u<2\pi, 0<v<\infty\}$ . $\sigma (u,v) = (v \sin(u), v \cos(u), \sqrt{a}v)$ is a smooth parametrisation of the cone minus a line. We can show that the Riemannian metric is given by $E=v^2, F=0, G=1+a$ . To solve the geodesic ODEs, we find that given a curve $\gamma = (x(t), y(t)) \colon [a,b] \to U$ $$y^2\dot x = c$$ $$(1+a)\ddot y = y\dot x^2$$ I am lookin for an answer as to whether what I have done so far is correct and to complete the argument.","['riemannian-geometry', 'differential-geometry', 'geometry']"
2762290,orthogonal matrix with negative determinant,"Question : Assume that $A$ is a $n\times n$ orthogonal matrix such that $det(A)<0$. Prove that there exists a nonzero vector $x\in\mathbb{R}^n$ such that $Ax=-x$. Since $A$ is orthogonal and $det(A)<0$, its determinant is $-1$. Please help, thanks a lot!","['matrices', 'linear-algebra']"
2762306,"Without using a calculator, is $\sqrt[8]{8!}$ or $\sqrt[9]{9!}$ greater?","Which is greater between $$\sqrt[8]{8!}$$ and  $$\sqrt[9]{9!}$$? I want to know if my proof is correct... \begin{align}
	\sqrt[8]{8!} &< \sqrt[9]{9!} \\
	(8!)^{(1/8)} &< (9!)^{(1/9)} \\
	(8!)^{(1/8)} - (9!)^{(1/9)} &< 0 \\
	(8!)^{(9/72)} - (9!)^{8/72} &< 0 \\
	(9!)^{8/72} \left(\left( \frac{8!}{9!} \right)^{(1/72)} - 1\right) &< 0 \\
	\left(\frac{8!}{9!}\right)^{(1/72)} - 1 &< 0 \\
	\left(\frac{8!}{9!}\right)^{(1/72)} &< 1 \\
	\left(\left(\frac{8!}{9!}\right)^{(1/72)}\right)^{72} &< 1^{72} \\
	\frac{8!}{9!} < 1 \\
	\frac{1}{9} < 1 \\
\end{align} if it is not correct how it would be?","['inequality', 'number-comparison', 'proof-verification', 'algebra-precalculus', 'factorial']"
2762323,Find an asymptotic for $\sum_{j=1}^N \frac{1}{1 - \cos\frac{\pi j}{N}}$,"I need to find the asymptotic behavior of $$\sum_{j=1}^N \frac{1}{1 - \cos\frac{\pi j}{N}}$$
as $N\to\infty$. I found (using a computer) that this asymptotically will be equivalent to $\frac{1}{3}N^2$, but don't know how to prove it mathematically.","['summation', 'asymptotics', 'limits']"
2762346,How to solve $\mathrm{d}^n y/\mathrm{d}x^n = (\mathrm{d}y/\mathrm{d}x)^n$ or $(\mathrm{e}^D) y = \mathrm{e}^{(Dy)}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Is there a general analytical solution for 
$$ \frac{\mathrm{d}^ny}{\mathrm{d}x^n} = \left(\frac{\mathrm{d}y}{\mathrm{d}x}\right)^n,\qquad n>2? $$ or equivalently $(\mathrm{e}^D) y = \mathrm{e}^{(Dy)}$ where $\mathrm{D} = \frac{\mathrm{d}}{\mathrm{dx}}$ and $\mathrm{e}^D$ is the exponentiatin operator. For $n=2$, the solution is  $y(x) = c_2 - \log(c_1 + x)$.","['ordinary-differential-equations', 'lie-algebras']"
2762356,A question on Lyapunov exponents associated with a fixed point of a vector field.,"The Lyapunov exponent $\chi(x_{0}, e)$ in a direction $e \in \mathbb{R}^{n}$ along the trajectory $x(t,x_{0})$ of a vector field $\dot{x} = f(x)$ through a point $x_{0}$ is defined to be $$\chi(x_{0},e) = \lim_{t \to \infty}\frac{1}{t} \log \frac{||X(t;x(t,x_{0}))e||}{||e||}$$ where $X(t;x(t,x_{0}))$ is the fundamental solution matrix of the linearisation of the vector field orbit about $x(t,x_{0})$. Here $x \in \mathbb{R}^{n}$. Let us consider the case of the the orbit being a fixed point. It is known that then $\chi$ is just the real parts of the eigenvalues associated with the matrix of the vector field linearised about the fixed point. How does one prove this? Why do the imaginary parts of e-values do not contribute to $\chi$?","['dynamical-systems', 'stability-theory', 'chaos-theory', 'ergodic-theory', 'ordinary-differential-equations']"
2762373,"Showing $\int_0^s \int_0^u (F_1(u)-F_1(u-v)) f_1(u-v) e^{-v}\, dv\, du \leq \int_0^s \int_0^u (F_2(u)-F_2(u-v)) f_2(u-v) e^{-v}\, dv\, du$","Question Let $F(s)$ be a cumulative distribution function (cdf) of a random variable on $[0,\infty)$ which only has an atom at $0$, i.e. $F(0) >0$ and for all $s>0$:$$ \lim_{h\rightarrow 0}F(s+h)=F(s).$$
Let $\bar{F}(s)=1-F(s)$ and $f = F'(s)$. Note that$$
F(0) = 1-\int_0^\infty f(s) ds.$$ Now define the following operation on $F$:
$$
HF(s)=\int_0^s \int_0^u (F(u)-F(u-v)) f(u-v) e^{-v}\, dv\, du.
$$
Now suppose $F_1,F_2$ are both cdfs as described above, and suppose for all $s$, $F_1(s) \leq F_2(s)$ and $F_1(0)=F_2(0)$, show that $HF_1(s) \leq HF_2(s)$ for all $s$. Thoughts One can use Fubini to change the order of integration, the second part can then be solved by writing it as:
\begin{align*}
-\int_0^s \int_v^s F(u-v) f(u-v) \, du e^{-v}\, dv
&=
-\int_0^s\int_0^{s-v}F(u)f(u)\,du e^{-v}\,dv\\
&=-\frac{1}{2} \int_0^s \left( F(s-v)^2-F(0)^2 \right) e^{-v}\, dv.
\end{align*}
However we can not do something similar for the first part as here the argument of $F$ and $f$ are not the same.. Partal Integration As suggested in the answer, partial integration can be used to get rid of the density $f$. An alternative partial integration to use to simplify the first part is to note that the first part equals:
$$
\int_0^sF(u)\int_0^uf(u-v) e^{-v}dv du
$$
and then use partial integration on $\int_0^uf(u-v) e^{-v}dv$, integrating $f(u-v)$ and differentiating $e^{-v}$.","['real-analysis', 'inequality']"
2762404,Find the parameters of this distribution and the probability,"The mean weight of a leopard is 190kg. We look at the leopards in the Zoo and assume their weight to be normally distributed. We know that 5% of all leopards weigh more than 220kg. (a) Determine the parameters Âµ and Ïƒ for this distribution. (b) What is the probability that a randomly chosen leopard weighs between 160kg and 190kg So lets say that W= weight in kg, E[W]=190kg a)$0.95=P[W \le 220]= P[\frac{W-190}{\sigma \le \frac{30}{\sigma}}]=\phi \frac{30}{\sigma}â‰ˆ 1.64$ b)$P[160 â‰¤ G â‰¤ 190] = P[G â‰¤ 190]âˆ’P[G â‰¤ 160] = Î¦(0/Ïƒ)âˆ’Î¦(30/Ïƒ) â‰ˆ Î¦(2.87)âˆ’Î¦(2.05)â‰ˆ 0.018$ Is this correct? I was unsure on how to calculate this. Are the values right?","['normal-distribution', 'probability-theory', 'probability-distributions', 'probability', 'linear-transformations']"
2762406,Is sublattice of $Z^2$ generated by at most 2 elements?,Is it true that sublattice of $Z^2$ is generated by at most 2 elements? By $Z^2$ I mean the group of pairs of integers with addition coordinatewise.,"['linear-algebra', 'discrete-mathematics']"
2762427,"No. of boolean functions of $n$ variables constructible from AND and OR, but without NOT","Consider a Boolean function $f(x_1, x_2, \dots, x_n)$ from $\{0,1\}^n$ to $\{0,1\}$.  It is well known that there are $2^{(2^n)}$ such functions, because for each of $2^n$ possible input vectors you can choose the result.  Moreover, all these functions can be constructed with AND, OR, NOT, e.g. using disjunctive normal form.  (Obviously we allow each input $x_i$ to appear multiple times in the logic formula.)  My question is: How many such functions can be constructed if you can use AND, OR, but you cannot use NOT? As usual, a function is defined by its outputs.  So two different-looking formulas that agree on every input counts as the same function, e.g. $(x_1 \land x_2) \lor x_3$ is the same function as $(x_1 \lor x_3) \land (x_2 \lor x_3).$ My thoughts: At the very minimum, the function now must return $1$ when all inputs are $1$s, and must return $0$ when all inputs are $0$s.  (Note: constant functions $f\equiv 1$ and $f\equiv 0$ cannot be constructed using AND, OR, without NOT and without the literals $1, 0$ themselves.)  This upperbounds the number to $2^{(2^n-2)}$, because for those two input vectors you no longer have a choice of output.  However, I suspect this bound is extremely loose. More generally, consider input vectors $x$ and $y$ where $x_i = 1 \Rightarrow y_i = 1$ (or equivalently, $y_i = 0 \Rightarrow x_i = 0$).  Then I think any function with $f(x) = 1$ forces $f(y) = 1$, and similarly $f(y) =0$ forces $f(x) = 0$.  This is because turning some $0$s in the input into $1$s cannot decrease the output if you are only combining with AND, OR, but without NOT.  (However, I am not sure how to make this reasonsing rigorous...  maybe assume a tree structure of the formula and recurse up the tree?) Anyway, assuming the previous paragraph is correct, then it seems one approach is to consider an input vector $x$ as the subset of indices $\{i: x_i = 1\}$.  These $2^n$ subsets are partially ordered by inclusion, and any $f()$ must kind of define a ""surface"" of transition or a ""cut"" in the directed graph of ordering s.t. $f = 1$ on one side of the surface/cut (the side including the all $1$s vector), and $f=0$ on the other side.  However: (A) I have no idea how to count the number of such surfaces/cuts, and (B) I am not sure every such surface/cut can be constructed with AND, OR, but without NOT.  (I think each surface/cut can be constructed, as a disjunctive normal form of the ""minimal"" subsets for which $f = 1$, but I'm not perfectly sure.  Anyway if some surface/cut cannot be constructed, this would still provide an interesting upperbound on the number of such functions.) Further motivation: My original motivation was actually how many functions of $n$ real variables can be constructed by composing with $\max(,)$ and $\min(,)$, allowing each variable to appear multiple times in the formula.  However, after I noticed that $\max(x,\min(y,z)) = \min(\max(x,y), \max(x,z))$, I think they act like the Boolean AND, OR, so I think the questions are actually equivalent.  (Comments on this point are also welcome, even though it is not my main question.) Finally, expert users of MSE please feel free to edit the tags...  I'm not sure I'm using the right ones for this question.","['boolean-algebra', 'combinatorics', 'function-and-relation-composition']"
