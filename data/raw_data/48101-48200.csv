question_id,title,body,tags
485351,Matrix Differentiation of $x^TAx$ [duplicate],This question already has answers here : How to take the gradient of the quadratic form? (6 answers) Closed 3 years ago . I know the matrix differentiation of $x^TAx$ is if A is symmetric is 2Ax. I saw that some people write as $2x^TA$. Are these two results the same? I am not sure how they are same. Can anyone explain to me..,"['matrices', 'linear-algebra']"
485363,Tensoring a flasque resolution by a line bundle give s a flasque resolution,"I had an argument explained to me the other day and I didn't quite understand one of the steps.  Here's my best reconstruction: Let $\mathscr{F}$ be a quasi-coherent sheaf, and $\mathscr{L}$ a line
  bundle, on some scheme $X$.  Consider an injective, thus flasque,
  resolution $$ 0 \to \mathscr{F} \to \mathcal{J}_0 \to \mathcal{J}_1 \to \cdots$$ Tensoring by $\mathscr{L}$, we obtain a flasque resolution $$0 \to \mathscr{F} \otimes \mathscr{L} \to \mathcal{J}_0 \otimes
 \mathscr{L} \to \mathcal{J}_1 \otimes \mathscr{L} \to \cdots$$ of $\mathscr{F} \otimes \mathscr{L}$. Two questions: Is this correct as stated?  What is the proof? Why is the hypothesis that $\mathscr{L}$ is a line bundle needed?","['homology-cohomology', 'algebraic-geometry', 'schemes']"
485371,Domain for PDE Solution,"I'm working on PDE exercises for solutions via characteristics. The problems ask for the solution and its domain. For $$y^{-1}u_x + u_y = u^2, \quad u(x,1) = x^2$$
I found the solution to be 
$$ u(x,y) = \left( \frac{1}{(x- \ln |y|)^2} - y +1 \right) ^{-1}$$. So far, so good, but I can't find a clear way to express the domain. The best I've come up with is that it's ""the union of open connected sets $U \subset \mathbb{R}^2$ such that $x \neq \ln |y|$ and $(x - \ln |y|)^2(y-1) \neq 1$ for all $(x,y) \in U$ and there exists a point $(x_0, 1) \in U$.    I.e., nothing in the solution breaks, and part of the initial data is in the set. For another, 
$$ u_x + u^{1/2} u_y = 0, \quad u(x,0) = x^2+1,$$
I get the implicit formula $u(x,y) = (x-\frac{y}{u(x,y)^{1/2}})^2 +1$, and here again, I don't see a good way to describe the domain. Is there some other way to express the solutions, or another way to think about them, which would make the domain clearer? I'm running into this problem over and over, and would appreciate any guidance. Thanks.","['ordinary-differential-equations', 'partial-differential-equations']"
485378,Convergence of $\sum_n a_nb_n$ for all $b_n\searrow 0$ implies convergence of $\sum_n a_n$,"I need a hint for a practice problem: Let $a_n \geq 0$. Show that if $\displaystyle\sum_{n=1}^\infty a_nb_n$ converges for every monotonically decreasing sequence $b_n \to 0$, then $\displaystyle\sum_{n=1}^\infty a_n$ converges. I've been trying to use the fact that $\sum\limits_{n=1}^\infty a_n r^n \leq M < \infty$ for all $r \in [0,1)$ iff $\displaystyle\sum_{n=1}^\infty a_n$ converges, but I can't seem to get it, so I'm not sure that's the right way to go about it. Thanks in advance!","['convergence-divergence', 'sequences-and-series', 'analysis']"
485402,"If $A^3=I$ for a real matrix, is $A$ normal/orthogonal?","I read earlier that if $A$ is a real $3\times 3$ matrix satsifying $A^3=I$, then $A$ is similar to a matrix of form
$$
\begin{bmatrix}
1 & 0 & 0\\
0 & \cos\theta & -\sin\theta\\
0 & \sin\theta & \cos\theta
\end{bmatrix}
$$ From the structure theorems for normal operators, I know that among the real normal operators, the othogonal operators are exactly those matrices which are block diagonal with their eigenvalues and $2\times 2$ blocks of the above form. So I suppose $A$ must be normal/orthogonal? Is there a way to deduce that at all from just knowing that $A^3=I$ without appealing to the structure theorem in hindsight?",['matrices']
485407,What is a the intuition behind a parametric equation?,"I have always used equations for the line (y=a + bx) in R2. Recently I came upon this thing called parametric equations. I cannot grasp the difference between them and the equations for lines that I used before. Of course, I can't understand the plane and the parametric equations for it. Any good example or reference for having a good intuition about them. I'm a first year student in economics, if possible, an example in economics will be of great help. I recently saw a video on khan academy about parametric equations where both x and y depend on time, time being the parameter. Why not just make a 3d graph with 3 variables: x, y and t instead of a parametric equation in 2d?","['plane-curves', 'linear-algebra', 'euclidean-geometry']"
485408,How prove $\lim_{n\to \infty}\frac{n}{\ln{(\ln{n}})}\left(1-a_{n}-\frac{n}{\ln{n}}\right)=-1$?,"Let equation $x^n+x=1$ have positive root $a_{n}$ . Show that $$\lim_{n\to \infty}\frac{n}{\ln{(\ln{n}})}\left(1-a_{n}-\dfrac{n}{\ln{n}}\right)=-1$$ some hours ago,it prove that $$\lim_{n\to \infty}\frac{n}{\ln{n}}(1-a_{n})=1$$ How prove this limit $\displaystyle\lim_{n\to \infty}\frac{n}{\ln{n}}(1-a_{n})=1$ this problem is from china paper(1993): http://www.cnki.com.cn/Article/CJFDTotal-YEKJ199301013.htm and this paper poof is very ugly,so I want see other nice methods,I kown these can use Incremental estimation analysis,Thank you","['sequences-and-series', 'roots', 'limits']"
485423,Fictional math proof = prime return function,"I am trying to write a piece of future fiction where one of the characters is famous for proving an important truth related to primes.  I want to make it as realistic as possible, but i'm not a math major, and I need some guidance. Basically the ""function"" takes as any input an real number and returns (in a single step) a real number related to prime numbers.  so an integer like ""3"" returns the prime number ""5"", and something like ""3.5"" returns ""6"", a real number between prime #3 (5) and prime #4 (7). The function is also reversible, so any number can (again in a single step) be determined to be prime. e.g. input of ""29"" returns ""10"", and because that's an integer we know it's prime, and the 10th prime.  It would work both ways for any size of input number. What would be the downstream effects of such a ""function"" being proven true?  How would this kind of ""function"" open up new avenues of research in math?  Would something like this be more obscure and only known to mathematicians, or known broadly to the general public, or somewhere in between, like Poincaré's theorem?","['prime-numbers', 'recreational-mathematics', 'number-theory']"
485431,When should one use the two-point compactification of $\mathbb R$?,"The real line $\mathbb R$ has a one-point compactification $\mathbb R\cup\{\infty\}$, where this ""$\infty$"" is at both ends of the line, so that the compactification is topologically a circle. It also has a two-point compactification $\mathbb R\cup\{\pm\infty\}$. With rational functions $\lim\limits_{x\to\pm\infty}$ doesn't depend on whether it's $+$ or $-$.  With vertical asymptotes, if one wishes to distinguish between two different ways of blowing up, one could say $f(x)\to\infty\!-$, i.e. $f(x)$ approaches $\infty$ from below, instead of $f(x)\to+\infty$, and similarly for the other direction.  That makes rational functions continuous everywhere, including the points where they have vertical asymptotes and the point $x=\infty$. With trigonometric functions, one can take the domain to be $\mathbb R/2\pi\mathbb Z$ and the codomain to be $\mathbb R\cup\{\infty\}$ and treat vertical asymptotes as with rational functions.  That also makes trigonometric functions continuous even at points where they have vertical asymptotes, and the function $\theta\mapsto\tan(\theta/2)$ becomes a homeomorphism from $\mathbb R/2\pi\mathbb Z$ to $\mathbb R\cup\{\infty\}$. This seems like a more felicitous way of doing things than any that involves two infinities. When, then, should one distinguish between $\pm\infty$?  Part of the answer seems to be with exponential functions:
$$
e^x\to\begin{cases} 0 & \text{as }x\to-\infty, \\ \infty & \text{as }x\to+\infty. \end{cases}
$$
In that case, it doesn't seem to make as much sense to say ""as $x\to\infty\!+$"" and ""as $x\to\infty\!-$"".  Similarly
$$
\arctan x \to \pm\frac\pi2\text{ according as }x\to\pm\infty.
$$ Is there more to the story than that?  If not, should we abandon $\pm$ in the case of rational functions and trigonometric functions?","['general-topology', 'calculus', 'real-analysis']"
485434,"What does ""generic"" mean in this context, and is it related to generic points in algebraic geometry?","In ""The characteristic polynomial and determinant are not ad hoc constructions"" by Skip Garibaldi, available at http://arxiv.org/abs/math/0203276 the characteristic polynomial is defined as the minimal polynomial of a ""generic element.""  Specifically, this is the setup: Let $F$ be a field and $A$ a finite-dimensional $F$-algebra. Let $\{a_1, \ldots, a_m\}$ be an $F$-basis for $A$. Let $R = F[t_1, \ldots, t_m]$ and $K = \operatorname{Frac} R = F(t_1,
> \ldots, t_m)$. Consider $\gamma = \sum_i a_i \otimes t_i \in A \otimes_F K$, which we
  call a generic element . Since $A \otimes_F K$ is a finite-dimensional $K$-vector space,
  $\operatorname{span} \{1, \gamma, \gamma^2, \ldots \}$ is
  finite-dimensional, so $\gamma$ has a minimal polynomial $m \in K[x]$,
  and it's easy to see that in fact $m \in R[x]$.  We define the
  characteristic polynomial of $a = \sum_i c_i a_i \in A$ to be the
  image of $m$ under the map $R[x] \to F[x]$ given by $t_i \mapsto c_i$. This is a nice argument, but it still feels a bit ad-hoc to me: we have to explicitly calculate that doesn't rely on the choice of $F$-basis, for instance, and why is $\gamma$ specifically a ""generic"" element of $A \otimes_F K$? I mean, I understand the idea of taking a matrix filled with indeterminates and computing its minimal polynomial, but it doesn't seem to be a natural thing to do from a purely algebraic perspective. Is there some way to rephrase this argument so that we can view $A$ as having a scheme structure and to regard $m$ as the ""minimal polynomial of the generic point"" or something of the sort?  I've tried a couple things but just get to a point where it seems like we're commingling elements of a -- is it called an ""algebra scheme?"" -- together with functions on it, and I get confused by the whole thing.  But that could just be my inexperience.","['linear-algebra', 'algebraic-geometry']"
485443,Finitely Additive not Countably Additive on $\Bbb N$,"Does there exist a function defined on the power set of the natural numbers to the interval from $0$ to $1$, $p:2^{\Bbb N}\rightarrow [0,1]$, such that $p$ is finitely additive, i.e. $p(A_1\cup\ldots\cup A_n)=p(A_1)+\ldots +p(A_n)$ for all pairwise disjoint subsets $A_i$ of $\Bbb N$ and some $n\in\Bbb N$, but $p$ is not countably additive. $p$ also satisfies the condition that $p(\Bbb N)=1$, $p(\emptyset)=0$.","['probability-theory', 'set-theory', 'descriptive-set-theory']"
485448,prove the way to generate geometrically distributed random numbers,"The way to generate geometrically distributed random numbers is the following $$\lfloor{\ln(u)/\ln(1-p)}\rfloor$$ where $u$ is uniformly distributed in $[0,1]$ and $p$ is the parameter in the geometric distribution. But can anybody help provide a rigorous proof? I only see that $\ln(u)/\ln(1-p)$ is exponentially distributed, but how to get the geometric distribution?",['probability']
485451,Weak convergence vs Convergence in Measure,"What is the difference between weak convergence and convergence in measure? example let 
$\mu_{n}\Rightarrow \mu$ on $[0,1]$ (the space where all measures are defined is $[0,1]$.)
How does this contrast with the statement that we have a sample space $\Omega$ on which are defined random variables $X_{1},\ldots,$ which map $\Omega $ to $[0,1]$ and $X_{n}$ converges in measure to some random variable $X$.","['weak-convergence', 'measure-theory', 'convergence-divergence']"
485461,Why can't all subsets of sample space be considered as events?,"My textbook is Probability and random processes by Grimmett & Stirzaker and the first chapter does not explain this,"" for reasons beyond the scope of the book"". The authors introduce the reader to sample spaces and to events and then go on to say that events are subsets of sample space. Then they ask, ""Need all subsets of sample space be events ?"" and then they say no. But I don't see why not. Can anyone give mean an intuitive explanation for this?",['probability']
485462,Birthday Problem for 3 people,"I know that, in a room of 23 people, there is a 50-50 chance that two people have the same birthday. However, what I want to know is: How many people do you need to have a 50-50 chance that 3 people share the same birthday? Note: Assume for this question, that birthdays are equally distributed","['birthday', 'probability']"
485469,Proving logical equivalences,"I've been stuck on this one problem for a couple of days now with no clue on how to complete it. I need to prove the following logical equivalence: $$\neg((\neg q \wedge \neg p) \vee (r \wedge q) \vee (r \wedge \neg p)) = (\neg q \rightarrow \neg p) \rightarrow \neg(q \rightarrow r).$$ If anyone could shed some light on this matter, please..","['logic', 'discrete-mathematics']"
485473,What new insights does numerical analysis give on linear algebra?,"I know linear algebra decently well, but I've never taken a numerical analysis course.
However, I've heard that it provides a good intuition for the subject. Assuming that I'm already familiar with most linear algebra concepts and matrix decompositions, in what way would a numerical analysis course benefit my understanding? Are there any concrete examples of something valuable from a computational perspective that one wouldn't get in a more abstract setting?","['numerical-linear-algebra', 'linear-algebra', 'numerical-methods']"
485493,Diameter of a Connected Graph,"Problem Prove that if $G$ is connected and $\text{ diam}(G) \geq 3$ , then $\overline{G}$ is connected. Prove that if $\text{ diam}(G) \geq 3$ , then $\text{ diam}(\overline{G}) \leq 3.$ Prove that if $G$ is regular and $\text{ diam}(G) = 3$ , then $\text{ diam}(\overline{G}) = 2$ . Approach I tried to find relationships between the diameters of $G$ and $\overline{G}$ , but all I could think of was the effect of adding edges to the graph reduces the diameter in most cases, but not necessarily. Any help would be greatly appreciated!","['graph-theory', 'combinatorics']"
485512,Subgroups of a direct product,"Until recently, I believed that a subgroup of a direct product was the direct product of subgroups.  Obviously, there exists a trivial counterexample to this statement. I have a question regarding this.  It is threefold: I hear that a theorem called Goursat's lemma states characterization of subgroups of a direct product.  I read it on Lang's Algebra, but its statement is a bit counterintuitive and I do not know how to use it to solve problems.  I would be grateful if you could give a hint regarding this lemma. I had the aforementioned false belief when I tried to solve this problem , and it seemed to work in this specific problem.  When is the generally false statement hold? (Or is my reasoning in concluding the answer to the problem is 8  flawed?) I have problems similar to the previous one, namely, counting the subgroups of $\Bbb Z/p\Bbb Z \times \Bbb Z/p \Bbb Z$ and $\Bbb Z/p^2\Bbb Z \times \Bbb Z/p^2 \Bbb Z$, where $p$ is a prime number.  How can I use the previous considerations to solve this problem? I would appreciate your help. EDIT: I fixed a typo in the last problem. EDIT 2: The problem I mentioned in 2. is actually about the number of elements of some order, not that of subgroups. (I forgot about that when I wrote this question.)  I am still interested in the question stated in 2., though.","['finite-groups', 'group-theory', 'direct-product']"
485513,what are pivot numbers in LU decomposition? please explain me in an example,"studying many pages like wikipedia , wolfram , Mathworks , Math Stack Exchange , lu-pivot , LU_Decomposition I couldn't find exactly whart are the pivot numbers in a specific example: for example what are the pivot numbers in this example: (I've extracted the LU-decomposition above based on an example in this pdf. ) or this one: Can you explain me how to extract the pivot numbers in both the examples above? Also if it is possible, can you explain me about these questions alittle? How can we extract pivot numbers in various forms of pivoting. e.g. LU factorization with Partial Pivoting ( PA = LU ) , LU
factorization with full pivoting ( PAQ = LU ) , LDU decomposition (
A = LDU ) ? How can we understand what permutation matrix ( P ) should be
multiplied by ( A ) to be able to extract a stable LU-decomposition
before starting to decompose?","['matrices', 'linear-algebra']"
485515,Trigonometric equation in two ways gives different answer,"I have been given the equation $\sin^2 x+ \cos x +1 = 0.$ I tried to solve it in two ways. First, $1 - \cos^2(x) + \cos(x) + 1 = 0,$ $\cos^2(x) - \cos(x) - 2 = 0,$ $\cos x=2$ or $\cos x=-1$ thus $x=\pi+n2\pi$ for all $n\in \mathbb{Z}.$ Second approach. Let $\tan \frac{x}{2}=t.$ Then $\sin x=\frac{2t}{1+t^2}$ and $\cos x=\frac{1-t^2}{1+t^2}.$ Thus the equation is
$$\left (\frac{2t}{1+t^2}\right )^2+\frac{1-t^2}{1+t^2}+1=0.$$ Therefore
$$4t^2+(1-t^2)(1+t^2)+(1+t^2)^2=0.$$ But $$4t^2+(1-t^2)(1+t^2)+(1+t^2)^2=4t^2+1-t^4+1+2t^2+t^4=6t^2+2>0.$$
and there is no solutions. What is my mistake in the second reasoning?",['trigonometry']
485517,What should be the proportions of a three sided coin?,"A classical coin has almost no chances of ending its course on the side when tossed. A round pencil with both ends flat has no chance of ending its course on the tip, when tossed. What would be the proportions of a cylinder that has 1/3 chances to land on one end, 1/3 chances to land on the other end and 1/3 chances to land on the side? I think my basic approach by integration is useless, I'm not even sure how to start.","['geometry', 'probability-distributions']"
485524,Why does this series converge?,"My question is: Why does the series $$ \sum_{j,k=1}^\infty \frac{1}{j^4+k^4} $$ converge? I tested the convergence with Mathematica and Octave, but I can't find an analytical proof. In fact, numerical computations suggest that the value of the series is $<1$. One obvious thing to do would be to use the generalized harmonic series to see that \begin{align} \sum_{j,k=1}^\infty \frac{1}{j^4+k^4} &= \sum_{k=1}^\infty \frac{1}{2k^4} + \sum_{j,k=1; j\neq k} \frac{1}{j^4+k^4} \\ &= \frac{\pi^4}{180} + \sum_{j=1}^\infty \sum_{k=1}^{j-1} \frac{1}{j^4+k^4} + \sum_{j=1}^\infty \sum_{k=j+1}^{\infty} \frac{1}{j^4+k^4}\\ &\leq \frac{\pi^4}{180} + \sum_{j=1}^\infty \sum_{k=1}^{j-1} \frac{1}{(j-k)^4} + \sum_{j=1}^\infty \sum_{k=j+1}^{\infty} \frac{1}{(j-k)^4} \end{align} but unfortunately the last two (double-)series do not converge. The problem arises when one tries to estimate the Hilbert-Schmidt norm of the Laplacian in $H^2(\mathbb{T}_\pi^2)$.","['convergence-divergence', 'sequences-and-series']"
485527,"Proving a function $f(m,n)$ which satisfies two conditions is a constant","I found the following question in a book only with one sentence. ""This question can be solved by an elementary way. Note that the following two are false: (1) If a function is bounded from below, then it has minimum value. (2) A monotone decreasing sequence reaches a negative value."" Question : Let $m,n$ be integers. Supposing that a function $f(m,n)$ defined by $m,n$ satisfies the following two conditions, then prove that $f(m,n)$ is a constant. 1. $f(m,n)\ge0$. 2. $4f(m,n)=f(m-1,n)+f(m+1,n)+f(m,n-1)+f(m,n+1)$. I suspect this question can be solved by a geometric aspect. I've tried to prove this, but I'm facing difficulty. Could you show me how to prove this?","['functions', 'number-theory']"
485547,A generator (or a cogenrerator) for the category of schemes,Does the category of Schemes admit a (single) generator (or a cogenerator)? What if we restrict to the category of schemes of finite type over a field $k$?,"['category-theory', 'algebraic-geometry']"
485586,Sum involving the Digamma function.,"Consider the double sum
$$f(x):=\sum_{m=1}^\infty\sum_{n=1}^\infty\frac{1}{m+\frac{1}{n+x}}-\frac{1}{m+\frac{1}{n}},$$
which converges for $x>0$.  One interpretation of this sum is the measure of the double preimage $T^{-2}([0,x])$, in which $T:[0,1]\to [0,1]$ denotes the Gauss map $T(x)=\{1/x\}$ (the fractional part of $1/x$). Let $\psi$ denote the Digamma function $\psi(z):=\Gamma'(z)/\Gamma(z)$.  The identity
$$\psi(z)=-\gamma+\sum_{k=0}^\infty\left(\frac{1}{n+1}-\frac{1}{n+z}\right)$$
can then be used to rewrite $f$ as
$$f(x)=\sum_{n=1}^\infty \psi\left(1+\frac{1}{n}\right)-\psi\left(1+\frac{1}{n+x}\right).$$
Is there any closed-form simplification of the sum above?  It seems plausible that there may be such a solution involving the higher Polygamma function $\psi^{(2)}$.","['gamma-function', 'sequences-and-series']"
485604,How find the value $\lim_{x\to 0}\dfrac{1}{x^2}\left(1-\cos{x}\cdot\sqrt{\cos{(2x)}}\cdots\sqrt[n]{\cos{(nx)}}\right)$,"find the value
$$I_{n}=\lim_{x\to 0}\dfrac{1}{x^2}\left(1-\cos{x}\cdot\sqrt{\cos{(2x)}}\cdots\sqrt[n]{\cos{(nx)}}\right)$$ This is my methods:
\begin{align*}I_{n+1}-I_{n}&=\lim_{x\to 0}\dfrac{1}{x^2}\left(\cos{x}\cdot\sqrt{\cos{(2x)}}\cdots\sqrt[n]{\cos{(nx)}}\left(1-\sqrt[n+1]{\cos{(n+1)x}}\right)\right)\\
&=\lim_{x\to 0}\dfrac{1-\sqrt[n+1]{\cos{(n+1)x}}}{x^2}\\
&=\dfrac{n+1}{2}
\end{align*}
so
$$I_{n}=\dfrac{n(n+1)}{4}$$ Have you other nice methods? Thank you","['calculus', 'limits']"
485626,Prove that some set is compact directly from definition,"Let $A$ be a subset of $R$ which consist of $0$ and the numbers $\frac{1}{n}$, for $n=1,2,3,\dots$. I want to prove that $K$ is compact directly from the definition of compact. So, given any open cover of $A$, I should be able to find a finite subcover. Proving a set is compact is much difficult than proving not compact. I have find a process of finding a finite sub cover for every open cover which means I need to find some common property of every open cover.","['metric-spaces', 'real-analysis']"
485648,Transvection matrices generate $ \operatorname{SL}_n(\mathbb{R}) $,"I need to prove that the transvection matrices generate the special linear group $\operatorname{SL}_n \left(\mathbb{R}\right) $ . I want to proceed using induction on $n$ . I was able to prove the $2\times 2$ case, but I am having difficulty with the $n+1$ case. I supposed that the elementary matrices of the first type generate $\operatorname{SL}_n(\mathbb{R})$ . And I want to show that an elementary matrix of the first type of order $n+1$ can generate $\operatorname{SL}_{n+1}(\mathbb{R})$","['algebraic-k-theory', 'matrices', 'group-theory']"
485663,Prove that a doubly transitive group is primitive.,"A transitive permutation group on a set $A$ is called doubly transitive if for any (hence all) $a \in A$ the subgroup $G_a$ is transitive on the set $A - \{ a \}$ . (a) Prove that $S_n$ is doubly transitive on $\{1, 2, \dotsc, n\}$ for all $n ≥ 2$ . (b) Prove that a doubly transitive group is primitive. Deduce that $D_8$ is not doubly transitive in its action on the $4$ vertices of a square. ( Original image ) My Attempt: (a) $S_n$ is transitive on $\{1,2,\dotsc,n\}$ and for any $(i,j)\in G_a$ , $(i,j)i=j$ whence $G_a$ is transitive on $\{1,2,\dotsc,n\}-\{a\}$ . (b) Without loss of generality let $|A|\ge2$ . Case I: $|A|=2$ or $3$ then $|A-\{a\}|=1$ or $2$ whence the blocks became trivial. So $G$ become primitive in this case. Case II: $|A|\ge4$ then $|A-\{a\}|\ge3$ . $A-\{a\}$ can’t have a nontrivial block $B$ since for any $i\in \{A-a\}-B$ and $j\in B$ , $(i,j)\in G_a$ and $(i,j)(B)$ is neither equal or disjoint with $B$ . Hence the result. $D_8$ is not doubly transitive: Label the four vertices as $1,2,3,4$ consecutively. Consider the action of $G_4,$ the stabilizer of $4,$ on $\{1,2,3\}$ . Then $\{1,3\}$ is a nontrivial block since $G_4$ contains only the reflection about the line of symmetry passing through $4$ and the identity. My Questions: Is my attempt correct? Do we define ‘blocks’ (and hence ‘primitive’) only when $A$ is finite ? (Even though in this exercise I never used finiteness of $A$ this question comes into my mind from their definition as given in Dummit-Foote text: Let $G$ be a transitive permutation group on a finite set $A$ . A block is a nonempty subset $B$ of $A$ such that for all $\sigma \in G$ , either $\sigma(B) = B$ or $\sigma(B) \cap B = \emptyset$ (here $\sigma(B)$ is the set $\{ \sigma(b) \mid b \in B \}$ . (a) Prove that if $B$ is a block containing the element $a$ of $A$ , then the set $G_B$ defined by $G_B = \{ \sigma \in G \mid \sigma(B) = B \}$ is a subgroup of $G$ containing $G_a$ . (b) Show that if $B$ is a block and $\sigma_1(B), \sigma_2(B), \dotsc, \sigma_n(B)$ are all the distinct images of $B$ under the elements of $G$ , then these form a partition of $A$ . (c) A (transitive) group $G$ on a set $A$ is said to be primitive if the only blocks in $A$ are the trivial ones: the sets of size $1$ and $A$ itself. Show that $S_4$ is primitive on $A = \{1, 2, 3, 4\}$ . Show that $D_8$ is not primitive as a permutation group on the four vertices of a square. (Original image)","['group-actions', 'group-theory', 'abstract-algebra']"
485700,Understanding Proof of Hopcroft & Karps Matching Algorithm,"Hopcroft & Karps algorithm to compute a maximum matching takes $\mathcal O(mn^{1/2})$ time, which is composed by $\mathcal O(n^{1/2})$ iterations and each iteration taking $\mathcal O(m)$. In my lecture script it says $\mathcal O(n^{1/2})$ iterations is bases on the fact that there are ""relativly"" short $M$-augmenting paths of maximal length of $2\cdot \lfloor |M|/ (s - |M|) \rfloor +  1$. I am having trouble understanding this upper bound for a path's length. Remarks: $G = (V, E)$ with $V = U \cup W$ bipartite graph $s \le n = |V|$ cardinality of a maximum matching $S$ $M$ any matching in $G$ Moreover, I know that After every iteration there are no shortest path of length $l$ anymore. shortest $M$-augmenting paths extend by the additive factor of 2, since they always have odd length. Matching $|M \triangle P| =  |M| + 1$ where $\triangle$ is the symmetric difference of a matching $ M$ and a $M$-augmenting Path $P$","['graph-theory', 'algorithms', 'combinatorics']"
485715,Prove $\sum_n^{\infty} \prod_{k=0}^n \dfrac{1}{x+k} = e \sum_ n^{\infty} \dfrac{(-1)^n}{(x+n)n!}$,Let $$f_n(x) = \prod_{k=0}^n \dfrac{1}{x+k}.$$ Show that $$\sum_{n=0}^{\infty} f_n(x) = e \sum_ {n=0}^{\infty} \dfrac{(-1)^n}{(x+n)n!}.$$,"['sequences-and-series', 'calculus', 'real-analysis']"
485728,A (probably) wrong exercise from Morandi's Field and Galois theory,"After some efforts I realize that the following exercise is wrong: (rings are unitary throughout the book) Morandi's Field and Galois Theory, Appendix A, exercise 18 (b) Let $A\subseteq B$ be commutative rings, suppose that there's a subset $S$ of $A$ that is closed under multiplication, every element of $S$ is a unit in $B$, and $B=\{a/s\colon a\in A,s\in S\}$. If $a\in A-S$, show that $aB\cap A=aA$. We write $B=A_S$ when $B$ is of this form. The next exercise is: (c) Let $A\subseteq B$, and suppose that there's a set $S$ as in Problem 18b with $B=A_S$. If $P$ is a prime ideal of $A$ with $P\cap S=\emptyset$, show that $PB$ is a prime ideal of $B$ and that $PB\cap A=P$. Exercise 18b is wrong. Let $A=\mathbb Z$, and $S=\{2^n\colon n\in\mathbb Z_{\ge0}\}$, then $B=\{m/2^n\colon m\in\mathbb Z,n\in\mathbb Z_{\ge0}\}$. Set $a=6$, then $aB\cap A=3\mathbb Z$, not $6A$. The preceding paragraph says that some of these parts are standard facts of localization . I believe that there's some typo in 18b, and 18c should be right. I have no idea on the topic of localization, so I don't know how to modify it to a true statement. Any idea? Thanks!","['commutative-algebra', 'ring-theory', 'ideals', 'abstract-algebra']"
485731,What are the higher derivatives of a multivariate function?,"I have recently realized that I am not sure what it means to consider $F''(x)$ and general higher derivatives for $F: \mathbb R ^n \rightarrow \mathbb R^m$. I am clear the at the first derivative is a matrix of partial derivatives $ \left( \begin{array}{ccc}
\frac{\partial f_1}{\partial x_1}(x) & ... & \frac{\partial f_1}{\partial x_n}(x) \\
... & ... & ... \\
\frac{\partial f_m}{\partial x_1}(x) & ... & \frac{\partial f_m}{\partial x_n}(x) \end{array} \right) $. But I am not sure how to differentiate this matrix. Do I want to treat it as a vector and then get the first derivative of the function $G: \mathbb R^n \rightarrow \mathbb R^{n \times m}$ which sends $x$ to the vector of partial derivatives?","['multivariable-calculus', 'calculus', 'derivatives']"
485734,Countable additivity implies countable subadditivity?,"Suppose $\mu$ is a measure in a ring $R$ of a set $X$. So for any mutually disjoint subsets $A_1,A_2,\ldots$ such that $\sum_{i=1}^\infty A_i\in R$, we have that $\mu(\sum_{i=1}^\infty A_i) = \mu(A_1)+\mu(A_2)+\cdots$. (i.e. countable additivity) I'm wondering: Does that imply countable subadditivity? I.e. for any subsets $A_1,A_2,\ldots$ such that $\sum_{i=1}^\infty A_i\in R$, is it always true that $\mu(\sum_{i=1}^\infty A_i)\le \mu(A_1)+\mu(A_2)+\cdots$? I believe it should be true, because you can take the mutually disjoint subsets $A_1,A_2-A_1,A_3-(A_1\cup A_2),A_4-(A_1\cup A_2\cup A_3),\cdots$, each of which is in $R$ (because unions and differences of sets in $R$ are again in $R$), then apply countable additivity, then use monotonicity on the fact that $A_n-(A_1\cup\cdots\cup A_{n-1})\subseteq A_n$. Is that right? I just want to make sure I didn't make any mistake in my logic.","['measure-theory', 'real-analysis']"
485741,About binary relations under certain conditions and their composition,"(I have edited it. The previous version was with errors.) Let $A$ be a set. Let $\pi_0$, $\pi_1$ be projections from $A\times A$. Let $F_0$, $F_1$, $G_0$, $G_1$ be binary relations on $A$. Let $\Phi_A$ be the maximal binary relation in $(A\times A)\times(A\times A)$ such that $\pi_0\circ\Phi_A\subseteq F_0\circ\pi_0$ and $\pi_1\circ\Phi_A\subseteq F_1\circ\pi_1$. Let $\Phi_B$ be the maximal binary relation in $(A\times A)\times(A\times A)$ such that $\pi_0\circ\Phi_B\subseteq G_0\circ\pi_0$ and $\pi_1\circ\Phi_B\subseteq G_1\circ\pi_1$. Prove (or disprove) that $\Sigma=\Phi_B\circ\Phi_A$ is the maximal binary relation on $A$ such that $\pi_0\circ\Sigma\subseteq G_0\circ F_0\circ\pi_0$ and $\pi_1\circ\Sigma\subseteq G_1\circ F_1\circ\pi_1$.","['relations', 'products', 'elementary-set-theory']"
485747,Why $G/N$ is discrete?,"I am reading the lecture notes . On page 15, Line -5, why $G/N$ is discrete? Thank you very much.","['algebraic-groups', 'representation-theory', 'group-theory']"
485752,TicTacToe State Space Choose Calculation,"I understand there are numerous questions around the internet about the state space of tic-tac-toe but I have a feeling they've usually got it wrong. Alternatively, perhaps it is I who have it wrong. Which is what leads me to my question. Common Over Estimates: Over Estimate One: First some common answers to the number of possible states in Tic-Tac-Toe: $9! = 362880$ This is one solution, which is overstates the upper-bound by the most I have seen, as it includes states such as: x1|o2|
--------
  |  |
--------
  |  | as well as: x2|o1|
--------
  |  |
--------
  |  | and all the other sequences of combinations possible. (Thank you to Exodus5 for pointing out the error.) Over Estimate Two: Another common answer that is better, common, but still over-estimating is: $3^9 = 19683$ Which is better. Now we only count the following board once... x|x|x
-----
x|x|x
-----
x|x|x but I've still never heard of any type of one-player tic-tac-toe and it seems boring. These guys claim they've got the answer but they are discussing games not state-spaces. That is the progression of the N-moves in a game is also taken into account. The Power of Choose: After sitting down and thinking for awhile I came up with a formula that does a more precise job at estimating the state space of tic-tac-toe and it is quite simple, but still not 100% as it still overestimates. $9 \choose 1$ * $8 \choose 0$ +
$9 \choose 1$ * $8 \choose 1$ +
$9 \choose 2$ * $7 \choose 1$ +
$9 \choose 2$ * $7 \choose 2$ +
$9 \choose 3$ * $6 \choose 2$ +
$9 \choose 3$ * $6 \choose 3$ +
$9 \choose 4$ * $5 \choose 3$ +
$9 \choose 4$ * $5 \choose 4$ +
$9 \choose 5$ * $4 \choose 4$ = 9+72+252+756+1260+1680+1260+630+127 = 6046 Edit: The final term above I had $4 \choose 5$ but the correct value is $4 \choose 4$ which yields the missing 1 from Immanuel's solution. Essentially each term of $9 \choose X$ is placing the X's on the board, then the $K \choose L$ is the O's choosing the appropriate number of places from the remaining open spaces on the board. Each term being added is the number of states being generated at each turn. So for turn 1 we have 9 states, for turn 2, 72 states and so on. The main point here is 6046 is far fewer than the other estimations, the use of Choose seems rather elegant considering its simplicity and the accuracy we are able to achieve, and lastly I like how each term being added correlates to each turn. I recognize that it is not perfect, as I am ignoring some win conditions, i.e. this board is also counted: x|x|x
-----
x|o|o
-----
x|o|o Which isn't a legitimate board but still 6045 is less than $1/3$ of the commonly stated $3^9$ and isn't the equation rather beautiful? The Question: The question is, does this application of choose accurately represent how X's and O's can alternatively be placed on a 3x3 grid? Have I missed anything? Bonus question: Any insights on how to estimate the number of illegitimate boards during moves 6, 7, 8, and 9? Note: With 5 or fewer moves, all boards generated are legitimate. The goal is not to have a computer brute force the thinking for us, but to gain a deeper understanding of the distribution of win conditions. Also to make sure I didn't make any mistakes.","['combinatorial-game-theory', 'combinatorics']"
485755,Do there exist an infinite number of 'rational' points in the equilateral triangle $ABC$?,"Let's call a point $P$ which satisfies the following condition 'a rational point'. Condition : Each distance $PA, PB, PC$ from a point $P$ to three vertices $A, B, C$ of an equilateral triangle $ABC$ which has edge-length $1$ is rational number . I'm interested in this point because I found the following three: 1. There exist an infinite number of rational points on an edge of the equilateral triangle $ABC$. 2. There exist an infinite number of rational points on the circumference of the circumscribed circle of the equilateral triangle $ABC$. 3. There exists a rational point in the equilateral triangle $ABC$. Supposing that $A(0,\frac{\sqrt3}{2}), B(-\frac12,0), C(\frac12,0)$, one example for the above 3 is the following:
$$P\left(\frac{61}{2058},\frac{220}{1029}\sqrt3\right), \left(PA, PB, PC\right)=\left(\frac{73}{147}, \frac{95}{147}, \frac{88}{147}\right).$$ I found this example by using computer. I found the other examples, but I don't know there exist an infinite number of rational points in the equilateral triangle $ABC$. Then, here are my questions. Question 1 : Do there exist an infinite number of rational points in the equilateral triangle $ABC$ ? Question 2 : Can we find all rational points in the equilateral triangle $ABC$ ?","['geometry', 'triangles', 'rational-numbers', 'euclidean-geometry']"
485757,Does the set of computable numbers get bigger if we strengthen our language?,"This might be a silly question, but can one given an example for a number, which is not computable? I want to get a mental picture of what these real numbers are, which you can't write down. At the end of this Wikipedia article en.wikipedia.org/wiki/Computable_number it says To actually develop analysis over computable numbers, some care must be taken. For example, if one uses the classical definition of a sequence, the set of computable numbers is not closed under the basic operation of taking the supremum of a bounded sequence (for example, consider a Specker sequence). This difficulty is addressed by considering only sequences which have a computable modulus of convergence. The resulting mathematical theory is called computable analysis. So does this say that one has identified something uncomputable here? But if this is so, doesn't a description of such a thing give us a way of compute it or the object it represents? If we step by step forever strengthen our language, do we somehow obtain more numbers out of the set or $\mathbb R\setminus\mathrm{computable numbers}$? Or is it that we can say ""once we've got a process of this and that computing power, we can compute certain numbers and never more.""?","['computer-science', 'real-analysis']"
485764,On the Hessian matrix and its properties,"For a $2$ -variable function $f(x,y)$ , the Hessian matrix is just the quadratic term of Taylor expansion, $$H = \left[\begin{array}{cc}f_{xx} & f_{xy}\\ f_{xy} & f_{yy}\end{array}\right]$$ and according the Taylor expansion $$f(x,y) \approx f(0,0) + [f_x, f_y]\left[\begin{array}{c}x\\y\end{array}\right] +\frac{1}{2}[x,y]H\left[\begin{array}{c}x\\y\end{array}\right]$$ My intuitive understanding of Hessian matrix is that, each entry in it is just the 2nd order derivative, and the 2nd order derivative indicates how fast the 1st order derivative changes, so I can understand that 2nd order derivatives show the concavity/convexity of $f(x,y)$ . But , there are many people out there saying that the eigenvalues/eigenvectors of Hessian can be used to determine/show blabla.... Why? How? Furthermore, second partial derivative test utilizes Hessian matrix, but the most strange part of is that it just shows the cases for $(f_x,f_y) = (0,0)$ , what about otherwise?","['hessian-matrix', 'multivariable-calculus', 'calculus']"
485774,"Find all functions $f(x+y)=f(x^{2}+y^{2})$ for positive $x,y$","Find all functions $f:\mathbb{R}^{+}\to \mathbb{R}$ such that for any $x,y\in \mathbb{R}^{+}$ the following holds:
$$f(x+y)=f(x^{2}+y^{2}).$$","['contest-math', 'functional-equations', 'functions', 'analysis']"
485801,Fixed-Point Iteration method unable to converge to any of a function's infinte roots,"An equation is given to me which has to be solved by direct iteration method:
    $$\sin(x) = {x+1 \over x-1}$$ or $$f(x)=\sin(x)-{x+1 \over x-1} = 0$$ I follow the following procedure with reasons given along: Rearrange the equation as:
    $$x=\sin^{-1}{{x+1\over x-1}}=g(x)$$ Then, we get
    $$g'(x) = {1 \over (1-x)\sqrt{-x}}$$ $$\implies \forall x < -1, \left|g'(x)\right| < 1$$ Now, $\forall x < -1, 0 < {x+1 \over x-1} < 1$. But, $\sin{x}$ oscillates between 1 and -1 infinitely over the whole domain $\mathbb{R}$ and hence also its subset, the interval $(-\infty, -1)$. Thus, $\sin{x}$ intersects infinitely with ${x+1 \over x-1}$, at least once each time in its interval of size $\pi$. These intersection points are exactly the roots of $f(x)$ over the interval $\left(-\infty, -1\right)$. Thus, if we choose arbitrary points $a,b < -1 : a - b \ge \pi$, then $\sin{x}$ goes from -1 to 1 at least once, and since ${x+1 \over x-1}$ is always between 0 and 1, the period contains a root of $f(x)$. Thus, to summarize, we have got a function $g(x)$ which is defined over the negative number line, and is bounded and continuous there. On the negative number line, we also have an interval $(a, b)$ where we have a root of given equation. Also, derivative of $g(x)$ is numerically less than one in the given interval. So, ideally, I should be able to take any value of $x = x_0$ in $(a, b)$ and should be able to get increasing better iterates. But the fact that my function $g(x)$ is $\sin^{-1}{{x + 1 \over x - 1}}$ means that any negative value of $x < -1 $yields me a positive value of iterate in the next step, which in turn leads to domain error. Where am I wrong? Or more precisely, are there any more conditions that are required for the fixed-point iterative method that are not known to me. One step which seems dubious to me is the very first step where I take $\sin^{-1}$ of original equation on the both sides, to get the $g(x)$, but I am not able to pinpoint how it can derail my method. Update : Renamed the method from direct iterative method to fixed-point iteration method. Also, as is noted in the comments below, problem seems to be in my choice of $g(x)$ only. I am interested in what it really is. How can I avoid the same in future too?","['trigonometry', 'nonlinear-system', 'numerical-methods']"
485815,Intuition behind the Caratheodory’s Criterion of a measurable set,"This week I saw the definition of a measurable set for an outer measure. Let $\mu^*$ be an outer measure on a set $X$. We call $A \subseteq X$ measurable if $$\mu^*(E) = \mu^*(A\cap E) + \mu^*(A^c\cap E)$$ for every $E \subseteq X$. This is not the first time I've seen this definition. Unlike most other things in mathematics, over time I have gained absolutely no intuition as to why this is the definition. The only explanation I've ever seen is that a set is measurable if it 'breaks up' other sets in the way you'd want. I don't really see why this is the motivation though. One reason I am not comfortable with it is that you require a measurable set to break up sets which, according to this definition, are non-measurable; why would you require that? Of course, you can't say what a non-measurable set is without first defining what it means to be measurable so I suppose no matter what your condition is, it will have to apply to all subsets of $X$. Is there an intuitive way to think about the definition of measurable sets? Is there a good reason why we should use this definition, aside from ""it works""?","['measure-theory', 'intuition', 'measurable-sets']"
485816,How find this $\sum_{n=1}^{\infty}a_{n}$,"let $$a_{1}=1,a_{n+1}=\dfrac{1}{a_{1}+a_{2}+\cdots+a_{n}}-\sqrt{2}$$ find the value
$$\sum_{n=1}^{\infty}a_{n}$$ my try:let $S_{n}=a_{1}+a_{2}+\cdots+a_{n}$,then we have
$$S_{n+1}=S_{n}+a_{n+1}=S_{n}+\dfrac{1}{S_{n}}-\sqrt{2}$$ and I find $S_{1}=1,S_{2}=2-\sqrt{2},S_{3}=3-\dfrac{3}{2}\sqrt{2}$
I guess
$$S_{1}>S_{3}>\cdots>S_{2n-1},S_{2}>S_{4}>\cdots>S_{2n}$$ so I try prove
$$S_{2n+1}-S_{2n-1}<0$$
if $n$ is odd. then
$$S_{n+2}=S_{n+1}+\dfrac{1}{S_{n+1}}=S_{n}+\dfrac{1}{S_{n}}-\sqrt{2}+\dfrac{1}{S_{n}+\dfrac{1}{S_{n}}-\sqrt{2}}-\sqrt{2}$$ let $$f(x)=x+\dfrac{1}{x}-\sqrt{2}\Longleftrightarrow S_{n+2}=f(S_{n+1})=f(f(S_{n}))$$
where $x=S_{n}$
and $$S_{n+2}-S_{n}=\dfrac{1}{x}-\sqrt{2}+\dfrac{1}{x+\dfrac{1}{x}-\sqrt{2}}-\sqrt{2}=\dfrac{(1-\sqrt{2}x)^3}{x(x^2-\sqrt{2}x+1)}$$
so if $x\in \left(\dfrac{1}{\sqrt{2}},1\right)$, then we have $$S_{n+2}<S_{n}$$
where $n$ is odd numbers. my question: How can I  determine
 $x=S_{n}$(n is odd) in $(\dfrac{1}{\sqrt{2}},1)$? and I think this problem have other nice methods.Thank you","['sequences-and-series', 'limits']"
485822,Why is compactness so important?,"I've read many times that 'compactness' is such an extremely important and useful concept, though it's still not very apparent why. The only theorems I've seen concerning it are the Heine-Borel theorem, and a proof continuous functions on R from closed subintervals of R are bounded. It seems like such a strange thing to define; why would the fact every open cover admits a finite refinement be so useful? Especially as stating ""for every"" open cover makes compactness a concept that must be very difficult thing to prove in general - what makes it worth the effort? If it helps answering, I am about to enter my third year of my undergraduate degree, and came to wonder this upon preliminary reading of introductory topology, where I first found the definition of compactness.","['intuition', 'general-topology', 'soft-question', 'analysis', 'compactness']"
485829,A Continuous-Time Markov Process Taking All Possible Values,"Let $\mathbb{N}$ be the set of positive integers. For each $n \in \mathbb{N}$ , let $X^{(n)}=\{ X^{(n)}(t): t \geq 0 \}$ be a Markov chain with state-space the two
point set $\{0,1\}$ and $Q$ -matrix \begin{equation}
Q^{(n)} = \begin{pmatrix} - a_{n} & a_{n}\\
b_{n} & - b_{n}\\
\end{pmatrix}
\end{equation} where $a_{n}, b_{n} > 0$ . Assume that $\sum a_{n} = \infty$ and $\sum a_{n}/b_{n} < \infty$ . The transition matrix is $P^{(n)}(t) = \exp(t Q^{(n)})$ .
The processes $(X^{(n)}: n \in \mathbb{N})$ are independent and $X^{(n)}(0)=0$ for
every $n$ .
Each $X^{(n)}$ has right-continuous paths. Consider the process $X = (X^{(n)})$ with values in $\{0,1\}^{\mathbb{N}}$ .
This process was introduced by David Blackwell in Another Countable Markov Process
with Only Instantaneous States , Ann. Math. Stat., Volume 29 (1958), 313 - 316.
His properties are studied e.g. in Kai Lai Chung, Markov Processes with Stationary
Transition Probabilities or David Freedman, Markov Chains , or in the guided exercise
E4.8 of David Williams, Probability with Martingales . In a note to the last one, the author states that... ... much deeper techniques
[can be used to] show that for certain choices of the sequences $(a_{n})$ and $(b_{n})$ , $X$ will almost certainly visit every point in $\{0,1\}^{\mathbb{N}}$ uncountably often within a finite time. Could someone tell me what kind of techinques he refers to?
What are the conditions on $(a_{n})$ and $(b_{n})$ ?
Is there a general theory which answers this kind of questions? Thank you very much for your help.","['stochastic-processes', 'markov-process', 'markov-chains', 'probability']"
485849,Proving that linear combination of exponentials is positive,"I found the following question in a book without any proof. Question : Prove that 
$$f(t)=3-5e^{-2t}+6e^{-3t}+2e^{-5t}-3e^{-(3-\sqrt5)t}-3e^{-(3+\sqrt5)t}\gt0$$ for any $t\gt0$. The book says that this question can be solved in an elementary way. I've tried to prove this, but I'm facing difficulty. Could you show me how to prove this?","['exponential-function', 'inequality', 'functions']"
485873,"What is the probability that GCD of $(a,b)$ is $b$?","My question is quite simple. I have been googling a lot lately trying to find a solution to this: 
Given a sequence of n integers $[1,2,...,n]$. If we pick two numbers randomly from the set say, a and b. The find the probability that GCD$(a,b)=b$? For example: If $N=1$, the probability is $1/1$. If $N=2$, probability is $3/4$ $[(1,1),(2,1),(2,2)$ satisfy out $of (1,1),(2,1),(2,2), (1,2)$ total cases] If $N=3$, the probability is $5/9$. My searches on google show me pages where : probability of GCD$(a,b)=1$ (relative co-prime) are calculated using the zeta function. I don't really know how to use that in this case !! Or whether if that is applicable here!!","['education', 'elementary-number-theory', 'recreational-mathematics', 'number-theory']"
485911,Sequences of sets and limits,"I'm reading Jacod & Protter's ""Probability Essentials"" and I am having difficulty proving one claim which is a step in a proof. I do not have much experience proving things, so I also don't know if what I think I got right is actually correct. Definition: Let $(\Omega,\mathcal{A})$ be a set and a $\sigma$-algebra on $\Omega$. We say $A_n \rightarrow A$ if $\lim_n 1_{A_n}(\omega) = 1_{A}(\omega)$ for all $\omega \in \Omega$. The claim I want to prove is the following: $$
A_n \rightarrow A \Leftrightarrow \lim \sup_n A_n = \lim \inf_n A_n = A.
$$ Attempt at a proof I start with the $\Rightarrow$ direction. Given that for all $\omega \in \Omega$ we have $\lim_n 1_{A_n}(\omega) = 1_{A}(\omega)$:
$$
\forall \omega \in \Omega, \forall \varepsilon > 0, \exists n \in \mathbb{N}: k \ge n \rightarrow |1_{A_k}(\omega) - 1_A(\omega) | < \varepsilon.
$$
That is
$$
\forall \omega \in \Omega, \underbrace{\exists n \in \mathbb{N}: k \ge n \rightarrow w \in A_k}_{\omega \in \liminf_n A_n} \Leftrightarrow \omega \in A.
$$
Therefore $\liminf_n A_n = A \subset \limsup_n A_n$. I don't know how to prove that the $\liminf$ is equal to the $\limsup$ . Now, on to the $\Leftarrow$ direction: Let $\omega \in \Omega$. Then, since we know $A = \liminf_n A_n$: \begin{align*}
\omega \in A &\Leftrightarrow \exists n \in \mathbb{N} : k \ge n \rightarrow \omega \in A_k \\
&\Leftrightarrow \exists n \in \mathbb{N}: \forall k \ge n, \, 1_A(\omega) - 1_{A_k}(\omega) = 0 \\
&\Leftrightarrow \forall \varepsilon > 0, \exists n \in \mathbb{N} : k \ge n \rightarrow |1_{A_k} (\omega) - 1_{A}(\omega) | < \varepsilon.
\end{align*}
Therefore, we have $\lim_n 1_{A_n}(\omega) = 1_A(\omega)$. Thank you in advance!","['elementary-set-theory', 'probability', 'limits']"
485913,Van der Waerden type numbers (for geometric progressions),"Van der Waerden theorem is true also for geometric progressions. 
Is there anything interesting in van der Waerden type numbers $ W'(r,k) $ derived from this version? ($ W'(r,k) $ is such that if the integers $ \{1, 2, ..., W'(r,k)\} $ are colored, each with one of r different colors, then there are at least k integers in geometric progression all of the same color). Probably there is some obvious connections between $ W'(r,k) $ and $ W(r,k) $. Is there any literature about this topic?","['ramsey-theory', 'discrete-mathematics', 'number-theory', 'combinatorics']"
485917,coarsest topology for separation axioms,"I have read that the cofinite topology is the coarsest topology on $T_1$, but I have not been able to find any similar statements for the other separation axioms. What are the coarsest topologies for $T_0, T_2, T_3,...$?","['general-topology', 'separation-axioms']"
485931,Did Euler have a trick? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 10 years ago . Improve this question Did Euler have a trick for discovering things? Some sort of general method he could apply to mathematical objects he came across to see if they yielded any new truths? Did he just ask the right questions at the right time? Was he lucky? Did he have a very advanced and well-developed intuition? How would you train a kid to become the next Euler. Just imagine you were given a kid who was really good at math, and it was down to you to give him all the training needed so he could embark on a career like Euler's (and you are guaranteed he would work as hard as Euler). For example, if I worked all day exploring maths I probably wouldn't discover a quarter of what Euler discovered, and even then I'm being HIGHLY generous to myself. How did he do it?","['geometry', 'education']"
485935,Piecewise interpolation with derivatives that is also twice differentiable,"This question regards the issue of interpolation of one dimension real functions. If one has a finite set of function values and its corresponding derivatives, one could find unique continuous piecewise cubic function that interpolates those points and has the desired derivatives. This function is at least once-differentiable and in the general case is not twice-differentiable as the second derivative is discontinuous. On the other hand a cspline-interpolation (with some boundary conditions) of those same points gives a three twice-differentiable function (but does not respect the values of the derivatives at the points). In other words, the cspline is the only cubic spline that is twice differentiable, which makes me think that if I want a twice-differentiable interpolation with derivatives I will need a higher order interpolation. For example quartic or quintic. The question is, does interpolation with derivatives that is also twice-differentialy exists already? In practice, should it be quartic or quintic? Is there any reference or numerical implementation for it? (I experimented with quartic interpolation --for values only-- in the past, but as it is well-know, even-number order interpolations produce unstable oscillations making it unsuitable for numerical approximation, which discourages me from trying quartic order interpolation) Here it is an illustration of function interpolation of values (on the right) and derivative values (on the left) (in this example the value of the derivative is choosen to be 1 in the sample data for illustration only)","['interpolation', 'spline', 'continuity', 'derivatives']"
485937,Interspersing of integers by rationals,"I'm wondering if the next argument is sound or maybe need some adjustments; Proposition (Interspersing of integers by rationals): Let $x\in \mathbb{Q}$. Then there exists an integer such that $n\le x< n+1$. In fact this integer is unique. In particular, there exists a natural number $N$ such that $N>x$ (i.e. there is no such thing as a rational number which is larger than all the natural numbers). Proof: By the trichotomy property of the rational numbers, either $x$ is positive, negative or zero. If $x=0$, it's trivial since $\,0 \le x<1$. Now if $x$ is positive number, by definition $x= \frac{p}{q}$ where $p,q\in \mathbb{N}- \left\{0 \right\}$. Then using the Euclidean algorithm we have that: $$p = mq+r, \text{  where   } \:\: 0 \le r < q $$ We shall show that the natural number $m$ has the desired property $\,m \le x < m+1$. It is sufficient to show that $\,\,0 \le x-m<1$. $x -m= \frac{p}{q}-m =\frac{mq+r}{q}-{m} = \frac{r}{q}$. Since by the Euclidean algorithm we know that $\,0 \le r < q$  then $\,0 \le \frac{r}{q} <1$ as desired. Now suppose there is a $n \not= m $ such that $p = nq+r$. So, $\,mq+r = nq+r$ and we conclude that $m=n$ which show the uniqueness of $m$. If $x$ is a negative rational number, we have that $x = \frac{-a\,}{\,\,\,b\,}$ where $a,b\in \mathbb{N}- \left\{0\right\}$, so $-x = \frac{a}{b}$ and we may  use the same argument that in the positive case. To conclude we need to show that the integer is unique and is follows of the above argument. I feel that the argument is a bit flawed, I would appreciate any suggestion. Thanks in advance","['self-learning', 'analysis']"
485959,"Primary decomposition of an ideal (exercise 7.8 in Reid, Undergraduate Commutative Algebra) [duplicate]","This question already has answers here : What is a primary decomposition of the ideal $I = \langle xy, x - yz \rangle$? (2 answers) Closed 10 years ago . I would like to understand how to use geometry to solve the problem 7.8 from Reid's book Undergraduate Commutative Algebra . The problem is the following Let $k$ be a field and consider the ideal $I = (xy, x - yz) \subset k[x,y,z]$. Find a primary decomposition of $I$. So the vanishing locus $V(I)$ is the two axis $Y$ and $Z$, and if $I = q_1 \cap \cdots \cap q_n$ with all $q_i$ being $p_i$-primary, we could guess that we can take $p_1 = (x,z)$ and $p_2 = (x,y)$. Moreover, the vanishing of $xy$ is the $Z$-axis, but with double multiplicity (is this true ?), so we could guess to take $q_2 = (x,y)^2$, but we need $x - yz$ to be in there, so I think that $q_2 = (xy, y^2, x - yz)$ and $q_1 = (x,z)$ would give a decomposition into primary ideals ($x^2$ is automatically in $q_2$, don't need it). Question 1 : How to make sure that these primes $p_1$ and $p_2$ are the only ones ? We can compute them by $\operatorname{Ass}(k[x,y,z]/(xy,x - yz))$, but wasn't able to do it. Question 2 : Is $(x,z) \cap (xy, y^2, x - yz)$ a primary decomposition of $I$ ? Question 3 : What is a better way to get to this answer with geometric intuition and not algebraic brute-force ? Thanks","['commutative-algebra', 'ideals', 'algebraic-geometry']"
485980,Proper map on compact Riemann surface,"i hope you can help me with a problem I discovered while dealing with the resolution of singularities for an algebraic curve in $\mathbb{P}^2$. A resolution means for me, that for an algebraic curve $C$ you've got a compact Riemann surface $S$ and a proper map $\pi:S \rightarrow C$, such that $\pi|_{S-Sing(C))}$ is a biholomorphism. Now I want to proof, that $S$ is unique up to biholomorphic equivalence. The only thing I'm not sure in that proof is, that for $x \in Sing(C)$ the preimage $\pi^{-1}(\{x\})$ is discrete and therefore since $\pi$ is a proper map finite. Am I able to proof this assertion? And if I should be how can I do so?","['riemann-surfaces', 'algebraic-geometry']"
486013,"If $B$ is a subset $A$, and if an injection $f: A \rightarrow B$ exists, then there is a bijection...","Prove the following: LEMMA If $B$ is a subset $A$ , and if an injection (one-to-one) $f: A \rightarrow B$ exists, then there is a bijection (one-to-one and onto) $g: A \rightarrow B$ . Since $f$ is a function, every $a \in A$ is sent to exactly one $b \in B$ . Since $f$ is injective, we know that $a_1 \not= a_2 \implies f(a_1) \not=f(a_2)$ $\forall a_1,a_2 \in A$ . This means that every $a \in A$ is sent to a unique $b \in B$ $\implies$ $|A| = |im f|$ . But since $B$ is a subset of $A$ and $im f$ is a subset of $B$ , we have $|imf| \leq |B| \leq |A| \implies |imf|=|B|=|A|$ from above. But $imf=B$ implies surjectivity by definition. Finally, since $imf \subseteq B \subseteq A$ and $|imf|=|B|=|A|$ , we know that $imf=A=B$ . Do you think my answer is correct? Thank you in advance",['functions']
486023,Exclusion Inclusion Principle Induction Proof,"I got new home work that I was asked to proof the exclusion inclusion principle with induction,
and my question is how can I do that? Any help will be appreciated!","['induction', 'inclusion-exclusion', 'combinatorics']"
486025,Geometric intuition for the tensor product of vector spaces,"First of all, I am very comfortable with the tensor product of vector spaces. I am also very familiar with the well-known generalizations, in particular the theory of monoidal categories. I have gained quite some intuition for tensor products and can work with them. Therefore, my question is not about the definition of tensor products, nor is it about its properties. It is rather about the mental images. My intuition for tensor products was never really geometric . Well, except for the tensor product of commutative algebras, which corresponds to the fiber product of the corresponding affine schemes. But let's just stick to real vector spaces here, for which I have some geometric intuition, for example from classical analytic geometry. The direct product of two (or more) vector spaces is quite easy to imagine: There are two (or more) ""directions"" or ""dimensions"" in which we ""insert"" the vectors of the individual vector spaces. For example, the direct product of a line with a plane is a three-dimensional space. The exterior algebra of a vector space consists of ""blades"", as is nicely explained in the Wikipedia article . Now what about the tensor product of two finite-dimensional real vector spaces $V,W$? Of course $V \otimes W$ is a direct product of $\dim(V)$ copies of $W$, but this description is not intrinsic, and also it doesn't really incorporate the symmetry $V \otimes W \cong W \otimes V$. How can we describe $V \otimes W$ geometrically in terms of $V$ and $W$? This description should be intrinsic and symmetric. Note that SE/115630 basically asked the same, but received no actual answer. The answer given at SE/309838 discusses where tensor products are used in differential geometry for more abstract notions such as tensor fields and tensor bundles, but this doesn't answer the question either. (Even if my question gets closed as a duplicate, then I hope that the other questions receive more attention and answers.) More generally, I would like to ask for a geometric picture of the tensor product of two vector bundles on nice topological spaces. For example, tensoring with a line bundle is some kind of twisting. But this is still some kind of vague. For example, consider the Möbius strip on the circle $S^1$, and pull it back to the torus $S^1 \times S^1$ along the first projection. Do the same with the second projection, and then tensor both. We get a line bundle on the torus, okay, but how does it look like geometrically? Perhaps the following related question is easier to answer: Assume we have a geometric understanding of two linear maps $f : \mathbb{R}^n \to \mathbb{R}^m$, $g : \mathbb{R}^{n'} \to \mathbb{R}^{m'}$. Then, how can we imagine their tensor product $f \otimes g : \mathbb{R}^n \otimes \mathbb{R}^{n'} \to \mathbb{R}^m \otimes \mathbb{R}^{m'}$ or the corresponding linear map $\mathbb{R}^{n n'} \to \mathbb{R}^{m m'}$ geometrically? This is connected to the question about vector bundles via their cocycle description.","['geometry', 'vector-bundles', 'tensor-products', 'linear-algebra', 'intuition']"
486029,Teams in tournament problem,"I have a practical math problem that I can't solve by myself.
The problem is probably already solved by other people but I can't think of any
Google 
search words.
If somebody knows a solution or is willing to try and solve it that would be
awesome.
I need a algorithm to plan some kind of tournament. I wrote an algorithm in
Mathematica 
that tries randomly to find the best option but it would take thousands of years
to solve the 
problem that way. This is the problem: There are a total of p people, they are distributed over teams.
Ever round g different games are played, t teams play game A, t teams play game
B etc. for 
all g games. (So the total number of teams is t*g.) For instance:
g = 5, t=3 (so there a 15 teams) ....................Round 1......................Round 2............. Round 3
etc. etc. Game A:.....1 vs 2 vs 3..............4 vs 8 vs 15...............etc. Game B:.....4 vs 5 vs 6.................1 vs 7 vs 12................etc. Game C:.....7 vs 8 vs 9.................2 vs 10 vs 13..............etc. Game D:....10 vs 11 vs 12...........3 vs 6 vs 14.................etc. Game E:.....13 vs 14 vs 15...........5 vs 9 vs 11................etc. Rule 1: Every team has to play every game at least once, but no more than
strictly necessary 
to make all rules work. Rule 2: Every team has to play against every other team ,so team 1 has to play
team 2,3,4...15 
(team 2 has to play team all other teams etc. etc.). If team 1 already played
team 12, they can 
only play each other again if it's strictly necessary to make the rules work. In
the example 
above there was a match ""1 vs 7 vs 12"" so later on match ""1 vs 12 vs 9"" may only
happen is 
there is no other option. Rule 3: If a team has to play a game more than once, it's better if there is a
pause between 
those games (so not in successive rounds). Rule 4: If a team has to play a other team more than once, it's better if there
is a pause 
between those games (so not in successive rounds). Rule 5: If the people can't be distributed equally over the teams (for instance
p=147 and 
there are 15 teams, three teams will be smaller), smaller teams shouldn't play
each other if 
possible. So if team 13, 14 and 15 are smaller match ""13 vs 14 vs 15"" should be
avoided if 
possible. (While match ""13 vs 14 vs ..."" can't be avoided since team 13
has to play team 14 at 
least once.) The rules are ordered according to importance, rule 1 is the most important. The answer to this problem may be given in any form: group theory, graphs,
algebra ect.
Buy I prefer some kind of pseudocode so I can easily make a Mathematica workbook
or C++ 
application. Of course every little tip is very welcome, it doesn't have to be a
complete 
solution! Many thanks,
Eric",['combinatorics']
486051,Are there cases where the difference between a partial and total derivative is purely reliant on syntax?,"It's always seemed to me that the difference between a partial and total derivative is artificial. I'm not sure how I'm wrong but surely, I must be. An example of my confusion is the function f(x,t)=x^2+t where x(t)=t. If I take the partial derivative of f w.r.t t, $\frac{\partial f}{\partial t}$=1.
Now suppose I take the partial again, but this time I substitute first. f(x(t),t)=t^2+t. This time $\frac{\partial f}{\partial t}$=2t+1.
This confuses me because, surely the result of a partial derivative relies only on the function f, and can't be dependent on my choice of how to write it. Unless the partial derivative is really such a whimsical, subjective operator.","['multivariable-calculus', 'partial-derivative']"
486058,Does the boundary of a handle decomposition obtain a handle decomposition?,"Let $M$ be the $4$-manifold $D^4\cup2\text{-handle}\cup\ldots\cup2\text{-handle}$, where the attachment of the handles is specfied by an oriented framed link $L=L_1\cup\ldots\cup L_n\subseteq S^3$. By Lickorish's theorem any smooth closed connected orientable 3-manifold can be obtained in this way as $\partial M$. For example, if $L$ consists of only one unknot with framing $n$, then $\partial M$ is the lens space $L(1,n)$. Thus in general, $H_1\partial M$ can be any finitely generated abelian group. Does $\partial M$ obtain a handle decomposition from the one on $M$? I know that $\partial M$ is obtained as $S^3$ with $n$ $1$-surgeries. I would like to show that $H_1\partial M\cong \mathbb{Z}^n/\mathrm{Im}A$, where $A\in\mathbb{Z}^{n\times n}$ has on the diagonal the framings of $L_1,\ldots,L_n$ and at $ij$-th place the linking number of $L_i,L_j$. There's a theorem in Ranicki's Algebraic and Geometric Surgery , p. 55, Proposition 4.19, describitng homology after surgery, burt it doesn't tell me much. The exact sequence of a pair $H_2\partial M\rightarrow H_2M\rightarrow H_2(M,\partial M) \rightarrow H_1\partial M \rightarrow H_1M \rightarrow H_1(M,\partial M)$ with $H_1M=0=H_3M$ and $H_2M=\mathbb{Z}^n$ doesn't tell me much. It would be desirable if the handle decomposition on $M$ which is uniquely specified by the link $L$ would induce a handle decomposition on $\partial M$, which would also be specified by $L$. If $\partial M$ had only $1$ $0$-handle and $n$ $1$-handles, then $\partial_1:\mathbb{Z}^{1\text{-handles}}\rightarrow\mathbb{Z}^{0\text{-handles}}$ would be the zero map, so $H_1\partial M=\mathbb{Z}^n/\mathrm{Im}\partial_2$ and then wishfully $\partial_2=A$. So, how does the link $L$ induce a handle decomposition on $\partial M$?","['differential-geometry', 'surgery-theory', 'manifolds', 'algebraic-topology', 'differential-topology']"
486072,Cardinality of the class of real nullsets?,How do I prove that the class of Lebesgue measure zero sets in $\mathbb{R}^d$ has cardinality $2^{\mathfrak{c}}$ where $\mathfrak{c}$ is the power of the continuum? (I wan't to do this also for meager sets but hopefully I will deduce it from the first answer. It should be more less the same). I have the impression it is a trivial observation which I am currently missing. Any hints?,"['measure-theory', 'elementary-set-theory']"
486073,Must an infinite intersection of infinite sets be infinite?,"If $A_2$ is a subset of $A_1$, $A_3$ is a subset of $A_2$, and this goes on infinitely and all contain an infinite number of elements, then is the intersection from $n=1$ to infinity, infinite as well? Prove if no.","['infinity', 'elementary-set-theory']"
486074,Proving $|e^{iθ}|=1$,How do I show that $|e^{iθ}|=1$? So I got that the length will be $\sqrt{\cos^2(x)-\sin^2(x)}$ and it can be written as the square root of $\cos 2x$ but I don't see how that equals 1.,"['complex-numbers', 'complex-analysis']"
486104,Is this relationship between spectral radius and singular values false?,"I found the following relationship $\max_{i} \sigma_i \le \rho(A)$, where $A$ is a matrix. 
But somehow I do not trust this relation, I'd rather guess that the converse is true, but I do not know.","['matrices', 'linear-algebra']"
486119,On differentiability of a certain function,"Let $f(x)$ be real-valued continuous function on the real line satisfying
$$\sup_{y \in \mathbb{R}}\textrm{ card}(f^{-1}(\{y\}))<\infty$$
where card denotes the cardinality of set. This means there exists certain $N \in \mathbb{N}$ such that $f^{-1}(\{y\})$ contains at most $N$ elements for every $y \in \mathbb{R}$. Now I want to show $f'$ exists almost everywhere (with respect to canonical Lebesgue measure on the real line). I guess the set containing points that cannot be differentiated should be at most countable but have no idea of where to start. Any hint shall be greatly appreciated!","['measure-theory', 'real-analysis']"
486126,Proving Cantor's theorem,"$\DeclareMathOperator{\card}{card}$ From Problem-Solvers Topology Prove the following: CANTOR'S THEOREM If $A$ is a set, then $$\card A < \card \mathcal{P}(A)$$ where $\card A$ stands for the cardinality of set $A$ . My Answer If $A = \emptyset$ , then $\card A =0$ and $\card \mathcal{P}(A)=1$ . If $A = \{a\}$ , then $\card A=1$ and $\card \mathcal{P}(A)=2$ . So suppose that $A$ has at least two elements. Define a function $f: A \rightarrow \mathcal{P}(A)$ such that $f(x) = \{x\}$ for all $x \in A$ . Then $f$ is injective. But it cannot be surjective, because for any two distinct elements $a,b \in A$ , there is no element in $A$ that is sent to the set $\{a,b\}$ in $\mathcal{P}(A)$ . Therefore, there is no bijection, and $\card A < \card\mathcal{P}(A)$ . Do you think my answer is correct? Thanks in advance","['elementary-set-theory', 'solution-verification']"
486135,Simplifying a sum?,"Define polynomials $P_{j,s}^{(r)}$ via the generating series $$\left(\frac{d^s}{dz^s}f(z)\right)^r=\sum_{j=0}^{\infty} P_{j,s}^{(r)}z^j,$$ where $r\geq 1$. Here, $f(z)=z+a_2z^2+a_3z^3+\cdots.$ I was hoping to simplify the expression $$ 3\sum_{k=0}^{j-1}P_{j-k-1,s}^{(r-1)}P_{k,s-1}^{(1)}+(s-2)\sum_{k=0}^j P_{j-k,s}^{(r-1)}P_{k,s-1}^{(1)}, $$ where $j\geq 1$ and $s\geq 2$","['summation', 'sequences-and-series', 'complex-analysis', 'combinatorics']"
486160,"Using Eigenvalues and Eigenvectors, Find the general solution of the following coupled differential equations. x'=x+y and y'=-x+3y.","Consider the matrix $A=\begin{bmatrix} 1 & 1 \\ -1 & 3 \end{bmatrix}$
I found the eigenvalue $\lambda=2$ with multiplicity $2$. However, the general solution I found degrees with the answer provided by the text. I found the solution
$$\begin{bmatrix} x \\ y \end{bmatrix} = A\begin{bmatrix} 1 \\ 1 \end{bmatrix} e^{2t} + B\begin{bmatrix} t \\ t-1 \end{bmatrix}e^{2t}$$ whereas the book finds $$\begin{bmatrix} x \\ y \end{bmatrix} = A\begin{bmatrix} 1 \\ 1 \end{bmatrix}e^{2t} + B\begin{bmatrix} t-1 \\ t \end{bmatrix} e^{2t}$$ What have I done wrong?","['ordinary-differential-equations', 'eigenvalues-eigenvectors']"
486168,Inequality with logarithms,"How do I show that $$
\frac{1}{n-1}\geq \ln \left ( \frac{n}{n-1} \right )
$$ for $ n>1 $? As far as I can tell, exponentiating both sides with base $e$ won't help, because then I get a nasty term on the LHS.","['inequality', 'logarithms', 'algebra-precalculus']"
486177,Calculating that confidence that pairs of lightbulbs are independently illuminated.,"So, you're sitting in a dark room, and on the far wall you see $n$ lightbulbs mounted above plaques numbered $1$ through $n$.  There is a lightswitch on the arm of your chair. Every time you flip the switch, some subset of the lightbulbs turn on. This subset can vary between flips. Your guess is that each of the lightbulbs has an intrinsic probability of being illuminated when you flip the switch, and that this probability is pairwise independent of the other lightbulbs.  In other words, for each lightbulb $i$ and $j$, you predict that $$\operatorname{P}\left(i\text{ and }j\text{ both illuminated}\right)=\operatorname{P}\left(i\text{ illuminated}\right)\operatorname{P}\left(j\text{ illuminated}\right)$$ To test this, you flip the lightswitch a whole bunch of times, each time recording the subsets of activated lightbulbs as $S_m$ (if you're on the $m^\text{th}$ flip).  Afterwards, you record the number of times each lightbulb lit up as $$c_i=\left|\{m:i \in S_m \}\right|,$$ and, similarly, for each pair of lightbulbs $i$ and $j$, you set $$c_{ij}=\left|\{m:\{i,j\}\subseteq S_m \}\right|.$$ Note that if the lightbulbs really are illuminated pairwise independently of one another, we would see $$\ell_{ij}:=\frac{c_ic_j}{c_{ij}}\longrightarrow 1$$ for every $i,j$ as the sample size grows large.  Naturally, we consider the matrix $\ell\in M_{n\times n}$ with entries $\ell_{ij}$. Suppose that you have flipped the switch $N$ times and, from looking at $\ell$, you believe that some pair of lightbulbs $i$ and $j$ are not statistically independent.  With what confidence can you assert, in terms of $N$, $n$, $c_i,c_j,$ and $c_{ij}$, that $$\left|1-\frac{\operatorname{P}\left(i\text{ and}j\text{ illuminated}\right)}{\operatorname{P}\left(i\text{ illuminated}\right)\operatorname{P}\left(j\text{ illuminated}\right)}\right|>\alpha\hspace{30pt}?$$ You may assume that $c_i$ and $c_{ij}$ are nonzero for each $i$ and $j$.  (or, if you do not wish to assume this, please explain why and compensate by modifying the definition of $\ell_{ij}$.)","['statistics', 'puzzle', 'statistical-inference', 'probability-theory', 'probability']"
486193,Alternating binomial sum with intervals of two,"Fix integer $n\geq 1$. Consider the number $$1-\binom{n}{2}+\binom{n}{4}-\binom{n}{6}+\cdots$$where the sum continues as long as the lower number in the binomial is $\leq n$. Is there a way to simplify this sum? The first few values are $1, 0, -2, -4, -4$.","['algebra-precalculus', 'binomial-coefficients']"
486194,Trigonometric problem using basic trigonometry,"If $x$ is a solution of the equation: $$\tan^3 x = \cos^2 x - \sin^2 x$$
  Then what is the value of $\tan^2 x$? This is the problem you are supposed to do it just with highschool trigonometry , but i can't manage to do it please help Here are the possible answers:
$$a) \sqrt{2}-1, b) \sqrt{2}+1, c) \sqrt{3}-1, d) \sqrt{3}+1, e)\sqrt{2}+3$$",['trigonometry']
486196,Set Theory notation simplification,"Let A and B be sets. i) Express { $x \mid x ∈ A ∨ x \notin  B$ } as simply as possible in the notation of set theory,
without using set-builder notation. ii) Express $∀x (x ∈ A ∨ x \notin  B)$ as simply as possible in the notation of set theory,
without any quantiﬁers. Well for the first part, I get the following: $A-B$ but, I'm confused as to how the other in part two differs? How does the universal quantifier change the meaning?","['discrete-mathematics', 'elementary-set-theory']"
486223,Question concerning mean value theorem,"Here's the problem: Suppose the set $\{x\mid f(x)\not = 0,x\in[a,b]\}$ is not empty, and $f$ is differentiable on $[a,b]$ , with $f(a)=f(b)=0$ . Prove that $\exists c$ , such that $$|f'(c)|>\frac{4}{(b-a)^2}\int_{a}^{b}|f(x)|dx$$ My attempt is that first, to prove that
exists $c$ s.t. $$|f'(c)|>\frac{1}{b-a}\int_{a}^{b}|f'(x)|dx$$ and then, use the positive variation to prove that $$\int_{a}^{b}|f'(x)|dx\ge\frac{2}{(b-a)}\int_{a}^{b}|f(x)|dx$$ since $|f(x)|\le P_F(b)$ , with $P_F(x)$ is positive variation function of $f$ . But the coefficient is only $\frac{2}{(b-a)^2}$ , not $\frac{4}{(b-a)^2}$ , which bother me  a lot. Both coefficient in my two inequality cannot be improved (as far as I know..) since the former one can be approximated by letting $f$ be a tent function and the latter one can be approximated by letting $f$ be a constant greater than zero.(Of course both example should be mollified so that $f$ can be differentiated.) Hope to find some valid method, thanks for your attention!","['real-analysis', 'analysis']"
486248,Is harmonicity preserved when taking limits (normal convergence) on the unit disk.,"I'm reading Koosis's book on $H^p$ spaces and have a question. He is proving a $L^p$ version of the Dirichlet problem which states that if $F(t)$ is in $L^p$ on the unit circle then $$ U_{r}(\theta)=F\ast P_{r}(\theta)$$ 
is harmonic in the open unit disk. He does this by noticing 
$$
U_{r}(\theta)=\sum_{n=-\infty}^{\infty} A_n r^{|n|} e^{i n \theta}.
$$
We get this from noting that the Poisson kernel has the form
$$
P_{r}(\theta)=\sum_{n=-\infty}^{\infty}r^{|n|} e^{i n\theta},
$$
where the sum converges uniformly on compact subsets of the open unit disk.
Since we have uniform convergence, we can interchange the summation and integral to get the form above. My question is this: if the partial sums
$$
\sum_{n=-N}^{N}A_n r^{|n|}e^{i n \theta}
$$
satisfy Laplace's equation, does the limit satisfy it as well? The limit function would have the mean value property since the partial sums do, but is this equivalent to harmonicity? EDIT:
I actually proved the result myself. The last summand, when split between summing $n\geq 0$ and $n<0$, is the sum of an analytic function and a conjugate analytic function. We know this because the partial sums converge uniformly on compact subsets, preserving holomorphicity. Thus, the real and imaginary parts are harmonic. However, if anyone has anything interesting to add I'd love to hear it.","['fourier-series', 'harmonic-analysis', 'complex-analysis', 'analysis']"
486250,Proof of the distribution of sample variance,"I'm reading Probability and Statistics by DeGroot and Schervish, and I got stuck on one particular line of the proof of the distribution of the sample variance $\hat{\sigma}$ of a random sample of $n$ many i.i.d. standard normal random variables $X_{i}$.  The sample has sample mean $\bar{X}_n$. The equality that I can't follow is $(\sum_{i=1}^n X_i^2) - n\bar{X}_n^2 = \sum_{i=1}^n (X_i - \bar{X}_n)^2$ I understand that you can rewrite $n\bar{X}_n^2 = \sum_{i=1}^n \bar{X}_n^2$, which then turns the left term of the first equality to $(\sum_{i=1}^n X_i^2) - (\sum_{i=1}^n \bar{X}_n^2) = \sum_{i=1}^n (X_i^2 - \bar{X}_n^2)$.  But for the life of me, I can't figure out how you get from that result to the right term of the first equality.  What am I missing here? Thanks in advance!","['statistics', 'probability-theory']"
486265,Book Searching in Stability Theory.,"Can anyone recommend me a book on Stability Theory with an intuitive approach? I have some course notes on that subject, but it's really abstract and theoretical. I really want to understand it, ex: Stable by Lyapunov/Asymptotically Stable/Globally Asymptotically Stable/  Lyapunov's Stability Theorem/ Hurwitz criteria... If there are many exercises (Or examples ) with instructions in books which are wonderful for me. Any suggestions about titles and authors's books (free download :) ) or pdf/djvu file, it will be appreciated. Thanks!","['matrices', 'ordinary-differential-equations', 'reference-request', 'functions']"
486270,Calculation of $\frac{n!}{1!+2!+3!+\cdots+(n-1)!}$,"Calculation of $\displaystyle \left[\frac{n!}{1!+2!+3!+\cdots+(n-1)!}\right] = $ Where $n\geq 4$ and $n\in \mathbb{N}$ and $\left[x\right] =$ Greatest Integer of $x$ My Try :: For Upper Bond:: $n! = n.(n-1)! = \{(n-1)+1\}.(n-1)! = (n-1).(n-1)!+(n-1)!$ $ = (n-1).(n-1)!+(n-1).(n-2)!=(n-1).(n-1)!+\{(n-2)+1\}.(n-2)!$ Now I did not understand How can i proceed further. plz help me , Thanks",['algebra-precalculus']
486275,How can one prove this geometric inequality?,"Let $ABCDEF$ be a convex hexagon with area $S$. Show that
$$BD\cdot(AC+CE-EA)+DF\cdot(CE+EA-AC)+FB\cdot(EA+AC-CE)\ge 2\sqrt{3}\cdot S.$$ At some point, I found this similar problem . Thank you to everyone who can help. Maybe this problem is very nice and not easy. The problem is also stated here. I hope to see some nice methods.","['geometry', 'inequality']"
486276,Localness of the UFD Property,"If $A$ is a noetherian domain and $A_p$ is a UFD for some prime ideal, is there some $f$ not contained in $p$ such that $A_f$ is a UFD?","['commutative-algebra', 'algebraic-geometry']"
486281,sum of 14 4th powers and sum of 14 cubes,"Prove that
$4(x_1^4 + x_2^4 + x_3^4 + \dots + x_{14}^4) = 7(x_1^3+ x_2^3 + x_3^3 + \dots + x_{14}^3)$ has no solution in positive integers. Hint : suppose on the contrary  $\sum_{k=1}^{14} {(x_k^4 - \frac74 x_k^3)} = 0$ . also use $\sum(x_k-1)^4$","['summation', 'contest-math', 'number-theory']"
486284,How to sketch the phase portrait near the critical point at the origin.,"A linear system and its general solution. $dx/dt$ = $6x - 2y$ $dy/dt$ = $4x + 2y$ It has a general solution of this: $$\begin{bmatrix} x(t) \\ y(t) \end{bmatrix} = A\begin{bmatrix} cos(2t) \\ cos(2t)+sin(2t) \end{bmatrix} e^{4t} + B\begin{bmatrix} sin(2t) \\ sin(2t) - cos(2t) \end{bmatrix}e^{4t}$$ Sketch the phase portrait near the critical point at the origin.
Discuss the type and stability of the critical point. I don't know how to approach this since I'm used to drawing in the 2 eigenvectors and figuring out if they face in or out against the origin. Then I would draw the orbits. How do I do this one?","['ordinary-differential-equations', 'eigenvalues-eigenvectors', 'graphing-functions']"
486286,Why Does the existence of $\frac{\partial f}{\partial x}$ not imply that $\frac{\partial f}{\partial x}$ is continuous?,"For $f(x)$, the existence of $f'(x)$ implies the continuity of $f(x)$. And I am assuming that it also implies the continuity of $f'(x)$. My question is why in a function $g(x,y)$, is the existence of $g_x$ and $g_y$ not sufficient condition for the continuity of $g_x$ and $g_y$ and hence the continuity of the function? To me, it seems existence of $f'(x)$ and $g_x$ should either both imply continuity of $f'(x)$ and $g_x$ or not. Why are they different in each case?","['multivariable-calculus', 'examples-counterexamples', 'continuity', 'partial-derivative', 'real-analysis']"
486288,A Tribonacci numbers identity for Pythagorean quadruples $a^2+b^2+c^2 =d^2$?,"We have the known Fibonacci identity for Pythagorean triples , $$(F_n F_{n+3})^2+(2F_{n+1}F_{n+2})^2 = (F_{2n+3})^2$$ and for Lucas numbers, $$(L_n L_{n+3})^2+(2L_{n+1}L_{n+2})^2 = (L_{2n+2}+L_{2n+4})^2 = (5F_{2n+3})^2$$ But given the tribonacci numbers , $$T_n = 0, 1, 1, 2, 4, 7, 13, 24, 44, 81, 149, 274, 504, 927, 1705, 3136,\dots$$ where we set $T_0 = 0,\; T_1 = 1$, etc, it seems they obey the analogous Pythagorean quadruples , $$(-T_{n+3}^2+T_{2n+3}+T_{2n+4})^2+(2\,T_n\,T_{n+1})^2+(2\,T_n\,T_{n+2})^2 = (T_{n-1}^2+\,T_{2n+1}+T_{2n+2})^2$$ Some questions: This relation was discovered empirically and holds true for $n$ up to the hundreds, but it would be good to know a proof that it is true for all $n$. Any tribonacci analogue for higher powers, like ( eq.30 ) $F_{n+1}^3+F_n^3-F_{n-1}^3 = F_{3n}$?","['sequences-and-series', 'number-theory']"
486295,"If $f$ is a $C^2$ diffeomorphism $\Longrightarrow$ $f(B[a,r])$ is convex","Let $f:U\longrightarrow V$ be a $C^2$ diffeomorphism where $U,V\subset\mathbb{R}^n$ are open sets. How can we prove that $$\forall a\in U,\exists \epsilon>0:r\le \epsilon \Longrightarrow f(B[a,r])\text{ is convex }$$ Any hints would be appreciated.",['real-analysis']
486297,Calculate $ \int_{-\infty}^{\infty} x^4 H(x)^2 e^{-x^2} dx$ where $H(x)$ is a Hermite polynomial,"I need to calculate the following integral $$ \int_{-\infty}^{\infty} x^4 H(x)^2 e^{-x^2} dx.$$ where $H(x)$ is a Hermite polynomial. I tried using the recurrence relation, but I don't get the answer.","['orthogonal-polynomials', 'calculus']"
486303,normalized Laplacian of Gaussian,"Laplacian of Gaussian formula for 2d case is
$$\operatorname{LoG}(x,y) = \frac{1}{\pi\sigma^4}\left(\frac{x^2+y^2}{2\sigma^2} - 1\right)e^{-\frac{x^2+y^2}{2\sigma^2}},$$ in scale-space related processing of digital images, to make the Laplacian of Gaussian operator invariant to scales, it is always said to normalize $LoG$ by multiplying $\sigma^2$, that is
$$\operatorname{LoG}_\text{normalized}(x,y) = \sigma^2\cdot \operatorname{LoG}(x,y) = \frac{1}{\pi\sigma^2}\left(\frac{x^2+y^2}{2\sigma^2} - 1\right)e^{-\frac{x^2+y^2}{2\sigma^2}}.$$ I wonder why multiply by $\sigma^2$ not $\sigma^4$ or anything else? UPDATE Thanks to comments from @achille. From the perspective of dimensional analysis , in the Laplacian of Gaussian operator
$$LoG(x,y,\sigma)=\frac{\partial^2g}{\partial x^2} +\frac{\partial^2g}{\partial y^2}$$, I think $x,y$ are variables with dimension $L$, $\sigma$ is a parameter with dimension $L$. But what about $g$? Since $g$ is a function of $x,y,\sigma$,
$$g(x,y,\sigma)=\frac{1}{2\pi \sigma^2}exp(-\frac{x^2+y^2}{2\sigma^2})$$,
and $x,y,\sigma$ are of the same dimension $L$, so I guess in $g$, the term $exp(-\frac{x^2+y^2}{2\sigma^2})$ is dimensionless, isn't it? And the term $\frac{1}{2\pi \sigma^2}$ is of dimension $L^{-2}$, right? So $g$ is actually of dimension $L^{-2}$, isn't it? Now come back to $LoG$, it should have dimension $L^{-4}$? UPDATE 2 Laplacian operator is 
$$\nabla^2 = \frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}$$,
and a Gaussian function's scale is $\sigma$, right? If I apply $\nabla^2$ on a Gaussian function $g(x,y,\sigma)$, what is difference of applying the dimensionless $\sigma^2*\nabla^2$?","['image-processing', 'derivatives']"
486316,Help with elementary question involving a partially ordered set.,"Let N with divisibility be a partially ordered set. Show that any 2 element subset of N has a greatest lower bound and a least upper bound. I seem to keep going in circles, but I have the idea that if we let $m=ab\in N$ then $a\mid m$ and $b\mid m$, but this only guarantees we have an upper bound. Any help is appreciated.","['lattice-orders', 'discrete-mathematics', 'order-theory']"
486332,Almost Everywhere pointwise limit measurable functions measurable?,"I'm having difficulties verifying a remark in Raymond Ryan's treatment of the Bochner Integral. $\bf{\text{Remark:}}$ If $\mu$ is $\sigma$-finite, and $(f_{n})_{n=1}^{\infty}$ is a sequence of $\mu$-measurable functions which converges to $f$ almost everywhere, then $f$ is $\mu$-measurable. $\bf{\text{Edit:}}$ At this point I am currently looking for an authoritative answer on what the hypothesis of this remark should be, given the comments below. $\bf{\text{Background:}}$ Let $(\Omega,\Sigma,\mu)$ be a $\sigma$-finite measure space, and $X$ be a Banach space. A function $f:\Omega\to X$ is simple if it assumes only finitely many values.  That is, there exists subsets $E_{1}, ... , E_{n}$ of $\Omega$ and scalars $x_{1}, ... , x_{n}\in X$ such that $f = \sum_{i=1}^{n}\chi_{E_{i}}x_{i}$. If the sets $E_{i}$ can be chosen from $\Sigma$, then $f$ is $\mu$-measurable simple. A function $f:\Omega\to X$ is $\mu$-measurable if it is the limit of a sequence of $\mu$-measurable simple functions (almost everywhere). A function $f:\Omega\to X$ is $\mu$-essentially separately valued if there exists $E\in \Sigma$ such that $\mu(\Omega\backslash E) = 0$ and $f(E)\subset Y$ for some separable subspace $Y$ of $X$. These are the immediately preceding results (which may or may not be useful). $\bf{\text{Lemma:}}$  Let $\mu$ be $\sigma$-finite.  $f:\Omega\to X$ is $\mu$-measurable if and only if $\chi_{E}f$ is $\mu$-measurable for every $E\in \Sigma$, $\mu(E) < \infty$. Proof (My previous question): Fact about measurable functions defined on $\sigma$-finite measure spaces. $\bf{\text{(Pettis Measurability Theorem)}}$  Let $\mu$ be a $\sigma$-finite measure.  The following are equivalent for $f:\Omega\to X$. (i) $f$ is $\mu$-measurable. (ii) $f$ is weakly $\mu$-measurable and $\mu$-essentially separately valued. (iii) $f$ is Borel measurable and $\mu$-essentially separately valued. Sorry for not having much of a start yet.  My ideas consisted of trying to adapt the solution given as an answer to my previous question: Fact about measurable functions defined on $\sigma$-finite measure spaces. but sadly went nowhere.  I'm just looking for a hint not a full solution if possible. $\bf{\text{Regarding My Issues Below:}}$ In Norbert's proof: Case (1): The functions $f_{n}$ are each $\mu$-measurable simple as they can be written as $f_{n} = \chi_{\phi}$ and $\phi\in\Sigma$.  Since $f_{n}\to\chi_{F}$ at every point outside of $F$, then by definition, $\chi_{F}$ is $\mu$-measurable.  So I don't think a contradiction exists here. Case (2): Before completeness is invoked, we have that since $f_{n}$ is $\mu$-measurable, $x^{*}\circ f_{n}$ is a $\mu$-measurable scalar valued function on $E$ for every $x^{*}\in X^{*}$.  Therefore it is concluded that $x^{*}\circ f$ is a $\mu$-measurable scalar valued function on $E$ for every $x^{*}\in X^{*}$.  I cannot manage to prove the details on this last step; it seems to actually require the remark which is to be proved? $\bf{\text{Follow Up:}}$  I think I have found the heart of the matter, which I have posted as a separate question: Contradiction achieved with the Pettis Measurability Theorem?","['measure-theory', 'functional-analysis']"
486355,Prove that $y^3=x^2+2^{16}3^9$ has no integer solutions,"Prove that $y^3=x^2+2^{16}3^9$ has no integer solutions. Let $k=2^83^4,$ then $y^3=x^2+3k^2=(x+\sqrt{-3}k)(x-\sqrt{-3}k),$ but that's going to be complex. I wonder is there a better way to solve this problem? Edit: Sorry, this statement is NOT true, since $1728^3=62208^2+2^{16}3^9.$
I saw this problem from a website, but that OP gave me a false statement..","['diophantine-equations', 'number-theory']"
486367,characterize all matrices $X$ such that $BA = X$ whenever $AB = X$,It is clear that if $A$ and $B$ are $n\times n$ matrices (over a field) with $AB = I$ then $BA = I$. I like to characterize all matrices $X$ such that $BA = X$ whenever $AB = X$.,['linear-algebra']
486369,Prove that the set of all diagonal matrices is a subring of $\operatorname{Mat}_n(R)$ which is isomorphic to $R \times\dots\times R$ ($n$ factors),"Can someone tell me, is that diagonal matrices is a subring of $\operatorname{Mat}_n(R)$ which is (ring) isomorphic to $R \times · · · \times R$ (n factors) and why?.","['matrices', 'ring-theory', 'linear-algebra']"
486382,How find this positive $n$ such $n<6(1-1.001^{-1000})<n+1$,"let $n$ is positive numbers,and such 
$$n<6(1-1.001^{-1000})<n+1$$ find the value $n$ This problem is from china compition today,(some hours ago) my try:use this following 
$$\lim_{n\to0}(1-n)^{\frac{1}{n}}=\dfrac{1}{e}$$
so
$$6(1-1.001^{-1000})\approx 6(1-\dfrac{1}{e})$$ so we have $$n=3$$ other idea
$$(1.001)^{-1000}=(1+0.001)^{-1000}=1-1000\cdot0.001+\dfrac{(-1000)(-1000-1)}{2}(0.001)^2+\cdots $$
 this idea seems very ugly my question, Have other good nice methods? Thank you","['calculus', 'limits']"
486398,"Andre LeClair, Riemann zeta zero approximation?","This sequence A177885 in the oeis seemingly relates imaginary parts of non-trivial Riemann zeta zeros with the LambertW function. The real and imaginary parts of the Riemann zeta function is the sum of cosine and sine waves with logarithms as frequencies. Logarithms can be calculated as: $$\log(n)=\lim_{s\to 1} \, \left(1-\frac{1}{n^{s-1}}\right) \zeta (s)$$ of which the numerators in the Dirichlet series are found in the following infinite table: $$T = \begin{bmatrix} 0&0&0&0&0&0&0 \\ 1&-1&1&-1&1&-1&1 \\ 1&1&-2&1&1&-2&1 \\ 1&1&1&-3&1&1&1 \\ 1&1&1&1&-4&1&1 \\ 1&1&1&1&1&-5&1 \\ 1&1&1&1&1&1&-6 \end{bmatrix}$$ which has the definition: $$T(n,k) = -(n-1)\; \text{ if }\; n|k, \;\text{ else } \;1,$$ Repeating/recursing the formula above we write: $$\log(a(n))= \lim_{s\to 1} \, \zeta (s) \sum _{k=1}^n \frac{T(n,k)}{k^{s-1}}$$ where a(n) appears to be: $$a(n)=\frac{n^n}{n!}$$ $a(n) =$ {1, 2, 9/2, 32/3, 625/24, 324/5, 117649/720, 131072/315, 
4782969/4480, 1562500/567, 25937424601/3628800, 35831808/1925,...} $\left\{1,2,\frac{9}{2},\frac{32}{3},\frac{625}{24},\frac{324}{5},\frac{117649}{720},\frac{131072}{315},\frac{4782969}{4480},\frac{1562500}{567},\frac{25937424601}{3628800},\frac{35831808}{1925}\right\}$ multiplying with the factorial one finds the similar but alternating sequence A177885 in the oeis. There in the comment this approximate formula is given: Table[N[1/2 + 2*Pi*Exp[1]*(n - 11/8)/Exp[1]/LambertW[(n - 11/8)/Exp[1]]*I], {n, 
 1, 12}]
Table[N[ZetaZero[n]], {n, 1, 12}] which gives: {0.5 + 14.5213 I, 0.5 + 20.6557 I, 0.5 + 25.4927 I, 0.5 + 29.7394 I, 
 0.5 + 33.6245 I, 0.5 + 37.2574 I, 0.5 + 40.7006 I, 0.5 + 43.994 I, 
 0.5 + 47.1651 I, 0.5 + 50.2337 I, 0.5 + 53.2144 I, 0.5 + 56.1189 I}

{0.5 + 14.1347 I, 0.5 + 21.022 I, 0.5 + 25.0109 I, 0.5 + 30.4249 I, 
 0.5 + 32.9351 I, 0.5 + 37.5862 I, 0.5 + 40.9187 I, 0.5 + 43.3271 I, 
 0.5 + 48.0052 I, 0.5 + 49.7738 I, 0.5 + 52.9703 I, 0.5 + 56.4462 I} The Series for x/LambertW is: Series[x/LambertW[x], {x, 0, 7}] $$\frac{x}{W(x)} = 1+x-\frac{x^2}{2}+\frac{2 x^3}{3}-\frac{9 x^4}{8}+\frac{32 x^5}{15}-\frac{625 x^6}{144}+\frac{324 x^7}{35}+O\left(x^8\right)$$ which has some similarity with $a(n)$ $$\frac{x}{W(x)} = \frac{(-1)^n n^n x^{n+1}}{(n+1)!}$$ $$a(n)=\frac{n^n}{n!}$$ $\left\{\frac{1}{2},\frac{2}{3},\frac{9}{8},\frac{32}{15},\frac{625}{144},\frac{324}{35},\frac{117649}{5760},\frac{131072}{2835},\frac{4782969}{44800},\frac{1562500}{6237},\frac{25937424601}{43545600},\frac{35831808}{25025}\right\}$ Is there a connection? Edit 7.9.2013: Would these sequences give more accurate power series approximations? Just a thought. Clear[t, s, nn, m, k, n];
m = 1;
nn = 12;
t[n_, 1] = 1;
t[1, k_] = 1;
t[n_, k_] := t[n, k] = (1 - If[Mod[k, n] == 0, n, 0]);
MatrixForm[Table[Table[t[n, k], {k, 1, m*nn}], {n, 1, m*nn}]];
Print[""here""]
Monitor[A = 
  Table[Limit[Zeta[s]*Sum[t[n, k]/k^(s - 1), {k, 1, m*n}], 
    s -> 1], {n, 1, nn}], n]



Clear[t, s, nn, m, k, n];
m = 2;
nn = 12;
t[n_, 1] = 1;
t[1, k_] = 1;
t[n_, k_] := t[n, k] = (1 - If[Mod[k, n] == 0, n, 0]);
MatrixForm[Table[Table[t[n, k], {k, 1, m*nn}], {n, 1, m*nn}]];
Print[""here""]
Monitor[A = 
  Table[Limit[Zeta[s]*Sum[t[n, k]/k^(s - 1), {k, 1, m*n}], 
    s -> 1], {n, 1, nn}], n]



Clear[t, s, nn, m, k, n];
m = 3;
nn = 12;
t[n_, 1] = 1;
t[1, k_] = 1;
t[n_, k_] := t[n, k] = (1 - If[Mod[k, n] == 0, n, 0]);
MatrixForm[Table[Table[t[n, k], {k, 1, m*nn}], {n, 1, m*nn}]];
Print[""here""]
Monitor[A = 
  Table[Limit[Zeta[s]*Sum[t[n, k]/k^(s - 1), {k, 1, m*n}], 
    s -> 1], {n, 1, nn}], n]



Clear[t, s, nn, m, k, n];
m = 4;
nn = 12;
t[n_, 1] = 1;
t[1, k_] = 1;
t[n_, k_] := t[n, k] = (1 - If[Mod[k, n] == 0, n, 0]);
MatrixForm[Table[Table[t[n, k], {k, 1, m*nn}], {n, 1, m*nn}]];
Print[""here""]
Monitor[A = 
  Table[Limit[Zeta[s]*Sum[t[n, k]/k^(s - 1), {k, 1, m*n}], 
    s -> 1], {n, 1, nn}], n]



Clear[t, s, nn, m, k, n];
m = 5;
nn = 12;
t[n_, 1] = 1;
t[1, k_] = 1;
t[n_, k_] := t[n, k] = (1 - If[Mod[k, n] == 0, n, 0]);
MatrixForm[Table[Table[t[n, k], {k, 1, m*nn}], {n, 1, m*nn}]];
Print[""here""]
Monitor[A = 
  Table[Limit[Zeta[s]*Sum[t[n, k]/k^(s - 1), {k, 1, m*n}], 
    s -> 1], {n, 1, nn}], n] Edit 7.9.2013: The connection I was looking for: $$\sum _{n=1}^{\infty} \frac{x (-x)^n \exp \left(\lim_{s\to 1} \, \zeta (s) \sum _{k=1}^n \frac{1-\text{If}[k \bmod n=0,n,0]}{k^{s-1}}\right)}{n+1}+x+1 =1+x-\frac{x^2}{2}+\frac{2 x^3}{3}-\frac{9 x^4}{8}+\frac{32 x^5}{15}-\frac{625 x^6}{144}+\frac{324 x^7}{35}-\frac{117649 x^8}{5760}+\frac{131072 x^9}{2835}-\frac{4782969 x^{10}}{44800}+\frac{1562500 x^{11}}{6237}-\frac{25937424601 x^{12}}{43545600}+\frac{35831808 x^{13}}{25025}-...$$ 1 + x + Sum[
  x*(-x)^n*Exp[
     Limit[Zeta[s]*
       Sum[(1 - If[Mod[k, n] == 0, n, 0])/k^(s - 1), {k, 1, n}], 
      s -> 1]]/(n + 1), {n, 1, 12}]
Series[x/LambertW[x], {x, 0, 12}] Edit 2.10.2013: Integration is better: Clear[x, n, k, s, a1, nn, b1]
b1 = Expand[
   Sum[Exp[Limit[
       1/(s - 1)*
        Sum[(1 - If[Mod[k, n] == 0, n, 0])/(k)^(s - 1), {k, 1, 4*n}], 
       s -> 1]]*(-x)^n, {n, 0, 32}]];
a1 = 1 + Integrate[b1, x];
x = N[(1 - 11/8)/Exp[1], 30];
Print[""here""]
N[2*Pi*Exp[1]*a1, 30]
N[2*Pi*Exp[1]*x/LambertW[x], 30]

Clear[x, n, k, s, a1, nn]
a1 = 1 + Integrate[b1, x];
x = N[(2 - 11/8)/Exp[1], 30];
Print[""here""]
N[2*Pi*Exp[1]*a1, 30]
N[2*Pi*Exp[1]*x/LambertW[x], 30] where the number $4$ within: {k, 1, 4*n}], can be varied for truncating the Dirichlet series for the logarithm of $n$. At least as long as the truncated Dirichlet series does not get longer than the power series, there is tendency for the Zeta zero approximations to stay close to the zeta zeros. 12.10.2013:
Better integration: Clear[x, n, k, s, a1, nn, b1]
b1 = Expand[
   Sum[Exp[Limit[
       Zeta[s]*Sum[(1 - If[Mod[k, n] == 0, n, 0])/k^(s - 1), {k, 1, 
          n}], s -> 1]]*(-x)^n, {n, 1, 32}]];
a1 = 1 + Integrate[1 + b1, x];
x = N[(1 - 11/8)/Exp[1], 30];
Print[""here""]
N[2*Pi*Exp[1]*a1, 30]
N[2*Pi*Exp[1]*x/LambertW[x], 30]

Clear[x, n, k, s, a1, nn]
a1 = 1 + Integrate[1 + b1, x];
x = N[(2 - 11/8)/Exp[1], 30];
Print[""here""]
N[2*Pi*Exp[1]*a1, 30]
N[2*Pi*Exp[1]*x/LambertW[x], 30] This Excel Spreadsheet formula uses Andre LeClaire's formula to approximate the Riemann zeta zeros: =IF(OR(ROW()=1; COLUMN()=1);0; IF(ROW()>=COLUMN();EXP(-(1-11/8/(COLUMN()-1))/EXP(1)*SUM(INDIRECT(ADDRESS(ROW()-COLUMN()+1; COLUMN(); 4)&"":""&ADDRESS(ROW()-1; COLUMN(); 4); 4)));0)) (European dot-comma) you need to divide the result with: /2/PI()/EXP(1) and take the reciprocal. tetration this is.","['riemann-hypothesis', 'lambert-w', 'number-theory']"
486409,How find this maximum of $f(n)$,"let $x_{i}\in (0,1),i=1,2,\cdots,n,x_{n+1}=x_{1}$,give for any positive integer numbets $n$, find 
$$f(n)=\max{\sum_{i=1}^{n}x_{i}(1-x_{i+1})}$$ find the $f(n)$ it is easy find when $n=1$, then 
$$f(1)=\max{x_{1}(1-x_{1})}=\dfrac{1}{4}$$ when $n=2$
$$f(2)=\max{\left(x_{1}(1-x_{2}),x_{2}(1-x_{1})\right)}\le\dfrac{1}{4}?$$ $$\cdots\cdots\cdots\cdots\cdots\cdots$$ so I can't any work,Thank you everyone","['multivariable-calculus', 'inequality']"
486428,Asymptotic Expansion of a Two Variable Function,"How is the double asymptotic expansion defined? I can't seem to find it anywhere. Suppose $$f(x)\sim \sum_{n=0}^\infty a_n\phi_n(x)$$ as described in the Wikipedia article .  How is then, for instance, $f(x,y)$ defined asymptotically? What are its general properties? Any similarities with the one-variable case? I'm trying to generalize the notion of asymptotic expansion to the two variable case. Does the following mean anything to you (I just made it up): $$f(x,y) \sim \sum_{m,n} a_m x^m b_n y^n$$ such that the difference $$f(x,y)-\sum_{m=0}^{M-1}a_mx^m\sum_{n=0}^{N-1}a_ny^n\in \mathcal{O}(x^my^n)$$ as $(x,y)\rightarrow(0,0)$ Does that make sense?","['asymptotics', 'complex-analysis', 'real-analysis']"
486431,Stratifications by smooth subvarieties,"Let $X$ be an algebraic variety over an algebraically closed field $k$.
Then $X$ is said to have a stratification if one can find irreducible locally closed subsets $X_i\subset X$ such that $X=\coprod X_i$ and whenever $\overline X_i$ intersects $X_j$ one has $\overline X_i\supseteq X_j$. Question :
Does every algebraic variety $X$ has a stratification by smooth subvarieties? To show the answer is yes (which I believe, but do not know), I tried to play with the smooth locus of the irreducible components, taking the interior and so on, but something possibly singular always seemed to pop out at the end. If there is any hypothesis one has to add on $X$ to get an affirmative answer, or if one has to relax a bit the definition of stratification, that would also be very useful to me. Thank you for any help.",['algebraic-geometry']
