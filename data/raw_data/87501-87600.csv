question_id,title,body,tags
1169561,Why is a metric space an open subset of itself?,"I've been reading about topology, and I've come across the following: Given a metric space $X$, the entire space $X$ is an open subset of $X$. I'm having some trouble thinking about this. I have a counterexample in mind. Suppose we consider the closed subset of $\mathbb{R}$ called $A = [a, b] \in \mathbb{R}$. Isn't $A$ also a metric space? As far as I know, the answer is yes. So, based on the above, $A$ is an open subset of $A$. But, since $a$ and $b$ aren't interior points of $A$, how is $A$ an open subset? What is wrong with my line of thinking?","['general-topology', 'metric-spaces']"
1169591,Can all linear transformations be calculated with a matrix?,"For all finite vector spaces and all linear transformations to/from those spaces, how can you prove/show from the definition of a linear transformation that all linear transformations can be calculated using a matrix.","['linear-transformations', 'matrices', 'linear-algebra']"
1169593,Is it true that $a\cos \alpha \theta = b \cos \beta \theta \implies a=b$ and $\alpha = \beta$,"Is it true that $\forall \theta:a\cos \alpha \theta = b \cos \beta \theta \implies a=b$ and $\alpha = \beta$? If so, how do I prove it? I know it isn't true for the sine case since we could have $a=-b$ and $\alpha = - \beta$",['trigonometry']
1169659,Selecting a type of distribution for a problem,"""Among 30 raffle tickets six are winners. Felicia buys 10 tickets. Find the
probability that she got three winners."" This problem ask me to first identify a random variable and describe
its distribution before doing any computations. I'm having trouble determine which kind of distribution should I use for it. Please help, thanks!","['statistics', 'probability-distributions', 'probability']"
1169684,Does a left-invariant vector field on a complex Lie group preserve holomorphic functions?,"Let $G$ be a (finite-dimensional) complex Lie group, and suppose $f : G \to \mathbb{C}$ is holomorphic.  Let $X$ be a left-invariant vector field on $G$.  Must $Xf$ be holomorphic? I think I have a proof, but I feel that I may have missed some subtlety, or overcomplicated matters.  I'm still learning this area and I don't think my intuition is completely calibrated yet.  I would also be happy to see alternate proofs. Let $\mathfrak{g}$ be the Lie algebra of $G$, considered as the tangent space of $G$ at the identity $e$.  Then $\mathfrak{g}$ has a complex structure; call it $J$.  Without loss of generality we can assume $X$ is a real vector field, so let $\xi = X(e) \in \mathfrak{g}$. By left-invariance it is sufficient to show $Xf$ is holomorphic at $e$.  Fix a holomorphic system of coordinates $(z^1, \dots, z^n)$ in a neighborhood of $e$.  I claim $\displaystyle \frac{\partial}{\partial \bar{z}_j} f = 0$ at $e$.  Let $\bar{Z}$ be a left-invariant complex vector field with $\bar{Z} = \displaystyle \frac{\partial}{\partial \bar{z}_j} $ at $e$.  Then $\bar{Z}$ is of type (0,1) so we can write $\bar{Z}(e) = \eta + i J \eta$ for some $\eta \in \mathfrak{g}$. Now we have $(\bar{Z}Xf)(e) = (X \bar{Z} f)(e) + ([\bar{Z}, X]f)(e)$.  Since $f$ is holomorphic and $\bar{Z}$ is of type (0,1), $\bar{Z} f = 0$ so the first term vanishes.  The second term equals $[\eta + iJ\eta, \xi]f = ([\eta, \xi] + i J [\eta, \xi]) f$ which also vanishes since $[\eta, \xi] + i J [\eta, \xi]$ is also of type (0,1).","['complex-geometry', 'differential-geometry', 'several-complex-variables', 'lie-groups', 'proof-verification']"
1169709,Why first fundamental form?,"Here is an excerpt from the notes we are using: The first fundamental form dictates how one computes dot products of vectors
  tangent to the surface assuming they are expanded according to the basis $\frac{\partial q}{\partial u},\frac{\partial q}{\partial v}$. In particular, we see that while the metric coefficients depend on our parametrization,
  the dot product $\text{I} (X, Y )$ of two tangent vectors remains the same if we change
  parameters. I assume that first fundamental form is really a map from $T_pM \times T_pM\to \text{R}$, but I don't understand what the first part is talking about. Why would we need a matrix to tell us how to perform dot products? I mean, suppose we have vectors $<a,b,c>$ and $<d,e,f>$, we just multiply them term by term, isn't that correct? There is a calculation in the notes, showing that $\text{I}(X,Y)=X \cdot Y$, that even made me more confused.",['differential-geometry']
1169715,"Prove that the set $ \{\sin(x),\cos(x),\sin(2x),\cos(2x)\}$ is linearly independent.","Prove that the set $ \{\sin(x),\cos(x),\sin(2x),\cos(2x)\}$ is linearly independent. I have tried plugging in values for $x$ but where does this lead? I know what the Wronksian is and it would give an almost trivial solution in this case, but I am not allowed to use that.","['trigonometry', 'linear-algebra']"
1169732,Application of Banach Steinhaus theorem,"Let $X,Y$ be Banach spaces and let $A:X\rightarrow Y,B:Y^*\rightarrow X^*$ be linear maps. Show that if for all $x\in X,y\in Y^*,y^*(Ax)=By^*(x)$, then both $A$ and $B$ are continuous","['functional-analysis', 'banach-spaces']"
1169749,Convergence of $\sum\limits_{k=2}^\infty \frac{|\sin kx|}{\log k}$,"For what values of $x \in \mathbb{R}$ do the series 
$$ \sum\limits_{k=2}^\infty \frac{|\sin kx|}{\log k} $$
converge (and how do you prove the rest diverge)? The series converge trivially at $x = n\pi$ where $n \in \mathbb{Z}$, but I'm not sure about any others.","['sequences-and-series', 'calculus', 'real-analysis']"
1169785,Is the countable direct sum of reflexive spaces reflexive?,"Let $(X_n)$ be a sequence of reflexive spaces. We define the $\ell_2$-direct sum $\bigoplus_n X_n$ as the normed space with elements $(x_n)\in \prod_n X_n$ such that 
$$
\|(x_n)\|=\left(\sum_{n}\|x_n\|^2\right)^{\frac{1}{2}}<\infty.
$$ Is $\bigoplus_n X_n$ reflexive? What if we define analogously a $\ell_p$-direct sum for a different $p$? Thank you.",['functional-analysis']
1169802,How to find $y$ from $y' = e^{2x}-e^x y$?,"The problem asks me to find $y(x)$ from the equation
$$y' = e^{2x}-e^x y$$ The $y'$ is $dy/dx$ right, so wouldn't the correct step be to integrate right away? If not, should I change some terms before integrating? I'm fairly new to this, and am unaware of rules so please be clear in explanation, thank you very much.","['ordinary-differential-equations', 'calculus', 'integration']"
1169817,$\cos(x+y)\frac{\partial z}{\partial x}+\sin(x+y)\frac{\partial z}{\partial y}=z+\frac{1}{z}$,"Having difficulty in solving the following partial differential equation: 
$$\cos(x+y)\frac{\partial z}{\partial x}+\sin(x+y)\frac{\partial z}{\partial y}=z+\frac{1}{z}.$$ Will it be easier if we substitute $x+y$ as $s$ and proceed?","['ordinary-differential-equations', 'partial-differential-equations']"
1169829,Convergence of monotone decreasing series $\sum_{n=1}^\infty a_n < \infty \iff \sum_{n=1}^\infty 2^na_{2^n} < \infty$,"Suppose $\{a_n\}$ is a monotone decreasing sequence of positive terms.  Prove that $$\sum_{n=1}^\infty a_n \text{ converges } \iff \sum_{n=1}^\infty 2^na_{2^n} \text{ converges}$$ thought about the integral test but there's no function to integrate, can't assume $a_n\to 0$ implies convergence, and having a tough time using comparison.  Would ratio test do it?","['convergence-divergence', 'sequences-and-series', 'analysis']"
1169871,Why is the tangent of 22.5 degrees not 1/2?,"Sorry for the stupid question, but why is the tangent of 22.5 degrees not 1/2? 
(Okay... I get
 that that the tangent of 45 degrees is 1 (""opposite"" =1, ""adjacent"" =1, 1/1 = 1.  Cool.  I am good with that.) Along those same lines, if the ""opposite"" drops to 1/2 relative to the ""adjacent"" i.e., ""opposite"" = 1, ""adjacent"" = 2 therefore 1/2. What am I missing?  Thanks in advance for your help.",['trigonometry']
1169877,"Proving that $ \int_{0}^{\pi/2} \frac{\mathrm{d}{x}}{\sqrt{a^{2} {\cos^{2}}(x) + b^{2} {\sin^{2}}(x)}} = \frac{\pi}{2 \cdot \text{AGM}(a,b)} $.","I know Neumann’s solution of this famous definite integral that is totally based on substitution, but is there any solution using complex analysis? Assuming that $ a > b $, show that
$$
  \int_{0}^{\pi/2} \frac{\mathrm{d}{x}}{\sqrt{a^{2} {\cos^{2}}(x) + b^{2} {\sin^{2}}(x)}}
= \frac{\pi}{2 \cdot \text{AGM}(a,b)},
$$
where $ \text{AGM}(a,b) $ is the arithmetic-geometric mean of $ a $ and $ b $, which satisfies the following functional equation:
$$
\text{AGM}(a,b) = \text{AGM} \! \left( \frac{a + b}{2},\sqrt{a b} \right).
$$","['definite-integrals', 'integration', 'complex-analysis']"
1169907,What is the word for set containing other sets?,"For example, define $S = \{\{3\}, \{2,1\}, \{1,1,1\}\}$. What is the word for $S$? Multiset? Doesn't seem to be correct. Edit:   Also, how can I denote the cardinality of a specific set within a set?","['notation', 'elementary-set-theory']"
1169913,Are there exists an analytic function satisfying the following condition,"Let, $D=\{z\in \mathbb C:|z|<1\}$. Then there exists a non-constant analytic function$f$ on $D$ such that for all $n=2,3,4,...$ (a) $f\left(\frac{i}{n}\right)=0$. (b) $f\left(\frac{1}{n}\right)=0$. (c) $f\left(1-\frac{1}{n}\right)=0$. (d) $f\left(\frac{1}{2}-\frac{1}{n}\right)=0$. Which is(/are) correct(/s). I tried with Identity theorem, but I have some confusion. From Identity theorem, $S=$ set of all zeros of $f$ has a limit point in $D$ for the options (a) , (b) & (d). So these functions are identically zero. As the function is non-constant so these are NOT possible. So option (c) is only correct. Am I right? OR wrong?","['complex-integration', 'complex-numbers', 'complex-analysis']"
1169930,Help me find the flaw in my method for prime counting,"I've been playing around with my own notation for estimating the number of integers relatively prime to a given primorial and I came up with a result that cannot be right. I would appreciate it if someone could help me restate my observations in standard notation and help me understand my mistake. Here's my notation: $H_{p_i}(x)$ = the number of integers less than or equal to $x$ that are relatively prime to $p_i\#$ For example: $H_3(10) = 3 \left\{ 1,5,7 \right\}$ $H_5(30) = 8 \left\{ 1,7,11,13,17,19,23,29 \right\}$ I use this notation because if I assume $p_0 = 1$ and $H_1(x) = x$, I get: $H_{p_i}(x) = H_{p_{i-1}}(x) - H_{p_{i-1}}\left(\left\lfloor\dfrac{x}{p_i}\right\rfloor\right)$ I also use this notation: $p_i\#_{-1} = (p_i -1)(p_{i-1}-1)(p_{i-2}-1)\dots(2-1)$ So that the standard primorial would be: $p_i\#_{0} = p_i\#$ And the number of pairs of $x,x+2$ that are relatively prime to $p_i\#$ and where $x < p_i\#$ is $p_i\#_{-2}$. So, I was reasoning about primorials using my notation as I normally do when I struck upon a simple formula for the lower bound for any $H_{p_i}$ Let me start with $H_2(x)$ which is easy to state in terms of an upper and lower bound: $\dfrac{x}{2} \le H_2(x) \le \dfrac{x+1}{2}$ Now, I would like to come up with a similar expression for $H_3(x)$ which gets overly complicated and unuseful if we approach it in the obvious way. So, I thought about using two different values: $H_{\text{min}\,3}(x)$ and $H_{\text{max}\,3}(x)$ which I derive in a simple way from $H_2(x)$: $H_{3}(x) = H_2(x) - H_2\left(\left\lfloor\dfrac{x}{3}\right\rfloor\right)$ $H_{\text{min}\, 3}(x) = \dfrac{x}{2} - \dfrac{\frac{x}{3}-\left\{\frac{x}{3}\right\}+1}{2}$ $H_{\text{max}\, 3}(x) = \dfrac{x+1}{2} - \dfrac{\frac{x}{3} -\left\{\frac{x}{3}\right\}}{2}$ so that I get the following upper and lower bounds: $\dfrac{2x-3}{6} \le H_{\text{min}\, 3}(x) \le \dfrac{2x-1}{6}$ $\dfrac{2x+3}{6} \le H_{\text{max}\, 3}(x) \le \dfrac{2x+5}{6}$ where $H_{\text{max}\,3}(x) \ge H_3(x) \ge H_{\text{min}\,3}(x)$ Let: $H_{\text{min}\, \text{low}\, 3}(x) = \dfrac{2x-3}{6}$ $H_{\text{min}\, \text{high}\, 3}(x) = \dfrac{2x-1}{6}$ $H_{\text{max}\, \text{low}\, 3}(x) = \dfrac{2x+3}{6}$ $H_{\text{max}\, \text{high}\, 3}(x) = \dfrac{2x+5}{6}$ Then, I have the following: $H_{\text{min}\, p_i}(x) = H_{\text{min}\, \text{low}\, p_{i-1}}(x) - H_{\text{min}\, \text{high}\, p_{i-1}}\left(\left\lfloor\dfrac{x}{p_i}\right\rfloor\right)$ $H_{\text{max}\, p_i}(x) = H_{\text{max}\, \text{high}\, p_{i-1}}(x) - H_{\text{max}\, \text{low}\, p_{i-1}}\left(\left\lfloor\dfrac{x}{p_i}\right\rfloor\right)$ Using induction (see below for my logic), I was able to generalize this to: $\dfrac{p_i\#_{-1}x - p_i(p_{i-1}\#_{-1})}{p_i\#} \le H_{\text{min}\, p_i}(x) \le \dfrac{p_i\#_{-1}x - p_i\#_{-1}}{p_i\#}$ $\dfrac{p_i\#_{-1}x + p_i(p_{i-1}\#_{-1})}{p_i\#} \le H_{\text{max}\, p_i}(x) \le \dfrac{p_i\#_{-1}x + p_i(p_{i-1}\#_{-1}) + p_i\#_{-1}}{p_i\#}$ Using the results above, I attempt to analyze Legendre's Conjecture : Let $p_i$ be the largest prime less than or equal to $x$ $\pi(x^2 + 2x) - \pi(x^2) = H_{p_i}(x^2 + 2x) - H_{p_i}(x^2) \ge H_{\text{min}\, p_i}(x^2+2x) - H_{\text{max}\, p_i}(x^2)$ $H_{\text{min}\, p_i}(x^2+2x) - H_{\text{max}\, p_i}(x^2) \ge \dfrac{p_i\#_{-1}(x^2+2x) - p_i(p_{i-1}\#_{-1})}{p_i\#} - \dfrac{p_i\#_{-1}(x^2) + p_i(p_{i-1}\#_{-1}) + p_i\#_{-1}}{p_i\#} =$ $= \dfrac{p_i\#_{-1}(x^2+2x -x^2) - (p_i + p_i + [p_i-1])(p_{i-1}\#_{-1})}{p_i\#} =$ $=  \dfrac{p_i\#_{-1}(2x) - (3p_i-1)(p_{i-1}\#_{-1})}{p_i\#} > \dfrac{(p_i-1)(2x) - (3p_i-1)}{p_i p_{i-1}}$ $\dfrac{(p_i-1)(2x) - (3p_i-1)}{p_i p_{i-1}} > \dfrac{2x-3}{p_i} \ge \dfrac{2x-3}{x} =2  -\dfrac{3}{x}$ which would suggest that Legendre's Conjecture is true for $x \ge 3$ This result is ridiculous given the primitiveness of my method.  Could someone help me to see what I am doing wrong? Here's my logic behind the induction. Lemma 1: $\dfrac{p_i\#_{-1}x - p_i(p_{i-1}\#_{-1})}{p_i\#} \le H_{\text{min}\, p_i}(x) \le \dfrac{p_i\#_{-1}x - p_{i-1}\#_{-1}}{p_{i}\#}$ (1)  $H_{2}(x) = x - \left\lfloor\dfrac{x}{2}\right\rfloor = \dfrac{x}{2} + \left\{\dfrac{x}{2}\right\}$ (2)  $H_{3}(x) = H_{2}(x) - H_2(\left\lfloor\dfrac{x}{3}\right\rfloor)$ (3)  $H_{\text{min}\, 3} = \dfrac{x}{2} - \dfrac{\frac{x}{3} -\left\{\frac{x}{3}\right\}+1}{2} = \dfrac{2x-3 + 3\left\{\frac{x}{3}\right\}}{6} $ (4) $\dfrac{2x-3}{6} \le H_{\text{min}\, 3}(x) \le \dfrac{2x-1}{6}$ (5) Assume $\dfrac{p_i\#_{-1}x - p_i(p_{i-1}\#_{-1})}{p_i\#} \le H_{\text{min}\, p_i}(x) \le \dfrac{p_i\#_{-1}x - p_{i-1}\#_{-1}}{p_{i}\#}$ (6) $H_{p_{i+1}}(x) = H_{p_i}(x) - H_{p_i}(\left\lfloor\dfrac{x}{p_{i+1}}\right\rfloor)$ (7) $H_{\text{min}\, p_{i+1}} =\dfrac{p_i\#_{-1}x - p_i(p_{i-1}\#_{-1})}{p_i\#} - \dfrac{p_i\#_{-1}\left\lfloor\frac{x}{p_{i+1}}\right\rfloor - p_{i-1}\#_{-1}}{p_i\#} =$ $= \dfrac{p_{i+1}\#_{-1}x - p_{i+1}(p_i\#_{-1}) + (p_i\#_{-1})(p_{i+1})\left\{\frac{x}{p_{i+1}}\right\}}{p_{i+1}\#}$ (8)  So that: $\dfrac{p_{i+1}\#_{-1}x - p_{i+1}(p_{i}\#_{-1})}{p_{i+1}\#} \le H_{\text{min}\, p_{i+1}}(x) \le \dfrac{p_{i+1}\#_{-1}x - p_{i}\#_{-1}}{p_{i+1}\#}$ Lemma 2: $\dfrac{p_i\#_{-1}x + p_i(p_{i-1}\#_{-1})}{p_i\#} \le H_{\text{max}\, p_i}(x) \le \dfrac{p_i\#_{-1}x + p_i(p_{i-1}\#_{-1}) + p_i\#_{-1}}{p_i\#}$ (1)  $H_{2}(x) = x - \left\lfloor\dfrac{x}{2}\right\rfloor = \dfrac{x}{2} + \left\{\dfrac{x}{2}\right\}$ (2)  $H_{3}(x) = H_{2}(x) - H_2(\left\lfloor\dfrac{x}{3}\right\rfloor)$ (3)  $H_{\text{max}\, 3} = \dfrac{x+1}{2} - \dfrac{\frac{x}{3} -\left\{\frac{x}{3}\right\}}{2} = \dfrac{2x+3 + 3\left\{\frac{x}{3}\right\}}{6} $ (4) $\dfrac{2x+3}{6} \le H_{\text{max}\, 3}(x) \le \dfrac{2x+5}{6}$ (5) Assume $\dfrac{p_i\#_{-1}x + p_i(p_{i-1}\#_{-1})}{p_i\#} \le H_{\text{max}\, p_i}(x) \le \dfrac{p_i\#_{-1}x + p_i(p_{i-1}\#_{-1}) + p_i\#_{-1}}{p_i\#}$ (6) $H_{p_{i+1}}(x) = H_{p_i}(x) - H_{p_i}(\left\lfloor\dfrac{x}{p_{i+1}}\right\rfloor)$ (7) $H_{\text{max}\, p_{i+1}} =\dfrac{p_{i}\#_{-1}x + p_i(p_{i-1}\#_{-1}) + p_i\#_{-1}}{p_i\#} - \dfrac{p_i\#_{-1}\left\lfloor\frac{x}{p_{i+1}}\right\rfloor + p_i(p_{i-1}\#_{-1}) }{p_i\#}=$ $= \dfrac{p_{i+1}\#_{-1}x + p_{i+1}(p_i\#_{-1}) + (p_i\#_{-1})(p_{i+1})\left\{\frac{x}{p_{i+1}}\right\}}{p_{i+1}\#}$ (8)  So that: $\dfrac{p_{i+1}\#_{-1}x + p_{i+1}(p_{i}\#_{-1})}{p_{i+1}\#} \le H_{\text{max}\, p_{i+1}}(x) \le \dfrac{p_{i+1}\#_{-1}x + p_{i+1}(p_{i}\#_{-1}) + p_{i+1}\#_{-1}}{p_{i+1}\#}$ Edit:  Additional examples $H_5(20) = H_3(20) - H_3(\left\lfloor\dfrac{20}{5}\right\rfloor) = [H_2(20) - H_2(\left\lfloor\dfrac{20}{3}\right\rfloor)] -[H_2(4) - H_2(\left\lfloor\dfrac{4}{3}\right\rfloor)] =$ $= [H_1(20) - H_1(\left\lfloor\dfrac{20}{2}\right\rfloor)] - [H_1(6) - H_1(\left\lfloor\dfrac{6}{2}\right\rfloor)] - [H_1(4) - H_1(\left\lfloor\dfrac{4}{2}\right\rfloor)] + [H_1(1) - H_1(\left\lfloor\dfrac{1}{2}\right\rfloor) =$ $= [20 - 10]  - [6-3] - [4-2] +[1-0] = 6 \{1, 7, 11, 13, 17, 19\}$ Edit: Added clarification on $3p_i - 1$ based on comment.","['prime-numbers', 'proof-verification', 'number-theory']"
1169933,Coefficients of Quotient of two power series,"So I have two functions $f$ and $g$ which are holomorphic on some disk $D(a,r)$ and such that $g$ is never zero on that disk. Where we can represent the two function as power series given by $f(z)=\sum\limits_{n=0}^\infty a_n(z-a)^n$ and  $g(z)=\sum\limits_{m=0}^\infty b_m(z-a)^m$ Let $f_N=\sum\limits_{n=0}^N a_n(z-a)^n$ and $g_N=\sum\limits_{m=0}^N b_m(z-a)^m$ then by carrying out the long division of the two polynomials we get that $$f_N=p_Ng_N+r_N$$ where $p_N$ and $r_N$ are two polynomials and $deg(r_N)$ is at most $N-1$ I want to show that for each integer $m$, the coefficient $c_m$ of $(z-a)^m$ is the same in all the polynomials $p_N$ for $N>m$, and that will be the coefficients on $z^m$ in the Taylor series for $f/g$. I'm not sure how to do that. Perhaps someone could give me a hint or tell me if I'm going about this the wrong way. What I have so far is that I know that since $f$ and $g$ are holomorphic on $D(a,r)$ and since $g$ is never zero on $D(a,r)$, $f/g$ will be holomorphic on $D(a,r)$ also. Thus $f/g$ has a power series representation on $|z-a|<r$. I also know that for every positive integer $m$ and every $s$ such that $0<s<r$, \begin{align*}c_m&=\frac{1}{2\pi i}\int_{|w-a|=s}\frac{f(w)}{g(w)(w-a)^{m+1}}dw\\
&=\lim\limits_{N\to\infty}\frac{1}{2\pi i}\int_{|w-a|=s}\frac{f_N(w)}{g_N(w)(w-a)^{m+1}}dw\\
&=\lim\limits_{N\to\infty}\frac{1}{2\pi i}\int_{|w-a|=s}\frac{p_N(w)g_N(w)+r_N(w)}{g_N(w)(w-a)^{m+1}}dw\\
&=\lim\limits_{N\to\infty}\frac{1}{2\pi i}\int_{|w-a|=s}\left[\frac{p_N(w)}{(w-a)^{m+1}}+\frac{r_N(w)}{g_N(w)(w-a)^{m+1}}\right]dw\\
&=\lim\limits_{N\to\infty}\frac{1}{2\pi i}\int_{|w-a|=s}\frac{p_N(w)}{(w-a)^{m+1}}dw+\lim\limits_{N\to\infty}\frac{1}{2\pi i}\int_{|w-a|=s}\frac{r_N(w)}{g_N(w)(w-a)^{m+1}}dw\\
\end{align*} I think that the first integral gives the coefficients of the polynomial $p$, but I'm not sure what happens with the second integral since $deg(g_N)>deg(r_N)$.",['complex-analysis']
1169942,Why can partial derivatives be exchanged?,"In the Equality of mixed partial derivatives post in this stack exchange, one of the answers to the questions of do partial derivatives commute is: Second order partial derivatives commute if f is $C^2$ (i.e. all the second partial derivatives exist and are continuous). This is sometimes called Schwarz's Theorem or Clairaut's Theorem. This theorem is in my textbooks, yet I cannot seem to find the proof in them. I have tried proving the theorem yet I have gotten stuck. So, what is the proof of Clairaut's Theorem, or why do partial derivatives commute? If the proof is too long, a link to the proof with an intuitive explanation will be sufficient.",['calculus']
1169981,"Problem 5, sec. 13, in Munkres' Topology, 2nd ed.: How to prove the assertion if $\mathscr{A}$ is a subbasis?","Show that if $\mathscr{A}$ is a basis for a topology on $X$ , then the topology generated by $\mathscr{A}$ equals the intersection of all topologies on $X$ that contain $\mathscr{A}$ . This is what I've managed. However, the following stumps me: Prove the same if $\mathscr{A}$ is a subbasis. That is, how to show that, the topology generated by $\mathscr{A}$ as a subbasis is the same as the intersection of all topologies on $X$ that contain $\mathscr{A}$ ? Let $\mathscr{T}$ be the topology that consists of all unions of finite intersections of sets in $\mathscr{A}$ , and let $\mathscr{T}^\prime$ be the topology that is the intersection of all topologies that contain $\mathscr{A}$ . Now $\mathscr{A}$ is a collection of subsets of $X$ whose union is all of $X$ , and each set $A \in \mathscr{A}$ is in both $\mathscr{T}$ and $\mathscr{T}^\prime$ . Am I right so far? And if so, then what next?","['general-topology', 'analysis']"
1170001,What is the smallest possible basis for the finite complement topology on $\mathbb{R}$?,"Let $\mathbb{R}$ denote the set of all real numbers, and let $\mathscr{T}$ be a collection of subsets of $\mathbb{R}$ such that $U \in \mathscr{T}$ if and only if $\mathbb{R} \setminus U$ is either finite or all of $\mathbb{R}$. Then $\mathscr{T}$ is a topology on $\mathbb{R}$, called the finite complement, or co-finite, topology. Now $\mathscr{T}$ itself is a basis for this topology, but can we determine a basis for $\mathscr{T}$ that is contained in every other basis for $\mathscr{T}$?","['general-topology', 'analysis']"
1170011,How to integrate $\frac{x^{2}\log {\sin x}}{1+x^{6}}$,"I recently stumbled upon a question
$$\int_0^{\infty}\frac{x^{m-1}\log^{a}x}{1+x^n}dx$$
I was able to evaluate it,but I am curious if there exists a closed form for,
$$\int_0^{\pi/2}\frac{x^{2}\log{\sin x}}{1+x^6}dx$$
It numerically evaluates to -0.1392432458. My attempt- $$\int \frac {x^2}{1+x^6}dx=\frac13 \int \frac {d(x^3)}{1+x^6}=\frac13 \arctan {x^3}$$
Then,by applying integration by parts,
$$\int_0^{\pi/2}\frac{x^2\log\sin x}{1+x^6}dx=-\int_0^{\pi/2}\frac13\arctan {x^3} \cot x dx$$.But now I'm stuck.","['definite-integrals', 'closed-form', 'integration']"
1170021,Intuitive explanation of binomial coefficient,"We know that $$\dbinom{n}r = \dfrac{n!}{(n-r)!r!}$$ An intuitive explanation of the formula is that, if I partition the total number of permutations of objects by $r!$, and choose one member of each partition, then no similarly ordered pattern will be registered more than once. Is there a more intuitive explanation than this?","['permutations', 'binomial-coefficients', 'combinatorics']"
1170024,Bijective isometry which fixes origin from $\mathbb{R}^{n} \longrightarrow \mathbb{R}^{n}$ is linear,I was  going through Hall's book about Lie groups.While presenting Euler groups $E(n)$ and on the way to prove that they form a matrix Lie group hee made a proposition that Every one one onto distance preserving map from $\mathbb{R}^{n}$ to $\mathbb{R}^{n}$ which fixes origin will be linear.He has not proved it.For $n=1$ it is clear.But how to prove it generally ?,"['lie-groups', 'differential-geometry']"
1170033,"If $f^2$ and $f^3$ are smooth, does it follow that $f$ is smooth?","Let $f: \mathbb{R} \to \mathbb{R}$ be given. Assume that the square and cube of $f$ are smooth. Is $f$ smooth? That is if $f \cdot f \in C^{\infty}$ and $f \cdot f \cdot f \in C^{\infty}$, does it follow that: $f \in C^{\infty}$ I got this from another question on SE. So, $f(x)^2$ is infinitely differentiable, and so is: $f(x)^3$ Also, realize: $$f(x) = \frac{f(x)^3}{f(x)^2}$$ But what can I do?","['functional-analysis', 'calculus', 'real-analysis', 'proof-writing', 'derivatives']"
1170039,Expectation of couples surviving after some time.,"There are $2m$ persons forming $m$ couples who live together at a given time. Suppose that at some later time, the probability of each person being alive is $p$, independently of other persons. At that later time, let $A$ be the number of persons that are alive and let $S$ be the number of couples in which both partners are alive. For any number of total surviving persons $a$, find $E[S∣A=a]$. I don't have the answer to the problem. Here is my proposed solution, can anyone verify whether it is correct. Let $$(S| A= a) = (S_1| A = a) + (S_2| A = a) + ... + (S_m | A = a)$$ Here $(S_i| A = a)$ is a indicator variable indicating whether both members in a couple are alive or not. So the probability of $p(S_i | A = a)$ is given by $$\frac{p(S_i \cap A = a)}{p(A = a)}$$ where the numerator is given by $p^2 {n - 2 \choose a-2}p^{a-2}(1-p)^{n-2-(a-2)}$ and denominator is given by ${n \choose a}p^a(1-p)^{n-a}$. Therefore $E[S_i | A = a]$ is now known to us, and by symmetry all the indicator variables will have same expectation. So we have the final answer as $m \cdot \frac{p(S_i \cap A = a)}{p(A = a)}$. If I am wrong, point out from the specific place where I went wrong. Thanks!","['probability', 'expectation']"
1170137,"Let $A$ and $B$ be sets, then if $A \subseteq B$ then $A \cap B = A$","Let $A$ and $B$ be sets, then if $A \subseteq B$ then $A \cap B = A$. How do I prove the above? I'm new to proving, please help! What are the steps I need to create a proof? I'm really lost. Now I know that the above is true (I can visualize it, and I can even draw a Venn diagram for it) but I don't really follow on formal proofs. How should I know what to do? Do I use a let $x$ for $A$? or something else?",['elementary-set-theory']
1170174,Orbits of algebraic groups (dimension of connected components),"Let $X$ be an algebraic variety with algebraic group $G$ acting on it. Let $x\in X$. I am trying to prove that all connected components of the orbit $Gx$ are of dimension $\dim G - \dim G_x$, where $G_x = \{g\in G\,\,|\,\,gx=x\}$. Thank you in advance! Lemma I believe I need to use: Let $\pi:X\rightarrow Y$ be a dominant morphism, ie $\overline{\pi(X)} = Y$. Then any irreducible component of a fibre $\pi^{-1}(y)$, where $y\in Y$, has dimension at least $\dim X - \dim Y$. Moreover, there exists some nonempty open subset $O\subseteq Y$ such that $\dim\pi^{-1}(O) = \dim X -\dim Y$. Some progress: I have shown that $Gx$ is a locally closed subvariety. It is the image of the morphism $\phi_x:G\rightarrow X$ where $g\mapsto gx$, thus a union of locally closed sets. Therefore it contains a subset $U$ which is dense and open in $\overline{Gx}$. Since the set GU = $\bigcap_{g\in G} gU$ is contained in $Gx$, but invariant under $G$ we have $Gx = GU$, which is open in $\overline{Gx}$. The problem is that I am not really sure what the connected components are, so I don't know what to apply the lemma to.","['algebraic-geometry', 'representation-theory']"
1170190,$A ⊂ B$ if and only if $A − B = ∅$,"I need to prove that $A ⊂ B$ if and only if $A − B = ∅$.
I have the following ""proof"": $$ A \subset B \iff A - B = \emptyset$$
proof for $\implies:$ $$\forall x \in A, x \in B$$ Therefore, $$A - B = \emptyset$$ proof for $\impliedby$: If $$A - B = \emptyset$$
then
$$\forall x \in B, x \in A$$
since $\forall x \in B, x \in A$, $$ A \subset B $$ However the whole thing seems to be incredibly ""fragile"" and relies on circular logic (see how I just switched the sets in the for all statements) Is this a valid proof? Is there a better way to write it?","['proof-writing', 'elementary-set-theory', 'proof-verification']"
1170193,Other integral related to Ahmed's integral,"I have a doubt regarding the evaluation of the following integral : $$
\int_0^\frac{1}{\sqrt{5}} \frac{\tan^{-1}\left({\sqrt{(1 + x^2)/2}}\right)}
{(1 + 3x^2)\sqrt{1 + x^2}}\,du = \frac{\pi^2\sqrt{2}}{60}.
$$ Could anybody please help by offering useful hints or solutions? I think very difficult to prove.","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
1170199,"Proof of Alternate, Corresponding and Co-interior Angles","During school our teacher always explains the proof for all theorems even simple ones such as why does the angles in a triangle of add up to $180$ and they all involve alternate, corresponding or co-interior angles. However it has never occurred to me that he never shown the proof of how are alternate angles are equal. Could any explain the proof for alternate, corresponding and co-interior angles?",['geometry']
1170209,"Is $\mathbb{Z}$ the only totally-ordered PID that is ""special""?","(All my rings are commutative and unital.) Definition. Call a totally-ordered ring $R$ special iff for all non-zero $b \in R,$ every coset of $bR$ has a unique element in the interval $[0,|b|).$ Motivation. This means that for any non-trivial principal ideal $bR$ of $R$, we have a natural bijective correspondence between $R/bR$ and $[0,|b|)$. We can, for example, use this to find the cardinality of $R/bR$. Examples. The totally-ordered ring $\mathbb{Z}$. Hence $\mathbb{Z}/a\mathbb{Z}$ has the same cardinality as $[0,|a|),$ for all non-zero $a$. Hence $|\mathbb{Z}/a\mathbb{Z}|=|a|,$ for all non-zero $a$. In fact, this is the only example I can think of. Mini-question: what are some other examples of totally-ordered rings that are special? Question. Is $\mathbb{Z}$ is the only totally ordered PID that is special?","['commutative-algebra', 'integers', 'abstract-algebra']"
1170216,Random variables with equal joint distributions have equal marginal distributions?,"We are given two vectors $X=(X_1,X_2, . . . ,X_n)$ and $Y=(Y_1, Y_2, . . . , Y_n)$ with equal joint distributions. Do their marginal distributions $P_{X_i}$ and $ P_{Y_i}$ have to be equal? I have no idea so far how to approach this problem. I'm sure there is a simple counterexample with a small $n$. I suppose I should look for dependent random variables. Could you help me a bit?","['probability-distributions', 'probability']"
1170237,Equivalence of another formula for the number of $r$-combinations with repetition allowed,"Basically it means choosing r things out of n, where order doesn't matter, and you are allowed to pick a thing more than once. For example, $\{1, 1, 2\}$ out of $\{1, 2, 3, 4\}$. I managed to find another solution: $$
{n \choose r} + (r-1){n \choose r-1} + (r-2){n \choose r-2} + \cdots + {n \choose 1}
$$ I am having trouble proving that these two are equivalent.",['combinatorics']
1170247,Finding range of $f(x) = \sin^4 x\tan x + \cos^4 x\cot x$,"I got to a certain step and couldn't continue. I can't fully understand the provided solution... $$ f(x) = {\sin^6x+\cos^6x \over \sin x \cos x} = {2-1.5\sin^2 2x \over \sin 2x}$$ Let$$ t=\sin2x, t \neq 0$$
$$ f(x) = g(t) = {2 \over t} - {3t \over 2}$$ I don't get the next part. Since $$\frac2t\ \text{and}\ -\frac{3t}2$$
are both decreasing on $$[-1,0)\cup(0,1]$$
The range of $g(t)$ is $$(-\infty , -0.5]\cup[0.5,+\infty)$$ which is the range of $f(x)$. Any explanation would be greatly appreciated.","['trigonometry', 'functions']"
1170280,Proof of the tower property for conditional expectations,"Let $Z$ be a $\mathfrak{F}$-measurable random variable with $\mathbb E(|Z|)<\infty$ and let $\mathfrak{H}\subset \mathfrak{G}\subset \mathfrak{F}$. Show that then $\mathbb E(\mathbb E(Z|\mathfrak{G})|\mathfrak{H})=\mathbb E(Z|\mathfrak{H})=\mathbb E(\mathbb E(Z|\mathfrak{H})|\mathfrak{G})$. The second equality is clear to me since the random variable $E(Z|\mathfrak{H})$ is $\mathfrak{H}$-measurable, hence its also $\mathfrak{G}$-measurable, so we can take it out. If I want to prove the first equality I have to show that $E(Z|\mathfrak{G})$ and $Z$ do agree on $\mathfrak{H}$-measurable sets, right? Because I have to show that $Z$ and $\mathbb E(Z|\mathfrak{G})$ are equal if I condition both with the sigma algebra $\mathfrak{H}$. Is this argumentation correct? For the proof: $\int_\Omega\mathbb E(Z|\mathfrak{G})\mathbb 1_HdP=\int_\Omega Z\mathbb 1_H$ just because $E(Z|\mathfrak{G})$ is $\mathfrak{H}$ measurable, hence ""I can remove one $\mathbb E$ and $\mathfrak{G}$ and still have equality"". I know I wrought much for a simple task, but I just want to understand it correctly, thanks :)","['probability-theory', 'conditional-expectation']"
1170282,What is the way of integrating $\dfrac{-e^x\sin x}{e^x+1}$?,Integrating $\dfrac{-e^x\sin x}{e^x+1}$. This is needed for me to solve an ODE. The issue is that I also need to figure out how to integrate $\dfrac{e^x\cos x}{e^x+1}$ so maybe this will give me a hint. Any assistance will be appriciated!,"['ordinary-differential-equations', 'integration']"
1170287,$\mu$ test for convergence of improper integral of first kind,"While going through an Indian text on Analysis I found a test for convergence of improper integral. It was stated without proof. I tried to prove it...then some doubts pop up... Statement is this: Let $f(x)$ be bounded and integrable in every closed subinterval of $ (a,\infty)$ , where $a >0$ . Let $\mu$ be a positive number  such that $\lim_{x \rightarrow \infty} x^{\mu}f(x)$ exists. If $\mu > 1 $ , then $\int_{a}^{\infty} f(x)dx$ converges. If $ \mu \leq 1 $ , then $\int_{a}^{\infty} f(x)dx$ diverges. My proof: $\lim_{x \rightarrow \infty} x^{\mu}f(x) =L $ then for suitable $\epsilon >0$ we will get $x_{0} $ such that $(-L+\epsilon)< |x|^{\mu}|f(x)| < (L- \epsilon)$ for $x>x_{0}$ . This will lead to to $|f(x)| < (L- \epsilon)|x|^{-\mu}$ then using comparison test we will get as $\mu$ >1 $\int_{a}^{\infty} f(x)dx$ converges absolutely. But this proof cannot be used for discussing divergence. Even though we use left inequality $|x|^{-\mu}(-L+\epsilon)< |f(x)|$ . There are two problems I felt. One is comparison test is applicable for positive functions. $|x|^{-\mu}(-L+\epsilon)$ need not be positive. Can we solve this problem  by taking out $(-L+\epsilon)$ ? Second problem is this: Even though we got for $\mu \leq 1$ this integral diverge  by comparison test we get $\int_{a}^{\infty} |f(x)|dx$ diverges. It does not lead to the divergence of improper integral as stated by theorem.","['improper-integrals', 'real-analysis']"
1170303,Why does this converge to $\|x\|$,"Take $h_n(x) = x^{1+ \frac{1}{2n-1}}$ on the set $[-1,1]$ Then if we take $\lim_{n \to \infty} h_n(x)$ shouldn't this converge to $x$ seeing as $$\lim_{n \to \infty} h_n(x) = x \lim_{n \to \infty} x^{\frac{1}{2n-1}} = x?$$",['limits']
1170315,"question concerning a proof in Liu's ""Algebraic Geometry and Arithmetic Curves""","I'm following the proof of Prop. 4.4., Chapter 7.4. Liu-Algebraic Geometry and Arithmetic Curves: $\textbf{Proposition 4.4.}$ Let $X$ be a smooth, geometrically connected, projective curve over a field $k$ of genus $g$. Let $\mathcal{L}$ be an invertible sheaf on X.
  (a) If $\text{deg}\mathcal{L}\geq2g$, then $\mathcal{L}$ is generated by its global sections. The proof goes as follows: We may suppose that $k$ is algebraically closed, and $\mathcal{O}_X(D)\simeq \mathcal{L}$ for a divisor $D$ on $X$. We then can show that 
\begin{equation}l(D-E)=l(D)-\text{deg}E  \end{equation}
for all effective divisors $E$ such that $\text{deg}E\leq 1$. Liu then mentions that $\mathbf{\text{in particular, }l(D)\neq 0\text{, so by linear equivalence } D\geq 0}$ . The claim should then follow by Lemma 4.2., so I follow its proof applied to my problem to deduce the claim: For all closed points $x\in X$, we should have $\mathcal{O}_X(D-x)_x=\mathfrak{m}_x\mathcal{O}_X(D)_x$. Further, since all closed $x\in X$ are effective divisor of degree 1, we have $l(D-x)<l(D)$. Consequently, we find an $s\in H^0(X,\mathcal{O}(D))\setminus H^0(X,\mathcal{O}(D-x))$. Thus, $s_x\notin \mathcal{O}_X(D-x)_x$ so $s_x$ is a generator of $\mathcal{O}(D)_x$. $\textbf{My question}$: Where do I need the information $D\geq 0$ that Liu was deducing in the proof of the proposition? $\textbf{Lemma 4.2. }$ Let $X$ be a projective curve over a field $k$ and let $D$ be an effective divisor on $X$ with support in the regular locus of $X$. Then $\mathcal{O}_X(D)$ is generated by its global sections iff for any $x\in \text{supp}(D)$, we have $l(D-x)<l(D)$. Thank you very much for all help!!!",['algebraic-geometry']
1170328,$X'=AX$ with $\det A=0$ - Plane solutions,"Let $A$ be a $3\times3$ real matrix with $\det A=0$, we consider the system of differential equations defined by $X'=AX$. How can I show that each solution is contained in a plane ? What I have so far : $\det A=0\Rightarrow$ there are constant solutions to $AX=0,X\neq0$. Let $\lambda_0$ be the eigenvalue for $0$ and $E_0$ the set of associated eigenvectors. If $A=0$, it's clear. If $A\neq0$: if $\dim E_0=1:E_0=span(X_0)$. If we were in $\Bbb{C}$, we could say that there are two more eigenvalues $\lambda_1,\lambda_2$ and thus the solutions of $X'=AX$ would be $c_0E_0+c_1E_{\lambda_1}e^{\lambda_1t}+c_2E_{\lambda_2}e^{\lambda_2t}$, which defines a plane. However, I doubt that by going back to $\Bbb{R}$ by taking the real part, that is still the equation of a plane. if $\dim E_0=2$ :  ?",['ordinary-differential-equations']
1170332,Show that Möbius transformation $S$ commute with $T$ if $S$ and $T$ have the same fixed point.,"Let $T$ be a Möbius Transformation such that $T$ is not the identity. Show that Möbius transformation $S$ commute with $T$ if $S$ and $T$ have the same fixed point. Here is what I know so far 1) if $T$ has fixed points says $z_1$ and $z_2$ then $S^{-1}TS$ has fixed point $S^{-1}(z_1)$ and $S^{-1}(z_2)$ 2) if $T$ is dilation then $0$ and $\infty$ are its only fixed point, but if $T$ is translation then only $\infty$ is its fixed point. Assume that $S$ and $T$ has the same fixed points $z_1$ and $z_2 $ then by 1) $S^{-1}TS$ and $T^{-1}ST$ have the same fixed point $S^{-1}(z_1)=T^{-1}(z_1)$ and $S^{-1}(z_2)=T^{-1}(z_2)$ I know that $T$ is not the identity, but I can't assume it is dilation or translation to use 2), because it can also be inverse, right? I wonder if anyone would please have me a hand from here.","['mobius-transformation', 'complex-analysis']"
1170354,Solving a second Order ODE of a catenary curve,"Given the second order ODE of a catenary curve
$$y''=a\sqrt{1+(y')^2}$$ With initial conditions $y(0)=0$ and $y'(0)=0$ The equation was first rewritten as $2y''y'''=2a^{2}y'y''$ and then dividing both sides by $$2y''$$ and letting $z=y'$ we would get the equation $$z''=a^2z$$ intital conditions $z(0)=0$ and $z'(0)=a$ I came across this question while i was reading the following article. http://www.emis.de/journals/BAMV/conten/vol12/juangil.pdf I couldn't fully understand what the article meant such as how did they form the Differential equation of the Caterny curve and how did they managed to solve the differential equation. Could anyone Please explain. Thanks",['ordinary-differential-equations']
1170372,"Find an analytic function that maps the angle $-\pi/4<\operatorname{arg}(z)<\pi/2$ onto the upper half plane so that $w(1-i)=2,w(i)=-1$, and $w(0)=0$","Find an analytic function that maps the angle $-\pi/4<\operatorname{arg}(z)<\pi/2$  onto the upper half plane so that $w(1-i)=2$, $w(i)=-1$ , and $w(0)=0$ I'm trying to use this formula $$\frac{w-w_1}{w-w_3 }\cdot\frac{w_2-w_3}{w_2-w_1 }=\frac{z-z_1}{z-z_3 }\cdot\frac{z_2-z_3}{z_2-z_1 }$$ so I got $$\frac{w-2}{w-0 }\cdot\frac{-1-0}{-1-2 }=\frac{z-1+i}{z-0 }\cdot \frac{i-0}{i-1+i }$$
$$\frac{w-2}{w }\cdot\frac{1}{3 }=\frac{iz-i-1}{z(2i-1) }$$ $$w-2=3w\cdot\frac{iz-i-1}{z(2i-1) }$$ $$w(1-3\cdot\frac{iz-i-1}{z(2i-1) })=2$$
$$w=\frac{2z(2i-1)}{2iz-z-3iz+3i+3}$$ $$w=\frac{4iz-2z}{-iz-z+3i+3}$$
$$w=\frac{4iz-2z}{(3-z)(1+i)}$$ In order for this to be analytic, $z$ must not be $3$, but the angle $-π/4<\operatorname{arg}(z)<π/2$ also include $3$. Now I follow the suggestion of GEdgar and tried the power of $z$. I know that $w=z^n$ always map the angle $\pi/n$ onto the upper half plane. In this problem my angle is between $\frac{-\pi}{4}$ and $\frac{\pi}{2}$ so the $arg(w)$ should be between $-n\pi/4$ and $n\pi/2$? and radius of $w$ is $r^n$ for $|z|=r$ Now plug into the function $w=z^n$ I got $$(1-i)^n=2$$ $$i^n =-1$$ $$0^n=0$$ The last equation work for any $n$, the second equation implies that $n=2$ but the first equation I solve for $n$ and got $n= \ln (\frac{2}{1-i})$ but $n$ is the real number, right? Actually, I don't have to worry about $n$ because $w=z^n$ is analytic for all $n$, but if this is true then why they have to give me $w(1-i)=2$, $w(i)=-1$ , and $w(0)=0$?",['complex-analysis']
1170383,Limit of a function of two variables,"This is a problem occurs to me when I was trying to find the limit of a function with two variables(if only it exists). Please help. When I have to show that the limit does not exist for some function. Then by showing along two paths have two different limits I can prove it since the functions with two variables have infinite number of directions of approach to the given point. So selecting the paths, should I only take the linear ones or can I take non linear paths also? As an example,consider the limit of $\frac{xy^3}{x^2+y^6}$ as $(x,y)$ goes to $(0,0)$
Then taking along $x$ axis I have the limit $0$.
Can I take $y=x^{1/3}$ which gives me the limit $1/2$ ? When I check the answer on some website it seems they haven't consider curved functions to find different limits. Please explain. Where am I wrong?","['multivariable-calculus', 'limits']"
1170407,Videogame (Dota 2) probability,"In Dota 2 after you launch a spell you usually have a cooldown time you need to wait before being able to launch that spell again. In the Year Beast Brawl anyway powerful beasts can have Refresher Aura: Refresher Aura: When an allied hero casts a spell within 900 range of the Beast,
that spell has a 50% chance to be instantly refreshed. Given that my hero has Refresher Aura active,the probability of having my spell instantly refreshed(no cooldown) $n$ times in a row is: $\frac{1}{2}^n$. Now my question is: What is the probability of having my spell instantly refreshed $n$ times in a row if I have Refresher Orb (Orb gives the ability to reset the cooldowns of all your items and abilities) given that Refresher Orb can be instantly refreshed by Refresher Aura too? Edit to make the question more clear: What is the probability of being able to cast the spell(Orb has no cooldown or spell has no cooldown or both have no cooldown) after $n$ consecutive spell casts?",['probability']
1170412,Show that $f:\mathbb{R}^2\to\mathbb{R}$ is constant.,"Let $f:\mathbb{R}^2\to\mathbb{R}$ such that $\left|f(x)-f(y)\right| \le \|x-y\|^2$ for every $x,y\in\mathbb{R}^2$. Show that $f$ is constant. So I think that if $f$ is constant then $\nabla f \equiv 0$. Let $(x_0, y_0) \in \mathbb{R}^2$. If $f$ is differentiable at this point then the following limit need to be zero: $$\lim_{(x,y)\to(x_0,y_0)} \left| \frac{f(x,y) - f(x_0,y_0) - \langle \nabla f,(x-x_0,y-y_0)\rangle}{\|(x-x_0,y-y_0)\|} \right| = 0$$ We know that: $$\lim_{(x,y)\to(x_0,y_0)} \left| \frac{f(x,y) - f(x_0,y_0) - \langle \nabla f,(x-x_0,y-y_0)\rangle}{\|(x-x_0,y-y_0)\|} \right| \le \lim_{(x,y)\to (x_0,y_0)} \left| \frac{\|(x-x_0,y-y_0)\|^2 - \langle \nabla f,(x-x_0,y-y_0)\rangle}{\|(x-x_0,y-y_0)\|} \right| $$ Where should I take it from here? I tried to develop it further but got stuck..","['multivariable-calculus', 'calculus', 'derivatives', 'limits']"
1170461,How many n-bit strings have at most m subsequent 0s?,"The title already is the complete question, but I would like to add some details to make clear what I mean. A $n$-bit string is an element of $\{0,1\}^n$. All possible 3-bit strings are: 0: 000 1: 001 2: 010 3: 011 4: 100 5: 101 6: 110 7: 111 As they can be encoded as binary numbers, there are $2^n$ $n$-bit strings. If I  want at most $m=1$ subsequent 0s, the allowed sequences are: 2: 010 3: 011 5: 101 6: 110 7: 111 Hence for $n=3, m=1$ the answer is 5. What is the answer for arbitrary $n \in \mathbb{N}$ and $m \in \{0, \dots, n\}$? What is the answer for $n=30, m=4$? Background of the question This is the background of my question. Is it not necessary to understand it / answer it. I have developed a symbol recognition application (see http://write-math.com ) and I am now thinking about different possibilities to extend it to formula recognition. One part of formula recognition is to recognize the single symbols. I get on-line data, that means I get the information how the symbol is written (in contrast to off-line data, where you only have pixels). My data is a list of strokes, where each stroke is a point. A point has x/y coordinates and a time: [[(x=12, y=21, t=0), (x=7, y=13, t=3), ((x=7, y= 21, t=5), ...],
 [(x=0, y=0, t=6)],
 [...], ...] Now I know that people always segment their symbols perfectly. That means a symbol can have multiple strokes, but one stroke always belongs to exactly one symbol. As I have one recognizer for symbols which works fairly well, it would be possible to simply use it to recognize multiple symbols by trying every possible segmentation. This can be modeled by taking a $n$-bit string for $n+1$ strokes. If a given bit is 0, then the neighboring strokes are connected: stroke1   stroke2   stroke3
        0         1

Stroke1 and stroke2 are connected, but separated from stroke3
Hence the first symbol has the first 2 strokes,
the second symbol has the last stroke I know that symbols with more than 4 strokes are very rare. So rare in fact, that I don't use any stroke after the 4th stroke for recognition. Hence I don't need to check $2^n$ segmentation, but less. My question is how many segementations I have to check.","['recreational-mathematics', 'combinatorics']"
1170536,Squaring Norms solved by Algebra,I found the following in a paper and am not sure how it is correct: $\Vert a - b \Vert^2$ was expanded to: $\Vert a \Vert^2 - 2a^Tb + \Vert b \Vert^2$ The paper was on gps location algorithms so $a$ and §b§ are and $\Vert a\Vert $ is the second norm of a My question is how this assertion can be made? I'm stuck on even multiplying out the terms individually to arrive at equalt roots: $\left((a_x+b_x)^2+(a_y+b_y)^2\right)^\frac{1}{2} = \left(a_x^2+a_y^2\right)^\frac{1}{2} +2 \left(a_xb_x+a_yb_y\right) +\left(b_x^2+b_y^2\right)^\frac{1}{2}$ Is this stamement correct? Additionally: What Can I do if i have more complex terms including matrices for rotation or the like.,"['normed-spaces', 'vectors', 'abstract-algebra']"
1170541,Riesz representation theorem in Sobolev spaces,"My question is about functionals on $W_{1,p}(\Omega)$ spaces, $\Omega$ is contained in $\mathbb R^n$ I am trying to figure out if there is a way to characterize all linear functionals on the above space. Is there any version of Riesz representation theorem in general Banach space?","['sobolev-spaces', 'riesz-representation-theorem', 'functional-analysis']"
1170559,Convergence types in probability theory : Counterexamples,I know that the following implications are true: $$\text{Almost sure convergence} \Rightarrow \text{ Convergence in probability } \Leftarrow \text{ Convergence in }L^p $$ $$\Downarrow$$ $$\text{Convergence in distribution}$$ I am looking for some (preferably easy) counterexamples for the converses of these implications.,"['convergence-divergence', 'examples-counterexamples', 'probability-theory', 'probability-distributions', 'lp-spaces']"
1170582,What are some areas of research/industry involving stochastic processes that aren't finance-related?,"I've always enjoyed probability and stochastic processes (took two courses in stochastic models in undergrad, and a PhD level intro to stochastic processes course for my master's). Someday I'd like to go back to school, and most likely I'll study applied probability/stochastic processes. Now, the vast majority of work in this area these days seems to be motivated by quantitative finance; while I have nothing against this field, it is not really what I'm interested in. I took a course in accounting and one in engineering economics and was bored out of my mind. Additionally, I still have no idea specifically what I want to research. This of course makes it hard to write a coherent personal statement for graduate school applications. I will be working for the next 3-4 years to pay off my loans, so I have some time to think about this. I work in revenue management, and the most interesting thing I've seen so far is a probabilistic overbooking model. That model isn't overly sophisticated but it's a cool example of using probability to maximize expected revenues. Any ideas on areas to research (and books/references) would be greatly appreciated!","['probability-theory', 'stochastic-processes', 'soft-question']"
1170602,Integral of root of $\sec x$,"How to evaluate the integral $$\int \sqrt{\sec x} \, dx$$ I read that its not defined. But why is it so ? Does it contradict some basic rules ?
Please clarify it .","['trigonometry', 'integration']"
1170627,Does every non empty open set has measure greater than zero?,"Is it true that every non-empty open set has Lebesgue measure greater than zero? I could think of a proof along the following lines but not sure if that would be right: Since every non-empty open set is a finite or countable union of open intervals where at least one open interval is nonempty, and since every nonempty open interval has measure greater than zero implies every nonempty open set has measure greater than zero. Is my reasoning sound?","['measure-theory', 'real-analysis']"
1170628,Markov Property Confusion,"I feel like I'm being very dense/employing some sort of circular reasoning, but I'm having trouble understanding the Markov Property.
According to Durrett (ISBN-10:1461436141), $X_n$ is a Markov chain with transition matrix $p(i,j)$ if for any $j, i, i_{n-1}, \ldots, i_0$:
$$P(X_{n+1}=j \mid X_n=i, X_{n-1}=i_{n-1}, \ldots, X_0=i_0)=p(i,j)$$ It seems to me that this property can never be satisfied. For example, suppose the transition matrix: \begin{array}{c|ccc}
  & a & b & c \\ \hline
a & 0 & 1 & 0 \\
b & 0.5 & 0 & 0.5 \\
c & 0 & 1 & 0 
\end{array} which is graphically represented as: $P(X_3=c \vert X_2=b, X_1=b)=0 \neq p(b,c)=0.5$.  I can similarly do this to any chain and have every probability be equal to $0$.
Is this because I'm conditioning on an event with 0 probability?  Or is it because I should be saying
$$\sum_{x \in \{a,b,c\}} P(X_3=c \mid X_2=b, X_1=x)=0.5=p(b,c)$$ Or am I just thinking about it completely wrong?","['stochastic-processes', 'markov-chains', 'markov-process', 'probability-theory', 'probability']"
1170630,Prove that $ \cos x - \cos y = -2 \sin ( \frac{x-y}{2} ) \sin ( \frac{x+y}{2} ) $,"Prove that $ \cos x - \cos y = -2 \sin \left( \frac{x-y}{2} \right) \sin \left( \frac{x+y}{2} \right) $ without knowing cos identity We don't know that $ \cos0 = 1 $ We don't know that $ \cos^2 x + \sin^2 x = 1 $ I have managed to prove it using the above facts, but just realised that I can't use them. Now I have been going in circles for a while. Any ideas how to prove this or even approach it? Thanks !",['trigonometry']
1170643,"If $P$ is a prime ideal of $R$, then $P[x]$ is a prime ideal of $R[x]$, for $R$ a commutative ring.","Prove that if $P$ is a prime ideal of $R$ then $P[x]$ is a prime ideal of $R[x]$ . This is homework. I have been trying to assume that there is an $fg$ in $P[x]$ such that neither $f$ nor $g$ is in $P[x]$ . Hence $f$ and $g$ have at least one coefficient not in $P$ . I was trying to show that $fg$ would then have a coefficient not in $P$ , obtaining a contradiction. But I don't see how to control the terms. If $f$ and $g$ had only one coefficient not in $P$ , then I think I could use the properties of the ideal to complete the proof. The problem is not being able to know for certain which if any of the coefficients of $f$ and $g$ are in $P$ . Perhaps my approach is wrong to begin. Please help. Even a hint in the right direction will much appreciated.","['commutative-algebra', 'ring-theory', 'abstract-algebra', 'polynomials']"
1170665,Dense subsets of an infinite set in the cofinite topology,"A subset $E \subset X$ of a topological space $X$ is dense if $\overline{E} = X$ where $$ \overline{E} = \bigcap \lbrace C \subseteq X \mid C \text{ is closed and } E \subseteq C \rbrace  $$ But in the cofinite topology closed sets are defined to be finite sets. So if $X$ is infinite and a subset $E$ is dense, then this would imply that $X$ (a infinite set) is the intersection of finite sets. Does this mean that $X$ endowed with the cofinite topology has no dense subsets?",['general-topology']
1170672,How to find the definite integral $\int_0^\infty \frac{x}{\sinh ax}\;dx$,I'm trying to prove that $$I:= \int_0^\infty \frac{x}{\sinh(ax)} dx = \frac{\pi^2}{4a^2}$$ Attempt: $$\sinh (ax) = \frac{1}{2}(e^{ax}-e^{-ax}) = \frac{1}{2}e^{-ax}(e^{2ax}-1)$$ Now I have $$\int_0^\infty \frac{x}{\sinh(ax)} dx = \int_0^\infty 2x \sum_{q=0}^\infty \frac{\frac{a^qx^q}{q!}}{e^{2ax}-1} dx$$. Substituting $y=2ax$ I get: $$I= \frac{1}{2a^2} \sum_{q=0}^\infty \frac{1}{2^qq!} \int_0^\infty \frac{y^{q+1}}{e^y-1}dy=\frac{1}{2a^2} \sum_{q=0}^\infty \frac{1}{2^qq!} \Gamma(q+2) \zeta(q+2)$$ Am I on the right way? What is with the infinite series; why it must have the value $\frac{\pi^2}{2}$? Every hints will be highly appreciated.,"['definite-integrals', 'calculus', 'integration', 'real-analysis']"
1170775,Simple Finite Continued Fraction,"I am working on my senior thesis and have encountered, unexpectedly, a finite continued fraction that I would be interested in resolving. I already know the answer (by an informed guess based on where the problem came from) but I was hoping that there was a less magic solution. Unfortunately, my web searches turned up very little on continued fractions of the finite variety, so I was hoping that someone might be able to help me or at least point me toward some theory. Anyway, the problem is probably about as simple as one could hope for in this area: given an indeterminate $\lambda$, what are the roots of
$$\lambda + \frac{1}{\lambda+\frac{1}{\lambda+\frac{1}{\cdots\,\lambda}}}$$
where there are $n$-many $\lambda$s in the expression? EDIT: Some combinatorial considerations show that the numerator of this expression is
$$\sum_k \binom{n-k}{k}\lambda^{n-2k}.$$ I know that the roots of this are all the numbers of the form $2i\cos\frac{k\pi}{n+1}$ for $1\leq k\leq n$, but only because of that magic guess from above.","['rational-functions', 'algebra-precalculus', 'continued-fractions']"
1170779,Factoring algebraic expressions of three variables,"I want to factor $$bc^2+ab^2+a^2c-b^2c-ac^2-a^2b$$ Using Wolfram, I know it's factored into $$-(a-b)(a-c)(b-c) = (b-a)(a-c)(b-c)$$ However, I don't think I ever got taught how to simplify such expression by hand. What's the general methodology for this? Is there any mental-tool that could be used to do this without the experience to spot factors by sight?","['factoring', 'algebra-precalculus']"
1170803,Norm of adjoint,"Assume we have 2 injective continuous operators with dense images $A$ and $B$ on a Hilbert space $\mathbb H$ and $B$ is self adjoint. Further let there be constants $a_1$ and $a_2$ such that- $a_1\|Bu\| \leq \|Au\| \leq a_2\|Bu\|$ for all $u \in \mathbb H$. Can we show that for $A^{*}$, the adjoint of $A$, we have - $a_1\|Bu\| \leq \|A^{*}u\| \leq a_2\|Bu\|$ for all $u \in \mathbb H$. This is obviously true when $A$ is normal. Is it true for non normal operators?",['functional-analysis']
1170843,Solving $Ax=b$ when $x$ and $b$ are given.,"I am trying to study least square and linear regression and I understand the solution for $Ax = b$ when x is the unknown and the LS solution is given by $(A^TA)^{-1}A^TA$. Now, I was wondering if something similar exists when A is unknown. I was wondering if I do the corresponding: $$
Ax=b
$$
$$
x^TA^T = b
$$ Therefore, $A^T = (xx^T)^{-1}xb$ or $A = b^Tx^T ((xx^T)^{-1})^T$","['matrices', 'linear-algebra', 'least-squares']"
1170853,Measurable sets whose sum is not measurable.,"I'm looking for two measurable sets in $\Bbb{R}^2$ st their sum is not measurable. I found the example , let $A\subset \Bbb{R}$ be a non-measurable set in $\Bbb{R}$ and consider the sets $A\times \{0\}$ and $\{0\}\times \mathbb R$, these both sets have measure zero in $\Bbb{R}^2$ but their sum $A\times \mathbb R$ is non measurable in $\Bbb{R}^2$. My question is why is $A\times \mathbb R$ non measurable in $\Bbb{R}^2$?","['measure-theory', 'lebesgue-measure', 'measurable-sets']"
1170886,How to comprehend $E(X) = \int_0^\infty {P(X > x)dx} $ and $E(X) = \sum\limits_{n = 1}^\infty {P\{ X \ge n\} }$ for positive variable $X$?,"Suppose $X$ is an integrable, positive random variable. Then, if $X$ is arithmetic, we have $E(X) = \sum\limits_{n = 1}^\infty  {P\{ X \ge n\} }$
and if $X$ is continuous, we have $E(X) = \int_0^\infty  {P(X > x)dx} $. How to understand these two formulas intuitively?","['probability-theory', 'probability', 'expectation']"
1170887,Trying to find function that defines a parabolic surface,"Say we are working in three dimensions and we have a function $u_1(x, y) = x^2$. Ie. this is just the regular $x^2$ parabola except it's now defined all along the way $y$-axis and forms a surface. Say we also have a function $u_2(x, y) = y^2$. Ie. this is just the regular $y^2$ parabola except it's now defined all along the way $x$-axis and forms a surface. ...now where I'm going with this is that I would like to be able to define $u_3(x,y)$ such that it is the 'same kind of parabola' except instead being on the $y$-axis or the $x$-axis it is now defined on the vector $(1,1)$...Ie. one of the above surface 'rotated' 45 degrees about the $z$ axis. What would be the equation for $u(x,y)$ in this case?","['geometry', 'multivariable-calculus']"
1170896,How to solve $x'=x^2$?,"I need this in order to solve a PDE. How does one solve $X'(s)=X(s)^2?$ where $X(0)=x_0$. Does it involve cosines/sin? I tried use to $e$, but I don't think it works.",['ordinary-differential-equations']
1170925,Confused by a proof about harmonic numbers,"I've been puzzled by a step in D'Aurizio's proof concerning the finiteness of a certain subset $J_p$ of $\mathbf{N}$: $$J_p = \{n : p \text{ divides the numerator of } H_n\}.$$ 
His paper is here: http://arxiv.org/abs/1102.0765 . [Note that he refers to $J_p$ unconventionally as $M_p$; everybody, including all the papers he cites, calls this set $J_p$.] A lemma from within reads Lemma 2. If $a$, $b$, $c$ are three distinct elements of $J_p$ with $a < b$ and $c - b \equiv 0$ (mod $p$) then $$c - b + a \in J_p.$$ Immediately after the proof of the lemma, the argument becomes hard to follow: Let us suppose, now, that $J_p$ is infinite. Then at least one residue class in $J_p/(p^2-p)$ is infinite; let $a$ be the smallest positive integer in such a class es . $p^2-p$ belongs to $J_p$, so, by Lemma 2, we have that $$a + (p^2-p)\mathbf{N} \subseteq J_p\tag{1}$$
  holds, and by applying Lemma 2 again, $$(p^2-p)\mathbf{N}\subseteq J_p.\tag{2}$$ Let's pick this apart. An infinite subset of $\mathbf{Z}$ modulo any nonzero integer will split into finitely many classes, so they can't all be finite. Thus, at least one residue class of $J_p$ modulo $p^2-p$ is infinite: pick one such class and call it $S$. Let $a = \min S$. The fact that $p^2 - p$ belongs to $J_p$ is a theorem of Eswarathasan and Levine. So far, so good. Questions. Why is (1) true? How does (2) follow from (1)?","['harmonic-numbers', 'proof-verification', 'number-theory']"
1170945,Stochastic control with stopping times,"Given a wealth process that evolves as
$$d w_t = r w_t dt + \theta_t ( \sigma dW_t + (\mu-r) dt) - c_t dt.$$
and smooth functions $u,F: [0, +\infty) \rightarrow \mathbb{R}$,
how can we optimise the following: $$V(w) = \sup_{c \geq 0, \, \theta, \, \tau} \mathbb{E} \bigg[ \int_0^{\tau} e^{- \rho t} u (c_t) dt + e^{-\rho \tau} F(w_{\tau}) \bigg| w_0 =w \bigg],$$
where $\tau$ is a stopping time. The traditional method of using the HJB and martingale principle of optimal control does not seem to work in this case, when stopping time is involved. Any suggestions on how to optimise this?","['probability-theory', 'martingales', 'finance', 'control-theory']"
1170958,Smooth manifolds and cartesian products,"So assume you have two smooth maps $f:M\rightarrow N$ and $g:P\rightarrow Q$. If we define the map $f\times g:M\times P\rightarrow N\times Q$ to be such that $(f\times g)(x,y)=(f(x),g(y))$. Does it follow that such a map is smooth?","['differential-topology', 'smooth-manifolds', 'real-analysis', 'analysis']"
1170966,Open balls in euclidean space are homeomorphic to the whole space,"The following question is from Fred H. Croom's book ""Principles of Topology"" Prove that each open ball $B(a,r), a\in \mathbb{R}^n, r>0$, considered as a subspace of $\mathbb{R}^n$, is homeomorphic to $\mathbb{R}^n$. After much studying, I concluded the first way to approach this problem would be by showing that the unit open ball $B(\theta,1)$ with center and radius 1 is homeomorphic to $\mathbb{R}^n$. Afterwards, show how any open ball $B(a,r)$ is topologically equivalent to $B(\theta,1)$, thus ending my proof. However, I am having a hard time showing that $B(\theta,1)$ is homeomorphic to $\mathbb{R}^n$. Any suggestions? I want to thank you for taking the time to read this question. I greatly appreciate any assistance you provide.","['general-topology', 'metric-spaces']"
1171002,Prove $k^2>k+1$ by induction,"How would you prove that: $$n^2>n+1 \text{   for   }  n\ge2$$ using induction? Progress The base is clear, and after that I have assumed $n=k$ and I am trying to prove $(k+1)^2>k+2$ , but I get stuck on proving $k^2>k+2$","['inequality', 'induction', 'discrete-mathematics']"
1171041,"``Minimal generating ring"" for a field of fractions","In this answer and the linked MathOverflow post, it's shown that any field $F$ of characteristic zero contains a proper subring $A$ such that $F$ is the field of fractions of $A$. However, there is often more than one such $A$. For example, $\mathbb{Q}$ is the field of fractions of $\mathbb{Z}$, $\mathbb{Z}[1/2]$, $\mathbb{Z}[3/8]$, etc. But in some sense, $\mathbb{Z}$ is the ""true"" subring of $\mathbb{Q}$ that generates $\mathbb{Q}$ as a field of fractions. In particular, $\mathbb{Z} \subset \mathbb{Z}[1/2]$ and $\mathbb{Z} \subset \mathbb{Z}[3/8]$. So my question: for any field $F$ of char zero, is there a minimal proper subring $A \subset F$ such that $F$ is the field of fractions of $A$? Where minimal means that if $A$ and $B$ are proper subrings of $F$ whose fields of fractions are $F$, and if $A$ is minimal, then $A\subset B$.","['commutative-algebra', 'abstract-algebra', 'field-theory']"
1171063,(product of) uniformly convergent functions and pointwise convergence,"Consider 2 sequences of real functions on $I \subset \Bbb R$: $f_n \to f$ and $g_n \to g$ uniformly. Need to prove that $f_ng_n \to fg$ pointwise on $I$ From definition I know that $\forall \epsilon > 0, \exists N, M \in \Bbb N$ such that $\forall n \ge N, \forall m \ge M, \vert f_n(x)-f(x) \vert < \epsilon$ and $\vert g_n(x)-g(x) \vert < \epsilon$ for all $x \in I$ How should I proceed from here? Thanks (Aside: I've found out that apparently it's not generally true that $f_ng_n$ is uniformly convergent)","['functions', 'convergence-divergence', 'real-analysis']"
1171121,The canonical height of a point on an elliptic curve,"I am struggling with exercise 3.3 in Silverman-Tate Rational Points on Elliptic Curves . Here is the paraphrased problem with necessary background: Let $C:y^2 = x^3 + a x + b$ be a nonsingular cubic and let $P=(x,y)\in C(\mathbb{Q})$ be a rational point on the curve. We define the height $h (P)$ of $P$ to be $h (P) = \log\max\left\{ \left\vert m \right\vert , \left\vert n \right\vert \right\}$ where $x = m/n$ is in lowest terms. Prove that the limit
$$\hat{h} (P) = \lim_{n\rightarrow \infty} \frac{h(2^n P)}{4^n}$$
exists (this is the canonical height of $P$). My attempt is to prove the sequence $a_n = 4^{-n} h(2^n P)$ is Cauchy, so take $m,n\in\mathbb{N}$ and WLOG assume $m\leq n$. We proved in the text that for any point $P_0 \in C(\mathbb{Q})$ there exists a constant $\kappa_0 = \kappa_0 (P_0, a, b)$ such that for all points $Q\in C(\mathbb{Q})$ we have a bound $h(Q+P_0) \leq 2 h(Q) + \kappa_0$. Using this idea we can bound the height of $2^n P$ in terms of $2^m P$ by splitting up $2^n P$ as a sum of terms of the form $2^r P$, where $r$ decreases from $n$ to $m$. This introduces new constants $\kappa_r$ but since there are only finitely many of them we can take a maximum and not be too hindered: $$h(2^n P)=h(2^{n-1}P + 2^{n-1} P)\leq 2 h(2^{n-1} P) + \kappa_0 = 2 h(2^{n-2}P + 2^{n-2} P) + \kappa_0$$
$$\leq 4 h(2^{n-2} P) + 2 \kappa_1 + \kappa_0 \leq \dots$$ $$\dots\leq 2^{n-m} h (2^m P) + \sum_{r=0}^{n-m-1} 2^r \kappa_r$$ Set $\kappa^* = \max\left\{\kappa_r : 0\leq r \leq n-m-1\right\}$. (Note that $\kappa^*$ depends on $m$ and $n$.) Then we have $$h (2^n P)\leq 2^{n-m} h(2^m P) + (2^{n-m}-1)\kappa^*$$ Therefore $$ a_n - a_m \leq \frac{2^{-m} - 2^{- n}}{2^n} (h(2^m P)+\kappa^*)$$ We also proved in the chapter that there exists a constant $\mu=\mu(a,b)$ ( not depending on $P$) such that $h(2 P)\geq 4 h(P) - \mu$. If we then apply this to bound $h(2^n P)$ from below in terms of $h(2^m P)$ and $\mu$, we obtain a similar recurrence as above, which (assuming I have calculated correctly) gives $$h(2^n P)\geq 4^{n-m} h (2^m P) - \frac{4^{n-m}-1}{3} \mu$$ Therefore we have the bounds $$-\frac{4^{-m}-4^{-n}}{3}\mu \leq a_n - a_m \leq \frac{2^{-m} - 2^{ -n}}{2^n} (h(2^m P)+ \kappa^*)$$ So
$$\left\vert a_n - a_m \right\vert \leq \max\left\{ \left\vert \frac{4^{-m}-4^{-n}}{3} \mu \right\vert , \left\vert \frac{2^{-m} - 2^{ -n}}{2^n} (h(2^m P)+ \kappa^*) \right\vert \right\}$$ $$ \leq (4^{-m} - 4^{-n}) \max\left\{ \frac{\left\vert \mu\right\vert }{3} , \left\vert h(2^m P)+ \kappa^* \right\vert \right\}$$ But I don't know where to go from here since I don't know what happens to  $h(2^m P) + \kappa^*$ as $m,n\rightarrow\infty$, because $\kappa^*$ depends on $n$. We could of course apply the same procedure to $h(2^m P)$ to bound it above in terms of $h(P)$ and terms depending on $m$ and $n$, but I have not found this to be particularly helpful. Can anyone help me on this? Thanks in advance!","['self-learning', 'sequences-and-series', 'elliptic-curves', 'number-theory']"
1171142,"$X$ compact Hausdorff space, characterize the maximal ideals of $C(X)$","I know this question has been asked before, but I think I'm very close to a new solution and wanted to know if it is a viable approach. Let $C(X)$ be the ring of continuous functions $X \rightarrow \mathbb{C}$ where $X$ is compact Hausdorff, and let $\mathfrak M$ be a maximal ideal.  We want to show that $\mathfrak M = I_{x_0} = \{ f \in C(X) : f(x_0) = 0\}$ for some $x_0$. For each nonempty closed set $A$, we define the ideal $I_A = \{ f \in C(X) : f(x) = 0, \forall x \in A\}$.  Clearly $A \subset B$ implies $I_B \subset I_A$ (I also need to show that $I_B \subseteq I_A$ implies $A \subseteq B$, which I haven't done yet).  We let $\mathcal S$ be the set of ideals $I_A$ which are contained in $\mathfrak M$ . An ascending chain $I_{A_i} \in \mathcal S$ corresponds to a descending chain of closed sets $A_i$, whose intersection is nonempty because $X$ is compact.  Thus the union $J$ of the chain $I_{A_i}$ is an ideal which is contained in $I_{\bigcap A_i}$ (now we have to show that $I_{\bigcap A_i} \subseteq \mathfrak M$ to show that it is an upper bound for the chain, I haven't been able to do this). So by Zorn's Lemma, $\mathcal S$ has a maximal element $I_D$ for some nonempty closed set $D$.  Now, I just want to show that $D$ is a singleton set $\{x_0\}$; then $I_D$ is a maximal ideal contained in $\mathfrak M$, whence $I_D = \mathfrak M$.  That will finish the proof. Edit: Assuming I can fix the holes, I finished the problem (answered below). Current problems with the proof: (i) Need to show that $I_B \subseteq I_A$ implies $A \subseteq B$. (ii) Need to finish the Zorn's lemma argument by showing that $I_{\bigcap\limits_i A_i} \subseteq \mathfrak M$. Second edit: (i) follows from the Urysohn lemma.  A compact Hausdorff space is normal.  If $x \in A$, but not in $B$, then $\{x\}$ and $B$ are disjoint closed sets, so by Urysohn there exists a continuous function $f: X \rightarrow [0,1] \subseteq \mathbb{C}$ for which $f(x) = 1$ and $f(b) = 0$ for all $b \in B$.  Thus $f \in I_B$, but not in $I_A$.  So there is only one hole in the proof left. Third edit: (ii) also follows from the Urysohn lemma. See the edited answer for details.","['commutative-algebra', 'functional-analysis', 'alternative-proof']"
1171172,Calculate limit for continuous function,"I am having trouble with this question: if f(x) is a continous function and $$ 1 - x^2 \leq f(x) \leq e^x $$ for all values of x, calculate $$ \lim_{x\to0} f(x) $$. Do I have to calculate the limit on both sides of $f(x)$? How would I got about solving this?","['calculus', 'continuity', 'limits']"
1171184,Why doesn't $\sum_{n=1}^\infty \frac{1}{n^{1+\frac{1}{n}}}$ converge?,$\sum_{n=1}^\infty \frac{1}{n^{1+\frac{1}{n}}} = \infty$. Is there a comparison that works well to prove this?,"['divergent-series', 'sequences-and-series', 'analysis']"
1171185,How long does it take the average voter to vote?,"So I was helping my brother with his homework question as follows The voting office can handle $50 \space \text {voters/hour}$ and has 20 voting stations. How long does it take the average voter to vote? He answered saying there are $60$ minutes for each machine, so $60 \space \text   {minutes} \times 20 \space \text {machines} = 1200 \space \text {total voting minutes/ hour}$. Therefore there are $$= \frac {1200 \space \text {minutes}}{50 \text {votes}}$$ $$=24 \text {minutes/vote}$$ I can tell that the answer is wrong because $24$ minutes is too long for one person to vote. My answer is that since there $60$ minutes in an hour, and $50$ votes per hour then $$\frac {60}{50}$$ $$=1.2 \text {minutes}$$ I am not really sure why my brother's answer is incorrect; his method seems correct but is probably overcounting somehow. Any insight on the problem is appreciated",['algebra-precalculus']
1171245,Explaining that $1 \cdot 3 \cdot 5 \dotsm (2n+1) = 1 \cdot 3 \cdot 5 \dotsm (2n-1)(2n+1)$,"I have a few students that are having trouble understanding that
$$1 \cdot 3 \cdot 5 \dotsm (2n+1) = 1 \cdot 3 \cdot 5 \dotsm (2n-1)(2n+1),$$
specifically that
$$\frac{1 \cdot 3 \cdot 5 \dotsm (2n+1)}{1 \cdot 3 \cdot 5 \dotsm (2n-1)} = 2n+1.$$
I've tried explaining it a few different ways, but it didn't seem to go over very well.  What would be a good way to explain this?","['education', 'algebra-precalculus']"
1171293,$\text{Prove }\prod_{i=1}^\infty(1+a_i) \text{ converges } \iff \sum_{n=1}^\infty a_n \text{ converges}$,Let $a_i \ge 0$ $$\text{Prove }\prod_{i=1}^\infty(1+a_i) \text{ converges } \iff \sum_{n=1}^\infty a_n \text{ converges}$$ I've got to this step $$\prod_{i=1}^\infty (1+a_i) = e^{\sum_{i=1}^\infty \ln(1+a_i)}$$ but I'm not sure how to proceed,"['convergence-divergence', 'infinite-product', 'analysis']"
1171307,Contractive condition implies the sequence is Cauchy,"$a_n$ is a sequence that satisfies the following contractive condition; $|a_{n+2}-a_{n+1}| \le c|a_{n+1}-a_n|, n\ge 1 $ for some $ 0 \lt c \lt 1.$
Show the sequence $a_n$ is a Cauchy sequence and converges. Consider the sequence $x_n$ given by $x_1=2$ and $x_{n+1} = 2+ \frac{1}{x_n}$ Show that $x_n$ is bounded below by 2 Show that $x_n$ satisfies the contractive condition in the first part and converges Find lim $x_n$ Not looking for the answers. Just strong hints to guide me to the answer.
The first part of the problem itself, makes sense. I'm unsure on the steps needed to prove this though.
The second part for (1), would I want to use induction to show that it keeps getting closer to 2 but never reaches it. For part (2), I may be way off, but as simple as plugging into the contractive condition above? I am confused on part 3. A lot here, I appreciate any sort of help. Thanks","['cauchy-sequences', 'sequences-and-series', 'real-analysis', 'limits']"
1171310,$ \lim_\limits{n \to \infty}{\frac{10^n+n^2}{n!}} $,$$ \lim_\limits{n \to \infty}{\frac{10^n+n^2}{n!}} $$ Any hints on how to take on this limit? I do not know how to deal with the factorial in the denominator.,['limits']
1171316,Why hasn't the median function made the mean (effectively) obsolete?,"I've learned in my AP statistics class that means can really only be used on nearly-normal distributions, but I know that many studies, experiments, etc. don't always give that perfect normal curve that one might find on a histogram. Why use medians? To my knowledge medians are a good averaging function because they are able to eliminate outliers. Consider finding the averages of the amount of money a person makes in a career. Typically, the curve would be skewed and there would be leveraging points (such as the high amount of money people with executive positions in a career would be making). Point: Medians are Means I've noticed that as a data-set becomes more and more normal, or 'better' suited for the use of a mean, the median approaches the value of the mean. If the median takes care of outliers and skewed data and embodies the value of the mean when it meets the 'conditions' of the mean, Why isn't the median always favored over the mean? (especially with the influx of computer based averaging solutions that would effectively eliminate the issue of efficiency of calculation for either averaging function)","['statistics', 'means', 'median']"
1171373,Prove $\frac{a}c = \frac{a-b}{b-c}$,"Suppose  $\frac{1}a,\frac{1}b,\frac{1}c$ are three consecutive terms in an arithmetic sequence. Show that: $$\frac{a}c = \frac{a-b}{b-c} $$ and that: $$\frac{2ac}{a+c} = b$$
How would I prove this?",['algebra-precalculus']
1171393,Definition of connection on vector bundle,"A connection on a vector bundle $E$ is a map $ D:\Gamma(E)\rightarrow \Gamma(T^*(M)\otimes E)$
satisfying 1) For any $s_1,s_2\in \Gamma(E)$, $D(s_1+s_2)=Ds_1+Ds_2$ 2) For $s\in \Gamma(E)$ and $\alpha\in C^{\infty}(M)$, $D(\alpha s)=d\alpha \otimes s + \alpha Ds$ I am having trouble understanding these conditions. I don't understand the notation $d\alpha \otimes s$. I have only ever dealt with tensor products of linear functionals. Ie $v^*\otimes w^*(v,w)=v^*(v)w^*(w)$. The quantity $d\alpha \otimes s$ is the tensor product of the differential of $\alpha$ and a smooth section of $E$. How is this quantity defined? Can anyone shed any light here? Thanks in advance.","['tensor-products', 'manifolds', 'smooth-manifolds', 'differential-geometry']"
1171397,Sum of squares in geometric progression,"In the geometric progression $b_1, b_2, b_3,\ldots, b_1+b_3+b_5=10$
  and $b_2+b_4=5$. Find the sum of the squares of the first five terms. If you solve for the first term and the common ratio, you will get nasty radicals and then squaring and adding is not a good option. How do I do it then?","['geometric-progressions', 'algebra-precalculus']"
1171406,"Evaluate a rational function of $x,y,z$ given two polynomial equations in $x,y,z$","Let $x, y, z$ be real numbers. Given that $$2x(y^2−1)+2y(x^2−1)=(1+x^2)(1+y^2)$$ and $$4z(1−y^2)+4y(1−z^2)=(1+z^2)(1+y^2)$$ Find the value of the following expression:
$$\Bigg(\frac{2x}{1+x^2}−\frac{2z}{1+z^2}\Bigg)^2+\Bigg(\frac{1−z^2}{1+z^2}−\frac{1−x^2}{1+x^2}\Bigg)^2$$ How do I use $x=\tan\alpha$ and $z=\tan\beta$ in this question. I know it will be useful as the expression to be found out is screaming trigonometric substitution. These were the two equations I finally got after substitution-$$(y^2-1)\sin2\alpha-2y\cos2\alpha=1+y^2$$ and $$2(1-y^2)\sin2\beta+4y\cos2\beta=1+y^2$$ and the expression to be found is $-2(\sin2\alpha\sin2\beta-2\cos2\alpha\cos2\beta)$. Now how do I manipulate my equations? Thanks.","['trigonometry', 'algebra-precalculus']"
1171410,"Prove if $n^2$ is even, then $n^2$ is divisible by 4","I am working on this question Prove for every integer n if $n^2$ is even, then $n^2$ is divisible by 4. prove  by contradiction Proof: Since there exists an integer $n$ such that $n^2$ is even, and $n^2$ is not divisible by 4, when $n$ is odd integer, we have $n = 2k + 1$ where $k \in \mathbb{Z}$, then $n^2 = 4k^2 + 4k + 1$, because $n^2$ is odd which is a contradiction; when $n$ is even integer, we have $n = 2j$ where $j \in\mathbb{Z}$, then $n^2 = 4j^2 \Rightarrow n^2 | 4$, because $n^2$ is divisible by $4$, this is a contradiction; therefore, for every integer $n$, if $n^2$ is even, then $n^2$ is divisible by $4$. Is my proof valid or can anyone give me hint or suggestion to write a better proof? Thanks!","['elementary-number-theory', 'proof-writing', 'discrete-mathematics']"
1171451,Continuous function from the closed unit disk to itself being identity on the boundary must be surjective?,"If there is a continuous function from the closed unit disk to itself such that it is identity map on boundary, must it be onto?","['general-topology', 'homotopy-theory', 'algebraic-topology']"
1171459,Series having strict inequality implies limits having strict equality?,"I was wondering if I have two convergent series, say, $\sum_{n=1}^{\infty} s_n = s$ and $\sum_{n=1}^{\infty} t_n$ = t, and for all $n \in \mathbb{N}$ the terms satisfy: $s_n > t_n$ . Is it then necessary that we have: $s > t$ ? My intuition wants to say yes, but then I know funky stuff goes down with sums, products, intersections, unions and the likes when they deal with infinity. When dealing with a situation like this I would probably inductively show the partial sums have a positive difference, then assume that the limits of the series must have a positive difference too. However this isn't rigorous at all to me and I was wondering if there was an actual proof (if this is a true implication). Thanks in advance.","['sequences-and-series', 'infinity', 'limits']"
1171498,Prove $1+2\sqrt3$ is not a rational number,"How would I go about proving $1+2\sqrt 3$ is not a rational number assuming $\sqrt 3$ is not a rational? Would direct proof be the easiest? Total beginner here, any insight would be appreciated.","['discrete-mathematics', 'proof-writing']"
1171553,is $(x+y)^2\neq (x^2+y^2)$ correct if we consider the integers mod $2$?,In general $(x+y)^2  \neq (x^2+y^2)$. Is this still correct in the case of mod $2$? Can anyone share some insight?,['discrete-mathematics']
1171572,A recursive formula to approximate $e$. Prove or disprove.,"Let the sequence $\{x_n, n=1,2,...\}$ be defined as follows: Let $x_2=x_1=1$
and for $n>2$ let
$$x_{n+1}=x_n-\frac{1}{n}x_{n-1}.$$ This sequence, generated by the recursion above, tends to zero extremely fast. My guess is that $$\sum_{i=1}^{\infty}x_i=e.$$ I came across this problem here on MSE while working on an infinite Markov chain related problem . The state transition probability matrix was given and the task was to find the stationary probabilities. The stationary probabilities could be generated by the recursion above but with an unknown $c=x_1=x_2$. I did some experiments with $c$ and the results lead me believe that $$c=e.$$ I would be surprised if this recursion was not known to somebody around here.","['probability-theory', 'markov-chains', 'sequences-and-series', 'real-analysis']"
1171591,Is this function continuous? Polar coordinates,"Is the function $f:\mathbb R^2\to \mathbb R^2$ given in polar coordinates by $f(r,\theta)=(1,\theta)$ continuous? How would one prove it? My guess would be yes, since geometricly it simply change the whole plane into $S^1$ in a way that seems continuous, but I don't know how to show it (one way I thought is to show that it is continuous in each coordinate in the range, but I couldn't tell if ($f(x)=\frac{1}{\|x\|}x$ is continuous . I believe it is). Thanks","['general-topology', 'multivariable-calculus', 'polar-coordinates', 'calculus']"
1171621,Show the series is convergent and find the limit,"Sequence of real numbers $a_n$ defined recursively with $a_1=1/2$ and $a_{n+1}=\frac{a_n^2}{a_n^2-a_n+1}$  for all $n \geq 1$.
Show that $\sum_{n=1}^\infty a_n$ is convergent and find its limit.
I have tried to convert the recursive form to explicit form but it's too difficult.","['sequences-and-series', 'real-analysis']"
1171623,a question about the proof of theorem 5.3 of Hartshorne's Algebraic Geometry,"This is on page 33 of Hartshorne's Algebraic Geometry . Let $Y$ be an affine variety, and Sing $Y$ be the set of singular points of $Y$. Suppose we already know that Sing $Y$ is a close subset of $Y$, now we need to show that $X := Y -$Sing $Y$, which is an open subset of $Y$, is not empty. In order to do this, the author considers a hypersurface in $\mathbb P^n$ which is birationally equivalent to $Y$. Since birational varieties have isomorphic open subsets, we reduce to the case of a hypersurface. I have three questions about this. As in Corollary 4.5(i)(ii) of this same book, two varieties are birationally equivalent if and only if they each contains one nonempty open subsets isomorphic to each other. Does this mean the existence of an isomorphism correspondence between all the open subsets of the two varieties? Another question is, let $Y,Y'$ be birationally equivalent varieties, and $X = Y -$Sing $Y$, $X'=Y'-$Sing $Y'$, then is it true that $X$ and $X'$ must be isomorphic? Combining with the first question, if the isomorphism correspondence between the open subsets of $Y$ and $Y'$ does exist, does it necessarily corresponds $X$ and $X'$? I think the answer to both of my questions must be negative, since the open subset might be the variety itself. But how can I understand the proof? Why can the author just consider $Y$ as a hypersurface? Thanks.",['algebraic-geometry']
1171625,Geometric proof of $\frac{\sin{60^\circ}}{\sin{40^\circ}}=4\sin{20^\circ}\sin{80^\circ}$,"It is well-known that $$\sin{20^\circ}\sin{40^\circ}\sin{80^\circ}=\frac{\sqrt{3}}{8}$$
It follows that $$\frac{\sin{60^\circ}}{\sin{40^\circ}}=4\sin{20^\circ}\sin{80^\circ}$$
But how to prove this by geometry?
Thank you.","['geometry', 'trigonometry']"
1171640,prove there is no smallest positive rational number,"How would I prove there is no smallest positive rational number?
what is the best method to prove this statement?","['discrete-mathematics', 'proof-writing']"
