question_id,title,body,tags
2024201,"Proof that $\sum\limits_{j,k=1}^N\frac{a_ja_k}{j+k}\ge0$","I found this inequality holds: Given a sequence of real numbers,
  $a_1,a_2,...,a_N$, if
  $$S=\sum_{j,k=1}^N\frac{a_ja_k}{j+k}$$ then $$S\ge0$$ Is it a known result? How is it possible to prove it?","['inequality', 'sequences-and-series']"
2024236,Infinite sum with two parameters [duplicate],"This question already has answers here : Is there a cleaner proof of convergence for this almost-telescoping series (2 answers) Closed 3 years ago . Evaluate the convergence of the following infinite sum. I am so bad when it comes to parameters. I don't know where to start.
$\sum_{n=1}^{\infty}\dfrac{(n+1)^a-n^a}{n^b}$, where $a,b\in\mathbb{R}$.","['sequences-and-series', 'calculus']"
2024255,What is the difference between the weak and strong law of large numbers?,"I don't really understand exactly what the difference between the weak and strong law of large numbers is. The weak law says \begin{align*}
\lim_{n \rightarrow \infty} \mathbb{P}[\mid \bar{X}_n - \mu \mid \leq \epsilon ] = 1,
\end{align*} while the strong law reads as \begin{align*}
 \mathbb{P}[\lim_{n \rightarrow \infty} \bar{X}_n = \mu ] = 1 
\end{align*} Isn't this a very subtle difference? Since I can chose my $\epsilon$ arbitrarily small I can write for $n \rightarrow \infty$ \begin{align*}
\mid \bar{X}_n - \mu \mid \leq \epsilon \\
- \epsilon \leq \bar{X}_n - \mu  \leq \epsilon \\
\mu - \epsilon \leq \bar{X}_n   \leq \mu + \epsilon
\end{align*} Which of course means that as $\epsilon \approx 0$ should be the same as $\lim_{n \rightarrow \infty} \bar{X}_n = \mu$ . So, in what sense are those conditions actually "" different ""? Regarding the weak law I'd like to know if these are actually the same: \begin{align*}
\lim_{n \rightarrow \infty} \mathbb{P}[\mid \bar{X}_n - \mu \mid > \epsilon] =  \mathbb{P}[ \mid \lim_{n \rightarrow \infty} \bar{X}_n - \mu \mid > \epsilon] 
\end{align*} I ask because the weak law always gets written like the l.h.s. but the strong law always has $\lim_{n \rightarrow \infty}$ inside the probability operator ..","['law-of-large-numbers', 'probability-theory', 'analysis']"
2024268,Infimum of probability and probability of infimum,I am studying the Borel Cantelli proof and there is the following step: $$\Pr\left( \bigcap \limits_{N=1}^{\infty} \bigcup\limits_{n=N}^{\infty}E_n\right) \le \inf_{N\ge1} \Pr\left( \bigcup\limits_{n=N}^{\infty} E_n\right)$$ What happened here? I guess that: $$\Pr\left(\bigcap \limits_{N=1}^{\infty}\bigcup\limits_{n=N}^{\infty} E_n\right) = \Pr\left(\inf_{N\ge1}\bigcup\limits_{n=N}^{\infty} E_n\right) \le \inf_{N\ge1} \Pr\left( \bigcup\limits_{n=N}^{\infty} E_n\right)$$ But why is this true?,"['borel-cantelli-lemmas', 'probability', 'supremum-and-infimum', 'elementary-set-theory']"
2024271,Restriction of smooth maps between manifolds,"Let $M$ and $N$ be two smooth manifolds, let $F: M \to N$ be a map between those two manifolds. $F$ is said to be smooth (or differentiable) if $\psi \circ F \circ \phi^{-1}$ is smooth, for every $(U, \phi)$ local chart on $M$ and for every $(V, \psi)$ local chart on $N$. Show that $F$ is smooth if and only if for all $p \in M$, there exists a neighbourhood $U$ of $p$ such that $F_{|U}$ (restriction of $F$ to $U$) is smooth. My problem with this question is that this seems to be trivially obvious to me, and I am struggling a bit to formalise the proof. The $\implies$ implication is easy, as it suffices to take $M$ as the neighbourhood $U$. As for the viceversa.. well, saying that $F_{|U}$ is smooth means that $\psi \circ F_{|U} \circ \phi^{-1}$ is smooth for every local chart. Now, since this holds for all $p \in M$, this means that  the neighbourhoods $U$ form an open covering of the manifold $M$. The restriction of $F$ to each element of this covering is smooth. It looks obvious to me that this implies that $F$ is smooth, but I can't figure out a way of showing this explicitly. Any hint is appreciated.","['smooth-manifolds', 'differential-geometry', 'functions']"
2024334,Integration of a huge trig function,"Consider $$\int _\frac{ -1}{\sqrt{3}} ^ \frac {1}{\sqrt {3}}\frac {x^4}{1-x^4}\arccos \left(\frac{2x}{1+x^2}\right) \mathrm{d}x.$$ Every condition like the limits, the value which arccosine is taking is making me put $x=\tan (t) $. Thus, on simplifying we get $$\frac {\sin^4 (t)}{(1-\sin^2 (t))(1-2\sin^2 (t)}\arccos (\sin(2t)),$$ 
but from there I don't know what to do. Another approach was writing the first part as $-1+\frac {1 }{2}\left(\frac {1}{1-x^2}+\frac {1}{1+x^2}\right) $ but still I have no hope that this helps . Thus I am hoping for a better approach . Thanks!","['definite-integrals', 'trigonometry', 'calculus', 'riemann-integration']"
2024367,Why squaring the trigonometric equation changes the solution?,"I have a trigonometric equation that is defined as: $\sin(\alpha) - \cos(\alpha) = \frac{1}{2}$ Solving this equation by mathematica will yield $\alpha = 65.70 $ and $\alpha = -155.705 $ But As I solve it analytically, I will obtain different results: First I exponentiate both sides to the power of two: $(\sin(\alpha) - \cos(\alpha))^2 = \frac{1}{2}^2$ Now I expand the expressions: $\sin(\alpha)^2 - 2 \sin(\alpha) \cos(\alpha) + \cos(\alpha)^2 = \frac{1}{4}$ As  $\sin(\alpha)^2 + \cos(\alpha)^2 = 1$, I will have: $1 - 2 \sin(\alpha) \cos(\alpha) = \frac{1}{4}$ Again if I put $2 \sin(\alpha) \cos(\alpha) = \sin(2\alpha)$ I will be left with: $\sin(2 \alpha) = \frac{3}{4}$ Which will readily give $\alpha = 24.3$ So, why I am having different results? I don't understand.","['algebra-precalculus', 'trigonometry', 'quadratics']"
2024411,Pointwise convergence doesn't imply $L^p$ convergence if $p=\infty$ under some hypothesis,"I just proved that if $1\leq p<\infty$ and $f,f_n$ is a sequence of measurable functions such that $f_n(x)\rightarrow f(x)$ a.e $x\in X$ and $\exists g\in L^p(\mu)$ such that $|f_n(x)|\leq g(x)$ a.e $x\in X$, then $f_n\rightarrow f$ in $L^p.$ Why is it that this is not true if $p=\infty$?","['lp-spaces', 'measure-theory', 'convergence-divergence']"
2024464,Prove that $\prod_{k=0}^{n-1}\sin \left( x + k\frac{\pi}{n} \right) = \frac{\sin nx}{2^{n - 1}}$ [duplicate],"This question already has an answer here : Proof of $\sin nx=2^{n-1}\prod_{k=0}^{n-1} \sin\left( x + \frac{k\pi}{n} \right)$ (1 answer) Closed 7 years ago . Prove that for any $n \in \mathbb{N}^*$ we have:
$$\sin x \sin \left( x + \frac{\pi}{n} \right) \sin \left( x + \frac{2\pi}{n} \right)\cdots \sin \left( x + \frac{(n - 1)\pi}{n} \right) = \frac{\sin nx}{2^{n - 1}}$$ Here is what I did so far: We know that $\sin x = \Im (e^{ix})$. So, we can rewrite our product the following way: $\prod_{k = 1}^{n - 1} \sin \left( x + k\frac{\pi}{n} \right) = \prod_{k = 1}^{n - 1} \Im \left( e^{i \left( x + k\frac{\pi}{n} \right)} \right)$ At this point I got stuck, mainly because I'm not sure if I can take the $\Im$ of the whole product or not. Thank you in advance!","['trigonometry', 'complex-numbers']"
2024468,Can this be solved without resorting to graphical method?,"I need to find the points of intersection of a circle with radius $2$ and centre at $(0,0)$ and a rectangular hyperbola with equation $xy=1$. As per the topic statement is there any way to solve this without the graphical method. I have tried setting the $y$ values equal but I cant solve the resulting equation for $x $.","['circles', 'analytic-geometry', 'euclidean-geometry', 'geometry', 'conic-sections']"
2024488,Show that $T/U$ is abelian,"Let $T$ be the group of nonsingular upper triangular 2 x 2 matrices with entries in $\mathbb{R}$; that is, matrices of the form 
$$\begin{bmatrix}
    a & b \\
    0 & c 
\end{bmatrix}$$ where $a, b, c\in\mathbb{R}$ and $ac\neq 0$. Let $U$ consist of matrices of the form
$$\begin{bmatrix}
    1 & x \\
    0 & 1 
\end{bmatrix}$$ where $x\in\mathbb{R}$. Prove that $T/U$ is abelian. My attempt: I've already proved that $U$ is normal in $T$. Let $t_1=\begin{bmatrix}
    a & b \\
    0 & c 
\end{bmatrix}$ and $t_2=\begin{bmatrix}
    d & e \\
    0 & f 
\end{bmatrix}$ $U=\left\{\begin{bmatrix}
    1 & x \\
    0 & 1 
\end{bmatrix}: x\in\mathbb{R}\right\}$ $(t_1U)(t_2U)=t_1t_2U=\left\{\begin{bmatrix}
    ad & adx+ae+bf \\
    0 & cf 
\end{bmatrix}: x\in\mathbb{R}\right\}$ $(t_2U)(t_1U)=t_2t_1U=\left\{\begin{bmatrix}
    ad & adx+bd+ce \\
    0 & cf 
\end{bmatrix}: x\in\mathbb{R}\right\}$ How do I prove that $(t_1U)(t_2U)=(t_2U)(t_1U)$? Thanks in advance.","['group-theory', 'linear-algebra']"
2024536,Order of limits of difference quotient,"Let $f$ be a uniformly continuous real function, and let $a$ be a real number. Assume that $f'$ is also uniformly continuous. I need to prove this: $$\lim_{x_1\rightarrow a}\lim_{x_2\rightarrow x_1}\frac{f(x_1)-f(x_2)}{x_1-x_2}
=\lim_{x_2\rightarrow a}\lim_{x_1\rightarrow a}\frac{f(x_1)-f(x_2)}{x_1-x_2}$$ Intuitively, the equation just says that the derivative of $f$ at $a$ is equal to the limit of the derivatives of $f$ close to $a$, and is therefore clearly true. However, I need a proof that proceeds directly from the definitions of limits and uniform continuity (or ""basic"" theorems about limits and uniform continuity), and I don't know how to do that.","['derivatives', 'real-analysis', 'limits']"
2024585,Function with finite integral is finite a.e.,"I'm trying to understand the concept of integrals over general sets (instead of just $\mathbb{R}$, or just $\mathbb{N}$ with the counting measure). Let $(\Omega, A, \mu)$ be a measure space and let $f: \Omega \to [0, \infty]$ be $A$-measurable. Assume that the integral exists: $$ \int_{\Omega} f d\mu $$ My question is: if $S = \{x \in \Omega : f(x) = \infty\}$, is the measure $S$ zero? (So that $f$ is finite a.e.) Intuitively, I think, the answer is yes, because otherwise, we would have (I think!) $$ \int_{S} f d\mu = \infty $$ but this would be a contradiction, since $S \subset \Omega$ gives us $$ \infty = \int_{S} f d\mu < \int_{\Omega} f d\mu < \infty $$ If my intuition is correct, please give a formal proof of the second formula; I am having a hard time with (in a formal way) dealing with the concept of an integral over a general set with respect to a general measure.","['integration', 'measure-theory']"
2024676,How to interpret parameter estimates in factor prediction ( in R ),"So I have some data set in a .csv file and there are three factor levels, $1$ , $2$ , $3$,  (there are fifteen of each) and each has a corresponding score. Here are some details. so the data is contained in a simple csv file, the first column is labelled Team, and the second column is labelled Score. The first column consists of fifteen 1's, followed by fifteen 2's , followed by fifteen 3's. The R code I used was data.source<-""http.www..   "" ( the data set) SportScores<-read.csv(file=data.source) I set x such that x prints 1 1 1.... 1  2 2 2 ... 2 3 3 3 .... 3
Levels 1 2 3 names(sportScores) y<-SportScores$Scores So using lm I get parameter estimates in R as Intercept (35.800) x2 (0.066) x3 (12.40) the t value are very large for intercept and $x3$, but very small for $x2$, ie it indicated to me that we cannot reject the null in this case, but what is the null?
$$\beta_{0}=35.8$$ , $$\beta_{1}^{c}=0.06667$$, $$\beta_{2}^{c}=12.40$$ But how do I interpret this? I want to see any differences in scores between the 3 levels, etc. I mean, what even is the test being conducted? For example 
$$\beta_{1}^{c}=0.06667$$ has a small t value, so the null hypothesis is not rejected, but what even is the null hypothesis in this case?  Moreover, from the code output itself, how can I know the associated individual standard errors of the estimated means?","['statistics', 'mathematical-modeling']"
2024683,Geometric interpretation of the second covariant derivative,"I'm having some doubts about the geometric representation of the second covariant derivative. I know that $\triangledown^{}_a(\triangledown^{}_bv)=(\triangledown^{}_a\triangledown^{}_b)v+\triangledown^{}_{\triangledown^{}_ab}v$ So the Riemann tensor can be defined in two ways : $R(a,b)v=\triangledown^{}_{a}(\triangledown^{}_{b}v)-\triangledown^{}_{b}(\triangledown^{}_{a}v)-\triangledown^{}_{[a,b]}v\quad$ or $\quad R(a,b)v=(\triangledown^{}_{a}\triangledown^{}_{b})v-(\triangledown^{}_{b}\triangledown^{}_{a})v$ So far so good (correct me if I'm wrong). But the problem arises when I read that the Riemann tensor represents the difference between a parallel transported vector along two parts of a closed path. Because if $\triangledown^{}_{b}v$ is the parallel transported vector along b, then it stands to reason that $\triangledown^{}_{a}(\triangledown^{}_{b}v)$ is the transported vector along b and then a. But there would be a correction term, so the representation would be inexact. And conversely, if $(\triangledown^{}_{a}\triangledown^{}_{b})v$ is the transported vector along the path b and then a, the representation would be correct, but I don't understand why... So, which is correct, A or B ? Edit : would the difference be linked with the torsion ? Are $\triangledown^{}_{a}(\triangledown^{}_{b}v)$ and $(\triangledown^{}_{a}\triangledown^{}_{b})v$ equal if the connection is torsion free ? PS : why is the image not integrated in the post ? too large ?",['differential-geometry']
2024712,Lebesgue dominated convergence integral,"How would one compute this integral using Lebesgue dominated convergence theorem?
$$\lim_{n\rightarrow \infty}\Big[\int_0^n\Big( 1+\frac{2x}{5n} \Big)e^{-x/2}dx\Big]$$
My understanding is we can't just set upper limit of the integral to be infinity and replace the integrand with just $e^{-x/2}$. But the upper limit being $n$ confuses me a lot.","['lebesgue-integral', 'measure-theory']"
2024721,A set which the interior of its boundary is not empty,"Let $(X,d)$ be a metric space and let $A\subset X$. If $A$ is either open or closed, then $(\partial A)^{\circ} = \varnothing$. I am asked to find a metric space and a subset that the interior of its boundary is not empty. I have tried something with the discrete metric, but then realized that since every set in a discrete metric is a union of open sets, every set is open, so this has no future.","['general-topology', 'metric-spaces']"
2024735,Prove $xy'+ay=f(x)$ has only one bounded solution,"Let $xy'+ay=f(x)$, where $a>0$ and $f(x)$ is a continuous and bounded function on $(0,\infty)$ that satisfies $\lim\limits_{x\to0^+}f(x)=b$. Prove that the equation has only one solution which is bounded on $(0,\infty)$. I was only able to prove that there can't be more than one bounded solution: suppose there are two solutions $y_1,y_2$ which are bounded $|y_1(x)|\leq M,|y_2(x)|\leq K$. Then $y_1-y_2$ solves the homogeneous equation $g'+\frac{a}{x}g=0$. But the general solution to this equation is $g(x)=Cx^{-a}$. Since $a>0$ we have $\lim\limits_{x\to0^+}g(x)=C\lim\limits_{x\to0^+}x^{-|a|}=\infty$, therefore the solutions are not bounded on $(0,\infty)$ which contradicts the fact that $|y_1-y_2|\leq|y_1|+|y_2|\leq M+K$. However I fail to prove that such (bounded) solution exists (I tried to prove that the integral which we obtain when finding the solution to the original equation is bounded, but I didn't succeed).",['ordinary-differential-equations']
2024756,Find the $n$ derivative of $y= e^{2x}\sin^2 x$,"We have \begin{align*}
y&= e^{2x}\sin^2 x\\
&= e^{2x}\left(\frac{1-\cos 2x}{2}\right)\\
&= \frac{e^{2x}}{2} - \frac{e^{2x}\cos 2x}{2}
\end{align*} Then \begin{align*}
y^{(n)} &= \left(\frac{e^{2x}}{2}\right)^{(n)} - \left(\frac{e^{2x}\cos 2x}{2}\right)^{(n)}\\
&= 2^{n-1}e^{2x} - \left(\frac{e^{2x}\cos 2x}{2}\right)^{(n)}
\end{align*}
I don't know how to proceed with the rightmost term. So far I've been applying the Leibniz Rule whenever I've had to find the $n$ derivative of a function of the form $f(x)g(x)$, because is clear that either $f(x)$ or $g(x)$ has a derivative a $k$ derivative ($1<k<n$) equal to zero, which simplifies the expression nicely. But here $$\frac{e^{2x}\cos 2x}{2}$$ both functions are infinitely differentiable on $\mathbb{R}$ which makes things a bit different. My only attempt was to write its n derivative in this form \begin{align*}
&=\frac{1}{2}\sum_{k=0}^n{n \choose k} \big(2^k e^{2x}\big)\bigg(2^{n-k}\cos \left[2x + \frac{\pi(n-k)}{2}\right]\bigg)\\
&=\sum_{k=0}^n {n \choose k} 2^{n-1}e^{2x}\cos \left[2x + \frac{\pi(n-k)}{2}\right]
\end{align*} So \begin{align*}
y^{(n)} &= 2^{n-1}e^{2x} -\sum_{k=0}^n{n \choose k} 2^{n-1}e^{2x}\cos \left[2x + \frac{\pi(n-k)}{2}\right]\\
&= 2^{n-1}e^{2x}\left(1 -\sum_{k=0}^n{n \choose k} \cos \left[2x + \frac{\pi(n-k)}{2}\right]\right)
\end{align*} But the textbook's answer is $$2^{n-1}e^{2x}\left(1 -2^{n/2}\cos \left[2x + \frac{\pi n}{4}\right]\right)$$ For some reason I have the feeling that a little of modular arithmetic has to be applied on $\frac{\pi(n-k)}{2}$","['derivatives', 'real-analysis', 'calculus']"
2024769,Baire's theorem and limits,"Let $f:[1,\infty) \longrightarrow \mathbb{R} $ continuous function such that $\forall x \geqslant 1$ we have $\lim_{n \longrightarrow \infty} f(nx)=0$.
Prove that $\lim_{y \longrightarrow \infty}f(y)=0$ My professor gave me as a hint to use Baire's theorem. This is what i have done so far: Let $\epsilon>0$. We define $A_m=\{x \geqslant 1: \forall n \geqslant m ,|f(nx)| \leqslant  \epsilon \}$ Let $x_k \in A_m$ and $x_k \longrightarrow x$ Then $\forall n \geqslant m$ and from the continuity of $f$ we have $|f(nx)|= \lim_{k \longrightarrow \infty}|f(nx_k)| \leqslant \epsilon$ Thus $x \in A_m$ ,so each $A_m$ is closed. Now let $x \geqslant 1$ .From our hypothesis  $\lim_{n \longrightarrow \infty} f(nx)=0$ ,hence $\exists m_0 \in \mathbb{N}$such that $\forall n \geqslant m_0,|f(nx)| \leqslant \epsilon$, thus $x \in A_{m_0}$.In other words $[1,\infty)=\bigcup_{m=1}^{\infty}A_m$ We also know that $[1,\infty)$ is a complete metric space with respect to the euclidean metric of the real line. From Baire's theorem exists a set $A_m$ with non empty interior. In other words exists $[a,b] \subseteq A_m$. If $x \in A_m$ then $|f(nx)| \leqslant \epsilon$ 
$\forall n \geqslant m$. Can someone help me to proceed form this point? Thank you in advance!","['general-topology', 'real-analysis', 'metric-spaces', 'baire-category']"
2024799,Is it true that an isomorphism maps elements of the same order to each other?,"I know that for two groups to be isomorphic each group must contain elements of the same order.  So then are elements of the same order mapped to each other?  If so, why?","['abstract-algebra', 'group-theory', 'group-isomorphism']"
2024800,Tennis Probability Pro and average Joe,"You are in a tennis club with two other members. One of them, Roger (think Federer) is a really good tennis player, and you have a 0.1 probability of winning a match against him. The other player is Joe (think average). He is a pretty good tennis player, and you have a 0.5 probability of winning a match against him. Now, you are given a choice of the following two sequences of matches:Roger, Joe, RogerorJoe, Roger, JoeThe rule is that you will collect a prize if and only if you win at least two games in a row among your set of three matches. (Note: winning two out of three is not enough; you have to win at least two consecutive matches.) QUESTION 1) Which of these two schedules (RJR or JRJ) offers you the better chance of collecting a prize? QUESTION 2) What is the expected number of wins for you in the sequence RJR? In the sequence JRJ?","['game-theory', 'probability', 'discrete-mathematics']"
2024867,Continuous function and Borel sets,"If $f:\mathbb{R}^p \rightarrow \mathbb{R}$ is continuous and $B\subset \mathbb{R}$ is Borel set, how to show that $f^{-1}(B)$ is also Borel set? I was trying to construct a $\sigma$-ring of sets whose preimage is Borel, but they're not necessarily all borel in that sigma ring... What would be the main idea for the proof here?",['measure-theory']
2024899,Prove that $\lim_{n\to \infty}\int_{0}^{\pi/6}{\sin}^{n}x~dx$ = 0,"Prove that the $\lim_{n\to \infty}\int_{0}^{\pi/6}{\sin}^{n}x~dx = 0$. Make use of the following theorem: Let $f_n$ be a sequence of functions in $R[a, b]$. Suppose the sequence converges uniformly on $[a, b]$ to the function f . Then $f\in R[a, b]$ and $\int_{a}^{b}f_n(x)dx \Rightarrow \int_{a}^{b}f(x)~dx$ You may assume $\sin(x)$ is continuous. I am not sure exactly how to start this proof. I think I would need to first find the pointwise limit, which I believe is $0$.","['real-analysis', 'integration', 'calculus', 'limits']"
2024962,Spectrum of the coordinate ring of an affine variety,"My question is rather simple for an algebraic-geometer maybe and because I'm not, it confuses me a lot and has to do with the following. Sometimes, I see authors indentify an affine variety $V \subset \mathbb{A}^{n}$ over an algebraically closed field say $\mathbb{K}$, with the spectrum $Spec(\mathbb{K}[V])$, and they are referring to the latter as the the affine variety with coordinate ring $\mathbb{K}[V]$. (where as far as I know the last spectrum it is called affine scheme in the literature) So, it's obvious by definition that those two sets are not equal, hence it's about an identification (natural or if you prefer categorical) between them. Even if $V$ is irreducible variety (which means that we don't have other primes except the maximals and the trivial $\{ 0 \}$ and due to Nullstellenstaz we have a ""good"" correspondence between the points of $V$ and elements in $Spec(V)$) there is something missing, namely the generic point we add because of the non-maximal prime ideal $\{ 0 \}$. I would understand the identification of $V$ with the maximal spectrum $mSpec(\mathbb{K}[V])$ in that case but the previous one doesn't make any sense. Can you please explain me how this identification comes in and what's the idea behind the ""equality"" $V=Spec(\mathbb{K}[V])$?","['affine-varieties', 'affine-schemes', 'algebraic-geometry']"
2024982,Polyhedral version of sphere eversion,"Is there a polyhedral version of sphere eversion (Smale's theorem), where you take a polyhedron with triangular faces homeomorphic to the sphere, and continuously move the vertices such that no dihedral angle becomes zero (that is, no pair adjacent faces ever overlap) and such that it ends inside-out of how it started? If so, how many vertices do we need? A simple argument shows the tetrahedron cannot be everted in that manner. I don't think the octahedron can, either. I imagine this probably needs a large polyhedron to work. (Alternate question: What if you require that the dihedral angles never leave $(\pi-\epsilon,\pi+\epsilon)$ for some $\epsilon$?)","['polyhedra', 'general-topology', 'differential-topology']"
2024993,"Spectrum of a ring homeomorphic to a compact, totally disconnected space","Let $X$ be a compact, totally disconnected space. It must be shown that $X$ is homeomorphic to $\mathrm{Spec}(A)$, where
$$ A:=C(X, \mathbb{Z}_2), $$
and $\mathbb{Z}_2$ is endowed with the discrete topology. At first, it is easy to see that $A=\{ \chi_S: S\; \mathrm{is\,open\,and\,closed\,in\;}X \}$ (no matter how ugly or cool $X$ is)[further, such $A$ is a boolean ring] And, naturally, there is a correspondence $$\{ \chi_S: S\; \mathrm{is\,open\,and\,closed\,in\;}X \} \rightleftarrows  \{ S\subseteq X: S\; \mathrm{is\,open\,and\,closed\,in\;}X \}=:\Gamma_X $$ I think I've read somewhere (sorry, I forgot where), that if $B$ is a boolean ring, then $B$ is isomorphic to $\Gamma_{\mathrm{Spec}(B)}$. Let us denote this result by $(*)$. I think that, under the assumption of $(*)$, $A\cong \Gamma_{\mathrm{Spec}(A)}$, but if $X$ is totally disconnected,  then  $\Gamma_{\mathrm{Spec}(A)}=\mathrm{Spec}(A)$, is this right ? Also, $X$ is in a one-to-one correspondence with $\{ \chi_{\{x \} }: x\in X \}$, which gives us
$$ X\cong A\cong\Gamma_{\mathrm{Spec}(A)}=\mathrm{Spec}(A). $$ I've not checked continuity yet, which shouldn't be too complicated. I'm stuck at this point because $A\cong \mathrm{Spec}(A)$ shocks me. Can you help me, please? 
Is my reasoning right?","['zariski-topology', 'general-topology', 'algebraic-geometry', 'commutative-algebra']"
2025005,Reparametrization of multivariable fisher information,"The task is to prove that reparametrization of multivariable Fisher information  with diffeomorphism $\eta: \Theta \rightarrow H$ is 
$$
I(\eta)=\bigg(\frac{\partial \theta^T}{\partial \eta}\bigg)I(\theta)  \bigg(\frac{\partial \theta}{\partial \eta^T}\bigg),
$$
for given $I(\theta)$. My solution: We know that multivariable Fisher information is 
$$
I(\theta)=\mathbb{E}\bigg\{\frac{\partial}{\partial\theta}\log{(f_\theta(x))}\bigg[\frac{\partial}{\partial \theta}\log{(f_\theta(x))}\bigg]^T\bigg\}.
$$ We can apply chain rule 
$$
\frac{\partial}{\partial \eta}= \frac{\partial \theta}{\partial \eta}\frac{\partial}{\partial \theta} \Rightarrow  \frac{\partial}{\partial \theta} = \bigg(\frac{\partial \theta}{\partial \eta}\bigg)^{-1}\frac{\partial}{\partial \eta}
%\theta'(\eta)\frac{\partial}{\partial\theta}
$$ Applying it to the first equation and changing $\theta \mapsto \eta$ we obtain
$$
I(\eta)=\mathbb{E}\bigg\{\frac{\partial\theta}{\partial\eta}\frac{\partial}{\partial\theta}\log{(f_\eta(x))}\bigg[\frac{\partial\theta}{\partial\eta}\frac{\partial}{\partial \theta}\log{(f_\eta(x))}\bigg]^T\bigg\}.
$$
Now it's somewhere close to solution, what I would like to do is to take this $\big(\frac{\partial\theta}{\partial\eta}\big)$s out of the expected value and tell that it is done.
But I don't think it is correct. Can anyone help?","['fisher-information', 'statistics']"
2025030,Second derivative as a multilinear map,"Well, let's assume that $T=(f\circ g)$. 
How do I compute $D^2 T(y)(v,w)$? I tried $D^2 T(y)(v,w)=(D_wD_vT)(y)$, i.e. do first the directional derivatives and then compute them at $y$. $D_vT=((Df)\circ g) \circ (Dg )\ (v)$, then I try to apply again the chain rule to $D_wD_vT$. My best (incorrect) effort gives $((D((Df)\circ g))\circ Dg \ (v))\circ D^2g(v,w)=((D^2f)\circ g)\circ Dg )\circ Dg \ (v))\circ D^2g(v,w)$ which is a big mess and this doesn't look like what I'm supposed to get, which is $$D^2f(x)(Dg(y)v,Dg(y)w)+Df(x)D^2g(y)(v,w)$$ How would one proceed? any help would be appreciated. P.S: If you're downvoting this question, at least tell me what's wrong it with  so that I can improve it. Thanks.","['multivariable-calculus', 'multilinear-algebra']"
2025043,When are two line bundles isomorphic?,"Probably not a very deep question follows. I struggle to understand the idea of the Picard group. I want to understand when two line bundles are isomorphic. Is there a nice illustrative example? For example what are the isomorphism classes of the the 1-forms living on the tangent space of a curve (i.e. $f \in \Omega^1(S)$ and $[f]\in H^1(S)$). Also, are there some easy counter-examples? And what about objects other than line bundles, like vector bundles? For those one usually constructs moduli spaces. Thus can we consider Picard group as being the moduli space of line bundles? Note: I have the impression that, in the example of 1-forms, we consider two of them isomorphic if they differ by an exact form (I think this makes sense in terms of cohomology). But still, I would like to see a concrete counter-example as well as an example that has different kind of line bundles)","['differential-geometry', 'algebraic-geometry', 'holomorphic-bundles']"
2025058,Why not defining random variables as equivalence classes?,"The usual definition of a random variable (or random element) is that of a measurable function $X : (\Omega, \mathcal{F}, P) \rightarrow (\Omega', \mathcal{F}')$. Now I am not aware of any property/theorem that depends on the specific values of $X$ for every $\omega \in \Omega$. In particular any other $P$-almost surely equal random variable $X'$ is generally considered as equivalent to $X$ for all practical purposes. So is there a good reason not to define random variables as equivalent classes rather than laboriously precising each time that such or such statement is true almost surely, that such or such sequence converges almost surely, that such or such object is unique almost surely, etc ? As a comparison defining $L^p$ spaces as spaces of equivalent classes of almost everywhere equal functions helps a lot in simplifying the phrasing of the theory. So are there some interesting/complex cases where we would really need to keep the distinction between almost surely equal random variables? Edit In agreement with @Pedro Tamaroff's comment I'm removing the last addendum to this question and opening a new one .","['definition', 'probability', 'measure-theory', 'random-variables']"
2025061,Most Economical Description of Two Lines in $\mathbb{P}^{3}$,"I have two lines $L_{1}$ and $L_{2}$ in $\mathbb{P}^{3}$, and in one case they intersect while in the other they are skew.  I am wanting to do a computation which involves writing them out explicitly in coordinates and I'm hoping to use projective linear transformations to describe the two lines as economically as possible.  I have an idea that I was hoping someone may critique or fix! Let $(x_{0}:x_{1}:x_{2}:x_{3})$ be coordinates on $\mathbb{P}^{3}$.  Now, we can most certainly use the automorphisms of $\mathbb{P}^{3}$, namely $\rm{PGL}_{4}(\mathbb{C})$, to describe one of the two lines as $$L_{1}: \{x_{2}=0, x_{3}=0\}.$$ Now, in general, the second line will be the complete intersection of two hyperplanes like $a_{0}x_{0}+a_{1}x_{1}+a_{2}x_{2}+a_{3}x_{3}=0$ and $b_{0}x_{0}+b_{1}x_{1}+b_{2}x_{2}+b_{3}x_{3}=0$.  Ideally, I would like to make these a lot simpler if at all possible! My idea is that maybe $\rm{PGL}_{4}(\mathbb{C})$ contains a subgroup like $\rm{PGL}_{2}(\mathbb{C})$ which actually fixes the first line $L_{1}$.  Then, maybe I can use this subgroup to make at least some of the $a_{i}$ and $b_{i}$ zero.  For example, I think I should at least be able to make $L_{2}$ be given by $\{x_{1}=0\}$ plus another hyperplane vanishing. So my question is, can this actually be done, and maybe it can even be done nicer than I described above?  Does the two lines intersecting or not play any role in this simplification?  My main worry is that I know a lot of intuition which comes from three-(real) dimensions is completely ""accidental"" so maybe in four-dimensions ($\mathbb{P}^{3} = \mathbb{P}(\mathbb{C}^{4})$), we can't make sense of a rotation around a fixed plane, leaving that plane fixed.","['algebraic-geometry', 'geometry']"
2025064,Is this solution correct? Eigenvector problem.,"Find the eigenvectors of :$$\begin{bmatrix}0&1&0&0\\1&0&0&0\\0&0&0&1\\0&0&1&0\end{bmatrix}$$ Finding the characteristic equation, we can write \begin{align*}
det(A-\lambda I) &= 0 \\
\begin{vmatrix}-\lambda&1&0&0\\1&-\lambda&0&0\\0&0&-\lambda&1\\0&0&1&-\lambda\end{vmatrix}&=0\\
-\lambda\begin{vmatrix}-\lambda&0&0\\0&-\lambda&1\\0&1&-\lambda\end{vmatrix} - \begin{vmatrix}1&0&0\\0&-\lambda&1\\0&1&-\lambda\end{vmatrix} &= 0\\
-\lambda(-\lambda(\lambda^2-1))-(\lambda^2-1) &= 0\\
-\lambda(-\lambda^3+\lambda)-\lambda^2+1 &= 0 \\
\lambda^4-\lambda^2-\lambda^2+1&=0\\
\lambda^2(\lambda^2-1)-1(\lambda^2-1)&=0\\
(\lambda^2-1)(\lambda^2-1) &= 0 \\
\lambda &= -1, 1\\
\end{align*} Now, finding the eigenvectors \begin{align*}
\lambda = 1, \begin{bmatrix}-1&1&0&0\\1&-1&0&0\\0&0&-1&1\\0&0&1&-1\end{bmatrix}\vec{v}_1&= 0\\
\begin{bmatrix}-1&1&0&0\\0&0&0&0\\0&0&-1&1\\0&0&1&-1\end{bmatrix}\vec{v}_1&= 0\\
\begin{bmatrix}-1&1&0&0\\0&0&1&-1\\0&0&0&0\\0&0&1&-1\end{bmatrix}\vec{v}_1&= 0\\
\begin{bmatrix}-1&1&0&0\\0&0&1&-1\\0&0&0&0\\0&0&0&0\end{bmatrix}\vec{v}_1&= 0\\
\therefore \vec{v} &= (1,1,0,0)\\
\lambda = -1, \begin{bmatrix}1&1&0&0\\1&1&0&0\\0&0&1&1\\0&0&1&1\end{bmatrix}\vec{v}_1&= 0\\
\begin{bmatrix}1&1&0&0\\0&0&0&0\\0&0&1&1\\0&0&1&1\end{bmatrix}\vec{v}_1&= 0\\
\begin{bmatrix}1&1&0&0\\0&0&1&1\\0&0&0&0\\0&0&1&1\end{bmatrix}\vec{v}_1&= 0\\
\begin{bmatrix}1&1&0&0\\0&0&1&1\\0&0&0&0\\0&0&0&0\end{bmatrix}\vec{v}_1&= 0\\
\therefore \vec{v} &= (-1,-1,0,0)\\
\end{align*} Therefore, all of this matrix's eigenvectors are spanned by (1,1,0,0) and (-1,-1,0,0). Is this correct? I feel like there should be more, specifically (1,-1,0,0) corresponding to $\lambda = -1$, but I could be wrong.","['eigenvalues-eigenvectors', 'linear-algebra', 'linear-transformations']"
2025085,A basis of a Galois extension.,"Let $f(x) = x^3 - 3x + 1 \in \mathbb{Q}[x]$. It is irreducible over $\mathbb{Q}$ since it is irreducible over $\mathbb{F}_2$. The discriminant of $f$ is $81 = 9^2$, so the Galois group of $f$ is isomorphic to $A_3$ and the splitting field of $f$ is $\mathbb{Q}(\alpha)$, where $\alpha$ is a root of $f$. Now I want to represent the elements of $G(\mathbb{Q}(\alpha)/\mathbb{Q})$ as matrices $3 \times 3$, but to do that I need a basis of $\mathbb{Q}(\alpha)$ over $\mathbb{Q}$. And the question is: What basis of $\mathbb{Q}(\alpha)/\mathbb{Q}$ is better to choose and how to express the roots $\alpha, \beta$ and $\gamma$ in terms of that basis? If I take ${1, \alpha, \alpha^2}$ as a basis, what is a good way of finding the coordinates of $\beta$ and $\gamma$?","['galois-theory', 'abstract-algebra', 'algebraic-number-theory', 'number-theory', 'field-theory']"
2025086,Partition of unity and volume form on a manifold,"A smooth manifold $M$ is orientable iff there exists a nowhere-vanishing top form (i.e. volume form). In a coordinate chart $U\subset M$ we can find a volume form over $U$ that corresponds to the standard volume form $\operatorname{vol} = dx^1\wedge\dots\wedge dx^n$ in $\mathbb{R}^n$. My question is, why can't we just use a partition of unity on the manifold to glue these local volume forms together? I.e. given a partition of unity $\{\rho_i\}$ subordinate to atlas $\{(U_i, \phi_i)\}$, why can't we say that $\sum_i\rho_i\phi_i^*(\operatorname{vol})$ defines a global volume form on $M$? (in the same way that we prove the existence of a Riemannian metric on any manifold: locally define $g_i$ to be, for example, the Euclidean metric, then $g=\sum_i\rho_ig_i$ is a metric on $M$)","['manifolds', 'orientation', 'differential-geometry']"
2025115,Periodicity of Sine from infinite Product Formula: $z\prod_{n=1}^{\infty}\left( 1 - \frac{z^2}{n^2\pi^2}\right)$,"Let $\sin z$ be defined by the following infinite product: $$
\sin (z) = z \prod_{n=1}^{\infty} \left( 1 - \frac{z^2}{n^2\pi^2} \right)
$$ How can one derive that $\sin(z + 2\pi) = \sin(z)$?","['complex-analysis', 'periodic-functions', 'infinite-product']"
2025124,Bernoulli numbers.,"Today I read a short article about Bernoulli numbers. This article give the way to calculate Bernoulli numbers. $\displaystyle \frac{x}{e^{x}-1} = f(x)$ $\displaystyle f(x)(e^{x}-1) = x = \sum_{n = 0}^{\infty}B_{n} \frac{x^{n}}{n!} \sum_{k = 1}^{\infty} \frac{x^{k}}{k!} = \sum_{n=1}^{\infty}x^{n} \sum_{k+m = n}^{\infty}\frac{B_{m}}{k!m!} = \sum_{n=1}^{\infty} \frac{x^{n}}{n!} \sum_{m=0}^{n-1} \binom{n}{m} B_{m}$
Now we could calculate Bernoulli numbers for different $n$. But I don't understand the step with $k+m = n$. Please help me with it!","['number-theory', 'proof-verification', 'proof-explanation']"
2025127,Is there any consistent theory for multivariate multiple regression?,"Given $X \in R^{n*p}$, representing the regression coefficients as an $p*k$ matrix $B^*$. the multivariate multiple regression model takes the form
$Y=XB^* + W$, 
where $Y\in R^{n*k}$ denotes the multiple response matrix and $W\in R^{n*k}$ are matrices of zero-mean noise, respectively. G. Obozinski, M. J. Wainwright, and M. I. Jordan.
Support union recovery in high-dimensional multivariate regression. The Annals of Statistics, 39(1):1–47, 2011. The THEOREM 1 (Eq.(20)) of this paper provides an upper bound between the multivariate group Lasso solution $\hat{B}$ and regression matrix $B^*$. The upper bound depends on the correlations of design matrices $X$, however, does not consider the relations of response matrix $Y$. For multivariate multiple regression, is there any references providing the consistent theory or support recovery theory considering the relations of response matrix $Y$?","['probability-theory', 'probability', 'statistics']"
2025185,No complex roots of a polynomial implies its derivative has no complex roots,"It's a well known result that if a degree $n \geq 2$ polynomial $P(x)$ with real coefficients has $n$ distinct real roots, then its derivative $P'(x)$ will have $n-1$ distinct real roots. This is a consequence of Rolle's Theorem. I would like to know if the following statement true: If a degree $n \geq 2$ polynomial $P(x)$ with real coefficients has $n$ real roots (not necessarily distinct), may consist of multiplicities $>1$), then $P'(x)$ will have $n-1$ real roots (not necessarily distinct). I've spent a while looking for a proof or a counterexample to this online but had no luck in doing so. I've also tried working out a proof for myself but ran into trouble when considering multiplicities of roots greater than one.","['derivatives', 'polynomials', 'roots', 'real-numbers', 'calculus']"
2025234,How to find the P-Value for this test of hypothesis?,"I so we started a new section where I need to identify the (Null hypothesis, alternative hypothesis, test statistic, and p-value) I found all the information expect the p-value I couldn't understand my professor when he explained it. So here's the problem. Ex:In a recent poll of 755 randomly selected adults, 587 said that it is morally wrong to not report all income on tax returns. Use a 0.05 significance level to test the claim that 75​% of adults say that it is morally wrong to not report all income on tax returns. Identify the null​ hypothesis, alternative​ hypothesis, test​ statistic, P-value, conclusion about the null​ hypothesis, and final conclusion that addresses the original claim. Use the​ P-value method. Use the normal distribution as an approximation of the binomial distribution. I found most of the information this is what I have: $p = .75\;$
$\hat p = x/n,$ which gives you .777;
$q = .25,\;$
$n = 755,\;$ and
$x = 587.$ The significance level is 0.05, and I found the test statistic: its 1.71. I used the following formula $$z = ( \hat p - p)/\sqrt{.75(.25)/755} = 1.71.$$ The one I missing is the p-value which I don't how to obtain.
I know that this is a two tail test however this is the part I'm stuck on.
Could anyone share their expertise with me so I may learn to do it on my own?","['statistics', 'hypothesis-testing']"
2025264,"Let, $A\subset\mathbb{R}^2$. Show that $A$ can contain at most one point $p$ such that $A$ is isometric to $A \setminus \{p\}$.","A challenge problem from Sally's Fundamentals of Mathematical Analysis. Problem reads: Suppose $A$ is a subset of $\mathbb{R}^2$. Show that $A$ can contain at most one point $p$ such that $A$ is isometric to $A \setminus \{p\}$ with the usual metric. I'm really not sure where to begin. I've found a fairly trivial example of a set for which this is true: let $A$, for example, be $\{(n,0) : n \in \{0\} \cup \mathbb{Z}^+\}$. Then we may remove the point $(0,0)$ and construct the isometry $f(n,0) = (n+1, 0)$. This is clearly an isometry because $d((n,0),(m,0)) = d((n+1,0),(m+1,0))$, in other words, we are just shifting to the right. But now suppose we remove some $(p,0) \neq (0,0)$. Then we must have $d((m,0), (m+1,0)) = 1$ for all points $(m,0), (m+1,0)$, but since $(p,0)$ was removed we will always have a ""jump"" point where the distance between two successive points is $2$. But I'm not sure where to proceed. Isometries are equivalence relations, so maybe we can show that if $A \setminus \{p\}$ is isometric to $A \setminus \{q\}$, then $p = q$? I will say that given how often Sally's errant in his book and that some of the other challenge problems are open problems, this might not have a reasonable solution (if it's even true). Any ideas? To avoid any confusion, the problem isn't asking a proof for the set not being isometric to itself minus two points at the same time. It's asking for a proof that there is at most one unique point that you can remove from the set and then create an isometry. This was something I misinterpreted for a while. Edit: This is still stumping me. I'm beginning to wonder whether it's even true at all. Well, I've put a bounty on it, which hopefully serves as bit more incentive to try this problem out!","['real-analysis', 'isometry', 'contest-math', 'general-topology', 'analysis']"
2025285,$|x^*Ax|\leq |\lambda_{\max}|$ true?,Where $\|x\|_2=1$ and $A$ is an arbitrary $\mathbb C^{m\times m }$ matrix. Can you give me a proof or counterexample of this statement?,"['complex-analysis', 'numerical-linear-algebra', 'linear-algebra']"
2025304,Prove that $T$ has a cyclic vector iff its minimal and characteristic polynomials are the same,"Let $k$ be an algebraically closed field and $V$ be a finite-dimensional $k$-vector space of dimension $n$. Let $T:V \rightarrow V$ be a $k$-linear endomorphism of $V$. A vector $v \in V$ is called a cyclic vector for $T$ if the set of vectors $\{T^nv: n \in \mathbb{Z}, n \geqslant 0\}$ span $V$. 1 Show that if $v \in V$ is a cyclic vector, then $\{v, Tv,\cdots, T^{n-1}v\}$ form a basis for $V$. 2 If $T$ admits a cyclic vector, and $A:V\rightarrow V$ is a linear map commuting with $T$, show that there exists a polynomial $P(x) \in k[x]$ such that $A=P(T)$. 3 Show that a cyclic vector for $T$ exists if and only if the minimal polynomial of $T$ is equal to the characteristic polynomial of $T$.","['finite-fields', 'vector-fields', 'field-theory', 'linear-algebra']"
2025310,Taylor expansion of ln(1+x) and small O,"http://people.math.sc.edu/girardi/m142/handouts/10sTaylorPolySeries.pdf The Taylor expansion of $\ln(1+x)$ is $\sum_{n=1}^{\infty} (-1)^{n-1}\frac{x^n}{n}$. Is it true that we can think of $\ln(1+x) = x+o(x^2)$, what does this mean pricesly? I find that such thing is an usual trick throughout mathematical analysis, but I can not find any related material on Baby Rudin. Does any one have any rigorous reference on this?","['real-analysis', 'calculus', 'analysis']"
2025318,constructing a matrix given its column space and null space,"This is not homework, class or a project. I've been out of college for some time now and decided to learn math on my own time. I can't figure out how to solve the following problem: Construct a 4 x 4 matrix A whose column space R and null space N are given by $$ R = \alpha \begin{bmatrix} 1\\2\\0\\0 \end{bmatrix} + \beta \begin{bmatrix} 0\\1\\2\\0 \end{bmatrix}$$ $$ N = \alpha \begin{bmatrix} 1\\2\\0\\0 \end{bmatrix} + \beta \begin{bmatrix} 0\\1\\2\\0 \end{bmatrix}$$ How do I approach this problem?","['linear-algebra', 'vector-spaces']"
2025331,Should I study projective geometry or commutative algebra as prerequisite to start algebraic geometry?,"I am looking to study Algebraic Geometry but some books list projective geometry as a prerequisite and some list commutative algebra. I have taken one semester of abstract algebra, real analysis, complex analysis, topology, combinatorics, and differential geometry. I have not taken a course in projective geometry nor commutative algebra. Which would be more important as a prerequisite if I want to start learning algebraic geometry? Do you have any books to recommend?","['algebraic-geometry', 'reference-request', 'book-recommendation', 'soft-question', 'learning']"
2025337,Number of Polynomials and continuous functions on $\mathbb R$,"The question is what is the cardinalyty of $1)$ $\mathcal P=$ The set of all polynomials with real co-efficient and $2)$ $\mathcal R=$ The set of all  real valued continuous functions Now a polynomial's standard form is $a_nx^n+a_{n-1}x^{n-1}+a_{n-2}x^{n-2}+....+a_0$ where $x$ is the variable and $a_i\in \mathbb R \forall i.$ So for a fixed $n$ , the cardinality of such polynomials is $|\mathbb R^n|=c.$ The set of all polynomials is bijective with the set $\bigcup_{n=0}^{\infty}\mathbb R^n.$ Hence the cardinality is $$\left|\bigcup_{n=0}^{\infty}\mathbb R^n\right|\\=\sum_{n=1}^{\infty}1.c\\=|\mathbb N|\cdot c\\=c$$ Am I correct here. But every continuous function can be wrtten as the limit of a sequence of polynomials. So, $\mathcal R=\bar {\mathcal P}$ So we can say that $$\mathcal R\supset \mathcal P\\\implies |\mathcal R|\ge |\mathcal P|=c.$$ Now what do I do to find an equality $?$ Thanks.","['general-topology', 'real-analysis', 'cardinals', 'functions']"
2025340,Rough trend calculation and approximation error,"In many cases calculating trend by using least-squares method is best decision. But sometimes it is overabundant. What I need is just to know, whether trend is positive or not.
Can I use such approach (difference in weight coefficient) and how to determine it's approximation error? ($x_1*1$ + $x_2*2$ + ... + $x_n * n$) - ($x_1*n$ + $x_2*(n-1)$ + ... + $x_n * 1$) Examples: Negative 19  17  11  1  4  4  6  3  2  2    => -283 Positive 0  0  1  3  1  1  7  5  6  12      => 182 Update Calculation using this approach and least-squares approach",['statistics']
2025356,maximum value of $xy+yz+zx.$ given $x+2y+z=4$,"if $x+2y+z=4$ and $x,y,z$ are real number. then find maximum value of $xy+yz+zx$ putting $x+z=4-2z$ in $y(x+z)+zx = y(4-2z)+zx = 4y-2yz+zx$ i wan,t be able to  go further,could some help me with this",['algebra-precalculus']
2025370,"Is the action of $SO(3, \mathbb R)$ on $S^2:=\{(x,y,z) \in \mathbb R^3 |x^2+y^2+z^2=1\}$ defined as $(A,x) \to Ax$ transitive?","Consider the action of $SO(3, \mathbb R)$ on $S^2:=\{(x,y,z) \in \mathbb R^3 |x^2+y^2+z^2=1\}$ as $(A,x) \to Ax$ . Is this action transitive ? i.e. is it true that for every $x,y \in S^2$ , $\exists A \in SO(3,\mathbb R)$ such that $Ax=y$ ?","['group-actions', 'infinite-groups', 'group-theory']"
2025393,Arrangement of word MISSISSIPPI in which no three S occur together,"how many different word can be formed by jumbling the letter of the word MISSISSIPPI in which no three $""S""$ occur together No. of arrangement of the words MISSISSIPPI is $ = \frac{11!}{4!\cdot 4!\cdot 2!}$ now arrangement of the words in which all $ ""S""$ are together is $ = \frac{8!}{4!\cdot 2!}$ total no. of arrangements of the words in which all four $""S""$ are occur together is $ = \frac{11!}{4!\cdot 4!\cdot 2!}-\frac{8!}{4!\cdot 2!}$ i want be able to go further , could some help me with this, Thanks",['combinatorics']
2025402,"Prove that if $a$ is odd, then $a^2\equiv 1\pmod 8$ [duplicate]","This question already has answers here : Proof by Cases involving divisibility (2 answers) Closed 7 years ago . Prove that if $a$  is odd, then $a^2\equiv 1\pmod 8$ I got this question in my discrete mathematics class, can anyone help me? Thanks.","['divisibility', 'discrete-mathematics']"
2025408,Proving that an isometry between compact spaces is a homeomorphism,"I've recently attempted to prove that if $f: X_1 \to X_2$ is isometric, $X_1, X_2$ compact, then $f$ is a homeomorphism. But before this, I have a few questions: 1) is this even necessarily true?
2) does an isometry have to be a homeomorphism? I've seen it defined as such, but it's not clear to me why it must be. Specifically surjectivity is a pain to show, as I've come to find. I think compactness is important here somehow but I can't quite figure it out. Here is what I've got: Suppose there is an isometry $f: X_1 \to X_2$. Clearly $f$ is continuous, for given any $\varepsilon>0, x,y \in X_1$ we can choose $\delta = \varepsilon$ so that $d(x,y) < \delta$ implies $ = d(f(x), f(y)) < \delta = \varepsilon  $, in their respective metrics. Injectivity is also clear, for if $f(x) = f(y)$, then $d(f(x), f(y)) = d(x,y) = 0$ implies $x=y$ by the definition of a metric. The existence and continuity of $f^{-1}$ is also now clear, for $f$ is injective and $X_1$ and $X_2$ are compact. Now we show that $f$ is surjective, and hence a homeomorphism. Suppose for the sake of contradiction that there exists a $p \in X_2$ such that $p \neq f(x)$ for any $x \in X_1$. Then there is some minimum distance $r = d(p,f(X_1))$ between $p$ and the image of $X_1$ under $f$. By compactness, we obtain a countable dense subset $\{q_1, q_2, ... q_n, ...\}$ of $X_2$. Constructing balls of radius $r$ around each $q_i, i \in \mathbb{N}$, we obtain an open cover of $X_2$. Then since $X_2$ is compact, $X_2 \subset \bigcup_{i=1}^N B_r(q_i)$. It follows that $p \in B_r(q_n)$ for some $n  \le n \le N$. Then since $f(X)$ is compact by the continuity of $f$, it is closed so that its complement $f(X)^c$ is open in $X_2$, and hence  $B_r(q_n) \subset f(X)^c$. So at the end there I was just finding every fact I could, but I'm not sure if they'll be useful. I don't think uniform continuity will come into it, but then again I don't know. Some guidance would be much appreciated!","['general-topology', 'real-analysis', 'analysis']"
2025448,How many relations in ${\mathscr P}(A \times A)$ are symmetric?,"How many relations in ${\mathscr P}(A \times A)$ defined on $A$ are symmetric? $A$ = $\{1,2,...,n\}$ and ${\mathscr P}(A \times A)$ is the power set of the cartesian product of $A$ with itself. A symmetric relation in this case would be $\forall x \forall y, \{x,y\} \in X \implies \{y,x\} \in X$ for $X$ in  ${\mathscr P}(A \times A)$. EDIT: I think the answer is $2^{\frac{n(n+1)}{2}}$, because you have $2^{\frac{n(n-1)}{2}}$ number of sets containing only $\{x, y\}$ where $x < y$ and $2^n$ number of sets containing only $\{x, y\}$ where $x = y$","['relations', 'combinatorics', 'elementary-set-theory', 'discrete-mathematics']"
2025476,"Is the function $f(n)=$ ""First prime greater than or equal to $n$"" from the natural numbers to the prime numbers bijective? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Define $f:\mathbb{N} \to \mathbb{P}$ as f(n)=First prime greater than or equal to it. $\mathbb{P}$: Set of prime numbers Is this function bijective?","['functions', 'elementary-number-theory']"
2025495,Fourier Transformation in exponential form negative infinity,"I have a quick question about Fourier series. Given that
$$f(x) $$ satisfies 4 conditions required for transformation, we know that f(x) can be expressed in terms of sines and cosines: $$ f(x) =a_0/2+ \sum^\infty_{n=1} a_n cos(wnx) + b_nsin(wnx), w = \frac{2\pi}{L}$$
Furthermore, using Euler's Identity, $$e^{ix} = cos x + isin x $$ and we can convert the equation to: $$ f(x)= \sum ^ \infty_{n=-\infty} c_n exp(wnx)$$. My question is, in the expression involving sines and cosines, note that index n is iterated from 1 and to the infinity. However, in bottom expression, the index n starts from 0 and is iterated in both directions. Of course, we know some results such as a_n = real(c_n + c_{-n})/2 and others from this. However, even before that, why is it that we can't iterate n in positive direction only instead of stretching the summation in both directions? i.e. $$f(x)= \sum ^ \infty_{n=0} c_n exp(wnx) $$ Is there a reason that we have to go in both direction instead of one direction, say positive direction? sidenote: I am sure that this is a mistake. Please correct me $$
e^{i\pi} = e^{2(1/2)i\pi} = ((e^{i\pi})^2)^{1/2} = ((-1)^2)^{1/2} = 1^{1/2} = 1.
$$","['fourier-series', 'trigonometry', 'complex-numbers']"
2025543,Understanding answer to question showing equality of two measures on the Borel $\sigma$ algebra on $\mathbb{R}$,"I understand that this question has been asked before, however my question is in reference to a specific answer given here. Proving two measures of Borel sigma-algebra are equal In particular it is the last answer (which the OP provided). Conveniently their answer has numbers so I when I am referring to numbers I am referring to the numbers they used. In part 5 they said that 
$$m(\cup_{i=1}^{\infty}(A_{i}\cap I))=\sum_{i=1}^{\infty}m(A_{i}\cap I)$$ This is only true if the $A_{i}\cap I$ are disjoint? Which they are not necessarily so. Also at the start they wrote $A_{i} \in A$, shouldn't it be in $S$. (It is my understanding that they are trying to show that $S$ is a $\sigma$-algebra). Also on a more fundamental level, what good does showing $S$ is a $\sigma$-algebra do? In part (7) they use the fact that $m(A\cap I)=n(A\cap I)$ but isn't this only true for elements in $S$? To me it seems that this shows $m(A)=n(A)$ for all elements in $S$ which is not necessarily all elements in $\mathcal{B}$.",['measure-theory']
2025590,Apparent (minor) error in Cauchy's article on pressure or tension in a solid body,"In his article De la pression ou tension dans un corps solide [On the pressure or tension in a solid body] , Cauchy introduces a theory that allows to define Cauchy stress tensor .  It looks like he makes a mistake in his formula for the ""surface element"" in his surface integrals, unless I am missing something.  Can someone check and confirm this, please?  I didn't find any errata or comments about this apparent error. The ""surface element"" in his surface integrals (in Cartesian coordinates) is written as $\cos\gamma\,dy\,dx$, where $\gamma$ is the angle between the normal vector to the surface and the positive direction of the $z$-axis.  On page 62 , formula (4), he seems to claim that the surface area is given by the integral
$$
\int\!\!\!\int\cos\gamma\,dy\,dx = s.
$$
Of course this is not true: the surface area is given by the integral
$$
\int\!\!\!\int\frac{dy\,dx}{\cos\gamma} = s,
$$
and the ""surface element"" is $\frac{dy\,dx}{\cos\gamma}$. Since one should be free to use any symbol for the ""surface element"" as long as one does not try to interpret it, such an error would normally not lead to any other errors, so it seems plausible that it might pass unnoticed...","['surface-integrals', 'tensors', 'math-history', 'analysis']"
2025602,Convergence of infinite sum (factorial and root),"Find the convergence of the following sequence:
$$\sum_{n=1}^{\infty}\left(\dfrac{n!}{(2n)!}\right)^{\frac{1}{n}}$$
I tried to use the ratio test. It wasn't useful. Also I used the logharitmic test (I'm not sure this is the standard name for it): $\lim_{n\to\infty}\dfrac{\ln\frac{1}{u_n}}{\ln n}=l$. If $l>1$,     $\sum_{n=1}^{\infty}u_n$ converges. It didn't work to well. Thanks for your help!","['logarithms', 'sequences-and-series', 'calculus']"
2025622,"If $M$ is a proper subspace of $\mathbb{C}^n$, then there is a nonzero linear functional $f$ on $\mathbb{C}^n$ such that $f(M)=0$","If $M$ is a proper subspace of $\mathbb{C}^n$, then there is a nonzero linear functional $f$ on $\mathbb{C}^n$ such that $f(M)=0$ I've tried to prove it by Hahn-Banach's theorem. Are  there any other simpler ways to prove it?","['functional-analysis', 'linear-algebra']"
2025632,Show that $\Bbb Q^n \cup (\Bbb R-\Bbb Q)^n$ is connected,I have difficulty with this problem and I have not idea to show this. How can I show that  $\Bbb Q^n \cup (\Bbb R-\Bbb Q)^n$ is connected? If $n=1$ it's obvious because the sum is $\Bbb R$ is connected. But in general?,"['general-topology', 'connectedness']"
2025652,Equivalent binary quadratic forms,"Given $f(x,y)=ax^2+bxy+cy^2$ we know that it is not necessarily equivalent to $f(-x,y)$ even if they represent the same numbers. For example our textbook says that $x^2+xy+2y^2$ is equivalent to $x^2-xy+2y^2$, but $3x^2+xy+4y^2$ is not equivalent to $3x^2-xy+4y^2$. How can I see this? Actually I thought $f(x,y)$ and $f(-x,y)$ cannot be equivalent, since the transformation has determinant $-1$. I hope someone can clarify.","['number-theory', 'abstract-algebra', 'quadratic-forms']"
2025678,There is no real $3\times3$ matrix $A$ for which $A^2=-I$.,"I'm asked to prove or disprove this but I'm stuck.
I feel like this is actually true but i'm not sure as to how I can formulate a proof for this statement. Any leads?","['matrices', 'linear-algebra']"
2025695,Show that $\|(\lambda - T)^{-1}\| \leq 1/(1-|\lambda|)$,"Let $X$ be a Banach space and let $T \in L(X)$ satisfy $\|Tx\| =\|x\|$ for each $x \in X$. Suppose that the range of $T \neq X$ and let $0 < |\lambda| < 1$. Assuming that $λ \in \rho(T)$, show that $\|(λ − T)^{−1}\| \leq 1/(1−|λ|)$. Here $\rho(T)$ is the resolvent set of $T$. I need this intermediate step in proving that $\sigma(T)$ is the unit disk.",['functional-analysis']
2025735,"Lebesgue-measure: Prove $\lambda(A) + \lambda(B) \le \lambda(A + B)$ for $A = \bigcup_{k=1}^{n_1} I_k$, $B = \bigcup_{k=1}^{n_2} J_k$","Assume that $A = \bigcup_{k=1}^{n_1} I_k$ , $B = \bigcup_{k=1}^{n_2} J_k$ , are disjoint unions with $I_k, J_k \subset \Bbb R$ . Let $\lambda$ be the Lebesgue-measure. Show that $\lambda(A) + \lambda(B) \le \lambda(A + B)$ . In order to do so, construct disjoint unions $A = A_1 \cup A_2$ and $B = B_1 \cup B_2$ such that $(A + B) \supset (A_1 + B_1) \cup (A_2 + B_2)$ . Then, use induction to show the inequality. Edit: This whole thing seems to be called ""Brunns-Minkowski-inequality"". We already know that $ a)$ $\lambda(A) + \lambda(B) \le \lambda(A + B)$ with $A = [a_1, b_1), B = [a_2, b_2).$ I didn't solve this either, wrote it down here: Prove that $\lambda(A + B) \ge \lambda(A) + \lambda(B) $ for A and B being half-open intervals Now, for this sub-excercise, I started the following way: For $n = 2$ , we get that $n_1 = n_2 = 1$ , and thus, we get: $\lambda(\bigcup_{k=1}^{n_1} I_k) + \lambda(\bigcup_{k=1}^{n_2} J_k) = \lambda(A) + \lambda(B)$ , and thus, the inequality follows from $a)$ . For $n \rightarrow n+1$ : We can either work with $n_1 + 1$ or $n_2 + 1$ , so let's just define $(n+1) := (n_1 + 1) + n_2$ . As long as I understood it so far, we use the same union of $J_k$ for $B$ , but a different kind of union of $I_k$ for $A$ . Besides that, we are still talking about the same $A$ here. We have to show: $\lambda(\bigcup_{k=1}^{n_1+1} I_k) + \lambda(\bigcup_{k=1}^{n_2} J_k) \le \lambda(\bigcup_{k=1}^{n_1+1} I_k + \bigcup_{k=1}^{n_2} J_k)$ . Now, my intuitive approach would be to write $\bigcup_{k=1}^{n_1} I_k \cup I_{n+1}$ , and with the help of using the induction hypothesis, we would get that this is $\le \lambda(\bigcup_{k=1}^{n_1+1} I_k + \bigcup_{k=1}^{n_2} J_k) + \lambda(I_{n+1})$ . Unfortunately, this is nonsense because we cannot assume that $\lambda(I_{n+1}) = 0$ , and thus, we wouldn't get the desired expression. Looking further into it tells me why this is nonsense: In the induction hypothesis, we assumed that $A = (\bigcup_{k=1}^{n_1} I_k)$ . Now, of course we could also assume that $A = (\bigcup_{k=1}^{n_1+1} I_k)$ and say that this is just a different union of $A$ , but when we now take a look at $(\bigcup_{k=1}^{n_1} I_k \cup I_{n+1}))$ , then it seems like this left union cannot be the same union as the one we assumed to have in the induction hypothesis. This would only hold for $I_{n+1} = \{\emptyset\}$ , but I don't think that we are allowed to assume so. So I guess we have to work with these disjoint unions mentioned above, but I don't know how to do it. I mean, I found that I could construct these disjoint unions with the specific properties by dividing $A$ and $B$ by $2$ (at least I think I did), but I don't see how this helps me here.","['inequality', 'lebesgue-measure', 'induction', 'measure-theory', 'elementary-set-theory']"
2025739,"Let $p_n$ denote the $n$th prime number. For $n \ge 3$, prove that $p_{n+3}^2 \lt p_np_{n+1}p_{n+2}$","Let $p_n$ denote the $n$th prime number.  For $n \ge 3$, prove that $p_{n+3}^2 \lt p_np_{n+1}p_{n+2}$. The book gives a hint as $p^2_{n+3} \lt 4p_{n+2}^2 \lt 8p_{n+1}p_{n+2}$, but I don't understand how to show that the hint is true either. The only inequality relationship with prime squares that I know is Bonse's inequality but I can't seem to derive either the hint or the main problem from this.","['number-theory', 'prime-numbers']"
2025803,Consequence of the Hahn-Banach Theorem,"From wikipedia's page on the Hahn-Banach Theorem: If $V$ is a normed vector space with linear subspace $U$ (not necessarily closed) and if $z$ is an element of $V$ not in the closure of $U$, then there exists a continuous linear map $ψ : V → K$ with $ψ(x) = 0$ for all $x$ in $U$, $ψ(z) = 1$, and $||ψ|| = dist(z, U)^{−1}.$ How is this a consequence of the Hahn-Banach Theorem?","['functional-analysis', 'vector-spaces']"
2025810,Locking on a uniformly linearly moving object by rotating the aim from above,"Setting . Suppose we have a scene and a spotlight above it that can be turned onto any object on the scene. On the scene we have an object that moves uniformly and linearly. We are given the angular velocity of the spotlight, the speed of the object and initial positions of both. The question is what is the minimal amount of time before we can put the object in the center of the light spot, and at what angle the spotlight should be moved? Mathmatical formulation . Given . Let consider 3d space with Cartesian coordinate system so that the object moves on the plane $xOy$ parallel to the $x$-axis, spotlight is hang at the point $(0,0,h)$ and shines onto $(x_1,y_1,0)$, i.e. onto  $(x_1,y_1)$ on the plane $xOy$. The spotlight angular velocity is $\varphi$. The object initially starts at the point $(x_2,y_2)$ and moves at the speed $v$, so the velocity vector is $(v, 0)$ (or globally $(v, 0, 0)$). To find . The minimal amount of time $t$ before we can put the object in the center of the light spot is the unknown. By that time the object will reach the position $(x_2+t\cdot v, y_2)$, so the spotlight would have to move directly from  $(x_1,y_1)$ onto $(x_2+t\cdot v, y_2)$ by turning through an angle $\beta$, which is the angle between vectors $(x_1,y_1,-h)$ and $(x_2+t\cdot v, y_2, -h)$. Equation . The above gives us the following equation:
$$
\frac{\beta}{\varphi} = t,
$$
where $\beta$, as was defined before, is the angle between vectors $(x_1,y_1,-h)$ and $(x_2+t\cdot v, y_2,-h)$. Using the formula for cosine between two vectors —  $\cos{\beta}=\frac{\overline{a}\cdot \overline{b}}{|\overline{a}|\cdot|\overline{b}|}$ —  we get: $$
\frac{1}{\varphi}\cos^{-1}\frac{x_1(x_2+t\cdot v)+y_1\cdot y_2 + h^2}{\sqrt{\left(x_1^2+y_1^2+h^2\right)\left((x_2+tv)^2+y_2^2+h^2\right)}} = t,
$$ This is too hardcore to my taste and I have no idea how to solve it. Of course I could use the fixed-point iteration to approximate $t$, but I was hoping for the exact solution. Besides I could also run an iterative procedure before formulating this formula, by moving the spotlight onto the current object position, see where the object occures after this and next time move the spotlight onto that new position, and so on. But again this would only approximate the desired result. Is there a way to solve this monstrous equation? Maybe we can reformulate the problem so the equation simplifies? Thank you very much in advance!","['trigonometry', 'algebra-precalculus', 'euclidean-geometry', 'geometry', 'classical-mechanics']"
2025814,"Locally Euclidian, Hausdorff and Second Countable are independent conditions","When defining a smooth manifold $M$, one usually requires $M$ to be a topological space satisfying these $3$ conditions: 1) Locally euclidean 2) Hausdorff 3) Second countable I want to verify that these are independent conditions, i.e., that one can find a topological space for each combination: a) Locally Euclidean + not Hausdorff + not second countable b) Not locally Euclidean + Hausdorff + not second countable (Ex.: $\mathbb{R}$ with coarse topology) c) Not locally Euclidean + not Hausdorff + second countable d) Locally Euclidean + Hausdorff + not second countable (Ex.: the long line $\omega_1\times[0,1)\setminus\{(0,0)\}$) e) Locally Euclidean + not Hausdorff + second countable f) Not locally Euclidean + Hausdorff + second countable (Ex.: union of two concurrent lines in $\mathbb{R}^2$) I'm still stuggling with a), c) and e), since non-Hausdorff spaces are always so hard to think about... Any ideas?","['general-topology', 'examples-counterexamples', 'smooth-manifolds']"
2025819,Proof that every function of a symbolic form $A$ has an antiderivative with a unique symbolic form $A'$,"I'm just learning about antiderivatives. I'm curious as to how to show that for any function having a particular symbolic structure there exist only one antiderivative corresponding to that symbolic structure. For example: to show that there is a unique relationship between all functions of the form $f'(x)=x^{n}$ and their antiderivatives $f(x)=\frac{x^{n+1}}{n+1}+C$. That is to say: if you could invent some sort of higher level form of function which takes a function as an input and gives the derivative of the function as an output, the function should be one to one for each symbolic class. Another example: with $\ln x$ as the antiderivative of $\frac{1}{x}$, how can we show $\ln x$ is the only function satisfying that relationship. Answering this question is beyond my current mathematical abilities. I can show that a certain antiderivative belongs to a function by differentiating the antiderivative and equating it to the function. However to show that this operation is one to one over symbolic classes I have no idea where to begin.","['general-topology', 'real-analysis', 'elementary-set-theory', 'functions']"
2025821,Corollary of Theorem 2.12 in Baby Rudin,"In Rudin´s Principles of Mathematical Analysis, Theorem 2.12 shows that if $\{E_n\}$ is a sequence of countable sets, then $$ S=\bigcup_{n=1}^{\infty} E_n \quad \text{is countable} $$ Theorem 2.12 is followed by a corollary stating that $T=\cup_{\alpha\in A}B_\alpha$, where $A$ is at most countable (finite or countable) and $B_\alpha$ is at most countable for each $\alpha\in A$, is at most countable because $T$ is equivalent to a subset of S, which is countable. It is of course a very intuitive idea that $T$ and a subset of S can be put in $1$-$1$ correspondence, but I'm having trouble defining a bijection between them. Can somebody give an example of a bijective function from $T$ to a subset of $S$ ? THANKS and i hope my question isn't too dumb.","['elementary-set-theory', 'real-analysis', 'analysis']"
2025823,Show $\int_{-a}^{a} [f(x)-f(-x)] dx=0$ for any continuous function f(x),"Show that for any continuous function $f(x)$ on $[-a, a]$, where $a>0$, $$\int_{-a}^{a} [f(x)-f(-x)] dx=0$$ I've tried to do something like: Let the primitive function of $f(x)$ be $F(x)$. $\int_{-a}^{a} [f(x)-f(-x)] dx$ $=[F(x)]_{-a}^{a}-[F(-x)]_{-a}^{a}$ $=F(-a)-F(a)-F(a)+F(-a)$ $=2F(-a)-2F(a)$ but I don't know how to continue.","['integration', 'definite-integrals', 'functions']"
2025842,common eigenvectors of commuting operators,"I am pretty sure that my problem has already discussed, but I didn't find.
So, the question is how to prove that two commuting operators have a common eigenvector. The first note is following: Let $A$ be the operator such that $Av = \lambda v$ (we are considering algebraically closed case, so such $v$ surely exists). Then $ABv = BAv = \lambda Bv$, so $Bv$ is eigenvector of $A$ with eigenvalue $\lambda$ as well. But I am not sure, what to do next.",['linear-algebra']
2025855,Is the image f(A) of a n-Lebesgue measurable function m-Lebesgue measurable when f is Lipschitz?,"Suppose $f:\mathbb{R}^n \rightarrow \mathbb{R}^m$ is Lipschitz, where $n\geq m$ . Let $\lambda_n$ and $\lambda_m$ denote the Lebesgue measure on $\mathbb{R}^n$ and $\mathbb{R}^m$ respectively. If $A\subset\mathbb{R}^n$ is $\lambda_n$ --measurable,  is $f(A)$ $\lambda_m$ --measurable? This statement appears in Evans-Gariepi's book on Measure Theory and fine properties of functions (Lemma 2 (i) in section 3.4.1) Using the machinery of Analytic sets I think the statement is true if $A$ is analytic, but without that machinery a prove for any $\lambda_n$ -measurable set that uses the fact that $f$ is Lipschitz escapes me at the moment. Just found out that the statement is actually incorrect. Evans-Gariepi already listed the statement above as errata and removed the statement in their second edition.",['analysis']
2025877,Does there exist a polynomial sequence $P_n$ satisfying this?,"Rudin - RCA p.276 exercise 3 Does there exist a sequence of polynomials $P_n$ such that $P_n(0)=1$ for $n=1,2,...$, but $P_n(z)\rightarrow 0$ for every $z\neq 0$, as $n\to \infty$? The chapter this exercise is included is about Runge's Theorem. However, Runge's Theorem gives no information about pointwise convergence, so I think it is true. But I have a trouble constructing one. How do I prove this?","['complex-analysis', 'examples-counterexamples']"
2025900,How to compute $\prod_{n=2}^{\infty} \left(1-\frac{1}{n^n}\right)$?,"Does
       $$\prod_{n=2}^{\infty} \left(1-\frac{1}{n^n}\right)$$
have any closed form in terms of known mathematical constants?","['infinite-product', 'sequences-and-series']"
2025911,Sequence converging fast to $u:=\int_0^1 \tan(x^2)dx$,Is there a sequence converging fast to $$u:=\int_0^1 \tan(x^2)dx$$ ? The only sequence I know is the antiderivate of the Mac-Laurin-series for $\tan(x^2)$. But the terms upto $x^{99}$ only give an accuracy of $\ 2\cdot 10^{-12}$. I am looking for a sequence converging faster to $u$.,"['numerical-methods', 'integration', 'sequences-and-series', 'calculus']"
2025942,Computations of derivatives on traces and determinants,"$\newcommand{\tr}{\operatorname{tr}}$I am looking for some indications on how to approach the following derivatives:
$$\frac{\partial}{\partial \bf{W}} (\tr(\bf{Y}^T(\bf{WW^T}+\sigma^2 I)^{-1}\bf{Y}))$$ and
$$\frac{\partial}{\partial \bf{W}} \log(|\bf{WW^T} + \sigma^2I|)$$ I have been using matrix cookbook For the first one, using eq.59 from the above document i believe that i have the following \begin{align}
& \frac{\partial}{\partial \bf{W}} (\tr(\bf{Y}^T(\bf{WW^T}+\sigma^2 I)^{-1}\bf{Y})) \\[10pt]
= {} & \bf{Y^T}(\bf{WW^T}+\sigma^2 I)^{-1}\frac{\partial (\bf{WW^T}+\sigma^2 I)}{\partial \bf{W}} (\bf{WW^T}+\sigma^2 I)^{-1} \bf{Y} 
\end{align} Set $\Sigma = \bf{WW^T}+\sigma^2 I$ And obtain $2\bf{Y^T\Sigma^{-1}W\Sigma^{-1}Y}$, implying that $\bf{W}$ is symmetric thus $\frac{\partial \Sigma}{\partial W}=2\bf{W}$ For the second one, using eq.46, I obtain $$\frac{1}{|\Sigma|}|\Sigma|\tr\left(\Sigma^{-1}\frac{\partial \Sigma}{\partial \bf{W}}\right) = \tr(\Sigma^{-1}\bf{W})$$ Are these computations correct?","['derivatives', 'matrices', 'matrix-calculus', 'determinant', 'trace']"
2025960,Linear algebra Geometric question - Brazilian Olympiad,"I've seen this question in the Brazil Undergrad Olympiad this year. There is also a solution provided in the official webpage , but I didn't get it. Please, I'd appreciate it if someone could give a solution. Let $A: \mathbb R^3 \to \mathbb R^2 $ given by $A(x,y,z) = (x+y+z,x+y)$. Prove that there exists an only s $\ge0$ such that the limit $c=\lim\limits_{\epsilon \to 0} \cfrac {vol(\{ v\; \in\;\mathbb R^3 ; \;|v|\; \le\; 1 \; \text{and } |Av| \;\lt \; \epsilon\})  }{\epsilon^s}$ exists, is positive, and compute s and c. Thanks in advance.","['real-analysis', 'limits', 'hausdorff-measure', 'contest-math', 'linear-algebra']"
2025975,Countable partition in atoms,"Let $\mu: \Sigma \to [0, \infty)$ a measure over $\Omega$. We say a set $A \in \Sigma$ is an atom if for all $B \in \Sigma$ with $B \subset A$, $\mu(B)=\mu(A)$ or $\mu(B)=0$. We say that $\mu$ is atomic if every set $A \in \Sigma$ with positive measure contains an atom with positive measure. So, I'm trying to prove that if $\mu$ is atomic, there exists $\{ A_n\}_{n \in \mathbb{N}}$ pairwise disjoint atoms such that its union covers $\Omega$. I can build a sequence this way: Let $A \in \Sigma$ be a set with positive measure. It contains an atom $A_1$.Then I pick up $\Omega \setminus A_1$. Again, it contains an atom $A_2$ which is disjoint from $A_1$. However, I do not know how to continue. I would appreciate any help.","['measure-theory', 'analysis']"
2025976,Derivative of function defined on only rational numbers,"Let $f:\mathbb{Q}\to\mathbb{R}$ be uniformly continuous and assume that $f':\mathbb{Q}\to\mathbb{R}$ is uniformly continuous as well. Let $a$ be an irrational number. I need help to prove that $$\lim_{q\to a}f'(q)=\lim_{q\to a}\frac{(\lim_{p\to a}f(p))-f(q)}{a-q}$$ Motivation for the question: $f'(a)$ does not exist, but both the left-hand side and the right-hand side of the equation is an intuitively reasonable substitute for it: on the LHS we first differentiate and then take the limit to $a$, and on the RHS we first take the limit to $a$ and then differentiate. It would therefore be nice to prove that they are equal.","['derivatives', 'real-analysis', 'limits']"
2026007,All $11$ Other Forms for the Chudnovsky Algorithm,"Continued from this post Ramanujan found this handy formula for $\pi$$$\frac 1\pi=\frac {\sqrt8}{99^2}\sum_{k=0}^{\infty}\binom{2k}k\binom{2k}k\binom{4k}{2k}\frac {26390k+1103}{396^{4k}}\tag1$$ Which is related to Heegner numbers. Sometime after, the Chudnovsky brothers came up with another $\pi$ formula$$\frac 1\pi=\frac{12}{(640320)^{3/2}}\sum_{k=0}^\infty
(-1)^k\frac {(6k)!}{(k!)^3(3k)!}\frac {545140134k+13591409}{640320^{3k}}\tag2$$
And according to Tito, $(2)$ has a total of $11$ other forms with integer denominators. Question: What are all $11$ forms? And what $e$-transcendal number to they correspond to?","['number-theory', 'sequences-and-series', 'modular-forms', 'pi']"
2026011,Prove using induction: $\prod_{k=1}^n\cos\frac{x}{2^k}=\frac{\sin x}{2^n\sin\frac{x}{2^n}}$,"I'm supposed to prove by induction the equality $$\prod_{k=1}^n\cos\frac{x}{2^k}=\frac{\sin x}{2^n\sin\frac{x}{2^n}}$$ I've shown the base case for $n=1$, assumed it is valid for $n$ then tried extending for $n+1$. I've used trigonometric identities to obtain the expression $$\left(2-2\cos\frac{x}{2^n}\right)\cos^2\frac{x}{2^k}=\sin ^2\frac{x}{2^k}$$ and it seems to me that I'm close, but I'm stuck here. Any help please?","['induction', 'trigonometry']"
2026014,Dimension of a Variety defined by the Weierstrass Equation,"I want to see why the following is true: A Variety described by the Weierstrass equation has dimension 1. Let $K$ be a field. An elliptic curve over $K$ is defined by the set of solutions in $\mathbb{P}^2(K)$ of a homogeneous Weierstrass equation $$E: Y^2 Z + a_1 XYZ + a_3 YZ^2 = X^3 + a_2 X^2 Z + a_4 XZ^2 + a_6 Z^3$$ with $a_1,a_2,a_3,a_4,a_5,a_6\in K$ . And we claim $E$ to be non-singular. As definition of the dimension: Let $V$ be an affine (projective) variety. We define the dimension $dim(V)$ as the biggest length $n$ of a chain $S_0\supset S_1 \supset \dots \supset S_n$ of distinct irreducible closed subspaces of $V$ . In Galbraith book Exercise 5.6.5 says: Let $f$ be a non-constant polynomial and let $X=V(f)$ be a variety in $\mathbb{A}^n$ . Show that $dim(X)=n-1$ . A proof for this is given in Hartshorne's ""Algebraic Geometry"" Proposition 1.13. But I don't understand all the algebra used for the proof: Proof: If $f$ is an irreducible polynomial, we have already seen that $Z(f)$ is a variety. Its ideal is the prime ideal $\mathfrak{p}=(f)$ . By ""Krull's Hauptidealsatz"" $\mathfrak{p}$ has height 1, so by 1.8A, $Z(f)$ has dimension $n-1$ . ( 1.8A: Let $k$ be a field, and let $B$ be an integral domain which is a finitely generated $k$ -algebra. Then: (a) the dimension of $B$ is equal to the transcendence degree of the quotient field $K(B)$ of $B$ over $k$ ; (b)For any prime ideal $\mathfrak{p}$ in $B$ we have $$
\operatorname{height}\mathfrak{p}+ \operatorname{dim} B/\mathfrak{p} = \operatorname{dim} B
$$ ) I don't understand the part (b) of the theorem 1.8A, what does the equation mean? What is $\operatorname{dim} B/\mathfrak{p}$ , what does this notation mean?.
Maybe there is a  different approach to proof this Proposition? I saw hints for this proof where they explain: Let $f\in k[x_1,x_2,\dots,x_n].$ Without loss of generality suppose $f$ contains at least one monomial featuring $x_n$ . Then write $f=f_r x_{n}^{r}+f_{r-1}x_{n}^{r-1}+\dots + f_0$ with $f_i\in k[x_1,\dots,x_{n-1}]$ or $k[x_0,\dots,x_{n-1}]$ . One can check that the field $k(X)$ contains a subfield isomorphic to $k(x_1,\dots, x_{n-1})$ . [ $k(X)$ field of fractions of $k[X]$ over $k$ , where $k[X]=k[x_1,\dots,x_n]/I_k(X)$ ] Finally, $k(X)$ is an algebraic extension of $k(x_1,\dots,x_n)$ . I would be really happy if someone could explain to me a little more detailed one of these proofs, or tell me another possible approach to prove this proposition.","['algebraic-curves', 'elliptic-curves', 'algebraic-geometry', 'dimension-theory-algebra']"
2026058,Prove that this set is compact?,"We define $\mathcal{E}:=\{E \subseteq \mathbb{N^2} : \text{$E$ is a reflexive and symmetric relation}\} \subseteq \{0,1\}^\mathbb{N^2}$. I have to prove that $\mathcal{E}$ is compact for the product topology. My idea is to prove that $\{0,1\}^\mathbb{N^2}$ is compact and $\mathcal{E}$ is closed in this compact. By Tychonoff's theorem the set $\{0,1\}^\mathbb{N^2}$ is compact (I think that $\{0,1\}$ has the Borel-Lebesgue property so it's compact). Now, I have no idea to prove that $\mathcal{E}$ is closed (which argument could I use ?). Thanks in advance !","['general-topology', 'relations']"
2026072,A first countable Hausdorff space is compactly generated,"I know that even a non-Hausdorff first countable space is compactly generated, but I assume that adding the property that the space is also Hausdorff, there is an easier proof. How would you prove that a first countable Hausdorff space is compactly generated? I assume using the fact that a compact subspace in a Hausdorff space is closed is to key to make the proof easier, but I don't see how. I use the following definition for a compactly generated space:  A space is compactly generated if (i) a subspace $ A $  is closed in $ X $ if and only if (ii) $ A\cap C $ is closed in $ C $ for all compact subspaces $ C\subseteq X $. To show that (i) $ \Rightarrow $ (ii) is easy. Since $ X $ is a Hausdorff space, $ C $ is closed and the intersection $ A\cap C $ is an intersection between two closed sets and hence closed in both $ C $ and $ X $. What about the converse?","['general-topology', 'compactness', 'first-countable']"
2026119,"Solving for $x$ in $f(f(x))=g(f(x))$ where $f(x)=3x$, $g(x)=x^2-3$","What I assumed they were asking is what values of x allows that equation to be true. If so then $f(3x) =3(3x) = 9x$ $g(3x) =(3x)^2 -3 = 9x^2 -3$ $9x = 9x^2 -3$ I saw a quadratic and went on to solve it but that doesnt give the correct answer so maybe I did the wrong thing. I am a bit stuck. Edit:
The answer according to the book is -0.5 and 1.5 but i am getting -0.26 and -1.26","['algebra-precalculus', 'functions']"
2026135,Finding the determinant of a block diagonal matrix,"We have the following square block matrix $X= \begin{bmatrix}
    A       & 0  \\
    0       & B 
\end{bmatrix}$, where $A$ and $B$ are square. I want to get the determinant of this matrix (I know it equals $\det A \times \det B$). I've looked through the question catalog and found a lot of questions similar to this one, but the answers they received use techniques I am not familiar with - Leibniz' formula, techniques beyond the scope of an introductory linear algebra course, etc. So I want to know how to do this with Laplace expansion . I know how Laplace expansion works for regular matrices but I don't know how to use it here. Let's say we want to use Laplace expansion along the first row of $A$, then we get that $ \det A = \displaystyle \sum_{j=1}^n (-1)^{j+1}a_{1j}\det A_{1j} $, but how do we use this to obtain the result for the entire block matrix? Can we say that because the elements of $A$ are always in different rows and columns as compared to the elements of $B$, the entire matrix $B$ is always present in the minors of $A$? If so, the result seems a bit more intuitive to me, but I still don't know how to computationally obtain it.","['matrices', 'block-matrices', 'linear-algebra', 'determinant']"
2026162,Generating $\sigma$-algebra and measure from the Riesz Representation Theorem,"Let $\Lambda:C_c(\mathbb R)\to\mathbb R$ be a positive linear functional. The Riesz representation theorem gives that to construct the measure $\mathcal M$ and $\sigma$-algebra $\mu$, we do the following: For every open set $V\subset\mathbb R$, define $$\mu(V)=\sup\{\Lambda f:f\prec V\}.$$ For every $E\subset\mathbb R$, define $$\mu(E)=\inf\{\mu(V):E\subset V,\ V\text{  open}\}.$$ Define $\mathcal M$ as the collection of all those $E\subset\mathbb R$ such that $$\mu(E)=\sup\{\mu(K):K\subset E,\ K\text{ compact}\}.$$ Here, $f\prec V$ means that $f\in C_c(\mathbb R)$, $0\leq f\leq 1$, $V$ is open, and $\operatorname{supp}(f)\subset V$. The whole construction is eluding me. Can someone give a specific example of a positive linear functional, and run through the steps of generating $\mathcal M$ and $\mu$? Many thanks.","['riesz-representation-theorem', 'real-analysis', 'measure-theory']"
2026164,UMVUE of a parameter for Pareto Distribution,"Problem: Let $ (X_1,X_2, \ldots, X_n) $ be a random sample from Pareto Distribution with pdf $ f(x; \theta) = (\frac{\theta}{c})(\frac{c}{x})^{\theta + 1}, ~~ x> c $. Find the UMVUE of parameter $ \theta$. My work so far: I proved that the UMVUE cannot be found through Cramer-Rao method. Then I tried with the classic Rao Blackwell method: I proved that the given Pareto Distribution is included in the Exponential Family and $T = \sum_{i=1}^{n} \log X_i $ is a complete and sufficient statistic of $ \theta $. Now I am stuck because I could not find an unbiased estimator of $ \theta $ to proceed.","['statistics', 'statistical-inference', 'probability-distributions']"
2026183,lusin's theorem,"Good morning, I was trying to analyze the demonstration of Lusin's Theorem of the book ""Measure Theory and Probability Theory - Krishna A. pg.69"" and I found myself having three difficulties, I would appreciate if you could help me. Lusin's Theorem: If $F:\mathbb{R\rightarrow{\mathbb{R}}}$ is a decreasing function and  $\mu=\mu_{F}^{*}$ the corresponding Lebesgue Stieltjes measure on $(\mathbb{R},M_{\mu_{F}^{*}})$. $f:\mathbb{R}\rightarrow{\mathbb{R}} $ $(M_{\mu_{F}^{*}},B(\mathbb{R}))$ measurable and $\mu({x: \left |{f(x)}\right |=\infty})=0$. Then $\forall{\epsilon>0}$, there is a continuous function  $g:\mathbb{R}\rightarrow{\mathbb{R}}$ such that $\mu({x: f(x)\neq{g(x)}})<\epsilon$. The proof  begins by setting $-\infty<a<b<\infty$ and proves that $\mu({x: a\leq{x}\leq{b},\left |{f(x)}\right |>K})<\epsilon/2$ $K\in{(0,\infty)}$, then define $f_{K}(x)=f(x)I_{[a,b]}(x)I_{\left |{f}\right |\leq{K}}$ that is bounded for being a product of bounded functions and measurable for the same reason. Then it makes the following statement which will prove later: For all $\epsilon>0$ , there is a continuous function $g:[a,b]\rightarrow{\mathbb{R}}$ such that
$\mu({x:f_K(x)\neq{g(x)},a\leq{x}\leq{b}})<\epsilon/2$ 1) My first question is that it says this implies $\mu({x: a\leq{x}\leq{b},f(x)\neq{g(x)},})<\epsilon$ . What I suppose is that we must use the two inequalities we have that are less than $\epsilon/2$. And maybe separate the values when $\left |{f}\right |>K$ y $\left |{f}\right |\leq{K}$ Then he begins to demonstrate the statement he made and how $f_K$  is measurable, for each $\epsilon>0$  there is a simple function $s(x)=\displaystyle\sum_{i=1}^k{c_iI_{A_i}(x)}$ with $A_i\subset{[a,b]}$, $A_i\in{M_{\mu_{F}^{*}}} $ all disjoint, with $\mu(A_i)<\infty$  and $c_i\in{\mathbb{R}}$. Then by a theorem indicating for each $A_i$  and $\eta>0$ there exists a finite number of disjoint open intervals $I_{ij}=(a_{ij},b_{ij}), j=1,...,n_{i}$ such that
$\mu(A_i \Delta \displaystyle\bigcup_{j=1}^{n_{i}}{I_{ij} })<\eta/2k$ and for an exercise there exists a continuous function $g_{ij}$ such that $\mu(g_{ij}^{-1}(1) \Delta I_{ij})<\eta/kn_{i}$, $j=1,2,...,n_{i}, i=1,2,...,k.$. where $ g_{ij}(x) = \left \{ \begin{matrix} 1 & \mbox{if } a+\eta\leq{x}\leq{b-\eta}
\\ 0 & \mbox{if } x\not\in{(a,b)} \\ lineal & \mbox{in} [a,a+\eta]\cup{[b-\eta,b]}\end{matrix}\right. $. That is to say $g_{ij}^{-1}(1)=[a+\eta,b-\eta]$
Defines $g_{i}=\displaystyle\sum_{j=1}^{n_{i}}{g_{ij}}, 1\leq{i}\leq{k}$
2) Why from here $\mu(A_i \Delta g_{i}^{-1}(1))<\eta/k$ Then define for each $n\geq{1}, h_{n}(.)=g_{\displaystyle\frac{1}{2^n},\displaystyle\frac{1}{2^n}}(.)$ y $A_{n}={x: a\leq{x}\leq{b}, \left |{f_{K}(x)-h_{n}(x)}\right |>1/2^n}$ 3) Why then $\mu{A_{n}}<1/2^n$ ? Thank you
The link of the book is Measure Theory and Probability Theory - Krishna A.","['lebesgue-measure', 'measure-theory']"
2026214,What is the coefficient in the differential coefficient?,"A term that apparently not used so much now is that of Differential Coefficient But I can not understand what we mean by the term coefficient in this context. So basically if $y=6x-x^2$ then the differencial coefficient is $dy/dx=6-2x$ but what part is the ""coefficient""?","['derivatives', 'ordinary-differential-equations', 'calculus']"
2026233,Finding stationary points numerically,"I'm writing a program which needs to be able to find the stationary points of a function within a given interval, and evaluate whether these points are maxima, minima or points of inflection. Using numerical differentiation I can find the derivative at a given point, but I'd prefer not to have to check every point on the function for a zero derivate, but I can't think of / find a better method. Once I have a stationary point, I should be able to use numerical differentiation techniques to find the second derivative (and thus whether it is a maxima, minima etc.) How can I estimate the stationary points without checking every point on a line?","['derivatives', 'numerical-methods', 'calculus']"
2026262,"Infinite series, injective function and rearrangement inequality",Let $f:\mathbb{N^*}\to\mathbb{N^*}$ an injective function. Show that the following infinite series $$\sum_{i=1}^{\infty}\frac{f(n)}{n^2}$$ is divergent. I am supposed to deal with this using the rearrangement inequality. But I don't know how!Could some explain this to me step by step? I really want to understand...,"['sequences-and-series', 'calculus', 'functions']"
2026265,Limit of geometric mean of series terms.,"Suppose an infinite series converges,  $\sum a_n = S > 0,$  and $a_n > 0.$ I know that (arithmetic-geometric inequality) $0 < (\prod_\limits{i=1}^n a_i)^{1/n} < (\sum_\limits{i=1}^n a_i) / n.$ This shows that $\lim_\limits{n \to \infty}(\prod_\limits{i=1}^n a_i)^{1/n} = 0$ since $\lim_\limits{n \to \infty}(\sum_\limits{i=1}^n a_i) / n = S/\infty = 0.$ I want to show $$\lim_{n \to \infty}n(\prod_{i=1}^n a_i)^{1/n} = 0.$$ I can't continue because $0 < n(\prod_\limits{i=1}^n a_i)^{1/n} < (\sum_\limits{i=1}^n a_i)$  has a limit of the upper bound equal to $S$ Suggestions?","['real-analysis', 'sequences-and-series']"
2026360,A Machinist's Imperfect Disk,"Exercise A machinist is required to manufacture a circular metal disk with area $1000$ cm $^2$ . What radius produces such a disk? If the machinist is allowed an error tolerance of $\pm 5$ cm $^2$ in the area of the disk, how close to the ideal radius in part (1) must the machinist control the radius? In terms of the $\epsilon$ , $\delta$ definition of $\lim \limits_{x \to a}{f(x)} = L$ what is $x$ ? What is $f(x)$ ? What value of $\epsilon$ is given? What is the corresponding value of $\delta$ ? Solution Note: I've decided to solve part (3) before part (2), as it helps set the stage of the solution of (2). 1. What radius produces such a disk? $\pi r_0^2 = 1000 \implies r_0 = \sqrt{\frac{1000}{\pi}} \approx 17.8412$ 3. In terms of the $\epsilon$ , $\delta$ definition of $\lim \limits_{x \to a}{f(x)} = L$ what is $x$ ? What is $f(x)$ ? What value of $\epsilon$ is given? What is the corresponding value of $\delta$ ? $a = r_0 \approx 17.8412$ $L = \pi r_0^2 = 1000$ $x = r$ $f(x) = \pi r^2$ $|r - r_0| < \delta$ $|\pi r^2 - \pi r_0^2| < \epsilon$ 2. If the machinist is allowed an error tolerance of $\pm 5$ cm $^2$ in the area of the disk, how close to the ideal radius in part (1) must the machinist control the radius? $|\pi r^2 - \pi r_0^2| < \epsilon$ $\implies |\pi r^2 - 1000| < 5$ $\implies -5 < \pi r^2 - 1000 < 5$ $\implies 995 < \pi r^2 < 1005$ $\implies \frac{995}{\pi} < r^2 < \frac{1005}{\pi}$ $\implies \sqrt{\frac{995}{\pi}} < r < \sqrt{\frac{1005}{\pi}}$ $\implies 17.7966 < r < 17.8858$ $|r - r_0| < \delta \implies |r - 17.8412| < \delta$ $|17.7966 - 17.8412| < \delta \implies 0.0446 < \delta$ $|17.8858 - 17.8412| < \delta \implies 0.0446 < \delta$ $\delta = \min(0.0446, 0.0446) = 0.0446$ Answer 1. What radius produces such a disk? $$r_0 = 17.8412 \text{ cm}$$ 2. If the machinist is allowed an error tolerance of $\pm 5$ cm $^2$ in the area of the disk, how close to the ideal radius in part (1) must the machinist control the radius? $$\delta = 0.0446 \text{ cm}$$ 3. In terms of the $\epsilon$ , $\delta$ definition of $\lim \limits_{x \to a}{f(x)} = L$ what is $x$ ? What is $f(x)$ ? What value of $\epsilon$ is given? What is the corresponding value of $\delta$ ? $$|r - r_0| < \delta$$ $$|\pi r^2 - \pi r_0^2| < \epsilon$$ Request Is my answer correct? If not, in what part of my solution did I make a mistake?","['proof-verification', 'word-problem', 'calculus', 'limits']"
2026383,What is Needed for Cantor-Bernstein-Schröder Theorem,"The $CBS$ Theorem is a superb tool to prove the equality of size of two infinite sets.  Inject $A$ in $B$, inject $B$ in $A$, done. When thinking in naïve set theory one often is unaware of the full extent of one's assumptions. What are the axioms (fragment of $ZFC$) required to allow for the $CBS$ Theorem?",['elementary-set-theory']
2026406,Existence of a $\mathbb C$-Banach space isometric to a Hilbert Space but whose norm is not induced by an inner product?,"As written in the title, does there exists a $\mathbb C$-Banach space isometric to a Hilbert Space but whose norm is not induced by an inner product? Since an inner product in the Hilbert space has to fulfill the Parallelogram Identity, how could it be that such a $\mathbb C$-Banach space exists?","['banach-spaces', 'hilbert-spaces', 'isometry', 'functional-analysis', 'inner-products']"
2026427,Frames and Co-frames,"I'm trying to write a precise definition of a frame and co-frame. I have that a frame is a basis for a tangent space $T_pM$ and the co-frame is the dual basis (basis for the co-tangent space $T^{\ast}_pM$) where $M$ is a manifold. In coordinates, I could write the frame as $\{\partial_{x^i}\}$  and the coframe as $\{dx^i\}$. Any suggestions for a more complete definition?",['differential-geometry']
2026428,What is second Bartlett identity?,I came across the term second Bartlett identity in the wikipedia link: https://en.wikipedia.org/wiki/Variance_function However could not find detail about it. Can anyone help me to understand what this identity is about. More importantly I want to know under what assumption this identity is true.,"['fisher-information', 'statistics', 'probability', 'statistical-inference']"
