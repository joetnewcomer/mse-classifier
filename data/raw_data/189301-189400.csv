question_id,title,body,tags
3546249,"If $y$ is a $k$th power modulo $p^\gamma$, then it is also a $k$th power modulo $p^t$ for $t \geqslant \gamma$","This question is the true version I wanted to ask of this question . Say $p$ is an odd prime number, $k$ a positive integer and $p^{\tau} || k$ .  Let $\gamma = \tau + 1$ . I would like to prove If $y \in \mathbf{Z}$ is a $k$ -th power modulo $p^\gamma$ , then it is also a $k$ -th power modulo $p^t$ for any $t \geqslant \gamma$ . I don't know how standard this fact is. Stated like this, it seems to be a rather simple fact. However, I do not find any simple proof for this fact, and I tried to write a messy proof (see post quoted above) but nothing that convinces me or shed lights on what is happening. This questions comes from my misunderstanding of the following statement, from Vaughan:","['hensels-lemma', 'number-theory', 'modular-arithmetic', 'prime-numbers']"
3546252,Is this elementary-number-theoretic conjecture already mentioned somewhere or it is entirely new?,"While I was doing some research in elementary number theory I discovered some regularities that seem to be very promising. First, function $d$ can be defined as $d(n)=d(\prod_{i=1}^{k(n)}  p_i^{r_i})=\sum_{i=1}^{k(n)}r_i$ where $n= \prod_{i=1}^{k(n)}  p_i^{r_i}$ is unique prime factorization of $n$ and it can be said that natural number $n>1$ is of degree $w$ if and only if $d(n)=w$ . So, for example, prime numbers are natural numbers of first degree. The conjecture I would like to propose is the following: Every prime number $\geq7$ is the sum of a prime number and number of second degree. As noted in the comments, the conjecture can be rephrased very simply as: Every prime number $p\geq 7$ can be written as $p=qr+s$ where $q,r,s$ are primes.","['conjectures', 'number-theory', 'elementary-number-theory', 'soft-question', 'prime-numbers']"
3546293,Subadditive functions,"For what values of $s\in [0,\infty),$ the function given by $f(x)=x^s$ sub-additive? i.e. $f(a+b)\leq f(a)+f(b) \quad \forall a,b \in [0, \infty)$ I feel $f$ is sub-additive for $s\in [0,1]$ and not sub-additive for $s>1$ If so, How to prove it?","['functions', 'analysis', 'real-analysis']"
3546335,"Matrices - given $AB$, how to find determinant of $BA$ ??","Let A $_{3×2}$ and B $_{2×3}$ be matrices such that their product $AB$ is $$AB=\begin{pmatrix}
8&2 & -2\\
2&5&4 \\
-2&4&5 \\
\end{pmatrix}$$ And $BA$ is nonsingular Find the determinant of $BA$ . I have no idea , how to solve this type of question. All I could notice is that $|AB| = 0$ and it's a symmetric matrix. I tried assuming a general matrix , but I get simply too many unknowns and very few equations.",['matrices']
3546358,"How are the ""corresponding points"" of a hyperbola and its auxiliary circle defined?","In case of an ellipse and its auxiliary circle (the circle with major axis as its diameter), the meaning of ""corresponding points"" is straightforward. Let us consider the following diagram which shows the upper half of an ellipse with its major axis horizontal: Image Source : Florida Center for Instructional Technology $QM$ is perpendicular to the horizontal. Here $Q$ and $P$ are called as ""corresponding points"" on the auxiliary circle and the ellipse respectively. And the angle $QOM$ is called the ""eccentric angle"" of the point $P$ . In case of an hyperbola, I understood that the auxiliary circle is the one which has its centre at the centre of hyperbola (usually origin) and diameter equal to the length of transverse axis. But I don't understand how ""corresponding points"" are defined in this case. Or in other words, if we're given a hyperbola and its auxiliary circle, how to find the corresponding point on the hyperbola for a point on the circle? Further, how many corresponding points on the hyperbola exists for each point on the circle (I'm having this doubt because hyperbola has two branches and suspect a second ""corresponding point"" on the other branch)? In my book, a diagram similar to the following one was given in the section ""Auxiliary circle of a Hyperbola"": Image Source : Florida Center for Instructional Technology","['conic-sections', 'geometry', 'terminology']"
3546364,Representing $\sum\limits_{n=1}^\infty a_{n-1}a_nz^n$ in terms of $\sum\limits_{n=0}^\infty a_nz^n$,"Let $f(z)=\sum\limits_{n=0}^\infty a_nz^n$ be an analytic function in some open set $D$ with $a_n>0$ for all $n\geq 0$ . Then there are various series that can be represented in terms of $f$ . For example, we have that $\sum\limits_{n=1}^\infty na_nz^n=zf'(z).$ Is there a way to represent the series $\sum\limits_{n=1}^\infty a_{n-1}a_nz^n$ in terms of $f$ ?","['complex-analysis', 'sequences-and-series']"
3546377,$X$ is compact iff every net in $X$ has a convergent subnet (using filters).,"I'm trying to prove that a topological space $X$ is compact iff every net has a convergent subnet. Here is what I already know about compactness/filters: A topological space $X$ is compact iff every filter on $X$ has an adherent point and I'd like to use the connection between filters and nets to prove this statement. So, I attempted like this: Let $X$ be compact and let $x:=(x_\alpha)_{\alpha\in I}$ be a net in $X$ . Then we can associate a filter $\mathcal{F}_x$ to this net by $$\mathcal{F}_x:= \operatorname{stack}\{\{x_n:n \geq m\}: m \in I\}$$ Because $X$ is compact, it follows that there is $y \in X$ such that $\mathcal{F}_x \dashv y$ . We then know that $x = (x_\alpha)_{\alpha \in I} \dashv y$ as well (by one of the properties of this associated filter). Consequently, $x$ has a convergent subnet converging to $y$ . Conversely, let $\mathcal{F}$ be any filter on $X$ . We can associate a net with this filter by considering the directed set $$I:= \{(x,F): x \in F, F \in \mathcal{F}\}$$ partially ordered via reverse inclusion, ignoring the first coordinate and the map $$N_\mathcal{F}: I \to X: (x,F) \mapsto x$$ then gives the desired net. By assumption, this net has a convergent subnet, which after an analaguous reasoning tells us that $\mathcal{F}$ has an adherent point as well, showing that $X$ is compact. Is this correct?","['filters', 'solution-verification', 'general-topology', 'nets', 'compactness']"
3546403,"Question about ODEs, while reading Milnor's Topology from the Differentiable Viewpoint","I am reading Milnor's Topology from the Differential Viewpoint , p.23. The paragraph below is extracted from the book: Let $\varphi : \Bbb R^n \to \Bbb R$ be a smooth function. Given any fixed unit vector $c=(c_1,...,c_n)\in S^{n-1}$ and a point $x_0 \in \Bbb R^n$ , consider the differential equations $$ \frac{dx_i}{dt}(t)=c_i \cdot \varphi (x_1(t),...,x_n(t))~(i=1,...,n),~~ ~x(0)=x_0.$$ These equations have a unique solution $x=x(t)=(x_1(t),...,x_n(t))$ defined for all real numbers. I know that existence and uniqueness follow from a theorem in ODE, but how can we assure that the domain of $x$ is the whole $\Bbb R$ ?","['differential-topology', 'ordinary-differential-equations']"
3546435,"UPDATED: If $f(x + y) \leq yf(x) + f(f(x))$ for all real numbers $x$ and $y$, prove that $f(0) = 0.$","$\large\text{UPDATED:}$ ( with completely correct arguments ) Let $f : \mathbb R \to \mathbb R$ be a real-valued function defined on the set of real numbers that satisfies $$f(x + y) \leq yf(x) + f(f(x))$$ for all real numbers $x$ and $y$ .  Prove that $f(x) = 0$ for all $x ≤ 0$ . (IMO $2011$ ) The purpose of my question is only proof verification. (not knowing the correct solution) Here, I focus only on the case of $f(0) = 0.$ Because this is the main part of the problem and this is very easy to show that, $f(0) = 0$ follows $f(x) = 0$ for all $x ≤ 0.$ I want to prove only the $f(0)=0$ . Here are my steps: Case $1.$ $f(0)\in \mathbb R^+$ We have, $$f(0)\leq-xf(x)+f(f(x))$$ $$f(x)\leq xf(0)+f(f(0))$$ Applying $x \longrightarrow -\infty$ we get from $f(x)\leq xf(0)+f(f(0))$ , $\lim_{x\to -\infty}f(x) = -\infty $ . Then applying again $x \longrightarrow -\infty$ , from $f(0)\leq-xf(x)+f(f(x))$ we get $f(0) \longrightarrow-\infty \not \in\mathbb R^+$ , which gives a contradiction. Case $2.$ $f(0)<0$ (with the wrong argument, e.g. $\lambda=0$ ) $\require{enclose} \enclose{horizontalstrike}{ \text{We have, from}}$ $\require{enclose} \enclose{horizontalstrike}{f(x)\leq xf(0)+f(f(0))}$ $\require{enclose} \enclose{horizontalstrike}{\text{we deduce}}$ $\require{enclose} \enclose{horizontalstrike}{\lim_{x\to +\infty}f(x)=-\infty.}$ $ \require{enclose} \enclose{horizontalstrike}{\text{Suppose that,}}$ $\require{enclose} \enclose{horizontalstrike}{ \lim_{x\to -\infty}f(x)=+\infty.}$ $\require{enclose} \enclose{horizontalstrike}{\text{Applying}}$ $\require{enclose} \enclose{horizontalstrike}{x\to-\infty}$ $\require{enclose} \enclose{horizontalstrike}{\text{from}}$ $\require{enclose} \enclose{horizontalstrike}{f(x-1) ≤ -f(x) + f(f(x))}$ $\require{enclose} \enclose{horizontalstrike}{\text{we have}}$ $\require{enclose} \enclose{horizontalstrike}{\lim_{x\to -\infty}f(x+(-1)) \longrightarrow +\infty}$ . $\require{enclose} \enclose{horizontalstrike}{\text{But,}}$ $\require{enclose} \enclose{horizontalstrike}{\lim_{x\to -\infty} (-f(x) + f(f(x)))=-\infty}$ . $\require{enclose} \enclose{horizontalstrike}{\text{According our assumption, we applied}}$ $\require{enclose} \enclose{horizontalstrike}{\lim_{x\to +\infty}f(x)=-\infty.}$ $\require{enclose} \enclose{horizontalstrike}{\text{So, this is a contradiction.}}$ $\require{enclose} \enclose{horizontalstrike}{ \text {Suppose that}}$ , $\require{enclose} \enclose{horizontalstrike}{ \lim \inf_{x\to -\infty}f(x)=a}$ $\require{enclose} \enclose{horizontalstrike}{ \text{and}}$ $\require{enclose} \enclose{horizontalstrike}{ \lim \sup_{x\to -\infty}f(x)=b}$ , $\require{enclose} \enclose{horizontalstrike}{ \text{where}}$ $\require{enclose} \enclose{horizontalstrike}{ a,b\in\mathbb{R}}$ $\require{enclose} \enclose{horizontalstrike}{ \text{and for any}}$ $\require{enclose} \enclose{horizontalstrike}{ \lambda \in [a,b]}$ $\require{enclose} \enclose{horizontalstrike}{ \text{we have}}$ $\require{enclose} \enclose{horizontalstrike}{ \lambda\leq y\lambda+f(\lambda)}$ . $\require{enclose} \enclose{horizontalstrike}{ \text{For any}}$ $\require{enclose} \enclose{horizontalstrike}{ \lambda}$ $\require{enclose} \enclose{horizontalstrike}{ \text{we can always choose a finite}}$ $\require{enclose} \enclose{horizontalstrike}{y}$ $\require{enclose} \enclose{horizontalstrike}{ \text{such that, where we get}}$ $\require{enclose} \enclose{horizontalstrike}{ \lambda\ > y\lambda+f(\lambda)}$ $\require{enclose} \enclose{horizontalstrike}{ \text{which gives a contradiction.}}$ $\require{enclose} \enclose{horizontalstrike}{ \text{So, we deduce that}}$ $\require{enclose} \enclose{horizontalstrike}{ \lim_{x\to -\infty}f(x)=-\infty}$ . $\require{enclose} \enclose{horizontalstrike}{\text{Then, applying}}$ $\require{enclose} \enclose{horizontalstrike}{x\to-\infty}$ $\require{enclose} \enclose{horizontalstrike}{\text{from}}$ $\require{enclose} \enclose{horizontalstrike}{f(0)\leq-xf(x)+f(f(x))}$ $\require{enclose} \enclose{horizontalstrike}{\text{we get}}$ $\require{enclose} \enclose{horizontalstrike}{f(0)\longrightarrow -\infty}$ . Case $2.$ $f(0) \in \mathbb {R^-}$ (with the correct argument) We have, from $f(x)\leq xf(0)+f(f(0))$ we deduce $\lim_{x\to +\infty}f(x)=-\infty.$ From $f(x + y) \leq yf(x) + f(f(x))$ we have: $\begin{cases} f(x)\leq f(f(x)) \\ f(x) \leq xf(0)+ f(f(0)) \end{cases} \Longrightarrow f(x)\leq f(x)f(0)+f(f(0)) \Longrightarrow f(x)(1-f(0))\leq f(f(0))$ . Then applying $x=f(0)$ , we get $f(f(0))\leq 0$ , which imply $f(x)\leq 0$ , which gives $f(f(x))\leq 0$ . In this case, we have $f(x)<0.$ Because, if $f(x)=0$ , from $f(x)\leq f(f(x))$ , we get $f(0)\geq 0$ , which gives a contradiction. 
  Then, from $f(x + y) \leq yf(x) + f(f(x))$ we have: $f(z)\leq(z-x)f(x)+f(f(x)) \Longrightarrow f(x) \leq (x-y)f(y)+f(f(y))\Longrightarrow 0\leq(f(y)-y)f(y) \Longrightarrow f(x)(f(x)-x)\geq 0 \Longrightarrow f(x) \leq x $ Applying $x\to-\infty$ from $f(0)\leq-xf(x)+f(f(x))$ , we get $f(0)\longrightarrow -\infty \not \in \mathbb{R^-}$ , which gives again a contradiction. So, we can deduce that $f(0)=0$ . Q.E.D. Can you verify the new solution? I just want to make sure that I got $ f (0) = 0 $ correctly. Thank you!","['contest-math', 'inequality', 'proof-writing', 'solution-verification', 'algebra-precalculus']"
3546565,Solve $(x+1)3^x > 3^{x+1}$,I'm only at a college algebra level (pre-calculus) and am having a hard time knowing what steps to perform to solve this as x is both an exponent and at the base level.  I put this into a calculator and got x = 2 but I'd like to know how to perform the steps.  I know logs are involved but haven't been able to figure it out.  Here is the problem again $(x + 1)3^x > 3^{x+1}$ Any help is greatly appreciated :),['algebra-precalculus']
3546621,Riemann Roch Space for an algebraic surface and degree of rational function.,"I am not familiar with the language of cohomology and definitely not fluent with the modern language of sheaves. I had learnt about Riemann Roch spaces and the associated theorem in the context of curves, but now I am trying to understand how divisors, rational functions and the Riemann Roch space looks like for a 2 dimensional algebraic variety. How do we define the Riemann Roch space for an 2 dimensional algebraic variety?
I know that a divisor will be a formal sum of curves ( co dimension one sub-variety).
Let $X$ be the algebraic surface. If $f \in K(X)^*$ , then the principal divisor is defined as follows $$\mbox{div}(f)=\sum_{C}\mbox{ord}_C(f)C \quad (\text{sum over irreducible curves}),$$ where \begin{equation}
  \mbox{ord}_C(f)=\begin{cases}
     \; \; \;n, & \text{if $f$ has a zero of order $n$ along $C$}.\\
    -n, & \text{if $f$ has a pole of order $n$ along $C$}.\\
     \; \; \;0, & \text{otherwise}.
  \end{cases}
\end{equation} Is it correct to write the Riemann Roch space of a divisor $D$ on $X$ as follows? $$ \mathcal{L}(D)=\{f\in K(X)^*: \mbox{div}(f)+D\geq 0\}\cup \{0\} $$ How do we define the degree of a rational function on a surface?
For $f \in K(C)^*$ , where $C$ is an irreducible curve, we define the degree of a rational function to be the degree of pole divisors of the rational function. Can I use a similar definition? Where does intersection theory come in? Please correct me if my definitions are wrong, maybe it is foolish to try to understand this without the modern language, but any input would be useful! I am interested in using these definitions for surfaces defined over finite fields.","['number-theory', 'algebraic-geometry', 'arithmetic-geometry']"
3546638,"Prove that $\lim_{t \to \infty} \int_1^t \sin(x)\sin(x^2)\,dx$ converges","Question_ Prove that $$\lim_{t \to \infty} \int_1^t \sin(x) \sin(x^2) \, dx$$ converges. I think the indefinite integration of $\sin(x)\sin(x^2)$ is impossible. Besides, I've wondered whether the definite integration of it is possible or not. I've tried to use the condition that $t \to \infty$ . The one that came up to my mind is to use partial integration. When using it, we can have: $$\int_{1}^{t}\sin(x)\sin(x^2) \, dx=-\left[ \sin(x^2) \cos(x) \right]_1^t + \int_1^t 2x\cos(x^2)\sin(x) \, dx$$ However, since $\sin(t^2)\cos(t)$ diverges as $t \to \infty$ , I couldn't determine whether the given integration diverges or not. Due to this, I re-tried to have partial integration in a quite different way: $$\int_1^t \sin(x)\sin(x^2) \, dx=\int_1^t \frac{\sin(x)}{2x}(2x\sin(x^2)) \, dx=-\left[\frac{\sin(x)}{2x} \cos(x^2)\right]_1^t + \int_1^t \frac{x\cos(x)-\sin(x)}{2x^2} \cos(x^2) \, dx$$ In this case, $\left[\sin(t)\cos(t^2)/2t\right]$ goes to $0$ as $t \to \infty$ .  Therefore, it is enough to see the integration part only. Unfortunately, I'm stuck here. Could you give me some key ideas that can investigate whether $$\int_{1}^{t}\frac{x\cos(x)-\sin(x)}{2x^2}\cos(x^2)dx$$ converges or not? The other way of solution is also welcome! Thanks for your advice.","['integration', 'calculus', 'convergence-divergence', 'trigonometry']"
3546674,Cardinality of a tuple,"Studying Linear Algebra, I learned how the dimension of a vector space $E$ is just the number of elements in any base of the vector space $E$ . $$ \mathscr{B}=(e_1, e_2, ..., e_n) \quad \text{base of E} \implies \mathrm{dim}(E)=n $$ If I wanted to further formalize this idea, it would come natural to me to express the notion of ""number of elements in a tuple"" as a cardinality. My textbook introduces basis of vector spaces as tuples after all.
Could I write something like $ \mathrm{card}(\mathscr{B})=n=\mathrm{dim}(E) $ or not? I know that the notion of cardinality is made for sets. Is there anything similar for indicating the ""length of a tuple""?","['elementary-set-theory', 'terminology']"
3546681,Leading Symbol of Pseudo-Differential Operators,"I have seen various definitions of symbols used to define pseudo-differential operators. The class of symbols I am working with is $S^d(U)=\{p(x,\xi)\in C^{\infty}\left (U\times \mathbb R^m ,M_{k\times l}(\mathbb C) \right): p$ has compact $x$ -support in $U , \ \forall \ \alpha,\beta $ multi-indices $ \exists \ C_{\alpha,\beta}>0$ such that $\left | D^{\alpha}_xD^{\beta}_{\xi}p(x,\xi)\right |\leq C_{\alpha,\beta}(1+|\xi|)^{d-|\beta|}  \}$ This defines a $\Psi DO$ of order $d$ $P: C^{\infty}_c (U)\rightarrow C^{\infty}_c(U) \\
f\longmapsto Pf$ defined by $Pf(x)=\int e^{ix\cdot\xi}p(x,\xi)\hat f(\xi) d\xi $ Let $\Psi^d(U)$ be the class of all pseudo-differential operators defined as above. The leading symbol map is then given by $\sigma_L :\Psi^d(U)\rightarrow \frac{S^d(U)}{S^{d-1}(U)} \\
P\mapsto [p(x,\xi)]$ Is there a canonical choice of representative for the leading symbol like in the case of differential operators of degree $d$ , one can canonically assign a homogeneous polynomial of degree $d$ . https://mathoverflow.net/questions/75976/symbol-of-pseudodiff-operator/77437#77437 In the answer to this question there is a suggestion of defining the leading symbol as $\sigma_LP(x,\xi) = \lim_{\lambda \rightarrow \infty } \lambda^{-d}e^{-i\lambda \phi}P(e^{i\lambda \phi}) $ \
but I can't really see why this limit should exist.","['pseudo-differential-operators', 'analysis', 'differential-geometry']"
3546777,Centralizer of factor group,"I'm dealing with a finite $p$ -group $G$ whose derived subgroup $G'$ is cyclic. The author defines $C^*\leq G$ as \begin{equation*}
 C^*=C_G\big(G'/(G')^{p^2}\big).
\end{equation*} By definition, the centralizer $C_G(S)$ of a subset $S$ of $G$ is the subgroup given by all elements $g$ of $G$ such that $[g,s]=1\, \forall s\in S$ . I'm wondering how I can define a subgroup like $C^*$ as I'm being asked to compute the commutator between an element of $G$ and a coset in $G'/(G')^{p^2}$ . The full article can be read here , this centralizer can be found at page 113.","['group-theory', 'finite-groups']"
3546801,"""$\mathbb{R}^2$ can't be totally ordered"" (nicely)","I have often heard (both online and in person) people say that "" $\mathbb{R}^2$ can't be totally ordered."" I would like to understand this statement. Of course, on the face of it, this is false: Pick your favorite bijection $f:\mathbb{R}^2 \to \mathbb{R}$ and define $x \leq y$ iff $f(x) \leq f(y)$ . When I bring this up, people usually dismiss it, saying it isn't ""nice"" enough. This is fair, but now leaves me with the question of what a ""nice"" ordering would look like. Other questions on this site (like this ) show that there is no ordering which makes $\mathbb{C}$ an ordered field. I find this answer somewhat unsatisfying. I don't need to appeal to the algebraic structure of $\mathbb{R}$ to give it a ""nice"" ordering. Furthermore, I would like to be able to extend this notion of a ""nice ordering"" to other topological spaces that don't admit field structures: does $\mathbb{R}^3$ have a ""nice"" ordering? how about $S^1$ ? Here's a definition I came up with: a total ordering on a topological space $X$ is ""nice"" if for every $x < y$ , there are neighborhoods $U_x \ni x$ and $U_y \ni y$ so that for all $a \in U_x$ and $b \in U_y$ , we have $a < b$ . So the usual ordering on $\mathbb{R}$ is ""nice,"" but (for all $f$ I can think of) the ordering of $\mathbb{R}^2$ given above isn't. I've tried proving that $\mathbb{R}^2$ and $S^1$ can't be given a nice total ordering under this definition, but have had some difficulty. Questions: Is there an established notion of a ""nice"" ordering on a topological space? How can you prove that $\mathbb{R}^2$ (or $S^1$ ) can't be totally ordered nicely? (either with my definition or someone else's, if it exists)","['general-topology', 'soft-question']"
3546814,"Does $\sum_{k=1}^∞ \frac1{\prod_{i=0}^{l(k)} (\ln^i k) · {(\ln^{l(k)} k)}^{l(k)}}$ converge, where $l(x) = \min \{ c\in\Bbb{N} : \ln^c x < e \}$?","Define $\def\lnc{\operatorname{lnc}}$$\lnc x$ is the minimum natural $c$ such that $\ln^c x < e$ , for each real $x ≥ 1$ . Prove that $\displaystyle\sum_{k=1}^∞ \frac1{\prod_{i=0}^{\lnc k} (\ln^i k) · {(\ln^{\lnc k} k)}^{\lnc k}}$ diverges. Prove that $\displaystyle\sum_{k=1}^∞ \frac1{\prod_{i=0}^{\lnc k} (\ln^i k) · {(\ln^{\lnc k} k)}^{(\lnc k)^r}}$ converges for every $r > 1$ . I came up with this for fun, just to try to squeeze the gap between the well-known boundary: $\displaystyle\sum_{k=1}^∞ \frac1{\prod_{i=0}^p (\ln^i k)}$ diverges for every natural $p$ . $\displaystyle\sum_{k=1}^∞ \frac1{\prod_{i=0}^p (\ln^i k) · (\ln^p k)}$ converges for every natural $p$ . My proofs are below. Any comments are welcome! Downvoters should note that such questions are explicitly encouraged .","['summation', 'logarithms', 'real-analysis', 'sequences-and-series', 'convergence-divergence']"
3546846,Compute the characteristic function of Wiener Process (Brownian Motion).,"Wiener process is a stochastic process $(W_{t})_{t\in\mathbb{R}_{\geq 0}}$ on some probability space $(\Omega,\mathcal{F},\mathbb{P})$ satisfying the following properties: $(1)$ $W_{0}\equiv 0$ ; $(2)$ For $t>s\geq 0$ , $W_{t}-W_{s}$ is independent of $\sigma(W_{r}, r\leq s)$ ; $(3)$ $W_{t}-W_{s}\sim\mathcal{N}(0,t-s)$ ; $(4)$ All paths are continuous, i.e. $W_{t}$ is a continuous function in $t$ . I am now trying to write out an explicit formula of the characteristic function of Wiener process. My idea was to write out the joint distribution and then get some density function if possible, but I got stuck. Below is my attempt: Since $W_{t_{i}}-W_{t_{i-1}}$ is Gaussian with $\mu=0$ and $\sigma^{2}=(t_{i}-t_{i-1})$ and since the increments $$W_{t_{1}}-W_{t_{0}}, W_{t_{2}}-W_{t_{1}},\cdots, W_{t_{n}}-W_{t_{n-1}}$$ are independent, we know that $$\mathbb{P}[W_{t_{i}}-W_{t_{i-1}}\leq \alpha_{i}, i=1,\cdots,n]=\prod_{i=1}^{n}\dfrac{1}{\sqrt{2\pi(t_{i}-t_{i-1})}}\int_{-\infty}^{\alpha_{i}}e^{\frac{-x^{2}}{2(t_{i}-t_{i-1})}}dx.$$ Now, I want to do a linear change of variables to ge the joint distribution of $(W_{t_{1}},\cdots, W_{t_{n}})$ , but I don't know how to do it.. Also, even if we retrieve the joint distribution of $(W_{t_{1}},\cdots, W_{t_{n}})$ , it seems that we cannot write out the explicit formula for the characteristic function since we don't know the density.. What can I do? Is there another way to write out the characteristic function? Thank you! Edit 1: Okay I think I progressed a little bit: Let $0=t_{0}<t_{1}<t_{2}<\cdots<t_{n}<\infty$ . Then note that \begin{align*}
\sum_{j=1}^{n}\lambda_{j}W_{t_{j}}&=W_{t_{1}}\Big(\sum_{j=1}^{n}\lambda_{j}-\sum_{j=2}^{n}\lambda_{j}\Big)+W_{t_{2}}\Big(\sum_{j=2}^{n}\lambda_{j}-\sum_{j=3}^{n}\lambda_{j}\Big)+\cdots+X_{t_{n}}\lambda_{n}\\
&=(W_{t_{1}}-W_{t_{0}})\sum_{j=1}^{n}\lambda_{j}+(W_{t_{2}}-W_{t_{1}})\sum_{j=2}^{n}\lambda_{j}+\cdots+(X_{t_{n}}-X_{t_{n-1}})\lambda_{n},
\end{align*} in the second equality we used $W_{t_{0}}=W_{0}=0$ . Therefore, we can write the characteristic function as \begin{align*}
\varphi_{t_{1},\cdots, t_{n}}(\lambda_{1},\cdots, \lambda_{n})&=\mathbb{E}\exp\Big(i\sum_{j=1}^{n}\lambda_{j}X_{t_{j}}\Big)\\
&=\prod_{k=1}^{n}\mathbb{E}\exp\Big(i(X_{t_{k}}-X_{t_{k-1}})\sum_{j=k}^{n}\lambda_{j}\Big),
\end{align*} where the second equality was obtained using the fact that the increments are independent (so the sum in the characteristic function can become to the product of characteristic function). Now I want to use the fact that the increments are Gaussian to write out the formula, but the problem now is that we have the sum of $\lambda_{k},\cdots,\lambda_{n}$ , and I don't really know how to deal with them... By the way, as what I discussed with Nap D. Lover , my final goal is to use the characteristic function to show the consistency of finite dimensional distribution, if there is another other way to show this, I will give up the current computation happily :) Edit 2: After some attempt, I derived a general result for my final goal: to prove the existence of Wiener process using characteristic function. In the middle of construction, I happened to find a formula for more general characteristic  function --- as long as you have the independent increments, I believe this construction can work all the time by only altering a little bit. This proof is a long one so I will post it by answering my own question. However, I don't believe this proof is only possible way to show the existence, since my proof is clearly a little beyond what I asked. So please let me know and please do not hesitate to post your proof if you have another one. I believe any new proof rather than the proof I am gonna give will be better one  :) Thank you guys so much for your upvotes :)","['stochastic-analysis', 'probability-distributions', 'stochastic-processes', 'brownian-motion', 'probability-theory']"
3546862,If the Hessian matrix is symmetric is $\mathscr C^2$?,"I know that, if $ f (x)$ is a $\mathscr {C}^2$ function, then the Hessian matrix is symmetric.
But if the matrix is symmetric could not be $\mathscr {C}^2$ ; can someone give me an example?","['multivariable-calculus', 'hessian-matrix']"
3546896,Quotient of $ S^3 \times S^3$ by a free torus action.,"I am looking for a direct method to compute the quotient of the action of the torus $T^2$ acting on $S^3 \times S^3$ (thinking of $T^2$ as pairs of complex numbers and $S^3$ as unit quaternions) where the action is given by $(z,w)\cdot (p,q)=(zp,z^{n+2k}q\bar{w})$ where $n$ and $k$ are any integers. I am pretty sure that the quotient should be $S^2 \times S^2$ , however, I've used up all of my usual tricks and cannot prove it.","['riemannian-geometry', 'lie-groups', 'algebraic-topology', 'differential-geometry']"
3546921,Limits and infinity minus infinity,I understand that we need to rationalize when we have infinity minus infinity like here $\lim_{x\to \infty}\left(\sqrt{x^2 + 1} - \sqrt{x^2 + 2}\right)$ My question is why can I not just split the limits like this $\lim_{x\to \infty}\left(\sqrt{x^2 + 1}\right) - \lim_{x\to \infty}\left(\sqrt{x^2 + 2}\right)$ and then $\lim_{x\to \infty}\sqrt{x^2} * \lim_{x\to \infty}\sqrt{1 + \frac 1x}  - \lim_{x\to \infty}\sqrt{x^2} * \lim_{x\to \infty}\sqrt{1 + \frac 2x}$ which gives $\lim_{x\to \infty}\sqrt{x^2} - \lim_{x\to \infty}\sqrt{x^2} = 0$ because $\frac 1x$ and $\frac 2x$ tend to $0$ Where am I wrong?,"['limits', 'calculus', 'limits-without-lhopital', 'radicals']"
3546956,Is the empty set finite in the sense of Tarski?,"The answers provided so far seem to rely on numerical approaches, but set theory transcends number theory.  So who can provide an answer that does not depend on a development of the cardinals or ordinals? Hint: Tarski's definition of a finite set is as follows ""A set is finite if and only if every non-empty family of its subsets has a minimal element."" This definition can be shown to be equivalent to definitions given by Russell, Zermello, Dedekind, Sierpinski, and Kuratowski.",['elementary-set-theory']
3546986,Solve an exact Differential Equation,"Given $x^3y^2dx+x^2y^3dy=0$ is not exact. But we can find an integration factor such that $(Mx^3y^2)dx+(Mx^2y^3)dy=0$ Consider that we can have $M=M(x)$ or $M=M(y)$ or $M=M(z)$ where $z=xy$ (actually many more but this should be worth pursuing), The latter should give a solution but I cannot seem to get it.",['ordinary-differential-equations']
3547064,Prime numbers satisfying a congruence relation,"Let $p_1, p_2, \ldots, p_n$ prime numbers such that for each $i, 1 \le i \le n$ , $$\prod\limits_{j \neq i} p_j  \equiv 1 \pmod{p_i}.$$ For example, $2,$ $3$ and $5$ satisfies these conditions. Then, it is true that one of $p_1, p_2, \ldots, p_n$ must be $2$ ?","['number-theory', 'elementary-number-theory', 'prime-numbers']"
3547119,"Sum of independent random variables, one of which has absolutely continuous distribution","I am facing such a problem Let $X$ and $Y$ be independent random variables and suppose $X$ has an absolutely continuous distribution. Show $X+Y$ also has an absolutely continuous distribution. My understanding is that, $X$ has an absolutely continuous distribution, it means that $X$ has density $f_{X}(x)$ , then let $Z=X+Y$ , $P(Z \leq z)$ = $P(X \leq z-Y)$ = $\int_{-\infty}^{z-Y} f_{X}(x)dx$ . But I don't know how to proceed, since I don't know if $Y$ has density so I can't use iterated integral. Could someone help me with it? Thanks in advance!","['probability-theory', 'random-variables']"
3547135,"Closed-form expression for $F(x,y) = \int_0^1 \frac{\sqrt{t(1-t)}}{(t+x)^2 (t+y)} \mathrm{d}t$?","I am considering the following function $$F(x,y) = \int_0^1 \frac{\sqrt{t(1-t)}}{(t+x)^2 (t+y)} \mathrm{d}t,$$ which is well-defined for any $x > 0$ and $y \geq 0$ . Is there a hope to obtain a closed form formula with respect to $x$ and $y$ ? For instance, according to Mathematical, we have that $$F(x,0) = \int_0^1 \frac{\sqrt{t(1-t)}}{(t+x)^2 t} \mathrm{d}t = \frac{\pi}{x \sqrt{x (x+2)}}.$$ Remark: To give a bit of context, the function $F$ appears when I consider the quadratic optimization problem of the form $\min_{\mathbf{x} \in \mathrm{R}^N} \lVert \mathbf{A} \mathbf{x} - \mathbf{y} \rVert_2^2 + \lambda \lVert \mathbf{x} \rVert_2^2$ and I try to understand the behavior of $\lVert \widehat{\mathbf{x}} - \mathbf{x}_0 \rVert_2^2$ with $\widehat{\mathbf{x}}$ the unique optimizer and $\mathbf{x}_0$ the vector we aim at recovering, with $\mathbf{y} = \mathbf{A} \mathbf{x}_0 + \mathbf{n} \in \mathbb{R}^M$ and $\mathbf{n}$ an i.i.d. Gaussian vector. The values $x$ and $y$ above appear as functions of $\lambda$ and $\gamma = \lim M/N$ when $N\rightarrow \infty$ when the matrix $\mathbf{A}$ is i.i.d. Gaussian and its spectrum behaves according to the Marchenko-Pastur law.","['integration', 'calculus', 'closed-form', 'real-analysis']"
3547143,Independence of a random variable and a sigma algebra,"Let $(\Omega,\mathcal{F},P)$ be a probability space and $X$ be a random variable on it. Consider a sub $\sigma$ -algebra $\mathcal{G}$ . $X$ is said to be independent of $\mathcal{G}$ if $\sigma(X)$ and $\mathcal{G}$ are independent as $\sigma$ -algebras. I already know the fact that independence of $X$ and $\mathcal{G}$ implies $\mathbb{E}[X|\mathcal{G}]=\mathbb{E}[X]$ but not necessarily the other way round. However, if $X$ satisfies the equality $\mathbb{E}[e^{itX}|\mathcal{G}]=\mathbb{E}[e^{itX}]$ , for all $t\in\mathbb{R}$ , then can we conclude that $X$ and $\mathcal{G}$ are independent?","['conditional-expectation', 'conditional-probability', 'probability-theory', 'probability']"
3547169,Applications of the Clifford algebra in machine learning and statistics?,"I recently came across this article, "" Geometric algebra and computer graphics "" and started wondering whether there are interesting applications of Clifford/Geometric algebra to statistics and machine learning. Any pointers are appreciated, thanks!","['machine-learning', 'statistics', 'clifford-algebras']"
3547184,The area of interior quadrilateral formed by connecting trisect points and vertices of larger quadrilateral,"I drew a figure on GeoGebra to explore the area of the smaller quadrilateral formed by joining the vertices of the larger quadrilateral and the trisect points on the edges of the larger quadrilateral. Here is what I think to be correct: $$Area_{\Delta E_2H_2G_2F_2}=\frac{2}{5}Area_{\Delta A_1B_1C_1D_1}$$ I haven't figured out a way to prove this question yet. If this is correct, could any of you provide a possible solution to the problem?",['geometry']
3547209,Difficulty working with $\forall$ quantifiers in particular proofs.,"I've been trying for a while now to prove that $(g \circ f) = ((g\circ f)^{-1})^{-1}$ as a corollary to one of the exercises in Tao's Analysis I book. I am trying to restrict myself to the following strategy because it highlights an issue that I have seen come up several time in my proofs . The goal of this proof is to conclude with the statement that $\forall x \in X, (g \circ f (x)) = (((g\circ f)^{-1})^{-1}(x))$ . This is the definition of function equality. Also, just for clarity: $f: X \to Y$ and $g:Y \to Z$ Here is what I know from prior exercises and prior proofs in the book: $(g\circ f)$ is bijective $(g \circ f)^{-1}$ is bijective $((g \circ f)^{-1})^{-1}$ is bijective $(g \circ f)^{-1}(g \circ f \ (x)) = x$ $(g \circ f)^{-1}(((g \circ f)^{-1})^{-1}\ (x))=x$ The proof is as follows: From $4$ and $5$ we know that: $(g \circ f)^{-1}(g \circ f \ (x)) = (g \circ f)^{-1}(((g \circ f)^{-1})^{-1}\ (x))$ From $2$ , we have the following statement: $\forall z \in Z$ if $(g \circ f)^{-1}(z)=(g \circ f)^{-1}(z')$ , then $z=z'$ . From $1$ and $3$ we have: $(g \circ f \ (X))=Z$ and $(((g \circ f)^{-1})^{-1} \ (X))=Z$ . Because every $z^* \in Z$ can be represented by a particular $(g \circ f \ (x^*))$ and a particular $(((g \circ f)^{-1})^{-1} \ (x^*))$ , I am going to rewrite my earlier statement as: $\forall z \in Z$ if $(g \circ f)^{-1}(g \circ f \ (x))=(g \circ f)^{-1}(((g \circ f)^{-1})^{-1}\ (x))$ , then $(g \circ f \ (x))=(((g \circ f)^{-1})^{-1}\ (x))$ . Now, the consequent of this statement is certainly part of what I want...however, I cannot figure out how (informally stated) $\forall z \in Z \implies \forall x \in X$ . I am struggling with the logical step(s) to get to this concluding statement. It's certainly intuitive that this SHOULD BE the case, but I cannot for the life of me figure out the proper wording to get here. Any help is greatly appreciated!","['proof-writing', 'functions', 'first-order-logic']"
3547220,Why does a power series converge absolutely within the radius of convergence using the root test?,"Here is one argument that I understand for why this is true, using the comparison test. Suppose the series $$\sum_{n=1}^{\infty}c_nx^n$$ converges for $|x|<R$ . We want to show that the series converges absolutely in the interval $[-R+\epsilon, R-\epsilon]$ Choose $\zeta $ such that $R-\epsilon<R-\zeta<R$ Then for $x\in[-R+\epsilon, R-\epsilon]$ , $$|c_nx^n|\leq |c_n (R-\epsilon)^n|=|c_n||R-\zeta|^n\frac{|R-\epsilon|^n}{|R-\zeta|^n}.$$ But since $\sum c_n(R-\epsilon)^n$ converges, there exists $M$ such that $M\geq |c_n(R-\epsilon)|^n$ for all $n$ . This, $$|c_nx^n|\leq M\frac{|R-\epsilon|^n}{|R-\zeta|^n},$$ and the result follows by comparison with the geometric series. My real question is, in Rudin, it is claimed that every power series converges absolutely within the radius of converges using the root test. I understand the formula given by $$R=\frac{1}{\limsup_{n\to\infty} |c_n|^{\frac{1}{n}}}.$$ I know that the series $\sum c_n (R-\epsilon)^n$ converges for any epsilon positive, but I cannot make any conclusion about the value of $$\limsup_{n\to\infty} |c_n(R-\epsilon)|^{\frac{1}{n}}.$$ (Since the converse to root test may not be true). Thanks in advance","['power-series', 'calculus', 'sequences-and-series', 'real-analysis']"
3547321,Inequality from a projectile motion problem,"Imagine this scenario: Two objects are thrown simultaneously, from $y=0$ , with different speeds $u$ and $v$ , and at angles $\varphi$ and $\varphi+\theta$ . We want to find out which projectile returns to its original position first (i.e $y=0$ ). When they are both back at it, the distance between them is $\Delta x$ , which we assume is positive. We assume that $\varphi+\theta\leq\pi/2$ , and that the angle $\varphi$ is associated to the projectile thrown with speed $u$ . Given: $\varphi+\theta\leq\frac{\pi}{2}$ , $\Delta x\geq0$ . For both projectiles, we can express their motion vector like this: $$\vec r(t)=(v_xt)\hat\imath+(v_yt-\frac{1}{2}gt^2)\hat\jmath$$ If I suppose that $A$ 's final position is $x$ , then I can find the time like this: $$t_A=\frac{x}{v\cos(\varphi+\theta)}=\frac{2v}{g}\sin(\varphi+\theta)$$ Doing the same thing for $B$ , I get: $$t_B=\frac{x+\Delta x}{u\cos(\varphi)}=\frac{2u}{g}\sin(\varphi)$$ Taking the difference using the solution from the $y$ coordinates: $$t_A-t_B=\frac{2}{g}(v\sin(\varphi+\theta)-u\sin(\varphi))$$ I know that $\sin(\varphi+\theta)\geq\sin(\varphi)$ , but I have no idea how the velocities are. The quotient of the times can help me, though: $$\frac{t_A}{t_B}=\frac{v}{u}\frac{\sin(\varphi+\theta)}{\sin(\varphi)}=\frac{x}{x+\Delta x}\frac{u\cos(\varphi)}{v\cos(\varphi+\theta)}$$ which means that: $$\frac{u^2}{v^2}=\frac{x+\Delta x}{x}\frac{\sin(\varphi+\theta)\cos(\varphi+\theta)}{\sin(\varphi)\cos(\varphi)}
=\frac{x+\Delta x}{x}\frac{\sin\left(2(\varphi+\theta)\right)}{\sin(2\varphi)}\geq1$$ or, in other words, $u\geq v$ and: $$u=v\sqrt{\frac{x+\Delta x}{x}\frac{\sin\left(2(\varphi+\theta)\right)}{\sin(2\varphi)}}$$ Going back to my orginal time difference: $$\begin{align*}
t_A-t_B&=\frac{2}{g}(v\sin(\varphi+\theta)-u\sin(\varphi))\\
&=\frac{2}{g}\sin(\varphi)\left(\frac{\sin(\varphi+\theta)}{\sin(\varphi)}v-u\right)\\
&=\frac{2}{g}\sin(\varphi)v\left(\frac{\sin(\varphi+\theta)}{\sin(\varphi)}-\sqrt{\frac{x+\Delta x}{x}\frac{\sin\left(2(\varphi+\theta)\right)}{\sin(2\varphi)}}\right)
\end{align*}$$ But how can I judge the sign of the difference between the parenthesis? Any ideas? Thank you for your time!","['physics', 'trigonometry', 'inequality']"
3547399,Is there a bijection between uncountable sets?,"I know that there is a bijection between naturals and rationals. I also know that there is no bijection between naturals and reals (diagonal argument). But, I have never heard of the existence of a bijection between uncountable sets (ex aleph-one). Is there a way to create a (computable ?) function that takes an element from an uncountable set and outputs (in infinite time ?) an element from another uncountable set ? (I do not have a strong mathematical background, so please keep it simple or use terms of computer science) [EDIT] It seems that my question was very trivial. An answer would be y = f(R) where f is just one-to-one. I was hoping for something more sophosticated :( . Sorry for the inconvenience. [EDIT2] How we would construct a bijection between these sets ? A = reals B = reals without naturals C = reals without primes","['elementary-set-theory', 'cardinals']"
3547418,Particular integral of a differential equation having a complicated exponential function,"So I have to solve the differential equation $x^2\frac{d^2y}{dx^2}+x\frac{dy}{dx}-y=x^2e^{2x}$ I identified this as a differential in Cauchy-Euler form, and used the substitution x=e^t to obtain $\frac{d^2y}{dx^2}-y=e^{2(t+e^t)}$ The Complementary function is pretty easy. Now I cannot understand how to find the Particular Integral.
I rearranged the equation as $y=\frac{e^{2t}.e^{2e^t}}{D^2-1}$ where $D=\frac{d}{dt}$ .
Then I substituted $D+2$ in place of $D$ according to the known rule. Now what should I do? Also, is what I've done till now correct? I've worked with differential equations where exponential functions were paired with trigonometric or linear functions, but not such functions before. Any help is appreciated. Thanks in advance.",['ordinary-differential-equations']
3547463,Find the $x$ and $y$ values that satisfy the constrained optimisation problem.,"I have the following constrained optimisation problem. We have the following multivariable function: $$f(x,y) = 4x^2 +4y^2 +3xy -2x +4$$ This function is minimised on the line: $$0 = \vec n \ (\vec x -\vec p)= \begin{bmatrix}-1\\1\end{bmatrix} \left(\begin{bmatrix}x\\y\end{bmatrix}-\begin{bmatrix}-2\\3\end{bmatrix} \right)$$ I have to use the Lagrange Multipliers to solve this problem and get the $x$ and $y$ values. I'm not sure how to go about doing this problem because normally I work with $g(x,y)$ as a linear equation which equals a constant (i.e. $x+y=12$ ). My initial idea was to write down the Lagrange Multipliers, since $f$ is subject to the constraint $g(x,y) = 0$ and simplify the line equation into a polynomial function. The function is as follows: $$L(x, y, \lambda)=f(x,y)+\lambda (g(x,y)-c)$$ The line equation in its equivalent polynomial form: $$-x+y-5 \equiv y-x = 5$$ Thus $c = 5$ and we have: $$L(x,y, \lambda) = (4x^2+4y^2 +3xy -2x +4) - \lambda(-x+y-5)$$ From here I can find the gradient of $L$ , which would be: $$\nabla L= \begin{bmatrix}8x+3y-2+ \lambda\\8y +3x-\lambda\\x-y+5\end{bmatrix}$$ I then setup an augmented matrix and reduced it to RREF to solve for $x$ and $y$ . The augmented matrix $A$ is as follows: $$\left[\begin{array}{rrr|r}
8 & 3 & 1 & 2\\
3 & 8 & -1 & 0\\
1 & -1 & 0 & -5
\end{array}\right] \to  ... \to \left[\begin{array}{rrr|r}
1 & 0 & 0 & -\frac{55}{22}\\
0 & 1 & 0 & -\frac{57}{22}\\
0 & 0 & 1 & -\frac{27}{2}
\end{array}\right]$$ Therefore, $x = -2.50$ and $y=-2.59$ . Hopefully this is correct but again, I'm not a 100% sure because of the line constraint. Edit: There is a computation error in reducing the augmented matrix (RREF). As stated in the comments and answers, the correct answers are $x=-2.41$ and $y=2.59$ .","['vectors', 'real-analysis', 'matrices', 'linear-algebra', 'optimization']"
3547523,modular curves over $\mathbb{C}$ as Riemann surfaces,"Let $\mathscr{M}_*(N)$ be the Deligne Mumford stack of elliptic curves with the level $\Gamma_*(N)$ .
( $* = \varnothing, 0, 1$ or bal. $1$ , see Katz-Mazur.)
Then this has the coarse moduli scheme $Y$ over $\mathbb{Z}$ . (not complex manifold) I want to show that as Riemann surfaces, $Y(\mathbb{C}) \cong \mathbb{H}/\Gamma$ , for suitable group $\Gamma$ .
(e.g., $\Gamma(N) = \operatorname{ker}(\operatorname{SL}_2\mathbb{Z} \to \operatorname{SL}_2\mathbb{Z}/N), \Gamma_0(N) = \{ \gamma \in \operatorname{SL}_2\mathbb{Z} | \gamma \equiv 
$$\begin{bmatrix}* & *\\0 & *\end{bmatrix} \mod N \}$ etc.) (Where by ""the Riemann surface defined by an affine smooth algebraic variety $X$ over $\mathbb{C}$ "", I mean the Riemann surface induced by a closed immersion $X \subseteq \mathbb{A}_\mathbb{C}^N$ and the identification $\mathbb{A}^N(\mathbb{C}) = \mathbb{C}^N$ .
See appendix B in Hartshorne's AG.) Here is what I have tried: First, by the definition of coarse moduli and by some fundamental properties about classical modular forms (e.g., see theorem 1.5.1 of Diamond-Shurman's text), we have $\require{AMScd}$ \begin{CD}
|\mathscr{M}_*(N)(\mathbb{C})| @>{\text{bijective}}>> Y(\mathbb{C}) \\
@V{\text{bijective}}VV \\
\mathbb{H}/\Gamma.
\end{CD} So if $\mathbb{H}/\Gamma$ is algebraic over $\mathbb{C}$ (write it by $Z$ ) and if we have a map $\mathscr{M}_*(N) \to Z$ , then $Y \cong Z$ , and so as Riemann surfaces $Y(\mathbb{C}) \cong \mathbb{H}/\Gamma$ . (By the universal property of a coarse moduli, we have $Y \to Z$ .
By above argument this is bijective on $\mathbb{C}$ rational points.
Thus is an isomoprhism, by Zariski Main theorem.) Because $\mathbb{H}^*/\Gamma$ ( $\mathbb{H}^*$ is the upper half plane with the cusps) is algebraic, it seems that $\mathbb{H}/\Gamma$ is also algebraic. However I have no idea how to get a map $\mathscr{M}_*(N) \to Z$ . (To define this map, by noetherian reduction and by the sheaf condition of representable functors on fpqc sites, it sufficies to define maps $\mathscr{M}_*(N)(S) \to Z(S)$ functorially for all affine scheme $S$ over $\mathbb{C}$ of finite type, I think.) Thank you very much!","['riemann-surfaces', 'modular-forms', 'algebraic-geometry', 'elliptic-curves']"
3547528,Every even degree polynomial is eventually symmetric,"Let  we have  a  polynomial function $F:\mathbb{R} \to \mathbb{R}$ with $F(x)=ax^{2n}+bx^{2n-1}+\ldots+px+q$ . We assume  that $a>0$ . For    sufficiently large $y$ ,  let $A(y), B(y)$ be two distinct right inverses of $F$ , that  is $F(A(y))=F(B(y))=y$ please see the picture of this  linked page Prove that $$\lim_{y\to{\infty}} A(y)+B(y)=-b/na$$ I  had  and I  have a  proof  for  this exercise but  I am searching for  some  other proofs or some other elementary proofs. Moreover   I wish to check and examine  whether it is really a very trivial elementary exercise or it is a bit nontrivial. Note that for  higher degrees, according to Galois, we have  no  a  precise  formula for $A(y)$ and $B(y)$ . Pleease see page 4, item III line $-3$ of    my paper  below. The journal who accepted my paper (year 2002), did not  asked me to provide any  proof. Regarding this limit , inside the paper below I wrote that  ""it is a simple  exercise"". I did not write any proof of this limit in my thesis. No one in my defense committee asked me any proof of this limit . After all I think that it is  quite easy to proof. Thought it is  a  very simple  limit but playt a  crucial role to determine the  stability of  the  homoclinic loop based at equattor of Poincare sphere: https://arxiv.org/pdf/math/0409594.pdf RemarK: This  actualy gives us some information on the  sum of  complex  preimages $F^{-1}(y) \subset \mathbb{C}$ as $y$ goes to $\infty$ . On the other hand, inspired by this post one may think to upper and  lower bound on  the norm of  subsets of $F^{-1}(y)$","['analysis', 'real-analysis', 'calculus', 'polynomials', 'limits']"
3547572,Hatcher's Algebraic Topology. Exercise 2.2.42,"Update: My attempts are moved to my answer. This is Exercise 2.2.42 in page 159 of Hatcher's Algebraic Topology . Let $X$ be a finite connected graph having no vertex that is the endpoint of just one edge, and suppose that $H_1(X; \Bbb Z)$ is free abelian of rank $n>1$ , so the group of automorphisms of $H_1(X; \Bbb Z)$ is $GL_n(\Bbb Z)$ . Show that if $G$ is a finite group of homeomorphisms of $X$ , then the homomorphism $\phi:G \to GL_n(\Bbb Z)$ assigning to $g:X \to X$ the induced homomorphism $g_*:H_1(X;\Bbb Z) \to H_1(X;\Bbb Z)$ is injective. Show the same result holds if the coefficient group $\Bbb Z$ is replaces by $\Bbb Z_m$ with $m>2$ . What goes wrong when $m=2$ ? Are there any hints or suggestions? Thanks for your time and effort!","['graph-theory', 'general-topology', 'homology-cohomology', 'algebraic-topology']"
3547656,Why are even primes notable?,"There are much-discussed theorems like Fermat's theorem on sums of two squares which make statements about odd primes only. This makes $2$ seem to be a ""special"" prime. In their book The book of numbers , Conway and Guy accordingly state that ""Two is celebrated as the only even prime, which in some sense makes it the oddest prime of all."" On the other hand, the fact that $2$ is the only even prime is completely trivial, because the term ""even"" means the same thing as ""divisible by $2$ "" and every prime number has the property that it is the only prime which is divisiable by itself. So my question is : Is there really something special about even primes and if yes, what is it? Does aesthetics with regard to the theorems we are looking for play a role or is there a mathematical reason? Do we have theorems about primes which aren't divisible by $3, 5, ... $ or are there only results which don't apply to even primes? Edit : As the user A.G has mentioned in a comment below, in many cases where we have a regular pattern, the fact that $2$ is too small for the pattern to kick in yet seems to be the decisive thing. So in these cases, the notable thing is not that $2$ is the only even prime but that it is the smallest prime.","['number-theory', 'soft-question', 'prime-numbers']"
3547680,"Does there exist a continuous function $f$ such that $f(x)+f(x^2)=x$ for $x\in[0,1]$?","Let $f$ be a continuous real valued function from $[0,1]$ such that $$f(x)+f(x^2)=x$$ for all $x\in [0,1]$ . Does there exist such a function? Plugging $x=0$ and $x=1$ respectively in the given equation we obtain $f(0)=0$ and $f(1)=\frac{1}{2}$ . By the intermediate value theorem, $f$ attains any value between $0$ and $1$ . Moreover, the range of $f$ is $[m,M]$ where $m$ (resp. $M$ ) is the minimum (resp. maximum) value of the function over $[0,1]$ . How to use these facts to decide whether such function exists or not? Please give some hint to proceed. Thank you.","['functional-equations', 'examples-counterexamples', 'real-analysis', 'continuity', 'power-series']"
3547692,"Find values of $x$, such as $\log_3 \sqrt{x+3}−\log_3(9−x^2) < 0$","The Function is $$f(x) = \log_3\sqrt{(x+3)}−\log_3(9−x^2)$$ and I need to figure out arguments for which $$ f(x) < 0 $$ So I calculated the domain of function which is $ D: (-3;3)$ However I am still unable to solve $f(x) < 0$ I simplified $  \log_3\sqrt{(x+3)}−\log_3(9−x^2) < 0$ to $\log_3\frac{\sqrt{(x+3)}}{(9-x^2)} < 0$ which gets me to $$ \frac{\sqrt{(x+3)}}{9-x^2} < 1$$ But the solutions of the above equation are complex numbers and I definitely should get them as my result. So, what I am doing wrong here? Would apprecite every answer","['real-numbers', 'calculus', 'functions', 'logarithms']"
3547757,A formula for any finite sequence of number,"In Advanced Problems in Mathematics by Stephen Siklos, pg24, he writes ""Given any finite sequence of numbers, a formula can always be found
  which will fit all given numbers and which makes the next number
  (e.g.) 42."" Is there a source or proof for this statement?",['sequences-and-series']
3547836,Why is the sum of two algebraic functions algebraic?,"Let $U\subset\mathbb{C}^n$ be a domain. A holomorphic function $f:U\to \mathbb{C}$ is called $\textbf{algebraic}$ if there exists a polynomial $p(x,y)$ in the variables of $U\times \mathbb{C}$ such that $p(x,f(x))=0$ . A more geometric interpretation is that the graph $G_f$ of $f$ is an $\textbf{analytic component}$ of an algebraic set $X$ . My question is: say $f,g$ are two algebraic functions, why is $f+g$ algebraic? It is unclear to me if the roots of $p$ define holomorphic functions, if they define them on all of $U$ etc. I also have a more general question. Say $f_1,_2:\mathbb{C}\to \mathbb{C}$ and $g:\mathbb{C}^2\to\mathbb{C}$ , all three algebraic. (Also I ask about the case where they are defined on some general domain, I just require them to be composable). Why is $g(f_1,f_2):\mathbb{C}\to\mathbb{C}$ algebraic? Here there is a real issue, that the zariski closure of the graph of $G$ may be bad over some set (say it contains the entire fibre) and $(f_1,f_2)$ may hit this set. So that the graph of the composition is in general $\textbf{NOT}$ an analytic component of $\overline{G_g}\cap (f_1,f_2)(\mathbb{C})\times\mathbb{C}$ . However it does seem that the composition is in general algebraic - why? Thank you very much!","['complex-geometry', 'several-complex-variables', 'algebraic-geometry', 'analyticity']"
3547852,Let $G$ be a group with order $14$ [duplicate],"This question already has an answer here : Question on groups of order $pq$ (1 answer) Closed 4 years ago . Let $G$ be a group with order $14$ . Proof that: a) $G$ contains normal proper subgroup b) $G$ is isomorphic with $\mathbb{Z}_{14}$ or $G$ is isomorphic with $D_7$ . Solution: $H \le G$ is normal $ \Leftrightarrow \forall_{g\in G} g H g^{-1} = \{ ghg^{-1} : h \in H \} = H$ From Lagrange theorem: $|G| < \infty, H \le G \implies |G| = |H| \cdot [G:H]$ From Cauchy theorem: $|G| < \infty$ , p is prime, $p\mid | 
G| \implies $ in $G$ exists an element with order $p$ , so also subgroup with order $p$ Prime divisions of $14:2,7$ so in $G$ exists $|H_1| = 2, |H_2| = 7$ . In each of these subgroups exists neutral element and some different elements so at total we have $1+1+6=8$ . So we don't have still considered $6$ element what give us $2$ possibilities for $2$ subgroups with order $7$ , one with order $2$ or four with order $2$ , one with order $7$ . But how can I proceed with that?","['group-theory', 'abstract-algebra']"
3547899,"Given $f(x) = x^n e^{-x}$, show that $\int_0^1 f(x)\, dx$ is equal to a given expression.",Consider the function: $$f : \mathbb{R} \rightarrow \mathbb{R} \hspace{2cm} f(x) = x^n e^{-x}$$ I have to show the following: $$\int_0^1 f(x) dx = n! \bigg [ 1 - \dfrac{1}{e} \bigg ( 1 + \dfrac{1}{1!} + \dfrac{1}{2!} + \dfrac{1}{3!} + ... + \dfrac{1}{n!} \bigg ) \bigg ]$$ I used the notation: $$I_n = \int_0^1 f(x)dx$$ And by integrating by parts I got the recurrence formula: $$I_n = - \dfrac{1}{e} + n \cdot I_{n - 1}$$ But I don't have any idea as to how I could show what is asked.,"['integration', 'calculus', 'definite-integrals']"
3547977,Closed but not topological complementary spaces,"I’ve shown that if $U$ and $V$ are topologically  complementary then they are closed on a normed space. Also, I’ve shown that if $X$ is a Banach space and $U,V$ are closed complementary subspaces then they are topologically complementary. My question is what if $X$ is not Banach for second? I could not find a counter example for complementary subspaces that are closed but not topological. My definition for topologic complements on a normed space : $U,V \subset X$ are complementary subspaces. $\forall x \in X, \quad x=u_x+v_x$ where $u_x \in U, v_x \in V$ If the mappings $P_U(x)=u_x, P_V(x)=v_x$ are continuous then $U,V$ are topologically complementary. Thanks in advance","['projection', 'linear-algebra', 'functional-analysis']"
3548097,"Find the slope of the graph of $xy-2y^2=8$ at $(10,4)$","Find the slope of the graph of $xy-2y^2=8$ at $(10,4)$ So there are two different routes we could take: We could implicitly differentiate, then solve for $\frac{dy}{dx}$ (the slope), then plug in the point $(10,4)$ . Or, we could implicitly differentiate, then plug in the point $(10,4)$ , then solve for $\frac{dy}{dx}$ (the slope). in my solution I will solve for $\frac{dy}{dx}$ and THEN plug in the point $(10,4)$ Solution: $$\frac{d}{dx}(xy-2y^2)=\frac{d}{dx}8=0$$ $$\left(\frac{d}{dx}(xy)-2\frac{d}{dx}(y^2)\right)=0$$ We will need to use the product rule to evaluate $\frac{d}{dx}(xy)$ : $$\left(\left(\frac{d}{dx}x\right)y+\left(x\left(\frac{d}{dx}y\right)\right)-2\left(2y\frac{dy}{dx}\right)\right)=0$$ $$(1)y+\left(x(1)\frac{dy}{dx}\right)-4y\frac{dy}{dx}=0$$ $$y+x\frac{dy}{dx}-4y\frac{dy}{dx}=0$$ $$(x-4y)\frac{dy}{dx}=-y$$ $$\frac{dy}{dx}=\frac{-y}{x-4y}$$ Cool, so we have now took the implicit derivative and then solved for $\frac{dy}{dx}$ , now we plug in $(10,4)$ $$\frac{dy}{dx}=\frac{-4}{10-4(4)}$$ $$\frac{dy}{dx}=\frac{-4}{-6}$$ $$\frac{dy}{dx}=\frac{2}{3}$$ And so the slope of $xy-2y^2=8$ at $(10,4)$ is $\frac{2}{3}$","['calculus', 'solution-verification', 'derivatives', 'implicit-differentiation']"
3548147,Conditional Expectation and Second-Order Stochastic Dominance,"This question is about the distribution of the Conditional Expectation and how to use it to prove Second-Order Stochastic Dominance. Let $(\Omega, \mathcal{F},P)$ be a probability space. For any $X \in L^{\infty}(\Omega, P)$ , let $F_{X}$ be its cumulative distribution function and $q_{X}(t)=\inf \{x \in \mathbb{R}:F_{X}(x)>t\}$ its upper quantile function. Consider a sub $\sigma-$ field $\mathcal{G} \subset \mathcal{F}$ and let $Y:=E[X|\mathcal{G}]$ be a version of the conditional expectation of $X$ over $\mathcal{G}$ . I want to establish the second-order stochastic dominance of $Y$ over $X$ . In order to do so, I could either show that $\int_{-\infty}^{x}F_{Y}(t)dt \le \int_{-\infty}^{x}F_{X}(t)dt$ (with strict inequality at some $x \in \mathbb{R}$ ) or $\int_{0}^{\lambda}q_{Y}(t)dt \ge \int_{0}^{\lambda}q_{X}(t)dt$ (with strict inequality at some $\lambda \in (0,1]$ - I guess) Could someone give me hints on how to establish the above inequalities?","['conditional-expectation', 'probability-theory']"
3548171,Is whether there is a complete negatively curved surface embedded in the unit ball still an open problem?,"I was reading the text ""Open problems in geometry of curves and surfaces"" by Mohammad Ghomi, and on page 15 Problem 7.2 asks ""are there any complete negatively curved surfaces embedded in the unit ball?"" I tried googling to search for solutions to this problem, but was only able to find general definitions of complete negatively curved surfaces unrelated to the problem in this question. Is this still an open problem?","['curves', 'spheres', 'geometry']"
3548175,What is the problem with Euclidean geometry?,"I read somewhere that Euclid's element is a little outdated (sounds normal since it's super old) then i read on wikipedia: ""..Well-known modern axiomatizations of Euclidean geometry are those of Alfred Tarski, George Birkhoff and David Hilbert"".. so since there are 3 (and I guess more) ""new geometries"" I think they are somehow better then classic euclidean geometry (with this I mean the geometry explained by Euclid) so I was wondering what the problem is with the old geometry. Can you guys explain me in easy words please since I don't know more than high school level geometry? Thank you!","['euclidean-geometry', 'geometry']"
3548294,"Does Rudin's definition of ""bounded"" overlook the empty set?","In Definition $2.18$ of Baby Rudin, Rudin defines boundedness for metric spaces as follows: given a metric space $X$ , and a set $E \subset X$ , we say $E$ is bounded if there exists a real number $M$ and a point $q \in X$ such that $d(p,q) < M$ for all $p \in E$ . Per this definition, if $E=X=\varnothing$ , then $E$ is unbounded. The reason is that ""there exists a point $q \in X$ "" is a false statement if $X = \varnothing$ . Should this be regarded as a minor mistake/typo in Baby Rudin? Or are there particular reasons the empty set should be considered unbounded? If we use the alternative definition that a set $E$ is bounded if there exists a real number $M$ such that for all $p,q \in E$ , $d(p,q) < M$ , then this coincides with the above definition for nonempty sets, but also always considers the empty set bounded.",['real-analysis']
3548368,Can anyone explain a compact set in a general topological space in an intuitive way?,"I know that there are many ways to define the compactness of the set in a topological space, e.g., $X$ is compact if and only if every open cover of $X$ has a finite subcover. I also know that it is the extension of the concept of the bounded closed set in an Euclidean space to a general topological space. However, I do not believe I truly understand what it is intuitively. Can anyone help me grasp the concept intuitively? ** I already got a wonderful answer, but please add more answers if you have different (or even similar) insight of yours. I can't examine what more I could learn on this post. I'm very excited!","['general-topology', 'compactness']"
3548511,Rays in $\mathbb{R}^n$ are closed,"A ray in $\mathbb{R}^n$ is a subset of the form $\{ x + t(y - x) \mid t \geq 0 \}$ for some distinct $x,y \in \mathbb{R}^n$ . Bourbaki's ""General Topology"" claim that such a ray is closed, but provide no proof. I can't find a proof myself. Let $R_{x,y} = \{ x + t(y - x) \mid t \geq 0 \}$ . To prove that $R_{x,y}$ is closed, we need to prove that $\mathbb{R}^n\setminus R_{x,y}$ open, that is, that for every $z \in \mathbb{R}^n\setminus R_{x,y}$ there is $\epsilon > 0$ such that $B_{\mathbb{R}^n}(z,\epsilon) \subseteq \mathbb{R}^n\setminus R_{x,y}$ . $\mathbb{R}^n\setminus R_{x,y}$ seems to consist of points of the form $x + t(y - x)$ where $t < 0$ and those who can't be written in the form $x + t(y - x)$ at all.","['general-topology', 'geometry']"
3548524,When every prime/irreducible element remains prime/irreducible in a ring extension,"Let $A \subseteq B$ be two commutative integral domains which are $\mathbb{C}$ -algebras. Question 1: Is it possible to find mild conditions on $A, B, A \subseteq B$ such that the following property P is satisfied: Property P: Every prime element in $A$ remains prime in $B$ . An empty example: $A=\mathbb{C}[x^2,x^3]$ , $B=\mathbb{C}[x]$ . There are no prime elements in $\mathbb{C}[x^2,x^3]$ , so the property is satisfied.
See this question. A nice example: If $B$ is the integral closure of $A$ in the fraction field of $A$ , then the property is satisfied, as was proved in an answer to this MO question. Non-examples: (i) $A=\mathbb{C}[x^2]$ , $B=\mathbb{C}[x^2,x^3]$ . $x^2$ is prime (= irreducible in a UFD) in $\mathbb{C}[x^2]$ , but $x^2$ is not prime in $\mathbb{C}[x^2,x^3]$ (it remains irreducible), since $x^2$ divides $x^6=x^2x^2x^2=x^3x^3$ but it does not divide $x^3$ . (ii) $A=\mathbb{Z}$ , $B=\mathbb{Z}[i]$ . $2$ is prime in $\mathbb{Z}$ (= irreducible in a UFD), but $2$ is not prime in $\mathbb{Z}[i]$ (also, it is not irreducible), since $2=(1+i)(1-i)$ divides the product $(1+i)(1-i)$ but it does not divide $1+i$ or $1-i$ ; this example was presented in an answer to this question. A plausible answer 1? Four mild conditions: (i) $Q(A)=Q(B)$ . ( $Q(D)$ denotes the fraction field of an integral domain $D$ ). (ii) $A^{\times}=B^{\times}$ .  ( $S^{\times}$ denotes the invertible elements of a set $S$ ). (iii) $B$ is integral over $A$ . (iv) $B$ is a finitely generated $A$ -algebra. Question 2: Is it possible to find mild conditions on $A, B, A \subseteq B$ such that the following property I is satisfied: Property I: Every irreducible element in $A$ remains irreducible in $B$ . Notice that the first, empty example, is not valid anymore since $x^2,x^3$ are irreducibles in $\mathbb{C}[x^2,x^3]$ , but reducibles in $\mathbb{C}[x]$ . Now I have asked the above question in MO also. Thank you very much!","['irreducible-polynomials', 'unique-factorization-domains', 'integral-domain', 'algebraic-geometry', 'commutative-algebra']"
3548635,"prove existence + compute $\lim_{(x, y) \to (0, 0)} \frac{e^{xy} - 1}{y}$ - is my proof correct?","$\lim_{(x, y) \to (0, 0)} \frac{e^{xy} - 1}{y}$ i'm substituting $t := e^x, u := e^y$ , then the limit looks like this: $\lim_{(t, u) \to (1, 1)} \frac{tu - 1}{\ln u}$ i believe that's acceptable, because even though $\ln u$ is only defined for $u>0$ , it is defined in small enough neighbourhoods of 1. does that make sense? i'm squeezing the transformed limit, using $|\ln u| < u$ for $u > 0.5$ , again limiting the validity of my squeezing functions (with the same argument). $o \leq |\frac{tu - 1}{\ln u}| = \frac{|tu - 1|}{|\ln u|} \leq \frac{|tu - 1|}{u}$ and since both, lower and upper limit, converge to 0 for $(t, u) \to (1, 1)$ , so will the middle one. would that be an acceptable proof? if not, what would be better? thanks!","['limits', 'multivariable-calculus', 'real-analysis']"
3548710,What is the image of the line $Re(z) = Im(z)$ under the transformation $f(z) = z^2$?,"What is the image of the line $\Re(z)$ = $\Im(z)$ under the transformation $f(z)=z^2$ ? My attempt so far: $z=x+iy$ ; thus if $f(z)=z^2$ , then we have $(x+iy)^2= x^2+2ixy-y^2$ . Is this correct: $f(z)=u(x,y)+iv(x,y)$ where $u(x,y) = x^2-y^2$ and $v(x,y)=2xy$ But if $\Re(z)=\Im(z)$ then is $u(x,y) = v(x,y)$ i.e $x^2-y^2=2xy$ I'm not sure if I am doing this correct and if so I'm not sure about how I should continue. Any help would be great; thanks.","['complex-analysis', 'functions', 'transformation']"
3548732,Integral of Brownian motion in a 2-d box,"Let $A=(a,b)\times (c,d) \subset \mathbb{R}^2$ with $0 \in A$ and $(B_t)$ be standard two dimensional Brownian motion. Additionally, let $\tau_A := \inf \{t\geq 0: B_t \notin A\}$ and let $g:A \to \mathbb{R}$ be a smooth bounded function which can be written as $g(x,y)=u(x)v(y)$ . I am investigating the random variable $$\int_0^{\tau_A} g(B_s) ds$$ in particular I am interested in the expectation $$E[\int_0^{\tau_A} g(B_s) ds].$$ I know that there is a connection to the Dirichlet problem but I am interested in calculating or estimating (in both directions) this expression in a stochastical way. E.g., a bound, which contains the $L^1$ norm of $g$ would be very interesting.
Since the domain $A$ is an ""easy"" one and $B_t$ consists of two one dimensional independent Brownian motions $B_t=(B_t^1, B_t^2)$ , I have tried to reduce the problem into one dimension in the following way: \begin{align*} 
E[\int_0^{\tau_A} g(B_s) ds] &= E^1 E^2 [\int_0^{\tau_{(a,b)}^1 \wedge  \tau_{(c,d)}^2} g(B_s^1,B_s^2) ds] \\
&= \int_0^{\infty}E^1 \big[ 1_{[0, \tau^1_{(a,b)})}(s)  u(B^1_s) \big] E^2 \big[1_{[0, \tau^2_{(c,d)})}(s) v(B^2_s)\big] d s
\end{align*} The superscripts $\{1,2\}$ refer to the distributions of the respective Brownian motion.
Now I have no further ideas on how to proceed and am not familiar with tools that could help me here. I would appreciate any help!","['integration', 'probability', 'stochastic-processes', 'brownian-motion', 'stochastic-calculus']"
3548735,How to create sequence of functions,"I'm sorry about this question but the more I think about this, the more I feel ignorant. How can I, by hand, create a sequence of functions $(f_h)_h$ , let's say in $L^2((01))$ , coverging, under the $\left\lVert \cdot\right\rVert_{L^1}$ norm, to $\frac{1}{\sqrt{x}}$ , for example. This specific example was meant to show that $L^2((0,1))$ is not closed in $L^1((0,1))$ , but this question would like to be way general, as I find myself always in trouble in creating explicitely sequences of functions. I'd really like to see the method for which create sequences, rather than simply read a specific answer as it won't help me grow, I think. Any solution, hint or reference would be much appreciate, thanks in advance.","['lp-spaces', 'functional-analysis', 'real-analysis']"
3548739,Does $\mathbb{F}_2$ have a finite free resolution as an $\mathbb{F}_2[\mathbb{Q}]$-module?,"If $k$ is a field with 2 elements and $\mathbb{Q}$ is the additive group of rational numbers, is there a finite resolution of $k$ as $R=k[\mathbb{Q}]$ module? By ""finite"" I mean a chain complex $$X=  R^{n_1}\rightarrow R^{n_{2}}\rightarrow \dots \rightarrow R^{n_{j}}\rightarrow k $$ where $R^{n}$ is a free generated R-module of dimension $n$ . Edit: It will be fine if one can find a finite resolution of finitely generated projective $R$ -module.","['homological-algebra', 'representation-theory', 'abstract-algebra', 'group-cohomology', 'group-theory']"
3548807,Is at least 1 of 4 non-concyclic points contained in the circle through the other 3?,"Given 4 coplanar points such that The 4 points do not fall on a circle No 3 of the points fall on a straight line Is it always true that at least one of the points will be contained in the circle that passes through the remaining 3? I believe it is probably true, but I have been struggling to find a proof that is not algebraically ""messy"". Here's my current thinking: since translations, reflections, rotations, and dilations do not change the essence of the problem, it is okay to make a sequence of these transformations to simplify things a bit. Look for the pair of points that are farthest apart, then do a sequence of transformations to put these 2 points at $(0,0)$ and $(1,0)$ . Call these $A$ and $B$ . Now, the remaining distances between any 2 points must be less than 1, which puts a pretty strict limit on where $C$ and $D$ can be located. I believe that either circle $ABC$ will contain $D$ , or circle $ABD$ will contain $C$ , or possibly both (after many trials with random points on Geogebra). Since $AB$ is a chord in either circle, and the maximum chord length is $2r$ , that means the radius of each circle is at least $\frac{1}{2}$ . I think I have most of the pieces, but I just can't think of how to make the proof ""rigorous"". Thanks for helping. Edit: I found a counterexample on Geogebra, where $A=(0,0)$ , $B=(1,0)$ , $CD < 1$ , but neither $C$ nor $D$ is contained in the circle through the remaining 3 points. However, one of $A$ or $B$ was contained in the circle through the other 3. What I want to be able to do is to take a set of 4 points, and then based on some characteristics of the points (distances, center of mass, etc) be able to say which point(s) will be contained by the circle through the others. Edit #2: I had previously thought that whichever of the 4 points was closest to the center of mass of the 4 points, i.e. $(\frac{x_1+x_2+x_3+x_4}{4},\frac{y_1+y_2+y_3+y_4}{4})$ , would be contained by the circle through the other 3, but I also found a counter example to that on Geogebra. 2 dead ends so far! As Piet Hein says, ""Problems worthy of attack prove their worth by hitting back.""","['euclidean-geometry', 'geometry']"
3548815,Show the charge of an electron?,"The charge a on one electron is too small to measure. However, one can make measurements of the current I passing through a detector. If N is the number of electrons passing through the detector in one second, then I = a N. Assume N is Poisson. Show that the charge on one electron is given by Variance( I )/Expected Value( I ). What I got so far...
since a is the charge of 1 electron, we want to solve a , where a = I /N. And $N$ is poisson, and the the pmf of a poisson random variable with rate $\lambda$ is $(1/x!) \lambda^x e^{-\lambda}$ . So substituting it in for $N$ , now we have $I/\text{(that whole jargon)}$ . I'm confused on how to further this to get Variance( I )/Expected Value( I ). (This is an exercise in my intro to stats book in the random variables section, but I'm completely lost on how to reduce this)","['statistics', 'random-variables']"
3548864,Where does this trigonometric substitution go wrong?,"$$I =\int\frac{1}{\sqrt{25-x^2}}dx$$ ( $\theta$ on left corner) $$\tag 1 5\cos(\theta)=x$$ $$\tag 2 5\sin(\theta)=\sqrt{25-x^2}$$ $$\tag 1 -5\sin(\theta)\,d\theta=dx$$ $$I=\int\frac{1}{5\sin(\theta)} \cdot (-5) \sin(\theta) \, d\theta$$ $$I=\int-d\theta$$ $$\tag 1 \theta=\arccos(x/5)$$ $$I = -\arccos\left(\frac{x}{5}\right)+c$$ However, putting this integral into WA gives $\arcsin\left(\frac{x}{5}\right)+c$ and two are clearly not equivalent.","['integration', 'calculus']"
3548915,Statistical test for boolean value groups,"Intro This question is somewhat of a prequel to this one - but can be seen also as a standalone! I have two distinct populations/measurements of boolean values: $\{x_i\}_{i=1}^{m_1},x_i \in \{0,1\},|x|=m_1$ and $\{y_i\}_{i=1}^{m_2},y_i\in\{0,1\},|y|=m_2$ . Each $x_i$ (and $y_i$ ) is independent of the other boolean values. These numbers represent activity values ( $1$ = active , $0$ = inactive ) of two different group of models, namely the good ones ( $x$ 's) and the bad ones ( $y$ 's). I wanted to find a measurement of how much the (mean) activity of the good models is different than the bad models' activity . So, I started with the average values $a_1=mean(x)$ and $a_2=mean(y)$ and took the difference: $d=a_1-a_2$ . Then I wanted to include a penalty related to the amount of models $m_1,m_2$ and this was solved in this question by introducing a proper scaling function for the difference $d$ . The problem I was considering that if I had two populations of continuous measurements, then I would probably do a Wilcoxon Rank Sum test (use wilcox.test in R for example) and get also a p-value + location parameter shift estimation (a kind of $d$ as is in the respective implementation) for this (for the boolean case, ranking methods are useless right?). So, the p-value would tell how sure I am about this difference - which is kind of what I wanted to solve numerically (by let's say inserting the uncertainty in the final formula) in this other question . All in all, I need a statistical test that would compare boolean values and get me as a result a p-value and the d difference (or similar) so to speak. What I tried So, since I work with two different and independent set of boolean values $\{x_i\}$ and $\{y_i\}$ the words binomial distribution and bionomial test came into my mind (from loooong ago :) But after reading about them for a while and playing with the respective R functions, it turned out not I wanted this to be. The most significant problem for me was that I do not know the probability of success , i.e. $p=P(x_i=1)$ (or $y_i$ for that matter) - actually that's what I want to know for each model category! I tried to use the average $a_1=mean(x)=p$ and then to take a value of the cumulative distribution but it does not give results representative to what I want (the average activity). And the binomial test does not come close to what I want either. For example: $x=\{0,0,0,0,1,0\}, m_1=n=6,p=1/6=0.1667$ and then I would calculate the $P(X\geq 1)=0.665$ , which is way higher than expected. Maybe I am overthinking it, but I believe there should be something close to what I want to do with this boolean dataset that I have. Any directions for distribution(s) or statistical tests that can accommodate my case are welcome! Also posted on Cross Validated .","['boolean-algebra', 'statistics', 'binomial-distribution', 'hypothesis-testing']"
3548929,Numbers on a line problem,"There are $n$ numbers on a line ( $1$ to $n$ ). The $n$ numbers can be in any order.
A step is defined as:
If the first number in the line is $k$ , then the first $k$ numbers are reversed, 
Prove that after a finite number of steps we always end with $1$ as the first number. Example:
Taking $n=5$ And arranging them in a random order $4,1,2,3,5$ . Step 1: $4$ is the first number, first $4$ numbers are reversed, $3,2,1,4,5$ . Step 2: Again $3$ is the first number, first $3$ numbers are reversed, $1,2,3,4,5$ . So we ended up with $1$ as the first number after exactly 2 steps, and we need to prove that we always end up with $1$ as the first number no matter what $n$ is, or how the numbers are arranged. My approach, I used induction but I am facing difficulty in applying the induction hypothesis, any hint would help.","['induction', 'combinatorics']"
3549038,Show $\int_{0}^{\infty}\frac{dx}{\sqrt{x^{4}+x}} = \frac{2 \Gamma(1/3) \Gamma(7/6)}{\sqrtπ}≈2.80436$,"How the following integral can be calculated? $$\int_{0}^{\infty}\frac{dx}{\sqrt{x^{4}+x}}$$ I tried to substitute $\sqrt{x^{3}+1}=u$ , but that would not help. Another way I used was $$\int_{0}^{\infty}\frac{dx}{\sqrt{x^{4}+x}}\le\int_{0}^{\infty}\frac{dx}{x^{2}}$$ which again is not useful, since I'm looking for a convergent integral.
Also integral-calculator.com could not solve the integral and WolframAlpha gave the following solution: $$\int_{0}^{\infty}\frac{dx}{\sqrt{x^{4}+x}} = \frac{2 \Gamma(1/3) \Gamma(7/6)}{\sqrtπ}≈2.80436$$ I don't know where this comes from, so can someone solve this integral or at least show me that the integral is convergent?","['integration', 'pi', 'definite-integrals', 'gamma-function']"
3549171,Prove that $m_a\geq \dfrac{b^2+c^2}{4R}$,"Let triangle ABC, $m_a$ the lenght of the median from A, $b,c$ the lenghts of the segments AC and AB respectively and R the circumradius. Prove that: $m_a\geq \dfrac{b^2+c^2}{4R}$ . I found this in a book and the hint was to denote M the midpoint of BC and $A_2$ the second intersection of the median and the circumcircle of the triangle. Then by power of a point we have that $AM \cdot MA_2=a^2/4$ . Also $AM+MA_2 \leq 2R$ . And then they said this to imply the conclusion. Please help me understand. Thank you in advance.","['euclidean-geometry', 'geometry', 'triangles', 'geometric-inequalities', 'inequality']"
3549202,Proof of $(1-x)x^n \leq \frac{n^n}{\left(n+1\right)^{n+1}}$ without use of derivatives,"If $x \in \left[0,1\right]$ and $n \in \mathbb{Z}^+$ , is it possible to show $$(1-x)x^n \leq \frac{n^n}{\left(n+1\right)^{n+1}}$$ without use of derivatives? With derivative it's smooth: Let $f(x)=(1-x)x^n.$ Thus, $$f'(x)=nx^{n-1}-(n+1)x^n=(n+1)x^{n-1}\left(\frac{n}{n+1}-x\right),$$ which gives $x_{\max}=\dfrac{n}{n+1}$ and we are done!","['inequality', 'a.m.-g.m.-inequality', 'real-analysis']"
3549287,Given by a graph is the function $f(x)$. How many solutions does $f(f(f(x)))=0$ have?,"This problem, like the other ones I've posted so far, is from a 2017 olympiad. It goes like this: Given by the following graph is the function $f(x)$ : How many solutions does $f(f(f(x)))=0$ have? In other words, how many time does the graph of $f(f(f(x)))$ touch or intersect the x-axis? For me, the issue already lies in identifying $f(x)$ . I know it must have something to do with $|x|$ . How would one go about solving this problem?","['contest-math', 'functions']"
3549306,Is $\ a + b$ defined by $\ (a + b)(x) = a(x) + b(x) $ a step function where $\ a $ and $\ b $ are step functions,"Note: x ∈ X $ is a step function where $ \ X ⊂ R^n $ is a finite union of boxes and $ \ a, b : X → [0,∞)$ are step functions. But I have only just started looking at step functions and I am struggling to come to terms with how this is possible. So I know that a function a is a step function if a takes only finitely many values and if there exists a finite union of boxes $\ a^{-1} ([R_i, ∞)) = $ { $\ x ∈ X | a(x)∈[R_i, ∞) $ } But I don't know how I proceed knowing this. In an example I have done, I took values from a graph and plugged them into $\ a^{-1} (R_i, ∞)) $ for some $\ R_1 $ and $\ R_2 $ to show they are both boxes... but I am unsure how we use this to show the product is a step function. Apologies if this is a juvenile question, but like I say, I am new to this topic so I am still trying to understand it.","['step-function', 'analysis']"
3549321,Why most of the differential equation and theorem were formalized at no more than second derivative?,"I'm reading book where I realized that in many math books, i.e. Calculus, ODE, DG etc., many theorems and propositions were formalized in terms of first or second derivatives, or just any arbitrary derivatives. I mean, if it stopped at first derivative, it's somewhat understandable. But if a proposition proceeded to second derivative, why doesn't it just go to third, fourth, fifth... derivatives? I'm wondering that why people tend to stop at second derivative? Is there any particular theorems that second derivative was somewhat sufficient for some special/nontrivial conditions?","['calculus', 'analysis', 'ordinary-differential-equations', 'differential-geometry']"
3549437,Why derivative is a slope?,"The change of $Y$ per $X$ is slope. 
And some say the change of slope per $X$ is derivative.
So it is like slope of a slope! But slopes are always numbers like the slope of $2x$ is $2$ . But derivates are not just numbers like the derivative of $3x^2$ is $6x$ . This is confusing me can someone please explain? Thank you.","['calculus', 'derivatives', 'slope']"
3549459,Pigeonhole principle with two groups of balls labeled $1$ through $50$,"Say you have $50$ red balls, labeled $1$ through $50$ , and $50$ blue balls, also labeled $1$ through $50$ . You pick $10$ red balls and $10$ blue balls at random. Prove that you can make the sum of $1$ red and blue ball exactly match the sum of a different red ball and different blue ball. My thought process: The max combined number of one red and one blue is $100$ . The lowest combined combined number is $2$ . So there are $99$ possible sums. However, there are $100$ possible combinations of balls. There is one more combination than possible sum, so two combinations must have the same sum. Question: Am I missing something? I feel like I'm missing something. I'm sure there must be a trick and I'm not seeing it.","['pigeonhole-principle', 'combinatorics']"
3549461,"Show that $(X_{t})_{t\in[0,1]}$ of i.i.d random variables with non-degenerate distribution has no continuous modification","I am working on an exercise stating as follows: Let $(X_{t})_{t\in [0,1]}$ be an (uncountable) family of i.i.d random variables with non-degenerate distribution. Prove that no modification of this process can be continuous. I have some attempt but cannot proceed: Let $(\Omega,\mathcal{F},\mathbb{P})$ be the probability space over which $(X_{t})$ is defined. Suppose $X_{t}$ has a continuous modification $\tilde{X}_{t}$ . That is, there exists a $\Omega_{0}\subset\Omega$ with $\mathbb{P}(\Omega_{0})=1$ such that we can define a random function $\tilde{X}:\Omega_{0}\times T\longrightarrow\mathbb{R}$ that satisfies $\tilde{X}_{t}(\omega)$ is continuous in $t$ for all $\omega\in\Omega_{0}$ and $X$ and $\tilde{X}$ only differ on a set $\Omega\setminus\Omega_{0}$ with probability $0$ . Then, note that, in the aspect of $X_{t}$ , not all events are elements of $\mathcal{F}$ . For instance $$A:=\{\omega\in\Omega:X(\omega,t)=0\ \text{for all}\ t\in [0,1]\}=\bigcap_{t\in[0,1]}\{X(\omega, t)=0\},$$ since this is an uncountable intersection of measurable events from $\mathcal{F}$ . However, since $\tilde{X}_{t}$ is continuous on, then we can depict $$B:=\{\omega\in\Omega_{0}:\tilde{X}(\omega,t)=0\ \text{for all}\ t\in[0,1]\}=\bigcap_{t\in D}\{\omega\in\Omega_{0}:\tilde{X}(\omega,t)=0\},$$ where $D$ is a dense countable subset of $[0,1]$ , for instance, $D=\mathbb{Q}\cap [0,1]$ . Therefore, $B\in\mathcal{F}$ . Then I got stuck, and for now I haven't even used the i.i.d and non-degenerate.... what should I do to get contradiction? Thank you!","['stochastic-analysis', 'stochastic-processes', 'probability-theory', 'stochastic-calculus']"
3549464,A 19th Century Probability Problems Book Written by a British Monk,"I'm trying to find this book I occasionally used for didactic and fun-inducing purposes when I taught basic probability but I can't remember the author or the title, here are the facts I vaguely recall about it: It was freely available via Google Books as it's from I believe around 19th century Most modern probability and basic combinatorics word problems are based on all those problems in the book, some people don't even realize that The author wrote it during his tenure at a monastery somewhere in modern-day UK It has a bunch of problems with rather exotic/not so popular these days games like bridge It has a problem about men and women dancing in like rows (imagine those country dances of regional British nobility you see in some Jane Austen film adaptations and the whole idea behind such musical endeavors is matchmaking) and the question of the problem had a funny wording like ""in how many way can a marriage be effectuated between the dancers at the ball?"" Any pointers to what the book is or a link to Google Books would be much, much appreciated!","['math-history', 'probability-theory', 'probability', 'reference-request']"
3549524,Is the closed form for $\sum_{k=1}^\infty\frac{\overline{H}_k}{k^m}$ known in the literature?,"I managed to find $$\sum_{k=1}^\infty\frac{\overline{H}_k}{k^m}=(1-2^{-m})\sum_{k=1}^\infty\frac{H_k}{k^m}-2^{-m}\sum_{k=1}^\infty\frac{H_k}{(k+1/2)^m}$$ $$=(1-2^{-m})\left[\left(1+\frac m2\right)\zeta(m+1)-\frac12\sum_{i=1}^{m-2}\zeta(i+1)\zeta(m-i)\right]$$ $$+\frac{(-2)^{-m-1}}{(m-1)!}\left[2\gamma\ \psi^{(m-1)}\left(\frac12\right)-\psi^{(m)}\left(\frac12\right)+\lim_{\substack{a\to1/2}}\frac{\partial^{m-1}}{\partial a^{m-1}}\psi(a)^2\right]$$ Where $\overline{H}_k$ is the skew harmonic number, $\gamma$ is Euler–Mascheroni constant, $\zeta$ is the Riemann zeta function and $\psi^{(m)}(a)$ is the Polylogarithm function where $$\psi^{(m)}\left(\frac12\right)=(-1)^mm!(1-2^{m+1})\zeta(m+1)$$ My question is the closed form above known in the literature? and can we do further simplifications for the limit term to have a cleaner closed form? Also I would like to see different approaches. Thank you Proof $$\sum_{k=1}^\infty\frac{\overline{H}_k}{k^m}=1+\sum_{k=2}^\infty\frac{\overline{H}_k}{k^m}=1+\sum_{k=1}^\infty\frac{\overline{H}_{2k}}{(2k)^m}+\sum_{k=1}^\infty\frac{\overline{H}_{2k+1}}{(2k+1)^m}$$ By writing $\overline{H}_{2k}=H_{2k}-H_k$ and $\overline{H}_{2k+1}=H_{2k+1}-H_k$ we have $$\sum_{k=1}^\infty\frac{\overline{H}_{2k}}{(2k)^m}=\sum_{k=1}^\infty\frac{H_{2n}}{(2n)^m}-\sum_{n=1}^\infty\frac{H_{n}}{(2n)^m}=\frac12\sum_{k=1}^\infty\frac{(-1)^kH_{k}}{k^m}+\left(\frac12-2^{-m}\right)\sum_{k=1}^\infty\frac{H_{k}}{k^4}$$ and $$\sum_{k=1}^\infty\frac{\overline{H}_{2k+1}}{(2k+1)^m}=\color{blue}{\sum_{k=1}^\infty\frac{H_{2k+1}}{(2k+1)^m}}-\sum_{k=1}^\infty\frac{H_k}{(2n+1)^m}$$ $$=\color{blue}{-1+\sum_{n=0}^\infty\frac{H_{2n+1}}{(2n+1)^m}}-\sum_{k=1}^\infty\frac{H_k}{(2k+1)^m}$$ $$=\color{blue}{-1+\frac12\sum_{k=0}^\infty\frac{(-1)^kH_{k+1}}{(k+1)^m}+\frac12\sum_{k=0}^\infty\frac{H_{k+1}}{(k+1)^m}}-\sum_{n=1}^\infty\frac{H_n}{(2n+1)^m}$$ $$=\color{blue}{-1-\frac12\sum_{k=1}^\infty\frac{(-1)^kH_{k}}{k^m}+\frac12\sum_{k=1}^\infty\frac{H_{k}}{k^m}}-\sum_{k=1}^\infty\frac{H_k}{(2k+1)^m}\\$$ Combine the two sums, $$\Longrightarrow \sum_{k=1}^\infty\frac{\overline{H}_k}{k^m}=(1-2^{-m})\sum_{k=1}^\infty\frac{H_k}{k^m}-\sum_{k=1}^\infty\frac{H_k}{(2k+1)^m}\tag1$$ The first sum is well-known $$\sum_{k=1}^\infty\frac{H_k}{k^m}=\left(1+\frac m2\right)\zeta(m+1)-\frac12\sum_{i=1}^{m-2}\zeta(i+1)\zeta(m-i)$$ For the second sum, from here we have $$\int_0^1\frac{x^{n}\ln^m(x)\ln(1-x)}{1-x}\ dx=(-1)^{m-1}m!\sum_{k=1}^\infty\frac{H_k}{(k+n+1)^{m+1}}\\=\frac12\frac{\partial^m}{\partial n^m}\left(H_n^2+H_n^{(2)}\right),\quad n\in\mathbb{R}\ge-1,\quad m\in\mathbb{N}$$ Let $m+1\to m$ and $n+1=a$ we get $$(-1)^m (m-1)!\sum_{k=1}^\infty\frac{H_k}{(k+a)^m}=\frac12\frac{\partial^{m-1}}{\partial a^{m-1}}(H_{a-1}^2+H_{a-1}^{(2)})$$ Substitute $H_{a-1}=\psi(a)+\gamma$ and $H_{a-1}^{(2)}=\zeta(2)-\psi^{(1)}(a)$ $$(-1)^m (m-1)!\sum_{k=1}^\infty\frac{H_k}{(k+a)^m}=\frac12\frac{\partial^{m-1}}{\partial a^{m-1}}((\psi(a)+\gamma)^2+\zeta(2)-\psi^{(1)}(a))$$ Because $m\ge 2$ for convergence, we can ignore the constants $\gamma$ and $\zeta(2)$ on the right side, $$(-1)^m (m-1)!\sum_{k=1}^\infty\frac{H_k}{(k+a)^m}=\frac12\frac{\partial^{m-1}}{\partial a^{m-1}}(\psi(a)^2-\psi^{(1)}(a)+2\gamma\ \psi(a))$$ $$=\frac12\left[2\gamma\ \psi^{(m-1)}(a)-\psi^{(m)}(a)+\frac{\partial^{m-1}}{\partial a^{m-1}}\psi(a)^2\right]$$ Now take the limit to both sides and let $a\to 1/2$ we get $$\sum_{k=1}^\infty\frac{H_k}{(k+1/2)^m}=\frac{(-1)^m}{2(m-1)!}\left[2\gamma\ \psi^{(m-1)}\left(\frac12\right)-\psi^{(m)}\left(\frac12\right)+\lim_{\substack{a\to1/2}}\frac{\partial^{m-1}}{\partial a^{m-1}}\psi(a)^2\right]$$ By combining the results of the two sums, the closed form follows. Note I am tagging "" integration"" as logarithmic integrals and harmonic series are strongly related.","['integration', 'polygamma', 'harmonic-numbers', 'generating-functions', 'sequences-and-series']"
3549527,Prove $\int_a^b \frac{1}{x}\sqrt{-(x-a)(x-b)}dx = (\frac{a+b}{2}-\sqrt{ab})\pi$,"Does anyone know how to solve $$\int_a^b \frac{1}{x}\sqrt{-(x-a)(x-b)}dx$$ After trying Wolfram Alpha, I conclude that it possibly equals $(\frac{a+b}{2}-\sqrt{ab})\pi = \frac{(\sqrt{a}-\sqrt{b})^2}{2}\pi$ .
The book I am reading says one can use residue theorem to quickly obtain the result, but the details are not written and I cannot figure out the solution. P.S. One can prove from this integral that arithmetic mean $\geq$ geometric mean.","['integration', 'definite-integrals']"
3549578,A variation of Doob's maximal inequality,"I'm looking for a proof for the following proposition, stated in ""Brownian Motion, Martingales, and Stochastic Calculus"" by Le Gall (page 263): Let $X=(X_n)_{n\in\mathbb{N}}$ be a supermartingale. For any $n\in\mathbb{N}$ and any $\lambda>0$ - $$\lambda\mathbb{P}\left(\sup_{k\le n}\left|X_k\right|>\lambda\right)\le
\mathbb{E}\left[\left|X_0\right|\right]+2\mathbb{E}\left[\left|X_n\right|\right]$$ He writes that a proof can be found in ""Discrete-Parameter Martingales"" by Neveu, but I couldn't find it there. Not only I've failed proving it, I moreover got results that made me a bit suspicious about the above proposition. For example, I can show that whether $X$ is a supermartingale or a submartingle - $$\lambda\mathbb{P}\left(\sup_{k\le n}\left|X_k\right|>\lambda\right)\le
12\mathbb{E}\left[|X_0|\right]+9\mathbb{E}\left[|X_n|\right]$$ (note that at the RHS the coefficient of $\mathbb{E}\left[|X_0|\right]$ is larger than the coefficient of $\mathbb{E}\left[|X_n|\right]$ , while in the proposition above it's the other way around.)","['reference-request', 'stochastic-processes', 'martingales', 'probability-theory', 'probability']"
3549607,What lies behind the definitions of split monics and epics?,"Is there an easy way to memorize the definitions of split monics and split epics, and not to confuse the domains/codomains of the arrows from those definitions? For example, is there a mnemonic rule? And/or what's the motivation for those definitions that would enable one to ""deduce"" the definition of split monic/epic if one gets lost in domains-codomains involved in the definitions? I don't understand what lies behind those definitions.","['mnemonic', 'motivation', 'category-theory', 'definition', 'elementary-set-theory']"
3549642,$\displaystyle \sup_{t\in \mathbb{R}}\left(\sin(\sqrt 2 \ t)+\sin(t)\right)=2$,"How to prove that $$\sup_{t\in \mathbb{R}}\left(\sin(\sqrt 2 \ t)+\sin(t)\right)=2$$ I know that $\displaystyle  \sup_{t\in \mathbb{R}}\left(\sin(\sqrt 2 \ t)+\sin(t)\right)\leq 2$ . I also know that the supremum is not reached on some number $t_0$ , otherwise we would have $\sqrt 2 \in \mathbb{Q}$ .","['number-theory', 'limits', 'supremum-and-infimum', 'real-analysis']"
3549658,Linearization of $C^r$ ODE system,"Consider the following ODE system \begin{align*}
\dot{x} &= x^5 + y^3 = f(x\,,y) \\
\dot{y} &= x^3 - y^5 = g(x\,,y)
\end{align*} Clearly, $(x\,,y) = (0\,,0)$ is the only fixed point. Linearizing $$
J = 
\begin{bmatrix}
5x^4 & 3y^2 \\
3x^2 & -5y^4
\end{bmatrix}
$$ evaluating at the fixed point will just give a zero matrix. Thus, need to use some other approach to analyze the stability, e.g., Lyapunov function. However, I can't find any Lyapunov function related to this problem. Since this ODE system is at least $C^3$ in both $x$ and $y$ . So I am wondering, for the linearization, is it possible to go all the way to 3rd-order derivative? Maybe something like $$
\begin{bmatrix}
\frac{\partial^3f}{\partial x^3} & \frac{\partial^3f}{\partial y^3} \\
\frac{\partial^3g}{\partial x^3} & \frac{\partial^3g}{\partial y^3}
\end{bmatrix}
$$ This way the matrix will not be a zero matrix and can find corresponding eigenvalues and eigenvectors.","['stability-theory', 'linearization', 'ordinary-differential-equations']"
3549695,Number of odd and even permutation.,"I needed to find number of odd and even permutations in a symmetric group $S_n$ (having $n$ elements). What we do is select a arbitrary fixed  odd permutation $h \epsilon S_n $ . We know that $hS_n=$ { $hg:g\epsilon S_n$ } = $ S_n$ . Let's say there are $x$ odd permutations and $y$ even permutations in $S_n$ . Number of odd permutation in $hS_n$ is $y$ (formed $h \cdot \#$ (even permutation $\in S_n$ )) and even permutation= $x$ . As $S_n$ and $hS_n$ are same sets therefore $x=y$ . Therefore even = odd = $\frac{n!}{2}$ . So , according to my proof if we can find even one odd permutation then number of even and odd permutation are same in any group. A subset of $S_n$ can only be a subgroup of $S_n$ if the subset either contains equal odd and even permutations or only even permutation. Is my result correct, or did I make any mistake?","['permutations', 'finite-groups', 'group-theory', 'combinatorics']"
3549712,How to compute CNF from truth table,"How can I write a propositional formula with variables p, q, r in a CNF that has 3 models v1, v2, v3 : I've failed to find any related sources.","['propositional-calculus', 'conjunctive-normal-form', 'logic', 'discrete-mathematics']"
3549799,Is a weakly$^*$ convergent net of positive(!) Radon measures eventually norm-bounded?,"Let $X$ be a locally compact Hausdorff space and $C_0(X)$ the space of continuous functions vanishing at infinity. If $\mu_n$ is a sequence of positive Radon measures on $X$ such that $\mu_n \to \mu$ for the weak $^*$ topology $\sigma(M(X), C_0(X))$ then $\mu_n$ is norm-bounded. How does this generalize to nets? In contrast to sequences, a convergent net need not be bounded (""the initial parts of a net can be infinitely long""). Moreover, a weakly $^*$ convergent net (of signed Radon measures) need not be eventually bounded, see here .  Does positivity help out? If $\mu_\alpha \geq 0$ and $\mu_\alpha \to \mu$ for the weak $^*$ topology, does it follow that $\mu_\alpha$ is eventually norm-bounded, i.e. is there $\alpha_0$ such that $\sup_{\alpha \geq \alpha_0} \lVert \mu_\alpha \rVert = \sup_{\alpha \geq \alpha_0} \mu_\alpha(X) < \infty$ ? This is related to the question here , but may be of independent interest for the MSE community. Edit: Note that this is true if $X$ is compact, because $1_X \in C_0(X) = C(X)$ . Then $\mu_\alpha \to \mu$ weakly $^*$ implies $\mu_\alpha(X) \to \mu(X)$ , so that $\mu_\alpha(X)$ is a convergent net in $\mathbb{R}$ and therefore eventually bounded: for $\varepsilon = 1$ there is $\alpha_0$ such that $0 \leq \mu_\alpha(X) \leq \mu(X) + 1$ for all $\alpha \geq \alpha_0$ . In particular, this example of an unbounded weakly $^*$ convergent net of Radon measures does not work for positive measures/functionals.","['measure-theory', 'functional-analysis']"
3549832,Banach algebra definition,"Definition : A Banach algebra $A$ is a triple $(A, \Vert \cdot \Vert, m)$ where $\Vert \cdot\Vert$ is a norm on $A$ and $m: A \times A \to A$ is a $\mathbb{C}$ -bilinear associative map such that $(A, \Vert\cdot \Vert)$ is a Banach space and such that $(A,m)$ is a $\mathbb{C}$ -algebra, such that $$\Vert xy \Vert = \Vert m(x,y)\Vert \leq \Vert x \Vert \Vert y\Vert$$ for all $x,y \in A$ . My notes say: Assume $A$ is unital with identity $1_A$ . Changing to an equivalent norm, we may assume that $\Vert 1_A \Vert=1$ . How exactly is this done? If $(A, \Vert \cdot \Vert)$ is a Banach algebra, then I can define a new norm $$p: A  \to [0, \infty[: a \mapsto \Vert a\Vert/\Vert 1_A\Vert $$ and I see $p$ and $\Vert \cdot \Vert$ are equivalent norms but $(A, p)$ does not satisfy $p(x,y) \leq p(x) p(y)$ so it can't give a Banach algebra. Any insight is appreciated!","['banach-algebras', 'functional-analysis']"
3549838,Solving a given Differential Equation,I have tried quiet a lot of methods to solve the given ODE. $$xdy-(3y+x^5y^{1/3})dx = 0$$ Can anybody share any clue on solving this?,['ordinary-differential-equations']
3549852,Lipschitz continuity of conformal maps,"I have a basic question on Lipschitz continuity of maps. Let $\mathbb{D}$ be the unit disk and $T$ be an equilateral triangle. We have a conformal map $\phi :\mathbb{D} \to T$ , which is extended to a homeomorphism from $\overline{\mathbb{D}}$ to $\overline{T}$ . In fact, $\phi$ can also be given specifically by the Schwarz--Christoffel formula. Let $p$ denote a vertex of $T$ . Then, it follows from the formula that there exist $C>0$ and $R>0$ such that \begin{align*}
|\phi^{-1}(z)-\phi^{-1}(p)| \le C|z-p|^3
\end{align*} for any $z \in B(p,R)$ . Here, we denote by $B(p,R)$ the ball centered at $p$ with radius $R>0$ . In particular, $\phi^{-1}$ is Lipschitz continuous at vertices of $T$ . We also see that $\phi^{-1}$ is smooth at any points other than vertices. Then, can we show that $\phi^{-1}$ is Lipschitz continuous on $\overline{T}$ ? Now, $\phi^{-1}$ is smooth function on $\overline{T}$ . Hence, we conclude that $|(\phi^{-1})'|$ is bounded on $\overline{T}$ . Therefore, we can conclude that $\phi^{-1}$ is Lipschitz continuous. Is this proof correct?","['complex-analysis', 'solution-verification']"
3549874,"Can $\ a^k+b^k+c^k\ $ be prime for $\ k\in\{0,\ldots, m\}$ arbitary large?","Let $\ a,b,c\ $ be integers with $\ 0<a<b<c\ $ and let $\ m\ $ be the smallest non-negative integer such that $$a^m+b^m+c^m$$ is composite. Define $$f(a,b,c)=m-1$$ Hence $\ f(a,b,c)\ $ is the largest non-negative integer $\ m\ $ such that $$a^k+b^k+c^k$$ is prime for $\ k=0,\cdots ,m\ $ . Since for $\ k=0\ $ , we get always $\ 3\ $ which is a prime, $\ f(a,b,c)\ $ is always non-negative. Has $f(a,b,c)$ a maximum ? I have found $$f(2, 186, 803)=8$$ with brute force, that means that $\ 2^k+186^k+803^k\ $ is prime for $\ k=0,1,2,3,4,5,6,7,8\ $ which is unbeaten , if $\ c\le 1000\ $ holds.","['number-theory', 'elementary-number-theory', 'prime-numbers']"
3549897,Simple examples of rings with non-trivial Picard group and infinite Brauer group,"I am working on a certain problem about commutative rings which has an obstruction involving the Picard group and the (algebraic) Brauer group of the ring. The obstruction is trivial at least when the Picard group is trivial or when the Brauer groups is finite. I would like to find some suggestions of where to look for examples/counter-examples to this obstruction, so the question is: What would you say are the simplest examples of (commutative) rings with a non-trivial Picard group and infinite Brauer group? Here I mean ""simplest"" not in the sense that the rings are the simplest to describe, but rather where the Picard/Brauer groups are the simplest to compute and work with. Of course in the question you can replace ""commutative rings"" with ""affine schemes"", but if you have some nice examples of non-affine schemes that you think are more interesting than any affine ones, I would also be interested (the problem I'm working on has clear extensions to general schemes, I just would like to start with the affine case).","['big-list', 'examples-counterexamples', 'ring-theory', 'algebraic-geometry', 'commutative-algebra']"
3549930,What is the gradient of length of gradient of function $f$?,"Suppose $f\in C^3(M)$ and $\nabla f$ denotes the gradient of $f$ w.r.t Riemannian metric $g$ . Then what is the equivalent expression of the following? $$\nabla \langle \nabla f, \nabla f\rangle=?$$ Background problem: By definition $\mathrm{Hess} f(X, Y) = \langle \nabla _X(\nabla f), Y\rangle$ ; $\triangle f= \mathrm{tr}(\mathrm{Hess} f)$ . Now I want to calculate $\triangle|\nabla f|^2$ . By above definitions we have: $$\triangle|\nabla f|^2=\mathrm{tr}(\mathrm{Hess} \langle\nabla f,\nabla f\rangle)=\langle \nabla _{X_i}(\nabla \langle \nabla f, \nabla f\rangle), X_i\rangle.$$ But I saw somewhere that $$\triangle|\nabla f|^2=\sum_iX_iX_i\langle\nabla f,\nabla f\rangle.$$ Why these two (my calculation and last one) are equal?","['riemannian-geometry', 'differential-geometry']"
3549952,How can I solve $\int \frac{P_1(t)}{P_2(t)e^{P_3(t)}} dt$,"The other day I found an integral on the form: $$\int \frac{P_1(t)}{P_2(t)e^{P_3(t)}} dt$$ where $P_1,P_2,P_3$ all are polynomials. Does there exist any particular technique to approach solving such integrals? My own work is mostly limited to quite fruitless experimentation with logarithmic derivative. One idea I had was to rewrite it as $$I(t_1) = \int_{-\infty}^{t_1} \frac{P_1(t)}{P_2(t)e^{P_3(t)}} dt$$ Then, by fundamental theorem of calculus: $$\frac{\partial}{\partial t_1} I(t_1) = \frac{P_1(t_1)}{P_2(t_1)e^{P_3(t_1)}}$$ and: $$P_2(t_1)e^{P_3(t_1)} \frac{\partial}{\partial t_1} I(t_1) = {P_1(t_1)}$$ This would then be solved in power series with some machinery which could solve for example an expanded version of: this , allowing $P_k$ to be arbitrary power series instead of polynomials.","['integration', 'power-series', 'analysis', 'ordinary-differential-equations']"
3550000,Posterior distribution of uniform likelihood and Pareto prior,"Let the sampling distribution be $$\mathbf{Y}|\Theta\sim U(0,\theta)$$ and $$f(\mathbf{y}|\theta)=\prod^n_{i=1}\frac{1}{\theta}\times \mathbb{1\{0<y_i\le\theta\}}=\frac{1}{\theta^n}\times \mathbb{1}\{0<y_i\}\times \mathbb{1}\{c'\le\theta\},$$ where $c'=\text{max}\{y_1,...,y_i\}.$ Let the prior distribution be Pareto distributed. That is $$p(\theta)=\frac{Kb^K}{\theta^{K+1}}\mathbb\times{1\{b\le\theta\}}\propto \frac{1}{\theta^{K+1}}\mathbb\times{1\{b\le\theta\}}.$$ I'm trying to get the posterior distribution. That is, $$p(\theta|\mathbf{y})=\frac{1}{\theta^n}\frac{1}{\theta^{K+1}}\times \mathbb{1}\{0<y_i\}\times \mathbb{1}\{\text{max}\{b,c'\}\le\theta\} \\
=\theta^{-(n+K+1)}\times \mathbb{1}\{0<y_i\}\times \mathbb{1}\{\text{max}\{b,c'\}\le\theta\}.$$ However, the correct answer is $$p(\theta|\mathbf{y})=\theta^{-(n+K)}\times \mathbb{1}\{b\le\theta\}\times \mathbb{1}\{\text{max}\{b,c'\}\le\theta\}$$ but I don't know how to get there.","['statistical-inference', 'statistics', 'probability-distributions', 'bayesian']"
3550030,"Properties of space $X = T \cup \bigcup_{n=1}^{\infty} S_n \cup \{ (0,q) : q \in \mathbb Q \wedge q \in [0,1] \} $","Let $S_n$ be closed interval in euclidean plane $\mathbb R^2$ with ends in $(\frac{-1}{n}, \frac{1}{n})$ and $(\frac{-1}{n}, 1)$ . Moreover let $T$ be boundary of triangle with vertices $(1,1),(0,0),(-1,1)$ . A. Prove that subspace of plane $$ X = T \cup \bigcup_{n=1}^{\infty} S_n \cup \{ (0,q) : q \in \mathbb Q \wedge q \in [0,1] \} $$ is connected space but not arc connectedness B. Let $Y = \bar{X}$ - closure of the set $X$ in euclidean plane. Prove that $Y$ is not contractible space. My attempt: A. Let $U,V$ be open sets such that $U,V  \subset \mathbb R^2$ and $X \subset U \cup V$ . Assume that $(U \cap X) \cap (V \cap X)= \emptyset$ . Now we want to prove that $$(U \cap X) = \emptyset \mbox{ or } (V \cap X)= \emptyset $$ If $ X \subset U \cup V$ then $T \subset U \cup V$ . So $T \cap V \neq \emptyset $ or $T \cap U \neq \emptyset$ . Without lost of generality assume that $T\cap U \neq \emptyset$ . Then $T \cap V = \emptyset$ because $T$ jest connected ( $T$ is sum of three intervals and they create triangle and interval is connected). So $T \subset U $ . And that's why $\forall_{n} S_n \cap U \neq \emptyset $ because boundarie of triangle $T$ are ends of intervals from $\bigcup _{n=1}^{\infty} S_n$ . Each interval is connected. 
Let $(\frac{-1}{n}, 1) \in \bigcup _{n=1}^{\infty} S_n$ and $J= I ((\frac{-1}{n}, \frac{1}{n}), (\frac{-1}{n}, 1))$ . We know that $J \subset U \cup V$ and $J \cap U \neq \emptyset$ . That's why $J \cap V = \emptyset$ because $J$ is connected, so $J \subset U $ . So we have that $T \cup \bigcup_{n=1}^{\infty} S_n \subset U$ . My problems: Firstly, I want somebody to check my solution. Secondly, I am not sure how can I prove that: $$ \{ (0,q) | q \in \mathbb Q \wedge q \in [0,1] \} \subset U$$ If it comes to B. I didn't find any idea how to solve that.","['locally-connected', 'general-topology', 'connectedness']"
3550063,Quotients of $\mathbb{P}^1 \times \mathbb{P}^1$,"It is known that $\mathbb{P}^1 \times \mathbb{P}^1 \not \cong \mathbb{P}^2$ . One way to see this is working with their respective class groups, $\mathbb{Z}^2$ and $\mathbb{Z}$ , which in this case, since they are normal toric varieties are fairly easy to compute. My question is whether we can ""fix"" this by identifying some points on $X =\mathbb{P}^1 \times \mathbb{P}^1$ , that is, if there exists some free group action $\sigma \colon G \times X \to X$ ( $G$ finite) such that the quotient $X/G$ is isomorphic to $\mathbb{P}^2$ . Forgetting the algebraic-geometry structure, the action of $\mathbb{Z}_2$ on $X$ via permutation of elements is isomorphic to $\mathbb{P}^2$ , so: Does this extend to an isomorphism of schemes? Also, any references that deal with this type of quotients will be welcome, of course. Thank you. Note: I wrote that the action is free because apparently this guarantees that the quotient is at least an algebraic space; the finiteness requirement guarantees that it is actually a scheme, as in the answers to this question.","['group-schemes', 'geometric-invariant-theory', 'algebraic-geometry', 'quotient-spaces']"
3550096,Minimal counterexample to $\frac{p - 1}{p^2}$-conjecture,"There existed once a “folklore” conjecture that stated: Suppose $p$ is a prime. Then any finite group $G$ with $> (1 - \frac{p-1}{p^2})|G|$ elements of order $p$ has exponent $p$ This conjecture was disproved by G.E.Wall in 1965, who constructed a group of exponent $25$ , where all elements of order $25$ lie in the subgroup of index $25$ . My question is: What is the minimal possible size of a counterexample to this conjecture? I am interested in it because I collect disproven conjectures with large  minimal counterexamples Note, that $p$ in this counterexample has to be $5$ of greater, as the conjecture was proven to be true for $p = 2$ and $p = 3$ by Thomas Laffey in 1976.","['conjectures', 'finite-groups', 'combinatorics', 'group-theory', 'prime-numbers']"
3550122,A computation with ramification groups,"I am trying to solve Exercise 3, Chapter 4, $\S 2$ of Local Fields by Serre.
The exercise is about ramification groups. Let $L/K$ be a $p$ -adic field extension with uniformizer $\pi$ . Assume it is Galois with Galois group $G$ . Let $e$ be the ramification index of $L$ over $\mathbf Q_p$ . Take $s$ in the $i$ -th ramification group $G_i$ , $i \geq 1$ , and denote by $a\in (\pi^i)$ the element such that $s(\pi) = \pi(1+a)$ . Knowing that $s(x)-x \equiv jax \pmod{\pi^{i+j+1}}$ for all $x\in \pi^{j}$ , show that for all $x \in (\pi^j)$ and $i > \frac{e}{p-1}$ the following holds: $$
  s^p(x) -x \equiv pjax \pmod{\pi^{i+j+e+1}}
$$ Does anybody have an idea of how to solve this? The book gives as a hint ""use the binomial formula"".","['number-theory', 'abstract-algebra', 'algebraic-number-theory']"
3550162,"if $a+bi$ is prime, $a- bi$ is also prime (Gauss integers) (irreducible)","if a complex number is prime in Gauss integers, does it follow that its complex conjugate is also prime? I know in general if a “regular” number divides $a+bi$ , it also divided $a-bi$ but can’t show the same for all cause integers. Irreducibility is the same as being prime in the ring. Gauss integers are the form $x+iy$ where $x$ and $y$ are integers.","['complex-analysis', 'gaussian-integers']"
3550188,"Let $A=[0,1]\times[0,1], f:A\mapsto \mathbb{R} $ bounded in A. Then the set $D_{f,A}$ of discontinuities of $f$ in $A$ is closed?","I think that the statement is true, but I don't know how to start yet. Could anyone help me or give me a hint? I will really appreciate that!","['integration', 'real-analysis', 'measurable-sets', 'multivariable-calculus', 'general-topology']"
3550228,Distribution of first exit time of Brownian motion,"Let $B_t$ be standard one dimensional Brownian motion and $\tau = \inf\{s : B_s \notin (a,b) \}$ where $a<0<b$ are real numbers. What is the distribution of $\tau$ ? I know that for hitting times $\tau_a = \inf \{s : B_s =a \}$ the distribution can be calculated with the reflection principle. And clearly $ \tau = \tau_a \wedge \tau_b$ . So how can I continue?","['stochastic-processes', 'brownian-motion', 'stochastic-calculus', 'probability']"
3550234,Formal proof of Occam's razor for nested models,"I consider 2 models $M_0$ and $M_1$ , $M_1$ being more complicated than $M_0$ in the sense that it has more parameters (I usually assume than $M_0$ is nested within $M_1$ ). They are respectively parametrized by $\theta_0$ and $\theta_1$ . I assume that $\theta_0 \subset \theta_1$ (i.e. $M_1$ has the same parameters as $M_0$ plus extra parameters) $p(\theta_0|M_1) = p(\theta_0|M_0)$ (both models have the same priors for the parameters they have in common) I would like to prove the following inequality: $$\forall \theta_0 \\ \langle \log p(\mathcal{D | M_0}) \rangle _{p(\mathcal{D | \theta_0, M_0})} \geq \langle \log  p(\mathcal{D | M_1}) \rangle _{p(\mathcal{D | \theta_0, M_0})}$$ i.e. that on average, if my data $\mathcal{D}$ are generated from $M_0$ parametrized with a given $\theta_0$ , then the Bayes factor is going to favor $M_0$ over $M_1$ . Has it already been done ? Intuitively, it is an application of Occam's razor (a simpler and true model will be favored over a more complicated one), but I lack a formal proof. Precision on the notations : $p(\mathcal{D}|M_0,\theta_0)$ is not the same as $p(\mathcal{D}|M_0)$ , and I thus cannot use the positivity of the Kullback-Leibler divergence. 
In "" $M_0,\theta_0$ "", I specify both the model and its parameters. In "" $M_0$ "", I only specify the model. $p(\mathcal{D}|M_0,\theta_0)$ is the probability that the data $\mathcal{D}$ are generated from model $M_0$ with parameters $\theta_0$ , while $p(\mathcal{D}|M_0)$ is the marginal likelihood over all parameters (the one we use to compute the Bayes factor) : $\int_{\theta} p(\mathcal{D}|M_0,\theta)p(\theta|M_0)$ where $p(\theta|M_0)$ is the prior of parameters under model $M_0$ . The question has previously been asked on Cross-Validated here but without an answer so far.","['bayesian', 'probability-theory']"
3550251,"A quick algebra question derived from a solutions by substitution, differential equation","The question I have starts with the problem $$x\frac{dy}{dx}=y+\sqrt{x^2-y^2},\space x>0$$ After substituting in the values for $y$ and $dy$ and multiplying out $$xu+x^2\frac{du}{dx}=ux+\sqrt{x^2-u^2x^2}$$ Then factoring both the $x$ and $u$ terms $$x(u+x)\frac{du}{dx}=ux+x\sqrt{1-u^2}.$$ so my question is... $$x(u+x)\frac{du}{dx}=x(u+1)\sqrt{1-u^2}$$ Does this still work and if it does have I only  complicated it further.","['substitution', 'ordinary-differential-equations']"
