question_id,title,body,tags
2789580,"Is the squaring function uniformly continuous on $[0, +\infty)$?","Is the function $f: I \to I, ~x \mapsto x^2$ uniformly continuous on $I :=[0, +\infty)$? I know that $f$ is uniformly continuous on every interval of the form $[0, b]$, where $b$ is a positive real number.","['real-analysis', 'calculus', 'continuity', 'uniform-continuity', 'analysis']"
2789586,Prove that $a^3+b^3=10^5$ has no positive integer solution.,"Prove that there do not exist two positive integers, $a$ and $b$, such that $$a^3+b^3=100\,000$$ I tried to use congruence modulo $7$ and some other modulo, but it does not seem to work. If possible, please prove it with modular congruences.","['number-theory', 'modular-arithmetic']"
2789677,Witt's proof of Gelfand-Mazur / Ostrowski's theorem,"Now asked on MathOverflow . Background : It seems that, after his groundbreaking work on quadratic forms and inventing Witt vectors, Ernst Witt developed the hobby of giving extremely short proofs to famous theorems. E.g. his collected works contain a one-page proof of the prime number theorem. What interests me in this question is his six-line proof of the Gelfand-Mazur Theorem (""The only $\Bbb C$ -Banach algebra $K$ which is a skew field is $\Bbb C$ itself"") resp. its historic predecessor and now corollary, Ostrowski's Theorem (""The only complete Archimedean fields are $\Bbb R$ and $\Bbb C$ ""; not to be confused with the more famous Ostrowski's theorem which classifies the valuations on $\Bbb Q$ ). Witt's article is ""Über einen Satz von Ostrowski"", Arch.  Math. 3 (1952), p. 334, reprinted on p. 404 of his Collected Papers. Unfortunately, I do not have access to either source right now. The best I could find is this (p. 245) English translation of its decisive three sentences. I understand the first sentence, which says that w.l.o.g. we can assume $\dim_{\Bbb R}K>2$ and hence $K^\times$ simply connected. I also understand the third sentence which says that there cannot be an isomorphism between the additive group of $K$ and the multiplicative group $K^\times$ (obviously, as we are in characteristic $0$ ; there is a misprint in the translation, since of course it's the element $-1$ which is of order 2 in $K^\times$ , and IIRC that's what Witt writes in the original). But the second sentence The differential equation $x^{-1}dx = y$ then [i.e. assuming $K\setminus \lbrace 0\rbrace$ simply connected] engenders a global isomorphism between the multiplicative group $(x\neq 0$ ) and the additive group $(y)$ . seems to hide some details. I guess the idea is that by simply connectedness, path-integrating $f(x) = x^{-1}$ from the startpoint $1$ to any $x\neq 0$ gives a well defined ""logarithm"" function $F(x)$ which has the property $F(ab) = F(a) + F(b)$ and is bijective. (Which then, as said, I understand gives a contradiction and shows no such $K$ with $\Bbb R$ -dimension $>2$ exists.) Question 1: How to understand the highlighted sentence? In particular, is my interpretation correct and if yes, how exactly to show such an $F$ is a group isomorphism $K^\times \simeq (K,+)$ ? Question 2: Does this prove Gelfand-Mazur, as the source of the above translation seems to imply, or merely Ostrowski's theorem, as Witt's own title claims? If it only proves Ostrowski's theorem, is there a way to upgrade this to a full proof of Gelfand-Mazur? Note 1: As said I cannot check it right now, but I think in the original article Witt actually writes the differential equation $x^{-1}dx = dy$ which makes more sense to me. Note 2: I am aware of the standard calculus proof that $F(x) = \int_1^x \frac{dt}{t}$ satisfies $F(ab) = F(a) +F(b)$ (actually, teaching that in my calculus class last week reminded me of this question), but it seems Witt is assuming a generalisation of this and maybe more differential calculus to a possibly infinite dimensional $\Bbb R$ resp. $\Bbb C$ -vector space, which is a bit outside of my comfort zone.","['real-analysis', 'banach-algebras', 'functional-analysis', 'complex-analysis', 'ordinary-differential-equations']"
2789725,Evaluating $\tan\left(\sum_{r=1}^{\infty} \arctan\left(\frac{4}{4r^2 +3}\right)\right)$ [duplicate],"This question already has answers here : arccot limit: $\sum_{r=1}^{\infty}\cot ^{-1}(r^2+\frac{3}{4})$ (2 answers) Closed 6 years ago . $$\tan\left(\sum_{r=1}^{\infty} \arctan\left(\dfrac{4}{4r^2
 +3}\right)\right)= ? $$ I wrote it in the form: $$\tan\left(\sum_{r=1}^{\infty} \arctan\left(\dfrac{\dfrac43}{\dfrac{4r^2}{3}
 +1}\right)\right)$$
and tried to use: 
$$\arctan x- \arctan y = \arctan\left(\dfrac{x-y}{1+xy}\right)$$ but that trick doesn't help here. How to go about solving this problem then?","['trigonometry', 'sequences-and-series', 'calculus', 'trigonometric-series']"
2789752,Multiple logarithmic integral [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question How would one go to prove that $$\int_{0}^{1} \int_{0}^{1} \int_{0}^{1} \frac{\mathrm{d}(x, y,z)}{ \ln x + \ln y + \ln z} = - \frac{1}{2}$$ I'm not good handling multivariable integrals and nothing pops up in my head. Note: It should be noted that for two variables or one variable the integral diverges.","['multivariable-calculus', 'integration']"
2789759,Can all natural numbers be expressed as $\lceil \frac{3^a}{2^b} \rceil$ or $\lfloor \frac{3^a}{2^b} \rfloor$?,"Can any natural number $n$ be expressed as
$n=\lceil \frac{3^a}{2^b} \rceil$ or $n=\lfloor \frac{3^a}{2^b} \rfloor$ where $ a,b \in \mathbb{N}$ ? I have found no approach to this problem. All suggestions are appeciated. Examples: $0=\lfloor \frac{3^0}{2^1} \rfloor$ $1=\lceil \frac{3^0}{2^1} \rceil$ $2=\lceil \frac{3^1}{2^1} \rceil$ $3=\lceil \frac{3^1}{2^0} \rceil$ $4=\lfloor \frac{3^2}{2^1} \rfloor$ $5=\lceil \frac{3^2}{2^1} \rceil$","['number-theory', 'elementary-number-theory']"
2789775,Finding the minimal polynomial of $2\sqrt[3]{3}+\sqrt[3]{4}$ in the most efficient way .,"How could one find the minimum polynomial of $2\sqrt[3]{3}+\sqrt[3]{4}$, withot using the method where we let $\alpha=2\sqrt[3]{3}+\sqrt[3]{4}$, and keep cubing until we get a polynomial for $\alpha.$ I know that method will work eventually, but the degree of the polynomial is 9 as the degree of the extension is 9 and so it takes far too long. Any help would be greatly appreciated.","['algebra-precalculus', 'polynomials', 'field-theory', 'minimal-polynomials']"
2789794,"A quick way, say in a minute, to deduce whether $1037$ is a prime number","So with $1037 = 17 \cdot 61$, is there a fast method to deduce that it's not a prime number? Say $1037 = 10^3+6^2+1$.  Does $a^3 + b^2 + 1$ factorize in some way? As part of their interviews, a company is asking whether a number is prime. I have never studied number theory, and I am not aware of a strategy for this apart from polynomial factorization. I am guessing that for a number they give you, it would have to not be prime, as the only way to see that a number is a prime by hand is to test all primes below $\sqrt{N}$.","['algebra-precalculus', 'primality-test', 'elementary-number-theory']"
2789800,The asymptotics of the products over primes $\prod\limits_{2<p\le n}\left(1 - \frac1{p-1}\right)$,"Short version If we define 
$$
f(n) = \prod_{2 < p \le n} \left( 1 - \frac{1}{p-1}\right)
$$
where the product is over prime numbers $p$, then is it true that asymptotically
$$
f(n) \sim \frac{c}{\log n}
$$
and if so for what value of $c$? Or if not, can we get an asymptotic formula for $f(n)$? Longer version Define $f(n)$ as above; for example
$$
\begin{align}
f(3) &= \left(1 - \frac{1}{2}\right) &&= \frac{1}{2} \\
f(5) &= \left(1 - \frac{1}{2}\right) \left(1 - \frac{1}{4}\right) &&= \frac{3}{8} \\
f(7) &= \left(1 - \frac{1}{2}\right) \left(1 - \frac{1}{4}\right) \left(1 - \frac{1}{6}\right) &&= \frac{5}{16} \\
f(11) &= \left(1 - \frac{1}{2}\right) \left(1 - \frac{1}{4}\right) \left(1 - \frac{1}{6}\right) \left(1 - \frac{1}{10}\right) &&= \frac{9}{32} \\
\end{align}
$$
and so on. In code (Python): from fractions import Fraction
import math
def isprime(n):
    return n > 1 and all(n % d != 0 for d in range(2, min(n, int(math.sqrt(n))+5)))
n = 2
f = {}
cf = Fraction(1, 1)
while True:
    n += 1
    if not isprime(n): continue
    cf *= (1 - Fraction(1, n - 1))
    f[n] = cf
    print(n, f[n] * math.log(n)) If we let this run for up to $n = 100000$, we see output like: (99881, 0.7410660117923158)
(99901, 0.7410714826009325)
(99907, 0.7410679310376648)
(99923, 0.7410708229998296)
(99929, 0.7410672721476895)
(99961, 0.7410804687613776)
(99971, 0.7410794950190189)
(99989, 0.7410836723109864)
(99991, 0.7410775482554816) so $f(n) \log n$ does seem to approach a value around $0.74$. Note that the third theorem of Mertens says that the similar product
$$
\prod_{p \le n}\left(1 - \frac{1}{p}\right) \sim \frac{e^{-\gamma}}{\log n}
$$
where $\gamma \approx 0.577$ is Euler's constant . This is my reason for trying to see whether
$$
f(n) = \prod_{2 < p \le n} \left( 1 - \frac{1}{p-1}\right) \sim \frac{c}{\log n}
$$
as well, for some other $c$. What I've tried (Obviously not successfully, so it may be best to ignore everything that follows.) Taking logs, we can write 
$$
\log f(n) = \sum_{2 < p \le n} \log\left(1 - \frac{1}{p-1}\right). \tag{1}\label{one}
$$
We can try to relate this to the theorem of Mertens that 
$$
\sum_{p \le x} \log\left(1 - \frac{1}{p}\right) = -\log\log x - \gamma + o(1)
$$
or (peeling off the $p=2$ term)
$$
\sum_{2 < p \le n} \log\left(1 - \frac{1}{p}\right) = -\log\log n - \gamma + \log 2 + o(1) \tag{2}\label{two}
$$
To try to relate $\eqref{one}$ to $\eqref{two}$, we can write $\log\left(1 - \frac{1}{p-1}\right)$ in terms of $\log\left(1 - \frac{1}{p}\right)$: for $p>2$ we have
$$
\begin{align}
-\log\left(1 - \frac{1}{p-1}\right) 
&= \frac{1}{p} + \frac{3}{2p^2} + \frac{7}{3p^3} + \frac{15}{4p^4} + \frac{31}{5p^5} + \frac{63}{6p^6} + \frac{127}{7p^7} + \dots \\
&= -\log\left(1 - \frac1p\right) + \left(\frac{2}{2p^2} + \frac{6}{3p^3} + \frac{14}{4p^4} + \frac{30}{5p^5} + \frac{62}{6p^6} + \cdots \right)
\end{align}
$$
where the second term is $\log\left(\frac{(p - 1)^2}{p(p-2)}\right)$. So, summing the above over $2 < p \le n$,
$$
\begin{align}
-\log f(n)
&= -\sum_{2 < p \le n}\log\left(1 - \frac{1}{p-1}\right) \\
&= -\sum_{2 < p \le n}{\log\left(1 - \frac1p\right)} + \sum_{2 < p \le n}\left(\frac{2}{2p^2} + \frac{6}{3p^3} + \frac{14}{4p^4} + \frac{30}{5p^5} + \frac{62}{6p^6} + \cdots \right) \tag{3}\label{three}\\
&\approx \log\log n + \gamma - \log 2 + \frac{2}{2}\left(P(2)-\frac{1}{2^2}\right) + \frac{6}{3}\left(P(3)-\frac{1}{2^3}\right) + \frac{14}{4}\left(P(4)-\frac{1}{2^4}\right) + \dots
\end{align}
$$
where $P(k) = \sum_{p} \frac{1}{p^k}$ denotes the prime zeta function . On the face of it, this seems like it may give an expression of the form $-\log f(n) = \log\log n + c + o(1)$ for some constant $c$, and therefore $\log f(n) = -c - \log\log n + o(1)$ or 
$$
f(n) \sim \frac{e^{-c}}{\log n}
$$
which is what we wanted. The problem with this is that, in addition to the $\approx$ on the last line of $\eqref{three}$ being sloppy, it appears that in fact the subtracted term $\left(\frac{2}{2\cdot2^2} + \frac{6}{3\cdot2^3} + \frac{14}{4\cdot2^4} + \frac{30}{5\cdot2^5} + \frac{62}{6\cdot2^6} + \cdots \right)$ diverges! So it's not clear whether $\eqref{three}$ is meaningful in any way (and even if it were, whether this is a “proper” way to express the constant $c$). Update: On actually trying the final expression of $\eqref{three}$, it seems to match the numerical data. The following Sage program (using mpmath.primezeta , the equivalent of PrimeZetaP in Mathematica): import mpmath
mpmath.mp.dps = 25 # Set precision to 25 decimal digits
ans = mpmath.euler - mpmath.log(2)
for k in range(2, 100):
    ans += (2**k - 2) * (mpmath.primezeta(k) - 1/2**k) / k
print(ans)
print(mpmath.exp(-ans)) prints (compare the second output with the output from an earlier program above): 0.2993387828283008984224987
0.7413082243919210826540034 This is quite persuasive, so the main thing that's missing is a more rigorous proof of $\eqref{three}$ (I guess we need to say something about the rate of convergence, to justify the “$\approx$”), and (if it exists) a more concise expression for the constant (something that isn't itself an infinite sum). Or of course, a completely different alternative solution.","['number-theory', 'analytic-number-theory', 'zeta-functions', 'asymptotics']"
2789940,$L^{p}_{loc}$ as a normed space,"What norms can we define on $L^p_{\mathrm{loc}}$ ?
or What is the most commonly used norm on $L^p_{\mathrm{loc}}$.
It is tempting to define
 $$\|f\|_{L^p_{\mathrm{loc}}}:=\sup_{K\;\text{is compact}}{\|f\|_{L^{p}(K)}}$$ But this can be infinite for $f\in L^p_{\mathrm{loc}}$.","['functional-analysis', 'real-analysis', 'lebesgue-integral', 'analysis']"
2789943,Multivariable Limits Using Substitution,"Suppose  I want to calculate a multivariable limit using substitution. For example,
$$
\lim _{(x,y)\to (0,0) } \frac{2^{xy}-1}{xy}
$$
or 
$$
\lim _{(x,y)\to (0,0) } \frac{\sin(xy) }{xy}.
$$
Substituting $u=xy$ and then moving to a limit of $u\to 0$ gives a result. As far as I can understand, if the limit of $u\to 0 $ exists, then in particular, the above limits also exist (even though the case of $u\to 0$ can also correspond to e.g. $(x,y)\to(0,2) $). I am not sure if this is legitimate and if I am right. Is it possible that the substitution $u=xy$ and then $u\to 0 $ only corresponds to a specific path? Thanks in advance!","['multivariable-calculus', 'limits']"
2790008,Is there another proof for Euler–Mascheroni Constant?,"Problem Prove that the sequence $$x_n=1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}-\ln n,~~~(n=1,2,\cdots)$$ is convergent. One Proof This proof is based on the following inequality $$\frac{1}{n+1}<\ln \left(1+\frac{1}{n}\right)<\frac{1}{n}$$ where $n=1,2,\cdots$ , which will be used repeatedly. On one hand, we obtain that $$\ln 2-\ln 1<1,~~\ln 3-\ln 2<\frac{1}{2},~~\ln 4-\ln 3<\frac{1}{3},~~\cdots,~~\ln (n+1)-\ln n<\frac{1}{n}.$$ Adding up all of these，we have that $\ln(n+1)<1+\dfrac{1}{2}+\dfrac{1}{3}+\cdots+\dfrac{1}{n}.$ Hence, $$x_{n+1}=1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}+\frac{1}{n+1}-\ln(n+1)>\frac{1}{n+1}>0.$$ This shows that $x_n$ is bounded below. On the other hand, $$x_n-x_{n+1}=-\frac{1}{n+1}+\ln(n+1)-\ln n=\ln \left(1+\frac{1}{n}\right)-\frac{1}{n+1}>0.$$ This shows that $x_n$ is decreasing. Combining the two aspects, according to Monotone Bounded Theorem, we can assert that $\lim\limits_{n \to \infty}x_n$ exists. Let $\gamma$ (so-called Euler–Mascheroni Constant ) denote the limit, i.e. $$\gamma=\lim_{n \to \infty}\left(1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}-\ln n\right),$$ which equals $0.577216 \cdots$ . We may also express that as $$1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}=\gamma+\ln n+\varepsilon_n,$$ where $\varepsilon_n$ represents an infinitesimal related to $n$ under the process $n \to \infty$ .","['euler-mascheroni-constant', 'limits']"
2790010,What does the delta notation in this formula mean?,"The following is a screenshot of the formula booklet I'll be able to use in an exam this week. I'm used to seeing the formulae for numerical differentiation in a different format though and I'm not sure how to interpret the ones in the formula booklet: I'm used to seeing the formulae in the following format: I want to know how the formulae in the book relate to the ones I'm used to using. I need to understand how to use the formula book versions of the formulae as these are the ones I will have access to in the exam. So, what do the $\Delta$, $\delta$ and $\mu$ symbols mean?","['numerical-methods', 'ordinary-differential-equations', 'calculus']"
2790016,A IMO problem about geometry which can probably be solved by simple angle chasing.,"A circle has centre on the side $AB$ of a cyclic quadrilateral $ABCD$ . The other three sides are tangent to the circle. Prove that $AD+BC=AB$. My Attempt: I extended $DA$ and $BC$ to meet at X.Clearly, The circle is the incircle of $\Delta XCD$ and the line $AB$ is antiparallel to base $CD$. Now Cut $AT$ from $ AB$ where $AT=AD$.Enough to show $BT=BC$.I failed to do anything after this.I believe by finding some cyclic quadrilaterals and by angle chasing it can be done. Please help me.","['euclidean-geometry', 'geometry']"
2790027,Is it possible to characterize the family of distributions where $\frac{d}{dy}(E[X\mid X>y])\geq1$?,"I have the following question, any help is greatly appreciated. Thanks! Let $Q(y)=E[X\mid X>y]$ , the truncated expected value of a given distribution. Is it possible to characterize the family of distributions where $\dfrac{dQ}{dy}\geq1$ ? I know that $$\frac{dQ}{dy}=h(y)(Q(y)-y)$$ where $h(y)$ is the hazard rate at $y$ . But I do not know how to proceed from here. Thanks!","['statistics', 'probability', 'probability-distributions']"
2790033,Faster way to calculate the area of this surface,"I have to solve this exercise: Find the area of the portion of the surface $z=xy$ included between the two cylinders $x^2+y^2=1$ and $x^2+y^2=4$ what i did so far: I parameterized the surface using cylindircal polar coordinates
$$\
\Phi(\rho,\theta)=\
\begin{pmatrix}\
   \rho\cos(\theta) \\
   \rho\sin(\theta) \\
   \rho^2\cos(\theta)\sin(\theta)
\end{pmatrix},\
\ \ \rho\in[1,2], \ \ \theta\in[0,2\pi]
$$ then i computed the partial derivates of $\Phi$ $$\Phi_\rho=\
\begin{pmatrix}\
   \cos(\theta) \\
   \sin(\theta) \\
   2\rho\cos(\theta)\sin(\theta)
\end{pmatrix}\
\text{ and }\
\Phi_\theta=\
\begin{pmatrix}\
   -\rho\sin(\theta) \\
   \rho\cos(\theta) \\
   \rho^2(\cos^2(\theta)-\sin^2(\theta))
\end{pmatrix}\
$$ At this point i knew the answer should be
$$\int_0^{2\pi}d\theta\int_1^2|\Phi_\rho\times\Phi_\theta|d\rho$$ the problem is that the expression $|\Phi_\rho\times\Phi_\theta|$ is massive and it would take me forever to compute its integral. Since this question is supposed to be answered within 3 minutes there must be some kind of trick i can use to do it. EDIT: The correct answer is $2\pi(5\sqrt{5}-2\sqrt{2})/3$ but i don't know how to get there","['multivariable-calculus', 'surface-integrals', 'integration']"
2790078,Hartshorne Exercise I.3.5.: $\mathbb{P}^n - H$ (a degree $d$ hyperplane) is affine,"This is Hartshorne Exercise I.3.5.: By abuse of language, we will say that a variety ""is affine"" if it is isomorphic to an affine variety. If $H \subseteq \mathbb{P}^n$ is any hyper surface,
  show that $\mathbb{P}^n - H$ is affine. The hint says we can let $H$ be degree $d$. Then consider the $d$-uple embedding of $\mathbb{P}^n \to \mathbb{P}^N$ and use the fact that $\mathbb{P}^N$ minus a hyperplane is affine. My questions are:
(1) What does it mean to say that a hyperplane have degree $d$? 
(2) What happens to the hyperplane after it is embedded in the larger projective space? From the hint, it seems like it remains a hyperplane? Or at least is embedded in a hyperplane? 
(3) Can you give me some intuition why the $d$-uple embedding works in this case? (I'm having a hard time picturing what is going on) The question here in MSE did not address my particular confusions. Thanks for any help!",['algebraic-geometry']
2790079,"Finding a colouring of an octahedron such that the stabilizer is $S_3$, $V_4$ or $A_4$","I am a bit playing around with the octahedral symmetry, and inspired by another exercise I did on finding configurations of the cube such that the stabilizer is equal to a certain group, I tried doing the same for an octahedron. I considered two ways to 'colour' the octahedron. The first is using colouring each face either black or white (the colours do not have to be used equally often), the second is to draw on each face an arrow pointing towards one of the three adjacent vertices. EDIT 2 : My work on the colouring of the octahedron with stabilizer $S_3$ was incorrect, as pointed out by Clément Guérin. Therefore I deleted this. I also just thought about the following. If we allow all rotations that leave one middle-of-two-opposite-faces-connecting line fixed (i.e. stabilizer is $S_3$), this means that we might colour one pair of opposite faces black, and the rest of the $6$ faces white, to get that $S_3$ is the stabilizer of this colouring. To me, this seems correct, and maybe someone can verify this. If so, we found colourings with stabilizer $S_3$, $V_4$, $A_4$ and $C_4$. Similarly I conjecture that a colouring of an octahedron with all but two faces white, and the two black faces are on the bottom of the octahedron, and not adjacent, would have stabilizer $C_2$. If this is correct, the question is completely answered for the case of a colouring. Perhaps someone also knows how to deal with arrow configurations then, and I will also think about this. EDIT As Steven Stadnicki pointed out a 'checkerboard pattern colouring (i.e. colour one face black and each adjacent face with a the other colour then the neighbours) the stabilizer is $A_4$ indeed! I coloured the printout below. Question: Am I right in my claims? $A_4$ was solved by Steven Stadnicki, $V_4$ and $C_4$ by Clément Guérin, and following the thoughts of Clément Guérin I have a conjecture on $C_2$ and $S_3$. The arrow configurations are still unclear to me. If you find a configuration such that the stabilizer is isomorphic to either $A_4$, $V_4$ or $S_3$ , I would find it most helpful if you draw it explicitly on a printout or an octahedron. I hope I made my question clear, because I am really in doubt about my work and my spatial visualization ability is not that strong.","['abstract-algebra', 'group-theory', 'symmetric-groups', 'geometry']"
2790082,Regular octagon inscribed in a square,"Problem: The corners of a 2 meter square are cut off to form a regular octagon. What is the length of the sides of the resulting octagon? From the picture below, the octagon would form a right isosceles, specifically a right isosceles triangle on the corners. The sides of the octagon were set to "" x "" and the legs of the triangle were set to $\frac{x}{\sqrt{2}}$. Then add the following cuts of a side of the square: $\frac{x}{\sqrt{2}}$ + x + $\frac{x}{\sqrt{2}}$ = 2 m, which results to x = 0.828 m. My inquiry is that, from what I know or learned, a right isosceles triangle has an angle ratio of $45-45-90$ and a side ratio of $1-1-\sqrt{2}$ or in algebra: $x-x-x{\sqrt{2}}$. In the problem he set the hypotenuse as $x$ instead and the legs of the triangle as $\frac{x}{\sqrt{2}}$, which I think is fine. But shouldn't setting the hypotenuse as $x\sqrt{2}$ and the sides as $x$ should equal the first equation? $\frac{x}{\sqrt{2}}$ + x + $\frac{x}{\sqrt{2}}$ = 2 should also equal $x + x\sqrt{2} + x = 2$ where 2 is the length of a side of a square. I don't think multiplying or dividing both sides by $\sqrt{2}$ is the answer as that would not satisfy both equations. This sounds like an easy problem, but it it's confusing me. Sorry.",['geometry']
2790095,Confusion about proof of Unit Balls are not compact in Infinite Dimensional Normed Spaces with Riesz's Lemma,"We can construct a sequence such that $\|x_n-x_m\|\gt 1/2$ via using Riesz's Lemma. It's not Cauchy sequence and thus it's not a convergent sequence. My question : In my notes ""since the sequence is not convergent, it doesn't have a convergent subsequence"" has been written. But when $(-1)^n$ is not convergent, its subsequence is $(-1)^{2n}$ is convergent to $1$. How can we say it doesn't have a convergent subsequence? Where am I wrong, I couldn't realize. Thanks a lot","['functional-analysis', 'normed-spaces', 'cauchy-sequences']"
2790130,Convergence of sequence $a_{n+1} = \int_0^{a_n}[1+\frac{\cos^{2n+1} t}{4}]dt$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How to show that sequence
  $$a_{n+1} = \int_0^{a_n}\left(1+\frac{\cos^{2n+1} t}{4}\right)\,dt$$
  with $a_0 \in (0, 2\pi)$ is convergent?","['sequences-and-series', 'convergence-divergence']"
2790180,Evaluate $\lim\limits_{n\to+\infty}\int_{0}^{1}\ln(1-x^2+2x^{n}+x^{2n}){\rm d}x$.,Problem Evaluate $$\lim_{n\to+\infty}\int_{0}^{1}\ln(1-x^2+2x^{n}+x^{2n}){\rm d}x.$$ I guess it needs to apply Integral Mean Value Theorem or Integral Inequality . But I fail to find the upper-bound function and the lower-bound function. Who can offer a hint?Thanks!,"['definite-integrals', 'limits']"
2790241,Inverse of Hermitian matrix with all negative eigenvalues?,"I am asked to prove that for a Hermitian matrix with all eigenvalues negative, the inverse is given by $$A^{-1} = - \int_0^\infty e^{tA} {\text { d}}t.$$ (I have the corrected the missing minus sign above) I have tried expanding out the integrand in series form, and can show that without taking into account the limits, I have $e^{tA}-I$ as the antiderivative, but I don’t really know how to play around with the limits to get a non-divergent solution. I was thinking of transforming to the diagonal basis, but I can’t seem to move on from there. Is there a trick I’m missing out on? Thanks!","['matrices', 'sequences-and-series', 'linear-algebra']"
2790244,Counting Lattice Paths,"Esther and Daniel are playing a video game called Latticeville. Each level in Latticeville consists of a grid of $m \times n$ rooms, and the two players start in the southwest-most room. From each room in the level, the players are only permitted to move north or east. The level ends when both players reach the room furthest northeast. Esther and Daniel want to maximize the amount of the game that they explore collectively, so they want to ensure that — as much as possible — they never visit the same rooms as each other. But there seem to be many different ways to accomplish this. Given the size of a level in Latticeville, determine how many different subsets of rooms Esther and Daniel can visit such that the number of rooms visited is maximal.
For $m = 3$ and $n = 4$ the output should be $6$. What's the formula for this?  I searched a lot but I could not find a good answer.  Hope to get a good answer here.",['combinatorics']
2790287,Topology of a hypersurface complement,"Is there a relatively explicit way to describe the topology of $\mathbb{CP}^{3}\setminus D$ where $D$ is a smooth, degree 4 hypersurface?","['differential-topology', 'algebraic-geometry']"
2790305,"Show that $\langle v,w\rangle _1=c\langle v,w\rangle _2$ for some scalar $c$.","Let $V$ be a vector space over $F$ and $\langle ,\rangle _1$ and $\langle ,\rangle _2$ be two inner products defined on it. It is given that $\langle v,w\rangle _1=0\iff \langle v ,w\rangle _2=0 \tag{H}.$ Show that $\langle v,w\rangle _1=c\langle  v,w\rangle _2$ for some scalar $c$ . Fix $w\in V$ . Define $f_1:V\to F$ by $f_1(v)=\langle v,w\rangle _1$ . and
Define $f_2:V\to F$ by $f_2(v)=\langle v,w\rangle _2$ . $v\in \ker f_1\iff v\in \ker f_2$ . If $\ker f=V$ then choose $c=1$ and we are done. If $\ker f\neq V$ then $\exists v_0\in V$ such that $f_1(v_0)\neq 0\implies f_2(v_0)\neq 0$ . How to choose $c$ in this case?
Please help me out.","['linear-algebra', 'inner-products']"
2790345,How to find where a Fourier series is discontinuous,"I have the Fourier series $$\sum_{n=1}^{\infty}\frac{\sin nx\sin^2n\alpha}{n}$$ which represents some function $f$ to be found, and I aim to determine the points at which the Fourier series is discontinuous. The answer is that it is some constant for $0<x<2\alpha$ and zero for $2\alpha<x<\pi.$ To do this I used the method of Stokes. I divided the interval $(0,\pi)$ at $n$ points $k_1,k_2,\dots,k_n,$ and if we break up the integrals for $a_n$ (the cosine coefficients) and $b_n$ (the sine coefficients) then we get $$na_n=A_n-b'_n,~nb_n=B_n+a'_n$$ where $a'_n$ and $b'_n$ represent the Fourier coefficients of the derivative, and $A_n,$ $B_n$ given by $$\pi A_n=\sum_{r=1}^{n}\{f(k_r^-)-f(k_r^+)\}\sin nk_r,~\pi B_n=-\sum_{r=1}^{n}\{f(k_r^-)-f(k_r^+)\}\cos nk_r$$ will vanish when $f$ is continuous at all points. I thought that since $f$ has a sine series it should be an odd function of $x$ and therefore its derivative should also be an odd function of $x.$ So that would mean $a'_n=0$ for all $n$ and therefore $nb_n=B_n=\sin^2n\alpha=\tfrac12(1-\cos2n\alpha),$ which seems to suggest that the points of discontinuity are only $k_1=2\alpha.$ Then if I take $$\pi A_n=\{f(2\alpha^-)-f(2\alpha^+)\}\sin2n\alpha$$ then if $0<2\alpha<\pi,$ the sine term cannot vanish, and I have just claimed that $f(2\alpha^-)\neq f(2\alpha^+),$ so this means $A_n\neq0.$ But then that demands $b'_n\neq0,$ and therefore a nonconstant $f.$ On the other hand, I can't see how to show that $b'_n=0$ for this Fourier series. Would someone be able to let me know how to see when a Fourier series is discontinuous when we know only the series, but not the function? I would appreciate either correcting any mistakes I have made (I am not a professional or a maths student and I'm aware this method might be outdated or cumbersome) or showing me a better way to tackle these sorts of problems.","['fourier-series', 'fourier-analysis', 'calculus', 'analysis']"
2790354,Is a sequence of r.v. are independent if and only if their characteristic factors as a product?,"It is obvious that if $\vec{X} = (X_1,X_2\cdots,X_n)^T$ are independent random variables, and their marginal characteristic function and joint characteristic function exists, then they are related by 
$$
Ee^{i\sum_{j=1}^n t_ix_i} = \prod_{j = 1}^n E e^{i t_i x_i},
$$ 
but is the converse true? That is, if there exists such a factorization, then the variables are independent? My professors says so, but I cannot find proof of it, nor in my literature or online. is it true? Is it true for normal r.v.? If it is true, can you provide a reference or proof?","['independence', 'reference-request', 'probability-theory', 'characteristic-functions', 'random-variables']"
2790395,Is the kernel of the adjoint operator equal to the kernel of the operator ($\ker (A)=\ker (A')$)?,"I am in a middle of a proof where I asked myself about the following: Is the kernel of the adjoint operator equal to the kernel of the operator ($\ker (A)=\ker (A')$)? Theorem :Let $X,Y$ be Banach spaces and $A$ an linear bounded operator. The closure of the image is $\overline{Im\: }A=\{y\in Y:f(y)=0,\forall f\in Y'$ such that $A'f=0$}. $(A'f)(x)=f(A(x))$ is the adjoint operator. $Im(A)=\ker(A')^\bot$ So I think that is straightforward the following identity: $\ker (A)=Im(A)^\bot=\ker(A')$ So $\ker (A)=\ker (A')$ Question: Are these moves valid? Is the kernel of the adjoint operator equal to the kernel of the operator ($\ker (A)=\ker (A')$)?","['functional-analysis', 'adjoint-operators']"
2790410,Does dy/dx change depending on the setup of the equation?,So I noticed that when I found $dy/dx$ of $$x\sin(y)=1$$ I got $$dy/dx=-\tan(y)/x$$ where as when I try to find $dy/dx$ of $$\sin(y)=1/x$$ I get $$dy/dx=-\frac1{x^2\cos(y)}$$Shouldn't these two equations yield the same result since they are the same equation but algebraically manipulated before differentiating. When I drew the slope fields of the two graphs using a computer they yielded two different graphs. Why is this the case?,"['derivatives', 'implicit-differentiation']"
2790452,Estimating the parameter lambda in exponential distribution,"I'm reading the following from page 60 of Information theory and Machine Learning. My questions are the following Under the assumption that $\lambda \ll 20$ why is $\bar{x}-1$ a good estimator, could someone add the detail explaining it? What kind of ad hoc binning techniques would work for $\lambda\gg20$ ? I know the author merely introduces his thought process so that the supervisor eventually leads him to a bayesian way of thinking but i'm interested in why his logic for these particular cases works even if the solution is not a unifying one. Thanks!","['statistical-inference', 'information-theory', 'machine-learning', 'statistics', 'bayesian']"
2790548,Can any curve in 3D space be described by an intersection of two surfaces?,"Can any curve in 3D space be described by an intersection of two surfaces? If not, what assumptions I need to let it be true? If this is too general, what if I restrict the scenarios to twice differentiable curves and surfaces? Suppose $\phi_i \in C^2 : \mathbb{R}^3 \rightarrow \mathbb{R}$. The two surfaces are represented by $\phi_1(x,y,z)=0$ and $\phi_2(x,y,z)=0$ respectively. Then the curve is the intersection of them: $L=\{(x,y,z) \;|\; \phi_1(x,y,z)=0, \phi_2(x,y,z)=0\}$.","['curves', 'differential-geometry', 'surfaces', 'geometry']"
2790599,$3$ is a quadratic residue $\bmod p$ iff $ p \equiv \pm 1 \bmod12$,"Could anyone give me any hints as to how to prove this? I've tried using Euler's formula $3^\frac{p-1}{2} \equiv \left(\frac{3}{p}\right)\bmod p$, and quadratic reciprocity but I'm not getting anywhere! I've tried messing around with the Legendre symbol, and I've looked at the proofs which show for what primes $p$, $-1$ and $2$ are quadratic residues, but I'm stuck on this one!","['number-theory', 'quadratic-reciprocity', 'prime-numbers', 'elementary-number-theory']"
2790617,Using taylor series expansion to approximate the derivative of a function,"I know that $f(x+h)=f(x)+hf'(x)+\frac{h^2}{2}f''(x)+\frac{h^3}{3!}f'''(x)$ but I do not know what to do to reach what is shown above, I would appreciate any collaboration.","['derivatives', 'real-analysis', 'calculus', 'numerical-methods', 'approximation']"
2790622,"A geometry problem - easy with trigonometry, harder without it","Consider a $\triangle ABC$, with $\angle A=15^{\circ}, \angle B=55^{\circ}, \angle C=110^{\circ}$. Prove that $c^2=ab+b^2$. This is from my math teacher. I solved it in 10 minutes with trigonomery, not that difficult. My question is: it is possible to prove it without trigonometry? Please help! I am thankful for every solution!",['geometry']
2790657,Solving Recurrence Relation for Series Solution of an ODE,"I am trying to solve the below problem: Assume $y = \sum_{n=0}^{\infty}a_nx^n$ is a solution to $(x-1)y''-(x-3)y'-y=0$. Find $a_n$. I took both derivatives of $y$, plug them into the equation, modify the indices until each series has the same $x^n$, and take terms out of the series such that they have the same index to bring all the terms under the same summation. I arrive at $\sum_{n=0}^{\infty}[(n+1)(n)a_n-(n+1)(n+2)a_{n+2} - na_n+3(n+1)a_{n+1}-a_n]x^n + (-2a_2+3a_1-a_0)=0$ Therefore $$a_2 = \frac{3a_1}{2}-\frac{a_0}{2}$$
and
$$a_{n+2} = \frac{(n+3)a_{n+1}-a_n}{(n+2)}, n = 1,2,3...$$ I also find some terms as
$$a_3 = \frac{4a_2}{3}-a_1 = \left(\frac{4\cdot 3}{3\cdot 2} - 1 \right) a_1-\frac{4}{3\cdot 2}a_0$$
$$a_4 = \left(\frac{5\cdot 4\cdot 3}{4\cdot 3\cdot 2} - \frac{13}{8} \right) a_1-\left(\frac{5\cdot 4}{4\cdot 3\cdot 2} - \frac{1}{8} \right)a_0$$
$$a_5 = \left(\frac{6\cdot 5\cdot 4\cdot 3}{5\cdot 4\cdot 3\cdot 2} - \frac{53}{40} \right) a_1-\left(\frac{6\cdot 5\cdot 4}{5\cdot 4\cdot 3\cdot 2} - \frac{17}{60} \right)a_0$$ I can see a pattern for the first set of coefficients, but not the next. For example the first part for $a_1$ is $a_n = \frac{n+1}{2}$ Any help would be greatly appreciated. Thanks!","['recurrence-relations', 'ordinary-differential-equations', 'sequences-and-series', 'power-series']"
2790669,Which manifold is formed by the set of resolutions of the identity operator into orthogonal projectors?,"A resolution of the identity operator $I$ on $\mathbb{R}^n$ or $\mathbb{C}^n$ is a decomposition
$$I = \sum_{i=1}^n P_i,$$
where the $\{P_i\}$ are a set of orthogonal rank-one projection operators. What is the manifold (or Lie group) structure of the set of all resolutions of the identity, or equivalently sets $P_i$? A naive guess is to express each $P_i$ as an outer product $|\psi_i\rangle \langle \psi_i|$ and identify every resolution of the identity with an orthonormal basis $\{|\psi_i\rangle\}$ - the set of which is diffeomorphic to $\mathrm{U}(n)$ (since you can rotate any orthonormal basis into another one via an appropriate unitary operator). But I don't think is quite right, because you could multiply any basis vector by a phase factor $e^{i \theta}$ (or in the real case, $-1$) without changing the corresponding projector $P_i$, so the orthonormal basis contains redundant information/degrees of freedom. (Permuting basis elements also leaves the decomposition unchanged, but we can ignore this possibility because it can't be done continuously.) Is the answer just $\mathrm{U}(n) / \mathrm{U}(1)^{\times n}$ to remove the $n$ redundant phase factors, or something more complicated? If so, is there a simpler expression for this quotient group?","['hilbert-spaces', 'smooth-manifolds', 'functional-analysis', 'manifolds', 'lie-groups']"
2790680,Linearization of a second order differential equation,"Linearize the equation $$x'' = -\alpha x-\rho x'+c \sin(t)$$ It is very easy when $c=0$ giving you a 
$$ x' = y
$$$$
y' = -\alpha x -\rho y
$$
giving you a very nice phase portrait. However, if $c$ is non-zero, the linearization should be like 
$$ x' = y
$$$$
y' = -\alpha x -\rho y +c\sin(t)
$$
but this gives a very ugly phase portrait (the lines keep intersecting with themselves) Is this still accurate or should I further use a Jacobian to linearize the matrix? (If so, can somebody provide a small hint on how to approach the result, take any initial state for initial condition)",['ordinary-differential-equations']
2790695,De Rham cohomology of punctured manifold,"I'm trying to solve the following problem (Lee's Intro to Smooth Manifolds, 17-6): Let $M$ be a connected smooth manifold of dimension $n \geq 3$. For any $x \in M$ and $0 \leq p \leq n-2$, prove that the map $H^p_{dR}(M) \to H^p_{dR}(M \setminus \{x\})$ induced by inclusion $M\setminus\{x\} \hookrightarrow M$ is an isomorphism. Prove that the same is true for $p = n-1$ if $M$ is compact and orientable. Let $U \approx \mathbb R^n$ be a coordinate chart for $x$, and let $V = M \setminus \{x\}$. Then $M = U \cup V$, and $U \cap V \simeq \mathbb S^{n-1}$, so $H_{dR}^p(U)\oplus H_{dR}^p(V) \cong H_{dR}^p(V)$, and $H_{dR}^p(U \cap V) \cong \mathbb R$ if $p = 0$ or $p=n-1$, and $H_{dR}^p(U \cap V) \cong 0$ otherwise. The Mayer-Vietoris sequence for $M$ is therefore 
$$
\cdots \to H_{dR}^{p-1}(\mathbb S^{n-1}) \to H_{dR}^p(M) \xrightarrow{\ell^*} H_{dR}^p(M \setminus \{x\}) \to H_{dR}^p(\mathbb S^{n-1}) \to \cdots
$$
where $\ell : M\setminus\{x\} \to M$ is inclusion. For $p \neq 0, 1, n-1$, this gives us the exact sequence $0 \to H_{dR}^p(M) \to H_{dR}^p(M \setminus \{x\}) \to 0$, from which it immediately follows that $\ell^*: H_{dR}^p(M) \to H_{dR}^p(M \setminus \{x\})$ is an isomorphism. For $p=0$, because $M$ is connected, so is $M \setminus \{x\},$ and so $H_{dR}^0(M) \cong H_{dR}^0(M \setminus \{x\}) \cong \mathbb R$, with basis the constant function $f \equiv 1$ in both cases, so clearly $\ell^*$ is an isomorphism. For $p=1$ and $p=n-1$, I'm having trouble. The map $H_{dR}^{p-1}(\mathbb S^{n-1}) \to H_{dR}^p(M)$ is induced by the map $\delta : H_{dR}^{p-1}(U \cap V) \to H_{dR}^p(M)$ defined in the following way: for $[\omega] \in H_{dR}^{p-1}(U \cap V)$, there are $\eta \in \Omega^{p-1}(U)$ and $\eta' \in \Omega^{p-1}(V)$ so that $\omega = \eta|_{U \cap V} - \eta'|_{U \cap V}$, so we define $\delta [\omega] = [\sigma]$, where $\sigma = d\eta$ on $U$ and $\sigma = d\eta'$ on $V$. My thought is to prove $\delta = 0$ for $p=1$ and $p=n-1$, but I don't know how. It looks to me as though $\delta$ defined in this way would always be $0$ on cohomology, since $[\sigma|_U] = 0$ and $[\sigma|_V]=0$ in both $H_{dR}^p(U)$ and $H_{dR}^p(V)$ respectively, but I'm sure I'm oversimplifying something. Is there a way to show why $\delta = 0$ for this Mayer-Vietoris sequence? Or is there a better way to approach this? EDIT: See the comments for the solution to the $p=n-1$ case.","['de-rham-cohomology', 'smooth-manifolds', 'differential-forms', 'algebraic-topology', 'differential-geometry']"
2790722,Integrating a real function using complex analysis,"There is an integral given:
$$\int_0^{+\infty} \frac{\sin^2(x)}{x^2}\, \mbox{d}x.$$
Of course the integrand has no antiderivative so it's impossible to calculate the integral above using real-analysis methods. Fortunately we have some methods from complex analysis. There is a tip which says that the integration of the complex function:
$$f(z) = \frac{1 - e^{2iz}}{z^2}$$
can lead us to the proper answer. 
I think it should be integrated over the half of a ring with the center at zero. However I have no idea why there is $1-e^{2iz}$ in the nominator because:$$\sin^2(z) = \frac{-2+e^{2iz}+e^{-iz}}{-4}.$$
After solving this problem should I use the residue theory or just Cauchy's theorem?","['complex-analysis', 'real-analysis', 'integration', 'complex-integration']"
2790731,Every prime divisor ($p \neq 5$) of $n^2+n-1$ is of the form $10k+9$ [duplicate],"This question already has an answer here : Prime divisors of the integer $n^2+n-1$ (using the Legendre symbol) (1 answer) Closed 6 years ago . Now, what I have done so far is the following: Let $p$ be a prime such that $p | n^2+n-1$, then $n^2+n-1 \equiv 0 \pmod p$ This congruence has a solution if and only if $x^2 \equiv \Delta \pmod p$ has a solution, where $\Delta = b^2 - 4ac = 1^2 - 4\cdot1\cdot(-1) = 5$. Since $\Delta = 5$, this has a solution iff $(\frac{5}{p}) = 1$ (the Legendre symbol). And this Legendre symbol is $1$ iff $p \equiv 1, 4 \pmod 5$ Which, in turn, means $p \equiv 1, 4, 6, 9 \pmod {10}$. But $p$ cannot be congruent to $4$ or $6$ modulo $10$, for otherwise it would not be a prime. Therefore, $p \equiv 1, 9 \pmod {10}$. How do I get rid of the $p \equiv 1 \pmod {10}$ solution and prove that it can only be congruent to $9$, i.e. be of the form $10k + 9$, for some k? Is this proof valid for all choices of $p\neq 5$? If so, mayhap my teacher forgot about the $p$ of the form $10k+1$?","['number-theory', 'modular-arithmetic', 'legendre-symbol']"
2790757,Show that the following is asymptotically stable - Liapunov function,"I am trying to figure out how to show that the zero solution to the following is asymptotically stable.
$$x'=xy-x^3$$
$$y'=-y+x^3y$$ I was trying to use a liapunov function: 
$$V(x,y)=\frac{1}{2}[x^2+y^2]$$
Which is always positive. This gives us that 
$$V'(x,y)=xx'+yy'$$
$$=x(xy-x^3)+y(-y+x^3y)$$
$$=x^2y-x^4-y^2+x^3y^2$$ I know that I need this to be strictly negative for some domain surrounding and including the origin. I am having a hard time showing this. I have tried a couple other liapunov functions as well, but none have been successful either. Thanks for any help! I am also open to other methods if there is something easier. When I linearized the system though, it seemed to be inconclusive. I found the linearization to be 
$$
\begin{bmatrix}
    x'\\
    y'\\
\end{bmatrix}=
\begin{bmatrix}
    y && -\frac{x^3}{y}\\
-\frac{y}{x} && x^3 \\
\end{bmatrix}
\begin{bmatrix}
    x\\
    y\\
\end{bmatrix}
$$
So I can't plug in $x=y=0$ to find the eigenvalues. Unless I am not doing that right...","['stability-in-odes', 'ordinary-differential-equations', 'stability-theory']"
2790805,Stumped on basic statistics question.,"The question: Alfonso and Colin each bought one raffle ticket at the state fair. If $50$ tickets were randomly sold, what is the probability that Alfonso got ticket $14$ and Colin got ticket $23$? According to this , the answer should be $ \frac{1}{2450}$ which presumably comes from $\frac{1}{50}\times \frac{1}{49}$. But it seems that the order does not count. I did not assume that Alfonso got ticket $14$ first then Colin got ticket $23$ second. Update: What is wrong with this reasoning.
When I said that I did not assume order, I meant that it's possible Alfonso got ticket $14$ first, then  Colin got ticket $23$, Colin got ticket $23$ first, then Alfonso got ticket $14$. Both of these possibilities are possible before the tickets are given out, so we can make an 'or' statement.
Label the event Alfonso got ticket $14$ by $A_{14} $ and Colin got ticket $23$ by $A_{23}$. Then by the addition rule $ \Pr(\text{ ($A_{14}$ first and $C_{23}$ second)  or  ($C_{23}$ first and $A_{14}$ second}) ) 
\\ = \Pr(A_{14}) \times \Pr(C_{23} \mid A_{14}) + \Pr(C_{23}) \times \Pr(A_{14}\mid C_{23}) = \frac 1 {50} \times \frac 1 {49} \times 2.$ I realize that once the tickets are sold, then only one of $ \{ A_{14}C_{23}~ , ~ C_{23}A_{14} \}$ must occur, but before the tickets are sold both possibilities are plausible. Why would the probability change before and after the tickets are sold.","['combinatorics', 'probability']"
2790808,Center of the Rubik's Cube Group,"I can think of a Rubik's-Cube subgroup with four two elements which commute with all other Rubik's cube elements: Identity Super-flip (flip all the edges around) Super-swap (swap all the edges with their opposite) Super-flip + super-swap Are there any others? EDIT:
As others have pointed out, there are only two. Super-swap is not in the center.","['finite-groups', 'rubiks-cube', 'group-theory']"
2790821,Can *any* real polynomial be factored linearly (plus a constant) over $\mathbb{R}$?,"It seems to be true that every real polynomial $p_n$ of degree $n$ can be factored in the following (not unique) way $$ p_n = \sum_{i=0}^n a_ix^i = s \left\{\prod_{i=1}^n(x-b_i)\right\} +t \tag{$\ast$}$$ with $a_i, s, b_i, t $ all in $\mathbb{R}$. For example: $x-1=(x-1)+0$ $x^2-5x+7=(x-2)(x-3)+1=(x-5)(x-0)+7$ $x^2+1 = (x-0) \cdot (x-0) +1$ I am having a hard time coming up with a rigorous proof. I have tried using the fact that every polynomial $p_n$ can be written as $(x-a)g(x)+b$, where $g$ is a polynomial function and $a$ is an arbitrary real number, but with no success. Another way it could be done is by expanding the right-hand side of $(\ast)$ and showing that the linear system of equations with the coefficients of matching powers of $x$ has always a real solution. But I feel there must be a more simple proof out there, e.g. by induction, if possible without the Fundamental Theorem of Algebra. Would be glad if someone could enlighten me!","['algebra-precalculus', 'polynomials', 'factoring']"
2790831,Indefinite integral of $\sqrt{x^2-x}$,"i was trying to compute the indefinite integral:
$$
\int\sqrt{x^2-x}dx
$$
but i got stuck: after a few (unsuccessful) attempts for some $u$-substitution, i tried integration by parts:
$$
\int\sqrt{x^2-x} \ dx=\int(x)'\sqrt{x^2-x} \ dx= \\ x\sqrt{x^2-x}-\int x(\sqrt{x^2-x})'dx= \\
=x\sqrt{x^2-x}-\frac{1}{2}\int x\frac{2x-1}{\sqrt{x^2-x}}dx= \\
=x\sqrt{x^2-x}-\int \frac{x^2}{\sqrt{x^2-x}}dx+\frac{1}{2}\int \frac{x}{\sqrt{x^2-x}}dx=...
$$
and now what? Can anybody help?","['indefinite-integrals', 'integration']"
2790855,"Computing $\pi_{et}(X,x)^{\operatorname{ab}}$","Let $X$ a smooth projective algebraic curve of genus $g$ over
$k$. ($k$ is an algebraically closed field of characteristic $0$). I want to compute  $\pi_{et}(X,x)^{\operatorname{ab}}$. I'm trying to understand the proof presented here at page 28. http://math.univ-lille1.fr/~borne/Recherche/pisa.pdf Here are the steps of the proof: It is enough to understand $\operatorname{Hom}(\pi_{et}(X,x),A)$ where $A$ is a finite abelian group. $\operatorname{Hom}(\pi_{et}(X,x),A) = H^1(X,A)$ and we can stick to the case $A = \mu_n$. Using Kummer theory  $H^1(X, \mu_n) = (\mathbb{Z}/n)^{2g}$ So, we get $\pi_{et}(X,x)^{\operatorname{ab}}= (\hat{\mathbb{Z}})^{2g}$ I understand all the steps except the first and last step. Can you someone why it is enough to understand $\operatorname{Hom}(\pi_{et},\mu_n)$? And we exactly in last step we get $\pi_{et}(X,x)^{\operatorname{ab}}= (\hat{\mathbb{Z}})^{2g}$? It seems they are claiming $$\pi_{et}(X,x)^{\operatorname{ab}} = \underset{n}{\varprojlim} \operatorname{Hom}(\pi_{et}(X,x),\mu_n) $$? Why is the last statement true? Does it hold for any profinite group?","['number-theory', 'etale-cohomology', 'algebraic-geometry', 'commutative-algebra']"
2790866,Value of Solving Unsolved / Edge-case Mathematical Problems,"I just came across Unsolved Problems in Group Theory , of which there are 100's of very specific, detailed problems, such as these: ... 15.68. Does there exist an infinite finitely generated 2-group (of finite exponent) all of whose proper subgroups are locally finite? 16.78. Do there exist linear non-abelian simple groups without involutions? 17.9. Is there a group containing a left Engel element whose inverse is not a left Engel element? ... In learning about the basics of group theory, it is an interesting subject. It has applications in many fields. But the applications as far as I can tell rely on the common body of knowledge in group theory (or in a mathematical field). Basically stuff you can find in textbooks or Wikipedia. So I was wondering if one could explain the value in answering these 100's of questions. I can see answering some questions like a very relevant theorem perhaps, but the detail of these questions is very deep and there are so many. It seems like many more questions could be proposed as well, lots of edge-cases etc.. I know I am missing a lot of context so I hope this comes across okay. I am hoping to find it interesting, right now it feels overwhelming :)",['group-theory']
2790867,Probability of drawing the Jack of Hearts? [duplicate],"This question already has answers here : Probability of second card being an ace (4 answers) Closed 4 years ago . You have a standard deck of cards and randomly take one card away without looking at it and set it aside. What is the probability that you draw the Jack of Hearts from the pile now containing 51 cards? I'm confused by this question because if the card you removed from the pile was the Jack of Hearts then the probability would be zero so I'm not sure how to calculate it. Edit: I asked this question about a year ago because I was struggling to get an intuitive understanding of an important concept in probability, and the comments and answers were really helpful for me (especially the one about ""no new information being added so the probability doesn't change"").","['probability', 'card-games', 'discrete-mathematics']"
2790868,discriminant of $x^p-1$,"I am attempting to solve Artin 16.10.9, part (b). I have already solved (a). Let $f(x)=(x-α_1) \cdots (x-α_n)$ . (a) Prove that the discriminant of $f$ is $\pm f'(α_1) \cdots f'(α_n)$ , where $f'$ is the derivative of $f$ , and determine the sign. (b) Use the formula to compute the discriminant of the polynomial $x^p-1$ , and use it to give another proof of Theorem 16.10.12. Here is Theorem 16.10.2, which we are asked to prove. Theorem: Let $p$ be a prime different from $2$ , and let $L$ be the unique quadratic extension of $\mathbb{Q}$ contained in the cyclotomic field $\mathbb{Q}(ζ_p)$ . If $p \equiv 1$ (mod 4), then $L=\mathbb{Q}(\sqrt p)$ , and if $p \equiv 3$ (mod 4), then $L=\mathbb{Q}(\sqrt{-p})$ . My progress so far I have shown, for part (a), that the discriminant of $f$ is $(-1)^{n \choose 2}f'(α_1) \cdots f'(α_n)$ . Then, using this result, I have shown that the discriminant of $x^p-1$ is $(-1)^{p \choose 2}p^p$ . If I have made a mistake, please correct me. Now, I want to use this formula to prove Theorem 16.10.2. So let $p\neq2$ and let $L$ be the unique quadratic extension contained in $\mathbb{Q}(ζ_p)$ . Write $L=\mathbb{Q}(\sqrt k)$ . For now, assume $p \equiv 1$ (mod 4). I see that $\mathbb{Q}(ζ_p)/ \mathbb{Q}$ is a Galois extension, with its Galois group isomorphic to $C_{p-1}$ . Additionally, I see that $\mathbb{Q}(ζ_p)/\mathbb{Q}(\sqrt k)$ is a Galois extension as well. I'm not sure how to show that $L=\mathbb{Q}(\sqrt p)$ though. How do it do it? Please help!","['galois-theory', 'polynomials', 'discriminant', 'abstract-algebra', 'roots-of-unity']"
2790871,Elliptic Bootstrapping for Gauge Transformations,"I'm reading John Morgan's book ""Seiberg-Witten equations and applications to the topology of smooth manifolds"". I'm stuck in the proof of Lemma 4.5.3, which says the following. Suppose $(a_n,\psi_n)$ and $(b_n,\mu_n)$ are sequences of $W^{2,2}$ (connection,spinor) on a closed $4$-manifold which converge in $W^{2,2}$ to $(a,\psi)$ and $(b,\mu)$ respectively. If $\sigma_n$ is a sequence of $W^{3,2}$ gauge transformations such that $(a_n,\psi_n)\cdot \sigma_n = (b_n,\mu_n)$, then there exists a subsequence of the $\sigma_n$ converging in $W^{3,2}$ to an element $\sigma$ of the gauge group. The proof starts as follows. Define $\tau_n = \det(\sigma_n)$, and note that we have $d\tau_n = \tau_n(b_n-a_n)$. We have (obviously) a uniform bound on $\|\tau_n\|_{L^6}$, which using the multiplication $L^6\otimes W^{2,2}\to L^5$ gives a uniform bound on $\|\tau_n\|_{W^{1,5}}$. Following this strategy once again, we can show (using Sobolev embeddings) that there is a uniform bound on $\|\tau_n\|_{W^{2,4}}$. After this, it is claimed we can iterate this argument once again to get a uniform bound on $\|\tau_n\|_{W^{3,3}}$. It is at this step that I'm having trouble. My understanding is that, we need to use a bounded multiplication $W^{2,4}\otimes W^{2,2}\to W^{2,3}$ to execute this step. But I suspect this is not true since $W^{2,2}$ does not embed in $W^{2,3}$ (since the latter embeds in $L^\infty$). Am I missing something? Can someone say where my mistake lies, or how to get the $W^{3,3}$ bound on $\tau_n$? Once this step is done, the rest of the proof looks okay to me.","['gauge-theory', 'differential-geometry', 'partial-differential-equations']"
2790878,Entire function having the property [duplicate],"This question already has answers here : Entire function with vanishing derivatives? (3 answers) Closed 6 years ago . Let $f$ be an entire function. Consider $A=\{z \in \Bbb{C} : f^{(n)}(z)=0\; \text{for some}\; n \in \Bbb{N}\}$. Then how to prove if $A=\Bbb{C}$, then $f$ is a polynomial ? This is same as proving if $f$ is not a polynomial then $A$ is not all of $\Bbb{C}$. I show the above statement with a particular example, like $f(z)=\sin z$ How to prove generally ?   Any ideas ?","['complex-analysis', 'entire-functions']"
2790897,Limit $\lim_{x \to \infty}\left (1- \frac1x\right)^x = ?$,"$$\lim_{x \to \infty} \left(1+ \frac1x\right)^x = e$$
, then$$\lim_{x \to \infty} \left(1- \frac1x\right)^x =\; ?$$ I tried $\lim_{x \to \infty} \left(1- \frac1x\right)^x = \lim_{x \to \infty}\left(\frac{x-1}{x}\right)^x$, but this is not helpful.","['exponential-function', 'limits']"
2790910,"If $X$ and $Y$ are independent random variables, with $Z = \min(X,Y),$ prove that $Z^2\sim\chi^2(1),$","Let $X \sim N (0, 1)$ and $Y ∼ N (0, 1)$ be two independent random variables, and define $Z = \min(X, Y )$ . Prove that $Z^2\sim\chi^2(1),$ i.e. Chi-Squared with degree of freedom $1.$ I found the density functions of $X$ and $Y,$ as they are normally distributed. How would one use the fact that $Z = \min(X,Y)$ to answer the question? Thanks!","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
2790946,Is Hilbert's space-filling curve measure preserving?,"Say $f_n:[0,1]\to [0,1]^d$ is the $n$-th iteration of a $d$-dimensional Hilbert curve touring its range. Is it true that for any open $S\subset [0,1]^d$, then amount of time $f_n$ spends in $S$ is approximately  $\mathrm{vol}(S)$? That is, for $S\subset [0,1]^d$ open, taking $f^{-1}_n(S)=\{t:f_n(t)\in S\}\subset [0,1],$ is it true that: \begin{equation}
    \mu(f^{-1}_n(S))\to_n \mu(S)?
\end{equation} I think so. Each $f_n$ maps to the boundary of some lattice of cuboids, $(c^{(n)}_\lambda)_{\lambda \in \Lambda^{(n)}}$, where each $c^{(n)}_\lambda$ corresponds to a single cuboidal cell in $[0,1]^d$ with side length $\ell^{(n)}$.
  Take $\mathcal{S}^{(n)}$ to be the collection of cuboids $c^{(n)}_\lambda$ which come within $\ell^{(n)}$ of $S$ and compute:
  \begin{align} \mu(S) &\leq \mu(\cup_{\mathcal{S}^{(n)}})\\
&=\left|\mathcal{S}^{(n)}\right|\cdot(\ell^{(n)})^d \\
&\leq \mu(f_n^{-1}(\cup_{\mathcal{S}^{(n)}}))/(\ell^{(n)})^d\cdot (\ell^{(n)})^d \\
&\leq \mu(f^{-1}_n(\cup_{\mathcal{S}^{(n)}}\backslash S))+\mu(f^{-1}_n(S)) \\ 
&\leq O(1/n)+\mu(f_n^{-1}(S)).
\end{align} 
  Get a similar upper bound on $
\mu(f_n^{-1}(S))$ by identically inspecting the collection of cuboids contained in $S$ and at least $\ell^{(n)}$ away from the boundary of $S$. Is this correct? Is there a better way?","['real-analysis', 'limits', 'proof-verification', 'measure-theory', 'general-topology']"
2790978,$f''(e^{x})$ and it's definition,"I'm working through ""The Calculus Tutoring Book"" by Carol and Robert Ash (0-7803-1044-6).  In chapter 3.3, when discussing derivatives of basic functions, they show and define the $D_{x}e^{x}$ and subsequently define $e$.  Page 67 for those that have the book. In any event, they define a ""base"", eventually, they land at $(1)$: $$D_{x}b^x = \lim_{\Delta x\to 0} b^x\lbrack \frac{b^{\Delta x}-1}{\Delta x} \rbrack$$  I have no problem here.  And I understand why they effectively ignore the constant $b^x$ when you factor it out $(2)$:
$$\frac{b^{\Delta x}-1}{\Delta x}$$ to $(3)$
$$D_{x}b^x=mb^x$$ And go on to state that the latter must be the slope of a line centered at $(0, 1)$ Then from the former, they land on the fact the $(4)$ $$D_{x}e^x = e^x$$ I don't see the path from $(2)$ to $(3)$ and subsequently $(4)$.","['derivatives', 'exponential-function', 'definition']"
2791002,"Intuitively, why are the curves of exponential, log, and parabolic functions all smooth, even though the gradient is being changed at every point?","Why are the curves of exponential, log, and parabolic functions all smooth, even though the gradient is being changed at every point? Shouldn't it be much more choppy? By the way, if possible, can this be explained intuitively (not too rigorously), and without Calculus? Because I want to understand this, but I haven't learnt Calculus yet.","['algebra-precalculus', 'functions']"
2791005,Finding a recurrence for $t_n$ that holds true for a set of integers,"I know the answer but I have no idea how to explain it Question A
$t_3 =$ ['aaa', 'abb', 'acc', 'bba', 'cca']               ($5$ elements) $t_4 =$ ['aaaa', 'aabb', 'aacc', 'abba', 'acca', 'bbaa', 'bbbb', 'bbcc', 'ccaa', 'ccbb', 'cccc'] ($11$ elements) $t_5 =$ ['aaaaa', 'aaabb', 'aaacc', 'aabba', 'aacca', 'abbaa', 'abbbb', 'abbcc', 'accaa', 'accbb', 'acccc', 'bbaaa', 'bbabb', 'bbacc', 'bbbba', 'bbcca', 'ccaaa', 'ccabb', 'ccacc', 'ccbba', 'cccca']    ($21$ elements) $t_6 = 43$ elements From handwriting a tonne of permutations, I know that the recurrence is:
$t_n = t_{n-1} + 2t_{n-2}$ What is the correct way to explain why my recurrence gives $t_n$?","['recursive-algorithms', 'recursion', 'discrete-mathematics']"
2791027,Evaluate $\int_{0}^{\infty} \frac{x \exp\left\{-\beta^2 x^2\right\}}{\sinh \left(\frac{\pi x}{2}\right)} \mathrm{d} x$,"I am trying to evaluate the integral
$$
\int_{0}^{\infty} \frac{x \exp\left\{-\beta^2 x^2\right\}}{\sinh \left(\frac{\pi x}{2}\right)} \mathrm{d} x,
$$
where $\beta \in \mathbb{R}$ is some constant. After many unfruitful attempts and checking up several integral handbooks, I am still not sure how to handle it. Does there exist an analytic solution? Thanks in advance! Edit: Inspired by the discussions in this question , I tried to make the following manipulation (assume we can interchange the order of the infinite sum and the definite integral):
$$
\begin{aligned}
\int_{0}^{\infty} \frac{x \exp(-\beta^2 x^2)}{\sinh(\pi x/2)}\mathrm{d}x =& \frac{16}{\pi^3} \int_{0}^{\infty}\sum_{n=0}^{\infty} x \exp(-\beta^2x^2) \exp(-(2n+1)x) \mathrm{d} x \\
=&\frac{16}{\pi^3} \sum_{n=0}^{\infty} \exp\left(\frac{(2n+1)^2}{4\beta^2} \right) \int_{0}^{\infty} x \exp\left\{ -\frac{1}{2\frac{1}{2\beta^2}} \left(x + \frac{2n+1}{2\beta^2} \right)^2 \right\} \mathrm{d}x\\
=& \frac{16}{\pi^3}\sum_{n=0}^{\infty} \exp\left(\frac{(2n+1)^2}{4\beta^2}\right) \left\{ \frac{\sqrt{2\pi}}{2\beta^2}\exp\left(-(2n+1)^2\beta^2\right) \right. \\
&\left.- \frac{\sqrt{\pi}(2n+1)}{2\beta^3} \left(1-\Phi\left(\frac{\sqrt{2}}{2}(2n+1)\beta\right)\right) \right\}
\end{aligned},
$$
where $\Phi(\cdot)$ is the standard normal cdf.
This still seems not very promising: I have little idea how to deal with this infinite series.","['hyperbolic-functions', 'calculus', 'improper-integrals', 'integration', 'definite-integrals']"
2791041,"Is $h^{+}(x) = \max\{h(x), 0\}$, where $h: \mathbb{R}^n \to \mathbb{R}$ and $h \in C^1$ continuously differentiable?","In this article (DOI: 10.2307/2319406 ), the author define a function as $$h^{+}(x) = \max\{h(x), 0\},$$
where $h: \mathbb{R}^n \to \mathbb{R}$ and $h \in C^1 (G), G\subseteq \mathbb{R}^n$. Is it the case that $h^{+}$ is always continuously differentiable ? My gut says that it should not necessarily be because at the points where $h(x) = 0$, $h^+$ might be not continuously differentiable because of that steep change fro the constant value $0$ to $h(x) > 0$. Edit: In case you cannot access to the article: This is the section that the claim is made.","['derivatives', 'continuity', 'calculus']"
2791087,"calculate $\operatorname{cov}(X,Y)$ from $f_{x,y}(x,y)$","I have the following density function:
$$f_{x, y}(x, y) = \begin{cases}2 & 0\leq x\leq y \leq 1\\ 0 & \text{otherwise}\end{cases}$$ We know that $\operatorname{cov}(X,Y) = E[(Y - EY)(X - EX)]$, therefore we need to calculate E[X] and E[Y]. $$f_x(x)=\int_x^1 2\,\mathrm dy = \big[2y\big]_x^1 = 2-x, \forall x\in[0, 1]$$ $$E[X] =  \int_0^1 x (2-x)\,\mathrm dx = \int_0^1 2x - x^2\,\mathrm dx= \left[\frac{2x^2}{2}-\frac{x^3}{3}\right]_0^1  = 1 - \frac{1}{3} = \frac23 $$ $$f_y(y) = \int_0^y\,\mathrm dx = \big[2x\big]_0^y = 2y, \forall y\in [0, 1]$$ $$E[Y] =  \int_0^1 y\cdot2y\,\mathrm dy= \int_0^1 2y^2\,\mathrm dy= \left[\frac{2y^3}{3}\right]_0^1 = \frac23$$ However, the provided solution states that $E[X]=\dfrac13$. Have I done a mistake or is the solution wrong? The continuation of the solution is: $$\mathrm{cov}(X,Y) = \int_0^1\int_x^1(x-\frac 13)(y- \frac 23) \times 2\,\mathrm dy\,\mathrm dx$$ Where does the $\underline{2\,\mathrm dy\,\mathrm dx}$ come from?","['statistics', 'probability', 'bivariate-distributions', 'covariance']"
2791113,Why does the smallest ring have two elements at least?,"I found it written in my lecturer's notes that the smallest ring will have $2$ elements, while the smallest group will have $1$ element. I'm not completely sure why this is true. My understanding of a ring $R$ is that it is an algebraic structure (which ensures closure) has two binary operations $+$ and $*$. $(R,+)$ forms an Abelian group. $(R,*)$ forms a semigroup (ensures associativity). From the definition alone, I'm not able to see why a ring should at the minimum have two elements. Can't it just have the identity element $e$ and nothing else? Edit: According to the comments, this seems to be just a matter of convention as usually the identity elements for $(R,+)$ and $(R,*)$ are considered to be different. In that case, could someone explain in which cases such a convention is useful?","['abstract-algebra', 'ring-theory']"
2791148,Determine whether or not $card(A^B)>card(C^D)$?,"Let's say I have $4$ sets: $A,B,C,D$, is there a way to determine whether or not $\left|A^B\right|>\left|C^D\right|$? I thought about this question because it is easy to show that $\left|n^\Bbb N\right|=\left|m^\Bbb N\right|$ forall $n,m\in\Bbb N$, but also $\left|\Bbb N^\Bbb N\right|$ is equal to the above. I was also told that  $\left|\Bbb R^\Bbb N\right|$ is equal to them(although I didn't prove that one), so $\left|n^\Bbb N\right|=\left|\Bbb N^\Bbb N\right|=\left|\Bbb R^1\right|=\left|\Bbb R^\Bbb N\right|$, it means that simply compare $|B|$ with $|D|$ and $|A|$ with $|C|$ won't be enough. Also, what about the other direction? If $\left|A^B\right|>\left|C^D\right|$ what can we say about the relation of the cardinality of $A,B,C,D$?","['cardinals', 'elementary-set-theory']"
2791165,How can a ratio containing only real numbers have a complex value? [duplicate],"This question already has answers here : Why is $1 - \frac{1}{1 - \frac{1}{1 - \ldots}}$ not real? (8 answers) Closed 6 years ago . Solving this equation $$x = 1-\cfrac{2}{1-\cfrac{2}{1-\cfrac{2}{\ddots}}}$$ Sub in $x$ $$x=1-\frac{2}{x}\implies x^2=x-2 \implies x^2-x=-2$$ Solve through completing the square
\begin{align}
x^2-x+\frac{1}{4}&=-2+\frac{1}{4}\\
\left(x-\frac{1}{2}\right)^2&=-\frac74\\
x-\frac{1}{2}&=\pm\sqrt{\frac{7}{4}}i\\
x&=\frac{1}{2}\pm\sqrt{\frac{7}{4}}i\\
\end{align}
When you substitute this value back in for $x$ it works. But i don't understand why a equation like this can equal a complex value Maybe I am missing something important here? EDIT: So this equation diverges right. Does that make my working invalid, or just explain the non-real part. Can anything useful be done by defining this recursively $$f(x)=1-\frac{2}{f(x)}$$ and then using a seed value I also wonder whether we would end up dividing by zero at some point. Can you prove we do or don't?","['algebra-precalculus', 'complex-numbers']"
2791186,How many spheres are needed to shield a point source of light?,"How many spheres are needed to shield a point source of light? I read this from a mathematical puzzle book. And book says the answer is six without explanation. From the geometric point of view, I'm thinking of a tetrahedron where the point source is located at the center. Then we can decompose 4 sectors, thus it seems to me 4 spheres is enough to shield the light. So I'm confused with the answer given in the book. If someone understands this problem, can you explain it to me?","['solid-geometry', 'recreational-mathematics', 'geometry']"
2791208,Multi-Gaussian Integrals with Heaviside for cosmic connectivity,"Context I would like to 
predict the connectivity of the so-called cosmic web in arbitrary dimensions. This is the cosmic web (in a hydrodynamical simulation) The little wiggly things are galaxies (as traced by the gas density) while the inset shows the corresponding light produced by the stars which were born from that gas. The connectivity $\kappa$ is defined as the number of ridges connecting a given maxima  to its surrounding saddles, which in turn therefore corresponds to $2 n_{\rm max}/ n_{\rm saddle}$ where $n_{\rm max}$ and $n_{\rm saddle}$ are 
the total number of maxima and saddles in the field. This is how the cosmic web looks like in 3D on larger scales (using a filament tracer algorithm): so the motivation is to predict how many filaments are connected to a given node from first principes. Definitions As a starting point I am restricting myself to a Gaussian random field.
For such fields  the connectivity $k^d$ is then simply \begin{equation}
\kappa^{d}  =\frac{2n_{\rm saddle}}{n_{\rm max}}= \frac{2 \left\langle   \Theta_{\rm H}(-\{\lambda_{i}\}_{i<d})  \Theta_{\rm H}(\lambda_{d})   \left| \prod  \lambda_i \right| \right\rangle}
{\left\langle   \Theta_{\rm H}(-\{\lambda_{i}]\}_{i\leq d})   \left| \prod  \lambda_i \right| \right\rangle}\,,
\label{eq:defkapND}
\end{equation} where the expectation is to be carried over Gaussian PDFs.
Technically 
I therefore need to evaluate in arbitrary dimensions integrals such as \begin{equation} \int \cdots \int
\prod_{i\le { d}}  d \lambda_i \,
G(\{\lambda_i\}) \prod_{i<j} (\lambda_j-\lambda_i)  \, \prod_{i\le d}\Theta_{\rm H}(-\lambda_i)
\,,  \label{eq:defQprob}
\end{equation} where $\Theta_{\rm H}$ is a Heaviside function and $G(\lambda_i)$ is a multi-Gaussian PDF with variance covariance given by \begin{equation}
M_{i,j}= \frac{1}{d (d+2)} \quad {\rm for}\quad i\neq j\\
M_{i,i}= \frac{3}{d (d+2)}
\end{equation} For instance for $d=7$ this matrix reads \begin{equation}
\left(
\begin{array}{cccccc}
 \frac{1}{16} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{48} \\
 \frac{1}{48} & \frac{1}{16} &
   \frac{1}{48} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{48} \\
 \frac{1}{48} & \frac{1}{48} &
   \frac{1}{16} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{48} \\
 \frac{1}{48} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{16} &
   \frac{1}{48} & \frac{1}{48} \\
 \frac{1}{48} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{48} &
   \frac{1}{16} & \frac{1}{48} \\
 \frac{1}{48} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{16} \\
\end{array}
\right)
\end{equation} Questions Is is possible to compute the ratio analytically for $d>3$ ? For instance \begin{equation}\kappa^2=4
\end{equation} for $d=2$ and \begin{equation}
\kappa^3=2 \frac{18 \sqrt{2} + 29 \sqrt{3}}{
    {-18 \sqrt{2} + 29 \sqrt{3}}} \approx 6.11 
\end{equation} for $d=3$ . 
It is strikingly close to a cubic face centred lattice, but with some level of impurity to the crystal. Can this ratio be computed numerically for $d>11$ ? So far I have $\kappa^d$ = $4$ , $6.11$ , $8.35$ , $10.73$ , $13.23$ , $15.85$ , $18.7$ , $21.4$ , $24.4$ , $27.4$ for $d=$ $2$ , $3$ , $4$ , $5$ , $6$ , $7$ , $8$ , $9$ , $10$ and $11$ resp. From inspection of $d\le 11$ we conjecture that it is closely approximated 
by \begin{equation}
 \kappa^d= 2d+\left(\frac{2d-4}{7}\right)^{7/4}.
 \end{equation} which suggests that the $d$ cosmic web behaves like a crystal with growing impurity. can the large d asymptote be computed? FYI, this question is linked to that mathematica question and this paper .
FYI2: this paper may be relevant to the asymptote ?","['asymptotics', 'numerical-methods', 'integration', 'probability', 'conditional-expectation']"
2791246,complex polynomial has zeroes only in the upper half plane,"Let $f(z)=z^{n}+a_{1}z^{n-1}+...+a_{n}$ be a polynomial with complex coefficients and suppose it has $n$ zeros in the upper half plane, that is $\operatorname{Im} z>0$, and let $\alpha_ {k}$ be the real part of $a_{k}$. Show that $\alpha(x)=x^{n}+\alpha_{1}x^{n-1}+...+\alpha_{n}$ has $n$ real distinct roots.","['complex-analysis', 'polynomials']"
2791255,For which $a$ is $y^2= x^3 + a$ a submanifold?,"I am having a hard time solving the equations to find the $a \in \Bbb R$ for which $$M_a = \left \lbrace {(x,y)\in \mathbb {R}^2} \mid {y^2= x^3 + a}\right \rbrace$$ is a submanifold of $\Bbb R^2$. I defined $F: \Bbb R^2 \to \Bbb R$ with $F(x,y)=y^2-x^3-a$ such that $M_a = F^{-1}(0)$ and $F$ is smooth. By the preimage theorem $M_a$ is a $1$ dimensional submanifold if $M_a$ doesn't contain any critical values of $F$. To compute the critical values of $F$, set $$D_{(x,y)}F = \begin{bmatrix} -3x^2 & 2y \end{bmatrix} = 0$$ and for $(x,y)$ to be a critical point of $F$ it must lie on the parabola $y=-\frac{3}{2} x^2$. So we search for the intersection points of $M_a$ and the parabola, which are all the critical points of $F$ contained in $M_a$, since we want to find $a$ such that there are no intersection points. Substituting the parabola eq. in the defining eq. of $M_a$ we get $$a = \frac{9}{4} x^4-x^3 = x^3(\frac{9}{4}x-1)$$ How do I proceed from here? A simple $a \lt 0$, $a \gt 0$, $a=0$ case analysis doesn't lead to anything, since for $a \lt 0$, there are $x$, namely $0 \lt x \lt \frac{4}{9}$, such that this is true and we can also find $y$ for those $x$. By playing with the plot in Mathematica I found that $a \approx -0.01$ is the turning point. For all $a$ greater than that there are two intersection points and for all $a$ smaller than that there are none. Can somebody show me how this could be extracted from the calculations above? Here is a plot for $a=0.2$ And a plot for $a=-0.005$",['differential-geometry']
2791314,Norms are equivalent if one hand side of inequality holds,"Let $(X,\|.\|_1)$ and $(X,\|.\|_2)$ are Banach spaces and $\forall x \in X$. Show that if  $\|.\|_1 \le k \|.\|_2 $ for $\exists k \gt 0$ then $\|.\|_1$ and $ \|.\|_2 $ are equivalent. I could think only belows $(x_n)$ is an arbitrary Cauchy Sequence in $X$ and since it is Banach wrt $ \|.\|_2 $ thus $\exists x \in X$ such that $\|x_n-x\|_2 \lt \varepsilon /k$ From inequeality we have $\|x_n-x\|_1 \le k\|x_n-x\|_2 \lt \varepsilon$  hence $x_n \to x$ wrt $\|.\|_1$ norm. I cannot continue and I think there are some mistakes and deficiencies my writtens above. I will be apreciated for any help I have used a version of Banach Isomorphism Theorem thanks to your comments : Let $I:(X,\|.\|_2) \to (X,\|.\|_1)$ identity map. It is (1-1) and onto. $\|I(x)\|_1 = \|x\|_1 \le k\|x\|_1 $ thus $I$ is bounded and equivalently continuous. By Banach Isomorphism Theorem it is a homeomorphism hence $I^{-1}$ is continuous and equivalently bounded. We can find $\exists c \gt 0$ such that $\|I^{-1}(x)\|_2 = \|x\|_2 \le c\|x\|_1 $ Finally we get the norms are equivalent Could you please check it?","['functional-analysis', 'normed-spaces', 'banach-spaces']"
2791355,How can I get the gradient of the normal equation for weighted linear regression?,"The normal equation for weighted linear regression looks like this: $$J(\theta) = (X\theta - y)^TW(X\theta - y),$$ where $X\in\Re^{m\times n}$, $\theta\in\Re^{n\times n}$, $y\in\Re^{m\times 1}$, $W\in\Re^{m\times m}$, and $W$ is a diagonal matrix, with the diagonals being the $m$ different weights. As a point of reference, this can also be written as $$J(\theta) = \frac{1}{2}\sum_{i=1}^mw^{(i)}(\theta^Tx^{(i)} - y^{(i)}),$$ where the superscripts indicate the $i$-th element of that vector or diagonal. I am trying to use the normal equation to show solve for $\theta$, specifically by taking the gradient of the normal equation and setting it equal to zero. My attempt I begin by expanding the equation: \begin{equation}
\begin{split}
J(\theta) & = (\theta^TX^T - y^T)(WX\theta - Wy) \\
& = \theta^TX^TWX\theta - \theta^TX^TWy - y^TWX\theta + y^TWy
\end{split}
\end{equation} Now I know that the answer to my problem is $$\nabla_{\theta}J(\theta) = 2(X^TWX\theta - X^TWy),$$ and the only way I can see to achieve this from what I have is if $$J(\theta) = \theta^TX^TWX\theta -2y^TWX\theta + y^TWy.$$ From my initial expansion of $J(\theta)$, this would imply that $$\theta^TX^TWy = y^TWX\theta.$$ I can't see how this last equality could hold. I'm quite new to linear algebra, so there is the possibility that I'm making some cardinal error. If so, could someone please outline where my line of reasoning here breaks down? If not, could someone please outline how the last equality holds?","['regression', 'least-squares', 'linear-regression', 'weighted-least-squares', 'linear-algebra']"
2791378,Evaluate $\lim_{n\rightarrow\infty}\sum_{k=1}^n\arcsin(\frac k{n^2})$,"Compute $$\lim_{n\to\infty}\sum_{k=1}^n\arcsin\left(\frac k{n^2}\right)$$ Hello, I'm deeply sorry but I don't know how to approach any infinite sum that involves $\arcsin$, so I couldn't do anything to this question. Any hints/tips would be appreciated. I know I have to make it somehow telescopic but I don't know how to use formulas like $$\arcsin x-\arcsin y=\arcsin\left(x\sqrt{1-y^2}+y\sqrt{1-x^2}\right)$$ My knowledge level is 12th grade. I tried to put it in between $$\arcsin\frac 1{n^2}< \sum_{k=1}^n\arcsin\frac k{n^2} <\arcsin\frac n{n^2}$$ so then $L=0$, but it's wrong.","['limits', 'definite-integrals', 'limits-without-lhopital', 'summation', 'sequences-and-series']"
2791382,Find a flag to transform a matrix to an upper triangular one,"Consider $F: \mathbb{R^3} \to \mathbb{R^3}$ represented by: $ A=
    \begin{bmatrix}
    1 & 1 & 2 \\
    -2 & 5 & 6 \\
    1 & -2 & -2 \\
    \end{bmatrix}
$
 , eigenvalues: $(\lambda - 1)^2(\lambda -2)$ Now, $A$ admits Jordan canonical form: $ J_A=
    \begin{bmatrix}
    2 & 0 & 0 \\
    0 & 1 & 1 \\
    0 & 0 & 1 \\
    \end{bmatrix}
$, so, the basis which brings $A$ in this form is a flag. However the exercise asks to find a flag with the method $\{0\} \subseteq V_1 \subseteq V_2 \subseteq ... \subseteq 
 \mathbb{R^n}$. It requests to verify that: $V_1 =x_1+x_3 =x_2+2x_3=0$ $V_2 = x_2+2x_3=0$ are s.t. $\{0\} \subseteq V_1 \subseteq V_2 \subseteq V_3\ = \mathbb{R^3}$ is a flag for $F$ That is true, because the eigenvector of the eigenvalue $\lambda_1 =1$ is $v_{\lambda_1}=(1, -2, 1)$ and $V_1 = span \{(1, -2, 1\}$; plus, we notice that $(1, -2, 1) = (1, 0, 0) + (0, -2, 1)$ and these two are vectors of a basis of $V_2$, so $\{0\} \subseteq V_1 \subseteq V_2$. Verified that, I have to complete a basis of $V_1$ on a complementary basis $W$ s.t. $V_1 \oplus W =  \mathbb{R^3}$ and write a matrix whose columns are those vectors: $B=
    \begin{bmatrix}
    1 & 0 & 0 \\
    -2 & 1 & 0 \\
    1 & 0 & 1 \\
    \end{bmatrix}
$, for example. I find $B^{-1} = 
    \begin{bmatrix}
    1 & 0 & 0 \\
    2 & 1 & 0 \\
    -1 & 0 & 1 \\
    \end{bmatrix}$ At this point $B^{-1}AB =C$ would be of the type: $
    \begin{bmatrix}
    \lambda_1 & \bullet & \bullet \\
    0 & * & * \\
    0 & * & * \\
    \end{bmatrix}
$, from here we have to write a new basis, whose first vector will be $(1,0,0)$, invariant, the second $(0,a,b)$ where $(a,b)$ is eigenvector of the restriction to $
    \begin{bmatrix}
    * & * \\
    * & *
    \\
    \end{bmatrix}
$ of $C$ and, finally, the tird vector as complementary basis and repeat. But $B^{-1}AB$, so ""built"", isn't of the type $C$ and I don't understand where I'm getting wrong. Thank you!","['jordan-normal-form', 'matrices', 'change-of-basis', 'geometry', 'linear-algebra']"
2791414,"If $X$ is a Banach space, is $\ell^{p}(X) \cong \ell^{q}(X^{*})$?","Here's the problem that I have: ( $\frac{1}{p}+\frac{1}{q} =1$ ) Let $(X, ||\cdot||_{X})$ be a Banach space, and let $\ell^{p}(X) = \lbrace (x_{n})_{n=1}^{\infty} | \sum_{n=1}^{\infty} ||x_{n}||_{X}^p < +\infty \rbrace$ , for some $1 \leq p < +\infty$ . Prove that: $\ell^{p}(X)$ is a Banach space with respect to the norm $||(x_{n})_{n=1}^{\infty}||_{p} = \sqrt[p]{\sum_{n=1}^{\infty}||x_{n}||_{X}^{p}}$ ; Every functional $y^{*} \in \ell^{p}(X)$ can be written as $y^{*}((x_{n})_{n=1}^{\infty}) = \sum_{n=1}^{\infty}y_{n}^{*}(x_{n})$ , where $y_{n}^{*} \in X^{*}$ , $\sum_{n=1}^{\infty}||y_{n}^{*}||_{X^{*}}^{q} < +\infty$ and $||y^{*}|| = \sqrt[q]{\sum_{n=1}^{\infty} ||y_{n}^{*}||_{X^{*}}^{q}}$ . A very similar question has been asked here: Banach valued sequence spaces $\ell^p(X)$ . However, it's not enough for me to work out the details of my problem. Here's what I have so far: I did not have any trouble with part 1, and I would like to omit my proof here because it's pretty standard, but I will type it out if someone requests it. For part 2: Given a functional $y^{*} \in \ell^{p}(X)^{*}$ , we define, for each $n \in \mathbb{N}$ , a functional $y_{n}^{*} \in X^{*}$ , $y_{n}^{*}(x) = y^{*}(0,0,...,0,x,0,...)$ , where $x$ is at the $n$ -th coordinate. $y_{n}^{*}$ are bounded because $y^{*}$ is bounded. Furthermore, for $x = (x_{n})_{n \geq 1}$ , $y^{*}(x) = y^{*}(\sum_{n=1}^{\infty} (0,...,0,x_{n},0,...))= \sum_{n=1}^{\infty}y^{*}(0,...,0,x_{n},0,...) = \sum_{n=1}^{\infty} y_{n}^{*}(x_{n})$ . By part 1, and because $X^{*}$ is also a Banach space with the operator norm, it follows that $\ell^{q}(X^{*})$ is also a Banach space with the corresponding norm. Now, let us define $Y = (y_{n}^{*})_{n \geq 1}$ . $||Y||_{q} = \sqrt[q]{\sum_{n=1}^{\infty} ||y_{n}^{*}||^{q}} \in [0, +\infty]$ . I wish to prove that this norm cannot be infinity, and that $||Y||_{q} = ||y^{*}||$ . By Hölder's inequality, $$|y^{*}(x)| = |\sum_{n=1}^{\infty}y_{n}^{*}(x_{n})| \leq \sum_{n=1}^{\infty}|y_{n}^{*}(x_{n})| \leq \sum_{n=1}^{\infty} ||y_{n}^{*}|| \hspace{1mm} ||x_{n}|| \leq \sqrt[q]{\sum_{n=1}^{\infty} ||y_{n}^{*}||^{q}} \sqrt[p]{\sum_{n=1}^{\infty} ||x_{n}||^{p}} = ||Y||_{q}||x||_{p},$$ so $||y^{*}|| \leq ||Y||_{q}$ . However, it seems (to me) pretty difficult to find an $x$ for which equality would hold in the previous inequality chain, and even more difficult to find a sequence of $x$ 's, $(x^{m})$ for which I could let $m \to \infty$ and achieve equality. Therefore, I'm having trouble proving $Y \in \ell^{q}(X^{*})$ and $||Y||_{q} \leq ||y^{*}||$ . The answer in the linked question says to proceed as in $(\ell^{p})^{*} \cong \ell^{q}$ , however, the proof that I know uses a very specific construction of a sequence of complex numbers, a luxury that I don't have in this case.","['functional-analysis', 'lp-spaces', 'banach-spaces', 'linear-transformations']"
2791415,"For every integer $n \geq 2$ , there is a unique non-trivial homomorphism $f: {S_n} \to \mathbb{C^*}$.","For every integer $n \geq 2$ , there is a unique non-trivial homomorphism  $f: {S_n} \to \mathbb{C^*}$. How can I prove this statement? I know there will be a homomorphism as $S_n \over A_n$ is isomorphic to ${(1 ,-1).}$ But how can I prove that there is no other homomorphism than that? Can anyone please help me?","['abstract-algebra', 'group-theory', 'symmetric-groups', 'group-homomorphism']"
2791417,"How to show that cusp of congruence subgroup $\Gamma_0(4)$ is $0,\frac{1}{2},\infty$？","Let $\Gamma_0(4)$ be a congruence subgroup of $SL(2,\mathbb{Z})$ defined as
  $$\Gamma_0(4)=\Big\{M=\begin{pmatrix}
a &b\\
c& d
\end{pmatrix}\in SL(2,\mathbb{Z}) |  c \equiv 0\bmod 4\Big\}.$$
  How to show that cusp of $\Gamma_0(4)$ is $0,\frac{1}{2},\infty$？I have looked up the answer: Inequivalent cusps of $\Gamma_0(4)$ , but I do not understand. 
  We define the group action: if $\forall \gamma \in SL(2,\mathbb{Z})$, 
  $$ \gamma \infty= \begin{cases}  \frac{a}{c}, c\neq 0\\ \infty, c=0 \end{cases}$$ $$ \gamma z= \begin{cases}  \frac{az+b}{cz+d}, cz+d \neq 0\\ \infty, cz+d=0 \end{cases}$$ I try to use the same method of proof $\Gamma_0(2)$ cusp $0,\infty$. For $\forall \frac{p}{q}$, if $q$ is even, there exists $r,s\in \mathbb{Z}$, s.t. $rp-sq=1$, we have $$\begin{pmatrix}
p &s\\
q& r
\end{pmatrix} \infty = \frac{p}{q},$$
where $\begin{pmatrix}
p &s\\
q& r
\end{pmatrix} \in \Gamma_0(2)$. if $q$ is odd, there exists $r,s\in \mathbb{Z}$, sinece $\gcd(2p,q)=1$, s.t. $-2rp+sq=1$, we have $$\begin{pmatrix}
s &p\\
2r& q
\end{pmatrix} 0 = \frac{p}{q}, $$
where $\begin{pmatrix}
s &p\\
2r& q
\end{pmatrix} \in \Gamma_0(2)$. Similarly, for $\Gamma_0(4)$, I have known $0, \infty$ and $0,\frac{1}{2}$ are not equivalent. $\textbf{But for $\forall \frac{p}{q}\in \mathbb{Q}$, how to find the matrix $\gamma \in \Gamma_0(4)$}$,  s.t. 
$$ \gamma \frac{1}{2}=\frac{p}{q}.$$ If $q \equiv 0 \mod4$, $\gcd(p,q)=1$, it is easy to seek the 
$$\begin{pmatrix}
p &s\\
q& r
\end{pmatrix} \infty = \frac{p}{q},$$
where $\begin{pmatrix}
p &s\\
q& r
\end{pmatrix} \in \Gamma_0(4)$. How about the $q \equiv 1,2,3 \mod4$?","['elliptic-functions', 'abstract-algebra', 'algebraic-number-theory', 'number-theory', 'modular-forms']"
2791419,prove: $\mathrm|{A}|=|\cup_{n\in\mathbb{N^{\mathrm{+}}}}\mathrm{A}^{n}|$ when $\mathrm{|A|\geq|A\times A|}$,"Let $$\mathrm{|A|\geq|A\times A|}$$ as $A$ is a given set such that $|A| > 1$. For every $n\geq1$, let $\mathrm{A^{n}}$ be the set of function from $\{0,1,....,n-1\}$ to $\mathrm{A}$. prove: $$\mathrm|{A}|=|\cup_{n\in\mathbb{N^{\mathrm{+}}}}\mathrm{A}^{n}|$$ if we look on any object: $\mathrm{A^{i}}\in\mathrm{A^{n}}$ as $i\in\mathbb{N}$ and $\sum_{i=1}^{n-1}\mathrm{A^{i}}=\mathrm{A^{n}}$ , than any $\mathrm{A^{i}}:i\longrightarrow\mathrm{A}$  as I understand is defined to be onto, therefore $\mathrm{A^{n}}$ is onto $A$, so $$|\mathrm{A}|\leq|\cup_{n\in\mathbb{N^{\mathrm{+}}}}\mathrm{A}^{n}|$$
(this is just some ideas I had because I didn't really found any information about how to solve this type of Q). after that, it is clear that I'll need to use the fact $\mathrm{|A|\geq|A\times A|}$ in some way so I could use CBS, but i really can't find the way to solve this.","['elementary-set-theory', 'cardinals', 'functions']"
2791489,Is a small linear invertible perturbation of a linear isomorphism also an isomorphism?,"Suppose we have a linear isomorphism $T_{0}: \mathbb{R}^{n} \mapsto \mathbb{R}^{n}$, and $T_{\epsilon}$ is a small linear perturbation of it, i.e. $$T_{\epsilon} = T_{0} + \epsilon T_{1} + O(\epsilon^{2}),$$ where $T_{1}$ is also linear isomorphism and $0< | \epsilon | <<1$. Does it follow that $T_{\epsilon}$ is also an isomorphism? If so, I am  wondering is it possible to use an implicit function theorem for this, or can some result from perturbation theory of linear operators be used? (Note that this question comes from an earlier one: How do I set up Implicit Function Theorem to verify this function is a $C^{r}$ diffeomorphism? ) Thanks!","['operator-theory', 'vector-space-isomorphism', 'functional-analysis', 'linear-transformations', 'linear-algebra']"
2791503,Compute: $\arcsin x+ \arctan \frac{\sqrt{1-x^2}}{x}$,"$$\arcsin x+ \arctan \frac{\sqrt{1-x^2}}{x}$$
This problem is from my final test for this semester in the third year highschool. I think this should be solved by using Lagrange or Rolle.
I computed the derivative for $f(x)$ ,$f(x)$=$\arcsin x+ \arctan \frac{\sqrt{1-x^2}}{x}$ $f'(x)=0; $ Using Rolle we know that $f(a)=f(b) $ where $x\in(a,b)$","['trigonometry', 'calculus']"
2791517,Integrate $\int\tan^{-1}\sqrt{\frac{1-x}{1+x}}dx$,"Integrate $\int\tan^{-1}\sqrt{\frac{1-x}{1+x}}dx$ My Attempt Put $x=\cos2a\implies dx=-2\sin2a.da$
$$
\int\tan^{-1}\sqrt{\frac{1-x}{1+x}}dx=\int\tan^{-1}\sqrt{\frac{1-\cos2a}{1+\cos2a}}.-2\sin2a.da\\
=-2\int\tan^{-1}\sqrt{\frac{2\sin^2a}{2\cos^2a}}.\sin2a.da=-2\int\tan^{-1}(\tan a)\sin2a.da
$$
We have $y=\tan^{-1}(\tan a)\implies\tan y=\tan a\implies y=n\pi+a$
$$
\begin{align}
&\int\tan^{-1}\sqrt{\frac{1-x}{1+x}}dx=-2\int(n\pi+a)\sin2a.da=-2n\pi a-2\int a.\sin2a.da\\
&=-2n\pi a-2\bigg[a\frac{-\cos2a}{2}-\int\frac{-\cos2a}{2}da\bigg]\\
&=-2n\pi a+a.\cos2a+\frac{\sin2a}{2}+C\\
&=-2n\pi.\frac{1}{2}\cos^{-1}x+\frac{1}{2}\cos^{-1}x.x+\frac{\sqrt{1-x^2}}{2}+C\\
&\color{red}{=\frac{1}{2}\bigg[-2n\pi\cos^{-1}x+x\cos^{-1}x-\sqrt{1-x^2}\bigg]}
\end{align}
$$
My reference has the solution $\frac{1}{2}\bigg[x\cos^{-1}x-\sqrt{1-x^2}\bigg]$. But, why am I getting the solution as above ?","['inverse-function', 'calculus', 'indefinite-integrals', 'integration', 'trigonometric-integrals']"
2791523,self-adjoint operator with positive spectrum is positive,"I have found many threads about the inverse statement but none for this: (Part of exercise 6.24 in Brezis) Let $T$ be linear, self-adjoint operator on a Hilbert space and assume that the spectrum of $T$ fulfills $\sigma(T) \subset [0,\infty)$. Prove that the operator is positive, i.e. $(Tu,u)\geq 0$. So from know on I will set $\lambda < 0$ be a real number outside the spectrum, i.e. $T-\lambda I$ will be one-to-one and onto. I have tried the following: Starting with $(Tu,u)$, we set $v$ such that $Tv-\lambda v = u$ (exists by assumption), and we have to prove that $(T^2v-\lambda Tv, Tv-\lambda v) \geq 0$. Now we can isolate a few interesting terms but I can't show positivity To me it looks like the proof should go like this: We have some property which is known to be positive and somewhere inside this term we have a factor of $-\lambda(Tu, u)$ and if we assume $(Tu,u)$ (and thus $-\lambda(Tu, u)$) to be negative, we will get a contradiction for $0>\lambda \to 0$. I started with $0\geq (Tu-\lambda u, Tu- \lambda) = \|Tu\|^2 - 2\lambda (Tu, u) + \lambda^2 \|u\|^2$ but this did not get me anywhere.",['functional-analysis']
2791535,Is this integral $\int_0^\infty\frac{\cos(a x+ 2b \arctan x)}{x^2+1}dx$ exactly zero when $b\in\mathbb{N}$?,"I recently encountered this integral
$$\int_0^\infty\frac{\cos(a x+ 2b \arctan x)}{x^2+1}dx$$
which suspiciously close to 0 for nonzero integer values of $b$, as indicated by numerical calculations. When $b$ is not an integer it is not 0. Based on my experiments I conjecture that
$$\int_0^\infty\frac{\cos(a x+ 2b \arctan x)}{x^2+1}dx=0,~~~~b\in \mathbb{Z}\setminus \{0\}.$$ Question. Is the above conjecture true?","['conjectures', 'calculus', 'integration', 'definite-integrals', 'contour-integration']"
2791574,Bounded derivative of increasing function,"Consider a function $f:[0,\infty)\longrightarrow [0,\infty)$. Suppose that $f(0)=0$ and that $f$ is strictly increasing. Moreover, assume that $f$ is continuously differentiable except at zero and that $f$ is differentiable (from right) at zero. Is it true that $f$ has a bounded derivative on some neighborhood of zero? If not, under which conditions on $f$ can we ensure this?","['derivatives', 'calculus', 'functions']"
2791580,$\lim\limits_{x\to \infty} \frac{1}{\ln(x+1)-\ln(x)}-x$,"Having a hard time solving $\lim\limits_{x\to \infty} \frac{1}{\ln(x+1)-\ln(x)}-x$. I tried using $\ln \left(\frac{a}{b}\right) = \ln a - \ln b$ , to rewrite the denominator so i got $\lim\limits_{x\to \infty} \frac{1}{\ln \frac {x+1}{x}}-x$ But from there im unsure how to use a series to substitute the ln part.","['calculus', 'limits']"
2791588,Leading terms in asymptotic expansion of modified bessel function of the first kind,"Show that leading and next-to-leading terms in an asymptotic expansion for large $x>0$ of the modified Bessel functions of the first kind $I_0(x)$ and $I_1(x)$ are: $$I_0(x) \sim \frac{e^x}{\sqrt{2\pi x}}\left(1+\frac{1}{8x}\right) \ \ \ \text{ and } \ \ \ I_1(x) \sim \frac{e^x}{\sqrt{2\pi x}}\left(1-\frac{3}{8x}\right).\tag{1}$$ I am fairly sure I should use the method of steepest descent to evaluate the integral, but not sure how to proceed. Any help would be greatly appreciated. Modified Bessel function of the first kind ( $n$ is an integer): $$I_n(x) = \frac{1}{\pi}\int_0^\pi e^{x \cos(\theta)} \cos(n\theta) d\theta.\tag{2}$$ Some helpful links: http://mathworld.wolfram.com/ModifiedBesselFunctionoftheFirstKind.html https://dlmf.nist.gov/10.40","['bessel-functions', 'asymptotics', 'integration', 'contour-integration', 'approximation']"
2791595,Intuition behind Heaviside expansion formula,"Hello my electrical engineering teacher gave me those formulas when teaching how to solve electrical circuits using Laplace transforms. Having a polynomial $Q(s)$ of degree $n$ and $P(s)$ with degree $m$ the if $m<n$ and $$F(s)=\frac{Q(s)}{P(s)}$$ then the inverse Laplace transform is given by $$f(t)=\sum_{k=1}^n\frac{P(s_k)}{Q'(s_k)}e^{s_kt}$$ also if $$F(s)=\frac{P(s)}{sR(s)}$$ then $$f(t)=\frac{P(0)}{R(0)}+\sum_{k=1}^{n-1}\frac{P(s_k)}{s_kR(s_k)}e^{s_kt}$$ and $s_k$ are the roots of the polynomial in the denominator. Now I have studied Laplace transform in math class, however my math teacher did not proved or mention those formulas. All that I found related to this was on this answer: https://math.stackexchange.com/a/248355/515527 Could you perhaps give me some intuition or a proof for these theorems, even though it is used in electrical engineering I think I can make use of it everytime I have to do ILT.","['complex-analysis', 'laplace-transform']"
2791610,simply connectedness implies unbounded connected components?,"Let $\Omega:=\{z\in\Bbb{C};\;0<\Im(z)<1\},$ it's convex so simply connected. As we can see the two connected components of $\Bbb{C}\setminus\Omega$ are not bounded. Any exemple I can imagine of open connected sets of $\Bbb{C}$ that are simply connected have this property. So I imagine the following result is true: Let $\Omega$ an open connected set of $\Bbb{C}.$ If $\Omega$ is simply connected then the c of $\Bbb{C}\setminus\Omega$ are not bounded. I am aware that a proof use, probably, algebraic topology. It's not a problem to read but much harder to find, I think. Is the result true? If yes, where I can find a proof?(even in the form of exercise)","['algebraic-topology', 'complex-analysis', 'general-topology']"
2791657,Divisors of the Euler totient function,"For which values of $m$ do there exist infinitely many $n$ such that $m$ divides $\phi(n)$? Now, I know $\phi(n)$ is even for $n >2$, so clearly $m$ can’t be an odd number (except $1$). 
So $m=2$ clearly satisfies this, so I was wondering do all even integers satisfy this? Or just even integers which are of the form $p-1$ for a prime $p$?","['number-theory', 'prime-numbers', 'elementary-number-theory']"
2791664,"Prove that smallest $\sigma$-algebra on a partition is $\left\{\bigcup_{i \in I} A_i : I \subseteq \{1,...,n\}\right\}$","I am stuck with this problem. I want to prove this equality but I don't know how to do it. First of all I am going to define what is a $\sigma$ -algebra is: Let $X$ be a set. Then a sigma-algebra $F$ is a nonempty collection of subsets of $X$ such that the following hold: $X$ is in $F$ . If $A$ is in $F$ , then so is $(X\setminus A)$ . If $A_n$ is a sequence of elements of $F$ , then the union of the $A_n$ is in $F$ . If $S$ is any collection of subsets of $X$ , then we can always find a sigma-algebra containing $S$ , namely the power set of $X$ . By taking the intersection of all sigma-algebras containing $S$ , we obtain the smallest such sigma-algebra. We call the smallest sigma-algebra containing $S$ the sigma-algebra generated by $S$ . Being $\Omega$ a set and $\{A_1, A_2,...,A_n\}$ a partition of it. I have to prove that: $$\sigma (\{A_1, A_2,...,A_n\})=\left\{\bigcup_{i \in I} A_i : I \subseteq \{1,...,n\}\right\}$$ Can somebody help me?","['abstract-algebra', 'probability-theory', 'probability', 'measure-theory']"
2791666,Space of finite measures as an $L_1$ space,"The dual of the space of continuous functions on a compact space $K$ is the space of regular signed measures with finite total variation, $rca(K)$. I have seen it stated (for example in this answer https://math.stackexchange.com/a/74877/564061 ) that this is isometric to $L_1(\mu)$ for some measure $\mu$ on $K$. I know that the space is isomorphic to the $l_1$ sum of spaces $L_1(\mu_i)$ for mutually singular probability measures $\mu_i$, $i\in\mathcal{A}$ (possibly uncountable), see $\mathcal M(K)$ is an $\mathcal{l}_1-$sum of $L_1(\mu)$ spaces . Is there a way to relate this space to one of the form $L_1(\mu)$? It seems to me that the obvious candidate bijection would map $(f_i)_{i\in\mathcal{A}}$ to $\sum_{i\in\mathcal{A}}f_i$. I think we can make sense of this sum since only countably many of the $f_i$ are non-zero at any $x\in K$, but I am not sure how to progress. At first I thought that for any $x$ there was at most one $i\in\mathcal{A}$ such that $f_i(x)\neq 0$, but that isn't the case. I am asking because I wish to write elements of $C(K)^{**}$ as functions on $K$. The above relation allows us to equate $C(K)^{**}$ and the $l_{\infty}$-product of the spaces $L_{\infty}(\mu_i)$, and really I would just like a 'nice' relation between $C(K)^{**}$ and some space of functions, to avoid dealing with these nets of functions- the properties of the space aren't important. I am interested particularly in the case where $K\subseteq \mathbb{R}^2$.","['functional-analysis', 'banach-spaces', 'measure-theory']"
2791696,Classification of all matrix transformations on $\mathbb{R}^2$ plane,"What is a complete exhaustive classification of all geometric transforms on the $\mathbb{R}^2$ plane obtained with: 2x2 matrices$$A = \pmatrix{a & b \\ c & d}$$ applied to a point $X= (x, y)$. 3x3 matrices $$A = \pmatrix{a & b& c \\ d & e & f \\ g & h & i}$$  applied to a point $(x, y)$ noted $X = (x, y, 1)$ using homogeneous coordinates. ? Note: I've already looked at Transformation matrix Wikipedia page, which is good, but it mainly gives examples (stretching, squeezing, etc.), and doesn't state it as a full classification of all possible transforms. In most lecture notes / resources I find, it usually goes this way: here is a list of geometric transforms => here are their representation as matrix In this question I'm more looking for: here is a random 3x3 matrix => what geometric transform is it? I'm looking for an exhaustive classification like ""All 2x2 matrices can be either a rotation matrix with parameter $\theta$, a scaling matrix of parameter $\lambda_1, \lambda_2$, a blahblah matrix of parameter $\delta$, or a composition of any 2 of them"" (nonsense, just an example).","['matrices', 'euclidean-geometry', 'linear-transformations', 'geometry', 'linear-algebra']"
2791703,Unclear calculus problem,"I don't know if that's called calculus or precalculus in the Anglosphere, so please pardon me if I got the terminology incorrect. I've been given the second derivative of $f(x): f''\left(x\right)=\frac{2x-1}{\sqrt{-x^2+x+6}} $. I was asked to find $f'(x)$, if it is known that the slopes of all tangent lines to the graph of $f(x)$ in the range of $-2<x<3$ are not smaller than -1. 
I integrated the second derivative:
$$f'\left(x\right)=\int \:\frac{2x-1}{\sqrt{-x^2+x+6}}dx\:=\:-2\sqrt{-x^2+x+6}\:+\:C$$
So the task at hand is essentially to find the value of C. The problem, however, is that I did not understand how to do that. The only thing I managed to conclude from the given information (about the slopes of the tangent lines) is that $f'\left(x\right)\ge -1$, and I don't know how to use an inequality to find C. If someone can make it clearer, I'll be extremely glad :) P.S. The final answer (according to the textbook) is $f'\left(x\right)=\:-2\sqrt{-x^2+x+6}\:+\:4$.","['derivatives', 'calculus', 'algebra-precalculus', 'indefinite-integrals', 'integration']"
2791760,Class of spaces on which a 'path integral' like construction holds,"I've been working through the proof of de Rham's theorem and as part of this effort, the fact that for a differentiable manifold $M$ there's an isomorphism between the regular and smooth singular homologies of $M$. This strikes me as an analytic, approximation-type result in spirit: smooth 1-chains are, modulo coefficients, just piece-wise differentiable curves in $M$, so at some level we're just approximating possibly very badly behaved $C^0$ curves in our space by nicer ones.  Continuing the 1-dimensional intuition, if I have some nice-enough behaved vector field/differential form-type object, then all I need for a well-defined contour integral is a nice-enough class of curves that I can integrate along, sufficient to recover/reflect the topological structure of my space. This to me begged the following (perhaps ill-posed) question. Question : What type of point-set/analytic considerations need be placed on a subset $X$ of $\mathbb{R}^n$ such that we can recover some similar type of result: using only some 'nice enough' (perhaps Lipschitz or something) collection of images of simplices into $X$ and we can recover some theory of integration for something spiritually similar to vector fields/differential forms, ideally reflective of the topology of $X$? I get that this is all very likely to hinge on the 'nice-enough' handwaving in the above, but I'd be very curious to hear about either examples in this vein or obstructions to defining them in any meaningfully interesting context. Motivation : Some trivial motivation, say $X \subseteq \mathbb{R}^n$ is convex.  If we consider only affine images of simplices into $X$, it would seem intuitive that we recover an analogue that 'every cycle is a boundary' and hence the ""homology"" of the resulting chain complex is zero, squaring with intuition.  Moreover, if you give me any, say ""1-cochain,"" it seems like we'd recover a fairly natural notion of path integral along polygonal paths, complete with a notion of exactness and closedness that work in the intuitive way.  Again, this is all meaningless because the collection of spaces is wholly uninteresting topologically, but I'd be curious to see how this type of intuition could be extended (maybe even the above construction to something like open sets or closed sets who are the closure of their interior) in ways I may not have encountered.","['differential-topology', 'integration', 'soft-question', 'algebraic-topology', 'differential-geometry']"
2791780,Can I Systematically Determine the Cardinality of a Finite Set?,"Is there any way you can, in a systematically manner, determine the cardinality of a finite set in which the elements are given by a specific expression? For example, let $A$ be a set $\ A=\{1,2,3,4,5,6\}$ and $B$ be a set defined by:
$$B=\biggl\{\frac{a-b}{a+b} : a,b\in A\biggl\}$$
My question is thus, can I somehow determine the cardinality of the set without having to calculate and enumerate each and every element ?",['elementary-set-theory']
2791787,"The difference between two periodic functions converges to zero, is this two functions identical?","If $f(x)$ and $g(x)$ are two periodic functions, that is, $f(x+T_1)=f(x)$ and $g(x+T_2)=g(x)$ for every $x \in \Bbb R$ . Now that $\displaystyle\lim_{x\to\infty}(f(x)-g(x))=0$ . Conjecture: $f(x) \equiv g(x)$ .","['periodic-functions', 'calculus', 'limits']"
2791831,"Why do $SU(2)$ and $SL(2,\mathbb{C})$ have the same Lie algebra?","The Lie algebras $su(2)$ and $sl(2,\mathbb C)$ have the same Dynkin Diagram (just a blob) and therefore also have the same structure constants and isomorphic Lie algebras. Additionally, they are both, as one can prove, simple and semisimple. But both Lie groups are not isomorphic (since the latter is non-compact) neither is one a covering group of the other. How is this possible?","['dynkin-diagrams', 'group-theory', 'lie-algebras', 'lie-groups']"
2791844,Find the length of the line segment $CE$,"Let $BD$ be a median in $\triangle ABC$. The points $E,F$ trisect $BD$ such that $BE=EF=FD$. If $AB=1$ and $AF=AD$, find the length of the line segment $CE$.","['triangles', 'geometry']"
2791853,Average of irrational flow on the torus,"Let $$F(x,y) = \frac{1}{\sqrt{2-\sin(2\pi x) - \sin(2\pi y)}}$$
defined on $\mathbb{T}^2$. Here $\mathbb{T}^2 = \mathbb{R}^2/ \mathbb{Z}^2$ is the 2-torus. How can I show that
$$ \lim_{T\longrightarrow \infty} \frac{1}{T}\int_0^T F(x,\sqrt{2}x)\;dx = \iint_{[0,1]^2} F(x,y)\;dxdy?$$
What can we say about the rate of convergence? Say $\frac{1}{T^\alpha}$ for some $\alpha \in (0,1)$?","['fourier-analysis', 'harmonic-analysis', 'irrational-numbers', 'functional-analysis', 'ergodic-theory']"
2791862,"Theorem 5.16 in Apostol's MATHEMATICAL ANALYSIS, 2nd ed: Intermediate-Value Theorem for Derivatives","Here is Theorem 5.16 (intermediate-value theorem for derivatives) in the book Mathematical Analysis by Tom M. Apostol, 2nd edition: Assume that $f$ is defined on a compact interval $[a, b]$ and that $f$ has a derivative (finite or infinite) at each interior point. Assume also that $f$ has finite one-sided derivatives $f^\prime_+(a)$ and $f^\prime_-(b)$ at the endpoints, with $f^\prime_+(a) \neq f^\prime_-(b)$. Then, if $c$ is a real number between $f^\prime_+(a)$ and $f^\prime_-(b)$, there exists at least one interior point $x$ such that $f^\prime(x) = c$. And, here is Apostol's proof: Define a new function $g$ as follows: 
  $$ g(x) = \frac{ f(x) - f(a) }{ x-a } \ \mbox{ if } x \neq a, \qquad  g(a) = f^\prime_+(a). $$
  Then $g$ is continuous on the closed interval $[a, b]$. By the intermediate-value theorem for continuous functions, $g$ takes on every value between $f^\prime_+(a)$ and $[ f(b) - f(a) ]/(b-a)$ in the interior $(a, b)$. By the Mean-Value Theorem, we have $g(x) = f^\prime (k)$ for some $k$ in $(a, x)$ whenever $x \in (a, b)$. Therefore $f^\prime$ takes on every value between $f^\prime_+(a)$ and $[ f(b) - f(a) ]/( b-a )$ in the interior $(a, b)$. A similar argument applies to the function $h$, defined by
  $$ h(x) = \frac{ f(x) - f(b) }{ x-b } \ \mbox{ if } x \neq b, \qquad h(b) = f^\prime_-(b), $$
  shows that $f^\prime$ takes on every value between $[ f(b) - f(a) ]/(b-a)$ and $f^\prime_-(b)$ in the interior $(a, b)$. Combining these results, we see that $f^\prime$ takes on every value between $f^\prime_+(a)$ and $f^\prime_-(b)$ in the interior $(a, b)$, and this proves the theorem. What Apostol has not mentioned is the fact that $f^\prime$ does actually take on the value $[ f(b) - f(a) ]/(b-a)$ somewhere in $(a, b)$, by virtue of the Mean-Value Theorem. Am I right? Immediately following the above proof is this Note: Theorem 5.16 is still valid if one or both of the one-sided derivatives $f^\prime_+(a)$, $f^\prime_-(b)$, is infinite. The proof in this case can be given by considering the auxiliary function $g$ defined by the equation $ g(x) = f(x) - cx$, if $x \in [a, b]$. Details are left to the reader. Although I think I fully understand Apostol's proof of Theorem 5.16 as given above, I'm unable to figure out how to prove the result if either one or both of the one-sided derivatives $f^\prime_+(a)$ and $f^\prime_-(b)$ is infinite; I have no idea of how the new auxiliary function $g$ is going to be helpful in this regard.","['derivatives', 'real-analysis', 'calculus', 'proof-explanation', 'analysis']"
2791863,calculating the limit $\lim _{n\rightarrow \infty}((4^n+3)^{1/n}-(3^n+4)^{1/n})^{n3^n}$,"We need to calculating the limit 
$$
\lim _{n\rightarrow \infty}((4^n+3)^{1/n}-(3^n+4)^{1/n})^{n3^n}
$$ I have tried taking the logarithm, but the limit doesnt seem to arrive at any familiar form.","['real-analysis', 'calculus', 'limits']"
2791880,On the anti-commuting matrices,"I have a Hermitian matrix of size $n$, $H_{n\times n}$ with only off diagonal entries, actually all the entries are real in $H$ (very special case). Now my job is to find the anti-commuting matrix say $O_{n\times n}$ to $H_{n\times n}$, $O H O^{-1} = -H $, and with $O^{2} = 1 $ which is unitary matrix There are two cases, (i) when $n$ is odd, (ii) when $n$ is even. (i) If $H$ has entries where only at the odd sum of indices($i+j$ $\epsilon$ odd) exists then we can find $O$, e.g. $$H_{1} =\begin{bmatrix}0_{1,1} & a_{1,2} & 0_{1,3} \\a_{2,1} & 0_{2,2} & b_{2,3} \\ 0_{3,1} & b_{3,2} & 0_{3,3} \end{bmatrix}$$ $O = \{\{\sigma_{z},0\},\{0,1\}\} $, where $\sigma_{z}$ is Pauli Matrix If we have element also at the even site $(1,3)$ and $(3,1)$, say $c$, then $$H_{2} =\begin{bmatrix}0_{1,1} & a_{1,2} & c_{1,3} \\a_{2,1} & 0_{2,2} & b_{2,3} \\ c_{3,1} & b_{3,2} & 0_{3,3} \end{bmatrix}$$ Then we can't find $O$. Then the story is same for case (ii) even $n$. Is there a way to show this? (My background is in Physics, I'm not very good with maths. I strongly apologize for that). Both a sketch solution or a good starting point would help me.","['matrices', 'linear-algebra']"
