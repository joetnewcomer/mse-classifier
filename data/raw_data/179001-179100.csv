question_id,title,body,tags
3246174,Does complex integration only depend on endpoints?,"I have been watching some videos on Complex Analysis and from my understanding, integrating an analytic function over a curve only depends on the endpoints of the curve. If that is true, why does $\int dz/z$ evaluated along the unit circle equal $2\pi i$ instead of $0$ ?","['complex-analysis', 'contour-integration', 'complex-integration']"
3246188,Convergence of moving point inside of unit disk.,"Suppose Set D : $$D=\left\{(x, y)\vert x^2 + y^2 \leq 1 \right\}$$ And Point $P(0, 0)$ on coordinate plane. Define 'Movement' : For a point P, select any direction and move $\frac{1}{2^n}$ to straight (Sorry, my english is poor.) When 'Movement' Execute $n$ -th times For example : $1$ st time, Suppose I selected positive-x-axis direction Then, Point $P(0,0)$ moves to $P\left(\frac{1}{2},0\right)$ $2$ nd time, Suppose I selected Positive-y-axis direction Then, Point $P\left(\frac{1}{2}, 0\right)$ moves to $P\left(\frac{1}{2},\frac{1}{4} \right)$ If I take $n\longrightarrow\infty$ , Arbitrary point $A(x, y)\in D$ can be expressed by 'Movement'? I Know that perimeter of $x^2+y^2=1$ can be expressed by 'Movement' because $$\sum_{n=1}^\infty \frac{1}{2^n}=1$$ But how about inside of $x^2 + y^2 =1$ ? Example The point with $1, 2, 3, 4, \cdots$ is a point which moved by $n$ -th 'Movement' The angle(direction) is free. the problem is : If $n \longrightarrow\infty$ , arbitrary points in $D$ can be expressed by 'Movement'?","['euclidean-geometry', 'limits', 'sequences-and-series', 'real-analysis']"
3246220,A signed version of the Hausdorff moment problem,"This is a follow-up to this question. Let $C([0, 1])$ denote the space of real-valued continuous functions, let $\mathbb R^{\infty}$ denote the space of all real sequences, and consider the mapping of $f\in C([0, 1])$ to $(\mu_n)\in \mathbb{R}^\infty$ , where $$\tag{1}
\mu_n(f):=\int_0^1 s^n f(s)\, ds.$$ (The letter $\mu$ stands for ""moment""). As we discovered in the linked question, this mapping is not surjective, because $\mu_n(f)$ must satisfy the bound $$\tag{2}
|\mu_n|\le \frac{C}{n+1},$$ where $C=\sup\left\{ |f(s)|\ :\ s\in[0,1]\right\}$ . Question . Suppose that $(\mu_n)\in \mathbb R^{\infty}$ is a sequence that satisfies the bound (2), for some constant $C>0$ . Does there exist $f\in C([0, 1])$ such that $\mu_n=\mu_n(f)$ , as in (1)? This is similar to the Hausdorff moment problem , but with signed continuous functions, not just positive ones, in place of positive probability measures. EDIT . The above is not the right question to ask, as mathworker21 clearly shows in his answer. The right question involves the mapping $$\tag{3}
\mu_n(m):=\int_0^1 s^n dm(s), $$ where $m$ is a signed Borel measure on $[0,1]$ . This sequence needs not satisfy (2); take, for example, $m(x) =\delta(x-1)$ . Instead, it satisfies $$\tag{4} \lvert \mu_n \rvert \le C, $$ where $C$ equals the total variation of $m$ . Refined Question . Suppose that $(\mu_n)\in\mathbb R^\infty$ is a sequence that satisfies (4) for some constant $C>0$ . Does there exist a signed Borel measure $m$ such that $\mu_n=\mu_n(m)$ , as in (3)? I have noticed that the same question has been already asked here , without response. My feeling is that the answer to the ""Refined question"" is affirmative, but that the proof is not very easy. I think that the method of proof of the Hausdorff moment problem can be adapted to the present case, but I don't know enough to do this adaptation myself. In case I do not get any feedback, I will accept mathworker21 answer, which fully solves the original question.","['probability-theory', 'functional-analysis', 'real-analysis']"
3246270,Suppose that $G$ is a group of order $924=2^2\cdot3\cdot7\cdot 11$. Prove that $G$ has an element of order $77$.,"Suppose that $G$ is a group of order $924=2^2\cdot3\cdot7\cdot 11$ . Prove that $G$ has an element of order $77$ . My attempt: By Sylow theorems, we know that there exist elements $ a, b\in G$ with $o(a)=7 $ and $o(b)=11$ . Note that $\gcd(7,11)=1$ , so if we can show that $ab=ba$ then we are through. Consider the group $\langle a \rangle$ acting on the set $\Omega=\{g\in G: o(g)=11\}$ by $$ a^k\cdot g:=a^kga^{-k}\ , k=1,2,...,7. $$ Note that the element and its conjugate have the same order and we can easily check that it is a well-defined $\langle a\rangle$ group action on $\Omega$ . Now by the Burnside's lemma , we know that the number of orbits, denoted by $|\Omega/\langle a\rangle|$ : $$ |\Omega/\langle a\rangle|=\frac{1}{7}\sum_{a^{k}\in\langle a\rangle}|\Omega^{a^k}| $$ where $\Omega^{a^k}=\{g\in\Omega:a^k\cdot g=g\}$ . Now suppose the converse, i.e., there are not elements fixed by $a^k$ in $\Omega$ if $k\ne 7$ ( $a^7=e$ the unit), then $$ |\Omega/\langle a\rangle|=\frac{1}{7}\sum_{e}|\Omega^{e}|=\frac{|\Omega|}{7}\in\mathbb Z. $$ So $\displaystyle 7\vert |\Omega|$ . But the number of Sylow $11$ -subgroups $n_{11}| 12\cdot 7$ and $n_{11}\equiv 1\pmod {11}$ , we have $n_{11}=1$ or $n_{11}=12$ and in either case, $|\Omega|=11-1=10$ and $|\Omega|=12\cdot (11-1)=12\cdot 10=120$ , respectively. But neither $7$ divides $10$ nor $7$ divides $120$ and we are done. Is my reasoning right? Moreover, I am looking for other solutions without using Burnside's lemma. Thank you.","['group-theory', 'abstract-algebra', 'proof-verification']"
3246357,A tricky integration over the unit sphere,"Please help me solve the following integral, $$
I=\int\limits_{\{x,y,z\}\in \mathbb{S}^2}\!\!\!\max\{0,x,x\cos{\theta}+y\sin{\theta}\}\,\mathrm dx\,\mathrm dy\,\mathrm dz
$$ where $\mathbb{S}^2$ is a unit sphere and $\theta$ is some constant such that $0\le\theta\le2\pi$ . Numerically (up to arbitrary precision) this is equal to $$
I=\pi(1+\frac{\sqrt{(1-\cos{\theta})^2+\sin^2{\theta}}}{2}).
$$ I am unable to solve/prove this analytically. This is for a research project, any help would be appreciated and acknowledged in the article.","['multivariable-calculus', 'multiple-integral']"
3246375,Totient function trick?,"I would like to search for primes of the form $$\varphi(n)^n+n$$ where $\ \varphi(n)\ $ denotes the totient function. The problem is that neither pfgw nor factordb seems to support the totient-function. Is there some trick allowing to determine the totient-function with some other functions that are supported by pfgw ? With PARI/GP, I calculated the positive integers $n$ , such that the above expression is prime. These are $\ 1,2,3,187\ $ and no other below $\ 3\ 000\ $","['number-theory', 'totient-function', 'elementary-number-theory', 'prime-numbers']"
3246385,"Closed Poincaré dual, why $\int_M \omega \wedge \eta_S$ and not $\int_M \eta_S \wedge \omega $?","This question might be the same as this: Definition of closed Poincaré dual (I didn't read too carefully) but there is no answer. My book is Differential Forms in Algebraic Topology by Loring W. Tu and Raoul Bott of which An Introduction to Manifolds by Loring W. Tu is a prequel. The characterization of the closed Poincaré dual is given here (the ""(5.13)"") in Section 5.5. This has $\int_M \omega \wedge \eta_S$ , where $\eta_S$ is on the right rather than left . Question : Why is it $\int_M \omega \wedge \eta_S$ , where $\eta_S$ is on the right rather than left ? Update : The book made a mistake. See my question on overflow .","['integration', 'geometry', 'homology-cohomology', 'algebraic-topology', 'differential-geometry']"
3246386,$\int_0^{100}\frac{e^{-x}}{x+100}dx>0.005$?,"$\int_0^{100}\frac{e^{-x}}{x+100}dx>0.005$ ?
My attempt: $$\int_0^{100}\frac{e^{-x}}{x+100}dx>\int_0^{100}\frac{e^{-x}}{200}dx=\frac{1-e^{-100}}{200}$$ A little bit error. How to amend it?",['integration']
3246387,Explicit solution to nonlinear ODE,"I'm trying to find an explicit solution $u(t)$ of $$
\dot{u} = \frac{\beta}{\sqrt{\alpha t}-u},\quad u(0)=0
$$ where $\alpha>0$ and $\beta\in\mathbb{R}$ are given constants. I did not know how to solve it directly, so I tried to solve it numerically, but still I could not find a way to find an explicit solution. Does anybody have idea to solve it. Any explanation would be greatly appreciated.","['calculus', 'problem-solving', 'ordinary-differential-equations']"
3246474,Can we prove that for ABC-triples the product $A*B*C$ is unique?,"Consider positive coprime integers $A$ and $B$ with $A+B=C$ . The triple $(A,B,C)$ is called an ABC-triple if the radical of the product $ABC$ is smaller then $C$ . The radical of a positive integer $n$ , denoted $\operatorname{rad}(n)$ , is the product of the distinct prime factors of $n$ . For instance $\operatorname{rad}(20)=2.5=10$ . The smallest ABC-triple is $(1,8,9)$ as $\operatorname{rad}(1.8.9)=6<9$ . There is a database with all ABC-triples with $C<10^{18}$ . I noticed that the product $A*B*C$ is unique, but can we prove it ? If the hypothesis is true, we can use it to split the Dirichlet series $$\sum_{n=1}^{\infty}\frac{\operatorname{rad}(n)^t}{n^s}=\prod_{p,prime}{(1+\frac{p^t}{p^s-1})}$$ into two disjunct sets with $n=A*B*C$ and $n \ne A*B*C$ . Note that the ABC-triples $(128,3645,3773)$ and $(648,3125,3773)$ have the same radical as $\operatorname{rad}(ABC)=2.3.5.7.11$ . Hence a split of the summand using $\operatorname{rad}(ABC)$ does not work. I can only conclude the following. Assume that we would have $A_1*B_1*C_1=A_2*B_2*C_2$ for two different ABC-triples, then $A_1 \ne A_2$ , $B_1 \ne B_2$ and $C_1 \ne C_2$ . Reasoning. Because if $C_1=C_2$ then we can assume without loss of generality that $A_1 < A_2$ . This implies $A_2B_2>A_1B_1$ hence $A_2B_2C_2>A_1B_1C_1$ which is which is contrary to the assumption. We conclude that $C_1 \ne C_2$ . Now suppose $A_1=A_2$ . We can assume without loss of generality that $C_1 < C_2$ which implies that $B_1=C_1-A_1 < C_2-A_2=B_2$ . This leads to $A_1*B_1<A_2*B_2$ and $A_1*B_1*C_1<A_2*B_2*C_2$ which is also contrary to the assumption. Hence $A_1 \ne A_2$ . By symmetry in $A$ and $B$ we conclude $B_1 \ne B_2$ .","['number-theory', 'abc-conjecture']"
3246493,Intersection of all Sobolev spaces with negative order,"Call $H^{s}$ the usual $L^2$ -based Sobolev spaces on, say, a closed manifold, for $s \in \mathbb R$ . The intersection $\bigcap _{s<0} H^s $ contains $L^2$ . Is this intersection equal to $L^2$ ? Thank you.","['sobolev-spaces', 'functional-analysis']"
3246578,Is the set of zero sets of rational coefficient polynomials countable?,"I am trying to prove that the set of algebraic numbers is countable. I have managed to prove that the set of rational coefficient polynomials is countable. My idea is to prove that the set of zero-sets of rational coefficient polynomials is countable and argue the algebraic numbers are a subset of that set. Here is my reasoning: If we assume each polynomial of positive degree k has at most $k \in \mathbb{Z}_+$ roots (we assume this without proof), then for each $p \in \mathbb{Q}[X]$ the set $P_0 = \{ x \in \mathbb{Q}\, |\, p(x) = 0 \}$ is countable (since the set is finite). If we let $\mathcal{P}$ be the collection of zero-sets, then the set of all zero-sets is $\bigcup_{P_0 \in \mathcal{P}} P_0$ . This is a countable union, since each zero set corresponds to a unique rational coefficient polynomial (the set of which is proven to be a countable set). Thus the set is a countable union of countable sets i.e countable. Is my argument correct? NOTE: This is not for homework. This is for self studying. 
EDIT 2: polynomial of positive degree k",['elementary-set-theory']
3246587,Does equivariance of the MLE require the function be invertible?,"My statistics text states this theorem as if it works for any function $g$ : Let $\tau = g(\theta)$ be a function of $\theta$ . Let $\hat{\theta}_n$ be the MLE (Maximum Likelihood Estimator) of $\theta$ . Then $\hat{\tau}_n = g(\hat{\theta}_n)$ is the MLE of $g(\theta)$ . And offers this proof that seems to assume $g$ has an inverse: Proof. Let $h = g^{-1}$ denote the inverse of $g$ . Then $\hat{\theta}_n = h(\hat{\tau}_n)$ . For any $\tau$ , $\mathcal{L}(\tau)
 = \prod_i f(x_i; h(\tau)) = \prod_i f(x_i;\theta) = \mathcal{L}(\theta)$ where $\theta = h(\tau)$ . Hence, for any $\tau$ , $\mathcal{L}_n(\tau) = \mathcal{L}(\theta) \leq
 \mathcal{L}(\hat{\theta}) = \mathcal{L}_n(\hat{\tau})$ . Is an inverse required? Maybe the author is assuming one for a simpler proof? Also I'm not sure where the inequality is coming from? I tried reading the Wikipedia article on equivariant maps (my statistics text is my first exposure to the term) but it uses too much material I haven't learned yet.","['statistics', 'equivariant-maps', 'maximum-likelihood']"
3246618,Finding how many lattice points are on the line between two given points?,"I know the slope is $\frac{303-28}{459-34}=\frac{275}{425}=\frac{11}{17}$ this is an irrational number so there are either no lattice points or one lattice point. I was looking at this link to try and get some more information on how to solve this. So it says that if you have $y=ax+b$ where $a$ is irrational and $b$ is rational, then you have one lattice point. So the equation of this line is $y=\frac{11}{17}x+b$ $28=\frac{11}{17}(34)+b$ $y=\frac{11}{17}x+6$ So there is only one lattice point, is this correct?",['algebra-precalculus']
3246690,Do diffeomorphisms preserving a parallelisms act properly?,"Let $M$ be a connected $n$ -dimensional manifold and $\omega:TM\to \Bbb R^n$ a parallelism, that is a $\mathbb R^n$ valued $1$ -form that is an isomorphism at each tangent space, alternatively described by a frame $(b_1,...,b_n)$ of vector fields $\mathfrak X(M)$ so that the restriction to any tangent space is a basis. Let $f_n:M \to M$ is a sequence of diffeomorphisms preserving the parallelism, that is $f_n^*(\omega)=\omega$ or $D_xf_n(b_{i,x})=b_{i,f_n(x)}$ for all $x\in M$ . My question is: If there exists a point $x\in M$ so that $f_n(x)$ converges, does there exist a diffeomorphism $f$ and subsequence $f_{n_k}$ so that $f_{n_k}\to f$ ? My question can be reformulated more concisely: Let $\mathrm{Aut}(\omega,M)$ be the group of diffeomorphisms preserving a parallelism $\omega$ , does $\mathrm{Aut}(\omega,M)$ act properly on $M$ ? The topology of $\mathrm{Aut}(\omega,M)$ is the inherited topology of $\mathrm{Diffeo}(M)$ , which should mean that the notion of convergence is that of uniform convergence on compacta.","['general-topology', 'differential-topology', 'differential-geometry']"
3246695,Prove that there is no $a\in \mathbb R$ so that $f(x)= e^x(x^2+a) $ has only one extremum,"As to my understanding in order to calculate the behavior of the extrema of a function, a good approach is to examine the behavior of the first derivative of the given function.
So by calculating the derivative I got: $$ f'(x)=(e^x(x^2+a))'=e^x(x^2+2x+a)$$ now in order to examine the behavior of $f(x)$ I examine where $f'(x)$ is positive or negative. And at the points where $f'(x)=0$ there will be an extremum. So because $$ e^x >0 \space \forall x\in \mathbb R $$ whether $f'(x)$ is negative or positive is defined by the polynom $x^2 +2x+a$ Then by using the quadratic formula I found that for the discriminant $\Delta$ the following are true. For $a<1$ it's $\Delta > 0 $ that means that for $a \in(-\infty,1)$ , $f(x)$ has two extrema because the polynom has two roots and therefore the monotony of $f(x)$ changes twice. And for $ a > 1$ it's $\Delta<0 $ , the polynom has no real roots and therefore for $a\in(1,+\infty)$ , $f(x)$ shows no change in its monotony and as a result it has $0$ extrema. For the special case of $\Delta = 0$ the polynom is as well everywhere positive and therefore once again $f(x)$ has not extrema. So there is no value for $a$ so that $f(x)$ will have only one extremum. The thing is that just examining that way doesn't seem that ""mathematically"" correct to me and I wonder if there is any better way to examine and actually prove that there is no $a$ so that $f(x)$ has only one extremum.","['maxima-minima', 'derivatives', 'polynomials', 'real-analysis']"
3246705,Asymptotic Expansion for $\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k}$,"Prior Art The fact that $$
\lim_{n\to\infty}\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k}=0\tag1
$$ is the topic of this question . An argument using a bit of probability theory gives a first order estimate of the size of the sum. Estimate of the Sum The binomial distribution has mean $\frac n2$ and variance $\frac n4$ , Chebyshev's Inequality says $$
\frac1{2^n}\sum_{k=1}^n\binom{n}{k}\left[\left|k-\frac n2\right|\ge x\right]\le\frac n{4x^2}\tag2
$$ Setting $x=n^{7/8}$ in $(2)$ gives $$
\frac1{2^n}\sum_{k=1}^n\binom{n}{k}\left[\left|k-\frac n2\right|\ge n^{7/8}\right]\le\frac1{4n^{3/4}}\tag3
$$ which means $$
\frac1{2^n}\sum_{k=1}^n\binom{n}{k}\left[\left|k-\frac n2\right|\lt n^{7/8}\right]\ge1-\frac1{4n^{3/4}}\tag4
$$ Note that when $\left|k-\frac n2\right|\le n^{7/8}$ , $$
\frac1{\sqrt{n/2+n^{7/8}}}\le\frac1{\sqrt{k}}\le\frac1{\sqrt{n/2-n^{7/8}}}\tag5
$$ and the width of this interval is $$
\begin{align}
\frac1{\sqrt{n/2-n^{7/8}}}-\frac1{\sqrt{n/2+n^{7/8}}}
&=\frac{\sqrt{n/2+n^{7/8}}-\sqrt{n/2-n^{7/8}}}{\sqrt{n^2/4-n^{7/4}}}\\
&=\frac{2n^{7/8}}{\sqrt{n^2/4-n^{7/4}}\left(\sqrt{n/2+n^{7/8}}+\sqrt{n/2-n^{7/8}}\right)}\\[6pt]
&=O\!\left(n^{-5/8}\right)\tag6
\end{align}
$$ Thus, when $\left|k-\frac n2\right|\le n^{7/8}$ , $$
\frac1{\sqrt{k}}=\sqrt{\frac2n}+O\!\left(n^{-5/8}\right)\tag7
$$ In any case, $\frac1{\sqrt{k}}\le1$ . Therefore, $$
\begin{align}
\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k}
&=\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k}\left[\left|k-\frac n2\right|\le x\right]\\
&+\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k}\left[\left|k-\frac n2\right|\ge x\right]\\
&=\left(\sqrt{\frac2n}+O\!\left(n^{-5/8}\right)\right)\left(1+O\!\left(n^{-3/4}\right)\right)\\[6pt]
&+O(1)\,O\!\left(n^{-3/4}\right)\\[6pt]
&=\sqrt{\frac2n}+O\!\left(n^{-5/8}\right)\tag8
\end{align}
$$ Question Using the approach above, it is hard to see how to get more terms of an asymptotic expansion. Chebyshev is not very precise and that might be a limitation. The Binomial distribution approaches a Normal distribution quite well and that might offer a better approach. Is there an approach that allows more terms of an asymptotic expansion to be determined?","['asymptotics', 'binomial-distribution', 'probability']"
3246756,Matrix differentiation involving exponential term,"Let the scalar field $\Phi : \mathbb{R}^{m \times r} \times \mathbb{R}^{r \times n} \to \mathbb{R}$ be defined by $$\Phi(X,Y) := \sum_{i=1}^m \sum_{j=1}^n \exp \left( - \left( \frac{XY-A}{\gamma} \right)_{ij}^2 \right) $$ where $A\in \mathbb{R}^{m\times n}$ and $\gamma \in \mathbb{R}$ are given. I would like to compute the gradients $\nabla_X \Phi$ and $\nabla_Y \Phi$ . Could anyone please help me with the above differentiation please? I would appreciate a lot.","['matrices', 'scalar-fields', 'matrix-calculus', 'derivatives']"
3246796,Question about motivation for upgrading varieties to schemes (nilpotency),"In the Wikipedia article on schemes where we give a motivation of nilpotence for transitioning from varieties to schemes, it says that the ring of regular functions (i.e. coordinate ring) of the closed subscheme of $\mathbb{A}^1_{\mathbb{C}}$ defined by $x^2=0$ (as a variety just $V(x^2)=\{0\}$ ) is $\mathbb{C}[x]/(x^2)$ . But if I were to use Hilbert's Nullstellensatz, I'd get $$ I(V(x^2)) = \sqrt{(x^2)} = (x) \implies \mathcal{O}_{V(x^2)}(V(x^2)) \cong \mathbb{C}[V(x^2)] = \mathbb{C}[x]/I(V(x^2))=\mathbb{C}[x]/(x) \cong \mathbb{C} $$ where $\mathbb{C}[V(x^2)]$ is the coordinate ring of our variety. On the other hand, if we start by defining the scheme rather than the variety, which I think would be defined by writing $R= \mathbb{C}[x]/(x^2)$ and then saying that the scheme is $\text{Spec}(R)$ , then the ring of regular functions (coordinate ring from previous paragraph) will be $$ \mathbb{C}[\text{Spec}(R)] = \mathcal{O}_{\text{Spec}(R)}(\text{Spec}(R)) \cong R \ncong \mathbb{C}. $$ My question is: is the moral of the story here that $(\text{Spec}(R), \mathcal{O}_{\text{Spec}(R)})$ as a pair remembers more information (e.g. about nilpotency) than the pair $(V(I), \mathcal{O}_{V(I)})$ ? I'm a bit confused because I've given my variety a structure sheaf, and a scheme is roughly a space with a structure sheaf, but on the other hand I'm describing my ""space"" algebraically via prime ideals (taking Spec) along with a structure sheaf on that, and this seems to remember more information. Is it the fact that before you even look at the structure sheaf of the variety, it has already forgotten all of the nilpotency information, i.e. $$ \{0\} =  V(x) = V(x^2) = V(x^3) = \cdots $$ so when you take the structure sheaves of $V(x^n)$ , they'll all be the same because the nilpotency information has already been forgotten? Thank you.","['affine-varieties', 'algebraic-geometry', 'schemes', 'sheaf-theory']"
3246801,The induced map of a finite ring homomorphism on $\text{Spec}$ has finite fibers,"Let $\phi:R\to S$ be a finite ring homomorphism, in the sense that $S$ is a finitely generated module over $R$ . Then $\phi^*:\text{Spec }S\to\text{Spec }R$ has finite fibers. I have not found a proof anywhere of this relatively simple fact, and to me, it's not completely obvious. Let $\phi$ be as above. Consider any prime $\mathfrak p\in\text{Spec }R$ and primes $\mathfrak q_i\in\text{Spec }S$ mapped to $\mathfrak p$ under $\phi^*$ , ie the points in the fiber, or rather $\mathfrak p=R\cap\mathfrak q_i$ . If $\mathfrak q_i\subset \mathfrak q_j$ , we automatically have $\mathfrak q_i=\mathfrak q_j$ , since this is the case for integral ring homomorphisms, and finite homormorphisms are integral. Hence, we can assume the $\mathfrak q_i$ are not subsets of each other. Passing to localisation by $\mathfrak p$ in each ring, we get an induced ring homomorphism $\phi_i:R _\mathfrak p\rightarrow S_{\mathfrak q_i}$ , which is finite since $\phi$ is finite. Further, taking the quotient by the maximal ideal, we get an induced morphism of fields $k(\mathfrak p)\hookrightarrow k(\mathfrak q_i)$ , which is a finite field extension again. I'm stuck here. If it were the case that there was a slightly larger finite field extension of $k(\mathfrak p)$ containing all the $k(\mathfrak q_i)$ , then I could imagine that this directly proves the theorem since there are only finitely many intermediate fields.","['algebraic-geometry', 'commutative-algebra']"
3246823,Number of binary words that can be formed,"How many binary words of length $n$ are there with exactly $m$ 01 blocks? I tried by finding number of ways to fill $n-2m$ gaps with $0$ and $1$ such that no $'01'$ block gets created again. But this method is not working and I am stuck in this problem. Please provide me an elegant solution of this problem. Edit: Hw Chu has given a wonderful solution and I really appreciate this solution. But I am now interested in the intuition behind his solution. Further, I request to provide a relatively easier solution to this problem.","['combinatorics-on-words', 'combinatorics', 'bit-strings']"
3246828,Asymptotic expansion of $u_{n + 1} = \frac12 \arctan(u_n)$,"(I'm aware of Asymptotic expansion of $v_n = 2^nu_n$ where $u_{n+1} = \dfrac{1}{2}\arctan(u_n)$ but it has no answers…) Let be $u_0 \in \mathbb{R}$ and the sequence $(u_n)_n$ defined by: $u_{n + 1} = \frac12 \arctan(u_n)$ . I define also: $v_n = 2^n u_n$ , so I can show that: $\lim (u_n)_n = 0$ (by studying $x \mapsto \frac12 \arctan(x)$ ), thus, I can show that $(v_n)_n$ is monotone and converges because it is bound. Now, I conclude: $u_n \sim \dfrac{l}{2^n}$ , I'd like to determine $l$ more precisely. Here is what I tried, I suspect $l$ to be something like $f(\pi)$ for some $f$ : push the asymptotic expansion of $\arctan$ to the 2nd order and reinject it ; use $\arctan(u_n) + \arctan(1/u_n) = \dfrac{\pi}{2}$ ; use series techniques to look for $\sum v_{n + 1} - v_n$ , maybe conclude using Cesaro summation","['asymptotics', 'real-analysis', 'sequences-and-series', 'limits', 'trigonometry']"
3246836,Hypothesis testing: Two-tailed tests and deciding $H_0$,"I'm kind of studying Hypothesis testing by myself and was looking for a clarification on the next topic:
In order to confirm my $H_1$ I basically need to reject $H_0$ .
What do I do in case I cas assume either way? Let's assume there's a packing maching in a factory and I need to decide whether it's well-calibrated so the packings have the average weight of: $\mu_x=80g$ and suppose I also have the S.D. $\sigma_x=2g$ . Given a certain $\alpha$ , let's suppose $\alpha = 0.4$ . since it's a two-tailed test I need to devide 0.2 worth of area in either side. My question is: Do I need to hypothesize my assumptions in such a way that the area of rejection is always on the edges of the Gaussian curve? Let us suppose: $$H_0: \mu_x=0.8$$ $$H_1: \mu_x\neq 0.8$$ Then the rejection area is necessarily on the edges. But since im not asked to assume anything about this machine I can assume in advance it's not calibrated and then: $$H_0: \mu_x\not=0.8$$ $$H_1: \mu_x= 0.8$$ And now I supposedly have a limited rejection area symetrically around $\mu_x$ . I tryed to look around for a thumb-rule. All of the examples I've seen used the first method I described but never justified it or explained why. Is it a thumb-rule that the rejection area has to be infinite, or under the circumstances of the problem the latter way can be equally fine? If there is just one right way I'd like to know.","['statistics', 'hypothesis-testing']"
3246874,What is the minimal possible size of an $n$-universal graph?,"Suppose $\Gamma(V, E)$ is a finite simple graph. Let’s call a finite simple graph $\Gamma’(V’, E’)$ an induced subgraph of $\Gamma$ iff $V’ \subset V$ and $E’ = (V’ \times V’) \cap E$ . Let’s call a finite simple graph $\Gamma$ $n$ -universal, iff any finite simple graph on $n$ vertices is isomorphic to some induced subgraph of $\Gamma$ . What is the minimal possible number of vertices in an $n$ -universal graph? I managed only to find a lower bound for that size: $2n - 1$ , as it contains $n$ -vertex induced full and empty subgraphs, that can not have more than one common vertex. However, no upper  bound other than the trivial $n2^{\frac{n(n-1)}{2}}$ is currently known to me.","['graph-theory', 'optimization', 'combinatorics', 'discrete-mathematics']"
3246933,Find all triples for which $\frac{1}{a}+\frac{1}{b}+\frac{1}{c}=1$ using the pigeon hole principle.,"Let $a,b,c\in\mathbb{N}$ and $a<b<c$ . Please find all the triples for which: $$\frac{1}{a}+\frac{1}{b}+\frac{1}{c}=1,$$ using the pigeon hole principle. Lemma 1: $a=2$ Proof: Suppose $a=1$ , because $\frac{1}{n}>0, \forall n \in \mathbb{N}$ , its clear that $\frac{1}{a}+\frac{1}{b}+\frac{1}{c}>1.$ , therefore $a\neq1$ . Suppose $2<a$ , if we look at the reciprocal then $\frac{1}{2}>\frac{1}{a}$ and we can add $b,c$ into the mix like so: \begin{align}
\frac{1}{2}+&\frac{1}{b}+\frac{1}{c}>\frac{1}{a}+\frac{1}{b}+\frac{1}{c}=1\\
\Rightarrow \frac{1}{2}+&\frac{1}{b}+\frac{1}{c}>1\\
\Rightarrow &\frac{1}{b}+\frac{1}{c}>\frac{1}{2}.
\end{align} From the inequalities above, $2<a$ we can say $2<3\leq a$ , which tells us $a< 4\leq b$ , and $b < 5 \leq c$ . We can conclude from this that $4\leq b$ and $5\leq c$ which says: \begin{align}
 \frac{1}{4}+\frac{1}{5}\geq \frac{1}{b}+\frac{1}{c} &>\frac{1}{2}\\
\Rightarrow \frac{9}{20}&>\frac{1}{2}.
\end{align} Which is a contradiction. qed Conclusion So I know the only solution to this is $(a,b,c)=(2,3,6)$ , but this came from a book on the pigeon hole principle and I just cant see how. I also know I can make a brute force solution show that anything else leads to a contradiction. With $a=2$ we can change the problem to: $$
 \frac{1}{b}+\frac{1}{c} = \frac{1}{2}.
$$ Where $b<c$ , show that there is one solution using the pigeon hole principle. Thanks","['pigeonhole-principle', 'combinatorics']"
3246940,Intuitive Interpretation of Filtration,"I am interested in getting a firmer grip on filtrations in the context of Stochastic processes, and specifically the adaptation (is this the correct tense) of random variables to their (natural) filtration. Consider a discrete time Stochastic Process $\{X_n\}_{n \in \mathbb{N}}$ , and the natural filtration, $\mathscr{F}_n = \sigma (X_1, \cdots , X_n)$ , where $\sigma$ here is a stand-in for the term ""sigma-algebra generated by"".   We say then that $X_n$ is $\mathscr{F}_n$ adapted, if we have that $X_n$ is $\mathscr{F}_n$ is for every $n \in \mathbb{N}$ . Now, I know that if $X_n $ is $\mathscr{F}_n$ adapted, this is the same as saying: $$
X_n = f(X_1, \cdots , X_n)
$$ where $f$ is a Borel-measurable, deterministic function. This follows from the approximation of a $\mathbb{F}$ measurable function by simple  functions, for any $\sigma$ -algebra $\mathscr{F}$ . This however, doesn't really seem to make much sense to me as a statement. It seems to be the case that any random variable $X$ is always $\sigma (X)$ measurable (by definition of $\sigma(X)$ ), and moreover $\sigma(X_n) \subset \sigma(X_1, \cdots , X_n)$ . So I decided to look up processes with the property that each $X_n$ is $\mathscr{F}_{n-1}$ measurable, and these are called predictable, and with good, reason: $X_n$ is a deterministic function of $X_{1}, \cdots X_{n-1}$ . This is however not what the natural filtration seems to want to capture. I have seen an interpretation for the natural filtration for the process being that the process cannot look forward into the future. How does this definition encapsulate that, and why is the condition not just a triviality?",['probability-theory']
3246969,Prove that a function is indefinitely differentiable,"Show that if $$f: \mathbb{R} \to \mathbb{R}$$ is differentiable in second order which satisfies the equation $$f'' =f'+f$$ then $f$ is indefinitely differentiable. I was thinking to write the $n$ the derivative as $$f^{(n)}=a_nf+b_nf',  a_n=b_{n-1}, b_n=a_{n-1}+b_{n-1} $$ I calculated a few derivatives so I think this must be the form of the sequence, but I don't know how to solve it and I cannot see any other pattern to write the general term.","['recurrence-relations', 'calculus', 'functions', 'sequences-and-series', 'derivatives']"
3247016,Generalized Measure of Central Tendency,"I was wondering if there is some general notion of central tendency. I had in mind the following axiomatization: A measure of central tendency on a totally ordered set $X$ is a family of functions $\mu_n : X^n \to X$ such that If $a_i \geq b_i$ for all $i \in \{1, \ldots, n\}$ , then $\mu_n(a_1, \ldots, a_n) \geq \mu_n(b_1, \ldots, b_n)$ . If $a_{n+1} \geq \mu_n(a_1, \ldots, a_n)$ , then $\mu_{n + 1} (a_1, \ldots, a_{n + 1}) \geq \mu_n (a_1, \ldots, a_n)$ . The same statement holds with $\geq$ replaced by $\leq$ or $=$ . $\min(a_1, \ldots, a_n) \leq \mu_n(a_1, \ldots, a_n) \leq \max(a_1, \ldots, a_n)$ If $\sigma \in S_n$ , then $\mu_n(a_1, \ldots, a_n) = \mu_n(a_{\sigma(1)}, \ldots, a_{\sigma(n)})$ (the $\mu_n$ are symmetric). It seems like everything we call a measure of central tendency satisfies these axioms. For example, the arithmetic, geometric, and harmonic means; median; and mode (when it is unique) all satisfy these axioms. Based on this, these axioms seem general enough, but are they too general? Do they allow functions which we wouldn't call measures of central tendency? I'm not that invested in the axiomatization I've layed out above. I'm mostly interested in whether or not this sort of thing has been written about. How have others attempted to generalize the notion of ""central tendency?""","['average', 'statistics', 'reference-request']"
3247091,Is the Grassmannian a unique algebraic variety?,"I'm fairly new to algebraic geometry, so this is may just be fairly simple question about when two varieties are ""the same"" variety. In this question , I noted that the Grassmannian can be expressed as an algebraic variety in (at least) two ways: Using the Plücker embedding , where the subspace spanned by any orthonormal $v_1, v_2, ..., v_n$ is given by $v_1 \wedge v_2 \wedge ... \wedge v_n$ Using the projective embedding , where a subspace is identified with the unique orthogonal projection matrix to that subspace Or as matrices, if the matrix $M = [v_1 | v_2 | ... | v_n]$ , where the $v_i$ are column vectors, then The Plücker embedding can be identified with the $n$ 'th compound matrix $C_n(M)$ The projective embedding can be identified with the projection matrix $MM^\dagger$ , where $M^\dagger$ is the pseudoinverse These would appear to be two totally different algebraic varieties, defined by different sets of polynomial equations, embedded in two different Euclidean spaces, with two different metrics. Yet somehow, people often talk of the ""Grassmann variety"" as though there were a unique variety associated with the Grassmannian. So this leads to my question: Is there some sense in which these two varieties are ""the same"" variety? In general, what intrinsic properties can one use to determine if two varieties are ""the same variety,"" independent of their particular embedding into a Euclidean space?","['grassmannian', 'algebraic-geometry', 'projective-varieties']"
3247100,Exterior derivative of 1-form and derivatives of sections of $T^*M$,"Let $M$ be a compact manifold and consider a differential form $\alpha\in\Omega^1(M)$ , which we can think of as a map $\alpha:M\to T^*M$ . Since $T^*M$ is a smooth manifold we can compute the differential of this map $$D\alpha:TM\to T(T^*M)$$ How does this differential differ from the exterior derivative on 1-forms? I have a feeling that $D\alpha(X) = d(\alpha(X))$ , but I'm not sure how to show this.","['differential-forms', 'differential-geometry']"
3247193,Solution of a coupled gradient system?,"Suppose $U \times V \subset \mathbb R^n \times \mathbb R^n$ is an open set and $\phi, \psi: U \times V \to \mathbb R$ are two $C^{\infty}$ -smooth functions. Furthermore, for each $y \in V$ , $\phi_y: U \to \mathbb R$ has the property: all sublevel sets are compact, i.e., $$S_a = \{x \in U: \phi_y(x) = \phi(x, y) \le a\}$$ is compact for every $a \in \mathbb R$ . For $\psi$ , we have that for each $x$ , the function $\psi_x: V \to \mathbb R$ has compact sublevel sets. We define a system of ODEs as follows $$\begin{align*}
\dot{x}(t) = -\partial_x \phi(x, y), \\
\dot{y}(t) = -\partial_y \psi(x, y).
\end{align*}$$ Since the partial derivatives are smooth and thus locally Lipschitz, for any initial condition, there should be a local unique solution. My questions: Is it possible to infer the solutions are defined for all time? Is there a name (and reference) for such defined systems? It seems to resemble a gradient system however they are coupled together.","['gradient-flows', 'ordinary-differential-equations', 'reference-request', 'real-analysis', 'dynamical-systems']"
3247207,Finding $f(x)$ with $\frac{1}{2a}\int_{x-a}^{x+a}f(t)dt=f(x)$,"Problem Let $f(x)$ be a differentiable function with $f(0)=1$ and $f(1)=2$ . For any $a,x$ where $a \neq 0$ , it holds $$\frac{1}{2a}\int_{x-a}^{x+a}f(t)dt=f(x).$$ Find $f(x)$ . Attempt Since $$f(x)=\frac{\displaystyle\int_{x-a}^{x+a}f(t)dt}{2a}$$ holds for all $x \in \mathbb{R}$ and $a \neq 0$ . One can fix $x$ and take the limit as $a \to 0$ . Thus $$\lim_{a \to 0}f(x)=\lim_{a \to 0}\frac{\displaystyle\int_{x-a}^{x+a}f(t)dt}{2a}=\frac{f(x+a)+f(x-a)}{2},$$ where we applied L'Hopital's rule. Thus $$f(x)=\frac{f(x+a)+f(x-a)}{2}.$$ How to go on from here?","['integration', 'calculus', 'definite-integrals']"
3247209,How can I find the relationship between two sides of a rectangle?,Kabir divides a rectangle ABCD into eight non-overlapping squares as shown below. Find the ratio of AB to AD . I started with the inner most square and called that side $a_1$ . Then the sides of the second biggest square I called $a_2$ . Then $a_1+a_2=a_3$ $a_1+a_3=a_4$ $a_1+a_4=a+5$ What can I do now?,"['algebra-precalculus', 'geometry']"
3247241,Graphing rational functions (and asymptotes),"I have a function whose graph is plotted below First, I want to find one possible definition for the function. I know I have vertical asymptotes at $x \in \{-500, 500, 1500\}$ so $(x+500)(x-500)(x-1500)$ is in my denominator. This is of degree three. I know that the horizontal asymptote has to be the same degree as the denominator since it is a straight line above the $x$ axis but I don't know what number it actually is. Is there a way for me to approximate aside from looking at the graph? Picking an arbitrary number $20$ , so far I have $$f(x)  = \frac{20x^3}{(x+500)(x-500)(x-1500)}$$ How do I know how many times the graph crosses the horizontal asymptote?","['algebra-precalculus', 'graphing-functions', 'rational-functions']"
3247329,Infinite Series $\sum_{n=1}^\infty\frac{H_n}{n^5 2^n}$,"Given the n th harmonic number $ H_n = \sum_{j=1}^{n} \frac{1}{j}$ , we get from this post that apparently, $$\sum_{n=1}^{\infty}\frac{H_n}{n^k}z^n= S_{k-1,2}(z) + \rm{Li}_{\,k+1}(z)$$ for $-1\leq z\leq 1$ , and with Nielsen generalized polylogarithm $S_{n,p}(z)$ and polylogarithm $\rm{Li}_n(z)$ . Hence for small $k$ , $$\sum_{n=1}^{\infty}\frac{H_n}{n^2\, 2^n}= S_{1,2}\big(\tfrac12\big)+\rm{Li}_3\big(\tfrac12\big)$$ $$\sum_{n=1}^{\infty}\frac{H_n}{n^3\, 2^n}= S_{2,2}\big(\tfrac12\big)+\rm{Li}_4\big(\tfrac12\big)$$ $$\sum_{n=1}^{\infty}\frac{H_n}{n^4\, 2^n}= S_{3,2}\big(\tfrac12\big)+\rm{Li}_5\big(\tfrac12\big)$$ and so on. Explicitly, given $a=\ln 2$ , $$S_{1,2}\big(\tfrac12\big) +\tfrac1{6}a^3-\tfrac18 \zeta(3)=0 $$ $$S_{2,2}\big(\tfrac12\big) +\tfrac1{168}a^4+\tfrac17a^2\,\rm{Li}_2\big(\tfrac12\big)+\tfrac17a\,\rm{Li}_3\big(\tfrac12\big)-\tfrac18\zeta(4) = 0$$ which are discussed in this and this post. And by yours truly, $$S_{3,2}\big(\tfrac12\big) -A+B  = 0$$ $$A = \tfrac{41}{840}a^5+\tfrac5{21}a^3\,\rm{Li}_2\big(\tfrac12\big)+\tfrac47a^2\,\rm{Li}_3\big(\tfrac12\big)+a\,\rm{Li}_4\big(\tfrac12\big) + \rm{Li}_5\big(\tfrac12\big) $$ $$B=\tfrac12\zeta(2)\zeta(3)+\tfrac18a\,\zeta(4)-\tfrac1{32}\zeta(5)$$ Q: What, however, is the explicit evaluation in ordinary polylogs of the next steps, namely $S_{4,2}\big(\tfrac12\big)$ and $S_{5,2}\big(\tfrac12\big)$ ? P.S. Try as I might, they resist being evaluated and there are indications these higher order integrals may not be expressible by ordinary polylogs.","['real-analysis', 'harmonic-numbers', 'closed-form', 'sequences-and-series', 'zeta-functions']"
3247341,Evaluate $\int_0^{\infty} \frac {\ln(1+x^3)}{1+x^2}dx$,"Prove that $$\int_0^{\infty} \frac {\ln(1+x^3)}{1+x^2}dx=\frac {\pi \ln 2}{4}-\frac {G}{3}+\frac {2\pi}{3}\ln(2+\sqrt 3)$$ Where $G$ is the Catalan's constant. Actually I proved this using the Feynman's trick namely by introducing the parameter $a$ such that $$\xi(a)=\int_0^{\infty} \frac {\ln(1+ax^3)}{1+x^2}dx$$ Where it is clear that $\xi(0)=0$ , hence we just need $$\int_0^1 \xi'(a)da$$ which I found too. Hence proving the statement, but this method was too much lengthy because it involved heavy partial fraction decomposition and one infinite summation. Can someone suggest some better method? Edit: I also tried some trigonometry bashing by using the substitution $x=\tan \theta$ but got stuck midway","['integration', 'calculus', 'definite-integrals']"
3247351,"Find $a,b,c,d$ such that $2^a + 2^b + 2^c = 4^d$","Let $a,b,c,d$ be whole numbers that satisfy $$2^a + 2^b + 2^c = 4^d$$ What values of $(a,b,c,d)$ would make this equation true? Here is my work so far. Without loss of generality, assume $a\ge b\ge c$ . Then one trivial solution by inspection is $(1,0,0,1)$ . Playing around, I also found a solution at $(3,2,2,2)$ . Then I checked $a=5,b=4,c=4$ and found that it also worked. It seems that there is a family of solutions at $(2n-1,2n-2,2n-2,n)$ . I can prove this easily: \begin{align}
LHS&=2^{2n-1}+2^{2n-2}+2^{2n-2}\\
&=2^{2n-1}+2^{2n-1}\\
&=2^{2n}\\
&=4^n\\
&=RHS
\end{align} Is this the only solution? If it is, how do I go about proving it?","['elementary-number-theory', 'algebra-precalculus', 'problem-solving']"
3247388,Toeplitz matrices question with Fourier coefficients,"Denote: $f(e^{i\theta})$ is continuous and strictly positive on the interval $ 0 \le \theta \le 2\pi$ with Fourier coefficients $$ t_j = \frac{1}{2\pi}\int_0^{2\pi}f(e^{i\theta})e^{-ij\theta} \quad T_k(f) = \begin{bmatrix}
    t_0 & t_{-1} & \cdots &t_{-k} \\
    t_1 & t_0 & \cdots & t_{1-k}\\
    \vdots & \ddots & \ddots & \vdots \\
    t_k & \cdots & t_1 & t_0
    \end{bmatrix}$$ for $k = 0,1, ..$ The matrix $T_k(f)$ is constant on diagonals; such matrices are called Toeplitz matrices . I've already shown that for $b=\begin{bmatrix}b_0&\cdots&b_n\end{bmatrix}^T$ we have $$\frac{1}{2\pi}\int_0^{2\pi}\left|\sum_{j=0}^nb_je^{ij\theta}\right|^2f(e^{i\theta})d\theta = b^HT_nb\,.$$ And also have shown that if $T_n\succ0$ and $v^H=\begin{bmatrix}t_1&\cdots & t_n\end{bmatrix}$ , then $$T_n=\begin{bmatrix}1&v^HT_{n-1}^{-1}\\0&1\end{bmatrix}
      \begin{bmatrix}\rho_n & 0^H\\0&T_{n-1}\end{bmatrix}
      \begin{bmatrix}1&0^H\\ T^{-1}_{n-1}v & I_{n}\end{bmatrix} \,.$$ Where $\rho_n^{-1} = (T_n^{-1})_{00}$ . [ Note : This is a special case of a connection between the blocks of a matrix and the blocks of its inverse that may be obtained by Schur complements. Where (Need to prove) $$\min\left\{ \frac{1}{2\pi}\int_0^{2\pi} \left|1-\sum_{j=1}^nc_je^{ij\theta}\right|^2f(e^{i\theta})d\theta: c_1,\ldots,c_n\in\mathbb{C}
\right\} = \rho_n \,.\tag{*}$$ Question: I'm struggling to show $(*)$ .","['toeplitz-matrices', 'linear-algebra', 'fourier-analysis']"
3247394,Determine the convergence/divergence of $\sum\limits_{n=1}^{\infty}\left(\sqrt{n+2}-2\sqrt{n+1}+\sqrt{n}\right)$ by comparison test,"It's simple to evaluate the sum as follows \begin{align*}
\sum_{n=1}^{\infty}\left(\sqrt{n+2}-2\sqrt{n+1}+\sqrt{n}\right)&=\lim_{n \to \infty}\sum_{k=1}^{n}\left[\left(\sqrt{k+2}-\sqrt{k+1}\right)-\left(\sqrt{k+1}-\sqrt{k}\right)\right]\\
&=\lim_{n \to \infty}\left[\sum_{k=1}^{n}\left(\sqrt{k+2}-\sqrt{k+1}\right)-\sum_{k=1}^{n}\left(\sqrt{k+1}-\sqrt{k}\right)\right]\\
&=\lim_{n \to \infty}\left[\left(\sqrt{n+2}-\sqrt{2}\right)-\left(\sqrt{n+1}-1\right)\right]\\
&=\lim_{n \to \infty}\left(\frac{1}{\sqrt{n+1}+\sqrt{n+2}}+1-\sqrt{2}\right)\\
&=1-\sqrt{2}.
\end{align*} But how to determine the convergence directly by comparison and without evaluating ?",['sequences-and-series']
3247414,Find the limit as $x \to 0$ with integral from $0$ to $x$ of $\cos(t^3)/(t+x)$,Find the limit $$\lim_{x\to 0}\int_0^x \frac{\cos(t^3)}{t+x} dt$$ Can we use that $\frac{\cos(t^3)}{t+x}$ ~ $\frac{1}{t+x}$ at $0$ and take this integral to be $\ln(2x) - \ln(x)  = \ln 2$ ? The given answer is $\ln 2$,"['limits', 'calculus']"
3247481,What exactly is going on here? (Trigonometric functions),"The exercise below confuses me so much and we are going to have these on our exams. I always thought that the way to solve such a problem was by combining the two functions $f_1 + f_2$ and then solving for A, omega and phi by using trigonometric identities so that the sum of the two functions can be written on the standard form $f_2(t)=A*cos(ω*t+ω)$ . However, in this case that wouldn't make much sense either, since the function that needs to be changed to the standard form is called $f_2$ , and that function has already been given. If the exercise was about combining the two functions (summing the two functions), then we would have created a new function named for instance $f_3$ , which would have consisted of $f_1 + f_2$ . Could someone provide me with the name of the theory that they are using to obtain the solution below?","['trigonometry', 'harmonic-functions']"
3247503,Density of outputs of divisor function,"We define the function: $$\sigma_k{(n)}=\sum_{d \mid n} d^k$$ as the sum of divisors function of the $k$ th power, where $k \in \mathbb{N_0}$ , for $n \in \mathbb{N}$ . Now, we define: $$S_k=\{a \space | \space \exists \space m \in \mathbb{N} \space ; \sigma_k{(m)}=a\}$$ It is clear that $S_0$ is the same as $\mathbb{N}$ since for any $n \in \mathbb{N}$ , we have $\sigma_0{(2^{n-1})}=n$ . However, it is clear than this is not true for $S_k$ where $k>0$ . What is the density of $S_k$ in $\mathbb{N}$ for $k \in \mathbb{N}$ ? Edit : As pointed out by @ThomasAndrews in the comments below, $k>1$ has zero density by bounding. Now, the problem is solved if anybody is able to find the density of the sum of divisors function $\sigma(x)$ ( $1$ st power).","['number-theory', 'divisor-sum']"
3247538,Sandwich rule and limits,"Let $f\colon A\subseteq \mathbb{R^n}$ $\rightarrow$ $\mathbb{R}^m$ and $h:A \subseteq \mathbb{R^n} \rightarrow \mathbb{R^{\geq0}}$ Assume $
> 0 \leq |f(x)| \leq h(x)$ for $x$ in a punctured ball of $a$ . Show that
  if $h(x) \rightarrow 0$ as $x \rightarrow a$ then $f(x)\rightarrow
  0$ as $x \rightarrow a$ . My Proof : Assume $h(x) \rightarrow 0$ as $x \rightarrow a$ . Let $\epsilon >0$ . So $\exists$ $\delta>0$ such that whenever we have $0 < |x-a| < \delta$ we have then $|h(x)| < \epsilon$ . Because $|f(x)|,h(x)\geq 0$ it follows that if I set $\delta'=\delta$ then whenever $0<|x-a|<\delta'$ we have $||f(x)||=|f(x)| <\epsilon$ . Is this proof correct? I would very much like feedback.","['proof-verification', 'proof-writing', 'real-analysis', 'multivariable-calculus', 'limits']"
3247543,"Compact operators on $L_1[0,1]$","Let $(T_Kx)(t)=\int_0^1 K(t, s)x(s)ds$ be linear operator on $L_1[0,1]$ . Here $K(t, s)$ is measurable function on $[0,1]\times[0,1]$ with $\sup\{\int_0^1|K(t,s)|dt ,s\in[0,1]\}<\infty$ . Prove that $T_K:L_1[0,1]\to L_1[0,1]$ is compact. My thoughts: It is easy to show that $T$ is bounded. Next I want to show that $T$ is compact, i.e. for any bounded set $M\subset L_1[0,1]$ the image $T(M)$ is precompact. We have a criterion for precompactness in $L_1[0,1]:$ $A\subset L_1[0,1]$ is precompact $\Leftrightarrow$ $A$ is bounded and for any $\varepsilon>0$ there is $\delta>0$ such that for any $h\in[0,\delta]$ and $x\in A$ we have $\int_0^1|x(t+h)-x(t)|dt<\varepsilon$ , where $x(t+h)=0$ when $t+h\notin[0,1]$ . I want to check whether it is true for $T(M)$ , where $M$ is a bounded set. We want \begin{align}
\int^1_0|(Tx)(t+h)-(Tx)(t)|dt&=\int^1_0\Bigl|\int_0^1 \Bigl(K(t+h,s)-K(t,s)\Bigr)x(s)ds\Bigr|dt\\
&\leq \int^1_0\int_0^1 \Bigl|K(t+h,s)-K(t,s)\Bigr||x(s)|dsdt
\end{align} to be small for all $x\in M$ and small $h$ . To show that it is small I try to approximate $K(t, s)$ with continuous function. Using Luzin's theorem we can find continuous on $[0,1]\times[0,1]$ functions $g(t,s)$ so that $K(t,s)$ and $g(t, s)$ are not equal only on set of arbitrarily small measure. We have \begin{align}
\int^1_0\int_0^1 \Bigl|K(t+h,s)-K(t,s)\Bigr||x(s)|dsdt&=\iint_A \Bigl|K(t+h,s)-K(t,s)\Bigr||x(s)|dsdt \,+\\
&\quad \iint_B \Bigl|g(t+h,s)-g(t,s)\Bigr||x(s)|dsdt=:I_1+I_2
\end{align} where $B=\{(t,s)\in [0, 1]\times [0,1]: g(t+h,s)=K(t+h,s), g(t,s)=K(t,s)\}$ , $A=[0,1]\times[0,1]-B$ . If $g(t,s)$ is fixed, second integral $I_2$ will be small for small $h$ due to uniform continuity of $g(t,s)$ and estimate can be made independent of $x$ . My problems began when I tried to estimate first integral $I_1$ . Due to absolute continuity of Lebesgue's integral, $I_1$ is small when measure of $A$ is small, but this estimate depends on $x$ . How can the problem be solved?","['lp-spaces', 'compact-operators', 'functional-analysis']"
3247602,"Mathematical language : how to explain the difference between ""$x$ as an unknown"" and ""$x$ as a variable""? Unknown versus variable? [duplicate]","This question already has answers here : Subtleties of ""unknown"" vs. ""variable"" (4 answers) Closed 1 year ago . How to explain precisely the distinction between ""using the letter $x$ as an unknown"" and ""using the letter $x$ as a variable""? Is it a syntactic difference? a semantic one? is the difference pragmatic in nature ( relative to the intentions of the person that uses the symbol : relative to ""I want to find the value of $x$ "")? Can I explain it in the following way : $x$ is an unknown iff $x$ appears in a conditional equation $x$ is a variable otherwise ( identity, defining formula of a function, etc?) In a book ( Mathématiques de A à Z , Georges Alain , 1999) I read : "" A variable is a number to which one can attribute any value one wants. An unknown is a number the possible values of which we are looking for. The oppositite of "" variable"" is "" constant"" , the opposite of "" unknown"" is "" given""). In case this distinction would be outdated or out of use, what was the traditional explanation of this distinction?","['algebra-precalculus', 'definition', 'terminology']"
3247609,Understanding of the definition of a Riemannian metric,"I have have an exercise where it says: Let $M=\{x \in \mathbb{R}^2 \vert x_2>0\}$ with metric $g=\dfrac{1}{x_2^2}((dx_1)^2+(dx_2)^2)$ . Now I have trouble understanding how this metric works, let for example $a,b$ be tangent vectors in $M$ . Then what is $g(a,b)$ ?","['curves', 'tangent-bundle', 'riemannian-geometry', 'differential-geometry']"
3247633,Probability of $y \leq x$ given $x \leq \frac 12$,"Please help me understand solve this problem. Let the sample space be the unit square, $\Omega =[0,1]^2$ , and let the probability of a set be the area of the set. Let $A$ be the set of points $(x,y) \in [0,1]^2$ for which $y \leq x$ . Let $B$ be the set of points for which $x \leq \frac 12$ . Find $\mathbf P(A∣B)$ . Is the region of $\mathbf P(A∣B)$ not the dark shaded triangle region in the following image? If so, isn't the area $\frac 12$ base height. In which case, I get $\frac 12 \cdot (\frac 12 \cdot \frac 12) = \frac 18$ . But my answer is wrong. How do I work this problem out? Thank you.","['conditional-probability', 'probability-theory', 'probability']"
3247651,Deducing that $R^kf_*(F \otimes L^{\otimes n})=0$ for large enough $n$ from a statement about sheaf cohomology,"$\newcommand{\spec}{\mathrm{Spec}} \newcommand{\ra}{\rightarrow} \newcommand{\oh}{\mathcal{O}} \newcommand{\P}{\mathbb{P}}$ Let $f : X \ra \spec(A)$ be a projective morphism (Hartshorne's definition) with $A$ a noetherian ring and let $F \in \mathsf{Coh}(X)$ . Let $L$ be an ample line bundle. Then there is $n_0 \geq 0$ such that $R^kf_*(F \otimes L^{\otimes n})=0$ for all $n \geq n_0$ and $k>0$ . In my class notes we have proved this by showing that $F(n) = F \otimes \oh(n)$ has no cohomology in positive degrees for $n$ sufficiently large, i.e. that $H^k(X, F(n))=0$ for $k>0$ and $n$ sufficiently large (this is where the proof in the class notes stops). This is what Hartshorne proves in p. 228 of his book, but the original claim (Theorem 5.2, p. 228) is that $H^k(X, F(n))=0$ rather than the statement about higher pushforwards $$R^kf_*(F \otimes L^{\otimes n})=0.$$ I'd like to know how $R^kf_*(F \otimes L^{\otimes n})=0$ follows from the vanishing cohomology result. I've tried writing $R^kf_*(F \otimes L^{\otimes n}) = H^k(f_*(I^\bullet))$ where $I^\bullet$ is an injective resolution of $F \otimes L^{\otimes n}$ , but I don't see how to relate the higher pushforward to the higher global sections functor which is what sheaf cohomology is)? Thank you. Edit: I've just realised that my question is perhaps related to a question I asked a few days ago which says that under certain assumptions $R^pf_*\mathcal{F} \cong \widetilde{H^p(X, \mathcal{F})}$ ; one of those assumptions is that $X$ is noetherian. I think this is OK - am I correct in saying that $\P^r_A$ is noetherian? It has a standard cover by affines $\mathbb{A}^m$ , and each of those are noetherian because their associated rings are polynomial rings which are noetherian. With this all being said, it seems that this is why/how we can make a connection between pushforwards and global sections/sheaf cohomology (I think maybe we should also note that the tilde functor $\widetilde{-}$ is exact), though the proof of $R^pf_*\mathcal{F} \cong \widetilde{H^p(X, \mathcal{F})}$ in my other question is rather technical, so I'm wondering if there is a simpler way to answer my original question? To summarise my edit, is the way I've outlined above using my other question from a few days ago a valid way of answering my original question in this post? If it is valid, is there a quicker/more obvious way of answering my original question? Thanks again.","['sheaf-cohomology', 'algebraic-geometry', 'sheaf-theory', 'schemes', 'projective-space']"
3247652,Why isn't $\arctan(\tan x)=x$?,I am in high school and my teacher happened to mention that $ \arctan(\tan x) $ isn't ALWAYS $x$ but that $\tan(\arctan x)$ is always $x$ . Why the difference between the two ?,"['trigonometry', 'inverse-function']"
3247700,Find $9$'th derivative of $\frac{x^3 e^{2x^2}}{(1-x^2)^2}$,"How can I find $9$ 'th derivative at $0$ of $\displaystyle \frac{x^3 e^{2x^2}}{(1-x^2)^2}$ . Is there any tricky way to do that?
This exercise comes from discrete mathematic's exam, so I think that tools like taylor  can't be used there.","['derivatives', 'discrete-mathematics']"
3247724,Integrating factor for $(x^2-y^2-y)dx-(x^2-y^2-x)dy=0$,"I am having trouble finding the integrating factor for turning the below differential equation into an exact one (Tenenbaum and Pollard, exercise 10, problem 6). Any hints and suggestions would extremely helpful and lead me to the solution. Solve the differential equation : $$ (x^2-y^2-y)dx - (x^2-y^2-x)dy=0$$ My attempt: The coefficients of $dx$ and $dy$ are not homogenous functions. Further, $
\begin{align}
P(x,y) &= x^2 - y^2 - y \\
\frac{\partial P(x,y)}{\partial y}&=-2y-1 \\
Q(x,y) &= -(x^2-y^2-x)\\
\frac{\partial Q(x,y)}{\partial x}&=-(2x-1) \\
\therefore \frac{\partial P}{\partial y} \neq \frac{\partial Q}{\partial x}
\end{align}
$ The given differential equation is not exact. We have : $\begin{align}
& \frac{\partial P}{\partial y} - \frac{\partial Q}{\partial x} \\
=& -2y-1+(2x-1)\\
=&(2x-2y-2)
\end{align}$ . Moreover, $\begin{align}
& yQ-xP\\
= & -y(x^2-y^2-x)-x(x^2-y^2-y)\\
= & -x^2 y + y^3 + xy - x^3 + xy^2 + xy\\
= & y^3 - x^3 + xy - xy(x - y - 1)
\end{align}$ It doesn't look like $(\partial P / \partial y - \partial Q / \partial x)/(yQ-xP)$ will be a function of $u=xy$ alone. Also, $\begin{align}
& yQ+xP\\
= & -y(x^2-y^2-x)+x(x^2-y^2-y)\\
= & -x^2 y + y^3 + xy + x^3 - xy^2 - xy\\
= & y^3 + x^3 - x^2 y - x y^2 \\
= & (y + x)(y^2 + x^2 - xy) - xy(y + x) \\
= & (y + x)(y^2 + x^2 - 2xy)\\
= & (y + x)(y - x)^2
\end{align}$ It doesn't look like $y^2(\partial P / \partial y - \partial Q / \partial x)/(yQ+xP)$ will be a function of $u=x/y$ or $x^2(\partial P / \partial y - \partial Q / \partial x)/(yQ+xP)$ will be a function of $u=y/x$ alone.",['ordinary-differential-equations']
3247768,"If $\{x_n\}$ is an increasing sequence and $\lim_{n\to\infty}x_n=L$, then $L$ is an upper bound of $\{x_n\}$","I was wondering if somebody could critique my proof -- I feel I have the general idea but my solution lacks elegance. I appreciate your help! Proposition: An increasing sequence $\{x_n\}$ has a limit $L$ . Then $L$ is an upper bound for $\{x_n\}$ . Indirect Proof: Assume that $L$ is not an upper bound. Then for some value $n=N$ , we have: $$x_{N}>L.$$ Since $ x_n $ is increasing, we have: $$x_{n}> L\text{ for all }n \geq N.$$ However, because $L$ is the limit of $x_n$ , we also have, given $\epsilon>0$ ,: $$L-\epsilon<x_n<L+\epsilon,$$ for sufficiently large $n$ . Because the above equation must hold for all $\epsilon >0$ , I can select a value of $\epsilon$ such that: $$ 0<\epsilon<x_N-L.$$ It follows that: $$L+\epsilon<x_N.$$ And since $x_n$ is an increasing sequence, I can extend the above equation to: $$L+\epsilon<x_n$$ for sufficiently large $n$ . This contradicts our earlier definition of $L$ as the limit of $x_n$ , which required $x_n<L+\epsilon$ for sufficiently large $n$ . Therefore, our original assumption is false, and we conclude that $L$ is an upper bound.","['proof-verification', 'real-analysis']"
3247800,Closed form for $\int_0^t(x+c)^p(1-2x)^{N-1}\text{d}x$,"I am trying to find a closed form for the integral $$I\equiv\int_0^t(x+c)^p(1-2x)^{N-1}\text{d}x,$$ where $N\in\mathbb{N}$ , $p>0$ , $c\ge 0$ and $t\in\left(0,\frac{1}{2}\right)$ . I thought to evaluate the integral proceeding by parts, in order to lower the integer power of the second factor in the integrand. \begin{equation}\begin{split}
I&=\frac{1}{p+1}\left[(t+c)^{p+1}(1-2t)^{N-1}-c^{p+1}\right]+\\[5pt]
&\quad+\frac{2(N-1)}{p+1}\int_0^t(x+c)^{p+1}(1-2x)^{N-2}\text{d}x=\dots\end{split}
\end{equation} By iterating $N$ times the above step the starting integral can be rewritten as a sum \begin{equation}\tag{1}\label{eq1}
I=\Gamma(N)\Gamma(p+1)\sum_{j=1}^N\frac{2^{j-1}}{\Gamma(N-j+1)\Gamma(p+j+1)}\left[(t+c)^{p+j}(1-2t)^{N-j}-c^{p+j}\right].
\end{equation} I wonder whether this is the best result one can hope for, or if further simplifications can be performed, maybe by evaluating the sum in a closed form or by proceeding in a different way from the beginning in the solution of the integral. Edit: after the mention of hypergeometric functions in the comments, I managed to rewrite the above expression in their terms. To show this I will consider only the second term in the square brakets, but the procedure is the same for the first one. $$S_1\equiv\sum_{j=1}^N\frac{(2c)^j}{\Gamma(N-j+1)\Gamma(p+j+1)}=\left(\sum_{j=1}^{\infty}-\sum_{j=N+1}^{\infty}\right)\frac{(2c)^j}{\Gamma(N-j+1)\Gamma(p+j+1)}$$ With the substitutions $j\rightarrow j-1$ and $j\rightarrow j-(N+1)$ in the first and second sum respectively I got $$S_1=\sum_{j=0}^{\infty}\left[\frac{(2c)^{j+1}}{\Gamma(N-j)\Gamma(p+j+2)}-\frac{(2c)^{j+N+1}}{\Gamma(-j)\Gamma(p+j+N+2)}\right],$$ where the second fraction vanishes due to the fact that $1/\Gamma(-j)=0\;\;\forall j\in\mathbb{N}$ . Using now the relation $$\Gamma(\epsilon-n)=(-1)^{n-1}\frac{\Gamma(-\epsilon)\Gamma(1+\epsilon)}{\Gamma(n+1-\epsilon)}$$ with the identifications $\epsilon=N$ and $n=j$ , I found $$S_1=-\frac{2c}{\Gamma(-N)\Gamma(N+1)}\sum_{j=0}^{\infty}\frac{\Gamma(j+1-N)}{\Gamma(p+j+2)}(-2c)^j.$$ Thanks to the formula $\Gamma(z+1)=z\Gamma(z)$ I wrote $\Gamma(-N)\Gamma(N+1)=\Gamma(1-N)\Gamma(N)$ , and it is quite easy using the definition of the hypergeometric function ${}_2F_1(a,b;c;z)$ to verify that $$S_1=\frac{2c}{\Gamma(N)\Gamma(p+2)}{}_2F_1(1,1-N;p+2;-2c).$$ Exactly in the same way I found that $$\sum_{j=1}^N\frac{2^j}{\Gamma(N-j+1)\Gamma(p+j+1)}\left(\frac{t+c}{1-2t}\right)^j=\frac{2}{\Gamma(N)\Gamma(p+2)}\frac{t+c}{1-2t}{}_2F_1\left(1,1-N;p+2;-\frac{2(t+c)}{1-2t}\right).$$ Putting together these results the integral of interest becomes \begin{equation}\begin{split}
I&=\frac{1}{p+1}\left[(t+c)^{p+1}(1-2t)^{N-1}{}_2F_1\left(1,1-N;p+2;-\frac{2(t+c)}{1-2t}\right)\right.\\[5pt]
&\left.\quad-c^{p+1}{}_2F_1(1,1-N;p+2;-2c)\right].\end{split}
\end{equation}","['integration', 'summation', 'definite-integrals', 'closed-form', 'hypergeometric-function']"
3247833,Proving that ${n+3\choose 3} =\frac{n+2}{2}\sum_{k=1}^{n+1}\csc^2\frac{k\pi}{n+2}$,"Fancy physics predicts the equality $${n+3\choose 3} =\frac{n+2}{2}\;\sum_{k=1}^{n+1}\csc^2\frac{k\pi}{n+2}$$ which I can check (numerically and symbolically) for small $n$ , but cannot prove for every $n$ . Does someone see an elegant way of doing this? Expressing $\csc$ in terms of exponentials allows one to see this as a sum involving roots of unity, but  I don't see how to proceed.","['trigonometry', 'binomial-coefficients', 'combinatorics', 'summation']"
3247842,Expected consultant bill given distribution of time taken,"The cdf of the number of hours it takes a consultant to complete a project is given by $F(x)= \dfrac{x^2}{16}$ for o to 4. The consultant bills $300 per hour, rounded up to the nearest half hour, for the project. What is the expected amount of the total bill? (a)900 (b)800 (c)872 (d)950 (e)1100 My work: $f(x)= \dfrac{dF(x)}{dx}$ $f(x)=\dfrac{x}{8}$ so integral of $x^2/8$ from 0 to 4 = $x^3/24$ from 0 to 4 = 64/24 = 2.6667 round 2.6667 to nearest half hour is 2.5 so 2.5*300 = 800 But that's wrong; the answer to the question is 872. Can I please have help understanding why my method is incorrect, so I can try another method while understanding why my last attempt was incorrect.","['probability-distributions', 'probability']"
3247868,Tangent space and Jacobian,"I'm reading John Willards Topology with a differential view point and an confused about tangent spaces. To define the notion of derivative $df_x$ for a smooth map between smooth manifolds we introduce a tanget space at each point $x$ in the manifold $M$ . The tangent space is denoted $TM_x$ . If $M$ is an $m$ -dimensional manifold then $TM_x$ is the $m$ -dimensional hyperplane through the origin parallel to the hyperplane that that best approximates $M$ at $x$ . Similarly one things of the nonhomegeneous linear mapping from the tangent hyperplane at $x$ to the tangent hyperplane at $y$ which best approximates $f$ . My confusion lies the following sentence: Translating both hyperplanes to the origin, one obtains $df_x$ . Is this saying $df_x$ is a map between these two hyperplanes? If so, how should I think about this map what is getting mapped to what? Edit: All manifolds are in $R^n$ for some $n$ , but the two manifolds may not be of the same dimension.","['differential-topology', 'differential-geometry']"
3247885,From system of coupled ODEs to separable ODE,"How does one go from \begin{align}
\dot{x}&=y\\
\dot{y}&=-x^3
\end{align} to the following ODE? $$\frac{dy}{dx} = -\frac{x^3}{y}$$",['ordinary-differential-equations']
3247910,"Prove that $\int _0^4\:f_n(x)\,dx < 4^{n+1}$ where $f_n(x)= \left(4x-x^2\right)^n$","$ f_n(x) = \left(4x-x^2\right)^n$ I'm trying to prove that $\int _0^4\:f_n(x)\,dx < 4^{n+1}$ When I'm doing a general integral to $n > 1$ , I'm getting an expression that equals to zero when $X = 4$ or $X = 0$ . This is the expression: $$\frac{\left(4x-x^2\right)^{n+1}}{(4-2X)(n+1)} $$ What am I missing? Because it doesn't make sense that every integral with $n > 1$ is equal to zero","['integration', 'analysis', 'real-analysis']"
3247932,"How to define the ""nice"" contour of a ""nice"" two-dimensional differential surface","Suppose I have a smooth function $f(x,y)$ defined on $(0,\infty)\times(0,\infty)$ (for instance, you can assume that $f(x,y)$ is $C^1$ or even $C^2$ ). It is ""nice"", in the sense that there is a constant $c>0$ , and for all $x>0$ $$
f(x,0^+) = \lim_{y\rightarrow 0^+}f(x,y)\geq c, f(x,\infty) = \lim_{y\rightarrow \infty} f(x,y) = -\infty.
$$ Now I define a set $$
S = \{(x,y):f(x,y) < 0\}.
$$ Then we can see that for any $(x,y)\in \partial S$ , $f(x,y) = 0$ . Moreover, it seems that there is a ""nice"" subset $L$ of the boundary, such that the points on $L$ are on a parametrized curve $$
L = \{(\phi_1(t),\phi_2(t)):t\in (-T,\infty)\},
$$ and there is a finite $t_0$ , $$
\phi_1(t) \rightarrow 0,\ \phi_2(t) \rightarrow y_0>0, \ {\rm as}\ t\rightarrow t_0
$$ and $$
\phi_1(t)\rightarrow \infty,\ {\rm as}\ t\rightarrow +\infty.
$$ My question is, can we define such a subset $L$ of the boundary rigorously based on $f(x,y)$ itself? An example of $L$ is shown in the picture, where the shaded area is $S$ , and the red curve is the subset $L$ of boundary I wanted. My thoughts: It seems that we can ""pick"" the connected component $K$ which is connected to $\{(x,\infty):x\in (0,\infty)\}$ , and then we ""fill in"" the blank area in $K$ to make $K$ simple connected. Then $L$ can be defined as $\partial K$ . But I am not sure how to rigorously define two operations ""pick"" and ""fill in"", and how to rigorously show that $L$ can be parametrized in the way described above. Here ""rigorously"" means that in a way that is well accepted by the academic community of mathematicians.^_^ Thanks in advance for any help!","['general-topology', 'differential-topology', 'analysis', 'differential-geometry']"
3247935,Making a matrix positive definite,"Suppose $p \times p$ matrix $X$ is symmetric and not positive definite (PD). I want to find the minimum value for $\mu$ such that $X + \mu I_p$ is positive definite. To this end, I suppose we can solve a semidefinite program (SDP) of the form $$\begin{array}{ll} \text{minimize} & \mu\\ \text{subject to} & X + \mu I_p  \succeq 0\\ & \mu \geq 0\end{array}$$ where $A \succeq 0$ denotes that matrix $A$ is PD, and $I_p$ is the $p \times p$ identity matrix. Is there a more elegant approach to find $\mu$ using linear algebra? I am also curious if $\mu$ has any interpretation or not. Thanks for possible feedback!","['matrices', 'linear-algebra', 'symmetric-matrices', 'optimization', 'positive-definite']"
3247966,Definition of function by finite recursion,"I am reading the book ""Set Theory and the Continuum Problem"" by Raymond Smillyan and Melvin Fitting. On page 43 §8 he states the following: Let $c$ be an element of a class $A$ , and $g$ be a function from $A$ into $A$ . Does there necessarily exist a function $f$ from numbers
  to elements of $A$ such that $f(0)=c$ and for every $n, f(n^+)=g(f(n))$ (In othe words, f(0)=c,
  f(1)=g(c), f(2)=g(g(c)),...)? An obvious induction argument on $n$ shows that there cannot be more than one such function $f$ , but how do
  we know there is at least one? Unfortunately some articles and
  textbook have given the fallacious argument that $f$ is defined on $0$ (since $f(0)=c$ ) and if $f$ is defined on $n$ , then $f$ is also
  defined on $n^+$ (since $f(n^+)=g(f(n))$ ) hence by mathematical
  induction $f$ is defined on every natural number $n$ . The counter to
  that fallacious argument is: What function $f$ ? I do not understand why the above argument is false. What exactly is the problem? I dont understand the question ""What function $f$ ""? Its already defined by $f(0)=c$ and $f(n^+)=g(f(n))$ for every natural number. Instead the author suggest to create the function $f_n$ defined on the set of integers from $0 \dots n$ by $f_n(0)=c$ , and $f_n(i^+) = g(f_n(i))$ for any $i<n$ . Then, the author suggest to show that $f_n(k) = f_{n^+}(k)$ for any $k\leq n$ . He then defines the function $f$ to be the set of all ordered pairs $<n, f_n(n)>$ (from §9 - a function is a relation $R$ such that for any x there s at most one element y with $<x,y> \in R$ ). Can someone explain to me, why the author does not accept the first proof? And what is substantially different from the second proof?",['elementary-set-theory']
3247979,"How to prove that a ""nice"" unbounded ""open"" curve can divide the plane into two parts.","Jordan curve theorem is well-known, and it says that a simple closed curve can divide the plane into two parts: an inner part and an outer part. Now I am wondering that how to prove a similar result about unbounded ""open"" (i.e., not closed) curves. Suppose I have a parametrized curve $$
C(t) = (x(t),y(t)),\ t\in (-\infty,\infty).
$$ $C(t)$ does not intersect with itself, and is unbounded in both sides, or $$
\|C(t)\|\rightarrow \infty,\ {\rm either}\ t\rightarrow \infty \ {\rm or}t\rightarrow -\infty.
$$ Can we prove that $C(t)$ divides the plane into two parts: a left part and a right part? Here ""left"" and ""right"" are determined by the orientation of $C(t)$ (imagine we walk through $C(t)$ as $t$ increases). I think the conclusion is correct but somehow I cannot find any results on this. Unfortunately I don't have any idea on proving it, either. Many thanks to helpful suggestions!","['general-topology', 'differential-geometry']"
3248027,"Frequency of integers $x, x+2$ such that gcd$\left(x(x+2),p\right)=1$","Let: $p\ge 5$ be a prime. $p\#$ be the primorial of $p$ . $0 < x < p\#$ be an integer. gcd $(a,b)$ be the greatest common divisor of $a$ and $b$ . It is straight forward to show that there are $\prod\limits_{q \text{ is odd prime, }q \le p}(q-2)$ instances of $x$ where $x < p\#$ and gcd $\left(x(x+2),p\#\right)=1$ : Base Case: There are 3 such $x$ for $p=5$ which are $\{11, 17, 29\}$ Inductive Hypothesis: Assume it is true up to some prime $p \ge 5$ Inductive Case: Let $x_1, x_2, \dots x_n$ fulfill this hypothesis for $p$ so that each $x_i < p\#$ , gcd $\left(x_i(x_i+2),p\#\right)=1,$ and $n = \prod\limits_{q\text{ is odd prime, } q \le p}(q-2)$ Let $r$ the least prime greater than $p$ . Each $x_i, x_i + p\#, x_i + 2p\#, \dots, x_i + (r-1)p\#$ forms a complete residue system modulo $r$ . As such, for each $x_i$ , exactly $2$ are either congruent to $r$ or $r-2$ .  The remaining $r-2$ will have the property that gcd $\left(x_i + up\#)(x_i + up\#+2),r\#\right)=1$ where $0 \le u \le r-1$ . Thus, the number of $x$ that have the desired property relative $r$ is $\left(\prod\limits_{q\text{ is odd prime, }q\le p}(q-2)\right)(r-2) = \prod\limits_{q\text{ is odd prime, }q\le r}(q-2)$ Here is my question: Let $C_p$ be the count of $x$ such that: $0 <x < p\#$ gcd $\left(x(x+2),p\#\right)=1$ I am interested in seeing if there is a bound for counting the number of $x$ for each $u$ where: $0 \le u < C_p$ $u\left(\dfrac{p\#}{C_p}\right) < x \le (u+1)\left(\dfrac{p\#}{C_p}\right)$ When I look at $p \le 13$ , I am finding that this count is never greater than $2$ . Is it known if this always follows?  Will there ever be a prime $r$ such that the count of an interval defined as above for $r$ would have a count greater than $2$ ? I am suspecting that it is straight forward to prove that $2$ is the maximum count.  Am I wrong? Is there a counter example? Edit: Updated question to make it clear that $q > 2$ .","['number-theory', 'gcd-and-lcm', 'primorial', 'prime-numbers']"
3248031,"Given a ""composite"" norm, what polygon describes its unit ball?","When answering this question about finding the open unit ball $\mathscr{B} := \{ x \in \mathbb{R}^2: \| x \| < 1\}$ of the ""composite"" norm $$
\| \cdot \|:
\mathbb{R}^2 \to \mathbb{R}, \
(x,y) \mapsto a \| (x,y) \|_1 + \frac{b}{2} \| (x,y) \|_{\infty}.
$$ I thought of the following question.
In the above question one has $\Omega := \mathbb{R}^2$ , $a := \frac{1}{3}$ and $b := \frac{4}{3}$ but those aren't important for my question.
All that matters is $a,b > 0$ , as verified in this question . It turns out that $\mathscr{B}$ is a octagon (as intersection of two rotated squares, as they are the geometric interpretations of $\| \cdot \|_1$ and $\| \cdot \|_{\infty}$ (is that really true?), which can be seen in the diagram appended to my answer to the first mentioned question). My question is if (and how) one can find out which shape (polygon?) $\mathscr{B}$ corresponds for a composite norm of the form $$
\| \cdot \|
:= \sum_{k = 1}^{\infty} \alpha_k \| \cdot \|_{x_k}, \qquad \text{where }
\alpha_k \ge 0, x_k \in [1, \infty].
$$ As @CalvinKohr points out in the comments, we can normalize this representation: $\sum_{k} \alpha_k = 1$ such that the sum is well defined i.e. converges. This question seems to be related but I don't know how the Minkowski functional would relate to this problem even though it was briefly covered in my Functional Analysis course.
It remarks that a polygon with a odd number of vertices can not occur because of the symmetry of the norm.
As you can see in the last example below, other shapes than octagons are possible.
Can $\mathscr{B}$ be another polygon with an even number of vertices? Maybe this is related to the concept of polyhedral norms ? One special case Cosider the norm $\mathfrak{p}_n(x,y) := \sum_{k = 1}^{n} \| (x,y) \|_{k}$ .
If we graph it and intersect it with a plane $z = \ell$ for $\ell > 0$ we obtain the the shape of $\mathscr{B}$ .
I graphed $\mathfrak{p}_n$ for $n \in \{1, \ldots, 5\}$ and one observes that shapes of $\mathscr{B}$ are 4-gons that ""get more convex"" and converge to some circle. This suggests it might by only interesting to at norms whose $\mathscr{B}$ is a polygon i.e. $\mathscr{B}$ s with straight lines. Are those just produced by $\| \cdot \|_1$ and $\| \cdot \|_{\infty}$ ?.","['geometric-functional-analysis', 'normed-spaces', 'geometry', 'polygons', 'functional-analysis']"
3248069,Taking expectation with respect to a probability measure,"Let $f$ be a function and $\mu$ be a probability measure. I've frequently seen a notation like: $\mathbb E_\mu[f]$ . Does it mean that $$
\mathbb E_\mu[f]=\int_\mu f=\int f(x)d(\mu(x))?
$$ I've checked a various sources but only something like (elementary) expectation operator $\mathbb E[X]=\sum_i x_ip_i$ is defined.","['integration', 'expected-value', 'calculus', 'functions', 'random-variables']"
3248102,Maximum-likelihood estimator of set of data from Normal Distributions,"I have -before- found the MLE of the two parameters of a Normal Distribution but I don't have any idea about how to proceed in this case. Problem A sample of size $n$ is drawn from each of four normal populations, all of which have the same variance $\sigma^2$ . The means of the four populations are $a + b + c$ , $a + b - c$ , $a - b + c$ , and $a - b - c$ . What are the maximum-likelihood estimators
  of $a, b, c$ , and $\sigma^2$ ? (The sample observations may be denoted by $X_{ij}$ , $i = 1,
2, 3,4$ and $j = 1,2, ... , n$ .)","['statistical-inference', 'statistics', 'normal-distribution', 'maximum-likelihood']"
3248104,Integral Expression of Legendre Polynomials,"a) Verify that for $x > 1$ , $n \in \mathbb{N}$ the function $$P_n(x) = \frac{1}{\pi} \int_0 ^ \pi (x + \sqrt{x ^ 2- 1} \cos \phi) ^ n d \phi$$ is a polynomial of degree $n$ (the $n$ th Legendre polynomial). b) Show that $$P_n(x) = \frac{1}{\pi} \int_0 ^ \pi \frac{d\varphi}{(x - \sqrt{x ^ 2- 1}\cos \varphi) ^ n}.$$ I have solved the first part of the problem but I am stuck on the second part. I have tried making the substitution $r = \varphi - \pi$ in the second integral and using the oddity of $y = \cos x$ to bring the denominator to $(x + \sqrt{x ^ 2 - 1} \cos r) ^ n$ , but I have little idea how to proceed from there. Can sombody help? Thanks in advance!","['analysis', 'legendre-polynomials']"
3248127,Continued fractions question (visual),"In the figure below, the rectangle has dimensions a x b and is tiled by squares. This is the smallest possible rectangle that can be tiled by squares in this manner. a) write the continued fraction for $a/b$ b) find the value of $a+b$ Can someone please explain how i'd break this up?
For part a, I am thinking that $b=6x$ $x=4y$ So $b=24y$ Is this correct? I've never seen a question like this before. I don't know how to solve this, can someone please help? thanks","['continued-fractions', 'algebra-precalculus']"
3248163,Prove that there exists an open set $V$ with compact closure such that $K⊆V⊆\overline V⊆ U$,"Suppose that $U$ is open in a locally compact Hausdorff space $X$ and $K\subseteq U$ is a compact set. Then there exists an open set $V$ with compact closure such that $K\subseteq V\subseteq\overline V\subseteq U$ . Theorem 2.5 Suppose $X$ is a Hausdorff space, $K\subset X$ compact and $p\in K^c.$ Then there exists $U,V\in\tau$ such that $p\in U,K\subset V$ and $V\cap U=\varnothing$ Theorem 2.6 Let $\{K_\alpha\}$ be a collection of compact sets of a Hausdorff space. If $\displaystyle\bigcap_\alpha K_\alpha=\emptyset,$ then there exists $\alpha_1,\dots,\alpha_n$ such that $\displaystyle\bigcap_{k=1}^n K_{\alpha_k}=\emptyset.$ I am having confusions with the proof, in the first paragraph we have $K\subseteq\ U_x\subseteq\overline U_x,\forall x\in K$ , I think. But $K$ is compact, so $K\subseteq\bigcup_{i=1}^n U_{x_i}\subseteq\bigcup_{i=1}^n\overline U_{x_i}.$ This last set is compact. If $G=\bigcup_{i=1}^n U_{x_i},$ then $K$ lies in an open set with compact closure? How will I know that $\overline G=\overline{\bigcup_{i=1}^n U_{x_i}}$ is compact? I only know that $\bigcup_{i=1}^n\overline U_{x_i}$ is compact. 2nd qstn. where it says $K\subset W_p$ and $p\not\in\overline W_p$ is that because $K\subset W_p\subset\overline W_p$ and thus $p$ can't be in $\overline W_p$ ? 3rd qstn. This is a collection of compacts $\{C\cap\overline G\cap\overline W_p\}$ and is empty. All are compacts because $C$ and $\overline W_p$ are closed thus intersected with compact $\overline G$ will be compact, correct? And is also empty because, suppose it's not. Then we would get a contradiction with $p\in C$ and $p\not\in\overline W_p$ , right? 4th qstn. This contention $\overline G\cap\overline W_{p_1}\cap...\cap\overline W_{p_n}\subset U$ (not explicitly mentioned in the proof) is because if it weren't truth i.e. $p\in\overline G\cap\overline W_{p_1}\cap...\cap\overline W_{p_n}$ and $p\not\in U$ , then $p\in U^c=C!$ with $C\cap \overline G\cap\overline W_{p_1}\cap...\cap\overline W_{p_n}=\emptyset$ Can anyone help me please? Thank you.","['elementary-set-theory', 'proof-explanation', 'general-topology', 'compactness']"
3248252,"If $|C\times C|=|\mathbb{R}|$, then can we conclude that $|C|=|\mathbb{R}|$?","I'm curious, is there a simple argument to suggest that if a set $C$ satisfies $|C\times C| = |\mathbb{R}|$ , that $|C| = |\mathbb{R}|$ as well? It seems trivially true, but I'm having trouble coming up with a simple argument for it. Obviously, if $|C| = |\mathbb{N}|$ then $|C\times C| = |\mathbb{N}|\neq |\mathbb{R}|$ , and if $|C| > |\mathbb{R}|$ , then $|C\times C|\ge |C|>|\mathbb{R}|$ . This might seem like a proof, but it only works under the continuum hypothesis, since it assumes there is no set $X$ with $|\mathbb{N}| < |X| < |\mathbb{R}|$ . It's obvious that if $C\times C$ is uncountable , then $C$ must be uncountable, since the contrapositive, that $C$ being countable implies $C\times C$ is countable, in this case makes no assumption of the exact cardinality of $C\times C$ . Without the continuum hypothesis, how do we know there isn't an ""uncountable"" set $X$ , with $|X|<|\mathbb{R}|$ and $|X\times X|=|\mathbb{R}|$ ? Edit: Additionally, is this possible without the Axiom of Choice?",['elementary-set-theory']
3248296,Quantum representation of a system of identical particles,"I'm studying mathematics and I began a course in quantum statistics, in which I got to the discussion related to indistinguishibility of particles. My professor's notes are not very clear and rigourous, but I understood from them that: Two quantum states are physically equivalent iff they differ by a complex phase factor $$|\Psi \rangle \equiv |\Psi' \rangle \iff |\Psi'\rangle = e^{i \phi} |\Psi\rangle$$ Particles $|\psi_i\rangle$ within a state $|\Psi\rangle \in \bigotimes_{i=1}^n H_i$ are indistinguishable iff $$P|\Psi\rangle \equiv |\Psi\rangle \quad \forall P \in S_n$$ that is if given a generic permutation of the variables ( $S_n$ is the symmetric group), the corresponding state is physically equivalent to the original. In a quantum system of identical particles, these are indistinguishible (which is postulate?) Then my professor notes jump and say that there are two kinds of particles: bosons and fermions, and that their representation in $\bigotimes_{i=1}^n H_i$ is given by: $$|\Psi\rangle_{Bosons} = \sqrt{\frac{\prod_n m_n!}{N!}}\sum_{\pi \in S_n} |\psi_{\pi(1)}\rangle|\psi_{\pi(2)}\rangle\dots|\psi_{\pi(n)}\rangle$$ with $m_n$ number of particles in the $|\psi_n\rangle$ state, while $$|\Psi\rangle_{Fermions} = \sqrt{\frac{1}{N!}}\sum_{\pi \in S_n} \text{sign}(\pi)|\psi_{\pi(1)}\rangle|\psi_{\pi(2)}\rangle\dots|\psi_{\pi(n)}\rangle$$ with no further explanation. So I proceeded, trying to derive the latter expressions. I started with noticing that by imposing that $$\pi|\Psi\rangle \equiv |\Psi\rangle$$ we are saying that $|\Psi\rangle$ is an eigenstate of $\pi \in S_n$ , and we need to impose this for all possible permutations $S_n$ . So, since the permutations have a spectrum $\sigma(\pi) \subseteq \{\pm 1\}$ then we need that $$|\Psi\rangle \in \bigcap_{\pi \in S_n}(E_\pi(+1) \cup E_\pi(-1))$$ where by $E_\pi(\pm 1)$ I mean the eigenspace of $\pi$ associated to the eigenvalue $\pm 1$ . Now we have that in general $|\Psi\rangle$ will be a linear combination (up to normalization) of the permuted elements: $$|\Psi\rangle = \sum_{\pi \in S_n} f(\pi) |\psi_{\pi(1)}\rangle|\psi_{\pi(2)}\rangle\dots|\psi_{\pi(n)}\rangle$$ By imposing $$ \text{for all transpositions } \tau \in S_n (\tau |\Psi\rangle = |\Psi\rangle \text{ or } \tau |\Psi\rangle = -|\Psi\rangle)$$ We get that $f:S_n \rightarrow \mathbb{Z}^*$ is a homomorphism, and we have that there are only two homomorphisms from $S_n$ into $\mathbb{Z}^*$ : $f_1 = 1$ $f_2 =$ sign So we can catalogue particles according to this result, that is the combination's coefficients are given by $f_1$ in case of Bosons, and by $f_2$ in case of Fermions. In particular we get that $$|\Psi\rangle_{Bosons} \in \bigcap_{\tau \in S_n} E_\tau(+1)$$ and $$|\Psi\rangle_{Fermions} \in \bigcap_{\tau \in S_n} E_\tau(-1)$$ Is this line of reasoning acceptable and\or reasonable?","['hilbert-spaces', 'group-theory', 'abstract-algebra', 'quantum-mechanics']"
3248322,Separatedness of open subscheme of affine schemes,"A scheme $X$ is separated if the daiganoal morphism $\Delta:X \rightarrow X \times_{\Bbb Z} X$ is a closed immersion. I know how to show that all affine schemes are separated. So Are open subschemes of affine schemes separated? If not, what is an example? For example, I would be interested to know if the open subscheme $$ D= Spec\,  k[x.y] \setminus \{0\} \rightarrow Spec \,k[x.y] $$ is separated.","['affine-schemes', 'algebraic-geometry', 'schemes', 'separation-axioms']"
3248354,Degree 2 map of elliptic Curve,"I'm having a hard time constructing an explicit degree $2$ map $$C \rightarrow \mathbb{P}_k^1$$ where C is given by cutting out the elliptic homogeneous equation $$X^3+Y^3-Z^3=0$$ in $\mathbb{P}_k^2$ . Considering the affine open $D(z)$ , I see a natural map of function fields $k(t) \hookrightarrow k(t)[s]/(s^3+(t^3-1))$ , but this map has degree $3$ I guess, as it gives an algebraic field extension of degree $3$ . Sending the generator $t$ to another element might solve that problem, but I don't see how.","['algebraic-geometry', 'geometry', 'elliptic-curves']"
3248361,What is the $\epsilon^{00}$-topology?,"""If $F$ is a locally convex space, then the topology on $F^*$ (the topological dual of F) will be the strong topology, and the topology on $F^{**}$ will be the $\epsilon^{00}$ -topology."" This is the first time I've seen this notation. It is described as the uniform convergence topology on the polars of p-unit balls, but I would like to know what is the exact thing this $\epsilon^{00}$ -topology is referring to, it is also mentioned in some other papers without any further explanation - is it always the same thing explained here? The paper I'm reading right now was published in 1974, ""Linear Operators and Vector Measures"" by Brooks and Lewis.","['notation', 'general-topology']"
3248419,applying Chinese Remainder Theorem,"Suppose $N=p_1^{n_1}p_2^{n_2}...p_t^{n_t} $ where the $p_i$ are unique primes . Now by the Chinese Remainder Theorem $$ SL_2(\mathbb{Z}/N\mathbb{Z})=SL_2(\mathbb{Z}/p_1^{n_1}\mathbb{Z}) \times SL_2(\mathbb{Z}/p_2^{n_2} \mathbb{Z}) \times...\times SL_2(\mathbb{Z}/p_t^{n_t}\mathbb{Z})$$ I only know that $$ \mathbb{Z}/N\mathbb{Z}=\mathbb{Z}/p_1^{n_1}\mathbb{Z} \times \mathbb{Z}/p_2^{n_2}\mathbb{Z} \times... \times \mathbb{Z}/p_t^{n_t}\mathbb{Z}$$ by the 
Chinese Remainder Theorem  , but why is it also true for $SL_2(\mathbb{Z})=\lbrace
    \begin{pmatrix}
    a & b  \\
    c & d  \\
    \end{pmatrix}  :a,b,c,d \in \mathbb{Z} \ \ , ad-bc=1 \rbrace
$ ? Thanks for help .","['number-theory', 'abstract-algebra']"
3248431,Errata for Bott Tu Differential Forms,"My book is Differential Forms in Algebraic Topology by Loring W. Tu and Raoul Bott of which An Introduction to Manifolds by Loring W. Tu is a prequel. I am making this as suggested here An old ""list question"" edited to include other points based on my rejected edit of another post containing some mistakes Some possible mistakes in Bott and Tu much like this one Errata for Atiyah-Macdonald Please post any others you've found. I'll start.","['differential-topology', 'big-list', 'algebraic-topology', 'differential-geometry']"
3248482,Removed Archer example from wikipedia.,"I have question about example illustration Convergence of random variables in probability but not almost surely. Suppose a person takes a bow and starts shooting arrows at a target. Let $X_n$ be his score in $n$ -th shot. Initially he will be very likely to score zeros, but as the time goes and his archery skill increases, he will become more and more likely to hit the bullseye and score $10$ points. After years of practice the probability that he hit anything but $10$ will be getting increasingly smaller and smaller and will converge to $0$ . Thus, the sequence $X_n$ converges in probability to $X = 10$ . Note that $X_n$ does not converge almost surely however. No matter how professional the archer becomes, there will always be a small probability of making an error. Thus the sequence $(X_n)$ will never turn stationary: there will always be non-perfect scores in it, even if they are becoming increasingly less frequent. https://en.wikipedia.org/w/index.php?title=Convergence_of_random_variables&diff=879355996&oldid=879219919 For me this example is true. But not for 69.181.249.190. Why? You have any idea? 69.181.249.190 talk‎ 36,722 bytes -957‎ →‎Convergence in probability: removed false archer example","['convergence-divergence', 'probability', 'random-variables']"
3248488,Find the modulus of continuity of a function,"I have the following Dirichlet problem \begin{equation}
\begin{cases} a(x)Du\cdot Du-b(x)\cdot Du=0 \ \ \ \ \text{in} \ \Omega, \\u(x) = g(x) \ \ \ \ \text{on} \ \partial\Omega. \end{cases}
\end{equation} Here $\Omega$ is an open bounded subset of $\mathbb{R}^N$ , $a \in C(\bar\Omega, \mathbb{R}^{N \times N})$ , $b \in C(\bar\Omega, \mathbb{R}^N)$ and $g \in C(\partial\Omega)$ . I make the following assumptions: 1) $a(x)\xi \cdot \xi \geq |\xi|^2$ for $x \in \Omega$ and $\xi \in \mathbb{R}^N$ . 2) There is a function $\psi \in C^1(\bar\Omega)$ such that $b(x) \cdot D\psi(x) \geq 1$ for $x \in \Omega$ . Now, I define $H(p,x) = a(x)p \cdot p- b(x) \cdot p$ How can I prove (if it is possible) that $H$ satisfies \begin{equation}
|H(x,p)-H(y,p)| \leq \omega(|x-y|(1+|p|)) \ \ \ \text{for} \ x,y \in \Omega \ \text{and} \ p \in \mathbb{R}^N?
\end{equation} Here $\omega$ is a modulus, i.e. a function $\omega\colon[0,+\infty[\to[0,+\infty[$ continuous, nondecreasing, and such that $\omega(0) = 0$ . My attempt: \begin{align}
|H(x,p)-H(y,p)|&=|a(x)p \cdot p- b(x) \cdot p - a(y)p \cdot p + b(y) \cdot p|\\
&=|(a(x)-a(y))p \cdot p - (b(x)-b(y)) \cdot p|
\end{align} but I don't know how to proceed from here. Any help would be appreciated. Thanks in advance.","['analysis', 'partial-differential-equations']"
3248503,How does $Y_n$ approach $\theta$ in probability here?,"From Statistical Inference by Casella and Berger: $\text{(Delta Method)}$ Let $Y_n$ be a sequence of random variables that
  satisfies $\sqrt{n}(Y_n - \theta) \rightarrow n(0,\sigma^2)$ in
  distribution.  For a given function $g$ and a specific value of $\theta$ , suppose that $g'(\theta)$ exists and is not $0$ .  Then $\sqrt{n}[g(Y_n) - g(\theta)] \rightarrow n(0, \sigma^2[g'(\theta)])$ in distribution. The taylor expansion of $g(Y_n)$ around $Y_n = \theta$ is $$g(Y_n) = g(\theta) + g'(\theta)(Y_n-\theta) + \text{ Remainder, }$$ where the remainder $\rightarrow 0$ as $Y_n \rightarrow \theta$ . Since $Y_n \rightarrow \theta$ in probability , it follows that the remainder $\rightarrow 0 $ in probability. Why does $Y_n \rightarrow \theta$ in probability?  This isn't assumed in the statement of the theorem, so why is this true?","['proof-explanation', 'statistics', 'probability-theory', 'statistical-inference']"
3248575,Proving monotone function of two variables is integrable,"Let $f:[0,1]^2\rightarrow \mathbb R$ be a monotone function of two variables, that is, $x\leq x'$ and $y\leq y' \implies f(x,y)\leq f(x',y').$ Prove that $f$ is Riemann integrable. I want to ""copy"" and generalize the argument for the one dimensional case. Well, what I tried so far was to consider the partition $P=\{P_{ij}: i,j = 1,\cdots, N\}, N\in \mathbb N, $ given by $P_{ij} = (\frac{i-1}{N},\frac{i}{N})\times (\frac{j-1}{N},\frac{j}{N})$ . This is a partition of the square by small squares of area $1/N^2$ . As in the one dimensional case, I want the sum $R(f,P)-L(f,P)$ to telescope and be something like: $\frac{f(1,1)-f(0,0)}{N}$ where $f(1,1)$ and $f(0,0)$ , as we may notice, is the maximum and minimum of the function on the square. But, it doesn't seem that this sum will be telescoping, because for each small square, its maximum and minimum of the function is reached at the opposed diagonal vertices (on the right) and will always remain diagonal vertices which will not ""kill each other"". Is this the right approach? Any hint on how to prove this?","['integration', 'multivariable-calculus']"
3248591,Does there exist $X$ such that $A = X^2 + X^t$?,"If $A \in M_n( \mathbb{R} )$ , then when does there exist $X \in M_n(\mathbb{R})$ such that $A = X^2 +  X^T$ ?","['matrices', 'matrix-equations', 'linear-algebra']"
3248613,Prove $\lceil z \rceil=z+\frac12-\frac{\tan^{-1}(\tan(\pi(z+0.5)))}{\pi}$ when $z$ is not an integer,"How can I prove that $\lceil z \rceil=z+\dfrac12-\dfrac{\tan^{-1}(\tan(\pi(z+0.5)))}{\pi}$ for all non-integer real numbers $z$ ? Z cannot be an integer because then tan(pi*z + pi/2) would be undefined. I got this equation by messing around with arcsin(sin(x)), arccos(cos(x)), and arctan(tan(x)) and noticed that arctan(tan(x))-x looked liked a weird negative ceiling function, so I made it x-arctan(tan(x)), and saw a disproportional ceiling function: Then I changed the equation so that it was the arctan(tan(x)) became $\dfrac{\tan^{-1}(\tan(\pi(z+0.5)))}{\pi}$ and I added 0.5 to make it the ceiling function. I am looking for a mathematical proof that is relatively simple and only uses trig, low level calc, and algebra.",['trigonometry']
3248622,Mistake in evaluating the secant integral?,"I was trying to solve the secant integral $$\int \dfrac{1}{\cos x} dx $$ by using the substitution $t := \tan(\dfrac{x}{2})$ . Using this, I found: $$dx =\dfrac{2\cdot dt}{t^2 + 1} $$ and $$\cos(x) = \dfrac{1 -t^2}{1+t^2} $$ This would mean that: $$\begin{split}
\int \dfrac{1}{\cos x} dx &= \int \dfrac{1+t^2}{1 -t^2} \cdot \dfrac{2\cdot dt}{t^2 + 1}\\&= 2 \int \dfrac{1}{1-t^2} dt \\&= 2 \int \left(\dfrac{1}{2(t-1)} - \dfrac{1}{2(t+1)}\right)dt\\&= \int \left(\dfrac{1}{t-1} - \dfrac{1}{t+1}\right)dt\\&=\log(t-1) - \log(t+1)\\&=\log\left(\dfrac{t-1}{t+1}\right)\\&=\log\left(\dfrac{\tan{\dfrac{x}{2}}-1}{\tan{\dfrac{x}{2}}+1}\right)
\end{split}$$ By using a plotting tool it is clear that this last expression is not equal to the answer . I know that there are many ways to derive this integral and I understand them all, but what I don't understand is why my method above fails. That's why I am asking specifically which step above is wrong.","['indefinite-integrals', 'calculus', 'trigonometry']"
3248644,Can anyone help me solve these sequence limits?,"I would be really thankful if someone helped me with these two sequence limits. $$\lim_{n\to\infty} \frac{1}{n^2} \left(2+ \frac{3^2}{2}+\cdots+\frac{(n+1)^n}{n^{n-1}}\right)$$ I've tried bounding the second term, but I don't know how to solve it. I think it's zero but I'm not sure about separating the limits.. $$\lim_{n\to\infty} \frac{\sqrt{(n-1)!}}{(1+\sqrt{1}) (1+\sqrt{2})\ldots(1+\sqrt{n})} $$ I've tried using the Stirling formula with this limit, but I'm not sure about how to solve what I get….
Thank you!","['limits', 'calculus', 'sequences-and-series']"
3248670,Frobenius twist of a field,"Let $k$ be a field of characteristic $p>0$ (not necessarily perfect). Consider the Frobenius endomorphism $F : k \to k$ , $x \mapsto x^p$ . I am curious about what happens when we take $k$ as a $k$ -vector space, and restrict scalars along $F$ . We get a new $k$ -vector space $F_*(k)$ , and I wonder how does it look (possibly even when $k$ is perfect)? Can we give a basis for $F_*(k)$ ? Is it finite dimensional? I will also be interested if we can say something more generally about $F_*(V)$ for $V$ a finite dimensional $k$ vector space. Thank you EDIT: I am still interesting in the question. From the comments, we have the following simplification by reuns: Find a basis for $k$ as a $k^p$ -vector space. I did not understand the rest of reuns' suggestion for how to do it though.","['positive-characteristic', 'vector-spaces', 'algebraic-geometry', 'linear-algebra', 'commutative-algebra']"
3248676,Proof that the number of 1's in $P(n)$ equals the number of distinct magnitudes in $P(n)$,"For given division of number $n$ (let name that $\pi$ ) we are going to consider: $A(\pi)$ it is a number of $1$ in $\pi$ $B(\pi)$ it is a number of different elements in $\pi$ . Proof that $$ \sum_{\pi} A(\pi)  = \sum_{\pi} B(\pi) $$ Example: $$ \pi = 1 + 1 + 2 + 2 +2 + 4 $$ then $$A(\pi) = 2 \wedge B(\pi)=3$$ Hint: Consider each side of equation in use of $P(1), P(2), ... P(n-1)$ where $P(k)$ is number of divisions of $k$ . My try I have no idea how to use that hint, so I decided to define $\delta = A(\pi)  - B(\pi) $ and hope that it can help me to find bijection. Example for $n=5$ \begin{array}{|c|c|c|c|}
\hline
\pi& \delta\\ \hline
5 & -1  \\ \hline
4+1 & -1  \\ \hline
3+2 &   -2 \\ \hline
3+1+1 & 0  \\ \hline
2+2+1 &  -1 \\ \hline
2+1+1+1 &  1 \\ \hline
1+1+1+1+1 & 4  \\ \hline
\end{array} but it doesn't help me so probably hint is really important.","['number-theory', 'discrete-mathematics']"
3248705,Find number of permutations $ \delta $ such that $\delta ^4 = \pi$,"Permutation $ \pi$ has a signature $2^43^5$ (it contains $4$ cycles of length $2$ and $5$ cycles of length $3$ ). Find number of permutations $ \delta $ such that $\delta ^4 = \pi$ My observation
Cycle of length $3$ : $$\pi = [a,b,c]$$ $$\pi^2 = [a,c,b]$$ $$\pi^3 = [a][b][c]$$ $$\pi^4 = [a,b,c]$$ Moreover for cycle of length $2$ : $$\pi = [a,b]$$ $$\forall_k \, \pi^2 = \dots = \pi^k = [a,b]$$ So it means that number of these permutations is just all possible permutations with given signature?
So it is $$\binom{23}{2}\binom{21}{2}\binom{19}{2}\binom{17}{2}\binom{15}{3}\binom{12}{3}\binom{9}{3}\binom{6}{3}\binom{3}{3} \cdot (3-1)!^5 \cdot (2-1)!^4 $$","['permutations', 'discrete-mathematics']"
3248722,Decay of non-negative functions with compact Fourier support,"Let $f$ be a function on the real line with $\widehat{f}$ supported in the interval $[-1,1]$ . Let's denote the space of such functions with $W_0$ . Let $g\ge 0$ denote a rapidly decaying (and say, continuous, if that matters) function on the real line; what I have in mind is something like the absolute value of a Schwartz function. Question: Given such a function $g$ , does there always exist $f\in W_0$ such that $g(x)\le f(x)$ for all $x\in\mathbb{R}$ ? If yes, can we also find $f\in W=W_0\cap \mathcal{S}$ ? (Here $\mathcal{S}$ denotes Schwartz functions.) Presumably, for the second part, rapid decay is not sufficient. On the other hand if $g$ is compactly supported, then the answer to the second question seems to be yes, let $f=\widehat{\phi*\phi}$ for an approriately chosen smooth $\phi$ supported in $[-1/2,1/2]$ . Partial  answers or helpful suggestions are welcome as well. Edit: Sorry for confusion over multiple edits.","['harmonic-analysis', 'fourier-analysis', 'fourier-transform', 'real-analysis']"
3248726,"Are all countable, infinite sets countably infinite?","It sounds like a hilarious question to ask, but these are terms we don't want to conflate; i.e. there are separate notions of an infinite set (a set with a bijection to one of its proper subsets), a countable set (a set from which an injection to $\mathbb N$ exists), and a countably infinite set (a set from which a bijection to $\mathbb N$ exists). If some set $A$ proves to be a countable and infinite set, then is it automatically countably infinite? For instance, let $A$ be some finite set and define the set $S$ to be the set of all finite sequences of elements of $A.$ It's easy to see that $S$ is an infinite set, since we can define a bijective function $f$ mapping $S$ to a proper subset of itself such that for any $s\in S$ we have that $f(s)=\langle s,a\rangle$ for some fixed $a\in S.$ We can also show that $S$ is countable by Theorem 0B stated in A Mathematical Introduction to Logic (Enderton) since $A$ is finite, hence countable. With these individual proofs, it does not occur to me immediately that there is a bijection from $S$ to $\mathbb N,$ because the proof for Theorem 0B involves mapping every member $\langle a_0,...,a_n\rangle$ of $S$ to some prime factorization $2^{g(a_0)+1}\cdot 3^{g(a_1)+1}\cdot...\cdot p^{g(a_n)+1}$ where $p$ is the $(n+1)$ th prime and $g$ is an injective function from $A$ to $\mathbb N$ and it's clear that no member of $S$ is mapped to $0$ or $1$ this way. Proving that $S$ is countably infinite therefore should involve a completely different procedure. Is there a theorem I'm missing that is completely relevant to this? I mean, it already sounds ridiculous to say that there's a countable, infinite set that is uncountably infinite, right? Thanks in advance.","['elementary-set-theory', 'number-theory']"
3248746,What is the meaning of the negative numbers?,"I am having troubles understanding what is the ""meaning"" or best way to think of the negative numbers. I am not really sure where is my confusion, so I would set some examples that make me trouble. Sorry for my informal language. When thinking of ""5 - 3"" should I think about it as ""taking away three elements from five elements"" or is it ""five positive elements and three negative elements together""? I mean, are negative numbers really numbers (or some quantity) or are they just a natural number under a subtraction operation. From there come I think the rest of my questions. What does ""10/-5"" really mean? Am I dividing ""10 elements"" into ""five negative groups""? How is that possible? How can there be negative groups?. How can the result be negative, since the elements I am dividing are positive? I know how to get the results of these cases. But I do not really think I understand what a negative number really mean. Can anyone help me see where is my confusion and if possible recomend some content to read?",['number-theory']
3248749,Random graph connectivity with different probability for each edge,"Let $G_{0}=(V,E)$ be a connected graph. Let $G_{1}=(V,E')$ be the probalistic subgraph of $G_{0}$ such that for each $e_{i}\in E$ the probability of $e\in E'$ is $p_{i}$ (each edge can get different probability) I need to find a way to describe the probability of $G_{1}$ to stay connected, meaning that we might lose some of $G_{0}$ edges but still stay connected. I have found only papers that describe the $G(n,p)$ model and the $G(n,m)$ model or related issues, all of them describe an equal p probability for each edge. I have tried to build a function of the vertices degree, something like $\Sigma_{i=0}^{n}\Pi_{j\in N(V_{i})}P_{j}$ where $n$ is the number of vertices and $N(v_{i})$ represents $v_{i}$ neighbors but I have duplications. I am thinking about the probability of finding a tree in $G_{1}$ but I can't find any material. Does anyone have any idea if there is a relevant material that is related to my problem?","['graph-theory', 'random-graphs', 'connectedness', 'probability']"
3248776,How do I get my math proof checked?,"I have a math proof that I think would be in the category of number-theory or algebra. EDIT: The proof is incorrect as pointed out by Empy2 but still proves that the values must be all odd or all even. The proof is that there doesn't exist a 3x3 magic square with all squares (see https://plus.maths.org/content/os/latestnews/may-aug10/magic/index ) Edit: Here is my proof: So the basic idea is to solve variables a^2    b^2    c^2 d^2    e^2    f^2 g^2    h^2    i^2 and we know that every row/column/diagonal must add to some value.  Say s for sum.  Now let's replace h^2 with s-b^2-e^2 since we know that the row must add to s. a^2    b^2    c^2 d^2    e^2    f^2 g^2    s-b^2-e^2    i^2 Now let's replace the bottom right value i^2 with s-a^2-e^2 since that diagonal must add to s. a^2    b^2    c^2 d^2    e^2    f^2 g^2    s-b^2-e^2    s-a^2-e^2 and now the same with the bottom left: a^2    b^2    c^2 d^2    e^2    f^2 s-c^2-e^2    s-b^2-e^2    s-a^2-e^2 We can also replace d^2 with s-(s-c^2-e^2)-a^2 which can be simplified as c^2+e^2-a^2: a^2   b^2   c^2 c^2+e^2-a^2   e^2   f^2 s-c^2-e^2   s-b^2-e^2   s-a^2-e^2 Let's also replace the middle-right f^2 with s-(s-a^2-e^2)-c^2 which is a^2+e^2-c^2. a^2   b^2   c^2 c^2+e^2-a^2   e^2   a^2+e^2-c^2 s-c^2-e^2   s-b^2-e^2   s-a^2-e^2 We also know that the middle row must add to s therefore (c^2+e^2-a^2)+e^2+(a^2+e^2-c^2)=s.  Which can be simplifyed as 3e^2=s.  Therefore e^2=s/3 and we already know that s is the sum of the top row therefore a^2+b^2+c^2=s.  Which means that e^2=(a^2+b^2+c^2)/3.  Let's now replace that: a^2   b^2   c^2 c^2+(a^2+b^2+c^2)/3-a^2   (a^2+b^2+c^2)/3   a^2+(a^2+b^2+c^2)/3-c^2 s-c^2-(a^2+b^2+c^2)/3   s-b^2-(a^2+b^2+c^2)/3   s-a^2-(a^2+b^2+c^2)/3 Let's also replace s with (a^2+b^2+c^2) and simplify: a^2   b^2   c^2 c^2+(a^2+b^2+c^2)/3-a^2   (a^2+b^2+c^2)/3   a^2+(a^2+b^2+c^2)/3-c^2 a^2+b^2-(a^2+b^2+c^2)/3   a^2+c^2-(a^2+b^2+c^2)/3   b^2+c^2-(a^2+b^2+c^2)/3 subsection{Multiples of 4} We know that every integer is one of these: 4m, 4m+1, 4m+2, 4m+3.  However if we square all of them we get: (4m)^2 = 16m^2 = 4(4m^2) (4m+1)^2 = 16m^2+8m+1 = 4(4m^2+2m)+1 (4m+2)^2 = 16m^2+16m+4 = 4(4m^2+4m+1) (4m+3)^2 = 16m^2+24m+9 = 4(4m^2+6m+2)+1 Which means that a square number can't be a multiple of 4 plus 2 or a multiple of 4 plus 3 and since all the values have to be squares none of them can be multiple of 4 plus 2 or a multiple of 4 plus 3.  Now let's look at the center value of (a^2+b^2+c^2)/3.  We know that all the squares in it can only be multiple of 4 or a multiple of 4 plus 1.  Here is a table of the inputs and the outputs (0 is a multiple of 4, 1 is a multiple of 4 plus 1, and so on): Output   a^2   b^2   c^2 0   0   0   0 3   0   0   1 3   0   1   0 2   0   1   1 3   1   0   0 2   1   0   1 2   1   1   0 1   1   1   1 Which means we are left with these options: Output   a^2   b^2   c^2 0   0   0   0 1   1   1   1 However we can ignore a^2,b^2,c^2=4j,4k,4l because if that's the case then you could divide everything by 4 and they would still be squares.  Therefore we can ignore it.  This is the only option: 4j+1   4k+1   4l+1 4m+1   4n+1   4t+1 4p+1   4q+1   4r+1 Since they are actually of the form 4(m^2+m)+1 instead of 4j+1 (due to the fact that they are an odd squared) and the fact that j^2+j will always be even we can rewrite it like so: 8j+1   8k+1   8l+1 8m+1   8n+1   8t+1 8p+1   8q+1   8r+1 (PLEASE NOTE: the variables before and the variables after are different!)  The sum of any row must be 12w+3 because the center value is a multiple of 4 plus 1.  Now let's write all the possiblities for whether they're 16j+1 or 16j+9 (We can write anything say 6u+1 as either 12u+1 or 12u+6+1): Sum   a^2   b^2   c^2 16x+3   1   1   1 16x+11   1   1   9 16x+11   1   9   1 16x+19   1   9   9 16x+11   9   1   1 16x+19   9   1   9 16x+19   9   9   1 16x+11   9   9   9 Let's look at a^2,b^2,c^2=16j+1,16k+1,16l+9: 16j+1   16k+1   16l+9 ?   ?   ? ?   ?   ? We know that there can only be one 9 per row/colum/diagonal therefore: 16j+1   16k+1   16l+9 ?   ?   16t+1 ?   ?   16r+1 and we can also put 1s from the diagonal. 16j+1   16k+1   16l+9 ?   16n+1   16t+1 16p+1   ?   16r+1 We also know that there must be one 9 per row/colum/diagonal: 16j+1   16k+1   16l+9 16m+9   16n+1   16t+1 16p+1   16q+9   16r+1 but wait!  There arn't any 9s in the top-left to bottom-right diagonal.  Therefore a^2,b^2,c^2=16j+1,16k+1,16l+9 is impossible.  As well as a^2,b^2,c^2=16j+9,16k+1,16l+1 is impossible becuase of symetry.  We can also ellimenate 2 more options by replacing 1 with 9 and 9 with 1.  So we are down to these: Sum   a^2   b^2   c^2 16x+3   1   1   1 16x+11   1   9   1 16x+19   9   1   9 16x+11   9   9   9 Now let's look at a^2,b^2,c^2=16j+1,16k+9,16l+1: 16j+1   16k+9   16l+9 ?   ?   ? ?   ?   ? We know that there can only be one 9 per row/colum/diagonal therefore: 16j+1   16k+9   16l+1 ?   16n+1   ? ?   16q+1   ? and we can also put a 9 in the bottom right because there must be a 9 in the diagonal. 16j+1   16k+9   16l+1 ?   16n+1   ? ?   16q+1   16r+9 and we can also put a 9 in the bottom left because there must be a 9 in the other diagonal. 16j+1   16k+9   16l+1 ?   16n+1   ? 16p+1   16q+1   16r+9 but wait!  There are two 9s in the bottom row therefore a^2,b^2,c^2=16j+1,16k+9,16l+1 is impossible.  Here are the two options left: Sum   a^2   b^2   c^2 16x+3   1   1   1 16x+11   9   9   9 Looking back at the original table now looks like this: 16j+1   16k+1   16l+1 16m+1   16n+1   16t+1 16p+1   16q+1   16r+1 or 16j+9   16k+9   16l+9 16m+9   16n+9   16t+9 16p+9   16q+9   16r+9 However I now can prove that both of these are impossible!  Imagine that we can split 16j+1 into 32j+1 or 32j+17 and we can keep repeating, but I can prove that all the numbers have to be the same option!  First let's start with the scenaros: a^2   b^2   c^2 n   n   n n   n   m n   m   n n   m   m m   n   n m   n   m m   m   n m   m   m where n and m are their values above some power of 2.  (like: 128+17, n=17)  Now let's get the basic idea:  we want to show that for any different n and m both greater than 0 and smaller than the power of 2  (which we will now write as P) that it won't work unless all numbers are of the form 2^P+n or 2^P+m but not combos of them. Let's start by proving n,n,m is impossible: 2^Pj+n   2^Pk+n   2^Pl+m ?   ?   ? ?   ?   ? To simplify for looks let's replace them with just n or m not 2^Pj+n or 2^Pj+m: n   n   m ?   ?   ? ?   ?   ? We can now put n from the top right m (since there has to be one m per line or else they can't add to the same number.  I have a proof of it but I don't think I need to show that here.  It's already kinda long.)  straight down, and diagonal from it: n   n   m ?   n   n n   ?   n but wait!  There are three n in the left diagonal therefore it can't work.  We are now down to these options:  (and since this doesn't work we can also remove the opposite and the backwards ones!) a^2   b^2   c^2 n   n   n n   m   n m   n   m m   m   m Now let's prove that n,m,n is impossible. n   m   n ?   ?   ? ?   ?   ? Create a line down from it: n   m   n ?   n   ? ?   n   ? Add two m because of the diagonals must have a m: n   m   n ?   n   ? m   n   m but wait!  There are two m in the bottom row therefore it can't work!  Meaning the all the top three values have to be like so: a^2=2^Pj+z b^2=2^Pk+z c^2=2^Pl+z where z is some constant amount.  (We know that z must be constant because we showed that the only options are if it's the same number for all 3.)
We also know that P can be as high as we want it to be as long as it's not infinity but a finite number.
Let's imagine that 2^P is greater than a^2, b^2, or c^2.
Then j,k, and l must all be 0.
Which means they all equal z therefore they would be the same number and that is against the rules so there doesn't exist a solution with all squares. Q.E.D. Thanks in advance.","['number-theory', 'proof-verification']"
3248804,Second order linear inhomogeneous ODE with characteristic function,"I'd like to calculate the solution $y : [0, \infty) \longrightarrow \mathbb{R}$ of the IVP $$\ddot{y}(t) -4\dot{y}(t)+4y(t) = t\mathrm e^{2t} \chi_{[0,1]}(t), \quad y(0) = 1,\ \dot{y}(0) = 0,$$ where $\chi_{[0,1]}(t)$ is the indicator function on the interval $[0, 1].$ What I was able to do is to solve the homogenous equation $\ddot{y}(t) -4\dot{y}(t)+4y(t) = 0$ . After this I wanted to find a particular solution of the inhomogeneous equation. My idea was, that I use the ansatz $y_{\mathrm p}(t) = f(t) \mathrm e^{2t}$ , where $f$ is $\mathcal{C}^2$ , plug this into the ODE and multiplicate the resulting solution with the characteristic function. That lead me to the particular solution $y_{\mathrm p}(t) = \frac{t^3}{6} \mathrm e^{2t} \chi_{[0,1]}(t)$ , but I was told that this is wrong. What is my mistake and how can one solve this problem?",['ordinary-differential-equations']
3248826,The diffeomorphism between two sub-level sets,"Let $f:M \rightarrow \mathbb{R}$ be a smooth map ( $f \in C^{\infty}(M)$ ), where $M$ is a compact manifold . Prove that $f^{-1}((-\infty,a])$ is diffeomorphic to $f^{-1}((-\infty,b])$ if the interval $[a,b]$ doesn't contain critical values of $f$ . I have no idea how to deal with this now and really need some hints. Any help would be appreciated.","['differential-topology', 'differential-geometry']"
3248828,Help me find my mistake for this variance,"Suppose X is an observation from a distribution with probability mass function $$X\sim f(x)=\left(\frac{\theta}{2}\right)^{\left | x \right |}(1-\theta)^{1-\left | x \right |} 1_{A}(x)$$ $$0<\theta<1$$ where $$A=\left \{ 1,0,-1 \right.\left.  \right \}$$ Suppose $$T(X)=2 \cdot 1_{B}(x)$$ where $$B=\left \{ 1 \right.\left.  \right \}$$ I am trying to find the variance of T and this is what i did : $$V(T)=E(4 \cdot 1_{B} ^2) - E^2(2 \cdot  1_{B})$$ where i used the fact that $$V(X)=E(X^2)-E^2(X)$$ We can show that $$E(T)=\theta$$ So the variance can now be written as $$V(T)=4[1^2 f(1,\theta) + 0^2  f(0,\theta)] - (\theta)^2$$ Can you spot my mistake?","['statistics', 'variance']"
3248847,Is this result already a known theorem in geometry?,"I have been playing around with geometry and I found that: Let two perpendicular lines intersect at a point that is inside a circle. Then the area of the quadrilateral formed by the vertices made by the lines cutting the circle is half of the product of the perpendicular chords' lengths. Like this: Is this already a theorem or at least discovered? If so, what is the name of it? If someone wants the proof:","['euclidean-geometry', 'area', 'quadrilateral', 'circles', 'geometry']"
3248863,"Calculate the operator norm of $A: L^2[0,1] \to L^2[0,1]$ defined by $(Af)(x):=i\int_0^x f(t)\,dt-\frac{i}{2} \int_0^1 f(t) \,dt$","I want to calculate the operator norm of the operator $A: L^2[0,1] \to L^2[0,1]$ which is defined by $$(Af)(x):=i\int\limits_0^x f(t)\,dt-\frac{i}{2} \int\limits_0^1 f(t)\, dt$$ I've already shown that this operator is compact and selfadjoint. I think maybe this helps me calculating the operator norm. Maybe through spectral theorem for compact self adjoint operators. I also know that for integral operators of the form $$(Kf)(x)=\int\limits_0^1 k(x,t) f(t)\,dt$$ the inequality $\Vert K \Vert \leq \Vert k \Vert{}_{L^2}$ holds. For $$(Af)(x)=i\int\limits_0^x f(t)\,dt-\frac{i}{2} \int\limits_0^1 f(t) \,dt = \int\limits_0^1 i\,\left(1_{[0,x]}(t)-\frac{1}{2}\right)f(t)\,dt$$ this gives me an upper bound: $$\Vert A \Vert \leq \left\Vert  i~1_{[0,x]}-\frac{i}{2} \right\Vert{}_{L^2}=\frac{1}{2}$$ Can someone help me?","['operator-theory', 'compact-operators', 'functional-analysis', 'self-adjoint-operators']"
3248909,"For four non-parallel, non-intersecting lines in 3D space, two other lines intersect with all four lines simultaneously. How are they found?","Using CAD software, I have been able to make a construction in which four arbitrary lines in space (infinitely long) have two lines that intersect with all four. There are only ever two solutions that the software finds and degrees of freedom analysis vaguely suggests this is the expected result. So we have four lines in space: $$ \vec I = \vec I_0 + \alpha \vec I_1$$ $$\vec J = \vec J_0 + \beta \vec J_1$$ $$ \vec K = \vec K_0 + \gamma \vec K_1$$ $$ \vec L = \vec L_0 + \kappa \vec L_1$$ where $\vec \cdot$ denotes a vector. Two more lines make the intersections: $$ \vec X = \vec X + \eta \vec X_1$$ $$ \vec Y = \vec Y_0 + \zeta \vec Y_1$$ There will be a unique set of $\alpha$ , $\beta$ , $\gamma$ , $\kappa$ and $\eta$ where the line $X = I$ , $X = J$ , $X = K$ and $X = L$ There will be another unique set of $\alpha$ , $\beta$ , $\gamma$ , $\kappa$ and $\zeta$ where the line $Y = I$ , $Y = J$ , $Y = K$ and $Y = L$ . I am supposing the six scalars will each have a parabolic function of a common parameter, say $f(t)$ , where the solutions to $f(t) = 0$ are the unique values. This also creates a challenge of identifying which solution corresponds to which intersection. I can vaguely see a way through the mathematics but the complexity is getting beyond me. Can anyone help?","['vectors', 'geometry', '3d']"
3248984,Representation Theory Block Diagonalizing,"I am currently examining the symmetric group $S_4$ , and I was tasked with finding a $2$ -D, a $3$ -D, and a $4$ -D representation of the group. The $4$ -D representation is reducible, so I first found it and then found that it was the direct sum of a $3$ -D irreducible representation plus the fully symmetric representation. Consider one element: This is not in block diagonal form. In python, there is a function available for a matrix m, m.jordan_form(), which applies a symmetry operation to the input matrix and returns that matrix in Jordan form. The result for this matrix was I assume that $I$ is $i$ , the imaginary number. Please correct me if I am wrong on this. The issue with this result is we know that the above matrix is the direct sum of the fully symmetric representation and a $3$ -D representation; but the corner elements are $-1$ and $I$ , neither of which are $1$ . The fully symmetric representation is always just $1$ , so I expect that the block form result should either have a $1$ in the top left corner; and then the bottom right block is the $3$ -D representation; or I expect the bottom right corner to be $1$ and then the top left block is the $3$ -D representation. To clarify, if the fully symmetric representation is represented by $\Gamma^{(1)}$ , then $$\Gamma^{(1)}[(1342)]=1$$ and for the general group element $R$ $$\Gamma^{(1)}[R]=1$$ My question is then, what am I doing wrong? Is there a different block form other than Jordan form which I need to use in this situation? Thanks for your help!","['group-theory', 'representation-theory', 'direct-sum']"
3249030,Integral $\int_0^1 \frac{\ln(1+x+x^2)\ln(1-x+x^2)}{x}dx$,"Prove that $$\sf I=\int_0^1 \frac{\ln(1+x+x^2)\ln(1-x+x^2)}{x}dx=\frac{\pi}{6\sqrt{3}}\psi_1\left(\frac{1}{3}\right)-\frac{\pi^3}{9\sqrt{3}}-\frac{19}{18}\zeta(3).$$ I have thought about the integral from above after I saw this similar integral and  I believe changing the sign to have $\sf 1+x+x^2$ might get us a nice  closed form. So I started using the following formula: $$\sf 2ab=(a+b)^2-a^2-b^2$$ $$\sf \Rightarrow 2I=\int_0^1\frac{\ln^2(1+x^2+x^4)}{x}dx-\int_0^1\frac{\ln^2(1+x+x^2)}{x}dx-\int_0^1\frac{\ln^2(1-x+x^2)}{x}dx$$ Using in the first integral the substitution $\sf x^2\rightarrow x $ gets us: $$\sf \int_0^1\frac{\ln^2(1+x^2+x^4)}{x}dx=\frac12\int_0^1\frac{\ln^2(1+x+x^2)}{x}dx$$ $$\sf \Rightarrow I=-\frac14\int_0^1\frac{\ln^2(1+x+x^2)}{x}dx-\frac12\int_0^1\frac{\ln^2(1-x+x^2)}{x}dx$$ Well, now we only need to find: $$\sf I(a)=\int_0^1\frac{\ln^2(1+ax+x^2)}{x}dx $$ Then set $a=1$ and $a=-1$ . Of course  I tried to use Feynman's trick: $$\sf I'(a)=2\int_0^1\frac{\ln(1+ax+x^2)}{1+ax+x^2}dx$$ But quickly gave up as it doesn't look promising. Another way might be to let $\sf x+\frac12=\frac{\sqrt 3}{2}t$ in order to get: $$\sf \int_0^1\frac{\ln^2(1+x+x^2)}{x}dx=\int_\frac{1}{\sqrt 3}^\sqrt 3 \frac{\ln^2\left(\frac34(1+t^2)\right)}{t-\frac{1}{\sqrt 3}}dt$$ But well.. I would appreciate some help! Update . In the meantime I found something a conjecture : $$\sf \int_0^1\frac{\ln^2(1+x+x^2)}{x}dx=\frac{2\pi}{9\sqrt3}\psi_1\left(\frac13\right)-\frac{4\pi^3}{27\sqrt3}-\frac23\zeta(3)$$","['integration', 'definite-integrals', 'closed-form']"
