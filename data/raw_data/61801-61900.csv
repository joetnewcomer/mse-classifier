question_id,title,body,tags
698598,Solving for $\sum_{n = 1}^{\infty} \frac{n^3}{8^n}$?,"I was trying to solve $ \displaystyle \sum_{n = 1}^{\infty} \frac{n^3}{8^n}$ and I found a way to solve it and I want if there are generalizations for, say, $\displaystyle \sum_{n=1}^{\infty} \frac{n^k}{a^n}$ in terms of $k$ and $a$. I would also like to know if there is  a better way to solve it. Here's how I did it: First I decomposed the series into the following sums: $S_1  = \frac{1}{8} + \frac{1}{64} + \dots = \frac{\frac{1}{8}}{\frac{7}{8}}$ $S_2 = \frac{7}{64} + \frac{7}{512} + \dots = \frac{\frac{7}{64}}{\frac{7}{8}}$ $S_3 = \frac{19}{512} + \frac{19}{4096} + \dots = \frac{\frac{19}{512}}{\frac{7}{8}}$ And deduced that the sum can be written as $\frac{8}{7} \displaystyle \sum_{n = 1}^{\infty} \frac{3n^2 - 3n + 1}{8^n}$ $\displaystyle \sum_{n = 1}^{\infty} \frac{1}{8^n}$ is easy to evaluate -- it's $\frac{1}{7} $by geometric series $\displaystyle \sum_{n = 1}^{\infty} \frac{n}{8^n}$ can be evaluated in a whole host of ways to get an answer of $\frac{8}{49}$. It remains to evaluate $\displaystyle \sum_{n = 1}^{\infty} \frac{n^2}{8^n}$, for which I took a similar approach as the cubics by decomposing it into many sums: $T_1 = \frac{1}{8} + \frac{1}{64} + \dots = \frac{\frac{1}{8}}{\frac{7}{8}}$ $T_2 = \frac{3}{64} + \frac{3}{512} + \dots = \frac{\frac{3}{64}}{\frac{7}{8}}$ And so forth, coming to the conclusion that it is equal to $\frac{8}{7} \displaystyle \sum_{n = 1}^{\infty} \frac{2n-1}{8^n}$ Now, I used this information and the above values for $\displaystyle \sum_{n = 1}^{\infty} \frac{1}{8^n}$ and $\displaystyle \sum_{n = 1}^{\infty} \frac{n}{8^n}$ to get the sum as $\frac{776}{2401}$, which is confirmed by WA. So, I would like to reiterate here: Is there a simpler way to compute this sum, and are there any known generalizations for this problem given an arbitrary $a$ in the denominator and arbitrary $k$ as the exponent in the numerator?",['sequences-and-series']
698611,Question of the relation between very ampleness and irreducibility,"Let $X$ be a projective surface and $D$ be a divsor.
Then I know $D$ correspond to a curve of $X$.
My qeustion is simple. If $D$ is very ample, then the corrsponding curve of $D$ is irreducible? More generally, if $X$ be a projective variety of dimension $r$, then the corrsponding subvariety of a very ample divsor $D$ is irreducible??",['algebraic-geometry']
698620,Confidence level of random sample from continuous distribution,"Let $X_1,X_2,\cdots ,X_n$ be a random sample from a continuous distribution with median $\mu$. If $[X_{min}, X_{max}]$ is used as a confidence interval for $\mu$, what is its confidence level? What is the confidence level if $n=10$? The formula for the confidence interval is $\overline{x}-z(\alpha /2)(\sigma)\leq \mu \leq \overline{x}+z(\alpha /2)(\sigma)$.
I know that I need to solve for $\alpha$, but I'm not sure what the fact that the question involves a random sample means for the solution.","['statistics', 'descriptive-statistics', 'statistical-inference']"
698664,Show this metric generates the product topology on $X$,"Let $(X_n, d_n)$ be a sequence of metric spaces. Show that the function $ d: X \times X \to \mathbb R^+$ on the product space $X: = \prod_n X_n$ defined by $$d ((x_n)_{n = 1}^\infty, (y_n)_{n=1}^\infty ) := \sum_{ n=1}^\infty 2^{-n} \frac{ d_n(x_n,y_n)} { 1+ d_n (x_n,y_n) } $$ is a metric on $X$ which generates the product topology on $X$. I showed that $d$ is actually a metric, which was easy. To show that this metric generates the product topology I think I need to show: (i) Each ball $ B((x_n)_{n=1}^\infty  , \epsilon )$ is open in the product topology. (ii) For any $B(x_n , \epsilon) \subset X_n$, $\pi_n ^{-1} (B(x_n , \epsilon)) \subset X$ is the union of finite intersections of balls in $(X, d)$. But I couldn't even get started to do (i). Any help is appreciated.","['general-topology', 'metric-spaces', 'functional-analysis', 'product-space']"
698683,Pullback of a linear system in a ramified cover (through an example),"I am trying to understand the pullback of sections of a line bundle, in the situation of a ramified cover $\pi:X\rightarrow Y$ of algebraic varieties. I am trying to work out some nice concrete examples first, as the following one with a K3 surface $X$. Let $\pi:X\rightarrow\Bbb{P}^2$ be a double cover of the plane branched along a smooth sextic. Then 
$$H^0(\pi^\ast O(3))=\pi^\ast H^0(O(3))\oplus V,$$ 
where $V$ is the subspace of sections vanishing on the ramification locus. It is (at least intuitively) quite clear to me that in the linear system $|\pi^\ast O(3)|$ we must get the system of double covers of the plane cubics. But I don't really understand the "" $\oplus V$ "" part. If somebody could elaborate on this, I would highly appreciate.",['algebraic-geometry']
698700,What's the proper graph representation for a category prices trends in time?,"As I'm not a mathematician I thought I'd ask here for advice how to approach something I'm working on (probably a basic question for a lot of you guys, but it was a subject of a debate at my work earlier) We have this graph: and here we're trying to show the prices trend for products in ""Shoes"" category, for the last year. Every week we extracted the average discount for the ending week, for all the products available at that time in the ""shoes"" category, and now we put them in this graph. For example during the week ending on 30 June 2013 we had an average discount of 9%. This graph shows us very easily the price trends, the discounts periods, the discounts magnitude, for the last year, but it is also misleading because comparing the starting point with the ending point it states that overall we had a discount of almost 50%, which is not true all the time (because new products arrived with bigger prices, and the discounted ones have been sold).
Is there any better graph representation, so we keep the price trending but not to mislead with the values? What We've tried In order to make it more understandable by the users I've generated a second graph to show the discounts level evolution (summed up for 4 continuous weeks, you can see it at http://vetements-et-chaussures.franceprix.fr/#evolution_prix , the second graph) but the discounts level graph doesn't actually really picture the big picture of the prices general trend (like in our first graph). Any suggestions how a problem like this could be approached? All ideas are more than welcome.",['statistics']
698735,"Definition of ""the surface measure""?","Let $\mu_n$ be the $n$-dimensional Lebesgue measure. Let $||\cdot||$ be a norm on $\mathbb{R}^n$. Define $S^{n-1}=\{x\in\mathbb{R}:||x||=1\}$. I have proven that $\forall A\in\mathscr{B}_{S^{n-1}}, (0,1]A\in \mathscr{B}_{\mathbb{R}^n}$. ($\mathscr{B}$ denotes the Borel-algebra and $(0,1]A$ is defined as $\{rb:r\in(0,1] , b\in A\}$) Define $\sigma(A)=n\mu_n((0,1]A), \forall A\in\mathscr{B}_{S^{n-1}}$ Then, $\sigma$ is a measure. Is this ""the surface measure"" or the completion of $\sigma$ the surface measure?","['polar-coordinates', 'measure-theory', 'real-analysis', 'definition']"
698738,Weak Laplacian of $\|x\|^\alpha$,"Let $\alpha> 0$ and consider the function $\|\mathbf x\|^\alpha = (x^2 + y^2)^{\frac{\alpha}{2}}$ defined on $\mathbb R^2$. I want to compute the Laplacian $\Delta (\|\mathbf x\|^\alpha)$ in the sense of distributions. If $\alpha \geq 2$ the function is differentiable and we get $\Delta (\|\mathbf x\|^\alpha) = \alpha^2 \|\mathbf x\|^{\alpha -2}$. Does this formula hold in general? From the fact that $\|x\|^{\alpha}$ is smooth outside the origin the above formula should hold on $\mathbb R^2 \setminus \{0\}$, but what about the singularity at $0$?","['multivariable-calculus', 'distribution-theory', 'weak-derivatives', 'partial-differential-equations']"
698768,A beautiful inequality for convex functions,"Let $f\in \mathcal{C}([0,1],\mathbb R_+)$ increasing. Prove that there exist  $g,h\in \mathcal{C}([0,1],\mathbb R)$, convexs, such that $g\leqslant f \leqslant h$ and :
  $$\displaystyle \frac{1}{2}\int_0^1 h \leqslant \int_0^1 f \leqslant 2\int_0^1 g$$ Let $H$ the Heaviside function : $f\leq g$ $=1$ for $x\geq0$ and $0$ for $x<0$ and $V(x) = x H(x) = \max(x,0)$. Let $f$ increasing positive, let $N\geq1$ and $\delta_j = f(\frac jN) - f(\frac{j-1}N)$ for $1\leq j \leq N$, Thus,
$$f_N(x) = f(0) + \delta_1 H\Big(x - \frac 1 N\Big) + \delta_2 H\Big(x - \frac 2 N\Big) + \dotsb + \delta_{N-1} H\Big(x - \frac{N-1}N\Big)$$ The function $f_N$ is bounded above by $f$ (winch is increasing positive). And,
$$\int_0^1 f(u)\,du - \int_0^1 f_N(u)\,du \leq \frac1N(f(1) - f(0))$$ Now, define :
$$ \begin{split} g_N(x) = f(0) + \delta_1\Big(1-\frac 1 N\Big)^{-1} V\Big(x- \frac 1 N\Big) &+ \delta_2\Big(1-\frac 2 N\Big)^{-1} V\Big(x-\frac 2 N\Big) \\ &+ \dotsb + \delta_{N-1} N V\Big(x- \frac{N-1}N\Big)\end{split} $$ Therefore, $g_N$  is convex, and $g_N(x) \leq f_N(x)$. Then : $$\forall x, \quad g_N(x) \leq f(x)  $$ \begin{align*} \int_0^1 g_N(u)\,du &= f(0) + \frac 1 2\delta_1 \Big(1 - \frac 1 N\Big) + \frac 1 2\delta_2 \Big(1 - \frac 2 N\Big) + \dotsb +\frac 1 2 \delta_{N-1} \frac 1 N\\ 
\int_0^1 f_N(u)\,du &= f(0) + \delta_1 \Big(1 - \frac 1 N\Big) + \delta_2 \Big(1 - \frac 2 N\Big) + \dotsb +\delta_{N-1} \frac 1 N \\ \end{align*} Therefore, \begin{align*}\int_0^1 f(u)\,du &\leq 2(\int_0^1 g_N(u)\,du - f(0)) + f(0) + \frac1N\big(f(1) - f(0)\big)\\ 
\int_0^1 g_N(u)\,du &\geq \frac 1 2\int_0^1 f(u)\,du + \frac 1 2 f(0)-\frac 1{2N}(f(1)-f(0)) 
\end{align*}. Then $ \int_0^1 f \leqslant 2\int_0^1 g$. How can I do for the second inequality ? Thanks in advance,","['alternative-proof', 'convex-analysis', 'inequality', 'integration']"
698802,Finding function given its Jacobian and the initial condition,"Consider continuously differentiable function $f:\mathbb{R}^k\mapsto \mathbb{R}^k$. We know that $f(x_0)=y_0$ and the Jacobian matrix is given for all $x$. I'd like to know the explicit for of the function $f$? If $k=1$, then I could know the explicit for of $f$ is able to be determined using the following method: Note that $f(x)=\int_{x_0}^xf^\prime(t)dt+c$ for some $c$. Then we can find $c=y_0$ by substituting $x$ with $x_0$. So, the explicit for of $f$ is $f(x)=\int_{x_0}^xf^\prime(t)dt+y_0$. However, I found when $k>1$. Any suggestion? Thanks for any help.","['multivariable-calculus', 'ordinary-differential-equations', 'functional-analysis']"
698813,Sequences of Rationals and Irrationals,"Let $(x_n)$ be a sequence that converges to the irrational number $x$. Must it be the case that $x_1, x_2, \dots$ are all irrational? Let $(y_n)$ be a sequences that converges to the rational number $y$. Must $y_1, y_2, \dots$ all be rational? This was one of my midterm questions yesterday and I just wanted to clarify my responses. For (1), I said NO and as a counterexample, gave the sequence $$
(x_n) = (3, 3.1, 3.14, 3.141, 3.1415, \dots)
$$ that converges to $\pi$ (note that each $x_j \in \mathbb{Q}$ since it is a finite decimal expansion). For (2), I said YES but was not sure how to prove it. Could anyone verify these responses and if I'm correct about (2), offer a proof for why it must be true.","['sequences-and-series', 'rational-numbers', 'solution-verification', 'irrational-numbers', 'real-analysis']"
698827,Factor $x^4+1$ over $\mathbb{R}$,"Factor $x^4+1$ over $\mathbb{R}$ Well, I read this question first wrongly, because the reader is about complex analysis, I did it for $\mathbb{C}$ first. I got. $x^4+1=(x-e^{\pi i/4 })(x-e^{3 \pi i/4})(x-e^{5\pi i/4})(x-e^{7\pi i/4})$. My teacher told me that there is very smart way to do this for $\mathbb{R}$ that we already learned. But I only can think of trial and error kind of methods.","['factoring', 'complex-analysis', 'polynomials']"
698853,Is my understanding of the Central Limit Theorem correct?,"Have I got this correct - Say we have a population. We take a random sample of size $n$ from this population. I.e. we form a sample $S$ based on random variables $X_1, X_2, ..., X_n$ taken from this population. So the sample $S$ is a set consisting of of these random variables, and hence the mean of the sample $\overline X$ will be a function of these random variables. The distribution of $\overline X$ will be approximately normal. And if we keep taking samples infinitely, and standardizing $\overline X$ by taking $$h(x) = \frac{\overline X - \mu}{\frac{\sigma}{\sqrt{n}}}$$ the limiting distribution of $h(x)$ will be $N(0, 1)$. Is my understanding correct here?","['statistics', 'normal-distribution', 'central-limit-theorem', 'probability']"
698865,Contraction of compact sets,"I am trying to solve the following problem. Let $X$ be a compact Hausdorff space and let $f:X\to X$ be continuous.
  Show that there exists a non-empty set $A\subset X$ such that
  $f(A)=A$. There is a hint to define $A=\cap_{n\ge 0} A_n$ with $A_{n+1}=f(A_n)$ and $A_0=X$. Then $x\in A_{n+1}$ implies that $f^{-1}(x)\cap A_n\ne\emptyset$. Right? So if $f^{-1}(x)\cap A_n=\emptyset$ then $x\notin A_{n+1}$. Is this correct? First I need to show that for $A$ defined in the hint it holds $f(A)=A$. For this to happen it is enough to have $f(A)=\cap_{n\ge 0} f(A_n)$ Because then $f(A)=\cap_{n\ge 1} A_n=\cap_{n\ge 1} A_n\cap X=A$. But got stuck proving the equality. What I did for that is to assume that there exists $x\in A$. This means that $\exists y_n\in A_n$ such that $f(y_n)=x$ for all $n$. Is this enough to deduct that $f(x)\in A$? Then I need to show that $A$ is not empty. For this I think it is enough to show that $A_{n+1}\subset A_n$, because $A_n$ are compact and then their intersection is not empty. However I am stuck there too. I tried by contradiction assuming $\exists x\notin A_n$ with $f(x)\in A_{n}$, but I cannot work from there. Initially I thought of something else. Choose $x_n\in A_n$ and create the sequence $\{x_n\}$. This has a convergent subsequence $\{x_{n_k}\}$. Then I create a sequence $\{x'_m\}$ by defining $x'_m=x_{n_k}$ with $n_k=\max\{j\in\{n_k\}|j\le m\}$. So basically i repeat the terms of the subsequence to get a convergent sequence. However this again requires that $A_{n+1}\subset A_n$ so I have $x'_m\in A_m$. Then I think that the limit $x'_m\to x$ is in $A$ but I was not able to show that also. Thanks in advance.","['general-topology', 'compactness']"
698904,"Power set of set containing empty set, sets of empty set, and mixes of the former","The title might be sort of confusing. The set is an infinite set like
$$
A = \{
\emptyset, \{ \emptyset \}, \{ \{ \emptyset \} \}, ...
\{ \emptyset, \{ \emptyset \} \}, \{ \{ \emptyset \}, \{ \{ \emptyset \} \} \}, ...
...
\}
$$
And it could be defined by the following rules #1: ∅ ∈ A #2: if a ∈ A, {a} ∈ A #3: if a ∈ A and b ∈ A, a ⋃ b ∈ A Consider a subset of 2 elements of A, like {x, y} ⊂ A, say, x ∈ A and y ∈ A, so {x} ∈ A and {y} ∈ A (#2), then {x} ⋃ {y} ∈ A (#3), as a result {x, y} is also an element of A. Similar deductions could be applied to subsets of 3 or even more elements. But that should have no chance according to Cantor's theorem . What mistakes I've made and what is the power set of A?",['elementary-set-theory']
698908,Determine the distribution underlying several given scores and their percentiles,"I am trying to build a FICO score calculator that estimates one's FICO score given one's percentile from another credit report.  FICO score data is kept fairly secret, but the following information is publicly available for 2012: A score of 750 had a percentile of 62.8% A score of 800 had a percentile of 81.7% A score of 850 had a percentile of 95.5% The average score was 689. The median score was 723. I tried to guess the standard distribution using Z-scores for the known data in combination with Excel's NORMSDIST function.  The ""Percentile"" row below is calculated with NORMSDIST while the ""Actual"" row reflects the percentiles listed above: The problem I ran into is this: when I approximate the standard deviation needed to place one of the given data points in the correct percentile, this results in incorrect percentiles for the other given data.  This indicates that the known score/percentile data do not fit the standard normal distribution.  How do I find a distribution that fits the given data?","['statistics', 'standard-deviation', 'statistical-inference', 'percentile']"
698913,Order of automorphism group,"I have this tiny question that I just can't figure out: Let $G$ be the dihedral group of order 8. Show that Aut($G$) is a $2$-group. I know that there is a general way to calculate the order of the automorphism group of a dihedral group, so the order in fact can be calculated to be $8$. But that is not how this question is supposed to be answered. Instead, I am given the hint that I can use the fact that the automorphism group of a cyclic $2$-group is a $2$-group. I know that $G$ has a cyclic $2$-group. So I guess the way to proceed is to assume that Aut($G$) is not a $2$-group and derive a contradiction via some coprime action argument. But I am not completely sure how to do this. Any ideas?","['finite-groups', 'group-theory']"
698917,Let $X$ be symmetrically distributed about 0. Show that $X$ and -$X$ are identically distributed,"Hello Mathematicians! The definition of being symmetrically distributed about zero means that the PDF (Continuous) or PMF (Discrete) $f(x) = f(-x)$. And the definition of being identically distributed is $$P(X \in A) = P(Y \in A)$$ for every $A \in \beta$, where $\beta$ is a sigma field. Actually, I don't see what to prove, because  Could you give any idea?","['statistics', 'probability']"
698919,What is the derivative of the expected value of a continuous random variable?,"Say we have a random variable $X$ , with density function $f(x)$ , and moment generating function $M(t) = E[e^{tX}]$ , and we take the derivative of $M(t)$ $$\frac{d}{dt} M(t) = \frac{d}{dt}E\left[e^{tX} \right] = E\left[\frac{d}{dt}e^{tX} \right]$$ I can see how this works in the discrete case, as we are bringing the derivative inside a summation and the derivative of sums is the sum of the derivatives. But why are we allowed to bring the derivative inside the integral in the continuous case? $$\frac{d}{dt}\int_X e^{tX}f(x)dx = \int_X \frac{d}{dt}[e^{tX}f(x)]dx$$ ?","['probability-theory', 'probability', 'real-analysis']"
698942,Prove that if $a$ is irrational then $\sqrt a$ is irrational,"Just hints but solution thx.
Any hints for me? 
I simply suppose that $a = \dfrac mn$ then $\sqrt a = \sqrt{\dfrac mn}$ But this does not make sense ..","['elementary-number-theory', 'irrational-numbers', 'discrete-mathematics']"
698961,"Finding the ""triangular root"" of a number. [duplicate]","This question already has answers here : Formula for the $n$th term of $1, 2, 2, 3, 3, 3, 4, 4 ,4, 4, 5, ...$ (4 answers) Closed 7 years ago . A triangular number is a number that is the sum of the natural numbers up to some $n$. The closed form is $x = \frac{n(n+1)}{2}$. How do I get $n$ on one side? I've been looking at it from every angle, and I can't find out how. Any help?",['algebra-precalculus']
698964,solve a trigonometric equation $\sqrt{3} \sin(x)-\cos(x)=\sqrt{2}$,"$$\sqrt{3}\sin{x} - \cos{x} = \sqrt{2} $$
I think to do :
$$\frac{(\sqrt{3}\sin{x} - \cos{x} = \sqrt{2})}{\sqrt{2}}$$
but i dont get anything.
Or to divied by $\sqrt{3}$ :
$$\frac{(\sqrt{3}\sin{x} - \cos{x} = \sqrt{2})}{\sqrt{3}}$$",['trigonometry']
698965,How prove this set isn't dense?,"I want to prove this set $M=\{U \in X ,\  \|U\|\le 1\}$  isn't dense in $X =C[a,b]$. Can you help me?","['functional-analysis', 'functions']"
698988,"For what reason, the surface measure represents the surface area?","Let $||\cdot||$ be a norm on $\mathbb{R}^n$ (It's an arbitrary norm, not 2-norm) Define $S^{n-1}=\{x\in\mathbb{R}^n : ||x||=1\}$ Let $\mu$ be the n-dimensional Lebesgue measure. Define $\sigma(E)=n\mu((0,1]\cdot E), \forall E\in\mathscr{B}_{S^{n-1}}$ This measure $\sigma_{n-1}:\mathscr{B}_{S^{n-1}}\rightarrow [0,\infty]$ is said to be the surface measure on $S^{n-1}$. (It has a property that $\mu(\Phi^{-1}(A\times B))=(\int_A r^{n-1}dr)\cdot\sigma_{n-1}(B)$ where $\Phi:\mathbb{R}^n\setminus\{0\}\rightarrow (0,\infty)\times S^{n-1}:x\mapsto (||x||,\frac{x}{||x||})$ is a homeomorphism and $A\in\mathscr{B}_{(0,\infty)}$ and $B\in\mathscr{B}_{S^{n-1}}$) I'm curious to know, for what reason this $\sigma_{n-1}$ represents the usual sense of the area of a surface, and why is it defined in a such way? why $n$ is multiplied? It may have a geometrical meaning. For example, when $||\cdot||$ is the max-norm, $\sigma_2(S^2)=24$. This is the ""intuitive"" area of the surface of a cube of length 2. Another example, when $||\cdot||$ is the 2-norm, $\sigma_2(S^2)=4\pi$. This is also the usual sense of the area of the surface of a ball. I wonder why this result is not really surprising,  but rather it has to have these values. I have another question whether there is a way to expand this idea of measuring the surface of a given measurable set,(e.g. area of the surface of a star-shaped subset, which cannot be represented as $S^{n-1}$) but i think it deserves another post..","['geometry', 'motivation', 'measure-theory', 'real-analysis', 'lebesgue-measure']"
698990,Local time of fractional Brownian motion,"For BM, there is a downcrossing representation of the local time at 0. Namely, $L_t(0)=\lim_2 (b_i-a_i)D(a_i,b_i,t)$, where $D$ is the number of downcrossing between level $b_i$ and $a_i$. I am wondering whether there is a similar representation for local time of fBm using  downcrossing. I only found some results for stationary gaussian process and semi-martingales. But for fBm, it doesn't work.  I tried to mimic the proof for BM, but due to the dependence of the increase of fBm, I am stuck. Could anyone please give me any hint about this? Or how is the research going for this problem? It will be greatly appreciated.","['probability-theory', 'stochastic-processes', 'brownian-motion']"
698999,Constructing a probability function from its moments.,"My intuition tells me that if we have a random variable that follows a Probability Mass Function (PMF) and that can take $n$ different values, then if we have the $n^{th}$ first moments we can reconstruct the original PMF. Is it true? How can we perform such thing? For example, what is the PMF which can take only 5 different values and which $5^{th}$ first moments are [1, 0.5, 0.4, 0.3, 0.2]? Similarly could we define the infinite set of Probability Density Functions (PDF) which correspond to a list of $n$ first moments? How can we do such thing? For example what is the infinite set of PDF which $5^{th}$ first moments are [1, 0.5, 0.4, 0.3, 0.2]?","['probability-theory', 'probability-distributions', 'probability']"
699003,Find the product of the series? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Can anybody please help me to evaluate the following product? $$\prod_{n=2}^\infty\dfrac{n^3 - 1}{n^3 + 1} $$","['sequences-and-series', 'calculus', 'infinite-product']"
699011,Find a limit of the recursive sequence,"The task is to prove sequence convergence and find a limit.
$x_0=0$
$x_1=1$
$x_{n+1}=\frac {x_n + n \cdot x_{n-1}} {n+1}$ I have computed some values of a sequence to build up some idea of the data:
elements with even indexes converge from 0 to ~0.68, and elements with odd indexes converge from 1 to the same value. It's obvious that the sequence isn't monotonic, hence I had to stick with a Cauchy theorem. But it led me nowhere:
$|x_{n+p}-x_{n}| < | \frac {n \cdot x_{n-1}} {n + 1} + 2 \cdot \sum_{i=n}^{2n-2} x_i + { \frac {x_{2n-1}} {2n} } |$
(I got there under the assumption that $n = p$.) Then I tried another move:
$x_{n+1} - x_{n} = \frac {x_n + n \cdot x_{n-1}} {n+1} - x_n = $ $= \frac {-n \cdot ( x_n - x_{n-1})} {n+1}$ $x_{n} - x_{n-1} = \frac {(1-n) \cdot (x_{n-1} - x_{n-2})} {n}$ It looks like progress, but I still don't know how to go next.","['sequences-and-series', 'cauchy-sequences', 'limits']"
699030,Can conditional distributions determine the joint distribution?,"Can conditional distributions determine the joint distribution? For example, let $X_1, \dots, X_n$ be random variables. Can their joint distribution be determined from the conditional distribution of $X_i$ given others, $i=1, \dots, n$? Can their joint distribution be determined from other types of conditional distributions, such as the type of $P(X_i|X_j)$, and/or the type of $P(X_i, X_j | \text{others})$, and/or other types? Thanks!",['probability']
699088,Finding the radius of convergence for $\sum n^p z^n$ (Proof Verification),"Goal: Find the radius of convergence for the following complex power series: $$
\sum n^p z^n
$$ Attempt: We have by Hadamard's formula for the radius of convergence that the complex power series $\sum a_n z^n$ converges if $|z| < R$ s.t. $$
R = \frac{1}{\underset{n \rightarrow \infty}{\limsup} |a_n|^{1/n}}
$$ Then we here have that $a_n = n^p$ for all $n \in \mathbb{N}$. Then applying Hadamard's formula we obtain that $$
R = \frac{1}{\underset{n \rightarrow \infty}{\limsup} |n^p|^{1/n}}
$$ Then since $$
\underset{n \rightarrow \infty}{\limsup} |n^p|^{1/n} = 1
$$ no matter the value of $p$, we have that $R = 1$. Is this correct?","['proof-verification', 'complex-analysis', 'analysis']"
699128,$\mathbb{Q}(i)$ has no unramified extensions,"It is a classical result that every extension of $\mathbb{Q}$ is ramified. Put differently: there are no unramified extensions of $\mathbb{Q}$ . The classical proof follows from the following two statements: (a) The only number field having discriminant $1$ is $\mathbb{Q}$ itself. (b) A prime number $p$ ramifies in a number field $K$ if and only if it is a divisor of the discriminant $\Delta_K$ . Is it possible to argue for something similar for $\mathbb{Q}(i)$ ? The goal of my question is to construct an example of a Hilbert Class Field without appealing (yet) to Artin Reciprocity. Using Artin Reciprocity, one has that $Gal(L/\mathbb{Q}) \cong Cl(\mathbb{Q})$ , where $L$ is the Hilbert Class Field of $K=\mathbb{Q}$ . Now, because $\mathbb{Z}$ is a PID, the class group becomes trivial, and we have that $L=\mathbb{Q}$ . Since $L$ is by definition the maximal unramified abelian extension of $K=\mathbb{Q}$ , this implies that there are no unramified extensions of $\mathbb{Q}$ . Repeating the argument (and observing that $\mathbb{Z}[i]$ is a PID), one deduces that the Hilbert Class Field of $K=\mathbb{Q}(i)$ is $L=\mathbb{Q}(i)$ . But this just means that $\mathbb{Q}(i)$ has no unramified extensions. However, I would like to have a proof from scratch which argues that $\mathbb{Q}(i)$ has no unramified extensions. EDIT: My question seems related to this MO post but I am having trouble following the argument there.","['class-field-theory', 'algebraic-number-theory', 'abstract-algebra']"
699145,Reading advice for Advanced Calculus by Loomis and Sternberg,"I am a math major currently in my sophomore year. I have a sound base in one variable calculus and basic linear algebra. I am currently doing a course in multivariable calculus. I have completed reading Calculus by Apostol Vol 1 and 2 and reached nearly half-way through Baby Rudin. I am currently thinking about reading Advanced Calculus by Loomis and Sternberg mainly because of its vast table of contents and applications in Classical Mechanics (I am a physics minor too). After going through the first few chapters lightly, I am certain that it would take a whole semester to complete this book. My question is: Is it worth spending the whole semester (5 months) in this book?","['multivariable-calculus', 'calculus']"
699172,Non-isomorphic Group Structures on a Topological Group,"Which Topological Groups Have a Unique Group Structure (up to isomorphism)? I know that there are many non-isomorphic finite groups of same order, so there are many group structures possible for discrete finite sets under discrete topology (in which case all functions will be continuous). On the other hand $\Bbb R$ and $S^1$  seem to have a unique group structure (addition and complex multiplication). (also see Group Structure on $\Bbb R$ ) So, basically what i want to know is that if $(X,.)$ and $(Y,.)$ are topological spaces with group operations $.$ then under what assumptions is it true that if $X$ is homeomorphic to $Y$(as a topological space) then $X$ isomorphic to $Y$(as a group)?","['general-topology', 'lie-groups', 'topological-groups', 'group-theory']"
699183,Help with the proof of the Witch of Agnesi curve,"$a=1$ (The radius is 1).
How do I prove that if we talking about $P=(x,y)$, then:  $$y=\frac{8}{x^2+4}$$
I'd like to get any help! Thank you!","['trigonometry', 'algebraic-geometry', 'calculus']"
699186,"The minimal sufficient statistic is not unique, but the minimal sufficient partition is unique, what does this mean?",Can anyone help to illustrate the statement with some examples?,"['statistics', 'probability']"
699211,"General approach to puzzles such as the ""$6$ books puzzle""","Six different books $(A,B,C,D,E,F)$ of identical size are stacked as in the figure. We know $A$ and $D$ are not touching. $E$ is between two books which are both vertical or both horizontal. $C$ touches exactly two books. $A$ and $F$ touch. Question: If in addition we know $E$ and $F$ touch along their cover (long side), how many books will have their positions known? Moreover, is there a general approach to such questions? I did not see how to use adjacency matrix to much benefit.","['puzzle', 'discrete-mathematics', 'recreational-mathematics']"
699224,Finding Radii of Convergence for $\sum a_n z^{2n}$ and $\sum a_n^2 z^n$,"Setting: Let $\sum a_n z^n$ have radius of convergence $R$.  We have that $$
R = \frac{1}{\underset{n \rightarrow \infty}{\limsup} \left|a_n \right|^{1/n}}
$$ via Hadamard's formula for the radius of convergence. Question: What are the radii of convergence for (i) $\sum a_n z^{2n}$ and (ii) $\sum a_n^2 z^n$? Attempt for $\sum a_n^2 z^n$: For ease of notation, let $R_1$ and $R_2$ denote the radii of convergence for power series $\sum a_n z^{2n}$ and $\sum a_n^2 z^n$ respectively. From Hadamard's formula, we then have $$
R_2 = \frac{1}{\underset{n \rightarrow \infty}{\limsup} \left|a_n^2 \right|^{1/n}} = \left( \frac{1}{\underset{n \rightarrow \infty}{\limsup} \left|a_n \right|^{1/n}} \right)^2 = R^2
$$ But what about $R_1$?","['complex-analysis', 'analysis']"
699258,Prove ${k \choose k} + {k + 1 \choose k} + {k + 2 \choose k} + ... + {n \choose k} = {n + 1 \choose k+1}$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question I have the following problem at discrete maths subject on college.
Let's say that $k, n ∈ {0, 1, 2, 3, ...}$ and $k <= n$.
Prove the following:
${k \choose k} + {k + 1 \choose k} + {k + 2 \choose k} + ... + {n \choose k} = {n + 1 \choose k+1}$","['summation', 'discrete-mathematics', 'binomial-coefficients']"
699286,Probability Discrepancy in drawing 2 cards from a Deck of 52,"A colleague and I are having a hard time figuring out this probability question and was wondering if anyone could provide an explanation / insight into it. The question is simple: what is the probability if you draw 2 cards at the same time (so without replacement) from a standard deck of 52, that one of those cards, or both, is a diamond? He mapped out all the possible outcomes and came to $\frac{7}{16}$, by writing out the following: DD DH DC DS HD HH HC HS SD SH SC SS CD CH CC CS Since 7 out of those 16 outcomes have a diamond in them, that is the probability. Trying mathematically though, the answer is not equivalent. We both believe that the formula is not right, but we can't figure out where the problem is. This is the formula we've tried: $\displaystyle\frac{{13\choose{1}}{39\choose1}}{52\choose{2}}+\frac{13\choose2}{52\choose2}$; the left term is for 1 diamond, another card different, and the right term is for 2 diamonds. This sum comes out to $\frac{15}{34}$ or approximately .44, which is close, but not exact to the answer we'd expect above. Which is correct - or where is the mistake? An explanation of the discrepancy would be much appreciated. Thanks a lot.","['card-games', 'probability']"
699370,Proving the AM-GM Inequality with Lagrange Multipliers,"Exercise: Let $x_1,x_2,...,x_n$ be real positive numbers. Prove the arithmetic-geometric mean inequality, $(x_1x_2...x_n)^{1/n}\le (x_1+x_2+...+x_n)/n$. Hint: Consider the function $f(x_1,x_2,...,x_n)=(x_1+x_2+...+x_n)/n$ subject to the constraint $x_1x_2...x_n=c$ a constant. My work: Consider $f(x_1,x_2,...x_n)=(x_1+x_2+...+x_n)/n$ on $S=\{(x_1,x_2,...,x_n) | x_1x_2...x_n=c\}$ $g(x_1,x_2,...,x_n)=x_1x_2...x_n-c=0$ $\nabla f(x_1,x_2,...,x_n)=(1/n,1/n...,1/n)$ $\nabla g(x_1,x_2,...,x_n)=(c/x_1,c/x_2,...c/x_n)$ $\nabla f = \lambda \nabla g$ $1/(n\lambda)=c/x_1=c/x_2=...=c/x_n$ $x_1=x_2=...=x_n=n\lambda c$ At the point $(n\lambda c, n\lambda c,... n\lambda c)$, $f$ on $S$ takes either a maximum or a minimum. $f(n\lambda c, n\lambda c,...,n\lambda c)=n(n\lambda c)/n=n\lambda c$ $(n\lambda c*n\lambda c*...*n\lambda c)^{1/n}=((n\lambda c)^n)^{1/n}=n\lambda c = f(n\lambda c, n\lambda c,...,n\lambda c)$ This shows the equality case. To prove the inequality, I want to show that at the point $(n\lambda c,n\lambda c,...,n\lambda c)$, $f$ on $S$ takes a maximum minimum . I tried proving that the Hessian is negative positive definite, but I had trouble working with the second derivatives. I've looked up various proofs for the AM-GM inequality. The Lagrange ones didn't make full sense to me, so I thought I would turn to MSE. Any ideas? Thanks!","['a.m.-g.m.-inequality', 'inequality', 'real-analysis', 'lagrange-multiplier']"
699377,Differentiation: exact or an approximation?,"I understand that a derivative of a function at a chosen input value describes the best linear approximation of the function near that input value. This makes sense, since we would take the limit of the interval over which the derivative is computed as the interval tends to zero. In other words, take the limit of the average rate of change as the interval over which the average is computed tends to zero. But I read today that ""differentiation is a method to find an exact value for the rate of change at any given value of $x$"". So is it a linear approximation or is it an exact value? Thanks.","['calculus', 'derivatives', 'limits']"
699381,SOLVED: Green's theorem result and line integral result are not equal! What am I doing wrong?,"I have this line integral: $\oint 3ydx+x^2dy$ and the path is a line from $(0, 0)$ to $(1, 0)$ (so this is $y=0$), another line from $(1, 0)$ to $(1, 1)$ (so this is $x=1$) and a curve $y=x^2$ from $(1, 1)$ to $(0, 0)$. Evaluating this integral using the line integral (and anticlockwise = positive): 1) $y=0$ gives $0$ 2) $x=1$ gives $0$ as well Edit: this gives actually $1$ 3) $y=x^2$ $dy=2xdx$ and substituing everything in gives $\oint 3x^2dx+x^2*2xdx=\oint 3x^2+2x^3dx$. The limits are from $1$ to $0$, so $\int_1^0 3x^2+2x^3dx=-1.5$ Adding everything gives $-1.5$ Edit: This becomes actually $-0.5$ Now using Green's theorem:
Finding the partial derivatives and substituing these into the Green's formula gives: $\int_0^1\int_0^{x^2}(2x-3)dydx=-0.5$ What am I doing wrong because obviously $-0.5 \neq -1.5$?
Edit: $-0.5 = -0.5$ Thanks!","['definite-integrals', 'multivariable-calculus', 'integration']"
699384,Nonconvex set converging to a convex set despite holes,"I'm looking at the example in Figure 4-7 of ""Variational Analysis"" (Rockafellar and Wets). Basically, there's a sequence of sets $C_{\nu}$ riddled with holes, and it states that the sequence eventually converges to the set $C$ (with the same shape but without holes) as long as the holes get finer and finer and thus vanish in the limit. If the holes vanish only in the limit, those $x$ in the center of the holes do not appear in $C_{\nu}$ infinitely many times, not even all but finitely many times. Indeed, they appear just once, i.e., for $\nu=+\infty$). Can anyone explain me why then $C_{\nu}$ is said to converge to $C$?","['optimization', 'functional-analysis', 'limits']"
699387,(Determinant of) Hessian in local coordinates,"Let $f\colon M\to \mathbb{R}$ be a smooth function on a manifold $M$ with a critical point $p$. We define its Hessian at $p$ via $H(u, v)=(UVf)(p)$ where $u, v\in T_pM$ and $U$ and $V$ are vector fields with $U_p=u, V_p=v$. I wonder if there is any way of computing the the matrix of Hessian other than using local coordinates. 
To make my question more concrete how do you go about computing the Hessian matrix of a real valued function defined on, say, a sphere? My other question is about the determinant of the Hessian. Hessian is a bilinear map and its matrices in different coordinates are congruent (not similar, in general). So, how can one make sense of the determinant of Hessian in a well-defined way? All I can say is that a distinguished inner product should be required on the tangent space at the critical point to make the determinant well defined. Any thoughts on this would be appreciated.",['differential-geometry']
699396,Closedness and convexity of half spaces $\mathbb{R}^n$ determined by hyperplanes,"Every hyperplane divides $\mathbb{R}^n$ into two ""half space"": the set of points ""on and above"" the hyperplace, $H^+ = \{ \mathbf{x} \mid \mathbf{a} \cdot \mathbf{x} \geq \alpha \}$, and the set of points ""on and below"" the hyperplace, $H^- = \{ \mathbf{x} \mid \mathbf{a} \cdot \mathbf{x} \leq \alpha \}$.  Prove that each of these two half spaces is a closed, convex set. Open Sets in $\mathbb{R}^n$ $S \subset \mathbb{R}^n$ is an open set if, for all $\mathbf{x} \in S$, there exists some $\varepsilon > 0$ such that $B_\varepsilon ( \mathbf{x} ) \subset S$. Closed Sets in $\mathbb{R}^n$ $S$ if a closed set if its complement, $S^c$, is an open set. I'm trying to prove the question above using the definitions provided in the textbook ( Advanced Microeconomic Theory by Jehle and Reny) that posed this question but I'm having trouble finding the required $\varepsilon$ such that you can draw a ball around every element in the complement of the closed half-space and that ball is still entirely contained in the complement of the closed half-space thereby proving that the complement of closed half-space is open, and the closed half space is indeed closed. Any proof that uses the above definition with regard to open and closed set is greatly appreciated.",['general-topology']
699402,Finding the second derivative; What am I doing wrong?,"Original Question: $xy+y-x=1$ Find the second derivative; $d^2y\over{dx^2}$$(xy+y-x=1)$ We are allowed to use either notation as far as I know: ${dy\over{dx}}$ or ${y'}$. Because ${dy\over{dx}}=y'$ according to my Math 1000 prof. $(xy)'+y'-x'-1'=0'$ $(y+xy')+y'-1=0$ $y'(x+1)-1+y=0$ $y'(x+1)=1-y$ $y'={1-y\over{x+1}}$ Now we're supposed to find $y''$ but, that's where I mess things up. Quotient rule: $y''={{(1-y)'(x+1)-(1-y)(x+1)'}\over[(x+1)]^2}$ $y''={{(-y')(x+1)-(1-y)(1)}\over[(x+1)]^2}$ $y''={{-({{1-y}\over{x+1}}){\cdot}(x+1)-(1-y)}\over{(x+1)^2}}$ $y''={{-(1-y)-(1-y)}\over{(x+1)^2}}={-2(1-y)\over{(x+1)^2}}={2(y-1)\over{(x+1)^2}}$ But, The answer is supposed to be ${y''={{y-1}\over{(x+1)^2}}}$ Why am I getting a 2? That's all I want to know. Also, I took out the unnecessary equal signs, my prof wants us to have those cause he's basically insane but, it's confusing everyone so I'm taking them out. The improper method! According to my prof: $(xy)'+y'-x'-1'=0'$ $(y+xy')+y'-1=0$ $y'+(xy')'+y''=0$ $y'+(y'+xy'')+y''=0$ $y''(x+1)=-2y'$ ${y''={{-2y'}\over{x+1}}}$ Plugin $y'$ and it's the same answer i'm getting. Supposedly the wrong one everywhere I've looked.","['implicit-differentiation', 'ordinary-differential-equations', 'derivatives']"
699433,Exercise 3.7 Hartshorne,"Problem. Show that any two curves in $\mathbb{P}^2$ have a nonempty intersection. This seems to follow immediately from the Projective Dimension Theorem, but I was wondering if anyone could provide a more 'elementary' proof? Thanks",['algebraic-geometry']
699471,Distinguished open sets in $\mathbb{P}^n$,"I have given a homogenous polynomial $F\in\mathbb{C}[x_0,\ldots,x_n]$ of degree $d>0$ and consider the open set $U_F=\{p\in\mathbb{P}^n; F(p)\neq 0\}$. I'd like to prove that $U_F$ is isomorphic to an affine algebraic variety. I've tried using the covering induced by the standard covering of $\mathbb{P}^n$ to construct an explicit morphism into an affine space, but have failed. What else should I try? Note that I have no machinery from scheme theory, so there should be a solution confined to the elementary notions above.","['algebraic-geometry', 'projective-geometry']"
699476,Relation between Right Riemann sum and definite integral,"Let a partition $\{t_0,\ldots,t_n\}$ of the interval $[a,b]$ and let $f$ an integrable function. (we may also assume that $f$ is differentiable on $[a,b]$) We know that the Right Riemann sum is $$R(f)=\sum_{i=1}^n f(t_{i})(t_i-t_{i-1})$$ What's the relation ( in order sense terms) between $R(f)$ and the integral $\displaystyle \int_a^b f(x)dx$? Can I say that there exists a positive constant $C>0$ such that $\displaystyle \int_a^b f(x)dx\leq C\cdot R(f)$? I know that if $f$ is increasing function, this is correct, but in the general case, i may say that? EDIT: Assume that $f(t)\geq 0$ on $[a,b]$","['definite-integrals', 'riemann-sum', 'integration', 'real-analysis']"
699484,Integral with absolut-value function,How do I seperate the following integral? The integral of $|x^2-y|$ with $|y| \leq 1$ and $|x| \leq 1$. I know that the absolute value is positive for $x^2 \geq 1$ and negative for $x^2$ but I am getting the wrong answer when I write them as a sum of integrals. I think I chose wrong bounds.,"['calculus', 'analysis']"
699505,"For all square matrices $A$ and $B$ of the same size, it is true that $(A+B)^2 = A^2 + 2AB + B^2$?","The below statement is a true/false exercise. Statement:
For all square matrices A and B of the same size, it is true that
$(A + B)2 = A^2 + 2AB + B^2$. My thought process: Since it is not a proof, I figure I can show by example and come to a valid conclusion based on such example. My work: Come up with a square matrix A and B let both be a 2 by 2 matrix(rows and cols must be same). Matrix $A$: $A = \begin{array}{ccc}
3 & 5 \\
4 & 6 \\
\end{array} $ Matrix $B$: $B =  \begin{array}{ccc}
5 & 8 \\
9 & 4 \\
\end{array} $ $A + B =  \begin{array}{ccc}
8 & 13 \\
13 & 10 \\
\end{array}$ $(A + B)^2 =  \begin{array}{ccc}
233 & 234 \\
234 & 264 \\
\end{array}$ $A^2 =  \begin{array}{ccc}
29 & 45 \\
36 & 56 \\
\end{array}$ $(AB) =  \begin{array}{ccc}
60 & 44 \\
74 & 56 \\
\end{array}$ $2(AB) =  \begin{array}{ccc}
120 & 88 \\
234 & 112 \\
\end{array}$ $B^2 =  \begin{array}{ccc}
97 & 72 \\
81 & 88 \\
\end{array}$ $A^2 + 2AB + B^2 =  \begin{array}{ccc}
246 & 205 \\
265 & 256 \\
\end{array}$ Based my above work, the answer is false. Is there another way to approach the problem? It seems like a lot of work needed to be done for a true/false question which raised my suspicion about whether there is a better way to look at the problem.","['matrices', 'linear-algebra', 'examples-counterexamples']"
699506,Fermat's Last Theorem with negative exponent,"FLT says that the Diophantine equation $a^n+b^n=c^n$ isn't satisfied by any triplet $(a,b,c)$ where $n\in\mathbb{N}$ and $n>2$. But what happens if $n\in\mathbb{Z}$ and thus can be negative? $\textbf{My first thoughts:}$ If we have a negative exponent coupled with a real $a^s$ we can re-write it as $1/a^{-s}.$ So if $n\in\mathbb{Z}$ then the FLT equation takes the rubbish form $$\frac{1}{a^n}+\frac{1}{b^n}=\frac{1}{c^n}$$
which means $$\frac{a^n+b^n}{(ab)^n}=\frac1{c^n}$$
$$\frac{(ab)^n}{a^n+b^n}=\frac{c^n}1$$
$$(ab)^n=(ac)^n+(bc)^n$$
$ab$, $ac$ and $bc$ are all elements of the integer set commonly denoted as $\mathbb{N}$, we thus arrive at a Diophantine equation that is equivalent to the first one we've seen. Therefore the Diophantine equation $a^n+b^n=c^n$ isn't satisfied by any triplet $(a,b,c)$ where $n\in\mathbb{Z}$ and $\mathbf{\color{red}{|n|>2}}$ where $|x|$ is the absolute value of the number $x$. Is my proof correct? Furthermore, what happens when the triplet $(a,b,c)\in\mathbb{Z}^3$?",['number-theory']
699514,An immersive map is locally left invertible,"Question: Suppose that $m < n$, that $U$ is an open set in $\mathbb R^m$ and that $f : U \rightarrow \mathbb R^n$ is a $C^1$ function that has rank $m$ everywhere in $U$. Show that for every $x$ in $U$ there is a neighborhood $V$ of $f(x)$ and a $C^1$ function $\tilde f : V \rightarrow \mathbb R^m$ that is a left inverse of $f$ in $V$ (that is, $\tilde f\circ  f$ is the identity on $V$). I do not understand the last sentence of this question. What does it mean by identity on $V$? Shouldn't the domain of $\tilde f\circ f$ is at least in $\mathbb R^m$ instead of $V$ which is in $\mathbb R^n$? Which of the following two is correct, please? $(\tilde f\circ f)(x^1,\cdots, x^m)=(x^1,\cdots, x^m)$; or $(\tilde f\circ f)(x^1,\cdots, x^m)=(x^1,\cdots, x^m, 0, \cdots, 0)$. In addition, I started with trying constant rank theorem, but it did not seem to work since rank theorem only change coordinates in $\mathbb R^m$ and $\mathbb R^n$ without connecting them. Any hint, please?","['differential-topology', 'multivariable-calculus', 'differential-geometry']"
699535,To say that the sequence $a_n$ is “bounded above” is to say what?,"This is a homework question for the coursera course Calculus 2 Sequences and Series offered by Jim Fowler at Ohio State To say that the sequence $a_n$ is “bounded above” is to say what? For all $M\in \mathbb{R}$, there exists an $n\in \mathbb{N}$, so that $a_n \ge M$. There exists an $M\in \mathbb{R}$, so that for all $n\in \mathbb{N}$, we have $a_n \ge M$. For all $n\in \mathbb{N}$, there exists an $M\in \mathbb{R}$, so that $a_n \ge M$. For all $n\in \mathbb{N}$, there exists an $M\in \mathbb{R}$, so that $a_n \le M$. There exists an $M\in \mathbb{R}$, so that for all $n\in \mathbb{N}$, we have $a_n \le M$. I am split between choice number 4 and choice number 5.  I am having trouble determining how these choices are different.  Does choice number 4 suggest that $M$ can be a different number for each $n \in \mathbb{N}$? Thanks in advance for your help Edit:
Here is the definition of bounded above given by the text: Deﬁnition: A sequence ($a_n$) is bounded above if there is some number
  $M$ so that for all $n$, we have $a_n \le M$. Likewise, a sequence
  ($a_n$) is bounded below if there is some number $M$ so that for every
  $n$, we have $a_n \ge M$. If a sequence is both bounded above and
  bounded below, the sequence is said to be bounded.","['sequences-and-series', 'calculus']"
699540,Checking the equivalence relations of sets,"$S=\{0,1,2,3\}, R:SxS, (m,n)\in R \text{ if } m+n=4$. From the condition of $R$, I found that $R=\{(2,2),(1,3),(3,1)\}$. Now I have to see if $R$ is reflexive, symmetric, antisymmetric, and transitive. $R$ is not reflexive because $(0,0), (1,1), (3,3) \not\in R$. $R$ is symmetric because $(1,3), (3,1)\in R$. $R$ is not antisymmetric because $(1,3), (3,1)\in R$ and $1\not=3$. $R$ is not transitive because $(1,1)\not\in R$. I am not really sure if  I did this correctly. Specifically the showing that $R$ is transitive. $R$ is transitive whenever $(a,b)\in R \text{ and } (b,c) \in R$, then $(a,c) \in R \text{ for all } a,b,c \in A$. Does it matter that $(2,2) \in R$? Also did I do the others correctly?","['relations', 'equivalence-relations', 'discrete-mathematics']"
699550,Mean and variance of truncated generalized Beta distribution,"The generalized Beta probability density function is given by: $$f(x) = \frac{(x-A)^{\alpha - 1} (B-x)^{\beta - 1}}{(B-A)^{\alpha + \beta - 1} \mathrm{B}(\alpha ,\beta)}$$ for $A<x<B$, and $f(x) = 0$ otherwise. Here $\alpha>0$ and $\beta>0$. Let $g(x)$ be a  truncated version of this distribution in the interval $[a,b]$, where $A\le a \le b \le B$. That is, $g(x)\propto f(x)$ if $a\le x\le b$, with a proportionality constant that normalizes $g(x)$, and $g(x)=0$ otherwise. Write explicit formulas (without integrations or infinite sums; you can use special functions) for the first and second moments of $g(x)$: $$\langle x \rangle_g = \int_{-\infty}^\infty x g(x)\mathrm{d}x$$ $$\langle x^2 \rangle_g = \int_{-\infty}^\infty x^2 g(x)\mathrm{d}x$$","['special-functions', 'probability']"
699562,How to build a compact support for a function,"I was wondering if it is possible to build a distribution with compact support from a function. More precisely, consider a compact set $\mathbf{K}\subset\mathbb{R}^2\setminus\{0\}$, and a function $h:\mathbb{R}^2\to\mathbb{R}^2$ of class $\mathcal{C}^1$ such that, for every $y\in\mathbf{K}$, $h(y)\neq0$. Then, if there exists a compact set $\widetilde{\mathbf{K}}\supsetneq\mathbf{K}$ the distribution
\begin{equation*}
	\tilde{h}(y)=\left\{\begin{array}{rcl}
					h(y),&\text{if}&y\in\mathbf{K},\\
					h(y)\exp\left(-\dfrac{|y|_\mathbf{K}^2}{\mathtt{dist}^2\left(y,\mathbb{R}^2\setminus\widetilde{\mathbf{K}}\right)}\right),&\text{if}&y\in\mathtt{int}\left(\widetilde{\mathbf{K}}\right)\setminus\mathbf{K},\\
					0,&\text{if}&\text{otherwise}\\
				\end{array}\right.
\end{equation*}
is such that $\mathtt{supp}(\tilde{h})=\widetilde{\mathbf{K}}$ and, for every $y\in\mathbf{K}$, $\tilde{h}(y)=h(y)$. Is this correct? Notation. $|y|_\mathbf{K}$ is the Hausdorff point-to-set distance: $|y|_\mathbf{K}:=\inf\{|x-y|:x\in\mathbf{K},y\notin\mathbf{K}\}$. Analogously, $\mathtt{dist}\left(y,\mathbb{R}^2\setminus\widetilde{\mathbf{K}}\right)$ is the is the Hausdorff point-to-set distance from $y$ to $\mathbb{R}^2\setminus\widetilde{\mathbf{K}}$. Thanks in advance.","['functions', 'distribution-theory', 'functional-analysis', 'real-analysis']"
699607,Help with a simple derivative,"I am trying to solve $\dfrac {6} {\sqrt {x^3+6}}$ 
and so far I made it to $6(x^3+6)^{-\frac 1 2}$ 
then I continued and now I have $(x^3+6)^{- \frac 3 2} * 3x^2$
and I cannot figure out what how to find the constant that should be before the parenthesis.","['calculus', 'derivatives', 'limits']"
699640,Determine the convergence of a sequence given by $a_n= \frac{a_{n-1} + a_{n-2}}2$,"let $a_0$ and $a_1$ be any two real numbers, and define $a_n= \dfrac{a_{n-1} + a_{n-2}}{2}$ Determine the convergence of a sequence. Alright, what I have so far. I have two cases $a_0$ > $a_1$ or $a_0$ < $a_1$ for $a_0 > a_1$ The sequence converges to $\frac{1}{3}$($a_0 - a_1$) + $a_0$ for $a_0 < a_1$ The sequence converges to $\frac{2}{3}$($a_1 - a_0$) +  $a_0$ Any additional input?","['convergence-divergence', 'sequences-and-series', 'real-analysis', 'recurrence-relations']"
699675,Determine the value of the integral $I=\int_{0}^{1}\frac{\ln\left(1-a^2x^2\right)}{\sqrt{1-x^2}}dx$,"Determine the value of the integral $$I(a)=\int_{0}^{1}\frac{\ln\left(1-a^2x^2\right)}{\sqrt{1-x^2}}dx, \: |a|\leq 1$$ My try: $\to I'(a)=\int_{0}^{1}\frac{-2ax^2}{\left(1-a^2x^2\right)\sqrt{1-x^2}}dx$ Set $x=\cos t\to dx=-\sin tdt$ Hence $I'(a)=\int_{0}^{\frac{\pi}{2}}\frac{-2a\cos^2t}{1-a^2\cos^2t}dt=\pi\left(\frac{1}{a}-\frac{1}{\sqrt{1-a^2}}\right)\to I(a)=\pi\left(\ln|a|-\arcsin a\right)+C$ Question: Find C?",['integration']
699730,Prove that the logarithmic mean is less than the power mean.,"Prove that the logarithmic mean is less than the power mean. $$L(a,b)=\frac{a-b}{\ln(a)-\ln(b)} < M_p(a,b) = \left(\frac{a^p+b^p}{2}\right)^{\frac{1}{p}}$$ such that $$p\geq \frac{1}{3}$$ That is the $\frac{1}{p}$ root of the power mean.","['inequality', 'analysis']"
699734,Number of moves to switch all tiles from black to red?,"Four tiles are arranged as per the diagram and all start off black. On each move, two connected tiles may be interchanged, and upon doing so each of the two tiles switches color from red to black or black to red depending on their current state. [As an example, swapping $a$ and $b$ would make them both red, and then swapping $a$ and $d$ would make $d$ red but make $a$ black again]. What is the minimum number of moves needed to change all the currently black tiles to red while still having them end up in the same position as they started? After playing around with it, I found the answer was 6. However, is there a more mathematical way to approach this? The only insights I could think of was that each tile must move an odd number of times for it to swap color.","['discrete-mathematics', 'contest-math']"
699735,"If I flip a coin $100$ times, why do the results trend towards $50-50$?","This sounds like a simple question, but here's the gist: Given a coin flip (or some other random process that can result in one of two outcomes) that has a perfect $50-50$ probability of landing on heads or tails (the probability of heads is $50\%$, the probability of tails is $50\%$), if I were to flip the coin 10 times, the results would be close to $5-5$. If I flip it $100$ times, the results would be close to $50-50$. The larger my sample size, the closer the results reflect the probability. But if I flip this coin once, there's a $50-50$ chance of landing on either heads or tails. The next time I flip the coin, the probability is the same. This means that each result of, say, $20$ flips would be equally likely ($8$ heads and $12$ tails and $10$ heads and $10$ tails would be equally likely). If this is true , why do the results of flipping a coin many times trend towards an equal split? If this isn't true, why not?",['probability']
699740,zero matrix to the power of 0,Why $0^0=I$? I'd tried prove that considering $N^0$ where N is a Nilpotent matrix and then using the Cayley -Hamilton theorem Thanks in advance.,"['matrices', 'linear-algebra']"
699746,Integral $\int_0^\pi \theta^2 \ln^2\big(2\cos\frac{\theta}{2}\big)d \theta$.,"I am trying to calculate $$
I=\frac{1}{\pi}\int_0^\pi \theta^2 \ln^2\big(2\cos\frac{\theta}{2}\big)d \theta=\frac{11\pi^4}{180}=\frac{11\zeta(4)}{2}.
$$
Note, we can expand the log in the integral to obtain three interals, one trivial, the other 2 are not so easy, any ideas?  We will use
$$
\left( \ln 2 +\ln \cos \frac{\theta}{2} \right)^2=\ln^2(2)+\ln^2\cos\frac{\theta}{2}+2\ln (2)\ln \cos\big(\frac{\theta}{2}\big)
$$ and re-write I as
$$
\pi I=\ln^2(2)\int_0^\pi \theta^2d\theta  +\int_0^\pi\theta^2 \ln^2 \cos \frac{\theta}{2}d\theta+2\ln 2 \int_0^\pi\theta^2 \ln \cos{\frac{\theta}{2}}d\theta.
$$
Simplfying this further by using $y=\theta/2$ we obtain
$$
\pi I=\frac{\pi^3\ln^2(2)}{3}+16\ln(2)\int_0^{\pi/2} y^2 \ln \cos (y) dy+8\int_0^{\pi/2} y^2 \ln^2 \cos (y) dy
$$
Any Idea how to approach these two integrals? I know that 
$$
\int_0^{\pi/2} \ln \cos y dy= \frac{-\pi\ln(2)}{2}\approx -1.08879
$$
but I am unsure how to use that here.  I do not think partial integration will work, Also the Riemann Zeta function is given by 
$$
\zeta(4)=\sum_{n=1}^\infty \frac{1}{n^4}=\frac{\pi^4}{90}.
$$
Thanks!","['integration', 'contest-math', 'definite-integrals', 'real-analysis', 'contour-integration']"
699760,"for $n$ an integer, why is $n^0=1$ ??","This is so going to cost me.... I was wondering why for any integer $n$: $n^0 =1$. Perhaps It's because $n$ is a round number and if $m$ is a non negative integer, also round then:
$$n^m = 1 \cdot n^m=1 \cdot \underbrace{n \cdot n \cdots n}_\text{m times}$$
So maybe if we set $m=0$ then:
$$n^m = n^0 = 1 \cdot n^0= 1 \cdot \underbrace{n \cdot n \cdots n}_\text{0 times} = 1$$
Maybe that is because an integer multiplied by it self $0$ times is really doing nothing. Wait so maybe $0$ multipled by $0$, $0$ times....? $$0^0 = 1 \cdot 0^0 = 1 \cdot \underbrace{0 \cdot 0 \cdots 0}_\text{0 times} = 1 \space\space??$$ $QED.$ If someone could prove to me (I'm trying) that $|x|^{|x|}$ is continuous in $\mathbb{R}$... Because we already know $lim_{x\to0}|x|^{|x|}=1$..","['absolute-value', 'algebra-precalculus', 'exponential-function', 'continuity', 'exponentiation']"
699774,Left Eigenvectors vs. Right Eigenvectors,"Suppose we have a matrix $A$ and a symmetric invertible matrix $D$ such that $DA$ is symmetric. 
The right eigenvectors of $A$ are $v_1,\cdots,v_n$ with eigenvalues $\lambda_1,\cdots, \lambda_n$.
Can we use this information to derive (or estimate) left eigenvectors/eigenvalues of $A$?","['linear-algebra', 'eigenvalues-eigenvectors']"
699816,"Number of common zeros of two quadratic polynomials in ${\Bbb C}[t,x]$","The following theorem is in Artin's Algebra (2nd edition): Theorem 11.9.10 Two nonzero polynomials $f(t,x)$ and $g(t,x)$ in two variables have only finitely many common zeros in ${\Bbb C}^2$, unless they have a common nonconstant factor in ${\Bbb C}[t,x]$. A comment after this theorem says that "" It is harder to prove the Bezout bound than the finiteness. We won't need that bound, so we won't prove it "". Then there is an exercise in the 1st edition: Prove that two quadratic polynomials $f, g$ in two variables have at most four common zeros, unless they have a nonconstant factor in common. Then in the 2nd edition, this exercise has been changed to the following one: Let $C_1$ and $C_2$ be the zeros of quadratic polynomials $f_1$ and $f_2$ respectively that don't have a common linear factor. (a) Let $p$ and $q$ be distinct points of intersection of $C_1$ and $C_2$, and let $L$ be the (complex) line through $p$ and $q$. Prove that there are constants $c_1$ and $c_2$, not both zero, so that $g=c_1f_1+c_2f_2$ vanishes identically on $L$. Prove also that $g$ is the product of linear polynomials. (b) Prove that $C_1$ and $C_2$ have at most $4$ points in common. I think (a) is supposed to be a hint to (b). But I don't see how I can make the implication. I guess I have to show that there cannot be too many $(c_1,c_2)$ as in (a), while such pairs might correspond to zeros of a polynomial of small degree. Here is my question : How can I prove (b) using (a)?","['ring-theory', 'algebraic-geometry', 'abstract-algebra', 'polynomials']"
699857,"For any sequence of $n$ integers, there exists a subsequence whose sum is divisible by $n$.","So I'm confused and stuck on how to approach this question. Any direction in the right path would be greatly appreciated. Let $n\in N$ . Prove that any sequence of $n$ integers $a_1, a_2, \ldots,a_n$ (no restriction on whether they are positive or negative, repetition is also possible), there exists a non-empty subsequence of consecutive integers such that their sum is divisible by $n$ . This subsequence could have any length from $1$ to $n$ . In other words, there exists two integers $i, j$ where $1\le i\le j \le n$ such that $\sum\limits_{k=i}^j$$a_k$ is divisible by $n$ . For example, when $n=5$ , the sequence $-12, 53, 3, 3, -44$ contains a subsequence $52, 3, 3, -44$ whose sum is $15$ , which is divisible by $5$ . Hint. Consider the $n$ sums of $a_1, a_1 + a_2, a_1 + a_2 + a_3, \ldots, a_1 + a_2, + \cdots + a_n$ . If any of these sums is divisible by $n$ , then we are done.  What happens if none of them is divisible by $n$ ?","['sequences-and-series', 'divisibility', 'elementary-number-theory', 'pigeonhole-principle', 'combinatorics']"
699864,perfect play in 1-dimensional Minesweeper,"In 1-dimensional Minesweeper with a known number of mines (that are distributed uniformly), is there a known somewhat-simple strategy for perfect play? When there are n cells and [0 or n-1 or n] mines, the strategy is utterly trivial. When there is 1 mine, the strategy is to choose an end cell and then every cell other than the obvious mine that was revealed. $\:$ While it is plausible that ""start at one end and go to the other, skipping obvious mines"" is always optimal, I certainly do not have a proof either way for that.","['algorithmic-game-theory', 'probability', 'algorithms', 'combinatorial-game-theory']"
699884,Definition of $Z_m$ is $[n] = \{x | x \equiv n \pmod m\}$?,"Any help or sort of input on this question would help a great deal. Thanks Let $m\in N$. Recall for any integer $n \in Z$, the definition of $[n]$ in $Z_m$ is 
$[n] = \{x | x \equiv n \pmod m\}$. Prove that $Z_m$, for any $a, b, \in Z$, either $[a] = [b]$ or $[a]\cap [b] = \emptyset$.","['congruences', 'elementary-set-theory']"
699886,Non analytic numbers,"We know that some real numbers (actually, most of them) are not algebraic and the proof of this fact is beautiful: algebraic numbers, like polynomials with integer coefficients, are countable, contrary to $\mathbb R$, hence there should be some non algebraic numbers. I was wondering if any real number $\alpha$ is ""analytic"", in the sense that it exists a power series $\displaystyle{ \sum_{n\geq 0} a_n(x-a)^n }$ of positive radius, with $a_n\in{\mathbb Q}$, and $a_n\in{\mathbb Q}$ for any $n\geq 0$, such that $\alpha$ is a root of $\displaystyle{ \sum_{n\geq 0} a_n(x-a)^n }$. Of course, the above proof for non algebraic number does not work, since power series are uncountable, but I would be surprised that the answer is no. In that case, is there a simple example and does it change something if we consider Laurent series instead of power series? Thanks in advance.","['real-analysis', 'number-theory']"
699889,Minimize an integral of a function and its derivative,"I'm trying to find the function $x(t)$ that minimizes the quantity $$\int_0^1 (x^2 +\dot{x}^2)dt$$ given that $x(0)=1$ and $x(1)$ is free (so I'm expecting the result to be a function of $x(1)$ itself). I am however utterly lost on this. One could say that the smallest value the integral could take is $0$, and therefore solve $x^2 +\dot{x}^2 = 0 \Rightarrow \dot{x}^2 = -x^2$, but this is an ODE that I find particularly weird (and even if it does make sense, I have no idea how to solve it). Any insight or solution would be greatly appreciated.",['ordinary-differential-equations']
699907,Is it true that subset D is dense in space X iff every nonempty open set in X contains one point of D,"I have a proposition that I am not sure if it is right: Let D be a subset of space X. D is dense in X if and only if every nonempty open set U of X contains at least one point of D. When X is a metric space, then I could verify that this is true in both directions. When X is a topological space, I could prove the ==> direction; however the <== direction is so difficult that I doubt the proposition is right. However, I cannot yet find a counter example. This proposition is the generalization of a property of real numbers R: Q is dense in R so every open interval of R contains a point of Q. Thank you.","['general-topology', 'real-analysis']"
699943,Find where the function $k(x):=|\sin(x)|$ is differentiable and calculate its derivative,"Find where the function$$k(x):=|\sin(x)|$$ is differentiable and calculate its derivative. I have started, by trying to make a function by parts, because of the absolute value, getting this:
$$k(x):=\left\{\begin{matrix}
 & \sin (x)& x>0 \\ 
 & (-1) \sin (x) &  x<0\\ 
 & 0 & x=0
\end{matrix}\right.$$ I have my doubts abut writing for $x=0$, but i really dont know hoy to do this excersice, can someone explain me and tell me how to write it correctly? The graph is like this:","['derivatives', 'real-analysis']"
699997,Complete Statistic: Uniform distribution,"Take a random sample $X_1, X_2,\ldots X_n$ from the distribution
$f(x;\theta)=1/\theta$ for $0\le x\le 
\theta$. I need to show that $Y=\max(X_1,X_2,...,X_n)$ is complete. Now, I know I should multiply the sample distribution of $Y$ and multiply it with a function of $Y$, then integrate over the range of $\theta$ and equate them to zero. But how do I get the sampling distribution of $Y$?","['statistics', 'uniform-distribution']"
700023,Injective analytic function,"Suppose $f: B(0,1) \rightarrow \mathbb{C}$ is an analytic function such that $f'(0)=1$ and $f'(z) \in B(1,1)$ for all $z \in B(0,1)$. Show that $f$ is injective.",['complex-analysis']
700050,When can we use Fubini's Theorem?,"I am using Munkres' Analysis on Manifolds textbook. Munkres defines Fubini's Theorem on rectangles and on simple regions (at least till the point that I have read). Now, according to the book, we cannot use Fubini's Theorem all the time because it is quite possible that Integral over a region exists but the iterated integral does not (because of problems with either of the single integrals), or the iterated integral exists but the function cannot be integrated over the region. From the exercises of the chapters, it seems that I need to apply Fubini's Theorem on rectifiable sets as opposed to simple regions and rectangles. My question is that if we know with certainty that the Integral exists over the region and we know that each of the single integrals in the iterated integral exist, then is it always true that the integral over the region will equal the iterated integral?","['multivariable-calculus', 'real-analysis', 'analysis']"
700078,Finding the order of an entire function defined from an integral,"The following problem is posed in Greene and Krantz, page 297, Problem 11. Let $g: \mathbb{R} \to \mathbb{C}$ be a continuous function, $\alpha \in \mathbb{R}$, and define $f: \mathbb{C} \to \mathbb{C}$ s.t. 
$$f(z) = \int^b_a e^{\alpha z t} g(t) dt .$$ Show that $f$ is entire and is of finite order. Determine whether or not the order of $f$ depends on $g$. I am able to show that $f$ is entire and of finite order. Intuitively, it seems to me that assuming $\alpha \neq 0$ and $g$ not identically $0$, $f$ should always be of order 1, but I can't show this nor find a counterexample. Insights would be appreciated.",['complex-analysis']
700083,Computing the closed subschemes of the projective line over a field,"(Specifically, this is III-15 in E&H, but I feel like I've hit a brick wall in actually applying the definitions they've given to this example.) In Chapter I of The Geometry of Schemes, E&H define the closed subscheme $Y \subseteq X$ associated to an ideal $I \subseteq R$ by quotienting $\mathscr{O}_X$ by the sheaf of ideals $\mathscr{J}$ induced by sending basic open sets $X_f \mapsto I \cdot R_f$, so that (denoting by $j$ the inclusion $|Y| \hookrightarrow |X|$) we have $j_*(\mathscr{O}_Y) = \mathscr{O}_X / \mathscr{J}.$ How do I show, using this definition, that the closed subschemes defined by the ideals $(x_0)$ and $(x_0^2,x_0x_1)$ consist of one point and are identical? (In particular, how can I figure out what $\mathscr{J}$ looks like by computing what the ideals look like under localization for each basic open set?) Any help would be greatly appreciated.","['commutative-algebra', 'algebraic-geometry']"
700094,"Projection $\pi : (x,y) \mapsto x$ of $V(y^2 - g(x))$ where g is cubic extends to a regular map of the projective closure","I'm supposed to prove that the map $\pi : (x,y) \mapsto x$ of $X = V(y^2 - g(x)) \subset \mathbb A^2$ where $g$ is cubic extends to a regular map of the projective closure $\overline \pi : \overline X \to \mathbb P^1$. The projective closure of X (I think) is $V(y^2z - \overline g(x,z))$ where $\overline g(x,z)$ is the homogenization of g ($x^3 + $ stuff in terms of x and z). Now the problem is that the naive projection isn't defined at the point $\overline \pi(0,1,0) = (0,0)$ isn't defined. I'm given a hint that I should consider changing the map to $(x,y,z) \mapsto (x^3, x^2z)$, but I don't know how that is supposed to help.",['algebraic-geometry']
700100,Evaluating $ \lim_{x \rightarrow 0}\left (\frac{\sin(x)}{x}\right)^\frac{1}{x^2}$,"I have got this problem on limits 
$$ \lim_{x \rightarrow 0}\left(\frac{\sin(x)}{x}\right)^\frac{1}{x^2}$$
What I am doing here is that taking log and then applying L-Hospital's Rule
$$y= \lim_{x \rightarrow 0}\left(\frac{\sin(x)}{x}\right)^\frac{1}{x^2}
$$
then $$\ln(y)=\lim_{x \rightarrow 0} \frac{1}{x^2}\ln\left(\frac{\sin(x)}{x}\right)$$ now it becomes $\frac{0}{0}$ type , but problem is how to take derivative here? when differentiating $\ln\left(\frac{\sin(x)}{x}\right)$ it will become $\frac{x}{\sin(x)}$ then we'll have to differentiate one more time like we do in case of $f(f(x))$ ? $\sin(x)$ and $x$ will be separately differentiated or together ?","['calculus', 'limits']"
700117,How to prove that $[G:xHx^{-1}] = [G:H]$ given $H \le G$?,"The problem is as follows: Let $G$ be a group and $H$ a subgroup of $G$ (i.e., $H \le G$); let $x$ be any element of $G$ (i.e., $x \in G$). To prove that $[G:xHx^{-1}] = [G:H]$. I am able to justify that the $xHx^{-1}$ is indeed a subgroup of $G$ (i.e., $xHx^{-1} \le G$) and that $|xHx^{-1}| = |H|$. To prove that $[G:xHx^{-1}] = [G:H]$, it is necessary to provide a bijective function $F$ between the set of (different, left) cosets of $H$ (denoted $S = \{ aH : a \in G \}$) and that of $xHx^{-1}$ (denoted $T = \{ a (xHx^{-1}) : a \in G\} $). I have tried the function $F(aH) = a(xHx^{-1})$, but failed to show it is bijective. Could someone offer a hint of the feasible function?","['group-theory', 'abstract-algebra']"
700138,Prove that cardinality of the symmetric difference of subsets less than 3,"We given a set $B = \{0,1,2,3,4,5,6,7,8,9\}$. Task is to prove, that amongst 100 arbitrary picked subsets of set B there are at least two subsets $S_x$ and $S_y$, such as $| S_x \Delta S_y | \le 2$ I started with determining possible cardinalities of the subsets.
Having that figured out I have realized that it isn't actually matter.
So I am out of my depth to find a right track to solve it.",['elementary-set-theory']
700140,Covariance of two Poisson Distributions,"Given two independent Variables X and Y with $ X \sim Poi_\lambda, Y \sim Poi_{2\lambda}$ and $Z = X + Y$ How to calculate the Covariance of X and Z? I know $Z \sim Poi_{3\lambda}$ I have: $C(X, Z) = E(XZ) - E(X)E(Z)$ So I was trying to calculate E(XZ) first, but got stuck with: $$E(XZ) = \sum_{n = 0, \frac{n}{k} \in N}^k \frac{\lambda^k \cdot (3\lambda)^{\frac{n}{k}}\cdot e^{-4}}{n! \cdot \frac{n}{k}!}$$
But I am not even sure, I haven't messed up already. It should be way easier, if I'd be asured that X and Z are independent, so $E(XZ)$ would be $E(X) \cdot E(Z)$ and with that $C(X, Z) = 0$","['probability-theory', 'probability-distributions', 'probability']"
700160,Intuition behind Variance formula [duplicate],"This question already has answers here : What's so special about standard deviation? (11 answers) Closed 5 years ago . Variance is given as:
$\operatorname{Var}(X) = \mathbb{E}[(X-\mathbb{E}(X))^2]$. Is there an intuition behind this and can you find this formula starting from the second generating moment ?","['intuition', 'probability-distributions', 'probability']"
700162,How to find the limit of $\lim_{n\to \infty} n(H(n) - \ln(n) - \gamma)$,How to find the following limit: $$\lim_{n\to \infty} n(H(n) - \ln(n) - \gamma)$$ where $H(n) = 1  + \frac{1}{2} + \cdots + \frac{1}{n}$ is  the $n^{th}$ harmonic number and $\gamma$ is the Euler Mascheroni constant . Also it is known that $\lim_{n\to \infty} \big(H(n)- \ln(n)\big) = \gamma$.,"['logarithms', 'sequences-and-series', 'limits']"
700172,Gradient on Sobolev spaces,"Suppose I have a function $\Phi \in L_p(\Omega)$ and $\nabla\Phi \in W^{-\alpha}_p(\Omega)$, $1<p<\infty$ and where $\Omega\subset\mathbb{R}^n$ is a bounded domain. Can I conclude that $\Phi\in W^{-\alpha+1}_p(\Omega)$ if $\alpha >0$? I have found results for $\alpha=1$ and for $\alpha <0$ (i.e. the gradient is contained in a Sobolev space with positive smoothness parameter). I would be thankfull for answers!","['sobolev-spaces', 'functional-analysis', 'lp-spaces', 'analysis']"
700178,Long ray: Proof of being locally euclidean,"Consider the topological space $X=\omega_1 \times [0,1)\setminus (0,0)$ equipped with the order topology that arises from the lexicographical order. I want to show that this space is locally euclidean. Clearly, for points $(\alpha,x)$ with $x>0$ I can construct a suitable homeomorphism. That's also no problem for points $(\beta,0)=(\alpha+1,0)$ where $\beta$ is a successor ordinal. But in the general case $(\lambda,0)$ where $\lambda$ is a limit ordinal, I have no idea. Nevertheless, for special limit ordinals like $\omega_0$ I worked out a proof but I don't know how to generalize it to all limit ordinals less than $\omega_1$. Here is my homeomorphism for $p=(\omega_0,0)$: We take $U=\{x\in X \mid x<(\omega_0+1,0)\}$ as open neighborhood of $p$. $$f:U\to(1,3)$$
$$(n,x)\mapsto x\cdot 2^{-n-1}+\sum_{i=0}^n 2^{-i} \quad\text{for}\quad n\in\mathbb{N}$$
$$(\omega_0,x)\mapsto 2+x \quad\text{else}$$ I think, that map should do it.",['general-topology']
700235,Is there an easy proof for the classification of $6$-transitive finite groups?,"For the background, see the post: Classification of triply transitive finite groups Thanks to the classification of finite simple groups (CFSG), we know that if $G$ is a finite $6$-transitive groups, then $G=S_n$ or $A_n$. Question : Is there an easy proof of this result (i.e. without using CFSG) ? I'm also interesting  by such a proof for $k$-transitive groups with $k$ sufficiently large. If such proof doesn't exist (yet), are there people working on ? I hope such an easy proof (will) exist.","['permutations', 'finite-groups', 'group-theory']"
700254,A game with two dice,"Imagine a game with two dice, played by two people and a referee.
The referee rolls the first die and the number will determine the number of times that the second die will be rolled.
The two players never know the result of the first die and they must place bets on the total outcome (the sum of the numbers rolled with the second die). They can review the bet each time after the second die is rolled.
With two regular (1:6) dice, and before any die is rolled, there are 55986 different combinations (6^6+6^5+...6^1), that will sum up in 36 total (from 1 to 36). My question is: how can I calculate the probability of each sum (from 1 to 36) without brute force? I attach a simple example with two dice of (1:3) instead of (1:6); in this case we have 3^3+3^2+3^1=39 combinations and it is easy to use brute force. The probabilities of the dice outcomes are:","['number-theory', 'combinatorics']"
700258,Measures with bounded total variation norm compact in $M(X)$?,"Let $X$ be a separable, metric, compact space. (e.g. an interval in $\mathbb{R}$ like $[0,10]$). Let $M(X)$ be the set of all finite signed measures over $X$ with weak-*-topology (in probability theory also called weak-topology), e.g. dual to bounded continuous functions over $X$. Then define $A= \left\{ 
\mu \in M(X) : |\mu|(X) \leq a
\right\}$ for $a>0$, and $|\mu|(X)$ the total variation norm. Now my question: Is the set $A$ compact in $M(X)$ ?","['probability-theory', 'measure-theory', 'compactness']"
700265,Binary relation R is symmetric and transitive iff?,"This is a homework question and I am stuck. Binary relation R is transitive and symmetric if and only if $R=R^{-1}∘R$ The ""only if"" way is trivial. On the ""if"" way, I worked out that given $R=R^{-1}∘R$ we have $R\subseteq R^{-1}$
, but this doesn't gives symmetry since symmetry requires $R^{-1}\subseteq R$.",['elementary-set-theory']
700275,Initial Segments and Initial Sections of Posets,"For a set A with a partially ordering <=, define the following 1)  A subset s(x) of A = {y in A such that y <=x} 2)  A subset S of A with the property that for every x in S then all y in A which are <= x are also in S. Most references I find call s(x) the initial segment of the element x in A. But in Azriel Levy’s book http://books.google.co.za/books?id=zbGjAQAAQBAJ&pg=PT62&lpg=PT62&dq=initial+section+set+theory&source=bl&ots=mmpAkVxTni&sig=AqJespyeN_8eXFTsot8INoRnQvQ&hl=en&sa=X&ei=qvYWU8qcLpGHhQeluYGYBg&redir_esc=y#v=onepage&q=initial%20section%20set%20theory&f=false he calls s(x) the initial section of x in A and defines S as an initial segment. I can’t find any other reference to a set defined as S is. Levy goes on to say that every set s(x) has the property of S (which would appear to follow by transitivity). To me it would appear that even if the ordering is total then it doesn’t necessarily follow that every S has an x where S = s(x): e.g. A is the rationals with normal ordering and S = {rationals that when squared <= 2} . I chanced on the “initial section” reference reading a proof of transfinite recursion, p.27  of http://www.uwec.edu/andersrn/SETSIII.pdf Can anyone clarify segments and sections, confirm common usage of terminology, and give a hint or reference to the usage of sets like S ?","['terminology', 'elementary-set-theory', 'order-theory']"
700288,General (Set Builder) definition for a relation composed with itself n times,"Questions What does the set builder notation for $S\circ R$ look like? I'm having the most trouble knowing when there is too much information or not enough information on either side of the 'such that'.
$$S\circ R=\{ a\in A\land c\in C\land\exists b\in B\mid (a,b)\in R\land (b,c)\in S\}$$
$$S\circ R=\{(a,c)\mid(\exists b\in B)\rightarrow((a,b)\in R\land(b,c)\in S)\}$$ A relation $R_1$ is difined on the set of integers such that $$R_1=\{(a,b)\mid a>b,\:\:\:a,b\in\mathbb{Z}\}$$ How would I write the set builder notation for the recursive composite of $R^n_1$ in terms of $a,b$ and $n$? As a part of question #2; In order for me to understand why the set builder definition looks the way it does I need to understand how to find $R^n_1$ for the relation $R_1$. What is a mathematical process, not an intuitive guess and check solution, that I can employ to see what is happening with respect to the given relation? Current Understandings Set-builder notation is a mathematical notation to describe a set in general form. It's short hand to cut down long worded explanations. A set is usually expressed using curly brackets : $\{\cdots\}$. The set builder notation is formulated by {(a variable)(""such that"")(logical predicate)} ex : The set containing all positive real numbers: Denoted in set builder notation as:
  $$\{x\mid x\in\mathbb{R}\land x>0\}$$ A binary relation on a set $A$ (of $n$ elements) is a group including pairs of elements from the set $A$. Namely, a relation $R$ on a set $A$ is a subset of $A\times A$ containing $2^{n^2}$ relations. ex : The relation ""less than"" is the set containing pairs of numbers where the first number is less than the second number. Denoted in set builder notation as:
  $$R=\{(a,b)\mid a<b\}$$ When you take the composition of multiple relations you join the set mapping of one relation to another (and so on). Let $R$ be a relation from set $A$ to set $B$ and $S$ a relation from $B$ to a set $C$.
$$R\subseteq A\times B\text{ and }S\subseteq B\times C$$
The composite of $R$ and $S$ (denoted by $S\circ R$) is the relation consisting of ordered pairs $(a,c)$, where $a\in A,c\in C$, and for which there exists an element $b\in B$ such that $(a,b)\in R$ and $(b,c)\in S$. (QUESTION 1) ex : $R$ is a relation on two sets such that $R=\{(1,1),(1,4),(2,3),(3,1),(3,4)\}$ and $S$ is a relation on two sets such that $S\{(1,0),(2,0),(3,1),(3,2),(4,1)\}$ $$S\circ R=\{(1,0),(1,1),(2,1),(2,2),(3,0),(3,1)\}$$ Continue to let $R$ be a relation on a set $A$. When composing the parent relation with itself, the powers $R^n, n=1,2,3,\dotsc,$ are defined recessively by $R^1=R$ and $R^{n+1}=R^n\circ R$. This shows that $R^2=R\circ R, R^3=R^2\circ R, and so on.$ (QUESTION 2,3)","['discrete-mathematics', 'function-and-relation-composition', 'relations', 'predicate-logic', 'combinatorics']"
700299,A Ramanujan-like summation: is it correct? Is it extensible?,"I'm still exercising with summation-procedures which I try to make correct Ramanujan-summations. I'm looking at the (gap-)series
$$ s(1/2,2) = (1/2)^1+(1/2)^{4}+(1/2)^{9}+(1/2)^{16}+(1/2)^{25}+... $$
and more general at
$$ s(b,p) = b+b^{2^p}+b^{3^p}+b^{4^p}+b^{5^p}+... \tag 1$$
For convergent case where $0<b<1$ we can evaluate this approximately using serial evaluation of expression (1), say 
$$ \begin{eqnarray} s(1/2,1) &=& 1 \\s(1/2,2) & =& 0.564468413... \\ 
s(1/2,3)&=&0.503906257... \end{eqnarray}$$. On the other hand, expanding that formal sum in a double series of a series of formal exponential series in $x$ and collecting like powers of the argument $x$ I got something like Ramanujan-summation (where I only express the Bernoulli-numbers in the Ramanujan formula by the equivalent zeta-references at negative arguments). So I define the expressions
$$ \begin{eqnarray}  I(b,p)&=& \int_{t=- 1}^\infty b^{(1+t)^p} dt \\
   Z(b,p)&=& \sum_{k=0}^\infty \beta^k {\zeta(-pk) \over k!} \qquad \text{ where } \beta = \log(b) \end{eqnarray} \tag 2$$
Then the summation-method $\mathcal Q$ 
$$ s(b,p) \underset{\mathcal Q}= I(b,p) + Z(b,p)  \tag 3$$
gives for the above convergent cases $s(1/2,1),s(1/2,2)$ the correct results by numerical approximations. (The second case is convergent because each zeta at negative even argument is zero). 
$$ \begin{eqnarray} 
I(1/2,1) &=& + 1.44269504089... \\
Z(1/2,1) &=&  -0.44269504089...\\
s(1/2,1) &\underset{\mathcal Q}=& \phantom + 1\\
\hline\\
I(1/2,2) & =& + 1.06446701943... \\ 
Z(1/2,2)&=& -0.5\\
s(1/2,2)&\underset{\mathcal Q}=& \phantom + 0.56446701943... \end{eqnarray}$$. Also various examples with other parameters, where everything in the $\mathcal Q$-method is convergent seems to approximate the results taken by serial evaluation of (1) correctly. 
For the case $s(1/2,3)$ the sum $Z(1/2,3)$ in (2) is no more convergent. However, using a Noerlund-summation $\mathcal N$ for that expression I could approximate the expected result (taken by evaluation of (1)) satisfyingly. 
$$ \begin{eqnarray} 
I(1/2,3) & =& + 1.00901976692... \\ 
Z(1/2,3)&\underset{\mathcal N}=& -0.50561...\\
s(1/2,3)&\underset{\mathcal Q}=& \phantom + 0.50340...\\
\hline \\
s(1/2,3)&=& \phantom + 0.503906257 \text{  by serial summation } \end{eqnarray}$$. So perhaps this allows more generalization. Q1: Is this eq (2) a valid reconstruction of the Ramanujan-summation, at least in principle? Q2: The integration-bounds were experimentally. Are they correct? and if: how could I have derived them correctly? [update1] : There must be some systematical error. For all even $p=2q$ the sum of the zetas $Z(1/2,2 \cdot q) =-1/2 = \zeta(0) $ and the correct sum $s(1/2,2\cdot q) = 1/2 + \delta $  is always bigger than $1/2$. So it is required that $$I(1/2,2\cdot q)= s(1/2,2\cdot q) - Z(1/2,2 \cdot q) = 1 +\delta$$ But now, by Wolframalpha I see that $$ \int_{t=-1}^\infty 1/2^{(1+t)^p} dt = { \Gamma(1+1/p)\over \sqrt[p]{\log 2} }  $$ which decreases below $1$ at $p \approx 3.44395$ so for all $p=4,6,8,...$ the $\mathcal Q$-summation cannot hold. Hmm... [update 2,update 3] Here are some data which show very nice approximation for the $\mathcal Q$-summation with the serial summation for small p of  $p=0.1 \ldots 1.2$ 
with errors $ \lt 1e-100$. 
$$
\small \begin{array} {r|rrl}
 p & s(1/2,p) & err &=s(1/2,p) - (I(1/2,p)+Z(1/2,p) \\
 \hline
 0.1 & 141745219.752 & -4.00E-156 \\ 
 0.2 & 749.678969635 & 2.82E-167 \\ 
 0.3 & 31.0876588123 & 4.18E-166 \\ 
 0.4 & 7.95318949339 & 1.33E-164 \\ 
 0.5 & 3.78821923065 & -1.96E-162 \\ 
 0.6 & 2.37977624581 & 9.16E-160 \\ 
 0.7 & 1.72998968339 & -2.28E-156 \\ 
 0.8 & 1.37118947539 & -6.79E-152 \\ 
 0.9 & 1.14893798357 & -4.14E-146 \\ 
 1.0 & 1.00000000000 & 5.69E-139 \\ 
 1.1 & 0.89438296309 & -1.18E-128 \\ 
 1.2 & 0.81625996055 & 2.25E-114 \\
  &&& \text{very small errors - perhaps is $\mathcal Q$-summation valid? }\\
 \vdots \\
     1.7 & 0.61712884341 & 2.28 E-18 & \text{using Borel-summation}\\
     1.8 & 0.59639864943 & -1.27 E-11 \\
     1.9 & 0.57905393685 & -0.0000000385 \\
  &&& \text{errors increase-  $\mathcal Q$-summation tends to become invalid? }\\
 \vdots\\
 3.0 & 0.503906257 \phantom {00} & 0.00040176 & \text{Z(1/2,p) by Noerlund/Borel-summation }
 \end{array}
$$
Because of the very slow convergence at the small p I used the Pari/GP-function sumpos which seems to be able to approximate the true value avoiding the computation of millions of terms in the serial summation (1). For the parameter $p \gt 1.5$ I crosschecked the Noerlund-summation for $Z(1/2,p)$ by Borel-summation.","['divergent-series', 'ramanujan-summation', 'summation', 'sequences-and-series']"
700306,Probability & Statistics: Random variables,"I have a problem similar to the well-known ""Coupon Collector Problem."" A box of a certain brand of cereal comes with a special toy. There are 10 different toys in all.  How many packs you will need to buy until you find the first toy already acquired in previous purchases?","['statistics', 'probability']"
700331,Who proved Fundamental Theorem of algebra using Liouville's theorem?,One of the most famous proofs of the Fundamental Theorem of Algebra involves Liouville's theorom stating that a bounded entire function in constant. Who first came up to the idea of deriving FToA from Liouville's theorem? Was it Liouville himself? I would be also grateful for information about when this proof was found.,"['math-history', 'complex-analysis']"
700333,Prove that there exist $c_n>0$ such that $f^{(n)}(c_n)=0 \forall n$,"Let $f \in C^\infty([0,+\infty),\mathbb{R})$, and $f(0)=\lim\limits_{x \to \infty}f(x)$ Prove that there exist $c_n>0$ such that $f^{(n)}(c_n)=0 $ for all $n$ integer, where $f^{(n)}$ is the n-th derivative of $f$ My attempt: If $f$ is constant then the result is obvious. If not there exist $x_0 \in (0,+\infty)$ such that $f(x_0) \neq f(0)$ Let $y=\frac{1}2 (f(x_0)+f(0))$, then by IVT theorem there exist $a
 \in (0,x_0)$ such that $f(a)=y$ Despite $f(0)=\lim_{+\infty}f(x)$, $y$ is an intermediate value of
  $f(x_0)$ and $f(x_1)$ with $x_1$ sufficiently large. Then, by IVT there exist $b \in (x_0,x_1]$ such that $f(b)=y$ Therefore by Rolle's theorem on $[a,b]$ we can conclude that
  $f'$ vanishes. Unfortunately I don't see any direct proof to show that $f^{(n)}$ vanishes. I managed to find a HINT in a book : Prove that either $\lim\limits_{x \to \infty}f'(x)=0$ or $f'$ admits an infinite number of extrema.","['functions', 'calculus', 'real-analysis']"
700361,How to show that any field extension $K/\mathbb{Q}$ of degree 4 that is not Galois has a quadratic extension $L$ that is Galois over $\mathbb{Q}$.,"$\newcommand{\Q}{\mathbb{Q}}$Let $K/\Q$ be a field extension of degree $4$ that is not Galois. How to show that there exists an extension $L\supseteq K$ such that $[L:K]=2$ and $L/\Q$ is Galois? I know the example of $\Q(\sqrt[4]{2})$ which is not Galois but is contained in the splitting field of $x^4-2$ which is Galois and of degree $8$, and I am trying to generalize this. But I am not even sure if we can write $K=\Q(\alpha)$ for some $\alpha$. Anyway, if this is the case, then the splitting field $L$ of the minimal polynomial of $\alpha$ would be Galois and of degree $8$, $12$ or $24$ since $\mathrm{Gal}(L/\Q)$ would be a subgroup of $S_4$. But how to rule out $12$ and $24$?","['galois-theory', 'extension-field', 'abstract-algebra', 'field-theory']"
