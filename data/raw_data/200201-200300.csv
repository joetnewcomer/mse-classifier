question_id,title,body,tags
3913376,"Integrability of generalization of Thomae's function on $[0,1] \times [0,1]$","Let $f:\left[0,1\right]\times\left[0,1\right]\to \mathbb{R}$ be defined by $$f\left ( x,y \right )=\begin{cases}
 0& ,x\in\mathbb{I} \\ 
 0& ,x\in\mathbb{Q},\hspace{2mm} y\in\mathbb{I}\\ 
 \frac{1}{q}& ,x\in \mathbb{Q},\hspace{2mm} y=\frac{p}{q}\hspace{2mm} \text{in lowest terms}
\end{cases}$$ Show that $f$ is integrable and $$\int_{\left[0,1\right]\times\left[0,1\right]}f=0$$ That was my tried. We know that $L(f,P)=0$ for any partition of $[0,1]\times[0,1]$ (This is easy to proof since the density of $\mathbb{I}$ on $\mathbb{R}$ ). Therefore, is enough to proof that given $\varepsilon$ there exist a partition $P$ such that $U(f,P)<\varepsilon$ . Then for any $\varepsilon$ there exist $n\in \mathbb{N}$ st $\frac{1}{n}<\frac{\varepsilon}{2}$ . Let $P$ the following partition $$P=(\{0,\frac{1}{n},\dots, \frac{n-1}{n},1\},\{0,1\})$$ . The volume $v(S)$ of each rectangle $S$ of the partition $P$ is $\frac{1}{n}$ , but i don't how to calculate $M_S(f)=\sup\{f(x,y):(x,y)\in S\}$ . This exercise was taken from Calculus on Manifolds - Michael Spivak, Chapter 3. Integration, exercise 3-7.","['multivariable-calculus', 'riemann-integration', 'real-analysis']"
3913383,Finding a constant which makes a Homogeneous ODE into a Non-Homogeneous ODE,"I have a Non-Homogeneous ODE of the form $y'' + 8y' + 17y = 5$ which I have obtained the solution $y(x) = ae^{-4x}[\cos(x) + i\sin(x)] + be^{-4x}[\cos(x)-i\sin(x)] + \frac{5}{17}$ where $a$ and $b$ are complex constants. I am unsure of how to find a constant, $c$ , which satisfies the equation $z(x) = y(x) - c$ where $c$ is a real constant and $z(x)$ is a Homogeneous Differential Equation. I originally thought that $c = \frac{5}{17}$ but that seems too simple. How should I go about finding $c$ ?","['homogeneous-equation', 'ordinary-differential-equations']"
3913426,Intersection of directed random walks,"I'm kinda worn out working on this seemingly classical question. I appreciate immensely any kind of help. Problem Let $S^{(1)}, S^{(2)}, S^{(3)}$ be three independent simple symmetric random walks in $\mathbb{Z}$ , starting from the origin. How can we prove the following sequence of random variables converges in law? $$H_N= \dfrac{1}{\sqrt{N}} \left( \sum_{n=1}^N \mathbb{1}_{S^{(1)}_n=S^{(2)}_n} +\sum_{n=1}^N \mathbb{1}_{S^{(2)}_n=S^{(3)}_n}+\sum_{n=1}^N \mathbb{1}_{S^{(3)}_n=S^{(1)}_n} \right) $$ $\square$ Update 1 A straightforward observation we have is that: $$ \mathcal{L}\left(\dfrac{1}{\sqrt{N}} \left( \sum_{n=1}^N \mathbb{1}_{S^{(1)}_n=S^{(2)}_n} \right) \right) \longrightarrow \mathcal{L}( \sqrt{2}\max_{ 0 \le t \le 1} B_t)$$ Update 2 There is some ""workaround""(very tedious) using Wiener chaos, but not what I'm looking for.","['probability-theory', 'weak-convergence']"
3913514,Showing that the free group of a disjoint union is isomorphic to the free product of the corresponding free groups,"P. Aluffi's ""Algebra: Chapter $\it 0$ "" , exercise II. $5.8$ . Still more generally, prove that $F(A\amalg B)=F(A)*F(B)$ and that $F^{ab}(A\amalg B)=F^{ab}(A)\oplus F^{ab}(B)$ for all sets $A,B$ . $($ That is, the constructions $F,F^{ab}$ 'preserve coproducts'. $)$ Here $F(A)$ is the free groups on the set $A$ , $A\amalg B$ is the disjoint union of $A$ and $B$ , and $G*H$ is the free product of $G$ and $H$ (i.e. the coproduct in $\sf Grp$ ). All of those are characterized by their usual universal properties which will be used extensively for the proof. $^*$ Proof. We will show that $F(A\amalg B)$ satisfies the universal property of $F(A)*F(B)$ . For startes, we will construct the (canonical) inclusion homomorphisms. Thus, consider the following diagrams Here $\iota_A,\iota_B,\iota$ are the inclusion of $A,B,A\amalg B$ into their respective free groups. The (unique) group homomorphisms $I_A,I_B$ are induced by considering the compositions $\iota\circ i_B$ and $\iota\circ i_B$ and the universal properties of $F(A)$ and $F(B)$ . Hence they are such that $$I_A\circ\iota_A=\iota\circ i_A,~~~I_B\circ\iota_B=\iota\circ i_B$$ Now, suppose we are given group homomorphisms $g_A\colon F(A)\to G,\,g_B\colon F(B)\to G$ to some arbitrary group $G$ . We can consider them in particular as set-functions and precomposing with $\iota_A$ and $\iota_B$ , respectively, gives us the following The unique map $g$ is given by the universal property of $A\amalg B$ and such that $$g\circ i_A=g_A\circ\iota_A,~~~g\circ i_B=g_B\circ\iota_B$$ Finally, $\overline{g}$ induces a unique map $\overline{f}$ such that by the universal property of $F(A\amalg B)$ and so $\overline{g}\circ\iota=g$ . Composing gives us uniquely determined group homomorphisms $\overline{g}\circ I_A\colon F(A)\to G$ and $\overline{g}\circ I_B\colon F(B)\to G$ factoring through $F(A\amalg B)$ . It remains to show the following $$\overline{g}\circ I_A=g_A,~~~\overline{g}\circ I_B=g_B$$ But using the given commutativity relations we see that $$(\overline{g}\circ I_A)\circ\iota_A=\overline{g}\circ(I_A\circ\iota_A)=\overline{g}\circ(\iota\circ i_A)=(\overline{g}\circ\iota)\circ i_A=g\circ i_A=g_A\circ\iota_A$$ and hence both triangles in the following diagram commute The right triangle corresponds to the fact the by $g_A\circ\iota_A$ universally induced map is $g_A$ itself. But from the left triangles we see that $\overline{f}\circ I_A$ makes the corresponding diagram commute as well and hence $\overline{f}\circ I_A=g_A$ by the uniquesness of the induced map. The same argument, with all $A$ s replaced by $B$ s, yields $\overline{f}\circ I_B=g_B$ . Thus, we conclude that $F(A\amalg B)$ satisfies the universal property of $F(A)*F(B)$ as every pair of group homomorphisms $g_A\colon F(A)\to G,\,g_B\colon F(B)\to G$ factors uniquely through $F(A\amalg B)$ using $I_A,I_B$ and $\overline{g}$ . Hence, $F(A\amalg B)\cong F(A)*F(B)$ . The argument is precisely the same for $F^{ab}$ where we note that $G*H=G\oplus H=G\times H$ for abelian groups. $\square$ Is the given proof correct; if so, can it be (substantially) improved? If not, where did I went wrong? I am not sure how to show actual equality instead 'mere' isomorphy (which is enough for me, to be honest) and the last part, i.e. showing that $\overline{g}\circ I_A=g_A$ , is a little bit sketchy to me, even though I am quite sure the argument works. Thanks in advance! $^*$ I know that this preservation essentially boils down to 'left adjoints presever colimits' as the (binary) coproduct is a simple colimit and the free functor $F\colon\sf{Set}\to\sf{Grp}$ is left adjoint to the forgetful functor $\sf{Grp}\to\sf{Set}$ . However, I would like to not dabble to deep into category theoretic terrain if it does not make the proof easier/more understandable. So the given proof is more or less from scratch.","['abstract-algebra', 'free-groups', 'solution-verification', 'free-product', 'group-theory']"
3913538,Is there anything interesting about the limit $\lim_{h\rightarrow 0}\Big|\frac{f(a+h)-f(a)}{|h|}\Big|$?,"I was wondering if there is anything interesting to say about the following limit: Let $f:\mathbb{R}^n\rightarrow \mathbb{R}^m$ , and $a\in \mathbb{R}^n$ . Consider $$\lim_{h\rightarrow 0}\Big|\frac{f(a+h)-f(a)}{|h|}\Big|$$ If $f$ is differentiable I don't think the limit needs to converge. Suppose $f$ is differentiable at $a$ , then $$\lim_{h\rightarrow 0}\Big|\frac{f(a+h)-f(a)}{|h|}\Big|=\lim_{h\rightarrow 0}\Big|\frac{f(a+h)-f(a)-T(h)}{|h|}-\frac{|h|T(u)}{|h|}\Big|=\Big|T(u)\Big|$$ where $u$ is the unit vector in the direction of $h$ . So the direction at which the limit is taken matters.","['limits', 'multivariable-calculus', 'derivatives', 'real-analysis']"
3913550,How do I determine from a picture of a vector field if it's a possible formula for the vector field and conservative or not?,"I have an image here of a vector field $F(x,y)$ and am tasked to do the following things: True or false: : A possible
formula for $F(x, y)$ is $F(x, y) = <âˆ’y, x>$ Is $F$ (the vector field in the picture) conservative? So the first one I really have no clue how to tell if that's a possible formula. The second one I think maybe it's conservative because it's circular so the curl = 0. But how do I actually know? How do I solve these problems with just a picture?","['vectors', 'vector-fields', 'multivariable-calculus', 'calculus', 'vector-analysis']"
3913569,$f\colon\mathbb{R}\to\mathbb{R}$ is continuous if and only if for every open set $A$ in $\mathbb{R}$ we have $f^{-1}(A)$ open in $\mathbb{R}$,"I would like some feedback and corrections to my proof below that $f\colon\mathbb{R}\to\mathbb{R}$ is continuous if and only if for every open set $A$ in $\mathbb{R}$ we have $f^{-1}(A)$ open in $\mathbb{R}$ , using $\varepsilon\text{-}\delta$ definition of continuity. ( $\Rightarrow$ ). If $f$ is continuous, then for all $a\in\mathbb{R}$ we have that for all $\varepsilon>0$ there is a $\delta>0$ such that for all $x\in X$ with $\left|x-a\right|<\delta$ this is going to imply that $\left|f(x)-f(a)\right|<\varepsilon$ . Take an open set $A\subset f[\mathbb{R}]\subset \mathbb{R}$ ( I'm not sure if it's necessary to take it as subset of $f[\mathbb{R}]$ ). For any $f(a)\in A$ , because $f$ is continuous, we can choose any $\varepsilon>0$ , so we do it by choosing $\varepsilon_{f(a)}>0$ such that $(f(a)-\varepsilon,f(a)+\varepsilon)\subset A$ , and this is possible because $A$ is open by hypothesis. As $f$ is continuous, this $\varepsilon_{f(a)}>0$ will gives us a $\delta_{a}>0$ such that all $x\in \mathbb{R}$ that are within a distance $\delta_a$ from $a$ will have their image $f(x)$ within a distance $\varepsilon_{f(a)}$ from $f(a)$ . That is, we are going to have an open interval $(a-\delta_a,a+\delta_a)$ , and because all of the $x\in\mathbb{R}$ inside of this interval have their image $f(x)\in A$ , this interval $(a-\delta_a,a+\delta_a)$ is a subset of $f^{-1}(A)$ . If we follow this for all $f(a)\in A$ , we are going to end up with an open interval with center $a$ and radius $\delta_a$ for each $a\in f^{-1}(A)$ , so $f^{-1}(A)$ is open. ( $\Leftarrow$ ). We have that for every open set $A$ of $\mathbb{R}$ we have $f^{-1}(A)$ open in $\mathbb{R}$ . As $A$ is open in $\mathbb{R}$ , for all elements $f(a)\in A$ there is an $\varepsilon_{f(a)}>0$ such that $(f(a)-\varepsilon_{f(a)},f(a)+\varepsilon_{f(a)})$ is a subset of $A$ . So we can obtain an $a\in f^{-1}[(f(a)-\varepsilon_{f(a)},f(a)+\varepsilon_{f(a)})]$ . And because $f^{-1}[(f(a)-\varepsilon_{f(a)},f(a)+\varepsilon_{f(a)})]\subset f^{-1}(A)$ and $f^{-1}(A)$ is open, we choose a $\delta_a>0$ such that $(a-\delta_a,a+\delta_a)\subset f^{-1}[(f(a)-\varepsilon_{f(a)},f(a)+\varepsilon_{f(a)})]$ . Therefore, we have that $f[(a-\delta_a,a+\delta_a)]\subset (f(a)-\varepsilon_{f(a)},f(a)+\varepsilon_{f(a)})$ and we conclude that $f$ is continuous.","['continuity', 'general-topology', 'real-analysis']"
3913605,Is log x + log y monotonically increasing with respect to x + y? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question We know $\log x + \log y = \log(xy)$ which is a monotonically increasing function with respect to the product $xy$ . I am wondering if $\log x + \log y$ is still a monotonically increasing function of the sum $x+y$ ?","['multivariable-calculus', 'calculus', 'monotone-functions', 'logarithms']"
3913741,How do you isolate $\theta$ from $\sin(\theta) - k\cos(\theta) = \frac{m_1}{m_2}$?,"This equation derives from physics force equations, and I have verified to make sure that the equation works. No actual physics pertains to this question. The part I need help on only requires math skills. Here is the equation: $$\sin(\theta) - k\cos(\theta) = \frac{m_1}{m_2}$$ where $k$ , $m_1$ , and $m_2$ are variables, specifically the kinetic friction coefficient, mass one, and mass two respectively (irrelevant). I have tried squaring both sides to then use double angle rules on the $2\sin\cos$ that yields, but all of my attempts have failed to simplify the equation further. Could someone help me derive an equation for theta?","['physics', 'algebra-precalculus', 'trigonometry']"
3913781,To solve an arctan sum $\sum_{n=0}^{\infty} \arctan\frac{\sqrt3a_n(a_n-1)}{(a_n+1)(2a_n^2-3a_n+2)}$,"I was suggested (without any background setting) to prove a numerically checked result, which is dramatically refined $$
\sum_{n=0}^{\infty} \arctan\frac{\sqrt3a_n(a_n-1)}{(a_n+1)(2a_n^2-3a_n+2)} = \frac{\pi}{12}
$$ where $a_n=(1+\sqrt3)^{4^n}$ , with $4^n$ on shoulder. Usually we deal with arctan series using telescoping or gamma function technique, but this $a_n$ holds a geometrical growth and I have no idea how to do the reduction. Thanks in advance for any suggestion.","['trigonometry', 'summation', 'sequences-and-series']"
3913816,Usage/Application of Raychaudhuri equation in Riemann geometry or pure maths,While going through this paper by Witten and seeing a discussion about different aspects of Raychaudhari Equation and Einstein Field Equation. I want to ask if Raychaudhari Equation find any application in pure Maths specifically Riemann geometry since the only assumption in arriving it is to have a metric with signature $(-+ + +)$ and geodesic equation. Hence it can be applied in the modified theory of gravity as well. I searched the Raychaudhri equation in the A Panoramic View of Riemannian Geometry with no results while a google search gives no result as well. Finally searching on arXiv in Maths section only produces 7 results which are more or less about singularity theorem or the usual application of Raychaudari equation in GR. This really bugs me since Raychaudhari equation is essentially about the evolution of geodesic equations therefore they should find at least some application in pure maths. Or does it happen that they are used but a more general version of them is used?,"['geodesic', 'riemannian-geometry', 'semi-riemannian-geometry', 'general-relativity', 'differential-geometry']"
3913853,What does $\mathbb Z[x]$ mean?,"Iâ€™ve seen usage of the notation $\mathbb Z[x]$ before, where $x$ is some non-integer. For example in the Wikipedia article on the Gaussian integers it says that the set of Gaussian integers can be written as $\mathbb Z[i]$ . But what does it actually mean? I suspect that $\mathbb Z[x]$ refers to the set of numbers of the form $a+bx$ , where $a,b\in\mathbb Z$ , but Iâ€™m not sure.","['elementary-set-theory', 'notation']"
3913886,Lifting a map to the total space of a circle bundle,"Let $\pi:P \to M $ be a smooth circle bundle, so $S^1$ is the fibre, $f:N \to M$ a smooth map. I would like to know what are the necessary and sufficient conditions for $f$ to lift to a map $g:N \to P$ covering $f$ . There are related questions reading which I think the answer is that $f$ lifts if and only if $f^*:H^2(M,\mathbb{Z})\to H^2(N,\mathbb{Z})$ is the zero map. However my understanding of algebraic topology is very basic and I cannot quite follow the arguments presented, so I would like for someone to confirm or  correct what I wrote. Incidentally, advice for the most accessible introduction to obstruction theory you know of would be appreciated. In fact I am interested in a related but slightly different question: with $\pi:P\to M$ as above when does a diffeomorphism $f:M\to M$ lifts to a map $h:P\to P$ ? If the above criterium is correct $f$ lifts if and only if $\pi^*: H^2(M) \to H^2(P)$ is the zero map. Can anything be said about when that happens given that $P$ is a circle bundle?","['fiber-bundles', 'fibration', 'algebraic-topology', 'differential-geometry']"
3913926,"Show that there is an injective homomorphism between $Aut(S_3)$ and $Bij(\{(12), (1 3), (2 3)\}$","Let $X$ be equal to $\{(1 2), (1 3), (2 3)\}$ . How can I prove the existence of an injective homomorphism between $Aut(S_3)$ and $Bij(X)$ ? I was thinking about this : Let $\varphi$ be a map between $Aut(S_3)$ and $Bij(X)$ defined as following : For $\psi$ in $Aut(S_3)$ , $\varphi(\psi) = f$ with $f : X \longrightarrow X$ such as $\forall x \in X$ , $f(x) = \psi(x)$ Then I think I can show that $\varphi$ is an injective homomorphism. Do you think it's correct ? Thank you for your help.","['permutations', 'group-homomorphism', 'group-theory', 'abstract-algebra']"
3913951,Fulton Algebraic Curves: Exercise 3.12,"I am trying to understand for which $n$ does the curve $F = Y - X^n$ has an inflection point at $P = (0,0)$ as in exercise 3.12 from Fulton's algebraic curves. From a geometric perspective I expect it to be all $n \ge 3$ with $n$ being odd. The tangent is $L = Y$ and $\mathfrak{m}_P = (X)$ as in the proof of theorem 1 in chapter 3.2. For $n=3$ : as I understand that would mean $L = Y = X^3 \in \mathfrak{m}^3$ , so $ord_P^F(L) = 3$ , so P is an ordinary inflection point. For $n=4$ : wouldn't this be here the same logic, i.e., $L \in \mathfrak{m}^4$ ? But here P is no inflection point, or what do I miss here?",['algebraic-geometry']
3913972,"Show that $Z^2 + Y^3 + X^5$ is irreducible in $\mathbb C[X,Y,Z].$","Here is the question I want to answer: Let $\mathbb C[X,Y,Z] \cong \mathbb C^{[3]}.$ Define rings $$ A = \mathbb C[Y,Z]/(Z^2 + Y^3) \text{ and } B = \mathbb C[X,Y,Z]/(Z^2 + Y^3 + X^5) = \mathbb C [x,y,z]$$ where $x,y,z$ are the images of $X,Y,Z$ under the standard projection $\mathbb C [X,Y,Z] \rightarrow B.$ $(b)$ Show that $Z^2 + Y^3 + X^5$ is irreducible in $\mathbb C[X,Y,Z].$ Conclude that $B$ is an integral domain. Here is my trial: 1- Can anyone give me a feedback on my trial please? specifically,I feel like my reasoning that it is an integral domain is not correct. Could anyone show me how to find this isomorphism and its kernel and image please? EDIT: 3-I also found this question here: Show that $f(x,y,z)=x^2-y^2z$ is irreducible in $\mathbb{C}[x,y,z]$. but still I am confused about the general procedure and the specific details I should calculate to solve those kinds of problems, could anyone clarify this to me please?","['irreducible-polynomials', 'integral-domain', 'ring-theory', 'algebraic-geometry', 'polynomial-rings']"
3913975,"Set of maps such that $f:M\rightarrow N$ is a covering space will be open in $C_S^r(M,N)$","I am trying to do an exercise that is as follows : Let $M$ and $N$ be manifolds. The set of maps $f\in C_S^1(M,N)$ such that $f:M\rightarrow N$ is a covering space with the extra restriction that instead of local homeomorphisms we have local diffeomorphisms ,is an open set in $C_S^r(M,N)$ . Now my first idea to try and prove this would be to use the fact that if we have a local diffeomorphism $f: U\rightarrow V$ then the set of diffeomorphisms is open in $C_S^r(U,V)$ , but then I realized I have the problem that $C_S^r(U,V)$ is not open in $C_S^r(M,N)$ , so I needed to try another approach . I have been thinking about this but I haven't gotten anywhere useful. Any help with this is aprecciated, Thanks in advance.","['differential-topology', 'covering-spaces', 'differential-geometry']"
3913986,On the convexity/concavity of c-concave functions,"Given a cost function $c:\mathbb{R}^d\times \mathbb{R}^d\rightarrow \mathbb{R}^+$ we say a function $\phi:\mathbb{R}^d\rightarrow \mathbb{R}$ is c-concave when there exists some $\psi:\mathbb{R}^d\rightarrow \mathbb{R}\cup\{-\infty\}$ , $\psi\not\equiv -\infty$ such that $$ \phi(x) = \inf_{y\in\mathbb{R}^d} [c(x,y)-\psi(y)]. $$ If the cost function is the usual euclidean metric $c(x,y) = \frac{1}{2}|x-y|^2$ then we know a function $\phi(x)$ is c-concave iff $$ \frac{x^2}{2}-\phi(x) \quad \text{is convex.} $$ I was wondering whether there was some way to characterize the convexity/concavity of a c-concave function regarding the concavity/convexity of the cost. In particular I am specially interested in the case in which $c(x-y)$ is a concave function (and a distance indeed). Thanks in advance!","['measure-theory', 'optimal-transport']"
3914128,Positive integer solution for $2n^3 + 5 \mid n^4+n+1$,"I am starting to study number theory and came across this question on the book I'm reading: Give all positive integer values for n such that $2n^3 + 5 \mid n^4+n+1$ . I came up with an attempt but it doesn't seem right, can anyone help me figure it out? We know $2n^3 +5 \mid n^4+n+1$ and trivially, $2n^3 + 5\mid 2n^3 + 5$ . From $a \mid b, a \mid c \implies a \mid xb + yc, x,y \in \mathbb{Z}$ we can show $2n^3+5 \mid n(2n^3+5) - 2(n^4 + n + 1) = 3n-2$ We also know that $a\mid b \implies a = 0$ or $|a| \le |b|$ . From the first part, $3n-2=0 \implies n \notin 
 \mathbb{Z}$ . From the second part, $|2n^3+5| \le |3n-2|$ . I didn't prove this but this inequality doesn't seem to have any positive integer solutions Any help is appreciated.","['algebra-precalculus', 'polynomials', 'divisibility']"
3914131,What is the difference between the first Chern class and integral first Chern class?,"I'm reading a paper which says that the first Chern class of a manifold is $0$ , but the integral first Chern class is not $0$ . What is the difference between the two? Does it have to do with taking integer coefficients?","['characteristic-classes', 'differential-geometry']"
3914147,Whats the intuitive difference between ${n \choose 2}$ and taking ${n \choose 1} {{n-1} \choose 1}$?,Example: I am trying to find the number of combinations of full house in poker. In that case I take ${13 \choose 1}{4 \choose 3} {12 \choose 1}  {4 \choose 2}$ . In a different scenario suppose I want to find the number of combinations of two pairs. There I take ${13 \choose 2}  {4\choose 2}  {4 \choose 2}$ . Why shouldn't I take ${13 \choose 1}$ and then ${12 \choose 1}$ like in the previous case?,"['binomial-coefficients', 'combinatorics', 'intuition', 'poker', 'probability']"
3914169,How to properly work with Leibniz notation,"This question regards the manipulation of derivatives as if they were fractions. But more generally it also regards doing calculus in a ""Leibnizian"" way. Before asking I checked out the current poll of question regarding this topic: link , link and another one for good measure; my objective with this question is to fill in the holes that I think are left open in the discussion of this topic on this site. In the cited questions is clarified why is incorrect to define the derivate not as a limit but as a fraction, and the consequent importance of knowing the proper definition of the derivative as a limit. This is clear. But when working whit derivatives and integrals I think the usefulness of working with Leibniz notation, and interpreting derivatives as fractions, is beyond any doubt, as this answer points out. Problem is: when working with imprecise assumptions things can go wrong really fast, and for this reason interpreting the derivative as a fraction has the nomea of a pretty dangerous gamble. Here are some examples on how this can go terribly wrong: Example 1: $$\int \nabla \phi \cdot d\vec{x}=\int \frac{d\phi}{dx}dx+\frac{d\phi}{dy}dy+\frac{d\phi}{dz}dz=\int \frac{d\phi}{dx}dx+\int\frac{d\phi}{dy}dy+\int\frac{d\phi}{dz}dz=\phi+\phi+\phi=3\phi$$ but on the other hand if we state that: $d\phi+d\phi+d\phi=d\phi$ we get the correct result: $$\int \nabla \phi \cdot d\vec{x}=\int \frac{d\phi}{dx}dx+\frac{d\phi}{dy}dy+\frac{d\phi}{dz}dz=\int d\phi+d\phi+d\phi=\int d\phi=\phi$$ But if we write it with the proper notation of partial derivative then we should elide $\partial x$ with $dx$ , even more chaos. Example 2: $$\frac{\partial \phi}{\partial x}/\frac{\partial \phi}{\partial y}=\frac{\partial y}{\partial x}$$ by ""eliding the $\partial \phi$ "". And I am sure I could go on with more example, but I think there is no need. Question is: is there a ruleset to follow to ensure to not fall for mistakes like this when working with Leibniz notation? I feel like this question hasn't been properly answered in the previous discussion on this topic. And if there is such ruleset, why it works? Also it's often said that this way of handling derivatives and integrals no longer works when dealing with multivariable calculus, but from my experience it seems to give the correct answer even in this case, what is up with this exactly? Why should it no longer work? For example let's take the integral: $$\int \frac{\partial \vec{A}}{\partial t} \cdot d\vec{x}$$ It would seem a bit difficult to solve this integral ""rigorously"", but by interpreting it in a somewhat Leibnizian way we get: $$\int \frac{\partial \vec{A}}{\partial t} \cdot d\vec{x}=\int \frac{\partial A_x}{\partial t}dx+\frac{\partial A_y}{\partial t}dy+\frac{\partial A_z}{\partial t}dz=\int dA_x \frac{dx}{dt}+dA_y\frac{dy}{dt}+dA_z\frac{dz}{dt}=\int \vec{v} \cdot d\vec{A}=\vec{v}\cdot \vec{A}$$ This seems like a miracle, should we not use this way of working with things like this?","['integration', 'notation', 'calculus', 'partial-derivative', 'derivatives']"
3914206,How do I compute the area of a cross which contains several disks which may overlap?,"I have found this in a Facebook group :)
The only thing we are given is the marked distance and we need to find the shaded area.
I have tried several options but I am always missing some data.
Then I tried the following: I considered two different conditions: The two side circles do not overlap; they are tangent to each other. In this case, the given distance corresponds to 3 diameters, so each is 3.33 units and the requested area is 100 sq. units. The two side circles overlap by 100%. Again the area is 100 sq. units. It is therefore obvious that the area is independent from the amount of overlapping, i.e. from the angle of the specific line segment to the horizontal line. Can you provide a geometrical solution? Many thanks!!","['euclidean-geometry', 'geometry']"
3914216,monic irreducible polynomial in $\mathbb Z[x]$ have a multiple root in $F_p$ over $F_p[x]$ for some prime $p$,"Could you help me with the following problem which I cannot solve ? Let $f\in \mathbb Z[x]$ be a monic irreducible polynomial with $deg(f)>1$ . Prove or disprove that there is always a prime $p$ satisfying the following condition: $\overline{f}$ have a multiple root in $F_p$ where $\overline{f}$ is a polynomial in $F_{p}[x]$ , whose coefficients are the reduction of those of $f$ modulo $p$ . From Minkowski's bound, |disc $(f)|>1$ . So we can take a prime $p$ dividing  |disc $(f)|$ . Then $\overline{f}$ have a multiple root in algebraic closure of $F_p$ . However, this does not mean $\overline{f}$ have a multiple root in $F_p$ . For example, $f=x^4 + 2x^3 + 3x^2 + 2x + 6$ and $p=5$ . In this case, disc $(f)$$=35600$ and $\overline{f}=(x^2+x+1)^2$ over $F_p$ . (On the other hand, $\overline{f}=x^2(x+1)^2$ over $F_2$ )","['algebraic-number-theory', 'number-theory', 'finite-fields', 'field-theory', 'polynomials']"
3914274,"What is a condition for two real functions $f,g$ to ""commute"", so $f(g(x))=g(f(x))$?","Say I'm given two functions $f,g$ . Can I tell if they ""commute"" without actually trying them in the formula $f(g(x))=g(f(x))$ ? And given a function $f$ , is there a way to find all functions $g$ such that $f(g(x))=g(f(x))$ ? I've tried using derivatives and the chain rule but haven't got anything interesting yet.","['real-numbers', 'calculus', 'functions', 'algebra-precalculus']"
3914334,Conditions for level sets to be diffeomorphic to each other,"I have a map $\pi:\mathbb R^d\longrightarrow\mathbb R$ which is Lipschitz continuous and $\|\nabla\pi\|>0$ almost everywhere. I know also that the level set $\pi^{-1}(0)$ is compact. Can I conclude that the level sets $\pi^{-1}(c)$ are diffeomorphic for all $c\geq0$ ? If not, what are the additional conditions for which I can conclude it? Thank you","['differential-topology', 'differential-geometry']"
3914340,Is it possible to define a bijection from nonnegative to positive numbers? [duplicate],"This question already has answers here : How to define a bijection between $(0,1)$ and $(0,1]$? (9 answers) Bijection from (0,1) to [0,1) (2 answers) Closed 3 years ago . Let $\mathbb{R}_{\geq 0}$ be the set of nonnegative numbers and $\mathbb{R}_{>0}$ the set of positive numbers, that is $$
\mathbb{R}_{\geq 0} = \{\,x \geq 0 \mid x \in \mathbb{R} \,\}
$$ and $$
\mathbb{R}_{> 0} = \{\,x > 0 \mid x \in \mathbb{R} \,\}
$$ Is it possible to define a bijection $f$ between these two sets?",['functions']
3914436,What is the answer of $ \lim_{n\to \infty}\frac{{(-1)}^{(n-1)}\cdot n}{(n+1)!}$,"I found a limit question in my textbook but i could not obtained the result given by answer key. Let me introduce the question : $ \lim_{n\to \infty}\frac{{(-1)}^{(n-1)}\cdot n}{(n+1)!}$ I tried to separate it into two part such that $ \lim_{n\to \infty}{(-1)}^{(n-1)}\cdot\lim_{n\to \infty}\frac{n}{(n+1)!}$ As you see, this partition gave me "" $\text{oscillating (undetermined)}$ "". $0$ However, the answer is zero. What am I missing? Thank you for your helps ...","['limits', 'calculus']"
3914469,Why do we not measure angles like this?,"An angle is a simple geometric figure that is obtained by taking a ray and rotating it about a point to form another ray, both of which have their starting point in common. The initial rays is called the initial side, the final one is called the terminal side and the common point is called the vertex. The point of measuring angles is to describe, in a way to what degree (pun intended) the initial line is rotated about the vertex to obtain the terminal line. The three usual measures of angles i.e. degree, radian and grads are dimensionless since they are all based on measuring an angle as a ratio of the arc length to the radius (I might be wrong, please let me know if I am). Now, let's say that we have an angle $AOB$ , as shown here : Here, $OP = OQ = 1~\mathrm{unit}$ . $L$ is the length of the arc $PQ$ . So, why can't we call say that $L$ is the angle measure of $\angle AOB$ (in a new angle measurement system). For such a system, the measure of any given angle will be the same as it's measure in radians, only the dimensionality will be different. The dimensionality of angle measure in this system becomes the same as of lengths. I don't see how that's a problem, though. Also, I find thinking about measuring angles like this much simpler than as a ratio of arc lengths. So, can this be called a valid way of measuring angles. If not, why? Thanks!","['angle', 'geometry']"
3914506,Expected size of a sample,"A warehouse contains seven printing machines, three of which are defective.
A company worker has a task to send two of the defective machines for a
repair. In order to identify such a pair, he selects a printing machine at random and
inspects whether it is a defective or a non-defective one. Then he selects another
printing machine at random for the inspection and he repeats the process until he
identifies the second defective printing machine. What is the expected number of
printing machines he has to inspect? I would really appreciate a hint on how to proceed with this problem. So far I have created a tree diagram, which made me believe the answer is 4. But I think there has to be another way to solve this.","['expected-value', 'statistics', 'probability']"
3914516,"For an irreducible Markov chain on a finite state space, all states are positive recurrent","I'm reading Jeffrey's A first look at rigorous probability theory , in particular, Proposition 8.4.10 . Here is a sketch of the proposition and its proof: There are two places in the Proof I'm stuck on. The first one is in the first paragraph. I'm confused about why a finite state space implies that $h_{ji}^{(m)} \geq \delta$ for all states $j$ , and for some $m \in$ N and $\delta > 0$ ?
The second confusion follows immediately at the beginning of the second paragraph, that is, how does the author come up with the result $1 - h_{ii}^{(n)} \leq (1- \delta)^{\lfloor n/m \rfloor}$ ? Any advice is greatly appreciated!!","['markov-chains', 'stochastic-processes', 'markov-process', 'probability-theory', 'probability']"
3914560,Clock angle problem from simulation of planetary orbits,"Description I'm trying to reproduce a Solar System mathematically using ellipses. The initial conditions are: All ellipses will have a common foci $(0,0)$ , but different centers A planet orbiting an ellipse will have a period $T$ The position of a planet in the ellipse will be the reflected point (from the center of the ellipse) given the angle $\theta$ at time $t$ (*) Every ellipse can have a different initial phase angle $\theta_0$ Every ellipse can be rotated about the common foci $(0,0)$ To simplify the problem. We will assume conditions $4.$ and $5.$ are nonexistent. Here's a simple representation of a single ellipse: where $(j,k)$ is the center of the ellipse $(x,y)$ is the result of the
ellipse formula at angle $\theta$ $(x',y')$ is the reflected
point using the center as a mirror $\omega$ is the angle at point $(x',y')$ *: This is needed to simulate Kepler's second law Problem Given two ellipses (whose variables are denoted by subindex $_1$ and $_2$ in the following formulas), I'd like to find a formula that describes at which times $t$ , $\omega_1$ and $\omega_2$ are equal. In other words, find the equation of $\omega$ in relation to time $t$ . Here's a gif that shows the specified system of two orbits: where The green dot is the center of the large ellipse The red dot is the center of the smaller ellipse The period of the large ellipse is $T_1 = 6$ s The period of the smaller ellipse is $T_2 = 14$ s The eccentricity of the large ellipse is 0.77 The eccentricity of the smaller ellipse is 0.75 The directrix of both ellipses is 2 So far, I've been able to figure out at which times $t$ both $\theta$ are equal: We know how $\theta$ varies in relation to $t$ , $$\theta = \frac{2\pi t}{T} + \theta_0$$ Since we have stablished that $\theta_0$ doesn't exist, $$\theta = \frac{2\pi t}{T}$$ We know that at time $t$ , both $\theta_1$ and $\theta_2$ must be equal: $$\theta_2 = \theta_1 + 2\pi k\ \ ,\  k \in \mathbb{Z}$$ where $2\pi k$ represents the periodicity of the orbit. If we substitute: $$\frac{2\pi t}{T_2} = \frac{2\pi t}{T_1} + 2\pi k\ \ ,\  k \in \mathbb{Z}$$ Solve for t: $$t = \frac{k}{\frac{1}{T_2}-\frac{1}{T_1}}$$ This formula gives me at which time $t$ both ellipses will have the same $\theta$ . If we substitute $T_1$ and $T_2$ with the periods of the ellipses in the example gif, we got for $k=1$ , $t=10.5$ s. If you look at the gif, after 10.5s, both red lines will be aligned, meaning $\theta_1$ and $\theta_2$ will be equal. Another way of finding this formula is using the polar expression of an ellipse: We know that the angle $\theta$ will be $$\theta = \arctan{\frac{y}{x}}$$ And we know that the point $(x,y)$ in polar coordinates is represented as: $$(x,y) = (r\cos{\theta}, r\sin{\theta})$$ Where $r$ is the distance from the center to the point $(x,y)$ , and this distance is given by the polar formula of an ellipse: $$r=\frac{ed}{1+e\cos{\theta}}$$ $$(x,y) = \left(\frac{ed}{1+e\cos{\theta}}\cos{\theta}, \frac{ed}{1+e\cos{\theta}}\sin{\theta}\right)$$ Going back to the formula described at step $1.$ , we have $$\theta = \arctan{\frac{y}{x}} = \arctan{\frac{\frac{ed}{1+e\cos{\theta}}\sin{\theta}}{\frac{ed}{1+e\cos{\theta}}\cos{\theta}}}$$ Simplifying, we have $$\theta = \arctan{\frac{y}{x}} = \arctan{\frac{\sin{\theta}}{\cos{\theta}}} = \arctan{(tan{\theta})}$$ Again, we want both $\theta_1$ and $\theta_2$ to be equal: $$\arctan{\left(tan{\frac{2\pi t}{T_2}}\right)} = \arctan{\left(tan{\frac{2\pi t}{T_1}}\right)}$$ Which is equivalent to $$\frac{2\pi t}{T_2} = \frac{2\pi t}{T_1} + 2\pi k\ \ ,\  k \in \mathbb{Z}$$ So far so good. Now we want to find at which time $t$ , both $\omega_1$ and $\omega_2$ are equal. We can use the second approach: We know that the point (x',y') is $$(x',y')=2(j,k)-(x,y) = (2j-x,2k-y)$$ And we already know how to represent $x$ and $y$ in relation to time: $$(x,y) = \left(\frac{ed}{1+e\cos{\theta}}\cos{\theta}, \frac{ed}{1+e\cos{\theta}}\sin{\theta}\right)$$ This means that $(x',y')$ will be $$(x',y') = \left(2j-\frac{ed\cos{\theta}}{1+e\cos{\theta}}, 2k-\frac{ed\sin{\theta}}{1+e\cos{\theta}}\right)$$ Which means that the angle $\omega$ will be $$\omega = \arctan{\left(\frac{2k-\frac{ed\sin{\theta}}{1+e\cos{\theta}}}{2j-\frac{ed\cos{\theta}}{1+e\cos{\theta}}}\right)}$$ Since we want $\omega_1$ and $\omega_2$ to be equal $$\omega_2 = \omega_1 + 2\pi k$$ $$\arctan{\left(\frac{2k_2-\frac{e_2d_2\sin{\theta_2}}{1+e_2\cos{\theta_2}}}{2j_2-\frac{e_2d_2\cos{\theta_2}}{1+e_2\cos{\theta_2}}}\right)} = \arctan{\left(\frac{2k_1-\frac{e_1d_1\sin{\theta_1}}{1+e_1\cos{\theta_1}}}{2j_1-\frac{e_1d_1\cos{\theta_1}}{1+e_1\cos{\theta_1}}}\right)} + 2\pi k$$ and we know that $k_2=k_1=0$ since condition $5.$ doesn't apply: $$\arctan{\left(\frac{-\frac{e_2d_2\sin{\theta_2}}{1+e_2\cos{\theta_2}}}{2j_2-\frac{e_2d_2\cos{\theta_2}}{1+e_2\cos{\theta_2}}}\right)} = \arctan{\left(\frac{-\frac{e_1d_1\sin{\theta_1}}{1+e_1\cos{\theta_1}}}{2j_1-\frac{e_1d_1\cos{\theta_1}}{1+e_1\cos{\theta_1}}}\right)} + 2\pi k$$ Simplifying... $$\tan{\left(\frac{2\pi t}{T_1}\right)}e_2d_2(4j_1-e_1d_1) = tan{\left(\frac{2\pi t}{T_2}\right)}e_1d_1(4j_2-e_2d_2)$$ At which point, I got stuck. WolframAlpha does not give me a clear answer for $t$ , and if I substitute the example gif variables in this formula, WolframAlpha gives 5 possible $t$ , of which 3 contain an imaginary number $i$ . Which doesn't make sense since time doesn't have 2 dimensions. Questions Am I doing something wrong? Is there a more elegant solution to this problem that I'm not aware of? Why is WolframAlpha giving me imaginary numbers?","['trigonometry', 'conic-sections']"
3914626,Infinity norm of the inverse of a matrix with integer coefficients,Let $A$ be a $k$ -dimensional non singualar matrix with integer coefficients. Is it true that $\|A^{-1}\|_\infty \leq 1$ ? How can I show that? Could you give me a counterexample?It is clear that $\|A^{-1}\|_{\infty}=\frac{1}{\min\{\|Ax\|_{\infty}:\|x\|_{\infty}=1\}}$ . My idea is to show that the minimum is obtained on an integer point so the denominator is bigger than $1$ . Is mi idea right? Thank you very much!,"['matrices', 'inequality', 'normed-spaces', 'numerical-linear-algebra']"
3914653,"If polynomial $P(x)$ has integer coefficients and at least three integer roots, then $P(x)+5^m$ has no more than one integer root for $m\geq 1$","I've been doing some polynomial excersises lately and in that one I got completly stuck. Let $m \geqslant 1$ be natural number and $P(x)$ polynomial with integer coefficients which has at least three different integer roots. Prove that $P(x)+5^m$ has no more than one integer root. At first I considered the easiest case: $(x-x_1)(x-x_2)(x-x_3)+5$ , but it did not turned out in anything helpful, so I am seeking for some clues on how to crack that problem. Also, I'd like to ask for as elementary hint/solution as possible since this question is from (inactive) high school contest. https://om.mimuw.edu.pl/static/app_main/problems/om48_1.pdf","['algebra-precalculus', 'polynomials']"
3914680,Besov spaces: Regularization by convolution,"Consider either a Besov space $B_{p,q}^s$ or a Triebel-Lizorkin space $F_{p,q}^s$ with parameters $p,q \in [1,\infty)$ and $s \in \mathbb{R}$ . It is known that the Schwartz space $\mathcal{S}(\mathbb{R})$ is dense in $A_{p,q}^s$ for $A \in \{B,F\}$ . I was looking for a ""concrete"" approximation. From my perspective, the most natural idea is to use convolutions: Fix $f \in A_{p,q}^s$ with $A \in \{B,F\}$ . For $\chi \in C_c^{\infty}(\mathbb{R}^n)$ with $\chi \geq 0$ and $\int \chi(x) \, dx =1$ , define $\chi_k(x) := k^d \chi(kx)$ . Then $$f_k := f* \chi_k$$ should converge to $f$ in $A_{p,q}^s$ , right? Moreover, $f_k$ is a Schwartz function, and we are done. Does anybody know a reference for this result? I checked the books by Triebel and also the book by Sawano, but I couldn't find it (probably because it is ""obvious"").","['besov-space', 'functional-analysis', 'reference-request']"
3914695,"If you choose two different sets of results to match inside a coin flipping record, does the odds of finding a match depend on what you pick on each?","Example, if you flip a coin 10 times and record the results, and you pick 2 different sets of 5 length (e.g HHTHT and TTHTT where H=heads and T=tails) and the goal is to match any of your two sets anywhere inside the coin results (e.g TTTTHHTHTH contains the example set HHTHT ). The question is, can the combined odds of finding a match on either set be affected depending on the way the sets are chosen? Also bonus in case the odds vary, explain which strategies could be used to improve and/or worsen the chances of finding a match (if it doesn't matter at all, bonus doesn't apply obviously). My hypothesis is that if they overlap (e.g set_a = HHHHH and set_b = THHHH ) you end up with less odds of finding a match, but usually these kind of problems are counter-intuitive and I couldn't tackle this problem myself, at least not in a non-inductive way.",['statistics']
3914705,"Differentiation under the integral sign with $h(x,t) = e^{xt}f(t)$","I'm working on the following problem and got stuck: Let $f:\mathbb{R}\rightarrow\mathbb{R}$ such that for every fixed $x\in(-1,1)$ the function $g_x(t):= e^{tx}f(t) \in L^1(\mathbb{R})$ . Let $\varphi:(-1,1)\rightarrow \mathbb{R}$ be defined as $$\varphi(x) = \int{e^{tx}f(t)}dt$$ Show that $\varphi$ is differentiable. My attempt: Let $h(x,t):(-1,1)\times\mathbb{R} \longrightarrow \mathbb{R}$ $$h(x,t) = e^{tx}f(t)$$ Then, in order to differentiate under the integral sign, we need: $\bullet\space h(.,t)=e^{tx}f(t)\in L^1(\mathbb{R})$ (which we know by definition) $\bullet\space h(x,.)\in C(\mathbb{R}) \space\space\space[\frac{d}{dx}\left(e^{xt}f(t)\right)=t\cdot e^{xt}f(t)]$ and $\bullet\space \lvert\frac{d}{dx} h(x,t)\rvert=\lvert t\cdot e^{xt}f(t)\rvert < s(t)\space$ for some $s(t)\in L^1(\mathbb{R})$ This last step is where I'm stuck. I can't find such $s(t)$ that dominated my function. I think that if I'm able to do so, then I'd be done. Or is my approach incorrect? Thanks.","['integration', 'lebesgue-integral', 'derivatives']"
3914706,"If $\,\lim_{p\to\infty} \sum_{j=1}^n a_j\cos(p\pi \theta_j) \to 0,\,$ then $\,a_1 = \dots = a_n = 0$.","The exercise Let $n \geq 1$ , $0 < \theta_1 < \dots < \theta_n < 1$ and $a_1, \dots, a_n \in \mathbb{R}^n$ . Assume $ \sum_{j=1}^n a_j\cos(\pi p \theta_j) \underset{p \to +\infty}{\longrightarrow} 0$ ( $p \in \mathbb{N}$ ). Show $a_1 = \dots = a_n = 0$ . My try I tried to prove this by induction over $n$ . I succeeded for $n = 1$ , but I have no clue to show how the property can be used for $n \geq 2$ .","['real-analysis', 'calculus', 'sequences-and-series', 'limits', 'trigonometry']"
3914723,Subgroups of free groups which avoid conjugacy classes,"Let $G = (\mathbb Z/2\mathbb Z)^{\ast m}$ be a free product of some groups of order $2$ .  Let $\alpha_1,\ldots,\alpha_m$ be the generators. Can I find a free, nonabelian subgroup of $G$ that has no nontrivial elements conjugate to any $\alpha_i \alpha_j$ ? How can I prove it?","['combinatorial-group-theory', 'group-theory', 'free-groups']"
3914827,Show that the set of points equals the function,"Let $f : A \rightarrow B$ be a function and let $\text{graph}(f) := \{(x, f(x))\mid x \in A\}$ . Show that $\text{graph}(f)= f$ . Could you give me a hint for that? Isn't that obvious since $\{(x, f(x))\mid x \in A\}$ is also the definition of a function?","['elementary-set-theory', 'functions']"
3914837,Determinant of Kronecker Product,"Problem. Let $A$ be an $m\times n$ matrix and $B$ be an $n\times m$ matrix. Show that $$\det(A\otimes B)=\det(B\otimes A).$$ This formula apparently holds if $A$ and $B$ are square matrices, but here this assumption fails in general. I am considering the general definition of determinant: $$\det(M)=\sum_{\sigma\in S_n}{(-1)^{\rm sgn(\sigma)}a_{1\sigma(1)}\cdots a_{n\sigma(n)}}.$$ We have $$\det(B\otimes A)=\det((B\otimes A)^T)=\det(B^T\otimes A^T).$$ The shape of $B^T$ is the same as $A$ and the shape of $A^T$ is the same as $B$ . Intuitively, the summands in the two determinants are exactly the same, but this argument is vague and complicated. It would be better if anyone has some easier proofs.","['matrices', 'determinant', 'kronecker-product']"
3914856,Finding the characteristic exponents (Floquet/Lyapunov exponents) of ODEs with periodic coefficients,"I am interested in finding the characteristic exponents $\lambda_i$ of the ODE $\pmb{x}'\left(t\right) = \pmb{A}\left(t\right)\pmb{x}\left(t\right)$ , where $\pmb{A}\left(t\right)$ is periodic with period $T$ . In particular, consider the following $2$ D case $\left[ {\begin{array}{cc}
   x \\
   y \\
  \end{array} } \right]' = \left[ {\begin{array}{cc}
   a_1 + b_1 \sin(\omega t) & a_2 + b_2 \sin(\omega t) \\
   a_3 + b_3 \sin(\omega t) & a_4 + b_4 \sin(\omega t) \\
  \end{array} } \right]\left[ {\begin{array}{cc}
   x \\
   y \\
  \end{array} } \right]$ , where $a_i$ , $b_i$ , and $\omega$ are all constants. Although we have useful relations such as $$\lambda_1+\lambda_2= \frac{1}{T}\int_0^T {\mathrm tr}\boldsymbol{A}(\tau)\,\mathrm{d}\tau,$$ in order to find the values of individual $\lambda_1$ and $\lambda_2$ , we still need to calculate the principal fundamental matrix, which as far as I know requires solving the original ODE. I know for the $1$ D case $x' = \left(a_1 + b_1 \sin(\omega t)\right) x$ , the solution is $x(t) = c_1\mathrm{e}^{-\frac{b_1}{\omega}\cos(\omega t)+a_1 t}$ . But what is the solution to the $2$ D case above? I tried something like $$x(t) = c_1\mathrm{e}^{p_1\cos(\omega t)+q_1 t} + c_2\mathrm{e}^{p_2\cos(\omega t)+q_2 t},$$ $$y(t) = c_3\mathrm{e}^{p_1\cos(\omega t)+q_1 t} + c_4\mathrm{e}^{p_2\cos(\omega t)+q_2 t},$$ but it doesn't seem to work.","['stability-theory', 'ordinary-differential-equations', 'dynamical-systems']"
3914898,How to solve $-4xy + x^2 - y^2 + 4x^2 \frac{dy}{dx} = 0$?,"We want to find the exact solution of the following ODE: $$
-4xy + x^2 - y^2 + 4x^2 \frac{dy}{dx} = 0
\quad
\quad
y = 2, x = 1
$$ This is my attempt:
We need to match this form: $$M(x,y) + N(x,y) \frac{dy}{dx} = 0$$ Then we find $M(x,y)$ and $N(x,y)$ : $$M(x,y) = -4xy + x^2 -y^2$$ $$N(x,y) = 4x^2$$ From this we get two differential equations: $$\frac{d\Psi(x,y)}{dx} = M(x,y)$$ $$\frac{d\Psi(x,y)}{dy} = N(x,y)$$ It is not important which one we solve by integrating.
Here we integrate the first one. $$\Psi(x,y) = \int M(x,y) dx  $$ $$= \int -4xy + x^2 - y^2  dx $$ $$= -2x^2y + \frac{x^3}{3} -xy^2  + C(y) = \Psi(x,y)$$ So far so good. From this onward I try to methods and both fail. First ATTEMPT: Integrating the other differential equation we get $$ 4x^2y  + D(x) = \Psi(x,y)$$ comparing the two $$ 4x^2y  + D(x) = \Psi(x,y) =-2x^2y + \frac{x^3}{3} -xy^2  + C(y)  $$ not sure what to do next since it is not easy to deduce the $C(y)$ and $D(x)$ from here. Second ATTEMPT: Now we use the OTHER differential equation: $$\frac{d\Psi(x,y)}{dy} = N(x,y)= 4x^2$$ and we use the $\Psi(x,y)$ that we found. We now need to find $C(y)$ . $$\frac{d\Psi(x,y)}{dy} = 4x^2$$ $$ -2x^2 -2xy + \frac{dC(y)}{dy}= 4x^2$$ $$ -6x^2 -2xy + \frac{dC(y)}{dy}= 0$$ integrating everything with respect to y
with constant of integration K(x), we get $$ -6x^2y -xy^2 + C(y) + K(x) = 0 $$ solve the above for $C(y)$ $$ C(y) = 6x^2y +  xy^2 - K(x) $$ and substitute into $\Psi(x,y)$ to get $$\Psi(x,y) = -2x^2y + \frac{x^3}{3} -xy^2 + 6x^2y +  xy^2 - K(x)  = 0   $$ $$\Psi(x,y) =  \frac{x^3}{3}  + 4x^2y  -K(x)  = 0   $$ we differentiate with respect to x $$\frac{d\Psi(x,y)}{dx} = M(x,y)$$ $$ x^2 + 8xy - \frac{dK(x)}{dx}= -4xy + x^2 -y^2 $$ $$ y^2 + 12xy  =  \frac{dK(x)}{dx} $$ $$ xy^2 + 6x^2y + Q  =  K(x) $$ $$\Psi(x,y) =  \frac{x^3}{3}  + 4x^2y - xy^2 - 6x^2y    + Q    = 0   $$ $$\Psi(x,y) =  \frac{x^3}{3}  -2x^2y - xy^2  + Q  = 0   $$ However I think here we get into an infinite loop because $Q$ is actually $Q(y)$ which
needs to be determined using a similiar integration ... so again I don't know what to do. The final solution $\Psi(x,y)$ does not agree with:: $$\frac{d\Psi(x,y)}{dx} = M(x,y)$$ $$\frac{d\Psi(x,y)}{dy} = N(x,y)$$ What am I doing wrong?","['integration', 'ordinary-differential-equations', 'calculus', 'indefinite-integrals', 'derivatives']"
3914899,Derivation of mutual information's closed-form analytical solution,"$$I(X;Y) = -\frac{1}{2} \ln(1-\rho^2)$$ is the mutual information between two Gaussian random variables. What source derived this formula? Could we have the full derivation here as an answer. First Attempt Given $f(x)$ is the Gaussian p.d.f. of variable $X$ and $f(y)$ is the Gaussian p.d.f. of variable $Y$ , and \begin{align}
f(x,y)&=\frac{1}{\left( (2\pi)^{n}\det{(\boldsymbol
\Sigma)}\right)^\frac{1}{2}  }\exp\left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})%
\right)\\
& = \frac{1}{2 \pi \sigma_X \sigma_Y \sqrt{1-\rho^2}} 
\exp \left\{ -\frac{1}{2\left(1-\rho^2\right)} \left[ \left(\frac{x-\mu_{X}}{\sigma_{X}}\right)^2
+ \left(\frac{y-\mu_{Y}}{\sigma_{Y}}\right)^2 -2\rho \left(\frac{x-\mu_{X}}{\sigma_{X}}\right) \left(\frac{y-\mu_{X}}{\sigma_{Y}}\right) \right] \right\}
\end{align} is the joint distribution where $\boldsymbol{x}, \boldsymbol{\mu}$ and $\boldsymbol{\Sigma}$ are the data observations, means and covariance matrix of the joint distribution, \begin{align}
I(X;Y) &= \int \int f(x,y) \ln \frac{f(x,y)}{f(x)f(y)} dx dy\\
&= \int \int f(x,y) \ln \frac{f(x,y)}{\left(2\pi \sigma_X^2\right)^{-\frac{1}{2}} e^{-(x-\mu_X)^2 / 2\sigma_X^2} \cdot \left(2\pi \sigma_Y^2\right)^{-\frac{1}{2}} e^{-(y-\mu_Y)^2 / 2\sigma_Y^2}} dx dy\\
&= ?
\end{align}","['statistics', 'entropy', 'logarithms', 'information-theory', 'gaussian']"
3914911,Why does graph $y=(\ln y/\ln x) x-\ln y/\ln x (x^2/y)+x$ not include $x = y$?,"Why does the graph $y=(\ln y/\ln x)x (-\ln y/\ln x (x^2/y))+x$ not include all positive $y$ and $x$ for which $y = x$ ? When I plotted this graph on desmos , the plot did not include the line $y = x$ , even though the equation is solved for all $y = x$ . This equation came up in the context of me trying to prove that the equations of the solutions to $x^y = y^x$ intersect at the point $(e,e)$","['algebra-precalculus', 'functions']"
3914921,Biharmonic functions on closed manifolds?,"Let $(M,g)$ be a closed (compact, $\partial M=\varnothing$ ) smooth connected Riemannian manifold with Laplaceâ€“Beltrami operator $\Delta_g$ . As it is well-known, every harmonic function ( $u\in \ker \Delta_g$ ) on $M$ is constant (e.g. Hodge Isomorphism Theorem). Question: What about biharmonic functions ( $u\in \ker \Delta_g^2$ )?
In particular, can we say that every (everywhere defined, at least continuous) (distributionally) biharmonic function on $M$ is constant? A few remarks: of course, the answer is negative on non-compact manifolds (think polynomials on $\mathbb R^n$ ), as well as on bounded domains with appropriate boundary conditions. (See e.g. this question ). Equivalently, we may look for smooth solutions to the Poisson equation $\Delta_g u\equiv 1$ . By multiplying on both sides by $u$ and integrating w.r.t. the Riemannian volume $\mu_g$ we get: $$\int u \Delta_g u d\!\mu_g=\int |du|^2 d\!\mu_g=\int u d\!\mu_g$$ If $u$ has mean $0$ , we immediately get that it is constant. If otherwise, we may assume that $\int u d\!\mu_g=1$ , in which case the same holds for $|du|^2$ . In particular if $u$ is a solution to the eikonal equation $|du|^2\equiv\mu_g(M)^{-1}$ , then it is biharmonic. If we allow $du$ to have a singularity at some point $x_0$ in $M$ , then this solution should be (?) the Green kernel for the bi-Laplacian pinned at $x_0$ . If however $du\equiv 1$ everywhere, I do not see why a solution should exist.","['laplacian', 'partial-differential-equations', 'riemannian-geometry', 'differential-geometry']"
3914956,Proof: not a perfect square,"Let $y$ be an integer.
Prove that $$(2y-1)^2 -4$$ is not a perfect square. I Found this question in a discrete math book and tried solving it by dividing the question into two parts: $$y = 2k , y = 2k + 1$$ But that got me nowhere.","['square-numbers', 'discrete-mathematics']"
3915027,Can an arbitary Jordan curve be approximated by a smooth Jordan curve?,"Given a Jordan curve $\gamma_1 \colon [a,b] \to \mathbb{C}$ and an $\epsilon > 0$ , can we find a continuously differentiable Jordan curve, $\gamma_2 \colon [a,b] \to \mathbb{C}$ , such that $ |\gamma_1(t) - \gamma_2(t) | < \epsilon$ for all $ t \in [a,b]$ ?","['complex-analysis', 'curves', 'differential-geometry']"
3915044,How does integration of forms make sense?,"I don't understand how integration of a $k$ -form on a manifold makes sense. For simplicity let's assume $M$ is a smooth $k$ -manifold, $\gamma: [a,b] \rightarrow M$ is a smooth curve on $M$ and that $\omega \in \Omega^1(M)$ . Then by definition, $$\int_{\gamma} \omega = \int_{[a,b]} \gamma^* \omega$$ In coordinates $(x^i)$ we can write $\omega = \omega_i dx^i$ so that we then have $$\int_{[a,b]} \gamma^* \omega = \int_a^b (\omega_i \circ \gamma)d\gamma^i = \int_a^b (\omega_i \circ \gamma) \frac{d\gamma^i}{dt}dt$$ From an elementary calculus point of view, when integrating, we take the value of $(\omega_i \circ \gamma) \frac{d\gamma^i}{dt}$ at a point on some subrectangle of some partition, which gives us a real number. We then multiply it by the length of the subrectangle (which is approximated by $dt$ ), which is also a real number and we add these products up, then let the mesh of the partition tend to $0$ . From a differential forms point of view, $(\omega_i \circ \gamma) \frac{d\gamma^i}{dt}$ is a function that is being multiplied by the $1$ -form $dt$ . The value of $(\omega_i \circ \gamma) \frac{d\gamma^i}{dt}$ at a point of a subrectangle is a real number, but the value of $dt$ , since it is a covector field , is a covector. Thus the value of $(\omega_i \circ \gamma) \frac{d\gamma^i}{dt} dt$ at a point of a subrectangle is a covector as well. How does it make sense to sum up a bunch of covectors to obtain a real number (the value of the integral)?","['line-integrals', 'differential-forms', 'differential-geometry']"
3915100,"Let $f:[a, b]\rightarrow\mathbb{R}$ be differentiable. If $f'(a)=f'(b)$, then exists a $c \in (a, b)$, such that $f'(c) = \frac{f(c) - f(a)}{c - a}$","In the book ( Curso de AnÃ¡lise, volume 1 ,Elon Lages), there is a suggestion that helps a lot. First, consider that $$f'(a) =f'(b)=0$$ Then, consider the function $g:[a,b] \rightarrow \mathbb{R}$ , where $g(x) = \frac{f(x) - f(a)}{x - a}$ and $g(a) = 0$ . Show that $g$ reaches it's maximum or minimum in a point $c \in (a,b)$ . For the general case, consider $$g(x) = f(x) - xf'(a)$$ I can see why the first case: if a take the derivative of g, I end up with something like: $$g'(x) = \frac{1}{x - a} \left( f'(x) - \frac{f(x) - f(a)}{x - a} \right)$$ So, by being continuous (from the differentiable hypothesis) on a compact set, by Weierstrass's Theorem, we have that $g$ must have it's maximum/minimum on $c \in [a,b]$ . By being a critical point, we must have $g'(c) = 0$ , and assuming $c \neq a$ , we have our first conclusion. But (1) I can't see why it must be a interior point (seriously, I've been on this question for 4 days), and (2) the second suggestion isn't that clear for me. Any other ideas for solutions will be of great help to me.","['limits', 'derivatives', 'real-analysis']"
3915135,"Extend an integral inequality from $C[0,1]$ to the whole $L^{2}([0,1])$ [related to operator norm].","Consider the following integral defined for $f\in L^{2}[0,1]$ and $x\in [0,1]$ , that $$(T^{n}f)(x)=\dfrac{1}{(n-1)!}\int_{0}^{x}(x-r)^{n-1}f(r)dr.$$ This shows that for $f\in C[0,1]$ and for any $x\in [0,1]$ , we have $$|(T^{n}f)(x)|\leq \dfrac{1}{(n-1)!}\int_{0}^{x}(x-r)^{n-1}|f(r)|dr\leq \dfrac{\|f\|_{\infty}}{n!}.$$ By definition of operator norm, this implies that the operator norm of $T^{n}$ $$\|T^{n}\|\leq \dfrac{1}{n!},$$ if the operator is on $C[0,1]$ . However, I want to prove the same bound of this operator norm on the whole $L^{2}([0,1])$ .  Is there anyway for me to extend this proof to all of $f\in L^{2}([0,1])$ ? and to conclude $\|T^{n}\|\leq\frac{1}{n!}$ My attempt was to use density of continuous function of compact support in $L^{2}$ to find $g$ such that $f=g+\epsilon$ where $\epsilon>0$ is arbitrarily fixed. Then we bound the integral in the same way, and you will have a summation, the second term in the summation will go to $0$ when $\epsilon\searrow 0$ . Therefore, we again have $$|(T^{n}f)(x)|\dfrac{\|g\|_{\infty}}{n!}.$$ But this cannot say anything to the operator norm $\|T\|$ . What should I do? Thank you! Edit: The overall purpose is to derive that $\|T\|\leq\frac{1}{n!}$ . So if there is any other way to find this, it will also be really good. Edit2: Proof Okay, I confused myself in the first place. The operator norm has nothing to do with the sup-norm since $T:L^{2}\longrightarrow L^{2}$ , so what we should do is to use Cauchy-Schwarz and $\|f\|_{L^{2}}$ . See below my own answer to my post for details. Also, Ruy gave a general theorem about how to compute the operator norm for Hilbert-Schmidt operator, and my computation will show you the idea about the proof. Basically, the absolute value of operator will be bounded by $\|f\|_{L^{2}}$ multiplication of the $L^{2}-$ integral of the kernel, so we should expect such a theorem. Thank you so much for all the users who helped me!!","['operator-theory', 'real-analysis', 'lp-spaces', 'functional-analysis', 'inequality']"
3915192,Classification of degree 3 rational maps on a hyperelliptic curve,"It's amazing how far in life you can get with theorems, without stopping to do any calculations. Let $\Sigma_2$ be a genus $2$ curve embedded in the projective plane given by the equation $z^4 y^2 = \prod_{i=1}^6 (x - z \zeta_i)$ in homogenous coordinates, with the $\zeta_i$ of course being the fixed points of the hyperelliptic involution. I want to understand what the possible degree $3$ rational maps are from $\Sigma_2$ to $\mathbb{CP}^1$ . Since the maps I'm interested in are rational maps, we just work in affine coordinates. This is convenient because as written, such a curve is singular at $[0:1:0]$ in the projective plane, and I don't want to have to compute the normalization. Now this reduces the problem to fidning when $[\mathbb{C}(x,y):f^\ast(\mathbb{C}(t))] = 3$ where $t$ is the local coordinate on $\mathbb{C}$ , and $x,y$ satisfy $y^2 = \prod(x-\zeta_i)$ . Prima facie this happens in two ways. By finding a degree $1$ map from $\Sigma_2 \to \mathbb{CP}^1$ and composing with a degree $3$ map from the sphere to itself, and by finding a genuine degree $3$ map. The former isn't possible though, since a degree $1$ map would be an isomorphism. Such a map is of course defined by what it does to $t$ . So I send $t \mapsto F(x,y)$ . Is there a strategy for computing the degree? Somehow I have made it this far in my life and only seen trivial examples, where the fields in question are things like $\mathbb{Q}(\text{radicals and stuff})$ over $\mathbb{Q}$ . In an attempt to figure this out, I noticed that I can write this as $F(x,y) = \frac{P(x,y)}{Q(x,y)}$ , and then $P,Q$ can be written as polynomials in $y$ , i.e. $P(x) = P_1(x) + yP_2(x)$ using the equation of the curve. Now the degree of $F$ is the difference of the degrees of $P$ and $Q$ , so I just need to compute these degrees. I believe that the degree of $y$ is $6$ (after being enlightened in the comments) since a generic choice of $y$ , we will obtain a polynomial of degree $6$ , having $6$ solutions. and the degree of $P_1, Q_1$ should be simply their degrees as polynomials in $x$ . Is all this correct? If so, then I think this tells us roughly how to classify the maps on hyperelliptic curves of a given degree.","['algebraic-geometry', 'solution-verification']"
3915264,Triangle related problem,"In the figure below if $tan \alpha=\frac{m}{n}$ , where $m$ and $n$ are relatively prime, find the value of $m$ and $n$ . My approach is as follow $\frac{{SinA}}{{14}} = \frac{{SinB}}{{15}} = \frac{{SinC}}{{13}}$ $\Delta APB$ $\angle PBA = B - \alpha $ $\angle APB = 180 - \left( {\alpha  + B - \alpha } \right) = 180 - B$ $\frac{{Sin\left( {180 - B} \right)}}{{13}} = \frac{{Sin\alpha }}{{BP}} \Rightarrow SinB = \frac{{13Sin\alpha }}{{BP}}$ $\Delta APC$ $\angle PAC = A - \alpha $ $\angle APC = 180 - \left( {\alpha  + A - \alpha } \right) = 180 - A$ $\frac{{Sin\left( {180 - A} \right)}}{{15}} = \frac{{Sin\alpha }}{{AP}} \Rightarrow SinA = \frac{{15Sin\alpha }}{{AP}}$ $\Delta BPC$ $\angle PCB = C - \alpha $ $\angle BPC = 180 - \left( {\alpha  + C - \alpha } \right) = 180 - C$ $\frac{{Sin\left( {180 - C} \right)}}{{13}} = \frac{{Sin\alpha }}{{PC}} \Rightarrow SinC = \frac{{13Sin\alpha }}{{PC}}$ $\frac{{SinA}}{{SinB}} = \frac{{\frac{{15Sin\alpha }}{{AP}}}}{{\frac{{13Sin\alpha }}{{BP}}}} = \frac{{14}}{{15}} \Rightarrow \frac{{{{15}^2}}}{{13 \times 14}} = \frac{{AP}}{{BP}}$ How do I approach from here?","['contest-math', 'trigonometry', 'triangles', 'geometry']"
3915303,"Prove that $a_{n+2}=0.5(a_n+a_{n+1})$, $a_1=2, a_2=5$ has a limit, and find it","I have the following sequence: $a_{n+2}=0.5(a_n+a_{n+1})$ , $a_1=2, a_2=5$ , and I need to prove that $\lim\limits_{n\to \infty}a_n$ exists, and find it. I don't know ho to prove that the limit exists, since the sequence neither decreasing nor increasing. In addition, I don't know how to find it, since the equation I am getting is $L=0.5(L+L)$ , whitch is true for all $L$ .","['limits', 'calculus']"
3915313,Unique linear transformation carrying projective hyperplane to projective hyperplane and point to point - a concise proof,"Let $\mathbb P^n$ denote the projective $n$ -space over an algebraically close field $k$ , i.e. $\mathbb P^n$ is given by $(\mathbb A^{n+1}\setminus \{0\})/ \sim$ where $\mathbb A^{n+1}$ is the affine $(n+1)$ -space and $\sim$ is the equivalence relation identifying points which are scalar multiples of one another, that is for two points $(a_0, \cdots , a_n)$ and $(b_0, \cdots , b_n)$ in $\mathbb A^{n+1}$ , $$(a_0, \cdots , a_n) \sim (b_0, \cdots , b_n) \iff \exists \hspace{1mm} \lambda \in k^\times \text{ s.t. } b_j = \lambda a_j \text{ for all }1 \leq j \leq n$$ By a hyperplane in $\mathbb P^n$ , I shall mean the zero set of some linear homogenous polynomial $f \in k[x_0, \cdots , x_n]$ , that is some polynomial of the form $f(x_0, \cdots , x_n) := \sum_{j=0}^n a_j x_j$ where $(a_0, \cdots , a_n) \in \mathbb P^n$ . I have seen the following result get used in a few contexts before, and although I can see intuitively why it must be true, I have been unable to find a rigorous argument justifying the same: Fact(?) Let $H$ be a hyperplane and $P$ any point in $\mathbb P^n \setminus H$ . Then there exists a linear transformation $A \in \text{GL}_{n+1}(k)$ such that $A(H)$ is the hyperplane $\{(x_0, \cdots , x_n) : x_0=0\}$ and $A(P) = (1, 0, \cdots , 0)$ . I am looking for a complete and concise proof of this result, which is clean if possible. I believe that one possible argument could rest on the following observations: $H$ is uniquely determined by any $n$ points on it. So we now pick $n+1$ points $P_1, \cdots , P_n$ on $H$ . There exists a linear transformation sending $P$ to $(1, 0, \cdots,  0)$ and $P_j$ to $(0, \cdots , 0 , 1, 0, \cdots, 0) \in \mathbb P^n$ ( $0$ in the $j$ -th slot, here the $n+1$ slots are being called the $0$ -th, $1$ -st, ..., $n$ -th slot slots) for each $1 \leq j \leq n$ . I have however been unable to make these clean and rigorous (I keep getting involved with too many linear equations) and am starting to doubt the accuracy of my intuition. I would really appreciate a complete argument for the above ""Fact(?)"" or a reference containing the same and if possible, suggestions on how to make my idea work. Edit (Some Progress): Thanks to Roland's comment, I think I have made some progress: Let $H$ be given by the equation $\sum_{j=0}^n a_j x_j = 0$ . Then in $\mathbb A^{n+1}$ , $H$ remains the same (nevertheless I will call it $H_0$ when viewed as a subset of $\mathbb A^{n+1}$ ) while $P := (p_0, \cdots , p_n)$ becomes the line $L_0 := \{(p_0 t, \cdots , p_n t) : t \in k\}$ . I should first show that there is a matrix $A \in \text{GL}_{n+1}(k)$ such that $A(H_0) = H_1$ and $A(L_0)=L_1$ , where $H_1 := \{(0, x_1, \cdots , x_n) : x_j \in k\} \subset \mathbb A^{n+1}$ and $L_1$ is the line $\{(t, 0, \cdots , 0) : t \in k\} \subset A^{n+1}$ . So now I can pick $n$ linearly independent points $A_j \in H_0$ ( $1 \leq j \leq n$ ), which is possible since $H_0$ is an $n$ -dimensional subspace of $\mathbb A^{n+1}$ and I get a linear transformation $A \in \text{GL}_{n+1}(k)$ which sends $A_j$ to $(0, \cdots , 0 , 1, 0, \cdots 0)$ (with $1$ in the $j$ -th slot) for each $1 \leq j \leq n$ . Thus $A$ sends $H_0$ to $H_1$ . I still have to send $A(L_0)$ to $L_1$ so I need a linear transformation $T \in \text{GL}_{n+1}(k)$ which sends $A(L_0)$ (which is also a line through the origin) to $L_1$ and leaves $H_1$ invariant (as a set). Finally, we let $T \in \text{GL}_{n+1}(k)$ be the linear transformation that sends $(p_0, \cdots , p_n) \in \mathbb A^{n+1}$ to $(1, 0, \cdots , 0)$ and fixes some basis of $H_1$ pointwise. Upon getting this last linear transformation $T$ , we note that $TA \in \text{GL}_{n+1}(k)$ sends $H_0$ to $H_1$ and $L_0$ to $L_1$ in $\mathbb A^{n+1}$ . Therefore $TA$ should also do the required job, namely, send $H$ to $\{(0, x_1, \cdots , x_n)\} \subset \mathbb P^n$ and $P$ to $(1, 0, \cdots 0)$ , thus completing the proof and making ""Fact(?)""$ a fact. My only follow-up question: Is this argument correct or are there are any gaps?","['projective-geometry', 'geometry', 'reference-request', 'algebraic-geometry', 'projective-space']"
3915318,Maxima and minima of $\frac{x^2-3x+4}{x^2+3x+4}$ without calculus,"How to find the minimum and max values of $y=\frac{x^2-3x+4}{x^2+3x+4}$ for all real values of $x$ without using calculus? Perhaps it could be done graphically by noting the fact that the numerator and denominator are a pair of parabolas symmetric about the $x$ axis, but I do not know how to continue. Thanks!","['maxima-minima', 'algebra-precalculus', 'rational-functions']"
3915342,Let $X_k$ be a sequence of IID random variable with $E(X_k)=0$ and finite variance. Show that $\frac{S_n}{n^p} \xrightarrow{a.s.} 0$ for p > 1/2,"My idea to this question is $\frac{S_n}{n^p}=\frac{S_n}{\sigma\sqrt{n}}\cdot\frac{\sigma}{n^{p-1/2}}$ By CLT, $\frac{S_n}{\sigma\sqrt{n}} \xrightarrow{d} N(0,1)$ Also, it can be shown $\frac{\sigma}{n^{p-1/2}} \xrightarrow{d} 0$ Therefore, $\frac{S_n}{\sigma\sqrt{n}}\cdot\frac{\sigma}{n^{p-1/2}}=\frac{S_n}{n^p} \xrightarrow{d} 0$ Since it converges to a constant, it implies $\frac{S_n}{n^p} \xrightarrow{p} 0$ We know if $\frac{S_n}{n^p} \xrightarrow{p} 0$ , then there is a subsequence $\frac{S_{n_{k}}}{n_k^p} \xrightarrow{a.s.} 0$ . My question is how to show such subsequence $\frac{S_{n_{k}}}{n_k^p}\xrightarrow{}  \frac{S_n}{n^p}$ ?","['convergence-divergence', 'probability-theory', 'probability']"
3915358,How to solve this trigonometric equation further?,"Find the sum of the roots of the equation $$
\sin (2\cos x - \sqrt{3}) = 0
$$ belonging to the segment $$
A_m = [2m\pi; ~ \frac{\pi}{2} + (2m+2)\pi]
$$ where $m = -4$ . Round the number to two decimal places if necessary. my incomplete solution: $$2\cos x - \sqrt 3 = k\pi$$ $$k = 0 \text{ fits}$$ $$k = 1$$ $$ 2\cos x = pi + \sqrt3 = 3.14 + 1.73> 2$$ - not suitable. For
larger $k$ , it is even worse ... $$k = -1$$ $$2\cos x = -3.14 + 1.73 = -1.41$$ Hmm Suitable unfortunately.
Smaller ones won't fit This means that there are 2 options $$cos x = 0$$ $$x = \pi / 2 + 2n\pi$$ The segment $$[-8\pi, \pi / 2 - 6\pi]$$ 2
roots hit $$-8\pi + \pi / 2$$ and $$-6\pi + \pi / 2$$ $$\cos x = -0.705$$ (coincidence with the root of 2 is random here) But
approximately you can say $$x = + -2\pi / 3 + 2n\pi$$ I have a problem with subsequent calculations, it lies in the fact that I do not understand how and what to calculate I would be grateful if you could solve this problem to the end with an explanation","['integration', 'algebra-precalculus', 'linear-algebra', 'trigonometry']"
3915561,"Subfields of $\mathbb{Q}(x,y)$ of the form $\mathbb{Q}(p,q,r)$","Let $\mathbb{Q}(x,y)$ be the field of rational functions in the variables $x, y$ with rational coefficients. Choose $p, q, r \in \mathbb{Q}(x,y)$ and consider the subfield $K=\mathbb{Q}(p,q,r)$ . Is it generally true that there exist $s, t \in K$ such that $K=\mathbb{Q}(s,t)$ ? Any help is welcome. NOTE. This question is a particular, but very interesting case of question (II) of my previous post Subextensions of Finitely Generated Fields .
In his answer to my other post Can $\mathbb{Q}(x^3,y^3,x+y)$ be generated by only two elements? professor RenÃ© Schoof proved that the answer is positive for the particular choice $p=x^3, q=y^3, r=x+y$ , which I had thought to give rise to a counterexample.","['field-theory', 'algebraic-geometry', 'abstract-algebra']"
3915589,Making sense of $x'=Ax\implies x(t)=e^{Jt}x(0)$ when $A$ is nondiagonalizable,"How do I make sense of $x'=Ax$ is solved by $x(t)=e^{Jt}x(0)$ when $A$ is nondiagonalizable. When we have an $n\times n$ system of ODE's, $\dfrac{dx}{dt}=Ax$ and if $A=VD_AV^{-1}$ is diagonalizable. Substitute $x=Vy$ , $$
\dfrac{dx}{dt}=Ax\implies V\dfrac{dy}{dt}=AVy\implies \dfrac{dy}{dt}=V^{-1}AVy=D_Ay\\
\begin{bmatrix}y_1'\\\vdots\\y_n'\end{bmatrix}=\begin{bmatrix}\lambda_1&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&\lambda_n\end{bmatrix}\begin{bmatrix}y_1\\\vdots\\y_n\end{bmatrix}\implies y_i(t)=c_ie^{\lambda_it}\\
x(t)=Vy(t)=\begin{bmatrix}v_1&\cdots&v_n\end{bmatrix}\begin{bmatrix}c_1e^{\lambda_1t}\\\vdots\\c_ne^{\lambda_nt}\end{bmatrix}\implies x(t)=c_1v_1e^{\lambda_1t}+\cdots+c_nv_ne^{\lambda_nt}\\
x(0)=V\begin{bmatrix}c_1\\\vdots\\c_n\end{bmatrix}=Vc\implies c=V^{-1}x(0)
$$ $$
x(t)=V\begin{bmatrix}e^{\lambda_1t}&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&e^{\lambda_nt}\end{bmatrix}\begin{bmatrix}c_1\\\vdots\\c_n\end{bmatrix}=V\begin{bmatrix}e^{\lambda_1t}&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&e^{\lambda_nt}\end{bmatrix}c=V\begin{bmatrix}e^{\lambda_1t}&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&e^{\lambda_nt}\end{bmatrix}V^{-1}x(0)=e^{At}x(0)
$$ where $e^{At}=V\begin{bmatrix}e^{\lambda_1t}&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&e^{\lambda_nt}\end{bmatrix}V^{-1}$ I think it makes sense why we define $e^{At}=Ve^{D_At}V^{-1}$ the way it is and how it comes into picture and we can also prove the Taylor series expansion is the same thing. When $A$ is nondiagonalizable $A$ can be decomposed into $A=XJX^{-1}\implies J=X^{-1}AX$ is called the Jordan canonical form and $X$ contains generalized eigenvectors $x_k$ such that $Ax_k=Î»_kx_k$ , or $Ax_k=Î»_kx_k+x_{kâˆ’1}$ and $J=X^{-1}AX=\begin{bmatrix}J_1&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&J_s\end{bmatrix}=J_1\oplus\cdots\oplus J_s$ where $J_i=\begin{bmatrix}\lambda_1&1&0&\cdots&0\\0&\lambda_2&1&\cdots&0\\\vdots&\vdots&\vdots&\ddots&\vdots\\0&0&0&\cdots&\lambda_i\end{bmatrix}$ Substitute $x=Az$ $$
x'=Ax\implies Bz'=ABz\\
z'=B^{-1}ABz=Jz\\
\begin{bmatrix}z'_1\\\vdots\\z'_n\end{bmatrix}=\begin{bmatrix}J_1&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&J_s\end{bmatrix}\begin{bmatrix}y_1\\\vdots\\z_n\end{bmatrix}
$$ I don't think it goes anywhere with it ! In this case how do I make sense of the fact that $x(t)=e^{Jt}x(0)$ solves $x'=Ax$ similar to the one we obtained above ?","['jordan-normal-form', 'linear-algebra', 'ordinary-differential-equations']"
3915595,Smooth function with specific features,"Im looking for a function that's continuous everywhere and whose second derivative is continuous everywhere with the following properties: Near the origin, the function is approximately constant: $$f\approx c$$ with $c \in \mathbb{R}$ Far from the origin (outside some scale), the function is approximately linear: $$f(x) \approx m*x+b$$ with $m \neq 0$ So the function would look like . I just defined this function piecewise in mathematica as an example, but the second derivative is not continuous, because the curvy bits are quadratic and the flat bits are linear, so the second derivative is a series of steps. I will eventually define a vector field from this scalar field which describes a flow in a flat manifold. Moreover, there is an energy functional that is defined in terms of the second derivatives of this scalar field, hence the reason for continuity. I tried using bump functions and integrating backwards to get the scalar field I want, but the integrals became messy quite fast, as you might expect. Similarly, I tried using hyperbolic tangents, but I wasn't able to smoothly attach the pieces together. I am also trying to minimize the magnitude of the second derivative (because it relates to the energy functional). So I am hoping to find a function that approaches the origin in a linear way, then curves in such a way that the second derivative has constant sign, then approaches zero again, then has constant opposite sign. Here is an example of such a second derivative using bump functions. I tried integrating this and using the integration constants to satisfy my required properties, but the integrals are quite messy! I appreciate any help!","['continuity', 'functions', 'real-analysis']"
3915661,Power sets of sets with nonempty intersection (Set Theory),"I started learning about Set Theory and I ran into the following unproven lemma:
There exist sets $A$ and $B$ with $A\cap B=\emptyset$ such that the power set of $A$ is equal to the power set of $A\setminus B$ . The statement is: P(A) = P(A/B) $\Leftrightarrow$ $A$ and $B$ are disjoint. I tried every possible pair of sets I could come-up with, yet I cannot find a concrete example.
I would really appreciate it if someone could point me in the right direction.
Thanks",['elementary-set-theory']
3915671,What is the Lie derivative of the Laplacian of a smooth function?,"I am fiddling around with some computations in (semi-)Riemannian geometry and have come across the following term: $$
\int_{M} \phi L_{X}(\Delta_{g}\phi)dvol_{g},
$$ where $\Delta_{g}$ is the Laplace-Beltrami operator and $L_{X}$ is the Lie derivative. Ideally, I would like this term to be $0$ or have it be a ""surface"" term, either in the way that the scalar part in front of the volume form is a covariant derivative or that the entire integrand is an exact form. Of course, if $\phi$ is harmonic, this whole thing is zero, which is good for other reasons, but I'm curious to see how this could be transfigured anyway.","['mathematical-physics', 'partial-differential-equations', 'riemannian-geometry', 'differential-geometry']"
3915712,Difference of positive semi-definite matrices,"If we have $S$ positive semi-definite matrices $A_1,\dots, A_S$ then what is the largest matrix positive semi definite matrix C such that $A_s -C$ is also psd for all $s=1,\dotsc,S$ ? By largest I mean in terms of a suitable norm.","['matrices', 'convex-cone', 'matrix-decomposition']"
3915733,"Determine all sets of non-negative integers x,y and z which satisfy the equation $2^x + 3^y = z^2$ [duplicate]","This question already has answers here : Algebra - Solving for three unknowns. (2 answers) Closed 3 years ago . Determine all sets of non-negative integers x,y and z which satisfy the equation $2^x + 3^y = z^2$ This came in the 1992 INMO and curiously enough also seems to have been included on the 1996 BMO Round 2? I have never heard of a question being directly copied from another Olympiad so this was a first for me. Anyways, first, I looked at the case $y=0$ . This quickly gave me one solution, viz $(x,y,z)=(3,0,3)$ Next, I considered $x,y,z>0$ We know $2^x + 3^y \equiv (-1)^x+0 \bmod 3$ and that perfect squares are $\equiv 0,1 \bmod 3$ . It is easy to see that the only combination that works is $x$ be even and $z=3m+1$ type $\Rightarrow z$ is odd Also, we know that odd perfect squares are $\equiv 1 \bmod 4$ . Further, $3^y\equiv (-1)^y \bmod 4$ and since $x$ is even it implies that $xâ‰¥2$ thus $2^x$ is divisible by $4$ . This further implies that $(-1)^y \equiv 1 \bmod 4 \Rightarrow y$ is also even. Let $x=2k$ . Then our original expression becomes $$3^y=(z+2^k)(z-2^k)$$ We have two possibilities: first is that $(z-2^k)=1$ and $(z+2^k)=3^y$ and second is $(z-2^k)=3^{y-a}$ and $(z+2^k)=3^a$ . But since we previously established that $z=3kÂ±1$ and as $2^k \equiv (-1)^y \bmod 3$ , we can quickly discard the second possibility. So we finally have, $$(z-2^k)=1$$ $$(z+2^k)=3^y$$ Here I got woefully stuck. Another thing I got was that $k$ is also even (which means $x$ is itself a multiple of $4$ ). One more thing is that since $y$ is even $3^y$ is divisible by $9$ . I don't know how we can use this fact right now but I thought it could be worth mentioning. Any help to proceed would be appreciated, thanks.","['contest-math', 'modular-arithmetic', 'divisibility', 'elementary-number-theory', 'discrete-mathematics']"
3915757,"Proof: If convergence of Dirichlet series in one point, then uniform convergent in a sector","I'm currently reading the proof the theorem: if a Dirichlet serie converges at some point, $s_0$ , then the serie is uniformly convergent in a sector around that point. (Montgomery and Vaughan: Multiplicative Number Theory I, Thr 1.1). But there are small things I don't understand. So, first we define $R(u)=\sum_{n>u}a_n n^{-s_0}$ to be the remainter term of a Dirichlet serie. We note that $a_n=(R(n-1)-R(n))n^{s_0}$ . Then the proof say: ""so by partial summation: \begin{align}
\sum^{N}_{n=M+1}a_nn^{-s}&=\sum^{N}_{n=M+1}(R(n-1)-R(n))n^{s_0-s}\\
&=R(M)M^{s_0s}-R(N)N^{s_0-s}-\sum^{N}_{n=M+1}R(n-1)((n-1)^{s_0-s}-n^{s_0-s})""
\end{align} Maybe someone can explain why the last equal-sign holds. The next question is how I can justify this bound: $$\int^{\infty}_{M} u^{\sigma_0 - \sigma -1} \,du \leq \frac{1}{\sigma - \sigma_0}$$ when $|R(u)|\leq\epsilon$ for all $u\geq M$ and if $\sigma>\sigma_0$ ?","['complex-analysis', 'number-theory', 'analytic-number-theory', 'dirichlet-series']"
3915816,Integrate $\int_{a}^1 \frac{\left(1-t^2\right) \tanh^{-1}t }{t^6} \ln \left(\frac{t+\sqrt{-1+t^2/a^2}}{t-\sqrt{-1+t^2/a^2}}\right) dt$,"Can this integral be found in a closed-form? $$\int_{\frac{1}{\sqrt{2}}}^1 \frac{\left(1-t^2\right) \operatorname{arctanh}t }{t^6} \ln \left(\frac{t+\sqrt{-1+2 t^2}}{t-\sqrt{-1+2 t^2}}\right) \, \mathrm{d}t$$ A natural generalisation arises: $$\int_{a}^1 \frac{\left(1-t^2\right) \operatorname{arctanh}t }{t^6} \ln \left(\frac{t+\sqrt{-1+t^2/a^2}}{t-\sqrt{-1+t^2/a^2}}\right) \, \mathrm{d}t$$","['integration', 'definite-integrals']"
3915841,What is the smallest group containing all finite cyclic groups?,"What is the smallest group $S$ (in terms of subgroups) for which every finite cyclic group is a subgroup?
I know that $\mathbb Q/\mathbb Z$ contain all finite cyclic groups as subgroups, is there a way to prove it doesnâ€™t contain a non-isomorphic subgroup who contains all of them?
Can any of you help?","['group-theory', 'abstract-algebra', 'cyclic-groups']"
3915868,"Let $F(x)=\int_0^x\left(t\int_1^tf(u)\,du\right)\,dt$. Show that $F''(x)$ is increasing on $(0, 1)$.","Question: Suppose that $f(x)$ is continuous and increasing on $[-1, 2]$ with $f(x)>0$ . Let $F(x)=\int_0^x\left(t\int_1^tf(u)\,du\right)\,dt$ . Show that $F''(x)$ is increasing on $(0, 1)$ . This is an exercise about the Fundamental Theorem of Calculus. Below is my attempt. My idea is to show that $F'''(x)\geq0$ for all $x\in(0, 1)$ . $$\begin{align}F(x)=\int_0^x\left(t\int_1^tf(u)\,du\right)\,dt&\implies F'(x)=x\int_1^xf(u)\,du\\
&\implies F''(x)=\int_1^xf(u)\,du+xf(x)\\
&\implies F'''(x)=2f(x)+xf'(x)
\end{align}$$ Here I want to say that $f'(x)\geq0$ for all $x\in(0, 1)$ since $f(x)$ is increasing on $(0, 1)$ . However, I am not sure whether $f'(x)$ exists for all $x\in(0, 1)$ . The question only states that $f(x)$ is ""continuous"", not ""differentiable"". How should I continue? Thanks in advance.","['integration', 'continuity', 'calculus', 'derivatives']"
3915875,Notion of cusp in algebraic geometry,"This relates to problem 3.14(b) of Hartshorne, wherein I am required to show that the projection of the twisted cubic curve (viewed as a subset of $\mathbb P^3$ ) from the point $(0,0,1,0)$ onto the hyperplane $\mathbb P^2$ defined by the equation $z=0$ is a cuspidal cubic curve. I have been able to show that the said projection is the zero set of the homogenous polynomial $f(x,y,z):= y^3-x^2z \in k[x,y,z]$ so it is a cubic curve. From some searching, I learnt that a cuspidal curve is one where all singularities are cusps and by using the characterization of singular points in projective curves defined by a single equation as points where all partial derivatives vanish, I have been able to show that the only singularity of $f$ occurs at the point $(0, 0, 1) \in \mathbb P^2$ . Now I am not sure how to show that this point is a cusp, because I require a rigorous definition of ""cusp"" in this context which is easy to verify. Most references I came across give a definition to the effect that a ""cusp"" is a point where two ""branches"" have a common semi-tangent, and the notion of ""branch"" is either handwaved or explained only for Euclidean spaces. The only rigorous definition I have found after searching of a cusp $P$ on a variety $Y$ involves completions of $\mathcal O_{P, Y}$ . Now I am not familiar with the idea of completion in this context and would really appreciate a definition which is rigorous and can be used in the aforementioned context. Edit: Here ( https://arxiv.org/pdf/1511.02691.pdf ) is a reference, where ""cusp"" is defined on pg. 6, but it uses the notion of a ""branch"", which has not been defined. I would really like to know a simple rigorous definition of that terminology.","['algebraic-curves', 'curves', 'algebraic-geometry', 'projective-space']"
3915879,Can the expected value of a random variable be viewed as a particular linear transformation?,"I teach a low-level probability and statistics class, and today, part of our discussion was of a couple of well-known properties that the expectation obeys. Namely, for random variables $X$ and $Y$ and a constant $a$ , $E(aX) = aE(X)$ and $E(X + Y) = E(X) + E(Y)$ . A student who is also enrolled in a Linear Algebra course then recognized these properties as the same properties one asks for to get a linear transformation. Thus, I'd like to know if one can view the expected value as a linear transformation from a vector space of random variables to $\mathbb{R}$ . Is this an already-studied notion that's out there ? Perhaps one can link me to a source that might contain a discussion on this, as well. Thank you !","['expected-value', 'statistics', 'probability-theory', 'linear-transformations']"
3915890,Does a bounded well-ordered set have a maximum?,"Suppose $(A,\preccurlyeq)$ is a well-ordered chain , i.e., every subset $B\subseteq A$ has a least element under the order $\preccurlyeq$ . We say that a set $B\subseteq A$ is bounded if there exists $s\in A$ such that $b\preccurlyeq s$ for all $b\in B$ . Question: Does every bounded subset of $A$ have a maximum? If $B$ is finite this is obviously true, since we can start with the minimum $m=\min B$ , and keep applying the successor operation $$x^+=\min\textstyle_{\preccurlyeq}(B\smallsetminus\{b\in B: b\preccurlyeq x\})$$ and stop when we end up with a singleton $\{M\}$ , this will be the maximum of $B$ . But what if $B$ is infinite? I can't think of an easy counterexample to this, it feels like it should be true.","['elementary-set-theory', 'order-theory', 'well-orders']"
3915900,How to find sum of $\frac{1}{2}+\frac{3}{8}+\frac{15}{48}+\frac{105}{384}+\cdots$?,"Sum $S_n$ of this series is given by, $S_n=\frac{1}{2}+\frac{3}{8}+\frac{15}{48}+\frac{105}{384}+...$ Express $r^{th}$ term ( $U_r$ ) in this series and hence show that, $$\frac{U_r}{U_{r-1}}=\frac{2r-1}{2r}$$ Considering the above relation find $f_{(r)}$ such that $U_{r-1}=f_{(r)}-f_{(r-1)}$ . Here $f_{(r)}$ shall be expressed interms of $U_r.$ Hence deduce $\sum_{r=1}^nU_r=(2n+1)U_n-1$ My Try: I was able to find $U_r=\frac{(2r-1)!!}{(2r)!!}$ Simplifying further I got the next relation, $U_r=\frac{(2r-1)(2r-3)!!}{2r(2r-2)!!}=\frac{(2r-1)}{(2r)}U_{r-1}$ But how do I proceed to find the summation. Please help me. Thanks in advance!","['algebra-precalculus', 'telescopic-series', 'recurrence-relations', 'sequences-and-series']"
3915901,What do characteristic classes of spinor bundle depend on?,"Let $M^n$ be a smooth manifold. Equip $M$ with a Riemannian metric and let $S$ be a spinor bundle. We can consider characteristic  classes of $S$ (or $S_+,S_-$ for when $n$ is even), for example the Euler characteristic. My question is: Will these classes depend on the metric $g$ or spin structure chosen and if not, are they expressable in terms of other topological invariants of $M$ ?","['spin-geometry', 'characteristic-classes', 'differential-geometry']"
3915902,"Number of divisors of $2^2\cdot 3^3\cdot 5^3\cdot 7^5$ of the form $4n+1,n\in N$?","In this question , the OP asks to find the number of divisors of $2^2\cdot 3^3\cdot 5^3\cdot 7^5$ which are of the form $4n+1,n\in N$ . The top answer points out that the required divisor is of the form $$3^a\cdot 5^b\cdot 7^c$$ with $0\leq a\leq 3,0\leq b\leq 3,0\leq c\leq 5$ and $a+c$ being even. The answer therefore is, apparently, $(4 \cdot 4 \cdot 6)/2=48$ . But this is wrong according to my book: the correct answer is $47$ . Obviously, one case has been overcounted, but which? As far as I know, the person who wrote the top answer employed a fairly standard approach and should have arrived at the correct answer.","['permutations', 'elementary-number-theory', 'combinations', 'combinatorics']"
3915962,Proving a set contains the product algebra,"The stuff in this question came from a measure theory course notes pdf (link below). The proof of the theorem I am interested is also included in this pdf but it is quite short and skips over details. I filled in the details and present my proof and it would be great if some experience proof writers can give it a look. https://www.math.ucdavis.edu/~hunter/measure_theory/measure_notes_ch5.pdf Defn 1: Measurable Rectangles Suppose that $(X,\mathcal{A})$ and $(Y,\mathcal{B})$ are measurable spaces, then a measurable rectangle is a subset $A\times B$ of $X\times Y$ where $A\in \mathcal{A}$ and $B\in \mathcal{B}$ are measurable subsets of $X$ and $Y$ respectively. Defn 2: Product $\sigma$ -algebra Suppose that $(X,\mathcal{A})$ and $(Y,\mathcal{B})$ are measurable spaces. The product $\sigma$ -algebra $\mathcal{A}\otimes \mathcal{B}$ is the $\sigma$ -algebra on $X\times Y$ generated by the collection of all measurable rectangles, $$
A\otimes \mathcal{B}=\sigma(\{A\times B:A\in \mathcal{A},B\in \mathcal{B}\}).
$$ The product of $(X,\mathcal{A})$ and $(Y,\mathcal{B})$ is the measurable space $(X\times Y,\mathcal{A}\otimes \mathcal{B})$ Defn 3: Sections Suppose that $E\subset X\times Y$ . For any $x\in X$ and $y\in Y$ , we define the $x$ -section $E_x\subset Y$ and then $y$ -section $E^y\subset X$ of $E$ by $$
E_x=\{y\in Y: (x,y)\in E\},\ \ \ E_y=\{x\in X: (x,y)\in E\}
$$ Thm : Generator of Product $\sigma$ -algebra If $(X, \mathcal{A})$ and $(Y,\mathcal{B})$ are measurable spaces and $E\in \mathcal{A}\otimes \mathcal{B}$ , then $E_x\in \mathcal{B}$ is for every $x\in X$ and $E_y\in \mathcal{A}$ for every $y\in Y$ . In mathematical symbols: $$
{A}\otimes \mathcal{B}\subset \mathcal{M}= \{E\subset X\times Y: E_x\in \mathcal{B},\ \forall x\in X\text{ and }E_y\in \mathcal{A},\ \forall y \in Y\}
$$ Proof Fix $E=A\times B\subset X\times Y$ . Let $E\in \{A\times B:A\in \mathcal{A},B\in \mathcal{B}\}$ . If $(x,y)\in E$ , then $E_x=B$ and $E_y=A$ . This proves that $\mathcal{M}$ contains the generator of $\mathcal{A}\otimes \mathcal{B}$ (the collection of measurable rectangles). Next, we prove that $\mathcal{M}$ is a $\sigma$ -algebra, this completes the proof that $$
A\otimes B\subset \mathcal{M}
$$ Let $A\times B\in \mathcal{M}$ . Closure under complements. Recall $$
(A\times B)^c=(A^c\times B)\cup (A\times B^c)\cup (A^c\times B^c)
$$ It is clear that either $(E^c)_x=E_x$ or $(E^c)_x=E_x^c$ . Since $\mathcal{B}$ is a $\sigma$ -algebra, $E_x\in \mathcal{B}\implies E_x^c\in \mathcal{B}$ . The arugument is similar for $E_y$ . Closure under countable union. We have $$
\Big[\bigcup_i^n (A_i\times B_i)\Big]_x=\bigcup_i^n E_{x,i}\in \mathcal{B}
$$ because $\mathcal{B}$ is $\sigma$ -algebra. The arugument is similar for $E_y$ . $\blacksquare$","['measure-theory', 'lebesgue-measure', 'real-analysis', 'solution-verification', 'elementary-set-theory']"
3915993,What is the correct notation to indicate that a function is taking a particular value for one of its parameters?,"Consider a function which has both variables and parameters, such as $$
y(x) = 3x^2 + ax + b,
$$ where $a$ and $b$ are the paramters (constants) for any one realisation, but $x$ is a variable. What is the correct notation to use to indicate the function with $a$ , for example, taking a certain value? Should it be something like the ""evaluated at"" symbol, like this: $$
y(x)\rvert_{a=2} = 3x^2+2x+b
$$ or would it be written as an argument like this: $$
y(x,a=2) = 3x^2+2x+b.
$$ Or is there another accepted way that I am not aware of? Thank you.","['notation', 'functions']"
3916034,Finding $\frac{\sum_{r=1}^8 \tan^2(r\pi/17)}{\prod_{r=1}^8 \tan^2(r\pi/17)}$,"I have tried to wrap my head around this for some time now, and quite frankly I am stuck. Given is that : $$a=\sum_{r=1}^8 \tan^2\left(\frac{r\pi}{17}\right) \qquad\qquad b=\prod_{r=1}^8 \tan^2\left(\frac{r\pi}{17}\right)$$ Then what is the value of $a/b$ ? I tried evaluating the quantities on DESMOS to realise that: a=136 and b=17 which gives 8 as the answer. Any helpful insight about how to reach at these values !?","['summation', 'trigonometry', 'products', 'algebra-precalculus', 'sequences-and-series']"
3916035,Compute the $n$-fold iteration of an indefinite integral operator using integration by parts and induction.,"Consider the following integral operator $T:L^2([0,2])\longrightarrow L^{2}([0,2])$ defined by $$(Tf)(x)=\int_0^x f(y)\,dy.$$ Page 230 of Peter Lax's functional analysis claimed that the $n$ -fold iterate of $T$ is given by the formula: $$(T^n f)(x)=\dfrac{1}{(n-1)!}\int_0^x (x-r)^{n-1}f(r) \, dr, \text{ for } x\in [0,1].$$ And he said that this can be proved using induction and integration by parts. So I followed his instruction:  Suppose this holds for a fixed $n$ , and we prove it is true for $n+1$ . By definition, for $x\in [0,1]$ , \begin{align*}
& (T^{n+1}f)(x)=T((T^{n}f)(x))=\int_0^x (T^{n}f)(y) \, dy \\[8pt]
= {} &\int_0^x \Big(\frac{1}{(n-1)!}\int_0^y(y-r)^{n-1}f(r) \, dr\Big) \, dy\\[8pt]
= {} & \frac{1}{(n-1)!}\int_0^x \int_0^y (y-r)^{n-1}f(r) \,dr\,dy.
\end{align*} For fixed $y\in [0,1]$ , we deal with the inner integral $\int_0^y (y-r)^{n-1} f(r) \, dr$ .  Consider $u:=f(r)$ so that $du=f'(r) \, dr$ , and $dv:=(y-r)^{n-1} \, dr$ so that $v=-\frac{1}{n}(y-r)^{n}.$ Then, using integration by parts, we have $$\int_{0}^{y}(y-r)^{n-1}f(r) \, dr=-\frac{1}{n}(y-r)^n f(r)+\int_0^1\frac{1}{n}(y-r)^n f'(r) \, dr.$$ Then, I focused on $\frac{1}{n}\int_0^1 (y-r)^{n}f'(r) \, dr$ . Consider $dv:=f'(r)\,dr$ so that $f(r)=v$ , and $u:=(y-r)^{n}$ so that $du=-n(y-r)^{n-1} \, dr.$ Using integration by parts, we have $$\dfrac{1}{n} \int_0^1 (y-r)^{n}f'(r) \, dr = \frac{1}{n}(y-r)^n f(r)+\frac{1}{n}\cdot n\int_0^1 (y-r)^{n-1} \, dr.$$ So if we plug this back into above, it seems I just proved $0=0$ . What should I do? Did I even have a wrong start? Thank you!","['integration', 'operator-theory', 'functional-analysis', 'real-analysis']"
3916084,Showing $\frac{f(a+2b)+f(a-2b)}{2f(a)}\leq\sqrt{1-\left(\frac{b}{a(1-a)}\right)^2}$ for $f(x)=\sqrt{x(1-x)}$ with some constraints,"My question is from a inequality that is not proved (it is just implicitly mentioned I guess) in a book. Specifically, let $a \in (0,1)$ and $b \in (0,1)$ with $a - 2b \geq 0$ and $a + 2b \leq 1$ . Then with $f(x) := \sqrt{x(1-x)}$ we are asked to show that $$\frac{f(a+2b)+f(a-2b)}{2f(a)} \leq \sqrt{1-\left(\frac{b}{a(1-a)}\right)^2}$$ I am really stuck at this, the only related inequality that comes to mind is that $$\frac{\sqrt{1+2\alpha}+\sqrt{1-2\alpha}}{2} \leq \sqrt{1-\alpha^2},\quad \forall \alpha \in [0,\tfrac{1}{2}]$$ But I still cannot prove the desired inequality. Any help is greatly appreciated!","['calculus', 'inequality', 'real-analysis']"
3916182,Can the map sending a presentation to its group be considered as a functor?,"It is well-known that the functor $Grp \to Set$ sending a group $G$ to its underlying set $UG$ has a left adjoint, the functor $Set\to Grp$ sending a set $X$ to the free group $FX$ . I wonder whether one can consider the following modification of the functor $F$ : to each presentation $\langle S\mid R\rangle$ we assign the group $FS/N$ , where $N$ is the normal subgroup induced by $R$ . Is this a functor? For this to be true, there need to be a category of presentations. Is there such a category? Does the functor $\langle S\mid R\rangle\mapsto FS/N$ have a right adjoint (maybe similar to $U$ )? Of course, my questions are not precise, because I haven't specified what the morphisms between presentations are. The question is if one can do all this in a sensible way.","['group-presentation', 'functors', 'category-theory', 'combinatorial-group-theory', 'group-theory']"
3916219,Let $G$ be a finite group and $A:=\{a\in G\mid a\neq a^{-1}\}$. Prove that $|A|$ is even.,"Let $G$ be a finite group and $A:=\{a \in G\mid a \neq a^{-1} \}$ a set that contains all the elements of $G$ that are not equal to their respective inverses. Prove that $A$ contains an even number of elements. I have seen some posts here here about this proof, but none of which were similar to my attempt. Here's my attempt: Since $G$ is finite, then $A$ is also finite. In addition, every element of $A$ has an inverse because $G$ is a group. Now, divide $A$ in two sets called $X$ and $Y$ , such that $X\subseteq A$ and $Y\subseteq A$ , so that every element of $X$ has its inverse in $Y$ . Let $k_{1},k_{2} \in \mathbb{N}$ , such that $\left | X \right | = k_{1}$ and $\left | Y \right | = k_{2}$ . Since there is no element equal to its inverse in $A$ , then $ \left | A \right | = \left | X \right | + \left | Y \right |$ . Moreover, $\left | X \right | = \left | Y \right |$ because $A$ only contains elements which are different from their respective inverses. So, \begin{aligned}
\left | A \right | &= \left | X \right | + \left | Y \right | \\
&= k_{1} + k_{2} && \text{[$\left | X \right | = k_{1}$ and $\left | Y \right | = k_{2}$]} \\
&= k_{1} + k_{1} && \text{[$\left | X \right | = \left | Y \right |$]} \\
&= 2\cdot k_{1}
\end{aligned} $2k_{1}$ is an even number, by the definition of even number. Therefore, the set $A$ contains an even number of elements. Does my proof look fine? Every help is appreciated!","['finite-groups', 'abstract-algebra', 'solution-verification', 'discrete-mathematics', 'group-theory']"
3916225,Why is the correct value set of functions so arbitrary?,"When my professor describes a function, for example $f(x) = \sin(x)$ , he is allowed to describe it as a function $f: A \rightarrow B$ with $A = B = \mathbb{R}$ , even tough sin(x) only has values in $[-1, 1]$ However, when we are getting asked which is the value set of $f(x) = e^x$ , the correct answer is not $\mathbb{R}$ , but $\mathbb{R}_+$ , because only positive values occur. What do I miss here? I don't understand why sometimes you can be unprecise with your sets, and sometimes not.","['algebra-precalculus', 'functions']"
3916249,$n$-th derivative change of variable,"I have a change of variables from $\alpha$ to $\beta$ such such that $$\frac{d}{d\beta} = \frac{1}{f(\alpha)}\frac{d}{d\alpha}$$ therfore, the second derivative will read $$\frac{d^2}{d\beta^2} =\frac{1}{f(\alpha)}\frac{d}{d\alpha}\times \frac{1}{f(\alpha)}\frac{d}{d\alpha}= \frac{1}{f^2(\alpha)}\frac{d^2}{d\alpha^2}-\frac{f'(\alpha)}{f^3(\alpha)}\frac{d}{d\alpha}$$ and the third order reads $$\frac{d^3}{d\beta^3} =-\frac{f''(\alpha)}{f^4(\alpha)}\frac{d}{d\alpha}+\frac{3 f'^2(\alpha)}{f^5(\alpha)}\frac{d}{d\alpha}-\frac{3 f'(\alpha)}{f^4(\alpha)}\frac{d^2}{d\alpha^2}+\frac{1}{f^3(\alpha)} \frac{d^3}{d\alpha^3}$$ I need to find the $n$ -th derivative in $\beta$ : $$\frac{d^n}{d\beta^n} =\, ?$$ is there a general formula for this case?","['derivatives', 'combinatorics', 'real-analysis']"
3916349,"If $(X, \|\cdot\|)$ is a normed vector space, then $(X\setminus\{0\}, d)$ is a metric space for $d(x, y) = \frac{\|x-y\|}{\|x\|+\|y\|}$","Consider the following statement: If $(X, \|\cdot\|)$ is a normed vector space, then $(X\setminus\{0\}, d)$ is a metric space for $$d(x, y) = \frac{\|x-y\|}{\|x\|+\|y\|}$$ I'm trying to figure out whether this statement is true (and if it is, whether it's only true in a special setting, e.g. uniformly convex Banach spaces). The context is that I'm trying to define a ""similarity metric"" between two vectors in a general normed vector space with the invariance $d(x, y) = d(\alpha x, \alpha y)$ for $\alpha\neq 0$ , among some other properties. It seems like it could maybe be a textbook problem, but I'm not quite sure if I've seen it somewhere or not. It's pretty clear that $d(x, y) = 0$ implies $x = y$ and $d(x, y) = d(y, x)$ , but the triangle inequality is a bit sticky. We can rearrange $d(x, y)\leq d(x, z)+d(z, y)$ as $$\|x-y\|\leq \left(\frac{\|x-z\|}{\|x\|+\|z\|}+\frac{\|y-z\|}{\|y\|+\|z\|}\right)(\|x\|+\|y\|)$$ which feels stronger than the standard triangle inequality on $(X, \|\cdot\|)$ . Does anybody have some insights on this? Am I missing a standard trick here? Thanks!","['inequality', 'normed-spaces', 'functional-analysis', 'metric-spaces']"
3916366,Cardinality exercise.,Prove that there is an injective function $ \phi: \mathcal P (A) \to \mathcal{P} (\mathcal {P} (A)) $ . What I did was define an injective function $  \psi: A \to \mathcal P (A) $ given by $ \psi (x) = \{x \} $ . Then define the function $ \phi: \mathcal P (A) \to \mathcal{P}(\mathcal{P}(A)) $ given by $$ \phi (A) = \{\psi (a) \mid a \in A \} $$ The $ \phi $ function will be injective. Is that correct?,"['elementary-set-theory', 'functions']"
3916369,Properties of a function without partial derivatives,"Let $f(x,y)$ be a function such that $f(sx, sy) = s f(x,y)$ for some positive real $s$ . Let $f_x(y)$ and $g_y(x) = f(x,y)$ be single variable analogues of $f$ , and suppose $f_x(y)$ and $g_y(x)$ are continuously differentiable. I'd like to show that $f(x,y) =  y f '_y(x) + x g'_y(x)$ for all positive $x,y$ . Using partial derivatives this isn't too hard. I'm wondering whether there is a solution that does not use any multivariable calculus, as it doesn't seem necessary for this problem.","['multivariable-calculus', 'calculus', 'derivatives']"
3916380,"If $f(x+1/n)$ converges to a continuous function $f(x)$ uniformly on $\mathbb{R}$, is $f(x)$ necessarily uniformly continuous?","Suppose $f:\mathbb{R}\mapsto\mathbb{R}$ is a continuous function. Define $f_n(x)=f(x+1/n)$ for all $n\in\mathbb{N}^+$ . If $f_n(x)\to f(x)$ uniformly on $\mathbb{R}$ , can we conclude that $f$ is actually uniformly continuous? If not, can you give a counterexample of $f$ to be not uniformly continuous but satisfies all above conditions? I know that if $f_n(x)$ 's are all uniformly continuous and $f_n(x)\to f(x)$ uniformly, then $f(x)$ must be uniformly continuous. However, here we do not assume $f(x)$ to be uniformly continuous, and $f_n(x)$ has specific structure related to $f(x)$ , so at least you cannot directly conclude they are uniformly continuous. I guess the statement above is wrong but it's hard for me to find a counter-example. Can anyone help me?","['uniform-continuity', 'uniform-convergence', 'real-analysis']"
3916428,Prove isomorphism of rings using Yoneda lemma,"I have seen many questions which prove the isomorphism of rings using the Yoneda lemma, for example, this question , this question and this question . The basic idea is that we can prove the two functors (from Ring category to Set category) $\hom(X,*)$ and $\hom(Y,*)$ are isomorphism, then by Yoneda lemma we know $X$ and $Y$ are isomorphic. For example, the first question proves that $(A/I)\otimes (B/J)\cong (A\otimes B)/(I\otimes 1+1\otimes J)$ . Question: By using category theory, can we see this isomorphism is natural? What I mean by natural isomorphism is that the isomorphism between $(A/I)\otimes (B/J)$ and $(A\otimes B)/(I\otimes 1+1\otimes J)$ is exactly given by the obvious map $\bar{a}\otimes\bar{b}\rightarrow\overline{a\otimes b}$ . I think that using category theory, one can indeed prove that $(A/I)\otimes (B/J)\cong (A\otimes B)/(I\otimes 1+1\otimes J)$ , but one can't actually know what the explicit isomorphism is. I think in commutative algebra and algebraic geometry, the naturalness or canonicalness of an isomorphism is very important, right?","['algebraic-geometry', 'category-theory', 'commutative-algebra']"
3916435,Prove $2 < (1 + \frac{1}{n})^n$ for all $n \ge 2$,"Prove $2 < (1 + \frac{1}{n})^n$ for all $n \ge 2$ .  I believe this will come out by induction.  It looks so much like induction, but I can't seem to find enough algebra to solve it.  The base case: for $n=2$ , we get $(1 + \frac{1}{2})^2 = 2 + \frac{1}{4} > 2$ . Suppose now there is a $k \ge 2$ such that $(1 + \frac{1}{k})^k > 2$ .  I must show $(1 + \frac{1}{k+1})^{k+1} > 2$ .  From this, I tried to undo the exponent as in \begin{align*}
\left(1 + \frac{1}{k+1}\right)^{k+1} &= \left(1 + \frac{1}{k+1}\right)^k \left(1 + \frac{1}{k+1}\right)
\end{align*} Now I'm looking for a way to use $(1 + \frac{1}{k})^k > 2$ , which is true by hypothesis.  But it doesn't seem obvious how to turn a fraction $\frac{1}{k+1}$ into $\frac{1}{k}$ . By the way , I know $(1 + \frac{1}{n})^n$ approaches $e$ as $n$ approaches infinity, but I'm trying not to use any related identities to solve this problem.  Can we do it by induction?  What is the algebra that I'm missing there?  Any hints?  Thank you! Thanks .  Lots of good answers down there.  I selected what seemed to be the most straightforward one.  Though it looked to me like induction, it seems easier to apply the binomial theorem as @jjagmath kindly pointed out. Solution . Considering just the first two terms of the binomial theorem expansion, we get \begin{align*}
   (1 + 1/n)^n &= 1 + n (1/n) + ... + C(n,n) 1/n^n\\
               &= 2 + ... + C(n,n) 1/n^n\\
               &> 2.
\end{align*} We must restrict $n \ge 2$ because $n=1$ fails with $3/2 > 2$ .","['induction', 'discrete-mathematics']"
3916444,A problem about a application of the MLE in $Y_{i}\sim \mathbf{Exp}(\beta)$,"Suppose that $X_{1}, X_{2}, \ldots, X_{n}$ denote a random sample from an exponentially distributed population with mean $\beta$ . Find the MLE of the population variance $\beta^{2}$ . My approach: I know that Method of Maximum Likelihood: Suppose that the likelihood depends on $k$ parameters $\theta_{1},\theta_{2},\ldots,\theta_{k}$ . Choose those values of the parameters that maximize the likelihood $\mathbb{L}[y_{1},y_{2},\ldots,y_{n}|\theta_{1},\theta_{2}\ldots,\theta_{k}]$ . So, in my problem a need to find the value of the parameter $\beta^{2}$ sucht that maximize the $$\mathbb{L}[x_{1},x_{2},\ldots,x_{n}|\beta^{2}]:=\mathbb{L}[\beta^{2}]$$ But I know that if $t(\theta)$ is a one-to-one function of $\theta$ and if $\hat{\theta}$ is the MLE for $\theta$ , so the MLE of $t(\theta)$ is given by $$\hat{t(\theta)}=t(\hat{\theta})$$ This result, sometimes refered to as the invariance property of MLEs . Now, using that result, I think I can calculate first $$\mathbb{L}(y_{1},y_{2},\ldots,y_{n}|\beta)=f(y_{1}|\beta)\times f(y_{2}|\beta)\times \cdots f(y_{n}|\beta)$$ where $f(y_{i}|\beta)$ is the density functio of the $Y_{i}\sim \mathbf{Exp}(\beta)$ . So, we have \begin{eqnarray*}
\mathbb{L}(\beta)&=&\left(\frac{1}{\beta}\right)^{n}\mathbf{exp}\left[\frac{-y_{1}-y_{2}-\cdots -y_{n}}{\beta}\right]
\end{eqnarray*} Question: How can I write the support of $\mathbb{L}[\beta]$ ? Also, I know  to do $\frac{d\mathbb{L}[\beta]}{d \beta}=0$ , and so we have $$\frac{d}{d\beta}\left(\left(\frac{1}{\beta}\right)^{n}\mathbf{exp}\left[\frac{-y_{1}-y_{2}-\cdots -y_{n}}{\beta}\right] \right)=0$$ since that $\ln(\mathbb{L}[\beta]$ and $\mathbb{L}[\beta]$ reach the maximum in the same $\beta$ , by monotony, then we can calculate $\beta$ in $$\frac{\ln(\mathbb{L}[\beta])}{d\beta}=0 \implies \frac{1}{\beta^{2}}\sum_{1\leq i \leq n}y_{i}=\frac{n}{\beta} \implies \beta=\frac{1}{n}\sum_{1\leq i \leq n}y_{i}=\overline{Y}_n$$ So, we have that $$\hat{\beta}_{MLE}=\overline{Y}_n$$ Now, by invariance property we can see that $$\hat{\beta}^{2}_{MLE}=\overline{Y}_n^{2}$$ Is correct my solution?
Any suggestion?","['statistics', 'probability-distributions', 'solution-verification', 'maximum-likelihood']"
3916451,A bijection between between the orbits $G$ on $G \backslash B \times G \backslash B$ and orbits of $B$ on $G \backslash B$?,"Let $G$ be a group and $B$ a subgroup. Can somebody show me how that orbits of $G$ on $G \backslash B \times G \backslash B$ are in bijection with the orbit of $B$ on $G \backslash B$ ? Here is what I've come up with so far: Let $(aB,cB) \in G \backslash B \times G \backslash B$ . Then $G.(aB,cB) = \{(gaB,gcB) : g \in G\}$ By setting $ga = h$ we can see that this is in bijection with: $=\{(hB,ha^{-1}cB) : h \in G\}$ Now, if we have $(hB,ha^{-1}cB) = (h'B,h'a^{-1}cB)$ then $(h'^{-1}hB,h'^{-1}ha^{-1}cB)=(B,a^{-1}cB)$ and in particular $h'^{1}h \in B$ . I felt like this might be going in the write direction to showing the desired bijection. Help appreciated!","['elementary-set-theory', 'group-actions', 'group-theory', 'abstract-algebra']"
3916490,"How to solve $\int \sqrt{1+\sin x}\, dx$?","It's easy to get this: $$\int \sqrt{1+\sin x}\, dx \\= \int \sqrt{ \sin^2{\frac{x}{2}} + \cos^2{\frac{x}{2}} + 2\sin{\frac{x}{2}}\cos{\frac{x}{2}}}\,\, dx  \\ = \int \left | \sin{\frac{x}{2}} + \cos{\frac{x}{2}} \right |\, dx \\= \sqrt{2} \int \left | \sin{\left ( \frac{x}{2} + \frac{\pi}{4} \right )} \right |\, dx$$ So, in fact, my question is how to solve the integrate $\int \left | \sin x \right| dx $ .
Or how to deal with the integrate when have absolute in it?","['integration', 'indefinite-integrals', 'calculus', 'trigonometry']"
3916499,Numerical Analysis or Numerical Linear Algebra Book with Available Solutions?,"I am a beginning graduate student in Mathematics soon and I am planning to self-study Numerical Analysis and Numerical Linear Algebra. I know there are already reference-request questions about this, but I am looking for some more specific books. I am looking for books in the following categories: Books with difficult problems, and solutions in the back (ideal) Books with difficult problems Books with solutions in the back Books with separate solution manuals Problem books (ideally with solutions in the back, or solution manuals) Could you please recommend me some textbooks, and tell me in which category they are? Thank you very much, any recommendations are immensely appreciated!","['reference-request', 'linear-algebra', 'numerical-linear-algebra', 'optimization', 'numerical-methods']"
3916502,Prove $\sum_1^n 1/i^2 \le 2 - 1/n$ for all natural $n$.,"I'm trying to do this by induction.  It works for $n=1$ because we get $1 \le 2 - 1 = 1$ .  Now suppose for some natural $k \ge 1$ , we have $\sum_{i=1}^k  \le 2 - 1/k$ .  I must show $\sum_{i=1}^{k+1} \le 2 - 1/(k+1)$ .  I started out from the hypothesis and added $1/(k+1)^2$ to both sides of the inequality.  I get \begin{align*}
  1 + \frac{1}{4} + \frac{1}{9} + ... + \frac{1}{k^2} + \frac{1}{(k+1)^2} \le 2 - \frac{1}{k} + \frac{1}{(k+1)^2}
\end{align*} and it's not obvious what to do from there.  Any hints?","['induction', 'discrete-mathematics']"
3916663,Jacobian of non-square matrices,"Let $m>n$ and $L\colon \mathbb{R}^m \to \mathbb{R}^n$ be a linear map(=matrix). The "" $n$ -dimensional Jacobian"" $$
J^n(L) = \sqrt{\det(LL^t)} 
$$ is of geometric significance! Let's say it makes the co-area formula possible. Suppose $C\colon \mathbb{R}^m \to \mathbb{R}^m$ is an invertible linear map (think of it as a change of coordinates). I am interested in the precise formula relating $J^n(L)$ and $J^n(L \circ C)$ . For simplicity assume $L$ is surjective, i.e. it has rank $n$ . Denote by $C^{ker}$ the restriction of $C$ to the $(m-n)$ -dimensional $(\ker L\circ C)$ . So, $C^{ker}\colon (\ker L\circ C) \to \ker L$ can be seen as a map $\mathbb{R}^{m-n} \to \mathbb{R}^{m-n}$ . I think the answer should be: $$
J^n(L) = \frac{|\det C^{ker}|}{|\det C|}\, \cdot J^n(L \circ C)\, ,
$$ Because for certain $C$ I do have a proof, albeit quite a tricky one. Questions: Is the claimed identity true? If not, what is the right formula? How does one prove it?","['determinant', 'geometry', 'matrices', 'multivariable-calculus', 'linear-algebra']"
3916727,What are the lengths of the major and minor axes of an ellipse inscribed in a rhombus of an isometric grid?,"Like this: where inner the angles of this rhombus are 60Â° and 120Â°, and the sides have length 1. We can see that the sides are tangent to the inscribed ellipse at their midpoints. I believe that the two intersections of the perpendiculars of the sides shown here are the foci of the ellipseâ€¦ but I can find no confirmation of that anywhere. If we can assume that is the case, then I worked out that the ellipseâ€™s minor axis has length $\sqrt{\frac{1 + \sqrt 5}{6}}$ and the major axis is $\frac{1 + \sqrt 5 }{2 \sqrt 3} $ . EDIT: Nope! Bad assumption.  See below. So a related question would be, are these really the foci of this ellipse? If not, then how to construct them properly? Iâ€™ve looked everywhere for these answers, to no avail. I have found many videos and websites explaining how to approximate this ellipse using a compass, a technique which makes use of the pair of points that Iâ€™m assuming are foci. It seems like the only people interesting in this are draftsmen and artists, not mathematicians. Quite frustrating and disappointing! A bit more discussion here: https://www.quora.com/What-are-the-lengths-of-the-major-and-minor-axes-of-an-ellipse-inscribed-in-a-rhombus-of-an-isometric-grid-i-e-with-opposite-angles-of-60-and-120","['isometry', 'conic-sections', 'geometry']"
3916742,Expected time until random walk on hexagonal grid exceeds distance N from start,"A particle starts in a cell in an infinite hexagonal grid, and every second, jumps to an adjacent cell uniformly randomly. What is the expected amount of time until the particle is $N$ cell-jumps away from its starting point? With some linear algebra, for example, one finds values of $1$ , then $10/3$ , then $213/29$ , for cases $N=1,2,3$ respectively. Computer simulation shows growth is approximately $4N^2/5$ . I expected to be able to solve this problem with similar methods (using polynomials in barycentric coordinates, constrained by dihedral symmetries) as to my recent Puzzling question , but to no avail so far. Curiously, by a coupling argument, this problem is equivalent to computing the expected value of the variable $\text{min}\{X_1,X_2\}$ where $X_i$ are iid variables representing the escape time of the honeybee from the center of its triangle in the linked problem, but that observation doesn't seem to help much. Some rambling about my current attempts: In barycentric coordinates $(\alpha, \beta, \gamma)$ whereby we always have $\alpha + \beta + \gamma = 3N$ , it would seem reasonable to demand thatâ€”in order to find the average escape time at $(\alpha, \beta, \gamma)$ from the $N-1$ -hexagon centered at $(N,N,N)$ â€”we find a function $H(\alpha, \beta, \gamma)$ algebraically satisfying the ""average-of-6-neighbors-plus-1"" property everywhere, which also satisfies $H = 0$ whenever $\alpha = 0, 2N$ or $\beta = 0, 2N$ or $\gamma = 0, 2N$ . After all, this approach is exactly how the triangular escape time problem is solved, just leaving out the $2N$ constraints. In that case, we think of the elementary symmetric polynomials in $\alpha, \beta, \gamma$ , and realize $\alpha\beta\gamma$ is a good candidate. It doesn't quite satisfy the averaging-plus-one lawâ€”its difference from its nearby-average function is $3N$ and not $1$ â€”so we tweak it to $\frac{3\alpha\beta\gamma}{\alpha+\beta+\gamma}$ to solve the problem. So that is how I proceeded here, examining the obvious candidate $H=\alpha \beta \gamma (\alpha-2\beta-2\gamma)(\beta-2\alpha-2\gamma)(\gamma-2\alpha-2\beta)$ . But its difference from its nearby-average function is gnarly, and not susceptible to obvious tweaks. With some thought, one realizes the field of rational functions invariant up to angular and mirror symmetry are generated by $H$ as well as $e_1 = \alpha+\beta+\gamma$ and $e_2 = \alpha \beta + \alpha \gamma + \beta\gamma$ . Especially considering the empirical evidence that our formula will be of degree $2$ , one might try candidate tweaks like $\frac{H}{e_1^4}$ or $\frac{H}{e_1^2 e_2}$ or $\frac{H}{e_2^2}$ or $\frac{H^2}{e_1^4 e_2^3}$ ... but some time spent in Mathematica proved fruitless. It's become clear to me now that no rational function of the form $\frac{F}{e_1^n e_2^m}$ will satisfy the criteria of the first paragraph , because such a function will still be defined on and inside the full triangular region, thus restricting to a solution of the honeybee escape time problem. By standard Markov chain reasoning, this solution is unique, and obviously not the solution to the problem at hand. So, either an even more complicated denominator is needed (one giving poles outside the hexagon but inside the triangle), or we need to allow possibilities like $H \neq 0$ even if $\alpha = 0$ as long as we're outside the hexagonal boundary, or we need some even more radical change to our techniques.","['random-walk', 'statistics', 'markov-chains', 'probability']"
3916787,How many LinkedIn connections would I need to be 2nd degree with everyone,"A mental experiment, If I would want to be a 2nd degree connection (only 1 person in between me and another one) with everyone on LinkedIn, how many connections would I need to have? I found these number: 722 million users in total ( https://news.linkedin.com/about-us#Statistics ) Every user has 400 connections on average ( https://techjury.net/blog/linkedin-statistics/ ) My reasoning, if all these people would have a unique network (all 400 connections are different), it would be like this: 722 000 000 / 400 = 1.8 million connections Now, I guess majority of users will have a good amount of overlap, so in reality the number would be higher.",['statistics']
3916834,Conditions for function to be discontinuous at 0,"I'm supposed to find out the set of values of $m$ for which f is discontinuous at 0, for $f(x)=x^m\sin\frac{1}{x}$ . The solutions obviously mention the interval $(-\infty, 0]$ . However; In the left-side limit, where the $x$ is negative, i.e. $$
\lim_{x \to 0^-}x^m\sin\frac{1}{x},
$$ if $m$ is of the form $\frac{1}{2^n}$ where $n$ is any natural number, wouldn't the resultant number become complex? Wouldn't the function only be defined in 0 and $\mathbf R^+$ ? The left-hand limit for $0$ wouldn't exist. Wouldn't this be considered a discontinuity? If so, why isn't this set included with set $(-\infty, 0]$ ?","['limits', 'continuity']"
