question_id,title,body,tags
142197,Simplifying Logarithmic Expression: $\frac{1-\log_a^{3}{b} }{(\log_a b+\log_b a+1)\log_a\frac{a}{b}}$,Compute: $$\frac{1-\log_a^{3}{b} }{(\log_a b+\log_b a+1)\log_a\frac{a}{b}}$$ I tried to expand it : $$\frac{1-\log_a^{3}{b} }{(\log_a b+\log_b a+1)\log_a\frac{a}{b}}$$ $$=\frac{(1-\log_a{b})(\log_a^{2}b+\log_a b+1)}{(\log_a b+\log_b a+1)(1-\log_a{b})}$$ $$=\frac{(\log_a^{2}b+\log_a b+1)}{(\log_a b+\log_b a+1)}$$ But I got nothing.,"['logarithms', 'algebra-precalculus']"
142214,Why are modular lattices important?,"A lattice $(L,\leq)$ is said to be modular when
$$
(\forall x,a,b\in L)\quad x \leq b \implies x \vee (a \wedge b) = (x \vee a) \wedge b,
$$
where $\vee$ is the join operation, and $\wedge$ is the meet operation. ( Join and meet .) The ideals of a ring form a modular lattice. So do submodules of a module. These facts are easy to prove, but I have never seen any striking examples of their utility. Actually, in a seminar I took part in, the speaker said the modularity condition wasn't very natural and that there was an ongoing search for better ones (this was in the context of the Gabriel dimension and its generalization to lattices -- unfortunately, I didn't understand much of that). I would like to see some motivation for this notion. That is, I would like to know when it is useful, and if it is natural. At the moment, it doesn't look any more natural to me than any random condition in the language of lattices. If you could shed some light on the opinion I quote in the previous paragraph, it would be very helpful as well. I would be especially interested in algebraic motivation, as I know very little about other areas if mathematics.","['motivation', 'big-picture', 'lattice-orders', 'abstract-algebra', 'soft-question']"
142215,"Counting the number of pairs $(a,b)$ such that $M \mid a+b$  with $a, b \in [N]$","We have been given first $N$ natural numbers and asked to count all distinct pairs $(a,b)$ where, $a < b$ such that $a+b$ is divisible by a given number $M$ . Example: Given $N = 4$ , i.e. $\{1,2,3,4\}$ $M = 3$ Only possible pairs satisfying above conditions are $(1,2)$ and $(2,4)$ . Since, $1 < 2$ and $1+2 = 3$ is divisible by $M$ . $2 < 4$ and $2+4 = 6$ is divisible by $M$ . Values $M$ and $N$ can be very large (of the order of $10^9$ ), so simply generating pairs and dividing won't work. My Idea: We need to generate pairs which sum up to multiple of $M$ . Since, there is a strict ordering between $a$ and $b.$ (i.e. $a < b$ ) so, for generating any number $x$ which lies in the range $1$ to $N$ there are $\frac{(x-1)}{2}$ possible pairs. So, we need to sum up these values over multiples of $M$ . But when the value of $x$ goes beyond $N$ , this idea doesn't work (as number of pairs decrease). I can't proceed any further. Kindly guide me if I am in a wrong direction. Or suggest any other alternative to efficiently calculate the same.",['combinatorics']
142223,$SU(2)$ Lie group,I have been studying Lie groups for a bit of fun for a while now and think they are fascinating. I have recently been told that $SU(2)$ can be used in some way to keep track of navigational systems in bodies as they complete whole turns. Does anyone know anything on this subject that can explain it to me clearly and maybe have any idea where I can read up on it?,"['lie-groups', 'reference-request', 'abstract-algebra']"
142238,Family of curves (in algebraic geometry),"How can I view, in algebraic geometry, a family of curves over a base curve? For instance, can the family $y^2 = x(x-1)(x-t)$ be viewed as a family over $\mathbb{P}^1$ ? How can I understand this rigorously? Can someone point me to a reference?","['algebraic-geometry', 'algebraic-curves']"
142241,What is the geometrical action of a skew-symmetric matrix on an arbitrary vector?,"What is the geometrical action of a skew-symmetric matrix on an arbitrary vector? The rotation matrix is a skew-symmetric matrix when $\theta$ is some multiple of $\frac{\pi}{2}$. But it cannot be true that every skew-symmetric matrix represents a rotation? Also, since the leading diagonal is zero, it cannot represent a scaling nor a shear. In fact, none of the standard transformation matrices on Wikipedia seem to fit the pattern of an arbitrary skew-symmetric matrix. So can anything be said about the geometrical action of a skew-symmetric matrix on an arbitrary vector?","['matrices', 'geometry']"
142252,A trigonometric identity: $(\sin x)^{-2}+(\cos x)^{-2}=(\tan x+\cot x)^2$,"I've been trying to prove it for a while, but can't seem to get anywhere. $$\frac{1}{\sin^2\theta} + \frac{1}{\cos^2\theta} = (\tan \theta + \cot \theta)^2$$ Could someone please provide a valid proof? I am not allowed to work on both sides of the equation. Work so far: RS: $$
\begin{align}
& \frac{\sin^2\theta}{\cos^2\theta} + \frac{\cos^2\theta}{\sin^2\theta} + 2 \\[10pt]
& = \frac{\sin^4\theta}{(\cos^2\theta)(\sin^2\theta)} + \frac{\cos^4\theta}{(\sin^2\theta) (\cos^2\theta)} + \frac{(\sin^4\theta)(\cos^2\theta)}{(\sin^2\theta)(\cos^2\theta)} + \frac{(\sin^2\theta)(\cos^4\theta)}{(\sin^2\theta)(\cos^2\theta)} \\[10pt]
& = \frac{\sin^4\theta + \cos^4\theta + (\sin^4\theta)(\cos^2\theta) + (\sin^2\theta)(\cos^4\theta)}{(\cos^2\theta)(\sin^2\theta)}
\end{align}
$$ I am completely lost after this.",['trigonometry']
142254,Easy probability theory proof,"$A$ and $B$ are random occurrences in $\Omega$. Prove that if $P(A)=0{,}9$ and $P(B)=0{,}7$, then $P(A\cap B')\leq0{,}3$, where $B'$ is a complementary event of $B$. I thought of something like this: $P(B')=1-P(B)=0{,}3$ and as the intersection of events can't be greater than any of the events it's taken from, $P(A\cap B')\leq0{,}3$ q.e.d. Is it OK? When I look at the answer the author gave to this task, it includes using the formula for the probability of the sum of occurrences. Is it needed or my solution works as well?",['probability-theory']
142260,Sum of every $k$th binomial coefficient.,"It is widely known that $$\sum_{m=0}^{n} {n\choose m} = 2^n$$
and that $$\sum_{m=0}^{\lfloor\frac{n}{2}\rfloor}{n\choose 2m} = 2^{n-1}$$ Both results can be proven by exploting the nature of the roots of unity. Analagously, we can find $$\sum_{m=0}^{\lfloor\frac{n}{3}\rfloor}{n\choose 3m}$$ by taking the sum of the equations
$$(1+1)^n = {n\choose 0} + {n\choose 1} + {n\choose 2} + {n\choose 3} + \cdots$$
$$(1+\omega)^n = {n\choose 0} + {n\choose 1}\omega + {n\choose 2}\omega^2 + {n\choose 3} + \cdots$$
$$(1+\omega^2)^n = {n\choose 0} + {n\choose 1}\omega^2 + {n\choose 2}\omega + {n\choose 3} + \cdots$$
by taking $\omega$ as a primitive cube root of $1$ and exploiting the fact that the roots of unity sum to $0$, i.e. $1 + \omega + \omega^2 = 0$. The above method however seems to depend on the fact that every non-trivial root is primitive, so that the method only works for primes (For example, attemtping this method for $k=4$ will quickly run into problems as there is no longer full cancellation). Is there a generalization of this method for finding the sum of every $k$th binomial coefficient for arbitrary $k$? Failing that, does anyone know of any general method for finding such a sum?","['complex-numbers', 'binomial-coefficients', 'combinatorics']"
142267,What is an example of a linear function that maps a matrix to a scalar? What makes it a 'function'?,"I suppose this is part terminology question and part math, but I am trying to untangle what we mean when we say ""The linear function $f$ maps $R_{m\times n}$ space to $R_{m}$ space"", and ""The linear function $f$ maps $R_{m\times n}$ space to $R_{1}$ space"". To wit: Let us say that there exists an $m\times n$ matrix $A$, and a function $f$ that maps $R_{m\times n}$ space to $R_{m}$ space. In this case, such a function $f$ can be an $n\times 1$ vector $v$. Thus, to apply the function, we have simply: $$ f(A_{m\times n}) = A_{m\times n}v_{n\times 1} =b_{m\times 1}$$ So here, the function $f$ is the vector $v$. My question is when we read the statement ""The linear function $f$ maps the $R_{m\times n}$ space to $R_{1}$ space"", (scalar), then what is an example of this function? It cant be just a vector or just a matrix, so what does it look like? I realize we can do $v^{T}Av$ if $A$ is a square, and this will give a scalar, but what is the function here? Thanks","['matrices', 'functions']"
142271,"When $X_s<Y_t$ almost surely, for every $s<t$, implies that $X_s<Y_t$ for every $s<t$, almost surely?","When I have shown, for $s\le t$ and for two continuous stochastic process an inequality: $$ X_s \le Y_t$$ P-a.s. How can I deduce that this P-a.s. simultaneously for all rational $s\le t$ ?
Thank you for your help EDIT: According to Ilya's answer, I see that we have $$P(X_s\le Y_t\text{ simultaneously for all rationals }s\le t) = 1.$$ 
How could we use continuity of $X,Y$ to deduce $P(X_s\le Y_t,s\le t)=1$. Of course we take sequences of rational, however I mess up the details. So a detailed answer how to do this, would be appreciated.","['probability-theory', 'stochastic-processes', 'almost-everywhere']"
142277,Proving two results about the spectral radius,"How do I prove these two theorems? Furthermore, can I apply them to infinite-dimensional spaces, such as Banach spaces? Theorem 1. Let $M\in \mathbb{C}_{n\times n}$ be a matrix and $\epsilon > 0$ be given. There is at least one matrix norm $||\cdot||$ such that
  $$\rho(M) \leq ||M|| \leq \rho(M) + \epsilon$$
  where $\rho(M) = \max\{|\lambda_1(M)|, \dots , |\lambda_n(M)|\}$ denotes the spectral radius of $M$. Theorem 2. If $P \in \mathbb{C}_{n\times n}$ and $S\in \mathbb{C}_{n\times n}$ are such that $P = P^2$ and $PS = SP$ then
  $$\rho(PS) \leq \rho(S).$$ I have used these results in finite dimensional spaces and want to use them in a Banach space.","['matrices', 'normed-spaces', 'functional-analysis']"
142279,Norm on a Hölder's space,"I want to prove that Hölder space is a Banach space under the ""Hölder Norm"" ie. $\|\cdot\|_{C^{k,\alpha}}$. 
Any hints would be appreciable .","['holder-spaces', 'functional-analysis', 'real-analysis']"
142302,Point on the bisector and excenter,"Given a triangle ABC, $\angle BAC = 20^{\circ}, \angle ACB=30^{\circ}$. M is a point inside the triangle such that $\angle MAC=\angle MCA=10^{\circ}$. L is a point on AC (L is between A and C) such that $AL=AB$. If $AM \cap BC =K$, prove that $K$ is the center of the excircle of $\triangle ABL$. Find $\angle AMB$. Proving that $K$ is the excenter of $\triangle ABL$ is easy. However, I cannot find $\angle AMB$.",['geometry']
142337,"Optimal lower bound of $k$-sums for the integers $\{1,2,\ldots,n\}$ arranged around a circle in arbitrary order.","This question is motivated by the following two questions and is a slightly generalized version of them. Some three consecutive numbers sum to at least $32$ Integers $1, 2, \ldots, 10$ are circularly arranged in an arbitrary order. Consider the first $n$ positive integers distributed along a circle in an arbitrary order. There are a total of $(n-1)!$ arrangements. Pick an arrangement $P_m$, where $m \in \{1,2,\ldots,(n-1)!\}$ The arrangement $P_m$ is of the form $a_{m,1},a_{m,2},\ldots,a_{m,n}$ around the circle where $a_{m,j} \in \{1,2,\ldots,n\}$ and $a_{m,i} \neq a_{m,j}$ whenever $i \neq j$. Define a $k$-sum as the sum of $k$ consecutive numbers in an arrangement $P_m$. For instance, $$a_{m,1} + a_{m,2} + \cdots +a_{m,k},$$
$$a_{m,n-1} + a_{m,n} + a_{m,1} + a_{m,2} + \cdots + a_{m,k-2}$$ are examples of $k$-sums. Clearly for any arrangement $P_m$, there are $n$ such $k$-sums. Now look at the maximum of these $k$-sums in the arrangement $P_m$, i.e. $$s_{m,k} = \max \{ (a_{m,1} + a_{m,2} + \cdots + a_{m,k}),(a_{m,2} + a_{m,3} + \cdots + a_{m,k+1}), \cdots,  (a_{m,n} + a_{m,1} + \cdots + a_{m,k-1})\}$$ The question is what is the optimal lower bound of this maximum sum? i.e. What is $\displaystyle \min_{m} s_{m,k}$? In Integers $1, 2, \ldots, 10$ are circularly arranged in an arbitrary order. it is shown that for $n=10$ and $k=3$, the optimal lower bound is $18$ and in Some three consecutive numbers sum to at least $32$ , it is shown that the optimal lower bound for $n=20$ and $k=3$ is $\geq 33$. Clearly, for $k=1$, $\displaystyle \min_{m} s_{m,1} = n$. For $k=2$, $\displaystyle \min_{m} s_{m,2} = n+2$. In general, a trivial lower bound is obtained by adding up all the $n$, '$k$' sums to get that $$n \times \min_{m} s_{m,k} \geq k \frac{n(n+1)}{2}$$ i.e. $\displaystyle \min_{m} s_{m,k} \geq \left \lceil k \frac{(n+1)}{2} \right \rceil$. Clearly, this is not the optimal bound as seen from the results for $k=1$ and $k=2$ and also from the two questions: Some three consecutive numbers sum to at least $32$ , Integers $1, 2, \ldots, 10$ are circularly arranged in an arbitrary order. . So the question is: What is the optimal lower bound? (I am also interested in better lower bounds even if the bound is not the optimal one. Any reference to articles where this has been discussed is welcome.) EDIT Some googling landed me on this article ( http://imi.cas.sc.edu/IMI/reports/2001/reports/0116.pdf ) where they have considered the same problem and have constructed better upper bounds for $\displaystyle \min_{m} s_{m,k}$. They prove that in general $$\displaystyle \min_{m} s_{m,k} \leq \min \left( \left \lceil \frac{k(n+1)}{2} + k + 6 \right \rceil, \left \lceil \frac{k(n+1)}{2} + \frac{k}{2} + 9 \right \rceil \right).$$ Further they prove that if $(n,k) > 1$, then the optimal lower bound is $$\displaystyle \min_{m} s_{m,k}\leq \left \lceil \frac{k(n+1)}{2} + \frac{7}{2} \right \rceil,$$ which I think is remarkable that the factor $\frac{7}{2}$ is independent of $k$ and $n$. However, I am wondering if the lower bound of $\displaystyle \min_{m} s_{m,k}$ can be tightened further and if an exact value of $\displaystyle \min_{m} s_{m,k}$ can be obtained.",['combinatorics']
142341,Formula for a sequence,"I have this sequence:
$-2, 1, 6, 13, 22, 33, ...$ where each term is the previous plus an odd number. The odd numbers are increasing from 3. I am asked to find an explicit formula with respect to $n$ which can give me the $n$-th number in the sequence. The sequence starts at $n = 1$. I tried to find a pattern, without success. I then tried to write the sequence as a recursive formula:
$a_1 = -2$ $a_{n + 1} = a_n + 2n + 1$ and then I got stuck. Can you please advice me about the way to go? Thanks, rubik",['sequences-and-series']
142348,Is there a standard way to compute $\lim\limits_{n\to\infty}(\frac{n!}{n^n})^{1/n}$?,"I'm computing the radii of convergence for some complex power series. For one I need to compute
$$\lim_{n\to\infty}\left(\frac{n!}{n^n}\right)^{1/n}.$$ I know the answer is $\frac{1}{e}$, so the radius is $e$. But how could you compute this by hand? I tried taking the logarithms and raising $e$ by this logarithm, but it didn't lead me to the correct limit. (This is just practice, not homework.)",['limits']
142354,Convex pentagons are similar if conformally equivalent.,"The problem: Suppose two convex pentagons $A$ and $B$ have equal interior angles (that is, $A=A_1A_2A_3A_4A_5$ and $B=B_1B_2B_3B_4B_5$) with $\angle A_j =\angle B_j$ for each $j\in\{1,\ldots,5\}$). Suppose that $\mbox{int}(A) \approx \mbox{int}(B)$ are conformally equivalent with a biholomorphism $f:\mbox{int}(A) \rightarrow \mbox{int}(B)$ whose continuous extension to the boundary maps $A_i\overset{f}{\mapsto}B_i$. Show that under these conditions, $A$ and $B$ are similar. Ideas: I would suspect the reflection principle would be applicable, but I'm not certain how to work out the proof.","['geometry', 'complex-analysis']"
142369,Recursive sequence and a quadratic equation related inequality proof,"I am trying to show that if a sequence of number $x_{n}$ is defined by $x_1 = h$, $x_{n+1}=x_n^2 + k$, where $0<k<\frac{1}{4}$ and $h$ lies between the roots $a$ and $b$ of the equation $$x^2 -x +k = 0$$ Then show that $$a < x_{n+1}<x_n<b$$ and i am also interested in evaluating the limit of $x_n$. Analysis towards a solution I suspect that geometrically this sequence may have tendencies to converge or intersect  this quadratic equation's parabola although i am unsure how to exploit this hunch. What else do I know $$x^2 -x +k = 0 = (x-a)(x-b)$$ hence $a + b =1$ and $0 < k = ab < \frac{1}{4}$ Although i am unsure how to proceed from here any help would be much appreciated.","['geometry', 'sequences-and-series', 'quadratics', 'real-analysis', 'limits']"
142381,Is there a $\sigma$-algebra on $\mathbb{R}$ strictly between the Borel and Lebesgue algebras?,"So, after proving that $\mathfrak{B}(\mathbb{R})\subset \mathfrak{L}(\mathbb{R})$, I asked myself, and now asking you, is there a set $\mathfrak{S}(\mathbb{R})$, which satisfies: $$\mathfrak{B}(\mathbb{R} )\subset \mathfrak{S}(\mathbb{R})\subset \mathfrak{L}(\mathbb{R})$$ ($\mathfrak{B}(\mathbb{R})$ is the Borel's set on $\mathbb{R}$ ; $\mathfrak{L}(\mathbb{R})$ is family of sets which are Lebesgue's measurable - which is a $\sigma$ algebra.)","['measure-theory', 'descriptive-set-theory', 'real-analysis']"
142382,elementary t-test question,"Q:
A tire manufacturer wishes to compare the tread wear of tires made of a new material with that of conventional material. 10 Cars are driven 40,000 miles as the sample set. the following data is obtained: (To avoid some confusion and messy tables I've done some of these computations myself) $\mu_{conventional}$ =4.11 $\mu_{new}$ = 4.814 $s$ = .6699 (To clarify this is the sample standard deviation of the  ""new"" material dataset) The question then is to test at $\alpha$=0.05 that the true mean of the new material exceeds that of the old material. This is a one-sided t-test. (Right?) So I've set it up the following way: $H_0 : \mu = 4.11$ $H_1 : \mu$ > 4.814 $ t = \frac{\bar{x}-\mu_0}{s/\sqrt{n}} = \frac{4.814-4.11}{.6699/\sqrt{10}}$ = 3.3233 Now to look for a .05 confidence using the t-test I obtained the value 1.833 from the t-distribution table. Since the value from our test statistic is 3.3233 > 1.833, I'd reject the Null hypothesis. Can anyone check my work to verify this?",['statistics']
142384,Orientability of the total space of a vector bundle over an oriented manifold,"Let $M$ be a (smooth) manifold of dimension $n$, and let $\pi : E \to M$ be a (smooth) vector bundle of rank $r$. If I choose a connection on $E$, then I obtain a decomposition of $T E$ as $V E \oplus_E H E$ where $V E \cong E \times_M E \cong \pi^* E$ (right...?) and $H E \cong E \times_M T M \cong \pi^* T M$, and thus a split short exact sequence:
$$0 \longrightarrow V E \longrightarrow T E \longrightarrow \pi^* T M \longrightarrow 0$$
Now, take the $(n+r)$-th exterior power of $T^* E$. The decomposition $T E \cong \pi^* E \oplus \pi^* T M$ should then yield an isomorphism as below (right...?):
$$\Lambda^{n+r} T^* E \cong \Lambda^r \pi^* E^* \otimes_E \Lambda^n \pi^* T^* M \cong \pi^* \left( \Lambda^r E^* \otimes_M \Lambda^n T^* M  \right)$$ It is now clear that any two of the following conditions implies the third: $\Lambda^{n+r} T^* E$ is a trivial line bundle over $E$. $\Lambda^r E^*$ is a trivial line bundle over $M$. $\Lambda^n T^*M$ is a trivial line bundle over $M$. Condition (2) can be replaced by “$\Lambda^r E$ is a trivial line bundle over $M$” if we pick a metric on $E$. Thus, assuming $M$ is orientable, $E$ is orientable as a manifold if and only if $\Lambda^r E$ is a trivial line bundle. Question 1. Is the above proof sketch correct? I'm more used to sheaves than vector bundles, and casually commuting $\otimes$ and $\Lambda^\bullet$ through $\pi^*$ makes me feel queasy. Question 2. Is there a way to do this without invoking a connection or a metric? Given that neither the hypotheses nor the conclusion mention such extra structure, it feels as if there has to be a proof that does not use arbitrary choices. For example, the same proof shows that $T^* M$ is an orientable manifold (regardless of the orientability of $M$), but the proof via the canonical symplectic form feels more morally correct and does not invoke connections or metrics.","['vector-bundles', 'differential-geometry']"
142389,Can this statistics question be solved as it stands?,"I have been presented with the following question: An attorney claims that more than 25% of all lawyers advertise. A sample of 200 lawyers in a certain city showed that 63 had used some form of advertisement. At $\alpha$ = 0.05 is there enough evidence to support the attorney's claim? Use the P-value method. I don't know what method I should use to solve it, because it seems as though a standard deviation is needed in order to generate a test-statistic. I believe a z-score test will be used but I can't be positive. Can anyone shed light on this situation? Thanks!",['statistics']
142394,"Is the function ""signomial""?","Function $f:(0, \infty)\longrightarrow \mathbb{R}$ is called $\textbf{signomial}$, if 
$$
f(x)=a_0x^{r_0}+a_1x^{r_1}+\ldots+a_kx^{r_k},
$$
where $k \in \mathbb{N}^*:=\{0,1,2, \ldots\}$, and $a_i, r_i \in \mathbb{R}$, $a_i\neq 0$, $r_0<r_1<\ldots<r_k$, and $x$ is a real variable with $x>0$. My question is simple in the first glamce, but I cannot get it. Question: whether function $\displaystyle{\sqrt p \int_0^{\infty}\left(\frac{\sin t}{t}\right)^p}dt$, for $t>0, p\ge 2$ is signomial? Thank you for your help.","['functional-analysis', 'real-analysis', 'polynomials']"
142404,Why is this function odd?,"Suppose a complex valued function $f$ is entire, maps $\mathbb{R}$ to $\mathbb{R}$, and maps the imaginary axis into the imaginary axis. I see that $f(x)=\overline{f(\bar{x})}$ on the whole real axis, and thus the identity theorem implies that $f(z)=\overline{f(\bar{z})}$ for all $z\in\mathbb{C}$. Then for $ai$ on the imaginary axis, it follows that
$$
f(ai)=\overline{f(\overline{ai})}=\overline{f(-ai)}=-f(-ai).
$$ Does this relation somehow extend to arbitrary $z$ so that $f$ is odd on the whole complex plane?","['parity', 'complex-analysis']"
142413,Gompertz growth equation,":) Hi!
I'm almost finished with a homework problem, but I cannot quite finish it. The problem is as follows: Given the Gompertz growth equation
$$\frac{dN}{dt}=K(t)N(t),\ N(0)=N_0 \\ \frac{dK}{dt}=-\alpha K(t),\ K(0)=\beta,$$ 
I shall first determined a closed-form expression, which will be $K(t)=\beta e^{-\alpha t}$ and $$\frac{dN}{dt}=\beta e^{-\alpha t} N(t) \Leftrightarrow \\ \int\frac{1}{N(t)}dN=\int \beta e^{-\alpha t}dt \Leftrightarrow \\ \log[N(t)]=\frac{-\beta}{\alpha} e^{-\alpha t} + C \Leftrightarrow \\ N(t)=\exp\left( \frac{-\beta}{\alpha}e^{-\alpha t}\right) \frac{N_0}{\exp\left(\frac{-\beta}{\alpha}\right)};$$ 
the last factor is due to the initial condition. Then: Determine the limit $$B:=\lim_{t\rightarrow \infty}N(t), $$ it will be $B=\frac{N_0}{\exp\left(\frac{-\alpha}{\beta}\right)}$ (right?) Then: Show that this is equivalent to $$\frac{dN}{dt}=\alpha N \log\frac{B}{N},$$ I also managed that (the LHS is $KN$, then solve the logarithm), but THEN: For the cases $N_0>B, N_0 <B$, determine $\lim_{t\rightarrow -\infty }N(t)$. If I plug in $t=-\infty$ into $N(t)$, then I get just $0$. Or not? And with my solution for $B$, I get $\exp\left( \frac{-\beta}{\alpha}\right)<> 1$, but since $\alpha, \beta >0$, the exp cannot be smaller than one? I either have a blonde moment, or my solutions are wrong, but magically the equivalence in the $\log$-equation works! Can someone defuse my brain? :) -marie","['ordinary-differential-equations', 'limits']"
142417,"Natural & important probability measures on $\mathcal{C}[0,1]$, in particular the Wiener measure","Which probability measures on $\mathbf{\mathcal{C}[0,1]}$ are known? (Here $\mathcal{C}[0,1]$ is the space of continuous real-valued functions defined on the unit interval.) I'm pretty sure the Wiener measure (or maybe it's ""a"" Wiener measure) is one such measure whose random elements are Brownian motion paths (or something like that, please correct me if this, or anything else I've said, is incorrect). Where can I read about the Wiener measure as a measure (instead of just a process with an implicit measure; I want explicit analysis of the measure)? Planet math has a little bit about this, but I'd like more detail. To answer my ""where can I read..."" question, feel free to just give an explanation yourself, if you're so inclined. Edit. At the behest of Nate (see the comments) I'll try to be more explicit. In Cantor space, $\{0,1\}^{\mathbb{N}}$, the uniform (i.e. Lebesgue) measure is the most natural. Is there a most natural measure in $\mathbf{\mathcal{C}[0,1]}$? After that, the Bernoulli measures are most natural measures on Cantor space. So I'd like some examples of ""natural"" measures on $\mathcal{C}[0,1]$. As Nate said in his comment, the space of measures is the same as the space of continuous processes. Since I'm not so ""process-inclined"", I'd prefer answers and references to be in the language of measures rather than processes. However, if there's a process that is very natural (or at least important), but who's corresponding measure is harder to work with and therefore unavailable in the literature, a reference to or description of that process will still be appreciated. Nate's comment also led to this question, an answer to which might render void my request for answers to be in the language of measures: What exactly is the correspondence between measures and continuous stochastic processes?","['probability-theory', 'stochastic-processes', 'measure-theory', 'reference-request']"
142424,Prove there are at least two periodic solutions,"Could anyone comment on the following ODE problem? Thank you. Given a 2-d system in polar coordinates:
$$\dot{r}=r+r^{5}-r^{3}(1+\sin^{2}\theta)$$
$$\dot{\theta}=1$$ Prove that there are at least two nonconstant periodic solutions to this system. It's easy to prove that there is a noncostant periodic solution using Poincare-Bendixson theorem, but I don't know how to prove the existantce of two nonconstant periodic solutions.",['ordinary-differential-equations']
142426,involving exponential distributions,"The question states:
Let X = time between calls to a service center, It is known that X follows an exponential distribution with a mean of 15 minutes, part 1. What is the probability that x is greater than 20 minutes. So far this is the only one I think I've been able to work out. Since we know that the average is 15 i.e. $ \mu$ = 15, then $\lambda$ = $\frac{1}{15}$, which means that the probability of X > 20 is: P(X>20) = $e^{-\lambda x}$ = $e^{-1}$ or .3678 (36.78%) the other questions are as follows: part 2: if there are no service calls during the last 10 minutes what is the probability that there will be no service call during the next 30 minutes? part 3: find the 90th percentile of X part 4: what is the median time between calls to the service center. can anyone help me solve these problems?",['statistics']
142437,How to calculate the $4$th central moment of binomial distribution?,"I just derived it by using the generation function to first get raw moments. The result is $(-1+3np^2-6p^2-3np+6p)n(p-1)p$. It was merely brutal force calculation, nothing interesting.  So I was wondering, if there any one knows tricks that could simplify the process a bit.",['probability']
142439,Using conjugate differential to determine existence of a harmonic conjugate?,"Consider $u(z)=\ln(|z|^2)=\ln(x^2+y^2)$. I know that $u$ does not have a harmonic conjugate from $\mathbb{C}\setminus\{0\}\to\mathbb{R}$ but playing around with partial derivatives and integrating around the unit circle. However, I know that a function $u$ has a harmonic conjugate if and only if its conjugate differential $*du$ is exact. This is defined as $*du=-\frac{\partial u}{\partial y}dx+\frac{\partial u}{\partial x}dy$. I calculate this to be
$$
*du=\frac{-2y}{x^2+y^2}dx+\frac{2x}{x^2+y^2}dy
$$
so I would assume this is not exact. Is there a way to see that easily? Is this how the criterion for existence or nonexistence of a harmonic conjugate is usually applied in terms of the conjugate differential? Thanks.",['complex-analysis']
142440,"If $f$ is analytic in a region and at every point either $f\,' = 0$ or$ f = 0$, then $f$ is constant","Assume that $f$ is analytic in a region and that at every point, either $f\,'= 0$ or $f  = 0$. Show that $f$ is constant. My attempt: $[f^{2}(z)]\,'=2f(z)f\,'(z)≡0$, so it would only be necessary to clear depending on the condition given Is my reasoning correct?",['complex-analysis']
142442,Maximum distance between images of two points under an analytic function,"Let $z$ and $w$ be two points in the complex unit disk, and let $f$ be a holomorphic function from the unit disk to itself (i.e. $|f| < 1$). Intuitively, it seems that the maximum value of $|f(z) - f(w)|$ over all such $f$ should occur when $f$ is fractional linear. I have tried to prove this using an argument similar to that for the Schwarz lemma, without much success. First, is this fact true? And, second, how would I prove it?",['complex-analysis']
142443,Derivation of the derivative of a square matrix w.r.t. a vector,"So I have gotten stumped on something that seems like it (should?) be easy. I am trying to find the following derivative shown below. I have scoured the wiki link on matrix derivatives , and I think my answer is correct but I want to make sure. So let us say we have a square matrix $\boldsymbol{A}$, and a vector $\boldsymbol{\theta}$. (I am assuming here that the dimensionality is 2 for ease. So: $$\boldsymbol{A} = \begin{bmatrix} a_{11} & a_{12} \\ a_{21} &a_{22}\end{bmatrix}, \boldsymbol{\theta}= \begin{bmatrix} \theta_0 \\ \theta_1\end{bmatrix}$$ I am trying to derive how we get: $$
\frac{\delta \boldsymbol{A}\boldsymbol{\theta}}{\delta \boldsymbol{\theta}}= \boldsymbol{A}
$$ So first I tried to 'open up' the matrix-vector product, so I now have the following matrix: $$
\begin{bmatrix} a_{11}\theta_{0} + a_{12}\theta_{1} \\ a_{21}\theta_{0} + a_{22}\theta_{1} \end{bmatrix}_{2x1}
$$ ... and this is where I am stuck. How do I show from here, that the derivative of the above is indeed equal to $\boldsymbol{A}$? I know that I have to take the partials, but I cannot seem to find a rule governing in what ordering of columns/rows those partials must be taken.","['matrices', 'derivatives']"
142446,Computing the degree of a finite morphism $\mathbb{P}^n\to \mathbb{P}^n$,"Let $k$ be an algebraically closed field. Suppose that $f\colon \mathbb{P}^n(k)\to \mathbb{P}^n(k)$ is a morphism of the form $f = [f_0:\cdots: f_n]$ where the $f_i$ are homogeneous polynomials of degree $d$ with no nontrivial common zeros. In this case, the degree of the morphism $f$ is $d^n$. The only way I know how to compute this is via the intersection theory of $\mathbb{P}^n(k)$. Since the degree of $f$ is defined (very concretely) as the degree of the field extension $f^*k(\mathbb{P}^n)\subseteq k(\mathbb{P}^n)$, I wonder if there is a less high-tech way of computing that $\deg f = d^n$. Does anyone know a way?",['algebraic-geometry']
142450,How do I prove that $\sin(π/2+iy)=1/2(e^{y}+e^{−y})=\cosh y$?,How do I prove that $\sin(π/2+iy)=1/2(e^{y}+e^{−y})=\cosh y$? Can you help please?,"['trigonometry', 'complex-analysis']"
142453,showing that $(\int f )(\int g) \geq 1$,"Let $\mu(X) =1$. Let $f,g \in L^1(X)$ be two positive functions satisfying $f(x) g(x)>1$ for almost all $x$, Then $$\left(\int f ~dx\right) \left(\int g~dx\right) \geq 1.$$ Show also that if $f,g\in L^2(X)$ with $\int f ~dx= 0$, then  $$\left(\int fg~dx\right)^2 \leq \left[ \int g^2 ~dx - \left(\int g~dx\right)^2 \right] \int f^2~dx.$$ I think I have to use Holder's inequality for both questions: For the first question, since $\mu(X) =1$, $1\lt \int fg~dx$. How do  I apply Holder's inequality.",['measure-theory']
142463,About the remainder of Taylor expansion and Riemann-Liouville integral,"Integral form of Taylor expansion looks like this:$$f(x)=\sum_{i=0}^k\frac{f^{(i)}(a)}{i!}(x-a)^i+\int_a^x\frac{f^{(k+1)}(t)}{k!}(x-t)^kdt$$
Riemann-Liouville integral is $$I^{\alpha}f=\frac{1}{\Gamma(\alpha)}\int_a^x{f(t)(x-t)^{(\alpha-1)}}dt$$
Q1: The integral form remainder of Taylor expansion is exactly $I^{k+1}f^{(k+1)}$. Why is that? Q2: As far as I know, Riemann-Liouville integral is basically $\alpha$th antiderivative of $f(x).$ Shouldn't $f(x)=I^{k+1}f^{(k+1)}$? Is that right?",['analysis']
142466,Weak convergence of stochastic process,"For a stochastic process with trajectories in $C[0,1]$ why is it that convergence of the finite dimensional distributions is not sufficient for weak convergence,unless we also have relative compactness, however it is sufficient for a sequence of random variables. Every book simply quotes Billingsley but none explains why this is the case, and I can't figure it out,",['probability-theory']
142472,Dense subspaces in complete TVS,"If $X$ is a complete topological vector space, Y is a dense subspace (so $\overline{Y}=X$), Z is a closed subspace, it is possible that $Y\cap Z=\{0\}$? This is definitely possible for subsets in topological spaces (with intersection being empty), but not sure about complete TVS, or even more particular in complete metric spaces, Banach or Hilbert spaces. Edit: Thanks for the answer Nate. Updated questions: 1) Is it possible to find $Y$ dense that non-trivially intersects any $Z$ of dimension at least 2? 2) Does any infinite dimensional closed $Z$ intersect non-trivially any dense $Y$?","['general-topology', 'functional-analysis', 'banach-spaces']"
142480,If $null(A) \subset null(B)$ can we draw any conclusion about range spaces of $A$ and $B$?,"$A$ and $B$ are given $n\times m$ matrices.
If $null(A) \subset null(B)$ what conclusion can we draw about range space of $A$ and $B$ ?
Can we conclude that range space of $B$ is contained in a range space of $A$ ?","['matrices', 'linear-algebra']"
142483,"Leibniz's Rule. Where did this ""t"" come from?","I know that they probably treated $\displaystyle f(s,t) = e^{-st} f(t)$ so the integration/differentiation thing doesn't matter, but what confuses me is when they got rid of the derivative and how the ""$t$"" pop out? It's taking the derivative with respect to $s$ not $t$. Proof : Consider the identity $$\frac{dF(s)}{ds} = \frac{d}{ds} \int_0^{\infty} e^{-st} f(t) dt.$$ Because of the assumptions on $f(t)$, we can apply a theorem from advanced calculus (sometimes called Leibniz's rule ) to interchange the order of integration and differentiation:
  $$
\begin{align}
\frac{dF(s)}{ds} & = \frac{d}{ds} \int_0^{\infty} e^{-st} f(t) dt\\
& = \int_0^{\infty} \frac{d \left(e^{-st} \right)}{ds} f(t) dt\\
& = - \frac{d}{ds} \int_0^{\infty} t e^{-st} f(t) dt\\
& = - \mathcal{L} \{ tf(t) \}(s).
\end{align}
$$
  Thus,
  $$\mathcal{L} \{ tf(t) \}(s) = (-1) \frac{dF(s)}{ds}$$","['laplace-transform', 'calculus', 'derivatives']"
142489,Upper bound for the series $\sum_{n\geq 1}\frac{1}{(n+1)^{a+1}}\sum_{k=0}^n b^k\left(\frac{(n-k)!}{n!}\right)^a$,"I want to show that the series $$\sum_{n\geq 1}\frac{1}{(n+1)^{a+1}}\sum_{k=0}^n b^k\left(\frac{(n-k)!}{n!}\right)^a$$ converges for $a,b>0$. I have tried this so much that the smallest hint will probably suffice. I asked a question before which would have been enough but it is not true. Right now I am really stuck and frustrated. Any help would be greatly appreciated!","['factorial', 'sequences-and-series', 'calculus', 'limits']"
142490,Showing an ideal is prime in polynomial ring,"Let $k=\mathbb{C}$ and let $J$ the ideal $(xw-yz,y^{3}-x^{2}z,z^{3}-yw^{2},y^{2}w-xz^{2})$. I want to see why $J$ is a prime ideal in $k[x,y,z,w]$. I know that $Z(J)$ (the zero set of $J$) is exactly the image of the $4$-fold Veronese embedding from $\mathbb{P}^{1}$ to $\mathbb{P}^{3}$, i.e., the map given by $[s : t] \mapsto [s^{4}: s^{3}t : st^{3}: t^{4}]$. What I tried: if we consider the following ring homomomorphism: $k[x,y,z,w] \rightarrow k[s,t]$ given by $x \mapsto s^{4}$, $y \mapsto s^{3}t$, $z \mapsto st^{3}$ and $w \mapsto t^{4}$, then one can check that $J$ is contained in the kernel of this ring homomorphism. Now if we can show the the other inclusion we are done because then $k[x,y,z,w]/J$ embeds a subring of $k[s,t]$ and hence $J$ is prime. However I don't see the other inclusion, can you please help? Perhaps there's an easier way.","['commutative-algebra', 'ideals', 'algebraic-geometry', 'abstract-algebra']"
142499,Are sets constructed using only ZF measurable using ZFC?,"Suppose $S$ is a subset of $\mathbb{R}$ which can be defined without using the axiom of choice, i.e. which can be proved to exist using only the axioms of ZF. Does it follow that $S$ is measurable? We know that ZF + ""All subsets of $\mathbb{R}$ are Lebesgue measurable"" is consistent (assuming ZF is), but the claim doesn't follow from this alone, since there could be a proof that $S$ is not measurable which uses choice.","['logic', 'set-theory', 'measure-theory', 'axiom-of-choice']"
142502,Cardinality of a product of countable many sets,"I'm working on this problem that involves the collections of sets. I'm not really sure how to approach this problem. I understand that to prove that something is numerically equivalent one must show that there is a bijection. Any help would be appreciated. Let $\{A_i\}_{i \in \mathbb{Z_+}}$ be a countable collection of sets. Let $B = \displaystyle \prod_{i\in \mathbb{Z_+}}A_i$ be the Cartesian product of the collection. Prove that if every set of the collection $\{A_i\}_{i\in \mathbb{Z_+}}$ contains two distinct elements, then $B$ is numerically equivalent to $\mathbb{R}$, that is, $|B|=|\mathbb{R}|$","['cardinals', 'elementary-set-theory']"
142507,Question regarding Von-Mangoldt function.,"Let $\psi(x) := \sum_{n\leq x} \Lambda(n)$ where $\Lambda(n)$ is the Von-Mangoldt function.
I want to show that if $$ \lim_{x \rightarrow \infty} \frac{\psi(x)}{x} =1 $$ then also $$\lim_{x\rightarrow \infty} \frac{\pi(x) \log x }{x}=1.$$ I tried to play a little bit with $\psi$, what I want to show is that: $$\left| \frac{\pi(x) \log x}{x} -1 \right| \leq \left| \frac{\psi(x)}{x} -1 \right| \rightarrow 0$$ So I tried to develop $\psi$ a little bit, but I got astray. So I have 
$$ \frac{\psi(x)}{x} -1 = \sum_{p^k \leq x , k \geq 1} \frac{\log p}{x} -1 = \frac{1}{x}\left(\sum_{p\leq x} \log p + \sum_{p^2\leq x} \log p + ...+ \sum_{p^k \leq x, p^{k+1} >x} \log p \right) -1 $$
and I want to estimate its aboslute value from below, but I don't have any idea? Any hints? Thanks.","['prime-numbers', 'analytic-number-theory', 'number-theory']"
142509,Inverse of $f^{-1}(x)=x^5+2x^3+3x+1$ question,"Let $f$ be a one-to-one function whose inverse function is $f^{-1}(x)=x^5+2x^3+3x+1$. Compute the value of $x_0$ such that $f(x_0)=1$.
I am confused as to what this question is asking me, particularly since I don't understand the subscript under the $x$ variable.","['algebra-precalculus', 'functions']"
142527,How come in statistics there is very little justification for the formulas used and proofs are almost nonexistent [closed],"As it currently stands, this question is not a good fit for our Q&A format. We expect answers to be supported by facts, references, or expertise, but this question will likely solicit debate, arguments, polling, or extended discussion. If you feel that this question can be improved and possibly reopened, visit the help center for guidance. Closed 12 years ago . I don't understand why people accept certain formulas in statistics without a mathematical proof style argument. You see this a lot in statistics textbooks and unfortunately this spills over with the instructors who are themselves ignorant of where the formulas come from yet teach them anyway.","['statistics', 'soft-question']"
142549,Calculating the inertia of a real symmetric (or tridiagonal) matrix,"I'm trying to find a quick method for evaluating the inertia of a real symmetric matrix, though I don't need to evaluate eigenvalues directly. The inertia of a matrix is a triple of the number of positive eigenvalues, negative eigenvalues and eigenvalues equal to zero. Thus far I have implemented a method of using Householder matrices to reduce a real symmetric matrix to tridiagonal form (whilst preserving inertia). A textbook by Gilbert Stewart I found through a simple Google search suggests that this is in the right direction. Does anyone have any ideas for the last step?","['numerical-linear-algebra', 'matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
142558,"Joint probabilities, conditional probabilities with the chain rule.","I'm reading through a book, and it walks through a problem. We need to compute $p(a | e, f)$. It says that by applying the chain rule we can see: $$p(a|e,f) = \frac{p(e,a|f)}{p(e|f)}$$ Looking at the chain rule, I do not understand how that was arrived at. I imagine there is a simple explanation (since no further working was shown in the book), is anyone able to provide one?",['probability']
142561,Restrictions for Principal Bundles on Manifolds,"I have some manifold $M$ and am wondering what kind of Principal Bundles I am allowed to construct on it. To be more precise, what are the restrictions when trying to construct principal Bundles over some Manifold? I imagine the topological properties give some quite strict restrictions, but I couldn't find anything in the literature I own. I am specifically looking for restrictions found on the Torus $T^2$. Any pointers are greatly appreciated!","['general-topology', 'fiber-bundles', 'differential-geometry']"
142572,"If cancellation laws hold, then a finite semi-group is a group [duplicate]","This question already has answers here : A finite, cancellative semigroup is a group (5 answers) Closed 10 years ago . Show that if both cancellation laws i.e $w.a = w.b \implies a = b$ and $a.w = b.w \implies a = b$ holds then a finite semi-group (a finite set with associative binary operation) is a group. I have seen some proofs which uses the alternative definition of group to prove it i.e. $a.x = b$ and $y.a =b$ have unique solutions for $x$ and $y$. I am not interested in such proofs. How to prove this statement starting with cancellation laws and then showing that all axioms of group can be derived from them? EDIT : As pointed out in one of the answer. This is only true when underlying set is finite. Edited accordingly.","['semigroups', 'group-theory']"
142575,Does there exist a vector space with 30 elements?,"Does there exist a vector space with 30 elements?
How to determine whether there exist any vector space of particular cardinality?",['linear-algebra']
142589,How to count number of bases and subspaces of a given dimension in a vector space over a finite field? [duplicate],"This question already has answers here : How many k-dimensional subspaces there are in n-dimensional vector space over $\mathbb F_p$? (3 answers) Closed 5 years ago . Let $V_{n}(F)$ be a vector space over the field $F=\mathbb Z_{p}$ with $\dim V_{n} = n$, i.e., the cardinality of $V_{n}(\mathbb Z_{p}) = p^{n}$. What is a general criterion to find the number of bases in such a vector space? For example, find the number of bases in $ V_{2}(\mathbb Z_{3})$. Further, how can we find the number of subspaces of dimension, say, $r$? I need a justification with proof. I have a formula, but I am unable to understand the basic idea behind that formula.","['finite-fields', 'linear-algebra', 'combinatorics']"
142594,List the $x$-axis intercepts for this trigonometric function,"Sketch the graphs of each of the following for $x$ in [0,2$\pi$]. list the $x$-axis intercepts of each graph for this interval. $$y=\sqrt{2} \cos \left(x-\frac{\pi}{4}\right)+1$$
I tried to solve the equation $y = 0$ by performing the following steps:
$$\begin{align*}
-1&=\sqrt{2} \cos\left(x-\frac{\pi}{4}\right) \\\\
-\frac{1}{\sqrt{2}}&=\cos\left(x-\frac{\pi}{4}\right) \\\\ 
-\frac{1}{\sqrt{2}}+\frac{\pi}{4}&=\cos(x) \end{align*}$$ I'm unable to proceed further. Can you please explain this to me in a step-by-step fashion? And I think that after you've got the answer you have to look the unit circle to get the exact answer. Please also show me how to look for the answer from unit cirle. Thanks so much!","['trigonometry', 'algebra-precalculus']"
142602,A sequence of measurable sets,"I want to find a sequence of measurable sets $A_k$. such that $A_k \subset [0,1]$, $\lim \lambda(A_k) =1$, but $\liminf A_k = \varnothing$. There are some examples on function such as $\sin x \over x$ , but I can't apply on a set, $A_k$. Please give me a simple example.",['measure-theory']
142603,Topological invariants,Do continuous maps necessarily preserve topological invariants? Or is it necessary for the maps to be homeomorphisms? Are there simple examples where continuous maps do not preserve these invariants?,['general-topology']
142627,Finding the distance between the centre of an arbitrarily rotated cylinder and a point on that cylinder,"this is a bit more complicated than the post title suggests because I was running out of words. I suppose the full title would be: ""Finding the distance between the centre of an arbitrarily rotated cylinder and a point on that cylinder which is the intersection of a ray projected from the centre of the cylinder at angles a and b, which are relative to the absolute axes."" To break it down a little: I have a circular cylinder, which is rotated to an arbitrary orientation in 3D. I have the radius of the cylinder and I have a vector which is the vector along the cylinder's length (essentially the cylinder's orientation). The cylinder's height is infinite. I also know the coordinates of the centre of the cylinder, let's call that point p. From p I draw a line in 3D in a direction specified by two angles, alpha and beta, which are angles of rotation in the cardinal axes of x and y (i.e. the absolute axes, and not relative to the cylinder). I would like to work out the point at which this line intersects the cylinder and also the distance between the two points. So to break it down further: 1) I need to rotate the cylinder back to the origin, and then rotate the line by the exact same same angles to get them relative to the cylinder while the cylinder is at the origin. 2) Using this new point of reference, I need to calculate the point of intersection between the now transformed cylinder and the line made from the two transformed angles I have. I can get x and y of this point by using rCosAlpha,rSinAlpha and I can get z by using rtanBeta (I have the adjacent - r (the radius) - and need the opposite) And then I simply use Pythagoras' theorem to get the distance. The problem is working this all out using these two frames of reference: absolute orientations and relative orientations. Or solving problem (1) so I don't have Does anybody have any ideas?","['geometry', 'trigonometry', '3d', 'rotations']"
142630,Prove that the Stirling numbers of the first kind satisfy $\displaystyle \sum_{k}\left[n\atop k\right]a_k=n!2^{n-1}$,"Let $a_n$ is the number of orderly divisions of set $\left\{ 1,2,...,n \right\}$ (which means that the sequence of blocks is important, but not the order of elements in blocks). Prove that: $\displaystyle \sum_{k}\left[n\atop k\right]a_k=n!2^{n-1}$ for $n\ge 1$. Is it possible to prove this by induction on $n$?
I think combinatorial interpretation will be easier way, but I don't know how to do that.","['stirling-numbers', 'discrete-mathematics', 'combinatorics']"
142633,How to find out the dimension of a given vector space?,What will be the dimension of a vector space $ V =\{ a_{ij}\in \mathbb{C_{n\times n}} : a_{ij}=-a_{ji} \}$ over field $\mathbb{R}$  and over field $\mathbb{C}$?,"['matrices', 'linear-algebra']"
142645,"Are all eigenvectors, of any matrix, always orthogonal?","I have a very simple question that can be stated without any proof. Are all eigenvectors, of any matrix, always orthogonal? I am trying to understand principal components and it is crucial for me to see the basis of eigenvectors.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
142649,On the Total Number of Tries Required to have $n$ Successes,"The Problem A bag contains $b$ black balls and $w$ white balls. Balls are drawn at random from the bag until the last white ball is drawn. What is the expected number of balls drawn? My Partial Solution Suppose the balls are lined up in a line and drawn from left to right. The number of balls to the left of the rightmost white ball (say $N$) ranges from $w-1$ to $w+b-1$, the number of balls to right is given by $w+b-N-1$. So, we can calculate the probability of each value of $N$ using the hypergeometric distribution, and we have $\text{Expected number}=\displaystyle \sum_{k=w-1}^{b+w-1}\frac{\binom{k}{w-1}\binom{w+b-k-1}{0}}{\binom{w+b-1}{w-1}}\cdot\left(k+1\right)$ which requires computation of $$\displaystyle \sum_{k=w-1}^{b+w-1}\binom{k}{w-1} \cdot \left(k+1\right)$$ which I am unable to do. Is my method even correct, and is there any easy way to do the problem or compute the sum?",['probability']
142668,Integrable function and measure space,"I have two similar problem in measure space. let $f$ be an integrable function on a measure space $X,M,\mu$ such that
$$\int_{E} f \, d\mu = 0$$for all sets $E \in M$. let $f$ be an integrable function on a measure space $R,L,\lambda$ (that is lebesgue space and measure) such that
$$\int_{a}^b f \, d\lambda = 0$$
for all $-\infty<a<b<\infty$. I wanna prove that $f=0$ $a.e.$ both case I got an intution that I can using that fact:
$$\lambda\left\{x\mid f(x)\geq \frac 1n\right\}\leq n\int f \, d\lambda=0,$$ 
But, I can't apply that precisely. Could you give some hints?",['measure-theory']
142683,Calculate the Laplace transform,"Help me calculate the Laplace transform of a geometric series.
$$
 f(t) = \sum_{n=0}^\infty(-1)^nu(t-n)
$$ show that 
$$
\mathcal{L} \{f(t)\} = \frac{1}{s(1+\mathcal{e}^{-s})}
$$ Edit:
 so far I know that $$
\mathcal{L} \{f(t)\} = \frac{1}{s}\sum_{n=0}^\infty(-1)^ne^{-ns}
$$","['laplace-transform', 'ordinary-differential-equations', 'sequences-and-series']"
142710,expansion of $\int_0^\infty\left(\frac{\sin t}t\right)^p\mathrm dt$ in inverse powers of $p$,"This question relates to this answer I gave to a question about the integral $$\int_0^\infty\left(\frac{\sin t}t\right)^p\mathrm dt\;.$$ I derived an expansion in inverse powers of $p$ and then realized that I don't know how to justify it rigorously or how to determine its radius of convergence. I substituted $u=\sqrt pt$ and applied $$\left(1+\frac xn\right)^n=\mathrm e^x\left(1-\frac{x^2}{2n}+\frac{x^3(8+3x)}{24n^2}+\dotso\right)$$ to $$
\left(\frac{\sin t}t\right)^p=\left(1+\frac1p\left(-\frac16u^2+\frac1{120}\frac{u^4}p-\dotso\right)\right)^p$$ to obtain $$
\begin{align}
\sqrt p\int_0^\infty\left(\frac{\sin t}t\right)^p\mathrm dt
&=
\int_0^\infty\mathrm e^{-u^2/6}\left(1-\frac1{180}\frac{u^4}p+\dotso\right)\mathrm du
\\
&=
\sqrt{\frac{3\pi}2}\left(1-\frac{3}{20}\frac1p+\dotso\right)\;.
\end{align}
$$ (For more details, see the answer.) With the help of Wolfram|Alpha , I worked out further terms: $$\sqrt p\int_0^\infty\left(\frac{\sin t}t\right)^p\mathrm dt
=
\sqrt{\frac{3\pi}2}\left(1-\frac{3}{20}\frac1p-\frac{13}{1120}\frac1{p^2}+\frac{27}{3200}\frac1{p^3}+\frac{52791}{3942400}\frac1{p^4}+\dotso\right)\;.
$$ I believe all the intermediate series are well-defined and convergent; the problem is that I don't know how to justify interchanging integration and summation at the end. I doubt that the dominated convergence theorem can be applied, since the integrand is $\operatorname{sinc}^p(u/\sqrt p)$, whose expansion I would expect to oscillate about as badly as the power series for $\sin x$, whose partial sums are unbounded. The last three coefficients given above are roughly of the same order of magnitude, which might indicate that if the series converges at all, it might converge for $p\gtrsim1$. However, while plugging in $p=10$ gives the right result up to six decimal places, the result for $p=2$ is off in the first decimal place, much worse than might be expected from the given terms. That makes me wonder whether this is perhaps just an asymptotic expansion . So my questions are: How can I justify interchanging integration and summation in the last step? Is the series that I obtained convergent? Or is it just an asymptotic expansion? If it converges, how might I determine the radius of convergence?","['definite-integrals', 'asymptotics', 'convergence-divergence', 'sequences-and-series']"
142712,Analytic caustics for 3D objects,"Is it possible to efficiently calculate caustics for a given 3D object, like a torus, or a cube? To be more precise: let's assume that we have a 3d torus, resting on a 2d plane and a single light source, emitting light in all directions. Is there an ""efficient"" (polynomial) algorithm for computing the intensity of light at arbitrary point on the plane?","['geometry', '3d', 'physics']"
142714,Finding the dimension of real symmetric matrices with trace zero,What is the dimension of the vector space of all symmetric matrices of order $n\times n$ $(n\geq 2)$ with real entries and trace equal to zero?,"['matrices', 'linear-algebra']"
142715,Converse of Lagrange's theorem for abelian groups,"I'm trying to prove that the converse of Lagrange's theorem is true for finite abelian groups (i.e. ""given an abelian group $G$ of order $m$, for all positive divisors $n$ of $m$, $G$ has a subgroup of order $n$""). This is an exercise from a book, and it is in the section on finite abelian groups, so I know I have to use the fundamental theorem of finite abelian groups. I have come up with a proof, but it seems a bit messy, and I'm not entirely sure if it's correct. It is given below. Let the order of $G$ be $m$ = $p_1^{\alpha_1} \ldots p_k^{\alpha_k}$. It is known that $G$ is a direct product of $p$-groups, say: $$G = G_1 \times \ldots \times G_k$$ where each $G_i$ is a $p_i$-group. By the fundamental theorem of finite abelian groups, each $G_i$ is isomorphic to a direct product of cyclic groups of the form $$\mathbb{Z}_{{p_i}^{\beta_1}} \times \ldots \times \mathbb{Z}_{{p_i}^{\beta_l}},$$ where $\beta_1, \ldots, \beta_l$ are positive integers such that $\sum_{j=1}^l \beta_j = \alpha_i$. Now if $n$ divides $m$, then we must have $$n = p_1^{\gamma_1} \ldots p_k^{\gamma_k}$$ for some $\gamma_1, \ldots, \gamma_k$ with $0 \leq \gamma_i \leq \alpha_i$. Claim : Each $G_i$ has a subgroup of order $p_i^{\gamma_i}$ Proof : As above, we have that $$ G_i \cong \mathbb{Z}_{{p_i}^{\beta_1}} \times \ldots \times \mathbb{Z}_{{p_i}^{\beta_l}} $$ where $\beta_1, \ldots, \beta_l$ are positive integers such that $\sum_{j=1}^l \beta_j = \alpha_i$. Now since $0 \leq \gamma_i \leq \alpha_i$, we can find
  $l$ numbers $\delta_1, \ldots , \delta_l$ such that $\gamma_i = \sum_{j=1}^l \delta_j$, and $0 \leq \delta_j \leq \beta_j$. (This choice of numbers is not necessarily unique). Then $p_i^{\delta_j} | p_i^{\beta_j}$ for each $j = 1, \ldots , l$. Hence, for each factor $\mathbb{Z}_{{p_i}^{\beta_j}}$, there exists a subgroup of order $p_i^{\delta_j}$, namely $\mathbb{Z}_{{p_i}^{\delta_j}}$ (using the fact that the converse of Lagrange's theorem is true for finite cyclic groups). Taking the direct product of each of these subgroups, we get a new subgroup $G_i'$ of $G_i$: $$G_i' \cong \mathbb{Z}_{{p_i}^{\delta_1}} \times \ldots \times \mathbb{Z}_{{p_i}^{\delta_l}}$$ The order of this subgroup is $p_i^{\delta_1} \times \ldots \times p_i^{\delta_l} = p_i^{\delta_1 + \ldots + \delta_l} = p_i^{\gamma_i} $. So we have found a subgroup of $G_i$ of order $p_i^{\gamma_i}$, as required. So each factor $G_i$ in the product $G = G_1 \times \ldots \times G_k$ has a subgroup $G_i'$ of order $p_i^{\gamma_i}$. Therefore, $G$ has a subgroup
  $$G_1' \times G_2' \times \ldots \times G_k'$$ of order $p_1^{\gamma_i}...p_k^{\gamma_k} = n$, which completes the proof. I have two questions about this: firstly, does this proof seem to work? Secondly, is there a way to make the proof more concise (e.g. a way to prove the statement without using all these indices)?","['finite-groups', 'group-theory', 'abelian-groups']"
142717,"The ring $\{a+b\sqrt{2}\mid a,b\in\mathbb{Z}\}$","The set $\{a+b\sqrt{2}\mid a,b\in\mathbb{Z}\}$ spans a ring under real addition and multiplication. Which elements have multiplicative inverses? This is part of an exercise from an introductory text to algebraic structures. The answer is that an element has a multiplicative inverse if and only if $a^2 - 2b^2 = \pm 1$. It is evident that elements verifying the condition are units but I fail to see that it is the only possible solution. Any one can shed some light?","['ring-theory', 'linear-algebra', 'abstract-algebra']"
142728,Understanding Fatou's lemma,"I want to prove that
(without using Fatou's lemma) for every $k \in N$ let $f_k$ be a nonnegative sequence $f_k(1),f_k(2),\ldots$ $$\sum^\infty_{n=1}\liminf_{k \to \infty} f_k(n) \le \liminf_{k \to \infty} \sum^\infty_{n=1}f_k(n)$$ Can you give some hint for me about that? hat",['measure-theory']
142735,Why is a full turn of the circle 360°? Why not any other number?,I was just wondering why we have 90° degrees for a perpendicular angle. Why not 100° or any other number? What is the significance of 90° for the perpendicular or 360° for a circle? I didn't ever think about this during my school time. Can someone please explain it mathematically? Is it due to some historical reason?,"['geometry', 'math-history']"
142754,Find dimension when sum of the entries in the first row and the sum of the diagonal entries are both zero.,"What is the dimension of the space of all $n \times n$ matrices with real entries
  which are such that the sum of the entries in the first row and the sum of
  the diagonal entries are both zero? I tried by finding number of independent entries. The number of independent entries on the diagonal is $n-1$. The number of upper triangular independent entries is $\frac{n(n-1)}{2}-1(n-1)$, and the number of lowertriangular independent entries is $\frac{n(n-1)}{2}$. Now adding them will give dimension. Am I right?","['matrices', 'linear-algebra']"
142760,"($\mathbb Q$,+) and $\mathbf{Z}_{p^\infty}$ has this property?","There is an exercise telling that every finite subset of group ($\mathbb Q$,+) or of group $\mathbf{Z}_{p^\infty}$ generates a cyclic group itself. For the first group if $X= \left\{\frac{p_{1}}{q_{1}},\frac{p_{2}}{q_{2}},\ldots,\frac{p_{n}}{q_{n}}\right\} $ be a finite subset, then obviously $X\subseteq \langle\frac{1}{q_{1} q_{2}...q_{n}}\rangle$ and so $\langle X\rangle$ is cyclic iself. Kindly asking about the second group. How to show that about $\mathbf{Z}_{p^\infty}$ ? Thanks.",['group-theory']
142767,How to find the equation of a graph with given coordinates? [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Writing a function $f$ when $x$ and $f(x)$ are known If I am given 9 co-ordinates of a random graph say for e.g 1. (2,1)
2. (4,3)
3. (7,9)
4. (9,5)
5. (10,3)
6. (11,1) 
7. (13,4)
8. (15,7)
9. (17,10) ((this is the plotted graph exactly  however it needs to be curved )) How can i create an equation to approximately fit the graphs trendline curve.","['coordinate-systems', 'graphing-functions', 'functions']"
142771,ancient concepts and modern concepts,"Is there an extant published expository account, comprehensible to all mathematicians, of the conceptual differences between ancient Greek mathematical concepts and modern ones? I have in mind things like this: Euclid (I'll need to look between the covers of a book to be sure whether this is right . . . .) didn't know how to multiply more than three numbers because no more than three lines can be mutually orthogonal; but he did know how to find the smallest number measured by more than three numbers (what today we would call the LCM); Consequently (?) he didn't know about factoring numbers into primes (for example, $90= 2\cdot3\cdot3\cdot5$ is not the LCM of its prime factors) (and that's why he stopped short of stating, let alone proving, the uniqueness of prime factorizations), but of course they did know that every number is ""measured by"" at least one prime number; (Maybe?) Euclid did not consider $1$ to be a number; The ancient Greeks had no concept of real number.  They had a concept of congruence of line segments, so that they could say that one line segment goes into another between $6$ and $7$ times, and the remainder goes into the shorter segment between $2$ and $3$ times, etc. etc., so they knew what it meant to say the ratio of the length of segment A to that of segment B is the same as the ratio of the length of segment C to segment D.  They even knew what it means to say the ratio of lengths A to B is the same as the ratio of areas E to F, and similarly volumes.  But they did not make the mistake of knowing whether a particular area is less than a particular length.  Modern mathematicians seem to make that mistake by saying those are real numbers; I think modern physicists may avoid that error. They did not have a concept of irrational number (since they didn't have a concept of real number), but they knew what it meant to say that two line segments have no common measure , and how to prove it in some cases (e.g. no segment can be laid end-to-end some number (= cardinality) of times to make the length of the side of a square and some other number of times to make the diagonal).","['geometry', 'math-history', 'number-theory']"
142781,Circles touching internally,"I need help with the following problem. Given three circles $k, k_1, k_2$. $k_1$ and $k_2$ touch internally $k$ at points $M$ and $N$ respectively. $a$ is the common interior tangent to $k_1$and $k_2$ at points $R$ and $S$. $MR \cap k = A$   and $NS \cap k = B$. Prove that $a \perp AB$.",['geometry']
142782,How to write an integral as a limit?,"We know that the derivative of a function called $f(x)$ can be written as a limit, just like here:$$\frac{d}{dx}f(x)=\lim\limits_{\Delta x\to0}\frac{f(x+\Delta x)-f(x)}{\Delta x}$$ but Is there any definition of integrals in the form of limits?","['calculus', 'integration']"
142787,The universal cover of the multiplicative group over the field of algebraic numbers,"Let $X=\mathbf{A}^1_{\overline{\mathbf{Q}}}-\{0\} = \mathbf{G}_{m,\overline{\mathbf{Q}}}$ be the multiplicative  over the field of algebraic numbers. Each finite etale cover $Y\to X$ (with $Y$ connected) is isomorphic to the finite etale morphism $X\to X$ given by $z\mapsto z^n$ for some $n\geq 1$. The universal covering space $\widetilde{X}$ of $X$ is the projective limit over all finite etale covers of $X$. It's not a scheme. (If $\widetilde{X}$ were a scheme, the ""morphism"" $\widetilde{X}\to X$ would be an etale morphism with non-finite fibres. That's not possible.) Is it endowed with a morphism $\widetilde{X}\to X$? In which category should I consider this ""morphism""? Can we describe $\widetilde{X}$ a bit more explicitly using the above description of all finite etale covers of $X$?","['arithmetic-geometry', 'covering-spaces', 'algebraic-geometry', 'algebraic-curves']"
142819,Uniqueness of subgroups of a given order in a cyclic group,"I am currently studying Serge Lang's book ""Algebra"", on page 25 it is proved that if $G$ is a cyclic group of order $n$, and if $d$ is a divisor of $n$, then there exists a unique subgroup $H$ of $G$ of order $d$. I have trouble seeing why the proof (as explained below) settles the uniqueness part. The proof (as I understand it) goes as follows: First we show existence of the subgroup $H$, given any choice of a divisor $d$ of $n$. So suppose $n = dm$. Obviously, one can construct a surjective homomorphism $f : \mathbb{Z} \to G$, and it is also clear that $f(m\mathbb{Z}) \subset G$ is a subgroup of $G$. The resulting isomorphism $\mathbb{Z}/m\mathbb{Z} \cong G/f(m\mathbb{Z})$ leads us to conclude that the index of $f(m\mathbb{Z})$ in $G$ is $m$ and so the order of $f(m\mathbb{Z})$ must be $d$. Ok, so we have shown that a subgroup having order $d$ exists. The second part is then to show uniqueness - and here is where I am lost as I don't understand why the following argument serves this end: Suppose $H$ is any subgroup of order $d$. Looking at the inverse image of $f^{-1}(H)$ in $\mathbb{Z}$ we know it must be of the form $k\mathbb{Z}$ for some positive integer $k$ (since all non - trivial subgroups in $\mathbb{Z}$ can be written in this form). Now $H = f(k\mathbb{Z})$ has order $d$, and $\mathbb{Z}/k\mathbb{Z} \cong G/H$, where the group on the right hand side has order $n/d = m$. From this isomorphism we can therefore conclude that $k = m$. Here Lang ends by saying "".. and H is uniquely determined"". But why is this ? Does he mean uniquely determined up to isomorphism ? Because, what I think I have shown is that any subgroup of order $d$ must be isomorphic to $m\mathbb{Z}$ - yet this gives me uniqueness only up to isomorphism.. what am I missing ? Thanks for your help!","['group-theory', 'abstract-algebra']"
142821,Matrix for rotation around a vector,"I'm trying to figure out the general form for the matrix (let's say in $\mathbb R^3$ for simplicity) of a rotation of $\theta$ around an arbitrary vector $v$ passing through the origin (look towards the origin and rotate counterclockwise). This is inspired by a similar problem which asked me to find the matrix for a rotation of $120^\circ$ around the vector $v=\begin{bmatrix}1&1&1\end{bmatrix}^\top$. However, in this case I was able to cheat a little since the transformation corresponds to a rotation of the vertices. So even though I found a solution, I'm not satisfied with my methodology. Is there a general form for rotation around an arbitrary vector in $\mathbb R^3$? A reference would be perfectly acceptable. Thanks.","['matrices', 'geometry', 'linear-algebra', 'transformation']"
142827,No simple group of order $96$,"I have to show that there is no simple group of order $96$ using the sylow theorems. I know that $96 = 2^5\cdot 3$, and from the third sylow theorem $n_2 = 1$ or $3$ and $n_3 = 1$ or $4$ or $16$. I have seen some proofs of this statement that use a so called index factorial theorem but I haven't learned about this. Is there a way to prove this using just the sylow theorems?","['group-theory', 'abstract-algebra']"
142829,"Weak convergence (to $\mathcal{N}(0,1)$)","Let $Y_1, Y_1, \dots$ be independent, identically distributed random variables with the uniform[0,1] distribution and let $X_k=k\cdot Y_k,\; S_n=X_1+X_2+ \dots +X_n$. How to prove that $$\frac{S_n}{\frac{n^2}{4}} \,{\buildrel \text{weakly} \over \to_{n \to \infty}}\, 1 $$
and
$$\frac{S_n-\frac{n^2}{4}}{\frac16n^{\frac32}} \,{\buildrel \text{weakly} \over \to_{n \to \infty}}\, \mathcal{N}(0,1).$$ Any help would be really appreciated!",['probability-theory']
142842,Cauchy's Integral Formula and Green's Theorem,"I have been re-reading through my complex analysis text and wanted to try something different. Cauchy's Integral Theorem is typically proved using an application of Green's Theorem and then by virtue of the Cauchy-Riemann Equations the integral vanishes. I have been trying to do the same to Cauchy's Integral Formula. That is, starting with $\int_{\gamma}\frac{f(z)}{z-a}dz$, with $a$ inside the region defined by the curve $\gamma$ I want to get back $f(a) 2 \pi i$. However, whenever I try Green's theorem on the integral, I get that it vanishes. Here is my work so far (mostly based on the proof of Cauchy's Integral Theorem): $$\begin{align}
& \int_\gamma \frac{f(z)}{z-a}dz \\[10pt]
& = \int_\gamma \frac{u(x,y)+iv(x,y)}{z-a}(dx+i\,dy)
\end{align}
$$ Now let $l(x,y)=\dfrac1{x+iy+a}$ So we have
$$
\begin{align}
& = \int_\gamma \frac{u(x,y)+iv(x,y)}{z-a}(dx+i\,dy) \\
& = \int_\gamma ul\;dx -vl\; dy + i \int_{\gamma}vl\; dx+ ul\; dy \\
& = \int\int_D -\frac{\partial vl }{\partial x} -\frac{\partial ul }{\partial y} dx\,dy + i \int\int_D \frac{\partial ul }{\partial x}-\frac{\partial vl }{\partial y} dx\,dy
\end{align}
$$ $\dfrac{\partial ul }{\partial x}=\dfrac{\partial l }{\partial x}u+\dfrac{\partial u }{\partial x}l$
and we know
$$\frac{\partial l }{\partial x}=\frac{\partial  }{\partial x}
\frac1{x+iy+a}=\frac{-1}{(x+iy+a)^2}
$$ and similarly $$\frac{\partial  }{\partial x}\frac1{x+iy+a}=\frac{-i}{(x+iy+a)^2} $$ Thus we have 
$$
\begin{align}
& {} \quad \int\int_{D}-\frac{\partial vl }{\partial x} -\frac{\partial ul }{\partial y} dx\,dy + i \int\int_{D}\frac{\partial ul }{\partial x}-\frac{\partial vl }{\partial y} dx\,dy \\[8pt]
& =-\int\int_{D}\frac{\partial vl }{\partial x} + \frac{\partial ul }{\partial y} dx\,dy + i \int\int_{D}\frac{\partial ul }{\partial x}-\frac{\partial vl }{\partial y} dx\,dy \\[8pt]
& =-\int\int_{D}\frac{\partial l }{\partial x}v+\frac{\partial v }{\partial x}l + \frac{\partial l }{\partial y}u+\frac{\partial u }{\partial y}l \, dx\,dy + i \int\int_{D}\frac{\partial l }{\partial x}u+\frac{\partial u }{\partial x}l-\frac{\partial l }{\partial y}v-\frac{\partial v }{\partial y}l \, dx\,dy \\[8pt]
& =-\int\int_{D}\frac{-1}{(x+iy+a)^2}v+\frac{\partial v }{\partial x}l + \frac{-i}{(x+iy+a)^2}u+\frac{\partial u }{\partial y}l\; dx\,dy + i \int\int_{D}\frac{-1}{(x+iy+a)^2}u+\frac{\partial u }{\partial x}l-\frac{-i}{(x+iy+a)^2}v-\frac{\partial v }{\partial y}l\;dx\,dy
\end{align}
$$ edit:
Taking out a small area around the singularity gives the correct answer. Thank you to froggie for pointing this out! This also gives: If $g(z)$ is a holomorphic function that is bounded for $| z| < 1$ then for all $|a|< 1$ we have $\displaystyle\pi g(a)=\int\int_{|z|<1} \dfrac{g(z)}{(1-a\bar z)^2}\,dx\,dy$ where $z=x+iy$.",['complex-analysis']
142848,Questions about effective Cartier divisors,"Let $f:X\rightarrow S$ be a morphism of schemes. The definition of an effective Cartier divisor in $X/S$ given in Katz-Mazur (what is called relative effective Cartier divisor in the Stacks Project) is: a closed subscheme $i:D\hookrightarrow X$ such that the ideal sheaf $I(D)$ is invertible and $f\circ i:D\rightarrow S$ is flat. I have two (possibly related questions). Question 1: Is the flatness of $f\circ i$ equivalent to flatness of the $\mathscr{O}_X$-module $i_*\mathscr{O}_D\cong\mathscr{O}_X/I(D)$ over $S$? I believe the answer to this question is yes, but only because $i$ is a closed immersion. Flatness of $f\circ i$ means the morphism $\mathscr{O}_{S,f(i(x))}\rightarrow\mathscr{O}_{D,x}$ is flat for all $x\in D$, while flatness of $i_*\mathscr{O}_D$ over $S$ means for each $x\in X$, $(i_*\mathscr{O}_D)_x$ is flat over $\mathscr{O}_{S,s}$ (or equivalently, $i_*\mathscr{O}_D$ is a flat $f^{-1}\mathscr{O}_S$-module). Because $i$ is a closed immersion, $(i_*\mathscr{O}_D)_x$ is either zero or $\mathscr{O}_{D,x}$ according as $x$ is or isn't in $D$. The equivalence of the two conditions follows from this. But surely for a general morphism $D\rightarrow X$ (not necessarily a closed immersion), flatness of $D$ over $S$ and flatness of $i_*\mathscr{O}_D$ over $S$ are different, right? Question 2: In Katz-Mazur, the claim is made (albeit implicitly) that in the sequence $0\rightarrow \mathscr{O}_X\rightarrow I(D)^{-1}\rightarrow i_*\mathscr{O}_D\otimes_{\mathscr{O}_X}I(D)^{-1}\rightarrow 0$, which is obtained by applying the exact functor $-\otimes_{\mathscr{O}_X}I(D)^{-1}$ to the exact sequence
$0\rightarrow I(D)\rightarrow\mathscr{O}_X\rightarrow i_*\mathscr{O}_D\rightarrow 0$ (here $I(D)^{-1}$ is the inverse of the invertible $\mathscr{O}_X$-module $I(D)$), the quotient is $S$-flat. I don't see why this is. I can't even think of an algebraic fact to which it can be reduced. Maybe it helps to think of the quotient as $I(D)^{-1}/1_DI(D)^{-1}$, wher $1_D$ is the section defining the injection $\mathscr{O}_X\rightarrow I(D)^{-1}$. The reason I say ""implicitly"" above is because, while the claim in my second question is never made explicitly, after defining effective Cartier divisors and writing down the exact sequence above, KM considers pairs $(\mathscr{L},\ell)$ consisting of an invertible $\mathscr{O}_X$-module $\mathscr{L}$ and a regular section $\ell$ of $\mathscr{L}$, meaning the associated map $\mathscr{O}_X\rightarrow\mathscr{L}$ is injective, such that in the sequence \begin{equation*}
0\rightarrow\mathscr{O}_X\rightarrow\mathscr{L}\rightarrow\mathscr{L}/\mathscr{O}_X\rightarrow 0
\end{equation*} the quotient is $S$-flat. Ultimately they describe a bijective correspondence between isomorphism classes of such pairs and effective Cartier divisors, given by $D\mapsto (I(D)^{-1},1_D)$. This is why I think the claim about $S$-flatness of the quotient in the exact sequence of Question 2 is being made implicitly.","['sheaf-theory', 'algebraic-geometry']"
142849,2nd order ODE to 1st order ODE/Forward euler method,"I have a $2^\text{nd}$ ODE: $$
\begin{cases}{d^2u \over dt^2} =5tu+\sin \left({du\over dt}\right)\\[5 pt] u(0)=1\\[5 pt] 
{du\over dt}(0)=0
\end{cases}
$$ I was reading my notes and it asked to write the $2^\text{nd}$ order ODE as a system of $1^\text{st}$ order ODEs. And then to construct a forward euler discretisation of the ODE with step size $\tau =1/2$ and interval $[0,2]$. What was done in the notes was: $$\begin{align}
\text{Let }&v={du \over dt}\\
&{dv \over dt}={d^2u \over dt^2}\\ 
\implies &{dv \over dt}=5tu+\sin v, \ v(0)=0.
\end{align}
$$ I understood the above, but I'm not sure what was done after that. Could someone explain to me what was done below? Let $$
w= \left(
    \begin{matrix}
      u \\
      v
    \end{matrix}
  \right)\\ 
\text{then } {dw \over dt}=f(t,w), \;\;\;\;\;\; w(0)=w_0 \\
\text{where } f(t,w)=\left(
    \begin{matrix}
      v \\
      5tu+\sin v
    \end{matrix}
  \right) \text{ and } w_0=\left(
    \begin{matrix}
      1 \\
      0
    \end{matrix}
  \right)$$ Continuing on from there, how does the following work? In particular how does $$
f(t_0, W^0)= \left(
    \begin{matrix}
      V^0 \\
      5\cdot 0 \cdot U^0 + \sin V^0 
    \end{matrix}
  \right) = \left(
    \begin{matrix}
      0 \\
      0
    \end{matrix}
  \right)$$ Forward euler for the $1^\text{st}$ order system: Given $W^0=w_0$, find $W^{n+1}$ such that $$W^{n+1}=W^n+\tau f(t_n,w)$$ $$n=0 \implies $W^0= \left(
    \begin{array}{c}
      1 \\
      0
    \end{array}
  \right) \\f(t_0, W^0)= \left(
    \begin{array}{c}
      V^0 \\
      5\cdot 0 \cdot U^0 + \sin V^0 
    \end{array}
  \right) = \left(
    \begin{array}{c}
      0 \\
      0
    \end{array}
  \right) \\ \implies W^1 = W^0 +\tau \left(
    \begin{array}{c}
      0 \\
      0
    \end{array}
  \right) \implies W^1 = W^0
$$","['ordinary-differential-equations', 'numerical-methods']"
142854,1st order ODE problem (forward euler),"Let ${du\over dt} = u, \ u(0)=1$. Let the step size be $\tau = 1/3$. Let $0=t_0<t_1=\frac{1}{3}<t_2 =\frac{2}{3}<t_3=1$. Given $U^0=u(0) =1$, we find $U^{n+1}$ $U^{n+1}=U^n+\tau f(t,U^N) \\ U^1=U^0+\tau f(t_0,U^0) \\ U^1 =1+\frac{1}{3}\cdot 1$ I tried to understand but Im still stuck, how does $f(t_0,U^0)=1$? I know $f(t_0,U^0)=f(0,1)$, but how does $f=(0,1)=1$?","['ordinary-differential-equations', 'numerical-methods']"
142865,"Is it true that fundamental group of a manifold with boundary can't be simple? If so, why?","Is it true that fundamental group of a manifold with boundary cannot be simple? I think I read that during a hurried research run through the basement of Geisel library, but didn't mark the  source. If false please provide a counterexample. If true, is there a ""simple"" proof or intuitive reason?","['general-topology', 'group-theory']"
142868,Compact sets as point spectrum of a bounded operator,"It is well known that if $K$ is any compact set in $\mathbb{C}$, then there exist a bounded linear operator $T:l_2\to l_2$ such that $\sigma(T)=K$. My questions are: Q1) Does there exist $T$, a bounded linear operator on $l_2$ such that the point spectrum $\sigma_p(T)$ is the given $K$? That is, the only eigenvalues are the complex numbers in $K$? Q2)  Does there exist $T$, a bounded linear operator on $l_2$ such that $\sigma(T)=\sigma_p(T)=K$. That is, there are no other points in the spectrum except the eigenvalues in $K$? Clearly a positive answer to Q2) implies a positive answer to Q1).","['operator-theory', 'functional-analysis']"
142878,Property of Analytic Function,"If $f:\mathbb{C}\rightarrow\mathbb{C}$ is analytic and $Im(f(z))\neq 0$ whenever $|z|\neq 1$, show that $f$ is a constant. It sounds familiar but not so trivial at all...",['complex-analysis']
142887,Reference request: Vector bundles and line bundles etc.,"I am interested in learning algebraic geometry and I talked to one of my professors today (who is, in part, an algebraic geometer) and he recommended I understand the analytic analogue of the ideas in algebraic geometry so it's not just abstract nonsense when I first see it. Some of specific words he mentioned were vector bundles and line bundles but he could not give any recommendations on the spot and recommended that I ask here. There are only two sources that I know of which cover these subjects in a way that I think coincide with my relatively modest understanding of mathematics (which I will cover a bit later) are the first part of Hatcher's book on K-theory and Spivak's Comprehensive Introduction to Differential Geometry although the latter will, admittedly, cover much more than I need or could handle at the moment. If there are any more differential geometry concepts of which I should be aware as well, please feel free to include that as well. I am also aware that I will need to know some commutative algebra and complex analysis and I have gotten some solid recommendations on those topics (some from here, in fact). These are the courses I've taken which I think are relevant to recommendations (all courses are undergraduate): algebra, analysis 1/advanced calculus, differential geometry, proof-based linear algebra, and I am familiar with some topology (in that I know what a topological space is and what a fundamental group is. I will definitely study that more over the summer), I did a reading course on algebraic curves covering the first three chapters of Fulton plus the proof of Bézout's theorem, and I have done an almost reading course in geometry/topology so I am aware of what manifolds are and some of the relevant topology.","['algebraic-geometry', 'reference-request', 'differential-geometry']"
142889,How can I show that arc length $L(\gamma)$ of a curve is unchanged after reparametrization?,Show that the arc length $L(\gamma)$ of a curve $\gamma$ is unchanged if $\gamma$ is reparametrized Can you help me please?,"['differential-geometry', 'complex-analysis']"
142896,Sum to closed form?,"Is there a general method for removing a sum from an expression to produce a closed form? For example I needed to ""unroll"" the following expression in a recent programming competition (as $k_1$ and $k_2$ are large) and couldn't do it... $$ \sum_{w=2}^{k_1}\sum_{h=2}^{k_2}(w-1)(h-1) $$ Do I miss some discrete math training?  By what method would you go about solving this?  Is there a common textbook that would cover this?","['summation', 'algebra-precalculus', 'discrete-mathematics']"
142916,A sequence similar to the Catalan numbers,"The $n$-th Catalan number $c_n$ has the closed form $\frac1{n+1}\binom{2n}{n}$ and follows the recursion $c_n = \sum\limits_{i = 0}^{n-1} c_{n-1-i}c_i$ I am interested in the quantity $e_n$ which follows the recursion $e_n= (n-1) \sum\limits_{i = 1}^{n-1}{e_i e_{n-i}}$ for $n > 1$, with $e_1 = 1$. I am wondering if it is possible to approximate $e_n$ using $c_n$?","['sequences-and-series', 'combinatorics']"
142917,Peano arithmetic inside ZFC,"Is it possible to define Peano arithmetic using ZFC solely? According to my knowledge of ZFC, it seems impossible to define Peano arithmetic using solely ZFC as it only includes few relations. Is a model required to do this?",['elementary-set-theory']
142920,"proof that $1 = \sum\limits_{k=0}^n (-1)^k { 2n \choose n,k,n-k } \frac{n}{n+k}$","I'm looking for a proof of this identity: $$
1 = \sum_{k=0}^n (-1)^k { 2n \choose n,k,n-k } \frac{n}{n+k}
$$ I'll take anything, but a combinatorial proof would be nice - all of the terms in the sum appear to be integers. Update: Given J.M.'s reformulation, if we start with
$$
x^{n-1} (1-x)^n = \sum_{k=0}^n { n \choose k } (-1)^k x^{n+k-1}
$$
and integrate both sides from 0 to 1 wrt $x$ we get:
$$
 \int_0^1 x^{n-1} (1-x)^n dx = \sum_{k=0}^n { n \choose k } \frac{(-1)^k}{n+k}
$$
and so it is sufficient to prove that the integral is $1/( n { 2n \choose n } )$. My instinct tells me to try a trigonometric substitution ($x = \cos^2 u$?) to evaluate the integral - haven't worked out all the details, though. ( Update: see leslie townes comment below.) In any case, I would really like to find a combinatorial proof. Update 2: Found this paper: Walking into an absolute sum and the sum I'm interested in is $P_n(1)$ where $P_n(x)$ is the polynomial defined by:
$$
P_0(x) = 1 \\
P_{n+1}(x) = x^2 [ P_n(x) - P_n(x-1) ] + x P_n(x-1)
$$
From this definition it is clear that $P_n(0) = 0$ for $n > 0$ and so $P_n(1) = 1$.","['binomial-coefficients', 'combinatorics']"
142932,Achilles and the tortoise paradox?,"Let's say we decide to race on a track $1000$ km long. You are a $100$ times faster than me, meaning if we both start at the beginning, you obviously win. To make things more fair you give me a head start of $1$m. The distance is still very small, meaning you will obviously win. A few premises: -For you to win the race you need to overtake me -To overtake me you need to reach a point of equivalence -If there is no point of equivalence you can't beat me Let's assume it takes you $1$ second to reach 1m. However in that $1$ second, I would have travelled a distance forward-lets say I am now at $1.01$m. You haven't caught up to me- I'm still $0.01$m ahead of you. It takes you $0.01$s to travel that $0.01$m. But in that $0.01$ s I would have travelled $0.0001$m, meaning I'm still ahead of you. Therefore you can never catch up to me- the distance between us will get infinitesimally small, but never $0$. Therefore since you can't catch up to me, you can never win. This obvious paradox has been resolved through the fact that an infinitesimal series adds up to one- however, doesn't thid simply prove both people will finish the race? How does it prove the faster person will win? Please don't simply give me a linear solution. I do not want to know when the faster person catches up - I want to know the mathematical flaw in the paradox's logic.","['sequences-and-series', 'paradoxes']"
142935,Rotation $x \to x+a \pmod 1$ of the circle is Ergodic if and only if $a$ is irrational,"I have a book, Ergodic problems of classical mechanics by Arnold/Avez, and in it they prove that rotation $Tx = x+a \pmod 1$ of the circle $M=\{x \pmod 1\}$ is Ergodic if and only if a is irrational. In it they use an earlier corollary that a system is ergodic if and only if any invariant measurable absolutely integrable function is constant a.e. So the start proof goes like this: Suppose $a$ is rational, then write $a=p/q$, $p,q$ coprime. Since $e^{2\pi qx}$ is nonconstant and measurable, $T$ is not ergodic. This is fine, but then how come I can't make a similar argument for irrational $a$? As in: Suppose $a$ is irrational, then $e^{2\pi x/a}$ is nonconstant, and it seems to be measurable and absolutely integrable. What did I do wrong?","['ergodic-theory', 'modular-arithmetic', 'measure-theory', 'irrational-numbers', 'circles']"
142942,Compactly supported function.,"Can anyone explain me the features of a compactly supported functions behave when they are compactly supported. I am learning PDE and I come across it very often. For example : When we define weak derivatives i.e $\int_U uD^\alpha f=(-1)^{|\alpha|}\int_U vf$
, why do we take a function $f$ to be compactly supported ? I wonder if it is has to do with the non-differentiability of $u$ at some point in the domain ? Looking forward. Thanks","['general-topology', 'functional-analysis', 'partial-differential-equations']"
142967,A be a $3\times 3$ matrix over $\mathbb {R}$ such that $AB =BA$ for all matrices $B$. what can we say about such matrix $A$ [duplicate],"This question already has answers here : A linear operator commuting with all such operators is a scalar multiple of the identity. (10 answers) Closed 9 years ago . Let $A$ be a $3\times 3$ matrix over $\mathbb {R}$ such that $AB =BA$ for all matrices $B$ over $\mathbb {R}$ then what can we say about such matrix $A$. 
or such matrix $A$ must be orthogonal matrix? Can we say anything about its eigen values?
 I tried by taking random examples also tried to construct such $3 \times 3$ matrices. But i am not able to get any proper conclusion and proof.",['matrices']
