question_id,title,body,tags
2143952,"What's about functions $f:[0,\infty)\to\mathbb{R}$ satisfying $\int_0^\infty f(x)(\log x)dx=1$?","I've deduced and I know how justify an example of a function $f:[0,\infty)\to\mathbb{R}$ satisfying $$\int_0^\infty f(x)\log xdx=1.$$ Now I state question, and after I write hints to get my example. Question. Imagine that a friend ask me about functions $$f:[0,\infty)\to\mathbb{R}$$ and its more relevant properties, that satisfy $$\int_0^\infty f(x)\log xdx=1.$$ Because it seems too broad, that is I believe that is difficut to determine all functions, impossible to state all relevant statements related to this kind of functions, I am asking here: What should be the first step/s to investigate this question, that is what are examples of functions that satisfies our condition, and what is the obvious property that satisfy as consequence of it? Many thanks. You are able to combine with techniques of real and complex analysis, integration methods ... to show me what should be the strategy and/or hints to study this problem. The example was to combine the closed-form for $\int_0^\infty\frac{\log x}{e^{nx}}dx$ , the Prime Number Theorem, and $(11)$ of this MathWorld's article for the MÃ¶bius function to deduce $$f(x)=\sum_{n=1}^\infty\frac{\mu(n)}{e^{nx}}$$ is a function that satisfies it, because is a consequence of Fubini's theorem: $$\int_0^{\infty}\sum_{n=1}^{\infty}\left|f_n(x)\right|dx\leq\int_0^\infty\frac{x}{e^x-1}dx=\zeta(2)<\infty,$$ with $f_n(x)=\mu(n)\log(x)e^{-nx}$ .","['real-analysis', 'reference-request', 'complex-analysis', 'improper-integrals', 'integration']"
2143974,Evaluating limit $\lim_{k\to \infty}\prod_{r=1}^k\cos{\left(\frac {x}{2^r}\right)}$,"I stumbled across the following question which asked to evaluate... $$\lim_{k\to \infty}\prod_{r=1}^k\cos{\left(\frac {x}{2^r}\right)}$$
I at first tried writing few terms
$$\cos{\left(\frac {x}{2}\right)}\cos{\left(\frac {x}{4}\right)}\cos{\left(\frac {x}{8}\right)}...$$
I used the Half-angle formula to write$$\cos{\left(\frac {x}{2}\right)}=\pm\sqrt{\frac{1+\cos(x)}{2}}$$
Therefore,
$$\sqrt{\frac{1+\cos(x)}{2}}\sqrt{\frac{1+\sqrt{\frac{1+\cos(x)}{2}}}{2}}...$$ 
As there are infinitely many two's in the denominator, the denominator goes to $\infty$ which means $$\lim_{k\to \infty}\prod_{r=1}^k\cos{\left(\frac {x}{2^r}\right)}=0$$ So..My question is ...Am I correct?... If not, Could you please give me some hint to how should I proceed ?",['limits']
2144007,Continuity at a point in topological spaces [duplicate],"This question already has an answer here : Functions between topological spaces being continuous at a point? (1 answer) Closed 1 year ago . I was trying to prove the equivalence between the epsilon delta definition and open ball definition of continuity, and there have already been quite a few discussions such as here already. I realised that in proving that ""epsilon delta $\Rightarrow$ open ball"" we try to show that every point in the preimage of an open ball in the domain is an interior point, which requires the global $\epsilon-\delta$ continuity of a function. This seems to suggest to me that open ball continuity is stronger, as in these two examples: 1) $f(x) :=\begin{cases} 
      0 & x \text{ is rational}\\
      x & x\text{ is irrational} 
   \end{cases}$ Here f(x) is continuous only at $x = 0$. However, the preimage of any open ball containing zero is never open. 2) $ f(x):=\begin{cases} 
      1 & x<-1 \\
      0 & -1\leq x \leq 1 \\
      1 & x>1 
   \end{cases}
$ Here $f(x)$ is continuous at zero, yet there exist an open ball $(-1/2,1/2)$ whose preimage is not open. If continuity on functions only 'makes sense' for global continuity, why do we then still talk about continuity at a point in a topological space (i.e. a function is continuous at $x$ if every neighbourhood of $x$ pulls back to open sets) ?","['general-topology', 'analysis']"
2144022,Homogeneity or heterogeneity of variance,"The international comparative school performance study PIRLS raised in 2011 the reading competences of the fourth graders in more than $40$ countries, among others in Germany. They would now like to investigate how the cultural capital of the parents affects the reading competencies of the children in the fourth class.
They operationalize the cultural capital as the volume of the books in the parents' house. They want to find out if there is a significant difference between children whose parents have over $100$ books, and children whose parents have a maximum of one hundred books. A table of statistic is given: where Mittelwert=mean value, Standardabweichung=standard deviation, Standardfehler des Mittelswertes=standard error of mean value. We have to compute a T-Test to find out, if we can confirm out hypothesis and to get a statistic significant relation. 
First we have to prove with a F-Test, if we have to apply a double T-Test  or a Test of Welch. 
At the F-Test and the T-Test we have a significance level of $5 \%$. $$$$ How can we check what T-Test we have to apply? The null hypothesis is that when the parents have more than $100$ books then the children are better in reading than others, or not? Do we get from that that we don't need a double T-Test? Also using the F-Test how can we check if there is an homogeneity or a heterogeneity of variance? Do  we have to use this formula ?","['statistics', 'variance', 'hypothesis-testing']"
2144037,Determining whether or not a vector is in a cone,"Determine whether or not the vector $\langle 0,7,3 \rangle$ belongs to the cone generated by $$\langle 1,1,1\rangle \qquad \langle -1,2,1\rangle \qquad \langle 0,-1,1\rangle \qquad \langle 0,1,0\rangle$$ That is, I am asked to determine whether or not $\langle 0,7,3 \rangle$ is a linear combination of the other four listed vectors. I have a solution (which I now realize is not correct)
$$
\langle 0,7,3 \rangle=(2)\langle 1,1,1\rangle+(2)\langle -1,2,1\rangle+(-1)\langle 0,-1,1\rangle+(0)\langle 0,1,0\rangle.
$$
My question is more so how would I set up a linear system of equations for the question at hand? I could throw in several more vectors and multiply them all by $0$ as well to have $\langle 0,7,3 \rangle$ in a variety of cones, but that is rather trivial (just multiplying other vectors by $0$). How would I set up the original question here as an augmented matrix so I could row reduce it effectively? Question: Can anyone find nonegative weights for $\langle 1,1,1\rangle$, $\langle -1,2,1\rangle$, and $\langle 0,-1,1\rangle$ that will give $\langle 0,7,3 \rangle$?","['linear-programming', 'convex-cone', 'linear-algebra', 'vectors']"
2144069,Complement of a divisor in an affine scheme,"Let $A$ be a domain, not necessarily noetherian or normal, let $X = {\rm Spec}(A)$ and let $U\subseteq X$ be the complement of a prime divisor of $X$. Is it possible that $\mathcal O_U(U) = \mathcal O_X(X)$?","['algebraic-geometry', 'commutative-algebra']"
2144073,A holomorphic function which has $|f(z)|>1$ for every $|z|=1$ and $|f(0)|<1$ has a fixed point inside the unit circle,"Edit: the answer suggested by @ShakedBader posted here works for this question as well. But I'm curious about the extra assumption here about $|f(0)|$. Does it allow to solve the question using Rouche's lemma? Let $f$ be a holomorphic function on a domain which contains the unit circle. We know that $|f(z)|>1$ for every $|z|=1$, and that $|f(0)|<1$. Show that there exists a point $a\in \mathbb C$, such that $|a|<1$ and $f(a)=a$. I see that due to continuity, we can find a path in the unit circle which circles zero, and where $|f(z)|=1$ hold for each $z$. But I'm not sure how to proceed. Any clues?",['complex-analysis']
2144077,Complete classification of the groups for which converse of Lagrange's Theorem holds,"It is known that the converse of Lagrange's Theorem isn't true in general. More precisely it is known that the following proposition: If $G$ is a finite group of order $n$ and $m\mid n$ then there exists a subgroup $H$ of $G$ such that $\operatorname{order}(H)=m$ . isn't true for all finite groups $G$ . My questions are: For which groups $G$ does the converse of Lagrange's Theorem (as stated above) hold? More precisely, if $G$ is a group for which the converse of Lagrange's Theorem as I mentioned above holds then what properties must $G$ satisfy? If there is no complete classification of such $G$ s then can someone give me references to works by other mathematicians where they try to give at least a partial classification of these $G$ s? Please note that I am not interested in knowing a complete classification of the groups for which a partial converse holds ( Sylow's Theorems does the job in some sense). I want to know a complete classification of the groups for which the converse of Lagrange's Theorem as I mentioned above holds.","['reference-request', 'abstract-algebra', 'group-theory', 'finite-groups']"
2144079,Infinite graph theory study guides,"I'm a first year Computer Science student and I've just finished the Algebra  I course. This included an introduction to set theory, equivalence relations, countable sets, factor set, groups, (iso)morphism. During my study I've stumbled upon the Cantor-Bernstein  Theorem: Consider two sets $A$ and $B$. If there exists two injective functions $f:A\rightarrow B$ and $g:B\rightarrow A$, then $|A|=|B|$. I've been trying to prove this theorem by using graph theory, by considering that the elements of $A$ and $B$ are the vertexes of a oriented bipartite graph and the two functions $f$ and $g$ determine a series of one-way arches between these vertexes. After some time I realized that the two sets may as well be uncountable, thus making finite graph theory of no use. I'd like to ask anyone here for some recommendations on infinite  graph  theory (pdfs, books, lecture notes etc.). Thanks in advance! PS: All my knowledge in graph theory comes from my work with them as a programming-related subject, not math-related.","['graph-theory', 'elementary-set-theory']"
2144092,$10 \times 10$ board travel,"You are given a $10 \times 10$ board and a figure that can move $3$ fields up, down, left or right, or $2$ fields diagonally in each direction. Is there any possible way of visiting every field of the board, so that you never visit the same field twice, and, if there is, which is it?","['combinatorics', 'chessboard']"
2144153,$ n$-dimensional rotation matrix,"I want to find $n$ dimensional rotation matrix which corresponds rotation of an angle  $\theta$
around the 
$(nâ2)$-dimensional subspace. There is  the n-dimensional rotation matrix formula . (see equation $15$) $$I+(n_2n_1^T-n_1n_2^T)\sin(a)+(n_1n_1^T+n_2n_2^T)(\cos(a)-1)$$ where $n_1$ and $n_2$  are $n$-dimensional orthogonal unit vectors. Can anybody explain how can I use this formula,  for $n=6$?","['matrices', 'linear-algebra']"
2144165,Why do you have to define that a specific value in a function is undefined?,"While teaching us about limits, my math teacher showed us how to define a function with a ""hole"" in it: $$f(x)=\begin{cases}x^2, & x \neq 2 \\ \text{undefined}, & x=2\end{cases}$$ This is really confusing me, why do I have to define that a value is undefined? I asked her, and her reasoning is that if you don't write that for $x=2$ there is no value, then it could be any value possible, like $7$ or $42$ as the function has only be written partially. She added that it is only I who thinks that it is undefined, for everyone else, it could be anything, and thus, I have to explicitly write that the function has no value for $2$, or else it wouldn't be mathematically correct. I don't understand the reasoning for the following reason: If I write $$f(x)=x^2, \text{ for } x\neq 2$$ then the function is already undefined for the value is $2$, as the function has no formula if $x=2$. And thus, the value is undefined, I don't have to write it again that it is in fact undefined. After a while, she dismissed me by saying that it is only a formality, and as a result not important. But I really want to know, so where is my flaw? Or rather, why do I have specify that the function is undefined for $2$ explicitly?",['functions']
2144324,"New, elegant proofs for $\varphi(p^{k})=p^{k}-p^{k-1}$","Are there any short, elegant proofs known for the identity $\varphi(p^{k})=p^{k}-p^{k-1}$
? (Here $\varphi$ is Euler's totient function and $p$ is a prime.) The standard combinatorial proof goes like this: In the set $\left\{ 1,2\ldots,p^{k}\right\} $ there in total $p^{k}$
  number. Split this set into $p$ subsets $\left\{ 1,\ldots,p\right\} $,
  $\left\{ p+1,\ldots,2p\right\} \ldots$ Then in each of these sets
  there is only one number -- namely the one of the form $m\cdot p$ for
  some suitable $m$, that divides $p^{k}$. There are in total
  $\frac{p^{k}}{p}=p^{k-1}$ such sets, so in total $p^{k-1}$-many number from
  $\left\{ 1,2\ldots,p^{k}\right\} $ divide $p^{k}$. Thus
  $(p^{k}-p^{k-1})$-many numbers are coprime to $p^k$, which proves the identity. $\square$ (A different proof that is often encountered assumes that we know that
 $\varphi(n)=n\prod_{p\mid n}(1-\frac{1}{p})$, from which our identity
 follows immediately.
 But this is actually a longer proof, since proving
the auxiliary identity is longer.) Surprisingly, I would have imagined that there are tons of wildly different proofs of such a basic fact out there, but a preliminary internet seach as well as book skimming returned only (minor variations of) these two proofs. EDIT The present proofs are more or less reformulations (very polished with details hidden as good as possible - but still reformulations) of my first proofs. What I'm looking for are more radically different approaches (if these exist).","['number-theory', 'alternative-proof', 'elementary-set-theory', 'totient-function']"
2144424,Negation of $0 = 1$,"I'm taking my first proof-heavy class (real analysis), and one practice problem on the first homework is to write the negation of $$0 = 1$$ My immediate thought was that it would simply be $$0 \neq 1$$ but I'm not 100% certain of that answer. I was wondering if there's more to it than just inverting the $=$ sign, and perhaps you'd distribute the negation like $$\neg 0 \neq \neg1$$ but logically that doesn't make sense to me. I've tried looking this up, but a statement as simple as $0 = 1$ has given me a hard time finding any good search results. Basically to break down my questions: Is $0 \neq 1$ right? if so, do I prove it somehow? if not, how do you negate expressions like $\langle expr \rangle = \langle expr \rangle$?","['real-analysis', 'logic']"
2144433,existence of a specific topology on $\mathbb{R}$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Is there a topology on $\mathbb{R}$ such that for every subbasis of it like $S$ 
,we have $Card(S) > Card(\mathbb{R})$ ?",['general-topology']
2144467,In how many ways we can color $15$ eggs..,"In how many ways we can color $15$ eggs with colors red, blue, and green, when each egg must  be colored with exactly two distinct colors. My answer is : (1) red and blue colored eggs are in the first box, and (2) red and green colored eggs are in the second box, and (3) blue and green colored eggs are in the third box. So we have $3$ boxes. Any one or two of these  boxes can be empty, because we can put all eggs in one box (that is color every egg with same combination of colors, so all are in one box). Boxes are labeled and objects (eggs) are not. So the answer is $$n+k-1 \choose k-1  $$ so $$ 15 + 3 -1 \choose 15-1$$
Is it correct?","['combinatorics', 'probability', 'elementary-set-theory']"
2144537,Help with the limit of a function in the $\frac{0}{0}$ case,"The limit is this one: $$\lim_{x \rightarrow 0}\frac{(1+2x)^\frac{1}{x}-(1+x)^\frac{2}{x}}{x}$$ I have found that both $(1+2x)^\frac{1}{x}$ and $(1+x)^\frac{2}{x}$ tend to $e^2$, so the numerator tends to 0. I think that the book said that the result of this limit is $-e^2$ if I recall correctly.","['calculus', 'limits']"
2144664,Do all Steiner Triple Systems of order greater than 7 satisfy the Parallel Line Postulate?,"A Steiner Triple System is a set $\mathcal{S}$ of $v \geq 3$ elements together with a set $\mathcal{B}$ of $3$-subsets (triples) of $\mathcal{S}$ such that every $2$-subset of $\mathcal{S}$ occurs in exactly one triple of $\mathcal{B}$. As an example, the following forms a Steiner Triple System of order $7$ on the set $\{ 1,2,3,4,5,6,7 \}$. $\mathcal{S}_7= \{ \{ 1,2,4\},\{2,3,5\},\{3,4,6\},\{4,5,7\},\{5,6,1\},\{6,7,2\},\{7,1,3\}\}$ This does not satisfy the parallel line postulate (where lines are represented here by the elements of $\mathcal{S}_7$), which I am defining here as: ""Given a line $l$ and a point $P$ not on $l$, there is at least one line through $P$ and parallel (disjoint) to $l$"". Consider the point $1$ and the ""line"" $\{2,3,5\}$. Every ""line"" containing $1$ has a non-empty intersection with $\{2,3,5\}$, and thus the parallel line postulate proves false. However, for a Steiner Triple System of order $9$, the parallel line postulate holds true. My question is, does this hold true for all Steiner Triple Systems of order $\geq 9$? My gut says yes, but I'm struggling with proving it. Thanks in advance for the help.","['combinatorial-designs', 'combinatorics', 'geometry']"
2144675,Limits for the solution of the non-linear ODE,"Consider the ODE
$$y''+y'+y^3=0$$
I need to prove that $$\lim_{x\rightarrow \infty} y(x) = 0$$ and $$\lim_{x\rightarrow \infty} y'(x) = 0.$$ Well, introducing the change of variables such as $x_1=y,x_2=y'$ I get the system of equations nonlinear in $x_1, x_2$. My question is, if I linearize this system around $(0,0)$ and analyze the behaviour of the linearized system there, would I be correct to infer that the behaviour is the same for a nonlinear (original) system? Say, for a solution to the linearized system the limits above hold true. Would they hold true for the original system as well then?","['stability-in-odes', 'ordinary-differential-equations', 'nonlinear-system']"
2144691,"Proving that the sequence $a_0=1, a_{n+1}=\cos(a_n)$ converges [duplicate]","This question already has answers here : Let $a_n=\cos(a_{n-1}), L=[a_1,a_2,...,a_n,...].$ Is there an $a_0$ such that $L$ is dense in$[-1,1]?$ (2 answers) Closed 7 years ago . Consider the following recursively defined sequence: $$a_0 = 1, a_{n+1}=\cos\left(a_n\right)$$ Having a look with Wolfram Alpha, it's fairly clear that this sequence converges to something in the neighborhood of $0.74$ or so. However, I have no clue how to actually prove that this sequence is convergent. I've thought about proving that it is a Cauchy sequence - that is, for any given $\varepsilon>0$, there exists an $N\in\mathbb{N}$ such that $|a_n-a_m|<\varepsilon$ for any $n,m>N$. However, I have no clue how to approach to repeated application of the cosine function, especially since you don't know how many iterations of the cosine function there are between $n$ and $m$. Looking at the Wolfram Alpha plot of the first 30 terms in the sequence also gave me the idea to separate the whole thing into two subsequences $a_{2n}$ and $a_{2n+1}$ and then prove that they are increasing and decreasing while being bounded, but again I had no idea how to proceed to due to the repeated iteration of the cosine function. I'd also be interested in a closed form of the limit if there is one, but I'd guess that none exists.","['sequences-and-series', 'calculus']"
2144738,Prove that if $A â C = B â C$ and $A\cap C = B\cap C$ then $A = B$,"I am trying to prove that if $A â C = B â C$ and $A\cap C = B\cap C$ then $A = B$. I have tried using Venn Diagrams as a proof technique, but we are not able to use proof by Venn Diagrams.",['elementary-set-theory']
2144787,Evaluating Sum involving binomial coefficients and powers,"I would like to evaluate the double sum $\sum\limits_{n=1}^{\infty} \sum\limits_{m=1}^{\infty} \dfrac{(n+m)!}{n!m!n^2 m^2}\left(\dfrac{1}{2}\right)^{n+m}$. My starting point was to consider $\sum\limits_{n=1}^{\infty} \sum\limits_{m=1}^{\infty} \dfrac{(n+m)!}{n!m!}x^n y^m = \dfrac{1}{1 -x -y} - \dfrac{1}{1-x} - \dfrac{1}{1-y} + 1$ $\;\;\forall\;\; |x|+|y|<1\;\;$ All what is left is to divide by $xy$ then integrate with respect to $x$ and then with respect to $y$ (process should be repeated twice) finally set $x = y = \frac{1}{2}$. I am however stuck in evaluating the resulting integrals. I expect logarithmic and polylogarithmic functions to show up in the final result. I would appreciate if you can help me formulating the value of this sum.
Thanks for your help...","['combinatorics', 'binomial-coefficients', 'sequences-and-series', 'polylogarithm']"
2144804,Odd and even number proofs,"Let $n$ be an integer. Prove that if $n^2+2n-1$ is even than $n$ is odd. Proof: $$n^2+2n-1=2n$$ $$n^2-1=0$$ $$(n-1)(n+1)=0$$ $$n=-1,1$$ Which are odd. 
Is this a complete proof? I feel like it only proves $n=-1,1$ not an odd number.","['proof-writing', 'foundations', 'proof-verification', 'discrete-mathematics']"
2144830,Hexahedron congruent faces,"Since I have an interest in polyhedra I've come across https://en.wikipedia.org/wiki/Trigonal_trapezohedron , especially the asymmetric one. So this made me wonder for a classification of convex hexahedron with congruent quadrilateral faces. Let $P$ be a convex hexahedron with only quadrilateral faces, which are all congruent to each other. I have been able to prove the following: The polyhedral graph of $P$ is the same as the polyhedral graph of a cube. A face of $P$ (thus each face) must have two sides of equal length. The edge configuration of $P$ is depicted in the figure below. Edges with same colour are of equal length. The angles $\alpha, \beta, \gamma$ and $\delta=2\pi-\alpha-\beta-\gamma$ completely define such a hexahedron (up to scale). Since the hexahedron is convex, we can get that $\alpha < \frac{2\pi}{3}$. So my question is: what extra constraints can I get on the angles? I've tried to use Descartes' theorem on total angular defect, but this gives an empty condition.","['polyhedra', 'congruences-geometry', 'geometry']"
2144888,How to come up with different ways to find the same solution?,"A coin has probability $p$ of heads. Adam flips it first, then Becca, then Adam, etc., and the winner is the first to flip heads. Compute the probability that Adam wins. So I saw this problem this afternoon and I tried solving it on my own. I used the following reasoning to get to the solution: If $n$ denotes the number of tosses done in total. Then the only way Adam can win is if the head appears at an ""odd"" trial ($2n-1$). For the head to occur at the $2n - 1$ trial the first $(2n-1) - 1$ tosses must be equal to tails, so I expressed this as $$p\sum_{n=1}^\infty (1-p)^{2n - 2}$$ I then realized that this is a geometric series, which converges to the following value
$$\frac{p}{1 - (1-p)^2} = \frac{1}{2 - p}$$ From my perspective I thought this was the only way you can get to this result, but the paper from which I got the question from used a very different approach ( recursion ). So I guess my question is, how can you train yourself to think about problems like this in more than one way?","['recreational-mathematics', 'probability', 'problem-solving']"
2144931,Pigeonhole principle - group of 4 friends,"I do not know how to approach an apparent variant of the friends and strangers problem: ""There are 251 students in a class, where every student lists exactly 168 other students who they can work with. For any two students in the class, if student A puts student B on his or her list, then student B will also have student A on his or her list. Show that there must be some group of 4 students who are all willing to work with one another."" Is it correct to take the 251 students as the pigeons, and 168 as the holes? So â251/168â = 2, which is the minimum number of students who choose someone who did not choose them?","['pigeonhole-principle', 'combinatorics', 'graph-theory', 'discrete-mathematics']"
2144940,Intuition for the prime number theorem,"(surprisingly, it appears that this question has not been asked before) Let $\pi(n)$ denote the number of primes $\leq n$. The prime number theorem states that $$\pi(n) \sim \frac{n}{\log n} \  \text{as}  \ n \to +\infty$$ After painstakingly reading through Erdos's elementary proof of this theorem, I think I understand the mechanics of it from a formal perspective. However, I still don't seem to understand intuitively why this theorem is true. I would like some intuitive insight as to why this theorem holds. I understand that for a result as deep as this one, even the intuition is going to contain some nitty-gritty details.  It's probably not the sort of thing that you could explain to a child, for example. Nevertheless, I will ask this question regardless. There has to be some convincing argument for this theorem beyond the technical details of the proofs.","['number-theory', 'prime-numbers']"
2144999,"Is $\{0\}$ a subset of $\mathbb{P}(\{0,1,2\})$?","I'm asked to state whether a statement is true or false and the following is one that is confusing to me: $$\{0\}\subseteq\mathbb{P}(\{0,1,2\})$$ I thought this would be true, but the book says this is false. Wouldn'tâ$\mathbb{P}(\{0,1,2\}) = \{\{0\},\{1\},\{2\},\{0,1\},\{0,2\},\{1,2\},\{0,1,2\},\emptyset\}$?",['elementary-set-theory']
2145008,How do I show that the overlap maps for the real projective space are smooth?,"In Lee's Manifolds and Differential Geometry , exercise 1.42 says ""Show that the overlap maps for $\mathbb{R}P^n$ are indeed smooth."" I'm not sure where to begin. I have read through the text up to this point and feel like I have either missed a particular criteria for a map to be smooth, or I am not connecting the ideas in the necessary way. Any hints to get me moving in the right direction would be greatly appreciated. If $(U_\alpha, \text{x}_\alpha)$ and $(U_\beta, \text{x}_\beta)$ are charts, then the overlap maps are of form $\text{x}_\beta \circ \text{x}_\alpha^{-1}:\text{x}_\alpha(U_\alpha\cap U_\beta)\rightarrow\text{x}_\beta(U_\alpha\cap U_\beta)$.","['smooth-manifolds', 'differential-geometry']"
2145049,Inverse of a square root operator.,"Specifically, let $B$ be a unbounded self-adjoint positive-definite operator on a complex Hilbert space $H$. Denote by $B^{1/2}$ the square root operator of $B$. I am interested in showing that there exists the bounded inverse operator of $B^{1/2}$. I would appreciate if anyone can give me a hint to start with. My intention here is to prove the result without the knowledge of how $B^{1/2}$ is obtained if possible......... If it helps at all, I am reading this book Operator Approach to Linear Problems of Hydrodynamics. , in particular Section 1.4.2.","['functional-analysis', 'unbounded-operators', 'hilbert-spaces', 'partial-differential-equations']"
2145060,Proving functions are linearly independent,"I'm currently going through Harvard's Abstract Algebra using Michael Artin's book, and have no real way of verifying my proofs, and was hoping to make sure that my proof was right. The question reads: Let $V$ be the vector space of functions on the interval $[0, 1]$. Prove that the functions $x^{3}$, $\sin(x)$, and $\cos(x)$ are linearly independent. My proof goes as follows: For these to be linearly dependent there must exist an $a_{i} \neq0$, where $ i = 1, 2, 3$ such that
$$a_{1}x^{3} + a_{2}\sin(x) + a_{3}\cos(x) = 0. $$
So, we'll do this in 3 cases: Case 1: $x = 0$ In this case, $x^{3} = 0$, $\sin(x) = 0$ but $\cos(x) = 1$.
So, we have 
$$0\times a_{1} + 0\times a_{2} + 1\times a_{3} = 0.$$
So, $a_{1}$ and $a_{2}$ could be anything but $a_{3}$ must be 0. Case 2: $x \in (0,1)$ In this case, $x^{3} \neq 0$, $\sin(x) \neq 0$ and $\cos(x) \neq 0$.
So, for this to be true, $a_{1}$, $a_{2}$ and $a_{3}$ all must be $0$. Case 3: $x = 1$ In this case, $x^{3} = 1$, $\sin(x) = .8...$ and $\cos(x) = .5...$.
So, we have 
$$1\times a_{1} +.8\times a_{2} + .5\times a_{3} = 0.$$ So, $a_{3}$ could be any value, while $a_{1}$ and $a_{2}$ must be $0$. So, if $a_{1} \neq 0$ then we have a problem in Case 3. If $a_{2} \neq 0$ we have a problem in Case 3. If $a_{3} \neq 0$ we have a problem in Case 1. So, we know that all of the $a$ values must be $0$ and we complete the proof.","['abstract-algebra', 'linear-algebra', 'proof-verification']"
2145140,CLT cannot be enhanced to convergence in probability,"Let $\{ \xi_n \}^{\infty}_{n=1}$ be iid nondegenerate random variables with finite second moment. Let $\mathbb{E} \xi_i = a$, $S_n = \xi_1 + \cdots + \xi_n$. Prove that $\sqrt{n} \left( \dfrac{S_n}{n} - a\right)$
  converges in distribution and has no limit for the convergence in probability. Ð¡onvergence in distribution is proved, using the central limit theorem. How to prove that there is no convergence in probability?","['weak-convergence', 'probability-theory', 'central-limit-theorem']"
2145255,"What is the affine connection, and what is the intuition behind/for affine connection?","Here is the definition of affine connection, as appears in Milnor's book Morse Theory . DEFINITION. An affine connection at a point $p \in \text{M}$ is a function which assigns to each tangent vector $\text{X}_p \in \text{TM}_p$ and to each vector field $\text{Y}$ a new tangent vector $$\text{X}_p \vdash \text{Y} \in \text{TM}_p$$ called the covariant derivative of $\text{Y}$ in the direction $\text{X}_p$ . (Note that our $\text{X} \vdash \text{Y}$ coincides with Nomizu's $\nabla_\text{X} \text{Y}$ . The notation is intended to suggest that the differential operator $\text{X}$ acts on the vector field $\text{Y}$ .) This is required to be bilinear as a function of $\text{X}_p$ and $\text{Y}$ . Furthermore, if $$f: \text{M} \to \mathbb{R}$$ is a real valued function, and if $f\text{Y}$ denotes the vector field $$(f\text{Y})_q = f(q)\text{Y}_q$$ then $\vdash$ is required to satisfy the identity $$\text{X}_p \vdash (f\text{Y}) = (\text{X}_p f)\text{Y}_p + f(p) \text{X}_p \vdash \text{Y}.$$ (As usual, $\text{X}_p$ denotes the directional derivative of $f$ in the direction of $\text{X}_p$ .) I have two questions. This definition of affine connection is quite terse hereâI'm just seeing text on a page and not really understanding what is going on here. Is it possible somebody could help me parse through/explain what is really being said here with regards to affine connection? Could somebody supply their intuitions behind/for affine connections? Thanks.","['connections', 'riemannian-geometry', 'differential-geometry']"
2145268,Shift of discrete unit step function,"I have $x[n]$ which is discrete unit step function where for $n < 0$, $x[n] = 0$. For $n \geq 0 $, $x[n] = 1$. Now, if I have $x[n-4]$, the $x[n]$ is shifted to the right by $4$. Now, if I have $x[-n]$, then $x[n]$ is flipped. So then, when I have $x[4-n]$, then shouldn't it be the following: $n \leq -4, x[n] = 1\text{; } n > -4, x[n] = 0$? But the graph shows the following: What am I missing? Why is what I thought wrong?","['graphing-functions', 'discrete-mathematics']"
2145271,Continuity ( and differentiability) of a function specified by the functional equation $f\bigl(xf(y)\bigr)f(y)=f(x+y)$,"I was studying the functional equation $f\bigl(xf(y)\bigr)f(y)=f(x+y)$ and observed that for $x=\delta y$ we can write $f(y+\delta y)-f(y) = f(y)\Bigl(f\bigl(\delta yf(y)\bigr)-1\Bigr)$ . I then reasoned that, as $f(0)=1$ we can make $f(y+\delta y)-f(y)$ arbitrarily small by decreasing $\delta y$ so the function ought to be continuous. I want to know whether this proves the function is continuous or the proof requires $f$ to be continuous at $x=0$ as well. Also what can I do to prove this (apart from solving the equation)? The solution, by the way, is $f(x)= \frac{2}{2-x}$ for $x\ne2$ .","['derivatives', 'real-analysis', 'functional-equations', 'continuity', 'analysis']"
2145272,Holomorphic function such that $f(2z)=f(z)$,"Does it exist a holomorphic function on $D(0,1)$ such that for all $z\in D(0,1/2)$ $f(2z)=f(z)$ Iterating we have $f(1/2)=f(2\cdot\frac1{4})=f(\frac1{4})=\cdots=f(\frac1{2^n}).$ By continuity we must have $f(\frac1{2})=f(0)$ so that when I write $f(z)=\sum_{k=0}^\infty a_kz^k,$ we have: $$a_0+\frac{a_1}{2}+\frac{a_2}{4}+\cdots+\frac{a_n}{2^n}+\cdots=a_0$$ so that $a_k=0$ for all $k\ge 1$, so f must be constant egual to $a_0.$ Is that correct ?",['complex-analysis']
2145301,Holomorphic function with constant modulus in the boundary of an annulus can be written as $f(z)=cz^n$ for $c\in \mathbb{C}$ and $n\in \mathbb{Z}$,"I'm preparing myself to take a qualifying exam for my math PHD. I was trying to solve the previous exams and I found a complex analysis problem I couldn't solve: Let $0<r<R$ and $A=\{z\in\mathbb{C}|r<|z|<R\}$. Suppose that $f:A\rightarrow \mathbb{C}$ is an holomorphic function, with a continuous extension to the boundary of $A$ and such that $f(z)\ne0$ for all $z\in A$. 
Also, suppose that for every $\theta\in [0,2\pi]$ we have $|f(re^{i\theta})|=\alpha$ and $|f(Re^{i\theta})|=\beta$, where $\alpha$ and $\beta$ don't depend on $\theta$. Prove that for some $n\in\mathbb{Z}$ and $c\in\mathbb{C}$ we have $f(z)=cz^n$ for all $z\in A$. So far, I tried to define a function that scaled the range and domain to fit into the unitary disc and then apply Schwarz's Lemma, but when I tried to prove the differentiability at 0 I noticed it depended on the derivative of $f$ in $re^{i\theta}$, and I can't define $f'$ in the boundary of the annulus, so I gave up on that idea.
Also, the problem has a hint that states: ""consider $\log|f(z)|-\gamma\log|z|$ for a convenient $\gamma$"". I tried to approach defining a logarithm function, but the domain isn't simply connected so I don't know how to proceed.
Any help is appreciated. Thanks P.S.:This is my first time asking a question on mathstack. If I'm breaking any rule please point it out so I can stop doing it in the future.","['complex-analysis', 'holomorphic-functions']"
2145391,Vakil Exercise $\mathrm{3.2.Q.}$,"I was looking at this exercise from Professor Vakil's book. $\textrm{3.2.Q.}$ EXERCISE: PICTURING $\mathbb{A}^n_\mathbb{Z}$ . Consider the map of sets $\pi: \mathbb{A}^n_{\mathbb{Z}} \to \operatorname{Spec} \mathbb{Z}$ , given by the ring map $\mathbb{Z} \to \mathbb{Z}[x_1, \dots , x_n ]$ . If $p$ is prime, describe a bijection between the fiber $\pi^{â1}([(p)])$ and $\mathbb{A}^n_{\mathbb{F}_p}$ . (You wonât need to describe either set! Which is good because you canât.) This exercise may give you a sense of how to picture maps (see Figure 3.7), and in particular why you can think of $\mathbb{A}^n_\mathbb{Z}$ as an â $\mathbb{A}^n$ -bundleâ over $\operatorname{Spec} \mathbb{Z}$ .(Can you interpret the fiber over $[(0)]$ as $\mathbb{A}^n_k$ for some field $k$ ?) Are we supposed to prove anything more than the isomorphism $\mathbb{Z}[x_1, ..., x_n]/(p)\mathbb{Z}[x_1,\ldots,x_n] = \mathbb{Z}/p[x_1, ..., x_n]$ ? Is there something deeper going on? In general, I think the fiber is given by the ideal generated by the image of the given prime ideal. That's why I got the above computation. But I think I'm missing something, because I don't understand the last part. For the prime ideal $(0)$ , I just get $\mathbb{A}^n_\mathbb{Z}$ with the above approach. Or is the answer to the parenthetical ""no""?","['algebraic-geometry', 'commutative-algebra']"
2145417,Limit of $\lim_{x\to0}\frac{f(x)-\sqrt{x+9}}{x}$?,"How to find this limit? For $|f(x)-3|\le x^2$,
$$\lim_{x\to0}\frac{f(x)-\sqrt{x+9}}{x}$$ Can I make $f(x)=x^2+3$, and then
$$\lim_{x\to0}\frac{x^2+3-\sqrt{x+9}}{x}$$
Using l'Hopital's, 
$$\lim_{x\to0}\frac{2x-\frac{1}{2\sqrt{x+9}}}{1} = -\frac{1}{6}$$ I'm not confident about this answer. How do I do this problem?",['limits']
2145453,Find the $\frac{c}{a-b}+\frac{a}{b-c}+\frac{b}{c-a}$,"Let $a,b,c$ such
$$a\sin^2{x}+b\cos^2{x}=c,~~~\dfrac{a}{\sin^2{x}}+\dfrac{b}{\cos^2{x}}=c$$
find the value
$$\dfrac{c}{a-b}+\dfrac{a}{b-c}+\dfrac{b}{c-a}$$","['trigonometry', 'calculus']"
2145490,Finding $\lim_{x\rightarrow 0^+}\frac{\sin(x\log(x))}{x\log(x)}$ without L'Hospital's rule,"Can someone help wit this question:
Does this limit exist? $$\lim_{x\rightarrow 0^+}\frac{\sin(x\log(x))}{x\log(x)}$$ I'm not allowed to use L'Hospital's rule, or differentiate or anything like that.
I think I have to figure it out by using the epsilon-delta defintion or inequalities.","['real-analysis', 'limits-without-lhopital', 'analysis', 'limits']"
2145497,Inversion is Smooth,"Let $\mathbf{E}$ be a real banach space and $\mathbf{L} = L(\mathbf{E})$ the resultant banach space of bounded linear operators $T:\mathbf{E} \to \mathbf{E}$ equipped with the operator norm $\| T \| = \sup_{\| x \| \leqslant 1 } \|Tx\|$. From https://en.wikipedia.org/wiki/Neumann_series I can see why the subset $\Omega \subset \mathbf{L}$ consisting of all invertible operators is an open set of $\mathbf{L}$. Moreover, from the accepted answer to differential inverse matrix I can see why the map $\Phi: \Omega \mapsto \mathbf{L} \, \,; \,\, T \mapsto T^{-1}$ is frechet differentiable, and specifically $D\Phi(T)S = -T^{-1} S T^{-1}$. How do I use this knowledge to prove the stronger result that $\Phi$ is smooth? Regarding finite dimensional spaces $\mathbf{E}$, this question has been asked before on stackexchange, but the answers almost always employ Cramer's rule for matrices and partial derivatives as ratios of smooth functions. I am not assuming $\mathbf{E}$ is finite dimensional, so Cramer's rule doesn't apply. I'm trying to find an answer that doesn't deal with partial derivatives at all.","['functional-analysis', 'frechet-derivative', 'banach-spaces', 'derivatives']"
2145537,Distribution of eigenvalues of adjacency operators of finite digraphs,"Let $A_n$ be the set of all eigenvalues of binary matrices with trace $0$ (equivalently, the union of spectra of all simple digraphs on $n$ vertices), and let $A=\bigcup A_n$. It is quite easy to prove that $A$ is dense in $\mathbb{C}$, but do we know anything about how it distributes? In particular, given an $r$ do we know to bound $\lim_{n\to\infty} \frac{|A_n\cap B_r|}{|A_n|}$ as a function of $r$ (where $B_r=\{z\mid |z|\le r\}$)?","['combinatorics', 'graph-theory', 'probability']"
2145567,Seminorm $p$ induces norm on $V/\text{ker}(p)$,"I am stuck in the following problem: Let $V$ be a vector space and $p$ seminorm in $V$. Show that $p$ induces norm on quotient space $V/\text{ker}(p)$ defined as $\lVert v+\text{ker}(p)\rVert=p(v)$. It's easy to show the axioms of norm, except the case $$\lVert v+\text{ker}(p)\rVert=p(v)=0 \Rightarrow v+\text{ker}(p)=0\in V/\text{ker}(p) .$$
So we should show that $p(v)=0$ implies $v=0$. But because $p$ is seminorm, there can be non-zero vectors which norms are zero. I don't know how to proceed, any help or hints would be appreciated.","['functional-analysis', 'linear-algebra', 'quotient-spaces']"
2145576,Representation of symmetric function,"I am interested in learning a bit more about symmetric functions of $n$ variables, namely functions that are invariant under permutation of their arguments : $\forall \pi \in \sigma_n$,
$$f(x_1,...,x_n) = f(x_{\pi(1)},...,x_{\pi(n)})$$ When $f$ is a polynomial or a rationial function, it can be written in a unique way as a sum of elementary symmetric polynomials or rational functions. This is the fundamental theorem of symmetrical functions (see http://mathworld.wolfram.com/FundamentalTheoremofSymmetricFunctions.html for instance). What can be said about a symmetric function that is not a polynomial or a rational function (only $C^\infty$ or analytic for instance) ?","['multivariable-calculus', 'symmetric-functions', 'symmetric-polynomials']"
2145595,Bob took a quiz,"Bob took a quiz consisting of 500 questions with two options: Yes and No. Bob did not prepare for the quiz. Flustered, he hastily reached for a fair coin in his wallet and started to toss this coin for answers. Whenever the coin landed heads, he shaded Yes; whenever the coin landed tails, he shaded No.
It turned out that 40% of the questions have Yes as the correct answer, and the rest have No as the correct answer. Among those questions that Bob shaded Yes, roughly how many percent did he get correct? A) 30% B) 40% C) 50% D)60% E) 70% My thought is that of the questions he put as Yes, the chance of getting the right answers is equal to 40%. But this is just a guess and I'm not sure of the explanation or if this is the right answer.","['statistics', 'sampling', 'probability', 'recreational-mathematics']"
2145617,Lie vs. covariant derivative: Visual motivation,"I'm currently teaching a course that ""applies"" differential geometry to computational problems but doesn't have time to go through theorems/proofs in detail.  We're taking a visual approach to help people see from a high level the differential geometry toolbox. I'd like to cover derivatives of vector fields on surfaces.  Both the Lie and covariant derivatives come up in such a lecture. Is there a clear/concrete example of a pair of vector fields $(X,Y)$ on the plane that illustrates (1) why the Lie derivative $\mathcal L_X Y$ is different from the covariant derivative $\nabla_X Y$ and (2) why both derivatives might be useful in different contexts? I'm looking for a succinct, plot-able visualization to help explain what's going on.","['lie-derivative', 'differential-geometry', 'vector-analysis']"
2145673,Product rule for Hadamard product differentation?,"Is there a ""simple"" solution to $\bf \frac{\partial}{\partial w}\big(w \odot f(w)\big)$ assuming the matrix $\bf \frac{\partial f}{\partial w}$ is known? With simple I mean something like in the normal vector multiplication case $\bf \frac{\partial}{\partial w}\big(w^Tf(w)\big) = f(w) + \big[\frac{\partial f(w)}{\partial w}\big]^T w$ such that no other knowledge of $\bf f(w)$ is required.","['derivatives', 'matrix-calculus', 'hadamard-product']"
2145680,proof of congruence of Ramanujan $\tau$ function,"Let
\begin{align*}
\Delta(q)=q\prod_{n=1}^{\infty}(1-q^n)^{24}, 
\end{align*} 
where $|q|<1$, then we can write it as
$$\Delta(q)=\sum_{n=1}^{\infty}\tau(n)q^n.$$
Then Ramanujan proves that for any prime number $p$,
we have 
\begin{align*}
\tau(p)\equiv 1+p^{11}.
\end{align*} I've found a proof using modular forms. 
More generally,
we have
$$\tau(n)\equiv \sigma_{11} \mod 691,$$
where $\sigma_{k}(n)=\sum_{d\mid n}d^k.$
In the proof,
he uses Eisenstein series $E_k$ and proves $E_{12}-E_6^2=\frac{c}{691}\Delta.$
This proof is great,
but I have the following questions: Is there other proof of this congruent identity? What the advantages of modular forms? I want explain my question further. At first glance, I think it is a question about $q-$series. And we may try a algebraic or combinational proof. Thus I seek for a such proof. Besides, what's the advantages of modular forms in dealing with
congruent problem? I am looking forward an answer, so any help will be appreciated!","['number-theory', 'automorphic-forms', 'modular-arithmetic', 'modular-forms']"
2145733,Are almost all $k$-tuples of vectors in high dimensional space almost orthogonal?,"I would like to know, in high dimensions, if you pick $k$ vectors (not necessarily distinct) are they likely to be $\textit{almost}$ orthogonal. I make this precise below but I am also open to other interpretation of the question. Since we only care about orthogonality, we can assume the vectors are unit vectors. Thus I want to consider a set $\textbf{V}=\{x_1,...,x_k\}\subset S^n$, where $S^n$ is the unit sphere. We can thus view $\textbf{V}\in \underbrace{S^n\times\cdots\times S^n}_{k-times}=\mathcal{S}_{n,k}$. Let $\mathcal{O}\subset\mathcal{S}_{n,k}$ denote the subset of $k$-tuples of orthogonal vectors. Let $\mathcal{U}_\epsilon=\{x\in\mathcal{S}_{n,k} : d(x,\mathcal{O}) <\epsilon\}$ be the $\epsilon$ neighborhood of $\mathcal{O}$ in $\mathcal{S}_{n,k}$ (using, say, the $l^2$ product metric, I don't think this matters). Let $\mu$ be the obvious probability product measure on $\mathcal{S}_{n,k}$. My questions is then: Is it true that $$\forall \epsilon > 0\textrm{ and } \forall k\textrm{ }\lim_{n\rightarrow\infty}\mu(\mathcal{U}_\epsilon) = 1$$ If not what can we say about this limit?","['matrices', 'measure-theory', 'probability-theory', 'linear-algebra']"
2145758,A doubt on a proof of $\lim \frac{\sin x}{x}$ as $x\to 0$ provided in Simmons's Calculus with Analytic Geometry,"I'm having difficulty understanding a proof of $\lim_{x\to0}\frac{\sin{x}}{x}=1$ provided in Simmons's Calculus With Analytic Geometry, pg. 72. The proof goes as follows: Let $P$ and $Q$ be two nearby points on a unit circle, and let $\overline{PQ}$ and $\widehat{PQ}$ denote the lengths of the chord and the arc connecting these points. Then the ratio of the chord length to the arc length evidently approaches 1 as the two points move together: $\frac{\text{chord lenght}\overline{PQ}}{\text{arc lenght}\widehat{PQ}}\to1$ as $\widehat{PQ}\to0$ With the notion in the figure, this geometric statement is equivalent to $\frac{2\sin{\theta}}{2\theta}=\frac{\sin{\theta}}{\theta}\to1$ as $\theta\to0$ My doubt is, doesn't this proof simply that $\lim_{x\to0}\frac{\sin{x}}{x}=\frac{0}{0}$ ? I mean, sure the ratio of $\text{chord lenght}\;\overline{PQ}$ to $\text{arc lenght}\;\widehat{PQ}$ approaches 1 as $\theta$ approaches $0$ , but that's because both the numerator and the denominator approach the samue value, which is $0$ . How is it any different from saying $\lim_{x\to0}\frac{\sin{x}}{x}=1$ because both $\sin{x}$ and $x$ approach the samue value $0$ as $x\to0$ ?",['calculus']
2145759,Meaning of symbol product (cross) in a circle: â¨,"I came across this expression: $\tilde{\Phi}(\mu, \nu)\ \dot{=}\ \int_{A\times B}{\Phi(a, b)\ \mathrm{d}\mu \otimes \mathrm{d}\nu}$ In a context where: $A$ and $B$ are compact metric spaces $\mu$ and $\nu$ are probability distribution over $A$ and $B$, resp. $\Phi$ is a continuous function $A \times B \rightarrow \mathbb{R}$ $\tilde{\Phi}(\mu, \nu)$ is said to be the expected value of $\Phi$ I understand that you need to integrate over $A \times B$ to get this expected value, and to take $\mu$ and $\nu$ distributions into account while doing this. But.. How am I supposed to understand the $\otimes$ symbol here? What is this operation? How does $\mathrm{d}\mu$ relates to $a$ and $\mathrm{d}\nu$ relates to $b$ within this integrand? (To get the full context, I've found this in these pretty neat notes introducing differential game theory (equation 2.8 page 13).)","['integration', 'notation', 'probability-distributions']"
2145760,Infinitely differentiable functions and their bounds,"We know that if $f(x)$ is analytic, i.e $f(x) \in C^\infty$ in an open set $D$ and $f(x)$ has a convergent Taylor series at any point $x_{0}\in D$ for $x$ in some neighborhood of $x_{0}$, we can write $\left|{\frac {d^{k}f}{dx^{k}}}(x)\right|\leq C^{k+1}k!$ Is there a counterpart for the derivative boundedness for infinite differentiable functions $g(x) \in C^\infty$? $\left|{\frac {d^{k}g}{dx^{k}}}(x)\right|\leq h(k)?$","['real-analysis', 'asymptotics', 'calculus', 'analysis']"
2145784,What differential equation does this function satisfy?,"Given the equation: $$\nabla f(x) \times \nabla g(x) = 0$$ for two scalar fields $f$ and $g$. It follows that when this is satisfied $h(f,g)=0$ for some function $h$. The question is to find a smooth function $h$ given functions $f$ and $g$ such $h(s,t)=0$ if and only if there exists a solution to: $s=f(x), t=g(x), \nabla f(x) \times \nabla g(x) = 0$ and otherwise $h(s,t)\neq 0$. Can we infer a differential equation that is satisfied by $h$? Or any other properties? If we write $h$ as: $$h(f,g) = \sum a_{nm} f^n g^m$$ is there a way to find values of $a_{nm}$ knowing the functions $f(x)$ and $g(x)$ ? My first attempt at trying to write a function which if it converges (which it probably doesn't) seems to have the right properties $$ \frac{1}{h(u,v)} = \int \frac{1}{\left((u-f(x))^2+(v-g(x))^2 + |\nabla f(x) \times \nabla g(x)|^2\right)^2 } dx^3 $$ Theoretically this has the right properties but I can't simplify it. e.g. whenever the top equation is satisfied the RHS becomes infinite which implies the function h is zero as required.","['ordinary-differential-equations', 'differential-geometry', 'vector-analysis']"
2145837,"Multivariable second derivative test: what if $f_{xx}(a, b) = 0$?","My textbook introduces the second derivative test for multivariable functions to determine local extrema. However, it does not discuss the case when $f_{xx} = 0$, so I'm at a loss as to what conclusion I can form. Here's the problem: Determine the local extrema for $f(x, y) = x^3 - 3x + 3xy^2$ My solution: $f_x = 3x^2 - 3 + 3y^2 = 0$ $f_y = 6xy = 0$ [this is true if $x = 0$ or $y = 0$] Using the conclusion above: $x = 0: 3y^2 - 3 = 0$, so $y = \pm1$ $y = 0: 3x^2 - 3 = 0$, so $x = \pm1$ Therefore, the critical points are $(0, -1)$, $(0, 1)$, $(-1, 0)$, and $(1, 0)$ Second partial derivatives: $f_{xx} = 6x$ $f_{yy} = 6x$ $f_{xy} = 6y$ Therefore: $D(x, y) = 36x^2 - 36y^2$ But at point (0, -1), I get that $D > 0$ and $f_{xx} = 0$. The textbook only specifies conclusions for $f_{xx} > 0$ or $f_{xx} < 0$.","['multivariable-calculus', 'optimization']"
2145924,A curious sequence (Ascending and descending a staircase),"The following story is true, not just to make it sound mysterious or coincidental. I found a very curious sequence of integers, and searching it gave no result. I am trying to learn more about it, just for fun. We were taking a break with two friends, and came up with the following game in the staircase: Assume there are $n$ stairs (so $n+1$ places to stand); Starting from the bottom, go up 1 stair at a time, until you reach the top; Then turn around and go down 2 stairs at a time, until you can't go further; Then turn around and go up 3 stairs at a time, until you can't go further; .. Then 4, 5, 6, etc. stairs at a time, until you can't even make one step. Whatever the step size is when you stop (the one you cannot achieve), is characteristic of the number of stairs in the staircase, and we call it the Mona number (after my friend Mona). For Example: For $n=5$ we go up to the top, then down in sets of $2$ until we reach $1$, then up $3$ to $4$, then down $4$ to $0$, then up $5$ to $5$, and then we are stuck because there aren't $6$ stairs to go down from our current position. Therefore $M(5)=6$. From there, we wondered if we could find a formula for that number. Obviously it has to be at least 2 (going up the stairs one stair at a time should always be possible), but it is not monotonic with the number of stairs. The ""mirroring"" operation of ""turning around"" makes it quite difficult; in particular the system clearly has a memory, but the state of that memory does not only depend on the previous step size. So instead, we wrote a program for it (Matlab code): function k = mona(n)

    assert( n >= 1 );    
    h = n;
    k = 2;

    while h >= k
        h = mod(h,k);
        h = n-h;
        k = k+1;
    end

end where n is the number of stairs, k is the step size, and h is the ""horizon"" -- aka the number of stairs remaining until the end of the staircase for a given step size. Plotting it for the first 1000 integers looks like this: I have thought about it for a while, but it is much more complicated to analyse than it seems, and the analytic formulation of the sequence is ugly so I'm not sure it can help. I would be curious to know whether this relates to any known integer process? And if not, whether you have a clever idea of how to analyse the Mona sequence? About the envelope As can be seen on the plot, there seems to be a bounding cone to the progression of this sequence. This ""envelope"" corresponds to the following cases (found programmatically): \begin{align}
N_\mathrm{upper} &= \left\{ n\ |\ M(n)=n+1 \right\} = \{ 1,2,5,8,14,50,119,200,269,299, ... \} \\
N_\mathrm{lower} &= \left\{ n\ |\ M(n)=\left\lceil \frac{n}{2}\right\rceil + 1 \right\} = \{ 1,3,7,39,47,111,959, ... \} 
\end{align} However once again, neither of these sequences give a hit in the OEIS.","['puzzle', 'integers', 'sequences-and-series']"
2145925,"How can I show that $\left|\sin \frac{s}{2}\right| \geq \frac{|s|}{\pi}, s \in [- \pi , \pi]$?","How can I show that $$\left|\sin \frac{s}{2}\right| \geq \frac{|s|}{\pi}$$ $s \in [- \pi , \pi]$, using that $\psi : x \mapsto \sin x$ is a concave function on $[0 , \pi]$? By definition of concave function,
$$
\psi(t \, x + (1 - t) \, y) \geq t \, \psi(x) + (1 - t) \, \psi(y)
$$
for each $x , y \in [0 , \pi]$ and for all $t \in [0 , 1]$. My thought was obtain that using just the definition but I think it is not possible but I am not sure. I have drown that and it's obvious but I want to prove that analytically. Can you help me, please? Thank you very much.","['real-analysis', 'inequality', 'convexity-inequality', 'absolute-value', 'analysis']"
2145977,"Given that $A$ is a projection, $A$ is Hermitian if and only if $AA^\ast A=A$","In this question, $A^\ast$ is the conjugate transpose of $A$. I am asked to show that if $A$ is a projection matrix, that $A$ is Hermitian if and only if $A=AA^\ast A$. One direction is easy--if $A$ is Hermitian, the result is trivial. So what about the converse? The assumption that $A=AA^\ast A$ and that $A$ is a projection gives us some identities:
$$A^2=A,$$
$$A^\ast=A^\ast AA^\ast,$$
$$A=A(A^\ast)^2A,$$
etc.... But I am at a loss. How can I use these to prove the converse: If $A=AA^\ast A$ and $A$ is a projection, then $A$ is Hermitian?",['matrices']
2146024,inverse Laplace transform of a piecewise defined function,"I understand the conditions for the existence of the inverse Laplace transforms are $\lim_{s\to\infty}F(s) = 0$ and $\lim_{s\to\infty}(sF(s))<\infty$. I am interested in finding the inverse Laplace transform of a piecewise defined function defined, such as $$F(s) =\begin{cases} 1-s &\text{ if }0\le s\le1 \text{ and}\\
 0&\text{ if } s>1
\end{cases}$$ 
Clearly the limits above do satisfy the existence of the inverse condition, but I'm not sure how to determine the inverse. I'm not sure whether the Bromwich integral method can be applied, since it would appear that if I choose gamma between 0 and 1 the function to integrate is (1-s), whereas if I choose gamma > 1 then the Bromwich integral is obviously 0. I'm also not sure whether Post's inversion formula can be used since I'm not sure I understand how to evaluate high-order derivatives of a function which is not differentiable at $s = 1$. Clearly for a finite $k$, the $k$th order derivative of $F$ exists for all $s$ except $1$, but how about as $k\to\infty$? Finally, just wondering if the two conditions I listed initially (the two limits) are sufficient for the inverse Laplace transform of $F(s)$ to exist.","['laplace-transform', 'complex-analysis', 'integration', 'calculus']"
2146094,Discrete Math: Seating at a circular table,"- Possible Problem and My thinking: Imagine a circular table, and you want to sit 7 people around it. The total arrangements would be 7!/7 or 6!. So, the order of left or right does not matter because we can sit these people anywhere and in any direction we want. However, If they are denoted A, B, C, D, E, F, G. Then the order matters. Thus it would be 2*(7!/7) or 2*(6!). - Logical Questions: Am I right in my logic? How should I know the order of the left and right matters?","['combinations', 'combinatorics', 'discrete-mathematics']"
2146115,How to prove that $11...111$ is not the sum of two perfect squares,"I'm stuck with this problem: Show that $a=11...111$ is not the sum of two perfect squares. That is to say, there are no pair of  integers ($b$ , $c$) so that $b^2+c^2=a$. I think I am supposed to use equivalence classes in some way, but I do not know how to approach it.","['equivalence-relations', 'relations', 'discrete-mathematics']"
2146136,Expectation of Max and Min of Two Uniform Random Variables,"I'm looking for someone to walk me through how to solve E[ZW] if Z = max[X,Y] & W = min[X,Y]. X & Y are independent, uniform variables over the interval [0,1]. I solved E[Z] = 2/3 and E[W] = 1/3. E[ZW] should equal 1/4 but I keep getting the wrong answer. I have searched the forums and used other people's answers to try and solve it but have gotten the incorrect numbers. Thank you in advance!","['uniform-distribution', 'probability', 'expected-value']"
2146152,How does one show that $\sum_{n=0}^{\infty}\left(-{1\over x}\right)^n\cdot{\Gamma\left({2n+1\over 2}\right)\over n!}=\sqrt{{x\pi\over x+1}}?$,"Consider $(1)$ $$\sum_{n=0}^{\infty}\left(-{1\over x}\right)^n\cdot{\Gamma\left({2n+1\over 2}\right)\over n!}=S\tag1$$
  $x>0$ How does one show that $S=\sqrt{{x\pi\over x+1}}$ An attempt: $$\Gamma\left({1\over 2}+n\right)={(2n-1)!!\sqrt{\pi}\over 2^n}$$ $(1)$ becomes $$\sum_{n=0}^{\infty}\left(-{1\over x}\right)^n\cdot{(2n-1)!!\over 2^n}\cdot{1\over n!}=\sqrt{x\over x+1}\tag2$$ further to $$\sum_{n=0}^{\infty}\left(-{1\over x}\right)^n\cdot{1\over 2^n(2n-2)!!}=\sqrt{x\over x+1}\tag3$$","['factorial', 'sequences-and-series', 'gamma-function']"
2146194,Is the link between Stern's diatomic sequence and binary subsequences genuine or a coincidence with exceptions?,"In a sister stack, Martin Ender raised a question about the following function: Let's define a function $f(N)$ on the integers via the following algorithm. We'll use $N = 38$ as an example: Get the binary representation of $N$: $[1,0,0,1,1,0]$. Take all subsequences of this list. These don't need to be contiguous, so $[1,1,1]$ is a valid subsequence, for example. Don't forget to include the empty subsequence: $$\{[], [1], [0], [0], [1], [1], [0], [1,0], ..., [1,0,1,1], \ldots, [1,0,0,1,1,0]\}$$ Convert each subsequence back to an integer by treating it as a list of bits. $[]$ should become zero: $$\{0, 1, 0, 0, 1, 1, 0, 2, \ldots, 11, \ldots, 38\}$$ Count how many distinct values you get. The distinct values in this case are: $$\{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 18, 19, 22, 38\}$$ That's $17$. This is $f(N)$. ... This sequence appears to be identical to A007306 , except that the index is off-by-one (A007306 starts with an additional 1) Is it genuinely the case that $f(N) = \textrm{A007306}(N+1)$, or is that just a coincidence which holds for a lot of numbers but has exceptions?","['combinatorics', 'binary', 'sequences-and-series', 'farey-sequences']"
2146231,Where is the mistake in this solution of $\lim_{x \to 1}{\frac{1-x^2}{\sin (\pi x)}}$?,"I'm trying to solve this limit: $$\lim_{x \to 1}{\frac{1-x^2}{\sin (\pi x)}}$$ The answer ought to be $\frac{2}{\pi}$, but I end up with $0$: $\lim\limits_{x \to 1}{\frac{1-x^2}{\sin (\pi x)}} = $
$\lim\limits_{y \to 0}{\frac{1-(y+1)^2}{\sin (\pi (y+1))}} = $
$\lim\limits_{y \to 0}{\frac{\pi(y+1)}{\sin (\pi (y+1))} \frac{1-(y+1)^2}{\pi(y+1)}} = $
$\lim\limits_{y \to 0}{\frac{1-(y+1)^2}{\pi(y+1)}} =  0$ Where and why is my solution incorrect? Note: I'm aware of this post , however I believe mine is different because I'm asking where and why my solution went wrong, not why my answer was wrong.","['limits', 'trigonometry', 'proof-verification', 'calculus', 'limits-without-lhopital']"
2146252,Defined integral of $x^{\alpha} (1-x)^{\beta-1}$,"How can one prove the following equality? $$\int_{0}^{1} x^{\alpha} (1-x)^{\beta-1} \,dx = \frac{\Gamma(\alpha+1) \Gamma(\beta)}{\Gamma(\alpha + \beta + 1)}$$","['integration', 'definite-integrals']"
2146349,An Alternate Solution to a Differential Equation,"The main question being asked: is it possible an $f(x)$ which satisfies the below equation where $u=u(x)$ ;if so, how? $$\boxed{ \frac{df(u^2)}{d(u^2)} = \left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2} \quad ,u = u(x)\qquad(*)}$$ or similarly after using the transformation in the Remarks section: $$\boxed{\frac{df(u^2)}{du} = 2u\left[\left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2}\right] \quad ,u = u(x) \qquad (**)}$$ Part 1 : This stems from the initial question assigned to me which was: Find an $f(x)$ which satisfies: $$ f'(\sin^2x) = \cos^2x + \tan^2x, \quad 0<x<1$$ ( I have left this part in 'prime' notation because this is how the original question was presented. ) The proper solution involves the following method: $$ f'(\sin^2x) = (1-\sin^2x) + \frac{\sin^2 x}{1-\sin^2 x}$$ Let $u = \sin^2x$ , then: $$ f'(u) = (1 - u) + \frac{u}{1-u}$$ $$ f(u) = \int\,\left[(1 - u) + \frac{u}{1-u} \right] du$$ $$ f(u) = \int\,\left[(1 - u) + \frac{u-1+1}{1-u} \right] du$$ $$  = \int\,\left[-u + \frac{1}{1-u} \right] du$$ $$ \therefore f(x) = -\frac{1}{2}u^2-\ln|1-u|=-\frac{1}{2}x^2-\ln|1-x|$$ Part 2: My question is if this can  be solved with the following alternate method: $$ \frac{d(f(\sin^2x))}{d(\sin^2x)} = \cos^2x + \tan^2x, \quad 0<x<1$$ then, $$\frac{d(f(\sin^2x))}{d(\sin^2x)} = \cos^2x + \frac{\sin^2x}{\cos^2x}$$ Let $u = \sin x$ , $du = \cos x\,dx$ then: $$ \frac{d(f(u^2))}{d(u^2)} = \left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2} \qquad$$ Can this equation be solved to find an $f(x)$ which satisfies this relation regardless of what $u(x)$ actually is? See Main Edit 1&2 for clarification on why it is in this form The following steps are INCORRECT, as this is not how the chain rule works. But there is something in my head grinding such that I feel that it can be solved in a way invoking the chain rule but I can't get my thoughts wrapped around it properly. ( I have left this part in 'prime' notation because this displays my erroneous thought process of misunderstanding differentials which probably led me to the wrong answer. ) $$ 2u\, f'(u) = \left(u'\right)^2 +\frac{u^2}{\left(u'\right)^2}$$ Clearly $ f'(u^2) \ne 2u\, f'(u)$ , however continuing with this incorrect thought.. $$ f'(u) = \frac{1}{2} \left[\frac{\left(u'\right)^2}{u}+\frac{u}{u'}\right]$$ $$ f(u) = \int\frac{1}{2} \left[\frac{\left(u'\right)^2}{u}+\frac{u}{u'}\right] $$ Is there anyway I can actually correctly use the chain rule starting from $(*)$ to reach this point and then integrate, or solve it through some method for differential equations? I've never experienced a question with the square of a derivative so I was wondering if someone could give me insight on this. Main Edit 1: As @JJacquelin noted, the notation with 'prime' causes quite problem with what the question being asked is: Using the fact that $u = \sin x\,\, \text{is a function of}\, x$ The line: $$ f'(u^2) = \left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2} \qquad$$ can be written as such: $$ \frac{df(u^2)}{d(u^2)} = \left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2} \quad ,u = u(x) \qquad(*)$$ And as so, I have replaced all appropriate parts of this post with Leibniz notation to suggest clarity. Now can I find an $f(x)$ which satisfies this equation? I have left my previous work as is, so that I may reference it one day in case I come across a problem of pinpointing what my prime notation means. Please do let me know if there are any further clarifications that need to be made before this can be solved properly. Edit 2: Proof of why [ incorrectly ] believed it is $\frac{d}{dx}$ : Thank you to @JJacquelin once again for helping me clarify the differentials in the question. I have edited the general question with reflection to their analysis, and hope to recieve the answer I was looking for now that the notion of differentials is cleared up. I was incorrect in my reasoning before and it is actually $\frac{df(X)}{dX}$ for any dummy variable $X$ , contrary to what I had thought as you can see below.: If we start from the solution of Part 1: $$f(x) = -\frac{1}{2}x^2-\ln|1-x|$$ $$\frac{df(x)}{dx} = -x+\frac{1}{1-x}$$ $$\frac{df(x)}{dx} = -x+\frac{1-x+x}{1-x}$$ $$\frac{df(x)}{dx} = -x+\frac{1-x}{1-x}+\frac{x}{1-x}$$ $$\frac{df(x)}{dx} = -x + 1 + \frac{x}{1-x}$$ $$\frac{df(x)}{dx} = 1 - x +\frac{x}{1-x}$$ Now $x \mapsto \sin^2x$ : $$\frac{df(\sin^2x)}{dx} = 1 -\sin^2x+\frac{\sin^2x}{1-\sin^2x}$$ $$\frac{df(\sin^2x)}{dx} = \cos^2x + \tan^2x$$ But this turns out to be wrong, when $x\mapsto \sin^2 x$ it becomes : $$\frac{df(\sin^2x)}{d(\sin^2x)} = \cos^2x + \tan^2x$$ $$f'(\sin^2x)=\cos^2x + \tan^2x$$ Which is what we started with. Now I am beginning to doubt my self, because I am not sure if the $dx$ changes to $d(\sin^2x)$ when $x\mapsto\sin^2x$ . I would appreciate it if someone could help me realize which one it is, because then I can't begin to even grasp the main question without formulating the correct statement. Thank you for @JJacquelin clearing this up . Remarks :
On another note, I looked back to some of my differential work from university and came across a homework problem we proved which shows that: $$\frac{d^2x}{dy^2}= -\frac{\frac{d^2y}{dx^2}}{\left(\frac{dy}{dx}\right)^3}$$ Which leads me to wonder, can the terms $\left(\frac{du}{dx}\right)^2$ be transformed into some $n$ -th derivative? More generally, are there possible transformations to convert powers of derivatives to $n$ -th derivatives in order to simplify this problem into a differential equation which can be solved using usual methods? Also something @JJacquelin helped me realize about use of the chain rule, which may be of some help to progress: $$\frac{df(u^2)}{d(u^2)}= \frac{df(u^2)}{2udu}$$ which may simplify the original question to: $$\frac{df(u^2)}{du} = 2u\left[\left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2}\right] \quad ,u = u(x) \qquad (**)$$ These two identities might be of some help...possibly.","['derivatives', 'integration', 'ordinary-differential-equations', 'calculus']"
2146376,"How many ways can 4 French, 2 Spanish, and 3 German books be arranged on a shelf if the French and German books are together?","We have 4 French, 2 Spanish and 3 German books. The French and German books have to be together. All the books are unique, they came from the same country but have different volume numbers. I combined the 3 German and 4 French and got $7!$, and then I added the 2 Spanish books. Since they are unique, lets assume C = the combined books.
I have SSC x2, SCS x2, CSS x2, so I have 6 ways of arranging them. I then did $7! \cdot 6$ Is this the right way of doing the problem or am I missing a few things?","['permutations', 'combinatorics']"
2146415,Function reflection question,"So I wrote an exam the other day for pre-calculus grade 12 and this was one of the questions ... Given f(x) = |x| + 1, determine the equation of the tranformation function when f(x) is reflected in the x-axis. So from my understanding, I expressed the transformation function in terms of g(x) where g(x) = -f(x) = -|x| - 1. However, my teacher said that ""the transformation fucntion should be g(x) = -|x| + 1 because y = |x| is the base function in f(x)."" Moreover, he did not help me to understand this any further, what am I misunderstanding?","['algebra-precalculus', 'reflection', 'functions']"
2146450,"Show if $p > 3$ is prime, then $(p + 1) | p!$","I know I must show that p! $\equiv$ 0 mod p + 1. I am attempting to use Wilson's theorem. 
p! $\equiv$ p(p - 1)! $\equiv$ p $\cdot$ - 1 mod p. Since p $\equiv$ 0 mod p, then p! $\equiv$ 0 mod p...but this is obvious since p divides p. So this argument seems to be a dead end. I tried the following: 
p must be odd since p is a prime larger than 3. Thus, p + 1 is even. Since p + 1 is even it must be the product of 2 and an integer n such that n < p + 1. Now, p! = p(p - 1) $\cdot\cdot\cdot$ n $\cdot\cdot\cdot$ 2 $\cdot$ 1. Thus p + 1 = 2n | p! Is this a rigorous enough argument?","['number-theory', 'congruences', 'prime-numbers', 'divisibility']"
2146508,Prove that $Gal(K/k) \cong \hat{\mathbb{Z}}$,"Let $K$ be the algebraic closure of a finite field $k$. Prove that $Gal(K/k) \cong \hat{\mathbb{Z}}$. From the definition in the book, here is how $\hat{\mathbb{Z}}$ is defined:
Let $D = Cr(\mathbb{Z}_{p} | \; p \; prime)$, let $\delta: \mathbb{Z} \rightarrow D$ be the map taking $x \in \mathbb{Z}$ to the vector with all coordinates equal to $x$. Then the group $D$ together with the map $\delta$ is the profinite completion of $\mathbb{Z}$, denoted $\hat{\mathbb{Z}}$. There seem to be many sources online that cite this result as true, but I'm having trouble finding anywhere that shows a proof. This question is from Profinite Groups (Wilson), so I doubt that the solution is all that straight-forward. Could anyone offer me a solution or perhaps some insight on how to tackle this problem?","['abstract-algebra', 'galois-theory', 'profinite-groups', 'group-theory']"
2146511,Affine tangent cone and the associated graded ring,"My question arises from a brief remark about the affine tangent cone in 
Chapter 5 of Commutative Algebra: with a View Toward Algebraic Geometry by Eisenbud.
To paraphrase, if $X$ is an affine variety, set $A(X) = A/I$ to be its coordinate ring and $I$ its defining ideal. Recall that the tangent cone at $p$, denoted by $TC_p(X)$ is an algebraic set that is given by the zero set of the initial ideal, $Z(\text{in}(I))$, where $\text{in}(I) = ( \text{in}(f) \, | \, f \in I)$, and $\text{in}(f)$ is the first non-zero homogeneous component of $f$. Geometrically, this is the cone composed of limiting positions of secants to $X$ passing through $p$. Now if $m_p$ is the maximal ideal in $A(X)$ corresponding to the point $p$, Eisenbud's claim is that $$\text{gr}_{m_p} A(X) = \bigoplus_{i=0}^{\infty} m_p^i / m_p^{i+1}$$ is isomorphic to the coordinate ring of the tangent cone at $p$. It is clear to me that $\text{gr}_{m_p} A(X)$ is a finitely generated $k$-algebra, and if $a_i$ are the generators of $m_p$, then $\xi_i = a_i \text{ mod } m_p^2$ generate $\text{gr}_{m_p} A(X)$. However I'm struggling to show that the kernel of this (homogeneous of degree zero) homomorphism, which sends $a_i$ to $\xi_i$ is given by $\text{in}(I)$.","['algebraic-geometry', 'commutative-algebra']"
2146516,Solve for $k$ such that $f$ is a real valued continuous function,"Find a non-zero value for the constant $k$ such that $f$ defined as below is continuous at $x = 0$. $$f(x) = 
\begin{cases}
\frac{\tan(kx)}{x}, \hspace{0.3cm}x< 0
\\
3x + 2k^2, \hspace{0.3cm}x\geq0
\end{cases}$$ My attempt: $$\lim_{x\rightarrow0^{-}}\frac{\tan(kx)}{ x} = \lim_{x \rightarrow 0^{-}} \frac{\sin(kx)}{ x\cos(kx)} = \lim_{x \rightarrow 0^{-}} \frac{k\sin(kx)}{(kx)}\frac{1}{\cos(kx)} = k\lim_{x \rightarrow 0^{-}} \frac{1}{\cos(kx)}  = k$$ $$\lim_{x \rightarrow 0^{+}}3x+2k^2 = 2k^2$$ For continuity we must have that the limit on the right must be equal to the limit on the left, i.e, $k = 2k^2$, so $$k(2k-1) = 0$$ Therefore, a non-zero value for constant $k$ such that $f$ is continuous on $x=0$ is $k = 1/2$. I am not fully confident in my solution. Could someone tell me if i went down the right path and why? Or maybe tell me I am entirely wrong and lend a hand?","['continuity', 'calculus', 'limits']"
2146598,"Is the sequence of functions $f_n=\chi_{[n,n+1]}$ uniformly integrable?","I wish to prove or disprove that the sequence of functions $f_n=\chi_{[n,n+1]}$ is uniformly integrable? At a glance my judgement is YES, it is uniformly integrable. From the definition of Uniform integrability, that's A sequence ${f_n}$ is called uniformly integrable if $\forall \epsilon >0 \exists \delta > 0 $ such that if $E \subset X$, $E$ measurable and  $\mu (E)< \delta $ then $\forall n$ $\int_E |f_n| d\mu < \epsilon$. So I let $E \subset R$ such that $\mu (E)<\delta$
then $\int_E|f_n|=\int|f_n|\chi_E \leq \mu (E)<\delta$. So in this case $\epsilon =\delta$. Does this make sense?","['real-analysis', 'uniform-integrability', 'lebesgue-measure', 'lebesgue-integral', 'measure-theory']"
2146606,Homeomorphism for computing homology/cohomology of unit tangent bundle,"I'm trying to (eventually) calculate the homology and cohomology of the space $T =\{(v,w)\in S^n \times S^n \mid v \perp w \},$ which is the unit tangent bundle, or sometimes called the Stiefel 2-manifold $V_2(\mathbb{R}^{n+1}).$ There are several ways to approach this: using a Gysin sequence ( The circle bundle of $S^2$ and real projective space ) or determining the cell structure of $T$ based on the cell structure of $SO(n)$ , as done in Hatcher: However, I am looking for an alternate way to solve this problem; in particular, the original hint I was given was to define $S_+ = \{(v,w) \in T \mid v_{n+1} \ge 0 \}$ and $S_- = \{(v,w) \in T \mid v_{n+1} \le 0 \}$ ,
where $v_{n+1}$ is the last coordinate of $v$ in $(v,w)$ . Then I am supposed to prove that $$S_{+} \approx S_{\text{north}}^+ \times S^{n-1}$$ where $S_{\text{north}}^+ = \{v \in S^n \mid v_{n+1} \ge 0 \}$ . However, doing so has been driving me absolutely crazy . When examining the fiber bundle $p:T \rightarrow S^n$ s.t. $p(x,w) = x$ , I know we have the local trivializations $$h_x: p^{-1}(U_x) \rightarrow U_x \times p^{-1}(x) \approx U_x \times S^{n-1}$$ where $U_x$ is the open hemisphere of $S^n$ that contains $x$ and is bounded by the tangent ""plane"" $P_x$ to $S^n$ at $x$ translated to intersect the origin of $R^{n+1}.$ In particular, $h_x(v,w) = (v, \pi_x(w))$ where $\pi_x$ is the projection onto $P_x$ . This almost seems to work since local trivializations are isomorphisms. So by picking $x$ to be $e_1$ , $P_x$ is the subspace $\{(v_1,...,v_n,0) \in \mathbb{R}^{n+1}\}$ and so $U_x$ is $\{v \in S^n \mid v_{n+1} > 0 \}$ , which is close to $S_{\text{north}}^+$ but doesn't allow $v_{n+1} = 0$ . Similarly, $p^{-1}(U_x) = \{(v,w) \in T \mid v_{n+1} > 0\}$ which is almost $S_+$ except for it excludes the case $v_{n+1} = 0$ . Trying to just add on these points doesn't work since $h_x$ is not injective when $v_{n+1} = 0$ (or involves the projection of a vector being zero). How could I show $S_{+} \approx S_{\text{north}}^+ \times S^{n-1}$ ? I don't even feel that this statement is true. UPDATE: (2/23) With help from the answer provided & comments, here is what I have (using the idea that a fiber bundle with contractible base is trivial). Method (1): Define $U_+ = S^n \setminus \{-e_1\}$ and $U_- = S^n \setminus \{e_1\}$ so that $S^n = U_+ \cup U_-$ with $U_+, U_-$ open and contractible. Let $\tilde{T} = \{(v,w) \in U_+ \times S^n \mid v \cdot w = 0\},$ meaning (given the definitions in the problem statement) that $$ S_+ \subseteq \tilde{T} \subseteq T.$$ Let $p: \tilde{T} \rightarrow U_+$ be a fiber bundle. (We know at least one such fiber bundle exists since there is the trivial bundle sending $(v,w) \mapsto v$ ). Since $U_+$ is contractible , this fiber bundle is trivial; that is, $\tilde{T} \approx U_+ \times F$ where $F$ is the fiber. Specifically, for $v$ fixed $$F = p^{-1}(v) = \{(v,w) \mid v\cdot w = 0\} \approx \{v\} \times S^{n-1} \approx S^{n-1}.$$ So $\tilde{T} \cong U_+ \times S^{n-1}.$ Since restrictions of homeomorphisms are still homeomorphisms, we can restrict this homeomorphism to the closed subspace $S_{\text{north}}^+$ of $U_+$ , so $$ S_{\text{north}}^+ \times S^{n-1} \approx \{(v,w) \in S_{\text{north}}^+ \times S^n \mid v \cdot w = 0\} = \{(v,w) \in S^n \times S^n \mid v \cdot w = 0, v_{n+1} \ge 0\} = S_+$$ by definition of hemisphere $S_{\text{north}}^+$ Thus, we have shown that $S_{+} \approxeq S_{\text{north}}^+ \times S^{n-1}.$ Is this argument correct? Is there some technical point I am missing? Method (2): (This uses the stereographic projection suggestion.) Let $p: S(S^n \setminus \{x\}) \rightarrow S^n \setminus \{x\}$ be the unit sphere bundle of $S^n \setminus \{x\}$ . Using the diffeomorphism $\Pi_x: S^n \setminus \{x\} \rightarrow \mathbb{R}^n$ , we then have $$S(S^n \setminus \{x\}) \overset{p}\rightarrow S^n \setminus \{x\} \overset{\Pi_x}\rightarrow \mathbb{R}^n$$ is also a fiber bundle since $\Pi_x$ is a diffeomorphism. Since $\mathbb{R}^n$ is contractile, the bundle is trivial. Thus, $S(S^n \setminus \{x\}) \approx \mathbb{R}^n \times F$ where $F$ is $p^{-1}(\Pi_x^{-1}(v)) = S^{n-1}$ for any $v \in \mathbb{R}^n.$ So $$S(S^n \setminus \{x\}) \approx \mathbb{R}^n \times S^{n-1}$$ and by restricting $S^n \setminus \{x\}$ to its closed subspace $S_{\text{north}}^+$ (choosing $x \not \in S_{\text{north}}^+$ ), we have the homeomorphism $$S(S^+) \approx  S_{\text{north}}^+ \times S^{n-1}.$$ However, $S(S^+) = S_+$ ( right? ) so $S_+ \approx S_{\text{north}}^+ \times S^{n-1}.$ Are there any technical points or general ideas that are wrong here? Thank you.","['algebraic-topology', 'general-topology', 'homology-cohomology']"
2146621,"Does the ""2nd isomorphism theorem"" hold for Banach spaces, when one of the subspaces is finite-dimensional?","Let $X$ be a Banach space. Let $Y, F \subseteq X$ be subspaces with $Y$ closed and $F$ finite-dimensional. It follows that $F + Y$ is also a closed subspace of $X$. Question: Is there an isometric isomorphism of finite-dimensional Banach spaces between $\frac{F+Y}{Y}$ and $\frac{F}{F \cap Y}$?","['functional-analysis', 'banach-spaces']"
2146693,"Correlation($U,V$)=Correlation($X,Y$) [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $X$ and $Y$ be random variables such that $0<\sigma^2_X<\infty$ and $0<\sigma^2_Y<\infty$. Suppose that $U=aX+b$ and $V=cY+d$, where $a \not= 0$ and $c \not= 0$. Show that $\rho(U,V)=\rho(X,Y)$ if $ac>0$, and $\rho(U,V)=-\rho(X,Y)$ if $ac<0$.","['statistics', 'correlation']"
2146766,Irreducible component of a product of varieties.,"If $X,Y$ and $S$ are varieties (over an algebraically closed field) and $X\to S$ and $Y\to S$ are maps with geometrically irreducible generic fibres; why it is true that there is a unique irreducible component of $X\times_{S}Y$ dominating over $S$?",['algebraic-geometry']
2146830,Relation between Ramanujan Theta Function and Jacobi Theta Function,"In the theory of $q-$series,
we have Ramanujan Theta function
\begin{align}\label{rama-theta}
        f(a,b):=\sum_{n=-\infty}^{\infty}
        a^{\frac{n(n+1)}{2}}b^{\frac{n(n-1)}{2}}
        ,\qquad |ab|<1.
\end{align}
And we also have Jacobi Theta function in complex analysis defined by
\begin{align}
          \Theta(z|\tau)=
          \sum_{n=-\infty}^{\infty}e^{\pi i n^2 \tau}e^{2\pi i n z}.
\end{align}
We can also write it as
\begin{align}
          \Theta(z|\tau)=
          \sum_{n=-\infty}^{\infty}q^{n^2}\eta^n,
        \end{align}
where $\eta=e^{2\pi i z}$ and $q=e^{2\pi i \tau}.$ In wiki, https://en.wikipedia.org/wiki/Ramanujan_theta_function ,
he says ""â¦â¦ the Ramanujan theta function generalizes the form of the Jacobi theta functionsâ¦â¦"". I cannot understand why it can be regarded as a generalization.
In my opinionï¼
Jacobi triple product have the following two expression
\begin{align}
\Theta(z|\tau)=\prod_{m=1}^{\infty}(1-e^{2\pi m i\tau})\left[1+e^{(2m-1)\pi i \tau+2\pi i z}\right]\left[1+e^{(2m-1)\pi i \tau-2\pi i z}\right].
\end{align}
But in the notation of Ramanujan,
we have
\begin{align}
          f(a,b)=(-a;ab)_\infty(-b;ab)(ab;ab)_\infty.
\end{align}
This is more beautiful. However,
I still don't know what's the relation between the two kinds of ""Theta function"".
Anybody can help me?","['number-theory', 'q-series', 'complex-analysis', 'modular-forms', 'combinatorics']"
2146845,Understanding graph automorphism as opposed to isomorphism.,"Consider the simple path graph, $P$ over vertices labeled from $1$ to $n$. If all path graphs over $n$ vertices are isomorphic to $P$ (I can relabel the vertices in $n!$ ways and still have the same graph.), then why does $P$ have only 2 automorphisms? Edit: Is the explanation related the fact that there is only one vertex set to map vertices from?","['combinatorics', 'graph-theory', 'graph-isomorphism']"
2146865,How does one show that $\lim_{n\to \infty}{n\over \sqrt{2k}}\cdot\sqrt{1-\cos^k\left({2\pi\over n}\right)}=\pi$?,Consider $$\lim_{n\to \infty}{n\over \sqrt{2k}}\cdot\sqrt{1-\cos^k\left({2\pi\over n}\right)}=L\tag1$$ How does one show that $L=\pi$ for $k>0$ ? An attempt: For $k=2$ $$\lim_{n\to \infty}{n\over 2}\cdot\sqrt{1-\cos^2\left({2\pi\over n}\right)}=L\tag2$$ $$\lim_{n\to \infty}{n\over 2}\cdot\sin\left({2\pi\over n}\right)=L\tag3$$ $$\lim_{n\to \infty}\pi\cdot{\sin\left({2\pi\over n}\right)\over {2\pi\over n}}=L\tag4$$ $$L=\pi\tag5$$,"['trigonometry', 'limits']"
2146886,Convergence in Probability where Yn= the max of n independent exponentially distributed rv's,"Let $X_1, X_2, \cdots$ be independent random variables, each with exponential distribution
with parameter $\lambda = 1$. For any $n â¥ 1$, let $Y_n := \max(X_1,\cdots, X_n)$. Let $0 < a < 1 < b$.
Show that $P(Y_n â¤ a \log n) \to 0$ as $n \to \infty$, and $P(Y_n â¤ b \log n) \to 1$ as $n \to \infty$. Conclude
that $Y_n/ \log n$ converges to $1$ in probability as $n\to \infty$. I have no idea how to approach this problem. I know the formula for convergence in probability, but this seems foreign to me.","['exponential-distribution', 'probability', 'convergence-divergence', 'limits']"
2146901,"20 circles in the plane, all passing through the origin","Suppose I draw $20$ circles in the plane, all passing through the origin, but no two tangent at the origin. Also, except for the origin, no three circles pass through a common point. How many regions are created in the plane?",['geometry']
2146909,Derivative of $e^y=x^{\ln x}$?,"How to obtain $y'$ from $e^{y}=x^{\ln x}$? This is what I did:
$$\ln e^y = \ln x^{\ln x}$$
$$y = \ln ^2 x$$
$$y' = \frac{2 \ln x}{x}$$
Is this correct? When I compare it with an online derivative calculator, the result they gave was different, and they used implicit differentiation instead.","['derivatives', 'implicit-differentiation']"
2146914,Find the number of merry-go-rounds formed by 10 carriages of two different colors,"Find the number of merry-go-rounds formed by 10 carriages of two different colors i tried this problem with 4 carriages: let the colors be {0,1} so with 2 colors and 4 carraiges the cofiguration is: 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0010, 0010, 0100, 1000 are the same so there is 0000, 0010, 0011, 0101, 0111, and 1111 so there is total 6 possible ways to color a 4 carriage merry go round with two colors is 6 what if there are m carriges and n colors, how to approach the problem?
and what is the general formula for it?","['permutations', 'combinatorics', 'discrete-mathematics']"
2146936,To what function does this series converge?,"I have the following series expansion
$$f(x) = \sum_{n=1}^\infty a_n x^{b_n},$$
where $a=\{a_n\}_{n=1}^\infty$ is such that $\sum_{n=1}^\infty |a_n| < \infty$ and $b=\{b_n\}_{n=1}^\infty$ such that $b_n\in (0,1/2)$ for all $n\geq 1$ and $\lim_n b_n = 0$. Can I find a choice of $a$ and $b$ such that I have a closed form for $f$? For example: $$f(x) = \sum_{n=1}^\infty \frac{(-1)^n}{n!} x^{1/n}, \mbox{ or } f(x) = \sum_{n=1}^\infty \frac{1}{n!} x^{1/n}$$
remind of the exponential but not quite. Any ideas? Thank you for your support!","['real-analysis', 'sequences-and-series', 'calculus', 'functions', 'convergence-divergence']"
2146974,Infinite torsion group with finitely many conjugacy classes,Do there exist infinite torsion groups with finitely many conjugacy classes? One can easily see that there are no such groups with only two conjugacy classes. Note also that one can construct torsion-free groups with finitely many conjugacy classes via HNN extensions.,['group-theory']
2147010,Do bounded linear operators on a Banach space which are injective or have dense range form an open subspace?,"We proved a theorem in our functional analysis class showing that the subspace of bijective bounded linear operators between two Banach spaces $X$ and $Y$ is open in the space $B(X,Y)$ of bounded linear operators. It was mentioned that the subspace of $(i)$ injective operators and $(ii)$ operators with dense range, however, are not open in $B(X,Y)$. I tried coming up with counterexamples, but was not able to do so. Admittedly, I tried in finite dimension, and maybe the counterexamples come from infinite dimension? I'd like to see counterexamples to each of these cases. I'd appreciate some help in this, thanks.",['functional-analysis']
2147037,How can I evaluate the following integral? $\int(\sqrt{x}-x)(e^{\arctan\sqrt{x}})^2dx$,"How can I evaluate the following integral? $$\int(\sqrt{x}-x)(e^{\arctan\sqrt{x}})^2dx$$ I'd like the whole solution if possible. I tried using the substitution: $\sqrt{x}=t$, followed by: $2\arctan{t}=m$, to get:
$$\int e^m\tan^2{\frac{m}{2}}\sec^2{\frac{m}{2}}\left[1-\tan{\frac{m}{2}}\right]dm$$ But it doesn't get me anywhere. A complete solution will be sincerely appreciated.","['indefinite-integrals', 'integration', 'calculus']"
2147133,How many elements with rank $r$ in the space $\mathbb{M}_n(\mathbb{F}_p)$?,"Let $\mathbb{F}_p$ be a field with $p$ elements and $\mathbb{M}_n(\mathbb{F}_p)$ is the set of all $n \times n$ matrices over the field $\mathbb{F}_p$ . Now, we know that $|\mathbb{M}_n(\mathbb{F}_p)| = p^{n^2}$ . The number of matrix with rank $0$ is $1$ , namely the null matrix of order $n$ . Number of matrices with rank $n$ is $$\prod_{i=0}^{n-1} (p^n-p^i),$$ namley $GL(n, \mathbb{F}_p)$ . How many elements with rank $r~ (0 \leq r \leq n)$ in $\mathbb{M}_n(\mathbb{F}_p)$ ? Note: If we denote the number of elements with rank $i~ (0 \leq i \leq n)$ is $R_i$ in $\mathbb{M}_n(\mathbb{F}_p)$ then $$\sum_{i=0}^{n} R_i= p^{n^2}.$$","['abstract-algebra', 'coding-theory', 'linear-algebra']"
2147146,"Does there exist a continuous f ,integration of $\int_{0}^{1} x^n f(x)= 1$ for all $n$","Does there exist  a continuous function $f: [0,1]\to[0, \infty )$ such that $$\int_{0}^{1} x^n f(x)= 1$$ for all $n$. Here is what I tried. As $f$ is a continuous function on the compact set $[0,1]$ , there exists $m,M \in \mathbb{R}$, $m \leq f(x) \leq M$. Now applying integration to both side we have $\frac{m}{n+1} \leq 1 \leq \frac{M}{n+1}$ i.e. $m \leq n+1 \leq M$ for all $n\geq 1$. This contradicts the fact that the set $\mathbb{N}$ is unbounded. It would be great help if you would verify my solution. If the solution is wrong a hint will be greatly appreciated.","['continuity', 'real-analysis', 'integration', 'proof-verification']"
2147193,Prove that :$\tan 70 - \tan 20 = 2\tan 40 + 4\tan 10$ [duplicate],"This question already has answers here : On the proof $\tan 70Â°-\tan 20Â° -2 \tan 40Â°=4\tan 10Â°$ (6 answers) Closed 7 years ago . Prove that :$\tan 70 - \tan 20 = 2\tan 40 + 4\tan 10$
My Attempt, 
$$70-20=40+10$$
$$\tan (70-20)=\tan (40+10)$$
$$\dfrac {\tan 70 - \tan 20}{1+\tan 70. \tan 20 }=\dfrac 
{\tan 40 + \tan 10 }{1-\tan 40. \tan 10 }$$ How should I move on?  Please help Thanks",['trigonometry']
2147211,Why are the eigenvalues of a covariance matrix equal to the variance of its eigenvectors?,"This assertion came up in a Deep Learning course I am taking. I understand intuitively that the eigenvector with the largest eigenvalue will be the direction in which the most variance occurs. I understand why we use the covariance matrix's eigenvectors for Principal Component Analysis. However, I do not get why the eigenvectors' variance are equal to their respective eigenvalues. I would prefer a formal proof, but an intuitive explanation may be acceptable. (Note: this is not a duplicate of this question. )","['eigenvalues-eigenvectors', 'variance', 'covariance', 'machine-learning', 'linear-algebra']"
2147262,Minimal set of generators for an algebraic variety (with Macaulay2),"First I describe my problem (note that I am not so familiar with algebraic geometry). I have the following family $\mathcal{F}$ of $19$ polynomials in the ring $\mathbb{C}[x_1,\dots,x_{10}]$, with complex parameters $p_1,p_2,p_3,p_4,p_\infty$: C1 = -4 + p1^2 + p2^2 + p3^2 - p1*p2*x1 + x1^2 - p1*p3*x2 + x2^2 - p2*p3*x3 + x1*x2*x3 + x3^2 + p1*p2*p3*x7 - p3*x1*x7 - p2*x2*x7 - p1*x3*x7 + x7^2;
C2 = -4 + p2^2 + p3^2 + p4^2 - p2*p3*x3 + x3^2 - p2*p4*x5 + x5^2 - p3*p4*x6 + x3*x5*x6 + x6^2 + p2*p3*p4*x8 - p4*x3*x8 - p3*x5*x8 - p2*x6*x8 + x8^2;
C3 = -4 + p1^2 + p3^2 + p4^2 - p1*p3*x2 + x2^2 - p1*p4*x4 + x4^2 - p3*p4*x6 + x2*x4*x6 + x6^2 + p1*p3*p4*x9 - p4*x2*x9 - p3*x4*x9 - p1*x6*x9 + x9^2;
C4 = -4 + p1^2 + p2^2 + p4^2 - p1*p2*x1 + x1^2 + p1*p2*p4*x10 - p4*x1*x10 + x10^2 - p1*p4*x4 - p2*x10*x4 + x4^2 - p2*p4*x5 - p1*x10*x5 + x1*x4*x5 + x5^2;
C6 = -4 + p1^2 + x1^2 - p2*(-p2 + p1*x1) + x6^2 - p1*x6*x9 + x9^2 + x1*x9*x8 - x1*x6*pinf - p2*x9*pinf + pinf^2 + (p2*x6 - x8)*(-x8 + p1*pinf);
C7 = -4 + x1^2 + p3^2 - x1*p3*x7 + x7^2 + p4^2 - x1*p4*x10 + x10^2 - p3*p4*x6 + x7*x10*x6 + x6^2 + x1*p3*p4*pinf - x7*p4*pinf - p3*x10*pinf - x1*x6*pinf + pinf^2;
C8 = -4 + p2^2 + p3^2 - p2*p3*x3 + x3^2 + x4^2 - p2*x4*x10 + x10^2 - p3*x4*x9 + x3*x10*x9 + x9^2 + p2*p3*x4*pinf - x3*x4*pinf - p3*x10*pinf - p2*x9*pinf + pinf^2;
C9 = -4 + p1^2 + x3^2 - p1*x3*x7 + x7^2 + p4^2 - p1*p4*x4 + x4^2 - x3*p4*x8 + x7*x4*x8 + x8^2 + p1*x3*p4*pinf - x7*p4*pinf - x3*x4*pinf - p1*x8*pinf + pinf^2;
R1 = p1*p2*p3*p4 - x1*p3*p4 - p1*x3*p4 + x7*p4 - p2*p3*x4 + x3*x4 - x2*x5 + p3*x10 - p1*p2*x6 + x1*x6 + p2*x9 + p1*x8 - 2*pinf;
R2 = -(p1*p2*p4) + x1*p4 + p2*x4 + p1*x5 - 2*x10 + p1*x3*x6 - x7*x6 - x3*x9 - p1*p3*x8 + x2*x8 + p3*pinf;
R3 = -(p1*p4) + 2*x4 + x1*x5 - p2*x10 + x2*x6 + x1*x3*x6 - p2*x7*x6 - p3*x9 - x1*p3*x8 + x7*x8 + p2*p3*pinf - x3*pinf;
R4 = -(p1*p2*p3) + x1*p3 + p2*x2 + p1*x3 - 2*x7 + p2*x4*x6 - x10*x6 - p2*p4*x9 + x5*x9 - x4*x8 + p4*pinf;
R5 = -(p1*p2) + 2*x1 + x2*x3 - p3*x7 + x4*x5 - p4*x10 + x3*x4*x6 - x3*p4*x9 - p3*x4*x8 + x9*x8 + p3*p4*pinf - x6*pinf;
R6 = p2*p3*p4 - x3*p4 - x1*p3*x4 + x7*x4 - p3*x5 + p1*p3*x10 - x2*x10 - p2*x6 + x1*x9 + 2*x8 - p1*pinf;
R7 = p1*p3*p4 - x2*p4 - x1*x3*p4 + p2*x7*p4 - p3*x4 - x7*x5 + x3*x10 - p1*x6 + 2*x9 + x1*x8 - p2*pinf;
R8 = -(p2*p4) + x1*x4 + 2*x5 - p1*x10 + x3*x6 - x7*x9 - p3*x8 + x2*pinf;
R9 = p1*p3 - 2*x2 - x1*x3 + p2*x7 - x4*x6 + p4*x9 + x10*x8 - x5*pinf;
R10 = p2*p3 - x1*x2 - 2*x3 + p1*x7 - x1*x4*x6 - x5*x6 + p1*x10*x6 + x1*p4*x9 - x10*x9 + p4*x8 - p1*p4*pinf + x4*pinf;
R11 = -(p3*p4) + x2*x4 + x1*x3*x4 - p2*x7*x4 + x3*x5 - p1*x3*x10 + x7*x10 + 2*x6 - p1*x9 - p2*x8 + p1*p2*pinf - x1*pinf; I am interested in the algebraic variety generated by the zero locus of the family $\mathcal{F}$. In particular I expect that the dimension of the variety is actually 4. In order to calculate the dimension of my variety with Macaulay2, I perform the following steps: kk = QQ;
kkk = frac(kk[p1,p2,p3,p4,pinf]);
R = kkk[x1,x2,x3,x4,x5,x6,x7,x8,x9,x10];    
I = ideal (C1,C2,C3,C4,C6,C7,C8,C9,R1,R2,R3,R4,R5,R6,R7,R8,R9,R10,R11);
X = spec (R/I)
dim X and I get the correct dimension (and the computation is reasonably fast): $\dim X = 4$. At this point I want to isolate $6$ polynomials, $f_1,\dots,f_6$ in $\mathcal{F}$, such that if I run the following piece of code: J = ideal(f1,...,f6);
X = spec(R/J);
dim X; I get again that the dimension of X is $4$. The problem is that I am not able to find out such sub-family $f_1,\dots,f_6$. I tried random combinations of $6$ polynomials, but for every such combination the computation in Macaulay2 doesn't end. Why it is easier for Macaulay2 to compute the dimension of spec(R/I) (where there are 19 polynomials) than to compute the dimension of spec(R/J)? Is there any way to find out this family of $6$ polynomials? [Update:] I can use the command mingens (as suggested by Jesko HÃ¼ttenhain) to get a minimal GrÃ¶bner basis: gB = gb I;
mgB = mingens gB; then gB has 32 elements and mgB has 15 elements. The following ideal: J = ideal(mgB_(0,7),mgB_(0,8),R1,C6,C7); is such that $\dim J = 5$. I need one more polynomial, but for every combination I tried (picking the 6th poly from $\mathcal{F}$) the computation doesn't end.","['polynomials', 'algebraic-geometry', 'groebner-basis', 'affine-varieties', 'computer-algebra-systems']"
2147276,BolzanoâWeierstrass theorem conclusion,"Can I conclude from BolzanoâWeierstrass theorem that there is more than one convergent subsequence, or the theorem tells me that there's only one ? To be more clear, given a bounded sequence $X_n$, not ecessarily converges, can I conclude there are two different subsequences $X_{n_k}$ that converges to $L_1$ and $X_{n_l}$ that converges to $L_2$?",['calculus']
2147282,Why would this be a $T_1$-space?,"Let $L$ be a first order language, and let $F$ be the set of the sentences in $L$. Let $\simeq$ denote semantic equivalence between sentences (of course, according to the completeness theorem, this is the same as syntactic equivalence, but in the context I'm working in, semantics are used rather thab syntax); and let $T := F/\simeq$. For $H \subset F$, let $H^*$ denote the union of all equivalence classes that intersect $H$ (letting $\pi : F\to T$ denote the canonical mapping, we have $H^* =\bigcup\pi[H]$). Set $\Phi^* := \{\Phi\}^*$ for $\Phi\in F$. For $H\subset T$, let $\overline{H} := \displaystyle\bigcap_{\Phi \in F, H\subset \{\Psi^* \mid \Phi\models \Psi\}} \{\Psi^* \mid \Phi \models \Psi\}$ (where $\models$ is the semantic implication relation) I am asked in an exercise to show that this closure operator makes $T$ into a topological space, which is $T_1$. But this seems false, as in a topological space, $\overline{\emptyset} = \emptyset$, whereas here, if we let $p := (\exists x, x=x)^*$, then for all $\Phi\in F$, $\Phi\models \exists x, x=x$, and so $p\in \overline{\emptyset}$. Moreover, if we decide to artificially add $\emptyset$ to this set, turning it into a family of closed sets, the resulting space cannot be $T_1$, because for any $q\in T$, $p\in \overline{\{q\}}$. What do you make of this ? Did the exercise forget to mention something, or am I wrong for some reason ?","['model-theory', 'general-topology', 'first-order-logic']"
2147294,How to prove this conjecture $x_{n}(n\ge 4)$ can't be an integer.,"Define sequence $x_{1}=1$,and $x_{n+1}=1+\dfrac{n}{x_{n}},n\ge 1$.
  I found
  $$x_{2}=2,x_{3}=2,x_{4}=1+\dfrac{3}{x_{3}}=\dfrac{5}{2}, x_{5}=1+\dfrac{4}{2.5}=\dfrac{13}{5},x_{6}=1+\dfrac{5}{x_{5}}=\dfrac{38}{13}$$
  $$x_{7}=1+\dfrac{6}{x_{6}}=\dfrac{58}{19},x_{8}=1+\dfrac{7}{x_{7}}=\dfrac{191}{58},\cdots$$ I conjecture :   $x_{n}\notin Z$ for $n\ge 4$; in other words, this sequence has only three integer terms.","['number-theory', 'sequences-and-series']"
2147295,Combining geometric means from different datasets,"In statistics, one sometimes uses the geometric mean which for a dataset $\{x_i\}_{i=1}^N$ is defined as  $$(\prod\limits_{i=1}^N x_i)^{(1/N)}.$$
This is particularly useful when the data of the experiment is distributed across many orders of magnitude, so that it would make more sense to plot histograms on a log scale than a linear scale. Now suppose I am doing an experiment to determine some experimental variable $X$, which theoretically is  the geometric mean of the data set I measure. Suppose I have done this experiment repeatedly to generate $r$ data sets with geometric means $\mu_1, \mu_2, \ldots, \mu_r$ and geometric standard deviations $\sigma_1,\sigma_2, \ldots, \sigma_r$. How do I combine the data from these different experiments to obtain one geometric mean that is the best estimate for the variable? Can one simply take the arithmetic mean and standard error of this collection of means? If so, why? Or should we consider a different 'geometric error of the mean'?","['statistics', 'probability']"
2147296,A matrix is given in echelon form,"This is my first time posting a question and I'm really stuck on this one.
Help would be appreciated. 
I'm given this matrix $$\left[
\begin{array}{ccc|c}
2&3&0&9\\0&1&\lambda+6&4\\
0&0&\lambda^2-5\lambda+6&9-3\lambda
\end{array}\right],
$$ and I need to find for which  Î» â â this matrix has one solution no solutions infinite solutions","['matrices', 'matrix-equations']"
2147353,How to prove the order of an element is the same as the order of the subgroup generated by that element? [duplicate],"This question already has an answer here : Order of cyclic subgroup equal to order of generator (1 answer) Closed 2 years ago . Let $G$ be a group and $g \in G$. Define $\langle g\rangle$ to be the smallest subgroup of $G$ containing $g$. Define $o(g)$ to the the order of the element $g$. That is the smallest natural number $d$ such that $a^d=1$ the identity. Is it true for all groups that $o(g)|G$? I know by Lagrange's theorem we get $\langle g \rangle$|G so if we can show that  $o(g)=\langle g \rangle$ then we are done but I don't know how to show this. Is it just because $\langle g \rangle=\{g^0,g^1,...,g^{d-1}\}$? Thanks.",['group-theory']
