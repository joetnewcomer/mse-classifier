question_id,title,body,tags
3488958,"How many ordered quadruples of positive integers $\{a,b,c,d\}$ are there such that $a\leq b\leq c\leq d\leq 50$ and $a+b+c+d=100$?","How many set of positive integers $\{a,b,c,d\}$ are there such that $ a\leq b\leq c\leq d\leq 50$ and $a+b+c+d=100$ ? I was thinking about using stars and bars, and it seems to work if there were only three variables:
If $a\leq b\leq c\leq 50$ and $a+b+c=100$ , then we can define $x=50-a,y=50-b,z=50-c$ such that $x,y,z\leq 50$ and $x+y+z=3\times 50-(a+b+c)=50$ . Then we can simply use stars and bars to find the number of triples of $\{x,y,z\}$ , each of which corresponds to a unique $\{a,b,c\}$ . If $x\neq y,y\neq z$ , and $z\neq x$ , then only one out of the six sets consisting of $x,y,$ and $z$ is listed from the smallest to the largest. Since $50$ is not a multiple of $3$ , $x=y=z$ is not possible. If two of the three elements are the same, then this element can be any integer between $1$ and $24$ , inclusive. Since it can be either $x=y\neq z$ , $x=z\neq y$ , or $y=z\neq x$ , each case appears three times. Thus, the total number of ordered triples $\{a,b,c\}$ is $\dfrac{C_{49}^2-24\times 3}{6}+24$ . However, when there's a fourth variable $d$ , this method doesn't seem to work. Are there any other ways to circumvent it? Sorry for my poor English.",['combinatorics']
3488997,Functional equation $\big(\frac{1}{x}-1\big)f(x)+\big(\frac{1}{x^{\phi-1}}-1\big)f(x^\phi)=1$,"Consider the functional equation $$\Big(\frac{1}{x}-1\Big)f(x)+\Big(\frac{1}{x^{\phi-1}}-1\Big)f(x^\phi)=1$$ where $\phi$ is the golden ratio. I’m looking for a continuous function $f:[0,1)\to \mathbb R^+$ with $f(0)=0$ satisfying this equation. I’ve shown that this function is unique, so if I can find a single elementary function satisfying it, then I’ve found the only solution meeting these requirements. QUESTION: Can anyone find the function $f$ in closed form? I’m not interested in integral or series representations. How I know there’s a unique solution: To see why there is a unique continuous solution with $f(0)=0$ , we can do a series of repeated substitutions into the original functional equation: $$\Big(\frac{1}{x^\phi}-1\Big)f(x^{\phi})+\Big(\frac{1}{x^{(\phi-1)\phi}}-1\Big)f(x^{\phi^2})=1$$ $$\Big(\frac{1}{x^{\phi^2}}-1\Big)f(x^{\phi^2})+\Big(\frac{1}{x^{(\phi-1)\phi^2}}-1\Big)f(x^{\phi^3})=1$$ $$...$$ If we keep making the substitution $x\mapsto x^\phi$ , we can treat this like a long system of equations in the variables $f(x),f(x^\phi),f(x^{\phi^2}),$ and so on. Through repeated substitution, we can solve for $f(x)$ in terms of $f(x^{\phi^n})$ , which approaches $0$ as $n\to\infty$ . The algebra is messy, but this leaves us with a different series representation for $f(x)$ , showing that it is uniquely determined when we assume continuity and $f(0)=0$ . MOTIVATION: It turns out that the unique solution $f$ has the following series representation: $$f(x)=\sum_{n=1}^\infty x^{n+(\phi-1)\lfloor n (\phi-1)\rfloor}$$ and I’m trying to find a closed-form of this series (if not in terms of $x$ , at least at some special values of $x$ ). It’s a bit tricky to explain how I know $f$ satisfies this functional equation, but it can be proven from the following generalized identity: $$\frac{1-x}{x}\sum_{n\ge 1}x^n y^{\lfloor n\alpha\rfloor}+\frac{1-y}{y}\sum_{n\ge 1}y^n x^{\lfloor n/\alpha\rfloor}=1$$ which holds for all $x,y\in (0,1)$ and positive irrational $\alpha$ . The functional equation for $f$ follows by setting $y=x^{\phi-1}$ and $\alpha=\phi-1$ .","['functional-equations', 'sequences-and-series']"
3489105,Show that a diagonal in a pentagon is the golden ratio,"I just learned that the diagonal of a pentagon (size 1) is the golden ratio ( https://twitter.com/fermatslibrary/status/1210561047154872320 ) I tried to verify that, but ended up having to show that: $$\cos{\frac{2\pi}{5}}=\frac{1}{\phi}$$ Question: is there a way to calculate the diagonal of a pentagon without having to do any relatively complex trigonometric calculations? For example only by drawing some smart supportive lines and using the Pythagorean Theorem?","['golden-ratio', 'trigonometry']"
3489140,Would my proof that $ \mathbb{Q} \sim\mathbb{N} $ count?,"So I saw that $ \mathbb{Q}\sim\mathbb{N} $ and I tried to prove it. The official proof was a function using prime factors. I'm learning and in doing so I try to prove each theorem and corollary or example before I read the one in the script or book.
But mine was a little funky as I tried long and hard to think of something, but unfortunately couldn't come up with anything better. Would this work: Every number in $ \mathbb{Q}$ can be interpreted as two integers $a$ and $b$ .
Then we can devise a function $f: \mathbb{Q} \rightarrow \mathbb{N} $ where $a$ is the first digit and $b$ is appended. For example $f(5/4) = 54$ or $f(1/1) = 11$ . Is such a function even allowed?
Would it be injective and bijective? Also, if this is an allowed function. Would $0/4$ and $0/1$ count as two different rational numbers or the same? ( I was struggling finding a definition for the zero numbers if they count as different). Sorry if this is complete nonsense!","['elementary-number-theory', 'functions', 'solution-verification']"
3489216,Equivalent definition of rational map,"On The Arithmetic of Elliptic Curves, Joseph H. Silverman, the definition of rational map is given by: Let $V_1$ and $V_2 \subseteq \mathbb{P}^n$ be projective varieties. A rational map from $V_1$ to $V_2$ is a map of the form $$\varphi : V_1 \rightarrow V_2, \qquad \varphi = [f_0,\ldots,f_n]$$ where the functions $f_0,...,f_n ∈ K(V_1)$ have the property that for every point $P ∈ V_1$ at which $f_0,...,f_n$ are all defined, $$\varphi (P) = f_0(P),...,f_n(P).$$ And Hartshorne, the definition is: Let $X$ and $Y$ be varieties. A rational map $\phi: X \to Y$ is an equivalence of pairs $(U, \phi_U)$ where $U$ is a nonempty open subset of $X$ , and $\phi_U$ is a morphism of $U$ to $Y$ , and where $(U, \phi_U)$ and $(V, \phi_V)$ are considered equivalent if $\phi_U$ and $\phi_V$ agree on $U \cap V$ . I wonder if these two definitions are equivalent? So far I can see the first definition satisfies Hartshorne's definition, but how to see if Hartshorne's also agrees with the first definition?",['algebraic-geometry']
3489226,On sums such as $\sum_{k=0}^\infty \binom{2k}{k}\frac{1}{8^k}=\sqrt{2}$,"This identity is a special case of a more general formula found here , and known at least since 1972 (published in Abramowitz and Stegun 1972, p. 555.) Many remarkable series involving the inverse of binomial coefficients are known and listed in the same source, see also here for a way to derive them. However, there are plenty of interesting series involving binomial coefficients (not their inverse) that are not listed in the references that I checked. For instance: $$\sum_{k=0}^\infty \binom{3k}{k}\frac{1}{8^k}=\frac{4\sqrt{10}}{5}\cos\Big(\frac{1}{3}\arcsin \frac{3\sqrt{6}}{8}\Big)$$ $$\sum_{k=0}^\infty \binom{4k}{2k}\frac{1}{32^k}= \sin\frac{\pi}{8}+\cos\frac{\pi}{8}$$ Another example is: Question How do you prove these results? I found them using WolframAlpha symbolic calculator, see here for an example. One of these results is proved here , but I am looking for a proof that would apply to a broad class of such series. Background The reason that I am interested in powers of two ( $8^{-k}, 32^{-k}$ ) is because I am looking for series converging to irrational numbers, with each term being a fraction: the denominator is a power of two, and the numerator is an integer (a binomial coefficient in this case.) The goal is to gain some insights in the binary digit distribution of numbers such as $\sqrt{2}$ . For instance, a result that could be useful for me is the following: $$\sqrt{2} = \lim_{n\rightarrow\infty}\frac{P_n}{8^n} = \lim_{n\rightarrow\infty}\frac{1}{8^n}\sum_{k=0}^n 8^{n-k}\binom{2k}{k},$$ with $P_n$ being an integer.","['binomial-coefficients', 'combinatorics', 'sequences-and-series']"
3489309,Finding $n$ if $|\sum_{r=0}^{3n-1}\beta^{2^r}|=4\sqrt{2}$ where $\beta=\exp(i2\pi/7)$,Find $n$ if $\left|\displaystyle\sum_{r=0}^{3n-1}\beta^{2^r}\right|=4\sqrt{2}$ where $\beta=\exp(i2\pi/7)$ . My Attempt $$\begin{aligned}\left|\sum_{r=0}^{3n-1}\beta^{2^r}\right|&=\left|\sum_{r=0}^{n}(\beta+\beta^2+\beta^4)\right|\\ &=n|\beta|\left|1+\beta+\beta^3\right|\\&=n\sqrt{\left(1+\cos\left(2\pi/7\right)+\cos\left(6\pi/7\right)\right)^2+\left(\sin\left(2\pi/7\right)+\sin(6\pi/7)\right)}\\&=n\sqrt{1+4\sin^2(3\pi/14)+4\sin(\pi/14)\sin(3\pi/14)}\end{aligned}$$ I'm not sure how to proceed on the simplification of the term inside the square roots. Any hints are appreciated.,"['contest-math', 'trigonometry', 'complex-numbers']"
3489314,Solving a limit using only special limits and algebric manipulations,"I'm wondering how to solve this limit: $$\lim_{x \to 0^+} \frac{\tan^3((1+x^{\frac 23})^\frac13-1)+\ln(1+\sin^2(x))}{\arctan^2(3x)+5^{x^4}-1}(\sqrt{\frac{1+x+x^2}{x^2}}-\frac 1x)$$ With my actual notions that are: -Special limits -A limit of a sum/product/quotient of functions is the sum/product/quotient of limits of those functions if the functions converge(and also if the denominator function doesn't converge to 0 in the case of quotient) -Basic notions like $+\infty\cdot a=+\infty, a>0$ etc -Comparison theorem -Algebric manipulations Often my teacher does this ""trick"": ""If we have to calculate: $\lim_\limits{x \to x_0} s(x)c(x)$ . Where $s$ is a simple function that we know to be convergent to a non-zero value and $c$ is a complicated functions whom limit is unknown. We can write this: $$ \lim_\limits{x \to x_0} s(x)c(x)=\lim_\limits{x \to x_0} s(x)\lim_\limits{x \to x_0} c(x)$$ If we discover then that: $$\lim_\limits{x \to x_0} c(x)\in \mathbb{R}$$ Then our previous passage is justified. If we discover that: $$\lim_\limits{x \to x_0} c(x)\in \pm \infty$$ Then our previous passage is not justified formally, but it doesn't affect the limit(it's a kind of notation abuse). If we discover that: $$\not\exists \lim_\limits{x \to x_0} c(x)$$ Then our passage is not justified and it may have affected the limit result"" I kinda understood why this works(it's a kind of retrospective justificatin) but i was wondering if there a was a more formal way to describe this, because when i try to do limits I always try to justify all the steps I do and to be formal. However let's go back to the initial limit and to my attempt: $$\lim_{x \to 0^+} \frac{\tan^3((1+x^{\frac 23})^\frac13-1)+\ln(1+\sin^2(x))}{\arctan^2(3x)+5^{x^4}-1}(\sqrt{\frac{1+x+x^2}{x^2}}-\frac 1x)$$ Let's try to calculate first: $$\lim_{x \to 0^+} \sqrt{\frac{1+x+x^2}{x^2}}-\frac 1x=\lim_{x \to 0^+} \frac{\sqrt{1+x+x^2}-1}{x}=\lim_{x \to 0^+} \frac{\sqrt{1+x+x^2}-1}{x+x^2}(x+1)$$ Now i use a known special limit: $$\lim_{x \to 0^+} \frac{x+1}{2}=\frac 12$$ Now let's use the trick of my teacher and let's hope that the remaining limit exists otherwise we are at the starting point(this is also why sometimes i'm a bit unsure doing this it feels like a bet): $$\frac 12\lim_{x \to 0^+} \frac{\tan^3((1+x^{\frac 23})^\frac13-1)+\ln(1+\sin^2(x))}{\arctan^2(3x)+5^{x^4}-1}$$ And now i'm stuck because I see many useful special limits that i could apply but it always come to a $$0 \cdot \infty$$ form where i can't apply the ""trick"". Sometimes I feel i'm overcomplicating everything by being too formal but I really want to understand why I can apply something and I don't want to make it become an automatism before i totally understood it.","['limits', 'proof-writing', 'limits-without-lhopital', 'analysis']"
3489325,How to prove this formula for the determinant of a $4 \times 4$ tridiagonal matrix?,"This following is a problem from B. S. Grewal's Higher Engineering Mathematics . Show $$\begin{vmatrix} 2\cos(\theta) & 1 & 0 & 0 \\ 1 & 2 \cos(\theta) & 1
 & 0 \\ 0 & 1 & 2 \cos(\theta) & 1 \\ 0 & 0 & 1 & 2 \cos(\theta)
 \end{vmatrix} = \frac{\sin(5\theta)}{\sin(\theta)}.$$ If I take the $3 \times 3$ matrix after deleting the first row and first column, the value is $\frac{\sin(4\theta)}{\sin(\theta)}$ , but I am unable to solve this $4\times 4$ matrix. I tried solving the RHS but I am still unable to solve.","['determinant', 'matrices', 'linear-algebra', 'trigonometry', 'tridiagonal-matrices']"
3489340,Euler's phi function.,An exercise in a text I am reading says to find the smallest $n$ such that $\frac{\phi(n)}{n}<\frac{1}{10}$ .  I checked the first 10 million integers and found none with this property.,['number-theory']
3489347,"Characterizing smooth, square-integrable functions on $(0,1]$","Is there a simple way to characterize the functions in $C^\infty((0,1])\cap L^2((0,1])$ ? That is, given a function $f(t)\in C^\infty((0,1])$ , is there a necessary/sufficient condition I can check to see if it's square integrable?  An example of such a function is $f(t)=t^{-1/3}$ , which diverges as $t\to0$ but satisfies $\int_0^1 f(t)^2\,dt=3<\infty.$ Notes: I was hoping to prove something to the effect that $f(t)$ is square integrable if and only if $$\lim_{t\to0} \frac{f(t)^2}{t^p}=L < \infty$$ for some $p>-1$ .  This is certainily a sufficient condition by the "" limit comparison test "" for improper integrals, but I'm not sure if it's necessary.  (But, I also couldn't find a simple counterexample!)","['convergence-divergence', 'improper-integrals', 'functional-analysis', 'real-analysis']"
3489365,"Find sample size given standard deviation, sample mean, confidence interval","A machine is set up such that the average content of juice per bottle equals u. Assume that the population standard deviation is $5$ cl. A sample of 100 bottles yields to an average of $48$ cl. Calculate a $90\%$ and $95\%$ confidence interval for the average content. Suppose the sample size is unknown. What sample size is required to estimate the average contents to be within $0.5$ cl at the $95\%$ confidence level? For the first question I found that: $\alpha=10\%$ gives $\text{CI} = \bar x\pm t_{1-\alpha/2}\frac\sigma{\sqrt n}=48\pm t_{0.05}\frac5{\sqrt{100}}=(47.175,48.825)$ and similarly $\alpha=5\%$ gives $\text{CI} =48\pm t_{0.025}\frac5{\sqrt{100}}= (47.02,48.98)$ . I have difficulty regarding the second question. I have never faced such a question and don't really know how to tackle the problem.","['statistics', 'confidence-interval']"
3489457,Residue of product,"Suppose $f$ has an $n$ -th order pole at $0$ and $g$ is holomorphic at $0$ .  Can I write the residue of the product ""in terms of"" the residue of $f$ ? Since $$Res(fg)=\frac {1}{(n-1!)}\lim _{s\rightarrow 0}\left (\frac {d^{n-1}}{ds^{n-1}}\left \{ s^nf(s)g(s)\right \}\right )$$ and since the derivative here is $$\sum _{k=0}^{n-1}\left (\begin {array}{l}n-1\\ \hspace {4mm}k\end {array}\right )\frac {d^{n-1-k}}{ds^{n-1-k}}\left \{ s^nf(s)\right \} \frac {d^{k}}{ds^{k}}\left \{ g(s)\right \}$$ I can deduce $$Res(fg)=\frac {1}{(n-1)!}\sum _{k=0}^{n-1}\left (\begin {array}{l}n-1\\ \hspace {4mm}k\end {array}\right )(n-1-k)!g^{(k)}(0)\lim _{s\rightarrow 0}\left (\frac {d^{n-1-k}}{ds^{n-1-k}}\left \{ s^nf(s)\right \} \right )$$ which perhaps isn't too far from what I want?  I'd like it if this last limit was ""something like"" the residue of $f$ .",['complex-analysis']
3489480,Which threshold maximizes the expected size of the final sample?,"For $c>0$ , sample repeatedly and independently from $(0, 1)$ until the sum of the samples exceeds $c$ . Let $\mu_c$ be the expected size of the final sample. For which $c$ is $\mu_c$ maximised? It is clear that as $c$ tends to $0$ , $\mu_c$ tends to $\frac{1}{2}$ and this is its minimum value.",['probability']
3489493,Can Higman's embedding theorem be generalised that way?,"Suppose $\mathfrak{U}$ is a variety of groups. Lets define $F_n(\mathfrak{U})$ as relatively free groups in $\mathfrak{U}$ Suppose $G$ is a finitely generated group. We call $G$ finitely presented in $\mathfrak{U}$ iff $\exists n \in \mathbb{N}$ and finite $A \subset F_n(\mathfrak{U})$ such that $G \cong \frac{F_n(\mathfrak{U})}{\langle \langle A  \rangle \rangle}$ . We call $G$ recursively presented in $\mathfrak{U}$ iff $\exists n \in \mathbb{N}$ and recursively enumerable $A \subset F_n(\mathfrak{U})$ such that $G \cong \frac{F_n(\mathfrak{U})}{\langle \langle A  \rangle \rangle}$ . My question is: Is it true, that a finitely generated group is recursively presented in $\mathfrak{U}$ iff it is isomorphic to a finitely generated subgroup of a group finitely presented in $\mathfrak{U}$ ? This fact is true for the varieties of abelian groups due to linear algebra, proved for the variety of all groups by Higman and for the Burnside varieties by Olshanski. However, I do not know, whether it is true in general.","['universal-algebra', 'group-presentation', 'combinatorial-group-theory', 'group-theory', 'computability']"
3489525,For what measures of ∠a are there infinitely many intersections?,"Suppose you have an xy coordinate plane with two circles both with a radius of one, centered at (-2,2) and (2,2). You have a line segment with one endpoint at (0,0) and forms an angle (∠a) with the x-axis. The line segment continues until it intersects one of the circles and then “bounces off” -that is it forms a new line segment with an endpoint at the intersection, forming an equivalent angle with the tangent of the circle at that point to the angle formed by the original segment and that tangent (as if the segments show the path of light and the circles are mirrors). The new segment extends until it intersects a circle and “bounces off” to form a new segment and so on. For what measure of ∠a are there infinitely many intersections? (The light never stops bouncing).","['euclidean-geometry', 'geometry']"
3489536,Evaluate $\int \cos 2\theta \ln\left(\frac{\cos \theta+\sin\theta}{\cos\theta-\sin\theta}\right)d\theta$,"$$\int \cos 2\theta \ln\left(\dfrac{\cos \theta+\sin\theta}{\cos\theta-\sin\theta}\right)\mathop{}\!\mathrm{d}\theta$$ My attempt is as follows: $$\ln\left(\dfrac{\cos \theta+\sin\theta}{\cos\theta-\sin\theta}\right)=t\tag{1}$$ $$\dfrac{\cos\theta-\sin\theta}{\cos\theta+\sin\theta}\cdot\dfrac{\left(\cos\theta-\sin\theta\right)^2-(-\sin\theta-\cos\theta)(\cos\theta+\sin\theta)}{(\cos\theta-\sin\theta)^2}=\dfrac{\mathop{}\!\mathrm{d}t}{\mathop{}\!\mathrm{d}\theta}$$ $$\dfrac{2}{\cos2\theta}=\dfrac{\mathop{}\!\mathrm{d}t}{\mathop{}\!\mathrm{d}\theta}$$ Let's calculate $\cos2\theta$ from equation $1$ $$\dfrac{\cos \theta+\sin\theta}{\cos\theta-\sin\theta}=e^t$$ $$\dfrac{1+\tan\theta}{1-\tan\theta}=e^t$$ Applying componendo and dividendo $$\dfrac{2}{2\tan\theta}=\dfrac{e^t+1}{e^t-1}$$ $$\dfrac{e^t-1}{e^t+1}=\tan\theta$$ \begin{align}
\cos2\theta & = \dfrac{1-\tan^2\theta}{1+\tan^2\theta}\\
& = \dfrac{(e^t+1)^2-(e^t-1)^2}{(e^t+1)^2+(e^t-1)^2}\\
& = \dfrac{4e^t}{2(e^{2t}+1)}\\
& = \dfrac{2e^t}{e^{2t}+1}\tag{2}\\
\end{align} So integral will be $$\dfrac{1}{2}\cdot\int \left(\dfrac{2e^t}{e^{2t}+1}\right)^2\mathop{}\!\mathrm{d}t$$ $$=\int \dfrac{2e^{2t}}{(1+e^{2t})^2}\mathop{}\!\mathrm{d}t$$ Let $1+e^{2t}=y$ we have $$2e^{2t}=\dfrac{\mathop{}\!\mathrm{d}y}{\mathop{}\!\mathrm{d}t}$$ $$2e^{2t}\mathop{}\!\mathrm{d}t=\mathop{}\!\mathrm{d}y$$ \begin{align}
\int \dfrac{\mathop{}\!\mathrm{d}y}{y^2} & = -\dfrac{1}{y}+C=-\dfrac{1}{1+e^{2t}}+C\\
& = -\dfrac{1}{1+e^{\ln\left(\dfrac{\cos\theta+\sin\theta}{\cos\theta-\sin\theta}\right)^2}}+C\\
& = -\dfrac{1}{1+\dfrac{1+\sin2\theta}{1-\sin2\theta}}+C\\
& = -\dfrac{1-\sin2\theta}{2}+C\\
& = \dfrac{\sin2\theta}{2}+C'\\
\end{align} And this should be actually wrong because if we differentiate the result, it will give $\cos2\theta$ , but integrand is $\cos 2\theta \ln\left(\dfrac{\cos \theta+\sin\theta}{\cos\theta-\sin\theta}\right)$ What am I missing here, checked multiple times, but not able to get the mistake. Any directions?","['integration', 'indefinite-integrals', 'calculus', 'trigonometric-integrals']"
3489544,Does the composition of a random variable-valued function with itself induce dependence?,"Say I have a probability space $(\mathbb{R}, \Sigma, \mu)$ and a function $f$ of the form $f: \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ such that for any distinct $x_1,x_2 \in \mathbb{R}$ the functions $f(x_1, -)$ and $f(x_2, -)$ are independent random variables over $(\mathbb{R}, \Sigma, \mu)$ . Now let's define the random variables $G$ and $H$ as: \begin{align}
G(y) = f(f(x_1, y), y) \\
H(y) = f(f(x_2, y), y) \\
\end{align} Are $G$ and $H$ independent?","['independence', 'probability-theory', 'random-variables']"
3489546,"Intuition on an inductive proof of gcd Bezout identity (from Apostol: Math, Analysis 2ed)","I've done proofs in discrete mathematics, but I'm still at the stage where proofs with more than a few steps make me uncomfortable. From Apostol's Mathematical Analysis [2nd Ed.] on page 5, we have Theorem 1.6. Every pair of integers $a$ and $b$ has a common divisor $d$ of the form $$ d = ax + by $$ where $x$ and $y$ are integers. Moreover, every common divisor of $a$ and $b$ divides this $d$ . The proof (with my questions throughout) goes as follows: Proof. First assume that $a \geq 0, b \geq 0$ and use induction on $n = a + b$ . If $n = 0$ then $a = b = 0$ , and we can take $d = 0$ with $x = y = 0$ . Assume, then, that the theorem has been proved for $0, 1, 2, ..., n - 1$ . I am a little confused about taking $n$ to be $a + b$ , since it's not obvious that all pairs $\{a, b\}$ would be covered by induction for all combinations of $a, b \in \mathbb{Z}$ . By symmetry, we can assume $a \geq b$ . If $b = 0$ take $d = a, x = 1, y = 0$ . OK. If $b \geq 1$ we can apply the induction hypothesis to $a - b$ and $b$ , since their sum is $a = n - b \leq n - 1$ . Hence there is a common divisor $d$ of $a - b$ and $b$ of the form $d = (a - b)x + by$ . I'm going to let $a' = a - b$ , let $b' = b$ and let $d' = a'x + b'y$ . (I wish Apostol did something like this to make his proofs clearer.) I don't understand this logical step. Why does the fact that $a' + b' \leq n - 1$ imply that $d'$ exists and is a common divisor of $a'$ and $b'$ ? This seems like a huge leap. This $d$ also divides $(a - b) + b = a$ , so $d$ is a common divisor of $a$ and $b$ and we have $d = ax + (y-x)b$ , a linear combination of $a$ and $b$ . At this point I am clueless. Why does $d$ divide $a$ and why does this imply it also divides $b$ ? And where does Apostol get $y-x$ from?? To complete the proof we need to show that every common divisor divides $d$ . Since a common divisor divides $a$ and $b$ , it also divides the linear combination $ax + (y-x)b = d$ . This completes the proof if $a \geq 0$ and $b \geq 0$ . If one or both of $a$ and $b$ is negative, apply the result just proved to $|a|$ and $|b|$ . Why not just do the entire proof with absolute values from the beginning? Soft question: is it normal for authors to be very terse and not explain or give motivation for any steps? How do you go about trying to understand proofs that require a higher level of intuition than you currently have?","['number-theory', 'induction', 'proof-explanation', 'gcd-and-lcm']"
3489588,"Find $p$ and $q$ such that $x^2+px+q<x$ iff $x \in (1,5)$","Find $p$ and $q$ such that $$x^2+px+q<x$$ iff $$x \in (1,5)$$ I tried the following: $$x^2+px+q = (x+\frac{p}{2})^2+q-\frac{p^2}{4}$$ where the global minimum is $$q-\frac{p^2}{4}$$ if $$x = \frac{-p}{2}$$ However this doesn't seem to help with the problem at hand...","['algebra-precalculus', 'quadratics', 'polynomials']"
3489601,Radon-Nikodym derivative of pushforward measure,"I am trying to show that two measures are equivalent. This is the same as showing that the Radon-Nikodym derivative is bounded from above and below. I'll break it down so that things are easy to follow. If you need more information, please do ask! Setup: Consider the probability space $(X,\rho$ ) and the map $R:X\to X$ . Let $Y\subset X$ with $\rho(Y)>0$ . Assumption 1: There exists a measure $\mu_Y$ on $Y$ such that $\mu_Y$ is equivalent to $\rho|_Y$ , where $\rho|_Y$ denotes the restriction of the measure $\rho$ to $Y$ (suitably normalised). Assumption 2: There exist; (i) A probability space $(Z=Y\times K,\nu)$ where $\nu=\mu_Y\times \kappa$ for some suitably normalised measure $\kappa$ on some space $K$ . (ii) An ergodic invariant function $F:Z\to Z$ and a measurable surjection $s:Z\to X$ such that $s\circ F=R\circ s$ . Assumption 3: Define the measure $\mu=s_*\nu:=\nu(s^{-1}(\cdot))$ on $X$ . It is assumed that $R$ is ergodic and invariant with respect to $\mu$ . Moreover, we assume that $R^{-1}A=A$ implies $\rho(A)\in\{0,1\}$ , but invariance of R with respect to $\rho$ fails. Question: Can we say that $\mu$ and $\rho$ are equivalent? My ""attempt"": I think a similar sort of argument for $\frac{d\mu}{d\rho}=\frac{ds_*\nu}{d\rho}$ to the following could work. If we define the measure $m=\rho|_Y\times \kappa$ , note that $$\frac{1}{C}\le \frac{d\nu}{dm}= \frac{d\mu_Y}{d\rho|_Y}\le C$$ for some $C>0$ , so that $\nu$ and $m$ are equivalent. So far however I am not sure how to get the result. Any help would be very much appreciated! Thanks!","['measure-theory', 'ergodic-theory', 'radon-nikodym', 'dynamical-systems']"
3489602,How to maximize Revenue subject to customer constraints?,"Imagine you have N people that want to buy your product. However, each person will buy your product if the price of your product is less than or equal to some price say T n (subscript). What is the price that maximizes your revenue? For example, say you have 3 people and that the first person will buy your product if its less than T1 = \$1 , the second person will buy your product if it is less than T2 = \$3 and the third person will buy your product if its less than T3 = \$5. If i set the price of my product to say $2. Then the first person will not buy my product since \$2 is larger than \$1, however the other two will buy my product and therefore giving a revenue of \$4. However, i can do better. You can easily see that the price that will maximize my revenue in this case is \$3 giving you a revenue of \$6. My question is that given any number of people with any ""constrains"" (T n ), what is the best price that will maximize my revenue? I tried to solve this problem analytically  but i couldn't. I think an approximate solution could probably be given using statistics. I wrote a python code to experiment with this problem and it seems like for a random set of Tn (the constrains that each person sets) the mean of that set is actually a close approximation to that price that maximizes revenue. However, sometimes the mean just differs a lot. Thank you for reading, if what i wrote before is not clear please tell so i can edit it.","['statistics', 'calculus-of-variations', 'economics', 'calculus', 'optimization']"
3489619,What's wrong in my calculation of $\int_0^{3 \pi/4} \frac{\cos x}{1 + \cos x}dx$?,"What's wrong in my calculation of $$\int_0^{3 \pi/4} \dfrac{\cos x}{1 + \cos x} dx\,?$$ I have to find: $$\displaystyle\int_0^{3 \pi/4} \dfrac{\cos x}{1 + \cos x} dx$$ and I can't seem to get the right answer. This is what I did: I decided to use the Weierstrass substitution with: $$t = \tan \dfrac{x}{2}$$ $$\cos x = \dfrac{1 - t^2}{1 +  t^2}$$ $$\sin x = \dfrac{2t}{1 + t^2}$$ $$dx = \dfrac{2}{1+ t^2}$$ I am pretty new to this type of substitution. Anyway, the boundaries become: $$t_1= \tan 0 = 0$$ $$t_2 = \tan \dfrac{3 \pi }{8}$$ We have $$\displaystyle\int_0^{3 \pi/4} \dfrac{\cos x}{1 + \cos x} dx = $$ $$=\displaystyle\int_0^{\tan 3 \pi/8} \dfrac{\dfrac{1 - t^2}{1 + t^2}}{1 + \dfrac{1 - t^2}{1 + t^2}} \cdot \dfrac{2}{1 + t^2} $$ $$=\displaystyle\int_0^{\tan 3 \pi/8} \dfrac{1-t^2}{1+t^2} dt$$ $$=\displaystyle\int_0^{\tan 3 \pi/8} \dfrac{1}{1+t^2}dt - \displaystyle\int_0^{\tan 3 \pi/8} \dfrac{t^2}{1+t^2} dt $$ $$=\displaystyle\int_0^{\tan 3 \pi/8} \dfrac{1}{1+t^2} dt - \displaystyle\int_0^{\tan 3 \pi/8} \dfrac{t^2 + 1 - 1}{1+t^2} dt$$ $$= \displaystyle\int_0^{\tan 3 \pi/8} \dfrac{1}{1+t^2} dt - \displaystyle\int_0^{\tan 3 \pi/8} 1 dt + \displaystyle\int_0^{\tan 3 \pi/8} \dfrac{1}{1+t^2} dt $$ $$= 2 \bigg [\arctan(t) \bigg ]_0^{\tan 3\pi/8} - \bigg [ t \bigg ]_0^{\tan 3\pi/8}$$ $$= 2\arctan \bigg ( \tan \dfrac{3 \pi}{8} \bigg ) - \tan \dfrac{3\pi}{8}$$ $$= 2 \dfrac{3 \pi}{8} - \tan \dfrac{3 \pi}{8}$$ $$=\dfrac{3 \pi}{4} - \tan \dfrac{3 \pi}{8}$$ So that's the answer that I got. However, my textbook claims that the correct answer is in fact $\dfrac{\pi}{4} + \tan \dfrac{3 \pi}{8} - 2$ . So, what did I do wrong?","['integration', 'calculus']"
3489620,Expression for the value of $\int_0^1 x^{1/x}dx$,"I'm looking to evaluate $$\int_0^1 x^{1/x} dx$$ So far, I have that $$
\int_0^1 x^\frac{1}{x} dx \Rightarrow \int_0^1 e^{\frac{\ln x}{x}} dx \Rightarrow \int_0^1 \sum_{n \geq 0} \frac{\ln^nx}{x^nn!} dx
$$ However, I know that $
\int_0^1 \frac{\ln x}{x} dx
$ diverges, so I can't see a justification for switching the integral and sum. Furthermore, substituting $x = e^\frac{-u}{n+1}$ yields that the above is equivalent to (assuming my calculations were right) $$
\sum_{n\geq0} \frac{(-1)^n}{(1-n)^{1+n}}
$$ which is nonsensical. This thought process can be used to solve the ""sophomore's dream"" integral, which is $\int_0^1 x^{-x} dx = \sum_{n\geq1} n^{-n}$ , to which I have two questions: Why can't the same process be used? What changes between the two expressions? I suspect is has something to do with switching the integral and sum, but being a power series for $e^x$ I believe it should be justifiable. If the above is true, what is another approach to take for this integral? For some context, I have barely cracked into analysis, so if the answer is rudimentary, this is why. However, its very clear that the original integral will have a finite value, and being a cousin of the sophomore's dream, I suspect it could have a solution of the same form.","['integration', 'real-analysis']"
3489661,How can I determine the probability of a number in a random sequence being of a cerrtain type?,"I would like to produce some kind of probability function/density for finding out the likelihood of a chosen number, $k$ , to occur in a random sequence of length, $N$ . For Example: Let's say we have a sequence of $N=1000$ , random numbers in the range $\in [0,1]$ . Furthermore, let's truncate the random numbers to have only 3 significant digits (0.001). How can I calculate how many times a particular ""even"" modulo number is expected to occur, such that we have the probability of: (a) $k \in [0.1, 0.2, ..., 0.9]$ (b) $k \in [0.01, 0.02, ..., 0.09]$ (c) $k \in [0.02, 0.05, 0.08]$ Possibly related questions: An integer is chosen at random from the first 1000 positive integers. Probability that is a multiple of both 6 and 8? Question about computing expected value of the limit of a geometric mean of random variables PS. It's quite likely I have not stated the title of this question correctly, please feel free to adjust it.","['random-variables', 'probability', 'sequences-and-series']"
3489676,Does this sequence always terminate or enter a cycle?,"I've been fiddling with the recursive sequence defined as follows: $$\begin{equation}
  f_n=\begin{cases}
    a, & n=1.\\
    b, & n=2.\\
c, & n=3.\\
f_{n-1}f_{n-2}f_{n-3} \mod[f_{n-1}+f_{n-2}+f_{n-3}], & n>3.
  \end{cases}
\end{equation}$$ And no matter my initial choices of positive integers $a,b,c$ , it seems $ \{  f_n \}$ always terminates (three consecutive zeros) or enters a cycle. For instance, if $a=12,b=12,c=9$ , then the sequence becomes $12,12,9, 9,12,$ $12\dots$ My question: can we prove (or disprove) that for any positive integers $a,b,c$ , the sequence $\{ f_n\}$ will always terminate (three consecutive zeros) or enter a cycle? More important remarks in quotes. (Dec. 27) Remark 1.1: it appears (though I have not proved it) that my conjecture is true for the simpler recursive sequence $$\begin{equation}
  f_n=\begin{cases}
    a, & n=1.\\
    b, & n=2.\\
f_{n-1}f_{n-2} \mod[f_{n-1}+f_{n-2}], & n>2.
  \end{cases}
\end{equation}$$ Perhaps this would be a better starting point. Hereafter, I will only be referring to the above. (Dec. 28) Remark 1.2: If $f_n=f_{n-1}$ and is odd, then $f_k=f_n$ for all $k>n$ . If $f_n=f_{n-1}$ and is even, the sequence will terminate. This can be proven simply enough. (Dec. 28) Remark 1.3: I conjecture that if $a$ is odd and $b>a+1$ is even, the sequence always terminates. Also, if $a$ is even and $b>a+1$ is odd, the sequence never terminates. (Dec. 28) Remark 1.4: the sequence reaches the cycle $\dots 5,7,11,5,7,11\dots$ for many choices of $a,b.$ Some pairs $(a,b)$ for which $f_n$ enters the cycle $\dots 5,7,11 \dots$ are $(3,5), (5,7), (7,11),$ $(7,3),(35,11),(44,13).$ There are probably infinitely many pairs $(a,b)$ for which this occurs. The frequency with which I see $5,7,11$ is probably due to my relatively small choices of integers. I wonder what the minimum of $X+Y+Z > 3$ is, where $X,Y,Z$ is a cycle eventually reached by the function. I wonder further if there are arbitrarily long sequences of numbers which this recurrence relation would cycle through for certain initial $a,b$ . I have not found any cycles longer than three terms, though $5,7,11$ is not the only three-term cycle I have found. For $(a,b) = (7,111111101)$ , the sequence eventually reaches the cycle $8496495, 3641355, 6068925$ . If we have $(a,b) = (6, 99)$ , the sequence reaches a different length- $3$ cycle. (Dec. 28) Remark 1.5: almost always, it seems that when $f_n$ does not terminate, the repeated terms are multiples of $5$ . Some exceptions are $\{ f_n \}^{(9,66)}$ , $\{ f_n \}^{(6,99)}$ , and $\{ f_n \}^{(3,11)}$ , where $\{ f_n \}^{(x,y)}$ is the sequence generated for $a=x,b=y$ . (Dec. 28) Remark 1.6: I conjecture $5,7,11$ are the only primes that appear in a distinct cycle (see Def. 1.1). In fact, it may even be the case that $5,7,11$ is the only distinct cycle with primes. (Dec. 29) Remark 1.7: I should probably state what the 'cycles' I am talking about are. Definition 1.1: $\{ f_n \}$ is said to enter cycle $X,Y,Z$ if for some $k>0$ we have $f_{k+3n} = X, f_{k+3n+1} =Y$ , and $f_{k+3n+2} = Z$ for all integer $n \geq 0$ . Definition 1.2: A cycle is said to be non-constant if $X,Y,Z$ are not all equal. Similarly, a cycle is said to be distinct if $X \neq Y \neq Z$ . (Dec. 29) Remark 1.8: It seems not every positive integer is part of a distinct cycle (see Def. 1.2) That is, there are some (in fact, many) integers for which, no matter our choice of integers $a,b > 0$ , the sequence $\{ f_n \}^{(a,b)}$ will not enter a distinct cycle with that integer. I am not sure if the same is true for non-constant cycles. For constant cycles, this is trivially not the case.","['modular-arithmetic', 'elementary-number-theory', 'recursion', 'recurrence-relations', 'sequences-and-series']"
3489689,Maximizing Area of two squares in a circle,"I'm trying to come up with the following geometry (potentially calculus) question: Q: Let $A(P)$ denote the area of a polygon. Two squares $S_1$ and $S_2$ are drawn inside the unit circle $C_1$ in such a way that that $A(S_1+S_2)$ is maximized. Find the value of $A(S_1+S_2)$ . My attempt:
Consider the problem with one square, the maximum area of one square would simply be the area of an inscribed square. meaning a square with a side length $l=\sqrt{2}r$ . Since the circle has $r=1$ , the square has a value of 2. So I thought in order to find max( $A(S_1+S_2)$ ), we can first consider the unit circle with an inscribed square, then ""add in"" the second square like such: However, I'm struggling to first find the area of $S_2$ , then proving that this configuration is indeed the best configuration to maximize $A(S_1+S_2)$ . I've tried tackling this with calculus as well, but to no avail.","['calculus', 'geometry']"
3489716,How to assign 3 rooms to 3 people with 1 coin randomly?,"We are 3 friends; just checked into an airbnb flat with 3 rooms. And to make things truly random we decided to use 1 coin to assign each person a room. What's the best way to do this?
(Assuming coin flip is truly random.) (One way to define 'best' is minimum number of flips)","['random', 'combinatorics', 'probability']"
3489726,Symmetry between function and its derivatives,"$f(x)=\sin x$ is a well known function which satisfies the differential equation $$\frac{df}{dx}=f(\pi/2-x)$$ with the initial condition $f(0)=0$ ; I am just curious to know are these all? If not,what kind of properties functions should satisfy? My attempt: Putting $y=\pi/2-x$ does not seem useful to me.","['calculus', 'delay-differential-equations', 'real-analysis']"
3489752,"Given a fair coin, what is the mean of the number of tails before we toss a head?","Question: Given a fair coin, what is the mean of the number of tails before we toss a head? Let $N$ be the number of tails before we toss a head. Then $$E(N) = \sum_{n=1}^\infty n P(N=n).$$ Since $$P(N=n) = \left(\frac{1}{2}\right)^{n-1}.$$ Then by using geometric series, we have \begin{align*}
E(N) & = \sum_{n=1}^\infty n P(N=n) \\
& = \sum_{n=1}^\infty n \left(\frac{1}{2}\right)^{n-1} \\
& = \frac{1}{(1-\frac{1}{2})^2} \\
& = 4.
\end{align*} Are my calculations correct?","['statistics', 'probability']"
3489753,Bertrand's Paradox and uniform distribution,"This is a problem from Hans-Otto Georgii's textbook. Recall the situation of Bertrand’s paradox, and let X be the distance of the random chord to the centre of the circle. Find the distribution density of X if (a) the midpoint of the chord is uniformly distributed on the disk $|x|<r$ , (b) the angle under which the chord is seen from the centre of the circle is uniformly distributed on the interval $\Omega_2$ = $[0,\pi]$ . The solutions are given as:
a. the distribution density of X on [0,r] is $\rho_1(x)$ = $2x/r^2$ . b. $\rho_2(x) = 2/(\pi*\sqrt(r^2 - x^2))$ , x $\in [0,r]$ . edit:
the overall approach is to derive cdf then differentiate. a. cdf = $\pi x^2/ \pi r^2$ ; pdf = $2x/r^2$ . my thoughts for b: The probability formula for continuous uniform distribution in my textbook: $U_\Omega(A) = \lambda^n(A) / \lambda^n(\Omega)$ . So I tried expressing cdf like some probability: $\Omega = [0,\pi]$ , so $\lambda^n(\Omega) = \pi$ . A is the range of angle POQ when the distance is in $[0,x]$ . PQ is the chord. A = $2arccos(x/r)$ for x in $[0,x]$ . cdf = $2arccos(x/r) / \pi$ ; pdf = $- 2 / \pi \sqrt(r^2 - x^2)$ . However there is an extra negative sign here. could anybody help correct my workings?",['probability']
3489762,Converting inequalities into equalities by adding more variables,"I was trying to solve a rather large system of equalities and inequalities and was stuck, until I realized that converting the inequalities into equalities by adding more variables showed that zero-vector was the only answer. But I'm not so sure if it's correct. So my question is, it is valid to do so? What I'm trying to do is to find the range of $x$ where the following is true: $$\mathbb{A} x\leq 0, x\geq 0$$ where $\mathbb{A}$ is a specific $m\times n$ coefficient matrix and $x$ is an $n\times 1$ vector. But is this the same as solving the following: $$\tilde{\mathbb{A}}\tilde{x}=0, \tilde{x}\geq 0$$ where $\tilde{\mathbb{A}}$ is an $m\times(n+m)$ matrix and $\tilde{x}$ is an $(n+m)\times 1$ vector. By solution, I mean writing the elements of the original $x$ in terms of the elements that are in $\tilde{x}$ but not $x$ .","['inequality', 'systems-of-equations', 'linear-algebra', 'linear-programming']"
3489775,"Prove that ""injective function $f:X\to Y$ exists"" and ""surjective function $g:Y\to X$ exists"" is logically equivalent.","Prove that injective function $f:X\to Y$ exists surjective function $g:Y\to X$ exists is equivalent. $(x,y\neq \emptyset)$ My approach First,prove left to right. If injective function $f:X\to Y$ exists, a set A can be defined like this. $$A=\{f(x):x\in X\}$$ then it is sure that $A\subset Y$ , and $|A|=|X|$ And, if we define function $g$ like $$g(y)=\begin{cases}x & \text{if $y\in A$ and } f(x)=y,\\x_0& \text{if }y\notin A.\end{cases}$$ ( $x_0$ is a fixed element of $X$ ) Then, $g$ is a surjective function, so surjective function $g:Y\to X$ exists. Now,prove right to left. If surjective function $g:Y\to X$ exists, $\forall x \in X$ , we can select a element $y\in Y$ that $g(y)=x$ , which is clear that we can pick a different $y\in Y$ for $\forall x \in X$ if we define function $f$ as $f(x)=\text{one element in Y that g(that element)=$x$}$ , f is a injective function, so injective function $f:X\to Y$ exists. But, I am not sure that my approach is right, especially on proving right to left. Please check whether my approach is right, ways to improve it,  and some other ways of proving this question.","['elementary-set-theory', 'functions']"
3489782,Use of Mellin transform for evaluation of a series,"Show that $$\sum_{n=1}^\infty \frac{\sin an}{n}=\frac{\pi-a}{2} \ , \ 0<a<2\pi$$ I was asked to use Mellin transform to prove this result. So I used a formula related to the general series as follows $$\sum_{n=1}^\infty f(nx)=\mathcal{M}^{-1}\{F(s)\zeta(s);x\}$$ where $F(s)=\mathcal{M}\{f(x);s\}$ and $\zeta(s)$ is Riemann zeta function. Now taking $f(n)=\displaystyle\frac{\sin an}{n}$ we have $\displaystyle\mathcal{M}\bigg(\frac{\sin ax}{x}\bigg)=-\frac{\Gamma(s-1)\cos \frac{s\pi}{2}}{a^{s-1}}$ . Combining everything and using the  formula that $$\pi^s\zeta(1-s)=2^{1-s}\Gamma(s)\zeta(s)\cos \frac{s\pi}{2}$$ we have $$\sum_{n=1}^\infty \frac{\sin an}{n}=-\frac{a}{2}\mathcal{M}^{-1}\bigg\{\bigg(\frac{2\pi}{a}\bigg)^s\frac{\zeta(1-s)}{s-1};x=1\bigg\}$$ Now if we use calculus of residues to evaluate the expression at RHS, we see that we have singularity at $s=1$ . Using $\zeta(0)=-\frac{1}{2}$ we can easily calculate the residue at $s=1$ , which is $\displaystyle-\frac{\pi}{a}$ . 
So I get the answer $$\sum_{n=1}^\infty \frac{\sin an}{n}=-\frac{a}{2}.\bigg(-\frac{\pi}{a}\bigg)=\frac{\pi}{2}$$ which is wrong of course as there should be an extra term $-\displaystyle\frac{a}{2}$ on RHS. 
My doubt is I am missing a residue on the RHS while calculating the Mellin inverse, but I am unable to get that. 
I need a help in this regard. Any help is appreciated.","['mellin-transform', 'integral-transforms', 'sequences-and-series']"
3489825,"""Almost Normal"" Matrix and Gap between Spectral Radius/Norm","Let's denote $$\Vert{A}\Vert := \max_{x\neq0}\frac{x^* Ax}{x^*x}$$ and let $\rho(A)$ denote the largest absolute value of the eigenvalues of matrix $A$ . From basic linear algebra, one could characterize normal matrices as those unitarily diagonalizable ones, namely, for $A^*A=AA^*$ , there exist $Q \in \mathsf{SU}(n)$ and $\Lambda \in \mathsf{diag}(n)$ such that $$
A = Q\Lambda Q^*.
$$ Therefore, the spectral norm is exactly the spectral radius, $\rho(A)=\Vert A\Vert$ . On the other hand, when $A$ is not normal, even if it is diagonalizable, it is easy to construct some matrices with small spectral radius but large spectral norm, e.g., for $$A=\pmatrix{\epsilon&0\\\frac{1}{\epsilon}&2\epsilon}$$ we clearly have $\rho(A)=2|\epsilon|\rightarrow 0$ but $\Vert A\Vert\geq\frac{1}{|\epsilon|}\rightarrow +\infty$ as $\epsilon\rightarrow 0$ . It seems natural that, if we quantify the obstruction from a not-normal matrix to normal, we might be able bound the gap between spectral radius/norm. So here is my question: Suppose for $A\in\mathbb{C}^{n\times n}$ there is some $Q\in\mathsf{SU}(n)$ that $\Vert A-QA^*\Vert\leq\epsilon$ is small, could we have some upper bound on either the multiplicative gap $\Vert A\Vert/\rho(A)$ or additive gap $\Vert A\Vert-\rho(A)$ between its spectral norm and radius?","['spectral-norm', 'matrices', 'spectral-radius', 'matrix-norms', 'matrix-analysis']"
3489850,tuple identity proof..,"I have in one book little proof to create. We know that tuple can be expressed as $(a,b) = \{\{a\},\{a,b\}\}$ and I have too prove that: $ a = c \  \land b = d \implies  (a,b) = (c,d) $ I know this proof is very trivial but I'm a little too unexperienced in proofs so i want to ask if this proof I created is valid enought? $a=c\ \land b=d \implies a=c=x\ \land b=d=y \implies \{\{x\},\{x,y\}\} = \{\{a\}\{a,b\}\} = \{\{c\},\{c,d\}\} \implies (a,b) = (c,d) $ Or is there any more basic proof?","['elementary-set-theory', 'alternative-proof', 'solution-verification']"
3489895,"On the proof that ""Poincare dual=Thom Class""","Suppose that $S$ is an oriented smooth $s$ -manifold, and $\pi :E\to S$ is an oriented real vector bundle over $S$ . The Thom isomorphism asserts that the integration along the fiber defines isomorphisms $$H_{cv}^*(E)\cong H^{*-n}_{dR}(S).$$ The Thom class $\Phi_E$ is defined to be the element $\Phi_E\in H^n_{cv}(E)$ which corresponds to $1\in H_{dR}^0(S)$ in the above isomorphism. In several sources I have read, such as Bott-Tu (around p.65) and this pdf , it is stated that the Poincare dual of $S$ in $E$ is equal to $\Phi_E$ , that is, if we equip $E$ an orientation by the canonical isomorphism $T_xE_x\oplus T_xS\cong T_x E$ , then we have $$\int_E \omega\wedge \Phi_E=\int _S\omega$$ for all $\omega\in H^s_{c}(E)$ . However, I have some trouble understanding the proof of this claim, and I need someone's help. The proof goes as follows: if $i:S\to E$ denotes the zero section, then $i\circ\pi$ is homotopy equivalent to the identity on $E$ , so $\omega -\pi^*i^*\omega =d\tau$ for some $\tau\in\Omega^{s-1}(E)$ . Thus we have $$
\int_E\omega\wedge \Phi_E=\int_E\pi^*i^*\omega\wedge\Phi_E+\int_E d\tau\wedge \Phi_E.
$$ The first term on the RHS of the above equation can be computed, using the projection formula, and it equals $\int_S\omega$ . The problem is the second term, which involves the integral of $d\tau\wedge \Phi_E=d(\tau\wedge \Phi_E)$ . If we can show that this integral vanishes, then we are done. But we cannot blindly apply the Stokes's theorem, for $\tau\wedge \Phi_E$ may not have compact support. In Bott-Tu, it is simply stated that this integral equals zero by the Stokes's theorem. But for the reasons stated above, I think we need to ensure compactness of the support of $\tau\wedge \Phi _E$ In the pdf I cited above, it is stated that $i\circ\pi$ is properly homotopic to the identity map of E via the homotopy $H:E\times [0,1]\to E, \,(v,t)\mapsto (1-t)v$ , and hence $i$ and $\pi$ induce isomorphism in the compact cohomology and thus we can actually assume $\tau $ to have compact support. However, if I understand it correctly, $H$ is not proper because, for example, if $x\in S$ is any point in $S$ and $0_x$ denotes the zero vector  in $E_x$ , then $H^{-1}(0_x)\cap(E\times\{1\})=E_x\times\{1\}$ is not compact, unless $E$ has rank $0$ . Actually, since $\Phi_E\in\Omega_{cv}^n(E)$ , it is enough to ensure the compactness of $\pi(\operatorname{supp}\tau)$ . But I have trouble proving even this. I must be missing something. Can anyone help me? Thanks in advance.","['differential-topology', 'poincare-duality', 'algebraic-topology', 'differential-geometry']"
3489898,How to show a metric space is not complete,"In order to show that a metric space $(X, d)$ is not complete one may apply the definition and look for a Cauchy sequence $\{x_n\}\subset X$ which does not converge with respect to the metric $d$ . Now I have often seen (on books, e.g.) another approach: one may show that a sequence $\{x_n\}\subset X$ converges with respect to the metric $d$ to a limit $x$ which is not contained in $X$ . A common example may be the following: since $x_n:= (1+1/n)^n\in \mathbb{Q}$ for every $n \in \mathbb{N}$ and $x_n \to e$ , but $e \notin \mathbb{Q}$ , one can conclude that $\mathbb{Q}$ is not complete. I've always considered this to be obvious but I now realize I can't explain why this works. The quantity $d(x_n, x)$ itself need not be well-defined, in general, if $x \notin X$ . So my question is: why (and under which conditions) this criterion for not-completeness of a metric space (""limit is not in the same space as the sequence"") can be used?","['complete-spaces', 'cauchy-sequences', 'metric-spaces', 'real-analysis', 'general-topology']"
3489956,Is $f=g$ almost everywhere if their integrals over any subset are the same?,"Let $(X,\Sigma, \mu)$ a general measure space, and $\mathcal B$ the Borel $\sigma$ -algebra on the extended real line $\overline{\mathbb R}$ . Let $$f,g:X \to \overline{\mathbb R}$$ be two measurable functions such that $\int f d\mu$ and $\int g d\mu$ both exist (by which I mean that $f^+,f^-$ cannot both integrate to zero and similarly for $g$ ). Assume furthermore that $$\int_A f d\mu = \int_A g d\mu$$ for all $A \in \Sigma$ . My question is: is it then true that $f=g$ almost everywhere on $X$ ? I know how to show this in the case $f,g$ are almost everywhere finite-valued and integrable. However, even if $f,g$ are a.e. finite valued, we still cannot just simply take the difference of the integrals $f,g$ because they might both be infinite. So is this actually true? If not in the general case, is it true when $\mu$ is $\sigma$ -finite? Motivation: The whole thing started by me reading Jensen's inequality: if $\phi:\mathbb R \to \mathbb R$ is convex, and $X$ an integrable random variable on a probability space $(\Omega, \Sigma, \mathbb P)$ , and $\mathcal G \subset \Sigma$ a sub- $\sigma$ -algebra, then we have: $$\phi(\mathbb E[X|\mathcal G]) \leq E[\phi(X)|\mathcal G]$$ The problem here is that $\phi(X)$ might not be integrable. The usual proof of existence of $E[X|\mathcal G]$ uses the Radon-Nikodym theorem, assuming $X$ is integrable. However, exercise 2.4.6 from Cohen's measure theory states the following: Show that the assumption that $\nu$ is $\sigma$ -finite can be removed
  from Theorem 4.2.2 if $g$ is allowed to have values in $[0,+\infty]$ . Theorem 4.2.2 is the ""usual"" Radon-Nikodym theorem for positive measures. Now using this exercise and Hahn decomposition for signed measures, existence of $\mathbb E[X|\mathcal G]$ is easy, but uniqueness relies on my question above. Even uniqueness in the Exercise would require that the question I pose has a positive answer. Final remark: $X$ of course is assumed to be finite valued, but it made me wonder about the general case above. UPDATE: I thought about it and have a proof in the case where $\mu$ is $\sigma$ -finite. Sketch: Step 1: Assume $f,g \geq 0$ and $\mu$ is finite. Set $A_n = \{x| f(x) \leq n\}$ for $n \geq 1$ . Then it is easy to see that $f = g$ a.e. on $A_n$ . So $f=g$ a.e. on $\{x|f(x) \neq \infty \}$ . Let $B = \{x|f(x) = \infty \}$ and $A \in \Sigma$ have finite measure. Then $$\int_{B \cap A} g d\mu = \int_{B \cap A} f d\mu \geq n\mu(B \cap A),$$ so $\int_{B \cap A} (g-n) d\mu \geq0$ and $g\geq n \text{ a.e. on } B \cap A$ .
By $\sigma$ -finiteness we get $g\geq n \text{ a.e. on } A$ , so $$g = \infty = f \text{ a.e. on } A$$ Step 2: Assume still $f,g\geq0$ but now $\mu$ is $\sigma$ -finite. Then easy to use the previous to deduct $f=g$ a.e. Step 3: Now for the general case, note that for all $A \in \Sigma$ the assumption implies that $$\int_A(f^++g^-)d\mu = \int (f^-+g^+)d\mu$$ so by Step 2 we get $$f^++g^-=f^-+g^+ \text{ a.e.}$$ which is what we want. In lieu of that, my updated question is: is the assumption on $\sigma$ -finiteness necessary? If yes, how do we prove it, if no, can you give a counterexample?","['conditional-expectation', 'measure-theory', 'probability-theory', 'radon-nikodym']"
3489958,Partition of the real line.,"I want to show that there exist sets $A_x \ \forall x\in \mathbb{R}$ s.t: $A_x\cap A_y =\emptyset , \forall x\ne y$ , $\cup_{x\in \mathbb{R}} A_x = \mathbb{R}$ and $\forall x\in \mathbb{R} : \ |A_x|=\aleph$ . I thought of intervals in $\mathbb{R}$ such as $(0,x)$ but this doesn't cut it, since the first criterion of disjoint intervals doesn't hold. I don't see how to define this.
Any help? Edit: for those who don't know $\aleph$ is the cardinality of $\mathbb{R}$ also known as the continuum.","['elementary-set-theory', 'discrete-mathematics']"
3490068,When does equality hold in the triangle inequality?,"We consider the supremum norm $\|f\|=\sup_{x\in [a,b]} |f(x)|$ in the space $B([a,b],\mathbb C)$ of all bounded functions $f: [a,b] \rightarrow \mathbb C$ .   We obviously have in general  that $\|f+g\| \leq \|f\|+\|g\|$ for $f,g \in B([a,b],\mathbb C)$ . However, it may happens that for some $f,g$ the equality holds $\|f+g\|=\|f\|+\|g\|$ (for example, but not only then, if $f$ and $g$ are  proportional with a positive constant factor). The problem is: find all $f,g \in B([a,b],\mathbb C)$ such that $\|f+g\|=\|f\|+\|g\|$ . Thanks.","['triangle-inequality', 'analysis']"
3490107,Calculus II: Limit exercise,"I'm currently studying for my Calc exam and I came across this exercise. The problem is to find the values for $a,b,c \in \mathbb{R}$ so that the following limit exists: $$ \lim_{(x,y) \rightarrow (0,0)} \frac{xy}{ax^2+bxy+cy^2} $$ Along the path $y=kx$ , the expression becomes: $$ \lim_{(x,kx) \rightarrow (0,0)}\frac{kx^2}{ax^2+kbx^2+k^2cx^2} $$ $$ \lim_{(x,kx) \rightarrow (0,0)}\frac{k}{a+kb+k^2c}$$ If we evaluate the limit along the path where $k=0$ or $k=1$ , we get $0$ and $\frac{1}{a+b+c}$ respectively. because the second one can never become zero for any value of $a,b,c$ , I would conclude that the limit doesn't exist, but I don't think that's the correct answer, so I'm probably doing something wrong. Some help would be appreciated!","['multivariable-calculus', 'limits', 'calculus']"
3490115,Does there exist an initial arrangement of 10 black squares such that all the squares will ultimately be black?,"Let there be a $12×12$ table of white squares. We draw $10$ squares in black. If a white square has $2$ black neighbours, then we draw it in black. We say that $2$ squares are neighbours if they have a common edge. Does there exist an arrangement of the $10$ black squares such that all the squares will ultimately be black? My intuition says that it's impossible. I divided the table into 9 $4×4$ squares and tried to use the Pigeonhole Principle, but I am stuck.","['contest-math', 'invariance', 'combinatorics', 'discrete-mathematics']"
3490149,Is it true that if $f$ is surjective from $A$ to $B$ then there is an injective function $g$ from $B$ to $A$? [duplicate],"This question already has answers here : Prove that ""injective function $f:X\to Y$ exists"" and ""surjective function $g:Y\to X$ exists"" is logically equivalent. (2 answers) Closed 4 years ago . I think the answer is yes because otherwise $f$ wouldn't be a function.
Is this correct? And how would the formal proof go?","['elementary-set-theory', 'functions']"
3490156,Finding the remainder when $5^{55}+3^{55}$ is divided by $16$,Find the remainder when $5^{55}+3^{55}$ is divided by $16$ . What I try $a^{n}+b^{n}$ is divided by $a+b$ when $n\in $ set of odd natural number. So $5^{55}+3^{55}$ is divided by $5+3=8$ But did not know how to solve original problem Help me please,['algebra-precalculus']
3490162,Lee - Introduction to Smooth Manifolds Problem 8-9,"Proposition 8.19 Suppose $M$ and $N$ are smooth manifolds with or without boundary, and $F:M\to N$ is a diffeomorphism. For every $X\in\mathfrak{X}(M)$ , there is a unique smooth vector field on $N$ that is $F$ -related to $X$ . Problem 8-9. Show by finding a counterexample that Proposition 8.19 is false if we replace the assumption that $F$ is a smooth diffeomorphism by the weaker assumption that it is smooth and bijective. My solution: I started by thinking of a smooth bijection that is not a diffeomorphism. Let $M=\mathbb{R}=N$ . Then $F(x):=x^3$ is such a map, because its inverse is not smooth at $0$ . Let $X=d/dx$ . Then $$dF_x(X_x)f=\frac{d}{dx}(f\circ F)=\frac{d}{dx}(f(x^3))=3x^2\frac{df}{dx}\,.$$ Let $Y=\alpha(x)\frac{d}{dx}$ . Then $$Y_{F(x)}=\alpha(x^3)\frac{d}{dx}\,,$$ so for $Y$ to be $F$ -related to $X$ , we need $\alpha(x^3)=3x^2$ , which implies that $\alpha(x)=3x^{2/3}$ , so $\alpha$ is not smooth, and thus $Y\notin\mathfrak{X}(\mathbb{R})$ . Is this correct?","['vector-fields', 'smooth-manifolds', 'differential-geometry']"
3490171,Modeling a point following another point,"Suppose you have a point starting at the origin $(0,0),$ i.e., $$(x(0)=0,y(0)=0).$$ We'll denote its coordinates with $(x(t),y(t)),$ and it is tracking another point with constant velocity $v$ . This point lies a few units to the right, i.e., $(x_0,0).$ The second point is going directly upwards with parametric coordinates $$(x_0,vt).$$ In figure 1, this is what the curve will look like for an instantaneous amount of time. figure 1 Using this, we can derive that \begin{align*} \sqrt{dx^2+dy^2}&=v\,dt \\ 
\dfrac{v\,dt}{x_0}&=\dfrac{dy}{dx},
\end{align*} which implies \begin{align*}
\sqrt{(x'(t))^2+(y'(t))^2}&=v \\ 
\frac{v\,dt}{x_0}&=\frac{dy}{dx}.
\end{align*} However I got stuck here and I wasn't able to set up a nice differential equation. I took a different approach and tried to generalize recursively what the curve would look like as you can see in figure 2 figure 2 Let $$x_n=x(n\,dt), y_n=y(n\,dt)$$ and using properties of similar triangles and shared angles, we'll find $$x_n=v\,dt \cdot \cos\left(\arctan\left(\frac{nv\,dt−y_{n−1}}{x_0−x_{n−1}}\right)\right)+x_{n−1} \\ y_n=v\,dt \cdot \sin\left(\arctan\left(\frac{nv\,dt−y_{n−1}}{x_0−x_{n−1}}\right)\right)+y_{n−1}$$ which implies $$x_n=\frac{v\,dt}{\sqrt{1+\left(\frac{nv\,dt-y_{n-1}}{x_0-x_{n-1}}\right)^{\!2}}}+x_{n-1} \\ y_n=\frac{(v\,dt)\frac{nv\,dt−y_{n−1}}{x_0−x_{n−1}}}{\sqrt{1+\left(\frac{nv\,dt-y_{n-1}}{x_0-x_{n-1}}\right)^{\!2}}}+y_{n-1}$$ However my progress stops here. Maybe I can set up a differential equation by reversing Euler's method through the recursive method? I am unsure of the most simple way to do this. Any ideas on finding $(x(t),y(t))?$","['calculus', 'ordinary-differential-equations']"
3490214,why is the intersection of two sets with no common element equal to the subset containing the empty set and not simply the empty set?,"working through some notes and, in essence, the following is said: "" $A=\{1,2\}$ and $B=\{3,4\}$ $A\cap B = \{\emptyset\}$ "" Is this a mistake? Should it not be $\emptyset$ ?",['elementary-set-theory']
3490234,How to prove that the Reiter property implies the Folner property?,"Let $G$ be a group acting on a set $X$ such that the Reiter property holds, i.e. $$
\forall S\subset G \text{ finite, }\forall \varepsilon>0,\ \exists\ \varphi\in\mathcal{l}^1(X),\ \forall s\in S: \|s\varphi-\varphi\|_1<\varepsilon\|\varphi\|_1,
$$ where $\mathcal{l}^1(X):=\{\psi:X\to\mathbb{R}\ |\ \sum_{x\in X}|\psi(x)|<+\infty\}$ and where if $g\in G$ and $\psi\in\mathcal{l}^1(X)$ we define $g\psi:X\to\mathbb{R},\ x\mapsto \psi(g^{-1}x)$ . I want to show that this implies the Folter property, i.e. $$
\forall S\subset G \text{ finite, }\forall \varepsilon>0,\ \exists\ A\subset X \text{ finite, }\forall s\in S: |sA\Delta A|<\varepsilon|A|.
$$ My thoughts: without loss of generality we may assume that $\varphi\geq 0$ and $\|\varphi\|_1=1$ (by replacing it with $|\varphi|/\|\varphi\|_1$ ). Then for $\delta>0$ , we can take $A_\delta\subset X$ finite such that $\varphi(a)>\varphi(x)$ for all $a\in A$ , $x\notin A$ , and such that $\sum_{a\in A_\delta}\varphi(a)>1-\delta$ . Then if $m=\min \varphi(A_\delta)$ and $s=\max \varphi(X\backslash A_\delta)$ , we have: $$
(m-s)|sA_\delta\Delta A_\delta|\leq \sum_{x\in sA_\delta\Delta A_\delta}|s\varphi(x)-\varphi(x)|\leq \|s\varphi-\varphi\|_1<\varepsilon
$$ So if we could somehow controle the quantity $(m-s)|A_\delta|$ , we could finish. Is it possible? How to proceed?","['amenability', 'group-theory']"
3490248,Lower Semicontinuous Function = Supremum of Sequence of Continuous Functions,"Background I'm reading Cedric Villani's Optimal Transport: Old and New [1] and came across a result (below) I'm not quite sure how to prove. It is used to prove Lemma 4.3 and through my research, I've found it to be known as ""Baire's Theorem for Lower Semi-continuous Functions"" with topological approaches found in other StackExchange posts like [3] and [4] but never formally worked out. Question If $(X, d)$ is a metric space and $F$ is a nonnegative lower semi-continuous function on $X$ , then it can be written as the supremum of an increasing sequence of (uniformly?) continuous nonnegative functions. To see this, choose $$
F_{n}(x) = \inf\limits_{y~\in~X}\{~ F(y) + n\cdot d(x,y) ~\} 
$$ and show it is: (i) increasing; (ii) (uniformly?) continuous; (iii) convergent to $F$ [1, pg. 26; 2, pg. 55]. References: C. Villani, Optimal Transport, vol. 338. Berlin, Heidelberg: Springer Berlin Heidelberg, 2009. Available: https://ljk.imag.fr/membres/Emmanuel.Maitre/lib/exe/fetch.php?media=b07.stflour.pdf C. Villani, Topics in Optimal Transportation, 1st ed. American Mathematical Society, 2003. “Prove by definition that every upper semi-continuous function can be expressed as infimum of a sequence of continuous functions.,” Stack Exchange, 2017. [Online]. Available: https://math.stackexchange.com/questions/2227074/prove-by-definition-that-every-upper-semi-continuous-function-can-be-expressed-a?noredirect=1&lq=1. [Accessed: 28-Dec-2019]. “Show that lower semicontinuous function is the supremum of an increasing sequence of continuous functions,” Stack Exchange, 2015. [Online]. Available: https://math.stackexchange.com/questions/1279763/show-that-lower-semicontinuous-function-is-the-supremum-of-an-increasing-sequenc/1284586. [Accessed: 28-Dec-2019]. “What's behind the function g(x)=inf{f(p)+d(x,p):p∈X}?,” Stack Exchange, 2013. [Online]. Available:  https://math.stackexchange.com/questions/616071/whats-behind-the-function-gx-operatornameinf-fpdx-pp-in-x?rq=1. [Accessed: 28-Dec-2019]","['semicontinuous-functions', 'metric-spaces', 'real-analysis']"
3490297,"Help understanding the definition of a ""filtration"" in probability theory","I am having trouble understanding wikipedia's definition of filtration in probability theory: Definition ""filtration"" Let $(\Omega ,\mathcal {A}, P)$ be a probability space Let $I$ be a totally ordered index set Then $\mathbb{F} = \bigl(\mathcal{F}_i\bigr)_{i\in I}$ is a filtration if every $\mathcal{F}_i$ is a sub- $\sigma$ -algebra of $\mathcal{A}$ and for all $m,n \in I \times I$ we have $\mathcal{F}_m \subseteq \mathcal{F}_n$ whenever $m \le n$ $~ \square$ This definition feels unintuitive and I would have thought the direction of containment would go in the other direction: $\mathcal{A} = \mathcal{F}_0 \supseteq \mathcal{F}_m \supseteq \mathcal{F}_n$ . After all, the set of possible outcomes becomes smaller as one observes longer prefixes and more of the process that's unfolding. For concreteness, can someone provide an example of what the structure of the sets $\mathcal{F}_n$ look like? Say for a sequence of Bernoulli RVs, $X_1, X_2, X_3, \ldots$ , what do $\mathcal{F}_0$ , $\mathcal{F}_2$ , $\mathcal{F}_2,$ contain? And what does $\mathcal{A}$ contain?","['time-series', 'martingales', 'probability-theory', 'filtrations']"
3490300,Prove that the quotient group $A/\varphi (A)$ is finite when $A$ is torsion-free abelian,"I want to prove the following. Suppose $A$ is a torsion-free abelian group of finite rank (or, if you prefer, an additive subgroup of $\Bbb{Q}^n$ , where $n\ge1$ is the rank of $A$ )and $\varphi$ is an injective homomorphism of $A$ into itself (not necessarily surjective).
Show that the quotient group $A/\varphi (A)$ is finite. Using the Chinese Remainder theorem, I was able to prove it for the special case $\varphi (a)=ma$ , where $m$ is a non zero integer. What about the general case? Thank you in advance for your help.","['group-theory', 'abelian-groups']"
3490336,Bounding a Riemann Stieltjes integral.,"I have little experience with Riemann Stieltjes integrals. Any good reading material on it would be much appreciated (specifically a large summary of the material). Suppose $|k|_t$ is the total variation of $k:\mathbb{R}\to \mathbb{R}$ . Where $k$ is non-negative and monotonically increasing.  Consider the Riemann-Stieltjes integral (of a continuous $f:\mathbb{R}\to\mathbb{R}$ ) $$ \int_0^t f(s) d|k|_s $$ Is there any hope in bounding this by something like : $$ \int_0^t f(s) d|k|_s\leq C |k|_t\int_0^tf(s)ds ~~~~?$$ Thanks in advance! I would like to stress that $|k|_t$ is continuous and differentiable a.e. $\textbf{Edit :}$ Motivation : (you can kind of ignore the probability stuff just imagine everything as deterministic if you wish) The reason for studying this is I have an integral $$ \frac{\partial}{\partial t}\mathbb{E}\int_0^t |X_s| d|k|_s. $$ Here $X_s$ is a continuous random variable solution to the Skorohod reflection problem on a convex domain $D$ . $k_t$ is the random ( $X_t$ dependent) process which keeps $X_s$ in the domain. $|k|_t$ its total variation (also random but a.s finite). Now I have bounds on $\mathbb{E}(X_t)$ and can bound $|k|_t$ by $|X_t|$ ! So I was hoping to write : \begin{align*}
\frac{\partial}{\partial t}\mathbb{E}\int_0^t |X_s| d|k|_s\leq \frac{\partial}{\partial t} C \mathbb{E} |k|_t \int_0^t |X_s| ds
\end{align*} Then use Cauchy Schwartz and my bounds previously mentioned.","['calculus', 'riemann-integration', 'analysis', 'real-analysis']"
3490338,Values of integer such that a matrix equality does hold,"The problem is to find all integer values $n\geq 2$ such that there exist two non-zero $n\times n$ real matrices $A,B$ satisfying $$A^2B-BA^2=A.$$ For $n=2$ such matrices do not exist. Therefore, I am a little bit puzzled on the path I should follow: that there are no such matrices for any $n$ , or to prove that such matrices exist, at least for some values of $n$ (maybe related to the parity of $n$ ...). I have managed to prove that if such matrices exist, then $\hbox{tr}(A)=0$ and $\det(A)=0$ .","['matrices', 'matrix-equations', 'linear-algebra', 'matrix-calculus']"
3490363,Prime exponent Diophantine equations with infinitely many solutions,"I am to prove that the following equation has infinitely many solutions in the set of natural numbers: $${x_1}^{p_1} + {x_2}^{p_2} + \cdots + {x_{n-1}}^{p_{n-1}} = {x_n}^{p_n},$$ where $p_1, \dots ,p_n$ are given different prime numbers. Should one resort to induction, checking the first step is not so difficult, as the case for $n=1$ is obvious, and as to $n=2$ for the equation ${x_1}^{p_1} = {x_2}^{p_2}$ one could set $x_1= p^{p_2} \, , x_2=p^{p_1}$ for an arbitrary prime $p$ . But in passing from the induction hypothesis (the case $n$ ) to the case $n+1$ , I could not get through. Maybe, of course, the problem is solved without induction. Thanks for any suggestion or solution!","['number-theory', 'elementary-number-theory']"
3490373,What is a simple definition of the pullback of a section?,"I am simply asking for a definition for something everyone uses but nobody defines. Really, this is used in class and in Hartshorne, and I have tried to look for a definition in Hartshorne, Qing Liu, Wikipedia, nothing comes up, so I am wondering whether somebody on this planet knows a definition of this. Let $X,Y$ be topological spaces and $F, G$ be sheaves of modules over $X,Y$ respectively. The pull-back of a sheaf is very well-documented and defined everywhere with high precision: If $f:X\rightarrow Y$ is a continuous map, then $f^*G=f^{-1}G\otimes_{f^{-1}O_Y} O_X$ So I know what $f^*G$ and what $(f^*G)(U)$ are (with $U \subset X$ ). But what is $f^*s$ if $s\in G(Y)$ , or more generally $s \in G(U)$ where $U \subset Y$ is some open subset of $Y$ ? I know there is already a discussion in this thread and apparently the definition is given in a comment for affine schemes (it is just the image by the induced ring map), but I don't find it particularly enlightening. Could somebody please provide a straightforward definition for the pull-back of a section of a sheaf of modules on a general scheme? Can it be defined in a simple way (with e.g. a formula) without using high-powered, unintelligible stuff? In particular I don't know what adjunction correspondance is...","['pullback', 'definition', 'algebraic-geometry', 'sheaf-theory']"
3490400,Why is $x^2\sin(1/x)$ not strictly differentiable?,"I am on Wikipedia reading on strict differentiability and I don't particularly understand the example proving a function that is differentiable does not have to be strictly differentiable, where $f(x)=x^2 \sin(1/x)$ , $f(0)=0$ . How can we show this is differentiable directly using difference quotients. Also then how can we show it's not strictly differentiable using our difference quotients? The simplest setting in which strict differentiability can be considered, is that of a real-valued function defined on an interval $I$ of the real line. The function $f: I \rightarrow \mathbf{R}$ is said strictly differentiable in a point $a \in I$ if $$
\lim _{(x, y) \rightarrow(a, a)} \frac{f(x)-f(y)}{x-y}
$$ exists, where $(x, y) \rightarrow(a, a)$ is to be considered as limit in $\mathbf{R}^{2}$ , and of course requiring $x \neq y$ .
A strictly differentiable function is obviously differentiable, but the converse is wrong, as can be seen from the counter-example $f(x)=x^{2}$ sin $\frac{1}{x}, f(0)=0, x_{n}=\frac{1}{\left(n+\frac{1}{2}\right) \pi}, y_{n}=x_{n+1}$ .
One has however the equivalence of strict differentiability on an interval $I$ , and being of differentiability class $C^{1}(I)$ . (Transcribed from Wikipedia screenshot) so far I have; To show $f(x)$ is differentiable, I would assume I'd use the statement that if $x^2$ is differentiable and $\sin(1/x)$ is differentiable (which can be shown by the difference quotients, then $x^2 \sin(1/x)$ is also differentiable?","['limits', 'derivatives', 'real-analysis']"
3490402,How can a vector represent velocity and a position as well?,"I'm relatively new to linear algebra. I've got a question about a question . I'm not looking for the exact answer (I'll try to find it by myself).
I stumbled upon the following question : ""*At 12:00 pm, a spaceship is at position $$\begin{pmatrix}
3 \\
2\\
4
\end{pmatrix}$$ km away from the origin with respect to some 3 dimensional co ordinate system. The ship is travelling with velocity $$\begin{pmatrix}
-1 \\
2\\
-3
\end{pmatrix}$$ km/h What is the location of the spaceship after 2 hours have passed? "". I understand what a $$\begin{pmatrix}
3 \\
2\\
4
\end{pmatrix}$$ position means (in three dimensional Cartesian coordinate system with x, y, z axes). 
I can point precisely the position on a paper. But what does a "" [-1,2,-3] velocity "" mean ? Again, I'm not looking for the precise answer. I'd just like to know how to approach the problem since a same format (vectors) is used to tackle two different concepts (namely, position and velocity ). How can I process to some calculations in this ""position"" I would say, aha. Thank you :) Alex",['linear-algebra']
3490404,Proving that $\int_0^\pi\frac{x\ln(1-\sin x)}{\sin x}dx=3\int_0^\frac{\pi}{2}\frac{x\ln(1-\sin x)}{\sin x}dx$,"Prove without evaluating the integrals that: $$2\int_0^\frac{\pi}{2}\frac{x\ln(1-\sin x)}{\sin x}dx=\int_\frac{\pi}{2}^\pi\frac{x\ln(1-\sin x)}{\sin x}dx\label{*}\tag{*}$$ Or equivalently: $$\boxed{\int_0^\pi\frac{x\ln(1-\sin x)}{\sin x}dx=3\int_0^\frac{\pi}{2}\frac{x\ln(1-\sin x)}{\sin x}dx}$$ In contrast we have: $$\boxed{\int_0^\pi\frac{\ln(1-\sin x)}{\sin x}dx=2\int_0^\frac{\pi}{2}\frac{\ln(1-\sin x)}{\sin x}dx}$$ This is of course easily provable by splitting the integral as $\int_0^\frac{\pi}{2}+\int_\frac{\pi}{2}^\pi$ and letting $x\to \pi-x$ in the second part, unfortunately this method doesn't work for the other one. I am already aware how to evaluate the integrals as we have: $$\mathcal I= \int_0^\frac{\pi}{2}\frac{x\ln(1-\sin x)}{\sin x} dx\overset{\tan \frac{x}{2}\to x}=-2\int_0^1 \frac{\arctan x}{x}\ln\left(\frac{1+x^2}{(1-x)^2}\right)dx=-\frac{\pi^3}{8}$$ And the latter integral is evaluated in many ways here , so if you have other approaches please add them there. Here's how I came up with $\eqref{*}$ : I knew from here that: $$I\left(\frac{3\pi}{2}\right)=\int_0^\frac{\pi}{2}\frac{\ln(1-\sin x)}{\sin x}dx=-\frac{3\pi^2}{8}$$ And since this result is very similar to the one from above, I tried to show that $\mathcal I=\frac{\pi}{3} I\left(\frac{3\pi}{2}\right)$ , equivalent to: $$\boxed{\int_0^\frac{\pi}{2}\left(\frac{\pi}{3}-x\right)\frac{\ln(1-\sin x)}{\sin x}dx=0}$$ I also noticed that we have: $$\mathcal J=\int_\frac{\pi}{2}^\pi\frac{x\ln(1-\sin x)}{\sin x}dx\overset{x\to \pi-x}=\int_0^\frac{\pi}{2}\frac{(\pi-x)\ln(1-\sin x)}{\sin x}dx=\pi I\left(\frac{3\pi}{2}\right)-\mathcal I$$ $$\Rightarrow \mathcal I+\mathcal J=\int_0^\pi \frac{x\ln(1-\sin x)}{\sin x}dx=\pi I\left(\frac{3\pi}{2}\right)=-\frac{3\pi^3}{8}$$ Of course now it's trivial to deduce that $2\mathcal I=\mathcal J$ as we know the result for $\mathcal I$ , but I'm interested to show that relationship without making use of the result or by calculating any of the integrals. If possible showing $\eqref{*}$ using only integral manipulation (elementary tools such as substitution/integration by parts etc). 
I hope there's a nice slick way to do it as it will give an easy evaluation of the main integral.","['integration', 'definite-integrals', 'logarithms', 'alternative-proof', 'calculus']"
3490429,Integral of Infinite Sines,"I constructed the following question: Let $S_n$ denote the sequence where \begin{align}
S_1=&\sin{x}\\
S_2=&\sin{(\sin{x})}\\
S_3=&\sin(\sin(\sin{x}))\\
&\vdots
\end{align} Evaluate $$I=\int_0^{\pi}\lim_{n\rightarrow\infty}S_n\,dx$$ Messing around in desmos, it would seem that $S_n$ approaches $0$ as $n\rightarrow\infty$ . However I cant seem to be able to prove this. Any ideas?","['calculus', 'real-analysis']"
3490436,Looking for better approaches to evaluate $\int \dfrac{x^2+x}{(e^x+x+1)^2}dx$ [duplicate],"This question already has answers here : Evaluating the integral $\int \frac{x^2+x}{(e^x+x+1)^2}dx$ (2 answers) Find $\int\frac{x^2+x}{(e^x+x+1)^2}dx$ (3 answers) Closed 4 years ago . $$\int \dfrac{x^2+x}{(e^x+x+1)^2}dx$$ My multiple attempts are as follows:- Attempt $1$ : Let's differentiate $\dfrac{f(x)}{e^x+x+1}$ $$\dfrac{d}{dx}\left(\dfrac{f(x)}{e^x+x+1}\right)=\left(\dfrac{f'(x)(e^x+x+1)-f(x)(e^x+1)}{(e^x+x+1)^2}\right)$$ If we can choose $f(x)$ such that $f'(x)(e^x+x+1)-f(x)(e^x+1)$ equals to $x^2+x$ , then our job will be done. But I was not finding such $f(x)$ . Attempt $2$ : $$N_r=A(e^x+x+1)^2+2B(e^x+x+1)(e^x+1)$$ $$N_r=A(e^{2x}+x^2+1+2x+2xe^x+2e^x)+2B(e^{2x}+e^x+xe^x+x+e^x+1)$$ $$x^2+x=(A+2B)e^{2x}+(2A+4B)e^x+(2A+2B)xe^x+Ax^2+(2A+2B)x+A+2B$$ $$A+2B=0$$ $$A=1$$ $$2A+2B=0$$ $$2A+2B=1$$ So we don't have any solution for $A$ and $B$ Attempt $3$ : $$\int \dfrac{x^2+x+xe^x}{(e^x+x+1)^2}-\dfrac{xe^x}{(e^x+x+1)^2}dx$$ $$\int \left(\dfrac{(e^x+x+1)^2}{(e^x+x+1)^2}-\dfrac{1}{2}\cdot\dfrac{2(e^x+x+1)(e^x+1)}{(e^x+x+1)^2}\right)dx-\int \dfrac{xe^x}{(e^x+x+1)^2}dx$$ $$x-\ln(e^x+x+1)-\int \dfrac{xe^x}{(e^x+x+1)^2}dx$$ $$x-\ln(e^x+x+1)-\int \dfrac{(x+e^x+1-e^x-1)e^x}{(e^x+x+1)^2}dx$$ $$x-\ln(e^x+x+1)-\int \left(\dfrac{1}{e^x+x+1}-\dfrac{e^x+1}{(e^x+x+1)^2}\right)e^xdx$$ So we have the standard integral form $\int e^x\left(f(x)+f'(x)\right)=e^xf(x)+C$ $$x-\ln(e^x+x+1)-\dfrac{e^x}{e^x+x+1}+C$$ But it took me a lot of time to arrive at this. Is there any simple thing which I am missing here? Feel free to suggest your alternatives.","['integration', 'calculus']"
3490472,Add Relation To Permutation Group in GAP.,"I suspect this is basic but I don't know how to do it. Using the GAP system, how would I go about adding a relation to a given permutation group? For example, maybe I start with modeling a Rubik's cube as a subgroup of $S_{48}$ by the following: \begin{align*}
cube := Group(
&( 1, 3, 8, 6)( 2, 5, 7, 4)( 9,33,25,17)(10,34,26,18)(11,35,27,19),\\
&( 9,11,16,14)(10,13,15,12)( 1,17,41,40)( 4,20,44,37)( 6,22,46,35),\\
&(17,19,24,22)(18,21,23,20)( 6,25,43,16)( 7,28,42,13)( 8,30,41,11),\\
&(25,27,32,30)(26,29,31,28)( 3,38,43,19)( 5,36,45,21)( 8,33,48,24),\\
&(33,35,40,38)(34,37,39,36)( 3, 9,46,32)( 2,12,47,29)( 1,14,48,27),\\
&(41,43,48,46)(42,45,47,44)(14,22,30,38)(15,23,31,39)(16,24,32,40) );
\end{align*} Where each of the $6$ generators corresponds to the action on the faces of turning one side. We could call these $L,R,F,B,U,D$ as is fairly customary. But now suppose I want to consider a modification, where all the edge pieces have the same color, or one corner has three stickers of the same color. There is some homomorphism from $cube$ to this smaller group which I could define by some relations among moves (maybe I want $R^2 = 1$ ). However, I'm not sure how to implement this in GAP. I've seen how to add relations to a free group, but describing a Rubik's cube as a free group seems extremely cumbersome and I'd rather work with it as a subgroup of the symmetric group. Any help is appreciated, thanks.","['gap', 'group-theory', 'rubiks-cube']"
3490482,Cardinality of Cartesian product of sets [duplicate],"This question already has answers here : Cardinality of the Cartesian Product of Two Equinumerous Infinite Sets (3 answers) Examples of bijective map from $\mathbb{R}^3\rightarrow \mathbb{R}$ (2 answers) If $X$ is infinite, then $X$ and $X\times X$ are equinumerous Closed 4 years ago . I was unable to find a proof (let alone a short one) for the proposition that $$|A\times A| = |A|\text{ for any infinite set }A.$$ The function from right to left is trivial, but I cannot find one from left to right. Would be happy for help.",['elementary-set-theory']
3490498,Whst's the relationship between these two theorems? [duplicate],"This question already has answers here : Why is compactness in logic called compactness? (7 answers) Closed 4 years ago . When studying Computational Logic last year, we had to prove a theorem called ""Compactness Theorem"" (""Teorema de Compacidad in Spanish) which states that a set of formulae $\Gamma$ is satisfiable if and only if every finite subset of $\Gamma$ is satisfiable I am now going over Rudin's Principles of Mathematical Analysis to ""master the basics"" and came upon a theorem that states that for a collection of compact sets $\lbrace K_\alpha \rbrace$ if the intersection of every finite subcollection is nonempty, then the intersection of the whole collection is nonempty. These two theorems seem to state extremely similar things, so I was wondering how they're connected","['general-topology', 'logic']"
3490501,Prove that $\mathbb{P}(T_y < \infty) = \frac{a}{y}$,"Problem : Let $M$ be a continuous non negative martingale such that $M_{0}=a>0$ and $\lim _{t \rightarrow \infty} M_{t}=0$ a.s. For $y \geq a,$ let $T_{y}=\inf \left\{t \geq 0, M_{t}=y\right\} .$ Prove that $\mathbb{P}\left(T_{y}<\infty\right)=a / y$ Prove that $\sup _{t \geq 0} M_{t} \sim \frac{a}{U}$ where $U \sim \mathcal{U}([0,1])$ My attempt : both $T_y \wedge n $ and $0$ are bounded stopping times, according to Doob's optional stopping theorem, we have : $$\mathbb{E}(M_{T_y \wedge n}) = \mathbb{E}(M_0) = a$$ on the other hand we have : \begin{align*}
    \mathbb{E}(M_{T_y \wedge n}) &= \mathbb{E}(M_{T_y \wedge n} | T_y < \infty )P(T_y < \infty) + \mathbb{E}(M_{T_y \wedge n} |  T_y = \infty )P(T_y = \infty) \\
    & = \mathbb{E}(M_{T_y \wedge n} )P(T_y < \infty) + \mathbb{E}(M_n)P(T_y = \infty) \\
\end{align*} since $M_{T_y \wedge n} \to M_{T_y}$ in $L^1$ then if $M_n \to 0$ in $L^1$ then question 1. is proven. but do we have $M_n \to 0$ in $L^1$ ? I know that a necessary condition to obtain the above is that the martingale is uniformly integrable, but in this problem it doesn't look like it's uniformly integrable. am I tackling the problem the wrong way ?","['martingales', 'stopping-times', 'probability-theory', 'probability']"
3490529,Computing Chern Number of $\mathbb{CP}^1$ Tautological Bundle,"I'd like to compute the Chern number of the tautological bundle of $\mathbb{CP}^1$ .  Consider $L \subset \mathbb{C}^2\times \mathbb{CP}^1$ given by $$
L \;\; =\;\; \left \{(w_1, w_2, [z_1, z_2]) \; | \; z_1w_2 = z_2w_1 \right \}.
$$ I want to compute $c_1(L)$ by considering splitting $\mathbb{CP}^1$ into two neighborhoods $U_1$ and $U_2$ where $\mathbb{CP}^1 = U_1\cup U_2$ and $U_1\cap U_2 := C$ where $C$ is diffeomorphic to $\mathbb{S}^1$ .  If we then pick symplectic trivializations of $L$ with $U_1$ and $U_2$ , then by computing the degree of the parameterization of $C$ we then obtain the Chern class. Pick $U_1$ and $U_2$ to be \begin{eqnarray*}
U_1 & = & \{[z, 1] \; : \; |z| \leq 1\} \\
U_2 & = & \{[1,z] \; : \; |z| \leq 1\}.
\end{eqnarray*} It's then apparent that $U_1 \cap U_2 = C = \left  \{ \left[e^{2\pi i\theta},1 \right] \; : \; 0\leq \theta < 1 \right \}$ .  We can then pick parameterizations $\Phi_i: U_i \times \mathbb{C} \to L$ given by: \begin{eqnarray*}
\Phi_1\left ([z,1], w\right ) & = & (wz, w, [z,1]) \\
\Phi_2\left ([1,z], w\right ) & = & (w, wz, [1,z]).
\end{eqnarray*} Because the Chern class is independent of the choice of trivializations we simply need to compute the degree of the transition between these mappings.  This is given by \begin{eqnarray*}
\left (\Phi_1^{-1}\circ \Phi_2\right )([1,z], w) & = & \Phi_1^{-1}\left (w,wz, [1,z] \right ) \\
& = & \Phi_1^{-1}\left (\frac{wz}{z}, wz, \left [ \frac{1}{z}, 1\right ] \right ) \\
& = & \left (\left [\frac{1}{z},1\right ], wz\right ) \\
& = & \left ([1,z], wz\right )
\end{eqnarray*} Showing that $w\to wz$ in this transition.  This however implies that along the boundary of the two regions $C$ , that $\theta \to e^{2\pi i \theta}$ . The problem I see is that the degree of this map $C\to \mathbb{S}^1$ is just $1$ , but I've been told that $c_1(L) = -1$ .  Is there an error
  in my computation or is there something I'm missing?  What is the
  correct value of the Chern number?  Also, is there a straightforward
  way to take this result and generalize this to the Chern number for
  the tautological bundle of $\mathbb{CP}^{n-1}$ ?","['symplectic-geometry', 'algebraic-topology', 'differential-topology', 'characteristic-classes', 'differential-geometry']"
3490544,"Given a root of $x\tan x-1 = 0$, how to approximate the next one?","Let $f(x) = x\tan x-1$ . 
Let's consider when $f(x)=0$ . In the neighbourhood of every $k\pi$ , where k is an integer, there should be a solution for $f(x)=0$ . Assuming $x_0$ approximately satisfies $f(x)$ , is it correct that the next solution can be approximated to be at $x_0 + \pi - g(x)$ ? If so, how can I find $g(x)$ to approximate the position of the next root to an arbitrary precision?","['approximation', 'trigonometry', 'numerical-methods', 'optimization', 'algebra-precalculus']"
3490561,What is the cardinality of the set of convergent real-valued sequences?,"Denote by $S$ the set of all convergent sequences $(a_n)_{n=0}^\infty$ , where each $a_n\in\mathbb{R}$ . What is $|S|$ ? It must be the case that $|S|\geq|\mathbb{R}|$ . For each $x\in\mathbb{R}$ , given the decimal expansion $x_0.x_1x_2x_3\ldots$ of $x$ , the mapping $x\mapsto(\sum_{k=0}^nx_k10^{-k})_{n=0}^\infty$ is an injection $\mathbb{R}\to S$ . I would guess that $|S|=|\mathcal{P}(\mathbb{R})|$ . Is this true? If so, what might be an approach to prove it? Given any countable subset of $\mathbb{R}$ , I believe the following construction generates a unique convergent sequence and hence an injection into $S$ . Order the elements of the subset as $a_1,a_2,\ldots$ , and consider the following map $f:\mathbb{R}\to\mathbb{R}$ : $$f(a_k)=\begin{cases}
|a_k|,&|a_k|\leq1 \\
|1/a_k|,&|a_k|>1 \\
\end{cases}$$ Then the sequence $\big(\sum_{k=0}^n(-1/2)^kf(a_k)\big)_{n=1}^\infty$ converges by the alternating series test. I'm not sure of any construction for uncountable subsets of $\mathbb{R}$ , as I don't think that this approach would help. Additionally, I would still need to show either an injection from $S$ into $\mathcal{P}(\mathbb{R})$ or that some map $g:\mathcal{P}(\mathbb{R})\to S$ is a bijection, and I don't currently have any ideas for either of these.","['elementary-set-theory', 'sequences-and-series', 'real-analysis']"
3490592,What is notable about the composite numbers between twin primes?,"Look at the composites between twin primes ( A014574 ): $$
4, 6, 12, 18, 30, 42, 60, 72, 102, 108, 138, 150, 180, 192, 198, 228, \\ 240, 270, 282, 312, 348, 420, 432, 462, 522, 570, 600, 618, 
\ldots \;.
$$ Is there anything special about their distribution of factors,
number of divisors, or other number-theoretical properties?
Or are these twin-prime averages totally ""normal"" numbers, as far as we know?","['number-theory', 'twin-primes', 'prime-factorization']"
3490602,How many permutations of [9] have no adjacent odd digits?,"How many permutations of [9] have no adjacent odd digits? For example, a permutation like 385164927 is not allowed because 5 and 1 are adjacent. Wouldn't the answer just be 4!5!? Since each even number must be placed between 2 odd numbers, we have 4! ways to arrange the even numbers. Then we have 5 spaces in between the odd numbers to arrange: so that would be 5!. Right?","['solution-verification', 'combinatorics']"
3490626,$\sum\limits_{n\geq 0}\frac{1}{(n+1)(n+2)(n+3)}$ without using telescoping sums,"I'm really new to complex analysis and would like to see how one would go about finding a solution to an infinite series that looks like this: $$\sum\limits_{n\geq 0}\frac{1}{(n+1)(n+2)(n+3)}$$ or $$\sum\limits_{n\geq 0}\frac{1}{(n+1)(n+2)(n+3)(n+4)}$$ I'm interested in how we evaluate the residues as well. I understand that here we have only simple poles. These specific examples I made look a little tedious, but they have pretty simple solutions according to Wolfram.","['complex-analysis', 'sequences-and-series', 'real-analysis']"
3490652,Using the limit comparison test,"Given the infinite series: $$\sum^{\infty}_{n=1}\frac{1}{2n+3}$$ Determine whether this series converges. The answer key used the integral test to determine that no, this series does not converge. I came at this problem differently. I first tried using the comparison test with $\frac1n$ which was inconclusive. I then tried the limit comparison test - again with $\frac1n$ . I got a limit of $\frac12$ . Because this is a finite, positive number - the limit diverges. As a beginner, I am simply unsure that my method was legitimate - after all - its a fifty fifty chance of getting it right:) So, I am asking here- did I find the answer using a legitimate method?","['calculus', 'convergence-divergence', 'sequences-and-series']"
3490678,On constants attainable by the expression $\int_0^1xf(x)dx$,"Question. Let $f:[0,1]\to[0,1]$ be an analytic, motonically increasing function such that $f(0)=0$ and $f(1)=1$ . Let $K\in(0,1)$ be a constant such that $\int_0^1xf(x) \, dx=K$ . For which $K$ does there exist such a function $f$ , and for which $K$ is $f$ unique? If we changed the expression $\int_0^1xf(x) \, dx$ to simply $\int_0^1f(x) \, dx$ , is it easy to see that any $K\in(0,1)$ works and we certainly do not have any uniqueness. In the case $f(x)=x^\alpha$ for $\alpha\in\mathbb Z_{>0}$ we get $\int_0^1xf(x) \, dx=1/(\alpha+2)$ , so at least rational numbers of this form are attainable. Intuitively, it feels like the condition $\int_0^1xf(x) \, dx=K$ is very weak, so there should for every attainable value of $K$ be many functions $f(x)$ attaining it, but I'm having lots of trouble showing this, or finding all attainable values for $K$ . Any help is appreciated! P.S. If it helps, this arose out of a physics problem where $f(x)$ models the height of a liquid at distance $x$ away from a reference point, and the condition $\int_0^1xf(x) \, dx=\text{constant}$ comes from volume conservation of the liquid. So the question of uniqueness of $f(x)$ answers whether or not the behaviour of the body of liquid is completely determined by the conditions listed above.","['functions', 'functional-analysis', 'analysis', 'real-analysis']"
3490698,Understanding components and vector derivative in general curvilinear coordinates,"I'm studying introductory vector calculus and need to confirm/clarify my concepts. The definition of the derivative of a vector (for example in $\mathbb{R}^2$ ) if the unit vectors are constant throughout the 2D space is in terms of its components: if we have $\mathbb{r}(t)=(x(t), y(t))$ in the standard Cartesian basis , then $$\frac{d\mathbb{r}}{dt}=\frac{dx}{dt}\mathbb{e}_x+\frac{dy}{dt}\mathbb{e}_y$$ Now if we move to polar coordinates $\rho, \phi$ , then the unit basis vectors $\mathbb{e}_{\rho},\mathbb{e}_{\phi}$ will change direction depending on the location in 2D space. To define the derivative in this case, the book that I'm studying gives the following quick method: we see that $\mathbb{r}=\rho \mathbb{e}_{\rho}$ (where $\rho$ is the distance of the vector's endpoint from the origin), which means $$\frac{d\mathbb{r}}{dt}=\frac{d\rho}{dt}\mathbb{e}_{\rho}+\rho\frac{d\mathbb{e}_{\rho}}{dt}$$ So far, so good: $\frac{d\rho}{dt}$ can be calculated since we can express $\rho$ in terms of $x(t)$ and $y(t)$ , and differentiate that expression w.r.t. $t$ . In this specific case, we can also express $\mathbb{e}_{\rho}=(\cos\phi)\mathbb{e}_x + (\sin\phi)\mathbb{e}_y$ . It turns out that $$\frac{d\mathbb{e}_{\rho}}{dt}=\frac{d\phi}{dt}\mathbb{e}_{\phi}$$ because of the specific way $\mathbb{e}_{\rho}$ and $\mathbb{e}_{\phi}$ are defined in terms of $\mathbb{e}_x$ and $\mathbb{e}_y$ . Expressing the same vector $\mathbb{r}$ in a general curvilinear coordinate system $u,v$ , To even start differentiating $\mathbb{r}$ , we need to find the components of $\mathbb{r}$ in the new system. I'm assuming the way to identify $\mathbb{r}$ is to identify it as the intersection of two coordinate curves $u=c_1$ and $v=c_2$ - in this case, $u=5$ and $v=4$ . Is my understanding correct? Is this the way to identify the components of a vector in a curvilinear system? So if we have some differentiable functions $f,g$ such that $u=f(x,y)$ and $v=g(x,y)$ and $\mathbb{r}=u\mathbb{e}_u+v\mathbb{e}_v$ , then $$\frac{d\mathbb{r}}{dt}=\frac{du}{dt}\mathbb{e}_u+u\frac{d\mathbb{e}_u}{dt}+\frac{dv}{dt}\mathbb{e}_v+v\frac{d\mathbb{e}_v}{dt}$$ $\frac{du}{dt}$ can be identified as $\frac{df(x(t),y(t))}{dt}$ and can be evaluated. How does one, in general, express basis vectors $\mathbb{e}_u$ and $\mathbb{e}_v$ in terms of $\mathbb{e}_x$ and $\mathbb{e}_y$ ? And even if we do manage to define curvilinear basis vectors in terms of $\mathbb{e}_x,\mathbb{e}_y$ , it's not necessary that we'll get a nice expression for $\frac{d\mathbb{e}_u}{dt}$ and $\frac{d\mathbb{e}_v}{dt}$ in terms of $\mathbb{e}_u$ and $\mathbb{e}_v$ . How do we get the curvilinear components of $\frac{d\mathbb{r}}{dt}$ in that case?","['vector-fields', 'differential-geometry']"
3490752,Po-Shen Loh's new way of solving quadratic equation,"Quadratic equation, $ax^2+bx+c=0$ and its solution is quadratic equation, $x=\frac{-b\pm \sqrt{b^2-4ac}}{2a}$ Now setting $a=1$ then we have $x^2+bx+c=0$ $$x=\frac{-b\pm \sqrt{b^2-4c}}{2}$$ rewrite as $$x=-\frac{b}{2}\pm \sqrt{\left(\frac{b}{2}\right)^2-c}$$ In this new video Dr. Loh claims to discover a new way of solving the quadratic equation! How? It is the same as the above formula, by using the quadratic formula, the only thing I see different, is he rewrite it in the above form! Can someone please explain to me how this is a new way?","['proof-explanation', 'soft-question', 'roots', 'algebra-precalculus', 'quadratics']"
3490830,"An example of group which is regularly presented, but not finitely presented","Suppose $F_n$ is a free group with $n$ generators. Suppose $G$ is a finitely generated group. We call $G$ finitely presented iff $\exists n \in \mathbb{N}$ and finite $A \subset F_n$ such that $G \cong \frac{F_n}{\langle \langle A  \rangle \rangle}$ . We call $G$ regularly presented iff $\exists n \in \mathbb{N}$ and $A \subset F_n$ , which is regular as a formal language over the alphabet of generators and their inverses ,  such that $G \cong \frac{F_n}{\langle \langle A  \rangle \rangle}$ . Does there exist a group, which is regularly presented, but not finitely presented? If there is, I would like to see an example. The things I managed to find: -The cardinalities of classes of finitely presented groups and regularly presented groups are the same (they are countable) -Any regularly presented group is recursively presented and thus isomorphic to a subgroup of a finitely presented group by Higman embedding theorem.","['group-presentation', 'regular-language', 'combinatorial-group-theory', 'group-theory', 'formal-languages']"
3490868,$\lim_{n\to\infty}\{\frac{3}{n}\sum_{k=1}^n[1+8\sin^2(\frac{k\pi}{n})]^{-1}\}^{2^n}$,"How to calculate the limit below? $$\lim_{n\to\infty}\{\frac{3}{n}\sum_{k=1}^n[1+8\sin^2(\frac{k\pi}{n})]^{-1}\}^{2^n}$$ Since I used Riemann integration to work out that $$\lim_{n\to\infty}[\frac{3}{n}\sum_{k=1}^n(1+8\sin^2(\frac{k\pi}{n}))^{-1}]=1$$ , I've been trying to express $$\frac{3}{n}\sum_{k=1}^n(1+8\sin^2(\frac{k\pi}{n}))^{-1}=(1+\frac{C}{2^n}+o(\frac{1}{2^n})),\quad n\to+\infty$$ Can anyone render me some hints?","['limits', 'analysis', 'real-analysis']"
3490991,Cardinality of the space of all subgroups,"Let $(G,+)$ be an (abelian) group whose cardinality is $\mathcal{k}$ .
What is the size of the space of all subgroups of $G$ ? This question suggests that it is possible the answer is $2^{\mathcal{k}}$ . Anyway, my question is concerned only with the case $G=\Bbb{Q}^n$ , where $n\ge1$ .
And I hope (with few chances) that the cardinality of the set of all its subgroups is exactly $\aleph_0$ . Edit: In the previous version of the question, I wrote $G=\Bbb{Q}$ .","['elementary-set-theory', 'group-theory']"
3491000,Can the context-sensitivity of word problem in group $G$ be equivalently characterised through some structural properties of $G$?,"Suppose $G$ is a finitely generated group, $A$ is a finite set of generators of $G$ . Define $\pi: (A \cup A^{-1})^* \to G$ using the following recurrence: $$\pi(\Lambda) = e$$ $$\pi(a \alpha) = a\pi(\alpha)$$ Now define the language $L(G, A) := \{w \in (A \cup A^{-1})^*| \pi(w) = e\}$ . It seems, that position of $L$ in Chomsky hierarchy uniquely depends on some structural properties of $G$ . There are the following three theorems about that: Anisimov theorem $L(A, G)$ is regular (type 3 in Chomsky hierarchy) iff $G$ is finite. Muller-Shupp theorem $L(A, G)$ is context-free (type 2 in Chomsky hierarchy) iff $G$ is virtually free. Higman theorem $L(A, G)$ is recursively enumerable (type 0 in Chomsky hierarchy) iff $G$ is isomorphic to a subgroup of a finitely presented group. You may have already noticed that something (and, to be exact, context-sensitive languages - type 1 in Chomsky hierarchy) is missing from the list. My question is: Can the condition of context-sensitivity of $L(G, A)$ also be equivalently characterised through some group-theoretic properties of $G$ .","['combinatorial-group-theory', 'finitely-generated', 'discrete-mathematics', 'group-theory', 'formal-languages']"
3491003,Number of ways to insert parentheses between elements,"From Rosen's Discrete Mathematics and Its Applications, 3ed, chapter 8.1 p. 506-507: ...there are Ck ways to insert parentheses in the product x0 · x1 · · · · · xk I would like to ask where this conclusion comes from.  I am at a loss here.  It feels that this proof does not give me the whole story.  Thank you.","['proof-explanation', 'catalan-numbers', 'combinatorics', 'discrete-mathematics']"
3491047,alternative equivalent of mass spring ODE with a dirac delta stimulus,"A mass spring system ODE with a dirac delta stimulus reads: $$mx’’+cx’+kx=\delta(t)$$ $$x(0)=0, x’(0)=0$$ where ’‚’ denotes t derivative. Textbooks usually say, according to momentum theorem, the ODE can be rewritten as: $$mx’’+cx’+kx=0, t>0$$ $$x(0+)=0, x’(0+)=\frac 1m$$ However, momentum theorem I think is just one way of treating integration here. In theory, one can always integrate mx’’+cx’+kx=dirac(t) on both sides w.r.t t within (0-,0+). Then momentum theorem chooses to keep the integral of mx’’ dropping the latter 2 integrals. What if instead keep the integral of cx’ dropping the other 2 integrals? Then the ODE will become: $$mx’’+cx’+kx=0, t>0$$ $$x(0+)=\frac 1 c, x’(0+)=0$$ However, physically this gives a different solution/motion than the original ODE! Where does the error come from?",['ordinary-differential-equations']
3491049,Showing expression of $dA$ in cartesian coordinates = $dA$ in cylindrical polar [duplicate],"This question already has answers here : Explain $\iint \mathrm dx\,\mathrm dy = \iint r \,\mathrm \,d\alpha\,\mathrm dr$ (4 answers) Closed 4 years ago . In cartesian coordinates, $dA = dx\,dy$ .
As $x=\rho \cos\phi\ $ and $y=\rho \sin \phi \ $ , then: $dx=  \cos\phi\, d\rho - \rho \sin\phi\, d\phi$ and $dy = \sin\phi\, d\rho + \rho \cos\phi \, d \phi  $ . So $dx\, dy = \rho\, d\rho\, d\phi(\cos^2\phi-\sin^2\phi) $ , (ignoring second order terms in $d\rho$ and $d\phi$ ) Why is this not equal to the correct result of $dA=\rho\, d\rho\, d\phi$ ?","['cylindrical-coordinates', 'multivariable-calculus', 'curvilinear-coordinates']"
3491093,which is larger: $\sin(4^\circ)$ or $2\sin(2^\circ)$?,"I had two expression that simplified to the ones in the title. Obviously, I can't use a calculator. We didn't learn the double angle (or half angle) formulas so Ill have to find a different way, maybe with the unit circle.",['trigonometry']
3491103,"Find $\int_1^a \sqrt[5]{x^5-1}\ dx + \int_0^b \sqrt[5]{x^5+1}\ dx$, where $a^5-b^5 = 1$","So I am preparing to go to this olympiad, the Latvian Sophomore's dream calculus olympiad. I received previous years problems and the toughest problem in the definite integral section was this $$\text{Find } \int_1^a \sqrt[5]{x^5-1}\ dx  + \int_0^b \sqrt[5]{x^5+1}\ dx$$ $$\text{where }\  a^5-b^5 = 1$$ I tried substituting the whole root sign in the respective integrals but that led to nowhere. I don't see how trigonometric substitution could be used, dummy variables or the DI method. I am really at a loss here. Any ideas? I added a picture of all the problems.","['integration', 'contest-math', 'definite-integrals', 'real-analysis', 'calculus']"
3491114,Proof of inequality in triangle,"I am back after a long time, with this question In a $\Delta ABC; r_1+ r = r_2 + r_3, \angle ABC > \dfrac{\pi}{3}$ . Then prove that $b < 3a$ . Here $r_1$ is exradius of excircle formed by internal angle bisector of $\angle BAC$ . Similarly other two are defined. $r$ is inradius and $a, b$ are usual notations with respect to a triangle. I proved it but won't write up the whole solution. Glimpse of my solution: I proved $3a > b + 3c$ , then manipulated L.H.S. to $3a + 3c > 3a$ , which gives the desired answer. But am sure there must be a better way. How should it be done?","['geometry', 'triangles', 'geometric-inequalities', 'trigonometry', 'quadratics']"
3491138,Does $T\setminus S$ make sense even if $S$ is not a subset of $T$?,Very simple question.  I have a set $S$ which contains some elements of set $T$ but $S\nsubseteq T$ .  Is it proper for me to define $$ X=T\setminus S $$ even though $S$ is not a subset of $T$ ?  My goal is to define $X$ as the set of elements in $T$ which are not in $S$ .,['elementary-set-theory']
3491151,"How to evaluate $\iint_A \frac{1}{x^2+y^2}\,\mathrm dx\,\mathrm dy,$ where $A=[\frac{1}{a},a]\times[0,1]$ [duplicate]","This question already has answers here : Evaluation of $\int_{\frac{1}{2014}}^{2014} \frac{\tan^{-1}x}{x} dx$ (2 answers) Closed 4 years ago . I want to compute $$\iint_A \frac{1}{x^2+y^2}\,\mathrm dx\,\mathrm dy$$ where $A:=\left[\frac{1}{a},a\right]\times[0,1]$ . I got that this is equal to $\int_{1/a} ^a \frac{1}{x}\arctan \Big(\frac{1}{x}\Big) \mathrm dx\ $ and I don't know what to do from here. Can somebody help me, please?","['integration', 'definite-integrals', 'analysis']"
3491165,Finding $n$ elements of $\mathbb{Z}_n\times\mathbb{Z}_n$ such that their differences are all different,"Let $n\geq 3$ be an integer and consider the group $\mathbb{Z}_n\times\mathbb{Z}_n$ under addition. Question : Does there always exist a choice of $n$ elements $$
(a_1,b_1),\dots,(a_n,b_n)\in\mathbb{Z}_n\times\mathbb{Z}_n
$$ in the group such that the set of differences $$
S = \bigl\{(a_i,b_i) - (a_j,b_j)\, \big|\, i,j\in\{1,\dots,n\} \text{ and }i\neq j\bigr\}
$$ contains $n(n-1)$ distinct elements? I've been able to find solutions for $n$ up to 7, but not enough of a pattern emerges for me to be able to figure out how to generalize it to all $n\geq3$ . In the case when $n=3$ , we may choose the elements $(0,0),(1,0),(0,1)\in\mathbb{Z}_3\times\mathbb{Z}_3$ . To see that this choice has the desired property, construct a table containing $(a_i,b_i) - (a_j,b_j)$ in the $ij$ entry for each pair of indices $i,j\in\{1,\dots,n\}$ with $i\neq j$ : \begin{array}{rr|ccc}
&&(a_i,b_i)\\
& +& (0,0) & (1,0) & (0,1)\\
\hline
-(a_j,b_j)&(0,0) & \cdot & (1,0) & (0,1)\\
&(2,0) & (2,0) & \cdot & (2,1)\\
&(0,2) & (0,2) & (1,2) & \cdot
\end{array} It is clear that the off-diagonal entries of this table are all different, and thus $\lvert S\rvert = 6 = 3(3-1)$ . In the case when $n=4$ , we may choose the elements $(0,0),(1,0),(0,1),(3,3)\in\mathbb{Z}_4\times\mathbb{Z}_4$ . A similar table may be constructed to show that this choice also has the desired property: \begin{array}{rr|cccc}
&&(a_i,b_i)\\
& +& (0,0) & (1,0) & (0,1) & (3,3)\\
\hline
-(a_j,b_j)&(0,0) & \cdot & (1,0) & (0,1) & (3,3)\\
&(3,0) & (3,0) & \cdot & (3,1) & (2,3)\\
&(0,3) & (0,3) & (1,3) & \cdot & (3,2)\\
&(1,1) & (1,1) & (2,1) & (1,2) & \cdot
\end{array} The off-diagonal entries are all unique. For $n=5$ , we can choose $(0,0), (2,1), (1,2), (0,2), (2,0)\in\mathbb{Z}_5\times\mathbb{Z}_5$ . For $n=6$ , we can choose $(0,0), (2,1), (1,2), (0,2), (2,0), (5,5)\in\mathbb{Z}_6\times\mathbb{Z}_6$ . For $n=7$ , we can choose $(0,0), (2,1), (1,2), (0,5), (5,0), (1,5),(5,1)\in\mathbb{Z}_7\times\mathbb{Z}_7$ .","['direct-product', 'group-theory', 'finite-groups', 'modular-arithmetic']"
3491183,Relation between two rational sequences approximating square root 2,"We define recursive sequences $a_{n+1}=1+\frac 1{1+a_n}$ , $a_1=1$ and $b_{n+1}=\frac{b_n^2+2}{2b_n}$ , $b_1=1$ . I wish to show that $b_{n+1}=a_{2^n}$ . This can be proven using closed forms expressions related to continued fractions. I know that $a_n$ can be expressed as $$a_n=\sqrt2\cdot  \frac{(1+\sqrt 2)^n +(1-\sqrt 2)^n}{(1+\sqrt 2)^n - (1-\sqrt 2)^n}$$ On the other hand, we can prove inductively that $$\frac{b_{n+1}-\sqrt 2}{b_{n+1}+\sqrt 2}=\left(\frac{1-\sqrt 2}{1+\sqrt 2}\right)^{2^n}$$ So the relation $a_{2^n}=b_{n+1}$ can be deduced by expanding the fractions. However the computation is rather tedious, I am looking for a proof that does not involve expanding everything into closed form expressions. Thanks.","['sequences-and-series', 'recurrence-relations', 'real-analysis']"
3491213,Is there a lower bound to density at boundary points of a convex set?,"Let $X \subset \mathbb R^d$ be convex and compact. For each $x \in X$ define $$D(x) = \lim_{r \to 0^+}\frac{\mu(X \cap B(x,r))}{\mu(B(x,r))}$$ where $B(r,d)$ is the ball with centre $x$ and radius $r$ and $\mu$ is the Lebesgue measure. The density measures what proportion of the ball is contained in $X$ as $r$ becomes very small. For example if $X$ is a polygon then $D(x) = 1$ at interior points; and $D(x) = 1/2$ at every point on an edge but not a vertex; while for $x$ a vertex the density $D(x)$ is the angle at that vertex. Thus for polytopes at least $$\min\{D(x): x \in X\} = \min\{D(v): v \in X  \text{ is a vertex}\}>0.$$ For smooth bodies I would imagine $D(x) = 1/2$ at every boundary point, since the boundary is locally approximated by a hyperplane. Hence we have $\min\{D(x): x \in X\}  =1/2$ For more general maybe-not-smooth bodies, is is known that $\min\{D(x): x \in X\}  >0$ ?","['measure-theory', 'convex-geometry', 'geometric-measure-theory', 'reference-request', 'convex-analysis']"
3491215,Filling a square with unequally sized circles,"Suppose we are given a set of circles with integer radii 1, 2, 3 ... $n$ . What is the smallest square which they can all fit in such that they do not overlap? For instance, when $n$ =1, clearly we can fit the circle of radius 1 into a square of side length 2 ( $s$ = 2). The circle fills $\frac{\pi}{4} \approx 0.785 $ of the area of the square. When $n$ =2, it is obvious that the circles should touch each other, and that $s=3+\frac{3}{\sqrt2}$ . Here, the circles fill $\frac{5\pi}{13.5+9\sqrt2} \approx 0.599$ of the area of the square. When $n$ = 3, we once again place the largest circles touching each other, and place the square around them. There is plenty of space for the circle of radius 1. $s=5+\frac{5}{\sqrt2}$ . Here, the circles fill $\frac{14\pi}{37.5+25\sqrt2} \approx 0.604$ of the area of the square. When $n$ =4, once again the 4- and 3- radii circles determine the minimum size of square, and there is space for the 2- and 1- radii circles to fit in around. This means the circles fill $\frac{30\pi}{63.5+49\sqrt2} \approx 0.66$ of the area of the square. However, when $n$ =5, the 3-radius circle can no longer fit within the square determined by the 5- and 4-radii circles. The situation becomes considerably more complex as $n$ increases. So my questions are: Is there an algorithm (or approximation) which optimally arranges the $n$ circles in a square? What does the area of the circles, as a proportion of the area of the square, limit towards as $n$ increases.","['optimization', 'area', 'circles', 'geometry']"
3491241,Partitioning sets,"Consider the set $S=\{3,4,5,\dots,n\}$ . Let $A$ and $B$ be two partitions of $S$ such that there does not exist a triplet $(a,b,c)$ in either $A$ or $B$ such that $ab=c$ (note that $a$ and $b$ are not necessarily distinct). Find the largest value of $n$ such that a partitioning is possible. After some experimentation, I see that $n=9, 10, 11,..., 16$ are feasible. Whenever $A$ contains a triplet $(a,b,c)$ such that $ab=c$ , we can place one or two of $a, b, c$ into $B$ . But I'm not sure how to determine a value of $n$ for which it is impossible to find a desired partitioning. I think it would be useful to find a way to determine how a partitioning is impossible.","['contest-math', 'combinatorics']"
3491251,Prove that $A$ and $B$ are nilpotent - proof checking,"Let $A$ and $B$ be $n \times n$ matrices with real entries and $c_1, c_2, \dots ,c_{n+1}$ distinct real numbers such that $A+c_1B, A+c_2B \dots, A+c_{n+1}B$ are nilpotent matrices. Prove that $A$ and $B$ are nilpotent. Is my proof alright? This is my approach: For $k$ chosen arbitrarily from $\{1,2, \dots, n\}$ define the polynomial : $ P_k(x) = \operatorname{tr}[ (A+xB)^k]$ . Suppose that $P_k$ is not constant taking the value $0$ . $A+c_iB \text{ is nilpotent} \iff tr[ (A+c_iB)^k ] = 0 \forall k \in \mathbb{N}^* \text{ and } \forall i \in \{1,2,\dots, n+1\} \Rightarrow P_k(c_1) = P_k(c_2) = \cdots = P_k(c_{n+1}) = 0 \Rightarrow$ $$\operatorname{deg} P_k \geq n+1.$$ However the elements of $(A+xB)^k$ are polynomials in $x$ of degree at most $k$ . So $$ \operatorname{deg} P_k \leq k. $$ But from these two statements $k \geq n+1$ which is a contradiction because we chose $ k \leq n$ . So $P_k(x) = 0 \forall x \in \mathbb{R} $ . That means that all of its coefficients are $0$ . But, because $(A+xB)^k = x^k B^k + \dots + A^k$ , the leading coefficient of $P_k$ is $\operatorname{tr} (B^k)$ and the constant term is $\operatorname{tr} (A^k) \Rightarrow \operatorname{tr} (A^k) = \operatorname{tr} (B^k) = 0 \forall k \in \mathbb\{1,2 \dots n\} \Rightarrow $ $$ A \text{ and } B \text{ are nilpotent} $$","['matrices', 'nilpotence', 'solution-verification', 'linear-algebra']"
3491267,Why are there (r-s-1) degrees of freedom in a Chi Square GoF Test for Composite Hypotheses?,"In a Chi Square GoF Test for Composite Hypotheses, we are interested in whether the distribution of the random variable $\ X$ , which can take on a discrete set of values $\ B_1 , B_2, ...B_r$ according to probabilities $\ \mathbb{P}(X= B_1)=p_1 $ , $\ \mathbb{P}(X = B_2)=p_2 $ ,  ... , $\ \mathbb{P}(X= B_r)=p_r $ , is described by a family of distributions  { $\ \mathbb{P}_{\theta}: \theta\in\Theta $ }. Using a maximum likelihood estimation of our parameter $\theta$ , denoted $\theta^{*}$ , and utilizing notation that $\ \mathbb{P}_{\theta} (X= B_j)\equiv p_j(\theta)$ , our claim is that if the $\ p_j(\theta)$ are sufficiently close to the $\ p_j$ for some $\theta\in\Theta$ , then the statistic $$T_C= \sum_{j=1}^r \frac{(\nu_j-np_j(\theta^*))^2}{np_j(\theta^*)}\longrightarrow^d \chi_{r-s-1}^2$$ converges to a Chi Square distribution with $\ (r-s-1)$ degrees of freedom, where $\ s$ refers to the dimension of the parameter set $\Theta$ . In the paper I was reading about this test, which can be accessed here , the degrees of freedom of the Chi Square distribution to which this sum converges is stated without proof. I have already grappled with and understood Pearson's Theorem , which states  that: $$T_S= \sum_{j=1}^r \frac{(\nu_j-np_j)^2}{np_j}\longrightarrow^d \chi_{r-1}^2$$ in the situation where we want to know if our counts follow a specific distribution, rather than any one of a family of distributions. My question is: Is there a simple extension of Pearson's theorem which makes it easy to understand rigorously why the degrees of freedom should be $\ (r-s-1)$ in this new composite hypothesis case? P.S. $\nu_j$ in the above statements refers to the experimentally observed counts of $\ X_i$ that take on the value $\ B_j$ . The likelihood function can therefore be written as $\ \varphi(\theta)= p_1(\theta)^{\nu_1}p_2(\theta)^{\nu_2}...p_r(\theta)^{\nu_r}$ , $\ \theta^*$ maximizing the value of this function on its domain. I have used the same notation as used in the linked paper, in case I've left anything out and also for continuity of discussion. Update: The exact proof I am searching for is mentioned here , but I cannot find the relevant document on MIT's OCW website. Any link to a valid proof would be appreciated.","['statistics', 'probability-distributions', 'hypothesis-testing']"
3491287,Copula simulation,"Let $(X_1,X_2)$ be a bivariate random vector where $X_1 \sim \mathcal{N}(\mu_1,\sigma_1^2)$ and $X_2 \sim \mathcal{E}(\lambda)$ . We suppose that the dependence function is given by the following copula: $$ C(u_1,u_2) = u_1u_2(1 + \theta (1 - u_1)(1 - u_2))$$ where $\theta \in [-1,1]$ . I would like to simulate the random vector but i can't achieve to do so. My idea is to start by simulating $(U_1,U_2)$ (uniforms in $[0,1]$ ) which have $C$ as cdf : Simulate $U_1$ then simulate $U_2 | U_1$ which has the following cdf : \begin{align*}
\mathbb{P}(U_2 \leq u_2 | U_1 = u_1) & = \lim_{\epsilon \to 0} \frac{P(U_2 \leq u_2, U_1 \in [u_1, u_1 + \epsilon])}{P(U_1 \in [u_1, u_1 + \epsilon])} \\
& = \lim_{\epsilon \to 0} \frac{C(u_1+\epsilon,u_2) - C(u_1,u_2)}{\epsilon} \\
& = \partial_{u_1}C(u_1,u_2) \\ 
& = u_2(1+ \theta(1-u_1)(1-u_2)) -\theta u_1u_2(1-u_2) \\ 
& = \theta u_2 ^2(2u_1 - 1) + u_2(1 + \theta - 2\theta u_1)
\end{align*} My idea is to simulate $U_2 | U_1$ by inverting $\mathbb{P}(U_2 \leq u_2 | U_1 = u_1)$ , but it doesn't seem to be invertible.
Any other idea? Thanks","['statistics', 'finance', 'copula', 'probability']"
3491323,"Show that for each integer $n ≥ 2$, $F_n$ is a finite index subgroup of $F_2$, where $F_n$ is the free group on $n$ generators. [duplicate]","This question already has an answer here : Show that the free group on $n$ generators is a finite index subgroup of $F_2$ (1 answer) Closed 4 years ago . I'm trying to answer a problem which asks me to show (using covering spaces) that for each integer $n ≥ 2$ , $F_n$ is a finite index
subgroup of $F_2$ , where $F_n$ is the free group on $n$ generators. I can see that if I can find some covering space with fundamental group $F_n$ of the wedge $S^1 \vee S^1$ then this will give me the existence of the subgroup, and I know that this will be of finite index if this covering map sends finitely many points to the vertex joining the two circles in $S^1 \vee S^1$ . The problem I'm having is I'm struggling to find such a covering space - the only space I know of with fundamental group $F_n$ is the wedge of $n$ circles, but I can't see any covering map from that to $S^1 \vee S^1$ so I assume I must need another. If anyone could suggest such a covering space (and if so how I can show it has fundamental group $F_n$ ) I'd really appreciate the help!","['group-theory', 'fundamental-groups', 'free-groups', 'general-topology', 'algebraic-topology']"
3491347,"Simple recurrences converging to $\log 2, \pi, e, \sqrt{2}$ and so on","See my question at the bottom of this post. The recurrence $P(n) x_{n+2} = Q(n)x_{n+1} - R(n)x_n$ , where $P(n), Q(n), R(n)$ are  polynomials of degree $1$ , sometimes leads to interesting results. Probably the most basic cases are: For $\log\alpha$ : $$P(n) = \alpha (n+2), Q(n) = (2\alpha-1)(n+1)+\alpha, R(n)=(\alpha-1)(n+1)$$ $$\mbox{with } x_1=\frac{\alpha-1}{\alpha}, x_2 = \frac{(\alpha-1) (3\alpha-1)}{2\alpha^2}$$ We have $\lim_{n\rightarrow\infty} x_n = \log\alpha$ . The convergence is fastest when $\alpha$ is close to $1$ . The related recurrence $$P(n) = 1, Q(n) = (2\alpha-1)(n+1)+\alpha, R(n)=(\alpha-1)\alpha(n+1)^2$$ $$\mbox{with } x_1=\alpha-1, x_2=(\alpha-1)(3\alpha-1)$$ yields $$\lim_{n\rightarrow\infty} \frac{x_n}{\alpha^n n!} = \log\alpha$$ and in addition $x_n$ is an integer if $\alpha>0$ is an integer. For $\exp \alpha$ : $$P(n) = n+2, Q(n) = n+2+\alpha, R(n)=\alpha$$ $$\mbox{with } x_0=1, x_1 = 1+\alpha$$ We have $\lim_{n\rightarrow\infty} x_n = \exp\alpha$ . The related recurrence $$P(n) = 1, Q(n) = n+2+\alpha, R(n)=\alpha(n+1)$$ $$\mbox{with } x_0=1, x_1=1+\alpha$$ yields $$\lim_{n\rightarrow\infty} \frac{x_n}{n!} = \exp\alpha$$ and in addition $x_n$ is an integer if $\alpha$ is an integer. For $\sqrt{2}$ : $$P(n) = 4(n+2), Q(n) = 6n+11, R(n)=2n+3$$ $$\mbox{with } x_0=1, x_1 = \frac{5}{4}$$ We have $\lim_{n\rightarrow\infty} x_n = \sqrt{2}$ . The related recurrence $$P(n) = n+2, Q(n) = 2(6n+11), R(n)=16(2n+3)$$ $$\mbox{with } x_0=1, x_1=10$$ yields $$\lim_{n\rightarrow\infty} \frac{x_n}{8^n} = \sqrt{2}$$ and in addition $x_n$ is an integer. Comment These formulas (and tons of other similar formulas) are easy to obtain, yet I could not find any reference in the literature. It would be interesting to see if one is available for $\gamma$ (the Euler Mascheroni constant), but I don't think so. Also, what happens when you change the initial conditions? What if you replace the recurrence by its equivalent differential equation, for instance $$(x+2) f(x) - (x+2+\alpha) f'(x) + \alpha f''(x) =0$$ corresponding to the case $\exp\alpha$ ? Generalization to arbitrary initial values As an example, here is what happens to the very first formula (the $\log \alpha$ case), if we change the initial conditions $x_1=\frac{\alpha-1}{\alpha}, x_2 = \frac{(\alpha-1) (3\alpha-1)}{2\alpha^2}$ to arbitrary values $x_1 = A, x_2=B$ , assuming here that $\alpha=2$ : $$\lim_{n\rightarrow\infty} x_n = (5-8\log \alpha)\cdot A + (8\log \alpha -4) \cdot B.$$ You may try proving this formula. It was obtained empirically, I haven't proved it. And it works only if $\alpha = 2$ . For $\alpha \neq 2$ , and also for the case $\sqrt{2}$ , a general formula is $$\lim_{n\rightarrow\infty} x_n = c_1 A + c_2 B$$ where $c_1, c_2$ are constants not depending on the initial conditions. This might be a general property of these converging linear recurrences (at least those involving polynomials of degree one). Another property, shared by the converging systems described here, is as follows: $$A = B \Rightarrow \lim_{n\rightarrow\infty} x_n = A.$$ This implies that $c_1+c_2 = 1$ . How to obtain these recursions? The case $\sqrt{2}$ can be derived from this other question . To me, it is the most interesting case as it allows you to study the digits of $\sqrt{2}$ in base 2. Some of these recursions can be computed with WolframAlpha, see here for the exponential case, and here for $\sqrt{2}$ . Numerous other recurrences, with much faster convergence, can be derived from combinatorial sums featured in this WA article . My question I am looking for some literature on these linear, non-homogeneous second order recurrences involving polynomials of degree $1$ . Also, I will accept any answer for a recurrence that yields $\pi$ . Should be easy, using formulas (37) or (38) in this article as a starting point. If you find my question too easy, here is one that could be much less easy: change the initial conditions to $x_0=A, x_1=B$ in any of these formulas, and see if you can get convergence to a known mathematical constant.","['limits', 'irrational-numbers', 'recurrence-relations', 'real-analysis']"
3491359,Сharacteristic property of polynomials with integer coefficients,"Here is the problem which was proposed on some contest. Problem. Polymomial $P(x)$ is satisfying the following conditions If $x\in\mathbb{Z}$ then $P(x)\in \mathbb{Z}$ ; For every positive integer $n$ and for every integer $x$ the sequence $x, P(x), P(P(x)), \dots$ is periodic modulo $n$ . Prove that $P(x)\in\mathbb{Z}[x]$ i. e. all coefficients of $P(x)$ are
integers. Comment. In this problem we call the sequence $\{a_n\}_{n=1}^{\infty}$ periodic if there are positive integers $n_0$ and $t$ such that for all $n\ge n_0$ the equality $a_{n}=a_{n+t}$ holds. It's well-known that all polynomials which satisfy first condition are linear combinations with integer coefficients of polynimials $p_k(x)$ , where $$
p_k(x):=\binom{x}{k}=\frac{x(x-1)\ldots(x-k+1)}{k!}.
$$ Hence, there are integers $c_0,c_1,\ldots, c_n$ such that $$
P(x)=\sum_{k=0}^{n}c_k\cdot p_k(x).
$$ Then, we need to prove that $k!\mid c_k$ for $k\ge 0$ (it's equivalent to $P(x)\in\mathbb{Z}[x]$ ). However, it's unclear how we should use the second condition.
It can be shown that polynomial $c\cdot p_r(x)$ where $r$ is a prime number doesn't satisfy the second condition if $r\nmid c$ (consider modulo $n=r$ in the second condition; it requires some work). It's hard even in this case to prove that $r!\mid c$ . Moreover, it's clear that polynomials with integer coefficients satisfy both conditions. That's why this actually is a characteristic property of such polynomials. Let me explain why the polynomial $P(x)=\frac{x(x-1)}{2}$ doesn't satisfy the conditions of the problem. Proof. Suppose the contrary. Define the sequence $\{x_k\}_{k=1}^{\infty}$ as follows: $$
x_0=4,
\\
x_{k+1}=P(x_k).
$$ It's clear that $\{x_n\}_{k=1}^{\infty}$ is an increasing sequence of positive integers.
From the second condtion for $n=2$ we obtain that there are positive integers $k_0$ and $t$ such that $x_{k+t}\equiv x_k\pmod 2$ for all $k\ge k_0$ . Hence, for all $k\ge k_0$ we have $x_{k+t}-x_k\equiv 0\pmod 2$ . Note that $x_{k_0+t}-x_{k_0}>0$ , so there is an $s$ such that $2^s\mid x_{k_0+t}-x_{k_0}$ , but $2^{s+1}\nmid x_{k_0+t}-x_{k_0}$ . Now, define the new sequence $\{a_k\}_{k=k_0}^{\infty}$ as $a_k:=x_{k+t}-x_k$ .
Notice that $a_k\equiv 0\pmod 2$ for all $k$ and $$
a_{k+1}=P(x_{k+t})-P(x_k)=\frac{x_{k+t}-x_k}{2}\cdot(x_{k+t}+x_k+1)=
\frac{a_k}{2}\cdot(x_{k+t}+x_k+1).
$$ Due to our assumption $x_{k+t}+x_k+1$ is an odd number. Thus, the sequence of 2-adic valuations of $a_k$ is a strcictly decreasing sequence, which is impossible beacuse all $a_k$ are integers (or, equivalently, $a_{k_0+s}$ is odd which contradicts $a_{k}\equiv 0\pmod 2$ ). Therefore, $P(x)$ doesn't satisfy the conditions of the problem, as desired. How we can approach this problem? Update. Actually, as WhatsUp noticed the statement of the problem is wrong, namely, the polynomial $P(x)=\frac{(x^2-x)^2}{2}$ is a counterexample. For more details see WhatsUp's answer below.","['contest-math', 'number-theory', 'polynomials']"
3491369,"Prove that $F_2$ is a subgroup of $F_3$, and construct a covering space of $S^1\vee S^1\vee S^1$ corresponding to this subgroup","As the title explains, I'm working on a question that asks me to prove that $F_2$ is a subgroup of $F_3$ , and construct a covering space of $S^1\vee S^1\vee S^1$ corresponding to this subgroup. If take $F_3$ = $\langle a, b, c\rangle$ then we can just take the subgroup generated by $\langle ab, c\rangle$ and it's easy to find an isomorphism from this to $F_2$ by mapping the generators to each other, but I'm not sure how I'd go about finding a covering space that corresponds to it. Any suggestions would be appreciated.","['group-theory', 'free-groups', 'covering-spaces', 'general-topology', 'algebraic-topology']"
3491379,Prove that $\lim_{x\to0}f(x)=\lim_{x\to0}f(x^3)$,"I'm not really sure how to do this. Is $(1)$ the way to go? $$\lim_{x\to0}f(x)-f(x^3)=0 \tag 1$$ What I tried to prove was $(2)$ with the stipulation that $x:=t^3$ . $$\lim_{x\to0}f(x) = L \iff \lim_{t\to0}f(t^3)=L \tag 1$$ Left to right : we know $|f(x)-L|<\epsilon$ when $0<|x|<\delta$ . Let $\delta':=\min\{1/2, \delta^3\}$ , so that if $|x|<\delta'$ , then $|t|<\delta$ . Then $|f(t^3)-L|<\epsilon$ . Right to left : we know $|f(t^3)-L|<\epsilon$ when $0<|t|<\delta$ . Let $\delta':=\min\{1/2, \delta\}$ , so that if $|t|<\delta'$ , then $|x|<\delta$ . Then $|f(x)-L|<\epsilon$ . Is this correct? Did I overcomplicate things?","['limits', 'real-analysis']"
