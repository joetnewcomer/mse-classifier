question_id,title,body,tags
1588412,Find a example such $\frac{(x+y)^{x+y}(y+z)^{y+z}(x+z)^{x+z}}{x^{2x}y^{2y}z^{2z}}=2016$,"Assume $x,y,z$ be postive integers,and Find  one  example $(x,y,z)$ such
$$\dfrac{(x+y)^{x+y}(y+z)^{y+z}(x+z)^{x+z}}{x^{2x}y^{2y}z^{2z}}=2016$$","['number-theory', 'diophantine-equations']"
1588416,"Three-gap problem, easy version.","Let $N$ be a positive integer and $\theta$ an angle in $(0, 2\pi)$. Consider the map$$f: \{0, 1, 2, \dots, N-1, N\} \to  \text{unit circle}, \text{ }f(k) = k\theta \text{ }(\text{mod } 2\pi).$$Show that the image of $f$ divides the circle into arcs of $1$, $2$, or $3$ different lengths.","['real-analysis', 'diophantine-approximation', 'trigonometry', 'complex-analysis', 'contest-math']"
1588421,shortest distance from point to hyperplane lagrange method,"I need to find the shortest distance, in D-dimensional Euclidean space ($\mathbb{R}^D$) from a point $\textbf{x}_0$ to a hyperplane $H: \textbf{w}^T \textbf{x} + b = 0$, using the method of Lagrange multipliers. The answer should be an expression in terms of $\textbf{w}, b$ and $\textbf{x}_0$. Note: I am aware that a few similar questions exist, such this one. I am creating a new question because I need to know how the derivation steps work in order to get a solution in a specific form. I know how to solve this problem in three dimensions, but not with linear algebra. Any help would be appreciated.","['linear-algebra', 'lagrange-multiplier']"
1588450,Measure theory for self study. [duplicate],This question already has answers here : Self-Studying Measure Theory and Integration (4 answers) Closed 8 years ago . I have good knowledge of Elementary Real analysis. Now I'd like to study measure theory by myself (self-study). So please give me direction for where to start? Which book is good for starting? I have Principles of Mathematical Analysis by W. Rudin and Measure Theory and Integration by G. de Barra. Which book is rich in examples and exercises? Please suggest to me. Thanks in advance.,"['self-learning', 'reference-request', 'lebesgue-measure', 'book-recommendation', 'measure-theory']"
1588479,Geometric derivation of the quadratic equation,The quadratic equation can be thought of as specifying distances in the Euclidean plane. It tells us that the $x$-intercepts of a function occur at a distance of $\frac{\sqrt{b^2-4ac}}{2a}$ from the $x$ coordinate of the max/min point. Does anyone know a purely geometric derivation of the quadratic formula related to this fact?,"['quadratics', 'conic-sections', 'geometry']"
1588484,when is it safe to swap the order of differentiation with integration?,"Let $f(u)=\cos u$ and 
$$g(u)=1-u^2,-1\leq u \leq 1;g(u)=0, otherwise\tag{0}$$.
Thus
$$\partial_u^2g(u)=-2,-1\leq u \leq 1;\partial_u^2g(u)=0, otherwise\tag{1}$$. Let $h(u)$ be the convolution of $f(u)$ and $g(u)$:
$$h(u):=\int_{-\infty}^{\infty}f(u-x)g(x)\mathrm{d}x=4\cos u (\sin1-\cos1)\tag{2}$$. So
$$h(u)=\int_{-\infty}^{\infty}g(u-x)f(x)\mathrm{d}x=4\cos u (\sin1-\cos1)\tag{3}$$. From $h(u)=4\cos u (\sin1-\cos1)$, we have:
$$\partial_u^2h(u)=-4\cos u (\sin1-\cos1)\tag{4}$$. From
$$\partial_u^2h(u)=\int_{-\infty}^{\infty}g(x)\partial_u^2f(u-x)\mathrm{d}x\tag{5},$$
we obtain
$$\partial_u^2h(u)=\int_{-1}^{1}(1-x^2)(-\cos(u-x))\mathrm{d}x=-4\cos u (\sin1-\cos1)\tag{6}$$. From
$$\partial_u^2h(u)=\int_{-\infty}^{\infty}f(x)\partial_u^2g(u-x)\mathrm{d}x\tag{7},$$
we obtain
$$\partial_u^2h(u)=\int_{u-1}^{u+1}\cos x(-2)\mathrm{d}x=-4\cos u (\sin1)\tag{8}$$. Question: The results for $\partial_u^2h(u)$ that we obtain from (4) and (6) are the same and seem to be correct. But result for $\partial_u^2h(u)$ that I obtain from (8) seems to be wrong. What is the problem? Thanks-
mike Update If we define $g(u)$ in terms of HeavisideTheta function as
$$g(u) := (1 - u^2) HeavisideTheta(1 - u) HeavisideTheta(1 + u)\tag{9}$$
Then we get the right result from (7):
$$\partial_u^2h(u)=\int_{-\infty}^{\infty}f(x)\partial_u^2g(u-x)\mathrm{d}x=-4\cos u (\sin1-\cos1)\tag{8b}$$.","['derivatives', 'integration', 'functions']"
1588486,A categorical perspective on the equivalence of sheaf cohomology and Cech cohomology?,"In the nLab article on cohomology , I found the following passage. One can then understand various ""cohomology theories"" as nothing but
  tools for computing $\pi_0 \mathbf{H}(X,A)$ using the known
  presentations of (∞,1)-categorical hom-spaces: for instance Čech
  cohomology computes these spaces by finding cofibrant models for the
  domain $X$, called Čech nerves. Dual to that, most texts on
  abelian sheaf cohomology find fibrant models for the codomain $A$:
  called injective resolutions. Both algorithms in the end compute the
  same intrinsically defined $(\infty,1)$-categorical hom-space. I find this paragraph incredibly interesting, since it offers a conceptual explanation for why Čech cohomology should agree with sheaf cohomology in certain cases. (I believe the usual proof for schemes uses a spectral sequence argument, which seems opaque to me.) Unfortunately, I do not know any higher category theory. In broad strokes--at a level accessible to someone with just a first course in algebraic topology and homological algebra--what is going on here? Also, what's a good reference that explains the details?","['algebraic-geometry', 'sheaf-cohomology', 'homological-algebra', 'higher-category-theory', 'algebraic-topology']"
1588490,Cubic hypersurfaces through 5 generic lines in $\mathbb{P}^3$,"Consider 5 generic lines $l_1, \dots, l_5 \subset \mathbb{P}^3$ (in particular, they do not intersect). Denote by $Z$ their union.
$$\dim H^0 \big( \mathbb{P}^3, \mathcal{O}_{\mathbb{P}^3} (3) \big) = \binom{3+3}{3} = 20$$ $$\dim H^0 \big( \mathbb{P}^3, \mathcal{O}_Z(3) ) = 5 \dim H^0( \mathcal{O}_{\mathbb{P}^1} (3) \big) = 5 \times 4 = 20$$ Consider restriction map $R$ $$R: H^0 \big( \mathbb{P}^3, \mathcal{O}_{\mathbb{P}^3} (3) \big) \rightarrow H^0 \big( \mathbb{P}^3, \mathcal{O}_Z(3) \big)$$ Question Is $R$ isomorphism? Comment 1. You can reformulate this if you wish. Are there cubic hypersurfaces, passing through these 5 lines? What is $H^1 \big( I_Z(3) \big)$, where $I_Z$ - sheaf of ideals. Comment 2. My question is particular case of this question. I tried to consider case by case. It is the easiest example, where I do not know the answer.","['polynomials', 'algebraic-geometry']"
1588528,Finite index of a subgroup of an infinite group,"It's mentioned in herstein that there can be infinite groups whose subgroups have finite index.
I cannot think of any examples.
Some examples would be useful",['group-theory']
1588532,Locus formed by point on a line intersecting 3 other lines in 3D,"I got this particular question from an old test paper... Consider three lines given by $y-2=z+3=0$ ; $z-3=x+1=0$ ; $x-1=y+2=0$ . Let $(\alpha,\beta,\gamma)$ be a point lying on a line intersecting the given three lines. Then the locus generated by $(\alpha,\beta,\gamma)$ is a. $\quad$ $xy+3yz+2xz+6=0$ b. $\quad$ $3xy+yz+2xz+6=0$ c. $\quad$ $2xy+3yz+xy+6=0$ d. $\quad$ none of these I suppose that the intersecting line is as $$\frac{x-\alpha}{l}=\frac{y-\beta}{m}=\frac{z-\gamma}{n}$$ where $l,m,n$ are direction ratios. Now I can't understand how to proceed from here. Please help me out...","['analytic-geometry', '3d', 'geometry']"
1588542,Prove This Inequality ${\pi \over 2} \le \sum_{n=0}^{\infty} {1 \over {1+n^2}} \le {\pi \over 2} + 1$,"$${\pi \over 2} \le \sum_{n=0}^{\infty} {1 \over {1+n^2}} \le {\pi \over 2} + 1$$ I see I should use Riemann sum, and that
$$\int_0^{\infty} {dx \over {1+x^2}} \le \sum_{n=0}^{\infty} {1 \over {1+n^2}}$$ But how do I explain this exactly, and how to get the other half of the inequality (with ${\pi \over 2} + 1$)?","['calculus', 'improper-integrals', 'integration', 'riemann-sum', 'sequences-and-series']"
1588550,Every set is a union of singleton sets,"Is it possible to prove this statement? What axioms are necessary to conclude that every set on, for instance, $\mathbb{R}$ can be expressed as a union of singleton sets (sets containing exactly one element)? Let $X=\{x : P\}$ where $P$ is a defining property of the elements of $X$, for instance $P$ can be $x>2$. Then I can simply state that $$X = \bigcup_{P} X_i$$ where $\{X_i : i \in \mathbb{R_+}\}$ is a collection of all singleton sets of $\mathbb{R}$. By the way, there are sets of bigger cardinality than of cardinality of all real numbers. In this case, using $\mathbb{R_+}$ as indexes for all singleton sets from such sets wouldn't be sufficient, right?",['elementary-set-theory']
1588584,When can stalks be glued to recover a sheaf?,"Let $\mathcal{F}$ be a sheaf over some topological space. The stalks are $\mathcal{F}_x= \underset{{x\in U}}{ \underrightarrow{\lim}} \mathcal{F}(U)$. Is there a special name for a sheaf that satisfies  $\mathcal{F}(U) = \underset{{x\in U}}{ \underleftarrow{\lim}} \mathcal{F}_x$? Obviously this is a very restrictive property but here's a possible example: Let $X=Spec A$ be an affine integral scheme with structure sheaf $\mathcal{O}_X$. We have: $$\mathcal{O}_{X,x}= \underset{{x\in X_f}}{ \underrightarrow{\lim}} \mathcal{O}_X(X_f)=\underset{{f \notin \mathfrak{p}_x}}{\underrightarrow{\lim}} A_f = \bigcup_{f \notin \mathfrak{p}_x} A_f$$ 
But we also have (I hope): $$\mathcal{O}_X(X_f)=A_f= \bigcap_{f \notin \mathfrak{p}_x  \subset A} A_{\mathfrak{p}_x}=\underset{{f \notin \mathfrak{p}_x}}{\underleftarrow{\lim}} A_{\mathfrak{p}_x}=\underset{{x \in X_f}}{\underleftarrow{\lim}} \mathcal{O}_{X,x}$$ So we can recover the structure sheaf as a limit of the stalks. Does it still hold for non affine scheme? More generally: When is a sheaf the inverse limit of its stalks? Can I turn this into a technique for constructing sheaves? Let $F: |X| \to Ab$ be a functor from the category of points of $X$ to Abelian groups. Now define: $$\mathcal{F}(U) = \underset{{x\in U}}{\underleftarrow{\lim}} F(x)$$ If I take stalks and then do the above will I get back to the same
  sheaf? (Possibly after sheafication). EDIT: Some details are missing. Whenever I'm taking limit of stalks, the category I'm taking the limit over is the poset of the points of the space. Where we have $x_0 \to x$ Iff $x$ is a generization of $x_0$ (i.e. if $x_0 \in \overline{\{x\}}$).","['category-theory', 'schemes', 'sheaf-theory', 'algebraic-geometry']"
1588585,Check if a Function is Differentiable at a Point,"Let 
  $$f(x)=
\begin{cases}
x+1 & x\leq0 \\
3^{-x} & x>0
\end{cases}$$ Is the function differentiable at $x=0$? I should look at the limits $$\lim_{h\to 0-} \frac{x+h+1-(x+1)}{h}$$ and $$\lim_{h\to 0+} \frac{3^{-(x+h)}-3^{-x}}{h}$$ What would I do if the point was for example $x=3$?","['algebra-precalculus', 'derivatives', 'calculus', 'limits']"
1588597,Definitions of the extended real number system: Baby Rudin vs Tom M. Apostol's _Mathematical Analysis_ 2nd edition,"I have of late had the chance to go through Chapter 1 of each of the following two books: Principles of Mathematical Analysis by Walter Rudin, 3rd edition Mathematical Analysis by Tom M. Apostol, 2nd edition The first chapters of both of these books is about the real and complex number systems, the extended real and complex number systems, and $\mathbb{R}^n$. In Definition 1.23, Rudin defined the extended real number system as the real field $\mathbb{R}$ and two symbols, $+\infty$ and $-\infty$, with the definitions that, for every $x \in \mathbb{R}$, $$-\infty < x < +\infty, \ \ \ x+\infty= +\infty, \ \ \ x-\infty = - \infty, \ \ \ {x \over +\infty} = {x \over -\infty} = 0, \ \ \ .$$
If $x \in \mathbb{R}$ and $x > 0$, then 
$$x \cdot (+\infty) = + \infty, \ \ \ \mbox{ and } \ \ \ x \cdot (-\infty) = - \infty.$$
On the other hand, if  $x \in \mathbb{R}$ and $x < 0$, then 
$$x \cdot (+\infty) = - \infty, \ \ \ \mbox{ and } \ \ \ x \cdot (-\infty) = + \infty.$$ That's all that Rudin defines. Now in Definition 1.24 in his book, Tom M. Apostol defines the extended real number system as the set of real numbers together with two symbols $+\infty$ and $-\infty$ which satisfy the following properties. (a) If $x \in \mathbb{R}$, then we have 
$$x+(+\infty) = +\infty, \ \ x+(-\infty)= -\infty, \ \ x-(+\infty) = - \infty, \ \  x-(-\infty)=+\infty, \ \ {x \over +\infty}= {x \over -\infty}=0.$$
(b) If $x > 0$, then we have 
$$x(+\infty)=+\infty, \ \ \ x(-\infty)=-\infty.$$
(c) If $x < 0$, then we have 
$$x(+\infty)=-\infty, \ \ \ x(-\infty)=+\infty.$$
(d)
$$(+\infty)+(+\infty)=(+\infty)(+\infty)=(-\infty)(-\infty)=+\infty.$$
$$(-\infty)+(-\infty)=(+\infty)(-\infty)=-\infty.$$
(e) If $x \in \mathbb{R}$, then we have $-\infty<x< +\infty$. Although both the books are about mathematical analysis, Apostol assumes much more than Rudin does about $\pm\infty$. Why? What is the justification for these discrepencies? Which definition is the more standard one? How does Rudin manage to do without what Apostol defines in part (d) above?",['analysis']
1588626,A combinatorial identity involving generalized harmonic numbers,"[This problem has now an answer here .] The $n$-th harmonic number is defined as
$$
H_n=\sum_{k=1}^{n}\frac{1}{k},
$$
and the generalized harmonic numbers are defined by
$$
H_{n}^{(r)}=\sum_{k=1}^{n}\frac{1}{k^r}.
$$
Recently, I have found the following combinatorial identity involving the second-order harmonic numbers (I have computational evidence). Question: \begin{align}
\sum_{s=0}^{m}{2s\choose s}{s\choose m-s}\frac{(-1)^s }{s+1}H_{s}^{(2)}=\frac{2(-1)^m}{m+1}\sum_{s=0}^m H_{s}^{(2)}. 
\end{align}
Is this a known combinatorial identity? Any proof or reference?
However, if I replace $H_s^{(2)}$ by other generalized harmonic numbers in the above identity, I can not find some similar identities. Comments: (1) This combinatorial identity was motivated by the following identity
\begin{align}
\sum_{s=0}^{m}{2s\choose s}{s\choose m-s}\frac{(-1)^s}{s+1}=(-1)^m.
\end{align}
One can refer to How to prove $\sum_{s=0}^{m}{2s\choose s}{s\choose m-s}\frac{(-1)^s}{s+1}=(-1)^m$? (2) This problem has also been posted here . I appreciate any hints, pointers etc.!","['combinatorics', 'summation', 'binomial-coefficients']"
1588630,Existence of Solutions to a $2-$Equation System of Congruences [duplicate],"This question already has answers here : Are there $a,b>1$ with $a^4\equiv 1 \pmod{b^2}$ and $b^4\equiv1 \pmod{a^2}$? (2 answers) Closed 8 years ago . Do there exist $a, b> 1$, such that $$ a^4 \equiv 1 \pmod{b^2}$$ and $$ b^4 \equiv 1 \pmod{a^2}.$$","['number-theory', 'modular-arithmetic', 'discrete-mathematics']"
1588638,What is the $n^{th}$ derivative of $\log_x(e)$?,"I happened to stumble upon the integral of $\log_x(e)$, finding it to apparently be non-elementary. So I had to see if I could discern a pattern by differentiating, much like finding the integral of $W(x)$. $$f(x)=\log_x(e)=\frac1{\ln(x)}$$$$f'(x)=-\frac 1{x\ln(x)^2}$$$$f^{\prime\prime}(x)=\dfrac1{(\ln x)^2}+\dfrac1{2x^2(\ln x)^3}$$ Hopefully, there is a pattern that can be used to find $f^{(n)}$. So please find $f^{(n)}$ and if we can, substitute $n=-1$ to find the integral of the function.","['derivatives', 'logarithms', 'integration']"
1588650,Prove that $\lim_\limits{x\to 2}f(x)=3.$ [duplicate],"This question already has answers here : Nowhere continuous function limit (3 answers) Proof that the Dirichlet function is discontinuous (4 answers) Closed 8 years ago . Let: $$f(x) =
\begin{cases}
5-x,  & \text{if $x$ is irrational.} \\[2ex]
1+x, & \text{if $x$ is rational.}
\end{cases}$$ Prove that $\lim_\limits{x\to 2}f(x)=3.$ Prove that $\lim_\limits{x\to 0}f(x) $ doesn't exist. Solution Attempt: I want to use the definition of continuity. by saying that for each each $\epsilon>0$ there is a $\delta>0$ s.t. $|x-2|<\delta$  $\Rightarrow$ $|f(x)-f(2)|<\epsilon$. and somehow I thought about using the qualities of $|f(x)|$ and try to get that an equation that might help me in the proof. but got stuck there. any help?","['continuity', 'calculus', 'limits']"
1588659,An infinite nested radical problem,"From this link , problem 36, I found that $$\sqrt{4+\sqrt{4+\sqrt{4-\sqrt{4+\sqrt{4+\sqrt{4-...}}}}}}=2\left(\cos{\dfrac{4\pi}{19}}+\cos{\dfrac{6\pi}{19}}+\cos{\dfrac{10\pi}{19}}\right).$$
The signs : + + - + + - + + - ... . How to prove it? Furthermore, how to represent $\sqrt{7+2\sqrt{7-2\sqrt{7-2\sqrt{7+2\sqrt{7-2\sqrt{7-...}}}}}}$ by trigonometric function ? The signs : + - - + - - + - - ... . Thanks for helping.","['nested-radicals', 'trigonometry', 'sequences-and-series']"
1588712,Different geometric figures from trapezoids,"I have recently bought a very interesting a Brazilian kit to my kid to build mosaics: It is easy to see that I am able to generate equilateral triangles, hexagons, parallelograms, Rhombuses etc. Furthermore, it is easy to see that the base angles are equal to 60 degrees. I wonder if there are other interesting geometric figures that can be built using this kit. If the bases angles of the basic trapezoid were equal to 45 degrees the Rhombus that I built would be a square. However, until now I am not able to build a square using this kit. Are there geometric algorithms that can be used to study this kind of problem? EDIT: What cannot be made with this kit? How can I prove this statement?","['algorithms', 'geometry']"
1588720,How to solve $\sqrt {1+\sqrt {4+\sqrt {16+\sqrt {64+\sqrt {256\ldots }}}}}$,How to solve this equation? $$x=\sqrt {1+\sqrt {4+\sqrt {16+\sqrt {64+\sqrt {256\ldots }}}}}.$$ Answer: $x=2$,"['algebra-precalculus', 'contest-math', 'nested-radicals']"
1588733,Calculate $\lim_{n \to \infty}\binom{2n}{n}$ without using L'Hôpital's rule.,"Questions: (1) Calculate $$\lim_{n \to \infty}\binom{2n}{n}$$ (2) Calculate $$\lim_{n \to \infty}\binom{2n}{n} 2^{-n}$$ without using L'Hôpital's rule. Attempted answers: (1) Here I start by using the definition of a binomial: $$\lim_{n \to \infty}\binom{2n}{n} = \lim_{n \to \infty} \frac{(2n)!}{n!(2n-n)!} = \lim_{n \to \infty} \frac{(2n)!}{n!n!} = \lim_{n \to \infty} \frac{2n \cdot (2n-1) \cdot (2n-2) \cdot ... \cdot (n + 1) \cdot n!}{n! \cdot n!}$$ Canceling one n! gives: $$\lim_{n \to \infty} \frac{2n \cdot (2n-1) \cdot (2n-2) \cdot ... \cdot (n + 1)}{n!}$$ Here I argue that, surely, the numerator grows faster than the denominator and so the result must be that the limit grows towards $\infty$. Is this sufficiently mathematically rigorous? (2) My first attempt looked at the binomial theorem in an effort to get the expression to look something like the general form: $$(a+b)^{n} = \sum_{k=0}^{n} a^{k} b^{n-k}$$ but it does not quite seem to match, since $k$ would have to be $0$ so that $a$ becomes $= 1$ does not interfere, but then $n-k$ would be $n$ instead. My second attempt was to do what I did in (1), but then multiply it by $2^{-n}$: $$\lim_{n \to \infty} \frac{2n \cdot (2n-1) \cdot (2n-2) \cdot ... \cdot (n + 1)}{n!} \cdot \frac{1}{2^{n}}$$ Now we can cancel one of the $2$s in the $2^{n}$ for every second factor in the numerator since they (i.e. 2n, 2n-2) are divisible by 2. But there are n factors in the numerator, so at most $\frac{n}{2}$ factors can be canceled. Issues: (a) is my answer to (1) sufficiently mathematically rigorous? Is it really ""obvious"" that the numerator grows faster or are there additional arguments that should be provided for the argument to be convincing? (b) what are some more productive approaches to question (2)?","['binomial-theorem', 'calculus', 'limits-without-lhopital']"
1588775,Question on circle and equilateral triangles [duplicate],"This question already has an answer here : Prove the triangle is equilateral given that a quadrilateral related to its circumcircle is a kite (1 answer) Closed 8 years ago . Let $ABC$ be a triangle. Let $T$ be its circumcircle and let $I$ be its incenter. Let the internal bisectors of $A,B,C$ meet $T$ at $A',B',C'$ respectively. Let $B'C'$ intersect $AA'$ at $P$ and $AC$ at $Q$. Let $BB'$ intersect $AC$ at $R$. Suppose that the quadrilateral $PIRQ$ is a kite, i.e. $PI=IR$ and $QP=QR$: how to prove that triangle $ABC$ is a equilateral triangle?","['circles', 'triangles', 'geometry']"
1588777,Conjugacy Classes of the Quaternion Group $Q$,"I am trying to study the quaternion group $Q =\{\pm1,\pm i,\pm j,\pm k\}$, where $i^2 = j^2 = k^2 = -1$, $ij = k$, $jk = i$, $ki = j$. First, I'm trying to find the conjugacy classes of $Q$. The conjugacy class defined for an element $a$ in $Q$ is
$$ (a)=\{b = gag^{-1}\mid g\in Q\}. $$ I am trying $a=-i$ and found $$(-i)=\left\{i= 
\left\{ \begin{array}{c}
j\\
-j\\
k\\
-k\\
1\\
-1\\
\end{array}\right\}
\cdot-i\cdot
\left\{ \begin{array}{c}
-j\\
j\\
-k\\
k\\
1\\
-1\\
\end{array}\right\}\right\}$$ So, shouldn't the the elements $1$ and $-1$ follow also the rule to say that $(-i)=i$? I am quite confused, any hint is appreciated.",['group-theory']
1588798,How would Pythagorean's theorem work in higher dimensions? (General Question),So for example when dealing with two dimensions you would use $a^2 + b^2 = c^2$ and for three dimensions you would use $a^2 + b^2 + c^2 = d^2$ (Say for example you are calculating the length of the diagonal of a box) but what about in the fourth dimension? (Not really sure if there is a fourth dimension or how that even works in math so correct me if that makes no sense to say) Wouldn't it be something like $a^2 + b^2 + c^2 + d^2 = e^2$ ?,['geometry']
1588818,Prove $1^2-2^2+3^2-4^2+......+(-1)^{k-1}k^2 = (-1)^{k-1}\cdot \frac{k(k+1)}{2}$,"I'm trying to solve this problem from Skiena book, ""Algorithm design manual"". I don't know the answer but it seems like the entity on the R.H.S is the summation for series $1+2+3+..$. However the sequence on left hand side is squared series and seems to me of the form: $-3-7-11-15\ldots $ I feel like its of the closed form: $\sum(-4i+1)$ So how do I prove that the equality is right?","['summation', 'sequences-and-series']"
1588844,What does vector mean in Linear Algebra?,"I have just started reading Linear Algebra and there are some basic things I cannot understand.
I read some answers on this site and also tried to search in some books but I didn't find a clear answer.
Here are few words form my textbook :
1. Here by VECTOR we do not mean the vector quantity which we have defined in vector algebra as a directed line segment.
2. Matrices having a single row or column are referred to as vectors.
3. I also watched a video in which at approximately 3:55 he says that a point in two dimensional real coordinate space is written in matrix form in LINEAR ALGEBRA. Now I'm confused! Since in the video it seems as a vector in LINEAR ALGEBRA is just same as a point in 1, 2, 3...n real coordinate spaces. But in my text book its written that vector is not the vector quantity! And I also read in a book in which it was written that we are using LINEAR word instead of VECTOR to avoid confusion! So is it really the difference in words? Why its not written clearly what the vector really is.","['linear-algebra', 'vector-spaces']"
1588854,Use of partial derivatives as basis vector,"I am trying to understand use of partial derivatives as basis functions from differential geometry In tangent space $\mathbb{R^n}$ at point $p$, the basis vectors $e_1, e_2,...,e_n$ can be written as $\frac {\partial}{\partial x^1} \bigg|_p,\frac {\partial}{\partial x^2} \bigg|_p,...,\frac {\partial}{\partial x^n} \bigg|_p$ Let's say in 2 dimensional Euclidean space, a function $f : \mathbb {R^2}\rightarrow \mathbb {R^2}$ is $x^2 + y^2=4$ , a circle with radius 2. 
Tangent at point $p$ (2,0) will be $0e_1 + e_2$. 
If I say $f =x^2 + y^2-4 =0$, $\frac {\partial f}{\partial x} \bigg|_{p=(2,0)} = 4 \quad$ and   $\quad \frac {\partial f}{\partial y} \bigg|_{p=(2,0)} = 4$ This does not make sense of the partial derivatives as basis vectors. Any comments?","['multivariable-calculus', 'differential-geometry', 'manifolds']"
1588888,Path connectedness and convexity of some sets of matrices,I have no idea of proving the following statements: $GL_n(\mathbb C) = \{ M \in M_n(\mathbb C): \det(M) \neq 0 \} $ is open and path connected in $M_n(\mathbb C)$. Is it convex? $SL_n(\mathbb R) = \{ M \in GL_n(\mathbb R): \det (M) = 1 \}$ is closed and path connected in $M_n(\mathbb R)$ (Hint: using the fact that the polynominal function: $z \to \det((1-z)A + zB)$ has a finite number of roots). Is it convex? The set of diagonalisable matrices of $M_n(\mathbb R)$ is path connected. Is it open or closed? Is it convex? What is the general idea when dealing with the path connectedness of these sets of matrices?,"['matrices', 'general-topology', 'connectedness']"
1588898,How to prove $\sum\left(\frac{a}{b+c}\right)^2\ge \frac34\left(\frac{a^2+b^2+c^2}{ab+bc+ca}\right)$,"The question is to prove:
$$\left(\frac{a}{b+c}\right)^2+\left(\frac{b}{c+a}\right)^2+\left(\frac{c}{a+b}\right)^2\ge \frac34\left(\frac{a^2+b^2+c^2}{ab+bc+ca}\right)$$
$$a,b,c>0$$
I tried Cauchy, AM-GM, Jensen, etc. but had no luck. Thank you.","['algebra-precalculus', 'inequality']"
1588917,The Schwartz Class is dense in $L^p$,Is there any hint to prove that for every $1 \le p < \infty $ the Schwartz Class is dense in $L^p$ ? Thanks so much.,"['real-analysis', 'schwartz-space', 'lebesgue-measure', 'functional-analysis', 'lp-spaces']"
1588925,Can $\sqrt{ab}$ and $\sqrt{a^2 + b^2}$ be both integers if $a$ and $b$ are natural numbers?,Does there exist an $a \in \mathbb{N}$ and $b \in \mathbb{N}$ such that $\sqrt{ab} \in \mathbb{Z}$ and $\sqrt{a^2 + b^2} \in \mathbb{Z}$?,"['radicals', 'number-theory', 'elementary-number-theory', 'integers', 'pythagorean-triples']"
1588926,Is it really true that the Cartesian product $\mathbb R^2 \times \mathbb R^3$ is not equal to $\mathbb R^5$? [duplicate],"This question already has answers here : Associativity of Cartesian Product (1 answer) Some questions about the cartesian product (1 answer) Closed 8 years ago . This is probably going to turn out to be an embarrassment for me (took me an hour to get the courage to post this), but I can't figure this out. Using the definition of cartesian product from wikipedia , we have
$$\mathbb R^3=\big\{(x_1,x_2,x_3); x_1,x_2,x_3\in \mathbb R \big\}$$
$$\mathbb R^2=\big\{(x_1,x_2); x_1,x_2\in \mathbb R \big\}$$
$$\mathbb R^2 \times \mathbb R^3 = \big\{\big((x_1,x_2),(x_3,x_4,x_5)\big); (x_1,x_2) \in \mathbb R^2, (x_3,x_4,x_5) \in R^3 \big\} $$ Which does not seem to be equal to $\mathbb R^5$, which has $(x_1,x_2,x_3,x_4,x_5)$ as elements instead of ordered pairs of 2-tuples and 3-tuples. Please make the universe functional again, thanks!",['elementary-set-theory']
1588930,Separating numbers prime with $n$ in fixed length intervals .,"This question ( Proving for $n \ge 25$, $p_n > 3.75n$ where $p_n$ is the $n$th prime. ) led me to ask the following . Take $n>2$ a positive integer . Let $a_1,a_2,\ldots,a_{\phi(n)}$ be all the numbers less than $n$ and coprime with $n$ . Also denote $x=\frac{n}{\phi(n)}$ .
  Then for which $n$ ,the numbers $a_1,a_2,\ldots,a_{\phi(n)}$ will be separated from each other by the multiples of $x$ : $$0<a_1<x<a_2<2x<\ldots <a_{\phi(n)-1}<x(\phi(n)-1)<a_{\phi(n)}<x\phi(n)=n$$ All I know is that (miraculously) $n=30$ works  . I find this question very intriguing .
Thanks for everyone who can help me with this problem .","['inequality', 'divisibility', 'totient-function', 'number-theory', 'elementary-number-theory']"
1588938,Transformed probability distribution function (non-continuous transformation),"Let $$
F_X(x) = \left\{
\begin{array}{ll}
\frac{1}{3}e^x & x < 0\\
1 - \frac{1}{2}e^{-x} & x \geq 0
\end{array}
\right .
$$ What is the distribution of $Y = F(X)$? I have a hard time using common-known results due to the discontinuity and lack of inverse of $F$. I'm not looking for an answer but rather a general method to solve such problems. Thanks.","['probability-theory', 'probability', 'probability-distributions']"
1588955,"Lebesgue integral, Cavalieri's principle","Merry Christmas, Can you prove my answer: Let $B_r^n (p):=\{x\in\mathbb R^n \mid |x-p|\le r\}$ 
be the Ball with radius $r\in\mathbb R_{+}$
and origin $p\in\mathbb R$ and dimension $n\in\mathbb N$. Evaluate $\lambda_3(B_1^3(0)\cap(B_r^2(0)\times\mathbb R))$,
when $r\in (0,1)$ Answer:
I evalute the internal term:
$$B_1^3(0)\cap(B_r^2(0)\times\mathbb R)
=\{(x,y,z)\in\mathbb R^3\mid x^2+y^2+z^2\le 1;x,y,z\in (-1,0)\cup (0,1)\}$$ And with the Principle of Cavalieri, I get following integral: $$\int_{-1}^1 \int_{-1}^1 \int_{-\sqrt{1-x^2-z^2}}^{\sqrt{1-x^2-z^2}} \, dy \, dx \, dz=\frac{4}{3}\pi$$ Do you agree?","['real-analysis', 'lebesgue-integral', 'measure-theory']"
1588958,Knight returning to corner on chessboard -- average number of steps,"Context: My friend gave me a problem at breakfast some time ago. It is supposed to have an easy, trick-involving solution. I can't figure it out. Problem: Let there be a knight (horse) at a particular corner (0,0) on a 8x8 chessboard. The knight moves according to the usual rules (2 in one direction, 1 in the orthogonal one) and only legal moves are allowed (no wall tunnelling etc). The knight moves randomly (i.e. at a particular position, it generates a set of all possible and legal new positions, and picks one at random). What is the average number of steps after which the knight returns to its starting corner? To sum up: A knight starts at (0,0). How many steps on average does it take to return back to (0,0) via a random (but only legal knight moves) walk. My attempt: (disclaimer: I don't know much about Markov chains.) The problem is a Markov chain. There are $8\times8 = 64$ possible states. There exist transition probabilities between the states that are easy to generate. I generated a $64 \times 64$ transition matrix $M_{ij}$ using a simple piece of code, as it seemed too big to do by hand. The starting position is $v_i = (1,0,0,...) = \delta_{0i}$. The probability that the knight as in the corner (state 0) after $n$ steps is
$$
P_{there}(n) = (M^n)_{0j} v_j \, .
$$
I also need to find the probability that the knight did not reach the state 0 in any of the previous $n-1$ steps. The probability that the knight is not in the corner after $m$ steps is $1-P_{there}(m)$. Therefore the total probability that the knight is in the corner for the first time (disregarding the start) after $n$ steps is
$$
P(n) = \left ( \prod_{m=1}^{n-1} \left [ 1 - \sum_{j = 0}^{63} (M^m)_{0j} v_j \right ] \right ) \left ( \sum_{j = 0}^{63} (M^n)_{0j} v_j \right )
$$
To calculate the average number of steps to return, I evaluate
$$
\left < n \right >= \sum_{n = 1}^{\infty} n P(n) \, .
$$ My issue: The approach I described should work. However, I had to use a computer due to the size of the matrices. Also, the $\left < n \right >$ seems to converge quite slowly. I got $\left < n \right > \approx 130.3$ numerically and my friend claims it's wrong. Furthermore, my solution is far from simple. Would you please have a look at it? Thanks a lot!
-SSF","['combinatorics', 'markov-chains', 'probability', 'expectation']"
1588967,Does the following equation have only 1 solution of $n=2$?,"Conjecture: If $$I=\frac{1}{1+p_{n+1}}+\sum_{k=1}^{n}\frac{1}{p_k}$$ (where $p_n$ denotes the $n$'th prime) then $n=2$ is the only natural number for $n$ that makes $I$ an integer. All I really understand to do is to input numbers in for $n$. Beyond that, however, I am at a loss. I attempted using the knowledge that $$\sum_{k=1}^n \frac{1}{p_k}$$ Is never an integer (for $n>1$), but that really lead nowhere. I am looking for a proof of my conjecture.","['number-theory', 'prime-gaps']"
1588980,Convolution with a polynomial is a polynomial. Why?,"Let $P:\mathbb{R}\to\mathbb{R}$ such that $\deg P=N$. Let $f$, an integrable-$2\pi$-periodic function. Show that $f\star P$ is also a polynomial. So we can prove it for an arbitrary $x^n$ (Since a linear combination of polynomial is obviously a polynomial). $$f\star P = \frac{1}{2\pi}\int_0^{2\pi} f(x-t)t^n \ dt$$ It looks like I don't have any other information in order to proceed.
What am I missing?","['convolution', 'calculus']"
1588996,"Yet another log-sin integral $\int\limits_0^{\pi/3}\log(1+\sin x)\log(1-\sin x)\,dx$","There has been much interest to various log-trig integrals on this site (e.g. see [1] [2] [3] [4] [5] [6] [7] [8] [9] ).
Here is another one I'm trying to solve:
$$\int\limits_0^{\pi/3}\log(1+\sin x)\log(1-\sin x)\,dx\approx-0.41142425522824105371...$$
I tried to feed it to Maple and Mathematica , but they are unable to evaluate in this form. After changing the variable $x=2\arctan z,$ and factoring rational functions under logarithms, the integrand takes the form
$$\frac{2 \log ^2\left(z^2+1\right)}{z^2+1}-\frac{4 \log (1-z) \log \left(z^2+1\right)}{z^2+1}\\-\frac{4 \log (z+1) \log
   \left(z^2+1\right)}{z^2+1}+\frac{8 \log (1-z) \log (z+1)}{z^2+1}$$
in which it can be evaluated by Mathematica . It spits out a huge ugly expression with complex numbers, polylogarithms, polygammas and generalized hypergeometric functions (that indeed matches numerical estimates of the integral). It takes a long time to simplify and with only little improvement (see here if you are curious). I'm looking for a better approach to this integral that can produce the answer in a simpler form.","['logarithms', 'trigonometry', 'integration', 'definite-integrals', 'polylogarithm']"
1589048,"How do I calculate $1.496\,\text{E}11$? [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question Sorry for that noobie question but how do I calculate this type of number $1.496\,\text{E}11$?","['algebra-precalculus', 'arithmetic']"
1589050,Irreducible polynomial of degree $3$ and degree of extension,"Let's assume we have an irreducible polynomial of degree $3$ on $\mathbb{Q}$. What are the possibility of degree of extension given by a splitting field on $\mathbb{Q}$. That is, if $K$ is splitting field over $\mathbb{Q}$ for $p(x)$ of degree $3$. What are possibilities for $[K:\mathbb{Q}]$? My attempt:
I know that if we have $p(x)=x^3+1$ then the degree of extension is $2$ (this one will not work because later I knew $p(x)$ is reducible). But if $p(x)=x^3+2$ now the degree of extension will be $6$. So in general what is the right way to do this?","['irreducible-polynomials', 'splitting-field', 'abstract-algebra', 'extension-field', 'field-theory']"
1589077,Problem of limit of function of function,"So I tried solving this: https://brilliant.org/practice/level-2-4-limits-of-functions/?p=1 Got this: I'm completaly curious to know if this answer marked in green is right (which is the right answer according to the website). For me, the limit shouldn't exist, but if that wasn't the answer, it could, at best, be 6. Intuitively, saying that the answer is 5 would imply that you're taking the limit x -> 2- over x -> 2+ which doesn't make sense to me.",['limits']
1589079,Explanation of a step in a proof of Steinhaus' Theorem,"Disclaimer : I understand this theorem has been discussed before. I am not looking for a proof however, just a clarification of a mysterious step. I was reading a proof of the following version of Steinhaus' Theorem, and got stuck on one step: Theorem (Steinhaus) : Let $E \subset \mathbb{R}$ and $m(E)>0$, where $m$ denotes Lebesgue measure on $\mathbb{R}$. Then the set $E-E$
  contains an interval around zero. Proof : By the Lebesgue differentiation theorem, or, equivalently, by the definition of a Lebesgue point, there exists an interval $I$
  such that $$m(I\cap E) \geq (1-\epsilon)\,m(I).$$ If the result were not true, there would exist a sequence $x_n \rightarrow 0$ with $x_n \not \in E-E$. Take $n$ large enough that $|x_n|<\epsilon\, m(I)$. Then $x_n +E \subset \mathbb {R} \setminus E$, but $$\mathbf{m(I\cap (x_n+E))\geq (1-3\epsilon)\,m(I)}$$ (since Lebesgue measure is invariant under translations.) Since $E$ and $\mathbb R \setminus E$ are disjoint, this is a contradiction. The part I am having difficulty with is in bold characters. I believe it follows from the following: \begin{align*}
m(I\cap (x_n+E)) & = m(x_n+(I-x_n)\cap E) \\
& = m((I-x_n)\cap E) \\
& \geq m(I) - 2|x_n| - m(I \setminus E) \\
& \geq (1-3\epsilon)\,m(I)
\end{align*} Is this correct? If not, could you point out the correct steps? Thanks! Note : For the sake of completeness, $$E-E:=\{x-y:\ x,y\in E \}.$$","['real-analysis', 'lebesgue-measure', 'measure-theory']"
1589084,Special Vertex Partitioning,"When can we partition the vertices of a graph $G$ into $n$ subsets such that every vertex is adjacent to vertex from every subset? For example, in the following graph, we have partitioned the vertices into $2$ subsets. Is anything known about this type of partitioning? A motivation for studying these partitionings is that we can represent vertices as possible states and adjacent vertices as states reachable through one move. Then this partitioning allows us to convey certain messages no matter what the state.","['combinatorics', 'graph-theory', 'reference-request']"
1589095,Proof of how multiplicity in a polynomial works.,"In Algebra (2) I was told that if a polynomial had an even multiplicity for some $x=a$, then the graph touches $y=0$ at $x=a$ but doesn't cross $y=0$.  Odd multiplicities go through the $x$-intercept.  For example:$$y=x^2\to y=(x-0)(x-0)\to x=0,0$$And you can clearly see the graph ""touches without intersecting"" at $x=0$. However, I am confused on how this is proven.","['algebra-precalculus', 'polynomials']"
1589123,How to find $\lim_{t\to0}\bigg(\int_0^1[bx+a(1-x)]^tdx\bigg)^{1/t}$,"If $0\lt a\lt b$, I'm trying to find: $$\lim_{t\to0}\bigg(\int_0^1[bx+a(1-x)]^tdx\bigg)^{1/t}$$ Solving the integral by substitution we have: $$\lim_{t\to 0}\bigg(\frac{1}{b-a}\cdot\frac{b^{t+1}-a^{t+1}}{t+1}\bigg)^{1/t}$$ I don't how to proceed. What I know: This identity
$b^{t+1}-a^{t+1}=(b-a)(b^t+b^{t-1}a+\ldots+ba^{t-1}+a^t)$ This limit is in the form: $1^{\infty}$. I think I'm close, I need a hand how to find this limit.",['calculus']
1589133,Violating Cauchy's Integral Theorem,"With regards to utilizing Cauchy's Integral Theorem for integration over closed contours: https://en.wikipedia.org/wiki/Cauchy%27s_integral_theorem In particular the result that $\int_\gamma f(z)\,dz = 0$ for closed paths $\gamma$ and holomorphic functions $f(z)$. It is stated (and shown algebraically) in numerous tutorials and texts that $f(z)=z^{-1}$ violates the conditions for the above result to hold. But in all elaborations given to this statement it has not been clear to me why this is not also true for $z^{-2}$ (or indeed any $z^{n}$ for integers $n$ smaller than -1). For example, in the Wikipedia article linked, it states: ""The Cauchy integral theorem does not apply here since $f(z)=\frac1 z$
  is not defined (and certainly not holomorphic) at $z=0$."" Which I believe is also true for any other $f(z) = \frac 1 {z^n}$. Alternatively, a set of notes from the Columbia's Complex Analysis course state: $1/z$ is analytic in the region $\mathbb C − \{ 0 \} = \{z ∈ \mathbb C
> : z \neq 0\}$, but this region is not simply connected. Again believe this also applies to other $f(z) = \frac 1 {z^n}$. Could someone please clarify what exact condition $\frac 1 z$ violates that $\frac 1 {z^n}$ does not? P.S. Some background - I am not a mathematician by training but trying to teach myself for applied research, so answers that favor intuition are greatly appreciated!","['intuition', 'complex-analysis', 'contour-integration']"
1589160,"Tightness, relative compactness and convergence of stochastic processes","For proving the convergence of a certain sequence of stochastic processes (which take values on a compact set), I am taking the following approach (as taken in previous papers I am looking at): 1) First proving the sequence of stochastic processes is tight. 2) Having proven tightness, I try to identify a possible limit of the sequence of stochastic processes (e.g. using tools like Donsker's invariance principle). I want to understand why, with the relevant additional conditions, these two steps are sufficient for proving that the sequence of stochastic processes does indeed converge to the possible limit (which is also a stochastic process) I find in step 2 above. My understanding so far: By Prohorov's theorem on a family $\mathcal{M}$ of probability measures on a complete, separable metric space (S,d), tightness is equivalent to relative compactness. Here relative compactness is equivalent to saying every sequence in $\mathcal{M}$  has a subsequence which converges in $\mathcal{M}_1(S)$ (the complete space of probability measures in $(S,\mathcal{B}(S)))$. So taking the family of probability measures to be the laws of the stochastic processes in the sequence gives: if the sequence of stochastic processes is tight, then there is a subsequence which has a weak convergence limit. However, at this point I am lost- how can I now show that the entire sequence (rather than one of its subsequences) has a weak convergence limit? Do we need some form of Cauchy criterion now to be satisfied by the sequence, so that the subsequence limit turns out to indeed be the sequence limit under completeness? Thanks.","['stochastic-processes', 'probability-theory', 'weak-convergence', 'probability']"
1589180,Measurable sets are approximately open set.,"I am new in measure theory and studying N.L.Carothers Real Analysis book. It is said in this book that measurable sets are approximately open. How is it this? But it is also said that we say that a set $E$ is measurable if, for each $\epsilon>0$ we can find a closed set $F$ and an open set $G$ with $F\subset E\subset G$ such that $m^{*}(G\setminus F)<\epsilon.$  According to this definition can we say that measurable sets are approximately closed? I am confused please suggest me. I am learning measure theory by self-study. Please help me. Thanks a lot.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
1589181,"Constructing a function with N zeros inside the unit disk,","Find all functions $f(z)$ such that: a) $f$ is analytic in some region containing |z| $\le$ 1 b) $|f| = 1$ on $|z| =1$ c) $f$ has N simple zeros $z_1, ... , z_N$ inside $|z| < 1$ and no other zeros on $|z| \le 1$. Any ideas are welcome. I had initially thought that $z^N$ was a good candidate but it only fulfills parts a) and b); its zeros are at the origin, of multiplicity N. Thanks,","['analyticity', 'complex-analysis', 'complex-numbers']"
1589182,If $A^2=A$ then prove that $\textrm{tr}(A)=\textrm{rank}(A)$.,"Let $A\not=I_n$ be an $n\times n$ matrix such that $A^2=A$ , where $I_n$ is the identity matrix of order $n$.  Then prove that , (A) $\textrm{tr}(A)=\textrm{rank}(A)$. (B) $\textrm{rank}(A)+\textrm{rank}(I_n-A)=n$ I found by example that these hold, but I am unable to prove them.","['matrices', 'linear-algebra', 'linear-transformations', 'vector-spaces']"
1589199,"Prove that $f \left(\lambda x + (1- \lambda )x' , \lambda y +(1- \lambda )y' \right) > \min \{f(x,y), f(x',y')\}$","Let $f(x,y)=xy$ where $x,y\geq 0$. Prove that the function $f$ satisfies the following property: $$f \left(\lambda x + (1- \lambda )x' , \lambda y +(1- \lambda )y' \right) \geq \min \{f(x,y), f(x',y')\}$$
   for all $(x,y) \neq (x',y')$ and $ \forall\; \lambda \in (0,1)$ This is a problem from an olympiad book. My try:
The left side of the inequality is a quadratic in $\lambda$ i.e. $$ (x-x')(y-y')\lambda^2 + \left\{(x-x')y' + (y-y')x'\right\}\lambda + x'y'$$ I'm unable to find the minimum value of above quadratic in $(0,1)$. Also, how to deal with $\min{\{xy,x'y'\}}$. Thank you.","['contest-math', 'inequality', 'functions']"
1589202,Can you give me an example of topological group which is not a Lie group.,I know the definitions of Lie group and topological group are different. Can you give me an example of topological group which is not a Lie group.,"['abstract-algebra', 'topological-groups', 'general-topology', 'group-theory', 'lie-groups']"
1589205,Singularity of $\sum_{n=0}^\infty \frac{1}{z^{n}n!} $,What kind of singularity does this function have: $$\sum_{n=0}^\infty \frac{1}{z^{n}n!}.$$ It can have pole but its answer is still zero after multiplication by $z^n$ at $n=0$. Therefore the second choice is that it has an essential singularity. Is that correct?,['complex-analysis']
1589218,Finding the values of $q$ for which the quadratic equation $qx^2-4qx+5-q=0$ will have no real roots.,"Find the values of $q$ for which the quadratic equation $qx^2-4qx+5-q=0$ will have no real roots. So I've gotten as far as using the discriminant to find the values of $q$, but I'm stuck on the last step.
$$(-4q)^2-4(q)(5-q)<0$$
$$16q^2-4q(5-q)<0$$
$$16q^2-20q+4q^2<0$$
$$20q^2-20q<0$$
$$20q(q-1)<0$$
What step should be taken next to find the values of $q$? Thank you.","['algebra-precalculus', 'quadratics']"
1589239,Show an equilibrium $x=0$ is asymptotically stable,"Merry Xmas everyone! Hope you all had a great day:) I'm currently getting stuck on the following problem, due to the inability to use one of a key hypothesis given. Here is the problem: Given the system $\dot{x} = Ax + h(x)$ in $R^{n}$ where $A =  n\times n$ matrix such that all the eigenvalues of $A$ have real part $< 0$, and $h : R^n\rightarrow R^n$ satisfies $h(0) = 0$ and $ \lim_{x\rightarrow 0}\ \frac{|h(x)|}{|x|} = 0$ (this condition is equivalent to $h'(0) = 0$). Prove that the equilibrium $x = 0$ is asymptotically stable. My question: I can't see how the condition $h'(0) = 0$ comes into play. My idea is to use Variation of Parameters formula, but that formula doesn't have anything to do with $h'(0) = 0$. Can somebody please help me with the proof, or at least a new approach?",['ordinary-differential-equations']
1589245,Prove this inequality $\sum \cos{A}\ge\frac{1}{4}(3+\sum\cos{(A-B)})$,"Prove that in any triangle $ABC$ the following inequality holds
$$\cos{A}+\cos{B}+\cos{C}\ge\dfrac{1}{4}(3+\cos{(A-B)}+\cos{(B-C)}+\cos{(C-A)})$$ And I have gotten
$$8(\cos{A}+\cos{B}+\cos{C})\ge 6+2(\cos{(A-B)}+\cos{(B-C)}+\cos{(C-A)})$$ $$2(\cos{(A-B)}+\cos{(B-C)}+\cos{(C-A)})+3=(\sum_{cyc}\cos{A})^2+(\sum_{cyc}\sin{A})^2$$
$$\Longleftrightarrow 8\sum_{cyc}\cos{A}\ge 3+(\sum_{cyc}\cos{A})^2+(\sum_{cyc}\sin{A})^2$$
then Any hints, ideas? Thanks in advance.","['inequality', 'trigonometry']"
1589248,"If the sum of two independent random variables is $ L^{p} $, does it imply that each is $ L^{p} $?","Let $ X $ and $ Y $ be two independent random variables, i.e.,
$$
\forall a,b \in \Bbb{R}: \quad
\textbf{Pr}(X < a,Y < b) = \textbf{Pr}(X < a) ~ \textbf{Pr}(Y < b).
$$
Let $ p > 0 $ (not necessarily $ > 1 $). If $ \Bbb{E}[|X + Y|^{p}] < \infty $, how can we prove that $ \Bbb{E}[|X|^{p}] < \infty $?","['expectation', 'lp-spaces', 'probability', 'random-variables']"
1589255,Find the number of distinct throws which can be thrown with $n$ six faced normal dice which are indistinguishable among themselves.,Find the number of distinct throws which can be thrown with $n$ six faced normal dice which are indistinguishable among themselves. The total outcomes will be $6^n$. But this this has many cases repeated since the dice are indistinguishable among themselves.,['combinatorics']
1589260,"Solve the integral equation $f(x) = x + \lambda \int_0^1 f(z)\,dz$","Find a closed-form solution for $f(x)$ in the following equation $$
f(x) = x + \lambda \int_0^1 f(z)\,dz
$$
where $\lambda$ is a constant I tried integrating both sides from $0$ to $1$ but wasn't exactly sure where to go from there $$
\int_0^1 f(x) = \int_0^1 \left[x + \int_0^1 f(z)\,dz\right] dx
$$","['integral-equations', 'ordinary-differential-equations', 'calculus']"
1589284,Number of elements of order $2$ in Abelian groups of order $2^{n}$,"I'm self studying some group theory and one of the exercises I came across: Question: Prove that an Abelian group of order $2^{n}, n \in \mathbb{N}$ must have an odd number of elements of order 2. I'm not sure how to approach this problem. Any hints would be appreciated. Prefer no complete answers but could use one for self checking. Thank you.","['finite-groups', 'abelian-groups', 'group-theory']"
1589288,Applications of the law of the iterated logarithm,"The law of the iterated logarithm says that if $X_n$ is a sequence of iid
random variables with zero expectation and unit variance, then the partial
sums sequence $S_n = \sum_{i = 1}^n X_i$ satisfies almost surely that
$\limsup_{n \rightarrow \infty} \frac{S_n}{\sqrt{2 n \log{\log\ n}}} = 1$. What are the applications of this result? Why is it considered important or
even useful? I looked at the wikipedia article . It doesn't explain to me in detail where is this result applied. What major results are built from it or what major areas of applications are. What I am looking for is something like a list of major applications of that theorem. Like how is it used to proved other stuff.","['probability-limit-theorems', 'probability-theory', 'probability', 'statistics']"
1589307,Solutions of this system of differential equations stay in first quadrant,"How do I show that all solutions $x(t)$ and $y(t)$ of
$$\frac{dx}{dt}=x^2+y\sin x,$$
$$\frac{dy}{dt}=-1+xy+\cos y$$
which start in the first quadrant remain there for all time? I thought that looking at $$\frac{dy}{dx}=\frac{-1+xy+\cos y}{x^2+y\sin x}$$
could help, but I don't know what do with this.",['ordinary-differential-equations']
1589309,Show that $\int_0^1 (\ln x)^n dx =(-1)^n n!$,"How can I prove the following: 
$$\int_0^1 (\ln x)^n dx =(-1)^n n!$$
where $n$ is an integer and $n>0$? By using partial integration, I started by finding a reduction formula $$
\begin{align*}
I_n &= \int (\ln x)^n dx \\ &= x(\ln x)^n - nI_{n-1}
\end{align*}
$$ however the bounds 0 and 1 complicate things seeing as $\ln x \to -\infty \quad \mathrm{as} \quad x \to 0^+$","['integration', 'definite-integrals', 'calculus']"
1589320,What is the degree of the differential equation $\left|\frac{dy}{dx}\right| + \left|y\right| = 0$?,"Consider the differential equation $$\left|\frac{dy}{dx}\right| + \left|y\right| = 0$$ 
where $\left|\cdot\right|$ means the absolute value function. I have to find the degree of the above differential equation. Can I say the degree of this differential equation is not defined as it is not a polynomial in $y'$? If we further solve it, we get $$\left|\frac{dy}{dx}\right| = -\left|y\right|$$ Then taking square we get  $ \left(\frac{dy}{dx}\right)^{2}- y^{2} =0$ which has degree $2$. Now can I say that the two differential equation are not same? So the degree of the first one is not defined. Am I right?",['ordinary-differential-equations']
1589325,Markov Chain with two components,"I am trying to understand a question with the following Markov Chain: As can be seen, the chain consists of two components. If I start at state 1, I understand that the steady-state probability of being in state 3 for example is zero, because all states 1,2,3,4 are transient. But what I do not understand is that is it possible to consider the second component as a separate Markov chain? And would it be correct to say that the limiting probabilities of the second chain considered separately exist? For example, if I start at state 5, then can we say that the steady-state probabilities of any of the states in the right Markov chain exist and are positive?","['stochastic-processes', 'markov-chains', 'probability-theory']"
1589337,Confidence interval of the parameter of $\exp$ and normal distribution from MLE?,"I have a sample $X_1,X_2,\ldots,X_n$ If the sample is from exponential distribution, I want to use MLE to estimate the parameter $\beta$. I know the result that $$\hat{\beta}=\frac{X_1+X_2+\ldots+X_n}{n}$$But how can I calculate the $95\%$ confidence interval of $\beta$? If the sample is from normal distribution, I want to use MLE to estimate the parameter $\mu$ and $\sigma$. I also know the result that $$\hat{\mu}=\frac{X_1+X_2+\ldots+X_n}{n}, \quad \hat{\sigma}=\left[\frac{n-1}{n}\cdot S^2(n)\right]^{1/2}$$
But how can I calculate the $95\%$ confidence interval of $\mu$ and $\sigma$? Step1 to calculate confidence interval ,  $$\hat{θ}\pm z_{1-\frac\alpha2}\sqrt{\frac{\delta(\hat{θ})}{n}}$$ Step2 to calculate confidence interval $$\delta(\hat{θ})=-n\left(E\left[\frac{d^2}{dθ^2}\ln \mathcal L(θ)\right]\right)^{-1}$$ I know the equation, but I am still confuzed how to calculate $$\left(E\left[\frac{d^2}{dθ^2}\ln \mathcal L(θ)\right]\right)$$ I want to know the equation in the red frame of this picture.","['parameter-estimation', 'statistics', 'confidence-interval', 'statistical-inference']"
1589364,Simplify $\frac{4\sqrt{7}}{3}\cos{\left(\frac{1}{3}\arccos{\frac{1}{\sqrt{28}}}\right)}+\frac{1}{3}$,"If $\dfrac{2\sqrt{19}}{3}\cos{\left(\dfrac{1}{3}\arccos{\dfrac{7}{\sqrt{76}}}\right)}-\dfrac{1}{3}$ can be simpified to $2\left(\cos{\dfrac{4\pi}{19}}+\cos{\dfrac{6\pi}{19}}+\cos{\dfrac{10\pi}{19}}\right)$. How to simplify  $\dfrac{4\sqrt{7}}{3}\cos{\left(\dfrac{1}{3}\arccos{\dfrac{1}{\sqrt{28}}}\right)}+\dfrac{1}{3}$ ? edit :
Now, I have get the answer :
$$\dfrac{4\sqrt{7}}{3}\cos{\left(\dfrac{1}{3}\arccos{\dfrac{1}{\sqrt{28}}}\right)}+\dfrac{1}{3}=2\left(\cos{\dfrac{\pi}{7}}+\cos{\dfrac{2\pi}{7}}+\cos{\dfrac{3\pi}{7}}\right)$$ How to prove it?",['trigonometry']
1589377,Find $\lim_{n\to \infty} \int_n^{n+1} {\sin x \over x} dx$,"Find $\lim_{n\to \infty} \int_n^{n+1} {\sin x \over x}  dx$ I thought about defining $\space F(x) = \int_0^x {\sin t \over t}  dt \space$ and then the limit is $\space \lim_{n\to \infty} (F(n+1) - F(n))$, so the answer is 0? It doesn't seem ok","['integration', 'calculus', 'limits']"
1589378,Conformal reparametrization,"We consider $$\sigma (u,v)=(f(u)\cos v, f(u)\sin v, g(u))$$ Picking $u=\theta , v=\phi , f(\theta )=\cos \theta , g(\theta )=\sin \theta$ we get that the first fundamental form is $$d\theta^2+\cos^2 \theta d\phi^2$$ We consider the reparametrization $\tilde{\sigma}(u, v) = \sigma (\psi(u), v)$. I want to show that the reparametrization is conformal. I have done the following: The first fundamental form of $\tilde{\sigma}$ is $$(\psi '(u))^2du^2+\cos^2(\psi(u))dv^2$$ So that the reparametrization is conformal it must stand $$(\psi'(u))^2=\cos^2 (\psi (u)) \Rightarrow \psi '(u)=\pm \cos (\psi (u)) \Rightarrow \frac{d\psi}{du}=\pm \cos \psi \Rightarrow \frac{1}{\cos\psi}d\psi=\pm du$$ We have that $$\int \frac{1}{\cos \psi}d\psi=\ln \sqrt{\frac{1+\sin \psi}{1-\sin \psi}}+C=\ln \sqrt{\frac{(1+\sin \psi)(1-\sin \psi)}{(1-\sin \psi)^2}}+C \\ =\ln \sqrt{\frac{1-\sin^2\psi}{(1-\sin \psi)^2}}+C=\ln \sqrt{\frac{\cos^2\psi}{(1-\sin \psi)^2}}+C=\ln \frac{\cos\psi}{1-\sin \psi}+C$$ Therefore, we have the following: 
$$\int \frac{1}{\cos \psi}d\psi=\pm \int du \Rightarrow \ln  \frac{ |\cos\psi |}{1-\sin \psi}+C=\pm u \Rightarrow \ln  \frac{ |\cos\psi |}{1-\sin \psi}=\pm u-C\\ \Rightarrow   \frac{ |\cos\psi |}{1-\sin \psi}=\tilde{C}e^{\pm u}$$ Therefore, the smooth function $\psi$ that we are looking for is given by the relation $\frac{ |\cos\psi |}{1-\sin \psi}=\tilde{C}e^{\pm u}$, for $\cos\psi\neq 0$. Is this correct? Could we get a specific formula for $\psi$ ? How can we show that $\tilde{\sigma}$ is the Mercator parametrization $$\sigma (u,v)=(\text{sech } u \cos v, \text{sech } u \sin v, \tanh u)$$ ? $$$$ EDIT: The first fundamental form of $\tilde{\sigma}$ is $$(\psi '(u))^2du^2+\cos^2(\psi(u))dv^2$$ So that the reparametrization is conformal it must stand $$(\psi'(u))^2=\cos^2 (\psi (u)) \Rightarrow \psi '(u)=\pm \cos (\psi (u)) \Rightarrow \frac{d\psi}{du}=\pm \cos \psi \Rightarrow \frac{1}{\cos\psi}d\psi=\pm du$$ We have that $$\int \frac{1}{\cos \psi}d\psi=\frac{1}{2}\ln \frac{1+\sin \psi}{1-\sin \psi}+C=\text{arctanh } (\sin\psi)+C$$ Therefore, we have the following: 
$$\int \frac{1}{\cos \psi}d\psi=\pm \int du \Rightarrow \text{arctanh } (\sin\psi)+C=\pm u \Rightarrow  \text{arctanh } (\sin\psi)=\pm u-C\\ \Rightarrow   \sin\psi=\tanh (\pm u-C) \Rightarrow \psi=\text{arcsin } (\tanh (\pm u-C))$$ Therefore, the reparametrization is $$\tilde{\sigma}(u, v) = \sigma (\psi(u), v) \\ =(\cos (\text{arcsin } (\tanh (\pm u-C)) )\cos v, \cos (\text{arcsin } (\tanh (\pm u-C)) )\sin v, \sin (\text{arcsin } (\tanh (\pm u-C)) )) \\ =(\cos (\text{arcsin } (\tanh (\pm u-C)) )\cos v, \cos (\text{arcsin } (\tanh (\pm u-C)) )\sin v, \tanh (\pm u-C)) )\\ =(\sqrt{1-\tanh^2 (\pm u-C)}\cos v, \sqrt{1-\tanh^2 (\pm u-C)}\sin v, \tanh (\pm u-C)) )=(\text{sech } (\pm u-C)\cos v, \text{sech } (\pm u-C)\sin v, \tanh (\pm u-C)) )$$ $$$$ How do we get rid of $C$ and $\pm$ ?","['parametrization', 'conformal-geometry', 'differential-geometry']"
1589419,Degree of a Differential Equation.,Consider the differential equation $$\sin\left(\frac{dy}{dx}\right)=x$$ what is the degree of the above differential equation? According to me it's degree is not defined as the equation is not polynomial in derivatives. Please help. Thanks.,['ordinary-differential-equations']
1589424,Explicit computation of a blowup,"I am working on a computation of a blowup and got stuck at a point, I hope there is somebody to help me. Consider $V=V(y^2-x^3-x^2) \subseteq \mathbb{A}^2_k$ for some algebraic closed field $k$. I want to blow up $V$ in the origin, the corresponding ideal is $I=(x,y)$. Let $R=k[V]=k[x,y]/(y^2-x^3-x^2)$ and $X=\mathrm{Spec}R$. I got that far to say, that the blowup $\tilde{X}$ of $X$ along $I$ is given by
$$\tilde{X}=\mathrm{Proj\ } k[x,y,X,Y]/(yX-xY,y^2-x^3-x^2, yY-x^2X-xX, Y^2-xX^2-X^2),$$ but now I want to show that 
$$\mathrm{Proj\ }k[x,y,X,Y]/(yX-xY,y^2-x^3-x^2, yY-x^2X-xX, Y^2-xX^2-X^2), \cong \mathrm{Spec} k[X]$$
(which is well-known result). But I was not able to do this. Does anybody have a hint or solution for me? Best regards and a merry christmas to you.","['algebraic-geometry', 'blowup']"
1589425,Finding the minimum value of $\sqrt { \frac { a }{ b+c } } +\sqrt [ 3 ]{ \frac { b }{ c+a } } +\sqrt [ 4 ]{ \frac { c }{ a+b } }$,"If $a, b, c\ge 0$ with $(a+b)(b+c)(c+a) > 0$ ,
find the minimum of $\sqrt { \frac { a }{ b+c }  } +\sqrt [ 3 ]{ \frac { b }{ c+a }  } +\sqrt [ 4 ]{ \frac { c }{ a+b }  }$ . The minimum is $\frac{3}{\sqrt[3]{4}}$ achieved at $b = 0, \frac{a}{c} = 2^{-4/3}$ . I am not able to progress in this problem.I tried applying AM-GM,Cauchy,Weighted AM-GM,etc. but none seem to provide fruitful results. Please help. Source: A collection of problems which couldn't be solved by any teacher of my school. Thanks.","['algebra-precalculus', 'inequality']"
1589429,How to prove that $\log(x)<x$ when $x>1$? [duplicate],"This question already has answers here : Simplest or nicest proof that $1+x \le e^x$ (26 answers) Closed 6 months ago . It's very basic but I'm having trouble to find a way to prove this inequality $\log(x)<x$ when $x>1$ ( $\log(x)$ is the natural logarithm) I can think about the two graphs but I can't find another way to prove it, and, besides that, I don't understand why should it not hold if $x<1$ Can anyone help me? Thanks in advance.","['logarithms', 'inequality', 'calculus']"
1589461,For which cases with $2$ or $3$ prime factors do formulas for $gnu(n)$ exist?,"Denote : $gnu(n)=$ number of groups of order $n$ For squarefree $n$ , there is a closed formula for $gnu(n)$ .
Prime powers upto $p^7$ are also completely solved and I found a formula
for the case $p^2q$ . In GAP, the cube-free case is solved. My limitied GAP-version works upto $n=50,000$ in this case. But even for $p^2q^2$ , I nowhere found an explicit
formula. My GAP-version is already doomed with numbers like $9317=7\times 11^3$ Do formulas exists for the cases $p^2q^2$ and $p^3q$ ? I read somewhere in this forum that these cases have been done, but I nowhere found a formula. Which cases are completely solved, if $n$ has at most $3$ distinct prime factors ? The easiest non-cube-free-case is $p^3q$ ? Again, formulas would be very welcome. Finally, does anyone know $gnu(n)$ or at least a sharp upper bound for the following n ? $$[2052,2058,2064,2072,2079,2080,2088,2106]$$ These are the smallest values beyond $2048$ , for which my GAP-version is doomed.","['finite-groups', 'group-theory', 'gap', 'groups-enumeration']"
1589487,Let the function satisfy $f(x)f'(-x)=f(-x)f'(x)$ and $f(0)=3$ for all $x$,"Question Let the function satisfy $f(x)f'(-x)=f(-x)f'(x)$ and $f(0)=3$ for all $x$. Then find the number of roots of $f(x)=0$ in $[-2,2]$ and evaluate $\displaystyle\int\limits_{-51}^{51}\frac{\mathrm dx}{3+f(x)}$. My Attempt I have solved this equation:
\begin{align}
f(x)f'(-x)&=f(-x)f'(x);\\\\
\frac{f'(-x)}{f(-x)}&=\frac{f'(x)}{f(x)};\\\\
\int\frac{f'(-x)}{f(-x)}\,\mathrm dx&=\int\frac{f'(x)}{f(x)}\,\mathrm dx;\\\\
\int\frac{\mathrm df(-x)}{f(-x)}&=-\int\frac{\mathrm df(x)}{f(x)};\\\\
\log(f(-x))&=-\log(f(x))+\log(c).
\end{align} Using the initial condition $f(0)=3$ I have found $$f(x)f(-x)=9,$$
but I do not know how to find $f(x)$ and hence how to find the number of roots of $f(x)$ in $[-2,2]$ and how to evaluate the given integral.","['definite-integrals', 'ordinary-differential-equations', 'calculus']"
1589518,Divisibility by 37 .,"Let the sum of two three-digit numbers be divisible by 37. Prove that the six-digit number obtained by concatenating the digits of those numbers is also divisible by 37. $\overline {abc}$ + $\overline {def}$ is divisible by 37. Prove $$\overline{abcdef}$$ is divisible by 37. $$\overline {abc} = 100a + 10b + c$$
$$\overline {def} = 100d + 10e + f$$
then we have
$$\overline {abc}+ \overline {def} = 100a + 10b + c + 100d + 10e + f = 100(a+d) + 10(b+e) + c + f $$
And I'm stuck here. Can anyone help me?","['number-theory', 'congruences', 'divisibility']"
1589532,What is the value of $\frac{\sin x}x$ at $x=0$?,"On plotting graph for $\frac{\sin x}{x}$ using Wolfram|Alpha and Google, got that : also, I can get the value of $\lim_{x\rightarrow 0} \frac{\sin x}{x} = 1$ using squeeze theorem and as illustrated on sources such as MIT . But I'm not able to understand how the function is defined at $x=0$ and its value came out to be $1$ at that point. As promised in the plot for the function. Using limits I got the idea about the behavior of the function in the neighborhood of that point but not its value exactly at $x=0$.","['trigonometry', 'fractions', 'functions', 'limits']"
1589542,Find a way out in $8 \times 8$ square,"Here is one of the mathematic contest problem that my teacher has given me. He said me to solve or find the reason why it cannot be solved. But I was not able to do it. And my searches for similar answers was not effective. Given: $8 \times 8$ square which consists of 64 squares. Objective: Draw connected lines from right-bottom square to top-left square which will include EVERY square. Rules: You must start from right-bottom square and finish at top-left square  (See the link). You can only draw a line up, down, left, right directions. Moving diagonally and crossing lines is not allowed. Sorry for bad English. Please warn me, if you misunderstood the problem. As an example, I provide the solved $7 \times 7$ square with the rules above. The example $7 \times 7$ square The $8 \times 8$ square","['puzzle', 'geometry']"
1589597,"If $f \colon \mathbb{R}^m \to \mathbb{R}^n$ is continuous and $\mathcal{H}^d(f(E))\leq L^d \mathcal{H}^d(E)$, is $f$ Lipschitz?","Let $f \colon \mathbb{R}^m \to \mathbb{R}^n$ be continuous and such that for every $E\subset \mathbb{R}^m$ we have
$$
\mathcal{H}^d(f(E))\leq L^d \mathcal{H}^d(E),
$$
where $\mathcal{H}^d$ denotes the $d$-dimensional Hausdorff measure, with $d=\min\{m,n\}$. Is $f$ $L$-Lipschitz? I have an answer to the question unless $n=1$ and $m>1$. See below for details. Case 1 : $m=1$ For $f \colon \mathbb{R} \to \mathbb{R}^n$, we first note that $\mathcal{H}^1(E) \geq \operatorname{diam}(E)$, so we have
$$
|f(x)-f(y)| \leq \operatorname{diam}(f([x,y])) \leq \mathcal{H}^1(f([x,y])) \leq L\mathcal{H}^1([x,y]) = L |x-y|.
$$
Hence the answer in this case is positive . Case 2 : $m,n>1$ We can define $f \colon \mathbb {R}^m \to \mathbb{R}^n$ by $f(x_1,\dots,x_n)=(x_1,x_1^2, 0,\dots,0)$. Then $\mathcal{H}^d(f(E))=0$ (recall $d=\min\{m,n\}$) for every $E \subset \mathbb{R}^m$, so the inequality is trivially satisfied. However, the function is not Lipschitz (because $x^2$ is not). Hence the answer in this case is negative. Case 3 : $m>1$, $n=1$ For this case, I have no proof nor counterexample.","['real-analysis', 'lipschitz-functions', 'measure-theory']"
1589603,Question on a constructive proof of irrationality of $\sqrt 2$,"Here is the constructive proof of $\sqrt 2 \not \in \mathbb Q$ found on this page : Given positive integers $a$ and $b$ , because the valuation (i.e., highest power of 2 dividing a number) of $2b^2$ is odd, while the valuation of $a^2$ is even, they must be distinct integers; thus $|2 b^2 - a^2| \geq 1$ . Then $$\left|\sqrt2 - \frac{a}{b}\right| = \frac{|2b^2-a^2|}{b^2(\sqrt{2}+a/b)} \ge \frac{1}{b^2(\sqrt2 + a / b)} \ge \frac{1}{3b^2},$$ the latter inequality being true because we assume $\frac{a}{b} \leq 3- \sqrt{2}$ (otherwise the quantitative apartness can be trivially established). I don't understand why the first equality holds: why is it possible to divide by $\sqrt 2 + a/b$ , since it is not yet known whether this number is zero... ? Thank you in advance for your comments !","['number-theory', 'rationality-testing', 'diophantine-approximation', 'proof-verification']"
1589613,"Prove that $g'(t)$ vanishes for $t=\frac{3}{2}$ and $2,g(t)$ is maximum when $t=\frac{3}{2}$ and $g(t)$ is minimum at $t=1.$","Let $f(x)= \left\{ \begin{array}{lcc}
             x+1,  & 0 \leq x \leq 1 \\
             \\ 2x^2-6x+6, & 1 < x \leq 2 \\
             \\ 
             \end{array}
   \right.$ and $g(t)=\int_{t-1}^{t}f(x)dx$ for $t\in[1,2]$ Then prove that $g'(t)$ vanishes for $t=\frac{3}{2}$ and $2,g(t)$ is maximum when $t=\frac{3}{2}$ and $g(t)$ is minimum at $t=1.$ I found $g'(t)=f(t)-f(t-1)$ Put $g'(t)=f(t)-f(t-1)=0$ As $t\in[1,2]$ so $f(t)=2t^2-6t+6$ and as $t-1\in[0,1]$ so $f(t-1)=(t-1)+1=t$ $g'(t)=2t^2-7t+6=0$ gives $t=\frac{3}{2}$ and $2$. $g''(t)=4t-7$ $g''(\frac{3}{2})=-1$,so $g(t)$ is maximum when $t=\frac{3}{2}$ But i do not understand how $g(t)$ is minimum at $t=1.$ Please help me.","['real-analysis', 'calculus', 'functions']"
1589621,"Why is there $(2,3)$ corner coordinates on the graph, using this function: $f(x)=2x-1+|x-2|?$","Currently I am studying about absolute values and I had to consider this function and draw it's graph: $$f(x)=2x-1+|x-2|$$ I helped myself with symbolab, here is the link: https://www.symbolab.com/solver/step-by-step/f%5Cleft(x%5Cright)%3D2x-1%2B%5Cleft%7Cx-2%5Cright%7C/?origin=button I understood everything about getting the $x$ coordinate $(-1, 0)$ and $y$ coordinate $(0,1)$ but I don't see where did $(2,3)$ corner coordinates come from or what does it mean - could anyone please tell that to me$?$ I am also including the picture: graph and it's coordinates","['absolute-value', 'functions', 'graphing-functions']"
1589622,Variance of random walk model?,"I'm taking my second term of statistics, and I find myself obsessed with an unnecessary detail...again. As follows: $$Y_t=\rho Y_{t-1}+u_t$$ That is to say, we are working with a time series. We assume our present value depends on our previous value. $\rho$ is assumed to be $<1$, so effects of values close in time is greater than the effects of values in the distant past. $u_t$ is assumed to be a purely random term.The $u_i$s are all assumed to be normally distributed, with zero mean and unit variance. $Y_0$ (our starting value) is assumed to be 0. My textbook then claims (out of nowhere)that the variance of this expression is equal to: $$\frac {1}{1-\rho^2}$$ That's what my question is all about, I am trying to figure out how to reach this expression. Below, I will describe my (so far unsuccessful) attempt at doing so. Our first formula is $$Y_t=\rho Y_{t-1}+u_t$$ This can be rewritten as: $$Y_t=\sum {\rho^{n-t}u_t}$$ This way the $\rho$ is raised to the power of 0 at $u_n$, 1 at $u_{n-1}$, 2 at $u_{n-2}$ and so forth. $\rho$ will be raised to the power of n-1 at our starting value. Using the formula for geometric sums, this can be rewritten as: $$Y_t=\frac{u_t-\rho^n u_t}{1-\rho}$$ Assuming that n approaches infinity (knowing that $|\rho|<1$),we can rewrite this as: $$Y_t=\frac{u_t}{1-\rho}$$ We take the variance of this expression: $$V(Y_t)=\frac{\sigma^2}{(1-\rho)^2}$$ Finally, according to the text we have unit variance. I think this means that the variance of each $u_t$ should equal 1. This would leave us with: $$V(Y_t)=\frac{1}{(1-\rho)^2}$$ This still isn't equal to $\frac {1}{1-\rho^2}$! Could someone please tell me what I'm doing wrong?","['time-series', 'statistics', 'variance']"
1589628,Proving that the Lebesgue integral over a measurable function $f$ is equal to the area/volume below the graph of $f$,"Given a Borel set $A \subseteq \mathbb{R}^d, d ≥ 1$ and a measurable function $f: A \to [0, \infty)$, I want to consider the set: $$E = \{(x, y) \in \mathbb{R}^{d+1}: x \in A, 0 ≤ y ≤ f(x)\} \subseteq \mathbb{R}^{d+1}$$ I first want to show that $E$ is a Borel set. Then, I want to prove that $$\lambda_{d+1}(E) = \int_A f(x) d \lambda_d(x)$$ where $\lambda_d$ is the $d$-dimensional Lebesgue measure. I unfortunately wasn't even successful showing that $E$ is a Borel set so far. I first thought that one could write $E$ as the product of two Borel sets ($E = A \times \text{another Borel set}$), but I then realized that it isn't that simple, seeing as the $y$ in a vector $(x, y) \in E$ is dependent on $x$. Maybe one could construct a clever measurable function that sends $E$ onto a measurable set in $\mathbb{R}$ or something like that? I'm not really all that sure though. Once established that $E$ is measurable, wouldn't the second part follow more or less right from Fubini's theorem ? Also, I think the intuition behind this excercice is to acknowledge that, in case $d = 1$, the Lebesgue integral of $f$ over $A$ is nothing but the area inbetween the graph of $f$ and the $x$-axis; for $d = 2$, it's the volume, and so on. I'm not really sure how that helps me (formally) showing it.","['real-analysis', 'integration', 'lebesgue-integral', 'analysis']"
1589630,Finding all possible integer solutions to $x_1+x_2+ \ldots$ where the variables have coefficients,"I know how to find integer solutions to equations of the form $x_1+x_2+x_3=n$. You would use stars and bars and do ${n+2}\choose{2}$. But what if the equation is of the form $x_1+3x_2+4x_3=n$. This is for the problem where you want to distribute n candies among 3 different sized boxes. One size holds one candy, another holds $3$ candies, and the other holds $4$ candies. And each box must be completely filled. Is it even possible to use the equation approach to this problem? And if so, how?","['combinatorics', 'integers']"
1589634,Let $k = 2008^2 + 2^{2008}$. What is the last digit of $k^2 + 2^k$?,"Let $k = 2008^2 + 2^{2008}$. What is the last digit of $k^2 + 2^k.$ I thought of this
$$2008^2+2^{2008}\pmod{10} ≡ {-2}^2+{2^4}^{502}\pmod{10} ≡ 4+{-4}^{502}\pmod{10} ≡ 4+6^{251} \pmod{10}$$
but I still cannot prove it. Maybe there is a clever solution but so far I have been unable to spot it. Can anyone help me?","['number-theory', 'congruences', 'divisibility']"
1589639,Replacing in equation introduces more solutions,"Let's say I have an equation $y=2-x^2-y^2$.
now, since I know that $y$ is exactly the same as $2-x^2-y^2$ I can create the following, equation by replacing $y$ with $2-x^2-y^2$. $y=2-x^2-(2-x^2-y^2)^2$ doing this replacement introduces new solutions such as $(-1, 0)$. Replacements in other various equations have similar results, although some do not change the equation at all! What mechanic introduces these new solutions, and what are they? Edit: one such example of an equation where no solutions are introduced via replacement is $y=x^2+y^2$. That will give $y=x^2+(x^2+y^2)^2$ which upon graphing is the same graph as the original, $y=x^2+y^2$. Here is an image of the iteration of this replacement on the same function, just for fun.","['algebra-precalculus', 'polynomials']"
1589652,Notation for second derivative,"I am confused with the notation in the following example: if $f(x,y)=g(x^2+y^2)$ then calculate $f_{xx},f_{yy},f_{xy}$ I'm thinking that if $x^2+y^2=t(x,y)=t$ then $f(x,y)=g(t)$ and $$f_x=2xg'(t), \ f_y=2yg'(t)$$ so $$f_{xx}=2g'(t)+4x^2g''(t)$$
$$f_{yy}=2g'(t)+4y^2g''(t)$$
$$f_{xy}=4xyg''(t)$$ Is this clear or should I use a different notation for the derivatives of $g$?","['multivariable-calculus', 'derivatives']"
1589666,How to proof $C_0^\infty(\mathbb{R}^n)$ is dense in $H^s(\mathbb{R}^n)$ by using mollifier,"Since the definition of $u\in H^s(\mathbb{R}^n)$ is $\left(1+|\lambda|^2\right)^{s/2}\hat{u}(\lambda)\in L^2(\mathbb{R}^n)$ I find it difficult to give an constructive prove that use mollifier. let $\rho_\delta$ be a mollifier (for example $\exp(\frac{1}{1-(x/\delta)^2}1_{B(0,\delta)})$ ), then how to say $(u\ 1_{B(0,R)})*\rho_\delta$ converge to $u$ in $H^s$ when $\delta\to 0^+,R\to+\infty$ The main purpose is to prove that $C_0^\infty(\mathbb{R}^n)$ is dense in $E=\{u\in H^s(\mathbb{R}^n):\partial_{x_1}u\in L^2(\mathbb{R}^n)\}$ where $||u||_E^2=||u||_{H^s}^2+||\partial_{x_1}u||_{L^2}^2$. Simply use the fact that $C_0^\infty(\mathbb{R}^n)$ is dense in $H^s(\mathbb{R}^n)$ does not work","['functional-analysis', 'sobolev-spaces']"
1589668,Does Darboux theorem imply that $f'$ cannot have jump discontinuity?,"Does the Darboux theorem for derivatives imply that a derivative on a interval $I$ cannot have jump discontinuity? Darboux theorem states that the derivative function follow the intermediate value theorem on a interval $I$. My doubts are about a function like this $f(x)=\begin{cases} x-1, 0\leq x\leq 2\\ x+1, -2\leq x < 0\end{cases}$ It has a jump discontinuity nevertheless it seems to follow the intermediate value theorem Am I missing something? Thanks for your help","['derivatives', 'continuity', 'calculus']"
1589674,Trying to make sense out of the transcript about divergence theorem,"Sometimes our lecturer forgets to prepare his lecture beforehand and thus his notes at the blackboard seem to be more his stream of thoughts than study material. I have already seen a couple of correct and full formulations of the Divergence Theorem, there really are not many variations of that. However for the homework exercises we are advised to strictly follow the lecturers notes and thus would like to know if the following transcript of the lecturer's note can be salvaged (especially, if it is equivalent to a ""usual"" definition of the Divergence Theorem"") - (if this is not possible, I will try to contact either my lecturer or his assistant) In lecture we defined the Divergence theorem as follows: $\Omega, U \subset \mathbb{R}^n $ $ \{g<0\} = \Omega \cap U, \{g = 0\} = U \cap \partial \Omega  , \{ g>0 \} = U \setminus \Omega $ $ \nu(x) = \frac{\nabla g(x)}{|\nabla g(x)|} $ with: $ g : U \to \mathbb{R} $ $ u : \Omega \to \mathbb{R}^n, C^1 function $ $ v: \to \mathbb{R}, C^1 function $ Then the Divergence theorem states: $ \int\limits_{\Omega} div(u*v) = \int\limits_{\partial\Omega} v(u*\nu) - \int\limits_{\Omega} div(u* \nabla v) $ Checking wikipedia (or any further calculus book) gives a slightly different formula of the Divergence Theorem. None of the version I have seen included this part:  $ - \int\limits_{\Omega} div(u* \nabla v) $ Does this part suffices a special purpose? Any constructive hint, comment or answer is appreciated.",['multivariable-calculus']
1589695,Divisibility by 7.,"Let $b = a_5a_4a_3a_2a_1a_0$ integer that has a maximum of six digits. Here we have: if $b$ is a five-digit number, then $a_5 = 0$; if $b$ is a four-digit number , then $a_5$, $a_4 = 0$, and so on. Prove that $$ b \equiv a_0 - a_3 + 3 (a_1 - a_4) + 2 (a_2 - a_5) \pmod 7 $$ $$ 10^6 \equiv 1 \pmod 7$$ From this derive the criterion of divisibility of an integer number $7$. Can anyone help me with this? I know that to determine if a number is divisible by $7$, take the last digit off the number, double it and subtract the doubled number from the remaining number. If the result is evenly divisible by $7$ (e.g. $14, 7, 0, -7$, etc.), then the number is divisible by seven.","['number-theory', 'congruences', 'divisibility']"
1589705,Probability Mass Functions,"I have a question regarding probability mass functions. I have been learning about joint p.m.fs and how to find the marginal p.m.fs from the joint p.m.fs, however I'm completely unsure how to tackle this problem below. Any help being pointed in the right direction would be greatly appreciated. Given the table below and the fact that $X_1$ and $X_2$ are independent random variables, how would I go about finding P($X_1$+$X_2$$\le$$1$ | $X_1$=$0$)? $$\begin{array}{c|c|c|} 
 & \text{P($X_i$=0)} & \text{P($X_i$=1)}& \text{P($X_i$=2)} & \text{$i$=1,2}\\ \hline
\text{$X_1$} & p & 3p & 1-4p &(0<p<1/4) \\ \hline
\text{$X_2$} & p & p^2 & 1-p-p^2 & (0<p<1/2)\\ \hline
\end{array}$$","['statistics', 'probability']"
1589716,Spectrum of right shift operator in weighted $l2$ sequence space,"Let $l_2(a)$ be a hilbert space defined with following inner product:
$\langle x_n,y_n\rangle = \sum a^k x_k y_k$. (It's a weighted sequence space with the weights  $\omega_i = a^i$).
It's elements are the sequences for which the norm is defined and finite. ( $\langle x_n,x_n \rangle = c ).$ The left and right shift operators are defined as usual: $S_r(({x_0 , x_1, x_2, ... x_n , ...})) = (0, x_0, ...)$ 
$S_l(({x_0 , x_1, x_2, ... x_n , ...})) = (x_1, x_2, ...)$ Now, I was asked to find $\sigma(S_r), \sigma(S_l)$. My attempt was this:
I found the operator norm of both operators. $\lvert S_r\rvert = a$, $\lvert S_l\rvert = 1/a$. Then, I figured that $S_l$ has eigenvalues for every $\lambda$ satisfying $\lvert \lambda \rvert < 1/a$. Because the specturm is closed and bounded by the operator norm, i figured that $\sigma(S_l)$ is the closed ball with radius $1/a$. Additionaly, i found that $S_r ^ * = aS_l$, and therefore $Im(S_r - \lambda I)^\bot = Ker(aS_l - \bar{\lambda} I) = Ker(a(S_l - (\bar{\lambda}/a) I)) = Ker(S_l - (\bar{\lambda} / a) I) \neq 0 \Longleftrightarrow \bar{\lambda} / a < 1/a$. So i deduced that if $\lvert\lambda\rvert < 1$ so $\lambda \in \sigma(S_r)$. which doesn't make sense to me if $a < 1$ and then the spectrum has to be bounded by $\lvert S_r \rvert = a$. Thanks alot.","['functional-analysis', 'spectral-theory', 'hilbert-spaces']"
1589717,Growth rates slower than logarithmic? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question So far, I've been able to determine growth rates using the following limit:$$\lim_{x\to\infty}\frac{f(x)}{g(x)}$$Which, if need be, can be solved with calculus. From this, I deduced that it is very difficult to have a function $f(x)$ that grows slower than a function $g(x)=\ln(x)$. I noted a few, the Lambert W function, or something simple like $\sqrt{\ln(x)}$.  This means we are excluding composite functions. However, I wondered if there are any ""parent"" functions that have slower growth rates than a logarithm. This is excluding non-elementary things like the Lambert W function or the inverse factorial. And by ""parent"" function, I mean you cannot combine multiple $x$'s or apply multiple operations to $x$. That is, we can't try to do something silly like $\ln[\ln(x)]$ or $x-\ln(x)$. One function, one operation, elementary functions only.  By elementary functions, I define an elementary function as being analytic and algebraic, unlike the inverse factorial or Lambert W function or similar things. Can we have growth slower than logarithmic under these restrictions? EDIT One last restriction.  The proposed function $g(x)$ must have the following:$$\lim_{x\to\infty}g(x)=\infty$$ Because it has come to my attention that horizontal asymptotes may apply.","['derivatives', 'logarithms', 'calculus', 'recreational-mathematics']"
1589723,Balanced cutting of a convex polygon,"Given a convex polygon $C$ and a number $R\geq 1$, say that a point $x$ is an $R$-balance-point of $C$ if every line through $x$ divides $C$ to two parts $C_1,C_2$ such that:
$$1/R \leq Area(C_1)/Area(C_2)\leq R$$ Some polygons have a 1-balance-point, e.g. the centroid of a rectangle or an ellipse, since every line through it cuts $C$ to two parts of equal area. Initially I thought that every convex polygon has a 1-balance-point, but then I found a counter-example. Consider the unit right-angled isosceles triangle, whose total area is 0.5: Suppose by contradiction that it has a 1-balance-point, H. Then, the verical line through H must cut a triangle of area 0.25, so it must have $x = 1-\sqrt{0.5} \approx 0.29$. Similarly, the horizontal line through H must have $y = 1-\sqrt{0.5} \approx 0.29$. This means that H must be the point (0.29,0.29). But, the line through H at angle $135^\circ$ from the x axis cuts a triangle of area $\approx 0.17$. So, my question is: what is the smallest $R$ such that every convex polygon has an $R$-balance-point? (and what is the standard name of this point?)","['convex-analysis', 'geometry']"
1589731,"Homeomorphism between $\mathcal{C}(X,\Omega Y)$ and $\mathcal{C}(\Sigma X, Y)$","It is easy to see that there is a natural bijection between $\mathcal{C}(X,\Omega Y)$ and $\mathcal{C}(\Sigma X, Y)$, where $\Omega Y$ is the based loop space, $\Sigma X$ is reduced suspension, $X$ and $Y$ are based spaces. Now $\mathcal{C}(*,*)$ and also $\Omega Y$ can be given the compact-open topology. Is the natural bijection mentioned above actually a homeomorhpism with this topology? I can prove this is true if I assume $X$ is a compact space.
I have shown that there is an obvious map $\Phi : \mathcal{C}(X,\Omega Y)\to \mathcal{C}(X\times S^1, Y)$ and $\Phi$ is a homeomorphism onto its image. From $\text{Im}{\Phi}$ I can define a map into $\mathcal{C}(\Sigma X,Y)$, but to show that this map is continuous I need $X$ to be compact. Then the composition is actually the natural bijection. Is compactness of $X$ necessary to prove the statement? Can it be generalized to say locally compact spaces or compactly generated spaces? Any help regarding this is appreciated.","['algebraic-topology', 'general-topology', 'loop-spaces']"
