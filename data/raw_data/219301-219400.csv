question_id,title,body,tags
4484961,"Numbers of $2\times 2$ matrices $A$ with elements from the set $\{-1, 0, 1\}$ such that $A^2 =I$ where $I$ is an identity matrix of order $2$.","Numbers of $2\times 2$ matrices $A$ with elements from the set $\{-1, 0, 1\}$ such that $A^2 =I$ where $I$ is an identity matrix of order $2$ . My Approach: Let $\;A=\begin{bmatrix} 
	a & b \\
	c & d \\ 
	\end{bmatrix}\;$ $\implies A^2 =\begin{bmatrix} 
	a^2+bc & b(a+d) \\
	c(a+d) & d^2+bc \\ 
	\end{bmatrix}\; =\begin{bmatrix} 
	1 & 0 \\
	0 & 1 \\ 
	\end{bmatrix},\; $ $\implies$ $a^2+bc=1,\; b(a+d)=0,\; c(a+d)=0,\; d^2+bc=1$ Then i made $5$ cases: Case $(1).$ $a+d=0\;, b\neq0,\;c\neq 0$ Here I obtained two matrices $a=0,\ d=0,\; b=1,\; c=1$ and $a=0,\; b=0,\; b=-1,\; c=-1$ Case $(2)$ $a+d=0,\;b=0,\;c\neq0$ Here I obtained $4$ matrices $a=1,\;d=-1,\;b=0,\;c=1\;$ and $a=1,\; d=-1,\; b=0, c=-1$ and $a=-1,\;d=1,\;b=0,\;c=1\;$ and $a=-1,\; d=1,\; b=0, c=-1$ Case $(3)$ $a+d=0,\ b\neq 0,\ c=0$ Here I obtained $4$ matrices $a=1,\;d=-1,\;b=1,\;c=0\;$ and $a=1,\; d=-1,\; b=-1, c=0$ and $a=-1,\;d=1,\;b=1,\;c=0\;$ and $a=-1,\; d=1,\; b=-1, c=0$ Case $(4)$ $a+d\neq 0,\;b=0,\;c=0$ Here i obtained two matrices $a=1,\;b=0,\;c=0,\;d=1$ and $a=-1,\;b=0,\;c=0,\;d=-1$ Case $(5)$ $a+d=0,\; b=0,\ c=0\;$ Here I obtained two matrices $a=1,\;d=-1, b=0, c=0\;$ and $a=-1,\; d=1,\; b=0,\; c=0$ I am obtaining $14$ Matrices in total but answer given is $16$ . What Case am I missing? and also is there any better method to solve these kind of problem? I am also attaching solution provided by My institute I didn't understood there solution at all","['matrices', 'combinatorics', 'permutations']"
4484968,Two inequalities with inclusion-exclusion,"Let $S$ be a base set of size $n$ .
Also denote $k$ of $S$ 's subsets by $A_1,...,A_k\in 2^S$ such that $\bigcup_i A_i=S$ .
Furthermore, let $n_\alpha=\lvert\bigcap_{i\in\alpha}A_i\rvert$ be the size of the intersection of sets in the index set $\alpha\subset I=\{1,...,k\}$ .
For example, $n_{1,3,4}=\lvert A_1\cap A_3\cap A_4\rvert$ if $k\ge4$ . We know that $\forall i\in I: n_i\ge3$ and $\sum_i n_i>\sum_{\alpha\subset I} (-1)^{\lvert\alpha\rvert+1}{n_\alpha\choose2}$ . If I could show that $\sum_{\alpha\subset I} (-1)^{\lvert\alpha\rvert+1}n_\alpha\le2k$ , that would help me a lot with my project. I have tried an inductive proof but got stuck.
I have also tried to represent the task with two lattices (or semi-lattices, I am not sure) and find some mapping there but that failed too.
I have checked Richard Stanley's book on Enumerative Combinatorics but I did not see anything that would connect inclusion-exclusion sums of numbers and binomial coefficients. I would be very grateful for any ideas.
Thank you.","['integer-lattices', 'inclusion-exclusion', 'binomial-coefficients', 'combinatorics']"
4484989,Prove $ (\tan(x))^{'} = \frac{1}{\cos^2(x)} $ [duplicate],"This question already has answers here : Proving $\frac{\mathrm d}{\mathrm dx}(\tan x)=\sec ^2x$ (3 answers) Closed 1 year ago . I want to prove $\displaystyle (\tan (x))'=\frac{1}{\cos^2(x)} $ using the definition of the derivative. So I started with the following: \begin{align*}\lim \limits _{h\to 0}\frac{\tan (x+h)-\tan (x)}{h} & =\lim \limits _{h\to 0}\frac{\sin (x+h-x)}{\cos (x+h)\cos (x)} \\
& =\lim \limits _{h\to 0}\frac{\sin (h)}{\cos (x+h)\cos (x)}.
\end{align*} But the problem is that $\lim \limits _{h\to 0}\sin (h)=0\neq 1$ . Can you give me a hint on how to solve this? I know there are other identities for tan(x + h) - tan(x), but I want to solve this problem using the on I wrote in the solution.","['calculus', 'derivatives', 'real-analysis']"
4485000,How do I show that the ideal $(2)$ of $\Bbb{Z}/4\Bbb{Z}$ is not flat?,Let $R=\Bbb{Z}/4\Bbb{Z}$ and let me take the ideal $(2)\subset R$ . I want to show that $(2)$ is not flat in $R$ . We only had the following definition: A module $M\subset R$ is flat if $M\otimes_R-$ is left exact. Using this definition I want to show it. My idea was the following. Since we know that tensoring is already right exact we only need to worry about left exactness. The problem is that I don't see what left exact sequence I need to consider such that after tensoring it isn't left exact anymore. Could someone give me a hint?,"['exact-sequence', 'abstract-algebra', 'tensor-products', 'commutative-algebra']"
4485030,"Compute the normalisation of $\mathbb{C}[X^3,XY^2,Y^3]$.","I'm pretty sure the answer should be $\mathbb{C}[X^3,XY^2, X^2Y, Y^3]$ . This guess comes from the fact $X^2Y$ is integral (it's the root of $t-\frac{X^3 Y^3}{XY^2}$ ) and some pretty sketchy geometric reasoning. I know how to compute normalisations of curves but the same techniques don't seem to apply.","['algebraic-geometry', 'commutative-algebra']"
4485031,Normal subgroups of direct product of non-abelian simple groups (Exercise 18 from Chapter 4.5 of Dummit's book),"I have written down a proof for an exercise from Chapter 4.5 in Dummit & Foote's Abstract Algebra . I think there might be something wrong with my proof, since most of the solutions I found emphasizing on proving $G_I$ is a direct product, but I somehow wrote quite a lot proving $K_i \leq G_I$ instead. I would appreciate if you can help locate the mistake. Exercise: Let $K_1, K_2, \dots, K_n$ be non-abelian simple groups and let $G = K_1 \times K_2 \times\dots\times K_n$ . Prove that every normal subgroup of $G$ is of the form $G_I = K_{i_1} \times K_{i_2} \times\dots\times K_{i_m}$ for some subset $I = \{i_1, i_2, \dots, i_m\}$ of $\{1,2,\dots,n\}$ . My attempts: Suppose $H$ is a non-trivial normal subgroup of $G$ . We prove first the following claim. Claim: For each $i \in \{1,2,\dots,n\}$ , either $K_i \leq H$ , or every $h \in H$ can be written as $h = k_1k_2\dots k_n$ with $k_j \in K_j$ and $k_i = 1$ . It suffices to establish the case $i = 1$ . Assume that there is some element $h = k_1k_2\dots k_n$ with $k_1 \neq 1$ . For any $g\in K_1$ , by the normality of $H$ we know $^gh = \,^gk_1k_2\dots k_n \in H$ , and it follows $^ghh^{-1} = [g, k_1] \in H$ . Hence, the group $[K_1,k_1] $ generated by $\{[g,k_1]:g\in K_1\}$ is a subgroup of $H\cap K_1$ . It remains to prove that $[K_1,k_1] $ is normal in $K_1$ , which follows from the following fact: Given any $x \in K_1$ , $^x[g,k_1] = [xg,k_1][x,k_1]^{-1} \in [K_1,k_1]$ . Also, $[K_1, k_1] \neq \{1\}$ , because there must be some $g$ not commutative with $k_1$ , otherwise $\langle k_1 \rangle$ would be an abelian normal subgroup of $K_1$ , a contradiction. Thus, $[K_1, k_1] = K_1$ by the simplicity of $K_1$ , that is, $K_1 \leq H$ . We have proved the claim . Denote $J=\{j: K_j \leq H, j\in\{1,2,\dots,n\}\}$ . Thus $G_J$ is a subgroup of $H$ . By the claim above, every element $h\in H$ can be written as $h = k_{j_1}k_{j_2}\dots k_{j_m}$ , hence also an element of $G_J$ . Therefore, $G_J = H$ , and we have proved the exercise. edit: I have correct the typos as Mr. Arturo Magidin pointed out in his first and second comment, also I have replaced ""Henceforth"" by ""Hence"". I apologize for my carelessness; I am really not in form yesterday. Also I am not a native speaker of English, so I make a lot of mistakes typing a long paragraph like this when feeling low. I also modify the notation of conjugate as suggested by Mr. Arturo Magidin. So $^xy$ stands for $xyx^{-1}$ , and $[x,y]$ for $xyx^{-1}y^{-1}$ . Following this convention, the equation $$^x[g,k_1] = [xg,k_1][x,k_1]^{-1}$$ means $$^x[g,k_1] = x(gk_1g^{-1}k_1^{-1})x^{-1} = xgk_1g^{-1}(x^{-1}k_1^{-1}k_1x)k_1^{-1}x^{-1} = (xgk_1g^{-1}x^{-1}k_1^{-1})(k_1xk_1^{-1}x^{-1}) = [xgk_1(xg)^{-1}k_1^{-1}](xk_1x^{-1}k_1^{-1})^{-1} = [xg,k_1][x,k_1]^{-1}.$$","['simple-groups', 'normal-subgroups', 'abstract-algebra', 'solution-verification', 'group-theory']"
4485032,Remainder of Taylor expansion of function at random point,"Given a function $f: \mathbb{R}^n \to \mathbb{R}$ , we can write its Taylor expansion about the point $m$ as $$
f(x) = f(m) + \nabla^T f(m) (x-m) + \frac{1}{2} (x-m)^TH_f(m)(x-m) + o(\|x-m\|^2),
$$ where $H_f(m)$ is the Hessian of $f$ evaluated at $m$ . I am interested in the case where $X$ is a Gaussian random vector with mean $\mu$ and covariance $\Sigma$ , then plugging in we get $$
f(X) = f(\mu) + \nabla^T f(\mu) (X-\mu) + \frac{1}{2} (X-\mu)^TH_f(\mu)(X-\mu) + \text{Rem}_f(X, \mu).
$$ What is the correct characterization of the remainder term? Clearly it is going to be a random variable, and intuitively it should be upper bounded (in probability) by $$
\text{Rem}_f(X, \mu) \le \|X-\mu\|^3 \sup_y \|D^{(3)}f(y) \|_{\text{op}},
$$ where the supremum is being taken over $y$ which is a point between $\mu$ and $X$ , so the domain is random. I am looking for a more rigorous expression or a reference to a text/notes that cover such issues. Generally speaking, in the statistics literature this kind of thing comes up under 'delta method' but in those cases you are dealing with a statistic (like the sample mean), and so the remainder can be dealt with by saying it vanishes at some rate as the sample increases. Here I am trying to characterise $f(X)$ where $X$ is a single random vector.","['taylor-expansion', 'statistics', 'probability-theory', 'probability']"
4485036,Is a holomorphic Function of a matrix invertible?,"I am currently reading a Paper and I don't quite get one part. The Paper is about Function of matrices and in one part he says: ""Since $g(z)$ is a holomorphic function on $\Omega$ and never vanishes, $g(A)$ must be invertible"" (for some open $\Omega$ that contains the spectrum of $A$ and a linear bounded operator $A$ ) I understand that since $g(z)$ never vanishes $h(z):=\frac{1}{g(z)}$ must also be holomorphic and therefor $h(A)$ exists. But how do I know that $h(A)$ is actually equal to $g(A)^{-1}$ ?","['complex-analysis', 'spectral-theory', 'functional-analysis', 'functional-calculus']"
4485083,Limit of sequence given by $x_{n} = \frac{x_{n-2}+x_{n-3}}{2}$?,"Let $x_1,x_2,x_3\in\mathbb{R}$ be three distinct real numbers. I am interested in the convergence of the sequence $$
x_{n} = \frac{x_{n-2}+x_{n-3}}{2},\quad n = 4,5,\ldots
$$ ie, $$
x_{4} = \frac{x_{2}+x_{1}}{2},\quad x_{5} = \frac{x_{3}+x_{2}}{2},\quad x_{6} = \frac{x_{4}+x_{3}}{2},\quad\cdots
$$ Please note that, although related to, this is not a recursive averaging sequence with two initial values, as described and studied elsewhere --- see, for instance, Smith, Scott G. ""Recursive Averaging"". The Mathematics Teacher , Vol. 108, No. 7 (March 2015), pp. 553-557. In the present case, convergence is easily verified by noting that $$
\big|\,x_{n}-x_{n-1}\,\big| = \big|\frac{x_{n-2}+x_{n-3}}{2}-\frac{x_{n-3}+x_{n-4}}{2}\big| = \big|\,\frac{1}{2} (x_{n-2}-x_{n-4})\,\big| = \big|\,\frac{1}{2^{\,n-4}}\,\big|\cdot\big|\, x_{3}-x_{1}\,\big| 
$$ Therefore the sequence is Cauchy and hence it converges in $\mathbb{R}$ . However, I was not able to find the limit to where the sequence converges. Computer experiments carried out with several different sets of initial values suggest that this limit should be a linear combination of the those initial values, as occurs in the case mentioned above. Also, the results of these experiments point to the existence of (how many?) sub-sequences, all converging to the very same limit. I would appreciate some help in the analysis of this problem.","['convergence-divergence', 'recurrence-relations', 'sequences-and-series']"
4485100,How to prove that all Minkowski spacetime isometries (transformations in Poincare group) are compositions of translation and Lorentz Transformations?,"It is said in wikipedia that Minkowski spacetime isometries, i.e. the transformation that preserves $$
(x_1-x_2)^2+(y_1-y_2)^2+(z_1-z_2)^2-(t_1-t_2)^2
$$ between points, can be represented as $\mathbb{R}^{1,3}\rtimes O(1,3)$ , meaning that it consists of transformations with the form $$
x \mapsto \Lambda x+b,   \Lambda \in O(1,3) (\text{Lorentz group}), b\in \mathbb{R}^{1,3}.
$$ How can we prove this? It seems that the techniques that is available for proving the form of Euclidean group is unavailable here since the ""distance"" is not positive definite.","['special-relativity', 'group-theory']"
4485128,How does pointwise Hölder continuous on compact subsets not imply locally Hölder continuous?,"When Gilbarg and Trudinger introduced the Hölder spaces, they mentioned on page 52 that Furthermore note that local Hölder continuity is a stronger property than pointwise Hölder continuity in compact subsets. without further elaboration. Can someone kindly explain why?","['function-spaces', 'functional-analysis', 'partial-differential-equations']"
4485132,Fermat's little Theorem and root power sums.,"Let $f\in\mathbb{Z}[x]$ be monic of degree $n\ge 1$ , and suppose $f$ factors as $$
f=(x-r_1)\cdots (x-r_n)
$$ where $r_1,...,r_n$ are algebraic integers. For each positive integer $k$ , let $$
s_k=\sum_{i=1}^n r_i^k
$$ By properties of symmetric functions of the roots, each $s_k$ is an integer. We have the following analog of Fermat's little Theorem . . . Claim: $\;$ If $p$ is prime, then $p{\,\mid\,}(s_p-s_1)$ . Proof: Let $p$ be a prime. $\;$ Then \begin{align*}
s_p-s_1&=
\sum_{i=1}^n r_i^p-\sum_{i=1}^n r_i
\\[4pt]
&\equiv
\left(\Bigl(\sum_{i=1}^n r_i\Bigr)^p-\sum_{i=1}^n r_i\right)\;(\text{mod}\;p)
\\[4pt]
&\equiv
0\;(\text{mod}\;p)
\\[4pt]
\end{align*} which completes the proof of the claim. Next consider $(s_{p-1}\;\text{mod}\;p)$ . . . If $p$ is prime and $r_1,...,r_n\in\mathbb{Z}$ are such that $p{\,\not\mid\,}r_i$ for all $i$ , then by Fermat's little Theorem we have $s_{p-1}\equiv n\;(\text{mod}\;p)$ . I'll conjecture a sort of converse . . . Conjecture: $\;$ If the congruence $s_{p-1}\equiv n\;(\text{mod}\;p)$ holds for all but finitely many primes $p$ , then $r_1,...,r_n\in\mathbb{Z}{\setminus}\{0\}$ . Question: $\;$ Does the conjecture hold?","['number-theory', 'symmetric-polynomials']"
4485262,Demonstrate that the limit does not exist.,"Is the following reasoning sound for demonstrating that the limit does not exist. The limit is: $$\lim_{(x,y) \to (0,0)}{x^y}$$ I show that the restriction gives me two different values of the limit as follows: $$\lim_{(0,y) \to (0,0)}{x^y}=\lim_{(0,y) \to (0,0)}0^y=0$$ $$\lim_{(x,0) \to (0,0)}{x^y}=\lim_{(x,0) \to (0,0)}x^0=1$$ Therefore the limit does not exist.","['limits', 'multivariable-calculus']"
4485266,What am I doing wrong in integrating $\frac1{\sqrt{x} + \sqrt[4]{x}}$,"$\displaystyle\int \dfrac{1}{\sqrt{x} + \sqrt[4]{x}}\mathrm dx$ Putting $x = t^4$ and $dx=4t^3\mathrm dt$ , $$ = \int \dfrac{4 t^3 \mathrm dt}{t^2 + 1}\\ = 4\int \dfrac{t^3 + t - t \mathrm dt}{t^2 + 1} \\= 4\int \dfrac{t^3 + t}{t^2 + 1}\mathrm dt - 4\int \dfrac{t }{t^2 + 1}\mathrm dt\\= 4\int \dfrac{t(t^2 + 1)}{t^2 + 1}\mathrm dt - 2\int \dfrac{2t }{t^2 + 1}\mathrm dt$$ $$= 4\int t\ \mathrm dt - 2\ln|t^2 + 1| + C$$ $$= 2t^2 - 2\ln|t^2 + 1| + C \\= \color{red}{2\sqrt{x} - 2\ln|\sqrt{x} + 1| + C}$$","['integration', 'calculus']"
4485277,Trading Cards & Packs - compute the hypothetical number of packs to purchase to achieve a certain probability to complete a certain Cards' set,"I'm trying to solve a probability problem within the context of a Trading Cards game, but I'm not sure if using Hypergeometric Distribution is the right way. Given the following conditions: Given a population size of N=1500 cards: 5 different Team Cards x 10 copies x 30 Teams To win the game, a user needs to collect all m=5 Cards of a chosen Team (e.g. Team A) User can buy only packs of 5 Cards per time ( n=5 permitted draws) Packs have no duplicated cards. Cards are equally distributed across Packs. By using the Excel Formula: =HYPGEOMDIST(k,n,m,N) the probability to pick 1 Team card by purchasing k=1 Pack should be 14.59% By making the product of the probabilities, the probability to complete a set of 5 team cards by purchasing 5 Packs should be 14.59%^5 = 0.01% If all above is correct, I'm still wondering how to find the number of packs I would need to buy, given a certain target p probability to complete the set . E.g. If I wanted a target p = 50% or p = 99% or p = 100% probability of completing the m = 5 Cards Team set, how many packs shall I buy? I'm adding here the excel with the data, hope it helps! https://docs.google.com/spreadsheets/d/1B-sRhDB_DGmPbGpL-4BD0fzVPJ01dUMlD950seoGMk4/edit?usp=sharing","['coupon-collector', 'probability', 'hypergeometric-function']"
4485281,How to solve such fraction differential equation?,"Here's my first-order differential equation: $$
(x^3 - 2xy^2)dx + 3yx^2dy = xdy - ydx
$$ I've tried to make it fraction, but it isn't separable differential equation, also it isn't differential equation in total differentials, so after it I lose any clue for answer.",['ordinary-differential-equations']
4485325,How to compute the fiber of point between algebraic stacks?,"Suppose $f: \mathcal{X}\rightarrow Y$ is a morphism from an algebraic stack $\mathcal{X}$ to a scheme $Y$ . It can induce a unique topological morphism $|f|:\mathcal{|X|}\rightarrow Y$ . Suppose $y\in Y$ is a point of $Y$ , my question is if $|f|^{-1}(y)\subseteq |\mathcal{X}|$ with the induced topology, homeomoephic to $|\mathcal{X}\times_Y k(y)|$ ? Any comment would be appreciated.","['algebraic-stacks', 'algebraic-geometry', 'fibre-product']"
4485335,"From 7 consonants and 5 vowels, how many words can be formed consisting of 4 consonants and 3 vowels if letters may be repeated? cannot be repeated?","From $7$ consonants and $5$ vowels, how many words can be formed consisting of $4$ consonants and $3$ vowels if: Any letter can be repeated. No letter can be repeated. My answer for the 1st part was $7 \cdot 7 \cdot 7 \cdot 7 \cdot 5 \cdot  5 \cdot 5$ (or $7^4 \cdot 5^3$ ). The way I thought about it is there are $4$ available slots for $7$ consonants that can be repeated so despite taking a consonant which we call it $c_1$ , the second/third/fourth slot might also be $c_1$ so each of the $4$ slots has $7$ consonants to choose from so its $7 \cdot 7 \cdot 7 \cdot 7$ . Same case for vowels which is $5 \cdot 5 \cdot 5$ . Multiply those together to get total number of ways where the letter is repeated in a word which is $7^4 \cdot 5^3$ . However it turned out that the correct answer is actually $7^7 (7C4 \cdot 5C3)$ . I don't understand the logic behind this. I don't get why not only the combinations nCr is used which is supposed to be used for the cases that don't require order and repetition, but also it is multiplied by $7^7$ . For the 2nd part, since the letter cannot be repeated then the available consonants and vowels decreases every time you choose from them so its $7 \cdot 6 \cdot 5 \cdot 4 \cdot 5 \cdot 4 \cdot 3$ (or $7P4 \cdot 5P3$ ). However that's not the case because the correct answer is $7! \cdot (7C4 \cdot 5C3)$ .","['permutations', 'combinations', 'combinatorics', 'discrete-mathematics']"
4485338,Orientation on level set manifold,"Let $M$ be an orientable smooth manifold of dimension $n$ and $f:M\to \mathbb{R}$ smooth with $0$ as regular value. I want to show that the level set $f^{-1}(0)$ is orientable (we know it to be an embedded manifold of dimension $n-1$ ). I sketched a proof using differential forms and would like a review of it. I would also be interested in other proofs involving (or not) differential forms. Thanks in advance. Here's my attempt: Let $d$ denote the exterior derivative of differential forms. Let $\varphi=(\varphi^1,\cdots,\varphi^n)$ denote a chart map of $M$ . As $f$ is a $0$ -form, $df$ is a $1$ -form and since $f*_p$ is surjective when $p\in f^{-1}(0)$ we have that $df=\sum\limits_{k=1}^n \frac{\partial f\circ \varphi^{-1}}{\partial x^k}d\varphi^{k}$ is non zero in an open neighborhood of $f^{-1}(0)$ , which is an embedded orientable submanifold of $M$ that I shall call $N$ . Claim : Since $df$ is non zero in $N$ and $N$ is orientable, I can obtain a basis $\{\omega_1,\cdots, \omega_{n-1},df\}$ for $\Omega^1N $ (the space of differentiable 1-forms on $N$ ) such that $\eta=\omega_1\wedge\cdots\wedge \omega_{n-1}\wedge df$ is nowhere $0$ on $N$ . i.e. $\eta_p\neq 0$ for all $p\in N$ . Let $i:f^{-1}(0)\hookrightarrow N$ be the inclusion map. Since $\omega_1\wedge\cdots\wedge \omega_{n-1}$ is an $n-1$ -form on $N$ , the pull-back $$\rho = i^*(\omega_1\wedge\cdots\wedge \omega_{n-1})=i^*\omega_1\wedge\cdots\wedge i^*\omega_{n-1}=(\omega_1\circ i)\wedge\cdots\wedge (\omega_{n-1}\circ i)$$ is an $n-1$ -form on $f^{-1}(0)$ and is nowhere vanishing, for if $\rho_q=0$ then $\eta_{i(q)}=0$ Thus $\rho$ is a volume form (nowhere vanishing) on $f^{-1}(0)$ which we know to induce an orientation on $f^{-1}(0)$ . To prove my claim, I first extend $\{df\}$ to a basis using that every vector space has one (or should I treat $\Omega^1 N$ as a free $C^\infty$ -module?).
Then I re-order the basis so that the volume form $\eta$ induces the same orientation as that of $N$ .
To prove $\eta$ is a volume form I take for each $p\in N$ a basis $\{v_1,\cdots,v_n\}$ of $T_pN$ such that $\{\omega_1,\cdots,\omega_{n-1},df\}$ is it's dual basis. i.e. $\omega_{k}(v_j)=\delta_{kj}$ and $df(v_j)=\delta_{nj}$ then $\eta_p(v_1,\cdots,v_n)=1$ and thus non zero.","['differential-forms', 'orientation', 'smooth-manifolds', 'differential-geometry']"
4485350,Proof of Grün's theorem,"I have a follow-up question to Problems in understanding a passage in the proof of Grün theorem for transfer . In the book of Kurzweil and Stellmacher, it is also concluded that $G\neq O^p(G) \iff H\neq O^p(H)$ . Here $O^p(G)$ is the smallest normal subgroup with $p$ -factor group. My attempt: If $G=O^p(G)$ , then $G$ has no proper normal subgroup with $p$ -factor group. In particular, $G$ has no proper normal subgroup with $p$ -factor Abelian group. So, $G= G'(p)$ . Thus, $H= H'(p)$ . Thus, $H$ has no proper normal subgroup with $p$ -factor Abelian group. However, to conclude, $H=O^p(H)$ , I need that $H$ has no proper normal subgroup with $p$ -factor group. How to show this? Edit: The precise statement of the theorem is: Let $P$ be a Sylow $p$ -subgroup of a finite group $G$ and $Z\leq Z(P)$ be weakly closed in $P$ . Set $H:=N_G(Z)$ . Then $P\cap G'=P\cap H'$ and $P/(P\cap G')\simeq G/G'(p) \simeq H/H'(p)$ . In particular, $$G\neq O^p(G) \iff H\neq O^p(H).$$ My doubt is about proving the displayed equivalence.","['transfer-theory', 'group-theory', 'abstract-algebra', 'finite-groups']"
4485412,A cryptogram Diophantine $\overline{ABCDE}=4 \ \overline{AB}^2+\overline{CDE}^2$,"ABCDE is a 5-digit number. AB and CDE are 2-digit and 3-digit numbers respectively. $\overline{ABCDE}=4 \ \overline{AB}^2+\overline{CDE}^2$ Find all possible values of $\overline{ABCDE}$ . Honestly, I designed this problem just for fun, and I tried everything to solve it. It seems that there is a neat solution around. I will be very happy if you take a look at it.","['contest-math', 'number-theory', 'elementary-number-theory', 'diophantine-equations', 'cryptarithm']"
4485429,Singular curves and normalization,"Let $C$ be a smooth projective curve over a base field of characteristic zero (maybe not necessary). If we identify two points $p_1,p_2$ on $X$ to define a singular nodal curve $Y$ , i.e., $Y := X \backslash \{p_1,p_2\} \cup \{Q\}$ , is $Y$ still projective? Also, would $X$ naturally be the normalization of $Y$ ? It seems to be the case since we can define the normalization map $X \rightarrow Y$ to be the identity everywhere except at $p_1,p_2$ , and send these two points to $Q \in Y$ .","['algebraic-curves', 'algebraic-geometry']"
4485446,"About the Set of $\mathbb{S}=\{ n | n = a^2+b^2, a, b \in \mathbb{Z}. \}$","About the Set of $\mathbb{S}=\{ n | n = a^2+b^2, a, b \in \mathbb{Z}. \}$ This is also known as OEIS A001481. I just found an interesting one from this set. From my favorite identity, Brahmagupta-Fibonacci's identity, we can get: $(ab+cd)^2+(ad-bc)^2=(a^2+b^2)(c^2+d^2).$ So, we get... If $a, b \in \mathbb{S}, ab \in \mathbb{S}.$ This is a well-known fact for the set. Now, I'm curious about the prime number of the set $\mathbb{S}$ . For example, $2, 5, 9, 13, 17, 29, 37, 41, 49, 53, 61, 73, 89, 97, 101, 109, 113, 121,  \cdots$ are the prime number of $\mathbb{S}$ . These are all the prime numbers except for $9, 49, 121, \cdots$ . And amazing thing is that they are all square numbers. So, I'm wondering if the prime numbers of $\mathbb{S}$ except the prime numbers in $\mathbb{N}$ have some pattern. I can see that they are $(4k+3)^2$ ... Is it right? Extension for this.","['prime-factorization', 'number-theory', 'elementary-number-theory', 'elementary-set-theory', 'prime-numbers']"
4485452,Brenier theorem on optimal transport,"This thread is meant to record a question that I feel interesting during my self-study. I'm very happy to receive your suggestion and comments. Let $X,Y$ be topological spaces. Let $\mathcal P(X), \mathcal P(Y)$ be the spaces of all Borel probability measures on $X,Y$ respectively. Let $c: X \times Y \to [0, +\infty]$ . Fix $\mu \in \mathcal P(X)$ and $\nu \in \mathcal P(Y)$ . $\Pi(\mu, \nu)$ is the set of $\pi \in \mathcal P(X \times Y)$ such that for all measurable subsets $A \subset X$ and $B \subset Y$ , $$
\pi (A \times Y) = \mu (A) \quad \text{and} \quad \pi (X \times B) = \nu (B).
$$ $\Phi_{c}$ is the set of all $(\varphi, \psi) \in L_1 (\mu) \times L_1 (\nu)$ satisfying $$
\varphi(x)+\psi(y) \leq c(x, y)
$$ for $\mu$ -a.e. $x \in X$ and $\nu$ -a.e. $y \in Y$ . Let $$
\mathcal T := \{T:X \to Y \text{ measurable} \mid T_\sharp \mu = \nu\}.
$$ For $\pi \in \mathcal P(X \times Y)$ and $(\varphi, \psi) \in L_1 (\mu) \times L_1 (\nu)$ and $T \in \mathcal T$ , let $$
\mathbb K (\pi) := \int_{X \times Y} c d \pi \quad \text{and} \quad \mathbb J(\varphi, \psi) := \int_{X} \varphi d \mu+\int_{Y} \psi d \nu \quad \text{and} \quad \mathbb M(T) := \int_{X} c (x, T(x)) \mathrm d \mu (x).
$$ Brenier Theorem: Let $X = Y = \mathbb R^d$ and assume that $\mu, \nu$ both have finite second moment such that $\mu$ does not give mass to small sets (those ones with Hausdorff dimension are at most $d-1$ ). The cost function is $c(x,y)  := \frac{1}{2} |x-y|^2$ . For each $\pi^\dagger$ minimizing $\mathbb K$ over $\Pi(\mu, \nu)$ , there is $T$ minimizing $\mathbb M$ over $\mathcal T$ such that $\pi^\dagger = (\operatorname{Id}, T)_\sharp \mu$ . For each $T \in \mathcal T$ , $T$ minimizes $\mathbb M$ over $\mathcal T$ if and only if $T =\nabla \varphi$ for some proper convex l.s.c. $\varphi \in L_1 (\mu)$ . There is a unique (up to $\mu$ -a.e.) minimizer of $\mathbb M$ over $\mathcal T$ .","['optimal-transport', 'convex-analysis', 'probability-theory', 'calculus-of-variations']"
4485486,Rolling 3 dice and getting exactly 2 to be of the same number,"I am reading about rolling a six-sided die and I came up with this equation myself. I know this is wrong but couldn't really figure out why. Could someone please help me understand? The probability of rolling $3$ dice and getting $2$ to be the same number $$=\frac{|E|}{|S|}= \frac{6 \cdot 5 \cdot 3!}{6^3}$$ The first $6$ is for having $6$ different possible choices of our target(AAX results), $5$ is for $5$ possible choices for the non-pair number and $3!$ is the number of possible ways to order the three numbers we rolled (and I think this might be the incorrect part of my equation). Finally, $6^3$ is just all possible outcomes.","['combinatorics', 'probability']"
4485501,Confusion about Finite Differences Method Notation,"I would need a confirmation that I am understanding one of the steps in the lecture notes about numerical methods right. We have an ODE with $y\in C^1(t)$ : \begin{align}
y'(t) &= f(t, y(t))\\
y(t_0) &= y_0
\end{align} and we choose the integration interval $I = [t_0, T]$ , which will be divided with the step length $h = (T-t_0)/N_h$ , with $N_h$ being the number of the steps. $u_j$ is the approximation of the exact solution at $t_j$ , the exact solution is denoted by $y_j := y(t_j)$ . Also let $f_j$ be defined as $f_j = f(t_j, u_j)$ and $u_0 = y_0$ . Then the text goes on as: 'When using a simple one step method we can use finite difference method: \begin{align}
y'(t_n) \approx \frac{y(t_{n+1})-y(t_n)}{h}
\end{align} and with using $y'(t_n) = f_n$ we get the Euler's forward method: $u_{n+1} = u_n + hf_n$ .'
The problem I am having stems from the fact that we choose the notation $y_n$ for the exact solutions and I am confused as far as how I can set $y(t_n) = f_n$ since $f_n$ is a function of the approximated solutions. It is clear to me, that when I put the values of $u_n$ into the finite difference method, I get the desired form of the Euler's formula, but is it how it is meant (and the finite difference method is just a general formula with a little unfortunate notation)?","['ordinary-differential-equations', 'cauchy-problem', 'numerical-methods', 'finite-differences', 'eulers-method']"
4485524,"If $f(z)=\overline{f(\overline z)}$ for a holomorphic $f$, is the same true for its derivative?","Suppose that $f : \mathbb C \to \mathbb C$ is an entire function which satisfies the relation $$
f(z)=\overline{f(\overline z)}
$$ for every $z \in \mathbb C$ . I'm wondering if the same is true for its complex derivative, i.e. so we have $f'(z)=\overline{f'(\overline z)}$ ?",['complex-analysis']
4485542,$\operatorname{tr}(A^k)=0 \space \forall k\in \Bbb{Z}^+$ implies $A$ is nilpotent. Does this imply $\operatorname {char}(K) =0$?,"$\mathcal{M}_{n}(K) $ : Set of all $n×n$ matrices over the field $K$ . $A\in \mathcal{M}_{n}(K) $ is called nilpotent if $A^k=\textbf{0}$ for some $k\in \Bbb{Z}^+$ It is clear that if $A$ is nilpotent then $\operatorname{tr}(A^k) =0$ for all $k\in \Bbb{Z}^+$ The converse is also true if $\operatorname{char}(K) =0$ My question: Suppose for a matrix $A\in\mathcal{M}_n(K)$ , $\operatorname{tr}(A^k)=0 \space  \forall k\in \Bbb{Z}^+ $ implies $A$ is nilpotent.
Can we conclude that $\operatorname{char}(K) =0$ ?","['trace', 'matrices', 'abstract-algebra', 'linear-algebra', 'soft-question']"
4485544,For which $B$ is $BA$ positive definite?,"Suppose $A$ is an $m\times n$ real-valued full-rank matrix. What is a nice way to characterize the set of real-valued $n\times m$ matrices $B$ such that $BA$ is positive definite? For $n=1$ , this is the set of vectors in the same half-plane as $A$ (viewed as column vector).","['matrices', 'linear-algebra', 'positive-definite']"
4485619,"Showing that for a subgroup $H \subset G$ of a linear algebraic group $G$, the closure $\overline{H} \subset G$ is a subgroup.","Let $G$ be a linear algebraic group over an algebraically closed field $K$ and $H \subset G$ be a subgroup. Denote by $\overline{H}$ the closure of $H$ in $G$ with respect to the Zariski-topology on $G$ . I now want to show, that $\overline{H} \subset G$ is a subgroup and hence a linear algebraic group. Idea: We have $H \subset G$ and the closure $\overline{H}$ is by definition the smallest closed subset of $G$ that contains $H$ , so in particular $\overline{H} \subseteq G$ (as subset). Also since, $H \subset \overline{H}$ , we have that $\overline{H}$ is non-empty. My problem now is that I don't know how to prove that this is actually a group. Edit: In order for $\overline{H}$ to be a subgroup, we have to show that $\overline{H} \overline{H}^{-1} \subseteq \overline{H}$ . Let $f: G \times G \to G$ , $f(x,y)=xy^{-1}$ be the multiplication (with inversion) in $G$ . By orangeskid´s answer below, this map is continious. Hence $f^{-1}(\overline{H})$ is closed. Furthermore we have $H \times H \subset f^{-1}(\overline{H})$ and taking closures $\overline{H \times H} \subset f^{-1}(\overline{H})$ . Then left to show is $$\overline{H} \times \overline{H} \subset \overline{H \times H}.$$ This would finally imply, that $$f(\overline{H} \times \overline{H}) = \overline{H} \overline{H}^{-1} \subseteq \overline{H}.$$ So now i´m stuck showing $\overline{H} \times \overline{H} \subset \overline{H \times H}$ . Is this way ok?","['general-topology', 'algebraic-groups', 'group-theory']"
4485625,Derivative of $\tan^{-1} \sqrt{\frac{1-\cos x}{1-\sin x}}$,Is there any way to differentiate $\tan^{-1} \sqrt{\frac{1-\cos x}{1-\sin x}}$ without any messy calculations? Here are my thoughts: We write $\cos x$ and $\sin x$ in terms of $\tan{\frac{x}{2}}$ . Then our function becomes $\tan^{-1} \frac{\sqrt{2}\tan \frac{x}{2}}{1-\tan \frac{x}{2}}$ . But I am afraid this doesn't seem to work since we can't extrapolate any triginometric formula of $\tan$ from here.,['derivatives']
4485643,What is the automorphism group of a complete bipartite graph?,"Let $m, n \in \mathbb{N}$ with $m \ne n$ . Determine the automorphism group of the complete bipartite
Graph $\mathcal{V}_{m,n}$ . Some definitions:
A complete bipartite graph is a special kind of bipartite graph where every vertex of the first set is connected to every vertex of the second set. A bipartite graph is a graph whose vertices can be divided into two disjoint and independent sets $U$ and $V$ , that is every edge connects a vertex in $U$ to one in $V$ . Equivalently, a bipartite graph is a graph that does not contain any odd-length cycles. My idea: In need to find an appropriate characterization of the larger set in the bipartite decomposition, but I am not sure. An old exam question I am looking at to learn for my upcoming discrete math exam. I unfortunately am not sure what to do. Thanks in advance!","['graph-theory', 'automorphism-group', 'discrete-mathematics']"
4485645,Why is Kummer's surface a smooth manifold,"The $\mathbb{Z}/2\mathbb{Z}$ action on $\mathbb{T}^4$ has $16$ fixed points. Blowing up at these $16$ points, we get a new manifold $\tilde{\mathbb{T}}^4$ . The action extends trivially at each exceptional divisor. Then the quotient space of $\tilde{\mathbb{T}}^4$ is called Kummer's surface. Since the action extends trivially, each exceptional divisor is fixed by the action so that the action is not free there. Thus, we cannot apply quotient manifold theorem. How to see Kummer's suface is a smooth manifold?","['complex-geometry', 'differential-topology', 'complex-manifolds', 'differential-geometry']"
4485648,What is the average of rolling two dice and only taking the value of the lower dice roll?,"My question is related to this question , with the exception that I'm looking for the average when taking only the lower of two dice rolls. My question is: What is the average of rolling two dice and only taking the value of the lower dice roll? This formula is used for the ""take higher roll"" case: $$
E[X] = \sum_{x=1}^6\frac{2(x-1)+1}{36}x = \frac{1}{36}\sum_{x=1}^6(2x^2 - x) = \frac{161}{36} \approx 4.47
$$ ...and includes the term "" $2(x−1)+1$ "". Could someone please explain how that term would have to be changed so that it applies for ""take lower roll""? From the original example, I'm somewhat confused where "" $x-1$ "" comes from, although it is mentioned in the comments. PS: I would have written this question as a comment to the original question, but I lack the points to be allowed to write comments.","['dice', 'probability']"
4485659,A Pseudo-Derivative for $f(x)=|x|$,"I was wondering what the significance of a function that gives the slope of $y=|x|$ at any $x$ is. If $$f(x)=|x|$$ then we could do, as the derivative: $$\frac{d f}{d x}=\frac{x}{|x|}$$ or $$\frac{d f}{d x}=\frac{|x|}{x}$$ This would give us the slope at any $x$ . What is wrong with my approach? How would this connect to limits?","['calculus', 'slope', 'derivatives', 'absolute-value']"
4485695,"Find the extinction time $T$ for the solutions $\ddot{y}+a\,\text{sgn}(\dot{y})\sqrt{|\dot{y}|}(1+|\dot{y}|^{3/2})+b\,\sin(y)=0,\,y(0)>0,\,y'(0)=0$?","For the differential equation with two real-valued positive parameters $\{a,\,b\}>0$ : $$\ddot{y}+a\cdot\text{sgn}(\dot{y})\sqrt{|\dot{y}|}\left(1+|\dot{y}|^{\frac{3}{2}}\right)+b\cdot\sin(y)=0,\,y(0)>0,\,\dot{y}(0)=0 \tag{Eq. 1}\label{Eq. 1}$$ I would like to know if is possible to find its extinction time $0 < T < \infty$ such their solutions become exactly $y(t)=0,\,t>T$ , as a function of their parameters and initial conditions $\{a,\,b,\,y(0),\,\dot{y}(0)\}$ , being in principle, $y(t)$ a real-valued scalar function. Motivation - not needed for finding the solution Recently I learned that a ordinary differential equation (ODE) require to have a point in time where is locally non-Lipschitz (LNL) in order to been able of having solution with a finite extinction time (details here ), which have interesting consequences in using ODEs as a tool for model reality: An ODE that stands solutions of finite duration cannot hold uniqueness of solutions at the same time (or at least, violates Picard-Lindelöf Theorem's conditions due the LNL singular point). If a solution is of finite duration, it don't going to hold time-reversal symmetry (property is commonly only attributed to entropy). Since traditional physics models holds uniqueness of solutions, their solutions, accurately speaking, are always never-ending in time: this means that everything have ever happen before in time could be, in principle, affecting any experiment in the present time, which is in conflict with locality and causality. With this in mind, I am exploring how to modify the classic nonlinear pendulum with friction in order of having a finite extinction time, and I am using a LNL drag force: $$F_d =  a\cdot\text{sgn}(\dot{y})\sqrt{|\dot{y}|}\left(1+|\dot{y}|^{\frac{3}{2}}\right) = a\cdot\text{sgn}(\dot{y})\sqrt{|\dot{y}|} + a\cdot\dot{y}|\dot{y}|  \tag{Eq. 2}\label{Eq. 2}$$ which behaves similar to the classic quadratic drag force for high speed $F_d \approx c\cdot (\dot{y})^2$ , also behaves similar the classic Stokes' Law for non-zero-low-speeds $F_d \approx 2c\cdot \dot{y},\,0.2 <\dot{y}<1.2$ , and makes a singular LNL point for $\dot{y}\to 0$ so finite duration solutions could arise (see details here ). Issues with numerical examples: If the classic nonlinear pendulum with friction equation is reviewed as example, in Wolfram-Alpha it can be seen it have decaying solutions as expected: $$\ddot{x}+2\cdot0.021\,\dot{x}+0.2\sin(x)=0, x(0)=\frac{\pi}{2}, \dot{x}(0)=0 \tag{Eq. 3}\label{Eq. 3}$$ But following the analysis for T-Symmetry , under the transformation $\hat{t} \to - t$ the position and acceleration remains the same, but the velocity profile change in sign: this applied to \eqref{Eq. 3} shows it change under this transformation, so it not fulfill T-Symmetry. If instead the standard drag force $F_{\text{drag}}\propto (\dot{x})^2$ is used as is shown here for the equation: $$\ddot{x}+0.021(\dot{x})^2+0.2\sin(x)=0, x(0)=\frac{\pi}{2}, \dot{x}(0)=0 \tag{Eq. 4}\label{Eq. 4}$$ their solution aren't showing the expected decay one can see on the experimental pendulums. This is commonly solve using an ansatz for the drag force $F_{\text{drag}}\propto \dot{x}|\dot{x}|$ , which as can be seen here for the equation: $$\ddot{x}+0.021\dot{x}|\dot{x}|+0.2\sin(x)=0, x(0)=\frac{\pi}{2}, \dot{x}(0)=0 \tag{Eq. 5}\label{Eq. 5}$$ their solution are indeed having the expected decaying behavior for a pendulum with friction. Since \eqref{Eq. 4} fulfills T-Symmetry but fails to proper model the pendulum with friction, but both \eqref{Eq. 3} and \eqref{Eq. 5} don't fulfill T-Symmetry but modeled properly the amplitudes, its look like for having a decaying behavior it was required to choose a differential equation that is not fulfilling the time-reversal-symmetry . But, since the function $f(x)=x|x|$ is locally Lipschitz (see here ), it cannot be used for having a singular point on a finite time where uniqueness could be broken, so this ansatz wouldn't have solutions of finite duration, this is why I chose to work instead with $F_d$ which also shows to have the decaying solutions (but also without T-Symmetry): $$\ddot{x}+0.021\,\text{sgn}(\dot{x})\sqrt{|\dot{x}|}(1+|\dot{x}|^{\frac{3}{2}})+0.2\sin(x)=0, x(0)=\frac{\pi}{2}, \dot{x}(0)=0 \tag{Eq. 6}\label{Eq. 6}$$ Analysis of the decay Since for some parameters $\{a,\,b\}$ the equation \eqref{Eq. 1} is having decaying solutions as can be seen for the example of \eqref{Eq. 6}, when the time is reaching the extinction time, the behavior of \eqref{Eq. 1} will be driving by: For the position the small-angle approximation could be used so $\sin(y)\approx y$ For the drag force $F_d$ , the quadratic term $\dot{y}|\dot{y}| \to 0$ for small speeds, so the remaining term $\text{sgn}(\dot{y})\sqrt{|\dot{y}|}$ will be only present. With this, in the small-angles low-speeds regimen the equation will be behaving as: $$\ddot{y}+a\cdot\text{sgn}(\dot{y})\sqrt{|\dot{y}|}+b\cdot y=0 \tag{Eq. 7}\label{Eq. 7}$$ Which, as for the previous examples without T-Symmetry, the equation show its having decaying solutions: $$\ddot{x}+0.021\,\text{sgn}(\dot{x})\sqrt{|\dot{x}|}+0.2\,x=0, x(0)=\frac{\pi}{14}, \dot{x}(0)=0 \tag{Eq. 8}\label{Eq. 8}$$ I have found the following papers under the term sublinear damping that shows example in physics of equations really similar to \eqref{Eq. 7} and \eqref{Eq. 8}: ""A note on the dynamics of an oscillator in the presence of strong friction"" - H.Amann & J.I.Diaz ""Behavior of Solutions of Second-Order Differential Equations with Sublinear Damping"" - J. Karsai & J. R. Graef So I believe they will be achieving a finite extinction time, but I have not being able to formally prove it. Added later I found this paper: ""The pendulum—Rich physics from a simple system"" - Robert A. Nelson & M. G. Olsson where the autors, in equation $(19)$ use a similar drag force of the form $F_d = b\ |\dot{y}| + c\ (\dot{y})^2$ , so at least a description through two components doesn't look like a complete insane approach. Also on equations $(59)$ and $(60)$ they introduce a Drag Force $F_d = b\ \dot{y} + c\ \dot{y}|\dot{y}|$ for a more accurate description of the air effects on the pendulum.","['ordinary-differential-equations', 'real-analysis', 'finite-duration', 'mathematical-physics', 'dynamical-systems']"
4485700,What is the probability that 3 random chords in a circle do not intersect?,"I understand that for 2 random chords, the probability of no intersections is 1/3 thanks to this blog post . What happens when I have 3 random chords? Is there an intuitive explanation for calculating the number of intersections given n random chords? I found a post that proposes the following formula for r chords, but this does not hold for 2 chords. Any ideas? $$P(NoIntersection) = \frac{2^r}{(r+1)!}$$ Note: By random chord, I mean by randomly picking 2 points that lie on the circle.","['intersection-theory', 'statistics', 'circles', 'probability-theory']"
4485729,What is the solution to this non-linear second order differential equation?,"I'm trying to solve the following non-linear second order differential equation: $$\tag{1}
\frac{d\, }{dx} \Bigl( \frac{1}{y^2} \, \frac{dy}{dx} \Bigr) = -\, \frac{2}{y^3},
$$ where $y(x)$ is an unknown function on the real axis.  I already know the ""trivial"" solution $y(x) = y_0 \pm x$ .  The solution I'm looking may involve trigonometric functions, but I'm not sure.  Take note that we may pose $$\tag{2}
u = \frac{1}{y},
$$ so that (1) takes another form: $$\tag{3}
\frac{d^2 u}{dx^2} - 2 \, u^3 = 0.
$$ So what is the non-linear solution $y(x)$ ?  Or $u(x)$ ?","['calculus', 'functions', 'ordinary-differential-equations', 'fundamental-solution']"
4485747,"With $x_1^2+3x_2^2+2x_1x_2=32$, find max value of $|x_1-x_2|$","With $x_1^2+3x_2^2+2x_1x_2=32$ , find the maximum of $|x_1-x_2|$ . I have tried with AM-GM, but can't solve it. With $d = |x_1-x_2|$ and $d^2 = 2x_1^2 + 4x_2^2 - 32$ , then I wonder how to do next.
Thank a lot for helping!","['multivariable-calculus', 'calculus', 'optimization', 'inequality']"
4485749,A uniform limit of bi-Lipschitz embedding which preserves total length,"I'm trying to verify part of a claim from Freedman-He-Wang's paper on Mobius knot energy, in Prop. 8.3. My question is less about knot energies, and more about the preservation of length in a uniform limit. To be specific, suppose $\gamma_i: [0,1] \to \mathbb{R}^3$ is a sequence of rectifiable simple closed curves, each parametrized with respect to arc length and with total length $1$ . Furthermore, suppose for each $\varepsilon > 0$ , there is some $\delta > 0$ such that each $\gamma_i$ is $(1 + \varepsilon)$ bi-Lipschitz on subarcs of length $\leq \delta$ . (This property is a consequence of Lemma 1.2, for knots with finite Mobius energy). Suppose $\gamma_i$ converges to a curve $\gamma$ uniformly. Must it be the case that $\gamma$ also has total length $1$ ? Showing $L(\gamma) \leq 1$ is a straightforward application of Fatou's lemma. However, the uniform limit of curves could lose length. For instance, consider a sequence $\Gamma_i$ of loops of length $1$ each contained in concentric spheres of radius $\frac{1}{i}$ . Then the uniform limit is a single point with zero length. This problem doesn't occur under our assumptions, but I'm having trouble showing the arc-length doesn't decrease in the limit.","['curves', 'geometry', 'real-analysis', 'calculus', 'knot-theory']"
4485774,A number sequence problem involving binomial transform.,"Let $\{b_n\}_{n\geq0}$ be a sequence of numbers such that $b_nb_{n+1}=0$ , and define $$a_n:=\sum_{k=0}^n(-1)^{n-k}\binom{n}{k}b_k.$$ If $\lim_{n\to\infty}a_n=0$ , can we conclude that $b_n=0$ for all $n$ ? I have tried many special $\{b_n\}$ but neither of them makes $\{a_n\}$ convergent. I think it’s a nontrivial problem. More generally, if $\{b_n\}_{n\geq0}$ is a sequence with infinitely many zeros and $\lim_{n\to\infty}a_n=0$ , can we still conclude that $b_n=0$ for all $n$ ?","['number-theory', 'integer-sequences']"
4485775,"Meaning of the derivative $\frac{d f(x,y)}{dx}$","Suppose we are given a function $f(x,y) = x^2 + y$ defined over $\mathbb{R}^2$ . Then $$\frac{df}{dx} = \frac{\partial f}{\partial x} + \frac{\partial f}{\partial y} \cdot \frac{dy}{dx} = 2x + \frac{dy}{dx}$$ and $$\frac{\partial f}{\partial x} = 2x$$ How do I interpret $\frac{df}{dx}$ , both mathematically and intuitively? We know derivatives refer to tangents and in the case of $\frac{\partial f}{\partial x}$ , we fix the $y$ and look at the tangent of the now-single-variable function $g(x) = f(x,y_0)$ . I don't know what it means in the case of $\frac{df}{dx}$ .","['multivariable-calculus', 'calculus']"
4485785,Prove $a\ge b \ge c \ge d \ge 1 \implies x^{4} -ax^{3}-bx^{2}-cx-d $ has no integer root.,"If $a,b,c,d$ are positive integers such that $a\ge b\ge c \ge d\ge 1$ , prove that $$ x^{4} -ax^{3}-bx^{2}-cx-d $$ has no integer root. Attempt: If there is an integer solution $x=x_{0}$ , then $$x_{0}^{4} = a x_{0}^{3}+ b x_{0}^{2}+c x_{0}+d$$ Notice that it is clear $x_{0} | d$ . Notice that $x_{0} \ne 0$ because $d>0$ . If $x_{0}=1$ then, $1=a+b+c+d$ , which is impossible because $a+b+c+d \ge 4$ . So $x_{0} \notin \{0,1\}$ . If $x_{0} = -1$ , then $1 = (b-a) + (d-c) \le 0$ , contradiction. So $x_{0} \notin \{-1,0,1\}$ . So far we can say that $|x_{0}| \ge 2$ . Now if $x_{0} < 0$ , then $x_{0}^{4} \ge 16 >  0$ . But $a x_{0}^{3},cx_{0} < -1$ with $$ |a x_{0}^{3} | > b x_{0}^{2} $$ $$ |c x_{0} | > d $$ so we have $x_{0}^{4} = ax_{0}^{3} + bx_{0}^{2} + cx_{0} + d < 0$ contradiction. So we must have $x_{0} \ge 2$ . Now, since $x_{0}| d$ then $d = e x_{0}$ , where $e$ positive integer.
But this means $ a \ge b \ge c \ge d \ge x_{0}$ , which means $$ax_{0}^{3}+bx_{0}^{2}+cx_{0}+d > x_{0}^{4}$$ contradiction. Some parts of this proof are not necessary I know, I was just working on it while writing it in this post. Are the better/more elegant solutions?","['contest-math', 'algebra-precalculus', 'roots', 'polynomials']"
4485789,"Show by divergence theorem $\int_SF.n\, dS=4\pi$ where $F=(x-z)i + (x^3+yz)j - 3xy^2k$","Show by divergence theorem $$\int_SF.n\, dS=4\pi$$ where $F=(x-z)i + (x^3+yz)j - 3xy^2k$ and S is the surface of the cone $z=2-\sqrt{x^2+y^2}$ above the xy-plane. $div\,F=1+z$ . $$\int_V\,div\,F\,dV=\int_V(1+z)\,dV$$ Edit: Using cylindrical co-ordinates, $x= r \cos\theta;
y=r \sin\theta; z=z$ , $z \in [0,2-r], \theta\in [0,2\pi], r\in [0,2]$ , we have $$\int_{r=0}^{2}\!\int_{\theta=0}^{2\,\pi}\!\int_{z=0}^{2-r}\!(1+z)\,{\rm d}z
\,{\rm d}\theta\,{\rm d}r=\frac{20\pi}{3}
$$ Ans would be $4\pi$ .....! Where is the mistake? Please suggest parametrization for the inverted cone and correct the limits of integration.","['divergence-theorem', 'multivariable-calculus']"
4485797,limit of function near a given point,"Find the limit of the given function as $x\to -2$ without using L’Hôpital’s Rule: $$\displaystyle \lim_{x \to -2} \frac{\sqrt[3]{x-6} + 2}{x^3 + 8}$$ I used the identity: $x^3 + 2^3 = (x+2)(x^2 -2x +4)$ at the denominator. Then i tried to use the same identity at the numerator and didnt succeed. So i tried to expand the numerator, but i got different answer by checking the limits from both of the sides near $x = -2$ .
The answer is $\frac{1}{144}$ which is an approximation of the limit at the given point. Any suggestions and support would be kindly appreciated. Edit: Just watching it from the side and I can rewrite the 2 at the numerator as $\sqrt[3]2$ . Yet, its not helping a lot.","['limits', 'calculus', 'limits-without-lhopital']"
4485815,The dimension of space of polynomials with matrix.,"Let $V:=M_{3\times 3}\ (\mathbb C)$ , i.e., $V$ is a set of $3\times 3$ matrices of complex number. Let $A=\begin{pmatrix}0&-2&0\\1&3&0\\0&0&2\end{pmatrix}$ , $W:=\{p(A)\mid p(t)\in \mathbb C [t]\}$ , where $\mathbb C[t]$ is the set of polynomials whose cooefficients are complex numbers. Then, $W$ is a subspace of $V$ . Calculate $\dim W.$ I think the characteristic polynomial of $A$ is necessary so I calculated it : $(x-2)^2(x-1)$ . And from Cayley-Hamilton, I get $(A-2I)^2(A-I)=O.$ I don't know what should I do next. For this $A$ , ・ $A$ is not a nilpotent matrix ・ $A$ doesn't seem to have periodicity. ( $n\in \mathbb N$ s.t. $A^n=A$ doesn't seem to exist.) So I'm having difficulty finding what $W$ is like. Thanks for any help.","['matrices', 'linear-algebra', 'polynomials']"
4485844,Compute $\lim_{n\to\infty}(\frac{a_{n+1}}{\sqrt[n+1]{b_{n+1}}}-\frac{a_n}{\sqrt[n]{b_n}})$ given $(a_{n+1}-a_n)/n\to a$ and $b_{n+1}/(nb_n)\to b$,"Let $(a_n)_{n\geq 1}$ and $(b_n)_{n\geq 1}$ be positive real sequences such that $$\lim_{n\to\infty}\frac{a_{n+1}-a_n}n=a\in \mathbb R_{>0}\qquad\text{and}\qquad \lim_{n\to\infty}\frac{b_{n+1}}{nb_n}=b\in \mathbb R_{>0}.$$ Compute $$\lim_{n\to\infty}\left(\frac{a_{n+1}}{\sqrt[n+1]{b_{n+1}}}-\frac{a_n}{\sqrt[n]{b_n}}\right).$$ This is W5 of József Wildt International Mathematical Competition, 2020 . I have made some progresses and got stuck. Using Cauchy's criterion , I have obtained that $\sqrt[n]{\frac{b_{n+1}}{b_1n!}}\to b$ and thus $$\sqrt[n]{\frac{b_n}{b_1n!}}=\sqrt[n]{\frac{b_{n+1}}{b_1n!}}\cdot\sqrt[n]{\frac{nb_n}{b_{n+1}}}\cdot\sqrt[n]{\frac1n}\to b,\qquad\text{as}\ \  n\to\infty.$$ Stirling's formula implies that $\lim_{n\to\infty}\frac{\sqrt[n]{b_n}}n=\frac be$ . Now it seems resonable to guess that $$\lim_{n\to\infty}\left(\frac{a_{n+1}}{\sqrt[n+1]{b_{n+1}}}-\frac{a_n}{\sqrt[n]{b_n}}\right)=\lim_{n\to\infty}\left(\frac{\frac{a_{n+1}}{n}}{\frac{\sqrt[n+1]{b_{n+1}}}{n}}-\frac{\frac{a_n}n}{\frac{\sqrt[n]{b_n}}n}\right)\overset{?}{=}\lim_{n\to\infty}\frac eb\frac{a_{n+1}-a_n}n=\frac{ae}b\tag{1};$$ or another possibility $$\lim_{n\to\infty}\left(\frac{a_{n+1}}{\sqrt[n+1]{b_{n+1}}}-\frac{a_n}{\sqrt[n]{b_n}}\right)=\lim_{n\to\infty}\left(\frac{\frac{a_{n+1}}{n+1}}{\frac{\sqrt[n+1]{b_{n+1}}}{n+1}}-\frac{\frac{a_n}n}{\frac{\sqrt[n]{b_n}}n}\right)\overset{?}{=}\frac eb\lim_{n\to\infty}\left(\frac{a_{n+1}}{n+1}-\frac{a_n}n\right),\tag{2}$$ where the limit $\lim_{n\to\infty}\left(\frac{a_{n+1}}{n+1}-\frac{a_n}n\right)$ can be obtained by $$\frac{a_{n+1}}{n+1}-\frac{a_n}n=\frac{a_{n+1}-a_n}n+\frac{a_{n+1}}{n+1}-\frac{a_{n+1}}n=\frac{a_{n+1}-a_n}n-\frac{a_{n+1}}{n(n+1)}$$ and Cesaro-Stolz: $\lim_{n\to\infty}\frac{a_{n+1}}{n(n+1)}=\lim_{n\to\infty}\frac{a_{n+1}-a_n}{n(n+1)-(n-1)n}=\frac a2$ , so $\lim_{n\to\infty}\left(\frac{a_{n+1}}{n+1}-\frac{a_n}n\right)=a-\frac a2=\frac a2$ . In $(1)$ and $(2)$ above, I don't know the eact reasons for both ' $?$ ', I just guess them. Therefore, when I looked at the same limit from two different points of view, namely $(1)$ and $(2)$ , I got different results, which makes me confused. I wonder which one is correct and what is the rigorous proof. Could someone help me to finish this problem?","['limits', 'calculus', 'real-analysis']"
4485857,Probability of rolling exactly 1 number exactly 3 times in 6 rolls of a fair die,"I'm trying to calculate the probability based on the size of the event space divided by the size of the sample space $P=\frac{|E|}{|S|}$ I know that $|S|=6^6$ , but am not sure what exactly the event space consists. Currently my thoughts are that we have 6 choices for our favorable event(the triples) and for the remaining 3 numbers we have $5\times5\times4=100$ , $4$ because we do not want to include the possibility of having 3 same numbers two times, and to consider all possible arrangements, there are then $\frac{6!}{3!1!1!1!}$ possibilities. This leads to our final equation of : $P=\frac{|E|}{|S|}=\frac{6!}{3!1!1!1!} \times \frac{6\times100}{6^6}$ But the problem is that this exceeds 1, which is clearly wrong but I couldn't really figure out what is the fix for my equation. Thanks:)","['combinatorics', 'probability-theory', 'probability']"
4485879,The set of compatible vector fields,"Let us fix some smooth vector field $F(x)$ in some open submanifold $M\subseteq \mathbb R^n$ , $n\ge3$ . A vector field $G(x)$ is said to be compatible with $F(x)$ if the Lie bracket $[F,G]$ is a linear combination of $F(x)$ and $G(x)$ , i.e. $$
\forall x\in M \quad [F(x),G(x)]= \alpha(x) F(x)+\beta(x) G(x),
$$ where $\alpha(x)$ and $\beta(x)$ are some smooth scalar functions. Denote by $C_F$ the set of all smooth vector fields compatible with a given vector field $F(x)$ . What is the structure of the set $C_F$ ? Does it always contain any vector fields other than fields of the form $\gamma(x) F(x)$ ,
where $\gamma(x)$ is a smooth scalar function? And if so, how can one get such vector fields?","['vector-fields', 'submanifold', 'smooth-manifolds', 'differential-geometry']"
4485903,"chapter 1 ex 4.22 from Brownian motion, martingales, and stochastic calculus by Jean-Francois Le Gall","This is ex 4.22 from chapter 1 of''Brownian motion, martingales, and stochastic calculus by Jean-Francois Le Gall''. exercise 4.22: Processes on defined on a probability space $(\Omega,\mathcal{F},P)$ equipped with a complete filtration $(\mathcal{F}_t)_{t \in [0,\infty]}$ . Let U be an $\mathcal{F}_0$ -measurable real random variable, and let M be a continuous local martingale. Show the process $N_t=UM_t$ is a continuous local martingale. Definition of continuous local martingale:an adapted process $M=(M_t)_{t \geq 0}$ with continuous sample paths and such that $M_0=0$ a.s. is called a continuous local martingale if there exists a nondecreasing sequence $(T_n)_{n \geq 0}$ of stopping times such that $T_n \uparrow \infty$ and, for every n, the stopped process $M^{T_n}$ is a uniformly integrable martingale. Property of continuous local martingale: A martingale with continuous sample paths is a continuous local martingale and the sequence $T_n=n$ reduces M. I am not sure [https-//math.stackexchange.com/questions/4289186/how-to-prove-that-um-t-t-geq-0-is-a-continuous-local-martingale?rq=1][1] this is a feasible way, since ex 4.22 has a stronger condition with a complete filtration. Bounty: I haven't made any further progress, so an answer is appreciated. update: I will follow neijimban's hint and try the techniques used in prop 4.7 of the book: We write $M_t=M_0+N_t.$ there exists a sequence $(T_n)$ of stopping times that reduces N. Then if $s \leq t$ , we have for every n, $N_{ s \wedge T_n}=E[N_{ t \wedge T_n} | \mathcal{F}_s]$ . Adding both sides the random variable $M_0$ (which is $\mathcal{F}_0$ -measurable and in $L^1$ by assumption), we get $M_{s \wedge T_n}=E[M_{t \wedge T_n} | \mathcal{F}_s]$ . Then I am not sure if we can assume there is a random variable Z such that $|M_{t \wedge T_n}| \leq Z$ , and then proceed by dominated convergence to get that $M_{ t \wedge T_n}$ converges to $M_t$ in $L^1$ . Then as $n \rightarrow \infty$ , we get $M_s=E[M_t | \mathcal{F}_s]$ to get uniformly integrable. Let $\tau_n= \inf \{t \geq 0: |UM_t| \geq n\}$ or $\tau \wedge T_n$ where $(T_n)_{n \geq 0}$ reduces $M$ . Since $T_n$ are stopping times and $M^{T_n}$ is a continuous local martingale and $|M^{T_n}| \leq n$ . If we assume $M_0 \in L^1$ , $M^{T_n}$ is dominated by $n+|M_0|$ . So $\lim_{n \rightarrow \infty} \int_{|M^{T_n}|>n} |M^{T_n}| dP(\omega)=0$ and this is the continuous local martingale. I am not sure if this works, so please provide an alternative if this is not correct, thanks!","['self-learning', 'probability', 'local-martingales', 'quadratic-variation', 'stochastic-calculus']"
4485998,Shortcut for drawing $f(-|x|)$,"I am trying to draw the graph of any function of type $f(-|x|)$ . I know that $f(|x|)$ means reflecting the graph to the right of the y-axis in the y-axis. Ignore the left hand side part of the graph , and $f(-x)$ means reflecting the graph in y- axis. Hence , i thought that $f(-|x|)$ can be interpreted such that firstly find the proper graph for $f(|x|)$ and after that reflect the graph of $f(|x|$ in y-axis to find $f(-|x|)$ . However , my thought did not work. For example if $f(x)=x^2+4x+4$ , then $f(-|x|)=x^2-4|x|+4$ is not the same as what i thought. Hence , i want to learn drawing the graph of $f(-|x|)$ . Is there any rule for it ?","['algebra-precalculus', 'functions', 'graphing-functions']"
4486028,Does finitely generated groups have finitely many finite retracts?,"A group $H$ is called a retract of a group $G$ if there exists homomorphisms $f:H\to G$ and $g:G\to H$ such that $gf=id_H$ . We know that a group $G$ is finite if and only if $G$ has finitely many subgroups. Now my question is that a finitely generated group $G$ has finitely many finite retracts? What I've tried: If $G$ is a finitely generated abelian group, then every retract of $G$ is a direct summand of $G$ . So the number of finite retracts of $G$ is finite.","['group-homomorphism', 'finite-groups', 'finitely-generated', 'retraction', 'group-theory']"
4486043,Doob's Martingale Decomposition -- Proving that the Martingale component is indeed a Martingale,"The Martingale-Part of the Doob decomposition for a stochastic process $(X_n)_n$ and filtration $(\mathcal F_n)_n$ is $$M_n=X_0+\sum_{k=1}^n\bigl(X_k-\mathbb{E}[X_k\,|\,\mathcal{F}_{k-1}]\bigr)$$ (see e.g. here ). I want to prove that this is indeed a Martingale and suceeded by showing $$\mathbb E[M_n-M_{n-1}| \mathcal F_{n-1}] =0$$ .
However, I failed to show $\mathbb E[M_n| \mathcal F_{n-1}] =M_{n-1}$ and wanted to know where my mistake is. My attempt is: $$\mathbb E[M_n| \mathcal F_{n-1}] = X_0 + \sum_{k=1}^n(\mathbb E[X_k | \mathcal F_{n-1}] - \mathbb E\big[  \mathbb E[X_k | \mathcal F_{k-1}] | \mathcal F_{n-1}\big]) = (*).$$ Now, note that for $k<n$ : $$  \mathbb E\big[  \mathbb E[X_k | \mathcal F_{k-1}] | \mathcal F_{n-1}\big]) = \mathbb E[X_k | \mathcal F_{n-1}] = X_k,$$ and for $k=n$ : $$\mathbb E\big[  \mathbb E[X_k | \mathcal F_{k-1}] | \mathcal F_{n-1}\big]) = \mathbb E[X_n | \mathcal F_{n-1}],$$ so that all terms of the sum in $(*)$ are 0. Therefore, we get $$(*) = X_0.$$ However, we should get $(*) = M_{n-1}$ . Where am I making my mistake?","['conditional-expectation', 'stochastic-processes', 'probability-theory', 'martingales']"
4486090,Is it possible to generalize this equation more?,"This is one of my discoveries, and my question is: can it be more general? Let $x, y, z$ be three arbitrary complex numbers and set $x_1=3 x^2+y^2$ , $x_2=1-z$ , $x_3=1+z$ , $x_4=3 x^2+y^2+4 x y z$ , $x_5=3 x^2+y^2-4 x y z$ , $x_6=3 x^2+y^2+z (3 x^2+2 x y-y^2)$ , $x_7=3 x^2+y^2-z (3 x^2+2 x y-y^2)$ , $x_8=3 x^2+y^2+z (3 x^2-2 x y-y^2)$ , $x_9=3 x^2+y^2-z (3 x^2-2 x y-y^2)$ . Then for $k=0,1,2,3,4,5$ , $2(x_1^k+x_1^kx_2^k+x_1^kx_3^k)=x_4^k+x_5^k+x_6^k+x_7^k+x_8^k+x_9^k$ . In case $x, y, z$ are integers, we get a Diophantine equation. For example, $2(7^1+21^1+(-7)^1)=(-9)^1+23^1+1^1+13^1+17^1+(-3)^1$ , $2(7^2+21^2+(-7)^2)=(-9)^2+23^2+1^2+13^2+17^2+(-3)^2$ , $2(7^3+21^3+(-7)^3)=(-9)^3+23^3+1^3+13^3+17^3+(-3)^3$ , $2(7^4+21^4+(-7)^4)=(-9)^4+23^4+1^4+13^4+17^4+(-3)^4$ , $2(7^5+21^5+(-7)^5)=(-9)^5+23^5+1^5+13^5+17^5+(-3)^5$ . My discovery published at: https://demonstrations.wolfram.com/author.html?author=Minh%20Trinh%20Xuan","['modular-arithmetic', 'number-theory', 'diophantine-equations', 'modular-forms', 'complex-numbers']"
4486113,"Check whether for a set of $n$ lines in 3D space, no two lines intersect – without testing each pair of lines","Given a set of lines in 3D space I want to determine whether no pair of lines intersect. Trivially, this can be done by checking each pair of lines. My question is if there is a way to avoid having to check each pair. Or, in other words: Does there exist an algorithm that tests a set of $n$ lines in 3D space for intersections in time less than $O(n^2)$ ? For Context: This is motivated by line segment intersection in 2D-space, where we naively can check all pairs of line segments, but in fact, there exists an output-sensitive algorithm that exploits the property that intersections can only occur between segments that are at some point sufficiently close to each other. Therefore, I wonder if for a set of lines in 3D space there is no way to exploit locality in a similar way resulting in only having to test lines that are sufficiently close to each other at some point? I spent the whole day researching this topic but could not find much on it - neither any hints on possible solutions nor explanations why this is impossible. I would be happy to receive either of both.","['computational-geometry', 'geometry', 'algorithms']"
4486120,Correct way to do U-sub,"Consider the following problem. $$\int x^2\sin (x^3) dx$$ let $u=x^3$ so $du=3x^2 dx$ .Then, $$\int x^2\sin (u) \frac{du}{3x^2}=\frac{1}{3}\int \sin(u)du$$ Is it mathematically correct? My concern is about keeping two variables $x$ and $u$ inside the integral sing. I know it can be done as follows: $$\int x^2\sin (x^3) dx=\frac{1}{3}\int 3x^2\sin (x^3) dx$$ and then let $u=x^3$ and $du=3x^2 dx.$ The point beyond my question is to know the correct way to teach someone the right way to do u-sub. I really appreciate any help you can provide.","['integration', 'solution-verification']"
4486150,Halmos: Principle of induction shows only one function satisfies a recurrence relation.,"Induction is often used not only to prove things but also to define things.
Suppose, to be specific, that $f$ is a function from a set $X$ into the same set $X$ , and suppose that $a$ is an element of $X$ . It seems natural to try to define
an infinite sequence $\{u(n)\}$ of elements of $X$ (that is, a function $u$ from $\omega \to X$ ) in some such way as this: write $u(0) = a, u(1) = f(u(0)), u(2) = f(u(1))$ , and so on. If the would-be definer were pressed to explain the ""and so on,"" he might lean on induction. What it all means, he might say, is that we define $u(0)$ as $a$ , and then, inductively, we define $u(n^{+})$ as $f(u(n))$ for every $n$ . This may sound plausible, but, as justification for an existential assertion, it is insufficient. The principle of mathematical induction does indeed prove, easily, that there can be at most one function satisfying all the stated conditions , but it does not establish the existence of such a function. (Book: Halmos, Paul. Naive Set Theory , Section 12, The Peano Axioms, p.48.) What might Halmos mean by the line in bold? What is the proof in question? I feel like I am missing something obvious. Context: The set of natural numbers is denoted $\omega$ here. The successor of $n$ is $n^{+}$ here. Principle of induction is expressed set-theoretically as $$ S\subseteq \omega \wedge 0\in S \wedge (n\in S \Rightarrow n^{+} \in S) \Rightarrow S = \omega$$","['elementary-set-theory', 'induction', 'set-theory']"
4486204,"How many $4$ letter words can be formed from the word ""CORONAVIRUS"".","Letters: $C$ , $O$ ( $2$ times), $R$ ( $2$ times), $N$ , $A$ , $V$ , $I$ , $U$ and $S$ . The number of $4$ letter words from $C$ , $N$ , $A$ , $V$ , $I$ , $U$ and $S$ is $7\times 6\times 5\times 4=840$ . The number of $4$ letter words from two $O$ or two $R$ while other $2$ letters are different is $\displaystyle \binom{2}{1}\times \binom{8}{2}\times \frac{4!}{2!}=672$ . The number of $4$ letter words from two $O$ and two $R$ together is $\displaystyle \frac{4!}{2!\times 2!}=6$ Total number of ways should be $840+672+6=1518$ . But this is not the right answer given. What am I doing wrong? What cases I am missing here? Please help!!! Thanks in advance!!!","['permutations', 'contest-math', 'combinations', 'solution-verification', 'combinatorics']"
4486237,"Probability of exactly $7$ unreplaced draws from $\{1,...,10\}$ to get $1,2,3$?","A box contains tickets numbered $1$ to $10$ . Tickets are drawn at random without replacement until the numbers $1, 2$ and $3$ are drawn. Find the probability that exactly $7$ draws are required. I am a little confused with this question. My first thought was to define the numbers $1,2,$ and $3$ as successes and the rest of the numbers as failures. Then, $$P(\text{in $6$ draws you get $2$ successes}) = \frac{\binom{3}{2} \binom{7}{4}}{\binom{10}{6}}.$$ But I don't know where to go next or if this is even needed. Can anyone help me? Thanks.","['combinatorics', 'probability']"
4486266,IMO combinatorics partitioning prime number products from 1973 shortlist,"Let $P$ be a set of 7 different prime numbers and $C$ a set of 28 different composite numbers each of which is a product of two (not necessarily different) numbers from $P$ . The set $C$ is divided into 7 disjoint four-element subsets such that each of the numbers in one set has a common prime divisor with at least two other numbers in that set. How many such partitions of $C$ are there? Observations: There are $\binom{7}{2}$ possible product pairings consisting of distinct primes from $P$ , and then also 7 prime squares, so together that accounts for the 28 elements in $C$ . Now suppose $p^2$ and $q^2$ were in the same partition. Then the condition would require that the other 2 numbers in the partition both be $pq$ , which is impossible because $C$ contains exactly 28 elements meaning that $C$ contains each product pairing (as formed in the ways discussed above) exactly once. So each of the partitions must contain a unique square, $a$ (say), and must take one of the forms { $a^2, ab, ac, ad$ } or { $a^2, ab, ac, bc$ }. It remains to count the possible ways of pairing the remaining elements in these forms for each of the seven sets. The IMO compendium solution arrives directly to this point before stating: It is now easy to count up the partitions There is a thread from half a decade back on this question but it wasn't solved and got messy. Some tentative thoughts: For the form { $a^2, ab, ac, bc$ }, the problem reduces to the number of bijections of the set { $1,1,2,2,3,3,4,4,5,5,6,6,7,7$ } to { $n_{1a}, n_{1b}, n_{2a}, n_{2b}, ... n_{7a}, n_{7b}$ } such that $n_i\neq i$ and $n_{ia}\neq n_{ib} \ \forall i$ for which the derangement formula (permutations without fixed points) might be a start, though I'm not convinced this is a step forwards. I suspect PIE would work somehow.","['contest-math', 'combinatorics', 'prime-numbers']"
4486267,How many distinct sets can be formed if each element can be present in at max r sets?,"A set of subsets of the set $\{1,2,\ldots,n\}$ is to be created in the following way : for a certain integer $r$ such that $n \geq r$ , Each element of $\{1,2,3,\ldots,n\}$ can be present in at most $r$ sets. The size of each subset is also equal to $r$ . How can one find such a collection of sets which has the largest size? Please note that I am taking $n \geq r$ . Example : Take $\{1,2,3,4\}$ (i.e. $n=4$ ) and each element can be present in at most $2$ sets so that $r=2$ . We obtain $\{1,2\},\{1,3\},\{2,4\},\{3,4\}$ as the answer. I don't know how to generalize this to larger $n$ and $r$ . Please tell me how to approach this. I did this using graph theory approach. But I was not sure of the exact number of sets. I defined a bipartite graph with left side as 1 to n with degree almost r and right side vertices of graph as some s with degree r. This gave me $nr\geq sr \implies s \leq n$ . But I was thinking of a certain number. * Is there any possible relation between s and $r^2$ is what I was looking for! Any thoughts?","['combinatorial-designs', 'graph-theory', 'combinatorics', 'discrete-mathematics', 'elementary-set-theory']"
4486280,Blowing Up the Indeterminancy Locus - Why is this sheaf invertible?,"The following is explained in Hartshorne, chapter 2.7. I will be considering varieties instead of schemes. Let $X$ be a variety over $k$ , and let $L$ be a line bundle on $X$ . Let $s_0,\dots,s_n$ be global sections of $L$ . This determines a morphism $\phi:X\setminus B\to\mathbb{P}^n$ , where $B$ is the base locus of the linear system. Then Hartshorne claims that there is a natural way to extend this to a morphism $\widetilde{\phi}:\widetilde{X}\to\mathbb{P}^n$ , where $\pi:\widetilde{X}\to X$ is the blow up along $B$ . He claims that this follows from the fact that the $\pi^*s_i$ generate a line bundle on $\widetilde{X}$ . My question is: how can this be true? If we are just pulling back the sections of $L$ , then these should vanish on the exceptional divisor. So how can they generate an invertible sheaf on $\widetilde{X}$ ?
Edit: as was pointed out below, vanishing of the sections does not imply vanishing of the germs, so this is fine. However, I still do not see how the morphism to projective space is meant to be defined if the sections still all vanish along the exceptional divisor, regardless of whether they generate the stalk.","['divisors-algebraic-geometry', 'algebraic-geometry', 'blowup', 'birational-geometry']"
4486282,Integral $\int_0^1 \frac{\ln(1-\sqrt{3}t+t^2)}{t} dt$,"$$I=\int_0^1 \frac{\ln(1-\sqrt{3}t+t^2)}{t} dt=-\frac{13}{72}\pi^2$$ Here is what I tried: $1-\sqrt{3}t+t^2=(z_1-t)(z_2-t)$ where $z_1=e^{\frac{\pi}{6}i}, z_2=e^{-\frac{\pi}{6}i}$ $$I=\int_0^1 \frac{\ln(z_1)+\ln(1-\frac{t}{z_1})}{t}+\frac{\ln(z_2)+\ln(1-\frac{t}{z_2})}{t} dt=\int_0^1 \frac{\ln(1-\frac{t}{z_1})}{t}+\frac{\ln(1-\frac{t}{z_2})}{t} dt$$ where $\ln(z_1)+\ln(z_2)=0$ and $\frac{1}{z_1}=z_2, \frac{1}{z_2}=z_1$ $$I=-\sum_{n=1}^\infty \frac{1}{n} \int_0^1 \frac{1}{t}\left(\frac{t}{z_1}\right)^n+\frac{1}{t}\left(\frac{t}{z_2}\right)^n dt = -\sum_{n=1}^\infty \frac{1}{n}\left( \frac{z_1^n+z_2^n}{n} \right)$$ where $z_1^n+z_2^n=2\cos(\frac{n\pi}{6})$ $$I=-2\sum_{n=1}^\infty \frac{\cos(\frac{n\pi}{6})}{n^2}$$ How to proceed next?","['integration', 'definite-integrals']"
4486323,Every graph on $6$ vertices with $\alpha(G) < 3$ contains at least $2$ copies of $K_3$ [duplicate],"This question already has an answer here : counting triangles in a graph or its complement (1 answer) Closed 1 year ago . I have to show that every graph on $6$ vertices with $\alpha(G) < 3$ contains at least $2$ copies of $K_3$ . $α(G)$ is the largest number of independent vertices and $ω(G)$ is the clique number. $ω(G) >3$ is clear, this means that we have $K_4$ which contains at least $2$ copies of $K_3$ How do I do $\omega(G) = 3$ ? Am I somehow supposed to use $R(3,3) = 6$ ?","['graph-theory', 'discrete-mathematics']"
4486387,Integral $\int_0^1 \frac{(1+t^2)}{1-t^2+t^4}\ln(t)dt$,$$I=\int_0^1 \frac{(1+t^2)}{1-t^2+t^4}\ln(t)dt=-\frac{4}{3}G  $$ G is Catalan's constant. $$I=\int_0^1 \frac{(1+t^2)^2}{(1+t^2)(1-t^2+t^4)}\ln(t)dt=\int_0^1 \frac{(1+t^2)^2}{(1+t^6)}\ln(t)dt$$ Do series expansion: $$I=\sum_{n=0}^\infty (-1)^n \int_0^1(1+2t^2+t^4)t^{6n}\ln(t)dt$$ Integrate term by term: $$I=-\sum_{n=0}^\infty (-1)^n\left( \frac{1}{(6n+1)^2}+\frac{2}{(6n+3)^2}+\frac{1}{(6n+5)^2}  \right)$$ Re-organize them: $$I=-\sum_{n=0}^\infty (-1)^n\left( \frac{1}{(6n+1)^2}-\frac{1}{(6n+3)^2}+\frac{1}{(6n+5)^2}\right)-\sum_{n=0}^\infty (-1)^n \frac{3}{(6n+3)^2} $$ The first part is Catalan's constant: $$I=-G-\sum_{n=0}^\infty (-1)^n \frac{3}{(6n+3)^2}=-G-\frac{3}{9}G=-\frac{4}{3}G$$ Done.,"['integration', 'definite-integrals']"
4486402,"Prove that for an orthogonal matrix $A$ and a certain reflection $R$, the $\mathbb C$-linear part of $RA$ is invertible","Hello: I need help with this problem: Let $V = (V,b)$ be a finite-dimensional vector space equipped with a symmetric and positive definite bilinear form $b$ . And let $\{e_1,…,e_n\}$ be a orthonormal basis for the subspace $\ker((P_A)^t)$ ( $P_A$ is defined below). For a matrix $A \in \mathrm{O}(V)$ , let $\mathrm{O}_*(V)$ the subset of $\mathrm{O}(V)$ such that be the matrix $P_A:=\frac{A-JAJ}{2}$ is invertible, where $J$ is a complex structure (a matrix such that $J^2=-1$ and $J^t=J^{-1}=-J$ ). Let $n=\dim \ker(P_A)$ . For every $j \in \{1,…,n\}$ we define the reflexions $r_j$ such that $r_j(e_j)=-Je_j$ , $r(Je_j)=-e_j$ and $r_j(v)=v$ for and $v \in V$ such that $b(v,e_j)=b(v,Je_j)=0$ . Finally, let $$R:=r_1r_2\dots r_n \in \mathrm{O}(V).$$ I need to prove that $$RA \in \mathrm{SO}_*(V),$$ where similarly as $\mathrm{O}(V)$ : $\mathrm{SO}_*(V)$ is the subset of $\mathrm{SO}(V)$ such that $P_B:=\frac{B-JBJ}{2}$ is invertible. I already proved that $RA \in \mathrm{SO}(V)$ ; the only thing that I haven’t been able to figure out is to prove that $\frac{1}{2}(RA-JRAJ)$ is invertible, since $n$ can be even or odd. Also, $P_{r_j}$ is not invertible since $\det(r_j)=-1$ . ¿What is good and optimized approach to deal with the product of reflections $$R=r_1r_2\cdots r_n?$$ In summary: I’m trying to prove that $RA$ (where $R$ the product of reflections $r_1r_2\dots r_n$ ) is a ortogonal matrix with $\det(RA)=+1$ and that the matrix $\frac{1}{2}(J-J(RA)J)$ is invertible. Any help will be greatly appreciated. Thanks :). UPDATE: Two things: I made a typo, $\{e_1,…,e_n\}$ be a orthonormal basis for the subspace $\ker((P_A)^t)$ , not on $\ker(P_A)$ . On the main reference I'm using, the author establishes the following: This operators (each reflection $r_j$ , with $j \in \{ 1,\dots, n \}$ ) has the identity restricted to the subspace ortogonal to $e_j$ as $p_{r_j}$ . Let $R:=r_1\dots r_n$ , then the operator $R$ is in block form, its lower right corner being the identity on $(\ker((P_A)^t))^{\perp}$ . And so $RA \in \mathrm{SO}_*(V)$ . And that's it, I think the author's argument has many gaps or things that I'm not getting :(. He says he's following this article , but I have read any multiply times and I don't see anything like what I'm trying to prove (or at least eith this notation).","['reflection', 'matrices', 'orthogonal-matrices', 'linear-algebra', 'linear-transformations']"
4486450,Compass-and-straightedge geometric construction problem (see image),"Given circle c with center A and a chord HI, and a point G within segment HI, construct circle d with center C such that the radical axis passes through G and point F lies on both d , line HI and line CA. TL;DR Given the things in blue, construct the things in red. Intuition tells me that there should be an unique solution given the level of constraint. I have also constructed one point J on the red circle. A purely geometric construction and proof, not utilizing analytic geometry, would be appreciated. Thanks in advance.","['euclidean-geometry', 'geometry', 'geometric-construction']"
4486451,Using gradient descent with cross entropy loss [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question In the logistic regression, for an intercept $$\beta_0\in R$$ ,parameter vector $$\beta=\left(\beta_0,\beta_1,...,\beta_p\right)\in R^p$$ , target $$y_i\in\left\{0,1\right\}$$ , and feature vector $$x_i=\left(x_{i1},x_{i2},...,x_{ip}\right)^T\in R^p$$ for i = 1, . . . , n, the (l2-regularized) log-loss that we will work with is: $$L\left(\beta_{0,}\beta\right)=\frac{1}{2}\beta^T\beta+\frac{\lambda}{n}\Sigma\left[y_i\ln\left(\frac{1}{\sigma\left(\beta_0+\beta^Tx_i\right)}\right)+\left(1-y_i\right)\ln\left(\frac{1}{1-\sigma\left(\beta_0+\beta^Tx_i\right)}\right)\right]$$ where $$\sigma\left(z\right)=\left(1+e^{-z}\right)^{-1}$$ How to calculate the gradient?",['derivatives']
4486460,Order type of a set that is ordered but not well-ordered,"I looking at ordered sets in the Kolmogorov (Introductory Read Analysis) book. Section 3.5 Definition 2 says the order type of a well ordered set is called an ordinal number. If the set is infinite, the ordinal is transfinite So the set of positive integers $\{1,2,...,k,..\}$ arranged in increasing order is well ordered with the order type $\omega$ . The set $\{..., -k,.., -2, -1\}$ is ordered but not well-ordered. But this set is isomorphic to the set of positive integers - map each element to its negative. So if order type is something shared by all isomorphic sets (Section 3.3), why can the set of negative integers (a set that is ordered but not well ordered and is isomorphic to a well ordered set) not have an order type? More broadly, if a set is ordered but not well ordered, but is isomorphic to a well ordered set, why should it not have an order type?","['elementary-set-theory', 'order-theory', 'well-orders']"
4486494,Finding number of injections $A \to A$.,"I believe I've been able to solve this problem without issue, but I'm most concerned with precision and the rigor of my argument. The problem is: Let $A$ be a finite set, $|A| = n > 0$ . How many functions $f: A \to A$ are there?
How many of these are injective? Here is what I came up. (a) Let $A = \{a_1, \ldots,a_n\}$ . Then, there are $n$ possibilities for the image of $a_1$ under $f$ . For each of these $n$ possibilities, there are $n$ possibilities for the image of $a_2$ . Furthermore, for each $i > 1$ , there are $n$ possibilities for the image of $a_i$ given the $n^{i-1}$ options for where $f$ sent $a_1, \ldots, a_{i-1}$ . Therefore, there are $|A|^{|A|} = n^n$ total functions $f: A \to A$ . (b) We enumerate the elements of $A$ as above. There are then $n$ possibilities for where $f$ maps $a_1$ . For each of these $n$ possibilities, there are then $n-1$ possibilities for where $f$ maps $a_2$ ; indeed, as $a_1 \neq a_2$ , we must have $f(a_1) \neq f(a_2)$ since $f$ must be injective. Then, for each $i > 1$ , we must have $f(a_i) \neq f(a_{i-1}) \neq \ldots \neq f(a_1)$ . Therefore, having assigned $i-1$ elements of $A$ , there are $n-i$ remaining possibilities for where $f$ assigns $a_i$ for each of these $n \cdot (n-1) \cdots (n-(i-2))$ possibilities for where $f$ assigned $a_1, \ldots, a_{i-1}$ . Therefore, there are exactly $n!$ such injections $f: A \to A$ . How does this look?","['proof-writing', 'functions', 'solution-verification']"
4486567,Rotation invariant 1-forms on spheres,"I'm currently learning calculus on manifolds, and I find myself feeling rather uncomfortable with basic calculations to do with forms. I am therefore seeking a second opinion on my solution to the following problem: [5.9.1, Berger and Gostiaux]
Let $\xi$ be a one-form on $\mathbb{S}^2$ . Assume that $\xi$ is invariant under rotation, that is, $s^{\star} \xi = \xi$ for any $s \in \text{SO}(3)$ . Prove that $\xi = 0$ . Solution : Let $U = \mathbb{S}^2 - \{N\}$ , where $N = (0,0,1)$ is the north pole, and let $f: U \to \mathbb{R}^2$ be the standard stereographic projection. Then let $\hat{\xi} := (f^{-1})^{\star} \xi$ be the coordinate representation of $\xi$ in $U$ . Next, let $s \in \text{SO}(3)$ be a rotation that fixes the poles, so that it restricts to a map of $U$ into itself. Then $\hat{\xi}$ must remain invariant under the coordinate representation of $s$ , since (restricting everything in the sphere to $U$ ) $$(f \circ s \circ f^{-1})^{\star} \hat{\xi} = (s \circ f^{-1})^{\star} \xi = (f^{-1})^{\star} s^{\star} \xi = \hat{\xi}.$$ Now the coordinate representation of $s$ is simply the top-left $2 \times 2$ block in $s$ , i.e. this is a rotation $r \in \text{SO}(2)$ . Conversely, any such rotation is the coordinate representation of a rotation in $\text{SO}(3)$ (just add an extra column and row). So let $r$ be a half-turn of the plane, and consider the effect of $(r^{\star}\hat{\xi})(0)$ on $v \in T_0 \mathbb{R}^2$ . We have $$(r^{\star}\hat{\xi})(0)(v) = \hat{\xi}(r(0))((T_0 r) v) = \hat{\xi}(0)((T_0 r)v)$$ Now since $r$ is a linear map, $T_0 r = r$ , so this reduces to $-\hat{\xi}(0)(v)$ . But by the $r$ -invariance of $\hat{\xi}$ , this is also equal to $\hat{\xi}(0)(v)$ . This is true for every $v$ , so $\hat{\xi}(0) = 0$ . It follows (since $f$ is a diffeomorphism) that $\xi(S) = 0$ . Finally, let $p \in \mathbb{S}^2$ be arbitrary. Since $\text{SO}(3)$ acts transitively, we can find an $s$ that sends $p \leadsto S$ . Then we have that $\xi(p) = (s^{\star} \xi)(p)$ , and this is zero: $$(s^{\star}\xi)(p) = (T_p s)^{\star} (\xi(s(p)) = 0,$$ and we are done. I am moderately confident that this procedure works, but it feels like there should be cleaner solutions. Could one approach this by looking at $S^{2}$ as an embedded submanifold of $R^2$ ? Or is passing to charts often necessary? Thanks in advance.","['spheres', 'smooth-manifolds', 'multivariable-calculus', 'solution-verification', 'differential-geometry']"
4486589,Derivative of Integral with respect to a function,"I have the following function $$
f(\tilde{x}) = \int^\tilde{x}_0 x dH(x)
$$ and I want to find $f'(\tilde{x})$ . Here, $H(x)$ denotes a cumulative density function. So far, it is clear to me that I can use the Second Fundamental Theorem of Calculus, i.e., if a function $g(x)$ is continuous and $G$ defined for a all $x \in [a,b]$ as the integral $$
G(x) = \int^x_a g(t) dt,
$$ then $G$ is differentiable on $(a,b)$ and $$
G'(x) = \frac{d}{dx} G(x) = \frac{d}{dx} \int^x_a g(t) dt = (G(x)-G(a))'=G'(x)=g(x).
$$ In the problem above I do not integrate with respect to a variable but to a function. Let $F(\tilde{x})$ be the integral of $f(\tilde{x})$ , then I get $$
f'(\tilde{x}) = \frac{d}{dx} \int^\tilde{x}_0 x dH(x) = \left[f(H(\tilde{x}))-f(H(0))\right]' = 
$$ There I am somewhat stuck and not sure how to proceed. Any help would be appreciated!","['integration', 'derivatives']"
4486601,Probability brain teaser crossing,"In this question, we have a person trying to cross the river. However a night before that, there is a storm and each bridge has 50% chance of being struck by lightning strike unconditionally from the previous lightning strike. This would destroy and bridge.
What is the probability that there exists a path to cross river? (As you can see in the drawings, we have 13 bridges, some of then cross at one of the 6 junctions) Firstly I just tried adding all the possibilities together and computing the probability of two vertical bridge move (1/4) and probability of (two vertical and one horizontal - 3/8) in the end both of these computations were wrong because the issue here is that there is a lot of overlapping, i.e. if there is 2+ routes, this overlapping event made me confused and stuck and any progress I made, or any pattern I tried to spot came back to the questions how do I get all the possibilities without actually writing all of them down.
Thanks for any help","['puzzle', 'probability-theory', 'probability']"
4486657,Function that grows faster than any function in a given (perhaps infinite) set,"I am self studying point set topology with MAT327 from Toronto University. In the topic of countability (chapter 4), I am asked to: ""given a fixed set of functions $f_n:\mathbb{N}\rightarrow\mathbb{N}$ , $n\in\mathbb{N}$ construct a function $g: \mathbb{N}\rightarrow\mathbb{N}$ that grows faster than all $f_n$ "" this is: $\lim_{k\rightarrow\infty}\frac{g(k)}{f_n(k)}= \infty$ In the course is assumed that $0\not\in\mathbb{N}$ . If the set of functions $f_n$ were finite $g(k)=\Pi_nf(k)^{f(k)}$ would be a solution, but I am not sure I can use this trick for an infinite set of functions. How can I construct a function than grows faster than a given (infinite) set of functions?","['elementary-set-theory', 'general-topology']"
4486697,"Find the extrema of $f(x,y)=max(x,y)$ constrained to $\mathscr A=\{(x,y) ∈ \mathbb R^2 ∣ x^2+y^2=1\}$","I know the maxima occurs at $f(x,y) = 1$ at the points $(1,0)$ and $(0,1)$ ... but I can't seem to find all the minima.
I've come to the conclusion that the minima occurs at a point $(a,a)$ where $a ∈ \mathbb R_<0$ , such that $2a^2=1\rightarrow a=\frac{\sqrt 2}{2} \lor a=-\frac{\sqrt 2}{2}$ . Does the minima occur at ( $-\frac{\sqrt 2}{2}, -\frac{\sqrt 2}{2}$ )?",['multivariable-calculus']
4486706,BOOK RECOMMENDATION: Integration Techniques / Tips,"While browsing MSE, I found some posts regarding integration tricks / integration formulae, for both definite and indefinite integrals. I saw this post , this post , this post , and some other posts. I saw the following (but not only the following), I am familiar with many of them Now I am asking about a book that includes such integration formulae with there proofs and examples. $$\int_{a}^{b} f(x) dx = \int_{a}^{b} f(a+b-x) dx$$ For rational expressions of trigonometric functions, substitute: $$\sin(x)=\frac{2t}{1+t^2}, \tan(x)=\frac{2t}{1-t^2}, \sec(x)=\frac{1+t^2}{1-t^2}, \text{and } dx=\frac{2dt}{1+t^2}$$ This is called ""tangent half-angle substitution"", so these substitutions can be derived by first putting $\tan(x/2)=t$ . This substitution also known as ""Weierstrass substitution"". $$\int_{-a}^{a} f(x) dx = \left\{\begin{matrix}
2\int_{0}^{a} f(x) dx &, \text{when }f(x) \text{ is an even function} \\
\\
0 &,  \text{when }f(x) \text{ is an odd function} \\
\end{matrix}\right.$$ Integration of an inverse function: $$\int f^{-1}(x)dx = x f^{-1}(x)-F(f^{-1}(x))+c, \text{where } F(x)=\int f(x)dx$$ Frullani Integral: $$\int_{0}^{\infty} \frac{f(ax)-f(bx)}{x} dx = \bigg(f(\infty)-f(0)\bigg)\log\bigg(\frac{a}{b}\bigg)$$ $$\int_{-a}^{a} \frac{f_{1}(x)dx}{1 \pm \bigg(f_{2}(x)\bigg)^{f_{3}(x)}}=\int_{0}^{a}f_{1}(x)dx$$ provided that both $f_{1}$ and $f_{2}$ are even functions, and $f_{3}$ is an odd function. Laplace Integration: $$\int_{0}^{\infty} \frac{f(x)}{x}dx = \int_{0}^{\infty}\mathcal{L}\{f(t)\}ds$$ I need a book that includes (not only these) integrals. Hopefully (only one comprehensive) book. Your help would be appreciated. THANKS!","['integration', 'improper-integrals', 'definite-integrals', 'book-recommendation', 'reference-request']"
4486709,Average of one over sum of complex exponentials,"I need to compute a time-average which is of the form $$ \lim_\limits{T \to \infty} \frac{1}{T} \int_0^T \frac{\mathrm{d}t}{1+\sum_k c_k e^{i x_k t}} $$ where $x_k \in \mathbb{R}$ , $c_k \in \mathbb{C}$ and the sum in the denominator is finite, $k=1,\ldots,K$ . I tried substituting $z = e^{it}$ and using the residue theorem but in the end I didn't get far. Is there some way of getting a closed form expression for the limit? Alternatively, I don't mind if I have to use numerical techniques, but preferably I'd do it on a limit where the convergence is more controlled.",['complex-analysis']
4486725,Sum of two squares mod p using primitive root,"My question is as follows (Problem 5.2 in Aluffi, Algebra: Chapter 0 ): Question. For any finite field $F := \mathbb{F}_{p^d}$ , show that any element $k$ can be written as a sum of two squares, i.e. there exists $x,y\in F$ such that $k = x^2 + y^2$ . I am wondering if there is a solution using primitive elements of the field $F$ , as suggested by Aluffi in the hint. The same question has been asked here , here , and here . However, all of the given answers are combinatorial (using Pigeonhole Principle), and they are not what I am looking for.","['modular-arithmetic', 'number-theory', 'finite-fields', 'pigeonhole-principle', 'abstract-algebra']"
4486754,Growth Rate of Supremum of Random Walk (with negative drift),"Let $(X_k)_{k=1}^\infty$ be a sequence of i.i.d. random variables, with $\mathbb{E}(X_i)$ finite and negative. Define $S_n := X_1 + ... + X_n$ , and $M_n := \max(S_1,S_2,...,S_n)$ . It follows from the final bullet point of Sangchul Lee's answer to this question Is the expectation of the supremum of a random walk with negative drift finite? that if $X_i$ have infinite variance, then $\mathbb{E}(M_n) \rightarrow +\infty$ as $n \rightarrow +\infty$ . However I am curious how quickly this growth to infinity occurs? I am not sure if there is a general answer in terms of the distribution of $X_i$ , so I started by trying to use a simple test example. I defined the $X_i$ variables to be absolutely continuous with density function $f(x) := \frac{2}{(x+3)^3}$ for $x \in [-2,\infty)$ . This is the simpliest example I could think of which would have a finite negative mean (in this case the mean is $-1$ ), yet infinite variance. However, with this example, I am struggling to work out how quickly $\mathbb{E}(M_n)$ diverges. By a very rough numerical calculation, it seems as though the density function of $M_2$ decays like $O(\frac{1}{x^{2.8}})$ (maybe the true exponent is $e$ ?). I'm guessing that as $n \rightarrow +\infty$ the density of $M_n$ tends to a decay rate of $O(\frac{1}{x^2})$ , but again I have no idea how to attack this. Does anyone know what kind of analytic tools I can use to tackle this problem? Cheers.","['random-walk', 'analysis', 'probability-theory', 'probability']"
4486761,Evaluate the definite integral $I = \int_0^\pi \frac{\sin^2(\theta) d\theta}{10-6\cos(\theta)}$,"I'm studying for my upcoming complex analysis qualifying exam by working through problems in past exams. For this problem, I'd like to know (1) if my answer is correct and complete (i.e. whether I've made any errors/omissions), and (2) if there are any better/faster ways of evaluating this integral. Thanks! Problem: Evaluate the definite integral $$I = \int_0^\pi \frac{\sin^2(\theta) d\theta}{10-6\cos(\theta)}.$$ Attempted Solution: We first note that the integrand is an even function, thus $$I = \int_0^\pi \frac{\sin^2(\theta) d\theta}{10-6\cos(\theta)} = \frac{1}{2}\int_{-\pi}^{\pi} \frac{\sin^2(\theta) d\theta}{10-6\cos(\theta)}. $$ Let $z=e^{i\theta} \implies d\theta = \frac{dz}{iz}$ , then we have $$\sin\theta =\frac{e^{i\theta} - e^{-i\theta}}{2i} =\frac{z-z^{-1}}{2i} \implies \sin^2\theta = \frac{z^2-2+z^{-2}}{-4} $$ and $$\cos\theta = \frac{e^{i\theta} + e^{-i\theta}}{2} = \frac{z+z^{-1}}{2}. $$ We can now substitute such that for the unit circle $\gamma(\theta) = e^{i\theta}, \;\theta\in[-\pi,\pi]$ , we have \begin{align*}
\frac{1}{2}\int_{-\pi}^{\pi} \frac{\sin^2(\theta) d\theta}{10-6\cos(\theta)} &= \frac{1}{2}\oint_\gamma \frac{(-\frac{1}{4})(z^2-2+z^{-2})}{10-3(z+z^{-1})}\frac{dz}{iz} \\
&= \frac{i}{8} \oint_\gamma \frac{z^2-2+z^{-2}}{z(10-3z-3z^{-1})} dz \\
&= \frac{i}{8} \oint_\gamma \frac{z^4 - 2z^2 + 1}{z^2(10z-3z^2 -3)} dz \\
&= -\frac{i}{24} \oint_\gamma \frac{z^4-2z^2 + 1}{z^2(z^2-\frac{10}{3}z + 1)} dz \\
&= -\frac{i}{24} \oint_\gamma \frac{z^4-2z^2 + 1}{z^2(z-3)(z-\frac{1}{3})} dz
\end{align*} It's clear that our integrand has a pole of order 2 at $z=0$ , and two simple poles at $z=3$ and $z=1/3$ . Using the Residue Theorem, we can evaluate this integral as $2\pi i$ times the sum of the residues at $z=0$ and $z=1/3$ , disregarding $z=3$ since this pole is outside of the curve $\gamma$ . At the simple pole $z=1/3$ , we calculate \begin{align*}
\text{Res}(1/3) &= \lim_{z\to\frac{1}{3}} (z-\frac{1}{3})\left(-\frac{i}{24} \frac{z^4-2z^2 + 1}{z^2(z-3)(z-\frac{1}{3})} \right) \\
&= -\frac{i}{24}\lim_{z\to\frac{1}{3}} \left( \frac{z^4-2z^2 + 1}{z^2(z-3)} \right) \\
&= \frac{i}{9}
\end{align*} The pole at $z=0$ is of order 2, therefore we calculate \begin{align*}
\text{Res}(0) &= \lim_{z\to 0}\frac{d}{dz} z^2 \left(-\frac{i}{24} \frac{z^4-2z^2 + 1}{z^2(z-3)(z-\frac{1}{3})} \right) \\
&= -\frac{i}{24} \lim_{z\to 0}\frac{d}{dz} \left( \frac{z^4-2z^2 + 1}{(z-3)(z-\frac{1}{3})} \right) \\
&= -\frac{i}{24} \lim_{z\to 0} \frac{(4z^3-4z)(z-3)(z-\frac{1}{3})-(z^4-2z^2+1)(2z-\frac{10}{3})}{(z-3)^2(z-\frac{1}{3})^2}\\
&= \frac{-5i}{36}
\end{align*} Finally, we calculate $$
I=2\pi i\Big(\text{Res}(0) + \text{Res}(\frac{1}{3})\Big) = 2\pi i\Big(\frac{-5i}{36} + \frac{i}{9}\Big) = \frac{\pi}{18}
$$","['complex-analysis', 'complex-integration', 'solution-verification']"
4486770,Ergodic Law of Large Numbers,"From jacob-Protter: Ergodic Strong Law of Large Numbers Let $\tau$ be a one-to-one measure preserving transformation of $\Omega$ onto itself. Assume the only $\tau$ -invariant sets are sets of probability $0$ or $1$ . If $X \in L^1$ then \begin{equation*}
			\lim_{n \to \infty} \frac{1}{n} \sum_{j=1}^n X(\tau^j(\omega)) = E\{X\}
		\end{equation*} a.s. and in $L^1$ . It is said there that it is a consequence of the Birkhoff ergodic theorem. Birkhoff Ergodic Theorem from 'Probability Theory A Comprehensive Course (Universitext) (Klenke, Achim)' : Let $f = X_0 \in L^1(P)$ . Then $$\frac{1}{n} \sum_{k=0}^{n-1} X_k = \frac{1}{n} \sum_{k=0}^{n-1} f \circ \tau^k \to E\{X_0|\mathcal{I}\} ~~ P-a.s. $$ In showing the ergodic strong law of large numbers, we only have to show that $E\{X_0|\mathcal{I}\} = E\{X_0\}$ . Can you please show how prove this.","['law-of-large-numbers', 'ergodic-theory', 'probability-theory']"
4486777,Why is it not important what mathematical objects are?,"In axiomatic set theory the term ""set"" and the relation "" $\in$ "" are primitive notions. Thus, it is not defined what sets are nor what the relation is. Axiomatic set theory is supposed to formalize how sets ""behave"", meaning what is true about them. One of the axioms is the axiom of infinity, which ensures that one can encode the natural numbers as sets, thus proving their existence from ZFC. This is one common procedure that is done in mathematics: we have an intuitive notion, namely the natural numbers "" $\{1,2,3,4,...\}$ "" that we used for a long time and want to make this precise mathematically. Thus, when ZFC is used as the chosen foundation, one tries to encode this intuitive object using sets. Another example where this is done is the notion of a function. Intuitively a function is an object/concept of mapping an object of one collection to exactly one object of another collection. This can again be defined in set theory: Suppose that $X$ and $Y$ are sets, then a function $f$ is defined to be a subset $f \subseteq X \times Y$ that satisfies the following condition. For every $x \in X$ there exists exactly one $y \in Y$ such that $(x,y) \in f$ . Thus we have proven that there exist objects that we call ""functions"" that have the property we intuitively expect functions to have, or more precisely that we expect the intuitive notion of function to satisfy. These are of course only two examples of many, where some intuitive concepts are encoded as sets. In my understanding, we have built ""models"" (I know this term is used with a meaning in logic, however I don't know if this is the same way its being used there; I am using it with the usual meaning of being a model for somethign) for intuitive concepts. It might be however, that, assuming the existence of mathematical objects, the actual objects are not encoded as sets, or that you are using a different definition for the same concept. In this sense, these might be the ""wrong"" definitions, without us knowing whether they are or not. My question is , why is this not problematic? Why do we not care what mathematical objects are but only what we can do with them/what is true about them? An attempt of answering this myself : I suspect that this is because the models we built above satisfy the essential properties we expect the intuitive notions to have. That is, if these intutive notions actually exist, they would have to have these properties. Thus when we prove anything for our models only using these properties, they necessarily would also have to be true for the actual objects. The same goes for different definitions/models of the intended intuitive notion. They would have the same essential properties. Thus, it doesnt matter what the mathematical objects are, since our model serves to prove the properties about them, no matter what they are. If I understand correctly, a similar view can be found in these notes that I randomly found some time ago. On page 25 of the document it says:
""The theorems that we proved for a Peano system also turn out to be true when they are
interpreted as being statements about whole numbers. This is just what one would
expect: if the axioms of $\mathcal{P}$ are true when interpreted as statements about whole numbers, then all the logical consequences of those axioms (theorems) will also be true about
whole numbers."" Another related question: When axiomatic set theory doesn't say what sets are, then could they be anything that satisfies the axioms? One intuitively has collections in mind when thinking about sets, which should be fine, as long as one uses the axioms to construct new collections. However, axiomatic set theory doesn't tell us that sets are collections. They could thus be anyhting. If this were correct, I guess one could use the same approach as above and view sets as a model for collections, meaning that the intuitive notion of a collection obeys these axioms, which means that anything we prove about sets is also true for the intuitive notion of a collection. So are sets necessarily collections? All of this would also make it a bit more intuitive why abstract concepts such as numbers of pure math actually work when talking counting real world things, or applying these concepts in general to the real world.","['foundations', 'elementary-set-theory', 'philosophy', 'soft-question', 'set-theory']"
4486838,An ordered basis for a finite-dimensional $F$-vector space $V$ establishes a bijection between $V$ and $F^n$.,"To summarize, each ordered basis of $V$ determines a one-one correspondence $\alpha \to (x_1,…,x_n)$ between the set of all vectors in $V$ and the set of all $n$ -tuples in $F^n$ . Question: How to prove bijective map between $V$ and $F^n$ explicitly? My attempt: $(V,F,+,\cdot)$ is finite dimensional vector space. Let $B=\{\alpha_1,…,\alpha_n\}$ be an ordered basis of $V$ . $B=\{\alpha_1,…,\alpha_n\}$ is basis of $V$$\iff$$\forall \alpha \in V$ , $\exists !x_\alpha =(x_{\alpha ,1},…,x_{\alpha ,n})\in F^n$ such that $\sum_{i\in J_n} x_{\alpha ,i}\cdot \alpha_i=\alpha$ . So $f:V\to F^{n}$ defined by $f(\alpha)=x_\alpha = (x_{\alpha ,1},…,x_{\alpha ,n})$ is a well-defined map, i.e. $\forall \alpha \in V$ , $\exists !x_\alpha \in F^n$ such that $f(\alpha)=x_\alpha$ . Claim: $f$ is invertible, i.e. $\exists g:F^n \to V$ such that $g\circ f=\text{id}_V$ and $f\circ g=\text{id}_{F^n}$ . Proof: We define $g:F^n \to V$ such that $g(y)=\sum_{i\in J_n}y_i \cdot \alpha_i$ . Let $\alpha \in V$ . Then $g\circ f(\alpha)=g(f(\alpha))=g(x_\alpha)$$= \sum_{i\in J_n} x_{\alpha ,i}\cdot \alpha_i=\alpha$ . Thus $g\circ f=\text{id}_V$ . Let $y=(y_1,…,y_n)\in F^{n}$ . Then $f\circ g(y) =f(g(y))=f(\sum_{i\in J_n}y_i \cdot \alpha_i)$ . Let $\sum_{i\in J_n}y_i \cdot \alpha_i =\beta \in V$ . Since $\exists !x_\beta =(x_{\beta ,1},…,x_{\beta ,n})$ such that $\sum_{i\in J_n} x_{\beta ,i} \cdot \alpha_i =\beta$ , we have $y=(y_1,…,y_n)=(x_{\beta ,1},…,x_{\beta ,n})=x_\beta$ . So $f\circ g(y)=f(\sum_{i\in J_n}y_i \cdot \alpha_i)=f(\beta)=x_\beta=y$ . Thus $f\circ g=\text{id}_{F^n}$ . Hence $f$ is invertible, or, equivalently, bijective. Is my proof correct?","['proof-writing', 'vector-spaces', 'functions', 'linear-algebra', 'solution-verification']"
4486860,Find the kernel of $\mathbb{Z}[x] \to \mathbb{Q}$ given by $f \mapsto f(1/3)$.,"The problem is to find the kernel of the homomorphism $\mathbb{Z}[x] \to \mathbb{Q}$ given by $f \mapsto f(1/3)$ . I think I've solved this using elementary techniques but I want to make sure the solution works. Claim: The kernel is the principal ideal $(3x - 1)$ . Proof: Clearly $(3x - 1)$ is in the kernel. Conversely, suppose $f(1/3) = 0$ . Then $x - 1/3$ divides $f$ in $\mathbb{Q}[x]$ so we may write $f = (x - 1/3)(C_0 + C_1x + \cdots C_n x^n)$ for $C_n \in \mathbb{Q}$ . To conclude, we show that all the $C_i \in 3\mathbb{Z}$ . Writing out the product, we see that $$f(x) = -\frac{1}{3}C_0 + \left(C_0 - \frac{1}{3}C_1 \right)x + \cdots + \left(C_{n - 1} - \frac{1}{3} C_n\right) x^n + C_nx^{n + 1}.$$ Since $f \in \mathbb{Z}[x]$ , the coefficients are all integers so that $C_0 \in 3\mathbb{Z}$ and $$C_i - \frac{1}{3} C_{i + 1} \in \mathbb{Z}$$ for all $0 \leq i \leq n - 1$ . Now, if $C_i \in 3\mathbb{Z}$ then $C_{i + 1} \in 3\mathbb{Z}$ by the above identity. We can then apply induction since $C_0 \in 3\mathbb{Z}$ to see that $C_i \in 3\mathbb{Z}$ for all $0 \leq i \leq n$ as required. Thanks!","['abstract-algebra', 'solution-verification']"
4486870,"Does $(a,b,1)$ lie on a line or a plane?","The following question is taken from Cengage book by G.Tiwani. This book is used for the preparation of IIT-JEE exam. Question : A function $f:\mathbb R \to \mathbb R$ is defined as $$f(x)=\lim_{n\to\infty}\frac{ax^2+bx+c+e^{nx}}{1+ce^{nx}},$$ where $f$ is continuous on $\mathbb R$ then (A) points $(a,b,c)$ lie on a line in the 3-dimensional coordinate system. (B) points $(a,b)$ represent the 2-dimensional Cartesian plane (C) locus of points $(a,c)$ and $(c,b)$ intersect at one point. (D) points $(a,b,c)$ lie on a plane in the 3-dimensional coordinate system. My Attempt: $$f(x)=\begin{cases} ax^2+bx+c;& x\lt0 \\ \frac{c+1}{1+c};&x=0 \\ \frac1c;&x\gt0\end{cases}$$ Therefore, $c=1, a, b \in \mathbb R$ So, I think the options B,D are correct. But the answer given is A,B,C. How to approach this?","['contest-math', '3d', 'geometry', 'calculus', 'limits']"
4486879,Is the Comparison Lemma valid for Asymptotic solutions of the differential inequality?,"The comparison lemma (from Khalil's Nonlinear Systems book) is stated as follows: Lemma 3.4 Consider the scalar differential equation $$\dot{u} = f(t,u), \quad u(t_0) = u_0 $$ where $f(t,u)$ is continuous in $t$ and locally Lipschitz in $u$ for all $t \ge0$ . Let $[t_0,T)$ be the maximimal interval of existence for the solution $u(t)$ . Let $v(t)$ be a continuous function that satisfies the differential inequality $$\dot{v}(t) \le f(t,v(t)), \quad v(t_0)\le u_0, \quad \forall t\in [t_0,T) $$ Then, $$ v(t) \le u(t), \quad \forall t\in [t_0,T).$$ Question I have an inequality such as this, but $f(t,u)$ is nontrivial to solve analytically, but I believe I can obtain an asymptotic solution, say $$ u(t) \sim \tilde{u}(t),\quad  t \rightarrow \infty.$$ For, say, $T = \infty$ , are there any existing theorems such that it possible to conclude that $$ v(t) \le \tilde{u}(t), \quad \forall t\in [T_0,\infty),$$ for some $T_0$ sufficiently large?","['stability-in-odes', 'asymptotics', 'ordinary-differential-equations']"
4486910,Evaluating limit using Riemann sums,"I am preparing for calc II exam, and i have some trouble with 2 problems. $$ \lim_{n \to \infty} \frac{1}{7n^2}+\frac{1}{7n^2+1}+\frac{1}{7n^2+2}+ \dots + \frac{1}{8n^2}$$ $$ \lim_{n \to \infty} \sum_{i=n+1}^{7n} \frac{i}{n^2} $$ Now what i usually do in these kinds of problems is is take out $\frac{1}{n}$ in front of the sum and rearrange rest of the terms in order to get some kind of function with $\frac{i}{n}$ , so that i can treat it as a Riemann Sums (and already solved bunch of examples using this). But for example in first one i end up with: $$\frac{1}{n}\sum_{i=0}^{n} \frac{1}{7n+\frac{i}{n}}  $$ And after playing with it for a while, I was not able to transform it to anything meaningful, same goes with the second example, Hints appreciated.","['limits', 'calculus', 'riemann-sum']"
4486943,Existence of rigid curves with non-negative self intersection,"The question is essentialy the title: is there a smooth algebraic surface $X$ , say over $\mathbb{C}$ , and an irreducible algebraic rigid curve $C\subset X$ with non-negative self intersection? Here by rigid I mean that $h^0(X,C)=1$ , so the only effective divisor linearly equivalent to $C$ is $C$ itself. The only examples of rigid curves I know have negative self intersection. Observations I'm pretty sure that the answer is negative for del Pezzo or K3 surfaces.
Indeed, for del Pezzo we have $\chi(X)= 1$ being $h^1(X,\mathcal{O}_X)=h^2(X,\mathcal{O}_X)= 0$ , $-K_X\cdot C> 0$ being $-K_X$ ample $h^2(X,C)=h^0(X,K_X-C)=0$ , using Serre duality. Therefore, by Riemann-Roch we get $$h^0(X,C)=h^1(X,C)+\chi(X)+\frac{1}{2}C^2-\frac{1}{2} K_X\cdot C> 1+\frac{1}{2} C^2$$ so $h^0(X,C)>1$ if $C^2\geq 0$ . A similar computation holds, with some differences, for K3 surfaces. Therefore, I tried to work on hypersurfaces of high degree in $\mathbb{P}^3$ but couldn't find such a curve.","['algebraic-geometry', 'intersection-theory']"
4486965,Is there an analytic solution to $\int_a^b \frac{\arctan(A+Bt)}{C^2 + (t-Z)^2}dt$?,"Is there a sensible analytic solution to the following integral: $$\int_a^b \frac{\arctan(A+Bt)}{C^2 + (t-Z)^2}dt$$ where all constants are real and $C>0$ . This integral is part of the third term in a Neumann expansion applied on a specific Rendering equation . I have solved the first and second terms in 2D and 3D, an interactive implementation can be found here (shadertoy). Mathematica was used first and it outputs an expression for the integral with sums of complex logs and polylogs (I use assumptions to help the program). The log-sum is multiplied by $i$ , so all real parts of the log-sum should cancel out since the integrand is real. As far as I know there is no way to generally extract the imaginary part from $\operatorname{Li}_2(\ldots)$ . No practical implementation probably exists based on this expression. I have also tried to use Feynman's integral trick, but not having much success. Since Mathematica is limited (the following example fails: $\int_0^\pi\ln(1-2a\cos(x)+a^2)\,dx$ from this tutorial , which has a closed form), I hoper there is a simpler solution without the dilogarithm. Edit: clarified the integral","['integration', 'polylogarithm', 'closed-form', 'trigonometry', 'complex-numbers']"
4486970,A more elegant way to prove an Euclidean geometry theorem,"Circle c (center $A$ ) and circle d (center $D$ ) is given such that the center of c lies on d . $DA$ intersects d at $C$ and $A$ . $HI$ is a chord of c that goes through $C$ . $EF$ is the radical axis of c and d that intersects $HI$ at $G$ . Prove that JG bisects $\widehat{HJI}$ . My proof currently is: $AK\bot CK$ at K (Thales' theorem) Thus $AK\bot HI$ at K Since $HI$ is a chord of c $\Rightarrow HK=KI=1/2HI$ Applying intersecting chords theorem to both c and d we get $GC\cdot GK=GH\cdot GI=GE\cdot GF$ $\Rightarrow GH\cdot (CI-CG)=(GH+HC)(HK-HG)$ $\Leftrightarrow GH\cdot CI-GH\cdot CG=(GH+HC)((CI-CH)/2-HG)$ $\Leftrightarrow GH\cdot CI-GH\cdot CG=(GH+HC)((CI-CH)/2)-GC\cdot HG$ $\Leftrightarrow GH\cdot CI=(GH+HC)(CI-CH)/2$ $\Leftrightarrow 2GH\cdot CI=(GH+HC)(CI-CH)$ $\Leftrightarrow 2GH\cdot CI=GH\cdot CI-GH\cdot CH+CH\cdot CI-CH^2$ $\Leftrightarrow GH\cdot CI=(CI-GH-CH)\cdot CH$ $\Leftrightarrow GH\cdot CI=CH\cdot GI$ $\Leftrightarrow GH/GI=CH/CI$ Since $\widehat{CJG}$ is a right angle we can use the inverse angle bisector theorem to arrive at the result. Evidently the algebra part is as painful as can be if not downright impossible if you don't know the target equation firsthand. Questions : Does this theorem have a name? Is there a way to prove this that circumvents the algebraic manipulation? Failing that, can the manipulation at least be made less cumbersome?","['alternative-proof', 'euclidean-geometry', 'geometry']"
4486977,Are the ratios of logarithms of prime numbers dense in $\mathbb{R}^+$?,"Let $\alpha$ and $\beta$ be two positive reals, $\alpha \lt \beta$ (arbitrarily close). Is it true that there always exists an ordered pair of prime numbers, $(p, q)$ , such that $$ \alpha \lt \frac{\log(q)}{\log(p)} \lt \beta $$ ? Context: I'm interested in classifying the natural numbers by their Factorization Patterns (FPs) and their Factorization Patterns of Sequences of Divisors (FPSDs), two kinds of symbolic signatures based on the prime factorization, where the order of the divisors matters; let's just provide self-explanatory examples: $$\mbox{FP}(350)=\mbox{FP}(2 \times 5^2 \times 7)=pq^2r$$ $$\mbox{FP}(12)=\mbox{FP}(20)=p^2q$$ $$\mbox{FPSD}(12)=[1 \lt p \lt q \lt p^2 \lt pq \lt p^2q]$$ $$\mbox{FPSD}(20)=[1 \lt p \lt p^2 \lt q \lt pq \lt p^2q]$$ The last 3 lines prove it's possible to find natural numbers with the same FP but with distinct FPSDs. Then comes the question: given an FP, how many distinct FPSD's for that FP can there exist? For example, is it worth looking for a $z$ , distinct from $12$ and $20$ such that $\mbox{FP}(z)$ is also equal to $p^2q$ but such that $\mbox{FPSD}(z)$ is neither $[1 \lt p \lt q \lt p^2 \lt pq \lt p^2q]$ nor $[1 \lt p \lt p^2 \lt q \lt pq \lt p^2q]$ ?
My work led me to arrangements of [vectorial] hyperplanes (by taking the logarithms) where the dimension is the number of distinct primes in the prime factorization of $z$ . In the case when the dimension is 2, the arrangement is just a drawing of lines passing through $(0,0)$ , like this: Conjecturally, there are as many FPSD for a given FP as there are colored regions. That supposes that every region contains at least one point with coordinates $(\log(p),\log(q))$ for some $(p,q)$ ordered pair of prime numbers, $p \lt q$ . Since the number of delimiting lines tends to grow fast when the exponents $m$ and $n$ increase in $\mbox{FP}=p^m q^n$ , the regions become thiner and thiner. Hence the asked question, which I was unsuccessful to prove. I'm wondering if it's a conjecture closer to Bertrand's conjecture (proved -- theorem of Chebychev) or to Goldbach's conjecture (still unproved). N.B.: this topic also deals with a entry in OEIS, that I'm writing, currently in draft status (A355474).","['general-topology', 'prime-numbers']"
4486979,Find all primes x such that f(x) is also a prime number.,"There is a function \begin{align*}
f(x)=x^3 + x^2 +11x +2 \\
\end{align*} Find all prime $x$ such that $f(x)$ is also a prime number. I found that this is satisfied with an x value of 3 then the function is equal to 71, so both are primes, but I am unsure how to find other values or prove that there are no other existing solutions. I tried to use modular arithmetic, but I did not go so far.",['number-theory']
4487020,Integration formula for cubic polynomial $\int_a^bq(x)dx=\frac{b-a}{2}(q(b)+q(a))-\frac{(b-a)^2}{12}(q'(b)-q'(a))$,"Show that $\forall a,b\in \mathbb{R}$ , with $a<b$ , we have $$\int \limits _a^bq(x)\,dx=\frac{b-a}{2}(q(b)+q(a))-\frac{(b-a)^2}{12}(q'(b)-q'(a)),$$ where $q\in \mathcal{P}_3$ is a cubic polynomial. I've tried doing integration by parts with $1$ and $q(x)$ . But that just gives $b-a$ instead of $\dfrac{b-a}{2}$ .","['integration', 'calculus', 'cubics', 'analysis']"
4487050,Prove that any automorphism $\phi \in Aut(\mathbb{Z}_n)$ is determined by $\phi([1])$ and that $\phi([1])$ must be a generator for $\mathbb{Z}_n$,"Relevant Proposition Suppose $G$ and $H$ are groups and that $e$ denotes the identity in each. If $\phi: G \to H$ is a group homomorphism then $\phi(e) = e$ . Furthermore for all $g \in G$ and $n \in \mathbb{Z}$ we have $\phi(g)^n = \phi(g^n)$ By the proposition we know that $$\phi([1])^k = \phi([1]^k)$$ where $[1]^k = [1] + [1] + \cdots + [1] = [(k)( 1)] = [k]$ . This means that the mapping of any element $[r] \in \mathbb{Z}_n$ by the automorphism $\phi$ , $\phi([r])$ , is determined by iterating the map of $[1]$ under $\phi$ $r$ -times. Hence any automorphism $\phi \in Aut(\mathbb{Z}_n)$ is determined by $\phi([1])$ . For the next part, showing that $\phi([1])$ is a generator of $\mathbb{Z}_n$ I always seem to struggle with showing that an element is a generator of a cyclic group. I saw a proof of a similar problem and have interpreted it as follows: By the proposition we know that $\phi([x]^k) = \phi([x])^k$ and $\phi([0]) = [0]$ for all $[x] \in \mathbb{Z}_n$ and $k \in \mathbb{Z}$ . Therefore, if $\phi([1])^k = [0]$ for $k \lt n$ then by applying the inverse map $\phi^{-1}$ (whose existence is guaranteed by the fact that $\phi$ is an automorphism). We find: $$[1]^k = [0]$$ Now, first, is this the correct proof that $\phi([1])$ is a generator for $\mathbb{Z}_n$ and second, I'm having trouble seeing why this proves $\phi([1])$ is a generator. Is it because we see that given the proposition and the assumptions our algebra leads us to the fact that $[1]^k = [0]$ where we know that $[1]$ is a generator for the (additive) group $\mathbb{Z}_n$ ? Thus $\phi([1])$ must also be a generator?","['modular-arithmetic', 'cyclic-groups', 'abstract-algebra', 'solution-verification', 'group-theory']"
4487067,A few questions regarding permutations,"I'm studying for a midterm for my online algebra course and am taking a practice exam. Unfortunately, the exam has no accompanying solutions so I was hoping to appeal to the kind folks here for validation/clarification about, specifically, a multi-part question regarding permutations. Part a Let $\sigma = (123)(45)(6789)$ and $\tau = (13)(578)(49) \in S_9$ . Compute the order of $\sigma$ . Here the order of a permutation that's comprised of disjoint cycles is the least common multiple of the orders of the cycles. Thus we have $$LCM(3,2,4) = \boxed{12}$$ Part b Is $\sigma$ even or odd Since $\sigma$ is a $12$ -cycle and $12$ is even that means $\sigma$ is $\boxed{\text{odd}}$ . Part c Compute the composition $\tau \sigma$ $\tau \sigma = \boxed{(12)(475968)}$ Part d Is the $2$ -cycle $(12)$ in the subgroup $H = \langle \sigma, \tau \rangle < S_9$ generated by $\sigma$ and $\tau$ ? For this I am a bit stuck. First I am slightly confused by the notation $\langle \sigma, \tau \rangle$ . I am used to seeing notation like $\langle g \rangle$ which simply means the cyclic subgroup generated by the element $g$ . So, in this case I'm assuming $\langle \sigma, \tau \rangle$ means ""the cyclic subgroup generated by the elements $\sigma$ and $\tau$ ""? What exactly does that look like. For instance, I know $\langle g \rangle = \{g^n \mid n \in \mathbb{Z} \} = G$ is the definition of the cyclic subgroup generated by the element $g$ but for $\langle \sigma, \tau \rangle$ would it be something like $\{(\sigma \tau)^n \mid n \in \mathbb{Z} \}$ or maybe $\{\sigma^n \tau^m \mid n,m \in \mathbb{Z} \}$ ? If this is true then wouldn't the question be trivial since if $(12) \in H$ then since $H$ is generated by $\sigma$ and $\tau$ then every element in the subgroup is generated by these $2$ elements as well? Or could it be the case that $(12)$ is only generated by only one of the $2$ elements? I'm unsure how exactly to proceed on this question.","['permutations', 'group-theory', 'abstract-algebra', 'solution-verification']"
4487074,How to calculate the sphere within an octahedron of six spheres? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question Apologies if you've already spent a lot of time answering this one but I've spent a lot of time looking for the answer here without success unfortunately.
If I bunch six spheres together to form an octahedron then how do I calculate the size of sphere that fits at the centre of those six spheres?
I assume the answer to be some expression of the size of spheres containing it?",['geometry']
4487126,p-value expressed in terms of angles,"Let $X_1,...,X_n$ be i.i.d. random variables with $E(X_i)=\mu$ and $V(X_i)=\sigma^2$ . Suppose we are to test $H_0 : \mu=0$ against $H_1 : \mu >0$ , we try to base our test statistic on $\tau_n = \frac{\sqrt{n}\bar{X}}{s_n}$ where $s_n$ is the sample standard deviation. Again, see that $\tau_n$ can be written as $\sqrt{n-1}\cot \theta$ where $\theta$ is the angle between $(1,....,1)'/ \sqrt{n}$ and $(X_1,...,X_n)$ . It can also be observed that $\tau_n$ is a monotonic decreasing function of $\theta$ . My question is can we find the p-value expressed in terms of the observed $\theta$ , say $\theta_0$ ?","['statistical-inference', 'statistics', 'probability-distributions', 'hypothesis-testing', 'probability-theory']"
4487137,Crossing the boundary of a subset of $ℝ^2$.,"Given a subset $U\subseteq \mathbb{R}^2$ , let us say that a point $p$ lying in the boundary of $U$ is a simple boundary point if there
exists a continuous curve $γ:(-1,1)→\mathbb{R}^2$ , such that $γ(0)=p$ , $γ(t)∈\text{int}(U)$ , for all $t∈(0,1)$ , and $γ(t)∈\text{ext}(U)$ , for all $t∈(-1,0)$ , where int and ext refer, respectively, to interior and exterior. Assuming that $U$ is a nonempty open set, and that its exterior is nonempty, can we guarantee the existence of simple
boundary points?   If so, can we also prove that the set of simple boundary points is large in any reasonable sense? PS.  It is not hard to see that there is a point in the boundary of the Warsaw circle which is not simple.","['plane-curves', 'general-topology']"
4487169,Expected number of turns to find all pairs in card matching game,"Suppose we have a game with $2n$ cards labeled $1,1,2,2,...,n,n$ , such that for every integer $i$ where $1\leq i\leq n$ we have 2 cards labeled with $i$ . Initially, all the cards are placed face-down on a table. Every turn, the player flips over 2 cards one at a time. If they match, which is if the two cards share the same number, the two cards are removed from the board. If they do not match, the two cards are flipped back to their face-down position. The game ends when all pairs have been found, and all the cards have been removed from the table. (This game is known as Concentration). Assume the player has perfect memory, and that even after flipping a card back over, they are able to remember which card has what number on it. My question is: what is the expected number of turns to complete a game given $n$ starting pairs? I have thought about this problem, and have come up with a few observations. Let $E(N,k)$ represent the expected number of moves to win from a state with $2N$ total face-down cards ( $N$ unfound pairs) remaining and $k$ face-down cards that the player knows the value of. No matter what, we have $k\leq N$ , since by PHP, $k>N$ implies that there are at least 2 face-down cards that share a value and where the player knows both their locations. Then the next move would be to flip all these ""known"" face-down pairs until $k\leq N$ again. $E(N,k)=\frac{k}{2N-k}(E(N-1,k-1)+1)+\frac{2N-2k}{2N-k}\cdot\frac{1}{2N-k-1}(E(N-1,k)+1)+\frac{2N-2k}{2N-k}\cdot\frac{2N-2k-2}{2N-k-1}(E(N,k+2)+1)+\frac{2N-2k}{2N-k}\cdot\frac{k}{2N-k-1}(E(N-1,k)+2)$ $E(N,N)=N$ $0\leq a<b\leq N\implies E(N,a)>E(N,b)$ $\lim_{N\to\infty} E(N,0)-E(N,k)=\frac{k}{2}$ $\lim_{N\to\infty} E(N,N-k)-E(N,N)=k$ There exists some constant $X$ such that $\lim_{N\to\infty} E(N,0)=X\cdot N$ . If I am not mistaken, the goal to find the expected number of turns to complete a game with $n$ starting pairs reduces to finding that constant $X$ . However, I am stuck here. I know $\frac{3}{2}<X<\frac{1+\sqrt{5}}{2}$ , but not much more.","['game-theory', 'markov-chains', 'combinatorics', 'probability']"
4487171,To plot a discontinuous function at rational numbers [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question Good day everyone ! I'm just curious on how to plot (preferable in matlab or mathematica) the following stepwise function. $
f(x) :=
    \begin{cases}
    \dfrac{1}{q}~~~:~x=\dfrac{p}{q} \in \mathbb{Q} ~~\text{(in reduced form)}\\
    0~~~:~x \not \in \mathbb{Q}
    \end{cases}
$ to illustrate that it is continuous at every irrational in the interval $(0,1)$ but discontinuous at every rational in $(0,1)$ . Thanks in advance.","['continuity', 'functions', 'graphing-functions']"
