question_id,title,body,tags
396000,Methods for determining the convergence of $\sum\frac{\cos n}{n}$ or $\sum\frac{\sin n}{n}$,"As far as I know, the textbook approach to determining the convergence of series like $$\sum_{n=1}^\infty\frac{\cos n}{n}$$ and $$\sum_{n=1}^\infty\frac{\sin n}{n}$$ uses Dirichlet's test, which involves bounding the partial sums of the cosine or sine terms. I have two questions: Are there any other approaches to seeing that these series are convergent? I'm mostly just interested to see what other kinds of arguments might be made. What's the best way to show that these two series are only conditionally convergent? I don't even know the textbook approach to that question.","['convergence-divergence', 'sequences-and-series']"
396006,Having trouble using eigenvectors to solve differential equations,"The question asked to solve $$\frac{dx}{dy} = \begin{pmatrix}
        5 & 4 \\
        -1 & 1\\
        \end{pmatrix}x$$ ,where $$ x = \begin{pmatrix} x_1 \\ 
x_2 \\ \end{pmatrix}$$ I went ahead an found the determinant of matrix $$ |A - I\lambda| = \lambda^2 - 4\lambda + 9$$
And found $\lambda = 3$ Then the $\alpha$ matrices was found to be $$ \begin{pmatrix}
5 & 4\\
-1 & 1\\
\end{pmatrix} \alpha = 3\alpha$$ where $$\alpha = \begin{pmatrix} 
\alpha_1 \\
\alpha_2 \\
\end{pmatrix}$$ Ultimately $-\alpha_1 = 2\alpha_2$ so I write $$\alpha = \begin{pmatrix} 
-1 \\
2 \\
\end{pmatrix}$$ Then because $\lambda$ is a repeated root I know the solution is supposed to look something like this: $$x = c_1\alpha e^{\lambda t} + c_2( \alpha t + \beta) e^{\lambda t}t$$ And then this is where it gets tricky for me. I know we find the $\beta$ matrix by figuring this out: $$(A - I\lambda)\beta = \alpha$$ Now when I multiply all that out I get $$2\beta_1 + 4\beta_2 = -1$$
$$\beta_1 + 2\beta_2 = -2$$ This is the system of equations I can't seem to solve to get a suitable $\beta$. One option I have is to make $$\beta = \begin{pmatrix} 
0\\
-1\\
\end{pmatrix}$$ But this doesn't work for the second system of equations. Help please.","['matrices', 'linear-algebra', 'calculus', 'ordinary-differential-equations']"
396014,Bound on expectation of absolute value in terms of variance,"In my book it says that a white noise process $\{Z_t\}$ with mean zero and variance $\sigma^2$ has the following property: E$|Z_t| \leq \sigma$. This had me thinking of Jensen's inequality, that $\text{E}(g(X)) \geq g(\text{E}(X))$, for convex functions g. Since we have that $\text{E}(Z^2_t) = \sigma^2$ and $\text{E}(Z_t) = 0$, we could apply this inequality to to  $\text{E}(Z_t)$ and obtain $\text{E}(|Z_t|) \geq |\text{E}(Z_t)| = 0$, since the absolute value is a convex function.  But we need the upper bound, and the inequality is only for convex functions, so we can't use $\text{E}(Z^2_t) = \sigma^2$ and take square roots on both sides..","['time-series', 'probability']"
396028,hint with Bayes rule problem,"The pirate Captain Queequeg has a lazy crew and suspects they are planning to stage a mutiny. Captain Queequeg's solution is to have every member of the crew roll Queequeg's lucky die. If the roll is even, the crew member must walk the plank. If the roll is odd, the crew member must take a swig of truth serum and then reveal his or her true intent. If the crew member was planning on mutiny, he or she must walk the plank, and if not, is allowed to remain on the ship. Queequeg's die has been cursed so that evens are rolled 61% of the time. Crew members are either lazy or mutinous but not both. Of the crew members who take the serum, 18% are forced to reveal they were planning mutiny. 1) What is the chance a crew member will walk the plank, given he or she is mutinous? 2) What is the chance a crew member will walk the plank, given he or she is just plain lazy (but not mutinous)? 3) What is the chance a crew member is mutinous, given he or she walked the plank? This is what I have so far: The probability of walking the plank seems to be $P(\text{plank}) = P(\text{mutinous} \cap \text{odd})+P(\text{lazy} \cap \text{even})$ $P(\text{plank}) = P(\text{mutinous})P(\text{odd})+P(\text{lazy})P(\text{even})$ Rolling the die is independent of being mutinous or lazy. $P(\text{lazy})= P(\lnot \text{mutinous})$ 1) I tried applying Bayes rule, but then I need the posterior probability from part 3) first. $$P(\text{plank} \mid \text{mutinous}) = {P(\text{mutinous} \mid \text{plank})P(\text{plank}) \over P(mutinous)}$$ Expanding the likelihood using total probability $$P(\text{plank} \mid \text{mutinous}) = {P(\text{mutinous} \mid \text{plank})P(\text{plank}) \over P(\text{mutinous} \mid \text{plank})P(\text{plank}) + P(\text{mutinous} \mid \lnot \text{plank})P(\lnot \text{plank})}$$ Using conditional probability, substituting the joint probability for the posterior and prior $$P(\text{plank}\mid\text{mutinous}) = {P(\text{mutinous} \cap \text{plank}) \over P(\text{mutinous}\mid\text{plank})P(\text{plank}) + P(\text{mutinous}\mid\lnot\text{plank})P(\lnot\text{plank})}$$ Being mutinous and walking the plank aren't independent events, so I am not sure where to go from here.","['bayesian', 'probability']"
396038,Symmetric Matrices of $I_{2}$,"Find $10$ symmetric matrices $ A = \begin{pmatrix}
a &b \\ 
 c&d 
\end{pmatrix}$ such that $A^{2}=I_{2}$ (I'm going to call matrix A the ""square root"" of $A^{2}$. If this is the incorrect name for it, may someone please tell me what it is actually called?) My professor posed this question in class and told us there was an infinite amount of square roots. (Assuming I understood him correctly). However I don't see how there would be many of these, as I was under the impression that a matrix only has one inverse, for $A  A^{-1}=I_{n}$. If someone could tell me if I either misunderstood the professor or if I'm thinking about something incorrectly, please correct me. My other question is other than blatant guess and check, is there a method to think of these symmetric square roots? Thanks in advance.","['matrices', 'linear-algebra']"
396049,"Does $\,x>0\,$ hint that $\,x\in\mathbb R\,$?","Does $x>0$ suggest that $x\in\mathbb R$? For numbers not in $\,\mathbb R\,$ (e.g. in $\mathbb C\setminus \mathbb R$), their sizes can't be compared. So can I omit ""$\,x\in\mathbb R\,$"" and just write $\,x>0\,$? Thank you.","['notation', 'real-analysis']"
396083,"Given $\Sigma$ a surface parameterized by $\Phi : D \to \Sigma$, prove a certain formula for $area(\Sigma).$","Let $\Sigma$ be a surface parameterized by  $\Phi : D \to \Sigma$, and let $$A=\Phi_u \cdot \Phi_u~,~B=\Phi_u \cdot \Phi_v,~ C=\Phi_v \cdot \Phi_v.$$ Prove $$area(\Sigma)=\int\int_D \sqrt{AC-B^2} dudv.$$ What I've done: We already know $$area(\Sigma)=\int\int_D ||\vec{N}||dudv.$$ where $\vec{N}$ is the normal vector $~\Phi_u \times \Phi_v.$ So it suffices to show that $||\vec{N}||=\sqrt{AC-B^2}.$ Now I can do this trivially by ""brute force computation"", i.e., by expanding out the components of $A,B,C$ and $\vec{N},$ and showing that the expressions are equal. I was wondering though if there is a simpler way to do this, without resorting to expanding into components.","['multivariable-calculus', 'integration']"
396085,How to find area of triangle from its medians,"The length of three medians of a triangle are $9$,$12$ and $15$cm.The area (in sq. cm) of the triangle is a) $48$ b) $144$ c) $24$ d) $72$ I don't want whole solution just give me the hint how can I solve it.Thanks.","['geometry', 'triangles', 'trigonometry']"
396092,Definition of simple spectrum,"From the book ""Spinning Tops"" by Audin, given Lax equation $[A_{\lambda},B_{\lambda}]$ where $\lambda$ is a parameter (so called spectral parameter), she claims that we have spectral curve $P(\lambda,\nu)=0$ where $P(\lambda,\nu)$ is a characteristic polynomial of $A_{\lambda}$ . Then, she talks about when $A_{\lambda}$ has a simple spectrum. I tried to look for definition of it, but I couldn't find it. Can you please tell me what does it mean for a spectrum to be simple?","['classical-mechanics', 'functional-analysis', 'algebraic-curves']"
396097,When is it solvable:$10^a+10^b\equiv -1 \pmod p$,"If $p$ is a prime, $(a,p)=1$,denote $ord(a,p)=d,$  where $d$ is the smallest positive integer solution to the equation $a^d\equiv 1 \pmod p$.We can prove that $$10^n\equiv -1 \pmod p\tag1$$ is solvable iff $ord(10,p)$ is even. Now,consider this equation,$$10^a+10^b\equiv -1 \pmod p.\tag2$$
If $10$ is a primitive root modulo $p$, then there is an integer $a$ for every $b≠\dfrac{p-1}{2}\pmod {p-1}$ so that $a,b$ satisfies $(2)$. My question is,what's the necessary and sufficient condition that $(2)$ has at least $1$ solution? If we are given a prime $p$,how to determine whether $(2)$ is solvabe? This is a way,but not effectively: for every positive integer $b\leq\frac{1}{2}ord(10,p)$,determine whether $(2)$ is solvabe for $a$.By this way,I find $(2)$ is solvable for these primes, which $10^n\equiv -1 \pmod p$ is not solvable : $3,31,37,43,53,67,71,83,107,151,163,173,191,199,227,277,283,307,311,317,347,359,397,431,439,443,467,479,523,547,563,587,599,613,631,643,683,719,751,757,773,787,797,827,839,853,883,907,911,919,947,991,\cdots$ My original problem is: how many ""$1$"" is need at least for a decimal number which is consisting of ""$0$"" and ""$1$"" and divisible by $p$?This question is to find these primes that three ""$1$"" is need at least. Thank you.","['modular-arithmetic', 'elementary-number-theory', 'number-theory']"
396102,Simplifying this expression $(e^u-1)(e^u-e^l)$,"Is it possible to write the following $$(e^u-1)(e^u-e^l)$$ as $$e^{f(u,l)}-1?$$","['algebra-precalculus', 'polynomials']"
396116,Set Theory Notation Crises,"For those who are familiar with the following notation, could you explain it in plain English because I picked up a set theory textbook but the book assumes the reader is familiar with the notation without giving a formal explanation anywhere. 1) $$\{x:\mathscr{P}x\}$$
2) $$\{\mathscr{a}_x: \mathscr{P}x\}$$ 
3) $$\left(\bigcup_{i \in I} \mathscr{a}_i\right)^{c}$$ 4) $$x \in \{y: y>2\}$$
5) (distributive laws) $$B \cap \left(\bigcup_{i \in I} \mathscr{a}_i\right)$$
6) $$\{x: x \not\in x\}$$ The Px is like a P that is curly and looks like old english writing or might be a greek and same with a_i. a is like a fat curly a which I'm thinking might stand for ""for all."" Any input with explanation would be great or any reference would work as well. The book I'm reading is 'Set Theory An Introduction' by Robert Vaught.","['notation', 'elementary-set-theory']"
396120,"Are there real numbers a and b such that $f(x,y,t) = x^a t^b$ satisfies the heat equation?","The question is in the title. The heat equation is as follows:
$$
\frac{\partial f}{\partial t} = k \left( \frac{\partial^2 f}{\partial x^2} +  \frac{\partial^2 f}{\partial y^2} \right),\quad k\in\mathbb{R}
$$ Attempt at solution Plugging the requested form into the above equation yields: $$
\frac{\partial f}{\partial t} = b\ t^{b-1} x^a\\
\frac{\partial^2 f}{\partial x^2} = a (a-1)\ t^b x^{a-2}\\
\frac{\partial^2 f}{\partial y^2} = 0
$$ Which leads to showing that:
$$
b\ x^2 = k\ a(a-1)\ t
$$ I'm not sure how to proceed from this point. Is this the correct procedure to solve this problem? Thanks!","['multivariable-calculus', 'ordinary-differential-equations', 'partial-derivative']"
396134,$\lim_n \frac{1}{n} E(\max_{1\le j\le n} |X_j|) = 0$,"If $\{X_n\}$ is a sequence of identically distributed r.v.'s with finite mean, then $$\lim_n \frac{1}{n} E(\max_{1\le j\le n} |X_j|) = 0$$ The inequality $$\frac{1}{n}E(\max_{1\le j\le n} |X_j|) \le \frac{1}{n}E(|X_1| + \cdots + |X_n|)=E(|X_1|)$$ suggests that the result has something to do with the ""graphs"" of the $|X_j|$ overlapping so that $E(|X_j|)=\int_0^\infty |X_j| P(d\omega)$ isn't fully counted $n$ times in the value of $E(\max_{1\le j\le n} |X_j|)$. But how do we make this rigorous? Notice there is no mention of the $X_j$ being independent.","['probability-theory', 'probability']"
396138,"How many ""$1$"" is need at least for a decimal number,which is consisting of ""$0$"" and ""$1$"" and divisible by $p$?","How many ""$1$"" is need at least for a decimal number,which is consisting of ""$0$"" and ""$1$"" and divisible by $p$? If $p=2^k\cdot d+1$, and $10^d\equiv 1 \pmod p$,then $10^n\equiv -1 \pmod p$ has no solution, so $10^n+1$ is never divisible by $p$, so two ""$1$"" is not enough,but since $\dfrac{10^{p-1}-1}{9}=11\cdots 111\equiv 0 \pmod p$,so $p-1$ is awlays enough,in fact,$ord(10,p)$ is enough,but may be not the least. In When is it solvable:$10^a+10^b\equiv -1 \pmod p$ , I asked that when three ""$1$"" is need at least,I think I should ask this original problem here,because this is more general and why I asked that question. Assume $(10,p)=1.$ Two ""$1$"" is need at least for $p=7, 11, 13, 17, 19, 23, 29, 47, 59, 61, 73, 89, 97, 101, 103,\cdots$ Three ""$1$"" is need at least for $p=3, 31, 37, 43, 53, 67, 71, 83, 107, 151, 163, 173, 191, 199,\cdots$ Four ""$1$"" is need at least for $p=79, 733,\cdots$ Thank you!","['elementary-number-theory', 'number-theory']"
396170,Evaluating $\int_0^\infty \frac{\log (1+x)}{1+x^2}dx$,"Can this integral be solved with contour integral or by some application of residue theorem?
$$\int_0^\infty \frac{\log (1+x)}{1+x^2}dx = \frac{\pi}{4}\log 2 + \text{Catalan constant}$$ It has two poles at $\pm i$ and  branch point of $-1$ while the integral is to be evaluated from $0\to \infty$. How to get $\text{Catalan Constant}$? Please give some hints.","['improper-integrals', 'calculus', 'integration', 'complex-analysis', 'contour-integration']"
396205,To show that function is constant [duplicate],"This question already has answers here : Function on $[a,b]$ that satisfies a Hölder condition of order $\alpha > 1 $ is constant (2 answers) Closed 6 years ago . Let $f$ be defined on $\mathbb{R}$ and suppose that |$f(x)$ - $f(y)$| $\leq$ $(x-y)^2$ $x,y \in\mathbb{R}$. Here I have to show that $f$ is a constant function. I think I have to show that $f'(x)$ = 0 for all $x$.
But I don't know from where to start this. I tried taking it as (|$f(x)$ - $f(y)$|/|$x$-$y$|) $\leq$ |$x$ - $y$|. Am I right in doing so? Any hint or suggestion will be helpful. Thanks",['real-analysis']
396207,"The elements of $\mathbb{Z}[\sqrt{-5}]/(2,\sqrt{-5}+1)$","I'm really confused with this one... How can I determine the elements of the module $\mathbb{Z}[\sqrt{-5}]/(2,\sqrt{-5}+1)$? Or its cardinality? Does $$\mathbb{Z}[\sqrt{-5}]/(2,\sqrt{-5}+1)=\{\bar{0},\bar{1},\overline{0+\sqrt{-5}}\}?$$","['ring-theory', 'abstract-algebra', 'number-theory']"
396209,Most elegant/simple proof of the irrationality of $\pi$,"What is the most elegant/shortest proof of this? The proofs I have seen are quite long, unlike the proof of the irrationality of $e$. thanks","['pi', 'elementary-number-theory', 'real-analysis', 'number-theory']"
396214,Probability of at least N events occuring,"I have a series of N events, each with its own probability of occurring . How would I calculate the probability that at least M of the N events actually do occur? I think this is conditional, in that getting at least M occurrences depends on getting at least M-1 occurrences. Past that I'm getting stuck.",['probability']
396227,"Neumann problem, stuck on a boundary condition.","I am stuck on a problem that I am trying for exam practice and I would very much appreciate a hint to help me out, here is the section where I am stuck: A solution is sought to the Neumann problem for $\nabla^2 u = 0$ in the half plane $z > 0$:
  $u = O(|x|^{−a}),
\frac{\partial u}{\partial r}
= O(|x|^{−a−1}) ~~ \mathrm{as} ~~  |x| → ∞,~~ \frac{\partial u}{\partial z} ~
= p(x, y) ~ on ~ z = 0,
\mathrm{where}~ a > 0$. It is assumed that
  $\int_{\infty}^{\infty}\int_{-\infty}^{\infty}
p(x, y) dx dy = 0$. Explain why this condition is
  necessary. My feeling is that this is to do with Green's third identity and that we need the normal derivative in the $x-y$ plane to be integrable in order to find out solution with a Green's function, am I correct? EDIT:
the divergence theorem sorts this out.",['multivariable-calculus']
396229,Is it possible to write any bounded continuous function as a uniform limit of smooth functions,Is $C^\infty(\mathbb{R})\subset C_b(\mathbb{R})$ dense? I.e. is any continuous bounded function $f:\mathbb{R}\to\mathbb{R}$ the uniform limit of smooth functions? On any bounded interval this is true since by Stone-Weierstrass polynomials are smooth and dense in the continuous functions. I guess the result is still true for $\mathbb{R}$ but I don't know how to prove it. Since I don't have any integrability conditions on $f$ the technique of convoluting with mollifiers is probably not applicable.,"['functional-analysis', 'real-analysis']"
396270,Sum involving binomial coefficient satisfies congruence (A contest question),"Let $p$ be an odd prime, and denote $$f(x)=\sum_{k=0}^{p-1}\binom{2k}{k}^2x^k.$$
Prove that for every $x\in \mathbf Z$,$$(-1)^\frac{p-1}2f(x)\equiv f\left(\frac{1}{16}-x\right)\pmod{p^2}.$$
This is a contest question, I do not know how to prove it. Thank you. Addition: I find it's equivalent to prove that:
$$\sum _{k=r}^{p-1} \frac{(-1)^r \binom{2 k}{k}^2 \binom{k}{r}}{16^{k-r}}\equiv(-1)^{\frac{p-1}{2}} \binom{2 r}{r}^2 \pmod {p^2}\tag1$$
for $r=0,1,2,\cdots p-1.$ And $(1)$ is equivalent to $$\sum _{k=r}^{p-1} \binom{2 k}{k}^2 \binom{k}{r}16^{-k} \equiv(-1)^{\frac{p-1}{2}} (-16)^{-r}\binom{2 r}{r}^2 \pmod {p^2}.$$","['elementary-number-theory', 'number-theory', 'contest-math', 'combinatorics']"
396271,"Finishing the proof that $\textrm{Spec}K[X,Y]\setminus\{(X,Y)\}$ is not an affine scheme","If $K$ is a field, $\mathbb A^2_K=\textrm{Spec}K[X,Y]$  and $U=\mathbb A^2_K\setminus\{(X,Y)\}$, I want to prove that $(U,\mathscr O_{\mathbb A^2_K|U})$ is not an affine scheme. I know that this topic has been handled many times, but I want to point a specific passage in the language of schemes. I have proved that $\mathscr O_{\mathbb A^2_K|U}(U)=\mathscr O_{\mathbb A^2_K}(\mathbb A^2_K)=K[X,Y]$. Now suppose that $(U,\mathscr O_{\mathbb A^2_K|U})$ is an affine scheme, there is a ring $R$ such that  $(U,\mathscr O_{\mathbb A^2_K|U})\cong (\textrm{Spec }R,\mathscr O_{\textrm{Spec}R})$; by the equivalence between the opposite category of rings and the category of affine schemes we have that $R\cong \mathscr O_{\mathbb A^2_K|U}(U)=K[X,Y]$. The conclusion is that $(U,\mathscr O_{\mathbb A^2_K|U})\cong (\mathbb A^2_K,\mathscr O_{\mathbb A^2_K})$ but I don't understand where is the contraddiction. Why $\mathbb A^2_K$ and $U$ shouldn't be homeomorphic (look here for a similar question)? Even if they are homeomorphic (I don't think so) why there shouldn't exist an isomorphism as locally ringed spaces? The fact that the open embedding is not an isomorphism doesn't imply that there is no isomorphisms between the two schemes.","['affine-schemes', 'algebraic-geometry', 'schemes']"
396280,Differentiability implies Lipschitz continuity,"Let $f:[0,1]\to\mathbb{R}$ be a continuous function and suppose $f$ is differentiable at $x_0\in [0,1]$. Is it true that there exists $L>0$ such that $\lvert f(x)-f(x_0)\lvert\leq L\lvert x-x_0\lvert$? I know that local continuously differentiable implies local Lipschitz continuity. Is this still true in the case given above?","['functional-analysis', 'real-analysis']"
396285,How does it follow $s\int_1^{\infty}\frac{\psi(x)}{x^{s+1}}dx$?,"I have two relations: 1)$-\frac{\zeta'(s)}{\zeta(s)}=\sum_{1}^{\infty}\frac{\Lambda(n)}{n^s}$. 2)$\psi(x)=\sum_{n\leq x}\Lambda(n)$. From these two how does it follow that $-\frac{\zeta'(s)}{\zeta(s)}=s\int_1^{\infty}\frac{\psi(x)}{x^{s+1}}dx$, for $s>1$.
Can anyone explain how does it follow?","['analytic-number-theory', 'integration', 'complex-analysis', 'number-theory']"
396288,Gauss–Ostrogradsky formula for Distributions,"Let $\Omega\subset\mathbb{R}^N$ be a bounded domain and $u\in W^{1,p}(\Omega)$, $v\in L^{p'}(\Omega)^N$ with $p\in (1,\infty)$. Let $\operatorname{div}(v)$ be the divergence of $v$ in the sense of distribtuion and suppose that $\operatorname{div}(v)=0$. Assume that $B$ is any ball in $\Omega$. How can one prove that $$\int_B v\cdot\nabla udx=\int_{\partial B}(v\cdot\nu)ud\Gamma$$ where $\nu$ is the outward normal and $\Gamma$ de surface measure in $\partial B$? This is claim $(7)$ from the paper of Zhikov : On the compansated compacness principle. I think I can prove it for almsot ball in $\Omega$ by using Fubini's theorem and mollifiers, but he estates the result for all $B$. Maybe there is a straighforward approach to it, but I can't see it. Thank you","['sobolev-spaces', 'measure-theory', 'distribution-theory', 'lp-spaces']"
396297,Evaluating $\lim _{n \rightarrow \infty} (2n+1) \int_0 ^{1} x^n e^x dx$,"Could you help me evaluate $\lim _{n \rightarrow \infty} (2n+1) \int_0 ^{1} x^n e^x dx$? I've calculated that the recurrence relation for this integral is: $\int_0 ^{1} x^n e^x dx = x^ne^x | ^{1} _{0} - n \cdot \int_0 ^{1} x^{n-1} e^x dx$ So if we let $I_n = \int_0 ^{1} x^n e^x \ dx$, we get $I_n = \left.x^ne^x \,\right |^1 _0 - n \cdot I_{n-1}$. Can this be useful here? I would appreciate all your help.","['convergence-divergence', 'integration', 'limits']"
396301,Why doesn't the Weierstrass approximation theorem imply that every continuous function can be written as a power series?,"I hope that my question in the title is well formulated. I am a little bit confused with the next exercise from a book: Argue that there exists functions $f \in C[0, \frac{1}{2}]$ that cannot be written on the form
$$
f(x) = \sum_{k=0}^{\infty}c_kx^k, x\in(0, \frac{1}{2}).
$$ But Weierstrass' theorem states that $||f(x)-P(x)||_{\infty} < \epsilon$, where $P(x)$ is a polynomial for $x\in[a,b]$. The statement of the exercises refers to an open and bounded interval, and in Weierstrass to a closed and bounded interval for the polynomial. Is this the key? to be honest, I do not see why.","['general-topology', 'normed-spaces', 'sequences-and-series']"
396302,"Why substitution method does not work for $\int (x-\frac{1}{2x} )^2\, \mathrm dx$?","Why $$\int \ \left(x-\frac{1}{2x} \right)^2 \, \mathrm  dx$$ is easy to integrate once $$\left(x-\frac{1}{2x} \right)^2$$ is expanded, but impossible using substitution method? (tried 5 different subs but of course that is not the proof that there is no suitable substitution) if mathematical results are independent of the logical methods used to derive them, why something so simple works one way but not the other?","['integration', 'problem-solving']"
396317,Surfaces ruled over elliptic curves,"Ground field $\Bbb{C}$. Algebraic category. Elliptic surfaces are those surfaces endowed with a morphism onto some smooth curve, with generic fiber an elliptic curve. Suppose $E$ is an elliptic curve and consider the ruled surface
$$ S=\frac{E\times\Bbb{P}^1}{G} $$
where $G$ is a group of translations of $E$, acting on $\Bbb{P}^1$. Thus $F=E/G$ is an elliptic curve (and $\Bbb{P}^1/G=\Bbb{P}^1$) Then $S$ is an elliptic surface, for the projection on the second factor induces a morphism $S\rightarrow\Bbb{P}^1$ whose fibers are elliptic curves ($F$, in fact). An exercise on Beauville's book (chap. IX) says that if $S$ is a ruled surface over an elliptic curve $E$, and $S$ is an elliptic surface, then $S$ is isomorphic to the above example. Any hint for attacking this ? Thank you. Edit: This question has been answered here .","['algebraic-geometry', 'elliptic-curves']"
396382,What does this dollar sign over arrow in function mapping mean?,"In a certain function mapping like this, $x \xleftarrow{\$}  \{0,1\}^k$ ( Lecture Notes on Cryptography by
 S. Goldwasser and M. Bellare , page 18) I fail to understand what exactly does this \$ sign mean. This has been put
here without any explanation or further elaboration. It may be very trivial or may be very silly of me asking it like this, but
I want to understand what is means. Google search (function, dollar, arrow) has not returned any result. http://en.wikipedia.org/wiki/List_of_mathematical_symbols does not mention anything as well.",['functions']
396383,Work-Time Problem,"$10$ cats can eat $10$ mice in $20$ minutes. $2$ cats started eating $60$ mice in $3$ minutes, then another $6$ cats were added, how many more minutes will it take them to consume the remaining mice? I got the answer as $149.25$ minutes. But it seems to be wrong. Can anyone help out? Since it'll take too long for me type out my solution, I'll just mention the key points I got:- Since $10$ cats can eat $10$ mice in $20$ minutes, I figured $1$ cat can eat $1$ mouse in $20$ minutes. From this, I got that $2$ cats can eat $0.3$ mice in $3$ minutes. So, the question then is, $8$ cats can eat $(60-0.3)$ mice in (?) minutes. According to my reasoning, $8$ cats can eat $1$ mouse in $2.5$ minutes. And so, I figured $8$ cats can eat $59.7$ mice in $149.25$ minutes. Can anyone expand on where I went wrong?",['algebra-precalculus']
396392,Proving a statement about $k$-colouring of a graph,"Prove that a graph is $k$-colourable iff its edges can be oriented in such a way that the resulting directed graph does not contain a path of length $k$. It seems to me that the '$\Leftarrow$' implication might be slightly easier to show if we were to consider directed acyclic graphs (then we could assign subsequent colors to vertices as we traverse along a path and do some rearranging when we visit an already coloured vertex)... But I am stuck at finding a valid argument that justifies the implication in either direction, not to mention I am actually interested in a stronger statement.","['graph-theory', 'discrete-mathematics']"
396411,Trigonometric Identity Problem - Cos Tan and Sin,"I have been going through my lecture notes for a structures question (the solution of a 2nd order ode for a buckling problem) when I came across a very weird trigonometric simplification which I just cannot get my head around. Could anyone shed any light on this? Further down the page, there is another similar simplification, but this one seems to be incorrect: Testing some random values, the simplification is incorrect unless I replace the C/2 with a C.",['trigonometry']
396455,Good introductory book for self-studying quasigroups?,"I'm looking for an undergraduate or beginning graduate level text from which to self-learn quasigroup theory. An emphasis on using quasigroups to understand the structure of groups would be appreciated. I prefer texts that are leisurely and systematic. I like having only a few examples, but those examples worked out in great detail.","['quasigroups', 'self-learning', 'reference-request', 'abstract-algebra']"
396459,Why is it important to have a discrepancy between image and codomain?,"A function $f:\mathbb{R}\rightarrow \mathbb{R}$ given by $f(x)=x^2$ has $\mathbb{R}_{\geq0}$ as its image and $\mathbb{R}$ as its codomain. What's the need for this discrepancy? Why don't we just write $f:\mathbb{R}\rightarrow \mathbb{R}_{\geq0}$? I believe the reason for this is that there may be some functions in which stating the image this way may be impractical - if this hypothesis is true, what is this class of functions? If yes or no, is there any other reason for this?","['elementary-set-theory', 'functions']"
396473,Linear Regression: Expectation Proof,"I found the following proof in my notes: $E(Y_i) = E[\beta_0 + \beta X_i + \varepsilon_i] =\cdots= \beta_0 + \beta X_i$.  This does not seem right to me, however.  Why would $E(\beta_1 X_i) = \beta_1 X_i$?  I wonder if i might have written it down incorrectly, with the actual proof meaning to be for the estimated value Yi hat (I don't know how to code this unfortunately).  Does anyone recall this property of linear regression?","['statistics', 'regression']"
396480,"How to understand $\frac{d}{dt}\{(\exp(tX))_*(Y)\}|_{t=0}=[X,Y]$?","Let $G$ be a Lie group on which $X$ and $Y$ are two vector fields. Let $G\xrightarrow{\exp(tX)} G$ be the (Lie theory) exponential map corresponding to $X$. Then of fundamental importance is \begin{equation}
\frac{d}{dt}\{(\exp(tX))_*(Y)\}|_{t=0}=[X,Y]
\end{equation} 
where $[\cdot,\cdot]$ is the Lie bracket, and $\exp(tX)_*$ is the differential map induced from $\exp(tX)$. Staring at this equation for a while, the only way I can prove it is by relating this exponential map to the (Remannian) exponential map . This proof involves a lot differential geometry, which seems rather unnecessary, and does not seem very instructive. I am wondering whether someone can share a more elegant proof (more direct, less differential geometry) or just some intuitive idea about how one should understand this equation. Thanks very much!","['differential-geometry', 'representation-theory', 'group-theory', 'lie-groups', 'intuition']"
396481,"How can I prove that $\sin (10^\circ), \sin(1^\circ), \sin(2^\circ), \sin(3^\circ), \tan(10^\circ)$ are irrational","Prove that $\sin (10^\circ)$, $\sin(1^\circ)$, $\sin(2^\circ)$, $\sin(3^\circ)$, and $\tan(10^\circ)$ are irrational. My Attempt: Let $x = 10^\circ$. Then $$
\begin{align}
x &= 10^\circ\\
3x &= 30^\circ\\
\sin (3x) &= \sin (30^\circ)\\
3\sin (10^\circ)-4\sin^3(0^\circ) &= \frac{1}{2}
\end{align}
$$ Now let $y = \sin (10^\circ)$. Then $$
\begin{align}
3y-4y^3 &= \frac{1}{2}\\
6y-8y^3 &= 1\\
\tag18y^3-6y+1 &= 0
\end{align}
$$ How can I calculate the roots of $(1)$?",['trigonometry']
396509,Equivalence Relations and functions on partitions of Sets,"let $f$ be a function on $A$ onto $B$.  Define an equivalence relation $E$ in $A$ by: $aEb$ if and only if $f(a)=f(b)$. Define a function $\phi$ on $A/E$ by $\phi([a]_{E})=f(a)$. Hint: Verify that $\phi([a]_{E})=\phi([a']_{E}) $ if $[a]_{E} = [a']_{E}$ I know that A/E is a partition of A. I know that a binary relation $F$ is called a function if $aFb$ and $aFc$ implies $b=c$ for any $a, b, \text {  and  } c$","['equivalence-relations', 'elementary-set-theory']"
396516,Question about diffeomorphism,"Here is an assignment problem: $f:\mathbb{S}^2 \longrightarrow \mathbb{S}^2$ is smooth and surjective. Prove $\exists$ open subset $ U $ of $\mathbb{S}^2$, such that $f|_U$ is a diffeomorphism. I've tried to relate it to covering maps but failed. Can someone help me with this problem? Thanks for help.","['manifolds', 'differential-geometry']"
396549,Which real functions have their higher derivatives tending pointwise to zero?,"Let $\mathrm C^\infty\!(\Bbb R)$ be the space of infinitely differentiable functions $f:\Bbb R\rightarrow\Bbb R$, and define the subspace$$A:=\{f\in\mathrm C^\infty\!(\Bbb R):(\forall x\in \Bbb R)\lim_{n\rightarrow\infty} f^{(n)}(x)=0\},$$where $f^{(n)}$ is the $n$th derivative of $f\;(n=0,1,\dots).$ Clearly all polynomial functions are in $A$. Are any others? Edit: Alfonso has answered this question well, but is there any characterization of $A$ in terms of familiar types of function?",['real-analysis']
396555,"integration by substitution, using $\;t = \tan \left(\frac 12 x\right)$","$\displaystyle\int_0^\frac{\pi}{2}\frac{1}{2-\cos x} \, dx$ using the substitution $t=\tan\frac{1}{2}x$ $x=2\tan^{-1}t$ $\dfrac{dx}{dt}=\dfrac{2}{1+t^2}$ $dx=\dfrac{2}{1+t^2}\,dt$ $\displaystyle\int_0^1 \left(\frac{1}{2-\cos x}\right)\left(\frac{2}{1+t^2}\right)\,dt$ Is this the right idea? If so what do I do next? $\displaystyle\int_0^1\left(\frac{1}{2-\frac{1-t^2}{1+t^2}}\right) \,\left(\frac{2}{1+t^2}\right)\, dt$ $\displaystyle\int_0^1\frac{2}{1+3t^2}\,dt$ $=2\left[\frac{\ln(1+3t^2)}{6t}\right]_0^1$","['definite-integrals', 'calculus', 'integration']"
396557,What is the functional inverse (with respect to $h$ (!)) of $f^{\circ h}(x)={F(h) +x F(h-1) \over F(1+h) +x F(h) }$?,"I've considered the fractional iteration of $f(x) = {1 \over 1+x} $ for which the general expression depending on the iteration-height parameter $h$ might be assumed by the formula 
$$ f^{\circ h}(x) = f(x,h)={F(h) +x \cdot F(h-1) \over F(1+h) +x \cdot F(h)  }$$  where $ \displaystyle \qquad \small F(h)=\operatorname{fibonacci}(h) = {\varphi^h - (1-\varphi)^h \over \sqrt5 }$ and $ \displaystyle \qquad \small \varphi = {1+\sqrt5 \over 2} \sim 1.618... $ (Note, that for fractional iterates we need $x \in \mathbb C$) Today I tried to find a formulation for the functional inverse with respect to h , but don't find a good starting point so: Q: How would look a function $ h = \operatorname{hgh}(x_0,x_h) $ which would indicate the required iteration-height $h$ given $x_0$ and $x_h = f(x_0,h)$ ? Is there even a closed form for it (I'd call it still closed-form  if it possibly includes e.g. the Lambert-W function) [update]: for more background see the older exercise of mine","['complex-dynamics', 'special-functions', 'function-and-relation-composition', 'fibonacci-numbers', 'functional-analysis']"
396562,Estimating the sum $\sum_{k=2}^{\infty} \frac{1}{k \ln^2(k)}$,"By integral test, it is easy to see that 
$$\sum_{k=2}^{\infty} \frac{1}{k \ln^2(k)}$$
converges. [Here $\ln(x)$ denotes the natural logarithm, and $\ln^2(x)$ stands for $(\ln(x))^2$] I am interested in proving the following inequality (preferrably using
  integral calculus) $$\sum_{k=2}^{\infty} \frac{1}{k \ln^2(k)}>2$$ By wolfram alpha, the actual value of the sum is about 2.10974. Since $\frac{1}{k \ln^2(k)}$ is decreasing, we have $$
\sum_{k=2}^{\infty} \frac{1}{k \ln^2(k)}\ge \int_2^{\infty} \frac{1}{x \ln^2(x)}
dx=\frac{1}{\ln(2)}\approx 1.4427$$
So this lower bounded is weaker than desired. My motivation for asking this question is that by being able to estimate this particular sum will hopefully teach me a general technique which I may try applying to sums of the form $\sum_{k=1}^{\infty} f(k)$. Thanks!","['sequences-and-series', 'calculus', 'integration', 'estimation', 'summation']"
396573,Orders of elements and homomorphisms.,"Corollary 4.6.8 There is a group $G$ of order $n^3$ given by $G= \{b^ic^ja^k \mid 0 ≤ i, j, k < n\}$, where $a$, $b$, and $c$ all have order $n$, and $b$ commutes with $c$, $a$ commutes with $c$, and $aba^{−1} = bc$. Thus,
  $(b^ic^ja^k) (b^{i'}c^{j'}a^{k'}) = b^{i+i'}c^{j+j'+ki'}a^{k+k'}$ The order of $(b^ic^ja^k)$ is n if n is odd and 2n if n is even. Now suppose that $s: K \rightarrow H \rtimes_{\alpha} K$ is given by s(k)=(e,k) and $i : H \rightarrow H \rtimes_{\alpha} K$ is given by $i(h)=(h,e)$. Proposition 4.6.9 Let α : K → Aut(H) be a homomorphism. Suppose given homomorphisms $f_1$ : H → G and $f_2$ : K → G for a group G. Then there is a homomorphism f : $H \rtimes_{\alpha}$ K → G with $f_1 = f$ ◦ i and $f_2$ = f ◦ s if and only if $f_2(k)f_1(h)(f_2(k))^{−1} = f_1(\alpha(k)(h))$ for all h ∈ H and k ∈ K. Such an f, if it exists, is unique, and is given in the HK notation by $f(hk) = f_1(h)f_2(k)$. a) In this problem we assume a familiarity with the group of invertible 3×3 matrices
  over the ring $Z_n$. Let $$G = \left\{ \begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix} \mid \bar{x},\bar{y},\bar{z} \in Z_n \right\}$$ Show that $G$ forms a group under matrix multiplication. Show, using Proposition
  4.6.9, that $G$ is isomorphic to the group constructed in Corollary 4.6.8. I already showed that $G$ is a group under matrix multiplication, but I'm having trouble with the second part of this problem. Let $G = \left\{ \begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix} \mid \bar{x}, \bar{y}, \bar{z} \in Z_n \right\}$ Let $G' = \{ b^ic^ja^k \mid 0 \leq i, j, k < n \}$ where a, b, c all have order n, and b commutes with c, a commutes with c, and $aba^{-1} = bc$. Thus, $$(b^ic^ja^k)(b^{i'}c^{j'}a^{k'}) = b^{i+i'}c^{j + j' + ki'}a^{k+k'}.$$ I want to show that G is isomorphic to G' by using proposition 4.6.9 However, in order to use that proposition, I need to come up with an H and a K, right? So... Let $H = \left\{ \begin{bmatrix} 1 & 0 & 0 \\0 & 1 & 0 \\0 & 0 & 1 \end{bmatrix} \right\}$ Let K=G Obviously $G \cong H \rtimes_{\alpha} K$ Let $f_1 : H \rightarrow G’$ be the trivial homomorphism. Let $f_2: K \rightarrow G'$ be given by $f_2 (\begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix}) = b^ic^ja^k$ Now we need to show that $f_2(\begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix})f_1( \begin{bmatrix} 1 & 0 & 0 \\0 & 1 & 0 \\0 & 0 & 1 \end{bmatrix})f_2(\begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix}^{-1})$ = $f_1(\begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 \\0 & 1 & 0 \\0 & 0 & 1 \end{bmatrix}\begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix}^{-1})$ But, $$f_2(\begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix})f_1( \begin{bmatrix} 1 & 0 & 0 \\0 & 1 & 0 \\0 & 0 & 1 \end{bmatrix})f_2(\begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix}^{-1}) = (b^ic^ja^k)(e)(b^ic^ja^k)^{-1} = e$$ and $$f_1(\begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 \\0 & 1 & 0 \\0 & 0 & 1 \end{bmatrix}\begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix}^{-1}) = e$$ So they must be equal. So the homomorphism $f: H \rtimes_{\alpha} K \rightarrow G$ exists. So now we just need to show that this homomorphism is an isomorphism. I tried to show that by proving that $\begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix}$ has order n when n is odd and order 2n when n is even. I first tried to show the case when n is odd: Let n=2k+1 where $k \geq 0$ Base Case:  n=0 is trivial. We can also try n=3, $( \begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix})^3 = \begin{bmatrix} 1 & 3(\bar{x}) & 3(\bar{y}) + 3(\bar{xy}) \\0 & 1 & 3(\bar{z}) \\0 & 0 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 0 & 0 \\0 & 1 & 0 \\0 & 0 & 1 \end{bmatrix} $ For the induction step, suppose for some 2w+1, an exponent of $\begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix}$ is 2w+1. We need to show that, for 2(w+1)+1 = 2w+3, an exponent of $ \begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix}$ must be 2w+3. By induction, we know that $$\begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix}^{2w+1} = \begin{bmatrix} 1 & (2w+1)\bar{x} & (2w+1)\bar{y}+(2w+1)\bar{xz} \\0 & 1 & (2w+1)\bar{z} \\0 & 0 & 1 \end{bmatrix}$$ However, $$\begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix}^{2w+3} = \begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix}^{2w+1} \begin{bmatrix} 1 & \bar{x} & \bar{y} \\0 & 1 & \bar{z} \\0 & 0 & 1 \end{bmatrix}^2 = \begin{bmatrix} 1 & (2w+1)\bar{x} & (2w+1)\bar{y}+(2w+1)\bar{xz} \\0 & 1 & (2w+1)\bar{z} \\0 & 0 & 1 \end{bmatrix} \begin{bmatrix} 1 & 2\bar{x} & 2(\bar{y})+\bar{xz} \\0 & 1 & 2\bar{z} \\0 & 0 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 2(\bar{x})+(2w+1)(\bar{x}) & 2(\bar{y})+\bar{xz}+(2w+1)(\bar{x})(2)(\bar{z})+ (2w+1)(\bar{xz})+(2w+1)\bar{y} \\0 & 1 & (2w+1)\bar{z}+2(\bar{z}) \\0 & 0 & 1 \end{bmatrix}$$ But that wasn’t the result we were supposed to get, right? Because $2(\bar{y})+\bar{xz}+(2w+1)(\bar{x})(2)(\bar{z})+ (2w+1)(\bar{xz})+(2w+1)\bar{y} = (2w+3)\bar{y} +(6w+4)\bar{xz}$ and 6w+4 is not a multiple of 2w+3. So I was a bit confused…and I was wondering if anybody could help me with this. Thank you in advance","['group-theory', 'abstract-algebra']"
396575,"If we know the eigenvalues of a matrix $A$, and the minimal polynom $m_t(a)$, how do we find the Jordan form of $A$?","We have just learned the Jordan Form of a matrix, and I have to admit that I did not understand the algorithm. Given $A = \begin{pmatrix} 1 & 1 & 1 & -1 \\ 0 & 2 & 1 & -1 \\ 1 & -1 & 2 & -1 \\ 1 & -1 & 0 & 1 \end{pmatrix} $ , find the Jordan Form $J(A)$ of the matrix. So what I did so far: (I) Calculate the polynomial: $P_A(\lambda) = (\lambda - 1)^2(\lambda -2)^2$ . (II) Calculate the minimum polynomial: $m_A(\lambda) = P_A(\lambda) =(\lambda - 1)^2(\lambda -2)^2 $ But I am stuck now, how do we exactly calculate the Jordan Form of $A$ ? And an extra question that has been confusing me. In this case, does $A$ have $4$ eigenvalues or $2$ eigenvalues?","['jordan-normal-form', 'matrices', 'linear-algebra']"
396576,"On an exercise from Hartshone's Algebraic Geometry, Ch I sect 4 [duplicate]","This question already has answers here : Hartshorne's Exercise I.4.9: What is the desired projection explicity? (1 answer) Exercise 4.9, Chapter I, in Hartshorne (1 answer) Closed 4 months ago . My question is about the Ex. 4.9 page 31 in the book Algebraic Geometry by Robin Hartshone. Let $X$ be a projective variety of dimension $r$ in $\mathbb{P}^n$ , with $n\geq r+2$ . Show that for suitable choice of $P\notin X$ , and a linear $\mathbb{P}^{n-1} \subseteq \mathbb{P}^n$ , the projection from $P$ to $\mathbb{P}^{n-1}$ (Ex. 3.14) induces a birational morphism of $X$ onto its image $X' \subseteq \mathbb{P}^{n-1}$ . An idea to prove this is to take a set of generators $\{x_1, \dots, x_n\}$ of $K(X)$ the the function field of $X$ and a subset $\{x_1, \dots, x_r\}$ that form a separating transcendence base (see Def. A on page 27). Then $K(X)$ is generated by a $k$ - combination of $x_{r+1}, \dots, x_n$ and as $r\leq n-2$ there exist another combination of these elements which is not proportional to the first one. Now we choose a point $P \notin X$ and not in this plane. But now, we have to prove that the projection from this $P$ is the one which induces the birrational morphism.",['algebraic-geometry']
396577,History of Hindman's Theorem,"At this blogpost about Hindman's Theorem , I read the following lines: 'I love the odd history so allow me to digress... etc. ' This sentence made me curious to know what this history looks like. Someone told me Hindman himself has written a paper about it, but I could not find it. So, can anyone tell me about this history, or recommend some books / papers?","['ramsey-theory', 'filters', 'math-history', 'combinatorics']"
396582,Two ramified covers $\Rightarrow$ reducible ramification divisor?,"Let $X,X',X''$ be algebraic varieties and let $X''\to X'$ and $X'\to X$ be two ramified covers. Is the ramification divisor of the composition $X''\to X'\to X$ reducible?",['algebraic-geometry']
396601,"How many functions $ f: \{1, 2, 3, \dots, 10\} \to \{0,1\}$ satisfy $f(1) + f(2) + \dots + f(10) = 2$?","How many functions $ f: \{1, 2, 3, \dots, 10\} \to \{0,1\}$ have this property: $$f(1) + f(2) + \dots + f(10) = 2.$$ I understand just $2$ functions can be $1$, the rest have to be $0$, in total there are $2^{10}$ functions, but how can I find out how many of them have this property?","['algebra-precalculus', 'functions', 'combinatorics']"
396608,Does $X\times S^1\cong Y\times S^1$ imply that $X\times\mathbb R\cong Y\times\mathbb R$?,"This question came up in a recent video series of lectures by Mike Freedman available through Max Planck Institut's website. He proves the ""difficult"" converse direction, that $X\times \mathbb R\cong Y\times \mathbb R$  implies $X\times S^1\cong Y\times S^1$ using a subtle ""push-pull"" argument, when $X$ and $Y$ are compact. He goes on to make the remark that the converse holds in the simply connected case by taking universal covers, but it is not obvious in general and there may even be a counterexample. So my question is whether anyone has any ideas about this question. Maybe someone can spot a counterexample in the non-simply connected case? Edit: Here's a link to the video series . If I recall correctly, the push-pull argument is in the first video.",['general-topology']
396622,looking for reference or nice proof of trig lemma,"Math people: I am looking for a reference or a nice proof of the following fact.  I have proven it myself, but my proof is messy: let $\theta \in (0,1]$ and $\alpha \in (0, \frac{1}{2}\theta^2]$.  Let $P$ and $S$ be two points on the unit circle $x^2 + y^2 = 1$ such that the arc length of ${\stackrel{\frown}{PS}}$ is $\theta$.  Let $Q$ and $R$ be on ${\stackrel{\frown}{PS}}$ with $Q$ between $P$ and $R$, such that ${\stackrel{\frown}{PQ}}$ and ${\stackrel{\frown}{RS}}$ have equal arc length, and the arc length of ${\stackrel{\frown}{QR}}$ is $\alpha$.  Let $T$ and $U$ be the points on the chord ${\overline {PS}}$ such that $\Delta PQT$ and $\Delta SRU$ are right triangles. See the picture below. Obviously I would not include a hand-drawn picture in a paper I would submit to a journal. I have proven that the the triangles have disjoint closures. I proved it the following way: I assumed $P = (\cos(\frac{1}{2}\theta),\sin(\frac{1}{2}\theta))$, $S = (\cos(\frac{1}{2}\theta),-\sin(\frac{1}{2}\theta))$.  Clearly it is good enough to take $\alpha = \frac{1}{2}\theta^2$.  Then $Q = (\cos(\frac{1}{4}\theta^2),\sin(\frac{1}{4}\theta^2))$.  I defined $V = (\cos(\frac{1}{2}\theta, 0)$.  It suffices to show $\angle VQP$ is obtuse.  I showed ${\vec{QP}} \cdot {\vec{QV}} < 0$.  This required a long calculation that was not pretty.  I am looking for a reference of this fact or a more elegant proof, perhaps a geometric proof.","['inequality', 'trigonometry', 'calculus', 'reference-request']"
396625,Polar coordinations - problem with r and $\theta$,"let's take a look on Archimedean spiral. 
the polar equation is $r = \theta$. click here to look. but $\tan (\theta) = y/x$ and $r = \sqrt{x^2+y^2}$, so $r = \theta \rightarrow \tan(\sqrt{x^2+y^2}) = y/x$. click here to look. but wolfram alpha shows that the equations are different. where is my mistake? or this is error on wolfram alpha? thank you.","['trigonometry', 'polar-coordinates', 'wolfram-alpha']"
396629,"Bilinear forms on C[0,1]","Let $C[0,1]$ be the vector space of real-valued continuous functions on $[0,1]$. Then
$$B(f,g) = \int_0^1{f(x)g(x)\, dx}$$
is a bilinear form on $C[0,1]$. More generally, if $k:[0,1]^2\rightarrow \mathbb{R}$ is continuous, then
$$B_k(f,g) = \int_{[0,1]^2}{f(x)g(y)k(x,y)\,dx\, dy}$$
is a bilinear form. In Keith Conrad's notes on bilinear forms, he asks if there is a $k$ corresponding to the first example. My intuition first suggested the characteristic function on the diagonal, but that is not continuous. Surely it must be something like this, but I can't think of what it should be. There is another question where he asks us to find conditions on $k$ under which $B_k$ will be a symmetric bilinear form. I sketched a proof that its both necessary and sufficient for $k(x,y) = k(y,x)$, but my proof is not pretty. Is there a natural proof?","['bilinear-form', 'multilinear-algebra', 'real-analysis']"
396636,does a matrix like this exist?,"Question: Does a matrix $A \in M_{3 \times 3}(F)$ exist s.t. $A^4=
\begin{bmatrix} 0&0&1\\0&0&0\\0&0&0\end{bmatrix}$ What I thought: I think it doesn't. How do you start a proof of such a thing (prefer hints at first).
Thx",['linear-algebra']
396654,"Function such that $f(x) = -1$ for $x < 0,$ and $f(x)=1$ for $x > 0$?","What is a function to returns $-1$ if number is negative, $1$ if positive, and zero if number is equal to 0? for example: $$
f(-8) = -1
$$
$$
f(8) = 1
$$
$$
f(0) = 0
$$ for $$x < 0$$ maybe? $$ f(x) = (-x-(-x-1))\cdot-1 $$","['algebra-precalculus', 'functions']"
396658,"If $\lim\limits_{x \to \pm\infty}f(x)=0$, does it imply that $\lim\limits_{x \to \pm\infty}f'(x)=0$?","Suppose $f:\mathbb{R} \rightarrow \mathbb{R}$ is everywhere differentiable and $\lim_{x \to \infty}f(x)=\lim_{x \to -\infty}f(x)=0$ , there exists $c \in \mathbb{R}$ such that $f(c) \gt 0$ . Can we say anything about $\lim_{x \to \infty}f'(x)$ and $\lim_{x \to -\infty}f'(x)$ ? I am tempted to say that $\lim_{x \to \infty}f'(x)$ = $\lim_{x \to -\infty}f'(x)=0$ . I started with the following, but I'm not sure this is the correct approach, $$\lim_{x \to \infty}f'(x)= \lim_{x \to \infty}\lim_{h \to 0}\frac{f(x+h)-f(x)}{h}.$$",['real-analysis']
396660,Topological manifolds (dimension),"I am taking an introductory course to topology and the professor defined a topological manifold of dimension $n$ if it is hausdorff and if for every point $x$ there exists an open set $U$ around $x$ such that $U$ is homeomorphic to $\mathbb{R}^n$. My question is: By the way she defined it, one could have (apriori) a topological space $X$ being a manifold of dimensions $n$ and $m$? Meaning I could find open sets $U$ and $V$ around every $x$ and $U$ is homeomorphic to $\mathbb{R}^n$ and $V$ is homeomorphic to $\mathbb{R}^m$, and this would make the notion of dimension not well defined. My guess is that since it is called ""topological manifold of dimension $n$"" what I described probably cant happen, but I dont see why not.","['general-topology', 'dimension-theory-analysis', 'manifolds']"
396668,Evaluating $\int_0^{\infty}e^{-\alpha x^2 \cos \beta} \cos(\alpha x^2 \sin \beta) dx$,"Q: Suppose $\alpha>0$ and $|\beta|<\pi/2$, show that
  \begin{align*}
\textbf{(1)} \; \int_0^{\infty}e^{-\alpha x^2 \cos \beta} \cos(\alpha x^2 \sin \beta) dx &= \frac 1 2 \sqrt{\pi/\alpha}\cos(\beta/2)\\ 
\textbf{(2)} \; \int_0^{\infty}e^{-\alpha x^2 \cos \beta} \sin(\alpha x^2 \sin \beta) dx &= \frac 1 2 \sqrt{\pi/\alpha}\sin(\beta/2)
\end{align*} How can I integrate the above with the method of contour ? The integral can be changed into $\displaystyle \int_0^{\infty}e^{-\alpha x^2 \cos \beta} e^{i(\alpha x^2 \sin \beta) }dx = \int_0^{\infty} e^{x^2\alpha e^{i (\pi - \beta)}}dx$. This is similar to $\displaystyle \int_0^{\infty} e^{-x^2}dx$ which has been discussed here except that it has complex coefficients. How do I modify it?","['complex-analysis', 'contour-integration']"
396669,"How many functions $f:\{1,2,3,4\}→\{1,2,3,4\}$ satisfy $f(1)=f(4)$?","I just need a hint or a way to think a about this problem: $f(1)$ can be $1, 2, 3, 4$ and $f(4)$ can be $1,2,3,4.$","['algebra-precalculus', 'functions', 'combinatorics']"
396689,Two terms that I want to understand: weakest topology and jointly continuous (in the following context).,"I was reading an article online, please help me to understand the following lines (in bold letters). - 
Topological structure:
If (V, ‖·‖) is a normed vector space, the norm ‖·‖ induces a metric and therefore a topology on V.the distance between two vectors u and v is given by ‖u−v‖. This topology is precisely the weakest topology which makes ‖·‖ continuous and which is compatible with the linear structure of V in the following sense: 1.The vector addition + : V × V → V is jointly continuous with respect to this topology. This follows directly from the triangle inequality. 2.The scalar multiplication · : K × V → V, where K is the underlying scalar field of V, is jointly continuous. This follows from the triangle inequality and homogeneity of the norm. Please explain me the Weak topology and how does it makes norm ‖·‖ continuous. what does it mean by ""Addition + : V × V → V is jointly continuous with respect to this topology"" Thank you so much in advance.","['general-topology', 'normed-spaces', 'linear-algebra', 'functional-analysis']"
396705,Vector Field Generating Variation Along Curve,"I'm learning a proof of the fact that length extremising curves are geodesics of the Levi-Civita connection, and have found something I don't understand. The argument states the following. Suppose $\gamma$ is an arbitrary curve in a manifold $M$ and $N$ is an arbitrary vector field along $\gamma$ which vanishes at the endpoints. Then there must exist a variation $\tilde{\gamma}$ of $\gamma$ such that $\gamma'$ and $N$ are the pushforwards of the coordinate vector fields on the domain of the variation. I can't see how this is true, because it would immediately imply that all vector fields commute (I think!). Am I missing something or is it false? If it's wrong, does anyone know how to prove that statement that length extremizing implies geodesic. The relevant lectures notes from which I've taken this argument are here , page 32. Thanks in advance!","['multivariable-calculus', 'calculus-of-variations', 'differential-geometry', 'manifolds', 'geodesic']"
396706,"Closed form for $\int_0^\infty\frac{\log\left(1+\frac{\pi^2}{4\,x}\right)}{e^{\sqrt{x}}-1}\mathrm dx$","I encountered this integral in my calculations: $$\int_0^\infty\frac{\log\left(1+\frac{\pi^2}{4\,x}\right)}{e^{\sqrt{x}}-1}\mathrm dx=2\int_0^\infty\frac{x\log\left(1+\frac{\pi^2}{4\,x^2}\right)}{e^x-1}\mathrm dx=6.041880938342236884944983747836284...,$$ but could not find a closed-form representation for it. I tried to replace a constant factor $\frac{\pi^2}4$ with a parameter and take a derivative, that made the integral look simpler, but I still was not successful in solving it. I also tried to find possible closed forms using Inverse Symbolic Calculator and WolframAlpha but they did not find anything. Could you please help me to find a closed form (even using non-elementary special functions), if it exists?","['closed-form', 'calculus', 'integration', 'definite-integrals', 'logarithms']"
396707,"If $f(x)\to 0$ as $x\to\infty$ and $f''$ is bounded, show that $f'(x)\to0$ as $x\to\infty$","Let $f\colon\mathbb R\to\mathbb R$ be twice differentiable with $f(x)\to 0$ as $x\to\infty$ and $f''$ bounded.
Show that $f'(x)\to0$ as $x\to\infty$.
(This is inspired by a comment/answer to a different question)",['real-analysis']
396711,What is $\int x^re^xdx$?,"Is there any simple way to get integral of $e^{x}x^{r}, r \in \mathbb{R}$? Basically I want to solve this: $$\displaystyle \int \frac{e^t(4t^2+1)}{2t \sqrt{t}}dt$$ so I will appreciate any help in both of the above problems.","['calculus', 'integration']"
396714,"Continuous function differentiable on $[0,1]\setminus\mathbb{Q}$, but nondifferentiable on all of $\mathbb{Q}\cap[0,1]$?","I'm trying to work out an example of a continuous function which is differentiable at all irrationals but nondifferentiable at all rationals in $[0,1]$. Since $\mathbb{Q}$ is countable, list it as $\mathbb{Q}=\{q_0,q_1,q_2,\dots\}$. Define a map $g\colon\mathbb{Q}\to\mathbb{R}$ by $q_n\mapsto 2^{-n}$. Since $\sum_{n=0}^\infty\frac{1}{2^n}$ is absolutely convergent, $\sum_{r\in\mathbb{Q}}g(r)$ is too. Then define $f\colon [0,1]\to\mathbb{R}$ by
$$
f(x)=\sum_{r\in\mathbb{Q};r<x}g(r)
$$
which is well defined. It is not hard to see that $f$ is monotonically increasing on $[0,1]$, and thus Riemann integrable on $[0,1]$. I've been able to show that $f$ is continuous at all irrationals, but discontinuous at all rationals. I can add this if needed. By the fundamental theorem of calculus, the function $F\colon [0,1]\to\mathbb{R}$ defined by
$$
F(x)=\int_0^x f
$$is continuous, and differentiable at all irrationals since $f$ is continuous at all irrationals. The example on page 7 of these notes, Math 131AH Winter 2003, Prof. Terry Tao remarks that $F$ is actually nondifferentiable at every rational, by use of the mean value theorem. I'm confused because I don't see how I can apply the mean value theorem. I don't think I'm intended to apply it to $f$, since $f$ is not differentiable on any nondegenerate interval. Also, although $F$ is continuous, I don't think I can apply the mean value theorem to it without assuming that $F$ is differentiable on all the rationals in some interval, which seems like a large assumption. How can the mean value theorem (if necessary), show that $F$ is discontinuous at all rationals? Thanks.","['real-analysis', 'analysis']"
396724,Rational Expression Question. (Word problem),"Joe got a mark of $\dfrac{44}{50}$ on one test and $\dfrac{32}{x}$ on another test. If the average mark on the two tests was 80%, what value was the second test out of? My revised attempt: Still confused, is this correct? Seems odd that the answer I am getting is a repeating decimal: $$\dfrac 12 \left(\dfrac{44}{50}+\dfrac{32}{x}\right)=.8$$ $$\dfrac{44}{50}+\dfrac{32}{x}=\dfrac{.8}{.5}$$ $$\dfrac{32}{x}=\bigg(\dfrac{8}{5}-\dfrac{44}{50}\bigg)x$$ $$32=\dfrac{8}{5}x-\dfrac{44}{50}x$$ $$50\bigg(32=\dfrac{8}{5}x-\dfrac{44}{50}x\bigg)$$ $$1600=80x-44x$$ $$\dfrac{1600}{36} = \dfrac{36x}{36}$$ $$\boxed{x=44.4}$$",['algebra-precalculus']
396729,Property of the trace of matrices,"Let $A(x,t),B(x,t)$ be matrix-valued functions that are independent of $\xi=x-t$ and satisfy $$A_t-B_x+AB-BA=0$$ where $X_q\equiv \frac{\partial X}{\partial q}$. Why does it then follow that  $$\frac{d }{d \eta}\textrm{Trace}[(A-B)^n]=0$$ where $n\in \mathbb N$ and $\eta=x+t$? Is there a neat way to see that this is true?","['trace', 'matrices', 'linear-algebra', 'partial-differential-equations']"
396730,Integral over null set is zero but integral of Dirac delta function is 1,"We know integral of any function over a null set is zero.
But for Dirac delta function ($\delta=+\infty$ iff $x=0$ otherwise $\delta=0$)
$$
\int_{-\infty}^{+\infty}\delta =\int_0^0\delta =1.
$$
Is it a contradiction?","['measure-theory', 'real-analysis']"
396745,derive using the chain rule,"Given the polinomyal $f(x)=\frac{x^3}{(4-x^2)^3}$ find $f'(x)$ So, If I try to derive this, first I must to apply the chain rule in the denominator and then derive of the division (...) $$f'(x)=\frac{x^3}{3(4-x^2)^2(-2)} = \frac{x^3}{-6(4-x^2)^2}$$ (...)? Or there is another way to do this?","['calculus', 'derivatives']"
396761,A numerical coincidence with continued fractions,"My brother built a garage that measures 45 feet by 30 feet.  To make sure the right angles were accurate, he measured the two diagonals of the rectangle to see that they were equal.  In  inches, \begin{align}
& \sqrt{540^2+360^2} \approx 648.999229548\text{ inches} \\[6pt]
= {} & 54\text{ feet}+1\text{ inch} - \text{less than $0.001$ inches}.
\end{align} It's a bit odd to come within a thousandth of an inch when rounding to the nearest inch, but there's more: $$
\sqrt{540^2+360^2} = 649 - \cfrac{1}{1298+\cfrac{1}{24073+\cdots}}.
$$ One part in twenty-four thousand?? Did I just happen to be there when someone rolled boxcars two dozen times in a row, or is there more to be said? (Maybe I should add that $540^2+360^2 = 649^2-1$ .) PS: $$
\sqrt{540^2+360^2} = 648 + \cfrac{1}{1+\cfrac{1}{1297+\cfrac{1}{25700+\cdots}}} \\
\text{(This part is mistaken; see below.)}
$$ Later edit: A calculator gave me the results above repeatedly; later another calculator disagreed, just as persistently, and I figured out what the truth is.","['euclidean-geometry', 'continued-fractions', 'number-theory']"
396762,"Adjoint operator, a condition for closed range","Let $X$ and $Y$ be two Hilbert spaces and $A\in\mathcal{L}(X,Y)$. Suppose that there's $\beta > 0$ such that
$$\inf_{z\ \in\ \text{Ker}(A)}\|x-z\|\ \leq\ \beta\|A(x)\|,\quad \forall\ x\in X.$$
Show that, $\text{R}(A) = \text{Im}(A)$ is closed. Please, somebody can help with this problem? I tried to prove that $\text{R}(A) = \text{Ker}(A^*)^{\perp}$ in order to show that $\text{R}(A)$ is closed, but I really don't know how I can use the fact of $\text{dist}(x, \text{Ker}(A)) \leq \beta\|A(x)\|$. Please, I need some hints. Thanks in advance.","['operator-theory', 'functional-analysis']"
396764,What is $2 - 1 + 1$? [duplicate],"This question already has answers here : Order of operations (BODMAS) (6 answers) Closed 11 years ago . $2-1+1$ ; a fairly straightforward question, but I (well, not me, but Henry Reich ) found something strange. Most people would evaluate it as $2+(-1)+1 = 2$ ; however, this goes against the famed, and fairly standard B.E.D.M.A.S./P.E.D.M.A.S., which states that addition goes first, and then subtraction. If this is the case, then the answer is $2 - (1 + 1) = 2-2 =0$ . Which is the correct answer, and why is the conventional way (B.E.D.M.A.S./P.E.D.M.A.S.) so ambiguous?","['arithmetic', 'algebra-precalculus', 'convention']"
396803,Kernel of the evaluation map on a power series ring,"Let $R$ be a commutative ring with unity and $r \in R$ a nilpotent element. Is it true that if $f \in R[[\epsilon]]$ satisfies $f(r) = 0$, then $(\epsilon - r) | f$ in $R[[\epsilon]]$? I tried solving for the coefficients of $f/(\epsilon - r)$ inductively and got myself confused.","['power-series', 'divisibility', 'abstract-algebra']"
396825,Are there more embeddings $U(2) \hookrightarrow SO(4)$?,"It is easy to prove that $SO(4)$ acts transitively and freely on $S^2$ with fiber $U(2)$. Therefore, we can identify each point of $S^2$ with a particular embedding $U(2) \hookrightarrow SO(4)$. My question is ¿are there more embeddings $U(2) \hookrightarrow SO(4)$ or are they completely parametrized by $S^2$?","['general-topology', 'riemannian-geometry', 'lie-groups']"
396826,mixture problem,"From Stewart, Precalculus, $5$th ed, p.$71$, q.$55$ The radiator in a car is filled with a solution of $60\%$ antifreeze and $40\%$ water. The manufacturer of the antifreeze suggests that, for summer driving, optimal cooling of the engine is obtained with only $50\%$ antifreeze. If the capacity of the radiator is $ 3.6$L, how much coolant should be drained and replaced with water to reduce the antifreeze concentration to the recommended level? I don't think there is a need to set up a model, since the currently concentration of antifreeze is at $60\%$ and desired contraction is $50\%$, the difference is $10\%$ of the total capacity of the radiator. $10\%\times3.6L = 0.36L$ $0.36$L to be drained from the original $60\%$ concentration of $\dfrac{2.16}{3.6}L$ and replaced with water would give $50\%$ concentration at $\dfrac{1.8}{3.6}L$ The answer at the back of the book says $0.6$L to be drained. I don't understand why this is so, if $0.6$L is drained the new concentration would be $43.333\%$.",['algebra-precalculus']
396828,Find: The expected number of urns that are empty,"A total of $n$ balls, numbered $1$ through $n$, are put into $n$ urns, also numbered $1$ through $n$ in such a way that ball $i$ is equally likely to go into any of the
urns $1, 2, . . . , i$. Find the expected number of urns that are empty. Can somebody help me? I don´t understand. Thanks very much.","['balls-in-bins', 'probability']"
396834,Linear polynomials of finite fields,"I have a final tomorrow, and I was looking over some exercises in my textbook. However, I can't seem to work this problem out. Let $F$ be a field of $p^n$ elements and let $\alpha \in F^*$, where $F^*=F-\{0\}$.
Show $(x- \alpha)(x- \alpha^p)(x- \alpha^{p^2})\cdots(x- \alpha^{p^{n-1}}) \in \mathbb{Z}_p[x]$. Also, my text has some weird notation, $\mathbb{Z}_p$ is shorthand for $\mathbb{Z}/p\mathbb{Z}$. It hints that I need to show both $\alpha+\alpha^{p}+\alpha^{p^2}+\cdots+\alpha^{p^{n-1}}\in\mathbb{Z}_p$ and $\alpha\alpha^{p}\alpha^{p^2}\cdots\alpha^{p^{n-1}}\in\mathbb{Z}_p$, but I'm having trouble with it. Help would be much appreciated.","['finite-fields', 'number-theory']"
396841,Finding a PDF from a function,"I have a function $y = f(x),\ x\in\mathbb{R}$ (assume $f(x)= \sin(x)/x$ if you need an example). How can I find the probability distribution function (PDF) of $y$, assuming $x\sim U(\mathbb{R})$ (uniformly distributed over the reals)? I'm a little rusty on whether the end points are problematic in defining it over the reals, so if that's an issue, let's make it simpler and say that $x\in\mathcal{D}\subset\mathbb{R}$ and $x\sim U(\mathcal{D})$ where $\mathcal{D}$ is an interval. Do I explicitly need to know the inverse $x = f^{-1}(y)$ in order to be able to compute it?","['probability', 'functions']"
396842,"For the following monic polynomial,$f$ of even degree how to prove that that $lim_{|x|\to\infty }(\sqrt {f(x)}-g(x))=0$","For any monic polynomial $f \in \mathbb {Q[x]}$ of even degree,how to prove, there exists polynomial $g \in \mathbb {Q[x]}$ such that $lim_{|x|\to\infty }(\sqrt {f(x)}-g(x))=0$","['polynomials', 'algebra-precalculus', 'functions', 'limits']"
396848,Let $f :\mathbb{R}→ \mathbb{R}$ be a function such that $f^2$ and $f^3$ are differentiable. Is $f$ differentiable?,"Let $f :\mathbb{R}→ \mathbb{R}$ be a function such that $f^2$ and $f^3$ are differentiable. Is $f$ differentiable? Similarly, let $f :\mathbb{C}→ \mathbb{C}$ be a function such that $f^2$ and $f^3$ are analytic. Is $f$ analytic?","['functions', 'complex-analysis', 'derivatives', 'real-analysis']"
396854,Does every category have a functor?,"Is there any one (or more) categories that doesn't have a functor? Functors go between categories, so is there any category that only has an identity functor but no other functor that maps it to another category?","['category-theory', 'abstract-algebra']"
396885,Find the volume of the region bounded by $z = x^2 + y^2$ and $z = 10 - x^2 - 2y^2$,So these are two paraboloids. My guess is I would want to find the intersection of these two which would be $2x^2 + 3y^2 = 10$ and construct a triple integral based on its projection. No idea how to do this but the answer comes out to be $\dfrac{50\pi}{\sqrt{6}}$.,['multivariable-calculus']
396892,Probability distribution for a digit of a number,"If someone choose a digit $\alpha$ and a digit $\beta$ independently. Each one can be in $0,1, ...,9$. So $\mu = \alpha \beta$ (e.g. if $\alpha = 5$ and $\beta = 3$ then $\mu =53$). And I observe a sample: $\{10,12,45,50\}$. How can I attribute a likelihood distribution and a prior distribution to $\alpha$ and $\beta$ to test the hypothesis that $\alpha < \beta$?
The sample for μ is {10,12,45,50},for α is {1,1,4,5} and for β is {0,2,5,0}. μ can any number between (0;99), α and β can be any number between (0;9). The person choosed only one time α and β, after this μ is fixed for a number of balls in an urn that can have (0;99) balls depending on the one's choice. Only after this, I observe the sample, with μ fixed. My estimative will depends on the sample that I observed. Here is my answer: $p(\alpha) = \frac{1}{10}$ For estimate $\alpha$, the most important digit of $\mu$ is the left one. So I call $a_{i}$ the left digit of the $n_{i}$ observation. And I call $a = max(a_{i}), i=1,...,n$. I don't know what is the pdf of $a = max(a_{i})$, but I know its cdf: $p(a \leq a_{i} |\alpha) = p(a_{1} \leq a |\alpha)p(a_{2} \leq |\alpha)...p(a_{n} \leq a |\alpha) = (\frac{max(a_{i})}{\alpha})^n = F(a|\alpha) $ To find the pdf: $\frac{dF(a|\alpha)}{da} = \frac{n*max(a_{i})^{n-1}}{\alpha^{n}}$ So the posterior of $\alpha$: $p(\alpha | a) \propto 1 \times \frac{n*max(a_{i})^{n-1}}{\alpha^{n}}$ The same for $\beta$: $p(\beta| b) \propto 1 \times \frac{n*max(b_{i})^{n-1}}{\beta^{n}}$ My only problem is how to test the hypothesis that $\alpha < \beta$? The Bayes Fator will be: $BF = \frac{\frac{n*max(a_{i})^{n-1}}{\alpha^{n}}}{\frac{n*max(b_{i})^{n-1}}{\beta^{n}}} = \frac{\alpha^{n}}{\beta^{n}} \times \frac{n*max(a_{i})^{n-1}}{n*max(b_{i})^{n-1}} $ That still depends on $\alpha$ and $\beta$, unknown","['statistics', 'bayesian', 'probability', 'statistical-inference']"
396893,"Dominant morphism, equal dimensions: always finite?","Let $f:X\to Y$ be a dominant morphism of varieties (integral separated schemes of finite type over an algebraically closed field) such that dim $X$ = dim $Y$. Question: must f be finite? It seems that f must have finite fibers by looking at dimensions.  So perhaps it is the same question to ask if $f$ must be proper, because finite fibers + proper = finite.  I am not familiar enough with standard non-examples of properness to have a good intuition on this. Finally, if it makes any difference to assume X and Y are quasi-projective, please do so. Edit: After Steve's answer to the original question, I would like to ask the same question for a self-morphism $f:X\to X$.","['algebraic-geometry', 'schemes']"
396912,The divergence of the series of reciprocals of primes (proof check):,"I want to check my attempt at a proof for the divergence of $$\sum_{n=1}^{\infty} \frac{1}{p_n} \tag{ $\star$ }.$$ We begin with assuming that $(\star)$ converges. If $(\star)$ converges, there is an integer $a$ so that, $$\sum_{j=a+1}^{\infty}\frac{1}{p_j} \lt \frac{1}{b}$$ where $b>1$ . Note that given any $b$ there exists an $a$ that satisfies the above inequality. Now, we let $M = p_1\cdot\cdot\cdot p_a$ and consider the number $1+ nM$ for $n = 1,2,\dots$ Any factors of $1+nM$ are $p_i$ for $i \geq a+1,a+2,\dots$ Hence, we can write for each $g \geq 1$ : $$\sum_{n=1}^{g} \frac{1}{1+nM} \leq \sum_{x=1}^{\infty}(\sum_{j=a+1}^{\infty}\frac{1}{p_j})^x$$ But on the right hand side, we have a geometric series: $$\sum_{n=1}^{g} \frac{1}{1+nM} \leq \sum_{x=1}^{\infty}(\frac{1}{b})^x$$ Since the geometric series converges, it means that $\sum_{n=1}^{\infty} \frac{1}{1+nM}$ converges and is bounded above. But that is a contradiction because if we do the integral test on $\sum_{n=1}^{\infty} \frac{1}{1+nM}$ , it diverges. Therefore, $(\star)$ diverges.","['prime-numbers', 'divergent-series', 'number-theory']"
396914,Right triangles with integer sides,"Most of you know these triples: $3:	4	:5$ $5:	12	:13$ $8:	15	:17$ $7:	24	:25$ $9:	40	:41$ More generally we can construct such triangles such as 
$$2x:x^2-1:x^2+1$$ My question is why one of the sides seems to be always prime? (When there is no common divisor)","['prime-numbers', 'geometry', 'number-theory']"
396915,How to evaluate $\sqrt[3]{a + ib} + \sqrt[3]{a - ib}$?,"The answer to a question I asked earlier today hinged on the fact that $$\sqrt[3]{35 + 18i\sqrt{3}} + \sqrt[3]{35 - 18i\sqrt{3}} = 7$$ How does one evaluate such expressions? And, is there a way to evaluate  the general expression $$\sqrt[3]{a + ib} + \sqrt[3]{a - ib}$$","['radicals', 'nested-radicals', 'algebra-precalculus']"
396925,$\sum\limits_{\text{prime }p} 2^{-p}$ is an irrational number,I need help to prove the following result. $\displaystyle\sum_{\text{prime }p} 2^{-p}$ is an irrational number.,"['prime-numbers', 'sequences-and-series', 'number-theory']"
396935,If ${ x }^{ 4 }+{ y }^{ 2 }=1$ then $x$ and $y$ can be both rational numbers?,"Can you give two numbers $x,y\in\mathbb{Q}$ such that  ${ x }^{ 4 }+{ y }^{ 2 }=1$? I don't know if exists or not. I derived this equation questioning that if $\sin { \alpha  } ={ x }^{ 2 }$ for $x\in \mathbb{Q}$ then for which $\alpha$, $\cos{ \alpha  }=y$ and $y\in \mathbb{Q}$? Edit: $x,y\neq0$","['trigonometry', 'algebra-precalculus']"
396943,Proving one function is greater than another,"How can I prove $f(x)$ $>$ $g(x)$ for all $x > 0$ given $f(x) = (x+1)^{2}$ and $g(x) = 4qx$ where $q$ is a constant in $(0, 1)$? My approach was to show that $(x+1)^2 > 4qx$ for the interval endpoints, e.g. $q=0$ and $q=1$. E.g. $(x+1)^2 \geq 4x$ for all $x$ and $(x+1)^2 > 0$ for all $x$. However, $q \neq 0,1$ so $f(x) > g(x)$ for all $x$. However, I'm looking for something more mathematically rigorous. Any suggestions?",['calculus']
396949,Question about comultiplication,"I have a question about comultiplication for coalgebras: Suppose $C$ is a coalgebra over the field $k$. How does one show that the comultiplication map $\Delta:C\to C\otimes C$ is a coalgebra map if and only if $C$ is cocommutative? The main problem that I encounter is that when I tried to do it by definition, I was struggling to find a relation between $c_{(1)(2)}$ and $c_{(2)(1)}$. In that case, is there any other way for which I could tackle this question?","['hopf-algebras', 'coalgebras', 'abstract-algebra']"
396955,Application of Urysohn's lemma,"I am working on the following hw problem: If we have that $X$ is a compact Hausdorff space, with $\{U_\alpha\}_{\alpha\in A}$, then we can find a finite number of continous functions $f_1,...,f_k$, with $f_i:X\mapsto [0,1]$ such that $f_1(x)+...+f_k(x)=1$ for all $x$, and for each $i$ there exists a $\alpha_i$ such that $\overline{f_i^{-1}((0,1])}\subset U_{\alpha_i}$. So this are my thoughts at the moment. Since $X$ is Hausdorff and compact it is normal, so we know that Urysohn's lemma applies. Meaning, if I have any two disjoint sets I can find a continous function that is $0$ is one of the sets and $1$ in the other one. My intuition is telling me to use compactness and find $U_{\alpha_1},..., U_{\alpha_k}$ that cover $X$, and then by the last requirement of the problem we would need $f_i(x)=0$ if $x\notin U_{\alpha_i}$. The problem is very clear if I can write my space $X$ as the disjoint union of finite closed sets cause then I could just apply Urysohns and get my functions very easily, but I do not see how to apply this lemma using the open cover given. Any hints would be greatly appreciated.",['general-topology']
396961,Bounded sequence in Hilbert space contains weak convergent subsequence,"In Hilbert space $H$, $\{x_n\}$ is a bounded sequence then it has a weak convergent subsequence. Is there any short proof? Thanks a lot.","['hilbert-spaces', 'sequences-and-series', 'functional-analysis', 'weak-convergence']"
396967,$-1$ is a quadratic residue modulo $p$ if and only if $p\equiv 1\pmod{4}$,I came across this problem and I believe Lagrange's theorem is the key to its solution.  The question is: Let $p$ be an odd prime. Prove that there is some integer $x$ such that $x^2 \equiv −1 \pmod p$ if and only if $p \equiv 1 \pmod 4$. I appreciate any help.  Thanks.,"['elementary-number-theory', 'quadratic-residues']"
396971,Regular $T_2$ space which is not completely regular.,"Theorem 10. of 
Pontryagin's Topological Groups says that: Every Hausdorff topological group is completely regular. But is there exists a Regular $T_2$ space which is not completely regular?","['general-topology', 'separation-axioms', 'examples-counterexamples']"
396982,Fisher information of a Binomial distribution,"The Fisher information is defined as $\mathbb{E}\Bigg( \frac{d \log f(p,x)}{dp} \Bigg)^2$, where $f(p,x)={{n}\choose{x}} p^x (1-p)^{n-x}$ for a Binomial distribution. The derivative of the log-likelihood function is $L'(p,x) = \frac{x}{p} - \frac{n-x}{1-p}$. Now, to get the Fisher infomation we need to square it and take the expectation. First, we know, that $\mathbb{E}X^2$ for $X \sim Bin(n,p)$ is $ n^2p^2 +np(1-p)$. Let's first focus on on the content of the paratheses. $$
\begin{align}
\Bigg( \frac{x}{p} - \frac{n-x}{1-p} \Bigg)^2&=\frac{x^2-2nxp+n^2p^2}{p^2(1-p)^2}
\end{align}
$$ No mistake so far (I hope!). \begin{align}
\mathbb{E}\Bigg( \frac{x}{p} - \frac{n-x}{1-p} \Bigg)^2 &= \sum_{x=0}^n \Bigg( \frac{x}{p} - \frac{n-x}{1-p} \Bigg)^2 {{n}\choose{x}} p^x (1-p)^{n-x} \\
&=\sum_{x=0}^n \Bigg( \frac{x^2-2nxp+n^2p^2}{p^2(1-p)^2} \Bigg) {{n}\choose{x}} p^x (1-p)^{n-x} \\
&= \frac{n^2p^2+np(1-p)-2n^2p^2+n^2p^2}{p^2(1-p)^2}\\
&=\frac{n}{p(1-p)}
\end{align} The result should be $\frac{1}{p(1-p)} $ but I've been staring at this for a few hours incapable of getting a different answer. Please let me know whether I'm making any arithmetic mistakes.","['statistics', 'probability-distributions', 'probability-theory']"
396988,Group actions and associated bundles,"Let $P$ be a principal $G$-bundle over $B$, and let $G$ act on some space $F$ (feel free to work in your favorite category of spaces, if this helps). Then $\text{Aut}{P}$ (aka the group of gauge transformations of $P$) acts on the space of sections of the associated bundle $P\times_G F$ as follows: if $\alpha\in\text{Aut}P$ then for each section $s\colon B\to P\times_G F$ we define $(\alpha\cdot s)(x)=[(\alpha u_x,f)]$ where $s(x)=[(u_x,f)]$ (since $\alpha$ is equivariant, this definition is independent of the representative $(u_x,f)$ for $s(x)$). For brevity let us agree to denote by $a$ the action of $G$ on $F$, and by $A$ the action of $\text{Aut}{P}$ on $P\times_G F$. My questions are the following: what properties of $a$ pass to $A$, in general (i.e. for any $P$)? In particular, what about transitivity? It might be worthwhile to check a few special cases. If $a$ is the trivial action then $A$ is also trivial. If $a$ is the action of $G$ on itself by conjugation then $A$ is (up to some isomorphism) the action of $\text{Aut}P$ on itself by conjugation (where the multiplication is composition of automorphisms). If $a$ is the action of $G$ on itself by multiplication and $P$ is trivial then $A$ is (again up to some isomorphism) the action of $\text{Aut}P$ on itself by composition (here the case $P$ non-trivial implies $P\times_G G\simeq P$ has no section, making the question moot). In all these cases it can be seen that transitivity, freeness, faithfulness pass from $a$ to $A$. EDIT: I split the question in two, so the part dealing with the case $P$ trivial has now become this other question .","['principal-bundles', 'differential-geometry', 'fiber-bundles', 'group-actions', 'gauge-theory']"
