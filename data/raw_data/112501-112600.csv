question_id,title,body,tags
1631442,"Constructing $\mathbb{P^n}$ ""bundle"" with different $n$","Can we find a complex/smooth manifold and map $f\colon X\to\mathbb{C}^3$ such that it is a $\mathbb{P}_\mathbb{C}^m$ bundle over linear subspace $\mathbb{C}^1$ and $\mathbb{P}_\mathbb{C}^n$ bundle over the $\mathbb{C}^3-\mathbb{C}^1$, with $m\neq n$? (I tried the following, but I am not sure if the quotient is a manifold: Consider $Y'=Bl_\mathbb{C^1}\mathbb{C}^n$, denote the exceptional divisor by $E$, we know $E\cong \mathbb{P}_\mathbb{C}^{n-2}\times\mathbb{C}^1$, we remove a closed subset $F$ in $E$ and leave a $\mathbb{C}^{n-2}\times \mathbb{C}^1$ in the exceptional divisor, denote $Y'-F$ by $Y$. Then consider $Y\times\mathbb{C}^k$, let $\mathbb{C}^*$ acts as scalar on each fiber of $f\colon X=Y\times \mathbb{C}^k\to Y\to\mathbb{C}^n$.) (I am trying to find examples to see if $R^2f_*(\mathbb{Z}/d$) is a locally constant sheaf?)","['algebraic-topology', 'differential-geometry', 'complex-geometry']"
1631510,Convolution Integral to Evaluate Fourier Transform,"According to Mathematica with Fourier transform convention $$\widehat{f}(\xi)=(2\pi)^{-1/2}\int_{-\infty}^{\infty}f(x)e^{i\pi x}dx$$ The Fourier transform of the function $f(x):=|x|^{-1/2}e^{-|x|}$ is given by $$\widehat{f}(\xi)=\left(\frac{1}{1+|\xi|^{2}}+\frac{1}{\sqrt{1+|\xi|^{2}}}\right)^{1/2}$$ Mathematica spitted out this result very quickly. This is not a function I recognize as having a well-known Fourier transform, but using Fourier analysis, I believe the Fourier transform should be something like (up to a multiplicative constant) the convolution $$\int_{\mathbb{R}}|y|^{-1/2}\frac{1}{1+|x-y|^{2}}dy$$ But Mathematica does not give a nice expression for this integral. I imagine one can evaluate this integral using contour integration and Cauchy residue theorem, but does anyone see a simpler argument, say using Fourier transforms of known functions?","['convolution', 'complex-analysis', 'contour-integration', 'fourier-analysis']"
1631554,Give a combinatorial proof for a multiset identity,"I'm asked to give a combinatorial proof of the following, $\binom{\binom n2}{2}$ = 3$\binom{n}{4}$ + n$\binom{n-1}{2}$. I know $\binom{n}{k}$ = $\frac{n!}{k!(n-k)!}$ and $(\binom{n}{k}) = \binom{n+k-1}{k}$ but I'm at a loss as to what to do with the $\binom{\binom n2}{2}$ Can someone point me in the right direction as to how to proceed with writing a combinatorial proof for this identity?","['combinatorics', 'multisets']"
1631573,"Why is it that in the parametrization of a line, the point $P_0$ is indicated with brackets and not parenthesis?","For example if I say I want the line perpendicular to the yz plane and through point $P = (4,9,8)$, then I have  $\langle4,9,8\rangle + t\langle1,0,0\rangle ={\langle4+t,9,8\rangle}$ Why when writing the equation, I use brackets around point P? I understand if P were a vector from the origin, but the line is just saying that it passes through point P. I also understand that the parmetrization equation is $r(t) = \vec{OP} + t\vec{v}$, but since I just want the line, then that means I shouldn't need $\vec{OP}$. It makes more sense to me if P were indicated using parenthesis (4,9,8).","['multivariable-calculus', 'linear-algebra']"
1631639,Upper bound on integral: $\int_1^\infty \frac{dx}{\sqrt{x^3-1}} < 4$,"I'm going through Nahin's book Inside Interesting Integrals, and I'm stuck at an early problem, Challenge Problem 1.2: to show that
$$\int_1^\infty \frac{dx}{\sqrt{x^3-1}}$$
exists because there is a finite upper-bound on its value. In particular, show that the integral is less than 4. I've tried various substitutions and also comparisons with similar integrals, but the problem is that any other integral that I can easily compare the above integral to is just as hard to integrate, which doesn't help solve the problem. I also tried just looking at the graph and hoping for insight, but that didn't work either. So how doesone one place an upper bound on the integral?","['integration', 'definite-integrals']"
1631641,In how many ways can 10 (identical) dimes be distributed among five children?,"a. If there are no restrictions? b. Each child gets at least one dime? c. The oldest child gets at least two dimes? For part (a), the textbook gives the answer $14 \choose 10$. Where did the 14 come from? I thought we had 10 dimes to choose from, and 5 children to distribute them to. Why doesn't this come out to $10 \choose 5$? Thanks!","['combinatorics', 'discrete-mathematics']"
1631684,What can we say about the eigenvalues and diagonalization of this $2N\times2N$ matrix $A$?,"There is a $2N\times2N$ matrix $A$, where $N$ is a positive integer, which is of the form: $A=\left(\begin{array}{cc}
B & C\\
-C^{*} & -B^{*}
\end{array}\right),$ where $B$ is a hermitian matrix, and $C$ is a symmetric matrix. What can we say about the eigenvalues of $A$ and it's diagonalization? For example, if $N=1$: $A=\left(\begin{array}{cc}
b & c\\
-c^{*} & -b^{*}
\end{array}\right),$ where $b$ must be a real number, and $c$ has no restriction . The eigenvalues are the same if and only if $\mid c\mid=\mid b\mid$,
and the eigenvalues are equal to $0$. But the matrix $A$ is not
diagonalizable under this condition: $A=b\left(\begin{array}{cc}
1 & e^{i\theta}\\
-e^{-i\theta} & -1
\end{array}\right)=b\left(\begin{array}{cc}
-e^{i\theta} & -e^{i\theta}\\
1 & 0
\end{array}\right)\left(\begin{array}{cc}
0 & 1\\
0 & 0
\end{array}\right)\left(\begin{array}{cc}
0 & 1\\
-e^{-i\theta} & -1
\end{array}\right).$ Is this an accident only for $N=1$ case? Is there some relation like
this for general cases $N>1$?","['matrices', 'diagonalization', 'eigenvalues-eigenvectors', 'linear-algebra']"
1631730,"Understanding the first fundamental form of a surface, how the parametrization doesn't matter.","The following is an excerpt from Pressley's Elementary Differential Geometry on the definition of the first fundamental form. However, there are some parts of this concept that I'm unclear about. It says in the bottom of this excerpt that the coefficients E,F,G and the linear maps du, dv depend on the choice of surface patch for $S$. Here, the patch is $\sigma$. But then, I don't understand how the first fundamental form is an inherent concept of the surface, that is the expression varies under different parametrizations of the same surface and the same point on it. So I can't understand why in the final line, it says ""but the first fundamental form itself depends only on $S$ and $\mathbf{p}$. So to make my question clear, there are theorems that show that the fundamental form determines many properties of different surfaces, such as surfaces that have the same fundamental form are locally isometric etc. But from what I understood from the below definition is that the first fundamental form is an expression, of which is determined by the coefficients $E, F, G$ and the linear maps $du, dv$. But these depend on the parametrization of the surface. So for the same surface and the same point on it, we can have two different expressions,say, $Edu^2+2Fdudv+Gdv^2$ and $\bar{E}d\tilde{u}^2+2\bar{F}d\tilde{u}d\tilde{v}+\bar{G}d\tilde{v}^2$. So the specific choice of parametrization seems to matter, but then how can we use this to talk about inherent properties of different surfaces? I would greatly appreciate any help to understand this.","['differential-forms', 'riemannian-geometry', 'differential-geometry', 'surfaces']"
1631759,Obtain magnitude of square-rooted complex number,"I would like to obtain the magnitude of a complex number of this form: $$z = \frac{1}{\sqrt{\alpha + i \beta}}$$ By a simple test on WolframAlpha it should be $$\left| z \right| = \frac{1}{\sqrt[4]{\alpha^2 + \beta^2}}$$ The fact is that if I try to cancel the root in the denominator I still have a troublesome expression at the numerator: $$z = \frac{\sqrt{\alpha + i \beta}}{\alpha + i \beta}$$ And this alternative way seems unuseful too: $$z = \left( \alpha + i \beta \right)^{-\frac{1}{2}}$$ If WolframAlpha gave the correct result, how to prove it?","['complex-numbers', 'calculus']"
1631765,If $R$ is a integral domain and $S$ is a subring of $R$ then is $S$ an integral domain automatically?,"Here is the problem that I have: Let $R$ be an integral domain and $S$ be a subring of $R$ containing the one of $R$. Prove that $S$ is also an integral domain. Here is my answer: Suppose for a contradiction that $S$ is not an integral domain then there exists $x,y \in S$ s.t $x,y \neq 0$ and $x \cdot y=0$ but since $S$ is a subset of $R$ then $x,y \in R$ and so $R$ is not an integral domain i.e. a contradiction. So $S$ is an integral domain.  $~\square$ My problem is why does the question stipulate that $S$ must contain the one from $R$. Why is this necessary?","['abstract-algebra', 'ring-theory']"
1631799,"Show that the limit $\lim_{(x,y)\to(0,0)}\frac{y+\sin3x-3x}{y+x^5}$ exist/does not exist.","How do I show that this limit exist/does not exist? My assumption is that it does not; however I don't see how I can apply the two-path test to verify this. $$\lim_{(x,y)\to(0,0)}\dfrac{y+\sin3x-3x}{y+x^5} = L,$$ $$\lim_{y\to0}\dfrac{y+\sin(0)-(0)}{y+(0)^5} = 1,$$ But I don't see any second path that simplifies this well; $$\lim_{x\to0}\dfrac{(0)+\sin x-x}{(0)+x^5} = \:?$$","['real-analysis', 'calculus', 'limits']"
1631841,Number of roots of a sequence of a uniformly convergent holomorphic functions implies an upper bound for the number of roots of their limit,"Let $G$ be an open, simply connected region in $\mathbb{C}$. We define a sequence of holomorphic functions $(f_n)_{n \in \mathbb{N}}, f_n: G \to \mathbb{C}$ as almost uniformly convergent iff $(f_n)$ converges uniformly on all compact subsets of $G$. I now want to show that, if $f_n \to f$ for a non-constant function $f: G \to \mathbb{C}$, and none of the $f_n$ has more than $m \in \mathbb{N}$ roots, then $f$ also has not more than $m$ roots. (If we count roots with their multiplicities.) I already know that the limit of an almost uniformly convergent sequence of holomorphic functions is also holomorphic, and (although I don't think that's helpful here), I also know that $(f_n')$ then converges almost uniformly against $f'$. So I only have to show this statement about the roots. I thought about using Rouché's Theorem , mostly because I couldn't think about any other Theorem I know that concretly talks about the actual number of roots of different functions. But I don't know how exactly I can apply Rouché here: what would I choose as the functions $f$ and $g$ that Rouché's Theorem demands, in order to show the inequality in the Theorem?","['complex-analysis', 'uniform-convergence', 'convergence-divergence', 'analysis']"
1631870,"If we have two non-zero-correlated random variables, then why do we say that ""correlation does not imply causation""?","If we have two non-zero correlated random variables then they are dependent. Why then do we have the saying ""Correlation does not imply Causation"". A change in one variable may not cause exactly the same change in another but there is at least some 'causal' link.","['causality', 'statistics', 'causal-diagrams', 'logic']"
1631879,"Increasing function $f(x)$ such that $f(\gcd(x,y))=\gcd(f(x),f(y))$","This problem was largely inspired by this problem here . There were many counterexamples given to the problem, such as a multiplicative function that maps primes to a permutation thereof. However, if $f(x)$ is a strictly increasing function, then what happens then? It appears that if such $f(x)$ existed, then $f(1)=\gcd(f(1),f(y))$. This implies that $f(1)$ would have to divide $f(x)$ for any integer $x$. So one thing I tried doing was setting $g(x)=\frac{f(x)}{f(1)}$. However, I was not able to proceed further. So how does one find all $f(n)$ such that $\gcd(f(x),f(y))=f(\gcd(x,y))$, where $f(x)$ is a strictly increasing function? Note that all the counterexamples given were not increasing. Any help would be appreciated.","['number-theory', 'functional-equations']"
1631885,"Set, n-Tuple, Vector and Matrix — links and differences","I know this question has been asked like 1000 times, however all supplied answers were not really satisfying to me. My question concerns the similarities and differences between these mathematical objects. First, the Set. A set is defined to be the entity of distinct objects (not necessarily numbers). The arrangement of objects is not relevant. We use curly braces to denote sets; commata are used to seperate the objects within the set. Second, the $n$-Tuple. A $n$-tuple is very similar to a set, however the objects need not to be the same and the ordering of objects within the $n$-tuple is important. $n$-Tuples are usually denoted with parentheses and the objects within are seperated with commata as in sets.
Also, it is common to build the set of even numbers for instance like this: $\{2n\mid n\in \mathbb{N}\}$. However, I have never seen something like this with regard to n-tuples. Third, the Vector. A vector is an element of a vector space. However, if I calculate the Cartesian product of, for instance, $\mathbb{R}×\mathbb{R}$ then the objects of $\mathbb{R}^2$ are (column-)vectors which are denoted as tuples. Furthermore, I often see box brackets to denote such vectors and the elements are written in one column (opposed to tuples or sets). Also, commata are not used to separate the objects (however, sometimes I see the elements of row vectors separated by commata).
However, I have never seen such notation when for instance describing elements of $\mathbb{N}\times\mathbb{R}$. Finally, matrices. Matrices are arrays of numbers and clearly linked to vectors as each column/row is a vector. However, I have never seen commata used in combination with matrices. Furthermore, the space of matrices is written as $A^{(m×n)}$. I know what the idea behind this notation is, however, as matrices are linked to vectors I have problems to really understand it. Those concepts are obviously linked, however at certain points there arise crucial differences between them (which also come, I believe, from notational differences between authors and fields of mathematics). I hope my problem is comprehensible and someone can help me and shed light on my issues. Thanks!","['matrices', 'vectors', 'notation', 'elementary-set-theory']"
1631896,"Suppose $e^A = A$, prove that $A$ is diagonalizable","Suppose $e^A = A$, prove  that $A$ is diagonalizable, where A is a matrix. What I have tried to do is write $A= D + N$,  where $D$ is diagonalizable, $N$ is nilpotent and $DN = ND$. Since $N$ is nilpotent, there exist a minimal $n$ such that $N^n=0$. Then $e^A=e^{D+N}=e^De^N=e^D(I+N+\frac{N^2}{2}+...+\frac{N^{n-1}}{(n-1)!})=A=D+N$. If we times $N^{n-1}$ on both side, then what remain is $e^DN^{n-1}=DN^{n-1}$. And then I don't know how to carry on. Please help! Do I need a new method to do this question? Thanks a lot!","['matrices', 'diagonalization']"
1631952,Riemann Surface Tennis [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question So a few months ago I read Brave New World by Aldous Huxley and found the authors insights and style of humor remarkable. It describes a utopian society where people are conditioned to be enslaved by the pursuit of short term pleasure and happiness at the sacrifice of truth and beauty. Some of the games people play in the Brave New World include electromagnetic golf, and my personal favorite Riemann surface tennis. Huxley went to Oxford so he must have had tons of really brilliant friends, but I think he's just taking the piss out of mathematicians and their magical powers of abstraction. Still, what would playing tennis on a Riemann surface be like? Say for example, $f(z)=\log(z)$? What kinds of surfaces could you play Riemann surface tennis on? I'd imagine it'd be...challenging.","['complex-analysis', 'soft-question']"
1631965,Convergence in probability implies Fatou's lemma?,"Let $(\Omega, \mathcal{F},P)$ be a probability space and $(X_n)$ be a positive-valued sequence of random variables on $\Omega$. We assume that $(X_n)$ converges in probability to the random variable $X$. Is it true that $$E(X)\leq \liminf_{n\to+\infty}E(X_n)$$ Thanks a lot for the help in advance!","['means', 'probability-theory', 'convergence-divergence', 'random-variables']"
1631979,Application of Doob's inequality,"Suppose that $X_n$ is a martingale with $X_0 = 0$ and $EX^2_n < \infty$. Show that 
  $$P\left(\max_{1\leq m \leq n} {X_m} \geq \lambda\right) \leq \frac{EX^2_n}{EX^2_n+\lambda^2}$$
  by using the fact that $(X_n+c)^2$ is a submartinagle. So far, I have tried to manipulate $P(\max_{1\leq m \leq n} X_m \geq \lambda) $ into the form of $$P\left(\max_{1\leq m \leq n} (X_m + c)^2 \geq \lambda^2 + EX^2_n\right)$$ by finding an appropriate $c$ that yields the inequality, but it does not seem to work. How should I proceed? The problem is from Durrett Exercise 5.4.5.","['inequality', 'expectation', 'probability-theory', 'martingales', 'conditional-expectation']"
1631986,An inequality regarding the expectation of a transformed random variable,"For any given nonnegative random variable $X$ and $0 < \rho \leq 1$, I define the following object. $$\pi_{\rho}(X) = \int_0^{\infty}(P\{X > t\})^{\rho}\, dt$$ The inequality that I want to prove is the following property of this object. If $X,Y \geq 0$ and $0 < \rho \leq 1$, then
  $$\pi_{\rho}(X+Y) \leq \pi_{\rho}(X) + \pi_{\rho}(Y)$$ Here is my attempt. $$X + Y > t \implies X > \frac{t}{2} \quad \text{or} \quad Y > \frac{t}{2}$$
Starting from this implication I reason as follows
\begin{align}P\{X + Y > t\} \leq  P\left\{X > \frac{t}{2}\right\} + P\left\{Y > \frac{t}{2}\right\}\end{align}
\begin{align}(P\{X + Y > t\})^{\rho} &\leq  \left(P\left\{X > \frac{t}{2}\right\} + P\left\{Y > \frac{t}{2}\right\}\right)^{\rho}\\ &\leq \left(P\left\{X > \frac{t}{2}\right\}\right)^{\rho} + \left(P\left\{Y > \frac{t}{2}\right\}\right)^{\rho} \quad (\triangle)\\ &\leq \left(P\left\{2X > t\right\}\right)^{\rho} + \left(P\left\{2Y > t\right\}\right)^{\rho}\end{align} The inequality $(\triangle)$ follows from the observation that for $a,b \geq 0$ and $0\leq p \leq 1$, $$a^p + b^p \geq (a+b)^p$$ Using the fact that for $a > 0$, $$\pi_{\rho}(aX) = a\pi_{\rho}(X)$$ I arrive at $$\pi_{\rho}(X+Y) \leq 2\pi_{\rho}(X) + 2\pi_{\rho}(Y)$$ I am not sure if what I have written is correct. In any case I didn't get the inequality I needed. Can someone please point out if one of the inequalities I used is too conservative or I should have taken a whole other path?",['probability-theory']
1631993,Why is the drift of an Itō process considered to be a Riemann integral even when it's not even Riemann integrable?,"Let $(\Omega,\mathcal A,\operatorname P)$ be a probability space $(\mathcal F_t)_{t\ge 0}$ be a filtration of $\mathcal A$ $(B_t)_{t\ge 0}$ be a real-valued Brownian motion with respect to $\mathcal F$ on $(\Omega,\mathcal A,\operatorname P)$ $\lambda$ be the Lebesgue integral on $[0,\infty)$ I've read the following: Let $\sigma$ and $b$ be real-valued $\mathcal F$-progressively measurable stochastic processes on $(\Omega,\mathcal A,\operatorname P)$ with $$\int_0^t\sigma_s^2+|b_s|\;{\rm d}s<\infty\tag 1\;\;\;\operatorname P\text{-almost surely}$$ for all $t\ge 0$ $\Rightarrow$ $$X_t=\int_0^t\sigma_s\;{\rm d}B_s+\int_0^tb_s\;{\rm d}s\tag 2$$ is called Itō process with diffusion coefficient $\sigma$ and drift $b$. However, some things are weird about that definition: People state that $(1)$ and the second integral in $(2)$ are Riemann integrals. But unless the points of discontinuity of the paths of $b$ form a $\lambda$-null set, it is not Riemann integrable and hence $(1)$ is not even defined (as a Riemann integral). So, shouldn't $\int_0^t{\rm d}s$ be replaced by $\int_0^t{\rm d}\lambda(s)$? In that case $(1)$ would ensure, that almost surely the paths of $b$ are $\lambda$-integrable on $[0,t]$ for any $t\ge 0$ and thereby the second integral in $(2)$ would be almost surely well-defined (as a Lebesgue integral). But we still got a problem: Since the second integral in $(2)$ is only well-defined on $\Omega\setminus N$ for some $\operatorname P$-null set $N\subseteq\Omega$, the integral and thereby $X_t$ is undefined on $N$. So, do we in fact need to replace $X_t$ on $N$ by something well-defined?","['stochastic-processes', 'probability-theory', 'stochastic-integrals', 'stochastic-calculus', 'stochastic-differential-equations']"
1632023,Evaluation of $\prod^{n}_{r=1}\sin \left(\frac{(2r-1)\pi}{2n}\right)$,"Find value of $$\prod^{n}_{r=1}\sin \left(\frac{\left(2r-1\right)\pi}{2n}\right)$$ Where $n\in \mathbb{N}$ and $n>1$ $\bf{My\; Try::}$ Let $$P = \sin \left(\frac{\pi}{2n}\right)\cdot \sin \left(\frac{3\pi}{2n}\right)\cdot \sin \left(\frac{5\pi}{2n}\right)\cdot \cdot \cdot \cdot \cdot \sin\left(\frac{n\pi}{2n}\right)\cdot\cdot \cdot \cdot \cdot \sin\left(\frac{(2n-1)\pi}{2n}\right)$$ Now we can write $\displaystyle \sin\left(\frac{(2n-1)\pi}{2n}\right)=\sin \left(\frac{\pi}{n}\right)$ Similarly $\displaystyle \sin\left(\frac{(2n-3)\pi}{2n}\right)=\sin \left(\frac{3\pi}{2n}\right)$ So we get $$P = \left[\sin \left(\frac{\pi}{2n}\right)\cdot \sin \left(\frac{3\pi}{2n}\right)\cdot \sin \left(\frac{5\pi}{2n}\right)\cdot \cdot \cdot \cdot \cdot \sin\left(\frac{(n-2)\pi}{2n}\right)\right]^2$$ Now How can i Solve after that, Help me Thanks","['products', 'trigonometry']"
1632035,Continuous functions with values in separable Banach space dense in $L^{2}$?,"Let $[0,1] \subset \mathbb R$ be a the compact interval in the real numbers $\mathbb R$.
We know that $C([0,1] \to \mathbb R)$ (the continuous function on $[0,1]$ with values in $\mathbb R$) are dense in $L^{2}  ([0,1] \to \mathbb R)$ (the usual Lebesgue space). Now consider the Lebesgue space of functions on $[0,1]$, that take values in a separable Banach space $X$, i.e. $L^{2}  ([0,1] \to X)$.
This space is equipped with the norm $\int_{[0,1]} | f(t) |_{X}^{2} d t$, where $|.|_{X}$ is the norm on $X$. Are the continuous functions with values in this space, i.e. $C([0,1] \to X)$, also dense in $L^{2}  ([0,1] \to X)$ ? For a concrete example, I am in particular interested in $X = C([1,2] \to \mathbb R )$, i.e. is $C([0,1] \to C([1,2] \to \mathbb R ))$ dense in $L^{2}  ([0,1] \to C([1,2] \to \mathbb R ))$? Edit: This question is related to this question , by a different order of the spaces.","['real-analysis', 'functions', 'functional-analysis', 'metric-spaces', 'analysis']"
1632045,What does it take to have a precise definition of volume?,"Many proofs in elementary geometry use an intuitive but imprecise definition of the area or the volume. For example, Euclid's first proof of the Pythagorean Theorem uses the fact that all triangles of a given base and a given height have the same area, which (in modern terms) say that the area is invariant by shear motions $\begin{pmatrix} 1 & \lambda \\ 0 & 1 \end{pmatrix}$. On the other hand, my favourite proof of the same theorem (apparently quite close to Euclid's second proof and also discovered by a 12-year old Albert Einstein, see this great article by David Mumford ) is an transparent corollary of the fact that the area of something is multiplied by $\lambda^2$ when the something is dilated by a factor $\lambda$. These and other similar arguments convinced me that what I want of a volume is the two following properties: The volume is additive : if you cut something into two somethings, the volume of the big one is the sum of the volumes of the two little ones (with obvious but quite tedious to write down generalisations if the two little ones aren't disjoint but have a small intersection, for example an intersection included in a hyperplane). The volume is a relative invariant , meaning that if you apply an affine transformation $A$ to a something, its volume is multiplied by $|\det(A)|$. Of course, Lebesgue measure does precisely that. To be more specific, the basic tenets of the Lebesgue measure, at least in the standard presentation, are somehow different (one wants a countable additivity and doesn't hard-code the invariance in the definition, but only requires invariance by translation) but the relative invariance in the sense I gave is a classical and easy property of the Lebesgue measure, so hurray! My question is: if I only want the two properties I've stated (not countable additivity) and only want to measure the volume of very nice things (let's say: polyhedra), how more low-tech can I be? For example, I could probably define the volume by using a simpler, older integration method (Riemann's one, for instance), but can I get significantly more elementary? For example, a natural method would be to cut my polyhedron into simplices, define the volume of a simplex to be the determinant of its contituent vectors (up to some constant, n!, if I'm correct) and declare the volume of the polyhedron to be the sum of the volumes of the simplices. However, you would have to prove that this volume doesn't depend on your choice of decomposition in simplices, and I fear this would be a nightmare to prove elementarily, even more so in higher dimensions where all kind of bad things may happen, like the failure of the Hauptvermutung . So: does such an elementary but rigorous definition of the volume exist? (I think this question may turn out to have two different answers, one for small dimension and one for the general case, so to be clear, I'm interested in both cases).","['volume', 'euclidean-geometry', 'invariant-theory', 'measure-theory']"
1632054,Is the variance of a random variable finite if and only if the first two moments of the random variable are finite?,"I don't know measure theory very well, and I'm not looking for a very detailed proof. Suppose $X \in \mathcal{L}^2$ (I believe this means that $\mathbb{E}[X^2]$ exists, which implies that $\mathbb{E}[X]$ exists by something I've already proven). The variance of $X$ is defined by $\mathbb{E}[(X-\mathbb{E}[X])^2]$. It then follows that we can write the variance of $X$ as $\mathbb{E}[X^2]-\left(\mathbb{E}[X]\right)^2$. What I'm wondering is, is the converse true? That is, if the variance is finite, then $X \in \mathcal{L}^2$? By definition of the variance, $X \in \mathcal{L}^1$ since $\mathbb{E}[X]$ is in there. But how do we know that $\mathbb{E}[X^2]$ exists? I have already read this question and answer , but I don't quite understand it, since writing the variance as $\mathbb{E}[X^2]-\left(\mathbb{E}[X]\right)^2$ assumes that $X \in \mathcal{L}^2$ anyway.",['probability-theory']
1632058,Relationship between factorial and derivatives,I was wondering if there is any relationship between factorials and derivatives because I notice that if we had $x^n$ and we take the $n$-th derivative of this function it will be equal to the factorial of $n$: $$\frac{d^n}{dx^n}(x^n)=n!$$,"['derivatives', 'factorial']"
1632067,"$C ([1,2] \times [0,1] \to \mathbb R)$ dense in $C ( [1,2] \rightarrow L^{2} ([0,1] \to \mathbb R))$?","Let $[0,1] \subset \mathbb R$ be a the compact interval in the real numbers $\mathbb R$.
We know that $C([0,1] \to \mathbb R)$ (the continuous function on $[0,1]$ with values in $\mathbb R$) are dense in $L^{2}  ([0,1] \to \mathbb R)$ (the usual Lebesgue space). Now consider the space of continuous functions on $[1,2]$ taking values in $L^{2}  ([0,1] \to \mathbb R)$ , i.e. $C ( [1,2] \rightarrow L^{2}  ([0,1] \to \mathbb R))$. Is the space $C ([1,2] \times [0,1] \to \mathbb R)$ dense in $C ( [1,2] \rightarrow L^{2}  ([0,1] \to \mathbb R))$? In other words:
Fix an arbitrary $f \in C ( [1,2] \rightarrow L^{2}  ([0,1] \to \mathbb R))$.
Can we find a sequence $f_{n} \in C ([1,2] \times [0,1] \to \mathbb R)$, such that 
$$\sup_{z \in [1,2]} \int_{[0,1]} ( f_{n} -f )^{2} (z,x) d x \rightarrow 0
?
$$ This question is related to this question , by a different order of the spaces.","['real-analysis', 'banach-spaces', 'functions', 'functional-analysis', 'continuity']"
1632071,The sum of integrals of a function and its inverse: $\int_{0}^{a}f+\int_{f(0)}^{f(a)}f^{-1}=af(a)$,"Regarding real numbers, the following appears to be true, or at least true with some modifications. Could you help me for the proof? $$\int_0^af(x)dx+\int_{f(0)}^{f(a)}f^{-1}(x)dx=af(a)$$","['real-analysis', 'integration', 'definite-integrals', 'calculus']"
1632072,"If $P(A \ \cup \ B) = P(A) + P(B)$, is it the case that $A$ and $B$ are disjoint?","I know that if $A$ and $B$ are disjoint events, then $P(A \cup \ B) = P(A) + P(B)$. However, is the converse true as well? Thanks.",['probability']
1632091,Automorphisms of a group and subgroup,"Is there a finite $p$-group $G$ such that $G$ has less number of automorphisms than some subgroup:
$$|\mbox{Aut}(G)|<|\mbox{Aut}(H)| \mbox{ for some }H\leq G.$$
If there is such a group, then can this happen in some abelian $p$-group? Perhaps there are non-nilpoent groups $G$ satisfying above condition, since, long back, I had seen an exercise to provide such example in Problems in Group Theory by John D. Dixon The example of a non-nilpotent group $G$ and its $2$-subgroup   is here . But, my question is within the Category of $p$-groups.","['finite-groups', 'p-groups', 'group-theory']"
1632094,How to gain an intuition of the affine function's definition?,"Here is the definition of Affine Functions according to Stephan Boyd (EE263 Stanford)  : 1- I believe linearity is more restrictive property of a function than being affine since it requires $f(0) = 0.$ I wonder, how is it the case that by imposing a constraint, namely $\alpha + \beta = 1$ , we achieve a less restrictive property? 2- How can we get an intuitive feeling of the concept of affinity via this definition? Thanks","['affine-geometry', 'linear-algebra']"
1632135,How to show that Cantelli's inequality has no better result,"Cantelli's Inequality states that for a random variable $X$ with mean $μ$ and variance $\sigma^2$: $$
P(X-μ\geq \alpha)\leq\frac{\sigma^2}{\sigma^2 + \alpha^2}
$$ Now, I read that if I consider a Bernoulli random variable with parameter $p$, then it can be shown that there is no better bound. I took this line of thinking but the farthest I got was that: $$
P(X-p \geq \alpha) \leq \frac{p(1-p)}{p(1-p) + \alpha^2}
$$ I am not sure even if I simplify here and get an equality what it could possibly show in terms of the efficiency of the bound. Does anyone have any insights? Thanks!","['probability-theory', 'probability']"
1632147,Theorem 2.27 (a) in Baby Rudin: Is his proof complete enough?,"Here's Theorem 2.27 (a) in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: If $X$ is a metric space and $E \subset X$, then $\overline{E}$ is closed. Now here's Rudin's proof: If $p \in X$ and $p \not\in \overline{E}$ then $p$ is neither a point of $E$ nor a limit point of $E$. Hence $p$ has a neighborhood which does not intersect $E$. The complement of $\overline{E}$ is therefore open. Hence $\overline{E}$ is closed. Is the above proof good enough, especially at the level Rudin is intended for? Now here's the proof I propose: If $p \in X$ and $p \not\in \overline{E}$ then $p$ is neither a point of $E$ nor a limit point of $E$. Hence $p$ has a neighborhood which does not intersect $E$. Let $N_\epsilon (p)$ be this neighborhood. Now we show that no point of $N_\epsilon (p)$ can be in $\overline{E}$. Let $q \in N_\epsilon (p)$. Then $d(q,p) < \epsilon$, where $d$ denotes the metric on $X$. Let $\delta \colon= \epsilon - d(p,q)$. Then $0 < \delta < \epsilon$. Now if $a \in N_\delta (q)$, then $d(a,q) < \delta = \epsilon - d(q,p)$, which implies that $$d(a,p) \leq d(a,q) + d(q,p) < \epsilon,$$
  and so $a \in N_\epsilon (p)$. Thus we have shown that $N_\delta (q) \subset N_\epsilon (p)$. Since 
  $ N_\epsilon (p) \cap E = \emptyset$, we have $N_\delta (q) \cap E = \emptyset$ as well. That is, the point  $q$ has a neighborhood --- namely  $N_\delta (q)$ --- which does not intersect $E$ at all. So $q \not\in \overline{E}$. But $q$ was an arbitrary point in $N_\epsilon (p)$. So $N_\epsilon (p) \subset \left( \overline{E} \right)^c$. But $p$ was an arbitrary point in $\left( \overline{E} \right)^c$. Thus, we can conclude that every point of $\left( \overline{E} \right)^c$ is an interior point. Hence $\left( \overline{E} \right)^c$ is open. Now is my proof any better than Rudin's? Are there any extra advantages to be had from inclusion or exclusion of extra details?","['real-analysis', 'proof-writing', 'metric-spaces', 'education', 'analysis']"
1632157,Calculate $\lim_{n\to\infty}(\sqrt{n^2+n}-n)$. [duplicate],"This question already has answers here : Prove that $\lim_{n\to\infty} (\sqrt{n^2+n}-n) = \frac{1}{2}$ (10 answers) Closed 8 years ago . Introduction: An exercise from ""Principles of mathematical Analysis, third edition"" by Rudin, page 78. Exercise: Calculate $\lim_{n\to\infty}(\sqrt{n^2+n}-n)$. Explanation: I have a hard time to grasp how to handle limits like this. I don't know how to start and what to look for. I've checked with mathematica and the answer should be $\frac{1}{2}$, and of course i've got the wrong answer. I find limits unintuitive. In the book, they proved ""the limits of some sequences which occur frequently"". The limits they proved were: (a) If $p>0$ then $\lim_{n\to\infty}\frac{1}{n^p}=0$ (b) If $p>0$ then $\lim_{n\to\infty}\sqrt[n]{p}=1$ (c) $\lim_{n\to\infty}\sqrt[n]{n}=1$ (d) If $p>0$ and $\alpha$ is real, then $\lim_{n\to\infty}\frac{n^\alpha}{(1+p)^n}=0$ (e) If $|x|<1$, then $\lim_{n\to\infty}x^n=0$. When they proved all of the above theorems it felt like they used the fact that they knew the limits. For example: Proof of (b): If $p>1$, put $x_n=\sqrt[n]{p}-1$. Then, $x_n>0$ and by the binomial theorem, $$1+nx_n\leq(1+x_n)^n=p$$ so that $$0<x_n\leq\frac{p-1}{n}.$$ Hence $x_n\to 0$. And so on... That is, I think they used the fact that the limit were 1 when they did put $x_n=\sqrt[n]{p}-1$. Before I compute a limit do I have to guess one? How can I do that when I don't think this is intuitive? Have you any tips how you do when you shall tackle a problem like this? How do you start when you want to compute a limit? Solution: This is how I did it: $\sqrt{n^2+n}-n=\sqrt{n}\sqrt{n-1}-n=\sqrt{n}(\sqrt{n-1}-\sqrt{n})$. Since $$(\sqrt{n-1}-\sqrt{n})\to 0\text{ when }n\to\infty.$$ The product approaches $0$. Which is obviously not true. I did realise this after a while. Since one of the factor grows really big while the other gets really small and I guess they tend to take each other out, so it's pretty clear it shouldn't approach 0, but I don't think it's clear that it should approach $\frac{1}{2}$ either. Thanks for your help.","['radicals', 'real-analysis', 'limits', 'calculus', 'sequences-and-series']"
1632159,There are 40 men and 40 women. In how many ways can you pick a board of 31 people that has a majority of women? [duplicate],"This question already has answers here : In how many ways can a $31$ member management be selected from $40$ men and $40$ women so that there is a majority of women? (3 answers) Closed 8 years ago . There are 40 men and 40 women. In how many ways can you pick a board of 31 people that has a majority of women? I was thinking - let's start with the women. There are $\binom{40}{16}$ ways to pick 16 women (so that there will be more women than men), and then I just need to choose the other 15 people out of all the rest - $\binom{64}{15}$... So I thought the answer would be : $\binom{40}{16}\cdot\binom{64}{15}$ but apparently it's incorrect... Why? And why is the correct answer $\frac{1}{2}\cdot\binom{80}{31}$?",['combinatorics']
1632232,"If any differential equation is given by $f''(x)+f'(x)+f^2(x) = x^2\;,$ Then $f(x)=$","If any differential equation is given by $f''(x)+f'(x)+f^2(x) = x^2\;,$ Then $f(x)=$ $\bf{My\; Try:}$ We can write the above differential  equation as $$e^xf''(x)+e^xf'(x)+e^x\cdot (f(x))^2 = e^x\cdot x^2$$ So $$\frac{d}{dx}\left[e^x\cdot f'(x)\right] = e^x\cdot x^2-e^x(f(x))^2$$ Now How can I proceed after that, help me Thanks.","['integration', 'ordinary-differential-equations', 'calculus']"
1632255,Is difference of two independent Gaussian R.Vs and their sum independent?,"I have been trying to answer a question I have been carry on from probability course. I'd appreciate if anyone can help me. Suppose we have two independent Gaussian distributions, both zero-mean with different variance. Is it true that their difference and their sum are independent from each other? Thanks.","['probability-theory', 'probability', 'probability-distributions']"
1632311,Find the value of $\sum_{n=0}^\infty\frac{1}{9n^2+9n+2}$,"I was doing some problems in algebraic number theory and this series came up $$\sum_{n=0}^\infty\frac{1}{9n^2+9n+2}.$$ So, I would like to know the value of this series. However, I don't want a full answer, only hints. I have tried to use Fourier's series, but with no success, perhaps an answer can be gotten usign this. Thanks","['real-analysis', 'sequences-and-series']"
1632328,CDF for Laplace distribution,"According to the Wiki article on the Laplace distribution, $$F(x)=\int\limits_{-\infty}^x f(u)du=\begin{cases} \frac{1}{2}\exp(\frac{x-\mu}{b}) && \text{if }x< \mu \\ 1-\frac{1}{2}\exp(-\frac{x-\mu}{b}) &&\text{if } x\geq \mu\end{cases},$$ where $$f(x|\mu,b)=\frac{1}{2b}\exp\big(-\frac{|x-\mu|}{b}\big). $$ I get the $x<\mu$ case. But for the other one, if I evaluate the integral, I get $$\int\limits_{-\infty}^x \frac{1}{2b}\exp\big(-\frac{u-\mu}{b}\big)du=-\frac{1}{2}\exp\big(-\frac{u-\mu}{b}\big),$$
which I need to evaluate between $-\infty$ and $x$. Substitute in $x$, and I get $$-\frac{1}{2}\exp(-\frac{x-\mu}{b}).$$ But why should I get $1$ if I substitute in $-\infty$?","['probability-theory', 'calculus', 'probability-distributions', 'integration', 'analysis']"
1632346,Solve $z^4+2z^3+3z^2+2z+1 =0$,"Solve $z^4+2z^3+3z^2+2z+1 =0$ with $z$: a complex variable. Attempt at solving the problem : We divide the polynom by $z^2$ and we get: $z^2+2z+3+\dfrac{2}{z}+  \dfrac{1}{z^2}=0  $  $         $ We set $w=z+  \dfrac{1}{z}$ We now have $w^2+2w+5=0$ $\bigtriangleup = -16$ Let's find $\omega$ such that $\omega^2=-16$ We have $\omega=4i$ Therefore we have the 2 roots:
$w_    {1}=-1-2i$ and $ w_    {2}=-1+2i  $ The issue is: I don't know how to find z","['complex-analysis', 'complex-numbers']"
1632367,Conditional expectation of Poisson r.v. $X$ given $X$ is even?,"We have a random variable $X$ that is poisson distributed with $\lambda$. We wish to show: $$E[X\mid X \text{ is even}]=\lambda \frac{1-e^{-2\lambda}}{1+e^{-2\lambda}}$$ So far, I have that $P(X \text{ is even})=\frac{1+e^{-2\lambda}}{2}$ $P(X\text{ is odd})=\frac{1-e^{-2\lambda}}{2}$ and that $E[X]=\lambda$ for the Poisson distribution. I am struggling because I'm not completely sure how these pieces fit together. Conditional expectation is still a little fuzzy to me. Any hints/solutions are appreciated.","['probability-theory', 'conditional-expectation', 'poisson-distribution']"
1632441,There are infinitely many projections,Can anyone explain please why such projections are infinitely many?,"['multivariable-calculus', 'operator-theory']"
1632444,Equivalence between constant and positive metric and usual $\Re^3$ metric,"I'm trying to answer the following question: Is any positive and constant metric in $\Re³$ equivalent to the usal metric defined as $$ds² = dx² + dy² + dz² \tag{*}\label{1} $$ with $ds = g_{ij}dx^{i}dx^{j}$ and $g_{ij} = \delta_{ij}$. Or alternatively, does always exist a coordinate transformation from the coordinates $y^\mu$ to the coordinates $x^i$ such that \eqref{1} is recovered from $$ds² =    \tilde{g}_{\mu\nu}dy^{\mu}dy^{\nu} $$ with $\tilde{g}_{\mu\nu}$ being constant in the $y^\mu$ coordinates. My initial guess it's that this is true, however I'm not sure on how this could be proved.","['euclidean-geometry', 'differential-geometry']"
1632451,How do you find the probability of A winning if the probability of getting a favourable outcome in the $r^{th}$ turn is a function of $r$?,"Problem: Two players A and B are playing snake and ladder. A is at 99 and he needs 1 to win in rolling of a dice. However, he is always allowed to re-throw the dice if 6 appears. What is the probability that A will win eventually before B gets a chance, if the probability of getting 1 in the $r^{th}$ throw is $\frac{1}{3^r}$ and that of getting 6 in the $r^{th}$ throw is $\frac{2r-1}{4r}$? My attempt: We know that A can win before B gets a chance only if he rolls {$1$},{$6$,$1$},{$6$,$6$,$1$} and so on. In the $r^{th}$ turn, we have the probability: $$\frac{1}{3^r}\cdot\frac{1}{4}\cdot\frac{3}{8}\cdot\cdot\cdot\frac{2r-3}{4(r-1)}$$ $$=\frac{1}{3^r}\cdot\frac{1}{4^{r-1}}\left(\frac{1\cdot3\cdot5\cdot7\cdot\cdot\cdot(2r-3)}{1\cdot2\cdot3\cdot4\cdot\cdot\cdot(r-1)}\right)$$ $$=\frac{1}{3^r}\cdot\frac{1}{4^{r-1}}\left(\frac{(2r-2)!}{(r-1)!\cdot(r-1)!\cdot2^{r-1}}\right)$$ $$=\frac{1}{3}\cdot\frac{1}{24^{r-1}}\left(\frac{(2r-2)!}{(r-1)!\cdot(r-1)!}\right)$$ Therefore, we have the probability as $$\sum_{r=1}^{\infty} \frac{1}{3}\cdot\binom{2r-2}{r-1} \frac{1}{24^{r-1}}$$ Taking $r-1$=$n$ $$\frac{1}{3}\sum_{n=0}^{\infty} \binom{2n}{n} \frac{1}{24^{n}}$$ I got stuck at the last step because I do not know how to evaluate that summation. Any help with the summation/providing an alternate way to solve this question will be appreciated.","['binomial-coefficients', 'algebra-precalculus', 'probability', 'contest-math', 'sequences-and-series']"
1632455,Mathematical meaning of certain integrals in physics,"While studying on texts of physics I notice that differentiation under the integral sign is usually introduced without any comment on the conditions permitting to do so. In that case, I take care of thinking about what the author is assuming and the usual assumption made in physics that all the functions are of class $C^\infty$, at least piecewise on compact subsets, often is enough to guarantee the liceity of freely commutating the derivative and integral signs. While studying the derivation of Ampère's law from the Biot-Savart law, someting has surprised me in this proof which seems to be ubiquitous on line and in cartaceous texts. In fact the magnetic field in a point $\mathbf{x}$ is $$\mathbf{B}(\mathbf{x}):=\frac{\mu_0}{4\pi}\iiint_V\mathbf{J}(\mathbf{l})\times\frac{\mathbf{x}-\mathbf{l}}{\|\mathbf{x}-\mathbf{l}\|^3}d^3l=\frac{\mu_0}{4\pi}\iiint_V\nabla_x\times\left[\frac{\mathbf{J}(\mathbf{l})}{\|\mathbf{x}-\mathbf{l}\|}\right]d^3l$$where I would prove the identity of the integrands at both members by considering the derivatives as... well, ordinary derivatives. I keep Wikipedia's notation except for $\mathbf{x}$, which is more common as a variable, and the norm sign, for which I have always seen $\|\cdot\|$ elsewhere. Then we can notice that the proof uses a differentiation under the integral sign (at $(1)$ below): since $\nabla_x\times\left[\nabla_x\times\left[\frac{\mathbf{J}(\mathbf{l})}{\|\mathbf{x}-\mathbf{l}\|}\right]\right]=\nabla_x\left[\nabla_x\cdot\left[\frac{\mathbf{J}(\mathbf{l})}{\|\mathbf{x}-\mathbf{l}\|}\right]\right]-\nabla_x^2\left[\frac{\mathbf{J}(\mathbf{l})}{\|\mathbf{x}-\mathbf{l}\|}\right]=\nabla_x\left[\mathbf{J}(\mathbf{l})\cdot\nabla_x\left[\frac{1}{\|\mathbf{x}-\mathbf{l}\|}\right]\right]$ $-\nabla^2\left[\frac{1}{\|\mathbf{x}-\mathbf{l}\|}\right]\mathbf{J}(\mathbf{l})$, where I would calculate the derivatives as ordinarily understood, again, we have that$$\nabla_x\times\mathbf{B}(\mathbf{x})=\nabla_x\times\left[\frac{\mu_0}{4\pi}\iiint_V\nabla_x\times\left[\frac{\mathbf{J}(\mathbf{l})}{\|\mathbf{x}-\mathbf{l}\|}\right]d^3l\right]$$$$=\frac{\mu_0}{4\pi}\iiint_V\nabla_x\times\left[\nabla_x\times\left[\frac{\mathbf{J}(\mathbf{l})}{\|\mathbf{x}-\mathbf{l}\|}\right]\right]d^3l\quad(1)$$$$=\frac{\mu_0}{4\pi}\iiint_V\nabla_x\left[\mathbf{J}(\mathbf{l})\cdot\nabla_x\left[\frac{1}{\|\mathbf{x}-\mathbf{l}\|}\right]\right]-\nabla_x^2\left[\frac{1}{\|\mathbf{x}-\mathbf{l}\|}\right]\mathbf{J}(\mathbf{l})\,d^3l$$and then the integral is split as licit for Riemann, and Lebesgue, integrals when both integrands are integrable, and the gradient and integral signs are commutated in the first of the two resulting integrals to get$$\frac{\mu_0}{4\pi}\nabla_x\iiint_V\mathbf{J}(\mathbf{l})\cdot\nabla_x\left[\frac{1}{\|\mathbf{x}-\mathbf{l}\|}\right]d^3l-\frac{\mu_0}{4\pi}\iiint_V\nabla_l^2\left[\frac{1}{\|\mathbf{x}-\mathbf{l}\|}\right]\mathbf{J}(\mathbf{l})\,d^3l$$where the first addend is $\mathbf{0}$ (I do not understand how it is calculated, but that is not the main focus of my question) and where the identity $\nabla_l^2\left[\frac{1}{\|\mathbf{x}-\mathbf{l}\|}\right]=-4\pi\delta(\mathbf{x}-\mathbf{l})$, where the derivatives are this time intended as derivatives of a distribution, is used to get$$-\frac{\mu_0}{4\pi}\iiint_V\nabla_l^2\left[\frac{1}{\|\mathbf{x}-\mathbf{l}\|}\right]\mathbf{J}(\mathbf{l})\,d^3l=\mu_0\mathbf{J}(\mathbf{x}).$$ Everything of my reasoning seemed to me to work by assuming $V\subset\mathbb{R}^3$ to be compact and such that $\mathbf{x}\notin V$ and intending the integral $\iiint...d^3l$ to be a Riemann (or Lebesgue, which, in that case, I think to be the same) integral, but at this last step I see that it was not what I thought. What are, then, the integrals appearing in such calculations?
They cannot be Riemann integrals, as far as I understand, because then it must be $\mathbf{x}\notin V$ and then $\iiint_V\nabla_l^2\left[\frac{1}{\|\mathbf{x}-\mathbf{l}\|}\right]\mathbf{J}(\mathbf{l})\,d^3l=\mathbf{0}$, and they cannot be Lebesgue integrals, because, even with $\mathbf{x}\in V$, then $\iiint_V\nabla_l^2\left[\frac{1}{\|\mathbf{x}-\mathbf{l}\|}\right]\mathbf{J}(\mathbf{l})\,d^3l$ $=\int_{V\setminus\{\mathbf{x}\}}\nabla_l^2\left[\frac{1}{\|\mathbf{x}-\mathbf{l}\|}\right]\mathbf{J}(\mathbf{l})\,d\mu_{\mathbf{l}}$ $=\mathbf{0}$, even if $\mathbf{J}(\mathbf{x})$ is not null. What else if not Riemann or Lebesgue integrals? Why is the commutation of the integral and differential operators licit and what do the derivatives mean in such a context? If we intend them to represent functionals as in the context of functional analysis (which is the only one that I know of where Dirac's $\delta$ is defined), which function ($\varphi$, to use the notation used here )  is the argument of the functional and what does the functional maps it to? What are the derivatives expressed by $\nabla$? Since theorems such as Stokes' are usually applied when integrating $\nabla\times\mathbf{B}$, I would believe that they are the ordinary derivatives of elementary multivariate calculus, but then the $\delta$, which is a tool of the theory of distributions, pops up in the outline of proof , and in the theory of distributions there exist derivatives of distributions which are a very different thing, but they are taken, as far as I know, with respect to the variables written as ""variables of integration"" in the distribution integral notation, while we start with $\nabla_r\times \mathbf{B}$ with $r$ , while the integral appears with $d^3l$... Or is that one of those cases , whose set I have been told not to be empty, where physics methods , at least at the didactic level, are not as rigourous as mathematics would require? I admit that I was rather inclined to think so until a user of PSE told me , without explaining how to interpretate the integrals and justify the steps, that the quoted proof is rigourous. I heartily thank any answerer.","['real-analysis', 'physics', 'functional-analysis', 'multivariable-calculus', 'integration']"
1632461,What is the probability of a pen touching a bar given that the length of the pen is $10$ cm and the bars are regularly spaced at $15$ cm?,"Problem: If a pen of length $10$ cm is thrown out of infinitely large window having vertical bars regularly spaced at $15$ cm, then find the probability that it will touch any of the bars. (Assume that the vertical bars are infinitely long) I don't know how to even begin with the question, so any help will be appreciated. All I know is that integration is involved in the calculation of this probability, but I don't know what to integrate, since the pen can be thrown anywhere, and at any angle.","['contest-math', 'probability']"
1632489,What is the minimal correction to the harmonic series such that it converges?,"as you all hopefully know, the series
$$
\sum_{k\ge 1}\frac{1}{k}
$$
diverges. Now I know that you can add some logarithmic corrections, such that it converges:
$$
\sum_{k\ge 1}\frac{1}{k\log(k)^2}
$$
(this might be wrong, i only remember this faintly). I once saw a wiki page which explained which sort of logarithmic corrections one can (and has to) make in order for the series to converge, does anyone know?
Thx!","['power-series', 'real-analysis', 'sequences-and-series', 'analysis']"
1632496,Does $\overline{ \sqrt{1 + i}} = \sqrt{1-i} \ $?,"I am having trouble with complex conjugates today.  Can someone help me?  $$\overline{ \sqrt{1 + i}} \stackrel{\color{#2222FF}{?}}{=} \sqrt{1-i} \tag{$\ast$} $$ In this case, since $\cos \frac{\pi}{4} + i \sin \frac{\pi}{4} = \frac{1}{\sqrt{2}}(i+i)$.  Then we can take the square root and get: $$\cos \frac{\pi}{8} + i \sin \frac{\pi}{8} = \frac{1}{\sqrt[4]{2}}\sqrt{1+i}$$ Then if we take complex conjugate of both sides, I don't know the cosine of $\frac{\pi}{8} = 22.5^\circ$ off the top of my head $$\cos \frac{\pi}{8} - i \sin \frac{\pi}{8} = \frac{1}{\sqrt[4]{2}} \overline{\sqrt{1+i}}$$ On other parts of Math.SE (and this ) we find that $\cos \frac{\pi}{8} = \frac{\sqrt{2 + \sqrt{2}}}{2}$ a very interesting number indeed. $$\frac{1}{\sqrt[4]{2}}\sqrt{1+i} =  \frac{\sqrt{2 + \sqrt{2}}}{2} + i \frac{\sqrt{2 - \sqrt{2}}}{2}$$ At this point, I am still not sure $(\ast)$ is correct or not.","['algebra-precalculus', 'radicals', 'complex-numbers']"
1632517,Continuous path inside the Mandelbrot set connecting i to zero?,"This relates to another challenge Question about drawing Mandelbrot filaments. It is possible to compute a formula for a continuous path inside the Mandelbrot Set connecting $c=i$ to $c=0$? Obviously, the part inside the cartoid or lobes is easy, but finding any in-Set curve that includes $i$ has eluded me. I know the Mandebrot boundary is infinitely long and detailed, but if a filament has any finite thickness there should be a finite-length path through it that doesn't follow the boundary. I tried to start by finding a direction one could travel from $i$ for a very short distance and remain in-Set, but even that eluded me. To show the topology we're up against, here is the $|z_{25}|==2$ contour in the vicinity of i. So, can one derive a formula for the path I want? As an aside, it's worth noting that $i$ is a Misiurewicz Point , meaning its orbit is not immediately periodic but becomes so after a finite number of steps, i.e., $z_3(i)=z_1(i)$.  This property places i exactly on the boundary of the Mandelbrot set. $$i\rightarrow-1+i\rightarrow-i\rightarrow-1+i\rightarrow-i\rightarrow-1+i\rightarrow-i...$$","['general-topology', 'fractals', 'recreational-mathematics']"
1632534,Question about weak convergence of random variables,"When you start to learn probability theory, for instance the central limit theorem, you learn about convergence in distribution $X_n\to X$ (where, say, both $X_n$ and $X$ are $\mathbb R$-valued random variables). At the beginning, the  first course start with the pointwise convergence of the repartition functions $F_n(x)\to F(x)$, where $F_n(x)=\mathbb P(X_n\leq x)$ and $F(x)=\mathbb P(X\leq x)$, but is not clear what it exactly implies (at least for me). Then you learn that this equivalently means the law $\mu_n$ of $X_n$ converges to the law $\mu$ of $X$ in the weak topology. By weak topology, it means weak-* topology when you embed the space of (Borel) probability measures on $\mathbb R$ into the Banach space of continuous linear forms over the space of continuous and bounded functions. Sometimes you look at the dual space of continuous and compactly supported functions, and then you speak about vague convergence. Now, I take for definition for the convergence in law that $\int f d\mu_n\to\int fd\mu$ for the class of continuous and bounded functions. But, what does it implies for larger spaces of test functions $f$? When $f$ is continuous but not bounded, it is not enough: you need uniform integrability, fine. But on the other way around, what if $f$ is bounded but not continuous (but still measurable) ? (if you even assume $X_n$ and $X$ take values on a same compact subset of $\mathbb R$ ?). In other words, is $f$ is bounded, what are the minimal regularity assumptions we can make on $f$ so that we still have $\int fd\mu_n\to\int fd\mu$ ? Moreover : what kind of minimal set of test functions $f$ so that $\int fd\mu_n\to\int fd\mu$ implies convergence in distribution ? For instance, what if $f$ is in the space of Lipschitz functions ?","['weak-convergence', 'general-topology', 'probability-distributions', 'probability-theory']"
1632536,Conjugate elements of $SO(3)$ group,"Composition of two rotations in 3d space yields another rotation $$R_1 R_2 = R_3, $$
and I can understand this by help of some figures in my book. So, the rotations in 3d space forms group. Then in my book, the author says that for two rotations $R$ and $R'$ with same angle but different rotation axis, they are connected by 
  $$ R' = QRQ^{-1}.$$
  Where $Q$ rotates the rotation axis of $R$ into $R'$. How do we prove this? Graphically, I can understand this. $Q$ just changes rotation axis $R$ into $R'$, so after all steps, the rotation axis comes to initial position. Next, since $R$ and $R'$ has the same rotation angle, any rigid body is rotated same angle. So I think $R'$ and $QRQ^{-1}$ would give same result. But How do I prove this by mathematically?",['group-theory']
1632543,"Solving integration by parts $\int\frac{xe^{2x}}{(1+2x)^2}\,dx$","$\displaystyle\int\frac{xe^{2x}}{(1+2x)^2}\,dx$ With this particular problem. my approach is to to rewrite the integral as  $$\int xe^{2x}\frac{1}{(1+2x)^2}\,dx$$ and then pick a $u$ and a $dv$ and take it from there. The only issue I'm running into is that $xe^{2x}$ appears to me as two functions instead of one. What is a suggestion for this?","['exponential-function', 'integration-by-parts', 'calculus', 'indefinite-integrals', 'integration']"
1632549,What is the probability that the upturned faces of three fair dice are all of different numbers?,"Three fair dice are rolled ($6$ sides). What is the probability that the upturned faces of the three dice are all of different numbers? I got that the number of possible outcomes total is $6^3$ and the number of possible outcomes for which the upturned dice are all different numbers is $6 * 5 * 4$, so the probability is $\frac{5}{9}$. Is this correct?","['probability-theory', 'probability', 'proof-verification', 'problem-solving']"
1632551,Textbook for Vector Calculus,"Can anyone recommend a textbook for studying vector calculus (vector analysis) only, that focuses on the theoretical mathematics behind vector calculus? Currently, I am using vector analysis by Snider. I have also taken a look at vector calculus by Marsden. Both of these books skip a large amount of the theory behind what we are doing and why it matters.","['reference-request', 'vectors', 'analysis', 'vector-analysis']"
1632553,Computing the limit of an integral,"Consider the following integral
$$
\int_{-\infty}^{\infty}f(t) K(\frac{a-t}{h})dt
$$
where (1) $h>0$, $a \in \mathbb{R}$ (2) $f:\mathbb{R}\rightarrow[0,\infty)$ is such that $\int_{-\infty}^{\infty}f(t)dt=1$ (3) For fixed $a$ and $h$, the map $K:\mathbb{R}\rightarrow[0,\infty)$ is such that $\int_{-\infty}^{\infty}K(\frac{a-t}{h})dt<\infty$ (4) For fixed $a$ and $t$, $\lim_{h\rightarrow 0}K(\frac{a-t}{h})=
\begin{cases}
1 \text{ if $t=a$}\\
0 \text{ otherwise}
\end{cases}$ Could you help me to show that 
$$
\lim_{h\rightarrow 0} \int_{-\infty}^{\infty}f(t) K(\frac{a-t}{h})dt=f(a)
$$
also stating under which sufficient conditions? The difficult part for me is bringing the limit inside the integral. Any hint would be really appreciated","['limits', 'distribution-theory', 'functional-analysis', 'integration', 'special-functions']"
1632554,Assume that $f : X \rightarrow Y $ is surjective. Show that $f(A^c) = (f(A))^c \ \forall A\subset X$ iff f is also injective.,"Assume that $f : X \rightarrow Y $ is surjective. Show that $f(A^c) = (f(A))^c \ \forall A\subset X$ iff $f$ is also injective. So I tried starting with the right implication $\Rightarrow$ Since $f$ is surjective we know that every $ y\in Y$ corresponds to some $x\in X$. Then we want to prove that this $x \in X $ is at most one. I came to the conclusion that since $f(A^c) = (f(A))^c \ \Leftrightarrow f(A) \cap (f(A))^c = \emptyset \ \Rightarrow \not\exists x \in A $ s.t $f(x) \in (f(A))^c$ and $\not\exists x \in A^c $ s.t $f(x) \in f(A)$. Now i want to prove that if there $\exists (f(x_1),\ f(x_2)) \in A$ s.t $ f(x_1)=f(x_2)$ then $x_1=x_2$ and of course
$\exists (f(x_1),\ f(x_2)) \in A^c$ s.t $ f(x_1)=f(x_2)$ then $x_1=x_2$ But here I have troubles.",['functions']
1632558,Finding the limit $\lim_{n\to \infty} \left({\frac{n+1}{n-2}}\right)^\sqrt n$,"I have to find:
$$\lim_{n\to \infty} \left({\frac{n+1}{n-2}}\right)^\sqrt n$$
But, to be honest, I haven't got a faintest idea how to even begin. Is there a way to evaluate this radical exponent?","['exponential-function', 'sequences-and-series', 'limits']"
1632577,Solving for the function $x(t)$ in the differential equation $\frac{dx}{x}=\frac{3}{2}C\left[\frac{\sqrt{A}}{x}+\sqrt{B}\right]dt$,I'm a little stumped on something I'm working on. I have an expression in this following form: $$\frac{dx}{x}=\frac{3}{2}C\left[\frac{\sqrt{A}}{x}+\sqrt{B}\right]dt$$ I was essentially wondering how I go about solving this for $x$ explicitly. I'm perhaps thinking I might need to make a substitution which may involve a $\sinh$ function? Help!,"['integration', 'ordinary-differential-equations', 'calculus']"
1632598,"For a.e. $x \in [0, 1]$, there are finitely many $p/q$ such that $\left| x - p/q \right| < 1 / \left( q \log q \right)^2$","I am stuck on a qualifying exam problem and was hoping to get some help. Show for a.e. $x \in [0, 1]$ that there are finitely many $p/q \in \mathbf{Q}$ in reduced form such that $q \geq 2$ and $\left| x - p/q \right| < 1 / \left( q \log q \right)^2$. There is a hint, which is to consider the intervals of length $2/\left(q \log q \right)^2$ centered at the $p/q$. To simplify notation, let $\mathbf{Q}_x$ be the set of such $p/q$ corresponding to each $x$. I've been working for awhile...I have been examining things like $$ \int_0^1 \sum_{p/q \in \mathbf{Q}_x} \frac{dx}{ \left( q \log q \right)^2} > \int_0^1 \sum_{p/q \in \mathbf{Q}_x} \left| x - p/q \right| dx = \sum_{p/q \in \mathbf{Q}} \int_0^1 \left| x - p/q \right| \chi_{\mathbf{Q}_x} dx.$$ I proved for $p/q \in (0, 1)$, $q \geq 3$, that $\left[ p/q, p/q + 1/ \left( q \log q \right) \right] \subset [0, 1]$. I feel like I could really use some guidance.  I have no idea how to capture what goes wrong if $\mathbf{Q}_x$ is infinite on a set of positive measure. Thanks for your help.","['borel-cantelli-lemmas', 'real-analysis', 'rational-numbers', 'measure-theory']"
1632600,Open covering of a scheme and global sections,"Let $X$ be a scheme. For a global section $f\in\Gamma(X,\mathcal O_X)$, let $X_f=\{x\in X\mid f_x\not\in\mathfrak m_x\}$. For $f_1,...,f_n\in\Gamma(X,\mathcal O_X)$, I wish to know if the following claim is true:
$$X_{f_1}\cup\cdots\cup X_{f_n}=X\iff (f_1,...,f_n)=\Gamma(X,\mathcal O_X).$$ In the case that $X={\rm Spec}\ A$ is an affine scheme, $X_f$ is just the distinguished open subset $D(f)$, and the claim can be proven easily. In general, I can show only one direction. Suppose $(f_1,...,f_n)=\Gamma(X,\mathcal O_X)$. Fix $x\in X$ and let $\rho_x:\Gamma(X,\mathcal O_X)\to\mathcal O_{X,x}$ be the natural map. Then $\rho_x^{-1}(\mathfrak m_x)$ is a prime ideal of $\Gamma(X,\mathcal O_X)$, so $f_i\not\in\rho_x^{-1}(\mathfrak m_x)$ for some $i$. But then $(f_i)_x=\rho_x(f_i)\not\in\mathfrak m_x$ and so $x\in X_{f_i}$. Since $x$ was chosen arbitrarily, $X=X_{f_1}\cup\cdots\cup X_{f_n}$. Is the other direction of the claim true? If not, what is a counterexample?","['schemes', 'algebraic-geometry']"
1632601,Limit of a multivariable piecewise function,"Let $f:\mathbb{R^2}\to\mathbb{R}$ given by: $f(x,y) =
  \begin{cases} 
      x-y+1     & \text{if }xy\geq 0 \\
      y-x-1  & \text{if } xy<0 \\
  \end{cases}$ I need to compute $\lim_{(x,y)\to(0,1)}f(x,y)$, but I'm not sure about the following reasoning: The problem here is that $f$, close to $(0,1)$, corresponds to different formulas. If $D_1=\{(x,y)\in\mathbb{R^2}: xy\geq0\}$ and $D_2=(D_1)^C$, we have $\lim_{(x,y)\to(0,1),(x,y)\in D_1}f(x,y)=0$ and the same for $(x,y)\in D_2$, because $f$ is continuous on $D_1$ and $D_2$. So, can I conclude that the limit is $0$? My english isn't very good; if you find any errors, please correct them.","['multivariable-calculus', 'calculus', 'limits']"
1632608,Will the generated sigma algebra have this property?,"Lets say you have a measurable space $(\Omega, \mathcal{A})$. And a measurable function $X: (\Omega, \mathcal{A})\rightarrow(\mathbb{R},\mathcal{B}(\mathbb{R}))$. We then know that for the sigma algebra generated by this function : $\sigma(X)=\{ X^{-1}(B)| B \in \mathcal{B}(\mathbb{R})\}$ has these properties: The sets $X^{-1}(\{r\})$ are disjoint and if a person we do not know chooses an $\omega$ but only tells us the value of of $X(\omega)$ but not $\omega$ itself, we can still find out for any $A\in \sigma(X)$ contains $\omega$ or not, like this: Lets say the stranger tells us that $X(\omega)=a$. Look at $X^{-1}(\{a\})\cap A$, if $X^{-1}(\{a\})\cap A=\emptyset$, then A did not happen. If $X^{-1}(\{a\})\cap A\ne \emptyset$, then A must have happened, because then we must have had $X^{-1}(\{a\})\subset A$.(Because $X^{-1}(\{a\})\cap A=X^{-1}(\{a\})\cap X^{-1}(B)=X^{-1}(\{a\}\cap B)$). My question is: Does this property extend when we have a collection of functions?: $X_c,c \in C$, where C is an index set. And we then look at the sigma algebra $\mathcal{F}$ which we define to be the sigma algebra generated by $\cup_{c \in C}\sigma(X_c). $ If a stranger now picks an $\omega$, but does not tell you the $\omega$, but he tells you all the values of $X_c(\omega), c \in C$, and you have an arbitrary set $A \in \mathcal{F}$, can you then say if you can find out if $\omega \in A$, and how would you find it out? PS: This question is ofcourse related to the fact that in regard to random variables, and stochastic processes etc., the sigma-algebra(or filtration) is said to be containing the information, but almost none of the books I have seen says how the information is recovered.","['stochastic-processes', 'probability-theory', 'measure-theory']"
1632613,Holomorphic Frobenius Theorem,"I'm trying to understand a proof of the Holomorphic Frobenius Theorem using the smooth version as seen in Voisin's Complex Geometry book: (pg 51) http://www.amazon.com/Hodge-Theory-Complex-Algebraic-Geometry/dp/0521718015 She starts with a holomorphic distribution $E$ of dimension $k$ on a complex manifold which is closed under bracket. So, $[E,E]\subseteq E$. Then, to reduce to the real case, we take the real part of the distribution to get another distribution $\Re(E)$ of dimension $2k$ in the real tangent bundle. What I can't understand is why this real distribution, $\Re(E)$, also satisfies the bracket condition. The books says this follows since $E$ is holomorphic and satisfies the bracket condition. My guess is that a local frame for it is given by the real and imaginary parts of a local frame $E$ but i'm not sure how to proceed from there. Any help is much appreciated.","['complex-geometry', 'differential-geometry']"
1632637,Is every compact space locally compact?,"Suppose that $(X,\tau)$ is a topological space. If $(X,\tau)$ is compact, then $(X,\tau)$ is locally compact. Does this statement hold for any $(X,\tau)$, or does it only hold when $(X,\tau)$ is Hausdorff?","['general-topology', 'compactness']"
1632646,"Conceptual Statistics. Define for this problem, population, Samples and Estimators, and when is Normal Dist?","Students in Stanford are supposed to spend on average 3 hours of time per week for
every credit hour they take. Last year, 263 randomly selected seniors were contacted and asked how much total time they spent on their studies over the last week and how many credit hours they currently take. (i) In this study, what is the population (be precise) and what is the
  sample? Population: (Senior) Students in Stanford. 
                  (My proff. told me this was, I needed to add seniors, in 
                  population) 

      Sample: 263 Seniors in Stanord (ii) What is the population parameter of interest? How could one
  compute a sample estimate of this population parameter? Population parameter of interest: average total time per student    
      Sample estimate of the population parameter: 263 times the mean of the sample (iii) Under which circumstances would it be reasonable to assume that
  the average time spent per credit hour computed from the responses is
  normally distributed? Concerns: I have no idea if my answers for i and ii are correct, and I need help doing the last question. If someone can help me to understand this it will be appreciated, thanks a lot! EDITED : My profesor said that point ii and iii , there is somemting missing(wrong). I can't figure out what it is, I know that the distribution of hours can't not be normal because are all greather or equal than 0. Also I asked point ii and iii, following the thouth of Michael Hardy and Probablemy, but he said is not correct"" I'm still working on an explanation. If I found it I will posted"" Thanks for all the aswers.","['probability-theory', 'probability', 'statistics']"
1632658,Harmonic map into $S^n \times \mathbb{R}$,"Consider a harmonic map $\Phi : \Sigma \to S^n \times \mathbb{R}$, where $\Sigma$ is a surface, and the metric on $S^n \times \mathbb{R}$ is given by the product metric. Choose local spherical (polar) coordinates $\omega_1,..,\omega_n$ on $S^n$ (coming from embedding in $\mathbb{R}^{n + 1}$) in the usual way. I am trying to see what local coordinate equations would be satisfied by the coordinates $r$ and $\omega_i$. Thanks for your help. Note: Moved here from MO, please post answers here.","['reference-request', 'harmonic-functions', 'riemannian-geometry', 'differential-geometry']"
1632659,Surface Integral of a dot product in spherical coordinates,"let $k$ and $l$ be two distinct radial unit vectors.  let $k$ be fixed. Allow that $l$ may point in each and any direction on a sphere with equal probability.  Am i correct that the expected value of $k \cdot l$, $\left<k \cdot l\right> $, is $\left<k \cdot l\right> = \frac{\int_0^{2\,\pi}\int_0^{\pi}\, k \cdot l \, \sin{(\phi)} \, d\phi \,   d\theta}{4\pi}$  ? How can I evaluate this integral?","['multivariable-calculus', 'calculus']"
1632666,Cardinality of polynomials with real coefficients,"What is the cardinality of the set of all polynomials with real coefficients? I know the power set of $\mathbb{R}$ is ""more infinite"" than $\mathbb{R}$ , so to speak, but I'm unsure of how to prove that there does or does not exist a surjection onto $\mathbb{R}[X]$ from $\mathbb{R}$ . Is it equinumerous with the power set of $\mathbb{R}$ , or something else more exotic?","['infinity', 'elementary-set-theory']"
1632667,"Calculate the probability, that a man repair 20 machines in 8 hours. It is correct my work?","The problem statement said: The servicing of a machine requires two separate steps, with the time
  needed for the 1st step being an exponential random variable with mean
  10 minutes and the time for the second step being an independent
  exponential random variable with mean 15 minutes. If a repairperson
  has 20 machines to service, compute the aproximate the probability
  that all the work can be completed in 8 hours. My work: *) Let Xi be the time to service the ith machine, then E[Xi]=E[X1]+E[X2]=10+15=25min (Thanks Andre!)

 V[Xi]=V[X1]+V[X2]=100+225=325 **) Therefore, Xi is modeled by a normal r.v. with parameters E[X]=20*E[Xi]=500
 V[X]=20*V[Xi]=6500  then std=80.622 ***) Last Part Now, I know that X is the sum of 20 independent and identict distributives r.v. x1, x2 ….x20 where each xi is the time for the repair of the ith machine. P(X<8*60min)=P(z<(480-500)/80.622)=P(z<-0.248071)=  2.74855E-10 Question:
Is may procedure correct? Looks very small probability, it is right? Thanks so much for your help.","['probability-theory', 'probability', 'statistics']"
1632670,"Every automorphism of $\mathfrak{sl}(2,\mathbb{C})$ is given by conjugation with some $u \in \mathrm{SL}(2,\mathbb{C})$","Let  $\mathfrak g = \mathfrak{sl}(2, \mathbb{C})$. Let $\gamma \in \operatorname{Aut}(\mathfrak{g})$. How to show that $\gamma$ is conjugation by some $u \in \mathrm{SL}(2, \mathbb C)$?","['abstract-algebra', 'lie-algebras']"
1632697,Intuition behid $P(A\mid B)$. [duplicate],"This question already has answers here : Intuition behind the Definition of Conditional Probability (for 2 Events) (10 answers) Closed 8 years ago . What is the intuition behind the formula $$P(A\mid B)=\frac{P(A\cap B)}{P(B)}$$
I have seen this formula around, but every site/book I look at does not really have a clear & cut explanation behind this formula.","['statistics', 'probability']"
1632725,What is so special about the Schwarz Inequality?,"I am studying Spivak's Calculus and the first two problem sets have  rather lengthy,but very interesting, work-throughs of three proofs for the Schwarz Inequality: $$\sum_{i=1}^{n} x_iy_i   \leq\sqrt{\sum_{i=1}^{n}x_{i}^{2}}\sqrt{\sum_{i=1}^{n}y_{i}^{2}}$$ Spivak calls this inequality the great-grandaddy of all inequalities, but leaves it at that. I, of course, consulted wikipedia Schwarz Inequality which lists very technical explanations, but the page is listed as being incomplete an/or without proper references. Which leads me to ask, on a more basic level, what is so special about the Schwarz Inequality?","['inequality', 'linear-algebra', 'calculus', 'analysis']"
1632739,"In common tongue, what is the differences between sparse and dense matrices?","What are the differences with sparse and dense matrices in practice, so as to offer some insight to new learners on a more intuitive level. Obviously everyone knows about the dictionary definition of sparse and dense matrices (a definition based on the portion of zero/non-zero elements) But why are they so important from a mathematical application/optimization/problem solving point of view? Is it that a lot of neat algorithms are defined such that they can only be operated on a problem if it satisfies such and such criteria, and some guy just proved that sparse | dense matrices tends to satisfy the aforementioned criteria really well Or is it to do with the limited amount of computer memory available in real life, and that we must somehow ""compress"" matrices for faster computation - as such sparse matrices would be more desired Or is it just a fuzzy guideline word that mathematicians use, as opposed to strict criterion fulfilling definitions that imply X properties about the matrices (e.g. make sure the matrix is sparse and not dense because too many elements/variables too long to compute - or something to that nature?) TLDR Question: Is the only major difference as a result of computational limitation and resource savings or are there fundamental mathematical differences between the two that make one uniquely operable and the other not TLDR Answer: So essentially it revolves around our ability to compute something. so there really isn't some ""fundamental"" difference (like the difference between the first derivative or a second derivative of a function). but its just a thing that rose out of technical limitations in real life during computation.","['numerical-linear-algebra', 'matrices', 'sparse-matrices', 'numerical-methods', 'linear-algebra']"
1632763,How to go upon proving $\frac{x+y}2 \ge \sqrt{xy}$? [duplicate],"This question already has answers here : Proving the AM-GM inequality for 2 numbers $\sqrt{xy}\le\frac{x+y}2$ (5 answers) How to prove that $\frac{a+b}{2} \geq \sqrt{ab}$ for $a,b>0$? [duplicate] (3 answers) Closed 8 years ago . I'm trying to prove this but am having some difficulty. For any $x,y\in\mathbb R$ such that $x\ge 0$ and $y\ge 0$ we have
$$\frac{x+y}2 \ge \sqrt{xy}.$$ So far what I have gotten to is $\frac{x+y}{2} \geq \frac{\sqrt{xy}}{2} $ After this point I don't know what to do. To get to this point: $$y \geq 0 $$
$$\implies y \geq y$$
$$\implies xy \geq xy$$
$$\implies 2xy \geq xy$$
$$\implies x^{2} + 2xy + y^{2} \geq xy$$
$$\implies (x+y)^{2} \geq xy$$ Sqrt both sides to get: $$\implies x+y \geq \sqrt{xy}$$
$$\implies\frac{x+y}{2} \geq \frac{\sqrt{xy}}{2}$$","['algebra-precalculus', 'means', 'inequality']"
1632790,Find the sum of the $\sum_{m=k}^{+\infty}\binom{m}{k}(1-p)^k\cdot p^{m-k}$,"Let $0<p<1$,Find the sum
$$\sum_{m=k}^{+\infty}\binom{m}{k}(1-p)^k\cdot p^{m-k}$$","['power-series', 'summation', 'binomial-coefficients', 'sequences-and-series']"
1632810,Number of quadrilaterals in a heptagon: is my reasoning correct?,"I found this question on a GRE prep site: If you join all the vertices of a heptagon, how many quadrilaterals
  will you get? There is a bunch of multiple choice answers but to me none of them seem correct and since it's not an official GRE site I am inclined to think that perhaps whoever made the question might have made a mistake. First please let me explain how I understand the question: Joining all the vertices to me means to draw the complete graph of the $7$-gon. A quadrilateral is a $4$-gon. So I have to find the number of $4$-gons inside a complete graph $K_7$. I tried to count them as follows, please could someone tell me if this
  is correct or explain why it isn't? I greatly appreciate your help since this is the very first question I've tried in order to prep for the GRE and it's making me extremely nervous that I can't seem to even understand the solution. To count $4$-gons I need to first determine the total number of vertices -- that's the seven outer vertices plus all the new ones we get from intersecting lines inside. To do this I first determine the total number of lines and then determine with how many lines each lines intersects. So let's do that: Starting with a random vertex we draw $7-3=4$ outgoing lines (minus three for the current vertex and the two adjacent ones). Moving to one of the two adjacent vertices we count $7-3=4$ outgoing lines. Now we move to the other adjacent vertex of the starting (=first) vertex. We have already drawn one outgoing line (coming from the second vertex we considered). So, the number of outgoing lines is $7-3-1=3$. Moving from this third vertex to the fourth (adjacent) vertex we note that we have already drawn two incoming lines into this one: one from the first and one from the second vertex we considered. So we count $7-3-2 = 2$ outgoing lines. We move on to the fifth vertex. By similar reasoning as before we count $7-3-3=1$ outgoing line. The sixth vertex will have $7-3-4=0$ outgoing lines. Altogether we drew $1+2+3+4+4=14$ lines. (Note: by now I realise that I could have used that this is the number of edges in a complete graph minus the 6 outside edges. So, somewhere I made a mistake since I should have $15$ lines drawn inside.). Next we need to count how many points of intersection per line. So considering one particular line we note that it intersects with all lines that do not emanate from the same vertex. Per vertex there are $4$ emanating lines hence one particular line intersects with $15-4=11$ lines. Hence the number of intersection points is $11\cdot 15=165$.In addition to those we had $7$ vertices to begin with hence in total we have $165 + 7 = 172$ vertices. The number of $4$-gons to make from given $172$ vertices is 
$$ {172 \choose 4}$$ which seems a little large. I also think that $165$ points of intersection in a heptagon seems too large.","['combinatorics', 'proof-verification']"
1632858,Can a Banach measure be consistent with Friedman's Fubini-type theorem for non-measurable functions?,"I read on Wikipedia that Harvey Friedman proved that the following is consistent with ZFC+¬CH: For all functions $f:[0,1]^2 \mapsto \mathbb{R}^+$ such that both
$\int_0^1 \left ( \int_0^1 f(x,y) dy \right ) dx$ and
$\int_0^1 \left ( \int_0^1 f(x,y) dx \right ) dy$ are well-defined and exist, these integrals are equal. Is it consistent with (or even provable from) ZFC + ""the Fubini theorem for non-measurable functions""  that there is a Banach measure $\mu$ on $\mathbb{R}^2$ with the following property: For all subsets $S$ of $[0,1]^2$ such that both iterated integrals for $\chi_S$ are well-defined and exist,
$$\mu(S)=\int_0^1 \left ( \int_0^1 \chi_S(x,y) dy \right ) dx
=\int_0^1 \left ( \int_0^1 \chi_S(x,y) dx \right ) dy.$$ If there is such a Banach measure, then it would seem to satisfy most of the properties a total measure on $\mathbb{R}^2$ ""should"" have (other than $\sigma$-additivity of course), and could provide a Platonistic argument for ¬CH (in the vein of the axiom of symmetry, but more convincingly in my opinion).","['descriptive-set-theory', 'set-theory', 'measure-theory']"
1632871,which of the following is NOT a possible value of $(e^{f})''(0)$??,"Let $f$ be an analytic function on $\bar{𝐷} = \{z \in \mathbb{C}: |z| \le 1\}$. Assume that $|𝑓(𝑧)| ≤ 1$ for each $z\in \bar{D}$.
Then, which of the following is NOT a possible value of $(e^{f})''(0)$?? $(A) 2$ $(B) 6$ $(C) \frac{7}{9}e^{\frac{1}{9}}$ $(D) √2 + 𝑖√2$ So I take a look at Cauchy Integral Formula and then $$(e^{f})''(0)=\frac{1}{\pi}\int_{|z|=1}\frac{e^{f(z)}}{z^3}$$ Taking modulus on both sides we have $$|(e^{f})''(0)| \le \frac{e}{\pi}2\pi=2e$$ Hence (b) cannot be the choice. Is this alright!! Thanks for the help!","['cauchy-integral-formula', 'complex-analysis', 'inequality', 'analysis']"
1632879,How to simplify $\lim_{n\to \infty}\sum_{r=1}^n \tan^{-1} \dfrac{2r+1}{r^4+2r^3+r^2+1}$,$$\lim_{n\to \infty}\sum_{r=1}^n \tan^{-1} \dfrac{2r+1}{r^4+2r^3+r^2+1}$$ How am I supposed to do it? One thing I see here is $$\lim_{n\to \infty}\sum_{r=1}^n \tan^{-1} \dfrac{2r+1}{(r^2+r)^2+1}$$ Here derivative of $r^2+r$ is $2r+1$. (if it helps) It's final answer is $\pi/4$,"['summation', 'trigonometry', 'limits']"
1632883,"Morera's theorem, Conway's proof","I have a question about the proof of Morera's theorem as presented in Conway's text volume I. Let $G$ be a region and let $ f:G \to \mathbb{C} $ be a continuous function. Fix $ z_o$ in $G$.  Then for any $z \in G$, let $[z_o,z]$ denote a line segment from $ z_o$ to $z$.
Then,
$$\bigg| \frac{1}{z-z_o} \int_{[z_o,z]} [f(w)-f(z_o)] dw \bigg|\leq |f(z)-f(z_o)|$$ I want to ask how to establish that inequality, my attempt is this, I know that 
$$\bigg| \frac{1}{z-z_o} \int_{[z_o,z]} [f(w)-f(z_o)] dw \bigg|\leq \frac{V([z_o,z])}{|z-z_o|}~ \text{sup}\{   ~|f(w)-f(z_o)| : w \in [z_o,z] ~\} $$
where $ V([z_o,z]) $ is the length of $ [z_o,z]$. So,
$$\bigg| \frac{1}{z-z_o} \int_{[z_o,z]} [f(w)-f(z_o)] dw \bigg| \leq \text{sup}\{   ~|f(w)-f(z_o)| : w \in [z_o,z] ~\} $$ I can't show that $$\text{sup}\{   ~|f(w)-f(z_o)| : w \in [z_o,z] ~\} \leq |f(z)-f(z_o)| $$
just by the continuity of $f$. I feel that I'm just missing some simple detail to show this.  thank you.",['complex-analysis']
1632928,Find the sum $\sum _{ k=1 }^{ 100 }{ \frac { k\cdot k! }{ { 100 }^{ k } } } \binom{100}{k}$,"Find the sum $$\sum _{ k=1 }^{ 100 }{ \frac { k\cdot k! }{ { 100 }^{ k } } } \binom{100}{k}$$ When I asked my teacher how can I solve this question he responded it is very hard, you can't solve it. I hope you can help me in solving and understanding the question.","['combinatorics', 'summation']"
1632930,How to find all relations of a set and determine which of them aren't functions?,"Given the following question: ""How many relations are there on {2, 3}, that aren't functions from {2, 3} to {2, 3}?"" The answer gives 16 relations, of which 12 aren't functions. How did they conclude that?","['relations', 'functions', 'discrete-mathematics']"
1632956,How to prove $\sqrt{\frac{bc}{a+bc}}+\sqrt{\frac{ca}{b+ca}}+\sqrt{\frac{ab}{c+ab}}\geq 1$,"Let $a,b,c>0,a+b+c=1$, show that
$$\sqrt{\dfrac{bc}{a+bc}}+\sqrt{\dfrac{ca}{b+ca}}+\sqrt{\dfrac{ab}{c+ab}} \geq 1$$ I tried
$$\dfrac{bc}{a+bc}=\dfrac{bc}{a(a+b+c)+bc}=\dfrac{bc}{(a+b)(a+c)}$$
It suffice to show that
$$\sqrt{\dfrac{bc}{(a+b)(a+c)}}+\sqrt{\dfrac{ca}{(b+a)(b+c)}}+\sqrt{\dfrac{ab}{(c+a)(c+b)}}\geq 1$$","['inequality', 'a.m.-g.m.-inequality', 'substitution', 'trigonometry', 'cauchy-schwarz-inequality']"
1632969,"Prove that $f = q_1 + Gq_2$ for some $q_1, q_2 \in \mathbb{k}_{sym}(x_1,\dots,x_n)$","Suppose the orbit of the function $f \in \mathbb{k}(x_1,\dots,x_n)$ under the action of $\{\phi_\sigma\mid\sigma \in \mathfrak{S}_n\}$ has length $2$. Prove that $f = q_1 + Gq_2$ for some $q_1, q_2 \in \mathbb{k}_{\text{sym}}(x_1,\dots,x_n)$, where $G = W_n$ in case of $\mathrm{char}(\mathbb{k}) \neq 2$ and $G=F$ in case of  $\mathrm{char}(\mathbb{k}) = 2$. $$F(x_1, \dots, x_n) = \sum_{\sigma \in \mathfrak{A}_n} \prod_{i=1}^nx^{i-1}_{\sigma(i)}$$ $$W_n(x_1, \dots, x_n)= \prod_{1 \leq i < j \leq n}(x_i - x_j)$$ Honestly, i'm not really good at Galois theory, so i would be glad to hear any suggestions.","['abstract-algebra', 'galois-theory']"
1632975,Limit problem $e^x$ without L'Hôpital's rule,"$$\lim_{x \to -\infty} \frac {1-e^{x^2-x}}{1+e^{x^2-x}}$$
I solved this limit problem by applying L'Hôpital's rule and I got $-1$. Question: how to solve this limit without L'Hopital rule and Taylor series?","['limits-without-lhopital', 'calculus', 'limits']"
1632979,The map $\phi: k\rightarrow C: (y^2=x^3) \subset k^2$ over a finite field,"On page 76 of Reid's book Undergraduate Algebraic Geometry , he says that Over an infinite field $k$, the polynomial map $\phi: k\rightarrow C: (y^2=x^3) \subset k^2$ given by $\phi(t)=(t^2,t^3)$ is not an isomorphism. This is because the induced homomorphism $\phi^*: k[C]\rightarrow k[t]$ maps $k[C]$ to $k[t^2,t^3]$, where $t^2,t^3$ cannot generate $k[t]$, so $k[C]$ is not isomorphic to $k[t]$. I checked that $\phi$ is bijective by the following. Let $\psi: C\rightarrow k$ be defined by $\psi(x,y)=\frac{y}{x}$. Then
$$\phi\circ\psi(x,y)=\phi\left(\frac{y}{x}\right)=\left(\left(\frac{y}{x}\right)^2,\left(\frac{y}{x}\right)^3\right)=(x,y)\\
\psi\circ\phi(t)=\psi(t^2,t^3)=t$$ My doubts : I think the argument should work over a finite field too. I cannot see why $t^2,t^3$ can generate $k[t]$ even in a finite field. But since the author says ""over an infinite field"" at the beginning of this example, I cannot be sure whether finite field is a different case. Thank you for your help.","['algebraic-curves', 'algebraic-geometry', 'commutative-algebra']"
1633029,Is the punctured plane homotopy equivalent to the circle?,"I know that the fundamental group of $X = \mathbb R^2 \setminus \{(0,0)\}$ is the same as the fundamental group of the circle $Y = S^1$, namely $\mathbb Z$. However, $X$ and $Y$ are not homotopic, i.e. we can't find continuous maps $f:X\to Y, g : Y \to X$ such that $f \circ g$ is homotopic to $id_Y$ and $g \circ f$ is homotopic to $id_X$. I would like to prove it, but I don't really know how to do it. If such $f$ and $g$ existed, then it would be something like $f : x \mapsto x/\|x\|$, and $g(Y)$ has to be compact... I don't know how to continue. Any hint would be appreciated. I apologize if this has already been asked.","['general-topology', 'homotopy-theory']"
1633049,Another way of describing a maximal torus,"Consider the Lie group $SU(2)$. A maximal torus for $SU(2)$ is
$$T=\left\{\begin{pmatrix}e^{i\theta} & 0 \\ 0 & e^{-i\theta}\end{pmatrix}:\theta\in{\Bbb R}\right\},$$
and its Lie algebra is the maximal abelian subalgebra of ${\frak su}(2)$
$${\frak t}={\rm span}(\sigma),\quad\text{where}\quad\sigma:=\begin{pmatrix}i & 0 \\ 0 & -i \end{pmatrix}.$$
In this particular case, it is easy to verify directly that the maximal torus $T$ is the set of matrices that fixes its Lie algebra by the adjoint action, i.e.
$$
\begin{align}
T &= \{g\in SU(2):g\sigma g^{-1}=\sigma\} \\
  &= \{g\in SU(2):{\rm Ad}_g(X)=X\text{ for all }X\in{\frak t}\}.
\end{align}
$$ Question: Does this generalizes to every compact connect Lie group $G$? In other words, let $G$ be a compact connected Lie group with maximal torus $T$ and corresponding maximal abelian subalgebra ${\frak t}$. Is it true that
  $$T=\{g\in G:{\rm Ad}_g(X)=X\text{ for all }X\in{\frak t}\}?\tag{1}$$ Or is there a condition on the Lie group such that this condition holds? For example, is it true for $SU(n)$? Edit: I am able to show one inclusion. Let $G_{\frak t}$ be the right-hand side of $(1)$. Then, we have $T\subseteq G_{\frak t}$. Indeed, let $X\in{\frak t}$. Then, for all $Y\in{\frak t}$,
$$\frac{d}{dt}\Big|_{t=t_0}{\rm Ad}_{\exp tX}Y={\rm Ad}_{\exp t_0X}[X,Y]=0,$$
since ${\frak t}$ is abelian. Thus, ${\rm Ad}_{\exp X}Y=Y$ for all $X,Y\in{\frak t}$. Since $T$ is connected, it follows that $T\subseteq G_{\frak t}$.","['differential-geometry', 'lie-algebras', 'lie-groups']"
1633066,How do I calculate this limit: $\lim\limits_{n\to\infty}1+\sqrt[2]{2+\sqrt[3]{3+\dotsb+\sqrt[n]n}}$?,"I have seen this question on the internet and was interested to know the answer. Here it is : Calculate $\lim\limits_{n\to\infty}(1+\sqrt[2]{2+\sqrt[3]{3+\dotsb+\sqrt[n]n}})$? Edit : I really tried doing it but wasn't able to get somewhere. I know how to do questions like  $ y =  (1+\sqrt{1+\sqrt{1+\dotsb+\sqrt 1}}) $
and then we write $ (y-1)^2 = y $ and solve. But for this I have no method. So I would like even a sort of a hint to try to get me started, no need for answer.","['radicals', 'limits', 'limits-without-lhopital', 'nested-radicals', 'sequences-and-series']"
1633071,"Absolute value and max/min function: why $a + b + |a - b|=2\max(a,b)$? [duplicate]","This question already has answers here : Show that the $\max{ \{ x,y \} }= \frac{x+y+|x-y|}{2}$. (7 answers) Closed 8 years ago . I am being told that $a + b + |a - b|$ is equal to $2\max(a,b)$. What is the reasoning behind this?","['algebra-precalculus', 'absolute-value']"
1633109,limit of the sequence $a_n=1+\frac{1}{a_{n-1}}$ and $a_1=1$,"Problem: Find with proof limit of the sequence $a_n=1+\frac{1}{a_{n-1}}$ with  $a_1=1$  or show that the limit does not exist. My attempt: I have failed to determine the existence. However if the limit exists then it is easy to find it. The sequence is not  monotonic and I have failed to find any monotonic subsequence subsequence. The sequence is clearly bounded below by $1$. I have observed that the sequence is a  continued fraction so it alternatively increases and decreases. So, please help me.","['recurrence-relations', 'real-analysis', 'sequences-and-series', 'calculus', 'convergence-divergence']"
1633152,How are simple groups the building blocks?,"I know a bit about simple groups. A finite Abelian group is a (direct) product of finite cyclic groups. The simple finite Abelian groups are exactly $\mathbb{Z}_p$ for $p$ a prime. And so, I understand how all finite Abelian groups are made up of finite simple groups. But, from what I understand, all finite groups are in some way made up of (finite) simple groups. My question is: how does that work? What does it (more precisely) mean that a finite group is made up of simple groups? Edit : Thanks to Stefan for directing me to questions that have basically already have the answer. I have done a bit more of research on this and I think I can narrow my question a bit. I would like to understand how simple groups are the building blocks of all finite groups. That is, I would like to understand how, given a finite group $G$, one can find (or show there exists) simple groups $G_1, \dots, G_n$ such that $G$ is [insert something] of $G_1,\dots G_n$. From here , I understand now that it somehow has to do with composition series and Jordan-Holder's Theorem. I think I understand the definition of a short exact sequence. From that same question: Then $G$ is built from some uniquely determined (Jordan-Hölder) simple groups $H_i$ by taking extensions of these groups. I still don't get how this group $G$ is determined by the simple groups. I guess I am looking for more details basically putting together how one starts with a finite group $G$, ""finds"" simple groups $G_1, \dots G_n$ and then says that $G$ is isomorphic to something in terms of the simple groups.","['finite-groups', 'abstract-algebra', 'group-theory', 'simple-groups']"
1633164,Why is the Jacobian matrix equal to the matrix associated to a linear transformation?,"Given the linear transformation $f$, we can construct the matrix $A$ as follows: on the $i$-th column we put the vector $f(\mathbf e_i)$ where $E = (\mathbf e_1, \ldots, \mathbf e_n)$ is a basis of $\mathbb R^n$. Now, I read that for linear transformations, if we use the canonical basis of $\mathbb R^n$, the matrix $A$ is equal to $J f$ (the Jacobian matrix associated to $f$). It's indeed so for the few examples that I tried, but I cannot find a proof of this fact.","['matrices', 'linear-algebra']"
1633187,How to read 4th order mixed Leibniz derivative,"How exactly is the order of mixed partials read in Leibniz notation?
In Lagrange notation, we just read from left to right. $$f_{xyzz} = \left(\frac {\partial} {\partial z}\left(\frac {\partial} {\partial z}\left(\frac {\partial} {\partial y}\left(\frac {\partial f} {\partial x}\right)\right)\right)\right)$$ But what would the compacted form of Leibniz be? $$? = \left(\frac {\partial} {\partial z}\left(\frac {\partial} {\partial z}\left(\frac {\partial} {\partial y}\left(\frac {\partial f} {\partial x}\right)\right)\right)\right)$$ Here are some options that I have seen, but don't know which one is right, it seems each person I ask/website I visit has its own convention for these rather odd/rarely used cases $$\frac {\partial^4f} {\partial z^2 \partial y \partial x} = \left(\frac {\partial} {\partial z}\left(\frac {\partial} {\partial z}\left(\frac {\partial} {\partial y}\left(\frac {\partial f} {\partial x}\right)\right)\right)\right)$$ $$\frac {\partial^4f} {\partial x \partial y \partial z^2} = \left(\frac {\partial} {\partial z}\left(\frac {\partial} {\partial z}\left(\frac {\partial} {\partial y}\left(\frac {\partial f} {\partial x}\right)\right)\right)\right)$$ I personally feel that the latter is more intuitive, since it would mean both Lagrange's subscripts and Leibniz's denominator have the same order $$f_{xyzz} = \frac {\partial^4f} {\partial x \partial y \partial z^2} =\left(\frac {\partial} {\partial z}\left(\frac {\partial} {\partial z}\left(\frac {\partial} {\partial y}\left(\frac {\partial f} {\partial x}\right)\right)\right)\right)$$","['derivatives', 'partial-derivative', 'notation']"
1633221,Taylor Series in Fractional Calculus,"I recently studied fractional calculus, namely the possibility to define fractional derivatives of some functions, like $$\frac{\text{d}^{1/2}}{\text{d}x^{1/2}}\ f(x) ~~~~~~~~~~~~~ \frac{\text{d}^{2/3}}{\text{d}x^{2/3}}\ f(x)$$ and so on. Now the question that came up into my mind is: if such a construction is possible, can we built "" new "" Taylor series for well known function in order to take into account (some) fractional derivatives too? I know the first problems that would arise would be: how could we take the whole possible derivatives of order between $0$ and $1$? They are infinite. And Yeah, that could be a really huge problem.. Are there any example of Fractional Taylor Series ? P.s. I've already read other similar questions, but they are too arid and I didn't find any good answer yet..","['derivatives', 'fractional-calculus', 'taylor-expansion']"
1633233,Calculations with an exponentially-weighted moving average,"I need help figuring out the following formula: Where: CTLy = yesterdays CTL TSS = current Training Stress Score TC_c = your CTL Time Constant Now I have TSS, thats a number between 20-500 About the CTL they say: CTL is calculated as an exponentially-weighted moving average of daily TSS values, with the default time constant set to 42 days. CTL can therefore be viewed as analogous to the positive effect of training on performance in the impulse-response model, i.e., the first integral term in Eq. 1, with the caveat that CTL is a relative indicator of changes in performance ability due to changes in fitness, not an absolute predictor (since the gain factor, ka (or k1), has been eliminated). Can anyone make an example with lets say a TSS = 100 ? So let's say every day from today on I have TSS = 100 CTL_day_1 = 100 * (1-CTL_exp) + (CTL_start * CTL_exp)
 CTL_day_2 = 100 * (1-CTL_exp) + (CTL_day_1 * CTL_exp)
 CTL_day_3 = 100 * (1-CTL_exp) + (CTL_day_2 * CTL_exp) But I'm not sure what exactly will CTL_exp and CTL_start be in numbers and how will they change? Update So I figured out that I can get the desired result like so: public function ctlFilter($tss, $constant, $start){
    return $tss * (1-(exp(-1/$constant))) + $start * exp(-1/$constant);
} calling the function like: $day1 = $this->ctlFilter(100, 42, 0);
$day2 = $this->ctlFilter(100, 42, $day1); But the question remains: I would like to know what is going on ""behind the scene"". So if anyone can explain, like Alfred Einstein sayd to a 6 year old, that would be much appreciated. Thank you.","['algebra-precalculus', 'systems-of-equations']"
1633269,Vandermonde's identity? How to continue? [duplicate],This question already has answers here : Binomial coefficient problem (3 answers) Closed 8 years ago . I have: $$\sum\limits_{k = 1}^{10}k\binom{10}{k}\binom{20}{10-k} = $$ and I know that it doesn't matter if $k = 0$ so it also equals: $$= \sum\limits_{k = 0}^{10}k\binom{10}{k}\binom{20}{10-k} = $$ and now it really reminds Vandermonde's identity so it's tempting to write: $$= \binom{30}{10} \cdot \sum\limits_{k = 1}^{10}k = \binom{30}{10} \cdot 10!$$ but it seems wrong because on smaller numbers the equations doesn't hold... What's the right way to continue in order to get an equivalent expression without sigma?,"['combinatorics', 'discrete-mathematics']"
1633288,"How to solve $\int_0^{\pi/2} \ln{(x^2 + \ln^2{(\cos{x})})} \,\mathrm{d}x$ [duplicate]","This question already has answers here : Prove $\int_{0}^{\pi/2} \ln \left(x^{2} + (\ln\cos x)^2 \right) \, dx=\pi\ln\ln2 $ (3 answers) Closed 8 years ago . $$\int_0^{\pi/2}  \ln{(x^2 + \ln^2{(\cos{x})})} \,\mathrm{d}x$$ I was given this integral yesterday by someone on a forum and after a few hours of having a go at it I didn't really get anywhere significant. My first idea was to use a series of substitutions which would simply the integral into a form where taylor expansions could be used to solve it. Another idea of mine was to use complex numbers to get rid of some of the log terms, changing the $\ln^2{(\cos{x})}$ term could possibly make this integral a lot more manageable. I'd prefer if someone could help me solve this using basic methods although if there is a more complicated but elegant solution (using contour integration for example) it could still be beneficial to someone else. We don't do the equivalent of Calc III in my school so I am not very familiar with methods which go beyond the Calc II syllabus (DUDIS, Laplace ect..).","['integration', 'definite-integrals', 'contour-integration']"
1633289,Subgroups of finite index of $\mathbb Z/2\mathbb Z\times \mathbb Z$,"Let $H$ be a subgroup of index $n$ in $(\mathbb Z/2\mathbb Z)\times \mathbb Z.$ Is there finitely many subgroups of finite index of  $(\mathbb Z/2\mathbb Z)\times \mathbb Z$ ? If yes, can we find all the explicit forms possible  of the subgroup $H$  ? thanks.","['abelian-groups', 'group-theory']"
1633318,Roots of polynomials combined with Trigonometric Functions,"If $$ f(x) = x^2 + ax + d \cos x $$, where $a$ is an integer and $d$ is a real number, what are all possible values of the tuple $(a,d)$ such that $f(x)$ and $f(f(x))$ have the same set of real roots?","['roots', 'trigonometry', 'functions', 'quadratics']"
