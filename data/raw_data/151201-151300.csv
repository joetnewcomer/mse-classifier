question_id,title,body,tags
2523014,Equilateral triangle touching three sides of a square,"Consider a unit square. What is the largest, and smallest, equilateral triangle  with vertices touching the sides? Clearly the sides have to be larger than one, and it looks like the biggest would be with side $\frac{1}{\cos(\pi/12)}=\sqrt{\frac{4}{\sqrt{3}+2}}$, by placing one vertex in a corner of the square, but Is it really the biggest such triangle ? what is the smallest one? You could call it an Ikea type problem, how to fit your box into the back of the van..",['geometry']
2523021,Proving that a ratio between two functions is decreasing,"I have a question that seems to be easy, but I haven't been able to prove it. Any help would be appreciated: Let $f,g\rightarrow[0,1]$ such that $f(0)=0$, $f'(0)>0$, $f(x)\geq0$, $f''(x)\leq0$, $\forall x$ and $g(0)=0$, $g(x)\geq0$, $g'(x)\geq0$, $g''(x)\geq0$, $\forall x$. 
  Prove that $\frac{f(x)}{g(x)}$ is decreasing. I tried to use the property that say: if $\frac{a}{b}<\frac{c}{d}$ then $\frac{a+c}{b+d}<\frac{c}{d}$. I used it with the fact that $f(x)=f(0)+\lim_{n\to \infty} \sum_{i=0}^{n-1} f'(\frac{ix}{n})\frac{x}{n}$ . With this two elements I can prove that if $\lim_{x\to 0} \frac{f(0)}{g(0)}$ exists,, then the solution is true. However, I haven't been able to prove it for the general case. Any help is greatly appreciated.","['derivatives', 'convex-analysis', 'limits']"
2523063,Summation about transcendental equation's positive real roots,"If $a_i$ are positive real roots of transcendental equation$$\left( {\cos x} \right)\left( {\cosh x} \right) + 1 = 0.$$And we have $0<a_1<a_2<a_3<\cdots$, prove:
  $$\sum_{i=1}^{\infty}{a_{i}^{-6}\left(\frac{\sin a_i-\sinh a_i}{\cos a_i+\cosh a_i}\right)^2}=\frac{1}{80}.$$ First, we have$${\left( {\sinh {a_i}} \right)^2} = {\left( {\cosh {a_i}} \right)^2} - 1 = \frac{1}{{{{\cos }^2}{a_i}}} - 1 = {\tan ^2}{a_i} \Rightarrow \sinh {a_i} = \left| {\tan {a_i}} \right|.$$ If $\sinh {a_i} = \tan {a_i}$, we obtain$${\left( {\frac{{\sin {a_i} - \sinh {a_i}}}{{\cos {a_i} + \cosh {a_i}}}} \right)^2} = {\left( {\frac{{\sin {a_i} - \tan {a_i}}}{{\cos {a_i} - \frac{1}{{\cos {a_i}}}}}} \right)^2} = {\tan ^2}\frac{{{a_i}}}{2}.$$ If $\sinh {a_i} = -\tan {a_i}$, we obtain$${\left( {\frac{{\sin {a_i} - \sinh {a_i}}}{{\cos {a_i} + \cosh {a_i}}}} \right)^2} = {\left( {\frac{{\sin {a_i} + \tan {a_i}}}{{\cos {a_i} - \frac{1}{{\cos {a_i}}}}}} \right)^2} = {\cot ^2}\frac{{{a_i}}}{2}.$$
In fact, both cases will happen.","['real-analysis', 'sequences-and-series', 'calculus', 'power-series', 'analysis']"
2523096,Positive sectional curvature & finite isometry group,Is there a known example of a compact Riemannian manifold with positive sectional curvature that doesn't have continuous symmetry (i.e. there are no nontrivial Killing fields)? I'm more interested in the case when the manifold is even-dimensional (related to the Hopf conjecture on Euler characteristic) but I'd be interested in the general case as well.,"['riemannian-geometry', 'differential-geometry']"
2523133,Convergence in measure iff every subsequence has a convergant subsequence,"My task is to show that on a finite measure space $(X,A)$, if $f_n \to f$ in measure, then every subsequence of $\{f_n\}$ has a subsequence that converges to $f$ almost everywhere. I believe I was successful in showing the converse, but one thing confuses me: I saw proof in my textbook that if $f_n \to f$ in measure, then there is a subsequence that converges to $f$ a.e. However my problem asks that every subsequence of $f_n$ have a convergant subsequence. I think I'm getting myself confused after thinking of subsequences of subsequences for too long, and a fresh take on things would be very helpful. I think I remember seeing someone say that it should be a consequence of Egorov's Theorem, but I don't see how that is since it assumes pointwise convergence a.e. so how could it be used to prove it?","['sequence-of-function', 'real-analysis', 'measure-theory']"
2523198,Fallacious proof involving trigonometry,"Which step in the following incorrect proof is fallacious? Is it something with the use of indefinite integrals or with the domain and range of trignometric functions? I encountered this fallacious proof here . $$
\int\tan(x)\,dx=\int\tan(x)\,dx
$$ substitute $\tan(x)$ : $$
\int\tan(x)\,dx=\int\sin(x)\sec(x)\,dx
$$
Integrate by parts, assume $$
u=\sec(x),dv=\sin(x)\,dx
$$ Therefore,
$$
\int\tan(x)\,dx=-\sec(x)\cos(x)+\int\cos(x)\tan(x)\sec(x)\,dx
$$
but $\cos(x)\sec(x)=1$ so: $$
\int\tan(x)\,dx=-1+\int\tan(x)\,dx
$$
we subtract both sides by $\int\tan(x)\,dx$ : $$
\int\tan(x)\,dx-\int\tan(x)\,dx =-1+\int\tan(x)\,dx-\int\tan(x)\,dx
$$ then: $0=-1$ Thanks in advance for any help.","['fake-proofs', 'trigonometry', 'calculus', 'proof-explanation', 'trigonometric-integrals']"
2523221,Lipschitz Continuous Diffeomorphism,"Denote the real line by $\mathcal{R}$. I look for non-trivial examples of functions $f:\mathcal{R}\longrightarrow\mathcal{R}$ that are Lipschitz continuous, differentiable and with non-vanishing derivative. By trivial examples I mean the ones of the form $f(x):=ax+b$ for $a,b$ real numbers.","['derivatives', 'real-analysis', 'calculus']"
2523234,Show that $ \ d(d \omega)=0 \ $,"If $ \ \omega=f(x,y,z)dx+g(x,y,z)dy+h(x,y,z)dz \ $ and $ f, \ g , \ h \ $ are smooth functions on $ \mathbb{R}^3 \ $ , then show that $ \ d(d \omega)=0 \ $. Answer: $$ d \omega=df \wedge dx+dg \wedge dy+dh \wedge dz$$ or  $$d \omega=(\frac{\partial f}{\partial x}dx+\frac{\partial f}{\partial y}dy+\frac{\partial f}{\partial z}dz) \wedge dx + (\frac{\partial g}{\partial x}dx+\frac{\partial g}{\partial y}dy+\frac{\partial g}{\partial z}dz) \wedge dy + (\frac{\partial h}{\partial x}dx+\frac{\partial h}{\partial y}dy+\frac{\partial h}{\partial z}dz) \wedge dz $$  or 
$$d (\omega)=(\frac{\partial h}{\partial y}-\frac{\partial g}{\partial z}) dy \wedge dz+ (\frac{\partial f}{\partial z}-\frac{\partial h}{\partial x}) dz \wedge dx + (\frac{\partial g}{\partial x}-\frac{\partial f}{\partial y}) dx \wedge dy $$ Next I can not proceed to show $ d(d\omega)=0 \ $ anyhow ? Help me out","['multivariable-calculus', 'differential-forms', 'differential-geometry', 'exterior-algebra']"
2523235,Verifying solution of Heat Equation,"Let $\theta$ be such that $0<\theta<1/2$. Show that $$F(t,x)=\int_{-\infty}^{+\infty}\exp[i\tau t-(i\tau)^{1/2}x-(i\tau)^\theta]d\tau$$
defines a $C^\infty$ function in $\mathbb{R}^2$ which solves the homogeneous heat equation $F_t=F_{xx}$. Also show that $F$ can be written as $$\int_{-a-i\infty}^{a+i\infty}\exp[-zt-z^{1/2}x-z^\theta]dz$$
where complex integration is performed over the vertical straight line $\text{Re} z=-a$ where $a>0$. How to proceed with this question ?","['heat-equation', 'linear-pde', 'ordinary-differential-equations', 'complex-integration']"
2523287,Liapunov's Function and kind of Stability,"Problem : Using the right Liapunov's Function V find the kind of stability of the non-linear system:
  $$ x'=\sin(x+y) $$ $$y'=-\sin(x-y)$$ given the Liapunov's function: $$V=x\cdot y $$ So, I don't have any experience on this type of exercices and I don't know even how to start the exercice.I know that i have to differentiate  the liapunov's function $$V=x\cdot y$$ so i take :$$V'=Vx\cdot x'+Vy\cdot y'$$ but i don't find the reason and i don't know if it's right too. I would really appreciate a thorough solution and explanation, since I've just started working on Liapunov's functions and Liapunov's stability and I have to clear my mind on them.I have to say that my dynamical's system book doesn't have problems of these types so to proceed.Thanks in advance!","['dynamical-systems', 'stability-theory', 'systems-of-equations', 'stability-in-odes', 'ordinary-differential-equations']"
2523331,Find conditions for a surface of rotation to be regular,"I am reading Geomtric Structures in Dimension two by Bjørn Jahren, and have some questions about exercise 5.1.4, which says the following: Let $\alpha(u)=(f(u),g(u)),u\in[a,b]$ be an embedded curve in the $xz$-plane such that $f (u) > 0$ for all $u$. Find a parametrization of the surface of rotation obtained by rotating $\alpha$ around the $z$–axis and find conditions for this to be a regular surface. Discuss what happens if we remove the condition $f (u) > 0$. A regular surface is defined by the following: Definition 5.1.3. Let $S$ be a subset of $\mathbb{R}^3$ which is also a smooth surface, and let $\iota: S \to\mathbb{R}^3$ be the inclusion map. $S$ is called a regular surface if for every local parametrization $x$ of $S$ the Jacobian of the composition $\iota\circ x$ has rank 2 at every point. A parametrization of this surface is given by $(u,t)\mapsto(f(u)\cos(t),f(u)\sin(t),g(u))$. By the definition of regular surfaces, we need the Jacobian of this parametrizationto be of rank 2. The Jacobian has the columns $(f'(u)\cos(t),f'(u)\sin(t),g'(u))$ and $(-f(u)\sin(t),f(u)\cos(t),0)$. If $g'(u)\neq0$ they are linearly independent if and only if $f(u)\neq 0$, since $\sin$ and $\cos$ are not 0 in the same point. If $g'(u)=0$ linear independence is equivalent to the matrix $\begin{bmatrix}
f'(u)\cos(t) & -f(u)\sin(t)\\
f'(u)\sin(t) & f(u)\cos(t)
\end{bmatrix}$ having nonzero determinant, i.e. that $f(u)f'(u)\neq 0$. To conclude, the Jacobian has rank 2 if and only if $g'(u)\neq0\land f(u)\neq0$ or $f(u)\neq0\land f'(u)\neq 0$. Under the condition $f(u)>0$, that is if and only if $\alpha'(u)\neq 0$. Where do I go from here? I have found conditions given one specific parametrization, but I need to show it for all possible parametrizations. How do I generalize the result? (( EDIT : Maybe this suffices, since I can create an atlas with just this parametrization, by varying the domain?)) What about the points $a$ and $b$ are mapped to? Can I find a parametrization from an open subset of $\mathbb{R}^2$ around these? And what happens if we remove the condition $f(u)>0$, how should I attack that? Here is a handwritten (i.e. not so readable) and brief solution which may be of some use: (Available here .)","['differential-geometry', 'surfaces']"
2523362,Prove that the union of relations is an equivalence relation,"Let $\{\alpha_i \mid i\in \mathbb N\}$ is family of equivalence relations on the set $A$ such that for every $i \in N$ $\alpha_i\subseteq\alpha_{i+1}$. Prove that the union of all $\alpha_i$ is equivalence relation on $A$. Whenever there are problems involving family of relations I'm clueless. I know that we obviously need to prove reflexivity,symmetry and transitivity but other than that I can't even begin.","['relations', 'equivalence-relations', 'elementary-set-theory']"
2523391,Why must be the additive and multiplicative identities in a field be different?,I was recently reading about fields like $\mathbb {Z}_p$ and I'm wondering what's the reason they can't be the same element. Is it about the additive identity being the only element with no multiplicative inverse? To be honest it's the only thing that comes to mind but it still doesn't tell me why it should be like that.,"['abstract-algebra', 'field-theory']"
2523417,The subset that $m(E \cap I) \geq \alpha m(I)$ has measure 1.,"I'm stucked in this question: If $E$ is a Lebesgue measurable set contained in the interval $[0,1]$ and there is a $\alpha>0$ such that $m(E \cap I) \geq \alpha m(I)$ for all open intervals $I \in [0, 1]$ then $m(E) = 1$. How should I proceed to prove this?","['lebesgue-measure', 'measure-theory']"
2523420,"Show that $\int_0^\pi f(\sin x)\,\mathrm{d}x = 2\int_0^{\pi/2}f(\sin x) \, \mathrm{d}x$ [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Any tips on how to show that $$\int_0^\pi f(\sin x) \, \mathrm{d}x = 2\int_0^{\pi/2} f(\sin x) \, \mathrm{d}x \text{ ?}$$","['definite-integrals', 'integration', 'trigonometry', 'trigonometric-integrals']"
2523462,Normal approximation of a mixture of normal distributions,"I have noticed that sometimes mixtures of normal distributions can be approximated very well by a simple normal distribution. For instance, the mixture of the normal distributions $\mathcal{N}(0,1)$ and $\mathcal{N}(1,1)$ (with both distributions having a weight $w_i$ of 0.5) is well approximated by $\mathcal{N}(0.5,1.2544)$; the density functions of both distributions differ by about 0.004 or less over the whole continuum. My question is, under which conditions is such a normal approximation of a mixture of normal distributions possible?","['statistics', 'probability-distributions']"
2523527,Sections of a Vector Bundle and Equivariant Maps on the Frame Bundle,"Throughout we work in the smooth setting. Let $\pi:E\to M$ be a rank $k$ real vector bundle and $F(E)\to M$ denote the corresponding frame bundle. I am trying to understand the following statement, which is taken from this wikipedia article, under the heading ""Relation to Principal and Ehresmann Connections."" The sections of $E$ are in one to one correspondence with the equivariant maps $F(E)\to \mathbf R^k$. (This can be seen by considering the pullback of $E$ over $F(E)\to M$, which is a trivial bundle isomorphic to $F(E)\times \mathbf R^k$). I don't see how the correspondence comes about, and especially how the triviality of the pullback bundle gives it. What I can see is that if we have a section $\sigma$ of $E$, then we can define a map $F(E)\to \mathbf R^k$ which sends $(p, T)\in FE_p$ to $T^{-1}(\sigma(p))$. But I am unable to get a map in the reverse direction. Can somebody please help, especially elucidating as to how the triviality of the pullback comes to our rescue.","['principal-bundles', 'connections', 'vector-bundles', 'differential-geometry']"
2523550,how to prove $\left | \sqrt[n]{a}- \sqrt[n]{b}\right |\leq \sqrt[n]{\left | a-b \right |}$,"$$\left | \sqrt[n]{a}- \sqrt[n]{b}\right |\leq \sqrt[n]{\left | a-b  \right |},n\in \mathbb{N^{*}},a,b\geq 0\\$$ I failed to prove it,  so if someone could prove it and explain it to me, it would be great.","['real-analysis', 'inequality', 'algebra-precalculus', 'proof-writing', 'absolute-value']"
2523612,Series unchanged by rearrangement implies absolute convergence?,"If a series converges absolutely, then it is known that the value of the series is independent of rearrangements. More precisely, if $\sum |a_n| < \infty$ and $\sigma:\Bbb N\to \Bbb N$ is a bijection then $\sum a_{\sigma(n)}$ converges and its value is independent of $\sigma$ . Now what about the converse? That is,  if $\{a_n\}_{n=1}^\infty$ is an arbitrary real or complex sequence such that for every bijection $\sigma$ of $\Bbb N$ , we have $\sum a_{\sigma(n)}$ converges to the same value,  is it true that $\sum a_n$ coverges absolutely? I am interested in this in the context of signed measures on a measurable space à la Stein's and Shakarchi's definition of signed measures in their third volume on real analysis.",['real-analysis']
2523660,Intersection of a set that contains the floor function,"I'm trying to solve the next question: For all $m\in I=(0,1)$ there is a subset $A_m \subseteq \mathbb{R}$ that $A_{m} = \{ a\in \mathbb{R} : a-\lfloor a \rfloor < m \} $. Find $\bigcap\limits_{m\in I} A_{m}$ So I think that the solution is $\bigcap\limits_{m\in I} A_m=\mathbb{Z}$, and I tried to prove it like this: let $x\in\mathbb{Z}$ then $-x\leq-\lfloor x\rfloor<1-x$. Therefore $0=-x+x\leq x-\lfloor x\rfloor<x+1-x=1$, so for every $m\in I, x\in A_{m} $ and then $x\in\bigcap\limits_{m\in I} A_{m}$, so $\mathbb{Z}\subseteq \bigcap\limits_{m\in I} A_{m}$. Now I need to prove that $\bigcap\limits_{m\in I} A_{m} \subseteq \mathbb{Z}$, but how?",['elementary-set-theory']
2523707,Low bound for Serre's vanishing of $\mathcal{O}_X$,"Let $X$ be a projective variety over a noetherian ring and let $L=\mathcal{O}_X(1)$ be a very ample line bundle. If $F$ is a coherent sheaf on $X$ Serre's vanishing theorem tells us that there is $n_0$ depending on $F$ s.t. for $i>0$ and $n \geq n_0$, $H^i(X,F(n))=0$. Let $F=\mathcal{O}_X$, how to find $n_0$ that works in this case? Is it true that $n_0=1$? In other words a very ample line bundle does not have any higher cohomology.","['coherent-sheaves', 'algebraic-geometry']"
2523733,Solving systems of differential equations with laplace transform,"I'm working on the system: $dx/dt=x-2y$, $x(0)=-1$ $dy/dt=5x-y$, $y(0)=6$ This seems like it should be easy to solve and yet I'm struggling. I am trying to use the Laplace transform and I have done this to every term but I get stuck when you I need to put everything in terms of $X(s)$ and $Y(s)$.",['ordinary-differential-equations']
2523742,Rooks on an incomplete chessboard,"I encountered this problem earlier today. Suppose we have an 8x8 chessboard, and 10 rooks. We fill in some of the squares on the board such that it's impossible to place the 10 rooks on empty squares so that every empty square on the board either contains a rook or is being attacked by a rook (Rooks cannot attack through a filled in square). Find the minimum number of squares we must fill in. It seems like the answer is 5 (as stated below in the answers) Is there a nice combinatorial proof to this result? Can we generalize this to other numbers of rooks (e.g. 16)?","['combinatorics', 'extremal-combinatorics']"
2523765,Extend multiple probability measures to a single probability measure on a bigger sigma algebra,"Suppose that $\mu_i$ is a probability measure on $(X,\Sigma_i)$, $i=1,2$. Here $X$ is an arbitrary set, and $\Sigma_i$ is a $\sigma$-algebra of $X$. I want to ask under what conditions, the following is true: There exists a probability measure $P$ on $(X,\sigma(\Sigma_1\cup\Sigma_2))$ such that $P$ agrees with $\mu_1$ and $\mu_2$. That is, $P(E)=\mu_i(E)$ if $E\in\Sigma_i$. $\sigma(\Sigma_1\cup\Sigma_2)$ is the smallest $\sigma$-algebra generated by $\Sigma_1\cup\Sigma_2$. Clearly, we must have whenever $E\in\Sigma_1\cap\Sigma_2$, $\mu_1(E)=\mu_2(E)$. What are the additional conditions sufficient for the existence of such $P$? Does any one know any reference for such result? More generally, what can we say when, in stead of just $i=1,2$, we have general index $i$ (countable or uncountable)? In particular, I wonder if the following condition is sufficient? $\Sigma_1\cap\Sigma_2=\{X,\emptyset\}$","['probability-theory', 'measure-theory']"
2523774,Induced Orientation of Boundary of Manifold,"I am trying to work through the following problem: Let $M$ be the cylinder $S^1 \times [0,1]$ with counterclockwise orientation when viewed from the exterior. I am trying to figure out the boundary orientation on the $C_0 = S^1 \times \{0\}$ and on $C_1 = S^1 \times \{1\}$. I am not sure how to find an orientation form on the cylinder, as it seems to be different from the other manifolds I have worked with. Also, what would be the outward pointing vectors on the boundary? This is the image associated with the problem:","['multivariable-calculus', 'general-topology', 'differential-geometry', 'manifolds']"
2523782,Is there a natural topology in which the analytic continuation of a series converges everywhere it is defined?,"The expression $$
\sum_{n=1}^\infty n = -\frac{1}{12}
$$ has been met with considerable controversy. Previous questions (such as this and this ) searching for a way of rationalizing the formal convergence of this series in some metric space. My question is more general. Given a function expressed as a series, for example $\zeta(s) := \sum_{i=1}^\infty n^{-s}$, which converges over some domain $D$, construct its analytic continuation $\bar{\zeta}$ to $\mathbb{C}\setminus S$ where $S$ is a set of singularities. Is there a natural topology on $\mathbb{C}$ in which $\sum_{n=1}^\infty n^{-s}$ converges to $\bar{\zeta}(s)$ for all $s\in \mathbb C \setminus S$? More specifically, is there a natural topology on $\mathbb{C}$ in which $\sum_{n=1}^\infty n = -\frac{1}{12}$? I am very aware that one can construct a metric in which $\sum_{n=1}^\infty n$ converges to $-1/12$, as is done here . But this is not interesting: one can define a metric so that $\sum_{n=1}^\infty n$ converges to anything. Given that the analytic continuation of a series is unique, it seems intuitively plausible at least that it is at least in principle possible to define a topology in which the series converges everywhere to its analytic continuation. Can this be done?","['complex-analysis', 'analytic-continuation', 'divergent-series']"
2523793,Show that a complete metric space without isolated points is uncountable,"I've seen a few questions already posted on here, but they all deal with perfect subsets and being Hausdorff, both of which are topics we haven't covered yet. I know that a point a is isolated if $\{a\}$ is open (aka there exists $\epsilon > 0$ s.t. $B_{\epsilon}(a) = \{a\}$.  I am supposed to consider singletons and then use Baire Category Theorem. Could someone help me with where to start?","['general-topology', 'baire-category']"
2523815,Self-adjoint operator as difference of two positive operators,"The problem comes from my functional analysis homework. Let $H$ be a complex Hilbert space and $A:H \to H$ be a bounded, self-adjoint linear operator. Prove that there exist positive operators $P$ and $N$ such that $A=P-N$ and $PN=0$. (An operator $T$ is positive if $\langle Tx,x \rangle \ge 0$ for all $x \in H$.) I found a question similar to this one: Bounded self adjoint operator can be written as difference of positive operators . An answer using $C^*$-algebra was provided there. However, we didn't learn anything on $C^*$-algebra in this class (and I know nothing about it), so the problem is supposed to be proven in an ""elementary"" way. Here is what I have done so far: Define $B=(A^2)^{1/2}$, and let
$$P=(A+B)/2$$
$$N=(B-A)/2$$
Then $P$ and $N$ are bounded, self-adjoint linear operators. It is easily verified that
$$A=P-N$$
and
$$PN=0$$
My question: how can we prove that $P$ and $N$ are positive? By direct calculation, this is equivalent to $|\langle Ax,x \rangle| \le \langle Bx,x \rangle$. @Shalop said in the comments that this inequality can be proven with polarization identity, but I don't see how to do that. Any ideas?","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'adjoint-operators']"
2523832,Intuitive explanation of a Pascal's triangle result,"We know that, in Pascal's triangle, the sum of all the elements of row $n$ is equal to $2^n$, i.e.:
$$\sum^n_{k=0} {n \choose k}=2^n. $$ Is there an intuitive explanation for why is this true?","['combinatorics', 'binomial-coefficients']"
2523898,Durett's proof of Skorokhod’s representation theorem,"I have a question on Skorokhod’s representation theorem in Durrett's Probability: Theory and Examples ( https://services.math.duke.edu/~rtd/PTE/PTEv5a.pdf starting at page 347). It says below: part 1 of proof part 2 of proof I don't understand the circled equation (part 2 of proof). It looks like the expectation is taken over $(-\infty,0) \times (0,\infty)$, with probability measure defined in (8.1.1). But the function whose expectation is taken depends on measures induced by points in $\mathbb{R}^2$.
What kind of technique is this? Can anyone give me a rigorous (non-intuitive) justification? Any reference is appreciated!","['probability-theory', 'probability-distributions', 'measure-theory', 'brownian-motion', 'convergence-divergence']"
2523932,How to show that $\|f+g\|_p=\|f\|_p+\|g\|_p$ implies $f$ and $g$ are positively linearly dependent?,"Suppose $1<p<\infty$ and let $f,g\in L^p$. It is said in Wikipedia that
$$
\|f+g\|_p=\|f\|_p+\|g\|_p\tag{*}
$$
if and only if $f=cg$ for some $c\geq 0$ or $g=0$. The ""if"" direction is trivial. I would like to prove the other direction. (I believe this must have been asked before but I can't find one here.) Suppose (*) is true. By the triangle inequality
$$
\|f+g\|_p\leq\||f|+|g|\|_p\leq\|f\|_p+\|g\|_p
$$
and thus
$$
\|f+g\|_p=\||f|+|g|\|_p
$$
which yields $|f+g|=|f|+|g|$ almost everywhere. Suppose $g\neq 0$. Then for a.e. $x$, one has
$$
f(x)=a(x)g(x)
$$
for some $a(x)\geq 0$. I'm stuck here with showing that $a(x)$ is a constant.","['functional-analysis', 'real-analysis', 'lp-spaces']"
2523988,How to normalize the matrix?,"I have this matrix,
\begin{equation}
T=\begin{bmatrix}a&b\\-b&-a\end{bmatrix}
\end{equation} To normalize it, the matrix $T$ must satisfy this condition: $T^2=1$ and $1$ is the identity matrix. To solve that I set $x^2T^2=1$ and solve for x which is $\frac{1}{\sqrt{a^2-b^2}}$.  The normalized matrix is 
\begin{equation}
T=\frac{1}{\sqrt{a^2-b^2}}\begin{bmatrix}a&b\\-b&-a\end{bmatrix}
\end{equation} The next matrix P is a bit different,
\begin{equation}
P=\begin{bmatrix}c+a&b\\-b&c-a\end{bmatrix}
\end{equation}
Can this matrix P be normalized for the same condition $P^2=1$?",['linear-algebra']
2523993,Derivative Solution,I understand the first step but at the second step how do they come to negative one in the numerator? Also why do they show the definition of derivative again for step 2? How does this produce a negative one?,['derivatives']
2524006,A and B have 10 dollars each. They bet 1 dollar each time. A wins the final game iff B has no money left.,"For each bet, A has prob = 0.5 to win the 1 dollar from B. and prob = 0.5 to lose 1 dollar to B. How to calculate the probability that A wins the final game? How about for the initial state A has 20 dollars and B has 10 dollars , what's probability that A wins the final game? How about A and B still have 10 dollars each, and A has prob = 0.6 to win each bet, what's probability that A wins the final game? Thanks!","['statistics', 'probability']"
2524048,Working out the limits of a triple integral - a volume bounded by a plane in the first octant,"I'm attempting to do the following exercise: And am now fairly aware now that the hardest part about solving these types of problems is understanding the bounds you are integrating in. Firstly, I try and draw a horrendous sketch of what I believe we're integrating in. I note: Intercepts: $x = h/a$, $z=h$, $y=h/b$, found by setting two variables equal to $0$ and solving for the other one. With $x=0$, $z = -by + h$. With $y=0$, $z = -ax + h$. With $z=0$, $y = -ax/b + h/b$ Keeping this in mind, here is the sketch I drew out what I think this is: Now, where the confusing part comes in (assuming I'm making sense so far). I need to note the order of integration I'd find would be most straightforward. My plan of attack is to make a line from the ends of $x$ within the object at $z=0$, which would involve integrating $x$ first, then moving it along $y$, so that it feels the trapezoid-looking figure at $z=0$. Then, I'll integrate in $z$, and have the entire volume filled. So, I'll try and establish some limits. For $x$, our first line goes from $by = -ax +h$, which arranges for $x$ to $x=-\frac{b}{a}y+h/a$ to the minimum value of $x$, which is the intercept $x=h/a$. For $y$, our line is scaled in $y$ from the $xz$ plane to the $yz$ plane to fill the area of the base of this figure. Finally, for $z$ our volume is made from scaling the area of the trapezoid from 0 to $h$. Thus, our limits are: $$-(\frac{b}{a}y+h/a) \le x \le h/a$$ and for $y$.. according to my thinking, it integrates from $z = -ax+h$ to $z = -by + h$ which means one of my limits cannot be expressed in terms of $y$ and $z$ which means I can't get a integrate the final $z$ integral properly since I'll have an $x$ term in it. Where am I going wrong? Is the sketch wrong? Are my thought processes wrong? If so, which? I have a feeling my sketch is wrong, as this object doesn't exactly strike me as a plane. Also, the bottom figure is not necessarily a trapezoid, as $b \ne a$ necessarily.","['multivariable-calculus', 'integration', 'definite-integrals', 'volume']"
2524053,"find if a function is injective or surjective, involving a set of all functions as well as the power set of the domain.","For $n \in \mathbb{N}$, let $A = \{a_1, a_2, a_3, · · · , a_n\}$ be a set and let $F$ be the set of all functions $f : A \rightarrow \{0, 1\}$ from
$A$ to $\{0, 1\}$. What is the size of $F$?
Now, for $P(A)$, the power set of $A$, consider the function $g : F \rightarrow  P(A)$, defined as
$g(f) = \{a \in A : f(a) = 1\}$.
Is $g$ injective? Is $g$ surjective? My answer to the first part is: There are $2^n$ number of ways to make a function $f$. Since $F$ is the set of all functions $f$, then 
$|F| = 2^n$. The second part of this question has me a bit perplexed. My attempt so far: $g$ takes an element from $F$ and maps it to an element in $P(A)$. Now clearly we can tell that $A$ has a cardinality of $n$ elements. By the definition of a power set, $|P(A)| = 2^n$. Because we are told $g$ is a function, then all elements in $F$ to a unique element $p$ in $P(A)$. Thus $g$ can map all elements in $F$ to a unique element in $P(A)$ as both sets contain $2^n$ elements. This particular arrangement makes $g$ both injective and surjective. However, $g$ could also map two unequal elements in $F$ to a single element in $P(A)$. This would make $g$ neither injective or surjective. Note, these are the only possibilities. $g$ can only be both injective and surjective or neither injective or surjective. The possibility of $g$ being injective but not surjective or vice-versa does not exist.","['proof-explanation', 'discrete-mathematics']"
2524058,Volume of the region lying inside circular and parabolic cylinders,"I have the following problem: Find the volume of the region lying inside the circular cylinder $x^2+y^2=2y$ and inside the parabolic cylinder $z^2 = y$. To solve the problem, I did the following: $x^2+y^2=2y \implies x^2 +(y-1)^2=1$. So we have a circle centered at $(0,1)$. I think writing volume $V=\displaystyle\int_{-1}^{1}\int_{-2}^2(?)dA$ is not useful at this point. We have $z^2 =y$ too so the lower bound for $y$ must be $0$. So, how can I calculate the volume, i.e., write down a double integral? Thanks.","['multivariable-calculus', 'integration', 'calculus']"
2524078,Prove $e^\alpha = \lim_{n\to\infty}(1+\frac{\alpha}{n})^n$ from first principles.,"Prove $$e^\alpha = \lim_{n\to\infty}(1+\frac{\alpha}{n})^n$$ from first principles. I know the proof for $e^1$, so in particular how could a generic formula for that limit (either with squeeze theorem, or just basic manipulation of your choice) lead to the general formula above? Feel free to use whatever proof you want, as long as it is generally understandable for people with only a beginning/intermediate understanding of calculus.","['exponential-function', 'limits']"
2524085,projection-valued measure and bounded self-adjoint operator,"Let $E$ be a projection-valued measure on Borel sets of $\mathbb{R}$ and assume $E([-R,R]) = \text{id}$ for some $R$. For each $x\in \mathcal{H}$, define the Boreal measure $\nu_x(B) = \left\lVert E(B)x\right\rVert^2$. How to show that there exists a bounded self-adjoint operator $T$ in $\mathcal{H}$ such that $$\langle Tx,\, x\rangle = \int_\mathbb{R} \lambda \;dv_x(\lambda)$$","['functional-analysis', 'spectral-theory', 'operator-theory']"
2524098,"If $f^3$ measurable, show $f$ is measurable (Check my solution please)","I am new on this site. I am wondering if my solution is correct. I know we can do this using the fact that composition of continuous functions with a measurable one is measurable, but I want to see if my reasoning is correct for this specific example. 
Let X be a set, with sigma algebra $A$.
Suppose $f: X\to \mathbb{R}$, and suppose $f^3$ is measurable. Then show that $f$ is measurable. My attempt: Let $a \in \mathbb{R}$, we will show $\{x: f(x)<a\}$ is measurable. Now $\{x: f(x)<a\}=\{x: f^3(x)<a^3\}$. But $\{x: f^3(x)<a^3\}$ is measurable as $f^3$ is measurable. Hence since $a$ is arbitrary and the intervals $(-\infty,b)$ generate the borel sigma algebra, $f$ is measurable. Thanks in advance. And if its not correct, please tell me why. Edit: The sigma algebra on R is assumed to be the Borel sigma algebra.","['borel-sets', 'real-analysis', 'measure-theory', 'analysis']"
2524105,Understanding Random Walks and Related Theorems/Definitions,"I'm reading Durret's book, chapter 4 on Random Walks.  Rather than spending time dwelling in my sorrow and frustration over how bad I think this book is, I think I'll take to Stack Exchange to help me understand some things. I'm going to ask several questions over three posts so that it's more likely for people to respond. Also, I did not know anything about Random Walks before reading this book.(Maybe that's relevant?) If $(S,F,\mu)$ is a measure sapce, Durret tells us that for this section our probability space is $\Omega = S^{\mathbb{N}}$ $($i.e sequences of elements of $S)$ where $F^{\mathbb{N}}$ is the corresponding $\sigma$ algebra, and $P = \mu \times \mu ...$ is our measure.  Lastly, $X_n(\omega) = \omega$ Given a finite permutation, $\pi$, of $\mathbb{N}$, Durret refers to an event $A \in F^\mathbb{N}$ being permutable for any finite permutation $\pi$ provided $\pi^{-1}(A) = A$.  The collection of such events is called the exchangeable $\sigma$ field. Ok cool. According to Durret, if $S = \mathbb{R}$ and $S_n(\omega) = X_1(\omega) + X_2(\omega) + ... X_n(\omega) = \omega_1 + \omega_2 + ...$ $1:\{\omega: S_n(\omega) \in B \ \ i.o \}$ is permutable;however, it's not a tail event. As expected, Durret does not say what $B$ is. I assume its just some subset of $S$ though. I don't understand why it's not a tail event. Please explain this if you can. $2$: In his proof of the Hewitt-Savage $0-1$ law, Durret says that we can choose $A_n \in \sigma(X_1,...X_n)$ such that $P(A_n \Delta A) \to 0$ I don't understand what the sets $A_n \Delta A$ looks like and why $A_n$ can be chosen so that $P(A_n \Delta A) \to 0$ I'll stop here and ask more questions on another post.","['random-walk', 'probability-theory', 'probability', 'probability-distributions']"
2524146,Simplify to terms of generalized power mean,"I have the following expression${}^1$ I'd like to simplify
$$r \equiv \left[ \frac1{x\sqrt{x}} \left( 1 - \frac{k}{x} \right) - \frac1{y\sqrt{y}} \left( 1 - \frac{k}{y} \right) \right]\left[ \frac1{\sqrt{x}} \left( 1 - \frac{k}{x} \right) - \frac1{\sqrt{y}} \left( 1 - \frac{k}{y} \right)\right]^{-1}$$
where $x > y > k\geq 1$. Some attempts led me to think that $r$ can be expressed nicely in terms of generalized means of $x,y$ like the harmonic ($p=-1$), geometric ($p \to 0$), and other powers:${}^2$
$$\begin{align}
H &\equiv \left( \frac1x + \frac1y\right)^{-1} & G &\equiv \sqrt{xy} & M \equiv \left( x^p + y^p \right)^{1/p} \quad \text{with perhaps} \quad p=\frac{-1}2
\end{align}$$ To be specific, my question is this: Is there a way to write it in this form $$r \overset{?}{=} \frac1x + \frac1y + \frac1{\sqrt{xy}} + {}\color{red}{??} =\frac1H + \frac1G + {}\color{red}{??} $$   such that the $\color{red}{??}$ part is ""nice"" in terms of $k$ and maybe $H,G$ or $M$ defined above? I also wonder if there's some standard techniques like examining the asymptotic form to guess the coefficients of the proposed terms. I tried a bit but didn't get very far. Directly pulling out $\frac1H$ and $\frac1G$ just change $r$ into something equally inviting but not more compact. Any suggestions will be appreciated. Honestly, one main reason for me to think that ""oh there must be some nice and more compact forms"" is the glaring symmetry. I will be okay if there turn out to be none. Thanks. Footnote 1: $\quad$For the record, $r$ is part of the expression of the ratio between $\frac{\partial^2 f(u)}{ \partial u^2}$ and $\frac{\partial f(u) }{ \partial u}$, evaluated at $u=0$, where $$f(u) = \left( \frac1{\sqrt{u+y}} - \frac1{\sqrt{u+x}} \right)\sqrt{u+k}$$ Footnote 2: $\quad$This is a slight abuse of notations, as the generalized means should carry the averaging factors $\frac12$ or $\frac1{\sqrt{2}}$. My shorthands can also match the p-norms, which has the benefit of the norms ordered in powers have correspondingly decreasing magnitudes. However, p-norms doesn't cover $\sqrt{x y}$ like generalized mean. Update (Nov.28th, 2017) With all the inverses lying around, it turns out that the best way is to express $r$ in terms of the ... you guessed it ... inverses: $v \equiv 1/x$ and $w \equiv 1/y$. I'll spare the readers of the actual algebra. Suffice to say that this is also the natural course to take to adopt the notions of p-norms; one just have to give up on unifying $1 / \sqrt{xy} = 1/G = \sqrt{vw}$ formally.","['algebra-precalculus', 'calculus']"
2524150,Show that a smooth map $f:\mathbb{R}^m\to \mathbb{R}^n$ for $m>n$ cannot be injective,"Some caveats: I am looking for a solution that uses smoothness. I know a way to prove it assuming only Borsuk Ulam with only continuity assumed. I was hoping for a more elementary solution that uses differentiability specifically. Some things I have tried: I wanted to relate the problem to linear algebra somehow, maybe with some sort of partial converse to the inverse function theorem. In the examples I can think of where this would fail (say $f(x)=x^3$ with trivial linearization at $0$) there aren't many ""bad"" points. I am not sure how to pick the good ones however. Next, I tried something using Sard's theorem to find some regular values, and an $m-n$ dimensional manifold, after which the conclusion would be immediate. However, there is no reason to believe that these regular points should be in the image of $f$, i.e. a map 
$$
f:\mathbb{R}^3\to \mathbb{R}^2
$$
taking everything to the real axis. Any thoughts and help would be appreciated.","['multivariable-calculus', 'geometric-topology', 'real-analysis', 'differential-topology']"
2524154,"Prove that $|\mathbb{R}| = |(0, 1)|$.","Prove that $|\mathbb{R}| = |(0, 1)|$. (Hint: Consider the tangent function.) This is my current thought process: Using the hint, I map $(0, 1) \rightarrow (-\frac{\pi}{2},\frac{\pi}{2})$ by the function $f(x) = \pi x - \frac{\pi}{2}$, and
  then state that since $f$ is linear, and bijective, it must be that -- somehow --
  $|\mathbb{R}| = |(0, 1)|$. Do I have the general idea? Or am I way off?","['elementary-set-theory', 'cardinals', 'logic', 'functions']"
2524157,How does the failure of integral closure of a coordinate ring relate to the cusp/singularity we see in the corresponding variety?,"Consider the affine variety with coordinate ring $R=\mathbb{C}[x,y]/(y^2-x^3)$. It is clear that the coordinate ring $R$ is not integrally closed since $t=y/x$, an element of the corresponding quotient field, is a root of an integral equation. What is the geometric intuition relating the failure of $y/x$ to belong to $R$ and the cusp we see on the graph of $y^2-x^2=0$?",['algebraic-geometry']
2524163,How many reflex angles can a polygon have? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I think the first of the polygons that can have a reflex angle is the pentagon. For a hexagon, a maximum of 2 reflex angles is possible. 
   I tried to draw many concave polygons to find out a relation, but I got stuck. Is there a formula for this?","['algebra-precalculus', 'angle', 'polygons', 'geometry']"
2524171,Are compact subsets closed in the one-point compactification of $\mathbb{Q}$?,"Let $\omega\mathbb{Q}$ denote the one-point compactification of $\mathbb{Q}$, where $\omega$ is a point not in $\mathbb{Q}$, and define a topology $\tau$ on $\omega\mathbb{Q}$ by
$$ \tau=\{U\subseteq \mathbb{Q}\ |\ U\text{ is open in }\mathbb{Q}\}\cup \{\omega\mathbb{Q}\backslash K\ |\ K\text{ is a compact subset of }\mathbb{Q}\}.$$ Is it true that any compact subset of $\omega\mathbb{Q}$ is then closed? If $C\subseteq \omega\mathbb{Q}$ is compact and $\omega\notin C$, I think that $C$ will then be compact in $\mathbb{Q}$, so the complement of $C$ is an element of $\tau$, hence $C$ is closed. However, if $\omega\in C$, I'm not sure what to do. I think I'd need to show the complement of $C$ is an open set in $\mathbb{Q}$, which I believe to be true, but I can't prove this explicitely.","['general-topology', 'compactification', 'rational-numbers', 'compactness']"
2524197,Finitely generated nilpotent group where every element is of finite order is finite,"Let $G = \langle g_1,g_2,\ldots,g_m\rangle$ be a nilpotent group, where each $g_i$ has finite order.  Prove $G$ is finite. I'd like to show this by showing that the lower central series has successive quotients that are finite, i.e., $$|\gamma_n(G) / \gamma_{n+1}(G)| < \infty$$ I'm going to show this by induction.  I'm on the base case $$\gamma_1(G)/\gamma_2(G) = G/[G,G]$$ Any reason why this should be finite?  Any idea how I can argue that $\gamma_{n+1}(G) / \gamma_{n+2}(G)$ should be finite in the inductive step, assuming $\gamma_n(G) / \gamma_{n+1}(G)$ is finite?","['abstract-algebra', 'group-theory', 'finitely-generated']"
2524218,Area of shaded region of circles inscribed in a circle,"I was given this question and told to find the area of the shaded region. The radius of the white circles is r that are arranged in a pyramid with N rows. ATTEMPT: When N=1, area = $\pi r^2$ N=2, area = $2\pi r^2$ N=3, area = $3\pi r^2$ N=4, area = $4\pi r^2$ Question: How can we find the area of the larger circle? Is there an implicit relationship between the smaller and larger circles that I'm missing?","['circles', 'trigonometry', 'geometry', 'contest-math', 'recreational-mathematics']"
2524248,Intersection of Power set and Power set of power set.,"If $\mathscr P(S)$ denotes power set of a set $S$ then is $\mathscr P(S) \cap \mathscr P(\mathscr P(S)) = \{\emptyset\}$ ? My book says its true. I considered a simple set $S=\{1,2\}$ Now $\mathscr P(S) = \{\emptyset, \{1\}, \{2\}, \{1,2\}\}$ $$
\mathscr P(\mathscr P(S))= \{\emptyset,\{\emptyset\}, \{\{1\}\}, \{\{2\}\},\{\{1,2\}\}, \{\{1\}\,\{2\}\}, \{\{1\},\{1,2\}\}, \{\{2\},\{1,2\}\} , \ldots\}
$$ Now $\mathscr P(S) \cap \mathscr P(\mathscr P(S))=\emptyset$ and not $\{\emptyset\}$ . So I think that above claim is wrong. If I go by theorem of power set intersection which says $\mathscr P(A) \cap \mathscr P(B)=\mathscr P(A\cap B)$ and put $A=\mathscr P(S)$ and $B=\mathscr P(S)$ , then I get $$
\mathscr P(S) \cap \mathscr P(\mathscr P(S)) = \mathscr P(S \cap \mathscr P(S)) = \mathscr P(\emptyset)={\emptyset}. 
$$ So if I go by theorem, then the claim seems to be correct. Where am I making a mistake?",['elementary-set-theory']
2524325,Functions such that $f(ax)=f(x)+f(a)$,"I thought of this question somewhat randomly on a walk, and have discussed it with another friend of mine (we both have pure mathematics degrees). We have made some headway, and we think we have generated a proof, but we would appreciate any additional insight and proof verification. Let $f:\mathbb{R}\to\mathbb{R}$ be a continuous function such that $f(ax)=f(x)+f(a)$. How much can we say about the behavior of $f(x)$? What additional restrictions, if any, allow us to show $f(x)=\log_b(x)$? We conjecture that, with the restriction that $f$ is not $0$ everywhere, $f$ must be the logarithm. We have, by the log rules, $$\log_b(|ax|)=\log_b(|x|)+\log_b(|a|)$$ So the logarithm is indeed one such $f$. I will give what we have been able to show about $f$ below, followed by our general proof. If you can offer any insight into this problem, we would greatly appreciate it. Edit: Turns out this can be shown fairly easily by considering the Cauchy Functional Equation and showing $g(x)=f(e^x)=cx$ for some $c$. The proof given below does not use this fact. From here on, we assume $f$ is not trivial. Result 1: $f(1)=0$ We note that $$f(a)=f(a\cdot1)=f(1)+f(a)$$ which shows $f(1)=0$. Result 2: $f(0)$ is not defined We see that $$f(0)=f(a\cdot0)=f(0)+f(a)$$ which implies $f(a)=0$ for all $a$. However, we have assumed $f(x)\neq0$ for some $x$, giving a contradiction. Thus $f(0)$ must not be defined. So, we redefine $f$ as $f:\mathbb{R}\setminus\{0\}\to\mathbb{R}$. Result 3: $f(-x)=f(x)$ If we allow $x<0$, we then have $$0=f(1)=f(-1\cdot-1)=2f(-1)$$ Showing that $f(-1)=0$ as well. Using this result, we have $$f(-a)=f(-1)+f(a)=f(a)$$ Our Proof: From here on, we use results from elementary abstract algebra and analysis. We realized that the condition on $f$ is that of a group homomorphism $\varphi:(\mathbb{R}\setminus\{0\},*)\to(\mathbb{R},+)$ where $$\varphi(xy)=\varphi(x)+\varphi(y)$$ Similarly, you can show the above results for $\varphi$. We noted that if we also define the continuous group homomorphism $\psi:(\mathbb{R},+)\to(\mathbb{R}\setminus\{0\},*)$ where $$\psi(x+y)=\psi(x)\psi(y)$$ $\psi$ and $\varphi$ seem like they could possibly be inverses with some additional restrictions. We see that $$\psi(x)=\psi(0+x)=\psi(0)\psi(x)=1$$ So that $\psi(0)=1$. We can then say for any integer $n\geq0$, $$\psi(n)=\psi(1+1+1+...+1)=\psi(1)\cdot\psi(1)\cdot\cdot\cdot\psi(1)=\psi(1)^n$$ Note, $\psi(1)<0$ may give us complex results, so we restrict $\psi(1)>0$. For any integer $n<0$, $$\psi(n)=\psi(-1-1+...-1)=\psi(-1)^{|n|}=(\psi(1)^{-1})^{|n|}=\psi(1)^{-|n|}=\psi(1)^n$$ Then, for any rational number $\frac{p}{q}$, $$\psi(\frac{p}{q})=\psi(\frac{1}{q})^p=\psi(q^{-1})^p=(\psi(q)^{-1})^p=\psi(1)^{\frac{p}{q}}$$ Let $x\in\mathbb{R}\setminus\mathbb{Q}$. Since the rationals are dense in the reals, we can find rational $\frac{p}{q}<x<\frac{r}{s}$ arbitrarily close to $x$. Note that $\psi$ is strictly increasing over the rationals, and thus $$\psi(1)^{\frac{p}{q}}<\psi(x)<\psi(1)^{\frac{r}{s}}$$ Since $\psi$ is continuous, this implies $\psi(x)=\psi(1)^x$ for all $x\in\mathbb{R}$. Therefore, $$\psi(x)=\psi(1)^x$$ This shows that $\psi$ must be the exponential function. Note that it is completely characterized by its value at $1$.  Noting that $\varphi$ seems like it should be related to the inverse of $\psi$, we would expect $\varphi(x)=\log_b(x)$. We note that for integer $n\geq0$ and real $a>0$, $$\varphi(a^n)=\varphi(a)+\varphi(a)+...+\varphi(a)=n\varphi(a)$$ For $n<0$, we have $$\varphi(a^n)=\varphi(\frac{1}{a})+...+\varphi(\frac{1}{a})=|n|\varphi(a^{-1})=-|n|\varphi{a}=n\varphi(a)$$ The rational case is slightly trickier. We note that $a^{\frac{n}{n}}=a$, and thus $$\varphi(a)=\varphi(a^{\frac{n}{n}})=n\varphi(a^{\frac{1}{n}})$$ And thus $\varphi(a^{\frac{1}{n}})=\frac{1}{n}\varphi(a)$. Therefore, for any rational $\frac{p}{q}$ $$\varphi(a^{\frac{p}{q}})=p\varphi(a^{\frac{1}{q}})=\frac{p}{q}\varphi(a)$$ Using the same argument as before, we can extend this to all $x\in\mathbb{R}$. Therefore, $$\varphi(a^x)=x\varphi(a)$$ Combining these, we have $$\varphi(\psi(x))=\varphi(\psi(1)^x)=x\varphi(\psi(1))$$ Thus, $\varphi$ and $\psi$ are inverses up to multiplication by a constant, which confirms that $\psi$ must be the logarithm. If we restrict $\varphi(\psi(1))=1$, these are exactly inverses. If $\psi(1)>0$, we must have $\varphi_{\psi(1)}(x)=\log_{\psi(1)}(x)$. This proof requires that $x>0$. However, we showed earlier that $\varphi(-x)=\varphi(x)$, and for positive $x$, $\varphi_b(x)=\log_b(x)$. To make this function even, we modify it as $$\varphi_b(x)=\log_b|x|$$ and this is the only possible continuous solution for $\varphi$ defined on all of $\mathbb{R}\setminus\{0\}$. In other words, $f$ must be the logarithm. We have shown the logarithm rules are unique to logarithms! One thing that concerns us is the restriction that $f$ is continuous. Are there discontinuous $f$ that satisfy this property? Please let us know if we made any invalid assumptions somewhere, or if our statements about the uniqueness of these functions is incorrect. We would also appreciate any alternate proofs you may have.","['real-analysis', 'alternative-proof', 'logarithms', 'abstract-algebra', 'proof-verification']"
2524343,Finding dimension of the vector spaces of polynomials with two commuting variables as well as two non-commuting variables,"Let $V$ (resp. $W$) be the real vector space of all polynomials in two commuting (resp. noncommuting) variables with real coefficients and of degree strictly less than $100$. What are the dimensions of $V$ and $W$? My approach : To calculate dimension of $V$ We just have to count number of basis elements in the basis of $V$. The basis elements of $V$ are of the form $x^iy^j$ where $i,j\in \Bbb N \cup \{0\}$ and $i+j \le 99.$ Case-1)For $i=0$, we have $0 \le j \le 99.$ i.e we have $100$ choices for $j$. Case-2)For $i=1$, we have $0 \le j \le 98$. i.e. we have $99$ choices for $j$. Case-99)For $i=98$, we have $0 \le j \le 1$. i.e. we have $2$ choices for $j$. Case-100)For $i=99$, we have $j=0$ as the only $1$ choice. By addition rule, we get $\text {number of elements in the basis of V} = 1+2+3+...+100=\frac {100(101)}2=5050=\dim V.$ To calculate dimension of $W$ Again we count the number of basis elements in the basis of $W$. But here $x^iy^j \neq y^jx^i \; \forall \; i,j \ge 1.$ Thus we count number of basis elements for $x^i,y^j \; \forall i,j \ge 1$ only and then multiply the same by $2$. We first count number of elements in the list $x^0, x^1, x^2,...x^{99}$ which is $100$ and number of elements in the list $y^1,y^2,...,y^{99}$ which is $99$. For the $x^iy^j \;\;\; i,j \ge 1$ part we proceed as follows, Case-1)For $i=1,$ we have $1 \le j \le 98.$ i.e. we have $98$ choices for $j$. Case-2)For $i=2,$ we have $1 \le j \le 97.$ i.e. we have $97$ choices for $j$. Case-97)For $i=97$, we have $1 \le j \le 2$ i.e. we have $2$ choices for $j$. Case-98)For $i=98$, we have only $1$ choice for $j$ i.e. $j=1$. Therefore by addition rule we have $1+2+3+...+98=\frac {98(99)}2=4851$ choices. As per our argument above, we have considered only $x^iy^j$ part. Thus $y^jx^i$ part also has $4851$ choices. $\therefore \text {Total number of elements in basis of W}=199+2 \times 4851=9901=\dim W$ Is my approach correct? EDIT : As it has been pointed out in comments by @NickPavlov, I have messed up in non-commuting case. I have left out elements such as $xyx^2$, $yxyxyxy^5$ etc. How should I count this kind of elements?","['alternative-proof', 'proof-verification', 'combinatorics', 'contest-math', 'linear-algebra']"
2524355,show that $\{ nq^{\frac{1}{3}} \} + \{ nq^{\frac{2}{3}} \} \geq Cn^{-\frac{1}{2}}$,"Let $q$ be a positive integer which is not a perfect cube. Prove that there exists a positive constant $C$ such that for all natural numbers $n$, one has
$$\{ nq^{\frac{1}{3}} \} + \{ nq^{\frac{2}{3}} \} \geq Cn^{-\frac{1}{2}}$$
where $\{ x \}$ denotes the fractional part of $x$","['number-theory', 'diophantine-approximation']"
2524364,Elementary properties of absolute value operator,"Let $T$ be a bounded linear operator on a Hilbert space. Define $|T| = (T^*T)^{1/2}$. I know $|T|$ is well-defined because $T^*T$ is a positive operator, so the positive square root exists. This is probably a trivial question, but why is $|T|$ bounded and linear? I don't see how to manipulate it because it is defined as a square root.","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
2524404,Find all irreducible representations of SO(2),"As per the title I wish to describe all of the irreducible representations of the group $SO(2)$ . As a first guess I would say that the following rep is irreducible. $$\text{Let }~~~\mathcal{D}\colon SO(2)\rightarrow GL(2,\mathbb{R}),
~~ \mathcal{D}(R):=R.$$ This representation acts on the vector space $\mathbb{R}^2$ , and, as one can imagine, there are no vectors which lie in the plane and that are invariant under all rotations in the plane (except for the trivial zero vector) thus there is no non-trivial invariant subspace and this representation is irreducible. But then since $SO(2)$ is an Abelian group, by Schur's lemma its irreps are one-dimensional, which is in clear contradiction to the above. I suspect this is because Schur's lemma applies only to complex vector spaces. So it is correct to say that with regards to real representations $\mathcal{D}$ is irreducible, but not with regards to complex representations. So is the question as stated in the title ill-defined, and the word real or complex representations must be inserted? This question appeared in an exam, when phrased in this way does one usually assume real representations is meant? If so then would I be correct in using $\mathcal{D}$ or the isomorphism $SO(2)\cong U(1)$ and thus irreps are labelled by an integer? EDIT Let $$\Psi\colon U(1)\rightarrow SO(2);\quad \Psi(e^{i\phi})=\begin{pmatrix}\cos(\phi)&\sin(\phi)\\-\sin(\phi)&\cos(\phi)\end{pmatrix}$$ be the map that establishes the isomorphism $U(1)\cong SO(2)$ . Denote the (complex) irreps of $U(1)$ by $\mathcal{T}^{(n)}$ where $$\mathcal{T}^{(n)}:U(1)\rightarrow GL(1,\mathbb{C})\cong\mathbb{C}^*;~~~\mathcal{T}^{(n)}(e^{i\phi})=e^{in\phi},~~n\in\mathbb{Z}.$$ Denote the (real) irreps of $SO(2)$ by $\mathcal{D}^{(n)}$ where $\mathcal{D}^{(n)}\colon SO(2)\rightarrow GL(2,\mathbb{R})$ and $$\mathcal{D}^{(n)}\bigg(\begin{pmatrix}\cos(\phi)&&\sin(\phi)\\-\sin(\phi)&&\cos(\phi)\end{pmatrix}\bigg)=\begin{pmatrix}\cos(n\phi)&&\sin(n\phi)\\-\sin(n\phi)&&\cos(n\phi)\end{pmatrix}.$$ Now $\mathcal{T}^{(n)}$ acts on the vector space $\mathbb{C}$ whilst $\mathcal{D}^{(n)}$ acts on the vector space $\mathbb{R}^2$ and since $\mathbb{C}\cong\mathbb{R}^2$ we can use $\Psi$ to show that the irreps are the same: $$\mathcal{D}^{(n)}\cong \Psi \circ\mathcal{T}^{(n)}.$$ Does this show that the complex and real irreps of $SO(2)$ are the same, or have I shown something else? Does this result generalize?","['representation-theory', 'group-theory']"
2524463,Change of coordinates for a first order linear PDE,"Given a linear PDE of order 1 with $C^ \infty$ real coefficients in a neighborhood of the origin in $\mathbb{R}^n$ : $$L=\sum_{j=1}^{n}\alpha_j(x)\frac{\partial}{\partial x_j}$$
Suppose that at least one of the coefficients $\alpha_j$ does not vanish at the origin. Show that there is a $C^\infty$ change of variables $x \to y$ in a nbhd of the origin s.t. $L$ in y-coordinates is $w(y)\frac{\partial}{\partial y_1}$ with $w(0)\neq 0$. Is it always possible to choose the  coordinates y so as to have $w(y) \equiv 1$ near $y=0$ ? ATTEMPT:I have solved the above problem for the constant coefficients case that is $\alpha_j$ are constant. For the variable case, how do I proceed ?","['functional-analysis', 'coordinate-systems', 'partial-differential-equations']"
2524493,"Why are second order linear PDEs classified as either elliptic, hyperbolic or parabolic?","Is there a geometric interpretation of second order linear partial differential equations which explains why they are classified as either elliptic, hyperbolic or parabolic, or is this just a naming convention? That is, do they have any relation with actual ellipses, hyperbolas and parabolas?","['intuition', 'partial-differential-equations', 'terminology', 'geometry', 'ordinary-differential-equations']"
2524505,Maximising the area of a triangle with its vertices on a parabola.,"Let $A\equiv (4,-4)$ and $B\equiv(9,6)$ be tw points on the parabola $y^2 = 4x$. Let $C$ be a point on the parabola between $A$ and $B$ such that the area of the triangle $\triangle ABC$ is maximal. What are the coordinates of $C$? The  parametric coordinates of C are $(t^2 , 2t)$. Using Shoelace formula , I get the area of the triangle to be $5t^2 -5t$. But this has no global maximum? In this case, what shluld I do?","['optimization', 'analytic-geometry', 'algebra-precalculus', 'maxima-minima', 'area']"
2524520,What is the probability that the first head will appear on the even numbered tosses,Question $\text{Consider a coin with probability R to be heads. What is the probability}$ $\text{that the first head will appear on the even numbered tosses?}$ My Approach let the required Probability $=P$ . Hence we can write our eauation as-: $$P=(1-R) \times R+(1-R) \times (1-R) \times (1-R) \times P $$ $$P(1-(1-R) \times (1-R) \times (1-R))=(1-R) \times R $$ $$P=\frac{(1-R) \times R }{(1-(1-R) \times (1-R) \times (1-R)}$$ Am i correct? Answer is given as-: $$P=\frac{(1 - R)}{(2 - R)}$$,"['probability-theory', 'probability']"
2524530,Cyclotomic polynomial : $\Phi_n(x^m)= \prod_{d\mid m} \Phi_{dn}(x)$,"Show that if $m, n$ are positive integers and $\text{gcd} (m,n)=1$, then $$\Phi_n(x^m)= \displaystyle\prod_{d\mid m} \Phi_{dn}(x)$$ My attempt : By formula, $x^n-1 = \displaystyle\prod_{d\mid n} \Phi_{d}(x)$ $x^n-1 - \displaystyle\prod_{d\mid n} \Phi_{d}(x) = 0$ $x^n-1 - \displaystyle\prod_{d\mid n} \Phi_{d}(x) + \Phi_{n}(x)= \Phi_{n}(x)$ $x^{nm}-1 - \displaystyle\prod_{d\mid n} \Phi_{d}(x^m) + \Phi_{n}(x^m)= \Phi_{n}(x^m)$ Please suggest how to proceed.","['number-theory', 'polynomials']"
2524556,Applying Riemann-Roch on the tangent bundle,"Recently, I encountered the version of the Riemann-Roch theorem for line bundles $\mathscr L$ on a compact Riemann surface $X$:
$$\dim H^0(X,\mathscr L) - \dim H^1(X,\mathscr L) = 1 - g + c_1(\mathscr L),$$ with $c_1$ the first Chern-number. I wonder if we can use this formula to derrive properties of the tangent bundle and the vector fields on $X$? I first wanted to use that the top Chern class is the Euler-class, i.e. the first Chern number of the tangent bundle is the Euler characteristics. But then I realized, that the tangent bundle is only complex, but not holomorphic, so in fact, we need to set $\mathscr L = T^{(1,0)}X$, the holomorphic part of $TX$ in order to apply Riemann-Roch. Can we still make some general statements about $c_1(\mathscr L)$ and if yes, what does the resulting formula tell us? Edit: I made some progress on this questionm however I am not sure about the meaning of the results. Maybe someone can provide some background information. As the holomorphic tangent bundle $\mathcal{T}_X$ is the dual of the canonical bundle $\Omega_X$, it follows that $c_1(\mathcal T_X)=-c_1(\Omega_X) = 2-2g=\chi(X)$. Thus we get $c_1(\mathcal T_X)=c_1(TX) = c_1(T^{1,0}X \oplus T^{0,1}X) = c_1(T^{1,0}X)+c_1(T^{0,1}X)$, so $c_1(T^{0,1}X)=0$. What does this mean (maybe in regards to curvature)? This also implies, that for $g\ge 2$, $\dim H^0(X,\mathcal T_X)=0$, so there is no global holomorphic section of the tangent bundle in this case, i.e. no global holomorphic vector field. Using Riemann-Roch, we get:
$$\dim H^0(X,\mathcal T_X)- \dim H^1(X,\mathcal T_X) = 1-g+c_1(\mathcal T_X)=3-3g. $$
As for $g=1$, $\mathcal T_X$ is trivial, it follows that $\dim H^0(X,\mathcal T_X)=1.$ For $g=0$, $X=\mathbb P^1$ and $\Omega_{\mathbb P^1}=O(-2)$, so $\mathcal T_{\mathbb P^1} = O(2)$, which is given by the homogeneous polynomials in $z_0,z_1$ of degree $2$. Thus $\dim H^0(X,\mathcal T_X) = 3.$ In conclusion: 
$$\dim H^1(X,\mathcal T_X) = 
\begin{cases} 0 &&g=0 ,\\1 && g=1, \\3g-3 && g\ge 2.
\end{cases}$$ Is this information any useful or can this be motivated by some geometric insights? Maybe there is a short exact sequence of vector bundles/sheaves starting with $\mathcal T_X$, so atleast in the case of $g=0$ one can conclude surjectivity of map.?","['riemann-surfaces', 'complex-geometry', 'algebraic-geometry', 'holomorphic-bundles']"
2524614,Simplifying a set and proving it,"Let $A$ be a set defined as the intersection $$\bigcap_{n\in\mathbb N}\{x \in\mathbb R | -1/(2^n) < x < 1+ n| n \in N\}$$ Not I believe it's $(0, 1]$ but I could only prove that $(0,1]$ is a subset of the intersection above(A), but I can't prove that A is a subset of $(0,1]$. I proved that for basically for any natural number:
$-1/(2^n) > 0$
and $1 + n\geq 1 $ But I am stuck from here on",['elementary-set-theory']
2524644,What does intrinsic and extrinsic mean?,"When I read books of geometry, I sometimes find the term ""intrinsic"" and ""extrinsic"" but don't understand them precisely. What are definitions of them? Are intrinsic properties more important than extrinsic properties?","['terminology', 'differential-geometry', 'geometry']"
2524648,Deriving the maximum likelihood estimator,"Suppose $X_1, X_2, X_3 \stackrel{\text{i.i.d.}} \sim \operatorname{Exp}(\theta)$. Exercise: derive the maximum likelihood estimator based on $X = (X_1, X_2, X_3)$. What I've tried: the likelihood is given by $\prod\limits_{i = 1}^3 f(X_i\mid \theta) \, d\theta = \prod\limits_{i = 1}^3 \theta e^{-3\theta x} \, d\theta$. The log-likelihood is given by $\log L = 3\log\theta - 3\theta x \log(e) = 3\log\theta - 3\theta x.$ Take the derivative and set it equal to $0$ and I get $\hat{\theta} = \frac{1}{x}$. My question: How do I derive the maximum likelihood estimator based on $X = (X_1, X_2, X_3)$? I know my solution is probably not correct, but I don't know what else I should try.","['maximum-likelihood', 'probability-theory', 'probability', 'statistics']"
2524693,Distance between a real number and a whole number,"Prove that if $a$ is real and $n$ natural. The distance between one of the numbers $a,2a,3a,...,na$ and a whole number is  at most $\frac{1}{n}$. This is a problem from discrete math, but hints from analysis would be appreciated.",['discrete-mathematics']
2524712,Maximum number of edges in a graph where length of every cycle is a multiple of 3,"I am doing a problem which asks to find the maximum number of edges in a graph on $n$ vertices which has the property that every cycle's length is a multiple of 3. I was able to show that if $G$ contains a cycle $C$ then that cycle $C$ can not contain a chord.
The answer is $n-1$ +$\left\lfloor{\frac{(n-1)}{2}}\right\rfloor$ edges. I proceed by induction and assumed the result is true for graph on n vertices.
Then if G has $n+1$ vertices then I reduced the problem into three cases: There exists a vertex in G of degree 1 ( then induction takes us home) $\delta(G)$ $\geq$$3$ where $\delta(G)$ is the minimum degree of $G$ (by observing that in this case $G$ must contain a cycle with a chord) When neither of the first two cases hold.
I am stuck with this case. Help?","['combinatorics', 'graph-theory', 'extremal-graph-theory']"
2524725,"Evaluate the triple integral $\iiint_E x\,dV$ where $E$ is bounded by the paraboloid $x=4y^2+4z^2$ and the plane $x=4$.","Evaluate the triple integral
  $$\iiint_E x\,dV$$
  where $E$ is bounded by the paraboloid $x=4y^2+4z^2$ and the plane $x=4$. I have been analyzing the part of my book where it evaluates triple integrals for paraboloids non stop, but I can't seem to figure out the method for setting it up. (and solving) I have a feeling one of the integrals will be the paraboloid given as an upper bound and the plane given as a lower bound, but I'm not sure how to get the other bounds without having to manually graph a bunch of points till i can see where everything intersects. I remember setting equations to each other to get intersections but I'm not sure how to apply that here. If someone could show me a detailed explanation of how to set this up (and solve) it would help a lot. Thanks. Edit: I have a feeling I'm supposed to put for my outer integral $x$ is from $0$ to $4$, and my inner integrals I use the $\pm$ solutions for $y$ and $z$. Is that right? But I'm not sure how to solve it from here.","['multivariable-calculus', 'integration', 'euclidean-geometry', 'calculus']"
2524815,Why do Laurentseries with $p$-adic coefficients that converge on some given annulus form a ring,"Let $L(r_1, r_2)$ be the set of Laurentseries with entries in $\mathbb{Q}_p$ that are convergent on some annulus $r_1<|x|<r_2$. The question is why $L(r_1, r_2)$ together with formal addition and multiplication forms a ring? I am getting stuck, trying to show that this set is closed under multiplication. So say we have two series $a=\sum_{i\in \mathbb{Z}}  a_i x^i$  and $b=\sum_{i\in \mathbb{Z}}  b_i x^i$. The product would be $a\cdot b= \sum_{i\in \mathbb{Z}} (\sum_{j\in \mathbb{Z}}  a_j b_{i-j})x^i$. But why is $\sum_{j\in \mathbb{Z}}  a_j b_{i-j}$ an element of $\mathbb{Q}_p$? This would be the case if $ |a_j b_{i-j}|\to 0$ as $j\to \pm \infty$. But I do not see why this would be true and how to use that the sequences are convergent somewhere.","['abstract-algebra', 'p-adic-number-theory', 'functions']"
2524816,Can we learn things about coefficients of cyclotomic polynomials from Sylow Theory?,"I am required to prove the following (which I believe was originally a result of Migotti): Let $p,q$ be distinct primes. Show that the $pq$th cyclotomic polynomial has coefficients all -1, 0 or 1. Show moreover that if n is a product of at most two distinct primes then the $n$th cyclotomic polynomial has coefficients -1,0 or 1. I have got an expression for the $pq$ case of $\frac{\Phi_q(t^p)}{\Phi_q(t)}$ where $\Phi_q(t) = 1+t+t^2+...+t^{q-1}$. I could slog through dividing that out, but it won't be pretty. I'm wondering if there is some deeper connection with Sylow theory that I could use, as the conditions look somewhat reminiscient of conditions on group order. Is it possible to formulate this usefully as a Sylow Theory problem?","['galois-theory', 'abstract-algebra', 'cyclotomic-polynomials', 'sylow-theory', 'cyclotomic-fields']"
2524826,"Show that $M^m + A = M^{m+1}$ with $M,A$ matrices?","Let $M,A$ denote matrices with
$$
M = \left(\begin{array}{cc}
1 & 1 \\
0 & 1
\end{array}\right),
~~~~
A = \left(\begin{array}{cc}
0 & 1 \\
0 & 0
\end{array}\right).
$$ Show that $$M^m + A = M^{m+1}.$$ $~$ Context: I encountered this problem when trying to prove that $M^m = E_2 + mA$ (1) by induction (where $E_2$ is the $2\times 2$ identity matrix. Adding $A$ on both sides yields $M^m + A = E_2 + mA +A =E_2 + (m+1)A$. Equation (1) would follow if $M^m + A = M^{m+1}$.","['matrix-equations', 'matrices', 'mathematical-physics', 'induction', 'linear-algebra']"
2524833,Cutting numbers into parts,"Let $x_1,x_2,\dots,x_n$ be positive integers written on a line, and $k\leq n$ a positive integer. Can we always cut the numbers into $k$ parts according to the line ordering to satisfy the following property: For each part, there is a number at one of the two ends of the part that if we remove it, then the sum of the numbers in the part is no greater than the sum of the numbers in any other part? An idea is to use induction on $k$. For $k=1$ we don't need to cut anything, so the statement is trivially true. For larger $k$, if we can show that there is always an appropriate ""cut point"" to cut the first part, and then use the induction hypothesis to cut the remaining numbers into $k-1$ parts, we would be done. However, it is not obvious how to find this cut point or whether it always exists. Another thing to note is that if $k=n$, we just cut the numbers into $n$ parts with one number each, and again this trivially works.","['algebra-precalculus', 'recreational-mathematics']"
2524871,Why does the closing lemma follow from the local closing lemma?,"Let $M$ be a closed smooth manifold. The $C^r$-closing lemma (open in the case $r >1$) says that if $x$ is a non-wandering point of $f \in \mathcal{Diff}^r(M)$ then there is a $g$ arbitrarily $C^r$ close to $f$ for which $x$ is periodic. The local $C^r$ closing lemma states that under the same hypothesis as above, for any neighborhood $U$ of $f$ in $\mathcal{Diff}^r(M)$ and neighborhood $V$ of $x$, there is a $g \in U$ and $x_g \in V$ such that $x_g$ is periodic for $g$. It's claimed in the 2012 survey article of D. V. Anosov and E. V. Zhuzhoma that the local closing lemma implies the closing lemma, by an argument from Pugh. The proof given in [1], for vector fields, but I'm having trouble understanding it. Does anyone know of a proof for diffeomorphisms? Thanks in advance. [1] Pugh, Charles C. ""The Closing Lemma."" American Journal of Mathematics 89, no. 4 (1967)","['real-analysis', 'ordinary-differential-equations', 'dynamical-systems']"
2524879,Residue theorem for a rational function,"Evaluate 
  $$\int_{-\infty}^{\infty}\frac{x^4}{1+x^8}\mathrm{d} x.$$ My concern: One of the consequences of the residue theorem states that, given a polynomial of the form $P/Q$ such that the degree of $Q$ exceeds $P$ by at least two, the integral can then be expressed as $$\int fdz=2\pi i\sum_{U}{\mathrm{Res}\left ( f;z_{i} \right )}.$$ 
The zeros of $Q$ in the Upper half plane  is here given by $z=e^{\frac{i \pi}{8}\left ( 2n+1 \right )}$ for $n\in \left \{0,1,2,3\right \}$. The residue at $z_{n}$ is now given by $\frac{P(z_{n})}{Q´(z_{n})}$. Should I derive the polynomial or exponential function?","['complex-analysis', 'improper-integrals', 'integration', 'calculus']"
2524929,Find value of $a_{2012}$,"A sequence $\left\{a_n\right\}$  is defined as: $a_1=1$, $a_2=2$ and $$a_{n+1}=\frac{2}{a_n}+a_{n-1}$$ $\forall$ $n \ge 2$ Find $a_{2012}$ My Try: we have $$a_{n+1}-a_{n-1}=\frac{2}{a_n}$$ $$a_n a_{n+1}-a_{n-1}a_n=2 \tag{1}$$ Replacing $n$ with $n-1$ we get $$a_{n-1} a_{n}-a_{n-2}a_{n-1}=2 \tag{2}$$ adding $(1)$ and $(2)$ we get $$a_n a_{n+1}-a_{n-2}a_{n-1}=4 \tag{3}$$ Again replace $n$ with $n-1$ in $(3)$ and adding with $(1)$ we get $$a_n a_{n+1}-a_{n-2}a_{n-3}=6 \tag{4}$$  Again replace $n$ with $n-1$ in $(4)$ and adding with $(1)$ we get $$a_n a_{n+1}-a_{n-3}a_{n-4}=8 \tag{5}$$ Continuing the process we get $$a_na_{n+1}-a_{n-2010}a_{n-2011}=4022$$ Now in above equation put $n=2012$ we get $$a_{2012}a_{2013}-a_1a_2=4022$$ $\implies$ $$a_{2012}a_{2013}=4024$$ Any further clue?","['algebra-precalculus', 'arithmetic-progressions', 'summation', 'sequences-and-series']"
2525048,Bijection between natural numbers and set of finite rows of natural numbers,"I have to construct a bijection between $\Bbb N$ the natural numbers and $\Bbb S$, where $\Bbb S$ is the set of finite rows of natural numbers. S=$\{(n_0,n_1,...,n_k)|k\in \Bbb N,n_i\in \Bbb N\}$
I did a similar problem here: bijection between natural numbers and set of strictly growing finite rows but can figure it out for this one.",['discrete-mathematics']
2525067,Generalized Pigeonhole Principle Proof,"From my book Discrete Mathematics by Rosen, I can't understand the conclusion of the proof. THE GENERALIZED PIGEONHOLE PRINCIPLE: If N objects are placed into k boxes, then there is at least one box containing at least ⌈N/k⌉ objects. Proof by contradiction: Suppose that none of the boxes contains more than ⌈N/k⌉ objects. Then, the total number of objects is at most ⌈N/k⌉-1 objects. $$⌈N/k⌉ < (N/k) + 1$$
$$k(⌈N/k⌉ - 1) < k[(⌈N/k⌉+1)-1] = N$$ This is a contradiction because there are a total of N objects. I don't understand how that inequality shows it's a contradiction, how did they get that the inequality shows less than N objects?","['proof-writing', 'proof-explanation', 'discrete-mathematics']"
2525094,"Proving that all the real roots of Hermite polynomials are in $(-\sqrt{4n+1}, \sqrt{4n+1})$","The Hermite polynomials are given by:
$H_n(x)=(-1)^n e^{x^2} \dfrac{d^n}{dx^n}e^{-x^2}$ There is the proof that all the roots are real: https://math.stackexchange.com/a/104875/504137 . And I know the fact that they all are bounded i.e. all the roots lie in $(-\sqrt{4n+1}, \sqrt{4n+1})$. 
But how to prove that?","['polynomials', 'roots', 'calculus', 'functional-analysis', 'orthogonal-polynomials']"
2525121,"Show that $u_n$ converges if $\min(u_n,u_{n+1})$ converges.","Let $\lambda \in (0,1)$ and $(u_n)_n$ a sequence of real numbers such that :  $\forall n \in \mathbb N : \; u_{n+2}\ge \lambda u_{n+1} + (1-\lambda)u_n$. And $\forall n \in \Bbb N \; v_n=\min(u_{n+1},u_n)$ . The problem first asks to show that $v_n$ does have a limit, I have done this by showing that it's an increasing sequence. This immediately gives us that if $v_n \to +\infty$ then $u_n \to +\infty$ . The next question is to show that if $v_n \to l \in \Bbb R$ then $u_n$ converges. I fail to see why this must be true, I tried to use the definition of limits but to no avail.","['real-analysis', 'real-numbers', 'sequences-and-series', 'convergence-divergence']"
2525130,An honest die is thrown 8 times; let X be the number of twos and let Y be the number of fours. Find the joint pmf of X and Y and calculate P(X=Y).,"An honest die is thrown 8 times; let $X$ be the number of twos and let $Y$ be the number of fours. Find the joint pmf of $X$ and $Y$ and calculate $\mathbb{P}(X=Y)$. This question is too big to manually draw a table for so I'm having trouble solving it. Can anyone help with the joint pmf? Calculating $\mathbb{P}(X=Y)$ should be straightforward once I have the joint pmf. I know that for either $X$ and $Y$ alone, the pmf will be ${{8}\choose{k}}(1/6)^k(5/6)^{8-k}$","['statistics', 'probability', 'dice']"
2525137,"How to prove that the closed unit ball in $\mathbb{R}^n$, with the subspace topology, is not a manifold? [duplicate]","This question already has answers here : Closed ball not a manifold. (2 answers) Closed 6 years ago . Our definition of a manifold $M$ is a Hausdorff topological space such that for every $x \in M$, there exists a neighborhood $U_x$ that is homemorphic to $\mathbb{R}^m$ for some $m$. We define the closed unit ball in $\mathbb{R}^n$ to be the set $\{x \in \mathbb{R}^n \colon \|x\| \leq 1\}$. The claim is that the closed unit ball is not a manifold. The open unit ball is clearly a manifold, so I assume that for every point $x$ on the boundary of the closed unit ball, none of the neighborhoods of $x$ are homemorphic to $\mathbb{R}$. However, I am having trouble doing so. I have tried proving this by contradiction by supposing such a homemorphism exists and showing there exists a topological property of $\mathbb{R}^n$ that the closed unit ball doesn't have.","['manifolds', 'general-topology']"
2525180,How to effectively compute fundamental units in rings?,"Consider the ring of integers of $K=\mathbb{Q}(\sqrt 2,\sqrt 3)$. By Dirichlet's unit theorem the units of $\mathcal O_K$ have rank 3, so they are expressible as $\pm u_1^au_2^bu_3^c$ for suitable units $u_1,u_2,u_3$ and $a,b,c\in\mathbb Z$. I found three units which are not expressible as powers of each other: $1+\sqrt 2$, $2+\sqrt 3$ and $\sqrt 3+\sqrt 2$ but how do I guarantee that none of these units is a power of another unit i.e $u^n=1+\sqrt 2$ or the same for the other two? For fields of the form $\mathbb Q(\sqrt m, \sqrt n)$ for coprime squarefree positive integers $m,n$ is it always sufficient to examine the minimal nontrivial solutions to $x^2-my^2=\pm 1$, $x^2-ny^2=\pm 1$ and $x^2-mny^2=\pm 1$?","['abstract-algebra', 'ring-theory', 'algebraic-number-theory']"
2525207,Decide if $b_n := \left(-1+\frac 1 {n^2}\right)^n$ converges,"I want to show if the sequence $b _n := \left(-1+\frac 1 {n^2}\right)^n$
is convergent or not, but im stuck finding a Limit to conclue with Epsilon-test","['convergence-divergence', 'limits']"
2525211,"Why do people say dy/dx is not a fraction, but then use it as one when doing the chain rule?","To my knowledge, dy/dx is equal to the limit of (f(x+h) - f(x)) / h as h approaches zero. That is, dy is equal to the difference in the y value (f(x+h) - f(x)) and dx is equal to the difference in the x value (h) and dy/dx is equal to the rate of change of the y function as the x function increases. As well as this, in the chain rule you multiply dy/du * du/dx in order to cancel out the du's like you would with normal fractions. Despite this, all of my teachers insist that dy/dx is not a ratio, it is just a symbol for the gradient or for the derivative of y with respect to x that can't be split up and manipulated like a normal fraction can be. On a side note, the symbol d/dx (y) to mean ""differentiate y with respect to x"" confuses me too, as i thought that dy and dx were atomic symbols, but this notation splits up d and y even further.","['notation', 'calculus']"
2525261,Can exponential functions be thought of as eigenfunctions for the derivative operator?,"I.e. is the function $y=b^{kx}$ an eigenfunction for the derivative operator $\frac{dy}{dx}$, where k is a constant because the derivative of such a function is ${k\ln(b)}b^{kx}$, which is a constant ($k\ln(b)$) times the original function ($b^{kx}$.) Does it even make sense to say this? If it does, are there any other such eigenfunctions for the derivative operator?","['derivatives', 'eigenfunctions']"
2525265,Changes of coordinates in differential geometry,"I'm taking an undergraduate differential geometry class, and because either because the professor has chosen to forgo rigor (as a background in analysis isn't required and most of the class has negligible proof-writing experience) or else because I'm just not getting it, I'm having a lot of difficulty understanding the way he discusses changes of coordinates. This is the general description he gives: If we change local coordinates from $\{x^1, ..., x^i, ... x^n\} $ to $\{\hat{x}^1, ..., \hat{x}^{\alpha},..., \hat{x}^n\}$ by the map $F$, the vector field $U = u^iX_i$ to $\hat{U} = \hat{u}^{\alpha}\hat{X}_{\alpha}$ $\hat{U} = DF(U)$ and $\hat{u}^{\alpha} = \frac{\partial \hat{x}^{\alpha}}{\partial x^i}u^i$ I understand (I think) what all the symbols mean, and I'm comfortable with Einstein summation convention, and the idea of a derivative map (again, at an unrigorous, undergrad level). That said, I cannot for the life of me understand why if the coordinates transform under $F$, why the vector transforms under $DF$. I would like a) some intuition about this (if there's an intuitive way to view it) and b) a way to show that this is true (if there's a straightforward, fairly elementary way to show it). Thanks!","['coordinate-systems', 'change-of-basis', 'differential-geometry']"
2525279,Coloring of $\mathbb{R}^3$ into 3 colors,"Every point of three-dimensional space is colored red, green, or blue. Prove that one of the colors attains all distances, meaning that any positive real number represents the distance between two points of this color. My proof: Suppose by contradiction that $\exists \delta>0$ such that for any $x,y\in \mathbb{R}^3$ with $d(x,y)=\delta$ points $x$ and $y$ have different colors. Let's consider the tetrahedron in $\mathbb{R}^3$ with base $A_1A_2A_3$ and upper vertex $A_4$. Suppose $A_1$ is colored into red,$A_2$ is colored into green then $A_3$ is colored into blue. Then $A_4$ should be colored into one of the colors blue, red, or green but due to $d(A_4,A_1)=d(A_4,A_2)=d(A_4,A_3)=\delta$ the coloring of point $A_4$ to red,blue, or green is impossible. EDIT: Let's prove that RED attains all distances.Suppose by contradiction that $\exists \delta>0$ such that for any $x,y\in \mathbb{R}^3$ with $d(x,y)=\delta$ points $x$ and $y$ not both RED. Let's consider the regular tetrahedron in $\mathbb{R}^3$ with base $A_1A_2A_3$ and upper vertex $A_4$. WLOG suppose $A_1$ is colored into red,$\ A_2$ is colored into green then $A_3$ is colored into blue. Then $A_4$ should be colored into one of the colors blue, red, or green but due to $d(A_4,A_1)=d(A_4,A_2)=d(A_4,A_3)=\delta$ but the coloring of point $A_4$ to red,blue, or green is impossible. Here we get contradiction. Right?","['combinatorics', 'contest-math', 'proof-verification']"
2525290,"Show that the trajectory of the solution $ x(t),y(t))$ is contained in the curve $E_{0}$. (Non-Linear Systems, ODE)","I've been visiting this site for years to solve doubts, and this is my first question it's about something that's almost totally new to me. We have the autonomous system $x'=y$ and $y'=x^3-x$ (pendulum).
And the following question:
Let $(x(t),y(t))$ be a $(C^1)$ class) solution of the nonlinear system, with $t=0$ given by $(xo,yo)$. Show that the trajectory $(x(t),y(t))$ must be contained on the curve:
$E_{0}=\dfrac{1}{2}y^{2}-\dfrac{1}{4}(x^{2}-1)^{2}, E_{0}$ its constant. I'm very confused about this exercise, because i don't know what to do with the curve $E_0$ if it's constant!.","['ordinary-differential-equations', 'systems-of-equations']"
2525295,"$S$ a subring of $R$ has the property that if $x,y \in S$, $y \not= 0$ and $xz = y$ in $R$ then $z \in S$","I'm having trouble remembering if the property described in the title has an actual name. Phrased informally, if an element of $S \subset R$ partially factors in $S$, then that factorization is actually valid in $S$. For example, the integers embedded in the rationals don't possess this property, but the integers embedded in $\mathbb{Z}[\sqrt 5])$ (or many other algebraic extensions of the integers) do, even though many integers have factorizations lying entirely in  $\mathbb{Z}[\sqrt 5 ]) \setminus \mathbb{Z}$. To further illustrate, a slightly less trivial and rather artificial example of a ring with this property is the following: Let $R$ be a GCD domain, and consider the ring of polynomials over $R$, let's call it $R_{gcd}[X]$, in which multiplication is normal polynomial multiplication and addition is defined on the monomial basis as $aX^i + bX^i \rightarrow \gcd(a,b)X^i$.  Fix an $r \in R$ not a unit.  Gauss' lemma goes to show that the polynomials whose content has a factorization as a pure power of $r$ form a subring of $R_{gcd}[X]$, and moreover this subring  is easily seen to have the property described above.  Furthermore, if $R$ is not a UFD (say, the algebraic integers), then for some choices of $r$ there will exist factorizations of polynomials in the subring entirely in terms of polynomials not in the subring.","['terminology', 'abstract-algebra', 'ring-theory']"
2525329,Find angle in a figure involving a scalene triangle,"$\triangle ABC$ is a scalene triangle and $\overline {AM}$ is the median relative to the side $\overline {BC}$. A circumference of diameter $\overline {AM}$ intersects by the second time sides $\overline {AB}$ and $\overline {AC}$ at points P and Q, respectively, both different from A. Assuming that $\overline {PQ}$ is parallel to $\overline {BC}$, find the measure of angle $\angle BAC$. Background: I'm a 9th grader who has some experience in math contests. This is question 5 (level 2), from the 2013 Brazilian Math Olympic (OBM). The answer was not given, and I believe that it's impossible to find a solution, given that $\triangle ABC$ cannot be scalene in the conditions given by the question, but I'm not sure. My attempt: (1)Using the information given in the question and considering that the circumference intersects the sides of the triangle is at point A, I came up with (2)$\overline {CB}$ is tangent to the circle, so:
$$\angle AMB=\angle AMC=90°$$ (3)Point M is the midpoint of $\overline {BC}$, so:
$$\overline {CM}=\overline {BM}$$ Using (1), (2), and (3), I can conclude that $\triangle ABC$ is isosceles, which contradicts the statement in the question, in which it is stated that $\triangle ABC$ is scalene. Question: Did I interpret something wrong? Is it impossible to find a scalene triangle that complies with the statement? Any help is appreciated.","['contest-math', 'triangles', 'geometry']"
2525334,The limit of a sum: $\lim_{n\to \infty} \sum_{k=1}^{n} \left(\frac{k}{n^2}-\frac{k^2}{n^3}\right)$,"Evaluate the following limit:
  $$
\lim_{n\to \infty} \sum_{k=1}^{n} \left(\frac{k}{n^2}-\frac{k^2}{n^3}\right)
$$ I haven't ever taken the limit of the sum... Where do I start? Do I start taking the sum?","['calculus', 'limits']"
2525355,"Automorphism group of the group $(\mathbb{R}^n,+)$","As a vector space, it is clear that the automorphism group of $\mathbb{R}^n$ is $\mathsf{GL}_n(\mathbb{R})$ . My question is: What is the $\text{Aut}((\mathbb{R}^n,+))$ ( $n \ge 2$ ) as a group? Clearly, $\text{Aut}((\mathbb{R}^n,+))$ contains $\mathsf{GL}_n(\mathbb{R})$ . Given that the automorphism group of $\mathbb{R}$ is enormous , to simplify matters, I would greatly appreciate an answer with respect to continuous automorphisms (if this is known). The question above is related to this question concerning additive maps that do not preserve scalar multiplication. In particular, are there continuous isomorphisms of $\mathbb{R}^n$ ( $n \ge 2$ ) that do not preserve scalar multiplication? (Clearly, this would indicate that the containment above is strict.)","['abelian-groups', 'abstract-algebra', 'infinite-groups', 'group-theory']"
2525424,"Matrix form of differential equation, non-diagonalizable","In this above matrix, normally I just diagonalize to find the eigenvalues/eigenvectors, but how would this work in the case where the resulting matrix is upper triangular and has 0's on the diagonal? Thanks!","['eigenvalues-eigenvectors', 'systems-of-equations', 'diagonalization', 'ordinary-differential-equations', 'linear-algebra']"
2525434,Line of best fit on the surface of a sphere,How would you calculate the line of best fit on the surface of a sphere for a set of points on the surface of that sphere? Specifically I'm looking to find the ideal location for an orbital ring around earth based on the distribution of the population. Thanks :),"['spheres', 'spherical-coordinates', 'surfaces', 'geometry']"
2525479,Zariski Topology on Spec A,"I am solving an exercise of Reid's Undergraduate Commutative Algebra, which asks the following. Let $A$ be Noetherian, and $X\subseteq \text{Spec A}$ be Zariski closed. Then $X$ is irreducible (i.e. not the union of two distinct closed subsets) if and only if $I(X)=\cap_{P\in X} P$ is prime. My problem is that I wrote a proof in which I don't see flaws, but I did not use the fact that $A$ was Noetherian. Could it be that Noetherianity is not needed? Here's a sketch. For the if part, by contraposition: if $X$ is reducible, there are closed $X_1,X_2$ such that $X=X_1\cup X_2$, both being non-nested and distinct. This implies that $I(X_1)$ and $I(X_2)$ are also distinct and non-nested, so there are $f\in I(X_1)\setminus I(X_2)$ and $g\in I(X_2)\setminus I(X_1)$, while obviously $fg\in I(X)$, which therefore is not prime. For the only if part, again by contraposition. Say $I(X)=I$ is not prime, so there is $fg\in I$ with $f,g\notin I$.  The proof then relies on the claim\begin{equation*} X=V(I,f)\cup V(I,g)\end{equation*}
Both directions are obvious: if $P\in X$, then $P\supseteq I$ so $fg\in P$ and thus either $f$ or $g$ are in $P$ so that $P\in V(I,f)$ or $P\in V(I,g)$. On the other hand if $P$ is in the RHS, say $P\in V(I,f)$, then obviously $P\supseteq I$, so that $P\in LHS$. Can anybody see flaws?","['abstract-algebra', 'zariski-topology']"
2525488,"If $f$ is a entire function such that $f(z+n+im)=f(z)$ for all $z\in \mathbb{C}$ and for all $n,m \in \mathbb{Z}$, then $f$ is constant.","If $f$ is a entire function such that $f(z+n+im)=f(z)$ for all $z\in \mathbb{C}$ and for all $n,m \in \mathbb{Z}$, then $f$ is constant. I'm having trouble solving this one. Could you help me? I have tried to get to that $f$ is bounded to apply the Liouville theorem, but I do not know how to limit this function, could someone help me please? Thank you.","['complex-analysis', 'analysis', 'functions']"
2525506,system of equations mod 7,"I am to solve the system of equations below for the field mod 7.  I am also to solve another system of equations that's the same system as below but with the right hand sides replaced with 2, 4, and 1 respectively.  I was told that these two problems could be solved simultaneously using an agumented matrix but wouldn't this completely change the general solutions for $x,y,z$? Thanks in advance! $$x + 4y +5z=1$$
  $$6y +4z=2$$
  $$4x +3z =3$$","['matrices', 'matrix-equations', 'modular-arithmetic', 'linear-algebra']"
2525510,How to derive the divergence theorem from the General Stokes theorem?,"So, given the generalized Stokes theorem: $$\int_{\partial M} \omega = \int_M d\omega$$ where $M$ is an $n$ -dimensional surface and $\omega$ is a $p$ -form on $M$ ( $p$ < $n$ ). How can I derive the Divergence Theorem? $$\iint_S {\bf F} \cdot d{\bf S} = \iiint_R \text{div}\;{\bf F}\; dV$$ I also have another related question. I'm learning that there are several theorems, like the divergence theorem, that are special cases of the generalized Stokes Theorem. For example, apparently, the Kelvin-Stokes Theorem is a special case of the General Stokes Theorem where $n=2$ . So my 2nd question is, what if $n=1$ in the general stokes theorem? What does that imply or lead to? Thank You.","['multivariable-calculus', 'stokes-theorem', 'differential-geometry']"
2525525,"Find local min, max, saddle point of the function $f(x, y) = 3x^3 − 9x + 9xy^2$","$f(x, y) = 3x^3 − 9x + 9xy^2$ I've tried taking the partial derivatives and double derivatives of this function to solve for the local minimum, maximum values, and saddle point but haven't made much progress.","['multivariable-calculus', 'partial-derivative', 'maxima-minima']"
2525536,Number of permutations such that $a-b+c-d+e-f+g-h=0$,"All possible permutations $\left\{a,b,c,d,e,f,g,h\right\}$
 of the set $A=\left\{1,2,3,4,5,6,7,8\right\}$ are formed.  How many of those permutations satisfy $$a-b+c-d+e-f+g-h=0$$ My Try: we have for example $$(2-1)+(4-3)+(5-6)+(8-7)=0$$ and each of the number in brackets if we treat them as four letters, they can be arranged in $4!=24$ ways.Now in all these possible permutations if we multiply with negative sign we get a different permutation. So total is $48$. similarly for $$(2-3)+(4-1)+(5-6)+(8-7)=0$$ we get $48$ permutations. but i feel this is an informal approach. Any clue for better approach?","['algebra-precalculus', 'combinatorics', 'permutations', 'sequences-and-series']"
2525540,Affine Curvature,"I was reading a paper related to convex curves, and encountered the following quantity: Let $\gamma$ be a convex curve and $k(\cdot)$ be its curvature (with respect to arc length). The author is using the following highly ambiguous (at least to me) notation: $$\int_\gamma k(s)^\frac{1}{3} ds$$ and calling this quantity the affine curvature. My question is: $\textbf{What does this notation mean?}$ First of all, what exactly is $k(s)?$ Secondly, what does it mean to integrate $k(s)$ with respect to $s$ along the curve $\gamma$?
Any help will be greatly appreciated!",['multivariable-calculus']
