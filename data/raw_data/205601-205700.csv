question_id,title,body,tags
4091811,"If we know how one variable depends on another, can we ""plug"" this into the total derivative?","Suppose we have a function $f(x,y)$ . The total derivative is $f_1(x,y)dx+f_2(x,y)dy$ . Now suppose that we know the explicit relationship between x and y. For example, suppose we know $y=h(x)$ . Then can we just write the total derivative as $f_1(x,y)dx+f_2(x,y)*h'(x)dx$ ? (which is just the ""partial"" derivative of $f(x,h(x))$ w.r.t $x$ . (I put partial in quotes because i guess in this second formulation $f$ is really just a function of one variable). If the above is true, then what do we use the total derivative for? Because for any application wouldn't we have an explicit dependency between $x$ and $y$ ? (and hence just be able to simplify to the latter case)","['partial-derivative', 'multivariable-calculus', 'derivatives']"
4091834,Flaw in Proof of Arzela-Ascoli in Carothers' Real Analysis?,"I came across this overview of a talk given by a CalTech student which claims that the proof of Arzela-Ascoli given in Carothers' ""Real Analysis"" is incorrect. I've been trying to find the flaw for some time now but I don't see it. Maybe there isn't one? The usual proofs I've seen involve obtaining a countably dense subset (via separability) and making a diagonal argument to find a subsequence, but this one does not do that. Here is the proof (of the just the converse direction because the forward direction is simple): Arzela-Ascoli Theorem 11.8 : Let $X$ be a compact metric space, and let $\mathcal{F}$ be a subset of $C(X)$ . Then $\mathcal{F}$ is compact if and only if $\mathcal{F}$ is closed, uniformly bounded, and equicontinuous. Proof. ( $\impliedby$ ) $ \ $ Suppose $\mathcal{F}$ is closed, uniformly bounded, and equicontinuous and let $(f_n)\in\mathcal{F}.$ We need to show that $(f_n)$ has a uniformly convergent subsequence. First note that $(f_n)$ is equicontinuous. Thus given $\epsilon>0, \exists \delta >0: d(x,y)<\delta\implies |f_n(x)-f_n(y)|<\epsilon/3, \forall n$ . Next since $X$ is totally bounded, $X$ has a finite $\delta$ -net, i.e, there exists $x_1,\ldots, x_k\in X$ such that each $x\in X$ satisfies $d(x,x_i)<\delta$ . Now since $(f_n)$ is also uniformly bounded, each of the sequences $(f_n(x_i))_{n=1}^{\infty}$ is bounded in $\mathbb{R}$ for $i=1,2,\ldots, k$ . Thus by passing  to a subsequence of the $f_n$ (and relabeling), we may suppose that $(f_n(x_i))_{n=1}^{\infty}$ converges for each $i=1,2,\ldots, k$ . In particular, we can find some $N$ such that $|f_m(x_i)-f_n(x_i)|<\epsilon/3$ for any $m,n\geq N$ and any $i=1,2,\ldots, k$ . And now we are done! Given $x\in X$ , first find $i$ such that $d(x,x_i)<\delta$ and then whenever $m,n\geq N$ , we will have \begin{align*}
&|f_m(x)-f_n(x)|\\
&\leq|f_m(x)-f_m(x_i)|+|f_m(x_i)-f_n(x_i)|+|f_n(x_i)-f_n(x)|\\ &<\epsilon/3+\epsilon/3+\epsilon/3\\
&=\epsilon
\end{align*} That is, $f_n$ is uniformy Cauchy, since our choice of $N$ does not depend on $x$ . Since $\mathcal{F}$ is closed in $C(X)$ by assumption, it follows that $f_n(x)$ converges to some $f\in\mathcal{F}$ , uniformly.","['arzela-ascoli', 'solution-verification', 'real-analysis']"
4091940,Shafarevich Basic Algebraic Geometry exercises 1.6.3 and 1.6.5 seem to contradict each other?,"In Basic Algebraic Geometry I, exercise 1.6.3 states Let $X\subset \mathbb{P}^2$ be the reducible $0$ -dimensional variety consisting of $3$ points not lying on a line. Prove that the ideal $\mathfrak{U}_X$ cannot be generated by $2$ elements. Exercise 1.6.5 states Prove that any finite set of points $S\subset \mathbb{P}^2$ can be defined by two equations. I am confused by these problems because I thought that for $S$ to be defined by two equations would mean that $\mathfrak{U}_S$ can be generated by 2 elements. However, $X$ in exercise 1.6.3 gives a finite set of points and the problem claims that $\mathfrak{U}_X$ cannot be generated by 2 elements. Am I misunderstanding something or is one of the problems misstated?","['algebraic-geometry', 'projective-geometry']"
4091965,Second derivative test and continuity of $f''$? [duplicate],"This question already has an answer here : Counterexample to second derivative test when f''(x) is not continuously differentiable (1 answer) Closed 3 years ago . In the 8th edition of Calculus by Stewart, The second derivative test is stated as follows The Second Derivative Test Suppose $f''$ is continuous near c. (a) If $f'(c)=0$ and $f''(c)>0$ , then f has a local minimum at c. (b) If $f'(c)=0$ and $f''(c)<0$ , then f has a local maximum at c. I don't see why continuity of $f''$ is an assumption here.
Can you provide a function that discontinuity of $f''(c)$ affects the test?","['calculus', 'derivatives']"
4091969,"Prove $|(0, 1]| = |\mathbb{R}|$ [duplicate]","This question already has answers here : How to define a bijection between $(0,1)$ and $(0,1]$? (9 answers) Closed 3 years ago . I could find proof for $|(0,1)| = |\mathbb{R}|$ , but could not find anything about $|(0, 1]| = |\mathbb{R}|$ . I do not know how to prove this. The only way I can think of is showing that there is a bijection from $(0, 1] \rightarrow (0,1)$ , then we will have $|(0, 1]| = |(0,1)| = |\mathbb{R}|$ . However, I would like to prove this by using The Schroder-Bernstein theorem with $(0,1]$ . What would be the key difference between $|(0,1)| = |\mathbb{R}|$ and $|(0, 1]| = |\mathbb{R}|$ ? I think there still should be the bijection from $(0,1]$ to $\mathbb{R}$ , but I'm struggling with coming up with idea.","['elementary-set-theory', 'cardinals', 'functions']"
4091983,Twenty students in a class when they are required to choose a partner,"The question consists of two subquestions: There are 20 students in the class. A. The students are required to divide into 10 pairs. In how many ways can they are divided? Attempt: First of all, we know that there are 20 students so in the first stage we can arrange them in upline so we get 20! for that, In the second stage, we determine two students in the line will be pair and the change between them makes the calculation $2^n$ , the last stage we can see of each pair can be move in the line together which gives us the $10!$ . Final solution: $\frac{20!}{10!\cdot 2^{10}}$ . This solution correct? B. The students are required to divide into pairs again, however, they cannot be with the same partners as in subquestion - A. . In how many ways can they do so? Attempt: I tried to use the inclusion-exclusion principle without any success.","['combinatorics', 'discrete-mathematics']"
4091986,"Is there a ""common"" name for this type of combinatorial optimization problem?","I'm trying to find papers that discuss approaches (in particular, any Deep Learning or Deep Reinforcement Learning techniques) that could be used used to solve the problem described in the next paragraph. My question is whether such problem has a an equivalent problem with a ""famous"" name (similarly to what happens with problems like the Knapsack problem or the Job Shop Scheduling problem ), since that would make my search much easier. The problem in question is: given n tasks T1, T2, ..., Tn of varying cost $c_{i}$ , and m nodes N1, ..., Nm with varying capacity $r_{i}$ , what is the task allocation that minimizes the number of used nodes as priority 1, and the total quantity of free resources in the used nodes as priority 2. So for example, if I have tasks {T1, T2} with costs {3, 7} , and nodes {N1, N2, N3} with capacity {5, 11, 12} . The optimal alocation would be assigning T1 and T2 to N2 , since it would require only one node, and the number of free resources is $11 - 7 - 3 = 1$ . Any tips on what sort of terminology I could use on my search are also welcome! Same applies to suggestions on similar ""famous"" problems that, even if not equivalent, could be interesting to look at (as per my comments above, I am already familiar with the Knapsack and the JSS problems). Thank you very much!","['np-complete', 'combinatorics', 'discrete-optimization', 'optimization', 'computer-science']"
4092016,Use of Hyperreal numbers,"I've come across hyperreal numbers and was curious about something in measure theory. Non measurable sets can be constructed with AC (correct me, if they can also be constructed without AC), and the contradictions these vitali sets induce, are well known. Assuming the measure is non zero, countably many disjoint unions of them would result in infinite measure, and assuming they have 0 measure individually, countable union would imply 0 measure. Now i have a question about defining the measure of some Vitali set $V$ to be an element from the hyperreals, for example $\varepsilon\in \mathbb{R}^*$ . I dont know too much about the arithmetic these ""numbers"" have, but wouldn't it somewhat be intuitive to then have the disjoint union of countably many translates of this set $V$ to be exactly the unit interval, and thus ""adding"" up to exactly 1 ( length of unit interval). Though, i could see some contradictions arising with this weak definition. Have similar attempts been made with hyperreal numbers for non measurable sets, and does anyone have some source i could read into? Thanks in advance :)","['measure-theory', 'nonstandard-analysis']"
4092049,Understanding Isolated Singularities.,"I have been going through Ahlfors Complex Analysis and am currently studying the section about isolated singularities. I have tried some problems from this section but cannot make any progress at all including looking at previous answers posted about these questions. For instance: If an entire function has a nonessential singularity at $\infty$ it reduces to a polynomial. Okay, well nonessential means we are either removable or a pole. Let us deal with the case for the removable singularity. Define $g(z)=f(1/z)$ , then if $f$ has a removable singularity at $\infty$ then $g$ must have a removable singularity at $0$ . From here we can extend the function $g$ so that it actually becomes analytic at the point $0$ simply by defining $g(0) = \lim_{z \rightarrow 0} g(0).$ Here is where I get stuck, where do I go from here? Of course we can substitute what $g$ is in the limit, but how does that help? For the pole, we know that this means that $\lim_{z \rightarrow \infty}f(z) = \infty$ . Therefore again define $g(z) = \frac{1}{f(1/z)}$ , and $g$ will have a removable singularity at $0$ . I do not know how to proceed from here using what Ahlfors covers so far. It seems like I am stuck basically at the same part in both cases. Any advice on how I can understand this concept and solve this problem is much appreciated.
Thanks!",['complex-analysis']
4092127,Characterize all sets of $2\times 2$ real matrices isomorphic to $\mathbb C$ as a field,"Let $A$ be the set of all 2x2 real matrices of  the form $$\begin{bmatrix}a&-b\\b&a\end{bmatrix}$$ Show that a set $B$ of $2\times 2$ real matrices is isomorphic to $\mathbb C$ as a field iff $B=gAg^{-1}$ for some invertible real matrix $g$ . I've shown that any field of the above form is isomorphic to $\mathbb C$ , but I cannot figure out how to prove the other direction, that if $B$ is isomorphic to $\mathbb C$ then it is of the above form. I can't find any way to characterize what $g$ would have to be for a given $B$ . The statement is basically equivalent to saying the set $B$ is the set of all matrices representing the linear operators on the vector space $\mathbb C$ over $\mathbb R$ of the form $T_w(z)=wz$ under some basis, but I cannot prove that either. Help would be appreciated.","['matrices', 'linear-algebra', 'complex-numbers']"
4092152,Which topological vector spaces have uncountable unordered sums?,"If $P$ is an uncountable locally finite poset, then the incidence algebra $I(P)$ is a topological vector space (in fact a topological algebra) with the interesting property that every element $f$ can be written uniquely as an uncountable unordered sum $\Sigma_{a,b\in P: a\leq b}f(a,b)1_{[a,b]}$ , i.e. $\{1_{[a,b]}:a,b\in P, a\leq b \}$ constitutes an ""uncountable Schauder basis"" for $I(P)$ .  I find this interesting because for normed vector spaces, a convergent unordered sum can only have countably many nonzero terms. So my question is, what other topological vector spaces have convergent unordered sums with uncountably many nonzero terms?  And also, what other topological vector spaces have this specific ""uncountable Schauder basis"" property, i.e. there exists an uncountable subset such that every element can be written as an unordered sum of scalar multiples of this subset, and such that there exists at least one convergent unordered sum of scalar multiples of this subset with uncountably many nonzero terms?","['schauder-basis', 'normed-spaces', 'topological-vector-spaces', 'combinatorics', 'functional-analysis']"
4092168,Is this result true? Uniform convergence and inverses,"Running through some geometry papers, I found some authors use the following idea: Let $f_n : \Bbb C^m \to \Bbb C^m$ be a sequence of holomorphic functions converging uniformly to $f : \Bbb C^m \to \Bbb C^m$ on compact sets. Suppose $f(0) =0$ and $\frac{\partial f }{\partial z}$ is invertible (ie, the inverse function theorem can be applied). Then for any $\varepsilon >0$ there is some $N$ and a point $z \in \Bbb C^m$ such that $f_N(z)=0$ and $|z|< \varepsilon$ . I know the result is true for $m=1$ , it just comes as a consequence of the argument principle, but I of course I cannot generalize to more dimensions. On top of that I have seen the problem for $m=1$ in some complex analysis books or lecture notes, which makes me think that the result exchanging $\Bbb C$ by $\Bbb R$ (and holomorphic by smooth or analytic) may not be true, which is problematic because it means that the theory of several complex variables is needed, something I am not very familiar with. Is the result true? References or direct proofs? Are there related results? Is is true for $\Bbb R $ instead of $\Bbb C$ ?","['complex-analysis', 'several-complex-variables', 'inverse-function-theorem']"
4092176,Confusion about covariant derivatives,"I have the following confusion about covariant derivatives. Let $(M,g)$ be a Riemannian manifold with Levi-Civita connection $\nabla$ and let $f$ be a scalar function on $M$ . The Hessian of $f$ , denoted by $\nabla^2f$ , is by definition a rank 2 tensor. However, I'm wondering whether $\nabla_{X}\nabla_{Y}f$ is the same as $\nabla^2f(X,Y)$ for vector fields $X,Y$ on $M$ . If not, then what would be the interpretation of $\nabla_{X}\nabla_{Y}f$ ? Obviously, we are not evaluating $\nabla_{Y}f$ and $\nabla_{X}(\nabla_{Y}f)$ sequentially, since otherwise we would get the usual partial derivatives.","['riemannian-geometry', 'differential-geometry']"
4092223,Show that no values of $b$ can make the equation $b\sin(bx)-2\cos(bx) = 0$ true.,"I am trying to prove that $𝑓(𝑥)=\cos(𝑏𝑥)$ is a solution to the DE $𝑦'''+2𝑦''+𝑦'+2𝑦=0$ , and by substituting $f$ and its derivatives, I have simplified the equation to $$(𝑏^2−1)(𝑏\sin(𝑏𝑥)−2\cos(𝑏𝑥))=0.$$ It is easy to show $𝑏^2−1=0$ has appropriate values for $b$ , but I am not so sure about $b\sin(bx)−2\cos(bx)=0$ . If I have the equation $b\sin(bx)-2\cos(bx) = 0$ , how do I prove that no values of $b \in \mathbb{R}$ , can make the equation true? It it enough to say that $2\cot(bx) \neq b$ for all $x \in \mathbb{R}$ , hence $b$ does not exists?",['ordinary-differential-equations']
4092236,What is the pdf of Z = XY?,"Consider two random variables $X$ and $Y$ with joint pdf $f_{XY}(x,y)$ . Determine the pdf of $Z = XY$ My friend said he solved this using a Jacobian matrix. I'm not well versed  in that topic so I tried solving it the way I solved similar problems. Here is the hyperbola formed when $Z = 2$ : From this figure, I can separate my original probability into the probability that $X > 0$ and the probability that $X < 0$ : $$
P(Z\leq z)=P(XY\leq z)=
P(Y\leq \frac{z}{X}\big|X>0)P(X>0)+P(Y\geq \frac{z}{X}\big|X<0)P(X<0)=
$$ $$
 \int\limits_{0}^{\infty}\int\limits_{-\infty}^{\frac{z}{x}}f_{X,Y}(x,y)dydx +  \int\limits_{-\infty}^{0}\int\limits_{\frac{z}{x}}^{\infty}f_{X,Y}(x,y)dydx
$$ I'm not sure how to proceed from here. Do I need to take partial derivatives of each integral because it is a joint pdf? I'm trying to solve this problem using this CDF -> to PDF method because that conceptually makes sense to me. Is it possible to solve it this way?","['calculus', 'statistics', 'probability']"
4092237,Find all functions that satisfy the functional equation: $ \exp\big(f(\log x)\big)=\log\big(f(\exp x)\big) $,"Find all functions that satisfy the functional equation: $$ \exp\big(f(\log x)\big)=\log\big(f(\exp x)\big) $$ I found that $f(x)=\log x, \exp x$ are solutions. And I think $\exp(x+1)$ also works. I think there are infinitely many solutions: $f(x+s)$ and $f(x)+s$ for $s \in \Bbb R.$ Are these all the solutions?","['functional-equations', 'functions', 'solution-verification']"
4092245,Proper usage of the theorems of Fubini and Tonelli,"I've just learned about the (rigorous versions of the) theorems of Fubini and Tonelli, given below. Theorem: (Fubini) Suppose $\left(X,\mathcal{A},\mu\right)$ and $\left(Y,\mathcal{B},\nu\right)$ are $\sigma$ -finite measure spaces, and suppose that $X\times Y$ is given the product measure $\mu\times\nu$ . If $f$ is $X\times Y$ integrable, meaning that $f$ is a measurable function and $$\int_{X\times Y}|f(x,y)|\,d(\mu\times\nu)<\infty,$$ then $$\int_{X\times Y}f(x,y)\,d(\mu\times\nu) = \int_{X}\left(\int_Y f(x,y) \, d\nu\right) \, d\mu = \int_Y\left(\int_X f(x,y) \, d\mu\right) \, d\nu.$$ Theorem: (Tonelli) Suppose $\left(X,\mathcal{A},\mu\right)$ and $\left(Y,\mathcal{B},\nu\right)$ are $\sigma$ -finite measure spaces, and suppose that $X\times Y$ is given the product measure $\mu\times\nu$ . If $f$ is a measurable function and non-negative then $$\int_{X\times Y}f(x,y) \, d(\mu\times\nu) = \int_X \left(\int_Y f(x,y) \, d\nu\right) \, d\mu = \int_Y \left(\int_X f(x,y) \, d\mu\right) \, d\nu.$$ Lets say I wanted to employ these theorems to solve the following integral, given below. Problem: For $0<a<b$ consider $$\int_0^\infty \frac{e^{-ax}-e^{-bx}}{x} \, dx.$$ I know how to solve the problem, but I'm interested more on how to actually be completely rigorous when employing these theorems. More specifically, I have the following question: To solve the problem, we write $$\int_0^\infty \frac{e^{-ax}-e^{-bx}}{x} \, dx = \int_0^\infty \int_a^b e^{-yx} \, dy \, dx \overbrace{=}^{(1)} \int_a^b \int_0^\infty e^{-yx} \, dx \, dy.$$ How do I use the theorems of Fubini or Tonelli to justify $(1)$ ? Should I say since $[a,b]$ and $[0,\infty)$ are $\sigma$ -finite and $f(x,y):=e^{-yx}$ is a non-negative measurable function, we have by Tonellis theorem $(1)$ holds?","['measure-theory', 'fubini-tonelli-theorems']"
4092251,What exactly do elements of $F[x] / (f(x))$ look like?,"For the field $F$ , integral domain $F[x]$ , some element $c$ which is not contained in $F$ and the minimal polynomial of $c$ , $f(x)$ I know that we have the isomorphism $$
F(c) \cong F[x] / (f(x))
$$ where $(f(x))$ is the ideal generated by the polynomial $f(x)$ , but I am having a lot of difficulty in comprehending what elements of $F[x] / (f(x))$ actually look like.  Can someone provide a few concrete examples, or is there a set-theory type definition which describes all of these elements?",['abstract-algebra']
4092257,Finding all groups with no proper subgroups,"I am trying to solve the following problem in Artin's algebra. Describe all groups $G$ that contain no proper subgroups. Here is my attempt. If $G = \{e\}$ , then it is clear $G$ has no proper subgroups, so suppose that $G \neq \{e\}$ . Let $x \in G$ be a non-identity element, and consider $\langle x \rangle$ , the cyclic group generated by $x$ . Certainly $\langle x \rangle \leq G$ , but if $G$ has no proper subgroup and $\langle x \rangle \neq \{e\}$ since $x \neq e$ , we have $G = \langle x \rangle$ . So $G$ must be cyclic. We prove that $G$ must be finite. Suppose $G$ were infinite. Then $\langle x \rangle \cong \mathbb{Z}$ by the map $\varphi: \mathbb{Z} \to \langle x \rangle$ sending $n \longmapsto x^n$ . But $2\mathbb{Z}$ is a non-proper subgroup of $\mathbb{Z}$ , and the image of a subgroup under a homomorphism is a subgroup of the codomain. In particular, $2\mathbb{Z}$ is the cyclic subgroup of $\mathbb{Z}$ generated by $2$ , so $\varphi(2\mathbb{Z})$ is the cyclic subgroup of $G$ generated by $x^2$ . But $x \not \in \langle x^2 \rangle$ , so $\langle x^2 \rangle \neq G$ . Furthermore, it is not the identity since $x$ has infinite order. So we have found a proper subgroup of $G$ , a contradiction, so $G$ has finite order. Finally, we prove that $G$ must have prime order. Suppose the order of $G$ is not prime, i.e., $|G| = ab$ for $a,b > 1$ . Let $G = \langle x \rangle$ , so $|x| = |\langle x \rangle| = ab$ . Then $\left(x^a\right)^b = e$ , so $\langle x^a \rangle$ is a cyclic subgroup of $G$ of order $b$ ; since $a,b > 1$ , this is a proper subgroup, so we have a contradiction. Hence, $|G| = p$ , where $p$ is prime. Finally, we must show that all prime cyclic groups contain no proper subgroups. If $G$ is a cyclic group of prime order $p$ , then any subgroup $H \leq G$ must have order dividing the order of $G$ by Lagrange's theorem. But the only divisors of $p$ in $\mathbb{N}$ are $1$ and $p$ , i.e., $\{e\}$ and $G$ . So there are no proper subgroups of $G$ , as desired. How does this look?","['group-theory', 'solution-verification']"
4092266,"Favorite application of the fact that disjoint compact sets are distant (i.e. $A$ compact, $B$ closed, $A \cap B = \varnothing\implies d(A,B)>0$)?","This problem is quite popular ( A and B disjoint, A compact, and B closed implies there is positive distance between both sets has currently 70 upvotes, not to mention the endless horde of repeats that one can find of this question on this site), and I myself have seen it for homework at least once or twice. I am wondering if this theorem is widely used. In essence, I am asking the same question as Your favourite application of the Baire Category Theorem but for this ""compact sets are distant"" theorem instead of BCT. I'll go first (added to the answers): I've seen it used in a key way on pg. 27 of Shlomo Sternberg's notes introductory notes on Lebesgue measure http://people.math.harvard.edu/~shlomo/212a/11.pdf . Basically we have that although Lebesgue outer measure $\mu^*$ is not additive in general, it's easy to show that for sets with positive distance between them, $\mu^*$ IS additive, meaning that for disjoint compact sets $\mu^*$ is additive.","['big-list', 'metric-spaces', 'applications', 'general-topology', 'compactness']"
4092288,Evaluating the Tensor Product of Smooth Tensor Fields at a Point,"I'm reading Lee's Introduction to Smooth Manifolds, and in Chapter 12 I've hit a minor but annoying wrinkle regarding tensor fields. Proposition 12.25(a) states that for any two covariant tensor fields $A$ and $B$ and smooth map $F : M \to N$ , $F^* (A \otimes B) = F^* A \otimes F^* B$ where $F^* A$ is the pullback of $A$ by $F$ . Proving the proposition is straightforward enough, but in doing so I make use of $(A \otimes B)_p = A_p \otimes B_p$ , which seems intuitively obvious and is actually the definition of the tensor product of tensor fields in another text. But unfortunately, Lee never explicitly states this, and it seemingly can't be derived from any other information in the chapter. In fact, after defining a covariant tensor field on a smooth manifold $M$ as a section of the tensor bundle $$ T^k T^* M = \coprod_{p \in M} T^k(T^*_p M), $$ (where $T^k(T^*_p M)$ is the vector space of covariant $k$ -tensors on $T_p M$ ) Lee simply states that any such section $A$ can be written (using the summation convention) as $$ A = A_{i_1 \dots i_k} dx^{i_1} \otimes \dots \otimes dx^{i_k}, $$ without any mention of how one is to evaluate the given tensor product of covector fields at a point. Is there any way I can arrive at the desired result using strictly what is presented by Lee, or am I being overly pedantic and should just move on?","['tensor-products', 'differential-geometry']"
4092320,Ask a question on Wald statistic (George Casella 10.35 (b)),"This question is from George Casella statistical inference textbook 10.35 (b). Let $X_1,...,X_n$ be a random sample from a $n(\mu,\sigma^2)$ population. If $\sigma^2$ is unknown and $\mu$ is known, find a Wald statistic for testing $H_0: \sigma =\sigma_0$ . My attempt: I refer to textbook page 493. First, I need to find the MLE of $\sigma^2$ . I find it and is the same as the solution. The log likelihood is $$-\frac{n}{2}log(2\pi\sigma^2)-\frac{1}{2\sigma^2}\Sigma(x_i-\mu)^2$$ . Then taking derivatives with $\sigma^2$ , I get the MLE of $\sigma^2$ is $\frac{\Sigma(x_i-\mu)^2}{n}$ . Then I got problems. According to page 473, next I need to get the approximate variance of the estimator. First, I need to get the observed information number. Just taking second derivatives and then adding a minus sign). My frist derivative w.r.t $\sigma$ is: $$-\frac{n}{\sigma}+\frac{\Sigma(x_i-\mu)^2}{\sigma^3}$$ My second derivative w.r.t $\sigma$ is: $$\frac{n}{\sigma^2}-\frac{3\Sigma(x_i-\mu)^2}{\sigma^4}$$ Add a minus sign: $$-\frac{n}{\sigma^2}+\frac{3\Sigma(x_i-\mu)^2}{\sigma^4}$$ Now plug in $\sigma=\sqrt{\frac{\Sigma(x_i-\mu)^2}{n}}$ , I got the observed information number is $\frac{2n^2}{\Sigma(x_i-\mu)^2}$ . Hence, according to page 473 formula, my variance of the MLE of $\sigma$ is the reciprocal, that is $\frac{\Sigma(x_i-\mu)^2}{2n^2}$ . Hence compared with the. solution, our numerator is the same. But my denominator is $\sqrt{\frac{\Sigma(x_i-\mu)^2}{2n^2}}$ , different from the solution. What step did I get wrong? The solution is here: One comment below said I cannot take derivatives r.p.t $\sigma$ . I don't know why. I think it's okay for me to do this, because my goal is to get the approximate variance of $\sigma^2$ . But if I choose to take derivatives r.p.t $\sigma^2$ as suggested, then my first derivative of log likelihood is $$-\frac{n}{2\sigma^2}+\frac{\Sigma(x_i-\mu)^2}{2(\sigma^2)^2}$$ . My second derivative is $$\frac{n}{2(\sigma^2)^2}-\frac{\Sigma(x_i-\mu)^2}{(\sigma^2)^3}$$ Then add a minus sign is: $$-\frac{n}{2(\sigma^2)^2}+\frac{\Sigma(x_i-\mu)^2}{(\sigma^2)^3}$$ Now plug in MLE $\sigma^2=\frac{\Sigma(x_i-\mu)^2}{n}$ , I got the observed information number is $\frac{n^3}{2(\Sigma(x_i-\mu)^2)^2}$ . Now it is the same as the solution. But I am still confused why my previous method to take derivatives r.p.t $\sigma$ failed. My idea is if I take derivatives r.p.t $\sigma$ directly, then I don't need to use delta method to get the variance of $\sigma$ from the variance of of $\sigma^2$ Also, I am stuck how to get the next. According to the solution, now I should use delta method to get the variance of $\sigma$ . My preferred version of delta method is if $W_n \sim AN(a, b_n)$ , where $b_n$ goes to 0, and g is differentiable with $g'(a)$ not 0, then $g(W_n) \sim AN(g(a), [g'(a)]^2 b_n)$ . (AN denotes approximate normal). So my $W_n$ is $\frac{\Sigma(x_i-\mu)^2}{n}$ , my $a$ is $\sigma^2$ , my $b_n$ is $\frac{2(\Sigma(x_i-\mu)^2)^2}{n^3}$ . My g is $\sqrt{}$ . Hence, my approximated variance of $\sigma$ is $$[g'(a)]^2 b_n=(\frac{1}{2\sqrt{a}})^2 b_n=\frac{1}{4a} b_n=\frac{1}{4\sigma^2} \frac{2(\Sigma(x_i-\mu)^2)^2}{n^3}$$ . It's weird. My approximated variance of $\sigma$ contains $\sigma^2$ . Something in my attempt is wrong here.","['statistical-inference', 'statistics', 'probability']"
4092353,Why does $\frac{z-i}{z+i}$ map the unit disk onto an open half-plane?,"I've been self studying complex analysis, and I read that there is a canonical conformal bijection $$\varphi(z) = \frac{z-i}{z+i}$$ from the open unit disc to the open half-plane. I see why $\varphi$ is analytic, and I was able to show that it is one to one by taking differences and counting zeros. I cannot see why $\varphi$ is onto, however, why is this true?",['complex-analysis']
4092376,Proving that odd partitions and distinct partitions are equal,"I am working through The Theory of Partitions by George Andrews (I have the first paperback edition, published in 1998). Corollary 1.2 is a standard result that shows that the number of partitions of $n$ into odd parts is the same as the number of partitions of $n$ into distinct parts. Andrews's proof uses generating functions, but it contains this step that has me confounded: $$
\prod_{n = 1}^\infty \frac{1 - q^{2 n }}{1 - q^n} = \prod_{n = 1}^\infty \frac{1}{1 - q^{2 n - 1}}.
$$ Can anybody point me in the right direction?
I tried turning $1 - q^n$ into an infinite sum and then expanding, to get $$
\frac{1 - q^{2 n }}{1 - q^n} = 1 + q + q^2 + \dots + q^{2 n -1},
$$ but I don't see how this manipulation will help me.","['integer-partitions', 'generating-functions', 'infinite-product', 'q-series', 'sequences-and-series']"
4092426,Counting how many different equivalence relations are possible with three elements,"Say I have a set $A = \{a,b,c \}$ . I want to know how many equivalence relations are there. I know the answer is $5$ from wikipedia, but I am not sure if the technique I am using is right. I want to use a counting approach. There is only one way to put all the elements in its own subsets, namely, $A \subseteq A$ . There is $\binom{3}{2}$ ways for two elements in one subset and one in another. Then there is only one way for each element to be in its own subset. All together we have $1+3+1 = 5$ . Is this the correct way of thinking when we use counting to count the partitions for a set?","['set-partition', 'solution-verification', 'combinatorics', 'discrete-mathematics', 'elementary-set-theory']"
4092467,Proving that the Hopf map $S^3 \to S^2$ is a submersion,"I need to show that the Hopf map $H : S^3 \to S^2$ is a submersion. There are many ways to define it, but for now I've gone with the restriction of the function $F : \mathbb{R}^4 \to \mathbb{R}^3$ mapping $$(x,y,u,v)\mapsto (2(xu+yv), 2(xv-yu), x^2+y^2-u^2-v^2).$$ It wasn't too bad to show that $F$ is a submersion, but is there a way to go from here to show that $H$ is a submersion? I can write down $H$ as the composition $$S^3 \overset{\iota}{\hookrightarrow} \mathbb{R}^4 \overset{F}{\to} \mathbb{R}^3 \overset{\pi}{\to} S^2,$$ and define $\pi(p) = p/\lVert p\rVert$ , but I don't really know where to go after computing the Jacobian of $\pi$ , and I don't know if this will even work for my purposes (I don't see how to argue that the composition of the corresponding differentials here isn't rank $1$ — I know $d\iota$ has trivial kernel but things seem to break down once I get to $d\pi$ ). I'm really just trying to avoid having to compute the Jacobian of $H$ with respect to the stereographic projections and show that that beast of a thing is full rank. Am I on the right track, or is there a better way?","['hopf-fibration', 'differential-geometry']"
4092470,Proving Proposition 2.4.3. in Artin,"I am trying to prove Proposition 2.4.3. in Artin. He leaves this fact unproved. It states: Let $x$ be an element of finite order $n$ in a group, and let $k$ be an integer that is written as $k = nq + r$ where $q$ and $r$ are integers and $r$ is in the range $0 \leq r < n$ . Then:
(a) $x^k = x^r$ ; (b) $x^k = 1$ if and only if $r = 0$ ; (c) Let $d$ be the greatest common divisor of $k$ and $n$ . The order of $x^k$ is equal to $n/d$ . Here is my attempt. Part (a) is fairly straightforward. We have $k = nq + r$ . $x$ has order $n$ , so $x^n = e$ , and raising $x$ to any multiple of $n$ also gives $e$ by exponent rules, so we have \begin{align*}
x^k = x^{nq + r} = x^{nq} x^r = (x^n)^q x^r = e^q x^r = ex^r = x^r.
\end{align*} I'm only confident on half of part (b). If $r = 0$ , then $k = nq$ , so \begin{align*}
x^k = x^{nq} = (x^n)^q = e^q = e.
\end{align*} Conversely, suppose $x^k = 1$ . Then \begin{align*}
e = x^k = x^{nq + r} = x^{nq} x^r = (x^n)^q x^r = x^r.
\end{align*} So $n \mid r$ , but $0 \leq r < n$ , so this forces $r = 0$ . I am most uncertain on part (c ) and do not know how to start the proof.","['group-theory', 'solution-verification']"
4092505,Why is the reverse of a prime about $45\%$ more likely to be a prime than that of a composite?,"Consider two cases a) we reverse the digits of a prime number b) we reverse the digits of a composite number. Are we more likely to obtain a prime in case a) or in case b) .  Since the last digit of primes other than $2$ and $5$ end in $1,3,7$ or $9$ hence if a prime or composite number begins in $2,4,5, 6$ or $8$ there is no way its reverse will be a prime. So to make a fair comparison, I only considered those prime and composite numbers whose first and last digits is $1,3,7$ or $9$ . Let $C$ and $P$ be the set of such composites and prime numbers respectively. I looked at the first $10^8$ numbers (in ascending order) in $C$ and observed the density of numbers whose reverse is a prime is roughly $\frac{2.4n}{\log n}$ . However in case of the set $P$ , the density of roughly $\frac{3.5n}{\log n}$ i.e. about $45\%$ higher which is significant. Question : Given the set of numbers whose first and last digits is $1,3,7$ or $9$ , why is the reverse of a prime about $45\%$ more likely to be a prime than that of a composite?","['divisibility', 'number-theory', 'elementary-number-theory', 'analytic-number-theory', 'prime-numbers']"
4092524,When is this a group?,"I've been trying to study group theory on my own, and came across the following question: Given a set defined by objects of the form $\lbrace a^i \otimes b^j\rbrace$ for integers $i,j$ , such that the identity element is $1=a^0=b^0$ .  Additionally, there are some integers $m,n\geq 2$ such that $a^m=b^n=1$ but for all integers $1\leq k<m, a^k\neq1$ and for all integers $1\leq k<n, b^k\neq1$ .  Additionally, the following properties hold: $$(a^x\otimes1)\otimes(a^y\otimes B)=a^{x+y}\otimes B$$ $$(A\otimes b^x)\otimes (1\otimes b^y)= A\otimes b^{x+y}$$ For each of the following definitions for $b\otimes a$ , for what values of $m,n$ does this constitute a group, and what group is it isomorphic to (in the simplest expression of that group): $b\otimes a=a\otimes b$ $b\otimes a=a^{-1}\otimes b$ $b\otimes a=a\otimes b^{-1}$ $b\otimes a=a^{-1}\otimes b^{-1}$ My attempt: All of these sets are closed and contain the identity operator.  What remains to define this as a group is to check that the operator is well defined and associative. This operator is always well defined and associative, and so this is always a group.  If $gcd(m,n)=1$ , this group is isomorphic to the cyclic group $C_{mn}$ .  Otherwise, it is isomorphic to the cyclic group $C_m\times C_n$ If $m=2$ , this definition is identical to that in 1).  If $m>2, n=2$ , this defines the dihedral group $D_m$ .  Otherwise, from a sampling of values of $m,n$ that I tried, it appears that this is not well defined and associative. If $n=2$ , this definition is identical to that in 1).  If $m=2,n>2$ , this defines the dihedral group $D_n$ .  Otherwise, from a sampling of values of $m,n$ that I tried, it appears that this is not well defined and associative. If $m=2$ or $n=2$ , this relationship is identical to at least one of the previous three.  From a sampling of values of $m,n>2$ , it appears that this operator is not well defined and associative. My questions: A) Did I miss any groups that are defined by one of the above relationships?  Did I correctly identify the dihedral and cyclic groups (and the direct product of cyclic groups)? B) How do I more rigorously prove that for $m,n>2$ , relationships 2-4 have no groups? EDIT: I forgot to prove inversibility.
The inverses of $a^i\otimes b^j$ are: $a^{-i}\otimes b^{-j}$ $a^i\otimes b^{-j}$ if $j\neq0$ and $a^{-i}$ if $j=0$ $a^{-i}\otimes b^j$ if $i\neq0$ and $b^{-j}$ if $i=0$ $a^i\otimes b^j$ if $ij\neq0$ and $a^{-i}\otimes b^{-j}$ if $ij=0$ EDIT 2:
A proof that for $m>2$ , 2) cannot be a group if $n$ is odd.  Assume that out operator is well-defined and associative. First, by iterating the relationship of 2), we can expand the relationship to show that $b\otimes a^i=a^{-i}\otimes b$ .  Next, we show: $$a=1\otimes a= b^n\otimes a= b^{n-1}\otimes a^{-1}\otimes b = b^{n-2}\otimes a^{(-1)^2}\otimes b^2=...=a^{(-1)^n}\otimes b^n= a^{(-1)^n}\otimes1=a^{(-1)^n}=a^{-1}$$ This would prove that $a$ is its own inverse, which is a contradiction of our assumptions. A similar proof can be applied to show that 3) has no groups for $n>2$ and $m$ odd, and that 4) has no groups for $m,n>2$ and either of $m,n$ odd",['group-theory']
4092539,Why the Euler Transformation converges more quickly?,"There is a problem I've met. I already know that the Leibniz series $\sum_{n=0}^\infty \frac{(-1)^n}{2n+1}$ converges to $\frac{\pi}{4}$ , but it does very slowly. Wikipedia says that Euler Transformation makes the series converge more quickly. Its transformation is $\sum_{n=0}^\infty \frac{(2)^n(n!)^2}{(2n+1)!}$ . By python programming, I confirmed that it converges more quickly than original one, but I don't know why it happens. Wikipedia does not give me a precise proof of rapid convergence. I found a document that proves the rapidity of convergence. In the document, however, does not give existence of such weight function $w(t)$ , satisfying $\int_0^1 t^k w(t)dt=a_k$ . Hence, the question is that, ""is there a proof for rapid convergence of Euler transformation?"" Thanks.","['generating-functions', 'numerical-methods', 'combinatorics', 'sequences-and-series']"
4092545,Induction for $f^{(k)}(x) = \sum_{i=0}^{k} {k \choose i} p^{(k-i)}(x) g^{(i)}(x)$ [duplicate],"This question already has an answer here : How to show via induction the product rule for derivatives? (1 answer) Closed 3 years ago . For $f(x) = p(x)g(x)$ , By writing them out repeatedly, I am guessing that $f^{(k)}(x) = \sum_{i=0}^{k} {k \choose i} p^{(k-i)}(x) g^{(i)}(x)$ (where $f^{(k)}(x)$ : $k$ -th derivative of $f(x)$ ). I tried proving this by mathematical induction, but am stuck on how to proceed from the induction hypothesis. how can I prove by mathematical induction that $f^{(k)}(x) = \sum_{i=0}^{k} {k \choose i} p^{(k-i)}(x) g^{(i)}(x)$ ? Please help! Thank you in advance.","['induction', 'derivatives']"
4092552,"$T: X \to Y$ is continuous if and only if for every continuous seminorm $p$ on $Y$, the map $p \circ T$ is continuous","I am reading a section from the book ""A Course in Functional Analysis"" by J. B. Conway, and I came across this exercise. Let $X$ and $Y$ be locally convex spaces and $T: X \rightarrow Y$ be a linear transformation. Then, $T$ is continuous if and only if for every continuous seminorm $p$ on $Y$ , the seminorm $p \circ T$ is continuous on $X$ . For reference, we will use the following definitions: Definition (Seminorm): Let $X$ be a vector space. A map $p : X \rightarrow \left[ 0, \infty \right)$ is a seminorm if (1) For all $\alpha \in \mathbb{F}$ and for all $x \in X$ , we have $p \left( \alpha x \right) = \left| \alpha \right| p \left( x \right)$ . (2) For all $x, y \in X$ , we have $p \left( x + y \right) \leq p \left( x \right) + p \left( y \right)$ . Definition (Locally Convex Space): Let $X$ be a vector space and $\mathscr{P} = \left\lbrace p_{\alpha} \right\rbrace_{\alpha \in \Delta}$ be a family of seminorms on $X$ . Then, we define a set $U \subseteq X$ to be open if and only if for each $x \in U$ , there are $p_1, p_2, \cdots, p_n \in \mathscr{P}$ and $\epsilon_1, \epsilon_2 \cdots, \epsilon_n > 0$ such that $\bigcap\limits_{j = 1}^{n} \left\lbrace y \in X \mid p_j \left( x - y \right) < \epsilon_j \right\rbrace \subseteq U$ . Now, to prove the result stated above, one way is easy. If $T$ is continuous, then $p \circ T$ is also continuous for every continuous seminorm $p$ on $Y$ . The map $p \circ T: X \rightarrow \left[ 0, \infty \right)$ is a seminorm because $T$ is linear. However, the converse seems difficult. To prove that $T$ is continuous, I go with inverse images of open sets. So, we consider $V \subseteq Y$ , an open set and then look at $T^{-1} \left( V \right) \subseteq X$ . To prove that $T^{-1} \left( V \right)$ is open, we have to prove that for every $x \in T^{-1} \left( V \right)$ , there are seminorms $p_1, p_2, \cdots, p_n$ on $X$ (through which the topology on $X$ is defined) and $\epsilon_1, \epsilon_2, \cdots, \epsilon_n > 0$ such that $\bigcap\limits_{j = 1}^{n} \left\lbrace y \in X \mid p_j \left( x - y \right) < \epsilon_j \right\rbrace \subseteq T^{-1} \left( 
V \right)$ . So, if we start with a point $x \in T^{-1} \left( V \right)$ , we would mean that $Tx \in V$ . Hence, we obtain seminorms $q_1, q_2, \cdots, q_n$ on $Y$ (through which the topology on $Y$ is defined) and $\epsilon_1, \epsilon_2, \cdots, \epsilon_n > 0$ such that $\bigcap\limits_{j = 1}^{n} \left\lbrace y \in Y \mid q_j \left( y - Tx \right) < \epsilon_j \right\rbrace \subseteq V$ . However, now I do know how to proceed! In particular, I know that somewhere I have to use the continuity of $p \circ T$ , but where and how exactly is unknown to me. Any help in this regard will be appreciated!","['general-topology', 'functional-analysis', 'locally-convex-spaces']"
4092558,Computation of Cholesky decomposition of Gram matrix from its components,"Let's assume I have a tall matrix $\mathbf{X} \in \mathbb{C}^{m\times n}$ , where $m \gg n$ . I form the Gram matrix $\mathbf{A} = \mathbf{X}^*\mathbf{X}$ , where $\mathbf{A} \in \mathbb{C}^{n\times n}$ is Hermitian. As $\mathbf{A}$ is Hermitian, there exists a lower triangular matrix $\mathbf{L} \in \mathbb{C}^{n\times n}$ such that $\mathbf{A} = \mathbf{L}\mathbf{L}^*$ (where $\mathbf{L}$ is the Cholesky factor of $\mathbf{A}$ ). Is there a way to compute $\mathbf{L}$ without forming $\mathbf{A}$ first? I saw some things based on Lyapunov equation solvers, but I can't figure how this could help here.","['matrices', 'linear-algebra', 'cholesky-decomposition', 'matrix-decomposition']"
4092564,"If $\tan A, \tan B, \tan C$ are roots of $x^3-ax^2+b=0$, find $(1+\tan^2 A)(1+\tan^2B)(1+\tan^2C)$",Here are all the results I got $$\tan(A+B+C)=a-b$$ And $$(1+\tan^2A)(1+\tan^2B)(1+\tan^2C)=(\frac{1}{\cos A\cos B\cos C})^2$$ And $$\cot A+\cot B + \cot C=0$$ How should I use these results?,"['algebra-precalculus', 'polynomials', 'trigonometry', 'factoring']"
4092620,Determine whether $\sum_{n=1}^\infty \frac{3n+5}{n^2}$ converges,"Determine whether the following converges: $$\sum_{n=1}^{\infty} \frac{3n+5}{n^2}$$ This is what I did, I just want to check that it is a correct method: $$3n + 5 > n$$ $$ \therefore \sum_{n=1}^{\infty} \frac{3n+5}{n^2} > \sum_{n=1}^{\infty} \frac{n}{n^2} = \sum_{n=1}^{\infty}\frac{1}{n}$$ $$\sum_{n=1}^{\infty} \frac{1}{n} \text{ diverges as it is a harmonic series}$$ Hence by comparison test, $\sum_{n=1}^{\infty}\frac{3n+5}{n^2}$ also diverges. Is this a correct method or do I need to add/change stuff?","['convergence-divergence', 'solution-verification', 'sequences-and-series']"
4092652,sign of limit of a sequence,"Let us consider the following sequences: $\{X_{n}\}_{n=1}^{\infty}$ and $\{Y_{n}\}_{n=1}^{\infty}$ such that $X_{n} \xrightarrow{a.s.} a$ and $Y_{n} \xrightarrow{a.s.} a$ ,
for some constant $a > 0$ . Next, assume that $$
\sqrt{n}(X_{n} - a) \xrightarrow{d} Z_{x}
$$ and $$
\sqrt{n}(Y_{n} - a) \xrightarrow{d} Z_{y},
$$ where $Z_{x}$ and $Z_{y}$ are some random variables. Next, assume that $X_{n} \leq Y_{n}$ for all $n$ . Can we say something about the sign of sequence $$
\frac{X_{n}}{n-1} - \frac{Y_{n}}{n}
$$ when $n\to\infty$ ?","['almost-everywhere', 'sequences-and-series', 'convergence-divergence', 'probability-theory', 'random-variables']"
4092656,"If $(M,d)$ is complete, is every non-empty open set a second category set?","If $(M,d)$ is complete, is every non-empty open set a second category set? I know Baire's Category Theorem for Metric Spaces, which says: ""A complete metric space is of the second category in itself, i.e. if we write $M = \bigcup_{n\ge 1} E_n$ , then the closure of some $E_n$ contains an open ball. Equivalently, if $(G_n)$ is a sequence of dense open sets in $M$ , then $\bigcup_{n\ge 1} G_n \ne \varnothing$ . In fact $\bigcap_{n\ge 1} G_n$ is dense in $M$ ."" Somehow, I need to use this (or more) to answer the question above. I feel that the answer is Yes , but I'm not sure how to prove/disprove it. Here's what I've tried so far: Suppose $S \ne \varnothing$ , and $S$ is open. So for every $x\in S$ , there exists $r_x > 0$ such that $B(x,r_x) \subset S$ . Now there are two possibilities, $S$ is either first category or second. Attempt 1: If $S$ is first category in $M$ , then $S$ can be written as $$S = \bigcup_{n\ge 1} S_n$$ where $S_n$ is nowhere dense in $M$ for every $n\ge 1$ (so, $\text{int}(\overline{S_n}) = \emptyset$ ). To find a contradiction, I must get hold of some $n$ such that $\text{int}(\overline{S_n}) \ne \emptyset$ . What do I do? Attempt 2 : Consider $M_n$ such that $M = \bigcup_{n\ge 1} M_n$ and $A \subset M$ is open. Since $M$ is complete, it is second category in itself, i.e. there is some $n$ such that $M_n$ is not nowhere dense. $M \cap A = A$ , so we get $$A = A \cap \bigcup_{n\ge 1} M_n = \bigcup_{n\ge 1} (M_n \cap A)$$ Now if we can prove that $M_n \cap A$ is not nowhere dense, then we are done (maybe it isn't true, maybe this isn't the right way). We know that $\text{int}(\overline{M_n}) \ne \emptyset$ , what can we say about $\text{int}(\overline{ M_n \cap A})$ ? A link in the comments proves that every open subset of a Baire space is also a Baire space. How does that help? $(M,d)$ is a complete metric space, and so a Baire space. $A\subset M$ is open, and by the statement above, $A$ is also a Baire space. How do I know that $(A,d)$ is complete? Are complete metric spaces the only metric spaces which are Baire spaces? If yes, then knowing that $A$ is complete - I can use Baire's theorem to conclude that $A$ is second category.","['baire-category', 'metric-spaces', 'analysis', 'real-analysis']"
4092679,how Bisimulations correspond to internal equality on the final coalgebra?,"From the paper ""Towards a mathematical operational semantics"" by Turi & Plotkin LICS (1997), in Definition 4.1,  I read : The greatest $B$ -bisimulation $\sim$ is the terminal span over two $B$ -coalgebras.
Right after the $\textit{internal equality}$ of a $B$ -coalgebra $(X,\alpha)$ is defined as the kernel pair over the identity $id_X$ on the carrier $X$ . I am assuming that means the pullback $X \times_X X$ over $X$ along the identity $id_X$ . In Set , when bisimilarity is defined over the terminal $B$ -coalgebra, say streams over labels $L$ ( $L^\omega$ ), this coincides with equality (over streams). This is an easy proof. However, for a generic endofunctor $B$ and from the categorical definitions of bisimilarity and equality I cannot seem to be able to prove it. The paper does not seem to introduce any useful assumption at this point. Any suggestions?","['abstract-algebra', 'category-theory', 'computer-science']"
4092687,Factorize $abx^2-(a^2+b^2)x+ab$,"Factorize the quadratic trinomial $$abx^2-(a^2+b^2)x+ab.$$ The discriminant of the trinomial is $$D=(a^2+b^2)^2-(2ab)^2=\\=(a^2+b^2-2ab)(a^2+b^2+2ab)=(a-b)^2(a+b)^2=\\=\left[(a-b)(a+b)\right]^2=(a^2-b^2)^2\ge0 \text{ } \forall a,b.$$ So the roots are $$x_{1,2}=\dfrac{a^2+b^2\pm\sqrt{(a^2-b^2)^2}}{2ab}=\dfrac{a^2+b^2\pm\left|a^2-b^2\right|}{2ab}.$$ How can I expand the modulus here? Have I calculated the discriminant in a reasonable way? Can we talk about ""the discriminant of a quadratic trinomial"" or only the corresponding quadratic equation (the trinomial=0) has a discriminant? What about ""the roots of a trinomial"" (or of the corresponding quadratic equation)?","['algebra-precalculus', 'quadratics', 'factoring']"
4092691,Damped Forced Motion Where forcing happens at a time ahead of 0,"So presume that I have the following DE which represents a vibrating spring with a mass attached to it $$x''+6x'+10x=25\cos(4t), x(0) = \frac{1}{2},x'(0)=0$$ I am lead to believe that the force is applied periodically starting when t = 0 seconds (that is to say the forcing function is applied when the mass is released). What form would this DE have if the force was applied starting when t was some greater positive number? Like say for example, 2 (that is to say the forcing function is applied 2 seconds after the mass is released) ? What form would it have if instead of a periodic forcing function, the forcing function was instead constant like for the DE: $$x''+6x'+10x=5$$",['ordinary-differential-equations']
4092704,What is the significance of a Borel $\sigma$-algebra?,"I am trying to get a firm understanding on probability theory currently. I understand the definition of a $\sigma$ -algebra and further understand that a $\sigma$ -algebra is a crucial part of a probability space and that it is necessary to uphold the foundations of probability theory. However, early into my course I am met with the definition of a Borel $\sigma$ -algebra: The Borel $\sigma$ -algebra on $\mathbb{R^d}$ , denoted by $\mathcal{B}(\mathbb{R^d})$ is the $\sigma$ -algebra generated by the collection of open sets of $\mathbb{R^d}$ . What is the signifiance of this Borel sigma-algebra in the grand scheme of probability theory? I do not have a background in topology, so struggle with some of the definitions online. Can anyone offer simple, intuitive reasoning?","['borel-sets', 'measure-theory', 'probability-theory']"
4092710,Properties of the Solutions of $y' = y$,"In this section of my notes we take $E(x)$ as a solution of the initial value problem $y'=y , y(0)= 1 $ We show that $E(x+r)$ is also a solution to this problem and show $E(x+r)=E(x)E(r)$ .
The notes then go on to prove that $E(x)>0$ . It is done as the following: Suppose $E(s) = 0$ for some $s  \in \mathbb{R}$ . Then, for arbitrary $x$ , we have $E(x + s) = E(x)E(s) = 0$ , so $E(x) ≡ 0$ .
This contradicts $E(0) = 1$ . My question is, surely $E(x)$ doesn't have to be $0$ , surely it could be anything because for whatever value of $E(x)$ , since we've said $E(s)=0$ then $E(x)E(s)$ will always be $0$ no matter what the value of $E(x)$ . Also I'm a little confused why $E(0)=1$ . How do we know this? Thanks in advance!","['initial-value-problems', 'ordinary-differential-equations']"
4092726,Prove $f(x)$ is differentiable at a point.,"Let $f(x)$ be a funciton defined over $(0,1)$ such that $$f(x)=\begin{cases} \dfrac{1}{p^3},&x=\dfrac{q}{p},\text{where} ~p,q
 \in \mathbb{N}, \text{and}~ {\rm GCD}(p,q)=1,\\ 0, &\text{otherwise}. 
 \end{cases}$$ Prove $f(x)$ is differentiable at $x=\dfrac{n\sqrt{2}}{m}$ for any $m,n \in \mathbb{N}$ . Obviously, what we need to do is show that $$\lim_{h \to 0}\dfrac{f\left(\dfrac{n\sqrt{2}}{m}+h\right)-f\left(\dfrac{n\sqrt{2}}{m}\right)}{h}$$ exists. Since $\dfrac{n\sqrt{2}}{m}$ is irrational, $f\left(\dfrac{n\sqrt{2}}{m}\right)=0$ . Therefore $$\lim_{h \to 0}\dfrac{f\left(\dfrac{n\sqrt{2}}{m}+h\right)-f\left(\dfrac{n\sqrt{2}}{m}\right)}{h}=\lim_{h \to 0}\dfrac{f\left(\dfrac{n\sqrt{2}}{m}+h\right)}{h}.$$ How to go on?","['limits', 'calculus', 'derivatives', 'real-analysis']"
4092742,$(\frac1a+\frac12\frac{x}{a+2}+\frac{1\cdot3}{2\cdot4}\frac{x^2}{a+4}+...)(1+\frac12x+\frac{1\cdot3}{2\cdot4}x^2+...)=\frac1a(1+\frac{a+1}{a+2}x+...)$,"For $a>0$ , prove $$\left(\frac{1}{a}+\frac{1}{2}\cdot\frac{x}{a+2}+\frac{1\cdot 3}{2\cdot 4}\cdot \frac{x^2}{a+4}+\cdots\right) \cdot 
\left( 1+\frac{1}{2}\cdot x+\frac{1\cdot 3}{2\cdot 4}\cdot  x^2 +\cdots \right)
= \frac{1}{a} \left[
1+\frac{a+1}{a+2}x+\frac{(a+1)(a+3)}{(a+2)(a+4)} x^2 +\cdots
\right]$$ I'm a bit lost on how to prove it. First I tried to prove it by induction but the expansion of $x^n$ 's coefficient on the left side is complex. Then I tried to simplify it. Call it $S_1 S_2 = S_3$ ,
apparently $S_2 = \sum_{n\ge 0} 4^{-n}{2n \choose n} x^n  = \frac{1}{\sqrt{1-x}}$ , but I got problem in $S_1$ . What I have done is: Denote $c_n = 4^{-n} {2n \choose n}$ , then $$\left( \sum_{n\ge 1} \frac{c_n}{n} x^n \right)' = \sum_{n\ge 1} c_n x^{n-1} = \frac1x \left( \sum_{n\ge 0} c_n x^n - 1 \right) = \frac1x\left(\frac{1}{\sqrt{1-x}}-1\right) $$ Let $f(x) = -2 \ln (1+\sqrt{1-x})$ , then $f' = \frac1x\left(\frac{1}{\sqrt{1-x}}-1\right)$ .
Integral from $0$ to $x$ leads to $$\sum_{n\ge 1} \frac{c_n}{n} x^n  = \int_0^x \frac1x\left(\frac{1}{\sqrt{1-x}}-1\right) dx = f(x) |_0^x =\ln 4 - 2 \ln (1+\sqrt{1-x})$$ To work out $S_1=\sum_{n\ge 1} \frac{c_n}{2n+a} x^n = \frac12 \sum_{n\ge 1} \frac{c_n}{n+b} x^n$ , where $b = a/2$ , define $g(x) = 2S_1 = \sum_{n\ge 1} \frac{c_n}{n+b} x^n $ . Then we have $$ \frac{(x^b g)'}{x^b} = g' + \frac{b}{x}g = \frac1x\left(\frac{1}{\sqrt{1-x}}-1\right) $$ So $$g = \frac{1}{x^b} \left( \int_0^x \frac{x^{b-1}}{\sqrt{1-x}} dx - \frac{x^b}{b} + c  \right) $$ , where $c$ is a constant. But then I'm stuck at the ​ $ \int_0^x \frac{x^{b-1}}{\sqrt{1-x}} dx$ integral.",['sequences-and-series']
4092815,Closed form of the sum $\sum _{n=1}^{\infty }\:\left(\frac{1}{x^2-n^2\pi ^2}\right)$,Came across this in an old textbook and I'm struggling to simplify this in any way. I tried to integrate it and write it as a product: $\int y\:=\:\frac{1}{2x}\left(\log\prod \:_{n=1}^{\infty }\left(x^2-n^2\pi ^2\right)\right)$ but that doesn't seem to help and neither did my attempt at partial fraction decomposition. Any help would be appreciated!,"['infinite-product', 'sequences-and-series', 'real-analysis']"
4092920,Is every polynomial with integral coefficients a Poincaré polynomial of a manifold?,"For any compact, smooth, oriented manifold $X$ of dimension $n$ we can define its  Poincaré polynomial $$p_X(z)=\sum_{k\geq0}b_k(X)z^k\in \mathbb Z[z],$$ which is the generating function of Betti numbers $b_k(X)=\operatorname{rank} H_k(X)\in \mathbb N_0$ . Let $$q(z)=\sum_{k\geq0}c_kz^k$$ be a polynomial with nonnegative integral coefficients $c_k\in\mathbb N_0$ , satisfying the Poincaré duality condition $c_k=c_{n-k}$ . Does there exist a manifold $X$ with $p_X=q$ ?","['general-topology', 'homology-cohomology', 'algebraic-topology']"
4092928,"What happens when a set has elements that are impossible? eg, $\left\{\frac{m}{n} \mid m \in \Bbb{Z} \wedge n \in \Bbb{Z}\right\}$, which allows $n=0$","I am currently learning naive set theory, and we learned that the set of all rational numbers is defined as: $$
\mathbb Q = \left\{\frac{m}{n} \mid m \in \Bbb{Z} \wedge n \in \Bbb{Z} \wedge n \neq 0\right\}
$$ I wonder what happens when we allow n to be equal to $0$ : $$
\mathbb Q' = \left\{\frac{m}{n} \mid m \in \Bbb{Z} \wedge n \in \Bbb{Z}\right\}
$$ Are all the impossible numbers not in the set? are they in the set but they are not numbers? is it not a set? or is this some sort of not well defined set? Thanks!",['elementary-set-theory']
4092934,Finding the sum of the series with $a_n = \frac{4n}{6n+7}$,"In my calc 2 course, one of the homework problems is to let $$a_n = \frac{4n}{6n+7}$$ and then find the limit of its sequence and the sum of its series. I started with the limit: $$\lim_{n\to \infty} \frac{4n}{6n+7}$$ Using L'Hopital, I ended up with $\dfrac{2}{3}$ as the answer. The sum of the series is where I seem to be having trouble. So with $\sum_{n=1}^\infty \frac{4n}{6n+7}$ , I generated the first 3 terms of the series: $$\frac{4}{13} + \frac{8}{19} + \frac{12}{25} + \cdots $$ To me this series does not appear to be geometric, so I tried to utilize a definition I was provided with in class: A series converges iff the sequence, $S_n$ converges. If $S_n$ converges, we say that $\lim_{n\to \infty} S_n = S = \sum_{n=1}^\infty \frac{4n}{6n+7}$ , where $S$ is some real finite number. Based on this, the sum of the series would have to also be $\frac{2}{3}$ but when I entered this as my answer, it was marked as incorrect. So at this point, I'm thinking I might have gotten this definition incorrect or there is some way to algebraically manipulate $a_n$ to get a geometric ""form"" that I'm not seeing.","['limits', 'calculus', 'convergence-divergence', 'sequences-and-series']"
4092976,Harmonic numbers as ratio of two Determinants,"Provide a proof to this interesting identity: $$\frac{\begin{vmatrix} 1^0 & 1^2 & 1^3 & \cdots & 1^n \\ 2^0 & 2^2 & 2^3 & \cdots & 2^n \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ n^0 & n^2 & n^3 & \cdots & n^n \end{vmatrix}}{\begin{vmatrix} 1^1 & 1^2 & 1^3 & \cdots & 1^n \\ 2^1 & 2^2 & 2^3 & \cdots & 2^n \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ n^1 & n^2 & n^3 & \cdots & n^n \end{vmatrix}} = H_n  \tag{1}\label{harmonic}$$ where $H_n$ is the nth Harmonic Number. I accidently stumbled upon this observation while Programming. The inverse of a $(n+1)\times (n+1)$ Vandermonde Matrix (say $V_n$ ) with $ [\alpha_1 , \alpha_2, \alpha_3, \cdots, \alpha_n , \alpha_{n+1} ] = [0,1,2,\cdots,n-1,n] $ , where we treat $0^0$ as $1$ , $$V_n = \begin{bmatrix} 1 & 0 & 0 & \cdots & 0 \\ 1^0 & 1^1 & 1^2 & \cdots & 1^n \\ 2^0 & 2^1 & 2^2 & \cdots & 2^n  \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ n^0 & n^1 & n^2 & \cdots & n^n \end{bmatrix} $$ has some interesting properties. The first row of $V_n^{-1}$ is $ [ 1 \ 0 \ 0 \cdots \ 0]$ . We also have this recurrence relation: $$V_n^{-1}[m][0] = - \sum_{k=1}^n \frac{V_n^{-1}[m-1][0]}{k}  \tag{2}\label{recurrence}$$ Using \eqref{recurrence} we find: $V_n^{-1}[1][0] = -H_n$ . We can also find $V_n^{-1}[1][0]$ using $ \ adj(V_n)/det(V_n)$ which gives $V_n^{-1}[1][0] = C_{01}/det(V_n)$ where $C_{01}$ is the Cofactor of $V_n[0][1]$ . But it is same as the -ve of LHS of \eqref{harmonic}. QCD We can prove the same using Cramer's rule by Reframing the Arguments here a little. But None of these proofs are "" nice "" in a way of not using inverse of Vandermonde Matrix but only elementary arguments like Expansion of the determinants or Mathematical Inductions or something else. I've put exhaustive efforts but haven't succeded yet. Beside an elementary proof, any other perspective on the Result would be helpful and appreciated.","['determinant', 'recurrence-relations', 'harmonic-numbers', 'linear-algebra', 'numerical-linear-algebra']"
4093008,Is derivative a one way function?,"In lectures we have just defined integrals, and said that if we take a derivative of some set of functions, it is much harder to go back to the original set of functions, if we only know the set of derivatives. However, I recently started reading about one way functions(Wikipedia, nothing serious for now) and I wonder, if thus the derivative is a one way function ?","['complex-analysis', 'cryptography', 'combinatorics', 'real-analysis']"
4093060,What is the correct interpretation for the integral of a differential $k$-form in terms of typical vector-calculus multiple integrals?,"Preliminary context : Prof. Kennan Crane from CMU posted a course on discrete differential geometry. I've been able to follow so far, until Lecture 7 . Please let me give some context on how he defines the stuff before posing my question. Basically, a vector is defined in terms of its components as a linear combination of the basis vectors denoted with $\left\{e_i=\frac{\partial}{\partial x_i}\right\}_{i=1}^n$ . Moreover $k$ -vectors are defined as linear combinations of $e_{i_1}\wedge\dots\wedge e_{i_k}$ for some indices $i_1,\dots,i_k$ (see Lecture 3 ). Then, it is explained that forms are basically a generalization of covectors (in euclidean space, the dual of vectors which can be thought as row vectors vs column vectors), which are linear transformations from vectors to scalars. Then, covectors (or 1-forms) are given as linear combinations of the basis 1-forms $\{dx_i\}_{i=1}^n$ , and $k$ -forms are linear combinations of $dx_{i_1}\wedge\dots\wedge dx_{i_k}$ . Until this point, the symbols $dx_i$ and $\frac{\partial}{\partial x_i}$ are not related to derivatives or differentials, but are just basis vectors/forms. Prof. Crane explains that $k$ -forms are meant to be applied to $k$ -vectors in order to obtain a scalar measure. For example the area of the parallelepiped $u\wedge v$ for two vectors $u,v$ can be measured by a 2-form $\alpha\wedge\beta$ for two 1-forms $\alpha,\beta$ , just scaled by the ""size"" of $\alpha,\beta$ . In particular the concrete relation between forms and vectors basis is given by $$
dx_i\left(\frac{\partial}{\partial x_j}\right) = \delta_{ij}
$$ where $\delta_{ij}$ is the Kronecker delta. Moreover, the application $(\alpha\wedge \beta)(u, v)=\alpha(u)\beta(v)-\alpha(v)\beta(u)$ which can be written as a determinant (and generalized for the $k$ -forms). Now comes my questions all regarding Lecture 7. At 6:23, the motivation behind the definition of the integral of a 2-form $\omega$ is that it is the summation of $\omega_{p_i}$ (evaluate $\omega$ at the point $p_i$ ) applied to a pair of vectors $u_i=u({p_i}),v_i=v(p_i)$ (for some vector fields $u,v$ ) along with the whole region $\Omega$ : $$
\sum_{i}\omega_{p_i}(u_i,v_i)\to \int_{\Omega}\omega
$$ However, in 8:31 we have the integral of a form $(x+xy)dx\wedge dy$ over $\Omega$ which is the unit square. Then, somehow it follows that $$
\int_{\Omega} (x+xy)dx\wedge dy = \int_0^1\int_0^1 (x+xy)dxdy
$$ where I don't see to what vectors $u,v$ are we applying the form $dx\wedge dy$ . Mainly, I'm lost at the motivation behind the interpretation of the 2-form $dx\wedge dy$ as a scalar $dxdy$ inside the integral, given that $dx$ and $dy$ were supposed to be just basis forms (covectors). The following may be too hand wavy, but I'm trying to get intuition about this: My thoughts are that we make a parallelepiped spanned by the vectors $u=(dx)\frac{\partial}{\partial x}$ and $v=(dy)\frac{\partial}{\partial y}$ where here $dx$ and $dy$ are small displacements in the directions $\frac{\partial}{\partial x},\frac{\partial}{\partial y}$ . This parallelepiped has area $dxdy$ , and we can measure such area by the form $dx\wedge dy$ . Hence, we use $dx\wedge dy$ to measure this parallelepiped obtaining $dx\wedge dy(u,v)=dxdy$ . However, this reasoning seems artificial to me (since we didnt't take advantage of the notation dx,dy for the basis covectors, instead we used other displacements $dxdy$ different from the basis covectors). It would be better to have defined $dx(\frac{\partial}{\partial x})$ ="" $dx$ "" (where the second $dx$ is the displacement and not the covector) instead of $dx(\frac{\partial}{\partial x})=1$ as we did before (move the displacements $dx$ and $dy$ to the definition of the covectors $dx$ and $dy$ instead of the parallelepiped $u\wedge v$ ). At 14:00, one finds the integral of a 1-form $\alpha=dy$ over the circular curve $S^1$ (parametrized as $\gamma:[0,2\pi)\to\mathbb{R}^2, \gamma(s) = (\cos(s),\sin(s))$ ), which somehow results in: $$
\int_{S^1}\alpha = \int_0^{2\pi} \alpha_\gamma(T(s))ds
$$ where $T(s)$ is the tangent vector to $\gamma(s)$ . Here we are clearly applying the form $\alpha$ to a vector, different from my previous doubt. Howeve, different than before, instead of using $dy$ as the differential in the integral, we introduced an additional $ds$ where I don't know where it came from. I already know how to compute this integrals, and I know that their expressions make sense from the typical vector calculus perspective. But I want to understand what is the systematic way of translating the integral of $k$ -forms to a multiple-integral. My confusion comes from the fact that it appears that very different ""rules"" were used to translate $\int_{\Omega} (x+xy)dx\wedge dy = \int_0^1\int_0^1 (x+xy)dxdy$ as in the case $\int_{S^1}\alpha = \int_0^{2\pi} \alpha_\gamma(T(s))ds$ .","['integration', 'differential-forms', 'differential-geometry']"
4093062,"Uniform convergence of $\sum\limits_{n=1}^{\infty} (-1)^n \frac{\arctan(x^n)}{\sqrt{n+1}}$ , $x \in[0,\infty)$","I have a problem with checking the uniform convergence of $\sum\limits_{n=1}^{\infty} (-1)^n \frac{\arctan(x^n)}{\sqrt{n+1}}$ , $x \in[0,\infty)$ . I suppose that using Abel-Dirichlet criterion should help, but I only know, that $\sum\limits_{n=1}^{\infty} \frac{1}{\sqrt{n+1}}$ is monotonically decreasing, non negative and bounded. And that the function $\frac{1}{\sqrt{n+1}}$ converges locally uniformly to $0$ on $(0,\infty)$ (I am also not sure, whether locally uniform convergence is enough for Dirichlet test, or if the uniform convergence on given interval is necessary) . But I am not able to show, that $\sum\limits_{n=1}^{\infty}(-1)^n \arctan(x^n)$ is uniformly convergent on $[0,\infty)$ (Abel) or that it has uniformly bounded partial sums (Dirichlet). Or should I use completely different approach? Thanks for any help.","['real-analysis', 'functions', 'uniform-convergence', 'sequences-and-series', 'convergence-divergence']"
4093114,Trigonometry application in a problem,"The answer to the question is 15 degrees. I would like to know if it is possible to solve by trigonometry. If so, how? Law of sines and other things, but how to do without using a calculator?","['trigonometry', 'geometry']"
4093188,Constructing a set by iteratively taking powersets,"Short question Is this definition correct (in the sense that it defines a set)? Let A be defined inductively as the smallest set such that: $ \{ 1, 2, 3 \} \subseteq A$ if $X \subseteq A$ , then $2^X \subseteq A$ A few ideas The ""defined inductively"" part seems to be ok to me since it could be seen as the least fixpoint of the function $$
F(X) = \{ 1, 2, 3 \} \cup 2^X
$$ which is monotone in $X$ . But does a non-naive set theory (maybe ZFC?) admit such a definition? Or would this definition, if admitted, lead to some paradoxes (like Russel's paradox )? If that definition works, what would be the domain of $F$ (because it cannot be the ""set of all sets""). I would approach it this way: $F$ could be a function on the class of all sets. But can we then take its fixpoint? Does the Knaster-Tarski theorem work outside the realm of sets, $\mu F$ then being a class? If so, we could then try to prove $\mu F$ to be a set from the ZFC axioms. Is this the right approach?",['elementary-set-theory']
4093216,"If f is integrable and g is bounded in [a,b] then the upper integral of f+g = integral of f+ upper integral of g","I need to prove the following when f is integrable: $\overline{\int_{a}^{b}}(f+g)(x)dx = {\int_{a}^{b}}f(x)dx+\overline{\int_{a}^{b}}g(x)dx$ I'm not sure how to go about this proof, in the first part of the question I proved that if both are bounded then: $\overline{\int_{a}^{b}}(f+g)(x)dx \le \overline{\int_{a}^{b}}f(x)dx+\overline{\int_{a}^{b}}g(x)dx$ but I'm not sure how to use f being integrable to prove these are equal. I do know that f being integrable also means I proved the $\le$ part of the question
but how do I prove the other way? Will appreciate any hint/tips...","['integration', 'riemann-integration']"
4093223,Change of variable formula when integrand involves partial derivatives,"A well known change of variable theorem of integral calculus says the following. Let $X$ and $Y$ be two open sets in $\mathbb{R}^2$ and $\phi: X \rightarrow Y$ be a diffeomorphism.
Then \begin{eqnarray}\tag{1}
\int\limits_{Y} f(y_1,y_2) dy_1 dy_2=\int\limits_{X} f(\phi(x_1,x_2)) \left|J_{\phi}(x_1,x_2)\right| dx_1 dx_2,
\end{eqnarray} where $J_{\phi}$ denotes the  Jacobian matrix of $\phi.$ What is the corresponding change of variable formula if the integrand involves derivatives.
More precisely, for $f \in C^1$ what is the change of variable formula if the integrand is \begin{eqnarray}
\int\limits_{Y} \left(\partial_1f(y_1,y_2)+\partial_2f(y_1,y_2)\right) dy_1 dy_2=\int\limits_{X} \cdot\cdot\cdot\cdot dx_1 dx_2.
\end{eqnarray} How to prove the change of variable formula for such integrand using the change of formula (1) ?","['integration', 'measure-theory', 'analysis', 'change-of-variable', 'partial-derivative']"
4093227,Find a positive integer $i$ such that $9i + 1$ divides $2 \times 10^i - 1$,"I have written a Python program running over $i$ , but up to billions there is no solution, so I guess there is no solution. Trying to prove that, I looked at multiplicative order, but I do not get a grip on $9i +1$ . Anybody an idea for the proof (or finding a huge $i$ )?","['exponential-diophantine-equations', 'number-theory', 'divisibility', 'diophantine-equations']"
4093251,How do I show the inequality $\tan(|\Re(\pi z/4)|) \le |\tan(\pi z/4 )|$ for $z$ in the unit disc?,"I trying to prove the ""Schwarz's lemma for harmonic functions:"" If $u:\Bbb D \to \Bbb R$ is harmonic, $u(0) = 0$ , and $|u(z)| \le 1$ for each $z \in \Bbb D$ , then $$ |u(z)| \le \frac{4}{\pi}\arctan(|z|). $$ The idea I have is to notice that since $\Bbb D$ is simply connected, $u$ is the real part of an analytic function $f:\Bbb D \to \Bbb C$ . In particular, we may choose its harmonic conjugate so that $f(0) = 0$ . Now since $|u(z)| \le 1$ , $f(\Bbb D) \subseteq (-1,1)\times\Bbb R$ , and we can map this infinite strip conformally onto $\Bbb D$ by the map $z \mapsto \tan\left(\frac{\pi}{4} z\right)$ . From here, we can use the standard Schwarz lemma on the function $g:\Bbb D \to \Bbb D$ defined by $$ g(z) = \tan\left(\frac{\pi}{4}f(z)\right) $$ since $g(0) = 0$ . This gives $$ |g(z)| \le |z|, $$ and unpacking this gives $$ \left|\tan\left(\frac{\pi}{4}f(z)\right)\right| \le |z|. $$ In order to complete the proof, I must show the inequality $$ \tan\left(\left|\mathrm{Re}\left(\frac{\pi}{4}z\right)\right|\right) \le \left|\tan\left(\frac{\pi}{4}z\right)\right|, $$ so that I can then get $$ \tan\left(\left|\frac{\pi}{4}u(z)\right|\right) \le |z| $$ and hence $$ |u(z)| \le \frac{4}{\pi}\arctan(|z|). $$ I found that you can write $\tan(z)$ in terms of its real and imaginary parts as $$ \tan(x + iy) = \frac{\sin(2x) + i\sinh(2y)}{\cos(2x) + \cosh(2y)}, $$ and using Desmos I assured myself that the inequality is true, but I have no clue how to show such an inequality. Any help is appreciated!","['complex-analysis', 'inequality']"
4093294,Characterization of free product of groups by lifting property with respect to morphisms with right inverse,"A morphism $i : A \to B$ has the left lifting properties with respect to a morphism $p : X \to Y$ if and only if any commutative square with $i$ on the left and $p$ on the right has a diagonal lift making everything commute: It is easy to see that the canonical inclusion of any group $G$ in a free product $G \to G * H$ has the left lifting property with respect to all morphisms with a right inverse. It made me think about the converse: is it true that for a morphism $f : G \to H$ , there exists a group $G'$ and an isomorphism $\phi : H \to G * G'$ such that $\phi \circ f$ is the canonical inclusion if and only if $f$ has the left lifting property with respect to all morphisms with right inverse? An interesting corollary, if this proposition is true, is that for a morphism $f : G \to H$ , there is a free group $F$ and an isomorphism $\phi : H \to G * F$ such that $\phi \circ f$ is the canonical inclusion if and only if it has the left lifting property with respect to all surjective morphisms.","['combinatorial-group-theory', 'group-theory', 'abstract-algebra', 'free-product']"
4093360,Confused about computing the gradient of least-squares cost,"Given matrix $A \in \mathbb R^{m \times n}$ and vector $y \in \mathbb R^m$ , I want to take the gradient of the following scalar field with respect to $x\in \mathbb R^n$ . $$x \mapsto \big((Ax - y)^T(Ax - y) \big),$$ $\textbf{Attempt}.$ \begin{align}
\frac{\partial}{\partial x}  \big((Ax - y)^T(Ax - y) \big)
&= \frac{\partial}{\partial x} \big( (x^TA^TAx - x^TA^Ty - y^TAx+ y^Ty )\big)\\
&= \frac{\partial}{\partial x}x^TA^TAx - \frac{\partial}{\partial x}x^TA^Ty - \frac{\partial}{\partial x}y^TAx+ \frac{\partial}{\partial x}y^Ty  \\
&= 2 A^TAx - A^Ty - y^TA\qquad\,\,\mathbf{(1*)}\\
&= 2 A^TAx - 2A^Ty. \qquad\qquad\,\mathbf{(2*)}\\
\end{align} $\textbf{Question}.$ There are two expressions above marked by $(*)$ . I don't understand the justification in going from $(1*)$ to $(2*)$ (in fact, the dimensions don't make sense...), which makes me think that there is a mistake in $(1*)$ . Can someone explain the basics involved in these matrix manipulations?","['matrices', 'multivariable-calculus', 'least-squares', 'scalar-fields']"
4093371,"Show that a graph that is connected but not complete has vertices u,v and w such that uv and vw are edges but not uw.","Show that if $G$ is connected and not complete, then $G$ has three vertices $u$ , $v$ and $w$ such that $\{ (u, v), (v, w)\} \subseteq  A(G)$ and $(u, w) \notin A(G)$ . I have the following: Since $G$ is not complete, we know that there exists vertices $u$ and $w$ that do not have an edge connecting. $G$ is connected, meaning that there is a path for any two vertices, and the shortest path between them would be $v=v_0,v_1,..., v_n=w$ from $v$ to $w$ . I think now we must find the shortest path from u to w. If G were a complete graph, we are done. Since G is not a complete graph, there must be some other path from v to w that is 2 or more long.","['graph-theory', 'graph-connectivity', 'path-connected', 'discrete-mathematics']"
4093373,Differential of exponential map w.r.t. the point,"Suppose we have a standard Riemmanian exponential map $\exp: TM \to M$ given by $\exp(s, v) = \gamma_s(1)$ , where $s \in M, p \in T_s M$ and $\gamma$ is a geodesic with $\gamma(0) = s, \gamma'(0) = v$ . It is a standard fact that for $\exp_s$ ( $\exp$ restricted to $T_s M$ ) we have $d_0\exp_s = id$ . I, however, want to know what is the differential of the full map $\exp$ when regarded as a map between manifolds $TM$ and $M$ . In other words, I want to know how this map changes when we infinitesimally move point $s$ around. I believe that it should involve curvature tensor of the ambient manifold M; however, my attempts to calculate it were unsuccessful so far. Because of that, my questions are: 1)How to approach this problem? 2)Is there a canonical choice of coordinates on $TM$ that would allow me to brute force it in coordinates? I was attempting to calculate it in Riemmann normal coordinates on $M$ together with the adapted frame on $T_s M$ moved to other points by parallel transport; in this case our mapping is nice on each fixed tangent space but is less nice on the zero section. Or maybe it is still ok - then I would appreciate an advice in this direction. Thank you all!","['riemannian-geometry', 'differential-geometry']"
4093378,Connection between Eulerian numbers and number of elements in set of uniform variables greater than the mean?,"I was recently investigating the following question: Given $n$ independent $\text{Unif(0, 1)}$ variables $U_1,\ldots,U_n$ , let $m$ be the number of elements in $[U_1,\ldots,U_n]$ that are greater than the mean $\frac{U_1+\ldots+U_n}{n}$ . What is the distribution of $m$ given $n$ ? For example, if $U_1,U_2,U_3,U_4=0.2,0.7,0.8,0.9$ , then the mean is $0.65$ and $U_2,U_3,U_4$ are greater than the mean, so $m=3$ . Running lots of simulations in Python, it appears that the probability of having $m$ elements greater than the mean in $n$ independent $\text{Unif(0, 1)}$ variables is $$P(m|n)=\frac{A(n-1,m-1)}{(n-1)!}$$ Where $A(n-1,m-1)$ is the Eulerian number equal to the number of permutations of $(1,\ldots,n-1)$ with $m-1$ ascents. More information about the Eulerian numbers can be found at https://en.wikipedia.org/wiki/Eulerian_number and https://oeis.org/A008292 Does anyone know of an existing proof relating the Eulerian numbers to number of uniform variables above the mean? The closest thing I could find is a proof that $P(k-1\leq\sum\limits_{i=1}^n U_i \leq k)=\frac{A(n,k)}{n!}$ , in the following article: https://www.sciencedirect.com/science/article/pii/S0097316597928326","['eulerian-numbers', 'combinatorics', 'uniform-distribution']"
4093420,Integration of function with respect to counting measure,"Consider the measurable space $\left(\mathbb{N},\mathscr{P}(\mathbb{N})\right)$ with the counting measure $c$ and let $f\colon\mathbb{N}\to\mathbb{R}$ be any function. I want to show that $$\int_{\mathbb{N}}f\,dc = \sum_{n=1}^{\infty}f(n).\tag{1}$$ I've seen the proof (on StackExchange) that $(1)$ holds given that $f\colon\mathbb{N}\to[0,\infty]$ , but not for this particular problem. Further, the proof in that case uses the Monotone Convergence Theorem as $f$ is non-negative. However, how can I do the proof without the assumption that $f$ is non-negative, i.e. without the Monotone Convergence Theorem? Moreover, is there anyway to modify the proof for case that $f$ is non-negaive? To add, I know some convergence theorem needs to hold, more than likely the Dominated Convergence Theorem, but I can figure out a sequence of functions that work. For the non-negative case, the sequence of functions given by $$
f_n(k)=\begin{cases}f(k) & \text{if }1\leq k\leq n\\ 0 & \text{else}\end{cases},
$$ for $n\in\mathbb{N}$ works.",['measure-theory']
4093446,Number of functions such that $f(f(f(x)))=f(f(x))$,"If $A=\left\{1,2,3,4,5\right\}$ , then find the number of functions satisfying $$f(f(f(x)))=f(f(x)), \forall x \in A \to (1)$$ Related: Number of functions satisfying $f(f(x))=f(x)$ . I actually took the help from the thread above and tried as follows:
From $1$ we see that if $y \in \operatorname{im}(f)$ , then $$f(f(y))=f(y) \to (2).$$ Now consider the following cases: Case $1.$ If $\operatorname{im}(f)$ contains only one element, then trivially its a constant function and satisfies $(1)$ . Number of such functions is $\binom{5}{1}=5$ . Case $2.$ Let $\operatorname{im}(f)$ contains only two elements. WLOG let us assume $\operatorname{im}(f)=\left\{1,2\right\}$ From $(2)$ we have $$f(f(1))=f(1), f(f(2))=f(2)$$ $\implies$ $$f(f(f(1)))=f(f(1)), \:f(f(f(2)))=f(f(2))$$ Now if $f(1)=2$ then it implies $f(2)=2$ and let $f(3)=1, f(4)=2,f(5)=2$ , then we have $$f(f(f(3)))=2=f(f(3))$$ $$f(f(f(4)))=2=f(f(4))$$ $$f(f(f(5)))=2=f(f(5))$$ So definitely this is one of the function which satisfies the hypothesis. But how to count number of such functions? What about the upcoming cases?","['contest-math', 'functions', 'combinatorics', 'function-and-relation-composition']"
4093474,Minimum of $E(z)=|z+1|+|z^{2n}+1|$,"Let $n \in \mathbb{N}$ . Find the minimum of the expression $E(z)=|z+1|+|z^{2n}+1|$ over $\mathbb{C}$ . I found this problem in a Romanian magazine with all sorts of math problems. ( Edit : ${\color{blue}{\textrm{This was suggested for a contest for 10th graders}}}$ , According to @alexanderv's comment.) What I've done so far(WRONG): $E \geq 0$ so if we can find $z$ with $E(z)=0$ it's enough. If $n=0$ , the minimum is achieved in $-1$ , $E(z) =2$ . If $n \geq 1$ , let's take $z= \cos \theta + i\sin \theta$ . Using $|1+\cos \alpha + i\sin \alpha|=2| \cos (\frac{\alpha}{2})|$ , we get $E(z)=2(|cos(\frac{\theta}{2})|+|cos(n\theta)|)$ . Then, taking the modulus and using $\cos(\pi-\alpha)=-\cos(\alpha)$ and the $\cos(x) + \cos(y)$ formula, we take $z$ so one of the product terms equals to $0$ , achieving the minimum. But I'm not sure if it's right, can someone approve? What's wrong above is $E(z)=0$ implies $z=-1$ , that means $E(z)=2$ , contradiction. I don't have any idea how to find the minimum.","['complex-analysis', 'inequality', 'complex-numbers']"
4093478,Switching quantifies for the definition of a limit.,"For my analysis homework I am asked to prove or disprove that if you switch the quantifiers of the definition of a limit, then the definitions are equivalent. More specifically we are asked to prove or disprove for $\lim_{x\to c}f(x)=L$ that these definitions are equivalent, $\forall \epsilon>0\; \exists\delta>0\; s.t. \forall x\in A\; \text{if}\; |x-c|<\delta, \text{then}\; |f(x)-L|<\epsilon $ $\exists\delta>0\; \forall \epsilon>0  s.t. \forall x\in A\; \text{if}\; |x-c|<\delta, \text{then}\; |f(x)-L|<\epsilon $ My idea is that they are not equivalent. My reasoning is that in the second definition there is an existence claim for delta followed by for all epsilon. This would imply that epsilon depends on delta which would make every limit exist because there is a delta for every epsilon meaning $|x-c|<\delta$ would always imply $|f(x)-L|<\epsilon$ . I am wondering if this is correct reasoning or if I am missing something. Thank you!","['epsilon-delta', 'real-analysis', 'definition', 'solution-verification', 'limits']"
4093606,"Double Integration in region $A=\{ (x,y)\in \mathbb{R}^{2} : x^{2}+y^{2}\le 1, x+y \ge 1, y \le x\}$.","Calculate $$\iint _{A} (x^{2}+y^{2})^{-3/2} \,dx\,dy\,,$$ where $A=\{ (x,y)\in \mathbb{R}^{2} : x^{2}+y^{2}\le 1, x+y \ge 1, y \le x\}$ . I first found the intersection points that are $(1,0)$ , $\left(\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}\right)$ and $\left(\frac{1}{2}, \frac{1}{2}\right)$ . And the determined the regions \begin{split}
D & =\left\{(x,y)\in \mathbb{R}^{2}: x^{2}+y^{2}, y \le x\} = \{(r,\theta)\in \mathbb{R}^{2}: 0 \le r \le 1, 0 \le \theta \le \frac{\pi}{4} \right\}\\
B & =\left\{(x,y)\in \mathbb{R}^{2}: 0 \le x \le \frac{1}{\sqrt{2}}, 0 \le y \le x\right\}\\
C & =\left\{(x,y)\in \mathbb{R}^{2}: \frac{1}{\sqrt{2}} \le x \le 1,  \frac{1}{\sqrt{2}} \le y \le 1-x \right\}
\end{split} Then, $$\iint _{A} (x^{2}+y^{2})^{-3/2} \,dx\,dy = \iint_{D} (x^{2}+y^{2})^{-3/2} \,dx\,dy - \iint_{B} (x^{2}+y^{2})^{-3/2} \,dx\,dy - \iint_{C} (x^{2}+y^{2})^{-3/2} \,dx\,dy$$ Is this right? Or is there any other easiest way?","['integration', 'multivariable-calculus', 'multiple-integral', 'definite-integrals']"
4093709,Combinatorics - How many ways are there to arrange the string of letters AAAAAABBBBBB such that each A is next to at least one other A?,"I found a problem in my counting textbook, which is stated above. It gives the string AAAAAABBBBBB, and asks for how many arrangements (using all of the letters) there are such that every A is next to at least one other A. I calculated and then looked into the back for the answer, and the answer appears to be $105$ . My answer fell short of that by quite a bit. I broke down the string into various cases, and then used Stars and Bars to find how many possibilities there are for each. Now here's what I have got so far. First case would be all As are right next to each other, leaving $2$ spots for the $6$ Bs. That gives $\binom{7}{1}$ from Stars and Bars, $7$ possibilities. Second case was dividing the As into $2$ groups of 3 As. There would have to be $1$ B between the two, which leaves $5$ Bs that can be moved. Using Stars and Bars, there are $3$ possible places to place a B and $5$ Bs in total, so $\binom{6}{2}$ , $15$ possibilities. Then there's a group of $4$ As and another group of $2$ As. $1$ B would be placed inbetween, and then the calculation would be the same as the second case, except it would have to be doubled to account that the groups of As can be swapped and it would be distinct. That gives $30$ possibilities. Then I found one final case of dividing the As into 3 groups of 2 As. 2 Bs would immediately be placed between the 3 groups, leaving 4 Bs to move between the 4 possible locations. I got $\binom{5}{3}$ for that, which adds $10$ possibilities. Summing it up, I only have $62$ possibilities, which is quite far from the $105$ answer. Any ideas where I might have miscalculated or missed a potential case? Additionally, are there any better ways to calculate this compared to this method of casework?","['combinatorics-on-words', 'combinatorics']"
4093729,How can I evaluate $ \sum_{n=0}^{\infty}{\frac{x^{kn}}{(kn)!}} $ where $k$ is a natural number? [duplicate],"This question already has answers here : Find the sum of series $\sum_{n=0}^{\infty}\frac{z^{kn}}{(kn)!}$ (1 answer) Exponential Taylor series with $k$ step (2 answers) Closed 3 years ago . I suddenly interested in the differential equation $$ f^{(k)}(x)=f(x) $$ So I tried to calculate for some $n$ . When $ k=1 $ , we know the solution $$ f(x)=A_0e^x=\sum_{n=0}^{\infty}{\frac{A_0x^n}{n!}} $$ Also, for $ k=2 $ , $$ f(x)=Ae^x-Be^{-x}=\sum_{n=0}^{\infty}{(\frac{A_0x^{2n}}{(2n)!}+\frac{A_1x^{2n+1}}{(2n+1)!})} $$ where $ A_0=A+B $ and $ A_1=A-B $ . Inductively, I could guess that the solution of the differential equation would be in the form $$ f(x)=\sum_{n=0}^{\infty}{\sum_{i=0}^{k-1}{\frac{A_ix^{kn+i}}{(kn+i)!}}} $$ But I could neither prove that it is the only solution nor get the explicit formula. How should I evaluate $ \sum_{n=0}^{\infty}{\frac{x^{kn}}{(kn)!}} $ , cause if we know the answer for it, we can evaluate the original expression by differentiating it. Thanks to WolframAlpha, I know the answer for $ k=3 $ , $$ \sum_{n=0}^{\infty}{\frac{x^{3n}}{(3n)!}}=\frac{1}{3}(2e^{-\frac {x}{2}}\cos{(\frac {\sqrt{3}}{2}x)}+e^{x}) $$ I think the answer might related to $ \sin $ and $ \cos $ of $ \frac {2\pi}{k} $ .","['power-series', 'functional-equations', 'ordinary-differential-equations', 'sequences-and-series']"
4093810,MLE and biasedness,"Question: Let $X_1, ..., X_n \sim \text{Exp}(\lambda)$ where $E(X) = \lambda$ . Find MLE for $\log(\lambda)$ , and show if it is biased or not. From the description, $f_X(x) = \lambda^{-1}\exp(-\lambda^{-1}x)$ I know that $\bar{X}$ is the MLE for $\lambda$ , and since $\log$ is a bijection, and overall a ""good"" function, invariance of MLE applies. So MLE of $\log(\lambda) = \log$ of MLE of $\lambda = \log(\bar{X})$ . I know $\bar{X}$ is an unbiased estimator of $\lambda$ , and I doubt $E(\log(\bar{X})) = \log(\lambda)$ because of Jensen's inequality. Is there a better way of proving this (preferably not calculating the integral), especially when Jensen's inequality doesn't apply? In addition, the follow-up question asks me to show that MLE of $\log(\lambda)$ is ""CAN"" for $\log(\lambda)$ , and then identify its asymptotic normal variance. I suppose ""AN"" in ""CAN"" means asymptotic normal. Does any one know what the ""C"" might stand for? Also, how do I calculate its asymptotic normal variance? Thanks!","['statistics', 'parameter-estimation', 'probability-theory', 'maximum-likelihood']"
4093817,"Clever substitution on evaluating $\int_{0}^{\infty} \frac{\sin(2x+\frac{x^2}{t^2})}{2x+\frac{x^2}{t^2}} \, dx$","I've been working on evaluating some integrals that come up when studying Fresnel integrals, and I've come across this one: $$\int_{0}^{t^2}  \frac{\sin(2x+\frac{x^2}{t^2})}{2x+\frac{x^2}{t^2}} \, dx$$ and immediately it reminded me of the famous integral: $$\int_{0}^{\infty} \frac{\sin{x}}{x} \, dx = \frac{\pi}{2}$$ with which I dared to conjecture that: $$\lim_{t\rightarrow \infty}{\int_{0}^{t^2}  \frac{\sin(2x+\frac{x^2}{t^2})}{2x+\frac{x^2}{t^2}} \, dx}=\frac{\pi}{4}$$ I have tried to do substitutions without success, I also tried to use something like the dominated convergence theorem to swap the integral with the limit and I think it may work, but, will there be some substitution that allows me to evaluate the integral without using something like the dominated convergence theorem ? Thank you all","['improper-integrals', 'calculus', 'definite-integrals', 'real-analysis']"
4093828,Prove that set of increasing polynomials of degree $n$ is a connected subset of the set of all polynomials of degree $n.$,"Let $X$ be the space of all real polynomials $a_0 + a_1 t + a_2 t^2 + \cdots + a_n t^n$ of degree at most $n.$ We may think of $X$ as a topological space via it's identification with $\Bbb R^{n+1}$ given by $$a_0 + a_1 t + a_2 t^2 + \cdots + a_n t^n \longmapsto (a_0,a_1,a_2, \cdots , a_n).$$ Now consider the space $S$ consisting of all polynomials in $X$ that are increasing (as a function from $\Bbb R$ to $\Bbb R$ ). Is $S$ a connected subset of $X\ $ ? $\textbf{My Thoughts} :$ If $f(t) \in S$ then $f'(t) \gt 0,$ for all $t \in \Bbb R.$ Now for each fixed $t \in \Bbb R$ the equation $f'(t) = 0$ determines a plane passing through the origin in $\Bbb R^{n+1}$ and thus it's complement will have two connected components. How to determine the connected components in terms of $f\ $ ? I think one of them is determined by $f'(t) \gt 0$ and the other one is determined by $f'(t) \lt 0.$ Although I am struggling to prove this. With these things in mind what can we conclude about the connectedness of $S\ $ ? I got stuck at this stage. Any help will be highly solicited. Thanks in advance.","['general-topology', 'derivatives', 'polynomials', 'connectedness']"
4093829,$f^{(n)}(0) = g^{(n)}(0)$ implies $f(x) = g(x)$? [duplicate],"This question already has an answer here : Smooth function with all derivatives zero (1 answer) Closed 3 years ago . I want to solve following problem Let $f,g : (-1, 1) \rightarrow \mathbb{R}$ be $C^{\infty}$ functions, and suppose that $f^{(n)}(0)= g^{(n)}(0) $ for $n=0,1,2,\cdots, $ . Is there some $\delta>0$ such that $f(x) = g(x)$ for all $x \in [-\delta, \delta]$ ? Naively, from taylor series expansion of $C^{\infty}$ functions, I suspect that there is $\delta>0$ but I don't know how to prove this rigorously.","['analysis', 'real-analysis']"
4093934,Find unique permutations of a set with constraints on sequences,"I have a set of 11 items {A, B, ... J, K}. I would like to find 11 permutations so that: Each permutation starts with a different item (e.g. the first with A, second with B...) Each sequence of two items in the 11 permutations is unique (if the sequence AB appears in the first permutation, it must not appear in any of the other 10 permutations). I would think this also means each permutation should end with a different item. For instance, these two permutations are a start: A,B,C,D,E,F,G,H,I,J,K
B,D,F,H,J,A,C,E,G,K,I How could I find a solution?","['graph-theory', 'combinatorial-designs', 'combinatorics', 'sequences-and-series']"
4093997,Resources to learn hard analysis,"I am looking for book (or any other resource) recommendations to practice ""epsilonics"", and technical analysis of the asymptotics of integer sequences (or real sequences), hard analytical estimates, etc. To give an example of what I have in mind, the following is from a paper of Erdos on the number of partitions $p(n)$ of a positive integer $n$ . Let $d=\liminf \frac{np(n)}{e^{cn^{1/2}}}$ , $D=\limsup \frac{np(n)}{e^{cn^{1/2}}}$ , where $c=\pi\sqrt{2/3}$ . Since $p(n)$ is an increasing function of $n$ there exists a $c_2$ such that for every $m$ in the range $n \le m \le n + c_2n^{1/2}$ , we have $$
\frac{mp(m)}{e^{cm^{1/2}}} > \frac{D + d}{2}
$$ Now we claim that for every $r_1$ there exists a $\delta_{r_1} = \delta(r_1)$ such that for $n \le m \le n + c_2n^{1/2}$ , $$
\frac{mp(m)}{e^{cm^{1/2}}} > d + \delta_{r_1}
$$ Then he goes on to prove the lemma. When I see statements such as ""for every $r_1$ there exists a $\delta_{r_1}...$ , or ""there exist constants $c$ and $x_0$ such that some function $f(n) < cn^{1/2}$ "", I'm in complete awe. I can read, but can't easily understand such hard technical statements, though the prerequisites seem to be nothing  beyond a first course in real analysis, which I have met (I'm an undergrad student). I want to learn how to create such technical arguments.Where does one go to get good at such things (None of my classes offer these sort of things)? What are some good resources for practicing?","['number-theory', 'soft-question', 'book-recommendation', 'analysis']"
4094015,Kernel of certain differential operators,"Let $U \subset \mathbb C^2$ be a domain and $f : U \to \mathbb C$ smooth (not necessarily holomorphic). Let $f$ further be in the kernel of the following differential operators. $$\frac{\partial^2}{\partial x_i \partial x_j} + \frac{\partial^2}{\partial y_i \partial y_j}$$ and $$\frac{\partial^2}{\partial x_i \partial y_j} - \frac{\partial^2}{\partial x_j \partial y_i}$$ for $i,j \in \{1,2\}$ . What is the solution space of $f$ ? Is it only the polynomials of degree less than 2?. Motivation: This should be just the kernel of $\partial \overline{\partial}$ sending $0$ -forms to $(1,1)$ -forms.","['ordinary-differential-equations', 'real-analysis', 'complex-analysis', 'derivatives', 'differential-forms']"
4094036,Find $f$ such that $f \star f(x) = \frac{1}{1-x}$.,"I'm looking for a measurable function $f$ defined on $]0,1[$ such that : $$f \star f(x) = \int_{0}^1 f(x-y) f(y) \ \mathrm{d}y = \frac{1}{1-x}$$ for (almost) any $x \in ]0,1[$ . Is it possible to find or construct such a function f ? Eventually, we can define $f$ on $\mathbb{R}$ with $f=0$ outside of $]0,1[$ . Any help or advises on how to proceed are welcomed. I have already tried without sucess : looking for $f$ in a rational fraction form looking for $f$ in the form $\sum_{n} a_n x^n$ looking for $f$ in the form $e^{F(x)}$ with a suitable $F$ . I also started to consider fourier transform and fourier series (by periodisation on $]0,1[$ ) but it is difficult to define the fourier transform of the right hand side $\frac{1}{1-x}$ . Also about the regularity of $f$ , we can see that $f$ can't be in $L^1(]0,1[)$ because of the regularity properties of the convolution.","['lebesgue-measure', 'integral-equations', 'definite-integrals', 'convolution', 'real-analysis']"
4094170,Cubic Casimir for $su(3)$,"I'm trying to figure out the form of the Casimir operators for $su(3)$ . According to Racah's theorem, this group has two independent Casimir operators that can be constructed from its generators. The first one is easy to find: using the Gell-Mann matrices $\lambda_i,\ i=1,...8\ $ as generators, it can be written as $$
C_1 = \sum_{i=1}^8 \lambda_i^2
$$ However, I'm struggling to construct the second one. In $\textit{The Lie Algebras su(N). An introduction}$ (section 4.11), Walter Pfeifer writes that $C_2$ is given by $C_2 = C_1(2C_1 - 11/6)$ , and that this operator can be transformed so that it is expressed as sum of products of three $\lambda_i$ 's. However, this Casimir operator is not independent from $C_1$ (in fact, it is completely determined by it). So, is this expression correct? If not, how can one construct the missing Casimir operator for $su(3)$ ?","['unitary-matrices', 'group-theory', 'lie-algebras', 'lie-groups']"
4094196,limit of two entirely different sequences,"Let be two sequences $a_n$ and $b_n$ with $a_0 $ and $b_0$ positive real numbers such that $$a_{n+1}=3a_nb_n(a_n+b_n)$$ and $$b_{n+1}=a_n^3+b_n^3$$ Find the limit of $$\lim \frac{a_0^3+a_1^3+...+a_{n-1}^3}{a_n}$$ I obtained that $a_n+b_n=(a_0+b_0)^{3^n}$ by induction.
If it helps I do not know how to obtain the sum $a_0^3+a_1^3+...+a_{n-1}^3$ what should I do. Any idea is welcomed.","['limits', 'sequences-and-series']"
4094231,When is the infinite union of compact sets a compact set?,"We know that in general the union of infinitely many compact sets is not a compact set, however it is possible to have some cases in which the union is compact. Is there any study about these cases? I tried to find some information but I couldn't find anything. I'd like some characterization of these unions that determines under which circumstances it is compact. Anything on any space is welcome. Thanks in advance!","['general-topology', 'compactness']"
4094296,An Application of Holder's Inequality (Possible use of Jensen's also?),"Let $(X,\mathcal{A},\mu)$ be a finite measure space with $\mu(X) = 1 $ Let $f,g$ be two measurable non-negative real valued functions $X \to (0,\infty)$ such that $f(x)g(x) \geq 1$ Show that $1 \leq \int_X f d\mu \cdot \int_X g d\mu $ My attempt: Assume that both $f$ and $g$ are integrable otherwise the statement holds trivially as the integrals cannot be $-\infty$ (by non-negativity of $f$ and $g$ ). Define $a(x) = f(x)^{\frac{1}{2}}$ and $b(x) = g(x)^{\frac{1}{2}}$ Then by our assumption of the integrability of $f $ and $g$ we have that $a,b \in \mathcal{L}^2$ Hence taking $p = q = 2$ and applying Holder's inequality we have the following: $\int_X a(x)b(x) d\mu \leq (\int_X a(x)^2 d\mu)^{\frac{1}{2}} \cdot(\int_X b(x)^2 d\mu)^{\frac{1}{2}}  $ Putting everything back into terms of $f$ and $g$ simplifies to: $\int_X (f(x)g(x))^{\frac{1}{2}} d\mu \leq (\int_Xf(x) d\mu)^{\frac{1}{2}} \cdot (\int_Xg(x) d\mu)^{\frac{1}{2}}  $ Considering the convex function, $\theta \to \theta^{\frac{1}{2}},$ and applying Jensen's inequality to our left hand side, namely $(\int p(x) d\mu )^{\frac{1}{2}} \leq \int p(x)^{\frac{1}{2}} d\mu$ We are left with: $(\int_X f(x)g(x) d\mu)^{\frac{1}{2}} \leq (\int_Xf(x) d\mu)^{\frac{1}{2}} \cdot (\int_Xg(x) d\mu)^{\frac{1}{2}}  $ And so: $\int_X f(x)g(x) d\mu \leq \int_Xf(x) d\mu \cdot \int_Xg(x) d\mu  $ And as $f(x)g(x) \geq 1$ and $\mu(X) = 1$ the result follows. This feels awfully long and cumbersome, does anyone know a few tips or another way to provide a better solution? Thanks!","['measure-theory', 'real-analysis']"
4094333,Prove $\{a_n\}$ converges.,"Suppose $a_1,a_2>0$ and $a_{n+2}=2+\dfrac{1}{a_{n+1}^2}+\dfrac{1}{a_n^2}(n\ge 1)$ . Prove $\{a_n\}$ converges. First, we may show $\{a_n\}$ is bounded for $n\ge 3$ , since $$2 \le a_{n+2}\le 2+\frac{1}{2^2}+\frac{1}{2^2}=\frac{5}{2},~~~~~~ \forall n \ge 1.$$ But how to go on?","['limits', 'calculus', 'sequences-and-series']"
4094375,Localization of sheaves,"Let $(X,\mathscr{O}_X)$ a ringed space and $\mathscr{F}$ an $\mathscr{O}_X$ -module. Let $U\subseteq X$ be an open subset, and suppose we have $\mathscr{F}|_U=\mathscr{O}_U$ , then for $x\in U$ , how does this imply $\mathscr{F}_x=\mathscr{O}_{X,x}$ ? The explanation I saw was ""because localization preserves exactness"", but I don't quite understand how does it work here. Can somebody explain?","['algebraic-geometry', 'schemes']"
4094390,Convert Weierstrass form to real $T^2$,"A one-dimensional complex torus can be described as the quotient of $\mathbb{C}/\{m_1 \omega_1 + m_2 \omega_2 \}$ , where $m_i \in \mathbb{Z}$ and the $\omega_i$ are complex numbers which form a basis for a lattice $\Lambda$ . From this we can construct the Weierstrass $\wp$ function, $$
\wp(z; \omega_1, \omega_2) = \frac{1}{z^2} + \sum_{m_1, m_2}^{\prime} \left( \frac{1}{(z- m_1 \omega_1 - m_2 \omega_2)^2} - \frac{1}{(m_1 \omega_1 + m_2 \omega_2)^2} \right)
$$ (where the prime means $(m_1, m_2) \neq (0,0)$ ). We can then map this to a cubic curve in $\mathbb{P}^2$ by using the relation $$
(\wp^{\prime}(z) )^2= 4 \wp(z)^3 - g_2 \wp(z) - g_3
$$ and letting $(x,y) \in \mathbb{C}^2$ be $x =\wp(z)$ , $y = \wp^{\prime}(z)$ , and then projectivizing by letting $x = z_1 / z_0$ , $y = z_2 / z_0$ . I want to go the other way around, starting with an equation that is in Weierstrass form, and then arrive at a map to a real $T^2$ surface in $\mathbb{R}^3$ , e.g. a hypersurface of the form $$
(x^2 + y^2 + z^2 + R^2 - r^2) = 4 R^2 (x^2 + y^2)
$$ with $(x,y,z) \in \mathbb{R^3}$ and $R > r \in \mathbb{R}^+$ . Is there a clear and systematic way to do this? EDIT : Thought about it a bit more, and I recall that for different choices of the complex structure $\tau = \omega_2 / \omega_1$ , we have different complex manifolds, but these are all diffeomorphic homeomorphic (can they be diffeomorphic?) to each other, i.e. the underlying real manifold $T^2$ does not change for different values of $\tau$ . So in going from a Weierstrass model to a quartic hypersurface in $\mathbb{R}^3$ there is some ""forgetfulness"" involved. In any case, it would be nice to have a map that is consistent in the sense that nearby points on the cubic in $\mathbb{P}^2$ are mapped to nearby points in the quartic hypersurface in $\mathbb{R}^3$ .","['complex-geometry', 'elliptic-functions', 'algebraic-geometry', 'elliptic-curves']"
4094417,Using Gröbner bases and Cylindrical Algebraic Decomposition to solve real polynomial systems,"I'm working on a project that involves solving systems of multivariate polynomial equations over the reals (and find their real solutions). Assuming that a system has a finite number of complex solutions, the two primary methods I've found for this task involve Gröbner bases (computed using Buchberger's algorithm) and Cylindrical Algebraic Decomposition (CAD). For the actual computation, we plan to use Mathematica, but I was hoping to learn about the following theoretical questions (ignoring complexity or computing logistics): Given an arbitrary polynomial system over the reals, can one use Gröbner bases/CAD to find all real solutions (in theory)? If not, are there certain constraints over the system that one can place to guarantee returning all real solutions? Could using either method ever produce a ""false positive"" (returning something that isn't a solution)? If this is clear given the descriptions of each method, some intuition as to why may be helpful. Where can I find literature or course materials by which I can answer the above? Thank you for reading and for your help.","['systems-of-equations', 'algebraic-geometry', 'abstract-algebra', 'real-algebraic-geometry', 'computer-algebra-systems']"
4094421,Where is the mistake here (proof of the dot product),"Consider two vectors $\vec{u},\vec{v}$ in $\mathbb R^n$ , if we sum up those two vectors we will get a parallelogram with sides length $\vec{u},\vec{v}$ .
And in this parallelogram we have two triangles With sides length $\vec{u},\vec{v}, \vec{u}+\vec{v}$ . By the law of cosine : $$\| \vec{u}+\vec{v} \|^2= \|\vec{u}\|^2+\|\vec{v}\|^2-2 \|\vec{u}\|\|\vec{v}\|\cos(\theta) $$ Where $\theta$ Is the angle between $\vec{u}+\vec{v}$ $$(\vec{u}+\vec{v})(\vec{u}+\vec{v})= \vec{u}\cdot\vec{u}+ \vec{v}\cdot\vec{v} -2 \|\vec{u}\|\|\vec{v}\|\cos(\theta)  $$ $$2 \vec{u}\cdot\vec{v}=-2 \|\vec{u}\|\|\vec{v}\|\cos(\theta)  $$ And then $$\vec{u}\cdot\vec{v}=-\|\vec{u}\|\|\vec{v}\|\cos(\theta)  $$ What is that? I’m sure that the formula of dot product with no minus sign, i’ve checked the proof a lot of times but i didn’t found any mistake, can you tell me  where is it? Here’s a quick picture :","['multivariable-calculus', 'vectors']"
4094464,Exceptional Divisor of Node Blow-Up is Two Smooth Reduced Points,"This is Vakil 29.3 D , self-study. We are to show that if $X$ is a variety over an algebraically closed field $k$ with a node at point $p$ , that the blow-up of $X$ at $p$ gives a morphism $$\beta: \tilde{X} \to X$$ such that the exceptional divisor $\beta^{-1}(p)$ consists of two smooth reduced points. I am not sure what $\tilde{X}$ is here, but I assume it is the proper transform. We have defined a node to be a closed point $p \in X$ such that $\widehat{\mathcal O}_{X, p} \cong k[[x,y]]/(xy)$ as topological rings, where the completion is of course taken $\mathfrak m_{X, p}$ -adically. I don't really see how to parse this. The given hint says to use the fact that completion is flat, I assume to conclude that the natural map $\mathcal O_{X, p} \to \widehat{\mathcal O}_{X, p}$ is flat. I assume then that we are supposed to use this to conclude that the proper transform map $$\beta: \tilde{X} \to X$$ is then flat. Then, we are supposed to use 24.2 P a), I think to conclude that $$\operatorname{Bl}_pX \times_X \tilde{X} \cong \operatorname{Bl}_{\beta^{-1}(p)}\tilde{X}$$ and somehow combine this information to turn this into a calculation on $\widehat{\mathcal O}_{X, p} \cong k[[x,y]]/(xy)$ . What calculation? And is everything I have said thus far correct?",['algebraic-geometry']
4094502,Examples of probability distributions that the product of their random variable is also in same distribution.,"Heads up: my statistics knowledge is very limited, I am not a mathematician. I've recently learned that given two random variables $x$ and $y$ sampled from the same normal distribution their product $xy$ is not normal but it instead belongs to a modified bessel function distribution of the second kind (I believe this is only for $\mu=0$ and $\sigma = 1$ ). What are some well known probability distributions such that $xy$ belongs to the same distribution? I am specially interested in symmetric distributions around the mean.","['statistics', 'probability-distributions', 'normal-distribution', 'examples-counterexamples', 'probability']"
4094506,"For any $n-1$ non-zero elements of $\mathbb Z/n\mathbb Z$, we can make zero using $+,-$ if and only if $n$ is prime","Inspired by Just using $+$ , $-$ , $\times$ using any given n-1 integers, can we make a number divisible by n? , I wanted to first try to answer a simpler version of the problem, that considers only two operations instead of three. Let $n>2$ and parentheses are not allowed. Then, there are equivalent ways to ask this: Given any set of $n-1$ non-multiples of $n$ , can we make a multiple of $n$ using $+,-$ ? Given any $n-1$ non-zero elements of $\mathbb Z/n\mathbb Z$ , can we make $0$ using $+,-$ ? Alternatively, we can also be asking to partition a $n-1$ element set $S$ into two subsets $S_+$ and $S_-$ , such that the difference between the sum of elements in $S_+$ and the sum of elements in $S_-$ is a multiple of $n$ (is equal to $0$ modulo $n$ ). For example, if $n=3$ then there are only $3$ (multi)sets we need to consider: $$
\begin{array}{}
1-1=0\\
1+2=0\\
2-2=0\\
\end{array}
$$ which are all solvable (we can make a $0$ in $\mathbb Z/n\mathbb Z$ ). In general, there are $\binom{2n-3}{n-1}$ (multi)sets to consider for a given $n$ . My conjecture is that any such (multi)set is solvable if and only if $n$ is a prime number. If $n$ is not prime, then it is not hard to see that this cannot be done for all (multi)sets. If $n$ is even, then take all $n-1$ elements to equal $1$ , to build an unsolvable (multi)set. If $n$ is odd, then take $n-2$ elements to equal to a prime factor of $n$ and last element to equal to $1$ , to build an unsolvable (multi)set. It remains to show that if $n$ is prime, then all such (multi)sets are solvable. I have confirmed this for $n=3, 5, 7, 11, 13$ using a naive brute force search. Can we prove this conjecture? Or, can we find a prime that does not work?","['number-theory', 'combinatorics', 'sumset', 'recreational-mathematics', 'prime-numbers']"
4094520,Intuition behind connectedness = path connectedness in the complex numbers,"The 2-D reals are isomorphic to the complex numbers, correct? So why is it that “connected” is equivalent to “path connected” in the complex numbers, but not in the 2-D reals (as exemplified by the topologist's sine curve )?  Couldn't we just construct a topologist’s sine curve in the complex numbers as well: that is, the collection of points that includes the origin $z=0$ as well as all points $z=x+iy$ in the complex plane where $(x,y) = (x, \sin(1/x)) : x \in (0,1] $ ? I think there's some intuition behind this that I'm missing.","['complex-analysis', 'general-topology', 'connectedness']"
4094600,Conditional Bias Variance Decomposition,"The standard bias variance decomposition says that: $$
E |f(X) - Y|^2 = \int_{\mathbb{R}^d} |f(x) - m(x)|^2 \mu(dx) + E|m(X) - Y|^2,
$$ where $\mu$ is some distribution over $X$ . I am trying to understand the conditional version of this decomposition: Let $D_n= \{(X_i,Y_i)\}_{i=1}^n$ be an i.i.d. sample and we construct an estimate $m_n(x) := m_n(x,D_n)$ based on the sample. We then have \begin{align*}
E [|m_n(X) - Y|^2\mid D_n] 
&= \int_{\mathbb{R}^d} |m_n(x) - m(x)|^2 \mu(dx)  + E|m(X) - Y|^2\\
&= E|m_n(X) - m(X)|^2   + E|m(X) - Y|^2,
\end{align*} These are equations 1.1 and 1.2 in the Nonparametric Statistics book by Gyorfi. What I am confused about is the first term in the second equation, should this not be a conditional (on $D_n$ ) expectation? That is: $$
E [|m_n(X) - Y|^2\mid D_n] = E [|m_n(X) - m(X)|^2 \mid D_n]  + E|m(X) - Y|^2
$$ update: I think what is happening is: \begin{align*}
E [|m_n(X) - m(X)|^2 \mid D_n] 
&= \int_{m_n} \int_x |m_n(x) - m(x)|^2 dP(x,m_n|D_n)\\
&= \int_{m_n} \int_x |m_n(x) - m(x)|^2 d\mu(x) dP(m_n|D_n)\\
&= E\left ( \int_x |m_n(x) - m(x)|^2 d\mu(x) \mid D_n \right )\\
&= E\left ( E[|m_n(X) - m(X)|^2]\mid D_n \right )\\
&= E[|m_n(X) - m(X)|^2],
\end{align*} where the second equality is due to $X$ being an independent draw, and the last equality is due to the fact that $m_n$ is measurable with respect to $D_n$ , so the expectation of the inner expectation conditional on $D_n$ is just equal to the inner expectation almost surely.","['conditional-probability', 'statistics', 'machine-learning', 'probability']"
4094630,Plot complex function from one plane to another?,"Is there a (free) program or something online that can plot a complex function from one complex plane to another? Like in the picture below? I want to be able to see where numbers go, so to speak, with colors or something.","['complex-analysis', 'complex-numbers', 'online-resources']"
4094650,"Is it true that $\text{Ext}(A,\Bbb Z)=\text{Ext}(A_{tor},\Bbb Z)$ for any abelian group $A$?","Is it true that $\text{Ext}(A,\Bbb Z)=\text{Ext}(A_{tor},\Bbb Z)$ for any abelian group $A$ ? Obviously this is true when $A$ is finitely generated, since $\text{Ext}(G,\Bbb Z)=0$ if $G$ is free. But I'm curious that whether or not this is true in the general case.","['homological-algebra', 'abstract-algebra']"
4094652,In a triangle prove that $IG \perp BC \iff b + c = 3 a$,"Consider the triangle $ABC$ . Denote the incenter with $I$ , the centroid with $G$ and $AB = c$ , $AC = b$ , $BC = a$ . Prove that $IG \perp BC \iff b + c = 3 a$ . I have tried using centroid's and incenter's properties but to no result. Any help is appreciated.","['euclidean-geometry', 'centroid', 'geometry']"
4094726,Gradient of norm [duplicate],"This question already has answers here : How to take the gradient of the quadratic form? (6 answers) Closed 3 years ago . How can I compute the gradient of f(x)= $||Ax-b||_{R^{-1}}^2$ I'm also confused about how to compute the gradient of g(x) = $||y-Ax||$ using the chain rule. I think the first step to take the gradient of g(x) would be $\nabla(g(x)) = \frac{d(y-Ax)^\top}{dx}(y-Ax)+ \frac{d(y-Ax)}{dx}(y-Ax)^\top$ . However, I'm unsure of how to take the derivative of (y-Ax) or the derivative of $(y-Ax)^\top$ . Any help is highly appreciated.","['matrices', 'multivariable-calculus', 'matrix-calculus', 'vector-analysis', 'derivatives']"
4094730,There are $2n$ people on a social media platform. Prove there are at least $5n$ pairs of friends.,"There are $2n$ people on a social media platform, where any pair of them may or may not be
friends. For any group of $n$ people, there are at least $n$ pairs of them that are friends. What
is the least number of friendships, that is, the least number of pairs of people that are friends, that
must be among the $2n$ people? This a problem from last year Canadian national competition. Offical solution is $5n$ . Here is what I did: For every $n$ vertices we have $n$ edges so $${2n\choose n} \cdot n \leq \varepsilon \cdot {2n-2\choose n-2} \implies \varepsilon\geq {2n(2n-1)\over n-1} $$ So, by this to naive method we get: $$\varepsilon \geq 4n+3$$ I also wonder if this is doable with the probabilistic method?","['contest-math', 'extremal-graph-theory', 'combinatorics']"
4094734,Pfaffian Equations,"Solve the Pfaffian Equation below: $$(yz-1)dx+((z-x)x)dy+(1-xy)dz=0$$ I have tried to find the determinant, and it is $0$ . So it is integrable. I let $z$ to be a constant. After I'm having problems solving it.","['ordinary-differential-equations', 'partial-differential-equations']"
4094762,Homology $H_n(\mathbb{RP}^n)$,"I don't understand the homology computation of real projective $\mathbb{RP}^n$ associated to the decomposition of $\mathbb{S}^i$ as union of two $i$ -cells, i.e $E_+^i,E_-^i$ . I'm going to introduce the notation and give a sketch of the proof given to me to underline the details I'm missing. Since $H_i(S^i,S^{i-1}) \simeq H_i(E_+^i,S^{i-1}) \oplus H_i(E_-^i,S^{i-1}) \simeq \mathbb{Z}\oplus \mathbb{Z}$ we have that the differential map are $$\mathbb{Z}\oplus \mathbb{Z} \overset{d_n}{\longrightarrow} \mathbb{Z}\oplus \mathbb{Z} \overset{d_{n-1}}{\longrightarrow} \cdots \mathbb{Z} \oplus \mathbb{Z} \overset{d_{n-2}}{\longrightarrow} \cdots \overset{d_1}{\longrightarrow} \mathbb{Z} \oplus \mathbb{Z}$$ Called $\alpha$ the antipodal map (which restricts to the skeletons $\mathbb{S}^i$ with this given decomposition) we know that $\alpha_*$ send a generator $x_i$ of $H_i(E_+^i,S^{i-1}) \simeq \mathbb{Z}$ into a generator $\alpha_*(x_i) \in H_i(E_-^i,S^{i-1}) \simeq \mathbb{Z}$ . From this Lemma I know that $d_n = (-1)^n +1$ . So the algebraic complex associated to $\mathbb{RP}^n$ is $$0 \longrightarrow \mathbb{Z} \overset{(-1)^n +1 }{\longrightarrow} \mathbb{Z} \overset{(-1)^{n-1}+1}{\longrightarrow} \cdots \mathbb{Z} \overset{0}{\longrightarrow} \mathbb{Z}$$ In other words $d_n$ are the multiplication by $\pm 2$ . It follows that $$H_n(\mathbb{RP}^n) = \begin{cases} 0 & 2 \mid n \\ \mathbb{Z} & 2 \nmid n\end{cases}$$ From this it should follow that $$H_i(\mathbb{RP}^n) = \begin{cases} \mathbb{Z}_2 & 0 < i < n & 2 \nmid i \\ 0 & 2 \mid i, i > n \\ \mathbb{Z} & i = 0,n\end{cases}$$ The proof given both in Hatcher and my notes in the same spirit takes $\alpha : \mathbb{S}^n \longrightarrow \mathbb{RP}^n$ which induces a map of algebric complex $C_i^{CW}(\mathbb{S}^i) = H_i(E_+^i,S^{i-1}) \oplus H_i(E_-^i,S^{i-1})$ and says : ""Both terms maps identically on $C_i^{CW}(\mathbb{RP}^n) = H_i(\mathbb{D}_+^i,\mathbb{S}^i)$ so $x_i$ and $\alpha_*(x_i)$ are mapped in the same generator $y_i$ , hence $d_i(y_i) = \pm (1+(-1)^i)y_i""$ . I really don't understand this proof or how should conclude. I don't understand neither how it should follow that the homology of projective are those written above. In particular my difficulties involve being able to distinguish all the pieces of this $CW$ -complex associated homology and being able to assemble those objects in order to compute the original homology of the space I'm studying, i.e $\mathbb{RP}^n$ . Any help or reference in order to understand or shed light on my doubts and difficulties would be appreciated.","['group-theory', 'general-topology', 'homology-cohomology', 'algebraic-topology', 'projective-space']"
4094856,Bessel function approach as a trigonometric function,"I was trying to find the eigenvalues, which is the positive roots of the equation bellow: $$J_{1}(a\lambda)Y_{1}(c\lambda) -J_{1}(c\lambda)Y_{1}(a\lambda) =0$$ I was presented with this trigonometric approach that worked fine. However, I need to know where that approach came from. Could anyone tell me how I get to this approach? $$J_{1}(a\lambda)Y_{1}(c\lambda) -J_{1}(c\lambda)Y_{1}(a\lambda) \approx -\frac{2\sin[(a-c)\lambda]}{\pi \lambda\sqrt{ac}}$$ and the zeros are $$\lambda_n \approx n\pi/ \vert a-c\vert$$ $$ a = 0.02$$ $$c=0.05$$","['trigonometry', 'functions', 'bessel-functions', 'eigenvalues-eigenvectors']"
