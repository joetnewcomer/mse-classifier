question_id,title,body,tags
2406775,$\sum_{k=0}^{n} Re(\cos(kx))=\sum_{k=0}^{n} Re(\cos(x)^k)$?,"I recently saw the following ( Proving $\sum\limits_{k=0}^{n}\cos(kx)=\frac{1}{2}+\frac{\sin(\frac{2n+1}{2}x)}{2\sin(x/2)}$ ), and I saw that they said the following is true. $$\sum_{k=0}^{n} Re(\cos(kx))=\sum_{k=0}^{n} Re(\cos(x)^k)$$ At the moment I believe this to be false, I tried a small case with, $n=2$ and $x=pi/4$. Which gives $$\sum_{k=0}^{2} Re(\cos(k\frac{\pi}{4}))=\sum_{k=0}^{2} Re(\cos(\frac{\pi}{4})^k),$$
and this is not true. The most I could show was, $\cos(kx)=Re((\cos(x)+i\sin(x))^k)$. Could any one show me why the person said the first equation is true?","['complex-analysis', 'trigonometry']"
2406780,How many lattice points are on the boundary or inside the region bounded by $y=|x|$ and $y=-x^2+6$?,"A lattice point is a point whose coordinates are both integers. How many lattice points are on the boundary or inside the region bounded by $y=|x|$ and $y=-x^2+6$? I thought there were two points, but that isn't right. What am I missing?","['algebra-precalculus', 'integer-lattices', 'coordinate-systems']"
2406781,Do there exist two primes $p<q$ such that $p^n-1\mid q^n-1$ for infinitely many $n$? [duplicate],"This question already has answers here : If $a\geq 2$, $a\nmid b$, and $a^n-1\mid b^n-1$ for all $n\in\mathbb{N}$, then $b=1$ (4 answers) Closed 2 months ago . We can prove that there is no integer $n>1$ such that $2^n-1\mid 3^n-1$. This leads to the following question: Is it true that for every pair of primes $p<q$ there are only finitely many integers $n$ such that $p^n-1\mid q^n-1$? Are there two primes $p<q$ and an integer $n>p+q$ such that $p^n-1\mid q^n-1$?Is it true that if $n>6$ then $2^n-1\nmid 5^n-1$? Edit: Here are some examples:
\begin{array}{ll}
2^{36}-1\mid 41^{36}-1,
&3^{12}-1\mid 97^{12}-1,\\
5^{6}-1\mid 37^{6}-1,
&7^{4}-1\mid 151^{4}-1.
\end{array} Now I prove there is no integer $n>1$ such that $2^n-1\mid 3^n-1.$ Proof: Denote $A=2^n-1$ and $B=3^n-1$. If $n$ is even then $3$ divides $A$ but not $B$, a contradiction. If $n$ is odd then $A\equiv -5\pmod {12}$. Since every prime greater than $3$ is $\equiv \pm1,\pm5 \pmod {12}$, some prime factor $p$ of $A$ must be congruent to $\pm5 \pmod {12}$. As $p \mid B$, we have $3^{n+1}\equiv 3 \pmod p$. Since $n+1$ is even, we get $(\frac{3}{p})=1$, a contradiction again.","['number-theory', 'divisibility', 'elementary-number-theory']"
2406796,Composition of absolutely continuous function on $\mathbb{R}$ [duplicate],"This question already has an answer here : Composition of Absolutely Continuous Functions (1 answer) Closed 6 years ago . Is it true that the composition of two absolutely continuous functions on the real line is absolutely continuous? I feel like this should be a resounding no, however, I'm unsure of any quick counterexamples to this claim.  Can anyone think of one?","['real-analysis', 'examples-counterexamples', 'absolute-continuity', 'function-and-relation-composition', 'measure-theory']"
2406811,Why does the triangle inequality for space $L^p$ with $0<p<1$ not hold?,"It is said that triangle inequality for the space $L^p(\mathbb{R})$ space doesn't hold if $0<p<1$ . Does anyone know an example for this? Also, what we can say, for example,  about the quantity like $\| f \| \colon =\int_{\mathbb{R}} \sqrt{|f|}  dx$ ? I think in the space $\{ f ; \|f\| < \infty \}$ , triangle inequality $\|f+g\| \le \|f\| + \|g\|$ is valid.","['lp-spaces', 'real-analysis', 'integration', 'measure-theory']"
2406821,"Why is ""totally ordered"" necessary in this implication of the Axiom of Foundation","The Axiom of Foundation was stated as: Every non-empty set contains an element disjoint from it. Then the following: Every non-empty set $S$ contains an element $x$ such that no element $y\in S$ satisfies $y\in x$. This means that $x$ is an $\epsilon$-minimal element of $S$. Thus the Axiom of Foundation implies that ever set that is totally ordered under $\epsilon$ is well ordered under $\epsilon$. My question, please, is why is ""totally ordered under $\epsilon$"" necessary? After all, if, as stated earlier, every non-empty set $S$ contains an $\epsilon$-minimal element and every non-empty subset is also a set, is that not enough (i.e., without the stipulation that it is also totally ordered) to assert that $S$ is well- ordered? Thanks","['axioms', 'elementary-set-theory']"
2406826,Interchange of expected value and summation,"Hey guys I'm studying Statistics and I'm currently at unbiased estimators. I'm trying to find the estimators for different problems. My question is : I know that the following formula holds $$E (\sum_{i=0}^n X_{i}) =\sum_{i=0}^n(E( X_{i}))$$ where $X_{i}$ are the possible values of a random vector. I think this is true because of Fubini's theorem but correct me if I am wrong. My question is if the following formula is also true $$E (\sum_{i=0}^n(X_{i}-X)^2) =\sum_{i=0}^n(E( X_{i}-X)^2)$$ where by $X$ I mean the $X=(\sum_{i=0}^n X_{i})/n$. Of course $(X_{i}-X)^2$ isn't a linear equation so I don't know if that means anything.
Can you please explain me if both formulas are true and why?","['statistics', 'probability']"
2406836,Number of intersection point of $\cos^{-1}$ function,"If $f:[0,4\pi]\to[0,\pi]$ is the function defined by $f(x)=\cos^{-1}(\cos x)$, the number of points $x\in[0,4\pi]$ satisfying the equation $f(x)=\frac{10-x}{10}$ is ______. I am  mapping the curve $f(x)=\cos^{-1}(\cos x)$. It is equivalent to $y=x$, in that case answer is '$1$', but actual answer is $3$. Where am I making mistake?","['functions', 'graphing-functions']"
2406866,Inequality $(x^2 + 3x + 1)\cdot(x^2 + 3x - 3) \geq 5$,"This is the question I have in front of me. Clearly, I need to find the range of values of $x$ for the given inequality. Having taken a cue from a similar question, here's how I approached it - Let $ a = x^2 + 3x + 1$
$\implies ax^2 + 3ax - (3a + 5) \geq 0$ Now, for this quadratic expression to be greater than or equal to $0$, the coefficient of $x^2$ must be $>0$, with the discriminant being equal to $0$. But, the coefficient of $x^2$ i.e. $a = x^2 + 3x + 1$ can take negative values also, which does not ensure the requirement. So, how shall I go about this one? Any help will be appreciated. Thanks.","['algebra-precalculus', 'inequality', 'quadratics']"
2406936,Evaluate the flux of the vector field without using divergence theorem,"Given $ F(x,y,z)=(z^2-x,-xy,3z)$ and $S$ is the surface of the solid
  delimited by the equations $z=4-y^2, x=0, x=3$ and $z=0$, with the
  normal vector exterior, evaluate $\iint_S F\cdot n \,ds$ without using
  The Divergence Theorem.","['multivariable-calculus', 'surface-integrals', 'calculus']"
2406966,Proving two integrals are equal to each other,"Question: How do you show that$$\int\limits_{0}^{\infty}\frac {e^{-ax}}{\sqrt{b+x}}\,\mathrm dx=\int\limits_{\sqrt{ab}}^{\infty}\frac 2{\sqrt{a}}e^{ab-t^2}\,\mathrm dt$$ This problem emerged when I was trying to prove an identity by working backwards, and I'm not sure how to tackle it. I need to find a way to get the limits of the right-hand side to zero to infinity but am unsure how to do that. Should I make the substitution$$u^2=ab$$If so, how do I get rid of the $\sqrt{a}$ term in the denominator? Note: Here, $a,b>0$ and are real numbers!",['integration']
2406971,"For a complex Banach space $X$ and an open $U\subset\Bbb C$, is a ""weakly holomorphic"" $f:U\to X$ also strongly holomorphic?","For any complex Banach space $X$ and any open $U\subset\Bbb C$, we say that a function $f:U\to X$ is holomorphic at a point $z_0\in U$ if for $|z-z_0|$ sufficiently small, we can express $f$ as $$f(z)=\sum_{k=0}^\infty a_k (z-z_0)^k$$ where $a_k\in X$ for all $k$, and where the sum converges absolutely. We say that $f:U\to X$ is (strongly) holomorphic if it is holomorphic at every point in $U$. Meanwhile, we say that a function $f:U\to X$ is weakly holomorphic if for every $x'\in X'$, the function $$\langle x',f\rangle:U\to\Bbb C$$ is holomorphic. Now, it's easy to see that any holomorphic function is weakly holomorphic, but does the converse hold?","['functional-analysis', 'complex-analysis', 'banach-spaces']"
2406976,Prime dividing repunit,"Let $ R(n) = \underbrace{111\ldots111}_{\text n\ ones}$. Prove that if a prime number $ p \neq 3 $ divides $ R(n) $ then $ n $ and $ p - 1 $ are not coprime. So obviously $ R(n) = \frac{10^n - 1}{9}$. Now if $ p $ divides $ R(n) $ then $$ \frac{10^n - 1}{9} \equiv 0 \pmod p $$ which implies $$ 10^n - 1 \equiv 0 \pmod p $$ $$ 10^n \equiv 1 \pmod p $$ Can we deduce from there that $ GCD(n, p - 1) \neq 1  $? How? Also, why is $ p \neq 3 $ requirement necessary? I suppose ""multiplying both sides"" by $ 9 = 3^2 $ is somehow relevant, but I'm not sure why... it's not diffucult to come up with a counterexample for $ p = 3 $ case, but I don't know how the proof would account for it.","['number-theory', 'congruences', 'modular-arithmetic']"
2406977,"Proof that A is the disjoint union of two sets, one contained in a set B and one disjoint from a set B","This is my first post here so please be gentle. I tried to find an answer to this and couldn't find anything this specific so bear with me if I didn't search hard enough. Can you tell me if this proof makes sense? Have I made any assumptions that mess everything up? Your input is greatly appreciated. If A and B are two sets, then prove that A is the union of a disjoint pair of sets, one of which is contained in B and one of which
  is disjoint from B. Proof by Cases: Case 1: A ∩ B = ∅ Case 2: A ∩ B ≠ ∅ Case 1: Suppose A ∩ B = ∅. Let a1 ∪ a2 = A such that a1 = ∅ and a2 =
  A. Then a1 ⊆ B and a2 ∩ B = ∅. Then A is the union of two sets, one of
  which is contained in B and one of which is disjoint from B. Case 2: Suppose A ∩ B ≠ ∅. Let a1 ∪ a2 = A such that a1 = A ∩ B and a2
  = A - B, so a1 ∩ a2 = ∅. Then A is the union of two sets such that a1 is contained in B and a2 is disjoint from B. Thus, if A and B are two sets, then A is the union of a disjoint pair
  of sets, one of which is contained in B and one of which is disjoint
  from B. Is this right? Is there an easier way to do this? Thanks in advance. Edit: Okay, so clearly this can be much easier. As simple as Let A = a1 ∪ a2 such that a1 = A ∩ B and a2 = A ∩ Bc. Then a1 ∪ a2 =
  ∅, a1 is contained in B and a2 is disjoint from B.","['elementary-set-theory', 'proof-verification']"
2406992,Question about derivative of $\cos(x)$.,"The question is how to show the derivative of $\cos x$ is $-\sin x$ using the definition of the derivative. I do this proof in the normal way by using the sum of $\cos (x+h)$ using the trig identity, and then factoring out the $\cos x$ and using two special squeeze theorems.  I get the correct answer of $-\sin x$. Here is how he does it and it seems illegal: $$\lim_{h \mapsto 0 } \frac{(\cos x)(\cos h)-(\sin x)(\sin h)  -\cos x}h   $$
then he says in the NUMERATOR, letting $ h=0$ makes the numerator become: $\cos x (1)-\sin x\sin h-\cos x$ Notice that he just selectively let the $\cos h$ term have $h$ go to zero but NOT the $\sin h$ term!!! The two $\cos x $ terms cancel out leaving 
$\lim_{h \mapsto 0 }-\sin x\sin h/h$
and he uses the squeeze theorm to get $-\sin x (1)$ But I don't see how it is legal to let $h=0$ for some terms in the numerator without considering the denominator.  He DOES get the right answer, but it seems illegal to me.  Thoughts?",['calculus']
2407012,Intuition behind applying the implicit function theorem to parameterization of unit circle,"This post is a modification of a previous post I have since deleted, which was much too messy and basically had two separate questions. (It received no answers.) A common motivating example for the implicit function theorem (IFT) is the equation $x^2+y^2=1$ where $(x,y)\in \mathbb R^2$, as we can locally write $y$ as an equation of $x$ (and vice versa) in the familiar way. Consider the following exercise from Wade's An Introduction to Analysis . Suppose that $f:=(u,v):\mathbb R\to \mathbb R^2$ is $C^2$ and set
  $(x_0,y_0)=f(t_0)$. Also assume that $f'(t_0)\ne 0$. Show that either
  there is a $C^1$ function $g$ with $g(x_0)=t_0$ and $u(g(x))=x$ for
  any $x$ near $x_0$ or there is a $C^1$ function $h$ with $h(y_0)=t_0$
  and $v(h(x))=y$ for any $y$ near $y_0$. (Note that I think the
  textbook has a typo since we just need to assume that $f$ is $C^1$.
  Correct me if I'm wrong.) I can do this by applying the IFT to the function $F(x,t)=x-u(t)$ and to the function $G(y,t)=y-v(t)$. Now, the unit circle can be parameterized (infinitely many times) by $(\sin(t), \cos(t))$ for $t\in \mathbb R$. And the map $(\sin(t), \cos(t))$ is everywhere $C^1$. Therefore, I am wondering if the exercise can be seen as describing the motivating example of the unit circle I described initially. That is, is there any way to relate this problem to the simple idea of writing the unit circle $x^2+y^2=1$ locally as a function of $x$ or $y$? I think that the answer is ""yes"" in some sense but am unsure how. I just want to gain a bit of intuition.","['multivariable-calculus', 'intuition', 'real-analysis', 'derivatives']"
2407038,Commutator Subgroup Characterization,"In a Wikipedia article on the Commutator Subgroup , the following is stated: ""The commutator subgroup can also be defined as the set of elements $g$ of the group which have an expression as a product $g = g_1 g_2 \cdots g_k$ that can be rearranged to give the identity."" I was wondering if there was a reference for this (that contains a proof) or if someone could provide a proof since I thought that this was a neat property. I spent some time searching and did not come up with anything. The only part of the proof that I was able to do myself was the trivial fact that every element of the commutator subgroup has this property, but there may be other elements that have this property as well.","['abstract-algebra', 'group-theory']"
2407062,Any given number will divide into some combination of 3 and 0's,"Now, I have to prove that any number could be made to divide into at least 1 arbitrary long sequence of 3's and 0's. That is, for any $n$ there always exist a number $x$ made up of 0's and 3's such that $ x\equiv 0 \pmod n$. The proof is supposed to be done by the pigeonhole principle but i can't seem to find it. Any idea on how to solve it using any method?","['number-theory', 'pigeonhole-principle', 'discrete-mathematics']"
2407063,Motivation behind definition of closed immersion of schemes,"In chapter II Hartshorne defines a closed immersion of schemes as a morphism $f:X \rightarrow Y$ of schemes such that is a homeomorphism between X and a closed subset of Y, and the map $f^{\#}: \mathcal{O}_Y \rightarrow f_{*}\mathcal{O}_X$ is surjective. Is there an analogous classical definition for a morphism $f: X \rightarrow Y$ of quasiprojective varieties? It seems a pretty basic concept but I can't quite find it in chapter I. 
If $f$ is such a morphism is it true that the induced map $f^{\#}$ is surjective?","['schemes', 'algebraic-geometry']"
2407068,Is the limit of $\left(\sum_{i=-n}^{i=n} \tanh(x - i)\right)-2x$ a sine wave?,"I have been plotting functions of the form 
$$\left(\sum_{i=-n}^{i=n} \tanh(x - i)\right)-2x$$
which, over the region around zero, look a lot like sine waves. For example, here's the function for $n=10$. Empirically, it seems to be something approximating $0.00065 \sin(2 \pi x)$.
Beyond about $n=10$ it is very stable over the region $x\in[-5,5]$, as you might expect from $\tanh(x)$ being approximately $\pm 1$ for large $\pm x$. I have found plots of the series and $0.00065 \sin(2 \pi x)$ are indistinguishable. Here's the same plot zoomed out with this sine wave in orange: Is this actually tending towards a sine wave? and if so, what is the exact value 
 of the constant $k$ in $$\lim_{n \to \infty}\left(\sum_{i=-n}^{i=n} \tanh(x - i)\right)-2x = k \sin(2 \pi x)$$ Update I've calculated the specific values of this function symbolically with Mathematica, and evaluated it with $N[.,100]$ function at x=1/4, 5/4, 401/4 and 4001/4 which gives 1/4: 0.0006499727271926147575932558139650291715585570399687299381104388139877502424025845538796044013975974138
   5/4: 0.0006499727271926147575932558139650291715585570399687299381104388139877502424025845538796044013975974138
 401/4: 0.0006499727271926147575932558139650291715585570399687299381104388139877502424025845538796044013975974138
4001/4: 0.0006499727271926147575932558139650291715585570399687299381104388139877502424025845538796044013975974138 I'm not 100% sure this is not a numerical issue, but I also don't see any reason why it should be 0.00065 exactly either.","['hyperbolic-functions', 'trigonometry', 'limits']"
2407102,What is the notation $\mathcal{A}_\infty$ for a sheaf of graded $\mathcal{O}_X$-algebras mean?,Today I encountered Hartshorne's condition $(\dagger)$ for quasi-coherent sheaves of algebras. This states that gives a graded $\mathcal{O}_X$-module $\mathcal{A}$ which has the structure of a graded algebra $\mathcal{A} = \oplus_{n\geq 0 }\mathcal{A}_n$ and $\mathcal{A}_0 = \mathcal{O}_X$ $\mathcal{A}_1$ is coherent as an $\mathcal{O}_X$-module $\mathcal{A}_\infty$ generates $\mathcal{A}$ as an $\mathcal{O}_X$-module What is $\mathcal{A}_\infty$?,"['sheaf-theory', 'algebraic-geometry', 'coherent-sheaves', 'graded-rings', 'graded-algebras']"
2407151,Subgroup of $S_7$ generated by two permutations,"I'm trying to solve an assignment about subgroups of symmetric groups but realized that I'm a bit rusty. Let $\pi_1 = (1234567)$ and $\pi_2=(124)(357)$ be elements of $S_7$, $G := \left<\pi_1,\pi_2\right>$ and $H := \left<\pi_1\right>$. First of all $|G|$ is needed. I remember an easy to calculate by just multiplying the orders of both permutations (in this case $7$ and $3$), thus $|G|=21$ but I do not remember the theorem itself. Otherwise the application of Lagrange would lead to $3 \mid |G|$ and $7 \mid |G|$ and therefore $21 \mid |G|$ as well as $|G| \mid 7!$ but I cannot deduce $|G|$ in the end. Afterwards all normal subgroups of $G$ and the conjugacy classes of all subgroups of $G$ have to be computed. 
I know that the conjugacy classes of $S_n$ are always represented by permutations of the same ""type"" and that normal subgroups are the union of conjugacy classes. Can that be applied here? In the end $\operatorname{Aut}(H)$ has to be calculated. 
$H \cong \mathbb{Z}_7$ since it has $7$ elements. Thus $\operatorname{Aut}(H) \cong C_6$.","['finite-groups', 'abstract-algebra', 'group-theory', 'symmetric-groups']"
2407154,Let $h(4x-1)=2x+7$. For what value of $x$ is $h(x)=x$?,"Let $h(4x-1)=2x+7$. For what value of $x$ is $h(x)=x$? If $h(a)=a$, then $4x-1=2x+7$ which implies $x=4$. So $a=15$ when I substitute $x=4$ into both linear equations. Is the value of $x$ $15$?",['algebra-precalculus']
2407163,Is completeness of the real line needed to show that if $\lim\limits_{x\to0} f'(x)$ exists and $f$ is continuous at $0$ then $f'(0)$ is the limit?,"A question about existence of derivative of function at Zero The question linked above inspires another question. $f:\mathbb R\to\mathbb R$ is assumed to be continuous everywhere. It is assumed to be differentiable at all points besides $0.$ It is assumed that $\displaystyle\lim_{x\to0} f'(x)$ exists in $\mathbb R.$ The question was whether $f'(0)$ exists and is equal to that limit. A posted affirmative answer used L'Hopital's rule, and another used the mean value theorem directly. Either of those relies on the gaplessness of the real line. Can an affirmative answer be proved without completeness?  Could it be proved, for example, in the field of rational numbers? If not, what would be a counterexample in $\mathbb Q$?","['derivatives', 'real-analysis', 'supremum-and-infimum']"
2407186,For which values of $a\in\mathbb{Q}$ does integer solutions to $x^2+x+1=a(y^2+1)$ exist?,"I am unable to determine for which values of $a\in\mathbb{Q}$ does integer solutions to
$$x^2+x+1=a(y^2+1)$$ in the form $(x,y)$ exist. My initial idea was to set $a=\frac{c}{d}$ to get $dx^2+dx+d=c(y^2+1)$ for $c,d\in\mathbb{Z}$ but I am unsure how to convert this into Pell's equation nor do I know how to apply initial solutions. Any suggestions?","['number-theory', 'diophantine-equations']"
2407187,$A = \liminf(A_n) = \limsup(A_n)$ then $P(A_n) \to P(A)$,"Let $A = \liminf(A_n) = \limsup(A_n)$. Show that $P(A_n) \to P(A)$ $Def.: \limsup A_n = \bigcap\limits_{m\geq1}\left[\bigcup\limits_{n\geq m}A_n\right]$ and
    $\liminf A_n = \bigcup\limits_{m\geq1}\left[\bigcap\limits_{n\geq m}A_n\right]$ $P$ a probability measure on $(\Omega,\mathscr{F},P)$. I know from a already proven theorem that, if $P$ is $\sigma$-additive (and it is), then if $A_n \uparrow A\implies P(A_n)\to P(A)$ and if $B_n \downarrow B \implies P(B_n) \to P(B)$. Let $E_m = \bigcup\limits_{n\geq m}A_n\implies E_m \downarrow A \implies P(E_m) \to P(A)$ Let $F_m = \bigcap\limits_{n\geq m}A_n \implies F_m \uparrow A\implies P(F_m) \to P(A)$ Now, I don't believe this shows that $P(A_n) \to P(A)$. How can I finish this proof?","['probability-theory', 'probability', 'measure-theory', 'convergence-divergence']"
2407249,Finding the Derivative of $\arctan \frac{x}{a - \sqrt{a^2 - x^2}}$,"I am trying to simplify the derivative of $\arctan \frac{x}{a - \sqrt{a^2 - x^2}}$. My work: Everybody knows that $\frac{d}{dx} (\arctan \space u) = \frac{1}{1 + u^2} \frac{du}{dx}$ We let $u =  \frac{x}{a - \sqrt{a^2 - x^2}} .$ To get the $du,$ I remember that $\frac{d}{dx} \left( \frac{u}{v} \right)= \frac{v \frac{du}{dx} - u \frac{dv}{dx}}{v^2}.$ So:
 $$\frac{d}{dx} \left ( \frac{x}{a - \sqrt{a^2 - x^2}}  \right) = \frac{a-\sqrt{a^2 - x^2} \frac{d}{dx} (x) - x \frac{d}{dx} (a-\sqrt{a^2 - x^2)}}{(a-\sqrt{a^2 - x^2)^2}} $$ $$ = \frac{a - \sqrt{a^2 - x^2} -x \left(\frac{x}{(\sqrt{a^2 - x^2})}\right)}{a^2 - 2\sqrt{a^2 - x^2} +a^2 - x^2}$$
$$ = \frac{ \frac{a - \sqrt{a^2 - x^2}}{1} + \frac{-x^2}{ \sqrt{a^2 - x^2} }}{2a^2 - 2\sqrt{a^2 - x^2} - x^2}$$
$$ = \frac{\frac{(a^2 - x^2)^{\frac{1}{2}} (a - (a^2 - x^2)^\frac{1}{2}) - x^2}{(a^2 - x^2)^{\frac{1}{2}}}}{2a^2 - x^2 - 2\sqrt{a^2 - x^2} }$$
$$ \frac{d}{dx} \left( \frac{x}{a - \sqrt{a^2 - x^2}}\right) = \frac{a(a^2- x^2)^\frac{1}{2} - (a^2- x^2) - x^2}{2a^2 - x^2 - 2\sqrt{a^2 - x^2} }$$ Then: $$\frac{d}{dx} \left( \arctan \frac{x}{a - \sqrt{a^2 - x^2}} \right) = \frac{1}{1 + \left( \frac{x}{a - \sqrt{a^2 - x^2}} \right)^2}  \left( \frac{a(a^2- x^2)^{\frac{1}{2}} - (a^2- x^2) - x^2}{2a^2 - x^2 - 2\sqrt{a^2 - x^2} } \right) $$ At this point, simplifying it is difficult. How do you get the derivative of $\arctan \frac{x}{a - \sqrt{a^2 - x^2}}?$","['derivatives', 'trigonometry', 'inverse-function', 'calculus', 'fractions']"
2407282,Find all polynomials : $ P(x^2-x)=xP(x-1)$,"Find all polynomials $P(x) \in\mathbb{R}[x]$ satisfying $$ P(x^2-x)=xP(x-1)$$ Please check my answer : $P(0) =0$, so $0$ is root of $P(x)$, there exists $Q(x)$ such that $P(x)=xQ(x)$ then $(x^2-x)Q(x^2-x)=x(x-1)Q(x-1)$, so $Q(x^2-x)=Q(x-1)$ where $x \not= 0, 1$ Substitute $x=2$, we have $Q(2) = Q(1)$ Substitute $x=3$, we have $Q(6) = Q(2)$ Substitute $x=7$, we have $Q(42) = Q(6)$ Substitute $x=43$, we have $Q(43^2-43) = Q(42)$ Since there are infinitely many $x$ such that $Q(x) = Q(1)$ so $Q(x)$ is constant polynomial. Therefore, $P(x)=cx$ where $c$ is constant.","['algebra-precalculus', 'contest-math', 'polynomials']"
2407289,Sufficient condition under which a pointwise convergent becomes uniform convergence,"Let $K$ be any compact subset of $\mathbb{R}$. Then what are the
  sufficient conditions so that any pointwise convergent sequence of functions on $K$ converges uniformly. The conditions can be given as in Dini's Theorem. Can we have other conditions (Weaker) apart from Dini's theorem so that this becomes true?","['real-analysis', 'convergence-divergence']"
2407306,Power set of any set.,"Question: Let $A$ be any set. Let $\mathbb{P}(A)$ be the power set of $A$ . Then which one is true? $\mathbb{P}(A)=\emptyset$ for some $A$ . $\mathbb{P}(A)$ is finite for some $A$ . $\mathbb{P}(A)$ is countable for some $A$ . $\mathbb{P}(A)$ is uncountable for some $A$ . Now 1. is not true, since if $A=\emptyset$ , $\mathbb{P}(A)=\{\emptyset\}\neq \emptyset$ . 3. is not true since let $A=\mathbb{N}$ , then $\mathbb{P}(A)=2^\mathbb{N}$ is uncountable. So answer will be 2 and 4. But when I saw the answer book, it says answer is (2,4) or (2,3,4) . That or is for answer is not decided yet. My question is why is their doubt!!! The answer should be $(2,4)$ .... this is obvious, isn't? I am very bad at set theoritic arguments. Can someone clarify it?","['elementary-set-theory', 'proof-verification']"
2407307,Motivation for spectrum of an Abelian category,"In his book Noncommutative Algebraic Geometry and Representations of Quantized Algebras , Rosenberg defines (III.1.2 on page 111) the spectrum of an Abelian category $\mathbf{A}$ in the following way.  He first defines a preorder $\succ$ on $\operatorname{Ob}(\mathbf{A})$ by declaring that $V\succ W$ iff $W$ is a subquotient of a coproduct of finitely many copies of $V$. Let us write $V\sim W$ iff $V\succ W$ and $W\prec V$ (my notation, not his---he just says ""equivalent with respect to $\succ$"").  He then defines $$\operatorname{Spec}(\mathbf{A}):=\left\{ V\in \operatorname{Obj}(\mathbf{A}):V\neq 0\text{ and }V\sim W\text{ for all nonzero subobjects }W\text{ of }V\text{.}\right\}$$ My question is simply ""Why?"":  of all the possible definitions one might write down, why this one? It is not at all clear to me what the intuition for this definition is supposed to be.  What does this actually 'mean'?","['abelian-categories', 'noncommutative-algebra', 'algebraic-geometry', 'noncommutative-geometry']"
2407318,${2^\left|(x+2)\right|}$ - $\left|2^{x+1} -1 \right| $=$ 2^{x+1}+1$ .What is the Minimum value of ${x}$?,"I try to use logarithm but I  cannot be applied on the equation. So how can I solve this  equation.
Any help will be appreciate.",['algebra-precalculus']
2407387,"Does $K_{70,70}$ decompose into subgraphs isomorphic to $K_{1,1}$ through $K_{24,24}$?","The complete bipartite graph $K_{n,n}$ has $n^2$ edges.  There's a curious number quirk that $$70^2=4900=1^2+2^2+\cdots+24^2.$$  This motivates the question: Question : Does $K_{70,70}$ decompose into subgraphs isomorphic to $K_{1,1}$ through $K_{24,24}$? I just ask out of simple curiosity since the number of edges checks out. It's equivalent to asking for a $70 \times 70$ matrix which contains symbols $1,\ldots,24$ where symbol $i$ belongs to an $i \times i$ all-$i$ matrix. One sanity check :  If it were possible, for each vertex in one part, we could write down the values of $k$ for which it intersects the $K_{k,k}$ used to decompose $K_{70,70}$.  This list would contain $1$ through $24$, with the number $i$ occurring exactly $i$ times, and no repeats in the rows.  I found an example of such a list: [1, 22, 23, 24], [2, 21, 23, 24], [2, 21, 23, 24], [3, 10, 16, 18, 23], [3, 14, 16, 17, 20], [3, 20, 23, 24], [4, 14, 15, 16, 21], [4, 15, 16, 17, 18], [4, 21, 22, 23], [4, 21, 22, 23], [5, 13, 15, 16, 21], [5, 19, 22, 24], [5, 20, 21, 24], [5, 20, 22, 23], [5, 20, 22, 23], [6, 13, 14, 16, 21], [6, 13, 14, 18, 19], [6, 17, 23, 24], [6, 19, 22, 23], [6, 19, 22, 23], [6, 20, 21, 23], [7, 12, 15, 16, 20], [7, 13, 14, 15, 21], [7, 18, 21, 24], [7, 18, 21, 24], [7, 18, 22, 23], [7, 18, 22, 23], [7, 20, 21, 22], [8, 10, 13, 17, 22], [8, 11, 12, 15, 24], [8, 11, 13, 17, 21], [8, 13, 15, 16, 18], [8, 17, 22, 23], [8, 19, 20, 23], [8, 19, 20, 23], [8, 19, 20, 23], [9, 10, 12, 15, 24], [9, 11, 12, 17, 21], [9, 12, 13, 17, 19], [9, 17, 20, 24], [9, 17, 20, 24], [9, 18, 19, 24], [9, 18, 19, 24], [9, 18, 21, 22], [9, 19, 20, 22], [10, 12, 14, 16, 18], [10, 15, 21, 24], [10, 15, 21, 24], [10, 17, 19, 24], [10, 17, 20, 23], [10, 18, 20, 22], [10, 18, 20, 22], [11, 12, 13, 15, 19], [11, 12, 14, 16, 17], [11, 12, 14, 16, 17], [11, 12, 23, 24], [11, 13, 22, 24], [11, 16, 19, 24], [11, 16, 19, 24], [11, 16, 21, 22], [12, 14, 20, 24], [12, 14, 21, 23], [13, 14, 19, 24], [13, 15, 20, 22], [13, 17, 18, 22], [14, 15, 18, 23], [14, 15, 19, 22], [14, 15, 20, 21], [16, 17, 18, 19], [16, 17, 18, 19] This means arguments involving degrees alone cannot exclude this possibility. In the matrix equivalence, this means that we can specify the columns the all-$i$ submatrices intersect in a non-clashing way (but it doesn't simultaneously give the rows).","['combinatorics', 'graph-theory']"
2407397,Canonical bijection from $\mathcal{P}\mathbb{X}$ to $^\mathbb{X}2$ for finite $\mathbb{X}$?,"The title pretty much says it all -- for a finite set $\mathbb{X}$, is there a canonical bijection between $\mathcal{P}\mathbb{X}$ and $^\mathbb{X}2,$ where $\mathcal{P}\mathbb{X}$ is the powerset of $\mathbb{X}$ and $^\mathbb{X}2$ is the class of functions from $\mathbb{X}$ into a set with two elements? It's well known that $|\mathcal{P}\mathbb{X}|=|^\mathbb{X}2|$, I was just wondering if there was a particularly nice way of associating subsets to functions bijectively.",['elementary-set-theory']
2407439,Graph isomorphism algorithm / sufficient condition,Is there a good algorithm to determine whether two graphs are isomorphic or not ? Are there any conditions that are sufficient to determine an isomorphism between two graphs? I've just started studying graph theory and I'm struggling with isomorphisms.,"['combinatorics', 'graph-theory', 'algorithms']"
2407546,"We define a map $T: L^2[0,1] \to L^2[0,1]$ s.t $T(f)=\int_0^1 fgdx$. Determine $||T||$.","Let $g \in L^ {\infty}$ we define a map $T: L^2[0,1] \to L^2[0,1]$ s.t $T(f)=\int_0^1 fgdx$. Determine $||T||$. I have seen that $||T||=\sup \{||T(f)|| : ||f||=1\} \leq ||g||_{\infty}$ How to prove the converse? I also know that the set $E_n=\{x \in [0,1]:  |g(x) >||g||_{\infty} - \frac1n\}$ has positive measure. So please check what I have done is right or not and provide the answer in details.","['functional-analysis', 'lp-spaces', 'measure-theory']"
2407569,Why two vectors cannot span ${\bf R}^3$?,"Consider two vectors 
$$
u_{1} = \begin{bmatrix}
-1 \\
 3 \\
 2 \\
\end{bmatrix},\quad
u_{2} = \begin{bmatrix}
 6 \\ 
 1 \\
 1 \\
\end{bmatrix}
$$ I can tell they don't span $R^3$ because $R^3$ requires three vectors to span it. But is there another way I can see that it does not span $R^3$, for example, in terms of overdetermined system, or not a square matrix? Just trying to develop a mature understanding of this topic, that's all.","['linear-algebra', 'vector-spaces']"
2407611,A more general closed-form of an integral involving a square power of $\theta_4$ - function,"$\textbf{Problem statement}$. Inspired by the computations at this nospoon we introduce the following integral: $$\int_{0}^{\infty }\frac{~\theta _{4}^{2}\left( \exp \left( -\pi \,y\,\beta
\right) \right) }{1+y^{2}}dy\;  \tag{1}\label{1}$$
which is as far as I know only calculated for $\beta =1$.
$$\int_{0}^{\infty }\frac{~\theta _{4}^{2}\left( \exp \left( -\pi \,y\right)
\right) }{1+y^{2}}dx=1   \tag{2}\label{2} $$
My goal is to calculate the integral of \eqref{1} for any $\beta $. $\textbf{Ansatz}$.With the aid of the well-known representation of the square power of $ \theta_{4}$ Dieckmann $$\theta _{4}^{2}\left( \exp \left( -\pi \,y\right) \right)
=1+2\sum_{k=1}^{\infty }(-1)^{k}~s{ech}(\pi k\,y)  \tag{3}\label{3}$$
and the transformation $y=\frac{x}{\beta }$, for \eqref{1} follows:
$$\frac{\pi }{2}+2\sum_{k=1}^{\infty }(-1)^{k}\int_{0}^{\infty }\frac{~\beta ~s%
{ech}(\pi k\,x)}{\beta ^{2}+x^{2}}\,dx  \tag{4}\label{4}$$
The integral in the sum:
$$\int_{0}^{\infty }\frac{\beta ~s{ech}(\pi k\,x)}{\beta ^{2}+x^{2}}%
\,dx=\int_{0}^{\infty }\frac{\beta ~}{\beta ^{2}+x^{2}}\frac{1\,}{\cosh
\left( \pi k\,x\right) }dx  \tag{5}\label{5}$$
is done in Sangchul Lee and returns the solution of \eqref{1}:
$$\mathcal{I}\left( \beta \right) =\frac{\pi }{2}+\sum_{k=1}^{\infty
}(-1)^{k}\left( \psi \left( \frac{k\,\beta \ }{2}+\frac{3}{4}\right) -\psi
\left( \frac{k\,\beta \ }{2}+\frac{1}{4}\right) \right) \;  \tag{6}\label{6}$$ Using nospoon returns $\mathcal {I} \left(1\right) = 1 $. A proof is upon request. For the readability, here some of the steps performed in Sangchul Lee .
Transformation of \eqref{5} with $y=\frac{x}{%
\beta }$ leads to:
$$\int_{0}^{\infty }\frac{\beta ~}{\beta ^{2}+x^{2}}\frac{1\,}{\cosh \left(
\pi k\,x\right) }dx=\int_{0}^{\infty }\frac{1~}{1+y^{2}}\frac{1\,}{\cosh
\left( a\,y\right) }dy  \tag{7}\label{7}$$
with $a=k~\beta \,\pi $. Transformation
with $z=$ $\frac{a\,y}{\pi }$ leads to:
$$\int_{0}^{\infty }\frac{1~}{1+y^{2}}\frac{1\,}{\cosh \left( a\,y\right) }dy=%
\frac{\pi a}{2}\int_{-\infty }^{\infty }\frac{dz}{\left( a^{2}+\pi
^{2}z^{2}\right) \cosh \left( \pi \,z\right) }  \tag{8}\label{8}$$ In the following, we need the Fourier transform of $f$
$$\widehat{f}\left( \xi \right) =\mathcal{F}\left[ f\left( z\right) \right]
=\int_{\mathcal{R}}f\left( z\right) \exp \left( -2\pi i\xi z\right) ~dz
\tag{9}\label{9}$$
Let
$$f\left( z\right) =s{ech}(\pi \,z),\;g\left( z\right) =\frac{1}{a^{2}+\pi
^{2}z^{2}}  \tag{10}\label{10}$$
and
$$\widehat{f}\left( \xi \right) =s{ech}(\pi \,\xi ),\;\widehat{g}\left( \xi
\right) =\frac{1}{a}\exp \left( -2a\left\vert \xi \right\vert \right) 
\tag{11}\label{11}$$ Also, if both $f$ and $g$ are in $L^{2}$, then
$$\int_{\mathcal{R}}\widehat{f}~g=\int_{\mathcal{R}}f~\widehat{g} \tag{12}\label{12}$$
results to
$$\frac{\pi }{2}+\pi a\sum_{k=1}^{\infty }(-1)^{k}\int_{-\infty }^{\infty }%
\frac{dz}{\left( a^{2}+\pi ^{2}z^{2}\right) \cosh \left( \pi \,z\right) }=%
\frac{\pi }{2}+2\pi \sum_{k=1}^{\infty }(-1)^{k}\int_{0}^{\infty }\frac{\exp
\left( -2\pi k\beta ~z\right) }{\cosh \left( \pi \,z\right) }dz  \tag{13}\label{13}$$ Further transformations then leads finally to the solution \eqref{6}. Now, for an equivalent integral representation of \eqref{1}, we first perform the sum in \eqref{13}:
$$\mathcal{I}\left( \beta \right) =\frac{\pi }{2}-2\pi \int_{0}^{\infty }\frac{%
s{ech}(\pi \,z)}{1+\exp \left( 2\pi \beta ~z\right) }dz  \tag{14}\label{14}$$ For $\beta =1$, the known value $\mathcal{I}\left( 1\right)
=1$ results. With the aid of Mathematica, 
further analytical expressions for some fixed $\beta$-values can be calculated. 
With \eqref{4} the following identity results: $$\sum_{k=1}^{\infty }(-1)^{k}\int_{0}^{\infty }\frac{s{ech}(k~\pi \,z)}{\beta
^{2}+z^{2}}dz=-\frac{\pi }{\beta }\int_{0}^{\infty }\frac{s{ech}(\pi \,z)}{%
1+\exp \left( 2\pi \beta ~z\right) }dz  \tag{15}\label{15}$$ The integral form \eqref{14} can be transformed into other interesting expressions. 
Using the known identity Kim :
$$\,_{2}F_{1}\left( a,a;a+1;\frac{1}{2}\right) =2^{a-1}a~\left( \psi \left( 
\frac{a}{2}+\frac{1}{2}\right) -\psi \left( \frac{a}{2}\right) \right)
\tag{16}\label{16}$$
and \eqref{6}, these expressions can be reproduced and further identities can be derived.
For the readability, I omit lots of results, I've found so far. In case of interest, these results can be requested. $\textbf{1st Question}$ $\textit{Does anybody know how to approach this sum \eqref{6}?} $
$\textit{ Where can I find out more about dealing with the sum?}$
$\textit{Is it possible to derive a simpler expression?}$ $\textbf{2st Question}$ $\textit{Can we find a closed form expression for $\mathcal{I}\left( \beta\right)$, at least for $\beta $ $\in \mathbb{N}$?, distinguishing even/odd $\beta $ ?}$ $\textbf{Bonus Q}$ $\textit{How can I proof the identity \eqref{15} with the help of the Poisson Summation Formula?}$ $\textit{Are there any further results can be obtained by doing so?}$","['theta-functions', 'closed-form', 'integration', 'definite-integrals', 'sequences-and-series']"
2407633,Review: Prove by induction Nicomachus's theorem,"Please help me out reviewing the way I wrote this proof: Prove by induction: $1^3+2^3+3^3+...+n^3=\left(\frac{n(n+1)}{2}\right)^2$ with $n\geqslant1$ Proof: Lets define the set, $S=\left \{n\in N:n\geqslant1, 1^3+2^3+3^3+...+n^3=\left(\frac{n(n+1)}{2}\right)^2  \right \}$ If $n=1$ then, $1\in S$ Lets asume that $k\in S$ with $k\geqslant1$, then $\begin{gather*} 1^3+2^3+3^3+...+k^3=\left(\frac{k(k+1)}{2}\right)^2\\ 
\end{gather*}$ Now lets proof that $k+1\in S$, $\begin{align*}1^3+2^3+3^3+...+k^3+(k+1)^3=&\left(\frac{k(k+1)}{2}\right)^2+(k+1)^3\\ =&(k+1)^2\left (\frac{k^2}{4}+(k+1)\right)\\=&(k+1)^2 \left(\frac{(k^2+4k+4)}{4} \right)\\ =&(k+1)^2 \left(\frac{(k+2)^2}{4}\right)\\ =&\left(\frac{(k+1)(k+2)}{2}\right)^2 \end{align*}$ Which is true.","['induction', 'discrete-mathematics']"
2407659,Why does the Newton-Raphson method not converge for some functions?,"$f(x)=2x^2-x^3-2$. This is a cubic type graph as shown.  The real root of this graph is $(-0.839,0)$. So, the question is to use Newton's approximation method twice to approximate a solution to this $f(x)$. I use an initial starting value of $x_0=1$.
My first approximation is $x_1=2$, and my second one is $x_2=1.5$.
I seem to not move any closer to the real solution as I keep iterating through the method. Am I misunderstanding how to use this approximation?  Is the issue that my first guess was too far from the actual solution?","['numerical-methods', 'calculus']"
2407664,Prove $\tan A_1<\dfrac{\sum_{i=1}^n \sin A_1}{\sum_{i=1}^n \cos A_1}<\tan A_n$ for $0<A_1<A_2<\dots<A_n<\pi/2$.,"If $0<A_1<A_2<\dots<A_n<\pi/2$, then prove that
  $$\tan A_1<\frac{\sin A_1+\sin A_2+\dots+\sin A_n}{\cos A_1+\cos A_2+\dots+\cos A_n}<\tan A_n$$ I have approached it in this way that $\sin\theta$ increases from $0$ to $\pi/2$ and $\cos\theta$ decreases from $0$ to $\pi/2$. I could not proceed after that.","['inequality', 'trigonometry']"
2407671,Surfaces with the same constant Gaussian curvatures are locally isometric?,"Question: I want to know whether surfaces with the same constant Gaussian curvatures are locally isometric or not. If the answer is yes, why? Definitions: Gaussian curvature of a surface at some point is the product of the eigenvalues of the shape operator of the surface at that point$.^1$ Shape operator of a surface is the minus derivative of the unit normal vectors on the surface. Formally speaking, let $f:U \to \mathbb {R}^3$ be a surface element with unit normal vector map $\nu$, $\nu: U \to S^2$ is defined by $$\nu (u_1,u_2):=\frac{\frac{\partial f}{\partial u_1} \times \frac{\partial f}{\partial u_2}}{\left \Vert \frac{\partial f}{\partial u_1} \times \frac{\partial f}{\partial u_2} \right \Vert},$$ then for every $u\in U$ we have the linear map $$D\nu|_u:T_uU \to T_uf,$$
where $T_uU=\{u\} \times \mathbb R^2$ and $T_uf=Df|_u\left(T_uU\right)$, and $$Df|_u:T_uU \to T_uf$$
is a linear isomorphism. Then the shape operator $L:=-D\nu \circ (Df)^{-1}$ is defined pointwise by $$L_u:=-\left(D\nu|_u \right) \circ \left(Df|_u\right)^{-1}:T_uf \to T_uf\,.^2$$ Two surface elements $f:U \to \mathbb R^3,g:V \to \mathbb R^3$ are said to be isometric , if there is a parameter transformation $\Phi:U \to V$ such that $$\left \langle \frac{\partial f}{\partial u^i},\frac{\partial f}{\partial u^j}\right \rangle =\left \langle \frac{\partial (g \circ \Phi)}{\partial u ^i}, \frac{\partial (g \circ \Phi)}{\partial u ^j}
\right \rangle$$ for all $i,j\,.^3$ [1], [2], [3] Wolfgang Kühnel, ""Differential Geometry Curves-Surfaces-Manifolds"", Second Edition, American Mathematical Society, 2006.","['curvature', 'geometry', 'manifolds', 'differential-geometry', 'surfaces']"
2407700,"$x^2 + 3x + \frac{3}x + \frac{1}{x^2} = 26$ and $x$ can be written as $a + \sqrt{b}$ where $a$ and $b$ are positive integers, then find $a + b$.","If $x$ satisfies $x^2 + 3x + \frac{3}x + \frac{1}{x^2} = 26$ and $x$ can be written as $a + \sqrt{b}$ where $a$ and $b$ are positive integers, then find $a + b$. This equation becomes $x^4+3x^3-26x^2+3x+1=0$ which has four solutions. One of the solutions is $2+\sqrt3$ which has the form $a+\sqrt b$. So, $a+b=2+3=5$. How does this look?","['algebra-precalculus', 'radicals', 'polynomials']"
2407714,"Show that for any integer $n\ge 6$, the inequality $2^n>7n$ holds.","Step one: for case where $n=6$ $$7n <2^n$$
$$7(6)<2^6 \rightarrow 42<64$$. Step two: Suppose for $n$ such that $7n<2^n$ is true. Now prove for $n+1$ $$(2)7n<(2)2^n$$
$$14n<2^{n+1}$$ But since $n<7n<2^n$, then $n+7<7(n+1)<2^n+7<2^{n+1}(?)$. Then $7(n+1)<2^{n+1}$ I'm new in this induction process, so any help/tips for this problem would be really appreciated.","['inequality', 'binomial-theorem', 'exponential-function', 'algebra-precalculus', 'induction']"
2407724,"If $f(x) = p \sin x + qx \cos x + x^2$ is defined for all $x,q,p \in \Bbb R$ and $f(2) = 3$ find $f(-2)$.","I'm preparing for the GRE Subject Test in Mathematics and unfortunately found that can't understand the way the following problem should be done. The right option is D , but I can't deduce it. For $x=2$ we obtain $-1 = p\sin 2 + 2q\cos 2$. Since $x=-2$ is symmetrical with $x=2$ around the $y$-axis the value of sine should change its sign ($\sin 2 = -\sin (-2)$) and the value of cosine stands similar ($\cos2 = \cos(-2)$), but we still have one equation with two unknows. How should I proceed to the answer?","['algebra-precalculus', 'trigonometry']"
2407726,Measure theory in practice,"I am trying to unite my knowledge of statistics and measure theory by considering the following example. Suppose we have a measurable space $(\Omega_1,B_1)$ and a random variable (measurable function) on the space, call it $X$: $\Omega_1 \rightarrow R$. Suppose we know the distribution function of $X$, say it is normal $X \sim N(0,1)$. Now consider the random variable 
$$Y=X +5$$ We know from basic statistics that $Y\sim (5,1)$, but how can we prove that by using the definition of $X$ and composition of functions? Explanations that are step by step greatly appreciated!","['statistics', 'probability', 'measure-theory']"
2407732,non-homogenous differential equation eigenvalues?,"I am confused by the fact that the following system is not homogenous: How can we speak of the eigenvectors of a system like this? without the $2$'s, we simply have the equation $Av=\lambda v\to (A-\lambda I)v=0$. So we know that the determinant of $A-\lambda I$ is zero. But I don't know what I can conclude from the equation $(A-\lambda I)v=\overrightarrow 2$ So how do I answer this question?",['ordinary-differential-equations']
2407743,Is the function $\frac{x}{2} \cdot (\sin(\ln{x}) - \cos(\ln{x}))$ a fractal?,Is the curve determined by the function $\displaystyle{ f(x) = \frac{x}{2} \cdot (\sin(\ln{x}) - \cos(\ln{x}))}$ a fractal? This function is the result of the integral $\displaystyle{\int{\sin{(\ln{x})}dx} }.$ It seems to repeat itself from $0$ to $+\infty.$ The difference between the magnitude of the repetitions is very big between each other. The function zeroes are on the form: $\displaystyle{ e^{\pi n - 3\pi/4} }.$,"['fractals', 'trigonometry', 'calculus', 'indefinite-integrals', 'integration']"
2407745,What is the theory of Matrices?,"I've just passed high school and studying matrices. I've learned about determinant, transpose and adjoint etc. I've learned the method of finding these things but what's the purpose of finding these things? What actually Matrices do which makes it solving equations easier. Why determinant is equal to $(ab)-(cd)$ not $(cd)-(ab)$ for the matrix, $\left[\begin{matrix}a&c\\d&b\end{matrix}\right] $ ? Why inverse of $\rm A$ is equal to $\dfrac{\operatorname{adj}A} {\det A}$ not $\dfrac{\det A} {\operatorname{adj}A}$ ? I've read many answers like, What is the usefulness of matrices? , they say that matrices do this and that ,but they does not explain how or why ? Also what is the relation between vectors and matrices?","['matrices', 'determinant']"
2407757,2D collision equations with inverse y-axis,"I am currently trying to code a 2D physics engine in gamemaker studio, however I have run into a problem. I have found the following useful website to help me calculate the new x and y components of my speed vector after collision: http://williamecraver.wixsite.com/elastic-equations EDIT:
I'll try and be more specific about my problem:
I want to calculate collision in 2D. In order to do this I first rotate my x-y axis so that x runs from the centre of one object through the center of the other object (both are circles). (the image in the link nicely illustrates the situation) In the link I provide, calculation of resulting vx and vy vectors for each object after the collision is explained.
It uses the following equations to rotate the vx and vy components(I'm sorry I don't know how to insert proper equations) vxr = v * cos(theta - phi) vyr = v * sin(theta - phi) with vxr being the rotated vx vector (same for vy), theta being my original angle between v and the x axis, phi being my rotation angle Then these ""rotated"" vx and vy components are inserted into the equations for conservation of momentum and kinetic energy to solve a 1D collision (which is possible because of the rotation of the axis). Afterwards he rotates the axis back using the following equations: vfx = vfxr * cos(phi) + vyr * cos(phi + pi/2) vfy = vfyr * sin(phi) + vyr * sin(phi + pi/2) with vfxr/vfyr being the resulting rotated x/y component after collision, vfx vfy being the resulting x/y components transformed back into the regular x-y plane. My problem is that my y-axis is pointing down (instead of the conventional up). Therefore I believe the original equations for vyr should be: vyr = v * -sin(theta - phi) My first question is if my assumption for the vyr component is correct and if I missed other things that should change in the calculation because of the inverted y-axis. What about the equation to rotate vx and vy back to the regular x-y plane? Secondly, if my assumptions are correct, I am unable to perform the calculations when inserting these equations into the 1D collision equations. Especially regarding the conversion back to regular x-y plane, I don't understand where these equations come from and how they change with an inverse y-axis.",['trigonometry']
2407781,Show that $g_*X = X$ for a symplectomorphism $g$ (Lectures on Symplectic Geometry Exercise),"This is again exercise 1, p. 22 from Lectures on Symplectic Geometry by Ana Cannas da Silva . Let $(M,\omega)$ be a symplectic manifold and $\alpha \in \Omega^1(M)$
  such that $\omega = -d\alpha$. Furthermore let $g: M  \to M$ be a
  symplectomorphism which preserves $\alpha$, i.e. $g^{*}\alpha =
\alpha$. Show that $$g_* X = X$$ where $X$ is the unique vector field
  such that $i_X\omega = -\alpha$. From my previous post , we get that $X = -\widehat{\omega}^{-1}(\alpha)$, where $\widehat{\omega} : TM \to T^*M$ is defined by $(p,v_p) \mapsto \omega_p(v_p,\cdot)$. Has anyone a hint for me how to show that $g_*X = X$? I mean we have that $$(g_* X)_{g(p)} = dg_p(X_p)$$ But I am not sure how to proceed. I guess I have to use that $g$ is a symplectormorphism and that it preserves $\alpha$, but I am not sure how to use this. Also I am a bit confused by $\omega = -d\alpha$, since until now I did not use this.","['symplectic-geometry', 'differential-geometry']"
2407815,Probability that the convex hull of random points contains sphere's center,What is the probability that the convex hull of $n+2$ random points on $n$-dimensional sphere contains sphere's center?,"['geometric-probability', 'geometry']"
2407851,Dirac notation - Outer product representation of Normal Matrix,"I'm studying some linear algebra applications in quantum mechanics, and I was told that a normal matrix can be written as:
$$
M=\sum_{i=1}^{n}\theta_i |\theta_i\rangle \langle\theta_i|
$$
where $|\theta_i\rangle$ is the eigenvector associated with it's eigenvalue $\theta_i$. The problem is that I can't properly visualize that summation as a normal matrix representation. Here's my attempt to visualize why that's true. I know, by spectrum theorem, that I can diagonalize that matrix M by some unitary matrices: $$
D = U^{\dagger}MU \Rightarrow U^{\dagger}\big(\sum_{i=1}^{n}\theta_i |\theta_i\rangle \langle\theta_i|\big)U
$$ So if I manage to calculate the right relation, I'll get why the matrix $M$ can be written as it was said, but how can I do that? How can I include $U$ and $U^{\dagger}$ into that summation to calculate it? Can someone please show me what's really happening in that summation? What I've been able to get is:
$$
\theta_i|\theta_i\rangle
$$
Is a scalar times a ""column"" vector.
$$
\langle\theta_i|
$$
Is a bra, or a conjugate transpose ket.
$$
\theta_i |\theta_i\rangle \langle\theta_i|
$$
Is a matrix, and the summation is actually adding multiple matrices with previous outer product computation. Can someone please help me out? Thanks!","['matrices', 'mathematical-physics', 'linear-algebra', 'quantum-mechanics']"
2407859,Completion and outer-measure extension of sigma finite measure,"I need some help with the proof of the following. Let $(X,\mathcal{A},\mu)$ be a measure space with $\mu$ being $\sigma$ -finite, $\mu^*$ be the outer measure given by the formula $\mu^*(E)=\inf\{\sum_{n}\mu(A_n): E\subset\bigcup A_n, (A_n)\subset\mathcal{A}\}$ and $\mathcal{M}$ the $\sigma$ -algebra of the $\mu^*$ -measurable sets. Also let $\mathcal{A}_{\mu}=\{A\subset X: \exists E,F\in\mathcal{A},$ with $E\subset A\subset F$ and $  \mu(F\setminus E)=0\}$ and $\overline{\mu}:\mathcal{A}_\mu\to [0,+\infty]$ given by $\overline{\mu}(E)=\sup\{\mu(B): B\in\mathcal{A}, B\subset E\}.$ Then $\mathcal{A}_\mu=\mathcal{M}$ and $\overline{\mu}=\mu^*\vert_{\mathcal{M}}$ . Okay, so it is known that the measure space $(X,\mathcal{A}_\mu, \overline\mu)$ is the completion of $(X,\mathcal{A},\mu)$ and by the facts that $\mu^*\vert_\mathcal{A}=\mu$ and $\mathcal{A}\subset\mathcal{M}$ , we have that $\mathcal{A}_\mu\subset\mathcal{M}$ and that $\mu^*\vert_{\mathcal{A}_\mu}=\overline\mu$ . So in order to prove the statement above, it would be enough to show that $\mathcal{M}\subset\mathcal{A}_\mu$ . I'm trying to prove that if $A\in\mathcal{M}$ and $\mu^*(A)<\infty$ then $A\in\mathcal{A}_{\mu}$ but I'm stuck. My progress is the following: For each $n\in\mathbb{N}$ there exists a sequence $(A_k^{(n)})\subset\mathcal{A}$ such that $\sum_{k}\mu(A_k^{(n)})<\mu^*(A)+\frac{1}{n}$ . Let $A_n=\bigcup_{k}A_k^{(n)}\in\mathcal{A}$ . We have that $\mu(A_n)\leq\sum_{k}\mu(A_k^{(n)})<\mu^*(A)+\frac{1}{n}$ . Finally let $F=\bigcap_{n} A_n$ . Then $\mu(F)\leq\mu(A_n)<\mu^*(A)+\frac{1}{n}$ for all $n$ . Taking limits we have that $\mu(F)\leq\mu^*(A)$ , but $A\subset F$ , so $\mu^*(A)\leq\mu^*(F)=\mu(F)$ so we found the first desirable set. But what about the other? I'm stuck here and I can't seem to be able to use the sigma-finiteness. Any help? EDIT: Maybe considering the fact that the sigma-algebra $\mathcal{A}_1=\{A\cup E: A\in\mathcal{A}, E\subset F,$ where $F\in\mathcal{A}, \mu(F)=0\}$ is equal to $\mathcal{A}_\mu$ helps. It is easy to show this equality.","['outer-measure', 'measure-theory']"
2407870,Maximum of $k$ binomial random variables?,"Imagine you have $k$  random variables $X_1,...,X_k$ drawn i.i.d. from a binomial distribution $B(n,1/2)$. For any $\epsilon > 0$, the probability that the maximum of these $k$ draws is above $(1-\epsilon) n$ 
$$
\Pr[\max_i X_i > (1-\epsilon) n] = 1- \Pr[X_k \leq (1-\epsilon) n]^k = 1 -\left( \sum_{i=0}^{\lfloor (1-\epsilon) n) \rfloor} \binom{n}{i} (1/2)^n\right)^k.$$ I want to show that if $k$ is chosen large enough (possibly larger than $n^s$ for some integer $s$), then $$\Pr[\max_i X_i > (1-\epsilon)n] \geq 1-  \frac{1}{\sqrt{n}}.$$ I know from previous questions ( Bounds for the maximum of binomial random variables ) that if $k = n$ this is unlikely to be the case, but is it true for $k = n^s$ for some power $s$?",['probability']
2407995,How can we show that $\sum_{n=1}^{\infty}{\zeta(2n)\over a^{2n}n}=\ln\left({\pi\over a\sin({\pi\over a})}\right)$?,"Using Sum Calculator on $(1)$, $$\sum_{n=1}^{\infty}{\zeta(2n)\over a^{2n}n}\tag1$$
for $a>1$ we noticed that it takes a closed form of $$(1)=\ln\left({\pi\over a\sin({\pi\over a})}\right)\tag2$$ How can we show that whether $(1)$ is correct or not? We can see that $${\sin x\over x}=\prod_{n=1}^{\infty}\left(1-{x^2\over n^2\pi^2}\right)\tag3$$ It looks like that the product $(3)$ can we change into a sum, but I can't see how it is done.","['infinite-product', 'sequences-and-series', 'closed-form']"
2408020,Given $a^2+b^2+c^2 = 1$ what type is this matrix?,"With $ a^2 + b^2 + c^2 = 1$, what type of matrix is $A$? $A =
\begin{bmatrix}
0  & a  & -b \\
-a & 0  & c \\
b  & -c & 0 
\end{bmatrix}$ So far I've tested $A$ for several types, I know that $A$ is non-orthogonal, obviously skew-symmetric and singular, as it's determinant equals $0$ and there is no chance to get an inverse. But nothing is related to the $ a^2 + b^2 + c^2 = 1$ condition, any ideas?","['matrices', 'matrix-calculus', 'robotics', 'linear-algebra']"
2408030,Is a linear vector field a geodesible vector field?,"Assume that $A\in M_n(\mathbb{R})$ is a  non singular matrix. Is the flow of linear vector field  $X'=AX$ a geodesible flow on $\mathbb{R}^n \setminus \{0\}$?Namely, is there a Riemannian metric on   $\mathbb{R}^n \setminus \{0\}$
  such that the trajectories of the linear vector field are unparametrized geodesics? Remark: For $n=2$ the answer is affirmative, as we explain below: Fact: A linear vector field associated to a non singular$ 2 \times 2$ real matrix is a geodesible vector field on the punctured plane. Proof: Let $A$ be an invertible matrix. We denote by $X$ the linear vector field associated to $A$. We consider two cases: 1)$A^2$ has no real eigenvalue. 2) $A^2$ has real eigenvalue. Case 1) In this case the linear vector field $Y$ associated to matrix $A^{-1}$ is transverse to $X$ on the puntured plane and satisfies $[X,Y]=0$ this obviously implies that $X$ is a geodesible vector field. Case 2) If $A^2$ has real eigenvalue then  $A$ is similar to one of the following matrices: $$\begin{pmatrix} a&0\\ 0& b \end{pmatrix}\;; \begin{pmatrix} a&\epsilon\\ 0& a \end{pmatrix} \;;\begin{pmatrix} 0&b\\ -b& 0 \end{pmatrix} $$
For the first matrix the closed one form $\psi=axdx+bydy$ satisfies $\psi(X)>0$.So $X$ is a geodesible vector field.  For the second matrix the $1$-form $\psi=axdx+aydy$ satisfies $\psi(X)>0$. For the third matrix the vector field is geodesible because we have a foliation of punctured plane by closed curve. The reason of geodesibility of case $1$ and three matrices in case $2$ is discussed in the following post which is essentially based on page 71 of ""Geometry of foliation "" by Philip Toender, Propsition $6.7$ and $6.8$ https://mathoverflow.net/questions/273635/finding-a-1-form-adapted-to-a-smooth-flow/273648#273648 Please see also this related post: https://mathoverflow.net/questions/282694/is-every-real-matrix-conjugate-to-a-semi-antisymmetric-matrix","['dynamical-systems', 'riemannian-geometry', 'differential-geometry']"
2408031,"Why is $\mathbb{C}[x,y]/(y^2 - x^3 + 1)$ normal?","A problem on an algebra qual reads Show that the ring $R = \mathbb{C}[x,y]/(y^2 - x^3 +1)$ is a Dedekind
  domain. (Hint: compare $R$ with the subring $\mathbb{C}[x]$.) $R$ is clearly Noetherian. It is an integral extension of $\mathbb{C}[x]$, so inherits its dimension, which is one. How do I know it is normal?","['abstract-algebra', 'commutative-algebra']"
2408043,Does integral extension of finitely generates $k$-algebras implies finite module?,"Let $k$ be a field, $ A \subseteq B$ finitely generated $k$ -algebras , with $B$ integral over $A$ . Is it true that $B$ is a finite $A$ -module? In the case where $A=k[x]$ , $x$ transcendental over $k$ , and $B$ is the integral closure of $A$ in a finite extension $L$ of the field of fractions $K=k(x)$ this follows from the properties of Dedekind domains (and/or function fields). What about the more general cases?","['abstract-algebra', 'ring-theory', 'commutative-algebra']"
2408045,Is $\mathbb{Z \times Q }$ with lexicographical order isomorphic to $\mathbb{Z \times Z }$ with lexicographical order?,"I think that $\{\mathbb{Z \times Q}, \leq_{lex}\}$ is not isomorphic to $\{\mathbb{Z \times Z }, \leq_{lex}\}$, but I am not sure if my argumentation is sufficient. Is it enough to state that $\{\mathbb{Z \times Q}, \leq_{lex}\}$ is a dense order, while  $\{\mathbb{Z \times Z }, \leq_{lex}\}$ is not?","['order-theory', 'elementary-set-theory', 'proof-verification']"
2408053,Convergence in probability implies convergence in $L^p$ with an additional condition,I have a problem with this exercise. Let $(X_n)$ be a succession of random variables such that $|X_n|<M \in \mathbb{R}$. Prove that if $(X_n)$ converges to a random variable $X$ in probability then $(X_n)$ converges to $X$ in $L^p$. I tried to solve the exercise in the following way: $X_n \to X$ in probability $\Rightarrow$ $X_n-X \to 0$ in probability $\Rightarrow$ $|X_n-X|^p \to 0$  in probability (because $|\cdot|^p$ with $p \ge 1$ is a continuous function). I'm stuck here. Thanks in advance for your help.,"['probability-theory', 'lp-spaces', 'convergence-divergence']"
2408080,How to calculate $\lim_{x\to\infty}\frac{7x^4+x^2 3^x+2}{x^3+x 4^x+1}$?,$$\lim_{x\to\infty}\frac{7x^4+x^2 3^x+2}{x^3+x 4^x+1}$$ I can't  seem to find away to get rid of the $3^x$ and $4^x$ and then resolve it.,"['calculus', 'limits']"
2408084,when do orthogonal projection $\ P_UP_V = P_VP_U$ [duplicate],"This question already has an answer here : Orthogonal projection and two subspaces (1 answer) Closed 6 years ago . U, V are subspaces of a finite dimensional vector space W,
Let $\ P_U$ and $\ P_V$ be the orthogonal projections onto U and V
respectively. When is it true that $\ P_UP_V = P_VP_U$?","['projection', 'linear-algebra']"
2408108,What are some mathematically interesting computations involving matrices?,"I am helping designing a course module that teaches basic python programming to applied math undergraduates. As a result, I'm looking for examples of mathematically interesting computations involving matrices. Preferably these examples would be easy to implement in a computer program. For instance, suppose $$\begin{eqnarray}
F_0&=&0\\
F_1&=&1\\
F_{n+1}&=&F_n+F_{n-1},
\end{eqnarray}$$
so that $F_n$ is the $n^{th}$ term in the Fibonacci sequence. If we set $$A=\begin{pmatrix}
1 & 1 \\ 1 & 0 
\end{pmatrix}$$ we see that $$A^1=\begin{pmatrix}
1 & 1 \\ 1 & 0
\end{pmatrix} =
\begin{pmatrix}
F_2 & F_1 \\ F_1 & F_0
\end{pmatrix},$$ and it can be shown that $$
A^n =
\begin{pmatrix}
F_{n+1} & F_{n} \\ F_{n} & F_{n-1}
\end{pmatrix}.$$ This example is ""interesting"" in that it provides a novel way to compute the Fibonacci sequence. It is also relatively easy to implement a simple program to verify the above. Other examples like this will be much appreciated.","['big-list', 'matrices', 'sequences-and-series', 'linear-algebra', 'discrete-mathematics']"
2408113,Tangent bundle of the quotient of matrix Lie groups,"Let $G:=GL^+(n)$ (all invertible $n \times n$-matrices with positive determinant) and $K:=SO(n)$. Let $\mathfrak{g}, \mathfrak{k}$ denote their Lie algebras and $E:=\mathfrak{g}/\mathfrak{k}$. I would like to understand Why the (total space of) tangent space $T(G/K)$ of $G/K$ can be identified with $(G \times E)/K$. Some facts which are familiar for me: 0. $K$ acts on $E$ via adjoint representation and on $G$ via group multiplication. Thus one has a diagonal action of $K$ on $G \times E$ i.e. $a \cdot (g,x):=(ag,ad(a)x)$. I guess that $(G \times E)/K$ should be understood using this action. 1. if $G$ acts in such a way that $M/G$ is a manifold then we have a canonical identification for $x \in M$:
$$T_xM/T_x(G \cdot x) \cong T_{\pi(x)}(M/G)$$ where $G \cdot x$ is the orbit of $x$ and $\pi$ is the canonical projection. In our case we have for $g \in G$:
$$T_gG/T_g(K \cdot g) \cong T_{\pi(g)}(G/K).$$ Since this correspondence is canonical it should give rise to vector bundles isomorphism (but which bundles?).
2. Lie groups are parallelisable thus $TG \cong G \times \mathfrak{g}, TK \cong K \times \mathfrak{k}$.","['vector-bundles', 'tangent-bundle', 'differential-geometry', 'lie-algebras', 'lie-groups']"
2408128,Sum of Homogeneous and Particular Solution Is the Full Solution Set?,"I was hoping if someone could point me to a (hopefully) not too technical proof of why the sum of the homogeneous and particular solution to a (linear) differential equation yields the full solution set that to that differential equation. Intuitively, I understand this as follows (from the answer to this question): ""Suppose I find one particular solution $x_{(p,1)}(t)$ while my friend finds another one $x_{(p,2)}(t)$. Then the difference $x_c(t)=x_{(p,2)}(t)−x_{(p,1)}(t)$ will satisfy the homogeneous equation, since you get $…=f(t)−f(t)=0…$ in the right-hand side when substituting. So two different particular solutions to my ODE can't be arbitrarily different; they can only differ by a solution to the homogeneous ODE."" I am trying to find a way this can be formalized. I am not looking for a proof on how the sum of the homogeneous and particular solutions satisfy the original differential equation - I am trying to see why this is the full solution set. Thanks!",['ordinary-differential-equations']
2408131,Line integral $\int_K \frac{y}{x^2+y^2} dx -\frac{x}{x^2+y^2} dy$,"Solve $\int_K \frac{y}{x^2+y^2} dx -\frac{x}{x^2+y^2} dy$ =? K: $x^2+y^2=1$ is oriented positively. My attempt: $\int_K \frac{y}{x^2+y^2} dx -\frac{x}{x^2+y^2} dy = |x=cost, y=sint,x'=- sint,y'=cost | $ = * I put for $dx = -sint,dy=cost$ $= \int_0^{2\pi} \frac{sint}{cost^2+sint^2} -sint -\frac{cost}{cost^2+sint^2} cost  dt=  -\int_0^{2\pi} 1 dt = - 2 \pi $ We can't use Green's theorem because $P(x,y)$ and $Q(x,y)$ aren't continuous and their diveratives aren't continuous at point. $(0,0)$?","['multivariable-calculus', 'integration', 'proof-verification']"
2408141,Find domain and range for $f(x)=x^2+4$,"Let $X\to Y$ so that $f(x)=x^2+4$ $X=\{6,9,2,8,5\}$ and $Y=\{27,85,40,8,12,29,63,68,17\}$ a) state the domain of $f$ b) state the range of $f$ I have calculated that the domain of $f(x)$ is all real numbers and that the range of $f(x)$ is $f\ge4$. Therefore I thought that the correct answers were: a) $\{6,9,8,5\}$ b) $\{27,85,40,8,12,29,63,68,17\}$ But this was wrong. Could anyone help me? Many thanks in advance!","['algebra-precalculus', 'functions']"
2408160,Rudin Chapter 3 exercise 14,"For exercise 14c of Baby Rudin: If $\{s_n\}$ is a complex sentence, define its arithmetic means $\sigma_n$ by 
$$\sigma_n = \frac{s_0 + s_1 + \cdots + s_n}{n + 1},$$
where $n = 0, 1, 2, ...$ 14c: Can it happen that $s_n>0$ for all $n$ and that $\limsup s_n = \infty$, although $\lim \sigma_n = 0$? Does my example of $s_n = \sqrt{n}$ work? My attempt: It is clear that $\limsup s_n = \infty$ since $\sqrt{n} \rightarrow \infty$ as $n \rightarrow \infty$. And $\sigma_n = \frac{1 + \sqrt{2} + \cdots + \sqrt{n}}{n + 1}$, so $$\begin{split}
\lim_{n\to\infty} \sigma_n &= \lim_{n\rightarrow\infty} \frac{1 + \sqrt{2} + \cdots + \sqrt{n}}{n + 1}\\
&= \lim_{n\rightarrow\infty} \frac{1/\sqrt{n} + 2/\sqrt{n}+ \cdots + 1}{\sqrt{n} + 1/\sqrt{n}} = 0
\end{split}$$","['real-analysis', 'sequences-and-series']"
2408169,Show right half-plane with points of closed unit disk removed is not a star domain,"Consider the right half-plane $\{z\in {\mathbb  {C}}:{\mbox{Re}}(z)>0\}$. We define a set $X$ by removing from the right half-plane the points of the closed unit disk $\mathbb{D} = \{z \in \mathbb{C} : |z| \leq 1 \}$. I want to show that $X$ is not a star domain, i.e. there is no point $z_0 \in X$, such that for all $z \in X$ the line segment $[z_0, z]$ is in $X$. Here's a region plot of the situation: Intuitively the only possible choices for a $z_0$ all lie on the dashed line. However, if we were to select such a point $z^{*}$ on this line there will always be a region around the points $(0,1)$, $(0,-1)$ whose points are not joined by a line segment with $z^{*}$. In some way I think this is because the ""tangents"" at these points are parallel to the real axis. Can anyone help me to formalize this argument?","['complex-analysis', 'elementary-set-theory', 'geometry']"
2408185,"Find $A,B\in\Bbb K^{2\times 2}$ such that $AB\neq BA$ but $e^{A+B}=e^Ae^B$","Find $A,B\in\Bbb K^{2\times 2}$ such that $AB\neq BA$ but $e^{A+B}=e^Ae^B$. Hint: $e^{2k\pi i}=1$ for all $k\in\Bbb Z$. This is the exercise 10 in page 146 of Analysis II of Amann and Escher. I dont know exactly what to do here more than just try things blindly (trying to guess what is the hint about). I know that $$A:=\begin{bmatrix}a&b\\0&c\end{bmatrix}\implies e^A=\begin{cases}\begin{bmatrix}e^{a}&\frac{b}{c-a}(e^{c}-e^{a})\\0&e^{c}\end{bmatrix},& c\neq a\\\begin{bmatrix}e^{a}&be^{a}\\0&e^{a}\end{bmatrix},& c= a\end{cases}\tag1$$ $$A:=\begin{bmatrix}0&-\omega\\\omega&0\end{bmatrix}\implies e^{A}=\begin{bmatrix}\cos \omega&-\sin\omega \\\sin\omega &\cos\omega \end{bmatrix}\tag2$$ What I thought about the hint is setup some matrices as in $(1)$ such that $i(A+B)=i2\pi I$, by example $$A:=\begin{bmatrix}a&b\\0&c\end{bmatrix},\quad B:=\begin{bmatrix}2\pi-a&-b\\0&2\pi-c\end{bmatrix}\implies e^{i(A+B)}=I$$ However we have that $AB=BA$, then I must find other way. Some help will be appreciated, thank you.","['matrices', 'linear-algebra', 'analysis']"
2408195,Is this method of indefinite integration correct? $\int{ dx\over12+5\tan(x)}$,"I am integrating: $$ \int{ dx\over12+5\tan(x)} $$ I proposed $x = \arctan(u)$, replacing $dx$ by $du \over 1+u^2$, so  the integral becomes: $$ \int{du \over (1+u^2)(12+5u)} $$ Which can be integrated using partial fractions and then I eventually get that the anti-derivative is: $$ {5 \over 169} \ln |12+5u| - {5 \over 338}\ln|1+u^2| + {12 \over 169}\arctan (u) + C $$ And finally going back to the original variable substituting $u = \tan(x)$ So my question is if this method is correct?","['integration', 'trigonometric-integrals']"
2408224,Covariance and Variance,"Given two random variables $X$ and $Y$ , I wish to find $Cov(X + Y, X − Y )$ assuming that $(a)$ $X$ and $Y$ are independent and $(b)$ $X$ and $Y$ are dependent & $Var(X) = Var(Y )$ I started with $$Cov(X + Y, X − Y) = Cov(X, X-Y) + Cov(Y, X-Y) = Var(X)- Cov(X,Y) + Cov(Y,X)- Var(Y)$$ 
such that for $a)$ we have $Var(x) - Var (Y)$ and for $b)$ we have $0$. Just checking if my method is correct thanks!","['statistics', 'probability', 'variance', 'covariance']"
2408233,"If $a$ is a root of $x^2+ x + 1$, simplify $1 + a + a^2 +\dots+ a^{2017}.$","If $a$ is a root of $x^2 + x + 1$ simplify $$1 + a + a^2 + a^3 + \cdots + a^{2017}.$$ my solution initially starts with the idea that $1 + a + a^{2} = 0$ since $a$ is one of the root then using the idea i grouped $$1 + a + a^2 + a^3 + \cdots + a^{2017}$$ just like this $$(1 + a + a^{2}) + a^3(1 + a + a^2) + a^6(1 + a + a^2) + \cdots + a^{2013} + (1 + a + a^2) + a^{2016} + a^{2017}$$
which is equivalent to $$(0) + a^3(0) + a^6(0) + \cdots + a^{2013}(0) + a^{2016} + a^{2017}$$ and finally simplified into $$a^{2016} + a^{2017}$$. That's my first solution, but eventually I noticed that since $1 + a + a^2 = 0$ then it can be $a + a^2 = -1 $ using this idea I further simplified $$a^{2016} + a^{2017}$$ into $$a^{2015}(a + a^{2})$$ ==> $$a^{2015}(-1)$$ ==> $$-a^{2015}$$ But answers vary if I start the grouping at the end of the expression resulting to $1 + a$ another solution yields to $-a^{2017}$ if I set $1 + a = -a^2$ several solutions rise when the grouping is being made anywhere at the body of the expression... my question is, Is $$a^{2016} + a^{2017} = 1 + a = -a^{2015} = -a^{2017} \text{ etc.?}$$ How does it happen? I already forgot how to manipulate complex solutions maybe that's why I'm boggled with this question...any help?","['algebra-precalculus', 'roots', 'polynomials']"
2408333,Connectedness of Euclidean plane excluding the origin,"Let $X= \mathbb{R}^2 \setminus \{(0,0)\}$. It is obvious that $X$ is path-connected and thus it is connected. The definition of connectedness of a set $A$ is stated as follows: there is no pair of open sets $U_1$ and $U_2$ such that $A \subset U_1 \cup U_2$; $A \cap U_1 \neq \emptyset$, $A \cap U_2 \neq \emptyset$; and $U_1 \cap U_2 = \emptyset$. Then, my question is can we prove the connectedness of $X = \mathbb{R}^2 \setminus \{(0,0)\}$ directly by the definition given above?","['general-topology', 'real-analysis', 'connectedness']"
2408342,"Number of one-to-one functions between $\{0, 1\}$ and $\{1, 2, 3, ..., 9\}$","First off, these are kind of confusing me. I'm not entirely sure what the question is asking. Would someone be willing to explain what the question is asking? Count the total number of different one-to-one functions from the set $\{0, 1\}$ into the set $\{1, 2, 3, \ldots, 9\}$ My guess is that we are assigning numbers from the second set in place in the first set, so the first number in the first set could be $1$ to $9$ and same for the second, giving you $9 \cdot 9 = 9^2 = 81$. However, the term one-to-one leads me to believe that I'm counting more solutions than I should. Any help is appreciated. Thank you.","['combinatorics', 'functions']"
2408343,Examples of matrices that are both skew-symmetric and orthogonal,"Are there matrices that satisfy these two conditions? That is, a matrix $A$ such that $$A^T=A^{-1}=-A$$ What I know is that a skew-symmetric matrix with $n$ dimensions is singular when $n$ is odd.","['matrices', 'orthogonal-matrices', 'examples-counterexamples']"
2408418,Explain this proof of the 5-color theorem,"I recently read about planar graphs and some proofs related to it, in particular I came across the 5-color theorem (any planar graph can be colored in at most 5 colors). I had some trouble understanding the theory behind it (however, I get the 6-color theorem) and came across a proof with helpful images on the mathonline wiki. I assume the audience here on this site is quite familiar with the proof, so I post only excerpts. Once again, suppose we have a graph $G$ on $k$ vertices. We know that a connected planar simple graph $G$ contains a vertex of degree 5 or less. Suppose the $v$ has $deg(v)=5$ . If we delete this vertex and all edges incident with $v$ , then by our induction hypothesis the resulting graph has a good 5 colouring. Now we reinsert the vertex $v$ . Notice that a good 5-colouring cannot happen if vertex $v$ has neighbours all with different vertex colours since v would then need a 6th colour. We will prove that the neighbours of v cannot all be the same colour now with the following two cases. We will arbitrarily select the red and orange vertices for these cases without loss of generality. Ok that is basically almost the same as proofing the 6 color theorem. Now: CASE 1: If there no is red-orange alternating vertex path starting at the red vertex and ending at the orange vertex, then we can interchange the red vertex with an orange vertex and our proof is complete: Yup, that makes sense to me. We interchange the red and the orange vertex and color $G$ in 5 colors. CASE 2: If there is a red-orange alternating vertex path starting at the red vertex and ending at the orange vertex, then inspect the yellow and the green vertices. There cannot be an alternating yellow-green vertex path starting at yellow and ending at green since the red-orange path interrupts this path. Hence the yellow vertex can be interchanged green and the proof is once again complete. ( Source of text and images ) What confuses me is ""If there is a red-orange alternating vertex path starting at the red vertex and ending at the orange vertex … There cannot be an alternating yellow-green vertex path starting at yellow and ending at green …"" Why not? If there is a connection between the red and the orange one, then I can just draw an edge line like this and also connect green and yellow: And $G$ is still a valid planar graph (can be drawn without overlapping edges). Or what am I missing?","['graph-theory', 'planar-graphs', 'proof-explanation', 'coloring', 'discrete-mathematics']"
2408436,Does the Young's inequality $x^2+ y^2\geq 2xy$ hold for negatives $x$ or $y$?,"I have noticed in the literature that Young's inequality $x^2+ y^2\geq 2xy$ is mentioned considering non-negative $x$ and $y.$ But considering various cases, I have found that the inequality holds for negative non zero $x$ and $y.$ Does the Young's inequality hold for negatives $x$ or $y$ in general ? Case 1 : $x=-1, y=1\implies1+1\geq-1$ (Inequality holds). Case 2 : $x=1, y=-1\implies 1+1\geq-1$ (Inequality holds). Case 3 : $x=-1, y=-1\implies 1+1 \geq 1$ (Inequality holds)","['algebra-precalculus', 'inequality', 'exponential-function', 'solution-verification']"
2408447,Linear dependence of continuous (non-differentiable functions),"I have a set of n+1 functions $f_i:[0,1]\rightarrow R$, that I know are linearly dependent and I want to find the coefficients s.t. $\sum_i \alpha_i f_i=0$. There are however three problems: The fucntions are not differentiable (actually they are, but there's no way to find $f_i'$) Evaluating the functions comes along with some numerical noise. I do not have a closed analytical representation of the fucntions. Essentially the functions are obtained by measuring real nature data. Hence I can't use Wronskian and also can't just evaluate the fucntions at $n+1$ points and solve the linear equations, as the numerical errors arising from this will be to large. (Note that as I already have some numerical noise, the ""real"" coefficients $\alpha_i$ can not be found, but I want to find coefficients that do not have to much error in them).","['fourier-series', 'linear-transformations', 'functions']"
2408522,Solving a PDE geometrically,"Suppose I want to solve a 1st order linear PDE $$xu_x-yu_y=0,\qquad u(x,0)=f(x)$$ The solution obtained from Lagrange's equation is $u(x,y)=f(y/x)$ . Here the characteristics look like rectangular hyperbola. How do I look at this pde from the geometric viewpoint so that I can get an intuitive picture of the solution by inspection without actually solving the pde ?","['linear-pde', 'geometry']"
2408550,Number of real solutions of $f(f(x))$,"Given $f(x)=x^3-12x+3$, find number of real solutions of $f(f(x))=0$. My Try: Since $f(x)$ is having three real toots say $\alpha$, $\beta$ and $\gamma$, we have $$f(f(\alpha))=f(f(\beta))=f(f(\gamma)) =f(3).$$ Hence by Rolles theorem $\exists$ atleast one $c $ such that $f'(c)=0$ But how to count number of roots?","['functions', 'algebra-precalculus', 'maxima-minima', 'cubics', 'quadratics']"
2408563,Simple proof that Fourier transform is an isomorphism between $L^p$ spaces for $p \neq 2$?,"It is known that the Fourier transform $\mathcal F$ maps $L^2 \to L^2$ as an (isometric) isomorphism and $L^1 \to L^\infty$ as bounded operator. Via Riesz-Thorin this result can be extended to give that $\mathcal F$ also maps $L^p \to L^{p'}$ where $1 = \frac{1}{p} + \frac{1}{p'}$ as a bounded operator, i.e. the Hausdorff-Young equality holds:
$$
\|\mathcal F(u) \|_{p'} \leq \|u\|_p
$$
for all $u \in L^p(\mathbb{R}^n)$, $p \in (1,2)$. How do we know that the Fourier transform is only an isomorphism from $L^2 \to L^2$? One could argue that no $L^p$ space is isomorphic to an $L^q$ space for $p \neq q$ using the invariants type and cotype as suggested here but, considering that I only want to show that $\mathcal F$ is not an isomorphism from $L^p \to L^{p'}$, I suppose there is a more simple approach directly related to the Fourier transform . I am thinking of showing the fourier transform from $L^p \to L^{p'}$ is simply not surjective. Can you think of an easier approach to this problem?","['fourier-analysis', 'harmonic-analysis', 'vector-space-isomorphism', 'functional-analysis', 'fourier-transform']"
2408626,Example of $\arg\min\limits_{T: E(T(X))=\theta}\mathbb{E}|T(X) - \theta| \neq \arg\min\limits_{E(T(X))=\theta}\mathbb{E}(T(X) - \theta)^2$,"Suppose that $X_1, X_2, \dots, X_n$ is an i.i.d. sample distributed according to $F(x, \theta)$ distribution function, and we want to estimate $\theta$. Among all unbiased estimators, the best one is considered to be the one which has the minimum variance. But what if we want to minimize not variance, but absolute deviation, e.g. find such statistics $T(X)$ which has minimum $\mathbb{E}|T(X_1, X_2, \dots, X_n) - \theta|$, not $\mathbb{E}(T(X_1, X_2, \dots, X_n) - \theta)^2$? Can you provide examples of a distribution $F(x, \theta)$ and two unbiased estimators one of which has the least variance and another one – the least expected absolute deviation? I tried to consider normal distribution. It is known that both the sample mean and the sample median are unbiased estimators for the mean. But I'm not sure that the median has the least expected absolute deviation here. Any help, comments, hints and, especially, complete answers are very welcome and would be greatly appreciated!","['probability-theory', 'optimization', 'statistics', 'parameter-estimation']"
2408635,Is this map a homeomorphism onto its image?,"Let us consider the map $\phi: \, (-1,\infty) \times \mathbb{R} \to \mathbb{R}^3$ so defined:
$$
\phi(x,y)=\left(\frac{3x}{1+x^3},\frac{3x^2}{1+x^3},y\right).
$$
Is it a homeomorphism onto its image? I think no, since the map $\phi$ represents a surface in $\mathbb{R}^3$ whose shape is the similar to that of the Descartes' folium. For any $C^\infty$-map $\phi: U \to \mathbb{R}^3$ whose differential has rank 2, it can be showed that it is locally a homeomorphism onto its image. So, I considered an open like $V:=(-1,1) \times (-1,1)$. What can I say of its image? Is it open? If no, I proved that $\phi$ it is not a homeomorphism onto its image, but I can't see which is the image of $V$. Can you help me, please?","['general-topology', 'differential-geometry', 'surfaces']"
2408641,Show this a tempered distribution,"I want to show that $f(x) : = e^{ie^x}$ is a tempered distribution. Therefore I need to show that for all $\varphi \in \mathscr{S}(\mathbb{R})$, that $$\int_{\mathbb{R}} \varphi(x) e^{ie^x}dx < \infty.$$ Equivalently, I could show that $$\int_{\mathbb{R}} \varphi(x) \mathcal{F}(e^{ie^x})dx < \infty,$$ where $\mathcal{F}$ denotes the Fourier transform. I have had no luck with this as of yet.","['functional-analysis', 'harmonic-analysis', 'fourier-analysis', 'dual-spaces']"
2408705,"Is $(\mathbb{N\times N\times N}, \leq_{lex})$ isomorphic to $(\mathbb{N\times N}, \leq_{lex})$?","Is $(\mathbb{N\times N\times N}, \leq_{lex})$ isomorphic to $(\mathbb{N \times N}, \leq_{lex})$? Prove it. $\leq_{lex}$ - lexicographical order I think that $(\mathbb{N\times N\times N}, \leq_{\text{lex}})$ is isomorphic to $(\mathbb{N\times N}, \leq_{\text{lex}})$. 
I defined function $f(l,m,n)=l, \frac{(m+n)(m+n+1)}{2}+m$. I want to show that if $l_1, m_1, n_1 \leq l_2, m_2, n_2$, then $f(l_1, m_1, n_1) \leq f(l_2, m_2, n_2)$, and in this case that is always true (should I show it somehow or is it enough just to state it?). Can you tell me if my reasoning is correct? If not, where am I making the mistake?","['order-theory', 'elementary-set-theory']"
2408775,Number of squares and rectangles in a grid with a corner removed,"I wish to find the number of squares and rectangles in an $8\times9$ checkered grid with two squares removed from the top right. I was able to find the total number of squares and the rectangles in the grid without the removal of the two squares. Since $n=9,m=8$, therefore $n-m=1$. number of squares = $\sum_{r=1}^8 (r+r^2) = \frac{8(8+1)}{2}+\frac{8(8+1)[2(8)+1]}{6}$=240 number of rectangles = $\frac {(9)(9+1)(8)(8+1)}{4}$ = 1620 The grid in question: Edit: The above calculations were derived as such: number of squares in an m*n grid, where $m\le n$, $=\sum _{r=1}^m r(n-m+r)\\=\sum _{r=1}^m (n-m)r+r^2\\=(n-m)\sum _{r=1}^m r+\sum _{r=1}^mr^2\\=\frac {1}{2}m(m+1)+\frac {1}{6}m(m+1)(2m+1)$ number of rectangles in an $m\times n$ grid, where $m\le n$, $={m+1 \choose 2}{n+1 \choose 2}\\=\frac{1}{2}(m)(m+1)\times\frac{1}{2}(n)(n+1)\\=\frac {1}{4}(m)(m+1)(n)(n+1)$ Please excuse me for the poor formatting. I'd be very grateful if someone could guide me on the formatting.",['combinatorics']
2408778,How is the remaining number in this case an odd number?,"My question goes like this. Write the numbers $1,\ 2,\ 3,\dots,\ 2n$ on a paper, where $n$ is an odd number.
Name this list as $l_{2n}$ where $2n$ represents the number of terms in the list. Now choose any two numbers $j$ and $k$ at random from this list. Calculate $\vert j - k\vert$, then remove the numbers $j$ and $k$ from the list and add the number $\vert j-k\vert$ in the list. So we get a new list $l_{2n-1}$ with $2n-1$ terms. For example, if $n=7$, we write the numbers
$$1,\ 2,\ 3,\ 4,\ 5,\ 6,\ 7,\ 8,\ 9,\ 10,\ 11,\ 12,\ 13,\ 14$$
Now, we choose two numbers at random, say $6$ and $11$. Now, $\vert6-11\vert=5$. So we remove $6$ and $11$ from the list and add $5$ in it (despite the fact that there is already a $5$). So the new list (with one less number of terms than the previous list) is
$$1,\ 2,\ 3,\ 4,\ 5,\ 7,\ 8,\ 9,\ 10,\ 12,\ 13,\ 14,\ 5$$ Now the problem is to prove that given an odd number $n$ and the starting list $1,\ 2,\ 3,\dots,\ 2n$, if we go on doing the above procedure iteratively on each new list, we always reach an odd number i.e. $l_1$ contains just one term which is always an odd number. Now by studying proof theory, I have concluded that this theorem can be proved by contradiction. I can suppose that the value of $l_1$ is an even number and then backtrack to reach a contradiction to the hypothesis. But I don't know how to do it. Should I keep track of the parities of each number removed or added to the list (which is a difficult thing) or should I just stick to the parity of the end result (which I know is odd but can't prove it). Please help me to do the proof.","['parity', 'proof-writing', 'discrete-mathematics']"
2408795,The first fundamental form is enough to determine the geometry of a hypersurface?,"Question: As we know, For two dimensional surfaces there are many examples for which their first fundamental forms are the same, but their second fundamental forms are not. However, it seems that for hypersurfaces (dimension $\ge 3$) their first fundamental forms are enough to determine the geometry of the hypersurfaces completely, provided that $Rank(L) \ge 3$, where $L$ is the shape operator. I want to know whether this is true or not. If the answer is yes, why? Definitions: The first fundamental form $I$ of a surface element is just the restriction of the Euclidean inner product in $\mathbb R^n$ to all tangent hyperplanes $T_uf$, i.e., $$I(X,Y):=\langle X,Y \rangle$$
for any two tangent vectors $X,Y \in T_uf$ or for vectors $X,Y \in \mathbb R^n$ which are tangent to the surface element$.^1$ Shape operator of a surface is the minus derivative of the unit normal vectors on the surface. Formally speaking, let $f:U \to \mathbb {R}^3$ be a surface element with unit normal vector map $\nu$, $\nu: U \to S^2$ is defined by $$\nu (u_1,u_2):=\frac{\frac{\partial f}{\partial u_1} \times \frac{\partial f}{\partial u_2}}{\left \Vert \frac{\partial f}{\partial u_1} \times \frac{\partial f}{\partial u_2} \right \Vert},$$ then for every $u\in U$ we have the linear map $$D\nu|_u:T_uU \to T_uf,$$
where $T_uU=\{u\} \times \mathbb R^2$ and $T_uf=Df|_u\left(T_uU\right)$, and $$Df|_u:T_uU \to T_uf$$
is a linear isomorphism. Then the shape operator $L:=-D\nu \circ (Df)^{-1}$ is defined pointwise by $$L_u:=-\left(D\nu|_u \right) \circ \left(Df|_u\right)^{-1}:T_uf \to T_uf\,.^2$$
The above definition can be easily generalized to the general $\mathbb R^n$ space. Let $f:U \to \mathbb R^3$ be given. Then for tangent vectors $X$ and $Y$, one defines: the second fundamental form $I\!I$ of $f$ by $$I\!I(X,Y):=I(LX,Y),$$
where $L$ is the shape operator$.^3$ The above definition can be easily generalized to the general $\mathbb R^n$ space. [1], [2], [3] Wolfgang Kühnel, ""Differential Geometry Curves-Surfaces-Manifolds"", Second Edition, American Mathematical Society, 2006.","['curvature', 'geometry', 'manifolds', 'differential-geometry', 'linear-algebra']"
2408804,2D Divergence Theorem: Question on the integral over the boundary curve,"Let $\;F=(F_1,F_2)\;$ be a two-dimensional vector field and
  consider the rectangle $\;\mathcal R= PQRS\;$: If $\;\vec v\;$ is a function which gives outward-facing unit normal
  vectors to $\;\partial \mathcal R\;$(=boundary of $\;\mathcal R\;$),
  then by divergence theorem one can get: $\;\int_{\mathcal R} div(F_1,F_2) \;dx=\int_{SR} F_2\;dx_1
 -\int_{PQ} F_2\;dx_1-\int_{SP} F_1\;dx_2+\int_{QR} F_1\;dx_2\;$ My Attempt: Searching on google, I found this: So, in my case it holds: $\;\int_{\mathcal R} div(F_1,F_2) \;dx=\;\int_{\partial \mathcal R} F_2 dx_1 - F_1 dx_2\;(1)$ In addition, $\;\partial \mathcal R=(SR)\cup(RQ)\cup(QP)\cup(PS)\;(2)$ Now, combining $\;(1),(2)\;$ and considering the counterclockwise direction , I get: $\;\int_{\partial \mathcal R} -F_2 dx_1 + F_1 dx_2=-\int_{SR} F_2 dx_1+\int_{PQ} F_2 dx_1-\int_{QR} F_2 dx_1+\int_{PS} F_2 dx_1+\int_{SR} F_1 dx_2-\int_{PQ} F_1 dx_2+\int_{QR} F_1 dx_2-\int_{PS} F_1 dx_2\;$ At this point, I've been stuck. Not only I find some additional terms such as $\;\int_{QR} F_2 dx_1\;$, but also some of the signs are wrong. I haven't seen boundary integrals since a very long time, so I'm $\;100\;$% sure there's something I'm missing here! Any help would be valuable. Thanks in advance!","['line-integrals', 'greens-theorem', 'multivariable-calculus', 'integration', 'divergence-operator']"
2408813,"Does there exist any space with $S^n$ as a covering space, that addmits immersion in $\mathbb{R}^{n+1}$?","Intuitively, it seems the only space covered by $S^n$ that admits immersion into $\mathbb{R}^{n+1}$ is itself. A necessary condition is that the product of the tangent bundle with $\mathbb{R}$ be parallelizable. Is there a rigorous proof of the general case? (or a counter-example) .","['algebraic-topology', 'characteristic-classes', 'differential-topology', 'geometry']"
2408816,"What is the closure of $(0,1)$ in $\mathbb{R}_k$?","BACKGROUND Let
$$K := \left\{\frac{1}{n} \mid n \in \mathbb{Z}_{+}\right\} = \left\{\frac{1}{1}, \frac{1}{2}, \frac{1}{3}, \ldots\right\},$$
where $\mathbb{Z}_{+}$ is the set of all positive integers. Let
$$\mathscr{B}_k = \left\{(a,b) \subseteq \mathbb{R} \mid a, b \in \mathbb{R}, a < b\right\} \cup \left\{(c,d)-K \mid c, d \in \mathbb{N}, c < d\right\}.$$ Then $\mathscr{B}_k$ is a basis for a topology on $\mathbb{R}$, and this is called the $K$-topology on $\mathbb{R}$ and is denoted as $\mathbb{R}_k$. Now, a subset $C$ of the topological space $X$ is said to be closed if $X - C$ is open.  The closure of a set $A$ is the smallest closed set containing A. QUESTION What is the closure of $(0,1)$ in $\mathbb{R}_k$? ATTEMPT This would have been easy if the $K$-topology $\mathbb{R}_k$ is coarser than the standard topology $\mathbb{R}_s$.  However, we know that $\mathbb{R}_s \subset \mathbb{R}_k$. Hence, I am unsure if the closure $\overline{(0,1)}$ of $(0,1)$ in $\mathbb{R}_k$ is still $[0,1]$ as it is in $\mathbb{R}_s$. Any help will be appreciated.",['general-topology']
2408839,How to find $\lim_{n\to\infty}\int_0^1 n\ln(1+{1\over n\sqrt x})\ dx$?,"Find $$\lim_{n\to\infty}\int_0^1 n\ln(1+{1\over n\sqrt x})\ dx$$ Can I apply monotonic convergence theorem? My work is that
$$\int_0^1\lim_{n\to\infty}nln(1+{1\over n\sqrt x})dx$$
$$\int_0^1\lim_{n\to\infty}n\int_1^{1+{1\over n\sqrt x}}1/ydy$$
Let $$y=1+{1\over n\sqrt t}$$
then dy=1/n(-t^(-3/2))dt $$\int_0^1\lim_{n\to\infty}\int_0^x{1\over 1+{1\over n\sqrt t}}(-1){1\over2}t^{-3/2}dt$$
Apply monotonic theorem $$\int_0^1x^{-1/2}dx=2$$","['real-analysis', 'measure-theory']"
2408850,"How to prove that $1+2=3, 4+5+6=7+8,... $ ad infinitum?","Given this set of equations: $$
1+2=3\\
4+5+6=7+8\\
9+10+11+12=13+14+15\\
\ldots
$$ How can I prove that this is true for all continuations of this sequence? I would put it in the form of: $$
(k,m)\in \{n^2,n|\in\Bbb N\}\\
\sum_{i=k}^{k+m} i=\sum_{i=k+m+1}^{k+2m}i
$$ However, I have problems in formulating and solving the inductions step, which I think should be to go from $n$ to $n+1$","['summation', 'sequences-and-series']"
2408895,Closed-form formula for the differential equation $D^{(n)}(f)=f$,"Let $n$ be a positive integer and $S_n$ be the set of all functions from $\mathbb{R}$ to $\mathbb{R}$ whose $n$th derivative is defined everywhere. In terms of the parameter $n$ and arbitrary real constants, is there a closed-form formula for the differential equation $D^{(n)}(f)=f$, where $D$ is the differentiation operator? Also, what if we consider functions from $\mathbb{C}$ to $\mathbb{C}$?",['ordinary-differential-equations']
2408924,Well-definedness of Lebesgue-Integral for non-negative measurable functions,"Setup: Let $(M, \mathscr A, \mu)$ be a measure space. $u$ is a non-negative simple function if there exist non-negative real numbers $\alpha_1,\ldots,\alpha_p$ and measurable sets $A_1,\ldots,A_p$ such that $u=\sum_{i=1}^p \alpha_i 1_{A_i}$. The integral of a non-negative simple function $u$ is $\int u\, d\mu = \sum_{i=1}^p \alpha_i \mu(A_i)$. My question is about the definition of the integral for non-negative measurable functions. My professor defines it like this: Let $f: M \rightarrow [0,\infty]$ be an $\mathscr A$ measurable function and $(u_n)$ an increasing sequence of non-negative simple functions which converges pointwise to $f$: $u_n \uparrow f$. Then the integral of $f$ is defined by
$$\int f \, d\mu = \lim_{n\rightarrow \infty} \int u_n \, d\mu$$ Question: My professor remarks that the last definition is independent of the choice of the sequence of simple functions $(u_n)$ with $u_n \uparrow f$. How can I verify this? Here's what I tried: Let $(u_n)$ and $(v_n)$ be two sequences of non-negative simple functions with $u_n \uparrow f$ and $v_n \uparrow f$. Since $u_1 \leq u_2 \leq,\ldots$ and $v_1 \leq v_2 \leq,\ldots$, $\int u_n \, d\mu$ and $\int v_n \, d\mu$ are increasing sequences. Therefore the limits of both sequences exist (possibly infinite) and it suffices to show that $\forall m \in \mathbb{N} \, \forall \gamma \in (0,1)$: $$\lim_{n\rightarrow \infty} \int u_n \, d\mu \geq \gamma \int v_m \, d\mu$$ Let $m \in \mathbb N, \gamma \in (0,1)$ and $x \in M$. Since $u_n(x)$ converges to $f(x)$ from below and $\gamma v_n(x)$ converges to $\gamma f(x)$ from below there exists $N \in \mathbb N$ such that $\forall n>N$: 
$$u_n(x) \geq \gamma v_m(x)$$ But now I'm stuck. I want to conclude that $\int u_n \, d\mu \geq \gamma \int v_m \, d\mu$, but I can't do that because my $n$ from the equation in previous line depends on the point $x$, so that I cannot be sure to find a finite $n$ such that $u_n(x) \geq \gamma v_m(x)$ holds for all $x \in M$! Can my attempt be salvaged or is there a better strategy to prove my professor's remark? Thank you!","['real-analysis', 'lebesgue-integral', 'measure-theory']"
2408930,Prove that a function $g$ has no roots,"I saw this link and had a problem with the first proof on the accepted answer, namely:
$\newcommand{\R}{\mathbb{R}}$ $\newcommand{\raw}{\rightarrow}$ $\newcommand{\N}{\mathbb{N}}$ $\newcommand{\Q}{\mathbb{Q}}$ $\newcommand{\Raw}{\Rightarrow}$ Suppose that $f:\R\raw\R$ and define a function $g:\R\raw\R$ by $g(x)=1/f(x)$. Prove that $g$ has no roots. I found this hard to make sense of. For certain functions, for example $f(x) = x^2$ it is obvious that $1/f(x)$ will have no roots, however I became confused when considering the case $f(x) = 1/x^2$, because then $g(x) = x^2$ which has a repeating root at $(0,0)$. Can anyone explain to me where I am making a mistake?","['algebra-precalculus', 'functions']"
2408945,Show that $\lim_{h\to0} \frac{g(a+h)-2g(a)+g(a-h)}{h^2} = g''(a)$,"Let $g\colon\mathbb{R}\to\mathbb{R}$ be a function of class $C^2$. Show that
$$\lim_{h\to0} \frac{g(a+h)-2g(a)+g(a-h)}{h^2} = g''(a)$$ we cannot pass the limit inside. How to proceed with the problem?","['derivatives', 'real-analysis', 'limits']"
