question_id,title,body,tags
1272081,Why is it that no bipartite graphs contain a triangle?,I know it has something to do with the vertices belonging to two differnt sets without intersection but I'm not exactly sure of a concrete explanation. Thanks in advance.,"['graph-theory', 'discrete-mathematics']"
1272082,Prove that totally bounded metric space is separable,"I'm reading the proof that says every totally bounded metric space is separable. The proof goes like this: Let $n$ be a positive integer. Then there exists $x_{n1},...x_{nm}$ such that the open balls with centers at $x_{nj}$ and radii $\frac{1}{n}$ cover $X$. The family of all these points is then a countable subset of $X$. Moreover, for each $x\in X$ and each integer $n$, there is an $x_{nj}$ such that $d(x,x_{nj})<\frac{1}{n}$. Consequently, these points are dense in $X$. I get the picture of this proof. Basically it's saying that, take any point $x\in X$. No matter how small $\epsilon>0$ is, we can always use balls with radius $\epsilon$ to cover the whole space, so consequently $x$ has to be within $\epsilon$ from some point. But aren't we supposed to first construct a set, then argue that the set would be dense no matter what $\epsilon$ we choose? I feel like in this proof, we first pick $\epsilon$ and then construct a set.","['separable-spaces', 'metric-spaces', 'general-topology']"
1272083,One tailed or two tailed,"Ok so this the question: An administrator at a medium-sized hospital tells the board of directors that, among patients received at the Emergency room and eventually admitted to a ward, the average length of time between arriving at Emergency and being admitted to the ward is 4 hours and 15 minutes. One of the board members believes this figure is an underestimate and checks the records for a sample of 25 patients. The sample mean is 6 hours and 30 minutes. Assuming that the population standard deviation is 3 hours, and that the length of time spent in Emergency is normally distributed, use the sample data to determine whether there is sufficient evidence at the 5% level of significance to assert that the administrator's claim is an underestimate. The first scenario is that that for the null hypothesis the mean is equals to 4hrs 15mins. For the alternative hypothesis the mean is not equals to 4hrs 15mins. So it could be less or more. However the question says that one the board memeber thinks that it might be an UNDERESTIMATE so that means the alternative hypothesis must be higher than 4hrs 15 mins? Right? So that opens the possibility to a another scenario which is: In the null hypothesis the mean is equals to or less than 4hrs 15mins. And in the alternative hypothesis the mean is greater than 4hrs 15mins. So the first scenario is a two tailed test and the second scenario is one tailed test. The question asks me whether it is a one tailed test or two tailed, and there is only one correct answer. But I am not sure which one is correct. From my perspective both make sense. If someone could give me the correct answer and explain it to me it would help me out a lot.",['statistics']
1272105,Separable Solutions vs Integrating Factors,"I am looking to better understand the key differences between these two methods of solving ODEs. I know they are very different, but I will give an example to show what I am a bit confused about. For example, in one of my previous problems I had $$\frac{dQ}{dt}=3-0.7Q$$ Now, when I first saw this, It appeared to be linear to me. I thought maybe the best way to solve it would be to rewrite it as $$\frac{dQ}{dt}+0.7Q=3$$ and then use the 0.7 to solve for the integrating factor. However, I was told that the correct answer is to look for separable solutions. Which I also understand how to do. But I am just a bit worried that I will try to solve something by using integrating factors when separation of variables should be used. Is this the case? How can I know? Thank you all!",['ordinary-differential-equations']
1272206,Probability that hand contains Ace and King of at least one suit?,"Compute the probability that a hand of 13 cards (drawn
randomly from a standard deck of 52) contains both the ace and the
king from at least one suit. I think I would use the inclusion exclusion principle here, but I'm not sure how to start. Would it be something like: P(Ace+King of suit 1) + P(Ace+King of suit 2) + P(Ace+King of suit 3) + P(Ace+King of suit 4) - ... so on.?","['probability', 'statistics', 'card-games']"
1272221,Prove that if $a \mid n$ then $a^2\mid (n + 1)(n − 1) + 1$,"I have this review question for an exam and I was hoping someone can help me solve it: Prove that if $a \mid   n$ then $a^2\mid  (n + 1)(n − 1) + 1$ this is what I have so far, not sure if it is right: $a^2\mid  (n + 1)(n − 1) + 1$ $=(n+1)(n-1)+1$ $=n^2-n+n-1+1$ $=n^2$","['discrete-mathematics', 'divisibility', 'elementary-number-theory']"
1272242,Ideal sheaf of intersection of two surfaces in $\mathbb P^3$,"Let X be an intersection of 2 surfaces of degree $d_1,d_2$ in $\mathbb P^3$. Is it true that there is a short exact sequence
$$
0\to\mathcal{O}_{\mathbb{P}^3}(-d_1-d_2)\to\mathcal{O}_{\mathbb{P}^3}(-d_1)\oplus\mathcal{O}_{\mathbb{P}^3}(-d_2)\to\mathcal{I}_X\to0,
$$
where $\mathcal{I}_X$ is ideal sheaf of $X$. And if it is true, how it could be proven?","['intersection-theory', 'algebraic-geometry', 'sheaf-theory']"
1272254,What did i do wrong with this derivation?,"$$
\cos(x) = \sum_{n=0}^\infty \frac{(-1)^n x^{2n}}{(2n)!}
$$
Therefore
\begin{align}
\frac{1}{\cos(x)} &= \frac{1}{1-(\frac{x^2}{2} - \frac{x^4}{4!} + \frac{x^6}{6!} - \cdots)}
\\
&= \sum_{n=0}^\infty (\frac{x^2}{2} - \frac{x^4}{4!} + \frac{x^6}{6!} - \cdots)^n
\\
&= \sum_{n=0}^\infty (1-\cos(x))^n
\end{align} This part i am okay with, but now i will attempt to find a power series of $\tan(x)$ in terms of $\cos(x)$ with the following reasoning: I realised that by differentiating The secant function i would get $\sec(x) \tan(x)$ and by differentiating the series would also yield a $\sin(x)$, therefore i would end up with $\sec^2(x)$ (which is the derivative of $\tan(x)$) therefore by integration i would find myself a power series for $\tan(x)$ in terms of $\cos(x)$ I will do as i explained below: $$
\frac{d}{dx}[\sec(x)] = \sum_{n=0}^\infty \frac{d}{dx}(1-\cos(x))^n
$$ $$
\frac{\sin(x)}{\cos^2(x)} = \sin(x) \sum_{n=0}^\infty (n+1) (1-\cos(x))^n
$$ $$
\frac{1}{\cos^2(x)} = \sum_{n=0}^\infty (n+1) (1-\cos(x))^n
$$ Now to redefine $(1-\cos(x))^n$ by using the following identity: $$
(1+x)^{\alpha} = \sum_{k=0}^\alpha {\alpha \choose k} x^k
$$ Therefore: $$
(1-\cos(x))^n = \sum_{k=0}^n {n \choose k}(-\cos(x))^k
$$ Now this is where i run into some doubt: $$
\sec^2(x) = \sum_{n=0}^\infty (n+1) \sum_{k=0}^n {n \choose k}(-\cos(x))^k
$$
Since the following is true for ordinary power series:
$$
fg \longleftrightarrow \left\{\sum_k a_k b_{n-k} \right\}
$$ Therefore by setting $a_k = \frac{(-\cos(x))^k}{k!}$ and $b_{n-k} = \frac{1}{(n-k)!}$ $$
\sum_{n=0}^\infty (n+1) \sum_{k=0}^n {n \choose k}(-\cos(x))^k = \sum_{n=0}^\infty (n+1)! e^{1-\cos(x)}
$$ This is clearly wrong obviously as the series does not converge... What was my error?","['power-series', 'calculus', 'generating-functions', 'trigonometry', 'derivatives']"
1272255,Proving a Certain Planar Measure Is Zero on Horizontal Lines,"Question: Suppose $\mu$ is a measure on $\mathbb{R}^{2}$ with respect to which all open squares are measurable. Suppose $\mu$ has the following
  property: there exists a constant $\alpha\geq 1$ such that if $Q$ and $Q'$ are
  any two open squares which are translates of one another and $\overline{Q}\cap\overline{Q}'\neq\emptyset$, then $$\mu(\overline{Q})\leq\alpha\mu(Q'),$$ where $\overline{Q}$ denotes the closure of $Q$. Then horizontal lines have zero measure with respect $\mu$. This is an old qual problem which I cannot solve. I know that by continuity of measure, it suffices to show that any horizontal line segment has $\mu$-measure zero. I tried imitating the proof that line segments have Lebesgue measure zero, but that approach quickly failed.","['real-analysis', 'geometric-measure-theory', 'measure-theory']"
1272266,Find kernel generators for ring maps,"This is the textbook question: Q: Find generators for the kernels of the following maps: $\mathbb{R}[x,y] \to \mathbb{R}$ defined by $f(x,y) \rightsquigarrow f(0,0)$ $\mathbb{R}[x] \to \mathbb{C}$ defined by $f(x) \rightsquigarrow f(2+ i)$ $\mathbb{Z}[x] \to \mathbb{R}$ defined by $f(x) \rightsquigarrow f(1+\sqrt{2})$ $\mathbb{Z}[x] \to \mathbb{C}$ defined by $x \rightsquigarrow \sqrt{2}+\sqrt{3}$ $\mathbb{C}[x,y,z] \to \mathbb{C}[t]$ defined by $x \rightsquigarrow t, y \rightsquigarrow t^2, z \rightsquigarrow t^3$ My work on the first three: Any polynomial that satisfies $f(0,0)=0$ will be in the kernel. Intuitively, the two polynomials $f(x,y)=x$ and $f(x,y)=y$ should generate this. How can I prove that? The kernel will have root $(2+i)$ and the conjugate $(2-i)$ which multiply to $(x-(2+i))(x-(2-i)) = x^2-4x+5$. The coefficients are real and the polynomial is irreducible in $\mathbb{R}$. That polynomial is clearly in the kernel. How can I show that it generates the kernel? I find polynomial $f(x) = x^2-2x-1$ that is in the kernel and is irreducible in $\mathbb{Z}$. How can I show that it generates the kernel?","['abstract-algebra', 'ring-theory']"
1272299,residue of a contour integral with a branch point on the boundary,"I am considering a problem where I would like to find the contour integral given by \begin{align}
\oint_C f(z) dz
\end{align} where $f = u+iv$. $C$ is the wedge shaped contour where $0 \leq r \leq 1$ and $0 \leq \theta \leq \pi/3$. $u$ and $v$ are functions of $\theta$ only. From my understanding, $f$ is multivalued at $z = 0$ and is considered a branch point type singularity. I would like to know how I can compute this contour integral as the branch point lies on the boundary of the contour. I understand that if this was not a branch point, I could compute the infinitesmal arc around the singularity with \begin{align}
\lim_{\epsilon \rightarrow 0}\oint_{C_\epsilon}f(z) dz = -i\phi Res
\end{align} where $\phi$ is the wedge angle ($\pi/3$ in this case). Is there a similar equation for the integral of an infinitesmal arc around a branch point?","['branch-points', 'multivalued-functions', 'complex-analysis', 'residue-calculus']"
1272323,Express unit sphere as countable union of great circles?,"Let $S = \{x\in \mathbb{R^3} | d(x,(0,0,0))=1\}.$   Is it possible that $S$ is a countable union of “great circles”? A great circle is the intersection of $S$ with a plane through $(0,0,0)$. What I know is that the sphere is closed and bounded, so it is compact, so given any open cover there is a subcover. But great circles are closed, so probably it's not gonna work out. Then I thought of using contradiction. But each great circles are uncountable. Countably union of uncountable set is still uncountable. Any hint?","['metric-spaces', 'general-topology']"
1272326,Find the function of separation between two functions,"I seriously doubt that is what it is actually called, but I'm not very knowledgeable in this matter. Conceptually, what I am trying to do is calculate the function of a line/curve that shows the divide between two other functions. As a visual example: $$Red: f(x) = x^2 + 2$$
$$Blue: g(x) = -(x-3)^2$$ The orange curve would be some function $h(x)$, where all points on one side of the function would be nearest $f(x)$ and all points on the other side would be nearest $g(x)$. I would like to find a way to figure out what $h(x)$ is. I'm sure something like this already exists, but I don't even know what to google to find out. I'd also like to mention that I'm looking for a general solution, not something specific to quadratic functions. Thanks in advance.",['functions']
1272331,Can a multiply-periodic complex function be analytic?,"It's possible to construct complex periodic functions with two periods in different directions, such as $f(z) = \cos x + i \sin 2y$.  That has periods $2\pi$ and $\pi i$.  It's also not analytic. It's been a long time since complex variables, and that was self-study, so I'm very likely under-thinking this, but...Is there any analytic function with two linearly-independent periods? I don't consider constant functions as properly periodic, since there's no minimum period...but I'm not sure if that attitude is mainstream.","['periodic-functions', 'complex-analysis']"
1272333,Random walk of geometric random variables,I was wondering if there's a more advanced theory that can fit with the following context: Let $\tau_{n} = \sum_{i=1}^{n}{T_{i}}$ be a sum of iid geometric random variables with parameter $p$ and for every positive real $t$ let $\tau(t)$ be the largest index $n$ such that $\tau_{n} \leq t$. What can we say about $E[\tau(t)]$?,['probability-theory']
1272399,When is shear useful?,"I'd never heard of the shear of a vector field until reading this article . Shear is the symmetric, tracefree part of the gradient of a vector field. If you were to decompose the gradient of a vector field into antisymmetric ($\propto$ curl), symmetric tracefree (shear), and tracefull(?) ($\propto$ divergence) parts you'd get that it has components: $$\frac {\partial A_i}{\partial x^j} = \sigma(A)_{ij} - \frac 12 \epsilon_{ijk}(\nabla \times A)_k + \frac 13 \delta_{ij} (\nabla \cdot A)$$ where $\sigma(A)$ is the shear and is defined as $$\sigma(A)_{ij} = \frac 12 \left(\dfrac {\partial A_i}{\partial x^j} + \frac {\partial A_j}{\partial x^i}\right) - \frac 13 \delta_{ij} (\nabla \cdot A)$$ Is the shear of a vector field only useful in fluid mechanics?  Does it have any use in pure mathematics -- perhaps analysis or differential geometry?  If so, does anyone have a reference?","['fluid-dynamics', 'reference-request', 'multivariable-calculus', 'tensors']"
1272402,How do I solve this improper integral: $\int_{-\infty}^\infty e^{-x^2-x}dx$?,"I'm trying to solve this integral:
$$\int_{-\infty}^\infty e^{-x^2-x}dx$$
WolframAlpha shows this to be approximately $2.27588$. I tried to solve this by integration by parts, but I just couldn't get there. I'd be glad if someone could show me how to do it. I've included my attempt at the problem below: Note $\int_{-\infty}^\infty e^{-x^2-x} = \int_{-\infty}^\infty e^{-x^2}e^{-x}dx$. Then we can integrate by parts. Let $u(x) = e^{-x^2}$. Then $u'(x) = -2xe^{-x}$. Let $v'(x) = e^{-x}$. Then $v(x) = -e^{-x}$. Then $u(x)v'(x) = u(x)v(x) - \int v(x)u'(x)dx$, i.e.
$$\int_{-\infty}^\infty e^{-x^2}e^{-x}dx = -e^{-x^2}e^{-x} - \int e^{-x}2xe^{-x}dx = -e^{-x^2-x} - 2\int e^{-2x}xdx$$ Then we integrate $\int e^{-2x}xdx$ by parts. We pick $u(x) = x$, $u'(x) = dx$, $v'(x) = e^{-2x}$, and $v(x) = \int e^{-2x} dx = \frac {-1}{2} e^{-2x}$ by u-substitution. Skipping some steps, it follows that 
$$\int e^{-2x}xdx = -\frac{1}{4}(e^{-2x})(2x+1)$$
Then 
$$ -e^{-x^2-x} - 2\int e^{-2x}xdx = -e^{-x^2-x} + \frac{1}{2}(e^{-2x})(2x+1)$$
Which, when evaluated numerically, doesn't yield the desired result. So there's a problem here. Maybe someone else knows how to do this.","['improper-integrals', 'calculus', 'definite-integrals', 'integration']"
1272404,Points of intersection of $\sin x$ and $\cos x$,"I'm trying to find the points of intersection of $\sin x$ and $\cos x$ between $0$ and $2\pi$. I've tried but I keep getting 4 solutions... Would someone please be able to take me through the process? I squared $\sin x$ and $\cos x$ and then got $\sin x = \frac{\pm 1}{\sqrt{2}}$
which gave the solutions $\pi\over 4$, $3\pi \over 4$, $5\pi \over 4$ and $7\pi\over 4$.",['trigonometry']
1272448,Prove every subset of $\Bbb N$ is countable.,"This isn't a homework problem.  I've seen a proof of the following statement online, and I think the proof is suspect, or at least incomplete. Theorem .  Every subset of $\Bbb N$ is countable. Proof .  Let $A \subseteq N$ .  Suppose without loss of generality $A$ is not finite.  Since $\Bbb N$ is well-ordered, $A$ has a least element $a_{1}$ .  Since $A$ is infinite, $A - \{a_{1}\} \neq \emptyset$ , and again by the well-ordering of $\Bbb N$ , there is a least element $a_{2} \in A - \{a_{1} \}$ . Proceeding inductively, for each $k \in \Bbb N$ , we can find $a_{k} \in A - \{a_{1}, a_{2}, \dots, a_{k - 1} \}$ with $a_{1} < a_{2} < \dots < a_{k}$ . Then $A = \{a_{1}, a_{2}, \dots \}$ , and so $A$ is countable, as desired. I don't think this proof is complete.  It should be shown that $A \subseteq \{a_{1}, a_{2}, \dots \}$ , right?  I don't think this is obvious because pretend we have a different ordering on $\Bbb N$ , i.e., the following ordering: $$1 < 3 <5 < \dots < 2 < 4 < 6 < \dots$$ Then if $A = \{1, 2, 3, \dots \}$ , using the above procedure, we would only get the odd numbers, so we wouldn't be able to say $A \subseteq \{1, 3, 5, \dots \}$ .  Does my objection to the proof of the theorem make sense?  How do you complete the proof (i.e., how do you show the containment I want to show)?","['elementary-set-theory', 'real-analysis']"
1272452,"Show that for every prime $p$, there is an integer $n$ such that $2^{n}+3^{n}+6^{n}-1$ is divisible by $p$.","So the problem states: Show that for every prime $p$, there is an integer $n$ such that $2^{n}+3^{n}+6^{n}-1$ is divisible by $p$. I was thinking about trying to prove this using the corollary to Fermat's Little Theorem, that for every prime $p$,  $a^{n-1}\equiv 1 \pmod {p}$, but I can't think about how to go about doing that. Any help would be greatly appreciated!","['congruences', 'prime-numbers', 'number-theory', 'modular-arithmetic', 'elementary-number-theory']"
1272475,Regarding the connected component of $|1/J| < 1$ containing $\infty$,"How does one explicitly describe the connected component of $|1/J| < 1$ containing $\infty$? Here, $J = J(\tau) = j(\tau)/12^3$ is the normalized $j$-invariant so that $J(i) = 1$, and $\tau$ is in the upper half-plane.","['modular-forms', 'algebraic-geometry', 'general-topology']"
1272491,$X + Y \overset{\mathcal{D}}{=} X \Longrightarrow \mathbf{P}[Y = 0] =1$,"Let $X$ and $Y$ be independent, real random variables. Show that $X + Y \overset{\mathcal{D}}{=} X$ implies that $\mathbf{P}[Y = 0] =1$. Note: $U \overset{\mathcal{D}}{=} V$ means that the random variables $U$ and $V$ have the same distribution. We know that a finite measure is fully determined by its characteristic function and vice versa. Two random variables $U, V$ having the same distribution is equivalent to their pushforward measures $\mathbf{P}_U := \mathbf{P}\circ U^{-1}, \mathbf{P}_V$ being identical. $$\phi_{\mathbf{P}_U}(t) = \int e^{i t x} \, d\mathbf{P}_U = \int e^{i t U} \, d\mathbf{P} =: \phi_U(t)$$ So $X + Y \overset{\mathcal{D}}{=} X$ is equivalent to $\phi_{X+Y} = \phi_{X}$. Since $X, Y$ are independent, it must hold that $\phi_{X+Y} = \phi_X \phi_Y$, therefore
\begin{align*}
  \phi_X\phi_Y \overset{!}{=} \phi_X  \; \Rightarrow \; \phi_Y = 1 \; \Rightarrow \; 
   \int e^{i t Y }\, d \mathbf{P} = 1\,.
\end{align*} One solution would be $Y = 0$ almost surely. But since a random variable is fully determined (almost surely) by its characteristic function, there cannot be another solution, so we conclude that $Y$ must be zero a. s. $\square$ Is everything ok? Thank you! NOTE: It is not assumed that $X$ and $Y$ have finite variance.","['probability-theory', 'solution-verification']"
1272508,Is exceptional divisor always a Projective bundle over the centre?,"Let $f:\tilde X \rightarrow X$ be a blow up at center Z. Is $f^{-1}(z)=\mathbb{P}^{k}$ ?for some $k$, $\forall$ $z\in Z$ In the case of blow-up of $\mathbb{A}^{n}$ at origin it is very clear that the $f^{-1}(0)=\mathbb{P}^{n-1}$. This is the description of blowing up an affine variety centered at a closed sub-variety. In this case also the fibers over the center are $\mathbb{P}^{k}$. My Question, 1.is it true that in a general blow-up of a scheme centered at closed sub-scheme the fibers over the center is a projective space  $\mathbb{P}^{k}$ If Yes, How do we find what is the Projective space? If yes, Is the exceptional divisor over the center is a projective bundle. (i.e., is it locally trivial).","['blowup', 'singularity-theory', 'algebraic-geometry']"
1272514,Shouldn't these two definitions for curvature agree?,"In $\mathbb R^n$ the defintion of curvature of a smooth regular curve $\gamma : \mathbb R \to \mathbb R^n$ is $$ \kappa (t) = \|\gamma''(t)\| / \|\gamma '(t)\|$$ In $\mathbb R^2$ the definition for the curvature of an arbitrary smooth regular curve $\gamma : \mathbb R \to \mathbb R^2$ given as $\gamma (t) = (x(t),y(t))$ is $$ \kappa (t) = {x'(t) y''(t) - x'' (t) y' (t) \over (x^{'2} + y^{'2})^{3/2}}$$ I assumed these should be equal because I thought the second formula was simply for convenience and not in fact different. But calculating a simple example says otherwise: If $\gamma (t) = (2 \cos t, \sin t)$ is an ellipse then $$ \|\gamma ''\|/\|\gamma'\| = {\sqrt{4 \cos^2 t + \sin^2 t}  \over \sqrt{4 \sin^2 t + \cos^2 t}}$$ whereas $$ \kappa(t) = {2\over (4 \sin^2 t + \cos^2 t)^{3/2}}$$ Similarly, a different curvature for $\gamma (t) = (t,t^2)$. Why is the curvature in $\mathbb R^2$ defined differently than for
  $\mathbb R^n$? It seems bizarre to me that they are not equal.",['differential-geometry']
1272538,When can variables simply be variables?,"This may seem a somewhat strange question, but I've been tying myself in knots about it recently. 
When constructing a polynomial ring, you must formally define a polynomial as an ordered ω-tuple, with the first entry being the constant value, the second being the coefficient of x, etc, and I think I understand why we need to do this...but I'm not entirely sure. When do we need to define polynomials in this way rather than just as terms? If I try to solve a system of linear equations with a column matrix $(x,y)$ (I know this isn't a column matrix but I'm not quite sure how to make matrices in LaTeX) do I need to invoke a similar construction? 
If I simply am solving a single equation such as $x^2+x+3=0$ would I need to work in a polynomial ring to correctly (in a strictly formal setting) do so? If I work with an abstract group, would I need some special construction or am I allowed to manipulate variables just as if they were""usual"" objects? I know this question may be somewhat pointless - we don't need to define these things in such a way to use them - but I'm trying to figure out how some concepts translate from ZFC to the main body of mathematics...and I'm just not sure how to deal with variables like this. 
When are variables....simply variables? If I have a rather large gap or error in my understanding that is causing this confusion I'd happily satisfy myself with plugging that gap, too. If that be the case I'm sorry for wasting your time, in a way.","['foundations', 'elementary-set-theory', 'polynomials']"
1272585,Boundary of the boundary of a manifold with corners,"A point of a manifold with corners is a boundary point by definition if one of its coordinates is $0$ by some (hence in all) chart with corners (see here ). In the same page one can read: The boundary of a smooth manifold with corners, however, is in general
  not a smooth manifold with corners (e.g., think of the boundary of a
  cube). ... It is, however, a union of finitely many such But how is the boundary of such an object defined? What is the definition of the boundary of the unions of manifolds with corners? In topological sense it is itself (or at least a subset of itself), but I think we should expect here a definition so, that the boundary of the boundary of a manifold with corner is empty. Second attempt to formulate my question without error Is there a definition of  the boundary of the boundary of a manifold with corners so, that we can state, that the boundary of the boundary of a manifold with corners is empty? (Similarly as we can say that the boundary of the boundary of a manifold with boundary is empty)","['differential-geometry', 'smooth-manifolds', 'manifolds-with-boundary']"
1272587,Is the sum of the reciprocals of the squarefree numbers divergent or convergent?,"I just come across this question by trying to analyze the pseudoinverse of some infinite matrix (the matrix T as interpreted in my answer to this MSE-question ), where this series occurs from some dotproducts. I think it can also be expressed in terms of the Moebius-function:
$$\sum_{k=1}^\infty \left| {\operatorname{moebius}(k) \over k} \right|  $$ 
Remembering, that the sum of the reciprocals of the primes is divergent I think I should assume divergence here as well, but I'm not sure. Q1: Is this sum convergent (and if, what is its value)? Q2: if it is divergent, is there possibly some finite value related, like for instance the Euler/Mascheroni-$\gamma$ for the harmonic series?","['number-theory', 'divergent-series']"
1272614,the topologist's sine circle is path-connected but it's not locally path-connected,"As you may know the topologist's sine curve is the set: $\{{(x,y) : x=0 \ and \ |y|\leq 1,\ or \ 0<x \leq 1 \ and\ y=\sin\dfrac{1}{x}}\}$ I want to show that the topologist's sine circle which is the union of circular arc and topologist's sine curve is path-connected but it's not locally path-connected. (you can see the picture of topologist's sine circle below): [topologist's sine circle] for saying that it is not locally path-connected I think we have to choose an interval near the $x=0$ and then show that it's not locally path-connected. Also the path-connectedness of this object is clear from the image, but unfortunately I don't know how to make a mathematical proof for being path-connected and not being locally path-connected.","['connectedness', 'general-topology']"
1272617,"W/ generating functions, How many solutions are there to the equation $2a+3b+c=n$ for some integer $n \geq 0$ and $a, b, c \geq 0$?","The question is: How many solutions are there to the equation $2a+3b+c=n$ for some integer $n \geq 0$ and $a, b, c \geq 0$? Solve this by writing down the correct generating function. I have no idea how to go about this. Any help would be appreciated. I was also confused about the more basic problem: How many solutions are there to the equation $a+b+c+d=n$ for some integer $n \geq 0$ and $a, b, c, d \geq 0$? So possibly helping me with the more basic one would help me get to the main problem. Thank you!","['number-theory', 'generating-functions', 'discrete-mathematics']"
1272624,Maxima and Minima of Sin(x)/x,"I am trying to calculate the maximum and minimum points (between $-3\pi$ and $3\pi$) of $$f(x)=\frac{\sin(x)}{x}$$ I have found the derivative of the function and let it equal to zero. $$f'(x)=\frac{x\cos(x) - \sin(x)}{x^2}$$ $$f'(x)=0$$
$$\frac{x\cos(x) - \sin(x)}{x^2}=0$$
$$x\cos(x) - \sin(x)=0$$
$$x\cos(x)=\sin(x)$$
$$x=\tan(x)$$ I am unaware as to how to find $x$. I assume that once I find $x$, I can use a sign diagram or second derivative test to determine the minimum and maximum values. Any help would be highly appreciated.","['calculus', 'trigonometry']"
1272651,"Let matrix $A$ be normal. If $A{A^T}$ has $n$ distinct eigenvalues, why is $A$ symmetric? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Let matrix $A \in {M_n}(\Bbb R)$ be normal. If $A{A^T}$ has $n$ distinct eigenvalues, why is $A$ symmetric?","['eigenvalues-eigenvectors', 'linear-algebra', 'symmetric-matrices', 'matrices']"
1272661,Is there a concept of asymptotically independent random variables?,"To prove some results using a standard theorem I need my random variables to be i.i.d. However, my random variables are discrete uniforms emerging from a rank statistics, i.e. not independent: for two $u_1$,$u_2$ knowing $u_1$ gives me $u_2$. Yet, my interest is in the asymptotics for ($u_i$) growing infinitely large, and thus these r.v. are becoming more and more independent. Is there a concept to formalize this idea? Is this standard? Can I have an entry point in the literature?","['asymptotics', 'uniform-distribution', 'statistics', 'random-variables']"
1272705,Priority vector and eigenvectors - AHP method,"I'm reading about the AHP method (Analytic Hierarchy Process). On page 2 of this document , it says: Given the priorities of the alternatives and given the matrix of
  preferences for each alternative over every other alternative, what
  meaning do we attach to the vector obtained by weighting the
  preferences by the corresponding priorities of the alternatives and
  adding? It is another priority vector for the alternatives. We can use
  it again to derive another priority vector ad infinitum. Even then
  what is the limit priority and what is the real priority vector to be
  associated with the alternatives? It all comes down to this: What
  condition must a priority vector satisfy to remain invariant under the
  hierarchic composition principle? A priority vector must reproduce
  itself on a ratio scale because it is ratios that preserve the
  strength of preferences. Thus a necessary condition that the priority
  vector should satisfy is not only that it should belong to a ratio
  scale, which means that it should remain invariant under
  multiplication by a positive constant c, but also that it should be
  invariant under hierarchic composition for its own judgment matrix so
  that one does not keep getting new priority vectors from that matrix.
  In sum, a priority vector x must satisfy the relation Ax = cx, c > 0 To let you quickly grasp what AHP is all about, check this simple tutorial . The matrix of preferences for each alternative over every other alternative is obvious to me. Ideally, such a matrix should satisfy a property $a_{ij}=a_{ik}a_{kj}$ (because if I say I prefer A to B two times, and B to C three times, then I should prefer A to C six times (it makes sense I guess, but it's a very informal rule). OK, but in the quote I gave, it says: what meaning do we attach to the vector obtained by weighting the
  preferences by the corresponding priorities of the alternatives and
  adding? It is another priority vector for the alternatives. I'm not quite sure what it means. Alternatives can be apple, banana, cherry. Preferences are just numbers in matrix of preferences, just like here But what are 'corresponding priorities of the alternatives'? I'd say to obtain a priority vector (i.e. to find out which fruit is preferred the most) one could just 1) divide every element in a given column by the sum of elements in that column (normalization) 2) calculate average of elements in each row of the matrix obtained in step 1). The obtained vector is the priority vector, I belive.
But in the quoted text, it gets worse - the author describes raising the matrix to consecutive powers. Why do we multiply priority matrix by itself? It says the result of this multiplication is 'another priority vector of alternatives'. Why? Haven't we just lost some information by doing this? I mean, we always can multiply matrices, but it should be justified. In case of priority matrix I can't see the justification. Later in the document I've quoted, the author uses the Perron-Frobenius theorem and other sophisticated methods. I'd be grateful for a intuitive, clear explanation of what's going on here. And finally: WHY the eigenvector $w$ matching the maximum eigenvalue $\lambda_{max}$ of the pairwise comparison matrix $A$ is the final expression of the preferences between the investigated elements? More articles on AHP method that might help you with answering my questions: http://books.google.com/books?id=wct10TlbbIUC&printsec=frontcover&hl=eng&redir_esc=y#v=onepage&q&f=false http://www.booksites.net/download/coyle/student_files/AHP_Technique.pdf http://www.isahp.org/2001Proceedings/Papers/065-P.pdf For example, what's the relationship between Perron-Frobenius theorem and this method?","['eigenvalues-eigenvectors', 'linear-algebra', 'matrices']"
1272709,"Suppose $y$, Does $\frac{dy}{dy} $ have meaning when we derive it with respect to itself?","Suppose we have a function and want to derive it with respect to itself e.g: $$\frac{dy}{dy} $$ Does this have any meaning , and if so what will be it's value?","['calculus', 'derivatives']"
1272721,Find a surface that has positive constant curvature that is not open subset of sphere,Can some one find a surface that has positive constant curvature that is not open subset of sphere. I know every connected and compact surface with positive constant curvature is sphere. I need some hint. Thanks a lot indeed,"['smooth-manifolds', 'differential-geometry', 'manifolds', 'riemannian-geometry']"
1272735,Proving direct sum when field is NOT of characteristic $2$.,"Let $\mathbb{F}$ be a field that is not of characteristic $2$. Define $W_1 = \{ A \in M_{n \times n} (\mathbb{F}) : A_{ij} = 0$ whenever $i \leq j\}$ and $W_2$ to be the set of all symmetric $n \times n$ matrices with entries from $\mathbb{F}$. Both $W_1$ and $W_2$ are subspaces of $M_{n \times n} (\mathbb{F})$. Prove that $M_{n \times n} (\mathbb{F})=W_1 \oplus W_2$. I know how to prove that $M_{n \times n} (\mathbb{F})=W_1 \oplus W_2$ for any arbitrary field $\mathbb{F}$ (by showing $W_1 \cap W_2 = \{0\}$ and any element of $M_{n \times n} (\mathbb{F})$ is sum of elements of $W_1$ and $W_2$). But what does ""$\mathbb{F}$ be a field that is NOT of characteristic $2$"" mean here (I am aware of definition of characteristic of a field), i.e. how does the characteristic of field affect the elements in $M_{n \times n} (\mathbb{F})$? And how does it change the proof? Thanks.","['linear-algebra', 'matrices']"
1272797,"Insights about $Tv_j=w_j$, the linear maps and basis of domain.","I'm now self-studying the book Linear Algebra Done Right. In chapter 3, I learned the theorem 3.5, Linear maps and basis of domain:
Suppose $v_1,...,v_n$ is a basis of V and $w_1,...,w_n∈W$. Then there exists a unique linear map $T:V→W$ such that
$$Tv_j=w_j$$
for each $j=1,...,n$. ""The existence part of the next result means that we can find a linear map that takes on whatever values we wish on the vectors in a basis. The uniqueness part of the next result means that a linear map is completely determined by its values on a basis."" -- a paragraph before this theorem. I'm still wondering how to make use of this theorem. It confused me quite a while, so would you please help me, really really appreciate it.","['linear-algebra', 'linear-transformations']"
1272804,Why is a double exponential function faster than $x!$?,"Reading this wikipedia article I found an interesting sentence: Factorials grow faster than exponential functions, but much slower than double-exponential functions. The author doesn't provide a link let alone a proof of that fact and I don't find it obvious. After all, factorial functions grow really fast but the author says they grow much slower than double exponentials. Does anyone know a proof that $$\lim_{x \to \infty} \frac{e^{e^{x}}}{x!} = \infty$$","['limits', 'real-analysis']"
1272830,Coin toss game - Probability of winning,"Question: Two players A and B, alternatively toss a fair coin (A tosses the coin first, then B, than A again, etc.). The sequence of heads and tails is recorded and if there is head followed by a tail (HT subsequence), the game ends and the person who tosses the tail wins. What is the probability that A wins the game? Solution: I was told the following solution. If $P(A),P(B)$ are the probabilities that A, B win, then we can write:
$$P(A) = P(A\mid H)P(H)+P(A\mid T)P(T)$$
where $P(H)=P(T)=1/2$ are the probabilites that A gets H, T in the first toss respectively. Then $$P(A\mid T)=P(B)=1-P(A)\tag{1}$$ and $$P(A\mid H)=1/2\cdot 0+1/2\cdot (1-P(A\mid H))\tag{2}$$
which gives $P(A)=4/9$. I am trying to understand equation (1),(2). I understand that if A gets T then the game essentially starts over with B being the first player. But since we want to know the probability of A winning, then shouldn't we have $P(A\mid T)=1-P(B)$? As for (2) I have not been able to find a starting point. Would somebody be able to explain their derivation?","['probability-theory', 'probability']"
1272846,When a given family of curves are geodesics of some affine connection?,"Let $M$ be a two-dimensional manifold and let $\mathcal C$ be a family of smooth paths on $M$. How to understand whether this family is actually a family of (possibly reparametrized) geodesics of some affine connection? In this paper by V. Matveev it is written that this problem is classical and the answer was known even to Sophus Lee. Matveev writes that in order to answer to this question one must construct an appropriate ODE $y''(x) = f(x,y(x),y'(x))$ and check whether the right hand side is a third degree polynomial in $y'$ or not. My question is whether there is some classical book where this problem is considered in detail and the mentioned results are presented?","['differential-geometry', 'riemannian-geometry', 'reference-request']"
1272867,"A difficult integral: $\int_0^{+\infty} e^{ - x}\left(\frac1{x( e^{ - x} - 1 )} + \frac1{x^2} + \frac1{2x} \right) \, dx$.","Could you help me calculate the integral? $$\int_0^{+\infty} e^{-x} \left(\frac1{x(e^{-x}-1)} + \frac1{x^2} + \frac1{2x} \right) \, dx .$$","['calculus', 'special-functions', 'closed-form', 'definite-integrals', 'integration']"
1272898,About direct sum of abelian groups and quotient,"I'm trying to understand properly the relations between quotient and direct sum. The first thing I wanted to know, and couldn't find online, is whether my guess is true or not:
Assume $G_\alpha$ are abelian groups, and $H_\alpha \leq G_\alpha$ a subgroup, is $\frac{\bigoplus G_\alpha}{\bigoplus H_\alpha}\cong\bigoplus\frac{G_\alpha}{H_\alpha}$? the reason i thought it would be true is because for every $G_\alpha$ we have that the only group on the nominator that affects $G_\alpha$ is $H_\alpha$. and it just seems symetric and reasonable.. thanks","['abelian-groups', 'abstract-algebra', 'group-theory', 'quotient-spaces', 'direct-sum']"
1272907,"Is this proof that $\kappa^{<\kappa}=\kappa$, when $2^{<\kappa}=\kappa$, correct?","Let $\kappa$ be a cardinal number. I want to show that if $\kappa$ is regular and if $2^{<\kappa} = \kappa$ then $\kappa^{<\kappa}= \kappa$. Here is what I got so far:
$$
\begin{align}\kappa^{<\kappa} ~&=~ \left| \bigcup\limits_{\alpha < \kappa}\bigcup\limits_{\beta < \kappa}\beta^\alpha \right| \\&\leq~ \sum\sum\limits_{\alpha, \beta < \kappa} |\beta|^{|\alpha|} \\&\leq~ \sum\sum\limits_{\alpha, \beta < \kappa}2^{|\beta|^{|\alpha|}} \\&=~ \sum\sum\limits_{\alpha, \beta < \kappa}2^{|\beta| \cdot |\alpha|} \\&=~ \sum\limits_{\gamma < \kappa}2^\gamma \\&=~ \kappa \cdot 2^{< \kappa} \\&\hspace{-3pt}\overset{\text{Hyp}}{=} \kappa \cdot \kappa \\&=~ \kappa.
\end{align}$$
But I feel that the first line is wrong... The following seems right 
$$\kappa^{< \kappa} ~=~ \left| \bigcup\limits_{\alpha < \kappa}\kappa^\alpha \right|$$
but I got doubts about 
$$\kappa^\alpha ~=~ \bigcup\limits_{\beta < \kappa}\beta^\alpha$$ since $\kappa$ is a regular cardinal. Any clue?","['elementary-set-theory', 'cardinals']"
1272927,Is $\exp$ the only function satisfying $f(x)=\displaystyle \int_{-x}^{+\infty} f(-t) dt$?,"Today in class we first dealt with improper integrals, and as an example we found $ \displaystyle \int_0 ^{+\infty} e^{-x}dx=1$. Soon, I noticed that in fact $$e^x=\int_{-x}^{+\infty}e^{-t}dt. $$ Since I already know $\exp$ can be defined as the unique function such that $f'(x)=f(x)$ and $f(0)=1$, I wondered whether this might be yet another way of defining it. In search of counterexamples, I rewrote the equation $$f(x) = \int_{-x}^{+\infty}f(-t)dt $$ as $$\lim_{x\to-\infty}f(x)=f(x)-f'(x),$$ but still couldn't think of other solutions (besides $c \cdot e^x$ ). If there aren't, how to prove it? (this question arised from a terribly silly oversight)","['exponential-function', 'improper-integrals', 'ordinary-differential-equations', 'integration']"
1272973,How does $x^2+4xy-6x+4y^2-12y+9=0$ represent a straight line.,I need to show $x^2+4xy-6x+4y^2-12y+9=0$ is a straight line. But I only know of a straight line in the form $y=mx+c$. Any help?,"['conic-sections', 'algebra-precalculus']"
1272992,Linearity of Multilinear Maps,"If $f: \mathbb{R^n} \rightarrow \mathbb{R^m}$, with $n>1$, is a multilinear map, is $f$ linear? I think $f$ is only linear for the special case that the range of $f$ consists of a single element, $\vec 0$. Is this correct?","['vector-analysis', 'multivariable-calculus', 'real-analysis']"
1273015,"Restrict $x$ in an equation, but keeping only one equation","How do you put restrictions on the $x$ in an equation without writing more than one equation? This is a two part question: How to take out a section of the graph of an equation? How to take out everything but a section of the graph of an equation? For example, to take out $x$ from $-1$ to $1$ in $y=|x|$, you can change the equation to $$y=|x|\times\dfrac{\sqrt{|x|-1}}{\sqrt{|x|-1}}$$ I need to take a function, say $f(x)$, and restrict it to $1 < x < 4$.",['functions']
1273032,"Prove non-existance of limit: $f(x,y) = \frac{xy\sin(\frac{x}{y})}{x^2 + |y|^3}$","I need to prove that $f(x,y) = \frac{xy^2\sin(\frac{x}{y})}{x^2 + |y|^3}$ does not tend to $0$ when $(x,y)$ approaches $(0,0)$. In order to do so, I would need to find some direction $\alpha$ such that $f(\alpha(t))$ approaches to some value $L \neq 0$ as $(x,y)$ approaches the origin. The problem is that I can't seem to find that direction. What could I try? I found  $$f(x^\frac{1}{2}, x^\frac{1}{3}) = \frac{x^\frac{7}{6}  \sin(x^\frac{-1}{6})}{2x} = \frac{x^\frac{1}{6}  \sin(x^\frac{-1}{6})}{2} = \frac{\sin(x^\frac{-1}{6})}{2 x^\frac{-1}{6}} \rightarrow \frac{1}{2}$$ Is this correct?","['continuity', 'multivariable-calculus', 'limits']"
1273043,Question about certain morphism between affine spaces,"Let the map $\varphi:\mathbb{A}^2\to\mathbb{A}^4$ is given by $$(x,y)\mapsto(x, xy, y(y-1), y^2(y-1)).$$ How to find the system of equations, which defines the image of $\varphi$? If we denote $u=x$, $v=xy$, $w=y(y-1)$, $t=y^2(y-1)$ then we have the relations 
$$ut=vw,\,\,v(v-u)=u^2w,$$
but it seems that it is not enough. Next, denote $A=\mathbb{C}[x,y]$, $B=\mathbb{C}[x, xy, y(y-1), y^2(y-1)]$. Then $A=B+yB$ which shows that $\varphi$ is a finite morphism. How to show that $\varphi$ is birational and $\text{Im}(\varphi)$ is closed in $\mathbb{A}^4$ but not normal?",['algebraic-geometry']
1273055,"Image of the upper half complex plane, under the function $g(z) = e^{2\pi i z}$","Problem: Given $W = \{z: z=x+iy, \ y>0\}$ and $g(z) = e^{2 \pi i z},$ what does the set $g(W)$ look like, and is it simply connected? Attempt: $W$ represents the upper-half complex plane. And $$g(z) = e^{2 \pi i (x+iy)} = \cdots = e^{-2\pi y}(\cos (2 \pi x) + i \sin (2 \pi x)).$$ (Am I on the right track?) I know simply connected means that there are no holes in the set, but I don't know how to describe the set geometrically. Further attempt: Since $e^{2 \pi i z} = e^{-2 \pi y}(e^{2 \pi i x})$ then $|e^{2 \pi i z}| = |e^{-2 \pi y}|$ and $y>0 \implies |e^{-2 \pi y}| \in (0,1).$ So $|e^{2 \pi i z}| \in (0, e^{2 \pi i x}).$ Right? Thanks in advance for help.",['complex-analysis']
1273057,Evaluate $\lim_{n\rightarrow\infty}\left[\frac{(2n)!!}{(2n-1)!!}\right]^2\cdot\frac{1}{2n+1}$,"If we know that $I_{n}=\int_0^\frac{\pi}{2}\sin^n(x)\,{\rm d}x$ we need to evaluate: $\lim_{n\rightarrow\infty}\left[\frac{(2n)!!}{(2n-1)!!}\right]^2\cdot\frac{1}{2n+1}$ ( !! means double factorial ). Here is all my steps to arrive at a squeeze theorem: $I_{_{n}}=\frac{n-1}{n}\cdot I_{n-2}$ , $\forall x\geq 2$ . Therefore: $I_{_{2k}}=\frac{\pi}{2}\cdot (\prod_{k=0}^{n}\frac{2k+1}{2k+2})=\frac{\pi}{2}\cdot(\prod_{k=1}^{n}\frac{2k-1}{2k})$ $I_{_{2k+1}}=\prod_{k=0}^{n}\frac{2k+2}{2k+3}=\prod_{k=1}^{n}\frac{2k}{2k+1}$ $\Rightarrow I_{2k}\geq I_{2k+1}$ , $\forall x\in[0,\frac{\pi}{2}]$ $\Rightarrow \prod_{k=1}^{n}\frac{2k}{2k+1}\leq\frac{\pi}{2}(\prod_{k=1}^{n}\frac{2k-1}{2k})\mid\cdot\prod_{k=1}^{n}\frac{2k}{2k-1}$ $\Rightarrow \prod_{k=1}^{n}\frac{2k^2}{4k^2-1}\leq\frac{\pi}{2}$ I don't know how can I arrive at $\left[\frac{(2n)!!}{(2n-1)!!}\right]^2\cdot\frac{1}{2n+1}$ and after use squeeze theorem. Is something $\frac{(2n)!!}{(2n-1)!!}=\prod_{k=1}^{n}\frac{2k}{2k-1}$ ? I want to continue with this method, if is something who can help me to finish I'll apreciate.","['calculus', 'real-analysis', 'limits', 'integration']"
1273078,"$X \sim \operatorname{Rice}(\nu,\sigma)$, what is the distirbution of $X^2$?","Let $X = |\nu e^{j\theta}+W|$ , where $W \sim \mathcal{CN}(0,2\sigma^2)$ , then $X\sim \operatorname{Rice}(\nu,\sigma)$ . What is the distribution of $X^2$ ? Note that $X$ also can be written in terms of real and imaginary parts: $X = \sqrt{\Re(X)^2 + \Im(X)^2}$ , where $\Re(X) \sim \mathcal N(\nu\cos\theta,\sigma^2)$ and $\Im(X) \sim \mathcal N(\nu\sin\theta,\sigma^2)$ : \begin{equation} \tag{1}
f_{X}(x) = I_0\bigg(\dfrac{x·\nu}{\sigma^2}\bigg)\dfrac{x}{\sigma^2} e^{-\dfrac{x^2+\nu^2}{2 \sigma}}.
\end{equation} I know that if $\sigma = 1$ the distribution is $X^2 \sim \chi_{2}^{,2} (\nu^2)$ , i.e. non-central chi squared distribution with noncentrality parameter $\nu^2$ and 2 degrees of freedom... But what happens for an arbitrary factor $\sigma$ ? I tried to follow the theory and compute the PDF of $X^2$ as following: Let $Y=X^2$ \begin{equation} \tag{2}
f_{Y}(y) =\frac{f_X(\sqrt{y})+f_X(-\sqrt{y})}{2\sqrt{y}}
\end{equation} However I ended up with the result $f_Y(y)=0$ ( $I_0$ function is symmetric), which I assume is not correct. Really appreciate your help, thanks.","['probability-theory', 'probability', 'signal-processing', 'probability-distributions']"
1273080,Computing Conditional Variance,"I have been tasked with trying to solve a conditional variance. I have red and black pens with respective exponential probability parameters 2 and 4. I have 70% red pens and 30% black pens. What is the variance of the lifespan? This is what I have so far: Let Y which batch it is from
$$Var(X)=V(X)=E(V(X|Y))+V(E(X|Y))$$
I broke this down and solved:
$$E(V(X|Y))=V(X|Y=red)*P(red)+V(X|Y=black)*P(black)=\frac{1}{2^2}*.7+\frac{1}{4^2}*.3=.19375$$
$$V(E(X|Y))= E([E(X|Y)]^2)-[E(E(X|Y))]^2$$
However, $E(E(X|Y))=E(X)$, which I have already solved. How does one find the $E([E(X|Y)]^2)$ part now. The E(X) is below
$$E(X)=E(E(X|Y))=E(X|Y=red)*P(red)+E(X|Y=black)*P(black)$$
Then each respective $E(X|Y=n)=\int_0^{\inf} xf_x$ such that $f_x$ is the respective exponential probabilities with parameters. Therefore $E(X)=.425$.","['probability-theory', 'probability', 'probability-distributions']"
1273097,Finding $\nabla r^n$,"Find $\nabla r^n$ where $r= \sqrt{x^2+y^2+z^2}$. So $r^n = (x^2+y^2+z^2)^{n/2}$. Then $$\frac{\partial r^n}{\partial x} = 2x\cdot\frac{n}{2}\cdot(x^2+y^2+z^2)^{n/2 - 1} = nx(x^2+y^2+z^2)^{(n-2)/2} = nxr^{n-2},$$ similarly $$\frac{\partial r^n}{\partial y} = nyr^{n-2}, \quad \frac{\partial r^n}{\partial z} = nzr^{n-2}.$$ Thus $$\nabla r^n = nr^{n-2} (x\mathbf{i} + y\mathbf{j} + z\mathbf{k}) = nr^{n-2}\mathbf{r}.$$ However the correct answer is $$\nabla r^n=nr^{n-1} \hat{\mathbf{r}}.$$ I don't really understand where I have gone wrong.",['multivariable-calculus']
1273112,Intuitively understanding $\sum_{i=1}^ni={n+1\choose2}$,"It's straightforward to show that $$\sum_{i=1}^ni=\frac{n(n+1)}{2}={n+1\choose2}$$ but intuitively, this is hard to grasp. Should I understand this to be coincidence? Why does the sum of the first $n$ natural numbers count the number of ways I can choose a pair out of $n+1$ objects? What's the intuition behind this?","['intuition', 'summation', 'combinatorics', 'soft-question']"
1273117,Kernel of an homomorphism between two free groups,"I am trying to prove that $G=\langle \alpha,\beta,\gamma \mid \alpha\beta\alpha^{-1}\beta^{-1}\gamma \rangle$ is isomorphic to $H=\langle \delta,\varepsilon \mid \hspace{0.5cm}\rangle$. Let N be the smallest normal subgroup including $\alpha\beta\alpha^{-1}\beta^{-1}\gamma$ In order to prove it, I define a surjective map from $\langle \alpha,\beta,\gamma\rangle$ to $\langle \delta,\varepsilon\rangle$ and I try to apply the First Isomorphism Theorem. $\varphi:\langle \alpha,\beta,\gamma\rangle \longrightarrow \langle \delta,\varepsilon\rangle$ with $\varphi(\alpha)=\delta,\varphi(\beta)=\varepsilon,\varphi(\gamma)=\varepsilon\delta\varepsilon^{-1}\delta^{-1}$. $\varphi$ is clearly surjective and $\varphi(\alpha\beta\alpha^{-1}\beta^{-1}\gamma)=\delta\varepsilon\delta^{-1}\varepsilon^{-1}\varepsilon\delta\varepsilon^{-1}\delta^{-1}=e$. So $N\subset\text{Ker}(\varphi)$ How do I prove $\text{Ker}(\varphi)\subset N$?","['group-theory', 'algebraic-topology', 'free-groups']"
1273131,30th problem of the fifth book of Diophantus;,"Is there a complete answer to this problem? I have found Saunderson's answer, but I believe it is missing a few answers. The problem states: $a^2+b^2=d^2 \\
a^2+c^2=e^2 \\
b^2+c^2=f^2$ Saunderson proves the answer is $a=y(4x^2-z^2)\\
b=x(4y^2-z^2)\\
c=4xyz$ where $x,y,z$ is the Pythagorean triple $x^2+y^2=z^2$. But this skips answers like $(85,132,720)$,$(132,351,720)$, etc. The complete Saunderson proof is here: https://play.google.com/books/reader?id=1NI_AQAAMAAJ&printsec=frontcover&output=reader&hl=en&pg=GBS.PA429 The solutions are also known as Euler Bricks. Also (since I don't think a complete answer exists), do any of you have suggestions on how to find one?","['number-theory', 'diophantine-equations', 'algebraic-number-theory']"
1273139,Dominated Convergence Theorem,"Give an example of a sequence $\{f_n\}_{n=1}^\infty$ of integrable functions on $\mathbb{R}$ such that $f_n \to f$ but $\int f_n \not\to \int f$ . Explain why your example does not conflict with the Dominated Convergence Theorem. I do notice that the inequality $|f_n(x)| \le g(x)$ , where $g$ is an integrable function over $\mathbb{R}$ , is not listed here in this problem. So the function need not be dominated by an integrable function. But this is required as one hypothesis of the Dominated Convergence Theorem; hence the example will not conflict. If this is sound reasoning, how may I come up with functions that are not dominated by another function? Initially I was thinking $f_n(x)=x \sin (nx)$ because its $\lim \sup$ is $\infty$ , but even then, we still have $|f_n(x)| \le |x| =: g(x)$ .","['real-analysis', 'lebesgue-integral']"
1273151,Circle and heart homeomorphic?,"Is a circle and heart homeomorphic to one another? Intuitively, I can picture that the one can be ""morphed"" into the other by bending and stretching and not breaking. But I am unsure if that is correct? This is not an assignment or anything, I am just thinking about it in general. Can anyone please confirm or reject my reasoning above and show it to me (algebraically or through a sketch or anything) in order to give me a nice explanation? This is the picture that got me thinking about it","['general-topology', 'soft-question']"
1273168,Transition function for absorbed Brownian motion,"I need an help with the following exercise. I've already seen this question Prove that Brownian Motion absorbed at the origin is Markov but I don't understand the answer. Also I would like to prove the thing differently (at least the two ways seem different to me). So let $\tau$ be the first time the Brownian motion arrives in $0$ and define $W^x_t = \begin{cases} x+B_t &\mbox{if } t\leq \tau \\ 
0& \mbox{else }. \end{cases} $ Here we denote with $B_t$ the standard Brownian motion starting at $0$ and with $B_t^x$ the Brownian motion starting at $x$, so $B_t^x=x+B_t$. I want to compute the transition function for the process, i.e. $p(t,x,A)$. I've already got an hint: show that $\mathbb P(B_t^x\in A)= \mathbb P(B^x_t\in A,B_s^x>0 \,\forall s \in [0,t] )+\mathbb P(B_t^x\in -A)$, for each $x>0, A\subset (0+\infty).$ Now I see that if I prove the hint, I'm done, but I don't know how to prove the hint. I know that I should use reflection principle, but how?
Any help will be really appreciated.","['probability-theory', 'brownian-motion', 'markov-process', 'stochastic-processes']"
1273180,Introductory book on Gromov Witten Theory,"I am looking for a good introduction to Gromov Witten Theory. I have a background in algebraic geometry, which corresponds roughly to the first three chapters of Hartshorne. Thanks in advance!",['algebraic-geometry']
1273187,Are there any differences between distributions (generalized functions) and probability distributions?,"A distribution/generalized function is an element of the dual space of $$S=\{f\in  C^{\infty}(\mathbb{R})\colon \|f\|_{\alpha,\beta}<\infty \text{ for all } \alpha ,\beta\}$$
Where $\|f\|_{\alpha,\beta}=\sup_{x\in \mathbb{R}}|x^{\alpha} f^{(\beta)}(x)|$. We know that all probability measures are elements of $S^*$, or more specifically the linear functional $L_{\mu}\colon S\rightarrow \mathbb{R}$ where $L_{\mu} (f)=\int_{-\infty}^{\infty}fd\mu$. In this sense, a probability measure is just a linear functional $L\colon S\cup\{1\}\rightarrow \mathbb{R}$ with $L(1)=1$. Using the Riesz Representation Theorem, any linear functional (with a few technical considerations) has a unique associated measure. So if $L$ is any distribution on $S\cup \{1\}$, where $L(1)=1$, it is a probability distribution. Is this correct? A ""probability distribution"" (in the sense of the Radon-Nikodym derivative of a probability measure with respect to Lebesgue measure) is really just a normalized (or is uniquely associated with a) normalized Schwartz distribution?","['probability-theory', 'distribution-theory', 'functional-analysis', 'measure-theory']"
1273199,Show that any solution of $x' = X(x)$ it is defined for all $t > 0$.,"If $X=(X_1,X_2,...,X_n)$ is a vector field of class $C^1$ in $\mathbb{R^n}$ and $V$ it is a differentiable function in $\mathbb{R^n}$ such that 
$$\sum_{i=1}^n\frac{\partial V}{\partial x_i}(x)X_i(x) \leq 0 $$ and $V(x)\geq |x|^2$ $\forall x \in \mathbb{R}^n$. Show that any solution of $x' = X(x)$ it  is defined for all $t>0$.","['analysis', 'ordinary-differential-equations']"
1273216,"Give a family of sets $\{F_a\}$ with each $F_a\subseteq (0,1)$ and $F_a \cap F_b \neq \emptyset$ but $\bigcap_aF_a = \emptyset$.","Give a family of sets $\{F_a\}$ with each $F_a\subseteq (0,1)$ and $F_a \cap F_b \neq \emptyset$ but $\bigcap_aF_a = \emptyset$.
What is an example of such a family of sets?",['elementary-set-theory']
1273237,"Show that: a) $X^{-1}(t)$ is bounded in $[\beta,\infty)$. b)No system solution approaches zero solution when $t \rightarrow \infty.$","Let a system $x' = A(t)x$ and suppose there are values positives $k, \beta$ such that a positive fundamental matrix $X(t)$ satisfies $\|X(t)\| \leq k$, $t \geq \beta$ and $$ \liminf_{t \rightarrow \infty} \int^t_\beta \operatorname{tr}(A(s))\,ds > - \infty.$$ Show that: a)$X^{-1}(t)$ is bounded in $[\beta,\infty)$. b)No system solution approaches zero solution when $t \rightarrow \infty.$","['analysis', 'systems-of-equations', 'ordinary-differential-equations']"
1273256,Does $\mathbb Q(\sqrt{-2})$ contain a square root of $-1$?,"This isn't a homework question but one I found online. Does $\mathbb Q(\sqrt{-2})$ contain a square root of $-1$? We just started doing field theory in my class and I want extra practice, but I have no idea how to even start this problem. It's no, right? I'm not sure why.","['extension-field', 'abstract-algebra', 'field-theory']"
1273267,$\sin$ and $\cos$ are the basis of what space?,"When learning Fourier expansions, we learn that $\{\sin(mx), \cos(mx)\}_{m \in \Bbb N}$ is an orthonormal basis for our space and thus we can expand functions in it.  My question is what space is this exactly? Is it the space of all functions $f: \Bbb R \to \Bbb R$?  I doubt it.  There are some really weird functions.  Or is it continuous functions?  Or periodic functions?  Or analytic functions?  Or just some set of functions that can only be described as the span of the above basis functions?","['hilbert-spaces', 'fourier-analysis', 'linear-algebra', 'functional-analysis']"
1273269,Prove that $\exists \delta>0$ such that $0<|x-y|<\delta \Rightarrow\Big|\dfrac{f(x)-f(y)}{x-y}-f'(c)\Big|<\varepsilon$,"Let $f: I \rightarrow \mathbb R$ be differentiable at $c\in I$. Prove that for every $\varepsilon>, \exists \delta>0$ such that $0<|x-y|<\delta$ and $a\leq x\leq c \leq y\leq b\Rightarrow\Big|\dfrac{f(x)-f(y)}{x-y}-f'(c)\Big|<\varepsilon$ My attempt: $f: I \rightarrow \mathbb R$ is differentiable at $c\in I$, i.e. $f'(c)$ exists. So, $0<|x-c|<\dfrac{\delta}{2} \Rightarrow\Big|\dfrac{f(x)-f(c)}{x-c}-f'(c)\Big|<\varepsilon$ And $0<|y-c|<\dfrac{\delta}{2} \Rightarrow\Big|\dfrac{f(y)-f(c)}{y-c}-f'(c)\Big|<\varepsilon$ I'm stuck here. Please help!","['real-analysis', 'derivatives']"
1273277,Matrix transponse in tensor notation,"In this paper , at the end of chapter 2, the author says that in index notation a matrix is written as $A^\mu_{\;\;\nu}$ and its transpose as $A_\nu^{\;\;\mu}$. $A^\mu_{\;\;\nu}$ looks like a (1,1)-tensor, but in a tensor the order of indices does not matter. How to explain this discrepancy? I am still trying to build intuition on tensors, so forgive me if the following questions are stupid. If $x$ is a vector and $A$ the matrix of a linear transformation, how to express $A^Tx$ in tensor notation? The linear algebra concept for a (1,1)-tensor is the matrix of a linear transformation, for a (0,2)-tensor is the matrix of a quadratic form. What it is for a (2,0)-tensor?","['convention', 'tensor-products', 'tensors', 'matrices']"
1273286,Is the complex plane homeomorphic to $\mathbb{R}^2$?,Is the set of complex numbers homeomorphic to $\mathbb{R}^2$? They are isomorphic. Are they homeomorphic?,['general-topology']
1273287,Intuition behind measurable random variables and $\sigma$-algebra,"I've been trying to understand $\sigma$-algebras and how it encodes information in context of filtration. While certain parts seem clear and logical, I can't say I get the whole picture. I'll try to explain the counter-intuition I get with the classical example of the coin tossing : the probability space $\Omega = \{ HH, HT, TH, TT \}$ and a r.v. $X(\omega)$ equal to the number of heads. At times $0$, $1$ and $2$ the available information is represented using $\sigma$-algebras $\mathcal{F}_0=\{\emptyset,\Omega\}$, $\mathcal{F}_1=\{\emptyset, \Omega, \{HH,HT\},\{TH,TT\}\}$ and $\mathcal{F}_2=\{\emptyset, \Omega,\{HH,HT\},\{TH,TT\},\{HH\},\{HT\},\{TH\},\{TT\}\}$. One can notice that $X(\omega)$ is not measurable with respect to $\mathcal{F}_0$ and $\mathcal{F}_1$, because $X^{-1}((\frac{3}{2}; +\infty))=\{HH\}$. To me it is quite surprising: intuitively $X$ makes perfect sense at all times. In particular it has an expected value at time $0$, which I interpret as that the probability and value of all outcomes $\{\omega\}$ can be computed. How do you think of a non-measurable function? Here's another way of expressing the same confusion. The most natural choice of $\sigma$-algebra in a finite discrete case is $\mathcal{F}=2^\Omega$, and it is implicitly used in all elementary probability problems. However, this choice of $\mathcal{F}$ does not reflect the fact that some information is known or unknown, conditional probability does. Does it mean that the statement ""$\sigma$-algebra is known information"" make sense only in conditioning? Why is it convenient then?","['probability-theory', 'probability', 'measure-theory']"
1273347,hard time coming up with an idea to find a limit,I am solving another problem and it boils down to solving this problem: We have that $b > a > 0$ are two arbitrary given real numbers. Let $p_n = \dfrac{a(a+1)...(a+n)}{b(b+1)...(b+n)}$ Prove that $\displaystyle\lim_{n\to\infty} p_n = 0$. Is this true at all? How do we prove it?,"['sequences-and-series', 'limits']"
1273351,Solve the equation $x^3-x+\frac16\sqrt3=0$,"8 ( i ) By first expanding $\sin(2\theta+\theta)$, show that $$\sin3\theta=3\sin\theta-4\sin^3\theta\tag4$$ ( ii ) Show that, after making the substitution $x=\frac{2\sin\theta}{\sqrt3}$, the equation $x^3-x+\frac16\sqrt3=0$
           can be written in the form $\sin3\theta=\frac34$. $\tag1$ ( iii ) Hence solve the equation $$x^3-x+\frac16\sqrt3=0$$
          giving your answers correct to 3 significant figures. $\tag4$ This equation in part 3. I can solve this by using $$\begin{align}
\sin(3\theta)&=\left(\frac{3}{4}\right)\\
3\theta&=\sin^{-1}\left(\frac{3}{4}\right)\\
3\theta&=\pi-\sin^{-1}\left(\frac{3}{4}\right)\\
3\theta&=2\pi+\sin^{-1}\left(\frac{3}{4}\right)
\end{align}$$ …and then getting values for $\theta$ after dividing these expressions by $3$, but the marking scheme says something else: ( iii ) Carry out a correct method to find a value of $x$ $\qquad\mathrm M1$ Obtain answers $0.322, 0.799, -1.12$ $\qquad\mathrm A1+\mathrm A1+\mathrm A1\quad[4]$ [Solutions with more than 3 answers can only earn a maximum of $\mathrm A1+\mathrm A1$.] What am I missing?",['algebra-precalculus']
1273371,3D Vector defined by 3 angles trigonometry components,"What I'm looking for is the trigonomery equations to calculate the x, y and z components of a 3D vector. What I mean: The counterpart formulas for a 2D vector defined by 1 angle: $x = \cos(\alpha)$ $z = \sin(\alpha)$ The counterpart for a 3D vector defined by 2 angles: $x = \cos(\alpha)  \cos(\beta)$ $z = \sin(\alpha)  \cos(\beta)$ $y = \sin(\beta)$ So what I need is something along the lines of: $x = \cos(\alpha)  \cos(\beta)  f(\gamma)$ $z = \sin(\alpha)  \cos(\beta)  g(\gamma)$ $y = \sin(\beta)  h(\gamma)$ where $f(\gamma),g(\gamma),h(\gamma)$ are some functions of $\gamma$ .","['vectors', '3d', 'trigonometry']"
1273373,Is a topological space isomorphic to some group?,"I'm reading topology without tears to develop intuition before attempting Munkres. I noticed how similar a topological space was to a group in Abstract Algebra. 1.1.1 Definitions. Let $X$ be a non-empty set. A set $\tau$ of subsets of $X$ is said to be a topology on $X$ if $X$ and the empty set, $\varnothing$ , belong to $\tau$ , the union of any (finite or infinite) number of sets in $\tau$ belongs to $\tau$ , and the intersection of any two sets in $\tau$ belongs to $\tau$ . The pair $(X,\tau)$ is called a topological space . Can you see why $X$ and $\varnothing$ behave like identities? And $\cup$ and $\cap$ are like binary operations. And this 'group' is closed under both operations. Is there a group a topological space is isomorphic to? Or are these just coincidences?","['group-theory', 'general-topology']"
1273376,"Suppose that $X$ is a discrete random variable taking values in $\{0,1,2,...\}$. Show that $E[X]=\sum^{\infty}_{k=0}{P(X>k)}$","Suppose that $X$ is a discrete random variable taking values in $\{0,1,2,...\}$. Show that $E[X]=\sum^{\infty}_{k=0}{P(X>k)}$ Absolutely lost. From my notes, we define $E[X]$ as follows $E[X]=\sum^{\infty}_{k=1}{xP(X=k)}$ I am also unsure how to explictly write $\sum^{\infty}_{k=0}{P(X>k)}$. My intuitive understanding of $P(X>k)=\{$ probability of the event not occuring consequetively until $X=k\}$, i.e. $P(X>k)=(1-P(0))(1-P(1))(1-P(2)) \dots (1-P(k-1))$ Or is it $P(X>k)=1-[P(X=0)P(X=1) \dots P(X=k-1)$","['summation', 'probability', 'discrete-mathematics']"
1273377,Conditions that guarantee a composite Bezier curve in the cartesian plane represents a function?,"Context I am allowing users of my application to control a curve connecting $(0,0)$ and $(1,1)$. There are a finite number of knots that are evenly spaced horizontally. The user can specify the height of the curve at each of these knots. The curve is formed numerically by computing and patching together cubic Bézier curves subject to the following constraints: $B''(t) = 0$ at each end of the composite curve; $B$ is $C^2$ at each knot. I would like the resulting curve to represent a function $y = f(x)$. Intuitively, I am guessing that there is probably a relationship between the horizontal knot separation and the maximum vertical separation of consecutive knots that will guarantee the composite curve represents a function. However, I have not been able to prove this analytically. Edit: since the $x$-coordinate of a Bézier curve depends only on the $x$-coordinates of its knots and control points, this hypothesis cannot be true. Question Is there a known result that describes when a composite Bézier curve (or more generally, any parametric curve) in the cartesian plane represents $y$ as a function of $x$? If not, is there a simple derivation that I'm missing that shows a certain bound on the variation in horizontal knot locations will be enough to guarantee the result I'm looking for?","['parametric', 'bezier-curve', 'functions']"
1273389,"In how many ways can we arrange $6$ red, $3$ blue and $4$ green balls in a row such that there is no adjacent green balls?","All ball of one color are identical . My idea is to calculate first the total numbers to arrange the $13$ balls. It equals $\dfrac{13!}{6! 3! 4!}=60060.$ Then I want  remove the cases where all $4$ green ball are adjacent, then remove cases where $3$ green ball are adjacent and the cases  $2$ green ball are adjacent. For the  first case (all $4$ green ball are adjacent) I have got $\dfrac{9!}{6! 3!}=84 $ cases,  but cant  calculate rest cases. Any   help please.",['combinatorics']
1273394,A question about projections of product measure space,"I am considering the space $\mathbb{R}^{\mathbb{N}}$ of real-valued sequences with the sigma-algebra $\mathcal{F}$ generated by sets of the form $$\{\omega \in \mathbb{R}^{\mathbb{N}} : \omega_k \in B\}$$ as $k$ ranges through $\mathbb{N}$ and $B$ through the Borel subsets of $\mathbb{R}$. Let $\mathcal{F}'$ be the sub-sigma algebra generated by the sets $$\{\omega \in \mathbb{R}^{\mathbb{N}} : \omega_k \in B\}$$ as $k$ ranges through $k \geq 2$ and $B$ through the Borel sets. My very simple questions is, how to show that: $$\{\omega: \omega_1 = 0\} \notin \mathcal{F}' .$$ My problem is that you can't write down a 'typical' element of the RHS explicitly. Is the only way to do this by transfinite induction? Many thanks for your help. EDIT: I am aware that it is possible to define a probability measure on the space and derive the contradiction $1/2=1/4$ using independence of $\mathcal{F}'$ and the sigma-algebra generated by the first co-ordinate mapping. However, I don't find this answer satisfying as it creates what seems like extraneous structure.","['probability-theory', 'measure-theory']"
1273429,Deducing a Taylor expansion in an arbitrary point from a MacLauren polynomial,"I have a function $f(x,y)=-2x^3 + 4y^3 +4xy+4x$ and I need to find a Taylor expansion, around the point $(-4,1)$ of this function. Since the function is actually a polynomial, I know this representation is also its Taylor expansion, but around $(0,0)$ . Is there any way to calculate the Taylor series around $(-4,1)$ without having to calculate all the derivatives ? (i.e.- only by using the known form of the function ) Hope I made myself clear Thanks in advance","['calculus', 'multivariable-calculus']"
1273437,Brownian motion and covariance,"Show that for $B = (B_t)$ Brownian motion, its covariance is
$cov(B_s, B_t) = min(s, t)$. The solution I was given was: For $s ≤ t$,
$B_t = B_s + (B_t − B_s)$, $B_sB_t = B_s^2 + Bs(Bt − Bs)$ $cov(B_s,B_t)=E[B_sB_t]$(as $E(B_i)=0)$ so $cov(B_s,B_t)=E[B_s^2]+E[B_s(B_t-B_s)]$, as all increments of Brown motion are independent the second term in the RHS $=E[B_s]E[B_t-B_s]=0*0=0$. Now $cov(B_s,B_t)=E(B_s^2)=Var(B_s)=s$. Similarly if $t\leq s$ we get $=t$. My question is, could I not have done this arguement the same way without assuming that $s\leq t$ in the first place? I mean, if $s\leq t$ why cant I say 
$B_s = B_t + (B_s − B_t)$ and conitnue like this to get the answer with a max instead of a min? Is it because $B_t-B_s$ is only an increment if $t\geq s$? I mean otherwise we dont have independency or something?","['brownian-motion', 'finance', 'probability']"
1273441,Functional equation $f'(x)=cf(x+1)$ has a solution if and only if $c\leq 1/e$,"In Contests in Higher Mathematics: Miklos Schweitzer Competitions,
1962-1991 by Gabor J Szekely, problem F.57 there is the study of
$f~:~[0,\infty)\to (0,\infty)$ such that: $\exists c>0, \forall x>0$,
$f'(x)=cf(x+1)$. It states, without proof, that for this equation has a solution if and only if
$c\leq 1/e$. There is a reference to an unpublished paper:
T. Krisztin,  Exponential bound for positive solutions of functional differential equations, unpublished manuscript Does anyone have this paper (or a proof of $c\leq 1/e$)?","['functional-equations', 'reference-request', 'real-analysis', 'functions']"
1273469,"Confusion: I can solve rate problem using ""1 pool per $a$ hours"", but not ""$a$ hours per pool"".","This problem is from Gelfand's Algebra (I'm self-studying, this is not homework): A swimming pool is divided into 2 equal sections. Each sections has its own water supply pipe. To fill one section (using its pipe), you need $a$ hours. To fill the other sections you need $b$ hours.
How many hours would you neeed if you turn on both pipes and remove the wall dividing the pool into sections? - What I tried and understand (please read this because I can solve the problem already one way so I'm not just looking for a solution. I can't solve this problem ""the other way"" and what I need is a conceptual clarification as to why it isn't working that other way): If I can find the time it would take both pipes together to fill up one section (1/2 pool), then I could multiply this rate by 2 and get the time it'd take to fill up the whole pool. The first pipe fills one section in $a$ hours, which I write as a ratio $\frac{1}{a}$. The second pipe's rate is then $\frac{1}{b}$, so that working together they will fill up a single section at a rate of $\frac{1}{a} + \frac{1}{b} = \frac{a+b}{ab}$. Therefore, to fill up the entire pool will take ( edited from Henning's correction) $2 \cdot \frac{ab}{a+b}$ hours. - My problem : I tried solving the problem using ratios of $\frac{a}{1}$ and $\frac{b}{1}$ instead, namely ""$a$ hours per pool"" and ""$b$ hours per pool""; I'm sure there's a way to make it work but I can't seem to make sense out of it. The rates are already over the same denominator, namely 1 pool section. Obviously, just adding them and ending up with $\frac{a+b}{1}$ is wrong, but I'm not sure why , or how to make this problem work thinking about it with the rates this way. I would really appreciate a conceptual explanation (some words) on top of the algebra. Thank you. EDIT (motivated by Henning's comment): When I say I'm sure there's a way to solve the problem with the inverse rates, I mean that I don't see why it wouldn't be possible; so if it is indeed impossible, my question would become ""what makes it impossible?""",['algebra-precalculus']
1273477,What is the unit normal vector of the curve $y + x^2 = 1$,"What is the unit normal vector of the curve $y + x^2 = 1$, $-1 \leq x \leq 1$? I need this to calculate the flux integral of a vector field over that curve.","['vectors', 'multivariable-calculus']"
1273504,Proof without using induction [duplicate],"This question already has answers here : Proving $\sum_{k=1}^n{k^2}=\frac{n(n+1)(2n+1)}{6}$ without induction [duplicate] (5 answers) Closed 9 years ago . How to prove that 
$$1^2+2^2+...+n^2=\frac{n(n+1)(2n+1)}{6}$$
without using induction. If we don't know the right side of this expression, how to get right expression. I tried with partial sums and binomial formula but can't get it. So the problem is:
$$1^2+2^2+...+n^2=?$$ Thanks for replies.","['induction', 'calculus', 'algebra-precalculus']"
1273514,Normal projective varieties and its coordinate ring,"Let $k[X_0,...,X_n]$ be a polynomial ring over an algebraically closed field of characteristic zero and $I$ an ideal of $k[X_0,...,X_n]$ generated by homogenous polynomials. Denote by $X$ the projective scheme Proj $k[X_0,...,X_n]/I$. Assume that $k[X_0,...,X_n]/I$ is an integral domain. Is it true that $X$ is a normal scheme if and only if the ring $k[X_0,...,X_n]/I$ is normal?","['algebraic-geometry', 'projective-schemes', 'commutative-algebra']"
1273520,How can you solve $x^2+2x^{-1}-1=0$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How can you solve $x^2+2x^{-1}-1=0$?",['algebra-precalculus']
1273538,Calculation of $A'(0)$ (first variation of the area functional).,"I'm trying to do the calculation that shows that a surface in $\Bbb R^3$ is area minimizing if and only if the mean curvature is zero. I'm getting a sign wrong and I'm going crazy, I need help. Notations: Fix a domain $D$. Here ${\bf x}$ is a parametrization, ${\bf x}^t = {\bf x}+t{\bf V}$ is a variation, with ${\bf V}$ being zero on $\partial D$, $\bf N$ is the normal unit vector and $A(t)$ is the area of ${\bf x}^t$. So far, I have $$A'(0) = \iint_D \langle {\bf N}, {\bf x}_u \times {\bf V}_v + {\bf V}_u \times {\bf x}_v \rangle \,{\rm d}u\,{\rm d}v,$$ and I'm positive that so far, so good. Then, the trick seems to use Green-Stokes with $P = \langle {\bf N}, {\bf V}\times {\bf x}_u\rangle$ and $Q =  \langle {\bf N}, {\bf V}\times {\bf x}_v\rangle$. $$\begin{align} \frac{\partial Q}{\partial u} - \frac{\partial P}{\partial v}  &= \langle {\bf N}_u, {\bf V}\times {\bf x}_v\rangle+\langle {\bf N}, {\bf V}_u\times {\bf x}_v\rangle+\langle {\bf N}, {\bf V}\times {\bf x}_{uv}\rangle \\ &\qquad -\langle {\bf N}_v, {\bf V}\times {\bf x}_u\rangle-\langle {\bf N}, {\bf V}_v\times {\bf x}_u\rangle-\langle {\bf N}, {\bf V}\times {\bf x}_{uv} \rangle \\ &= \langle {\bf N}_u, {\bf V}\times {\bf x}_v\rangle-\langle {\bf N}_v, {\bf V}\times {\bf x}_u\rangle + \langle {\bf N}, {\bf x}_u \times {\bf V}_v + {\bf V}_u \times {\bf x}_v \rangle\end{align}$$ Now let's look only at: $$\begin{align} \langle {\bf N}_u, {\bf V}\times {\bf x}_v\rangle-\langle {\bf N}_v, {\bf V}\times {\bf x}_u\rangle &= \langle {\bf V}\times{\bf x}_v, {\bf N}_u\rangle  - \langle {\bf V}\times{\bf x}_u,{\bf N}_v\rangle \\ &=  \langle {\bf V},{\bf x}_v\times {\bf N}_u\rangle  - \langle {\bf V},{\bf x}_u\times{\bf N}_v\rangle  \\ &= \langle {\bf V}, {\bf N}_v\times{\bf x}_u+{\bf x}_v\times{\bf N}_u\rangle \\ &= -2H\langle {\bf V},{\bf x}_u\times{\bf x}_v\rangle,\end{align}$$ using that $${\cal S}{\bf v}\times{\bf w}+{\bf v}\times{\cal S}{\bf w} = 2H {\bf v}\times{\bf w},$$ where ${\cal S}$ stands for the shape operator, with ${\bf v} = {\bf x}_v$ and ${\bf w}={\bf x}_u$. The line integral that appears after using Green-Stokes is zero because $\bf V$ is zero in $\partial D$ and we get: $$A'(0) = 2\iint_D H \langle {\bf V},{\bf N}\rangle \,{\rm d}A.$$ But all books say that $$A'(0) = \color{red}{-}2\iint_D H \langle {\bf V},{\bf N}\rangle \,{\rm d}A.$$
Where is the mistake?","['differential-geometry', 'multivariable-calculus']"
1273555,Show that ~ creates a partition of $M_2(\mathbb{R})$,"Let $M_2 (\mathbb{R})$ be the set of 2x2 matrices over $\mathbb{R}$: 
$$
M_2 (\mathbb{R}) = \biggl\{ 
\begin{pmatrix} a & b \\ c & d \end{pmatrix}
\; \biggm| \; \text{with } a,b,c,d \in \mathbb{R} \biggr\}. 
$$
For $M_1, M_2 \in M_2(\mathbb{R})$, we say that $M_1 \sim M_2$ if $\det(M_1) = \det(M_2)$, where 
$$
\det \begin{pmatrix} a & b \\ c & d \end{pmatrix} = ad-bc.
$$ Show that $\sim$ creates a partition of $M_2(\mathbb{R})$. What are the representative elements of each partition? Are there countably or uncountably many distinct equivalence classes? I am stuck and I could really use some help. I know that in order to have a partition, the union of all the partitions $X_i$ should be $X$ and $X_i \cap X_j = \varnothing$ for $i \ne j$.","['elementary-set-theory', 'linear-algebra', 'set-partition']"
1273595,Order of differentiaton for multivariable functions with arbitrary dependence of variables,"While studying Neural Networks, I was bogged with a nasty problem, for which I did not find a satisfying answer using my mathematical knowledge. Let's assume we have a complex multivariable function, which is directly or indirectly dependent on various variables; such that we can draw an arbitrary directed acyclic graph using the variables which affect the function. To visualize the situation, let's consider the following example diagram: Here $F$ is a function of $F(X,Y,Z)$, $X$ is a function of $X(B,D)$, $Y$ is a function of $Y(C)$ and $Z$ is a function of $Z(X)$; in general, each variable is dependent on its parents directly. Much more simple tree diagrams are common in resources about multivariable chain rule and I am familiar with them. But I cannot justify the following problem: Assume that, in such a hierarchy of variables, where $F$ is the final function which is being evaluated (which is nicely smooth), we want to take the total derivative of $F$ with respect to a variable in the hierarchy; let's name this variable $Q$. By the total derivative, I mean that I am going to perturb $Q$ and look how $F$ is going to change, without holding other variables fixed, in contrast to a partial derivative. So, we are going to evaluate $\dfrac{dF}{dQ}$. I can show by induction that this is equal to $\sum_{i}\dfrac{dF}{dP_i}\dfrac{\partial P_i}{\partial Q}$ where the sum runs on the variables which directly depends on $Q$ and where I evaluate the total derivative with respect to such variables. Let's assume we have another variable, say $W$, in this hierarchy. For regular partial derivatives, the order of differentiation does not matter. I want to learn that whether this holds for this case as well, where we have $\dfrac{d^2F}{dWdQ}$ and $\dfrac{d^2F}{dQdW}$. If I take the total derivative twice, in different orders, will I obtain the same result? I tried to show this by using induction and succeeded in some simple examples, but I cannot generalize this for an arbitrary hierarchy of variables.","['partial-derivative', 'calculus', 'multivariable-calculus', 'derivatives']"
1273623,How many ways are there to express a number as the product of groups of three of its factors?,"Specifically, I am thinking of a cuboid with a given volume ($28\,000$) that has sides of integer length. For example, $20 \cdot 20 \cdot 70 = 28\,000$, but so do $10 \cdot 40 \cdot 70$ and $1 \cdot 1 \cdot 28\,000$. I am interested in finding how many possible integer combinations of side lengths there are that produce this volume . Its prime factorisation is $2^5 \cdot 5^3 \cdot 7$, so I think that the answer may have something to do with permutations of those. The order of the three groups does matter because there is a distinction between it being height, width or length.","['volume', 'prime-factorization', 'combinatorics']"
1273634,Intuition behind direction of maximum variance?,"I'm trying to understand the phrase ""direction of maximum variance"" which keeps popping up in the context of PCA. For example, in this set of 2D points, it is clear they approximately lie on a line. If I could only choose one dimension on which to represent these points it would be that line -- but why does that make this line the direction of maximum variance?","['statistics', 'linear-algebra']"
1273635,RSA cryptography?,"I understand how RSA cryptosystem works; however, I am not sure how to apply it to answer these questions. Can someone explain please? Let $N=3869$ and be equal to the product of two distinct, unknown, odd prime numbers $p$ and $q$ such that $(p−1)(q−1)$ is not divisible by $3$. Show that there are exactly nine messages which are unchanged by RSA encryption using the public key $(N, 3)$. Also explain how to find $p$ and $q$ if at least four of these messages are known. I understand and have worked out how to show the first part.  However, I do not understand part 2. Can I get some help please?","['cryptography', 'discrete-mathematics']"
1273645,Promissory note example Financial Math,"Brenda owes Cathy $\$8500$ and has signed a promissory note to repay the debt in 15 months from the signing date. The note was signed on December 6, 2009, and the maturity value of the note is $\$10043.55$ . Cathy decides to sell the note to a bank on May 6, 2010. If the bank wishes to earn $r = 8\%$ . What price does Cathy receive for the note? I got the answer $$P = 10043.55 (1 + 0.08 (304/365))^{-1}$$ by using the formula provided to me which is $P = (1+r(n/365))^{-1}$ for the bank's payment using $n$ as the amount of days left until maturity, and $r$ is the bank's interest rate at discount. Is this correct?","['finance', 'algebra-precalculus', 'functions']"
1273650,A problem about abelian group,"Given a group $G$, let $G_m$ be the group generated by the set $S=\{g^m|g\in G\}$. Prove that if $G_m$ and $G_n$ are both abelian, then $G_{\gcd(m,n)}$ is also abelian.","['abstract-algebra', 'group-theory', 'abelian-groups']"
1273663,Interchange of expectation and summation,"Assume $(\Omega,\mathscr{F},P)$ is a probability space and $\{X_n\}_{n\geq 1}$ is a sequence of random variables. Let $\{A_n\}_{n\geq 1}$ be a measurable partition of $\Omega$. My question is when the following equality holds:$$E\Big(\sum_{n=1}^\infty X_n1_{A_n}\Big)=\sum_{n=1}^\infty E\big(X_n1_{A_n}\big).$$ Of course, if $\sup_n|X_n|\leq X$ for some integrable $X$, then this is just an implication of dominated convergence theorem. My question is whether this is still true if $\sup_n X_n\leq X$ for some $X$ with $E(X)<+\infty$ if we allow $-\infty$ for expectation? Thanks!","['probability-theory', 'probability', 'expectation']"
1273674,Coin Flips and Hypothesis Tests,"Here's a problem I thought of that I don't know how to approach: You have a fair coin that you keep on flipping. After every flip, you perform a hypothesis test based on all coin flips thus far, with significance level $\alpha$, where your null hypothesis is that the coin is fair and your alternative hypothesis is that the coin is not fair. In terms of $\alpha$, what is the expected number of flips before the first time that you reject the null hypothesis? Edit based on comment below: For what values of $\alpha$ is the answer to the question above finite? For those values for which it is infinite, what is the probability that the null hypothesis will ever be rejected, in terms of $\alpha$? Edit 2: My post was edited to say ""You believe that you have a fair coin."" The coin is in fact fair, and you know that. You do the hypothesis tests anyway. Otherwise the problem is unapproachable because you don't know the probability that any particular toss will come up a certain way.","['hypothesis-testing', 'probability', 'statistics', 'expectation']"
1273678,$\frac{d\Phi^{-1}(y)}{dy} = \frac{1}{\frac{d}{dy}[\Phi(\Phi^{-1}(y))]}$?,"If $\Phi(y)$ is a monotonic decreasing function is true that $$\frac{d\Phi^{-1}(y)}{dy} = \frac{1}{\Phi'(\Phi^{-1}(y))}$$ If so, how? It works for $y = \Phi(x) = e^{-x}, \quad \Phi^{-1}(y) = -log(y), \quad \frac{d\Phi^{-1}(y)}{dy} = \frac{-1}{y}, \quad $","['inverse', 'calculus', 'derivatives']"
1273690,"When $p=3 \pmod 4$, show that $a^{(p+1)/4} \pmod p$ is a square root of $a$","Let $a$ and $p$ be integers such that $p$ is prime, and $a$ is a square modulo $p$.
When $p\equiv3\pmod4$, show that $a^{(p+1)/4}\pmod p$ is a square root of $a$. Why does this technique not work when $p\equiv1\pmod4$? This is a question that appeared on a past exam paper for Cryptography at Undergraduate level. I think it might have something to do with the Legendre Symbol:
$(\frac{-1}{p})  =\begin{cases}
1 & \mbox{ if }p \equiv 1\mod{4} \\
-1 & \mbox{ if }p \equiv 3\mod{4}.  
\end{cases}$ But I cannot seem to make the connection here. I have also thought about the use of Euler's criterion $a^{(p-1)/2} \equiv (\frac{a}{p}) \equiv 1 \pmod p.$ But that does not mean $a^{(p-1)/4}$ is a square root of $a$. Could anyone hint me please on the direction I should take? Thanks in advance!","['legendre-symbol', 'number-theory', 'elementary-number-theory']"
1273702,Evaluate $\lim_{x \to \infty} \sqrt{x} \sin(\frac{1}{x})$,I am trying to evaluate $\lim_{x \to \infty} \sqrt{x} \sin(\frac{1}{x})$. I have been taught that L'Hopital's Rule is only valid for fractions $\frac{f(x)}{g(x)}$ which have the form where $f(x) = g(x) = 0$ or where $g(x) = \pm \infty$ and $f(x)$ is anything. Right away I notice that this limit evaluates to $\infty \cdot 0$. I need to put this in either the $\frac{0}{0}$ or the $\frac{\text{anything}}{\pm \infty}$ form to use L'Hopital's rule. So I write $\sqrt{x} \sin(\frac{1}{x}) = \frac{\sin(\frac{1}{x})}{\frac{1}{\sqrt{x}}}$ to get it in the $\frac{\text{anything}}{\pm \infty}$ form. Executing L'Hopital's Rule I find $\lim_{x \to \infty} \sqrt{x} \sin(\frac{1}{x}) = \lim_{x \to \infty} \frac{2\cos(\frac{1}{x})}{\sqrt{x}} = \frac{0}{\infty}$ but this is yet another undetermined form is it not? It seems fairly obvious to me that the limit here is zero but also that we have an undetermined form. Do I have to keep doing rounds of L'Hopital's Rule?,"['calculus', 'real-analysis', 'limits']"
