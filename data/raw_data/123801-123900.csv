question_id,title,body,tags
1868331,Is it possible / allowed to use L'Hôpitals rule for products?,"In our readings, we had L'Hôpitals rule and defined it like that: $\lim_{x\rightarrow x_{0}}\frac{f'(x)}{g'(x)}$ Because we had it in our readings, we are allowed to use this to find limit of functions. Now my question is, is it possible to use this rule for products? If yes, do you think I would be allowed to do it (since we have dicussed this rule in our reading...)? Actually, a fraction is a product at the same time, isn't it? Because we can also write: $\lim_{x\rightarrow x_{0}}f'(x)*\frac{1}{g'(x)}$ and it would be called product, or am I totally wrong here? How would you use L'Hôpitals rule for products? Possible at all?
I could imagine it has something to do with fraction and reciprocal.
But not sure about that.","['functions', 'calculus', 'analysis']"
1868341,conditional probability on zero probability events and conditional Radon-Nikodym derivatives,"Consider a stochastic process $\{x_t\}_{t\in T}$ adapted to some filtered probability space $(\Omega,\mathcal{F},\{\mathcal{F}\}_{t\in T},\mathbb{P})$ taking values in the state space $(\mathbb{R},\mathcal{B})$ I wish to consider the probability Pr$(x_t\in\mathcal{A}|x_s)$ where $(s<t)$ This should be a sensible question, as I should be able to assign probability to a question of the form ""What is the chance I obtain an outcome $x_t \in [0.5,0.6]$ given that last time I got $x_s=0.4$"". e.g. a transition probability. Naturally we have Pr$(A| B)=$Pr$(A\cap B)/$Pr$(B)$ but then we have Pr$(B)=$Pr$(x_s)=0$ for any particular value. Now I think that this is where we have the notion of regular conditional probability entering which, as I understand it means we write: $$\text{Pr}(x_t\in \mathcal{A}|x_s=B)=\lim_{\mathcal{B}\to B}\frac{\text{Pr}(x_t\in \mathcal{A}\cap x_s \in \mathcal{B})}{\text{Pr}(x_s\in \mathcal{B})}$$ Vagaries of the meaning of $\lim_{\mathcal{B}\to B}$ aside (which would have to be implementation specific e.g. here $\lim_{r\to 0} \text{Pr}(x_s\in (B-r,B+r)$), is the above correct? Should I understand this as a Radon Nikodym derivative? It seems related, but not identical. How do I relate this to, and formulate it in such a way to be consistent to, how conditional probabilities are usually defined? (as I understand it) viz $$\text{Pr}(x_t\in\mathcal{A}|x_s\in\mathcal{B})=\mathbb{E}_{\mathbb{P}}[1_{\mathcal{A}}(x_t)|\sigma(\mathcal{B})\subseteq\mathcal{F}_s]$$ Surely $$\mathbb{E}_{\mathbb{P}}[1_{\mathcal{A}}(x_t)|\sigma({B})]$$ just wouldn't work? i.e. $\sigma(B)\nsubseteq\mathcal{F}$? Is it legitimate to construct Radon-Nikodym derivatives out of measures formed from regular conditional probabilities? i.e. is this (heuristically) ok? $$\frac{d\mathbb{P}(x_t|x_s=B)}{d\mathbb{Q}(x_t|x_s=B)}=\lim_{\mathcal{A}\to\emptyset}\lim_{\mathcal{B}\to B}\frac{\mathbb{P}(x_t\in\mathcal{A}|x_s\in\mathcal{B})}{\mathbb{Q}(x_t\in\mathcal{A}|x_s\in\mathcal{B})}$$ Thanks. EDIT: Based on discussion in the comments, the issues appears to boil down to why one can write $$\text{Pr}(x_t\in \mathcal{A}|B)=\mathbb{E}_{\mathbb{P}}[1_{\mathcal{A}}(x_t)|\sigma({B})]$$ when $B$ is a zero probability event. What I don't understand is what the sigma algebra generated by a zero probability event looks like and why you can condition on it. Surely the sigma algebra generated by a zero probability event is itself formed from (complements and unions of) zero probability events in $\mathbb{P}$, thus not in $\mathcal{F}$ e.g. $$\sigma(x_s=B)=\{\omega,\omega^c,\emptyset,\Omega\}\nsubseteq\mathcal{F}$$
with $\mathbb{P}(\omega)=0$ such that $\mathbb{E}_{\mathbb{P}}[f(x_t)|\sigma({B})]=\mathbb{E}_{\mathbb{P}}[f(x_t)]$ or $0$? so why can we condition on these? What am I getting wrong here?","['stochastic-processes', 'probability-theory', 'probability']"
1868345,Quotient ring of Gaussian integers $\mathbb{Z}[i]/(a+bi)$ when $a$ and $b$ are NOT coprime,"The isomorphism $\mathbb{Z}[i]/(a+bi) \cong \Bbb Z/(a^2+b^2)\Bbb Z$ is well-known , when the integers $a$ and $b$ are coprime. But what happens when they are not coprime, say $(a,b)=d>1$? — For instance if $p$ is prime (which is not coprime with $0$) then
$$\mathbb{Z}[i]/(p) \cong \mathbb{F}_p[X]/(X^2+1) \cong
\begin{cases}
\mathbb{F}_{p^2} &\text{if } p \equiv 3 \pmod 4\\
\mathbb{F}_{p} \times \mathbb{F}_{p} &\text{if } p \equiv 1 \pmod 4
\end{cases}$$
(because $-1$ is a square mod $p$ iff $(-1)^{(p-1)/2}=1$). — More generally, if $n=p_1^{r_1} \cdots p_m^{r_m} \in \Bbb N$, then 
each pair of integers $p_j^{r_j}$ are coprime, so that by CRT we get
$$\mathbb{Z}[i]/(n) \cong \mathbb{Z}[i]/(p_1^{r_1}) \times \cdots \times \mathbb{Z}[i]/(p_m^{r_m})$$ I was not sure how to find the structure of $\mathbb{Z}[i]/(p^{r}) \cong (\Bbb Z/p^r \Bbb Z)[X] \,/\, (X^2+1)$ when $p$ is prime and $r>1$. — Even more generally, in order to determine the structure of $\mathbb{Z}[i]/(a+bi)$ with $a+bi=d(x+iy)$ and $(x,y)=1$, we could try to use the CRT, provided that $d$ is coprime with $x+iy$ in $\Bbb Z[i]$. But this is not always true: for $d=13$ and $x+iy=2+3i$, we can't find Gauss integers $u$ and $v$ such that $du + (x+iy)v=1$, because this would mean that $(2+3i)[(2-3i)u+v]=1$, i.e. $2+3i$ is a unit in $\Bbb Z[i]$ which is not because its norm is $13 \neq ±1$. — I was not able to go further. I recall that my general question is to known what $\mathbb{Z}[i]/(a+bi)$ is isomorphic to , when $a$ and $b$ are integers which are not coprime (for instance $a=p^r,b=0$ or $d=(a,b) = a^2+b^2>1$). Thank you for your help!","['gaussian-integers', 'abstract-algebra', 'algebraic-number-theory', 'ring-theory', 'commutative-algebra']"
1868383,"Problem with proof of $H \cap K $ is of finite index if $ H,K$ are finite index subgroups","I came across a proof earlier for a solution to a Herstein Topics in Algebra question earlier that I'm not convinced with, from AOPS site. If $G$ is a group and $H,K$ are two subgroups of finite index in $G$, prove that $H \cap K$ is of finite index in $G$. Can you find an upper bound for the index of $H \cap K$ in $G$? Since $[G:H]$ and $[G:K]$ are finite we can write:
$$G = Hx_{1} \cup Hx_{2} \cup \cdots \cup Hx_{r}$$
and
$$G = Ky_{1} \cup Ky_{2} \cup \cdots \cup Ky_{s}$$ where $[G:H]=r$ and $[G:K]=s$. Therefore, \begin{align*}
 G = G \cap G &= (Hx_{1} \cup Hx_{2} \cup \cdots \cup Hx_{r}) \cap (Ky_{1} \cup Ky_{2} \cup \cdots \cup Ky_{s}) \\
              &= \bigcup_{\substack{1 \le i \le r \\ 1 \le j \le s}} (Hx_{i} \cap Ky_{j}).
\end{align*}
Hence, we need to consider the sets $Hx_{i} \cap Ky_{j}$ in the union. Suppose $Hx_{i} \cap Ky_{j} \neq \varnothing$ so that for some $g \in G$,  $g \in Hx_{i} \cap Ky_{j}$. As right cosets in $G$ we have $Hg = Hx_{i}$ and $Hg = Ky_{j}$, so that we can write $Hg \cap Kg = Hx_{i} \cap Ky_{j}$. A small argument, set theoretical in nature, can show that $Hg \cap Kg = (H \cap K)g$. That is, $Hx_{i} \cap Ky_{j} = Hg \cap Kg = (H \cap K)g$ so each $Hx_{i} \cap Ky_{j}$ is either $\varnothing$ or some coset of $H \cap K$ in $G$. Since
$$G = \bigcup_{\substack{1 \le i \le r \\ 1 \le j \le s}} (Hx_{i} \cap Ky_{j})$$
is a finite union, $Hx_{i} \cap Ky_{j}$ is either $\varnothing$ or some coset of $H \cap K$ in $G$ we know every coset of $H \cap K$ appears in this union as cosets are either equal or disjoint and their union fills out all of $G$. We can conclude not only $[G:H \cap K]$ is finite but also
$$[G:H \cap K] \le [G:H][G:K]$$
since there are at most $[G:H][G:K]$ sets $Hx_{i} \cap Ky_{j}$. The problem Im having is with the part saying ""Suppose $Hx_{i} \cap Ky_{j} \neq \varnothing$ so that for some $g \in G$,  $g \in Hx_{i} \cap Ky_{j}$. As right cosets in $G$ we have $Hg = Hx_{i}$ and $Hg = Ky_{j}$, so that we can write $Hg \cap Kg = Hx_{i} \cap Ky_{j}$"" I understand that any two cosets of the same subgroup are either equal or disjoint, but why should this hold for 2 different subgroups? e.g. consider the integers under addition. ${4n}, {3n}$ are subgroups but the cosets ${4n+1}, {3n+1}$ only have some elements in common. So if someone could explain why/if we can conclude $Hx_{i}$, $Ky_{j}$ must equal the same coset $Hg$ it would be appreciated. (I understand alternative solutions exist to this on MSE but I was wandering about this proof specifically).","['abstract-algebra', 'group-theory']"
1868384,"Questions on color theory, expressed in linear algebra","I'm reading into color theory and there were a few questions which I asked myself along the way, maybe you can put me forward to some source where I can find answers or give them directly. The following paragraph contains some context, I'll try to summarize everything in purely mathematical terms below. The human eye has three main types of color reception cells (one for reddish light, one for greenish light and one for blueish light).  So every source of light (monochromatic, i.e. single wavelength, or not) induces a state in those cells, which can be described as a three tuple of non-negative, real numbers and it is assumed that this transition works semi-linearly, i.e. adding two sources of light induces the sum of the states induced by the single sources of light and same with multiplying by non-negative scalars.  I call this transition $T:S\rightarrow{\bf R}^3_{\ge 0}$ where $S$ is the space of spectral power distributions.  In the 1930s, as far as I understood, they didn't know exactly how $T$ looked like, so in order to build up a color space in accordance with human perception, they fixed three monochromatic sources of reg, green and blue light (they chose those wavelengths which were most easy to reproduce physically) and let a user mix it together in order to match the color of an arbitrary given monochromatic source of light.  This was not always possible, so they allowed the user to choose negative values for the primaries, which meant that instead of adding the wavelength to the mixture, it was added to the given source.  They succeeded to match every wavelength in the visible spectrum and took those values as a base of a first color space.  Again you get a semi-linear transition $T':S\rightarrow{\bf R}^3$ but this time non-negative values are included, yet it's not surjective on ${\bf R}^3$ .  What they did then was to choose a linear isomorphism which takes $T'(S)$ to ${\bf R}^3_{\ge 0}$ , so they can describe colors using non-negative values only. So in pure terms, there is the semi-linear space $S$ of spectral power distributions (which one can safely think as ${\bf R}^n_{\ge 0}$ for some large $n$ ) and a semi-linear transformation $T:S\rightarrow{\bf R}^3_{\ge 0}$ which is in general not known.  Also there are 'wavelengths' $p_1,p_2,p_3\in S$ and a semi-linear transformation $T':S\rightarrow{\bf R}^3$ such that for every $s\in S$ we have, denoting ${\sf max}(x,0)$ by $x^+$ and $(-x)^+$ by $x^-$ , the following: \begin{equation*}\tag{*}T(\sum_i T'(s)^+_i p_i)=T(s+\sum_i T'(s)^-_i p_i)\end{equation*} My questions related to this: Can we derive $T$ (or some of its properties) from $T'$ and (*)? Assuming we know $T$ , are there other triples of wavelengths which make this procedure possible, and if yes, What are their properties purely in terms of $T$ ? How does $T'(S)$ look like (geometrically) and How should it look like so we can find a linear isomorphism taking it to ${\bf R}^3_{\ge 0}$ ? My thoughts so far: (1) Here it helps to think the codomain of $T$ as whole ${\bf R}^3$ , then one can easily derive $T(s)=\sum_i T'(s)_i T(p_i)$ or equivalently $T=M\circ T'$ where $M$ is the $3\times 3$ -matrix $(T(p_1),T(p_2),T(p_3))$ .  If $T(S)$ is $3$ -dimensional, i.e. the set is not contained in a $2$ -dimensional subspace (which I assume), then $M$ is full rank, hence $T'$ is indeed semi-linear and we have that vice versa every full rank matrix $M$ with $M(T'(S))\subseteq{\bf R}^3_{\ge 0}$ produces a permissible $T$ which satisfies (*) via $T=M\circ T'$ . (2), (3) Constructing $T'$ should be possible for every triplet $p_1,p_2,p_3$ such that the $T(p_i)$ are linearly independent. (4) I realized that the semi-linearly closed subsets of ${\bf R}^n$ equal exactly the convex subsets which are closed under non-negative scalar multiplication.  For semi-linearly closed subsets of ${\bf R}^n_{\ge 0}$ these correspond exactly with the convex subsets of the $(n-1)$ -simplex (via projection along the semi-rays through the origin). (5) My intuition is that for a semi-linearly closed and topologically closed subset $A\subseteq{\bf R}^n$ , there exists a linear isomorphism taking it to ${\bf R}^n_{\ge 0}$ if and only if and only if there is no point $x\neq 0$ with $x,-x\in A$ . If someone can confirm my thoughts, they are encouraged to put them in an answer!","['reference-request', 'physics', 'book-recommendation', 'linear-transformations', 'linear-algebra']"
1868398,Number of equivalence classes based on a relation regarding a non-principal ultrafilter,"We have an equivalence relation on $\mathbb{N}^\mathbb{N}$ given by $$f\equiv g \iff \{n\in\mathbb{N}: f(n)=g(n)\}\in\mathbb{U},$$ where $\mathbb{U}$ is a non-principal ultrafilter on $\mathbb{N}$. The question is to find the cardinality of the set of all equivalence classes. My guess would be $2^{\aleph_0}$, but, well, it is just a guess. I don't really know how to tackle this exercise, not even where to start... What we know, I believe, is that all the sequences which differ on all the places but for one, are in separate equivalence classes (because the ultrafilter is non-principal). On the other hand, there might not be a $2$-element set in $\mathbb{U}$ as well, or $3$-element, $4$-element etc., which would give me that there are at most 
$$\sup_\limits{n\in\omega}\aleph_0^n = \aleph_0^{\aleph_0}=2^{\aleph
_0}$$
equivalence classes (I count all the combinations of $n$-element sets). Hence my guess. Could be wrong though. Do you have any ideas?","['model-theory', 'filters', 'cardinals', 'elementary-set-theory']"
1868399,Polar coordinates for vector field to find sticking flow,"I am currently working on an impacting system which is basically just a spring damper and a circular enclosure. Because of the rotational symmetry of the problem I need the vector field in polar coordinates to derive the sticking flow along the enclosure. It should be an easy problem, but contrary to my expectation there are no scores of textbooks which contain the solution and I am not used to mechanical problems. The system in Cartesian coordinates is the following:
$$
\left(
\begin{array}{c}
 \dot{x} \\
 \ddot{x} \\
 \dot{y} \\
 \ddot{y} \\
\end{array}
\right)= \left(
\begin{array}{cccc}
 0 & 1 & 0 & 0 \\
 -\nu^2 & -\gamma & 0 & 0 \\
 0 & 0 & 0 & 1 \\
 0 & 0 & -\nu^2 & -\gamma \\
\end{array}
\right)
\left(
\begin{array}{c}
 x \\
 \dot{x} \\
 y \\
 \dot{y} \\
\end{array}
\right)
$$ I have replaced $x$, $y$ and their derivatives by $x=r \cos(\theta)$, $y=r \sin(\theta)$ and their derivatives as was also done in this question .
Solving for $\ddot{r}$ and $\ddot{\theta}$ I obtained
$$
\ddot{r}= -r \nu ^2-\gamma  \dot{r}+r \dot{\theta} ^2
$$
and 
$$
\ddot{\theta}=-\frac{\left(r \gamma +2 \dot{r}\right) \dot{\theta}}{r}
$$
which I verified with mathematica. But when I test using the following Matlab-code nu2=1.96; gam=0.28;
ODE1=@(t,z) [0 1 0 0;-nu2 -gam 0 0;0 0 0 1;0 0 -nu2 -gam]*z;
ODE2=@(t,z) [z(2); 
            -nu2*z(1)-gam*z(2)+z(1)*z(4)^2; 
             z(4); 
            -z(4)*(gam*z(1)+2*z(2))/z(1)];
z0=[1;0;1;0.5];
tspan=[0, 1];
z0p=[1.4142 0.3536 0.7854 0.3536];
[T1,Z1]=ode45(ODE1,tspan,z0);
[T2,Z2]=ode45(ODE2,tspan,z0p);
Z2c=[Z2(:,1).*cos(Z2(:,3)),Z2(:,1).*sin(Z2(:,3))];
hold on
plot(Z1(:,1),Z1(:,3));
plot(Z2c(:,1),Z2c(:,2));
hold off
legend('Cartesian','Polar') I find that they are not equivalent. Now I am wondering whether there is a conceptual error as I am fairly confident in my derivation. So I am starting to think that my approach must be wrong and I would happy if someone could tell me where my error lies. Update Found the problem, answer below.","['ordinary-differential-equations', 'dynamical-systems', 'polar-coordinates']"
1868420,Limit of sequence $\lim_{n\to\infty}\frac{1+(\sqrt{n}+1)^{3}+2\sqrt{n}}{n+\sin(n)}$,"This is no homework. It's another task of a sample exam and I'd like to know how to solve it. Find the limit of $$\lim_{n\to
 \infty}\frac{1+(\sqrt{n}+1)^{3}+2\sqrt{n}}{n+\sin(n)}$$ Both numerator and denominator go towards $\infty$ for $n \rightarrow \infty$. So I have tried using L'Hôpitals rule because we got $\frac{\infty}{\infty}$. Here I had the first question in mind, shall I simplify everything before I derivate? (In most cases I think that would be very useful...?) I have tried both ways (simplify before derivate, derivate and then simplify) and both ended up in $\frac{\infty}{\infty}$ even after several derivations. Here is how I simplified it: $$\lim_{n\rightarrow \infty}\frac{n\sqrt{n}+3n+5\sqrt{n}+2}{n+\sin(n)}$$ Then I differentiated the numerator and denominator: $f'(x) = \frac{3}{2}\sqrt{n}+3+\frac{5}{2\sqrt{n}}$, $g'(x) = 1+\cos(n)$ giving $$\lim_{n\rightarrow \infty}\frac{\frac{3}{2}\sqrt{n}+3+\frac{5}{2\sqrt{n}}}
{1+\cos(n)}$$ Doesn't really help me...","['functions', 'limits', 'calculus', 'analysis']"
1868460,Construct smooth mapping $f: B^{n + 1} \to S^n$ with two singularities at which $f$ has degree $+/- 1$.,"I'm currently working through a paper by Pjotr Hajlasz who wants to show that For smooth manifolds $M,N$, if $\pi_{[p]}(N) \neq 0$ and $1 \leq p < n = \dim M$, then the smooth mappings $C^\infty(M,N)$ are not dense in $W^{1,p}(M,N)$. In his proof he asserts that ""It is easy to construct a smooth mapping $f: B^{[p]+1} \to S^{[p]}$ with two singularities such that $f$ restricted to small spheres centered at the singularities have degree +1 and -1 respectively."" How would one go about to construct or at least think about such smooth mapping? I'd appreciate any help!","['differential-topology', 'manifolds', 'smooth-manifolds', 'algebraic-topology', 'differential-geometry']"
1868483,Definition second differential of a vector field,"Let $f: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ be a smooth function.
Then we know that its differential $df: \mathbb{R}^2 \rightarrow Hom(\mathbb{R}^2,\mathbb{R}^2)$ maps vectors to matrices/linear maps. But how do we define $D^2 f$? Is it defined like $D^2f: \mathbb{R}^2 \rightarrow Hom(\mathbb{R}^2, Hom(\mathbb{R}^2, \mathbb{R}^2))$ (and in this case: how do I write it explicitly?) or is it defined like $D^2 f(y)(z,w) := D(Df(y)(w))(z)$ or like something else?
In the solutions of the problem 5.2 of this problem sheet there's this ( screenshot ). I don't understand why does $D^2f$ have two arguments, $w$ and $z$. Is it possible to generalize the whole thing for $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$? Thank you!","['differential', 'calculus', 'analysis']"
1868507,Show that the following equation has got exactly one solution for each $C>0$,"Show that the equation $$C=\left ( 1+x+\frac{1}{2}x^{2} \right)*e^{-x}$$ has got exactly one solution for each $C>0$. Alright so I did it like that but not sure if it's correct: $0<\left ( 1+x+\frac{1}{2}x^{2} \right)*e^{-x}$ |: $e^{-x}$ $0<\left ( 1+x+\frac{1}{2}x^{2} \right)$ | *$2$ $0<\left ( 2+2x+x^{2} \right)$ $0<x^{2}+2x+2$ $0 < \left ( x+1 \right)^{2}+1$ $0 < x+1+\sqrt{1}$ $x > -2$ To be honest, I'm not sure if my preparation is correct at all. ""show(...) exactly one solution for each $C>0$"" confusing me. Again, this is no homework, only practice for me.
If anyone wants I can upload the pdf (example for our exam) here.","['functions', 'calculus', 'analysis']"
1868511,Interpretation of the ratio of the derivative of a function to the function.,Let $f\colon X\to\mathbb{R}$ be a differentiable function. What is interpretation of the following quantity: $$h(x_{0}):=\frac{f'(x_{0})}{f(x_{0})}$$ where $x_{0}\in X$. My own reaserch. a) We know that $$f'(x_{0})=\lim_{h\to 0}\frac{f(x_{0}+h)-f(x_{0})}{h}$$ so $$f'(x_{0})h\approx f(x_{0}+h)-f(x_{0})$$ If we take $h=1$ we get $$f'(x_{0})\approx f(x_{0}+1)-f(x_{0})$$ so we have the following interpretation: If we increase an argument of function $f$ by 1 unit form level $x_{0}$ then the value of function $f$ will change (approximately) by $f'(x_{0})$ units. This interpretation is used in economics. b) We know that $$h(x_{0})=\lim_{h\to0}\frac{f(x_{0}+h)-f(x_{0})}{hf(x_{0})}$$ so $$h(x_{0})h\approx \frac{f(x_{0}+h)-f(x_{0})}{f(x_{0})}$$ and if we take $h=1$ we obtain $$h(x_{0})\approx \frac{f(x_{0}+1)-f(x_{0})}{f(x_{0})}$$ How can we interpret this quantity?,"['derivatives', 'calculus', 'limits']"
1868543,Infinitely many primes $\equiv 3 \mod 4$,"Question 1 Is the following proof of the infinitude of primes $\equiv 1\mod 4$ okay? Consider a prime divisor $p\mid (n!)^2+1$. Then $(n!)^2\equiv -1 \mod p$, hence $n!$ has multiplicative order $4$ in $\Bbb F_p^\times$ (question: is this conclusion true? what did I use here?) . Thus $n!\in \Bbb F_p^\times$ generates a subgroup of order $4$ and by Lagrange, $4\mid p-1$, i.e. $p\equiv 1\mod 4$. Now we do the same thing, replacing $n$ by $p$. This will give a new prime $\equiv 1\mod 4$ and this prime is bigger than $p$ (otherwise it would divide $1$). Question 2 My lecture notes say that from this one can conclude that there are infinitely many primes $p\equiv 3\mod 4$ by considering $n!-1$, which leaves remainder $3$ upon division by $4$. How does this imply infinitude of such primes?","['abstract-algebra', 'elementary-number-theory']"
1868601,Is a measure on product space necessarily a product of measures?,"Let $X,Y$ be some nice measureable spaces (i'm interested in $[0,1]$ so we can assume compact, etc.). let $\mu$ be a measure on $X\times Y$.(again, assume it's nice, i.e. probability measure. anything else needed? Are there necessarily measures $\mu_1,\mu_2$ on $X,Y$ resp. such that $\mu=\mu_1\times\mu_2$? I thought it is a reasonable conjecture, but i couldn't prove it.
My intuition is the lebesgue [/haar] measure, for which the answer is obviously true.
I thought one could define $\mu_1(A)=\mu(A\times Y)$ and reps. $\mu_2$, but I couldn't show it would be a good construction (it is good for lebesgue, though). EDIT - only this is now relevant : thanks guys. But now i'm slightly confused, as I saw in a paper the terminology ""projection of a measure"", which is supposed to be some measure on XX derived from the measure on $X\times Y$. this must be something like the pushforward measure by projection, which is μ1μ1 that I defined here if i'm not wrong. I think that the paper does not really require the measure to be the product of those (which I now understand is not true), but perhaps satisfy some kind of a fubini identity $\mu(A)=\int\mu_1(A^y)d\mu_2(y)$ ? is that necessarily true? , (under nice enough conditions) The goal is to deduce properties of μ from the projections, so what could be true?","['lebesgue-measure', 'measure-theory']"
1868615,Handelman's Theorem on Nonnegative polynomial in Compact Polytope?,"Background: Representing polynomials by positive linear functions on compact convex polyhedra by David Handelman Consider a polynomial $f\in K[x_1,\ldots,x_n]$ in a compact polytope, related question on trying to formulate the polytope algebraically, where each variable $x_i$ is defined in some compact set such as $x_1\in [0.2,0.5]$. Example 1: is $f$ non-negative in $K$? Yes for $f_1$, no for $f_2$. $f_1[x_1,x_2,x_3]=x_3-x_1 x_2$ $f_2[x_1,x_2,x_3]=x_3x_2-x_1$ \begin{eqnarray*}
x_{1} & \in & [0.2,0.5]\\
x_{2} & \in & [0,1]\\
x_{3} & \in & [1,1]
\end{eqnarray*} Example 2: is $f(x_{1},x_{2})=x_{1}-x_{2}$ positive on the polytope $K$ restricted by the intervals? The answer is no in the example below but how do we use Handelman's theorem on this? \begin{eqnarray*}
0.1<x_{1}<0.5 & \Leftrightarrow & x_{1}>0.1,-x_{1}>-0.5\\
0.2<x_{2}<1 & \Leftrightarrow & x_{2}>0.2,-x_{2}>-1\\
 & \Rightarrow & \begin{cases}
\beta_{1}=x_{1}-0.1\\
\beta_{2}=-x_{1}+0.5\\
\beta_{3}=x_{2}-0.2\\
\beta_{4}=-x_{2}+1
\end{cases}
\end{eqnarray*} where $\{\beta_i\}=\{\beta_1,\beta_2,\beta_3,\beta_4\}$ and we guess the right ""positive
  linear combination of products of members of $\{\beta_i\}$"" (but it may not easy to come up with it) \begin{eqnarray*}
f & = & a\beta_{1}+b\beta_{2}+c\beta_{3}+d\beta_{4}\\
 & = & a(x_{1}-0.1)+b(-x_{1}+0.5)+c(x_{2}-0.2)+d(-x_{2}+1)\\
 & = & x_{1}(a-b)+x_{2}(c-d)+(-0.1a+0.5b-0.2c+d)\\
 & \underset{f_{1}}{=} & x_{1}-x_{2}\\
 & \Rightarrow & a-b=1,c-d=-1,-0.1a+0.5b-0.2c+d=0\\
 & \Rightarrow & \begin{cases}
b-a=c-d\\
0.9a-0.5b+0.8c+d=0
\end{cases}\Rightarrow\begin{cases}
d=c+a-b\\
0.9a-0.5b+0.8c+d=0
\end{cases}\\
 & \Rightarrow & 0.9a-0.5b+0.8c=0
\end{eqnarray*} where the positivity actually means that $a,b,c,d\geq 0$ and all values of $a,b,c,d$ cannot be zero at the same time. Since $a-b=1\Rightarrow a=1,b=0$ (only case satisfying this). $c-d=-1$ so $c=0,d=1$ (similar as earlier). So $$-0.1a+0.5b-0.2c+d=0 \Leftrightarrow 1+4b+8d=0$$ which cannot be true since $b,d$ are not negative. So no function $f$ exists in the basis so by Handelman's theorem f is not non-negative in the polytope restricted by the inequalities. No positive linear combination of products of members of $\{\beta_i\}$ terms can express $x_1-x_2$ so $f$ is not non-negative. How can I computationally check the condition on the positivity? I. Macaulay2 example with hand-on examples and trying to define the ideal for the intervals error here . Define quotient ring for the $\{\beta_i\}$ (originating from inequalities)? R=RR[x1,x2];
f=x1-x2;
intervals=ideal(x1-0.1,-x1+0.5,x2-0.2,-x2+1);     
f%intervals
i4 : f%intervals
o4 = 0
o4 : R and verified with R2=RR[x1,x2]/(x1-0.1,-x1+0.5,x2-0.2,-x2+1);
f2=x1-x2

i11 : f2
o11 = 0
o11 : R2 that is a contradictive result: we showed that $x_1-x_2$ on $K$ can be expressed as a positive linear combination of products of members of $\{\beta_i\}$, did we? We know by the Handelman's theorem that this should not be possible -- $x_1-x_2$ is negative when $x_1=0.1$ and $x_2=1$ so we should not be able to express it in terms of the products. Numeric notice in dealing with numeric real values, I_0+I_2==f should be true (but false because of the small $\epsilon=-5.55112e-17$) i35: R=RR[x1,x2];f=x1+x2-0.3;I=ideal(x1-0.1,-x1+0.5,x2-0.2,-x2+1); I_0+I_2 - f 
o34=  -5.55112e-17 so with exact arithmetics i1 : R=RR[x1,x2];f=x1+x2-3/10;I=ideal(x1-1/10,-x1+1/2,x2-1/5,-x2+1); I_0+I_2 - f    
o3 : Ideal of R
o4 = 0
o4 : R II. Mathematica where PolynomialReduce but cannot find a way to specify that each quotient term positive and remainder zero. How does Handelman's Theorem work to check non-negativity of $f$ in some compact polytope?","['algebraic-geometry', 'polytopes']"
1868623,Trigonometry Olympiad problem: Evaluate $1\sin 2^{\circ} +2\sin 4^{\circ} + 3\sin 6^{\circ}+\cdots+ 90\sin180^{\circ}$,"Find the value of
  $$1\sin 2^{\circ} +2\sin 4^{\circ} + 3\sin 6^{\circ}+\cdots+ 90\sin180^{\circ}$$ My attempt I converted the $\sin$ functions which have arguments greater than $90^\circ$ to $\cos$ but I have gone no where with it! I also tried using double angle formula for the angles which are even.","['trigonometry', 'sequences-and-series', 'closed-form']"
1868634,Which primes $p$ divide $q^q-1$ for a prime divisor $q$ of $p-1$,"I am looking for (a formula) for all the primes $p$ less than or equal to $X$ with the following criteria: There is at least one prime $q$ dividing $p-1$ such that $p$ divides $q^q-1$. $7$, for example is not one of these primes since $7$ does not divide $2^2-1$ or $3^3-1$. $11$ is a good example since $11$ divides $2^2-1$ or $5^5-1$. What primes $p$ are these less than $1000$ for example. Thanks for helping.","['number-theory', 'prime-numbers']"
1868656,Very strange - what's the limit of $\lim_{x \rightarrow 0}\frac{sin(x)+cos(x)}{x}$?,"What's the limit of: $\lim_{x \rightarrow 0}\frac{sin(x)+cos(x)}{x}$ ? $\lim_{x \rightarrow 0} \left (sin(x) + cos(x) \right) = sin(0)+cos(0) = 1
$ $\lim_{x \rightarrow 0} x = 0$ $\Rightarrow \frac{1}{0} \Rightarrow$ L'Hôpital's rule is needed $f'(x) = cos(x) - sin(x)$ $g'(x) = 1$ $\Rightarrow $ $\lim_{x\rightarrow 0} \left (cos(x) - sin(x) \right ) = cos(0) -sin(0) = 1-0 = 1$ So 1 will be the limit? No way because as it looks like, the denumerator will be too small and thus the complete function will go towards $\infty$ for $x \rightarrow 0$. This is very confusing for me :S Maybe the mistake is using L'Hôpital?","['functions', 'calculus', 'analysis']"
1868657,"I don't see why $W^{1, 2}(\partial D)$ being compactly embedded in $L^2(\partial D)$ lets us show an operator is Fredholm of index zero.","Let $D$ be a bounded Lipschitz domain. Let $A$ be the single layer potential which maps $L^2(\partial D)$ into $W^{1, 2}(\partial D)$ boundedly. $A$ is given by: $$
A_D[\phi] = \int_{\partial D}G(x-y)\phi(y) d\sigma(y), \quad x \in \mathbb{R}^3,
$$ where $G$ is the fundamental solution of the Laplacian. Now as $W^{1, 2}(\partial D)$ is compactly embedded in $L^2(\partial D)$ we have that $A$ is Fredholm of index zero. I don't see how we can say this operator is Fredholm of index zero based on the given information? To show it is Fredholm of index zero we must show that $A$ is a bounded linear operator The range of $A$ is closed in $W^{1, 2}(\partial D)$. The subspaces $\ker(A)$ and $\text{coker}(A)$ are finite-dimensional. The dimensions of $\ker(A)$ and $\text{coker}(A)$ are the same. We have point 1. by the definition of $A$, but I don't see how the statement $W^{1, 2}(\partial D)$ is compactly embedded in $L^2(\partial D)$ gives us points 2. - 4? Just to mention I am unfamiliar with compact embedding but from reading up on definitions of it I don't see how it gives us points 2. - 4.? Edit :
$A$ is actually a single layer potential but I left that out to simplify the question. My question comes from the proof of Theorem 2.13 in this book on page 29.","['functional-analysis', 'compact-operators', 'sobolev-spaces', 'operator-theory']"
1868675,How to explain this contradiction about Weyl group of $SL_n(K)$?,"I have some difficulties in understanding why the Weyl group of algebraic group $SL_n(K)$ is isomorphic to symmetric group $S_n$. Let $G=SL_n(K)$ be the simply-connected algebraic group over the algebraic closed filed $K$ with $charK>2$. Also let $T$ be the maximal tori of $G$ consists of diagonal matrices with determinant 1. In this case, we have $W=N_G(T)/T$ is the Weyl group of $G$ in which $N_G(T)$ is the group of generalized permutation matrices with determinant 1. On the other hand, it is well-known that Weyl group of $G$ is isomorphic to symmetric group on $n$ letters. Hence $N_G(T)/T\cong S_n$. Addendum and Edition: Now let $S\in N_G(T)$ be corresponding to the cycle $(1~~ 2)\in S_n$. Considering the action of $S$ on $diag[a_1, a_2,..., a_n]\in T$, we get $diag[a_1, a_2,..., a_n]^S=diag[a_2, a_1, a_3,..., a_n]$. Since the determinant of a permutation matrix is just the Sign of the corresponded permutation, we have $det(S)=Sign(1~~2)=-1$ , which is impossible according to $S\in N_G(T)$. This implies that $N_G(T)$ can not contain any element which is corresponded to $(1~~2)$. So how could I explain the isomorphism $N_G(T)/T\cong S_n$? I would be grateful for any help.","['abstract-algebra', 'algebraic-groups', 'group-theory', 'lie-algebras']"
1868680,"Creating unusual probabilities with a single dice, using the minimal number of expected rolls","Problem I want to create an 'event' with probability of $\frac{1}{7}$ with a single dice as efficiently as possible (to roll the dice as little as possible). To give you some better understanding of the question, if I would like an event with probability of $\frac{1}{9}$ , I could easily do it in various ways. One way is to see whether the sum of two rolls is $5$ . Another way is to roll the dice twice and see whether they are both not higher than $2$ . If I had to choose $\frac{1}{5}$ , we can do this 'trick': success on drawing $1$ , but if we draw $6$ just disregard it and roll again, until we draw a number which is not $6$ . In that case the expected number of rolls is $\frac{6}{5}$ . So, one way to get probability of $\frac{1}{7}$ is basically the same, choosing $7$ predefined ordered pairs of 2 rolls to be the success set, and disregard any other combination (and to roll the dice twice again, if other combination occurs). In that case, the expected number of dice rolls needed is $\frac{72}{7}$ which seems pretty bad to me and makes we wonder... is there a better way? Generalization In general, if we have a $k$ -sided dice what is the optimal way of obtaining an event with probability $\frac1m$ using the least expected dice rolls? And what if we want to simulate an $m$ -side dice and not just one event?","['probability', 'dice']"
1868690,"Differentiating $\int\cdots \int f(X_1,X_2,\ldots,X_n)\varphi_1(x_1,\theta)\cdots\varphi_n(x_n,\theta)~dx_1\cdots dx_n$","Differentiating:$$\int_{-\infty}^\infty \cdots \int_{-\infty}^\infty f(X_1,X_2,\ldots,X_n)\varphi_1(x_1,\theta)\cdots\varphi_n(x_n,\theta)\,dx_1 \cdots dx_n$$ with respect to $\theta$. The result is given in one line, (the next one). I do not understand how this is. (Statistics proof)
Anyway the result given being: $$\int_{-\infty}^\infty \cdots \int_{-\infty}^\infty f(X_1,X_2,\ldots,X_n) \sum_{i=1}^n \left(\frac{\partial}{\partial \theta}\varphi(x_i,\theta)\frac{1}{\varphi(x_i,\theta)}\right) \varphi_1(x_1,\theta)\cdots\varphi_n(x_n,\theta)\,dx_1\cdots dx_n$$","['derivatives', 'multivariable-calculus', 'statistics', 'probability', 'random-variables']"
1868729,Analyze if this series converges: $\sum_{n=0}^{\infty}\frac{n^{2}+1}{n!}$,"Analyze if this series converges: $\sum_{n=0}^{\infty}\frac{n^{2}+1}{n!}$ I have used ratio test: $\lim_{n\rightarrow  \infty}\left |\frac{a_{n+1}}{a_{n}}  \right |< 1$ $\Rightarrow$ $\lim_{n\rightarrow  \infty}\left | \frac{(n+1)^{2}+1}{(n+1)!}:\frac{n^{2}+1}{n!} \right | = \lim_{n\rightarrow  \infty}\frac{((n+1)^{2}+1)n!}{(n+1)!*(n^{2}+1)}$ $= \lim_{n\rightarrow  \infty}\frac{(n+1)^{2}+1}{(n+1)*(n^{2}+1)} = \lim_{n\rightarrow  \infty}\frac{n^{2}+2n+2}{n^{3}+n^{2}+n+1}$ The denominator is bigger than the enumerator, so we got $\infty > 1$ and thus the sequence will diverge. (Can I just say that or this requires an additional proof? We got a $n^{2}$ in the enumerator and a $n^{3}$ in the denominator...?) Did I do it correctly? Edit: Converges absolutely to $0$ and NOT $\infty$","['ratio', 'sequences-and-series', 'calculus', 'analysis']"
1868740,Algorithm for multiplying infinite decimals? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question What is the (best) algorithm for multiplying two real numbers based on their decimal expansions? Obviously the algorithm can't be completed but I mean an algorithm that will successively approximate it and give a rule for the $n$th decimal number.","['algebra-precalculus', 'discrete-mathematics']"
1868802,Why is multivariable continuous differentiability defined in terms of partial derivatives?,"Both in my textbook and on Wikipedia, continuous differentiability of a function $f:\Bbb R^m \to \Bbb R^n$ is defined by the existence and continuity of all of the partial derivatives.  Since there is a notion of a (total) derivative (AKA differential) for multivariable functions, I'm wondering why continuous differentiability is not defined as existence and continuity of the derivative map $Df(a)$?  Is there some reason why having existence and continuity of partials is more convenient or maybe continuity of the total derivative is too strict of a condition?","['multivariable-calculus', 'real-analysis', 'derivatives']"
1868803,"What are ""words""?","Related but not duplicate. I am reading Classical Mathematical Logic by Richard L. Epstein, page $3$ : B. Types When we reason together, we assume that words will continue to be used in the same way. That assumption is so embedded in our use of language that it's hard to think of a word except as a type , that is, as a representative of inscriptions that look the same and utterances that sound the same. ...We will assume  that throughout any particalar discussion equiform words will have the same properties of interest to logic....Briefly, a word is a type. I don't really understand what a word is. The author says it is ""a representative of inscriptions that look the same and utterances that sound the same."" Does this mean that a word is the collection (not set?) of all equiform inscriptions and utterances that have been, are, will be, will never be, written or uttered? If I write: car, car, did I just pluck out two inscriptions from an infinite collection (cars, cars, cars...)? Is each ""cars"" distinguishable while it is in the collection? Meaning, does the collection actually look like ( $\text{cars}_{\text{That will be used by Ovi on 7/23/2016}}$ , $\text{cars}_{\text{That will be used by Ovi on 7/25/2016}}$ , ...) or does each inscription become distinguishable only after it has been plucked out from the collection? This interpretation sounds a little bit platonic, which is the reason why I think it is probably wrong; the author had distinguished himself from platonics on a previous page. When I think of a word, I think that the word is inscription or utterance itself. This inscription or utterance is a representative of the meaning of the word.","['terminology', 'logic', 'discrete-mathematics']"
1868804,To prove limit of function,"To prove $\lim_{x\to 0} x\sin(\frac{1}{x})=0$
I tried sandwich theorem but I have no clear idea to prove the problem",['limits']
1868870,Integral of Simple Functions converges to Integral of Measurable Function,"Let $f$ be a measurable function and $E_{n,m} = \{x : \frac{m}{2^n} \leq f(x) < \frac{m+1}{2^n} \}$. Prove: $$\lim_{n \to \infty} \sum_{m=1}^{\infty} \frac{m}{2^n} \mu(E_{n,m}) \to \int f \, d\mu$$ Attempted Proof: We wish to show for any $\phi \leq f$, $\phi$ simple, there exists $\varphi$ of the form $$\sum_{m=1}^{k} \frac{m}{2^n} \mathbb{1}_{(E_{n,m})},$$ another simple function such that $\int \phi \leq \int \varphi$, which will imply the supremums over all such simple functions are equal. Let $\phi  = \sum \limits_{i=1}^{r} a_i \mathbb{1}_{(A_i)}$ Let $\epsilon > 0$. Let $M = \max \limits_{i=1, \ldots, n} \{\mu(A_i)\}.$ Let $\tilde{\epsilon} = \min \{a_i, \frac{\epsilon}{nM} \}$. Then, $$\sum_{i=1}^{r} (a_i-\tilde{\epsilon}) \mu(A_i) > \int \phi \, d\mu - \epsilon.$$ Now choose $2^{-N} < \tilde{\epsilon}$ so for each $a_i$ we have (wlog) $$\frac{m-1}{2^N} \leq a_i -\tilde{\epsilon} < \frac{m}{2^N}.$$ Thus if $$\varphi = \sum_{m=1}^{k} \frac{m}{2^N} \mathbb{1}_{(E_{N,m})}$$ for sufficiently large $k$, then $$\int \phi \, d\mu - \epsilon < \int \varphi \, d\mu$$ and letting $\epsilon \to 0$ implies $\int \phi \leq \int \varphi$. This implies the convergence. Anything wrong here? any poor assumptions that break this proof? an easier method to proving this?","['real-analysis', 'probability-theory', 'proof-verification', 'measure-theory', 'analysis']"
1868899,Does this particular axiom on a semigroup guarantee that it is a group?,"Update : Eric Wofsey has demonstrated the conjecture in the commutative case below, and Tobias Kildetoft has provided a simple counterexample to the non-commutative claim. This would-be replacement for the usual group axioms was suggested by the ##math IRC channel user Aleric, and no solution has been found so far. In its original form, the conjecture reads: Let $(S,+)$ be a non-empty commutative semigroup satisfying the following ""reversibility"" axiom: for all $x,y \in S$, there exists a $z \in S$ such that $$x + y + z = x.$$
  Then there exists an identity, i.e., an element $0 \in S$ such that $x + 0 = x$ for all $x \in S$. Of course, if this is true then the identity must be unique, and $S$ becomes an Abelian group by applying the reversibility axiom to $0,x$. I suppose one could just as easily drop the commutativity condition and formulate a stronger conjecture as follows: Let $(S,\cdot)$ be a non-empty semigroup satisfying the following ""reversibility"" axiom: for all $x,y \in S$, there exist $z,w \in S$ such that $$xyz = wyx = x.$$
  (Actually, it's not clear to me if we shouldn't ask for a sole element $z = w$ instead.) Then there exists an identity, i.e., an element $1 \in S$ such that $x1 = 1x = x$ for all $x \in S$. Again $S$ becomes a group by applying the reversibility axiom to $1,x$. I have checked all the commutative semigroups of order $3$ and found none which satisfy this axiom and aren't groups, but this isn't very satisfactory. I am looking for a proof of either conjecture or a counterexample.","['abstract-algebra', 'semigroups', 'group-theory', 'binary-operations']"
1868911,Moment generating function of $X+Y$ using convolution of $X$ and $Y$,"Given that the pdf of $X+Y$ is the convolution of pdfs $X$ and $Y$ , show that $M_{X+Y}$ is $M_XM_Y$ where $M$ is the moment generating function. $X$ and $Y$ are independent and continuous. I am confused how to proceed from here (see picture). Thank you. My approach:","['probability-limit-theorems', 'probability-theory', 'probability', 'probability-distributions']"
1868929,"$\int_{- \infty}^{\infty} \frac{f(x)}{1+\exp{g(x)}}dx=\int_{0}^{\infty} f(x) dx$ for $f(x)=f(-x),~g(x)=-g(-x)$ - are there other formulas like that?","If $f(x)$ any even function, integrable on $(0,\infty)$ and $g(x)$ any odd function, then we have: $$\int_{- \infty}^{\infty} \frac{f(x)}{1+e^{g(x)}}dx=\int_{0}^{\infty} f(x) dx \tag{1}$$ The proof is elementary: $$I(a)=\int_{- \infty}^{\infty} \frac{f(x)}{a+e^{g(x)}}dx$$ $$I(1/a)=\int_{- \infty}^{\infty} \frac{f(x)}{1/a+e^{g(x)}}dx=a \int_{- \infty}^{\infty} \frac{e^{-g(x)}f(x)}{e^{-g(x)}+a}dx= \\ = a \int_{- \infty}^{\infty} f(x)dx-a^2\int_{- \infty}^{\infty} \frac{f(x)}{a+e^{g(x)}}dx$$ $$\frac{1}{a} I(1/a)+aI(a)=\int_{- \infty}^{\infty} f(x)dx$$ $$I(1)=\int_{0}^{\infty} f(x)dx$$ With this formula we can write some crazy looking integrals to scare people, like: $$\int_{- \infty}^{\infty} \frac{e^{-x^2}}{1+e^{\sin (\sinh x)+x^3-\arctan x}}dx=\frac{\sqrt{\pi}}{2}$$ To be fair, it might also be useful for some quatum statistics applications (i.e. Fermi-Dirac distribution). I want to know, what other formulas like $(1)$ exist? Maybe with the exponential function, or some other functions I also know of Glasser's Theorem , but I wonder if some more interesting cases exist. To be more specific, I mean the non-trivial formulas of the following kind: $$\int_{a}^b g(x) f(x) dx=k \int_{A}^B f(x) dx$$ With $k$ being some constant, independent on $f(x)$, $f(x)$ is a general function (with some restricitions), $g(x)$ is some interesting function. $A,B$ might be different from $a,b$, but also should not depend on $f(x)$.","['exponential-function', 'integration', 'definite-integrals']"
1868938,Tangent vector of a curve,"Let $\vec{\sigma}:[a,b]\longrightarrow \mathbb{R}^2$ be a regular and closed curve of class $C^1$, parametrized respect to the arc lenght. Is true that the map $\vec{\sigma}':[a,b]\longrightarrow S^1$ is surjective?","['differential-geometry', 'plane-curves']"
1868944,Writing continued fractions of irrational numbers as infinite series,"Infinite sums have been formulated for famous irrational numbers, such as $\pi, \phi,e,\sqrt2$ and a few others that can be listed here and here : Here are some examples: (There are more examples if you follow the links above) $$\sqrt 2 = \sum_{k=0}^\infty{\frac{(2k+1)!}{2^{3k+1} (k!)^2}}$$
$$\pi = \sum_{k=0}^\infty{\frac{(2^{k+1})(k!)^2}{2k+1}}$$
$$\phi = \frac{13}{8} + \sum_{k=0}^\infty{\frac{((-1)^{k+1})(2k+1)!}{((k+2)!)(k!)(4^{2k+3})}}$$
$$e =  \sum_{k=0}^\infty{\frac{1}{k!}}$$ In the section that follows I will just be discussing non-transcendental numbers (such as $\sqrt2,\sqrt3,\sqrt5$, etc (not $\pi,e$, etc) As far as I know there are no known infinite sums for $\sqrt3,\sqrt5$ and irrational numbers such which can be written as $\sqrt[a]b$ Where $a$ is an real number > 0, and b is a prime number or the product of prime numbers. And such that $\sqrt[a]b$ is not an integer (perfect squares or perfect cubes). However , there are continued fractions which can represent some of these numbers, such as $\sqrt5$: $$\sqrt5 = 2+ \frac{1}{4 + \frac{1}{4 + \frac{1}{4 + \frac{1}{4 + \frac{1}{4 + \frac{1}{4 + ...}}}}}}$$ This wikipedia section discusses this concept nicely: Click here SO MY QUESTION IS: If there is a continued fraction for $\sqrt x$, then how do we go from the continued fraction to an infinite sum? (Conversion maybe?) Let's take $\sqrt5$ as an example: How I thought of doing this, would to work out rational approximations by taking the continued fraction to certain terms (T), such as: T1 = $2 = \frac{2}{1}$ T2 = $2+ \frac{1}{4} = \frac{9}{4} = 2,25$ T3 = $2+ \frac{1}{4 + \frac{1}{4}} = \frac{38}{17} = 2,234294118...$ T4 = $2+ \frac{1}{4 + \frac{1}{4+\frac{1}{4}}} = \frac{161}{72} = 2,236111111...$ T5 = $2+ \frac{1}{4 + \frac{1}{4+\frac{1}{4+\frac{1}{4}}}} = \frac{682}{305} = 2,236065574...$ T(n) = $\frac{T_{n+1}(OEIS: A001077)}{T_{n+1}(OEIS: A001076)}$ and the list goes on (if we did this ""infinitely"" many times we should theoretically reach $\sqrt5$ and that is what we are looking for :) Then what I tried to do is take these rational approximations and finding the difference between them, so we could then write it as an infinite sum, comprising of adding the differences (D) of these rational approximations. $D1 = T2-T1 = \frac{9}{4} - 2 = \frac{1}{4}$ $D2 = T3-T2 = \frac{38}{17} - \frac{9}{4} = -\frac{1}{68}$ $D3 = T4-T3 = \frac{161}{72} - \frac{38}{17} = \frac{1}{1224}$ $D4 = T5-T4 = \frac{682}{305} - \frac{161}{72} = -\frac{1}{21960}$ The numerator stays 1 and the denominators continue in the following sequence: https://oeis.org/A156084 (Each time the term alternates between being positive and negative). Let's call the absolute value of each term in the sequence $a_k$, $(a_1 = \frac{1}{4},a_2 = \frac{1}{68})$;  then$\sqrt5$ could be written as: $$\sqrt5 =  2 + \sum_{k=0}^\infty{(-1)^k} . {a_{k+1}} = 2 + \frac{1}{4} - \frac{1}{68} + \frac{1}{1224} - \frac{1}{21960} ...$$ Kind Regards Joshua","['continued-fractions', 'sequences-and-series', 'irrational-numbers']"
1868953,Relation between Fibonacci number and the golden section,"We denote the $n$th term of Fibonacci number with $F_n$. Assume that 
$\alpha=\frac{1+\sqrt{5}}{2}$. With simulation, I found the following 
relation between Fibonacci number and the golden section
$$
\mid \frac{F_{n+1}}{F_{n}}-\alpha\mid \, \approx \,  \frac{1}{(F_n)^2}~.
$$
Is there a analytical method that we can proof the mentioned formula. I would greatly appreciate for any suggestions. Edit: First I want to gratitude from Milo Brandt for nice answer. In continue, i want to generalize my question. One of the most important generalization of the classical Fibonacci numbers is the Fibonacci $p$-step numbers that is defined as follows
$$
\begin{equation}\label{cp26}
 F_n^{(p)}=F_{n-1}^{(p)}+F_{n-2}^{(p)}+\cdots+F_{n-p}^{(p)}\, .
 \end{equation}
$$
With boundary conditions
$$
F_{0}^{(p)}=0\quad ,  \quad F_{1}^{(p)}=0\quad ,\, \cdots\, ,\quad F_{p-2}^{(p)}=0\quad , \quad F_{p-1}^{(p)}=1\, .
$$ We can get the limit value of Fibonacci $p$-step numbers by inverse of solution of equation $x^{p+1}-2\, x+1=0$ in the interval $(0,1)$. We denote the limit value of Fibonacci $p$-step numbers with $\alpha_p$. In fact, $\alpha_p$ is defined in the following form
$$
\alpha_p=\displaystyle{\lim_{n\rightarrow\infty}}\quad \frac{F^{(p)}_{n+1}}{F^{(p)}_{n}}~.
$$
The generalization of the above formula is 
$$
\mid \frac{F^{(p)}_{n+1}}{F^{(p)}_{n}}-\alpha_p\mid \, \approx \,  {F^{(p)}_{n}}^{-{\displaystyle{(\frac{p}{p-1})}}}~.
$$ For example for the case $p=4$, we have","['fibonacci-numbers', 'golden-ratio', 'sequences-and-series']"
1868958,Geometric differences between $\operatorname{Spec}\mathbb{C}[x]/(x^2-x)$ and $\operatorname{Spec}\mathbb{C}[x]/(x^3-x^2)$,"As far as I can tell, the topological spaces associated to the schemes in the title are both sets with two elements, with the discrete topology since both have prime ideals $(x)$ and $(x-1)$ which are maximal and thus closed. In regards to the sheaf structure, obviously the global functions are different. However, as far as I can tell, the local rings of $\mathbb{C}[x]/(x^2-x)$ at $(x)$ and $(x-1)$ are isomorphic to $\mathbb{C}$, as is the local ring of $\mathbb{C}[x]/(x^3-x^2)$ at $(x-1)$, but the local ring of $\mathbb{C}[x]/(x^3-x^2)$ at $(x)$ is a bit larger in some sense (since for example $x$ is not identified with some element of $\mathbb{C}$). What I would like to know is: how does one translate this algebraic difference (which feels minor to me, because in my mind, both schemes are pairs of points, and if we think about the local rings are local functions, despite the second having more elements in the local ring at $(x)$, there is still only one prime ideal in said local ring to evaluate the functions on, so all functions are still in some sense constant) into a geometrically satisfying picture?","['affine-schemes', 'algebraic-geometry', 'commutative-algebra']"
1869036,Sequence of integrable function with $\sum_{n=1}^\infty \|f_n\|_1<\infty$. Show that $\sum_{n=1}^\infty f_n$ converges a.e. and is integrable.,"Let $\{f_{n}\}$ be a sequence of functions in $L^1(\mathbb{R})$ such that $\displaystyle \sum_{n=1}^\infty\|f\|_{1}<\infty.$ Show that $$f(x): = \sum_{n=1}^\infty f_n(x)\text{ converges a.e., }\, f\in L^{1}(\mathbb{R}), \text{ and } \int_{\mathbb{R}} f = \sum_{n=1}^\infty \int_{\mathbb{R}}f_n$$ Here's my solution: First, recall that $(\mathbb{N},\mathcal{P}(\mathbb{N}),c)$ and $(\mathbb{R},\mathcal{M},m)$ are $\sigma$-finite measure spaces. From Tonelli's Theorem, $$\int_{\mathbb{N}\times\mathbb{R}}|f_{n}(x)| \, d(c\times m) = \int_{\mathbb{N}} \int_{\mathbb{R}}|f_{n}(x)| \, dc\times dm = \sum_{n=1}^\infty \|f_{n}\|_1<\infty.$$ Since $f_{n}(x)$ is integrable with respect to the product measure of $c$ and $m$, Fubini's Theorem gives $$\int_{\mathbb{R}}f(x)\,dm = \int_{\mathbb{R}}\sum_{n=1}^\infty f_n(x)\,dm =\sum_{n=1}^\infty \int_{\mathbb{R}}f_n(x) \, dm.$$ Now, are we able to say that $f$ is integrable, since the RHS of the above is finite? How can we say the sum converges a.e.? Does that follow immediately from the integrability of $f$? Is there a simple way to prove this using either the Monotone Convergence Theorem or Lebesgue Dominated Convergence Theorem, without Tonelli or Fubini?","['real-analysis', 'lebesgue-integral', 'measure-theory']"
1869041,Why is the empty set in the standard topology?,"The ""standard topology"" (put in quotations because I haven't verified that it is in fact a topology yet) is defined by $$\mathcal U \in \mathcal O_\text{standard} \iff \forall p\in \mathcal U \exists r\in \Bbb R^+ : B_r(p)\subseteq \mathcal U$$ Now I'm checking whether this is a topology and I'm getting hung up on the very first property. If $\emptyset\in \mathcal O_\text{standard}$, then for every $p\in \emptyset$, there exists $\dots$  But there is no $p\in \emptyset$ for us to check the rest of the condition.  So how are we allowed to conclude that $\emptyset \in \mathcal O_\text{standard}$?",['general-topology']
1869080,Write summation of vector outer products into matrix form,"My question is as follows: Given the weighted summation of vector outer products $\sum_i\sum_jh_{ij}{\bf v_i}{\bf u_j}^T$, where $h_{ij}$ is the weight, and ${\bf v_i,u_j}$ are column vectors, I was wondering if we could write it in a more elegant matrix form? For example, a simpler case $\sum_i {\bf u_i}{\bf u_i}^T$, we can write it in the matrix form ${\bf UU}^T$, where ${\bf U}=[{\bf u_1,u_2},\ldots]$. Thanks!","['matrices', 'linear-algebra', 'vectors']"
1869081,Intuitive reconciliation between Dedekind cuts and uncountable irrationals,"I've looked around, haven't found a good explanation of this one. Basically, I'm looking for the simplest route to get from these starting points: The set of all rational numbers is countably infinite There exists a set of rational numbers A such that all members of A are less than x , and A has no greatest element. To this end point: The set of all irrational numbers is uncountably infinite I've seen various people trying to argue that this is a contradiction. I am not one of those people. I'm just looking for clarity on how you go about getting from the countable, dense set of rationals to the uncountable, dense set of irrationals with these starting points. I'm familiar with other means of getting to the uncountability of the reals, which combined with the countability of the rationals demonstrates that the irrationals are uncountable. Just looking for how you get to that point using these starting points.","['irrational-numbers', 'elementary-set-theory']"
1869083,Not understanding the wrong logic in this proof,"The problem is : Suppose $a,b \in Z$. If $a^2 + b^2 $ is a perfect square, then $a$ and $b$ are not both odd. My question is why can't I answer like so: Proof by Contradiction -- Suppose $a^2 + b^2 $ is a perfect square, and $a$ and $b$ are both odd. Let $a = 5$ and $b = 7$. Then $5^2 + 7^2$ is a perfect square. $5^2 + 7^2 = 74$, so 74 is a perfect square. However, we know that 74 is not a perfect square. Therefore there is a contradiction. So if $a^2 + b^2 $ is a perfect square, then $a$ and $b$ are not both odd.",['number-theory']
1869112,An application of Egoroff' theorem,"Let $\left\{f_{n}\right\}$ be a sequence of measurable functions on the real line $\mathbb{R}$, and $f_n\rightarrow f$ almost everywhere. Prove that there exists a sequence of measurable sets $\left\{E_{k}\right\}$ such that the Lebesgue measure of $\mathbb{R}\setminus\bigcup^{\infty}_{k=1}E_{k}$ is zero, and $f_{n}\rightarrow f$ uniformly on each $E_{k}$. The first thing occurs to me is the Egoroff's theorem. So my thought was to construct some bounded sets and select subsets of it using Egoroff's theorem to finish the proof. But I don't know how to choose these sets.","['real-analysis', 'measure-theory']"
1869135,Proof that two non-parallel planes must intersect?,"I managed to find, by enumeration, the intersection point of two planes $ax+by+cz+d=0$ and $ex+fy+gz+h=0$, in all possible cases (with the condition that the planes are not parallel). But this is a very ugly proof. I wonder if there is a quicker and more elegant proof (without linear algebra --- this is high school level (Euclidean) geometry)?",['geometry']
1869154,"$R$ be a Noetherian domain , $t\in R$ be a non-zero , non-unit element , then is it true that $\cap_{n \ge 1} t^nR=\{0\}$?","Let $R$ be a Noetherian domain, $t\in R$ be a non-zero, non-unit element, then is it true that $$\bigcap_{n \ge 1} t^nR=\{0\} \text{?} $$ It almost feels like the nilradical (which is zero for any domain) and intersection of prime ideals, but I can't quite crack it, possibly because I can't see where Noetherianness comes into play. Please help. Thanks in advance.","['noetherian', 'abstract-algebra', 'commutative-algebra', 'integral-domain', 'ideals']"
1869199,Regarding the general method of the ''Classify groups of order $X$'' question.,"Anyone who has had to prepare for an algebra qualifying exam is familiar with the ""Classify groups of order $X$"" question. To illustrate my general question, which I postpone until the end, consider the following simple example in which I classify groups $G$ of order $3 \cdot 7$.  Let $H$ and $K$ be the $7$- and $3$-Sylow subgroups, respectively.  By Sylow's theorems, we find easily that $H$ is normal and $K$ is either normal or one of seven conjugate copies.  Also $H \cong \mathbf{Z}_7$ and $K \cong \mathbf{Z}_3$.  Let $x$ be a generator of $\mathbf{Z}_3$ and let $y$ be a generator of $\mathbf{Z}_7$, both viewed multiplicatively.  Now $G$ is a semidirect product of $H$ and $K$, hence the possible structures of $G$ are determined by the possible group homomorphisms $$ \mathbf{Z}_3 \to \mathrm{Aut}(\mathbf{Z}_7) \cong \mathbf{Z}_6. $$  Such a group homomorphism is determined by the image of $x$; since the order of this image must divide the order of $x$, we see $x$ is either sent to the identity automorphism $\mathbf{1}$ or an automorphism of order three. We find that a generator of $\mathbf{Z}_6$ is the automorphism $\alpha \colon y \mapsto y^3$.  Therefore, there are three possible group homomorphisms, determined by sending $x$ to $\mathbf{1}$, to $\alpha^2 \colon y \mapsto y^2$, or to $\alpha^4 \colon y \mapsto y^4$.  It follows there are at most three possible groups of order $21$, generated by $x$ and $y$ and subject to the relations $x^3 = x^7 = 1$ as well as one of the following commutativity relations: $$xy = yx, \;\;\;\;\; xy = y^2 x, \;\;\;\;\; xy = y^4 x. $$  All such groups exist by employing the abstract construction of the semidirect product. What follows is always the most subtle part of the analysis. Which of these groups are duplicates? The first is the case $G \cong \mathbf{Z}_3 \times \mathbf{Z}_7$ which is clearly distinct from the remaining two.  Let the second group be denoted $G_2$ and the third $G_4$.  If $G_2$ were isomorphic to $G_4$, then there would have to exist $X, Y \in G_4$ of orders three and seven, respectively, and satisfying $XY = Y^2 X$ (or $X, Y \in G_2$ satisfying $XY = Y^4 X$).  And it is easy to see that, in fact, this condition is sufficient for $x \mapsto X$, $y \mapsto Y$ to determine an isomorphism $G_2 \cong G_4$.  Note that both $G_2$ and $G_4$ have seven $3$-Sylow subgroups (otherwise they would be Cartesian products).  So there are $14$ candidates for $X$ and $6$ candidates for $Y$. Morally, at least in my opinion, these groups should be isomorphic, because the only difference in their definition occurs when we chose between the two generators $\alpha^2$ and $\alpha^4$ of the cyclic subgroup $\mathbf{Z}_3 \subset \mathrm{Aut}(\mathbf{Z}_7) \cong \mathbf{Z}_6$, and these generators are 'essentially the same'. This is indeed the case, but the proof feels 'lucky'.  One finds by calculation that no map of the form $X = x$ and $Y = y^k$ satisfies $XY = Y^2 X \in G_4$.  But this is satisfied by taking $X = x^2$ and $Y = y$:  $$X Y = x^2 y = x y^4 x = y^{16} x^2 = y^2 x^2 = Y^2 X \in G_4. $$  We conclude there are two groups of order $21$ up to isomorphism. To give an example of how this problem becomes more complex, if instead one were computing groups of order $3 \cdot 7 \cdot 13$, then one must determine group homomorphisms $$\mathbf{Z}_3 \to \mathrm{Aut}(\mathbf{Z}_7 \times \mathbf{Z}_{13}) \cong \mathbf{Z}_6 \times \mathbf{Z}_{12}. $$  (Don't forget that the automorphisms of the direct product is the direct product of the automorphisms when the orders of the groups are coprime!)  If $\alpha$ generates $\mathbf{Z}_6$ and $\beta$ generates $\mathbf{Z}_{12}$, then there are nine possible semidirect structures, corresponding to $x$ being sent to to any of the following pairs: $$(\mathbf{1}, \mathbf{1}), \;\;\;\;\; (\alpha^2, \mathbf{1}), \\ (\alpha^4, \mathbf{1}), \;\;\;\;\; (\mathbf{1}, \beta^4), \\ (\mathbf{1}, \beta^8), \;\;\;\;\; (\alpha^2, \beta^4), \\ (\alpha^4, \beta^4), \;\;\;\;\; (\alpha^4, \beta^8), \;\;\;\;\; (\alpha^2, \beta^8). $$  Which of these are isomorphic? Hopefully at this point my general question is clear.  First, in words: In considering semidirect products $G \cong H \rtimes K$ is there a (natural?) proof that shows the choice of generator(s) of $\mathrm{Aut}(H)$ affects the resulting group only up to the choice of 'non-equivalent' generators? Here is a precise phrasing for which I would be thrilled to receive an answer: Question:  Prove or disprove. Let $p$ and $q$ be primes such that $q$ divides $p-1$.  Consider semidirect products $G_\rho = \mathbf{Z}_p \rtimes_\rho \mathbf{Z}_q$ determined by group homomorphisms $$ \rho \colon \mathbf{Z}_q \to \mathrm{Aut}(\mathbf{Z}_p) \cong \mathbf{Z}_{p-1}. $$  Let $x$ multiplicatively generate $\mathbf{Z}_q$ and let $\alpha$ multiplicatively generate $\mathbf{Z}_{p-1}$.  Setting $n = (p-1)/q$ the generators for $\mathbf{Z}_q \subset \mathbf{Z}_{p-1}$ are $\alpha^{nk}$ where $k = 1, \dots, q-1$.  Let $\rho_k$ denote the group homomorphism determined by $x \mapsto \alpha^{nk}$.  Then $G_{\rho_k} \cong G_{\rho_\ell}$ for all $1 \leq k, \ell \leq q-1$.","['finite-groups', 'abstract-algebra', 'semidirect-product', 'group-theory']"
1869222,Difference between set theory proof and logic proof of complete induction,"Set theory proof: Let $\mathbf{A}$ be the set such that $\{0,1,2,...,n\} \subset \mathbf{A} \implies n+1 \in \mathbf{A}$. Our goal is to show that $\mathbf{A} = \mathbb{N}$. To do this, we construct the set $\mathbf{B}$ such that it contains $n$ whenever $\{0,1,2,...,n\} \subset \mathbf{A}$. Now we induct on $\mathbf{B}$. Clearly it contains $0$. Suppose it contains $n$, then $\{0,1,2,...,n\} \subset \mathbf{A}$. By the hypothesis of complete induction, $n+1 \in \mathbf{A}$, hence $\{0,1,2,...,n+1\} \subset \mathbf{A}$, hence $n+1 \in \mathbf{B}$. So $\mathbf{B} = \mathbb{N}$, which implies that $\mathbf{A} = \mathbb{N}$, and we're done. Logic proof: Let $\mathbf{Q}(n)$ $\equiv$ $\ \mathbf{P}(m)$ for all $0 \leq m \lt n$. Inducting on $n$, we're done. Now comes the question that's been puzzling me: Naively, I would've thought that the set theory proof is just the logic proof written in the language of sets. But this doesn't seem to be the case, in the set theory proof, we constructed the set $\mathbf{B}$ which is in some sense ""weaker"" than $\mathbf{A}$. However, the logic proof hinged on the statement $\ \mathbf{Q}(n)$, which is ""stronger"" than $\mathbf{P}(m)$. This means (I think) the set theory proof isn't a direct translation of the logic one. Is there a deeper reason why this is the case? What's the difference between the language of sets and mathematical logic using quantifiers?","['induction', 'logic', 'elementary-set-theory']"
1869254,Field with $125$ elements,I want to construct a field with $125$ elements. My idea is to consider the polynomial ring $\Bbb F_5[x]$. It is enough to find an irreducible polynomial $f\in \Bbb F_5[x]$ of degree $3$ because then $\Bbb F_5[x]/(f)$ is a field with exactly $5^3=125$ elements. How do I find an irreducible polynomial of degree $3$ in $\Bbb F_5[x]$?,"['finite-fields', 'abstract-algebra', 'irreducible-polynomials', 'field-theory']"
1869275,Is there a general way to tell whether two topological spaces are homeomorphic?,"We know that if two topological spaces $X$ and $Y$ are homeomorphic, then they have the same fundamental groups, and the same homology. In other words, we have functors
$$\pi_1 : \mathsf{Top} \to \mathsf{Grp} \quad\text{and}\quad H_n : \mathsf{Top} \to \mathsf{Ab}$$
(actually this works even if the spaces are homotopy equivalent). The important thing here is that these functors can be used to prove that the two spaces are not homeomorphic: for instance $H_3(S^3) \cong \Bbb Z \not\cong 0 = H_3(S^2)$, so that $S^3$ and $S^2$ are not homeomorphic (they don't even have the same homotopy type). I was wondering whether there was somehow a ""converse"" to this, i.e. is they a way to prove that two topological spaces are homeomorphic.
More precisely: Is there a category $\scr C$ and a functor $\mathsf F : \mathsf{Top} \to \mathscr C$ such that $\mathsf F(X) \cong \mathsf F(Y) \implies X \cong Y$ ? Of course, I want to avoid obvious examples as $\mathsf{Id_{Top}}$ . (By the way, I don't know if there is a name for such functors, which are injective on objects. Faithful is already used for something different). I would also accept discussing the case where the homeomorphism $ X \cong Y$ is replaced by a homotopy equivalence $X \simeq Y$. Trying the functor $\mathsf F(X) = X \times X$ doesn't work, as shown here . The functor $\mathsf F(X) = X \sqcup X$ doesn't work as well. The closest result I found is a theorem due to Gelfand and Kolmogorov : given two compact and Hausdorff spaces, if the commutative rings $C(X)$ and $C(Y)$ of continuous functions $f\,:\,X,Y\rightarrow \mathbb{R}$ (under pointwise addition and multiplication) are isomorphic, then $X$ and $Y$ are homeomorphic. Maybe we could try to generalize this to the category of locally compact and Hausdorff spaces, using the Alexandorff compactification. Thank you for your comments!","['algebraic-topology', 'category-theory', 'general-topology']"
1869317,"If $f:\mathbb{R} \rightarrow \mathbb{R}$ is continuous and $f(x) = f(2x)$, prove that $f(x)$ is constant [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question If $f:\mathbb{R} \rightarrow \mathbb{R}$ is continuous and $f(x) = f(2x)$, prove that $f(x)$ is constant.","['calculus', 'limits']"
1869319,What are these quotient spaces homeomorphic to?,"I would like to know what the following spaces $X$ and $Y$ look like. More precisely, I want to know if they are homeomorphic to some other known spaces. I define $X$ and $Y$ as a quotient of the square $[0,1]^2$ by gluing the edges (red with red, blue with blue): $\qquad\qquad\qquad\quad$ In other words, $X=[0,1]^2 / \sim$ and $Y=[0,1]^2 / \sim'$ where $\sim$ is the equivalence relation defined by
$$(x,s) \sim (y,t)    \iff    (x,s)=(y,t) \;\text{ or }\;
s=0, y=1, t = 1-x  \;\text{ or }\;
s=1, y=0, x = 1-t $$
and $\sim'$ is the equivalence relation defined by
$$(x,s) \sim' (y,t)    \iff    (x,s)=(y,t) \;\text{ or }\;
s=0, y=1, t = x  \;\text{ or }\;
s=1, y=0, x = 1-t $$ I tried to see with a handkerchief what I could obtain when gluing the edges as shown on the diagrams, but it was quite unsuccessful. I believe that I would obtain non-orientable spaces, maybe a wedge of projective space and something else. I failed to understand what $X$ and $Y$ are homeomorphic to. However, I know what the following similar diagrams give : $\qquad\quad$ $\qquad\qquad\qquad\qquad$ Any suggestion will be appreciated, thanks in advance!","['general-topology', 'surfaces', 'quotient-spaces']"
1869343,Is my proof of $\lim_{x\rightarrow c}x^2=c^2$ correct?,"I know the most common proof of $\lim_{x\rightarrow c}x^2=c^2$. But I wonder if my alternative proof is valid and correct. Here's my proof. Let $\varepsilon>0$, want to find a $\delta>0$ such that $\forall x\in\mathbb{R},0<|x-c|<\delta\Rightarrow |x^2-c^2|<\varepsilon$ For the convenience for observation, suppose that $0<|x-c|<\square$, we want to find out which $\square$ is ok, and then know what $\delta$ to pick. Since $|x^2-c^2|<\varepsilon\Leftrightarrow |x+c||x-c|<\varepsilon$ and \begin{alignat*}{3}
&0<|x-c|<\square\\
\Longleftrightarrow &c-\square<x<c+\square&(except\ x=c)\\
\Longleftrightarrow &2c-\square<x+c<2c+\square\qquad&(except\ x=c)\\
\Longrightarrow &|x+c|< |2c|+\square
\end{alignat*} So we see that if we want  $|x+c||x-c|<(|2c|+\square)\square<\varepsilon$ to be true, we need to solve a positive solution of the quadratic inequality $\square^2+|2c|\square-\varepsilon<0$, by the relationship between roots and coefficient, we know $\square^2+|2c|\square-\varepsilon=0$ has exactly one positive and one negative root. Hence the solution of the prior inequality is $(-c-\sqrt{c^2+\varepsilon},-c+\sqrt{c^2+\varepsilon})$, where the right endpoint is positive. Thus, we pick $\delta=-c+\sqrt{c^2+\varepsilon}$ to complete the proof.",['analysis']
1869349,Differentiate equation with parenthesis,"I have a problem. I'm studying calculus, but I don't have a good math background, so I have a problem: I don't know well how to differentiate an equation with parenthesis. The equation is the following: $f(x) = 25x^3(x-1)^2$ Is it correct to use the Differentiation Product Rule in this way: $f'(x)=75x^2*(x-1)^2+25x^3*2(x-1)$ or before I have to solve $(x-1)^2$ in this way: f(x) = $25x^3*(x^2+1-2x)$ and then
     = $25x^5+25x^3-50x^4$ ? Thanks in advance",['derivatives']
1869394,"Find two different rules for one sequence $2, 4, 8, \ldots$","Question : The first three terms of a sequence are given. $2, 4, 8...$ Write two different rules for continuing the sequence. Give the next two terms for each rule. Answer : I have found one rule which satisfies this sequence and could not think of another one. $1)$ The next term is double the previous term: $2, 4, 8, 16, 32...$ I'm not entirely what another different rule could be... Thank you.","['algebra-precalculus', 'sequences-and-series']"
1869432,"proving that triangles $ABC$, $A'B'C'$ are congruent","Given $AD$ is a median to $BC$ in triangle $ABC$, and $A'D'$ is a median to $B'C'$ in triangle $A'B'C'$, and $AD=A'D', AC=A'C', AB=A'B'$. How can i prove that triangles $ABC$, $A'B'C'$ are congruent? I can't see how the median is helping me to prove that. I tried to build a Parallelogram but it didn't work out. Thanks.","['analytic-geometry', 'congruences-geometry', 'trigonometry', 'geometry']"
1869442,Whether a given algebra is the algebra of endomorphisms for a vector space.,"Let $\mathbb{F}$ be a field and let $A$ be an associative unital $\mathbb{F}$-algebra. Is there a criterion to let me know if $A$ is isomorphic to the algebra $\mbox{End}(\mathbf{V})$ of endomorphisms for some $\mathbb{F}$-vector space $\mathbf{V}$? Generalizations to $A$ being an associative unital ring and $\mathbf{V}$ an Abelian group or similar are welcome. Answers for particular cases $\mathbb{F}\in\{\mathbb{R},\mathbb{C}\}$ are also appreciated. Thank you.","['abstract-algebra', 'linear-algebra']"
1869473,What is the coordinate of the maximum value of a quadratic function given by two points and axis?,"There are only three pieces of information available: the graph passes through (0,0) and (6,0) the symmetry axis is $x$ = 3 the graph is downward My attempt: I've tried to work on that problem and got quadratic function $y = ax^2 - 6ax$. However, I couldn't find the value of $a$ and of course the coordinate of the maximum value.","['optimization', 'functions', 'quadratics']"
1869481,What operations on infinite sets are allowed? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question I'm trying to solve one puzzle, which deals with infinite set, so I wonder what operations on infinite sets are allowed in mathematics and what operations have no sense? Let me explain my problem in more details. For example, consider an infinite subsets of natural numbers. Like odd numbers: {1,3,5,7,...}.
It is clear that you can find Unions, Intersections, Complements and Cartesian product. But can you add all elements of this set by modulo? Or, at least say, for example, that if $x=(...((3+5) mod 2)+7) mod 2)+9)...$ and $y=(...((5+7) mod 2)+9) mod 2)+11)...$ then for sure $x$ and $y$ has different, though unknown values? Since $x=(3+y) mod 2$. Can you compare sets one to another? For example if you define comparison of two different well-ordered sets like: 1) take the first (smallest) elements of the sets: $a1$ and $b1$. if $a1 < b1$, then $set A < set B$. 2) if $a1 = b1$, then take second elements of the sets: $a2$ and $b2$. if $a2 < b2$, then $set A < set B$. 3) continue, until you find different elements. You can clearly do this with finite sets, but can you do this with infinite sets? Can you say that set of all possible subsets of natural numbers can be ordered with this comparison? If not, then why? What if we take not natural numbers, but some sets with higher cardinality, like real numbers?","['infinity', 'elementary-set-theory']"
1869506,Help on how to show that $\int_{0}^{1}\left(2{x-1\over \ln^2{x}}-{x+1\over \ln{x}}\right)dx=3\ln{2}-2$,"$$\int_{0}^{1}\left(2{x-1\over \ln^2{x}}-{x+1\over \ln{x}}\right)dx=3\ln{2}-2\tag1$$ Rewrite, so we can apply Frullani's formula on first part $$\int_{0}^{1}\left(-{x+1\over \ln{x}}+{2\over \ln{x}}+{2(x-1)\over \ln^2{x}}\right)=3\ln{2}-2\tag2$$ $$-\ln{2}+\int_{0}^{1}\left(-{2\over \ln{x}}+{2(x-1)\over \ln^2{x}}\right)=3\ln{2}-2\tag3$$ $$\int_{0}^{1}\left(-{1\over \ln{x}}+{x-1\over \ln^2{x}}\right)=2\ln{2}-1\tag4$$ How do I continue from $(4)$?","['integration', 'definite-integrals', 'calculus']"
1869512,Does $A^2 \cong B^2$ imply $A \cong B$ for rings?,"If $A$ and $B$ are two unital rings such that $A \times A \cong B \times B$, as rings, does it follows that $A$ and $B$ are isomorphic (as rings)? I believe that the answer is no, but I can't come up with a counterexample. A similar question for groups has already been asked - the answer is not straightforward.
Here is a possibly related question , but there are $R$-modules isomorphisms. [If $A$ and $B$ are fields, then we can see $B^2$ as a $2$-dimensional $A$-vector space, so that $A \cong B$ as $A$-vector spaces, because they have the same dimension. I may be wrong about this, but anyway this is not sufficient to get a field isomorphism.] Thank you for your comments!","['abstract-algebra', 'ring-theory', 'examples-counterexamples']"
1869518,Find the number of ways to reach from one end of grid to another,There's a 6 by 6 grid and you're asked to start on the top left corner. Now your aim is to get to the bottom right corner. You are only allowed to move either right or down. You must never move diagonally or backwards. I figured out the way to do this through writing number of ways to reach each cell in a box and got the answer to be 252 However I saw a formula for questions of this type which gives answer as 12!/(6!*6!) I would like to know why the above formula doesn't work in this case and preferably where it's applicable Thanks,['combinatorics']
1869525,APICS Mathematics Contest 1999: Prove $\sin^2(x+\alpha)+\sin^2(x+\beta)-2\cos(\alpha-\beta)\sin(x+\alpha)\sin(x+\beta)$ is a constant function of $x$,"This is question 3 from the APICS Mathematics Competition paper of 1999: Prove that $$\sin^2(x+\alpha)+\sin^2(x+\beta)-2\cos(\alpha-\beta)\sin(x+\alpha)\sin(x+\beta)$$ is a constant function of $x$. Expanding it seems rather daunting, in particular the last term, and nothing I've tried has been useful towards cancelling terms out.
It was assigned in a pre-calculus course, so it should be possible to solve without using derivatives. However, showing that $f'(x)=0$ would obviously be a valid solution. Any ideas are greatly welcome.","['proof-writing', 'trigonometry', 'functions']"
1869527,A generalization of Barrow's inequality,"I proposed the conjecture as following: Let $ABC$ be a triangle, $P$ be arbitrary point inside of $ABC$, let $A_1B_1C_1$ be the tangential of ABC. Let A', B', C' be three be arbitrary points on $B_1C_1, C_1A_1, A_1B_1$ respectively. Let internal angle bisectors of three angles $\angle B'PC'$, $\angle C'PA'$, $\angle A'PC'$ meet $BC, CA, AB$  at $A'', B'', C''$ respectively. Then show that:
$$PA'+PB'+PC' \ge 2(PA''+PB''+PC'')$$. 
Equality hold iff ABC be an equilateral triangle and  $\angle B'PC'= \angle C'PA'=\angle A'PC' =120^0$ 
When $A'=A, B'=B, C'=C$ we have Barrow's inequality Can you check in The Meterial Geogebra","['inequality', 'geometric-inequalities', 'geometry']"
1869543,Existence of absolute maxima and minima,"In which of the following functions can be guaranteed the existence of absolute maxima and minima? a) $f(x,y,z)=x+y$ with $z\geq x^2+y^2+1$. b) $f(x,y)=\ln (x^2+y^2+1)$, with $x\geq 0$ and $y\geq 0$. c) $f(x,y)=\dfrac{xy}{x^2+(y-2)^2}$ with $x^2+y^2\leq 1$. d) $f(x,y)=2(x^2+y^2)$ with $x^2+y^2> 1$. Do I have to find the critical points and see if they belongs to the set given? If so, I get that the critical points of each functions are: a) It does not have critical points b) $(0,0)$ c) $(0,0)$ d) $(0,0)$ But I do not see what else to do.","['multivariable-calculus', 'optimization']"
1869545,Solve $\sec (x) + \tan (x) = 4$,"$$\sec{x}+\tan{x}=4$$
Find $x$ for $0<x<2\pi$. Eventually I get $$\cos x=\frac{8}{17}$$
$$x=61.9^{\circ}$$
The answer I obtained is the only answer, another respective value of $x$ in $4$-th quadrant does not solve the equation, how does this happen?  I have been facing the same problem every time I solved this kind of trigonometric equation.",['trigonometry']
1869555,Prove $\tan(A+B)$ using $\cos(A-B)$ and $\sin(A-B)$,Use $\cos(A-B)$ and $\sin(A-B)$ to prove $$\tan(A+B)=\frac{\tan{A}+\tan{B}}{1-\tan{A}\tan{B}}$$ It seems like we cannot simply change $A+B$ to $A+(-B)$ to prove it? Any ideas?,['trigonometry']
1869622,Find the value of $\sum_{r=0}^{\left\lfloor\frac{n-1}3\right\rfloor}\binom{n}{3r+1}$,"Show that $$\binom{n}{1}+\binom{n}{4}+\binom{n}{7}+\ldots=\dfrac{1}{3}\left[ 2^{n-2} + 2\cos{\dfrac{(n-2)\pi}{3}}\right]$$ My solution:- $$(1+x)^n=\binom{n}{0}+\binom{n}{1}x+\binom{n}{2}x^2+\binom{n}{3}x^3+\ldots=\sum_{r=0}^{n}{\binom{n}{r}x^r} \\ \therefore x^2(1+x)^n=\binom{n}{0}x^2+\binom{n}{1}x^3+\binom{n}{2}x^4+\binom{n}{3}x^5+\ldots=\sum_{r=0}^{n}{\binom{n}{r}x^{r+2}}$$ In the above Binomial Expansion on substituting $x=1,\omega,\omega^2$, $\omega$ being a complex cube root of unity, we get the following three equations $$\tag{1}(1)^2(1+1)^n=\sum_{r=0}^{n}{\binom{n}{r}}=2^n$$ $$(\omega)^2(1+\omega)^n=\sum_{r=0}^{n}{\binom{n}{r}\omega^{r+2}}=(-1)^n(\omega)^{2n+2} \tag{2}$$ $$(\omega)^4(1+\omega^2)^n=(\omega)(1+\omega^2)^n=\sum_{r=0}^{n}{\binom{n}{r}\omega^{2r+4}}=(-1)^n(\omega)^{n+1} \tag{3}$$ On adding $(1),(2) \text{ and }(3)$, we get $$\dfrac{1}{3}\left(2^n+(-1)^n(\omega^{n+1}+\omega^{2n+2})\right)=\sum_{r=0}^{\left\lfloor\frac{n-1}3\right\rfloor}\binom{n}{3r+1}$$
Now, as $\omega=-e^{i(\pi/3)}$  ($\omega$ being the cube root of unity) $$\begin{aligned}
\therefore (\omega^{n+1} +\omega^{2n+2})
&= \left(\left(-e^{i(\pi/3)}\right)^{n+1}+\left(-e^{-i(\pi/3)}\right)^{n+1}\right) \\ 
&=(-1)^{n+1}\left(e^{i(\pi(n+1)/3)}+e^{-i(\pi(n+1)/3)}\right) \\
&=(-1)^n\left(2\cos{\left(\dfrac{\pi(n+1)}{3}\right)}\right)
\end{aligned}$$ Now, substituting the value of $(\omega^{n+1}+\omega^{2n+2})$ back into $(4)$, we get $$2^n+(-1)^n(\omega^{n+1}+\omega^{2n+2})=2^n-2\cos{\left(\dfrac{\pi(n+1)}{3}\right)}=\sum_{r=0}^{n}{\binom{n}{3r+1}}$$ $$\therefore \sum_{r=0}^{\left\lfloor\frac{n-1}3\right\rfloor}\binom{n}{3r+1}=\boxed{\dfrac{1}{3}\left(2^n-2\cos{\left(\dfrac{\pi(n+1)}{3}\right)}\right)}$$ So, where did I go wrong, or is it that the book has provided the wrong answer.","['complex-analysis', 'binomial-theorem']"
1869635,$E(X_1|X_1+X_2=k)$ increases with $k$?,"$X_1$ and $X_2$ are independent, but they may not follow the same distribution. I want to know whether $E(X_1|X_1+X_2=k)$ increases with $k$. I guess this is correct, but is there a proof or counter example? Thank you very much!",['probability-theory']
1869647,Branch points and Ramification points of a meromorphic map between Riemann Surfaces,"Let be $f(z)=\frac{z^3}{(1-z^2)}$ be considered as a meromorphic function on the Riemann Sphere $\mathbb C_{\infty}.$ Consider the affiliated holomoprhic map $F:\mathbb C_{\infty}\rightarrow \mathbb C_{\infty}$. Now I want to determine all the branch points and ramification points of $F$. I also want to determine the degree deg($F$) of $F$. Note: I am using Rick Miranda's ""Algebraic Curves and Riemann Surfaces"". The ramification point $p\in \mathbb C_{\infty}$ is a point with $mult_p(F)\geq 2$. For poles and zeros its quite easy to determine whether they are ramification points or not.. I found for example the following point: $p=0$ because its a zero of $f$ and so $mult_p(F)=ord_p(F)=3\geq2$ The poles $+1$ and $-1$ are no ramification points sich their order are just $-1$. Also $\infty$ is no ramification points since $$f(1/z)=\frac{1}{z(z^2-1)}$$ has a pole of order just $1$ in zero ($ord_1(F)=-1$). But I think I am not done. How can I check the points which are neither poles nor zeros? Thanks in advance!:)","['riemann-surfaces', 'abstract-algebra', 'general-topology']"
1869654,More generalization of the Sawayama lemma,"Let $ABC$ be a triangle, $P$, $Q$ be two isogonal conjugate. $AP$, $AQ$ meets (ABC) at $D, E$ respectively. Two lines through $D, E$ meet (ABC) at $T, N$ and meet BC at $G, H$ respectively. Let $PG, HQ$ meets $(GHNT)$ again at $K, F$. Then $K, F, A$ are collinear.","['circles', 'plane-geometry', 'triangles', 'geometry']"
1869663,Is a non-separable algebraic field extension $k \subset E$ normal if $\mathrm{Aut}_{E}(\bar{k})$ is a normal subgroup of $\mathrm{Aut}_{k}(\bar{k})$?,"Over a perfect field $k$ it is well known that an algebraic field extension $k \subseteq E$ is normal if and only if $\mathrm{Aut}_{E}(\bar{k})$ is a normal subgroup of $\mathrm{Aut}_{k}(\bar{k})$, as in the infinite Galois correspondence closed normal subgroups of $\mathrm{Aut}_k(\bar{k})$ correspond exactly to normal field extensions of $k$. Here $\bar{k}$ denotes an algebraic closure of $k$. Is the same true when $k$ is not perfect? The closest I have gotten to providing an answer is the following: The group $\mathrm{Aut}_k(\bar{k})$ acts on the set of $k$-algebra homomorphisms $E \to \bar{k}$ by postcomposition. The stabiliser of the inclusion $E \subseteq \bar{k}$ is given by $\mathrm{Aut}_E(\bar{k})$; as by assumption $\mathrm{Aut}_E(\bar{k})$ is a normal subgroup of $\mathrm{Aut}_k(\bar{k})$ we see that it is the stabiliser of all $k$-algebra homomorphisms $E \to \bar{k}$, and therefore any conjugate of $E$ must lie within the purely inseparable closure of $E$, as this field coincides with the fixed field of $\mathrm{Aut}_E(\bar{k})$.","['abstract-algebra', 'galois-theory', 'extension-field', 'field-theory']"
1869696,Dual of the Banach space of $k$-times continuously differentiable functions.,"Let $C^k([0,1])$ denote the Banach space of $k$-times continuously differentiable functions $f:[0,1]\to \mathbb R$ with norm $$\|f\|_{C^k}:=\max_{i=0,\dots,k}\sup_{x\in [0,1]}|f^{i}(x)|.$$ I'm trying to understand its (continuous) dual space -- is there a nice characterisation of it and perhaps a reference where I can read about such things? I'm also interested in the dual space of $C^r$ for $r>0$ non-integer ($\lfloor r\rfloor$-times continuously differentiable functions with $\lfloor r\rfloor^{\text{th}}$ derivative being $(r-\lfloor r\rfloor)$-Holder continuous if anyone could shed some light on this. Many thanks!","['functional-analysis', 'real-analysis', 'analysis']"
1869739,Why are geodesically convex sets diffeomorphic to $\Bbb R^n$?,"In the construction of a good cover for a manifold $M^n$, Bott & Tu use the fact that each point in $M$ is contained in a geodesically convex set (after picking a Riemannian metric). They then claim that the intersection of geodesically convex sets is a geodesically convex set, and that makes sense. They further claim that any geodesically convex set is diffeomorphic to $\Bbb R^n$. For this, they reference Spivak, who does not actually show the last bit. Perhaps one way to do this is to show that the convex set is star-shaped, so the inverse image of it under the exponential map is convex, and somehow diffeomorphic to a ball, and thus to $\Bbb R^n$?","['algebraic-topology', 'riemannian-geometry', 'differential-geometry', 'differential-topology']"
1869769,Image of $\mathbb{P}^1 \times \mathbb{P}^1$ by Segre embedding is a hyperboloid,"Let $f: \mathbb{P}^1 \times \mathbb{P}^1 \to \mathbb{P}^3$ be the Segre embedding given by $((x_0:x_1),(y_0:y_1))\mapsto(x_0y_0,x_0y_1,x_1y_0,x_1y_1)$ . Gathmann's notes claim that the real points of the image of $f$ form a hyperboloid, and that lines map to lines as in this picture: I'm having trouble seeing why these two facts holds. 
Using the affine coordinates on each $\mathbb P^1$ , we get that $f$ sends $((1:x),(1:y))$ to $(1:y:x:xy)$ , so as an affine function we have $(x,y) \mapsto (y,x,xy)$ . This seems to me as a mirror image of the surface $z=xy$ , which is a hyperbolic paraboloid and looks very different from a one-sheeted hyperboloid. What am I missing? And how can we see the geometric phenomenon that is pictured above?","['projective-space', 'algebraic-geometry']"
1869777,A tricky integral - $\int_0^1 \sqrt{\frac{1}{(1-t^2)^2}-\frac{(n+1)^2t^{2n}}{(1-t^{2n+2})^2}}dt $,"$$
\mathbf{\mbox{Evaluate:}}\qquad
\int_{0}^{1} \sqrt{\frac{1}{\left(1 - t^{2}\right)^2} -
\frac{\left(n + 1\right)^{2}\,t^{2n}}{\left(\, 1 - t^{2n+2}\,\,\right)^{2}}}
\,\,\mathrm{d}t
$$
  where $n$ is any positive integer. Introduction : This integral came up while studying the distribution of the roots of random polynomials - and I can't crack it. It seems impervious to methods of integration I know. Neither Mathematica nor Wolfram-Alpha could find a closed form, not only for this general integral, but any special case of $n>1$. My attempt: For $n=1$, the integral is pretty trivial to compute - expanding the integrand gives:
  $$\int_0^1 \sqrt{\frac{1}{t^4-2 t^2+1}-\frac{4 t^2}{t^8-2 t^4+1}}$$
  Which simplifies quite easily to:
  $$\int_0^1 \frac{1}{t^2+1}$$
  The antiderivative of the integrand is $\tan^{-1}{t}$. Evaluating at the limits gives:
  $$\int_0^1 \sqrt{\frac{1}{t^4-2 t^2+1}-\frac{4 t^2}{t^8-2 t^4+1}}=\frac{\pi}{4}-0=\frac{\pi}{4}$$
  However, this method does not work for $n>1$, and niether does any method I know of. Numerical values: Listed below are the approximate numerical values for this integral. Neither Wolfram Alpha nor the Inverse Symbolic calculator were able to find closed forms for these numbers. $$n=2 \qquad 1.01868$$
  $$n=3 \qquad 1.17241$$
  $$n=4 \qquad 1.28844$$
  $$n=5 \qquad 1.38198$$
  $$n=6 \qquad 1.46049$$ Any help on this integral would be greatly appreciated. Thank you!","['integration', 'definite-integrals', 'calculus']"
1869783,'2nd order' Picard Iteration,"I'm self-studying differential equations using MIT's publicly available materials.  One of the problem set exercises deals with what I'm calling a second order Picard Iteration.  To be explicit, we are given the initial value problem
\begin{align}
	x'' = f(t,y), \qquad x(t_0) = x_0, \qquad x'(t_0) = x_1
\end{align}
where $f$ is continuous and Lipschitz on a rectangle $|t -t_0| \leq T$ and $|x - x_0| \leq K$ and a sequence of functions given by
\begin{align}
x_n(t) & = \begin{cases}
x_0 & n = 0\\
x_0 + x_1(t - t_0) + \int_{t_0}^t(t-s)f(x_{n-1}(s),x)ds & n \geq 1
\end{cases}
\end{align}
We are to show that $\lbrace x_n \rbrace$ converges to a solution to the IVP on the interval $|t - t_0| \leq \min \left(T, \frac{K}{B}\right)$, where $M$ is the maximum value on the rectangle in question and $B = |x_1| + \frac{MT}{2}$.  It seems to me that we are to proceed in a manner analogous to the proof of the local existence theorem; I am, however, getting stuck on the inductive step. Here's what I have.  In essence, what we want to do is show that $\lbrace x_n \rbrace$ converges uniformly and then use the fact that uniform convergence implies that we can move the limit from the outside to the inside of an integral sign.  So
\begin{align}
|x_1(t) - x_0(t)| & = \left|(t - t_0)x_1 + \int_{t_0}^t(t-s)f(x_0,t)ds\right|\\
& \leq |(t - t_0)x_1| + \int_{t_0}^t|t-s||f(x_0,x)ds\\
& \leq T|x_1| + M\int_{t_0}^t|t-s|ds\\
& \leq T|x_1| + \frac{MT^2}{2}\\
& \leq TB
\end{align}
and therefore
\begin{align}
|x_2(t) - x_1(t)| & \leq \int_{t_0}^t|t-s||f(x_1(s),t) - f(x_2(s),t)|ds\\
& \leq L\int_{t_0}^t|t-s||x_1(s) - x_0(s)|ds\\
& \leq TBL\int_{t_0}^t|t-s|ds\\
& \leq TBL\left(\frac{T^2}{2}\right)\\
\end{align}
And here we reach the inductive step, where my troubles begin.  Assume we have
\begin{align}
|x_n(t) - x_{n-1}(t)| \leq TBL^{n-1}\left(\frac{T}{2}\right)^{2(n-1)}
\end{align}
Then we obtain
\begin{align}
|x_{n+1}(t) - x_{n-1}(t)| \leq TBL^n\left(\frac{T}{2}\right)^{2n}
\end{align}
We want the right side of this inequality to go to $0$, but of course it doesn't, unless $T < 2$.  Now, in the proof of the local existence theorem, the analogous denominator is $n!$, which suggests that instead of $2^{2n}$ we should have $(2n)!$, but I can't see how we'd obtain that, given that each iteration of $\int_{t_0}^t(t-s)$ is going to yield $\frac{(t - t_0)^2}{2}$, so that we're doubling the denominator each time. Any thoughts would be appreciated.",['ordinary-differential-equations']
1869794,Question about arc-connected property in a continuum,"Suppose $X$ is metric, compact, connected, and $p\in X$. An arc is a copy of $[0,1]$. Is it possible that every two points in $X\setminus \{p\}$ can be joined by an arc, but there is no arc in $X$ containing $p$?","['general-topology', 'path-connected', 'connectedness']"
1869842,Prove that $a_n$ is a perfect square,"Let $\,\,\,\left(a_{n}\right)_{\ n\ \in\ \mathbb{N}\,\,\,}$ be the sequence of integers defined recursively by
  $$
a_{1} = a_{2} = 1\,,\qquad\quad a_{n + 2} = 7a_{n + 1} -a_{n} - 2\quad
\mbox{for}\quad n \geq 1
$$ Prove that $a_{n}$ is a perfect square for every $n$. We have $a_{3} = 4, a_{4} = 25, a_{5} = 169,\ldots$ Is there a way we can simplify the recursion or get its closed form in order to get that it is a perfect square ?.",['number-theory']
1869843,"Are there $a,b \in \mathbb{N}$ that ${(\sum_{k=1}^n k)}^a = \sum_{k=1}^n k^b $ beside $2,3$","We know that:
$$\left(\sum_{k=1}^n k\right)^2 = \sum_{k=1}^n k^3 $$ My question is there other examples that satisfies: 
$$\left(\sum_{k=1}^n k\right)^a = \sum_{k=1}^n k^b $$","['algebra-precalculus', 'summation']"
1869851,"If $G$ is a non-abelian group of order 10, prove that $G$ has five elements of order 2.","I'm trying to prove this statement: If $G$ is a non-abelian group of order $10$, prove that $G$ has five elements of order $2$. I know that if $a\in G$ such that $a\neq e$, then as a consequence of Lagrange's theorem $|a|\in \{2,5,10\}$. The order of $a$ cannot equal $10$, since then $G$ would be cyclic, and thus abelian which is a contradiction. Now this means that $|a|=2 $ or $|a|=5$. I know from this question that $G$ has a subgroup of order $5$. This subgroup $H$ has prime order, so it is cylic, and all of its non-identity elements have order $5$. Now I need to show that the elements not in $H$ have order $2$. This is where I'm stuck. I've tried assuming that an element $b \notin H$ has order $5$, in order to derive a contradiction, but to no avail. I also know from a previous exercise that if $G$ has order $10$, then it has at least one subgroup of order $2$, so I tried to assume toward a contradiction that $G$ has two subgroups of order $5$, and one subgroup of order $2$. I was trying to show that this would make $G$ abelian, but I couldn't. Any ideas?","['finite-groups', 'abstract-algebra', 'group-theory']"
1869863,"Counting the number of Eulerian trails in a connected, directed graph","I can't find anything about this online, and I'm beginning to suspect it's a hard problem. I know that counting the number of circuits is #P-complete, but I don't need the number of circuits; I need the number of trails . My current ""solution"" is to simply walk the graph, find every path, and count them. Important notes: The graph is directed. The graph is connected. The graph has at most two vertices with different in- and out-degrees. I'm looking for trails , including but not limited to circuits. Any information on this, including upper limits, computational complexity, algorithms, etc., would be helpful.","['eulerian-path', 'combinatorics', 'graph-theory', 'discrete-mathematics']"
1869874,How does one plug radicals with non-perfect squares and variables into the Pythagorean theorem formula?,"I am working on the following integral $$\int\left( 7x^2 - 3 \right)^{\frac 5 2} \, dx$$ I want to use the $\sqrt{u^2 - a^2}$ $u = a\sec\theta$ I know in order to get it into the form that will allow me to do this I will have to do the following. $$\int \sqrt {\left( 7{ x }^{ 2 }-3 \right)^5 } \, dx$$ At this point in solving this kind of problems I would draw a right triangle and place the values for a b and c in the appropriate places. This allows me to see that the substitution I am choosing is going to work and this lets me have something to refer to when putting the solved integral back into terms of x from theta. This usually works great when I am working with values such as $x^2-16$ or $x^2-25$ These values plug into the the Pythagorean theorem formula just fine. However, the above produces radicals I am not sure how to deal with. Triangle diagram I am assuming the above drawing is correct. I know regardless that I will end up substituting x with $$x =\sqrt{\frac{3}{7}}\sec\theta$$ I know this is simple but I am not sure if I am understanding this correctly. Have I drawn this diagram correctly outside of the placement of $\sqrt{7x^2-3} $? Also, how does the math work exactly when plugging these values into the Pythagorean theorem?  I am not understanding how when I square $\sqrt{7x}$ I end up with $7x^2$. Shouldn't I end up with just $7x$?","['algebra-precalculus', 'trigonometry', 'calculus']"
1869927,Lower bound on gap between consecutive eigenvalues on $L_2(\mathbb{R}^3)$,"A similar version of this question was originally posted by me in the physics community , but it was suggested that I ask the mathematicians instead. So I have tried to strip off most of the physics jargon and brush up my functional analysis-fu. Consider the stationary Schrödinger equation on $L_2(\mathbb{R}^3)$:
\begin{equation}
-\nabla^2\psi(\vec r)+V(\vec r)\psi(\vec r) = E\psi(\vec r)\text.
\end{equation}
Here $V(\vec r)$ can be assumed to be a sufficiently well-behaved function that vanishes at infinity. Assume this operator has a discrete spectrum and denote the discrete eigenvalues as $E_{n,\tau}$, where $n$ is the principal quantum number and $\tau$ represents all the other quantum numbers, if any. For a given $V(\vec r)$, is it possible to derive a lower bound on $E_{n+1,\tau}-E_{n,\tau}$, i.e. on the energy gap between consecutive levels with the same additional quantum numbers? Physical intuition tells me that long-range potentials should allow smaller gaps (cf. the Coulomb potential $V(r)=1/r$, which yields $E_n\propto 1/n^2$, with the gap getting infinitely small as $n\to\infty$), but I haven't managed to express this quantitatively.","['functional-analysis', 'spectral-theory', 'hilbert-spaces']"
1869946,Function with $f(f(n))=f(n-1)f(n+1)-f(n)^2$,"Let $\mathbb{N}$ denote the set of positive integers. Does there exist a function $f:\mathbb{N}\rightarrow\mathbb{N}$ such that  $$f(f(n))=f(n-1)f(n+1)-f(n)^2$$ for all $n\geq 2$? If $f$ is linear, plugging in $f(n)=an+b$, we get
$$a(an+b)+b=(a(n-1)+b)(a(n+1)+b)-(an+b)^2$$
which is
$$a^2n+ab+b=-a^2$$ This means $a=0$. But then also $b=0$, hence $f\equiv 0$, but this is not allowed. So there is no such linear function.","['functions', 'functional-equations']"
1869970,$a_n$ is relatively prime to $a_k$ for $k<n$,"Let the sequence $\{a_n\}_{n=0}^\infty$ be defined by $a_n=|n(n+1)-19|$. Show that for $n\neq 4$, if $a_n$ is relatively prime to $a_k$ for all $k<n$, then $a_n$ is prime. The first few terms are $19, 17,13,7,1,11,23,37,53,71,91$, where $a_{10}=91$ is the first non-prime term (other than $a_4=1$), and indeed it is not relatively prime to $a_2=13$ and $a_3=7$.","['prime-numbers', 'sequences-and-series']"
1869981,Explanation: In how many ways can 6 things be divided between 2 people?,"I have a question in a book which says in how many ways can 6 different things be divided between 2 boys and (my understanding of) the explanation goes something along the lines of: Items: 1 1 1 1 1 1 The first item can be distributed to either boy 1 or boy 2, i.e. 2 choices the second item could be distributed to either boy 1 or boy 2 therefore you get 2 choices again.
Therefore the number of choices are $2\times2\times2\times2\times2\times2$. However if I thought of it in another way such as you have 6 items therefore boy 1 can get all 6 and boy 2 could get 0, you could organise it into pairs such that: \begin{array}{c c}
boy 1 & boy 2 \\
0 & 6 \\
1 & 5 \\
2 & 4 \\
3 & 3 \\
4 & 2 \\
5 & 1 \\
6 & 0
\end{array} Therefore there are 7 ways of distributing the items. Where am I wrong with my thoughts? I cannot see why my way of thinking is wrong.","['combinatorics', 'discrete-mathematics']"
1869998,Proving that a limit doesnt exist even if it exists,"When I was trying to find a path that would prove that some limit doesn't exists, I was simply equaling the equation to a number and finding some expression. I will use some trivial limit, that can be easily be proven to exist by Definition or by Squeeze Theorem, to show the case.
$$\lim_{(x,y)\to (0,0)}\frac{x^2y}{x^2+y^2}$$
Since this fraction is limited
$$0\le\frac{x^2}{x^2+y^2}\le1$$
I can multiply both sides by $y$
$$0\lim_{(x,y)\to(0,0)}y\le\lim_{(x,y)\to (0,0)}\frac{x^2y}{x^2+y^2}\le\lim_{(x,y)\to(0,0)}y$$
Which only solution is
$$\lim_{(x,y)\to (0,0)}\frac{x^2y}{x^2+y^2}=0$$
So we know the limit exists and it is equal to 0.
$$ $$
But if I take this curve (that I found simply equaling the limit to 1)
$$x = \sqrt{\frac{y^2}{y-1}}$$
I think it's okay because when $y\to0, x\to 0$.So the limit will be:
$$\lim_{t\to 0}\frac{\frac{y^3}{y-1}}{\frac{y^2}{y-1}+y^2}=\lim_{y\to 0}\frac{\frac{y^3}{y-1}}{\frac{y^3}{y-1}}=1$$
So I found a path that proves the limit doesn't exist. But we know it exists, so must be something wrong.
Did I missed something ? Where is the mistake ? I feel that there is something wrong in the domain of the curve, but since the domain is $y\gt 1$ or $y = 0$ I can't prove that with some formality.","['multivariable-calculus', 'limits']"
1870008,Triple Integration in vector calc,NIn the following example I have been asked to find the volume V of the solid bounded by the sphere $ x^2 + y^2 +z^2 = 2 $ and the paraboloid $ x^2 + y^2 = z $ by using triple integration. I am not quite sure how to set up this triple integration and what each of the integrands should be.,"['integration', 'calculus']"
1870034,Hausdorff measure vs Lebesgue measure for a hypersurface in $\mathbb{R}^n$,"Let $H$ be a compact smooth hypersurface with boundary in $\mathbb{R}^n$. We can compute the Lebesgue measure $\mathcal{L}(H)$ with respect to the induced Lebesgue measure coming from $\mathbb{R}^n$, and also separately the Hausdorff measure $\mathcal{H}^{n - 1}(H)$. My question is, how do they compare? Does one always have $\mathcal{L}(H) \leq \mathcal{H}^{n - 1}(H)$?","['hausdorff-measure', 'reference-request', 'lebesgue-measure', 'measure-theory']"
1870072,For which dimensions is it possible to have $A \succeq B \succeq 0$ with $A^2 - B^2$ having $n-1$ negative eigenvalues?,"For any dimension $n$, can we write down two symmetric, positive semi-definite matrices $A,B$ with $A \succeq B$ in the sense of the usual ordering (i.e., $A-B$ is positive semidefinite) such that $A^2 - B^2$ has $n-1$ negative eigenvalues? Notes: For $n=2$, there are examples of matrices $A,B$ such that $A \succeq B$ but it is not true that $A^2 \succeq B^2$. For example: $$A  = \left( \begin{array}{cc} 2 & 1 \\ 1 & 1 \end{array} \right), B = \left( \begin{array}{cc} 1 & 0 \\ 0 & 0 \end{array} \right)$$ For $n=2$, this pair of matrices provides an answer to this question. Since ${\rm tr}(A^2-B^2) \geq 0$, the matrix $A^2 - B^2$ has to have at least one nonnegative eigenvalue. My motivation: the fact that $A \succeq B$ does not imply $A^2 \succeq B^2$ is somewhat unintuitive to me. I was just wondering if one can construct an example where $A^2 - B^2$ is ``as close'' to a negative definite matrix as possible.","['matrices', 'linear-algebra']"
1870103,"For $f$ analytic on $|z|<1$, $|f|\le M$ with $a_1,\ldots,a_n\in \Bbb{D}$ zeros of $f$ show that $|f(0)|\le M \prod |a_j|$","For $f$ analytic in unit disk $\Bbb{D}$ where $|f|\le M$ with $a_1,\ldots,a_n\in \Bbb{D}$ such that $f(a_1)=\cdots=f(a_n)=0$ show that $|f(0)|\le M \prod |a_j|$. I have tried many approaches including modifying the function using the Cauchy Formula, ML estimate, Maximum Principle and more. nothing seems to get me forward. I am really clueless here and could use a guidance.",['complex-analysis']
1870116,"If $m^*([-n,n] \cap E) + m^*([-n,n] \setminus E) = 2n$ for all $n$, then $E$ is Lebesgue measurable","Let $E \subset \Bbb R$ and let $m^*$ denote the Lebesgue outer measure on $\Bbb R$ . Show that if for all $n \in \Bbb N$ , $m^*([-n,n] \cap E) + m^*([-n,n] \setminus E) = 2n$ , then $E$ is Lebesgue measurable. Hint: for all $n \in \Bbb N$ , there are measurable sets $F_n$ , $G_n$ such that $F_n \subset E \cap [-n,n] \subset G_n$ , and $m(G_n \setminus F_n) = 0$ . Given the hint, it is not difficult to conclude: put $F = \cup_n F_n$ and $G = \cup_n G_n$ . We have: $$m^*(E \setminus F) = m^* \left( \bigcup_n ((E \cap [-n,n]) \setminus F) \right) \le m (G \setminus F) \le m(\cup_n (G_n \setminus F_n)) = 0$$ So $E \setminus F$ is negligible, hence measurable. Therefore, $E = (E \setminus F) \cup F$ is measurable. How to prove the claim in the hint?","['lebesgue-measure', 'measure-theory', 'analysis']"
1870143,For which category (if any) are Lie algebras the algebras of a monad?,"I was reading about monads recently, and it came to me that the purpose of the category of algebras of a monad seems to be to switch to a ""representation"" which is easier for computations. Soon after I realized that I heard similar things were true for Lie algebras (i.e. that they simplify calculations for Lie groups), as well as for the matrix representations of groups. I know that (free) monoids are the algebra for the monad on $Set$ which given a set $X$ returns the set $X^*$ of words in elements of $X$. Since Lie algebras are monoids, I figured that they might also be the algebra of some monad. In other words, I would like to know if it is possible to make the above analogy rigorous. Do Lie algebras (over $\mathbb{R}$ or $\mathbb{C}$) form the category of algebras for any monad $T$? What I tried to do to find an answer (these efforts were not successful) Ideally I would probably want to find some adjunction that generates an appropriate monad, but since I am new at this, I decided to Google instead. Here is the most relevant result I found, from page 133, edited by Paul Gregory Goerss and Stewart Priddy, of the collection of papers: "" Homotopy Theory: Relations with Algebraic Geometry, Group Cohomology, and Algebraic $K$-Theory: Relations with Algebraic Geometry, Group Cohomology, and Algebraic K-theory : an International Conference on Algebraic Topology, March 24-28, 2002, Northwestern University "" Specifically the result I am looking at, Proposition 1.2.16, says the following: We assume that the ground ring $\mathbb{K}$ is a field of characteristic $p >0$. Recall that an algebra over the monad $\mathcal{S(L)}$ is a Lie algebra $\mathcal{G}$ together with a Lie bracket $[-,-]:\mathcal{G}\otimes\mathcal{G} \to \mathcal{G}$ such that $[x,y]=-[y,x]$, for all $x,y \in \mathcal{G}$. An algebra over the monad $\Lambda(\mathcal{L})$ is a Lie algebra $\mathcal{G}$ together with a Lie bracket $[-,-]: \mathcal{G} \otimes \mathcal{G} \to \mathcal{G}$ such that $[x,x]=0$. An algebra over the monad $\Gamma(\mathcal{L})$ is a restricted Lie algebra $\mathcal{G}$. Since I don't really understand the article, I am not quite sure what all of the notation means, except that $S$ is a functor which takes operads to monads (whatever operads are). Also this might not be a result I am interested in, since it seems to only hold for fields of characteristic $p>0$, i.e. not for Lie algebras over the real or complex numbers. Most of the other Google search results I found for ""Lie algebra monad"" also did not seem to answer my question. I thought this question might help: Do adjoint functors really define monads? , but I'm not sure how to interpret it -- was the result that Lie algebras cannot be/are not the algebra of any monad?","['category-theory', 'abstract-algebra', 'monads', 'lie-algebras']"
1870158,What happens with negative plurigenus?,"It is a well known result that for a smooth, projective k-variety, the dimension of the global section $H^0(X,K_X^j)$ of $j$-powers of the canonical bundle. Also called plurigenus, are birational invariants when $j\geq 0$. I was wondering what goes wrong in the proof for negative powers of the canonical bundle.The proof that I read via a series of exercises goes like this: Fix a dense open subset of definition of the birational map with
$U \subset X$ with $X\setminus U$ of codimension at least 2. Since $K_X^j$ is locally free, and $X\setminus U$ has codim 2 or more, every regular section of $H^0(K_X^j, U)$ can be extended to a section of $H^0(K_X^j, X)$. -If $V$ is the dense open subset isomorphic to $U$ on $Y$.
We have $H^0(K_Y^j, Y)$ again equal to $H^0(K_Y^j, V)$. But $H^0(K_Y^j, V)$ is equal to $H^0(K_X^j,U)$.",['algebraic-geometry']
1870173,Axioms for a Heyting Algebra as a Set System (Partial Order Lattice Under Inclusion),"According to the corresponding section in Wikipedia : An element $x$ of a Heyting algebra $H$ is called regular iff $x = \neg y$ for some $y \in H$ . Elements $x$ and $y$ of a Heyting algebra are called complements to each other iff $x \land y = 0$ and $x \lor y =1$ . If it exists, any such $y$ must be unique and in fact equal to $\neg x$ . If $x$ admits a complement then we call it complemented . For any Heyting algebra, the following three conditions are equivalent: $H$ is a Boolean algebra Every element of $H$ is regular. Every element of $H$ is complemented. My question is the following: If we consider this as a set system, then is a Heyting algebra the same as a Boolean algebra except that it does not necessarily need to be closed under set complements? My reasoning is as follows: The terminology complemented , complement , and set complement are quite similar. If we change the lattice notation to the corresponding set notation ( $\neg \iff ^c$ , $\land \iff \cap$ , $\lor \iff \cup$ ), then given a set $A$ , and considering a Heyting algebra $H$ on its lattice of subsets, we have that $X \subset A$ is regular iff $X=Y^c$ for some $Y \in H, Y \subset A$ , $X$ and $Y$ are complements if and only if $X \cap Y=\emptyset$ , $X \cup Y=A \implies X = Y^c$ . The above excerpt implies that if for every $X \in H$ , $X=Y^c$ for some $Y\in H$ (i.e. $H$ is closed under set complements) then it is a Boolean algebra (since it is a lattice and hence closed under finite intersections and unions). The same way that Boolean algebras are the algebraic model for classical logic, Heyting algebras are the algebraic model for intuitionistic logic, which rejects the Law of the Excluded Middle. Not necessarily being closed under set complements seemed to be the set-theoretic analog to the Law of the Excluded Middle not holding (because then $(X^c)^c$ is not necessarily defined, which means that we can not immediately conclude that $X=(X^c)^c$ , the same way in intuitionistic logic we cannot always conclude that $\neg \neg x =x$ ).","['boolean-algebra', 'lattice-orders', 'elementary-set-theory']"
1870193,"""Approximate Isometry"" in Riemannian Geometry","I apologize if the notion I'm asking about is well known, I'm no expert in geometry (and I did not find an answer via google). Suppose $(X,g_X)$ and $(Y,g_Y)$ are (smooth) Riemannian manifolds. I'm wondering if one may describe a diffeomorphism $f:X \to Y$ as being ""close to an isometry."" Is there a criteria to measure this, and what would one call such a map? A natural idea is to call $f$ an $\epsilon$-isometry if for any $p\in X$, $u,v \in T_pX$, $$g^X_p(u,v) - g^Y_{f(p)}(dfu,dfv) < \epsilon$$
(This idea is analogous to that of an approximate isometry on Banach spaces). Does this concept exist and if so in what context is it useful? Thanks.","['riemannian-geometry', 'isometry', 'smooth-manifolds', 'conformal-geometry', 'differential-geometry']"
1870239,Find $\lim_{x\to \infty}\left(\frac{n+2}{n-1}\right)^{2n+3}$,Find  $$\lim_{n\to \infty}\left(\frac{n+2}{n-1}\right)^{2n+3}.$$ My attempt : $$\lim_{n\to \infty}\left(\frac{n+2}{n-1}\right)^{2n+3}=\lim_{n\to \infty}\left(1+\frac{3}{n-1}\right)^{2n+3}=\lim_{n\to \infty}\left(1+\frac{1}{\frac{n-1}{3}}\right)^{2n+3}$$ Now we should do something to change the power to $\frac{n-1}{3}$ because: $\lim_{x\to \infty}(1+\frac{1}{x})^x=e$ But I cannot get the answer(the answer is $e^2$). Please give small hints not full answers. Here is a picture from my answer: Note that in persian $2=۲$ and $3=۳$. edit :The answer is mistaked and take $n+1$ instad of $n+1$.,['limits']
1870255,How to pick all the colors?,"Prove of disprove: Suppose there are n boxes, each containing m balls of the same color,with n colors in total. No matter how we reallocate these balls (still each box contains m balls), we can pick up a ball from each box such that all colors are picked. This question came to my mind when I tried to solve a problem in algebra: Let $H $ be a subgroup of the finite group G. Show that there exists a subset {$z_1,...,z_r$} of G which is simultaneously a set of representatives of the left and of the right cosets of H in G, that is, G=$\cup_{i=1}^r z_iH=\cup_{i=1}^rHz_i$.",['combinatorics']
1870268,"How do I prove that for a random variable $X$, we have $P(X \le a) \le p$?","Specifically, suppose that $X$ is a random variable with properties $\mathrm{Var}(X) = 9$, $\mu = \mathbb{E}(X) = 2$, and $\max(X) \le 10$, (or $P(X \ge 10) = 0$). How can I prove the following? $$P(X \le 1) \le \frac{8}{9}$$","['probability-theory', 'probability']"
1870305,Derivative of quaternions,"I am trying to calculate the Jacobian of a function that has quaternions and 3D points in it. I refer to quaternions as $q$ and 3D points as $p$ $$h_1(q)=A C(q)p $$ $$h_2(q)=q_1\otimes q \otimes q_2 $$ where $A\in R^{3x3}$ and $C(q)$ is Direction cosine matrix . I am using the Hamilton form for the quaternions. I would like to calculate the following Jacobians: $$H_1 = \frac{\partial h_1(q)}{\partial q} $$ $$H_2 = \frac{\partial h_2(q)}{\partial q} $$ Following Joan Solà's reference eq. 18 what I have is $$H_1 = A^TC(q)^T[p]_x $$ $$H_2 = [q_1]_L[q_2]_R $$ Where $[q]_R$ and $[q]_L$ are the right and left handed conversion of quaternion to matrix form as defined in Joan Solà's reference eq. 18. All rotations are body centric. Is this correct? 
Is there a better way to do this? 
Can the expression be easily simplified?","['derivatives', 'quaternions']"
1870320,Decomposition to rotation around arbitrary axis,"In 3d, I have a $4\times4$ matrix $M$, which has only a rotation part and a translation part. In other words, I can compute $X'=RX+T$ ( with $R$ a $3\times3$ rotation matrix, $T$ a vector for the translation, $X$ a point and $X'$ its image). Can I write the $4\times4$ matrix $M$ as a rotation around an arbitrary axis (not necessarily through origin)? I would write it as $X'=R(X-X_a)+X_a$  with $X_a$ a point on the axis, and $R$ the same rotation matrix. If yes, I would like to get one point $X_a$, i.e. a point on the axis. My first thought was to solve the system $RX_a+T=X_a$. It's a singular system because we look for an axis. So I set $z=0$ and solve for $x$ and $y$ to get one point. Is there a mistake somewhere? I thought about another way to get this axis, but I don't understand why it does not work. I take two random points, $X_1$ and $X_2$ and compute their image $X_1'$ and $X_2'$ by $M$. I assume the axis is on the plane perpendicular to $X_1X_1'$ through the middle of $X_1X_1'$. Indeed, $X_1$ would be at the same distance to the axis than $X_1'$. I assume this also for $X_2X_2'$. So I get the axis with the intersection between both planes. What is wrong in this approach? Thanks for helping","['matrices', 'rotations', 'geometry']"
1870367,What algebra is generated by $\mathrm{O}(2)$?,"The unit complex numbers can be identified with the $2 \times 2$ special orthogonal matrices $\mathrm{SO}(2)$. The problem with $\mathrm{SO}(2)$, however, is that its not closed under $\mathbb{R}$-linear combinations. To rectify this, we can consider the $\mathbb{R}$-algebra generated by $\mathrm{SO}(2)$, namely $\mathbb{R}[\mathrm{SO}(2)]$, which turns out to be isomorphic to $\mathbb{C}$. It seems natural to play the same trick with $\mathrm{O}(2)$, and see what we get. Question. What is $\mathbb{R}[\mathrm{O}(2)]$? If its not too much to ask, I'd also like to know what $\mathbb{R}[\mathrm{SO}(3)]$ is. I'll ask another question if this isn't answered here.","['abstract-algebra', 'noncommutative-algebra', 'reflection', 'euclidean-geometry', 'geometry']"
