question_id,title,body,tags
3778001,Chi Squared for Goodness of Fit,"Hi, any help is appreciated :) I am trying to teach myself statistics. I've watched the Khan Academy Series on Chi square statistic for hypothesis testing ( https://www.khanacademy.org/math/ap-statistics/chi-square-tests/chi-square-goodness-fit/v/chi-square-statistic ) After completing the multiple choice quizzes, I wanted to create an example of a usecase from my field and walk through the calculating chi square and determining goodness of fit. Here's the assignment I made for myself: 1. Description of scenario Education manager has historical enrollment data, showing the final student enrollment statuses on average are: 5% - transfer 10% - withdraw 20% - fail 65% - pass Over the past two years, there have been organizational changes, so the manager wants to see if the seemingly improved pass rates are better than what we might expect by random chance, given the known distribution. 2. Sample Size, Does it pass the large counts condition? Sample size will be 100, since that is the smallest sample that allows the expected count of 5 or higher. 3. Observed Counts (statistic) transfer - 1 (1.6) withdraw - 5 (2.5) fail - 10 (5) pass - 84 (5.55) 4. Chi Square Test Statistic $\chi ^{2} = 14.65$ 5. Test of Significance df = 3 $\alpha = 0.05$ critical value = 7.815 $\chi ^{2} = 14.65 > 7.815$ So, the difference between the observed and expected values is significant P-Value $H_0 =$ the sample is from the distribution $H_a =$ the sample is from a different distribution $P = 0.002 < P=0.05$ 6. Conclusion Reject the null hypothesis. The observed scores are not from the same distribution. In plain speak, the differences that I am seeing in enrollment trends are significant. Thank you","['chi-squared', 'statistical-inference', 'statistics', 'hypothesis-testing']"
3778024,Properties of distribution function,"Let $(\Omega, \mathcal{F}, P)$ be a probability space, $X$ a random variable and $F(x) = P(X^{-1}(]-\infty, x])$ . The statement I am trying to prove is The distribution function $F$ of a random variable $X$ is right continuous, non-decreasing and satisfies $\lim_{x \to \infty}F(x) = 1$ , $\lim_{x \to -\infty} F(x) = 0$ . As $F(x + \delta) = F(x) + P(]x, x + \delta])$ , we have that $F$ is non-decreasing, but is the measure of an interval bounded by its length? In that case we would have right continuity as well. For the limits, we have $F(x) + P(X^{-1}(]x, \infty]) = P(\Omega) = 1$ , so $F(x) = 1 - P(X^{-1}(]x, \infty])$ , so it suffices for $P(X^{-1}(]x, \infty])$ to get small as $x$ gets large and to get large as $x$ gets small. This is not true for general measures, take the Lebesgue measure for example, but maybe because we need $P(X^{-1}(\mathbb{R}))$ to be $1$ ?","['measure-theory', 'probability-theory']"
3778041,Prove $x^n-p$ is irreducible over $Z[i]$ where $p$ is an odd prime.,"Prove $x^n-p$ is irreducible over $Z[i]$ where $p$ is an odd prime. By gausses lemma this is equivalent to irreducability over $\mathbb{Q}(i)$ . Using field extensions this is easy. $[\mathbb{Q}(i,\sqrt[n]{p}):\mathbb{Q}(i)][\mathbb{Q}(i):\mathbb{Q}]=[\mathbb{Q}(i,\sqrt[n]{p}):\mathbb{Q}(\sqrt[n]{p})][\mathbb{Q}(\sqrt[n]{p}):\mathbb{Q}]=2n$ Thus $[\mathbb{Q}(i,\sqrt[n]{p}):\mathbb{Q}(i)]=n$ and so $x^n-p$ must be the minimal polynomial, and so it is irreducible. However, the book says you can solve this problem using Eisenstein criterion. That is easy when $x^2+1$ is irreducible mod $p$ as $(p)$ is then prime. What do you do in the other cases?","['field-theory', 'abstract-algebra']"
3778048,How would I simplify this function $\rho(x)=x+\sqrt{x-\sqrt{x-\sqrt{x+\sqrt{\dots}}}}$,"How do I simplify $\rho(x)$ into simple terms? $$\rho(x)=x+\sqrt{x-\sqrt{x-\sqrt{x+\sqrt{x-\sqrt{x+\sqrt{x+\sqrt{x-\sqrt{\dots}}}}}}}}$$ where the subtracting and the adding follows the Thue–Morse sequence $$+,-,-,+,-,+,+,-,-,+,+,-,+,-,-,+,\dots$$ I tried doing it with $x+\sqrt{x+\sqrt{x+\sqrt{x+\sqrt{x+\sqrt{x+\sqrt{x+\sqrt{x+\sqrt{\dots}}}}}}}}$ and  got a answer by myself and I did it with $x+\sqrt{x-\sqrt{x+\sqrt{x-\sqrt{x+\sqrt{x-\sqrt{x+\sqrt{x-\sqrt{\dots}}}}}}}}$ and found a post here Simplify the radical $\sqrt{x-\sqrt{x+\sqrt{x-...}}}$ and I understood how it worked I would like to know how to solve a problem like this? where the adding and the subtracting never repeats.","['nested-radicals', 'calculus', 'functions', 'radicals']"
3778059,Derivative Greater Than 0 Implies One-To-One Function In Neighborhood,"Let $f: \textrm{dom}(f) \rightarrow \mathbb{R}.$ Let $x_0 \in \mathbb{R}.$ Assume $f'(x_0) > 0$ . i.e. $~ \displaystyle\lim_{h \rightarrow 0} \frac{f(x_0 + h) - f(x_0)}{h} > 0$ i.e. $~ \exists l > 0 \textrm{ s.t. } \forall \varepsilon_1 > 0, \exists \delta_1 > 0 \textrm{ s.t. } \forall h \in \mathbb{R}, 0 < |h| < \delta_1 \Rightarrow \Bigg| \displaystyle\frac{f(x_0 + h) - f(x_0)}{h} - l \Bigg| < \varepsilon_1$ This implies that $f$ is continuous at $x_0$ , as I have proven before. i.e. $~ \forall \varepsilon_2 > 0, \exists \delta_2 > 0 \textrm{ s.t. } \forall x \in \mathbb{R}, |x - x_0| < \delta_2 \Rightarrow |f(x) - f(x_0)| < \varepsilon_2$ Also, $\exists \delta_3 > 0 \textrm{ s.t. } \forall x \in \mathbb{R}, 0 < |x - x_0| < \delta_3 \Rightarrow \displaystyle\frac{f(x) - f(x_0)}{x - x_0} > 0$ I would like to prove there exists an open interval containing $x_0$ where $f(x)$ does not have a value of $f(x_0)$ for any $x$ in that interval apart from $x_0$ . i.e. $~ \exists a, b \in \mathbb{R} \textrm{ s.t. } a < x_0 < b \wedge \big( \forall x \in (a, b), x \neq x_0 \Rightarrow f(x) \neq f(x_0) \big)$ Unfortunately, I cannot say anything about double differentiability of $f$ . Because of this, I cannot mention continuity of $f$ in a neighborhood of $x_0$ (or can I?) Perhaps there is a counterexample and I shouldn't try to prove this statement. Help needed.","['limits', 'functions', 'derivatives', 'continuity']"
3778069,Combinatorics of a Tournament,"$8$ people participate in a tournament, so that each person plays with all the other people once. If a person wins against another, then the winner gets $2$ points, while the losing team will get none. If they tie, they each get $1$ point, respectively. When finished, the people are ranked depending on how many points they have in total. How many points does a person need to have, to secure their spot in the best four players. I know that the maximum possible amount of points one can achieve is $14.$ I also know a score of $12$ gurantees you to be in the top $5.$ I'm not really sure how to continue with this information, how would I do this problem?",['combinatorics']
3778076,Show that $y'(t)=y^{2/3}(t) \text{ with } y(0)=0$ has infinitely many solutions,"Show that the problem $$y'(t)=y^{2/3}(t) \text{ with } y(0)=0$$ has infinitely many solutions.
Explain why the existence and uniqueness theorem does not apply here My attempt By solving the differential equation by the variable separation method, We get: $\int\frac{1}{y^{2/3}}dy=\int dt$ $\frac{y^{1/3}}{1/3}=t+c$ And by substituting the initial condition $y(0)=0$ we can get $c=0$ Thus $$y(t)=\frac{t^3}{3^3}$$ But from here how should I prove that there are infinitely many solutions?... And for the second part (Uniqueness theorem) isn't it because for the solution of $y'=f(y)$ to be unique, we need $f$ to have a continuous first derivative. But here in this specific example, $$\frac{d}{dy}f=\frac{2}{3}y^{-1/3}$$ which is not continuous at zero.","['calculus', 'ordinary-differential-equations']"
3778083,Convergence/Divergence of Complex Series $\sum\limits_{n=1}^{\infty} \frac{n(2+i)^n}{2^n}$,"$$\sum\limits_{n=1}^{\infty} \frac{n(2+i)^n}{2^n}$$ My Attempt : I am new to analyzing complex series, so please forgive me in advance. I apply the ratio test: $$\lim_{n \to \infty}\frac{|a_{n+1}|}{|a_n|} = \lim_{n \to \infty}\frac{|(n+1)(2+i)^{n+1}2^n|}{|2^{n+1}n \ (2+i)^n|} = \lim_{n \to \infty} |\frac{n+1}{2n}(2+i)| = \frac{1}{2} \lim_{n \to \infty} |2+i|$$ I know that $|z| = |a + bi|$ can be expressed as $\sqrt{a^2+b^2}$ , hence: $$\frac{1}{2} 
\lim_{n \to \infty} \sqrt{5} > 1$$ By the ratio test, this makes the series diverging series. Is this approach correct?","['complex-analysis', 'sequences-and-series']"
3778088,Are there any elementary functions $\beta(x)$ that follows this integral $\int_{y-1}^{y} \beta(x) dx =\cos(y)$,Are there any simple functions $\beta(x)$ that follows this integral $$\int_{y-1}^{y} \beta(x) dx =\cos(y)$$ I think there is an infinite amount of solutions that are continuous everywhere but how can I find one that only uses elementary functions?,"['integration', 'elementary-functions', 'calculus', 'real-analysis']"
3778110,"If $D$ is a Weil divisor, how do I get the invertible sheaf $\mathcal{O}_S(D)$?","In Beauville's Complex Algebraic Surfaces , chapter $1$ , the author takes a smooth variety $S$ (over $\Bbb{C}$ ) and mentions the correspondence between Weil divisors modulo linear equivalence and invertible sheaves modulo isomorphisms: $$D\mapsto \mathcal{O}_S(D)$$ I know that a Cartier divisor $D=\{(U_i,f_i)\}\in\text{CaDiv}(S)$ provides an invertible sheaf defined simply by: $$\mathcal{O}_S(D)\big|_{U_i}:=\frac{1}{f_i}\mathcal{O}_S\big|_{U_i}$$ Which is how we define a map $\text{CaCl}(S)\to\text{Pic}(S)$ . I've already found in different authors an explicit isomorphism $\text{WCl}(S)\to\text{CaCl}(S)$ , so technically I'm able do describe $D\mapsto \mathcal{O}_S(D)$ by the composition $\text{WCl}(S)\to\text{CaCl}(S)\to\text{Pic}(S)$ . However, the construction of $\text{WCl}(S)\to\text{CaCl}(S)$ uses a somewhat subtle argument involving local rings in order to find the functions $f_i$ , so we need at least one paragraph to explain the whole composition honestly. The way Beauville mentions the map $D\mapsto\mathcal{O}_S(D)$ makes it seem natural, so I wonder if there's a simpler description that I don't know about.","['coherent-sheaves', 'divisors-algebraic-geometry', 'algebraic-geometry', 'schemes']"
3778125,Dual image map restricts to open sets?,"A book I'm reading on category theory says that if $A$ and $B$ are topological spaces and $f:A\to B$ is continuous, then the ""dual image"" map $$f_*(U)=\{\,b\in B\mid f^{-1}(b)\subseteq U\,\}$$ restricts to open sets; that is, $f_*:\mathcal{O}(A)\to\mathcal{O}(B)$ . (So then it's right adjoint to $f^{-1}:\mathcal{O}(B)\to\mathcal{O}(A)$ .) This seems wrong, since it would imply for example (taking $U=\varnothing$ ) that the image of a continuous function is always closed. Are there natural conditions under which it does make sense to restrict to open sets?","['continuity', 'general-topology', 'category-theory', 'adjoint-functors']"
3778134,"""Naturally occurring"" non-Hausdorff spaces?","It is not difficult for a beginning point-set topology student to cook up an example of a non-Hausdorff space; perhaps the simplest example is the line with two origins. It is impossible to separate the two origins with disjoint open sets. It is also easy for a beginning algebraic geometry student to give a less artificial example of a non-Hausdorff space: the Zariski topology on affine $n$ -space over an infinite field $k$ , $\mathbf{A}_{k}^{n}$ , is not Hausdorff, due to the fact that polynomials are determined by their local behavior. Open sets here are in fact dense. I am interested in examples of the latter form. The Zariski topology on $\mathbf{A}_{k}^{n}$ exists as a tool in its own right, and happens to be non-Hausdorff. As far as I'm aware, the line with two origins doesn't serve this purpose. What are some non-Hausdorff topological spaces that aren't merely pathological curiosities?","['big-list', 'examples-counterexamples', 'algebraic-geometry', 'general-topology', 'soft-question']"
3778142,How to show $\lim_{n\to\infty}n\cdot \sum_{m=1}^{\infty}\Big(1-\frac{1}{m}\Big)^n\cdot \frac{1}{m^2}=1.$,"I am wondering if the following limit is correct and how to show it. $$\lim_{n\to\infty}n\cdot \sum_{m=1}^{\infty}\Big(1-\frac{1}{m}\Big)^n\cdot \frac{1}{m^2}=1.$$ Edit:
I apologize for the lacking context. My initial motivation was considering the probability that given $n+1$ randomly chosen positive integers, a prime $p$ divides at least two of them. I understand that “randomly choosing $n+1$ integers” isn’t rigorous, and this is simply introducing how I got to the infinite series above. Assuming that a prime $p$ divides an integer with probability $1/p$ and the process is independent, the probability $f(n,p)$ is $$f(n,p)=1–\Big(1-\frac{1}{p}\Big)^n\Big(1+\frac{n}{p}\Big).$$ Interestingly, summing $f(n,p)$ over all primes and observing the plot on mathematica, it seems to bound the prime-counting function $\pi(n)$ from below and I conjectured $\sum_{p}f(n,p) \sim \pi(n).$ Naturally, I also considered $f(n+1,p)-f(n,p),$ which is $$n\Big(1-\frac{1}{p}\Big)^n\cdot \frac{1}{p^2}.$$ Noting that the logarithmic integral approximates the prime-counting function and again comparing plots on mathematica, I conjectured the above formula summed over all primes asymptotically equals $1/\ln(n).$ Finally, to consider a simpler version, I summed the above formula over all positive integers $m$ , which is the infinite series in my original question. Again based on mathematica and “feeling” based off the prime number theorem, I guessed the limit to be 1 as $n$ grows to infinity.","['limits', 'real-analysis']"
3778158,Solving the Biharmonic Equation on an elliptical domain,"I would like to solve the Biharmonic Equation $$\Delta^2 \phi=0$$ on an elliptical domain $c_1<\frac{x^2}{a^2}+\frac{y^2}{b^2}<c_2$ . I converted the Biharmonic equation into $(R,\omega)$ coordinates, where $$R\cos(\omega)=\frac{x}{a},$$ $$R\sin(\omega)=\frac{y}{b}$$ In this new coordinate system the boundary conditions of the PDE correspond to $R=c_1$ and $R=c_2$ and are related the derivatives of $\phi$ with respect to $R$ and $\omega$ . In this new coordinate system I had a PDE where every term had the form $$\frac{C_{k,m}(\omega)}{R^{4-k}}\frac{\partial^{m+k}\phi}{\partial R^k\partial \omega^m}.$$ This looked like a Cauchy-Euler equation in $R$ , so I guessed a solution of the form $$\phi(R,\omega)=R^nH(\omega).$$ When I made this substitution the PDE simplified to an ODE of the form $$P_4(cos(2\omega))H^{(4)}+P_3(\cos(2\omega),\sin(2\omega))H'''+P_2(\cos(2\omega),\sin(2\omega))H''$$ $$+P_1(\cos(2\omega),\sin(2\omega))H'
+P_0(\cos(2\omega))H=0,$$ where $$P_4(x)=c_{41}x+c_{42}x^2,$$ $$P_3(x,y)=c_{31}y+c_{32}xy,$$ $$P_2(x,y)=c_{21}+c_{22}y+c_{23}x+c_{33}xy+c_{34}x^2+c_{35}y^2,$$ $$P_1(x,y)=c_{11}y+c_{12}xy,$$ $$P_0(x)=c_{01}+c_{02}x+c_{03}x^2$$ and the coefficients depend on $n$ , $a$ , and $b$ . If I can find $H$ in terms of $n$ and then I am hoping that I can write $$\phi(R,\omega)=\sum_{n\in K}\left(A_nR^nH_n(\omega)\right)$$ for some set $K$ (or maybe it might be an integral rather than a sum if there is an uncountable number of values of $n$ that I would use) and then I would solve for the $A_n$ 's using my boundary conditions. In summary, I want to know how to solve the biharmonic equation on an elliptical domain with a hole in it. Either I would like to know how to start from scratch if my attempt won't get me there, how to solve for $H$ in the ODE I wrote down, or if there is a source where they already solved my problem and where I can find their paper. EDIT: I tried using elliptical coordinates as mattos suggested and I got the PDE $$\left(\frac{\partial^4\phi}{d\mu^4}+\frac{\partial^4\phi}{\partial\mu^2d\nu^2}+\frac{\partial^4\phi}{\partial\nu^4}\right)\left(\cosh(2\mu)-\cos(2\nu)\right)-4\sinh(2\mu)\left(\frac{\partial^3\phi}{\partial\mu^3}+\frac{\partial^3\phi}{\partial\mu\partial\nu^2}\right)$$ $$-4\sin(2\nu)\left(\frac{\partial^3\phi}{\partial\mu^2\partial\nu}+\frac{\partial^3\phi}{\partial\nu^3}\right)$$ $$+4(\cosh(2\mu)+\cos(2\nu))\left(\frac{\partial^2\phi}{\partial\mu^2}+\frac{\partial^2\phi}{\partial\nu^2}\right)=0.$$ I can't use separation of variables because of the mixed derivative terms and the method of characteristics doesn't work well for elliptic PDEs so I'm not sure how to proceed (the only two methods for solving PDEs that I know of are separation of variables and the method of characteristics)","['elliptic-equations', 'ordinary-differential-equations', 'partial-differential-equations']"
3778183,Question on Radon-Nikodym derivatives,"In Folland's Real Analysis, there is this theorem: Suppose that $\nu$ is a $\sigma$ -finite signed measure and $\mu, \lambda$ are $\sigma$ -finite positive measures on $(X, \mathcal{M})$ such that $\nu \ll \mu$ and $\mu \ll \lambda$ . Then, the following hold: (a) If $g \in L^{1}(\nu),$ then $g(d \nu / d \mu) \in L^{1}(\mu)$ (the function $g$ multiplied by $d \nu / d \mu$ ) and $$
\int g d \nu=\int g \frac{d \nu}{d \mu} d \mu
$$ (b) We have $\nu \ll \lambda$ (this is obvious from $\nu \ll \mu$ and $\mu \ll \lambda$ ), and $$
\frac{d \nu}{d \lambda}=\frac{d \nu}{d \mu} \frac{d \mu}{d \lambda} \text{ holds for } \lambda \text {-a.e. }
$$ The proof is given as follows: Let $E \in \mathcal{M}$ . By considering $\nu^{+}$ and $\nu^{-}$ separately, we may assume that $\nu \geq 0$ . The equation $\int g d \nu=\int g(d \nu / d \mu) d \mu$ is true when $g=\chi_{E}$ by definition of $d \nu / d \mu$ . That is, noting that $d \nu = f d \mu$ , we have $\int \chi_E d \nu = \int \chi_E f d \mu$ . This is exactly $\int g d \nu=\int g(d \nu / d \mu) d \mu$ for $g=\chi_{E}$ . It is therefore true for simple functions by linearity of integrals, then for nonnegative measurable functions by the monotone convergence theorem, and finally for functions in $L^{1}(\nu)$ by linearity (adding/subtracting the positive/negative parts of the real/imaginary parts of $g, g \frac{d \nu}{d \mu}$ , etc.) again. Replacing $\nu, \mu$ by $\mu, \lambda$ and setting $g=\chi_{E}(d \nu / d \mu),$ we obtain from (a): $$
\nu(E)=\int_{E} \frac{d \nu}{d \mu} d \mu=\int_{E} \frac{d \nu}{d \mu} \frac{d \mu}{d \lambda} d \lambda
$$ for all $E \in \mathcal{M},$ $\textbf{therefore $(d \nu / d \lambda)=(d \nu / d \mu)(d \mu / d \lambda)$ holds for $\lambda$-a.e. by proposition 1}$ . I don't understand the last part, the part in boldface. For reference, proposition 1 states: (a) If $f \in L^1$ , then $\{ x:f(x) \neq 0\}$ is $\sigma$ -finite. (b) If $f,g \in L^1$ , then $\int_E f = \int_E g$ for all $E \in \mathcal{M}$ $\iff$ $\int ||f-g|| = 0$ $\iff$ $f = g$ a.e.. Surely, in order to use this proposition, one must have $\int_{E} \frac{d \nu}{d \mu} d \lambda=\int_{E} \frac{d \nu}{d \mu} \frac{d \mu}{d \lambda} d \lambda $ ? Is there some connection between $\mu$ and $\lambda$ that I am missing?","['measure-theory', 'solution-verification', 'radon-nikodym', 'real-analysis']"
3778201,"What are differences between Geometric, Logarithmic and Exponential Growth?","At past I have read in some ecology text that geometrical, logarithmic and exponential growths are not exactly the same thing; and there were various equations for them. (The book is not available to me now, and I forgot its name). My question is : What is the basic difference of these 3 growth patterns? What would be some real-life analogy to distinguish 3 growth patterns? Note: This question is Not same with existing decay curve question Thanks in advance. Update: I have found a diagram similar to the book in which I saw the concept. Source: https://cmapspublic3.ihmc.us/rid=1R0TPVNFG-113V4JS-1H9C/1R2CJ0126I1VCLY5MI1GHRIimage Looks like there are already confusion about this distinction between exponential and geometric growth. Some sources claim a difference such as There are another source at nature scitable that says ""Exponential growth and geometric growth are similar enough that over longer periods of time, exponential growth can accurately describe changes in populations that reproduce periodically (like bison) as well as those that reproduce more constantly (like humans)"" i.e. it accepts that exponential growth and geometric growth are different at least to some extent. Some other sources critic this idea such as this source says this distinction a ""Zombie idea"" and according to a quora discussion answer ""There is absolutely no difference"" For example, the function 2ˣ tell us that the number 2 can be multiplied “x times” you want. Lets do a simple sequence of the latter function where x goes from 0 to 5. Our sequence looks like this 2⁰=1, 2¹=2, 2²=4, 2³=8, 2⁴=16, 2⁵= 32, … this is exponential growth.
Now lets do it using the geometric method that is repeated multiplication, in this case we start with x goes from 0 to 5 and our sequence goes like this: 1, 2, 2•2=4, 2•2•2=8, 2•2•2•2=16, 2•2•2•2•2=32. The conflicts have made me more confused about the concept of a dfference between Geometric and exponential growth.","['biology', 'statistics', 'applications', 'logarithms']"
3778210,ISL 2006 G3:Prove that the line $AP$ bisects the side $CD$.,"Let $ABCDE$ be a convex pentagon such that $$ \angle BAC = \angle CAD = \angle DAE \qquad \text{and}\qquad \angle ABC = \angle ACD = \angle ADE.$$ The diagonals $BD$ and $CE$ meet at $P$ . Prove that the line $AP$ bisects the side $CD$ . My Proof: Note that by $AAA$ , we get $\Delta ABC \sim \Delta ADE$ . Hence $A$ is the spiral center of the spiral similarity that sends $CB$ to $ED$ . Hence, $EDPA$ is cyclic and $PACB$ is cyclic . Now, note that, since $\angle AED= \angle ADC$ and $\angle ABC=\angle ACD$ , we have $DC$ as the common tangent of $(EDPA)$ and $(APCB)$ . Let $AP\cap DC= M$ . Note that, since $AP$ is the radical axis of $(EDPA)$ and $(APCB)$ , and $DC$ is the common tangent of $(EDPA)$ and $(APCB)$ . We have $AP$ bisecting $DC$ .","['contest-math', 'euclidean-geometry', 'geometry']"
3778233,"How well can the function $f(x_1,x_2)$ be approximated by $f_1(x_1)+f_2(x_2)$?","Is it possible to find the upper bound of the following quantity? $\min_{f_1,f_2}\int_0^1\int_0^1|f^*(x_1,x_2)-f_1(x_1)-f_2(x_2)|^2dx_1dx_2$ . where $f_1,f_2$ can be any continous functions. For example, $\min_{f_1,f_2}\int_0^1\int_0^1|x_1x_2-f_1(x_1)-f_2(x_2)|^2dx_1dx_2$ . Are there any related works in the literature? Any comments are welcome.","['calculus', 'functional-analysis']"
3778261,"MLE of $(\theta_1,\theta_2)$ in a piecewise PDF","I am trying to find the MLE of $\theta=(\theta_1,\theta_2)$ in a random sample $\{X\}_{i=1}^n$ with the following pdf $$f(x\mid\theta)= \begin{cases}
(\theta_1+\theta_2)^{-1}\exp\left(\frac{-x}{\theta_1}\right) &,  x>0\\ 
(\theta_1+\theta_2)^{-1}\exp\left(\frac{x}{\theta_2}\right) &,  x\le0\\
\end{cases}
$$ If I let $\bar{X}_1$ be the average of the $n_1$ values where $X_1>0$ and $\bar{X}_2$ the average of $n_2$ values where $X_i\le 0$ and $n_1+n_2=n$ Then the likelihood function is: $$L(\theta\mid  X)=\left(\frac 1 {\theta_1+\theta_2}\right)^n\exp\left(\frac{-n_1\bar{X}_1}{\theta_1}+\frac{n_2\bar{X}_2}{\theta_2}\right)$$ but I am having trouble maximizing this function.","['statistical-inference', 'statistics', 'parameter-estimation', 'maximum-likelihood']"
3778288,How does the universal set apply to the truth set?,"If the truth set is identical to it's universal set, then the statement is logically true statement and it's called a tautology. Can someone please explain the universal set to me in this context? I thought the universal set has to be defined for each problem, so how is it defined, for, say, $\neg (p\wedge q)\iff (\neg p) \vee (\neg q)$ I'm not taking a class, just interested in learning more about math. Thanks 😊","['logic', 'discrete-mathematics']"
3778319,Calculating (the orbits under the action of) the group generated by two 1-parameter subgroups acting on a Euclidean space: is there a method?,"I have a 5-dimensional Euclidean space, $E$ , with an orthonormal basis ${\bf x}, {\bf y}_{1}, {\bf w}_{1}, {\bf y}_{2}, {\bf w}_{2}$ and two transformations: $$
A_{1} : -{\bf x} + {\bf y}_{1} \mapsto {\bf w}_{1}, \quad {\bf w}_{1} \mapsto {\bf x} - {\bf y}_{1}, \quad 
{\bf y}_{2} \mapsto {\bf 0}, \quad {\bf w}_{2} \mapsto {\bf 0} 
$$ and $$
A_{2} : -{\bf x} + {\bf y}_{2} \mapsto {\bf w}_{2}, \quad {\bf w}_{2} \mapsto {\bf x} - {\bf y}_{2}, \quad 
{\bf y}_{1} \mapsto {\bf 0},\quad {\bf w}_{1} \mapsto {\bf 0}.
$$ I am trying to calculate the orbit of a generic point in $E$ under the action of the group, $G_{A_{1}, A_{2}}$ , generated by the 1-parameter groups $t \mapsto e^{t A_{1}}, t \mapsto e^{t A_{2}}$ . Here are approaches I have tried and challenges encountered (which are almost surely from my lack of familiarity with the needed theory, so an answer like ""read X"" is a great answer). Calculate the Lie algebra generated by $A_{1}, A_{2}$ with the Lie bracket defined as the commutation: $[A_{1}, A_{2}] = A_{2} A_{1} - A_{1} A_{2}$ .  I am getting that the dimension is no lower than 6.  But even having a basis for the Lie algebra, is there a theory for determining the group $G_{A_{1}, A_{2}}$ ?  (The underlying field is the reals, not algebraically closed, so Dynkin diagrams would not apply.) Trying to consider, first, the two 1-parameter groups as if acting on two disjoint 3-D Euclidean spaces (then the orbit of a point is the torus $S^{1} \times S^{1}$ ), and then trying to calculate the topological factor space $(S^{1} \times S^{1}) / \sim$ by a suitable relation $\sim$ (which identifies two 1-dimensional subspaces from each 3-D space), but have had a hard time ""seeing"" the factor space. Anyway, if there is a theory, I'd appreciate some sources.  If I am missing something straightforward, being pointed toward it would be great.","['general-topology', 'lie-groups', 'differential-geometry']"
3778392,Radon-Nikodym Derivative: Proposition 3.9 Folland,"Suppose that $\nu$ is a $\sigma$ -finite signed measure and $\mu, \lambda$ are $\sigma$ -finite positive measures on $(X, \mathcal{M})$ such that $\nu \ll \mu$ and $\mu \ll \lambda$ . Then, the following hold: (a) If $g \in L^{1}(\nu),$ then $g(d \nu / d \mu) \in L^{1}(\mu)$ (the function $g$ multiplied by $d \nu / d \mu$ ) and $$
\int g d \nu=\int g \frac{d \nu}{d \mu} d \mu
$$ (b) We have $\nu \ll \lambda$ (this is obvious from $\nu \ll \mu$ and $\mu \ll \lambda$ ), and $$
\frac{d \nu}{d \lambda}=\frac{d \nu}{d \mu} \frac{d \mu}{d \lambda} \text{ holds for } \lambda \text {-a.e. }
$$ I have no qualms with the proof of (a). Here is the proof for (b), and I am having difficulty understanding the part in bold: For any measurable set $E$ , note that by definition we have $$
\nu(E) = \int_E \left(\frac{d\nu}{d\lambda}\right)d\lambda.
$$ Use (a) by replacing measures $\nu,\mu$ by the measures $\mu, \lambda$ , and we obtain that for $g \in L^1(\mu)$ , $$\int g d\mu = \int g \left(\frac{d\mu}{d\lambda}\right)d\lambda.$$ $\textbf{Letting $g = \chi_E \left(\frac{d\nu}{d\mu}\right)$, we obtain that (how do we show $g \in L^1(\mu)$? This is needed for us to use (a).)}$ $$\int \chi_E \left(\frac{d\nu}{d\mu}\right) d\mu = \int \chi_E \left(\frac{d\nu}{d\mu}\right) \left(\frac{d\mu}{d\lambda}\right)d\lambda.$$ We also have by definition: $$
\nu(E) = \int_E \left(\frac{d\nu}{d\mu}\right)d\mu := \int \chi_E \left(\frac{d\nu}{d\mu}\right)d\mu.
$$ Thus, we conclude: $$\nu(E) = \int \chi_E \left(\frac{d\nu}{d\mu}\right) d\mu = \int \chi_E \left(\frac{d\nu}{d\mu}\right) \left(\frac{d\mu}{d\lambda}\right)d\lambda.$$ Note that we have shown $$
\nu(E) = \int_E \left(\frac{d\nu}{d\lambda}\right)d\lambda = \int \chi_E \left(\frac{d\nu}{d\mu}\right) \left(\frac{d\mu}{d\lambda}\right)d\lambda.
$$ We can now apply proposition 1 to give the desired conclusion. (This is irrelevant to the question, but) Proposition 1 states: (a) If $f \in L^1$ , then $\{ x:f(x) \neq 0\}$ is $\sigma$ -finite. (b) If $f,g \in L^1$ , then $\int_E f = \int_E g$ for all $E \in \mathcal{M}$ $\iff$ $\int ||f-g|| = 0$ $\iff$ $f = g$ a.e..","['measure-theory', 'solution-verification', 'radon-nikodym', 'real-analysis']"
3778403,Coset Enumeration: Defining Cosets,"I have a problem with understanding the initial step in the Todd-Coxeter coset enumeration algorithm. One needs to define a few cosets when you start off, but I'm not sure how to define them. As an example, I found the following example: For the presentation $\left\langle {x,y\;\left| {{x^3} = {y^3} = {{\left( {xy} \right)}^2} = 1} \right.} \right\rangle$ and subgroup $H = \left\langle x \right\rangle$ , I do understand you firstly define $H: = 1$ , and hence $1x=1$ , but how does one know to define $1y=2$ , $2y=3$ , $3y=1$ , $2x=3$ , etc.? I know for example $1y=2$ follows from $Hy=2$ and $2y=3$ follows from $Hy^2=3$ , but how does one know in which order to enumerate them? Why was $Hy^2$ not defined to be ' $Hy^2=4$ ' for example? Another example I found is the presentation $\left\langle {x,y\;\left| {{x^2} = {y^2} = {{\left( {xy} \right)}^3} = 1} \right.} \right\rangle$ and subgroup $H = \left\langle x \right\rangle$ . Here, how does one know to initially define $2x=3$ , $3y=4$ and $4x=5$ ?","['combinatorial-group-theory', 'group-presentation', 'group-theory', 'abstract-algebra']"
3778496,What is the shortest distance you have to travel to reach where the other person was initially(12 ft apart)?,"You are 12ft away from a person walking towards you. He will keep walking straight, even in these COVID times. But you want to keep a minimum 6ft distance at all times. Both are walking at the same speed at all times. And you can take any path. But he will move along the straight line joining the 2 points. What is the shortest distance you have to travel to reach where the other person was initially (12 ft apart)?","['optimization', 'locus', 'geometry']"
3778520,Further interesting examples? Obtaining (co)monoids from dual objects,"1. Context Obtaining (co)monoids from dual objects Let $(C, \otimes,  I, a, l,r)$ be a monoidal category. To simplify notation (and work with string diagrams) we assume that $C$ is strict. Let $V \in C$ be a right dualizable object, i.e. there exists an object $V^* \in C$ and morphisms $b_V: I \rightarrow V \otimes V^*$ , $d_V: V^* \otimes V \rightarrow I$ that satisfy the zigzag-identities. It seems, this data alone induces the structure of a monoid object $(V \otimes V^*, \mu, \eta)$ where $\mu = (r_V \otimes id_{V^*})\circ (id_V \otimes d_V \otimes id_{V^*})$ and $\eta =b_V$ . This can be verified by using the zigzag identities. Analogously, it seems we have the structure of a comonoid object $(V^* \otimes V, \Delta, \epsilon)$ where $\Delta:(id_{V^*} \otimes b_V \otimes id_V)\circ (r^{-1}_{V^*} \otimes id_V)$ and $\epsilon=d_V$ . Two motivating examples The category of endofunctors $End(C)$ of any small category $C$ . It becomes a monoidal category in the following way: Composition of functors is the monoidal product. The monoidal unit is given by the identity functor on $C$ . As the composition of functors is associative this category is strict. A right dual to an object $F \in End(C)$ is a right adjoint functor to that functor $F$ . (Co)monads are (co)monoid objects in the category of endofunctors. Hence, above construction shows how one can obtain a (co)monad from a pair of adjoint functors (i.e. by suitably composing the pair of adjoint functors, and defining the respective natural transformations as described above.) Consider the monoidal category of finite dimensional vector spaces (over a field) with tensor product of vector spaces as the monoidal product. This category is rigid. (The dual vector space is precisely the right/left dual object. Evaluation and coevaluation are the morphisms $d$ and $b$ respectively.) Let $V$ be an object in that category. We then have the identification $End(V) \cong V \otimes V^*$ . The above construction hence endows $End(V)$ with the structure of a unital, associative algebra. 2. Questions This algebra structure is the same as the the algebra structure on $End(V)$ given by the composition of maps (multiplication) and $\eta (1_{\mathbb k})=id_V$ (unit). Correct? By the above construction we can turn $V \otimes V^* \cong End(V)$ into a coalgebra. Is the induced coproduct $\Delta:End(V) \rightarrow End(V) \otimes End(V)$ simply the diagonal map $\Delta(f)=f \otimes f$ ? What is the counit specified on a basis of $End(V)$ ? What are other (enlightening or interesting) examples of the above construction (obtaining (co)monoids from dual objects) in other monoidal categories from the ones mentioned?","['monoidal-categories', 'examples-counterexamples', 'category-theory', 'abstract-algebra', 'dual-spaces']"
3778523,Condition of positive definiteness based upon diagonal elements of the original and inverse matrices,This is a sequel to this question in which I sought to expand on this question . Let me put it straight. Given a non-singular symmetric real matrix $A\in\mathbb{R}^{n\times n}$ such that $A_{ii}>0$ . Can we conclude that $A$ is positive definite if $$(A^{-1})_{ii}\ge \frac1{A_{ii}}$$ holds for all $1\le i\le n$ ?,"['reference-request', 'matrices', 'linear-algebra', 'inverse', 'positive-definite']"
3778527,Prove a relation $\mathcal R$ is reflexive if and only if its complement $\overline{\mathcal R}$ is irreflexive (strict).,"Given a homogeneous binary relation $\mathcal R$ over a set $A$ , $\mathcal{R}$ is reflexive if: $$\forall a \in A:(a,a) \in \mathcal R$$ Prove a relation $\mathcal R$ is reflexive if and only if its complement $\overline{\mathcal R}$ is irreflexive (strict). $\Longrightarrow$ By the definition of complement relation: $$\forall a,b \in A :(a,b) \in \mathcal R \implies (a,b) \notin \overline{\mathcal R}$$ Taking $a=b$ follows: $$\forall a \in A :(a,a) \in \mathcal R \implies (a,a) \notin \overline{\mathcal R}$$ Which is true since $\mathcal R$ is reflexive. $\Longleftarrow$ By the definition of complement relation: $$\forall a,b \in A :(a,b) \in \overline{\mathcal R} \implies (a,b) \notin \mathcal R$$ Taking $a=b$ follows: $$\forall a \in A :(a,a) \in \overline{\mathcal R} \implies (a,a) \notin \mathcal R$$ Since $ \overline{\mathcal R}$ is irreflexive, hence $\forall a \in A :(a,a) \in \overline{\mathcal R}$ is never true, and hence its negation is always true for all $a \in A$ , however I still cannot finish the proof. Another way is using contradiction argument, assume $\overline{\mathcal R}$ is irreflexive, but $\mathcal R$ is not reflexive, i.g.: $$\forall a \in A :(a,a) \notin \overline{\mathcal R}$$ And $$\exists a \in A :(a,a) \notin \mathcal R$$ From here we see that exists such $a \in A$ satisfying the two conditions $(a,a) \notin \overline{\mathcal R}$ and $(a,a) \notin \mathcal R$ , but do we end up with a contradiction? Can someone help me finishing this proof?","['elementary-set-theory', 'proof-explanation', 'relations']"
3778528,"Evaluate $\int_{(0,\infty)^n}\text{Sinc}(\sum_{k=1}^nx_k) \prod_{k=1}^n \text{Sinc}(x_k) dx_1\cdots dx_n$","In this post @metamorphy established this remarkable result (here Sinc $(x)$ denotes $\frac{\sin(x)}x$ ): $$I(n)=\int_{(-\infty,\infty)^n}\text{Sinc}(\sum_{k=1}^nx_k) \prod_{k=1}^n \text{Sinc}(x_k) dx_1\cdots dx_n=\pi^n$$ The current problem is: What can we say about $$J(n)=\int_{(0,\infty)^n}\text{Sinc}(\sum_{k=1}^nx_k) \prod_{k=1}^n \text{Sinc}(x_k) dx_1\cdots dx_n=?$$ It's not hard to establish $J(1)=\frac \pi 2, J(2)=\frac {\pi^2}6$ . Due to lack of enough symmetry, in  general $J(n)$ can't be deduced from $I(n)$ directly. I tried to apply the method used in previous post but did not succeed. Any suggestion is appreciated.","['integration', 'definite-integrals']"
3778529,Derivation of an integral function in $L^p$,"I know that for any continuous function $f:[0,1]\to\mathbb{R}$ $$\frac{d}{dx} \int_0^x f(y)dy = f(x).$$ Let's say that $f\in L^p$ for $p>1$ . Can I say that the equality still holds almost everywhere?
If not, what is the largest subset of $L^p$ such that the equality holds almost everywhere?","['integration', 'derivatives', 'real-analysis']"
3778550,How to evaluate the limit of multifactorial $\lim_{n\to 0} \sqrt[n]{n!!!!\cdots !}$,"It is well known that $\displaystyle \lim_{n\to \infty}\sqrt[n]{n!}=\infty$ , however, if we let $n\to 0$ we have a different result with a beautiful combination of $e$ and $\gamma$ , that is $$\lim_{n\to 0}\sqrt[n]{n!}= e^{-\gamma}\tag{1}\label{1}$$ To prove result \eqref{1}, we observe that the limit attains the form of $1^{\infty}$ so we can write it as $$\lim_{n\to 0} \exp\left(\frac{\ln\Gamma(n+1)}{n}\right)\underbrace{=}_{\text{L'Hopital's rule}}\lim_{n\to 0} e^{\Gamma'(n+1)}=e^{\psi_0(1)}= e^{-\gamma}$$ Now I wish to know the limit of the following  multifactorial form  for $k\in\mathbb {Z^+}$ $$\lim_{n\to 0}\sqrt[n]{n\smash[b]{\underbrace{!! !!\cdots !}_{k}}}={?}\tag{2}\label{2}\\$$ For $k=1$ we are done above and for $k=2$ we get the limit $\sqrt{2} e^{-\frac{\gamma}{2}}$ . To prove this we use the double factorial argument ( see equation (5) ) \begin{align}\lim_{n\to 0}\sqrt[n]{n!!}&=\lim_{n\to 0} \left(2^{\frac{n}{2}+\frac{1-\cos(\pi n)}{4}}\pi^{\frac{\cos(\pi n)-1}{4}}\Gamma\left(1+\frac{n}{2}\right)\right)^{\frac{1}{n}}\\&=\sqrt{2}\lim_{n\to 0} \sqrt[n]{\Gamma\left(1+\frac{n}{2}\right)}\\&=\sqrt 2\exp\lim_{n\to 0}\left(2^{-1} \Gamma\left(1+\frac{n}{2}\right)\psi_0\left(1+\frac{n}{2}\right)\right)\tag{L'Hopital's rule}\\&=\sqrt{2}e^{-\frac{\gamma}{2}}\end{align} since for $k=1,2$ we have evaluated the limit. How to evaluate the limit of equation \eqref{2} for all $k>2$ ?","['factorial', 'real-analysis', 'gamma-function', 'sequences-and-series', 'limits']"
3778564,What is an example of a function $f: \mathbb{R} \rightarrow \mathbb{R}$ that is only continuous on the irrational numbers and zero?,Can someone give me an example of a function $f: \mathbb{R} \rightarrow \mathbb{R}$ that is only continuous on the irrational numbers and zero ?,"['continuity', 'functions', 'real-analysis']"
3778570,"What does a ""well ordering on $\Bbb R$"" mean? [duplicate]","This question already has answers here : A way to well-order real line (3 answers) Closed 3 years ago . A well order is a poset such that every non empty subset of this set has a least element. Does ""well ordering on $\Bbb R$ "" mean that every non empty subset of $\Bbb R$ (which is a poset) has a least element?","['elementary-set-theory', 'lattice-orders', 'real-analysis']"
3778626,Transitive actions and equivalence relations (Berkeley Problems in Mathematics),"This question is about Problem 6.5.12 in the Berkeley Problems in Mathematics, 3rd edition, which reads as follows: Let $G$ be a transitive subgroup of the group $S_n$ .  Suppose that $G$ is a simple group and that $\sim$ is an equivalence relation on $\{1,...,n\}$ such that $i\sim j$ implies that $\sigma(i)\sim \sigma(j)$ for all $\sigma \in G$ .  What can one conclude about relation $\sim$ ? After working through the problem I'm still not quite sure what answer this problem might be looking for (unfortunately the answer is not in the back of my edition).  According to Keith Conrad's posting ""Transitive Group Actions"", relations such as the above are called $G$ -equivalence relations, and they can be classified as follows: fix an index in $\{1,...,n\}$ (let's just say $1$ for definiteness).  Then let $H$ be the stabilizer of $1$ .  The $G$ -equivalence relations on $\{1,...,n\}$ are in bijective correspondence with intermediate subgroups $H \subset K \subset G$ (Theorem 7.5 in the aforementioned article). All this sounds nice and reasonable to me - but I don't see how simple groups are relevant in any of this, except to say that if $G$ is abelian and simple then there are no non-trivial such equivalence relations since there are no non-trivial intermediate subgroups.  Is there an answer to the above question that takes into account the ""simple"" part of the requirement in a natural way?","['group-actions', 'equivalence-relations', 'group-theory', 'abstract-algebra']"
3778651,What is the relation between the two definitions of typical set,"In the 3rd chapter of the book Elements of Information Theory , typical set is defined as follows. $$A_{\epsilon}^{n}=\{x^n: H(X)-\epsilon \le\frac{1}{n}\log p(x^n) \le H(X)+\epsilon\}$$ In the 11th chapter, another definition is given as: $$T_{Q}^{\epsilon}=\{ x^n:D(P_{x^n})||Q)\le\epsilon\} $$ What is the relation between them? Which is stricter?","['statistics', 'probability-theory', 'asymptotics', 'information-theory']"
3778656,"Prove: $\int_0^{\infty} \frac{\ln{(1+x)}\arctan{(\sqrt{x})}}{4+x^2} \, \mathrm{d}x = \frac{\pi}{2} \arctan{\left(\frac{1}{2}\right)} \ln{5}$","Prove: $$\int_0^{\infty} \frac{\ln{(1+x)}\arctan{(\sqrt{x})}}{4+x^2} \, \mathrm{d}x = \frac{\pi}{2} \arctan{\left(\frac{1}{2}\right)} \ln{5}$$ This might be a repeat question (I couldnt find a question of this here).  If im being honest I dont know the first step really...  Maybe a clever integration by parts, substitution, differentiation under integral sign, power series, or contour?  If someone could give advice.","['integration', 'definite-integrals', 'real-analysis', 'complex-analysis', 'calculus']"
3778663,"Evaluate $\int_0^{\pi/2} \frac{\arctan{\left(\frac{2\sin{x}}{2\cos{x}-1}\right)}\sin{\left(\frac{x}{2}\right)}}{\sqrt{\cos{x}}} \, \mathrm{d}x$","Evaluate: $$\int_0^{\frac{\pi}{2}} \frac{\arctan{\left(\frac{2\sin{x}}{2\cos{x}-1}\right)}\sin{\left(\frac{x}{2}\right)}}{\sqrt{\cos{x}}} \, \mathrm{d}x$$ I believe there is a ""nice"" closed form solution but Wolfram is too weak.  These arctan integrals are so tricky!  I sense a substitution like $\sin{\frac{x}{2}}$ because of arctan argument and $\sqrt{\cos{x}}$ but I just cant get it.  Any ideas or tips please. Source: https://tieba.baidu.com/p/4794735082 (Exercise 3.1.22).","['integration', 'calculus', 'definite-integrals', 'real-analysis']"
3778713,Why is it important for a correlation matrix to be positive semidefinite?,Now I understand the definition of positive semidefiniteness but I am struggling to understand as to why a Correlation matrix must be positive semidefinite. What are the effects of negative eigenvalues in relation to correlation matrices?,"['statistics', 'positive-semidefinite', 'correlation', 'matrices', 'positive-definite']"
3778737,Are singular foliations spanned by collinear vector fields equal?,"Let $M$ be a compact $n$ -manifold (let's say with boundary, but this isn't too important), $X$ a vector field on $M$ and $f:M \to \mathbb{R}$ a non-zero function on $M$ . My question: are the singular foliations spanned by $X$ and $fX$ equal? In other words, do the traces of trajectories of $X$ and $fX$ with the same starting point coincide? I tried a couple of simple examples and checked that they do coincide, and I did a heuristic argument which works in my favor: if $p \in M$ such that $X_p = 0$ , then obviously the trajectories starting at $p$ of $X$ and $fX$ coincide (it's just the point $p$ ). Otherwise, there exists a chart centered at $p$ where $X = \frac{\partial}{\partial x_1}$ , and so in this chart, $\phi_t^X(p) = (e^t,0,\dots,0)$ . On the other hand, the flow of $fX$ starting at $p$ is locally the solution of the equation $$x' = (f(x) \cdot x_1, 0, \dots, 0), \hspace{5pt} x(0) = 0,$$ and if we set $g(x_1) := f(x_1,0,\dots,0)$ , then $x_1' = g(x_1)x_1$ , $x_2 = \cdots = x_n = 0.$ If we define $$G(x_1) := \int \frac{dx_1}{g(x_1)x_1},$$ then, heuristically, $$x_1 = G^{-1}(t),$$ and both of the trajectories are contained in the $\{ x_2 = \cdots = x_n = 0\}$ -part of the chart. However, I don't think this is a difficult question and I'd like to see a formal argument. I suspect that the only reason that I'm unable to resolve this is because of my (very) rusty knowledge of the theory of ODE's.","['vector-fields', 'foliations', 'ordinary-differential-equations', 'differential-geometry']"
3778764,Find derivative of $\lfloor{x}\rfloor$ in distribution,Find derivative in distribution of $f(x)=\lfloor{x}\rfloor=E(x)$ $$E(x)≤x≤E(x+1)$$ Answer is : $$\lfloor{x}\rfloor '=\displaystyle\sum_{k=-\infty}^{\infty}\delta_{k}$$ I don't have any idea about how to. Can you assist? I'm too thankful,"['distribution-theory', 'derivatives', 'real-analysis']"
3778779,L'Hopital's Rule Complication,"$\textrm{Let } f(x) = \begin{cases} \displaystyle\frac{g(x)}{x}~, & \!\! x \neq 0 \\ 0~, & \!\! x = 0 \end{cases} \textrm{ for all } x \in \mathbb{R}.$ $\textrm{Assume } g(0) = g'(0) = 0 \wedge g''(0) = 17.$ $\textrm{Want To Prove } f'(0) = \displaystyle\frac{17}{2}.$ Information Necessary For The Use Of L'Hopital's Rule: Important Lemmas I showed that $f$ is continuous at $0$ so that $f'(0)$ can be computed using the limit definition. In order to compute $f'(0)$ , I wish to use L'Hopital's Rule (LHR). $f'(0)$ $= \displaystyle\lim_{x \rightarrow 0} \frac{f(0 + x) - f(0)}{x}$ $= \displaystyle\lim_{x \rightarrow 0} \frac{f(x) - f(0)}{x}$ $= \displaystyle\lim_{x \rightarrow 0} \frac{f(x) - 0}{x}$ $= \displaystyle\lim_{x \rightarrow 0} \frac{f(x)}{x}$ $= \displaystyle\lim_{x \rightarrow 0} \frac{\displaystyle\frac{g(x)}{x}}{x}$ $= \displaystyle\lim_{x \rightarrow 0} \frac{g(x)}{x^2}$ $= \displaystyle\lim_{x \rightarrow 0} \frac{g'(x)}{2x}~~~$ According to LHR: Justification In order to get $\displaystyle\frac{17}{2}$ , I must use L'Hopital's Rule again to get $\displaystyle\lim_{x \rightarrow 0} \frac{g''(x)}{2}$ . However, so far, I cannot show that $g''(x)$ is never $0$ as $x \rightarrow 0$ , which is an important property justifying the use of LHR. In other words, I have no continuity assumption or third derivative to prove there exists an interval containing $0$ where $g''(x)$ is never $0$ , using the information I have derived. This is my attempt so far of justifying my second use of LHR: Justification 2 As you can see, I am missing the final step regarding $g''(x)$ . Any help would be appreciated. Let me know if there is any function $g$ where $f'(0)$ wouldn't be $\displaystyle\frac{17}{2}$ , in which case I must assume something about $g$ or $g''$ .","['limits', 'functions', 'derivatives', 'continuity']"
3778790,"Is the function $f = \sum_{n=0}^{\infty} 2^{-n}\chi_{[n,n+1)}$ Lebesgue integrable on $\mathbb{R}$?","Is the function $f = \sum_{n=0}^{\infty} 2^{-n}\chi_{[n,n+1)}$ Lebesgue integrable on $\mathbb{R}$ ? Justify your answer. I came across this question on a past exam paper for a measure theory course I'm taking and I can't find anything similar in my professors notes to help me work through it. I have a feeling that I should be using a convergence theorem but I'm not quite sure which one. A push in the right direction would be appreciated! Thanks in advance.","['integration', 'measure-theory', 'lebesgue-integral']"
3778791,"Show that the $L^1$ and $L^2$ norms are not equivalent on the set of continuous functions from $[0,1]$ to $\mathbb{R}$","Let $E$ be the vector space of continuous functions on $[0,1]$ .
Show that the $L^1$ -norm is not equivalent to the $L^2$ -norm. My thought was that, given a sequence of functions $f_n\in E$ which converges to the function $\frac{1}{\sqrt{x}}$ , we can see that $$||f_n||_1=\int_0^1|f_n|dx \to \int_{0}^1 \frac{1}{\sqrt{x}}dx=2\sqrt{0}+2\sqrt{1}=2 $$ However, $$||f_n||_2=\left(\int_{0}^1 (f_n)^2 dx \right)^{1/2}\to \left(\int_0^1 \frac{1}{x}dx\right)^{1/2}$$ Since this sequence converges with respect to one norm but not the other we can conclude that they are not equivalent. Does this argument make any sense? It feels like it doesn't make sense to talk about the norm of a function that isn't in the space $E$ since $\frac{1}{\sqrt{x}}\notin E$ . But the hint for the problem says to consider truncating said function near 0.","['lp-spaces', 'solution-verification', 'normed-spaces', 'functional-analysis']"
3778801,A property of the floor function $x\mapsto \lfloor x\rfloor$,"This is problem is from Vinogradov's elementary number theory book. For any real number $a>0$ , define $f_a:\mathbb{N}\rightarrow\mathbb{Z_+}$ by $x\mapsto \lfloor ax\rfloor$ . Given $\alpha,\beta>0$ , show that $f_\alpha$ , $f_\beta$ are injective, $f_\alpha(\mathbb {N})\cap f_\beta(\mathbb{N})=\emptyset$ , and $\mathbb{N}=f_\alpha(\mathbb{N})\cup f_\beta(\mathbb{N})$ if and only if $\alpha,\beta\in\mathbb{R}\setminus\mathbb{Q}$ and $\frac1\alpha + \frac1\beta =1$ Sufficiency is not difficult to prove. The part I am struggling with is necessity, where I don't seem able to control the gaps between values of $f_\alpha$ (or $f_\beta$ for that matter.) Any hints will be appreciated.","['elementary-number-theory', 'real-analysis']"
3778881,generalization of cubic spline and thin plate spline,"Let us consider some interpolation problems: $\renewcommand\phi\varphi$ We have some points $n$ points $x_i \in \mathbb R^d$ along with corresponding values $y_i \in \mathbb R$ . We'd like to find a function $f: \mathbb R^d \to \mathbb R$ subject to the constraints $f(x_i) = y_i \forall i=1, \ldots, n$ . For $d=1$ if we additionally require $f$ to minimize the bending energy $E = \int \left(\frac{d^2f}{dx^2} \right) dx$ (the energy of a thin rod bent in a way such that it goes through $(x_i, y_i)$ ), then it turns out $f$ must be the cubic spline. We can represent cubic splines using the RBF (radial basis function) $\phi(r) = \vert r \vert^3$ . For $d=2$ we can repeat the same, this time instead of a rod, we use a thin idealized piece of e.g. sheet metal, where the bending energy is $E = \int \left(\frac{\partial^2 f}{\partial x^2}\right)^2 + 2\left(\frac{\partial^2 f}{\partial x\partial y}\right)^2+\left(\frac{\partial^2 f}{\partial y^2}\right)^2 dxdy$ . We can then represent  the function $f$ minimizing $E$ using thin plate splines which can be represented using the RBF $\phi(x) = |r|^2 \log(|r|)$ . Are there any $RBFs$ known for the solutions of when we generalize this problem to $d=3$ and $d>3$ ? I'm not sure but I assume in the general case the energy would be $$E = \int \sum\limits_{i_1 + i_2 + \ldots+  i_n = 2} \binom{2}{i_1,i_2,\ldots,i_n}\left( \frac{\partial^2f}{\prod_j \partial x_{j}^{i_j}} \right)^2 d\pmb x.$$","['numerical-methods', 'spline', 'functional-analysis', 'functional-calculus']"
3778888,Almost disjoint families on uncountable sets,"Suppose that $\Gamma$ is an infinite set. Let us say that a family $\mathscr A$ of subsets of $\Gamma$ is almost disjoint, whenever for any two distinct sets $A_1, A_2\in \mathscr{A}$ the intersection $A_1\cap A_2$ has cardinality strictly less than $|\Gamma|$ and for any $A\in \mathscr{A}$ we have $|A|=|\Gamma|$ . Does there always exist an almost disjoint family of cardinality $2^{|\Gamma|}$ , or at least bigger than $|\Gamma|$ ? When $\Gamma$ is countable, then of course this is the case, but I have a feeling this should fail for singular cardinals.","['cardinals', 'combinatorics', 'set-theory']"
3778900,Is there a function defined on an interval that is right-differentiable a.e. but not left-differentiable?,"Inspired by this post , I was thinking about how different the left and right sided derivatives could be at a point. For instance, if $f(x) = e^{-1/\log(x)}$ , $f(1)=0$ , the right derivative at $x=1$ is zero but the left-derivative doesn't exist. One could stitch together several of these functions, for instance $F_n(x) = \sum_{k=1}^n f(x-k)$ , but I'm wondering if this pathology can be extended to yield a function $F$ that is right-differentiable almost-everywhere but left-differentiable almost-nowhere. Happy to provide clarification or more details if needed.","['derivatives', 'real-analysis']"
3778929,"Weyl theorem, compact and relatively compact operators","Weyl's Theorem says that if $A$ is a $T$ -compact operator on a Banach space $X$ , then $T$ and $T+A$ have the same essential spectrum. To be $T$ -compact, $A$ must satisfy two conditions (1) $D(T)\subset D(A)$ (2) For any bounded sequence $\{u_n\}\subset D(T)$ such that $\{Tu_n\}$ is bounded then $\{Au_n\}$ contains a convergent sub-sequence. I have a few questions: (1) From what I understand, the definition of being compact is that for any bounded sequence $\{u_n\}\subset X$ then $\{Au_n\}$ contains a convergent sub-sequence. Thus it implies that the domain of a compact operator be all of $X$ . Is that right? (2) If $A$ is compact, it is automatically $T$ -compact, thus satisfies the condition of the theorem. Is that right? (3) If I have an operator $T+A$ with both $T$ and $A$ having each a ""natural"" domain such that the condition $D(T)\subset D(A)$ be not satisfied. However, $D(T+A)=D(T\cap A)$ . Then one could reduce the domain $T$ and $A$ to $D(T+A)$ . Then the condition (1) of relative compactness would automatically be satisfied and only condition (2) is needed to be checked. Then, in the end, one just need to check Condition (2) on $D(T+A)$ to apply Weyl's theorem. Is that right? (4) Finally, I am in the following situation: I can check that for any bounded sequence $\{u_n\}\subset D(A)$ , then $\{Au_n\}$ has a converging subsequence. So, "" $A$ is compact on its domain"". Does such a notion exist?","['banach-spaces', 'compact-operators', 'hilbert-spaces', 'functional-analysis', 'spectral-theory']"
3778958,Homogeneous Linear Differential Equation with Constant Coefficientes,"Consider the differential equation $$x^{(n)} + c_{n-1} x^{(n-1)} + \dots + c_1 x' + c_0 = 0,$$ with $c_0, c_1, \dots, c_{n-1} \in \mathbb{R}$ . Show that $x(t) = t^ke^{\beta t}$ is a solution if and only if $\beta$ is a root of $z^n + c_{n-1}z^{n-1} + \dots + c_1z + c_0 = 0$ with multiplicity greater than $k$ . Attempt: I tried to solve this exercise in several ways, but they all led me to calculate $$(t^k e^{\beta t})^{(n)} + c_{n-1} (t^ke^{\beta t})^{(n-1)} + \dots + c_1 (t^ke^{\beta t})' + c_0.$$ After a few tries, I got that $$(t^k e^{\beta t})^{(i)} = \sum_{j=0}^{i} i! \left( \begin{array}{c} k \\ k-j \end{array} \right) t^{k-j} \beta^{i-j} e^{\beta t}. $$ My initial idea was to use induction over $n$ . The case $n = 1$ is quite easy, but it is too tedious to work with this sum through the rest of the induction. My professor suggested that I use Jordan Canonical Form, but I am having a hard time to understand how to use it in order to prove the equivalence. Any help would be appreciated!",['ordinary-differential-equations']
3778967,Integral for infinitely small interval,"I was thinking about integration by parts on small interval, $[a, a + dx]$ when $dx \to 0.$ More precisely, suppose $f(x) = f, g(x) = g$ are both differentiable. I wanted to prove directly that $$f(a + dx)g(a + dx) - f(a)g(a) \tag{*} $$ is equal to $\int_{a}^{a + dx} g \, df + \int_{a}^{a + dx} f \, dg $ (this is formula for IBP). Indeed, we can simply write $f(a + dx) - f(a) = df$ and similarly $g(a + dx) - g(a) = dg.$ Now we have that (*) is $(f(a) + df)(g(a) + dg) - f(a)g(a) = f(a)dg + g(a)df + dfdg.$ We can intuitively exclude $dfdg$ from calculation (as product rule tells us). And now, the crushing part : if $\int_{a}^{a + dx}g\,df$ is equal to $gdf$ (and of course same for other integral) we are done. Let me explain: we can treate $df$ as some fixed value, so we want to prove $$df \cdot \int_{a}^{a + dx}g = g(a)df.$$ This looks very weird. Interval is getting smaller and smaller but we can always find input $x := \frac{2a + dx}{2}$ (midpoint of $[a, a + dx]$ ) and corresponding output $g(\frac{2a + dx}{2})$ (and midpoints of that two subintervals, etc.) Therefore, sum of $g$ -values is always (much) greater than $g(a)$ because there is $\infty$ many $g$ values for inputs between $a, a + dx.$ My intuition tells me that this is because somehow $dx < c, \forall c \in \mathbb{R},$ but that doesn't seem right. In short: how is possible (if is) that for real function defined on interval $[a, a + dx]$ is $\int_{a}^{a + dx}f(x) = f(a)$ ?","['real-numbers', 'definite-integrals', 'real-analysis', 'limits', 'derivatives']"
3779033,is it possible for a function continuous everywhere and differentiable nowhere have a finite arc length between two points? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question is it possible for a function continuous everywhere and differentiable nowhere have a finite arc length between two points? and if so how would you find it? it was a little weird finding out such functions exists I didn't know if it was possible or not to even define arc length.","['functions', 'real-analysis']"
3779060,Order 5 rational map?,$p(z) = 1-\frac{1}{z}$ has order 3: $p(p(p(z))) = z$ Is there an order 5 rational map with rational coefficients?,['functions']
3779061,Is $i$ well defined? [duplicate],"This question already has an answer here : Why are $i$ and $-i$ ""more indistinguishable"" than $\sqrt{2}$ and $-\sqrt{2}$? (1 answer) Closed 3 years ago . I know, it may sound as nothing but a provocative question, and probably it is. However I've been thinking about it for a while, despite being aware that the question itself may not have much sense. Consider the field $\mathbb{R}$ . Each element can be defined univocally. First $0$ and $1$ , then the integers, so the rationals and then all the others (for instance as equivalence classes of Cauchy sequences on $\mathbb{Q}$ ). Now we can define the complex field $\mathbb{C}$ as $$\mathbb{C} = \mathbb{R}[X]/(X^2+1)$$ where $\mathbb{R}[X]$ is the ring of polynomials with real coefficient. However here it becomes impossible to univocally define a root of the polynomial $X^2+1$ since it has two roots (which we will eventually call $\pm i$ ) and they are totally indistinguishable. I know that in practice it's not a problem, we just decide to call one of the two roots $i$ and the other $-i$ . But what's going on exactly? Is it some kind of ""axiom"" the fact that we are allowed to choose one out of a set of two identical elements?","['complex-analysis', 'abstract-algebra', 'axioms']"
3779070,Ring Homomorphisms on Integral Domains,"THIS PROBLEM WAS TAKEN FROM A CURRENTLY UNPUBLISHED MANUSCRIPT OF JOSEPH SILVERMAN FROM BROWN UNIVERSITY Characterize all integral domains $R$ for which the map $f: R \rightarrow R$ given by $f(a) = a^{pq}$ for distinct primes $p,q$ is a ring homomorphism. If $pq=6$ , then there's only one such integral domain ( $\mathbb{F}_2$ , and for $pq = 15$ , the integral domains are $\mathbb{F}_2, \mathbb{F}_3$ ), but beyond that I can't make much meaningful progress. Could we maybe separate into cases based on the characteristic of $R$ ? This seems related to the Frobenius endomorphism, but that deals with a map to a single prime power. Perhaps if we could somehow prove a congruence with a power of a prime so as to permit iteration of the mapping?","['field-theory', 'number-theory', 'ring-theory', 'abstract-algebra']"
3779116,Union of intersection of families,"I'm studying Halmos' Naive Set Theory . In Section 9, Families , he (essentially) mentions a following exercise (on page 35). Exercise. If $\{A_i\}$ and $\{B_j\}$ are both nonempty families, then $(\bigcap_iA_i)\bigcup(\bigcap_jB_j)=\bigcap_{i,j}(A_i\bigcup B_j)$ . However, I think that this is wrong, and the equality should be replaced with inclusion, i.e. , LHS should be a subset of ( not generally equal to) the RHS. Correct?",['elementary-set-theory']
3779118,Need help with $\arccos$ equation,"I have the equation $$ \cos(2x + \frac{\pi}{9}) = 0.5$$ I know that in order to solve for $x\in \Bbb R$ , I need to use $$\arccos(0.5) = 2x + \frac{\pi}{9} $$ This yields $$  2x + \frac{\pi}{9} =
\begin{cases}
\frac{\pi}{3} + 2k\pi,  & \text{Positive angle} \\
2 \pi - \frac{\pi}{3}+ 2k\pi, & \text{Negative angle}
\end{cases} $$ I would then subtract $\frac{\pi}{9}$ from both sides and get: $$  2x  =
\begin{cases}
\frac{2\pi}{9} + 2k\pi,  & \text{Positive angle} \\
\frac{14\pi}{9}+ 2k\pi, & \text{Negative angle}
\end{cases} $$ However according to the handout the correct solution is: $$  2x  =
\begin{cases}
\frac{4\pi}{9} + 2k\pi,  & \text{Positive angle} \\
\frac{16\pi}{9}+ 2k\pi, & \text{Negative angle}
\end{cases} $$ Can anyone help me?","['algebra-precalculus', 'solution-verification', 'roots', 'trigonometry']"
3779135,Prove an Elementary sum of floor function,"Prove:
If $a$ and $b$ are odd and relatively prime, $$\sum_{\substack{0 \lt x \lt b/2\\x \in Z}} \left\lfloor \frac{ax}{b} \right\rfloor + \sum_{\substack{0 \lt y \lt a/2\\y\in Z}} \left\lfloor \frac{by}{a} \right\rfloor = \frac{a-1}{2} \cdot \frac{b-1}{2}$$ I have already proved that if $a$ and $b$ are relatively prime, $\sum_{x=0}^{b-1} \left\lfloor \frac{ax}{b} \right\rfloor = \frac{(a-1)(b-1)}{2}$ . My thinking was to possibly use this fact, and split this equation into 2 equations according to the separate variables and intervals. However, I am not sure how to split the equation into $a$ and $b$ , so I'm lost on how to approach this problem. Any help would be appreciated.","['number-theory', 'summation', 'elementary-number-theory', 'ceiling-and-floor-functions']"
3779238,Prove that $F$ is Lebesgue measurable and $\sum_{n=1}^\infty m(E_n)\geq Km(F)$ under these conditions...,"Question : Suppose $E_n$ , $n\in\mathbb{N}$ , is a sequence of Lebesgue measurable subsets of $[0,1]$ .  Let $F$ be the set of all points $x\in[0,1]$ that belong to at least $K$ (some positive number) of the $E_n$ 's.  Prove that $F$ is Lebesgue measurable and $\sum_{n=1}^\infty m(E_n)\geq Km(F)$ . My Attempt/Idea :  First, let's show that $F$ is measurable.  Let's consider a function $f=\sum_n\chi_{E_n}$ .  Then, $f:[0,1]\rightarrow[0,\infty]$ is measurable, and so $f^{-1}([K,\infty])$ is measurable.  Since $f^{-1}([K,\infty])$ is precisely the number of points that belong to at least $K$ of the $E_n$ 's, we have that $F=f^{-1}([K,\infty])$ is measurable. Now we want to show the inequality. $\int f=\int\sum_n\chi_{E_n}=\sum_n\int\chi_{E_n}$ , since $f$ are nonnegative functions by MCT.  Let $G$ be the set of all points $x\in[0,1]$ that don't belong to at least $K$ of the $E_n$ 's.  Then, $\sum_n\int\chi_{E_n}=\sum_n(\int_F\chi_{E_n}+\int_G\chi_{E_n})$ .... but I am not sure if I am on the right track.....","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
3779263,Simple Concave Function Question,"Suppose we have a function $f:[0,\infty)\longrightarrow [0,\infty)$ that is concave and $a > b>0$ . Then given a constant $c>0$ I claim that $f(a+c) - f(a) \le f(b+c) - f(b)$ . If I draw a picture, this statement seems obvious, but I can't seem to find a simple proof to actually show that this is the case! Any help would be greatly appreciated. Thanks.","['functions', 'convex-analysis']"
3779267,"If $ab + c = 1993,$ what is $a + b + c?$","$a, b$ and $c$ are three prime numbers and $c$ is a one-digit number. If $ab + c = 1993,$ what is $a + b + c?$ So just by guessing, I've determined that $c=2$ , and $a=181, b=11$ . But if someone could explain how to do it quicker, I'd really appreciate it! Thank you!","['number-theory', 'divisibility', 'prime-numbers']"
3779289,Kloosterman sums in $\mathbb{Z}_{(p)}$,"Define the Kloosterman sum $$K(m, n, c) := \sum_{d \hspace{1ex}(\hspace{-1.2ex}\mod\hspace{-.5ex} c)^{*}} e^{\frac{2\pi i (nd + m\overline{d})}{c}},$$ where $d \hspace{1ex}(\hspace{-1.2ex}\mod\hspace{-.5ex} c)^{*}$ runs through those primitive $d$ coprime to $c$ , and where $\overline{d}$ is the inverse of $d$ modulo $c$ . I want to find what conditions on $m, n, c$ , if any, make $K(m, n, c)$ a $p$ -rational number. That is, I want to find out when $K(m, n, c) \in \mathbb{Z}_{(p)}$ . Is there any literature on this? I have no success so far in Googling. At least a little push in the right direction could help :-)","['number-theory', 'abstract-algebra', 'reference-request']"
3779332,Properties of subsets for which $\sum 1/k$ diverges,"The well-known Erdos-Turan conjecture is the following. Let $V \subset \mathbb{N}$ be such that $\sum_V k^{-1}$ diverges. Then $V$ contains arithmetic progressions of every possible length. A recent result showed such a set $V$ must contain infinitely many length- $3$ progressions. I am wondering: if $V \subset \mathbb{N}$ is such that $\sum_V k^{-1}=\infty$ , what are some properties of $V$ ? This Wikipedia page gives a small number of properties, but I am curious whether there are others (being non-trivial).","['divergent-series', 'conjectures', 'number-theory', 'additive-combinatorics', 'combinatorics']"
3779369,Examining cycles in a sequence,"I am looking at a problem in Engel's problem solving strategies: Start with an $n$ -tuple $S=(a_0,a_1,\ldots, a_{n-1})$ of nonnegative integers.
Define the operation $T(S):=(|a_0-a_1|, |a_1-a_2|,\ldots, |a_{n-1}-a_0|)$ .
Now consider the sequence $S, T(S), T(T(S)),\ldots$ .
For instance, if we take $n=4$ and $S=(0,3,10,13)$ , we get $(0,3,10,13)\mapsto (3,7,3,13)\mapsto (4,4,10,10)\mapsto(0,6,0,6)\mapsto(6,6,6,6)\mapsto(0,0,0,0)$ . Prove that, for $n\neq 2^r,$ we get (up to some exceptions) a cycle containing just two numbers: $0$ , and evenly often some number $a>0$ . Let $n\neq 2^r$ and let $c(n)$ be the cycle length. Prove that $c(2n)=2c(n)$ up to some exceptions. Prove that, for odd $n$ , $S=(0,0,\ldots,0,1,1)$ always lies on a cycle. The problem does not elaborate on what the 'exceptions' are.
Some given hints/progress I've made: The sequences $S$ and $tS$ have the same 'life expectancy', where $tS$ denotes multiplication of each element by $t\in \mathbb{N}$ .
This is because $T(tS)=tT(S)$ , so $T^k(tS)=0 \iff tT^k(S)=0 \iff T^k(S)=0$ . For $n=2^r$ , we always reach $(0,\ldots, 0)$ .
Note that in mod 2, $|a-b|\equiv a+b$ .
So $T(a_0,a_1,\ldots,a_{n-1})\equiv (a_0+a_1,a_1+a_2,\ldots,a_{n-1}+a_0)$ , and $T^2(S)\equiv (a_0+a_2,a_1+a_3,\ldots)$ etc.
Continuing on, we see that these indices $a_i$ present in each slot has a structure identical to the parity of Pascal's triangle, where applying $T$ takes us to the next row in the triangle.
So for $n=2^r$ , via the property of Pascal's triangle that the $2^r-1$ 'th row is entirely odd, we will reach $(\sum a_i, \sum a_i, \ldots, \sum a_i)$ , which then maps to $(0, 0,\ldots,0)$ in mod 2.
Therefore after each $2^r$ steps we can extract a common factor of 2 from the $n$ -tuple.
Further let $\max S$ denote the maximal element of $S$ . Observing that $\max S\geq\max T(S)$ , a descent argument will show that the eventually we must reach all $0$ 's. A suggestion from the book: given the sequence $(a_0,a_1,\ldots,a_{n-1})$ , assign the polynomial $p(x)=a_{n-1}+\ldots+a_0x^{n-1}$ with coefficients in mod 2, and $x^n=1$ .
Then the polynomial $(1+x)p(x)$ belongs to $T(S)$ . EDIT:
the book includes a table of $c(n)$ values, which were computer generated. The first few values on the table are: $c(3)=3, c(5)=15, c(7)=7, c(9)=63, c(11)=341, c(13)=819, c(15)=15, c(17)=255, c(19)=9709...$ . There seem to be various patterns in here, for instance, $c(2^k+1)=2^{2k}-1$ .","['invariance', 'problem-solving', 'absolute-value', 'sequences-and-series']"
3779374,What would the picture for partial fractions look like?,"As how integration by parts has the picture below, what would the picture for partial fractions look like? Although there's probably no way to escape the heavy algebra necessary for partial fractions, is there a intuitive or geometric visualization of partial fractions? And is there one that doesn't rely on animated pictures? The closest thing that seems are those diagrams where kids do basic operations on fractions by colouring in boxes like . And so, for partial fractions, each of those coloured sections would be different rational functions. Probably would be hard or impossible to generalize though.","['integration', 'calculus', 'polynomials', 'partial-fractions', 'rational-functions']"
3779392,How many $4$-digit numbers of the form $1a2b$ are divisible by $3$?,"How many $4$ -digit numbers of the form $\overline{1a2b}$ are divisible by $3?$ Hello I am new here so I don’t really know how this works. I know that for something to be divisible by 3, you add the digits and see if they are divisible by $3$ . So that means $3+a+b=6, 9, 12, 15, 18,$ or $21.$ I’m just confused about how to calculate the number of cases.","['number-theory', 'divisibility']"
3779508,Jordan normal form of sum of two commuting nilpotent matrices over a finite field (variant on a linear matrix pencil problem),"This question comes up with trying to construct Lie subalgebras of (large) Lie algebras that are invariant under a finite group $H$ . I have two isomorphic $H$ -invariant nilpotent subalgebras and am interested in the Jordan normal forms of matrices in diagonal subalgebras of these algebras. I have two commuting nilpotent matrices $A$ and $B$ , (dimension 1596, so cannot be just looked at), defined over the field $\mathbb{F}_9$ . They both cube to zero, and so $A+\lambda B$ cubes to zero for any $\lambda\in\overline{\mathbb{F}_3}$ . I'm interested in the Jordan normal form of the matrix $A+\lambda B$ , where $\lambda$ is a parameter. In all the examples I have so far, if $A$ and $B$ have the same normal form (in the particular case I have in front of me, blocks $3^{285},1^{741}$ ) then for all but finitely many values of $\lambda$ the blocks of the sum are the same. Furthermore, the number of exceptions to this statement is small, say around $2$ . This could be because my matrices, coming from Lie algebras, are very special. What I really want to know if the following: Is it true that $A+\lambda B$ has Jordan normal form independent of $\lambda$ for cofinitely many $\lambda$ ? Is there a bound on the number of exceptions, say in characteristic $3$ with cube zero matrices? If $A$ and $B$ are defined over $\mathbb{F}_q$ then do the exceptions lie in a fixed overfield, say $\mathbb{F}_{q^6}$ ? (I am thinking $6$ because then all quadratics and cubics in $\lambda$ split. I know that one needs at least $\mathbb{F}_{q^2}$ by examples.) I really want to know that the JNF of $A+\lambda B$ is what I think it should be for most elements of the algebraic closure, leaving only a finite number to check with a computer. I can do finitely many checks, but not infinitely many! Or is there an algorithm that allows us to understand such problems?","['jordan-normal-form', 'lie-algebras', 'finite-fields', 'matrices', 'linear-algebra']"
3779512,No simple group of order 720,"In his Notes on Group Theory, 2019 edition ( http://pdvpmtasgaon.edu.in/uploads/dptmaths/AnotesofGroupTheoryByMarkReeder.pdf p. 83 and ff.)
Mark Reeder gives a proof of the non-existence of simple groups of order 720.
P. 83, before the proof, he says : ""In the former case, where $n_3(G) = 40$ , the normalizer of a Sylow3-subgroup P acts by an involution on P with trivial fixed points, and normalizes every subgroup of P.""
A little lower, in the proof of Lemma 10.26, he says :
""If $n_{3}(G)  =  40$ then $N_{G}(P)$ contains an element inverting $P$ ,  hence normalizing $Q$ ."" If I understand it correctly, the reasoning is as follows : if $G$ is a simple group of order 720, if the number of Sylow 3-subgroups of $G$ is 40, then the normalizer $N_{G}(P)$ of a Sylow 3-subgroup $P$ of $G$ has order 18 and is not abelian. So far, so good (the normalizer is nonabelian in view of Burnside's normal complement theorem). M. Reeder seems to find it obvious that this implies that $N_{G}(P)$ is isomorphic either to the dihedral group of order 18 or to the generalized dihedral group constructed on a noncyclic group of order 9. But a nonabelian group $H$ of order 18 can also be isomorphic to the direct product of a group of order 3 with $S_{3}$ and in this case, it is not true that every element of order 2 of $H$ normalizes every subgroup of order 3 of $H$ . Thus, for me, the remark of Mark Reeder is not evident. Mark Reeder gives the following link to a proof by Derek Holt : http://sci.tech-archive.net/Archive/sci.math/2006-12/msg07456.html but this link no longer works. I can prove that $G$ has exactly 10 Sylow 3-subgroups and deduce from this that these  Sylow 3-subgroups have trivial pairwise intersections, but my proof is quite long, so, reading M. Reeder, I'm afraid that something is escaping me. Thus, my question is : can you explain the two sentences of M. Reeder that I quoted above ? Thanks in advance. By the way, I think that the non-existence of simple groups of order 720 can be proved in the following way. Let us define a colian group as a finite froup G with the following properties :
1° G is simple;
2° the order of G is divisible by 9 and not by 27;
3° the Sylow 3-subgroups of G are in number 10;
4° the Sylow  3-subgroups of G are noncyclic;
5°  the Sylow  3-subgroups of G interset pairwise trivially. The proof given by Cole of the isomorphy of all simple groups of order 360 (or, in any case the variant of this proof given here : https://fr.wikiversity.org/wiki/Th%C3%A9orie_des_groupes/ chapter 35) can easily be extended to the following statements :
1° every simple group of order 360 is colian;
2° every colian group is isomorphic to $A_{6}$ ;
3° (and thus  every simple group of order 360 is isomorphic to $A_{6}$ .) Then we prove that a simple group of order 720 should be colian, and thus should be isomorphic to $A_{6}$ , which is absurd since $A_{6}$ has order 360. Edit 1 (September 18, 2020). There is no problem with this part of Mark Reeder's proof. He proves (lemma 10.16) that if $P$ is an abelian Sylow subgroup of a nonabelian finite simple group $G$ , then no non-identity element of $P$ is centralized by $N_{G}(P)$ . Thus if $\vert P \vert = 9$ , $N_{G}(P)$ cannot be the direct product of a group of order $3$ with a group isomorphic to $S_{3}$ . Edit 2 (September 22, 2020). I think that the end of the proof of lemma 10.26 in M. Reeder's exposition (p. 83-84) can be simplified.
The author assumes that $G$ is a simple group of order 720 and that $Q$ is a subgroup of order 3 of $G$ contained in several Sylow 3-subgroups of $G$ and he needs to draw a contradiction from it.
He proves that $N_{G}(Q)$ has order 72, so $Q$ has exactly 10 conjugates in $G$ . Let $X$ denote the set of the conjugates of $Q$ in $G$ . Thus, $X$ has cardinality 10 and, as noted by the author, $G$ acts faithfully on $X$ by conjugation. The author proves that the $Q$ -orbits in $X$ have sizes 1, 3, 3, 3. Thus, if $t$ is an element of $Q \setminus \{1\}$ , (1) the permutation $M \mapsto tMt^{-1}$ of $X$ has only one fixed point. The author also notes that, by the $N/C$ theorem, $C_{G}(Q)$ has order 36 or 72. From here, I would say what follows. Just remember that $C_{G}(Q)$ has even order. That implies that $t$ is the square of an element of order 6. (Choose $a$ of order 2 in $C_{G}(Q)$ , then $t$ is the square of $t^{-1}a$ and $t^{-1}a$ has order 6.) Thus $t = u^{2}$ , with $u$ of order 6. In view of simplicity of $G$ , $u$ acts on $X$ by conjugation as an even permutation of order 6 and thus $t$ acts on $X$ by conjugation as the square of an even permutation of order 6. But an even permutation of order 6 of a set with cardinality 10 has cyclic structure 6-2-1-1, 3-3-2-2 or 3-2-2-1-1-1, thus the square of such a permutation has at least 4 fixed points, which contradicts the result (1) of the author, If I'm wrong, please say it me. Edit 3. (October 26, 2020) There is another problem, perhaps more serious, with M. Reeder's proof. See ( No simple group of order 720, again ). Edit 4. (March 26, 2023) @Derek Holt. Introducing your proof, you said : ""Let me know if it would helpful to include any further details anywhere, or if you can shorten any parts of the proof."" I think your proof is correct, but I can perhaps make some remarks. Here is my first remark. (I will continue if it seems to interest you.) 1° I think that in the proof of Jordan's proposition, it is not necessary to distinguish between the cases $|\Delta \cap g(\Delta)| = 1$ and the other case. Here is a proof without this distinction. It is long, but the reason is perhaps that I try to be exhaustive. For a finite set $\Omega$ and a subset $E$ of $\Omega$ , I will note $Alt_{\Omega}(E)$ the subgroup of $Alt({\Omega})$ formed by the even permutations of $\Omega$ that fix all elements of $\Omega \setminus E$ . $Alt_{\Omega}(E)$ is canonically isomorphic to $Alt(E)$ . (You note it $Alt(E)$ .) If $\Omega$ is a finite set and $G$ a subgroup of $Sym(\Omega)$ , I will say that a subset $E$ of $\Omega$ is richly permutated by $G$ if $Alt_{\Omega}(E)$ is contained in $G$ . The two following lemmas are easy to prove. Lemma 1. Let $\Omega$ be a finite set, $E$ a subset of $\Omega$ and $\sigma$ an element of $Sym(\Omega)$ . Then $Alt_{\Omega}(\sigma(E)) = \sigma Alt_{\Omega}(E) \sigma ^{-1}$ . Lemma 2. Let $\Omega$ be a finite set, $G$ a subgroup of $Sym(\Omega)$ , $E$ a subset of $\Omega$ richly permutated by $G$ . For every element $g$ of $G$ , $g(E)$ is also a subset of $\Omega$ richly permutated by $G$ . Theorem (Jordan). Let $\Omega$ be a finite set and $G$ a primitive subgroup of $Sym(\Omega )$ . If $G$ contains a $3$ -cycle, then $G$ contains $Alt(\Omega )$ (and is thus equal to $Alt(\Omega )$ or to $Sym(\Omega )$ ). Proof. By hypothesis, $G$ contains a $3$ -cycle $(x_{1} \ x_{2} \ x_{3})$ . Then the subset $\{x_{1}, \ x_{2}, \ x_{3})$ of $\Omega$ is richly permutated by $G$ , so there is at least a subset of $\Omega$ that is richly permutated by $G$ and that has cardinality at least $3$ (for example, $\{ x_{1}, \ x_{2}, \ x_{3} \}$ is such a subset). So, among the subsets of $\Omega$ that are richly permutated by $G$ and that have cardinality at least $3$ , we can choose one, say $\Delta$ , that is maximal for inclusion. We will prove that $\Delta$ is the whole $\Omega$ . Assume, by contradiction, that (hyp. 1) $\Delta$ is not the whole $\Omega$ . Then, since $| \Delta | > 1$ , $\Delta$ is not a trivial block for $G$ . Thus, since $G$ is primitive by hypothesis, $\Delta$ is not a block for $G$ . So, there is an element $g$ of $G$ such that we can choose $e_0 \in \Delta \cap g(\Delta )$ and $c_0 \in g(\Delta ) \setminus \Delta$ . For every distinct $a, b$ in $\Delta \setminus \{e_0 \}$ , $a, b$ and $e_0$ are three distinct elements of $\Delta$ , thus (since $\Delta$ is richly permutated by $G$ ) (2) $(a \ b \ e_0 ) \in G$ . On the other hand, $c_0 $ and $e_0 $ are two distinct elements of $g(\Delta )$ . Since $|\Delta| \geq 3$ , which implies $|g(\Delta )| \geq 3$ , we can choose an element $d_0 $ of $g(\Delta )$ that is distinct from $c_0 $ and $e_0 $ . Since (Lemma 2), $g(\Delta )$ is a subset of $\Omega$ richly permutated by $G$ , we have (3) $(c_0 \ d_0 \ e_0 ) \in G$ . From (2) and (3) results $(c_0 \ d_0 \ e_0)  \ (a \ b \ e_0 ) \ (c_0 \ d_0 \ e_0 )^{-1} \in G$ , i.e. (I compose permutations from right to left) (4) $(a \ b \ c_0 ) \in G$ , for every distinct $a$ and $b$ in $\Delta \setminus \{e_0 \}$ . We proved this for every distinct $a$ and $b$ in $\Delta \setminus \{e_0 \}$ . Let us prove that is true for every distinct $a$ and $b$ in $\Delta $ . We have to prove that (4) is still true if $a$ or $b$ is equal to $e_0 $ . In other words, we have to prove the two following theses : (thesis 5) for every $b$ distinct from $e_0$ in $\Delta $ , $( e_0 \ b \ c_0 ) \in G$ (thesis 6) for every $a$ distinct from $e_0$ in $\Delta $ , $( a \ e_0 \ c_0 ) \in G$ . Let $b$ be an element distinct from $e_0$ in $\Delta $ . Since $|g(\Delta )| \geq 3$ , we can choose an element $a_0$ distinct from $b$ in $\Delta \setminus \{ e_{0} \}$ . Then, by (2), (7) $(a_0 \ b \ e_0 ) \in G$ . On the other hand, we have, by (4), $(a_0 \ b \ c_0 ) \in G$ . With (7), this implies $(e_0 \ b \ a_0 ) (a_0 \ b \ c_0 ) \in G$ , i.e. (8) $( e_0 \ b \ c_0 ) \in G$ , which proves our thesis (5). Let now $a$ be an element distinct from $e_0$ in $\Delta $ . Since $|g(\Delta )| \geq 3$ , we can choose an element $b_0$ distinct from $a$ in $\Delta \setminus \{ e_{0} \}$ . Then by (2) et (4), $(a \ b_0 \ e_0) \ (c_0 \ b_0 \ a) \in G$ , i.e. (9) $(a \ c_0 \ e_0) \in G$ . which proves our thesis (6). From (4), (8) and (9), it results that for every distinct $a$ and $b$ in $\Delta $ , $(a \ b \ c_0 )$ is ìn $G$ . Since $\Delta $ is richly permutated by $G$ , it proves that every $3$ -cycle in $\Delta \cup \{ c_0 \}$ is in $G$ (more rigorously : the canonical image of every such cycle in $Sym(\Omega)$ is in $G$ ). Since every alternating group is generated by its $3$ -cycles, $\Delta \cup \{c_0 \}$ is thus richly permutated by $G$ , which contradicts the maximality of $\Delta $ . This contradiction shows that our hypothesis (1) is false, so $\Delta$ is the whole $\Omega$ , thus $\Omega$ is richly permutated by $G$ , which means that $G$ contains $Alt(\Omega)$ , which proves Jordan's proposition. By the way, a primitive group is by definition a transitive group with no non-trivial block. If I'm not wrong, the proof of Jordan's proposition doesn't depend on transitivity, only on the non-existence of non-trivial blocks. So, Jordan's proposition can be stated : ""Let $\Omega$ be a finite set and $G$ a subgroup of $Sym(\Omega )$ with no non-trivial block. If $G$ contains a $3$ -cycle, then $G$ contains $Alt(\Omega )$ (and is thus equal to $Alt(\Omega )$ or to $Sym(\Omega )$ )."" It is not really a strengthening of Jordan's proposition, in the sense that there is no case where the weak hypotheses are satisfied and the strong hypotheses are not, since the "" strengthening"" of Jordan's proposition shows that transitivity results from the weak hypotheses (since $Alt(\Omega)$ is transitive when $\Omega$ has at least $3$ elements).",['group-theory']
3779561,How can I evaluate $\int _0^1\frac{\text{Li}_2\left(-x\right)\ln \left(1-x\right)}{1+x}\:dx$,I am trying to evaluate $\displaystyle \int _0^1\frac{\text{Li}_2\left(-x\right)\ln \left(1-x\right)}{1+x}\:dx$ I first tried using the series expansion for the dilogarithm like this $$\sum _{n=1}^{\infty }\frac{\left(-1\right)^n}{n^2}\int _0^1\frac{x^n\ln \left(1-x\right)}{1+x}\:dx$$ Then I used integration by parts but this lead to nothing useful.,"['integration', 'harmonic-numbers', 'polylogarithm', 'definite-integrals']"
3779584,"Given a function $f(x)$ that is define by $f(x-1)$, by knowing $f(0)$ is it possible to rewrite $f(x)$ without using $f(x-1)$","Let a function $f(x)$ that is written using the function itself. Something like Fibonacci sequence $f(x)=f(x-2)+f(x-1)$ . Now given enough result of $f(x)$ (in the example of Fibonacci sequence, $f(1)$ and $f(2)$ ), is it possible to rewrite the function so that it doesn’t require calling itself again, but only uses the input $x$ and the pre-given results (again for Fibonacci sequence it can be written as $f(x)=\frac{\phi^x-(1-\phi)^x}{\sqrt 5}$ ? Is it possible to prove that any of these self-calling function could be rewritten?","['recursive-algorithms', 'functions', 'recursion']"
3779587,Counting integers $n$ such that $1\leq n \leq 200$ and $n$ is not divisible by $2$ nor $5$,"How many integers $n$ are there such that $1\leq n \leq 200$ and $n$ is not divisible by 2 nor 5? Here is just my trying. By the hypothesis I just let by contradiction. It means that I find the integers $n$ that is divisible by $2$ or $5$ . $n=2k_1$ and $n=5k_2$ for $k_1,k_2\in\mathbb{N}$ .So that I can write $$0\leq n\leq 200$$ $$0\leq 2k_1\leq200$$ $$0\leq k_1\leq 100$$ So there are $100$ integers of $k_1$ that satisfies that n is divisible by $2$ . By the same way I get $$0 \leq k_2 \leq 40$$ So there are $40$ integers of $k_1$ that satisfies that n is divisible by $5$ .
But I find the n that is divisible by $2$ and $5$ . Since $LCM(2,5)=10$ . Let $n=10k_3$ By the Same way I get $$0\leq k_3 \leq 20$$ So there are 20 integers of $k_3$ that satisfies $n$ is divisible by 2 and 5. Hence there are 120 integers of n that is divisible by $2$ nor $5$ .
By contradiction there are 80 integers of n that is being find. So please help to tell me ! That is right or wrong. If you have other hints help to tell me.","['number-theory', 'inclusion-exclusion', 'solution-verification', 'combinatorics']"
3779589,Metric Space Question: is $H(x)$ in this neighborhood?,"Let the metric $d$ be defined as $$
d(f,g) =\sup_{x\in[0,1]}|f(x)-g(x)|,
$$ and let $$
H(x) = \begin{cases} 0 \text{ if } x \leq \frac{1}{2}\\ 1 \text { if } x > \frac{1}{2} \end{cases}.
$$ Is $f(x) = x$ in $B_\frac{1}{2}(H)$ ? My answer . No, because $$
d(H(x),f(x)) = \sup_{x\in[0,1]}|f(x)-H(x)| = \frac{1}{2}.
$$ Therefore, $f(x) \not \in B_\frac{1}{2}(H)$ I am not sure if my answer is correct, and I found that it is hard to visualize this metric. Can someone helps me on this?","['general-topology', 'metric-spaces', 'real-analysis']"
3779596,Find the remainder when $(x - 1)^{100} + (x - 2)^{200}$ is divided by $x^2 - 3x + 2$ .,"Find the remainder when $(x - 1)^{100} + (x - 2)^{200}$ is divided by $x^2 - 3x + 2$ . What I tried : In some step I messed up with this problem and so I think I am getting my answer wrong, so please correct me. We have $x^2 - 3x + 2$ = $(x - 1)(x - 2)$ and I can see $(x - 1)^2 \equiv 1$ $($ mod $x - 2)$ . We also have :- $$\frac{(x - 1)^{100}}{(x - 1)(x - 2)} = \frac{(x - 1)^{99}}{(x - 2)}.$$ We have :- $(x - 1)^{98} \equiv 1$ $($ mod $x - 2).$ $\rightarrow (x - 1)^{99} \equiv (x - 1)$ $($ mod $x - 2)$ . Now for the case of $(x - 2)^{200}$ we have :- $$\frac{(x - 2)^{200}}{(x - 1)(x - 2)} = \frac{(x - 2)^{199}}{(x - 1)}.$$ We have :- $(x - 2) \equiv (-1)$ $($ mod $x - 1)$ $\rightarrow (x - 2)^{199} \equiv (-1)$ $($ mod $x - 1)$ . Adding all these up we have :- $(x - 1)^{100} + (x - 2)^{200} \equiv (x - 2)$ $($ mod $x² - 3x + 2)$ . On checking my answer with wolfram alpha , I found the remainder to be $1$ , so I messed up in some step .
Can anyone help me?","['modular-arithmetic', 'algebra-precalculus', 'polynomials', 'divisibility']"
3779667,"If $x\sin A+y\sin B+z\sin C=x^2\sin2A+y^2\sin2B+z^2\sin 2C=0$, show $x^3\sin3A+y^3\sin3B+z^3\sin 3C=0$","I'm having trouble with a question that came in one of my exam and is about complex numbers and trigonometry: If $$x \sin A +y \sin B+z\sin C=0$$ and $$x^2 \sin 2A + y^2 \sin 2B + z^2 \sin 2C=0$$ then prove that $$x^3 \sin 3A+y^3 \sin 3B +z^3 \sin 3C=0$$ where $x$ , $y$ , $z$ belong to $\mathbb{R}$ and $A+B+C=\pi$ . What I tried: I tried maybe doing it as imaginary part of $xe^{iA} + ye^{iB} +ze^{iC} =0$ and similarly, but I'm reaching a dead end in that approach","['trigonometry', 'systems-of-equations', 'complex-numbers']"
3779668,Book recommendations for Riemannian geometry,"I'm doing a PhD thesis about Riemannian geometry and i would like to improve my knowledge. I know all the basic defintions and concepts (I have the ""semiRiemannian geometry with applications to relativity"" from Barret O'neill and i have studied it during the degree and the master ). So i'm looking for books with the following to characteritics: First, a book which go forward with respect the content of O'neill's book. Secondly, it would be great that the author/s stop in the basic (or advanced) concepts to think about it and not just give the defintions and going on. Thanks for advance","['book-recommendation', 'reference-request', 'riemannian-geometry', 'differential-geometry']"
3779710,Solve $\sqrt[4]{x}+\sqrt[4]{x+1}=\sqrt[4]{2x+1}$,"Solve $\sqrt[4]{x}+\sqrt[4]{x+1}=\sqrt[4]{2x+1}$ My attempt: Square both sides three times $$\begin{align*}
36(x^2+x)&=4(\sqrt{x^2+x})(2x+1+\sqrt{x^2+x})\\
(\sqrt{x^2+x})(35\sqrt{x^2+x}-4(2x+1))&=0
\end{align*}$$ This means $0,-1$ are solutions but I can't make sure that these are the only solutions. Also I'm not sure that squaring three times is a good approach or not.","['algebra-precalculus', 'systems-of-equations', 'roots', 'radicals']"
3779741,Why does definition of the inverse of a matrix involves having $AB=I=BA$?,"So, I was reviewing the first course in Linear Algebra which I took and got curious about the reason behind defining the inverse of a matrix in the following way (from Wikipedia): In linear algebra, an $n$ -by- $n$ square matrix $A$ is called invertible (also nonsingular or nondegenerate) if there exists an $n$ -by- $n$ square matrix $B$ such that $$
AB=BA=I
$$ Now, I had an exercise to prove that if $AB=I$ , then $BA=I$ . Then, what is the reason to put both the equalities in the definition ? Is that somewhat traditional or is it because of some specific reason which I'm not aware of? I'd be happy if someone could help me out. Thanks in advance!","['matrices', 'definition', 'linear-algebra', 'inverse']"
3779748,Bound on difference of eigen projections of positive definite matrices,"Suppose I have two positive semidefinite matrices (and their eigendecompositions) $A = U \Lambda_A U'$ and $B = V \Lambda_B V'$ . I was wondering if $$
||U_jU_j' - V_jV_j' ||  \leq C || A - B ||
$$ for some $C$ . Here, $U_j$ is the $j$ th column of $U$ . Hence, I'm asking if the eigenprojections are Lipschitz continuous with respect to the original matrices. I've went through Kato's praised book on perturbation theory, which is great by the way, but the theory there is mostly about when the matrices depend on a single parameter. Any help would be greatly appreciated.","['eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'perturbation-theory', 'matrix-analysis']"
3779756,Convergence in metric spaces and measurability,"Let $(E,d)$ be a metric space, then $(x,y) \rightarrow d(x,y)$ is a continuous function from $E^2$ to $\mathbb{R},$ so $d$ is $(B(E^2),B(\mathbb{R}))$ -measurable. Is it true that $d$ is $(B(E)\otimes B(E),B(\mathbb{R}))$ -measurable ? We know that $B(E)\otimes B(E) \subset B(E^2),$ and if $E$ is separable then we have equality. So is there an example where a distance function is not $(B(E)\otimes B(E),B(\mathbb{R}))$ -measurable and the metric space is not separable ? Also we should mention, each time, that $(f,h)$ is $(B(E),B(E^2))$ -measurable? Because in the following lemmas, from Foundations of Modern Probability , they are taking measurable functions in a metric space, $f, h,$ for example, and taking $d(f,h)$ as a measurable function, without checking it is measurable or not. On the other hand, in Real Analysis and Probability , they mentioned that $E$ must be separable.","['measure-theory', 'metric-spaces', 'real-analysis', 'measurable-functions', 'probability-theory']"
3779760,When is the projection from a point on the variety smooth?,"Let $X\subset\mathbb{P}^n$ be a smooth irreducible variety (over $\mathbb{C}$ ) and $p\in\mathbb{P}^n$ a point. Let $\pi:\mathbb{P}^n\setminus\{p\}\to\mathbb{P}^{n-1}$ be the linear projection with center $p$ and denote by $Y$ the Zariski closure of $\pi(X\setminus\{p\})$ .
I would like to know: When is $Y$ smooth and the restriction $X\setminus\{p\}\to\pi(X\setminus\{p\})$ of $\pi$ an isomorphism? If $p\not\in X$ , then I think this is equivalent to $p$ not lying on the secant variety of $X$ . But I am mainly interested in the case when $p\in X$ . In this case we can rephrase the question as: When is $Y$ the blow-up of $X$ at $p$ ?","['algebraic-geometry', 'blowup', 'birational-geometry']"
3779780,Functions satisfying $f(x)f(y)=2f(x+yf(x))$ over the positive reals,"From the IMO shortlist: We denote by $\mathbb{R}^+$ the set of all positive real numbers. Find all functions $f: \mathbb R^+\rightarrow\mathbb R^+$ which have the property: $$f(x)f(y)=2f(x+yf(x))$$ for all positive real numbers $x$ and $y$ . $\textbf{My progress: }$ At first assume $f$ is not injective. Then there exist $z,y$ such that $f(z)=f(x)$ assume WLOG $z >x$ .Now,We can choose some appropriate $y$ such that $x+yf(x)=z$ . Then it follows that $f(y)=2$ which means $2$ has an inverse. Now, substituting inverse of $2$ in place of $y$ from which we could get a bunch of values for which the function assumes the same value. I then thought of somehow proving this would show the function is constant which I failed to do. The case with $f$ injective is pretty easy.interchaging $x,y$ we get, $f(x+yf(x))=f(y+xf(y))$ Using injectivity we could easily deduce from here that $f$ is linear and get a contradiction. But I cannot do the first case. I do believe that $f(x)=2$ is the only function that works. Any kind of hint or solution is appreciated.","['contest-math', 'functional-equations', 'algebra-precalculus', 'functions']"
3779814,Change of variable in Lebesgue integral,"In my book it is shown how to compute the following Lebesgue integral: $$\int e^{-x^2} =\sqrt{\pi}$$ I want to show that this result is equivalent to $$\int e^{-x^2/2} =\sqrt{2\pi}$$ Up to now we haven't proven any change of variable formula, but we have proven the following: Proposition. Let $f$ be a Borel measurable function which is Riemann integrable over every compact interval. Then $f$ is Lebesgue integrable over $\mathbb{R}$ if and only if $\lim_{n\to\infty}\int_{-n}^{n}|f(x)|dx $ exist in $\mathbb{R}$ . In this case $\int f =\lim_{n\to\infty}\int_{-n}^{n}f(x)dx $ . Using this with $f(x)=e^{-x^2}$ and applying the change of variable rule from calculus I get $$\sqrt{\pi}=\int e^{-x^2} =\lim_{n\to\infty}\int_{-n}^{n}e^{-x^2}dx = \frac{1}{\sqrt{2}} \lim_{n\to\infty}\int_{-\sqrt{2}n}^{\sqrt{2}n}e^{-x^2/2}dx = \frac{1}{\sqrt{2}}  \lim_{n\to\infty}\int_{-n}^{n}e^{-x^2/2}dx$$ which shows, by the previous proposition, that $\int e^{-x^2/2} $ exists and equals $\sqrt{2\pi}$ . The converse implication is similar. This reasoning made use of the fact that $e^{-x^2}$ is a non-negative function because in general the convergence of $\int_{-n}^{n}f(x)dx$ does not imply Lebesgue integrability. How shoud I proceed when $f$ can be both positive and negative? Can this approach still work? Here is an example: consider the Lebesgue integral $\int_{0}^{\infty} xe^{-x^2}=1/2$ . From symmetry it should be clear that the integral $\int_{-\infty}^{0} xe^{-x^2}$ exists and its value ought to be $-1/2$ . Indeed the proposition gives $$ \int_{0}^{\infty} xe^{-x^2}=\lim_{n\to \infty} \int_{0}^{n} xe^{-x^2} dx=-\lim_{n\to \infty} \int_{-n}^{0} xe^{-x^2}dx$$ which shows that $\lim_{n\to \infty} \int_{-n}^{0} xe^{-x^2}dx$ exists and equals $-1/2$ . But the existence of this limit of Riemann integrals does not imply the existence of the Lebesgue integral $\int_{-\infty}^{0} xe^{-x^2}$ . Existence must be confirmed separately by checking that $$\lim_{n\to \infty} \int_{-n}^{0} |x|e^{-x^2}dx=\lim_{n\to \infty} \int_{0}^{n} xe^{-x^2}dx=\int_{0}^{\infty} xe^{-x^2}=1/2$$ This example is trivial but for more complicated cases the problem is the same.","['integration', 'measure-theory', 'change-of-variable', 'lebesgue-integral']"
3779821,Prove $\sum_{k=1}^{\infty} \frac{{(-1)}^n}{k^2} \sum_{j=0}^{\infty} \frac{{(-1)}^j}{2k+j+1}=-\frac{\pi^2}{12}\ln{2}+\pi C-\frac{33}{16} \zeta(3)$,"Prove $$\sum_{k=1}^{\infty} \frac{{(-1)}^k}{k^2} \sum_{j=0}^{\infty} \frac{{(-1)}^j}{2k+j+1}=-\frac{\pi^2}{12}\ln{2}+\pi C-\frac{33}{16} \zeta(3)$$ where C is catalan's constant.
Wolfram Alpha confirms that the sums converge to approximately the right side.  Wolfram Alpha also evaluates the first sum in terms of Hurwitz lerch transcendent or digamma function but how do I then evaluate the outer sum with either of these functions. Original question is $$\int_0^1 \frac{\text{Li}_2(-x^2)}{1+x} \; \mathrm{d}x$$ and I've got it to the double sum here by writing Li as its series form and forming a geometric series with $\frac{1}{1+x}$ . Any tips or suggestions?  maybe other approach to the integral? Edit: Integration by parts may work better? $$\ln{(1+x)}\text{Li}_2(-x^2) \bigg \rvert_0^1 + 2\int_0^1 \frac{\ln{(1+x)}\ln{(1+x^2)}}{x} \; \mathrm{d}x$$ Wolfram says that second integral is $\pi C -\frac{33 \zeta(3)}{16}$ which is very good here but I don't know how to evaluate that integral. $$\int_0^1 \frac{2\ln{(1+x)}\ln{(1+x^2)}}{x} \; \mathrm{d}x=\int_0^1 \frac{\ln^2{(1+x)(1+x^2)}}{x} \; \mathrm{d}x-\int_0^1 \frac{\ln^2{(1+x)}}{x} \; \mathrm{d}x - \int_0^1 \frac{\ln^2{(1+x^2)}}{x} \; \mathrm{d}x$$ Last integral is 0 $$\int_0^1 \frac{2\ln{(1+x)}\ln{(1+x^2)}}{x} \; \mathrm{d}x=\int_0^1 \frac{\ln^2{(1+x)(1+x^2)}}{x} \; \mathrm{d}x-\int_0^1 \frac{\ln^2{(1+x)}}{x} \; \mathrm{d}x$$","['integration', 'calculus', 'sequences-and-series', 'real-analysis']"
3779823,Can a Markov chain converge faster than a geometric rate?,"In Theorem 4.9 of the book Markov Chains and Mixing Times by Levin & Peres, there is a convergence theorem for ergodic Markov chains which states that there exist constants $C > 0$ and $\alpha \in (0,1)$ such that $$\sup_{x \in \mathcal{X}}\|P^t(x) - \pi\|_\text{TV} \leq C \alpha^t$$ Here $\mathcal{X}$ is the state space of the Markov chain, $P$ is a time independent transition kernel, and $\pi$ is its stationary distribution. A Markov chain that has this convergence rate is called geometric uniform ergodic. Is this the fastest rate at which a Markov chain can converge? If true, is there a way to prove it? If false, are there examples of chains that converge at a rate faster than geometric? Edit: I realize that i.i.d. chains have ""already"" converged, so they're obviously faster than an ergodic MC. However, I'm looking for examples with a non-trivial transition kernel, ideally a class of Markov chains that converge faster than a geometric rate.","['markov-chains', 'probability-theory', 'asymptotics', 'mixing']"
3779826,How to Find Solutions to a Multivariate Polynomial System,"I have a system of polynomials, where the first one is a multivariate linear polynomial, but the rest are univariate quadratic polynomials. How would I solve such a system (finding one or all solutions, or showing there are no solutions)? For example, $$17x+16y-5z-67=0 \\ x^2+3x-5=0 \\ 4y^2-7y-4=0  \\ z^2-6z-3=0$$","['nonlinear-system', 'multivariable-calculus', 'systems-of-equations']"
3779831,Local formula of Laplacian on Kähler manifolds,"Let $M$ be a Kähler manifold with Kähler form $\omega=g_{j\bar{k}}\,dz^j\wedge d\bar{z}^k$ in local holomorphic coordinates. I want to show that the associated Laplacian $\Delta:=2(\bar{\partial}^*\bar{\partial}+\bar{\partial}\bar{\partial}^*)$ (one could take $d,\partial$ instead, but I think $\bar{\partial}$ is more convenient here) has the following expression acting on functions : $$\Delta f=-2g^{\bar{j}k}\frac{\partial^2f}{\partial z^j\partial\bar{z}^k}.$$ It is remarkable that this formula does not involve derivatives of the metric! Here is my attempt: Given functions $f,\phi$ compactly supported on a holomorphic chart, we compute the $L^2$ inner product $$\frac{1}{2}(\Delta f,\phi)=(\partial f,\partial\phi)=\int_{\mathbb{C}^n}\frac{\partial f}{\partial\bar{z}^j}\frac{\partial\bar{\phi}}{\partial z^k}g^{\bar{j}k}G,$$ where $G=\det(g_{j\bar{k}})$ (coefficient of the volume form). After integration by parts, this becomes $$-\int\frac{\partial^2f}{\partial z^j\partial\bar{z}^k}g^{\bar{j}k}\bar{\phi}G-\int\frac{\partial f}{\partial\bar{z}^j}\bar{\phi}\,\frac{\partial(g^{\bar{j}k}G)}{\partial z^k}.$$ Now I have to show that the latter term vanishes, but I can't see why. I guess I have to use the Kähler condition. However, it seems that expanding the determinant and inverse matrix leads to nowhere. How do I proceed? Or is there any other way to show this?","['kahler-manifolds', 'riemannian-geometry', 'complex-geometry', 'laplacian', 'differential-geometry']"
3779845,Prove that $H<G\Rightarrow |H|\le \left\lfloor \frac{|G|}{2}\right\rfloor$ without Lagrange's theorem.,"Suppose we do not have yet the notion of coset, and thence Lagrange's theorem either. So, if $G$ is a finite group and $H<G$ , we just know that $H$ is a nonempty, proper, closed subset of $G$ . (How) Can we prove, in this framework, that $|H|\le \left\lfloor \frac{|G|}{2} \right\rfloor$ ? Some facts we might be using are, e.g. (here $f$ denotes group's operation): $f(H\times H) = H$ $f(H\times (G\setminus H))= G\setminus H$ Based on this, I've tried to come up with some equation/inequality involving the cardinalities of the ""level sets"" $L_a^{H×H}:=\{(h,h')∈H×H\mid hh'=a\}$ for $a∈H$ , and $L_a^{H×H^c}:=\{(h,c)∈H×H^c\mid hc=a\}$ for $a∈H^c$ (where $H^c:=G\setminus H$ ), but unsuccessfully. Addendum . Some more stuff, just to see whether the idea may get to somewhere. We have: \begin{alignat}{1}
|H|^2 &= \sum_{a\in H}|L_a^{H\times H}| \\
&= |H|+\sum_{a\in H\setminus\{e\}}|L_a^{H\times H}| \\
\end{alignat} whence: \begin{alignat}{1}
|H|\cdot(|H|-1) &= \sum_{a\in H\setminus\{e\}}|L_a^{H\times H}| \\
\tag 1
\end{alignat} Moreover: \begin{alignat}{1}
|H||H^c| &= \sum_{a\in H^c}|L_a^{H\times H^c}| \\
\tag 2
\end{alignat} By $(1)$ and $(2)$ , we get both: \begin{alignat}{1}
|H|\cdot(|G|-1) &= \sum_{a\in H^c}|L_a^{H\times H^c}| + \sum_{a\in H\setminus\{e\}}|L_a^{H\times H}| \\
\tag 3
\end{alignat} and: \begin{alignat}{1}
|H|\cdot(|H^c|-|H|+1) &= \sum_{a\in H^c}|L_a^{H\times H^c}| - \sum_{a\in H\setminus\{e\}}|L_a^{H\times H}| \\
\tag 4
\end{alignat} If from $(3)$ and/or $(4)$ we could deduce that $|H|\mid |G|$ (or, equivalently, $|H|\mid |H^c|$ ), we'd get actually more than what I originally asked, namely a ""coset-free"" proof of Lagrange's theorem.","['group-theory', 'abstract-algebra', 'finite-groups']"
3779920,Check the validity of the characterization of reflexive closure $\mathcal S$,"Given a binary relation $\mathcal R$ over a set $A$ ,then the reflexive closure of $\mathcal R$ on $A$ denoted by $\mathcal S$ is the smallest reflexive relation on $A$ containing $\mathcal R$ . Equivalently it's the least reflexive relation on $A$ that is a superset of $\mathcal R$ . Reflexive closure is explicitly given by: $$\mathcal S=\text{id}_A \cup\mathcal R$$ Since $\mathcal S$ is reflexive,hence by definition of reflexivity $\text{id}_A \subseteq \mathcal S$ ,on the other hand since it contains $\mathcal R$ ,implies that: $$\text{id}_A \cup \mathcal R \subseteq \mathcal S$$ Therefore $\mathcal S $ can be written as: $$\mathcal S=\text{id}_A \cup \mathcal R\cup B$$ It's left to show that $B=\varnothing$ ,assume for the sake of contradiction $B \ne \varnothing$ ,then there is another reflexive closure $\mathcal S '$ with $B=\varnothing$ which is indeed $\mathcal S'=\text{id}_A \cup \mathcal R$ ,from here it's seen that $\mathcal S' \subset \mathcal S$ ,contradicts the fact that $\mathcal S$ is the smallest such reflexive relation on $A$ containing $ \mathcal R$ . $\blacksquare$ All I tried to show,was the validity of such characterization of the reflexive closure. However I'm not sure if my arguments are right,it would be highly appreciated if someone check them.","['elementary-set-theory', 'solution-verification', 'relations']"
3779929,A finite set of distinct positive numbers is special if each integer in the set divides the sum of all integers within the set.,"A finite set of distinct positive numbers is special if each integer in the set divides the sum of all integers within the set. Prove that every finite set of positive integers is a subset of some special set. What I Tried :- I tried to attack this problem by means of Contradiction. Suppose there dosen't exist a finite set of positive integers which is a subset of some special set . Let the set contain elements $(a_1,a_2,...,a_k)$ . Then there dosen't exist a bigger set with all the same elements than this set which is special. From here I couldn't go solving it  . Edit :- As small examples we have $(1,2,3)$ a special set ; hence $(1,2),(2,3),(1,3)$ are subsets of this set . For $(1,4)$ we have $(1,2,4,7,14)$ , although $6$ and $28$ are perfect numbers. If we have a set which is not a subset of the factors of a perfect number , say $(1,5)$ ; we still have a special set $(1,4,5,10)$ where $(1,5)$ lies at it's subset . I am not getting any clues or ways to get these special sets. Now can anyone help ?","['elementary-set-theory', 'elementary-number-theory', 'combinatorics']"
3779948,Harmonic functions without critical points (global isothermal coordinates),"Let $(M,g)$ be a compact, orientable Riemannian surface with non-empty boundary $\partial M$ . Question. Does there always exist a smooth function $f:M\rightarrow \mathbb{R}$ with $\Delta_gf=0$ in the interior of $M$ and $d_pf\neq 0$ for all $p\in M$ ? For $M\subset \mathbb{R}^2$ , equipped with the Euclidean metric, this is clear (just take an affine linear map). Given a finite subset $P\subset M$ , one can always find a smooth function $f:M\rightarrow \mathbb{R}$ such that, for all $p\in P$ we have $\Delta f = 0$ near $p$ and $d_pf\neq 0$ . (This follows from a well known trick used to construct isothermal coordinates, see below.) If $M$ is contractible, this is equivalent to the existence of global isothermal coordinates on $(M,g)$ . Proof of 2) Extend $M$ to a closed surface $(N,g)$ and write $R:H_\perp^3(N)\rightarrow \mathbb{R}^{\vert P \vert}$ for the map that sends $f$ to the list $(\vert d_p f\vert: p\in P)\in \mathbb{R}^{\vert P \vert}$ . Here $H^s_\perp(N)$ consists of Sobolev-functions of regularity $s$ with zero mean (i.e. $\perp\{\mathrm{constants}\}$ ). Further write $F:H_\perp^1(N)\rightarrow H_\perp^3(N)$ for the map that sends $h$ to the solution $f$ of $\Delta f = h$ . Now the point is that the set $D_P=\{h\in H_\perp^1(N)\cap C^\infty(N):h \text{ vanishes near } P\}$ is dense in $H_\perp^1(N)$ , which implies that $RF(D_P)\subset \mathbb{R}^{\vert P\vert}$ is dense (as both $R$ and $F$ are continuous and surjective). In particular there is a vector in $RF(D_P)\subset\mathbb{R}^{\vert P\vert}$ with all coordinates non-zero and an $R$ -preimage $f\in F(D_P)$ satisfies the desired requirements.","['partial-differential-equations', 'differential-geometry', 'riemannian-geometry', 'real-analysis']"
3779993,"Volume Bound by $z+x^2=1; z+y^2=1, x=0;y=0;z=0$","I am trying to produce a triple integral that finds the volume underneath the surraces $x^2+z=1$ , $y^2+z=1$ , and is bound by the coordinate planes. On the graph, this looks like two parabaloids orthogonal to each other intersecting along the line $x=y$ . The bounds I choose are $0<z<1-y^2$ , $0<y<x$ , $0<x<1$ . I then solve this integral and multiply it by two (because of symmetry) and get $5/6$ but apparently the answer is $1/2$ according to the book I'm using. I assume I have my bounds incorrect, could someone explain to me why this is?","['integration', 'multivariable-calculus', 'multiple-integral', 'volume']"
3779996,Hypothesis Testing show LRT is Chi-Square test,"Let $(X_1,...,X_n)$ be a random sample with PDF $f(x;\theta) = \frac{x}{\theta}\exp(-x^2/(2\theta)), \theta > 0$ I want to show that the likelihood ratio test of $H_0 : \theta \le \theta_0$ against $H_1 : \theta > \theta_0$ where $\theta_0>0$ is given is a Chi-square test This gives that the the likelihood function $\displaystyle L(\theta) = \frac{\prod x_i}{\theta^n}\exp(-\sum x_i^2/2\theta)$ I am going to set $t = \prod X_i$ and $s = \sum X_i^2$ . So we get $\displaystyle L(\theta) = \frac{t}{\theta^n}\exp(-s/2\theta)$ . And $\max_{\theta \ge 0 }L(\theta)$ occurs when $\theta = \frac{s}{2n}$ And $\max_{0 \le \theta \le \theta_0} L(\theta) = \begin{cases}
   L(\frac{s}{2n})&\text{if }\theta_0 \ge \frac{s}{2n}\\
                L(\theta_0)&\text{else}
        \end{cases}$ Now we have $$
\Lambda_{H_0} = \frac{\max_{0 \le \theta \le \theta_0} L(\theta)}{\max_{0 \le \theta } L(\theta)} = \begin{cases} 1 &\text{if } \theta_0 \ge \frac{s}{2n}\\ \bigg (\frac{s}{2n\theta_0}\bigg)^n\exp(n - s/(2\theta_0))&\text{else}
\end{cases}
$$ Hopefully I have calculated both of those correct, now is where I run into my issue I don't quite see how this is a Chi-square test.","['statistical-inference', 'statistics', 'probability-distributions', 'maximum-likelihood', 'hypothesis-testing']"
3780024,How to prove that $S=\sum_{n=0}^{\infty}\frac{(\sqrt{2}-1)^{2n+1}}{(2n+1)^2}=\frac{\pi^2}{16}-\frac{1}{4}\log^2(\sqrt{2}-1)?$,"How to prove that $$S=\displaystyle\sum_{n=0}^{\infty}\frac{(\sqrt{2}-1)^{2n+1}}{(2n+1)^2}=\frac{\pi^2}{16}-\frac{1}{4}\log^2(\sqrt{2}-1)$$ My attempt: We have for $|x|\leq1$ $$\tanh^{-1}(x)=\displaystyle\sum_{n=0}^{\infty}\frac{x^{2n+1}}{2n+1}$$ and : \begin{align*}
\displaystyle\int_0^{\sqrt{2}-1}\frac{\tanh^{-1}(x)}{x}\ \mathrm{d}x&=\displaystyle\int_0^{\sqrt{2}-1}\frac{1}{x}\displaystyle\sum_{n=0}^{\infty}\frac{x^{2n+1}}{2n+1}\mathrm{d}x\\
&=\displaystyle\sum_{n=0}^{\infty}\frac{1}{2n+1}\displaystyle\int_0^{\sqrt{2}-1}x^{2n}\mathrm{d}x\\
&=\displaystyle\sum_{n=0}^{\infty}\frac{(\sqrt{2}-1)^{2n+1}}{(2n+1)^2}\\
&=S\\
\end{align*} So : \begin{align*}
S&=\displaystyle\sum_{n=0}^{\infty}\frac{(\sqrt{2}-1)^{2n+1}}{(2n+1)^2}\\
&=\displaystyle\int_0^{\sqrt{2}-1}\frac{\tanh^{-1}(x)}{x}\mathrm{d}x\\
&=\displaystyle\int_0^{\sqrt{2}-1}\frac{1}{2x}\left(\log(1+x)-\log(1-x)\right)\mathrm{d}x\\
&=\frac{1}{2}(J_1-J_2)
\end{align*} Where: \begin{align*}
J_1&=\displaystyle\int_0^{\sqrt{2}-1}\frac{\log(1+x)}{x}\mathrm{d}x\\
&=\displaystyle\sum_{n=0}^{\infty}\frac{(-1)^n}{n+1}\displaystyle\int_0^{\sqrt{2}-1}x^n\mathrm{d}x\\
&=\displaystyle\sum_{n=0}^{\infty}\frac{(-1)^n(\sqrt{2}-1)^{n+1}}{(n+1)^2}\\
\end{align*} And: \begin{align*}
J_2&=\displaystyle\int_0^{\sqrt{2}-1}\frac{\log(1-x)}{x}\mathrm{d}x\\
&=\displaystyle\int_0^{\sqrt{2}-1}-\displaystyle\sum_{n=0}^{\infty}\frac{x^n}{n+1}dx\\
&=-\displaystyle\sum_{n=0}^{\infty}\frac{1}{n+1}\left[\frac{x^{n+1}}{n+1}\right]_0^{\sqrt{2}-1}\\
&=-\displaystyle\sum_{n=0}^{\infty}\frac{(\sqrt{2}-1)^{n+1}}{(n+1)^2}\\
\end{align*} Finally we find : $$S=\frac{1}{2}\left(\displaystyle\sum_{n=0}^{\infty}\frac{(\sqrt{2}-1)^{n+1}((-1)^n+1)}{(n+1)^2}\right)$$ But I could not find a way to calculate $S$ .
Any help please? and thank's in advance.","['integration', 'calculus', 'sequences-and-series', 'real-analysis']"
3780089,Extending the concept of distribution function to any totally or partially ordered measurable space,"Let $(\Omega,\mathcal A, P)$ be a probability space. Let $(Y,\Sigma)$ be a measurable space. Let $X:(\Omega,\mathcal A) \to (Y, \Sigma)$ be a random variable. Then $X$ has probability measure $\mu_X = P \circ X^{-1}$ , also called the distribution of $X$ , in the probability space, also called the distribution space , $(Y, \Sigma, \mu_X)$ . In Wikipedia and other Google search, the concept of a distribution function $F_X: Y \to [0,1]$ in measure theory and probability theory seems to be limited to the case where $Y = \Re$ , where $$F_X(t) = P(\{\omega \in \Omega : X(\omega) \leq t\})$$ For example this Wikipedia definition of distribution function is limited to $Y= \Re$ : Let $ \mu $ be a measure on the real numbers, equipped with the Borel $\sigma$ -algebra. Then the function $$ F_\mu \colon \Re \to \Re \cup \{ +\infty, - \infty \} $$ defined by $$ F_\mu(t)= \begin{cases} \mu((0,t]) & \text{if } t\geq 0 \\ -\mu((t,0]) & \text{if } t < 0\end{cases}$$ is called the (right continuous) distribution function
of the measure $ \mu $ . Similarly, in these lecture notes on measure theory , the concept of a distribution function $F: Y \to [0,1]$ is limited to domain $\Re$ : Definition 4. A map $F:\Re\to[0,1]$ is said to be a distribution function if it is increasing, right continuous and $F(-\infty) = 0 = 1-F(\infty)$ . even though the concept of a distribution $\mu: \Sigma \to [0,1]$ is stated more generally: Definition 7. Let $Y$ be a metric space. A $Y$ -valued random variable on a probability space $(X,\Sigma,p)$ induces a Borel probability measure on $Y$ as follows: $$p_x(S) = p(x^{-1}(S))$$ for every $S \in B(Y)$ .  This is the distribution of $x$ .  If $Y =\Re$ , then we call this the distribution function of $x$ . Q. Can the restriction of $Y$ to $\Re$ be lifted in case $Y$ has a total or partial order?  This is exactly the point I am trying to generalize.  In place of ""If $Y=\Re$ "" I want to say ""If $Y$ is totally ordered"" or ""If $Y$ is partially ordered"" or something of this nature which indicates that $Y$ has enough order to define a distribution function as opposed to a distribution . This is the essence of the question, no more no less. The above definition seems to work fine for any totally ordered $Y$ .  Actually, since only $\leq$ is involved, it seems that we really only need $Y$ to be partially ordered .","['order-theory', 'measure-theory', 'probability-distributions', 'probability-theory']"
3780090,Why does $V(I(S))=\overline{S}$?,"Let $S\subset\operatorname{Spec}A$ , where $A$ is a commutative ring with $1$ . I am having trouble seeing why $V(I(S))=\overline{S}$ , where $\overline{S}$ is the Zariski closure of $S$ . My attempt is as follows. It is not hard to see that $S\subset V(I(S))$ : $V(I(S))$ is the set of all prime ideals of $A$ containing $I(S)$ , and $I(S)$ is the intersection of all elements (prime ideals) of $S$ . Since every element of $S$ contains $I(S)$ , it follows that $S\subset V(I(S))$ . This implies that $\overline{S}\subset V(I(S))$ . The issue I'm having is proving the reverse inclusion. Suppose $V(J)$ is any closed set containing $S$ . Then $I(V(J))\subset I(S)$ since $I(\cdot)$ is inclusion reversing. I'm not sure where to go from here or even if this is the correct line of thought to have. What am I missing?","['algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
3780124,Coefficients of a polynomial function from $\Bbb{N}$ to $\Bbb{N}$,"Let $f$ be a polynomial from $\Bbb{N}$ to $\Bbb{N}$ . So let $f(x) = a_0+a_1x+a_2x^2+..a_rx^r$ Then for every natural number $k$ , $f(k) \in \Bbb{N}$ . But how does it imply that all the coefficients of $f(x)$ i.e. $a_0, a_1,..a_r$ will belong to $\Bbb{Q}$ ?",['elementary-set-theory']
3780126,"Scheme theoretically, when the union of the interserction is the intersection of the union","We have the definition: Definition. Let $X$ be a scheme. Let $Z,Y⊂X$ be closed subschemes corresponding to quasi-coherent ideal sheaves $\mathcal{I},\mathcal{J}⊂\mathcal{O}_X$ . The scheme theoretic intersection of $Z$ and $Y$ is the closed subscheme of $X$ cut out by $\mathcal{I}+\mathcal{J}$ . The scheme theoretic union of Z and Y is the closed subscheme of $X$ cut out by $\mathcal{I}∩\mathcal{J}$ . Is true, in general, that given closed subschemes $Y,Z$ and $W$ of $X$ we have $$Y\cap (Z\cup W)= (Y\cap Z)\cup (Y\cap W), \mbox{scheme-theoretically?}$$ If not, there is any necessary and sufficient conditions?
Any hint, reference or solution is welcome!! Remark: Using the language of ideal, if we denote $I_*$ the ideal of the variety $*$ we have just one inclusion, in general $$I_Y+(I_Z\cap I_W)\subseteq (I_Y+I_Z)\cap(I_Y+I_W).$$","['quasicoherent-sheaves', 'algebraic-geometry', 'abstract-algebra', 'sheaf-theory', 'schemes']"
3780174,Finding generators for vanishing ideal $I(S)$,"Let $A=k[x,y]$ where $k$ is a field. Let $S=\{(y),(x,y-1)\}$ be a subset of $\operatorname{Spec}A$ . Then $I(S)$ consists of those polynomials in both $(y)$ and $(x,y-1)$ . How could one find generators for the ideal $I(S)$ ? I know that if $f\in S$ , then we have that $f=gy$ for some $g\in A$ . Further, we have $f=hx+j(y-1)$ for some $h,j\in A$ . From this it follows that $(g-j)y-hx-j=0$ . But I'm not sure how this helps us find the generators. What am I missing?","['algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
3780194,Smooth quadrics as quotient of $SO(2n+1)$,"I've just started studying parabolic subgroup, and I read I can obtain smooth quadrics of the form $$x_0x_{n+1}+\ldots+x_{n-1}x_{2n}+x_n^2=0$$ in $\mathbb{P}^{2n}$ as quotients of $SO(2n+1)$ by a appropriate parabolic subgroup, that is a subgroup containing a Borel subgroup. I know $SO(2n+1)=\{A\in M_{2n+1}(\mathbb{C})\mid A^t Q A=Q \text{ and } \det(A)=1\}$ , where $$Q=\begin{pmatrix} 0_{n,n} & 0 & I_n \\ 0 & 1 & 0 \\ I_n & 0 & 0_{n,n}
\end{pmatrix},$$ but to be honest I cannot go much further, I always struggle to translate the theory regarding algebraic groups in a concrete example. Since this is very new to me I'd like to understand why this statement is true and how to find such a subgroup: also a proper reference may be fine.","['algebraic-geometry', 'algebraic-groups', 'abstract-algebra', 'lie-groups']"
3780205,Is the summation $\sum_{i=1}^{n}\frac1{i} \binom{n}{i}$ possible?,"I want to compute the following sum: $$
\sum\limits_{i=1}^{n} \frac{{n\choose{i}}}{i}
$$ What I have done so far: We know that $$(1+x)^n=\sum\limits_{r=0}^{n} {n\choose{r}}x^r$$ so, $$\frac{(1+x)^n-1}{x}=\sum\limits_{i=1}^{n} {{n\choose{i}}}x^{i-1}$$ therefore, upon integration we get, $$\int\limits_{0}^{1}\frac{(1+x)^n-1}{x}dx=\sum\limits_{i=1}^{n} \frac{{{n\choose{i}}}}{i}$$ I cannot get any further with the LHS of the above equation. Primary questions to be addressed: Is such an integration possible (why so)? Are there any other approximations for the sum?","['integration', 'summation', 'definite-integrals', 'binomial-coefficients', 'combinatorics']"
3780236,Evaluate $\int_{-\infty}^{\infty} \frac{\sin{\left(t\pi x^2\right)}}{\sinh^2{\left(\pi x\right)}} \; \mathrm{d}x$,"Evaluate $$\int_{-\infty}^{\infty} \frac{\sin{\left(t\pi x^2\right)}}{\sinh^2{\left(\pi x\right)}} \; \mathrm{d}x$$ I converted $\sinh{(x)}$ to exponential form and considered Imaginary part of the numerator: $$4\Im{\left(\int_{-\infty}^{\infty} \frac{e^{2 \pi x}e^{t\pi x^2}}{{\left(e^{2 \pi x} -1\right)}^2} \; \mathrm{d}x\right)}$$ I think a semi circle contour in upper quadrants would work.  Residues are at $x=k \cdot i, k \in \mathbb{N}$ including $0i$ .  Where I calculated the residues to be $$-\frac{2t}{\pi} \sum_{n=0}^{\infty} ne^{-n^2 \pi i t}$$ I dont know what to do from here (closed form) or maybe my work is wrong?  Ideas or tips please.","['integration', 'complex-analysis', 'definite-integrals']"
3780247,Is this definition of boundedness correct?,"Hi I'm trying to learn precalc and one thing I'm stumped on is the concept of boundedness. From what I understand boundedness is whether or not a function has an absolute maximum and minimum. If it has only max then it is bounded above, otherwise if it has only a minimum it is bounded below. If it is both then its bounded, if it has neither it is not bounded. Is this definition correct? I'm trying to use this logic to check if $y=\sqrt{13-x^2}$ is bounded in any way or not.","['algebra-precalculus', 'bounded-variation']"
