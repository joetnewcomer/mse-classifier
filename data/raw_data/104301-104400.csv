question_id,title,body,tags
1466036,Partition into block matrix,"If $$A=\begin{bmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{bmatrix}$$ is a partition of $A$ such that $A_{11}$ and $A_{22}$ are $r \times r$ and $(n − r) \times (n − r)$ matrices, respectively, then $$\det(A) \leq \det(A_{11}) \cdot \det(A_{22})$$ with equality holding if and only if $A$ is block diagonal, Hint: Use $\det(A+B)^{\frac{1}{n}} \geq \det(A)^{\frac{1}{n}} + \det(B)^{\frac{1}{n}}$ with $$B=\begin{bmatrix} A_{11} & -A_{12} \\ -A_{21} & A_{22} \\
\end{bmatrix}$$ Why is $B$ positive definite?","['positive-definite', 'linear-algebra', 'block-matrices', 'matrices']"
1466065,"Determine the image of the set $G = \{ z \mid |z|<1,\; Im(z)>0\}$ under $f(z) = \frac{z+\frac{1}{z}}{2}$","I wish to describe the image of $G = \{ z \mid |z|<1,\; Im(z)>0\}$ under $f(z) = \frac{z+\frac{1}{z}}{2}$. $G$ is the open upper unit=semicircular region. $f(z) = \frac{z^2 + 1}{2z}$. I thought this was a mobius transformation, but apparently not. Does anyone have ideas on how to proceed? My attempt: $z \to z^2$ forms a parabolic region
$z \to z^2 + 1$ translates the parabola up by $1$
$z^2 +1 \to \frac{z^2 +1}{2z}$ translates the parabola by $\frac{1}{2z}$ downward.
Is this correct?","['complex-analysis', 'complex-numbers']"
1466077,An Inequality for sides and diagonal of convex quadrilateral from AMM,"Let $\square ABCD$ be a convex quadrilateral. If the diagonals $AC$ and $BD$ have mid-points $E$ and $F$ respectively, show that: $$\overline{AB} + \overline{BC} +\overline{CD} + \overline{DA} \ge \overline{AC}+\overline{BD}+2\overline{EF}$$ where, $\overline{XY}$ denotes the length of the line segment $XY$. The problem was 11841 from May 2015 issue of AMM magazine. While writing complex numbers/vectors for vertices reduces the problem to the well known Hlawka's Inequality for Inner-product spaces, I am interested in purely geometrical solutions. (It's way past the last date of submission, so I believe it's safe to ask for alternative solutions here.) Edit: We have the following reformulation, (not that it makes the job any easier though!) If $H,I,J$ and $K$ are the midpoints of $AD,DC,CB$ and $BA$ respectively, then $\square HIJK$ is a parallelogram and it's easy to see that the diagonals $\overline{HJ}$ and $\overline{IK}$ intersect at $G$, which is the midpoint of $\overline{EF}$ as well. Then we have the equivalent reformulation of the question: In a parallelogram $\square HIJK$, whith diagonals intersecting at $G$ and $F$ be an interior point, we need to show: $$\overline{FH}+\overline{FI}+\overline{FJ}+\overline{FK} > \overline{IJ}+\overline{KJ}+2\overline{FG}$$","['contest-math', 'geometry']"
1466084,Give an open cover with no finite subcover.,"I am looking for an example of an open cover of $\mathbb Q \cap [0,1]$ (with the metric induced from the usual metric on $\mathbb R$) that has no finite subcover. I'm at a loss because of the intersection with $\mathbb Q$.  I originally thought of $(-\frac 1n, 1+ \frac 1n$) for $n \in \mathbb N$ but then I think this has a finite subcover, so I'm not sure where to go from here.","['analysis', 'metric-spaces', 'general-topology']"
1466102,Dense Subspace: Separability,"Given a topological space $\Omega$. Consider a dense subset:
$$S\subseteq\Omega:\quad\overline{S}=\Omega$$ Then does it hold true:
$$\Omega\text{ separable}\iff S\text{ separable}$$ Clearly it holds:
$$\exists A_0\subseteq S\subseteq\Omega:\quad\overline{A_0}=\overline{S}=\Omega\quad(\#A_0\leq\#\mathbb{N})$$
But what about the converse?","['separable-spaces', 'general-topology']"
1466109,Practical matter to proving a function is measurable: trouble with definitions...,"Suppose that I have the simple function $f:\mathbb{R}\to \mathbb{R}$ defined by $f(x)=x$. To show that $f$ is $(\mathcal{B}_{\mathbb{R}},\mathcal{B}_{\mathbb{R}})$-measurable (where $\mathcal{B}_{\mathbb{R}}$ is the Borel $\sigma$-algebra) I must show that $f^{-1}(E) \in \mathcal{B}_{\mathbb{R}}$ for every $E \subset \mathcal{B}_{\mathbb{R}}$. I would theoretically have to go through each set $E \in \mathcal{B}_{\mathbb{R}}$ and determine that $f^{-1}(E) \in \mathcal{B}_{\mathbb{R}}$ (I realize I would not actually have to do this, but stay with me...) Lets say I started with the set $(0,1)$. I know this is a silly question, but how is it possible to show $f^{-1}((0,1)) \in \mathcal{B}_{\mathbb{R}}$ since $f$ is a function and not a correspondence? Even if I went through each singleton $x \in (0,1)$ and showed that $f^{-1}(\{x\}) \in \mathcal{B}_{\mathbb{R}}$, uncountable unions are not necessarily in $\mathcal{B}_{\mathbb{R}}$ so I could not say for sure that $(0,1)$ is in $\mathcal{B}_{\mathbb{R}}$. Clearly I am having some conceptual difficulties with the idea of measurability. Any help would be appreciated.","['elementary-set-theory', 'measure-theory']"
1466159,"Given a surface $z=f(x,y)$ is $\nabla (f(a,b))$ always perpendicular to the surface at the point $(a,b,f(a,b))$","Given a surface $z=f(x,y)$ is $\nabla (f(a,b))$ always perpendicular to the surface at the point $(a,b,f(a,b))$. I see many problems using this gradient function to find a normal vector to a surface so it is most likely true I guess but I can't seem to come up with an intuitive reason or better still a proof to show me why this is the case. Any help?",['multivariable-calculus']
1466169,Tangent vectors as derivatives,"I am reading ""An introduction to manifolds"" by Loring Tu and I struggle understanding a concept.
In the book the directional derivative is given a tangent vector $v$ at a point $p$ the map :
$$D_v : \mathcal{C}_p^\infty \rightarrow \mathbb{R}$$
The follows by explaining that a map satisfying the leibniz rule is a ""Derivation at p"". The we can define the map :
$$\phi : T_p(\mathbb{R}^n) \rightarrow \mathcal{D}_p(\mathbb{R}^n)\\
v \rightarrow D_v = \sum v^i \frac{d}{dx^i} |_0$$ where : the ""d"" are partials evaluated at $0$. So far so good, then the book proceed to the proof that this map is an isomorphisme of vector spaces. And by this decide to write every tangent vectors $v = (v_1,...,v_n) = \sum v^i e_i$ as $v = \sum v^i \frac{d}{dx^i}|_p$ I have trouble understanding how a vector could be equal to a function. For me the RHS takes a function and the LHS is just a vector. I would like to know how is that intuitively correct and also what is the proof of the last equation.","['smooth-manifolds', 'partial-derivative', 'manifolds', 'calculus']"
1466185,How to prove the set G is a group with operation *,"Let G be a set with the operation $*$. Then, suppose the associativity holds with respect operation $*$.
Assume that as for any $b\in G$,the map $\phi_{b}:G\to G$ defined by $\phi_{b}(g)=g*b$ is surjective and that there is an  $a\in G$ so that $\sigma_{a}:G\to G$ is surjective,where $\sigma_{a}(g)=a*g$. Prove that G is a group with the operation $*$. I am stuck in this problem, firstly, we need to find the identity. However, I cannot figure out how to find the identity, if we can find the identity, then give any element a in G, we can use the surjectivity to know there is an inverse element $a^{-1}$ such that $a^{-1}*a$=e. Then, we can  prove the G is a group. However, I still have no idea how to find the identity of the set. Can someone give me some help?","['abstract-algebra', 'group-theory', 'finite-groups']"
1466204,The angle between two rays in 3D space,"This is a problem from Mathematics GRE Subject Test - #42. In the xyz-space, what is the degree measure of the angle between the rays $z= (x>=0), y=0$ and $z=  (y>=0), x=0$ ? a)0; b)30; c)45; d)60; e)90 My Attempt at a Solution Because the first set of rays are always along the line y=0, they must be spread out on solely the x-z plane, in the direction of the positive x-axis. Similarly, the second set of rays would be on the y-z plane, and in the direction of the positive y axis. So I figured that because the rays are on perpendicular planes, they should have an angle of 90 degrees. Sorry if this is drastically wrong, I'm at a loss where to proceed. I'm not totally even sure what topic to tag this under. Any help is much appreciated. Thanks","['3d', 'geometry', 'analytic-geometry']"
1466251,Counting combinations ( help),"can you help me with this problem: This problem concerns lists made from the letters A,B,C,D,E,F,G,H,I,J. (a) How many length-5 lists can be made from these letters if repetition is not
allowed and the list must begin with a vowel? (b) How many length-5 lists can be made from these letters if repetition is not
allowed and the list must begin and end with a vowel? (c) How many length-5 lists can be made from these letters if repetition is not
allowed and the list must contain exactly one A? for a) I said :
3*9*8*7*6 for b) 
I did
3*8*7*6*2 for c) I did
5*(9*8*7*6*1) I am not sure of a or b Help is appreciated!","['combinations', 'combinatorics']"
1466273,Is it possible to construct a field larger than the complex numbers?,Can we extend the complex numbers in any way such that $\mathbb{C} \subset\mathbb{C}[a]$ ? Or is $\mathbb{C}$ the extension to end all extensions?,"['extension-field', 'abstract-algebra']"
1466306,Probability a couple sits at the same table.,"There is a chess tournament for married couples.   There are a total of $2n$ participants in this tournament; implying there are $n$ married couples.   All of the participants meet in a ballroom which has $n$ tables in it with $2$ chairs per table.   This implies there are $2n$ chairs.   The host/hostess of the chess tournament enters the names of every participant into a computer and the computer uniformly and randomly pairs the participants up.   We define a random variable $X$ and let this equal the number of participants paired up with their original partners.   Find $E[X]$. Okay, that's the question.   Now, let me type up my current thought process.   I want to define $X$ as a sum of Bernoulli random variables i.e. $X = X_1+X_2+ \cdots + X_n$. $X_i$ ranges from $1 \to n$ because there are $n$ partners. Each $X_i$ is distributed as: $X_i = \begin{cases} 1 & \text{if partners ""i' are sitting together} \\ 0 & \text{if partners ""i"" are not sitting together} \end{cases}$ Then, I can just use the linearity of expectation to calculate $E[X]$: $E[X] = E[X_1] + E[X_2] + \cdots + E[X_n]$ However, I'm having a hard time deriving the expectation of each $X_i$. I know $E[X_1] = E[X_2] = \cdots = E[X_n]$ and in a simpler Bernoulli problem the expectation is just $p = \text{probability of success} = \frac{1}{n}$ when there are $n$ choices but I am having a hard time translating that to this example. In this problem, there are $2n$ choices for seats. So, does this imply:
$P(X_i = 1) = \text{probability partners are sitting together} = \frac{1}{2n-1}$? I say $\frac{1}{2n-1}$ because, if I am standing in one of the participant's shoes, there are $2n-1$ people other than myself and only one of them is my partner. Or, would it be $\frac{2}{2n-1}$ because there are two ways for the couple to be paired up together i.e. let $A$ and $B$ represent the two members of a couple. Either $A$  can be paired with $B$ or $B$ can be paired with $A$.","['probability-theory', 'expectation', 'probability', 'combinatorics']"
1466343,What does 'vanishing' mean in the context of Linear Algebra?,"https://en.wikipedia.org/wiki/Wronskian The line under 'Wronskian and linear independence' is what I'm talking about. When you take the determinant of a matrix with linearly dependent vectors, doesn't it make the determinant $0$? Is going to $0$ what they are talking about?","['terminology', 'linear-algebra', 'ordinary-differential-equations']"
1466395,"Given a finite non abelian group G, prove the order of the center is less than or equal to 1/4 of the order of the group.",I am a bit confused on where to start with this one. The question given was Let $G$ be a non abelian finite group. Prove $|Z(G)| \leq \frac {1}{4} |G|$. Am I supposed to use some property of centers or am I just blanking on something really basic,"['abelian-groups', 'group-theory', 'finite-groups', 'group-actions']"
1466398,"Converting a series to a Riemann sum,","I am manipulating a series and have gotten this far: $$ \lim_{n\to\infty} \sum_{m=1}^n \frac {(\frac{m}{n})^{p-1}}{1+ (\frac{m}{n})^p} \frac{1}{n}$$ I want to now say that this is a Riemann sum, which corresponds to the Riemann integral $$ \int_0^1 \frac {x^{p-1}}{1+x^p}dx$$ which evaluates to ln(2)/p -- the answer I am looking for. Have I converted to the integral correctly? My concerns are:  I just relabeled the discrete variable ($m/n$) as a continuous variable $x$.  Also I converted the $1/n$ interval length to $dx$ -- this part I am ok with, just from checking the definition of Riemann integral and knowing that I have to let mesh($p$) = supremum of sub-interval lengths go to zero. So, I sort of did it blindly but I would like to know what are the rules that I may have missed?  E.g., does the variable ($m/n$) also have some size limits to adhere to?  Does ($m/n$) have to be small? Thanks, EDIT: The main concern really is:  in past problems, I converted to Riemann integrals that did not correspond to the Riemann sums that I was working with.  An MSE contributor gave me the heads up -- and showed that my corresponding ""Riemann integrals"" actually had values different from the sums.  But I used the same ""rules"" as I did with this current problem statement.  Apparently, it was incorrect.  So, I just want to know whether I have converted this sum to an integral  correctly.","['calculus', 'limits', 'real-analysis', 'riemann-sum', 'sequences-and-series']"
1466402,"Getting two answers to: How many monoalphabetic substitution ciphers of $\{A,B,C,D\}$ are possible in which no letter is fixed?","From Combinatorics by Mazur: I am trying this with $\{A,B,C,D\}$ but I am getting two answers. If I enumerate then I get $9$. $ABCD,\ ABDC,\ ACBD,\ ACDB,\ ADBC,\ ADCB$ $BACD,\ BADC(1),\ BCAD,\ BCDA(2),\ BDAC(3),\ BDCA$ $CABD,\ CADB(4),\ CBAD,\ CBDA,\ CDAB(5),\ CDBA(6)$ $DABC(7),\ DACB,\ DBAC,\ DBCA,\ DCAB(8),\ DCBA(9)$ However, $U=4!$ $$|f_A \cup f_B \cup f_C \cup f_D| = |f_A|+|f_B|+|f_C|+|f_D|-|f_A \cap f_B|-|f_A \cap f_C|-|f_A \cap f_D|-|f_B \cap f_C|-|f_B \cap f_D|-|f_C \cap f_D|+|f_A \cap f_B \cap f_C \cap f_D|$$ $$|f_A \cup f_B \cup f_C \cup f_D|=3!+3!+3!+3!-2!-2!-2!-2!-2!-2!+1=13$$ So, $$U-|f_A \cup f_B \cup f_C \cup f_D|=4!-13=11$$ What is wrong?","['coding-theory', 'discrete-mathematics', 'inclusion-exclusion', 'proof-verification', 'combinatorics']"
1466415,How does $\tan^{-1}(x-\sqrt{1+x^2})=\frac{1}{2}\tan^{-1}x+C$ directly?,"I'm teaching baby calculus recitation this semester, and I meet a problem to calculate the derivative of 
$$y=\tan^{-1}(x-\sqrt{1+x^2})$$
Just apply the chain rule and after some preliminary algebra, I find 
$$\frac{dy}{dx}=\frac{1}{2(1+x^2)}$$
What surprises me is that the result implies 
$$y=\frac{1}{2}\tan^{-1}x+C$$
Can anyone tell me how to see that directly?","['derivatives', 'calculus', 'trigonometry']"
1466432,Does the equation $(AB-BA)^2=I_n$ have a solution for each $n\geq 3$?,"Does the equation $(AB-BA)^2=I_n$ have a solution for each $n\geq 3$ ? $A$ and $B$ are matrices? I found out that the equation $(AB-BA)^m=I_n$ does have solution when $n=km$ where $k$ is an arbitrary integer number. It should be noted that $m>1$ is an integer number. To prove, we just need to consider $C=\operatorname{diag}(r_1,..., r_m)$ where $r_1,..., r_m$ are the roots of $x^m-1=0$ , i.e., the eigenvalues of matrix $C$ . In this case we know $\operatorname{trace}(C)=0$ , and so there are two matrices $A$ and $B$ such that $C=AB-BA$ , and also it is vivid that $C^m=I_m$ . For each $n=km$ , we can duplicate the matrix $C$ , $k$ times to get an $mk\times mk$ matrix to consider as new matrix $C$ .","['matrix-equations', 'linear-algebra', 'matrices']"
1466434,How to show this cover of $\mathbb{Q}$ doesn't cover $\mathbb{R}$?,"Let $\{q_n : n \in \mathbb{N}\}$ be an enumeration of $\mathbb{Q}$ and define $\mathcal{O} = \{I_n : n \in \mathbb{N}\}$ being $$I_n = \left(q_n - \frac{1}{2^n}, q_n + \frac{1}{2^n}\right).$$ It is obvious that $\mathcal{O}$ is an open cover of $\mathbb{Q}$, but I want to show this is not a cover of $\mathbb{R}$. One possible way that I've already seem is to see that the total length of the intervals is $2\sum_{n=1}^\infty 2^{-n}=2$ while the length of $\mathbb{R}$ is $+\infty$. Although this works, I'm trying to find another way to prove this result. One thing that is intuitively clear is that if $n\to \infty$ then the intervals shrink as small as desired around the rational midpoint, since $1/2^n \to 0$ as $n\to \infty$. I thought on using this to show that there is some irrational in the ""middle"" of two such $I_n$ for large enough $n$, but I don't even know how to start this. Anyway, how can I prove this result without using the measure argument? Is my idea correct? If so, how can it be made rigorous?","['rational-numbers', 'alternative-proof', 'real-analysis']"
1466443,Why is a parabolic subgroup $P$ connected?,"A parabolic subgroup of a connected algebraic group is one which contains a Borel subgroup. I'm trying to understand why parabolic subgroups are connected. Let $P$ be a parabolic subgroup containing a Borel group $B$. Since $B$ is connected, $B\subset P^\circ$, the component of the identity in $P$. Also, $P^\circ$ is a connected algebraic group itself, so any other Borel subgroup of $G$ in $P^\circ$ is $P^\circ$-conjugate to $B$. Thus
  $$
N_G(P^\circ)=P^\circ N_G(B)=P^\circ B=P^\circ.
$$
  Since $P\subset N_G(P^\circ)$ since $P^\circ\unlhd P$, it follows $P=P^\circ$. I'm missing the equality $N_G(P^\circ)=P^\circ N_G(B)$, it seems to follows from the fact that the Borel subgroups of $G$ in $P^\circ$ are still conjugate in $P^\circ$, but I don't see it.","['algebraic-groups', 'abstract-algebra', 'algebraic-geometry', 'group-theory']"
1466453,Sum of exponential random variables?,"I am trying to find the PDF of $Y$, the sum of I.I.D. exponential random variables $X_1, ... X_n$ with $\lambda = 1$ and $n$ some known constant. So far, I have determined that moment-generating function/characteristic function $M_s(Y) = M_s(X_1)^n = \left( \dfrac{1}{1-s} \right)^n.$ But this does not match the characteristic function of any other simple RV so i am at a loss as to how to proceed.","['probability', 'statistics', 'random-variables']"
1466457,"Does ""ring of sets"" have anything to do with the ""ring"" in abstract algebra? [duplicate]","This question already has answers here : Is the ring and semi-ring definition of algebra and set linked? (3 answers) Closed 8 years ago . The following comes from Wikipedia. It looks very strange to me since this ""ring"" seems to have nothing to do with the ""ring"" in abstract algebra. $(\cal R, \bigcup)$ is not an Abelian group (no inverse element if empty set is chosen as the identity), and $(\cal R, \backslash)$ is not a monoid (does not satisfy associativity). Am I right? Then why this thing is called a ring? Thanks!","['abstract-algebra', 'measure-theory']"
1466471,Sufficient condition for Uniform integrability,"The following is a problem that I've been struggling hard to prove. Any help would be appreciated. Suppose $\mu$ is a finite measure and for some $\gamma>0$
$$
\sup_n \int |f_n|^{1+\gamma} \ d\mu < \infty
$$
Prove that $\{f_n\}$ is uniformly integrable, i.e given an $\epsilon>0$ there exists $M$ such that $\displaystyle \sup_{n} \int_{\{x:|f_n(x)|> M \}} |f_n(x)|\  d\mu < \epsilon$ My attempt to solve: I wrote $\int |f_n|^{1+\gamma} \ d\mu = \int_{\{x:|f_n(x)|> M \}} |f_n|^{1+\gamma} \ d\mu + \int_{\{x:|f_n(x)|\leq M \}} |f_n|^{1+\gamma} \ d\mu$. How do I get rid of $1+\gamma\ ?$","['lebesgue-measure', 'measure-theory']"
1466477,"Prove that for all $n\in\mathbb{N}$, $\sqrt{n(n+1)}$ is not an integer.",I'm sure this is a very simple proof but I can't seem to get it right. I tried to do it by induction but get stuck trying to show that $\sqrt{(k+1)(k+2)}$ is not an integer and also cannot seem to do it through other methods. Anyone have any ideas? Thanks so much in advance!,"['analysis', 'real-analysis']"
1466478,What's the name of these two surfaces?,"I've plot two implicit surfaces which are shown in the above, I only know their expression, but I don't know how to call them.","['visualization', 'algebraic-geometry', 'surfaces', 'multivariable-calculus']"
1466508,Stochastic process: A bus with random numbers of passengers entering and exiting at each stop?,"A bus with infinite capacity runs on an infinite route with stops indexed $n = 1, 2, 3,\dots$ The bus arrives empty at stop $1$. When the bus arrives at stop $n$, each passenger on it gets off with probability $p$, independent of each other. Then all the waiting passengers get on. Let $W(n)$ be the number of passengers waiting at stop $n$, and suppose $\{W(n), n\ge0\}$ are iid Possion$(λ)$ random variables. Let $R(n)$ be the number of passengers on the bus when it leaves stop $n$. What is the distribution of $R(n)$? The answer is given as: $$Poisson(λ/p*(1-(1-p)^n))$$ My attempt: $$R(n)=Binomial(R(n-1),1-p)+Poisson(λ) = Poisson(R(n-1)*(1-p)+λ)$$
I don't know what to do past this, or if I'm thinking about this the right way.","['poisson-distribution', 'random-variables', 'stochastic-processes', 'statistics', 'binomial-distribution']"
1466518,Why can't we combine events in a poisson distribution?,"Let's say that babies in a hospital are delivered according to a Poisson distribution, where on average 1 baby is delivered every hour. Question 1 : What is the probability that at least 1 baby is delivered per hour? It is 1 - P(X = 0) for $\lambda = 1$, i.e. $1 - e^{-1} = 63\%$. Question 2 : What is the probability that at least 2 babies are delivered per 2 hours? It is 1 - P(X = 0) - P(X = 1) for $\lambda = 2$, i.e. $1 - e^{-2} - 2e^{-2} = 59\%$. To simplify the calculation of the question 2, let's combine 2 babies into one superbaby . We could then ask a question which seems (to me) to be identical to question 2: Question 3 :  What is the probability that at least 1 superbaby is delivered per 2 hours? It is 1 - P(X = 0) for $\lambda = 1$, i.e. $1 - e^{-1} = 63\%$. Here's what I don't understand: if a superbaby is simply 2 babies, Why is the probability that 1 superbaby is delivered per 2 hours not equal to the probability that 2 babies are delivered per 2 hours? My intuition tells me it has something to do with the assumption that events which follow a Poisson distribution are independent, but that's just a guess.","['probability', 'poisson-distribution']"
1466530,Proving $n! > n^3$ for all $n > a$,"Prove by induction: Find a, and prove the postulate by mathematical induction. $$\text{For all}~ n > a,~ n! > n^3$$ Where ! refers to factorial. So far I've done a bit of it, I'll skip right to the inductive statement and assume that $k! > k^3$ , then try to prove $(k+1)! > (k+1)^3$ Inductive statement: $(n+1)! > (n+1)^3$ $(n+1)^3= n^3 + 3n^2 + 3n + 1 < n! + 3n^2 + 3n + 1$ (By Induction Hypothesis) ...But now I'm stuck. Does anyone know where to go next?","['faq', 'induction', 'discrete-mathematics']"
1466535,"Two Matlab ODE solvers, two different results","I am solving a system of ODEs using Matlab. One particular set of parameters caused the solver to fail, so I worked my way through the different solvers Matlab provides. I was surprised to find that two of the solvers (ode23s and ode23tb) produced completely different, yet reasonable, results. Every other solver failed. My question: Which one (if any) should I trust and why? I'm not entirely sure if this is a mathematics question or a programming question, but I suspect it comes to a difference in the numerical methods, hence posting it here. ode23s: ode23tb: For reference the ODEs are:
$$\frac{dS}{dt}=-\beta IS+\xi(1-S)+3 \kappa L\\
\frac{dI}{dt}=\beta IS+\alpha IL-\xi I-\gamma I\\
\frac{dR}{dt}=\nu \beta IW+\gamma I - \xi R - 3\kappa R \\
\frac{dL}{dt}=-\alpha IL+3 \kappa W-\xi L -3 \kappa L\\
\frac{dW}{dt}=-\nu \beta IW + 3 \kappa R -\xi W - 3 \kappa W\\$$ With parameters:
$$\alpha=26,
\beta=260,
\kappa=.1,
\gamma=17,
\nu=5,
\xi=0.0125$$ And initial conditions: $$S_0=.99,
I_0=1-S_0,
R_0=0,
L_0=0,
W_0=0$$","['dynamical-systems', 'numerical-methods', 'ordinary-differential-equations', 'matlab']"
1466554,Application of Dominated Convergence Theorem and Monotone Convergence Theorem,"Find the limit $$\lim_{n \rightarrow \infty} \int _0^n (1 - \frac{x}{n})^n \log (2 + \cos(\frac{x}{n})) dx$$ and justify the answer. I think that the Dominated Convergence Theorem can be applied to this problem. Since $$\int _0^n (1 - \frac{x}{n})^n \log (2 + \cos(\frac{x}{n})) dx = \int _0^\infty (1 - \frac{x}{n})^n \log (2 + \cos(\frac{x}{n}))1_{[0, n]}(x)  dx,$$
if I can find the dominating function, I will then apply DCT. After applying DCT, we will have $$\lim \int _0^\infty (1 - \frac{x}{n})^n \log (2 + \cos(\frac{x}{n}))1_{[0, n]}(x)  dx = \int _0^\infty \lim (1 - \frac{x}{n})^n \log (2 + \cos(\frac{x}{n}))1_{[0, n]}(x)  dx = \int _0^\infty e^{-x} \log (3)  dx = \log(3)e^{-x}|_{x=\infty, x=0} = - \log (3).$$ But I am not sure if $$\Big| (1 - \frac{x}{n})^n \log (2 + \cos(\frac{x}{n})) \Big| \leq 3e^{-x}$$ with $3e^{-x}$ integrable on $[0, \infty).$ Can someone check if my dominating function is alright ? Prove that $$\sum_{k = 1}^\infty \frac{1}{(p + k)^2} = - \int_0^1 \frac{x^p}{1-x}\log (x) dx$$ for $p>0.$
(This problem is allow to use the Fundamental Theorem of Calculus) I suppose that I should apply FTC with DCT. But I have no ideas about doing this, any hints please ?","['real-analysis', 'lebesgue-integral', 'integration']"
1466567,Is there an analytic function with $f(z)=f(e^{iz})$?,"Does there exist a non-constant analytic function $f$ satisfying
  $f(z)=f(e^{iz})$ ? I don't know where to start.",['complex-analysis']
1466707,When do parallel sections exist?,"I suspect that this is a ""trivial"" question, but I don't have enough background to know the answer immediately:
Suppose $\pi : E \to M$ is a trivial real line bundle on a smooth manifold $M$, and suppose we have a flat connection $\nabla$ on $E$. Does there always exist a nowhere vanishing parallel section of $E$? If not, when does one exist?","['differential-geometry', 'connections', 'vector-bundles']"
1466742,Which notation is wise to consdier?,"Consider that $f(x)$ is a continuous function on the closed interval $\left[ a,b \right]$. Also, its $n$-th derivative is continuous on $\left( a,b \right)$ where $n$ is any desired integer. I mean that $f$ is infinitely differentiable. Now I want to say that $f(x)$ satisfies a second order differential equation on some interval with some boundary conditions. I give an example. Which of the following is correct to write down? 
$$
\left\{
\begin{array}{ll}
\frac{d^2 f}{dx^2} + f =0 &\hbox{on $[a,b]$}\\
f(a)=1 \\
f'(b)=0
\end{array}
\right. \tag{1}
$$
or
$$
\left\{
\begin{array}{ll}
\frac{d^2 f}{dx^2} + f =0 &\hbox{on $(a,b)$}\\
f(a)=1 \\
f'(b)=0
\end{array}
\right. \tag{2}
$$ My thought I think $(2)$ is correct as the derivatives are not defined at the end points $a$ and $b$. If we accept this thought what does it mean to say $f'(b) = 0$. I am stuck.","['notation', 'calculus', 'ordinary-differential-equations']"
1466770,What are some topos-theoretic insights about $G$-sets?,"Since a $G$-set is just a functor $G\longrightarrow \mathsf{Set}$, the category of $G$-sets seems to be a simple example of a topos. What are some topos-theoretic insights into $G$-sets? Insights deserving to be called ""geometric"" are particularly welcome (hopefully with an explanation).","['topos-theory', 'group-theory', 'group-actions', 'category-theory']"
1466780,What is the maximum volume of an equilateral triangular prism inscribed in a sphere of radius 2?,"What is the maximum volume of an equilateral triangular prism inscribed in a sphere of radius 2? Since the volume of an equilateral triangular prism is $\frac{\sqrt3}{4}a^2h$,where $a$ is the side length of the base triangle and $h$ is the height of the prism.How to express this volume in terms of radius of the sphere so that i can differentiate it and equate it to zero.Thanks.","['solid-geometry', 'geometry', 'calculus']"
1466801,Issue with trigonometry identity related to condition number of matrix,"So, in attempting to compute the condition number for the 2-norm of a matrix, I have stumbled upon a problem i can't resolve. I have the formula $$
\frac{1-\cos\left(\frac{n}{n+1} \pi\right)}{1-\cos\left(\frac{1}{n+1} \pi\right)}.
$$ I arrived at this because the eigenvalues for my matrix are $2\left(1-\cos\left(\frac{p}{n+1} \pi\right)\right)$ for $p=1,..,n$. The problem comes from the fact that I need to show that this formula somehow ends up being equal to 
$$\frac{1}{\tan^2\left(\frac{1}{2(n+1)}\pi\right)}
$$ I've arrived at $$
\frac{1-\cos\left(\pi\frac{n}{n+1}\right)}{2\sin^2\left(\frac{\pi}{2(n+1)}\right)}
$$ but can't seem to get any further, mostly due to the $n$ in the numerator of the cosine. Any help would be appreciated.","['numerical-linear-algebra', 'trigonometry']"
1466827,"If a bounded real-valued function $f(t)$ is discretized into $k$ values, what happens to Fourier transform $F(\omega)$?","Suppose there is a bounded real-valued function $f(t)$, with $t$ always a real number and can be interpreted as time. Let $\max[f(t)] = x_k$ and $\min[f(t)] = x_1$. And let us divide $[x_1,x_k]$ into $k-1$ equal intervals, which creates $x_1,x_2,x_3,..,x_k$. Suppose that whenever $(x_{i-1}+x_i)/2<f(t)\leq (x_i+x_{i+1})/2$, a new function $g(t) = x_i$. In such a case, how would Fourier transform of $g(t)$ differ from $f(t)$?","['fourier-analysis', 'discrete-mathematics']"
1466851,Counting clique free graphs?,"I'm looking for a reasonable but simple lower bounds or asymptotics for $S_n(k)$, the number of labelled graphs on $n$ vertices that contain no $k+1$-clique.
A rather weak lower bound is the number of connected graphs on $k$ vertices times the number of ways to choose $k$ vertices from $v$, but even this is quite messy. Kolaitis, Prömel, and Rothschild showed in 1987 that $S_n(k)$ is asymptotically equal to the number of labelled graphs on $n$ vertices that are $k$-colourable (or $k$-partite).
J. Balogh et al. recently improved this, showing that nearly all $k$-free graphs are $k-1$-partite when $k$ is a slowly growing function of $n$.  (arXiv:1406.6961)
Finally, Prömel in 1987 showed that nearly all labelled graphs containing no $k$-clique are rigid.
However, these results do not seem to yield an explicit expression.","['asymptotics', 'graph-theory', 'combinatorics']"
1466855,Limit of $\frac{\frac{1}{e}(1+x)^{1/x}-1+\frac{x}{2}}{x^2}$ when $x\to0$,"Find the limit of $\dfrac{\frac{1}{e}(1+x)^{1/x}-1+\frac{x}{2}}{x^2}$ when $x\to0$. I tried applying L'Hospital rule, but it is not working here. How should I solve this?",['limits']
1466910,How can we explain $e^{\pi}-\pi\approx20$?,"Using a calculator we can easily check that $$\color{Green}{e^{\pi}-\pi}=19.999\cdots\color{Green}{\approx 20}$$ This article and this one provides some details about this almost near identity, but no explanation. My question is : Can we obtain the above almost equality geometrically? Add: Let me add more details to address the issues pointed some people in the comments section. As I think both numbers $\pi$ and $e$ are very geometric and their appearance in some unexpected places is due to this geometric nature. Also, here by geometry, I do not mean just Euclidean geometry (or ruler and compass construction), but in the inclusion sense. Secondly, consider the graphs of functions $y=e^x$ and $y=x+20.$ We can compute their exact intersection points of them using Lambert W function, and approximately they are $x=-19.99999\cdots$ and $x=3.1416\cdots.$ One of these numbers almost indistinguishable from $-20$ and the other is very close to $\pi.$ How can we explain this unreasonable result?","['pi', 'exponential-function', 'geometry', 'geometric-inequalities', 'inequality']"
1466940,Among $2n$ people there are two who have an even number (including $0$) of friends in common .,"The following problem is found in a textbook. Prove that among $2n$ people there are two who have an even number (including $0$) of friends in common. To be more precise, in a graph with an even number of vertices, there exist two distinct vertices $x$ and $y$ with the property that the number of vertices which are adjacent to both $x$ and $y$ is an even number (including $0$). This statement holds for $n=1, 2$. If $0$ is not allowed then the statement does not hold as is seen in a path graph. Though the matrix approach may not be of help, if $A$ is the adjacency matrix of the graph, then the statement is equivalent to saying that $A^2$ has an even off-diagonal entry. Can anyone show me how to proceed?","['graph-theory', 'combinatorics']"
1466983,What is the reason behind calling $\emptyset$ improper subset of any non-empty set.? [duplicate],"This question already has answers here : Is the void set (∅) a proper subset of every set? (5 answers) Closed 8 years ago . I'm learning about Sets. I'm confused in two statements given in my book,i.e every set is a subset of itself and the empty set is the subset of every set. These two subsets are called improper subset. Another statement: a subset A of a set B is called proper set of B if A is not equal to B. I didn't get how phi is improper subset since it is not equal to any non-empty set. I searched about this question in this site but I didn't understand it fully. Please explain. Thankyou in advance.",['elementary-set-theory']
1467019,Is Cramer's rule efficient for computational point of view?,I am not sure if Cramer's rule is used for computation purposes. Your help would mean a lot. Thanks!,"['linear-algebra', 'computational-complexity']"
1467030,$\lim_{t \to + \infty}(y'(t)+\alpha y(t))=0 \implies \lim_{t \to +\infty}y(t)=0$,"Problem: Let $y \in C^1([0,+\infty), \mathbb{R})$ and $\alpha >0$. Prove that $$ \lim_{t \to + \infty}(y'(t)+\alpha y(t))=0 \implies \lim_{t \to +\infty}y(t)=0$$ I will show two attempts I have made, both of them didn't work out for me 1st Attempt : Let $\alpha > 0$ such that $$\lim_{t \to + \infty} (y'(t) + \alpha y(t))=0 \\ \implies \forall \epsilon >0, \exists S \in \mathbb{R}: \forall t \in [0, \infty) \text{ with } t\geq S \implies y'(t)+\alpha y(t)  \leq \epsilon  $$ But I can easily work with $y'(t)+ \alpha y(t) \leq \epsilon$ by multiplying it with $e^{\alpha t}$ one easily finds that  $$ \left(y(t)e^{\alpha t}\right)' \leq \epsilon e^{\alpha t} $$
Integration of both sides and using the fact that integration preserves the inequality I obtain that $$y(t) \leq \frac{\epsilon}{\alpha}+ C \exp(-\alpha t), \ \text{ for } C \in \mathbb{R} \\ \implies |y(t)| \leq \frac{\epsilon}{\alpha}+|C| \exp(-\alpha t)  $$
Which looks promising at first, because as $t \to + \infty$ the most right term vanishes, however the fraction $\epsilon / \alpha$ doesn't provide any useful information, because possibly $\alpha, \epsilon$ are arbitrarily, so I am not sure if it is a rigorous statement to just say ""$\epsilon$ can always be smaller than $\alpha$"" 2nd Attempt : I was hoping that with the help of Gronwall's inequality I could get rid of the missing rigor of the above attempt Gronwall Inequality : Assume that $y'(t) \leq f(t) + g(t)y(t)$ then we have $$ y(t) \leq y(a) \exp \left( \int_a^t g(s)ds\right) + \int_a^t f(s) \exp \left( \int_s^t g(r)dr \right) ds $$ So I did use again the only thing that I know which is that $y'(t) + \alpha y(t) \leq \epsilon $ and to apply Gronwalls Lemma I did set $f(t)= \epsilon$ and $g(t)=- \alpha$ for all $t \in [0, \infty)$ Doing the necessary integration for Gronwalls Inequality I obtain that $$ y(t) \leq y(a) \exp(-\alpha (t-a)) + \frac{\epsilon}{\alpha} \left(1-\exp(-\alpha(t-a)  \right)$$
Which somehow just shows that my 1st attempt was equally good/bad as my 2nd attempt. Any hints? Corrections?","['analysis', 'real-analysis', 'ordinary-differential-equations']"
1467036,how to estimate $\prod_{k=2}^n \log(k)$?,"I wonder if I can estimate $\prod_{k=2}^n \log(k)$ as $a^l$ for some a. I know that it is bounded by $e^{n^2}$, but I would like to get something finer.","['products', 'real-analysis', 'combinatorics', 'analysis', 'infinite-product']"
1467067,To show that a matrix defines a map from $l^2$ to $l^2$,"Let $$M=\begin{bmatrix}
1 &\frac{1}{2}&\frac{1}{3}&\frac{1}{4} \dots\\
0 &\frac{1}{2}&\frac{1}{3}&\frac{1}{4} \dots\\
0 & 0 &\frac{1}{3} &\frac{1}{4} \dots\\
\vdots & \vdots &\dots
\end{bmatrix}$$ I need to find out if this matrix defines a map from $l^2$ to $l^2$. For that I look at a typical $y(j)$ position, meaning if I multiply $M$ by $x=\left(x(1),x(2),..,x(j),...\right)$, I get $y=\left(y(1),y(2),..,y(j),..\right)$ and for $M$ to be a map each $y(j)$ should make sense and whole of $y$ should make sense. For each $y(j)$ to make sense , $y(j)=\sum_{k=j}^{\infty} \dfrac{1}{k}x(k)$, should converge. So I look at $$\sum_{k=j}^{\infty}|\frac{1}{k} x(k)| \le \sqrt{\sum_{k=j}^{\infty}\frac{1}{k^2}} \times ||x||_2$$
So the series converges absolutely and hence it converges. No problem with this. Now $y$ should be in $l^2$ for everything to fall through. So I look at $$||y||^{2}_2=\sum_{j=1}^{\infty} |\left(\sum_{k=j}^{\infty}\frac{1}{k}x(k)\right)|^2 \le \sum_{j=1}^{\infty}\left(\sum_{k=j}^{\infty}|\frac{1}{k}x(k)|\right)^2 $$
$$\le \sum_{j=1}^{\infty}\{\left(\sum_{k=j}^{\infty}\frac{1}{k^2}\right)\left(\sum_{k=j}^{\infty}|x(k)|^2\right)\} $$ This is where I am stuck . I can always pull out $||x||_2$ but that doesn't help. I have a double series here. To solve this problem it seems to me that i have to show that this is double series converges. Cauchy-Schwarz is the best possible approximation I can get. So I don't think I have to do something with that. I tried to use the fact that the tail of the series goes to zero but that doesn't help either. (since there is a difference between going to zero and actually being zero) Now suppose I multiply the matrix with $ x=(0,...0, j,0,0,0..) $ where $ j $ is at the $ k$ th place, then $ y=(1,1,1,...,1,0,0..0) $ where the last$1$ is at the $ k $ th place. Also $||y||_2=\sqrt {k}$. This doesn't lead to anything.  I think that finally it boils down to choosing $ x $ such that the series on the right diverges. Suppose I multiply by an arbitrary $x=\left(x(1),x(2),..,x(j),..\dots \right)$, (of course $x \in l^2$)then $y=(y(1),y(2),..,y(j),..\dots )$, where $y(j)=\sum_{k=j}^{\infty} \dfrac{x(k)}{k}$. I am unable to find an $x$. 
Thanks for the help!!","['normed-spaces', 'matrices', 'matrix-calculus', 'functional-analysis', 'linear-transformations']"
1467094,Can $f(g(x)) = x$ if $g(f(x))$ is not equal to $x$?,"Is it possible that there are functions $f(x)$ and $g(x)$ where $f(g(x)) = x$ and $g(f(x))$ does not equal $x$? If so, is there a pattern or general rule for them? If not, what is the proof that there is not? This originated when a math teacher said that in order for $g$ of $x$ to be the inverse of $f$ of $x$, it must be that both $f\circ g$ and $g \circ f$ equal $x$, and a student asked if one of these cases exists.",['algebra-precalculus']
1467166,"Find $M_{min}$ if there exist constant $M$ such $f(x)<M$,and $\frac{f(x)}{x^2}$monotone increasing function","If   $\dfrac{f(x)}{x^2}$monotone increasing function on $x\in (0,+\infty)$,and there exist constant $M$,such $f(x)<M,\forall x\in (0,+\infty)$,then Find the $M_{min}$ If we let $g(x)=\dfrac{f(x)}{x^2}$,then for any $x,y>0(x<y)$,we have $g(x)<g(y)$ or
$$\dfrac{f(x)}{x^2}<\dfrac{f(y)}{y^2}$$
but I don't have any idea how to start proving it,
Thanks",['functions']
1467177,"intuition on what PDEs mean ""physically"".","I've taken PDE/ODE classes and now I'm starting to do work that requires knowledge about them but I've never felt comfortable.  I've learned about laplace/heat/wave equation and other examples, but I can rarely see a PDE/ODE and be able to translate the equations into a ""physical"" interpretation to gain some intuition as to what the system of equations is representing.  I see that if $u:\mathbb{R}^n\rightarrow\mathbb{R}$ is some differentiable function then $\nabla u$ is the gradient, which essentially is a vector valued function that points in the direction of fastest increase for $u$.  This is probably the most basic example, but then we get to, for example, the laplacian $\Delta u$, and even though I know it's the sum of the squared second derivatives, I have no clue how to relate this to the world besides the mathematical definition.  Another example comes from Ulrich Hornungs book on homogenization, where he starts with the ODE: $\frac{d}{dx}(a(x)\frac{d}{dx}u(x))=0$ for $0<x<1$, $u(x)=0$ for $x=0$, $u(x)=1$ when $x=1$. He says this is a one dimensional diffusion problem and that the differential equation requires that the flux $q(x)=-a(x)\frac{d}{dx}u(x)$ be constant.  I see why $q(x)$ must be constant, but why in the world is this the flux and how does this describe diffusion? I feel like perhaps my vector calculus is just not where it needs to be, but I never saw the biggest picture when I took multivariable calculus a while ago.  Is there any book that goes through the mathematics of the vector calculus/PDEs but also explains the physics/intuition behind what everything talks about?  I suppose I'm just at the point where I don't know what I need to study to make myself more comfortable with the subject.","['multivariable-calculus', 'partial-differential-equations']"
1467183,Does category theory help in operator algebras?,"I'm currently studying the basics of Banach and $C^*$-algebras. Almost all the proofs i've seen so far are very simple but some of them are extremely tricky (in my opinion). This tricky interplay between the bits of analysis and algebra make some of the proofs seem unilluminating and disconnected from the flow of the theory. Is there an approach to operator algebras that uses category theory to simplify and ""trivilize"" the elementary theory? Ideally it would use input from analysis (category of banach spaces, hilbert spaces, topological vector spaces) and algebra (category of associative algebras over $\mathbb{C}$ for a start) only when absolutely (and obviously) necessary.","['operator-algebras', 'noncommutative-algebra', 'functional-analysis', 'c-star-algebras', 'category-theory']"
1467212,Improvement on $\phi(n)\sigma(n)/n^2$ bounds?,"We have: $$\dfrac{6}{\pi^2}\lt\dfrac{\phi(n)\sigma(n)}{n^2}\le1$$ with equality iff $n=1$. Wikipedia Are there any known improvements on these bounds? APPENDUM For $n$ prime, $\dfrac{\phi\sigma}{n^2}\to1$. Generally if $n=\prod p_i^{k_i}$, $\dfrac{\phi\sigma}{n^2}=\prod \big(1-\dfrac{1}{p_i^{k_i+1}}\big)$, which means the lower bound is sharp.","['number-theory', 'totient-function', 'divisor-sum']"
1467219,Where are the roots going?,"Each polynomial of degree $n$ has $n$ different roots. We know that $$e^z = \sum_{n=0}^\infty \frac {z^n}{n!}$$ has no roots. What is the behaviour then of the root of $S_N = \sum_{n=0}^N\frac {z^n}{n!}$? Where do they go? We could generalize this and ask Given $f(z)$ holomorphic in some $\Omega$ (feel free to take any condition you want on $\Omega$), what is the relationship between the root of $f(z)$ and the roots of the truncated expansion of $f(z)$? edit I've seen the suggested duplicate and its really interesting, though I am interested in a more general result :-)","['roots', 'calculus', 'real-analysis', 'analysis', 'complex-analysis']"
1467222,Approximating $(1+\frac{1}{z})^z$ where $|z|$ is large,"I know that
$$\lim_{x\rightarrow \infty}\left(1+\frac{1}{x}\right)^x=e$$
Is there an equivalent in complex analysis for
$$\lim_{|z|\rightarrow \infty}\left(1+\frac{1}{z}\right)^z=?$$","['limits', 'complex-analysis', 'complex-numbers']"
1467279,"If $ I = \int_{0}^{1}x^{1004}\cdot (1-x)^{1004}dx$ and $J=\int_{0}^{1}x^{1004}\cdot \left(1-x^{2010}\right)^{1004}dx\;,$ Then $I/J$","If $\displaystyle I = \int_{0}^{1}x^{1004}\cdot (1-x)^{1004}dx$ and $\displaystyle J=\int_{0}^{1}x^{1004}\cdot \left(1-x^{2010}\right)^{1004}dx\;,$ Then Relation between $I$ and $J.$ $\bf{My\; Try::}$ Given $$\displaystyle J = \int_{0}^{1}x^{1004}\cdot (1-x^{2010})^{1004}dx\;,$$ Now Put $\displaystyle x^{1005}=t\;,$ Then $1005x^{1004}dx = dt$ And Changing Limit, We get $$\displaystyle J=\frac{1}{1005}\int_{0}^{1}(1-t^2)^{1004}dt = \frac{1}{1005}\int_{0}^{1}\left[1-(1-t)^2\right]^{1004}dt$$ So we get $$\displaystyle J=\frac{1}{1005}\int_{0}^{1}t^{1004}\cdot (2-t)^{1004}dt$$ Now How can I solve after that , Help me Thanks",['calculus']
1467318,The Borel sigma-algebra on $\mathbb{R}^2$.,"Let $Bo(\mathbb{R}^2)$, be the borel-sigma algebra on $\mathbb{R}^2$, it is the sigma algebra generated by the open sets on $\mathbb{R}^2$. Let $\mathcal{B}$ be the borel sigma algebra on $\mathbb{R}$. Let $\mathcal{B}\otimes\mathcal{B}$ be the sigma-algebra on $\mathbb{R}^2$, generated by the set $\{B_1\times B_2|,B_1,B_2 \in \mathcal{B} \}.$ I am trying to prove that $Bo(\mathbb{R}^2)=\mathcal{B}\otimes\mathcal{B}$. Now the implication $Bo(\mathbb{R}^2)\subset \mathcal{B}\otimes \mathcal{B}$, is ok: $\mathcal{B}\otimes \mathcal{B}$ is a sigma algebra, and for any two intervals in $I_1,I_2 \subset\mathbb{R}$, $I_1,I_2 \in \mathcal{B}$, so $I_1\times I_2 \in \mathcal{B}\otimes\mathcal{B}$.Since any open set in $\mathbb{R}^2$ is a countable union of open rectangles, $\mathcal{B}\otimes \mathcal{B}$ must contain the open sets of $\mathbb{R}^2$, since it is a $\sigma$-algebra, it must contain the smallest sigma algebra on $\mathbb{R}^2$ containing the open sets, which is $Bo(\mathbb{R}^2)$, hence $Bo(\mathbb{R}^2)\subset \mathcal{B}\otimes \mathcal{B}$. But how do I prove the reverse implication, that is: $\mathcal{B}\otimes\mathcal{B}\subset Bo(\mathbb{R}^2)$? If I can prove that for any two sets $B_1,B_2 \in \mathcal{B}$, $B_1 \times B_2\in Bo(\mathbb{R}^2)$, I will be done. But how do I prove this? All we know about the sets $B_1,B_2$ is that they are in $\mathcal{B}$, which is the smallest sigma-algebra on the real line, containing the open sets. but this doesn't really tell us much about how the sets $B_1,B_2$ are. Do you guys have any tips?","['real-analysis', 'general-topology', 'measure-theory']"
1467336,Finding a point on a circle that makes a specific angle of incidence with a given point inside it?,"Suppose we have a circle of radius r centered at the origin, and we are given a point C$(x,y)$ inside the circle. Let $\theta_i$ be the angle of incidence of the line drawn from C. If we know $\theta_i$ (say, 23º) and C, how can we find the coordinates of P$(x,y)$, the point on the circle where the angle of incidence from C is $\theta_i$? Edit 1: Oops, forgot to draw P in the circle. It's the point where the line meets the circle.","['algebraic-geometry', 'geometry', 'circles', 'trigonometry']"
1467362,Endomorphism rings and torsion subgroups.,"Let $G$ be an abelian group and let $T$ be its torsion subgroup, i.e., $T = \{g \in G \hspace{1mm} | \hspace{1mm} g \text{ of finite order}\} $. Is the restriction map $\phi: \text{End}(G) \rightarrow \text{End}(T), \hspace{1mm} f \mapsto f|_{T}$, which is a homomorphism of rings, a surjection? If $G$ is finitely generated, the answer to this question is positive. This can be seen by invoking the classification of finitely generated abelian groups. I don't think that $\phi$ is a surjection in general, but I haven't been able to construct a counterexample yet.","['abelian-groups', 'group-theory', 'torsion-groups']"
1467400,Best strategy to find a parking spot,"New Bounty Edit (2 days remaining on the Bounty): To point out that the only answer given at this time cannot be considered an answer, because it simply gives a hint on how to formally model the problem, which is not what I was looking for, considering I wrote it informally on purpose. Still looking forward to some analyses of this problem! I was wondering about the following problem. Assume the following. you have to find a parking spot for your car in a very busy saturday night to go in a restaurant; you search for this parking spot by basically going around (literally) in the hope to get a spot; of course, (the saturday night is really busy) other people are in the same situation as you are and they are running in circle like you are; the direction of the movement is only one (again, you literally go around); the time frame of the problem lies between 20:00 and 00:00. Finally (of course!); when you start your search at 20:00 there are no free parking spots. Question: What is the best strategy you can use to find a parking spot? Should you stop in a place and wait until one of the cars that you can cover with your eyesight leaves? Or is it better to move around in the hope to find a free parking spot? I was thinking about the following few variables that I think should essentially change the nature of the problem: Cardinality of the set of parking spots (countable vs. uncountable); Cardinality of the set of agents involved in this situation (countable vs. uncountable); Probability of having a car that already occupies a parking spot leaving that lot in function of time (normally distributed, uniformly distributed, etc); Farsightedness of the agents (extreme cases: one place ahead of you, whole circle ahead of you) Hence, a solution should be explicit about what is assumed concerning those variables. [Notice that the in general I assume that the space where you are looking for a spot is homeomorphic to a circle] Any feedback as always is most welcome. PS: As you can guess, where I live it is very (very!) difficult to find a parking spot on Saturday nights... Bounty Edit: As in the bounty text, I would like to know what are reasonable answers to this question (without considering as options using the bus, the tram, a bicycle or an helicopter...).","['probability', 'puzzle', 'decision-theory', 'recreational-mathematics']"
1467416,"entire functions and multi-valued functions, an easy to understand explanation?","From wikipedia: The Bessel function of the first kind is an entire function if α is an
  integer, otherwise it is a multivalued function with singularity at
  zero. I have plotted the function $J_\alpha(x)$ for a few values of $\alpha$ in the $-10\le x\le 10$ interval: Plot[{Re[BesselJ[0, x]], Im[BesselJ[0, x]]}, {x, -10, 10}] $\alpha = 0$ Plot[{Re[BesselJ[1, x]], Im[BesselJ[1, x]]}, {x, -10, 10}] $\alpha = 1$ Plot[{Re[BesselJ[-2, x]], Im[BesselJ[-2, x]]}, {x, -10, 10}] $\alpha = -2$ Plot[{Re[BesselJ[5/4, x]], Im[BesselJ[5/4, x]]}, {x, -20, 20}] $\alpha = \frac{5}{4}$ Plot[{Re[BesselJ[-2/3, x]], Im[BesselJ[-2/3, x]]}, {x, -20, 20}] $\alpha = \frac{-2}{3}$ Plot[{Re[BesselJ[Sqrt[2], x]], Im[BesselJ[Sqrt[2], x]]}, {x, -20, 20}] $\alpha = \sqrt{2}$ Plot[{Re[BesselJ[-Sqrt[3], x]], Im[BesselJ[-Sqrt[3], x]]}, {x, -20, 
  20}] $\alpha = -\sqrt{3}$ Plot[{Re[BesselJ[2 + I, x]], Im[BesselJ[2 + I, x]]}, {x, -20, 20}] $\alpha = 2+i$ Plot[{Re[BesselJ[-2 + I, x]], Im[BesselJ[-2 + I, x]]}, {x, -20, 20}] $\alpha = -2+i$ Plot[{Re[BesselJ[10, x]], Im[BesselJ[10, x]]}, {x, -100, 100}] $\alpha = 10$ Seems that for integer values of $\alpha$, the function $J_\alpha(x)$ is real-valued but for other values $\alpha\in(\mathbb R-\mathbb Z)$ the function has complex values. Could you please give an easy and intuitive explanation for the concepts entire function and multivalued function based on these plots?","['definition', 'bessel-functions', 'functional-analysis', 'functions', 'intuition']"
1467421,How to give a combinatorial proof for this forumula,"I need to give a combinatorial argument that $$S(n,m) = \sum_{i =0} ^{n-1} {n -1 \choose i} S(i,m-1)$$ Where $S(n,m)$ is the Stirling numbers of the second kind. Here is my attempt. Well first thing to know here is that $S(n,m)$ is the number of ways to distribute $n$ distinct among $m$ non empty identical containers. So If by somehow I managed to show that the right hand side of the above equation mean the same thing then I am done right ! Now for $ 0 \leq i \leq n-1$, let $i$ count the number of distinct objects that we actually distribute (The number of objects that got distributed from $n-1$ objects). This number of distinct objects can be chosen in ${n-1 \choose i}$ ways, Now the number of ways that we can distribute those $i$ objects among $m-1$ non empty identical container is ${n-1 \choose i} S(i,m-1)$. But if we kept doing that we will get $S(n-1,m-1)$ and not $S(n,m)$. I feel like I am missing something here, and something is wrong with my reasoning. How do I proceed with this proof or re correct it.","['combinations', 'discrete-mathematics', 'stirling-numbers', 'combinatorics']"
1467478,"Let $G$ be a group, if $H=\{b\in G\ |\ bab^{-1} \in \langle a \rangle\} $ is H a subgroup of G?","I've seen this question around when $G\wedge\langle a \rangle$ are finite, but what if $G$ is infinite and $\langle a \rangle $ is finite? My approach: Show $H$ is closed, which just follows from the cyclicality of $\langle a \rangle$. In the case that $G$ is infinite I also have to show that $\forall b \in H,\ b^{-1} \in H$. I can't figure out how to show condition 2. I was hoping somone could help me out","['abstract-algebra', 'group-theory']"
1467514,Help me in showing that there is only 2 solutions for $f(x)=(x-1)e^{2x}+x^2-x-1=0$?,"I have a problem with part (b) in the following question Question a) Function: $f(x)=(x-1)e^{2x}+x^2-x-1$, show that $f(x)$ has a zero between −1 and 1/2 and between 1/2 and 2. b) Show that there are only exactly two solutions (two 0's). My Approach a) Pretty easy: $$f(x)=(x-1)e^{2x}+x^2-x-1=0$$
$f(-1)>0,f(1/2)<0$ Intermediate Theorem tells that there is a solution. $f(1/2)<0,f(2)>0$ Intermediate Theorem tells that there is a solution in between. b) This is where I have the problem with, how do I show exactly that there is only 2 solutions. The most obvious thing that came to my mind is that the highest power is 2 . But then I thought it can't be that easy, there is something I am missing.","['calculus', 'functions']"
1467515,Bijective homomorphism of algebraic groups is isomorphism (characteristic 0),"Let $X$ and $Y$ be affine algebraic groups over an algebraically closed field $k$ of characteristic $0$ , and $\phi: X \to Y$ be a group homomorphism, which is also a morphism of varieties. I would like to prove that $\phi$ is an isomorphism. I know that in characteristic $p$ there is Frobenius map $Fr: \mathbb G_a \to \mathbb G_a, x \mapsto x^p$ , which is bijective but not an isomorphism. It corresponds to field extension $k(x^p) \subset k(x)$ , which is purely inseparable. I suppose that to start I should prove that, as all field extensions in characteristic 0 are separable, the field extension corresponding to $\phi$ is trivial. After this, one could use the fact that a bijective birational morphism $\phi$ between irreducible affine varieties $X, Y$ , such that $Y$ is normal, is an isomorphism.","['algebraic-groups', 'algebraic-geometry', 'field-theory']"
1467517,Problem of $\pi$- and $\lambda$-systems,"I have some trouble with a theoretic-like exercise about measure theory, and $\pi$- and $\lambda$-systems, and I would like to have some help. The problem is stated in the book Mathematical Statistics, Jun Shao , exercise 5 of section 1.6, page 74: I am somewhat puzzled because I expected $\mathcal{D}$ to be a $\sigma$-algebra (the exercise would be vacuosly easy then), but to be a $\lambda$-system is strictly weaker. I suppose one has to use some trick about $\pi$-systems, but I cannot guess what to use because of the non-constructive definition of the $\sigma$-algebra generated by some subset. Any suggestion is welcome. Thanks in advance.","['probability-theory', 'problem-solving', 'measure-theory']"
1467556,Prove that $\sin^{6}{\frac{\theta}{2}}+\cos^{6}{\frac{\theta}{2}}=\frac{1}{4}(1+3\cos^2\theta)$,"A question on submultiple angles states... Prove that:$$\sin^{6}{\frac{\theta}{2}}+\cos^{6}{\frac{\theta}{2}}=\frac{1}{4}(1+3\cos^2\theta)$$ My efforts I tried using the formula
$$a^3+b^3=(a+b)^3-3ab(a+b)$$
and
$$\cos^2{\frac{\theta}{2}=\frac{\cos\theta + 1}{2}}$$
Then I tried simplifying it:
$$\require{cancel} \begin{align} \sin^{6}{\frac{\theta}{2}}+\cos^{6}{\frac{\theta}{2}} & = (\sin^{2}{\frac{\theta}{2}}+\cos^{2}{\frac{\theta}{2}})^3 - 3\sin^2{\frac{\theta}{2}}\cos^2{\frac{\theta}{2}}(\sin^{2}{\frac{\theta}{2}}+\cos^{2}{\frac{\theta}{2}})\\
& = 1 - 3\sin^2{\frac{\theta}{2}}\cos^2{\frac{\theta}{2}}\\
& = 1 - 3(1 - \cos^2{\frac{\theta}{2}})\cos^2{\frac{\theta}{2}}\\
& = 1 - \frac{3}{2}(\cos\theta+1) + \frac{3}{4}(\cos\theta+1)^2\\
& = \frac{4\cancel{-6\cos\theta}-2+3\cos^2+3+\cancel{6\cos\theta}}{4}\\
& = \frac{1}{4}(5+3\cos^2\theta)\end{align} $$ I suspect I must have messed up with some sign somewhere. The trouble is, I can't seem to find where . Please help me in this regard. Update: I am not accepting an answer because all the answers are equally good. It would be an injustice to the other answers. Note to the editors: I also suspect that my post is a little short on appropriate tags. If required, please do the needful.",['trigonometry']
1467581,What does it mean for a probability distribution to have a finite fourth moment?,"For example, suppose that some probability distribution X has a finite fourth moment. What distinguishes this distribution from another one, Y, which does not have a finite fourth moment? I am to understand that this gives us greater control over the ""tails"" of the distribution, but I don't understand how so.","['probability', 'expectation']"
1467774,On p-groups having maximal class,"Let's suppose P is p-group of maximal class and let N be a normal subgroup of P whose index in P is greater than or equal to $p^2$. How can we show that N turns out to be one of the terms of the lower central series for P? Considering the lower central series for P, it's clear that all the successive quotients are of order p, except for the top-most quotient which is of order $p^2$. It seems clear that N cannot be properly squeezed in the lower central series, but then I'm not sure how to show N is actually one of the terms.","['abstract-algebra', 'group-theory', 'finite-groups']"
1467784,Inverse of a function's integral,The function $g$ is strictly positive. Let the function $f$ be defined as $$f(x) = \int_0^x g(u) du$$ Is there a way to express $f^{-1}(x)$ in terms of $g$?,"['inverse', 'calculus', 'functions', 'integration']"
1467805,Indefinite Integral of Absolute Value of x? Is there a closed form solution?,Been searching the net for awhile and everything just comes back about doing the definite integral. So just thought to ask here. Title says it all. Is there a closed form solution for the indefinite integral $\int |x| dx$ ?,['calculus']
1467830,Proof that a measure is a countable sum of dirac measures,"Let $\mu$ be a measure on $\mathcal{B}_\mathbb{R}$ with $\mu(\mathbb{R})=1$. Suppose there exists $t\neq 0$ such that $|\int e^{itx}d\mu (x)|=1.$ Prove $\mu$ is a countable sum of dirac measures with coefficients. Here's how I'm trying to go about it. Let $f(x)=e^{itx}$.
Let $\alpha=\overline{\int f}$ that is, the conjugate of $\int f$. Since $|\int f|=1$, $|\int f|=\alpha \int f=\int \alpha f$. Since  $\int \alpha f$ is real, we have
$|\int f|=Re\int \alpha f=\int Re(\alpha f)\leq\int|Re(\alpha f)|\leq \int|\alpha f|=\int|f|$, but we know that, in this case, $|\int f|=\int|f|$ so all the inequalities are actually equalities. $\int|Re(\alpha f)|= \int|\alpha f|$ implies that $Im(\alpha f)=0$ a.e., that is, $\cos^2(tx)=\sin^2(tx)$ a.e. I'm trying to derive from it some useful implication to solve this problem, but with no progress. Could anyone give me some direction? 
I would appreciate any comment. 
Thank you.","['real-analysis', 'measure-theory']"
1467859,"understand quaternion algebra ramified at p,q and split everywhere else","I came across the following on this question on mathoverflow and my questions is can someone explain in more detail (e.g give a presentation by generators and relations) what $D$ and $\mathcal O_D$ are: ""Fix two primes $p$ and $q$, and let $\mathcal O_D$ be a maximal order in the quaternion algebra $D$ over $\mathbb Q$ ramified at $p$ and $q$, and split everywhere else (including at infinity).
Let $\mathcal O_D^1$ denote the multiplicative group of norm one elements in $\mathcal O_D$.Since $D \otimes_{\mathbb Q} \mathbb R \cong M_2(\mathbb R)$..."" My guess is the construction of $D$ begins with the ring $R$ of quaternions over $\mathbb Q$ $$ $:=\mathbb Q[i,j,k]/(i^2=j^2=k^2=ijk=-1)$$
and then I don't know what to do the make this ramified at $p,q$ (I know that means when we mod out by say $p$, we get a field or something) and unramified elsewhere. And then what is $\mathcal O_D$?","['abstract-algebra', 'algebraic-number-theory']"
1467860,"how many permutations of {1,2,...,9}","How many permutations of {1,2,…,9} are there such that 1 does not immediately precede 2, 2 does not immediately precede 3, and so forth up to 8 not immediately preceding 9? One obvious example of such a permutation might be 987654321, but there are many others, such as 132465879 or 351724698.","['discrete-mathematics', 'combinatorics', 'permutations']"
1467895,Construct a Lyapunov Function for the system,"Construct a Lyapunov Function in order to show that the system \begin{align}\frac{dx}{dt}&=x(y^2 +1) +y \\ \frac{dy}{dt} &= x^2y +x\end{align} has no closed orbits (limit cycle) and hence no periodic solutions. I have absolutely no experience in constructing Lyapunov functions. Can anyone please help guide me with this? I know the conditions that the Lyapunov function $L(x,y)$ must satisfy, but I do not know how to ""create"" the function $L$.","['stability-in-odes', 'dynamical-systems', 'ordinary-differential-equations']"
1467915,Converse of Cauchy Integral Formula,"The Cauchy Integral Formula for a disk is stated as follows: Let  $f$: D $\to \mathbb C$ and $ z_0\in D$ If $f$ is analytic, then for every $ r\gt0$ with $\overline{B_r(z_0)} \subset D$ we have:
$$f(z)=\frac{1}{2\pi i}\int_{\partial B_r(z_0)}\frac{f(w)}{w-z}dw$$ Is the converse true? That is, are all functions that satisfy this integral equation, automatically analytic? Or is there some function that satisfies this relation, but is not analytic?",['complex-analysis']
1467916,Proving that a differential equation has unique solution.,"Let $P,Q,f:[-1,1]\to\mathbb{R}$ continuous and $a,b\in\mathbb{R}$. Then I want to prove that the IVP $$\begin{cases} u''(x)+P(x)u'(x)+Q(x)u(x)=f(x)\\u(0)=a,\qquad u'(0)=b\end{cases}$$ has a unique solution in a neighborhood of x=0. To this end I have to show that the function $F(x,y,t)$ is lipschitz in the first variables and the constant independent of the parameter $t$. (This comes when this problem is converted to solve the integral equation and invoke the condition that the operator $\Phi(x)(t)=x_0 + \int_0^tF(x(s),s)ds$ has only one fixed point and the use the Banach fixed point theorem) So I chose $F(x,y,t)=f(x)-P(x)-Q(x)$ then: $$|F(x,y,t)-F(u,v,t)|=|(f(x)-f(u))+(P(u)-P(x))+(Q(u)-Q(x))|$$ Now, by continuity of $f,P,Q$ in a compact set we have that they are uniformly continuous so we pick $\delta = \{ \delta_1,\delta_2, \delta_3 \}$ so if $|x-y|<\delta$ we get $$|F(x,y,t)-F(u,v,t)|< \epsilon<\epsilon |x-y|$$ but the thing is that I don't know how to extend this property to all $x,y \in [-1,1]$ Can someone help me to fix this problem or provide another way to prove this Lipschitz condition ?  because I don't know other way to proceed. Thanks a lot in advance.","['real-analysis', 'ordinary-differential-equations']"
1467918,Finding Sylow 2-subgroups of the dihedral group $D_n$,"I am trying to describe the Sylow $2$-subgroups of an arbitrary dihedral group $D_n$ of order $2n$. In the case that $n$ is odd, $2$ is the highest power dividing $2n$, so that all Sylow $2$-subgroups have order $2$, and it is fairly easy to describe them. However, if $n$ isn't odd, we may factor a power of $2$ out and write $|D_n|=2^{k}m$ for some odd integer $m$. There is a proof that there exist precisely $m$ Sylow $2$-subgroups, but it does not provide an explicit description of such subgroups in the case $n$ is odd. Additionally, someone has asked a similar question in the past, and they claim to give a description of the Sylow $2$-subroups in the case $n$ is odd, but I can not find a source or an explanation. The question is here . Can anyone provide a description of how one may determine precisely the Sylow $2$-subgroups for the case $n$ is odd? Thank you.","['abstract-algebra', 'sylow-theory', 'dihedral-groups', 'finite-groups']"
1467942,Nonabelian group of order $pq $,"I just showed that if $G $ is a nonabelian group of order $pq $, $p <q $, then it has a non normal subgroup $K $ of index $q $. But now I want to show that $G $ is isomorphic to a subgroup of the normalizer in $S_q $ of the cyclic group generated by the cycle $(1~2~\cdots~q) $. I think I should let $G $ act on left cosets of $K $, but I don't see what to do next.","['abstract-algebra', 'group-theory', 'group-actions']"
1467961,The Remainder of $\frac{2000!}{5^{397}}$ (Just Checking my theory),"The remainder of $\frac{2000!}{5^{397}}$ This is a question from my homework. The remainder of $\frac{2000!}{5^{397}}$ My answer is there is no remainder. Solution: There are 400 numbers that can be divisible by 5 between 2000 and 1. So all three hundred and ninety seven 5's will be used up to cancel 397 numbers out of those 400 numbers. Therefore, there is no remainder. For example, consider $\frac{10!}{2^{5}}$ There are 5 numbers that can be divisible by 2 between 10 and 1. $\frac{10!}{2^{5}}=\frac{10\times9\times8\times7\times6\times5\times4\times3\times2\times1}{2\times2\times2\times2\times2}$ Then all you left with ${5\times9\times4\times7\times3\times5\times2\times3\times1\times1}$ So is my explanation right?","['number-theory', 'discrete-mathematics']"
1467964,Is there a term for two subsets whose intersection is {0}?,"In linear algebra I've just recently learned about the ""direct sum"", which can be defined as the sum of two vector spaces whose intersection is the null vector. Basically, I'm wondering if there's a formal term in abstract algebra to define algebraic substructures whose intersection is the identity element, as it seems like it'd be a, in the case of vector spaces, useful way to differentiate between subspaces that can be directly summed and subspaces that can't be. I'm specifically asking this because algebraic substructures whose intersection is the identity element seem like they could have some interesting interacting properties that differ from the interacting properties of any two substructures (and that the term disjoint wouldn't work in the case of any algebraic substructures).","['vector-spaces', 'linear-algebra', 'terminology']"
1467981,second order differential equation to hypergeometric equation,I know how to transform a general second order differential equation of the form $$\frac{d^2w}{dz^2} + \left(\frac{A}{z-\xi}+\frac{B}{z-\eta}\right)\frac{dw}{dz} + \frac{1}{z-\xi}\frac{1}{z-\eta}\left(\frac{D}{z-\xi}+\frac{E}{z-\eta}\right)w=0$$ into a hypergeometric equation. But now I have to solve $$\frac{d^2w}{dz^2} + \left(\frac{A}{z-\xi}+\frac{B}{z-\eta}\right)\frac{dw}{dz} + \frac{1}{z-\xi}\frac{1}{z-\eta}\left(\frac{D}{z-\xi}+\frac{E}{z-\eta}+C\right)w=0$$ in terms of hypergeometric functions and I can't seem to find the change of variables adequate to obtain an equation like the first one. I'm sure I'm missing something very simple here.,"['hypergeometric-function', 'ordinary-differential-equations']"
1467983,Show that the Cantor set is nowhere dense,"I want to prove that the cantor set is nowhere dense. First, a subset $A$ of $\mathbb{R}$ is said to be nowhere dense provided that for every open set $\mathcal{O}$ has an open subset that is disjoint from $A$. Proof: Since the Cantor set is closed, then the closure of the Cantor set is the Cantor set. Then, to prove that the Cantor set is nowhere dense, it is enough to show that the interior is empty. 
Observe that for a subset $A$ of a topological space $X$, the interior of $A$ is defined as the union of all open sets contained in $A$. Let $A = C$, the Cantor set and $X = \mathbb{R}$,
notice that $C = \bigcap_{k\in\mathbb{N}}C_k$, where each $C_k$ is closed. Moreover, we have
$$\forall k\in \mathbb{N} \quad C_k = \bigsqcup_{k\in\mathbb{N}}F_k$$ where each $F_k$ is the disjoint union of $2^k$ closed intervals, each of length $1/3^k$. We thus conclude that $C$ dont contain any open sets and thus
$$\text{int}(C) = \emptyset.$$ Is this proof correct?","['lebesgue-measure', 'cantor-set', 'real-analysis', 'measure-theory']"
1468016,Convolution - Difference of two random variables with different distributions,"This is a homework problem, but it isn't me looking for an easy way out. I've been thinking about this problem for a while now and even went to my professor's office hours and still don't quite understand it. Question: Let $X \sim Exp(1)$ and $Y \sim Unif[0,1]$ be two independent random variables. Find the PDF of $|X-Y|$ by using convolution. So, the very first thing I did was define $Z = |X-Y|$. Usually, when I deal with problems like this and want to find the PDF of a sum (difference), I find the CDF of $Z$ and then differentiate to get the PDF of $Z$. 
\begin{align*}
F_Z(z) &= P(Z \leq z) = P(|X-Y| \leq z)\\ &= P(-z \leq |X-Y| \leq z)\\&= P(X-Y \leq z) - P(X-Y \leq -z)\\
&=F_{X-Y}(z) - F_{X-Y}(-z)
\end{align*}
So, this is the CDF of $Z=|X-Y|$. If i differentiate it, then the F's (CDF's) simply spit out f's (PDF's) and by the chain rule the second CDF would produce a negative. Altogether, this means:
\begin{align*}
f_Z(z) = f_{X-Y}(z) + f_{X-Y}(-z)
\end{align*}
Okay, now that's all fine and dandy, but now I want to explicitly write out the distribution functions in terms of how they are defined over particular intervals. I think this is where convolution comes into play. My game plan was to solve for the two separate pdf's by computing two convolutions. Because $X$ is distributed exponentially, I know it must take on a positive value. Because $Y$ is uniform on $[0,1]$ I know we are only considering the values $[0,1]$ and not all positive values. So, this is where I start getting a little ""bewildered"", haha. I have this written down so far:
\begin{align*}
&f_{X-Y}(z) &= \int_{-\infty}^{\infty}{f_X(x)f_Y(x-z)dx}\\
&f_{X-Y}(-z) &= \int_{-\infty}^{\infty}{f_X(x)f_Y(x+z)dx}
\end{align*} Does this set-up make sense? I obviously have to change the limits of integration but that is the part that confuses me the most. How can I derive the limits of integration on my own? Thank you!","['probability-theory', 'probability', 'random-variables', 'convolution']"
1468022,Show that sup$AB$=(sup$A$)(sup$B$),"Where $AB$ is the product of the sets and $A,B \in \mathbb{R^+}$. Since $A,B$ are bounded above sup $A$ and sup $B$ exist. Let $\alpha = $ sup $A$ and $\beta = $ sup $B$. This implies $\forall a \in A$ and $\forall b \in B$ $a \leq \alpha$ and $b \leq \beta$. Then $ab \leq \alpha\beta$ because $a,b > 0$. Thus $ab$ is bounded above and sup $AB$ exists and sup $AB \leq \alpha\beta$. \
    We now show sup $AB \geq \alpha\beta$. \
    Let $\varepsilon > 0$ then $\exists a \in A$ s.t. $\alpha - \varepsilon < a \leq \alpha$ and $\exists b \in B$ s.t. $\beta - \varepsilon < b \leq \beta$. So:
    \begin{equation*}
      (\alpha-\varepsilon)(\beta-\varepsilon) < ab \leq \alpha\beta \text{ since } a,b,\varepsilon > 0
    \end{equation*}
    \begin{equation*}
      = \alpha\beta-\varepsilon(\alpha+\beta-\varepsilon) < ab \leq \alpha\beta
    \end{equation*} I spoke with my professor today about this and he suggested I show that $\varepsilon$ is sufficiently small to proceed. I'm not sure exactly how to write this detail. EDIT: I was meant to show what $\varepsilon$ was bounded by to proceed. The proof below realizes this idea. Feedback is welcome and appreciated. Since $A,B$ are bounded above sup $A$ and sup $B$ exist. Let $\alpha = $ sup $A$ and $\beta = $ sup $B$. This implies $\forall a \in A$ and $\forall b \in B$ $a \leq \alpha$ and $b \leq \beta$. Then $ab \leq \alpha\beta$ because $a,b > 0$. Thus $ab$ is bounded above, sup $AB$ exists and sup $AB \leq \alpha\beta$.
    Let $\varepsilon > 0$ then $\exists a \in A$ s.t. $\alpha - \varepsilon < a \leq \alpha$ and $\exists b \in B$ s.t. $\beta - \varepsilon < b \leq \beta$. So:
    \begin{equation*}
      (\alpha-\varepsilon)(\beta-\varepsilon) < ab \leq \alpha\beta
    \end{equation*}
    \begin{equation*}
      = \alpha\beta-(\varepsilon\alpha+\varepsilon\beta-\varepsilon^2) < ab \leq \alpha\beta
    \end{equation*}
    Since $ab$ is bounded above by $\alpha\beta$ we have $ab \leq \text{ sup}(AB)$. We let $\varepsilon' = \varepsilon\alpha+\varepsilon\beta-\varepsilon^2 > 0 $ so $\forall(0 < \varepsilon' < \alpha+\beta)$ we have $\alpha\beta-\varepsilon'< ab < \text{ sup}(AB) \implies \alpha\beta \leq \text{ sup}(AB) + \varepsilon' \implies \alpha\beta \leq \text{ sup}(AB)$ by ``elbow room''.","['proof-verification', 'real-analysis', 'proof-writing', 'supremum-and-infimum']"
1468027,How to find $\lim_{x \to 7} \frac{x-7}{\sqrt{x+2}-3}$?,"I'm totally at a loss for this... someone please help! $$\lim_{x \to 7} \frac{x-7}{\sqrt{x+2}-3}$$ I've tried multiplying by the conjugate, but after doing that I couldn't find a way to cancel out the $x-7$ still (the only thing making the limit not work). Edit: Thank you all so much! I made a simple math error when I multiplied by the conjugate...","['limits-without-lhopital', 'calculus', 'limits']"
1468064,Determinant of transpose intuitive proof,"We are using Artin's Algebra book for our Linear Algebra course. In Artin, $\operatorname{det}(A^T) = \operatorname{det} (A)$ is proved using elementary matrices and invertibility. All of us feel that there should be a 'deeper' or a more fundamental or a more intuitive proof without using elementary matrices or invertibility. The one our professor came up with used linear transformations between tensor algebras, wedges and exterior algebras which we do not understand. Are there any other proofs for $\operatorname{det}(A^T) = \operatorname{det} (A)$ ? Edit : Also, is there a geometric proof? For the $2\times2$ case at least?","['transpose', 'matrices', 'determinant', 'linear-algebra', 'intuition']"
1468080,Unions and intersections: $(A \cup B = A ∪ C) \land (A \cap B = A ∩ C) \implies B = C.$,"Prove or give a counterexample: $$(A ∪ B = A ∪ C) \land (A ∩ B = A ∩ C) \implies B = C.$$ I think this is true, but I am not sure how to show it. I don't know if there are any manipulations with unions and intersections that allows me to move things around. Thanks in advance for any hints.",['elementary-set-theory']
1468123,Extending functions to homeomorphism,"Is there a homeomorphism $f:(0,1) \to \mathbb{R}$ such that $f$ (co)restricts to a homeomorphism $f:(0,1)\cap \mathbb{Q} \to \mathbb{Q}$? I am a bit rusty in general topology, but I think that $\mathbb{Q} \cong (0,1) \cap \mathbb{Q}$ and $ \mathbb{R}-\mathbb{Q} \cong (0,1) - \mathbb{Q}$. So there wouldn't be any easy contradiction. So is there another strategy or a counterexample to (dis)prove the statement? More generally, given a space $X$ and $Y,Z\subset X$ such that $|X|=|Z|$, is there a homeo sending $Y$ to $Z$? Of course it is false in general (e.g $Y$ has some topological property that $Z$ hasn't). But is there some conditions on $Y$ and $Z$ (and $X$?) such that there is such homeomorphisms ?","['continuity', 'general-topology']"
1468128,Square of hockey stick identity: $\sum_{i=r}^n{i \choose r}^2$,"Evaluate $\sum_{i=r}^n{i \choose r}^2$ where $n,r\in \mathbb{N},n>r$. This looks like the hockey stick identity but I can't find a way to evaluate it without a computer. Can someone help me out?","['summation', 'binomial-coefficients', 'combinatorics', 'contest-math']"
1468129,Contour integration of log over polynomial with fractional power,"I've stumbled upon one integral which is rather challenging because of the fractional power of t: \begin{equation}\int_0^\infty \log(1+tx)t^{-p-1}dt,
\end{equation}
 where $p\in(0,1)$ and $x>0$. Any idea how to approach it using contour integration? Update: to add some interesting background, it turns out that this integral is used to express a very simple expression
\begin{equation}
x^p = \frac{1}{\pi}p \sin(p\pi)\int_0^\infty \log(1+tx)t^{-p-1}dt
\end{equation}","['improper-integrals', 'definite-integrals', 'contour-integration', 'integration', 'complex-analysis']"
1468141,"Brownian motion, quadratic variation, existence of partitions?","Let $A_t$ be a standard Brownian motion. Where can I find a reference to/can anybody supply a proof of the fact that with probability $1$ there exists a sequence of partitions $\{t_{k, n} : k = 1, \dots, k_n\}$ $$0 = t_{0, n} < t_{1, n} < \dots < t_{k_n, n} = 1,$$with$$\lim_{n \to \infty} \max \{t_{j, n} - t_{j - 1, n} : j = 1, \dots, k_n\} = 0$$and$$\liminf_{ n \to \infty} \sum_{j=1}^{k_n} (A(t_{j, n}) - A(t_{j-1, n}))^2 > 1?$$All the sources I have been looking at have just been assuming the existence of this sequence? It's not very clear to me how this is clear. Thanks in advance!","['probability-theory', 'brownian-motion', 'probability', 'real-analysis']"
1468198,Two topological groups $\mathrm{O}(n)$ (orthogonal group) and $\mathrm{SO}(n)\times \mathbb{Z}_2$ [duplicate],"This question already has an answer here : Are $SO(n)\times Z_2$ and $O(n)$ isomorphic as topological groups? (1 answer) Closed 2 years ago . Problem. (Basic topology (M.A.Armstrong) Exercise 16 in chapter 4.3) (1) Prove that $\mathrm{O}(n)$ is homeomorphic to $\mathrm{SO}(n)\times \mathbb{Z}_2$. (2) Are these two isomorphic as topological groups? ($\mathrm{O}(n)$ : Orthogonal group , $\mathrm{SO}(n)$ : Special orthogonal group) My attempt for (1) : Let's pick any element $C$ from $\mathrm{O}(n)-\mathrm{SO}(n)$, and let \begin{aligned}
&f:\mathrm{SO}(n)\to \mathrm{SO}(n) ; \; f(A)=A\\
&g:\mathrm{O}(n)-\mathrm{SO}(n)\to \mathrm{SO}(n) ; \; g(A)= CA
\end{aligned} Then $f$ and $g$ are homeomorphisms. Since $\mathrm{SO}(n)$ is compact, $g^{-1} (\mathrm{SO}(n))=\mathrm{O}(n)-\mathrm{SO}(n)$ is also compact. So, they are closed in the subspace topology on $\mathrm{O}(n)$. Thus, by the glueing lemma, the function
$$\varphi:\mathrm{O}(n)\to \mathrm{SO}(n)\times \mathbb{Z}_2; \; \varphi(A)=
\begin{cases}
(f(A), 0)\quad&(\text{when }A\in \mathrm{SO}(n))\\
(g(A), 1)&(\text{otherwise})
\end{cases}$$
becomes continuous. We can easily confirm that $\varphi$ is bijective and $\varphi^{-1}$ is continuous. Questions : (1) I'm not sure I'm going in the right direction (in proving (1)). I used glueing lemma to justifying continuousness of the function $\varphi$, but I doubt whether I'm using that lemma in the right place. (2) I tried to prove that two groups are NOT isomorphic, but I can't find any key for that. I tried to compare orders of elements in two groups, but I couldn't find some good elements to compare... Is there any simple way to check whether two groups are isomorphic? Thanks.","['group-isomorphism', 'algebraic-topology', 'general-topology']"
1468211,Does $|x^*|=|x|$ in a star ring with an absolute value?,"Let $R$ be a star ring with an absolute value . Is it true that $|x^*|=|x|$ for all $x\in R$? Here a star ring is a ring with a function $*:R\to R$ called conjugation such that $(x+y)^*=x^*+y^*$ $(xy)^*=y^*x^*$ $x^{**}=x,$ and an absolute value is a function $|\cdot|:R\to\Bbb R$ such that $|x|=0\iff x=0$ $|x-y|\le|x|+|y|$ $|xy|=|x||y|.$ Obviously it is true for the trivial conjugation $x^*=x$, and it is also true for $\Bbb C$ and matrix rings over $\Bbb R$ and $\Bbb C$ with transposition and any of the various common matrix norms, so I wonder if it is true in general.","['ring-theory', 'matrices', 'noncommutative-algebra', 'abstract-algebra', 'absolute-value']"
1468276,"Prove: If $f:A\to B, C\subseteq A, D\subseteq B$, then $f(C) \subseteq D \iff C \subseteq f^{-1}(D)$","Prove: If $f:A\to B, C\subseteq A, D\subseteq B$, then $f(C) \subseteq D \iff C \subseteq f^{-1}(D)$ My attempt: Suppose $f(C) \subseteq D$. If $x\in C$, then $f(x)\in f(C)$ and certainly $f(x) \in D$ since $f(C)\subseteq D$. But whenever $f(x)\in D$, we have that $x\in f^{-1}(D)$. So $C\subseteq f^{-1}(D)$. Conversely, suppose $C\subseteq f^{-1}(D)$. Given that $C \subseteq f^{-1}(D)$, if $x\in f^{-1}(D)$, then certainly $f(x)\in d$. Hence $C\subseteq f^{-1}(D)$. Is there any flaw with my proof? Also, when is the equality part of this proof satisfied and why?","['elementary-set-theory', 'functions']"
1468300,"Assume $A,B,C,D$ are pairwise independent events. Decide if $A\cap B$ and $B\cap D$ are independent","Assume A,B,C,D, are pairwise independent events. Decide if $(A \cap B)$ and $(B \cap D)$ are independent events? Then repeat this assuming the four events are mutually independent. Well, what I'm thinking is 
$P(A \cap B) = P(A) \cdot P(B)
\\P(A \cap C) = P(A) \cdot P(C)
\\P(A \cap D) = P(A) \cdot P(D)
\\P(B \cap C) = P(B) \cdot P(C)
$...and soo on
, which is what makes it pairwise independent, so assuming this is pairwise, 
then that means $(A \cap B)$ and $(B \cap D)$ are also independent
because $P(A \cap B) = P(A) \cdot P(B)
\\P(B \cap D) = P(B) \cdot P(D)
$......this is correct to say they are independent?? then I dont understand to assume the 4 events are mutually exclusive? does that mean $P[(A \cap B) \cap (B \cap D)] = P(A) \cdot P(B) \cdot P(D)$?? Which does not make them independent because of B? I am not too sure. I am confused and clarification is much appreciated. Any help IS MUCH APPRECIATED TOO.","['probability-theory', 'discrete-mathematics', 'probability-limit-theorems', 'independence', 'probability']"
1468328,Area and circumference of a square?,"I've encountered this weird question: Show that the derivative of the area of a circle with respect to its radius is equal to its circumference. Show that this relationship holds between the area and circumference of a square, too. Explain what you mean by the radius of a square. I don't have any trouble with the first part, $A=\pi r^2$,  $A'= 2\pi r$ and $c = 2\pi r$.
Now for the square, my speculation was that the ""radius"" is half of the diagonal ($\frac{r\sqrt 2}{2}$) but it's derivative is not equal to the perimeter (or ""circumference""). Something that makes sense in terms of the numbers is $A$ equal the whole diagonal ($r \sqrt 2)^2$. But I don't know if it means anything on a geometry basis. What are your thoughts on this? Thanks!","['geometry', 'calculus']"
1468345,Lebesgue Measurable Sets Are Translation Invariant,"I'd like a few proofs that translation of Lebesgue measurable sets are Lebesgue Measurable. As an example, and to add to the collection, I've included my own proof of the statement as an answer. Let $\mathfrak{M}(\mu)$ be the space of $\mu$-measurable sets as defined in Baby Rudin as the countable union of things in $\mathfrak{M}_F(\mu)$, finitely $\mu$-measurable sets. Any and all methods of proof appreciated. I suppose there's a more elegant way to prove this statement.","['lebesgue-measure', 'measure-theory', 'real-analysis', 'analysis', 'measurable-sets']"
1468385,Geometric meaning of normal in group theory?,"How should one think about normal subgroups intuitively? Is there any useful geometric intuition behind them? For instance, I remember reading somewhere that normal subgroups are like bundles in some sense.","['group-theory', 'normal-subgroups']"
1468394,"Prove that $\int_0^\infty \int_0^\infty e^{-xy}(\sin x)\,dy\,dx=\int_0^{\infty}\int_0^{\infty}e^{-xy}(\sin x)\,dx\,dy$.","By theorem. Let $f(x,y)$ be continuous on $[a,\infty) \times [c,\infty)$, and assume that the integrals $\int_a^{\infty}|f(x,y)|\,dx$ and $\int_c^\infty |f(x,y)|\,dy$ converge uniformly in every compact interval $[c,d]$ and $[a,b]$,respectively. Then $$\int_c^\infty \int_a^\infty f(x,y)\,dx\,dy=\int_a^\infty \int_c^\infty f(x,y) \, dy \, dx.$$ I have $f(x,y)=e^{-xy}\sin x$ I want to prove that $$\int_0^{\infty}\int_0^{\infty}e^{-xy}(\sin x) \,dy \, dx = \int_0^\infty \int_0^\infty e^{-xy}(\sin x)\,dx\,dy.$$ Question : 1. How to prove $f(x,y)=e^{-xy}\sin x$ is continuous on $[0,\infty) \times [0,\infty)$. How to prove $\int_0^\infty e^{-xy}(\sin x)\,dx$ converge uniformly on $[0,d]$ and $\int_0^\infty e^{-xy}(\sin x)\,dy$ converge uniformly on $[0,b]$. I know that the definition says $f_n$ converges uniformly to $f$ if given $\forall \varepsilon > 0$, $\forall n \geq N$, such that $|f_n(x) - f(x)| < \varepsilon, \forall n \geq N$. I would be really happy if someone could help me. Thank you.","['calculus', 'real-analysis', 'definite-integrals', 'uniform-convergence', 'integration']"
1468404,Expected win in a selection game,"You've got a game where you have two 5x4 boards. In each board there are 20 hidden prizes from 1 to 20 (each board has all 20 prizes). You have 8 moves. In each move you choose a board and a unrevealed cell in that board. Then you get the prize that was hidden there and a cell in the other board is revealed, showing a prize that you'll be no longer able to get in that board. That way, there's always the same number of revealed cells in each board. Obviously the best strategy is to always pick a cell in the board where the lowest sum of prizes had been revealed. My question, though, is: What's the expected win in this game? I tried to think about creating a random variable $X_n$ that gives the win in a board after $n$ selections if you choose that board. And $Y_n$ the variable that gives the win following this strategy.
Then I'd say something like $E[Y_n]=\max(X_n,X'_n)$","['probability', 'expectation']"
