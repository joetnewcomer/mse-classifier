question_id,title,body,tags
2922714,First generalization of the inverse function theorem Q.10 section 1.3 in Allan Pollack and Guillemin(1).,"Part of Q.10 section 1.3 in  Allan Pollack and Guillemin is the following: ""Generalization of the inverse function theorem.let $f:X \rightarrow Y$ be a smooth map that is 1-1 on a compact submanifold Z of X. Suppose that for all $x \in Z$ , $$df_{x}: T_{x}(X) \rightarrow T_{f(x)}(Y) ,$$ is an isomorphism. then $f$ maps $Z$ diffeomorphically onto $f(Z)$ . why?"" The inverse function theorem that is stated in Allan Pollack differential Topology before this question is: Suppose that $f:X \rightarrow Y$ is a smooth map whose derivative $df_{x}$ at the point $x$ is an isomorphism. Then $f$ is a local diffeomorphism at $x$ . Does the answer is ""by the inverse function theorm""? am I correct?","['general-topology', 'differential-topology', 'differential-geometry']"
2922717,Can every finite group be embedded in $\text{Homeo}(\mathbb{R})$?,"Let $\text{Homeo}(\mathbb{R})$ denote the group of self-homemorphisms of $\mathbb{R}$. If $G$ is a finite group, is $G$ isomorphic to a subgroup of $\text{Homeo}(\mathbb{R})$? (Edit: this was previous denoted $\mathrm{Aut}(\mathbb{R})$, so in the comments, $\mathrm{Aut}(\mathbb{R})$ has to be interpreted as $\text{Homeo}(\mathbb{R})$.)","['general-topology', 'finite-groups', 'group-theory']"
2922748,Induction proof of a series,"Suppose we have the series 
$$f(n) = \sum_{i=1}^n \frac{2i-1}{i^4 - 2 i^3 + 3 i^2 - 2 i + 2}.$$
As a hint it was said that this series ""telescopes"". I observed the pattern to be $f(n)=\frac{n^2}{n^2 +1}$. I wish to prove this via induction. The base case holds, since $f(1)=\frac{1}{2}$ which comes out of both the definition of $f(n)$ and my proposed formula. Now I wish to prove that for some arbitrary $k$ we assume $f(k)=\frac{k^2}{k^2+1}$, then I wish to prove that $f(k+1)=\frac{(k+1)^2}{(k+1)^2+1} (=\frac{k^2 +2k +1}{k^2 +2k +2})$. I wanted to start out by noticing: 
$$f(k+1) = \sum_{i=1}^{k+1} \frac{2i-1}{i^4 - 2 i^3 + 3 i^2 - 2 i + 2}= \\f (k)+ \frac{2(k+1)-1}{(k+1)^4 - 2 (k+1)^3 + 3 (k+1)^2 - 2 (k+1) + 2}$$
This eventually simplifies to
$$ f(n+1)= \frac{k^2}{k^2 +1} + \frac{2k+1}{k^4 +2k^3+3k^2+2k+2}$$","['fractions', 'induction', 'sequences-and-series']"
2922766,For which $n\in \mathbb N$ does $n^n$ end with a $3$ in its decimal form?,"For which $n\in \mathbb N$ does $n^n$ end with a $3$ in its decimal
  form? I didn't really know where to go from here, but I thought I might be able to use that
$n^n \equiv 3 \text{ (mod } 10)$ , $n^n \equiv 3 \text{ (mod } 5)$ and $n^n \equiv 1 \text{ (mod } 2)$. Since the $gcd(2,5)=1$ I thought I might be able to do something with the Chinese remainder theorem, but so far I'm not sure how. I'd prefer a hint over a full answer :) Thank you in advance!",['number-theory']
2922817,Why is the set of continous paths of a browian motion not measurable?,"Øksendal states in his book ""stochastic differential equations"" ( Defintion 2.2.1 iii), p.13 ) that the set $H = \{\ \omega \mid t → B_t (\omega)\ \text{is continuous}\
\}$ is not measurable with respect to the Borel $\sigma$ -algebra $\mathcal{B}$ on $(\mathbb{R}^n)^{[0,\infty)}$ (...) ( $H$ involves an uncountable number of $t$ 's), where $B_t$ is a brownian motion and we identify $\omega$ with the path of $B_t(\omega)$ . Unfortunately I don't know much about $\mathcal{B}((\mathbb{R}^n)^{[0,\infty)})$ aside its defintion. According to this question a set $A$ is measurable iff there exists $J\subseteq \mathbb{R}$ with $|J|≤\aleph_0$ and $B\in \mathcal{B}(\mathbb{R}^J)$ such that $A=B \times \mathbb{R}^{\mathbb{R}\setminus J}=\{f \in \mathbb{R}^\mathbb{R} \colon  \ (f(j) \colon \ t \in J) \in B\}$ . I would appreciate it, if someone could provide me a reference for the statement above. Edit: If I am not mistaken the product $\sigma$ -algebra $\mathcal{B}((\mathbb{R}^n))^{[0,\infty)}$ is a true subset of the Borel- $\sigma$ -algebra $\mathcal{B}((\mathbb{R}^n)^{[0,\infty)})$ and thus the statement above should be correct for the product, but not for the Borel algebra. Prior to the quote Øksendal writes ( after Definition 2.1.4, p. 10 ): $\mathcal{B}$ [the algebra generated by cylindrical sets] is the same as the Borel $\sigma$ -algebra on $\tilde{\Omega}$ [ $=(\mathbb{R}^n)^T$ ] ­ if $T = [0,\infty)$ and $\tilde{\Omega}$ ­ is given
  the product topology This should be false or am I missing something?","['measure-theory', 'stochastic-analysis', 'borel-sets', 'brownian-motion', 'stochastic-calculus']"
2922875,Degree of Map between Spheres,"Let $f: S^n \to S^n$ be a continuous morphism between $n$-spheres. One knows (for example using Freudenthal's suspension thm) that for all $n \in \mathbb{N}$ holds $\pi_n(S^n) \cong \mathbb{Z}$. Therefore we can define the degree $deg(f) \in \mathbb{Z}$ of $f$ in following unique way such the diagram below commutates: $$
\require{AMScd}
\begin{CD}
\pi_n(S^n)  @>{f_*}  >> \pi_n(S^n)   \\
@VV \cong V  @VV \cong V   \\
\mathbb{Z} @>{\cdot deg(f)}>> \mathbb{Z} 
\end{CD}
$$ Remark: the isomorphisms $\pi_n(S^n) \cong \mathbb{Z}$ are choosen compatible in the way that the fixed generator of $i_n \in \pi_n(S^n)$ is wlog in the left and right vertical maps is maped to $1$. Therefore the map $\mathbb{Z}    \xrightarrow{\text{deg(f)}}  \mathbb{Z} $
is given as multiplication map $z \to deg(f) \cdot z$ Consider from now on as $f_n$ the concatenation of canonical maps $$f_n: S^n \xrightarrow{\text{p}} \mathbb{PR}^n \xrightarrow{\text{q}} \mathbb{PR}^n/\mathbb{PR}^{n-1} \cong S^n$$ Here $p$ comes from double cover $S^n \to \mathbb{PR}^n$ and $q$ is the quotient arising from the CW / pushout structure of $\mathbb{PR}^n \cong \mathbb{PR}^{n-1} \cup_j D^n$ where $j: S^{n-1} \to \mathbb{PR}^{n-1}$ is the attatching map (the same as $p$ but for lower power $n-1$). One can calculate using homology groups of $S^n$ and $\mathbb{PR}^n$ that \begin{equation}
   deg(f_n) =
   \begin{cases}
     2 &  \text{if n odd} \\
     0 & \ \text{if n even} 
   \end{cases}
\end{equation} My question is how one can visulize / understand intuitively that $deg(f_2) =0$ therefore that $f_2:S^2 \to S^2$ is null homotopic? If we consider the case $f_1: S^1 \to S^1$ then one can intuitively relize that $deg(f_1) =2$ since by construction of $f_n$ and the identification $\mathbb{PR}^2 = S^1 /(x \sim -x)$ the map $f_1$ makes $S^1$ to run two times around itself. But where is the the crux of the matter is why this argument fails for $f_2$? Here I have drawn (please don't critizise my drawing talent :) ) the situation for  n=1: But for $S^2$ it seems since $deg(f_2)=0$  that $f_2$ can be contracted to constant map. I suppose that this has do with the properties of boundary $S^1$ but I can’t really find an intuitive argument. Can anybody help me to visualize the intuition behind this phenomena?","['general-topology', 'algebraic-topology']"
2922876,"Good books to learn olympiad geometry,number theory, combinatorics and more","I want to start learning olympiad mathematics more seriously, and I would like to have advice on some good books or pdfs to learn with. I have background but not a big background. For example I know high school geometry (and in general high school mathematics) really well but in olympiad geometry (where creativity is really needed) I am not that good. I can solve a bit of the problems from the national math olympics in my home country but not problems from the IMO (though I can understand the solutions of the easier problems in the IMO, mostly easier geometry problems). Right now I want to focus mainly on geometry and number theory, and maybe some combinatoris. Are there any books that are really recommended for a beginner (not a beginner who starts from absolute scratch, but still a beginner). I heard about the book ""Euclidean geometry in mathematical olympiads"" written by Evan Chen but I understood that this book is advanced and a beginner should not start from that. Any good books to begin with in geometry, number theory, and combinatorics (and if you have anything else to recommend on - for example a good Algebra book to begin with when I'll start learning algebra - of course I would like to hear it as well). If you have any advice on math olympiad in general, or if you think I should learn something else first (for example if you think I should learn algebra before number theory) - please tell me. Thanks!","['contest-math', 'number-theory', 'geometry', 'reference-request', 'combinatorics']"
2922880,$\int_{1}^\infty\frac{\sin(x^2)}{x^p}dx$ for which p values does the integral converge in condition,"$$\int_1^\infty\frac{\sin(x^2)}{x^p} \, dx$$ 
for which p values does the integral converge in condition? and for which values does it converge absolutely? I managed to find the values of $p$ which will make the integral to converge absolutely , they are $p>1$, but i could not manage to solve for the condition values of $p.$ $$\int_1^\infty\frac{\sin(x^2)}{x^p} \, dx $$ assign $t=x^2$ you will get : 
$$\frac{1}{2}\int_1^\infty\frac{\sin(t)}{t^\frac{p+1}{2}} \, dt$$ $$\int_1^\infty \left|\frac{\sin(t)}{t^\frac{p+1}{2}}\,dt\right| \le \int_1^\infty\frac{1}{t^\frac{p+1}{2}}\,dt$$
hence if $\frac{p+1}{2}>1 \to p>1$ the integral converges. In the answers the value for the conditional convergence is for $0<p\le1$ can't understand why","['integration', 'calculus', 'real-analysis']"
2922881,How can I evaluate this complex integral $\int_{|z|=1}e^{\frac{1}{z}}\cos{\frac{1}{z}}dz$?,"I'm trying to evaluate the following complex integral using the residue method. $$\int_{|z|=1}e^{\frac{1}{z}}\cos{\frac{1}{z}}dz$$ The point $z_0=0$ seems to be a singularity. I'm not sure but I think it's also a non-removable one. I tried using the Taylor expansion of $e^x$ and $\cos{x}$ as that usually helps. $$e^{\frac{1}{z}}\cos{\frac{1}{z}}=(1+\frac{1}z+\frac{1}{2!z^2}+\frac{1}{3!z^3}+...)(1-\frac{1}{2!z^2}+\frac{1}{4!z^4}-...)\\=>e^{\frac{1}{z}}\cos{\frac{1}{z}}=(1+\frac{1}{z}+...)$$ It seems like the negative power terms are infinite showing that $z_0=0$ is no pole. If I'm correct, the coefficient of $1/z$, which is $1$, is the residue of the singularity and this leads to the result:$$ \int_{|z|=1}e^{\frac{1}{z}}\cos{\frac{1}{z}}dz=2\pi i$$ I don't think I've evaluated other integrals with non-removable singularities and I'm not sure about the whole process..","['complex-analysis', 'contour-integration', 'laurent-series']"
2922887,How to develop a method to know if my box can pass around a corner?,"[EDIT2] Following the help I got in the comments + answers I found $$\begin{align}
a &\leq \sqrt{H^2-b^2} \\[4pt]
a &\leq \sqrt{h^2-b^2}
\end{align}$$ as the answer with this process https://i.sstatic.net/Z6mwd.jpg I need to develop a method to know if the box can pass or not ] I need to find a method to know if I can turn my box to keep moving in the hallways, when I give $a$, $b$, $h$ and $H$ (in meter) can show if it will pass or not. For example $a=3, b=1.5, h=2.1, H=2.1$ I'm really stuck with that and I though that someone here could help me (if you want to do it with voice call or anything I can give you my Discord in private) I tried to draw a isosceles triangle with the side a of my box to calculate his height of the triangle but I'm stuck with the $h$ and $H$","['rectangles', 'trigonometry', 'linear-algebra']"
2922952,Finding a closed form $x_n$ for the recurrence relation $x_{n+2} = px_{n+1} + qx_n + r$,"Given a recurrence relation:
  $$
x_{n+2} = px_{n+1} + qx_n + r
$$
  Find the general term $x_n$ given initial conditions $x_1 = a$ and $x_2 = b$, where $a,b,p,q,r$ are some given numbers, $n \in \mathbb N$. Since this is a non-homogeneous linear recurrence relation i've started with solving for $x_n^h$ which is a solution for homogeneous relation: $$
x_{n+2} - px_{n+1} - qx_n = 0 \\
\lambda^2-p\lambda - q = 0
$$ I'm assuming here that two distinct roots $\lambda_{1,2}$ exist for this equation (single root case is handled similarly). So the general term is in the form: $$
x_n = C_1\lambda_1^{n-1}+C_2\lambda_2^{n-1}
$$ With the initial condition it's possible to find the values for $C_1$ and $C_2$: $$
C_1 + C_2 = a \\
C_1\lambda_1 + C_2\lambda_2 = b
$$ After solving the system of equation with respect to $C_1$ and $C_2$: $$
C_1 = \frac{b-a\lambda_2}{\lambda_1 - \lambda_2} \\
C_2 = \frac{b-a\lambda_1}{\lambda_2 - \lambda_1} \\
$$ Which eventually results in: $$
x_n^h = \frac{(a\lambda_2 - b)\lambda_1^{n-1} - (a\lambda_1-b)\lambda_2^{n-1}}{\lambda_2 - \lambda_1}
$$ Final solution consists of a sum of particular and homogeneous solutions, but that is where I got stuck. What is the way to find the particular solution for the given problem? I'm pretty new to such kind of problems so any details are very much appreciated. upd: Based on the technique in @rtybase answer here are my findings: $$
\begin{align}
x_1 &= a \\
x_2 &= b \\
x_3 &= pb - qa + r
\end{align}
$$ Writing the system for $c_1, c_2, c_3$: $$
\begin{align}
a &= c_1 + c_2 + c_3 \\
b &= c_1\lambda_1 + c_2\lambda_2 + c_3 \\
pb+qa+r &= c_1\lambda_1^2 + c_2\lambda_2^2 + c_3
\end{align}
$$ Now solving for the coefficients gives a huge formula. The answer to this problem suggests that: $$
x_n = \frac{(\lambda_2(a+\gamma) - b -\gamma)\lambda_1^{n-1} - (\lambda_1(a + \gamma) - (b-\gamma))\lambda_2^{n-1}}{\lambda_2 - \lambda_1} - \gamma
$$ Where: $$
\gamma = \frac{r}{p+q-1}
$$ Unfortunately I was not able to arrive at exactly the same result, but testing my solution (not posting since it's monstrously big) using SameQ in Mathematica with the given answer shows that they are equivalent. Those transformations are not very obvious to me, so i skipped them since the answer matches the given one (yet the symbolic expressions are different)","['algebra-precalculus', 'recurrence-relations']"
2922967,A conjecture on the Lyapunov equation,"Let $A\in\mathbb{R}^{n\times n}$ be a Hurwitz stable matrix (i.e., all the eigenvalues of $A$ have strictly negative real part). Let $X\in\mathbb{R}^{n\times n}$ be a positive semi-definite matrix of unit trace, that is $X\succeq 0$ s.t. $\mathrm{tr}(X)=1$ , and let $P$ be the positive semidefinite solution of the following Lyapunov equation $$
AP+PA^\top = -X.
$$ My question. Does there always exist a matrix $X\succeq 0$ with $\mathrm{tr}(X)=1$ such that the equality $$
\|P\|_2 = \frac{1}{-2\,\mathrm{tr}(A)}
$$ holds true, where $\|P\|_2$ denotes the 2-norm of matrix $P$ ? If $A+A^\top$ is negative semi-definite ( $A+A^\top\preceq0$ ), then it is easy to see that the answer is in the affirmative. In fact, in this case, picking $X=\frac{1}{2\mathrm{tr}(A)}(A+A^\top)$ , yields $P=\frac{1}{-2\mathrm{tr}(A)}I$ , which in turn clearly implies $\|P\|_2=\frac{1}{-2\,\mathrm{tr}(A)}$ . After running an extensive amount of numerical simulations, it seems that the answer should be in the affirmative also for the case $A+A^\top\not\preceq 0$ . However, proving the latter fact seems to be a daunting task. So, any help or suggestions to tackle this conjecture is very appreciated. Thanks a lot! Remark. (Condition $A+A^\top\preceq 0$ is not necessary) Consider the following $2\times 2$ matrix $$
A = \begin{bmatrix}-1 & \frac{\sqrt{3}+2}{2} \\ \frac{\sqrt{3}-2}{2} & 0 \end{bmatrix}.
$$ Matrix $A$ has two eigenvalues at $-0.5$ , whereas the eigenvalues of $A+A^\top$ are $-3$ and $1$ . Let us define $$
X = \begin{bmatrix}1 & 0 \\ 0 & 0 \end{bmatrix}, \quad P = \begin{bmatrix}\frac{1}{2} & 0 \\ 0 & -\frac{\sqrt{3}-2}{2(\sqrt{3}+2)} \end{bmatrix}\succ 0.
$$ It holds that $$
AP+PA^\top =-X,
$$ and $$\|P\|_2 = \frac{1}{2}=-\frac{1}{2\mathrm{tr}(A)}.$$","['eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'matrix-equations', 'positive-definite']"
2922995,Solution to differential equation $y'(x) = a * y(x)^2$,"first of all: I am not a mathematician. I am struggling since a few hours with a simple differential equation which I would like to solve to approximate the expectation curve for computer simulations I am doing. Recursive function: $$y[x+1] = y[x] - c * y[x]^2$$ If c is small, this can be approximated by the following differential equation: $$y'[x] = -c * y[x]^2$$ Which I do not manage to solve... Sorry for such a low-level question here and thanks :) EDIT: I know that $y$ at position $x$=0 equals 0.8.","['recursive-algorithms', 'ordinary-differential-equations']"
2923014,"truth value of ""if...then...""","From the truth table, when both $p$ and $q$ are true, then ""if $p$ then $q$"" is true.
However, this is a little weird as ""if $p$ then $q$"" is used to show the relationship between $p$ and $q$. If $q$ is independent of $p$, even both $q$ and $p$ are true, how is about the truth value of ""if $p$ then $q$""? For example, let $p$ and $q$ are unrelated and both are always true. We have a statement: If $1+1=2$, then Paris is the capital of France. Is this statement true or false? EDIT : From truth table, this statement is definitely true. However, if it is true, it seems that the basic property of $p\Rightarrow q$, the causal relationship , is lost. It also makes the definition ""$p$ is the sufficient condition of $q$"" weird, as obviously in my example, $p$ is definitely not a condition of $q$.","['elementary-set-theory', 'propositional-calculus', 'logic', 'logic-translation']"
2923057,Proof of an inequality using analytic geometry,"If $p,q,r$ are real numbers and $0<p<q<r$, then $$\frac pq +\frac qr +\frac rp >\frac qp +\frac rq +\frac pr$$ Is this a well-known inequality? My proof of it is based on analytic geometry: If you plot the points $P=(p,1/p)$, $Q=(q,1/q)$, $R=(r,1/r)$ in this order, you get the vertices of a triangle circumscribed by an equilateral hyperbola $xy=1$ entirely on the first quadrant (as all numbers $p,q,r$ are positive and because a line cannot intercept a conic in three points). The area of this triangle PQR can be given by the following formula: $$\frac 12 \begin {vmatrix} p & \frac 1p & 1 \\ q & \frac 1q & 1 \\ r & \frac 1r & 1 \\ \end {vmatrix}$$ And as these coordinates are written anticlockwise in this determinant, it has to be positive:
$$\begin {vmatrix} p & \frac 1p & 1 \\ q & \frac 1q & 1 \\ r & \frac 1r & 1 \\ \end {vmatrix}>0$$ From that we get $$\frac pq +\frac qr +\frac rp >\frac qp +\frac rq +\frac pr$$ Is this proof correct? Is there another, simpler proof for this inequality?","['analytic-geometry', 'inequality', 'proof-verification', 'proof-writing', 'algebra-precalculus']"
2923070,Associativity of the product of measurable spaces,"The product of two measurable spaces $(X_1,M_1)$, $(X_2,M_2)$ is defined to be $(X,M)$, with $X = X_1\times X_2$, cartesian product of $X_1$ and $X_2$ and $M = M_1 \otimes M_2$ sigma-algebra generated by the collection of rectangles $A\times B$ with $A \in M_1$ and $B \in M_2$. The definition is naturally generalized to the case of the product of $n$ spaces. Can someone give me an hint to the proof of: Let $(X_1,M_1)$, $(X_2,M_2)$ and $(X_3,M_3)$ be measurable spaces. Prove that $(M_1 \otimes M_2) \otimes M_3 = M_1 \otimes M_2 \otimes M_3$, if we identify $((x_1,x_2),x_3)$ with $(x_1,x_2,x_3)$. The fact that any rectangle $A \times B \times C$ belongs to $(M_1 \otimes M_2) \otimes M_3$ is obvious, so $M_1\otimes M_2\otimes M_3 \subseteq (M_1\otimes M_2)\otimes M_3$. But I have troubles proving formally that any set of the form $D\times C$, with $D \in M_1 \otimes M_2$ and $C \in M_3$, belongs also to $M_1\otimes M_2\otimes M_3$.",['measure-theory']
2923082,Sum of the square of a recursively defined function,"This problem is from a math competition from 1994. I have been having trouble working with this problem: Let $f(1) = 1, $ and $f(n + 1) = 2\sqrt{f(n)^2 + 1}$ for $n \geq 1$. If $N \geq 1$ is an integer, find $$\sum_{n = 1}^{N}f(n)^2.$$ I tried many things, and although I found some patterns, I couldn't really get anywhere. Some values, which might help, are listed below: $f(1) = 1$ $f(2) = 2\sqrt{2}$ $f(3) = 6$ $f(4) = 2\sqrt{37}$ $f(5) = 2\sqrt{149}$ Since the problem is so old, there is no solution provided.","['contest-math', 'discrete-mathematics', 'sequences-and-series', 'recreational-mathematics', 'algebra-precalculus']"
2923107,On Stirling Number,"Let $H(n,k)$ be the number of sequences $b_1,b_2, \ldots, b_n$ such: that the largest element is $k$, all numbers $1,2,\ldots,k$ do occur, and the first occurrence of $i$ occurs before the first occurence of $i+1$ for all $i \in \{1,2,\cdots, k-1\}$. My goal is to show  that $H(n,k)= S_{n,k}$ where $S_{n,k}$ denotes the Stirling number of the second kind. Here is my approach: I started by understanding how these sequences look like and I came up with the following: $H(2,1) = |\{11\}| =1 = S_{2,1}$ $H(2,2) = |\{12\}| =1 = S_{2,2}$ $H(3,2) = |\{112, 121,122\}| =3 = S_{3,2}$ I computed couple more to see whats going on. Here is my observation: I realized that $$H(3,2)=1+2(1) = H(2,1) + H(2,2)$$ and that quickly let me realize that $H(n,k)$ will satisfy the well known Stirling number of the second kind relation reccurence which is $$S_{n,k}= S_{n-1,k-1}+ kS_{n-1,k}.$$ Thus, I claim that $H(n,k)= S_{n,k}$. I tried to show this by induction but I am not show if this make sense: $$H_{n+1,k+1}=H_{n,k} + (k+1) H_{n,k+1}= S_{n,k} + (k+1) S_{n,k+1}= S_{n+1,k+1}$$ I figured this question is related to Express $F(n,k)$ through Stirling Numbers if ... Is this enough? Any help on this will appreciated.","['proof-verification', 'combinatorics', 'stirling-numbers']"
2923143,Finding Multivariable limits using polar coordinates,"How do I find the limit of this multivariable function as it goes to zero using polar coordinates? $$	\frac{\sin (x^2 + y^2)}{(x^2 + y^2)^2}
$$","['limits', 'multivariable-calculus', 'polar-coordinates']"
2923149,An equality between a product and a combinatorial sum,"I'm trying to prove the following identity (of which I numerically verified the truth) : $$\text{For every $n\in\mathbb{N}^*$ and $\alpha \in \mathbb{R}\setminus\lbrace-2k\text{ }|\text{ }k\in\mathbb{N}\rbrace$,}$$ $$\text{$\prod\limits_{k=1}^{n}$}\left[1-\frac{1}{2k+\alpha}\right]=\frac{\alpha}{4^{n}}{2n \choose n}\text{$\sum\limits_{k=0}^{n}$}\frac{{n \choose k}^2}{{2n \choose 2k}}\frac{1}{2k+\alpha}$$ I've tried induction, unsuccessfully. Tbh, I don't really have any other ideas for tackling it. Products such as this are not that easy to work with. Any ideas or suggestion ?","['summation', 'calculus', 'combinatorics', 'products', 'sequences-and-series']"
2923174,Proving $\frac{1}{1-x} \circ \frac{1}{1-x} = 1 - \frac{1}{x}$ from a series point of view,"It's an elementary exercise in grade school algebra that $$ \frac{1}{1-\frac{1}{1-x}} = 1 - \frac{1}{x}  $$ However from the series point of view it's not at all obvious. There are two different series expressions for $\frac{1}{1-x}$ which are $$ \sum_{k=0}^{\infty} x^k = 1 + x+ x^2 + ... \ |x| < 1  $$ $$ - \sum_{k=1}^{\infty} \frac{1}{x^k} = -\frac{1}{x} - \frac{1}{x^2} - \frac{1}{x^3} ... \ |x| > 1 $$ and attempting to compose yields troubles: (there are 4 cases to analyze here) $$ 1+ (1+x+x^2 ... ) + (1 + x + x^2 + ...)^2 + ... $$ This leads to coefficient blow up, and even with using zeta function values to renormalize infinities it leads to an expression that seems meaningless (or I should say, is very ""difficult"" to interpret). $$ 1 + (-\frac{1}{x} - \frac{1}{x^2} ... ) + (-\frac{1}{x} - \frac{1}{x^2} ...)^2 ... $$ actually simplifies to the correct expression $1- \frac{1}{x}$ (so series can confirm the identity for: $|x|<1, 1 > |x-1|$ ) $$ - \frac{1}{1 + x + x^2 ... } - \frac{1}{(1 + x + x^2 ... )^2 } ... $$ Is again intractable without referencing the geometric series formula. $$ - \frac{1}{ - \frac{1}{x} - \frac{1}{x^2} ... } - \frac{1}{(-\frac{1}{x} - \frac{1}{x^2} ... )^2} ... $$ Is even more horrific (I nicknamed this expression Harmonic Hell). My worry here is only 1 of these 4 compositions could be simplified into the correct target expression, how to correctly manipulate the other 3 to yield the target expression, after all there are specific domain, range combinations that I am losing when I only consider any one of these pairs of series (yet the expression $1 - \frac{1}{x}$ is true globally). Motivation This is part of a toy problem: Action of 3x3 invertible matrices on $\mathbb{C}$? where I began to wonder if it was possible to find an action of $3\times 3$ matrices on the complex plane. My program of research was the following: Interpret mobius transformations as literally pairs of laurent series which accept a quadruple of parameters $a,b,c,d$ corresponding to elements of a $2\times 2$ rotation matrix. Prove the action property (that composing these series yields a new series of the same form, with parameters respecting $2\times 2$ matrix multiplication), [this is where i'm stuck hence this question] Look to now construct series that respect the action of $3\times 3$ matrix multiplication, perhaps inspired by the completion of (2).","['complex-analysis', 'sequences-and-series']"
2923237,Double dual of $\mu$-semistable sheaf,"Is it true that if $F$ is a $\mu$-semistable sheaf, then its double dual is also $\mu$-semistable? We know $c_1(F)=c_1(F^{**})$. Given a sub sheaf $E$ of $F^{**}$, if we can associate to it some subsheaf of $F$, then we can make use of the $\mu$-semistability of $F$. But I am stuck here. Thanks for the help!",['algebraic-geometry']
2923291,Co-countable set and a countable set,"I have this question: let $X$ be an uncountable set.
 Let $\mathcal{M}=\{A \subseteq X : A $ is countable or A is co-countable$\}$, co-countable means its complement is countable. Then, define $m: \mathcal{M} \rightarrow [0, \infty]$ as 
$$m(E) = \left\{ \begin{array}{rcl}
         0 & \mbox{for}& E\ \  countable 
\\ 1  & \mbox{for} & E\ \  co-countable 
                \end{array}\right.$$
Prove that $m$ is a measure. Here is my proof:
I need to show that 1# $m(E)< \infty$ for some $E \subseteq X$, 2# $m$ is countable additive. Clearly 1 is trivial. Then, for 2 I divided it to three cases: Case 1: $E_j$ is countable for all $j$. So that is trivial as well by the definition of $m$. Case 2: $E_j$ is co-countable for all $j$  with the assumption that $\{E_j\}_{j\geq 1}$ is a countable collection of disjoing sets. So $X \thicksim \bigcup_{j \geq1} E_j \subseteq X \thicksim E_m$ for any $m$ positive integer which is countable, so $\bigcup_{j \geq1} E_j$ it is co-countable. Therefore, $m(\bigcup_{j \geq1} E_j )=1$. But then $\sum_{j\geq1}m(E_j)=1+1+1+...=\infty$ since for each $j$ $E_j$ assumed to be co-countable. I am getting stuck here.
Also, in
Case 3: If we have a mix of countable and co-countable sets, then $X \thicksim \bigcup_{j \geq1} E_j \subseteq X \thicksim E_m$ for some $m$ with $E_m$ is countable, so $\bigcup_{j \geq1} E_j $ is co-countable, and hence $m(\bigcup_{j \geq1} E_j )=1$. However, $\sum_{j\geq 1}E_j=0+...+0+1+1+...+1 \neq 1$. WHAT I am missing of ideas here?? Appreciate any help with that.
Thank you.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral']"
2923321,"if $f$ convex, $f$ has bounded first derivative iff $f$ uniformly continuous","Formal statement: if $f: \mathbb{R} \rightarrow \mathbb{R}$ is convex and differentiable, it is uniformly continuous iff there exists some $a > 0$ such that $|f'(x)| \leq a$ for all $x$. One direction seems slightly easier to prove: if $|f'(x)| \leq a$ for all $x$ and we know $f$ is differentiable, we know there's $c$ such that $|f(y) - f(x)| = c \cdot |x - y| \leq a \cdot |x - y|$ we apply Mean Value Theorem (edit: previously cited convexity in ADDITION to the MVT for this part and it was deemed unnecessary). Then we can just let $\delta = \epsilon / a$ to show uniform continuity. The other direction has me stumped. Any suggestion?","['convex-analysis', 'derivatives', 'uniform-continuity']"
2923353,Can a complex manifold that is not a Calabi-Yau manifold be homeomorphic to a Calabi-Yau manifold?,"This is a kind of a follow up to this question , which actually already had an answer here , in which it is asserted that Hodge numbers in general are not topological invariants. Could it be so extreme that a Calabi-Yau $n$ -manifold (compact Kähler with $h^{k,0} = 0$ for $0 < k < n$ , trivial canonical bundle) is homeomorphic to a non-Calabi-Yau complex manifold? In other words, could there be a topological manifold that admits one complex structure for which it is Calabi-Yau, and another for which it isn't?","['kahler-manifolds', 'complex-geometry', 'k3-surfaces', 'algebraic-geometry', 'complex-manifolds']"
2923366,"If $\| \alpha(s) \| \leq \| \alpha(s_0) \| = R$, then the curvature $k(s_0)$ is greater than $1/R$","This question is in Ted Shifrin's A first course in curves and surfaces, page 18, exercise 7: Suppose $\alpha$ is an arclength-parametrized space curve with the property that $\| \alpha(s) \| \leq \| \alpha(s_0) \| = R$ for  all $s$ sufficiently close to $s_0$ . Prove that $k(s_0) \geq 1/R$. (Hint: Consider the function $f(s)=\| \alpha(s)\|^2$. What do you know about $f''(s_0)$?) Here's what I have tried: $$f(s) = \| \alpha(s)\|^2 =  \langle \alpha(s), \alpha(s) \rangle \implies f'(s) = 2 \langle T(s), \alpha(s) \rangle $$ And using the Cauchy-Schwartz inequality : $$f'(s_0) = 2 \langle T(s_0), \alpha(s_0) \rangle \leq 2 \|T(s_0)\|\|\alpha(s_0)\|=2R \implies \langle T(s_0), \alpha(s_0) \rangle \leq R$$ Now we find $f''(s)$: $$f''(s) = 2 \langle k(s)N(s), \alpha(s) \rangle  + 2 (\langle T(s), \langle T(s \rangle )=  2 k(s) \langle N(s), \alpha(s) \rangle  + 2$$ And because $s_0$ is maximum of $\| \alpha(s)\|$: $$2 k(s_0) \langle N(s_0), \alpha(s_0) \rangle  + 2 \leq 0 \implies -1/k(s_0) \geq \langle N(s_0), \alpha(s_0) \rangle$$ I don't know how to continue from here.",['differential-geometry']
2923369,Compute $\lim_{x\to0}{1 - e^{-x}\over e^x - 1}$,"Compute $\displaystyle \lim_{x\to0}{1 - e^{-x}\over e^x - 1}$. So first and foremost, I know what the answer to this question is: $$\begin{align}\lim_{x\to0}{1 - e^{-x}\over e^x - 1} &= \lim_{x\to0}\left({1 - e^{-x}\over e^x - 1}\right)\cdot{e^x\over e^x} \tag{$\star$}\\ & = \lim_{x\to0}{e^x - 1\over (e^x - 1)e^x} \\ &= \lim_{x\to0}{1 \over e^x} \\ &= {1\over e^0} \\ &= 1.\end{align}$$ Unfortunately, I found this solution by complete accident. I can't really justify the motivation of why I performed the step $(\star)$ other than ""I saw the $e^{-x}$ and thought to try and get rid of it. Initially the first thought that I had was to use the conjugate of one of the functions, but we end up not going anywhere with the problem (There's still that nasty $e^{-x}$ using either conjugate). Is this likely the intended solution to this problem? I unfortunately cannot see any other way of solving the problem.","['limits-without-lhopital', 'limits', 'calculus', 'exponential-function']"
2923375,Is this a good way to show that $I$ and $J$ are not independent?,"Given $$P(I\mid J)=0.7$$$$P(I^c\mid J^c)=0.3$$
does the following bit of working out show that $I$ and $J$ are not independent events? $$P(I\mid J)P(J)=P(I \cap J)=0.7P(J)$$ $$P(I^c\mid J^c)P(J^c)=P(I^c \cap J^c)=0.3P(J^c)$$ Since $P(I^c \cap J^c)=1-P(I \cap J)$, and $P(J^c)=1-P(J)$ $$1-0.7P(J)=0.3(1-P(J))$$ $$1-0.7P(J)=0.3-0.3P(J)$$ $$0.4P(J)=0.7 \rightarrow P(J)=7/4,$$ which is silly. I feel like there's a better way to show that the two are not independent though...","['conditional-probability', 'statistics', 'independence']"
2923382,"discuss about the differentiability of $g(x)=|f(x)|$, where $f$ is a differentiable function","I want to discuss about the differentiability of $g(x)=|f(x)|$ , where $f$ is a differentiable function Example 1 Take $f(x)=|x|$ , function is clearly not differentiable at $x=0$ . Example 2 Take $f(x)=|\sin(x)|$ , function is clearly not differentiable at the point $x=n\pi$ After taking few more examples like $|x-1|, |\cos(x)|$ , it always seems to be the case that $|f(x)|$ is not differentiable at the points where $f(x)=0$ Observation: One thing is common in all the examples that some portion of $f(x)$ lies below $x$ axis.
So I took another example $f(x)=x^2$ but $|f(x)|$ is differentiable at the point where $f(x)=0$ Question 1: Am I right in concluding that we can not just say in general setting that $|f(x)|$ is not differentiable at the points where $f(x)=0$ ? When can we(I mean under what conditions can we )conclude that $|f(x)|$ is differentiable at points where $f(x)=0$ . My hypothesis is that graph of $f$ should lie below $x$ axis. Question 2: Let $f(x)$ and $g(x)$ be two differentiable function, when can we conclude that $|f(x)|+|g(x)|$ is not differentiable at the  points where $f(x)=0$ and $g(x)=0$ Example $|sin(2-x)|+ |cos(x)| $ are not differentiable at $x=2+2\pi, x=(2n+1)\frac{k}{2}$ Edits As mentioned by @Torsten Schoeneberg in comments, my hypothesis fails!! Grand Edit: $f(x)=|x|$ then $f'(x)=\text{sign}{(x)}$ So let $f(x)$ be a differentiable function, and let $g(x)=|f(x)|$ , then $$g'(x) =\text{sign}(f(x))f'(x)$$ Note that $\text{sign}{(f(x))}=\begin{cases}{ -1 \quad \text{if } f(x)<0\\+1 \quad \text{if } f(x)>0 } \\{ 0 \quad \text{if } f(x)=0} \end{cases}$ Am I going in right direction?","['general-topology', 'real-analysis']"
2923397,Expected value of number of trials to get k SUCCESSIVE successes,"Independent trials, each of which is a success with probability p, are performed until there are k consecutive successes. What is the mean of the number of the necessary trials? Let $N_k$ be the number of trials needed to get k successive successes. While I am convinced that to answer this problem we should start by 
doing $$M_k = E[N_k]= E[E[N_k|N_{k-1}]]$$
like explained in another post on StackExchange(See Expectation by conditioning ) 
I don't understand how to complete the solution.
The  suggested solution is  $$\begin{align} M_k &= E[N_k]\ (line1 ) \\&= E[E[N_k|N_{k-1}]] \ (Line 2)
\\&=E[p(N_{k-1}+1)+q[N_{k-1}+1+E[N_k]]] \ (line3) 
\\ &=E[N_{k-1}+1+qE[N_k]] \ (Line 4 ) 
\\ &=E[N_{k-1}]+1+qE[N_k] \ (Line 5 ) 
\\&= M_{k-1}+1+qM_{k} \ (Line 6 ) 
\\&=\frac{1}{p}+\frac{M_{k-1}}{p} \ (Line 7 ), M_0=0 \end{align}$$ What I don't understand is $(line3)$ especially $ q* [N_{k-1}+1+E[N_k]]$ Please someone could provide me an explanation ? Thank you","['conditional-probability', 'probability-distributions', 'probability-theory', 'probability']"
2923494,Understanding finding sine of radian angle,"So given the problem to find the sine of angle $7\pi / 6$ without using a calculator. I reasoned that a half unit circle has radian measure of $\pi$. So we go one half circle
and another $1/6$ which leads us into the 3rd quadrant. So the value will be negative. I then drew a right triangle with the hypotenuse equal to the radius of the unit circle, which is 1. Now, since I know that the angle $O$ in the right triangle is 30 degree, and we are in a $30-60-90$ triangle, I concluded the sine I am looking for is $-1/2$. But assuming I wouldn’t know sine of $30$ deg or I wouldn’t want to rely on the right triangle definition of sine - how could I find out the sine of $7\pi / 6$?","['trigonometry', 'intuition']"
2923502,Find an angle $A$ such that $\tan A + \cot A = 2$,"Find an angle $A$ such that $\tan A + \cot A = 2$ I'm recently getting into trigonometry, so i think I may have some trouble, that's why I'm asking. I used the identities $$\tan A = \frac{\sin A}{\cos A}$$ and $$\cot A = \frac{\cos A}{\sin A}$$ So it follows $$\frac{\sin A}{\cos A}+\frac{\cos A}{\sin A}=\frac{\sin^2 A+\cos^2 A}{(\sin A)(\cos A)}$$ 
and we have that $\sin^2 A+\cos^2 A =1$, so it clearly follows that $$(\sin A)(\cos A)=\frac{1}{2}$$ From here, is there any identity i could use?. What i did next was to try to use the basis of sine and cosine, so if we let $a$ be the opposite and $b$ the adyacent, we have $$(\sin A)(\cos A)=\frac{ab}{h^2}=\frac{ab}{a^2+b^2}=\frac{1}{2}$$
And thus it's possible to find the answer if we find positive values for $a,b$, but i don't have more ideas.","['number-theory', 'trigonometry']"
2923527,Limits and convergence - selecting the right epsilon for proofs,"Show that if limit of sequence $x_n$ goes to $x$ as $n$ goes to $ \infty$ and $ x > a$, then $x_n > a$ all but finitely many $ n$. I have started it like this:
$x_n > x - \epsilon$ (as  $|x_n- x| < \epsilon$ for all $\epsilon$) $x_n > a - \epsilon$ From here on, how does one chose the right epsilon to show that $x_n > a$?","['limits', 'convergence-divergence', 'real-analysis']"
2923530,How many unique outcomes can be made from the 12 river tiles in Carcassonne?,"I have been pondering this question for some time now and it's a bit out of my scope to solve it. I am curious to know how many arrangements are possible for the river 1 expansion for Carcassonne. The rules for playing the river are as follows: The source tile is played first, The lake tile is played last, and If two river bends are drawn in sequence they must have opposing orientation. I understand the following: The first and last tile played will not factor into the counting so we just look at the $10$ tiles in between. Each tile has $2$ orientations and there are $8$ unique tiles, plus $1$ repeated corner, and one repeated straight. We must also exclude possibilities that become unplayable when the river curves in onto itself. Here's an image of the $12$ river tiles: My preliminary guesswork at counting is $$\frac{(2^8)10!}{2!2!}$$ My rationale 
$10!/2!2!$ Because order of selection matters and repetition tiles are excluded by dividing by $2!$ $2^8$ because each tile can be placed in $2$ ways (the $2$ straight tiles are not included because they are not unique) I know this is wrong. It's just my first guess at it, and it has not excluded possibilities where the river curves into itself and creates an unplayable game. Any assistance would be much appreciated, thanks!","['permutations', 'combinations', 'combinatorics']"
2923537,Definition of Topological Embedding,"The following definition of topological embeddings is given in Introduction to Topological Manifolds by John M. Lee. Definition. An injective continuous map that is a homeomorphism onto its image (in the subspace topology) is called a topological embedding . In defining topological embeddings, is it necessary to first suppose a function is injective and continuous? Is there such a function $f:X\to Y$ that is not injective or continuous, but the function $\tilde{f}:X\to f(X)$ is a homeomorphism? The requirement $f:X\to Y$ be injective and continuous seems redundant to me, for if the function $\tilde{f}:X\to\ f(X)$ obtained by restricting the codomain of $f$ to its range is a homeomorphism, then it automatically guarantees $f$ is continuous and injective. In short, why not define a topological embedding as follows? Definition. A map $f:X\to Y$ between topological spaces is called a topological embedding if the function $\tilde{f}:X\to\ f(X)$ obtained by restricting the range of $f$ is a homeomorphism.",['general-topology']
2923549,Counterexample for the $L^p$ Ergodic Theorem of Von Neumann when $p=\infty$,"I am looking for a counterexample to the following theorem when $p=\infty$ : $L^p$ Ergodic Theorem of Von Neumann. Let $1\leq p<\infty$ and let $T$ be a measure-preserving transformation of the probability space $(X,\mathfrak{B},m)$ . If $f\in L^p(m)$ there exists $f^*\in L^p(m)$ with $f^*\circ T=f^*$ a.e. and $\left\lVert (1/n)\sum_{i=0}^{n-1}f(T^ix)-f^*(x)\right\rVert_p\to 0$ . Specifically, I want to find a probability space and $f\in L^{\infty}(m)$ , such that there doesn't exist a $f^*$ preserved by $T$ such that the convergence holds in $L^\infty$ norm.","['measure-theory', 'ergodic-theory', 'examples-counterexamples', 'lp-spaces', 'probability-theory']"
2923551,A difficulty in understanding a part of solution of Q.1.3.10 in Allan Pollack and Guillemin.,"""Generalization of the inverse function theorem.let $f:X \rightarrow Y$ be a smooth map that is 1-1 on a compact submanifold Z of X. Suppose that for all $x \in Z$, $$df_{x}: T_{x}(X) \rightarrow T_{f(x)}(Y) ,$$ is an isomorphism. then $f$ maps $Z$ diffeomorphically onto $f(Z)$. why? prove that $f$, in fact, maps an open neighborhood of Z in X diffeomorphically onto an open neighborhood of $f(Z)$ in Y. Note that when Z is a single point, this specializes to the inverse function theorem."" The author gives a hint mentioning in it exercise 5 which is: ""Prove that a local diffeomorphism $f: X \rightarrow Y $""is actually a diffeomorphism of $X$ onto an open subset of $Y$, provided that $f$ is 1-1. The hint says: ""Prove that, by Excercise 5, you need only show $f$ to be 1-1 on some neighborhood of Z. Now if $f$ is not so, construct sequences ${a_{i}}$ and ${b_{i}}$ in $X$ both converging to a point $z \in Z$, with $a_{i} \neq b_{i}$, but $f(a_{i}) = f(b_{i})$. Show that this contradicts the nonsingularity of $df_{z}$."" I have found an answer for this question on the internet in page 8 in the following link: https://math.berkeley.edu/~ceur/notes_pdf/Eur_GPDiffTopSolns.pdf But I could not understand (imagine) the second paragraph of the solution given in the image below: Could anyone explain this for me please? Also in the second line in the solution I do not know why he take the intersection on $U_{i}'s$ and not the union?Could anyone explain this for me please?","['geometric-topology', 'general-topology', 'differential-topology', 'differential-geometry']"
2923568,"An event with unit density still has zero information, despite not being an event that is guaranteed to occur.","My textbook says the following in a section on information theory : The basic intuition behind information theory is that learning that an unlikely event has occurred is more informative than learning that a likely event has occurred. A message saying “the sun rose this morning” is so uninformative as to be unnecessary to send, but a message saying “there was a solar eclipse this morning” is very informative. We would like to quantify information in a way that formalizes this intuition. • Likely events should have low information content, and in the extreme case, events that are guaranteed to happen should have no information content whatsoever. • Less likely events should have higher information content. • Independent events should have additive information. For example, finding out that a tossed coin has come up as heads twice should convey twice as much information as finding out that a tossed coin has come up as heads once. To satisfy all three of these properties, we define the self-information of an event $\mathrm{x} = x$ to be $$I(x) = -\log(P(x))$$ In this book, we always use $\log$ to mean the natural logarithm, with base $e$ . Our definition of $I(x)$ is therefore written in units of nats. One nat is the amount of information gained by observing an event of probability $\dfrac{1}{e}$ . Other texts use base- $2$ logarithms and units called bits or shannons; information measured in bits is just a rescaling of information measured in nats. When $\mathrm{x}$ is continuous, we use the same definition of information by analogy, but some of the properties from the discrete case are lost. For example, an event with unit density still has zero information, despite not being an event that is guaranteed to occur. Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron. Deep Learning (Page 71). My question is about this last part: When $\mathrm{x}$ is continuous, we use the same definition of information by analogy, but some of the properties from the discrete case are lost. For example, an event with unit density still has zero information, despite not being an event that is guaranteed to occur. What is meant by ""unit density""? What is meant by ""an event with unit density""? What is meant by ""an event with unit density still has zero information, despite not being an event that is guaranteed to occur""? I would greatly appreciate it if people could please take the time to clarify this.","['random-variables', 'information-theory', 'machine-learning', 'probability-theory', 'density-function']"
2923633,Why are sheaves called sheaves?,"By ""why"" I mean: what were the stated intentions of the namers? More generally, how did the theme of agricultural terminology in algebraic geometry come about?","['algebraic-geometry', 'math-history', 'terminology']"
2923662,Question on coin tossing - probability,"When considering an infinite sequence of tosses of a fair coin, how long will it take on an average until the pattern H T T H appears? I tried to break the problem into cases where ultimately the pattern HTTH appears, but that makes things complex. Any insight would be helpful.","['conditional-probability', 'probability-distributions', 'probability-theory', 'probability', 'random-variables']"
2923680,"If $\sum\limits_{n=1}^{\infty}\frac{1}{p(n)}\in\mathbb{Q}$, is $\sum\limits_{n=1}^{\infty}\frac{n}{p(n)}\in\mathbb{Q}$?","Suppose $p(n)$ is a polynomial with rational coefficients and rational roots of degree at least $3$. If we know 
$$\sum_{n=1}^{\infty}\frac{1}{p(n)}\in\mathbb{Q}$$
are we able to infer that
$$\sum_{n=1}^{\infty}\frac{n}{p(n)}\in\mathbb{Q}?$$ I've tried several approaches to proving (or disproving) this to include the following: -Looking for counterexamples -Generating functions -Residues -Partial fraction decomposition but nothing has yielded any positive or negative results. Any tips, terms, papers, methods, or generally topics that I could look into would also be welcome. Edit: As noted by Carl Schildkraut below, if this is true, then we would automatically know that $\zeta(2k+1)$ was irrational. Since this seems to greatly increase the potential difficulty, I offer the following modification in order to simplify it: Suppose $p(n)$ is a polynomial with rational coefficients, rational roots, $\deg(P)\geq 3$, and every root has order $1$. If we know 
$$\sum_{n=1}^{\infty}\frac{1}{p(n)}\in\mathbb{Q}$$
are we able to infer that
$$\sum_{n=1}^{\infty}\frac{n}{p(n)}\in\mathbb{Q}?$$","['number-theory', 'complex-analysis', 'polynomials', 'generating-functions', 'sequences-and-series']"
2923730,Extending the Fourier transform on $L^1(\mathbb{R}^n)$ to $L^2(\mathbb{R}^n)$,"We define the Fourier transform of $f \in L^1(\mathbb{R}^n)$ with the usual formula $\int e^{-i k \cdot x} f(x) dx$. This does not work for the functions in $L^2(\mathbb{R}^n)$. The defining integral may not converge. However, we can extend Fourier transform to $L^2(\mathbb{R}^n)$ by its continuity. First show that Fourier transform on Schwartz functions $S \subset L^2(\mathbb{R}^2)$ is an isometry with respect to the $L^2$ norm. Then, by the continuity (isometries are continuous) of the Fourier transform on $S$ and the densinty of $S$ in $L^2(\mathbb{R}^n)$, we can extend Fourier transform to the whole $L^2(\mathbb{R}^n)$ as an isometry. $L^2(\mathbb{R^n})$ is complete so the extension is unique and surjective. Therefore it is unitary, not merely an isometry. Thus the Fourier transform of an $L^2(\mathbb{R^n})$ function is also an $L^2(\mathbb{R^n})$ function and it preserves the inner product. The above is a rather long quote from the material in a class I attend. I don't have strong background on analysis but am struggling to understand the above argument. I think I can understand most part except the uniqueness and surjectivity. Why the completeness ensures the uniqueness and surjectivity? I have read some textbooks on the same subject and found that the bijectivity is usually proved by the extension of the inversion formula on $S$ to $L^2$, which I can understand. For the uniqueness, I couldn't find any argument in my textbooks. Does the completeness of $L^2$ really ensure the uniqueness and surjectivity?","['fourier-transform', 'functional-analysis']"
2923780,"Find the line through $P = (2,4,7) $ that intersects and is perpendicular to the line : $x = -1 + t, y = -2 + 3t, z = 4 $","Find the line through $P = (2,4,7) $ that intersects and is
  perpendicular to the line : $x = -1 + t, y = -2 + 3t, z = 4 $ I set up a system of equations and obtained : $-1 + t = x_0 +2 \\ -2 + 3t = y_0 + 4 \\ 4 = z_0 + 7$ Solving for each and putting them I obtain the vector $ v_1 = <t -3, 3t-6, -3>$ I then set the direction vector as $ v_2 =<1,3,4>$ Since $v_1 \cdot v_2 = 0 $ means they are orthogonal I obtain : $<t -3, 3t-6, -3> \cdot <1,3,4> = 0  $ Multiplying out and solving for t I get $t = 10/21$ Would I now just substitute my given value for t back into $t_1$ ?","['multivariable-calculus', 'vectors', 'geometry']"
2923822,"$(\varphi,\Gamma)$-modules and valuation in Zp","The theory of $(\varphi,\Gamma)$ -modules and a reciprocity law due to Cherbonnier and Colmez involve the ring $A_K$ , that is described below. The question is why for the valuation defined as $l_ν(a):=min\{i| p^ν - does- not- divide - a_i\}$ of $a=\sum_i a_i(\pi_k)^i$ $\in$ $A_K$ , the $l_1(a)$ is independent of a choice of uniformizer for $A_K$ but $l_v(a)$ for $v\geq2$ is not? Can someone help me here, please? Is there an example of where one can see this? The ring $A_K$ :
Set $E$ to be the set of sequences $(x^{(0)},x^{(1)}, . . . )$ of elements of $C_p$ satisfying $(x^{(n+1)})^p=x^{(n)}$ , with addition given by $(x + y)^{(n)} = \lim_m (x^{(n+m)} + y^{(n+m)})^{p^m}$ and $(xy)^{(n)} = x^{(n)}y^{(n)}$ . Then $E$ is a complete, algebraically closed field of characteristic $p$ .
Fix a compatible system of roots of unity $(\zeta_p^m),\forall m\in\mathbb N$ where $(\zeta_p^{m+1})^p= \zeta_p^m$ , and write $K_n=K(\zeta_p^n)$ . We set $\epsilon=(1,\zeta_p,\zeta_p^2,...)$ and denote by $E_{\mathbb Q_p}$ the subfield of $E$ given by $F_p((\epsilon− 1))$ .
We write $E_s$ for its separable closure and note that $E$ is the completion of the algebraic closure. We write $E_K=E^{H_K}$ for the subfield of $E$ fixed by $H_K=\ker\chi^{cyclo}$ . We take $A=W(E)$ the ring of Witt vectors over $E$ , and $B=A[1/p]=Frac(A)$ . This is a complete discrete valuation field with residue field $E$ . We can write $x\in A$ as $\sum_{k=0}^\infty p^k[x_k]$ where $x_k\in E$ and $[\cdot]$ is the Teichmüller lift. We write $\pi=[\epsilon]−1$ , and $A_{\mathbb Q_p}$ for the closure of $\mathbb Z_p[\pi,\pi^{−1}]$ in $A$ ; it is a complete discrete valuation ring with residue field $E_{\mathbb Q_p}$ . We write $B_{\mathbb Q_p}=Frac(A_{\mathbb Q_p})=A_{\mathbb Q_p}[1/p]$ .
We have actions of $\varphi$ and $G$ on $B$ given by $\varphi(\pi)=(1 + \pi)^p−1$ and $g(\pi)=(1+\pi)^{\chi^{cyclo}(g)}−1$ . We write $B_c$ for the closure of the maximal unramified extension of $B_{\mathbb Q_p}$ in $B$ and $A_c=B\cap A$ such that $A_c[1/p]=B$ We have $B_K=B^{H_K}$ and $A_K=A^{H_K}$ . We observe that $$ B_K=\{\sum_{n \in\mathbb Z} a_n \pi_K^n : a_n \in F, \lim_{n \rightarrow -\infty} a_n=0\}$$ where $\pi_K$ is $e-$ th root of $\pi$ and a uniformizer of $B_K$ . We likewise have $$ A_K=\{\sum_{n \in\mathbb Z} a_n \pi_K^n \in B_K : a_n \in\mathcal O_F, \forall n\in\mathbb Z\}$$","['number-theory', 'p-adic-number-theory', 'valuation-theory']"
2923831,"Testing if two finite sets of points differ only by rotation (unordered, in polynomial time in size and dimension)?","Imagine we have two size $m$ sets (without order) of points $X=\{x^i\}_{i=1..m}, Y=\{y^i\}_{i=1..m} \subset \mathbb{R}^n$ and we want to answer the question if they differ only by rotation: if there exists othogonal $O^TO=OO^T=I$ such that $X=\{Oy^i:i=1..m\}$ . It simple to test in exponential time, the question is if it be answered in polynomial time (in both $m$ and $n$ )? While it might seem simple, it isn't - the most difficult cases of graph isomorphism problem: for strongly regular graphs (SRG) can be translated to above problem. We can assume that all points are on a sphere , for SRGs they form very regular high dimensional polyhedron (diagram below) having $m\approx 2n$ points. Testing differing only by rotation is simple for symmetric matrices - they differ only by rotation if traces of all $n$ powers are equal ( $\exists_O P=O^TQO \Leftrightarrow \forall_k \textrm{Tr}(P^k)=\textrm{Tr}(Q^k)$ ). Maybe we could use it for sets of points - by translating them into matrix e.g. $n\times n$ : $$P_{ab} = \sum_{i=1..m} x^i_a x^i_b\qquad Q_{ab} = \sum_{i=1..m} y^i_a y^i_b \qquad \forall_{k=1..n}\textrm{Tr}(P^k)=^?\textrm{Tr}(Q^k).$$ Above formula looks like eigendecomposition $(P=\sum_i \lambda_i v^i v^{iT})$ if vectors are orthogonal and $m\leq n$ , but generally it does not determine the used sets of points: for SRGs we have $m\approx 2n$ and above matrices turn out proportional to identity matrix like for POVM s. One question is: for how many points above test works? (assume all have the same norm) It trivially works for $m=1$ point, for two they can be opposite - zeroing the matrix, but it works otherwise (determining single angle), hence we need some independence assumption (?). Generally, for $m$ vectors spanning $n'$ dimensional subspace $(m\leq n'\leq n)$ , they contain $m(n'-1)-n'(n'-1)/2=(m-n'/2)(n'-1)$ degrees of freedom modulo rotation, while above test uses $n$ degrees of freedom, from which all but $n'$ are trivial (zero eigenvalue). Hence we need $(m-n'/2)(n'-1)\leq n'$ condition. Is it sufficient? We can also analogously use tests with higher order matrix (on tensor product) to increase the number of independent invariants, e.g. (corresponding to ladder-like graphs) $n^2 \times n^2$ : $$P_{ab,cd}=\sum_{ij} x^i_a x^i_c (x^i\cdot x^j) x^j_b x^j_d \qquad Q_{ab,cd}=\sum_{ij} y^i_a y^i_c (y^i\cdot y^j) y^j_b y^j_d$$ and testing if $\forall_{k=1..n^2 }\textrm{Tr}(P^k)=\textrm{Tr}(Q^k)$ . I have recently checked it for SRGs and it worked: distinguished all I have tested (up to 29 vertices). The question is how to prove it: what maximal number of points (assuming some independence) it always distinguishes? How this number changes with order of such method? Some example of third order: $P_{abc,def}=\sum_{ijk} x^i_a x^i_d x^j_b x^j_e x^k_c x^k_f (x^i\cdot x^j) (x^i\cdot x^k)(x^j\cdot x^k)$ . Any other way to test it in polynomial time? Example of two non-isomorphic $m=16$ vertex SRGs of the same parameters we would like to distinguish (for any vertex permutation). Eigenspectrums of their adjacency matrices are highly degenerated - taking orthonomal basis of $n=6$ dimensional eigenspace, treating its columns(!) as vectors, they form very regular polyhedron: scalar products recreate neighborhood relation: has one value for all neighbors, second for all non-neighbors, like in schematic diagram on the right: Update (2018-09-21): interesting comment from https://redd.it/9hdwnl : any graph isomorphism problem can be translated to above by putting points in basis $\{e_i\}$ and $\{e_i + e_j \textrm{ for each edge }(i,j)\}$ . This construction restricts rotations to permutations. Hence, solving the above problem for $m\sim n^2$ would also solve graph isomorphism problem. For strongly regular graphs it suffice to do it for $m\sim 2n$ . Update (2018-09-22): there was pointed similarity to orthogonal Procrustes problem , which finds optimal rotation knowing which point should rotate to which. Here we don't know it - just have sets without order: there are $m!$ possibilities.","['graph-isomorphism', 'invariance', 'geometry', 'algebraic-geometry', 'linear-algebra']"
2923849,Does there always exist an algebraic integer in a number field whose discriminant divides its norm?,Let $K$ be a number field of degree $n$ over the rationals. Under what conditions does there exist an algebraic integer $\alpha $ in $K$ such that the discriminant of $\alpha$ divides the norm of $\alpha$?,"['number-theory', 'algebraic-number-theory']"
2923899,Does every set have a power set?,"While reading the probability space in Wikipedia, I'd found the usual formulation is a triplet, which is ${\displaystyle (\Omega ,{\mathcal {F}},P)}$. Upon my understanding, the middle ${\mathcal {F}}$ is a power set of $\Omega$ which will be allocated with real-valued probabiilty by $P$. If every set in this nature has power set, there might be no necessity of introduction of ${\mathcal {F}}$ I guess however, I've never thought of a set which doesn't have its power set. Is there any set that doesn't have power set? or if not, which means every set has its power set, is there any plausible reason that ${\mathcal {F}}$ is introduced in probability formulation?","['elementary-set-theory', 'probability']"
2923901,$\forall n\in\mathbb N:n^x\in\mathbb Q$ implies $x\in\mathbb Z$ - elementary proof?,"Consider the following two problems: Show that if for some $x\in\mathbb R$ and for each $n\in\mathbb N$ we have $n^x\in\mathbb N$, then $x\in\mathbb N$. Show that if for some $x\in\mathbb R$ and for each $n\in\mathbb N$ we have $n^x\in\mathbb Q$, then $x\in\mathbb Z$. The first of those is a somewhat infamous Putnam problem (A6 from 1971) and there is an elementary proof of this using calculus of differences and mean value results, which you can read here . As mentioned in an answer here , the second problem follows from the six exponentials theorem, even if we only require $2^x,3^x,5^x$ to be rational. However, this solution is very non-elementary, and I suspect that using all values of $n$ we might be able to give an easier proof, just like we can for the first problem (though I'm aware the linked proof doesn't generalize). Is it possible to solve the second problem with elementary means?",['number-theory']
2923913,What is logical consequence and logically equivalent in discrete math?,I'm having a difficult time understanding what the meaning are with these two. Is it correct if I have (P ⇒ Q) ∧ P and I say Q is a logical consequence. This means that whatever P may be T or F the result all comes down to what Q is?,"['logic', 'discrete-mathematics']"
2923914,Solution of SDE with additive noise,"I have a question about stochastic differential equations with additive noise. My question is: Is the solution of a SDE with additive noise almost surely equal to the solution of the corresponding deterministic equation plus the noise? Mathematically formulated, my question is the following: Let $X_t$ be the solution to the SDE
$$
\mathrm{d}X_t = b(t,X_t) \mathrm{d}t + \mathrm{d} B_t,\; X_0=\xi,
$$
where $B_t$ denotes a Brownian motion and with suitable assumptions on $b$ to assure existence and uniqueness of a solution. Furthermore, let $Y_t$ be the solution to the integral equation
$$
\mathrm{d}Y_t = b(t,Y_t)\mathrm{d}t,\; Y_0 =\xi.
$$
Is it true that it holds $X_t = Y_t +B_t$ almost surely? Thank you in advance for your input! Best,
Luke","['stochastic-differential-equations', 'brownian-motion', 'stochastic-calculus', 'ordinary-differential-equations']"
2923950,"Does there exist a measurable subset $A \subset \mathbb{R}$, such that $\mu(A)$ is finite, but $\mu(\{a+b|a,b\in A\}) = \infty$?","Does there exist a measurable subset $A \subset \mathbb{R}$, such that $\mu(A)$ is finite, but $\mu(\{a+b|a,b\in A\}) = \infty$? Here $\mu$ stands for Lebesgue measure. If such subset exists, it can not be bounded:
Suppose it is. Then there exists such $a \in \mathbb{R}$ such that $A \subset [-a;a]$. That results in $\{a+b|a,b\in A\} \subset [-2a;2a]$, from which follows that $\mu(\{a+b|a,b\in A\}) \leq 4a$ is finite. However, I do not know, how to solve the problem in general. Any help will be appreciated.","['real-numbers', 'measure-theory', 'lebesgue-measure', 'real-analysis', 'elementary-set-theory']"
2923972,For given problem if we change the setting what will happen?,"I encountered following problem and I solved it by using the hint provided. Thinking of it I noticed 
that I am able to solve it even if I use the following function:
$$
F(z)=1/f(1/z)),\quad |z|> 1$$
$$ =f(z) ,      \quad |z|\leq 1
$$ What is the problem if I use this function to solve the problem? I can extend it to the whole $\mathbb{C}$ as well: I know that analytic continuation of any function is unique, but I am thinking where is problem if I choose to use this function. Any Help will be appreciated.","['complex-analysis', 'holomorphic-functions', 'analytic-continuation']"
2923981,integral form of Taylor theorem remainder multivariable,"Let a function f be in $C^{k+1}(B(x_0,r)),r>0$, then 
$$f(x) = P_k(x;x_0)+ (k+1)\sum_{\vert \alpha \vert= k+1}\left(\int_0^1 (1-t)^kD^\alpha f(x_0+t(x-x_0))dt\right)\frac{(x-x_0)^\alpha}{\alpha !}$$
Where $P_k(x;x_0)$ is the Taylor polynomial centered at $x_0$.and $\alpha$ here is multivariable index $\alpha = (\alpha_1, \cdot \cdot \cdot, \alpha_n )$ and usual multivariable notation is used here. 
I know how to get the Taylor polynomial (just use integration by part repeatedly) but how can we get the remainder in that form?","['multivariable-calculus', 'taylor-expansion', 'analysis', 'real-analysis']"
2924071,"Differentiability of the function $f(x,y)=\begin{cases} \frac{xy}{x^2+y^2}, & \text{if $(x,y)\ne(0,0)$}\\ 0, & \text{otherwise} \end{cases}$ [duplicate]","This question already has answers here : If $F(0,0)=0$ and $F(x,y)= \frac{xy}{x^2+y^2}$ for $(x,y)\neq (0,0)$ then $F$ is differentiable at $(0,0)$? [duplicate] (2 answers) Closed 5 years ago . Consider the function $f(x,y)=\begin{cases}
    \frac{xy}{x^2+y^2}, & \text{if $(x,y)\ne(0,0)$}\\
    0, & \text{otherwise}
  \end{cases}$ Question :
Is it differentiable everywhere? Does it have partial derivatives everywhere? My attempt : $f$ is differentiable on $\Bbb R^2\backslash\{(0,0)\}$ because it is the ratio between two differentiable functions and the denominator doesn't vanish. Is it still the case in $(0,0)$? If we write $x=r\cos\theta$ and $y=r\sin\theta$ then the function becomes $\begin{cases}
    \frac{r^2\cos\theta\sin\theta}{r^2} & \text{if } r\ne0 & \\ 
    0 &\text{if } r=0
\end{cases}$ =
$\begin{cases} \cos\theta\sin\theta & 
\end{cases}$ We realize that $f$ doesn't depend on the radius, so the fact that $f(1,1)=1/2\ne-1/2=f(-1,1)$ so we can approach zero by decreasing the radius and preserving the values $1/2$ and one hand and $-1/2$ on the other. So the function is discontinuous at zero, so not differentiable. Does it have partial derivatives everywhere? $$\frac{\partial f}{\partial x}=\lim_{h\to\ 0}\frac{f(h,0)}{h}=0$$
$$\frac{\partial f}{\partial y}=\lim_{h\to\ 0}\frac{f(0,h)}{h}=0$$
So the partial derivatives exist in zero and elsewhere.","['partial-derivative', 'multivariable-calculus', 'proof-verification']"
2924080,Converting English to Set Theory Notation,"I am having trouble finding expressions for the following. My attempts are separated from the question with a semicolon. Let $A$, $B$, and $C$ be events. Find expressions for: only $A$ occurs; $A \cap \neg B \cap \neg C$ only $A$ doesn't occur; $\neg A \cap B \cap C $ $A$ and $B$ don't occur, but $C$ does; $\neg A \cap \neg B \cap C$ $A$ and $B$ occur, but $C$ doesn't occur; $A \cap B \cap \neg C$ at least one of $A$ and $B$, but not $C$ occurs; $(A \cup B) \cap \neg C $ at least one of the events occur; $A \cup B \cup C$ at least two of the events occur; $(A \cup B) \cup (B \cup C) \cup (C \cup A)$ all three events occur; $A \cap B \cap C$ none of the events occur; $\neg A \cap \neg B \cap \neg C$ at most one of the events occurs; $(A - (A \cap B \cap C)) \cup (B - (A \cap B \cap C)) \cup (C - (A\cap B\cap C))$  . Could someone please let me know if my reasoning is correct?","['elementary-set-theory', 'notation']"
2924094,Conditional probabilities with impossible outcomes,"Suppose we want to predict the outcome of a race between three runners $A$, $B$, $C$. We know the prior probabilities for head-to-head runs: $p_{A>B}$, $p_{A>C}$, $p_{B>C}$, where $A>B$ means that A finishes before B. How do we get the probability $p_{A>B>C}$? I thought I could just use a tree diagram but I run into the following problem: Some outcomes are impossible. For example, if my first edge is ""A finishes before B"" and my second edge is ""A finishes after C"", then ""B finishes before C"" is no longer possible. I thought about just setting probability of impossible outcomes to 0, but then my outcome probabilities are different depending on which of the three probabilities I start with. I think I'm making some basic mistake here. I've seen a lot of similar questions but I don't think they answer this. I've also tried looking at how horse race outcomes are predicted, but couldn't find an answer that I understood.",['probability']
2924095,"Is the function $f(x,y) = \frac{x^2y^2}{x^2y^2 + (y-x)^2}$ if $(x,y) \neq (0,0)$, $f(0,0) = 0$ differentiable? Continuous?","Define $f(x,y) = \frac{x^2y^2}{x^2y^2 + (y-x)^2}$ if $(x,y) \neq (0,0)$, $f(0,0) = 0$ on $\mathbb{R}^2$. (a) For which vectors $u \neq 0$ does $f'(0,u)$ exist? Evaluate it when it exists (b) Do $D_1f, D_2f$ exist at $0$? (c) Is $f$ differentiable at $0$? (d) Is it continuous at $0$? My attempt : (a)$$f'((0,0),(u_1,u_2)) = \lim_{t \to 0} \frac{u_1^2 u_2^2t}{t^2 u_1^2 u_2^2 + (u_1-u_2)^2}$$ exists only if $u_1 \neq u_2$, and then equals $0$. (b) Since $D_1f(0,0) = f'(0,(1,0))$, it follows that $D_1f(0,0) = 0$. Similalrly for $D_2f(0,0)$ (c) No, not all directional derivatives exist, and also no because of (d) (d) $(1/n,1/n) \to 0$ but $f(1/n,1/n) = 1 \not \to 0 = f(0,0)$. Hence, $f$ isn't continuous at $0$. Is this correct?","['multivariable-calculus', 'derivatives']"
2924109,Measurability of random variable wrt pullback $σ$-algebra,"Three Polish spaces $A$ , $B$ and $R$ are given, and are equipped with their Borel $σ$ -algebras $\mathcal B_A$ , $\mathcal B_B$ and $\mathcal B_R$ . Let $f\colon A \to B$ and $g\colon A \to R$ be $(\mathcal B_A,\mathcal B_B)$ - and $(\mathcal B_A,\mathcal B_R)$ -measurable functions. Let's write $p(f,g)$ as a shorthand for the following. For every Polish space $X$ and all $(\mathcal B_X,\mathcal B_A)$ -measurable maps $h,k\colon X\to A$ , $$f \circ h = f \circ k \implies g \circ h = g \circ k.$$ My question is, is it true that if $p(f,g)$ , then $g$ is $(f^{-1}\mathcal B_B,\mathcal B_R)$ -measurable? Here, $\mathcal B_X$ is the Borel $σ$ -algebra of $X$ and $f^{-1}\mathcal B_B = \{f^{-1}(B'):B'\in \mathcal B_B\}$ is the usual pullback $σ$ -algebra. The idea behind this is that $f$ is a sort of extension of a probability space, in the sense that $B$ is extended by $f$ to $A$ (here I don't consider particular measures, though, and $f$ would have additional properties that I think are unnecessary here). $g$ is a $R$ -valued random variable, and $p(f,g)$ sort of states that $g$ is not related to the extension and that $g$ is already available in the smaller space $B$ . Actually, this is true if the answer to my question is yes, but I'm not even sure where to start to show that (or to confute it).","['measure-theory', 'probability-theory', 'random-variables']"
2924127,Rank of Matrix Determination,"$X=(I+ab^T)A(I+ba^T)$; $A$ is symmetric and positive definite matrix of $n \times n$. $I$ is the Identity matrix of $n \times n$. $a$ and $b$ are vectors of $n \times 1$. $a.b \neq -1$ and $a.b \neq 0$ $a$ is not parallel to $Ab$ How do we show that $X-A$ is a rank $2$ matrix ? Efforts: $$X-A= ab^T A + Aba^T+ ab^T A ba^T$$
Hence each of the terms are having rank $1$. so the sum of all the terms can have rank $\leq 3$
But I am not getting how it can be exactly of rank $2$..","['matrices', 'matrix-rank', 'linear-algebra']"
2924137,"Two vectors with the same normal surface projection and the same normal surface cross product, are equal?","I have two vectors, $\mathbf a$ and $\mathbf b$ , that fulfill the following conditions: $(\mathbf a-\mathbf b)\cdot \mathbf n= 0$ $(\mathbf a-\mathbf b)\times  \mathbf n=\mathbf 0$ being $\mathbf n$ a unit surface normal. My question is, is $\mathbf a = \mathbf b$ ? I have confirmed this by doing the cross product in a reference frame for which its first direction is coincident with the surface normal. Since both the dot and cross products are invariant under reference frame transformations, the results should be confirmed for all coordinate systems. Is this reasoning ok?","['cross-product', 'vectors', 'geometry']"
2924195,Parametrizing the surface $x^2 = 1-z$ and $y^2 = z$,"I am given the following exercise: Find the parametrization of the surface $C: x^2 = 1 - z$ and $y^2 = z$ I got to the following answer: \begin{cases}
x &= \sin (t)\\
y &= \cos (t)\\
z &= \cos^2 (t)
\end{cases} Unfortunately, there's no way to evaluate if my answer is correct on the textbook. Could someone please verify if that's the case? Thank you.","['multivariable-calculus', 'parametrization', 'parametric']"
2924229,$\frac{d^2}{dx^2}f(x)>\frac{d^2}{d x^2}g(x) \implies \frac{d^2}{d x^2}\log(f(x))> \frac{d^2}{d x^2}\log(g(x))$?,"Does the following inequality hold? $$\frac{d^2}{dx^2}f(x)>\frac{d^2}{d x^2}g(x) \implies \frac{d^2}{d x^2}\log(f(x))> \frac{d^2}{d x^2}\log(g(x))$$ EDIT: as this does not hold i wonder whether it works with $\geq$ ? To give some insights why I was interested in this question: The fisher-information is defines as $$ I(\theta)=\int \frac{\partial^2}{\partial \theta ^2}log(f_\theta(x))dP_\theta(x)$$ and I was trying to figure out whether this cannot only be interpreted as the ""expected curvature"" of the log-likelihood but also as containing information about the expected curvature of the likelihood, but the relationship is at least not as simple as I hoped it would be.","['calculus', 'derivatives']"
2924242,Prove that all $2 \times 2$ orthogonal matrices can be expressed as rotation or reflection,"Let A be some $2 \times 2$ matrix with real entries. Prove that $A^T$$A$ = $I$ if and only if $A$ is the rotation matrix or the reflection matrix. My Progress: It can be shown that if $A$ is either the rotation or reflection matrix, then $A^T A = I$ holds by matrix multiplication. Where I get suck is showing that if $A$ is a $2 \times 2$ orthogonal matrix, then $A$ must either be the Rotation or Reflection Matrix. I suppose that since $A$ is orthogonal, it is distance preserving - and the only $2 \times 2$ matrices that preserve distance are the Rotation and Reflection Matrices, but this isn't really a proof.","['matrices', 'linear-algebra']"
2924298,Is a monoid commutative if $(ab)^2=a^2b^2$?,"Let M be a monoid. Suppose that:
$(ab)^2=a^2b^2$
for any elements a,b in M. Is M commutative? The result is obviously true for groups, but I can't find a counterexample for monoids. And without cancellation law, I can't seem to show that it's true either.","['monoid', 'abstract-algebra', 'semigroups']"
2924300,Why do metrics act on tangent vectors?,"Consider a manifold $M$ and a curve $\gamma : \mathbb{R} \supseteq I \rightarrow M$. The length of this curve is defined as $$ L = \int \sqrt{g(X,X)}_{\gamma(t)} dt $$ where $g$ is the metric tensor, $X$ is the tangent vector to the curve and $t$ is the parameter of the curve. I do not understand why we require a tangent space in order to calculate lengths of curves. I understand a metric tensor takes in two tangent vectors and spits out a number which allows us to calculate lengths and angles on manifolds, but why exactly do we require a metric defined in this way? Why is there no notion of length that is independent of tangent spaces and is in terms of the manifold alone?",['differential-geometry']
2924357,What is the probability to get more heads in n-1 tosses than in n tosses ? (fair coin),My approach so far is as follows: If $X_{n-2}$ is the number of heads in $n-2$ tosses then $E[X_{n-2}] = \frac{n-2}{2}$. So up to the $n-2$ toss it is all the same regardless if we end our experiment in $n$ or $n-1$ tosses. Then if we want to ensure that we get more heads in $n-1$ than in $n$ tosses: $P(X_{n-1} > X_{n}) = \frac{1}{2} \frac{1}{2.2} = \frac{1}{8}$ where $\frac{1}{2}$ is the probability of obtaining heads in the last toss out of $n-1$ and $\frac{1}{2.2}$ is the probability of obtaining two tails in the last two of $n$ tosses ? Does this make any sense ? And what is the general approach for problems like this ? Thanks in advance!,['probability']
2924382,Euler's totient function applied to higher power triples,"I've been working my way through the mathematics presented in this question: Pythagorean triples that ""survive"" Euler's totient function concerning Pythagorean triples $a^2+b^2=c^2$ for which it is also the case that $\phi(a^2)+\phi(b^2)=\phi(c^2)$ , where $\phi$ is Euler's totient function. Ignoring the occurrence of exponents, there are many triples $x+y=z$ for which $\phi(x)+\phi(y)\ne \phi(z)$ e.g. $5,7,12$ , and conversely many triples $x+y\ne z$ for which $\phi(x)+\phi(y)=\phi(z)$ e.g. $3,7,16$ . So there seems to be nothing special about choosing triples whose members are squares other than the limiting condition it places on the triples being looked at, and the interesting answers it affords. Fermat's Last Theorem establishes that there are no natural number triples $a,b,c$ such that $a^n+b^n=c^n$ for $n>2$ . In light of the cited question, I am curious: Are there any triples such that $$\phi(a^n)+\phi(b^n)=\phi(c^n)$$ for $n>2$ . Of greatest interest would be triples that are non-trivial in the sense that $0<a<b<c$ . I tried applying the logic in the cited question, using numbers sharing common prime factors, but I became a bit overwhelmed. By reference to the specific example of that question, it is certainly the case that $\phi(90^3)+\phi(120^3)\ne \phi(150^3)$ . So the simple expedient of choosing triples whose members have common factors does not necessarily yield examples. Furthermore, I suspect that it is unlikely that $a,b,c$ can each be prime numbers, as the relationship $a^{n-1}(a-1)+b^{n-1}(b-1)=c^{n-1}(c-1)$ looks unpromising (but I would enjoy being surprised). I don't have the programming skills to examine this question computationally, so I am asking for any help or insight the community can provide, either by way of examples or proofs.","['number-theory', 'pythagorean-triples', 'totient-function', 'elementary-number-theory']"
2924391,Direct proof of Closed Graph Theorem (or Bounded Inverse Theorem) from Uniform Boundedness Principle,"I'm looking for a direct proof of the Closed Graph Theorem (or Bounded Inverse Theorem) from the Uniform Boundedness Principle. But I can't find one in the literature. I'm hoping there's a nice proof of the Closed Graph Theorem of the following form. Let $T:X \to Y$ be a closed linear map between Banach spaces. 
Define a family $\{T_{\alpha}\}_{\alpha \in A}$ of bounded linear maps from $X$ to $Y$ (or from $X$ to another normed space $Z$ ) such that $\sup_{\alpha \in A} \| T_{\alpha}(x) \| < \infty$ for all $x \in X$ and $\| T \| \leq \sup_{\alpha \in A} \| T_{\alpha}\|$ . Conclude using Uniform Boundedness Principle. Of course, coming up with the family $\{T_{\alpha}\}_{\alpha \in A}$ is the hard part. Similarly/Alternatively, I'd be very happy to see a proof of the Bounded Inverse Theorem of the following form. Let $T:X \to Y$ be a bounded linear bijection between Banach spaces. 
Define a family $\{S_{\alpha}\}_{\alpha \in A}$ of bounded linear maps from $Y$ to $X$ such that $\sup_{\alpha \in A} \| S_{\alpha}(y) \| < \infty$ for all $y \in Y$ and $\| T^{-1} \| \leq \sup_{\alpha \in A} \| S_{\alpha}\|$ . Conclude using Uniform Boundedness Principle. I was inspired by this proof of the Uniform Boundedness Principle from the Closed Graph Theorem: https://math.stackexchange.com/a/1473367/570438 It looks at the map $\Phi(x) = (T_{\alpha}(x))_{\alpha \in A}$ , which maps $X$ to the space of bounded maps in $Y^A$ . A similar question was asked here before, but without a satisfactory answer: Does the Closed Graph Theorem follow from Banach-Steinhaus? Theorem 27.26-27.31 of Schechter's Handbook of Analysis and its Foundations gives a indirect argument. Relatedly, the argument is adapted to give a direct proof of the Open Mapping Theorem from the Uniform Boundedness Principle here: https://mathoverflow.net/questions/190587/is-there-a-simple-direct-proof-of-the-open-mapping-theorem-from-the-uniform-boun I am aware of the standard arguments for the implications Open Mapping Theorem $\Leftrightarrow$ Bounded Inverse Theorem $\Leftrightarrow$ Closed Graph Theorem. Edit: Cross-posted at MO: https://mathoverflow.net/questions/311275/direct-proof-of-closed-graph-theorem-or-bounded-inverse-theorem-from-uniform-b","['functional-analysis', 'analysis']"
2924409,"Prove that $ |x-a|<b \iff x∈(a-b,a+b)$","I am not sure if I am doing this correctly, my forward proof is: Since $|x-a|$ is an absolute value function, it can be defined as $|x-a|:= \max\{(x-a),-(x-a)\}$ . Let $S={(x-a) ∈ ℝ}$ and $b ∈ S, b>0,$ then $ x-a>b x>b+a $

 2.-(x-a)>b

   -x+a>b

   -x>b-a

    x<a-b which prove that x ∈ (a − b, a + b) Am I doing this correctly, and how can I prove the backward? Edit:
What I am thinking about the backward equation: a-b < x , then a-b-x<0,  next -(a-b-x)>0,  so -(a-b-x)>(a-b-x) -->max = a-b-x a+b>x , then a+b-x<0,  next -(a+b-x)>0,  so -(a+b-x)>(a-b-x) --> max= a+b-x then I am stuck.","['algebra-precalculus', 'absolute-value', 'inequality']"
2924466,"find $A,B$ in way that $f:A\rightarrow B$ is bijective, when $f(x)=\sqrt{x^2-1}$","Problem find $A,B$ in  way that $f:A\rightarrow B$ is bijective, when $f(x)=\sqrt{x^2-1}$ . Attempt to solve map $f:A \rightarrow B$ is bijective when it's surjective and injective simultaneously. This map is injective when: $$ \forall(x,y) \in A : x \neq y \implies f(x) \neq f(y)  $$ This map is surjective when: $$ \forall y \in B \exists x \in A : f(x)=y $$ if function $f(x)$ is ""truly"" monotonic it implies that function has to be injective. Observation: $$ \forall x \in \mathbb{R} : \frac{d}{dx}f(x) \neq 0$$ $$ \frac{d}{dx}\sqrt{x^2-1}=\frac{x}{\sqrt{x^2+1}} = f'(x) $$ It is visible that only way $f'(x)$ could be zero is when $x=0$ but $\sqrt{-1}$ is not defined in $\mathbb{R}$ which implies that $f(x)$ is injective if we pick $A$ in a way: $$ A\in \mathbb{R}\setminus[-1,1] $$ and $B$ : $$ B \in \mathbb{R} $$ we have map: $$ f:\mathbb{R}\setminus[-1,1] \rightarrow \mathbb{R} $$ Inverse function of $f(x)$ can be computed by solving y from following equation. Inverse function is map $f^{-1}:B \rightarrow A$ $$ \sqrt{x^2-1}=y $$ $f(x)$ is defined when : $x^2-1 \ge 0 \implies x^2\ge 1 \implies -1 \ge x \ge 1$ $$ x^2-1=y^2 $$ $$ x^2=y^2+1 \implies x=\pm \sqrt{x^2+1} $$ $$ h^{-1}(x)=\sqrt{x^2+1} $$ meaning $f(x)$ is surjective. Which implies $f(x)$ is bijective when: $$ A\in \mathbb{R}\setminus[-1,1], B \in \mathbb{R} $$","['functions', 'proof-verification', 'real-analysis']"
2924495,Prove that $P(A \cap B ) \geq 1 - P(\bar{A}) - P(\bar{B})$,"Prove that $P(A \cap B ) \geq 1 - P(\bar{A}) - P(\bar{B})$ This is what I got: So I know that $P(A \cup B) = P(A) + P(B) - P(A \cap B)$ Rearranging for $P(A \cap B)$ $P(A \cap B) = P(A) + P(B) - P(A \cup B)$ Substitute $P(A) = 1-P(\bar{A})$ and $P(B) = 1-P(\bar{B})$ $P(A \cap B) = 1 - P(\bar{A}) - P(\bar{B}) + 1 - P(A \cup B)$ Substitute $P(\overline{A \cup B}) = 1 - P(A \cup B)$ $P(A \cap B) = 1 - P(\bar{A}) - P(\bar{B}) + P(\overline{A \cup B})$ So $P(A \cap B) \geq 1 - P(\bar{A}) - P(\bar{B}) \enspace\enspace\enspace \text{ Since } P(\overline{A \cup B})\leq 1$ I'm not sure if my proof is correct or not and wanted to ask for some verification and correction if i'm wrong. Sorry if the structure is messy, I'm not that familiar with latex.","['proof-verification', 'probability']"
2924497,Showing $\cos \left( \frac{1}{n} \right) > 1 - \frac{1}{2n^2}$ [duplicate],"This question already has answers here : Showing that $1 - \frac{x^2}2\leq\cos x$, $\forall x \in \mathbb{R}$ (4 answers) Closed 5 years ago . I'm interested in showing the inequality $$ \cos\left(\frac{1}{n}\right) > 1-\frac{1}{2n^2}$$ For all $n$ positive integer. I've tried to proceed by induction and it's easily seen (assuming properties of trigonometric functions) that it holds for $n=1$ but I get stuck on showing it for $n+1$ . Once $\cos(x)$ is decreasing on $[0,1]$ we have $$\cos\left(\frac{1}{n+1}\right) > \cos\left(\frac{1}{n}\right) > 1- \frac{1}{2 \, n^2}.$$ But I don't know how to get it from here.","['trigonometry', 'induction', 'inequality', 'real-analysis']"
2924513,Trouble understanding how the Transfer Principle is applied for the Extreme Value theorem.,"I am reading Keisler's Elementary Calculus (which can be downloaded here ). I am having trouble understanding his proof sketch of Extreme Value Theorem and how he is applying the Transfer Principle. For reference, he defines the ""Transfer Principle"" as: Every real statement that holds for one or more particular functions holds for the hyperreal natural extension of these functions. On page 164 (using left corner numbering) of the book he provides the following ""sketch"": I understand the counter examples and I am able to understand the issues with them using standard tools. I don't understand, however, how one can immediately utilize the Transfer Principle. It is not immediately obvious to me that ""there is a partition point $a + K\delta$ at which $f(a + K\delta)$ has the largest value."" To elaborate, the proof seems circular. In trying to to ""expand"" the sketch to be more precise. I ended up writing instead of: By the Transfer Principle, there is a partition point $a + K\delta$ at which $f(a + K\delta)$ has the largest value. To: Applying the Transfer Principle to the Extreme Value Theorem we see that the Extreme Value holds for hyperreals as well. Hence, there is a partition point $a + K\delta$ at which $f(a + K\delta)$ has the largest value. But this relies on a proof of the Extreme Value Theorem for reals. Hopefully what I am saying makes sense, please ask for any clarification.","['extreme-value-theorem', 'calculus', 'nonstandard-analysis']"
2924555,Real matrix $A_{3\times 3}$ such that $\operatorname{tr(}A)=0$ and $A^2+A^T=I$?,"I'm dealing with the test of the International Mathematics Competition for University Students, 2011, and I've had a lot of difficulties, so I hope someone could help me to discuss the questions. The question 2 says: Does exist a real matrix $A_{3\times 3}$ such that $\operatorname{tr}(A)=0$ and $A^2+A^T=I$ ? The only thing I could get in that problem is that if $A$ exists, so $\operatorname{tr}(A^2)=3$ , because $\operatorname{tr}(A^2+A^T)=\operatorname{tr}(I)\Longrightarrow $ $\operatorname{tr}(A^2)+\operatorname{tr}(A^T)=3\Longrightarrow $ $\operatorname{tr}(A^2)+\operatorname{tr}(A)=3\Longrightarrow $ $\operatorname{tr}(A^2)=3$ Thanks for the help.","['contest-math', 'trace', 'linear-algebra']"
2924578,"If $E(U|X)=0$, then $E(U)=0$?","If $U$ and $X$ are random variables such that $E(U|X)=0$ , then $E(U)=0$ . Really? how to prove?",['statistics']
2924598,Solving a 2-variable differential equation using logarthmic differentiation,"Let $f(x,k): \mathbb{R}^2_+\rightarrow \mathbb{R}_+$ be the following function, $$\dfrac{2kx}{x+c},$$ where $c$ is some positive constant. I'm essentially trying to figure out the ""elasticity"" of this equation between variables $k$ and $x$ (this is just context, and understanding of the concept is not required for the maths). Let $f_x$ be $df(x,k)/dx$ , and $f_k$ be $df(x,k)/dk$ . Then what is, $$\frac{dln(x/k)}{dln(f_k/f_x)}?$$ I know that this becomes the following, $$\frac{d(x/k)}{x/k}/\frac{d(f_k/f_b)}{f_k/f_x}$$ Given that $f_x=\frac{2kc}{(x+c)^2}$ , and $f_k=\frac{2x}{x+c}$ , this is $$\frac{d(x/k)}{x/k}/\bigg(\frac{d(f_k/f_b)}{x(x+c)/kc}\bigg).$$ But how do I evaluate what's left? I'm used to derivatives, and not so much to differentiation expressions.","['calculus', 'ordinary-differential-equations', 'real-analysis']"
2924636,Condition of being a measure,"I'm working on a measure theory problem and I'm completely stumped. I'm trying to find out for which integers $j$ , $\mu$ will be a measure on $(\mathbb Z_+, \mathcal P(\mathbb Z_+))$ where $\mu$ is defined to be: $$
\mu(E)=
\begin{cases}
 \sum_{n\in E}n^j&\text{if}\, c(E)< \infty\\
 \infty&\text{if}\, c(E) = \infty\\
\end{cases}
$$ * $c$ is the counting measure here. I think I can simply consider finite sets or countable union of disjoint sets { ${A_n}$ } $_{n=1}^\infty$ where for some $N$ , $A_n = \varnothing$ where $n\geq N$ . Satisfying $\mu(\varnothing)$ = $0$ is trivial, and since we are on $\mathbb Z_+$ , $\mu(E) \geq 0$ for every $E \in \mathcal P(\mathbb Z_+)$ . I think countable additivity would impose some condition on $j$ , but not really sure of the point of attack here. Any help is appreciated!","['measure-theory', 'analysis', 'real-analysis']"
2924678,Seeking a special topology on $\mathbb{N}$,"Is there any topology on $\mathbb{N}$ such that every continuous map to a topological space (continuous sequence) is equivalent with convergence of that sequence in the classical sense?? Formally, if $X$ is a topological space, we want a topology on $\mathbb{N}$ such that for every function $f:$ $\mathbb{N}$$\mapsto$$X$ , $f$ is continuous if and only if the sequence $f_n$ (the function $f$ ) is convergent in the classical sense ,(there exists a $x$ on $X$ such that for every neiborhood $U$ of $x$ , there exists a natural number $n_0$ such that for every $n>n_0$ $f_n$ lies on $U$ ). I first thought the topology $T=\{\{n,n+1,n+2,...\} | n\in\mathbb{N}\}$ , but it turns out that every continuous sequence with that topology must be constant, so that topology is inadequate for that purpose.","['general-topology', 'convergence-divergence']"
2924686,When will the complement of a hypercube be bipartite?,"I know that every hyper cube is bipartite, but I am lost when it comes to their complements... I'm try to go off the theorem that ""A graph is bipartite if and only if it does not contain any odd cycles"", but I am having a hard time visualizing exactly when a hyper cube has odd cycles. Any hints to tackle this would be appreciated.","['graph-theory', 'discrete-mathematics']"
2924834,Meaning of the leibniz notation for the derivatives of parametric equations,"I'm trying to understand the meaning behind the leibniz notations when taking the derivative of a parametric equation. Say we have $x=f(t)$ and $y=g(t)$ Why does the derivative of this equal $\frac{\frac{dy}{dt}}{\frac{dx}{dt}}$ ?
I guess what I'm trying to ask is, how does the ""derivative of $y$ with respect to $t$ "" over ""derivative of $x$ with respect to $t$ "" equal ""derivative of $y$ with respect to $x$ ""? And what happens when I want to take a second derivative of a parametric equation? How would that work?","['notation', 'calculus', 'derivatives']"
2924838,Cat / mouse probability question,"There exist 7 doors numbered in order from 1 to 7 (going from left to right).  A mouse is initially placed at center door 4.  The mouse can only move 1 door at a time to either adjacent door and does so, but is twice as likely to move to a lower numbered door than to a higher numbered door each time it moves 1 door.  There are cats waiting at doors 1 and 7 that will eat the mouse immediately after the mouse moves to either of those 2 doors. So for example, the mouse starts at door 4.  He could then move to door 3, then to door 2, then back to 3, then back to 2, then to door 1 where he gets eaten.  That counts as 5 moves total.  Skipping doors is not allowed. So there are 2 questions I have regarding this: 1) What is the expected average number of moves before the mouse gets eaten?  (do not count the initial start at door 4 as a move but count any final move to doors 1 or 7 and any ""intermediate"" moves between those 2 states). 2) What is the probability that the mouse will survive for 100 or more moves?",['probability']
2924843,Average change for an implicitly defined function,"I was wondering if there is a way to compute the average change for an implicitly defined function such that as the interval of a change decreases, we converge to the derivative. For a ""standard"" function such result is easy to obtain. Suppose we have $y=f(x)$ and want to find the average change in $f(x)$ as $x$ changes from $x_0$ to $x_0+h$ . In that case, we have the $$ \frac{\Delta y}{\Delta x}:= \frac{y(x_0+h)-y(x_0)}{x_0+h-x_0}=\frac{f(x_0+h)-f(x_0)}{(x_0+h) - x_0},$$ and as $h \rightarrow0$ the average change in $f$ converges to $f'$ ; that is, $$ lim_{h\rightarrow 0}\frac{\Delta y}{\Delta x} = \frac{d y}{dx} $$ My question : Is there an equivalent expression/relationship for an implicitly defined function? My Attempt :
Let $f(x,y(x))=0$ and suppose I want to compute the average change in $y(x)$ as $x$ varies from $x$ to $x+h$ . We know that $$ f(x+h,y(x+h))=0$$ Subtracting from the above equation $f(x,y(x))$ , and performing simple manipulations, I obtain $$ \frac{f(x+h,y(x+h))-f(x+h,y(x))}{y(x+h)-y(x)}(y(x+h)-y(x)) + \frac{f(x+h,y(x))- f(x,y(x))}{h}h =0$$ Rearranging, I obtain: $$ \frac{y(x+h))-y(x)}{(x+h)-x} = - \frac{\frac{f(x+h,y(x))- f(x,y(x))}{h}}{\frac{f(x+h,y(x+h))-f(x+h,y(x))}{y(x+h)-y(x)}} $$ If I define $\Delta y:= y(x+h)-y(x)$ and $\Delta x:= (x+h)-x$ , then I have $$ \frac{\Delta y}{\Delta x} = - \frac{\frac{f(x+h,y(x))- f(x,y(x))}{h}}{\frac{f(x+h,y(x+h))-f(x+h,y(x))}{y(x+h)-y(x)}}, $$ which seems intuitive and seems to capture the average change in y(x) over interval [x,x+h]. Next, I would like to take the limit as $h\rightarrow 0$ and show that the above expression converge to the derivative of $y(x)$ that we obtain by applying the implicit function theorem. When I take the limit as $h\rightarrow 0$ on the LHS, I can see that the numerator converges to $f_x(x,y)$ ; but I am not sure how to deal with the denominator. Does the denominator converge to $f_y(x,y)$ ? Or is there another way to link the average change in $y$ over interval $[x,x+h]$ to $dy/dx$ .","['real-analysis', 'multivariable-calculus', 'calculus', 'limits', 'derivatives']"
2924857,Identical Function Query,"If $f(x)=\frac{x}{\ln x}$ & $g(x)=\frac{\ln x}{x}$ . Then identify the correct statement. A) $\frac{1}{g(x)}$ and $f(x)$ are identical functions B) $\frac{1}{f(x)}$ and $g(x)$ are identical functions C) $f(x)\cdot g(x)=1 \forall x>0$ D) $\frac{1}{f(x)\cdot g(x)}=1 \forall x>0$ I don't have the solution but as per the answer key Only A is the correct statement , B,C,D are incorrect statement . My Approach for B let $t(x)=\frac{1}{f(x)}$ , now the question is whether $t(x)$ & $g(x)$ are identical function, my thought would be that they are identical function because for identical function we need to check domain and range on $t(x)$ and not on its reciprocal.But on contrary in the ANSWER Key this is mentioned as INCORRECT . Regarding C and D I don't know why it is incorrect.",['functions']
2924863,"Bijection between $\mathbb R^2$ and $(0,1)$","[TIFR GS-2013, Part D] Does there exist any bijection between $\mathbb R^2$ and the open interval $(0,1)$ ?? At the first glimpse, I thought about the function $f: \mathbb R^2 \to (0,1)$ defined by $f(x,y) = {0.2}^{x}{0.3}^{y}$ . But then I realized that the preimage of any element in $(0,1)$ may not be unique. Here I am stuck with finding any example. Any help would be appreciated.",['functions']
2924870,Cardinal of a finite set is unique,"I have been thinking about how I can prove whether a cardinal of a finite set is unique, after some thoughts I figured out it would be better to prove it in such a way, If $n \in \mathbb{N}$ , then there is no one-to-one mapping of $\mathbb{N}$ onto a proper subset $X \subset \mathbb{n} $ I tried to prove it by induction on $\mathbb{n}$ that for $\mathbb{n}=0$ it is trivial. if we assume that it is true for $\mathbb{n}$ then we should prove it for $\mathbb{n+1}$ but I don't know how to go further.","['elementary-set-theory', 'cardinals']"
2924881,Intuition behind why being integral over a ring is important,"I'm currently in an algebraic geometry class and many of our proofs and lemmas have to do with some element $w$ being integral over a ring. The proofs end up working out, but I have trouble understanding why this is an important property to have (being the root of a monic polynomial) and what intuition I should have behind it. For example, consider: $R \subset F, \space L=Frac(R). Let \space w \in I$ be algebraic over $R$ . Then $\exists \space p \in R,p≠0$ s.t. $pw$ is integral over R.","['algebraic-geometry', 'commutative-algebra']"
2924885,Discussing Whether Solutions to ODE Exist for all $t \in \mathbb{R}$,"I am asked whether any solution for $y''+y'+y+y^3 =0$ exists for all $t \in \mathbb{R}$ . Here is what I am thinking: First, introduce a change of variables $z_1 = y$ , $z_2 = y'$ so that the equation given becomes the 1st order system: \begin{equation}
\pmatrix{z'_1\\z_2'}=\pmatrix{0&1\\-1&-1}\pmatrix{z_1\\ z_2} +\pmatrix{0\\-z_1^3}
\end{equation} After computing the Jacobian, we get that: $\frac{\partial F}{\partial y} = \pmatrix{0&1\\-1-3z_1^2&-1}$ Now, we need to check whether $F(z_1,z_2)=\pmatrix{0&1\\-1&-1}\pmatrix{z_1\\ z_2} +\pmatrix{0\\-z_1^3}$ is Lipschitz. Clearly, $F$ is continuous (component wise). Note then if we compute the operator norm of the Jacobian, we get (using the sup norm): $\left\lVert\frac{\partial F}{\partial y}\right\rVert_\infty = \max$ { $|1|$ , $|1+3z_1^2|+|1|$ } Since $3x^2 +1 \neq 0$ for $x \in \mathbb{R}$ , then the above expression is just \begin{equation}
1 +|3z_1^2 +1| \leq 2 +3|z_1|^2
\end{equation} Because of the $z_1$ term above, then the Jacobian is not bounded. Thus, $F$ cannot be (globally) Lipschitz. If we did assume that $z_1 =  y$ was bounded beforehand, then it might work. However, we're not given any further assumptions. I am aware that there are alternate methods to solving this problem, maybe finding a potential function $V(y)$ and checking if $V'(y) \leq 0$ . However, I don't want to go that route, as we can only use material we've covered so far. We just got to linear systems last lecture. Does this work? I feel there's something I am overlooking.","['lipschitz-functions', 'ordinary-differential-equations', 'dynamical-systems']"
2924934,Maximal subgroups that force solvability.,"For which finite groups $M$ is it the case that every finite group $G$ with $M$ as a maximal subgroup solvable? If $M$ satisfies this condition then $M$ is solvable. Also, if $M$ is abelian then $M$ satisfies this condition . Futhermore, I believe that if $M$ is nilpotent and if all 2-subgroups of $M$ are normal subgroups of $M$ (if Sylow 2-subgroups of $M$ are abelian or quaternion, for example) then $M$ satisfies this condition (proof below). More specific questions: 1) Is there a non-nilpotent group that satisfies this condition? 2) Which 2-groups satisfy this condition? Apparently, the dihedral group of order 8 satisfies this condition (see Mikko Korhonen's comment on this post).
Also, if $M\times N$ satisfies this condition then $M$ and $N$ both satisfy this condition. (This proof is adapted from j.p.'s answer to the linked question).
Let $G$ be minimal such that $G$ is not solvable and such that $G$ contains a maximal subgroup $M$ that is nilpotent and whose 2-subgroups are normal. If $M$ contains a nontrivial normal subgroup $N$ of $G$ then $G/N$ contradicts the minimality of $G$ . Thus, $M$ does not contain nontrivial normal subgroups of $G$ . In particular, $N_G(P)=M$ for all Sylow $p$ -subgroups $P$ of $M$ . Then $P$ is a Sylow $p$ -subgroup of $N_G(P)$ so $P$ is a Sylow $p$ -subgroup of $G$ . This shows that $M$ is a Hall subgroup of $G$ . If $P$ is a Sylow $p$ -subgroup of $M$ and if $Q$ is a nontrivial normal subgroup of $P$ then $N_G(Q)=M$ which has a normal $p$ -complement. For $p=2$ , Frobenius' normal $p$ -complement theorem gives that $G$ has a normal $p$ -complement. For $p\geq3$ , Thompson's normal $p$ -complement theorem or Glauberman's normal $p$ -complement theorem gives that $G$ has a normal $p$ -complement (since you only have to consider characteristic $p$ -subgroups). Thus, for each prime $p$ dividing the order of $M$ , $G$ has a normal $p$ -complement. Then $M$ has a normal complement $N$ in $G$ . Since $M$ is solvable but $G$ is not solvable, $N$ is not solvable. In particular, $N$ does not admit a fixed-point-free automorphism of prime order. If $m\in Z(M)$ has prime order then $C_N(m)$ is nontrivial. Then $C_N(m)M$ is a subgroup of $G$ that properly contains $M$ so $C_N(m)M=G$ by the maximality of $M$ . Comparing cardinalities shows that $C_N(m)=N$ so $m\in Z(G)$ . Then $\langle m\rangle$ is a nontrivial normal subgroup of $G$ contained in $M$ which is a contradiction.","['group-theory', 'finite-groups', 'solvable-groups']"
2924946,Interesting examples of commutative linear algebraic groups; uniqueness of composition series,"We define an algebraic group to be solvable if it has a filtration where the successive quotients are abelian. The Lie-Klochin theorem says that every smooth solvable connected group admits an embedding into the Borel subgroup of $GL_n$ . But the Borel subgroup o $GL_n$ has a filtration where the successive quotients are $\mathbb{G}_m's$ and $\mathbb{G}_a's$ . Therefore it seems like there are really no examples of abelian linear algebraic groups other than $\mathbb{G}_m's$ and $\mathbb{G}_a's$ or tori and finite abelian groups. Unless the composition factors for a linear algebraic group need not be unique, unlike the case for finite groups. Are the composition factors for a linear algebraic group unique, and  if not, then what are some more interesting examples of abelian linear algebraic groups?","['group-theory', 'algebraic-geometry', 'linear-algebra', 'algebraic-groups']"
2924992,Well ordering principle for rationals,"Why can positive rationals be not well ordered?  If we define the relation to be greater than(>), then every subset will have a least element.  Or why are positive or even integers not well ordered?  By the same logic we can always find a least element in any subset.  I know I am wrong at some very fundamental point, but please explain it to me.","['elementary-set-theory', 'well-orders']"
2925028,Interpretation of one-dimensional p-laplacian,"Do you know some interpretation or practical application of one-dimensional p-Laplacian systems (which is also an example of Euler-Lagrange system) $
\frac{d}{dt}(|\dot u(t)|^{p-2}\dot u(t))=\nabla W(t,u(t)),
$ where $\nabla W(t,u)$ is the gradient $W$ in $u$ , $t\in\mathbb{R}$ , $u\in\mathbb{R}^N$ .
Or even more general system $
\frac{d}{dt} \nabla G(\dot{u}(t))=\nabla W(t,u(t)),
$ where $G$ is some convex, $C^1$ function? We know that in pde's one practical application is image denoising Intuition and applications for the p-Laplacian","['p-laplacian', 'ordinary-differential-equations', 'euler-lagrange-equation']"
2925031,Compactness of a metric space,"If a metric space $(X,d)$ is compact then for every equivalent metric $\sigma$ , $(X,\sigma)$ is complete. This is because, for any Cauchy sequence in $(X,\sigma)$ has a convergent subsequence due to fact $(X,\sigma)$ is a compact metric space, hence original sequence is convergent. My question is, does the converse also hold ? In other words, let $(X,d)$ be a metric space such that for every equivalent
metric $\sigma$ on $X$ is complete. Does this imply $(X,d)$ is
compact?","['complete-spaces', 'metric-spaces', 'real-analysis', 'general-topology', 'compactness']"
2925081,connected set of sum of upper semi continuous function,"Let $C(X)$ :space of continuous functions on a compact space. Consider $f$ and $g :C(X)\rightarrow \mathbb{R}$ are upper semi continuous. suppose  for every $T\in C(X)$ set of $f(T)$ and  set $(f+g)(T)$ are closed interval(connected set).Can we say set of $g(T)$ is closed interval(connected set),as well? If Not,under which condition we have it.","['harmonic-analysis', 'analysis', 'real-analysis', 'continuity', 'functional-analysis']"
2925133,The Baire space as an automorphism group?,"Wikipedia claims that the Baire space ""is [the] automorphism group of [a] countably infinite saturated model $\mathfrak{M}$ of some complete theory $T$ "", however I see neither an obvious group structure on $\mathcal{N}$ nor an obvious topology on $\operatorname{Aut}(\mathfrak M)$ for a generic $\mathfrak M$ . How is this claim to be interpreted and what can be said about $T$ ?","['general-topology', 'the-baire-space', 'descriptive-set-theory', 'model-theory']"
2925145,Ask a about hard integral of $\int_{0}^{\infty} \log x \log (\frac{a^2}{x^2}+1) \log(\frac{b^2}{x^2}+1)dx$,"I want to evaluate the integral: $$I(a,b)=\int_{0}^{\infty} \log x \log (\frac{a^2}{x^2}+1) \log(\frac{b^2}{x^2}+1)dx$$ Attempt: $$\frac{\partial ^2I}{\partial a\partial b}=4ab\int_{0}^{\infty}\frac{\log x}{(a^2+x^2)(b^2+x^2)}dx=\frac{4ab}{b^2-a^2}\int_{0}^{\infty}\log x\left(\frac{1}{a^2+x^2}-\frac{1}{b^2+x^2}\right)dx$$ $$=\frac{4ab}{b^2-a^2}\frac{\pi}{2}\left(\frac{\log a}{a}-\frac{\log b}{b}\right)=\frac{2\pi(b\log a-a\log b)}{b^2-a^2}$$ Then $$I(a,b)=2\pi\int_{0}^{b}\int_{0}^{a}\frac{(y\log x-x\log y)}{y^2-x^2}dxdy$$ But this integral very hard to solve,can anyone help me,thank you!","['integration', 'calculus', 'definite-integrals', 'real-analysis']"
2925151,Ratio of series $A$ and $B$ is an integer.,"Let $$ A= {1\over 1\cdot 2}+\color{red}{1\over 3\cdot 4}+...+ {1\over 1997\cdot 1998}$$ and $$B= {1\over 1000\cdot 1998}+{1\over 1001\cdot 1997}+...+ {1\over 1997\cdot 1001}+{1\over 1998\cdot 1000}$$ Prove that $A\over B$ is an integer. I could only find that $$ A= 1-{1\over 1998}$$ using standard trick ${1\over x(x+1)} = {1\over x}-{1\over x+1}$ . But I could not find answer for the second one. It is supposed to be a task for 15 years old (Romanian) children! Edit I write it down wrong, so the $A$ is not correctly calculated. And it is different $A$ as in suggested duplicate.","['contest-math', 'algebra-precalculus']"
2925233,"If $\sin^8\theta+\cos^8\theta=\frac{17}{32}$, find the value of $\theta$ using de Moivre's theorem.",If $$\sin^8\theta+\cos^8\theta=\frac{17}{32}$$ find the value of $\theta$ using  de Moivre's theorem. I tried a lot exapanding using Binomial theorem and taking real part and equating it given value.,"['trigonometry', 'complex-numbers']"
2925282,"Finding an orthonormal basis of $L^2[0,1]$ consisting of elements from $C[0,1]$","Problem: Let $f \in L^1[0,1]$ but $f\notin L^2[0,1]$ . Is there an orthonormal basis of $L^2[0,1]$ consisting elements {g_n} in $C[0,1]$ such that $\int g_n f = 0$ ? To start with, one can show that $\{g \in L^2[0,1]| \int gf = 0\}$ is dense in $L^2[0,1]$ . It follows that one is able to extract an orthonormal basis out of this subspace. It remains to show further that this basis can be chosen from the subspace of $C[0,1]$ if possible. I wonder whether this is correct and how to finish the last step.","['functional-analysis', 'real-analysis']"
2925286,"If a hypersurface has a self-intersection point, then the second fundamental form it is negative in a neighborhood of this point","I'm studying by myself Mean Curvature Flow and I'm reading Lecture Notes on Mean Curvature Flow by Xi-Ping Zhu. The doubt of the title of this topic arised when I read the proof of the following result: $\textbf{Corollary 2.7 (Preserving convexity)}$ Let $X(\cdot, t)$ be a solution of the mean curvature flow. Suppose the initial hypersurface $X(\cdot,0)$ is a convex and compact hypersurface, then $X(\cdot,t)$ is also a convex and compact hypersurface for $t > 0$ . $\textbf{Proof.}$ Applying the strong maximum principle, we know that $H(\cdot, t) > 0$ for $t > 0$ . Combining Proposition $2.6$ , we deduce that the second fundamental form of $X(\cdot, t)$ is positive definite for $t > 0$ . To show $X(\cdot, t)$ remains embedded, we argue by contradiction. Suppose for some first time $t_0 > 0$ the solution $X(\cdot, t)$ develops a self-intersection. Clearly, at this self-intersection point, there must be a piece of hypersurface which has negative second fundamental form. This contradicts with the fact the second fundamental form of $X(\cdot, t)$ is positive definite everywhere for $t > 0$ . $\square$ I didn't understand this part: Clearly, at this self-intersection point, there must be a piece of hypersurface which has negative second fundamental form. It seems to be a well-known result, but I didn't find this result. Can anyone indicate a reference for this result? Thanks in advance!","['proof-explanation', 'mean-curvature-flows', 'riemannian-geometry', 'differential-geometry']"
2925295,"For any $a$, can we find $b$ and $c$ such that $\phi(a^2)+\phi(b^2)=\phi(c^2)$? ($\phi$ is Euler's totient function.)","This question was inspired by the discussion in: Euler's totient function applied to higher power triples . Keith Backman suggested that perhaps there are many solutions to the following equation: $$\phi(a^2)+\phi(b^2)=\phi(c^2) \tag{1}\label{1}$$ Without loss of generality I will assume $a \leq b$ . Is there a solution to $\eqref{1}$ with some $b$ and $c$ values, for any given value of a? For example with $1 \leq a \leq 4$ there is are solutions: $$\phi(1^2)+\phi(1^2)=\phi(2^2)$$ $$\phi(2^2)+\phi(3^2)=\phi(4^2)$$ $$\phi(3^2)+\phi(7^2)=\phi(12^2)$$ $$\phi(4^2)+\phi(6^2)=\phi(5^2)$$ I created a program and verified there is a solution for $1 \leq a \leq 8500$ . And Peter's program verified up to $33000$ . I expect that the answer to my question is yes, but I don't know how I would begin proving it. Update I've made some progress in proving it for some cases of $a$ . Case 1 : $a$ is odd (Thanks to Peter's comment) Let $b = a$ and $c = 2 a$ $$\phi(a^2)+\phi(a^2)=\phi((2a)^2)$$ $$2\phi(a^2)=\phi(4a^2)$$ Since $a$ does not contain a prime factor of $2$ . It's totient can be calculated separately: $$2\phi(a^2)=\phi(4)\phi(a^2)$$ $$2\phi(a^2)=2\phi(a^2)$$ $\square$ Case 2 : $a$ contains at least two $2$ 's and no $5$ 's in its prime factorization Let $b = 2a$ and $c = \frac{5}{2}a$ . Let $n$ be the number of $2$ 's in the prime factorization of $a$ . Let $q$ be the prime factors of $a$ excluding all $2$ 's which may be present. Thus we can express $a$ as: $a = 2^nq$ $$\phi\lbrack(2^nq)^2\rbrack+\phi\lbrack(2\cdot2^nq)^2\rbrack=\phi\lbrack(\frac{5}{2}2^nq)^2\rbrack$$ $$\phi(2^{2n}q^2)+\phi(2^{2n+2}q^2)=\phi(5^2\cdot2^{2n-2}q^2)$$ Separate out the totient function because of the definition of $q$ : $$\phi(2^{2n})\phi(q^2)+\phi(2^{2n+2})\phi(q^2)=\phi(5^2)\phi(2^{2n-2})\phi(q^2)$$ $$\phi(2^{2n})+\phi(2^{2n+2})=\phi(5^2)\phi(2^{2n-2})$$ $$2^{2n-1}+2^{2n+1}=20\cdot2^{2n-3}$$ $$2^{2n-1}+2^{2n+1}=5\cdot2^{2n-1}$$ $$1+2^{2}=5$$ $\square$ Note where this proof would fail if $a$ was allowed to have a prime factor of $5$ . If there were one $5$ in the prime factorization then in order to divide both sides by $\phi(q^2)$ the expression "" $\phi(5^2 \cdot q^2)$ "" would become $25 \cdot \phi(q^2)$ instead of $20 \cdot \phi(q^2)$ . This would force b to require a different multiplier, but this would just be a wild goose chase since another prime factor would not be allowed! I found some alternate values of b and c that work for other cases (exactly one 2 in prime factor was one case), but nothing seems to come out cleanly because it just creates more restrictive cases.","['number-theory', 'totient-function', 'elementary-number-theory']"
