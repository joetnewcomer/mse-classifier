question_id,title,body,tags
2905976,Can we prove that $(\mathbb{Z}/p^{n}\mathbb{Z})^{\times}$ is a cyclic group by using $p$-adic integer?,"It is well known that $(\mathbb{Z}/p^{n}\mathbb{Z})^{\times}$ is a cyclic group for a prime $p>2$ and $n\geq 1$. However, most of the proofs are a little complicated, and I want to find some neat proof of this. It is also known that the unit group $\mathbb{Z}_{p}^{\times}$ of $p$-adic integers is isomorphic to $(\mathbb{Z}/p\mathbb{Z})^{\times}\times (1+p\mathbb{Z}_{p})\simeq \mathbb{Z}/(p-1)\mathbb{Z}\times \mathbb{Z}_{p}$, where the latter isomorphism $(1+p\mathbb{Z}_{p}, \bullet)\simeq( \mathbb{Z}_{p}, +)$ is given by $\log$ map. I want to use this to prove that $(\mathbb{Z}/p^{n}\mathbb{Z})^{\times}$ is cylic. In fact, a sort of converse holds: assume that we knows $(\mathbb{Z}/p^{n}\mathbb{Z})^{\times}\simeq \mathbb{Z}/p^{n-1}(p-1)\mathbb{Z}$. Then we have
$$
\mathbb{Z}_{p}^{\times} = \lim_{\longleftarrow}(\mathbb{Z}/p^{n}\mathbb{Z})^{\times}\simeq (\mathbb{Z}/(p-1)\mathbb{Z})\times \lim_{\longleftarrow} \mathbb{Z}/p^{n-1}\mathbb{Z} \simeq \mathbb{Z}/(p-1)\mathbb{Z}\times \mathbb{Z}_{p},
$$
so we may reprove that $\mathbb{Z}_{p}^{\times}$ is isomorphic to $\mathbb{Z}/(p-1)\mathbb{Z} \times \mathbb{Z}_{p}$. Is there any nice way to reverse this argument so that we can prove $(\mathbb{Z}/p^{n}\mathbb{Z})^{\times} \simeq\mathbb{Z}/p^{n-1}(p-1)\mathbb{Z}$? Thanks in advance.","['number-theory', 'abelian-groups', 'p-adic-number-theory', 'torsion-groups']"
2906003,It's confusing to calculate Euler characteristic of this surface,"This pic below is an exploded view of a cone. I'm trying to calculate the Euler characteristic of the surface made from the fragment $M$, i.e., At first I thought the Euler characteristic is 0, but the one who made this question says it is actually 1. And this is actually a part of an exercise to find the total geodesic curvature of $\partial M$. I tried to figure it out using the Gauss-Bonnet theorem. I'm sorry that the question is not clear.
$M$ is the region between top circle of cone and closed geodesic meeting the top circle of cone at one point.",['differential-geometry']
2906052,Evaluating $\int_0^\infty\frac{\ln(1+x^2)}{e^{\pi x}-1}dx$,"I want to evaluate $$\int_0^\infty\frac{\ln(1+x^2)}{e^{\pi x}-1}\,\mathrm dx$$ I tried to let $$I(a)=\int_0^\infty\frac{\ln(1+a^2x^2)}{e^{\pi x}-1}\,\mathrm dx,$$ and then $$
\begin{align}
I'(a)&=\int_0^\infty\frac{2ax^2}{(1+a^2x^2)(e^{\pi x}-1)}\,\mathrm dx\\[25pt]
&=2a\int_0^\infty\mathscr L^{-1}\Big(\frac{x}{1+a^2x^2}\Big)\mathscr L\Big(\frac{x}{e^{\pi x}-1}\Big)\,\mathrm dx\\[25pt]
&=-2a^{-2}\pi^{-2}\int_0^\infty \sin\frac xa \psi^{(1)}\left(1+\frac x\pi\right)\,\mathrm dx
\end{align}
$$
I can't go further.","['integration', 'calculus', 'definite-integrals']"
2906074,What is the name of this result about isosceles triangles?,"$\Delta ABC$ is isosceles with $AB=AC=p$. $D$ is a point on $BC$ where $AD=q$, $BD=u$ and $CD=v$. Then the following holds. $$p^2=q^2+uv$$ I would like to know whether this result has a name.","['euclidean-geometry', 'triangles', 'geometry']"
2906091,"Is the normed linear space $X$ isometrically isomorphic to $Y$, if there is a linear operator $T: X \to Y$ such that $\|T\|=1$?","My question is if $\|T\|=1$ a sufficient condition for isometric isomorphism. If yes, how to prove it? If not, which additional conditions are needed? Perhaps $\|T^{-1}\|=1$ is necessary?","['isometry', 'normed-spaces', 'linear-algebra', 'functional-analysis']"
2906100,"When I say that $[0,1]/_\sim$ is the circle, do I have to prove it or it's obvious?","I saw on wikipedia that quotient topology doesn't behaves well in the sense that $X$ can be metrizable, haussdorf... but $X/_{\!\sim}$ not. We can see that gluing $0$ and $1$ in the segment $[0,1]$ gives the circle. But do I really have to prove it or such construction is clear by visualizing ? Same if I take $[0,1]\times [0,1]$ and I glue all point of the boundary in one, we "" see "" that it's going to be the sphere $\mathbb S^2$. Do I have to prove it rigorously, or it's not really necessary ? I'm asking this because in a course notes on manifold I'm reading, the teacher say always : ""we see that gluing $A$ and $B$ gives torus, or sphere or any geometric figure"", but  he doesn't prove it rigorously. I sent him an email yesterday, and he sais that such argument is enough to identify things. Is it really the case ? I mean, if the quotient doesn't behaves well, we have to prove rigorously that such identification gives the sphere or the torus (or anything else), no ? Can someone gives me an example where we expect that a quotient $X/_\sim$ we'll be a specific figure, but in fact it will not be ?","['manifolds', 'general-topology']"
2906101,A function that is in $C^k_b(\mathbb R)$ but not in $C^{k+1}_b(\mathbb R)$,"Is there an example of a family of functions, index by $k$ , that is in $C_b^k(\mathbb R)$ but not in $C_b^{k+1}(\mathbb R)$ for arbitrary $k$ ? $C_b^k(\mathbb R)$ is the space of functions with continuous and bounded derivatives up to $k$ .","['special-functions', 'functional-analysis']"
2906143,Is every monotonic additive function $f \colon \mathbb{R} \to \mathbb{R}$ continuous?,"Let a function $f \colon \mathbb{R} \to \mathbb{R}$ have the following two properties: (1) For all $x_1, x_2 \in \mathbb{R}$ such that $x_1 < x_2$, we have 
$$f \left( x_1 \right) \leq f \left( x_2 \right). $$ (2) For all $x_1, x_2 \in \mathbb{R}$,  we have 
$$f \left( x_1 + x_2 \right) = f \left( x_1 \right) + f \left( x_2 \right).  $$ Is such a function $f$ continuous at every point $c$ of $\mathbb{R}$? My Effort: We can show that for every rational number $q$, we have 
  $$ f(q) = q f(1). $$ As $f$ is monotonic (increasing), so the set of points of discontinuity of $f$ is at most countable. How to proceed from here? If we could show that $f$ is continuous at every rational point $c \in \mathbb{Q}$, then $f$ would also be continuous at every point of $\mathbb{R}$. Am I right? What next? Context : Sec. 5.6 (in fact immediately after Theorem 5.6.4) in the book Introduction To Real Analysis by Robert G. Bartle & Donald R. Sherbert, 4th edition.","['monotone-functions', 'analysis', 'real-analysis', 'continuity', 'calculus']"
2906196,Expectation value : trials with and without replacement,"Two cards are drawn at random from a deck of cards. Let X be the
  number of aces obtained. Then the value of E(X) is Direct Method $$
P(X=0)=P(\text{no ace})=\frac{{}^{48}C_2}{{}^{52}C_2}=\frac{48*47}{52*51}\\
P(X=1)=P(1 \text{ ace and }1\text{ non-ace})=\frac{{}^{4}C_1.{}^{48}C_1}{{}^{52}C_2}=\frac{4*48*2}{52*51}\\
P(X=2)=P(2 \text{ non-ace})=\frac{{}^{48}C_2}{{}^{52}C_2}=\frac{4*3}{52*51}
$$
$$
E(X)=\frac{384+24}{52*51}=\frac{408}{2652}=\frac{2}{13}
$$ Doubt In some references it is solved by considering it a Bernoulli trial, Pls check Method . If the experiment was with replacement, without doubt I'd say it a Bernoulli trial. $$n=2\\p=\frac{4}{52}=\frac{1}{13}\\
E(X)=np=2*\frac{1}{13}=\frac{2}{13}$$ Why do we have the expectation value matching the one with replacement (Bernoulli trial) ?","['statistics', 'binomial-distribution', 'probability']"
2906237,Solving A Factorial Inequality Without Trial And Error,"How does one solve the following inequality for $n$ , without trial and error, and assuming $n$ can only be an integer? The inequality is $(n+1)!-1>10^9$ . I want to find the minimum value of $n$ such that $(n+1)!-1>10^9$ . How does one do this without graphing the inequality, or using a calculator? I figured it out throwing trial and error on a calculator, but I desire a more elegant solution, one that gets to the answer algebraically, and without a calculator or graph. Any suggestions?","['algebra-precalculus', 'factorial']"
2906263,Introduction to von Neumann algebras,"I'm learning the basics of von Neumann algebras.
Every reference on the subject I can find turns to the study of projections, introduces factors and the type classification immediately after having only barely introduced what a von Neumann algebra is. This makes it hard to follow the references since I have no idea of what they are actually trying to do/accomplish by introducing these things. What I'm really asking is the following: Having introduced the definition of von Neumann algebras and the bicommutant Theorem, what are open questions one tries to solve immediately and leads to the study of projections, factors and type classification? Examples of von Neumann algebras which have interesting properties and help to solve my question are certainly welcome. Thanks in advance.","['von-neumann-algebras', 'c-star-algebras', 'functional-analysis']"
2906264,Rolle's theorem on $e^x\sin x-1=0$,"Prove that between any two real roots of the equation $e^x\sin x-1=0$ the equation $e^x\cos x+1=0$ has at least one root. My attempts: By Rolle's theorem, the derivative of $e^x\sin x-1=0$ has at least one root between the roots $(\text{let}\ a,b)$ of $e^x\sin x-1=0$ $$f'(x)=e^x\sin x +e^x\cos x=\overbrace{\underbrace{(e^x\sin x-1)}_{2). \text{ no root in}\ (a,b)} +\underbrace{(e^x\cos x+1)}_{1,2\implies\text{ no root in}\ (a,b)}}^{\text{1). at least one root in}\ (a,b)}=0,\ x\in(a,b)$$ I found alternative proof of this here , but please don't mark this as duplicate as I want to know what's the wrong with what is tried.","['roots', 'real-analysis', 'calculus', 'functions', 'rolles-theorem']"
2906268,Calculate a multiple Ito integral,"Consider the following multiple Ito integral, $$I(n)=\int\limits_0^t \int\limits_0^{t_n} \int\limits_0^{t_{n-1}} \dots \int\limits_0^{t_2}dW_{t_1} \, dW_{t_2} \, \dots \, dW_{t_n},$$ where $W_t$ is a standard Brownian motion. $I(1)=W_t$ $I(2)=\frac{1}{2}W_t^2-\frac{1}{2}t$ $I(3)=\frac{1}{6}W_t^3-\frac{1}{2}tW_t$ The first 3 terms seem to be elegant. I wonder whether there is a general term formula.","['stochastic-integrals', 'brownian-motion', 'probability-theory', 'stochastic-calculus']"
2906293,Optimal stopping time for coin toss with unkown bias,"I am working on a question that involves uncertainty and decision making, but I realized I am not making progress for a long time. That is why I formulated a more basic problem in the hope that I can make progress but I still don't know how to proceed. Suppose there is a game where at each stage $t$ we get a stochastic reward/loss. We can also choose to stop at any stage $t$ and move away with rewards collected until that stage. Let $X_t$ be the random variable that denotes the reward we get at $t$'th stage.
$$
X_t = +1 \text{ with probability } p\\
X_t = -1 \text{ with probability } 1 -p
$$
with $p$ unkown . We want to find $\tau$ such that
$$
\sum_{t = 0}^{\tau} \mathop{\mathbb{E}}[X_t]
$$
is maximized. If $p$ were known, this would not be an interesting problem because the decision of continuing or stopping does not depend on the outcomes of the coin. But since we do not know $p$, our decision depends on the previous outcomes, for example, we might find out that it was not logical to play the game at all ! The problem is similar to other exploration-exploitation problems but I could not find anything related to my problem. I tried estimating $p$ and then tried to find a threshold for stopping the game but could not succeed. I would appreciate any kind of comment, suggestion or references.","['optimal-control', 'stopping-times', 'probability']"
2906314,How to calculate angle between two vectors in 3D with clockwise or counter clockwise notation?,If I have vectors a and b sharing a common point of intersection then I know how to calculate angle between them by using the formula for dot product. But whether b lies to the right or left of a if I am moving along a can not be gotten from this. What would be the easiest way to find out whether b lies left or right of a?,"['trigonometry', 'angle', 'vectors', '3d']"
2906340,Find limit $\lim_{z\to 0}\frac{\bar z}{z}$,Evaluate $\lim_{z\to 0}\frac{\bar z}{z}$ where $z=x+iy$ My try: $$\lim_{z\to 0}\frac{\bar z}{z}=\lim_{z\to 0}\frac{x-iy}{x+iy}$$ $$=\lim_{z\to 0}\frac{(x-iy)(x-iy)}{(x+iy)(x-iy)}$$ $$=\lim_{z\to 0}\frac{x^2-y^2-2ixy}{x^2+y^2}$$ $$=\lim_{z\to 0}\frac{x^2-y^2}{x^2+y^2}-\frac{2ixy}{x^2+y^2}$$ I can't solve it from here. My teacher says that the limit doesn't exist but I don't know how & why. Please help me solve this question,['complex-analysis']
2906367,Sharpness of the constant $1/6$ in Cancellation Theorem.,"Let $\langle \; S \; | \; R \; \rangle$ be a presentation of a group $G$ with a set $R = R^{-1}$ of freely and cyclically reduced relators, and let $\Lambda$ be the girth of $\langle \; S \; | \; R \; \rangle$ . Suppose that 1) the set $R$ of relators contains no proper power, and 2)  for any triple $x,y,z \in F(S)$ of reduced words, such that $yx$ and $zx$ are two distinct (reduced) cyclic conjugates of elements of $R$ , we have $$|x| \leq 1/6 \Lambda,$$ where $|x|$ denotes the length of $x$ . Then, the famous Cancellation Theorem says that the corresponding presentation complex $P(S,R)$ is aspherical. Does anybody know if (and why) the constant $1/6$ in the statement is sharp? To be more precise, I am not looking for an aspherical presentation that fails to meet condition $2$ (such are easy to construct). I am looking for a group with a non-aspherical presentation (in the above sense) that satisfies both conditions, but with constant $c > 1/6$ . Ideally, I am looking for an answer to the following question: For every $\epsilon > 0$ , does there exist a presentation $P_{\epsilon}$ of a group $G_{\epsilon}$ , satisfying both conditions, but with constant $1/6 + \epsilon$ , such that $P_{\epsilon}$ is not aspherical?","['geometric-group-theory', 'group-presentation', 'group-theory', 'finite-groups']"
2906398,Function of more than 1 variable,"If you use the  definition of a function as a set of ordered pairs which relate elements from two sets, how would this apply when you have a function of more than one variable, say 2? Would the ordered pairs be of the form $((a,b),c)$?",['functions']
2906404,"For $f(x,y) = \frac{xy-1}{x^2 y^2-1}$, what is the limit as $(x,y)$ goes to $(1,1)$?","For $f(x,y) = \frac{xy-1}{x^2 y^2-1}$, what is the limit as $(x,y)$ goes to $(1,1)$? Since the denominator can be factored into $(xy-1)(xy+1)$ and then the $(xy-1)$'s in both the numerator and denominator can be cancelled, we are left with $f(x,y) = \frac{1}{xy+1}$ and substituting $x=1$ and $y=1$, the limit becomes $\frac{1}{2}$. Is this solution right? We had this question on our test todayin Multivariable Caclulus, and some people put $1/2$ while others put $DNE$. Who is right?","['limits', 'multivariable-calculus']"
2906416,Do binary operations need to be surjective functions?,"Let $\star$ be a binary operation on the set $S=[0,1]$ defined to be $$\star : [0,1] \times [0,1] \to [0,1] $$ $$\text{where } a \star b = \text{min}\left(\frac12 a , \frac12 b\right) $$ From observation we can see that the set $S$ is closed under $\star$ and that each ordered pair $(a,b)$ is mapped to only one element in $S$. For example, $1 \star 0.3 = 0.15$ But we also don't have every element in the codomain being hit. There doesn't exist any $(a,b) \in S^2$ such that $a \star b = 0.75$, for example. Does this cause a problem at all? Is $\star$ still considered a binary operation on $S$? In class we were told all binary operations were surjective, but the textbook for the class states no such thing. And if it is not a problem, I am wondering if there are any more complicated or ""elegant"" examples. I am interested to see them if they are. Thanks for any clarification on my confusion.","['binary-operations', 'abstract-algebra']"
2906428,find angle between the line $y = x + 3 \text { and } y = 2 x + 3$,"hello i tried to solve but i am not sure if its accurate answer 
that how i did it by using this formula $\tan \theta = \frac { m _ { 2 } - m _ { 1 } } { 1 + m _ { 1 } m _ { 2 } }$ 1st line $y=x+3$ assumed $1$ as $m _ { 1 }$ 2nd line $y = 2 x + 3y$ $m _ { 2 }=2$ applied values to formula $= \frac { 2 - 1 } { 1 + ( 1 ) ( 2 ) } = \frac { 1 } { 1 + 2 } = \frac { 1 } { 3 }$ $\tan^{-1} (\frac { 1 } { 3 }) = 18.43494°$ i am kind of curious if this is right or i did something wrong.",['trigonometry']
2906461,Are Eigenvalues Invariant?,"Question: are the eigenvalues of a dynamical system invariant under a change of variables? More specifically, consider a dynamical system A defined on a manifold $M_A$ by the evolution function $\phi_A(t,x)$ for all $x \in M_A$. Let $g$ be a diffeomorphism from $M_A$ to a different manifold $M_B$ and define the dynamical system $B$ on the manifold $M_B$ through the evolution function $\phi_B(t,y) = g \circ \phi_A \circ g^{-1}$ for $y \in M_B$. I can see that the fixed points of system A map one-to-one to the fixed points of system B. For instance if a fixed point is stable in A, the corresponding fixed point in B will also be stable. Are the eigenvalues of the fixed points also the same in the two systems?","['differential-geometry', 'ordinary-differential-equations', 'lyapunov-functions', 'fixed-points', 'dynamical-systems']"
2906545,Does every finite non-trivial complete group have even order?,"Does every finite non-trivial complete group have even order? I checked three well known classes of complete groups, and this statement is true for them all: 1) Symmetric groups:
All symmetric groups have even order (a well known fact) 2) Automorphism groups of non-abelian simple groups:
All non-abelian simple groups are of even order by Feit-Thompson theorem. Thus they have elements of order 2. And, as all non-abelian simple groups are centreless, this element is not in its centre. Thus, the conjugation by it is an automorphism of order 2. That means, that all automorphism groups of non-abelian simple groups have even order. 3) Holomorphs of cyclic groups of odd order (here is the proof, why they are complete: Is the statement that $ \operatorname{Aut}( \operatorname{Hol}(Z_n)) \cong \operatorname{Hol}(Z_n)$ true for every odd $n$? ):
All cyclic groups are abelian and thus all cyclic groups of even order have automorphism of order 2, that maps all their elements to their inverse. Thus both their automorphism group and their holomorph are of even order. However, I do not know, how to prove this statement in general. Any help will be appreciated.","['automorphism-group', 'complete-groups', 'finite-groups', 'abstract-algebra', 'group-theory']"
2906563,Binomial testing,"Suppose in any given year, the probability of getting a success is $0.8$. Suppose we have $10$ years of data and we have observed $3$ failures. How can I test if these three failures are statistically significant at say the 90% confidence interval? I have vague memories of high school hypothesis testing but cannot seem to recall it!","['statistics', 'probability']"
2906575,"How many ways can we construct $(a,b,c,d)$ such that $a \geq b, c \geq d$ and $a+b \geq c+d$?","I've been stuck on the counting problem described below for a while. I'm constructing ordered sequences of four positive integers of the form $(a,b,c,d)$, each of which are bounded above. i.e. $$a,b,c,d \in \{1,2,...,N\}$$ so that each of the variables can take on $N$ possible values. Of course, the number of lists we can form this way is $N^4$. Now, I impose that both $a\geq b$ and $c \geq d$. Since these conditions are independent, one can consider the number of ways to construct the first two elements of the list and square it. The number of ways to construct $(a,b)$ such that $a \geq b$ is simply $\frac 12 N(N+1)$, so the answer to this problem is $$\left(\frac 12 N(N+1) \right)^2=\frac 14 N^2(N+1)^2.$$ Now, where I'm getting stuck is the addition of a third constraint. This is to require that $a+b \geq c+d$, thus making the first two and last two components dependent on each other. My question is therefore: How many ordered lists of the form $(a,b,c,d)$ such that $$a,b,c,d \in \{1,2,...,N\}$$
$$a \geq b, \qquad c\geq d$$
$$a+b \geq c+d$$ are there?","['combinations', 'combinatorics']"
2906582,Turning a product into a sum,"Is it possible to change $$\prod_{i=1}^n(1+2a_ib_i),$$ where all elements are contained in an unital associative algebra generated by $a_i,b_i$, $i=1,...,n$, such that $a_ib_i=-b_ia_i$, into a sum which contains the summand $$\sum_{i=1}^n 2a_ib_i?$$ There is no special background for this question it is just about what I am asking. Thank you very much.","['summation', 'abstract-algebra', 'analysis', 'products']"
2906604,Find the smallest and highest value of the product $xyz$,"Find the smallest and highest value of the product $xyz$ assuming that: $x + y + z = 10$ and
$x^2 + y^2 + z^2 = 36$. I calculated this: $x+y+z=10 => (x+y+z)^2=10^2$ $x^2+y^2+z^2+2xy+2yz+2zx=100$ $(x^2+y^2+z^2+2xy+2yz+2zx)-(x^2+y^2+z^2)=100-36$ $2xy+2yz+2zx=64$ $xy+yz+zx=32$ I'm stuck. What is the next step to this exercise? My idea is to show the equation using one variable and after computing the derivative reach global extremes.","['cubics', 'inequality', 'systems-of-equations', 'symmetric-polynomials', 'algebra-precalculus']"
2906613,A curious variant of the classical 2D random walk: allowing duplication and vanishing,"Background. Recall the standard random walk on a 2D grid (i.e. $\mathbb{Z}^2$). A person starts at the origin. At every iteration, the person moves in one of the four directions (up, down, left, or right), each with a probability $1/4$. It is well-known that the person will at some point return to the origin with probability $1$. We now consider the following variant.  A person starts at the origin. At the first iteration, for each of the four points surrounding the person, a 'duplicate' of the original person is placed at this point with probability $1/4$; we remove the person at the origin. We do not require that there be exactly one duplicate. It can happen that there are more than one, or even that there are none altogether (in which case the simulation halts). At the following iterations, we repeat the process for each of the duplicates that we have: at each of the four points surrounding a given duplicate, a new duplicate is placed with probability $1/4$, and the original duplicate is removed. Example. A process could go as follows:
$$\{(0,0)\} \Rightarrow \{(0,1)\} \Rightarrow \{(0,0),(0,2)\} \Rightarrow \{(0,1),(0,1)\} \Rightarrow \{(1,1)\} \Rightarrow \{\}.$$
Notice that it can happen that more than one duplicate is at the same spot, and that the process halts after the duplicate on $(1,1)$ no longer formed any new duplicates. Question. We simulate the random walk described above. Throughout the simulation, we count the number of times that a duplicate is formed at the origin. What is the probability that at least one duplicate will return to the origin? Follow-up question. What is the probability distribution for the number of returns to the origin, and can we derive from this the expected number of returns? What I know. I am vaguely aware that the simulation will halt (because there are no more duplicates) in a finite amount of time with probability $1$. (This is probably a well-known result for the set people working within this area, but I am not an element thereof.) So we need not worry about the number of returns being infinite. The probability that the simulation halts at the first iteration is $(3/4)^4 \approx 0.32$, thus giving a trivial (and weak) upper bound for the probability of returning at least once, at about $0.68$. I have run the simulation 1.000.000 times in Python. The numerical results are as follows. It states the number of simulations that yielded a given number of returns to the origin.
\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\text{Returns} & 0 & 1 & 2 & 3 & 4 &5&6&7&8&9&10& >10 \\ \hline
\text{Runs} & 682919 & 143705 & 56318 & 29616 & 17856 & 11876 & 8512 & 6342 & 4898 & 3964 & 3312 & 30682 \\ \hline
\end{array}
Here's a plot of the first 80 values. The $x$-axis represents the number of returns; the $y$-value represents the number of runs with $x$ returns. The values at $x = 0,1$ have been cut off from the image so as to make the rest visible. We find that the probability of returning at least once is approximately $0.317$. Remarkably, there are also a bunch of extreme outliers. When I ran 100.000 runs without artificial termination, about one in a hundred simulations yielded more than a hundred returns. Two runs even yielded thousands of returns. (One yielded $8205$ returns. It lasted for $23230$ iterations, and at its peak there were $13769$ duplicates on the grid. The other gave even more: $13823$ returns after $70578$ iterations, with a peak number of $44232$ duplicates.) These outliers strongly influence the expected value. Estimates of the expected value are inconsistent. Though in the comments, user joriki gives a compelling argument in the comments that we should expect the value to be infinite.","['random-walk', 'stochastic-processes', 'recreational-mathematics', 'probability-theory', 'probability']"
2906633,Comparing Fisher Information of sample to that of statistic,"Let $X_1,...,X_n$ be Bernoulli($p$) where $p$ is unknown, and $n>2$, and let $T=X_1+X_2$. My task is to calculate the information about $p$ in the entire sample and compare it to the information about $p$ given by the statistic. After a few lines of work, I obtain the following expression for information contained in the sample: $$I_X(p)= n*E_p[(\frac{X_1p^{-1}(1-p)+X_1+1}{1-p})^2] $$ To calculate this, I first calculated the information given by one observation, and then multiplied that information by $n$. Now, after some work, I obtained the following expression for  information contained in $T$: $$I_T(p)=E_p[(\frac{Tp^{-1}(1-p)-1}{1-p})^2]$$ Now, I know from previous questions that $T$ is sufficient for $p$. Hence, $I_X(p)$ should equal $I_T(p)$. However, I have no idea how I am to compare these two quantities, because one has an $n$, and the other has an $X_2$ (in the $T$). Any advice?","['fisher-information', 'statistics']"
2906643,Property of set exclusion set.,"Let $T$ have the property that for all sets $A, B \in T$ we have that $(A\backslash B) \in T$. How can I prove that $\forall A,B \in T, A\cap B \in T$? I was thinking I should start with both expressions:
$(A\backslash B) \in T$. $(B\backslash A) \in T$. and show that$ (A \cup B)\backslash((A\backslash B)\cup (B \backslash A)=A\cap B \in T$. I'm not sure how to show that the final part is in that set. It doesn't say anything about unions.",['elementary-set-theory']
2906672,Subsets of an equivalence relation- terminology question,"Let $(A_n)_{n\in\mathbb N}$ be an increasing sequence of sets and let, for any $n\in\mathbb N$, $R_n$ be a relation on $A_n$ (i.e. a subset of $A_n\times A_n$, such that the following hold For any $n\in\mathbb N$, the relation $R_n$ is reflexive and symmetric on $A_n$, For any $n\le m\le k$, given $a_n\in A_n$, $a_m\in A_m$ and $a_k\in A_k$, such that $a_n R_m a_m$ and $a_m R_k a_k$, there exists some $l\ge k$ such that $a_n R_l a_k$. That is to say, the relations $R_n$ themselves are not necessarily equivalence relations, but their union is an equivalence on $A_n$. I was wondering if such a phenomenon has a commonly used name (e.g. pre-equivalence or graded equivalence relation). I came upon a sequence of relations of this sort recently, and would rather use the commonly used name, if such exists. Thank you!","['elementary-set-theory', 'equivalence-relations', 'relations']"
2906688,"Show that no two of the three sets ⌀, {⌀}, and {{⌀}} are equal to each other.","I'm doing this course on logic and we have an exam from set theory coming up,  ""Show that no two of the three sets ⌀, {⌀}, and {{⌀}} are equal to each other."" is one of the problems in the workbook we were assigned and I can't for the life of me even begin to solve this. I have the general knowledge surrounding empty sets and operations, but I don't know how I would go about writing a solution to this problem.","['elementary-set-theory', 'logic']"
2906707,"Suppose $f: \mathbb{R} \to \mathbb{R}$ is twice differentiable. Show that $\lim_{x \to \infty} f'' (x) = 0$, given conditions.","Suppose $f: \mathbb{R} \to \mathbb{R}$ is twice differentiable. Show that $\lim_{x \to \infty} f''(x) = 0$, given that $\lim_{x \to \infty} f(x)$ and $\lim_{x \to \infty} f''(x)$ exist. My attempt: Let $x > 0$. By MVT, there is $c_1(x) \in (x,2x)$ and $c_2(x) \in (3x,4x)$ with $$1/x(f(2x)-f(x)) = f'(c_1(x)); \quad  1/x(f(4x)-f(3x)) = f'(c_2(x))$$ Again, by MVT, there is $c_3(x) \in (c_1(x), c_2(x))$ with $$f''(c_3(x)) ( c_2(x)-c_1(x)) = f'(c_2(x))-f'(c_1(x)) = 1/x (f(2x)-f(x)-f(4x)+f(3x))$$ Taking $\lim_{x \to \infty}$ of both sides, we find: $$\lim_{x \to \infty} f'' (c_3(x)) (c_2(x)-c_1(x)) = 0$$ Because $c_2(x) - c_1(x) > 3x - 2x = x \to \infty$, it must be the case that $\lim_{x \to \infty} f''(c_3(x)) = 0$ But $c_3(x)  > c_1(x) > x \to \infty$, which implies that $\lim_{x \to \infty} f''(x) = 0$. Is this correct?","['limits', 'derivatives', 'real-analysis']"
2906711,Interpretation of Differential Algebraic Equation,"Considering the Differential Algebraic Equation (DAE) of the form $$\dot{x}=f(x,y)$$
$$0=g(x,y)$$
We can use the Implicit function theorem to conclude that as long as the Jacobian $ 
\frac{\partial g(x,y)}{\partial y}$ is non-singular, $\dot{y}$ can be written as a function of $x$ and $y$, and thus, we can use the local equivalent ODE version of this DAE. (i)- Under what condition we can interpret the above DAE as an ODE on the manifold $S:=\{ g(x,y)=0 \}$? (ii)- What if the DAE is of the form $\dot{x}=f(x)$, $g(x)=0$ (i.e., when we have a complete ODE plus a set of algebraic equations)?","['ordinary-differential-equations', 'control-theory', 'smooth-manifolds', 'manifolds', 'dynamical-systems']"
2906732,Calculate powers of sums,"Assuming we have an unital associative complex algebra with generatorn $a_i,b_i$, $i_1,...,n$ such that they anticommute, that is $$a_ia_j=-a_ja_i,\quad b_ib_j=-b_jb_i,\quad a_ib_j=-b_ja_i$$. Consider the element $$F_n:=\sum_{i=1}^n2a_ib_i.$$ Is it possible to give, for fixed $n$, expanded expressions for $F_n^k$ for $k=2,...,n$? 
Considering the case $n=2$ and using that powers of the generator vanishes as they anticommute we get $$F_2^2=4a_1b_1a_2b_2+4a_2b_2a_1b_1=8a_1b_1a_2b_2.$$ But what happens in general?","['summation', 'abstract-algebra', 'analysis']"
2906769,Solving $\frac{x^2-2}{x^2+2} \leq \frac{x}{x+4}$.,"Solve the inequality $\frac{x^2-2}{x^2+2} \leq \frac{x}{x+4} \Leftrightarrow$ $\frac{x^2-2}{x^2+2}  - \frac{x}{x+4} \leq 0 \Rightarrow$ $\frac{x^3+4x^2-2x-8-x^3-2x}{(x^2+2)(x+4)} \geq 0 \Leftrightarrow$ $4x^2-4x-8 \geq 0 \Rightarrow$ $x \geq \frac{1}{2} \pm \sqrt{2.25} \Rightarrow$ $x_1 \geq -1, \; x_2 \geq 2$ We notice that $x_2 \geq 2$ is a false root and testing implies that the solutions of the inequality lies within the interval $-1 \leq x \leq 2$. Problem : But $x<-4$ also solves the inequality, so I must have omitted or done something wrong? And also, am I using implication and equivalence symbols correctly when doing the calculations? Thank you for your help!","['algebra-precalculus', 'inequality']"
2906775,Prove the theorem of level sets as manifolds.,"THEOREM. Let $f_1,..f_r \in C^\infty (\mathbb R^n$ and $X=\{ x\in\mathbb R^n | f_i(x)=0, 1\le i\le r\}.$ If 
    $$Df_1(x)=(\frac{\partial f_1}{\partial x_1}(x),...,\frac{\partial f_1}{\partial x_n}(x)),\\\vdots\\Df_r(x)=(\frac{\partial f_r}{\partial x_1}(x),...,\frac{\partial f_r}{\partial x_n}(x))$$
    are linearly independent for all $x\in X$, then $X$ is an $(n-r)$ dimensional smooth manifold. Proof: First, Construct the coordinate charts. Let $a\in X$, then since the $r\times n$ matrix $\left( \frac{\partial f_i}{\partial x_j}(x) \right)$ has rank $r$ for $x\in X$, and so there exists an $r\times r$ minor of $\left( \frac{\partial f_i}{\partial x_j}(a) \right)$ which is different from $0$. In other words, $\exists ~1\le\alpha_1<...<\alpha_r\le n$ such that $\text{det} \left( \frac{\partial f_i}{\partial x_j}(a)\right)\ne0$. Let $1\le\alpha'_1<...<\alpha'_{n-r}\le n$ be complement to $\alpha_1<...<\alpha_r\le n$. By the implicit function theorem, there exists open neighborhood $U_{\alpha_1,...,\alpha_r}$ of $a$, an open nbd $V$ of $(a_{\alpha'_{1}},...,a_{\alpha'_{n-r}})$ and a unique map $g:V\to \mathbb R^r$ such that (1) $g(a_{\alpha'_{1}},...,a_{\alpha'_{n-r}})=(a_{\alpha_1},...,a_{\alpha_r})$ (2) $(x_1,...,x_n) \in X \cap U_{\alpha_1,...,\alpha_r} \Longleftrightarrow 
(x_{\alpha_1},...,x_{\alpha_r})=g(x_{\alpha'_1},...,x_{\alpha'_{n-r}}).$ Define $\phi_a: X\cap U_{\alpha_1,...,\alpha_r} \to \mathbb R^{n-r},~~(x_1,...,x_n)\to (x_{\alpha'_1},...,x_{\alpha'_{n-r}})$ Then $((x_1,...,x_n) \in X \cap U_{\alpha_1,...,\alpha_r},~\phi_a)$ is a coordinate chart containing $a\in X$. Second, we need to show that the transition maps are smooth. I have no idea how to prove the transition maps are smooth. The coordinate chart $\phi_a$ is like a projection map and I think the inverse $\phi^{-1}_a$ should be an inclusion map. Also, another coordinate chart, say $\phi_b$ should also be a projection map and its inverse is an inclusion map as well. Then the transition map $\phi_a \circ \phi_b^{-1}$ will mess up because the projection map and the inclusion map are about the sequences like $\alpha_1,...\alpha_r$ and $\alpha'_1,...\alpha'_{n-r}$. So, I don't know how to write down the transition map explicitly. Also, it seems that in the definition of $\phi_a$, we don't use $f_i$. But $f_i's$ are the only smooth functions that we know. So, I have no idea how to do this proof. I've just started learning smooth manifolds, so please do not use big theorems. Thank you in advance.","['manifolds', 'differential-topology', 'smooth-manifolds', 'differential-geometry']"
2906787,Finite-Galois-theoretic characterization of formally real fields?,"I have been trying to come up with a characterization of formally real fields in terms of their finite Galois theory, in order to pique the curiosity of a friend who is a distinguished algebraist, who cares a great deal about finite Galois theory and not at all about formally real fields.  I believe the following is such a characterization and want to know if you agree: Let $K$ be a field. I think that $K$ is formally real iff it has a quadratic extension $L$ such that, for any finite Galois extension $M/K$ containing $L$ , there is an involution of $M/K$ that extends the involution of $L/K$ . Do you agree? Here is my thinking. $K$ is formally real if and only if it lies in a real-closed subfield of its algebraic closure $\overline K$ (because if it is formally real, its real-closure is such a subfield, and if it lies in a real-closed field, it inherits an order by restriction so it is formally real). In turn, there is a real-closed subfield $K_R$ of $\overline K$ containing $K$ if and only if there is an involution of $\overline K / K$ ; if there is such an involution, then $K_R$ is its fixed field, and if $K_R\supset K$ exists, then $[K:K_R]=2$ , thus there is an involution fixing $K_R$ and therefore $K$ . To summarize, $K$ is formally real iff its absolute galois group $G_K := \operatorname{Gal}(\overline K/K)$ contains an involution. The above is an attempt to render the statement "" $G_K$ contains an involution"" in finite-Galois-theoretic terms. Since $G_K$ is the inverse limit of the finite Galois groups over $K$ , it seems to me that "" $G_K$ contains an involution"" literally means ""there is a Galois field extension $L/K$ with an involution and such that every Galois extension of $K$ containing $L$ contains an involution that restricts to this one."" Thus if there is no involution in $G_K$ , no such $L$ exists at all. It remains to argue that if there is such an involution, then $L$ can be taken to be quadratic over $K$ . I think this because if there is an involution in $G_K$ , then let $K_R$ be its fixed field. Then $K_R$ is formally real, so doesn't contain $i = \sqrt{-1}$ , so then neither does $K$ , and then $L$ can be taken to be $K(i)$ .","['field-theory', 'number-theory', 'algebraic-number-theory', 'galois-theory']"
2906792,Evaluating an Integral with a $\sqrt{1-x^2}$ in it,"Below is a problem I did but my answer does not match the book's table of
integrals. I would like to know where I went wrong. Thanks Bob Problem: Evaluate the following integral:
\begin{eqnarray*}
	\int x^2 \sqrt{ 1 - x^2 } \,\, dx \\
\end{eqnarray*} Answer \begin{eqnarray*}
	\text{Let } I &=&  \int x^2 \sqrt{ 1 - x^2 } \,\, dx \\ \\
	\text{Let }\sin u &=& x \\
	dx &=& \cos{u} \, du \\
	I &=& \int \sin^2{u} \sqrt{1 - \sin^2u}  \,\, \cos{u} \, du \\
	I &=& \int \sin^2{u} \cos^2{u} \,\, du \\
\end{eqnarray*}
Now recall the following two standard identities:
\begin{eqnarray*}
	\sin^2{\theta} &=& \frac{1 - \cos{2 \theta}}{2} \\
	\cos^2{\theta} &=& \frac{1 + \cos{2 \theta}}{2} \\
\end{eqnarray*}
Now applying the above two identities we have:
\begin{eqnarray*}
	I &=& \int \frac{(1 - \cos{2 u})(1 + \cos{2 u})}{4} \,\, du \\
	4I &=& \int 1 - \cos^2{2u} \,\, du = \int \sin^2{2u} \,\, du \\
	4I &=& \int \frac{1 - \cos{4u}}{2} \,\, d\theta \\
	8I &=& \int 1 - \cos{4u} \,\, du \\
	\int \cos{4u} \,\, du &=& \frac{\sin{4 u}}{4} + C_1 \\
\end{eqnarray*}
Now recall the following two standard identities:
\begin{eqnarray*}
	\sin{2 \theta} &=& 2 \sin{\theta} \cos{\theta} \\
	\cos{2 \theta} &=& 1 - 2 \sin^2{\theta} \\
\end{eqnarray*}
\begin{eqnarray*}
	\sin{4 u} &=& 2 \sin{2 u} \cos{2 u} = 4 \sin u \cos u ( 1 - 2 \sin^2 u) \\
	\sin{4 u} &=& 4 \sin u \cos u - 8 \sin^3 u \cos u \\ 
	\sin{4 u} &=& (4 \sin u - 8 \sin^3 u ) ( 1 - \sin^2 u)^\frac{1}{2} \\ 
	\int \cos{4u} \,\, du &=&
	( \sin u - 2 \sin^3 u ) ( 1 - \sin^2 u)^\frac{1}{2} + C_2 \\
	8I &=& \sin^{-1} x - (x - 2x^3)\sqrt{1 - x^2} + C_2 \\
	I &=& \frac{1}{8}\sin^{-1} x - \frac{(x - 2x^3)\sqrt{1 - x^2}}{8} + C \\
\end{eqnarray*}
However, the book's answer is:
\begin{eqnarray*}
	\int x^2 \sqrt{1 - x^2} \,\, dx &=&
	\frac{1}{8} \sin^{-1}{x} - \frac{x\sqrt{1-x^2}(1-2x^2)}{8} + C \\
\end{eqnarray*}","['integration', 'calculus', 'trigonometry']"
2906823,Two points of a square $K$ determine a diagonal of another square that is contained in $K$,"Let $K:=[0,1]^2$ be a square on $\mathbb{R}^{2}$ . We select 2 random points $A$ , $B$ $\in [0,1]^{2}$ in this square. What is the probability that the square whose diagonal is the line segment $AB$ , is contained in $K$ ? I found that if we fix coordinates of $A=(x,y)\in [0,1]^{2}$ , then the probability equals $$\int\limits_{0}^{1}\int\limits_{0}^{1}[1-(x-y)^{2}-(1-x-y)^{2}\times\textbf{1}(x+y<1)]dxdy \, ,$$ where: $\textbf{1}(x+y<1):=1$ if $x+y<1$ and $\textbf{1}(x+y<1):=0$ otherwise. Some attempts(or some elements of stream of consciousness) I tackled other problems from geometric probability, but this problem cannot be solved by standard methods(i.e. by finding dependency between given information in question, then making, at least, rough plot on cartesian coordinate system and integrate the area under the graph of detected dependencies within specific constraints). I have completely, even intuitively, idea how to come towards such solution. The only thing, which comes to my mind, is that in this problem we should consider complement of given event, i.e. set of these points that determine square not contained completely in the square $K$ . This may account for minus signs. So, presumably, the probability that we choose inapropriately is $$\int\limits_{0}^{1}\int\limits_{0}^{1}[(x-y)^{2} + (1-x-y)^{2}\times\textbf{1}(x+y<1)] dxdy $$ However, this is just intuition after solving hitherto plenty of problems from, let say, ""elementary"" probability... Motivation for knowing method of solving this problem I am very interested in getting to know how to derive quite rigorously solution to this problem. I would be very thankful for help. Note : this question is neither from any current mathematical contest nor a part of any ""homework""/""coursework"".","['contest-math', 'recreational-mathematics', 'geometric-probability', 'probability']"
2906865,How can I determine general formula of this sequence?,"I am trying to find general formula of the sequence $(x_n)$  defined by
$$x_1=1, \quad x_{n+1}=\dfrac{7x_n + 5}{x_n + 3}, \quad \forall n>1.$$
I tried
put $y_n = x_n + 3$, then $y_1=4$ and
$$\quad y_{n+1}=\dfrac{7(y_n-3) + 5}{y_n }=7 - \dfrac{16}{y_n}, \quad \forall n>1.$$
From here, I can't solve it. How can I determine general formula of above sequence? With Mathematica , I found $x_n = \dfrac{5\cdot 4^n-8}{4^n+8}$. I want to know a method to solve problem, than have a given formula.",['sequences-and-series']
2906868,Is the piecewise-defined function differentiable,"The function is defined as $$f(x)=\begin{cases}x^2, &\text{ for }x\leq 1\\ \sqrt{x}, &\text{ for }x>1\end{cases}$$ and Is this function differentiable at $x=1$? I thought that since $\lim_{x\to 1}$ of $f'(x)$ exists then it IS differentiable. And I think this limit does exist so it should be differentiable. Book says no. My logic must not be correct here.","['calculus', 'derivatives', 'real-analysis']"
2906880,Using the Harmonic Addition Theorem to simplify $\cos(x)+i\sin(x)$,"The Harmonic Addition Theorem states that:
$$A\cos(x)+B\sin(x) = \operatorname{sign}(A)\sqrt{A^2+B^2}\cos\left(x-\arctan\left(\frac{B}{A}\right)\right)$$ http://mathworld.wolfram.com/HarmonicAdditionTheorem.html $$$$
But when I try using it to simplify the famous formula: $$\cos(x)+i\sin(x)$$ I get: $$A=1,B=i \implies \operatorname{sign}(1)\sqrt{1+(-1)}\cos(x-\arctan(i)) =0 $$ which is clearly not right. What am I doing wrong? Is there some restriction I'm missing?","['complex-analysis', 'trigonometry']"
2906939,If $f$ is differentiable for $x\neq x_0$ and $\lim_{x\to x_0} f'(x) = c$ then $f'(x_0) = c$,Exercise : Let $f : \mathbb R \to \mathbb R$ and $x_0 \in \mathbb R$. Suppose that $f$ is differentiable for all $x \neq x_0$. If $\lim_{x \to x_0}f'(x) = c \in \mathbb R$ show that $f$ is differentiable at $x_0$ and $f'(x_0) = c$. Attempt : Isn't it pretty straight forward that since $\lim_{x \to x_0} f'(x) = c$ then $f'$ is continuous at $x_0$ and thus differentiablewith $f'(x_0) = c$ ? Does it need some more delicate or rigorous mathematical proof ?,"['limits', 'calculus', 'derivatives']"
2906974,Solve $\frac{a^2}{x^2 f'(x)}-\log{{(1-f(x))}}=S^2 +1$,"Solve
  $$  \frac{a^2}{x^2 f'(x)}-\log{{(1-f(x))}}=S^2 +1,  $$ for $x\geq 1$, $f(x)<1$
  where $a,S\in \mathbb{R}$ and $f'(x)=\frac{d f(x)}{dx}$. My effort: It is equivalent to 
$$  {a^2}-(x^2 f'(x))\log{{(1-f(x))}}-(S^2 +1)(x^2 f'(x))=0,  $$
or
$$  {a^2}- f'(x)x^2(\log{{(1-f(x))}}-S^2 +1)=0,  $$ I am not sure what to do with the $\log(1-f(x))$. Any idea?","['derivatives', 'ordinary-differential-equations']"
2906983,"Define $T:L^2[0,1]\to L^2[0,1]$ by $Tf(t)=\int_0^1 \frac{f(s)ds}{1+s^2+t^2}$","We want to show that $T$ is self-adjoint and compact. To show that $T$ is self-adjoint we show $$\begin{align} 
\langle Tf(t),g(t)\rangle
 &= \int_0^1 Tf(t)\cdot g(t)dt \\
 & = \int_0^1 \left(g(t)\left( \int_0^1 \frac{f(s)ds}{1+s^2+t^2} \right)dt\right) \\
 &=^? \int_0^1 \left( f(t) \left(\int_0^1 \frac{g(s)ds}{1+s^2+t^2} \right) dt\right) \\
 &=\langle f(t),Tg(t)\rangle 
\end{align}$$ Would you do this with a substitution? Maybe Fubini's theorem? I'm not really sure where to go with this. For compactness, consider a bounded sequence $\{f_n\}$, say by $M$, in $L^2[0,1]$. We need to show that $$Tf_n=\int_0^1 \frac{f_n(s)ds}{1+s^2+t^2}\leq M\int_0^1\frac{ds}{1+s^2+t^2}$$ has a convergent subsequence. This one I'm not sure how to approach at all. Any help for either problem would be much appreciated, thank you so much!","['functional-analysis', 'analysis', 'real-analysis']"
2906993,Show that a function is not integrable but an iterated integral exist,"So, I have the funcion $f(x,y) =
    \begin{cases}
      0 & \text{if }x \text{ irrational} \\
      2y & \text{if } x \text{ rational}\
    \end{cases} $ Defined in $R=[0,1]\times[0,1]$ I know that $f$ is not Riemann-integrable since the value of the lower/upper Darboux' sums depends on the choice of the sample points. I just don't understand why should the iterated integral exist: $\int_{0}^{1}[\int_{0}^{1}f(x,y)dy]dx$ But it does, and I don't know what its value should be.","['integration', 'riemann-sum', 'multivariable-calculus', 'real-analysis']"
2907001,Getting $p_y(y) = p_x(g^{-1}(y)) \left| \frac{\partial{x}}{\partial{y}} \right|$ by solving $| p_y(g(x)) \ dy | = | p_x (x) \ dx |$?,"My textbook has a very brief section that introduces some concepts from measure theory: Another technical detail of continuous variables relates to handling continuous random variables that are deterministic functions of one another. Suppose we have two random variables, $\mathbf{x}$ and $\mathbf{y}$ , such that $\mathbf{y} = g(\mathbf{x})$ , where $g$ is an invertible, continuous, differentiable transformation. One might expect that $p_y(\mathbf{y}) = p_x(g^{−1} (\mathbf{y}))$ . This is actually not the case. As a simple example, suppose we have scalar random variables $x$ and $y$ . Suppose $y = \dfrac{x}{2}$ and $x \sim U(0,1)$ . If we use the rule $p_y(y) = p_x(2y)$ , then $p_y$ will be $0$ everywhere except the interval $\left[ 0, \dfrac{1}{2} \right]$ , and it will be $1$ on this interval. This means $$\int p_y(y) \ dy = \dfrac{1}{2},$$ which violates the definition of a probability distribution. This is a common mistake. The problem with this approach is that it fails to account for the distortion fo space introduced by the function $g$ . Recall that the probability of $\mathbf{x}$ lying in an infinitesimally small region with volume $\delta \mathbf{x}$ is given by $p(\mathbf{x}) \delta \mathbf{x}$ . Since $g$ can expand or contract space, the infinitesimal volume surrounding $\mathbf{x}$ in $\mathbf{x}$ space may have different volume in $\mathbf{y}$ space. To see how to correct the problem, we return to the scalar case. We need to present the property $$| p_y(g(x)) \ dy | = | p_x (x) \ dx |$$ Solving from this, we obtain $$p_y(y) = p_x(g^{-1}(y)) \left| \dfrac{\partial{x}}{\partial{y}} \right|$$ or equivalently $$p_x(x) = p_y(g(x)) \left| \dfrac{\partial{g(x)}}{\partial{x}} \right|$$ How do they get $p_y(y) = p_x(g^{-1}(y)) \left| \dfrac{\partial{x}}{\partial{y}} \right|$ or equivalently $p_x(x) = p_y(g(x)) \left| \dfrac{\partial{g(x)}}{\partial{x}} \right|$ by solving $| p_y(g(x)) \ dy | = | p_x (x) \ dx |$ ? Can someone please demonstrate this and explain the steps?","['measure-theory', 'real-analysis', 'change-of-variable', 'probability-theory', 'random-variables']"
2907031,"If $T:[0,1] \rightarrow [0,1]$ preserves Lebesgue, then $\liminf_n(n|T^n(x)-x|) \leq 1$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Let $T:[0,1] \rightarrow [0,1]$ be a measurable function such that $T$ preserves Lebesgue, then for almost all point: $$\liminf_n(n|T^n(x)-x|) \leq 1$$","['measure-theory', 'lebesgue-measure', 'ergodic-theory']"
2907036,How do you know if “by inspection” is a valid argument? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 5 years ago . Improve this question Sometimes while certain deductions may seem obvious, they are only obvious because of much prior work. For instance, even describing something as simple as $1+1=2$, you would first need to: define group containing a set of objects $S$, define the operation of addition such that $S \times S \rightarrow S$, define that the set is closed under this operation $(S_{1},S_{2}) \rightarrow S_{1}+S_{2}$, define that addition is associative $(S_{1}+S_{2})+S_{3}=S_{1}+(S_{2}+S_{3})$, and it even continues on from there. So, if you can't even argue “by inspection” for something as elementary as $1+1=2$, what exactly makes it valid for more complex derivations dealing with summations or matrices or special functions of a complex variable and etc.?","['algebra-precalculus', 'abstract-algebra', 'proof-writing', 'arithmetic']"
2907045,Negating a Symbolic Expression/Logic,Negate the following and simplify as much as you can... $$\exists x ~\forall y~(p(y) \to \forall z~q(z))$$ How would I negate this expression. Not sure how to start it.,"['logic', 'discrete-mathematics']"
2907050,Neighbourhood of a point where $(\theta_1)_{t_1} \circ (\theta_2)_{t_2} \circ \cdots \circ (\theta_k)_{t_k}$ is defined,"This is actually a detail in Lee’s smooth manifold 2nd ed p.234, 2nd paragraph in the Theorem 9.46. What i found is possibly a correction for the book. Forgive me if it’s not even close. Let $M$ be a smooth manifold of dimension $n$ and $p \in M$ be an arbitrary point and $U$ is a domain of a smooth chart centered at $p$. Suppose that we have $k$-tuple of smooth vector fields $(V_1, \dots, V_k)$ defined on $U$. Let $\theta_i$ denote the flow of $V_i$. Before i state the problem that has bugged me, i want to note that actually; first, the chart $U$ above is a slice chart. Second the vector fields $(V_i)$ above is linearly independent and mutually commuting. But for the following problem, i think we will not use those assumptions. Here’s the problem Lee claim that there exists $\epsilon>0$ and a neighbourhood $Y$ of $p$ in $U$ such that the composition $(\theta_1)_{t_1} \circ (\theta_2)_{t_2} \circ \cdots \circ (\theta_k)_{t_k}$ defined on $Y$ and maps $Y$ into $U$ whenever $|t_1|,\dots,|t_k|$ are all less than $\epsilon$. After this claim, he also said that To see this, just choose $\epsilon_k>0$ and $U_k \subseteq U$ such that $\theta_k$ maps $(-\epsilon_k,\epsilon_k)\times U_k$ into $U$, and then inductively choose $\epsilon_i$ and $U_i$ such that $\theta_i$ maps $(-\epsilon_i,\epsilon_i)\times U_i$ into $U_{i+1}$. And then taking $\epsilon = \text{min }\{\epsilon_i\}$ and $Y=U_1$. I did the suggested construction but i think the suggestion should be To see this, just choose $\epsilon_1>0$ and $U_1 \subseteq U$ such that $\theta_1$ maps $(-\epsilon_1,\epsilon_1)\times U_1$ into $U$, and then inductively choose $\epsilon_{i}$ and $U_{i}$ such that $\theta_{i}$ maps $(-\epsilon_{i},\epsilon_{i})\times U_{i}$ into $U_{i-1}$. And then taking $\epsilon = \text{min }\{\epsilon_i\}$ and $Y=U_k$. I may get this wrong. I hope somebody could clarify this for me. Is the suggestion is correct or it should be other way around as i did. Any help will be appreciated. Thank you","['differential-topology', 'smooth-manifolds', 'differential-geometry']"
2907061,"If $P(A) = \frac{1}{3}, P(B) = \frac{1}{2}$, and $P(A \cup B) = \frac{3}{4}$ find...","If $P(A) = \frac{1}{3}, P(B) = \frac{1}{2}$, and $P(A \cup B) = \frac{3}{4}$ Find: $P(A \cap B),\\  
P(A^\complement \cup B^\complement) \\
P(A^\complement \cap B)$ Here is what I did: $P(A \cap B) = P(A) + P(B) - P(A \cup B) = \frac{1}{12}$ $P(A^\complement \cup B^\complement) = P( [A \cap B]^\complement ) = 1 - \frac{1}{12} = \frac{11}{12}$ (Not sure if this is correct) $P(A^\complement \cap B) = ...$ (I'm not quite sure how to approach this)","['elementary-set-theory', 'probability']"
2907079,Given $\{ x_n\}$ be a sequence of rational numbers such that $\lim_{n \to \infty}x_n=0$ then $\lim_{n \to \infty} a^{x_n}=1$,Let a be a positive real number $a>0$ and $\{ x_n\}$ be a sequence of rational numbers such that $\lim_{n \to \infty}x_n=0$ Show that $\lim_{n \to \infty} a^{x_n}=1$ My attempt given  = $e^{x_n \ln a} \to 1$ But any other alternative way? this was asked for 10 marks.,"['sequences-and-series', 'cauchy-sequences', 'real-analysis']"
2907137,Conditional Expectation on von Neumann algebras,"A linear map $\phi$ from a von Neumann algebra M to the subalgebra N is called a conditional expectation when $\phi$ has the following properties.
1) $\phi(I)=I$ , 2) $\phi(x_{1}y x_{2})=x_{1}\phi(y)x_{2}$ whenever $x_{1},x_{2}\in N$ and $y\in M.$ Can anyone explain me why this map is called conditional expectation? How it is related to the classical case? Thanks in advance.","['conditional-expectation', 'von-neumann-algebras', 'functional-analysis']"
2907139,Compactness of a set in the complex plane.,"Consider $$A=\Big\{(z_1,z_2) \in \Bbb{C}^2 : z_1^2+z_2^2=1\Big\}$$ Is $A$ compact? My try:  If $A$ is compact, then it is closed and bounded But it is not bounded! Since $(n,\sqrt{1-n^2});n\in \Bbb{N}$ satisfies this and $\Bbb{N}$ is unbounded. So not compact. Am I right? If not, any help?","['complex-analysis', 'complex-geometry']"
2907149,show that $\ \sum^{n}_{k=1}|f(2^n)-f(2^k)|\leq \frac{n(n-1)}{2}$,"If $\displaystyle \bigg|f(a+b)-f(b)\bigg|\leq \frac{a}{b}\; \forall\;  a,b\in \mathbb{Q},b\neq 0.$ Then show that $\displaystyle \sum^{n}_{k=1}\bigg|f(2^n)-f(2^k)\bigg|\leq \frac{n(n-1)}{2}$ Try: put $\displaystyle a=h>0$ Then $\displaystyle \bigg|f(b+h)-f(b)\bigg|\leq \frac{h}{b}$ So $\displaystyle \lim_{h\rightarrow 0}\bigg|\frac{f(b+h)-f(b)}{h}\bigg|\leq \lim_{h\rightarrow 0}\frac{1}{b}\Rightarrow |f'(b)|\leq \frac{1}{b}$ Could some help me how to solve it, please help me. Thanks",['functions']
2907164,Limit of sequence exists but might be infinity,"Assumption 4.2 in Stokey et al. states, for the real sequence $x_t$: ... $\lim_{n\rightarrow \infty} \sum_{t=0}^n x_t$ exists but might be positive or negative infinity. But this goes against my intuition and understanding. How can a series going to $\infty$ be converging to a limit? And what is the difference between converging to $\infty$ and diverging? Source: Stokey, N. & Lucas, R.(1989} Recursive Methods in Economic Dynamics, page 84","['limits', 'sequences-and-series']"
2907167,Finding a certain entry in a matrix,"Can we find the entry $s_{23}$ of $S=H^3$ where $H=\pmatrix{2&-1&0\\3&1&2\\-1&1&1}
$ without finding $S$. I know that $s_{23}$ is given by multiplying the second row of $H^2$ and the third coloumn of $H$ but it is dull. Thank you for any hints!","['matrices', 'linear-algebra']"
2907189,"Show that the projection from $C[0,1]$ onto $P_n[0,1]$ under $L^q$ norm is nonlinear when $q>1$ and $q\neq 2$.","Let $C[0,1]$ denote the space of real valued continuous functions defined on $[0,1]$. Let $P_n[0,1]$ the space of real polynomials with degree not greater than $n$ defined on $[0,1]$. Let $q>1$ denote a finite real number. For any $f\in C[0,1]$, one can show by compactness argument and uniform convexity of $L^q$ norm that there exists an  unique $P(f)\in P_n[0,1]$ such that
\begin{equation}
||f-P(f)||_{L^q(0,1)}=\inf\limits_{p\in P_n[0,1]}||f-p||_{L^q(0,1)}.
\end{equation}
In this fashion, we define a projection operator: $f\in C[0,1]\mapsto P(f)\in P_n[0,1]$. How to show that $P(\cdot)$ is nonlinear when $q\neq 2$? Could anyone help me show this? I really don't know how to start it.","['projection', 'continuity', 'lp-spaces', 'polynomials', 'functional-analysis']"
2907197,Find the probability that the white ball labelled $1$ is drawn before all the black balls.,"Suppose in an urn there are $20$ black balls labelled $1,2, \ldots , 20$ and $10$ white balls labelled $1,2, \ldots ,10$. Balls are drawn one by one without replacement. Find the probability that the white ball labelled $1$ is drawn before all the black balls. My attempt $:$ If we want to draw the first white ball before all the black balls then I have to draw the first white ball in one of first $10$ steps. Suppose I draw the first white ball in $k$-th step. Then in order to fulfil my requirement I have to draw white balls in first $k-1$ steps. That can be done in $\binom 9 {k-1}  (k-1)!$ ways. For each of these ways remaining $30-k$ balls can be drawn in $(30-k)!$ ways. This $k$ can run from $1$ to $10$. So the total number of ways to draw the first white ball before all the black balls is $$\sum\limits_{k=1}^{10} \binom 9 {k-1}(k-1)! (30-k)!$$ So the required probability is $$\frac1{30!}{\sum\limits_{k=1}^{10} \binom 9 {k-1}(k-1)! (30-k)!} =\sum\limits_{k=1}^{10} {\frac {9!(30-k)!} {30!(10-k)!}}$$ Now my instructor has given it's answer which is $\frac {1} {21}$. Does the above sum evaluate to $\frac {1} {21}$? Is there any other simpler way to do this? Please help me in this regard. Thank you very much.","['permutations', 'combinatorics', 'probability']"
2907209,"Solve $(x+y \log y)y\, \mathrm{d}x=(y+x \log x)x \,\mathrm{d}y$","Solve the differential equation $$(x+y \log y)y \,\mathrm{d}x=(y+x \log x)x \,\mathrm{d}y$$ My try: put $x=e^t$ and $y =e^w$: we get $$(e^t+w e^w)e^w e^t \,\mathrm{d}t=(e^w+te^t)e^we^t\,\mathrm{d}w\implies
(e^t+we^w)\,\mathrm{d}t=(e^w+te^t)\,\mathrm{d}w$$ Any clue here?","['integration', 'definite-integrals', 'ordinary-differential-equations', 'indefinite-integrals', 'algebra-precalculus']"
2907226,Is a uniformly integrable martingale stopped at every stopping time also uniformly integrable?,"Let $\{X_n \}$ be a  uniformly integrable martingale w.r.t. the natural filtration $\{ \mathcal{F}_n \}$. Is $\{ X_\tau : \tau \text{ is a stopping time w.r.t. }
 \{ \mathcal{F}_n \} \}$ uniformly integrable? I've tried using this theorem that conditional expectations of integrable random variables forms a uniformly integrable family, but this isn't working because I don't see how $X_\tau$ is actually the same thing as $\mathbb{E}(X_n | \mathcal{F}_\tau)$. I'm really not sure how to proceed here... can anyone help? Note that $X_\tau := \sum\limits_{n=0}^\infty X_n \textbf{1} \{ \tau = n\}$.","['martingales', 'stopping-times', 'probability-theory', 'uniform-integrability']"
2907237,On the solution of a linear system of differential equations for the unknown series coefficients,"In a mathematical physical problem, I came across the following linear system of differential equations (obtained upon using Fourier series expansion):
\begin{align}
		\frac{\mathrm{d} \rho_n}{\mathrm{d}  t} +
		\alpha \sum_{i = 1}^{\infty} \frac{\mathrm{d} \rho_i}{\mathrm{d} t} 
		&= - H_n \bigg( H_n \, \rho_n
		+ \frac{\phi_n}{2} \bigg) +  1    \, , \\
		\frac{\mathrm{d}  \phi_n}{\mathrm{d}  t} 
		&= - H_n \, \rho_n - \phi_n \, ,
\end{align}
where 
$$
H_n = 2n-1 \, , 
\quad
\alpha \in \mathbb{R} \, ,
\quad
\text{and}
\,\,
n \ge 1\, .
$$ The system is subject to the initial conditions $\rho_n(0)=\phi_n(0)=0$. The goal is to determine the general expression of the coefficients $\rho_n$ and $\phi_n$.
    When $\alpha=0$, the solution of the problem is easy and straightforward. I have tried to solve the above linear system of differential equations for $\alpha \ne 0$ using the Laplace transform technique but without success. The calculation of the inverse Laplace transform doesn't seem to be possible (since the Laplace-transformed function has an infinite number of singularities and choosing an abscissa of convergence $\sigma>0$ for which the contour is located to the right of all singularities is not within reach.) I was wondering whether someone here could be of help and try to tell how one can solve such a mathematical problem.
Your hints and ideas and very welcome.
Very much thanks!","['ordinary-differential-equations', 'laplace-transform', 'real-analysis', 'linear-algebra', 'sequences-and-series']"
2907263,Problem on Matrix Calculus.,"How do I find $$\arg\min_{\alpha \in\mathbb R^n} (K\alpha-y)^T(K\alpha-y)+\lambda \alpha^T K \alpha$$ using Matrix calculus ? Here $K$ is $n\times n$ matrix, $\alpha$ and $y$ are $n\times 1$ vectors, $\lambda$ is positive real number. I am completely new to Matrix Calculus, a solution might help me to relate with the Wikipedia's article on Matrix Calculus.","['matrices', 'multivariable-calculus', 'calculus', 'matrix-calculus', 'derivatives']"
2907298,Dual of cocyclic module is cyclic,"I am working on a paper, which states that the dual of a finite dimensional cocyclic module is cyclic. I tried to write down a proof, but I failed and I do not know if this is true in full generality or of it is true just in my case. Let $A$ be a complex Hopf algebra and $M$ a finite $\mathbb{C}$-dimensional cocyclic $A$-module with cocyclic vector $m \in M\setminus \lbrace 0 \rbrace$, i.e. every nontrivial submodule $U \subset M$ contains $m$. Let $M^* = \operatorname{Hom}(M,\mathbb{C})$ be the dual module. The statement is, that $M^*$ is cyclic with cyclic vector $m'$ corresponding to $m$. What I tried so far, is the following. Let $e_1, \dots, e_n$ be a $\mathbb{C}$-basis of $M$ and let $\delta_1, \dots, \delta_n$ be the dual basis of $M^*$, i.e. $\delta_i(e_j) = \delta_{ij}$. We can assume that $m = e_1$, in particular $m' = \delta_1$. Now since $m = e_1$ is cocyclic, there exists for every $e_i$ an element $a_i \in A$ such that $a_ie_i = e_1$. To show that $M^*$ is cyclic with cyclic vector $\delta_1$, it suffices to find elements $\tilde a_i$ such that $\tilde a_i \delta_1 = \delta_i$ for every $1 \le i \le n$. The first obvious idea is to try to act with $a_i$ on $\delta_1$ and look what happens. It is clear that 
\begin{align*}
(a_i \delta_1)(e_i) = \delta_1(a_i e_i) = \delta_1(e_1) = 1,
\end{align*}
but if we write $a_i e_j = \sum_k a_k^{ij} e_k$, we have 
\begin{align*}
(a_i \delta_1)(e_j) = \delta_1(a_i e_j) = a_1^{ij}
\end{align*}
which a priori can be nonzero. I tried to correct the elements $a_i$ to make $a_1^{ij}$ be $0$, but this only works if $n = 2$, and moreover I think, that there should be a more intrinsic reason why the dual of a cocyclic is cyclic. In the paper I am working on, my algebra is the universal enveloping algebra $U(\mathfrak{g} \otimes \mathbb{C}[t])$ of the current algebra, where $\mathfrak{g}$ is a semisimple finite dimensional Lie algebra. My module $M$ is in fact graded, but I do not think, that this is important.","['lie-algebras', 'representation-theory', 'combinatorics', 'hopf-algebras', 'dual-spaces']"
2907315,Proof of Hardy inequality in $\mathbb{R}^n$,"I've often seen people use the inequality 
$$\int_{\mathbb R^3} \frac{|u(x)|^2}{|x|^2}\,dx  \leq 4\int_{\mathbb R^3}|\nabla u(x)|^2\,dx,\qquad u\in C_0^\infty(\mathbb R^3) $$
without proof, refering to it as ""Hardy's inequality"". I struggled to find a direct proof of this in the literature and couldn't prove it myself. Does anyone know a straightforward proof of this or a book in which Hardy's inequality in this form is proved? I would also be interested in the general form of this inequality, i.e. what happens if one replaces $\mathbb R^3$ with $\mathbb R^n$?","['lebesgue-integral', 'lp-spaces', 'sobolev-spaces', 'functional-analysis', 'inequality']"
2907316,Neural Networks - Are these functions Lipschitz continuous?,"Assuming for simplicity a neural network with 1 parameter. Let $x \in R$ be a training pattern, $t \in R$ the target variable, $w \in R$ the parameter and $g: R \rightarrow R$ the activation function. Given the regularized loss function: $$ f(x;w)  = \frac{1}{2}(t - g(xw))^2 + \frac{1}{2} \lambda w^2$$ The activation function $g$ can be linear , sigmoid , tanh or ReLU . Depending on the choice of $g$, are $f$, $\nabla f$ and $\nabla^2 f$ Lipschitz-continuous? ps: I need to check whether some assumptions of optimization algorithms are true, so I think they require global Lipschitz continuity.","['functions', 'lipschitz-functions']"
2907338,Does this matrix sequence always converge?,"Suppose $a_0, a_1, ... , a_{n-1}$ are real numbers from $(0; 1)$, such that $\sum_{k=0}^{n-1} a_k=1$. Suppose $A = (c_{ij})$ is a $n \times n$ matrix with entries $c_{ij} = a_{(i-j)\%n}$, where $\%$ is modulo operation. Is it always true that $\lim_{m \to \infty} A^m = \frac{1}{n} \begin{pmatrix} 1 & 1 & \cdots & 1 \\1 & 1 & \cdots & 1 \\ \vdots & \vdots & \ddots & \vdots \\ 1 & 1 & \cdots & 1 \end{pmatrix}$? This statement is true for $n = 2$: 
Suppose $A = \begin{pmatrix} a_0 & {1 - a_0} \\ {1 - a_0} & a_0 \end{pmatrix} = \begin{pmatrix} 1 & -1 \\ 1 & 1\end{pmatrix}^{-1}\begin{pmatrix} 1 & 0 \\ 0 & {1-2a_0} \end{pmatrix}\begin{pmatrix} 1 & -1 \\ 1 & 1 \end{pmatrix}$. Because $a_0$ is in $(0; 1)$, $1-2a_0$ is in $(-1;1)$. Thus $$\lim_{m \to \infty} A^m = \begin{pmatrix} 1 & -1 \\ 1 & 1\end{pmatrix}^{-1}\begin{pmatrix} 1 & 0 \\ 0 & 0\end{pmatrix}\begin{pmatrix} 1 & -1 \\ 1 & 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix}$$ However, I do not know how to prove this statement for arbitrary $n$. Any help will be appreciated.","['matrices', 'matrix-calculus', 'linear-algebra', 'sequences-and-series', 'limits']"
2907339,Large invertible submatrix in random sparse matrices,"The Problem Informal statement of the problem: consider a natural distribution $D_n$ of very sparse $n\times n$ matrices over the binary field $\mathbb{F}_2$ - that is, a matrix sampled from $D_n$ contains a constant number of $1$ per row. How likely is a matrix sampled from $D_n$ to contain a large invertible submatrix? More formally, consider the two ""natural distributions"" over $n\times n$ matrices in $\mathsf{M}_{n\times n}(\mathbb{F}_2)$ : $D^0_n$ samples each entry of the matrix independently from the Bernouilli distribution with probability $p_n = d/n$ , where $d$ is a small constant (that is, each entry of a sampled matrix is $1$ with probability $d/n$ , and $0$ with probability $1-d/n$ ). $D^1_n$ samples each row of the matrix independently; to sample the $i$ th row, pick a random size- $d$ subset $S_i$ of $[1,\cdots, n]$ . The subset $S_i$ denotes the position of the $1$ s in the $i$ th row (and $[1,\cdots, n]\setminus S_i$ denotes the position of the $0$ s). Then, consider the following conjecture (with $b=0$ and $b=1$ giving two variants depending on the choice of the distribution): there exists constants $\gamma<1, N$ such that for any $n > N$ , the probability that a random matrix sampled from $D^b_n$ contains an invertible submatrix of size $\gamma n \times \gamma n$ is at least $1-f(n)$ . Here, $f(n)$ is some fixed function that goes to $0$ when $n$ grows, e.g. an inverse polynomial, or an inverse exponential. Question What is known about the above conjecture? Is it known to hold for one of $D^0_n,D^1_n$ ? Alternatively, is it known to hold if we relax the requirement to containing an invertible submatrix of size $\gamma n \times \gamma n$ with constant probability (instead of a probability that goes to $1$ when $n$ increases)? I'm specifically interested in the case $d = 5$ (that is, the sparse matrices have on average five $1$ s per row), in case this simplifies the problem in any way. I would also be happy with any partial answer, giving pointers to relevant literature, relating the problem to existing problems, or providing any clues. Thoughts on the question I have not found any literature directly addressing the problem above. There is, however, a rather large body of research on the rank of random less-sparse matrices, namely, $n\times n$ matrices containing an average of $O(\log n)$ $1$ s per row (as opposed to constant in my scenario). More specifically, this paper shows that the rank of random (Bernouilli) sparse matrices will be $n - O(1)$ with probability $1-o(1)$ , where the Bernouilli probability is $p_n = c\log n/n$ for some constant $c>0$ . A similar result for any field is proven in this other paper . However, it is not clear to me whether these results could be extended to guarantee a rank $\gamma\cdot n$ for some constant $\gamma$ , with probability $1-o(1)$ , in the setting $p_n = d/n$ for some small constant $d$ . Furthermore, I do not know either if these results can be extended to the stronger statement that a random sparse matrix has a large invertible subsystem (as opposed to a large rank). In another paper (which I could not find back), there was a more fine-grained analysis of the rank of a random $O(\log n)$ -sparse matrix over $\mathbb{F}_2$ . Unfortunately, replacing $O(\log n)$ by a constant in their calculations only leads to the statement that the number of dependencies in a random sparse matrix is at most $O(n)$ (with probability $1-o(1)$ ); it does not allow (as far as I could see) to prove the stronger statement that the number of dependencies will be upper bounded by $(1-\gamma)\cdot n$ for some constant $1>\gamma >0$ . And this is still only about the rank anyway. Note I've not verified this specific conjecture experimentally, but I've done so (well, some coauthors of mine have done so) for a more complex distribution over sparse matrices (for the context, it arose when analyzing the success probability of a subexponential-time attack on a cryptographic pseudorandom generator), and it seemed to be verified (with a constant $\gamma$ above $0.9$ ), for large values of $n$ (a few hundredth). The sampled sparse matrix always contained a $\gamma n\times \gamma n$ invertible submatrix in our experiments; the same seems very likely to hold also for the simpler distributions I consider in this question.","['matrices', 'linear-algebra', 'sparse-matrices', 'random-matrices', 'probability']"
2907344,Evaluating $\frac{1}{\sin(2x)} + \frac{1}{\sin(4x)} + \frac{1}{\sin(8x)} + \frac{1}{\sin(16x)}$,Evaluate $$\dfrac{1}{\sin(2x)} + \dfrac{1}{\sin(4x)} + \dfrac{1}{\sin(8x)} + \dfrac{1}{\sin(16x)}$$ It would be tough for us to solve it using trigonometric identities. There should be strictly an easy trick to proceed. Rewriting and using trigonometric identities $$\dfrac{1}{\sin(2x)} + \dfrac{1}{\sin(2x) \cos (2x)} + \dfrac{1}{ 2\big [2\sin (2x)\cos (2x)\cos (4x)\big ]} + \dfrac{1}{\sin(16x)}$$ What am I missing? Regards,['trigonometry']
2907389,Homomorphism of coordinate rings induces a polynomial map,"I have a question about the proof of Proposition 2 on page 26 of Fulton's algebraic curves. Let $V\subset \mathbb A^n$ and $W\subset \mathbb A^m$ be affine varieties, and let $\Gamma(V)$ and $\Gamma(W)$ be their coordinate rings. Suppose that we have a homomorphism $\alpha\colon \Gamma(V)\longrightarrow\Gamma(W)$ . We want to show that there is a polynomial map from $V$ into $W$ , which induces $\alpha$ . Choose $T_1,...,T_m\in k[X_1,...,X_n]$ with the property $\alpha(\overline{X_1})=\overline{T_1},\ldots,\alpha(\overline{X_m})=\overline{T_m}$ , where bars denote taking residues in $\Gamma(V)$ and $\Gamma(W)$ . We thus get a polynomial map $T=(T_1,\ldots,T_m)\colon\mathbb A^n\longrightarrow \mathbb A^m$ . This induces a homomorphism $\widetilde{T}\colon k[X_1,\ldots,X_m]\longrightarrow k[X_1,\ldots,X_n]$ . Fulton says that it is easy to check that $\widetilde{T}(I(W))\subset I(V)$ . Why should this be true?",['algebraic-geometry']
2907423,Map $f:S^2 \to S^1$ with $f(-x) = -f(x)$,"Consider a continuous function $f:S^2 \to S^1$ with $f(-x) = -f(x)$ for all $x \in S^2$. I intend to show that such map doesn't exist using topological covering/lifting theory. Here my attempts: If we assump that such function $f$ exists then since $S^2$ simply connected and $\mathbb{R}$ is a covering of $S^1$ there exist a lift map $g: S^2 \to \mathbb{R}$ with property $f = p \circ g$. Here  $p: \mathbb{R} \to S^1$ is the canonical covering map. Then I tried to consider a path $\gamma:[0,1] \to S^2$ with property $\gamma(0)= -\gamma(1)$, therefore $\gamma(0), \gamma(1)$ are antipodal. And therefore (by property of $f$) also holds $f(\gamma(0)) = f(-\gamma(1)) = -f(\gamma(1))$. I guess that considering this property one can deduce a contradiction by considering a lift $\widetilde{\omega}:[0,1] \to \mathbb{R}$ of the path $\omega:= f \circ \gamma$. Can anybody explain what here goes wrong/ how to get the desired contradiction? Intiutively I guess that something goest wrong with the uniquess of the lift (see homotopy lifting prop)... but I don't find this last step. Another attempt of mine would be to cosider the new path $\omega^2$ which is obviously a loop. Can I get a contradiction by considering the lift of it? Should the lift be also a Loop? Why? Remark: As in a comment stated below this problem is a special case of Borsum Ulam and can be proved rigorously using homological methods. The intention of this question how to prove the statement for $n=2$ with toolbox from elementary lifting properties / covering theory.","['general-topology', 'covering-spaces']"
2907458,Complex Derivative with respect to conjugate?,"I am reading about complex analysis on my own. I came across this result which is equivalent to Cauchy Riemann equations. A necessary condition for a complex valued function of complex variable to be differentiable at a point is 
$$\frac{df}{d\bar{z}}=0$$ I am trying to practice through the examples. Please have a look and point out the error. Note: I will denote $\frac{df}{d\bar{z}}=f'$ Problem 1 $f(z)=\bar{z}$ Solution: $f'=1$ so nowhere differentiable. Problem 2 $f(z)=\Re(z)$ $2 \Re(z)=z+\bar{z}$, so $f'=1/2$. We conclude that function is nowhere differentiable. Problem 3, $f(z)=|z|$ $f= \sqrt{z\bar{z}}$ $f'=\frac{z}{2\sqrt{z\bar{z}}}$. We conclude that function is not differentiable for $z\neq0$. Problem 4 $f(z)=|z|^{2}$ As $|z|^{2}=z\bar{z}$, we get $f'=z$, so function is not differentiable at $z\neq 0$ Problem 5 $f(z)=\Re(z)^2$ $f=\frac{z+\bar{z}}{2}^2=\frac{1}{4}(z^2+\bar{z}^2+2z\bar{z})$
So $f'=\frac{z+\bar{z}}{2}=\Re(z)$ Now this implies that function is not differentiable at all points $z$ where $\Re(z)\neq0$ Related Questions Since it is just a necessary condition, we can not conclude whether a function is differentiable at the points where $f'=0$. We have to use the definition of differentiability. I know, form the theory of Cauchy Riemann Equations that if partial derivative exist and is continuous then CR equations become a sufficient condition. How to capture this point in $\frac{df}{d\bar{z}}=0$",['complex-analysis']
2907471,An intrinsically curved surface with no extrinsic curvature,"An intrinsic curvature is the property of a manifold itself. It shows it's deviation from euclidean geometry. The extrinsic curvature, on the other hand, depends on how the surface is embedded in a higher dimensional manifold. Now as a beginner student wherever I've seen examples of difference between these two I'm always led to the example of a cylinder. It has no intrinsic curvature but looking at it from R3 it does have an extrinsic curvature. My question is : Is the opposite true? Can I have a surface with no extrinsic curvature(due to my ""clever"" embedding) but is intrinsically curved? If yes, what will be a simple example?","['manifolds', 'geometric-topology', 'riemannian-geometry', 'differential-geometry']"
2907499,"Metric on the space $\lbrace (u,v) \in \mathbb{R}^3\times\mathbb{R}^3 , \langle u,v\rangle=0 \rbrace$","Consider the following set :
$$\Omega=\lbrace (u,v) \in \mathbb{R}^3\times\mathbb{R}^3 , \langle u,v\rangle=0 \rbrace$$ where $\langle ,\rangle$ is the canonical scalar product of $\mathbb{R}^3$. Except that it is the set of all pairs of orthogonal vectors in $\mathbb{R}^3$ , what can be said about this specific space? Does exist any metric to define a distance $d(x,y)$ between two elements $x,y\in\Omega$? Is their any interesting geometrical or topological properties related to such mathematical object?","['general-topology', 'orthogonality', 'geometry', 'metric-spaces']"
2907510,Does $\lim_{n\to\infty} \sum^{n^2}_{k=n}\frac{1}{k}$ exist?,"Does $\lim_{n\to\infty}\sum^{n^2}_{k=n}\frac{1}{k}$ exist? MY TRIAL \begin{align} \lim_{n\to\infty}\sum^{n^2}_{k=n}\frac{1}{k}=\int^{n^2}_{n}\frac{1}{t} \,\mathrm{d}t=\ln n^2- \ln n=\ln n\end{align} Please, am I right? If no, can anyone show me the right answer? Thanks!","['integration', 'definite-integrals', 'analysis', 'real-analysis', 'calculus']"
2907519,What is the integral of $e^{x\cos\theta + y\cos\theta}$,"Knowing that $$\int_{0}^{2\pi} e^{x\cos \theta } d\theta = 2\pi I_0(x)$$ where $I_0$ is the modified Bessel function . Is there a way/trick to find an analytical expression for
$$\int_{0}^{2\pi} e^{x\cos \theta + y\cos \theta} d\theta.$$","['integration', 'special-functions', 'bessel-functions']"
2907541,Finding value of $\lim\limits_{n\rightarrow \infty}\Big(\frac{(kn)!}{n^{kn}}\Big)^{\frac{1}{n}}$,Finding value of $\displaystyle \lim_{n\rightarrow \infty}\bigg(\frac{(kn)!}{n^{kn}}\bigg)^{\frac{1}{n}}$ for all $k>1$ Try: I have solved it using stirling Approximation $\displaystyle n!\approx \bigg(\frac{n}{e}\bigg)^n\sqrt{2\pi n}$ for laege $n$ So we have $\displaystyle \lim_{n\rightarrow \infty}\bigg(\frac{kn}{e}\bigg)^{kn}\cdot \bigg(\sqrt{2\pi k n}\bigg)^{\frac{1}{n}}\cdot \frac{1}{n^k}=\bigg(\frac{k}{e}\bigg)^k$ Could some help me how to solve it without stirling Approximation Thanks.,"['radical-equations', 'limits', 'calculus', 'factorial']"
2907571,Matrices of functions commute,"Given two $n\times n$ matrices  $A(z), B(z)$ with entire functions entries; with $A$ and $B$  invertible on $\mathbb{C}$, and $A$ is normal (i.e., $A(z)A^{*}(z)=A^{*}(z)A(z)$ on $\mathbb{C}$). If $A(z)B(z)=B(z)A(z)$ , and $A(z)B^{*}(z)=B^{*}(z)A(z)$  for all $z\in \mathbb{C}$, does this imply that $$A(z)B(w)=B(w)A(z) , \quad \text{for all}\; z,w\in \mathbb{C}?$$ Added: May be showing if $A(z)A(w)=A(w)A(z)$ could help!","['matrices', 'complex-analysis']"
2907594,Finding the sum $\sum_{k=1}^rk^2\binom {n-k}{r-k}$,"I was stuck while finding the given summation. $$\sum_{k=1}^rk^2\binom {n-k}{r-k}$$ Since $n$ and $r$ are both constants, so I have first converted the above summation into this: $$\sum_{k=1}^rk^2\binom {n-k}{n-r}$$ I have no idea how to proceed next. Any help will be appreciated.","['calculus', 'binomial-coefficients', 'combinatorics']"
2907596,"Let $R$ be the region bounded by $x+y=1, x=0, y=0$. Show $\iint \cos\frac{x-y}{x+y}\, dx\,dy=\frac{\sin1}{2}$ over the region $R.$","Let $R$ be the region bounded by $x+y=1, x=0, y=0.$ Show 
$$\iint_R \cos\frac{x-y}{x+y}\, dx\,dy=\frac{\sin1}{2}.$$ So I've let $u=x-y$, $x+y=v$. Graphically, the domain is a triangle with the slope as the $y=1-x$ line with vertices $(0,1)$ and $(1,0)$. It seems pretty obvious that the domain for $v$ is $0$ to $1$. For $u$, I've imagined a bunch of $y=x-u$ lines whereby $u$ is the variable. So in my mind as $u$ varies we get a stack of lines with gradient $1.$ The domain for $u$ will be when these lines intersect $(0,1)$ and $(1,0)$. Graphically, it seems like $u$ will vary from $1$ to $-1$. Calculating the inverse Jacobian: $$J=
    \begin{vmatrix}
    1 & -1\\
    1 & 1
    \end{vmatrix}=2
$$ $$\frac{1}{J}=\frac{1}{2}.$$ But when I start plugging in the substitution the problem starts: $$\iint_R \cos\frac{x-y}{x+y}\, dx\,dy$$
$$\frac{1}{2}\int^1_0\int^1_{-1}\cos\frac{u}{v}\,du\,dv$$
$$\frac{1}{2}\int^1_0 2v\sin\frac{1}{v}\,dv.$$ After this I'm stuck. Am I on the right track?","['integration', 'multivariable-calculus', 'calculus']"
2907615,Is this operator on $L^\infty$ injective / surjective?,"$$
f \in L^\infty (0,1) \\
Tf(x) = \int_0^x e^{y-x}f(y)dy, x\ge0
$$
I've shown that T is a bounded linear operator from $L^\infty(0,\infty)$ into itself. I've computed its norm (it should be $\|T\| = 1$). 
Now, I was wondering if it is injective and/or surjective.
For injectivity , I have to show that $Tf = Tg \implies f=g \text{ in } L^\infty(0,1)$. This seems to be true
$$ 
Tf(x) = Tg(x) \\ 
e^{-x}\int_0^x e^y f(y) dy = e^{-x}\int_0^xe^yg(y)dy \\
\int_0^x e^y f(y) dy = \int_0^xe^yg(y)dy 
$$
Differentiating both sides with respect to $x$ and using the Fundamental Theorem of Calculus: 
$$
e^x f(x) = e^x g(x) \; a.e.\\
f = g \; a.e.
$$
Is this right? However, I do not know how to show surjectivity ( and I do not if it is surjective ) . 
If it is surjective, then: 
$$
\forall g \in L^\infty(0,\infty), \exists f \in L^\infty(0,\infty): Tf = g
$$
Therefore, I have to solve the following for $f$: 
$$
e^{-x} \int_0^x e^y f(y) dy = g(x)
$$
I try: 
$$
\int_0^x e^y f(y) dy = g(x)e^x \\
e^x f(x) = g'(x)e^x + g(x)e^x \\
f(x) = g(x) + g'(x)
$$
The problem is that I'm writing $g'(x)$ without knowing if $g$ is differentiable (in general, it is not, I think).
I do not know how to proceed. Can someone please help? Thank you.","['integral-operators', 'measure-theory', 'operator-theory', 'functional-analysis']"
2907656,A prime’s square dividing a sum of a geometric sequence [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question For what $p$ primes does there exist two positive integers $(a,b)$, such that
$$\dfrac{1-a^p}{1-a}=bp^2?$$ This is from a junior olympiad from Britian but I can’t solve it. Please help!","['prime-numbers', 'sequences-and-series']"
2907658,On the definition of ergodicity and how it relates to random processes.,"Let $\mathcal{M} : = \{ \mu | \mu \text{ is a probability measure} \}$ , and let $f:\mathbb{R} \rightarrow \mathbb{R}$ be a measurable function. $\mu \in \mathcal{M}$ is ergodic if for all $A \in \mathcal{B} $ (the Borel set on $\mathbb{R}$ ) such that $f^{-1}(A) = A$ either $\mu(A) = 0$ or $\mu(A) = 1$ . Let $f$ have a periodic orbit of period $n \in \mathbb{N} $ with points $\{p_1, \dots, p_n  \}$ then $$\mu = \frac{1}{n} (  \delta_{p_1} + \dots + \delta_{p_n} )$$ is easily seen to be ergodic according to the definition given. Even a weighted average of the $ \delta_{p_1} + \dots + \delta_{p_n}$ would be. Under the article on Ergodicity on wikipedia I find that ""A random process is ergodic if its time average is the same as its average over the probability space"", if I Imagine the orbit of $f$ as a random process this statement does not seem to agree with the definition since the time average would be $$\frac{1}{n} (  p_1 + \dots + p_n )$$ and the average over the probability space is $$\mu = \frac{1}{n} (  \delta_{p_1} + \dots + \delta_{p_n} )$$ (?). Also the statement ""a Markov chain is ergodic if there is a positive probability to pass from any state to any other state in one step"" seems in contrast with the example give with $f$ having a periodic orbit of period $n$ . In short my question is, how does the given definition of ergodicity reconcile itself with the statements quoted on the Wikipedia page? Simple examples are welcome (or utilizing mine would be great).","['ergodic-theory', 'probability-theory', 'probability', 'dynamical-systems']"
2907712,Differential Geometry or Functional Analysis? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 5 years ago . Improve this question I am starting my Master's degree, and I have to chose between these two courses that I have not taken during my Bachelor's (I can only chose one!). I am interested in group theory and in particular geometric group theory. On the one hand, I'd like to do differential geometry to have a stronger basis for studying Lie groups. On the other hand, I know that the study of analytical properties of groups, such as everything around the notion of amenability, relies on some results of functional analysis. If any of you works in (geometric) group theory, what do you think is most important for a mathematician working in that field to master, and what is easier to learn by oneself? Thanks in advance.","['functional-analysis', 'education', 'geometric-group-theory', 'group-theory', 'differential-geometry']"
2907725,No. of solutions of $f(x)=f'(x)$?,"Let $f:[0,1] \to \Bbb R$ be a fixed continuous function such that $f$ is differentiable on $(0,1)$ and $f(0)=f(1)$. Then the equation $f(x)=f'(x)$ admits No solution $x \in (0,1)$ More than one solution $x \in (0,1)$ Exactly one solution $x \in (0,1)$ At least one solution $x \in (0,1)$ As I have tried taking $f(x)=0$ on $[0,1]$ ruled out options 1 and 2 and by Rolle's Theorem there exists $c\in (0,1)$ such that $f'(c)=0$.  Then I thought to construct function $g(x)=f(x)-f'(x)$ to check zeros but I'm stuck because $f'(x)$ need to be continuous. Can anyone give some hint to proceed further?","['continuity', 'real-analysis']"
2907760,Change the trace of a Matrix,"I want to know if I have a matrix $A \in \mathbb{M}_{n\times n}(\mathbb{K}) $ and I want to change the trace multiplying it by a number $\beta \in \mathbb{K}$:
$$ A=\left( \begin{array}{ccc}
\alpha_{11} & ... & \alpha_{1n} \\
\vdots &  & \vdots \\
\alpha_{n1} & ... & \alpha_{nn} \end{array} \right) \to  B=\left( \begin{array}{cccc}
\beta \alpha_{11} & \alpha_{12} & ... & \alpha_{1n}  \\
\alpha_{21} &\beta\alpha_{22}  & & \vdots \\
\vdots &  & & \vdots \\
\alpha_{n1} & ... & ... & \beta\alpha_{nn} \end{array} \right)$$
There exist some $X \in \mathbb{M}_{n\times n}(\mathbb{K})$ s.t $A\times X = B$ and if it exist, what form does it have. Thanks","['matrices', 'trace', 'linear-algebra']"
2907780,Topology and smooth structure on tangent bundle,"My lecture notes on differential geometry read the following (without proof): For $M$ a manifold, let $TM = \bigcup_{p \in M} T_p M$ be the (disjoint) union of all its tangent spaces. Then, there exists a unique topology and smooth structure on $TM$ making it into a smooth manifold such that any section $X:M \rightarrow TM$ of the canonical projection map is smooth if and only if for all smooth functions $f$ on $M$, the function $Xf$ is smooth. I am not quite sure as to how to approach this (I am talking about the uniqueness part, the usual topology and smooth structure evidently imply the desired equivalence). I found a related post without an answer here: Why is the manifold structure on the tangent bundle unique? It seems that in this post, OP also assumes the projection map to be continuous, whereas my lecture notes do not. Any help would be appreciated.","['differential-topology', 'tangent-bundle', 'smooth-manifolds', 'differential-geometry']"
2907932,"Find order, degree & linearity of ordinary D.E.","Given an ordinary differential equation (O.D.E.): $$y\left(\frac{d^5y}{dx^5}\right)^2+x^3\left(\frac{d^3y}{dx^3}\right)^3+x\left(\frac{dy}{dx}\right)=y^2\sin(x^2)$$ Which of the following options is correct for given O.D.E.? a) It is a fifth order linear O.D.E. of degree 2 b) It is a fifth order non-linear O.D.E. of degree 3 c) It is a fifth order non-linear O.D.E. of degree 2 d) None My try: Given D.E. $y\left(\frac{d^5y}{dx^5}\right)^2+x^3\left(\frac{d^3y}{dx^3}\right)^3+x\left(\frac{dy}{dx}\right)=y^2\sin(x^2)$ The order of O.D.E.=highest order=5 The degree of O.D.E.=degree of highest order derivative =2 Since $y$ is multiplied with $\left(\frac{d^5y}{dx^5}\right)$ or $y$ has a power $2$ so it is a non-linear O.D.E. Thus, My answer becomes (c) but I am not sure if i am right. Please tell me if I am wrong or right & correct me if i am wrong & give explanation. Thank you.","['calculus', 'ordinary-differential-equations']"
2907936,Prove that $\lim\limits_{s\to0^+}s^z=\lim\limits_{s\to 0^+} e^{z\ln s}=0$ where $z\in\mathbb C$ and $Re(z)>0$,"Prove that $\displaystyle\lim_{s\to0^+}s^z=\lim_{s\to 0^+} e^{z\ln s}=0$ where $z\in\mathbb C$ and $Re(z)>0$ Using the $\epsilon-\delta$ definition we have Let $\epsilon>0.$ We have to find $\delta>0$ such that $0<s<\delta$ implies $|e^{z\ln s}|<\epsilon$ I have no idea what to do next, could anyone help please? Maybe a hint? or maybe 2 hints? Note I am not asking for the proof since I know this site doesn't work like that.","['complex-analysis', 'limits', 'analysis', 'epsilon-delta']"
2907946,How to solve this equation $\sin 5x = \sin (x + \frac{\pi}{3})$,"Could you give a hint how to solve this equation $\sin 5x=\sin (x + \frac{\pi}{3})$? I tried to change $\sin 5x$ in function of $\sin x$ and $\cos x$, but I wasn't able to go further.",['trigonometry']
2907991,Hadamard product: Optimal bound on operator norm,"Let $A,B$ be $n\times n $ matrices and denote by $A\star B$ the Hadamard product $(A\star B)(i,j)=A(i,j)B(i,j)$ (pointwise matrix multiplication). For $A$ positive definite it is known that 
$$\|A\star B\| \leq \sup_{i,j} |A(i,j)| \|B\|.$$
My question is what happens if we drop the positive definiteness assumption, i.e. what is the best constant $C>0$ such that
$$\|A\star B\| \leq C \sup_{i,j} |A(i,j)| \|B\|$$
holds for arbitrary $n\times n$ matrices $A,B$. Is the constant $C$ independent of the size of the matrix $n$?","['matrices', 'linear-algebra', 'functional-analysis']"
2908016,Calculate $\int_0^{\infty} \frac{x}{\sinh(\sqrt{3}x)} dx$,"I was asked, by a high school student in the UK, how to calculate the following integral: $$\int_0^{\infty} \frac{x}{\sinh(\sqrt{3}x)} dx.$$ It has been a long time since I have done any calculus and most of my immediate thoughts used mathematics that he is unlikely to have seen before. I know that the result is $\frac{\pi^2}{12}$ but I am interested in a proof which a (good) high school student would be satisfied by. I do not mind if it goes a little beyond the A-level further maths syllabus, but I would like to avoid having to teach complex analysis or Fourier analysis just to understand this proof.","['complex-analysis', 'calculus', 'fourier-analysis', 'taylor-expansion']"
2908042,Cobordism theory for piecewise-linear (PL) and topological manifolds,"The Cobordism theory was originally developed by René Thom for smooth manifolds (i.e., differentiable), but there are now also versions for piecewise-linear and topological manifolds . I know the Cobordism theory for smooth manifolds, for example, given two $d$-dimensional manifolds $M_1$ and $M_2$, we can ask whether they are (co)bordant via a $d+1$-dimensional manifolds $W$, such that
$$
\partial W= M_1 \sqcup M_2.
$$
For example, (1) 5-dimensional Dold manifold and Wu manifold are manifolds which are cobordant to each other via 5-dimensional bordism group:
$$
\Omega^{SO}_5=\mathbb{Z}_2.
$$
In other words, my interpretation is that the Dold and Wu manifolds are both the nontrivial generators of $\Omega^{SO}_5=\mathbb{Z}_2$. (2) For example, consider an oriented bordism, bordisms between $4$-manifolds. The signature $\sigma(X^{4k})$ of an oriented $4k$-manifold $X^{4k}$ is an oriented bordism invariant. Now $\sigma(S^4) = 0$
and $\sigma( C P^2) = 1.$ So $S^4$ and $ C P^2$ are not oriented bordant. In fact, $\Omega_4^{{SO}} \cong \Bbb Z$ with generator $[C P^2]$. So in the above, I give one example (Dold manifold and Wu manifold) that are cobordant via $\Omega^{SO}_5$, and another counterexample where $S^4$ and $ C P^2$ are not oriented bordant $\Omega_4^{{SO}}$. Questions : Now, I am not familiar with Cobordism theory of piecewise linear and topological manifolds. Can we explain how the cobordant of piecewise-linear (PL) and topological manifolds is defined, in a simple manner? Can we give one example and another counterexample, in dimensions 3, 4 and 5,  such that two PL topological manifolds are cobordant or not cobordant, respectively?","['cobordism', 'geometric-topology', 'manifolds', 'general-topology', 'algebraic-topology']"
2908051,Trace on $\mathcal{S}(\mathbb{R}^k) \mathbin{\hat{\otimes}_\pi} \mathcal{S}'(\mathbb{R}^k)$,"$\newcommand{\Tr}{\operatorname{Tr}}$ Let $\mathcal{S}(\mathbb{R}^k)$ denote the $k$ -dimensional Schwartz space with the usual topology, and let $\mathcal{S}'(\mathbb{R}^{k}))$ denote its strong dual (i.e. the space of tempered distributions equipped with the topology of uniform convergence on bounded sets). Let $\mathcal{S}(\mathbb{R}^k) \mathbin{\hat{\otimes}_\pi} \mathcal{S}(\mathbb{R}^k)$ denote the completed projective tensor product of $\mathcal{S}(\mathbb{R}^k)$ and $\mathcal{S}'(\mathbb{R}^k)$ . Note that since both the Schwartz space and the space of tempered distributions are nuclear, the projective tensor product coincides with the injective tensor product. If $f\in\mathcal{S}(\mathbb{R}^k)$ and $g\in\mathcal{S}'(\mathbb{R}^k)$ , then we can define $$\Tr(f\otimes \bar{g}) := \overline{\langle{g, \bar{f}}\rangle}_{\mathcal{S}'-\mathcal{S}},$$ where $\langle{\cdot,\cdot}\rangle_{\mathcal{S}'-\mathcal{S}}$ denotes the duality pairing. Now if the duality pairing were a continuous map $$\mathcal{S}(\mathbb{R}^{k}) \times \mathcal{S}'(\mathbb{R}^{k}) \rightarrow \mathbb{C},$$ then by the universal property of the $\pi$ -tensor product, we would obtain a unique continuous map $$\Tr: \mathcal{S}(\mathbb{R}^k) \mathbin{\hat{\otimes}_\pi} \mathcal{S}'(\mathbb{R}^k) \rightarrow \mathbb{C}$$ with the property that $\Tr(f\otimes \bar{g})$ is as above. Unfortunately, the duality pairing is not continuous , it is only separately continuous--this is a general feature of non-normable locally convex spaces. Therefore, the preceding approach fails, which leads me to my question. Question 1. Is there a way to define a ""canonical"" way to define a trace $\Tr$ on $\mathcal{S}(\mathbb{R}^k) \mathbin{\hat{\otimes}_\pi} \mathcal{S}'(\mathbb{R}^k)$ (i.e. a map such that $\Tr(f\otimes\bar{g}) = \overline{\langle{g,\bar{f}}\rangle}$ )? Question 2. If the answer to Question 1 is no, is there a non-canonical way of defining a trace $\Tr$ on $\mathcal{S}(\mathbb{R}^k) \mathbin{\hat{\otimes}_\pi} \mathcal{S}'(\mathbb{R}^k)$ in such a way that if $\gamma\in\mathcal{S}(\mathbb{R}^k) \mathbin{\hat{\otimes}_\pi} \mathcal{S}' (\mathbb{R}^k)$ and can be identified with an element of trace-class operators on $L^2(\mathbb{R}^k)$ , then $\Tr$ coincides with the usual definition of trace?","['tensor-products', 'operator-theory', 'trace', 'functional-analysis']"
2908071,"Proof attempt at ""Adjoint of compact operator is compact"" on Banach spaces","I was trying to prove this result and this is my attempt. Theorem [Schauder] Let $E,F$ be Banach spaces, and let $T:E\to F$ a compact operator. Then its adjoint
  $T^*:F^*\to E^*$ is compact. Proof attempt. An operator between Banach spaces is compact iff the image of any bounded sequence has a Cauchy subsequence. So let $\left\{ v_n\right\}\subset F^*$ be a bounded sequence, with $\|v_n\|\leq C$. By the sequential Banach-Alaoglu's theorem, $\left\{ v_n\right\}$ has a weakly-star converging subsequence to some $\bar{v}\in F^*$, which we keep calling $\left\{ v_n\right\}$. Thus
$$|\left\langle v_{n}-\bar{v},y\right\rangle| \to 0,\qquad \forall y\in F   $$
To prove the thesis, we need to show that $\left\{ A^*v_n\right\}$ has a Cauchy subsequence,  which we keep calling $\left\{ A^*v_n\right\}$. Let $B_E$ be the closed unit ball of $E$; we have
\begin{align*}\|A^*v_n-A^*v_m\|_{E^*}&=\sup_{x\in B_E}|\left\langle A^*v_n-A^*v_m,x\right\rangle|=\sup_{x\in B_E}|\left\langle v_n-v_m,Ax\right\rangle|=\\ 
&=\sup_{y\in T(B_E)}|\left\langle v_n-v_m,y\right\rangle|
\end{align*}
so it suffices to show that the latter term converges to $0$ as $n,m\to +\infty$.\ To this purpose, since $T$ is compact, then $B':=\overline{T(B_E)}$ is compact in $F$. Thus, for all $n\in\mathbb{N}$ there is $y_n\in B'$ such that 
$$\sup_{y\in T(E)}|\left\langle v_n-\bar{v},y\right\rangle|\leq \sup_{y\in B}|\left\langle v_n-\bar{v},y\right\rangle|= |\left\langle v_n-\bar{v},y_n\right\rangle|$$
Since $\left\{y_n\right\}\subset B'$ and $B'$ is compact, $\left\{y_n\right\}$ has a converging subsequence, which we keep calling $\left\{ y_n\right\}$, so that $y_n\to \bar{y}\in B'$. Thus
 \begin{align*}|\left\langle v_n-\bar{v},y_n\right\rangle|&\leq |\left\langle v_n-\bar{v},y_n-\bar{y}\right\rangle|+|\left\langle v_n-\bar{v},\bar{y}\right\rangle|\leq\\ 
 &\leq 
 2C\|y_n-\bar{y}\|+ |\left\langle v_n-\bar{v},\bar{y}\right\rangle|\to 0 \end{align*} And finally 
$$\sup_{y\in T(E)}|\left\langle v_n-v_m,y\right\rangle|\leq \sup_{y\in T(E)}|\left\langle v_n-\bar{v},y\right\rangle|+ \sup_{y\in T(E)}|\left\langle \bar{v}-v_m,y\right\rangle|\to 0$$
and the thesis is proved. The problem is that the sequential Banach Alaoglu's theorem holds only when $E$ is separable. Is there a way I could adapt this proof to the general case? Maybe using nets instead of sequences?","['operator-theory', 'functional-analysis', 'compactness']"
2908157,"Given $\cos^2 x = 2 \sin x \cos x$, why can't I cancel $\cos x$ to get $\cos x = 2 \sin x$?","If I have a function where I know $\cos^2 x = 2 \sin x \cos x$. Why can I not cross out $\cos x$ on both sides, because I get different values for $\cos x = 2 \sin x$?","['algebra-precalculus', 'trigonometry']"
2908185,Numerical Triangle Question,"If a numerical triangle is constructed such that each number is the sum of three numbers in the previous row: the number above it, the number to the left of the one above it, the number to the right of the one above it, and each number that isn't filled is treated as 0. We get this
$$\begin{matrix}
&&&&&1\\
&&&&1&1&1\\
&&&1&2&3&2&1\\
&&1&3&6&7&6&3&1\\
&...&...&...&...&...&...&...&...&...\\
\end{matrix}$$ I'm trying to prove that each row after the second row will always contain an even number. I'm not really sure how to go about it.","['number-theory', 'discrete-mathematics']"
2908234,Equations with factorials,"Solve the following equation :
$$4 (x+1)!= x! (2 x-6)!$$
My turn :$$24(x+1)!=6 x! (2x-6)!$$
$$4!(x+1)!=3!x!(2x-6)!$$
$$\frac{(x+1)!}{3!x!}=\frac{(2x-6)!}{4!}$$
I tried to get a formula of a permutation in both sides but i could not do it",['combinatorics']
