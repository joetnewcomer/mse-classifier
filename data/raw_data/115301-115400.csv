question_id,title,body,tags
1689429,Determining Sample Size for a Desired Margin of Error,"I'm trying to study for a test in my AP Statistics course. My lecturer spent the majority of the unit going over the various proportion tests. On my review, I was presented with the following question: Suppose that you wanted to estimate p, the true proportion of students at your school who have a tattoo with 98% confidence and a margin of error no more than 0.10. How many students should you survey? What I'm not understanding is what should be substituted for p . In the given problem, no value for p is given, but yet I need to find n using the following formula: $$
ME = (z\ast )(\sqrt{\frac{p(1-p)}{n}})
$$ How can I determine a value for n ?",['statistics']
1689448,Statistical Testing of a Biased Coin,"Somebody comes up to you and says that the quarter he has in his hand is unfair. How do we know if he's telling the truth? First of all, what are the possible hypotheses? The coin could be completely fixed ($p = 1$) and only land on heads (maybe both sides are the same). The coin could be completely fair ($p = 0.5$) and land on both heads and tails with equal frequency. Or the coin could be between these two extremes ($p \in (0.5, 1)$) and have a varying degree of bias. So we design an experiment. Let $C$ be the random variable representing the number of times the coin lands on the most frequent side (wlog). $C \sim Binomial(n, p)$. We flip the suspected coin $n$ times and observe that it comes up heads $k$ times. What is $P[p = x | C = k]$? We know that by Bayes theorem that $P[p = x | C = k] = \frac{P[C = k | p = x] P[p = x]}{P[C = k]}$ However, here is the problem: $p$ needs to be assigned a continuous probability distribution over the support of $(0.5, 1)$, but that entails that $P[p = x] = 0$ for any value of $x$. How do I overcome this?","['statistics', 'hypothesis-testing']"
1689483,"Spivak ""Differential Geometry ""volume 1 page 41","I want to ask question related to Lemma 6 from Spivak ""Differential Geometry Volume 1"" page 41. The lemma states: If $f:\mathbb{R}^{n}\rightarrow\mathbb{R}^{n}$ is $C^{1}$ and $A\subset\mathbb{R}^{n}$ has measure 0, then $f(A)$ has measure 0. The author claims that we can assume $A$ to be contained in a compact set $C$, and because $|f(x)-f(y)|\leq n^{2}K|x-y|$ for all x,y in C, f takes rectangles of diameter d into sets of diameter $\leq n^{2}Kd$. Then, Spivak wrote"" This clearly implies $f(A)$ has zero measure if $A$ does"". Could anyone enlighten me why he can straightaway claimed that $f(A)$ has zero measure? To my knowledge so far, set which has zero measure might not imply that it has zero diameter (for instance, set of all rational numbers between 0 and 1).","['differential', 'measure-theory', 'geometry']"
1689500,Shortcut for finding number of rational terms in $(a^{\frac{1}{p}}+b^{\frac{1}{q}})^n$,"My teacher taught me a shortcut for finding number of rational terms in $\left(a^{\frac{1}{p}}+b^{\frac{1}{q}}\right)^n$. For example, find the number of rational terms in $\left(5^{\frac{1}{6}}+2^{\frac{1}{8}}\right)^{100}$. Algorithm: Find LCM of $(p,q)$. In the above example, its $24$. Divide $n$ by the LCM obtained. Let quotient be $Q$ and remainder be $R$. If $R=0$, number of rational terms is $Q+1$. Else its $Q$. In the above example, $R\neq 0$. So number of rational terms is $4$. How did he derive this shortcut?","['algebra-precalculus', 'binomial-theorem']"
1689523,Laplace Question $f(t) = e^{-t} \sin(t)$,"I need help with this Laplace question. $$f(t) = e^{-t} \sin(t) $$ Answer should be $\dfrac{1}{s^2 + 2s + 2}$ What I'm currently doing is as follows: $u = \sin(t)\qquad$ $dv = e^{-(s+1)t}dt$ $du = \cos(t)dt\qquad$ $v = \dfrac{e^{-(s+1)t}}{-(s+1)}$ $\dfrac{-\sin(t) e^{-(s+1)t}}{-(s+1)}  - \int\dfrac{ e^{-(s+1)t}\cos(t)}{ -(s+1)} dt$ But even if I solved the integral, I wouldn't get this (which is what I should, see picture).","['laplace-expansion', 'laplace-method', 'ordinary-differential-equations', 'laplace-transform']"
1689525,"If $s(x)= \int \sqrt{1+ \Big(\frac{dy}{dx}\Big)^2} dx$, what is $x(s)$?","$s(x)$ is the formula for arc length of a function $f(x)=y$. In the book I'm studying, curvature is defined as the instantaneous rate of change of direction (inclination of angle $\theta$) with respect to arc length, where $\theta = \arctan\big(\frac{dy}{dx}\big) $, all of which makes sense to me. In order to find the curvature function, or $\frac{d\theta}{ds}$, the author goes: $$\frac{d\theta}{ds} = \frac{d}{ds} \left(\arctan\left(\frac{dy}{dx}\right)\right)$$ Followed by: Since $\theta$ is a function of $x$, to get $\frac{d\theta}{ds}$ we have to use the chain rule: $$\frac{d\theta}{ds} = \frac{d}{dx}\left(\arctan \left(\frac{dy}{dx}\right)\right) \cdot \frac{dx}{ds}$$ where $$\frac{dx}{ds} = \frac{1}{\frac{ds}{dx}} = \frac{1}{\sqrt{1+ \big(\frac{dy}{dx}\big)^2}}$$ All of this makes sense, even intuitively to some extent. However, I'm unsatisfied by the ""skipping"" of the original function. In other words, I'd like to have an expression for $\theta(s)$, from which I could directly take the derivative $\frac{d\theta}{ds}$. But I can't figure out how to do it and I get lost between all of the different functions and how they interact, and I think my main problem is that I have no idea how to get an expression for $x(s)$","['derivatives', 'calculus', 'functions']"
1689566,Poisson Process: indepedent increment,"Let $\{N(t): t\geq0\}$ be a Poisson process of rate $\lambda$, and let $S_n$ denote the time until the $n_{th}$ event occurs. compute $P(S_3>5|N(2)=1)$ Attempt: Notice that $P(S_3>5)=P(N(5)<3)$. Therefore, we write $P(N(5)<3|N(2)=1)$. Using indepedent increment, this is equivalent as $P(N(5)-N(2)\leq1)=P(N(3)\leq1)=e^{-3\lambda}(1+3\lambda)$ . What do you guys think?","['probability-theory', 'poisson-process', 'probability', 'exponential-distribution', 'poisson-distribution']"
1689602,Cohomology of affine hypersurface,"I'm interested in calculating cohomology of a smooth affine hypersurface (over an arbitrary field). I know I can use (algebraic) de Rham cohomology, which is ""easy"" in the complex case, but even there I'm finding the computations a bit messy for, say, polynomials with many variables. Any advice for me? Thanks!","['algebraic-geometry', 'reference-request', 'etale-cohomology', 'affine-schemes', 'soft-question']"
1689603,density and cumulative functions of a random variable multiplied by a constant,"I have 2 related questions that I am stuck on, in particular, there is the following: ""Let X be a random variable with density function $f_{X}$ , and let $Y
> = X + b$, $Z = aX$, and $W = aX + b$, where $a \neq 0$. Find the density functions $f_{Y}$ , $f_{Z}$, and $f_{W}$"" As a follow up, the 2nd goes as follows ""Let X be a random variable with cumulative distribution function $F_{X}$, and let $Y=X+b$,$Z=aX$,and $W =aX+b$,where $a$ and $b$ are any constants. Find the cumulative distribution functions $F_{Y}$ , $F_{Z}$ , and $F_{W}$"" I would be able to figure out the two if one just shows me how to do the case for $a > 0$ because I think it is quite analogous. However, I am quite stuck on these two questions. I know that for the former question, the answer is given by $a \neq 0: f_{W}(w) = \frac{1}{|a|}*f_{X}(\frac{w-b}{a})$ but I am not quite sure how this result is derived and would like some help. Would greatly appreciate any sort of help. Thank you.","['probability-theory', 'probability', 'probability-distributions']"
1689616,Are there any good statistical inference exercise and solutions books?,"I was wondering if anyone was aware of any exercise and solutions books on statistical inference at a graduate level (ie, UMVUE, UMP tests, hypothesis testing) that contains nothing but exercises and solutions? I would like to do a look of problems to strengthen my understanding of inference and am interested in finding a book that is similar to 1000 Exercises in Probability by Grimmett and Stirzaker . In this book, they have over 1000 exercises with corresponding solutions. Thanks in advance for the recommendations!","['reference-request', 'statistics', 'book-recommendation']"
1689620,Lipschitz function with right derivative =0,"$f:\mathbb{R}\to\mathbb{R}$ is a Lipschitz function satisfying $$\forall x\in\mathbb{R}, \lim_{n\to\infty} n(f(x+\frac1n)-f(x))=0$$
I want to show that $f$ is constant everywhere. I proved 
$$\lim_{y\to x^+} \frac{|f(y)-f(x)|}{|y-x|}=0$$
by choosing $y\in[x+\frac1{n+1},x+\frac1n]$ and using Lipschitz condition. How can I finish the rest?","['derivatives', 'real-analysis', 'lipschitz-functions']"
1689628,Trouble with double integration,"I'm simply trying to compute the following double integral: $$ \int_1^4\int_0^3\ (\ x\ +\ 2y\ )\ dx\ dy $$ And here are my steps: $$ \int_1^4\ \left.(\ \frac{1}{2}x^2\ +\ 2xy\ )\right|_0^3\ dy $$
$$ \int_1^4\ (\ \frac{9}{2}\ +\ 6y\ )\ dy $$
$$ \frac{9}{2}\ +\ 6\int_1^4\ y\ dy $$
$$ \frac{9}{2}\ +\ 6\ \frac{1}{2}\left.(\ y^2\ )\right|_1^4 $$
$$ \frac{9}{2}\ +\ 3(\ 16\ -\ 1\ ) $$
$$ \frac{9}{2}\ +\ 3(\ 15\ ) $$
$$ \frac{9}{2}\ +\ 45 $$
$$ \frac{9\ + 90}{2} $$
$$ \frac{99}{2} $$ The answer according to my book is 117 / 2, however. $$ \int_1^4\int_0^3\ (\ x\ +\ 2y\ )\ dx\ dy\ =\ \frac{117}{2} $$ What am I doing wrong?","['multivariable-calculus', 'multiple-integral']"
1689653,Problem on similar triangles in a weakened axiom system,"In the figure above, $A'C'$ is parallel to $AC$. It is obvious, using similar triangles, that if $B$ is the midpoint of $AC$, then $B'$ is the midpoint of $A'C'$. I would like to know how easily this can be proved without using the theory of ratio, similar triangles or area. Loosely speaking, what this means is that I don't want to use any theorems derived from considerations that involve products of lengths or irrational ratios of lengths. I will state the problem more formally in terms of Hilbert's axiom system. I would like a proof relying only on the axioms of incidence, order and congruence, as well as the parallel axiom, but not using Archimedes' axiom and its consequences. I would also like the proof to be purely geometric. I add this requirement because I already know that it is possible, based on the stated axioms, to construct an ordered field $F$ such that the plane is isomorphic to $F^2$, and the problem then becomes trivial. But that construction is relatively involved, and what I would like is the most direct geometric proof possible. I would prefer a proof not using any assumptions about the intersection of two circles or of a circle and a line, but a proof using these would be better than no proof.","['euclidean-geometry', 'geometry']"
1689657,How can I Differentiate $ y = x^{2/3} $ using first principles,"How can I Differentiate $ y = x^{2/3} $ using first principles Using the normal rule to find derivative, I got: $dy/dx = ⅔x^{-⅓}$ I don't understand the first principles method. Someone please help. Thanks","['derivatives', 'calculus']"
1689659,"Number of permutations of the word ""PERMUTATION"" such that no two vowels occur together and no two Ts occur together","In how many ways we can arrange the letters of the word ""PERMUTATION"" such that no two vowels occur together and no two Ts occur together. I first arranged consonants including one T as below: $*P*R*M*T*N*$ Now in $6$ star places I will arrange the vowels $A,E,I,O,U$ which can be done in $\binom{6}{5} \times 5!=6!$ ways. Also $P,R,M,N,T$ can themselves arrange in $5!$ ways. Hence, total number of ten letter words now is $5! \times 6!$ . But one $T$ should be placed in eleven places of the ten letter word such that it should not be adjacent to $T$ which is already there. Hence, the remaining $T$ has $9$ ways to place. Hence, total ways is $6! \times 5! \times 9$ . But my answer is not matching with book answer. Please correct me.","['algebra-precalculus', 'combinatorics', 'permutations']"
1689660,Evaluate square of first Chern class on K3 Surface,"I want to let $X$ be a K3 surface, with $Y \subset X$ a smooth curve with genus $g$.  Since $Y$ is a hypersurface, we have a line bundle $\mathcal{O}(Y)$ on $X$.  I'm curious how to prove the following statement, $\int_{X} c_{1}^{2}(\mathcal{O}(Y)) = 2g-2$ I feel like I most likely need to use some exact sequence, perhaps like, $0 \to \mathcal{O}(-Y) \to \mathcal{O}_{X} \to \mathcal{O}_{Y} \to 0$, but I'm not totally sure how.  Also, perhaps there are other ways to get at this formula, but I'm hoping for a rather direct argument specifically pertaining to this integral.  Much thanks in advance.","['riemann-surfaces', 'algebraic-geometry']"
1689682,Prove that $\int_0^4 \frac{\ln x}{\sqrt{4x-x^2}}~dx=0$ (without trigonometric substitution),"The integral is from P. Nahin's ""Inside Interesting Integrals..."", problem C2.1. His proposed solution includes trigonometric substitution and the use of log-sine integral. However, I think the problem should have an easier solution (without appealing to another complicated integral at least). I have the following trick in mind. Let's introduce the substitution $x=4-z$ $$I=\int_0^4 \frac{\ln x}{\sqrt{4x-x^2}}~dx=\int_0^4 \frac{\ln (4-z)}{\sqrt{4z-z^2}}~d(4-z)=\int_0^4 \frac{\ln (4-z)}{\sqrt{4z-z^2}}~dz$$ $$2I=\int_0^4 \frac{\ln (4x-x^2)}{\sqrt{4x-x^2}}~dx$$ $$I=\int_0^4 \frac{\ln \sqrt{4x-x^2}}{\sqrt{4x-x^2}}~dx$$ And here I'm stuck. I'm not sure if this can go somewhere. Maybe partial integration can help, but I don't know how to choose the functions. What do you think? Here is a question about this integral . Only one answer does not use trig substitution, it used gamma function instead. If there are no other ways, I'm prepared to give up on my question. But I would be grateful if it's left open at least for several days Edit After many attempts, I conclude that there is no trick to this integral. The reason is: the general form of this integral in not zero, but has the same symmetry properties, as the above case: $$I(a)=\int_0^a \frac{\ln x}{\sqrt{ax-x^2}}~dx=\int_0^a \frac{\ln (a-x)}{\sqrt{ax-x^2}}~dx=\int_0^a \frac{\ln \sqrt{ax-x^2}}{\sqrt{ax-x^2}}~dx \neq 0$$ $$I(4)=0$$ So we will get nothing from symmetry considerations alone. There are two possible ways to solve this - either trigonometric substitution or gamma function. Edit 2 I was wrong it seems, see the accepted answer.","['definite-integrals', 'calculus']"
1689712,"Use Cauchy's Theorem to show that if $\int_{0}^{\infty}f(x)dx$ exists, then so does $\int_{L}f(z)dz$","Suppose that $f(z)$ is analytic at every point of the closed domain $0 \leq arg z \leq \alpha$ $(0 \leq \alpha \leq 2 \pi)$, and that $\lim_{z \to \infty}z f(z) = 0$. I need to prove that if the integral $\displaystyle J_{1}=\int_{0}^{\infty}f(x) dx$ exists, then the integral $\displaystyle J_{2}=\int_{L}f(z)dz$, where $L$ is the ray $z=r e^{i \alpha}$, $0 \leq r \leq \infty$. Moreover, I need to show that $J_{1} = J_{2}$ I have been given the hint to use Cauchy's Theorem (not the Cauchy integral formula or residues - answers using either of those things are useless to me), and the result of the previous problem, which states as follows: If $f(z)$ is continuous in the closed domain $|z|\geq R_{0}$, $0 \leq arg z \leq \alpha$ $(0 \leq \alpha \leq 2 \pi)$, and if the limit $\displaystyle \lim_{z \to \infty} zf(z) = A$ exists, then $\displaystyle \lim_{R \to \infty}\int_{\displaystyle \Gamma_{R}}f(z)dz = i A \alpha$, where $\Gamma_{R}$ is the arc of the circle $|z|=R$ lying in the given domain. So, for this problem, I can use the fact that $\lim_{z \to \infty}zf(z) = 0$ to show that $\displaystyle \lim_{r \to \infty}\int_{\displaystyle \Gamma_{r}}f(z)dz = 0$ at some point, I guess. Thus far, I've tried approaching this problem in two different ways. The first way was to start out with $J_{2} = \int_{L}f(z)dz$ and then try to get $L_{1}$ to pop out somewhere. Didn't get too far with that, and anyway, I'm not sure that it is correct to write $\int_{L}f(z)dz = \lim_{r \to \infty}\int_{0}^{2\pi}f(re^{i\alpha})ire^{i \alpha}d \alpha$. All of these angles and args are confusing me, and I'm not even entirely sure what the domain on which $f(z)$ is analytic looks like. The second way was to start out with $J_{1} = \int_{0}^{\infty}f(x) dx$, and try to parametrize it in terms of $z = re^{i \alpha}$. But, I'm not sure exactly how to do this (again, the domain is confusing. Tried to draw it; didn't help. Maybe I'm just not visualizing it right). Then, at some point, I assume I can apply Cauchy's Theorem and the given limit. I'm guessing that since Cauchy's Theorem is involved and that the given limit goes to $0$, I'm probably going to wind up with $0 = J_{1} = J_{2}$, but I need a lot of help and guidance to show this. I'm at my wits end, don't have a lot of time to figure this out, and am starting to panic. Please help.","['complex-numbers', 'complex-integration', 'complex-analysis', 'improper-integrals', 'integration']"
1689723,Integral of divergence over a closed surface,"I am reading a paper, where an integral of a divergence over a closed surface is used without proof. $\oint_S [\nabla \cdot \vec{v}(\vec{r})] d\vec{s} = 0$ , where $\vec{v}$ is tangential to the surface ( $\vec{v}(r)\cdot \vec{n}(\vec{r}) = 0$ ) I have looked at vector calculus identities and Green theorems and can't seem to find the expression I need. Any suggestions?","['surface-integrals', 'integration', 'vector-analysis']"
1689725,"If $Y_1, \ldots, Y_n \sim Poisson(\lambda)$ are iid, how to show that $E(Y_1 | T = \sum_{i=1}^{n}Y_i) = \frac{T}{n}$?","Suppose I have that $Y_1, \ldots, Y_n \sim Poisson(\lambda)$ are iid. I saw a line in a book that said that if $T = \sum_{i=1}^{n}Y_i$, then: $$
E(Y_1 | T) = \frac{T}{n}
$$ I am lost as to how they obtain this. One approach I did was: $$
E(Y_1 | T) = E\left(Y_1 | \sum_{i=1}^{n}Y_i = t\right)  = E\left(Y_1 | Y_1 = t-\sum_{i=2}^{n}Y_i \right) = E\left(T-\sum_{i=2}^{n}Y_i\right) = T- (n-1)\lambda
$$ However, I know this is wrong but dont know why.","['statistical-inference', 'statistics', 'probability', 'conditional-expectation', 'poisson-distribution']"
1689779,A matrix norm inequality,"Given a real $m\times n$ matrix $C$, a $m\times m$ diagonal matrix $p$ whose diagonal entries $p_{ii}$ are either 0 or 1, and a $n\times n$ diagonal matrix $q$ whose diagonal entries $q_{ii}$ are either 0 or 1. Let $P(\alpha)=\frac{\exp(i\alpha)}{2}p + \frac{I-p}{2}$, a diagonal matrix whose diagonal elements are either $1/2$ or $\exp(i\alpha)/2$. Let $Q(\alpha)=\frac{\exp(i\alpha)}{2}q + \frac{I-q}{2}$, a diagonal matrix whose diagonal elements are either $1/2$ or $\exp(i\alpha)/2$. Then we can construct the function
$$n(\alpha)=\frac{\|P(\alpha) C + C Q(\alpha)\|}{\|C\|}$$
where the norm is the operator norm . The figure below shows all possible $n(\alpha)$ curves for a $7\times 7$ matrix $C$. We are interested in the behaviour of $n(\alpha)$ for $\alpha\in[0,\pi]$. We can prove easily that $n(\alpha)\leq 1$:
$$\frac{\|P(\alpha) C + C Q(\alpha)\|}{\|C\|}\leq \frac{\|P(\alpha) C \|+\| C Q(\alpha)\|}{\|C\|}\leq \frac{\|P(\alpha)\|\| C \|+\| C \|\|Q(\alpha)\|}{\|C\|}\\
\leq \frac{\frac{1}{2}\| C \|+\| C \|\frac{1}{2}}{\|C\|} \leq 1$$ In the case where $P(\alpha)=I/2$, we can easily prove that $n(\alpha)$ is a nonincreasing function of $\alpha$:
$$n(\alpha+\delta_{\alpha})=\frac{\|C/2 + C Q(\alpha+\delta_{\alpha})\|}{\|C\|}=\frac{\|C (I/2+ Q(\alpha+\delta_{\alpha}))\|}{\|C\|}\\
=\frac{\|C (I/2+ Q(\alpha))(I/2+ Q(\alpha))^{-1}(I/2+ Q(\alpha+\delta_{\alpha}))\|}{\|C\|}\\
\leq n(\alpha)\|(I/2+ Q(\alpha))^{-1}(I/2+ Q(\alpha+\delta_{\alpha}))\|$$
$(I/2+ Q(\alpha))^{-1}(I/2+ Q(\alpha+\delta_{\alpha}))$ is a diagonal matrix with diagonal elements either 1 or $\frac{1+\exp(i(\alpha+\delta_{\alpha}))}{1+\exp(i\alpha)}$. Note $|\frac{1+\exp(i(\alpha+\delta_{\alpha}))}{1+\exp(i\alpha)}|\leq 1$ for relevant parameter values ($\alpha\in[0,\pi],\delta_{\alpha}>0,\alpha+\delta_{\alpha}\leq\pi$), so $\|(I/2+ Q(\alpha))^{-1}(I/2+ Q(\alpha+\delta_{\alpha}))\|\leq 1$ so $n(\alpha+\delta_{\alpha})\leq n(\alpha)$, so $n(\alpha)$ is indeed a non-increasing function of $\alpha$. So, on to the actual question I suspect that $n(\alpha)$ is always a non-increasing function of $\alpha$, not just in the $P=I/2$ case as shown above, but the proof technique used above does not work in the general case. How could I prove this? It also seems like $n(\alpha)\geq \cos(\alpha/2)$. How could I prove this?","['matrices', 'normed-spaces']"
1689786,"Cyclic Modules, Characteristic Polynomial and Minimal Polynomial","Suppose that $\mathrm{dim}_{F}M<\infty$ for $F$ a field and $M$ an $F$ vector space. Let $T$ be a linear transformation on $M$. Show that $M$ is cyclic (as an $F[x]$ module) if and only if $m(x)$ is the characteristic polynomial of $T$, for $m(x)$ being the minimal polynomial of $T$. How would one be able to show this? I'm not sure on how to start with either direction. We know that the torsion of $M$ would just be $M$ (since $m(T)=0$) if we consider $M$ as an $F[x]$ module with $x$ being represented as the action of $T$ (i.e. $p(x) \cdot v=p(T)v$). Would the Cayley-Hamilton theorem help in this case? Thanks for the help.","['modules', 'abstract-algebra', 'characteristic-polynomial', 'linear-algebra', 'vector-spaces']"
1689806,Probability that one part of a randomly cut equilateral triangle covers the other,"If you make a straight cut through a square, one part can always be made to cover the other. (This is true by symmetry if the cut goes through the centre, and if it doesn't, you can shift it to the centre while taking from one part and giving to the other.) However, if you cut an equilateral triangle, it may or may not be the case that one part can be made to cover the other. In some cases it may depend on whether we're allowed to flip the parts; I'll leave that to you in case one or the other version has a more elegant solution. How can the cuts that allow one part to cover the other best be characterized? What is the probability that a random cut will allow one part to cover the other? Of course we need to specify a distribution for the cuts, and again I'll leave you to choose between two plausible distributions in case one yields a nicer result: Either Jaynes' solution to the Bertrand ""paradox"" (i.e. random straws thrown from afar, with uniformly distributed directions and uniformly distributed coordinates perpendicular to their direction), or a cut defined by two independently uniformly distributed points on two different sides of the triangle. Update : I've posted the case without flipping as a separate question .","['geometric-probability', 'probability', 'triangles']"
1689831,Simplify Product of sines,"Is there a way simplify this product? $$
\sin\left({n} \frac{\pi}{2}\right)  \sin\left({n} \frac{\pi}{3}\right) \sin\left({n} \frac{\pi}{4}\right) ...\sin\left({n} \frac{\pi}{n-1}\right) 
$$ And, is this the correct way to write it?
$$
 \prod_{m=2}^{n-1} \sin\left(n \frac{\pi}{m}\right)
$$ I'm not a professional so I'd appreciate a simple explanation.","['products', 'trigonometry', 'trigonometric-series']"
1689839,Divergence theorem in curvilinear coordinates,"Suppose I have a tensor \begin{gather}
\stackrel{\leftrightarrow}{A} =
\begin{bmatrix}
a_{11}(\vec{r}) & a_{12}(\vec{r}) & a_{13}(\vec{r})\\
a_{21}(\vec{r}) & a_{22}(\vec{r}) & a_{23}(\vec{r})\\
a_{31}(\vec{r}) & a_{32}(\vec{r}) & a_{33}(\vec{r})
\end{bmatrix}
\end{gather} where $\vec{r} = x_{1} \hat{e}_1 + x_{2} \hat{e}_2 + x_{3} \hat{e}_3$ The divergence of this tensor in general curvilinear coordinates is  given by \begin{gather}
\nabla^{c} \cdot \stackrel{\leftrightarrow}{A} =
\left[
  \frac{\partial A_{ij}}{\partial x^{k}} - \Gamma_{ki}^{l} A_{lj} - \Gamma_{kj}^{l} A_{il}
\right] g^{ik} \vec{b}^{j}\\
\vec{b}_{i} = \frac{\partial_{x_{i}} \vec{r}}{
  \left|
    \partial_{x_{i}} \vec{r}
  \right|
}
\end{gather} Using Mathematica, I computed the volume integral of the curvilinear divergence for cylindrical coordinates, giving
\begin{gather}
  \iiint \nabla^{c} \cdot \stackrel{\leftrightarrow}{A} dV =
  \begin{bmatrix}
    r \int a_{11} d\theta dz + \int a_{12} dr dz +
    \int r a_{13} dr d\theta -
    \int a_{22} dr d\theta dz\\
    r \int a_{21} d\theta dz + \int a_{22} dr dz +
    \int r a_{23} dr d\theta +
    \int a_{12} dr d\theta dz\\
    r \int a_{31} d\theta dz + \int a_{32} dr dz + \int r a_{33} dr d\theta
  \end{bmatrix}
\end{gather} This does not match the traditional Divergence theorem I'm familiar with, or at least it doesn't appear so to me because of the extra triple integral terms $\vec{C}$: \begin{gather}
\iiint \nabla^{c} \cdot \stackrel{\leftrightarrow}{A} dV = \oint A_{ij} n_j \vec{b}_i dS + \vec{C}\\
\vec{C} \neq 0
\end{gather} What is the correct transformation from the volume integral of the curvilinear divergence to some surface integral?","['multivariable-calculus', 'tensors', 'coordinate-systems', 'vector-analysis']"
1689849,Pullback of an invertible sheaf through an isomorphism,"Consider an isomorphism of schemes $(f,f^{\#})(X,\mathcal{O}_X)\to(Y,\mathcal{O}_Y)$. Moreover let $\mathcal F$ be an invetible sheaf on $Y$ and  let $f^{*}\mathcal{F}$ be its pullback. Is it true that $\chi(\mathcal{F})=\chi(f^{*}\mathcal{F})$? Clearly $\chi(\cdot)$ is the Euler-Poincaré characteristic of the sheaf.","['schemes', 'sheaf-theory', 'sheaf-cohomology', 'algebraic-geometry']"
1689878,What is THE domain of analyticity of a holomorphic function?,"I am self-studying complex analysis, and I am a little bit confused on notations. Suppose that $f:U \to \mathbb C $ is a holomorphic function defined on an open subset of $\mathbb C^n $. I understand that every holomorphic extension of $f$ to a connected open set containing $U$ is uniquely determined by $f$. I understand also that there may be many maximal holomorphic extensions of $f$. However, sometimes I read things like ""find THE domain of holomorphy of the locally-defined holomorphic function ..."" and so on. My question is: what is THE domain of analyticity of a function? If it is meant to be the domain of a maximal holomorphic extension on it, then why use the word ""THE"", since such maximal holomorphic extension is not unique? They refer to some particular maximal holomorphic extension? Thank you.",['complex-analysis']
1689889,Lower limit topology is normal,"How do I prove that the space of real numbers, under the lower limit topology, is a normal space. I could prove very easily that it is regular, by using an argument of basic sets, but I haven't been able to generalise that argument.","['general-topology', 'sorgenfrey-line']"
1689946,Multivariate Inverse Transformation Sampling,"Summary Given a multivariate density distribution, I use inverse transformation sampling to sample points from this distribution. While the first dimension exhibits the correct distribution, all other dimensions contain a slight, stable error. Details My density distribution is given as a bilinear interpolation on the $([0-1], [0-1])$ rectangle. In the rest of this question, I use the following example: $$
d(x,y)=\frac{4}{11}(2+x+2y-3xy)
$$ This results in the following density plot (brighter colors represent higher density): The cumulative density function is $$
cum(x,y)=\int_{0}^{x} \int_{0}^{y} d(px,py) dpy\ dpx = \frac{1}{11}(8xy+2x^2y+4xy^2-3x^2y^2)
$$ In order to sample from this distribution, I draw two samples $ux$ and $uy$ from the uniform $[0, 1)$ distribution and transform them to $x$ and $y$ as follows: $$
cum(x, 1)=ux \\
x = 6-\sqrt{36-11ux}
$$ and
$$
cum(x, y)=ux \cdot uy \\
y = \frac{4+x-\sqrt{16+48uy+8x-40uy x+x^2+3 uy x^2}}{3x-4}
$$ The samples resulting from this transformation look reasonable (5000 samples in the following figure): I tried to verify the result by approximating the cumulative density from the samples by simply counting how many of the samples have a smaller or equal x and y coordinate. Here are some results for 10 million samples. I report the analytic expected value and the results of two samplings. Digits are truncated: i : 0.0   0.1   0.2   0.3   0.4   0.5   0.6   0.7   0.8   0.9   1.0
---------------------------------------------------------------------------------------
  analytic cum(i, 1) : 0.0   0.108 0.214 0.319 0.421 0.522 0.621 0.719 0.814 0.908 1.0
sampling 1 cum(i, 1) : 0.0   0.108 0.214 0.319 0.421 0.522 0.621 0.718 0.814 0.908 1.0
sampling 2 cum(i, 1) : 0.0   0.108 0.214 0.319 0.421 0.522 0.621 0.719 0.814 0.908 1.0
---------------------------------------------------------------------------------------
  analytic cum(1, i) : 0.0   0.091 0.185 0.280 0.378 0.477 0.578 0.680 0.785 0.891 1.0
sampling 1 cum(1, i) : 0.0   0.080 0.164 0.253 0.347 0.445 0.547 0.653 0.764 0.880 1.0
sampling 2 cum(1, i) : 0.0   0.080 0.164 0.253 0.347 0.445 0.547 0.653 0.764 0.880 1.0 Obviously, the cumulative density of the x-coordinates ($cum(i, 1)$) is almost exactly the analytic expression. On the other hand, there is a clear error in the y-coordinates ($cum(1, i)$). This error is stable across different samplings. I cannot explain this slight error. Both the theoretical fundamentals and the implementation (with Mathematica) look sound. Is there something I might have missed? Univariate sampling works perfectly as can be seen from the x-coordinates. However, multivariate sampling exhibits a slight error.","['statistics', 'sampling', 'probability', 'probability-distributions']"
1689953,Rearrangement of Students (flaw in my solution),"There are 11 students in a class including A, B and C. The 11 students have to form a straight line. Provided that A cannot be the first person in the line, what is the probability that in any random rearrangement of line, A comes before B and C. For eg, this is a valid rearrangement (1-8 are other students) 1 2 3 A 4 5 C 6 7 B 8 Here's my solution - Probability that A goes before B and C without any restrictions is $\frac13$. (Notice the symmetry. The answer will be same for B goes first and C goes first.) Probability that A goes first without any restrictions is $\frac{1}{11}$ Hence the answer is $$\frac13 - \frac{1}{11} = \frac{8}{33}$$ But the answer is $\frac{4}{15}$ according to my textbook. Please help me to find flaw in my solution.","['combinatorics', 'probability']"
1690072,How to evaluate this limit about Bernoulli number?,"First,we define $\displaystyle I_{1}\left ( x \right )=\frac{\sin x}{x}$, then $\displaystyle \lim_{x\rightarrow 0^+}I_{1}\left ( x \right )=1$, also we have
\begin{align*}
I_2\left ( x \right )&=\frac{I_1\left ( x \right )-1}{x^{2}}~,~\lim_{x\rightarrow 0^+}I_2\left ( x \right )=-\frac{1}{6}\\
I_3\left ( x \right )&=\frac{I_2\left ( x \right )+\dfrac{1}{6}}{x^2}~,~\lim_{x\rightarrow 0^+}I_3\left ( x \right )=\frac{1}{120}\\
&\cdots \\
I_n\left ( x \right )&=\frac{I_{n-1}\left ( x \right )-\displaystyle \lim_{x\rightarrow 0^+}I_{n-1}\left ( x \right )}{x^{2}}
\end{align*}
Now we have the following questions. (1)$I_n(x)$ is related to bernoulli number, but how to find it. (2)Evaluate $\displaystyle \lim_{k\rightarrow +\infty }\left [ \lim_{x\rightarrow 0^{+}}I_{2k}\left ( x \right ) \right ]~,~\lim_{k\rightarrow +\infty }\left [ \lim_{x\rightarrow 0^{+}}I_{2k+1}\left ( x \right ) \right ]~,~k\in \mathbb{Z}.$","['bernoulli-numbers', 'sequences-and-series', 'calculus', 'limits']"
1690078,positive definite matrix plus positive semi matrix equals positive definite?,"I have a questions related to the positive definite[PD] matrix and positive semi definite[PSD] matrix I see and get the property about PD and PSD 1) PD + PD = PD 2) PSD+ PSD = PSD how about the positive definite[PD] matrix plus positive semi definite matrix ? (I mean sum of positive definite matrix and positive semi definite matrix : PD + PSD) Is it right to be positive definite matrix? For example, If matrix  B is $R \times R$ and it is  sum of identity matrix $I$ 
and symmetry matrix A that is, $B=I+A$ 1) $I=\det(I)=1>0 $ positive definite 2) $X^{T}AX=X^{T}L^{T}LX=U^{T}U=||U||\geqslant 0 $ positive semidefinite I think that it would be positive definite, I am not so sure... So I would like to get some help from you Thank you very much in advance !","['matrices', 'positive-definite', 'linear-algebra']"
1690197,"Reference request for ""Elementary"" Proofs of Picard's Great Theorem","This is Picard's Great Theorem; $\textbf{Great Picard Theorem.}$ Suppose an analytic function $f$ has an essential singularity at $z=a$. Then in each neighbourhood of $a$, $f$ assumes each complex number with one possible exception, an infinite number of times. I was wondering if there are any essentially elementary proofs of Picard's Great Theorem that could be taught to a student not well versed in complex analysis. Or a relatively short proof that could be taught to a student who has taken at least one semester of complex analysis. Also how many different proofs of this theorem are there? The proof I have seen, using normal families and Montel's Theorem, is the one in John B Conway's Functions of One Complex Variable. The proof is in Chapter 12 Section 4 and uses quite a number of results that aren't immediately apparent and many of the intermediary results are quite long. If anyone could point me to a book that provides the kind of proof I'm looking for, or explain that such a proof does not exist, I would appreciate it.","['alternative-proof', 'complex-analysis', 'reference-request']"
1690285,Does there exist a computable number that is normal in all bases?,"Following up on this exchange with Marty Cohen... Almost all numbers are normal in all bases (absolutely normal), but there are only a countable number of computable numbers, so it is plausible that none of them are absolutely normal.  Now I don't expect to be able to prove this since it would imply $\pi$, $\sqrt{2}$, etc. are not absolutely normal.  Also I don't expect to be able to find a particular computable number that is normal in all bases, since Marty states none are known.  But is it possible to show non-constructively that there is some computable number which is absolutely normal?",['number-theory']
1690289,What is a probability distribution?,"I have a couple of fundamental questions about probability distributions, a term that is thrown around a lot. In my undergraduate courses, the term itself was not actually given a definition, rather we defined the PMF (and PDF); then said ""this is an example of a probability distribution"", and ""here's another example of a probability distribution"" (when referring the the common Normal Distribution, Binomial Distribution, etc.). The 'definition' according to wikipedia is that the probability distribution ""usually refers to the more complete assignment of probabilities to all measurable subsets of outcomes, not just to specific outcomes or ranges of outcomes"". When we say the Normal distribution (for example) is a ""probability distribution"", do we mean to say that the Normal distribution is a family of ""probability distributions"" with similar properties (shapes)? Why is the probability distribution defined in this way: when it is completely characterized by the PMF (or PDF)? It seems redundant to me. Do we need a (quote unquote) probability distribution in order to completely assign probabilities to all measurable subsets of outcomes -- or could this be done with just the probability space $(\Omega,\mathcal{F},P)$?","['probability-theory', 'probability-distributions']"
1690305,Calculating the Payout of an Unusual Digital Slot Machine,"Say you have a digital slot machine. Rather than using virtual reels, this slot machine generates results using predetermined probabilities for a given symbol appearing in any position. Given: Five 'reels' (positions for a symbol to appear) Wild symbols exist (and have their own probability of appearing) Matches must be left-aligned How does one calculate the probability of each possible number of matches, 0-5, for a given symbol? (A 'match' of 1 would mean a symbol appears in the left-most position, but is not followed by itself or a Wild.) Please include in your response a formula which is readable by a layman (I'm no mathemetician). What follows is a description of my attempts to solve this problem. As an example: the Cherries symbol pays 4x the bet for 3 matches. In any given position, Cherries has a 20% chance of appearing, and Wild has a 2% chance of appearing. My first attempt at calculating this probability was $0.2 * (0.2 + 0.02)^2 = 0.00968$. At least one Cherries, plus two more symbols which are either Cherries or Wild. $4 * 0.00968 = 3.872%$ pay for 3 Cherries. It then occurred to me that this probability would seem to also include the probability of getting a match of 4 Cherries and would need to exclude the chance of the next symbol being Cherries or Wild. Thus, I updated the calculation to be $0.2 * (0.2 + 0.02)^2 - (0.2 * (0.2 + 0.02)^3) = .0075504$, giving a payout of ~3.020%. (This step is skipped if we are testing for 5 matches, since 6 matches is impossible.) Is this correct?","['statistics', 'probability']"
1690352,Norm of a bounded linear functional as the reciprocal of the distance from zero to an hyperplane,"Let $(X,\|\;\|)$ be a normed vector space over $K$ and let $f\in B(X,K)$ (bounded linear functional) $(f\neq0$). Let $L=\{x\in X: f(x)=1\}$. I want to prove that: $$
\|f\|=\frac{1}{d(0,L)}
$$ My attempt goes like this: Since $f$ is bounded, is clear that $|f(x)|\le\|f\|\|x\|\;\;\forall x\in X$. So,
$$
1\le\|f\|\|x\|\;\forall x\in L
$$
and,
$$
\frac{1}{\|f\|}\le\|x\|\;\;\forall x\in L
$$
thus
$$
\frac{1}{\|f\|}\le\inf_{x\in L}(\|x\|)=\inf_{x\in L}(d(0,x))=d(0,L)
$$
so
$$
\|f\|\ge\frac{1}{d(0,L)}
$$
Any ideas for the other part would be appreciated since I couldn't figure out how to show that $\|f\|\|x\|\le 1\;\;\forall x\in L$","['functional-analysis', 'analysis']"
1690353,A variant of Dominated Convergence Theorem,"Let $(a_1,a_2,\ldots)$ be a sequence of nonnegative numbers summing up to $1$. Given a measurable space $(X,\mathscr{F})$, assume also the $f:X\to \mathbb{R}$ is a measurable function, and let $(\mu_1,\mu_2,\ldots)$ be a sequence of probability measures $\mathscr{F} \to \mathbb{R}$. Then, is it true that
$$
\int_X f \mathrm{d}\left(\sum_{i\ge 1} a_i\mu_i\right)=\sum_{i\ge 1}a_i \left(\int_X f \mathrm{d}\mu_i\right)\,\,\,?
$$","['measure-theory', 'limits']"
1690381,Prove that $\sin(x) + \cos(x) \geq 1$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question $\forall x\in[0,\pi/2]: \sin{x}+\cos{x} \ge 1.$ I am really bad at trigonometric functions, how could I prove it?","['inequality', 'trigonometry']"
1690386,Solve the recurrence relation $a_n = 2a_{n-1} + 2^n$ with $a_0 = 1$ using generating functions,"Here is what I have so far, or what I know how to do, rather: I am given this equation: $a_n = 2a_{n-1} + 2^n$ with $a_0 = 1$ So, with the $2a_{n-1}$, I know I can do the following. We change the $a_n$ to $x^n$, so then we have $x^n = 2^{n-1}$. When we take away $n-1$ from both sides, we get $x = 2$, and the root is 2. Then when have $a_n = A_12^n$, with $a_0 = 1$, to which then we do: $1= a_0 = A_12^0 = A_1 = 1$, and $a_n = 1*2^n$. But, that is not the correct answer, and I am not sure what to do with the $2^n$ part, which is necessary to get the answer. Could anybody help me? Any help is greatly appreciated.","['generating-functions', 'combinatorics', 'recurrence-relations']"
1690403,Find a surjective function $f:\mathbb{N}\to \mathbb{Q}$,"I'm trying to find a surjective function $f:\mathbb{N}\to \mathbb{Q}$; I know that at least one such function must exist since $\mathbb{Q}$ is countable, but I haven't been able to find one. Can someone show me one such function? Best regards, lorenzo",['functions']
1690410,if the fibers of all points are finite then will the map be finite?,If $f:X\to Y$ is a regular map between affine varieties then we say $f$ is finite if $k[X]$ is integral over $k[Y]$. If $f$ is finite then fibers of all points are finite. I think the converse of this statement is false but I can't give a counter example. Can you give a counterexample?,"['algebraic-geometry', 'commutative-algebra']"
1690434,Two i.i.d random variables inequality [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question If $X$ and $Y$ are i.i.d positive random variables, Prove that $\Bbb E(X/Y) \ge 1$: I use Jensen's inequality $\Bbb E[\exp(\log(X/Y))]$ and get the answer. One can also use the A-G inequality to prove this. (Difficult) if ${\rm Var}(\log(X))\ge 2$, prove that $\Bbb E(X/Y) \ge 2$. While the first inequality is not that difficult, the second one is rather hard...","['probability-theory', 'probability', 'random-variables']"
1690437,Why being the discriminant $D<0$ guarantees that there is a saddle point in some direction?,"I'm studying multi-variable calculus, and stopped at this theorem: I'm wondering why being the discriminant $D<0$ guarantees that there is a saddle point in some direction ?",['multivariable-calculus']
1690448,Probability that one part of a randomly cut equilateral triangle covers the other without flipping,"At Probability that one part of a randomly cut equilateral triangle covers the other , the case with flipping allowed was quickly solved. The case without flipping seems more difficult and hasn't been adressed, so I'm posting it as a separate question: What is the probability that randomly cutting an equilateral triangle will allow one part to cover the other if you're not allowed to flip the parts? The cuts are distributed according to Jaynes' solution to the Bertrand ""paradox"" : random straws thrown from afar, with uniformly distributed directions and uniformly distributed coordinates perpendicular to their direction. A succinct characterisation of the cuts that allow one part to cover the other would already constitute significant progress.","['geometric-probability', 'probability', 'triangles']"
1690454,Can every element of a finite field be written as a sum of two non-squares?,"We know that any element of a finite field $\mathbb{F_{q}}$ ($q$ odd prime power) can be written as a sum of two squares - is the same true for non-squares? Can any element of a (sufficiently large) finite field be written as a sum of two non-squares? I know that the above is not true in general, e.g. in $\mathbb{F_{3}}$, the only non-square is $2$ and so $2$ itself cannot be written as a sum of two non-squares. However, if $q$ is large enough could the above be true? If it is true, then could anyone provide any hints on I could prove it? Many thanks!","['number-theory', 'finite-fields', 'quadratic-residues']"
1690455,Generalization of invariance of domain,Suppose I say a topological space $X$ has the invariance of domain property iff $S \subset X$ is open as soon as $S$ is homeomorphic to an open set of $X$. We know that $\mathbb{R}^n$ has this property. What other spaces have this property?,"['algebraic-topology', 'general-topology']"
1690470,Hint for $\lim_{n\rightarrow\infty} \sqrt[n]{\prod_{i=1}^n\frac{1}{\cos\frac{1}{i}}}$.,"How to calculate the following limit:
$$\lim_{n\rightarrow\infty}\sqrt[n]{\prod_{i=1}^n\frac{1}{\cos\frac{1}{i}}}$$ thanks.","['calculus', 'limits']"
1690593,Cardinality of $\mathbb{R}^\mathbb{R}$ by diagonal argument,"I want to prove that the set of all real functions $\mathbb{R}^\mathbb{R}$ has a higher cardinality than the real numbers $\mathbb R$, by Cantor's diagonal argument. I'm having difficulties with approaching this problem. What I'm looking for is a hint in the right direction. I've seen an example where it is shown that the power set $2^S$ of a countable set $S$ is uncountable, by the diagonal argument.",['elementary-set-theory']
1690606,"Suppose $f$ is continuous on $[0,2]$ and $f(0) = f(2)$. For which $a\in(0,2)$ must there exist $x,y\in[0,2]$ so that $|y − x| = a$ and $f(x) = f(y)$?","Suppose $f$ is continuous on $[0,2]$ and $f(0) = f(2)$.  For which $a\in(0,2)$ must there exist $x,y\in[0,2]$ so that $\lvert y − x\rvert = a$ and $f(x) = f(y)$ I'm really unsure how to approach this problem ...we did a similar problem where $a=1$, by defining $g(x) = f(x+1)-f(x)$ on $[0,1]$, then applying the IVT. Is this problem approached in a similar way? If not, what's a good starting point? Thank you for any ideas!",['calculus']
1690631,How do I solve a double absolute value inequality?,How do I solve this? |x-2| > |x-4| Do I split the inequality up into two as so? -(x-2) > x-4 x-2 > -(x-4),"['algebra-precalculus', 'inequality']"
1690633,(Generalization) Possibilities of picking k nonconsecutive from n consecutive numbers.,"The original task asked how many possibilities there are to pick 6 out of 45 numbers, where no two of those 6 differ by 1. The solution of an even further simplified problem (3 out of 8) would look lke this: Write zeroes for the numbers which are not picked and ones for those which are. Since you take three, 5 zeroes remain. Then you have 6 places to pick from so the ones don't touch. Thus $\binom{~6~}{~3~}$. 0 0 0 0 0
^ ^ ^ ^ ^ ^ But what if I wanted them to differ by at least 3? (Originally, they had to differ by at least 2, $\{1, 3, 5\}$ was valid, now only combinations like $\{1,4,8\}$ are.) I started by rearranging the possible locations for the (representative) ones: 0 0 0 0 0
 ^   ^   ^ But then I kinda have the same problem with the locations of the numbers as I had with the numbers themselves in the original, because this 0 0 0 0 0
^     ^   ^ would also be valid. Now I have 6 locations from which some are valid, but I don't know how many (in general), and that is something I didn't have before (I think?). So how can I proceed from here? (To ultimately obtain a formula for picking k numbers out of n consecutive integers, where each 2 out of those k are at least d apart.)","['combinatorics', 'discrete-mathematics']"
1690704,Example of topological spaces $A \subset X$ with $X \setminus A$ not homeomorphic to $(X/A) \setminus (A/A)$,"This is a homework question. I am asked to show that if $A \subset X$ is closed, then $X \setminus A$ is homeomorphic to $(X/A) \setminus (A/A)$. I have done this, and I now have to show by example that this is false if we do not require that $A$ is closed. Could someone point me in the right direction in finding such an example?",['general-topology']
1690710,Sets of natural numbers which are almost closed under addition,"I am interested in a classification of sets $A \subseteq \mathbb{N}$ such that for all $k \in A$, $d( A+k \cap \mathbb{N} \setminus A) = 0$ where $d$ is the asymptotic density and $A+k = \{n \in \mathbb{N} : n-k \in A\}$. Sets with this condition are in a sense almost closed under addition. Some examples are sets of the form $C \setminus N$ where $C$ is closed under addition and $N$ has density $0$. Any set of density $0$ or $1$ also satisfies this property. I hoped this condition was equivalent to $d(A \triangle C) = 0$ for some set $C$ closed under addition, but $A = 2 \mathbb{N} \cup \{1\}$ is a counterexample. Is there some nice additive combinatorics classification of such sets?","['number-theory', 'additive-combinatorics']"
1690720,What is the complex line integral measuring? How do we motivate it?,How do we motivate it? I am not necessarily looking for a geometric answer to my question so much as I am looking for a way to motivate the idea of a complex line integral. For any path $\gamma$ and any function $f(z)$ we have $$\int_\gamma f(z)=\int f(\gamma(t))\gamma '(t)dt$$ and it turns out that this has a lot of power in terms of characterizing functions. But historically how did we make a decision to define things this way? What motivates this? I've gotten a lot of after the fact answers but I don't really feel like this is satisfactory. It turns out this is useful doesn't motivate its original discovery/definition very well. Possible questions: What is the complex line integral measuring?,"['complex-analysis', 'integration', 'soft-question']"
1690740,"Prove that $E(X) = \int_{0}^{\infty} P(X>x)\,dx = \int_{0}^{\infty} (1-F_X(x))\,dx$.","Let $X$ be a continuous non-negative random variable (i.e. $R_x$ has only non-negative values). Prove that $$E(X) = \int_{0}^{\infty} P(X>x)\,dx  = \int_{0}^{\infty} (1-F_X(x))\,dx$$ where $F_X(x)$ is the CDF for $X$. Using this result, find $E(X)$ for an exponential ($\lambda$) random variable. I know that by definition, $F_X(x) = P(X \leq x)$ and so $1 - F_X(x) = P(X>x)$ The solution is:
$$\int_{0}^{\infty} \int_{x}^{\infty} f(y)\,dy dx   
= \int_{0}^{\infty} \int_{0}^{y} f(y)\,dy dx 
= \int_{0}^{\infty} yf(y) dy.$$ I'm really confused as to where the double integral came from. I'm also rusty on multivariate calc, so I'm confused about the swapping of $x$ and $\infty$ to $0$ and $y$. Any help would be greatly appreciated!","['integration', 'probability', 'calculus']"
1690755,Prove $\sum_{i=1}^{\infty}P[A{\cap}C{\cap}Bi] = P[A{\cap}C]$.,"How to prove this mathematically rather than using venn diagram?
  $$\sum_{i=1}^{\infty}P[A{\cap}C{\cap}Bi] = P[A{\cap}C]$$
  where $B_i$ is the partition of $C$ (not $S$). $A$ and $C$ are arbitrary sets. I have proved that 
$$A{\cap}C = A{\cap}C{\cap}C = A{\cap}C{\cap}\left({\bigcup_{i=1}^{\infty}}B_i\right) = {\bigcup_{i=1}^{\infty}}(A{\cap}C{\cap}B_i).$$
Thus $$P(A{\cap}C) = P\left({\bigcup_{i=1}^{\infty}}(A{\cap}C{\cap}B_i)\right)$$
Then I need to apply the axiom of probability/measure to get the summation out. However how do I know each $A{\cap}C{\cap}B_i$ are disjoint with each other using a formal proof instead of Venn diagram?","['probability-theory', 'probability']"
1690758,Prove using the formal definition of a limit that,"How would I go about proving this limit? $\lim_{x\to\infty}\frac{1}{x^4+x^2+5}=0$ so far I have: $|f(x) -L|< ϵ$ wherever $x > N$ $|\frac{1}{x^4+x^2+5} - 0| < ϵ $ wherever $x > N$ $|\frac{1}{x^4+x^2+5}| < ϵ  ,\; x > ∞$, assuming, $x > 0$ taking the absolute value $\frac{1}{x^4+x^2+5} < ϵ$ ${x^4+x^2+5}$ > $\frac{1}{ϵ}$ i am not sure whether this is correct, but what would be the next step?","['real-analysis', 'limits']"
1690771,"Solving a system of differential equations, and periodicity","The question Given the following system of differential equations $\left\{\begin{matrix}
\; \dot{x} & = & y-1 \\ 
\; \dot{y} & = & -xy
\end{matrix}\right.$ Give a differential equation for its trajectories and solve it. Find which trajectories are closed, and therefore correspond to periodical solutions. My problem I know that it follows from the chain rule that $\frac{\mathrm{d}y}{\mathrm{d}t} = \frac{\mathrm{d}y}{\mathrm{d}x} \cdot \frac{\mathrm{d}x}{\mathrm{d}t} \; \Rightarrow \; \frac{\mathrm{d}y}{\mathrm{d}x} = \frac{\dot{y}}{\dot{x}}$ so that after substituting in the equations from the above system a trajectory is given by the planar coordinates $x(t), \; y(x(t))$ for $y$ a solution to the differential equation $\frac{\mathrm{d}y}{\mathrm{d}x} = \frac{-xy}{y-1}$ When I try to solve this as a seperable differential equation however, I end up with a nasty solution from which I cannot isolate $y$. Furthermore I have no idea how to determine if a trajectory is closed, or how to show any solution is periodical. What should my approach be?",['ordinary-differential-equations']
1690789,Any open set in $\Bbb{R}^n$ is a countable union of closed sets,"I don't know how to directly approach it. If we were looking at an open ball, WLOG $B(0,r)$ in $\Bbb{R}^n$, I suppose I would be looking sets of the form $\overline{B}_n(0,r-{1\over n})$ (supposing $r\ge 1$). But is there a way to generalize it to all open sets using balls? I am focusing on the Euclidean space, in Analysis and not in Topology, so I would appreciate if you could refer in terms of basic Topology and not advanced one...","['general-topology', 'calculus']"
1690797,How to show that $(W^\bot)^\bot=W$ (in a finite dimensional vector space),"I need to prove that if $V$ is a finite dimensional vector space over a field K with a non-degenerate inner-product and $W\subset V$ is a subspace of V, then:
$$
(W^\bot)^\bot=W
$$
Here is my approach: If $\langle\cdot,\cdot\rangle$ is the non-degenerate inner product of $V$ and $B={w_1, ... , w_n}$ is a base of $V$ where ${w_1, ... , w_r}$ is a base of $W$ then I showed that 
$$
\langle u,v\rangle=[u]^T_BA[v]_B
$$
for a symmetric, invertible matrix $A\in\mathbb{R}^{n\times n}$. Then $W^\bot$ is the solution space of $A_rx=0$ where $A_r\in\mathbb{R}^{r\times n}$ is the matrix of the first $r$ lines of $A$. Is all this true? I tried to exploit this but wasn't able to do so. How to proceed further?","['orthogonality', 'linear-algebra', 'inner-products']"
1690853,Probability of an independent event according to past events,"A binary communication system is used to send one of two messages: (i) message A is sent with probability 2/3, and consists of an infinite sequence of zeroes, (ii) message B is sent with probability 1/3, and consists of an infinite sequence of ones. The ith received bit is “correct"" (i.e., the same as the transmitted bit) with probability 3/4, and is “incorrect"" (i.e., a transmitted 0 is received as a 1, and vice versa), with probability 1/4. We assume that conditioned on any specific message sent, the received bits, denoted by Y1,Y2,… are independent. Given that Y1,…,Y5 were all equal to 0, what is the probability that Y6 is also zero? For me the answer was P(Y1 = 0) = P(Y6 = 0) because as I understood the received bits are independent, but the right answer is 0.749267 . Could you just help me to understand what I missed in the problem? :(","['probability-theory', 'probability', 'geometric-probability']"
1690870,Prove whether series converges or not?,"Does anyone know how to determine with proof whether the series
$$\sum_{n=1}^\infty\frac{1}{n^{2+\cos(2\pi\ln(n)) }}$$
converges?",['calculus']
1690876,$X<Y$ a.s. but $\mathrm{AV@R}_\alpha[X] = \mathrm{AV@R}_\alpha[Y]$,"$\newcommand{\avar}{\mathrm{AV@R}_{\alpha}} \renewcommand{\Re}{\mathbb{R}}$Let $(\Omega, \mathscr{F}, \mathrm{P})$ be a probability space and define $\mathcal{Z}:=\mathcal{L}_p(\Omega, \mathscr{F}, \mathrm{P})$ for some $p\in [1,\infty)$. The average value-at-risk of a $X\in\mathcal{Z}$ - often referred to as expected shotfall or conditional value-at-risk is defined as $$
\avar[X] := \inf_{t\in\Re}\{t+\alpha^{-1}\mathbb{E}[(X-t)_+]\},
$$ where $\mathbb{E}$ is the expectation operator and $(\cdot)_+$ is defined as $(Z)_+=\max\{0, Z\}$. There are a few other useful formulae. For example $$
\avar[X] = \mathbb{E}[X\mid X\geq \Phi_X^{-1}(1-\alpha)],
$$ where $\Phi_X^{-1}$ is the inverse cumulative distribution function of $X$, and, the dual representation $$
\avar[X] = \sup_{\zeta\in\mathfrak{A}}\langle \zeta, X\rangle
$$
where $\langle \zeta, X\rangle:=\int_{\Omega}\zeta X \mathrm{dP}$ and
$\mathfrak{A}:=\left\{\zeta\in \mathcal{L}_q(\Omega,\mathscr{F},\mathrm{P}) \mid \mathbb{E}[\zeta]=1, \zeta\in[0,\alpha^{-1}]\ \text{a.s.}\right\}$. Given that $X\leq Y$ almost surely we know that $\avar[X]\leq \avar[Y]$ by the monotonicity property of $\mathrm{AV@R}[\cdot]$. However, I I believe it is not true that $\avar[X]< \avar[Y]$ whenever $X<Y$ (a.s.). My question. I suspect that this assertion is false, but I would like to find a counterexample. My guess. If we take $X<Y$ (a.s.) then, since all $\zeta\in\mathfrak{A}$ are nonnegative (a.s.), we have $\langle \zeta, X\rangle \leq \langle \zeta, Y\rangle $ from which we can infer $\avar[X]\leq \avar[Y]$, but not $\avar[X]<\avar[Y]$. Intuition. In order to acquire some intuition about this problem, I create the figure below. The CDFs of the two variables don't have the same shape, they have different value-at-risk values, but the same average value-at-risk, it is $X<Y$. The CDF of $X$ after its value-at-risk moves faster to $1$ and as a result its average value-at-risk is further away from its value-at-risk. On the other hand, the CDF of $Y$ exhibits a more sluggish ascend and the two AV@Rs coincide.","['probability', 'measure-theory', 'risk-assessment']"
1690879,"Finding extrema of $f(x,y) = sin(xy)$","I did calculate $f_{xy}(x,y)$ and $f_{yx}(x,y)$ and equating them gives the expression $$\tan(xy)=-\frac{xy}{2}$$ and equating $f_x(x,y)=0$ and $f_y(x,y)=0$ gives $$xy=(2m+1)\frac{\pi}{2}$$ These are the expressions I got: $$f_x(x,y) = y\cos(xy)$$ $$f_y(x,y) = x\cos(xy)$$ $$f_{xx}(x,y) = -y^2\sin(xy)$$ $$f_{yy}(x,y) = -x^2\sin(xy)$$ $$f_{xy}(x,y) = -2y\sin(xy)-xy^2\cos(xy)$$ $$f_{yy}(x,y) = -2x\sin(xy)-x^2y\cos(xy)$$ How do I move from here?","['multivariable-calculus', 'optimization']"
1690895,Volume of a divisor?,"One can define the volume of a divisor $D$ by the formula $\displaystyle \limsup_{m \to \infty} \frac{h^0(X, O(mD))}{m^n/n!}$, where $n$ is the dimension of $X$. For example, see the definition here (a paper that I randomly chose from a google search): http://www.math.northwestern.edu/~mpopa/papers/RVLS.pdf Does anyone know if there is a geometric meaning to this definition? (""Why volume?"") The author says that this is the ""top self-intersection"" number, but I don't really know what this means, or what it has to do with the concept of volume (on a complex algebraic manifold). I'm just curious to know. Edit: probably this contains an answer to my question: http://www.ms.uky.edu/~corso/Purdue_2011/posters/fulger-poster.pdf","['divisors-algebraic-geometry', 'algebraic-geometry', 'birational-geometry']"
1690926,Differentiate wrt Cholesky decomposition,"I wish to find the most likely estimator of the precision matrix (inverse covariance matrix). One option is to maximise the following:
$$
f(\Theta) = \frac{N}{2}\log|\Theta|-\sum_i \mathbf{x}_i^T\Theta\mathbf{x}_i
$$
(assume that the mean is zero without loss of generality). $\mathbf{x}_i$'s are constant. I know how to differentiate the above by exploiting the fact that $\mathbf{x}_i^T\Theta\mathbf{x}_i=Tr(\Theta\mathbf{x}_i\mathbf{x}_i^T)$. However, if I pose the question as instead to optimise the cholesky decomposition $L$ where $LL^T=\Theta$,
$$
f(L) = {N}\log|L|-\sum_i \mathbf{x}_i^TLL^T\mathbf{x}_i
$$
what is $\frac{\partial f(L)}{\partial L}$? It's really the second term that I am struggling with.","['matrices', 'matrix-decomposition', 'matrix-calculus']"
1690944,"Let $X|Y = y\sim\text{Poisson}(y)$ and $Y\sim\text{Gamma}(\alpha, \lambda)$. Find $f_X(x)$.","Question: Let $X|Y = y\sim\text{Poisson}(y)$ and $Y\sim\text{Gamma}(\alpha, \lambda)$. Find join density $f_{X,Y}(x,y)$ and find the probability density function of $X$ (simplify until there are no integrals). Answer: So, I believe that the joint density function for this will be: 
$$f_{X}(x|y) \cdot f_{Y}(y) = f_{X,Y}(x,y) = \frac{y^x \cdot e^{-y}}{x!} \cdot \frac{\lambda e^{-\lambda y}(\lambda y)^{\alpha-1}}{\Gamma(\alpha)}.$$ Next, in order to find the pdf of $X$, I need to 
$$\int_{-\infty}^{\infty} f_{X,Y}(x,y)\,dy.$$ I tried to use integration by parts, but I couldn't find any answer. Does anyone know the approach to integrating $f_{X,Y}(x,y)\,dy$?","['gamma-distribution', 'poisson-distribution', 'probability', 'probability-distributions']"
1690950,how to show that $\tan^2 y=-\csc 2x$,If $\csc y=\sin x -\cos x$ how to show that $\tan^2 y=-\csc 2x$ Can anyone explain to me? What identity I should use?,"['algebra-precalculus', 'trigonometry']"
1690957,Show Y has a uniform distribution if Y=F(X) where F(x)=P[X $\le$ x] is continuous in x.,"If $ F(x) = P[X\le x] $ is continuous in x, show that $ Y=F(X) $ is measurable and that $Y$ has a uniform distribution $ P[Y\le y] = y, \; 0\le y \le 1 $ My first question is about notation. What does $ F(X) $ mean? I cant make sense of $F(X) = P[X \le X] $. Also how do you show $Y$ is measurable? For the last part if $F^{-1}$ exists then we get that $ P(Y \leq y ) = P(F(X) \leq y) =  P(X \leq F^{-1}(y)) = F(F^{-1}(y)) = y $. Which would show that $Y$ has a uniform distribution on $[0,1]$. But how do I know that $F^{-1}$ exists. Wouldn't $F$ need to be strictly increasing for the inverse to exist? But we only know that it is non decreasing.","['uniform-distribution', 'probability-theory', 'measure-theory', 'random-variables']"
1691009,"Difficulty putting into words 'Universe of Discourse', Let $A =$ $\Bbb Z$","I am struggling with a particular concept, I'll lay it out how I think will best allow for an answer: Let $A =$ $\Bbb Z$ be the set of all integers and the universe of discourse. Let B, be the set of even numbers

Let C, be the set of odd numbers

Let D, be the set of positive numbers

Let E, be the set of negative numbers Now I would like the ability to be able to express the following Sets in words, to help my understanding of the topic: A) $(A-B)$ B) $ C \cap D$ C) $\overline{(D \cup B)}$ Any help to express these sets in 'words' would be great, it has me stumped. Thanks!",['elementary-set-theory']
1691025,Solving multiple integrals,"I need to integrate $\displaystyle f(x,y)=\frac{x^2-y^2}{(x^2+y^2)^2}$ on $R=[0,1]\times [0,1]$ If I take $u=x^2+y^2,$ then $\int_0^1\int_{y^2}^{1+y^2}\frac{u-2y^2}{u^2}du$. I do not know how to proceed from here. Any help would be appreciated! Thanks in advance!","['multivariable-calculus', 'integration', 'calculus']"
1691039,Prove that if m and n are any two odd (integers) then mn is also odd. [duplicate],"This question already has answers here : Prove directly, by contradiction, or contraposition? If the product of two integers is even, at least one of them must be even. (3 answers) Closed 6 months ago . Here is what i have so far By definition an integer is called odd if there exist an integer k such that n=2k+1 so if n and m are any two odd integers the product of those two integers is odd. I dont know is this is the correct way of proving that mn is odd.",['discrete-mathematics']
1691043,Why is cos at $\pi/2$ not undefined?,"If the $\cos$ function is based off of the ratio of the adjacent side of Euclidean, right triangle, with fixed hypotenuse length (such as the unit circle), then how does this correspond to a defined value when $\theta = \pi/2$ ? To me the limit as $\theta \rightarrow 90$ appears to be undefined (specifically 1/0). Arguments against my view point:
1.) Once you hit 90 for a triangle to exist a new, right triangle will be formed, that is if the hypotenuse is a real number. Counterpoint : That's not the same angle, $\theta$, we used for our original function and when you hit 90 there's not going to be an adjacent side length of zero.","['trigonometry', 'functions', 'definition']"
1691051,Show that if $a+bi$ is irreducible over $\mathbb{Z} [i]$ then $a^2 + b^2$ is prime over $\mathbb{Z} $,"Show that if $a+bi$ is irreducible over $\mathbb{Z} [i]$ then $a^2 + b^2$ is prime over $\mathbb{Z} $ . (a,b are non-zero integers) I know that $\mathbb{Z} [i]$ is a Euclidean domain and so  $a+bi$ is prime in it. Can I say that as the norm of  $a+bi$ is $a^2 + b^2$ that $a^2 + b^2$ must be prime over $\mathbb{Z} $? This doesn't seem correct to me but it's the best try I have been able to come up with.",['number-theory']
1691068,Does blow up of subscheme in special fiber change the generic fiber?,"Let $X\to \mathrm{Spec}(R)$ be a finite type scheme over DVR, choose a closed subscheme $Y$ of the closed fiber $X_0$ and blow up $Y$ in $X$, will the generic fiber always remain the same?",['algebraic-geometry']
1691075,"Game, stealing edges in a graph.","I was inventing a problem for a math contest, I was really pleased with it, but then I found a mistake in my solution and have not been able to solve it. It is as follows: Alice and Bob play a game. Let $n$ be a fixed positive integer. Alice selects a connected simple graph on $n$ vertices. After this Alice and Bob take turns selecting a vertex with at least $1$ adjacent edge and removing all the edges adjacent to it. Bob starts. For which values of $n$ does Bob always have a strategy that allows him to take strictly more edges than Alice? I have found it is possible for $n=2,3,5$ and that it is not possible for $n=1$ and every even integer above $2$ (Alice can select $K_{2,n-2}$). It remains to be seen if there is a non-trivial graph on an odd number of vertices that works. Some trivial observations: Bob can always take the graph with the highest degree every turn. For a graph to be able to resist this strategy it must have at least two vertices with the highest possible degree which are non-adjacent; the graph must also have an even number of edges. We can also define $B(G)$ as the maximum possible difference between the number of edges for Bob and Alice that Bob can guarantee. We are then looking for graphs with $B(G)=0$. It is clear $B(G)=\max(d(v)-B(G - v))$, where $v$ is any vertex in $G$ and $d(v)$ is the degree of $v$.","['combinatorics', 'graph-theory', 'combinatorial-game-theory']"
1691099,Let n be an arbitrary odd natural number. Prove that $n^2≡1$ (mod4),"Let n be an arbitrary odd natural number. Prove that $n^2≡1$ (mod4) I know that this is true, but I'm not exactly sure how to write the proof for it. I found out then when you square any odd number, it will end in a 1,5,or 9, which I think is important. But then I can't say that whenever you subtract 1 from those to get a number ending in 0,4,or 8, that every number ending in 0,4, and 8 is divisible by 4 since for example, 38 is not, and others.",['discrete-mathematics']
1691108,Proving a variant of closed range theorem on Hilbert space,"I've been working on closed range theorem. There are a lot of materials on general Banach spaces, but not much on Hilbert spaces, so I was wondering if I could get some help.
I'm trying to prove the following claim: A bounded linear map $T:X\to Y$ between Hilbert spaces $X$ and $Y$ has closed range if and only if there exists a constant $C>0$ so that $\|f\| \le C\|T^*f\|$ This statement seems like the statement is a usual closed range theorem, but a bit different, especially with adjoint of the operator. Can someone help me proving this claim? Thanks!","['functional-analysis', 'real-analysis', 'operator-theory', 'hilbert-spaces']"
1691110,"Solving the IVP: $y'(x) = \frac{1}{1-(xy)^2}, y(-1)=1$","I am only starting to learn diff.equations and have the following initial value problem:
$y'(x) = \frac{1}{1-(xy)^2}, y(-1)=1$. So, since $y'(x)$ is undefined at $(-1,1)$ do we say that the solution of the initial value problem doesn't exist or do we say that it ""jumps"" to infinity (or negative infinity?) as $y'(x)$ at the given point is infinite? Is $y(-1)=1$ still a solution of the problem? Is this point the only solution? I am lost. EDITED: Given the response below, if we solve such a problem with Euler's method, will it not provide any solution? I assume the Existence and Uniqueness theorem will also not be applicable. How can we ensure that the solution exists?",['ordinary-differential-equations']
1691147,Why is surface area not simply $2 \pi \int_{a}^{b} (y) dx$ instead of $2 \pi \int_a^b (y \cdot \sqrt{1 + y'^2}) dx$?,"Geometrically speaking, it seems to me that if you have for example $y^2=8x$ revolved around the x-axis, taking the limit of the sum of $n$ surfaces of cylinders as $n$ approaches infinity should give you the surface area of that surface of revolution. This is how the author initially derives the formula for finding the volume of solids of revolution. Take a rectangle under the curve over $\Delta x$ and revolve it around the axis to get an approximation of the volume of the solid over that interval. Add up those rectangles over $n$ changes in $x$ and take the limit as $n$ approaches infinity, which is the integral of the function that gives you the $y$ value (radius of that approximating cylinder) for each $x$ value. Following the same principle, why wouldn't we be able to take those same cylinders, but instead of taking their volume, taking their surface area and take the limit as the number of those cylinders approaches zero? In other words, in this case each $y$ value is given by $y = \sqrt{8x}$, which is the radius of that cylinder of height $\Delta x$ and an approximation of the surface area over that interval. Why doesn't that work? Why do we need to deal with arc length? I don't understand why it doesn't work in this case, it seems to me that you're still getting a better and better approximation of surface area as those cylinders get smaller and smaller, eventually getting the exact surface area with the limit as their number goes to infinity. PS: I saw this Surface area of a solid of revolution: Why does not $ \int_{b}^{a} 2\pi \,f(x) \,dx $ work? but it's still not making sense visually/geometrically.","['integration', 'calculus']"
1691163,"If $A,B$ are invertible, show that $AB$ is invertible and express $(AB)^{-1}$ in terms of $A^{-1},B^{-1} $. [duplicate]","This question already has an answer here : Invertibility of the Product of Two Matrices (1 answer) Closed 8 years ago . If $A,B$ are invertible, show that $AB$ is invertible and express $(AB)^{-1}$ in terms of $A^{-1},B^{-1} $. $($$A,B$ are matrices.$)$ I did the following: Suppose $AB$ is invertible. $$AB(AB)^{-1}=I$$ $$A^{-1}AB(AB)^{-1}=A^{-1}I$$ $$B(AB)^{-1}=A^{-1}$$ $$B^{-1}B(AB)^{-1}=B^{-1}A^{-1}$$ $$(AB)^{-1}=B^{-1}A^{-1}$$ I found what $(AB)^{-1}$ might be, now I need to show that $B^{-1}A^{-1}$ is really the inverse: $$ABB^{-1}A^{-1}=A[BB^{-1}]A^{-1}=[AA^{-1}]=I$$ $$B^{-1}A^{-1}AB=B^{-1}[A^{-1}A]B=[B^{-1}B]=I$$ Is it correct? Do I need these two steps? I feel that the first step shows me what the inverse would be if it exists and the second actually shows that it is the inverse. EDIT : This question is completely different of this one . In the aforementioned question, the person didnt know how to do it. I asked if mine is correct and asked if the first part would be required. It is sad that MSE users don't read the questions completely anymore.","['matrices', 'linear-algebra']"
1691171,I call this the Punt on the Wine Bottle Theorem.,"My grad school days are 30 years behind me, and to my chagrin proving what seems a simple observation draws upon skills which are too badly atrophied to be useful.  The inspiration is a wine bottle.  Why do wine bottles have ""punts"" - i.e. indentations on the bottom?  Obviously so that you can stand the bottle on its end and it won't tip over.  Can we prove that is always true? Consider two continuously differentiable surfaces, $A, B$ in $\Bbb R_3$, $A$ convex; continuously differentiable closed curves, $a, b$ on each; and a mapping, $\Gamma:A\rightarrow B $, which maps $a \rightarrow b$, and $int(a) \rightarrow int(b)$, $ext(a) \rightarrow ext(b)$, such that the mapping preserves curvature at every point in the exterior, and inverts the curvature within in interior. Prove $\Gamma$ is a plane curve. For the special case of $A$ being a sphere, $B$ is a sphere with a dimple, and the proof is as simple as noting that the intersection of two spheres is a circle.  Sadly, that isn't much of a start on the general case.",['differential-geometry']
1691212,Flawed AP Calc question? Inflection points.,"The following question was presented to me by a tutoring student in AP Calculus. It's supposedly from a practice test - not sure if it's official. Here's the issue. Below I've reproduced the complete graph of some continuous function $f(x)$. The question asks us to identify what $x$ are inflection points and to offer an explanation as to why. My student's teacher provided her class with an answer that $x=2$ is an inflection point. I disagree. $f'(x)$ is discontinuous at $x=2$ and $f''(x)$ does not exist! Furthermore, there is no tangent at $x=2$. I see no transition from concavity to convexity anywhere here. From the definitions of an inflection point provided in Stewart's and Thomas's textbooks, no inflection points exist . Can anyone chime in here? Is anyone aware of an alternate definition of inflection point - especially one that is taught in US high schools - that could have been intended here?",['calculus']
1691224,Just got confused with what my friend asked (paradox and fake proofs). [duplicate],"This question already has answers here : Where is the flaw in this ""proof"" that 1=2? (Derivative of repeated addition) (11 answers) Closed 8 years ago . Take $x^2=x+x+x+\cdots$ ($x$ times).
Now differentiating both sides wrt $x$, we get: $$2x=x.$$ This means $x=0$ or $2=1$. How? Where did I go wrong?","['paradoxes', 'fake-proofs', 'ordinary-differential-equations', 'calculus']"
1691254,How to show every field is a Euclidean Domain.,"I'm having trouble proving this. This is what I have so far: Let $F$ be a field. Let $v(x) \rightarrow 1$ for all $x$ not equal to $0$. So if we let $x$ be in $F$ where $x$ not zero then we can write $x$ as:
$x=qy+r$ for some $y$ in $F$.
If $r$ not zero then $V(r)=1$. Not sure what to do from here. I know eventually I'm supposed to get no remainder $(r=0)$ but I'm stuck at applying the definition and valuation map.","['abstract-algebra', 'euclidean-algorithm', 'field-theory', 'integral-domain']"
1691266,"Let $f$ be a permutaion of $\{0,\ldots,n\}$. Then the weighted projective space $\mathbb P(q_0,\ldots,q_n)\cong \mathbb P(q_{f(0)},\ldots,q_{f(n)})$","Fix $q_0,\ldots,q_n\in\mathbb Z$ to be $n+1$ coprime integers. Let $S^1$ act on $S^{2n+1}$ as follows - $$\lambda\cdot(z_0,\ldots,z_n)=(\lambda^{q_0}z_0,\ldots,\lambda^{q_n}z_n)$$ $($ The resulting quotient space is what is known as the weighted projective space $\mathbb P(q_0,\ldots,q_n))$ I am trying to prove the following - Proposition : Let $f$ be a permutaion of $\{0,\ldots,n\}$ . Then the weighted projective space $\mathbb P(q_0,\ldots,q_n)$ is homeomorphic to $\mathbb P(q_{f(0)},\ldots,q_{f(n)})$ . Attempt at a proof : Denote by $(S^{2n+1}/S^1)_f$ the quotient of the action of $S^1$ on $S^{2n+1}$ given by $$t\cdot(z_0,\ldots,z_n)=(t^{q_{f(0)}}z_0,\ldots,t^{q_{f(n)}}z_n)$$ Let each class of elements in it be denoted by $[(z_0,\ldots,z_n)]_f$ . Define $\phi:(S^{2n+1}/S^1)\rightarrow (S^{2n+1}/S^1)_f$ by $[(z_0,\ldots,z_n)]\mapsto[(z_0,\ldots,z_n)]_f$ . If $\phi$ is well-defined then we have the diagram, $\require{AMScd}$ \begin{CD}
   S^{2n+1}    @>id>>  S^{2n+1}\\
   @VVpV        @VVp_fV\\
   (S^{2n+1}/S^1) @>\phi>> (S^{2n+1}/S^1)_f
 \end{CD} Where $p$ and $p_f$ are the respective quotient maps. Then $\phi$ is clearly a homeomorphism. Well-definedness of $\phi$ : (This is what I am stuck with) Suppose $(z'_0,\ldots,z'_n)=(t^{q_0}z_0,\ldots,t^{q_n}z_n)$ for some $t=e^{2\pi i\theta}$ . Need a $t_1\in S^1$ such that $(z'_0,\ldots,z'_n)=(t_1^{q_f(0)}z_0,\ldots,t_1^{q_(n)}z_n)$ . I am unable to proceed further. Q 1 : Is my approach correct? Can someone help me proceed? Q 2 : Is $\phi$ an isomorphism of varieties as well? EDIT Second attempt : Since any permutation can be written as the product of transpositions we can WLOG assume $f$ is a transposition, i.e; $f^2=$ identity permutation. By abuse of notation let $f:S^{2n+1}\to S^{2n+1}$ denote the map $(z_0,\ldots,z_n)\mapsto (z_{f(0)},\ldots,z_{f(n)})$ . Denote $S^{2n+1}_f$ as the sphere with permuted co-ordinates which is homeomorphic to $S^{2n+1}$ via $f$ . Let $S^1$ act on $S^{2n+1}$ and $S^{2n+1}_f$ as follows - $$\lambda\cdot(z_0,\ldots,z_n)=(\lambda^{q_0}z_0,\ldots,\lambda^{q_n}z_n)$$ $$\lambda\cdot(z_{f(0)},\ldots,z_{f(n)})=(\lambda^{q_0}z_{f(0)},\ldots,\lambda^{q_n}z_{f(n)})$$ Claim : $$\mathbb P(q_0,\ldots,q_n)\cong S^{2n+1}_f/S^1\cong \mathbb P(q_{f(0)},\ldots,q_{f(n)})$$ Again I am not sure how to prove this (or if it can be done) Thanks!","['general-topology', 'algebraic-geometry']"
1691268,Sequential continuity implies continuity in the weak topology on a normed space,"Let $X$ be a normed vector space (over $\mathbb{R}$ or $\mathbb{C}$) and let $f$ be a linear functional on $X$ that is not necessarily continuous. If for any sequence $(x_n)$ that converges to $x$ weakly, we have $\lim f(x_n)=f(x)$, does it follow that $f$ is continuous in the weak topology? In other words, does sequential continuity imply continuity in the weak topology? (We know that the weak topology need not be first countable , so a priori we cannot characterise continuity of linear functionals in terms of sequences.)","['general-topology', 'real-analysis', 'functional-analysis']"
1691328,question on equivalent ideas of absolute continuity of measures,"The measure $\nu$ is absolute continuous with respect to $\mu$ if for each $A$, $\mu(A)=0$ implies $\nu(A)=0$ (indicated by $\nu \ll \mu$). There is an $\epsilon$-$\delta$ idea related to this definition: If $\nu$ is finite, then: $\nu \ll \mu$  $\iff$ for every $\epsilon$ there exist a $\delta$ satisfying $\nu(A)<\epsilon$, if $\mu(A)<\delta$ What is the necessity of finiteness of $\nu$?
What happens if $\nu$ is not finite?
Is there any example to show that $\epsilon$-$\delta$ definition does not hold if $\nu$ is infinite, even if $\nu\ll\mu$?",['measure-theory']
1691337,"Spotting that $\,x^8 + x^7 + 1\,$ is reducible.","I saw a puzzle recently that came down to spotting that $\,x^8 + x^7 + 1\,$ is reducible — namely, we have $$x^8 + x^7 + 1 = \left(1 + x + x^2\right)\left(1-x+x^3-x^4+x^6\right)$$ After playing around a bit, I noticed that this is a special case of the fact that $$\left.\Phi_m\left(x\right) \quad \big| \quad x^{mk} \big[\Phi_m\left(x\right) - 1\big] + 1\right.$$ for each $k$, which holds since $$x^{mk} \big[\Phi_m\left(x\right) - 1\big] + 1 = x^{m k} \Phi_m\left(x\right) + \left(1 - x^{m k}\right)$$ and of course both terms on the RHS are divisible by $\,\Phi_m\left(x\right)$.  In the cases $\,m = 1, 2, 3\,$ this recovers the statements: $x-1\;$ divides $\;x^{k+1} - 1$ $x+1\;$ divides $\;x^{2k+1} + 1$ $x^2 + x + 1\;$ divides $\;x^{3k+2} + x^{3k+1} + 1$ Of course the first two are very well-known.  Is it simply the case that many people also know the third statement off the tops of their heads?  Or is there some other way of spotting that $x^8 + x^7 + 1$ is reducible?","['cyclotomic-polynomials', 'combinatorics']"
1691347,"If $a\in R$ and the equation $-3(x-\lfloor x \rfloor)^2+2(x-\lfloor x \rfloor)+a^2=0$ has no integral solution,then all possible values of $a$","If $a\in R$ and the equation $-3(x-\lfloor x \rfloor)^2+2(x-\lfloor x \rfloor)+a^2=0$ has no integral solution, then all possible values of $a$ lie in the interval $(A)(-1,0)\cup(0,1)$ $(B)(1,2)$ $(C)(-2,-1)$ $(D)(-\infty,-2)\cup(2,\infty)$ My try: Let $x-\lfloor x \rfloor  = \{x\}= t$, where $ 0 \leq \{x\}<1\Rightarrow 0\leq t<1$. Then $$\Rightarrow -3t^2+2t+a^2 = 0\Rightarrow 3t^2-2t-a^2 = 0$$ $$\displaystyle \Rightarrow t = \frac{2\pm \sqrt{4+12a^2}}{6} = \frac{1\pm \sqrt{1+3a^2}}{3}$$ I do not know how to solve further.","['algebra-precalculus', 'ceiling-and-floor-functions', 'quadratics']"
1691370,Solving two electron integral,"During one of my practical courses we had to do the Hartree-Fock-method ""by hand"". Part of that was to calculate the occurring two electron integrals. With $$\chi_i(r) = 2 \cdot \alpha_i^{3/2} e^{-\alpha_i r} Y_0^0$$
we were given the following equation:
$$\iint \frac{\chi_m(r_1)~\chi_n(r_1)~\chi_t(r_2)~\chi_u(r_2)}{|r_1-r_2|}~\mathrm d r_2 \mathrm d r_1$$
$$= 16\pi^2\int_0^{\infty}\int_0^{r_1} \chi_m(r_1)~\chi_n(r_1)~\chi_t(r_2)~\chi_u(r_2)~r_1~r_2^2~\mathrm d r_2 \mathrm d r_1$$
$$+ 16\pi^2\int_0^{\infty}\int_{r_1}^{\infty} \chi_m(r_1)~\chi_n(r_1)~\chi_t(r_2)~\chi_u(r_2)~r_1^2~r_2~\mathrm d r_2 \mathrm d r_1$$ What are the steps to come up with this? (At least I know where the $16\pi^2$ come from $\ldots$)","['integration', 'chemistry']"
1691413,Show $g.S = \{g.x|x\in S\}$ defines an action on the power set,Let $X$ be a finite set and let $\mathscr{P}(X)$ be its power set. A group $G$ acts on $X$. Given $g \in G$ and $S \subseteq X$ show $g.S = \{g.x|x\in S\}$ defines an action on $\mathscr{P}(X)$. I know this means that I have to show that $(gh).S = g.(h.S)$ but I am unsure as to how actually show this.,"['group-actions', 'abstract-algebra', 'group-theory']"
1691430,How to remember hyperbolic functions [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 8 years ago . Improve this question I forget them all the time in solving PDE.
Can someone provide a way to remember them:
$$
\cosh\left(x\right)=\dfrac{e^x+e^{-x}}{2}
\qquad \text{ and } \qquad
\sinh\left(x\right)=\dfrac{e^x-e^{-x}}{2}
$$","['algebra-precalculus', 'hyperbolic-functions', 'ordinary-differential-equations', 'calculus']"
1691450,Under what circumstances do we have $\partial(A \setminus B) = \partial A \cup (A \cap B)$?,"Let $A$ and $B$ denote subsets of $\mathbb{R}^n$. Then if $A$ is an open set and $B$ is a ""sufficiently small"" closed set, then we might expect the following to hold: $$\partial(A \setminus B) = \partial A \cup (A \cap  B)$$ For example, imagine that $X = \mathbb{R}^2$, that $A$ is the unit (open) ball centered at the origin, and that $B$ is a line through the origin. Then $\partial A$ is the unit circle centered at the origin, $A \cap B$ is a line segment of length $2$ through the origin, and $\partial(A \setminus B)$ is the union of these. Question. Let $A$ and $B$ denote subsets of $\mathbb{R}^n$, with $A$ open and $B$ closed. Under what assumptions does the identity of interest hold? I'm also interested in generalizing beyond $\mathbb{R}^n$ to e.g. sufficiently well-behaved topological spaces. I tried proving this under the assumption that $\mathrm{int}(B) = \emptyset$ but didn't get very far.","['general-topology', 'real-analysis', 'metric-spaces']"
1691463,Example of an oscillation Young measure,"I'm taking a course in which Young measures are introduced for oscillation and concentration. I have understood the examples the lecturer has given us for concentration Young measures, but cannot get my head around the ones for oscillation. Here is an example: Let $v_j:=\sin(jx)$ , let $\Omega=(0,1)$ and let $\mathbb{E}_1$ be the space of ""1-admissible integrands"", that is the space of $\Phi \colon \Omega \times \mathbb{R}\to\mathbb{R}$ such that $\lim_{t\to\infty}\frac{\Phi(x,tz)}{t}$ exists for $z\in\{+1,-1\}$ . The functions $v_j$ may be viewed as 1-Young measures, which are viewed as elements of the dual space to $\mathbb{E_1}$ , under the duality relation \begin{align*}
\langle\langle v_j,\Phi\rangle\rangle&:=\int_\Omega\int_\mathbb{R}\Phi(x,z)d\delta_{v_j(x)}dx \\
 &=\int_{\Omega}\Phi(x,v_j(x))dx
\end{align*} We claim that the $v_j\to v$ for some $v$ as Young measures in the sense that they tend weak* in $\mathbb{E}_1^*$ . That is, we claim that there exists a family $v=(v_x)_{\{x\in\Omega\}} $ where each $v_x$ is a probability measure on $\mathbb{R}$ such that for any $\Phi\in\mathbb{E}_1$ \begin{align*}
\langle\langle v_j,\Phi\rangle\rangle &\to \langle\langle v,\Phi\rangle\rangle \\
&:= \int_\Omega\int_\mathbb{R} \Phi(x,z)dv_x(z)dx
\end{align*} as $j\to\infty$ . Our lecturer claims that this Young measure $v$ is given by the pushforward of the Lebesgue measure restricted to $(0,2\pi)$ , under the map $\sin(\cdot)$ , divided by $2\pi$ , at all points $x\in\Omega$ . That is $$v_x=\sin(\cdot)_*\left(\left(\frac{1}{2\pi}\right)\mathcal{L}\llcorner(0,2\pi) \right) $$ Where the pushforward measure is defined as $f_*(\mathcal{L})(A)=\mathcal{L}(f^{-1}(A))$ . They also claim that this follows from the Riemann-Lebesgue lemma. Is anyone able to explain why this is the limit? It is not obvious to me how the integrals converge, let alone to what is stated. Many thanks for any advice,
A.","['functional-analysis', 'calculus-of-variations', 'measure-theory', 'partial-differential-equations']"
1691466,Common notation for non vacuous implication,"Taking the definition of vacuous truth to be an implication where nothing satisfies the antecedent. Is there notation commonly used for ""non-vacuous implication""? I could write: $(\forall x . P(x) \implies Q(x)) \land (\exists x . P(x))$ But I need to write it a lot, so I would prefer to write some shorthand.","['notation', 'elementary-set-theory']"
1691483,Focus of the Parabola,"Find the Focus of $$(2x+y-1)^2=5(x-2y-3)$$. Clearly its a Parabola whose axis is $2x+y-1=0$ and since $x-2y-3=0$ is perpendicular to $2x+y-1=0$ Tangent at the vertex is $x-2y-3=0$.Also the Vertex is $(3,-1)$, but now how to find its focus?","['analytic-geometry', 'calculus', 'geometry']"
1691497,"If $f,g$ are analytic in the unit disk, and $|f|^2+|g|^2=1$, then $f,g$ constant.","I need to prove that if $f,g$ are analytic in the unit disk, and $|f|^2+|g|^2=1$ for all $z$ in the unit disk, then $f,g$ are constant. This is an exercise question so it should not be very hard, but I don't know where to start. Any hint is appreciated.",['complex-analysis']
1691503,"What is wrong with this argument that closed interval [0, 1] is not compact?","I am a student majoring engineering. I am studying real analysis with textbook 'Measure and Integral' by Wheeden and Zygmund. This book defined compact like the following: $E$ is compact if every open cover of $E$ has a finite subcover. By the definition $[0, 1]$ is not compact. However, by the Heine-Borel theorem, $[0, 1]$ is compact. Let me prove why $[0, 1]$ is not compact by the definition. According to the definition, it is enough to show an open cover of $E$ having infinite subcover. If $C=\{U_\alpha:\alpha\in \mathbb{N}\}$ is an indexed family of sets $\displaystyle U_\alpha=\left(-1+\frac{1}{n}, 2\right)$,
then $C$ is a cover of $[0, 1]$ because $\displaystyle [0,1] \subseteq \bigcup\limits_{\alpha  \in \mathbb{N}} {\mathop U\nolimits_\alpha  }$. This $C$ has infinite subcovers like $C=\{U_{2\alpha}:\alpha\in \mathbb{N}\}$ Can someone teach me what is my fault?","['real-analysis', 'proof-verification', 'compactness', 'general-topology', 'definition']"
