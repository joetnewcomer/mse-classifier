question_id,title,body,tags
670916,A closed form for the antiderivative of $\frac 1{\sin^5 x +\cos^5 x} $,Does there exist a closed form expression for  $$\int \dfrac {dx}{\sin^5 x +\cos^5 x}? $$,"['trigonometry', 'integration', 'indefinite-integrals']"
670930,Product of symmetric positive definite matrices,"I was asked the following question: Let $A,B \in \mbox{Mat}_n(\mathbb R)$ be symmetric positive definite matrices. Show that $AB$ does not have negative eigenvalues. My answer I'm getting something very weird. According to my answer, $AB$ has to be positive definite. which is weird because we don't know that $AB$ is symmetric. $B$ is symmetric so there is a basis $v_1,...,v_n$ of eigenvectors such that $Bv_i=\lambda_i$ and $\lambda_i>0$ for all $i$, and $<v_i,v_j>=0$ when $i\neq j$ let's look at $<ABx,x>$ where $x$ is some vector in $\mathbb R^n$ $<ABx,x>=<AB\sum_{i=1}^n \alpha_i v_i,\sum_{i=1}^n \alpha_i v_i> = <AB\alpha_1 v_1,\alpha_1 v_1>+<AB\alpha_2 v_2,\alpha_2 v_2>+...+<AB\alpha_n v_n,\alpha_n v_n> = \alpha_1 ^2 \lambda_1<Av_1,v_1>+\alpha_2 ^2\lambda_2<Av_2,v_2>+...+\alpha_n ^2 \lambda_n<Av_n,v_n>$ obviously for all $i$ $\alpha_i ^2$ is positive. Because $B$ is positive definite, for all $i : \lambda_i >0$. Because $A$ is positive definite, for all $i: <Av_i,v_i>$ is positive. so overall, for all $i: \alpha_i ^2 \lambda_i <Av_i,v_i>$ is positive. So we got that $<ABx,x>$ is larger than zero for any vector $x$, and so I infer that $AB$ is positive definite. And so it doesn't have negative eigenvalues. But how can we say that it's positive definite if it's not symmetric? I did something wrong I'm sure.","['positive-definite', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'positive-semidefinite']"
670933,Cardinality of $\mathbb{Z}[x]$,"What is the cardinality of $\mathbb{Z}[x]$, the set of all polynomials with integer coefficients?
It seems like it is countably infinite: Define the height of a polynomial to be the sum of the absolute value of its coefficients and its degree $-1$. There are only finitely many polynomials of each height. We can list each polynomial, starting with height $-1$, $0$, and then $1$, etcetera, ordering the polynomials of each height by their constant term, and moving to the linear term if they are equal. It seems as though this is an ordering of the polynomials with integer coefficients, so the set is countably infinite. However, each polynomial can be expressed as an infini-tuple. Then a diagonal argument shows that there is a polynomial that is not in the list. How can this be?",['elementary-set-theory']
670939,A is Mn×n(C) with rank r and m(t) is the minimal polynomial of A. Prove deg $m(t) \leq r+1$,"$A$ is a matrix of $M_{n \times n}(\mathbb{C})$ with rank $r$ and $m(t)$ is the minimal polynomial of A.
I need to prove that : deg $m(t) \leq r+1$ I need to find a condition of the matrix A, in which deg $m(t) = r+1$ Can anyone help me ? The solution involves the primary decomposition theorem for matrices and Jordan form..","['matrices', 'linear-algebra', 'polynomials']"
670975,Converting 2nd order to 1st order,"So I have 2 second order odes that I need to convert into 4 first order odes. The odes are:
$$m_1x_1^{\prime\prime} = -k_1(x_1-l_1)+k_3(x_2-x_1-l_3)$$
$$m_2x_2^{\prime\prime} = -k_2(x_2-l_2)-k_3(x_2-x_1-l_3)$$ So I saw these posts so I understand I have to use a change a variable (I think that's what they are called) but I just don't understand the step-by-step portion. I kind of need to be walked through the process to really understand WHAT I'm doing.","['differential', 'ordinary-differential-equations']"
670998,"$H^{-1}(\Omega)$ given an inner product involving inverse Laplacian, explanation required","Let $\Omega$ be a bounded domain and define $V=L^2(\Omega)$ and $H=H^{-1}(\Omega)$. Endow $H$ with the inner product
$$(f,g)_{H} = \langle f, (-\Delta)^{-1}g \rangle_{H^{-1}, H^1}$$
where $(-\Delta)^{-1}g = \tilde g$ is the solution of $-\Delta \tilde g = g$  on $\Omega$, $\tilde g= 0$ on $\Gamma$. In Lions' Quelques methodes... on page 192, he uses this set up to deal with a PDE of the form
$$u_t - \nabla \cdot (|u|\nabla u) = f.$$ Now, we have a Hilbert triple $V \subset H \subset V^*$. I remember that we identify $H$ with its dual, but not $V$ with its dual. But $V^*= (L^2)^* = L^2$. So how should I think of the dual of $V$? I ask because Lions then says the following: ...standard theory from before tells us there is a unique $u \in L^2(0,T;V)$ with $u_t \in L^2(0,T;V^*)$ such that
  $$(u'(t), v)_H + a(u(t),v) = L(t)(v)$$
  where $a(u,v) = \frac{1}{2}\int_\Omega |u|uv$ (and $L(t)$ is given but it's not relevant here). My question is, why does Lions write $(u_t,v)_H$ and not $\langle u_t, v \rangle_{V^*,V}$? We only know that $u_t \in L^2(0,T;V^*)$, don't know that it's in $L^2(0,T;H)$. But if we did identify $V^* = L^2$, then we get $L^2 \subset H^{-1} \subset L^2$ (but this would mean $L^2=H^{-1}$!!!), and the duality pairing becomes the $H^{-1}$ inner product as defined above so it kinda makes sense. Finally, any references to other work where PDEs are tackled with the pivot space equal to $H^{-1}$ with the inverse Laplacian are hugely appreciated. Thanks.","['reference-request', 'sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
671017,Questions about Bayesian inference,"From Wikipedia The prior distribution is the distribution of the parameter(s) before any data is observed, i.e. $p(\theta \mid \alpha )$. ... The sampling distribution is the distribution of the observed data conditional on its parameters, i.e. $p(\mathbf {X}\mid \theta )$ .
  This is also termed the likelihood,... The marginal likelihood (sometimes also termed the evidence) is the distribution of the observed data marginalized over the
  parameter(s), i.e. $$p(\mathbf {X}\mid \alpha )=\int_{\theta
    }p(\mathbf {X}\mid \theta )p(\theta \mid \alpha )\operatorname
    {d}\!\theta .$$ The posterior distribution is the distribution of the parameter(s) after taking into account the observed data. This is
  determined by Bayes' rule, which forms the heart of Bayesian
  inference: $$
        p(\theta \mid \mathbf {X},\alpha )={\frac {p(\mathbf {X}\mid\theta )p(\theta \mid \alpha )}{p(\mathbf {X} \mid \alpha )}}\propto p(\mathbf
    {X} \mid \theta )p(\theta \mid \alpha ) $$ In the calculation of the marginal likelihod and posterior
distribution, I wonder what is the reason that $p(\mathbf
    {X }\mid \theta )$ is not $p(\mathbf {X} \mid \theta, \alpha )$ instead? The posterior predictive distribution is the distribution of a new data point, marginalized over the posterior: $$
        p(\tilde {x} \mid \mathbf {X},\alpha )=\int_{\theta}p(\tilde {x} \mid \theta )p(\theta \mid \mathbf {X},\alpha )\operatorname
    {d}\!\theta $$ Why is $p(\tilde{x} \mid \theta )$ not $p(\tilde {x} \mid \theta, X,
    \alpha )$ instead? Thanks!","['statistics', 'bayesian', 'probability', 'statistical-inference']"
671029,Finding the metric of a surface embedded in $\mathbb{R}^3$,"I have a problem about finding the metric of a surface defined by $x=\rho\cos\varphi,\ y=\rho\sin\varphi,\ z=\rho^2$, embedded into $\mathbb{R}^3$, where $ds^2=dx^2+dy^2+dz^2$. I have literally no idea how to do this. Worse perhaps, is I find the expression $ds^2=dx^2+dy^2+dz^2$ hopelessly meaningless, because I can't understand any precise meaning of $ds, dx$ etc. I understand it's supposed to capture the nature of the pythagorean theorem as used to calculate distances in 3D and generalise it, but what exactly $dx$ is precisely escapes me. ""A small distance"" or ""A small change"" don't do it for me; it's apparently being used to define distances so calling it a small distance is clearly circular, and what exactly makes a small change? How do you calculate with such quantities? How do you know how the expression for $ds^2$ is going to change when you change coordinates? (These are questions I feel I really shouldn't have to ask, but my lecturer is very sporadic, unclear, and provides very few resources, and feel quite stuck.) I am looking for an explanation or some resources to enlighten me as to what I should understand by these quantities/expressions, and some hopefully some help with how I would go about finding the metric of the paraboloid above. I would also appreciate a recommendation of a good text for a first course on differential geometry of curves and surfaces to self-study from. Thanks in advance.",['differential-geometry']
671032,Show that $f :X \to Y$ is injective iff $f^{-1}f(A))=A$ for all subsets $A$ of $X$ (proof checking),"Show that $f :X \to Y$ is injective iff $f^{-1}f(A))=A$ for all subsets $A$ of $X$. Now I wrote a proof for this theorem and my question is firstly, is it correct? Secondly, since this is my first experience in writing such proofs, is it clear and concise enough? It feels quite unclear to me. So any tips and help would be appreciated. Here is my proof: First we assume that  $f$ is injective, i.e. $f(x_1)=f(x_2)$ implies that $x_1=x_2$. Now This means that $\forall y\in f(A) \exists\text{ a unique } x\in X | f(x)=y$. For each element in $x\in X$ we thus have $f^{-1} f(x) = x$. Thus we have for all subsets $A$ of $X$ that $f^{-1}f(A))=A$. We can see this results is not true when $f$ is not injective, or when each element $y$ in $f(A)$ may not have unique inverse. In this case $f^{-1}(y)$ is not defined. To show the opposite direction we assume that $f^{-1}f(A))=A$ for all subsets of $X$. Then in particular for all singleton sets $A=\{x \}$ we have $f^{-1}f(x))=x$. Now when $f(x_1)=f(x_2)$ we may apply the inverse mapping to each side to obtain $f^{-1}f(x_1))=f^{-1}f(x_2))$. By the hypothesis this reduces to $x_1=x_2$ and we have shown that $f$ is injective. Once again, if anyone could help me identify any mistakes, inconsistencies or stylistic mistakes I would be happy to hear them! Thanks in advance.","['elementary-set-theory', 'proof-verification']"
671043,Unbounded linear functional maps every open ball to $\mathbb{R}$?,"I can't get my head wrapped around this: Let $X$ be a normed linear space. Let $f:X\rightarrow\mathbb{R}$ be a linear functional on $X$. Prove that $f$ is unbounded if and only if $\forall y\in X$ and $\forall \delta>0$ we have $\{f(x)\,:\,|x-y|<\delta\}=\mathbb{R}$. I have already proved: 1.) $f$ is continuous if and only if $f$ is bounded 2.) $f$ is bounded if and only if $f^{-1}(0)$ is closed 3.) either $f^{-1}(0)$ is closed ($f$ bounded) or $f^{-1}(0)$ is dense in $X$ ($f$ unbounded) I know that all these ideas play off one another in some fashion, but cannot seem to tease out a solution to the above statement. Any help or direction would be appreciated.",['functional-analysis']
671055,Is proving both sides of iff necessary?,"I have always been taught to prove both ways of an ""if and only if"" statement in a formal proof, but if the opposite way is very similar to the proof of the first way. Can you just leave a note and leave it at that?","['logic', 'discrete-mathematics']"
671066,Zeros diagonal element of a semidefinite matrix leads to zeros row/column. Why?,"I have a similar problem as in this question. In short words: Assume a square, positive semidefinite matrix $A\in\mathbb R^{n\times n}$.
Show that if a diagonal element of $A$ is zeros then the corresponding row and column are all zero. The answer in the other question suggests to look at the definiteness of the matrix
$$ B = \begin{pmatrix} a_{i,i} & a_{i,k} \\ a_{k,i} & a_{k,k} \end{pmatrix}$$
where $a_{k,k}=0$ and both $a_{i,k}$ and $a_{k,i}$ are non-zero. I tried to proof this fact but I am unsure if I did it correctly.
Also there might be a better/quicker/clearer way to do it.
Would you mind going through it and give me your oppinion? If one calculates the eigenvalues we get 
$$\lambda_{1,2} = \frac{a_{i,i}\pm\sqrt{a_{i,i}^2+4a_{i,k}^2}}{2}.$$
Thus we know that $B$ is indefinite as $\sqrt{a_{i,i}^2 + 4a_{i,k}^2} > \lvert a_{i,i} \rvert$. If $A$ is positive semidefinite then $x^T A x \geq 0$ for all $x\in\mathbb R$ must hold.
Assume a matrix $C\in\mathbb R^{n \times 2}$ that is zeros except for the elemets $c_{i,1}=c_{k,2}=1$.
This must also hold true for the special case that $x=Cy$ with $y\in\mathbb R^2$.
We obtain $y^T C^T A C y = y^T B y$ means that $C^T A C$ is indefinite.
This is a contradiction to the assumption that $A$ is positive semidefinite. Is there an (easy) way to extend this to block matrices?","['matrices', 'eigenvalues-eigenvectors', 'block-matrices', 'analysis']"
671098,How much space probability should have in Statistics learning,"Of late I have started self-learning. I have bought a few well-advised Statistics books such as Statistics for Management by Levin and First Course on Probability by Ross. I observe that Ross' book has much more coverage than that of Levin's. I think Ross covers probability from Mathematical Statistics point of view rather than that of Business Statistics. Levin's does not have as much coverage on probability as Ross (In my humble opinion). And there I get confused. Given that I want pursue a career in Data Analysis, should I follow Ross book along with Levin's? Will Levin's book's coverage of Probability will suffice? Do you think following Ross' book First Course in Probability would be difficult and I should first start with Levi? Could you please give your guidance. Warm Regards Sabya","['statistics', 'probability']"
671155,Measurable function applied on stationary sequence,Let $(X_t)_{t\in\mathbb{N}}$ be a strictly stationary sequence of real random variables and $f:\mathbb{R}\rightarrow\mathbb{R}$ a measurable function. My simple question: Is $$ Y_t:=f(X_t)$$ also strictly stationary?,"['probability-theory', 'stochastic-processes']"
671173,a basic doubt on continuous image of a measurable set measurable,"Is continuous image (say the function is on $\Bbb R^n$) of a measurable set measurable ? Hint enough. Actually, $f: \Bbb R^n \to \Bbb R^n$ is given to be linear. I used some theorem to conclude that it is continuous.",['measure-theory']
671176,The set of smooth maps from exotic smooth manifolds to the reals,"Here a $M,N$ are topological manifolds and $\mathcal{A}$ and $\mathcal{B}$ are atlases. The brackets $[]$ denote the formation of the equivalence class of atlases. Let $(M,[\mathcal{A}])$ and $(N,[\mathcal{B}])$ smooth manifolds exotic to each other ($M$ and $N$ homeomorphic, lets say $h(M)=N$, but not diffeomorphic with the smooth structures). I wondered if the following statements are true. $f\in C^\infty (M,[\mathcal{A}])$ is not equivalent to  $f\circ h \in C^\infty (N,[\mathcal{B}])$ There exists an $f\in C^\infty (M,[\mathcal{A}])$ such that there is no $g\in C^\infty (N,[\mathcal{B}])$ such that $f=g\circ h$ and the other way around: There exists an $g\in C^\infty (N,[\mathcal{B}])$ such that there is no $f\in C^\infty (M,[\mathcal{A}])$ such that $g=f\circ h^{-1}$. For all $f\in C^\infty (M,[\mathcal{A}])$ there is no $g\in C^\infty (N,[\mathcal{B}])$ such that $f=g\circ h$. Or in more transparent version with atlases dropped from notation and $M=N$ as topological spaces, but still not diffeomorphic. $C^\infty M\neq C^\infty N$ $C^\infty M\not\subset C^\infty N$ and $C^\infty N\not\subset C^\infty M$ $C^\infty M\cap C^\infty N=\emptyset$ Thanks in advance and maybe the diffoelogy characterization of smoothness is helpful. Kind regards Mar (corrected the error)",['differential-geometry']
671182,Summation of the series,"Please help me find the summation of following series under limit. $$
\lim_{n \to \infty}
\sum_{x = 1}^{n}{1 \over x}\,\cos\left(\left[x - 1\right]{\pi \over 3}\right)
$$ Thank you.
:)","['sequences-and-series', 'limits']"
671201,"$f:X\to Y$, $A,B,\subseteq X$. Show that $f(A\setminus B)=f(A)\setminus f(B)$ iff $f(A\setminus B)\cap f(B) =\emptyset$","I tried to prove this but I am not sure if its correct. Please help me out with any tips or advice on how to improve. Here it is: First let $f(A\setminus B)\cap f(B)=\emptyset$. Now $$f(A\setminus B)=(f(A)\setminus f(B)) \cup \{     y\in Y| \exists (x_1 \in (A\setminus B), x_2\in B) |f(x_1)=f(x_2 ) \}.$$
Now by the hypothesis $f(A\setminus B)\cap f(B)=\emptyset$ we have that $\nexists (x_1 \in (A\setminus B), x_2\in B) |f(x_1)=f(x_2 ) $. Thus
$$f(A\setminus B)=(f(A)\setminus f(B)) \cup \emptyset=f(A)\setminus f(B).$$
Now for the reverse implication we assume that $f(A\setminus B)=f(A)\setminus f(B)$. We intersect both sides with $f(B)$ to obtain $$f(A\setminus B)\cap f(B)=(f(A)\setminus f(B))\cap f(B)=\emptyset.$$ So this is my proof. I personally think it's correct but very unclear possible. Any help or verification will be appreciated. Thanks in advance","['proof-verification', 'proof-writing', 'elementary-set-theory', 'functions']"
671214,$\sigma$-finite measure and semi-finite measure,"Let $ (X, \Sigma, \mu)  $ it will be a space with measure. $\mu$ is $\sigma$ -finite measure if it exist sequence of sets $X_{i} \in \Sigma $ and $\cup_{i=1}^{\infty}X_{i}=X$ and $\mu(X_{i})<\infty$ for all i $\mu$ is semi-finite measure if for all $G \in \Sigma $ and $\mu (G)=\infty$ it exist $H \in \Sigma$ and $H \subset G$ and $0<\mu(H)<\infty$ Show that if $\mu$ is $\sigma$ -finite measure then $\mu$ is semi-finite measure","['measure-theory', 'real-analysis', 'analysis']"
671246,Elevator Problem (Sample Space),"Carefully describe the events $A$, $B$, $A\cup B$, and $A\cap B$ in the following sample space: Six people enter the elevator in the basement of a building with 6 floors. Each states where they will get out. $A$ = {all six get off on the same floor}, $B$ = {exactly five people get off on floor two} From my understanding: $A$ - Everyone says they will get out on a floor $S$ = Everyone gets off at floor {1,2,3,4,5,6} $|S| = 6$ $B$ - Exactly five people get off on floor two $S$ = One person will get off at either floor {1,3,4,5,6} $|S|$ = 5 But as far as calculating $A\cup B$ or $A\cap B$ of the following, I don't quite understand",['discrete-mathematics']
671264,How to determine the length of $x$ in this sketch?,"Consider the following construction: Assume that you are given the lengths of the sides $a,b,c,d,e$ as well as the size of the angle $\phi$ . The task is to determine the length of $x$ in terms of the given parameters. I've found that $x$ has to satisfy the equation $$\frac{c^2+x^2-d^2}{2cx}=\cos(\phi) \frac{b^2+(x+e)^2-a^2}{2b(x+e)} + \sin(\phi) \sqrt{1-\left(\frac{b^2+(x+e)^2-a^2}{2b(x+e)}\right)^2}.$$ However, I don't see any possibility to solve this equation (which yields something like a polynomial of 6th degree in $x$ ) explicitly.","['geometry', 'algebra-precalculus', 'euclidean-geometry']"
671275,"Closed form double integral $ \int_{a}^{c}dr \int_{b}^{d} dr' \, \frac{r r'}{\sqrt{(r - a)(r' - b)(r-c)(r'-d)}} \frac{r_<^{\ell}}{r_>^{\ell+1}}$","Is there a closed form expression for
$$
S_\ell =
\int\limits_{a}^{c}dr
\int\limits_{b}^{d} dr' \,
\frac{r r'}{\sqrt{(r - a)(r' - b)(r-c)(r'-d)}}
\frac{[\min( r , r')]^{\ell}}{[\max(r,r')]^{\ell+1}}
$$
for $0<a<b<c<d$? Here $\max(r,r') = r$ if $r\geq r'$ and $\max(r,r') = r'$ otherwise, $\min(r,r')$ is defined similarly.
For large $\ell$, it may be shown that the integral is dominated by $r\approx r'$ and asymptotically
$$
S_{\ell} \rightarrow \frac{2}{\ell}\int\limits_{b}^{c} dr \,
\frac{r^2}{\sqrt{(r - a)(r - b)(r-c)(r-d)}}
$$
This can be integrated in a closed form using elliptic integrals as shown here .
That solution seemed so general, I wonder if the double integral can also be integrated similarly in a closed form.","['closed-form', 'calculus', 'special-functions', 'definite-integrals', 'elliptic-integrals']"
671281,Derivative of exponential function proof,"I'm looking for a straight forward proof using the definition of a derivative applied to the exponential function and substitution of one of the limit definitions of $e$, starting with $e = \lim_{h\to \infty}\left({1+\dfrac{1}{h}}\right)^h$ or $e=\sum_{h=0}^{\infty}{\dfrac{1}{h!}}$ and $\dfrac{d}{dx}\left( e^x \right) = \lim_{h\to 0}\left({\dfrac{e^{x+h}-e^{x}}{h}}\right)$ I found a proof I sort of liked here (which is sort of along the lines of a proof I'd like to use): http://www.math.brown.edu/UTRA/explog.html My only problem is that he combines the dummy variable, $h$, for the limit definition of $e$ and the dummy variable, $h$, used for the derivative. To me, it seems like it's not quite valid to do such a thing because it assumes both values are equal. Can anyone provide a better proof or justification for why the dummy variables can be combined? EDIT: I guess I'd also like to have a proof of why: $\lim_{h\to 0}\left({\dfrac{e^{h}-1}{h}}\right) = 1$ using one of the limit definitions of $e$ shown above.","['sequences-and-series', 'calculus', 'exponential-function', 'derivatives', 'limits']"
671297,directional derivatives implications,"Suppose $f:\mathbb{R}^n \rightarrow \mathbb{R}^m$. Let $y\in\mathbb{R}^n$. Then we define the directional derivative in the direction $y$ by :
\begin{equation}
f'(x;y) = \lim_{t \to0}\frac{f(x+ty)-f(x)}{t} 
\end{equation}
I guess the directional derivative of $f$ in the direction of $\lambda y, \lambda\in \mathbb{R}$ should be the same with the one in the direction of $y$. But if $f'(x;y) $ exists then one can see that,
\begin{equation}
\frac{f(x+t\lambda y)-f(x)}{ t}=\lambda\frac{f(x+t\lambda y)-f(x)}{\lambda t} 
\end{equation}
and the limit of the right hand side when $t\rightarrow 0$ is $\lambda f'(x;y)$. Do I do something wrong here? Please help by giving a rigorous answer. Thank you.","['multivariable-calculus', 'calculus', 'limits']"
671303,Inverse of identity plus scalar multiple of matrix,"Given the matrix $M = ( I + \alpha D P )$, where $I$ is the nxn identity, $D$ is nxn symmetric and invertible, $P$ is nxn symmetric but not always invertible, and $\alpha$ is a scalar, is there a way to updatae $M^{-1}$ when $\alpha$ changes without performing a new matrix inverse calculation? I need to calculate this inverse many times, so I'm trying to find a formula that doesn't require a new matrix inverse every time $\alpha$ changes. I've tried manipulations with the Woodbury identity, but they all include a matrix inverse that's a function of $\alpha$. Let me edit this to backup a step and add some more information: I'm solving for $s$ in this equation $s=s^{tr}-\alpha D P s$, where $s$ is a $n \times 1 $ vector and $s^{tr}$ is a constant $n \times 1 $ vector. Then the solution is then $s=(I+\alpha D P)^{-1}s^{tr}$. This is part of an iterative solution to solve for $s$ and $\alpha$, where $\alpha$ depends on $\| s\|$.","['matrices', 'inverse']"
671341,Common Factor in Matrices?,"I am trying to solve some matrix multiplications, but I would like to know If I am allowed to take a common factor from matrices like this C - ABC = (1 - AB)*C where A is m*n and B is n*n. And if yes, what matrix will be the 1 matrix? It cannot be an identity as the AB is m*n. Thanks a lot",['matrices']
671351,"How to find $\int_{S^2}f \cdot n \ \text{d}S$ if $f(x,y,z):=(x^3,y^3,z^3)^T$","With $\mathbb{S}^2$ being the unit sphere, how to find $$\int\limits_{\mathbb{S}^2} \vec{f} \cdot \vec{n} \ \text{d}S$$ if $\vec{f}(x,y,z):=(x^3,y^3,z^3)^T$? Apparently, we need to use Gauss. With $B$ being the unit ball we get: $$\int\limits_{\mathbb{S}^2} \vec{f} \cdot \vec{n} \ \text{d}S = \int\limits_B \operatorname{div} \vec{f} \ \text{d}V$$ with $\operatorname{div}f=3x^2+3y^2+3z^2$. Yet I'm not quite sure how to move further. I've tried the transformation theorem: $$\int_{\phi(K)} f = \int_{K} f(\phi(x)) |\det \phi'(x)| \ \text{d}x$$
with $\phi(r,\alpha,\beta):=(r \cos\alpha, r \sin\alpha \cos\beta, r \sin\alpha \sin\beta)$ and got stuck right away.","['multivariable-calculus', 'calculus', 'integration', 'vector-analysis', 'real-analysis']"
671374,"supA, infA, maxA, minA","Having the set $$A=\{x: x \leq 0, x^2+x-1<0\}$$
I am asked to find $\sup A, \inf A, \max A, \min A$. I found the roots of the equation $x^2+x-1=0$, which are $$\frac{-1+ \sqrt{5}}{2} \text{ and } \frac{-1- \sqrt{5}}{2}.$$ Since $x \leq 0$, we have $x \in \left( \frac{-1- \sqrt{5}}{2},0 \right]$. So $$A= \left\{x:x  \in \left( \frac{-1- \sqrt{5}}{2},0 \right] \right\}.$$ So $\sup A=0, \max A=0, \inf A= \frac{-1- \sqrt{5}}{2}, \nexists \min A$. Is this correct?","['real-analysis', 'analysis']"
671387,Counterexample to Converse of Extreme Value Theorem?,"The extreme value theorem says:
If $X$ is a compact topological space, then for all functions $f: X \to \mathbb{R}$ such that $f$ is continuous we have that $f$ satisfies the extreme value property.  That is, if $f$ is continuous then there exists a point $c$ in $X$ such that $f(c)= \sup \{f(x) : x \in X \}$, where this supremum is necessarily finite. My question is: Does the converse of this theorem hold in general?  That is, if every continuous function on a space $X$ has the extreme value property, then is $X$ compact?  Or is it instead true that there exists a topological space $X$ which is not compact but such that every continuous function on $X$ has the extreme value property?  If the latter is true, I would like an example.  If the former is true, a proof would be ideal. Thanks!","['general-topology', 'continuity', 'compactness']"
671388,"Find sup, inf, min, max of the set B","Given the set $$B=\left\{\frac{1}{n}+(-1)^n, n \in \mathbb N\right\}$$ I have to find $\sup B$ , $\inf B$ , $\max B$ , $\min B$ . $$$$ For $n=even:$ $$B_{even}=\left\{\frac{1}{2k}+1, k=1,2,...\right\}$$ For $n=odd:$ $$B_{odd}=\left\{\frac{1}{2k+1}-1, k=0,1,2,...\right\}$$ So, $\max B= 1+ \frac{1}{2}=\frac{3}{2}$ , $\sup B =\frac{3}{2}$ , $\min B=-1$ , $\nexists \inf B$ . Is this correct?",['analysis']
671392,Calculating the trace of the product of two matrices,"I have to calculated $\mbox{trace}(A^{-1}B)$ where $A$ is a symmetric positive definite matrix and $B$ is a symmetric matrix, very sparse with only two elements non zero. I want to find a way that I could calculate the above expression efficiently specially when A and B are high dimensional like $10000\times 10000. $  What is the best way to do it. I have a bunch of Bs each very sparse with only two non zero values. I cannot store $A^{-1}$ since it is dense and I won't have enough memory. Any efficient ways/tricks to do it efficiently, like trace properties or something?","['trace', 'linear-algebra', 'inverse']"
671401,About the converse of Maschke's theorem,"The Maschke's theorem say that\ Let $G$ be a finite group and $F$ a field whose characteristic does not divide $\mid G \mid$. Then every $FG$-module is completely reducible (I'm using the notation of Isaac's in the book Character Theory of finite groups).
The converse of this theorem is true, but I can not prove it.\
I would like your help, if possible. 
Thank you.
Below I outline the idea of proof.","['finite-groups', 'group-theory', 'representation-theory']"
671421,"Law of large numbers: second moment tends to 0, but $S_n/n$ doesn't converge a.e.","What is an example of a sequence of random variables $\{X_n\}$ on a probability space $(\Omega, \mathscr{F}, P)$ such that $E\left(X_n^2\right) \to 0$ but it is not the case that
$$
\frac{S_n - E(S_n)}{n} \to 0
$$
almost everywhere. There is no assumption of independence of $\{X_n\}$. See Chung's A Course in Probability Theory, problem 5.1.1, for reference. Attempts Take $P$ to be Lebesgue measure on the Borel sets $(0,1]$. Let $X_1 = 1$ on $(0,1]$, $X_2 = 1$ on $(0,0.5]$, $X_3 = 1$ on $(0.5,1]$, $X_4 = 1$ on $(0,1/3]$, and so on. This is an example to show convergence in probability does not imply convergence almost everywhere. This fails. Take $X_n = 1$ on $(0,1/n]$. This fails.","['examples-counterexamples', 'probability-limit-theorems', 'random-variables', 'probability-theory', 'law-of-large-numbers']"
671454,A metric space with a countable dense subset removed is totally disconnected?,"I am wondering if it is true, and what the proof would go like, that given a metric space $X$ with a countable dense subset $D$, $\ X\setminus D$ is totally disconnected.","['general-topology', 'connectedness']"
671494,Differential equations. Shortcut way to solve this problem?,"Disclaimer: I am not a student trying to get free internet homework help. I am an adult who is learning Calculus from a textbook. I am deeply grateful to the members of this community for their time. Here is the problem I am trying to solve: The weight in pounds of a certain bear cub $t$ after birth is given by
  $w(t)$. If $w(2)=36, w(7)=84,$ and $\frac{dw}{dt}$ was proportional to
  the cub's weight for the first $15$ months of his life, how much did
  the cub weigh when he was $11$ months old? A friend of mine emailed me his solution: No calculus involved. $\frac{dy}{dy} = k y$ That implies $y=\exp(kt+C)$ One $(t,y)$
  pair gives $k$, another gives $C$. You don't have to know the
  differentiation, just the result, hence, no Calculus. Can someone decipher what he's saying?  What is $\exp()$?  Exponent?  $y$ equals an exponent?  Huh?  I had no idea what he meant, and asked for clarification.    His alternate solution was If Diff. Eq. is of the form $\frac{dy}{dt} = ky$, then write solution as $y=$
  $\exp(...)$ That's it! I don't understand how this problem can be solved in just 1 line.  It's clear that he's addressing this problem with a totally different approach than the traditional ""Calculus/DiffEq"" approach. Below is is how I did it.   Although I arrive at the correct answer after 10 mins. and an entire page of paper, I'd like to understand the 1-liner shortcut method above, as it seems a big time saver.  Can anyone explain his approach written out legibly in a photo scan?","['ordinary-differential-equations', 'calculus']"
671543,Literature on Chern-Weil Theory and the Chern-Gauß-Bonnet Theorem,"At my university there are plans for a graduate seminar on Chern-Weil Theory and Chern's generalisation of the Gauß-Bonnet Theorem. Unfortunately I am having a though time in finding adequate and modern literature on this subject. Classically I know of Milnor's Appendix C in Milnor, Stasheff: ""Characteristic Classes"" and the famous text from Spivak's A Comprehensive Introduction to Differential Geometry entitled ""The Generalized Gauß-Bonnet Theorem and What It Means To Mankind"". Is there any more recent recommendable source? During my search I also came along Zhang: Lectures on Chern-Weil Theory and Witten Deformations . Does anyone have practical experience with this book? Thanks in advance!","['advice', 'soft-question', 'differential-geometry']"
671545,Projective module over a PID is free? [duplicate],"This question already has an answer here : Submodule of free module over a p.i.d. is free even when the module is not finitely generated? (1 answer) Closed 10 years ago . A common result is that finitely generated modules over a PID $R$ are projective iff they are free. Is the same true that an arbitrary projective module over a PID is free? I can't find this fact anywhere, so I suspect it is false, but I can't construct an example. Does anyone have an example of a projective module over a PID which is not free? Thank you.","['projective-module', 'abstract-algebra', 'principal-ideal-domains', 'modules', 'commutative-algebra']"
671589,Group isomorphism mapping generators to generators,"I know that an isomorphism between cyclic groups maps generators to generators, but is this still the case if the groups are non-cyclic? Many thanks!",['group-theory']
671637,Correct notation to indicate multiplying all elements within a set,"Is there a correct notation to indicate multiplying all elements within a set? For example, if $M = \left\{n_0, n_1, ..., n_t\right\}$ be the set of elements where I want to multiply all the numbers within the set to create the product, $P$. Is there a better way to indicate this multiplication than writing $P = n_0\times n_1\times...\times n_t$? I'm not an actual mathematician so any help on this would be greatly appreciated.","['notation', 'elementary-set-theory']"
671648,Is there a general way to count the number of sigma-algebras on a finite set? [duplicate],"This question already has an answer here : Number of $\sigma$  -Algebra on the finite set (1 answer) Closed 10 years ago . I was asked a high-school question today which was merely asking the number of sigma-algebras on a set. Let $X$ be a set Let $S\triangleq \{\Sigma\subset P(X): \Sigma \text{ is a sigma-algebra on }X\}$ . If $X$ is finite, what would be the cardinality of $S$ ? The question i was asked was the case $|X|=3$ . In this case $|S|=5$ . What would be the cardinality of $S$ in general? Is it possible to find this value via elementary function?",['measure-theory']
671659,Parameterization of the Schwarz P surface,Is there a closed form parameterization of the Schwarz P minimal surface ?,"['parametrization', 'minimal-surfaces', 'closed-form', 'differential-geometry']"
671663,Flabby sheaf comonad,"If one Googles sufficiently hard one finds the statement that Roger Godement gives the first example of a comonad, used to compute flabby resolutions of sheaves, in his monograph ""Topologie algébrique et théorie des faisceaux"". For example, see here . I am interested in comonads in the category $\mathsf{Sh}(X)$ of sheaves of abelian groups on a topological space $X$, so I looked out this paper and attempted some translation. I think that the relevant part is, given a sheaf $\mathscr{F}$, we define a new sheaf $C \mathscr{F}$ where
$$
C\mathscr{F}(U) = \{ \text{functions } s \colon U \longrightarrow \mathscr{E}_\mathscr{F} \mid s(x) \in \mathscr{F}_x \forall x \in U  \}
$$
where $\mathscr{E}_\mathscr{F}$ is the étalé space of $\mathscr{F}$, and $\mathscr{F}_x$ is the stalk of $\mathscr{F} $ at $x \in X$. My question is, is this really a comonad? I have found it hard to define a natural transformation $\varepsilon \colon C \longrightarrow 1$ that would turn $C$ into a comonad. Is there another functor $\mathsf{Sh}(X) \longrightarrow \mathsf{Sh}(X)$ which is the comonad which is being referred to? Is the original statement incorrect?","['sheaf-theory', 'general-topology', 'monads', 'category-theory', 'sheaf-cohomology']"
671681,Proof of Schwarz Formula,"I have a question for homework that asks If $f(z) = u(z) + iv(z)$ is analytic on $\mathbb{D}$ (the open unit disk), and $u(z)$ extends to be continuous on $\overline{\mathbb{D}}$, then
  $$ f(z) = \int_0^{2 \pi} u(e^{i \theta}) \frac{e^{i \theta} + z}{e^{i \theta} - z} \frac{d \theta}{2 \pi} + iv(0) $$
  for every $z \in \mathbb{D}$. Since $u(z)$ is harmonic (because $f$ is analytic) on $\mathbb{D}$ and extends to be continuous on $\overline{\mathbb{D}}$, I know from a theorem that
$$ u(z) = \int_0^{2 \pi} u(e^{i \theta}) \frac{e^{i \theta} + z}{e^{i \theta} - z} \frac{d \theta}{2 \pi} $$
for every $z \in \mathbb{D}$.  Further, since $v$ is harmonic, I know that there is some $\varepsilon > 0$ such that $\{ |z - z_0| < \varepsilon \} \subseteq \mathbb{D}$ and
$$ v(z) = \int_0^{2 \pi} v(z + \varepsilon e^{i \theta}) \frac{d \theta}{2 \pi} $$
for every $z \in \mathbb{D}$.  Where I am having trouble is that pesky '$iv(0)$' in the expression above.  Why are we evaluating $v$ at $0$?",['complex-analysis']
671694,The relationship between Golbach's Conjecture and the Riemann Hypothesis,"My question pertains to two famous groups of related conjectures: Goldbach's Conjecture ( GC ); Goldbach's Weak Conjecture ( GWC ); The Riemann Hypothesis ( RH ); The Generalized Riemann Hypothesis ( GRH ). These two groups of conjectures both appear to be strong statements about the distribution of the prime numbers. Yet it is unclear to me if each provides independent information about the distribution of the primes. If the two conjectures expressed the same underlying fact, we would expect a strong coupling between the conjectures, such as GC if and only if RH . Therefore, I am asking if someone would someone please take the time to review the state of the reseach on the  relationships between GC , GWC , RH , and GRH . References for any results mentioned would be much appreciated. For my part, I've read that by assuming GRH , one can provide an asymptotic proof of GWC . This strikes me as a weak relationship, and I wonder if there are stronger results which make use of RH to prove GC . In the other direction, I've heard one person claim, without references, that GC implies RH . The latter claim seems unlikely to me, but I'd like to find someone that can set the record straight. Note : I am looking for relationships across the two conjectures. It is clear to me that GC implies GWC , and GRH implies RH .","['riemann-hypothesis', 'goldbachs-conjecture', 'sequences-and-series', 'number-theory']"
671696,Finding the additive inverse in a vector space with unusual operations,"Let $V=\mathbb{R}$. For $u,v\in V$ and $a\in\mathbb{R}$, define vector addition by $$u\boxplus v:=u+v+2$$
  and scalar multiplication by
  $$a\boxdot u:=au+2a−2.$$
  It can be shown that $(V,\boxplus,\boxdot)$ is a vector space over the scalar field $\mathbb{R}$. Find the following... I have found the sum, scalar multiple and the zero vector. I don't know where the x is coming from, let alone how to find the additive inverse. Can someone assist me? Thanks.",['linear-algebra']
671702,Derivative of a polynomial,"First of all, I would like to say I'm new to Mathematics StackExchange, so pardon me if there're any mistakes (until I read the right formatting rules!). That said, we are currently learning derivatives in Cal I and I'm not sure if I'm following the right path for differentiating the following function: $$f(x) = (8x ^ 2 + 6) ^ 6 (-9x ^ 2 - 6) ^ {14}$$ So, all I used was the Product rule combined with the power rule and got: $$f'(x) = 6(8x^2+6)^5(-9x^2-6)^{14} + 14(8x^2+6)^6(-9x^2-6)^{13}$$ We do not have to distribute. Is that good or am I wrong? EDIT: Thank you for your quick answers! But I forgot to mention, we have not learned the chain rule yet. Next class!","['ordinary-differential-equations', 'calculus', 'derivatives']"
671716,Showing a linear map has a unique extension from a Sobolev space to an Lp space,"This is related to another question I asked: Directional derivative in a Sobolev-like inequality Suppose that $u \in C_{0}^{\infty}(\Omega)$. Show that the linear map $u \to u(x,0) \in C^{\infty}(\mathbb{R}^{n})$ has a unique continuous extension as a map from $W^{1,p}_{0}(\Omega)$ to $L^{p}(\partial \Omega_{+})$, where $\partial \Omega_{+} \equiv \{x;(x,0)\in\Omega\}$. I know that you can define extensions from one Sobolev space to another. Is the reason why we can do it here from a Sobolev space to an $L^{p}$ space because $L^{p}$ spaces are contained inside Sobolev spaces? Also, I was thinking about using the BLT Theorem, but do I know that the map from $u$ to $u(x,0)$ is bounded? I'm very confused, and not as well-versed in functional analysis as I should be, so any assistance/hints you could give me for this proof would be much appreciated!","['sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
671718,Transpose of continuous operator bounded below is surjective,Suppose $T: X\rightarrow Y$ is a continuous linear transformation between 2 normed vector spaces such tha $\|Tx\| \geq C\|x\|$ for some $C > 0$. Why must the transpose $T^{\ast}: Y^{\ast} \rightarrow X^{\ast}$ be surjective?,"['functional-analysis', 'real-analysis', 'analysis']"
671727,Question with nonempty bounds and sets,"Let $A$ and $B$ be nonempty sets of real numbers, bounded above and below. Prove that if $A\cap B$ is also nonempty, then $infB\leq supA$. So my train of thought goes like this: I'm picturing that the elements in set B are generall greater than the elements in set A. Makes sense, since the lowest bound of B is less than or equal to the highest bound in A. Now the problem I'm having here is using existing proofs to really put this altogether.  I understand that there is a completeness axiom that helps with the least upper bound, but the opposite is not really churning anything. Now the corollary to this would be that the subset of S that is bounded below has a greatest lower bound inf S. My other way of attempting this is to try turning on of these (as in A or B) the same but negative of the other. (I.E. B = -A) and applying this corollary.","['discrete-mathematics', 'proof-writing', 'real-analysis']"
671782,Applications of Complex Numbers,"For my Complex Analysis course, we are to look up applications of Complex Numbers in the real world. The semester has just started and I am still new to the complex field. I want to get a head start on my research for the course. Anything I have seen on the complex field has only been in passing from my other course like ODE, Linear Algebra, and Abstract Algebra. I was wondering if someone can lead me into the right direction about what applications of complex numbers I can look into for my research topic. Recommended books I can refer to would also help. Thank you for your time and thanks in advanced for your feedback.","['applications', 'soft-question', 'complex-numbers', 'complex-analysis', 'advice']"
671818,Isolated singularities of the resolvent,"Let $T$ be a bounded operator on $l_2$ such that there exists $\mu$ in the spectrum of $T$ which is an isolated point of the spectrum. We know that for any $x\in l_2$ the resolvent function $R(x):\rho(T)\to l_2$ given by $R(x)(\lambda)=(\lambda I-T)^{-1} x$ is analytic, and so $\mu$ is an isolated singularity of $R(x)$. Is it possible that, for some $x\neq 0, $ $\mu$ is a removable singularity for $R(x)$?","['operator-theory', 'functional-analysis', 'complex-analysis']"
671823,The infinite Direct Sum in the category Ring,"If you don't have strong personal feelings about it already, most of you have at least witnessed the opposing factions on how we should define a ring and, by extension, how we should define a ring homomorphism. The strong majority define a ring to have a unity and require that ring homomorphisms preserve it. Others do not require these things of a ring. The general pattern I've seen which determines into which camp any given mathematician falls is how 'good' they want their category of rings to be. Those who want zero morphisms and want to be able to define the kernel of a morphism categorically often opt to go without unity. There is a printed semi-famous comment about this problem in the Radical Theory of Rings by Gardner and Wiegandt: This is where my question begins. I have searched for why the category of Rings (with unity) does not have infinite coproducts. And basically everywhere that comments on it does not prove that there is no object in Ring which satisfies the universal property of a coproduct for an infinite family . What they do explain is that the thing we would expect to be the coproduct (namely the set-theoretic direct sum with pointwise addition and multiplication) is not a coproduct in Ring . I have attempted to prove the non-existence of such an object for myself but have not gotten far. One would have to show that either every infinite family of rings cannot all be embedded in another ring; or in the case that there is such an object, there is always a 'smaller' (non-isomorphic) object in Ring which has the same property. Thus my question is can someone prove to me that Ring (the category of rings with unity and unity preserving homomorphisms) does not have infinite coproducts? Or can you direct me to a reference that may have my answer?","['ring-theory', 'category-theory', 'reference-request', 'abstract-algebra']"
671862,"Every well-ordered set has a ""Parity"" function.","The problem is this: Given a well ordered set $U$, there exists a unique function $$Par: U \rightarrow \mathbb{N}$$ such that $Par(y) = 0$ if $y$ is $0$ or a limit point, and at successor points $x$, $$Par(S(x)) = 1 - Par(x).$$ [Sidenote:] This $Par$ function seems to determine whether the 'distance' of $x$ to a limit point $y$ below $x$ is odd or even. Is this correct? (Not part of the homework, purely a curiosity.) My idea for the problem is to somehow apply the Transfinite Recursion Theorem. However, to use this, I am required to define an $h: ( U \rightharpoonup \mathbb{N}) \times U \rightarrow \mathbb{N}$ so that $$Par(x) = h(Par|_{seg(x)}, x).$$ My attempts at a construction of such an $h$ seem somewhat ""circular"", unfortunately. Any hints or tips are appreciated. Please no direct answers. :P",['elementary-set-theory']
671863,"How prove that, for every $n$, $ \lim\limits_{x\to\infty}f_{n}(x)=\frac{1}{n!}$","Let $$f_{1}(x)=\left(\left(\dfrac{\ln{(1+x)}}{\ln{x}}\right)^x-1\right)\ln{x}$$
$$f_{2}(x)=\left(\left(\left(\dfrac{\ln{(1+x)}}{\ln{x}}\right)^x-1\right)\ln{x}-1\right)\ln{x}$$
$$f_{3}(x)=\left(\left(\left(\left(\dfrac{\ln{(1+x)}}{\ln{x}}\right)^x-1\right)\ln{x}-1\right)\ln{x}-\dfrac{1}{2!}\right)\ln{x}$$
$$\cdots\cdots\cdots\cdots$$
$$f_{n+1}(x)=\left(f_{n}(x)-\dfrac{1}{n!}\right)\ln{x}$$ Find the limit
$$\lim_{x\to +\infty}f_{n}(x)$$ I know $$\lim_{x\to+\infty}f_{1}(x)=1,\lim_{x\to+\infty}f_{2}(x)=\dfrac{1}{2!}$$ so I guess
$$\lim_{x\to\infty}f_{n}(x)=\dfrac{1}{n!}$$
But I can't prove it,Thank you",['limits']
671915,Relation between exterior (second) derivative $d^2=0$ and second derivative in multi-variable calculus.,"What does an exterior (second) derivative such as in $d^2=0$ have to do with second derivatives as in single- or multi-variable calculus? Is this a correct start: Calculus derivatives are good for Taylor expansions (and thus optimization), and curvature. Exterior derivatives are needed for integration -- and are essential for generalizing the Fundamental Theorem of Calculus (i.e., Stokes theorem).","['multivariable-calculus', 'differential-forms', 'exterior-algebra']"
671932,"A non-trivial, non-negative, function bounded below by its derivative with $f(0)=0$?","I did not know what to search to see if this existed elsewhere. But, I could not find it. Here's the question: Does there exist a continuously differentiable function, $f: [0,1] \rightarrow [0, \infty)$ , such that the following hold? (i) $f(0) = 0$ (ii) $f'(x) \le c f(x)$ for all $x$ ( $c$ is a fixed constant) (iii) $f \not\equiv 0$ This was a fun problem someone asked me a long time ago. I have always been convinced there is no such function, but I cannot prove it. I have mainly tried using the mean value theorem (in multiple forms), and re-wording the problem in terms of the integral of a continuous function to no avail. I spent some time trying to use (ii), the definition of derivative, and squeeze theorem, but no luck. After much time trying to prove non-existence, I spent a little time trying to find such a function... also with no luck. This problems ability to avoid being solved has since taken away the original fun and replaced it with a twinge of annoyance.","['functions', 'recreational-mathematics', 'real-analysis']"
671945,Second Order Derivative of a function $f:R^2\to R^2$,"The Exercise: My Work: Part 1: $$
Df=\left( \begin{array}{ccc}
D_1f_1 & D_2f_1\\
D_1f_2 & D_2f_2 \\\end{array} \right)
$$ $$f_1(x,y)=\sin x+\sin y$$ $$f_2(x,y)=\cos x+\cos y$$ $$
Df(x,y)=\left( \begin{array}{ccc}
\cos x & \cos y\\
-\sin x & -\sin y \\\end{array} \right)
$$ Part 2: I don't know how to do part 2. How do I find the partial derivatives of the components of $Df(x,y)$ ? Edit: (Attempted solution, per user127645's answer) $$D^{k+1}f = \begin{pmatrix} D_1(D^kf) & \bigg| & D_2(D^kf)\end{pmatrix}$$ $$D_1(D^1f)(x,y)=D_1\left( \begin{array}{ccc}
\cos x & \cos y\\
-\sin x & -\sin y \\\end{array} \right) = \left( \begin{array}{ccc}
-\sin x & 0\\
-\cos x & 0 \\\end{array} \right) $$ $$D_2(D^1f)(x,y)=D_2\left( \begin{array}{ccc}
\cos x & \cos y\\
-\sin x & -\sin y \\\end{array} \right) = \left( \begin{array}{ccc}
0 & -\sin y\\
0 & -\cos y \\\end{array} \right) $$ $$D^2f(x,y)= \left( \begin{array}{ccc}
-\sin x & 0 & 0 & -\sin y\\
-\cos x & 0 & 0 & -\cos y \\\end{array} \right)$$","['matrices', 'partial-derivative', 'ordinary-differential-equations', 'multivariable-calculus']"
671947,Radius of Convergence of $\sum\ z^{n!}$ [duplicate],"This question already has answers here : What is the radius of convergence of $\sum z^{n!}$? (2 answers) Closed 3 years ago . Does anyone know how to find the radius of convergence of the series $\sum\ z^{n!}$ , where $z$ is a complex number? I tried to use the definition: $$\frac{1}{R}=\limsup\left|\frac{a_{n+1}}{a_{n}}\right|$$ but I wasn't successful.","['power-series', 'sequences-and-series', 'real-analysis', 'analysis', 'complex-analysis']"
671980,Moment Matrix Positive Semidefinite,"Let $\phi(x)$ be a probability distribution on$[0,1]$, and consider the moment matrix $M$ where the $(i,j)^{th}$ entry is
$$
M_{ij} := \int_0^1 x^{i+j}\phi(x)dx,
$$
or in other words, the expectation $\mathbb E(x^{i+j})$. Is there an easy way to see that this matrix is positive semidefinite? The matrix is definitely symmetric, and
$$z^T Mz =
\begin{bmatrix}
\sum_{i=1}^n M_{i1}z_i
&
\cdots
&
\sum_{i=1}^nM_{in}z_i
\end{bmatrix}
\begin{bmatrix}
z_1\\\vdots\\z_n
\end{bmatrix}
$$
$$=
\left(
\sum_{i=1}^nM_{i1}z_i
\right)
z_1
+
\cdots
+
\left(
\sum_{i=1}^nM_{in}z_i
\right)
z_n
$$
$$=
\left(
\sum_{i=1}^n\mathbb E(x^{i+1})z_i
\right)
z_1
+
\cdots
+
\left(
\sum_{i=1}^n\mathbb E(x^{i+n})z_i
\right)
z_n$$
I got stuck here aiming to prove it via the definition. Or perhaps there is an eigenvalue approach?","['matrices', 'linear-algebra', 'probability']"
671990,Lower bound for the maximum modulus of a complex polynomial on the unit disc,"This question might be obvious, but it's been stumping me for the moment. Let $p(z)=\sum^n_{k=0} a_kz^k$ be a complex polynomial. Is it true that $$\max_{k\in\{0,\ldots,n\}}|a_k| \leq \max_{|z|=1}|p(z)|?$$
I'm guessing that it's true, but I can't find a satisfactory proof. I would appreciate it if someone could explain why it's true, or if it is not, provide a counterexample.",['complex-analysis']
672000,The set of subsequential limits is closed,So I understand how to find subsequential limits of a sequence but why does the set of subsequential limits have to be closed? A line in my textbook briefly goes over this but doesn't really explain why. Any clarification? Thanks.,"['general-topology', 'real-analysis']"
672011,"If a smooth map between manifolds is injective, is the induced map on the tangent spaces injective too?","If $\phi:M\longrightarrow N$ is an injective smooth map between two manifolds, then is $d\phi_m:M_m\longrightarrow N_{\phi(m)}$, the induced map between the tangent spaces injective too? I tried the following : If $v\in M_m$ is such that $d\phi_m(v)=0$, then for all $g$, $C^{\infty}$ function in a neighbourhood of $\phi(m)$, $d\phi_m(v)(g)=0$, that is $v(g\circ\phi)=0$ for all such $g$. From this can we conclude that $v$ is the $0$ tangent vector. I got this doubt when I was trying to understand the definition of an immersion. I was wondering if $\phi$ being injective will automatically make it an immersion.","['manifolds', 'differential-geometry']"
672050,"What does $[0,1]/\{1, \frac 12, \frac 13, ... 0\}$ look like?","What does $[0,1]/\{\frac 1n : n \in \mathbb N \cup \infty\}$ look like - where the quotient operation is the quotient topology after identifying the latter set with a point? I'm mostly curious if this space can be visualized. Any open set in $[0,1]$ that doesn't contain one of $\{\frac 1n : n \in \mathbb N \cup \infty\}$ is unchanged by the quotient operation - but any open set that contains one of these points then contains all of them, and in fact contains every point in the interval close enough to $0$. My naive guess is that this space is homeomorphic to the Hawaiian earring - each $[\frac 1{n+1}, \frac 1n]$ becomes identified with a circle, and these become ""increasingly smaller"" as $n$ decreases (this is topologically nonsense, but I'm not sure how to word it in a way that's not, if this is even possible). Am I right in my guess? If so, how would I go about proving the existence of a homeomorphism?","['general-topology', 'quotient-spaces']"
672051,How to determine measure from the integral equation?,"Let $\{c_{n}\}_{n\in \mathbb Z}\subset \mathbb C$  and $\sum_{n\in \mathbb Z} |c_{n}| < \infty$ (that is, the series $\sum c_{n}$ is absolutely  converges); we define $F:\mathbb R \to \mathbb C$ such that  $F(y)= \sum_{n\in \mathbb Z}( c_{n}\cdot e^{iny})$, $(y\in \mathbb R).$ Suppose there exists bounded complex Borel measure on $\mathbb R$ such that
$$F(y)= \int_{\mathbb R} e^{-iyx} d\mu(x);  \  (y\in \mathbb R).$$ My Questions : (1) What can we say about $\mu$ ? 
  (2) Can we expect to determine $\mu$  just from the above information; or we need to have some more information to determine $\mu$ ?  Can you suggests some method to determine $\mu$ in such a situation ? Thanks,","['fourier-analysis', 'measure-theory', 'harmonic-analysis', 'analysis', 'functional-analysis']"
672055,How to find this limit using integration?,"What is the value of $$\lim_{n \to \infty}\frac{(\sum_{k=1}^{n} k^2 )*(\sum_{k=1}^{n} k^3 )}{(\sum_{k=1}^{n} k^6)}$$
I just know that it has to be done by converting it into an integral. I have no idea how to do it. Any other solution is also welcome.","['definite-integrals', 'sequences-and-series', 'integration', 'limits']"
672056,"For a well orderable, infinite cardinal number $\kappa$, $\kappa + 1 =_c \kappa$.","Here is my attempt at the proof: Clearly $\kappa \leq_c \kappa + 1$. It suffices to show that $\kappa + 1 \leq_c \kappa$. By definition, $$\kappa + 1 := \kappa \uplus \{0\} := (\{\flat\} \times \kappa) \cup (\{\flat\flat\} \times \ \{0\}).$$ Where $\flat = \emptyset$ and $\flat\flat = \{\emptyset\}$. Define $\varphi: \kappa +1 \rightarrow \kappa$ by $$
\varphi(a,b) = \left\{
        \begin{array}{ll}
            0 & \quad (a,b) = (\flat\flat,0) \\
            \omega_0 & \quad (a,b) = (\flat,0) \\
            \omega_{i+1} & \quad (a,b) = (\flat,\omega_i) \\
            \omega & \quad (a,b) = (\flat,\omega_N) \\
            S(x) & \quad (a,b) = (\flat,x)
        \end{array}
    \right.
.$$ Where 1) $0$ is the minimal element in $\kappa$, 2) $\omega_i$ is the $i$th limit point in $\kappa$, 3) $\omega$ is the ""last"" general point in $\kappa$ ( $\forall x \in \kappa$ $\omega < S(x)$ ), 4) $\omega_N$ is the ""last"" limit point in $\kappa$ ($N \in \mathbb{N}$), 5) $x$ is neither a limit point nor the minimal element $0$. $\varphi$ is well defined as $\kappa$ is well ordered. By inspection, $\varphi$ is injective and hence, by definition, $\kappa + 1 \leq_c \kappa$. Apply Shr$\ddot{o}$der-Bernstien. This completes the proof $\Diamond$? (Essentially, I attempted to ""shift"" $\kappa$ and started at a new point, but as $\kappa$ is infinite, there is no effect. I suppose I tried to formalize the ""Infinite Hotel"" argument.)",['elementary-set-theory']
672063,What is the probability to win? Die game [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question You have a die. If you get one pip at any point in the game you lose. If you get two,..., six pips you start adding the number of pips to a sum. To win the sum must get greater or equal to 100. What is the probability to win the game?",['probability']
672092,Can we use a sum of residues to develop an asymptotic expansion for this unknown function?,"In the course of solving a particular physical problem, I have derived a relationship between two unknown functions:
$$ f(s) = \frac{s \sinh{\frac{\pi s}{2}}}{2 \pi i \beta} \int_{-c- i \infty}^{-c+i\infty} X(\nu) \ \Big(\frac{2}{\beta a}\Big)^\nu \ \Gamma\Big(\frac{1}{2}(\nu + i s)\Big) \Gamma\Big(\frac{1}{2}(\nu - i s)\Big) \ d\nu$$
The two functions $f(s)$ and $X(\nu)$ are unknown and $1>c>0$ specifies the vertical line along which we integrate . The two parameters $\beta$ and $a$ can be tuned such that their non-dimensional combination is either very large or very small. I am hoping to use this large/small parameter to develop some asymptotic expansion using a sum of residues. Simply getting an algebraic relationship in certain limits between the two functions could be helpful. Although $X(\nu)$ is unknown, I do know a number of results about its structure in the complex plane: 1) It decreases exponentially along vertical lines as you move away form the real axis 2) $X(\nu)$ is meromorphic in the whole complex plane with simple poles at (and only at) $\nu = u_p +n$ where $n,p \in \mathbb{N}$ and the $u_p$ satisfy $u_p \sin{\frac{\pi u_p}{2}} + 1=0, Re(u_p)\ge0$ 3) $X(\nu)$ decreases factorially in the positive real direction along horizontal lines and increases factorially in the negative real direction. My intuition says that we can close the given integration contour and then argue either from point 1) or from the small/largeness of $\beta a$ that the closure of the contour has a vanishingly small contribution (depending on exactly how we close; I have been using box contours). The results I am getting though are not consistent with previous numerical and approximate results I have obtained, which I am very confident in. The fact that the gamma functions and $X(\nu)$ can have poles that coincide has me stumped. This occurs because almost all of the $u_p$ are purely real, but $u_0$ is purely imaginary and so if $ s = -i u_0$ the gamma functions and $X(\nu)$ have overlapping poles. How can I systematically approximate this integral as a sum over the residues, given the information provided above?","['residue-calculus', 'approximation', 'complex-analysis']"
672111,Why are the rational numbers not continuous?,"I am trying to understand why the rational numbers are not continuous. Given two rational numbers $a$ and $b$, I can always find a number $c = \frac{a+b}{2}$ between these two numbers. So when I plot the rational numbers as a line, this is a steady line (unlike natural numbers, which are obviously not continuous). Why are they not continuous?","['real-analysis', 'rational-numbers']"
672146,How to make a parabola in GeoGebra?,"I need to make a parabola in GeoGebra. ""Smallest"" one is going to contain 3 points, while the ""biggest"" one is going to be defined by 9 points. So if anyone could explain to me how to make a parabola (from 3, 5, 7, 9... points)? I tried to make parabola by using segments (and combining them), but that just seems too daunting and I don't get the curves. Thanks in advance!","['geometry', 'math-software']"
672159,How to draw this particular rectangle?,"how can one draw the line $d$ into the rectangle $ABCD$ with only compassses and a ruler when $AY=XY=CX$ ($X$ is the intersection of $AB$ and $d$, $  Y$ is the intersection of $CD $ and $d$) BTW: the ruler can't measure anything. Here is the figure when drawn:",['geometry']
672191,Erdős's exercise.,"I have tried to solve an exercise I saw in ""Topics in the theory of numbers"" (Erdős & Suranyi) many times but failed every time I tried. Here it is: Prove that if $a_1,a_2,\cdots$ is an infinite sequence whose elements are either $1$ or $-1$, then for every positive $K$, there exist numbers $b,c,d$ for which $$\left |\sum\limits_{i=k}^d a_{ib+c}\right|>K$$ But I read today that a very similar problem is open. Look at this abstract. So, Erdős  suggested as an exercise an open problem?
Or if not can anybody give me a proof of the above statement? Thanks in advance.","['number-theory', 'combinatorics']"
672197,Why is studying maximal subgroups useful?,"When looking at finite group theory research, it seems to me that a lot of energy is devoted to determining the maximal subgroups of certain classes of groups. For example, the O'Nan Scott theorem gives a classification of the maximal subgroups of $S_n$. There is an entire book ( link ) devoted to studying the maximal subgroups of simple classical groups. I'm pretty sure there are many other examples. Question: How does understanding the maximal subgroups of a group help us in understanding the structure of the group? Why should we care about maximal subgroups? This question is of course a bit vague. What I'm looking for is motivation and examples of applications. For example, I can see how the classification of finite simple groups (CFSG) is useful and interesting in group theory: every group is made up of simple groups (Jordan-Hölder), and CFSG is a very powerful tool for proving things. Many theorems have been proven with the following strategy: Step 1: Prove that a minimal counterexample is a finite simple group. Step 2: Check the theorem for each family of finite simple groups. So the importance of CFSG is clear. What I don't understand currently is why a group theorist would care about maximal subgroups or classifying them.","['finite-groups', 'group-theory', 'abstract-algebra']"
672212,How to prove that Fibonacci number is integer? [duplicate],"This question already has answers here : The number $\frac{1}{\sqrt{5}}\left[\left(\frac{1+\sqrt{5}}{2}\right)^{n}-\left(\frac{1-\sqrt{5}}{2}\right)^n\right]$ is always an integer (2 answers) Closed 7 years ago . How to prove that formula for Fibonacci numbers are always integers, for all $n$: $$
F_n = \frac{\varphi^n - \psi^n}{\sqrt{5}}
$$
where, $\varphi = \frac{1 + \sqrt{5}}{2}$ and $\psi = \frac{1 - \sqrt{5}}{2}$. I know how to prove that $F_n$ is rational, but what about integer?","['fibonacci-numbers', 'number-theory']"
672216,The series $2+3x+5x^2+7x^3+11x^4+...$,"It occurred to me to ask whether the power series whose coefficients are the primes has non-zero radius of convergence, and if so, what kind of function it produces. Wikipedia has some bounds on the $n$th prime number, and assuming that they're correct, we eventually have (where the $^2$ indicates iteration): $$p_n<n\log n + n\log^2n=n\log (n\log n)$$ Now, we have eventually $n < n\log n < n^2$, the left inequality as $\log n > 1$ and the right because $\log n < n$, and both logs and $n$th roots are increasing, so we conclude: $$\sqrt[n]{\log n} < \sqrt[n]{\log(n\log n)} < \sqrt[n]{\log(n^2)}=\sqrt[n]2\sqrt[n]{\log n}$$ And as $1<\log n<n^2$, we have $\sqrt[n]{\log n}\to 1$ and so $\sqrt[n]{\log(n\log n)}\to 1$. So the series with $n$th coefficient $n\log (n\log n)$ has radius of convergence $1$. Since it's coefficient-wise greater than the series with prime coefficients, the latter has radius of convergence at least $1$. Is this reasoning correct? Did I interpret the upper bound on $p_n$ correctly? (ie. is it exact, like I think it is, or is it just asymptotically true in some sense?) If I'm right, then what's known about the function $f(x)=\sum p_n x^n, x\in \mathbb C$? Otherwise, where did I go wrong, and is the radius of convergence actually non-zero?","['power-series', 'sequences-and-series', 'number-theory', 'prime-numbers', 'complex-analysis']"
672228,"If $f$ is twice differentiable and $f(2^{-n}) = 0 $, for all $n \in \mathbb N$, then $f^\prime(0) = f^{\prime\prime}(0) = 0$.","Let $f : \mathbb R \to \mathbb R$ be a twice differentiable function, such that $f(2^{-n}) = 0$, for all $n \in \mathbb N$ . Show that $$f^\prime(0) = f^{\prime\prime}(0) = 0.$$ My attempt. First, let us show that $f(0) = 0$ . Since $f$ is twice differentiable, it is also continuous. Suppose $f(0) = k$ where $k \ne 0$ . Then there is a $\delta > 0$ such that whenever $x \in (-\delta,\delta)$ , $f(x) \in (k/2,3k/2)$ . But $f(2^{-n}) = 0 $ for all positive integer values of $n$ . Thus we have a contradiction as no $\delta$ works for $f$ to be continuous at $x=0$ . Thus $f(x) = 0$. $f(x)$ is differentiable , thus $f^\prime(x)$ is continuous. Suppose $f^\prime (0) = m$ such that $m\neq0$ , then by continuity of $f^\prime(x)$ there is a $\delta$ such that whenever $x \in (-\delta,\delta)$ , $f^\prime(x) \in (m/2,3m/2)$ . Choose an $N$ such that 
$2^{-N} < \delta$  . Now, $\int_{x=0}^{1/2^N} f^\prime(x) = f(2^{-N}) - f(0) = f(2^{-N})$ (I am confused whether this integral exists or not ,as in if $f^\prime(x)$ is integrable or not in the interval I am using) . Now $\int_{x=0}^{1/2^N} f^\prime(x) > m/2(1/2^N)$ as the integral would be greater than the rectangle formed using a lower bound for the value of $f$ in the interval. Thus  $\int_{x=0}^{2^{-N}} f^\prime(x) > 0$ and thus $f(2^{-N}) > 0$ but this is a contradiction as $f(2^{-N}) = 0$ by the function definition. Thus we have a contradiction and thus, $f^\prime(0)$ can't be non-zero. We can proceed similarly to prove that $f^{\prime\prime}(0) = 0$ . Is my approach correct, is there a better way to prove it ?  I am not sure if my solution is correct as I am not sure of using integrals the way I used it. Thanks.","['calculus', 'continuity', 'real-analysis', 'analysis', 'derivatives']"
672252,Monkey typing ABRACADABRA and gamblers,"Problem: A monkey is sitting at a typewriter, typing a letter (A-Z) independently and with uniform distribution each minute. What is the expected amount of time that passes before ABRACADABRA is spelled? Standard Solution: Suppose that, before every keystroke is made, a gambler enters and wagers $\$1$ on the next keystroke being an A fairly (so that if the keystroke is indeed an A, then the payoff is $\$26$). If the keystroke is an A, the gambler stays and wagers everything (in this case $\$26$) on the next letter being B, and so on. If the gambler ever loses a wager, then it leaves. Now let’s analyze what happens when ABRACADABRA is finally spelled out. The gambler who kept making correct wagers all the way through won $\$ 26^{11}$. But another gambler who got in on the second ABRA won $\$ 26^4$, and a third gambler who got in on the final A got $\$26$. Hence the total payoff is $\$ 26^{11}+\$26^4+\$26$. But all the wagers are fair, and the house gets $\$1$ on every turn from the new gambler, so the expected time before ABRACADABRA is spelled is $26^{11}+26^4+26$. My question:
What if the strategy of the gamblers changes?
In the ""standard solution"" of the problem each gambler first bet on A, then on B, and so on...
If the new gambler looks at the sequence of past letters and wagers $\$1$ on the NEXT USEFUL LETTER, why the game is not fair anymore?
In this case, if the last letters are ""..ABRACA"" the new gambler bets on D instead of A.
In this way the total payoff at the end of the game will be $\$26^{11}+\$26^{10}+...+\$26^2 + \$26$.","['probability-theory', 'martingales', 'game-theory']"
672266,Why does maximum likelihood estimation for uniform distribution give maximum of data?,"I am looking at parameters estimation for the uniform distribution in the context of MLEs.  Now, I know the likelihood function of the Uniform distribution $U(0,\theta)$ which is $1/\theta^n$ cannot be differentiated at $\theta$. The conclusion is that the estimate of $\theta$ is $\max(x_i)$, where $x_1,x_2,\ldots,x_n$ is the random sample. I would like a layman's explanation for this.","['estimation', 'probability', 'random-variables']"
672276,Dense subspace in a Hilbert space,Let $H$ be a Hilbert Space and $\{e_n\}_{n\in\mathbb{N}}$ an orthonormal basis. Now let $(x_n)$ be a sequence in $H$ satisfying $$\sum_{n=1}^{\infty}||x_n-e_n||^2<1.$$ Prove that $\operatorname{lin}\{x_n:n\in\mathbb{N}\}$ is dense in $H$. I don't know even how to start this problem...,"['hilbert-spaces', 'functional-analysis']"
672278,Lindelöf property and $\omega$-covers,"Let $X$ be a Lindelöf topological space. Does this imply that every $\omega$-cover has a countable subcover which is also an $\omega$-cover?
if not, is there an example of a topological Lindelöf space with an $\omega$-cover for which there isn't a countable sub $\omega$-cover? We say that an open cover $\mathcal{U}$ of $X$ is an  $\omega$-cover, if $X \notin \mathcal{U}$ and for any finite set $A \subset X$ there is a $U \in \mathcal{U}$ such that $A \subseteq U$. Thank you!","['general-topology', 'examples-counterexamples']"
672315,Every closed separable subspace is complemented,"Let $X$ be a Banach space. Suppose that every closed separable subspace $Y$ of $X$ is complemented in $X$ (i.e., there is a bounded linear projection of $X$ onto $Y$). Is $X$ necessarilly isomorphic to a Hilbert space? Note: If $X$ is separable, or if every closed subspace $Y$ of $X$ (not necessarilly separable) is complemented in $X$, then the answer is positive, as proved by Lindenstrauss and Tzafriri (1977) (and pointed out by Harald Hanche-Olsen in the comment below).","['functional-analysis', 'banach-spaces']"
672359,A basic question regarding the proof of existence of product measure,"Suppose that $(X,\mathcal F_1,\mu)$ and $(Y,\mathcal F_2,\nu)$ are measure spaces and suppose that $\mu$ and $\nu$ are finite measures. Define the function $\nu_E : X \to \Bbb R$ by $$\nu_E(x) = \nu \big(\{y: (x,y) \in E\}\big),$$ where $E \in \mathcal F_1 \otimes \mathcal F_2$. (Note that it is not a Cartesian product, but the $\sigma-$algebra generated by the measurable rectangles). Define $$L=\{E \in \mathcal F_1 \otimes \mathcal F_2 : \nu_E \text{  is measurable}).$$ I want to prove that $L$ is a $\lambda-$system . I am able to check the first two properties but stuck in checking that it is closed under disjoint union.","['probability-theory', 'measure-theory']"
672383,"If a Laplacian eigenfunction is zero in an open set, is it identically zero?","This seems like it should be easy but I can't seem to figure it out. Suppose $f$ satisfies $\Delta f + \lambda f = 0$ in $\mathbb{R}^n$ (where $\lambda > 0$ is a constant), and in some open set $U$ we have $f = 0$. Does this mean $f = 0$ in $\mathbb{R}^n$? My idea for solving it: Suppose not; WLOG suppose $U$ is a maximal open set ordered by inclusion in which $f = 0$. Let $x \in \partial U$. If $x$ has a neighborhood where $f \le 0$, then $\Delta f \ge 0$ there, so $f$ is subharmonic and by the maximum principle, $f = 0$ in the neighborhood, contradicting the maximality of $U$. If $x$ has a neighborhood where $f \ge 0$ then the same argument applies to $-f$ (or the same argument with ""superharmonic"" and ""minimum principle""). Here is where I'm stuck: How do I rule out a third possibility, where every neighborhood of $x$ contains positive and negative points?","['harmonic-functions', 'partial-differential-equations', 'analysis']"
672392,Are marginal densities always greater than the corresponding joint density?,"I.e. if $\mathbb P\left(x,y\right)$ is a joint density function, and $\mathbb P\left(y\right)$ is a marginal distribution is it always true that: $\mathbb P\left(x,y\right)\leq \mathbb P\left(y\right)$ ? Using the rule for probability of intersections: $\mathbb P\left(\mathbb X = x \cap \mathbb Y= y\right)= \mathbb P\left(\mathbb X=x\right) + \mathbb P\left(\mathbb Y=y\right) - \mathbb P\left(\mathbb X=x \cup \mathbb Y=y\right)$ (for random variables $x,y$ taking values in some sets $\mathbb S\left(\mathbb X\right),\mathbb S\left(\mathbb Y\right)$) Seems to imply this, but I find it surprising. Also, it seems to contradict an inequality from information theory: $\mathbb H\left(\mathbb X,\mathbb Y\right) \geq \mathbb H\left(\mathbb Y\right)$","['probability-theory', 'information-theory']"
672399,"Boundedness of the operator $[\Lambda, \Theta]$.","I am reading Griffiths-Harris book on algebraic geometry and in ""Theorem B"", where he proves (the analogue of Serre's vanishing theorem) that Let $M$ be a compact, complex manifold, $L\rightarrow M$ be a positive line bundle. Then for any holomorphic vector bundle $E$, there exists $\mu_{0}$ such that for all $q>0$ and $\mu\geq\mu_{0}$, $H^{q}(M,\mathcal{O}(L^{\mu}\otimes E))=0$. Here, if we let $\Lambda$ be the dual of the Lefschetz operator, $\Theta_{E}$ be the curvature of $E$, he asserts that $[\Lambda,\Theta_{E}]$ is bounded on $A^{0,*}(L^{-\mu}\otimes E)$. Why is this so? Thanks!","['complex-geometry', 'algebraic-geometry', 'vector-bundles', 'differential-geometry']"
672435,Prove that the set of lines in the plane is equal in cardinality to $\mathbb{R}$,"My attempt: I begin by trying to find a bijection between $\mathbb{R}^2$ and $\gamma=\{$the set of lines in the plane$\}$. I think the set $\mathbb A = \{ \{(a,-b),(-c,d) \} | \forall a,b,c,d \in \mathbb{R} \}$ would give me all of $\mathbb{R}^2$. I also know that every $x \in \gamma$ is defined by a slope and point. Then there would exists $f$: $\mathbb A \to \gamma$ such that $$f(\mathbb A)=\left ( \dfrac{-b-d}{a+c},(a,-b) \right )$$ The order of the slope and the point obviously do not matter. I am just trying to show that $f$ maps to a point, and slope which uniquely determines each $x \in \gamma$. If this is correct then $\gamma \equiv_c \mathbb{R}^2 \equiv_c \mathbb{R}$ I see that there are easier ways but is there anything strikingly incorrect about my attempt?",['elementary-set-theory']
672436,Degree of polynomial seen as a smooth map,"I need some help with a part of an exercise. Let $P$ be a real polynomial of degree $d$, seen as a map $P:\mathbb{R}\rightarrow\mathbb{R}$. Prove that if $d$ is even then the degree of $P$, $degP$, seen as a smooth map is zero and if $d$ is odd, then $degP=\pm1$. I thought to use the fact that $degP=\sum_{x\in P^{-1}(y)}\epsilon(x)$, where $y\in Reg(P)$ and $\epsilon(x)$ is $\pm 1$ if $P$ preserves resp. reverses the orientation in a neighbourhood of $x$. Then, if $d$ is even, $P$ is not surjective, so $degP=0$. If $d$ is odd, then I choose $y\in Reg(P)$, and I know that, if $x\in P^{-1}(y)$, $P'(x)$ is not $0$ and so it is positive or negative if $P$ preserves or reverses the orientation. Intuitively, I can see that the statement is true, but I can't prove it properly.","['manifolds', 'algebraic-geometry', 'differential-geometry']"
672507,"What is the interior of [0,1)?","I think it would be (0,1). I just need to check if my explanation makes sense. 1 is not an interior point as it doesn't belong to the set. 0 is not an interior point as the left neighborhood of 0 is not part of the set as it is a closed interval.","['general-topology', 'real-analysis']"
672518,Volume above cone and below paraboloid.,"I need to find the volume above the cone $z=\sqrt{x^2+y^2}$ and below the paraboloid $z=2-x^2-y^2$. I thought about using spherical coordinates and finding $p$, which would be (before simplification) : $$-z=-2+x^2+y^2$$
$$-p \cos(\theta) =-2+p^2 \sin^2 (\theta) \cos^2(\theta)+p^2 \sin^2(\theta) \sin^2(\theta)$$ But I can't seem to be able to isolate $p$ even knowing that $\sin^2(\theta)+\cos^2(\theta)=1$. Any hint would be greatly appreciated! Thanks.","['multivariable-calculus', 'calculus']"
672526,Proving an integral using a series,"If $f:(0,1]\rightarrow \textbf {R}$ is defined by $f(x)=2nx$ for $\frac{1}{n+1}\leq x \leq \frac 1n$ and $n$ is a natural number, assuming that $\sum_{k=1}^{k=\infty}1/k^2=\pi^2/6$,  show that $\int_0^1 f(x)dx=\pi^2/6$. So I wrote the summation of the integral from $x=\frac{1}{n+1}$ to $x=\frac{1}{n}$ of $f(x)dx$. After I integrate I'm left with the infinite series of $\frac{1}{k}-\frac{k}{(k+1)^2}$ from $k=1$ to $k=\infty$? Not sure where to go from here.","['sequences-and-series', 'integration', 'real-analysis', 'analysis']"
672570,The Fano's plane and its homogenous coordinates,"We let $k=\mathbb{Z}_{2}$. Is the assignment of the homogeneous coordinates $(0:0:1)$, $(0:1:0)$,  $(1:0:0)$ to the main equilateral triangle of the Fano plane arbitrary? Could we for example start with the base of the triangle and ''name'' the vertex $(0:0:1)$ as $(1:0:0)$ instead? I know how to obtain the point between the ones that are the vertices of the triangle, but I am affraid I don't get the general idea. What point in the Cartesian system represents the point given in homogeneous coordinates? $(0:0:1)$? Thanks",['algebraic-geometry']
672575,Proof for the formula of sum of arcsine functions $ \arcsin x + \arcsin y $,"It is known that \begin{align}
\arcsin x + \arcsin y  =\begin{cases}
\arcsin( x\sqrt{1-y^2} + y\sqrt{1-x^2}) \\\quad\text{if } x^2+y^2 \le 1 &\text{or} &(x^2+y^2 > 1 &\text{and} &xy< 0);\\
\pi - \arcsin( x\sqrt{1-y^2} + y\sqrt{1-x^2}) \\\quad\text{if } x^2+y^2 > 1&\text{and} &0< x,y \le 1;\\
-\pi - \arcsin( x\sqrt{1-y^2} + y\sqrt{1-x^2}) \\\quad\text{if } x^2+y^2 > 1&\text{and} &-1\le x,y < 0.
\end{cases}
\end{align} I tried to prove this myself, have no problem in getting the 'crux' $\arcsin( x\sqrt{1-y^2} + y\sqrt{1-x^2})$ part of the RHS, but face trouble in checking the range of that 'crux' under the given conditions.",['trigonometry']
672610,Derivative of remainder function.,"I cannot find a derivative of remainder function (i.e. derivative of a(x) mod b(x) with respect to x , and x is a real number and a() , b() is also real-valued functions) in tables of derivatives. Without the loss of generality, we may assume (and it desired at all), that continuous approximation is acceptable. I note, that (a(x) mod const)' ~ a'(x) , (c(x) mod c(x))' = 0 , but still I can't conclude form of desired right hand side (a(x) mod b(x))' -> ? function from these borderline cases (maybe dimensional method or method of indefinite coefficients in some form is applicable, but I have not an intuitions of how). What is the generalized (in sense of continuity) form of remainder derivative? I mean a remainder function as presented on x86/x86-64 architectures ( FPREM and FPREM1 ).",['derivatives']
672612,$\frac{\mathrm{d}}{\mathrm{d}x}$ Notation Explanation please?,"I know how to derive, I know how to integrate. I know what to do when I see $\frac{\mathrm{d}}{\mathrm{d}x}$ and such but what does it really mean? I know it means something like derive in terms of $x$ , but whats the difference between $\frac{\mathrm{d}y}{\mathrm{d}x}$ and $\frac{\mathrm{d}}{\mathrm{d}x}$ ? If someone could give me an explanation in layman's terms that would be very helpful as this has always perplexed me. Basically, what's that $\mathrm{d}$ mean?",['calculus']
672619,Vector Delta Function Identity,"I'm trying to prove the the vector extension of the identity 
\begin{equation} 
1 = \int \left|\sum_i\frac{ \partial  g  }{ \partial a }\big| _{a =a _i} \right| \delta ( g ( a ) ) da
\end{equation} 
where the sum is over all the zeros of $g$. The vector extension is:
\begin{equation} 
1 = \left( \prod _{i =  1 } ^n  \int d a _i \right) \delta ^{ ( n ) } \left( {\mathbf{g}} ( {\mathbf{a}} )  \right) \det \left( \frac{ \partial g _i }{ \partial a _j } \right) 
\end{equation}
where ${\mathbf{g}}$ and $ {\mathbf{a}} $ are $n$ dimensional vectors. This identity is used in Quantum Field Theory by Peskin and Schroeder (pg. 295). I'm a physics graduate student and I don't know much formal mathematics.  Any help on how to prove this would be greatly appreciated.","['multivariable-calculus', 'dirac-delta', 'special-functions', 'integration']"
672635,Trying to solve an odd equation minimum.,"Here is a math puzzle I've been working on - The set-up - I am a dog, 50 feet from the water. A rubber duck is in the water 50 feet from shore and 140 feet to my right. This makes a triangle base of 140 ft, height 100 ft. I can run 30fps on land, 4fps in water. What is the fastest I can get to the duck? Given the only real choice is to vary the point he hits the water, I have the image showing that point, and how it produces two right triangles. So we have this equation to minimize. $y=\frac{\sqrt{\left(2500+x^2\right)}}{30}+\frac{\sqrt{\left(2500+\left(140-x\right)^2\right)}}{4}$ Graphing this produces the conclusion that at X= 133.71, Y= 17.357. I got this far, but manipulating to get rid of radicals sent me down a rabbit hole. Disclosure, a high school junior came to me with this problem. If the solution requires calculus, I'd love to see the method, but the students that had this problem were not that advanced. (I'd welcome a better title for this problem)",['algebra-precalculus']
672646,"A die is thrown five times, what is the probability that you get 20 as the sum of the values","This is supposed to be a Inclusion-Exclusion problem. We have $6^5=7776$ different results. Now, with the Inclusion-Exclusion principle i resolve the number of solutions for the equation: $d_1+d_2+d_3+d_4+d_5=20  , 1 \leq d_i \leq 6 ,\forall 1 \leq i \leq 5$ That, i think, is equivalent to resolve: $d_1+d_2+d_3+d_4+d_5=15  , 0 \leq d_i \leq 5 ,\forall 1 \leq i \leq 5$ This is: $\binom{19}{15}-\binom{5}{1} \binom{13}{9}+\binom{5}{2} \binom{7}{3}=651$ So mi answer is: $\frac{651}{7776}$. However, the ""correct answer"" is: $\frac{116}{7776}$. Whats the problem with mi reasoning? EDIT I found the solutions for my problem in the book, the result is: $\frac{651}{7776}$. I was right, but the solution from mi teacher was wrong. Thats why the confusion.","['inclusion-exclusion', 'discrete-mathematics', 'combinatorics']"
672665,Are there real algebras that don't have rational structure constants?,"Take a finite dimensional associative algebra $A$ over the reals. Fix a basis $\{x_1, x_2, \ldots x_n\}$. The multiplication is completely specified by specifying structure constants $c^{ij}_k$ defined by the following equation:
$$x_i \cdot x_j = \sum_k c^{ij}_k x_k \quad\forall i, j$$
Of course, the structure constants depend on the choice of basis. My question is:
Are there algebras such that no choice of basis leads to structure constants that are all rational? My conjectured example would be the algebra spanned by two variables $a$ and $b$, and relations $a^2 = a, ab = ba = b, b^2 = \sqrt{2}a$, but I couldn't prove it yet. Note: One could also ask ""integer"" instead of ""rational"", this is equivalent.",['abstract-algebra']
672693,Integral asymptotic expansion of $\int_0^{\pi/2} \exp(-xt^3\cos t)dt$ as $x \to \infty$,"I have the integral
$$I(x)=\int_0^{\pi/2}\exp(-xt^3\cos t)dt$$
and I want to derive the first two terms in the asymptotic expansion for $x\rightarrow \infty$, which should give me
$$\frac{1}{3x^{1/3}}\Gamma(1/3)+\left(\frac{1}{6}+\frac{8}{\pi^3} \right)\frac{1}{x}+\dots$$ Using the Laplace Method as stated here ,
I get only one term so my idea was to use partial integration, which gives me $$\pi/2-\int_0^{\pi/2} \left[ \exp(-xt^3\cos t)\,\, t\,\,(xt^3\sin(t)-3xt^2\cos(t)) \right] dt$$","['asymptotics', 'integration', 'laplace-method']"
672710,How can I check the convergence of the sequence? Does it diverge?,"How can I check the convergence of the sequence $\frac{1}{\sqrt{n^2+1}}+\frac{2}{\sqrt{n^2+2}}+\cdots+\frac{n}{\sqrt{n^2+n}}$? I think that it diverges,because it is bounded below from $\frac{n(n+1)}{2\sqrt{n^2+n}} $ and above from $\frac{n(n+1)}{2\sqrt{n^2+1}}$..Is this correct?","['calculus', 'analysis']"
