question_id,title,body,tags
1281761,Derivative of a polar coordinate equation,"I was trying to plot the polar curve: $r=\cos(2n\theta)$ ($0\leq\theta\leq 2\pi$) and tried differentiating with respect to $\theta$ to get some information about where the petals would be. My reasoning was along the lines of: since when $\frac{\text{d}y}{\text{d}x}=0$ the function is flat, or the change in $y$ is becoming zero; so surely when $\frac{\text{d}r}{\text{d}\theta}=0$ the change is $r$ is becoming zero (around the particular $\theta$ that makes $r'(\theta)=0$), or it would be similar to a circle of suitable radius (since if $r(\theta)=c$ then $r'(\theta)=0\; \forall \theta$ so $r$ doesn't change with respect to $\theta$). Now this seems to work for the equation $r(\theta)=\cos(2n\theta)$ since we would get: $$ r'(\theta)=-2n\sin(2n\theta) \text{ which is zero when } 2n\theta=k\pi \rightarrow \theta=\frac{k\pi}{2n}$$
so that would imply that for $\cos(2n\theta)$ there would be $4n$ petals, which seems to agree with what actually happens. The issue came when trying to apply the same logic to $r(\theta)=\cos(3\theta)$ since we would get that the petals should be at:
$$ 3\theta=n\pi \rightarrow \theta=\frac{n\pi}{3} $$
which means that there would be 6 petals, which isn't true. So I'm wondering where the problem is in my reasoning, the whole thing was more of a guess that anything else, but I'm curious about why it doesn't work.","['polar-coordinates', 'algebra-precalculus', 'derivatives']"
1281770,Prove ten objects can be divided into two groups that balances each other when placed on the two pans of balance. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question There are 10 objects with total weight 20, each of the weight being a positive integer. Given that none of the weights exceed 10, prove ten objects can be divided into two groups that balances each other when placed on the two pans of balance. Hints are appreciated. Sorry I do not know how to start this problem, so I have not shown any efforts.","['combinatorics', 'proof-writing']"
1281780,Right-continuous process is measurable with respect to product measure.,"Let $(\Omega,\mathcal{F},P)$ be a probability space and $\{X_t\}_{t\geq0}$ be a collection of real random variables such that the map $t\mapsto X_t$ is right-continuous. Show that the map $(t,\omega)\mapsto X_t(\omega)$ is measurable with respect to the product measure $\mathcal{B}(\mathbb{R_+})\otimes\mathcal{F}$. There a standard argument which I will outline below but I do not understand it all so will hope some one can fill in the gaps for me. Firstly define for $t\geq0$ and $k\in\{0,1,...,n2^n-1\}$, $X^{(n)}_t(\omega):=X_{(k+1)/2^n}(\omega)$,  for $\frac{k}{2^n}<t\leq\frac{k+1}{2^n}$. Now it is claimed that $X_t^{(n)}$ is $\mathcal{B}(\mathbb{R}_+)\otimes\mathcal{F}$-measurable, but I am not sure why? And this  my 1st question.  Now we know that $X_{(k+1)/2^n}$ is $\mathcal{F}$-measurable, and that I think we can write $X^{(n)}_t(\omega):=\sum\limits_{k=0}^{n2_n}1_{\frac{k}{2^n}<t\leq\frac{k+1}{2^n}\}}{X_{(k+1)/2^n}}(\omega)$ but am not sure why this is measurable w.r.t. the product $\sigma$-algebra, so would appreciate if anyone could fill in the gaps. Secondly I can see that for a fixed $\omega$, $\lim\limits_{n\rightarrow\infty}X^{(n)}_t=X_t$a.s. in $\Omega$, but then not sure how this implies that the map converges in the product space as $\omega$ won't be fixed or am just confusing matters? And the right continuity comes to play as we have a decreasing sequence, is that correct?  So any help to clear up this matter is greatly needed. Thirdly I was wondering if using the limiting sequence of $X_{(\lfloor nt\rfloor+1)/n}$ would work better but still have the same measurability questions as before. Also I can see that $(\lfloor nt\rfloor+1)/n\rightarrow t$ but am a bit stuck showing it is a decreasing sequence. Also for the converse of this result, i.e. every process that is measurable to the product $\sigma$-algebra has a right continuous modification, is it true and where can I find a reference for it? I am also looking for a reference for the result, that any processes that is product measurable and adapted to a filtration on the space has a progressively-measurable modification. 
So any help with any of these queries is greatly needed and appreciated. Thanks in advance.","['probability-theory', 'stochastic-analysis']"
1281785,What is the value of $i^0$?,"I have to solve the following question - $$\sum_{n=0}^{1000} i^n$$ where $i = \sqrt{-1}$ To be able to solve the problem, I need to know the value of $i^0$. What is the value of $i^0$? Is it 0 or indeterminate or something else?","['complex-numbers', 'algebra-precalculus']"
1281790,How to find the limit of this seq.?,"Please help me to solve this limit: $$
\lim _{n\to \infty }\left(\frac{1}{n^2}\sqrt[n^2]{e}+\frac{2}{n^2}\sqrt[n^2]{e^4}+\frac{3}{n^2}\sqrt[n^2]{e^9}+...+\frac{n}{n^2}\sqrt[n^2]{e^{n^2}}\right)
$$ Thank you",['limits']
1281819,Infinity - infinity calculus,$$\lim_{x\to\infty} (x-1)e^{-1/x}-x$$ I know that this limit equals $-2$ but I don't know how to prove it. I can only get to $\infty-\infty=?$,"['infinity', 'calculus', 'limits']"
1281848,"If a Subset Admits a Smooth Structure Which Makes it into a Submanifold, Then it is a Unique One.","$$
\newcommand{\wh}{\widehat}
\newcommand{\R}{\mathbf R}
\newcommand{\mr}{\mathscr}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\inclusion}{\hookrightarrow}
\newcommand{\vp}{\varphi}
$$ I am trying to understand the following theorem: Theorem. Let $M$ be a smooth manifold and $S$ be a subset of $M$.
  There is a unique smooth structure on $S$, if one exists, which makes it into a smooth manifold such that $i:S\inclusion M$ is a smooth embedding. The only way I could prove this is via the lemma proved below whose proof is very long.
I think the proof of the above theorem should be fairly straightforward and clear and should not require to do what I have done. Does somebody have a short proof? Lemma. Let $S$ be a $k$-dimensional embedded submanifold of a smooth manifold $M$.
  Then for each $p\in S$, there exist a smooth charts $(U_p, \vp_p)$ and $(V_p, \psi_p)$ about $p$ on $S$ and $M$ respectively such that $U_p=V_p\cap S$, and $\psi_p\circ\vp_p^{-1}:\wh U_p\to \wh V_p$ (the `hat' denotes the image of the open set under the corresponding chart)
  \begin{equation*}
\psi_p\circ\vp_p^{-1}(x_1 , \ldots, x_k)
=
(x_1 , \ldots, x_k, 0 , \ldots, 0)
\end{equation*}
  for all $(x_1 , \ldots, x_k)\in \wh U_p$.
  Therefore $\vp_p=(\pi\circ \psi_p\circ i)|_{V_p\cap S}$, where $\pi:\R^n\to \R^k$ is the projection on the first $k$ coordinates, and the collection of smooth charts $\mr U=\set{V_p\cap S,\ (\pi\circ \psi_p\circ i)|_{V_p\cap S}}_{p\in S}$ is a smooth atlas on $S$. Proof: Since $i:S\inclusion M$ is an immersion (it's more than that), by the Constant Rank Theorem, we know that there exists a smooth chart $(U,\vp)$ on $S$ containing the point $p$, and a smooth chart $(V,\psi)$ on $M$, again containing $p$, such that $U\subseteq V$ and $\psi\circ\vp^{-1}(x_1,\ldots,x_k)=(x_1,\ldots,x_k,0,\ldots,0)$ for all $(x_1,\ldots,x_k)\in \wh U$.
Since $i:S\inclusion M$ is in particular a topological embedding, we know that $U$ is open in $M$ and thus we may WLOG assume that $U=V\cap S$. We now show that $\vp=(\pi\circ \psi\circ i)|_{V\cap S}$.
For take $q\in V\cap S$, and say $\vp(q)=(x_1 , \ldots, x_k)$.
Now we have $\psi\circ \vp^{-1}(x_1 , \ldots, x_k)=(x_1, , \ldots, x_k, 0 , \ldots, 0)$, giving $(\pi\circ \psi\circ i)(q)=(x_1 , \ldots, x_k)$. So we have shown that for each $p\in S$, there exist a smooth charts $(U_p, \vp_p)$ and $(V_p, \psi_p)$ about $p$ on $S$ and $M$ respectively such that $U_p=V_p\cap S$, and $\psi_p\circ\vp_p^{-1}:\wh U_p\to \wh V_p$
\begin{equation*}
\psi_p\circ\vp_p^{-1}(x_1 , \ldots, x_k)
=
(x_1 , \ldots, x_k, 0 , \ldots, 0)
\end{equation*}
for all $(x_1 , \ldots, x_k)\in \wh U_p$.
It remains to show that $\mr U=\set{U_p, \vp_p}_{p\in S}$ is a smooth atlas on $S$.
To see this, consider note that
\begin{equation*}
\vp_q\circ \vp_p^{-1} = \vp_q\circ \psi_p^{-1} \circ \psi_p\circ \vp_p^{-1}
\end{equation*}
and this map sends $(x_1 , \ldots, x_k)$ to $\pi\circ\psi_q^{-1}\circ\psi_p(x_1 , \ldots, x_k, 0 , \ldots, 0)$ for all $(x_1 , \ldots, x_k)\in \vp_p(U_p\cap U_q)$, and hence is smooth.","['differential-topology', 'differential-geometry', 'smooth-manifolds']"
1281851,What is a branch point?,"I am really struggling with the concept of a ""branch point"". I understand that, for example, if we take the $\log$ function, by going around $2\pi$ we arrive at a different value, so therefore it is a multivalued function. However, surely this argument holds for all points in the complex plane, so I don't really understand how $z=0$ is the ONLY branch point. Additionally, the course I am revising for needs no Riemann surfaces or knowledge of that area of mathematics, just what a branch point is and how to find it. Thanks for any help.","['multivalued-functions', 'branch-points', 'branch-cuts', 'complex-analysis']"
1281855,Holonomy reduction from constant spinors,"Let $(M,g)$ be a $d$-dimensional Riemannian oriented, spin, manifold, and let us denote by $S$ the corresponding spinor bundle. The Levi-Civita connection $\nabla$ on $(M,g)$ lifts to a unique spin connection $\nabla^{S}$ on $S$. Now, suppose there is a no-where vanishing parallel spinor $\epsilon\in\Gamma(S)$ on $M$, namely $\nabla^{S}\epsilon =0$. It is clear then that $Hol(\nabla^{S})\subseteq G$, where $G\subseteq Spin(d)$ is the stabilizer of the spinor under the spin group action. My question is, what is then the holonomy of $\nabla$? Intuitively, it should be $\rho(G)\subseteq SO(d)$, where $\rho\colon Spin(d)\to SO(d)$ is the double covering map, but I do not know how to prove this claim. Thanks.","['lie-groups', 'differential-geometry', 'holonomy']"
1281856,Why is a geometric progression called so? [duplicate],This question already has an answer here : Arithmetic and geometric sequences: where does their name come from? (1 answer) Closed 4 years ago . Just curious about why geometric progression is called so. Is it related to geometry?,"['sequences-and-series', 'terminology', 'geometric-progressions']"
1281883,Prove a result in multiple linear regression,"This arises in multiple linear regression. Given $m, n \in \mathbb{N}$ and matrices $X \in \mathbb{R}^{m \times (n+1)} (m > n + 1), H = X(X'X)^{-1}X' \in \mathbb{R}^{m\times m}, I = I_m$ and $J \in \mathbb{R}^{m\times m}$, a matrix of $1$'s, how does one show that $$J(I-H) = 0\text{ ?}$$ I am actually trying to show $$(I-H)(H-\frac{1}{n}J) = 0$$ which reduces to $J(I-H) = 0$ by noting that $HH =H$. Apparently, this might have something to do with $J(y - X \hat{\beta}) = 0 \ \forall y \in \mathbb{R}^{1\times(m+1)}$ where  $\hat{\beta} = (X'X)^{-1}X'y $? Is the statement true? If so why? If not, why not, and how then to prove $J(I-H) = 0$ or $(I-H)(H-\frac{1}{n}J) = 0$? I think there's some property of MLR needed. On the other hand, the equation $J(I-H) = 0$ itself looks like it is independent of statistics. Must one really use some properties of MLR? What are some possible counterexamples?","['statistics', 'linear-algebra', 'regression']"
1281906,What is the exact definition of an Injective Function,"Am I right to believe that a function is injective, if some elements of the first set are mapped to some elements of the second set? It is also possible to 4 elements of the first set, are mapped to the same element of a second set? Is this correct? A simple answer is much appreciate, already confused enough :) THANK YOU","['definition', 'functions']"
1281908,"Conditional expectation, max, min of random variables","We are given two independent random variables $A, B$ with uniform distribution on $[0,1]$. We define new random variables $X = \max (A,B)$ and $Y = \min (A,B)$. Find $\mathbb{E}(X\mid Y)$ (defined as the one, up to measure zero, random variable which satisfies $\sigma (\mathbb{E}(X\mid Y)) \subset \sigma(Y))$ and $\forall B \in \sigma(Y) : \int_B X \, dP = \int_B \mathbb{E}(X\mid Y) \, dP$). I've done this by finding distribution function of $(X, Y)$ and then joint density function $f_{XY}(x,y)$ and then using the formula $$\mathbb{E}(X\mid Y) = \frac{1}{f_Y(Y)}\int_{\mathbb{R}}x f_{XY}(x,Y) \, dx$$ I wonder if there is a clearer, shorter, less time consuming way of dealing with this problem.","['probability-theory', 'conditional-expectation', 'probability-distributions', 'uniform-distribution', 'probability']"
1281909,"""Perimeter"" of the sine function","Given a sine function with certain parameters (period, amplitude) I would like a function to calculate its ""perimeter"", i.e. the length of the curve itself. Everyday application: let's say we need to line a piece of corrugated iron, of which we have its dimensions, but we would need to know the ""real length"" of it, taking into account its foldings. Thanks in advance,
cl.","['periodic-functions', 'functions']"
1281932,Not complete but minimal sufficient statistic,"Let $X =(X_1,\ldots, X_n), ~ X_i \mathrm{iid} \sim \mathcal N ( \theta, \theta^2), ~ \theta \in \Theta = \mathbb R \setminus \{0\}, ~ T(X)=(\sum_{i=1}^n X_i, \sum_{i=1}^n X_i^2)$. I figured out that $T(X)$ is sufficient. To show that it's not complete I checked the function $g$ with $g(u,v) = 2u^2 - (n+1)v$ and noticed that $E_{\theta}[g(T(X))] = 0 ~ \forall \theta \in \Theta$ - but why is $P_{\theta}(g(T(X)) = 0) < 1$? And how to show that $T(X)$ is minimal sufficient? I know that one can choose a subfamiliy $\mathcal P_0 \subset \mathcal P = \{f_{\theta} \mid \theta \in \Theta \}$ where $P$ is a family of densities with the same support and that's enough to show that $T$ is minimal sufficient for the subfamiliy. And if we have such a subfamily, $T^{*}(X) = \left(\frac{f_{\theta_1}(x)}{f_{\theta_0}(x)}, \ldots, \frac{f_{\theta_k}(x)}{f_{\theta_0}(x)}\right)$ is minimal sufficient (for $\Theta = \{\theta_0, \ldots, \theta_k\}$). But how to apply on the present case?",['statistics']
1281961,Geometry of cubic 3-fold,"I'm having some questions about the geometry of the cubic 3-fold. Every variety is over $\mathbb C$. Take $Y$ a smooth cubic 3-fold in $\mathbb P^4$ and $E$ a curve of degree 6 and genus 1 contained in it. First assume it is smooth. If i study the exact sequence $$0\to I_E(2)\to O_Y(2) \to j_*O_E(2)\to 0$$ I arrive at the conclusion that $H^0(Y,I_E(2))$ has dimension 3, and $E$ is contained in the zero locus of a section of the linear system $O_Y(2)$ that is smooth. I can compute its tangent bundle using the adjunction formula and as it is a complete intersection, I can prove that its $h^{0,1}$ is zero, and therefore it is a smooth K3 surface, let us call it $S$. Now, I'd like to prove that $O_S(E)$ is generated by 2 sections. I belive I can compute the dimension of $H^0(S,O_S(E))$ using Riemann-Roch, but how do I get that the sections actually generate $O_S(E)$. Thanks.","['complex-geometry', 'algebraic-geometry', 'intersection-theory']"
1281964,Probability Generating Function of Compound Poisson Process,"Let $(N_t)_{t\ge 0}$ be a poisson process with intensity $\alpha > 0$. Let $(X_n)_{n \in \mathbb N}$ be iid real valued random variables that are independent of $N_t$. Let $Y_t = \sum^{N_t}_{k=1}X_k$, a compound poisson process. I am trying to derive the PGF of $Y_t$ in terms of the PGF of $X_t$ when $X_1$ has density: $\rho(n) = \dfrac{-p^n}{n\ln(1-p)}, n \in \mathbb N$ Attempt: Let the PGF of $Y_t$ be denoted by $\phi_{Y_t}$, then:
\begin{align*}
\phi_Y(s) &= E[s^{Y}]\\
&=\sum^{\infty}_{i=1}s^iP(Y_t = i)\\
&=\sum^{\infty}_{i=1} \sum^{\infty}_{j=1}s^iP(Y_t = i \mid N_t=j)P(N_t=j)\\
&=\sum^{\infty}_{j=1} P(N_t=j) \sum^{\infty}_{i=1}   s^iP(Y_t = i \mid N_t=j)\\
&=\sum^{\infty}_{j=1} P(N_t=j) \sum^{\infty}_{i=1}   s^iP(X_1+\cdots+X_j=i)\\
&=\sum^{\infty}_{j=1} P(N_t=j) (\phi_x(s))^j\\
&=\phi_N(\phi_X(s))
\end{align*}
Thus, 
$$
\phi_Y(s)=e^{\alpha t(\phi_{X_1}(s)-1)}
$$ Now, I've worked out that $\phi_{X_1} = \frac{\ln(1-ps)}{\ln(1-p)}$, therefore: $$
\phi_Y(s)=e^{\alpha t\left(\frac{\ln(1-ps)}{\ln(1-p)}-1\right)}
$$ Could anyone verify this result?","['probability-theory', 'poisson-distribution', 'generating-functions']"
1281970,Question about eigenvalue of Hermitian matrix,"This is an eigenvalue problem I found. Let $A$ be an $n$-by-$n$ Hermitian complex matrix and $u$ is a vector in $C^n$ such that $u^*u=1$. Let $k=u^*Au$. Show that there exists an eigenvalue $r$ of $A$ such that $|r-k| \le ||Au-ku||_2$ (norm-2). I've been trying to use some facts about maximum or minimum eigenvalue but got no clue at the end. I think it talks about Rayleigh quotient tho.
How should it be done?","['eigenvalues-eigenvectors', 'linear-algebra', 'matrices']"
1281981,27 lines on Fermat surface,"I want to describe the $27$ lines on the Fermat surface and have found the information below. I don't understand the last part. How is it possible to go from $9$ different lines to $27$ different lines by changing the projective coordinates. Can somebody explain how you get the three last equations? Lemma 11.1. The Fermat cubic $X = V_p(x_0^3+x_1^3+x_2^3+x_3^3)\subset\mathbb P^3$
contains exactly 27 lines. Proof. Up to a permutation of coordinates, every line in $\mathbb P_3$
is given by two linear equations of the
form $x_0 = a_2x_2 + a_3x_3$ and $x_1 = b_2x_2 + b_3x_3$ for suitable $a_2,a_3,b_2,b_3 \in \mathbb C$. Such a line lies in X if
and only if
$(a_2x_2 +a_3x_3)^3 + (b_2x_2 +b_3x_3)^3 +x_2^3+x_3^3 = 0$
as a polynomial in $\mathbb C[x_2, x_3]$ So by comparing coefficients, if and only if $$a_2^3 +b_2^3=-1 \dots (1)$$ $$a_3^3 +b_3^3=-1 \dots (2)$$
$$a_2^2a_3=-b_2^2b_3 \dots (3)$$
$$a_2a_3^2=-b_2b_3^2 \dots (4)$$ If $a_2,a_3,b_2,b_3$ are all non-zero, then $(3)^2/(4)$
gives $a_2^3=-b_2^3$ in contradiction to $(1)$ Hence for a line in the cubic at least one of these numbers must be zero. Again after possibly renumbering the
coordinates we may assume that $a_2 = 0$. Then $b_2^3=-1$ by $(1)$; $b_3 = 0$ by $(3)$; and $a_3^3=-1$ by $(2)$ Conversely, for such values of $a_2,a_3,b_2,b_3$ the above equations all hold, so that we really obtain a line in the cubic. We thus obtain $9$ lines in $X$ by setting $b_2 = −\omega^j; a_3=-\omega^k$
for $0 \le j, k \le 2$ with $\omega = exp(\frac {2\pi i}3)$,
a primitive third root of unity. So finally, by allowing permutations of the coordinates we find that there are exactly the following $27$ lines on $X$:
$$x_0 +x_3\omega^k = x_1 +x_2\omega^j=0: 0 \le j, k \le 2$$
$$x_0 +x_2\omega^k = x_3 +x_1\omega^j = 0: 0 \le j, k \le 2$$
$$x_0 +x_1\omega^k = x_3 +x_2\omega^j = 0: 0 \le j, k \le 2$$ http://www.mathematik.uni-kl.de/~gathmann/class/alggeom-2014/chapter-11.pdf",['algebraic-geometry']
1282001,Looking for help to clearly define a function that counts the number of twin primes in a range,"My goal is to define a function that counts the number of twin primes between $q$ and $q^2$ where $q$ is any prime greater than $7$. I would like to do this using: The Sieve of Eratosthenes The concept of least prime factor (lpf) Here is my attempt.  Please let me know if I make any mistakes or there is an easier way to define the function in terms of these two ideas. Let $f_p(x) = $ the number of elements $y$ such that $x < y < x^2$ and $p = \text{lpf}\left[y(y+2)\right]$ I want to now define a function $t(x)$ where $t(x) = $ the number of twin primes pairs $z,z+2$ such that $x < z < x^2$ and $z,z+2$ are twin primes. Here's my attempt at a definition based on $f_p(x)$ Let $t(x) = (x^2 - x) - \sum\limits_{p \le x} f_p(x)$ Did I do it correctly?  Does $t(x)$ now count the number of twin primes that are between $x$ and $x^2$? I ask because I posted a question (now deleted) with this assumption and everyone seemed confused by my reasoning.","['twin-primes', 'proof-writing', 'functions']"
1282015,"If a composition of two maps is smooth, as well as one of the maps, then so is the other.","Let $M$, $N$, and $K$ be smooth manifolds, and consider the maps $g:M\to N$, and $f:N\to L$. Assume that the composition $f\circ g$ is smooth. If any of $f$ and $g$ is smooth can we conclude that the other is also smooth? In particular, is $f$ smooth if $g$ is a smooth surjection? Is any of the preceding statements a case of a categorical theorem? What conditions should $f$ and $g$ satisfy for the first statement to hold true? What conditions should $f$ and $g$ satisfy for the second statement to be true?","['differential-geometry', 'smooth-manifolds', 'function-and-relation-composition', 'category-theory']"
1282024,$\int_2^x\frac{dt}{\log^kt}=O\left(\frac{x}{\log^kx}\right)$,"I seek to prove the identity $$\int_2^x\frac{dt}{\log^kt}=O\left(\frac{x}{\log^kx}\right)$$ I was given the following hint: Split the integral into $\int_2^{f(x)}+\int_{f(x)}^x$ for a well-chosen function $f(x)$ with $2\le f(x)<x$ and estimate both parts from above. but my proof was different. Can anyone (i) confirm if my proof is correct or incorrect and (ii) find the proof using the author's hint? My proof: Pick any $a>e^k$. Then $\int_2^a\frac{dt}{\log^kt}$ is constant and finite, so it suffices to prove that $\int_a^x\frac{dt}{\log^kt}=O\left(\frac{x}{\log^kx}\right)$, which follows from $$\left(1-\frac{k}{\log a}\right)\int_a^x\frac{dt}{\log^kt}\le\int_a^x\frac{dt}{\log^kt}\left(1-\frac{k}{\log t}\right)=\frac{x}{\log^kx}-\frac{a}{\log^ka}\le\frac{x}{\log^kx}$$","['asymptotics', 'approximation', 'analytic-number-theory', 'integration']"
1282041,Geometrical representation of the unit ball?,"Let $E$  be the vector space of $\mathbb{R}$-valued continuous functions on $[0\ 1]$. With the norm $\| f \| = \max \{\ | f (x) |; 0 \leq x \leq 1\}$, the open ball centered at $f$ and radius $r$ has a simple graphical representation: it is a “parallel to f band”: the distance from all point on the function at each of its two edges is constant and equal to $r$; for example the closed ball of center the constant function $f(x)= 5$ and radius $1$ is the set of all functions in $E$ contained in the closed rectangle of vertices $(0,4),(1,4),(1,6),(0, 6)$. Is there a similar or analog geometrical representation when the norm on $E$ is given by
$\int_{{0}}^{1}|f(x)|$?",['functional-analysis']
1282046,"If $ab=ba$, Prove $a^2$ commutes with $b^2$","From Dr. Pinter's ""A Book of Abstract Algebra"": Given $a$ and $b$ are in $G$ and $ab=ba$, we say that $a$ and $b$ commute. Prove $a^2$ commutes with $b^2$ I tried: $$
ab=ba
$$
$$
a^{2}b^{2}=b^{2}a^{2} \text{ // to prove that $a^2$ commutes with $b^2$}
$$
$$
aabb=bbaa
$$ Then, knowing that $$a=b^{-1}ab,$$ I substituted that '$a$' into '$aabb=bbaa$'. But that simplified to '$aabb=bbaa$', i.e. I got nowhere with it. How can I prove that $$aabb=bbaa$$ per this problem?",['abstract-algebra']
1282058,"Does $(f_n(x))= (\frac{nx}{1+nx^2})$ converge pointwise/uniformly on $I= [0,1]$?","Does $\displaystyle(f_n(x))= \bigg(\frac{nx}{1+nx^2}\bigg)$ converge pointwise/uniformly on $I= [0,1]$? My attempt: Pointwise: $\displaystyle \lim_{n \to \infty}f_n(x) = \lim_{n \to \infty} \frac{x}{\frac{1}{n}+ x^2} = \frac{1}{x}$. However, notice that $f(x) = \frac{1}{x}$ is discontinuous at the point $x=0$, hence $(f_n(x))$ does not converge pointwise on $I = [0,1]$. Consequently it does not converge uniformly on $I = [0,1]$. Is my reasoning correct? Or am I missing something?","['sequences-and-series', 'real-analysis', 'uniform-convergence']"
1282076,"How general $ [X,[Y,Z]] \cong [X \times Y, Z] $ is?","In some algebraic categories (abelian groups, modules on a ring) and in pointed spaces categories the following holds: $$ [X,[Y,Z]] \cong [X \times Y, Z] $$ In wich generality this lemma holds?","['abstract-algebra', 'algebraic-topology', 'category-theory']"
1282109,$\sum a_n$ converges $\implies\ \sum a_n^2$ converges? [duplicate],"This question already has answers here : Prove that if $\sum{a_n}$ converges absolutely, then $\sum{a_n^2}$ converges absolutely (3 answers) Series proof $\sum_1^\infty|a_n|<\infty$ then show that $\sum_1^\infty{a_n^2}<\infty$ [duplicate] (3 answers) Closed 9 years ago . If $\sum a_n$ with $a_n>0$ is convergent, then is $\sum {a_n}^2$ always convergent? Either prove it or give a counter example. Im trying in this way, Suppose $a_n \in [0,1] \ \forall\  n.\ $ Then ${a_n}^2\leq a_n\ \forall\  n.$ Therefore by comparison test $\sum {a_n}^2$ converges. So If $a_n$ has certain restrictions then the result is true.
 what about the general case? How to proceed further?
Hints will be greatly appreciated.","['sequences-and-series', 'real-analysis']"
1282144,Trying to prove a trigonometric identity,"I've been trying to solve it for quite some time but I still don't get it why it is true. The original equation is:
\begin{equation*}
1-\frac{\sin{^2}\theta}{1-\cos\theta}=-\cos\theta.
\end{equation*}
My work so far:
\begin{equation*}
\frac{1-\cos\theta}{1-\cos\theta}-\frac{\sin{^2}\theta}{1-\cos\theta}
=\frac{1-\cos\theta-\sin{^2}\theta}{1-\cos\theta}
=\frac{(1-\sin{^2}\theta)-\cos\theta}{1-\cos\theta} \\
=\frac{\cos{^2}\theta-\cos\theta}{1-\cos\theta}
=\frac{\cos\theta(\cos\theta-1)}{1-\cos\theta}.
\end{equation*}
I saw on some sites that this is equal to $-\cos\theta$ but I don't see why.",['trigonometry']
1282158,The series of function $f(x)=\sum_{n\geq 1}\frac{1}{n}\ln(1+\frac{x}{n})$; the convergence and the differentiability.,"Consider the series of function $f(x)=\sum_{n\geq
 1}\frac{1}{n}\ln(1+\frac{x}{n})$ for $x>-1$. a) Show that the series is pointwise convergent. Answer : I actually don't know how to show it. I could show that the series is convergent for all $x>-1$. First I noticed that
\begin{equation*}
\frac{1}{n}\ln\left ( 1+\frac{x}{n} \right )=\ln\left ( \left ( 1+\frac{x}{n} \right )^{1/n} \right )<\left ( 1+\frac{x}{n} \right )^{1/n}
\end{equation*}
for all $x>-1$. Comparing the series with $\sum_{n\geq 1}\left ( 1+\frac{x}{n} \right )^{1/n}$ that diverges makes me to find other comparisons. I have not yet found a good comparison that converges. Or, if $\epsilon>0$ is given, then I am unable to find a $K>0$ such that
\begin{equation*}
\left | \sum_{n= 1}^{k}\frac{1}{n}\ln\left ( 1+\frac{x}{n} \right )-f(x) \right |<\epsilon
\end{equation*}
for all $k>K$. b) Determine the termwise differentiated series, and show that it is
  uniformly convergent. Answer : Let $f_{n}(x)=\frac{1}{n}\ln\left (1+\frac{x}{n}  \right )$. Since $f_{n}(x)$ is differentiable with $f_{n}'(x)=\frac{1}{n(n+x)}$ for $x>-1$, so the termwise differentiated series is
\begin{equation*}
\left ( \sum_{n\geq 1} f_{n}(x) \right )'= \sum_{n\geq 1}f_{n}'(x)=\sum_{n\geq 1}\frac{1}{n(n+x)}.
\end{equation*}
Since, for example, $0\in (-1,\infty)$ and $\sum_{n\geq 1}f_{n}'(0)$ is convergent, then the series $\sum_{n\geq 1}f_{n}'(x)$ is uniformly convergent for all $x\in (-1,\infty)$. c) Explain that $f$ is differentiable. Answer : Isn't the problem b) enough to say that it is differentiable? Or, if $\epsilon>0$ is given, then I am unable to find a $\delta>0$ such that for all $x\in (-1,\infty)$
\begin{equation*}
\left | \frac{f(x)-f(a)}{x-a}-f'(a) \right |<\epsilon\implies \left | x-a \right |<\delta.
\end{equation*}","['sequences-and-series', 'convergence-divergence', 'epsilon-delta', 'derivatives']"
1282168,Must a non-simple group have a normal Sylow subgroup?,"In class, one way we're taught to prove a group is not simple is to exhibit a normal Sylow subgroup. I'm wondering if the converse is true, i.e. if a group is not simple, must it have a normal Sylow subgroup? I can't seem to prove this is the case but I haven't been able to come up with a counterexample yet either.","['sylow-theory', 'abstract-algebra', 'group-theory', 'finite-groups', 'simple-groups']"
1282196,$a^{13} \equiv a \bmod N$ - proof of maximum $N$,"From Fermat's Little Theorem, we know that $a^{13} \equiv a \bmod 13$. Of course $a^{13} \equiv a \bmod p$ is also true for prime $p$ whenever $\phi(p) \mid 12$ - for example, $a^{13} = a^7\cdot a^6 \equiv a\cdot a^6 = a^7 \equiv a \bmod 7$. So far I have that the largest $N$ for which all $ a^{13} \equiv a \bmod N$, is $N = 2\cdot 3\cdot 5\cdot 7\cdot 13 = 2730$ Can someone either put together an elegant proof of this, or find and prove a different limit?","['prime-numbers', 'elementary-number-theory', 'modular-arithmetic', 'algebra-precalculus']"
1282202,Incorrect Euler Totient Function definition?,"According to wikipedia , definition of Euler's totient function (or Euler's totient function) is: Euler's totient function is an arithmetic function that counts the positive integers less than or equal to $n$ that are relatively prime to $n$, ie if $n$ is a positive integer, then $\phi(n)$ is the number of integers $k$ in the range $1 ≤ k ≤ n$ for which the greatest common divisor $gcd(n, k) = 1$. Why does the definition specifically mention that the relative prime number to $n$ can be equal to $n$ (Check the highlighted area in the definition)? I think that for any positive number $n$ the value of $gcd(n,n)$ will always be $n$, so $n$ is never relatively prime to $n$. So why does it state that range of $k$ is $1 ≤ k ≤ n$ instead of $1 ≤ k < n$ Am I correct in making this assumption? Is there any exception?","['number-theory', 'algebra-precalculus', 'functions']"
1282203,Constrained zero diagonal low rank approximation of a matrix with zero diagonal,"Suppose that you have a $n\times n$ matrix $A$ that is symmetric and has zero diagonal, such as for example
$$
A=\pmatrix{
0 & 2 & 2\\
2 & 0 & 1\\
2 & 1 & 0},
$$
and you want to represent it by a low rank approximation but respecting the symmetry and the zero diagonal in the output of that approximation. Like doing the eigenvalue decomposition by the spectral theorem
$$
A=\sum_{i=1}^n \lambda_iv_iv_i^T
$$
and then truncate this sum to get an approximation for $k\leq n$ (assuming $|\lambda_1|\geq\ldots\geq|\lambda_n|$). But if you do this for $A$ of course you get something like (with two eigenvalues)
$$
A=\pmatrix{
0 & 2 & 2\\
2 & 0.5 & 0.5\\
2 & 0.5 & 0.5
},$$
which is not in the spirit of what I want. Question : Is there a standard procedure/method for dimension reduction respecting these constraints? EDIT 1 : I realized that since you need to have a zero diagonal output as an approximation matrix, this implies full rank except if some of the entries are zero. So I guess the answer is in choosing which entries are set to zero and how the others are reweighted. Thanks!","['matrix-rank', 'eigenvalues-eigenvectors', 'matrices']"
1282263,Show a matrix satisfying $A^2 − 8A + 15I = 0$ is diagonalisable.,"A square matrix $A$ (of some size $n × n$) satisfies the condition $A^2 − 8A + 15I = 0$. Show that this matrix is similar to a diagonal matrix. I know that we must show that 5 and 3 are the eigenvalues of this matrix, and that they yield n linearly independent eigenvectors, but I have no idea how. Furthermore: Show that for every positive integer $k ≥ 8$ there exists a matrix $A$ satisfying the above condition with $tr(A) = k$. I think there is some formula that the sum of the eigenvalues is equal to the trace, but I'm not entirely sure.","['linear-algebra', 'matrices']"
1282273,When are the geometric realisations of two simplicial sets homeomorphic?,"I'm given two simplicial sets $X,Y : \Delta^{\operatorname{op}} \to Set$. Of, course, if I study their geometric realisations $\lvert X \rvert$ and $\lvert Y \rvert$, I might find a homeomorphism, or maybe I can show via homology that they aren't homeomorphic. But how do I find that out just given the combinatorial data? Is there a combinatorial condition? Or is there an algorithm that can decide it for simplicial sets with finitely many nondegenerate simplices? Edit: Is there a set of moves (similar to Pachner moves for triangulations) that can be applied to go from one simplicial set to another?","['general-topology', 'simplicial-stuff']"
1282282,Is a random variable constant iff it is trivial sigma-algebra-measurable?,"I found a proof here for a measurable function (instead of probability theory's random variable) being constant if and only if the sigma-algebra generated by it is the trivia sigma-algebra, I think (If so, I believe it is the same in the probabilistic version since the poster actually says ""probability space""). I copied the proof below. Here are my questions: Is capital $X$ supposed to be $A$? Is $A$ supposed to be a sample space rather than a probability space? So we say $f$ is a random variable/measurable function on probability space/measure space ($X, F, P$) for some probability measure $P$? Is $C$ supposed to be a Borel set? What is the relevance of $c_1$ being a closed set? Here is the proof: In reply to ""probability"", posted by alex on May 10, 2004: Suppose that $A$ is probability space and $f$ is a any real-valued function on $A$. Prove that
  If $F=\{\emptyset, A\}$, then $f$ is $F$-measurable $\iff f$ is a constant If $f==c$ is constant it is ALWAYS measurable (for any sigma-algebra).
This holds as $f^{-1}[C]$ is $X$ if $c \in C$ and empty if $c \notin C$. And both sets are in any sigma-algebra. On the other hand, if $f$ is $F$-measurable and non-constant, then it assumes at least two values $c_1$ and $c_2$. The set $f^{-1}[{c_1}]$ must be in $F$ (by being $F$-measurable, as ${c_1}$ is a closed set) but this set is non-empty (as $c_1$ IS a value of $f$) and not $X$ (as the points $x$ where $f$ assumes the value $c_2$ are not in it).
So this set cannot be in $F$, and so $f$ must be constant.","['probability-theory', 'constants', 'real-analysis', 'measure-theory']"
1282286,Trigonometric Identities help please,$$  \frac {\sec \theta}{  \csc \theta - \cot \theta }  - \frac {  \sec \theta }{  \csc \theta + \cot \theta }  =  2\csc \theta $$ I really have no idea how to verify. I try then but can't make sense of it. Thanks in advance for any help.,['trigonometry']
1282290,How to calculate the Summation??,"Can we get the formula in terms of N and k for this summation series? $$
A=\sum_{t=0}^N\sum_{s=0}^t\sum_{r=0}^sk^rk^{s-r}k^{t-s}
$$","['discrete-mathematics', 'sequences-and-series', 'summation', 'combinatorics']"
1282307,What is the minimum and maximum number of eigenvectors?,"I am given the eigenvalues of a square, 8x8, matrix. They are all non-zero. I have determined that the matrix is diagonalizable and has an inverse. In one part of the problem, I am asked to find the maximum and minimum number of eigenvectors that the matrix could possibly have? Since A is diagonalizable does that mean it will have n linearly independent eigenvectors. So, is the max and min number of eigenvectors is 8?","['numerical-linear-algebra', 'linear-algebra']"
1282308,limsup/liminf of a random variable?,"The limsup of events $A_1, A_2, ...$ is $\limsup A_n = \bigcap_{m\geq1} \bigcup_{n\geq m} A_n$ Is there a limsup for random variables $X_1, X_2, ...$? I've seen $\limsup X_n$ sometimes but it usually precedes ""= 5"" or ""$\geq \alpha$"" thus referring still to a $\limsup$ or events namely $\limsup (X_n = 5)$ and $\limsup (X_n \geq \alpha)$, respectively. I mean, $(\limsup X_n) = 5$ and $(\limsup X_n) \geq \alpha$ don't make sense, do they? According to this , the limsup of random variables is the same: $\limsup X_n = \bigcap_{m\geq1} \bigcup_{n\geq m} X_n$ What does $\bigcup_{n\geq m} X_n$ even mean? I was thinking the equation was supposed to be $\bigcup_{n\geq m} \sigma(X_n)$, but that's taken ...","['probability-theory', 'limits', 'random-variables', 'limsup-and-liminf']"
1282343,Finding the limit of a function with 2 variables,"Please help to solve the limit. $$\lim_{(x,y)\rightarrow(0,0)}\dfrac{x^3+y^3}{x^2+y^2}$$ I tried to solve it but... $$x:=0 \Rightarrow \dfrac{x^3+y^3}{x^2+y^2} = y$$
$$y:=0 \Rightarrow \dfrac{x^3+y^3}{x^2+y^2} = x$$","['calculus', 'limits']"
1282478,Definition of a geometric sequence,"Is the sequence $0, 0, 0, 0 ...$ geometric? If so how would you define it? In order to define a geometric sequence you need the first term, and the ratio of terms. In this case you could have: $a = 0$ $r = k$ for some $k \in \mathbb{R}$ Is this still geometric, even though a single unique definition doesn't exist (a non variable $r$)? EDIT: This is an interesting debate. But you could also say that $0, 0, 0, 0 ...$ is an arithmetic sequence. So to all who are saying that it is geometric, can a sequence be both geometric and arithmetic?",['sequences-and-series']
1282486,Proving a function is not differentiable,"Given the function $f(x) = |8x^3 − 1|$ in the set $A = [0, 1].$
Prove that the function is not differentiable at $x = \frac12.$ The answer in my book is as follows: $$\lim_{x \to \frac12-} \dfrac{f(x)-f(1/2)}{x-1/2} = -6$$ 
$$\lim_{x \to \frac12+} \dfrac{f(x)-f(1/2)}{x-1/2} = 6$$ Can anyone explain how the $6$'s were derived. I understand that as $x$ tends to $\frac12$ from the negative side, the bottom will be negative, so thats why the first one is a minus. But how do you get to the $6$, what am I missing? Obviously $f(\frac12)=0$ but what do you make $f(x)=$ as $x$ tends to $\frac12$ Thanks","['limits', 'real-analysis', 'analysis', 'ordinary-differential-equations', 'derivatives']"
1282498,Stopping and optional times.,"Let $(\Omega,\mathcal{F},\{\mathcal{F}_t\}_{t\geq0},P)$ be a filtered probability space. Put $\mathcal{F}_{t^+}:=\cap_{s>t}\mathcal{F}_s$ and  $\{\mathcal{F}_{t^+}\}_{t\geq0}$ be the right-continuous filtration. A non-negative real random variable, $\tau$ is called a $\mathcal{F}_t$-stopping time iff $(\forall t\geq0)(\{\tau\leq t\}\in\mathcal{F}_t)$ and a $\mathcal{F}_t$-optional time iff $(\forall t\geq0)(\{\tau<t\}\in\mathcal{F}_t)$ Show that $\tau$ is a $\mathcal{F}_{t^+}$-stopping time iff it is a $\mathcal{F}_t$-optional time. I am having trouble showing the sufficient condition so this is what I've done so far, please correct any errors. (Necessity) If $\tau$ is a $\mathcal{F}_{t^+}$-stopping time, then for a $t\geq0$  and all $n\in\mathbb{N}$, we have $\{\tau\leq t-1/n\}\in\mathcal{F}_{t-1/n^+}\subset\mathcal{F}_t$, thus $\{\tau<t\}=\cup_{n\in\mathbb{N}}\{\tau\leq t-1/n\}\in\mathcal{F}_t$ (Sufficiency) If $\tau$ is a $\mathcal{F}_{t}$-optional time, then for any $n,m\in\mathbb{N}$ with $n\geq m$ $\{\tau<t+1/n\}\in\mathcal{F}_{t+1/m}\supset\mathcal{F}_{t^+}$, therefore, $\{\tau\leq t\}=\cap_{n\in\mathbb{N}}\{\tau< t+1/n\}\in\cap_{m\in\mathbb{N}}\mathcal{F}_t(\subset\mathcal{F}_{t^+})???$  The problem is of course with the last step so any suggestions of how I can get unstuck. My second question relates to a claim made by the notes I am using that If $\tau$ is a $\mathcal{F}_{t^+}$-stopping time, then $\{\tau=t\}\in\mathcal{F}_t$, and they say this is true as $\{\tau=t\}=\{\tau\leq t\}\setminus\{\tau<t\}$. I believe that is wrong and maybe there is a typing error and it should read that $\{\tau=t\}$ is a $\mathcal{F}_t$-stopping time. So is the claim correct or am I wrong. Thanks in advance any help is really appreciated.","['probability-theory', 'stochastic-processes']"
1282542,Transitivity of the discriminant of number fields,"Let $M/L/K$ be a tower of number fields with discriminant of $M/K: d_M$ and of $L/K: d_L$. I would like to find a transitivity theorem for the discriminant and by letting $p_i$ and $q_i$ be integral basis for $M$ and $L$ respectively and $A =[a_{ij}]$ the transition matrix between the basis, a calculation gives: $$[M:L]^{[L:K]}d_L = \det(A)^2d_M$$ However, these two links give different(even from each other) answers: Divisibility of discriminants in number field extensions $([M:L]^2 d_L = \det(A)^2 d_M)$ Quadratic subfield of cyclotomic field (discriminant of $M$ is divisible by discriminant of $L$ to the power $[M:L]$ Both of these are given in the accepted answers and use different notation. Which of the three is correct?(The last one is not strictly contradictory but probably often will be...).","['extension-field', 'abstract-algebra', 'galois-theory', 'algebraic-number-theory']"
1282550,Asymptotic for primitive sums of two squares,"A positive integer $n$ can be written primitively as the sum of two squares, meaning $n = x^2 + y^2$ with $\gcd(x,y)=1,$ precisely when $n$ is not divisible by $4$ or by any prime $q \equiv 3 \pmod 4.$ Since this applies to primes $p \equiv 1 \pmod 4,$ the count of such numbers up to some large positive $x$ is at least 
$$  \frac{x}{2 \log x}. $$ On the other hand, it cannot be any larger than all sums of two squares up to $x,$ which is about
$$  \frac{0.7642 \; x}{\sqrt{ \log x}}. $$ The ratio of these two quantities becomes arbitrarily large as $x$ grows. Question: what is the true asymptotic for the count of numbers up to $x$ that are primitively the sum of two squares? Numerical experiment suggests closer to the larger quantity but needing to be smaller by a factor that grows more slowly than anything else in sight, perhaps $$  \frac{ x}{\sqrt{ \log x} \; \; \log \log x} $$
or the like.","['number-theory', 'analytic-number-theory']"
1282579,Arrangements of sets of k positions in a n-competitors race,"Let $E(n)$ be the set of all possible ending arrangements of a race of $n$ competitors . Obviously, because it's a race, each one of the $n$ competitors wants to win.
Hence, the order of the arrangements does matter.
Let us also say that if two competitors end with the same result of time, they win the same spot. For example, $E(3)$ contains the following sets of arrangements: ${(1,1,1), (1,1,2), (1,2,1), (1,2,2), (1,2,3), (1,3,2), (2,1,1), (2,1,2),(2,1,3), (2,2,1), (2,3,1), (3,1,2), (3,2,1)}.$ Needless to say, for example, that the arrangement $(1,3,3)$ is invalid, because the two competitors that supposedly ended in the third place, actually ended in the second place. So the above arrangement ""transfers"" to $(1,2,2)$. Define $k$ to be the number of distinct positions of the competitors in a subset of $E(n)$. 
We have for example: $(1,1,1)\Rightarrow k = 1$ $(1,2,1)\Rightarrow k = 2$ $(1,2,3,2)\Rightarrow k = 3$ $(1,2,1,5,4,4,3)\Rightarrow k = 5$ Finally , let $M(n,k)$ be the number of subsets of $E(n)$ in which the competitors ended in exactly $k$ distinct positions. We get, for example, $M(3,3) = M(3,2) = 6$ and $M(3,1) = 1$. ------------------------------------------------------------------------------------------- Thus far is the question It's a problem I came up with solely by myself. After some time of thought I came up with the following recursive formula for $|E(n)|$: (Don't continue reading if you want to derive a formula yourself!) $$|E(n)| = \sum_{l=1}^n\binom{n}{l}\cdot |E(n-l)| \quad\text{where}\quad |E(0)| = 1$$ The logic behind this recurrence relation is that $l$ symbolizes how many ""first"" spots we have. For each $l$, the binomial coefficient $\binom{n}{l}$ symbolizes in how many ways we can pick $l$ first-placers out of the $n$ competitors. Once we have chosen them, we to need to figure out in how many ways we can arrange the $n-l$ competitors we have left, which is just $|E(n-l)|$.
I get the following: $|E(3)| = 13$ $|E(5)| = 541$ $|E(10)| = 102247563$ $|E(100)|$ mod $1$ $000$ $000$ $007 = 619182829$ $\rightarrow$ 20 ms. And $|E(1000)|$ mod $1$ $000$ $000$ $007 = 581423957$ $\rightarrow$ 39 sec. I figured out that $|E(n)|$ can also be visualized as the number of sets to which the following applies: For every $i = 1, 2, 3 ... n$, every $i$-tuple subset of the original set has GCD (greatest common divisor) of all of its elements equal to 1.
But I'm not 100% sure about this because I was not able to compute this approach for large $n$.
However, even with precalculating factorials and memoizing the $E(n)$'s, the calculating times for higher $n$'s grow very fast.
Is anyone capable of verifying the above formula and values?
Can anyone derive a better, faster formula? Perhaps with generating functions? As for $M(n,k)$.. I'm totally clueless. I absolutely have no idea how to calculate it, and therefore I couldn't post any meaningful data points. 
Perhaps it's $P(n,k) = \frac{n!}{(n-k)!}$.
Can anyone figure out a formula for $M(n,k)$? I have no idea which function is harder to compute, either $E(n)$ or $M(n,k)$, but helping me with either of them will be very much appreciable. I want the solutions to be generic as well as work efficiently even for large $n$'s. Exhaustive search is not what I'm looking for, unfortunately. 
What I am looking for is solutions based purely on combinatorial approach and efficient formulas. I hope I was clear enough with the wording and what I ask for throughout my post. By the way, I can program using Java. I also know Mathematica pretty decently :) . Thanks a lot in advance, Matan.","['elementary-set-theory', 'permutations', 'combinations', 'group-theory', 'combinatorics']"
1282580,$\operatorname{Gal}(\overline{K}/K)=\mathbb{Z}$ possible?,Is it possible to have $\operatorname{Gal}(\overline{K}/K)=\mathbb{Z}$? My question comes from the link beetween covering and field extensions. For covering the simplest example is $\operatorname{Gal}(\mathbb{R}/\mathbb{S}^1)=\mathbb{Z}$. Maybe something like $\mathscr{M}(\mathbb{C})/\mathscr{M}(\mathbb{C}^*)$ where $\mathscr{M}(X)$ is the field of meromorphics functions on a Riemann surface?,"['group-theory', 'galois-theory', 'covering-spaces', 'riemann-surfaces']"
1282610,Computing a limit similar to the exponential function,"I want to show the following limit:
$$
\lim_{n \to \infty}
n
\left[
    \left( 1 - \frac{1}{n} \right)^{2n}
    - \left( 1 - \frac{2}{n} \right)^{n}
\right]
    = \frac{1}{e^{2}}.
$$
I got the answer using WolframAlpha, and it seems to be correct numerically, but I am having trouble proving the result. My first instinct was to write the limit as
$$
\lim_{n \to \infty}
\frac
{
    \left( 1 - \frac{1}{n} \right)^{2n}
    - \left( 1 - \frac{2}{n} \right)^{n}
}
{1/n}.
$$
Then, I tried applying l'Hopital's rule, and I got
$$
\lim_{n \to \infty}
\frac
{
    \left( 1 - \frac{1}{n} \right)^{2n}
    \left( 2 \log\left( 1 - \frac{1}{n} \right) + \frac{2}{n-1} \right)
    -
    \left( 1 - \frac{2}{n} \right)^{n}
    \left( \log\left( 1 - \frac{2}{n} \right) + \frac{2}{n-2} \right)
}
{-1/n^{2}}.
$$
This does not seem to have gotten me anywhere. My second attempt was to use the binomial theorem:
$$
\begin{align*}
n
\left[
    \left( 1 - \frac{1}{n} \right)^{2n}
  - \left( 1 - \frac{2}{n} \right)^{n}
\right]
&
=
n
\left[
    \sum_{k=0}^{2n} \binom{2n}{k} \frac{(-1)^{k}}{n^{k}}
  - \sum_{k=0}^{n} \binom{n}{k} \frac{(-1)^{k} 2^{k}}{n^{k}}
\right]
\\ &
=
\sum_{k=2}^{n} \left[ \binom{2n}{k} - \binom{n}{k} 2^{k} \right] \frac{(-1)^{k}}{n^{k-1}}
+ \sum_{k=n+1}^{2n} \binom{2n}{k} \frac{(-1)^{k}}{n^{k-1}}.
\end{align*}
$$
At this point I got stuck again.",['limits']
1282622,The box has minimum surface area [duplicate],"This question already has an answer here : Minimum area of the parallelepiped surface (1 answer) Closed 8 years ago . Show that a rectangular prism (box) of given volume has minimum surface area if the box is a cube. Could you give me some hints what we are supposed to do?? $$$$ EDIT : Having found that for $z=\frac{V}{xy}$ the function $A_{\star}(x, y)=A(x, y, \frac{V}{xy})$ has its minimum at $(\sqrt[3]{V}, \sqrt[3]{V})$, how do we conclude that the box is a cube?? We have that $x=y$. Shouldn't we have $x=y=z$ to have a cube??",['calculus']
1282660,Proof of this definite integral?,"Saw this sometime in my calculus book, from the Putnam Math Challenges listed: $$\lim _{ n\rightarrow \infty  }{ \int _{ 0 }^{ 1 }{ \int _{ 0 }^{ 1 }{ \underbrace{\dots}_{n-3 \, times} \int _{ 0 }^{ 1 }{ \cos ^{2} { \left\{ \frac { \pi  }{ 2n } \left({x}_{1}+{ x }_{ 2 }+\dots +{ x }_{ n }\right)\right\}  \quad { dx }_{ 1 }{ dx }_{ 2 }\cdots { dx }_{ n } }  }  }  } = \dfrac{1}{2} } $$ Thank you to whoever can help me understand this! : )","['calculus', 'multivariable-calculus', 'definite-integrals', 'integration']"
1282669,"Linear independence of $\sin(x)$, $\sin(2x)$, $\sin(3x)$ in Map($\mathbb{R},\mathbb{R}$)","It seems rather obvious to me that $\sin(x)$, $\sin(2x)$, $\sin(3x)$ are linearly independent in $\operatorname{Map}(\mathbb{R},\mathbb{R})$, but I'm not sure how to prove it (or disprove it if I'm wrong?). I know that for linear independence it must $$ a\sin(x)+b\sin(2x)+c\sin(3x)=0 $$
$$ \implies a=b=c=0$$
but how can I show this is true for any $x \in \mathbb{R}$?","['abstract-algebra', 'linear-algebra']"
1282688,How can I get unblocked on learning Calculus? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 9 years ago . Improve this question I love math and science. In fact paid for $1/2$ my college tuition by tutoring algebra and trigonometry. But when it came to calculus, I became blocked. I understand the concepts of speed and rate of change, but when I start seeing all the symbols like $f'(x)$ and $dx$, my mind goes all fuzzy. My learning style is that if I can picture something and comprehend it in real life, then I get it in symbols. Algebra, geometry, and trig are all easy enough to picture. But what does it look like in real life to 'take the derivative' or the integral of something? Does it look like a sphere becoming a circle? Does anyone else's brain work like this? How did you 'get' calculus?",['calculus']
1282727,In what sense does $\sum_{k=0}^{\infty} 2^{2k} = - {1 \over 3}$?,"In The Road to Reality Penrose remarks on an identity written down by Euler which is ""obviously wrong"" and yet correct ""on some deeper level"". He makes reference to the series again when discussing renormalisation. The partial series don't look much better at $\sqrt{-4}$ than they do at 2. So the answer to making use of it can't be simply to look at $\Bbb C$ . In what sense is this divergent series good? Edit: Sorry, I mean in what sense other than as a formal power series. Edit 2: Penrose remarks that the lower = left & right parts of the plot are ""inaccessible"" to the partial series. So maybe a way to rephrase the question is, how can one access them?","['summation', 'divergent-series', 'real-analysis']"
1282732,Prove that a number with 30 digits cannot have more than 100 prime factors.,"I know that the a number with more than  100 prime factors must be  larger than $2 ^ {100}$, so it must have more than 30 digits but i am having trouble with proof. I was given 
Hint: every prime number is $≥ 2$.
 Can someone help me connect the two ideas.",['discrete-mathematics']
1282739,"Let $(X, \mathfrak T)$ be a topological space and suppose that $A$ is a subset of $X$. Then $A'$ is a closed set.","Let $(X, \mathfrak T)$ be a topological space and suppose that $A$ is a subset of $X$.  Then $A'$ is a closed set. ($A'$ is the set of all limit points) I originally thought this was a true statement based on the research I have done on the internet.  I however am now beginning to doubt myself based on my definition of limit points. My definition of limit points is ""Let $(X, \mathfrak T)$ be a topological space with $A \subseteq X$ A point $x$ in X is said to be a limit point of $A$ provided that every open set containing $x$ contains a point of $A$ different from $x$. I have been trying to work on some examples in the usual topology and I have come up with this: Let $X = \mathbb R$ in the usual topology and let $A = \mathbb Q$  then $A' = irrationals$ but I not sure if the set of irrationals is closed? I have looked through my notes and I think it is neither open nor closed therefore this is false. I have also tried to come up with some very basic examples but I am unsure about the limit points: Let X = {a, b, c} and $\mathfrak T = \{X, \emptyset, \{a\}, \{b\}, \{a,b\}\}$. Let $A = \{b\}$ but I don't think this works as a counterexample . Can anyone clarify my thinking? We have not talked about metric spaces and I am familiar with the usual, half-open line, half-open interval , discrete and indiscrete topologies.","['elementary-set-theory', 'general-topology']"
1282799,Exercise 3.3 Riemannian Manifolds an Introduction to Curvature,"STATEMENT: Let $\gamma(t)=(a(t),b(t)),t\in I$(an open interval), be a smooth injective curve in the $xz$-plane, and suppose $a(t)>0$ and $\dot{\gamma}(t)\neq 0$ for all $t\in I$. Let $M\subseteq \mathbb{R}^3$ be the surface of revolution obtained by revolving the image of $\gamma$ about the $z$-axis. a)Show that $M$ is an immersed sub manifold of $\mathbb{R}^3$, and is embedded if $\gamma$ is an embedding. b)Show that the map $\varphi(\theta,t)=(a(t)\cos(\theta),a(t)\sin(\theta),b(t))$ from $\mathbb{R}\times I$ to $\mathbb{R}^3$ is a local parametrization of $M$ in a neighborhood of any point. c)Compute the expression for the induced metric on $M$ in $(\theta,t)$ coordinates. d)Specialize this computation to the case of the doughnut-shaped torus of revolution give by $(a(t),b(t))=(2+\cos(t),\sin(t))$ QUESTION So I wanted someone to check if my solution is correct. a)We note that if $\varphi:S^1\times I\rightarrow\mathbb{R}^3$ then $$d\varphi=\begin{bmatrix}a'(t)\cos\theta& -a(t)\sin\theta\\
a'(t)\sin\theta&a(t)\cos\theta\\
b'(t)& 0 \end{bmatrix}$$ So our map is an immersion since the two columns are always linearly independent. The only thing we should verify is that $M\cong S^1\times I$. This is easy to verify as we can take the map $\phi:S^1\times I\rightarrow M$ where $\phi(x,y,t)=(a(t)x,a(t)y,b(t))$, which is a diffeomorphism if we check it in local coordinates. b)From considering $\varphi$ as we did in part $a$ we can restrict it to open sets of $S^1$ which products an open image since the map is a diffeomorphism. c)$$
\begin{align}
g=&(d\varphi^1)^2+(d\varphi^2)^2+(d\varphi^1)^2\\
=&(a'(t)\cos\theta dt-a(t)\sin\theta d\theta)^{2}+(a'(t)\sin\theta dt+a(t)\cos\theta d\theta)^{2}+(b'(t)dt)^{2}\\
=&\left(a'(t)^{2}+b'(t)^{2}\right)\left(dt\right)^{2}+a^{2}(t)\left(d\theta\right)^{2}
\end{align}
$$ d)$$g=(dt)^{2}+(2+\cos t)^{2}(d\theta)^{2}$$","['differential-geometry', 'smooth-manifolds', 'riemannian-geometry']"
1282827,Confused about intuition behind Lie derivative,"I'm trying to fix my intuition behind $\mathcal L_X T$ , where $T$ is any tensor field. I'd prefer explanations that are not along the lines of $\mathcal L_XY=[X,Y]$ (I'm not sure how this extends to the case where $Y$ is an arbitrary tensor field). I have two specific questions, but explanations beyond answering these questions are more than welcome. Denote the flow of $X$ by $\varphi$ . Certainly $(\mathcal L_XT)_p$ depends on both $X|_U$ and $T|_U$ , where $U$ is an arbitrarily small neighborhood of $p$ . But does it depend on the values of $X$ and $T$ on all of $U$ , or just their values on the flow line, i.e., $\{\varphi_t(p)\}_{t\in\mathbf R}\cap U$ ? More specifically, is there an explicit example of $X$ , $X'$ (with flow $\varphi'$ ), and $T$ , such that for some $p$ , we have $\varphi_t(p)=\varphi'_t(p)$ (i.e., $X=X'$ on the flow line through $p$ ) but $(\mathcal L_XT)_p\neq(\mathcal L_{X'}T)_p$ ? [Lee's Riemannian Manifolds , Exercise 4-3(b).] Show that there is a vector field on $\mathbf R^2$ that vanishes along the $x$ -axis, but whose Lie derivative with respect to $\partial_x$ does not vanish on the $x$ -axis. My failed attempt at this problem: Suppose $V=f\partial_x + g\partial_y$ is such a vector field. Then $f(x,0)=g(x,0)=0$ for all $x$ by hypothesis. Using $\mathcal L_XY=(XY^i-YX^i)\partial_i$ , we have $\mathcal L_{\partial_x}V=(\partial_xf-0)\partial_x+(\partial_xg-0)\partial_y$ , which is supposed to be nonzero somewhere on the $x$ -axis, i.e., there is some $x_0$ such that $\partial_xf(x_0,0)\neq0$ or $\partial_xg(x_0,0)\neq0$ . Without loss of generality, assume $\partial_xf(x_0,0)\neq0$ . So now we have to come up with some $f:\mathbf R^2\to\mathbf R$ such that $f(x,0)=0$ for all $x$ but $\partial_xf(x_0,0)\neq0$ for some $x$ , which is a contradiction. What went wrong?","['differential-geometry', 'lie-derivative']"
1282868,Write the complex number in trigonometric form (homework question),"Write the complex number in trigonometric form, once using degrees and once using radians. Begin by sketching the graph to help find the argument θ. (Do not use cis form.) $$−1 + i$$ My work: I graphed $x = -1$ and $y = 1$ $$z=r= \sqrt{ x^2 + y^2}$$ $$r= \sqrt{2}$$ $$\tan \theta = \frac{Opposite}{Adjacent} $$ $$\tan \theta = \frac{-1}{1} = -1$$ $$\theta= 45^\circ$$ When put into trig form: $$\sqrt{2} (\cos 45^\circ +i \sin 45^\circ)$$ Here is how my submitted answer looks (it is #9): https://i.sstatic.net/FCthN.png I also need help with $9 − 40i$ (instructions: convert the complex number to trigonometric form. (Enter the angle in degrees rounded to two decimal places. Do not use cis form.). I went through the same steps as I did on the other problem, and I got $r=41$ and $θ= -77.32$.",['trigonometry']
1282905,Lebesgue measures defined on subspaces of $\Bbb R^n$,"For any subspace $V$ of $\Bbb R^n$, we have a special measure $\lambda_V$ which can be described in various ways: Haar measure on $V$, or the measure induced by the metric $V$ inherits from $\Bbb R^n$, or ""$k$-dimensional Lebesgue measure on $V$"" when $\dim V=k$. I want to be better able to calculate with this measure. For example, I might have linearly independent vectors $v_1,v_2\in \Bbb R^n$ and $V={}$span$\langle v_1,v_2 \rangle$. Suppose I have an integral of the form
$$
\int_{\Bbb R} \int_{\Bbb R} F(tv_1+uv_2) g_1(t) g_2(u) \,du \,dt,
$$
where $F\colon \Bbb R^n\to\Bbb R$ and $g_1,g_2\colon \Bbb R\to\Bbb R$. Can I say that this integral is equal to
$$
\int_V F(v) h_1(v) h_2(v) \,d\lambda_V,
$$
for some functions $h_1,h_2\colon V\to\Bbb R$? Perhaps each $h_j$ is $g_j$ composed with some canonical projection from $V$ onto the vectors it's made from. (And perhaps there needs to be some global constant corresponding to the determinant of something involving $\{v_1,v_2\}$.) I emphasize that I'm looking for a way to rigorously establish the connection between those two integrals; my formal ability with these Lebesgue measures on subspaces lags behind my intuition. Bonus points for an explanation that includes a reference to where these Lebesgue measures on subspaces are concretely defined and discussed. (This related question discusses a special case of the measure $\lambda_V$, but no answer was provided.)","['lebesgue-measure', 'reference-request', 'measure-theory']"
1282918,"Interesting properties of the function $(a,b)\mapsto a/(a-b)$","Consider the extremely simple function
$$f(a,b)=\frac a{a-b}.$$
This gives the coordinate where the line through $(0,a)$ and $(1,b)$ meets the $x$-axis. I noticed that the function $f$ has some interesting properties:
$$\begin{gather}
f(a,b)+f(b,a)=1, \\
f(a,x)f(a,y) = f(a,x)f(x,y) + f(a,y)f(y,x), \\
f(a,x)f(b,x) = f(a,b)f(b,x) + f(b,a)f(a,x),
\end{gather}$$
These identities can be verified by calculation, but for the latter two it is hard to see a priori that they should be true. By the way, if you imagine $f(a,b)$ as a directed edge from $a$ to $b$ in a graph, the three identities have an elegant graphical representation:
$$\begin{gather}
{}\rightarrow{} + {}\leftarrow{} = 1 \\[1em]
{}\nwarrow\nearrow{} = {}\overrightarrow{\nwarrow\ \ }{} + {}\overleftarrow{\ \ \nearrow} \\[1em]
{}\searrow\swarrow{} = {}\overrightarrow{\ \ \swarrow}{} + {}\overleftarrow{\searrow\ \ } \\[1em]
\end{gather}$$ I have a couple of questions: Does $f$ fall into any well-studied class of functions? It's not even commutative or associative, but those properties above are interesting. Is there an elegant way to prove these identities without laborious calculation, or to discover them (and any others I might have missed) starting only from the definition of $f$?","['recreational-mathematics', 'functions']"
1282932,Local maximum of brownian motions,"Let $B=(B_t)_{t\geq 0}$ be the standard Brownian motion.
I want to show that for every $t_0 \geq 0$ $\mathbb{P}$($B$ has a local maximum in $t_0$)=0. I've already shown that for every $0<a<b<\infty$ $B$ is $\mathbb{P}$-a.s. not monotone on the interval [$a,b$]. My ideas were the following: Suppose $B_t$ attains a local maximum in $t_0$. Can I assume that since $B$ has a.s. continuous paths, $t_0$ is preceded by an interval ($t_0-\epsilon, t_0$) where $B_t$ increases and is followed by an interval ($t_0,t_0+\epsilon$) where $B_t$ decreases? ($\epsilon > 0$) Then I would have two intervals where $B$ is monotone and since $B$ is not monotone on these intervals $\mathbb{P}$-a.s., I get $\mathbb{P}$($B$ has a local maximum in $t_0$) = $\mathbb{P}$($B$ is monotone on ($t_0-\epsilon,t_0$) and $(t_0,t_0+\epsilon)$)=0. Is that correct or do I have to argue in a different way? Can I always find those non-empty increasing and decreasing intervals ""before"" the next extremum? Thanks in advance.","['probability-theory', 'stochastic-calculus', 'stochastic-processes', 'brownian-motion', 'probability']"
1282950,"Prove $xe^x =2$ for some $x \in (0,1)$","We are trying to prove $xe^x =2$ for some $x \in (0,1)$. I know for certain that if this question were asking to prove the equality for some $x$ in the closed interval $[0,1]$ then I could apply the intermediate value theorem: Let $f(x) = xe^x$ implying: $f(0) = 0 \lt 2$ and $f(1) = 1\cdot e^1=e \gt 2$ and by the intermediate value theorem there must exist some $x \in [0,1]$ such that $f(x)=2$. My question is if we can use the Intermediate Value Theorem in my original question - where we have $x \in (0,1)$ the open interval. I know the discrepancy arises since the interval is open and there is no explicit definition of the function at the end-points $0$ and $1$. Thank you guys!","['continuity', 'real-analysis']"
1283013,Integer solutions of $x^3 = 7y^3 + 6 y^2+2 y$?,"Does the equation  $$x^3 = 7y^3 + 6 y^2+2 y\tag{1}$$ have any positive integer solutions?  This is equivalent to a conjecture about OEIS sequence A245624 . Maple tells me this is a curve of genus $1$, and its Weierstrass form is $s^3 + t^2 + 20 = 0$, with $$ \eqalign{ s = \dfrac{-2(7 y^2 + 6 y + 2)}{x^2},& \
t = \dfrac{-2(3 x^3 + 14 y^2 + 12 y + 4)}{x^3}\cr
x = \dfrac{-2s(t-6)}{s^3+56},&\ y = \dfrac{4t-24}{s^3+56}}$$
So I can find rational points on both curves, but I haven't been able to find integer points on (1) other than the trivial $(0,0)$.","['elliptic-curves', 'number-theory', 'diophantine-equations']"
1283026,"Find all pairs of primes $p,q$ such that $pq \mid 2^p +2^q$","Find all pairs of primes $p,q$ such that $pq \mid 2^p +2^q$. My attempt  : When either one of them is $2$ then easy case checking gives me set of solutions. But what happens when neither of them is $2$?","['number-theory', 'elementary-number-theory']"
1283028,Prove $\limsup{A_n}\backslash\liminf{A_n}=\limsup{(A_{n+1}\backslash A_n)}$,"$\newcommand{\N}{\mathbb{N}}$ Problem: Prove $\limsup{A_n}\backslash\liminf{A_n}=\limsup{(A_{n+1}\backslash A_n)}$ Attempt(Revised): (I am not sure if it's correct. I would appreciate if anyone can help check..) Let $x\in\left(\limsup A_{n}\right)\backslash\left(\liminf A_{n}\right)$.
First, observe that 
\begin{align}
\left(\limsup A_{n}\right)\backslash\left(\liminf A_{n}\right) & =\left(\limsup A_{n}\right)\cap\left(\liminf A_{n}\right)^{c}\\
 & =\left(\limsup A_{n}\right)\cap\left(\limsup A_{n}^{c}\right)
\end{align}
So, we have for any $n\in\N$ 
\begin{align}
x\in\limsup A_{n} & \Rightarrow\exists m_{1}>n\mbox{ s.t }x\in A_{m_{1}}\\
x\in\limsup A_{n}^{c} & \Rightarrow\exists m_{2}>n\mbox{ s.t }x\in A_{m_{2}}^{c}
\end{align}
We can assume that $m_{2}\geq m_{1},$ since if not we can acquire
another $m_{2}>m_{1}$ using the definiton. Suppose that $x\in\cap_{k>m_{2}}A_{k}^{c}$,
then $x\notin\limsup A_{n}$, which contradicticts with our choice
of $x$. Therefore $x\in A_{k}$ for some $k>m_{2}.$ By well-ordering
principle, we can acquire the smallest $k$ which satisfy the requirement.
Thus, we have $x\in A_{k}\backslash A_{k-1}=A_{\left(k-1\right)+1}\backslash A_{k-1}$.
So upon reindexing, we have for $\forall n\in\N,$ $\exists k\geq n$
such that $x\in A_{k+1}\backslash A_{k}$. Therefore, $x\in\limsup A_{k+1}\backslash A_{k},$which
implies $\limsup A_{n}\backslash\liminf A_{n}\subseteq\limsup A_{k+1}\backslash A_{k}$.
On the other hand, let $x\in\limsup\left(A_{n+1}\backslash A_{n}\right)$.
Then for any $n\in\N,$ $\exists m\geq n$ such that $x\in A_{m+1}\backslash A_{m}$,
i.e., $x\in A_{m+1}$ and $x\in A_{m}^{c}.$ Since $n$ is arbitrary,
we have 
\begin{align}
x & \in\left(\limsup A_{n}\right)\cap\left(\limsup A_{n}^{c}\right)\\
 & =\left(\limsup A_{n}\right)\cap\left(\liminf A_{n}\right)^{c}\\
 & =\left(\limsup A_{n}\right)\backslash\left(\liminf A_{n}\right)
\end{align}
hence, $\limsup\left(A_{n+1}\backslash A_{n}\right)\subseteq\left(\limsup A_{n}\right)\backslash\left(\liminf A_{n}\right)$.
Therefore, we have 
\begin{align}
\limsup\left(A_{n+1}\backslash A_{n}\right) & =\left(\limsup A_{n}\right)\backslash\left(\liminf A_{n}\right)
\end{align}
as desired.","['probability-theory', 'analysis', 'elementary-set-theory', 'real-analysis']"
1283047,An infinite series,"Hopefully this question is not a duplication. Consider the following infinite series: $$\LARGE\sum_{k=0}^\infty\frac{2^k}{1+\frac{1}{x^{2^k}}}$$ We know the answer is $\frac{x}{1-x}$ if $|x|<1$. We also know the partial sum is actually given by $\sum_{k=0}^n\frac{2^k}{1+\frac{1}{x^{2^k}}}=\frac{\sum_{k=1}^n kx^k}{\sum_{k=0}^n x^k}$. This formula can of course be proved by induction. What I want to know is a way to derive this formula. Since the bottom is the geometric series and the top is its derivative multiplied by $x$, there should be a nice way to derive it. We know there is a way of finding the sum of the infinite series by appealing to double series, and this is the last thing I want to see. Thanks a lot!","['sequences-and-series', 'calculus']"
1283072,Confused about dimension of circle,"I confused myself when thinking about the circle: It can be parameterised as 
$$ C(t) = (\cos t , \sin t)$$ for $t \in [0,2\pi)$. This makes it clear that the circle is one dimensional. 
But then the circle is also defined by $x,y$ such that $$ x^2 + y^2 = 1$$ If we try to solve this equation for $y$ then $$ y = \pm \sqrt{1-x^2}$$ which is not a function! But if the circle was indeed one dimensional then we should be able to write it as $$ (x,y(x))$$
which seems to be impossible. Therefore the circle is not one dimensional. Please could someone help me resolve my confusion?","['geometry', 'real-analysis']"
1283075,how to find the integral of $z$-conjugate along a circular path?,"$$\int_\gamma \overline{z}\>dz,\quad \text{where} \quad |z|=2.$$ How to find the integral of $z$ -conjugate, where the path is determined as given above? I saw that we can write $z=x+iy$ , but how to continue?","['contour-integration', 'complex-analysis']"
1283085,Hexagon packing in a circle,"Suppose I want to pack hexagons in a circle, as on the drawing below (red indicates ""packed"" hexagons).  I am wondering what is known about this problem. Specifically, I am interested in an approximation to how many fit (given the radius of the circle and the length of the side of the hexagon) and the error in such approximation.  Any ideas?","['euclidean-geometry', 'geometry', 'packing-problem']"
1283099,A question on perfect square,"Prove that if $ab$ is a perfect square and $\gcd(a,b)=1$, then both $a$ and $b$ must be perfect squares. Their Answer: Consider the prime factorization $ab=p_1^{e_1}\cdots p_k^{e_k}$. If $ab$ is a square, all the $e_i$ are even and each term $p_i^{e_i}$ is a square in its own right. (Do you see why?) Each prime in the factorization divides either $a$ or $b$ but not both, since we have $\gcd(a,b)=1$. Thus each term $p_i^{e_i}$ in the factorization completely divides either $a$ or $b$. Hence, $a$ is the product of many terms $p_i^{e_i}$, each of which is a square; since it’s a product of squares, $a$ is itself a square. Similarly for $b$. □ My Question The answer states if: $$ab = P_1^{e_1}....P_n^{e_n}$$ Then if $ab$ is a perfect square, $e_k$ is even for any $k$. But since: $$ab = (P_1 \cdots P_n)^{e_1 \cdots e_n}$$ It is possible that if $e_1 = 3$ and $e_2 = 4$ then, $e_1 \cdot e_2 = 12$ So not all $e_k$ have to be even?","['contest-math', 'prime-numbers', 'number-theory', 'algebra-precalculus', 'elementary-number-theory']"
1283150,Solve first order nonlinear differential equations,"I want to solve this nonlinear 1-st order ODE, $$\frac{1}{1+x}=(\frac{1}{x-y}-\frac{1}{y})\frac{dy}{dx}$$ I find it non-separable, and Wolfram Alpha does not give me a closed form solution, but the following plots. I am a little rusty on solving ODEs, can someone tell me the method to solve this one? A variable transformation or any other trick? Or do I need initial values to see the behavior of the system (directional fields)? Thanks in advance. Update Now the modified code is as follows, f[x_] = NDSolveValue[{(1 + x) (0.5 y[x]^-0.5 (x - y[x])^0.5 - 
       0.5 y[x]^0.5 (x - y[x])^-0.5) == -y[x] (x - y[x])/y'[x], 
   y[1] == 0.5}, y[x], {x, 0, 2}] But the result is still error, Infinite expression 1/0. encountered. >>
NDSolveValue::ndnum: Encountered non-numerical value for a derivative at x == 1.`. >> Why in your code, we do not have the indeterminate problem?
And the direction field I want is like the one below:","['boundary-value-problem', 'nonlinear-system', 'ordinary-differential-equations', 'problem-solving']"
1283163,"antiderivative of $\frac{1}{z(z-1)}$, complex logarithm","I have the domain $\mathbb{C} \backslash [0,1]$ and want to show that $$\int_\gamma \frac{1}{z(z-1)}dz = 0$$
for all closed curves $\gamma$. I want to accomplish this by explicitly finding an antiderivative. I did a partial fraction decomposition and got
$$f(z) = \frac{1}{z(z-1)} = \frac{1}{z-1} - \frac{1}{z}$$ Now
$$ F(z) =\text{log}(z-1) - \text{log}(z)$$
would be an antiderivative but I don't feel comfortable with the complex logarithm yet. Is my $F(z)$ well-defined on my whole domain? If not, how do I find a well-defined antiderivative?","['complex-analysis', 'logarithms']"
1283186,Is level set near a maximum value a circle?,"Let $f$ be a $C^2$ function defined on $[0,1] \times [0,1]$. Let $0 \leq f(x) < 1$ on $[0,1] \times [0,1] \setminus \left(\frac{1}{2},\frac{1}{2}\right)$ and $f(\frac{1}{2},\frac{1}{2})=1$. It has no critical point except $(\frac{1}{2},\frac{1}{2})$. I wonder there exists a number $0<a<1$ such that $f^{-1}(a)$ to be a circle. By the smooth manifold theory, $f^{-1}(a)$ is always a 1-dimensional submanifold. Since $f$ is continuous, it is closed. Thus, it is a compact. But it can still be a line segment. Any reference are welcome. Thanks in advance.","['differential-topology', 'analysis', 'differential-geometry', 'multivariable-calculus']"
1283188,"Prove for each positive integer $n$, there exists $n$ consecutive positive integers none of which is an integral power of a prime number","Prove for each positive integer $n$, there exists $n$ consecutive positive integers none of which is an integral power of a prime number. I'm not getting a single idea of how to approach it. One I found was to show that $n$ consecutive integers should not be divisible by any prime but it didn't worked. Thanks in advance.",['number-theory']
1283195,"Can we determinine the convergence of $\int_0^\infty \frac{x^{2n - 1}}{(x^2 + 1)^{n + 3}}\,dx$ without evaluating it?","Can we determine convergence without evaluating this improper integral? $$\int_0^\infty  {\frac{x^{2n - 1}}{{\left( x^2 + 1 \right)}^{n + 3}}\,dx}\quad\quad n\geq 1\;,\; n\in\mathbb{Z}$$ When trying to bound the integrand, relating a known function, the integral does not converge. But when I use the software package Maple I see that the integral converges to:
$$\int_0^\infty  {\frac{x^{2n - 1}}{{\left( x^2 + 1 \right)}^{n + 3}}\,dx}=\frac{1}{{\left( {n + 1} \right)\left( {n + 2} \right)n}}$$ Evaluating it is not difficult, but I want to know if you can determine convergence (delimiting the integrand) without evaluating such an improper integral.","['calculus', 'real-analysis', 'improper-integrals', 'integration']"
1283210,Classification of all subrings,"Let $R$ be an integral domain whose underlying additive group is finitely generated free and whose field of fractions $K$ is a finite Galois extension of $\mathbb{Q}$. Is there a method of classifiying all subrings of $R$? Is there perhaps a variant of Galois theory? (Notice that I don't want to restrict to étale subrings!) For example, the subrings of $\mathbb{Z}[\sqrt{2}]$ should be $\mathbb{Z}[z \cdot \sqrt{2}]$ for $z \in \mathbb{Z}$, right? Here we also see that the subring structure is more complicated than the subgroup structure of the automorphism group.","['ring-theory', 'galois-theory', 'abstract-algebra', 'reference-request', 'algebraic-number-theory']"
1283230,When is the topological closure of an equivalence relation automatically an equivalence relation?,"Let $X$ be a topological space, not necessarily nice, let $R$ be a subspace of $X \times X$, and let $\overline{R}$ be the closure of $R$ in $X \times X$. Then: If $R$ is a reflexive binary relation on $X$, then $\overline{R}$ is also a reflexive binary relation on $X$. If $R$ is a symmetric binary relation on $X$, then $\overline{R}$ is also a symmetric binary relation on $X$. On the other hand, the following claim is false : If $R$ is an equivalence relation on $X$, then $\overline{R}$ is also an equivalence relation on $X$. Indeed, we could take $X = \mathbb{R}$ and 
$$R = \left\{ (x_0, x_1) \in \mathbb{R} \,\middle\vert\, \exists z \in \mathbb{Z} . -\frac{1}{2} \le x_0 - z < \frac{1}{2}, -\frac{1}{2} \le x_1 - z < \frac{1}{2} \right\}$$
in which case $\overline{R}$ fails to be a transitive binary relation. (Note that $X / R$ is indiscrete, so the smallest closed equivalence relation containing $R$ is $X \times X$ itself!) Of course, this cannot happen if $X$ is either discrete or indiscrete. What I would like to know is this: Question. What are some necessary or sufficient conditions on $X$ that ensure that the closure of an equivalence relation on $X$ is always an equivalence relation?","['equivalence-relations', 'general-topology']"
1283262,"Perturb a given smooth function to a Morse function relative to fixed level sets, which are already fine.","Let $M$ be a manifold (not necessarily compact) , for the sake of clearness embedded in $\mathbb{R^n}$ and $f\colon M\rightarrow \mathbb{R}$ a smooth function. The theorem of Sard gives us that $$f+\langle\ \cdot\ ,a\rangle \colon M\rightarrow \mathbb{R}, \ x\mapsto f(x)+a_1x_1+...+a_nx_n$$ is a Morse function for almost all $a\in\mathbb{R}^n$. Now suppose I have a finite set of regular values $c_1,...,c_n$ of $f$, so $f^{-1}(c_1),...,f^{-1}(c_n)$ do not contain critical points. Can I deform $f$ slightly to $\tilde f$, such that it becomes a Morse function, but the level sets of $c_1,..,c_n$ remain unchanged, i.e. $f^{-1}(c_i)=\tilde f^{-1}(c_i)$? This is somehow a relative version of the density of Morse functions in the space of smooth functions.","['morse-theory', 'real-analysis', 'manifolds', 'differential-topology', 'differential-geometry']"
1283263,What's so useful about diagonalizing a matrix?,"I'm told the the purpose of diagonalisation is to bring the matrix in a 'nice' form that allows one to quickly compute with it. However in writing the matrix in this nice diagonal form you have to express it w.r.t. a new eigenvector basis. But you'll probably want the answer of your matrix multiplication written w.r.t. to the original basis, so you'll have to do a not-nice matrix multiplication regardless. Example of what I  mean: I want to compute $Ax$, where $A$ and $x$ are given w.r.t. the standard basis ($\epsilon$). However $A$ is quite large and annoying to compute, so I calculate $A_E$ which is a diagonal matrix written w.r.t. the eigenvector basis. But to compute $Ax$ using this matrix, I still have to compute the following:
$$ _\epsilon S_E  A_E\ _E S_\epsilon$$
Where the $S$ are basis-transition matrices, and those are quite likely to be at least as ugly as our original $A$, so I don't see what we're gaining here. If anything this seems to be a lot more work. The only thing I can imagine being easier this way is computing something like $A^{10000}x$ or something, because $A^{10000}$ has a really easy form when $A$ is a diagonal matrix, while this would take forever if $A$ is not a diagonal matrix. But is this really the only purpose of diagonalisation; to compute things like $A^{10000}x$?","['linear-algebra', 'diagonalization']"
1283313,converge value of series $\sum_{n=0}^{\infty} \left( \frac{1}{n+d+1} - \frac{1}{n+5d+1} \right) $,"\begin{align}
\sum_{n=0}^{\infty} \left( \frac{1}{n+d+1} - \frac{1}{n+5d+1} \right) = \sum_{n=0}^{\infty}\frac{4d}{(n+d+1)(n+5d+1)}=
?
\end{align}
I know from the $p$-test, ($i.e$ $\sum \frac{1}{n^p}$ : $p>1$ series converges)
The above series converges. 
I want to know the exact value(or function) in terms of $d$.","['sequences-and-series', 'convergence-divergence', 'divergent-series']"
1283325,Questions about p-adic numbers,"I got two questions about $p$-adic numbers: I often read that the field $\mathbb Q_p$ is much different than the field $\mathbb R$. An element of $\mathbb Q_p$ is of the form $\sum_{i=-k}^{\infty}a_ip^i$ where $a_i\in \{0,...,p-1\}$. But isn't this just a real number? So at least the elements of $\mathbb Q_p$ are a subset of $\mathbb R$? That would mean that these fields are especially different in terms of their operation? Let $x\in \mathbb Q_p^*$. Why $x$ can be written uniquely like this: $x=p^na$ where $a$ is an element of the $p$-adic integers? Thanks in advance!","['abstract-algebra', 'p-adic-number-theory']"
1283337,Impact of weight of the dice,"If you throw a 6-sided die there is a probability of 1/6 to throw any specific value. However, this assumes that dice are exactly symmetrical, and we all know that they are not, in reality. Let's assume that the sides with more eyes weigh less , because the eyes are carved in the surface of the dice. Would that mean that the probability of throwing a 6 becomes bigger ?
At first sight, that seems to make sense, because the heavier side of the dice is impacted more by gravity . On the other hand, while the die makes a circular movement through the air, the heavier side is more likely to hit ground first . Assuming that a dice always roles after hitting the ground, that again makes it just a little less likely to actually finish in the position that it landed at. So, do you think that weight increases/decreases the probability ?","['probability', 'physics']"
1283378,Ordered Pairs (Ordering multiple elements),"I have been doing some reading on set theory and I have come across ""ordered pairs"". I understand that sets in general are unordered, and when we want to place them in a particular order we use the 'Kuratowski' definition to say, for example a pair of elements such as $(a,b)=\{(a),(a,b)\}$ which is why $a$ is the 'first entry' and $b$ the 'second entry'. I also understand that ordered pairs are very important and are the very definition of coordinate systems. What I want to understand is, say we wanted to order a set of $3,4...n$ elements, how would we do that, and why would we want to do that even at all? I've read that those are called ordered $n-tuples$, but they seemed to have just divided the set into two elements, bunching up all elements save one into a subset, how would we even interpret something like that? e.g $(a,b,c,...,z)=\{(a,b,c...,y), (z)\}$ That confuses me a little because you haven't really ordered anything. All you've done was make the last element $z$. The first $25$ elements are still ambiguous.",['elementary-set-theory']
1283393,Prove that $\int_S n\times r dS=0$,"If $r$ be the position vector of a point on a closed surface $S$ and $n$ be the unit normal (outward) vector to $S$, then prove that $$\int_S n\times r\,dS=0$$ Attempt: $r=xi+yj+zk$, $n=\frac{\nabla \phi}{|\nabla \phi|}$, where $\phi$ is the given surface. Then how to proceed? The form of $\phi $ is not given.","['geometry', 'vector-analysis', 'multivariable-calculus', 'vectors']"
1283413,Why does $a\cdot \cos(kx)+b\cdot\sin(kx)=\sqrt{a^2+b^2}\sin(kx+\phi)$ hold?,"I've just bought a book to learn how Laplace, Fourier- and z-transformation works and stumbled over \begin{align}
 a_k\cos(kx)+b_k\sin(kx)&=A_k \sin(kx+\varphi_k)\\
&= A_k[\sin(kx)\cos(\varphi_k)+\cos(kx)\sin(\varphi_k)]
 \end{align}
  Equating coefficients leads to
  $A_k \cos(\varphi) = b_k$ and $A_k \sin(\varphi)=a_k$. It follows:
  $A_k = \sqrt{a_k^2 + b_k^2}$ and $\tan(\varphi_k) = \frac{a_k}{b_k}$ I understand the part with equating the coefficients and why $\tan(\varphi_k) = \frac{a_k}{b_k}$ is true (because $\tan(\alpha) = \frac{\sin{\alpha}}{\cos(\alpha)}$ if $\cos(\alpha) \neq 0$). But I don't understand how they follow $A_k = \sqrt{a_k^2 + b_k^2}$. My thought was \begin{align}
A_k \cos(\varphi) = b_k \land A_k \sin(\varphi)=a_k\\
\Rightarrow (A_k \cos(\varphi))^2 + (A_k \sin(\varphi))^2 = b_k^2 + a_k^2\\
\Leftrightarrow A_k^2 (\cos(\varphi)^2 + \sin(\varphi)^2) = a_k^2 + b_k^2\\
\Leftrightarrow A_k^2 = a_k^2 + b_k^2\\
\Leftrightarrow A_k = \pm \sqrt{a_k^2 + b_k^2}\\
\end{align} Why is $A_k = - \sqrt{a_k^2 + b_k^2}$ not possible?","['analysis', 'trigonometry']"
1283448,$\sum \frac {1}{n^2 a_n}$ is divergent,Suppose $a_n\geq 0$ and $\sum a_n$ converges .Show that $\sum \frac {1}{n^2 a_n}$ is divergent I think that this inequality will going to help me. $\frac{1}{n^2a_n} \leq \frac{1}{n(na_n)} \leq \frac{1}{n} $,"['sequences-and-series', 'real-analysis']"
1283465,"Showing Sobolev space $W^{1,2}$ is a Hilbert space","I have the Sobolev space $W^{1,2}$ consisting of all continuous functions $f \in L^2(\mathbb{R})$ such that there exists an $f'$ with $f(b) - f(a) = \int_a ^b f'(t) dt$. $W^{1,2}$ has inner product $<f,g> = \int fg + f'g'$. I'm trying to show this is a Hilbert space but I'm having some difficulties. I can show that as $t \to+/-  \infty$ we must have $f(t) \to 0$ because $f$ is continuous. From this and using the relation $f(x)^2 = \int_{-\infty} ^x f(t)f'(t)$ I can obtain the estimate $||f||_{\infty} \le K||f||_{1,2}$ If we now take a sequence $f_n$ in $W^{1,2}$ such that $f_n \to f$ in $W^{1,2}$ norm. I want to show that in fact $f$ is in $W^{1,2}$. We know from the above estimate that $f_n \to f$ uniformly and hence $f$ is continuous and in $L^2$ so it remains to show that $f$ has the weak derivative property. I'm struggling to show this last part. I know that for each $f_n$ there is an $f_n'$ such that $f_n(b) - f_n(a) = \int_a ^b f_n'(t) dt$ but how can we show that these $f_n'$ converge to a derivative for $f$? Thanks for any help here!","['sobolev-spaces', 'functional-analysis']"
1283466,Showing planarity of graphs,"I am trying to show $G_3$ is planar. I have constructed $G'_3$ as shown. Is it correct to say that by the Jordan curve theorem, $G_3$ cannot be planar, as any drawing will cause edges to overlap. Therefore it is non-planar?","['planar-graphs', 'graph-theory', 'proof-verification', 'combinatorics']"
1283489,"Alternating Group $A_n$ does not have proper subgroup of index less than n, where n>4.","A proof is to be given for this. 
So what i have thought is:
Let us assume to the contrary, i.e. it does have a subgroup of index m (say) less than n.
Then, since $A_n$ is simple for n>4 , by embedding theorem, $A_n$  is isomorphic to a subgroup of $A_m$. 
but this is not possible as the order of $A_n$ (n!/2) does not divide the order of $A_m$ (m!/2) {since $m<n$}.
Is this reasoning correct?",['abstract-algebra']
1283494,Find the Derivative $ 7^{\ln x} $ using first principle,"I still can't figure this out, Question is Find the Derivative $ 7^{\ln(x)} $ using first principle This is where I got $$\lim_{h \to 0} \frac{7^{\ln(x+h)} -  7^{\ln(x)}}{h}  $$ then What should I do?","['calculus', 'limits']"
1283506,A extending the p-adic valuation to a quadratic extension of $\mathbb{Q}_p$,"I'm trying to solve the following problem. Prove that, if $d \in \mathbb{Z}_p$ is non-square, then
$|a + b \sqrt{d}|p = |a^2 − b^2d|^{1/2}_p$ , for any $a, b \in \mathbb{Q}p$,
defines a non-Archimedean valuation on $\mathbb{Q}_p(\sqrt{d})$ which extends the usual $|. |_p$ on $\mathbb{Q}_p$. The hint we are given is to show that $|\alpha|_p\le 1 \Rightarrow |\alpha +1|_p \le 1$. I've managed to reduce this to different cases, and the only case where I'm still having trouble $|a|_p=|b|_p$. Apparently I need to use Hensel's Lemma somehow, but I don't know how. Can anyone give me a hint?","['p-adic-number-theory', 'number-theory', 'valuation-theory']"
1283510,What does this vector notation really mean?,"With regard to vectors, how is this (form 1):
$$\begin{bmatrix}1\\2\\-1\end{bmatrix}$$
Different to this (form 2): 
$$\begin{bmatrix}1\ 2\ -1 \end{bmatrix}$$ I would think that the first set consists of magnitudes of the same variable (where simply the sum gives the magnitude), while the second refers to the coefficients of three different variables. In my book they take the magnitude of form 1 by $$\sqrt{1^2+2^2+(-1)^2}$$
That would indicate a set of vectors in different directions. So my question is; which of the two (rows or columns) give an indication of the variable or the vector direction / dimension?","['vectors', 'linear-algebra']"
1283536,Purely algebraic proof of the trigonometric inequalities,"While calculating various limits of trigonometric functions, one must resort to the squeeze theorem which is founded on the inequalities $$1 > \frac{\sin x}{x} > \cos x$$ for some ""small"" $x$. These inequalities are, however, always (to my knowledge) established geometrically by drawing various triangles and circles where one sees that they hold. Is there a purely algebraic proof of this inequalities, using only the properties of trigonometric functions and not relying on the underlying geometry?",['trigonometry']
1283551,Uniform Convergence on Compact Sets Means Uniform Convergence on the whole Set,"Let $\Omega\in Open(\mathbb{R}^n)$ for some $n\in\mathbb{N}_{\geq1}$. Then we know that $\exists \{K_n\}_{n\in\mathbb{N}_{\geq1}}$, a collection of compact sets, such that $\Omega = \bigcup_{n\in\mathbb{N}_{\geq1}}K_n$ and $K_n \subseteq int(K_{n+1})\forall n\in\mathbb{N}_{\geq1}$ (in particular, define $K_n := \{x\in\Omega\,|\,||x||\leq n\}\cap\{x\in\Omega\,|\,d(x,\,\Omega^c)\geq\frac{1}{n}\}$). Suppose there is a sequence of continuous functions $f_i:\Omega\to\mathbb{C}$ which we somehow know converge uniformly to the pointwise limit function $f$ on $K_n$, for all $n\in\mathbb{N}_{\geq1}$. Prove that $\{f_i\}$ then converges uniformly on $\Omega$. (This came up while studying Example 1.44 in Rudin's Functional Analysis--it is a fact which he takes for granted and I couldn't figure out why it holds)","['analysis', 'real-analysis', 'functional-analysis']"
1283605,Monotone convergence theorem assuming convergence in measure,"I have heard that the monotone convergence theorem holds, if the hypothesis of almost everywhere convergence is replaced by convergence in measure.
I concur; if $f_n$ converges in measure then there exists a subsequence of $f_n$ which converges to $f$ a.e. so that we can apply MCT for that subsequence but I couldn't see why the conclusion holds for the original sequence $f_n$ .","['lebesgue-integral', 'lebesgue-measure', 'real-analysis', 'functional-analysis']"
1283612,How can I go about solving this group of equations in as simple a way as possible?,"They arise from partial derivatives of the Lagrange multiplier function. Here below is the original problem: Goal function: 
  $$f(x,y,z)=\frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2} $$
  with two constraints: 
  $$
\begin{cases}
x^2+y^2+z^2-1=0 \\
Ax+By+Cz=0 
\end{cases}
$$
  provided that $a>b>c>0$ and $A^2+B^2+C^2=1$, determine all the possible extremums. My Lagrange function is 
$$L(x,y,z,\lambda,\mu):=f(x,y,z)+\lambda (x^2+y^2+z^2-1)+\mu (Ax+By+Cz)$$
From which naturally arises
$$
\begin{array}{c}
\partial L/\partial x =&2x/a^2+2\lambda x+A\mu=0 \\ 
\partial L/\partial y =&2y/b^2+2\lambda y+B\mu=0 \\ 
\partial L/\partial z =&2z/c^2+2\lambda z+C\mu=0 \\
\partial L/\partial \lambda =&x^2+y^2+z^2-1=0 \\
\partial L/\partial \mu =&Ax+By+Cz=0
\end{array}
$$
( Here I want to tag them $(1)$ to $(5)$ from top to bottom, but don't know how to write the Jax code. Is it possible to insert two or more tags into one array made up of several equations and can you help me with this?) I made some failed attempts to solve them. Every time I failed because I simply didn't know how to take off the coefficients leading $x,y,z$ terms. They might be zero, which really messed things up! For example, in $(1)$ I got $2x(\frac{1}{a^2}+\lambda)+A\mu=0$ but I don't know whether $(\frac{1}{a^2}+\lambda)$ is zero or not. And for $(1)$ to $(3)$, well, I got three uncertain cases. To make things worse, I also could not determine whether $A,B,C$ or $\mu$ is zero or not.... Too many possibilities! which really freaked me out.. So, except the case-by-case discussion about the $A,B,C$ and $\lambda,\mu$, is there a possible way (or trick) to find all the possible solutions for $(x,y,z)$ without much pain? I really need some enlightening. Any useful hint or help that sheds a light on this problem will be appreciated, thanks in advance!","['lagrange-multiplier', 'calculus', 'multivariable-calculus']"
1283618,Simplify the expression (combination and factorial),Simplify the following expression: $\binom{n+1}{3} * \frac{(n-1)! + (n-2)!}{(n+1)!}$ My attempt: $\binom{n+1}{3} * \frac{(n-1)! + (n-2)!}{(n+1)!} = \frac{(n+1)!}{3!(n+1-3)!} * \frac{(n-1)! + (n-2)!}{(n+1)!} = \frac{(n+1)!}{3!(n-2)!} * \frac{(n-1)! + (n-2)!}{(n+1)!}$ and this is where I get stuck... How to continue? When I put $\binom{n+1}{3} * \frac{(n-1)! + (n-2)!}{(n+1)!}$ into Wolfram Alpha it simplifies it into: $\frac{n}{6}$ When I put $\frac{(n+1)!}{3!(n+1-3)!} * \frac{(n-1)! + (n-2)!}{(n+1)!}$ into Wolfram Alpha it simplifies it into: $\frac{1}{6} * (n^{3} - n +1)$,"['combinations', 'factorial', 'combinatorics']"
1283671,Which term is bigger? $\sqrt[102]{101}$ or $\sqrt[100]{100}$,Which term is bigger? $\sqrt[102]{101}$ or $\sqrt[100]{100}$ I tried AM-GM but didn't succeed.,"['number-comparison', 'algebra-precalculus', 'inequality']"
1283686,"Is $\{\varnothing\}$ a subset of $\varnothing$, the empty set?","Formed a table for a competitive exam: $\begin{array}{cc}
\text{True} & \text{False} \\
\hline
\varnothing\subseteq\varnothing & \varnothing \in \varnothing\\
\varnothing\subseteq\{\varnothing\} & \,\\
\varnothing\in\{\varnothing\} & \{\varnothing\}\in\varnothing\\
\{\varnothing\}\subseteq\{\varnothing\} & \{\varnothing\}\in\{\varnothing\}
\end{array}$ I wish to know if $\{\varnothing\} \subseteq \varnothing$?",['elementary-set-theory']
