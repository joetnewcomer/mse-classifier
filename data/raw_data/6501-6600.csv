question_id,title,body,tags
48704,Intersection of open and compact,"In a metric space let $A$ be compact and $B$ - open, dense everywhere. Does it mean that
$$
\overline{A} = \overline{A\cap B}
$$
or there are counterexamples?","['general-topology', 'real-analysis']"
48709,"What is the definition of a ""predictable process""?","I am reading a book on financial mathematics, and frequently encounter the phrase ""predictable process"", which I haven't seen definition of, and cannot find the definition online. At first I thought that this was referring to a process which is known exactly at $t = 0$, but that is not the case, because then I see decomposition of an $(\mathcal F_t)_{t\in\mathbb N}$-adapted process $(X_t)$ into a martingale process $(M_t)$ and a predictable process $(A_t)$ where $$
\begin{eqnarray}
M_0 = 0, &\hspace{10mm} &\Delta M_t = M_t - M_{t-1} = X_t - E(X_t|\mathcal F_{t-1}) \\
A_0 = 0, &\hspace{10mm} &\Delta A_t = A_t - A_{t-1} = E(X_t|\mathcal F_{t-1}) - X_{t-1}
\end{eqnarray}
$$ so it seems like $A_t$ can only be predicted at $t-1$.  Is that what a ""predictable process"" is?","['statistics', 'stochastic-processes', 'finance']"
48713,Product of slopes is -1 iff perpendicular proof from first principles,"Once again I'm working through Stillwell's Four Pillars of Geometry .  I'm on Chapter 3 where he first introduces coordinates.  The question reads, 3.5.1 Show that lines of slopes $t_1$ and $t_2$ are perpendicular just in case $t_1t_2=-1$. I read that as, ""Line 1 and Line 2 Perpendicular $\Leftrightarrow$ $t_1t_2=-1$"".  From what I've tried I can say that using contrapositives isn't very useful since in algebra having something not equal something else doesn't tell you much. I also tried assuming you could move out from the intersection by 1 on both lines.  Then draw two right triangles and go from there.  (So, both hypotenuses being 1 and sides $a$ and $b$.)  I couldn't finish this idea - there are a couple cases, and it involves ""moving"" the intersection to the origin which, although allowable, isn't quite allowed yet in Four Pillars Is there an elegant way to show 3.5.1 ? Questions about the question will be promptly answered in the comments!","['analytic-geometry', 'geometry', 'euclidean-geometry']"
48714,"$A$ and $B$ disjoint, $A$ compact, and $B$ closed implies there is positive distance between both sets.","Claim: Let $X$ be a metric space. If $A,B\subset X$ are disjoint, $A$ is compact, and $B$ is closed, then there is $\delta>0$ so that $ |\alpha-\beta|\geq\delta\;\;\;\forall\alpha\in A,\beta\in B$ . Proof . Assume the contrary. Let $\alpha_n\in A,\beta_n\in B$ be chosen such that $|\alpha_n-\beta_n|\rightarrow0$ as $n\rightarrow \infty$ . Since $A$ is compact, there exists a convergent subsequence of $\alpha_n\;(n\in\mathbb{N})$ , $\alpha_{n_m}\;(m\in\mathbb{N})$ , which converges to $\alpha\in A$ . We have $$|\alpha-\beta_{n_m}|\leq|\alpha-\alpha_{n_m}|+|\alpha_{n_m}-\beta_{n_m}|\rightarrow0 \;\;\;as\;\;m\rightarrow\infty.$$ Hence $\alpha$ is a limit point of $B$ and since $B$ is closed $\alpha\in B$ , contradiction. Is my proof correct? I feel as though I am missing something simple which would trivialize the proof.","['general-topology', 'metric-spaces', 'compactness', 'solution-verification']"
48740,$\int_{0}^{\infty}\frac{dx}{1+x^n}$,"My goal is to evaluate $$\int_{0}^{\infty}\frac{dx}{1+x^n}\;\;(n\in\mathbb{N},n\geq2).$$ Here is my approach: Clearly, the integral converges. Denote the value of the integral by $I_n$. Now let $\gamma_R$ describe the section of a circle which goes from the origin to $R$ to $Re^{2\pi i/n}$ and back to the origin. If we let $C_R$ denote the relevant circular arc, then 
$$\left|\int_{C_R}\frac{dz}{1+z^n}\right|\leq \left(\frac{2\pi R}{n}\right)\left(\frac{1}{R^{n}-1}\right)\rightarrow0\;\;\;as\;\;R\rightarrow\infty.$$ Furthermore, $$\int_{[R,Re^{2\pi i/n}]}\frac{dz}{1+z^n}=\int_{R}^{0}\frac{e^{2\pi i/n}dr}{1+r^n}.$$ Hence $$\lim_{R\rightarrow\infty}\int_{\gamma_R}\frac{dz}{1+z^n}=\lim_{R\rightarrow\infty}\int_{[0,R]}\frac{dx}{1+x^n}+\int_{[R,Re^{2\pi i/n}]}\frac{dx}{1+x^n}+\int_{C_R}\frac{dx}{1+x^n}=(1-e^{2\pi i/n})I_n\;\;\;(1).$$ Thus if we can obtain the value of $\int_{\gamma_R}\frac{dz}{1+z^n}$ we can evaluate $I_n$. Now the zeroes of $1+z^n$ are of the form $z=e^{i\pi/n+2\pi  i m/n}\;\;(m\in\mathbb{N})$ from which it is clear that the only zero which lies within the contour occurs at $z=e^{i\pi/n}$ with multiplicity 1.
So all that remains to be done is to evaluate the residue of $\frac{1}{1+z^n}$ at $z=e^{i\pi/n}$. However, if $z=e^{i\pi/n}u$ and $u\neq1$, we have
$$\frac{z^n+1}{z-e^{i\pi/n}}=\frac{1-u^n}{-e^{i\pi/n}(1-u)}
=-e^{-i\pi/n}\sum_{m=0}^{n-1}u^m\;\;\;(2).$$ In particular, (2) implies $$Res_{z=e^{i\pi/n}}\frac{1}{1+z^n}=-\frac{e^{i\pi/n}}{n}\;\;\;(3).$$ Finally, (1) and (3) imply 
$$I_n=\frac{2\pi i (Res_{z=e^{i\pi/n}}\frac{1}{1+z^n})}{1-e^{2\pi i/n}}=\frac{-2\pi ie^{i\pi/n}}{n(1-e^{2\pi i/n})}=\frac{\pi/n}{\sin(\pi/n)}.$$ I have three questions: One, is my method correct? Two, is there a simpler/different method to evaluate the integral? Three, is there an easier way to evaluate the residue of $\frac{1}{1+z^4}$ at $z=e^{i\pi/n}$?",['complex-analysis']
48746,Existence of non-constant continuous functions with infinitely many zeros [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: A nontrivial everywhere continuous function with uncountably many roots? Does there exist a continuous non-constant real-valued function on $[a,b]$ that has infinitely many zeros?   If one does exist, please give me an example.",['real-analysis']
48748,"How to prove the cofactor formula for determinants, using a different definition of the determinant?","So, I am very interested on this theorem (Laplace expansion), but I am still a high school student. I have four books about matrices, but only one of them have proo and that doesn't start with my definition of determinant. Also I don't understand the proof of Laplace expansion in wikipedia, because there is too much symbol and terms I didn't learn and that proof dosn't start with my definition. So may someone give me the outline of the proof start with my definition? Here's my definition of the $n \times n$ determinant: The value of the determinant of a matrix of order $n$ is defined as the sum of $n!$ terms of the form $(-1)^k a_{1 i_1} a_{2 i_2} \cdots a_{n i_n}$. Each term contains one and only one element from each row and one and only element from each column; i.e., the second subscripts $i_1, i_2 , \ldots, i_n$ are equal to $1,2, \ldots, n$ taken in some order. The exponent $k$ represents the number of interchanges of two elements necessary for the second subscripts to be placed in the order $1,2, \ldots, n$. For example, consider the term containing $a_{13} a_{21} a_{34} a_{42}$ in the evaluation of the determinant of a matrix of order four. The value of $k$ is $3$ since three interchanges of two elements are necessary for the second subscripts to be placed in the order $(1,2,3,4)$.","['matrices', 'linear-algebra']"
48750,Finding the real roots of a polynomial,"Recent posts on polynomials have got me thinking. I want to find the real roots of a polynomial with real coefficients in one real variable $x$. I know I can use a Sturm Sequence to find the number of roots between two chosen limits $a < x < b$. Given that $p(x) = \sum_{r=0}^n a_rx^r$ with $a_n = 1$ what are the tightest values for $a$  and $b$ which are simply expressed in terms of the coefficients $a_r$ and which make sure I capture all the real roots? I can quite easily get some loose bounds and crank up the computer to do the rest, and if I approximate solutions by some algorithm I can get tighter. But I want to be greedy and get max value for min work.","['approximation', 'numerical-methods', 'algebra-precalculus', 'polynomials']"
48752,Derive $\frac{d}{dx} \left[\sin^{-1} x\right] = \frac{1}{\sqrt{1-x^2}}$,"Derive $\frac{d}{dx} \left[\sin^{-1} x\right] = \frac{1}{\sqrt{1-x^2}}$ (Hint: set $x = \sin y$ and use implicit differentiation) So, I tried to use the hint and I got: $x = \sin y$ $\frac{d}{dx}\left[x\right] = \sin y\frac{d}{dx}$ $\frac{dx}{dx} = \cos y \frac{dy}{dx}$ $\frac{dy}{dx} = \frac{1}{\cos y}$ $\frac{dy}{dx} = \sec y$ From here I need a little help. Did I do the implicit
differentiation correctly? How do I use this to help with
the original question?","['trigonometry', 'calculus']"
48771,Help with simultaneous equation with additional term,"I hoped someone can help me with 3 simultaneous equations with an additional condition. I can easily solve the following 3 equations using substitution in terms of $S_1$, $S_2$ and $S_3$""
$$\begin{align*}
\text{Eq 1)} &\qquad& (O_{1}-1)S_1 - S_2 - S_3 &= 0.5P\\
\text{Eq 2)} && (O_{2}-1)S_2-S_1-S_3 &= 0.29P\\
\text{Eq 3)} && (O_{3}-1)S_3-S_1-S_2 &=0.21 P
\end{align*}$$ However, I'm struggling to solve these same equations with an additional condition
$$\text{Eq4)}\qquad S_1+S_2+S_3 = T.$$ Essentially, I want to be able to specify $T$ and calculate the values required for $S_1$, $S_2$ and $S_3$ to make Eq1 50% , Eq2 29% and Eq3 21% of the total. $O_1$, $O_2$, & $O_3$ are known; $P$ = Eq1+Eq2+Eq3 Any advice is appreciated, thanks. (this is not homework!)",['algebra-precalculus']
48772,Number of real solutions of a random equation,"Let $(J_{ij})$ be an $n \times n$ random matrix with i.i.d Gaussian centered coefficients with $\displaystyle \mathbb{E}[J_{ij}^2] = \frac{\sigma^2}{n}$. Let the random variable $A_n(\sigma)$ defined as the number of real solutions in $\mathbb{R}^n$ of :
$$-x_i + \sum_{j=1}^n J_{ij} \phi(x_j) = 0\mbox{ for all }1\leq i \leq n$$
where $\phi(x) = \arctan(x)$. The question is :  what is the law of $A_n(\sigma)$ ? In particular, its expectation ? I know how to solve ""by hand"" the case n=1, and n=2, but then it becomes really painful. Any idea? Thank you! Edit : I have a conjecture but I do not know if it is true: $$\lim_{n \to \infty} \frac{1}{n}\log \mathbb{E}[A_n(\sigma)] = C(\sigma)$$
with $C(\sigma)=0$ for $\sigma <1$ and $C(\sigma)=O((\sigma-1)^2)$ for $\sigma \to 1^+$. What do you think of this?","['geometry', 'linear-algebra', 'probability']"
48773,Understanding this partial derivative problem,"Problem: Considering $x$ and $y$ as independent
   variables, find $\dfrac{\partial
 r}{\partial x}, \dfrac{\partial
 r}{\partial y}, \dfrac{\partial
 \theta}{\partial x}, \dfrac{\partial
 \theta}{\partial y}$ when $x = e^{2r}
 \cos \theta, y = e^{3r} \sin \theta$ . Solution: First differentiate the given
   relations with respect to $x$ : $1 = 2e^{2r} \cos \theta
 \dfrac{\partial r}{\partial x} - e^{2r}
 \sin \theta \dfrac{\partial
 \theta}{\partial x}$ and $0 =
 3e^{3r}\sin \theta \dfrac{\partial
 r}{\partial x} + e^{3r} \cos \theta
 \dfrac{\partial \theta}{\partial x}$ . Then solve simultaneously to obtain $\dfrac{\partial r}{\partial x} =
 \dfrac{\cos \theta}{e^{2r}(2+\sin^{2}
 \theta)}$ and $\dfrac{\partial
 \theta}{\partial x} = - \dfrac{3 \sin
 \theta}{e^{2r}(2+sin^2 \theta)}$ Question: (1)
So first of all, why does differentiating with respect to $x$ result in $\dfrac{\partial r}{\partial x}$ and $\dfrac{\partial \theta}{\partial x}$ (by the way what are these called?)? Is this because the problem says "" $x$ and $y$ as independent variables"" ? My initial reaction was to do $r$ and $\theta$ separately while regarding all other variables as constants... This is implicit (partial?) differentiation, right? How should I understand what is being done here? A lot of times it seems that things like this turn out to really just be a mapping. Can I think of this that way as well? I couldn't even say what the domain and codomain would be... Whenever I perform this operation, do I just take partial derivatives of both sides treating all independent variables (other than the variable with respect to which I am differentiating) as constants and all non-independent (dependent?) variables as variables that need to be differentiated and will have that partial derivative symbol? Once I accept that I can see how they got the first implicit partial differentiation (if that's what it is called). (2)
What do they mean by ""solve simultaneously"" ? I tried to solve for each (again I don't know what they're called yet) ""partial differential"" resulting in: $$\dfrac{\partial \theta}{\partial x} = -\dfrac{\sin \theta \frac{\partial r}{\partial x}}{\cos \theta}$$ and $$\dfrac{\partial r}{\partial x} = \dfrac{1+e^{2r}\sin \theta \frac{\partial \theta}{\partial x}}{2e^{2r}\cos \theta}$$ But I couldn't get the same answer... I tried to substitute this further, but looking at that answer, I was sure I was missing something... Could somebody please show me what to do? Thank you in advance for any help!",['multivariable-calculus']
48776,Capacity theory beginner resources,"I'm currently studying a book on shape optimization: Variation et optimisation de formes: Une analyse géométrique By Antoine Henrot, Michel Pierre . The book introduces at some point capacity, and uses this to define quasi-open sets, quasi continuous functions, and these results apply very nice to approximation theorems in Sobolev spaces. As a remark, this is one of the few mathematical concepts I searched on Google, and found nothing like a wikipedia article or some sites which contain good knowledge about this subject in a beginner's terms. The capacity is defined for compact sets first like this: For $K\subset \Bbb{R}^N$ compact, we denote $cap(K)=\inf \{ \|v\|_{H^1(\Bbb{R}^N)}^2 : v \in C_0^\infty(\Bbb{R}^N),\ v \geq 1 \text{ on }K\}<\infty$. $C_0^\infty$ is the space of smooth functions with compact support. From here, capacity extends to open sets, by taking the supremum on the capacities of compact sets contained in an open set. The relative capacity is defined for a compact $K$ subset of a bounded open set $D\subset \Bbb{R}^N$ by $cap_D(K)=\inf\{ \int_D |\nabla v|^2 : v \in C_0^\infty(D),\ v \geq 1 \text{ on }K\}<\infty$. I understood pretty well the Lebesgue measure by finding a way to visualize it (surely, this is not hard). I would like to know if there is something similar for capacity. How could I visualize it or understand it? How it relates to the physical reality? For example, what does the capacity of a ball or box in $\Bbb{R}^3,\Bbb{R}^n$ mean (for Lebesgue measure is the ""volume"")? I would like to know if there are some books which treat the capacity subject in a manner like measure theory books do it, with many proved properties and some study problems to understand it better. How can I understand capacity related to some physical aspect (shape, smoothness, finess...)? What are some good references for a beginner in the field?","['book-recommendation', 'self-learning', 'partial-differential-equations', 'reference-request', 'functional-analysis']"
48779,Computing an integral where the poles of the integrand are the roots of unity,I am trying to compute the following integral: $$\int_0^{2\pi} \frac{y}{y^n-1} dy$$ I've tried to decompose $y^n-1$ into $(y-1)(y-e^{i\theta})(y-e^{i2\theta})...(y-e^{i(n-1)\theta})$ but I don't know what to do with this factorization. I've read some others similar questions with the answers but I don't know if the same methods apply.,"['definite-integrals', 'complex-analysis']"
48798,Fourier series at discontinuities,"I was reading about Fourier series and have a doubt concerning it. The book I am reading from does not seem to help. As I understand, $\{e_0=\frac{1}{\sqrt{2}},e_1=sin(x),e_2=cos(x),e_3=sin(2x),e_4=cos(2x)\cdots\}$ is a basis for the inner product space of piecewise continuous functions in $[-\pi,\pi]$ with inner product $<f,g>=\frac{1}{\pi}\int_{-\pi}^{\pi}f\bar g$. Hence any function in this space may be represented by $f=\sum_{k=0}^{\infty}<f,e_k>e_k$. My question is what happens at points of discontinuity x. As f is identical with the series (which by the way is unclear to me as to why it coverges) shouldn't f(x) be identical with the series at x, i.e. $f(x)=\sum_{k=0}^{\infty}<f,e_k>e_k(x)$. But Dirichlet's theorem (stated without proof in my book) says that at points of discontinuity, the series $\sum_{k=0}^{\infty}<f,e_k>e_k(x)$ converges to $\frac{f(x-)+f(x+)}{2}$ and not to f(x). Why is this so? Thanks.","['fourier-series', 'analysis']"
48800,Finite Sets and Unions,"I came across the following problem on finite sets: If $A_1, \dots, A_m$ is a finite list of finite subsets of a set, show that $A_1 \cup \dots \cup A_m$ is also finite. By definition, for each positive integer $j=1, \dots, m$ there is a positive integer $r_j$ and a surjection $\sigma_j: \{1, \dots, r_j \} \to A_j$. Let $r = r_1 + \cdots + r_m$. Then we want to construct a surjection $\sigma: \{1, \dots, r \} \to A$. Now if $x \in A$, then $$x \in A_1 \ \text{or} \ x \in A_2 \ \text{or} \ \dots \ \text{or} \ x \in A_m$$ Note that the or is inclusive. So perhaps we can construct the surjection by saying that if $x \in A_i$ and only one $A_i$ for $i = 1, \dots, m$ then use the ""individual surjections"" pertaining to $A_i$. For example, if $x \in A_3$ only then there is a number $f$ in $\{1, \dots, r_3 \}$ such that $\sigma_3(f) = x$. How do we get to the case where $x$ is in an intersection of sets? For example if $x \in A_1 \cap A_2$ then we would have to consider a surjection that involved $\{1, \dots , r_1\}$ and $\{1, \dots, r_2 \}$.",['elementary-set-theory']
48808,Shortest sequence containing all permutations,"Given an integer $n$, define $s(n)$ to be the length of the shortest sequence $S = (a_1, \cdots a_{s(n)})$ such that every permutation of $\{1,\cdots,n\}$ is a subsequence of $S$. If $n=1$, then $S = (1)$ is the shortest sequence containing all permutations of $\{1\}$, so s(1) = 1.  If $n=2$, then $S = (1, 2, 1)$ contains all permutations of $\{1,2\}$ as a subsequence, so $s(2)=3$. Is there a general formula for $s(n)$?","['permutations', 'sequences-and-series', 'combinatorics']"
48810,Differential Equations Flow-chart/genealogical diagram?,"There are many methods to solve differential equations. There are many kinds of equations, different orders, linear, non-linear, homogeneous, exact, the other kind of homogeneous etc. I would like to know of any diagrams that organize equations in to families by the best suited solution method. Or maybe a genealogical diagram, or even a flow chart. Something that gives the ""big picture"" on all these methods and types of equations. Is there any such digram? If not how would you organize it? (the goal is for the diagram to assist one in choosing a method for solving, while at the same time clarifying the similarities and difference between equations. Something like the diagram that shows the real, imaginary, natural  and complex numbers, perhaps: Of course it would be more complex... and it might fill a wall, but I'm OK with that.","['ordinary-differential-equations', 'partial-differential-equations']"
48815,Agreement of $q$-expansion of modular forms,"If I have modular functions $f$ and $g$ with $f = a_{1} + a_{2}q + \cdots$ and $g = b_{1} + b_{2}a + \cdots$ both $q$-expansions, why does/how does it follow $f = g$ after checking only finitely many terms?","['modular-forms', 'number-theory']"
48828,"How to prove that from ""Every infinite cardinal satisfies $a^2=a$"" we can prove that $b+c=bc$ for any two infinite cardinals $b,c$?","Prove that if $a^2=a$ for each infinite cardinal $a$ then $b + c = bc$ for any two infinite cardinals $b,c$. I tried $b+c=(b+c)^2=b^2+2bc+c^2=b+2bc+c$, but then I'm stuck there.","['cardinals', 'elementary-set-theory']"
48843,"Are the fractional parts of $\log \log n!$ equidistributed or dense in $[0,1]$?","Are there any results relevant to the distribution of the sequence $\{\log \log n!\}$ for integers $n$, where $\{x\}$ denotes the fractional part of $x$? For instance, it is known that for irrational real numbers $\alpha$, the sequence $\{n\alpha\}$ is dense in $[0,1]$ and in fact equidistributed. Does something similar hold for the logarithms of the logarithms of the factorials? (This curiosity is provoked by this question , and an affirmative answer here would complete the answer to that question.)","['dynamical-systems', 'equidistribution', 'reference-request', 'number-theory']"
48850,"Continuity of the function $x\mapsto d(x,A)$ on a metric space","Let $(X,d)$ be a metric space. How to prove that for any closed $A$ a function $d(x,A)$ is continuous - I know that it is even Lipschitz continuous, but I have a problem with the proof: 
$$
|d(x,a) - d(y,a)| \leq d(x,y)
$$
for any $a\in A$ - but we cannot just replace it by $|d(x,A) - d(y,A)|\leq d(x,y)$ since the minimum (or infimum in general) can be attained in different points $a\in A$ for $x$ and $y$, so we only have that
$$
|d(x,A)-d(y,A)|\leq d(x,y)+\sup\limits_{a,b\in A}d(a,b)
$$
which does not mean continuity.","['metric-spaces', 'continuity', 'real-analysis']"
48854,Connectedness in Zariski topology,"How to show that, for example, the Zariski topology of a cyclic group ring (thus $\mathbb{Z}[\rho]/(\rho^n-1)$) is connected?
Does this still hold for an Abelian group?
Or in general, how do we determine the connected components for such spaces? (Is it by searching its smallest prime ideals? If so, can you give an explicit example?)
Note that it's not a domain, which makes it not necessarily an irreducible space.
Many thanks.
[edit: it seems that I only need to show there's no idempotent element in this group ring, is that right?]","['commutative-algebra', 'algebraic-geometry']"
48865,Find angle subtended by overlapping circles [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Solving $2x - \sin 2x = \pi/2$ for $0 &lt; x &lt; \pi/2$ I need a little nudge for this problem. I have figured out everything but the last bit(albeit the most important!). Two equal circles of radii $a$ intersect and the common chord subtends an angle of $2\theta$ radians at either center. Find an expression for the area of the region common to the two circles. If this area is equal to half the area of either circle, estimate the value of $\theta$ which satisfies this equation Using the sector area formula, I found the area of the minor segment = $\dfrac{1}{2}a^2(2\theta - \sin 2\theta)$ Hence area of overlapping region = $a^2(2\theta - \sin 2\theta)$ Since this area is half of either circle, $a^2(2\theta - \sin 2\theta) = \dfrac{1}{2}\pi a^2$ Simplifying further, I got, $\sin 2\theta = 2\theta - \dfrac{\pi}{2}$ This is how far I have gotten. I don't know how to solve this equation. Can you guys help? Thanks again.","['trigonometry', 'algebra-precalculus']"
48871,Differential Equation,"Suppose Ms. Lee is buying a new house and must borrow 150,000. She wants a 
30-year mortgage and she has two choices. She can either borrow money at 7% per 
year with no points, or she can borrow the money at 6.5% per year with a charge of 
3 points. (A ""point"" is a fee of 1% of the loan amount that the borrower pays the 
lender at the beginning of the loan. For example, a mortgage with 3 points requires 
Ms. Lee to pay 4,500 extra to get the loan.) As an approximation, we assume that 
interest is compounded and payments are made continuously. Let $$M(t) = \text{amount owed at time } t\ \left(\text{measured in years}\right)$$
$$r= \text{annual interest rate, and}$$
$$p= \text{annual payment}$$ Then the model for the amount owed is $$ \frac{dM}{dt}=rM-p$$ Q.How much does Ms Lee has to pay in each case? I have tried solving the DE, and i get $$ M(t)=C_1e^{rt} + \frac{p}{r}$$ Now what to do?",['ordinary-differential-equations']
48874,An integral identity,"In the science paper labelled ""Effect of Fermi surface geometry on electron-electron scattering"", by Hodges, Smith and Wilkins, there is a following identity: $$ \int_{0}^{ \infty}dx\int_{0}^{ \infty}dz f(z)\left[ 1- f(x) \right]\left[ 1- f(t+z-x)\right] = \frac{1}{2}(\pi ^2 + t^2)\left[ 1- f(t)\right] $$ where $$f(x) = \frac{1}{e^x + 1}$$ Now, can anyone tell me is there some fancy way to prove it, without the ""brute- force"" method. Thanks.","['calculus', 'integration']"
48881,How to prove completeness of the Spherical Harmonics,"Laplace's spherical harmonics ""form a complete set of orthonormal functions and thus form an orthonormal basis of the Hilbert space of square-integrable functions"" [1] .  I have three related questions about this statement: (1) I can prove their orthonormality, but how do you prove that they form a complete set? (2) What does completeness mean for an set with an infinite number of elements? (3) How does the assertion that the spherical harmonics form an orthonormal basis of the Hilbert space of square-integrable functions follow from their being a complete set of orthornormal functions?","['spherical-harmonics', 'calculus', 'group-theory']"
48892,Getting the determinant value of the original matrix from its upper triangular matrix,"Sometimes when finding the upper triangular of a matrix, I may just happen to switch rows to make the whole process shorter. Say for this matrix:
$$
A=\begin{bmatrix}
1 & -1 & -1\\ 
3 & -3 & 2\\ 
2 & 1 & 1
\end{bmatrix}
$$ The determinant of it is $\left | A \right | = -5$. Then to find the upper triangular matrix of A, I thought maybe switching row2 and row 3 would make the process simpler. So I did this:
$$
\begin{bmatrix}
1 & 0 & 0\\ 
0 & 0 & 1\\ 
0 & 1 & 0
\end{bmatrix}\cdot A=\begin{bmatrix}
1 & -1 & -1\\ 
2 & -1 & 1\\ 
3 & -3 & 2
\end{bmatrix}
$$
And I let this be B this way: $B=\begin{bmatrix}
1 & -1 & -1\\ 
2 & -1 & 1\\ 
3 & -3 & 2
\end{bmatrix}$. I figure out the elementary rows:
$$
E_{21} = \begin{bmatrix}
1 & 0 & 0\\ 
-2& 1 & 0\\ 
0 & 0 & 1
\end{bmatrix}, 
E_{31} = \begin{bmatrix}
1 & 0 & 0\\ 
0 & 1 & 0\\ 
-3 & 0 & 1
\end{bmatrix}
$$ Multiply the elementary row matrices to the matrix $B$:
$$
E_{31}\cdot E_{21}\cdot B=
\begin{bmatrix}
1 & -1 & -1\\ 
0 & 1 & 3\\ 
0 & 0 & 5
\end{bmatrix}
$$ Now I got the upper triangle of matrix B, which is also the upper triangle of matrix $A$.
Then I do a check on its determinant: $1\cdot 1\cdot 5=5$. To my surprise, I get $5$ instead of $-5$! I realise that this is because $\left | B \right | = 5$. But since I had a row exchange to get the upper triangle, how can I make sure that its determinant is also the same as its original matrix $A$, which should be $-5$? I thought this is quite important because sometimes I use this to find the determinant value of higher dimension matrices. Thanks for any help.","['matrices', 'linear-algebra']"
48896,Differential equation with a constant in it,"Solve $$y'' + s^2y = b \cos sx$$ where $s$ and $b$ are constants.  I have tried undetermined coefficients, but it makes such a mess that I keep getting lost, I also tried variation of parameters. Really my issue is staying organized enough to get the solution, my solutions are always just a little off from the book. I have solved the complementary homogenous equation, this gave me a solution with $\cos{sx}$ in it... So that's off limits in the particular solution. I looked for a solution in $x \sin{sx}$ and $x \cos{sx}$, but as I said, it was a mess. I wonder if I'm just going about it all wrong. Related to this, why will variation of parameters sometimes produce a term that is a solution to the homogenous case? Thanks",['ordinary-differential-equations']
48897,Power Series with the coefficients $n!/(n^n)$,"I'd be grateful if someone could tell me how to obtain the convergence radius of the aforementioned power series.
Or, by Cauchy Hadamard, the limit of
$(n!/(n^n))^{(1/n)}$ as n approaches infinity.
Thanks, Paul I tried the quotient criteria, but since the quotient of two consecutive coefficients is not bounded by any value strictly smaller than 1, it didn't yield a result.","['power-series', 'convergence-divergence', 'real-analysis']"
48911,Solving for the center of mass of a Semi Circle (without integration) [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Solving $2x - \sin 2x = \pi/2$ for $0 &lt; x &lt; \pi/2$ For fun, I was trying to solve this problem without doing calculus.  After dinking around with it for a while, I came across the following term and don't quite know how to solve it without guessing: $$a - \sin{(a)} = \frac{\pi}{2}$$ Where $a$ will be the angle of the chord that will allow me to solve for the height - in theory :)","['trigonometry', 'algebra-precalculus']"
48912,Category of isomorphism classes?,"Is there such a thing as a category of isomorphism classes of, say, modules? First step in definining morphisms in such a category would be to identify two morphisms $f:M\rightarrow N$ and $f':M'\rightarrow N'$ if there are isomorphisms $i:M\simeq M'$ and $j:N\simeq N'$ such that $j\circ f=f'\circ i$.
But this equivalence realtion doesn't satisfy  properties like $$f\sim g\implies f\circ h\sim g\circ h,$$
so I don't know how to compose two morphisms in such a category.
This question arose because Ext and Tor (or derived functors in general) depend on the choice of resolutions, though not so modulo isomorphism classes. They don't seem to be functors in the standard sense, but a ``functor from isomorphism classes to isomorphism classes.''","['homology-cohomology', 'category-theory', 'abstract-algebra']"
48917,Linear system of divisors,"Let $F:X \rightarrow \mathbb{C}_{\infty}$ be a nonconstant holomorphic map with X a Riemann surface.. How could I show that the divisors $F*(q)$ for $q \in \mathbb{C}_{\infty}$ form a pencil? $F*(q)$ here is the inverse image divisor. I am not quite sure how to do this to be honest, any help would be appreciated.","['riemann-surfaces', 'algebraic-geometry']"
48923,A question about subsets,"The question is from the following multiple choice problem: Let $A$ and $B$ be subsets of a set $M$ and let $S_0=\{A,B\}$ . For $i\geq 0$ , define $S_{i+1}$ inductively to be the collection of subsets $X$ of $M$ that are of the form $C\cup D$ , $C\cap D$ , or $M-C$ (the complement of $C$ in $M$ ), where $C,D\in S_i$ . Let $S=\cup_{i=0}^{\infty}S_i$ . What is the larest possible number of elements of $S$ ? A. 4 B. 8 C. 15 D. 16 E. $S$ may be infinite. It seems that this might be related to the "" $\sigma$ -algebra"". But I have no idea what technique one needs to solve this problem. I tried some finite set, e.g., $\{0,1,2,3,4,5\}$ and let $A=\{0\}$ , $B=\{1\}$ . But I cannot find any pattern in the example. Any ideas how to solve it? Also, I have a question: Is this just a trivial exercise for testing some knowledge? Or is there a big picture behind the problem? Edit: As the answer suggested, I draw the picture. However, unless I finally enumerate all the 16 possibilities and cannot get more, I cannot convince myself that the answer is D. Any quick way to do this?",['combinatorics']
48938,"Deriving the rest of trigonometric identities from the formulas for $\sin(A+B)$, $\sin(A-B)$, $\cos(A+B)$, and $\cos (A-B)$","I am trying to study for a test and the teacher suggest we memorize $\sin(A+B)$,  $\sin(A-B)$, $\cos(A+B)$, $\cos (A-B)$, and then be able to derive the rest out of those. I have no idea how to get any of the other ones out of these, it seems almost impossible. I know the $\sin^2\theta + \cos^2\theta = 1$ stuff pretty well though. For example just knowing the above how do I express $\cot(2a)$ in terms of $\cot a$? That is one of my problems and I seem to get stuck half way through.",['trigonometry']
48946,Do these series converge to the von Mangoldt function?,"Jeffrey Shallit formulated this recurrence for me:
$\displaystyle T(n,1)=1, k>1: T(n,k) = \sum\limits_{i=1}^{k-1} T(n-i,k-1)-\sum\limits_{i=1}^{k-1} T(n-i,k)$ which is the lower triangular array equal to 1 if k divides n, 0 otherwise. By changing the recurrence so that it takes values from either the vertical or horizontal direction: $\displaystyle T(n,1)=1, T(1,k)=1, n>=k: -\sum\limits_{i=1}^{k-1} T(n-i,k), n<k: -\sum\limits_{i=1}^{n-1} T(k-i,n)$ we get this array starting: $$\displaystyle T = \left(   \begin{array}{ccccccc}   +1&+1&+1&+1&+1&+1&+1&\cdots \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&-2&+1&+1&-2&+1 \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&+1&+1&-4&+1&+1 \\ +1&-1&-2&-1&+1&+2&+1 \\ +1&+1&+1&+1&+1&+1&-6 \\ \vdots&&&&&&&\ddots \end{array}   \right)
$$ Do the series $\displaystyle \sum\limits_{k=1}^{\infty}\frac{T(n,k)}{k}$ $\;$ converge to the Mangoldt function $\Lambda(n)$? http://mathworld.wolfram.com/MangoldtFunction.html Edit 14.7.2011, added Mathematica program: Clear[t]; 
nn = 100; 
mm = 15; 
t[n_, 1] = 1; 
t[1, k_] = 1; 
t[n_, k_] := 
t[n, k] = 
If[n < k, 
If[And[n > 1, k > 1], Sum[-t[k - i, n], {i, 1, n - 1}], 0], 
If[And[n > 1, k > 1], Sum[-t[n - i, k], {i, 1, k - 1}], 0]]; 
a = Table[Table[t[n, k], {k, 1, mm}], {n, 1, nn}]; 
b = Range[1, nn]; 
c = a/b; 
MatrixForm[c]; 
d = N[Table[Total[c[[All, i]]], {i, 1, mm}]] 
d[[1]] = 0; 
mangoldt = Exp[d] 
mangoldtexponentiated = Round[Exp[d]] that outputs the sequence: $1, 2, 3, 2, 5, 1, 7, 2, 3, 1, 11, 1, 13, 1, 1...$
which is the Mangoldt function exponentiated. Edit 9.2.2014: Just for memory: $$\varphi (n) = 
 n\lim\limits_ {s \rightarrow 1}\zeta (s)\sum\limits_ {d | n}\mu (d) (e^{1/d})^{(s - 1)}$$ $$a(n) = \lim\limits_{s \rightarrow 1} \zeta(s)\sum\limits_{d|n} \mu(d)(e^{d})^{(s-1)}$$ $$\Lambda(n) =\sum\limits_{k=1}^{\infty} \frac{a(GCD(n,k))}{k}$$ $$\Lambda(n)=\lim\limits_{s \rightarrow 1} \zeta(s)\sum\limits_{d|n} \frac{\mu(d)}{d^{(s-1)}}$$ $$\text{Fourier Transform of } \Lambda(n) \sim \sum\limits_{n=1}^{n=k} \frac{1}{n} \zeta(1/2+i \cdot t)\sum\limits_{d|n} \frac{\mu(d)}{d^{(1/2+i \cdot t-1)}}$$ Edit 3.3.2014: Just for memory:
Mathematica: nn = 12;
mm = nn;
MatrixForm[
 Chop[N[Total[
    Transpose[
     Table[Table[
       If[Mod[n1, k1] == 0, 
        Table[(Table[
             Sum[Exp[-a*b/n*2*Pi*I], {b, 1, n}], {a, 1, mm}]), {n, 1, 
            nn}][[n1/k1]]*MoebiusMu[n1/k1], 0], {k1, 1, nn}], {n1, 1, 
       nn}]]]]]] Edit 14.9.2014: Just for memory:
Conjectured formula from Dirichlet characters: nn = 12;
b = Table[Exp[MangoldtLambda[Divisors[n]]]^-MoebiusMu[Divisors[n]], {n, 1, nn}];
j = 1;
MatrixForm[Table[Table[Product[(b[[n]][[m]] * DirichletCharacter[b[[n]][[m]], j, k] - (b[[n]][[m]] - 1)), {m, 1, Length[Divisors[n]]}], {n, 1, nn}], {k, 1, nn}]]
(* Conjectured expression as Dirichlet characters. Mats Granvik, Nov 23 2013 *) Just for memory (18.1.2015) : A = Table[Table[If[Mod[n, k] == 0, 1, 0], {k, 1, 12}], {n, 1, 12}];
B = Table[
   Table[If[Mod[k, n] == 0, MoebiusMu[n]*n, 0], {k, 1, 12}], {n, 1, 
    12}];
MatrixForm[A.B] Just for memory (20.1.2015): nn = 42
Z = Table[Table[If[Mod[n, k] == 0, 1, 0], {k, 1, nn}], {n, 1, nn}];
A = Table[Table[If[Mod[n, k] == 0, k, 0], {k, 1, nn}], {n, 1, nn}];
B = Table[
   Table[If[Mod[k, n] == 0, MoebiusMu[n], 0], {k, 1, nn}], {n, 1, nn}];
MatrixForm[T = Z.A.B];
T[[All, 1]] = 0;
a = Table[Total[Total[T[[1 ;; n, 1 ;; n]]]], {n, 1, nn}]
a = Table[Total[Total[T[[1 ;; n, 1 ;; n]]]]/n, {n, 1, nn}]
g1 = ListLinePlot[a];
b = Accumulate[MangoldtLambda[Range[nn]]];
g2 = ListLinePlot[b];
Show[g1, g2] Relation to square roots: nn = 32;
A = Table[
   Table[If[Mod[n, k] == 0, Sqrt[k], 0], {k, 1, nn}], {n, 1, nn}];
B = Table[
   Table[If[Mod[k, n] == 0, MoebiusMu[n]*Sqrt[n], 0], {k, 1, nn}], {n,
     1, nn}];
MatrixForm[A.B]","['sequences-and-series', 'number-theory']"
48954,Theorem on behaviour of real continuous functions on the integers,"I tried (and still try) to prove that $\sin (\log n)$ doesn't have a limit at $\infty$.
I know it is enough to show that a subsequence of $\log n$ approaches, modulo $2\pi$, arbitrarily close to 2 distinct values $\alpha, \beta$ (such that $\sin \alpha \neq \sin \beta$), which is a much weaker statement than ""$\ \frac{\log n}{2\pi}$ is equidistributed modulo $1$"" (which is even false...). My questions are: How do you prove my specific case? Is there a general theory of limit of $f \circ g (n)$ where $f$ is a periodic continuous function and $g$ is continuous, (possibly monotone increasing) function diverging to $\infty$ at $\infty$? What is a good source about equidistribution?","['equidistribution', 'sequences-and-series', 'real-analysis']"
48955,The conformal map $f(z)=\frac{1}{2}\left(z+\frac{1}{z}\right)$,"I want to show that $f(z)=\frac{1}{2}\left(z+\frac{1}{z}\right)$ is a conformal map from the set of $z$ such that $0<|z|<1$ onto $\mathbb{C} \setminus [-1,1]$. I find that $f'(z)=\frac{(z+1)(z-1)}{2z^2}$ so this means that $f$ is conformal except for $z=1$ or $z=-1$ which is ok since they're not in the domain of $f$. So $f$ is a conformal mapping. Now for $z=re^{i\theta}$, we find $w=\frac{1}{2}\left(z+\frac{1}{z}\right)=re^{i\theta}+\frac{e^{-i\theta}}{r}$ which gives $u=(r+\frac{1}{r})\frac{cos(\theta)}{2}$ and $v=(r-\frac{1}{r})\frac{sin(\theta)}{2}$. When we compute we end up with $\frac{u^2}{(r+1/r)^2} + \frac{v^2}{(r-1/r)^2}=\frac{1}{4}$ which means that circles about the origin, i.e  the ones such that $|z|<1$ are mapped to ellipses. Finally if $[-1,1]$ were in the image then this means that the unit circle has been mapped by $f$ since would take $r=1$ which implies $-1<u<1$ ($v=0$ here). Is the exercise complete or do I need to add more justification as to why $f$ maps the punctured interior of the unit disc to the whole plane? EDIT: I corrected the typo in the equation of the ellipse, it should be $\frac{1}{4}$ like in Zarrax's answer",['complex-analysis']
48958,Proof of the polynomial division algorithm,"The theorem which I am referring to states: for any $f, g$ there exist $q, r$ such that $f(x)=g(x)q(x)+r(x)$ with the degree of $r$ less than the degree of $g$ if $g$ is monic. The book I am using remarks that it can be proven via induction on the degree of $g$, but leaves the proof to the reader. Unfortunately, this reader is not clever enough to get it. The base case is fairly clear, but I'm completely stuck after that. Any hints?","['induction', 'abstract-algebra', 'polynomials']"
48961,Laplacian of a Smooth Function $f(\vec x) = 1/\|\vec x \|$ for $\| \vec x \| \geq 1$,"This is a multivariable calculus problem from a past prelim exam. I have an answer for this written up (posted below), but it seemed rather time-intensive. If there is a slicker way to approach this problem, I'd appreciate seeing it. Thanks! Recall that for a smooth function $f: \mathbb{R}^3 \to \mathbb{R}$, the Laplacian of $f$ is defined by
  $$ \Delta f = \nabla \cdot ( \nabla f). $$ Suppose that $f: \mathbb{R}^3 \to \mathbb{R}$ is a smooth function satisfying $f(\vec{x}) = 1/\|\vec{x}\|$ for $\|\vec{x}\| \geq 1$. Verify that $\Delta f(\vec{x}) = 0$ for $\|\vec{x}\| \geq 1$. Compute $\int_{\mathbb{R}^3} \Delta f \, dV$.",['multivariable-calculus']
48974,Linear Algebra: finding a basis for a subspace of $\mathbb{R}^4$,So I am stuck on this example from my Into. Linear Algerbra book I'm not exactly sure how I'm supposed to find the basis in this case. Am I just supposed to use a random t and s value and call the single vector a basis? (There were no previous examples in the book that were similar) Thank you,['linear-algebra']
48980,Finding an analytic function given the real/imaginary part,"I want to check if there is (or not) an analytic function on $\mathbb{C}$ \ ${0}$ such that $Im(f)=78+x^2-5y^6- \frac{5y}{3(x^2+y^3)}$. What I thought of doing is first applying the Identity Theorem which guarantees the uniqueness of the analytic function (if it really exists), so I just set $x=z$ and let $y=0$. So I would get $f(z)=u(z,0)+iv(z,0)$. If $f$ is analytic then by the Cauchy-Riemann equations, we get $v_x=2x=-u_y$ and $v_y=0=u_x$. So $u$ does not depend on $x$, which contradicts that $u_y=-2x$. So there is no such analytic function by the Identity Theorem. Is it that easy or did I just do complete nonsense by first applying the Identity Theorem then going to the partial derivatives? Can I do that? Thx.",['complex-analysis']
48989,"How to prove $\text{Rank}(AB)\leq \min(\text{Rank}(A), \text{Rank}(B))$? [duplicate]","This question already has answers here : How to prove and interpret $\operatorname{rank}(AB) \leq \operatorname{min}(\operatorname{rank}(A), \operatorname{rank}(B))$? (9 answers) Closed 9 years ago . How to prove $\text{Rank}(AB)\leq \min(\text{Rank}(A), \text{Rank}(B))$?","['matrices', 'linear-algebra', 'inequality', 'matrix-rank']"
48992,The floor of $\sqrt{2x}+1/2$ is the ceiling of $(\sqrt{1+8x}-1)/2$,"I've been working on this for a while now and I can't figure out how to prove it:
$$\left\lfloor \sqrt{2x} + \frac{1}{2}\right\rfloor = \left\lceil \frac{\sqrt{1+8x}-1}{2}\right\rceil.$$ Here $x$ is an integer.","['radicals', 'algebra-precalculus', 'ceiling-and-floor-functions']"
48993,How quickly we forget - basic trig. Calculate the area of a polygon,"I think the easiest way to do this is with trigonometry, but I've forgotten most of the maths I learnt in school.  I'm writing a program (for demonstrative purposes) that defines a Shape, and calculates the interior angles of the shape, based on the number of sides. Now I'm trying to calculate the area based on the length of each of those sides. So given a square, we know it has 4 sides.  And given that the length of each of those sides is 8, we should be able to calculate the area (I know a square is easy... but the same formula needs to work for polygons with more/less sides). What I've done, is this: Calculated the interior angles in the polygon as interior_angle = 180 - (360 / num_sides) . Divided the polygon into an equal number of isosceles triangles and then divided each of those into 2 right-angled triangles, assuming this simplifies the logic.  This is where I'm stuck. Since the interior angle of the polygon is known, I've divided that by 2 in order to get the angle on one corner of these triangles, knowing that there's another angle of 90º.  So my logic tells me: # Polgygon: sides = 4, length = 8
interior_angle = 180 - (360 / sides) = 90
a = interior_angle / 2 = 45
# Given that tan(a) = height / base
base = length / 2 = 4
tan(a) = height / base
# therefore
height = tan(a) * base = tan(45) * 4 This gives me 6.47 as the height (I think that's wrong... shouldn't it just be a round 3?). Now to get the area of the entire polygon, I just have to calculate the area of each triangle and multiple that by the number of sides: area = 0.5 * height * length * sides For my 8 * 8 square, this gives me 51.83 , so I've clearly got my logic wrong.  If there's a simpler way to calculate the area of a uniform polygon, based on the number of sides and the length of each side, please educate me :)  I just need to convert the maths into code for a computer program.","['geometry', 'trigonometry']"
49002,gradient vector of composition of functions,"Let $U \subset \mathbb{R}^n$ be open and let $f:U \to \mathbb{R}$ and $h:\mathbb{R}\to \mathbb{R}$ be differentiable functions. How can I prove the following equation?
$$\nabla{(h\circ f)}(P)=h'(f(P))\nabla f(P)$$",['multivariable-calculus']
49003,order statistics,I would like to understand the relationship between the asymptotic moments of order statistics and the moments of the distribution of the mother distribution. I will appreciate any references on this matter.,['statistics']
49015,Poincare-Hopf Theorem,"I need to show that if we put a closed curve on earth's surface, number of maxima plus number of minima inside it will be equal the number of saddle points plus 1. A hint was to use Poincare-Hopf Theorem. The problem with this is that Poincare-Hopf requires that on the boundaries the vector field should be pointing inwards. For example, as in the image I attached, some vectors point inwards and some point outwards. Also, what bothers me is that in the image that is attached, there is one maxima, one minima, but no saddle points (or maybe the drawing is decieving?), so what I was asked to show seems not hold. Any hints or directions will be appreciated .","['general-topology', 'analysis']"
49020,Rotating a rectangle,"Lets say we have a rectangle with height h and width w . If we rotate it by d degrees , what would be the width and height of the window to display it without any clipping? I mean what is the formula to calculate wh and ww ?",['trigonometry']
49029,Pointwise topology embedding,"First let $\Lambda$ be the bijective mapping between $Y^{Z \times X}$ and $(Y^X)^Z$ defined as follows: every mapping $f: Z \times X \to Y$ defines a set of mappings from $X$ to $Y$: for each $z \in Z$ is $f_z:X \to Y$ defined as $f_z(x) = f(z,x)$. The mapping $z \mapsto f_z$ of $Z$ to $Y^X$ obtained this way we denote as $\Lambda(f)$. Engelking calls this the exponential mapping. Then he goes on to define a topology on $C(X, Y)$ called the pointwise topology as the restriction of the product topology on $Y^X$ restricted to $C(X,Y)$. We can also see that this is equal to the topology generated by the subbasis
$$\{M(x, U) : x \in X \text{ and $U$ open in $Y$}\},$$
where $M(x,U) := \{f \in C(X,Y) : f(x) \in U\}$. So now I can finally ask the question I want to ask... Give $C(X,Y)$, $C(Z \times X, Y)$ and $C(Z, C(X, Y))$ the pointwise topology. How do I now show that $\Lambda:C(Z \times X, Y) \to C(Z, C(X,Y))$ is an embedding? I'm drowning in a syntax mess. I don't need a full solution a road map is fine.",['general-topology']
49033,"Simplifying trigonometric expressions, is there a unified theory?","$\frac{1}{3}\cos^3 x \cos(2x)+\frac{1}{12}\sin(2x)(\sin(3x)+3\sin x)=\frac{1}{3} \cos x$ I got this as the result of a differential equation that I solved. The answer in the book is (1/3) cos(x), but after applying variation of parameters I got the expression on the left. To my delight Wolfram Alpha tells me that they are equal! (yay!!) But, without cheating and using the computer, how would I ever know that? Nothing about my expression screams ""simplify me"" unless I'm missing something. Perhaps I'd notice the graph looked like cosine if I happened to graph it. I know many trig identities, but I have never heard of a formal procedure that always works to simplify. Is there such a thing? How would you approach this messy expression? How can I get better at this important skill? I have more problems to solve and it feels cheap to keep plugging my answers in to W.alpha to see if they are right. Ps. Is there a widget to convert thing formatted for mathematical to latex and vice versa?","['trigonometry', 'ordinary-differential-equations']"
49038,"Is $\mathbb{R}(X+Y)\subseteq\mathbb{R}(X,Y)$ a purely transcendental extension?","Is there a nice, short and elementary argument that the field extension $\mathbb{R}(X+Y)\subseteq\mathbb{R}(X,Y)$ is purely transcendental? Obviously, $\mbox{tr deg}_{\mathbb{R}(X+Y)}\mathbb{R}(X,Y)\le1$, because $\mathbb{R}(X+Y)\subseteq\mathbb{R}(X+Y,Y)=\mathbb{R}(X,Y)$, so it is left to show that $Y$ is not algebraic over $\mathbb{R}(X+Y)$. I don't see any nice proofs of this fact, only some brute force methods of summing degrees of powers of $Y$ in polynomials from $\mathbb{R}(X+Y)[\mathbb{X}]$. Similar question concerns the transcendence degree of the extension $\mathbb{R}(X^2+Y^2)\subseteq\mathbb{R}(X,Y)$. This extension is not purely transcendal (an easy proof using automorphisms from Galois group). $X$ is algebraic over $\mathbb{R}(X^2)$, so again $\mbox{tr deg}_{\mathbb{R}(X^2+Y^2)}\mathbb{R}(X,Y)\le1$, because $\mathbb{R}(X^2+Y^2)\subseteq\mathbb{R}(X^2+Y^2,Y)=\mathbb{R}(X^2,Y)\subseteq\mathbb{R}(X,Y)$. But how to show that $Y$ is not algebraic over $\mathbb{R}(X^2+Y^2)$? I don't know algebraic geometry, thus please don't use it in your answer.","['abstract-algebra', 'field-theory']"
49058,Galois ring extension,"Is there an analogous theory to Galois extension of fields for commutative rings? In particular, what does it mean for a ring extension to be Galois?
Thanks.","['galois-theory', 'commutative-algebra', 'ring-theory', 'abstract-algebra']"
49078,Counting paths of a variable length on a directed graph,"If I've been given a directed Graph $G = (V,E)$ and its adjacency matrix $A$. How do I calculate how many (directed) paths do exist from one specific node to another (specific) one? In general $a_{v,w}^{(n)}$ which is the n -th power of the entry $a_{v,w}$ of $A$ is the answer I am looking for (for the amount of pathes of the length $n$ from node $v$ to node $w$). But how do I determine an explicit formula for a variable n? Thank you in advance!","['matrices', 'graph-theory']"
49079,What does the notation $\binom{n}{i}$ mean?,"What do the parentheses next to the summation involving the binomial coefficients mean? Like this:
$$\sum  _{i=0}^{n} \binom{n}{i}a^{(n-i)}b^i=\left(a+b\right)^n $$","['notation', 'algebra-precalculus', 'binomial-coefficients', 'discrete-mathematics']"
49080,To prove there exist two relatively prime numbers in a finite set. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Prove that in any set of $n+1$ positive numbers not exceeding $2n$ there must be two that are relatively prime.",['combinatorics']
49090,Probability of Drawing a Card from a Deck,"I like to play Magic: The Gathering, and I'm interested in calculating the probability of certain things in the game. After drawing 7 cards from a 60 card deck, what is the probability that draw will contain at least one of x, where x is a card having y copies? My best effort has been with the following formula: $$
\binom{y}{1}\binom{60 - y}{6}/\binom{60}{7}
$$ There are deck analyzers that will generate the answer for a simple 7-card draw (I'm wanting to get the formula though). Our answers are the same for y=1, but they start to deviate for y=2, y=3, etc. which has put some doubt in this formula. What's the proper way to solve this?",['probability']
49091,Negative 1 to the power of Infinity,Can anyone explain me what the result of $$\lim_{n\rightarrow\infty} (-1)^n$$ is and the reason?,"['exponentiation', 'infinity', 'limits']"
49097,integrals inequalities,"$$
\left( {\int\limits_0^1 {f^2(x)\ \text{d}x} }\right)^{\frac{1}
{2}} \  \geqslant \quad \int\limits_0^1 {\left| {f(x)} \right|\ \text{d}x} 
$$ I can't prove it )=",['integration']
49110,"sequence lemma, relaxing some hypothesis of a theorem","I know that if I have a sequence $ x_n \to x,$ where $ x_n  \in A,$ then $x$ is a limit point of $A.$ But the converse is not always true, at least in the case of a first countable space, if so. The question is: Is this condition of being first countable necessary? or it´s possible to relax even more this condition?",['general-topology']
49134,Tricky integral $\int_{a}^{b}\frac{\gamma d \gamma}{\gamma + \phi_{1}(\mu)-e^{-\frac{\phi_{2}(\mu)}{\gamma}}}$,"in this integral $a=\psi_{1}(\mu), \ b=\psi_{2} (\mu)$. I expanded the function in Taylor series (3 terms) around ($\gamma= \frac{b}{2}$), numerically (for varioud values of $\mu$, and other constants I didn't include here for better readability/simplicity) it gave a fairly good approximation (although a bit worse than Simpson/Riemann quadrature). When I solve this integral symbolically though, both Taylor series expansion and its integration are just gigantic ($ \approx 20$ terms). If anyone could help me out with simplification of this expression, I'd massively appreciate it. This is an expectation of the first hitting time.","['special-functions', 'calculus', 'integration']"
49135,Is every field of characteristic zero a divisible group (under addition)?,"I am convinced about this, directly from the definition, but I found it strange that I could not find a reference. Every field of characteristic zero contains $\mathbb{Q}$ and hence given and natural number $n$ and any element field element, say $g$, we can write $f=g*\frac{1}{n}$ and then, $nf=g$. Am I doing something wrong here?","['group-theory', 'abstract-algebra']"
49137,Summation formula name,"What is the name of the following summation formula? $$\sum_{k = 1}^n f(k)) = \int_1^{n + 1} f - \frac{f(n + 1) + f(0)}2 + \int_1^{n + 1} f'w,$$ where $w$ is the “sawtooth” function, defined by $w(x) = (x – (k + 1/2))$, for $k < x <= k + 1$, if $k$ is an integer. From this formula one can obtain the sum of the first $n$ $k$-th powers. No guessing is necessary, you just turn the crank. However, you have to start at 1 and work your way up. So, if you want the formula for the sum of the first $n$ cubes, say, then you first use this formula to find the formula for the sum of the first $n$ 1-st powers, and then use all this information to find the formula for the sum of the first $n$ squares, and then, finally, use all this information to find the formula for the sum of the first $n$ cubes. I’ve been calling it Gauss’s Summation Formula, but attributions are often variable, and there might be a more appropriate one that I should be using. I got taken to the woodshed over this. Here is the woodshed link: Prove that $\sum\limits_{k=1}^nk^2 = \frac{n(n+1)(2n+1)}{6}$?","['sequences-and-series', 'calculus', 'reference-request', 'terminology']"
49139,Second differential at extremum,"As we learned in calculus, if a function $f:\mathbb{R} \rightarrow \mathbb{R}$ is twice differentiable, and has a local maximum at point $x_0$, then $f'(x_0) = 0$ and $f''(x_0) \leq 0$. In addition, it's not hard to show. What I have trouble with is the higher dimensional analogue: Let $f:\mathbb{R}^n \rightarrow \mathbb{R}$ be twice differentiable, and has a local maximum at $x_0\in \mathbb{R}^n$, then $Df(x_0) = 0$ and $D^2f(x_0) \leq 0$ (i.e. the symmetric matrix $-D^2f(x_0)$ is positive semidefinite).",['multivariable-calculus']
49144,Characterization of normed vector spaces of finite dimension,"I have this problem: Let $E$ be a normed vector space. $S=\{x\in E : ||x||=1\}$. Show that if $S$ is compact then $\dim E$ is finite. This follows directly from the Riesz's lemma, but in the notes of the course, the hint for this exercise is: ""The set $\{x\in E: a\leq ||x||\leq b\}$ is homeomorphic to the set$[a,b]\times S$, for $b>a>0$."" How can I use this to solve the problem? Here a homeomorphism is a function $f$ between metric spaces $E$ and $E'$, bijective, and such that $f$ and $f^{-1}$ are continuous. And then, $E$ is homeomorphic to $E'$ if there exist a homeomorphism $f:E\to E'$.","['normed-spaces', 'metric-spaces', 'analysis']"
49145,$ \cos(\hat{A})BC+ A\cos(\hat{B})C+ AB\cos(\hat{C})=\frac {A^2 + B^2 + C^2}{2} $,"What more can be said about the identity derived from law of cosines (motivation below)$$ \cos(\widehat{A})BC+ A\cos(\widehat{B})C+ AB\cos(\widehat{C})+=\frac {A^2 + B^2 + C^2}{2} \tag{IV}$$ RHS seems as if operator $\cos(\widehat{\phantom{X}})$ is being applied consecutively to terms of ABC, I tried to represent it in an analogous way to the Laplacian operator convention, but maybe there are more common ways of representing RHS using some operator and sigma notation ( please let me know if there is). My question is : Are there any identities/structures relating or looking similar to IV, I apologize if this looks like a general fishing expedition question but I can not think of anything more that I can add to this post at this stage. Thank you Motivation for IV, Let $A,B,C$ be a triangle. Let $\widehat{C}  = \widehat{AB}$ stand for the Angle opposite to side C between the sides A and B, then the law of cosines for all three sides can be written as $$ A^2 + B^2 - 2 AB\cos(\widehat{C}) = C^2 \tag{I} $$ 
$$ A^2 + C^2 - 2 AC\cos(\widehat{B}) = B^2 \tag{II} $$ 
$$ B^2 + C^2 - 2 BC\cos(\widehat{A}) = A^2 \tag{III} $$ 
Adding $I ,II,III$ and juggling the terms we get : $$  AB\cos(\widehat{C})+AC\cos(\widehat{B})+BC\cos(\widehat{A}) =\frac {A^2 + B^2 + C^2}{2} \tag{IV} $$","['trigonometry', 'reference-request']"
49161,Nesting functions to understand nesting series,"So I am working on a problem that involves an expression that has a ""nested"" sigma notation. Maybe ""nested"" isn't the correct word, because you start with an input (of your choosing) and the output becomes the input for the next iteration. So it's like a recursive sequence. I am almost positive that this has been studied before. Not because I've heard of it, but because it's too simple of an idea to not have been studied before. (I could be wrong.) If, instead of a series, we had a function, then this function ""nested"" 3 times would look like $f(f(f(x)))$. I am looking to generalize this to any type of function nested any number of times. To give a simple example of what I mean: if we have $f(x)=ax+b$, then, $f(x)$ ""nested"" $N$ times with starting value $X$ can be generalized as $$Xa^N+b((1-a^N)/(1-a))$$ 
If anybody can provide with generalizations (or links to generalizations) for trigonometric, exponential, quadratic, polynomial, etc. functions, like the one I have provided, it would be of most help. Thank you. EDIT: Also, if these types of generalizations have been made for series (in sigma notation would be even better) that would just be, as you say, ""icing on the cake"". :) Thanks.","['recursive-algorithms', 'functions']"
49169,Why $\sqrt{-1 \times -1} \neq \sqrt{-1}^2$? [duplicate],"This question already has answers here : Why $\sqrt{-1 \cdot {-1}} \neq \sqrt{-1}^2$? (14 answers) Closed 10 years ago . We know $$i^2=-1 $$then why does this happen?
$$
i^2 = \sqrt{-1}\times\sqrt{-1}
$$
$$
=\sqrt{-1\times-1}
$$
$$
=\sqrt{1}
$$
$$
= 1
$$ EDIT: I see this has been dealt with before but at least with this answer I'm not making the fundamental mistake of assuming an incorrect definition of $i^2$.","['complex-numbers', 'algebra-precalculus', 'fake-proofs']"
49189,If the law of large numbers holds then the increments are integrable,Let $X_{i}$ be independent and identically distributed random variables such that $S_n/n\to 0$ almost surely where $S_n=X_1+\dots+X_n$. How to prove that $E|X_1|<\infty$ and therefore $EX_1=0.$,['probability-theory']
49190,Plücker Relations,"Let $K$ be a field, $1 \leq d \leq n$ integers and $V$ an $n$-dimensional vector space. The Plücker relations are quadratic forms on $\wedge^d V$ whose zero set is exactly the set of decomposable vectors in $\wedge^d V$ (i.e. which are of the form $v_1 \wedge ... \wedge v_d$), thus describing the ideal corresponding to the Plücker embedding $\text{Gr}_d(V) \to \mathbb{P}(\wedge^d V)$. But in every book I've read so far, these Plücker relations are constructed by means of many identifications between duals, exterior powers, etc. so that I am not able to write them down explicitely. Although I've tried it, many signs and sums confuse me. Question. Is it possible to write down these Plücker relations explicitely as a set of polynomials in the ring $K[\{x_H\}]$, where $H$ runs through the subsets of $\{1,...,n\}$ with $d$ elements? (Of course it is possible, but I wonder how do this in general) Edit : Following the answer below, here is the Answer : Instead of using these subsets $H$, use indices $1 \leq i_1 < ... < i_d \leq n$, and extend the definition of $x_{i_1,...,i_d}$ to all $d$-tuples in such a way that $x_{i_1,...,i_d}=0$ if these $i_j$ are not pairwise distinct, and otherwise $x_{i_1,....,i_d} = sign(\sigma) \cdot x_{i_{\sigma(1)},...,i_{\sigma(d)}}$, where $\sigma$ is the unique permutation of $1,...,d$ which makes $i_{\sigma(1)} < ... < i_{\sigma(d)}$. Then the Plücker relations are $\sum\limits_{j=0}^{d} (-1)^j x_{i_1,...,i_{d-1},k_j} * x_{k_0,...,\hat{k_j},...,k_d} = 0$ for integers $i_1,...,i_{d-1},k_0,...,k_d$ between $1,...,n$.","['linear-algebra', 'projective-geometry']"
49206,Fourier series of almost periodic functions and regularity,"Let $f$ a $2\pi$-periodic function represented by its Fourier series $\displaystyle\sum_{k=-\infty}^{+\infty}c_ke^{ikx}$. We know that $f$ is smooth if we have $\displaystyle\lim_{|n|\to +\infty}|c_n|n^k =0$ for all $k\in\mathbb{N}$; if $f$ is $C^k$ we have $\displaystyle\lim_{|n|\to +\infty}n^k|c_n|=0$ and if $c_n =o\left(\dfrac 1{|n|^{k+2}}\right)$ then $f$ is $c_k$. The space of almost periodic functions is the closure for the uniform norm of $\mathrm{Span}\left\{e^{i\lambda x},\lambda\in\mathbb R\right\}$. We define 
$$a(\lambda,f) := \lim_{T\to +\infty}\dfrac 1{2T}\int_{-T}^Tf(t)e^{-i\lambda t}dt$$ and if we put $C:=\left\{\lambda\in\mathbb{R},a(\lambda,f)\neq 0\right\}$, then $C$ is at most countable and we can associate a series $\displaystyle\sum_{\lambda\in C}a(\lambda,f)e^{i\lambda t}$. The numbers $a(\lambda,f)$ are the Fourier coefficients of $f$ and $\lambda\in C$ the Fourier exponents. The question is: are there some properties of the Fourier coefficients and exponents which allow us to ""read"" the regularity of an almost periodic function?","['fourier-series', 'analysis']"
49208,$f\colon I\rightarrow G$ and Gromov $\delta$-hyperbolicity,"Please recall that $\left|\int_0^1 f(t)\,dt -w\right|\leq \int_0^1|f(t)-w|\,dt$. In general, let $(X,d)$ be a metric space. Given a function $f:I\to X$ let $m_f\in X$ be such that $d(m_f,w)\leq \int_0^1 d(f(t),w)\,dt$ for every $w\in X$. If such $m_f\in X$ exists then we call $f$ as $D$-integrable with $D$-integral $m_f$. ($I=[0,1]$.) Question: Given a finitely generated group $G$ (with a usual word distance), does there exist a condition on the set of $D$-integrable functions $f: I\to G$ (which uses $D$-integrability) for the Gromov $\delta$-hyperbolicity of $G$? I.e, what is the characterization of hyperbolicity in terms of $D$-integrability? (It seems to me that the real question here should be: how can one extract group theoretic intel from $D$-integrability?)","['calculus', 'group-theory', 'metric-spaces']"
49221,A subset of a transitive set is transitive,"Given a transitive set$$a,$$ I can prove that $$\bigcup a$$ is also transitive, but I don't quite like my method because I must first prove $$a \subseteq \mathcal{P}(\bigcup a)$$ to get at $$\bigcup a\subseteq \mathcal{P}(\bigcup a).$$ Could you please show me a smarter proof?",['elementary-set-theory']
49229,Why can ALL quadratic equations be solved by the quadratic formula?,"In algebra, all quadratic problems can be solved by using the quadratic formula. I read a couple of books, and they told me only HOW and WHEN to use this formula, but they don't tell me WHY I can use it. I have tried to figure it out by proving these two equations are equal, but I can't. Why can I use $x = \dfrac{-b\pm \sqrt{b^{2} - 4 ac}}{2a}$ to solve all quadratic equations?","['quadratics', 'algebra-precalculus', 'polynomials']"
49240,Algebraic proof for simple set theory problem,"Prove that: $(A^{c}\cap B^{c} \cap C) \cup (B \cap C) \cup (A \cap C) = C$ (cmp = complement) Now, one way to solve this is to take a small universe $U$, say $U$ = {a, b, c, d, e, f, g} , draw the Venn diagram, figure out the union-ed parts of the equation and prove it. How can we do this purely algebraically? using the laws of sets like the idempotent law, duality, domination, absorption etc?",['elementary-set-theory']
49241,Proof that a linear transformation is isomorphic,"As homework, I need to proove whether a few linear transformations are isomorphic or not, however i do not know how to achieve this. First of all i have proven that the following map is linear: $$f:\mathbb{R}^2\mapsto\mathbb{R}^2, f\left( \begin{bmatrix}x\\y\end{bmatrix} \right)=x\begin{bmatrix}1\\1\end{bmatrix} + y \begin{bmatrix}-1\\1\end{bmatrix}$$ via the definition that a linear transformation $T: X\mapsto Y$ must satisfy the following condition (let $X$ and $Y$ be linear spaces over the field $\mathbb{K}$ ) $$\forall\alpha,\beta\in\mathbb{K}\wedge x_1,x_2\in X\,:\,T(\alpha x_1+\beta x_2) = \alpha T x_1+\beta T x_2$$ Can you explain me where to go ahead? (I am from germany so please make your explanations not that difficult :-))",['linear-algebra']
49252,The number of bit strings with only two occurrences of 01,"How many bit strings of length $n$, where $n \geq 4$, contain exactly two occurrences of $01$?",['combinatorics']
49253,Requesting abstract algebra book recommendations [duplicate],This question already has answers here : Good abstract algebra books for self study (13 answers) Closed 1 year ago . I've taken up self-study of math. (How smart can that be?) I've just about finished a course in real analysis which spent a lot of time on metric spaces and some time revisiting calculus. I was thinking of trying abstract algebra. I would appreciate any book recommendations. Thanks in advance. Andrew,"['book-recommendation', 'reference-request', 'abstract-algebra']"
49255,Why does my tangent vector not lie in the tangent space?,"Me again , still learning my lesson of ""don't drink and derive"": I have got two parametrizations of the surface $H :=\{ (x,y,z) \in \mathbb{R}^3 \, | \, z^2 = 1+x^2+y^2, \, z > 0\}$, $$F:\mathbb{R}^2 \rightarrow H, \  (x,y) \mapsto (x,y,\sqrt{1+x^2+y^2})$$ $$G:D^2 \rightarrow H, \ (x,y) \mapsto (\frac{x}{\sqrt{1-x^2-y^2}}, \frac{y}{\sqrt{1-x^2-y^2}}, \frac{1}{\sqrt{1-x^2-y^2}})$$ where $D^2$ denotes the open unit disk in $\mathbb{R}^2$. I take the first to give me a base of the tangent space at a point $F(x,y)$: $$\frac{\partial F}{\partial x}(x,y)=(1,0,\frac{x}{\sqrt{1+x^2+y^2}}), \ \ \frac{\partial F}{\partial y}(x,y)=(0,1,\frac{y}{\sqrt{1+x^2+y^2}})$$ Now I triple checked the fact that $G$ really goes to $H$ and that $$\frac{\partial G}{\partial x}(x,y) = (\frac{1-y^2}{\sqrt{1-x^2-y^2}^3}, \frac{xy}{\sqrt{1-x^2-y^2}^3}, \frac{x}{\sqrt{1-x^2-y^2}^3})$$ I even got the latter confirmed from a book. But then $\frac{\partial G}{\partial x}(x,y)$ should lie in the tangent space, hence be expressible as linear combination of the above basis vectors. Due to the $1$s and $0$s in our basis vectors the coefficients are easy to read off, we must have $$ \frac{\partial G}{\partial x}(x,y) = \frac{1-y^2}{\sqrt{1-x^2-y^2}^3}\frac{\partial F}{\partial x}(x,y) + \frac{xy}{\sqrt{1-x^2-y^2}^3}\frac{\partial F}{\partial y}(x,y)$$ But then the third coordinate doesn't match: $$\frac{x}{\sqrt{1-x^2-y^2}^3} \neq \frac{1-y^2}{\sqrt{1-x^2-y^2}^3} \cdot \frac{x}{\sqrt{1+x^2+y^2}} + \frac{xy}{\sqrt{1-x^2-y^2}^3} \cdot \frac{y}{\sqrt{1+x^2+y^2}}$$ The difference is exactly the factor of $\frac{1}{\sqrt{1+x^2+y^2}}$ which I can't get rid of. Where is my mistake (apart from drinking too much yesterday)? Thank you!",['differential-geometry']
49275,Motivating algebra from quadratic equations,"This question gave me pause for thought. We have a quadratic equation $ax^2+bx+c=0$. How much algebra can be motivated from the standard solution. Comments point out that the formula does not apply in characteristic 2, and that we need to be able to divide by $a$ and take the square root of the discriminant. I reckon this gets us thinking about fractions, fraction fields (and even local fields) with the rationals as the field of fractions of the integers (and rational functions from polynomials not far behind). Then we get quadratic extensions of fields and rings. Including Complex Numbers. What struck me was that relatively elementary observations could take us a long way. I think of talking to my daughter (age 13) about mathematical ideas and reckon I could do all of the above with her in the Quadratic case. But the quadratic case has some special features and therefore is not always paradigmatic for general theory. It has always seemed to me that indicating possible directions of travel in generalising simple results would be of huge benefit in motivating bright youngsters to take up mathematics. I'm looking for answers which give me insight into how much algebra, algebraic geometry, algebraic number theory I could motivate in an elementary way based on the ""formula"" for solving a quadratic equation.","['soft-question', 'algebra-precalculus', 'abstract-algebra']"
49276,Zooming formula,"I am sorry if this is a noob question, I need help with relatively simple math problem and assurance that I understand the problem correctly. I have a map-like program that zooms in and zooms out if you press the + and - icons (much like google map). Every time you zoom the map size doubles or halves. I know the minimum and maximum size of the map, how do I calculate the number of the doubling steps? I was thinking of this: A on power of 2*x equals B, where A is the minimal zoom, B is the maximal zoom a x is the number of steps between them. Am I right? How do I calculate x form that formula? Many thanks","['logarithms', 'algebra-precalculus']"
49282,Roots of unity in $\mathbb{Q} _{11}$,"Here $\mathbb{Q} _{11}$ denotes the 11-adic field. How can I show that the only root of unity of order 7 in this field is 1?
Is it true that for any two distinct primes $p,q$, the only root of unity of order $q$ in $\mathbb{Q} _{p}$ is 1? (Or more generally - Is there some simple condition on $n\in \mathbb{N}$, $p$ prime, so that there are non-trivial roots of unity of order $n$ in  $\mathbb{Q} _{p}$?) Thanks.","['algebraic-number-theory', 'abstract-algebra', 'p-adic-number-theory']"
49292,What strategy do you use when solving vector equations involving $\nabla$?,"$\Phi, \Lambda$ are both scalars dependent upon, and $\mathbf u$ is a vector independent of coordinates. I'm trying to express $\Lambda$ in terms from $\mathbf U \cdot \nabla\Lambda = \Phi$ and to start with, since I'm just familiar with the basics, it looks pretty hopless. So: Get help from people more expert in this area Trawl through the list of standard vector identitites involving $\nabla$ Search for an online mathematics program to solve it. Make it simpler to start with by solving in one dimension, and progress from there what strategy would/did you use in tackling this problem? Solving it would be a bonus ;) Edit: I've added the context of the problem since some people think this will help: I'm trying to work out the conserved canonical momentum for a static electric field, using Noether's theorem on the relativistic electromagnetic Lagrangian $$L = \frac{m_0c^2}{\gamma} + \frac{e}{c}\mathbf{u \cdot A} - e\Phi(x,y,z)$$ $L$ needs to be independent of coordinates which can be done by transforming $\mathbf A\rightarrow \mathbf A'= \mathbf A + \nabla\Lambda$ The conserved canonical momentum $$ P = \frac\partial{\partial \mathbf u} ( \frac{-m_0c^2}{\gamma} + \frac{e}{c}\mathbf{u \cdot (A+\nabla\Lambda}) - e\Phi)$$ With no magnetic field $A=0$ $$P = -m_0\mathbf u\gamma +\frac e c \frac\partial {\partial\mathbf u}\mathbf u  \cdot\nabla\Lambda$$ becomes $$P = -m_0\mathbf u\gamma +\frac e c (\nabla\Lambda + \mathbf u  \cdot\frac\partial {\partial\mathbf u}\mathbf\nabla\Lambda)$$ To get any further, I need to know the form $\Lambda$ must take, which comes from making $L$ independent of the coordinates before, and so $$\nabla( \frac{e}{c}\mathbf u \nabla\Lambda - e\Phi) = 0$$","['multivariable-calculus', 'physics']"
49296,Does the likelihood of an event increase with the number of times it does not occur?,"I would seem logical that the more times an event does not happen, the more likely it is to happen, for example: If a coin is flipped and it lands on tails 10 times in a row it would seam more likely that the next flip will result in heads. The Infinite Monkey Theorem is one such idea that suggests this is true, http://en.wikipedia.org/wiki/Infinite_monkey_theorem It states that if some number of monkeys are left in a room with typewriters for an infinite amount of time then they will eventually compose all written texts ever produced.  This seems to suggest that since the chance of the monkeys writing a work, say Shakespeare's Romeo and Juliet , is very low. The more times they do not write it, the more likely they are to write it, until the chance becomes significant and it, the writing of the play, happens. However another idea, Gambler's Fallacy states quite the opposite. http://en.wikipedia.org/wiki/Gambler%27s_fallacy It states that the chance of an event does not increase with the number of times it does not occur. So what is the answer? Does the likelihood of an event go up the more times it does not happen, or does it stay the same? And if it does stay the same then how does one explain the Infinite Monkey Theorem?",['probability']
49297,The only two rational values for cosine and their connection to the Kummer Rings,"I am trying to learn about Kummer Rings , and in particular what makes $n=3,4,6$ so special. (That is the Gaussian and Eisenstein integers) The only $\theta\in [0,\frac{\pi}{2}]$ which are rational multiples of $\pi$ for which $\cos(\theta)\in \mathbb{Q}$ are $\theta=\frac{\pi}{2},\frac{\pi}{3}$ which corresponds  exactly to $n=4,6$ in $\frac{2\pi}{n}$. Can someone give me an explanation for why $\cos(\theta)$ is rational only in these cases?  Also, can we go the other way, and use some nice property of the Kummer Rings to show that $\cos(2\pi/n)$ is rational if and only if $n=1,2,3,4,6$? Thanks, Edit: As pointed out by Qiaochu, what I previously wrote above was certainly not the norm.","['ring-theory', 'abstract-algebra', 'trigonometry', 'reference-request', 'intuition']"
49309,Intersection of prime ideals,"This is a problem from an algebra textbook. Let $R$ be a ring, and $I$ be an ideal. If the radical of $I$ is $I$ itself, i.e. $\operatorname{rad}(I) = I$ , then $I$ is an intersection of prime ideals.","['commutative-algebra', 'ring-theory', 'ideals', 'abstract-algebra']"
49311,reason of the definition of the covariance,"The covariance of two random variables $X$ and $Y$ is defined to be 
 $${\rm Cov}(X,Y) =   E[(X-E[X])(Y-E[Y])]. $$
I don't understand it, if someone could explain me this please.
Why does this value tell us of some relation about $X$ and $Y$?",['statistics']
49318,A complete proof that a triangle (or arbitrary polygon) is a cell,"A cell is any subset of the plane homeomorphic to a disk. Could someone provide a complete proof that a triangle is homeomorphic to a disk? I have two ideas but I can't seem make them fully rigorous. One would be via this explicit mapping $f$: Map the boundary of the triangle to the boundary of the disk, and since they are both Jordan curves we're okay so far. Now, map the centroid $C$ (? I think the centroid is always inside the triangle, unlike the orthocenter or circumcenter) of the triangle to the center of the disk and then map radii to radii. Specifically, for each point $P$ on the boundary of the triangle, map the line $PC$ to the line $f(C)f(P)$. The other way would be showing something like all closed connected subsets of the plane with Euler characteristic 2 are homeomorphic. Feel free to use any definition of homeomorphism or continuity that you would like.",['general-topology']
49330,The Dihedral Angles of a Tetrahedron in terms of its edge lengths,"I am interested in any references which discuss a general formula for the dihedral angles of a tetrahedron in terms of its six edge lengths. If there is a well known formula could someone please post it here. Edit: The solution below works in the case of a Euclidean tetrahedron, which I am thankful for. Is anyone aware of other methods that extend to higher dimensions, i.e. like the Cayley-Menger method for computing volumes does? I should also mention that I am interested in the cosine of the dihedral angle, the sine is easy to find using the generalized sine law.",['geometry']
49332,$F[x]/(x^2)\cong F[x]/(x^2 - 1)$ if and only if F has characteristic 2,"Artin's Algebra, Chapter 10 problem 5.16 states: Let $F$ be a field. Prove that the rings $F[x]/(x^2)$ and $F[x]/(x^2-1)$ are isomorphic if and only if $F$ has characteristic 2. As a pedantic concern: if F has characteristic 0, then surely this isomorphism still holds? So maybe it should be ""characteristic at most 2""? More seriously, it seems like $F[x]/(x^2)=\left\{f_0 + f_1 x\right\}$ since we're just setting $x^2=0$. Similarly, it seems like $f_0 + f_1x / (x^2-1) = f_0 + f_1 x$, which implies that $F[x]/(x^2)=F[x]/(x^2-1)$ independent of the characteristic of $F$. To prove this we need to show that $\text{deg}(fg)=\text{deg}(f)+\text{deg}(g)$,  which I believe is true in at least integral domains. What is my mistake here?","['ring-theory', 'abstract-algebra', 'field-theory']"
49347,An identity involving Lucas numbers,"Let $L_n$ be the Lucas numbers, defined by $L_n = F_{n-1} + F_{n+1}$ where $F_k$ are the Fibonacci numbers. How to prove that $$L_{2n+1} = \displaystyle \sum_{k=0}^{\lfloor n + 1/2\rfloor}\frac{2n+1}{2n+1 - k}{2n+1 - k \choose k} $$","['fibonacci-numbers', 'discrete-mathematics', 'lucas-numbers', 'combinatorics']"
49348,Inner Product Spaces over Finite Fields,"Inner product spaces are defined over a field $\mathbb{F}$ which is either $\mathbb{R}$ or $\mathbb{C}$. I want to know what happens if we try to define them over some finite field. Here's an example: Let $\mathbb{F} = \{0,1,a,b\}$ be a finite field with + and * defined by the following Cayley tables: Now, define a very simple vector space $\mathcal{V} = \{O, V\}$ over $\mathbb{F}$ as follows: $\mathcal{V}$ is an Abelian group over addition, with identity $O$. Therefore, $O+O = V+V = O$, and $O+V = V+O =V$. The scalar multiplication is governed with these rules: For any $e \in \mathbb{F}$, we have $eO = O$. Define $0V = O$, and $1V=aV=bV=V$. One can easily check that $\mathcal{V}$ is a vector space over $\mathbb{F}$. Now, we define an inner product for $\mathcal{V}$: $\langle O,O \rangle = 0$ and $\langle V,V \rangle = 1$; $\langle V,O \rangle = \langle O,V \rangle = 0$. It seems that the above example demonstrates an inner product space over a finite field. Is the above notion ever studied? Does it have any applications? We avoided ""conjugate symmetry"" in the definition above, by assuming the conjugate of each member of $\mathbb{F}$ is itself. Can we define conjugation for fields other than $\mathbb{C}$? (Well, I heard the name C*-algebra , but I don't know whether it relates to my question.) For instance, let $\mathbb{Q}[\sqrt 3] = \{a+b\sqrt 3 \mid a,b \in \mathbb{Q} \}$ be $\mathbb{Q}$ adjoined with $\sqrt 3$. For any $e = a+b\sqrt 3$ in $\mathbb{Q}[\sqrt 3]$, can we define the conjugate of $e$ as $e^* = a-b\sqrt 3$? This satisfies the condition below: Both addition and multiplication of $e$ and $e^*$ are members of the underlying subfield.","['vector-spaces', 'finite-fields', 'inner-products', 'abstract-algebra']"
49349,"Does the uniform continuity of $f: X \rightarrow \mathbb{R}$ imply $f: A \rightarrow \mathbb{R}$ is also uniformly continuous, when $A \subset X$?","I've been preparing for the prelim in August, and was working on a problem involving uniform continuity and restriction of functions.  I absentmindedly assumed the above by considering the contrapositive: if $f: A \rightarrow \mathbb{R}$ isn't uniformly continuous, that implies $\exists \ \epsilon$ such that no $\delta$ satisfies $d(x,y) < \delta \implies d(f(x),f(y)) < \epsilon, \,\,\ \forall x,y \in A$, and this failure of $\epsilon$'s existence shouldn't change when I ""add more points"" by considering $f: X \rightarrow \mathbb{R}.$ However, if this is true, we obtained a lot of results I consider to be strangely powerful.  For example, if a function is continuous on $\mathbb{R}$, it is uniformly continuous on any bounded interval I, as it's uniformly continuous on $\overline{I}$ which is compact by Heine-Borel.  Hence, if $f$ is a real-valued function continuous on a subset $A$ of $R$, it's uniformly continuous on any bounded subset $X$ of $A$. Conclusions such as this seem too strong! Is there a flaw in my reasoning, and if so, where is it?",['real-analysis']
49359,Automorphism Group of a graph,"If $X$ is a locally finite graph, (i.e. each vertex has finite index), is it true that the automorphism group Aut($X$) of the graph X is locally compact? Here, Aut($X$) has compact open topology; and topology of $X$ is the weak topology when we consider $X$ as a CW-complex (see. Hatcher, Algebraic Topology - Graphs and Free Groups).","['general-topology', 'algebraic-topology']"
49361,Order type and its reverse,"I am given the following definition: For an arbitrary order type $\Theta$, denote by $\Theta$* (the reverse of $\Theta$) the order type $type\Theta$*$=typeA(\succ)$, where $\langle A,\prec \rangle$ is an ordered set of order type $\Theta$. And the example: $\omega_0$*$=type${$-n : n \in \omega $}$(<)$. I am having a hard time understanding this. Is the example showing that if $\omega_0$ is the order type of $\omega$, then $\omega_0$* is the order type of the negative integers? Also, if $\eta_0$ is the order type of $\mathbb{Q}$, why does $\eta_0 = \eta_0$*?","['elementary-set-theory', 'order-theory']"
49362,A tricky geometry problem,"I already have my own solution for the following question. But I am still interested in other elegant solutions without trigonometry if possible. This is my own solution. I am lazy to upload the TeX code, I am sorry.",['geometry']
49366,Why is the direct product of a finite number of nilpotent groups nilpotent?,"I read that a direct product of a finite number of nilpotent groups is nilpotent. Here the definition of a nilpotent group is one that has a central series. A comment in my book following this claim says If $G_{ij}$ is the $i^{th}$ term of a central series of the $j^{th}$ factor $H_j$, with $G_{ij}=G$ if the series has already terminated at $G$, then $\prod_j G_{ij}$ will be the $i^{th}$ term of a central series for $\prod_j H_j$. My guess is that the central series for $\prod_j H_j$ is something like
$$
1\unlhd \prod_j G_{1j}\unlhd\prod_j G_{2j}\unlhd\cdots\unlhd\prod_j G_{rj}=\prod_j H_j
$$ 
and additionally
$$
\prod_j G_{i+1,j}/\prod_j G_{ij}\subseteq Z(\prod_j H_j/\prod_j G_{ij}).
$$
I'm struggling to understand why the containment above is true. I think I need to show
$$
\begin{align*}
\prod_j g_{i+1,j}\prod_j G_{ij}\cdot\prod_j h_j\prod_j G_{ij} &= \prod_j g_{i+1,j}\prod_j h_j\prod_j G_{ij} \\
&= \prod_j h_j\prod_j g_{i+1,j}\prod_j G_{ij} \\
&= \prod_j h_j\prod_j G_{ij}\cdot\prod_j g_{i+1,j}\prod_j G_{ij}
\end{align*}
$$
but I just don't see why the second equality would be true. I'm sure there's a nice simple explanation, and I'd be glad to see it. Thanks.","['nilpotent-groups', 'group-theory', 'direct-product']"
49373,Sparseness for a matrix,"I would like to define a function $f$ whose range is $[0,1]$ such that it takes a matrix $C \in R_+$ of dimension $m \times n$. The entries in the matrices are also in the range $[0,1]$. In addition, each row of $C$ sums to $1$. The function $f$ should produce $0$ when all the entries in the matrix $C$ are same and produce $1$ when there is only one $1$ entry in each row. For example,when C = [1 0 0 0
     0 0 1 0
     0 0 0 1
     0 1 0 0] $f(C) = 1$ In other case, when C = [0.25 0.25 0.25 0.25
     0.25 0.25 0.25 0.25
     0.25 0.25 0.25 0.25
     0.25 0.25 0.25 0.25] $f(C) = 0$ Can anyone help me out in contructing such a function?","['matrices', 'functions']"
49378,When can two linear operators on a finite-dimensional space be simultaneously Jordanized?,"IN a comment to Qiaochu's answer here it is mentioned that two commuting matrices can be simultaneously Jordanized (sorry that this sounds less appealing then ""diagonalized"" :P ), i.e. can be brought to a Jordan normal form by the same similarity transformation. I was wondering about the converse - when can two linear operators acting on a finite-dimensional vector space (over an algebraically closed field) be simultaneously Jordanized? Unlike the case of simultaneous diagonalization, I don't think commutativity is forced on the transformations in this case, and I'm interested in other natural conditions which guarantee that this is possible. EDIT: as Georges pointed out, the statements that two commuting matrices are simultaneously Jordanizable is in fact wrong. Nevertheless, I am still interested in interesting conditions on a pair of operators which ensures a simultaneous Jordanization (of course, there are some obvious sufficient conditions, i.e. that the two matrices are actually diagonalizable and commute, but this is not very appealing...)","['jordan-normal-form', 'linear-transformations', 'linear-algebra']"
49383,How does $ \sum_{p<x} p^{-s} $ grow asymptotically for $ \text{Re}(s) < 1 $?,"Note the $ p < x $ in the sum stands for all primes less than $ x $. I know that for $ s=1 $,
$$ \sum_{p<x} \frac{1}{p} \sim \ln \ln x , $$
and for $ \mathrm{Re}(s) > 1 $, the partial sums actually converge to a finite limit called the prime zeta function , which has an analytic continuation to the whole right-half plane but the actual series diverges in the critical strip. So anyway, I'm wondering what the asymptotic behavior of the partial sums are in the limit as $ x \to \infty $ for a given value of $ s $ with $ \mathrm{Re}(s) < 1 $. At first I intuitively conjectured it might be something vaguely like the following 
$$ \sum_{p<x} \frac1{p^s} \sim f(s) \pi(x)^{1-s} , \quad f(s) = \lim_{n\to\infty} \int_0^1 g_n(u) u^{-s} du $$
but after some thought I'm not sure if this kind of formula will work after all. Any ideas? Note again: I'm asking about asymptotics when $ \mathrm{Re}(s) < 1 $.","['asymptotics', 'analytic-number-theory', 'number-theory']"
