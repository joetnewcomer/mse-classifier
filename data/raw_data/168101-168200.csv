question_id,title,body,tags
2942085,Simplify $\frac{2}{\sqrt{4-3\sqrt[4]{5}+2\sqrt{5}-\sqrt[4]{125}}}$ [duplicate],"This question already has answers here : How to prove: $\left(\frac{2}{\sqrt{4-3\sqrt[4]{5}+2\sqrt[4]{25}-\sqrt[4]{125}}}-1\right)^{4}=5$? (3 answers) Closed 4 years ago . Simplify $$\frac{2}{\sqrt{4-3\sqrt[4]{5}+2\sqrt{5}-\sqrt[4]{125}}}$$ Found in a book with tag ""Moscow 1982"", the stated answer is $1+\sqrt[4]{5}$ . Used all tricks that I know but without success. The answer appears to be correct, checked in Wolfram Alpha. Hints and answers welcomed. Sorry if this is a duplicate.","['contest-math', 'algebra-precalculus', 'radicals', 'nested-radicals']"
2942103,Socle of a direct product of finite groups.,"The socle of a group $G$ is defined as the subgroup generated by minimal subgroups among normal subgroups of $G$ , and it is denoted as $\textrm{Soc}(G)$ . Suppose $A_1,...,A_n$ are finite groups. Is it true that $\textrm{Soc}(A_1 \times ... \times A_n) = \textrm{Soc}(A_1) \times ... \times \textrm{Soc}(A_n) $ ? The $\supseteq$ inclusion seems to be true, but I'm not sure whether the inclusion $\subseteq$ is generally true (though I would guess it is true in the case of all the groups $A_i$ being abelian, for example - I think this might be true because in a direct product of abelian groups, minimal groups are cyclic groups prime order).","['socle', 'group-theory', 'finite-groups']"
2942117,"Derivative of positive, continuously differentiable function is positive close to zero","Consider a continuously differentiable function $f: [0, 1] \to \mathbf{R}_{\geq 0}$ , such that $f(0)=0, f'(0)=0$ and $f(x)>0$ for $x>0$ . I want to prove that there exists $\bar{x}>0$ such that $f(x)$ is increasing on $[0, \bar{x}]$ . (or, even better, strictly increasing) This question is nearly identical to this Derivative of positive function is positive close to zero However, apart from continuity, I have additionally continuous derivatives and, because of that, cannot make the counterexample proposed there to work. The answer to that question is (paraphrasing): 'for a function oscillating near 0 between $x^2$ and $x^4$ we have $f(0)=0$ , $f(x)>0$ for $x>0$ and the function is continuous'. However, I cannot construct such a function that would not violate continuity of the derivative. For example, consider: $$f(x)= (\sin(1/x)+1)x^2+(\cos(1/x)+1)x^4.$$ The derivative of this function oscillates between $0$ and $1$ and thus is not continuous (whilst all the other conditions are met). In short: is the continuity of the derivative sufficient to make the original statement  true, or does there exist a counterexample with continuous derivatives?","['calculus', 'derivatives', 'real-analysis']"
2942120,Use of residue theorem to evaluate a real integral,"I have seen this integral on youtube, I tried to solve it for 5 hours but I expect I need to use residue theorem which I don't really know $$\int_{0}^1\frac{\ln(x+1)}{x^2+1}\,dx$$ , numerical integration yields $$0.272198261$$ with an estimated error of $$10^{-15}$$ but I am not really sure how to get there, I tried to take antiderivative but failed miserably. When trying to use residue theorem which I don't really know, I got $$ \ln(2)\pi$$ which is precisely 8 times the value of the numerical integration.","['complex-analysis', 'calculus', 'definite-integrals', 'residue-calculus']"
2942158,Soft quesion: what do we lose if we assume measures are complete and $\sigma$-finite in integration theory?,"This is intended to be a really soft question, which might be considered bad for this site. Let me know if that's true. I'll try to make this question as ""answerable"" as possible. I've been reading measure and integration theory on Analysis III by H. Amann & J. Escher (Chapter IX and X). This text is famous for its characteristic that everything is presented in the greatest generality . For example, he talks about convergence on Banach spaces right at the beginning. With this being said, it is not surprising that the text develops the theory of Bochner integrals first, even before Lebesgue integrals. However, what really annoys me is that, at the beginning of each section he says: In the following, let $(X,\mathcal{A},\mu)$ be a complete, $\sigma$ -finite measure space . This goes against the spirit of the book! Moreover, I'm utterly confused when the Wikipedia article on Bochner integrals does not assume completeness and $\sigma$ -finiteness, and yet it seems that many important results remains true without that assumption. Now my question is this. What do we lose if we assume all measures are complete and $\sigma$ -finite? I know that every measure has a completion, so that probably explains why we assume completeness. But what about $\sigma$ -finiteness? Is it just that non- $\sigma$ -finite just rarely exist? (This situation is much like topology: We often assume our topological spaces are Hausdorff without regret, because non-Hausdorff spaces are just too pathological.) To make this question more concrete, let me elaborate: Do we often encounter non- $\sigma$ -finite measures in higher analysis? I fear the theorems here are not general enough for later use. Is that true? Are there any other books that, like Amann, develops Bochner integrals in detail and presents results without assuming completeness and $\sigma$ -finiteness? I've looked into several standard real analysis texts so far, and they either treat it as an exercise (Folland), or in an appendix (Cohn), or omit it altogether. I also found the book Topics in Banach space integration by Schwabik, but unfortunately this book simply assumes $X$ to be a cube in $\mathbb{R}^n$ ... What significant results are not true or are much harder to prove if measures are not complete or $\sigma$ -compact? I already know Fubini's theorem is one example. (This might be too vague since it's impossible to list all such results. But maybe just name a few?) Thanks in advance!","['banach-spaces', 'measure-theory', 'analysis', 'real-analysis', 'soft-question']"
2942168,"How to solve $v f^{'}_v + f = 0$, $f(0, y) = y^2$","So I was presented with this equation in my textbook, currently studying multi variable calculus: $$yf^{'}_x(x,y) - xf^{'}_y(x,y) = f(x,y)$$ Using the substitution: $$x^2 + y^2 = u$$ $$e^{{-x^2}{/2}} = v$$ I get the equation (which is correct): $$v f^{'}_v + f = 0$$ My next task is to find the solution, $f(x,y)$ that satisfies $f(0, y) = y^2$ . The correct answer should be $f(x,y) = (x^2 + y^2)e^{{-x^2}{/2}}$ . But here I am stuck, I have solved similar tasks but I don't know how to handle the $f$ . For example $v f^{'}_v = x$ or similar would be easy to solve.",['multivariable-calculus']
2942169,Nice Example of a Non-Borel Set in $\mathbb{R}^2$?,"Can someone explain, intuitively, what the meaning of a non-Borel set in $\mathbb{R}^2$ is? Is it some sort of collection of points with some weird property that it cannot be formed from countable unions or intersections of the open sets of the Euclidean topology on the 2D plane? What does this look like? Though there are explanations, is there some nice way of understanding this?","['elementary-set-theory', 'general-topology', 'measure-theory']"
2942203,The eigenvalues of $\begin{pmatrix}0&A\\A^*&0\\ \end{pmatrix}$ are the singular values of $A$ along with the negative signs.,"The eigenvalues of $\begin{pmatrix}0&A\\A^*&0\\ \end{pmatrix}$ are the singular values of $A$ along with the negative signs. Here $A$ is an $n \times n$ matrix, has $n$ singular values. Here we are consider both $\lambda $ and $- \lambda$ if $\lambda$ is an singular value of $A$ . Thus we have a set of $2n$ elements and we have to show that these are the eigenvalues of $\begin{pmatrix}0&A\\A^*&0\\ \end{pmatrix}$ . Need some hint to proceed with the problem.","['matrices', 'matrix-analysis', 'linear-algebra', 'eigenvalues-eigenvectors']"
2942227,"What is an estimator for the ""number of trials"" given observed successes and the success probability?","The binomial distribution with $n$ trials, $k$ successes and success probability $p$ is given by $$P(k;n,p) = \binom{n}{k} p^k (1-p)^{(n-k)}, \quad k \in \{0,...,n\}$$ Suppose that we observe $k$ successes and know $p$ but we do not know $n$ . Observe that now $k$ and $p$ are fixed whereas $n$ is stochastic. So if $k=6$ and $p=0.4$ , $$P(k=6; n ,p=0.4) = \binom{n}{6} 0.4^6 (0.6)^{(n-6)}, \quad n \in \{6,...,\infty\}.$$ This is however (remark by @Xiaomi) not a valid probability function as it does not sum to one over its suppoer. Is there a probability mass function for $n$ ?  What is a useful (unbiased, consistent) estimator for its parameter $n$ ?","['statistics', 'parameter-estimation', 'binomial-distribution']"
2942230,"Finding $a>1$ such that $\int_0^\pi \tfrac{\sin x\,\mathrm{d}x} { \sqrt{1 − 2a\cos x + a^2}}$ equals given constant","$a > 1$ , solve for $a$ : $$\int_0^\pi \frac{\sin(x)} { (1 − 2a\cos(x) + a^2)^{1/2}} dx = 0.2018$$ I have attempted to use substitution $u = -\cos x$ , $\frac{du}{dx} = \sin x$ , limits $[1, -1]$ . I end up with $\frac{1}{a}(1 + 2a + a^2)^{1/2} - \frac{1}{a}(1 - 2a + a^2)^{1/2}  = 0.2018$ . I believe this is not the right direction. I would greatly appreciate any ideas on how to solve this.","['integration', 'calculus', 'legendre-polynomials']"
2942251,Use an appropriate change of variables to solve the differential equation.,Use an appropriate change of variables to solve the differential equation. $$t\frac{dy}{dt}-y=\sqrt{t^2+y^2}$$ My friend and I are trying to figure out how to solve this equation. Our professor has given us several methods but we aren't sure which to use because none of the equations are similar to this one. Any help would be appreciated especially if you could help us with step by step. Thanks! -- UPDATE: $$t\frac{dy}{dt}-y=\sqrt{t^2+y^2}$$ $$\frac{dy}{dt}-\frac{y}t=\sqrt{1+\frac{y^2}{t}}$$ where u= y/t $$\frac{dy}{dt}=\sqrt{1+u^2}+u=f(u)$$ $$f(u)-u=\sqrt{1+u^2}+u-u=\sqrt{1+u^2}$$ ... We ended up with $ln|\sqrt{1+u^2}|=ln|x|+c$,"['change-of-variable', 'derivatives', 'ordinary-differential-equations']"
2942263,Determining the minimum value of the function $y = x + 2\sqrt{x^2 - \sqrt{2}x + 1}$,I am curious whether there is an algebraic verification for $y = x + 2\sqrt{x^2 - \sqrt{2}x + 1}$ having its minimum value of $\sqrt{2 + \sqrt{3}}$ at $\frac{1}{\sqrt{2}} - \frac{1}{\sqrt{6}}$ . I have been told the graph of it is that of a hyperbola.,"['analytic-geometry', 'optimization', 'algebra-precalculus', 'maxima-minima']"
2942315,Multiples are closed under integral linear combinations,"My lecturer gave us the following side note when explaining the euclidean algorithm in class. Eucledian Algorithm: Let $a$ and $b$ be natural numbers, then there are integers $m$ and $n$ such that $\gcd(a, b) = am + bn$ The implementation of the Euclidean
Algorithm consists of a sequence of repetitions
of the Division Algorithm with
the integers m and n being obtained
by unravelling this sequence of steps.
To appreciate why such an operation
identifies $\gcd(a, b)$ , we may start with
the assumption that $a > b$ otherwise $\gcd(a, b) = a$ (the case $a = b$ ) and there
is nothing to be done. When $a > b$ the Division Algorithm asserts that $a =
bq + r$ with $0  r < b.$ There are two
points to note. a) Since $\gcd(a, b)$ divides $a$ and $b$ so $\gcd(a, b)$ must also divide the remainder $r.$ Therefore the greatest
common divisor of $a$ and $b$ is also
the greatest common divisor of $b$ and $r$ , that is, $\gcd(a, b) = \gcd(b, r)$ .
b) Since $b < a$ and $r < b$ the sequence
of applications of the Division Algorithm
generates a strictly decreasing
sequence of remainders terminating
with 0, but such that each remainder
is divisible by $\gcd(b, r)$ . By definition,
the penultimate remainder is
therefore $\gcd(a, b)$ . I understand and can apply the algorithm, i.e. I can do the repeated division and find the gcd. But I still don't understand the part in bold above. Why can we just assume that? When trying to prove the same for polynomials in a tutorial homework, I simply used a modified version of the part in bold as a lemma, specifically: Any polynomial divisor of both $f(x)$ and $g(x)$ must also divide the remainder polynomial when $f(x)$ is divided by $g(x)$ and the tutor made no remark, so I'm assuming this is something which can be clearly seen but that I'm missing. Could anyone please break it down for me?","['number-theory', 'algebra-precalculus', 'definition', 'proof-explanation']"
2942357,Prove all derivatives of $f(x)=\frac{1}{1+x}$ by induction,"Problem Prove all derivatives of: $$ f(x)=\frac{1}{1+x} $$ by induction. Attempt to solve I compute few derivatives of $f(x)$ so that i can form general expression for induction hypothesis. I compute all derivatives utilizing formula: $$ \frac{d}{dx}x^n=nx^{n-1} $$ First 4 derivatives are: $$ f'(x)=(-1)\cdot(1+x)^{-2}\cdot 1 = -\frac{1}{(1+x)^2} $$ $$ f''(x)=(-1)(-2)(1+x)^{-3}\cdot 1 = \frac{2}{(1+x)^3} $$ $$ f'''(x)=(-1)(-2)(-3)(1+x)^{-4}\cdot 1 = -\frac{6}{(1+x)^4} $$ $$ f''''(x)=(-1)(-2)(-3)(-4)(1+x)^{-5} \cdot 1 = \frac{24}{(1+x)^5} $$ Observe that $(-1)(-2)(-3)(-4)\dots (-n)$ can be generalized with: $$ (-1)(-2)(-3)(-4)\dots(-n) = (-1)^n\cdot n! $$ Expression follows factorial of $n$ except every other value is positive and every other is negative. If i multiply it by $(-1)^n$ it is positive when $n \mod 2 = 0$ and negative when $n \mod 2 \neq 0$ . Rest of the expression can be generalized as: $$ (1+x)^{-n-1} = (1+x)^{-(n+1)}=\frac{1}{(1+x)^{n+1}} $$ Combining these gives formula in analytic form: $$ f(n)= \frac{(-1)^n \cdot n!}{(1+x)^{n+1}} $$ I can form induction hypothesis such that: $$ \frac{d^n}{dx^n}\frac{1}{1+x} = \frac{(-1)^n\cdot n!}{(1+x)^{n+1}} $$ Induction proof Base case Base case when $n=0$ : $$ \frac{d^0}{dx^0}\frac{1}{1+x}=\frac{1}{1+x}=\frac{(-1)^0\cdot 0!}{(1+x)^{0+1}} $$ Induction step $$ \frac{d^n}{dx^n}\frac{1}{1+x} =_{\text{ind.hyp}} \frac{(-1)^n\cdot n!}{(1+x)^{n+1+1}} $$ $$ \frac{d^n}{dx^n}\frac{1}{1+x} = \frac{(-1)^n\cdot n!}{(1+x)^{n+2}} $$ Now the problem is that formula i used for derivation can only be used recursively. I believe this is correct notation for $n$ :th derivative but computing one is only defined recursively with formula i used: $$ \frac{d}{dx} x^n = nx^{n-1} $$ Which is not defined for case: $$ \frac{d^n}{dx^n}x^n = \text{
undefined} $$ The idea is to show that this recursion can be expressed in analytical form and it is valid for all $n\in \mathbb{Z}+$ by induction. Problem is i don't know how do you express this in recursive form and how do you get from recursion formula to the analytical one.","['induction', 'derivatives', 'real-analysis']"
2942374,Show that $\lim_{x \rightarrow \infty} f'(x)<1$ implies $f(x_0)<x_0$ for some $x_0$,"Let $f:[0,\infty)\rightarrow R $ be a continuously differentiable function. Show that if $ \lim_{x \rightarrow \infty} f'(x)<1   $ then $ f(x_0)<x_0 $ for some $x_0$ large enough. (An example of a function that satisfies these assumption is $f(x) = \sqrt x $ ). I am struggling with the proof. I've tried with the mean value theorem: Choose $0<x<y$ . Then by the MVT there esists a number $c \in (x,y)$ such that $ \dfrac{f(y)-f(x)}{y-x} = f'(c)  $ But at this point I got stuck... The other info I have is that there exists a number $M>0$ such that if $x>M$ then $f'(x)<1$ (the limit condition stated in the hp). Is there a way to combine these two facts in order to prove what I want?","['limits', 'inequality', 'infinity', 'real-analysis']"
2942386,Sheaf of Differentials on a product,"I tried to solve exercise II.8.3 (a) in Hartshorne's Algebraic Geometry which reads as follows. Let $X$ and $Y$ be schemes over another scheme $S$ . Use (8.10) and (8.11) to show that $\Omega_{X\times_S Y/S} \cong p_1^*\Omega_{X/S} \oplus p_2^*\Omega_{Y/S}$ . First I observed that by (8.10) we know $\Omega_{X \times Y / Y} \cong p_1^* \Omega_{X / S}$ . (8.11) gives an exact sequence $$p_2^*\Omega_{Y/S} \rightarrow \Omega_{X\times Y/S} \rightarrow \Omega_{X\times Y/Y} \rightarrow 0,$$ so both things together already look promising. We just have to show that the  first arrow is injective and that the sequence splits. My failed attempt to prove this follows. Reading Matsumura's Commutative ring theory I noticed, that he already provides a criterion for exactly this (in the affine case). Given ring homomorphisms $k \rightarrow A  \rightarrow B$ ( $k$ is not necessarily a field), we get an exact sequence $$\Omega_{A/k} \otimes B \rightarrow \Omega_{B/k} \rightarrow \Omega_{B/A} \rightarrow 0,$$ which is exactly the sequence on affine opens. If $A \rightarrow B$ is 0-smooth (afaik this is also called formally smooth), the first arrow is injective and the sequence is in fact split-exact. So this looks exactly like what I want. But I think this does not apply in our case, where $B = A \otimes_k C$ for some $k$ -algebra $C$ . Suppose $N \subset A$ is an ideal with $N^2 = 0$ and $C = A/N$ . Then $B = A/N$ and the identity map $A \rightarrow A$ never admits a lift $A/N \rightarrow A$ if $N \neq 0$ . So $B$ is in fact not smooth over $A$ .","['algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
2942394,$\left|\sin(x)\right|$ derivative at $\pi$,"Let $f$ be a function, $f:\mathbb{R}\to\mathbb{R}$ $$f(x)=\begin{cases} 
      e^{x^2}-2 & x< 0 \\
x^3+x-1 & 0\leq x \leq 1 \\ 
     \left|\sin(x)\right|  & x>1. 
   \end{cases}$$ Check if $f$ is continuous and differentiable at $a$ , when $a=0,1,\frac{\pi}{2}, \pi$ . If $f$ is differentiable at $a$ , find $f'(a)$ . What I've been doing: I found that: $f$ is continuous at $0$ but not differentiable. $f$ is not continuous at $1$ so it's not differentiable. And then I thought that $f$ was differentiable at $\pi$ and $\frac{\pi}{2}$ because $f$ is continuous at $(1, +\infty)$ ( $\left|\sin(x)\right|$ ), so I looked for: $f'(\frac{\pi}{2})=\left|\cos(\frac{\pi}{2})\right|=0$ (by the solution my prof gave me this is correct). $f'(\pi)=\left|\cos(\pi)\right|=-1$ Now this is wrong. The solution they gave me says that $f$ is not differentiable at $\pi$ , and I'm really lost. Why is it differentiable at $\frac{\pi}{2}$ and not $\pi$ ?","['continuity', 'calculus', 'derivatives', 'real-analysis']"
2942432,Linear Independence of Complex Absolute Value Function,"Given $n$ different complex numbers $z_1,z_2\cdots z_n$ , $n$ real numbers $a_1,a_2\cdots a_n$ and a constant $C$ , if $$\sum_{i=1}^{n}a_i\left|z-z_i\right|=C$$ for every complex number $z$ in a region $\Omega$ on the complex plane, will it imply that $a_i=C=0\quad\left(i=1,2,\cdots n\right)$ ? i.e. functions $\left|z-z_i\right|$ are linearly independent in the space $\mathbb{R}^\Omega$ ? If not, does there exist a counterexample? I think it’s unlikely to be false, because intuition tells me the equation $\sum_{i=1}^{n}a_i\left|z-z_i\right|=C$ (if non-trivial) always represents a curve in $\Omega$ . I noticed recently that it can be converted into the following question: If $$\sum_{i=1}^n a_i\frac{\left(z-z_i\right)}{\left|z-z_i\right|}=0$$ for all $z\in \Omega$ , prove $a_i=0,\quad i=1,2\cdots n$ . My thought is to pick $z=Z_1,Z_2\cdots Z_n$ such that the matrix $$\left(\frac{\Re\left(Z_i-z_j\right)}{\left|Z_i-z_j\right|}\right)_{n\times n}\quad or \quad\left(\frac{\Im\left(Z_i-z_j\right)}{\left|Z_i-z_j\right|}\right)_{n\times n} $$ has nonzero determinant.","['complex-analysis', 'linear-algebra', 'analysis']"
2942457,Flat ring homomorphism but not injective.,"Let $A\to B$ be flat ring homomorphism(i.e. $B$ is flat $A$ module.) If $B$ is faithfully flat, then $A\to B$ is injection. $\textbf{Q:}$ What is the example of flat but not injective ring homomorphism?(i.e. I want to fail faithfully flat but remain flat.) I think I need some ring $B$ as projective which realizes $B=F/N$ where $F$ is free $A-$ module and this has to be compatible with ring structure as well. Clearly, I could not get this work over $A$ being a field.","['abstract-algebra', 'commutative-algebra']"
2942484,Absolute sum of partitioned Rademacher variables,"$
    \newcommand{\E}{\mathop{\mathbb{E}}}
  $ Hi, this is the first time I post a question here, so I'd be glad to have comments to make it better. So here it goes. The problem I am looking to compute the Rademacher complexity of a class of function and I have reduced the problem to this. Let $\vec{\sigma} \in \{\pm 1\}^m$ be a set of $m$ Rademacher variables (i.e. taking value $\pm 1$ with probability $\frac{1}{2}$ each). Split $\vec{\sigma}$ in two consecutive sequences: sum each sequence individually, then take the absolute value of these sums before summing them together. I am looking for the split which will achieve the maximum value for this operation. More formally, we write: \begin{align}
T(\vec{\sigma}) = \displaystyle\sup_{1 \leq i < m} \left( \left| \sum_{k \leq i} \sigma_k \right| + \left| \sum_{k > i} \sigma_k \right| \right).
\end{align} We need to take the expectation over $\vec{\sigma}$ of this expression to obtain the Rademacher complexity: \begin{align}
R_m = \E_{\vec{\sigma}} \left[ T(\vec{\sigma}) \right].
\end{align} I am looking for an analytical expression for $R_m$ . Questions Is this problem known or equivalent to another one? If yes, I'd like references. If not, is there a way to compute exactly $R_m$ ? If not, is it possible to upper bound it non-trivially? (A trivial bound would be $R_m \leq m$ .) Any insight about how to tackle the problem would be appreciated, and could be accepted as an answer if none of the above is provided. What I've tried I have computed the sum over all $\vec{\sigma}$ up to $m=12$ to find a pattern, without success. Here they are: \begin{equation}
\begin{array}\\
m & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12\\
2^m R_m & 2 & 8 & 20 & 48 & 112 & 248 & 548 & 1184 & 2540 & 5408 & 11420 & 24048
\end{array}
\end{equation} This sequence is not in the OEIS, so no luck there. I have tried to express $R_m$ in terms of $R_{m-1}$ . I was not able to find a pattern there either. Finally, I have tried to express the numbers $2^m R_m$ as a sum by counting the number of $\vec{\sigma}$ for which $T(\vec{\sigma})$ would give $m$ , then how many would give $m-2$ , then $m-4$ , etc. up to $m=2$ or $1$ (if $m$ is even or odd). (It is easy to convince yourself that $m$ minus an odd number is not possible.) Mathematically speaking, we have: \begin{align}
2^m R_m = \sum_{i=0}^{\lfloor \frac{m}{2} \rfloor} a^m_i (m-2i).
\end{align} I have found that: for all $m\geq 1$ , $a^m_0 = 2m$ for all $m\geq 4$ , $a^m_1 = 2m(m-3)$ for all $m\geq 7$ , $a^m_2 = m(m^2 -7m +8)$ for all even $m=2n$ , the last coefficient is $a^m_{n-1} = 2^{n+1}$ for all odd $m=2n+1$ , the last coefficient is $a^m_n = 2$ I have yet to find a general formula for $a^m_i$ , but it would be a nice starting point. Related problem I have considered the following related simpler problem \begin{align}
T^0(\vec{\sigma}) = \left| \sum_{k=1}^m \sigma_k \right|, \qquad R^0_m = \E_{\vec{\sigma}} \left[ T^0(\vec{\sigma}) \right].
\end{align} We have that for all $\vec{\sigma}$ , $T^0(\vec{\sigma}) \leq T(\vec{\sigma})$ . This problem has an exact solution. We have that \begin{align}
2^m R_m = \sum_{i=0}^{\lfloor \frac{m}{2} \rfloor} 2 \binom{m}{i} (m-2i) = 2m \binom{m-1}{\lfloor \frac{m}{2} \rfloor}.
\end{align} Just to give an idea, this function is upper bounded by \begin{align}
2m \binom{m-1}{\lfloor \frac{m}{2} \rfloor} \leq \sqrt{\frac{2}{\pi}} \frac{2^m m}{\sqrt{m+\frac{1}{2}}}.
\end{align} Hope this can give some insights.","['machine-learning', 'combinatorics', 'probability']"
2942513,can the sine of a polynomial be periodic?,"For which polynomials $p(x)$ is $\sin p(x)$ periodic? I started by observing that if $f(x)$ is periodic than also $f'(x)$ is periodic. Than $p\,'(x) \cos p(x)$ is periodic. Of course if $\deg p\,'(x) > 0$ that thing isn't periodic but... how can I prove it? ${{}}$","['periodic-functions', 'trigonometry', 'polynomials']"
2942609,"What is the number of subsets of $\{1, ..., n\}$ which sum to a given number $k \leq \frac{n(n+1)}{2}$?","I'm trying to compute the number of ways to sum the first $n$ unique positive integers to a number $k$ . This is not a partition of $n$ since we can't repeat numbers. Any hints on how I can derive a generating function for this? I encountered this in trying to compute the variance of the sum of $k$ balls randomly drawn from an urn of $n$ balls (where each ball is labeled with a unique positive integer from $1...n$ ). Letting $S$ be the random variable which is this sum, computing the variance using the definition of expectation directly uses $P(S = k) = \frac{N_{n,k}}{{n\choose k}}$ , where $N_{n,k}$ denotes the desired quantity above. I can compute the variance by writing $S$ as a sum of indicators and expanding the expression inside of the expectation, but I was wondering if there was a nice expression for the above quantity. Thank you!","['combinatorics', 'probability']"
2942624,Why is the homogeneous line through all points at infinity (1:0:0) and not (0:0:0)?,So I just had a geometry lecture that introduced me to homogenous coordinates. To be clear with notation let me recap: Homogenous coordinates in $\mathbb R^n$ space are described as $$(x_0:x_1: ... : x_n)$$ where $x_0$ is the factor by which to divide to get cartesian coordinates: $$(\dfrac{x_1}{x_0}:\dfrac{x_2}{x_0}: ... : \dfrac{x_n}{x_0})$$ next up we learned that the point at both ends of of a line in 2 dimensions - and each line parallel to it - is defined as $$(0:x_1:x_2)$$ Now here's my question: After hearing this I concluded that the line through all points at infinity must be $(0:0:0)$ but instead we got told that the line homogenous coordinates for that line are $(1:0:0)$ and that the point at $(0:0:0)$ does not exist. What is the reasoning behind this? How does this follow from the definiton of other points at infinity?,"['coordinate-systems', 'homogeneous-spaces', 'geometry', 'infinity']"
2942630,Show that $\int_0^1 \frac{\ln(1+x)}x\mathrm dx=-\frac12\int_0^1 \frac{\ln x}{1-x}\mathrm dx$ without actually evaluating both integrals,"While doing some research on the 'alternating Basel Problem' I have come across this related post which states the equality $$\int_0^1 \frac{\ln(1+x)}x\mathrm dx=-\frac12\int_0^1 \frac{\ln x}{1-x}\mathrm dx\tag1$$ Using the Dilogarithm one can show that 'alternating Basler Problem' is a direct consequence of this equation and yields to $$\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n^2}=\frac{\pi^2}{12}$$ Therefore I have no doubts to trust the author of the the cited post. However, I tried to verify the equality by myself and failed. For this purpose I enforced the substitution $x\mapsto1+x$ within the integral on the right $$\begin{align}
-\frac12\int_0^1 \frac{\ln x}{1-x}\mathrm dx=-\frac12\int_{(0-1)}^{(1-1)} \frac{\ln(1+x)}{1-(1+x)}\mathrm dx=-\frac12\int_{-1}^{0} \frac{\ln(1+x)}x\mathrm dx
\end{align}$$ But from hereon I am not sure how to proceed. Clearly now I have to show that $$\begin{align}
-\frac12\int_{-1}^0\frac{\ln(1+x)}x\mathrm dx&=\int_0^1 \frac{\ln(1+x)}x\mathrm dx\\
\frac12\int_0^1\frac{\ln(1-x)}x\mathrm dx&=\int_0^1 \frac{\ln(1+x)}x\mathrm dx\\
0&=\int_0^1 \frac1x\left(\ln(1+x)-\frac12\ln(1-x)\right)\mathrm dx
\end{align}$$ It seems like I have made a mistake somewhere inbetween since WolframAlpha does not agree with my reasoning. Additionally I have no idea how to proceed. To be honest I am quite confused right now. First of all where exactly did I went wrong? Furthermore could someone provide a complete proof for the given equality? Please tell me when this question has been asked before. Thanks in advance!","['integration', 'calculus', 'definite-integrals', 'logarithms']"
2942790,Why do Integrating Factors Work?,"Given a non-exact differential equation, $$M(x,y) dx + N(x,y)dy = 0,$$ an integrating factor is a function $\mu(x,y) \ne 0$ such that the equation $$\mu Mdx + \mu N dy = 0$$ is exact. I understand how to find integrating factors, but my only confusion is, why do they work?  How do we know that the resulting function will have the same solution set as the original differential equation? I understand that multiplying a function by another function can drastically change the behavior.  So for this procedure, how do we know that solving the new differential equation will lead to potential solutions to the original one?","['integration', 'ordinary-differential-equations']"
2942812,Numbers of the form $m^2+2^n$,"I would like to show that there are infinitely many primes $p$ such that every number is congruent to $m^2+2^n$ modulo $p$ for some positive integers $m,n$ . This is what I have tried so far: if 2 is a primitive root modulo $p$ , then clearly the claim is true since every number except 0 is of the form $2^n$ modulo $p$ . Moreover, $0=(-1)+1$ and since $-1 \equiv 2^k$ for some $k$ , we have $0 \equiv 1^2+2^k \pmod p$ . However, we don't know if 2 is a primitive root modulo infinitely many primes. I also tried to look at the set of quadratic residues modulo $p$ . Let's denote this set by $Q_p$ . Then we look at the sets $Q_p+2^k=\{q+2^k: q \in Q_p,~k\geq 0\}$ and define $S=\bigcup_k (Q_p+2^k)$ . We need to show that $S=\mathbb{Z}_p$ . I can show that the if $2$ is a quadratic residue modulo $p$ then the set $S$ is closed under multiplication by 2 modulo $p$ and has size greater than $3p/4$ . Also the sum of the elements of $S$ is zero modulo $p$ . I can't see a way forward.","['number-theory', 'prime-numbers']"
2942824,"Differential equations, Linear Equations: Find value of B so that a function is a solution to homogeneous func.","I need to find the value of B so the function $y=c_1e^{3x}+c_2e^{5x}+Be^{4x}$ is a solution to $y''-8y'+15y=6e^{4x}$ . Here's the work I have done. I know that $y_1=e^{3x}$ so I can use that to find some differentials: $y_1'=3e^{3x}$ and $y_1''=9e^{3x}$ substituting these values into the homogenous equation above just verifies that the functions are solutions to the nonhomogeneous equation (sorry if I have the homogenous and nonhomogeneous equations backward). Anyway, after that verification, I would take $y_p=6e^{4x}$ and verify it too by subbing. However, this does not help me find the value of B. I'm really not sure what to do with this question and would really appreciate some help. I've been looking at this for quite a while now. Thank you.","['linear-algebra', 'ordinary-differential-equations']"
2942831,Proof of a criterion for Bochner integrability,"The following comes from the Wikipedia article on Bochner integrals . Theorem . If $(X,\Sigma,\mu)$ is a measure space, then a Bochner-measurable function $f:X\to B$ is Bochner integrable if and only if $$\int_X\|f\|_B\,d\mu<\infty.$$ Here are the relevant definitions. Definition . A function $f:X\to B$ is called Bochner-measurable if it is equal $\mu$ -almost everywhere to a function $g$ taking values in a separable subspace $B_0$ of $B$ , and such that the inverse image $g^{−1}(U)$ of every open set $U$ in $B$ belongs to $\Sigma$ . Definition . A measurable function $f:X\to B$ is Bochner integrable if there exists a sequence of integrable simple functions $s_n$ such that $$\lim_{n\to\infty}\int_X\|f-s_n\|_B\,d\mu=0,$$ where the integral on the left-hand side is an ordinary Lebesgue integral. How do I prove the theorem above? I'm following Analysis III by H. Amann & J. Escher, and this theorem is indeed proved, but under the assumption that $\mu$ is complete and $\sigma$ -finite. The subtlety here is this (I'll stick to the notations and terminologies on the wikipedia article): Theorem . $f$ is Bochner measurable if and only if $f$ is limit $\mu$ -almost everywhere of a sequence of simple functions. Theorem . If $\mu$ is $\sigma$ -finite, $f$ is Bochner measurable if and only if $f$ is limit $\mu$ -almost everywhere of a sequence of integrable simple functions. The proof of the latter makes use of $\sigma$ -finiteness to ensure that the the simple functions $s_n$ are indeed integrable , i.e., $s_n^{-1}(B\setminus\{0\})$ has finite measure. On the other hand, I can prove this (by adapting the proof from Amann & Escher): Theorem . If $f$ is limit $\mu$ -almost everywhere of a sequence of simple functions, then there is a sequence of simple functions $s_n$ such that $$\lim_{n\to\infty}\int_X\|f-s_n\|_B\,d\mu=0.$$ Theorem . If $f$ is limit $\mu$ -almost everywhere of a sequence of integrable simple functions, then there is a sequence of integrable simple functions $s_n$ such that $$\lim_{n\to\infty}\int_X\|f-s_n\|_B\,d\mu=0.$$ (The reason is that, the proof assumes there is a sequence of simple functions $t_n\to f$ a.e., and then constructs $s_n$ out of $t_n$ . If $t_n$ are integrable, then $s_n$ are integrable by construction.) Therefore, assuming $\sigma$ -finiteness, we can show: $f$ is Bochner-measurable $\implies$ $f$ is limit $\mu$ -almost everywhere of a sequence of integrable simple functions $\implies$ there is a sequence of integrable simple functions $s_n$ such that $$\lim_{n\to\infty}\int_X\|f-s_n\|_B\,d\mu=0.$$ However, I don't know how I should prove this without $\sigma$ -finiteness.","['banach-spaces', 'measure-theory', 'analysis', 'real-analysis']"
2942852,Finding $\beta$ where $u_x(0)=\beta$ is a boundary value of a heat equation,"Suppose an ice core are perfectly insulated and heated at one end at a rate $\alpha$ and cooled from the other end at a rate $\beta$ . Consider the following boundary value problem $$u_t-u_{xx}=0, \ u_x(0)=\beta, \ u_x(l)=\alpha,$$ where $u$ is temperature, $t$ is time and $l$ is the length of the core. What should $\beta$ be such that the ice cores temperature remains stable ( $u_t=0$ )? My attempt: If $u_t=0$ , then this implies $u_{xx}=0$ . if we integrate both sides with respect to $x$ , we get $$u_x=A$$ for some $A\in\mathbb{R}$ . So, $$u_x(0)=\beta\implies A=\beta,\\u_x(l)=\alpha\implies A=\alpha.$$ Hence, we conclude that $\beta=\alpha\in\mathbb{R}$ . For part (b), assuming $\alpha=1, l=10$ and the average temperature of the core is $-15$ , what is the solution for $u$ in the stable case. Finally, If the cooling mechanism were to fail ( $\beta=0$ ) how long would it take before the ice core started to melt (i.e. when would $u$ rise above $0$ at any point)?","['heat-equation', 'boundary-value-problem', 'proof-verification', 'ordinary-differential-equations']"
2942903,"""winding number"" of the map: $M \to S^3$ when $M$ is a non-orientable 3-manifold","Let $M$ be a non-orientable three dimensional manifold. I am interested in knowing how to characterize the topological properties of the map $$M\to S^3$$ where $S^3$ is parameterized by $(\phi_1, \phi_2, \phi_3, \phi_4)$ with the constraint $$\sum_{i=1}^{4} \phi_i^2=1$$ More concretely, I want to know how the integral $$\mathcal{I}[M]\equiv \frac{2}{\pi^2} \int_{M} (\epsilon^{abc} \phi_1 \partial_a \phi_2 \partial_b \phi_3 \partial_c \phi_4) \;dx dy dz\;$$ is quantized. In particular, it is known that the integral $\mathcal{I}[M]$ is quantized to be an integer for any oriented $M$ . See the post An integral map from 3-torus $\mathbb{T}^3$ to 3-sphere $S^3$ for an explanation when $M=T^3$ . Here I am interested to know how $\mathcal{I}[M]$ is quantized when $M$ is non-orientable. Presumably, I expect $\mathcal{I}[M]$ is quantized to be $$\mathcal{I}[M]\in \frac{1}{p_M}\mathbb{Z}$$ for some integer $p_M$ that depends on $M$ , and I would like to know what $p_M$ is. More concretely, 1) When $M=RP^2 \times S^1$ , what is $p_{RP^2 \times S^1}$ ? 2) When $M=KB\times S^1$ , $KB$ is klein bottle,  what is $p_{KB}$ ? 3) What is the largest possible value of $p_{M}$ for all possible non-orientable manifold $M$ ? Thanks for your help!","['integration', 'general-topology', 'differential-topology', 'differential-geometry']"
2942922,"What is the solution for the differential equation $\frac{dy}{dx} = -\frac{y}{x}, y(-2) = -2$","Given $\dfrac{dy}{dx} = -\dfrac{y}{x}, y(-2) = -2$ I wish to solve for $y(x)$ . Separating the variables, I have, $\dfrac{1}{y} dy = -\dfrac{1}{x} dx$ So $\ln(|y|) = -\ln(|x|) + c$ So $|y| = \exp({-\ln(|x|)+ c)}) = K \exp({\ln(\dfrac{1}{|x|})}) = K\dfrac{1}{|x|}$ At this step, I am unsure how to deal with the absolute value sign. Does anyone have idea as to how to proceed?","['analysis', 'mathematical-modeling', 'ordinary-differential-equations']"
2942923,Representation of ordinary differential operators in terms of a given regular operator,"I'm trying to understand Lemma 3.2 from p. 355 of the paper R. C. Carlson and K. R. Goodearl, Commutants of Ordinary Differential Operators , Journal of Differenial Equations 35 (1980), 339–365. The authors define $B$ as a matrix coefficient with $C^\infty$ entries, $D$ is the ordinary derivative operator on $\bigoplus^k C^\infty(\mathscr J)$ for some open interval $\mathscr J$ , and $L$ as the differential operator given below (from the previous page) $\textbf{Question}$ : I can't see how this is true that any differential operator can be written in this way. I'm trying to see it in the scalar case, i.e. where $A,B$ are $1\times 1$ matrices but I can't even construct non-trivial examples that can be written in that way. Moreover, I don't even understand what the proof is doing.","['differential-operators', 'ordinary-differential-equations', 'operator-theory', 'real-analysis', 'functional-analysis']"
2942972,Showing a sub-sequence ($r_{n_{k}}$) converges to $x$,"There exists a bijection that $f : N → Q, x \in R$ * $r_{n}$ := $f(n)$ I am asked to show that there exists a sub-sequence ( $r_{n_{k}}$ ) of ( $r_{n}$ ) so that the limit of the sequence ( $r_{n_{k}}$ ) will converges to $x$ as I know I only need to show ( $r_{n}$ ) converges to $x$ as ( $r_{n_{k}}$ ) is just a sub-sequence of it. But how can I show ( $r_{n}$ ) converges to $x$ and what is it to do with bijection?","['education', 'limits', 'discrete-mathematics']"
2942989,Evaluating the limit : $ \lim_{n \to \infty} \frac{ \sum_{k=1}^n n^k}{ \sum_{k=1}^n k^n}$,Here I'm given this limit. $$\displaystyle \lim_{n \to \infty} \dfrac{\displaystyle \sum_{k=1}^n n^k}{\displaystyle \sum_{k=1}^n k^n}$$ $\displaystyle \sum_{k=1}^n n^k$ simplifies to $\dfrac{n(n^n-1)}{n-1}$ but I'm unable to tackle $\displaystyle \sum_{k=1}^n k^n$ . How do you evaluate this limit?,['limits']
2943074,Confusion about order of rotations for Euler Angles,"I'm taking a robotics class and trying to understand Euler angles. My understanding is, matrices are applied to to the vector from right to left (the first transformation applied is the one closest to $\overrightarrow{\boldsymbol{x}} $ ) My book defines Euler angles as: If we are rotating about the Z axis first , then shouldn't the rightmost matrix be for the Z rotation and not the X rotation? Shouldn't we have the transformation $${_a^b}R_{{Z^\prime}{Y^\prime}{X^\prime}}=R_X(\gamma)R_Y(\beta)R_Z(\alpha) $$ rather than $${_a^b}R_{{Z^\prime}{Y^\prime}{X^\prime}}=R_Z(\alpha)R_Y(\beta)R_X(\gamma) $$ I've read the definition from my textbook in several places and am aware it is correct, but","['linear-algebra', 'linear-transformations', 'rotations']"
2943089,Uniqueness of Lebesgue measure on $S^n$,"I am trying to prove that the Lebesgue measure on $S^n$ is the unique countably additive, rotation-invariant measure of total measure 1 defined on Lebesgue-measurable sets. I know the proof of the analogous statement for the Lebesgue measure with $\mathbb{R}^n$ . However, in that case we start from rectangles, which have the nice property that a disjoint union of countably many rectangles cover the whole space and that the intersection of two rectangles is again a rectangle. I don't know how to define the analogue of a rectangle on the sphere, even if in $S^1$ and $S^2$ I can sort of picture what they should look like... Also I have found no reference apart from one in Russian so if someone knows of something in English French Italian or German please answer with a link!","['measure-theory', 'lebesgue-measure', 'spheres', 'real-analysis']"
2943094,Motion of an object that always has an acceleration perpendicular to its velocity,"Consider an object whose position vector $x$ (changes with time) satisfies the condition $$
\dot{x}\cdot\ddot{x}=0
$$ i.e. the object is always accelerating in the direction perpendicular to its direction of motion. How can I solve the DE and find an equation relating $x$ and $t$ (the time)? Is it wrong to say that the speed should be constant?","['physics', 'vector-analysis', 'ordinary-differential-equations']"
2943101,How many numbers are there which only contain digits $4$ and $7$ in them? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question I wanna know how many numbers $n$ are there which only contain digits $4$ and $7$ in them, where $1 ≤ n ≤ 10^9$ . Ex: $4, 7, 44, 47, 74, 77, ...$ I am trying to find a general equation to compute the numbers, given how many digits, which is $2$ in this case, and the range, which is $1 ≤ n ≤ 10^9$ in this case.","['combinatorics', 'discrete-mathematics', 'decimal-expansion']"
2943102,Solution to the equation of a polynomial raised to the power of a polynomial.,"The problem at hand is, find the solutions of $x$ in the following equation: $$ (x^2−7x+11)^{x^2−7x+6}=1 $$ My friend who gave me this questions, told me that you can find $6$ solutions without needing to graph the equation. My approach was this: Use factoring and the fact that $z^0=1$ for $z≠0$ and $1^z=1$ for any $z$ . Factorising the exponent, we have: $$ x^{2}-7x+6 = (x-1)(x-6) $$ Therefore, by making the exponent = 0, we have possible solutions as $x \in \{1,6\} $ Making the base of the exponent = $1$ , we get $$ x^2-7x+10 = 0 $$ $$ (x-2)(x-5)$$ Hence we can say $x \in \{2, 5\} $ . However, I am unable to compute the last two solutions. Could anyone shed some light on how to proceed?","['algebra-precalculus', 'systems-of-equations', 'polynomials']"
2943158,Is it possible to prove that $M$ is an integer with $p+M \over x$ is always an integer?,"Given a prime number $p$ and a set $S$ of $n$ rational numbers . Multiply all $n$ rational numbers we get a number $M$ . For each number $x$ in the set $S$ , we have $\frac{p+M}{x}$ is an integer . Is it possible to prove that $M$ is also an integer ? For $n = 2$ , let $S=\left\{x,y\right\}$ . Then $\frac{p+M}{x}=\frac{p}{x}+y$ , $\frac{p+M}{y}=\frac{p}{y}+x$ are integers, then multiply the two numbers we have $\frac{p^2}{M}+2p + M$ is an integer, thus $\frac{p^2}{M} + M=\alpha$ is an integer. If $M=\frac{A}{B}$ with $A$ , $B$ are coprime, then $B^2\times p^2+A^2=\alpha A B$ so $B|A^2$ then $B=1$ , thus $M$ is an integer. Is it true that for every $n>2$ , $M$ is an integer? If not, then what are the conditions of $n$ so that $M$ must be an integer? Edit: If $M$ is an integer, then is $M$ a power of $p$ ?","['number-theory', 'abstract-algebra', 'combinatorics', 'geometry']"
2943162,Generic condition for vector fields/normal sections,"Let $(M,g)$ be a riemannian manifold, and $S\subset M$ a submanifold. I would like to know if there is a result which states that, for some hypothesis about the codimension of $S$ , the property for a vector field $X\in\mathcal{T}(M)$ to being nowhere tangent to $S$ is generic. Writing, for $p\in S$ , the orthogonal decomposition $T_pM=T_pS\oplus N_pS$ , and $f_X:S\to NS$ defined by $f_X(p)=(X_p)^\perp$ , the property can be rewrited as $f_X^{-1}(0_{NS})=\varnothing$ , the latter being equivalent to $f_X\pitchfork 0_{NS}$ iff $\dim S-\mathrm{codim}\,0_{NS}<0$ , i.e. $2\dim S<\dim M$ . Since transversality is a generic property, a generic vector field is nowhere tangent to $S$ if $2\dim S<\dim M$ . I would like to know if this kind of reasoning is correct, and if this result is true we can actually find sharper bounds for the inequality. Thank you!","['vector-bundles', 'differential-geometry']"
2943176,Find the equation in spherical coordinates of $x^2 + y^2 – z^2 = 4$.,"Find the equation in spherical coordinates of $x^2 + y^2 – z^2 = 4$ . $$\begin{align}
x^2 + y^2 &= r^2\sin^2(\theta)\\
z^2 &= r^2 \cos(\theta) \\
x^2 + y^2 - z^2&=r^2(\sin^2(\theta) - \cos^2(\theta)) = 4
\end{align}$$ Thus, $$-r^2(\cos(2\theta)) = 4$$ Is this right?","['multivariable-calculus', 'spherical-coordinates']"
2943202,Classifying bundles with homogeneous space as fibers,"A principal $G$ -bundle over a space $X$ is classified by the homotopy classes of maps $[X,BG]$ , where $BG$ is the classifying space of the group $G$ . My question is what can we do about this when the fiber is a homogeneous space. For a general fiber bundle $F\hookrightarrow E\rightarrow X$ , the classification is usually done by $[X,B\rm{Diff}(F)]$ and is obviously a difficult beast. But for a homogeneous space $G/H$ , for $G$ a Lie group and $H$ a closed subgroup, can we say something about the space $B\rm{Diff}(G/H)$ ? Is there any way to relate them to say $BG$ and $BH$ ? More specifically what I'm looking for is a way to classify Lagrangian Grassmann bundles over a certain manifold. It is known that the fiber $LG(n,2n)=U(n)/O(n)$ is a homogeneous space. So is there any classification result in this direction? Any help is appreciated!","['homogeneous-spaces', 'fiber-bundles', 'algebraic-topology', 'differential-geometry']"
2943253,How to come up with a greedy solution and prove it?,"Say we have a function $S(x)$ , which gives the sum of the digits in the number $x$ . So $S(452)$ would be $4 + 5 + 2 = 11$ . Given a number $x$ , find two integers $a, b$ such that $0 <= a, b <= x$ and $a + b = x$ . Objective is to maximize $S(a) + S(b)$ . I came across this question on a programming website and the answer is to greedily choose a number $a$ containing all $9$ 's such that it is lesser than $x$ , and the other number would be $x - a$ . If $x = 452$ , then $S(99) + S(353) = 29$ which is the maximum possible. How do I come up with this and prove the same?","['number-theory', 'discrete-mathematics', 'algorithms']"
2943260,Why noetherian rings [duplicate],"This question already has answers here : Why are Noetherian Rings important? (4 answers) Closed 5 years ago . While in undergraduate years, abstract stuctures are very confusing since they arise without many motivations most of the times, and find their living ground later on. I would like to understand why noetherian rings are interesting. Principal and euclidean rings are definitely useful to have arithmetic tools and notion generalizing those of the arithmetics of integers. What about noetherian rings? It often appears in arithmetic courses, however what allows them to do that other rings do not? What are the lost properties compared to a principal ring? In one sentence: how to grasp the meaning and interest of noetherian rings (or other structures)?","['number-theory', 'ring-theory', 'abstract-algebra', 'noetherian']"
2943261,"Maximum likelihood - uniform distribution on the interval $[θ_1,θ_2]$","Based on a random sample (6.3, 1.8, 14.2, 7.6) use the method of maximum likelihood to estimate the maximum likelihoods for $\theta_1$ and $\theta_2$ . $$f_y(y;\theta_1, \theta_2) = \frac{1}{\theta_2- \theta_1} \;, \quad \theta_1 \le \theta_2$$ $$L(\theta_1, \theta_2) = \prod_\limits{i=1}^{n}\frac{1}{\theta_2-\theta_1} \\
= \frac{1}{(\theta_2- \theta_1)^n}\prod_\limits{i=1}^{n}1(\theta_1 \le y_i \le \theta_2) \\
= \frac{1}{(\theta_2- \theta_1)^n}\prod_\limits{i=1}^{n}1(\theta_1 \le y_i)1(y_i \le \theta_2) \\
\text{Let } T = \ln[L(\theta_1, \theta_2)] = -n \ln(\theta_2 - \theta_1) + \sum_\limits{i=1}^n\ln(1(\theta_1 \le \min_i(y_i))1(\max_i(y_i) \le \theta_2)) \\
\begin{cases}
-\infty, & \text{if } \theta_1>\min_i(y_i) \text{ or } \theta_2 < \max_i(y_i) \\
-n\ln(\theta_2 - \theta_1), &  \text{otherwise} 
\end{cases} $$ now take the derivative with respect to one of them $$\frac{\partial{T}}{\partial{\theta_2}} = \frac{-n}{\theta_2 - \theta_1} \\
= \frac{n}{\theta_1 - \theta_2}$$ To maximise this we want the numerator magnitude to be as small as possible, so we set $\theta_2 = \max_i(y_i)$ and for $\theta_1$ $$\frac{\partial{T}}{\partial{\theta_1}}=\frac{n}{\max_i(y_i) - \theta_1}$$ To maximise this, we want $\theta_1 = \min_i(y_i)$ This implies $\theta_1 = 1.8$ and $\theta_2 = 14.2$ If someone could check my correctness particularly around the indicator functions because I'm new to those and anything else you can see wrong in math or formatting. Actually I think that stuff in yellow directly above is not right. I'm not equating the derivative to 0. I think I got the correct answer regardless.
Probably more preferably is to look at the $$-n\ln(\theta_2 - \theta_1)$$ And know to minimise the value in the brackets will maximise the $\ln[L(\theta_1, \theta_2)]$ function, and coming to the same result that I did illegitimately. Implies that $\hat{\theta_1} = 1.8$ and $\hat{\theta_2}=14.2$","['calculus', 'statistics', 'maximum-likelihood']"
2943291,The ways of covering a $4\times 4$ square by $1\times 2$ colored dominoes,"I'm stuck with this question We have eight $1\times 2$ tiles that each one of them has one $1\times 1$ blue square and one $1\times 1$ red square. We want to cover a $4\times 4$ area with these tiles in a way that every row and every column of this area had exactly $2$ blue and $2$ red $1\times 1$ squares. In how many  ways we can do this? First of all, I tried to find out all possible  ways which I can cover a $4\times 4$ square by $1\times 2$ dominoes. If I know all such possibilities,  then  for each such a covering, by obtaining the number of ways that some one can tiles this dominoes in blue-red squares in the manner that described above, we can get the answer. In the article How Many Ways Can We Tile a Rectangular Chessboard With Dominoes? the writer claims that the number of ways which we can tile a $4\times 4$ rectangle is $36$ . But he did not described all this $36$ ways. The above method is very prolix and also, I need to obtain all the possibilities of covering $4\times 4$ square by $1\times 2$ tiles and for each of such covering, all the ways which can satisfied by the conditions of question. Dose any one know a simpler method? I should point out that the above question is designed for high school students and so I think it must have a simple solution.","['combinatorics', 'tiling', 'discrete-mathematics']"
2943310,Linearity of ordinals,"Ordinals are defined as a set which is transitive and all its elements are transitive. In the proof of linearity of ordinals i.e. $$\forall a \forall b : a<b  \vee a>b \vee a=b $$ We assume that this fails and choose minimal $a$ such that $b$ is neither less than or greater than or equal to $a$ . How do we know we can choose such a minimal element? i.e. 1) How do we know the set of such $a$ has all elements comparable  (aren't we proving this very thing ?)? 2) If this set has all elements comparable then how is a minimal element guaranteed? One can go further and ask does 1) makes sense, i.e. do such $a$ s make a set. How does one answer this question?","['elementary-set-theory', 'ordinals']"
2943312,How does Weierstrass' theorem follow from Mergelyan's theorem?,"According to Theorems 1 and 3 in this review article we have Weierstrass: Suppose $f$ is a continuous function on a closed bounded interval $[a,b] \subset\mathbb{R}$ . For every $\epsilon > 0$ there exists a polynomial $p$ such that for all $x \in [a,b]$ we have $| f(x)− p(x)| < \epsilon$ . Mergelyan: If $K$ is a compact set in $C$ with connected complement, then every continuous function $f\colon K\to \mathbb{C}$ that is holomorphic in the interior of $K$ can be approximated
  uniformly on $K$ by holomorphic polynomials. Both Wikipedia and the review say that the latter is a generalization of the former. In which sense is this true? 
How does Weierstrass' theorem follow from Mergelyan's?","['complex-analysis', 'weierstrass-approximation', 'approximation-theory']"
2943314,Is there any other way to solve this difficult integral $ \int \frac{1}{ (a^2 \cos ^2 x + b ^ 2 \sin ^2x) ^2} \ dx $,"$$
 \int \frac{1}{ (a^2 \cos ^2 x + b ^ 2  \sin ^2x) ^2} \ dx
$$ So this is the question . The solution given in book is to divide numerator and denominator by $\cos ^4x$ and then substitute $\tan x = t$ in the resulting integrand. Other way of doing this was to substitute $b \tan x = a \tan t$ . So I was thinking is not there any other way to solve this as it seems to a complicated problem as the given methods are very lengthy while solving. Any simpler\shorter method anyone could think of ?","['integration', 'indefinite-integrals', 'trigonometry', 'trigonometric-integrals']"
2943316,How to solve $32^x - 8 = 2 \cdot 4^x$,"I am given the following equation to solve $$32^x - 8 = 2 \cdot 4^x$$ which one can simplyfy to $$2^{5x}-2^3 = 2^{2x+1}$$ where do we go from here? If we had something like $$2^{2x} - 5 \cdot 2^x + 6 = 0$$ we could convert it to a quadratic, but not in this case. Any help is highly appreciated.","['algebra-precalculus', 'exponential-function']"
2943322,"Given $f(a-x)=f(a+x)$ and $f(b-x)=f(b+x)$, where $a,b$ are positive constants $(a>b)$, prove that $f(x)$ is a periodic function","Given $f(a-x)=f(a+x)$ and $f(b-x)=f(b+x)$ , where $a,b$ are positive constants $(a>b)$ , prove that $f(x)$ is a periodic function I have done the following: $f(a-x)=f(a+x)$ ....(1) or, $f(-(x-a))=f(x+a). $ Putting $x=x+a$ , we get $f(-x)=f(x+2a) ....(i)$ Similarly, $f(b-x)=f(b+x).....(2) $ Putting $x=x+b,$ we get $f(-x)=f(x+2b)......(ii)$ Equating $(i)$ & $(ii)$ , we get: $f(x+2a)=f(x+2b).$ Given, $a>b$ Therefore, $2a=2b+h.$ Putting $x=x-2a$ , we get $f(x+h)=f(x).$ Is this mathematically correct? Also, what other ways are there to solve it?",['algebra-precalculus']
2943368,Infinitesimal generator of a smooth $S^1$-action over $\mathbb C$,"Question : Consider the symplectic manifold $(\mathbb C, \omega_0 = \frac{i}{2} {\rm d}z \wedge {\rm d}\bar z)$ and a smooth $\Bbb S^1$ -action over $\mathbb C$ given by $$(t,z) \mapsto t^kz$$ for some fixed $k \in \mathbb Z$ , with moment map $\mu: \mathbb C \to \frak {g}^* \cong i\mathbb R$ given by $$\mu (z) = -\frac{i}{2}k|z|^2$$ What is the infinitesimal generator of this action $(X^\#)_{z_0} = \displaystyle \frac{d}{dt}\bigg|_{t=0} \exp(tX)\cdot z_0$ ? Attempt: I tried to use polar coordinates $z = r e^{i\theta}$ . Then the symplectic 2-form is $\omega_0 = r {\rm d}r \wedge {\rm d}\theta$ and the moment map should be $$\mu (re^{i\theta}) = -\frac{i}{2}kr^2$$ if we consider the global flow $\exp : \mathfrak g = \text{Lie} (S^1) \cong i\mathbb R \to S^1$ , $\exp (is) = e^{is}$ then $$\begin{align}(X^\#)_{z_0} &= \frac{d}{dt}\bigg|_{t=0} \exp(tX)\cdot z_0 = \frac{d}{dt}\bigg|_{t=0} e^{its}\cdot z_0 \\&= \frac{d}{dt}\bigg|_{t=0} e^{itks} z_0 = iksz_0 \\&= iksr_0 e^{i\theta_0} = -ksr_0 \sin \theta_0 + i ksr_0 \cos \theta_0\end{align}$$ I can't see how this is a vector field written in coordinates $\frac{\partial}{\partial r}$ and $\frac{\partial}{\partial \theta}$ . Any help?","['symplectic-geometry', 'smooth-manifolds', 'lie-groups', 'differential-geometry']"
2943404,Does there exist a function $ f $ such that $ f ( x ) $ is an integer for only finitely many values of $ x $?,Consider $ f : \mathbb R \to \mathbb R $ such that $ f ( x ) \le f ( y ) $ whenever $ x \le y $ and $ f ^ { 2018 } ( z ) \in \mathbb Z \ \forall z \in \mathbb R $ . Does there exist a function $ f $ such that $ f ( x ) $ is an integer for only finitely many values of $ x $ ? I think that the condition of the problem forces $ f ^ n ( x ) \in \mathbb Z $ for all integer $ n \ge 2018 $ . But this doesn't help I guess. And I'm somewhat sure that the answer is NO . Side-Note: $ f ^ n ( x ) $ denotes $ n $ -th composition of $ f $ .,"['functional-equations', 'functions']"
2943416,Proving that $(-1)^{n+1}G_n =\int_0^\infty \frac{1}{(1+x)^n (\pi^2+\ln^2 x)} dx$,"Prove Schroder's Integral formula : $$(-1)^{n+1}G_n =\int_0^\infty \frac{1}{(1+x)^n (\pi^2+\ln^2 x)}\mathrm dx$$ where $G_n$ are Gregory coefficients. This is into my interest because I received an answer to this question: Integral $\int_0^1 \frac{x\ln\left(\frac{1+x}{1-x}\right)}{\left(\pi^2+\ln^2\left(\frac{1+x}{1-x}\right)\right)^2}dx$ that uses the above formula. I thought of this for some time already, but I have no idea how to start. I also searched the web, but it appears that wikipedia is the only place that it's  mentioned, of course no proof is given. I would appreciate some help! Edit. I have found here on AoPS a way using real methods that solves my problem.","['integration', 'improper-integrals', 'alternative-proof', 'definite-integrals']"
2943436,Possion distribution exercise,"Suppose box A contains countless black balls and box B contains one white ball. We took the black ball out of box A, put it into box B, and experimented with selecting one ball randomly from box B. At this time, the number of black balls taken out of box A and carried to box B follows Poisson distribution. How could I calculate the probability that the ball from B is white. and how could I calculate if the ball from box B was white the probability distribution for the number of black balls moved to box B.","['statistics', 'poisson-distribution']"
2943442,Second derivative test using $f_{yy}$ instead of $f_{xx}$?,"The second derivative test for functions of two variables says to first find critical points. For each critical point one finds $$
D = f_{xx}f_{yy} - f_{xy}^2
$$ If $D>0$ , the sign of $f_{xx}$ says something about whether the point is a local maximum or local minimum. My question is: Why do we use $f_{xx}$ ? Could we use $f_{yy}$ instead?","['maxima-minima', 'calculus', 'derivatives']"
2943491,"Prove that $[0,1]^n / S_n \cong \Delta^n$","Prove that $[0,1]^n / S_n \cong \Delta^n$ , ( $S_n$ denotes the permutation group on n symbols, $\Delta^n:=\{(x_0,\dots,x_n)\in\Bbb R^{n+1} : x_0,\dots,x_n \ge 0 , x_0+\dots+x_n=1\}$ , and the action is defined by permuting coordinates) My attempt : Intuitively  I can visualize the orbit spaces to be homeomorphic to the $\Delta^n$ upto $n\le 2$ . But facing real difficulty in writing an explicit quotient map from $[0,1]^n \to \Delta^n$ so that I can implement the Universal Property Of Quotient Topology. Thanks in Advance for help!","['general-topology', 'topological-groups', 'quotient-spaces']"
2943521,Quadratic reciprocity and gamma function,"Is there a direct connection between gamma function and quadratic reciprocity ?
I am currently writing about quadratic reciprocity and I am interested in including gamma function as suggested by a professor previously however, when I searched about gamma function I could not find something that helps in quadratic reciprocity or any very close connection.
Any idea would be appreciated  ?","['number-theory', 'group-theory']"
2943603,A question of non-singularity,"Let $A$ and $B$ be matrices such that $B^2+ AB + 2I = 0$ , where I
denotes the identity matrix. Which of the following matrices must be
nonsingular? (A) $A + 2I$ (B) $B$ (C) $B + 2I$ (D) $A$ I tried using a few tricks assuming each option to be nonsingular and then coming to the given form but to no avail. Any hint is appreciated.","['matrices', 'determinant', 'linear-algebra']"
2943628,Prove $\frac{a}{\sqrt{a^2+1}}+\frac{b}{\sqrt{b^2+1}}+\frac{c}{\sqrt{c^2+1}} \le \frac{3}{2}$,"If $a.b,c \in  \mathbb{R^+}$ and $ab+bc+ca=1$ Then Prove $$S=\frac{a}{\sqrt{a^2+1}}+\frac{b}{\sqrt{b^2+1}}+\frac{c}{\sqrt{c^2+1}} \le \frac{3}{2}$$ My try we have $$S=\sum \frac{a}{\sqrt{a^2+ab+bc+ca}}=\sum \frac{a}{\sqrt{a+b}\sqrt{a+c})}$$ any hint here?","['inequality', 'radicals', 'a.m.-g.m.-inequality', 'symmetric-polynomials', 'algebra-precalculus']"
2943668,Method of moments exponential distribution,"Find the method of moments estimate for $\lambda$ if a random sample of size $n$ is taken from the exponential pdf, $$f_Y(y_i;\lambda)= \lambda e^{-\lambda y} \;, \quad y \ge 0$$ $$E[Y] = \int_{0}^{\infty}y\lambda e^{-y}dy  \\
= \lambda \int_{0}^{\infty}ye^{-\lambda y} dy \\
= -y\frac{e^{-\lambda y}}{\lambda}\bigg\rvert_{0}^{\infty} - \int_{0}^{\infty}e^{-\lambda y}dy \\
=\bigg[\frac{e^{-\lambda y}}{\lambda}\bigg]\bigg\rvert_{0}^{\infty} \\
E[Y] =  \frac{1}{\lambda} \\
$$ Now solve for $\bar{y}$ $$E[Y] = \frac{1}{n}\sum_\limits{i=1}^{n} y_i \\
\bar{y} = \frac{1}{\lambda} \\
\lambda = \frac{1}{\bar{y}} $$ Implies that $\hat{\lambda}=\frac{1}{\bar{y}}$ Did I get this one? I have not got the answer for this one in the book.","['statistics', 'exponential-distribution']"
2943669,Evaluating $\int_{0}^{\infty} \frac{1}{a_{n}x^{n} + ... + a_{2}x^{2} + a_{o}}dx$ via Residue Theory?,"In the text ""Functions of a Complex Variable"" by Robert E. Greene and Steven G.Krantz I'm having trouble verifying my solution to $\text{Problem (1)}$ $\text{Problem (1)}$ Using Calculus of Residue evaluate the following $$\int_{0}^{\infty} \frac{1}{a_{n}x^{n} + ... + a_{2}x^{2} + a_{o}}dx \, \, \, $$ $\text{Remark}$ $p(x)$ is any polynomial with no zero's on the nonnegative real axis $\text{Solution}$ For $(1)$ real variable methods would be fruitless we have to take the, $$\oint_{\eta_{R}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz.$$ For our choice $f$ , we initially let $$\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \eta_{R}^{1}(t)  =  t + i/\sqrt{2R},  \, \, \, \,   1/\sqrt{2R} \leq t \leq R,$$ $$\eta_{R}^{2}(t)= Re^{it}, \, \, \, \,  \theta_{0} \leq t \leq 2 \pi - \theta_{0},$$ where $\theta_{0} = \theta_{0}(R) = \sin^{-1}(1/(R \sqrt{2R}))$ $$\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \eta_{R}^{3}(t)  =  R -t -i/\sqrt{2R},  \, \, \, \, 0 \leq t \leq R-1/\sqrt{2R}.$$ $$\eta_{R}^{4}(t)  =  e^{it}/\sqrt{R}, \, \, \, \, \,  \, \, \, \, \, \, \, \, \, \, \, \, \, \pi/4 \leq t \leq 7 \pi /4.$$ It's important to consider that, $$\oint_{\eta_{R}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz = 2 \pi i \bigg( \sum_{j} \operatorname{Ind_{\eta_{R}}}(P_{j}) \cdot \operatorname{Res_{\eta_{R}}}(P_{j}) \bigg) $$ Clearly our choice of $f$ has a pole of the order of $P$ and a pole of the order $n$ . Clearly, \begin{align*} 
\operatorname{Res_{f}(P)} &=  \frac{1}{(n-1)!} \bigg( \partial_{z} \bigg)^{n-1} \bigg( (z-n)^{n} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}\bigg) \bigg|_{z=P}\\ 
\, \, \,  &=  \frac{1}{(n)!} \bigg( \partial_{z} \frac{\log(z)}{a_{n}x^{n} + ... + a_{n}z^{2} + a_{o}}\bigg|_{z = P} \bigg) \\
 &= \frac{1}{(n!)}\frac{\log(z) - a_{n}z^{n} + ... + a_{2}P^{2} + a_{o}}{(\log(x)^{2})}\\   &= \frac{1}{(n!)}\frac{\log(P) - a_{n}P^{n} + ... + a_{2}P^{2} + a_{o}}{(\log(P)^{2})}.
\end{align*} Putting the pieces together, $(*)$ $$\oint_{\eta_{R}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz  = 2 \pi i \bigg(  \frac{1}{(n!)}\frac{\log(P) - a_{n}P^{n} + ... + a_{2}P^{2} + a_{o}}{(\log(P)^{2})} \bigg) \cdot 1$$ Applying the  Residue Theorem unfortunately isn't enough to finish our game so it becomes imperative to claim that $(**)$ $$ \Bigg| \lim_{R \rightarrow \infty}\oint_{\eta^{2}_{R}} f(z)dz \Bigg| \rightarrow 0 $$ and that, $(***)$ $$ \Bigg| \lim_{R \rightarrow \infty}\oint_{\eta^{4}_{R}} f(z)dz\Bigg| \rightarrow 0.$$ A particular device used to justify convergence over $\eta_{4}$ and $\eta_{2}$ is the fact that $$\bigg(\log \bigg( \frac{x + i \sqrt{2R}}{(x-i/\sqrt{2R}} \bigg) \bigg)\rightarrow -2 \pi i \text{.}$$ We will return to this particular device after dealing with our analysis of convergence over $\eta_{4}$ and $\eta_{2}$ . First we take that, $$\sum_{\psi}^{4} \bigg(\oint_{\eta_{R}^{\psi}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz \bigg). $$ Now over $\eta_{2}$ one can see that, \begin{align*}
\bigg| \oint_{\eta_{R}^{2}}\frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz\bigg|& = \bigg| \int_{-R}^{+Ri} \frac{\log(Re^{it})}{a_{n}(Re^{it})^{n} + ... + a_{2}(Re^{it})^{2} + a_{o}} iRe^{i \theta} d \theta\bigg|\\&=  \int_{-R}^{+Ri} \bigg|\frac{\log(Re^{it})}{{a_{n}(Re^{it})^{n} + ... + a_{2}(Re^{it})^{2} + a_{o}}} \bigg| \big| iRe^{i \theta} d \theta \big|\\&= \int_{-R}^{+Ri} \frac{\bigg|\log(Re^{it}) \bigg|}{\bigg| {a_{n}(Re^{it})^{n} + ... + a_{2}(Re^{it})^{2} + a_{o}} \bigg|}  \bigg|iRe^{i \theta} \bigg| d \theta  \bigg| \\& = \int_{\theta_{0}}^{2 \pi - \theta_{0}} \frac{\bigg|\log(Re^{it}) \bigg|}{\bigg|{a_{n}(Re^{it})^{n} + ... + a_{2}(Re^{it})^{2} + a_{o}} \bigg|}  \bigg|iRe^{i \theta} \bigg| \bigg|d \theta  \bigg|.
\end{align*} Now we can establish a precise estimate for $\eta_{2}$ $$\bigg| \oint_{\eta_{R}^{2}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz\bigg| \leq  \frac{\ln(R) + \pi }{R^{n} - a_{o}} \pi R \, \, \text{as} \, \, \, R \rightarrow \infty.$$ A similar process for $\eta_{4}$ says that, \begin{align*}
\bigg| \oint_{\eta_{R}^{4}} \frac{\log(e^{it}/\sqrt{R})}{{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}}  dz\bigg|& =  \oint_{\eta_{R}^{4}} \bigg| \frac{\log(e^{it}/\sqrt{R})}{{a_{n}(e^{it}/\sqrt{R})^{n} + ... + a_{2}(e^{it}/ \sqrt{R})^{2} + a_{o}}}  iRe^{i \theta} d \theta\bigg|\\&= \oint_{\eta_{R}^{4}}  \frac{\bigg|\log(e^{it}/\sqrt{R}) \bigg|}{\bigg|a_{n}(e^{it}/\sqrt{R})^{n} + ... + a_{2}(e^{it}/ \sqrt{R})^{2} + a_{o} \bigg|}  iRe^{i \theta} d \theta \\&= \oint_{\eta_{R}^{4}}  \frac{\bigg| \log(e^{it})- \frac{1}{2}\log(R^{}) \bigg|}{ \bigg|a_{n}(e^{it}/\sqrt{R})^{n} + ... + a_{2}(e^{it}/ \sqrt{R})^{2} + a_{o} \bigg|} \bigg|  iRe^{i \theta} d \theta \bigg|\\& =\oint_{\frac{\pi}{4}}^{\frac{7 \pi}{4}}  \frac{\bigg| it\log(e^{})- \frac{1}{2}\log(R^{}) \bigg|}{ \bigg|a_{n}(e^{it}/\sqrt{R})^{n} + ... + a_{2}(e^{it}/ \sqrt{R})^{2} + a_{o}\bigg|} \bigg|  iRe^{i \theta}\bigg| d \theta \bigg|.  \end{align*} Now we can establish a precise estimate for $\eta_{4}$ hence, $$\bigg| \oint_{\eta_{R}^{4}} \frac{\log(e^{it}/\sqrt{R})}{{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}}  dz\bigg|   \leq  \text{length}(\eta_{R}^{4})  \cdot \sup_{\eta_{R}^{4}}(g) \leq \pi R \frac{O(\log(R))}{\sqrt{R}} \, \text{as} \, R \rightarrow \infty.$$ By taking care to provide estimates over $\eta_{2}$ and $\eta_{4}$ we have proved $(***)$ and $(**)$ . Applying Szeto's Lemma it becomes apparent that, $(****)$ $$\oint_{\eta^{1}_{R}}g(z) dz + \oint_{\eta^{3}_{R}}g(z) dz \rightarrow  - 2 \pi i \int_{0}^{\infty} \frac{1}{a_{n}t^{n} + ... + a_{2}t^{2} + a_{o}}dx \, \, \,$$ Now taking $(*)$ , $(**)$ , $(***)$ , $(****)$ taken together yield, $$\int_{0}^{\infty} \frac{1}{a_{n}x^{n} + ... + a_{2}x^{2} + a_{o}}dx = 2 \pi i \bigg(  \frac{1}{(n!)}\frac{\log(P) - a_{n}P^{n} + ... + a_{2}P^{2} + a_{o}}{(\log(P)^{2})} \bigg)$$","['integration', 'improper-integrals', 'proof-verification', 'complex-analysis', 'contour-integration']"
2943670,Toy example of deformed diffeomorphism group,"Consider a toy example of a diffeomorphism group – the group of diffeomorphisms of a 1-dimensional manifold with a disconnected boundary (2 points). The group is a group of monotonically increasing functions defined on the interval $[0..1]$ such that $$ f(0) = 0, \quad f(1) = 1. $$ The group product is given by the composition of functions, and the group inverse is the function inverse. The group identity element is $$ e(\tau) = \tau. $$ Now consider a suitably defined algebra of nonvanishing functionals over the diffeomorphism group. Because it is an algebra of functions over a group, it is a Hopf algebra: Algebraic product and inverse are given by point-wise multipliction and inverse. Comultiplication and the antipode are given by duals of the group product and inverse (function composition and function inverse). I'm interested in nontrivial examples of deformations of the mentioned above Hopf algebra in the category of Hopf algebras, such that commutativity of the algebraic product is restored in the $\hbar \rightarrow 0$ limit. In other words, I'm interested in quantizations of the diffeomorphism group. Do such deformations exist? Have they been studied?","['noncommutative-geometry', 'diffeomorphism', 'quantum-groups', 'group-theory', 'differential-geometry']"
2943677,Show on $\mathbb{N}$ there are $2^{\aleph_0}$ nonisomorphic linear orders.,"How can I attack this problem? 
My idea is for $X \subset \mathbb{N}$ set up a linear order $O_{X}$ such that if $X \not =Y$ then $O_X \not = O_Y$ .","['elementary-set-theory', 'order-theory', 'natural-numbers']"
2943688,Do a pair of orthogonal directions with slopes equal to zero imply $\nabla f = 0$?,"The definition given on wikipedia for a saddle point is is a point on the surface of the graph of a function where the slopes (derivatives) in orthogonal directions are both zero (a critical point), but which is not a local extremum of the function. Looking at their picture ( https://en.wikipedia.org/wiki/Saddle_point#/media/File:Saddle_point.svg ) it's clear that $f_x(0,0) = 0$ and $f_y(0,0)=0$ .... just from taking a look. What isn't as clear is that $D_u f(0,0) = 0$ and that $D_v f(0,0)=0$ whenever $u\perp v$ (for unit $u$ and $v$ ). However if I turn the graph so that $\langle 1,0\rangle \mapsto u$ and $\langle 0,1\rangle \mapsto v$ then I would have $D_u f(0,0) = 0$ and that $D_v f(0,0)=0$ but then I don't see why $f_x(0,0)=0$ and $f_y(0,0)=0$ in that coordinate system. Put another way.....  Is it true that $\nabla f(x_0,y_0)=0$ if and only if $D_u f(x_0,y_0)= D_v f(x_0,y_0)=0$ for some (and hence any) pair of unit vectors $u,v$ such that $u\perp v$ ? If this is true then in the boxed sentence above I could write instead ""a point where $\nabla f=0$ but which ...""","['multivariable-calculus', 'analysis']"
2943713,Counting Strings,"There are 7 5 = 16,807 strings of length 5
formed from the 7 letters a , b , c , d , e , f , & g .   For example, one such string is ebdbg . In how many of these 16,807 strings
are the letters b & d adjacent (appearing in either order bd or db ) ? In other words, how many of these 16,807 strings contain either bd as a substring or contain db as a substring?",['combinatorics']
2943752,Prove that $\int_0^1\frac{\operatorname{Li}_3(1-z)}{\sqrt{z(1-z)}}\mathrm dz=-\frac{\pi^3}{3}\log 2+\frac{4\pi}3\log^3 2+2\pi\zeta(3)$,"While going through the recent questions concerning tagged polylogarithms I stumbled upon this post which asks for a concrete evaluating of a polylogarithmic integral. However the post also states the equality $$\int_0^1\frac{\operatorname{Li}_3(1-z)}{\sqrt{z(1-z)}}\,\mathrm dz=-\frac{\pi^3}{3}\log 2+\frac{4\pi}3\log^3 2+2\pi\zeta(3)\tag1$$ Together with the comment ""It is not difficult to show that"". Since I know the author of this post $-$ Jack D'Aurizio $-$ is familiar with integrals of this type I guess, indeed, for himself it is easily done. However, I have problems proving $(1)$ As we are dealing with an integral involving a Polylogarithm I thought about applying IBP to get rid of the the Polylogarithm. But I am not sure about the right choice of $u$ and $\mathrm dv$ , respectively. My first guess was simply $u=\operatorname{Li}_3(1-z)$ and therefore $\displaystyle\mathrm dv=\frac1{\sqrt{z(1-z)}}$ . From hereon the first problem occurs: integrating $\mathrm dv$ . There are at least the two possibilities $v=\sin^{-1}(2z-1)$ and $v=2\sin^{-1}(\sqrt{z})$ which both lead to the same $\mathrm dv$ but on the other hand imply different results for the first IBP step. To be precise $$\begin{align}
\tag{1}\int_0^1\frac{\operatorname{Li}_3(1-z)}{\sqrt{z(1-z)}}\,\mathrm dz&=\left[\operatorname{Li}_3(1-z)\sin^{-1}(2z-1)\right]_0^1-\int_0^1\sin^{-1}(2z-1)\frac{\operatorname{Li}_2(z)}{z}\,\mathrm dz\\
&=\color{red}{\frac38\pi\zeta(3)}-\int_0^1\sin^{-1}(2z-1)\frac{\operatorname{Li}_2(z)}{z}\,\mathrm dz\\
\tag{2}\int_0^1\frac{\operatorname{Li}_3(1-z)}{\sqrt{z(1-z)}}\,\mathrm dz&=\left[\operatorname{Li}_3(1-z)2\sin^{-1}(\sqrt{z})\right]_0^1-\int_0^12\sin^{-1}(\sqrt{z})\frac{\operatorname{Li}_2(z)}z\,\mathrm dz\\
&=\color{red}{0}-\int_0^12\sin^{-1}(\sqrt{z})\frac{\operatorname{Li}_2(z)}{z}\,\mathrm dz
\end{align}$$ I am in favor of the first option since it contains the value $\pi\zeta(3)$ but with the wrong coefficient. However, I am not capable of evaluating the remaining integrals which involves a combination of the inverse sine function and the Dilogarithm. Again I thought about IBP but I am totally confused what to choose as $u$ and $\mathrm dv$ . Therefore I think I am on the wrong tack. I have dealed with polylogarithmic and logarithmic integrals before but the square roots are causing me trouble. I tried to absorb at least the $\sqrt{1-z}$ within the Trilogarithm and then doing IBP which results in $$\begin{align}
\int_0^1\frac{\operatorname{Li}_3(1-z)}{\sqrt{z(1-z)}}\mathrm dz&=\int_0^1\sum_{n=1}^{\infty}\frac{(1-z)^{n-1/2}}{n^3}\frac{dz}{\sqrt{z}}\\
&=\left[\sum_{n=1}^{\infty}\frac{(1-z)^{n-1/2}}{n^3}2\sqrt{z}\right]_0^1-\int_0^1\frac{\operatorname{Li}_3(1-z)-2\operatorname{Li}_2(1-z)}{(1-z)^{3/2}}\sqrt{z}\mathrm dz\\
&=\color{red}{0}-\int_0^1\frac{\operatorname{Li}_3(1-z)-2\operatorname{Li}_2(1-z)}{(1-z)^{3/2}}\sqrt{z}\mathrm dz
\end{align}$$ I am not sure whether this is helpful at all or if it does not make the whole problem more complicated. Honestly speaking, I am lost right now and do not know how to proceed of how to approach to the given equality at all. Could someone explain me how to proceed with the given integrals including integrands combined out of inverse sine and polylogarithmic functions? Are these integrals even solvable; when yes how (maybe without using the given the given integral)? Or was my whole approach nonsense and another attempt is needed here? You can also share a link or refer to another post here on MSE in case I have overlooked something. Thanks in advance!","['integration', 'polylogarithm', 'definite-integrals', 'closed-form']"
2943781,Proof of a linear algebra lemma for Cohn-Vossen's theorem,"For the proof of Cohn-Vossen's rigidity theorem I need to prove the next lemma (can be found in Montiel-Ros's Curves and Surfaces page 218): If $\Phi$ and $\Psi$ are two definite self-adjoint endomorphisms of a Euclidean vector
  plane and $det \Phi = det \Psi$ . Then, $det (\Phi + \Psi) \leq 0$ and that equality occurs if and only if $\Phi = - \Psi$ . The proof says the following: If $det(\Phi +\Psi) > 0$ , the endomorphism $\Phi+\Psi$ would be definite, say, positive definite. Now, we take $\{ e_1, e_2 \}$ a basis of the plane diagonalizing $\Phi$ , one has $$ \langle \Phi(e_i), e_i \rangle + \langle \Psi(e_i), e_i \rangle > 0, \;\;\;\; i = 1,2.$$ Consequently, $$ det \Phi = \langle \Phi(e_1), e_1 \rangle \langle \Phi(e_2), e_2 \rangle \stackrel{(1)}{>} \langle \Psi(e_1), e_1 \rangle \langle \Psi(e_2), e_2 \rangle \geq \langle \Psi(e_1), e_1 \rangle \langle \Psi(e_2), e_2 \rangle - \langle \Psi(e_1), e_2 \rangle^2 \stackrel{(2)}{=} det \Psi $$ which gives a contradiction to our hypothesis. Therefore, $det( \Phi + \Psi ) \leq 0$ . Here, I don't understand inequality (1) and equality (2). Moreover, the lemma says the following: In the above inequality, equality occurs if and only if $\Phi = -
 \Psi$ . The proof says the following: Following the reasoning above, if equality holds, there wouldbe at least a non-null vector in the kernel of $\Phi + \Psi$ . Let $\{u_1, u_2 \}$ be a basis diagonalizing $\Phi + \Psi$ , that is, such that $$ \Phi(u_1) + \Psi(u_1) = 0 \;\;\;\; and \;\;\;\; \Phi(u_2) + \Psi(u_2) = \lambda u_2, \;\;\; \lambda \in \mathbb{R}. $$ From the first equality we deduce that $$ \langle \Phi(u_1), u_1 \rangle = - \langle \Psi(u_1), u_1 \rangle \;\;\;\; and \;\;\;\; \langle \Phi(u_1), u_2 \rangle = - \langle \Psi(u_1), u_2 \rangle, $$ which together with the facts that $det \Phi = det \Psi$ and that $\Phi$ and $\Psi$ are definite, gives the equality $$ \langle \Phi(u_2), u_2 \rangle \stackrel{(3)}{=} - \langle \Psi(u_2), u_2 \rangle, $$ implying $\lambda = 0$ . Thus, in this case, $\Phi = - \Psi$ . Of this latest part I don't understand the equality (3). Could you show me why these equations hold?","['determinant', 'proof-explanation', 'self-adjoint-operators', 'linear-algebra', 'differential-geometry']"
2943824,If T follows a t-distribution them prove that U=T^2 follows an F-distribution,Is this correct is there a more elegant way to do this,['statistics']
2943834,Approximation of measurable function via simple functions [Proof],"Let's denote by $\mathfrak{M}$ the set of all measurable subsets of $\mathbb{R}^d$ . I mean the Lebesgue measure. Definition: Let $\{E_k\}_{k=1}^{N}\in\mathfrak{M}$ with $m(E_k)<\infty$ then the function of the form $\varphi(x)=\sum \limits_{k=1}^{N}a_k\chi_{E_K}(x)$ is called simple function. Theorem: Let $f:X\to [0,+\infty]$ is measurable function, then there exist the sequence of real-valued simple functions $\{s_n(x)\}_{n=1}^{\infty}$ on $X$ such that $0\leq s_1\leq s_2\leq \dots\leq f$ and $s_n\to f$ pointwise. This is the theorem from Stein Shakarchi's book but I have found the following proof (not from the book). Honestly to say two moments of the proof are quite not precise. 1) Note that we can write the function $\phi_n(x)$ in the following form $$\phi_n(x)=\sum \limits_{k=0}^{n2^n-1}\frac{k}{2^n}\chi_{\left[\frac{k}{2^n},\frac{k+1}{2^n}\right)}(x)+n\chi_{[n,+\infty)}(x)$$ But this function is not simple simple since the interval $[n,+\infty)$ has infinite measure. 2) When we compose any function on the left with simple function, namely $\phi_n\circ f(x)$ we get the following function $$\phi_n\circ f(x)=\sum \limits_{k=0}^{n2^n-1}\frac{k}{2^n}\chi_{f^{-1}\left[\frac{k}{2^n},\frac{k+1}{2^n}\right)}(x)+n\chi_{f^{-1}[n,+\infty)}(x),$$ since $f$ is measurable then we know that each set $f^{-1}\left[\frac{k}{2^n},\frac{k+1}{2^n}\right)$ and $f^{-1}[n,+\infty)$ is measurable but why their measure is finite?","['measure-theory', 'real-analysis']"
2943843,"Prove that for every $n\in \mathbb{N*}$ , there is a number $p\in \mathbb{N}$ such that $n\le 1+\frac{1}{2}+\frac{1}{3}+\ldots+\frac{1}{p}<n+1$","I think it is equivalent to prove that $f(p)=E(1+\frac{1}2+\frac{1}{3} \ldots+\frac{1}{p})$ is surjective, but I have no idea how to prove it. But here is what I did: $$f(2n)-f(n)=\frac{1}{n+1}+\ldots+\frac{1}{2n},$$ so $f(2^n)-1\ge \frac{1}{2}n.$ Hence, $f(2^{2n})\ge1+n>n$ .",['sequences-and-series']
2943863,Closed form sum for the following series on the euclidean grid.,"I am trying to find a closed form solution for the following series. The $\sqrt{i^2 + j^2}$ in the exponent comes from distances on the euclidean grid from the origin. $x = \sum_{i,j} e^{-\sqrt{i^2 + j^2}}$ where $i,j$ range from $0$ to infinity. It appears this expression is not a geometric series, so I have trouble analyzing it. I did some quick simulations to realize that the value converges quickly. For $i,j$ in range (0,40), and using double-precision floating point, the value converges to $2.95878712840391$ . Altering the range of $i,j$ no longer changes the sum because the incremental values are beyond the precision of the floating point decimal. I would greatly appreciate some help in approaching this series, and if there is a way to represent it in a closed form. Or if there is a way to approximate the answer to a desired precision.","['power-series', 'sequences-and-series']"
2943892,Why can't completeness be defined on topological spaces without using metrics?,"I have heard it said that completeness is a not a property of topological spaces, only a property of metric spaces (or topological groups), because Cauchy sequences require a metric to define them, and different metrics yield different sets of Cauchy sequence, even if the metrics induce the same topology.  But why wouldn't the following definition of Cauchy sequence work? (*) A sequence $(x_n)$ in a topological space $(X,\tau)$ is Cauchy if there exists a nested sequence of open sets $(U_n)$ where each open set is a proper subset of the one before it and the intersection of all of them contains at most one element, such that for any natural number $m$ , there exists a natural number $N$ such that for all $n\geq N$ , we have $x_n\in U_m$ . My question is, why isn't this definition equivalent to being Cauchy in all metrics on $X$ whose topology is $\tau$ ?  Are there any metrics where being Cauchy is equivalent to (*)?","['cauchy-sequences', 'general-topology', 'complete-spaces', 'metric-spaces']"
2943961,Antiderivative of $x\sqrt{1+x^2}$,"I am attempting this problem given to me, but the answer key does not explain the answer.  The question asks me to find the antiderivative of $x\sqrt{1+x^2}$ . My attempt: $\frac{d}{dx}f(g(x)) = g'(x)f'(g(x))$ $g'(x)$ must be $x$ , therefore $g(x)=\frac{1}{2}x^2$ $f'(x)$ must equal $\sqrt{1+x^2}$ , therefore $f(x)=\frac{2}{3}(1+x^2)^{\frac{3}{2}}$ But then I saw that if $g(x)=\frac{1}{3}x^2$ , then $g'(x)=\frac{2}{3}x$ ,  and $f(x)=(1+x^2)^{\frac{3}{2}}$ , then $\frac{d}{dx}f(g(x))'=g'(x)f'(g(x))=(2/3)x(3/2)\sqrt{1+x^2}=x\sqrt{1+x^2}$ . But I saw this by chance; what would be a more general and effective way to do this?  Should I check $this$ , and then write $that$ , and put together $those$ , etc.? Or is the way I just 'saw' the way the numbers should fall together how one would normally approach this?","['integration', 'derivatives', 'chain-rule']"
2943967,Faithful action of stabiliser on group of automorphisms of a hypersurface,"Let $f\in\mathbb{C}[x_{1},\ldots,x_{n}]$ , and $G_{f}\le\mathrm{GL}_{n}(\mathbb{C})$ be the group of all matrices under which $f$ is invariant, i.e. the stabiliser of $f$ in $\mathrm{GL}_{n}(\mathbb{C})$ consisting of all $\pi\in\mathrm{GL}_{n}(\mathbb{C})$ such that $f(\pi(x_{1},\ldots,x_{n}))=f$ . Then each matrix in $G_{f}$ induces an automorphism on the hypersurface $$V=\mathcal{V}(f)=\{p\in\mathbb{C}^{n}:f(p)=0\}.$$ Thus we get a group homomorphism $\phi:G_{f}\to\mathrm{Aut}(V)$ , that assigns each matrix an automorphism of $V$ . My question is; under what conditions is the action of $G_{f}$ on $V$ faithful? That is, when is the mapping, $\phi$ injective? There is a small discussion of this here , and it is mentioned that this question deserved its own thread.","['matrices', 'algebraic-geometry', 'polynomials']"
2943970,"Does a ""full enough"" convex set have an internal point?","Let $C \subseteq V$ be a convex subset of a vector space (not necessarily finite dimensional). Suppose that for every $v \in V$ , there are some $a ∈ \mathbb{R}^+$ and $x, y ∈ C$ such that $v = a(x - y)$ . Intuitively, $C$ has some positive ""thickness"" in every direction, somewhere. Does it follow that $C$ has an internal point? Here's a bit more detail. For a vector $v ∈ V$ , call a point $x ∈ C$ $v$ -internal iff for some $α > 0$ , for every $0 < β ≤ α$ , $x + βv$ is in $C$ . Given that $C$ is convex, this is equivalent to just saying that $x + αv ∈ C$ for some $α > 0$ . A point $x ∈ C$ is internal iff it is $v$ -internal for every $v ∈ V$ . My question amounts to this: given that, for every $v ∈ V$ , there is some $v$ -internal point $x ∈ C$ , does it follow that there is a point $x ∈ C$ which is $v$ -internal for every $v ∈ V$ ? In the finite dimensional case this checks out. Given a basis $e₁, …, e_n$ , and some points $x₁, …, x_n, y₁, …, y_n ∈ C$ which are $e₁$ -internal, …, $e_n$ -internal, $-e₁$ -internal, …, and $-e_n$ -internal, respectively, the mean of all of these points must be an internal point. But I don't know how things would go in an infinite dimensional vector space.","['convex-analysis', 'linear-algebra', 'analysis', 'real-analysis']"
2943977,Some questions about radical of modules,"As we all know, every ring with unit has left maximal ideals; then we can define the radical of a ring as the intersection of all left maximal ideal. But for modules, not every module has maximal submodules, for instance the $\mathbb{Z}$ -module $\mathbb{Q}$ doesn't have maximal submodules. But in almost every book, the definition of radical of a module is as the intersection of all maximal submodules. This has confused me for a long time. Does this really make sense for all modules? How to explain this? For the $\mathbb{Z}$ -module $\mathbb{Q}$ , what is $\operatorname{Rad}\mathbb{Q}$ ? There are many questions about radical of modules in Mathmatics like Question about radical of a module. . In the proof of this question, it is also used the existence of maximal submodules. If we use the equivalent result in this question, we have $\operatorname{Rad}\mathbb{Q}=\mathbb{Q}$ . Every nonzero projective module has maximal submodules. How to prove this?","['homological-algebra', 'ring-theory', 'abstract-algebra', 'representation-theory']"
2943983,Average height of a semicircle. Why are these different answers?,"In my mind, there are two approaches to finding the average height of a semicircle. Integrating Cartesianally: $$y_{av}=\frac{1}{2r}\int_{-r}^r\sqrt{r^2-x^2}dx=\frac{\pi r}{4}$$ Or integrating polar: $$y_{av}=\frac{1}{\pi}\int_{0}^\pi r\sin(\theta)d\theta=\frac{2r}{\pi}$$ Both of these seem intuative as you are integrating the height of all possible inputs, then dividing by the range of inputs to give you the average height of all inputs. Yet, we get different results from each. Which is the correct average height, and why are they different? Or are they correct in their own manner, and why?","['integration', 'average', 'circles', 'geometry']"
2943993,equations of unbounded operator,"$T$ is densely defined closed operator on $\mathcal{H}$ which is a Hilbert space. Prove that $\forall a,b\in H$ ,the equations \begin{equation} \label{eq:1}
\left\{ \begin{aligned}
         -Tx+y &= a \\
                  x+T^{\star}y&=b
                          \end{aligned} \right.
                          \end{equation} have unique solution $x\in D(T),y\in D(T^\star)$ . $T^\star$ is the adjoint operator of $T$ . $D(T)$ is the space where $T$ is defined. I have proved the uniqueness. And if $a\in D(T^\star),b\in D(T)$ , I can just solve it just by taking $T$ on the second equation and plus the first one. But for $\forall a,b\in H$ , I have some troubles.
 Any idea will help, thank you.","['functional-analysis', 'unbounded-operators']"
2943999,Prove $\frac{a^2}{3^3}+\frac{b^2}{4^3}+\frac{c^2}{5^3} \ge \frac{(a+b+c)^2}{6^3}$,"If $a,b,c \in \mathbb{R+, }$ Then Prove that $$\frac{a^2}{3^3}+\frac{b^2}{4^3}+\frac{c^2}{5^3} \ge \frac{(a+b+c)^2}{6^3}$$ My try: Consider $$P=\frac{a}{3\sqrt{3}}+\frac{b}{4\sqrt{4}}+\frac{c}{5\sqrt{5}}$$ BY Cauchy Scwartz Inequality we have $$P \le \sqrt{3} \times \sqrt {\left(\frac{a^2}{3^3}+\frac{b^2}{4^3}+\frac{c^2}{5^3} \right)}$$ any way proceed here?","['algebra-precalculus', 'cauchy-schwarz-inequality', 'inequality']"
2944012,What sequences are Cauchy in all metrics for a given topology?,"Different metrics for the same topology can have different sets of Cauchy sequences.  But I'm interested in what sequences are Cauchy in every metric for a given topology.  For a completely metrizable topology, the answer is obvious: the convergent sequences.  (Where convergence is a property of the topology independent of the metric.) But my question is, if a topology is metrizable but not completely metrizable (like $\mathbb{Q}$ with the standard topology), is it possible for non-convergent sequences to be Cauchy in every metric for a given topology?","['cauchy-sequences', 'general-topology', 'complete-spaces', 'metric-spaces']"
2944040,Calculate the derivative of a scalar function w.r.t its vector argument?,"If $J$ is a scalar function of two vectors $\boldsymbol{q}$ and $\boldsymbol{g}$ : $$J(\boldsymbol{q},\boldsymbol{g})=\frac{\boldsymbol{g\cdot g}}{\boldsymbol{q\cdot q}}.$$ How do I calculate the derivative $\frac{\partial J}{\partial \boldsymbol{q}}$ ? What I have tried: $$\frac{\partial J}{\partial \boldsymbol{q}}=\frac{\partial}{\partial \boldsymbol{q}}\left(\frac{\boldsymbol{g\cdot g}}{\| \boldsymbol{q} \|^2} \right)=-2\|\boldsymbol{q}\|^{-3} \boldsymbol{g\cdot g}=-2 \|\boldsymbol{q}\|\:( \boldsymbol{g\cdot g}) \|\boldsymbol{q}\|^{-4}=-2\|\boldsymbol{q}\|\: (\boldsymbol{g\cdot g}) (\|\boldsymbol{q}\|^{2})^{-2}\\=-2\|\boldsymbol{q}\|\:( \boldsymbol{g\cdot g}) (\boldsymbol{q\cdot q})^{-2}.$$ I am sure that my answer is wrong because it should have been a vector instead of a scalar. For your reference, the answer given is $$\frac{\partial J}{\partial \boldsymbol{q}}=-2\boldsymbol{q}( \boldsymbol{g\cdot g})/(\boldsymbol{q\cdot q})^2.$$ Thank you in advance.","['matrices', 'derivatives', 'vectors']"
2944090,Converse of Bolzano-Weierstrass theorem,"Bolzano-Weierstrass theorem states that every bounded sequence has a limit point. But, the converse is not true. That is, there are some unbounded sequences which have a limit point. In my course book, I found an example for this claim, but it doesn't make sense. Here's the example give in the book:
The set: {1, 2, 1, 4, 1, 6, ...} is unbounded, but has a limit point of 1 . 
I can't understand how this set has a limit point as 1 .  According to the book definition of limit point, 'x' is the limit point of a sequence, if every neighborhood of 'x' has infinitely many elements of the sequence. If I apply it here, then I get only infinity as the limit point. Am I missing something?","['limits', 'sequences-and-series', 'real-analysis']"
2944104,Obtaining two-holed torus as a quotient of $\Bbb C$,"The torus $T^2$ arises as a quotient space $\Bbb{C}/\Gamma$ for some lattice $\Gamma=\Bbb{Z}\gamma_1+\Bbb{Z}\gamma_2$ for $\gamma_1,\gamma_2\in\Bbb C$ . One could think of this as gluing a $4g$ -gon where $g=1$ . Can we find the two holed torus $T^2\# T^2$ as a quotient space $\Bbb{C}/Y$ ? I can see that we can obtain it from gluing an $8$ -gon, but am not sure that we can get it as a quotient space, given there isn't a 'fundamental region' in $\Bbb{C}$ that tessellates. Do I need to quotient $\Bbb{C}^n$ for some $n$ instead?","['general-topology', 'algebraic-topology', 'quotient-spaces']"
2944175,Intuitive meaning of the members of the spectrum of a linear operator which are not eigenvalues,"Let $A$ be a (maybe unbounded) linear operator on a Hilbert space $\mathcal{H}$ . If $A-\lambda$ is not injective, $\lambda$ is an eigenvalue. It simply means that $A$ does not change the ""direction"" of some vectors and so the vectors form an invariant subspace. The rest of the spectrum of $A$ consists of $\lambda$ such that $A - \lambda$ is injective but not surjective or it is bijective but the inverse is not bounded. Spectral theorems require not only eigenvalues but such $\lambda$ s. Is there some intuitive or educational meaning for the existence of such $\lambda$ ?","['spectral-theory', 'functional-analysis']"
2944185,Questions about uncountable orthonormal bases in Hilbert spaces,"I am currently reading the chapter on Hilbert spaces in the book Functional Analysis by Peter D. Lax and I am confused about whether the orthonormal sets being alluded to are uncountable or not. Specifically he states the following theorem Theorem 9. Every Hilbert space contains an orthonormal basis. The proof of this theorem never refers to whether the set obtained via an application of Zorn's lemma is countable or not. He then goes on to state that: Suppose that $H$ is a separable Hilbert space; that is, it contains a denumerable set of points that is dense. In this case every orthogonal basis is denumerable, and the basis elements can be constructed without appealing to transcendental arguments such as Zorn's lemma... so i assume that the theorem is valid for any Hilbert space. But then if $\{x_j\}$ is some orthonormal set in a Hilbert space then is it true, as is claimed in the book, that $\overline{\mathrm{span }\{x_j\}} = S$ where $S$ is the set of points \begin{align*}
x = \sum (x,x_j)x_j,\quad \sum |(x,x_j)|^2<\infty.
\end{align*} Are we to consider this as a transfinite sum? Could we go about proving this in the following way: Suppose that $\{x_j\}$ is uncountable and let $y\in \overline{\mathrm{span}\{x_j\}}$ then we could find a sequence $\{y_n\}$ together with an increasing sequence of finite index sets $\{F_n\}$ and scalars $\{c_{n,j}\}$ such that $$y_n = \sum_{j\in F_n}c_{n,j}x_j$$ and $\|y_n-y\|\rightarrow 0$ . By Pythagoras $$\|y-y_n\|\geq \|y-\sum_{j\in F_n}(y,x_j)x_j\|$$ and therefore $\sum_{j\in F_n}(y,x_j)x_j\rightarrow y$ as $n\rightarrow \infty$ . By Bessel's inequality we have for finite index sets $F$ $$\sum_{j\in F}|(y,x_j)|^2\leq \|y\|^2$$ and therefore $$\sum |(y,x_j)|^2 = \sup_{F\text{ is finite}}\sum_{j\in F}|(y,(x_j))|^2\leq \|y\|^2$$ which implies that $y\in S$ . But how is the sum $\sum(y,x_j)x_j$ defined? It is transfinite but not positive? As Asaf Karagila stated in the comments the fact that $\sum |(y,x_j)|^2<\infty$ implies that at most countably many $(y,x_j)$ are nonzero. Say that $G$ is a countable set which contains all indices $j$ such that $(y,x_j)\neq 0$ and let $G_n$ be some sequence of finite indices such that $\cup G_n = G$ . We want to show that $$\lim_n \sum_{G_n}(y,x_j)x_j = y.$$ Note that we can choose $G_n$ such that $F_n\setminus G_n$ only contains indices $j$ with the property that $(y,x_j) = 0$ then $$\|y-y_n\|\geq \|y-\sum_{G_n}(y,x_j)x_j\|$$ which proves the result.","['hilbert-spaces', 'functional-analysis']"
2944206,Finding the geodesic equations on $S^2$,"The metric on $S^2$ is given as $\bar{g} = ds^2 = d\theta^2 + \sin^2\theta d\phi^2$ where $x^1 = \theta$ and $x^2 = \phi$ . The only non-zero components of the Christoffel symbols are $\Gamma^{\ 1}_{ \ 2 \ 2}$ and $$\Gamma^{\ 2}_{ \ 2 \ 1} =  \Gamma^{\ 2}_{ \ 1 \ 2} =  \cot\theta$$ Write down the geodesic equations for the co-ordinates $\theta(t)$ and $\phi(t$ ) I know that in local co-ordinates on any smooth manifold $M$ the geodesic equation is given by $$\frac{d^2x^a}{dt^2} +  \Gamma^{\ a}_{ \ b \ c}\frac{dx^b}{dt}\frac{dx^c}{dt} = 0$$ on $S^2$ then substituting for $x^1$ and $x^2$ in local co-ordinates we get $$\frac{d^2\theta}{dt^2} -\sin\theta\cos\theta \left(\frac{d\phi}{dt}\right) + \frac{d^2\phi}{dt^2} + 2\cot\theta \frac{d\theta}{dt}\frac{d\phi}{dt} = 0$$ rearranging for $\frac{d^2\theta}{dt}$ we get $$\frac{d^2\theta}{dt^2} =\sin\theta\cos\theta \left(\frac{d\phi}{dt}\right) - \frac{d^2\phi}{dt^2} - 2\cot\theta \frac{d\theta}{dt}\frac{d\phi}{dt} $$ and similarly we can rearrange and solve for $\frac{d^2\phi}{dt}$ . My question is, what exactly do the authors mean by ""write down the geodesic equations for the co-ordinates $\theta(t)$ and $\phi(t)$ , do I need to solve the above differential equation and then obtain $\theta(t)$ ? If so how can I go about doing that, what's the best approach?","['riemannian-geometry', 'ordinary-differential-equations', 'differential-geometry']"
2944232,What is $15^{15} + 16^{16} + 17^{17} + 18^{18} + 19^{19} + 20^{20} \pmod{7}$?,"I am trying to evaluate $15^{15} + 16^{16} + 17^{17} + 18^{18} + 19^{19} + 20^{20} \pmod{7}$ . I have found that $15^{15} \equiv 1 \pmod{7}$ and that $16^{16} \equiv 2 \pmod{7}$ . To evaluate $15^{15} \pmod{17}$ , I did the following: $$15 = 2 \times 7 + 1 \equiv 1 \pmod{7}$$ $$15^{15} \equiv 1 \pmod{7}$$ Then, to evaluate $16^{16}$ , I wrote: $$16 = 15 + 1 \equiv 1 + 1 = 2 \pmod{7}$$ $$16^{16} \equiv 2^{16} \pmod{7}$$ $$2^{3} = 8 = 7+1 \equiv 1 \pmod{7}$$ $$2^{16} = 2^{3} \times 2^{13} \equiv 2^{13} = 2^{3} \times 2^{10} \equiv 2^{10} \equiv \dots \equiv 2 \pmod{7}$$ Nevertheless, I have not managed to figure out how to evaluate $17^{17}$ . How should I go about this and is my overall approach for evaluating the sum in question a good one?","['modular-arithmetic', 'discrete-mathematics']"
2944252,"Finding the probability that someone has the disease, given they test positive on two tests","This question is from the textbook ""Introduction to Probability - Blitzstein & Hwang."" I was studying for a class when I came across an example problem that I solved, but got a slightly different result than the textbook. Here's the problem in question, paraphrased: ""Fred tests for a disease which afflicts 1% of the population. The test's accuracy is deemed 95%. He tests positive for the first test, but decides to get tested for a second time. Unfortunately, Fred also tests positive for the second test as well. Find the probability that Fred has the disease, given the evidence."" $\ $ My approach is as follows: Let $D$ be the event that Fred has the disease, $T_1$ be the event that the first test result is positive, and $T_2$ be the event that the second test is also positive. We want to find $P(D\ |\ T_1,\ T_2)$ . We are also able to condition on $T_1$ (i.e. the event that the first test result is positive). This would give us: $$P(D\ |\ T_1,\ T_2) = \frac{P(T_2\ |\ D,\ T_1)P(D\ |\ T_1)}{P(T_2\ |\ T_1)}$$ From my calculations: $$P(T_2\ |\ D,\ T_1)\ =\ P(T_2\ |\ D)\ =\ 0.95$$ $$P(D\ |\ T_1)\ \approx\ 0.16$$ $$P(T_2\ |\ T_1)\ =\ \frac{P(T_1 ,\ T_2)}{P(T_1)}\ =\ \frac{P(T_1,\ T_2,\ D)\ +\ P(T_1,\ T_2,\ D^c)}{P(T_1,\ D)\ +\ P(T_1,\ D^c)}\ =\ \frac{0.0115}{0.059}\ \approx\ 0.19$$ $\ $ $$P(D\ |\ T_1,\ T_2)\ =\ \frac{0.95\ \times\ 0.16}{0.19}\ =\ 0.8$$ Therefore, I concluded that there is an 80% chance that Fred has the disease, given that both the first and second test results are positive. $\ $ The problem is that the textbook has taken a different approach of using the odds form of Bayes' rule , which resulted in a conclusion slightly different from mine (0.78), and I'm having trouble understanding how that conclusion came to be. $\ $ Textbook approach is as follows: $$\frac{P(D\ |\ T_1,\ T_2)}{P(D^c\ |\ T_1,\ T_2)}\ =\ \frac{P(D)}{P(D^c)}\ \times\ \frac{P(T_1,\ T_2\ |\ D)}{P(T_1,\ T_2\ |\ D^c)}$$ $$=\ \frac{1}{99}\ \times\ \frac{0.95^2}{0.05^2}\ =\ \frac{361}{99}\ \approx\ 3.646$$ which ""corresponds to a probability of 0.78."" $\ $ Here are the specific questions I have: Is my approach wrong? A 0.02 difference is a pretty big difference. How did the author derive the equation: $$P(D\ |\ T_1,\ T_2)\ =\ P(D)P(T_1,\ T_2\ |\ D)$$ What does the author mean when he/she says ""3.646 corresponds to a probability of 0.78?"" $\ $ Any feedback is appreciated. Thank you!","['conditional-probability', 'bayes-theorem', 'probability']"
2944265,"On the integral $\int_0^\pi\sin(x+\sin(x+\sin(x+\cdots)))\,dx$","This question came into my head when I did a course on Fourier series. However, this is not an infinite sum of sines, but an infinite recurrence of sines in a sum. Consider $f_1(x)=\sin(x)$ and $f_2(x)=\sin(x+f_1(x))$ such that $f_n$ satisfies the relation $$f_n(x)=\sin(x+f_{n-1}(x)).$$ To what value does $$L:=\lim_{n\to\infty}\int_0^\pi f_n(x)\,dx$$ converge? Since it is impossible to evaluate the integrals directly, we begin by considering the first few values of $n$ . A pattern clearly emerges. $$I_1=\int_0^\pi f_1(x)\,dx=2\quad\quad\quad I_2=1.376527...\\I_3=2.188188...\quad\quad\quad\quad\quad I_4=1.625516...\\ I_5=2.179090...\quad\quad\quad\quad\quad I_6=1.732942...\\ I_7=2.155900...\quad\quad\quad\quad\quad I_8=1.927035...$$ For odd values of $n$ , $I_n$ decreases monotonically (except $n=1$ ) and for even values of $n$ , $I_n$ increases monotonically.  These two observations have led me to claim that $L=I_1=2$ . Is it possible to prove/disprove this claim?","['integration', 'limits', 'convergence-divergence']"
2944283,Is it legal to multiply left side of equation by $\mathrm{d}y$ and right side by $\mathrm{d}x$?,"I have a question about calculus rules which I find difficult to find an answer to.
Say I have an equation of $x$ and $y$ , e.g.: $y=x^2$ . Am I then allowed to multiply the left side by a small change in y and the right side by a small change in $x$ : $y\mathrm{d}y=x^2\mathrm{d}x$ ? If the equation is true, then it should be true for an infinitesimal change in $x$ and $y$ , but I am not sure about the Leibnitz notation and how we are allowed to use it in equations.","['notation', 'calculus', 'derivatives']"
2944327,Prove that $(I+A^{-1})^{-1}=A(A+I)^{-1}.$,Prove that $(I+A^{-1})^{-1}=A(A+I)^{-1}$ assuming that the inverse matrices exist. My idea is to show that $(I+A^{-1})$ is the inverse matrix of $A(A+I)^{-1}$ by proving $(I+A^{-1})A(A+I)^{-1}=I$ and $A(A+I)^{-1}(I+A^{-1})=I$ . I have started with $(I+A^{-1})A(A+I)^{-1}=(IA+A^{-1}A)(A+I)^{-1}=(A+I)(A+I)^{-1}=I$ but when I go on to prove this the other way around $A(A+I)^{-1}(I+A^{-1})=I$ I am not sure how to open up the expression.,"['matrices', 'linear-algebra']"
2944374,Combinatorics meaning of $L_m=\sum_{j=m}^{n}(-1)^{j-m}\binom{j-1}{m-1}S_j$,"Let $U$ a universe and there are $n$ properties defined on it: $a_1,a_2,\dots,a_n$ . Define the sum of the size of all $m$ -intersection(s) of $A_i=\{x\in U|x\textrm{ has property }a_i\}$ to be: $S_m=\sum_{|I|=m}\left|\bigcap_{i\in I}A_i\right|$ . Now let $L_m$ counts the number of elements have at least $m$ properties, then $$L_m=S_m-{m\choose m-1}S_{m+1}+{m+1\choose m-1}S_{m+2}-\dots+(-1)^{n-m}{n-1\choose m-1}S_n.$$ Is there any combinatorial way to explain the meaning of these coefficients? The strange thing is that: Let $E_m$ counts the number of elements have exactly $m$ properties, then $$E_m=S_m-{m+1\choose m}S_{m+1}+{m+2\choose m}S_{m+2}-\dots+(-1)^{n-m}{n\choose m}S_n,$$ and we can obtain $L_m$ by modifying $E_m$ : for each coefficient $j\choose k$ of $E_m$ , the corresponding one is $j-1\choose k-1$ for $L_m$ . This observation seems related to the shift by one property pointed out in a very great answer [https://math.stackexchange.com/a/809201/390226] by Mr. @Markus Scheuer: $$E(z)=L(z-1)$$ which $E(z)$ and $L(z)$ are two generating functions \begin{align*}
L(z) = \sum_{k=0}^{n}l_kz^k\qquad\qquad E(z)=\sum_{k=0}^{n}e_kz^k
\end{align*} (Notice that $e_k$ is correspond to my $E_m$ , and $l_k$ to $S_m$ in my question above.)","['inclusion-exclusion', 'combinatorics', 'combinatorial-proofs']"
2944378,Show that $SO(3)$ in an embedded submanifold of $\mathbb{R}^{3 \times 3}$,"How does one go about proving that $SO(3)$ is an embedded submanifold of $\mathbb{R}^{3 \times 3}$ ? I know that there is a definition of embedded submanifold in terms of the induced topology, and I know the Cayley construction of charts for $SO(3)$ . I'm looking for a simpler method.","['submanifold', 'differential-geometry', 'matrices', 'lie-groups', 'rotations']"
2944435,Joint convergence in distribution of independent random variables,"Question: My approach: Fix any $x$ and $y$ in the codomains of $X$ and $Y$ respectively. $\mathbb{P}(X_n \leq x, Y_n \leq y) = \mathbb{P}(X_n \leq x)\mathbb{P}(Y_n \leq y) \rightarrow \mathbb{P}(X \leq x)\mathbb{P}(Y \leq y)$ , by the fact that $\mathbb{P}(X_n \leq x) \rightarrow \mathbb{P}(X \leq x)$ and $\mathbb{P}(Y_n \leq y) \rightarrow \mathbb{P}(Y \leq y)$ and by the product rule of convergence of sequence of real numbers. Using the three necessary and sufficient conditions of a function being a CDF, $\mathbb{P}(X \leq x)\mathbb{P}(Y \leq y)$ is a CDF, which is same as that of the random vector $(X,Y)$ constructed taking $X$ and $Y$ as independent. Is there anything I'm missing? The official solutions given are all much longer and involve Portmanteau Lemma.","['measure-theory', 'weak-convergence']"
2944463,Equivalent Capital Pi Notation Expressions,"So I was working on a probability question and then this expression came up. When I consulted the answers, I struggled to understand exactly how I would get from one expression to the other myself. Substituting a constant such as let $n=5$ makes it a bit clearer how they got from one expression to the other. But is there a simple , yet general explanation of these expressions. I am hoping the community could give some insight into how I should have approached this problem and similar ones in future.","['algebra-precalculus', 'products']"
2944479,Proof Verification: $\tilde{\beta_1}$ is an unbiased estimator of $\beta_1$ obtained by assuming intercept is zero,"Consider the standard simple regression model $y= \beta_o + \beta_1 x +u$ under the Gauss-Markov Assumptions SLR.1 through SLR.5. Let $\tilde{\beta_1}$ be the estimator for $\beta_1$ obtained by assuming that the intercept is 0.
Find $E[\tilde{\beta_1}]$ in terms of the $x_i$ , $\beta_0$ , and $\beta_1$ . Verify that $\tilde{\beta_1}$ is an unbiased estimator of $\beta_1$ obtained by assuming intercept is zero. Are there any other cases when $\tilde{\beta_1}$ is unbiased? Proof: We need to prove that $E[\tilde{\beta_1}] = E[\beta_1]$ Using least squares, we find that $\tilde{\beta_1} = \dfrac{\sum{x_iy_i}}{\sum{(x_i)^2}}$ Then, $ \tilde{\beta_1} = \dfrac{\sum{x_i(\beta_0 +\beta_1x_i +u)}}{\sum{(x_i)^2}}$ $\implies  \tilde{\beta_1} = \beta_0\dfrac{\sum{x_i}}{\sum{(x_i)^2}} +\beta_1 +\dfrac{\sum{x_iu_i}}{\sum{(x_i)^2}}$ Taking Expectayion on both sides: $\implies E[\tilde{\beta_1}] = \beta_0E[\dfrac{\sum{x_i}}{\sum{(x_i)^2}}]+ \beta_1 +\dfrac{\sum{E(x_iu_i)}}{E[\sum{(x_i)^2}]}$ (since summation and expectation operators are interchangeable) Then, we have that $E[x_iu_i]=0$ by assumption (results from the assumption that $E[u|x]=0$ $\implies E[\tilde{\beta_1}] = \beta_0E[\dfrac{\sum{x_i}}{\sum{(x_i)^2}}]+ \beta_1 +0$ Now, the only problem we have is with the $\beta_0$ term. If we have that $\beta_0 =0$ or $\sum{x_i}=0$ , then $\tilde{\beta_1}$ is an unbiased estimator of $\beta_1$ / Can anyone please verify this proof? Also, why don't we write $y= \beta_1x +u$ instead of $y= \beta_0 +\beta_1x +u$ if we're assuming that $\beta_0 =0$ anyway? Please let me know if my reasoning is valid and if there are any errors. Thank you. EDIT: Here's where I got the slope estimate from:","['statistics', 'regression', 'proof-verification', 'parameter-estimation', 'expected-value']"
2944491,Can someone help me finish this: evaluate $S_n = \frac{x}{1-x^2}+\frac{x^2}{1-x^4}+ ... + \frac{x^{2^{n-1}}}{1-x^{2^{n}}}$ [duplicate],"This question already has answers here : Two different expansions of $\frac{z}{1-z}$ (3 answers) Closed 5 years ago . I am asked to find the closed form solution for the below. $$S_n = \frac{x}{1-x^2}+\frac{x^2}{1-x^4}+ ... + \frac{x^{2^{n-1}}}{1-x^{2^{n}}}$$ Just writing out the $S_1, S_2, S_3$ , I have managed to find a pattern, which is: $$S_n = \frac{S_{n-1}}{1-x^{2^n}} + \frac{x^{2^n}}{1-x^{2^{n+1}}}$$ I am not sure how to proceed onwards to solve this recurrence relation. Is there a clever trick I can do to solve it?","['convergence-divergence', 'sequences-and-series', 'summation', 'real-analysis']"
2944493,The character group is an algebraic group.,"Let $X$ be a finite dimensional connected CW complex. Let $G=\pi_1(X)$ .
Let $\hat G=Hom(G,\mathbb C^*)$ the character group of $G$ .
Then $\hat G$ is an affine algebraic group. Could someone explain why this is true, i cannot relate $\hat G$ to any set of zeros of polynomials. Thank you for your help!","['representation-theory', 'group-theory', 'cw-complexes', 'algebraic-geometry', 'general-topology']"
