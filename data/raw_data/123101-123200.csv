question_id,title,body,tags
1854787,Show by example that $A \ge B \ge 0 \implies A^2 \ge B^2 \ge 0$ is not true in general,"Show by example that $A \ge B \ge 0 \implies A^2 \ge B^2 \ge 0$ is not true in general, where $A$ and $B$ are both $n \times n$ matrices in $\mathbb{R}$. I know that if $AB=BA$, then $A \ge B \ge 0 \implies A^k \ge B^k \ge 0$ holds for $k=1,2,3, \cdots$. So, the aim is to find such two matrices $A$ and $B$, $AB \ne BA$, and the proposition above dosen't hold. Can anyone help me to find such a counterexample? remark: here $A \ge B$ means that $A-B$ is positive semidefinite.","['matrices', 'linear-algebra']"
1854789,Mordell curves with many integral points,"For $k\in{\mathbb Z},k\neq 0$, denote by $f(k)$ the number of integral points on the Mordell curve $y^2-x^3=k$. According to the data at http://tnt.math.se.tmu.ac.jp/simath/MORDELL , the largest value of $f$ on the interval $[-10000,10000]$ is 32, attained for $k=1025$. Is it known/conjectured whether $f$ can take arbitrarily high values ?","['number-theory', 'mordell-curves', 'elliptic-curves', 'diophantine-equations']"
1854818,How to solve $y(x) y'(x) +C_1y(x)^2+C_2y(x)={1\over2}C_3$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question $$y(x) y'(x) +C_1y(x)^2+C_2y(x)={1\over2}C_3
$$ C1, C2 , C3 are constants. how to solve this equation??",['ordinary-differential-equations']
1854827,"On the distribution and the moments of $\max\{1/\sqrt{U_1},...,1/\sqrt{U_n}\}$, where $(U_k)$ is i.i.d. uniform on $(0,1)$","Let $U_1,U_2,...$ denote an i.i.d. sequence of random variables with the uniform distribution on $[0,1]$. For every integer $n\geq1$, we set $M_n = \max\{1/\sqrt{U_1},...,1/\sqrt{U_n}\}$. a) Compute the distribution function of $M_n:$ $F_n(x)=\mathbb{P}(M_n\leq x),\qquad x\geq 0.$ Let $p>0$. Specify the values of $p$ for which $\mathbb{E}(M_n^p)<\infty$. I was able to compute the distribution function, which is $F_n(x) = (1-\frac{1}{x^2})^n$ for $x\geq1$ and zero otherwise. which is correct regarding the solution. However, I am having trouble understanding the solution of the second part. The solution says: 
$\mathbb{E}(M_n^p)\stackrel{\text{1}}{=}\int_0^\infty x^p dF_n(x) = \int_1^\infty x^pn(1-x^{-2})^{n-1}2x^{-3}dx = 2\int_1^\infty x^{p-3}n(1-x^{-2})^{n-1}dx$ and this integral converges if and only if $p-3<-1$ i.e. $p<2$ I cannot see how this is consistent with the definition of the expected value.
In my opinion 1) should be $\mathbb{E}(M_n^p)=\int_0^\infty M_n^p dF_n(x)$ I know that does not make much sense, but can somebody explain the equality 1? The second thing I do not understand is why this integral converges. How do you see that the value of $\mathbb{E}(M_n^p)$ is finite?? Obviously there is not a chance to compute it.","['probability-theory', 'expectation', 'probability-distributions']"
1854841,If $ a_n$ is increasingly divisible by $2$ and not a multiple of $10$ then the sum of its digits goes to infinity,"Let $(a_n)_{n \geq 0}$ be a sequence of positive integers not divisible by 10 such that the number of factors 2 in $a_n$ tends to inﬁnity for $n \to \infty$. Prove that the sum of the digits of an in the decimal system tends to inﬁnity for $n \to \infty$. What I did: Feel free to use any method you like, but it was originately meant to be solved with the 10-adic numbers $\mathbb{Z}_{10}$.
Any element $(x_n)_{n \geq 0} \in \mathbb{Z}_{10}$ can be represented as a ""number""
$$
\sum_{n \geq 0} c_n 10^n
\quad \text{ for some } c_n \in \{0, 1, \dots, 9 \}
\quad \text{ for each integer } n \geq 0.   
$$
In this way we can identify $\mathbb{Z}$ with a subset in $\mathbb{Z}_{10}$
that we denote by $D$. 
If we equip $\mathbb{Z}/10^n \mathbb{Z}$ with the discrete topology and 
$\prod_{n \geq 1}\mathbb{Z}/10^n \mathbb{Z}$ with the corresponding product topology, $\mathbb{Z}_{10}$ and $D$ can be equipped with the induced topologies since 
$
D \subseteq \mathbb{Z}_{10} \subseteq \prod_{n \geq 1}\mathbb{Z}/10^n\mathbb{Z}
$.
I showed that $D$ is dense in $\mathbb{Z}_{10}$. If we define
$$
v \ : \ D \ \longrightarrow \ \mathbb{R}
\ : \ a \ \longmapsto \frac{1}{\text{number of factors 2 in } a}  
$$ 
This map is continuous on $D$. By density of $D$ it can be extended in a unique way to $\mathbb{Z}_{10}$. Hoewever, I have no idea how to prove the given statement. The problem is that I don't know what the number of decimals actually represents in this framework. Could you help me with that? The question is due to this syllabus , exercise 1.15.","['number-theory', 'decimal-expansion', 'divisibility', 'limits']"
1854849,Trigonometric Ratios for angles greater than 90 degrees and the Unit Circle,"I am confused about the Unit Circle explanation for the trigonometric ratios for angles greater than 90 degrees. It seems that for the first (top right) quadrant, $\sin(\theta)$ is equivalent to the y-coordinate, because $\sin(\theta)$ = opposite / hypotenuse $\sin(\theta)$ = opposite       [hypotenuse is 1] $\sin(\theta)$ = y-coordinate   [length of opposite side is the
y-coordinate] then, as theta extends in counter-clockwise manner to the top left quadrant, it is assumed that $\sin(\theta)$ is the still the value of the y-coordinate. From what I understand, the basis for this is that because $\sin(\theta)$ is equivalent to the y-coordinate in the first quadrant, this extends to all quadrants. But this does not make sense to me because the $\sin(\theta)$ = o/h equation was applicable in the first quadrant but not in the others. It seems to me that there are two definitions for the sine function: The relationship between the opposite side and the hypotenuse for an
acute angle in a right-angled triangle The y-coordinate of a point along the unit circle, with angle theta (counter-clockwise from the x-axis) The co-existence of these two definitions is making it confusing for me as it is not clear to me how we can get from the first to the second.",['trigonometry']
1854915,Transformation of random variables exercise,"I want to know if my solution to the following exercise is correct: Let $X$ be a gamma distributed random variable with parameter 2, meaning with distribution
$$P_X(\mathrm{d}x)=\mathbb{1}_{\{x>0\}}xe^{-x}\mathrm{d}x$$
And let $U$ be a uniform distributed random variable on $[0,1]$ that is independent of $X$.
Define$$Y_1=UX\qquad \text{ and }\qquad Y_2=(1-U)X$$ What's the distribution of $(Y_1,Y_2)$ and prove that $Y_1$ and $Y_2$ are independent with exponential distribution. Determine the parameter. Solution: 
The inverse $T^{-1}(y_1,y_2)$ of the transformation $T(x,u)$ is:
$$X=Y_1 +Y_2$$
$$U=\frac{Y_1}{Y_1+Y_2}$$
Jacobi matrix of $T^{-1}$ is
$$J_{T^{-1}}=\begin{pmatrix}1 & 1\\ \frac{y_2}{(y_1+y_2)^2} & \frac{-y_1}{(y_1+y_2)^2} \end{pmatrix}$$
With $|Det(J_{T^{-1}})|=\frac{1}{(y_1+y_2)}$, the old joined density is $$f_{X,U}=\mathbb{1}_{\{x>0\}}xe^{-x}\mathbb{1}_{[0,1]}(y)$$ and now for the new joint density
$$f_{Y_1,Y_2}=f_{X,U}\cdot|Det(J_{T^{-1}})|=f_{X,U}\left(y_1+y_2,\frac{y_1}{y_1+y_2}\right)\frac{1}{(y_1+y_2)}$$
$$=\mathbb{1}_{\{y_1+y_2>0\}}e^{-(y_1+y_2)}\mathbb{1}_{[0,1]}\left(\frac{y_1}{y_1+y_2}\right)\frac{(y_1+y_2)}{(y_1+y_2)}$$
$$=\mathbb{1}_{\{y_1+y_2>0\}}\mathbb{1}_{\left\{\frac{y_1}{y_1+y_2}\right\}\in[0,1]}e^{-(y_1+y_2)}$$ So we have an exponential distribution with parameter $\lambda=1$.
Independence follows from $f_{Y_1,Y_2}=f_{Y_1}f_{Y_2}$
$$\mathbb{1}_{\{y_1+y_2>0\}}\mathbb{1}_{\left\{\frac{y_1}{y_1+y_2}\right\}\in[0,1]}e^{-(y_1+y_2)}=\mathbb{1}_{\{y_1>0\}}e^{-y_1}\mathbb{1}_{\{y_2>0\}}e^{-y_2}$$ What confuses me is the indicator function especially $\mathbb{1}_{\left\{\frac{y_1}{y_1+y_2}\right\}\in[0,1]}$ So I don't know if I did this correct. Thanks a lot for help!","['probability-theory', 'probability', 'random-variables', 'probability-distributions']"
1854923,Value of the limit at $x=0$,"What is $$\lim_{x \to  0^+} \left((x\cos(x))^x+(x\sin(x)\right)^{1/x}?$$ I substituted $x = 0+h$ and used that near $0, \cos(h) \approx 1, \sin(h)\approx h$ to get the new limit as $$\lim_{h \to 0} \left(h^h+h^{2/h}\right).$$ But now the problem is the second term. How to reduce it to form like $0/0,\infty/\infty$? Thanks.","['limits-without-lhopital', 'limits']"
1854930,Prove that $\left|\frac{z_1-z_2}{1-z_1\bar{z_2}}\right|\lt 1$ [duplicate],"This question already has answers here : Show that $\left|\frac{\alpha - \beta}{1-\bar{\alpha}\beta}\right| < 1$ when $|\alpha|,|\beta| < 1$ (4 answers) Closed 6 years ago . Question: Prove that $\left|\dfrac{z_1-z_2}{1-z_1\bar{z_2}}\right|\lt 1$ if $|z_1|\lt1$, $ |z_2|\lt 1$ My solution: I had no idea how to go about this one so instead I started simplifying the inequality and my solution is as follows:- $$\begin{equation}
\left|\dfrac{z_1-z_2}{1-z_1\bar{z_2}}\right|\lt 1 \\
\implies \left|\dfrac{z_1-z_2}{1-z_1\bar{z_2}}\right|^2\lt 1 \\ 
\implies \left( \dfrac{z_1-z_2}{1-z_1\bar{z_2}}\right)\overline{\left({\dfrac{z_1-z_2}{1-z_1\bar{z_2}}}\right)} \lt 1 \\
\implies |z_1|^2+|z_2|^2 \lt 1 +|z_1|^2|z_2|^2 \\
\implies (|z_1|^2-1)(1-|z_2|^2) \lt 0
\end{equation}$$ Now as $|z_1| \lt 1$, so $(|z_1|^2-1) \lt 0$ and similarly $(1-|z_2|^2) \gt 0$, hence we can safely conclude that the above inequality holds. Whats my question about:- Now the book that I am solving from also gave the same solution it just further factored $(|z_1|^2-1)(1-|z_2|^2)$. This doesn't seem a good enough proof for me. If anyone can suggest a proof which doesn't simply verify the statement to be proved. P.S.:- This question has also been asked here , but I don't think I have the same query as the OP of that post.","['inequality', 'complex-numbers', 'complex-geometry', 'algebra-precalculus', 'complex-analysis']"
1854942,"Proving a function is not differentiable, when its partials are not continuous","Let $$f(x,y)=\frac{y \sin (3 x)}{\sqrt{x^2+y^2}},$$ and $f(0,0)=0$. I'm trying to prove that it's not differentiable in $(0,0)$. Some my plan was to compute the limit of the definition of differentiability, and check that it doesn't exist. However, when I try to calculate the partial derivatives, I get $$\frac{\partial f}{\partial x}=\frac{3 y \cos (3 x)}{\sqrt{x^2+y^2}}-\frac{x y \sin (3 x)}{\left(x^2+y^2\right)^{3/2}}.$$ Should I just assume that this partial derivative can be extended by continuity, or should I prove it? If I convert to spherical coordinates, I get zero as the limit.
I'm not sure if the teacher had this in mind, or I'm doing some mistake... Any help would be appreciated.","['multivariable-calculus', 'derivatives']"
1854967,Are all infinite sums not divergent? In quantum field theory,"I am a physicist interested in physics.  In particular this question is related to quantum field theory. I recently came across a derivation of the infinite sum $1+1+1+1+..... $ that produced the result -1/2, aka zeta regularization (from Terry Tao's blog ) This was quite surprising to me as I had previously known an infinite sum of 1s to be divergent - from taking a math physics course  by the guy that wrote ""the book"" on asymptotic methods. (Indeed I've known the sum of all positive integers to be finite for quite some time as well as many other ""divergent-looking"" sums and I get the whole idea behind summation methods like Padé, Shanks, Euler, etc.) Anyways this prompted me to wonder; Are ALL infinite sums not divergent? If not then how can one determine whether a sum os divergent or not? What was all this business in undergrad calculus about learning tests of convergence and all this business in complex analysis about series if weird things like $1+1+1+1+.....$ are actually convergent?? I'm still confused by all this stuff. And I haven't found an answer to these questions that ""click"" Any help understand this topic would be kindly appreciated.",['sequences-and-series']
1855000,Why do $x^{x^{x^{\dots}}}=2$ and $x^{x^{x^{\dots}}}=4$ have the same positive root $\sqrt 2$?,"What is  $x$ when is satisfies $x^{x^{x^{\dots}}}=2$ ? I am really confused with this; the root is $\sqrt{2}$, but why does the equation $x^{x^{x^{\dots}}}=4$ have the same root?","['sequences-and-series', 'analysis', 'power-towers']"
1855019,Show that $σ_n$ converges uniformly to $σ$.,"Let $a$ and $b$ be two points of $\mathbb{R}^2$.Let $σ_n : [0, 1] → \mathbb{R}^2$ be a sequence of continuously differentiable constant speed curves with $||σ_n'(t)|| = L_n$ for all $t ∈ [0, 1]$ and $σ_n(0) = a$ and $σ_n(1) = b$ for all $n$. Suppose that $\lim_{n→∞} L_n = ||b − a||$. Show that $σ_n$ converges uniformly to $σ$, where $σ(t) = a + t(b − a)$ for $t ∈ [0, 1]$. My Try: Intuitively this is clear since it talks about a sequence of paths from $a$ to $b$ that converges to the straight line through $a$ and $b$. For a rigorous proof, I wanted to show first that $σ_n'(t)$ converges uniformly. But all I have is given $\epsilon>0$ there is $N$ such that $|   \;||σ_n'(t)||-||b − a||\;|<\epsilon$ for all $n>N$, which does not support what I need to prove. Any suggestion please..","['multivariable-calculus', 'real-analysis', 'uniform-convergence']"
1855024,Generalized Harmonic Number Summation $ \sum_{n=1}^{\infty} {2^{-n}}{(H_{n}^{(2)})^2}$,"Prove That $$ \sum_{n=1}^{\infty} \dfrac{(H_{n}^{(2)})^2}{2^n} = \tfrac{1}{360}\pi^4 - \tfrac16\pi^2\ln^22 + \tfrac16\ln^42 + 2\mathrm{Li}_4(\tfrac12) + \zeta(3)\ln2 $$ Notation : $ \displaystyle H_{n}^{(2)} = \sum_{r=1}^{n} \dfrac{1}{r^2}$ We can solve the above problem using the generating function $\displaystyle \sum_{n=1}^{\infty} (H_{n}^{(2)})^2 x^n $ , but it gets rather tedious especially taking into account the indefinite polylogarithm integrals involved. Can we solve it using other methods like Euler Series Transform or properties of summation ?","['generating-functions', 'real-analysis', 'harmonic-numbers', 'sequences-and-series']"
1855043,"Prove that $\max\{a_i \mid i \in \{0,1,\ldots,1984\}\} = a_{992}$","Consider the expansion
  $$\left(1 + x + x^{2} + x^{3} + x^{4}\right)^{496} =
a_{0} + a_{1}x + \cdots + a_{1984}\,\,x^{1984}
$$
  Prove that
  $\max\left\{a_{i} \mid i \in \left\{0,1,\ldots,1984\right\}\right\} =
a_{992}\ $. Since $1 + x + x^{2} + x^{3} + x^{4}$ is a palindromic polynomial, so is $\left(1 + x + x^{2} + x^{3} + x^{4}\right)^{496}$. Now we want to show that $a_{1},a_{2},\ldots,a_{1984}$ has exactly one maximum and we are done.","['algebra-precalculus', 'number-theory']"
1855089,"How do I prove that $\int_0^1 \int_0^1 {{2+x^2-y^2}\over {2-x^2-y^2}} \, dx \, dy=2G?$","Let $G$ the Catalan's constant, prove that $$\int_0^1 \int_0^1 {{2+x^2-y^2}\over {2-x^2-y^2}} \, dx \, dy=2G$$ I not sure what do, anyway I try to integrate with respect to x first $$\int_0^1 {2-y^2+x^2\over 2-y^2-x^2}\,dx$$ Make a substitution $x^2=2+y^2$ $$-\int_0^1 {2\over xy} \, dy$$ $$-\int_0^1 {2\over y\sqrt{2+y^2}} \, dy$$ I can't find a standard integral for this, some help please.","['catalans-constant', 'integration', 'definite-integrals', 'calculus']"
1855104,What is the intuition behind $\mathbb{P} (A \text{ and }B) = \mathbb{P}(A) · \mathbb{P}(B)$ if they are independent events?,I am unable to understand this formula intuitively.,"['intuition', 'probability']"
1855115,How many unique ways are there to arrange the letters in the word HATTER?,"How many unique ways are there to arrange the letters in the word HATTER? I can't wrap my head around the math to find the answer. I know that if they were all different letters the answer would be 6!. However, I know that these T's are going to overlap, so it won't be that. I am trying to give myself examples like AAA, it can only be written once but if it was 3 different letters it would be 6 times instead.  Somehow I need to get a 6/6, so that it can become 1. If I try it with AAC, half of the permutations disappear. So it must be divided by 2 I guess. 6/2. ABC AAC 1 ACB ACA 2 BCA ACA 2 BAC AAC 1 CAB CAA 3 CBA CAA 3 I kind of see a pattern here. Possible combinations if all letters were different factorial / Divide by the number of equal letters factorial, but still I am confused. Explanation is appreciated. The answer is 360.","['combinatorics', 'statistics', 'probability']"
1855140,How to explain combinatorial identities?,"The setup of binomial expansion formula can be traced by two paths, one of which is ""pure"" proof by induction (using properties of combinatorial numbers), the other is ""practical"" comprehension by operation (considering subsets of a finite set). There are some more examples of things like this. $$\binom n 1 + 2\binom n 2 + \cdots + n\binom n n = n 2^{n - 1}$$ (Make a team out of $n$ people, and appoint a leader.) or $$\binom n 0 ^2 + \binom n 1 ^2 + \cdots + \binom n n ^2 = \binom {2n} n$$ (Choose $n$ people from $n$ ladies and $n$ gentlemen.) Sadly I cannnot figure out what this means ""in real life"": $$\binom n 1 + 3\binom n 3 + \cdots = 2\binom n 2 + 4\binom n 4 + \cdots$$ Any hint will be appreciated. (BTW: Is it always possible to ""explain"" combinatorial identities by ""reality""? I wonder sometimes it may seem too ""artificial""...)","['algebra-precalculus', 'combinatorics', 'probability-theory', 'probability']"
1855142,Resolvent of a Self-Adjoint Operator,"Let $\mathbb{H}$ be a Hilbert space and $A$ a self-adjoint operator with domain $D(A) \subset \mathbb{H}$.. Suppose that the spectrum $\sigma(A)$ of $A$ is contained in $[0,\infty)$.
Let $R_{A}(z)$ be the resolvent of $A$. I am looking for an elementary proof of the fact that for every $\lambda > 0$:
\begin{equation}
||R_{A}(-\lambda)|| \leq \lambda .
\end{equation}
I found this inequality in Hoslip & Sigal, Introduction to Spectral Theory, Sect. 5.2, where it is stated without proof.
Thank you very much in advance for your help. PS I tried the following line of proof. We have for every $\phi \in D_{A}$:
\begin{equation}
||(A+\lambda) \phi||^2 = ||A\phi||^2 + 2 \lambda (A\phi,\phi) + \lambda^2 ||\phi||^2.
\end{equation}
So the result would immediately follow if we could prove that $(A\phi,\phi) \geq 0$, that is if we could prove that $A$ is positive. Even though I suspect this is true, I cannot see a simple way to prove this.","['functional-analysis', 'operator-theory']"
1855151,Norm of the Resolvent,"Let $\mathbb{H}$ be a Hilbert space, $A$ a self-adjoint operator with domain $D_{A}$ , $R_{A}$ the resolvent of $A$ , and $z$ a point in the resolvent set $\rho(A)$ . How could you prove the inequality \begin{equation}
||R_{A}(z)|| \leq 1/ d(z,\sigma(A)),
\end{equation} where $\sigma(A)$ is the spectrum of $A$ , and $d(z,\sigma(A))$ the distance of $z$ from $\sigma(A)$ ?
I found this inequality in Hislop & Sigal, Introduction to Spectral Theory , Sect 5.2, where they reference Reed and Simon, Methods of Modern Mathematical Physics, vol. I, but I could not find a proof in that book.
Thank you very much in advance. PS I just note here that since for any closed operator \begin{equation}
||R_{A}(z)|| \geq 1/ d(z,\sigma(A)),
\end{equation} (just note that all the point $w$ such that $|z-w| < ||R_{A}(z)||$ belong to $\rho(A)$ ), the above inequality must actually hold with equality.","['functional-analysis', 'operator-theory']"
1855159,Square Root of a matrix without diagonalization,"It's well known ( wikipedia: Square root of a matrix ) that we can calculate a square root of a matrix by diagonalization or Jordan decomposition (if it's possible). But I saw a different method which seems to work, although it isn't obvious for me why it works. The method for a diagonalizable matrix $A$: First calculate the minimal polynomial $\mu_A$ of the matrix. Then chose a polynomial $p$ with $p(\lambda)=\sqrt{\lambda}$ for every eigenvalue $\lambda$. Now we get $\sqrt{A}=p(A)$. But does it always work and why? It seems to be possible to use the method in a similar way, if the matrix isn't diagonalisable e.g. if the multiplicity $\lambda$ as a zero of $\mu$  is greater than one. In this case we have to add conditions to the derivates of $p$, like $p'(\lambda)=\frac{1}{2\sqrt{\lambda}}$. Is this also correct?","['matrices', 'linear-algebra', 'elementary-functions']"
1855160,General form of Nullstellensatz,"At lots of places (some examples are 1 , 2 , 3 ), it is stated, that Hilbert's Nullstellensatz is well understood as theorem about more general Jacobson rings. Namely (When $R$ is a Jacobson ring and $S$ finitely generated $R$ -algebra, then $S$ is also Jacobson.) If $M$ is a maximal ideal of $S$ , then the pullback ideal $N=M\cap R$ of $R$ is also maximal and the field $S/M$ is finite extension over the field $R/N$ . Why is this considered to be generalize Nullstellensatz? Isn't that mainly a statement about restrictions for existence of solutions, or more precise characterization of the Galois connection in question. The general version statement is in my opinion analogous to Zariski's lemma , which is used in the first step of the usual Nullstellensatz' proof. It's very well possible it's called Nullstellensatz even though the analogy is not a strong one, because the Zariski's lemma is the crucial ingredient in the proof. However, I'm not writing here to rant about the name. I want to make sure I'm not missing something: Are the other parts of Nullstellensatz deducible from the general form or is there more to the theory of Jacobson rings, that would generalize the usual case?","['algebraic-geometry', 'commutative-algebra']"
1855175,Relearning differential geometry,"I will shortly describe my situation and than formulate the problem. From around year I am working under supervision of my professor on master thesis in differential geometry (mainly discussion of different geometric structures on manifolds) I intend to stay in field of differential geometry during PhD. Yet I very often find myself unaware of some basic fact or have trouble to rebuild some part of theory from foundations so I have decided to relearn foundations of differential geometry. For that purpose I can spare 2-3 hours during my semester break and even longer if necessary in order to do that. I plan to workout one or two handbook covering foundations of diff. geometry (especially - here I find the biggest problems - connection theory in principal bundles) and Riemannian geometry (curvature, geodesics, normal coord., Jacobi fields etc - I know that these are basic themes yet here my gaps are quite big I presume). I have some propositions for that textbook yet I ask you for opinion or propositions if you know better one (list is partial based on: List of books I , List of books II ): Foundations of Differential Geometry I - S. Kobayashi, K. Nomizu (in my opinion great for connections yet lacks other material except for some Riemannian geometry) Introduction to Smooth Manifolds - John Lee's (It was mentioned in second list yet however it covers a lot of material seems to basic) Topics in differential geometry - P. Michor (It was not mentioned on neither of lists yest I am curious of you opinion) My second question is about post from second list, namely it was stated there that it is worthwhile to master/ be familiar (which one??) with theory of surfaces and curves. What is your opinion on it? If it is really necessary to master that themes for knowing what is going on which book will you recommend? I know there are many researchers here in our community and I would be very grateful for your responses. Formally I have taken two courses connected with differential geometry. Firs one rather connected with differential topology - definition of abstract manifold, construction of canonical bundles, differential forms, hodge decomposition and some facts about differential operators (I barely remember). Second one was about Riemannian geometry - Riemannian connection, geodesics, normal coordinates, Jacobi fields, curvature, Hopf-Rinow (without proof), harmonic maps (informations). Actually I have never had classes about classical diff. geometry of curves and surfaces. If it helps my current interest is in geometric structures (G-structures and pseudo-group structures) so feel free to take it into account.","['reference-request', 'riemannian-geometry', 'differential-geometry', 'soft-question']"
1855217,Does the limit exist for $y=\sqrt{x}\sin \frac{1}{x}$?,"For the graph of   $$y=\sqrt{x}\sin \frac{1}{x},$$
Do the following limits exist? If so, what is it? (a) $\lim_{x \to 0^+} f(x)$ (b) $\lim_{x \to 0^-}f(x)$ (c) $\lim_{x \to 0}f(x)$ By the way, the graph is $\sin \frac{1}{x}$ inside of the parabola $x=y^2$ Here's what I got (a)  Yes, the limit is $0$ (b)  No (c) No I am confused on (a) because if $x$ approaches $0$ from the right hand side, then, according to the parabola, it reaches the limit $0$. But if $x$ approaches $0$ from the right hand side, according to $\sin\frac{1}{x}$, there is not limit. Please help?","['continuity', 'calculus', 'limits']"
1855242,Is there any specific criteria for a matrix $A(t)$ to have either time-dependent or independent eigenvectors?,"I am investigating properties of a matrix $$A(t_1,t_2) \equiv U_1(t_1) \otimes U_2(t_2) - U_2(t_2) \otimes U_1(t_1)$$ where $U_1$ and $U_2$ are time-dependent unitary matrices. I'm finding that for some choices of $U_1$ and $U_2$, when $t_1 \neq t_2$, the eigenvectors of $A$ are time-independent. Are there any testable properties of $A, U_1, U_2$ which could be used to predict this?","['matrices', 'eigenvalues-eigenvectors', 'kronecker-product']"
1855266,"Are Pandemic chain reactions confluent? (vertex spills weight to neighbors at threshold, once)","Are resolutions of chain reactions order-independent in the board game Pandemic?  More formally: You're given an undirected graph $G = (V, E)$ and a vertex weight $w \colon V \to \{0, \ldots, 3\}$.  Each vertex is also in a state $s \colon V \to \{\textsf{no outbreak}, \textsf{outbreak}\}$. To increase a vertex $v$: If $s(v) = \textsf{outbreak}$ then nothing happens. Else, if $w(v) < 3$ then $w(v) \gets w(v) + 1$. Else $s(v) \gets \textsf{outbreak}$ and increase all of $v$'s neighbours. It is not specified which order $v$'s neighbours should be increased in.  Is such a specification superfluous? I observe that setting $s(v) \gets \textsf{outbreak}$ is essentially the same as removing $v$ from $G$.  I don't know how that helps, though. Also, if I understand what confluence means, I think my question can be stated: ""is the following rewriting system confluent?"", where each element is a specification of $w$ and $s$ and a number of due increases for each vertex $v$, and each rewrite is an increase of some $v$ (for which an increase is due; also decrement the number of increases due for $v$).","['graph-theory', 'computer-science', 'abstract-algebra', 'convergence-divergence', 'discrete-mathematics']"
1855277,Percentage of Composite Odd Numbers Divisible by 3,"What is the percentage of odd composite positive numbers divisible by 3? In that same vein, what is the percentage of odd composite positive numbers divisible by 5? And, for the future, what is the percentage of odd composite positive numbers divisible by n where n is some prime greater than 2?","['number-theory', 'prime-numbers', 'elementary-number-theory']"
1855327,"Solid tori, meridians, and longitudes","I am working through some of Rolfsen's ""Knots and Links"" and I have needed to go back and take a more careful look at the first few sections where he carefully discusses curves on solid tori.  Let $V$ be a solid tori.  A simple (i.e. injective) closed curve that is essential (i.e. not homotopic to a point) in $\partial V$ is called a meridian if it bounds a disc in $V$. 1) Why is such a curve $J$ bounding a disc in $V$ imply that $J$ is the image of $\{ 1\} \times S^1$ under a homeomorphism $S^1 \times D^2 \to V$? 2) Why are all meridians in $V$ ambiently isotopic (thus permitting to talk about ""the"" meridian)? My next questions regard the equivalence of various definitions of a longitude in a solid torus.  A simple closed curve $K$ is called a longitude if it is the image of $S^1 \times \{1\}$ under some homeomorphism $S^1 \times D^2 \to V$.  If $K$ is a longitude of $V$ then we see that $K$ represents a generator of $H_1(V) = \pi_1(V)$ and $K$ represents some meridian of $V$ transversely at a single point.  However, I do not understand the converses to these statements: 3) If a simple closed curve in $\partial V$ represents a generator of $H_1(V)$ why is a longitude of $V$? 4) If $K$ intersects some meridian of $V$ (transversely) in a single point, then why does it follow that $K$ is a longitude? Finally, I understand that a automorphism of $\partial V$ that extends to an automorphism of $V$ must map a meridian to a meridian but: 5) Why is it that if an automorphism of $\partial V$ that maps a meridian on $V$ to a meridian of $V$ extends to an automorphism of $V$?  Is there an analogous result giving a criterion for when automorphisms of boundaries of arbitrary genus handlebodies extend to automorphisms over the whole handlebody? Thanks - sorry if this is too many questions packed into one post but I figured that they are all interrelated.","['geometric-topology', 'general-topology', 'differential-topology']"
1855330,Monkey typing on 29 letter keyboard.,"This monkey is driving me a little crazy. I think he should get fired - it's not nice. Here is the information. 
A monkey is typing on a 29 letter keyboard. He is writing a word that is 5 letters long. How many words can the monkey write? 29*29*29*29*29 What is the probability the monkey starts with the letter H? 1/29 What is the probability the monkey writes the word ""YASOV""?
1/29*29*29*29*29 What is the probability the word contains ""H"" once? I don't understand the last one. My best bet would have been 29*29*29*29*1/29^5.
The mindset being that you can press every key (4 times), and then press H once. Or maybe even 29*29*29*29*29-29*29*29*29*28. Doing a baby calculation with a keyboard of ABC, and the monkey typing a word of two letters, containing the word ""A"" only once I get 4/9. I just scribbled every possibility and found the answer, so I assume: 2*2/3*3. I don't see the connection to the 5 in the answer. I also don't understand why 28 (or 2 for that matter), as 28 would mean 28 possibilities. Wouldn't that be the possibility of not getting H? Every possibility except H? The correct solution to the real answer is 28^4*5/29^5.","['combinatorics', 'probability']"
1855371,Relation between open sentences and sets (conceptual question),"Hi I'm a college student getting into the more proof oriented side of math. I was reviewing Mathematical Proofs, A Transition to Advanced Mathematics 2nd edition and after thinking about chapters 1 and 2 came up with a question. Can sets be thought of us as the solution set of an open sentence over a specific domain? Sets can be described in a number of ways: a list of numbers following some pattern {2,4,6,...}; an expansion of sorts {2x: x is a natural number}; and what got me thinking about this whole thing, elements which satisfy some condition {x is even: x>0}. For example x>0 could be considered an open sentence with the set of even numbers as the domain. If all sets could be described as elements that satisfy some condition (or open sentence) wouldn't that mean sets are the solution sets of open sentences? Then normal set operations like intersections, unions, differences of sets, or partitions of sets could be thought of in terms of doing those operations to solution sets of open sentences. These open sentences may even be seemingly unrelated except for sharing similar solution sets. Also for an open sentence to have a solution set it needs to have a set as its domain. However this domain could be considered as a solution set to an open sentence containing its own domain (if what I'm asking is true atleast), and that type of thinking could go on infinitely. So is this connection between sets and open sentences correct? Any thoughts or advice about this whole topic are welcome. Maybe it seems like a pointless question, but I enjoy finding interrelations between seemingly separate parts of math.","['logic', 'elementary-set-theory', 'definition']"
1855408,Puiseux Expansion of Gamma Function about Infinity,"In trying to find interesting proofs that Student's T Distribution converges to the Regularized Normal Distribution when $k$ (the number of desgrees of freedom) grows without bounds (i.e. $= \infty$). One of the ways I tried involved trying to find an expansion for $\frac{\Gamma\left(\frac{v+1}{2}\right)}{\Gamma\left(\frac{v}{2}\right)}$ about $v=\infty$, though I could not make any headway on finding the expansion and I feared it would be extremely complicated. However, when I asked Wolfram Alpha I got a beautiful Puiseux Series, which is expressed as:
$$\frac{\Gamma\left(\frac{v+1}{2}\right)}{\Gamma\left(\frac{v}{2}\right)}\simeq \frac{v^{1/2}}{\sqrt2}-\frac{v^{-1/2}}{4\sqrt2}+\frac{v^{-3/2}}{32\sqrt2}+5\frac{v^{-5/2}}{128\sqrt2}-21\frac{v^{-5/2}}{2048\sqrt2}+\cdots$$
(more terms can be found in the link provided if desired). I can't help but notice that the denominators are simply $2^n \sqrt{2}$ for $n\in(0,2,5,7,11,\ldots)$ However, I can't find any pattern in $n$, nor can I explain the additional coefficients that appear starting on the fourth term, so I can't think of a way to work backward to find a proof. Regardless, all I need is the first term for the purpose of taking a limit, as all the other terms will vanish anyway. Does anyone know how to prove the expansion? Edit: I should note that I have already attacked the problem using Stirlings Series,  but I found that to be somewhat brute force for such a simple summation and I hoped for a more clever argument (it does however  some light on where the coefficients come from). Again,  I only need to know the series up to $\frac{v^{1/2}}{\sqrt2} + O(v^{-1/2})$","['asymptotics', 'sequences-and-series', 'gamma-function']"
1855445,Is $x^5 + x^3 + 1$ irreducible in $\mathbb{F}_{32}$ and $\mathbb{F}_8$?,"Problem: Is $f(x) = x^5 + x^3 + 1$ irreducible in $\mathbb{F}_{32}$ and $\mathbb{F}_8$? My thought: $f(x)$ is irreducible in $\mathbb{F}_2$ and has degree $5$. So we can conclude that $\mathbb{F}_{32} \simeq \mathbb{F}_2[x]/f(x)$. Then apparently $f$ is not irreducible in $\mathbb{F}_{32}$. But I don't know how to work on the case $\mathbb{F}_8$. I know that $\mathbb{F}_8 \simeq \mathbb{F}[x]/g(x)$ where $g(x)$ is some irreducible polynomial of degree $3$ in $\mathbb{F}_2 [x]$. For example, it can be $g(x) = x^3 + x + 1$. But how would that help me?","['finite-fields', 'abstract-algebra', 'polynomials']"
1855459,Showing the set of real values for which the pre-image has measure greater than zero is measure zero,"The question is stated as follows: Show that if $f: \mathbb{R} \rightarrow \mathbb{R}$ is measurable, then the set $E = \{x \in \mathbb{R} \ | \ m(f^{-1}(x)) > 0 \}$ has measure zero. This problem seems simple enough at first glance, and I feel like I had a solution. We begin by showing that $E$ is measurable using a definition from Royden. That is, since $E \subset \mathbb{R}$, and we have
\begin{align}
m^*(\mathbb{R}) = m^*(\mathbb{R} \cup E) + m^*(\mathbb{R} \cup E^C) 
\end{align} it follows that $E$ is a measurable set. Traditionally, if the inverse of $f$ is defined, then f is bijective and for each $y \in \mathbb{R}$, there should be one $x \in \mathbb{R}$ such that $f(x) = y$. But then for each $y \in \mathbb{R}$, $m(f^{-1}(y)) = m(\{x\}) = 0$. From this, it should follow not only that $E$ is empty, but that $m(E) = 0$. Here is where I'm not sure. If we just consider $f^{-1}$ to return the pre-image of a point $y \in \mathbb{R}$, and say that $f$ is a constant function defined $f(x) = c$, then $m(f^{-1}(c)) = m(\mathbb{R}) = \infty > 0$. In this case, however, $E = \{c\}$, which has measure zero. With this new interpretation of $f^{-1}$, I'm not exactly sure how to proceed. If the measure of $E$ was not zero, there would necessarily be an interval $(y_1,y_2) \subset E$ for which each point in the interval $y \in (y_1,y_2)$, we have $f^{-1}(y) = (x_1,x_2)$. I'm not sure what implications this might have, if any. Should I work at obtaining a contradiction here, or should I attempt to prove that $m(E) = 0$ directly? Edit: As was pointed out in the comments, my argument for the measurability of $E$ is insufficient. Further, my conclusion that an interval lived in $E$ is equally false (thanks Cantor)","['real-analysis', 'measure-theory', 'analysis']"
1855464,Is the universal enveloping algebra functor exact?,"The universal enveloping algebra is a functor from Lie algebras to unital associative algebras, and is left adjoint to the functor which sends a unital associative algebra to a Lie algebra with bracket given by the commutator. Being a left adjoint, the universal enveloping algebra construction is obviously right exact, but is it left exact? It would be nice if it was, but I have a feeling it isn't. Unfortunately I don't know enough about Lie algebras to think of a counterexample.","['category-theory', 'abstract-algebra', 'lie-algebras']"
1855470,Dual space of polynomial algebra,"Let $k$ be an infinite field and let's consider the ring $R=k[x_1,\dots,x_n]$. This ring has a structure of $k$-vector space (or a $k$-algebra). I am interested to know about the structure of the vector space $R^*$. It would be enough to know about the structure of the vector space $k[x]^*$ since $R\cong k[x]^{\otimes n}=\stackrel{n\text{ times}}{k[x]\otimes\cdots\otimes k[x]}$ (this, as a $k$-algebra) and $(V\otimes W)^*\cong V^*\otimes W^*$ as here (as a vector space). So these are my questions: Is there any known vector space which is isomorphic to $k[x]^*$? If $A$ is a $k$-algebra, does this extra structure induce a $k$-algebra structure over the dual space $A^*$? If 2. is true, does this structure preserve the property $(V\otimes W)^*\cong V^*\otimes W^*$? While I was writing I found this . This answers 1: $k[x]^*\cong k[[x]]$. About 2, the homomorphism defined there doesn't seem to be an algebra homomorphism (if I am not mistaken $$\sum_{i=0}^\infty f(x^i)g(x^i)x^i\neq \sum_{i=0}^\infty \sum_{n=0}^i f(x^n)g(x^{i-n})x^i$$ in general) so it just preserves the structure as a vector space. So Is there any way to save 2. and/or 3.? And last: What can we say about the structure of $k[[x]]^{\otimes n}$? Note: I am not sure if the notation $R^{\otimes n}$ is correct, I just thought it would be shorter that way.","['abstract-algebra', 'linear-algebra', 'tensor-products']"
1855504,Non-invertible measure preserving transformations of $\mathbb{R}^n$,"I am looking for particular examples of measure-preserving transformations of $\mathbb{R}^n$ (with Lebesgue measure) to get a better idea of how they behave. A large family of such transformations are the diffeomorphisms whose derivative has determinant $\pm 1$ everywhere. 
There are also non-continuous examples like the map $x \mapsto x - 1/x$ on $\mathbb{R}$. However, all the continuous measure-preserving maps that I know of are in fact homeomorphisms. I was wondering how far from a homeomorphism can a continuous measure-preserving map be, but I don't have any examples on my mind. So my question is: What are examples of continuous measure-preserving maps of $\mathbb{R}^n$ that are not homeomorphisms? Here are some thoughts: Such a map must be ""almost-surjective"", in the sense that its image has full measure. Indeed, the preimage of the complement of the image is empty, so it must have measure $0$ since the map is measure-preserving. Also, the map cannot be excessively non-injective since the preimage of a point must have measure $0$. I was wondering if there was some stronger statement we could say about injectivity (like we have for surjectivity).","['lebesgue-measure', 'measure-theory']"
1855508,Irreducibility of a quadric,"I am struggling with a problem in Shafarevich's Basic Algebraic Geometry. First, some context: Fix $k$ an algebraically closed field. Lines in $\mathbb{P}^3$ correspond to planes through the origin in $4$-dimensional space. Thus lines in $\mathbb{P}^3$ have an interpretation as points of the $(2,4)$-Grassmannian, which has an embedding in $\mathbb{P}^5$ given by Plücker coordinates. Call this embedding $\Pi$. In section 1.6 of Shafarevich's book, it is detailed how points corresponding to lines in a surface in $\mathbb{P}^3$ are given by a projective subvariety of $\Pi$. The problem I am struggling with asks you to show that points in the Plücker surface corresponding to lines in an irreducible quadric $Q$ over $\mathbb{P}^3$ are given by two disjoint conics. One way to approach this seems to find a ""nice"" form for $Q$ where the solution becomes obvious, for example by using the fact that one can pick coordinates to ""diagonalize"" $Q$ and then solve the problem there. However, I am having the following issues: (i) I am not sure what the rank of the quadratic form corresponding to an irreducible quadric should be. According to Georges Elencwajg's answer, Quadrics are birational to projective space it seems that the rank should be 4, but $x_0^2+x_1^2+x_2^2$ which would correspond with a quadratic form of rank 3 seems pretty irreducible to me. I understand that the rank cannot be less than 3 though (2 is a problem because then we have a change of coordinates to $x_0^2+x_1^2$ which is obviously reducible, and 1, well...). (ii) Diagonalizing seems to require a ""Gram-Schmidt"" process using the bilinear form associated with the quadratic form, which only is available for fields with characteristic different from 2, and since Shafarevich does not specify this in his statement of the exercise, this approach to the problem does not work in all cases. Thus another approach is necessary, and I don't have one. Any help would be appreciated.","['quadrics', 'quadratic-forms', 'projective-space', 'algebraic-geometry']"
1855523,How to find a symmetric matrix that transforms one ellipsoid to another?,"Given two origin-centered ellipsoids $E_0$ and $E_1$ in $\mathbb{R}^n$, I'd like to find an SPD (symmetric positive definite) transformation matrix $M$ that transforms $E_0$ into $E_1$. Let's say $E_0$ and $E_1$ are specified by SPD matrices that take the unit sphere to the respective ellipsoid:
$$
    M_0 = R_0 D_0 {R_0}^{-1} \mathrm{\ takes\ unit\ sphere\ to\ }E_0\\
    M_1 = R_1 D_1 {R_1}^{-1} \mathrm{\ takes\ unit\ sphere\ to\ }E_1
$$
where each $R_i$ is a rotation matrix and $D_i$ is a positive diagonal matrix whose diagonal entries are the respective ellipsoid's principal radii. Then of course the matrix $M_1 {M_0}^{-1}$ will take $E_0$ to $E_1$, but it is in general not a symmetric matrix (even though each $M_i$ is symmetric), so that's not a solution. I strongly suspect there is a unique SPD matrix that takes $E_0$ to $E_1$.  How can it be computed? More generally, if $R$ is any rotation matrix, then $M_1 R {M_0}^{-1}$ will take $E_0$ to $E_1$. In fact I suspect the matrices that take $E_0$ to $E_1$ are precisely the matrices of this form.  So perhaps the question boils down to ""Given SPD $M_0$, $M_1$, find a rotation $R$ such that $M_1 R {M_0}^{-1}$ is symmetric"". This comes from a statistics question: given a point cloud in $\mathbb{R}^n$ and a target covariance matrix, I want to find an SPD transformation such that the transformed point cloud has the target covariance.  Intuitively, it seems like what's needed is an SPD transformation that transforms the point cloud's error ellipsoid (found by taking the square root of its covariance matrix) to the error ellipsoid of the target covariance matrix; so that's why I'm asking this question.  However, even if I found such a transform, I'm not certain the transformed point cloud will have exactly the desired target covariance;  if it turns out that it doesn't, I'll ask a different question for the underlying statistics problem.","['statistics', 'symmetric-matrices', 'linear-algebra', 'linear-transformations']"
1855529,about representations of a simple $C^*$-algebra,"We know that every simple $C^*$-algebra is primitive, say it has a faithful non-zero irreducible representation. The converse is not necessarily true. An counterexample is just the $B(H)$ when $H$ is of infinite dimension. But if  every irreducible representation of $C^*$-algebra $A$ is faithful, whether $A$ is simple? Thank you for all helps!","['functional-analysis', 'c-star-algebras', 'operator-algebras']"
1855545,How to find normal distribution that has a quadratic?,"Let $X$ be a normal random variable with mean 1 and variance 4. Find
$P(X^2 − 2X ≤ 8)$. (Answer key .86) My attempt  $$P(X^2-2X\le 8)=P((X+2)(X-4)\le 0)$$ and this is where I am lost.  I did the following$$P(X\le -2)+P(X\le 4)=1$$ and noticed that answer is just $1$   by looking at the mean.  So I am doing something wrong.","['statistics', 'probability', 'normal-distribution']"
1855552,What is significance of this proof of existence of free groups (Lang's Algebra),"There are different proofs of existence of free groups. While reading Lang's Algebra , it caught my attention towards proof of this theorem by first bracket statement in proof: Later I went on reading proof, and lost after half-part. Then an overlook at the proof suggested me that its significance may be due to the fact that the construction comes within the category of groups. However, in some part of construction of free group, he has moved into (category of) set theory also (I feel) -see Lemma 12.2. This burned the question in mind what is real significance of this proof? Even before or after construction of free group there, it was not mentioned about why this proof was given which he owe to Tits? (I mean, there should be some thought-process and communication between Lang and Tits to give this new proof than earlier proofs)","['category-theory', 'free-groups', 'group-theory', 'soft-question']"
1855562,Two rows corresponding to adjacent vertices of a tree cannot both be linear combinations of the other rows,"Let $T$ be a tree and $A$ its corresponding adjacency matrix. Let $u,v \in V(T)$ and $u$ is adjacent to $v$. If the row corresponding to $u$ is a linear combination of the other rows of $A$, then prove that the row corresponding to $v$ cannot be written
  as a linear combination of the other rows of $A$. I can prove it when $u$ is pendant but couldn't prove it in general. Any help is appreciated. Example Take $T$ as path on $7$ vertices, $u=3$ and $v=2$ or $5$.
Here $R_3=R_1+R_5-R_7$ but we can see that $R_2$ can't be written in any linear combination of rows in $A$. Same is the case with $R_4$.","['matrices', 'graph-theory', 'linear-algebra']"
1855586,Show that the equation of motion for a particle on Norton's Dome is $\frac{d^2 r}{dt^2}=r^{1/2}$,"A particle sits at the top of a dome, whose height drops away from the centre, with a drop given by $$h=\frac{2r^{3/2}}{3g}$$ where $g$ is the acceleration due to gravity, and $r$ is a coordinate measured radially along
  the surface from the peak. At $t = 0$ the particle is at rest at the top of the dome. Show that the equation of motion is
  $$\frac{d^2 r}{dt^2}=r^{1/2}\tag{1}$$ Resolving the gravitational acceleration along the surface, $g \cos\theta$,
where $\theta$ is the angle between the surface and the vertical. A sketch shows that $dh = \cos \theta \,dr$. Hence $$\cos \theta = \frac{dh}{dr}=\frac{r^{1/2}}{g}$$ I am unable to proceed any further. Could someone please explain to me how to obtain equation $(1)$? Note: Please do not migrate this to Physics.SE (it's already there). What I am asking here is purely about the mathematics behind equation $(1)$. Thanks.","['derivatives', 'classical-mechanics', 'proof-explanation']"
1855605,What is the period of $f(x)=\sin x\cos x$?,"Problem We need to find the period of the following: $f(x)=(\sin(x))(\cos(x))$
using basic trigonometric identities which is as follows: My steps disclaimer! I know the steps but I will pin point where I am confused and please explain so Steps: 1) $f(x)=\sin(x)\cos(x)$ 2) $f(x)=\frac{1}{2}\sin(2x)$     <-- I do not understand the transition from line 1 to line 2 3) therefore period is $\pi$","['algebra-precalculus', 'periodic-functions', 'trigonometry']"
1855650,Solve $2^x+2^{-x} = 2$,Need to solve: $$2^x+2^{-x} = 2$$ I can't use substitution in this case. Which is the best approach? Event in this form I do not have any clue: $$2^x+\frac{1}{2^x} = 2$$,"['exponential-function', 'transcendental-equations', 'algebra-precalculus', 'exponentiation', 'quadratics']"
1855668,Approximation of log(n!),"I just finished calculus 1 (derivative and integral) then I take another course on calculus 2. In the video the professor talks about the the series $$\frac{n!}{(\frac{n}{e})^n}$$ He shows the approximation of the numerator ($n!$) and the denominator ($(\frac{n}{e})^n$) he approximates $\log(n!)$ using $$\sum_{k=1}^n\log(k) \approx \int_1^n\log(x) \text{d}x$$ I'm very curious because I think the $\log(n!)$ is a step function. I tried it with graphing calculator here but it shows continuous function. Is the calculator wrong? Because $n!$ has whole number as a domain so $\log(n!)$ should also be a step function? My second question is can we apply integral to a step function? What is the result different from continuous function, and how can we distinguish. For example when we have $f(x) = x^2$ and we want to do integral with the step domain (whole number) or all the domain? Here is the video (you can go and view it at 2:30) I'm a beginner in this field please explain a step by step and beginner friendly to me.","['factorial', 'integration', 'sequences-and-series']"
1855688,Could Euclid have proven Dedekind's definition of real number multiplication?,"In Euclid's day, the modern notion of real number did not exist; Euclid did not believe that the length of a line segment was a quantity measurable by number. But he did think it made sense to talk about the ratio of two lengths. In fact, he devotes Book V of his Elements to the study of such ratios, using the so-called Eudoxian theory of proportions. Here's how it works. Let $w$ and $x$ be two magnitudes of the same kind (for instance two lengths), and let $y$ and $z$ be two magnitudes of the same kind (for instance two areas). Then [according to Euclid,][2] the ratio of $w$ to $x$ is said to be equal to the ratio of $y$ to $z$ if for all positive integers $m$ and $n$, if $nw$ is greater, equal, or less than $mx$, then $ny$ is greater, equal, or less than $mz$, respectively.  Or to put it in modern language, $w/x = y/z$ if the same rational numbers $m/n$ are less than both, the same rational numbers are equal to both, and the same rational numbers are greater than both. In other words, a ratio is defined by the classes of rational numbers which are less than, equal to, and greater than it. If you've studied real analysis; this should look familiar to you: it is how the real number system is constructed using Dedekind cuts! In fact, Dedekind took the Eudoxian theory of proportions in Euclid's Book V as the inspiration for his Dedekind cut construction. So to sum up, while Euclid wouldn't have thought of them as numbers, his notion of ""ratios"" basically corresponds to our notion of ""positive real numbers"". Now with that background, my question is about the multiplication of real numbers.  Here is how Euclid defines the product of ratios: we say that the product of $w/x$ and $y/z$ is equal to $u/v$ if there exist magnitudes $r,s,$ and $t$ such that $w/x = r/s$, $y/z = s/t$, and $u/v = r/t$.  (This is well-defined by Euclid's proposition V.22 )  But this is not the standard way that multiplication is defined in the Dedekund cut construction of the real numbers, where you form a new cut by taking the products of the rational numbers in the two cuts that you're multiplying. So my question is, how can we prove than Euclid's definition of real number multiplication is equal to the Dedekind cut definition?  If I'm not mistaken, the problem basically reduces to proving the following: For all positive integers $l$, $m$, and $n$ and all magnitudes $x$, $y$, and $z$: If $l/m < x/y$ and $m/n < y/z$ then $l / n < x/ z$ If $l/m = x/y$ and $m/n = y/z$ then $l / n = x/ z$ If $l/m > x/y$ and $m/n > y/z$ then $l / n > x/ z$ And that in turn is equivalent to the following: For all positive integers $l$, $m$, and $n$ and all magnitudes $x$, $y$, and $z$: If $ly < mx$ and $mz < ny$ then $lz < nx$ If $ly = mx$ and $mz = ny$ then $lz = nx$ If $ly > mx$ and $mz > ny$ then $lz > nx$ So does anyone have any idea how to go about proving that?  For reference, addition of magnitudes is associative and commutative, and magnitudes also obey the following properties : V.1. Multiplication by numbers distributes over addition of magnitudes.
  $m(x_1 + x_2 + ... + x_n) = m x_1 + m x_2 + ... + m x_n$ V.2. Multiplication by magnitudes distributes over addition of numbers.
  $(m + n)x = mx + nx$ V.3. An associativity of multiplication.
  $m(nx) = (mn)x$ V.5. Multiplication by numbers distributes over subtraction of magnitudes.
  $m(x – y) = mx – my$ V.6. Uses multiplication by magnitudes distributes over subtraction of numbers.
  $(m – n)x = mx – nx$ EDIT: Out of the three statements I wanted to prove, I just realized that Euclid proved statement 2 in his proposition V.22 . So now I just need to prove statements 1 and 3.","['real-analysis', 'math-history', 'real-numbers', 'euclidean-geometry', 'geometry']"
1855748,Find a solution of the differential equation: $\frac{d\left(x^2\frac{dy}{dx}\right)}{dx}=x\frac{dy}{dx}-y+5$,Find a solution of the differential equation: $$\frac{d\left(x^2\frac{dy}{dx}\right)}{dx}=x\frac{dy}{dx}-y+5$$ What I have attempted: Consider:  $$\frac{d\left(x^2\frac{dy}{dx}\right)}{dx}=x\frac{dy}{dx}-y+5$$ $$ \frac{d}{dx} (x^2 \frac{dy}{dx}) =x\frac{dy}{dx}-y+5 $$ $$ x^2 \frac{d^2y}{dx^2}+2x\frac{dy}{dx}=x\frac{dy}{dx}-y+5$$ $$ x^2 \frac{d^2y}{dx^2}+x\frac{dy}{dx} +y = 5 $$ Now I am stuck..,"['integration', 'ordinary-differential-equations']"
1855759,"IMO 2016, Problem 3: Number Theory with the Area of a Polygon","IMO 2016 (Problem 3). Let $P=A_1A_2\cdots A_k$ be a convex polygon in the plane. The vertices $A_1, A_2, \cdots , A_k$ have integral coordinates and lie on a circle. Let $S$ be the area of $P$ . An odd positive integer $n$ is given such that the squares of the side lengths of $P$ are integers divisible by $n$ . Prove that $2S$ is an integer divisible by $n$ . Also on http://www.artofproblemsolving.com/community/c6h1270467_imo_2016_problem_3 Here's my idea so far. $k=3$ is a very easy case. My idea is to strong induct on $k$ . Assume that the statement for $3 \le k \le t$ . We show this for $k=t+1$ .
Start with a $t+1$ -gon on a circle. If one of the main diagonals of this polygon has square of its length as a multiple of $n$ , we can slice the polygon by that diagonal. Then we are left with two polygon with squares of all of its side lengths as a multiple of $n$ , and the polygons have no more than $t$ vertices each. So if we denote the areas as $S_1, S_2$ , we have $n|2S_1$ and $n|2S_2$ , so $n|2S$ and we are good. So for this induction to work, we need to prove that for every polygon that satisfies the condition, there is at least one main diagonal which has the square of its length as a multiple of $n$ . For example, we can prove the case $k=4$ with just Ptolemy. Can someone help me finish the solution using this idea, or maybe introduce a different solution?","['polygons', 'geometry', 'contest-math', 'area', 'elementary-number-theory']"
1855795,Which domain is correct for the function $f(x)=2\log(x-3)$,"If $f(x)=2\log(x-3)$ Then $$\text{ Dom}(f)=(3, \infty)$$ But by property of logarithm $$n\log b=\log(b^n)$$ we can write $f(x)$ as $$f(x)=\log(x^2-6x+9)$$ and now the domain is $\mathbb{R}-\{3\}$. Can I know which is correct?","['algebra-precalculus', 'functions']"
1855818,Understanding the prime ideals in the ring of dual numbers over a field,"I want to understand $\mathrm{Spec}(k[\epsilon]/(\epsilon^2))$ where $k$ is an algebraically closed field and $R:=k[\epsilon]/(\epsilon^2)$ is the ring of dual numbers . Here is my attempt: Every element in $R$ can be written as $a+b\epsilon$ for $a,b\in k.$ If $a\neq 0, \ a+b\epsilon$ is invertible and $(a+b\epsilon)(a^{-1}+ba^{-2}\epsilon)=1.$ Now from the following result in commutative algebra Suppose $R$ is a commutative ring with $1$ and $m\subset R$ is an ideal such that every element in $R-m$ is a unit. Then $R$ is a local ring and $m$ is its maximal ideal. we conclude that $R=k[\epsilon]/(\epsilon^2)$ is a local ring and the principal ideal $(\epsilon)$ is the maximal ideal. We know that the prime ideals in the quotient ring $R$ are in $1:1$ correspondence with the prime ideals in $k[\epsilon]$ that contain $(\epsilon^2)$. What is $\mathrm{Spec}(k[\epsilon])$? Well the primes in $k[\epsilon]$ are $(0)$ and $(\epsilon-a)$ for all $a\in k.$ Since  $(0)$ does not contain $(\epsilon^2)$, the only possibility is that primes in $k[\epsilon^2]/(\epsilon^2)$ could be of the form $(\epsilon -a) + (\epsilon^2)$ for $a\in k.$ Does a general $a \in k$ work here? No: we know from above that $R$ is a local ring with $(\epsilon)$ being its maximal ideal. Hence every prime ideal must be contained in this unique maximal ideal $(\epsilon)$. So this means that if $(\epsilon -a) + (\epsilon^2)$ for $a\in k$ is a prime ideal in $R$, then we must have that $$
(\epsilon) \supset (\epsilon -a).
$$ However if $a\neq 0,$ then above containment is not true. Hence we conclude that 
$$
\mathrm{Spec}(k[\epsilon]/(\epsilon^2)) = \{(\epsilon)\}. 
$$ Is my answer and reasoning correct?","['algebraic-geometry', 'commutative-algebra']"
1855824,Find the limit $\lim_{n\to \infty }\frac{1}{a_1a_2}+\frac{1}{a_2a_3}+\cdots+\frac{1}{a_na_{n-1}}$,"Given $a_1=1$ and $a_n=a_{n-1}+4$ where $n\geq2$ calculate,
  $$\lim_{n\to \infty }\frac{1}{a_1a_2}+\frac{1}{a_2a_3}+\cdots+\frac{1}{a_na_{n-1}}$$ First I calculated few terms $a_1=1$, $a_2=5$, $a_3=9,a_4=13$ etc. So 
$$\lim_{n\to \infty }\frac{1}{a_1a_2}+\frac{1}{a_2a_3}+\cdots+\frac{1}{a_na_{n-1}}=\lim_{n\to \infty }\frac{1}{5}+\frac{1}{5\times9}+\cdots+\frac{1}{a_na_{n-1}}
$$ Now I got stuck. How to proceed further? Should I calculate the sum ? Please help.",['limits']
1855872,Sinc function derivative formula,"I was trying to find a formula for the derivative of the following function $$
f_{\alpha}(x) = \frac{\sin(\alpha x)}{x}
$$ Since $$
\sin^{(k)}(\alpha x) = \alpha^k g_k(\alpha x),
$$ where $$
g_k(\alpha x) =
\left\{
\begin{array}{l}
sin(\alpha x) & k \; mod \; 4 = 0 \\
cos(\alpha x) & k \; mod \; 4 = 1 \\
-sin(\alpha x) & k \; mod \; 4 = 2 \\
-cos(\alpha x) & k \; mod \; 4 = 3 
\end{array} ,
\right.
$$ and $$
\left( \frac{1}{x} \right) ^{(k)} = (-1)^k \frac{k!}{x^{k+1}}
$$ by the Leibniz rule we have $$
f_{\alpha}(x)^{(k)} = \sum_{j=0}^k \binom{k}{j} \sin^{(j)}(\alpha x) \left(\frac{1}{x} \right)^{(k-j)} = \sum_{j=0}^k \binom{k}{j} \alpha^j g_j(\alpha x) (-1)^{k-j} \frac{(k-j)!}{x^{k-j+1}}
$$ and assuming also I haven't done any mistake so far i have $$
\sum_{j=0}^k \binom{k}{j} \alpha^j g_j(\alpha x) (-1)^{k-j} \frac{(k-j)!}{x^{k-j+1}} = (-1)^k \frac{k!}{x^{k+1}}\sum_{j=0}^k \frac{1}{j!} \alpha^j g_j(\alpha x) (-1)^{j} x^j
$$ which leads me at $$
f^{(k)}_{\alpha}(x) = \left( \frac{1}{x} \right)^{(k)} \sum_{j=0}^k \frac{(-1)^{j}}{j!} (\alpha x)^j g_j(\alpha x)
$$ My question is, is there any mistake so far? If there's no mistake, is there a ""simpler expression"" than the one I'm proposing?","['derivatives', 'calculus']"
1855932,Arnold's proof of Abel's theorem,"I'm seeking help understanding this video . The author considers the equation $ax^5+bx^4+cx^3+dx^2+ex+f = 0$ and shows both the coefficients $a, b$... and solutions $x_1, x_2$... in the complex plane. The author claims that if the coefficients are varied, moving them along short loops so they return to their original values and the solutions don't return to their original values, but instead exchange places, an expression for the solution cannot be found. What is the significance of the solutions not returning to themselves?","['abelian-groups', 'complex-analysis', 'proof-explanation']"
1855939,Spivak's proof of change of variable,"I'm reading the proof of change of variable in Spivak's Calculus on manifolds. In the last inequality of page 68, I think this proof assumed that $ f\circ g |\det g'| $ is integrable on $g^{-1}(V)$ . But Cannot understand why this is true. Can anyone explain why this function is integrable?","['multivariable-calculus', 'analysis']"
1855945,Closed form solution of a hypergeometric sum.,"The binomial theorem is one of the best known hyper-geometric sums for whom a closed form expression exists. The natural question is whether generalizations exist . In particular I would like to know if the following sum :
\begin{equation}
S^{(k)}_{p,q}(x) := \sum\limits_{l=0}^{k-2} \binom{k+p+l}{2 l+q} (-x)^l
\end{equation}
for $p,q \in {\mathbb N}$  is given in closed form? I have found a positive answer. Firstly I used sister Celine's algorithm to find the recursion relation for the term in the sum. From that by summing over the paramater $l$ I found the recursion relation for the sum itself. It reads:
\begin{eqnarray}
S^{(k)}_{p,q} + (x-2) S^{(k+1)}_{p,q} + S^{(k+2)}_{p,q}  &=& \binom{k+p}{q-2}  +\\
&&(-x)^{k-1} (x \binom{2 k+p}{p-q}-2 x \binom{2 k+p+1}{p-q+1}-\binom{2 k+p-1}{p-q+1})
\end{eqnarray}
now since the recursion relation has constant coefficients a closed form expression can always be found by solving the characteristic equation and then convolving the respective power functions with the right hand side. The solution reads:
\begin{eqnarray}
&&S^{(k)}_{p,q} =\\
&& 
\left(\frac{\sin(\phi(k-1))}{\sin(\phi)} f_{p,q-2}^{(\phi)} - \frac{\sin(\phi(k-0))}{\sin(\phi)}  f_{p+1,q-2}^{(\phi)} + f_{p+k,q-1}^{(\phi)}\right) 1_{q\ge 2} +\\
&&-
\left(\frac{\sin(\phi(k-1))}{\sin(\phi)} \tilde{f}_{p,p-q}^{(\phi)} + x \frac{\sin(\phi(k-0))}{\sin(\phi)} f_{p+2,p-q}^{(\phi)} + (-x)^k f_{p+2 k,p-q}^{(\phi)}\right) 1_{p-q\ge 0} +\\
&&2\left(\frac{\sin(\phi(k-1))}{\sin(\phi)} \tilde{f}_{p+1,p-q+1}^{(\phi)} + x \frac{\sin(\phi(k-0))}{\sin(\phi)}  f_{p+3,p-q+1}^{(\phi)} + (-x)^k f_{p+1+2 k,p-q+1}^{(\phi)}\right) 1_{p-q+1\ge 0} +\\
&&-\left(\frac{\sin(\phi(k-2))}{\sin(\phi)} \tilde{f}_{p+1,p-q+1}^{(\phi)} + x \frac{\sin(\phi(k-1))}{\sin(\phi)} f_{p+3,p-q+1}^{(\phi)} + (-x)^{k-1} f_{p-1+2 k,p-q+1}^{(\phi)}\right) 1_{p-q+1\ge 0}\\
\end{eqnarray}
where  $k \ge 2$.
Here $\phi := \arccos(1-x/2)$ and:
\begin{eqnarray}
f_{p,q}^{(\phi)} &:=& \left. \frac{1}{q!} \frac{d^q}{d \xi^q} \left(\frac{\xi^p}{1-2 \xi \cos(\phi)+\xi^2}\right)\right|_{\xi=1}\\
\tilde{f}_{p,q}^{(\phi)} &:=& \left. \frac{1}{q!} \frac{d^q}{d \xi^q} \left(\frac{\xi^p}{1+2 x \xi^2 \cos(\phi)+x^2 \xi^4}\right)\right|_{\xi=1}
\end{eqnarray}
Now, I reiterate the question. Is it possible to do the sum when the number 2 in the binomial factor in the sum in question is replaced by some integer greater or equal three?","['summation', 'discrete-mathematics']"
1856016,How to find the matrix of a quadratic form?,"I was wondering. If I have a bilinear symmetric form, it is easy to find its matrix. But, when I have a quadratic form, which is the procedure to do that? I heard that one possibility is: If $q$ is my quadratic form, then $$f(x,y) = \frac{1}{4}q(x+y) - \frac{1}{4}q(x-y)$$ is the bilinear symmetric form associated, so the method reduces to find the matrix of $f(x,y).$ The point is that seems a little noising... How to find, in practice, the matrix of quadratic form? Thanks in advance.","['quadratic-forms', 'linear-algebra']"
1856032,$\sqrt[n]{m}$ is irrational if $m$ is not the nth power of an integer,"I'm reading the book A Classical Introduction to Modern Number Theory by Ireland and Rosen, and I think that there is an exercise which is false. The exercise says: Prove that "" $\sqrt[n]{m}$ is irrational if $m$ is not the nth power of an integer"". Okey, a counterexemple for this proposition is that: Taking $$ m = \frac{8}{27},  n = 3$$ $m$ is an irreductible fraction and $$\sqrt[3]{\frac{8}{27}} = \frac{2}{3} \in \mathbb{Q}$$ with the propierty that  $$\nexists k\in \mathbb{Z} / \frac{8}{27} = k^3$$
In this counterexample we can see that m is not the nth power of an integer but $\sqrt[3]{\frac{8}{27}}$ is rational. Am I right? PD: If we suppose that $ m \in \mathbb{Z}$ we can prove that. First we are going to prove this Lemma: Lemma: $ q^n | p^n \Rightarrow q|p$ Proof (by contrapositive): We have to show that: $  q \not|p \Rightarrow q^n \not| p^n $ We will denote the set of primes as $\mathbb{P}$. Note that we assume that elements in $\mathbb{Z}$ have a unique factorization. $q \not|p \Rightarrow \exists \alpha \in \mathbb{P} / \alpha | q  \wedge \alpha \not| p \Rightarrow \alpha | q^n \wedge \alpha \not| p^n \Rightarrow \forall t \in  \{ t \in \mathbb{Z} : (\exists s \in \mathbb{Z})(t = sq^n) \} \alpha|t \Rightarrow p^n \not\in \{ t \in \mathbb{Z} : (\exists s \in \mathbb{Z})(t = sq^n) \} \Rightarrow q^n \not| p^n \\ \Box$ Now we can prove the main proposition: Proposition: $\sqrt[n]{m}$ is irrational if $m \in \mathbb{Z}$ is not the nth power of an integer Proof: $$\sqrt[n]{m} = \frac{p}{q} \Leftrightarrow m = \frac{p^n}{q^n} \Rightarrow \frac{p^n}{q^n} \in \mathbb{Z} \Rightarrow q^n | p^n \Rightarrow q|p \Rightarrow  \exists t \in \mathbb{Z} / qt = p \Rightarrow \frac{p^n}{q^n} = (\frac{p}{q})^n = t^n = m $$ $\Box$","['number-theory', 'elementary-number-theory']"
1856038,Spectrum of the Resolvent of a Self-Adjoint Operator,"Let $\mathcal{H}$ be a Hilbert space, and $A$ a self-adjoint operator with domain $D_{A} \subseteq \mathcal{H}$. Assume that $\lambda_0 \in \rho(A)$, where $\rho(A)$ is the resolvent set of $A$. For any $z \in \rho(A)$, let $R_{A}(z)=(A - z I)^{-1}$ be the resolvent of $A$. Choose $\lambda \neq \lambda_0$. Then it is well known that $\lambda \in \rho(A)$ if and only if $(\lambda - \lambda_0)^{-1} \in \rho(R_{A}(\lambda_0))$ (see e.g. Schmudgen, Unbounded Self-adjoint operators on Hilbert Space, Proposition 2.10). So we have (note that by the spectral theorem $\sigma(A)$ is nonempty):
\begin{equation}
\sigma(R_{A}(\lambda_0)) \backslash \{0\} = \left \{ \frac{1}{\mu - \lambda_0} : \mu \in \sigma(A) \right \}.
\end{equation}
If $A$ is a bounded operator on $\mathcal{H}$, then $0 \in \rho(R_{A}(\lambda_0))$, so that in this case, being $\sigma(A)$ closed, we have
\begin{equation}
\sigma(R_{A}(\lambda_0)) = \left \{ \frac{1}{\mu - \lambda_0} : \mu \in \sigma(A) \right \} = \text{closure}  \left \{ \frac{1}{\mu - \lambda_0} : \mu \in \sigma(A) \right \}.
\end{equation}
Now suppose that $A$ is unbounded. In this case $0 \in \sigma(R_{A}(\lambda_0))$. If we could prove that $0$ is not an isolated point of $\sigma(R_{A}(\lambda_0))$ (which is the same to say that $\sigma(A)$ is not bounded), we could conclude also in this case that
 \begin{equation}
\sigma(R_{A}(\lambda_0)) =  \text{closure}  \left \{ \frac{1}{\mu - \lambda_0} : \mu \in \sigma(A) \right \}.
\end{equation}
So my question is the following: if $A$ is unbounded, can $\sigma(A)$ be bounded? PS This question arouse from the answer given by TrialAndError in this post Norm of the Resolvent","['functional-analysis', 'operator-theory']"
1856042,What are some standard methods for solving functional equations?,"I have searched the internet for methods on solving functional equations, unfortunately, most of them consist mainly of substituting values for the variables or on guessing solutions. I think those methods sound like either an impossible task due to the infinite number of possible substitutions or a leap of faith due also to the infinite number of guesses there can be. How could one for example solve:
$$f(1+x)=1+f(x)^2$$
I have tried many different ideas on this, from trying guesses to applying integrals, to eliminating the $1$ by calculating $f(2+x)$ and subtracting equations, then trying to simplify the answer through sums or products, but nothing seems to work. I think this is a rather interesting subject because $f(x)=f(x-1)^2$ has a solution that is very easy to find but somehow adding a $1$ makes it a much harder problem. Are there ways to solve this equation or even a polynomial functional equation?","['functions', 'functional-equations']"
1856074,Prove that the derivative of $x^w$ is $w x^{w-1}$ for real $w$,"Can anyone give a proof of the derivative of this type of function? Specifically showing that $\dfrac{d(x^w)}{dx} = wx^{w-1}$ for a real $w$ ? I tried to use the Taylor series expansion for $(x+dx)^w$ and got the correct result. However, the proof of the Taylor series requires knowledge of the derivative of these functions. So this is essentially circular reasoning. I know that the same series is also given by the binomial expansion, but that's not entirely satisfactory either, because where's the proof that the binomial expansion works for all reals (isn't it only apparent for integers)? So far all of the arguments I've come across involve circular reasoning. I was thinking of showing that the binomial expansion is true for all reals using some form of proof by induction e.g. something like this. http://www.math.ucsd.edu/~benchow/BinomialTheorem.pdf I'm really not sure.","['algebra-precalculus', 'sequences-and-series', 'calculus', 'derivatives']"
1856109,"If $k$ is an eigenvalue of $A$ of algebraic multiplicity $r$, then is $p(k)$ an eigenvalue of $p(A)$ of algebraic multiplicity $r$?","Let $k \in \mathbb C$ be an eigenvalue of $A \in M(n,\mathbb C)$ of algebraic multiplicity $r$ (i.e. $k$ is an $r$-fold root of the characteristic polynomial of $A$). Let $p(x)$  be a polynomial with complex coefficients. Then is it true that $p(k)$ is an eigenvalue of $p(A)$ of algebraic multiplicity $r$ ? (I know that $p(k)$ is an eigenvalue of $p(A)$, but I am not sure about the algebraic multiplicity.)","['eigenvalues-eigenvectors', 'matrices', 'cayley-hamilton', 'linear-transformations', 'linear-algebra']"
1856121,How to determine the optimal length away from the pivot point and angle to the radius to use the least amount of force to rotate the lever?,"I'm writing an essay for school in physics and my topic is torque. My topic deals with the elbow joint and the tendon that attaches the radial bone to the biceps, the force that rotates the forearm upward in supentination. The tendon attaches at a certain angle, which causes the force to be at an angle. My research goal is to find the optimal length away from the elbow joint in order to create a joint that requires the least amount of force to rotate it. My set up is that of a third class lever with a weight at the end of the would be radial bone. The force pulls upwards at an angle and attaches at the humerus at a fixed height. H is constant as well and r and mg (the gravitational force on the weight). I know that the torque equation is $\text{torque}=RF\sin(\theta)$ . To produce a certain amount of torque with the least amount of force, both $\theta$ and $R$ have to be at their highest values. However, as $R$ increases, $\theta$ decreases and vice versa. I'm assuming that both will be be the highest they can be in the middle but I don't know how to prove this. Any help at all in how to figure out mathematically which values are best would be greatly appreciated. The link of the picture is below. https://i.sstatic.net/38Cfk.jpg Also, my teacher gave me the equation $\text{sum of torques}= 0 = RF\sin(\theta) - mgr$ (this is assuming that the set up is not rotating or has a constant acceleration). This turns into $RF\sin(\theta)=mgr$ . I'm going to have to graph this equation with the data I collect but I'm not sure how because there are three variables: $\theta$ , $R$ , and $F$ . My teacher vaguely referenced the lever equation and that this cancels out one variable. However, I found the lever equation to be exactly the same as the torque equation. Any help here would be greatly appreciated as well.","['physics', 'trigonometry']"
1856135,Prove: if $f(0)=0$ and $f'(0)=0$ then $f''(0)\geq 0$,"let $f$ be a nonnegative and differentiable twice in the interval $[-1,1]$ Prove: if $f(0)=0$ and $f'(0)=0$ then $f''(0)\geq 0$ Are all the assumptions on $f$ necessary for the result to hold ? what can be said if $f''(0)= 0$ ? Looking at the taylor polynomial and lagrange remainder we get: $$f(x)=f(0)+f'(0)x+\frac{f''(c)x^2}{2}$$ $$f(x)=\frac{f''(c)x^2}{2}$$ Because the function is nonnegative and $\frac{x^2}{2}\geq 0$ so $f''(c)\geq 0$ For 1., all the data is needed but I can not find a valid reason. For 2., can we conclude that the function the null function?","['derivatives', 'real-analysis']"
1856150,Number of ways to choose 4 groups of 4 people from a set of 16 people,"How many ways are there to choose 4 groups of 4 people each from a set of 16 people (the groups are distinct) ?
I can't quite decide if the answer should be ${16 \choose 4} + {12 \choose 4} + {8 \choose 4} + {4 \choose 4}$ or if it should be 
${16 \choose 4} \cdot {12 \choose 4} \cdot {8 \choose 4} \cdot {4 \choose 4}$ Can somebody give an intuitive explanation?","['combinatorics', 'discrete-mathematics']"
1856208,explain why one can write $\hat{f}(\xi)=\lim_{n\to\infty}\frac{1}{\sqrt{2\pi}}\int_{-n}^{n}e^{-i\xi x}f(x)dx$ when $f\in L^2(\mathbb{R})$,"Let $f\in L^1(\mathbb{R})$ where the measure is taken to be the Lebesgue measure. The Fourier transform of $f$ is the function $\hat{f}$ defined as 
$$\hat{f}(\xi)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-i\xi x}f(x)dx \qquad ,\xi\in \mathbb{R}$$ (Plancherel Forumla) If $f\in L^1(\mathbb{R})\cap L^2(\mathbb{R})$ then $\hat{f}\in L^2(\mathbb{R})$ and $\|f\|_2=\|\hat{f}\|_2$ (*) Assuming this result, we can extend the Fourier transform to an isometric operator $L^2(\mathbb{R})\to L^2(\mathbb{R})$ Let $f\in L^2(\mathbb{R})$ be arbitrary. Using the idea (*), explain why one can write $$\hat{f}(\xi)=\lim_{n\to\infty}\frac{1}{\sqrt{2\pi}}\int_{-n}^{n}e^{-i\xi x}f(x)dx$$ In this question, Is the equality $$\lim_{n\to\infty}\frac{1}{\sqrt{2\pi}}\int_{-n}^{n}e^{-i\xi x}f(x)dx=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-i\xi x}f(x)dx$$ correct? If the above equality is correct, do we need to show that $\int_{-\infty}^{\infty}e^{-i\xi x}f(x)dx<\infty$  i.e.  $\int_{-\infty}^{\infty}|f(x)|dx<\infty$? How can we solve the question? Thanks! Update Let $f_n=\chi_{[-n,n]}f$. Is it enough to show the following steps? $f_n\in L^1(\mathbb{R})\cap L^2(\mathbb{R})$ $f_n \to f$ in $L^2$ and $L^1$ as $n\to\infty$ $\hat{f_n}=\frac{1}{\sqrt{2\pi}}\int_{-n}^{n} e^{-i\xi x}f(x)dx$ If the answer yes, my attempt is the following: Note that $|f_n|<|f|$ implies $\int_{\mathbb{R}}|f_n|^2<\int_{\mathbb{R}}|f|^2<\infty$ . So $f_n\in L^2(\mathbb{R})$. On the other hand we have 
$$\int_{\mathbb{R}}|f_n|=\int_{[-n,n]}|f_n|\leq \sqrt{\int_{[-n,n]}|f_n|^2}\sqrt{\int_{[-n,n]}\textbf{1}^2}=\sqrt{\int_{[-n,n]}|f_n|^2}.\mathcal{L}([-n,n])<\infty$$ So $f_n\in L^1(\mathbb{R})$ as well. $|f_n-f|^2= \left\{
  \begin{array}{lr}
    0 & \text{on $[-n,n]$}\\
    |f|^2 &  \text{otherwise}
  \end{array}
\right.
$ So $$\|f_n-f\|_2^2=\int |f_n-f|^2=\int_{[-n,n]}|f_n-f|^2+\int_{\mathbb{R}-[-n,n]}|f_n-f|^2=\int_{\mathbb{R}-[-n,n]}|f|^2$$
So $\|f_n-f\|_2\to 0$ as $n\to \infty$. Similarly $\|f_n-f\|_1 \to 0$ as $n\to\infty$ By definition, it is obvious.","['functional-analysis', 'real-analysis', 'analysis']"
1856223,A simple question about the Hamming weight of a square,"Let we define the Hamming weight $H(n)$ of $n\in\mathbb{N}^*$ as the number of $1$s in the binary representation of $n$. Two questions: Is it possible that $H(n^2)<H(n)$ ? If so, is there an absolute upper bound for $H(n)-H(n^2)$? It is interesting to point out that, quite non-trivially, the answers to the same questions for polynomials $\in\mathbb{R}[x]$, with the Hamming weigth being replaced by the number of non-zero coefficients, are yes and no , but I am inclined to believe that the situation for the Hamming weigth is radically different, due to the non-negativity of coefficients. What are your thoughts about it?","['combinatorics', 'arithmetic']"
1856225,Solving what Mathematica could not,"Right, so as the final step of my project draws near and after having made a bad layout sort of question, I am posting a new one very clear and unambiguous. I need to find this specific definite integral which Mathematica could not solve: $$  \int_{x=0}^\pi \frac{\cos \frac{x}{2}}{\sqrt{1 + A \sin^2 \frac{x}{2}}} \sin \left( \frac{1+A}{\sqrt{A}} \omega \tanh^{-1} \frac{\cos \frac{x}{2}}{\sqrt{1 + A \sin^2 \frac{x}{2}}} \right) \, dx.$$ where $ 0<A<1 $ and $ \omega > 0 $ are parameters of the problem.
I tried to use a substitution of the argument of the hyperbolic arctan but that seemed to make it worse. I was posting here in the hopes of receiving help, if someone could tell me if it is at all possible to solve it analytically via a trick of sorts or a clever substitution, or maybe it is an elliptic integral in disguise. I thank all helpers. ** My question on the Melnikov integral can be found here I just used trig identities to soften it up","['integration', 'definite-integrals', 'elliptic-integrals']"
1856255,"Prove $|x|=\max\{x,-x\}$","first time poster here, so please excuse my noobiness I'm going through some basic first year college math exercises, because i found out i still can't do some of the proofs, and I've encountered this the absolute value of x is defined as $$|x|=\begin{cases}x& \text{ if } x\geq  0\\ -x& \text{ if } x<  0
\end{cases}$$ prove that $|x|=\max\{x,-x\}$ i honestly have no idea on what is required from me/how should i start can someone please help me out with a hint, or just something what would get me on the right track? thx","['algebra-precalculus', 'absolute-value']"
1856257,Giving a basis for the column space of A,"Let $A = \begin{bmatrix}3&3&3\\3&5&1\\-2&4&-8\\-2&-4&0\\4&9&-1\end{bmatrix}$ Give a basis for the column space of A So what I've done so far is put it in RREF (which was a task itself) and got $\begin{bmatrix}1&0&2\\0&1&-1\\0&0&0\\0&0&0\\0&0&0\end{bmatrix}$ , but I'm not sure what to do next to give the ""basis"" of the column space of A",['linear-algebra']
1856271,Evaluate the flux of the vector field $\vec F = -9\hat j- 3 \hat k$ on the surface $z=y$ bounded by the sphere $x^2+y^2+z^2=16$,"Evaluate the flux of the vector field $\vec F = -9\hat j- 3 \hat k$ on the surface $z=y$ bounded by the sphere $x^2+y^2+z^2=16$ My attempt: $$\iint_S \vec F \cdot \vec n dS = \iint_S (0,-9,-3) \cdot (0,1,-1) dS = -6\iint_S  dS = -6A$$ Where $A$ is the area of the surface. $A$ equal to the area of a circle with radius $4$, so $A= \pi \cdot 4^2 = 16 \pi$ Therefore the flux is:
$$\iint_S \vec F \cdot \vec n dS = -6A = -96\pi$$ But the correct answer is $-48 \sqrt{2}\pi$. Where is my mistake?","['multivariable-calculus', 'vector-analysis']"
1856289,Relationship between eigenvalues and matrix elements (Note: eigenspectrum gap and rescaling),"Let $\textbf D$ be a square matrix with eigenvalues separated into two or more groups using their magnitude (say the first group of eigenvalues is $\{1,2,\dots,10\}$ and the second group has eigenvalues $\{1010,1021,1051,\dots,10000\}$). Then consider the eigenvalue relation of transition matrix $\textbf{D}$,
$$\textbf{D}\textbf{R}=\textbf{R}\Lambda$$
Partitioning $\Lambda$ gives
$$\textbf{D}\textbf{R}=\textbf{R}
\begin{bmatrix}\Lambda_{dd}&\textbf{0}_{dm}\\\textbf{0}_{md}&\Lambda_{mm}\end{bmatrix}$$
wheere $\Lambda_{dd}$ has the smallest group and $\Lambda_{mm}$ has the largest group of eigenvalues. Rescale the system using $k$ (a value with magnitude greater than the small group of eigenvalues and less than large group of eigenvalues - say 100 or 1000 in the previous example of eigengroups) as
$$\frac{1}{|k|}\textbf{D}\textbf{R}=\frac{1}{|k|}\textbf{R}
\begin{bmatrix}\Lambda_{dd}&\textbf{0}_{dm}\\\textbf{0}_{md}&\Lambda_{mm}\end{bmatrix}$$
$$\frac{1}{|k|}\textbf{D}\textbf{R}=\textbf{R}
\begin{bmatrix}\frac{\Lambda_{dd}}{|k|}&\textbf{0}_{dm}\\\textbf{0}_{md}&\frac{\Lambda_{mm}}{|k|}\end{bmatrix}$$
Assume that $k$ infinitely large, then $\lim\limits_{|k|\rightarrow \infty}\frac{\Lambda_{dd}}{|k|}=\textbf{0}_{dd}$, $$
\tilde{\textbf{D}}\textbf{R}=\textbf{R}\begin{bmatrix}\textbf{0}_{dd}&\textbf{0}_{dm}\\\textbf{0}_{md}&\frac{\Lambda_{mm}}{|k|}\end{bmatrix}$$ However, to rescale, I need to know what is the separation between eigenvalues to find a suitable k. This is hard in large dimensional matrices due to the need of computing a large number of eigenvalues. Then instead of checking the gap in eigenvalues, How can confirm that rescaling using the gap in elements of D will rescale the eigenvalues to zero. A worked out example is given below In the first figure, elements of D is sorted by their magnitude and second figure shows the eigenvalues. If I rescale D using $10^4$ (A  value in the second gap in the element spectrum. first gap is not useful in the case), I will get the first group of eigenvalues rescaled to zero. Then by $10^6$, I may (sometimes there will be the same number of zero eigenvalues by stepping up) rescale the second group to zero and so on. How can I confirm this is true in general or for some specific cases under some conditions?. A small observation about infinity. What is infinity? When we say a value $x$ is infinite, what are we meant by that?. To my knowledge: if $x$ is defined as $\infty$, then $1/x=0$. But we know for any large number, no $x$ will satisfy this condition. There will be a decimal value at some point in $1/x$. The question is, are we considering this decimal point or not. If we are truncating it, then we can say $x=\infty$ which is an approximation. If someone says, 100 is infinite for him, then $1/100=0.01$ is a zero for him. By using this fact I trucated the matrix D by removing the decimal point which satisfies the limit condition on $k$.","['matrices', 'eigenvalues-eigenvectors', 'sparse-matrices']"
1856294,Derivation of a representation through a vector field,"Question: ( Exercise 3.4.12 - Sharpe ) Let $H$ be a Lie group, $V$ a vector space, and $\rho: H \to Gl(V)$ a representation. Let $U$ be a manifold, $X$ a vector field on $U$, and $h: U \to H$ and $f: U \to V$ smooth functions. Show that $$X(\rho (h^{-1})f) = \rho(h^{-1})X(f) - \rho_{*e}(Ad(h)(h^*\omega_H(H) )) f$$ where $\omega_H$ is a Maurer-Cartan form. Attempt: Here are some of the results I have used so far $(i)$ If $\iota : G \to G$ is the inverse function of $G$ and $\omega_H$ is a Maurer-Cartan form then $$\iota^* \omega_H(v) = - Ad(g)\omega_H(v) \,\,\, \text{for}\,\,\, v \in T_g(G)$$ $(ii)$ A smooth map $f:N \to M$ induces a pullback map $f^*: A^p(N,V) \to A^p(M,V)$ defined by $$(f^*\omega)_x (X_1, \ldots, X_p) = \omega_{f(x)} (f_*X_1, \ldots,f_*X_p)$$
where $X_1, \ldots, X_p \in T_x (M)$. By the Leibniz rule we have $$X(\rho (h^{-1})f)  = \rho (h^{-1})X(f) + X(\rho(h^{-1}))f$$ Now the idea was to show that $X(\rho(h^{-1})) = - \rho_{*e}(Ad(h)(h^*\omega_H(H) ))$. Thus, using the chain rule, $(i)$ and $(ii)$ we get $$\begin{align}X(\rho(h^{-1}))|_h &\underset{\text{def}}= \rho(h^{-1})_*(X_h)\\&\underset{\text{C.H.}}= (\rho_{*e}h^{-1}_*)(X)\\&=[\rho_{*e}(\iota h)_*](X)\\&\underset{\text{C.H.}}=\rho_{*e}[\iota_* h_*(X)]\\&=\rho_{*e}[L_{h*}\circ L_{h^{-1}*}\iota_* h_*(X)]\\&=\rho_{*e}[L_{h*}\omega_H(\iota_* h_*(X))]\\&\underset{\text(ii)}=\rho_{*e}[L_{h*}\iota^*(\omega_H(h_*X))]\\&\underset{\text{(ii)}}= \rho_{*e}[L_{h*} \iota^*(h^*\omega_H(X))]\\&\underset{\text{(i)}}= -\rho_{*e}[L_{h*}Ad(h)h^*\omega_H(X) ]\end{align}$$ this is what I got so far. $1)$ Is it correct? $2)$ What can be improved? $3)$ Where to go from here? 4) Should the vector field be considered left-invariant?","['differential-forms', 'differential-geometry', 'proof-verification', 'lie-groups']"
1856315,The square of a infinite series.,"Say we have $\sum_{n=1}^{\infty} f(n,x)=f(x)$, which often happens with Taylor series: Can we express: $$\left(\sum_{n=1}^{\infty} f(n,x) \right)^2$$ As something that does not involve the square. I.e  can multiply this out : $$\left(f(1,x)+f(2,x)+f(4,x)+.... \right)\left(f(1,x)+f(2,x)+f(3,x)+...\right)$$ I know by distributive property we have: $$=f(1,x)\sum_{n=1}^{\infty} f(n,x)+f(2,x)\sum_{n=1}^{\infty} f(n,x)+f(3,x)\sum_{n=1}^{\infty} f(n,x)+..$$ Can we simplify further? Why I ask this is that I'm really interested if we can express $\left(\frac{\ln (x)}{x-1} \right)^2$ as a series by only using the Taylor series for $\ln x$. I know I can just write the coefficients and multiply them out , but the new coefficients to the new series do not form an easy pattern to right down.",['algebra-precalculus']
1856319,prove $\bigcup_{n=1}^\infty A_n=\bigcup_{n=1}^\infty B_n$,prove$\bigcup_{n=1}^\infty A_n=\bigcup_{n=1}^\infty B_n$ if $A_i$ is a arbitrary set and $B_1=A_1$ and $B_n=A_n-\bigcup_{i=1}^{n-1} A_i$ for $n\ge 2$. I have no ideas for solving it there was another question befor this that wanted to show: $A_n\cap[A_n\cup B_n]=A_n$ that was easy to solve because $A_n\cup B_n=B_n$ and then $B_n \cap A_n=A_n$.I wrote this because I think it may helpful. Thanks for your answers.,['elementary-set-theory']
1856323,"Vertices of a cyclic polygon have integer coordinates and sides. If odd $n$ divides the squares of the sides, it divides twice the area.","IMO 2016 Problem 3: Let $P = A_1 A_2 \cdots A_k$ be a convex polygon in the plane. The vertices $A_1, A_2, \ldots, A_k$ have integral coordinates and lie on a circle. Let $S$ be the area of $P$ . An odd positive integer $n$ is given such that the squares of the side lengths of $P$ are integers divisible by $n$ . Prove that $2S$ is an integer divisible by $n$ . I tried using the formula for area of a polygon in cartesian plane, after assuming coordinates, but to no avail.","['polygons', 'analytic-geometry', 'geometry', 'contest-math', 'elementary-number-theory']"
1856325,When do differential operators commute?,"Given that the equation of motion of a particle placed on the apex of Norton's Dome is $$\frac{d^2 r}{dt^2}=r^{1/2}\qquad\longleftarrow\text{as proved in this previous question}\tag{1}$$ Solve this non-linear equation by multiplying both sides by $$2\frac{dr}{dt}$$ and integrating to find that $$r(t)=\frac{\left(t-T\right)^4}{144}$$ for any $T\ge 0$. Pre-multiplying both sides of $(1)$ by $$2\frac{dr}{dt}$$ gives $$2\color{red}{\frac{dr}{dt}}\color{blue}{\left(\frac{d^2r}{dt^2}\right)}=2\frac{dr}{dt}r^{1/2}\tag{2}$$ Rewriting $(2)$ $\bbox[yellow]{\text{with the order of the red and blue factors switched}}$ gives: $$2\color{blue}{\frac{d^2r}{dt^2}}\color{red}{\left(\frac{dr}{dt}\right)}=2\frac{dr}{dt}r^{1/2}\tag{3}$$ The reason for the switch is because the blue factor in $(3)$ is the derivative of the red factor (I had to write it this way in order to integrate by inspection). Integrating both sides gives $$\left(\frac{dr}{dt}\right)^2=\frac{4}{3}r^{3/2}+C\tag{4}$$ In obtaining $(4)$ from $(3)$ I used the chain rule on the RHS, namely $$\frac{d}{dt}=\frac{d}{dr}\cdot\frac{dr}{dt}$$ Finally, my question is all about the validity of the sentence highlighted in yellow. I am aware that differential operators do not commute in general. So is it plausible for me to simply switch the order of the red and blue factors as I did in getting from $(2)$ to $(3)$? Many thanks.","['derivatives', 'classical-mechanics', 'proof-explanation']"
1856346,Find $x$ in $\mathbb{R}^2$ whose cordinate vector relative to the basis $B$,Consider the basis $B$ of $\mathbb{R}^2$ consisting of vectors $\begin{bmatrix}5\\-1\end{bmatrix}$ and $\begin{bmatrix}-7\\-4\end{bmatrix}$ . Find $x$ in $\mathbb{R}^2$ whose coordinate vector relative to the basis $B$ is $[x]_B = \begin{bmatrix}2\\5\end{bmatrix}$ $x = ?$ I put the matrices together obtaining a $3 \times 3$ matrix that I row reduced to get $\begin{bmatrix}1&0&-1\\0&1&-7/11\end{bmatrix}$ but then when I tried $x = \begin{bmatrix}-1\\-7/11\end{bmatrix}$ it said it was incorrect. I'm confused what i'm doing wrong,['linear-algebra']
1856354,What's the probability of getting $5$ different numbers but not any $6$ when throwing $5$ dice?,"I have $5$ dice, I throw them at once. What is the probability of getting $5$ unique numbers, i.e., $1\ \  \&\ \  2\ \  \&\ \  3\ \  \&\ \  4\ \  \&\ \  5$ in any order BUT NOT any $6$? Of course they can be in any order as long as all $5$ dice are all unique numbers but not any $6$. I presume number of possibilities is divided by $6$ to the power of $5$ ($7776$)? But I do not know the number of possible permutations for $5$ unique numbers, excluding a $6$. Please help. The question has an actual usefulness for me. What is the probability of getting $5$ different numbers but not any $6$ when throwing $5$ dice at once?","['permutations', 'dice', 'probability', 'combinations']"
1856364,Elementary question: local computation of curvature on principal bundle,"Let $G$ be a Lie group and $S=[0,1]^2$. Let $\omega$ be a connection $1$-form on the trivial principal $G-$bundle $P=S\times G$ over $S$. Let $(x_1,x_2)$ be coordinates on the base $S$. We can choose a trivialization of $P$ which is parallel with respect to the $x_1-$direction over the $x_1-$axis (aka $[0,1]\times\{0\}$) and which is parallel in the $x_2-$direction at every point of $S$. Then $\omega=A_1dx_1+A_2dx_2$ where $A_i\in\mathfrak{g}$ satisfy $A_2=0$ everywhere and $A_1|_{[0,1]\times\{0\}}=0$. Denote the horizontal lift of a vector field $\chi$ on the base to $P$ as $\tilde{\chi}$. Let $\sigma$ be the vertical projection on $P$ given by $\omega$. Let $\chi_i=\partial_{x_i}$ then $\tilde{\chi_2}=\partial_{x_2}$ and $\tilde{\chi_1}|_{[0,1]\times\{0\}}=\partial_{x_1}$. How to show that $\sigma([\tilde{\chi_1},\tilde{\chi_2}])=-\partial A_1/\partial x_2$ at $(0,0)\in S$? I mean, it doesn't make sense since $\omega|_{(0,0)}=0$, is it not? Where is my misunderstanding? This is taken from page $73$ of the book ""Gauge Theory and the Topology of Four-Manifolds"" by Friedman and Morgan. Thank you.","['reference-request', 'gauge-theory', 'differential-geometry', 'algebraic-geometry']"
1856369,Computed wrong the sum $\displaystyle\sum_{n\ge1}\frac{\cos n}{n^2} $ [duplicate],"This question already has answers here : Series $\sum_{n=1}^{\infty}\frac{\cos(nx)}{n^2}$ (7 answers) Closed 7 years ago . I've computed (using standard complex analysis techniques) the sum
$$
\sum_{n\ge1}\frac{\cos n}{n^2}
$$
and I found $\pi^2/6+1/4$ which is strictly greater than $\pi^2/6$, and this is impossibile, since my series is less or equal than $\sum_{n\ge1}1/n^2$. So I must have done some mistake, somewhere. I won't write all details of my computation because it would be boring for me and for you too; I only need to know where can I find the sum of this series: in this way I could look at my computations and find the mistake. Many thanks","['complex-analysis', 'sequences-and-series']"
1856396,Is a relation between A and B the same as a mapping from elements of A to subsets of B?,"The way I always saw it was that a relation is a subset of $A \times B$, or a collection of ordered pairs $(a,b)$, where $a \in A$ and $b \in B$. Is there any meaningful distinction between the two definitions? If they are one and the same, I think my trouble lies in the definition of ""mapping"", and any insight you can give would be great. The reason I ask this question is because this is how it's defined in my discrete mathematics class. Thanks for your help!","['definition', 'elementary-set-theory', 'discrete-mathematics']"
1856400,Finding Size-Bias Distributions,"For a RV $W$ with mean $\mu$, let $W^*$ denote the $W$-size biased distribution (so that $EG(W^*)=\frac{E(WG(W))}{\mu}$ for all functions $G$ for which the expectations exist). I would like to learn how to find a formula for $W^* $ when $W=X_1+\cdots +X_n$ is a sum of dependent RVs. From ""Multivariate Normal Approximations by Stein's Method and Size Bias Couplings"", https://arxiv.org/pdf/math/0510586v1.pdf page 3: We replace $X_I$ with $X^* _I$ where the random index is chosen independently with $\mathbb{P}(I=i)=\frac{EX_i}{\sum EX_j}$, and adjusting the remaining variables to their conditional distribution given the new value of $X_I$. I cannot quite understand this statement. I want to be able to apply this to find $W^*$ for particular examples. For example, I'd like to know how to find $W^*$ when $X_i \sim Be(p_i)$ for $i=1,\ldots, n$.","['statistics', 'sampling', 'probability', 'probability-distributions']"
1856409,Fun with combinatorics and 80 business customers,"In business with 80 workers, 7 of them are angry. If the business leader visits and picks 12 randomly, what is the probability of picking 12 where exactly 1 is angry? (7/80) (73/79) (72/78) (71/77) (70/76) (69/75) (68/74) (67/73) (66/72) (65/71) (64/70)*(63/69)*12=0.4134584151106464 What is the probability more than 2 are angry? My idea is to calculate the probability of 2,3,4,5,6, and 7 angry people just like did in the previous example and then add them altogether. In the previous example I can seat the one person 12 times. In all the different 12 spots, and then times by 12. The problem I have now is, how many times can I seat 2 people in 12 spots? If I use the combinatorics formula I will get a negative factorial. There must be a much easier way than this.","['combinatorics', 'probability']"
1856432,Why are Lie groups automatically analytic manifolds?,"In the book by Kolar, Michor, and Slovak, it is shown that multiplication $\mu:G\times G\to G$ is analytic in some neighborhood of $e$. Specifically, they show that in the chart given by $\exp^{-1}$, with domain some neighborhood of the origin, multiplication is real analytic. They claim that it follows that $\mu$ is analytic on all of $G$. By this, I think they mean there always exists a real analytic structure on $G$ in which $\mu$ is everywhere analytic. Could someone please supply the details? I'm assuming the thought is to push this neighborhood of analyticity around the group by using the multiplication map and the fact that a Lie group is generated by any neighborhood of $e$. However, this is only true for connected Lie groups, so this approach would fail for e.g. $\mathrm{O}(n)$, $n>2$.","['differential-geometry', 'group-theory', 'lie-groups']"
1856452,Quotients of Elliptic Curves,"I am fairly inexperienced with elliptic curves so there might be aspects of my question that may need better wording but let me know if there are any issues: Question: Say I have an elliptic curve over $\mathbb{F}_7$ and this curve has 12 points. I take a subgroup of size 3 and I quotient the curve by that subgroup. Magma and Sage can easily tell me the equation of the curve where the quotient lives. Not surprisingly, extra points pop up when taking a quotient that where not defined over $\mathbb{F}_7$ but become defined over $\mathbb{F}_7$ when you take the quotient. So the curve they spit out may (and usually does according to my random sample) still have 12 points. What is happening on the function field side? Is the function field of the original curve an extension of the function field of the other curve? If not what is going on?","['function-fields', 'elliptic-curves', 'algebraic-geometry']"
1856520,"How to ""abstractly"" differentiate function, expressed in terms of itself","I am interested in differential equations of a single variable in the the dependent function. For example 
$$y = e^x \rightarrow \frac{dy}{dx} = y$$ 
$$y = \frac{1}{1-e^{-x}} \rightarrow \frac{dy}{dx} = y(1-y)$$ In general if i'm given $y= f(x)$, How do I find an $F$ such that $y$ satisfies the differential equation $$ \frac{dy}{dx} = F(y)$$ One solution is $$ \frac{dy}{dx} = f'(f^{-1}(y)) $$ Of which the two above are a special case, but how do we characterize the entire set of such  $F$?","['ordinary-differential-equations', 'calculus']"
1856552,"Example of set, finite outer measure, subsets, where outer measure does not converge","What is an example of a set $X$ and a finite outer measure $\mu^*$ on $X$, subsets $A_n \uparrow A$ of $X$, and subsets $B_n \downarrow B$ of $X$ such that $\mu^*(A_n)$ does not converge to $\mu^*(A)$ and $\mu^*(B_n)$ does not converge to $\mu^*(B)$?","['real-analysis', 'probability-theory', 'lebesgue-measure', 'measure-theory', 'general-topology']"
1856564,"$A_{mn} = \frac{1}{\pi}\int_0^{\pi}d\theta\, \sin(2m\theta)\, \frac{1-\cos^{2n}(\theta)}{\tan(\theta)} = $ ? $m$, $n$ integers > 0","The integral 
$$
A_{mn} = \frac{1}{\pi}\int_0^{\pi}d\theta\, \sin(2m\theta)\, \frac{1-\cos^{2n}(\theta)}{\tan(\theta)}
$$
popped up when I was playing around with the integral representation of the harmonic numbers $H_n$. I find that Mathematica can give a result for specific values of $m$ and $n$ but I can't get a general formula. Some observations that appear to be true, based on Mathematica results for specific cases: 1) $A_{mn} > 0$. 2) When $m = n$, $A_{nn} = \frac{1}{4^n}$. 3) When $m > n$, $A_{mn} = 0$. (I think this should follow from expanding the $\cos^{2n}(\theta)$ part out in a finite sum of terms like $\sin$ or $\cos$ of integers times $\theta$.) I tried doing this via contour integration by extending the integral (which is symmetric around $\pi$) to $[0,2\pi)$, and making the substitution $z = e^{i\theta}$. Unless I've made a mistake, this leads to:
$$
A_{mn} = \frac{1}{2\pi i}\oint dz\,
\frac{\left(z^{2m} - z^{-2m}\right)\left(z+z^{-1}\right)\left[1 - \frac{1}{2^{2n}}{\left(z + z^{-1}\right)}^{2n}\right]}{z^2 - 1}\, ,
$$
where the integral is over the counter-clockwise unit circle. This doesn't seem to work: The zeroes appear to cancel on the top and bottom at $z = \pm 1$, so the residues are zero. Have I made a mistake in the contour integration approach? Is there a better way to evaluate this whole thing?","['integration', 'fourier-series']"
1856626,Expected value of the zeros of random polynomials of degree two,"Let $a_1,a_0$ be i.i.d. real random variables with uniform distribution in $[-1,1]$. I'm interested in the random zeros of the polynomial $$p(x) = x^2 + a_1x + a_0. $$ One thing (between many) thing I'm particularly interested is in computing the expected value of it's zeros. It's possible to write exactly what are the zeros $z_1,z_2$ of $p(x)$, they are
$$ z_1 = \frac{-a_1+\sqrt{a_1^2-4a_0}}{2} $$
and
$$ z_2 = \frac{-a_1-\sqrt{a_1^2-4a_0}}{2}. $$ Therefore what I want is to calculate $$E[z_1] = E\Bigg[\frac{-a_1+\sqrt{a_1^2-4a_0}}{2}\Bigg] = \frac{-E[a_1] + E\Big[{\sqrt{a_1^2-4a_0}}\Big]}{2} = \frac{E\Big[{\sqrt{a_1^2-4a_0}}\Big]}{2}.$$ Note that I only need to calculate $E[z_1]$, for $E[z_2] = \overline{E[z_1]}$. Also, doing some experimentation with Matlab, it looks like $E[z_1] = i$. I want to confirm that result with a mathematical proof, if possible. Thank you. Edit: From my own computation, we can see that the correct relation between the expected values should be $E[z_2] = -E[z_1]$, not $E[z_2] = \overline{E[z_1]}$.","['probability-theory', 'polynomials', 'expectation']"
1856644,Left vs right semi direct products,"I just want to make sure that I am not doing anything silly here, but if we let $G$ be a group with $H,K$ subgroups, $H\lhd G$, and $\phi:K\rightarrow Aut(H)$, then is $$H\rtimes_\phi K \approx K \ _\phi\ltimes H$$ where the multiplication in the first is given by $$(h_1,k_1)(h_2,k_2) = (h_1\phi_{k_1}(h_2),k_1k_2). $$  Basically does it make complete sense just to switch the ""slots"" in the order pair?  This idea has come up in a project that I have been looking at for some time and using this notion would help me simplify some calculations greatly. Thanks in advance.","['abstract-algebra', 'semidirect-product', 'group-theory']"
1856654,Proving that $2^{2a+1}+2^a+1$ is not a perfect square given $a\ge5$ [duplicate],"This question already has answers here : Solve $1+2^x+2^{2x+1}=y^2$ for integers $x,y>0\,$ [IMO 2006 P4] (2 answers) Closed 6 years ago . I am attempting to solve the following problem: Prove that $2^{2a+1}+2^a+1$ is not a perfect square for every integer $a\ge5$. I found that the expression is a perfect square for $a=0$ and $4$. But until now I cannot coherently prove that there are no other values of $a$ such that the expression is a perfect square. Any help would be very much apreciated.","['algebra-precalculus', 'square-numbers', 'exponentiation']"
1856656,"Why is $(h,k)$ in the vertex formula of a parabola $=a(x-h)^2 +k$ the vertex?","Why is it that in the form $y=a(x-h)^2+k$ of a parabola, that $(h,k)$ is the coordinate of the vertex? I am reviewing Algebra and cannot find a reasonable explanation anywhere.The highest level of math I am familiar is with Pre-Calculus. Thanks!","['algebra-precalculus', 'conic-sections']"
1856666,Is square-root of a real symmetric positive semi-definite matrix real as well?,"Given a real symmetric positive semi-definite matrix $A$, will there be a root $R$ which is real symmetric positive semi-definite as well? Can you comment on it's uniqueness? It will be nice if you can give proofs as well.","['matrices', 'linear-algebra']"
1856672,If $BNA=N$ it can happen that $B$ and $A$ identities?,"Consider two matrices $A\in GL_m(K)$, $B\in GL_n(K)$ such that for any $N\in M_{n,m}(K)$ is true that
$$BNA=N$$ How can I prove that $B$ and $A$ are identities?","['matrices', 'matrix-equations']"
1856697,A question concerning non-algebraic extension.,Let $\tau:F \to \overline{F}$ be a field embedding. Then is $\overline{F}/\tau(F)$ algebraic extension? I don't think so but I cannot find a counterexample. Would you let me know a counterexample?,"['abstract-algebra', 'extension-field', 'field-theory']"
1856725,Is it possible to be a frequentist and a subjectivist at the same time?,"I'm trying to understand the differences between (1) Bayesian vs frequentist; and (2) subjectivist vs objectivist. So far my understanding (correct me if I'm wrong) is that: (1) Bayesian vs frequentist. Frequentist: A probability $p$ represents a long-run frequency. Bayesian: A probability $p$ simply reflects our tentative state of knowledge. Given new information, we may update $p$. (2) Subjectivist vs objectivist. Subjectivist: A probability is simply one's personal, subjective degree of belief about some particular matter. So two rational, intelligent people with the same information and knowledge can disagree about a probability $p$. Objectivist: It is impossible for two perfectly-rational people with the same information and knowledge to disagree about a probability $p$. My understanding is that Bayesians are typically subjectivist and frequentists are typically objectivist. However, it is possible for Bayesians to be objectivist. My question is this: Is it possible for frequentists to be subjectivist? And how would such a subjectivist-frequentist interpret probability?","['statistics', 'probability', 'philosophy']"
1856807,Radius of inner circles given radius of outer circle and number of inner circles in circular fractal,"I am trying to create a circular fractal in which each circle is composed by a given number $n$ of smaller circles. It would look something like this for $n = 8$: However, I don't know how to calculate the radius of the smaller circles. Of course I know that the distance from the centre of the bigger circle to the centres of the smaller circles is $r_1 - r_2$, where $r_1$ is the radius of the bigger circle and $r_2$ is the radius of the smaller ones, and that their radius is $\frac{d}{2}$ where $d$ is the distance between two adjacent circles' s centres. $d$ is for sure related to $n$ but I don't know how to calculate it.","['circles', 'fractals', 'geometry']"
1856810,Blow-up of a point on a smooth simply connected variety,Apologies if this is an obvious question. Suppose I have a variety which I know is smooth and simply connected and blow-up a smooth point so that the resulting variety is smooth. Does the exact point that I blow-up matter or will the resulting variety be the same regardless of which points I blow-up?,"['algebraic-geometry', 'blowup']"
