question_id,title,body,tags
2240366,Most efficient algorithm to neutralize all positive and negative,"So I've been lately working on an app which requires me to code this algorithm. But I'm unsure what I've come up with is the most efficient algorithm. Say I have 2 sets (or rather arrays, as there can be duplicates) A and B with all positive values in A and all negative values in B. Ex - A = {1, 3, 1} (sum = 5) B = {-2, -3} (sum = -5) The sum of all elements in both the array will always be 0 (-5 + 5 = 0). The number of elements might be different. Now what is the most efficient way (minimum steps) to neutralize all values? For example one way: -3 + 1 = -2 Now A looks like: {0, 3, 1} and B looks like: {-2, -2} Then -2 + 3 = 1 Now A looks like: {0, 1, 1} and B looks like {0, -2} Now doing 2 more steps. Hence total of 4 steps. Can I compute the most efficient solution for this? How? My take was to neutralize first the exact matching values (makes 2 elements 0 directly). Then look for biggest in positive and start merging with biggest in negative as long as possible. But it is just intuitive thinking from my side. Is there any efficient algorithm to this?","['combinatorics', 'algorithms']"
2240392,Rolling $2$ dice: NOT using $36$ as the base?,"I apologize for such a simple question. It has been a while since I took math classes. When you roll $2$ dice, there are $36$ possibilities. However, there are only $21$ combinations, if order does not matter. Rolling a $(4,2)$ = rolling a $(2,4)$. Let's say in a game, rolling a $(1,1)$ makes you lose. The odds of rolling this is a $1/36$. But why can't you say the probability is a $1/21$, assuming you roll both dice at the same time? There's only one combination that makes you lose, so why can't you use $21$ as the denominator? I have tried searching on this topic, but have not found a good answer. (Most likely because my thinking is fallacious.)","['permutations', 'combinatorics', 'probability', 'dice']"
2240401,How to show that some set is open?,"I know my question will sound stupid, that it should be simple, and I know there are already a lot of questions related to this topic, but I've spent hours on it and I still don't get how to show that a given set is open or not . I'm completely stuck and I don't exactly know how I'm supposed to start and proceed. I already looked for other posts about the topic ( like this one , for example, for which I did not manage to understand the answers that were given) but it didn't help. Here is a set for which I'm supposed to determine if it is open or not:
$$U := \{(x_1 , x_2) \in \mathbb{R}^2 : x_2 > \sqrt{|x_1|} \}$$ What I know (and what I would like to use): Let $(X,d)$ be a metric space. A set $U \subset X$ is open if, for all $x \in U$, there exists $r>0$ such that $B(x,r) \subset U$. For a metric space $(X,d)$ with $x \in X$, an open ball $B(x,r)$ is defined as $\{y \in X : d(x,y) < r \}$ The metric $d$ is not specified, so I guess it's the Euclidean metric: for $x = (x_1, x_2)$ and $y=(y_1, y_2)$, we have $d(x,y) = \sqrt{(x_1 - y_1)^2+(x_2 - y_2)^2}$. So, if I understand all this properly, what I'm supposed to show is that, for all $x \in U$, there exists (or not) $r$ such that $B(x,r) \subset U$, i.e. such that the elements $(y_1, y_2)$ of $B(x,r)$ are such that $y_2 > \sqrt{|y_1|}$. And, since these elements are in $B(x,r)$, they are such that $\sqrt{(x_1 - y_1)^2+(x_2 - y_2)^2} < r$. So, if I get this right, the elements $y$ of $B(x,r)$ should be such that $y_2 > \sqrt{|y_1|}$ and $\sqrt{(x_1 - y_1)^2+(x_2 - y_2)^2} < r$. But then what? I don't understand what I'm supposed to do with all this. How can I ""mix"" those things together so that I have, at the same time, a convenient $r$  and $y_2 > \sqrt{|y_1|}$? I'm missing something, but what? Could anyone give me some hints or indications that would help me to get started? I hate to ask for help in such situations, because it looks like I did not even try, but the thing is that I really don't know where to start. Any help would be, therefore, greatly appreciated.",['general-topology']
2240429,Pairwise distance matrix,"Suppose $x_1,\dots,x_n \in \mathbb{R}^d$. Is there a vectorized way of representing the square distance matrix $D_{ij} = \lVert x_i - x_j \rVert^2$?","['optimization', 'linear-algebra']"
2240441,"Don't know how to solve systems, any help or resources would be appreciated","I missed a week of class because I was sick and I'm trying to do my homework but I simply don't know how. I tried looking for videos on youtube but couldn't find anything similar (not sure what these are called? Differential system of equations maybe?). Any explanation on the steps needed to solve these problems (or the one below) would be greatly appreciated. Please note I'm looking for how to solve them, not the answer (answers are already in the back of the book). Thanks! Solve the systems
  \begin{align*}
\frac{\mathrm{d}x}{\mathrm{d}t} &= 2x -y\\
\frac{\mathrm{d}y}{\mathrm{d}t} &= x
\end{align*}","['ordinary-differential-equations', 'systems-of-equations']"
2240487,Determining a value $k$ that gives a size = 0.05 test.,"A single observation $X$ from a normal distribution with mean $\mu$ and $\sigma^2$ =1 is used to test $$H_0 : \mu = 1 \ \ \ \text{vs} \ \ \ H_1 : \mu \lt 1 $$ using the critical region $C = {{x : x \lt k}}$ Determine the value of k that gives a size 0.05 test. My attempt: The size of the test = significance level = $\alpha$ = 0.05 From my notes, I am told $\alpha = \pi(H_0)$ , where $\pi$ signifies the power function. The only thing I could think of that might link these together is the z-score formula. $$ Z_{0.05} = 1.65 $$ $$ 1.65 = \frac{\bar x - 1}{1} $$ However this doesn't make sense to me, as when I solve for $\bar x$ I get 2.65, which is greater than $\mu$ , and this region should be less than $\mu$ Am I supposed to derive the power function for $\mu$ myself?",['statistics']
2240579,Idea behind pattern seen in topology,"In topology, I have come across a ""pattern"" that involves a subsequence or subset of a sequence or set. For example, this definition of a second countable space uses: A topological space $T$ is second countable if there exists some countable collection $\mathcal{U} = \{U_i\}_{i=1}^{\infty}$ of open subsets of $T$ such that any open subset of $T$ can be written as a union of elements of some subfamily of $\mathcal{U}$. Another variant of that ""pattern"" can be found in: Let $\{x_n\}$ be a bounded sequence such that every convergent subsequence converges to $L$. Then $\lim_{n\to\infty}x_n = L.$ What is the idea behind that pattern of a subsequence/subset of sequence/set? I realize that the two examples are different, I am not saying that they are the same, but it feels to me that they share an important idea of "" a sub-thing of a thing does this or that "" in their construction, and it is that idea/thought process that I'd like to get at. As a bonus question: in which fields/sub-fields of maths is that idea more prevalent/used? Does it show up only in e.g (some branch of) topology, or is it also used in e.g. (some branch of) algebra?","['general-topology', 'real-analysis']"
2240588,"Fourier Series, Sturm-Liouville Problem - What is the connection that I'm missing?","Fourier Series So in my book we are talking about Fourier Series. $$f(x) = \frac{1}{2}a_0+\sum_{n=1}^\infty\left[a_n\sin{\left(\frac{n\pi x}{L}\right)}+b_n\cos{\left(\frac{n\pi x}{L}\right)}\right]$$ It says the represents ""fairly nice"" periodic functions of period $L$. Sturm Liouville Problem A sturm liouville problem is one where $$(p(x)y')'+q(x)y+\lambda w(x)y=0 \qquad p(x),w(x)>0 \qquad \text{on} \qquad x_0 \leq x \leq x_1$$ with Boundary Conditions that allow self-adjointness i.e. Dirichlet, Neumann, Singular POint, Periodic or Radiation. Solution of Sturm Liouville Problem When solving the SL problem, we normally look at  three different values for $\lambda$ ($0,>0,<0$), find the eigenvalues (which are all positive and real), find the eigenfunctions (which are all real) and so if I pick any eigenvalue and its respective eigenfunction, that is a solution to the SL problem (i.e. the Differential Equation with those eigenvalues substituted to lambda has a solution, the eigenfunction, that respects the Boundary Conditions). Connection between the two My book then briefly says that ""$\sin{\left(\frac{n\pi x}{L}\right)}$ and $\cos{\left(\frac{n\pi x}{L}\right)}$ are eigenfunctions of the SL problem $y''+\lambda y=0$ on $[-L,L]$ with periodic BCs. And that $$\left\{1, \sin{\left(\frac{n\pi x}{L}\right)}, \cos{\left(\frac{n\pi x}{L}\right)}\right\}$$ form an orthogonal basis for the space of $2L$ -periodic ""nice"" functions."" My trial So I tried, using $w(x)=1$, $q(x)=0$, $p(x)=1$, on $[-L,L]$ with $y(-L)=y(L)$ and $y'(-L)=y'(L)$ $\lambda =0$ gives $y=Ax+B$ and applying the conditions gives $A=0$. However doesn't tell us anything about B. $\lambda=-\mu^2$ ($\mu\neq 0$) gives $y=Ae^{\mu x}+Be^{-\mu x}$ and applying the conditions gives only the trivial solution $y\equiv 0$ $\lambda=\mu^2$ ($\mu\neq 0$) gives $y =A\sin{(\mu x)}+B\cos{(\mu x)}$ and applying the conditions gives$\mu=\frac{n\pi}{L}$ only. However I don't know how to continue to connect the two. I got another solution from the case $\lambda =0$, how do I unify everything? But in general my question is What is the connection between fourier series and SL problems? How can I show that sin and cos are eigenfunctions of that particular sturm liouville problem? And finally, if that is the case, what are the sturm-liouville's problems associated with sine fourier series and cosine fourier series?","['sturm-liouville', 'fourier-series', 'fourier-analysis', 'partial-differential-equations', 'ordinary-differential-equations']"
2240594,Ramsey type theorem for polygons on lattices,"It's not difficult to show that given a 2-coloring of the lattice $L:=\{1,2,3\} \times \{1,\dots,9\} \subseteq \mathbb Z^2$ we find a monochromatic rectangle in $L$. Generalizing, for any $r$-coloring on $\mathbb Z^2$ can we always find a lattice $L \subseteq \mathbb Z^2$ containing a given monochromatic polygon? How large is a minimal $L$?","['polygons', 'ramsey-theory', 'integer-lattices', 'coloring', 'discrete-mathematics']"
2240616,"If $f(a^+)$ and $f(a^-)$ exist, then $f$ is bounded.","Let $f:[0,1] \to \mathbb{R}$ be a function such that for every $a \in [0,1)$ and $b \in (0,1]$ the one-sided limits $$f(a^+)=\lim _{x\to a^+}f(x) \in \mathbb{R}$$ $$f(b^-)=\lim _{x \to b^-} f(x) \in \mathbb {R}$$ exist. A) Show that $f$ is bounded. B) Does $f$ necessarily achieve its maximum at some $x \in [0,1]$? C) Suppose further that $f$ is continuous at $0$ and $1$, and that $f(0) f(1)<0$. Prove that there exists  some point $p \in (0,1)$ such that $f(p^-)f(p^+) \leq 0$. Intuitively, I can see why part A is true, but I am not sure how to prove this formally. For part B, I think the answer is no, but I haven't yet come up with a counterexample. My initial thoughts on part C are to somehow apply the intermediate value theorem, but I am not sure if this is the correct approach or not.",['real-analysis']
2240619,Showing that $\hat \theta$ is a minimum variance unbiased estimator of $\theta$,"Let $X_1,X_2,\ldots,X_n$ be a random sample from a $\operatorname{Poisson}(\theta)$ distribution with probability function $$ P(X = x) = \frac {\theta^xe^{-\theta}}{x!} $$ Show that $\hat \theta$ is the minimum variance unbiased estimator of $\theta$ i.e. that is unbiased and attains the Cramerâ€“Rao bound. My attempt: Showing that $\hat \theta$ is unbiased is easy; $$ E[\hat \theta] = \theta $$ $$ \hat \theta = \bar X $$ $$\operatorname E[\bar X] = \operatorname E\left[ \frac{1}{n} \sum_{i=1}^n X_i \right] = \frac{1}{n} E\left[\sum_{i=1}^n X_i\right] = \frac{1}{n}n\theta = \theta $$ Now to show that the variance attains the Cramer-Rao Bound is what I'm having trouble with. $$\operatorname{Var}(\hat \theta) = \frac{1}{E[(\frac{d\ell(\theta)}{d\theta})^2]} $$ $$\operatorname{Var}(\hat \theta) = \frac{1}{E[(\frac{\sum_{i=0}^n(x_i)}{\theta} - n)^2]}  $$ And now I'm not sure how to expand this further. Is the square of a sum just itself?",['statistics']
2240622,Can someone please clarify this proof of the five-color theorem?,"I am having trouble following this proof of the five-color theorem: http://www.unco.edu/nhs/mathsci/facstaff/roberson/Docs/MATH%20695/5%20Color%20Theorem.pdf . (The proof is from pages 1-4.) In particular, I do not understand Case 2 of the inductive step. To give a little background info without following the link, I think the author is trying to show that the boundary of any planar graph can be 3-colored while its interior vertices can be 5-colored. He proves this statement is true by strong induction over the number of vertices. For Case 1 of the inductive step, he shows it is true for graphs with chords. For Case 2, he shows it is true if boundary nodes are connected to interior nodes. Here is the text of the confusing part of Case 2: This $G'$ has an outer boundary defined by the
  following $B' = (B\setminus\{v_0\}) \cup \{v_1, v_2, \dots, v_t\}$. We know by our second assumption that $|C(v_0)| \geq 3$,
  and that there must exist two colors $\gamma$ and $\delta$ in $C(v_0)$
  that are different from $\alpha$. Now we want to
  remove the colors $\gamma$ and $\delta$ from the color sets for
  each of the vertices $v_1, \dots, v_t$ since we know that $v_0$
  will have one of those two colors. Thus, we can
  think that if $C(v_i)$ was the original color sets for
  the vertices $v_1, \dots, v_t$, their new color sets will be
  of the form $C(v_i) \setminus \{\gamma, \delta\}$. The remaining vertices in $G'$
  that did not share a common edge with $v_0$ may
  maintain their original color sets in $G'$. Now $G'$
  satisfies all three of our assumptions, and is
  therefore 5-list colorable by induction. Then we can return to our graph $G$ and choose $v_0$ to be
  color $\gamma$ or $\delta$, a color different from $w$, and show that $G$ must also be 5-list colorable. Why are vertices in $G$ that did not share an edge with $v_0$ allowed to keep their color? We haven't proven the hypothesis for $G$, so what if they are colored with a color that isn't $\alpha$, $\beta$, $\delta$, or $\gamma$? Then adding $v_0$ back would mean $G$ has 4 colors on its boundary. If $w$ is colored $\gamma$ or $\delta$, and $v_0$ is added back, then wouldn't $w$, $v_0$, $x$, and $y$ be 4 different colors? What exactly is the color set of a vertex? Why can we simply say $v_1, \dots, v_t$ are different colors than $v_0$? Don't we have to prove that's possible? Why can't we also say $w$ is a different color than $v_0$? I'm simply left really, really confused by this proof, even after looking through the examples. I've searched online for another version, but this appears to be the only one. Can someone clarify the above points, or, ideally, reexplain Case 2?","['graph-theory', 'planar-graphs', 'discrete-mathematics']"
2240652,How to determine all possible values of $x$ to find congruency,How would I find all the possible integer values of $x$ for the following congruence (or any of this form): $3131x^{3131} + 2760x^{2761} \equiv 64$ (mod $93$),"['congruences', 'discrete-mathematics']"
2240698,Sampling four socks from $n$ distinct pairs of socks,"A drawer contains $n$ distinct pairs of socks. A sample of four socks is made, without replacement. Let $X$ denote the number of pairs of socks in the sample. What is the probability mass function of $X$? The variable $X$ can take on only the values $0$, $1$, and $2$, so I compute the probability that $X$ takes on each value. For $P(X = 0)$, all the socks have to come from different pairs, so it suffices to multiply the four probabilities, that each new chosen sock does not form a pair with any previously chosen sock.
$$
P(X=0)
= 1 
\cdot \frac{2n - 2}{2n - 1} 
\cdot \frac{2n - 4}{2n - 2} 
\cdot \frac{2n - 6}{2n - 3}
$$ For $P(X=1)$, I focus on a single pair. Say they have a particular color $c$. What is the probability that the sample contains the pair $c$? Let $Y_c$ be the number of  socks of color $c$ in the sample. Of course, $Y_c \leq 2$. The variable follows a hypergeometric distribution. Hence, the probability of getting a pair of color $c$ is
$$
P(Y_c = 2)
= \frac{\binom{2}{2} \binom{2n - 2}{4 - 2}}{\binom{2n}{4}}
= \frac{6}{n(2n-1)}
$$ The probability that there is at least one pair in the sample is obtained by multiplying by $n$. How can I find the probability that there is exactly one pair and the probability that there are exactly two pairs?","['probability', 'discrete-mathematics']"
2240712,"Functional ""Square Root"" of $1/(x+1)$","I've been dabbling in functional iteration lately, but I've run into a problem that's causing me a lot of grief.
First I tried to iterate the softplus function $f(x)=\ln(e^x+1)$, which wasn't hard. By a preexisting theorem, any function of the form $g(h(g^{-1}(x)))$ iterated $n$ times is given by $g(h^n(g^{-1}(x)))$, so the nth iterate of the softplus function is given by $f^n(ð‘¥)=\ln(e^x+n)$. I've been mostly focused on functional square roots (a half-iteration of a function), and in this case, the functional square root was $\ln(e^x+\frac{1}{2})$. Then I tried iterating a very similar function: $f(x)=-\ln(e^x+1)$. This proved to be much more difficult, because in order to put it in the form $g(h(g^{-1}(x)))$, I have to let $h(x)=\frac{1}{x+1}$. Then, to find the functional square root, I would have to find the functional square root of $h(x)$. So far, I haven't been able to do this, but I've convinced myself that the answer will contain imaginary exponents. Can somebody please tell me how to do this (or how to find out if it is possible or not)?","['function-and-relation-composition', 'functions']"
2240744,Prove that $U_k(n)$ is a subgroup of $U(n)$,"For each divisor $k\gt 1$ of $n$, let $U_k(n) = \{x \in U(n) ~|~ x\pmod {k} = 1\}$. Prove that $U_k(n)$ is a subgroup of $U(n)$ ($U(n)$ is the group formed by the positive integers less than $n$ that are coprime to $n$) My attempt : 1) $1\equiv 1 \pmod{k}$, so $e\in U_k(n)$ 2) $a,b \in U_k(n) \implies ab\equiv 1 \cdot 1 \equiv 1 \pmod{k}$, so $ab \in U_k(n)$ 3) Since $\gcd(a,n)=1$ and $k\mid n$, we have $\gcd(a,k)=1$, for all $a\in U(n)$. Also, since $a^{-1}\in U(n)$, we have $\gcd(a^{-1}, k) = 1$. I'm not sure how to proceed from here. Appreciate any help. Thanks! (I'm trying to show $a^{-1} \equiv 1 \pmod{k}$ at 3rd step )","['abstract-algebra', 'group-theory', 'elementary-number-theory']"
2240749,"Expected value question regarding bijections of $\{1,2,\ldots,n\}$","Context: this is just a problem I thought of for fun. Let $\Sigma_n$ be the symmetric group on $\{1,2,\ldots n\}$. We define a random variable $X$ on $\Sigma_n$ by: $$X(f)=\mbox{max}\{k\mid\forall j\leq k, f(j)\geq j\}.$$ In other words, $X(f)$ is the largest $k$ such that, in the graph of $f$, the points $(1,f(1))$, $(2,f(2))$, $\cdots$, $(k,f(k))$ all lie on or above the diagonal. My question is: What is $E[X]$? Is there even a ""nice"" way of finding or expressing it? If not, is there a way of estimating $E[X]$?","['combinatorics', 'probability']"
2240781,Proving that limit of dot product equals dot product of limit,"Suppose $\lim_{\mathbf{x} \to \mathbf{c}} \mathbf{f}(\mathbf{x})=\mathbf{L}$ and $\lim_{\mathbf{x} \to \mathbf{c}} \mathbf{g}(\mathbf{x})=\mathbf{K}$. I want to prove that $\lim_{\mathbf{x} \to \mathbf{c}} \mathbf{f}(\mathbf{x})\bullet \mathbf{g}(\mathbf{x})=\mathbf{L}\bullet \mathbf{K}$, where $\bullet$ denotes the Euclidean dot product. Let $\epsilon >0$. We know that $\exists \delta_1, \delta_2>0$ such that $\forall \mathbf{x} \in A : 0<\|\mathbf{x}-\mathbf{c}\|<\delta_1$ implies $\|\mathbf{f}(\mathbf{x})-\mathbf{L}\|<\epsilon$ and $0<\|\mathbf{x}-\mathbf{c}\|<\delta_2$ implies $\|\mathbf{g}(\mathbf{x})-\mathbf{K}\|<\epsilon$. Let $\delta=\min\{\delta_1, \delta_2\}$. We have $|\mathbf{f}(\mathbf{x})\bullet \mathbf{g}(\mathbf{x}) -\mathbf{L}\bullet \mathbf{K}|= |\mathbf{f}(\mathbf{x})\bullet \mathbf{g}(\mathbf{x}) -\mathbf{K} \bullet \mathbf{f}(\mathbf{x})+\mathbf{K} \bullet \mathbf{f}(\mathbf{x})-\mathbf{L}\bullet \mathbf{K}|=|\mathbf{f}(\mathbf{x})\bullet (\mathbf{g}(\mathbf{x})-\mathbf{K})+\mathbf{K}\bullet (\mathbf{f}(\mathbf{x})-\mathbf{L})|\leq |\mathbf{f}(\mathbf{x})\bullet (\mathbf{g}(\mathbf{x})-\mathbf{K})|+|\mathbf{K} \bullet (\mathbf{f}(\mathbf{x})-\mathbf{L})|$. The Cauchy-Schwartz inequality yields $|\mathbf{f}(\mathbf{x})\bullet \mathbf{g}(\mathbf{x}) -\mathbf{L}\bullet \mathbf{K}|\leq \|\mathbf{f}(\mathbf{x})\|\|\mathbf{g}(\mathbf{x})-\mathbf{K}\|+\|\mathbf{K}\|\|\mathbf{f}(\mathbf{x})-\mathbf{L}\|.$ If we let  $0<\|\mathbf{x} -\mathbf{c}\|<\delta$, I'll
just need an upper bound for $\|\mathbf{f}(\mathbf{x})\|$, but I can't find one. I'd appreciate help finishing the argument.","['real-analysis', 'limits']"
2240822,"Let $U=\operatorname{min}\{X,Y\}$ and $V=\operatorname{max}\{X,Y\}$. Show that $V-U$ is independent of $U$.","Let $X$ and $Y$ be exponentially distributed random variables with
  parameter $1$ and let $U=\operatorname{min}\{X,Y\}$ and
  $V=\operatorname{max}\{X,Y\}$. Show that $V-U$ is independent of $U$. We have shown that $U$ is distributed exponentially with parameter $2$. I am surprised to find that I don't actually know how to do this. I know of no other way than to show that $\mathbb{P}(U<x,V-U<y)=\mathbb{P}(U<x)\space\mathbb{P}(V-U<y)$ and I don't think I know how to compute the left hand side. Can we do $$\int^{\infty}_0f_V(v)\mathbb{P}(x>U>v-y)\operatorname{dv}=\int^{\infty}_0\left(\left(\int F_X(t)F_Y(t)\operatorname{dt}\right)\left(\int^x_{v-y}2e^{-2u}\operatorname{du}\right)\right)\operatorname{dv}?$$ As $F_V(v)=F_X(v)F_Y(v)$ where $F_X$ and $F_Y$ are the distribution functions of $X$ and $Y$ respectively and $\int^x_{v-y}2e^{-2u}\operatorname{du}=\mathbb{P}(v-y<U<x)$. I think I've seen this before but I really don't think this is what I'm meant to do, is this correct in general and is there a better way in this specific case? Any guidance would help me out a lot, thanks!","['independence', 'poisson-process', 'exponential-distribution', 'probability']"
2240831,How may we show that $\int_{0}^{1}{1-x\over 1+x}\cdot{2k+3+x^2\over 1+x^2}\cdot{\mathrm dx\over \ln x}=-\ln(2^k\pi)?$,"A simple closed form $$\int_{0}^{1}{1-x\over 1+x}\cdot{2k+3+x^2\over 1+x^2}\cdot{\mathrm dx\over \ln x}=-\ln(2^k\pi)\tag1$$
  Where $k$ is a real number Making an attempt: This integral is too difficult to even try to make an attempt. Anyway let's try $x=e^y\implies dx=e^ydy$, then $(1)$ becomes $$-\int_{0}^{\infty}{1-e^{-y}\over 1+e^{-y}}\cdot{2k+3+e^{-2y}\over 1+e^{-2y}}\cdot{e^{-y}\over y}\mathrm dy\tag2$$ Using hyperbolic identities $$-\int_{0}^{\infty}\tanh\left({y\over 2}\right)\cdot{2k+3+e^{-2y}\over 1+e^{-2y}}\cdot{e^{-y}\over y}\mathrm dy\tag3$$ $$-\int_{0}^{\infty}\tanh\left({y\over 2}\right)\cdot\left[(k+1)e^{2y}sech{y}+1\right]\cdot{e^{-y}\over y}\mathrm dy\tag4$$ Another try: $x=\tan y\implies dx=\sec^2y dy$, then $(1)$ becomes $$\int_{0}^{\pi/4}\tan\left({\pi\over 4}-y\right)\cdot{2k+2+\sec^2y\over \ln\tan y}\mathrm dy\tag5$$ Still going no where! How can we prove $(1)?$","['integration', 'calculus']"
2240832,What is an example of a genus 5 smooth projective curve?,"Recall that if $k$ is an algebraically closed field, then any degree $d$ plane curve $X$ will have arithmetic genus $g=(d-1)(d-2)/2$, by a simple calculation of $H^1(X,\mathscr{O}_X)$. This tells us that no smooth projective curve of genus $5$ can be embedded in $\mathbb{P}^2_k$. This is my thought process so far: if $i:X\hookrightarrow\mathbb{P}^n$ is a closed immersion (with $n\ge2$), then the short exact sequence $$0\to\mathscr{I}\to\mathscr{O}_{\mathbb{P}^n}\to i_*\mathscr{O}_X\to 0$$ gives and the fact that $H^1(\mathbb{P}^n,\mathscr{O}_{\mathbb{P}^n}) = H^2(\mathbb{P}^n,\mathscr{O}_{\mathbb{P}^n})=0$ gives us that $$H^1(X,\mathscr{O}_X)\cong H^1(\mathbb{P}^n,i_*\mathscr{O}_X)\cong H^2(\mathbb{P}^n,\mathscr{I})$$ and so, the problem of finding a curve with arithmetic genus $5$ reduces to finding an ideal sheaf $\mathscr{I}\subset\mathscr{O}_{\mathbb{P}^n}$ cutting out a curve, such that $\dim_k H^2(\mathbb{P}^n,\mathscr{O}_{\mathbb{P}^n})=5$. Is this the correct approach? If so, where should I go from here?","['algebraic-curves', 'algebraic-geometry']"
2240834,Why isn't $6$ necessarily a divisor of $\ \ \ \cdots 336$?,"I have to prove that if a given positive integer n ends with digits 336, then n has to be divisible by 2, by 4 and by 8, but its not necessarily divisible by 6. I know that a positive integer is divisible by 2 if the last digit is 0, 2, 4, 6, and 8. And because 4, 6, and are multiples of 2 they should also be divisible. However I can't find why it wouldn't be divisible by 6? Here's my proof so far for divisibility by 2: 10 divided by 2 has a remainder of 0.
So 10 â‰¡ 0 (mod 2). Then 10k â‰¡ 0
k â‰¡ 0 (mod 2) for k = 1, 2, 3, . . .. so
x â‰¡ a0 + a1 Â· 0 + a2 Â· 0 + a3 Â· 0 + a4 Â· 0 + Â· Â· Â· + am Â· 0
â‰¡ a0 (mod 2). Therefore x is divisible by 2 if and only if its last digit a0 is divisible by 2, which
happens if and only if the last digit is one of 0, 2, 4, 6, 8.
a0 is the digit in the one's place, a1 in the ten's place etc.","['discrete-mathematics', 'divisibility', 'decimal-expansion', 'elementary-number-theory']"
2240867,"Why does ""solvability"" for groups suggest something about the solution of polynomials?","I watched a few videos about the solvability of a general quintic in radicals and I'm somewhat confused about a few concepts. My main confusion lies in the following definition; $\textbf{Def}:$ Solvable group A group $G$ is said to be solvable if it has a subnormal series
  $$ G_0 \triangleleft G_{1} \triangleleft \cdots \triangleleft G_{n-1} \triangleleft G_n$$
  with $G_n = G$ and $G_0 = \left\lbrace e\right\rbrace$ such that each successive quotient group $G_i/G_{i-1}$ is abelian. Why is the notion of ""solvability"" attached to this property? More precisely, if I have a polynomial $p(x) \in F[x]$ with $F$ a field and Galois Group $\operatorname{Gal}(p)$, in an ""explain it like I'm stupid""-sense, what is it about $\operatorname{Gal}(p)$ having these seemingly arbitrary properties that forces $p$ to have solutions in radicals?","['galois-theory', 'polynomials', 'abstract-algebra', 'solvable-groups', 'group-theory']"
2240874,What is a tower?,"I am reading James Dugundji's Topology from 1966. In it he describes a tower. But I do not understand completely. Why is it called a tower? It seems as though 2.2.b is recursive because the union of any well ordered family of sets will create another well ordered family of sets in $F$; and with any well ordered family of sets, their union is in $F$. Does that mean towers are infinite? Also what is the significance of 2.2.c? If anyone can shed some light on this I will appreciate it.","['general-topology', 'elementary-set-theory']"
2240898,Stabilty of leapfrog scheme applied to wave equation,"The leapfrog scheme applied to the equation:
$$\frac{dz}{dt} =  \lambda z$$
gives
$$\frac{z^{n+1} - z^{n-1}}{2\Delta t} = \lambda z^n.$$
The region of absolute stability is calculated and it is the pure imaginary interval $-i\leq \lambda \Delta t\leq i$. From that how can I conclude that what are the stability restrictions of the leapfrog scheme applied to the diffusion equation with periodic boundary conditions?","['stability-in-odes', 'numerical-methods', 'ordinary-differential-equations']"
2240924,Countability of $\{S\subseteq \Bbb Q:\;\text{S is finite}\}$,"I was given the following problem on a test and provided the proof below. My professor says there is an error in my logic (which I'll identify later) but I respectfully disagree and am looking for a second opinion. I'm asked to consider the following set $A$ and prove that $|A|=|\Bbb Q|$. $$A=\{S\subseteq \Bbb Q:\;\text{S is finite}\}$$ To show that $|A|\ge|\Bbb Q|$, I said consider the following subset $B$ of $A$: $$B=\{S\subseteq \Bbb Q: |S|=1\}$$ The set $B$ consists of elements which are sets of cardinality $1$. This means $\forall\;x\in \Bbb Q$, $\{x\}\in B$. Since $B\subseteq A$, $|A|\ge|\Bbb Q|$. She gave credit for this part, but the next was where we disagreed. To show $|A|\not>|\Bbb Q|$, I offered the following: Consider a finite subset of $\Bbb Q$ with cardinality $\le n$. This subset is comparable to an ordered pair in $\Bbb Q^n$. E.g. if $n=4$, we have the following: $$\{a,b,c,d\}\text{ is comparable to } (a,b,c,d) \text{ in }\Bbb Q^4$$ For subsets of cardinality $p$ less than four, I said one could simply repeat the last entry $n-p$ times since sets require unique elements but ordered pairs do not. $$\{a,b\}\text{ is comparable to }(a,b,b,b)\text{ in }\Bbb Q^4$$ In each case , the ordered pair in $\Bbb Q^n$ is unique, implying injectivity. Thus, my solution simply found an injection from $A$ to $\Bbb Q^n$ and utilised the fact that the Cartesian product of countable sets is countable to show that $|A|\le|\Bbb Q|\implies|A|=|\Bbb Q|$. However, my professor claimed that this does not necessarily hold for sufficiently large $n$. She compared my work to the false proof that the sum of naturals is finite because each time you add the next natural to the previous sum, you're adding a finite number to a finite sum. I disagree because no matter how large $n$, this is still comparable to $\Bbb Q^n$. I normally would never have the confidence to disagree with her as she's an extremely good professor, but I feel like my approach is valid and want to see if anyone else does.","['cardinals', 'elementary-set-theory', 'proof-verification']"
2240927,Random walk with 3 cases.,"Let the walking start be at $x=0$. With probability $p_1$ new $x=x+1$, with probability $p_2$: $x=x-1$ and with probability $1-p_1-p_2 \geq 0$ walking ends. The question is what is the probability of ending on point $n$. I've computed it numerically and getting something close to normal distribution with peak at zero, but with different dispersion on sides of $x=0$. How to get it analytically? The provided answer seems ok, but I hope I can find some smooth function for it. Maybe with another type of solution. Upd: my idea of solution. $$P_{n+1} (x) = p_1 P_{n} (x-\delta x) + p_2 P_{n} (x + \delta x)$$
$$P_{n+1} (x) - P_{n} (x) = p_1 [P_n(x-\delta x) - P_n(x)] + p_2 [P_n(x+\delta x) - P_n(x)] - q\cdot P_{n}(x)$$
Dividing by $\delta n$ and $\delta x$ getting something like:
$$\frac{\partial P(n,x)}{\partial n}= \frac{\delta x}{\delta n}\left[ (p_2 + p_1) \frac{\partial P(n,x)}{\partial x} - (1 - p_2 - p_1)\cdot P(n,x)\right]$$
Solving it leads to something like this:
$$P(n,x) = Ae^{\frac{-q x}{p_1 + p_2}}(n + \frac{x}{p_1 + p_2})$$
I'm not sure yet  if it means something.","['random-walk', 'probability']"
2240951,What is $x$ in the formula?,"What is $x$ (assume it's integer) in $512p+ 1 = x^3$, where $p$ is a prime number. Attempt: $$a^3 - b^3 = (a-b) (a^2 + ab+b^2) \Longrightarrow 512p = x^3 -1 = (x-1)(x^2+x+1).$$ Here I got stuck. Am I suppose to plug in $p$ and try it one by one? What about $16p + 1 = x^3$??","['number-theory', 'prime-numbers']"
2240983,"If $(A-B)^2=AB$, prove that $\det(AB-BA)=0$.","Let $A,B\in M_{n}(\mathbb{Q})$. If $(A-B)^2=AB$, prove that $\det(AB-BA)=0$. I considered the function $f:\mathbb{Q}\rightarrow \mathbb{Q}$, $f(x)=\det(A^2+B^2-BA-xAB)$ and I obtained that:
$$f(0)=\det(A^2+B^2-BA)=\det(2AB)=2^n\det(AB)$$
$$f(1)=\det(A^2+B^2-BA-AB)=\det((A-B)^2)=\det(AB)$$
$$f(2)=\det(A^2+B^2-BA-2AB)=\det((A-B)^2-AB)=\det(AB-AB)=0$$ I don't have any other idea.","['matrices', 'linear-algebra', 'determinant']"
2241030,distribution of one normal RV's rank within another normal distribution,"This is a question originating from some research I'm doing on the discovery of correlations in a mass of time-series data. Suppose I have a random variable $X$ that is normally distributed with mean $\mu_X$ and variance $\sigma^2_X$.  In addition, I have i.i.d. random variables $Y_i$ ($1 \leq i \leq n$) that are also normally distributed, but with mean $\mu_Y$ and variance $\sigma^2_Y$.  Typically, $\mu_X > \mu_Y$, and we can assume that's the case in this question. I'm interested in the distribution of $X$'s rank within the $Y_i$â€”effectively, the number of $Y_i$ that are greater than $X$.  Is there a straightforward way of obtaining even an approximate expression for this? There is this question , but I'm not sure that's really sufficiently close to the same question.  For one thing, it concerns only two samples, one drawn from each distribution, and for another, it gives only the probability that $X > Y$.  This is of limited use in determining the distribution of $X$'s rank, since the event $X > Y_i$ is not in general independent of the event $X > Y_j$.  However, if someone can articulate why an answer to that question will give me the answer to mine (or if there is another, more related question and answer), I'd be satisfied with that.","['probability', 'normal-distribution', 'probability-distributions']"
2241040,"What is the symbolic form of ""there does not exist a largest natural number ""","Other students in office hour said this is the correct form
$(\forall x)(\exists y)(y>x)$
{ for all x natural number, there exists y such that y is greater than x } But
""there does not exist a largest natural number ""
$\neg(\exists x)(x\text{ largest natural number})$ Am I even close ?","['proof-writing', 'discrete-mathematics']"
2241059,Group Theory and Divisors,"Here is the problem I'm working at: Find a divisor $d$ of $6! = 720$ such that $S_6$ does not have a subgroup of order $d$. Initial Approach : 
So I factored the number $720$ and here are the divisors that I came up with: $1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 15, 16, 18, 20, 24, 30, 36, 40, 45, 48, 60, 72, 80, 90, 120, 144, 180, 240, 360, 720$ So there are a total of 30 divisors for the number $720$. I believe it would be helpful to know how many total subgroups are there in $S_6$. I did find this link, not sure if it would help out or not. Update So after doing some further research, I found out that $S_6$ has a total of $1455$ subgroups, but a proof is not given as to why this is true. But why is this true? Well the divisors of $1455$ are given as follows: $1, 3, 5, 15, 97, 291, 485, 1455$","['abstract-algebra', 'group-theory']"
2241082,Sample Space as the image of a Random Variable?,"My understanding is that a random variable $X$ is a function that goes from a sample space $\Omega$ to a measurable space $E$, where $\Omega$ is part of a probability space (along with a sigma-algebra $F$ and a measurable function $\mu$) and where $E$ is tipically $\mathbb R$. A sample space is a set of all the possible  ""outcomes"" that may arise in an experiment, $F$ could be thought of as a set of ""events"" (which are, in turn, sets of outcomes), and $\mu$ is a measure used to assign probabilities to events in $F$. I am not a mathematician , and I only have very superficial knowledge of Probability Theory and Measure Theory. Nonetheless, I am interested on having a general intuition of the concepts I've mentioned above, and to learn how to correctly use the vocabulary of Probability and Statistics. Thus, I am concerned about the way the terms ""Outcome"" and ""Sample Space"" seem to be used in different places; particularly when it's implied that the codomain or the image of $X$ is the Sample Space of $X$ , and/or that $X$ ""takes the values of"" the ""outcomes"" (which I believe are both wrong given the definitions above). Some examples include: Wikipedia's article on ""Random Variates"": AÂ random variateÂ is a particular outcome of aÂ random variable Reading ahead it's clear what they mean: that a Random Variate is a particular value that a r.v. can take. Thus, that sentence says that an ""outcome"" is a possible value for a r.v., and not a value where the r.v., as a function, is evaluated. An answer at Cross Validated, on the nature of ""Sample"" and ""Outcome"": So the Sample Space will be ""{Heads, Tails}"", which will be the domain of the random variable, while the ""outcome space"", its range, will beÂ {5,17} Since the ""outcome space"" is the range of a r.v., then ""outcomes"" are elements of the range and not of the domain, according to his definition. Wikipedia's article on PDF's : InÂ probability theory, aÂ probability density functionÂ (PDF), orÂ densityÂ of aÂ continuous random variable, is aÂ function, whose value at any given sample (or point) in theÂ sample spaceÂ (the set of possible values taken by the random variable) can be interpreted as [â€¦] I always thought intuitively that a PDF helps in solving problems like finding the probability that $ X \le k $, by making integrals from minus infinity to k. Thus, the domain of a PDF is the image of X, and not the domain of X, right? The one that confused me the most (although I can't find it now) was one that said something along the lines of ""X is a discrete r.v. if its sample space is discrete"". I believe that's totally wrong if we define the sample space of X as its domain! So my conclusion is that it's extremely common to find the terms ""sample space"" and ""outcome"" used to refer to the image of a random variable and its possible values. Nonetheless, that usage is fundamentally different from the one used in more ""formal"" treatments of probability theory, and one must be always alert as to what definition is being used . So my questions are: Is my conclusion right, or am I missing something? Is it possible to define a r.v. where both its domain and its image are the same sample space? I'm unsure if that even makes sense, but that may make it acceptable to say things like the ones I've cited. I'm specially interested in that if $\Omega$ and $E$ can both be $\mathbb R$?! Is it possible to make a probability space ""around"" $E$ (the codomain of X)? So that $E$ is also a Sample Space? Thanks!","['probability-theory', 'probability', 'random-variables']"
2241119,L'Hospital's rule help,"I tried using L'Hospital's rule to find the limit as $x$ tends to $0$ for the following function: $$f(x) = \frac{(1 - \cos x)^{1.5}}{x - \sin x}$$
I tried differentiating the top and the bottom and I can do it many times but it still gives the denominator with zero meaning I have to differentiate again and again (mainly because a  $(1 - \cos x)^{0.5}$  always manages to find its way into the numerator.) Is there a better way of solving this limit question?",['limits']
2241213,Question about application of dominated convergence theorem to random variables.,"Prove or give a counter-example to the following statement. It is impossible to construct a sequence of random variables $\{X_n, n â‰¥ 1\}$ and a random variable $X_\infty$ on the
same probability space such that the following are all true simultaneously: â€¢ With probability 1, $X_\infty$ is a strictly positive integer. â€¢ $E[X_\infty] = \infty.$ â€¢ For all $n\ge 1$, w.p.1, $X_n$ is an integer. â€¢ $E[|X_n|] < \infty$ for all $n \ge 1$. â€¢ $E[X_n] = 1$ for all $n \ge 1$. â€¢ $\{X_n, n \ge 1\}$ converges a.s. to $X_\infty$. I tend to prove it by using dominated convergence theorem to show $E[X_n]=1\Rightarrow E[X_\infty]<\infty$ for a contradiction, but I am wondering what dominated function I should use.","['real-analysis', 'probability', 'measure-theory', 'probability-theory']"
2241221,Orthonormal frame bundle,"Why does the orthonormal frame bundle have dimension $\frac{n(n+1)}{2}$, and why is the isometry group a submanifold of the orthonormal frame bundle? Consider a complete manifold $(M,g)$. Here the orthonormal frame bundle is the set of $(p,e_1, \dotsb, e_n)$, where $e_1, \dotsb, e_n$ forms an orthonormal basis for $T_pM$. Why is the frame bundle a manifold of dimension  $\frac{n(n+1)}{2}$?","['riemannian-geometry', 'differential-geometry']"
2241247,"In linear algebra, why is it that linear transformation is orthogonal if it preserves the length of vectors?",How are orthogonality and preserving length of a linear transformation even relating? A linear transformation can also be orthogonal even if it doesn't preserve the length of vector.,"['matrices', 'orthogonality', 'linear-algebra', 'linear-transformations']"
2241294,Questions on Convergence of an Infinite series,"If the sequence of partial sums of an infinite series $$\sum_{n=1}^âˆž a_n$$ is bounded, show that $$\sum_{n=1}^âˆž a_ne^{-nt}$$ is convergent for $t>0$ Request: Actually I don't need a direct answer, I'm studying infinite series since the last couple of days. So I don't fully understand this thing. That's why I want to understand the process to solve this type of problems. Thank you.","['real-analysis', 'sequences-and-series', 'problem-solving']"
2241410,Range of $\operatorname{arccot}(x)$,"Why don't we choose range of $\operatorname{arccot}(x)$ to be $\left(\frac{-\pi}{2},\frac{\pi}{2}\right]-\{0\}$ instead of $(0,\pi)$ so that it becomes little easier to work with arctan and arccot if they have similar range.","['trigonometry', 'inverse-function', 'inverse']"
2241494,Let a general term $T_n$ be defined as $T_n =\left(\frac{1\cdot 2\cdot 3 \cdot 4 \cdots n}{1 \cdot 3 \cdot 5 \cdot 7 \cdots (2n+1)}\right)^2$,"Let a general term $T_n$ be defined as $$T_n =\left(\frac{1\cdot 2\cdot 3 \cdot 4 \cdots n}{1 \cdot 3 \cdot 5 \cdot 7 \cdots (2n+1)}\right)^2$$ Then prove that 
$\lim_{n\to\infty}(T_1 + T_2 +\cdots+T_n) \lt  \frac{4}{27}.$ I tried  finding pattern between terms ..
$T_1=\frac{1}{9} ,   \frac{T_2}{T_1}=(\frac{2}{5})^2,   \frac{T_3}{T_2}=(\frac{3}{7})^2$
 but could not think more of how to get a bound on the series.
Any help is appreciated.","['sequences-and-series', 'limits']"
2241534,Probability of finding missing cards,"I'm thinking about such problem. Let it be 108 different cards to collect. They come up in a 4-cards packages and we can assume that all 4 cards in the package are different, but we can have some of the cards to be the same in different packages. We can also assume all cards are equally likely to be in a package. Now, suppose you have collected 104 cards and you are lacking only four. What is the smallest number of packages you have to buy to have a probability of collecting all remaining four cards greater than 50%?","['combinatorics', 'probability', 'discrete-mathematics']"
2241536,What is Cartesian product for two empty sets.,If there are two sets $A$ and $B$ and both are null sets(or empty sets). What is $A\times B$ ? Is it also a null set?,['elementary-set-theory']
2241561,Questions about the proof of Chen's $\pi_1$-de Rham theorem in Hain's Hodge Structure on $\pi_1$ paper,"I read a proof of Chen's $\pi_1$-de Rham theorem in Hain's paper The Geometry of the Mixed Hodge Structure on the Fundamental Group . The proof is very elegant, but there are a few (hopefully trivial) things near the end that are confusing me. Let me recall some notation and details in the proof. Let $M$ be a smooth manifold and $x\in M$ a basepoint. Let $G=\pi_1 (M,x)$. We denote the vector space of of iterated integrals on $M$ of length (number of differentials in the integrand) less than or equal to an integer $s$ by $B_s (M)$, and the vector subspace of those that are homotopy functionals by $H^0 (B_s (M),x) = H^0 (B_s (M))$ (all of this notation comes from the bar construction ). Let $J$ be the augmentation ideal of the group ring $\mathbb{Z}[G]$. Chen's theorem asserts that for every $s\geq 0$ the integration map $$H^0 (B_s (M)) \to \text{Hom}_{\mathbb{Z}} (\mathbb{Z}[G]/J^{s+1}, \mathbb{R}), \quad [\omega_1 \vert \dots \vert \omega_r]\mapsto \left(\gamma\mapsto \int_\gamma \omega_1\dots\omega_r \right)$$ is an isomorphism. (This can be interpreted as giving a canonical isomorphism between Betti and de Rham Tannakian fundamental groups after base change). Let $R$ be a ring and $V = R[G]/J^{s+1}$. Assuming $G$ is finitely generated, $V$ is finite-dimensional. Hain shows that right translation on $V$ is a unipotent representation of $G$. We have a filtration of subspaces $$V\supseteq J/J^{s+1}\supseteq J^2/J^{s+1}\supseteq \dots \supseteq J^s/J^{s+1}\supseteq 0, \quad (*)$$ and $G$ acts trivially on the graded quotients $J^t/J^{t+1}$. We form a flat line bundle $E\to M$ where $E=(V\times \tilde{M})/G$, and since $G$ stabilises $(*)$, this bundle inherits a filtration by flat subbundles $$E\supseteq E^1\supseteq E^2 \supseteq \dots \supseteq E^s \supseteq 0,$$ with the fiber of $E^t$ equal to $J^t/J^{s+1}$. Hain shows that each of these flat connections can be trivialised. Now comes the part I am confused about. Define $\text{End}_J (V)$ to be the Lie algebra of endomorphisms of $V$ that preserve the flag $(*)$. There are two confusing things: Hain claims that every element of $\text{Hom}_J (V)$ satisfies $A^{s+1}=0$. I don't see why this is the case - for example, why is the identity map not in $\text{End}_J (V)$? Secondly, parallel transport $T$ of the connection on $E$ is shown to be an element of $H^0(B_s (M))\otimes \mathbb{R}[G]/J^{s+1}$. Then it is claimed that integration $\gamma\mapsto T(\gamma)$ (parallel transport of the connection along $\gamma$) induces the identity map on $\mathbb{R}[G]/J^{s+1}$. I really don't understand where this step came from, and would be grateful if anyone can shed some light on this. Many thanks!","['algebraic-geometry', 'integration', 'fundamental-groups', 'algebraic-topology', 'hodge-theory']"
2241577,"In a $10$-member family, what is the probability that the birthdays of the members include all seven days of the week?","Is my solution for the following textbook problem correct? In a 10-member family, what is the probability that the birthdays of the members include all seven days of the week? My solution: All possible combinations are equal to $7^{10}$, which is akin to the problem of distributing $10$ different objects into 10 distinct boxes with repetitive objects allowed. Now, we select $7$ objects (i.e., people) ${10 \choose 7}$, put them in the boxes (i.e., days) so that we have at least one birthday on each day. Accounting for  internal permutation, we have ${10 \choose 7}\cdot7!$ Three objects are left. These could be put in the same box or in different boxes. We break down the possibilities: All three in different boxes. We have $7$ choices for the first object, $6$ for the seven and $5$ for the third. In other words,  ${7 \choose 1}\cdot {6 \choose 1}\cdot {5 \choose 1}$. Now, we have three $2$-member boxes each having a $2!$ internal permutation. Hence, we have $$\frac{{7 \choose 1}\cdot {6 \choose 1}\cdot {5 \choose 1}}{2!\cdot2!\cdot2!}$$ Two  in the same box. We choose a pair put them in any of the seven boxes and there's six choices for the remaining object. Again, factoring in repeated cases, we get $$\frac{{3 \choose 2}\cdot {7 \choose 1}\cdot {6 \choose 1}}{3!\cdot2!}$$ All three one the same  day. This is easy: $$ \frac{{7 \choose 1}}{4!}$$ Now, employing the rule of sum (since the above cases are mutually exclusive), we compute the probability $$ \frac {{10 \choose 7} \cdot 7! \cdot  [\frac{{7 \choose 1}\cdot {6 \choose 1}\cdot {5 \choose 1}}{2!\cdot2!\cdot2!} + \frac{{3 \choose 2}\cdot {7 \choose 1}\cdot {6 \choose 1}}{3!\cdot2!} +\frac{{7 \choose 1}}{4!}]} {7^{10}} $$
   which is almost $0.08$. Also, can you think of a better, more systematic (or perhaps general) solution for the above problem? I suspect there's one and that this could be done through computing the complement cases. I have been trying to no avail. I can't eliminate repetitive distributions. Update : Thanks for the replies gentlemen. All were very helpful. Case closed.","['combinatorics', 'recreational-mathematics', 'probability', 'discrete-mathematics']"
2241580,Calculate the area of a pixel on a sphere,"Given an photographical image of a sphere, i.e. an circle with radius $r$ quantized into uniform, square pixels, how can one calculate the equivalent area of the sphere covered by each pixel? I'm assuming that the projection is parallel. Example: 
Let a sphere of radius $R = 1$ be projected to a circle with a radius of $r = 100\,\mathrm{px}$, where the center of the sphere is the center of the middle pixel $(50, 50)$ in the image. Basically I'm interested in the reverse projection from the pixel space to the sphere. I guess I have to cast rays from the corners of the pixel onto the sphere and from those four points get the area of the sphere in the section that is encased in the four points.","['spheres', 'differential-geometry', 'projective-geometry', 'geometry']"
2241608,Solving $x^{3} - 2 = 0$ and the field $\mathbb{Q}(\sqrt[3]{2})$,"Let's start with a simple polynomial $f(x) = x^{3} - 2 \in \mathbb{Q}[x]$. It is known that $f$ is irreducible in $\mathbb{Q}[x]$ and hence without any further information (i.e. working in field $\mathbb{Q}$ and ring $\mathbb{Q}[x]$) we can not distinguish the $3$ roots of $f$. The distinction between roots is only possible once we have the splitting field of $f$ available . Now consider the quotient $\mathbb{Q}[x]/(f(x))$ which is a field (because $f$ is irreducible) and this field contains a member $x + (f(x))$ which is a root of $f(x)$. Moreover this field is isomorphic to $\mathbb{Q}(\sqrt[3]{2})\subset \mathbb{R}$. Why is this extension field obtained using quotient by $(f(x))$ give us the real root $\sqrt[3]{2}$ and not one of the other two roots? I mean while taking the quotient with $f$ we are just getting an extension field which depends on $\mathbb{Q}$ and $f(x)$ and we don't know for sure which of the three roots it will contain. The same question however does not apply to all irreducible polynomials. Thus if we take $f(x) = x^{4} + x^{3} + x^{2} + x + 1$ (or more simply $x^{2} + 1$) then $\mathbb{Q}[x]/(f(x))$ contains all the roots of this polynomial. Update : For the simple polynomial $x^{2} + 1$ I can show that both of its roots are in the extension field $\mathbb{Q}[x] / (x^{2} + 1)$. With some reasonable effort we can show the same for $f(x) = x^{4} + x^{3} + x^{2} + x + 1$. I think we can also show that for $f(x) = x^{3} - 2$ the field $\mathbb{Q}[x]/(f(x))$ has only one root (I have not yet proved this for myself but I am sure I can). My real question is that even if we assume that this field has only one of the roots how do I know that this particular root is special and other two roots are more of a similar nature (ie this one is real and others are complex conjugates)? It appears I have been misunderstood so I add more formalism and details. Let $K$ be the splitting field of $x^{3} - 2 \in \mathbb{Q}[x]$. So $K$ has three elements $a, b, c$ each of which is a cube root of $2$ in $K$. Also we have $$K \supset \mathbb{Q}[x]/(x^{3} - 2) = L \supset \mathbb{Q}$$ My point is that the roots $a, b, c \in K$ are not indistinguishable from each other. Precisely we have one of these (say $a$) in $L$ and rest two ($b, c$) in $K$. Also there is automorphism $\sigma$ of $K$ which fixes $\mathbb{Q}$ and $\sigma(b) = c$. But there is no automorphism of $K$ which fixes $\mathbb{Q}$ and sends $a$ to $b$ (or $c$). I know this only by working in field $\mathbb{C}$. How do I know this without working in $\mathbb{C}$? Thanks to DonAntonio, I understood the flaw in my reasoning. Also sorry to other people who answered for bearing with my nonsense comments. What I gather from the overall discussion is this: Summary : The cubic $x^{3} - 2$ has three roots and they all lie in splitting field $K$. The intermediate field $L = \mathbb{Q}[x]/(x^{3} - 2)$ contains only one of the roots (see last part of egreg's answer as to why $L$ can't have all the roots) and it is not possible to determine via algebra as to which of $a, b, c$ lie in $L$. Thus $a, b, c$ are indeed indistinguishable and any one (say $a$) can be supposed to lie in $L$ and the rest lie in $K$. And we can then prove that $K = L(b) = L(c)$ and $L = \mathbb{Q}(a)$ and $L$ is of degree $3$ over $\mathbb{Q}$ and $K$ is of degree $2$ over $L$. I think it is now easy to get the Galois group and show that it is indeed $S_{3}$.",['abstract-algebra']
2241655,Maximum entropy principle for Poisson distribution,"I know that certain probability distributions may be derived from the requirement that entropy be maximal along with a constraint such as fixed variance. In the case of fixed variance, for example, one finds the normal distribution . In particular, the maximisation is over the set of all (!) continuous PDFs with that fixed variance. Now my question is, is there a similarly general derivation of the Poisson distribution as a maximum entropy distribution? E.g. fixing that mean and variance are equal and maximising entropy? I have found a couple of articles but they always seem to prove maximality on a restricted set of discrete PDFs. Is it because there is no more general maximum entropy principle for the Poisson distribution? If so, is it because the discrete case is simply more complex than the continuous one?","['entropy', 'probability']"
2241665,Connected spaces that remain connected after removing finitely many points,Suppose that $X$ is a connected compact Hausdorff space with the property that for every finite set $F\subseteq X$ the space $X\setminus F$ is connected. Can we conclude that the covering dimension of $X$ is at least 2? Note: I do not assume that $X$ is path-connected. This question is somewhat dual to the classical problem of Menger whether adjoining finitely many points to a zero-dimensional space keeps the dimension 0.,"['general-topology', 'dimension-theory-analysis', 'compactness', 'connectedness']"
2241690,Alpha-Trimmed Mean and Median,"I'm currently working on a proof for my stochastics course, and I am a bit stuck. I tried to find some hints or help online, but so far I haven't found anything. So I figured I'd see if someone could help me here. So the problem is the following: We have to use a proof by cases, one with an even number of observations and one with an odd number of observations in our sample, that the $\alpha$-truncated mean converges to the median, as $\alpha \rightarrow \frac{1}{2}$. As the course is in German, and I'm not sure about the English term for this mean, I'll also leave the definition here. It also contains the problem I have with this proof: $$x_{t,\alpha} := \frac{1}{n-2k}\sum^{n-k}_{j=k+1}x_{[j]} $$
with $0 < \alpha < 1/2$ and $k:= \lfloor n\alpha \rfloor$, and where our sample $(x_{[1]},\dots,x_{[n]})$ is already ordered. Now, I am just looking for a starting point, not a complete solution, after all I would really love to figure it out by myself - at least partially. I'm just not sure how to deal with the floor function and the change in the size of the sum. Any good hints or references? Thanks in advance!","['descriptive-statistics', 'statistics', 'median', 'ceiling-and-floor-functions']"
2241698,Closed form expressions for harmonic sums,"It is well known that there are deep connections between harmonic sums (discrete infinite sums that involve generalized harmonic numbers) and poly-logarithms. Bearing this in mind we have calculated the following sum:
\begin{equation}
S_a(t) := \sum\limits_{m=1 \vee a} H_m \cdot \frac{t^{m+1-a}}{m+1-a}
\end{equation}
where $t\in (-1,1)$ and $a \in {\mathbb Z}$. The result reads:
\begin{eqnarray}
S_a(t) = 
\left\{
\begin{array}{lll}
\frac{1}{2} [\log(1-t)]^2 + \sum\limits_{j=1}^{a-1} \frac{1}{j \cdot t^j} \left( \sum\limits_{m=1}^j \frac{t^m}{m} + (1-t^j) \log(1-t) \right) + Li_2(t) 1_{a\ge 1} & \mbox{if $a \ge 0$} \\
\frac{1}{2} [\log(1-t)]^2 -\sum\limits_{j=1}^{|a|} \frac{1}{j } \left( \sum\limits_{m=1}^j \frac{t^m}{m} + (1-t^j) \log(1-t) \right) & \mbox{if $a < 0$} \\
\end{array}
\right.
\end{eqnarray} 
Unfortunately it took me a lot of time to derive and thoroughly check the result even though all the calculations are at elementary level. It is always helpful to use Mathematica. Indeed for particular values of $a$ Mathematica ""after long thinking"" comes up with solutions however from that it is hard to find the generic result as given above. Besides in more complicated cases Mathematica just fails. In view of the above my question is the following. Can we prove that every infinite sum whose coefficients represent a rational function in $m$ and in addition involve products of positive powers of generalized harmonic numbers, that such a sum is always always given in closed form by means of elementary functions and poly-logarithms? If this is not the case can we give a counterexample?","['harmonic-numbers', 'sequences-and-series', 'discrete-mathematics']"
2241699,How can I tell whether this set is closed or open?,"the question I'm having trouble with is this: $$A:=\bigcup_{n=1}^{\infty}\left({\left[\frac{1}{n+1},\frac{1}{n}\right) \times \left(0,n\right)}\right).$$ In the Euclidean space $\mathbb{R}^2$, is the subset $A$ either closed or open? I drew a picture in $\mathbb{R}^2$ and I really think it's open, but I can't come up with an elaborate way to describe why. Any help would be appreciated. Thanks.",['general-topology']
2241714,On the derivative of the matrix exponential,"I have the following set up, for column vectors $\alpha,\beta$ and square matrix $A$ I am looking at the derivative $\frac{\partial\alpha^T e^{Ax}\beta}{\partial x}=\alpha^T Ae^{Ax}\beta=\alpha^T e^{Ax}A\beta$, where $e^{Ax}$ represents the matrix exponential. Can I write this in terms of the original function? So, $$\frac{\partial\alpha^T e^{Ax}\beta}{\partial x}=\alpha^T Ae^{Ax}\beta=X\alpha^T e^{Ax}\beta$$ for some $X$? Under what circumstances is this possible? Thank you!","['derivatives', 'matrices', 'matrix-calculus', 'matrix-exponential', 'linear-algebra']"
2241718,Which Maps are Box-Continuous?,"The box topology on the set $\mathbb R^\infty$ is defined to have sub-basis of sets $U_1 \times U_2 \times \ldots$ for each $U_i \subset \mathbb R$ open. Observe this is different from the product topology which also demands all but finitely many $U_i = \mathbb R$. The box topology is known to be badly behaved. For example the reasonable-looking function $x \mapsto (x,x,\ldots)$ is not continuous when the codomain carries the box topology. On the other hand functions like $x \mapsto (x,1,1,\ldots)$ are in fact box-continuous. There is an easy rule to check if any function $F \colon \mathbb R\to \mathbb R^\infty$ is product-continuous. Simply write $F(x) = (f_1(x),f_2(x),\ldots)$ then check all $f_i \colon \mathbb R \to \mathbb R$ are continuous. This condition is necessary and sufficient. Is there a simple characterisation of exactly which functions are box-continuous? Failing such a characterisation, could someone provide me with a large family of box-continuous functions? That family has to at least include all functions like $G(x) =(g_1(x),g_2(x), \ldots, g_n(x), a_1,a_2,\ldots)$ for $g_i\colon \mathbb R \to \mathbb R$ continuous and $a_i$ constants.","['continuity', 'product-space', 'general-topology', 'box-topology']"
2241720,"Integrate $\int \arcsin\left(\frac{x+2}{x^2+4x+13}\right)\,\mathrm dx$","$\def\d{\mathrm{d}}$Any hint on how to compute this integration?$$\int \arcsin\left(\frac{x+2}{x^2+4x+13}\right)\,\d x$$ This is what I have done:$$
\int \arcsin\left(\frac{x+2}{x^2+4x+13}\right)\,\d x=\int \arcsin\left(\frac{x+2}{(x+2)^2+9}\right)\,\d x.
$$
Substitute $x+2=3 \tan\theta$ and $\d x=3\sec^2\theta\,\d\theta$,\begin{align*}
&\mathrel{\phantom{=}} \int \arcsin\left(\frac{x+2}{(x+2)^2+9}\right)\,\d x\\
&=3\int \arcsin\left(\frac{3\tan\theta}{9\tan^2\theta+9}\right)\sec^2\theta\,\d\theta\\
&=3\int \arcsin\left(\frac{3\tan\theta}{9\sec^2\theta}\right)\sec^2\theta\,\d\theta\\
&=3\int \arcsin\left(\frac{\sin\theta\cos\theta}{3}\right)\sec^2\theta\,\d\theta\\
&=3\int \arcsin\left(\frac{\sin2\theta}{6}\right)\sec^2\theta\,\d\theta.
\end{align*} What can I do from here?","['indefinite-integrals', 'integration', 'calculus']"
2241758,On a Collatz-like problem with two end cycles,"In an alternative version of Collatz problem, one iterates the function $f:\mathbb{N}\to\mathbb{N}$ defined by
$$f(n)=\begin{cases}n/3 &\mbox{if}\ n\equiv0\ (\mbox{mod}3)\\
2n+1&\mbox{if}\ n\equiv1\ (\mbox{mod}3)\\
2n+2&\mbox{if}\ n\equiv2\ (\mbox{mod}3)
\end{cases}$$ There are two cycles: $\{1,3\}$ and $\{2,6\}$. Starting from any $n$ in $\mathbb N$, one ends up in $\{1,3\}$ or in $\{2,6\}$. To show this, use induction. The desired property holds for $n=1$ and $n=2$, obviously. If it holds for every $m<n$, then: if $n=3k$, then $f(n)=k$ and $k<3k=n$ hence, by the induction hypothesis, some number of iterations of $f$ brings $k$ to the cycle $\{1,3\}$ or to the cycle $\{2,6\}$; if $n=3k+1$, then $f(n)=6k+3$, $f(f(n))=2k+1$ and $2k+1<3k+1=n$ hence, by the induction hypothesis, some number of iterations of $f$ brings $2k+1$ to the cycle $\{1,3\}$ or to the cycle $\{2,6\}$; if $n=3k+2$, then $f(n)=6k+6$, $f(f(n))=2k+2$ and $2k+2<3k+2=n$ hence, by the induction hypothesis, some number of iterations of $f$ brings $2k+2$ to the cycle $\{1,3\}$ or to the cycle $\{2,6\}$. Given any number $n$, let $c(n)=1$ if, starting at $n$ and iterating $f$, one ends in the $\{1,3\}$ cycle, and $c(n)=2$ if one ends in the $\{2,6\}$ cycle. The table of the first values of $c(n)$ is as follows: \begin{array}{c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
n&1&2&3&4&5&6&7&8&9&10&11&12&13&14&15&16&17&18&19&20\\
\hline
c(n)&1&2&1&1&1&2&1&2&1&1&2&1&1&1&1&2&1&2&1&1\\
\end{array} Is there any way to characterize numbers $n$ according to $c(n)$, the cycle they fall into? In other words, what can be proved about the set $\{n\in\mathbb N\mid c(n)=1\}$?","['number-theory', 'dynamical-systems', 'collatz-conjecture']"
2241769,"On odd perfect numbers and $x\varphi(y)=y\varphi(x)$, where $\varphi(n)$ is the Euler's totient function","Motivation. If we presume that there exists an odd perfect number $n$ , then since the Euler's totient function satisfies $$\varphi(n)=n\cdot\prod_{p\mid n}\left(1-\frac{1}{p}\right),$$ then denoting with $\operatorname{rad}(m)=\prod_{p\mid m}p$ the radical of an integer $m\geq 1$ with $\operatorname{rad}(1)=1$ , and $\sigma(m)=\sum_{d\mid m}d$ then sum of divisors function we get that our odd perfect number satisifies $$2\varphi(n)\operatorname{rad}(n)=\sigma(n)\varphi(\operatorname{rad}(n)).$$ That is, our odd perfect number satisifies $$\varphi(n)\operatorname{rad}(n)=n\varphi(\operatorname{rad}(n))\tag{1}$$ and we conclude that our odd perfect number $n$ satisfies by application of the Fermat's little theorem $$2^{n\varphi(\operatorname{rad}(n))}\equiv 1\text{ mod }n,\tag{2}$$ and $$2^{\operatorname{rad}(n)\varphi(n)}\equiv 1\text{ mod }\operatorname{rad}(n).\tag{3}$$ Question 1. Is true or false the following conjecture: If $n>1$ is an odd integer that satisfies $$m\varphi(n)=n\varphi(m)\tag{4}$$ where $m\mid n$ and $m<n$ then $n$ is an odd perfect number with $\operatorname{rad}(n)=m$ . Thus I am asking if you can provide me a proof of the statement or well a counterexample $(n,m)$ of odd integers such that satisfy $(4)$ and $m\mid n$ , but or well $n$ is not an odd perfect nunber or well $m$ is such that $m\neq\operatorname{rad}(n)$ . Question 2. Do you know odd integers $n,m\geq 1$ such that $$2^{n\varphi(m)}\equiv 1\text{ mod }n,$$ and $$2^{m\varphi(n)}\equiv 1\text{ mod }m?$$ (If there are many examples and you want help me, I am especially interested in examples of odd integers $n$ of the form $n\equiv 1\text{ mod }12$ or well of the form $n\equiv 9\text{ mod }36$ , and being $m\mid n$ with $m$ without repeated prime factors.) Thanks in advance.","['divisibility', 'sequences-and-series', 'totient-function', 'elementary-number-theory']"
2241824,Let $ 0 \preceq A \preceq I$ can we relate $Tr( (I-A) B+A C)$ to $Tr(I-A)Tr(B)+Tr(A) Tr(C)$,"Let $ 0 \preceq A \preceq I$  and let $B$ and $C$ be two symmetric positive definite matrices. Can we related
\begin{align}
{\rm Tr}( (I-A) B+A C)
\end{align} to \begin{align}
Tr(I-A)Tr(B)+Tr(A) Tr(C)
\end{align} via some inequality? Note, that in the case $A=aI$  for any $a\in [0,1]$ there is an equality. Edit: Note, from a very nice answer below we have: \begin{align}
\lambda_{\min}(I-A){\rm Tr}(B)+\lambda_{\min}(A){\rm Tr}(C) \le {\rm Tr}( (I-A) B+A C) \le \lambda_{\max}(I-A){\rm Tr}(B)+\lambda_{\max}(A){\rm Tr}(C).
\end{align}","['matrices', 'linear-algebra']"
2241879,Reference for trace/norm inequality,"I'm looking for a reference for a matrix-norm inequality that I used in this answer , which has a few equivalent forms.  I will use notation that applies to complex vector spaces with a sesquilinear inner product, but of course the same applies over real matrices. The statement is as follows: Take $A,B \in \Bbb F^{n \times n}$.  Then 
  $$\vert\operatorname{tr}(A^*B)\vert \leq \sigma_1(A)\sum_{i=1}^n \sigma_i(B) = \|A\| \operatorname{tr}|B|$$
  where $\sigma_i$ denotes the $i$th singular value, $|B| = (B^*B)^{1/2}$, and $\|\cdot\|$ denotes the spectral norm (induced Euclidean norm). I did manage to find some references, but they're overkill, and the texts themselves are not readily accessible to the faint of heart (Bhatia's text is dense and Pedersen's is not about matrices in particular). A suitable reference would be greatly appreciated.","['matrices', 'reference-request', 'numerical-linear-algebra', 'linear-algebra']"
2241898,Conditions for positive definiteness: matrix inequality,"Let $0<\alpha<1$ and $A,B\in\mathbb{R}^{n\times n}$. I am trying to find conditions on $A$ and $B$ such that
\begin{equation}
I_n-\frac{1}{\alpha}B^{\rm T}B-\frac{1}{4\alpha(1-\alpha)}( A^{\rm T}B+A)^{\rm T}( A^{\rm T}B+A)>0.
\end{equation}
However, I do not know how to proceed. Any idea or suggestion is appreciated.","['eigenvalues-eigenvectors', 'matrices', 'positive-definite', 'spectral-theory', 'linear-algebra']"
2241925,Double integral substitution,"I am looking for a substitution which will allow me to compute the double integral, $$\iint \frac{\cos(x-y)}{\sin(x+y)}\,dA,$$ over region bound by $x+y=\frac{\pi}{2}$, $x=0$, and $y=\frac{\pi}{4}$.","['multivariable-calculus', 'integration', 'calculus']"
2241955,Does $\sum_{n=1}^\infty \frac{1}{\log(e^{n}+e^{-n})}$ converge or diverge?,How would I show that the following series converges or diverges? $$\sum_{n=1}^\infty  \frac{1}{\log(e^{n}+e^{-n})}$$ Any help would be appreciated.,"['real-analysis', 'sequences-and-series', 'convergence-divergence']"
2242073,The intersection $\bigcap_{i \in I}G_i$ is an order relation,"Let $\{G_i\}_{i \in I}$ be an indexed family of order relations in a set $A$. Show that $\bigcap_{i \in I}G_i$ is an order relation in $A$. My attempt: Since $G_i$ is reflexive for all $i \in I$, $\forall x \in A, (x,x) \in G_i \forall i \in I$ $\implies \forall x \in A, (x,x) \in \bigcap_{i \in I}G_i$ Is this the right way of proving the reflexive part?
And could anyone help me with the antisymmetric and transitive part. Any help would be appreciated.","['order-theory', 'elementary-set-theory']"
2242141,An integral of a rational function of logarithm and nonlinear arguments,"This problem was posted in I&S $$ \int_{0}^{1} \dfrac{\log x \log (1+x) \log (1+x+x^{2})}{(1-x)(1+x^{2})}\,\mathrm{d}x \approx -0.223434.$$ I am not sure if there exists a closed form but it seems worth trying. I am completely clueless on how to start with this beast. It is worth saying that$$1-x^3= (1-x)(1+x+x^2).$$ That seems to go no where. I think the integral can be represented as the derivative of the integral representation of the Hypergeometric function but I am not comfortable with that. Any ideas ?","['integration', 'definite-integrals', 'calculus']"
2242223,Distributional limit.,"I`m preparing for an exam and I have this question:
how can I find the distributional limit for something like for $f\in L^1 (R)$ : $$\lim_{t \rightarrow 0} \int^{\infty}_0 f(x) \cos \left(t \sqrt x\right) dx $$ $$\lim_{t\rightarrow \infty} \int^{\infty}_0 f(x) \cos\left(t \sqrt x\right) dx $$ Thanks.","['functional-analysis', 'harmonic-analysis', 'distribution-theory', 'analysis']"
2242237,The measure-theoretical definition of a bootstrap sample,"Iâ€™m currently learning the bootstrap method, and I have two questions to ask about the definition of a bootstrap sample. Let $ (\Omega,\mathscr{S},\mathsf{P}) $ be a probability space. Let $ X_{1},\ldots,X_{n} $ be i.i.d. random variables on $ (\Omega,\mathscr{S},\mathsf{P}) $, with their common c.d.f. denoted by $ F $. Let $ \hat{F} $ denote the empirical c.d.f. of $ X_{1},\ldots,X_{n} $, i.e.,
$$
\forall x \in \mathbf{R}: \qquad
\hat{F}(x) = \frac{1}{n} \sum_{i = 1}^{n} \chi_{(- \infty,x]} \circ X_{i}.
$$
Clearly, $ \hat{F}(x) $ is a random variable on $ (\Omega,\mathscr{S},\mathsf{P}) $ for each $ x \in \mathbf{R} $, and for each $ \omega \in \Omega $, the function
$$
\left\{ \begin{matrix}
\mathbf{R} & \to & [0,1] \\ x & \mapsto & \left[ \hat{F}(x) \right] \! (\omega)\end{matrix} \right\}
$$
is the c.d.f. of some discrete random variable. Question 1: What does it mean to say that $ (X_{1}^{*},\ldots,X_{n}^{*}) $ is a bootstrap sample drawn from $ \hat{F} $? As mentioned, $ \hat{F}(x) $ is not a number but a random variable for each $ x \in \mathbf{R} $. I require an answer to this question strictly in terms of measure theory. Question 2: What probability space are $ X_{1}^{*},\ldots,X_{n}^{*} $ defined on? Is it still $ (\Omega,\mathscr{S},\mathsf{P}) $? Thanks!","['probability-theory', 'statistics', 'probability', 'bootstrap-sampling', 'random-variables']"
2242255,Compute matrix determinant for matrix with $\lambda$ on diagonal and $\mu$ elsewhere [duplicate],"This question already has answers here : Determinant of a matrix with diagonal entries $a$ and off-diagonal entries $b$ [duplicate] (9 answers) Closed 7 years ago . Given $n\in \mathbb N$, how can I compute the determinant of $(a_{ij})_{1\leq i,j \leq n} \in \mathcal M_{n\times n}(\mathbb R)$ where, for each $1\leq i,j\leq n:$ $$a_{ij}= \begin{cases} \lambda &i=j \\ \mu & i\neq j \end{cases}$$
The only (or the only easy) way to do this I think involves using Laplace's formula, expanding along any row. But doing this everything gets too messy, I can't express it in a good way. I tried to get a recursive relation and prove it via induction but didn't get anywhere. Is there an easier way? Any hints appreciated.","['matrices', 'linear-algebra', 'determinant']"
2242305,"Regarding recurrences, why do characteristic polynomials work, and why do we look for the roots?","I'll use an example recurrence but my question is meant to be generalized. Let's say we had some recurrence, such as: $$F(n) = -8F(n-1) + 9F(n-2) + 92F(n-3) - 140F(n-4)$$ where we already know the first few base constants $F(0), F(1), F(2), F(3)$ so the entire recurrence is defined for all integers $n \geq 0$. Normally we convert this to some kind of characteristic polynomial : $$x^n = -8 x^{n-1} + 9 x^{n-2} + 92 x^{n-3} - 140x^{n-4}$$ Divide everything by $x^{n-4}$ and put everything on one side: $$x^4  +8 x^3 - 9 x^2 - 92 x + 140 = 0$$ This polynomial can be factored: $$(x - 2)^2 (x + 5) (x + 7) = 0$$ And now we know that the roots are $2, -5, -7$. The $2$ root has multiplicity $2$, whereas the $-5$ and $-7$ roots each have multiplicity $1$. From this we can say that: $$F(n) = a  \cdot (2)^n + b \cdot n \cdot  (2)^n + c \cdot (-5)^n + d \cdot (-7)^n$$ And then we use the original four values of $F$ that we do know to solve a short system of equations and solve for $a, b, c, d$ to finish up the closed form. The short version of my question is basically ""Why does this work?"" Why can we use a ""characteristic polynomial"" (what is this, exactly) instead of a recurrence? Why does that polynomial's roots directly correspond to the closed-form of that recurrence? Why do we need to add an additional term with another power of $n$ for roots of multiplicity $>1$?","['intuition', 'recurrence-relations', 'polynomials', 'roots', 'number-theory']"
2242308,"Proving $\alpha(x) = f(x,y_0)$ is a continuous function.","Problem: $f:\mathbb{R}^2\to \mathbb{R}$, if f is continuous at $(x_0,y_0)$ show that the function $\alpha(x) = f(x,y_0)$ is continuous at $x_0$. I know that a function is continuous if $$\lim_{(x,y) \to (x_0, y_0)}  f(x,y) = f(x_0,y_0)$$ I did this: $$\lim_{x \to x_0} \ \alpha(x) = \lim_{x \to x_0} \ f(x,y_0) = f(x_0,y_0) = \alpha(x_0)$$ I doubt this is okay, need help, thanks","['multivariable-calculus', 'continuity', 'limits']"
2242327,"Prove that $v, Tv, T^2v, ... , T^{m-1}v$ is linearly independent","Suppose $T$ is in $L(V)$ , $m$ is a positive integer, and $v$ in vector space $V$ is such that $(T^{m-1})v \neq 0$ , and $(T^m)v = 0$ . Prove that $[v, Tv, T^2v, ... , T^{m-1}v]$ is linearly independent I get that $(T^j)v \neq 0\ \forall\ j < m$ . Additionally, since $T$ is nilpotent, $V$ has a basis with respect to which the matrix of $T$ has $0$ s on and below the diagonal. However, I'm not sure if these can be used to show linear independence or if they're even relevant to the problem at all. Any help is appreciated!","['matrices', 'linear-algebra', 'linear-transformations']"
2242337,When are two measures equivalent? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Given to measures $\mu$ and $\nu$, with the relation $d\nu = f d \mu$, $f$ measurable and non-negative, then we know that $\nu << \mu$ (the Radon Nikodym theorem proves that the converse also holds). Under what condition on $f$  is $\mu << \nu$, i.e. the two measures are equivalent?",['measure-theory']
2242394,"Integrate $ \int_0^\infty \left( ( x A+I)^{-1} A - \frac{1}{c+x} I \right)\, \mathrm dx $ where $A$ is positive-definite and $c>0$","$\def\d{\mathrm{d}}$Can someone outline for me have to integrate the following expression:
\begin{align}
\int_0^\infty \left( ( x A+I)^{-1} A - \frac{1}{c+x} I \right) \,\d x
\end{align}
where $A$ is a positive definte  matrix and $c>0$. The integration is done element-wise. In the scalar case, this inegral becomes $\log(a)+\log(c)$. One of the responses suggests that the answer is $\log(A)+\log(c)I$.
However, I am not very sure how this was shown. Thanks.","['multivariable-calculus', 'integration', 'linear-algebra']"
2242402,What are all the generalizations needed to pass from finite dimensional linear algebra with matrices to fourier series and pdes?,"I've studied Linear Algebra on finite dimensions and now I'm studying fourier series, sturm-liouville problems, pdes etc. However none of our lecturers made any connection between linear algebra an this. I think this is a very big mistake because I see many questions here where everyone just talks about these topics as generalizations of simple linear algebra. Hence what are the generalizations? For example I think a matrix becomes a function in infinite dimension, but that's about it.","['sturm-liouville', 'fourier-analysis', 'partial-differential-equations', 'ordinary-differential-equations', 'linear-algebra']"
2242455,"How can we show that $\int_{-\infty}^{+\infty}{ke^x\pm1\over \pi^2+(e^x-x+1)^2}\cdot{(e^x+1)^2\over \pi^2+(e^x+x+1)^2}\cdot 2x \,\mathrm dx=k?$","Motivated by this paper . Conjecture: $$\int_{-\infty}^{+\infty}{ke^x\pm1\over \pi^2+(e^x-x+1)^2}\cdot{(e^x+1)^2\over \pi^2+(e^x+x+1)^2}\cdot 2x \,\mathrm dx=k,\tag1$$
  where $k$ is a real number. Making an attempt: $u=e^x+1\implies \,\mathrm du=e^x\,\mathrm dx$ and let $k=1$ for simplification, then (1) becomes $$\int_{1}^{\infty}{u^3\over \pi^2+(u-x)^2}\cdot{\ln(u-1)\over \pi^2+(u+x)^2}\cdot{2\mathrm du\over u-1}.\tag2$$ I have no idea where to go from here! I don't think substitution work here, probably using contour integration. How can we prove (1)?","['integration', 'definite-integrals', 'contour-integration', 'calculus']"
2242471,Solving a linear system of ODEs in matrix form,"I would like to solve the linear system of ordinary differential equations
$$
\begin{align*}
\dot\mu&=R^\mathrm T\mu \\
\dot\Sigma&=R^\mathrm T\Sigma+\Sigma^\mathrm T R+\mathrm{diag}(R^\mathrm T\mu)
\end{align*}
$$
where $\mu$ is a column vector, $\Sigma$ is a (symmetric) covariance matrix, and $R$ is a square rate matrix. Clearly $\mu(t)=e^{R^\mathrm Tt}\mu(0)$, but is there any way to solve for $\Sigma(t)$?","['matrices', 'ordinary-differential-equations', 'dynamical-systems', 'systems-of-equations']"
2242477,Lifting Free Group Actions on $S^1$ to $\mathbb{R}$,"The free group $F_2$ acts faithfully on the circle $S^1$ by homeomorphisms.  Someone told me that given any such action on $S^1$, we can lift it to a faithful action $F_2\curvearrowright \mathbb{R}$ by homeomorphisms.  Why isn't there an obstruction?  It seems to me like we should have to worry about lifts composing correctly.","['covering-spaces', 'free-groups', 'group-actions', 'general-topology', 'group-theory']"
2242488,Tangent half angle formula,"So we start with the following tangent half angle formula:
$$ \tan\left(\frac \theta2\right) = \pm\sqrt{\frac {1 - \cos \theta}{1 + \cos \theta}} $$ If I do some algebraic manipulation I end up with the following below:
$$ \tan \left(\frac \theta2\right)= \pm\frac {1 - \cos \theta} {\sin \theta}$$ Now according to Michael Corral's Trigonometry the minus sign is not possible so I only end up with: $$ \tan \left(\frac \theta2\right)= \frac {1 - \cos \theta} {\sin \theta} $$ Can you please explain why that is true?",['trigonometry']
2242500,Root of the quintic $x^5 âˆ’ 5x^4 + 30x^3 âˆ’ 50x^2 + 55x âˆ’ 21=0$,"What is real root of the quintic $x^5 âˆ’ 5x^4 + 30x^3 âˆ’ 50x^2 + 55x âˆ’ 21=0$? Some remarks: I saw this quintic in wikipedia Real root is given $x=1+{\sqrt[ {5}]{2}}-\left({\sqrt[ {5}]{2}}\right)^{2}+\left({\sqrt[ {5}]{2}}\right)^{3}-\left({\sqrt[ {5}]{2}}\right)^{4}$ in wikipedia. I used the transformation $x=y+1$ (Tschirnhaus transformation) and $y^5 + 20 y^3 + 20 y^2 + 30 y + 10=0$. (We can remove the term of degree four.) Therefore, we have to solve $x^5 + 20 x^3 + 20 x^2 + 30 x + 10=0$ and we have to find $x={\sqrt[ {5}]{2}}-\left({\sqrt[ {5}]{2}}\right)^{2}+\left({\sqrt[ {5}]{2}}\right)^{3}-\left({\sqrt[ {5}]{2}}\right)^{4}$. But, I want to know how to solve this without plugging it in and verifying an already known root. Can the depressed quintic be solved? Or does one need to use another method to solve this polynomial?","['galois-theory', 'polynomials', 'analysis']"
2242511,Find the last three digits of $383^{101}$,"We have to find out $383^{101} \equiv ? \pmod {1000}$. 
I know that $383^2 â‰¡ 689 \pmod {1000}$
$383^5â‰¡143 \pmod {1000}$ I know that $Ï•(1000)=400 >101 $  from Euler.
It definitely can't help me.
I don't know how to continue.
I can't use the Chinese Remainder Theorem.","['algebra-precalculus', 'congruences', 'congruence-relations']"
2242515,Stabily from autonomous to nonautonomous,"Suppose we have some ODE of the form $$\dot{x}=f(\alpha,x),$$ where $\alpha \in \mathbb{R}^k$ is some vector of parameters. And for $\alpha \in A$ we have $x=e_{\alpha}$ stable hyperbolic equilibriums for the corresponding equations. 
Now, lets change $\alpha$ for $\alpha (t)$ with $\alpha (t) \in A,\forall t$. Can we ensure (under some conditions on $f$ and $\alpha (t)$) that the equilibrium ""will turn"" into a trajectory $e(t)$ which attracts solutions (locally) of the non-autonomous equation $\dot{x}=f(\alpha(t),x)$ (forward or in a pull-back sense)? In particular, I'm working with a system for which I know the equilibriums for $\alpha \in A$. And if I change $\alpha$ for a periodic function, I can prove (using degree theory) that a periodic solution exists, provided $\alpha (t) \in A$ and the amplitude of oscillation is small. Is this solution a ""perturbation"" of the equilibrium? does it preserve the attractiveness? I hope the question is well posed,
Thanks! Edit: Thank you RPA for your answer. My problem is actually a little bit more complex because my system involves time delays. I could write the equations here if you are interested. But basically I have 2 equations which depend on the parameters $\gamma$, $K$, and $\delta$. If they satisfy certain inequalities its not hard to solve for the non trivial equilibrium. And for $\gamma(t)$, $K(t)$, and $\delta(t)$ T-periodic, if the same inequalities hold $\forall t$ then I can probe existence of a non trivial periodic solution. So I believe that if the amplitude of this functions gets small, then this periodic solution should also have small amplitude until it becomes a point. But I don't know how to see this.","['ordinary-differential-equations', 'dynamical-systems', 'calculus', 'stability-theory']"
2242530,Distribution of Norm of Two-Dimensional Brownian Motion,"I am trying to solve the following: Let $W_{t}=\left(W_{t}^{1},W_{t}^{2}\right)$ be a two dimensional Brownian motion.  Find the distribution of $$\|W_{t}\|=\sqrt{(W_{t}^{1})^2+(W_{t}^{2})^2}.$$ I know by the properties of Brownian motion for any $k \ge 1$ and $0<t_1<\dotsb<t_k$ the random vector $(W_{t_1},\dotsc,W_{t_k})$ is Gaussian with zero mean and covariance matrix $B(t_i,t_j)=\min(t_i,t_j).$  I also know that the sum of square iid Gaussian random variables $N(0,\sigma)$ is exponential with mean $2\sigma^2.$ Can I use this property to infer anything about the $L^2$ norm of a two-dimensional Brownian motion?","['probability-theory', 'probability', 'brownian-motion']"
2242548,Inverse Laplace Transform Formula,"I'm trying to learn how to evaluate inverse Laplace transforms without the aid of a table of transforms, and I've found the inversion formula:
$$\mathcal{L}^{-1}\{F\}(t)=\frac{1}{2\pi i}\int_{\gamma-i\infty}^{\gamma+i\infty}F(s)e^{st}ds$$ I'm currently in high school, and I don't a lot of knowledge in terms of complex analysis, but I do have a pretty good base in calculus, so if anyone could help me out, it'd be great if you could also explain some of the complex analysis methods that may be involved in evaluating this integral.
A step by step solution for the ILT of $F(s)=\frac{1}{s}$ would be awesome. Thanks in advance.","['multivariable-calculus', 'ordinary-differential-equations']"
2242549,Is weighting by relative variance a meaningful way to weight variables?,"For a school project, I am trying to determine similarity between participants based on different aspects of their athletic mechanics. I have the same number of observations per participant, and 8 variables per observation. I need to algorithmically determine weights for each variable. My current idea is to weight each variable by the variance of the variable across all observations. My reasoning is that variables that have greater variability will be better indicators of the similarity of participants, since variables with low variance will just clump all of the participants together. I've set the weight of the most varied variable to 1, and all others are weighted relative to this variable. Would this be considered a reasonable way to determine weights? Is there a peer-reviewed method of weighting similar types of variables? I could not find one that I clearly understood. Thanks in advance!","['statistics', 'standard-deviation', 'variance']"
2242595,Computing Characteristic Functional of Brownian Motion,"I am trying to solve the following: Define the characteristic functional of a random process $X_t, T=\mathbb{R}$ by $$L(\varphi)=E\left[\exp \left(i\int_{T}\varphi(t)X_{t}\, dt \right) \right],$$ where $\varphi(t)$ is continuous differentiable with compact support.  Determine the characteristic functional for Brownian motion. I want to compute $L(\varphi)=E[\exp(i\int_{T}\varphi(t)W_{t} \, dt)]$, where $W_t$ is a Brownian motion with continuous trajectories and independent gaussian distributed increments.  How can I apply these facts to compute $L(\varphi)$?  Am I supposed to estimate $\int_{T}\varphi(t)W_{t} \, dt$ using a Riemann sum?","['characteristic-functions', 'probability-theory', 'probability', 'brownian-motion']"
2242597,Proof about Involutory Functions,"I would like to prove (or disprove) that involutory functions (functions that are their own inverses) have no real functional square root/half iterate, but I'm not sure where to start with this. This assumption seems ""correct"", but that isn't really enough. So far all of these functions that I've come across have some functional square root involving complex numbers. For example, if $ð‘“(ð‘¥)=-x$, then the functional square root is $ð‘”(ð‘¥)=ix$. Another example is that if $ð‘“(ð‘¥)=\frac{1}{x}$, then $ð‘”(ð‘¥)=x^i$. One last example is that if $ð‘“(ð‘¥)=1-x$, then $ð‘”(ð‘¥)=ix+\frac{1}{2}-\frac{1}{2}i$. Can anybody help me out by giving me some idea how I can begin this proof, or give a counterexample?","['inverse-function', 'function-and-relation-composition', 'functions']"
2242624,Applying Stokes' theorem - what surface?,"$\def\d{\mathrm{d}}$Determine the integral $$\oint_L \mathbf{A} \cdot \,\d\mathbf{r},$$
  where $$\mathbf{A} = \mathbf{e}_x(x^2-a(y+z))+\mathbf{e}_y(y^2-az)+\mathbf{e}_z(z^2-a(x+y)),$$
  and $L$ is the curve given by the intersection between the cylinder $$\begin{cases}(x-a)^2+y^2=a^2 \\z\geq0\end{cases}$$
  and the sphere $$x^2+y^2+z^2=R^2, \quad (R^2>4a^2)$$
  The orientation is such that at $x=0$ the tangent to the curve is parallel with $-\mathbf{e}_y$. Attempted solution: Let's apply Stokes' theorem. First, let me introduce a graphical representation of the problem. The path $L$ will then, as seen from above, be the following: A simple calculation shows $\nabla \times \textbf{A} = (0,0,a)$. Here comes my problem... Question What surface am I looking to take a surface integral over? Is it the whole cylinder or just the ""top""? How can I determine?","['multivariable-calculus', 'stokes-theorem', 'surface-integrals', 'vector-analysis']"
2242629,If $A+B=AB$ then $AB=BA$,"I was doing the problem $$ A+B=AB\implies AB=BA. $$ $AB=BA$ means they're invertible, but I can't figure out how to show that $A+B=AB$ implies invertibility.","['matrices', 'linear-algebra']"
2242640,Induced path of length $\sqrt{\log n}$ in a sparse random graph,"I'm trying to solve Exercise 1.4.2 in this book. Here $G_{n,p}$ is a random graph on $n$ vertices where each edge is present independently with probability $p$. Suppose that $p=d/n$ where $d>1$. Show that w.h.p. $G_{n,p}$ contains
  an induced path of length $\sqrt{\log n}$. The only technique for such problems introduced in the book at the point is the second moment method, so I tried that. Recall this method uses the inequality
$$P(X=0)\le \frac{\operatorname{Var X}}{(\mathbb E X)^2}.$$ So, if $X$ counts the number of induced paths of length $\sqrt{\log n}$, and we show that the square of its expectation dominates its variance, we're set. Write $X = \sum_{i\in K} I_i$, where $K$ is the set of possible paths and $I_i$ is an indicator function for the presence of the induced path. We compute $$|K| = \frac{1}{2} \frac{n!}{(n - \sqrt{\log n})!}$$ and the probability of each $I_i$ occurring is $$\mathbb E I_i =p^{\sqrt{\log n}}(1-p)^{\binom{\sqrt{\log n}}{2} - \sqrt{\log n}}.$$ The $(1-p)$ factor tends to a constant, and we get asymptotically that the first moment of $X$ is $\mathbb E X= d^{\sqrt{\log n}}$, which explains why the problem requires $d>1$. However, it seems that the variance won't be small enough to give the result. Since all the $I_i$ are positively correlated, we can get a lower bound by asking what happens in the case where all the $I_i$ are independent. Recall the variance of a binomial variable (such as $I_i$) with expectation $a$ is $a(1-a),$ and here $a$ is $o(1)$ so we get that the variance is approximately $a|K|$. Then $$ \frac{\operatorname{Var X}}{(\mathbb E X)^2} \approx \frac{ |K| a (1-a)}{|K|^2 a^2} \approx \frac{1}{K|a|} = \frac{1}{\mathbb E X}.$$ So ignoring all correlations, we would just barely get the result, since $\mathbb EX$ grows slowly. However, since it grows so slowly, it seems trying to account for all the correlations will inevitably spoil the proof by making the variance too large. Am I on the right track here? Or is another method needed? I'm also curious why $\sqrt{\log n}$ works but something larger like $\log{n}$ doesn't. This restriction doesn't come out of the above calculations.","['graph-theory', 'random-graphs', 'probability', 'discrete-mathematics']"
2242645,"Let $( \sqrt{2} + 1)^{1000} = a + b \sqrt{2}$, where a and b are integers. Find the greatest common factor of b and 81.","Let $( \sqrt{2} + 1)^{1000} = a + b \sqrt{2}$, where $a$ and $b$ are integers. Find the greatest common factor of $b$ and $81$. How would one solve this question? I tried to use the binomial theorem but that approach did not work. How would one solve this problem if it were to appear on a Math Olympiad? I know the answer is one of: (A) 1 (B) 3 (C) 9 (D) 27 (E) 81. According to one of the Stack Exchange members, the answer is 3. It was found using Python.","['number-theory', 'binomial-theorem']"
2242657,Perturbation series for $x^5+\varepsilon x-1=0$,"I want to find a closed form for the perturbation coefficients $a_n$ defined by the perturbative solution 
$$
x(\varepsilon)=1+\sum_{n=1}^\infty a_n \varepsilon^n
$$
to the quintic equation
$$
x^5+\varepsilon x-1=0.
$$
By computing the determinant, as was suggested for this related question regarding the cubic case, we can argue that the radius of convergence of the above series must be
$$
\rho=\frac{5}{4^{4/5}}=1.64938\dots
$$
Furthermore, the Lagrange-BÃ¼rmann theorem allows us to formally write down a closed form for the coefficients, namely 
$$
a_n=\frac{(-1)^n}{n!}\frac{d^{n-1}}{dx^{n-1}}\left(\frac{x}{1+x+x^2+x^3+x^4}\right)^n_{x=1}
$$ 
but this doesn't look very illuminating. (For the case of the cubic equation a slightly more explicit but still cumbersone rewriting was made possible by the simpler form of $a_n$). What I would like to achieve is obtaining $\rho$ from the explicit closed expression for the $a_n$. Therefore I set out to compute some of them. Here they are:
$$
a_1=-\frac{1}{5},\
a_2=-\frac{1}{5^2},\
a_3=-\frac{1}{5^3},\
a_4=0,\\
a_5=\frac{21}{5^6},\
a_6=\frac{78}{5^7},\
a_7=\frac{187}{5^8},\
a_8=\frac{286}{5^9},\
a_{9}=0,\\
a_{10}=-\frac{9367}{5^{12}},\
a_{11}=-\frac{39767}{5^{13}},\
a_{12}=-\frac{105672}{5^{14}},\
a_{13}=-\frac{175398}{5^{15}},\
a_{14}=0.
$$
The behavior of the $a_n$ for $n=1,\ldots,30$ supports the following conjecture:
$$\boxed{
a_n = -(-1)^{\lfloor n/5\rfloor}\frac{c_n}{5^{\alpha_n}}
}
$$
where
$$
\alpha_n=\sum_{k=0}^\infty \left\lfloor \frac{n}{5^k} \right\rfloor
$$
and the $c_n$ are nonnegative integer coefficients which are not divisible by $5$ and vanish for $n=5m-1$.
I think that $c_n$ should be something of the form
$$
\frac{1}{4n+1}\binom{5n}{n}
$$
which for $n=4$ goes very near to reproducing $c_8=286$ and has a scaling similar to that exhibited by the $c_n$. This problem is also motivated by this video where it is suggested that the answer can be guessed with some effort by staring at the coefficients hard enough (27.08).
I think I need some help, however!","['recurrence-relations', 'roots', 'pattern-recognition', 'perturbation-theory', 'sequences-and-series']"
2242672,Euclidean + Taxicab Minkowski Space is Finsler metric?,"Define the function $F$ on the elements $(x,v)$ of the tangent bundle of $\mathbb{R}^D$ by
$$
F(x,v) \triangleq \|x-v\|_2 + \|v\|_1,
$$
where $\|\cdot\|_p$  is the $p$-norm on $\mathbb{R}^D$.  Does $F$ define a Finsler function (in the sense that the Hessian of $F^2$ is a symmetric bilinear form)? I can prove that this defines a geodesic length space by convexity arguments but I'm not sure how to show (or check) if it is Finslerian.","['finsler-geometry', 'riemannian-geometry', 'differential-geometry', 'metric-geometry']"
2242693,Algebraic structure of the extended real line $\overline{\Bbb R}$.,"The extended real line $\overline{\Bbb R}$ is defined to be the set $\overline{\Bbb R}=\Bbb R\cup\{\infty,-\infty\}$, where the adjoined symbols $\{\infty,-\infty\}$ represents the ""points at infinity"" in both positive and negative direction. $\overline{\Bbb R}$ can be given a topology by declaring that apart from the usual open basis, we let $(a,\infty]$ and $[-\infty,a)$ be open for any $a\in\Bbb R$. This is the two-point compactification, making $\overline{\Bbb R}$ a compact topological space. However, the algebraic structure of $\overline{\Bbb R}$ seems rather unique. We declare that for any $a\in \Bbb R$,
$$\begin{align}
\infty+a &= \infty \\
-\infty+a &= -\infty \\
\infty+\infty &= \infty \\
-\infty-\infty &= -\infty \\
\frac a{\infty} &= 0 =\frac a{-\infty}
\end{align}$$
 and for $\infty\ge a>0> b\ge -\infty$,
$$\begin{align}
a\cdot\infty &= \infty \\
a\cdot(-\infty) &= -\infty \\
b\cdot\infty &= -\infty \\
b\cdot(-\infty) &= \infty \\
0\cdot\infty &=0 = 0\cdot(-\infty).\\
\end{align}$$
All other combinations, like $\infty-\infty$ or $\frac{\infty}{\infty}$, are left undefined. Yes, these all make sense but I just want to know if it fits into any bigger framework? This clearly is not in accordance with ""basics"" algebraic structures that we studied in our undergraduate years. $-\infty$ is not the additive inverse of $\infty$, neither is $\frac a{-\infty}=a\cdot{-\infty}^{-1}$  since ${-\infty}$ does not have a multiplicative inverse. Is there a general theory to this kind of algebraic structure? I am thinking about boolean algebra since $1$ in a boolean algebra also exhibits this kind of `absorbing' behaviour. Since I lack any deep knowledge in the field of algebra, I hope that someone here might be able to give an insight into this. PS. I tagged ""logic"" since I think it looks similar to boolean algebra. Please tell me if this is somehow not appropriate.","['real-analysis', 'abstract-algebra', 'logic', 'measure-theory', 'soft-question']"
2242758,Is this fraction undefined? Infinite Probability Question.,"Where $\frac{1}{\infty}$ and $\frac{\infty}{\infty}$ are both undefined terms that generally lead to nonsense, I'm wondering if we can assert that...: $$\frac{1+1+1+\cdots}{1+1+1+\cdots} = 1$$ ...or even $$\frac n {1+1+1+\cdots} = 0$$ ...for any natural number $n$.  In terms of infinite probabilities, it might make sense to recognize something like this because then we can differentiate: $$\frac{1+1+1+\cdots}{2+2+2+\cdots} = \frac 1 2\left(\frac{1+1+1+\cdots}{1+1+1+\cdots}\right) = \frac 1 2.$$ I ask because I independently developed the following proof for selecting a natural number using a method where all natural numbers have an equal, however undefined, probability of being selected. Introduction: It is helpful to consider a simple observation pertaining to finite sets in order to get started.  Let $A = \{1, 2\}$ and $B = \{3, 4, 5, 6\}$.  Let $f(x) = 1$ if $x$ is odd and $f(x) = 2$ if $x$ is even.  Then, function $f$ is a surjection from $B$ onto $A$ that is â€œuniformâ€ in the sense that selecting an element $x \in B$ uniformly at random will result in the selection of $f(x) \in A$ uniformly at random as well.  Note that in order to do this, we have effectively partitioned $B$ into subsets the same size as $A$ so that we could biject those subsets with $A$.  Likewise, this work shows how we can partition $[ \,0, 1) \,$ into countable sets that are then bijected with the natural numbers.  Consideration is then given to whether selecting an element of $[ \,0, 1) \,$ uniformly at random allows for the selection of a natural number uniformly at random as well. Definitions: Let $V^{( \,0.5, 1) \,}$ be a set containing one and only one element from each Vitali equivalence class on the interval $( \, 0.5, 1 ) \,$ (Vitali equivalence classes are equivalence classes of the real numbers that partition $\mathbb{R}$ under the relation $x \equiv y \iff ( \, \exists q \in \mathbb{Q} ) \, ( \, x - y = q ) \,$).  The axiom of choice allows for such a selection. For any real number $r$, let $d(r)$ equal the one and only one element $v \in V^{( \,0.5, 1) \,}$ such that $r - v \in \mathbb{Q}$. Let $h : \mathbb{N} \longmapsto \mathbb{Q} [ \, 0, 1 ) \,$ (here $\longmapsto$ denotes a bijection). Let $x$ be an element of $[ \,0, 1) \,$ selected uniformly at random. Let $k(x) = \begin{cases}
h^{-1}(x - d(x) + 0.5) && x \geq d(x) - 0.5 \\
h^{-1}((x + 1) - d(x) + 0.5) && x < d(x) - 0.5
\end{cases}$. For each natural number $1, 2, 3, â€¦$, let $V^1, V^2, V^3, \ldots$, respectively, be the sets such that $( \, \forall x \in V^{n} ) \, ( \,k(x) = n ) \,$.  We then have $V^{( \,0.5, 1) \,} = V^{h^{-1}(0.5)}$, for example.  Each $V^{n}$ will be a Vitali set by definition with the collection $\{ V^{n} : n \in \mathbb{N} \}$ forming a partition of $[ \,0, 1) \,$. Comments on Uniformity: A uniform distribution is a concept of translation invariance.  For example, if $S$ is a measurable set, we may want the probability of $S$ to be the same as the probability of $\{y : y = z + n, z \in S \}$ for each natural number $n$.  In the case of function $k$ over the domain $[ \,0, 1) \,$, however, we end up mapping each element of each non-measurable Vitali set $V^n$ to a distinct natural number $n$.  Where $a, b \in \mathbb{N}$, it is easy to see that the probability of $x$ falling within $V^a$ is equal to the probability of $x$ falling in $V^b$, but we cannot rely on a Lebesgue measure as a means of establishing probability or creating any sort of cumulative distribution function on $\mathbb{N}$.  The probability of selecting any given natural remains undefined.","['uniform-distribution', 'probability-theory', 'probability-distributions', 'elementary-number-theory']"
2242821,Tuple-builder notation,"For some function $f : \mathbb{N} \to S$, is there a concise (and preferably established) way to build tuples from sets $A\subset \mathbb{N}$ of the values they map to in $S$? The exact order of the tuple doesn't really matter, as long as it preserves some ordering. An example is in place. Let $A = \{1, 5, 6\}$, I'm looking for a way to express the $|A|$-tuple $(f(1), f(5), f(6))$. The tuple $(f(5), f(6), f(1))$ is equally acceptable, but the (multi)set $\{f(1), f(5), f(6)\}$ would not do. If we see tuples as nested ordered pairs $(a_1, a_2, \cdots, a_n) \equiv (a_1, (a_2, \cdots, a_n))$ with $(a_i)\equiv (a_i, \emptyset)$, I'm essentially looking for notation for the function: $$ g(f, A) = \left\{\begin{array}{ll}
\emptyset & \text{if } A = \emptyset, \\
(f(\min A), g(A \setminus \min A)) & \text{else}.
\end{array}\right.$$ I'm tempted to use notation parallel to the set-builder, i.e., $(f(x) : x \in A)$ but that doesn't really convey that the ordering matter. Edit to clarify the order requirement: The order of the tuple doesn't matter at all, but it matters that it is ordered. In other words, for $f : \mathbb{N} \to S$ and $h : \mathbb{N} \to S$, I want the following property of the notation: $$(f(x) : x \in A) = (h(x) : x \in A) \iff \forall x \in A, f(x) = h(x).$$ Obviously, this property holds for any ordering as long as it only depends on $A$. But it doesn't really feel that $(f(x) : x \in A)$ conveys that.","['notation', 'elementary-set-theory']"
2242841,If $K$ be an algebraic extension of $E$ and $E$ be an algebraic extension of $F$ then $K$ is an algebraic extension of $F$.,"Let $K$ be an algebraic extension of $E$ and $E$ be an algebraic extension of $F$ then $K$ is an algebraic extension of $F$ Proof- Let $a \in K$,then since $a$ is algebraic over $E$, so there exist an irreducible polynomial in $E[x]$ say $p(x)$ such that $p(a) = 0$. Let
$p(x) = b_{0} + b_{1}x +... +b_{n}x^n$ where $b_{0},b_{1},...,b_{n} \in E$ We need to show that $a$ is in some finite extension of $F$
How do we construct such a finite extension. In the remaining proof it adds element by element to the field $F$ but I am not sure why are we adding the elements $b_{i}$, $0 \leq i \leq n$ in order to show the existence of such a finite extension?. Any help is great!","['abstract-algebra', 'extension-field']"
2242849,Inexact differential equation $(x-y)\mathrm{d}x + (x+y)\mathrm{d}y$,"I'm having trouble with this equation:
$$(x-y)dx + (x+y)dy = 0.$$ How do I find the integrating factor? Since it's a inexact equation, I've tried to do the method of looking for an integrating factor that is only function of $x$ or $y$, but it does not seems to work.",['ordinary-differential-equations']
2242851,If prime $p=a_n10^n+a_{n-1}10^{n-1}+\ldots+a_110+a_0$ then $f(x)=a_nx^n+\ldots+a_0$ is irreducible in $\mathbb{Z}[x]$,"I have been trying to solve this problem on my own for four days now, and I cannot figure out how to prove it: If we express a prime $p$ in base $10$ as
$$p= a_m10^m+a_{m-1}10^{m-1}+\ldots +a_110+a_0,$$
with $0\leq a_i \leq 9$ for all $i \in [m]$, then the polynomial 
$$f(x)= a_mx^m+a_{m-1}x^{m-1}+\ldots +a_1x+a_0$$
is irreducible in $\mathbb{Z}[x]$. First, note that $\gcd(a_n, \ldots, a_0)=1$, otherwise $p$ would not be prime. I want to prove this by contradiction. Suppose, to the contrary, that $f(x)$ is reducible in $\mathbb{Z}[x]$. Then there exist $a(x), b(x) \in \mathbb{Z}[x]$, neither of which are units, such that $f(x)=a(x)b(x)$. Now $p=f(10)=a(10)b(10)$, which implies that $a(10)\in \{1, -1\}$ or $b(10)\in \{1, -1\}$ (whichever is the case will imply that the other is $\pm p$). Without loss of generality, suppose that $a(10)=1$. Now, I was given the following hint: Show that $f(x)$ takes on infinitely many prime values, that is, show that show that there exists a sequence $\{x_n\}$ of integers such that $f(x_n)=q_n$, where $q_n$ is prime for each $n$. If I can show this, I am done because by the argument made above, without loss of generality, this would imply that $a(x)$ takes on the value 1 infinitely many times. Then $a(x)-1=0$ for infinitely many $x$-values, but since a polynomial has infinitely many zeros if and only if it is the zero function itself, this would imply that $a(x)=1$ for all integers $x$, a contradiction. Can someone help me figure out why the hint is true? Thank you!! This problem is very interesting, don't you agree?","['irreducible-polynomials', 'polynomials', 'abstract-algebra', 'ring-theory', 'prime-numbers']"
2242859,Paradox: Two completely different values for $\lim_{n\to\infty} \left(\frac{1}{1-n^2}+\frac{2}{1-n^2}+...+\frac{n}{1-n^2}\right)$,"I am asked to evaluate the following question: $$\lim_{n\to\infty} \left(\frac{1}{1-n^2}+\frac{2}{1-n^2}+...+\frac{n}{1-n^2}\right)$$ I did the following: Using the property: Limit of a sum is the sum of limits, I take on each term separately. $$\lim_{n\to\infty}(\frac{1}{1-n^2}) = \lim_{n\to\infty}(\frac{\frac{1}{n^2}}{\frac{1}{n^2}-1}) = \frac{0}{-1} = 0.$$ Similarly each term evaluates to $0$ despite the dependence on n: $$\lim_{n\to\infty}(\frac{n}{1-n^2}) = \lim_{n\to\infty}(\frac{\frac{n}{n^2}}{\frac{1}{n^2}-1}) = 0.$$ I checked the answer and it said -$\frac{1}{2}.$ I checked the complete solution: $$\lim_{n\to\infty}(\frac{1}{1-n^2}+\frac{2}{1-n^2}+...+\frac{n}{1-n^2}) = \lim_{n\to\infty}(\frac{1+2+...+n}{1-n^2}) = \lim_{n\to\infty}(\frac{\frac{n(n-1)}{2}}{1-n^2}) = -\frac12.$$ Obviously, only one answer is ryt [hoping that the limit of an expression is a uniques number]. Both the deductions seem quite logical to me. The only plausible mistake i have noticed is $1+2+...+n = \frac{n(n-1)}{2}$ is only true for $n$ $\in$ $\Bbb Z$. Solve the paradox.","['fake-proofs', 'sequences-and-series', 'paradoxes', 'limits']"
2242928,"Understanding ""Equality"" notation in a limit","I am wondering about the word ""equal"" in the context of a limit. When a limit ""equals"" a value, is the expression including the $\lim$ equal to the limiting value in the same sense that $1+1 = 2$? I am not sure if, in the context of a limit, the limiting value is ever reached. If it is never reached, is the expression with the $\lim$ actually equivalent to the limiting value? I am wondering if there are two different types of equality--one in the context of limits and the other in the context of addition. Thank you!",['limits']
2242938,How to mathematically describe a spiral torus knot?,How would one mathematically describe the geometry as shown? For the purpose of implementing in something like matplotlib. Spiral Torus Knot Other examples (easier to see):,"['knot-theory', 'geometry']"
2243025,Integration and limit,"$\def\d{\mathrm{d}}$Let $$f(x)=\frac 1{e^{x}+8e^{-x}+4e^{-3x}},\ g(x)=\frac 1{e^{3x}+8e^{x}+4e^{-x}},$$ and$$\int (f(x)-2g(x)) \,\d x=h(x)+c,$$where $c$ is the constant of integration, and $$\lim_{x \to \infty} h(x)=\frac{\pi}4.$$ If $h(0)=\displaystyle \frac 1a\tan^{-1}\left(\frac bc\right)$ (where $a, b, c \in \mathbb N$, $b$ and $c$ are coprime), then find the value of $a+b+c$. In this question I am not able to solve the integration. I am not getting any method. Can anybody provide a hint?","['integration', 'limits']"
