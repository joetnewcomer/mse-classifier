question_id,title,body,tags
2530481,Definition of symmetric relation,"I know that the relation is symmetric if $\forall x \forall y \  xRy \implies yRx $. Consider the set $ A = \{{a, b, c, d}\}$
and 
$R = \{{(a, a),(a, b),(a, d),(b, a),(b, b),(c, c),(d, a),(d, d)}\}.$ My textbook claims that this relation is symmetric. But what about $(c,d)$ and $(d,c)$ that are not part of the $R$ set? In the definition, it said for all $x$ and $y$, so shouldn't this violate the symmetricity?","['relations', 'discrete-mathematics']"
2530606,Bounded operator on a non-empty set,"Let $S$ be non-empty set, and let $X$ be the vector space of bounded functions on $S$, subject only to the condition that it be a Banach space when $X$ is supplied with the supremum-norm. Suppose $f:S \to \mathbb{F}$ is a function such that $fg \in X$ for all $g \in X$. Then the multiplication operator $M_f:X \to X$, defined by $M_f(g)=fg(g \in X$) is bounded. I do not ask for the proof of this theorem. I just wonder if we assume $X\neq \lbrace0\rbrace$, *) Is it true that $f$ is necessarily bounded? That would certainly explain why $M_f$ is bounded. *)Is the theorem still true if $X$ is not required to be complete?","['functional-analysis', 'real-analysis', 'analysis']"
2530617,Lagrange Multiplier Problem with trivial gradient of $g$,"Consider the Lagrange Multiplier problem where we want to maximize $f(x,y) = x$ subject to $g(x,y) = y^2+x^4-x^3 = 0$ Now, setting up $\nabla f(x,y) = \lambda \nabla g(x,y)$, we obtain $$\langle 1, 0 \rangle = \lambda \langle 4x^{3}-3x^{2},2y \rangle \\ \implies \begin{cases} 1& = &\lambda(4x^{3}-3x^{2}) \\ 0 & = &\lambda 2y\end{cases} $$ However, I am confused about 3 things : 1) How to proceed at this point if $\lambda = 0$. 2) If $\lambda \neq 0$, then $y = 0$, and we must have both that $x^{4} - x^{3} = 0$ and $4x^{3}-3x^{2} = 0$. But, in the case where $x \neq 0$ here, we would have that both $x = 1$ and $x = 3/4$ at the same time, which we can't have. So, I'm assuming then that if $\lambda \neq 0$, then $(0,0)$ is the only critical point? 3) I was told that this problem is a case where the gradient of $g$ is trivial. Trivial as in $\nabla g(x,y) = (0, 0)$? How is it trivial? Because the only critical point is $(0,0)$? Also, this is supposed to be an example of what this article is talking about, but I'm not seeing it. Could someone please explain this to me? Thank you.","['multivariable-calculus', 'lagrange-multiplier', 'maxima-minima', 'calculus']"
2530638,Let $p(x)$ be a real $7$ degree polynomial with $p(\pi)=\sqrt 3$ and $\int_{-\pi}^{\pi}x^k p(x)=0$ for $0\le k\le 6$. Find $p(0)$ and $p(-\pi)$.,"Q.Let $p(x)$ be a real $7$ degree polynomial with $p(\pi)=\sqrt 3$ and $\int_{-\pi}^{\pi}x^k p(x)=0$ for $0\le k\le 6$. Find $p(0)$ and $p(-\pi)$. Let $p(x)=a_0 + a_1 x+ a_2 x^2+ a_3 x^3+...+a_7 x^7.$ Then we can approach this problem by evaluating the definite integral given in question for each $k$, therefore giving us $7$ equations in $8$ variables $a_0, a_1,...,a_7$. We get eighth equation by using given condition $p(\pi)=\sqrt 3$. This way we have $8$ equations with $8$ unknowns. We form following system of equations, $$
    \left(\begin{matrix}
    1 & 0 & \frac {{\pi}^2}3 & 0 & \frac {{\pi}^4}5 & 0 & \frac {{\pi}^6}7 & 0 \\
    0 & \frac 13 & 0 & \frac {{\pi}^2}5 & 0 & \frac {{\pi}^4}7 & 0 & \frac {{\pi}^6}9 \\
    \frac 13 & 0 & \frac {{\pi}^2}5 & 0 & \frac {{\pi}^4}7 & 0 & \frac {{\pi}^6}9 & 0 \\
    0 & \frac 15 & 0 & \frac {{\pi}^2}7 & 0 & \frac {{\pi}^4}9 & 0 & \frac {{\pi}^6}{11} \\
    \frac 15 & 0 & \frac {{\pi}^2}7 & 0 & \frac {{\pi}^4}9 & 0 & \frac {{\pi}^6}{11} & 0 \\
    0 & \frac 17 & 0 & \frac {{\pi}^2}9 & 0 & \frac {{\pi}^4}{11} & 0 & \frac {{\pi}^6}{13} \\
    \frac 17 & 0 & \frac {{\pi}^2}9 & 0 & \frac {{\pi}^4}{11} & 0 & \frac {{\pi}^6}{13} & 0 \\
    1 & \pi & \pi^2 & \pi^3 & \pi^4 & \pi^5 & \pi^6 & \pi^7 
    \end{matrix}\right)
\cdot 
    \left(\begin{matrix}
    a_0  \\
    a_1  \\
    a_2  \\
    a_3 \\
    a_4 \\
    a_5 \\
    a_6 \\
    a_7  \\
    \end{matrix}\right)=
    \left(\begin{matrix}
    0  \\
    0 \\
    0  \\
    0 \\
    0   \\
    0 \\
    0 \\
    \sqrt 3 \\
    \end{matrix}\right)$$
If we solve this system of equations, then we get the values of $a_i$s. This way we have identified the polynomial $p(x)$. Once we have identified the polynomial it is easy to calculate $p(0)$ and $p(-\pi)$. Note that $p(0)=a_0$. But this approach is very much lengthy. Is there a faster way?","['alternative-proof', 'contest-math', 'real-analysis', 'linear-algebra']"
2530649,Complex differential equation,"How do I solve
$$x'=e^{it}\overline{x}?$$ This is a complex differential equation, but I don't see how to solve it. Edit: the original ODE is given by
$$(x', y')=\begin{pmatrix}\cos t& \sin t\\
\sin t&-\cos t\end{pmatrix}(x,y)$$
I want to show that solutions of this ODE do not remain bounded for all $t$, and the idea was to solve the complex equation.","['complex-analysis', 'ordinary-differential-equations']"
2530680,"How to take the derivative of quadratic term that involves vectors, transposes, and matrices, with respect to a scalar","What are the proper steps to take the derivative with respect to $\alpha$ of $$\frac 1 2 (x - \alpha g)^T Q (x - \alpha g)$$ to get following? $$-(x-\alpha g)^T Q g$$ (where $\alpha$ is a scalar, $Q$ is a symmetric positive definite matrix, and $x$ and $g$ are vectors of proper size.) Background and further explanation: I saw this differentiation as part of a differentiation of a larger expression in Nocedal and Wright's book Numerical Optimization, just above (3.25). The authors skip explaining differentiation steps and obtain the minimizer $\alpha$, as that is their purpose. When I try to follow I see that the differentiation of this term must yield as above. Now my problem is, if I were to differentiate the term above I would not know that there would be a transpose there, or $Q$ would need to be in the middle. E.g. if everything were scalars the term would be $\frac 1 2 Q (x - \alpha g)^2$, and using the chain rule, I would obtain the derivative as $-Q(x-\alpha g)g$. Now that the vectors and transposes and matrices are involved, how should one apply the chain rule here properly?","['multivariable-calculus', 'derivatives']"
2530689,Non linear to linear differential equation,"Is there exist a non linear differential equation
$$
y'(t) = f(t,y(t))
$$
such that a change of variable $z=\varphi(t,y)$ leads to a linear differential equation ?","['vector-fields', 'change-of-variable', 'ordinary-differential-equations']"
2530694,Poincare map of this system,"Let $$x'=1+y-x^2-y^2$$
$$y'=1-x-x^2-y^2$$ How do I use the Poincare map to show that this has a not asymptotically stable solution? What I did: I transformed the system to polar coordinates
$$r'=(\cos\theta+\sin\theta)(1-r^2)$$
$$\theta'=(\cos\theta-\sin\theta)(1/r-r)-1$$
which has a periodic solution $(r,\theta)=(1,-t)$ or $f(t)=(x,y)=(\cos(t),-\sin(t))$. How do I find the Poincare map? And how do I show that $f(t)$ is not aymptotically stable? Edit: The original question gives the system as above and asks for an explicit periodic solution $f(t)$ (which I'm sure is the one I found above). Show that $f(t)$ is stable (but not asymptotically stable). What can you say about the Poincare map?","['ordinary-differential-equations', 'dynamical-systems', 'stability-theory']"
2530707,Reference request for Minimal Surfaces.,"I need books or articles based on minimal surfaces. By minimal surface, I mean a surface with 0 mean curvature. More specifically, I wish to explore the Plateau's Problem: There exists a minimal surface with a given boundary. I would also like to see a proof of the fact that a surface of revolution that is minimal is either a plane, helicoid or a catenoid. As a supplementary text, could I also have a reference for calculus of variations? (Unimportant, but why is calculus of variations not taught as a course in universities?) Thank you for your time.","['reference-request', 'calculus-of-variations', 'minimal-surfaces', 'differential-geometry']"
2530711,Area of cut-out of three circles,"Let three circles at different centers with different radii be given.
They might intersect as shown in the picture. How to derive the area of the set (blue) in terms of the centers and radii? Because of multiple overlappings formulas like this seem not to
be useful.","['circles', 'area', 'geometry']"
2530728,Variance of log Survival Odds,"I'm trying to undestand why $${Var}\left(\log\frac{\hat S(t)}{1-\hat S(t)}\right) \approx \frac{1}{\left(1-S(t)\right)^2}\sum_{i:Y_{(i)}\le t}\frac{d_i}{r_i(r_i-d_i)}$$ I know that by Greenwood formula:
$${Var}\left({\hat S(t)}\right) = {\left(\hat S(t)\right)^2}\sum_{i:Y_{(i)}\le t}\frac{d_i}{r_i(r_i-d_i)}$$ So I know how to get to second part by I don't see why: $$\log\left(\frac{\hat S(t)}{1-\hat S(t)}\right) \approx \frac{1}{\left(1-S(t)\right)^2}$$","['self-learning', 'statistics', 'probability']"
2530730,Find the minimum of the value $f=(1+\sin^2{x})(1+\sin^2{y})$,"Let $\tan{x}\tan{y}=-\frac{1}{2}$,find the minumin of the value $$f=(1+\sin^2{x})(1+\sin^2{y})$$ My ugly solution:
$$f=\dfrac{1+\sin^2{x}}{\sin^2{x}+\cos^2{x}}\cdot\dfrac{1+\sin^2{y}}{\sin^2{y}+\cos^2{y}}=\dfrac{2m^2+1}{m^2+1}\cdot\dfrac{2n^2+1}{n^2+1}$$where $m=\tan{x},n=\tan{y},mn=-\frac{1}{2}$,so 
$$f=2\cdot\dfrac{4m^4+4m^2+1}{4m^4+5m^2+1}=2\left(1-\dfrac{m^2}{4m^4+1+5m^2}\right)\ge 2\left(1-\dfrac{m^2}{4m^2+5m^2}\right)=\dfrac{16}{9}$$ some other simple methods?such as AM-GM and Cauchy-Schwarz inequality kill it?","['inequality', 'a.m.-g.m.-inequality', 'substitution', 'trigonometry', 'fractions']"
2530745,"Can Matrices be ""assigned"" to groups and be manipulated to determine the classification of the group.","I am writing a paper to introduce group theory through symmetry in molecules and group classification. How can (adjacency?) matrices represent molecules (abstract structure) and be used (through certain matrix operations) to deduce what symmetry/point group this molecule (or abstract structure) belongs to? Also, by interest (as a small extension) I am wondering whether adjacency matrices are applied in other areas than pure graph theory- do you have examples that I could investigate?
Thanks!","['graph-theory', 'matrices', 'adjacency-matrix', 'group-theory', 'discrete-mathematics']"
2530802,"Riesz representation theorem in $C^k([0,1])$","I'm trying to figure out the next exercise Let be $k\geq 1$ and $C^k([0,1])$ the banach space of all k-times differentiable function with the norm
  $$\lVert f\rVert_{k,\infty}=\sum_{i=0}^{k}\lVert f^{(i)}\rVert_{\infty}$$
  Show that $L\in (C^{k}([0,1]),\lVert\cdot\rVert_{k,\infty})^*$ iff exists $(\mu_0,...,\mu_k)$ radon measures in $[0,1]$ such that for all $f \in C^k([0,1])$ 
  $$L(f)=\sum_{i=0}^k\int f^{(i)}d\mu_i$$ Where  $(C^{k}([0,1]),\lVert\cdot\rVert_{k,\infty})^*$ is the dual space. There is a similar exercise in the Folland Chapter 7 exercise 27. But in this exercise I use de Taylor's formula, now I think that I can't. Any idea?","['riesz-representation-theorem', 'integration', 'measure-theory', 'dual-spaces']"
2530837,Intuitively understanding the purpose of Bayes' theorem for a $3/4$-probability truth-teller [duplicate],This question already has answers here : A man who lies a fourth of the time throws a die and says it is a six. What is the probability it is actually a six? (2 answers) Closed 6 years ago . The problem states: The probability of a man telling the truth is = $3/4$. He rolls a dice and claims he got a six. What is the probability that he actually got a six? And my textbook solves this using Bayes' theorem and gets $3/8$ as the answer. The way I'm looking at it is: The probability that he really got what he's claiming (a six) should be equal to the probability of him telling the truth which = $3/4$. Where am I going wrong here?,"['bayes-theorem', 'probability']"
2530839,"continuous, closed and surjective not open.","Above proof, [Topology, J.Munkres (Part 2 Algebraic topology)] I cannot show that the map $\pi: S^1\times I\to B^2$ given by $\pi(x,t)=(1-t)x$ is continuous, closed and surjective, but is not open. Any help?","['algebraic-topology', 'general-topology', 'retraction', 'continuity']"
2530861,Split conormal sequence in Kahler differentials. Where is the flaw in reasoning?,"Consider lemma 10.130.10 from this Stacks Project site . Lemma. Let $\alpha:R\to S,\pi:S\to T$ be two ring maps and assume that $\pi$ is surjective. If there is a $R$-linear $\iota:T\to S$ such that $\pi\circ\iota = 1_T$, then there is a following short split exact sequence of $T$-modules
  $$0\to I/I^2\to\Omega_{S/R}\otimes_S T\to\Omega_{T/R}\to 0,$$
  where $I=\ker(\pi).$ Assume that we have ring $K$ and two $K$-algebras $A,B$ and $K$-algebra homomorphism $\phi:A\to B.$ (Everything here is commutative, associated and unitial). In addition define 
$$\pi:B\otimes_K A\to B,\quad\iota:B\to B\otimes_K A$$ 
respectively by 
$$\pi(b\otimes a)=\phi(a)b,\quad \iota(b)=b\otimes 1.$$ 
We will now apply lemma to two cases: First : Let $\alpha:K\to B\otimes_K A$ be natural map form $K$-algebra structure of $B\otimes_K A.$ Then
$$0\to I/I^2\to\Omega_{(B\otimes_K A)/K}\otimes_{(B\otimes_K A)} B\to\Omega_{B/K}\to 0$$
is short split exact seqence of $B$-modules. Second : Let $\alpha:A\to B\otimes_K A$ be given by formula $\alpha(a)=\phi(a)\otimes 1.$ Then
$$0\to I/I^2\to\Omega_{(B\otimes_K A)/A}\otimes_{(B\otimes_K A)} B\to\Omega_{B/A}\to 0$$
is short split exact seqence of $B$-modules. Everything looks ok, but then we put $B=K$ then the first exact sequence degenerates to 
$$0\to I/I^2\to\Omega_{A/K}\otimes_A K\to 0$$
and the second one to 
$$0\to I/I^2\to 0.$$ However $\Omega_{A/K}\otimes_A K$ does not have to vanish in general. Question . Were is the flaw in the above reasoning?","['abstract-algebra', 'modules', 'algebraic-geometry', 'commutative-algebra']"
2530881,Prove a group of order $28$ with a normal subgroup of order $4$ is abelian without Sylow Theorems,"I have made some headway with the proof, but I can't quite finish it off. Please could I have some help? Please note that at no point are Sylow Theorems to be used during this proof. Let $G$ be a group such that $|G| =28$. We are given $H$, such that $|H|=4$, and $H$ is a normal subgroup of $G$. Previously, I have proven that $G$ must also contain a normal subgroup, $K$, where $|K|=7$. This was done without Sylow. I noticed that $H$ must be isomorphic to $C_4$ or $C_2\times C_2$ because these are the only groups of order 4, up to isomorphism. Since I'm trying to show $G$ is abelian, I guessed that $G$ will be $C_{28}$ or $C_2 \times C_{14}$. To try and show this, I started using the Direct Product Theorem. In either case of the identity of $H$, $H \cap K = e$, because $H$ will not contain any elements of order 7, and all the elements of $K$ are order 7 apart from the identity. Also, $H$ and $K$ are normal, so their elements commute with each other: For $h \in H$ and $k \in K$, $(khk^{-1})h^{-1} \in H$ and $k(hk^{-1}h^{-1}) \in K$ means $khk^{-1}h^{-1} = e$. But I cannot work out how to show any element of $G$ is the product of elements in $H$ and $K$. Should I perhaps consider the order of elements in $G$? When $H$ is $C_4$, $G$ will be $C_{28}$ and so must contain an element of order 28. Any help is very much appreciated.","['finite-groups', 'abstract-algebra', 'abelian-groups', 'group-theory']"
2530901,How many solution to an equation where 2 variables are odd and the 2 others are even,"Given the equation:
$$x_1+x_2+x_3+x_4=20$$ Find the number of solutions where: Where $x_i\ne7$ for all $i=1,2,3,4$. Where $x_i$ are odd, for $1\leq i\leq 4$ Where two variables are odd and two variables are even I solved the first two and got to: Please correct me if I am wrong The number of times where 7 is a variable in the solution = $4*D(3,13)=4*C(15,2)=420$ so the total number of solutions with no restrictions on the variables minus that is the solution so: $D(4,20)=C(23,3)=1771$ and $1771-420=1351$ is the solution . So to solve this I know that if I take this equation: $2x_1+2x_2+2x_3+2x_4=16$ every variable is even, and if I add 1 to the variables, we get that all variables are now odd and we got to the solution (20), so to simplify the equation: $x_1+x_2+x_3+x_4=8$ and now we only need to solve the number of solutions to this equation without any restrictions and we get $D(4,8)=C(11,3)=165$ And on the third problem, I don't really know how to approach it, I thought about using something similar like I used on the second problem, but ended up stuck, any hint on how to solve this? Thanks in advance.","['combinatorics', 'discrete-mathematics']"
2530921,Suppose $\sum |a_n|$ converges. Is it true that $\lim_{n\to\infty}n|a_n|=0$?,"Question : Suppose $\sum |a_n|<\infty$. Is it true that $\lim_{n\to\infty}n|a_n|=0$? Suppose not. Then for some $\epsilon>0$ and for every $N\in{\bf N}$, there exists $n\geq N$ such that
$$
|a_n|>\frac{\epsilon}{n}.
$$
This is far from enough to conclude that $\sum |a_n|=\infty$. I think there might be counterexamples to the statement. Other than this I don't see what could be useful here. Note that the monotonicity assumption has been dropped from this classical problem: Series converges implies $\lim{n a_n} = 0$","['real-analysis', 'sequences-and-series']"
2530935,Are all quadratics factorable into a product of two binomials?,"I'm learning algebra in school, and my teacher said that all quadratics are factorable into a product of two binomials. I then realized however that some quadratics would have imaginary roots, and therefore wouldn't be able to be put into factored form. Who's wrong here, my teacher or me? For example, can $x^2 + 4x + 1$ even be expressed in factored form? Thanks in advance.","['algebra-precalculus', 'polynomials', 'quadratics']"
2530944,Theory of floating point math,"We learn about groups, rings and fields in algebra - but floating point numbers (like double in many modern programming languages) do not form one of the above algebraic entities because they are not associative. Is there an algebraic theory behind these numbers?","['group-theory', 'floating-point']"
2530946,"Evaluate line integral $\int_c x\,dx+ y\,dy + z\,dz$, where $C$ is the straight line from $(1,0,0)$ to $(0,1,\pi/2)$","$ \displaystyle \int_c x\,dx+ y\,dy + z\,dz$, where $C$ is the straight line from
  $(1,0,0)$ to $(0,1,\pi/2)$ Parametric form of line will be: $$x=1 - t, \quad y= t, \quad z= \frac{\pi t} 2$$ The integral becomes $$\int_0^1 2t -1 + \frac{\pi^2t} 4  \, dt$$ but the final answer given in my book is $\pi^2/8$
which I am not getting by this.
So where am I making the mistake ?",['multivariable-calculus']
2530987,Solving this second order differential equation $m\frac{d^2x}{dt^2}+c\frac{dx}{dt}+k\sin{x}=0$,"I am investigating something in Physics and found out that I will have to solve this equation:
$$m\frac{d^2x}{dt^2}+c\frac{dx}{dt}+k\sin{x}=0$$ I haven't even learned how to solve ones that involve $kx$ and so I am very troubled by the $k\sin{x}$. Is this possible to solve? If so how could it be solved for $x$? Edit: I can't assume that $\sin{x}\approx x$ since I am investigating cases in which such an assumption is not applicable (at large angles of $x$)","['trigonometry', 'ordinary-differential-equations']"
2531008,Subextension of a field with Galois series of subextensions of prime degree,"Let $p$ be a prime number, and $E/F$ be a field extension. Suppose $E/F$ has a finite series of subfields $$
F = E_0 < E_1 < \cdots < E_n = E
$$ with $E_i / E_{i-1}$ Galois of degree $p$ for each $i$ . In this case, call $E/F$ special . Claim: If $K$ is an intermediate field of a special extension $E/F$ , then $K/F$ is also special. Things we know: $E/F$ has degree $p^n$ from multiplying the degrees of its subextensions, and so the degrees of $E/K$ and $K/F$ must also be $p$ -powers. $E/F$ is separable, since each extension $E_i / E_{i-1}$ is separable and separability is transitive. Then, $E/K$ and $K/F$ are also separable since transitivity also goes in the other direction. If in addition $K/F$ is normal, then the claim is very simple, since $K/F$ will then be Galois, and $\mathrm{Gal}(K/F)$ is then a $p$ -group. We can construct a normal series of $p$ -index subgroups in the Galois group, and then use the correspondence to bring them back to the desired series of fields between $F$ and $K$ . But, $K/F$ will not be normal in general (I think). The order of its automorphism group must divide the degree of the extension, so $\mathrm{Aut}(K/F)$ must still be a $p$ -group. We can still construct a normal series of $p$ -index groups in the automorphism group, but I don't think then we can bring them back to fields between $F$ and $K$ (indeed, if $|\mathrm{Aut}(K/F)| \neq [K : F]$ , then there will not be enough intermediate groups to bring back). Any tips would be appreciated.","['galois-theory', 'field-theory', 'p-groups', 'group-theory']"
2531033,Random splitting of a the unit square,"Consider the unit square $S=[0,1]^2$. Let us choose randomly a point $(x,y)$ in $S$ (uniformly over $S$) and consider the four triangles whose two vertices are a pair of consecutive vertices of $S$ and the third one is $(x,y)$. What is the expected area of the largest triangle?","['probability', 'geometric-probability']"
2531045,Resnick - Probability Path - Exercise 7.6,"I'm trying to solve this exercise: Suppose ${X_k,k \ge 1}$ are independent randon variables and suppose $X_k$ has a gamma density $f_k(x)$, $f_k(x)=\frac{x^{\gamma_k-1}\rm{e}^{-x}}{\Gamma(\gamma_k)}, x>0, \gamma_k>0$. Give necessary and sufficient conditions for $\sum\nolimits_{k = 1}^\infty  {{X_k}} $. to converge almost
  surely. (Compare with the treatment of sums of exponentially distributed
  random variables). I know $X_k \sim Gama(\gamma_k,1)$, then $E(X_k)=V(X_k)=\gamma_k$. So, by the theorem of Kolmogorov Convergence Criterion, we have:
If $\sum\nolimits_{k = 1}^\infty  {{V(X_k)}}< \infty $, then
$\sum\nolimits_{k = 1}^\infty  {[{X_k}-E(X_k)]}$ converges almost surely. Let $M$ such that $\sum\nolimits_{k = 1}^\infty  {[{X_k}-\gamma_k]} \to M $ converges almost surely. Thus, for $\sum\nolimits_{k = 1}^\infty  {\gamma_k}<\infty $   $\Rightarrow $ $\sum\nolimits_{k = 1}^\infty  {X_k}\rightarrow M+\sum\nolimits_{k = 1}^\infty  {\gamma_k}<\infty $ a.s. Therefore, can I say that is sufficient and necessary that $\sum\nolimits_{k = 1}^\infty  {\gamma_k}<\infty$? Or do I need to show the other side, like if $\sum\nolimits_{k = 1}^\infty  {{X_k}}$ converge a.s., then $\sum\nolimits_{k = 1}^\infty  {\gamma_k}<\infty$?","['probability-limit-theorems', 'probability-theory', 'probability-distributions', 'probability', 'measure-theory']"
2531077,Why would you want to change the order of integration on a double integral?,I know how to do it of course I am just wondering why it is done. Are some problems unsolvable without doing that or is it just to make it faster to solve?,"['multivariable-calculus', 'multiple-integral', 'real-analysis']"
2531090,Change of variables and circular solutions,"Consider the equations: $ \frac{dx}{dt} = y$  and  $ \frac{dy}{dt} = -x $ By transforming variables, obtain $ \frac{dr^2}{dt}=0 $ and $ \frac{d \theta}{dt} = -1$ I know that if I say let $r^2 =x^2 +y^2 \cdot \frac{dr^2}{dt} = tx \frac{2x}{dt} + 2y \frac{dy}{dt} =2xy =2xy-2xy = 0$, which would mean $r^2$ is neutrally stable, but I don't understand where this gets me, much less what a change of variables is. Moreover, what can one conclude about whether these are circular solutions, their direction, and their stability. I have not seen this mentioned before.","['stability-in-odes', 'ordinary-differential-equations', 'calculus']"
2531126,Expected value of stopped Brownian motion is $0$,Let $B_t$ be a Brownian motion. Let $\tau$ be a stopping time with $\mathbb E(\tau)< \infty $ Show that $\mathbb E(B_\tau)=0$ I know that since $B_t$ is a martingale we have $\mathbb E(B_{\tau \wedge n})=B_0=0$ but I can't see how I could use any covergence theorem to take the  limit into the expactation. Is this the right approach at all? Any ideas?,"['expectation', 'probability-theory', 'stopping-times', 'martingales', 'brownian-motion']"
2531191,Set has Measure Zero iff There is a Collection of Intervals,"I'm stuck on the following real analysis problem. Show that a set $E$ of real numbers has Lebesgue measure zero if and only if there is a countable collection $\{I_{k}\}_{k=1}^{\infty}$ of open intervals for which each point in $E$ belongs to infinitely many of the $I_{k}$'s and $\sum_{k=1}^{\infty}\ell(I_{k})<\infty$, where $\ell(I_{k})$ is the length of the interval $I_{k}$. I think the converse implication $(\Leftarrow)$ should be trivial by the definition of the Lebesgue measure, but I'm not sure. I also think that I should be using the Vitali Covering Lemma somewhere (possibly in the forward implication?). Thanks in advance for any help!","['real-analysis', 'lebesgue-measure', 'measure-theory']"
2531250,Calculating the volume of the unit ball in $\mathbb{R}^d$,How can I prove that: $$v_d= 2 v_{d-1} \int_{0} ^{1}(1-x^2)^{\frac{d-1}{2}}dx $$ without using polar coordinates. $v_d$ denotes the volume of the unit ball in $\mathbb{R}^d$,"['multivariable-calculus', 'real-analysis']"
2531256,"Given $f(x) =\begin{cases} x\sin(1/x) & x \neq 0,\\ 0 & x= 0, \end{cases} $ why is $f'(0)$ not zero?","When we use our standard product and chain rules for when $x$ not equal to $0,$ our derivative function works. But when $x=0,$ $f'(x)$ does not exist. But why can't we just use standard differentiation rule on $x=0$? Won't that mean $f'(0) = 0$?","['derivatives', 'real-analysis', 'limits', 'calculus', 'indeterminate-forms']"
2531259,Optimal partitioning of a graph,"I found the following problem in Graph Theory which states that: For every simple undirected graph, there is a way of partitioning the set of vertices in two blocks such that every vertex in a block has at least half of its neighbors in the other block. The solution I found was based on the idea that: if the partition is such that there is a maximum number of edges between the two blocks, than the partition satisfies the required property. I am not sure about the converse, but there was no need to have equivalence between the two properties in order to solve the problem. Also, the above solution provides a way of constructing such a partition (by starting with an arbitrary partition and moving vertices from one block to the other, when the vertices do not satisfy the property required for the partition). Is there an algorithmic approach to this problem to find ALL the partitions with the required conditions? Do you know if this has been studied somewhere in more detail?","['optimization', 'graph-theory', 'reference-request', 'discrete-mathematics']"
2531282,Confusion about differential of multivariable functions.,"I have been given a function $F: \mathbb{R²} \to \mathbb{R³}$ and another function $\beta: J \to \mathbb{R³}: t \mapsto F(a + tx)$ where $x = v_1(1,0) + v_2(0,1) = (v_1,v_2)$ and $a$ is fixed. we can assume that all given functions are differentiable on their domain. I'm asked to find $\beta'(0)$ (this should be equal to $D_1F(a)v_1 + D_2F(a)v_2$) My attempt: Let $R(t) = a+tx$ Then $\beta'(0) = D\beta(0) = D(F\circ R)(0) = DF(R(0)) \circ DR(0)$ and then I'm stuck.","['multivariable-calculus', 'derivatives']"
2531315,On the Riemann Sum Like of $L^{p}$ Functions,"If $f$ is a continuous function on $[0,1]$, then the following is clear: \begin{align*}
\lim_{n\rightarrow\infty}n\sum_{k=0}^{n-1}\left(\int_{k/n}^{(k+1)/n}f(x)dx\right)^{2}=\int_{0}^{1}f^{2}(x)dx,
\end{align*}
but that is also true for $L^{2}[0,1]$, I tried to approximate using mollifier but no help. And I wonder why the Hilbert space $L^{2}$ does matter, that is, does this also hold for any $L^{p}$ for $1\leq p<\infty$ for nonnegative function $f$:
\begin{align*}
\lim_{n\rightarrow\infty}n^{p-1}\sum_{k=0}^{n-1}\left(\int_{k/n}^{(k+1)/n}f(x)dx\right)^{p}=\int_{0}^{1}f^{p}(x)dx.
\end{align*}","['functional-analysis', 'real-analysis', 'measure-theory']"
2531349,Arithmetic mean converges almost surely,"I've been asked to show that, for a sequence of independent random variables $(X_n)$, if $$\mathbb{P}[\lim_{n\rightarrow \infty} \frac{1}{n}\sum_{k=1}^{n} X_k = 1] > 0$$ then
$$\frac{1}{n}\sum_{k=1}^{n} X_k \rightarrow 1$$ almost surely. I'm really not sure how to begin. I thought it might be possible with the Borel Cantelli lemma, but the sequence of sums is not an independent sequence, which is required in the statement. Any help would be appreciated.","['borel-cantelli-lemmas', 'probability-theory', 'martingales']"
2531355,How can one best visualize a measurable cardinal? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 4 years ago . Improve this question I've searched the web for several years attempting to find an intuitive and visualizable explanation of what measurable cardinals are and how best to conceive of them. All I've found are definitions. For example: a two-valued measure on a cardinal $\kappa$ , or more generally, on any set. A cardinal, $\kappa$ , can be described as a subdivision of all of its subsets into large and small sets such that $\kappa$ itself is large $\varnothing$ and all singletons $\{\alpha\}, \alpha \in \kappa$ are small Complements of small sets are large and vice versa The intersection of fewer than $\kappa$ large sets is again large​. I know what these various terms mean, but that doesn't help me: a. Visualize what a measurable cardinal looks like b. Know how one makes a measurable cardinal c. Understand how Ulam first ""discovered"" -- or ""invented""? -- them by working on the Lebesgue measure problem troubling everyone in the late 1920s d. Know whether they can all still be reached by some Beth cardinal, say Beth omega, or Beth c -- presumably not! e. Know why they have the amazing properties they do including that of being vastly larger than all of the inaccessible cardinals below them","['set-theory', 'measure-theory', 'large-cardinals']"
2531365,Computing limit of $\sqrt{n^2+n}-\sqrt[4]{n^4+1}$,"I have tried to solve this using conjugate multiplication, but I got stuck after factoring out $n^2$. $\begin{align}
\lim_{n\rightarrow\infty}\dfrac{n^2+n-\sqrt{n^4+1}}{\sqrt{n^2+n}+\sqrt[4]{n^4+1}}
&=\lim_{n\rightarrow\infty}\dfrac{n(1+\dfrac{1}{n}-\sqrt{1+\dfrac{1}{n^4}})}{\sqrt{1+\dfrac{1}{n}}+\sqrt[4]{1+\dfrac{1}{n^4}}}\\&
=\lim_{n\rightarrow\infty}\dfrac{n+1-n\sqrt{1+\dfrac{1}{n^4}}}{\sqrt{1+\dfrac{1}{n}}+\sqrt[4]{1+\dfrac{1}{n^4}}}
\end{align}$ Given that $\dfrac{1}{n}$ tends to $0$ (so denominator is 2), can I reduce $n$ and $-n\sqrt{1+\dfrac{1}{n^4}}$ and say that the limit is $\dfrac{1}{2}$? I mean $\dfrac{1}{n^4}$ tends to $0$, so $\sqrt{1+\dfrac{1}{n^4}}$ tends to $1$ and in this case $n-n\sqrt{1+\dfrac{1}{n^4}}$ can be simplified to $n-n$. Solution given in my book uses conjugate multiplication twice to get rid of all the roots in nominator, but I am curious if my answer is correct or my teacher will tell me that simplifying the way I did it is incorrect.","['real-analysis', 'limits', 'calculus', 'algebra-precalculus', 'analysis']"
2531380,Limit of a trig function. (Without using L'Hopital) [duplicate],"This question already has answers here : Limit without l'Hopital or Taylor series: $\lim\limits_{x \to 0} \frac{x\cos x- \sin x}{x^3}$ (3 answers) Closed 6 years ago . I'm having trouble figuring out what to do here, I'm supposed to find this limit: $$\lim_{x\rightarrow0} \frac{x\cos(x)-\sin(x)}{x^3}$$ But I don't know where to start, any hint would be appreciated, thanks!","['trigonometry', 'calculus', 'limits']"
2531457,Using Stokes's theorem to prove $curl(F) = 0 \implies F$ is conservative.,"A classical result from vector calculus says that if a vector field $F: \mathbb{R}^3 \to \mathbb{R}^3$ satisfies curl$(F) = 0$, then $F$ is conservative, i.e. $F = \nabla f$ for some $f: \mathbb{R}^3 \to \mathbb{R}$. I am curious about the following rough sketch of a proof of this fact, using Stokes's theorem: ""Proof:"" Recall that $F$ is conservative if and only if $\int_C F \cdot dr = 0$ for every closed curve $C$. To show the latter condition, let $C$ be any curve, and choose an oriented surface $S$ with $\partial S = C$(!). By Stokes's theorem, $\int_C F \cdot dr = \int_S \text{curl}(F) \cdot dS = \int_S 0 \cdot dS = 0.$ Thus $F$ is conservative. I am wondering how the formal details of (!) would go: namely, how does one show that any closed curve $C$ is the boundary of some oriented surface $S$? This seems intuitively obvious. I would be happy with a proof of this fact even under very nice assumptions on $C$, say if $C$ is a simple, closed, smooth curve. I haven't been able to find a reference for this, other than a parenthetical mention in Stewart's calculus, which says 'This can be done, but the proof requires advanced techniques.'","['differential-geometry', 'vector-analysis']"
2531474,Bernoulli's Second Problem - not the brachistochrone,"I had been reading up on the Brachistochrone problem, and what interested me was that Bernoulli actually put a second problem in his New Year's Day Programma. The Brachistochrone takes all the glory, but the following problem seems interesting: ``To find a curve such that the sum of the two segments $PK$ and $PL$, on a line drawn at random from a point $P$ to cut the curve in two points $K$ and $L$, though the two segments be raised to any power, is constant."" First, I am trying to even figure out what this is saying. So it seems necessary that the random line that is drawn through $P$ must intersect the curve at exactly 2 places, otherwise there's some ambiguity. Second, does the constant they speak of vary depending on the point $P$? This also seems necessary, but I could be confused based on the curve at hand. Third, assuming one understands the question, does anyone have a solution? Any helpful hints, comments, or clarifications would be most helpful in allowing me to satisfy my curiosity. Thanks!",['geometry']
2531534,Spring-mass function,"Here is the question that I'm stuck on: What is the smallest value of $b$ for which we
  get solutions that, when viewed in the position-velocity plane, lie along a straight line? Algebraically
  support your conclusion. I'm given Newton's Law of motion equation which is
$$ m \frac{d^2x}{dt^2}+b \frac{dx}{dt} + kx = 0$$ where $x$ is the position of an object (a block, for example) that's attached to the end of the spring, $m$ is the mass of the object, $b$ is the firction parameter (damping coefficient) and $k$ is the spring constant. I'm not sure how to approach the question that I imposed above, but I do know that $$\frac{dx}{dt} = y$$ where $y$ is the velocity. Also, I know that 
$$\frac{dy}{dt} = \frac{d^2x}{dt^2}$$ I could then re-write my  second order linear differential equation as a system of first order linear differential equations, which is $$\frac{dx}{dt} = y$$
$$\frac{dy}{dt} = -\frac{k}{m}x - \frac{b}{m}y$$ Even if the work above doesn't pertain to how to solve the problem, this is what I know so far.",['ordinary-differential-equations']
2531552,Counterexamples to gluing complexes of sheaves,"Background: I have read the claim that perverse sheaves behave more like sheaves than like complexes of sheaves.  This refers to the fact that they can be glued. For instance, suppose that $X$ is a complex analytic space and $P_1^{\bullet}, P_2^{\bullet}$ are perverse sheaves defined on the open sets $U_1, U_2$ respectively. Then if there exists an isomorphism $\alpha_{ij}: P_1^{\bullet}|_{U_1 \cap U_2} = P_2^{\bullet}|_{U_1 \cap U_2},$ then there exists a unique (up to canonical isomorphism) perverse sheaf $P^{\bullet}$ defined on $U_1 \cup U_2$ such that $P|_{U_i}$ is isomorphic to $P_i^{\bullet}.$ More generally, if one has an open cover $\{U_i\}$ of $X$ and perverse sheaves $P_i^{\bullet}$ of with isomorphisms on the overlaps $U_i \cap U_j$ satisfying the co-cycle condition, then this data glue in the usual way. My question: What goes wrong if one tries to glue ordinary complexes of sheaves?  Are there counterexamples showing that the gluing property cannot hold in $C^{\bullet}(Sh(X))$ (the category of sheaves on $X$) or in $D^b(X)$ (the bounded derived category of sheaves on $X$)?","['sheaf-theory', 'homological-algebra', 'algebraic-geometry']"
2531560,"prove :$ \frac{1}{1!}+\frac{1}{2!}+\frac{1}{3!}+...+\frac{1}{n!}< \frac{5}{2}-\frac{1}{n},\forall n\in \mathbb{N}^{*}$","prove :$ \frac{1}{1!}+\frac{1}{2!}+\frac{1}{3!}+...+\frac{1}{n!}< \frac{5}{2}-\frac{1}{n},\forall n\in \mathbb{N}^{*}$ i tried to do this with induction so i d like to know if what i did is correct:
for $n=1$  the statement is true since $1<\frac{5}{2}-1$ if the statement is true for for n we have :
 $\frac{1}{1!}+\frac{1}{2!}+\frac{1}{3!}+...+\frac{1}{n!}+\frac{1}{n+1!}< \frac{5}{2}-\frac{1}{n+1},\forall n\in \mathbb{N}^{*}$
which is true since as n gets larger the sum increases at a lower rate whereas the difference increases at a higher rate because the fraction gets smaller and smaller... so because the statement stands for n it will also stand for $n + 1$.","['real-analysis', 'inequality', 'sequences-and-series']"
2531566,Dynamical system with only one chain component,"Let $(X,d)$ be a compact metric space and $f:X\to X$ be a surjective map. A finite sequence $\{x_n\}_{n=0}^{k}$ is called $\varepsilon$-chain if $d(f(x_n), x_{n+1})<\varepsilon$ for $n=0, \ldots k-1$. We say that the point $x$ is chain recurrent if for every $\epsilon>0$, there is $\varepsilon$-chain $\{x_n\}_{n=0}^{k}$ with $x_0=x_k=x$; and denote by $R(f)$ el set of chain recurrent points. I am interested in the veracity of the following statement: If $R(f)$ is connected, then $X=R(f)$. I would greatly appreciate some counterexample or suggestion for the proof of it.","['general-topology', 'ordinary-differential-equations', 'dynamical-systems']"
2531567,On changing the order of summation between a finite sum and an infinite sum.,"Suppose that for every $j=1,...,t$ we have a convergent series of complex numbers $\displaystyle\sum_{m=0}^\infty a_j^m$. My question is: Is it true in general that $$\sum_{j=1}^t\left(\sum_{m=0}^\infty a_j^m\right)=\sum_{m=0}^{\infty}\left(\sum_{j=1}^ta_j^m\right)$$
  If not, under which extra conditions this can be true? Thank you very much for your help.","['fourier-series', 'complex-numbers', 'analysis']"
2531572,$ G \leq S_n$ transitive and n prime $\Rightarrow$ $n$ divides $ord(G)$,"I am doing a task and therefore I need to show the following: $ G \leq S_n$ transitive and n prime $\Rightarrow$ $n$ divides $ord(G)$ I think it's quite obvious, but I don't know, how to proof it formally right. Transitivity means that for all $x,y \in G$ exists $g \in G$ such that $x^g=y$, where $x^g$ denotes the conjugation $g^{-1}xg$.","['finite-groups', 'abstract-algebra', 'permutations', 'symmetric-groups']"
2531623,Gambler's ruin model,"In the gambler's ruin model, $X_n$ is a gambling player's fortune after the $n^{th}$ game, when making 1 dollar bets at each game. Also, for fixed $0<p<1$, we can find random variables $\{Z_i\}$ which are i.i.d. with $P(Z_i=1)=p$ and $P(Z_i=-1)=1-p$. So, we can set $$X_n=a+Z_1+Z_2+...Z_n$$ with $X_0 = a$. Suppose that $0<a<c$, and let $\tau_0=\inf\{n\ge0:X_n=0\}$ and $\tau_c=\inf\{n\ge0:X_n=c\}$ be the first hitting time of $0$ and $c$, respectively. The Question is, For the gambler's ruin model mentioned above, let $\beta_n=P(min(\tau_0,\tau_c)>n)$ be the probability that the player's fortue has not hit $0$ or $c$ by time $n$. (a) Find any explicit, simple expression $\gamma_n$ such that $\beta_n<\gamma_n$ for all $n \in N$, and such that $\lim_{n \to \infty}\gamma_n=0$. (b) Also, find any explicit, simple expression $\alpha_n$ such that $\beta_n>\alpha_n>0$ for all $n \in N$. I have no idea where to start to find $\gamma_n$ which is greater than $\beta_n$ for all $n$. For (b), I thought about $\alpha_n=P(\tau_0>n)$, the probability that player's fortune is not hitting $0$ by time $n$. But I'm not sure how to show $\beta_n>\alpha_n>0$ for all $n \in N$. Thanks for any help...","['stochastic-processes', 'probability-theory', 'probability', 'gambling']"
2531650,Are limits commutative?,"Generally speaking, is the following true:
$$\lim_{x\to a}f'(x)=\lim_{x\to a}\left(\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}\right)=\lim_{h\to 0}\left(\lim_{x\to a}\frac{f(x+h)-f(x)}{h}\right)$$","['real-analysis', 'limits']"
2531689,Generating function of square harmonic numbers,"During my study of generating functions, I was able to calculate the generating function of the sequence of harmonic numbers $H_n$:
$$\sum_{n=1}^\infty H_nx^n=\frac{\ln(1-x)}{x-1}$$
However, I also tried to find generating functions for $H_n^2$ and $H_n^3$, with which I was unsuccessful (the rearrangement method I used for the generating function of $H_n$ didn't reduce as nicely for $H_n^2$ and $H_n^3$). Any hints about how to find
$$\sum_{n=1}^\infty H_n^2x^n=\space ?$$
and
$$\sum_{n=1}^\infty H_n^3x^n=\space ?$$
Please don't write a full answer and spoil it for me - I just want a hint.","['generating-functions', 'summation', 'harmonic-numbers', 'sequences-and-series']"
2531720,Probability of flipping at least 2 heads when flipping a coin 100 times,"I tried using finding the contrary, that is the probability of getting 1 (100C1/2^100) heads and then 0 heads (100C0/2^100) and using the formula that P = 1 - P(b), where P(b) is the probability of the opposite. But when. I do P = 1 - ((100C1/2^100) + (100C0/2^100)), I get 1... which doesn't make any sense. So I'm not sure where I'm going wrong here.","['permutations', 'combinatorics', 'probability']"
2531747,Singularities of representation varieties,"Background: Fix an algebraically closed field $k$ and a group $\mathbb{G}$ which is algebraic over $k.$ Let $H$ be a discrete group. There is a functor from $k$-algebras to sets which sends $A \to Hom(H, \mathbb{G}(A)).$  This functor is representable.  Let $\mathcal{A}_H$ be the representative. Then $V_H:= Spec(\mathcal{A}_H)$ is called the representation scheme of the group $G.$ In general, this scheme can be non-reduced and singular. The GIT quotient $X_H:= V_H // \mathbb{G}^{ad}$ is called the character scheme. It is also in general non-reduced and singular. Finally, there is an open subscheme $X_H^0 \subset X_H$ whose $k$-points consist of irreducible representations. My question: I believe that $X_H^0$ can also be singular an non-reduced. However, I don't know any examples.   I would be interested in examples with any group $H$, and any algebraic group $\mathbb{G}.$ I would particularly interested in cases where $H$ arises as the fundamental groups of a $3$-manifold.","['low-dimensional-topology', 'representation-theory', 'group-theory', 'algebraic-geometry']"
2531759,"Question on ""Spivak's"" Theorem","I stumbled upon this Theorem here on pages 91 and 92 in the text. Check the complete Theorem there but it's basically this one. I am having trouble understanding two parts in the final step of the proof: $(1)$ Now, as $x \rightarrow a$ every point in the interval $[a,x]$ gets arbitrarily close to $x$ , so $$\lim_{x\to a}{c_x}=x$$ Wouldn't it be $\lim_{x\to a}{c_x}=a$ instead? $(2)$ Thus, $$f'_R(a)=\lim_{x\to a^{+}}\frac{f(x)-f(a)}{x-a}=\bbox[yellow]{\lim_{x\to a^{+}}f'(c_x)=\lim_{x\to a^{+}}f'(x)}=L$$ I'm not quite sure I follow that highlighted part, can someone enlighten me?","['real-analysis', 'limits']"
2531776,Domain issue on $\tan^{-1}(\frac{1}{x})$,"$$\int\arctan\left( \frac 1 x \right)\,dx$$ I used this method: Method 1 $u=\arctan(\frac{1}{x})$ and $du=-\frac{1}{1+x^2}\,dx$ $dv=dx$ and $v=x$ Then I get: $$x\tan^{-1} \left(\frac 1 x \right) + \int\frac{x}{1+x^2} \, dx$$ $$x\tan^{-1} \left(\frac 1 x \right)+\frac 1 2 \int\frac 1 u \, du$$ $$x\tan^{-1} \left(\frac 1 x \right) +\frac{\ln(1+x^2)} 2 + C$$ While integrating I realized that the function $\tan^{-1}(\frac{1}{x})$ does
not serve as a cofunction for $\cot^{-1}(x)$ , and it only does so for part of the domain. My Question Is there a cofunction using $\tan^{-1}$ that fits $\cot^{-1}$ domain completely?","['integration', 'calculus', 'functions']"
2531789,Volume of the unit ball through areas of spheres,"How can the following formula be proved? $$
|B_n| = \int_0^1 r^{n-1} \sigma_n \, dr = \frac{\sigma_n}{n}.
$$ Here, $|B_n|$ is volume of the unit ball in $\mathbb R^n$ and $\sigma_n$ is area of the unit sphere in $\mathbb R^n$. The expression under the integral represents area of the sphere with radius $r$.","['integration', 'analysis', 'geometry']"
2531793,Multivariate Calculus: continuous functions,"I was reading about continuity and i saw this problem as a exercise but I cannot find a way to prove it. Suppose that $f$ is continuous on a region and $f$ is different of zero, show that $f$ has only one sign. Thanks","['multivariable-calculus', 'real-analysis', 'continuity']"
2531810,Why does probability theory insist on sample spaces?,"When you open a textbook on probability theory it'll routinely start by setting up some 3-tuple $(\Omega, \mathcal{A}, \mathbb{P})$ and then defining random variables as functions of type $\Omega \rightarrow \mathbb{R}$. But unless you're actually contemplating the throwing of dice and coins you'll never actually bother with the sample space in practice. Instead you'll simply say ""let $X \sim \mathcal{N}(0,1)$..."". If a sample space is ever required, it'll just be reverse engineered to fit the desired distribution function. So then why all this fuss about sample spaces? Why not just define your measure on the real numbers straight up? Is it just to make the dice throwers happy?","['probability-theory', 'measure-theory', 'random-variables']"
2531913,"How to evaluate $\int^\infty_0 \log^2(x)\exp(-x)\,dx$","I attempted to solve this equation using integration by part, but it leads me no where and it gets too complicated to solve. I hope some can give me a hint how to approach this integral $$\int^\infty_0 \log^2(x)\exp(-x)\,dx$$ Thanks,",['calculus']
2531934,Inverse Trigonometry System of Equations,"$$2\tan^{-1}\left(\sqrt{x-x^2}\right) = \tan^{-1}\left(x\right)\: +\, \tan^{-1}\left(1-x\right)$$ I have a feeling solution includes drawing triangles but cannot make the leap to get the solution","['trigonometry', 'inverse']"
2532071,Mapping to unique nearest point,"In my class, we showed that if $B$ is closed in $\mathbb{R}$ and $A\subseteq\mathbb{R}$ and every $x\in A$ has the unique nearest point $f\left(x\right)$ of $B$, then $x\mapsto f\left(x\right)$ is continuous. My professor asked if we could find an arbitrary metric space $X$ (not necessarily with $X=\mathbb{R}$) where $A$ and $B$ (with $B$ not necessarily having to be closed now) have this same unique nearest point property, but $f$ is no longer continuous. I've been thinking about it for a couple of days now, but I haven't come up with any examples. If anyone could provide an example, I would greatly appreciate it.","['continuity', 'general-topology', 'metric-spaces']"
2532086,"Prove that $\int_0^{\pi} \sin^2 x\, dx = 2 \int_0^{\pi/2} \sin^2 x\, dx$ [duplicate]","This question already has answers here : Show that $\int_0^\pi f(\sin x)\,\mathrm{d}x = 2\int_0^{\pi/2}f(\sin x) \, \mathrm{d}x$ [closed] (4 answers) Closed 6 years ago . It can be observed that
$$\sin^2 \left( x + \frac{\pi}{2} \right) = \cos^2 (x)$$
Being the squared cosine an even function, the squared sine will be symmetrical as well, but with respect to $x = \pi / 2$. Are there any other approaches for this proof? Is there anything else that can be observed, hopefully about the $\sin^2 x$ function itself, without considering the space-shift $x + \pi / 2$ and the cosine?","['definite-integrals', 'trigonometry', 'trigonometric-integrals', 'calculus']"
2532103,Pointwise convergence in Holder space,"Throughout, we denote $C^\alpha$ for $\alpha \in (0,1]$ is the collection of real functions on the domain $[0,1]$ with Holder continuity of $\alpha$, i.e. if $f\in C^\alpha$, we have its norm 
$$|f|_\alpha = \sup_{[0,1]} |f| + \sup_{x\neq y \in [0,1]} \frac{|f(x) - f(y)|}{|x- y|^\alpha}$$ 
I want to know if the following claim is true, if not, a counter-example is desirable. [Claim 1] Let $|f_n|_\alpha <1$, and $\lim_n f_n(x) = 0$ for all $x\in [0,1]$. Then $f_n\to 0$ in $C^\alpha$. The following weaker result seems correct, please check. [Claim 2] Let $|f_n|_\alpha <1$, and $\lim_n f_n(x) = 0$ for all $x\in [0,1]$. Then $f_n\to 0$ in $C^\beta$ for all $\beta\in (0, \alpha)$ Proof of [Claim 2]. A bounded set in $C^\alpha$ is precompact in $C^\beta$. Thus, any subsequence has its own subsequence $f_{n_k} \to g$ in $C^\beta$. By pointwise convergence, we must have $g= 0$. QED","['functional-analysis', 'real-analysis']"
2532148,The Hahn-Banach Theorem for Hilbert Space,"The Hahn-Banach Theorem for Normed Space: Let $X$ be a real or complex normed space and let $W$ be a linear subspace of $X$ . If $f_W \in W'$ (the dual of $W$ ), then there exists an extension $f \in X'$ such that $\|f\|=\|f_w\|$ . How if I extend to a Hilbert Space?","['functional-analysis', 'real-analysis', 'hilbert-spaces', 'analysis']"
2532152,"Intuitively, what does it mean that two charts are compatible?","Let $(U, \phi), (V, \psi)$ two charts of the same manifold. We say that two charts are $C^\infty$-compatible if the following two maps
$$\phi \circ \psi^{-1} : \psi(U \cap V) \to \phi(U \cap V), \; \psi \circ \phi^{-1} : \phi(U \cap V) \to \psi(U \cap V)$$
are $C^\infty$. Can someone explain me what's the intuitive meaning of charts compatibility?","['manifolds', 'differential-geometry']"
2532187,"Lower bound on sizes of ""sum"" and ""product"" of a set of real numbers","The problem is like this: Let $A$ be a finite subset of $\mathbb{R}$. Define $A+B = \{ a+ b \mid a \in A,\ b \in B\}$ and $A\cdot B = \{a \times\ b \mid a\in A, \ b\in B\}$ Prove that $$|A+A|\cdot|A\cdot A| \ge \frac{1}{64}|A|^{\frac{5}{2}}$$ My attempts The only hint I have is to solve via probabilistic method. Another one is that $|A+A|$ is maximized when elements of $A$ in A.P and then $|A+A| \ge 2|A|-3$ and same for GP. But I could not use this property and the fact that it cant be an AP and GP simultaneously to show that their product is greater then what is to be proved. Any help would be appreciated.","['probabilistic-method', 'discrete-mathematics']"
2532206,Proving $\sum\limits_{r=1}^n \cot \frac{r\pi}{n+1}=0$ using complex numbers,"Let $x_1,x_2,...,x_n$ be the roots of the equation $x^n+x^{n-1}+...+x+1=0$. The question is to compute the expression $$\frac{1}{x_1-1} + \frac{1}{x_2-1}+...+\frac{1}{x_n-1}$$
  Hence to prove that $$\sum_{r=1}^n \cot \frac{r\pi}{n+1}=0$$ I tried rewriting the expression as $$\sum_{i=1}^n \frac{\bar{x_i}-1}{|x_i-1|^2}$$ I then used the fact that $$x^{n+1}-1=(x-1)(x^n+x^{n-1}+...+x+1=0$$ so $x_i$ are the complex nth roots of unity.Using cosine formula I found that $$|x_i-1|^2=2-2\cos(\frac{2i\pi}{n+1})=4(\sin \frac{\pi}{n+1})^2$$ After substituting this I couldn't simplify the resulting expression.Any ideas?Thanks.","['algebra-precalculus', 'trigonometry', 'complex-numbers']"
2532232,Interchange of integral and derivative,"I want to show for all $t\in \mathbb R$: 
$$\frac{d}{dt}\int_{\mathbb R} e^{-x^4 + tx^2}dx = \int_{\mathbb R}x^2e^{-x^4+tx^2}dx$$
Now once we justified the interchange of the differential operator and the integral it's easy to see.
Obviously $x \mapsto e^{-x^4 + tx^2} $ is differentiable for all $t\in \mathbb R$.
But I can't seem to find a suitable dominating integrable function $f(x)$ satisfying $$\forall t\in \mathbb R: \left \lvert \frac{\partial}{\partial t} e^{-x^4 + tx^2}\right \rvert = \left \lvert x^2 e^{-x^4 + tx^2}\right \rvert \leq f(x)$$
I assume we can split this into compact intervals and get an estimate for each fixed $t_0 \in \mathbb R$, but then our $f(x)$ depends on $t$. Any hints?","['real-analysis', 'integration', 'measure-theory', 'analysis']"
2532271,Order of study in mathematical analysis textbooks.,"I have just started studying mathematical analysis and, when choosing the books I was going to use, I realized that there is some levels of difficulty. I am very lost in the sense that I don't know which is the proper order of study. The idea I have right now is the next: 1: First course in Real Analysis (epsilon-delta approach): Here is where we can find those books on 1 real variable such as calculus (spivak), understanding analysis (Abbott), Analysis I (Terence Tao), A course in mathematical analysis I (Garling), Mathematical Analysis vol. I (V. Zorich), Introduction to Real analysis (Bartle)... 2: Second course (using concepts such as metric spaces..., multivariable calculus, vector calculus): Here we find books like The elements of Real Analysis (Bartle), Analysis in Euclidean Space (Hoffman), Rudin's PMA, Pugh's Real Mathematical Analysis, Apostol's Mathematical Analysis, Analysis II (Terence Tao), Mathematical Analysis vol. I (V. Zorich), other books in several variables (such as Lang's, Fleming's...), Real Analysis (carothers), some introductions to Lebesgue integration... 3: Intermediate-Advanced: Here we have those books with a hard content in Topology (metric spaces, topological spaces, Continuity, Compactness, Completeness, Connectedness, Convergence...) and Analysis in several variables using all these topological concepts(introduction to differential forms, vector analysis, analysis on manifolds...). Some books in this section are: A course in mathematical analysis II (Garling), Topology (munkres) and other books in Point-Set Topology (as well as books dealing exclusively with metric spaces or topological spaces), Foundations of Modern Analysis (J. Dieudonne), Introductory real analysis (Kolmogorov & Fomin), Mathematical Analysis vol.II (V. Zorich), Introduction to Topology and Modern Analysis (Simmons), calculus on manifolds (spivak), analysis on manifolds (munkres)... Advanced (measure theory, advanced analysis): Royden, Folland, Papa Rudin, others... This is the classification that I have in mind but it is correct ? I am just in the first level but, due to I am self studying the subject, I would like to know how to study all these topics in the most ordered possible way. Finally, I have 2 additional questions. Which are the main differences between the 2 books from Bartle ? (Introduction to real analysis and the elements of real analysis) When should I study each ? Is vector calculus the same than multivariable calculus (as seen in the second course) ? Is there 2 kinds of multivariable calculus (one studied in the second course and called 'vector calculus' and another in the intermediate course and called 'vector analysis' ? ) Thank you in advance.","['reference-request', 'real-analysis', 'analysis']"
2532305,Limit of uniformly convergent sequence of recursive integrals is differentiable?,"I have the sequence $(y_n)_{n\in\mathbb N_0}$ of functions
$$y_n\colon [0,\alpha] \to \mathbb R$$
defined recursively by
$$ y_{n+1}(x) = \int_0^x g\bigl(y_{n}(\xi)\bigr)\,d\xi,\qquad n\in\mathbb N $$
and the constant function $y_0(x)\equiv 0$. We know nothing about the function $g$, except that all those integrals always exist. Suppose we know that $(y_n)_{n\in\mathbb N}$ converges uniformly to a function $y^*$:
$$\|y_n - y^*\|\to0,\qquad(n\to\infty)$$
where $\|\bullet\|$ is the supremum norm on $[0,\alpha]$:
$$ \| y \| = \sup_{x\in [0,\alpha]} |y(x)|. $$ The question is: Can we prove that $y^*$ has to be differentiable? If I'd know that $y_n$ was always differentiable with $y_n'(x) = g\bigl(y_{n-1}(x)\bigr)$, then it would suffice to show that $(y_n')_{n\in\mathbb N}$ converges uniformely, but I don't really know anything about the convergence of $y_n'$, since I don't know anything about $g$? Would it be easier or at least doable if $g$ was continuous? This question arises, when you try to apply the Picard-iteration to the initial value problem
$$ y'(x) = g\bigl(y(x)\bigr),\qquad y(0) = 0, $$
where one does not have Lipschitz-continuity of $g$.
There is a similar exercise in the german standard textbook „Gewöhnliche Differentialgleichungen“ by Harro Heuser. It is Exercise III.12.5 in that book (at least in the fourth edition).","['uniform-convergence', 'recursion', 'integration', 'ordinary-differential-equations', 'analysis']"
2532306,An inequality by using general Hölder's inequality,"Let $w$ be a weight function and $\frac{1}{p}=\frac{1}{p_1}+\frac{1}{p_2}+\dots+\frac{1}{p_n}$. For suitable functions let $\overrightarrow{f}=(f_1,f_2,\dots,f_n)$ and operator $T$ satisifies the condition 
$$
T(\overrightarrow{f})(x)\leq \prod_{i=1}^{n}f_{i}(x).\tag{*}
$$
By using (*) and generalization of Hölder's inequality , I get
$$
\left(\int_{\mathbb{R}^n}|T(\overrightarrow{f})(x)w(x)|^pdx\right)^{\frac{1}{p}}\leq \left(\int_{\mathbb{R}^n}| \prod_{i=1}^{n}f_{i}(x)w(x)|^pdx\right)^{\frac{1}{p}}\leq \prod_{i=1}^{n}\left(\int_{\mathbb{R}^n}|f_{i}(x)|^{p_i}w(x)^pdx\right)^{\frac{1}{p_i}},
$$
where I apply Hölder's inequality  for the measure $d\mu(x)=w(x)^p$. But the paper which I read now writes this inequality as following
$$
\left(\int_{\mathbb{R}^n}|T(\overrightarrow{f})(x)w(x)|^pdx\right)^{\frac{1}{p}}\leq \left(\int_{\mathbb{R}^n}| \prod_{i=1}^{n}f_{i}(x)w(x)|^pdx\right)^{\frac{1}{p}}\leq \prod_{i=1}^{n}\left(\int_{\mathbb{R}^n}|f_{i}(x)w(x)|^{p_i}dx\right)^{\frac{1}{p_i}}.
$$
Which one is true?","['real-analysis', 'inequality', 'harmonic-analysis', 'functional-analysis', 'holder-inequality']"
2532347,smooth submersions and maps with local sections,"Let $M$ and $N$ be smooth manifolds and $\pi:M\rightarrow N$ be a smooth map. A local section of $\pi$ is a a smooth map $\sigma:U\rightarrow M$ defined on some open subset $U\subseteq N$ such that $\pi\circ\sigma=1_U$. I am reading about this from Lee's Introduction to smooth manifolds. It says the following : Many of the important properties of smooth submersions follow from the fact that they admit an abundance of smooth local sections. Local section theorem says the following : Suppose $M$ and $N$ are smooth manifolds and $\pi:M\rightarrow N$ is a smooth map. Then, $\pi$ is a smooth submersion if and only if every point of $M$ is in the image of a smooth local section of $\pi$. I was trying to prove this on my own. Let $p\in M$. As $\pi:M\rightarrow N$ is a smooth submersion, it is in particular of constant rank $n$ (dimension of $M$ is $m$, dimension of $N$ is $n$). So, constant rank theorem says that given this $p$, there exists chart $(U,\varphi)$ cetered at $p$ and a chart $(V,\psi)$ centered at $q=\pi(p)$ such that $$\psi\circ \pi\circ \varphi^{-1}:\varphi(U)\subseteq \mathbb{R}^m\rightarrow \psi(V)\subseteq \mathbb{R}^n$$ is of the form
$$(x_1,\cdots,x_n,x_{n+1},\cdots,x_m)\mapsto (x_1,\cdots,x_n).$$ This map $\mathbb{R}^m\rightarrow \mathbb{R}^n$ given by $(x_1,\cdots,x_n,x_{n+1},\cdots,x_m)\mapsto (x_1,\cdots,x_n)$ have so many  global sections, one of which is the map $$\eta:(x_1,\cdots,x_n)\mapsto (x_1,\cdots,x_n,0,\cdots,0)$$ It is natural to expect that this gives a local section of $\pi$. Lee's proof also ends with this line saying some map whose coordinate representation is $$(x_1,\cdots,x_n)\mapsto (x_1,\cdots,x_n,0,\cdots,0)$$ a local section of $\pi$. But, I want to construct the map $V\rightarrow M$ that is a local section of $\pi$. One choice would be to consider $$\varphi^{-1}\circ \eta\circ \psi:V\rightarrow \psi(V)\subseteq \mathbb{R}^m\rightarrow \mathbb{R}^n\rightarrow U.$$
 Only problem here is why would $\eta(\psi(V))\subseteq \varphi(U)$. How do I change the map so that we have composition as said above. Assuming we have made a small change for above composition, we can see that this is actually a section (in terms of set maps for now). We need to prove that $\pi\circ(\varphi^{-1}\circ \eta\circ \psi)$ to be identity on $V$.
We have $$\psi\circ(\pi\circ(\varphi^{-1}\circ \eta\circ \psi))
=(\psi\circ\pi\circ\varphi^{-1})\circ(\eta\circ \psi)$$
Let $q\in V$ and $\psi(q)=(x_1,\cdots,x_n)$. Then,
$$\psi\circ(\pi\circ(\varphi^{-1}\circ \eta\circ \psi)(q))
=(\psi\circ\pi\circ\varphi^{-1})\circ(\eta\circ \psi)(q)
=(\psi\circ\pi\circ\varphi^{-1})\circ(\eta(x_1,\cdots,x_n))$$
$$=(\psi\circ\pi\circ\varphi^{-1})(x_1,\cdots,x_n,0,\cdots,0)
=(x_1,\cdots,x_n)=\psi(q)$$
As $\psi$ is injective, we have 
$$\pi\circ(\varphi^{-1}\circ \eta\circ \psi)(q)=q$$
for all $q\in V$. Thus, $\varphi^{-1}\circ \eta\circ \psi$ is a local section of $\pi$. Any suggestions regarding how to modify $\varphi^{-1}\circ \eta\circ \psi$ 
is welcome. I do not understand why in the book author did not explicitly write down the map. Is it only about the existence?","['smooth-manifolds', 'differential-geometry']"
2532351,Convexity of a functional on a Sobolev space,"Denote a specific Sobolev space by
$$W^{2,2}(a,b) = \left\lbrace x\in L_2(a,b) : x'\in AC[a,b],\quad x''\in L_2(a,b) \right\rbrace $$
where $AC[a,b]$ is the class of absolutely continuous functions on $[a,b]\subset\mathbb R$. Given smoothing problems in the context of theory of splines (and, as I've witnessed, in statistics) the objective is to minimize the following expression over all $f\in W^{2,2}$:
$$M(f) := \left [ \sum_{j=0}^n w_j(f(x_j)-y_j)^2 + \int_a^bf''(x)^2w(x)dx\right ]^{1/2} $$
where $x_0<x_1<\ldots <x_n$ (in $[a,b]$), $w,w_j>0$ (weights) and $y_j\in\mathbb R$ are provided and then the (unique?) minimizer of $M$ is christened the smoothing spline. What about the functional $M : W^{2,2}\to\mathbb R$ itself, though? Is it, perhaps, convex? Even strictly convex? Specifically, for convexity:
$$\forall u,v\in W^{2,2}, \forall t\in (0,1), M(tu +(1-t)v)\overset{?}\leq tM(u)+(1-t)M(v).$$
Strict convexity means that whenever $u\neq v$ the inequality is strict. I haven't been able to find any discussion on this particular property of $M$ and it doesn't seem all that obvious either. A thought. Perhaps, we could obtain
$$M^2(tu+(1-t)v)\leq t^2M^2(u)+(1-t)^2M^2(v) $$
and state that perhaps $2t(1-t)M(u)M(v)>0$ for $u\neq v$. That won't work. If $u = 0$ with $y_j\equiv 0$, then $M(u) = 0$ and at the same time
$$M((1-t)v) = (1-t)^2M(v)< (1-t)M(v), $$
since $0<t<1$, provided $M(v)>0$.","['optimization', 'spline', 'functional-analysis', 'lebesgue-integral', 'functional-inequalities']"
2532362,How to calculate $\lim_{x \to 0}\frac{x^2 - \tan^2(x)}{x^4}$ [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question How do I calculate $\lim_{x \to 0}\frac{x^2 - \tan^2(x)}{x^4}$? I just need a hint, not the entirely solution. Thank you in advance!","['taylor-expansion', 'limits', 'trigonometry', 'calculus', 'analysis']"
2532386,"If $P,Q\ge 0;P+Q=I$, how to prove $||P-Q||_2\le1$","We define $$\|A\|_2=\max_{x\ne0}\frac{\|Ax\|_2}{\|x\|_2}$$ as the matrix norm (Spectral Norm, http://mathworld.wolfram.com/SpectralNorm.html ). If $P,Q$ are definite symmetry matrices and $P+Q=I$. How to prove that $$\|P-Q\|_2\le1$$ My thinking: In fact, from $P+Q=I$, we can conclude that each pair eigenvalue of P and Q are sum up to 1. As a result, their eigenvalue are all less than 1. But what's the next step to say that $\|P-Q\|_2\le1$?","['matrices', 'eigenvalues-eigenvectors', 'spectral-theory', 'matrix-calculus']"
2532389,"If a segment of length 1 is randomly divided into n intervals, with what probability are all intervals are less than 1/k?","If $n-1$ points are chosen at random on a line segment of length $1$ (with uniform distribution), thus dividing it into $n$ segments, what is the probability that no segment has a length greater than $1/k$? I've gotten this far as of now-
For $k=2$, only one segment can be greater than $1/2$, so, the probability is just 1 - n times the probability of first segment being of length greater than $1/2$.
so $P = 1-(n/2^{n-1})$","['combinatorics', 'probability', 'probability-distributions']"
2532397,Calculate height of triangle given angle and base,I need to calculate the height of $x$ in my triangle and I know the base as well as the inner angles. I've used the following equation to try calculate it based off this answer here: How do you find the height of a triangle given $3$ angles and the base side? Image given. The equation that I got based off that answer was this: $$x = \frac{1000  \sin(90)  \sin(5)}{  \sin(85)}$$ this gives me a value of around $4000$ which can't be right so not sure where i've gone wrong here?,"['trigonometry', 'triangles']"
2532413,Theorem 2.8 in baby Rudin alternative proof,"The theorem says that ""every infinite subset of a countable set A is countable"". In order to prove this Rudin creates a 1-1 mapping of $J= (1,2,3,...)$ onto $E$ which is the subset in question $(E\subset A)$. But I'm wondering if there is a way to create a bijection like this $f:A \rightarrow E $ to show that $A \sim E$ and since $A \sim J$ then from Definition 2.3 it follows that $E \sim J$. It was proposed by a friend of mine, saying that we can use the common elements of $A$ and $E$, but I don't really see how to construct such a function. Can somebody come up with the idea or prove that there is no such fuction possible, which is also fine for me. Thank you in advance!","['real-analysis', 'elementary-set-theory']"
2532427,Formula for CircumRadius,"The formula for the circumradius $r$ of a triangle $ABC$ tells me that $r={abc\over{}4\triangle}$, where the lengths of the sides are $a$, $b$, $c$. I'm not sure, but I occasionaly got wrong values. They might have been calculation mistakes, but then I got fixated on deriving the formula for myself. So, I took a triangle $ABC$, circumcenter $R$. I know that: $RA=RB=RC$ Altitudes from $R$ to sides bisect those sides. Side $AB$ was divided into two parts each of length $c$, $BC$ into two of $a$, and $AC$ into two of $b$. Let the altitudes to $BC$ be of length $h_1$, to $AC$ be of length $h_2$, and to $AB$ of length $h_3$. So, using the Pythagorean Theorem, $\begin{align}r^2&=a^2+h_1^2\\r^2&=b^2+h_2^2\\r^2&=c^2+h_3^2\end{align}$ Since I know $a,b,c$, I have four variables, namely $r,h_1,h_2,h_3$. But since I have only three equations, I am unable to solve. I have tried many times, yet I cannot find any other relations.  So my primary problem is to find the fourth equation . Please help.","['circles', 'trigonometry', 'euclidean-geometry', 'triangles', 'geometry']"
2532488,Matrices restricted to a subspace,"Let $Q$ be an $n\times n$ stochastic matrix. Let $\mathcal S$ be the following subspace of $\mathbb R^n$ : $$\mathcal S:=\left\{x\in\mathbb R^n: \sum_{i=1}^nx_i=0 \right\}\, .$$ In a paper that I'm reading, there is a concept that I do not know: the restriction of $Q$ to $\mathcal S$ , (denoted by $Q|_{\mathcal S}$ ). What does it mean? For example, if I have a given matrix $Q$ , how could I calculate $Q|_{\mathcal S}$ ?",['linear-algebra']
2532512,Number of 8-digit Passwords with at least 1 digit and/or 1 symbol,"I think I know how to calculate the number of 8-digit passwords with 1 digit or 1 symbol.
The sets are lowercase (26), uppercase (26), symbols (32), digits(10). That means there are $(26 + 26 +32 + 10)^8 = 94^8$ total passwords and I just have to remove the all letter combinations $(52)^8$, so $94^8 - 52^8$. For the number of passwords with a digit and a number, I am confused. All Combos: $94^8$ All Letters: $52^8$ Letters + Digits: $62^8$ Letters + Symbols: $84^8$ I think I need inclusion/exclusion. I know that I am removing too many numbers, if I just subtract $94^8 - 52^8 - 62^8 - 84^8$, but I'm not sure how to build the intersections.","['inclusion-exclusion', 'combinatorics', 'discrete-mathematics']"
2532613,Is $PGL_n(\mathbb{Q})=PGL_n(\mathbb{Z})$?,"Since $PGL_n(\mathbb{Q})=GL_n(\mathbb{Q})/Z(GL_n(\mathbb{Q}))$, I think I should be able to clear denominators in any matrix in $PGL_n(\mathbb{Q})$ to get a matrix in $PGL_n(\mathbb{Z})$. But then I am confused, because each embedding $\mathbb{Q} \hookrightarrow \mathbb{Q}_p$ induces an injective homomorphism $PGL_n(\mathbb{Q}) \rightarrow PGL_n(\mathbb{Q}_p)$. By my reasoning, the image would be in $PGL_n(\mathbb{Z}_p)$ which doesn't seem right, but I don't see the gap in my reasoning. Could someone clarify?","['group-theory', 'p-adic-number-theory']"
2532635,How many uncountable subsets of power set of integers are there?,"The question is to determine how many uncountable subsets of ${P(\mathbb Z)}$ are there. I think that the answer is $2^c$. Let $A=\{B\in P(P(\mathbb Z)):B \text{ is uncountable}\}$ $P(P(\mathbb Z))$ has $2^c$ elements, so cardinality of $A$ is at most $2^c$. Of course, I'm having trouble with the lower bound and I'm trying to find an injective function from some set of cardinality $2^c$ into $A$. If anybody has any idea, I'd be very grateful!",['elementary-set-theory']
2532686,If $S$ is homeomorphic to a torus $\Rightarrow$ $S$ has a differentiable vector ﬁeld without singular points,"I'm studying differential geometry using doCarmo's book, and in the chapter about Gauss-Bonnet's theorem, I got stuck in the following exercise: Let $S \subset \mathbb{R}^3$ be a surface homeomorphic to the torus
  $\Rightarrow$  $S$ has a differentiable vector ﬁeld without singular
  points. I know that if $\xi:S \rightarrow TS$ is a differentiable field with only finite  singular points (I know that I can always construct this field) $$0= \sum_{\{x \in S;\xi(x) = 0\}} I_x = \chi (S) $$ where $I_x$ is the index of $\xi$ in the point $x$, and $\chi(S)$ is the Euler characteristic of the surface $S$. But I don't know how to use this information to build a differential vector field without singular points.","['vector-fields', 'riemannian-geometry', 'smooth-manifolds', 'differential-geometry', 'surfaces']"
2532711,Are these mixed partial derivatives equal?,"Let's say I have a set of $m$ functions depending on $n$ variables
$$x^{i} = x^{i}(s^{1}, ... , s^{n})$$
I use latin indices to denote $(1, ..., m)$ and greek letters to denote $(1, ..., n)$. I know
$$\frac{\partial x^{i}}{\partial x^{j}} = \delta^{i}_{j}$$
$$ \implies \frac{\partial^{2} x^{i}}{\partial s^{\alpha} \partial x^{j}} = \frac{\partial (\delta^{i}_{j})}{\partial s^{\alpha}} = 0$$ What I'd like to know is whether commutativity of partial derivatives allows me to do this: $$\frac{\partial^{2} x^{i}}{\partial x^{j} \partial s^{\alpha}} = \frac{\partial^2 x^{i}}{\partial s^{\alpha} \partial x^{j}} = 0$$ And if I'm not allowed to do so, why? Thanks a lot, and I'm sorry if it is a silly question. Edit: For example, I get troubles when I'm in the simplest case, $m=1, n=1$.
Let's say $x=s^2$
$$\frac{dx}{dx}=1$$
$$\implies \frac{d}{ds}\left( \frac{dx}{dx} \right) = 0$$ But when I do it in the opposite order: $$\frac{dx}{ds}=2s$$ $$\implies \frac{d}{dx}\left( \frac{dx}{ds} \right) = \frac{d}{dx}\left( 2s \right)$$
substituting $s = \sqrt{x}$
$$\frac{d(2s)}{dx} = \frac{d(2\sqrt{x})}{dx} = \frac{1}{\sqrt{x}} = \frac{1}{s}$$ What am I doing wrong?","['multivariable-calculus', 'partial-derivative', 'coordinate-systems']"
2532830,Theory of ordinary differential equations - challenging problem (partially solved) - request for help,"Preliminary notation: $\wedge$ - logical ""and"", $J$ - bessel function of I kind, $Y$-bessel function of II kind Problem: a) Solve: $\frac{d^{2}y}{dx^{2}} - [\frac{p(p+1)}{x^{2}} + c]y = 0$ $(\star)$ $(c, p \in \mathbb{R}$, $x \in \mathbb{R} \setminus \{0\}$)  and distinguish bounded solutions for this equation in the neighbourhood of $x=0$. My partial solution(a.k.a. what I did by far): Let: $A:=c$ $\wedge$ $B:=p(p+1)$. Then: $(\star)$ is equivalent to: 
$$ x^{2}\frac{d^{2}y}{dx^{2}}-(Ax^{2}+B)y=0 $$ This equation is recognised as Bessesl differential equation. We proceed as follows: Consideration of given algebraic form of coefficients of dependent variable $y$ implies existence of the solution in the form of general power series in the surrounding of $x=0$. Let's apply Frobenius method. Let: $y=y(x)=x^{\rho}\sum\limits_{n=0}^{+\infty}a_{n}x^{n}$ ($a_{0} \in \mathbb{R} \setminus \{ 0 \}$ $\wedge$ $\mid x \mid < +\infty$ $\wedge$ $\rho \in \mathbb{R}_{+}$). Then:
$y^{'}(x) = \sum\limits_{n=0}^{+\infty}(n+\rho)a_{n}x^{n+\rho-1} = x^{\rho} \sum\limits_{n=0}^{+\infty}(n+\rho)a_{n}x^{n-1}$ $\implies$ $y^{''}(x) = \sum\limits_{n=0}^{+\infty}(n+\rho)(n+\rho-1)a_{n}x^{n+\rho-2}$   $\implies$ $x^{2}y^{''}(x) = x^{\rho}\sum\limits_{n=0}^{+\infty}(n+\rho)(n+\rho-1)a_{n}x^{n}$ $\implies$ $x^{2}\frac{d^{2}y}{dx^{2}}-(Ax^{2}+B)y = 0$ $\iff$ $x^{\rho}\sum\limits_{n=0}^{+\infty}(n+\rho)(n+\rho-1)a_{n}x^{n} - (Ax^{2}+B)x^{\rho}\sum\limits_{n=0}^{+\infty}a_{n}x^{n} = 0$ $\implies$ $\sum\limits_{n=0}^{+\infty}(n+\rho)(n+\rho-1)a_{n}x^{n} - A\sum\limits_{n=0}^{+\infty}a_{n}x^{n+2} - B\sum\limits_{n=0}^{+\infty}a_{n}x^{n} = 0$ $\implies$ $\sum\limits_{n=0}^{+\infty}(n+\rho)(n+\rho-1)a_{n}x^{n} - \sum\limits_{n=2}^{+\infty}Aa_{n}x^{n} - \sum\limits_{n=0}^{+\infty}Ba_{n}x^{n} = 0$ $\implies$ 
$[\rho(\rho - 1)-B]a_{0} + [(1 + \rho)\rho - B]a_{1}x + \sum\limits_{n=2}^{+\infty}\Big\{ [(n+\rho)(n+\rho-1)-B]a_{n} - Aa_{n-2}\Big\}x^{n} = 0$ $\implies$  $\implies$
$\begin{cases}
\rho(\rho-1)-B=0 \\
[(1+\rho)\rho-B]a_{1}=0 \\
[(n+\rho)(n+\rho-1)-B]a_{n}-A a_{n-2} = 0
\end{cases}$ $\implies$ 
$\begin{cases}
B=\rho(\rho-1) \\
[(\rho+\rho^{2})-(\rho^{2}-\rho)]a_{1}=0 \\
a_{n} = \frac{A}{[(n+\rho)(n+\rho-1)-B]}a_{n-2}
\end{cases}$ $\implies$ 
$\begin{cases}
B=\rho(\rho-1) \\
2\rho a_{1} = 0 \\
a_{n} = \frac{A}{[(n+\rho)(n+\rho-1)-B]}a_{n-2}
\end{cases}$ $\implies$ 
$\begin{cases}
B=\rho(\rho-1) \\
a_{1} = 0 \\
a_{n} = \frac{A}{[(n+\rho)(n+\rho-1)-B]}a_{n-2}
\end{cases}$ $\implies$ 
$\begin{cases}
B=\rho(1-\rho) \\
\forall n \in \mathbb{N}_{0}: a_{2n+1}=0 \\
\forall n \in \mathbb{N}: a_{2n} = \frac{A}{[(2n+\rho)(2n+\rho-1)-B]}a_{2n-2}
\end{cases}$ ;
$\rho(\rho-1)-B=0$ $\iff$ $\rho^{2}-\rho-B = 0$. $\Delta = 1+4B$. $\rho = \frac{1\pm \sqrt{1+4B}}{2}$ $\implies$ $\rho = \frac{1+\sqrt{1+4B}}{2}$ $\implies$ $\forall n \in \mathbb{N}$: $a_{2n} = \frac{A}{[(n+\frac{1+\sqrt{1+4B}}{2})(n+\frac{1+\sqrt{1+4B}}{2}-1)-B]}a_{2n-2}$ $\implies$ $\forall n \in \mathbb{N}$: $a_{2n} = \frac{A^{n}}{\Big{[} \prod\limits_{k=0}^{n}(2k+\frac{1+\sqrt{1+4B}}{2})(2k+\frac{1+\sqrt{1+4B}}{2}-1)-B\Big{]}}a_{0}$ 
$\implies$ $y_{1}(x) = a_{0}\sum\limits_{n=0}^{+\infty}\frac{A^{n}x^{2n}}{ {\Big{[} \prod\limits_{k=0}^{n}(2k+\frac{1+\sqrt{1+4B}}{2})(2k+\frac{1+\sqrt{1+4B}}{2}-1)-B\Big{]}}} = \sqrt{x}J_{\frac{1}{2}\sqrt{1+4B}}(-i\sqrt{A}x)$ 
$\rho_{1} = \frac{1+\sqrt{1+4B}}{2}$ $\wedge$ $\rho_{2} = \frac{1-\sqrt{1+4B}}{2}$ $\implies$ $\rho_{1} - \rho_{2} = \sqrt{1+4B}$ $\implies$ $y_{2}(x) = b_{0}\sum\limits_{n=0}^{+\infty}\frac{(-1)^{n}A^{n}x^{2k-\sqrt{1+4B}}}{{\Big{[} \prod\limits_{k=0}^{n}(2k+\frac{1+\sqrt{1+4B}}{2})(2k+\frac{1+\sqrt{1+4B}}{2}-1)-B\Big{]}}} = \sqrt{x}Y_{\frac{1}{2}\sqrt{1+4B}}(-i\sqrt{A}x)$ \
$\implies$ $y(x) = C_{1}y_{1}(x) + C_{2}y_{2}(x)=C_{1}\sqrt{x}J_{\frac{1}{2}\sqrt{1+4B}}(-i\sqrt{A}x) + C_{2}\sqrt{x}Y_{\frac{\sqrt{1+4B}}{2}}(-i\sqrt{A}x)$  [$C_{1},C_{2} \in \mathbb{R}$ $\wedge$ $A:=c$ $\wedge$ $B:=p(p-1)$: $c,p \in \mathbb{R}$] I checked my solution with mathematical package Maple and it turned out that I obtained correct result. Note: I know that the solution can be expressed in more concise way by using Bessel function of III kind(a.k. Hankel function) What is my problem: I do not know how to distinguish bounded solutions in the neighbourhood of $x=0$. I got stuck here completely. My request Since I did a significant work, I do very request for help in the determination of the aforementioned bounded solution of the considered equation in the neighbourhood of x=0. Help very appreciated!","['real-analysis', 'special-functions', 'contest-math', 'ordinary-differential-equations', 'analysis']"
2532853,Expected value of exit time of Brownian motion,"Let $B_t$ be $n$-dimensional Brownian motion. Let $\tau$ be the stopping time $\tau=\inf(t\in \mathbb R_+: |B_t-x| \ge r)$ with $x \in \mathbb R^n $ and $r>0$  i.e. the first exit time from a ball with radius $r$ around some point $x$.
Assume we already know $\mathbb E(\tau)<\infty$ Show $\mathbb E(\tau)=\begin{cases}
\frac{r^2-|x|^2}{n},  & \text{$|x|<r$} \\
0, & \text{else}
\end{cases}$ I was already able to show that $\mathbb E(\tau)=\frac 1 n \mathbb E(|B_\tau|^2)$ but I don't know how to compute $\mathbb E(|B_\tau|^2)$. 
I am used to hitting times where I can simply plug in the value for the stopped process but I am not sure what to do here. I can show the case where it equals $0$ but what about the other? It makes sense that it will be $r^2-|x|^2$ but what would be the right way to show this?","['expectation', 'probability-theory', 'stopping-times', 'martingales', 'brownian-motion']"
2532961,Computing: $\lim\limits_{n\to\infty}\sum\limits_{k=1}^{\infty} \frac{n}{nk^2+k+1}$,"I would like to find an equivalence at infinity  to the following sequence. $$C_n= \sum_{k=1}^{\infty} \frac{n}{nk^2+k+1}$$ Here are the given questions 1-Find the $\lim_{n\to\infty}C_n$ 2- If the limit blows up give an equivalence at infinity. For the first question, I set $$C_n(k)=  \frac{n}{nk^2+k+1}$$ then $$\lim_{n\to\infty}C_n(k) =\frac{1}{k^2} $$ and I proved that the sequence $(C_n(k))_n$ is monotone
it therefore springs from monotone convergence
that, $$\lim_{n\to\infty}C_n=\lim_{n\to\infty}\sum_{k=1}^{\infty} \frac{n}{nk^2+k+1}= \sum_{k=1}^{\infty} \lim_{n\to\infty}\frac{n}{nk^2+k+1} = \sum_{k=1}^{\infty} \frac{1}{k^2} =\frac{\pi^2}{6}$$ Is this reasoning  correct if yes then I am interested on knowing some more elegant way (if there is some) of solving this. if not give me answer. I am don't how to solve the question in the case the limit is infinity.","['real-analysis', 'sequences-and-series', 'calculus', 'limits']"
2532971,Partitioning a graph in cycles of four,"I have the following question: Suppose that in a simple undirected graph with $4n$ vertices, each vertex has degree at least $2n$ . Is it true that we can always partition the set of vertices in $n$ parts of size $4$ such that the vertices of every part can form a cycle (of length $4$ )? I was able to prove only that it is possible to find $4$ vertices that form a cycle.","['graph-theory', 'cyclic-decomposition', 'set-partition', 'discrete-mathematics']"
2532976,bound on covariant derivative of second fundemantal form,"I'm trying to read the paper ( Schoen-Simon-Yau '74 ) and can't figure out one of the bounds they use on the derivative of the second fundamental form. In detail: Let $M$ a minimal hypersurface embedded in an $n$+1 dimensional Riemannian manifold $N$. It follows $$h_{ijk} = \nabla_k h_{ij} = -\frac 12 \, K_{n+1,ijk},$$ where $h_{ij}$ is the second fundamental form of $M$, $\nabla$ is the induced connection on $M$ and $K$ is the Riemann tensor on $N$. Let the sectional curvatures of $N$ be bounded between $K_1$ and $K_2$. In the paper, before eq. (1.28) they introduce the inequality $$|K_{n+1,iji}| \leq \frac 12 (K_1 - K_2). \qquad (*)$$ How do I see this result? I tried to use that $\sum_i h_{ii} = 0$, $\sum_i h_{iik} = 0$, and $(*)$ but that lead to nowhere. Maybe someone has a tip? I would be very grateful!","['minimal-surfaces', 'riemannian-geometry', 'differential-geometry']"
2532979,local trivialization of quotient manifold map,"Let $G$ be a lie group acting on a smooth manifold $M$ smoothly, properly and freely. Then, there exists a unique smooth structure on the orbit space $M/G$ such that the map $\pi:M\rightarrow M/G$ is a smooth submersion. I am trying to show that this map has local trivialization property  with $G$ as fiber space i.e., given $q\in M/G$ there exists an open subset $U\subseteq M/G$ containing $q$ and a diffeomorphism $$\varphi:U\times G\rightarrow \pi^{-1}(U).$$ Local section theorem says that any smooth submersion has abundant local sections. In particular, given $p\in M$ there exists a local section of $\pi$ whose image contains $p$. Let $q=\pi(p)$ and $\sigma:U\rightarrow M$ be a local section of $\pi$ with $\sigma(q)=p$. As $\pi\circ \sigma=1_U$ we have $\sigma(a)\in \pi^{-1}(a)\subseteq \pi^{-1}(U)$ for all $a\in U$. So, we have ,$U\rightarrow \pi^{-1}(U)$ a smooth map. Define $\varphi:U\times G\rightarrow \pi^{-1}(U)$ by $(a,g)\mapsto g\sigma(a)$. As $a=\pi(\sigma(a))=\pi(g\sigma(a))$, we have $g\sigma(a)\in \sigma^{-1}(a)\subseteq \sigma^{-1}(U)$. So, we have a well defined map $U\times G\rightarrow \pi^{-1}(U)$ given by $(a,g)\mapsto g\sigma(a)$. Let $(a,g),(a',g')\in U\times G$ be such that
$\varphi(a,g)=\varphi(a',g')$ i.e., $g\sigma(a)=g'\sigma(a')$. So, $\pi(g\sigma(a))=\pi(g'\sigma(a'))$ i.e.,
$\pi(\sigma(a))=\pi(\sigma(a'))$ i.e., $a=a'$. As the action of $G$ on $M$ is free, $g\sigma(a)=g'\sigma(a')=g'\sigma(a)$ implies $gg'$. Thus, $\varphi :U\times G\rightarrow \pi^{-1}(U)$ is injective. Let $x\in \pi^{-1}(U)$ then, $\pi(x)\in U$. This suggests to consider $(\pi(x),g)\in U\times G$ such that $\varphi(\pi(x),g)=x$ (This is with gut feeling that $\varphi$ is surjective.) i.e., $g\sigma(\pi(x))=x$. But, how do 
we know there exists $g\in G$ such that $g\sigma(\pi(x))=x$? We have not assumed that the action is transitive. Am I missing something? Suppose such $g$ exists then it is clear that $\varphi$ is smooth bijective map. Its inverse  $\pi^{-1}(U)\rightarrow U\rightarrow G$ is given by $x\mapsto (\sigma(x),g)$ where $g\in G$ is such that $g\sigma(\pi(x))=x$ and I do not see how one can show that this inverse is smooth. It is smooth in first coordinate as it is just the map $\pi$.  How do we prove that $\pi^{-1}(U)\rightarrow G$ given by $x\mapsto g$ where $g$ is such that $g\sigma(\pi(x))=x$ is a smooth map. Any suggestions are welcome.","['fiber-bundles', 'smooth-manifolds', 'differential-geometry']"
2532992,How to differentiate a power series?,"I have a task where I need to write the power series: $\sum\limits_{n=0}^\infty\frac{(-1)^n}{(2n)!}x^n$ differentiated 2 times where $x=0$. This is what I have done so far: $f'(x) = \sum\limits_{n=1}^\infty n\frac{(-1)^n}{(2n)!}x^{n-1} \\
    f''(x) = \sum\limits_{n=1}^\infty n(n-1)\frac{(-1)^n}{(2n)!}x^{n-2} = \sum\limits_{n=1}^\infty\frac{((-1)^n (n - 1) n x^{n - 2})}{((2 n)!)}$ However I'm not quite sure how to proceed. Update:
So I found the solution by replacing x with 0 which meant that the only term that wouldn't be undefined was 2 which resulted in the sollution: $ f''(0) = \frac{(-1)^2(2-1)2}{(2*2)!} = \frac{2}{4!} = \frac{2}{4*3*2*1} = \frac{1}{4*3} = \frac{1}{12}$","['derivatives', 'power-series', 'calculus']"
2533027,"The closure of differentiable functions are the continuous functions in the interval $[0,1]$","Let $X=C([0,1])$ with the $||\cdot||_\infty$-norm. Show that $\overline{C^1([0,1])}=X$. Every differentiable function is continuous. So $C^1([0,1])\subset X$. Now I have to show $D=\overline{C^1([0,1])}\subset X$. I also have to show: $X\subset D$. So every continuous function which is not differentiable is in $\overline{D}/\dot{D}$. Every continuous function f in a compact intervall is bounded, so $||f||_\infty<\infty$. $C^1([0,1])\subset X$, so $||f||_\infty<\infty \forall f\in C^1([0,1])$. So for the functions g in the closure of $C^1([0,1])$ we have $||g||_\infty<\infty$. How can I show that these functions g are also in X? And how can I show that every continuous non-differentiable function is in $\overline{D}/\dot{D}$? Can someone help me?","['functional-analysis', 'continuity', 'functions']"
2533046,Classifying a degenerate point,"I have the function $$f(x, y)=y^4-4y^3+x^2y-x^2-2y^2+12y-7$$
I found that the function has three critical points: $(0, 3)$, $(0, 1)$ and $(0, -1)$. I'm now trying to classify the degenerate point $(0, 1)$ by considering the value of $f$ along the curve $y=cx^2+1$ for different values of c. Substituting $y=cx^2+1$ into $f$ gives: $$f(x, cx^2+1)=cx^4-8c^2x^4+c^4x^8$$ The second derivative is: $$12cx^2-96c^2x^2+56c^4x^6$$ However, substituting $x=0$ into the second derivative gives $0$, which tells us nothing about whether the degenerate critical point is a local maximum or a local minimum. Am I missing something here? Thanks in advance.","['derivatives', 'calculus']"
2533103,"A function $f$ is analytic in $ D=D(0,1)$ and $f(0)=f'(0)=0$","A function $f$ is analytic in $ D=D(0,1)$ and $f(0)=f'(0)=0$ and that $|f'(z)|\leq 1$ for every $z \in D.$ Prove that $|f(z)|\leq |z|^2/2$ for every $z \in D.$ I always have problems to get an inequality for $f$ from $f'.$ I can note this is similar to one version of Schwarz's Lemma: ""If $f$ is analytic in the unitary disk $\mathbb D$ and $f(0)=0$ and for every $z \in \mathbb D$ then $|f(z)|\leq |z|.$ Thanks so much!","['complex-analysis', 'maximum-principle']"
2533110,Definition of the topology on the inverse limit,"I just want to make sure that I have the topology on the inverse limit correctly as I am having quite a bit of difficulty understanding this.
If $\lim_{\leftarrow i \in I} A_i$ is some inverse limit then the topology on it is the coarsest collection of open sets such that the projection $$
\varprojlim_{i \in I} A_i \rightarrow A_j
$$ is continuous for each $j \in I$ .
This is my understanding. Could I possibly verify this with someone because I just can't find anywhere that spells it out.","['category-theory', 'general-topology']"
2533120,Simons '68 minimal varieties notation,"I'm trying to understand this paper ( Simons '68 ) and I'm a bit confused with notation. For a $p$ dimensional manifold $M$ immersed in an $n$ dimensional manifold $\bar M$ with $TM$, $NM$ respectively the tangent and normal bundle of $M$ and $SM$ ""the bundle whose fibre at each point is the space of symmetric linear transformations of $T_pM \to T_pM$"" he defines $$\overset {\sim} A := \, ^t\!A \circ A$$ and $$\underset \sim A := \sum_{i=1}^{n-p} \text{ad } A^{V_i} \, \text{ad } A^{V_i}$$ where $\langle ^t\!A(S),V\rangle = \langle A^V,S\rangle$, $S \in SM, \, V \in \text{Hom}(NM,SM)$, $A^{V} = - (\nabla_X V)^T$ for a tangential vector field $X$ and a normal field $V$. What does he mean by $\text{ad } A^{V}$ ? Is this just the adjoint, ie. the transpose? Ultimately I'm trying to understand the equation from Theorem 4.2.1. Let $A$ be the second fundamental form of a minimal variety. Then $A$ satisfies
  $$ \nabla^2 A = - A \circ \overset \sim A - \underset \sim A \circ A + \bar R(A) + \bar R'$$ and how this differential equation is linear. Does anyone know a review of that paper? It's quite technical, and some more text wouldn't hurt. (also explaining no(ta)tions a bit more) As always, thanks a lot for any help!","['minimal-surfaces', 'riemannian-geometry', 'differential-geometry']"
2533169,A complex ordinary differential equation [duplicate],This question already has an answer here : Complex differential equation (1 answer) Closed 6 years ago . I’m trying to see what instruments I could use to analyse the following ODE in the complex plane: $ \dot{z} = \exp(it)\cdot \bar{z}$. Where $z$ is a function of real valued time. ${{}}$,"['complex-analysis', 'ordinary-differential-equations']"
2533209,Galois Descent of morphisms for field extensions,"Let $L/K$ be a finite separable extension of fields and $X,Y$ two finite type schemes defined over $K$. Suppose there is a morphism $f: X_L\to Y_L$ over $L$ such that it is Galois equivariant. That is, for any $\sigma \in Gal(L/K)$, we have $f^\sigma = f$. How do I prove that there exists a $f' : X\to Y$ over $K$ such that $f'_L = f$? Please feel free to skip to the bolded part. I know that one can prove this for a general fpqc extension by proving it for quasi coherent sheaves first but I would like a more direct method just for fields. I also know the following ""proof"": Prove first that galois equivariant closed sets descent and then, to construct $f'$, consider the graph $\Gamma_f$ of $f$ in $X_L\times_L Y_L = (X\times Y)_L$ and descent this to a closed subscheme of $X\times Y$ and use this to define $f'$. There are two problems with this approach: First, The graph need not be a closed subscheme (I am not assuming that our morphism is separated). Second, I don't know how to actually get a morphism given a closed subscheme of $X\times Y$ that is an isomorphism under the projection to $X$. skip to here So I would really appreciate it if someone could construct the morphism quite explicitly. For instance, suppose $X = K[x]/(a)$ and $Y = K[y]/(b)$ and suppose $f$ is defined by sending $y \to p(x)$ in $L[x]$ such that $\sigma(p) \equiv p \pmod{a}$ for all galois conjugates $\sigma$. In this case, what should I define $f'$ to be? The first try might be to define $y \to \frac{1}{[L:K]}\sum_\sigma p^\sigma(x)$ but what if $[L:K] = 0 \in K$?","['extension-field', 'algebraic-geometry', 'commutative-algebra']"
2533221,A function that turns a power to a product/sum?,"I just recently started learning about the logarithm functions, and its concept is quite amazing (f(x.y)=f(x)+f(y)).
Now I'm asking for a similar function but instead of x.y ; we use x^(y) (like f( x^(y) )=f(x).f(y)/or a sum.... or it could involve another function whatsoever).
Something like (Linearization?) but in calculus (Sorry my vocab isn't that great).
Thank you","['logarithms', 'linearization', 'calculus', 'functions']"
