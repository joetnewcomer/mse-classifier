question_id,title,body,tags
4005837,Does there exist a real function with domain $\Bbb{R}$ such that $f'(x)>0$ and $f''(x)+(f'(x))^2<0$ for all $x$?,"Does there exist a real function $f(x)$ that satisfies the following properties? its domain is $\mathbb{R}$ $f'(x) > 0$ for all $x$ $f''(x) + (f'(x))^2 < 0$ for all $x$ The log function $\ln(x)$ gives some idea about conditions 2 and 3.  But for now, I did not find any example. Besides, I want to find a non-linear differential function $f(x)$ defined on $\mathbb{R}$ and that is: strictly increasing (quasi)-concave I think this is easier than the previous one. By looking at the graph, I guess this function exists, but I did not find one explicitly. EDIT 1 Thank you for all the comments, especially by @mihaild. I have found an example for these questions. An example for the 2nd question is $-e^{-x}$ . And an example for the 1st question is borrowing the idea of the 2nd one, which is the following. If $f(x)=-e^{g(x)}$ , then $f'(x)=-g'(x)e^{g(x)}$ , $f''(x)=-g''(x)e^{g(x)}-(g'(x))^2e^{g(x)}$ , and $f''(x)+(f'(x))^2=-g''(x)e^{g(x)}$ . So we just need $g(x)$ is defined on $\mathbb{R}$ and satisfies: $g'(x) <0$ for all $x$ , $g''(x) >0$ for all $x$ Then simply we choose $g(x)=e^{-x}$ . So an example is $-e^{e^{-x}}$ . This is a wrong computation. I will try to fix it. $(f’(x))^2$ should be $(g’(x))^2 e^{2g(x)}$ . EDIT 2 After checking my previous example and reading all comments again. I see there does not exist a real function for the 1st question. (Thanks a lot for a remark in @mihaild comment.) Indeed, assume that there exists $f(x)$ that satisfies the 1st condition. Then $g(x)=e^{f(x)}$ is a positive, strictly increasing and strictly concave function. But by its concavity $$g(x) \leq g(0)+ g'(0)x.$$ Since $g'(0)>0$ , we have $\displaystyle\lim_{x \to - \infty}g(x) =-\infty$ , which contradicts its positivity.","['calculus', 'real-analysis']"
4005904,"If $f:A \to B$ is a real function, and $y\in B, $ Is Rudin's definition of $f^{-1}(y)$ commonly accepted as convention or not?","Let $f:A \to B\ $ be a function. In Rudin's PMA, at the bottom of page 24 and top of page 25, he states: If $y \in B, f^{-1}(y)\ $ is the set of all $x \in A\ $ such that $f(x) = y.\ $ This notation could be confused with the function $f^{-1}:B \to A.$ Is Rudin's use of $f^{-1}(y)$ as a set still conventional today?","['notation', 'convention', 'functions']"
4005915,Relations between partial derivatives used in the Maxwell relations,"In the context of Maxwell's relations, there are two frequently used expressions relating the partial derivatives of different thermodynamic quantities: $$\left(\frac{\partial x}{\partial y}\right)_{z} \left(\frac{\partial y}{\partial z}\right)_{x} \left(\frac{\partial z}{\partial x}\right)_{y}= -1 \tag{1}$$ $$\left(\frac{\partial y}{\partial x}\right)_{z}=1 \bigg{/} \left(\frac{\partial x}{\partial y}\right)_{z} \tag{2}$$ What is the mathematical background of these two expressions? Is there a simple demonstration for them?","['calculus', 'derivatives']"
4005947,A question about two rules in isomorphism and cardinality,"In class I have encountered the next two rules: the next models - $\langle \mathcal{P}(A),\subseteq \rangle$ and $\langle \mathcal{P}(B),\subseteq \rangle$ are isomorphic, if $A$ and $B$ , have the same cardinality. I had a chance to use this rule in a certain question, but I wondered to find out that I was wrong. Now, I am not sure when I can apply this rule. The question was finding isomorphism between $\langle \mathcal{P}(\mathbb{N})\cup\{\mathbb{Z}\},\subseteq \rangle$ and $\langle \mathcal{P}(\mathbb{N}),\subseteq \rangle$ , which are not isomorphic. But on the next question, I have found that: $\langle \mathcal{P}(\mathbb{N}\cup\{\mathbb{Z}\}
),\subseteq \rangle$ and $\langle \mathcal{P}(\mathbb{N}),\subseteq \rangle$ are indeed isomorphic, and I cannot see the differences at all, because in both scenarios we have the same cardinalities of the models. Therefore, I need an extended explanation of when I can apply this rule, etc. if $B=\{X\in\mathcal{P}(\mathbb{Z}):x\ is\ finite\}$ then $\left|B\right|=\left|\mathcal{P}(\mathbb{Z})\right|=\left|\mathbb{R}\right|$ . Can you give me an explanation for why is true? Thanks!","['elementary-set-theory', 'set-theory']"
4005950,Why does plotting Collatz sequences in polar coordinates produce a cardioid and nephroid?,"I generated the Collatz sequences for the first 2,000 starting integers, and plotted these sequences ""on top of each other"" in polar coordinates, using a fixed radius and with each element in the sequence as theta (converted to radians, i.e., modulo 360). Successive elements within each sequence are connected by (semi-transparent) lines. Following these steps produced the image below, where we can clearly see two shapes (a cardioid and nephroid). (The Python code that generates this image is available here . The total number of elements in the 2,000 sequences is 136,100, so the total number of lines plotted in the image below is 136,100 - 2,000 = 134,100.) Link to generated image (high-quality) or lower quality My question is: Why do a cardioid and nephroid clearly appear? Is there something notable about the Collatz sequences that produce these shapes, or is this unrelated to the intricacies of the Collatz sequences, and that other unrelated integer sequences also produce similar shapes? As of now, I haven't seen any substantive references online to nephroids and the Collatz conjecture together . A post here describes how you can generate a cardioid in polar coordinates by drawing lines between evenly spaced points on a circle, but this doesn't relate to the Collatz sequences, and doesn't construct a nephroid. Update: Based on the discussion, the cardioid can be generated based on the envelope of lines drawn between points around a circle, with each line drawn between point line between points n and 2n (mod N), as described here . The nephroid is based on the same concept for points between n and 3n, as described here . The Collatz sequence contains both behaviors: some elements in sequence follow 2n->n (the order of the two doesn't matter if we are connecting lines), and some elements follow n->3n+1 (but the +1 component is negligible for the overall shape), resulting in the cardioid and nephroid. Update #2: Per a suggestion by heropup below, I've redrawn the image where for each line connecting terms (N,N+1) in a sequence, the line is red if N+1 > N and blue if N+1 < N. From this and per the update above, we can clearly see that the nephroid is red and the cardioid is blue. Link to colored generated image (high-quality) or lower quality (This now probably looks better on a white background but takes a long time to generate).","['collatz-conjecture', 'number-theory', 'polar-coordinates']"
4006005,If each slice of $f : X \times Y\rightarrow Z$ is continuous then $f$ is continuous?,"I'm having trouble to conclude my proof of the next statement. If $f:X \times Y \rightarrow Z$ is a function such that, $f_x : Y \rightarrow Z$ given by $f_x(y) = f(x,y)$ is continuous for each $x \in X$ and $f_y : X \rightarrow Z \ $ given by $\ f_y(x) = f(x,y)$ is continuous for each $y \in Y\ $ then $f$ is continuous This is what I've tried, given $(x,y) \in X \times Y$ and $\ U \in \tau_Z$ such that $f(x,y) \in U$ we take $\ f_x, \ f_y$ continuous functions, so $f_x^{-1}(U) \in \tau_Y \text{ and } f_y^{-1}(U) \in \tau_X$ so we take $V = f_y^{-1}(U) \times f_x^{-1}(U)$ wich is open in $X \times Y$ and $(x,y) \in V$ . My problem is when I have to show that $f(V) \subseteq U$ . I need some help Edit: I've saw something similar here and uses strongly compactness, so this is likely false, But I don't know how can be a function wich each are continuous but not the whole function.","['continuity', 'general-topology']"
4006008,Does $\mathbb{R}^2$ Contain Uncountably Many Disjoint Copies of the Warsaw Circle?,"The Warsaw Circle is defined as the closed topologist's sine curve, with an additional arc attached at its free end point and one of the end points of the critical line: Since we don't have an uncountable collection of disjoint open sets in the plane - such as the bounded component of its complement - we'll have to have an uncountable sequence $W_r$ such that if $r < s$ then $W_r$ is contained in the bounded component of $W_s^c$ .  Trying to draw it, it's actually kind of hard for me to tell for sure if it's true or not; it LOOKS true, but jeeze I think showing it with analytic, coordinate representations of each one is gonna be a bear. Anyone really feeling it? To be honest, I don't know the answer for the closed topologist's sine curve itself, either!  Probably both are possible or both are impossible; have never seen it proved for either space.","['continuum-theory', 'plane-curves', 'geometric-topology', 'plane-geometry', 'general-topology']"
4006010,"How do you integrate $x ^ 2 + y ^ 2$ over the area where $x \geq 0, y \geq 0,$ and $3x + 4y <10$? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question How do you integrate $x ^ 2 + y ^ 2$ over the area where $x \geq 0, y \geq 0,$ and $3x + 4y <10$ ？ I thought I should use polar coordinates because of the form of the function $x^2+y^2$ , but I can't set up the integral properly. How can I calculate this integral? Thanks in advance for your help!","['integration', 'multivariable-calculus', 'calculus', 'definite-integrals']"
4006018,structure of sigma algebra generated by a set,"i don't have idea of solve this problem. this problem from ""Problems in Real and Functional Analysis by Alberto Torchinsky"" Given a nonempty class ${\cal C}$ of subsets of $X$ , let ${\cal{C}}_1=\left \{A\subset X\ ; \ A\in{\cal{C}}\ \mbox{or}\ A^c\in {\cal{C}}\right \}$ , ${\cal{C}}_2=\left \{\bigcap_n A_n \ ; \ A_n\in{\cal{C}}_1\right \}$ , and ${\cal{C}}_3=\left \{\bigcup_n A_n \ ; \ A_n\in{\cal{C}}_2\right \}$ . Prove that ${\cal{C}}_3={\cal M}(C)$ . which ${\cal M}(C)$ is $\sigma$ -algebra generated by ${\cal C}$ I know structure of sigma-algebra generated by finite set.","['measure-theory', 'real-analysis']"
4006031,In how many different ways can these fruits be eaten in succession considering only the type of fruit?,"A basket contains 3 mangoes, 2 papayas and 2 kiwis. In how many different ways can these fruits be eaten in succession considering only the type of fruit? For me the answer is $3! C^7_3C^4_2C^2_2 = 1260$ , but the answer seems $7\times6 \times 5=210$ . Can you explain to me where have I done the error?","['combinatorics', 'discrete-mathematics']"
4006042,Vector valued linear differential equation,"Let $I$ be an interval in $\mathbb{R}$ and suppose. $$\bf \dot{x(t)} =A(t)x(t),t\in I\hspace{1cm}(\star)$$ is a linear first order differential equation with $A$ an $n\times n$ matrix of continuous functions on an $I$ . Suppose $\bf y_1(t), . . . ,y_n(t)$ are $n$ solutions of this differential equation on $I$ .  Let $W=W(\bf y_1, . . . ,y_n) $ $:I\rightarrow \mathbb{R}$ be the function given by $W(t) = \det [\bf y_1(t), . . . ,y_n(t)],(t∈I)$ ,where $[\bf y_1(t), . . . ,y_n(t)]$ is regarded an $n\times n$ matrix whose $i^{th}$ column is $\bf y_i(t)$ $,i= 1, . . . , n.$ We need to show that either $W$ is identically zero on $I$ or it is nowhere vanishing on $I$ . My idea as below: $[\bf y_1(t), . . . ,y_n(t)]$ are solution of $(\star) $ and $V:=\{x(t):\, (\star) \}$ is clearly $n$ dimensional $\mathbb{R}-$ vector space.
Note that, $\bf y_i(t)$ $\in V,i= 1, . . . , n.$ Now if $[\bf y_1(t), . . . ,y_n(t)]$ form a basis ( linearly independent is enough here)then results directly follows as in a $n\times n$ matrix, $\det$ is non zero iff all columns of it are linearly independent. Is this a correct strategy?
Any helpful comments or answer are welcome and thank for that.","['multivariable-calculus', 'ordinary-differential-equations']"
4006046,"Finding all natural $x$, $y$, $z$ satisfying $7^x+1=3^y+5^z$","The problem goes as follows: Find all possible pairs of $x,y,z \in \mathbb{N}$ which satisfy the equation $7^x+1=3^y+5^z$ My first instinct was to continue by modding, but I don't think I can get anything out of it. The obvious solutions seem to be $x,y,z=1$ and $x,y,z=0$ , but I am not really sure how to approach the problem. Thanks in advance!","['exponential-diophantine-equations', 'number-theory', 'elementary-number-theory']"
4006053,"Finding $\int_{S}^{} x^{4} \sin (x^{3}z^{5})\,dx\,dy\,dz$ where $S$ is part of a sphere","Let $S$ be the subset of the sphere $x^{2} + y^{2} + z^{2} = 1,  z > 0$ . Calculate the integral $$\int_{S}^{} x^{4} \sin (x^{3}z^{5})\,dx\,dy\,dz$$ So I know that this is a surface integral. I used these parameters: $$\boldsymbol{\mathbf{}\Phi} (\varphi ,\theta )=(\sin \varphi \cos \theta, \sin \varphi \sin \theta, \cos \varphi) , 0<\varphi < \frac{\pi}{2}, 0<\theta<2\pi$$ I also found $$\left \| \Phi_{\phi} \times \Phi_{\theta} \right \| = \sin \varphi$$ So I got the double integral $$\int_{0}^{\frac{\pi}{2}}\int_{0}^{2\pi} \sin^{4}\varphi\cos^{4}\theta \sin(\sin^{3}\varphi \cos^{3}\theta \cos^{5}\varphi)\sin\varphi \,d\varphi \,d\theta $$ but I don't think that it's a good idea.","['integration', 'surface-integrals', 'multivariable-calculus', 'multiple-integral']"
4006080,Asymptotics or methods for this integral,"I was wondering if there is some ""good"" numerical method, or some cool asymptotic method, for this integral: $$\int_0^{+\infty} \frac{\sin(\sin(x))}{\Gamma(x+1)} \ln\left(\frac{1+\Gamma(x+1)}{1+x}\right)\ \text{d}x$$ $\texttt{W. Mathematica}$ returns the value $$0.0057963275757687840000000$$ (I do not know if there are problems in the application or if it is a really exact result, in this case a rational expression would be trivial to get). Pushed by the curiosity, I plotted it and it follows that the greatest part of the integration is covered between $0$ and $17$ , even if, as an estimation, we could stop at $7-8$ : So basically: how can we attack this integral?","['integration', 'definite-integrals', 'asymptotics']"
4006107,Knot theory and creative writing?,I am a Ph.D. Candidate in Creative Writing and an M.S. Student in Mathematics and I'm writing my master's thesis on knot theory and trying to tie in applications to creative writing. Has anyone come across any sources that explicitly use knot theory as a basis/structure/theoretical underpinning for creative writing/composition? The Oulipo often use combinatorics but I am looking primarily for knot theory focused writing/theory. Thanks!,"['knot-theory', 'general-topology']"
4006112,"Can $(X, \left \| \cdot \right \|_{T})$ being a Banach space imply $T$ as a closed operator?","Let $X$ and $Y$ be Banach spaces and let $T:X \rightarrow Y$ be a
linear operator. For each element $x \in X$ , define a norm (more
specifically, the graph norm ) $\left \| \cdot \right \|_{T}$ on $X$ by : $$\left \| x \right \|_{T} = \left \| x \right \| + \left \|
 Tx \right \|$$ for $x \in X$ . I managed to prove that if $T$ is a closed operator, then $(X, \left \| \cdot \right \|_{T})$ is a Banach space, using Cauchy sequences. I was wondering if it's possible to prove the other way around, respectively if $(X, \left \| \cdot \right \|_{T})$ is a Banach space, then $T$ is a closed operator and if so, how I could achieve this.","['banach-spaces', 'functional-analysis']"
4006132,How many ways can you choose $8$ tickets if the order of selection does not matter?,"A cash drawer holds $ \$1$ , $ \$5$ , $ \$10$ , $ \$20$ , and $ \$50$ bills. How many ways can you choose $8$ bills? (The order of selection does not matter.) For me, the answer is simply $5^8 = 390625$ , but the answer is simply $495$ . It seems I misunderstood ""The order of selection does not matter"". Can you explain where I was wrong in considering the last comment?","['combinatorics', 'discrete-mathematics']"
4006162,Find the coefficient of $x^{16}$ in $(1 + x + x^2 + x^3 + x^4 + x^5)^4$,"We are supposed to find the coefficients of it, I wanted to know if my approach is right here. The final answers seems a bit iffy. $$(1+x+\dots+x^5)^4=\left(\frac{1-x^6}{1-x}\right)^4=(1-x^6)^4(1-x)^{-4}$$ Using the binomial theoerem, I got the following: $$
(1-x^6)^4=\sum_{k\ge0}(-1)^k\binom{4}{k}x^{6k}
$$ and using the negative binomial theorem, $$
(1-x)^{-4}=\sum_{k\ge0}(-1)^k\binom{-4}{k}x^k=\sum_{k\ge0}\binom{4+k-1}{k}x^k
$$ So the $x^{16}$ coefficient is $$
\binom{4}{0}\binom{8+16-1}{16}-\binom{4}{1}\binom{8+10-1}{10}+\binom{4}{2}\binom{8+4-1}{4}\
$$ $$
 = 1(245157)-4(19448)+6(330)\
$$ $$
= 245157-77792+1980\
= 169345
$$ Not too sure if I did this right. I think my math may be off somewhere but can't figure out where.","['combinatorics', 'multinomial-coefficients', 'generating-functions']"
4006220,A group of order $150$ has at least $4$ conjugacy classes made by elements of order a power of $5$?,"Let be $G$ a group of order $150$ and $g \in G\,\,$ s.t. $|g|=25\,$ : Prove that $\exists \,\,K\lhd G\,\,$ s.t. $K \simeq C_5$ . $\,\,$ Say whether $\exists \,\,h \in G\,\,$ s.t. $|h| =15$ . $\,\,$ Prove that if $\,\,\exists\,\, t\in G/K$ s.t. $\,\,|t|=15$ then $G/K$ has only one $5$ -Sylow; in this case how many elements of order $15$ does $G$ have? $\,$ Prove that $G$ has at least $4$ conjugacy classes made by elements of order a power of $5$ . I am struggling with the last part of this exercise, any help will be greatly appreciated. My solution: We know, by hypothesis, that $\exists \,\,g\in G$ s.t. $|g|=25\,\,$ and this means that $C_{25} \leqslant G\,$ , where $\langle g \rangle = C_{25}\,$ , which is abelian because $25$ is the square of a prime, but it is also a $5$ -Sylow of $G$ , because $150=2 \cdot 3 \cdot 5^2$ , hence, for the Sylow's Theorems, the conjugacy action of $G$ on $C_{25}$ is transitive, which implies $C_{25} \lhd G\,\,$ . Observing that $g^5 \in C_{25}$ and that $|g^5|=5$ in $C_{25}$ , we have $C_5 \simeq \langle g^5 \rangle \lhd C_{25}\,\, \Rightarrow \,\, C_5 \lhd G$ . $G$ has an element $h$ of order $15 \iff C_{15}\leqslant G$ . Let be $P \in{\rm Sylow}_3(G)$ , now $|P| = 3$ which is a prime, therefore $P \simeq C_3$ . We have seen that $C_5 \lhd G$ , thus $H := C_3C_5 \leqslant G$ . From this: $C_3 \cap C_5 = \{1\}$ , $|C_3C_5| = 15 = |H|$ and $C_3, C_5 \lhd H$ because they are the only $3$ -Sylow and the only $5$ -Sylow in $H$ ; hence $H \simeq C_3 \times C_5 \simeq C_{15} \leqslant G$ . $h$ is the generator of $C_{15}$ . By hypothesis $C_{15} \leqslant G/K$ , with $K \simeq C_{25}$ . Now $|G/K|=30 =3 \cdot 2 \cdot 5$ and $[G/K : C_{15}]=2$ , which is the minimum prime that divides the order of $G/K$ , that implies $C_{15} \lhd G/K\,\,$ . We can observe that $C_{15}$ has only one $5$ -Sylow $Q$ , hence $Q \lhd C_{15} \lhd G/K$ , therefore $Q \lhd G/K$ , which means that $Q$ is the only $5$ -Sylow of $G/K$ . Any idea about the last two requests? Thank you.","['group-theory', 'abstract-algebra', 'finite-groups', 'sylow-theory']"
4006293,What is this polynomial?,"I came across the "" summation by parts "" formula, and wondered how it could be useful in any way: $$
\sum_{k=n}^m\ a_k \Delta b_k=\left[a_k b_k\right]_{n}^{m+1}-\sum_{k=n}^{m}\ b_{k+1} \Delta a_k
$$ Where $\Delta a_k$ is the Forward difference operator . I tried to do the following: with $|\alpha|<1$ : $$
\sum_{k=0}^m \ k \alpha^k=\frac{1}{\alpha-1}\sum_{k=0}^m \ k \alpha^k(\alpha-1)=\frac{1}{\alpha-1}\left(\left[ k\alpha^k\right]_0^{m+1}-\sum_{k=0}^m\ \alpha^{k+1}\right)
$$ And then I took the limit as $m\to \infty$ , getting: $$
\sum_{k=0}^\infty\ k\alpha^k=\frac{\alpha}{(1-\alpha)^2}
$$ Which is a result I'm sure many of you know, but then I realized that, with this formula, i could do the same for $\sum_{k=0}^\infty\ k^2 \alpha^k$ , being $\Delta k^2=2k+1$ , arriving at: $$
\sum_{k=0}^\infty\ k^2 \alpha^k=\frac{\alpha}{(1-\alpha)^2}\left(2\cdot\frac{\alpha}{1-\alpha}+1\right)
$$ But I could do the same for $\sum_{k=0}^{\infty}\ k^3\alpha^k$ , and so on, obtaining this formula: $$
\sum_{k=0}^\infty\ k^3\alpha^k=\frac{\alpha}{(1-\alpha)^2}\left(6\cdot \left(\frac{\alpha}{1-\alpha}\right)^2+6\cdot \left(\frac{\alpha}{1-\alpha}\right)+1\right)
$$ And so on with the fourth degree and the fifth: $$
\sum_{k=0}^{\infty}\ k^4\alpha^k=\frac{\alpha}{(1-\alpha)^2}\left(24\cdot \left(\frac{\alpha}{1-\alpha}\right)^3+36\cdot\left(\frac{\alpha}{1-\alpha}\right)^2+14\cdot\left(\frac{\alpha}{1-\alpha}\right)+1\right)
$$ $$
\sum_{k=0}^{\infty}\ k^5\alpha^k=\frac{\alpha}{(1-\alpha)^2}\left(120\cdot\left(\frac{\alpha}{1-\alpha}\right)^4+240\cdot \left(\frac{\alpha}{1-\alpha}\right)^3+150\cdot\left(\frac{\alpha}{1-\alpha}\right)^2+30\cdot \left(\frac{\alpha}{1-\alpha}\right)+1\right)
$$ At this point I got bored and wanted to find a general formula, seeing a polynomial pattern, but all i could figure out was this: (I didn't prove any of the following, I just tried to figure out the patterns, which could be misleading) Given $|\alpha|<1$ , and $n\in \mathbb{N}$ $$
\sum_{k=0}^\infty k^n \alpha^k=\frac{\alpha}{(1-\alpha)^2}\left(\sum_{k=0}^{n-1} P_{n,k} \left(\frac{\alpha}{1-\alpha}\right)^k\right)
$$ Where $P_{n,k}$ is a coefficient defined for $n\in \mathbb{N},\ k\in \{0,1,2,...,n-1\}$ , with these defining properties: $$
\forall n \in \mathbb{N}, P_{n,0}=1\\
P_{n,k}=\sum_{h=1}^{n-k}\binom{n}{h}P_{n-h,k-1}
$$ I'm having some troubles on how to get to a closed form of theese coefficients, all i know is that the coefficient of the highest term is $n!$ , the known term is $1$ , and that the linear term is $2^n-2$ , the formulas for the other coefficients are a mess beyond my comprehension, with nested sums of binomial coefficients. If you recognize these polynomials by any chance, or if you can find a closed form for them, or any kind of insight on this, please let me know. Post Scriptum: I didn't prove any of the results i showed about $P_{n,k}$ , so if you got a correction to make, please point that out.","['limits', 'sequences-and-series', 'real-analysis']"
4006325,Is there a link between two magic squares with the same constant?,"For instance we consider the magic squares of order $3$ with the constant $15$ . We can find : \begin{array}{ | l | c | r | }
     \hline
     8 & 3 & 4 \\ \hline
     1 & 5 & 9 \\ \hline
     6 & 7 & 2 \\
     \hline
    \end{array} and \begin{array}{ | l | c | r | }
     \hline
     -2 & 8 & 9 \\ \hline
     16 & 5 & -6 \\ \hline
     1 & 2 & 12 \\
     \hline
    \end{array} Do we have a tool to transform the first matrix into the second ? I mean that does the invariant (same constant) is sufficient to classify all the magic squares of a given constant under a group's action ? I know that of it was the same numbers for the two matrices, there exists an action from the group $\mathcal{D}_4$ on the set of magic squares of order $3$ . Thanks in advance !","['matrices', 'invariance', 'magic-square', 'group-actions']"
4006333,Rational Elliptic Fibration from Pencil of Cubics,"A rational elliptic fibration can be obtained from the total space of a pencil of cubics (i.e. $\mathbb{P}^2$ ), by Blp the 9 basepoints of the pencil. If the basepoints are distinct, the resulting elliptic fibration has 12 singular, nodal fibers. Most proofs of this I've seen rely on, e.g. using the Euler characteristic of the total space. Is there a way to understand this using just the geometry of the pencil (open to seeing different interpretations of what that means)?",['algebraic-geometry']
4006362,Simplifaction of Negative Fractional Exponent for Derivatives,"I'm self learning calculus and I ran across this question during my practice. The question asks to differentiate the following equation: $$\sqrt{x^3 + \csc(x)}$$ Now, I was able to do the following... $$(1/2(x^3 + \csc(x)))^{-1/2}\cdot\cot(x)\cdot-\csc(x) + 3x^2$$ Basically, I applied the chain rule However, when I looked at the solution, I was only partially correct. My numerator was right, but the denominator was wrong. The solution provided was $$\frac{3x^2-\cot(x)\csc(x)}  {2 (\csc(x) + x^3)^{1/2}}$$ I am confused as to how the ""two"" comes into the denominator. Doesn't $1/2$ as an exponent imply a regular square root? The negative in the exponent makes it a fraction and the $1/2$ just makes it a regular square root . Thus, I'm thinking there is no reason for the ""2"" to be there at all, becuase it's a regular square root. Hoping someone can clear this up. Thanks","['calculus', 'derivatives']"
4006372,Is there a way to show $\frac{1646-736\sqrt{5}}{2641-1181\sqrt{5}}=\frac{17+15\sqrt{5}}{7+15\sqrt{5}}$ without multiplying large numbers?,"I need to show that the following equality holds $$\frac{1646-736\sqrt{5}} {2641-1181\sqrt{5}} =\frac{17+15\sqrt{5}} {7+15\sqrt{5}} $$ The only way I could prove it was via cross multiplication using a calculator. Is there any simpler way to do this? Following prime factorization is given $$1646=2\times 823,736=2^5\times 23,2641=19\times 139$$ and $1181$ is prime. I strictly want to avoid multiplying large numbers. I don't know if that's possible here. The above simplification is used to obtain a famous approximation to $\pi$ given by Ramanujan .",['algebra-precalculus']
4006377,Integration with complex constant,"This may be an overly simple question, but: If I am integrating something like $$\int -i\ dx\,,$$ is this the same as $$-i \int\ dx = -i x + c, c \in \mathbb{R}\,$$ that is, the complex constant $i$ can just be treated as how one typically treats real constants in integration? Thank you.","['integration', 'indefinite-integrals', 'calculus']"
4006382,"A problem on group rings from Isaacs Algebra, a Graduate Course","Updated below, but still not sure of my approach. I am trying to solve problem $13.6$ from Isaacs' Algebra, a Graduate Course . I am probably not understanding the question, but here is my attempt. A proper solution would be most appreciated. I copied the problem to an image for reference. $\textbf{13.6}$ Let $G$ be a finite $p$ -group and $F$ a field of characteristic $p$ . Construct the group algebra $A=FG$ . Show that $J(A)$ has codimension one in $A$ . (In other words, $\dim(J(A))=|G|-1$ .) HINT: Work by induction on $|G|$ . If $|G|>1$ , let $Z\subseteq\mathbf{Z}(G)$ with $|Z|=p$ , and let $1\ne z\in Z$ . Show that $A/(1-z)A\cong F(G/Z)$ and that $(1-z)A\subseteq J(A)$ . NOTE: The augmentation ideal of $A$ (see the note following Problem $12.8$ ) has codimension one and so is a maximal right ideal and thus contains (and therefore equals) $J(A)$ . Therefore $1-g\in J(A)$ for all $g\in G$ . Observe that Using the hint I use induction starting with the fact that dimension of $ J(F(G/Z)) = |G|/p-1$ I want to show that the dimension of $J(A)=J(F(G))$ is $|G|-1$ The surjective homomorphism $\theta:F(G)\rightarrow F(G/Z)$ given by $$\sum a_g\cdot g \rightarrow \sum a_g \cdot Zg $$ then provides (Corrollary 13.2) that $J(F(G/Z)) = \theta (J(F(G)))$ Since the kernel of $\theta$ is $(1-z)A$ I know that $F(G/Z) \cong A/(1-z)A$ and that $\theta (J(A)) =J(F(G/Z)))$ so $J(F(G/Z)))=J(A)/(1-z)A$ Assuming this much is correct (I am very new at this) it seems that I need to determine the dimension of the ideal $(1-z)A$ . Then I get the dimension of $J(A)$ from the equation (which I need confirmation of) $\dim(X/Y)=\dim(X)-\dim(Y)$ . I am not seeing easily what this dimension is. I think a spanning set is the set $\{1-z)g\}$ but I'm not sure how to determine the number of independent elements present. I do know (or believe) that the set of elements of $G$ is a spanning set, with the proviso that the sum of the coefficients is zero. So an unrestricted spanning set (basis) would be the set $\{1-g\}$ . But this doesn't seem to get me where I am supposed to be. I also think that the elements of $(1-z)A$ are nilpotent, and thus $(1-z)A \subset J(A)$ . This does seem to imply that the dimension of $J(A)$ equals $|G|-1$ . But I don't think this requires the induction proof. UPDATE: I see that the kernel is bigger than $(1-z)A$ , containing $(1-y)A$ for all $1 \neq y \in Z$ . However, I am still not set up to calculate the requested dimensions. My approach is obviously clumsy. Thank you in advance for clarifying. I am trying to learn from the book.","['group-rings', 'group-theory', 'ring-theory']"
4006384,Follow-up Question about Cesaro mean proof,"I am trying to understand the proof behind the Cesaro mean converging. I am using https://math.stackexchange.com/a/2342856/633922 (hopefully it is also correct) as a guide because it seems very direct. I will comment on the steps I understand and where I need help. The statement: If $(x_n)$ converges to $x$ , the sum of averages $y_n=\dfrac{x_1+x_2+\cdots+x_n}{n}$ also converges to the same limit. Proof: Since $(x_n)$ converges, given an arbitrary $\epsilon >0$ , there exists an $N_1\in\mathbb{N}$ such that whenever $n\geq N_1$ we have $|x_n-x|<\epsilon$ .
(Definition of convergent sequence) Now, $$\begin{align*}
\left|\frac{x_1+x_2+\cdots+x_n}{n}-x\right|=&\left|\frac{(x_1-x)+\cdots+(x_{N_1-1}-x)}{n}+\frac{(x_{N_1}-x)+\cdots+(x_{n}-x)}{n}\right|\\
\leq& \left|\frac{(x_1-x)+\cdots+(x_{N_1-1}-x)}{n}\right|+\left|\frac{(x_{N_1}-x)+\cdots+(x_{n}-x)}{n}\right|\text{ (Triangle inequality)}
\end{align*}
$$ Now we want to make a statement about the first $N_1-1$ terms, $\color{red}{why?}$ That is: By the Archimedean principle we can find an $N_2$ such that whenever $n\geq N_2$ we have that $$\left|\frac{x_1+x_2+\cdots+x_{N-1}}{n}\right|<\epsilon
$$ (Thought: is it because $x_1,\dots,x_{N_1-1}$ is finite?) Now we can choose an $N_3=\max\{N_1,N2\}$ such that for all $n\geq N_3$ we have (My thought: Is this because choosing the max of both will always guarantee the final inequality to always work?) $$
\left|\frac{x_1+x_2+\cdots+x_n}{n}-x\right|\leq \underbrace{\epsilon}_{N_1-1}+\underbrace{\color{red}{\frac{n-N_1}{n}}}_{\text{why and how?}}\epsilon< 2\epsilon
$$ And this finishes the proof. I always assumed the ending statement has to be (something) $<\epsilon$ or is this saying that each sum of the right side of the triangle inequality is less than $\epsilon/2$ . I would really appreciate the help on the areas I am thoroughly confused about.","['analysis', 'real-analysis', 'sequences-and-series', 'limits', 'cesaro-summable']"
4006400,Why is $A \rtimes B \simeq \mathbb Z \rtimes \mathbb Z/2\mathbb Z$,"Hello everyone I have a hard time trying to resolve this problem if anyone could help it would be a lot appreciated. Let $$f_1\colon\mathbb R\rightarrow \mathbb R,\,f_1(x)=-x,\quad f_2\colon\mathbb R\rightarrow \mathbb R,\,f_2(x) = -x +1$$ We define $D_\infty = \langle f_1,f_2 \rangle$ , the infinite dihedral group and $A = \langle f_2 \circ f_1 \rangle$ and $B=\langle f_2\rangle$ ,  then we have : $$D_\infty = A \rtimes B \simeq \mathbb Z \rtimes \mathbb Z/2\mathbb Z$$ How can we prove that statement ? Should we prove that $f_1 ^2=f_2 ^2=1$ , so I can use the following answer ? I also found here exactly what I want but how can I prove it using $f_1$ and $f_2$ . ( How can we also prove infinite order of $\langle f_2 \circ f_1\rangle$ , I thought maybe we have to compute $(f_2 \circ f_1)^k(x)$ ?)","['infinite-groups', 'dihedral-groups', 'semidirect-product', 'abstract-algebra', 'group-theory']"
4006404,Uniqueness and existence of solution $\frac{dy}{dx} = \sqrt{x-y}$ given $y(2)=2$,"I want to determine if there exists a solution and the uniqueness of it for: $\frac{dy}{dx} = \sqrt{x-y}$ given $y(2)=2$ A solution said that we cannot determine if there exists a solution since it was discontinuous at (2,2). This solution seems to imply that it is possible for x to be a number for example 1.99 and y be 2.00 or x be 2.00 and y be 2.01. I'm confused as to why the textbook makes this sort of assumption - I thought we were just determining the continuity of the point. If we were to look at the neighborhood then why then if we are given $y(2)=1$ as the condition that we know that the above has a solution? It seems arbitrary as to how far we can go left and right or above and down a certain point to say that it was not continuous?","['continuity', 'calculus', 'ordinary-differential-equations']"
4006445,Dot product of functions on cosets,"Let the measures of locally compact groups $\,K < G\,$ be $\, dk\,$ and $\, dg\,$ , correspondingly.
For a Hilbert space $\mathbb{V}$ equipped with a dot product $\,\langle~,~\rangle\,$ , introduce the space ${{\cal{L}}^G}$ of square-integrable functions: $$
 {\cal{L}}^G=\left\{\right.\varphi\,:\, G\longrightarrow{\mathbb{V}}\; {\LARGE\mbox{$|$}}\int dg\,\langle \varphi(g),\varphi^{\,\prime}(g)\rangle<\infty\;\;\,
 \mbox{for}\;\forall\,\varphi,\,\varphi^{\,\prime}
 \left.\right\}.
 $$ Of interest to us will be the subspace of Mackey functions, those obeying the equivariance condition $$
 \varphi(gk)=D^{-1}(k)\,\varphi(g)~,~~g\in G\,,~~k\in K~,
 $$ where a representation $\, D(K)\,$ is assumed (pseudo)unitary, i.e. preserving $\,\langle~,~\rangle\,$ . Treat the group $G$ as a principal bundle on the base $G/K$ , and fix a section $x=\gamma(X)$ , with each $x$ acting as the representative of a coset $X=xK$ . Functions on cosets can be naturally introduced as functions on the section: $$
 \tilde{\varphi}(X)\equiv\varphi(x)~.
 $$ We also can define a dot product on the section as $$
 \int \langle\, \varphi(x)\, ,\,\varphi^{\,\prime\,}(x)\,\rangle\,dx~.\qquad\qquad\qquad(*)
 $$ To be able to interpret it as a dot product on the quotient space, we must be sure that it remains invariant under a different section choice, say $\bar{x}=\bar{\gamma}(X)$ . The two sections are related via $x\,=\,\bar{x}\, k(x)$ , where $k(x)\in K$ . Plugging this in the above expression, and keeping in mind that $\varphi(x)=\varphi(\bar{x}\, k(x))= D^{-1}(\, k(x)\,)\,\varphi(\bar{x})\,$ , we obtain: $$
 \int\langle\,\varphi(\bar x)\,,\,\varphi(\bar x)\,\rangle\; d\bar x~=~
 \int\langle\varphi(x)\,,\,\varphi(x)\rangle\; d (\, x\, k(x)\,)~.
 $$ QUESTION 1. $~~$ I have been sloppy by writing simply $k(x)$ instead of $k(X)$ where $X\in G/K$ . Is this forgivable for a right-invariant measure $dg\,$ ? QUESTION 2. $~~$ Assuming the measure is right-invariant, can we say that $ d (\, x\, k(x)\,)=dx $ for any reasonable function $k(x)$ ? /""Reasonable"" $k(x)$ means: ""good enough for a physicist"", so that the representatives $x$ always make Borel algebras and the measure $dx$ is well defined./ QUESTION 3. $~~$ Was the assumption of (pseudo)unitarity of $D(K)$ inded necessary here? QUESTION 4. $~~$ If the answer to all the above questions happens to be affirmative, may I assume that I have proven the invariance of product (*) under a change of section, so it can be understood as a dot product in the quotient space?","['measure-theory', 'principal-bundles', 'harmonic-analysis', 'fiber-bundles', 'haar-measure']"
4006463,How to compute Trigonometric functions based on Inverse Square Root,"I am writing a rational number library for performing fast math on integer-only microcontrollers. So far, I have all the basic operations, as well as a first-step estimation function for square root. It takes a positive integer input and returns a rational number approximating the square root (accurate to roughly 4 bits of precision; to be refined further by Newton-Raphson or similar method). Obviously, inverse (reciprocal) square root comes for free since the answer is a fraction that can be trivially inverted. I read somewhere that other functions (e.g. trigonometric functions) can be calculated in terms of inverse square root (can't find the link now), but I am having a hard time finding any algorithms since search results are almost entirely about inverse trigonometric functions (mostly high school help stuff). Does anyone have a handy resource where I can find efficient methods for calculating sin, cos, tan, atan, etc. in terms of square root or inverse square root? Is it possible or am I imagining things? I know this is not a ""code"" StackExchange but I believe this is fundamentally a math question. If you're interested in my code, it's here . The sqrt_est() function is somewhat remarkable in that it is very short, uses only shifts and adds, no looping or iteration, or even multiplies or divides! (core implementation is on lines 39-45 .)","['trigonometry', 'algorithms']"
4006478,Question about meaning of derivative of vector-valued function,"So I was wondering about the interpretation of the derivative of a vector-valued function in the sense of how it is analogous to a function with one variable input and one output. With the derivative in single variable calculus, it is interpreted as the slope of the line that is tangent to the curve. With a vector valued function, when we take the derivative, it is equivalent to taking the derivative of each of the components of the function's output. So are we saying that instead of a representing a line that is tangent to the curve, it is representing a vector that is tangent to the curve? But what is confusing me about the analogy is this. In the single variable situation, we can travel along the tangent line that is given by the derivative. What is the meaning of ""travelling along the tangent line"" when we have a tangent vector? Do we travel along the tangent vector?","['multivariable-calculus', 'tangent-line']"
4006486,Find points at which tangent intersects curve for variable x and y values,"I am not sure if I titled this correctly. I am working through Calculus With Analytic Geometry by Simmons. Question $\# 17$ on page $87$ reads Find the equation of the tangent to the curve $y = x^3$ at the point $(a, a^3)$ . For what values of a does this tangent intersect the curve at another point? I can calculate the equation of the tangent line to be $y=3a^2x-2a^3$ but I am not sure how to calculate the values of $a$ where the tangent intersects the curve at another point. Even a hint would be great, thank you.","['calculus', 'derivatives', 'tangent-line']"
4006488,Completing the proof of a theorem,"My question is about the proof of the Theorem 1.3 which is on the page 9 of the book ""Topics in Real Analysis"" , which is available electronically through the previous link. I want to demonstrate that theorem in the case $\mu (X)=\infty$ . In that book there's the following tip: To extend our result to the general case observe that the finite case implies $\mu (A\cap X_j)=\tilde \mu (A\cap X_j)$ ( just restrict $\mu,\tilde\mu$ to $X_j$ ). Hence $$\mu (A)=\lim_{j\to\infty}\mu (A\cap X_j)=\lim_{j\to \infty}\tilde \mu(A\cap X_j)=\tilde \mu (A)$$ Below is my attempt to use that tip to prove that theorem in the case $\mu (X)=\infty$ . Let $j\in\mathbb{N}$ be any element and define $S_j:=\big\{E\cap X_j:E\in S\big\}$ . It's trivial to verify that $S_j$ is a $\pi$ -system (because $S$ is by hypothesis a $\pi$ -system). Besides, since $X_j\in S$ , then $S_j\subseteq S$ which implies that $\Sigma (S_j)\subseteq\Sigma (S)=\Sigma $ in which $\Sigma (S_j)$ means the $\sigma$ -algebra generated by $S_j$ . Let $\mu _{S_j}$ and $\tilde \mu _{S_j}$ , respectively, be the restrictions of $\mu$ and $\tilde \mu$ to $\Sigma(S_j)$ . It's easy to see that $(X_j,\Sigma (S_j),\mu_{S_j})$ is a measure space. The elements of $\{X_j\cap X_n\}_{n\in\mathbb{N}}$ belongs to $S_j$ and satisfy $(X_j\cap X_n)\nearrow X_j$ and $\mu_{X_j}(X_j\cap X_n)<\infty $ for all $n\in\mathbb{N}$ . Because of the above considerations and $\mu_{S_j}(X_j)<\infty$ , we can use the first part of the proof of the Theorem 1.3 which is in the book mentioned above to prove that $\mu_{S_j}(E)=\tilde \mu_{S_j}(E)\,\,\color{red}{(1)}$ for all $E\in \Sigma (S_j)$ . Let $A\in\Sigma $ be any element. If there's a $j\in\mathbb{N}$ such that $A\cap X_j\in \Sigma (S_j)$ , then I can use $(1)$ and that tip above to prove that $\mu (A)=\tilde \mu (A)$ . However, if $A\cap X_j\,\,{\color{red}{\notin}} \,\,\Sigma (S_j)$ for all $j\in\mathbb{N}$ , then I can't use $(1)$ and, therefore, that tip is useless. Please help me to finish the proof. At least indicate some reference that contains the proof of that theorem. Thank you for your attention!",['measure-theory']
4006494,Deeper question about Cayley's theorem,"Cayley's theorem states that there exists an injective homomorphism $\phi:G \rightarrow S_n$ for any finite group with $|G|=n$ . Let $\pi: \phi(G) \rightarrow \mathbb{Z}_2$ be the sign map, sending even permutations to $0$ and odd permutations to $1$ . If I compose the functions to get $\pi \circ \phi$ , then the kernel of the homomorphism is still a normal subgroup of $G$ . So, $\ker(\pi \circ \phi) \trianglelefteq G.$ Does this normal subgroup have any significance in group theory? I'm not sure if there would be a connection to a normal subgroup of elements of even order (I can think of a counterexample to this) or if there's even any remote connection with elements of even order for this group. I also have speculated this means that simple groups must be isomorphic to a generating set of only even permutations. The idea of the proof would be to assume that the kernel of the composition of functions is equal to the identity. Thus, the nonidentity elements of $G$ must map to odd permutations. However, multiplying two odd permutations gives an even permutation. So, there must be a nontrivial element mapping to an even permutation. If there's anything I should consider or if there are any mistakes in my argument, I'd love to hear it.","['normal-subgroups', 'group-theory', 'abstract-algebra']"
4006503,How to evaluate $\int _0^1\frac{\ln \left(1+\sqrt{x}\right)}{1+x^2}\:dx$,"How can I approach: $$\int _0^1\frac{\ln \left(1+\sqrt{x}\right)}{1+x^2}\:dx$$ I tried the usual differentiation under the integral sign but it didn't work so well. I also tried to rewrite it the following 2 ways: $$\int _0^1\frac{\ln \left(1+\sqrt{x}\right)}{1+x^2}\:dx=\int _0^1\frac{\ln \left(\sqrt{x}+x\right)}{1+x^2}\:dx-\frac{1}{2}\underbrace{\int _0^1\frac{\ln \left(x\right)}{1+x^2}\:dx}_{-G}$$ $$\int _0^1\frac{\ln \left(1+\sqrt{x}\right)}{1+x^2}\:dx=\underbrace{\int _0^1\frac{\ln \left(1-x\right)}{1+x^2}\:dx}_{\frac{\pi }{8}\ln \left(2\right)-G}-\int _0^1\frac{\ln \left(1-\sqrt{x}\right)}{1+x^2}\:dx$$ Yet I'm still stuck with those other integrals, any help is appreciated. Managed to numerically find that: $$\int _0^1\frac{\ln \left(1+\sqrt{x}\right)}{1+x^2}\:dx=\frac{\pi }{16}\ln \left(2\right)+\frac{\pi }{4}\ln \left(1+\sqrt{2}\right)-\frac{1}{2}G$$ But I still dont know how to approach it.","['integration', 'improper-integrals']"
4006566,Show that $e^z = z + \lambda$ has exactly $m + n$ solution in a horizontal strip.,"Suppose $\lambda \in \mathbb{C}$ ,
show that for sufficient large $m$ and $n$ ,
then the equation $e^z = z + \lambda$ has exactly $m + n$ solutions in the horizontal strip $\{- 2 \pi im < \operatorname{Im} z < 2 \pi i n\}$ . I tried to compute the increase in the argument of $f(z) = e^z - z + \lambda$ around the rectangle with vertices $R-2\pi im$ , $R + 2 \pi in$ , $-R + 2 \pi in$ and $-R + 2 \pi im$ . When $R$ is sufficiently large, $f(x) \approx e^z$ ,
but then I got that the increase in the argument around the rectangle is $4\pi (m + n)$ .
So what I did wrong?",['complex-analysis']
4006567,How Jacobian is defined for the function of a matrix?,"Let $f: \mathbb{R}^{m\times n} \rightarrow \mathbb{R}^m$ where $f(W)=Wx$ . Question1: How is the Jacobian matrix defined for a vector-valued function whose variable is a matrix? Question2: Using the answer to the above, how one can generalized the Jacobian formula of a composition functions whose variables are matrices? By generalization I mean how the Jacobian of a function like $g(x)=h(u(x))$ where $x \in \mathbb{R}^n$ , $u: \mathbb{R}^n \rightarrow \mathbb{R}^l$ , and $h: \mathbb{R}^l \rightarrow \mathbb{R}^m$ as follows: $$
J_x(g) = J_u(h) J_x(u)
$$ and $J_x(g)$ is the Jacobian of $g$ with respect to $x$ can be handle when $x$ becomes a matrix. The above simply says the Jacobian of a composition function is the product of the Jacobians. How can one mimic this when the variable is a matrix? My thoughts: For the given function $f(W)=Wx$ one can write the following: $$
f(W)=Wx
=
\begin{bmatrix}
W_{1\bullet}x\\
\vdots\\
W_{m\bullet}x
\end{bmatrix}
$$ where $W_{m\bullet}$ is the m-th row of $W$ . Now the Jacobian could be either $\begin{bmatrix}
x^T\\
\vdots\\
x^T
\end{bmatrix}
\in \mathbb{R}^{m \times n}
$ or $\begin{bmatrix}
x&
\dots&
x
\end{bmatrix}
\in \mathbb{R}^{n \times m}.
$","['jacobian', 'linear-algebra', 'partial-derivative', 'derivatives', 'total-variation']"
4006642,What is the analogy to logic when denoting independence of random variables as $p\models X\perp Y$?,"I'm reading Nir Friedman and Daphne Koller's ""Probabilistic Graphical Models: Principles and Techniques"". The authors occasionally use the notation $$p\models X\perp Y \mid Z$$ to indicate that the set of random variables $X$ is independent of $Y$ given $Z$ , under $p$ (which is a joint distribution over the values of all of these variables). I've never studied mathematical logic, but I read a little about models, semantic and syntactic consequences and am still unclear as to the precise meaning of the symbol $\models$ in the expression above. How is this analogous to formal logic systems? Are the conditional independence assertions analogous to formulae? Axioms?","['bayesian-network', 'independence', 'logic', 'probability']"
4006673,Anagrams of MISSISSIPPI with atleast 3 consecutive I's,"I'm trying to solve this question but I don't know if I am doing it right, my approach is: Total letters (Cardinality) MISSISSIPPI: 11 Arrange 3 I's [III]ISSSSPPM And Calculate the possible combinations 9!/(4!2!) = 7560 But I cannot verify if this is the correct solution.","['combinatorics', 'discrete-mathematics']"
4006676,"Boundary of $M \times [0,1]$ where $M$ is a smooth manifold","I'm trying to understand this fact that looks very intuitive drawing, but I'm completely stuck trying to prove it formally. Let $M$ a smoot manifold of dimension $n$ without boundary. Then $M \times [0,1]$ is a smooth manifold with boundary $\partial(M \times [0,1]) = M\times\{0\} \sqcup  M\times\{1\}$ . In addition, if $M \times [0,1]$ is oriented the orientation induced on $M\times\{0\}$ and $M\times\{1\}$ are opposite (where I'm identifying $M\times\{t\}$ with $M$ ). Any kind of help will be appreciated.","['manifolds', 'manifolds-with-boundary', 'smooth-manifolds', 'differential-geometry']"
4006683,Prove that $\left \lfloor \frac{1+\lfloor na+1/a\rfloor}{a} \right \rfloor=n$,"If $a \geq \frac{1+\sqrt{5}}{2}$ and $n \in \Bbb W$ , prove that $$\left \lfloor \frac{1+\left\lfloor \frac{1+na^2}{a}\right\rfloor}{a} \right \rfloor=n.$$ I could prove only when $a$ is an integer, that is $a \geq 2$ . If $a \in \Bbb Z$ we have: $$\left \lfloor \frac{1+na^2}{a} \right \rfloor=na+\left\lfloor \frac{1}{a} \right\rfloor=na$$ so we get: $$\left \lfloor \frac{1+\left\lfloor \frac{1+na^2}{a}\right\rfloor}{a} \right \rfloor=\left \lfloor \frac{1+na}{a} \right \rfloor=n+\left\lfloor \frac{1}{a} \right\rfloor=n.$$ But what if $a \notin \Bbb Z$ ?","['golden-ratio', 'algebra-precalculus', 'ceiling-and-floor-functions']"
4006693,"Why is $A ∪ B$ called ""A or B"" when $A ∪ B$ means all elements in $A$, $B$ and their intersection?","Definition: $A ∪ B$ is the set of elements that is contained in either $A$ or $B$ , or in both. My question: why is $A ∪ B$ called ""A or B"" when $A ∪ B$ is literally everything that is in $A$ , $B$ and their intersection. For example, a Venn diagram of $A ∪ B$ is having both circles A and B shaded in: $A$ , $B$ , and $A ∩ B$ . However, my confusion is that I interpret the definition above as selecting only one of the following, since it says ""or"": $A = A ∩ B^{c}$ $B = A^{c} ∩ B$ ""in both"" = $A ∩ B$ It is clear that if I combine all three subsets above, then I will have $A ∪ B$ . But the definition says ""or"" which makes me think I am selecting strictly one of the three possible subsets above. So why is $A ∪ B$ called ""A or B"" rather than ""A,B, A and B""",['elementary-set-theory']
4006706,Unambiguous formal grammars for a specific class of languages,"Suppose that $w \in \{0; 1\}^*$ is a binary word. Let's denote the number of $0$ -s in $w$ as $\#_0(w)$ and the number of $1$ -s in $w$ as $\#_1(w)$ . Now suppose that $q \in \mathbb{Q}$ is a positive rational number. Consider the language $L_q \subset \{0; 1\}^*$ of all words $w$ , such that for any its prefix $p$ we have $\#_0(p) \leq q \#_1(p)$ . For example, $L_1$ is the language of all possible prefixes of Dyck words. It is not hard to see, that $L_q$ is deterministic context-free for any $q$ . Indeed, if $q = \frac{m}{n}$ for some natural $m$ and $n$ we can build a following deterministic pushdown automaton that recognises our language. It has the following states: State $0$ : Reads an element from the input. If it is $1$ , adds $m$ elements to the stack and remains in the State $0$ . If it is $0$ , moves to State $1$ . This is both the initial state and the only final state. State $i$ (for $1 \leq i \leq n-1$ ): Does not read input, but tries to read from the stack. If it succeeds, the stack has $1$ element less, and we transit to State $i+1$ . If it fails because the stack was empty, we transit to State $-1$ . State $n$ : Does not read input, but tries to read from the stack. If it succeeds, the stack has $1$ element less, and we transit to State $0$ . If it fails because the stack was empty, we transit to State $-1$ . State $-1$ : Reads input but does nothing. Nothing ever leaves this state. Note, that this automaton is a final-state one. It stops when it attempts to read the input and finds that it has ended. It accepts the input if it stops in a final state. From the fact, that $L_q$ is deterministic context-free we can conclude, that it is unambiguous. My question is: How can we explicitly build unambiguous formal grammars for $L_q$ for arbitrary $q \in \mathbb{Q}$ ?","['automata', 'context-free-grammar', 'discrete-mathematics', 'pushdown-automata', 'formal-languages']"
4006737,Parametrization of Contour $C$,"For the function $f(z)=1$ $(z\in \mathbb{C})$ and C is an arbitrary contour from any fixed point ${z}_{1}$ to any fixed point ${z}_{2}$ in the $z$ plane. Use parametric representations for $C$ to evaluate $\int _{C}^{}f(z)dz$ . Here is my solution: Let ${z}_{1}$ and ${z}_{2}$ are two fixed point and $C$ is straight line. Then $z=(1-t){z}_{1}+t{z}_{2}$ where $t\in \left[0,1\right]$ , from here $dz=-{z}_{1}dt+{z}_{2}dt$ . Then we get $\int _{{z}_{1}}^{{z}_{2}}f(z)dz=\int _{0}^{1}1({z}_{2}dt-{z}_{1}dt)=\int _{0}^{1}{z}_{2}dt-\int _{0}^{1}{z}_{1}dt={z}_{2}-{z}_{1}$ Hence, $\int _{C}^{}f(z)dz=\int _{{z}_{1}}^{{z}_{2}}f(z)dz=\int _{{z}_{1}}^{{z}_{2}}1dz={z}_{2}-{z}_{1}$ Is that my solution right ? I feel that I'm missing something. Any help will be appreciated.","['analysis', 'complex-analysis', 'contour-integration', 'complex-integration', 'parametrization']"
4006859,"Norm of functional on $C[-1,1]$ defined as $P(f) = f(1)+f(-1)-2f(0)$","I am studying for my final exam and kinda struggling with the following: Calculate the norm of functional on $C[-1,1]$ defined as $P(f) = f(1)+f(-1)-2f(0)$ This seems like one-liner but I am clueless anyway. I appreciate your time.",['functional-analysis']
4006877,Little help understanding the wikipedia derivation of the Chi-Squared with k degrees of freedom,"It seems something simple but I still haven’t totally grasped. While reading this wikipedia’s derivation of of Chi-Squared distribution with k-degrees of freedom : Consider the $k$ samples $x_i$ to represent a single point in a $k$ -dimensional space. The chi square distribution for $k$ -degrees of freedom will then be given by: $$
P(Q) \, dQ = \int_\mathcal{V} \prod_{i=1}^k (N(x_i)\,dx_i) = \int_\mathcal{V} \frac{e^{-(x_1^2 + x_2^2 + \cdots +x_k^2)/2}}{(2\pi)^{k/2}}\,dx_1\,dx_2 \cdots dx_k
$$ where $N(x)$ is the standard normal distribution and $\mathcal{V}$ is that elemental shell volume at $Q(x)$ which is proportional to the $(k-1)$ -dimensional surface in $k$ -space for which $Q=\sum_{i=1}^k x_i^2$ The derivation continues, but I have a question concerning the term $dQ$ in the above equation for $P(Q)dQ$ . What I understand of the probability of $P(Q)$ is that it is a composition of the function $Q: \mathbb{R}^k \to \mathbb{R}$ with the probability function $P$ . So the probability of the event $P(Q = q)$ is the probability of the event that is a surface of the $k$ -sphere which is the level surface of $w = Q$ at $q$ (which is, the surface $Q(x) = q$ ). So the probability of $P(Q = q)$ should be the integral over this spherical surface of the density function (this density function being $k$ -independent joint normal distributions multiplied). However I don’t quite get de $dQ$ term. Shouldn’t it be just $P(Q)$ ?","['statistics', 'normal-distribution', 'real-analysis', 'chi-squared', 'probability']"
4006878,Prove $\sqrt{x_1^2+4x_1x_2+5x_2^2+2x_1+6x_2+5}$ is convex,I came across a question which contained this $\sqrt{x_1^2+4x_1x_2+5x_2^2+2x_1+6x_2+5}$ I needed to prove $x_1^2+4x_1x_2+5x_2^2+2x_1+6x_2+5\geq0$ which I've done by just showing that the minimum is 3 and it's convex function. The second part asked to show that the whole problem is convex but I didn't know how to prove $\sqrt{x_1^2+4x_1x_2+5x_2^2+2x_1+6x_2+5}$ is convex which is same as asking $\sqrt{x^TAx+b^Tx+c}$ is convex where $x^TAx+b^Tx+c\geq0$ . any help?,"['convex-optimization', 'convex-analysis', 'real-analysis']"
4006893,Aggregate Relationships,Which of the following represents an aggregate relationship (has-a)? Parent and child. Animal and dog. teacher and computer phone and fax machine All of the bove The correct answer is 3. But why is not 1 also an aggregate relationship?,['discrete-mathematics']
4006902,What is the meaning of this Pigeon hole problem?,"I copied this question from How are the pigeonholes calculated in this pigeon-hole problem? To prepare for a marathon, an elite runner runs at least once a day over the next 44 days, for a total of 70 runs in all. Show that there's a period of consecutive days during which the runner runs exactly 17 times. I tried. But I can't understand this problem. How is it possible that there is a consecutive period of days during the runner runs exactly 17 times? Here are my inferences: Runner runs daily. So each day the number of runs increases by 1 (at least) If he completed 15 runs in someday, the next day it will be 16, then 17 and so on.. (at least, because he runs daily) Then where is the period of consecutive days? I am lost here! Mathematically it can be shown as mentioned in the linked question, but I can't understand the logic behind it. Any help would be appreciated. Thanks!","['pigeonhole-principle', 'discrete-mathematics']"
4007031,Does every finite group $G$ have a set of generators such that the sum of the orders of the generators is less than or equal to $|G|$?,"Does every finite group $G$ have a set of generators such that the sum of the orders of the generators is less than or equal to $|G|$ ? This is surely true but I am failing to see why. This is easily seen to be true for the symmetric group, abelian groups, the quaternions, and it follows from their classification that simple groups have this property too.","['combinatorial-group-theory', 'finitely-generated', 'group-theory', 'finite-groups']"
4007035,Is it permitted to use $\tan 90^\circ$ to prove an equation/identity even if it is not defined? defined?,"Domain of tangent function limits to all real numbers except odd integral multiples of $\frac{\pi}{2}$ . I noticed when proving an equality that using $\tan 90^\circ$ yielded the exact same result. Here what I did: For a triangle $\mathrm{ABC}$ , prove that $$\tan \frac{A}{2}\tan\frac{ B}{2 }+\tan \frac{B}{2} \tan \frac{C}{2} + \tan \frac{C}{2}\tan \frac{A}{2}=1$$ Since $\mathrm{A+B+C = \pi}$ $$\mathrm{\frac{A+B+C}{2} = \frac{\pi}{2}}$$ I applied identity for sum of angles $$\tan{(A/2 + B/2 + C/2)}=\frac{\tan \frac{A}{2} +\tan \frac{B}{2} +\tan \frac{C}{2}-\tan \frac{A}{2} \tan \frac{B}{2} \tan \frac{C}{2}}{1-\tan \frac{A}{2}\tan\frac{ B}{2 }-\tan \frac{B}{2} \tan \frac{C}{2} - \tan \frac{C}{2}\tan \frac{A}{2}}$$ Then I reciprocated both side to get L.H.S. to be equal to 0 and I was able to prove the given equation. Why did I arrive at the right conclusion by using the value out of domain for tangent function?",['trigonometry']
4007090,"Calculating the improper integral $\int _{1}^{\infty}\frac{e^{\sin x}\cos x}{x}\,dx$","I want to calculate the value of $$\int_{1}^{\infty}\frac{e^{\sin x}\cos x}{x}\,dx$$ I was able to prove using Dirichlet's test that it does converge, but how can I calculate its value?","['integration', 'calculus', 'improper-integrals']"
4007136,Recurrence relation $a_{n+1} = 2 a_n -1$ with $a_0=3$. What is $a_n$ expressed as a function of $n$?,"I'm having a hard time finding an explanation how to solve the following problem. Given the recurrence relation $a_{n+1} = 2 a_n -1$ with $a_0=3$ .   What is $a_n$ when expressed as an explicit function
of $n$ ? Supposedly the correct answer is $a_n = 2^{n+1}+1$ . But what is the step by step approach to arrive at this solution? All of the resources I've found begin with a recurrence relation in the form a n = (some expression) but how to handle this type of problem in the form a n+1 = (some expression) ? Is it a matter of moving the variable to the other side and then solving iteratively? Or is there some clever/magic approach we should use here? Super appreciate if anyone can detail the steps to take to arrive at the correct solution. Thanks in advance!","['recurrence-relations', 'discrete-mathematics', 'recursion']"
4007145,"Proving that the outer measure of a closed interval $[a,b]$ is $b-a$","In Sheldon Axler's book, Measure Integration, and Real Analysis , he defines outer measure of a set as $|A| = \inf\big\{\sum_{k=1}^\infty \ell(I_k): I_1, I_2, \dots \text{are open intervals such that} A\subset \bigcup_{k=1}^\infty I_k\big\}$ , where $\ell(I)$ for an open interval $(a,b)$ is just $b-a$ . He later proves that outer measure preserves order, i.e. $A\subset B \Rightarrow |A| \le |B|$ . Later, we are trying to prove that the outer measure of the closed interval $[a,b]$ is $b-a$ . We bound it from above by saying for $\varepsilon > 0$ , $(a-\varepsilon, b+\varepsilon), \varnothing, \varnothing,\dots$ is a sequence of open intervals whose union contains $[a,b]$ , so $|[a,b]|\le b-a+2\varepsilon$ which with the definition of outer measure implies $|[a,b]| \le b-a$ . The next section is confusing to me: Is the inequality in the other direction obviously true to you? If so,
think again, because a proof of the inequality in the other direction
requires that the completeness of $\mathbf{R}$ is used in some form...Thus
something deeper than you might suspect is going on with the
ingredients needed to prove that $|[a, b]| ≥ b − a$ . He then goes onto prove it using the Heine-Borel theorem. However, because outer measure preserves order and $(a,b)$ is a subset of $[a,b]$ , couldn't we easily bound it from below with that? Is the open interval not thought of as a subset? I don't quite understand the reasoning and feel I'm missing something obvious. Any help would be appreciated.","['outer-measure', 'real-analysis']"
4007197,Calculate the gradient and Hessian of $x_0^T(X\operatorname{Diag}(w)X^T)^{-1}x_0$ w.r.t. vector $w$ in matrix calculus?,"I'm trying to calculate the Hessian matrix of the formula $$
f(w) = x_0^T(XWX^T)^{-1}x_0
$$ where $w=(w_1,\cdots ,w_n)^T$ , $W=\operatorname{Diag}(w)$ is a diagonal matrix that has $w$ as diagonal elements, $x_0$ is a column vector, $X$ is a matrix. To calculate the first-order derivative, do I need to first transform $W$ into $$\sum_i w^T e_i E_i,$$ where $e_i$ is a column vector whose $i$ -th element is $1$ and others $0$ , and $E_i$ is a matrix whose $(i,i)$ element is $1$ and others $0$ ? Any reference is appreciated.","['matrix-calculus', 'derivatives']"
4007263,"Find $r>0$ such that $\mathrm E[\mathrm e^{r(X-cW)}] = 1$ where $c>0$, $X\sim$ Exp$(\lambda)$ and $W\sim$ Gamma$(2,\alpha)$","Given a risk process $U_t = U_0 + \Pi_t + S_t = u + c t - \sum_{i=1}^{N_t} X_i$ with payment rate $c>0$ and starting capital $u>0$ where $N = \{N_t : t\geq0\}$ is a Poisson( $\lambda$ ) process and the damages $X_i$ are Gamma $(2,\alpha)$ distributed. Let $X=X_1$ and $W=W_1$ where $W_i$ are the Exp $(\lambda)$ waiting times of $N$ . I want to compute the adjustment coefficient, that is an $r>0$ that suffices $$
\mathrm E[\mathrm e^{r(X-cW)}] = 1
$$ under the net profit condition (NPC) $\mathrm E[X] < c \mathrm E[W_1]$ . My idea so far: By independence of $X$ and $W$ we have $$\mathrm E[\mathrm e^{rX}]=\mathrm E[\mathrm e^{-crW}]^{-1}.$$ With the pdfs $f(x) = \alpha^2 x \mathrm e^{-\alpha x}$ of $X$ and $g(x) = \lambda \mathrm e^{- \lambda x}$ of $W$ we can just compute the expected values as $$\mathrm E[\mathrm e^{rX}]
= \int\limits_0^\infty \mathrm e^{r x} \alpha^2 x \mathrm e^{-\alpha x} \mathrm d x
= \frac{\alpha^2}{(\alpha- r)^2}$$ and $$\mathrm E[\mathrm e^{-crW}]
= \int\limits_0^\infty \mathrm e^{-crx} \lambda \mathrm e^{- \lambda x} \mathrm d x
= \frac{\lambda}{\lambda + c r}.$$ Plugging that into the equality gives $$\frac{\alpha^2}{(\alpha- r)^2} = \frac{\lambda + c r}{\lambda}.$$ Arriving at that cubic equation and quite an ugly expression for $r$ I have to wonder whether I made some mistake or have I overlooked something to simplify this?","['actuarial-science', 'stochastic-processes', 'probability-theory', 'poisson-process']"
4007286,When I not seen a formula of prostapheresis in an identity,"We suppose that I must to proof this identity $$\sin(220°)+\cos(10°)=\cos(70°)$$ Easily if I put $\cos(10°)$ to RHS of the identity, I can apply the formula of prostapheresis $\cos(\alpha)-\cos(\beta)$ and I solved all. But if we not will put the $\cos(10°)$ to the RHS, the identity is it possible to solve with a calculator or is there another alternative?","['algebra-precalculus', 'soft-question', 'trigonometry', 'education']"
4007384,What is the relation between a matrix as a linear function versus the same matrix as a bilinear function?,"Given an $n \times n$ matrix $A$ , we can define a linear transformation $T: \mathbb{R}^n \rightarrow \mathbb{R}^n$ by $T(x)=Ax$ . We could also define a bilnear function $T: \mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}$ by $T(x,y) = y^TAx$ . Is there a relation between these two uses of the matrix? Also, we could do the same thing with an $n \times m$ matrix and get a linear function $\mathbb{R}^m \rightarrow \mathbb{R}^n$ and a bilinear function $\mathbb{R}^m \times \mathbb{R}^n \rightarrow \mathbb{R}$ . Is the relationship between using $A$ to define a linear function versus a bilinear function the same in this case?","['matrices', 'bilinear-form', 'linear-algebra', 'linear-transformations']"
4007440,"Let $G$ be a group in which $aba = b \; \forall a,b \in G$. Prove that $G$ is Abelian.","I was wondering if someone could tell me if my method is correct. I feel like the substation $b=e$ is a stretch and that there is a better way to do it. We know that $G$ is Abelian $\iff (ab)^{-1} = a^{-1}b^{-1}$ . So I know that we will have to manipulate $aba = b$ into $(ab)^{-1} = a^{-1}b^{-1}$ . But this is where I get stuck. $$aba = b \implies ab = ba^{-1} \implies (ab)^{-1} = (ba^{-1})^{-1} \implies (ab)^{-1}=ab^{-1}$$ This is close, but not what I want. One thing that I did notice is that if $b=e$ , then $aba=b \implies a^2 = e \implies a=a^{-1}$ . Since $a^{-1}$ is a unique element we know that $a=a^{-1}$ regardless of what $b$ is. So if we make that substitution into out previous equation we get $$(ab)^{-1} = a^{-1}b^{-1}$$ Therefore $G$ is Abelian.","['group-theory', 'solution-verification', 'abelian-groups']"
4007468,Rings with non-zero intersection of all non-zero ideals,"Let $R$ be a ring such that $\bigcap_{I\neq 0} I \neq 0$ , ie. has a non-zero intersection of all non-zero ideals. This is equivalent to ask for the existence of an element $a\in R$ which is a multiple of all non-zero elements of the ring. What can be said of such rings? Can they be classified? Right now the only examples I can think of are $\Bbb Z/(p^k)$ and fields. I also know that if $R$ is an integral domain with this property then it must be a field. Are there other examples? Thank you in advance.","['ring-theory', 'abstract-algebra']"
4007474,Learning to prove equality of sets and their cardinality,"On $\mathbb R^2$ , define $(x_1, y_1) \sim (x_2, y_2) \iff x^2_1 + y^2_1 = x^2_2 + y^2_2$ . Find a transversal for $\sim$ and prove your answer. Partial answer: The equivalence class of a point $(a,b) \in \mathbb R^2$ is given by $[(a,b)] = \{(x,y): x^2 + y^2 = a^2 + b^2 \}$ meaning  the equivalence classes are concentric circles centered at the origin in $\mathbb R^2$ . One possible transversal is $S = \{(0,r): r \ge 0\}$ -- set of representatives from distinct concentric circles. Another possibility for transversal is to choose any ray from the origin, fix a nonzero point $(a,b) \in \mathbb R^2$ and obtain a transversal $\{(ra,rb) \in \mathbb R^2: r \ge 0\}$ . To prove this, we wanna show $\mathbb R^2 = \bigcup_{r\ge0}[(0, r)] = \bigcup_{r\ge0}[(ra, rb)].$ I want to try proving equality of the given sets. So, Suppose $(x, y) \in \bigcup_{r\ge0}[(0, r)].$ Then $(x, y) \in [(0, r)]$ for some $r \ge 0.$ Then $(x, y) \sim (0, r) \iff x^2 + y^2 = 0^2 + r^2 = r^2$ for some $r \ge 0.$ Now $[(ra,rb)] = \{(x,y): x^2 + y^2 =r^2(a^2 + b^2) \}$ for some $(a, b) \in \mathbb R^2$ . In particular, $[(ra,rb)] = \{(x,y): x^2 + y^2 =r^2 \}$ for $(a, b) = (0, 1)$ meaning $(x, y) \in [(ra,rb)]$ for some $r \ge 0$ and some $(a, b) \in \mathbb R^2$ and so $(x, y) \in \bigcup_{r\ge0}[(ra, rb)]$ which proves $\bigcup_{r\ge0}[(0, r)] \subseteq \bigcup_{r\ge0}[(ra, rb)].$ The other direction is very similar. Assume $(x, y) \in \mathbb R^2$ . Then $x, y \in \mathbb R$ for all $x, y$ . In particular, $y = r$ for some $r \ge 0$ and so $(x, y) = (0, r)$ for some $r \ge 0$ meaning $(x, y) \in \bigcup_{r\ge0}[(0, r)]$ and so $\mathbb R^2 \subseteq \bigcup_{r\ge0}[(0, r)]$ . The other direction is very similar. Since equality is transitive, we have $\mathbb R^2 = \bigcup_{r\ge0}[(ra, rb)].$ Just for practice I will try showing $|\mathbb R^2| = |\bigcup_{r\ge0}[(0, r)]|.$ Assume $(x, y) \in \mathbb R^2$ and consider $f: \mathbb R^2 \to \bigcup_{r\ge0}[(0, r)]$ as $f(x, y) = (0, r)$ for some $r\ge 0.$ Suppose $f(x_1, y_1) = f(x_2, y_2) \iff (0, r_1) = (0, r_2)$ . Since ordered pairs are equal iff the corresponding first components are equal and second components are equal, we have $r_1 = r_2$ . Thus $(x_1, y_1) = (x_2, y_2)$ meaning $f$ is injective. Since $r$ is real, for any $(0, r) \in \bigcup_{r\ge0}[(0, r)]$ , we can find some $y \in \mathbb R$ s.t. $y = r.$ Also, $(0, y) \in \mathbb R^2$ for any real $y$ . Thus there's some $(x, y) \in \mathbb R^2$ s.t. $f(x, y) = (0, r)$ for any $(0, r) \in \bigcup_{r\ge0}[(0, r)]$ meaning $f$ is surjective. Do the proofs above work? If not, what are some alteratives? Thanks. Edit: Turns out everything above is all sorts of incorrect. Anyone interested in corrections, can take a look at this reddit link below: https://www.reddit.com/r/learnmath/comments/l9ql09/showing_set_and_cardinality_equality/","['elementary-set-theory', 'proof-writing', 'solution-verification', 'discrete-mathematics']"
4007524,MLE of difference is difference of MLEs,"Suppose a distribution has two parameters $\alpha$ and $\beta$ , and let the maximum likelihood estimators for these parameters be $\hat{\alpha}$ and $\hat \beta$ . Is the maximum likelihood estimator for $\alpha-\beta$ necessarily equal to $\hat{\alpha}-\hat{\beta}?$ We cannot assume the independence of $\hat \alpha$ and $\hat \beta$ since they are both functions of the same data set.","['statistics', 'maximum-likelihood']"
4007535,"If $E$ has Lebesgue measure $0$, must there exist a translate such that $E\cap E+x=\varnothing$?","If $y\in E\cap E+x$ then $y=h=h'+x \implies x=h-h'$ for $h,h'\in E$. Likewise, if $x=h-h'$, then $h\in E\cap E+x$. So that $E\cap E+x$ is non empty iff $x=h-h'$ where $h,h'\in E$. Thus, if there exists a real $x$ which cannot be expressed as above, the result is proven. The problem is I cannot prove that such an $x$ must exist. I have tried assuming that all real $x$ are of that form, but that gives me nothing except that $E$ must be uncountable and unbounded. Any hints?","['measure-theory', 'lebesgue-measure', 'real-analysis']"
4007556,"$(0,1)$-normalization of cooperative games","I'm currently doing some exercises on cooperative games. To be honest I can't really find any examples of (0-1)-normalization of games. Consider the game with $N=\lbrace I,II,III \rbrace$ and characteristic function as follows: $$v(\emptyset)=0,\ v(I)=1,\ v(II)=2,\ v(III)=3,$$ $$v(\lbrace I,II\rbrace)=5,\ v(\lbrace I, III\rbrace)=7,\ v(\lbrace II,III\rbrace)=9$$ $$v(\lbrace I,II,II\rbrace)=12$$ So the (0-1)-normalization of such game should satisfy following conditions: $v(N)=1$ $0\leq v(S)\leq 1$ for every $S\subseteq N$ $v(i)=0$ for $i\in\lbrace1,2,3\rbrace$ So we know that in this normalized game $$v'(\emptyset)=v'(I)=v'(II)=v'(III)=0,$$ $$v'(\lbrace I,II,II\rbrace)=1$$ EDIT:
Okay I think I figured this out using formula: $$v'(S)=\frac{v(S)-\sum_{i\in S } v(i)}{v(N)-\sum_{i\in N } v(i)}.$$ By this I calculated: $$v'(\lbrace I,II\rbrace)=1/3,\ v'(\lbrace I, III\rbrace)=1/2,\ v'(\lbrace II,III\rbrace)=2/3$$ Is that correct?","['game-theory', 'discrete-mathematics']"
4007565,"For $\boldsymbol{n} \in \mathbb{N}$, does $\boldsymbol{n} \not\in \boldsymbol{n}$ rely on the Axiom of Regularity?","From the axiom of regularity: \begin{equation}
\left(\forall x\right)\left(x \neq \emptyset \longrightarrow \left(\exists y \in x\right)\left(y \cap x = \emptyset\right)\right),
\end{equation} we are able to deduce that $x \not \in x$ for any set $x$ in the ZF language system. Consequently, for every $\boldsymbol{n} \in \mathbb{N}$ , we have $\boldsymbol{n} \not \in \boldsymbol{n}$ . Is it possible to deduce the same conclusion using only the definition of natural numbers? That is, to deduce $\boldsymbol{n} \not\in \boldsymbol{n}$ using only $\boldsymbol{0} = \emptyset$ and $\boldsymbol{n}^{+} = \boldsymbol{n} \cup \left\{\boldsymbol{n}\right\}$ .",['elementary-set-theory']
4007566,"In how many permutations of $\lbrace a,b,c,d,e \rbrace$ a comes before e and e come after c?","In how many permutations of $\lbrace a,b,c,d,e \rbrace$ $a$ comes before $e$ and $e$ come after $c$ ? I know that the answer is $\frac{5!}{3}$ but I don't understand why? My approach is: In half of the permutations, $a$ comes before $e$ , and then we should determine the order of $e$ and $c$ .  Then $c$ may be between $a$ and $e$ or $c$ comes after $e$ or $c$ comes before $a$ and $\frac{2}{3}$ of possible situations are just as we wanted. so $\frac{2}{3} \times \frac{1}{2} = \frac{1}{3}$ of all permutations is the answer. Is my approach correct? and is there another way to solve this? Thanks a lot!","['permutations', 'combinatorics', 'discrete-mathematics']"
4007626,How to find $\operatorname{P.V.}\int_0^1 \frac{1}{x (1-x)}\arctan \left(\frac{8 x^2-4 x^3+14 x-8}{2 x^4-3 x^3-11 x^2+16 x+16}\right) \textrm{d}x$?,The following problem is proposed by Cornel Valean: $$\operatorname{P.V.} \int_0^1 \frac{1}{x (1-x)}\arctan \left(\frac{8 x^2-4 x^3+14 x-8}{2 x^4-3 x^3-11 x^2+16 x+16}\right) \textrm{d}x=\log \left(\frac{5}{4}\right) \arctan\left(\frac{1}{2}\right).$$ The question is how can we prove this equality without using the main result in this paper and without the use of complex numbers?,"['integration', 'real-analysis', 'alternative-proof', 'calculus', 'cauchy-principal-value']"
4007640,compact metric spaces,"Let $(X,d_X)$ and $(Y, d_Y)$ be compact metric spaces. Show that for a nonempty set $A\subseteq X,$ the function $f : X\to \mathbb{R}, f(x) = \inf \{d_X(x,a) : a\in A\}$ is continuous. Show that if a map $f : X\to Y$ is both continuous and bijective, then its inverse $f^{-1} : Y\to X$ is also continuous. Let $C$ be the Cantor set with metric from $(\mathbb{R},|\cdot|)$ and $P = \prod_{k=1}^\infty \{0,\frac{1}{2^k}\}$ with metric from $(\ell_1, \lVert \cdot \rVert_1).$ Show that there exists a continuous bijection $f : C\to P.$ For $1),$ let $x\in X$ and let $\epsilon > 0.$ Choose $\delta = \epsilon.$ Then if $y\in X$ is such that $d(x,y) < \epsilon, we $ have \begin{align}d(f(x), f(y)) 
&= \inf\{d(x,a) | a \in A \} - \inf\{d(y,a) | a\in A\}\\
&\leq \inf \{d(x,a) | a\in A\} - (\inf \{d(x,a) - d(x,y) | a \in A\})\\
&= \inf \{d(x,a) | a\in A\} - (\inf \{d(x,a) | a \in A\} - d(x,y)\}\\ 
&= d(x,y) < \epsilon.\end{align} Is this part correct? For $2),$ suppose $f:X\to Y$ is continuous and bijective. Let $y\in Y$ and $\epsilon > 0.$ We want to show that there exists $\delta > 0 $ so that if $d_Y(x,y) < \delta$ then $d_X(f^{-1}(x), f^{-1}(y)) < \epsilon$ . Let $(y_n)$ be a sequence in $Y$ such that $y_n\to y.$ Then $(f^{-1}(y_n))\subseteq X$ and since $X$ is compact, it has a convergent subsequence, say $(f^{-1}(y_{n_k}))_k.$ Since $f$ is bijective, we can write $y_n = f(x_n)$ for each $n\in\mathbb{N},$ where $x_n \in X.$ Let $x = \lim_{k\to\infty} f^{-1}(y_{n_k}) = \lim_{k\to \infty} x_{n_k}.$ Since $f$ is continuous, $f(x) = \lim_{k\to\infty} f(x_{n_k}).$ But here I'm stuck as I'm not sure how to show $f^{-1}$ is continuous from here. As for the third part, every element of the Cantor set can be uniquely written in the form $\sum_{k=1}^\infty \frac{a_k}{3^k}, a_k \in \{0,2\}\forall k.$ Then it suffices to show that the function $f : C\to P, f(\sum_{k=1}^\infty \frac{a_k}{3^k}) = \prod_{k=1}^\infty \{\frac{a_k/2}{2^k}\}$ is continuous. I think one could show it's sequentially continous, but I'm not really sure about the details.","['elementary-set-theory', 'continuity', 'calculus', 'real-analysis']"
4007701,How to transform a multi (2) dimensional uniform random function to a given probability density function?,"Well as per title, say I have the probability density function on domain $x \in [0,1] ; y \in [0,1]$ $$f(x,y) = \frac{12}{5} \left( x^2 + y^2 - xy \right)$$ Can I generate this density function from a given uniform (pseudo) random function on the same domain? When using a single variant it's slightly easy: Integrate the function to calculate the cumulative distribution function calculate the inverse of the CDF. plug in the uniform random function. However in multiple dimensions this can't be really done the ""inverse"" isn't clearly defined. - If I could split the variables it's a bit more trivial. But how can this be done in the generic case where the variables aren't independent? I could of course do it by rasterizing the function and getting linearizing the raster (just putting row behind row) and then using normal technologies for this. However this numerical approach seems inexact and arbitrary.","['multivariable-calculus', 'probability-distributions']"
4007705,Show $2^{n-1} (z^n+1)-(z+1)^n=0$ for $n \geq 2$ implies $|z|=1$.,"I've been trying to prove the following question: For $n \geq 2$ , if $z \in \mathbb{C}$ solves $2^{n-1} (z^n+1)-(z+1)^n=0$ , then $|z|=1$ . I rewrite the equation as $\frac{z^n+1}{2}=\left(\frac{z+1}{2}\right)^n$ . I don't know how to proceed from here. Any help would be appreciated! Thanks!","['complex-analysis', 'complex-numbers']"
4007708,"Cauchy product rule to replace ""pi"" with a different infinite series in a particular ellipse","The circumference of a circle has a simple formula $ c = 2 r \pi $ , but there is no simple formula for circumference of an ellipse with major and minor axes of a and b. There are approximations, including the not very close $ c=(a+b)\pi$ , but this infinite series $$ h = \frac{(a^2)-(b^2)}{(a^2)+(b^2)}$$ $$p=\pi (a+b)\sum_{i=0}^\infty \left(\frac{(2n-3)!!}{2^n n!}\right)^2 h^n$$ gave me an idea. In some ways you can think of the summation part as a correction factor to $\pi$ . Let's say that we pick a particular ellipse with a=5 and b=1. Then $\pi$ is a few percent too low to make $ c=(a+b)\pi$ work, so we need a different constant to multiply times (a+b). Can we make a new infinite series not containing the letter $\pi$ for this very specific ellipse? I know this is kind of a silly task since every specific shaped ellipse would need its own infinite series, but it would be useful for a talk I'm to give. My thought was to Cauchy product rule to multiply the summation part of the formula above with one of the infinite series for $\pi$ , but it turns out that is beyond my skills. Can someone help? Thank you in advance.","['cauchy-sequences', 'analysis', 'sequences-and-series']"
4007714,order of a class-preserving automorphism of $G$ have all its prime factor divides $|G|$,"Let $\alpha$ be an automorphism of finite group $G$ , if $\alpha$ maps any element $g$ to its conjugate $x_ggx_g^{-1}$ ( $x_g$ could depend on g, so $\alpha$ is not necessarily inner), then the order of $\alpha$ has its prime factors all divide $|G|$ . These automorphisms are called class-preserving automorphisms denoted $\mathrm{Aut}_c(G)$ . source [1] says ""One of the basic facts about class-preserving automorphisms is that primes
dividing the order of $\mathrm{Aut}_c(G)$ also divide the order of $G$ "", which easily leads to the above result, however I can't find its proof anywhere. [1] Class-Preserving Automorphisms of Finite Groups,
Martin Hertweck, doi:10.1006/jabr.2001.8760","['group-theory', 'abstract-algebra']"
4007716,Permutation Problem: Select m objects from n ones of r types by sampling without replacement,"Problem Description If there are $n$ objects with: $n_1$ indistinguishable objects of type 1, $n_2$ indistinguishable objects of type 2, ... $n_r$ indistinguishable objects of type r s.t. $$n_1 + n_2 + ... + n_r = n$$ How many possible arrangements are there for selecting $m$ objects from them by sampling without replacement, where orders of the same type of objects do not matter while orders of different types matter . Background I thought of this question when I was reviewing the counting chapter of the book Discrete Mathematics and Its Applications . When it came to the generalized problems of permutations and combinations, I came up with and got confused of this question which I thought belonged to the box-ball problems. But I could not find a solution in the book, neither in Google. No doubt that this question is interesting and valuable. Progress The only idea about the solution is the case of $m=n$ , and the solution should be $$\frac{n!}{n_1!n_2!...n_r!}$$","['combinatorics', 'discrete-mathematics']"
4007718,How to argue that variance integral actually converges?,"I'm just starting out with a course where were being taught about expectation and variance of continuous distributions via probability density functions. I was given a definition of how the variance of a random variable $X$ is calculated given its probability density function $f(x)$ , but the definition seems all to suspicious to me. In particular, if $X$ is a random variable and its PDF is $f(x)$ , then it's variance is computed via $$
\text{Var}(X) = \int _{\mathbb{R}}x^2 f(x) \, dx
$$ where I've assumed the expected value of $X$ is $0$ just to make things a bit simpler. Now, since $f(x)$ is assumed to be a PDF, then you'd expect $$
\int _{\mathbb{R}}f(x) \,dx = 1
$$ which seems to hint that the function is (sort of) integrable. But, how can you even make sure that integration of $x^2 f(x)$ actually yields a finite value? I've tried a back-of-the-envelope calculation using integration by parts, and the situation seems to hinge on whether or not $x^2 f(x) \rightarrow 0$ as $|x| \rightarrow 0$ , yet I can't find how this is justified. Any and all help will be appreciated :)","['probability-distributions', 'probability']"
4007740,Show that $ 3^n$ is not $\mathcal{O}(2^n)$,"To show that $2^n$ is $\mathcal{O}(3^n)$ is straightforward. On the other hand, if we want to show the opposite that $3^n$ were $\mathcal{O}(2^n)$ , then we would have $3^n\le C·2^n$ for all sufficiently large $n$ . This is equivalent to $C\ge (\frac{3}{2})^n$ , which is clearly impossible, since $(\frac{3}{2})^n$ grows without bound as $n$ increases. Question :is it clearly impossible based on the question because $C$ is supposed to be constant in the definition of Big- $\mathcal{O}$ ?",['discrete-mathematics']
4007787,Algebraic Curves in Positive Characteristic Reference,"I am looking for an (advanced) book on algebraic curves that treats positive characteristic, something beyond Hartshorne Chapter IV. I am looking for material close to Geometry of Algebraic Curves by Arbarello et al, but where positive characteristic is also treated. All algebraic curves books I have seen rely heavily on the fact that things are being done specifically over the complex numbers. (I am starting to think that maybe it just not true that the analogous results hold in positive characteristic?)","['algebraic-curves', 'algebraic-geometry', 'positive-characteristic']"
4007789,JEE Main 2019:finding $\lim_{x \to \infty} \frac{f(x)}{x}$,"let $f$ be a differentiable function such that $$f'(x)=7-\frac{3}{4} \frac{f(x)}{x}\tag 1$$ then $\lim_{x \to \infty} \frac{f(x)}{x}=?$ This came in JEE Main 2019.Although I got the answer $4$ which matches with the answer key,I( think my solution is not complete. Approach :Assuming the limit exists we have by L-Hospitals rule $$\lim_{x \to \infty} \frac{f(x)}{x}=\lim_{x\to \infty}f'(x)=L \tag{say}$$ Then By taking $\lim_{x\to \infty}$ on both sides of equation $(1)$ we have $$L=7-\frac{3}{4}L \implies L=4$$ Question :Although this approach has quickly given the answer the problem is that I have assumed that the Limit exists which need not be the case.I am aware of the method of actually solving the differential equation and then calculating the limit as done here but I was wondering if my method could be actually tweaked  to show that the limit exists or any other method without solving the differential equation.","['limits', 'calculus', 'real-analysis']"
4007804,"Geometrical Interpretation of the general solution of a first order, quasi linear partial differential equation","In a course on partial differential equations I came through this theorem about the general solution of a first order quasi-linear partial differential equation. The general solution of a first-order, quasi-linear partial differential equation $$a(x,y,u)u_x + b(x,y,u)u_y = c(x,y,u)$$ is given by $f(ϕ,ψ)=0$ ,
where $f$ is an arbitrary function of $ϕ(x,y,u)$ and $ψ(x,y,u).$ $ϕ=C1$ and $ψ=C2$ are solution curves of the characteristic equations $$\frac{dx}{a}=\frac{dy}{b}=\frac{du}{c}.$$ Is there any geometric interpretation of both these points so that I can have a better intuitive understanding of the graphical representation of $f$ , $\phi$ and $\psi$ ?","['multivariable-calculus', 'partial-differential-equations']"
4007810,"For a differential equation, prove that there exists an integrating factor dependent only on $x$","Consider the differential equation $M(x, y)dx + N(x,y)dy = 0$ . Prove that there exists an integrating factor that is dependent on $x$ if and only if $\frac {M_y - N_x}{N} = f(x)$ , a function of $x$ only. I need to prove that in such a case, the integrating factor is: $$I(x) = e^ { \int {f(x)dx}}.$$ I tried to approach this problem by rewriting $M(x, y)dx + N(x,y)dy = 0$ as $M(x, y) + N(x,y) \frac {dy}{dx} = 0.$ Assuming the differential equation is exact, there exists a potential function $φ$ such that $ \frac {∂φ}{∂x} + \frac{∂φ}{∂y} \frac{dy}{dx} = 0.$ But this implies that $\frac {∂φ}{∂x} = 0$ . So $φ(x, y)$ is a function of $y$ only. So we can deduce that $φ(x, y)$ is a function of $x$ only and $φ(x, y) = c$ , where $c$ is a constant. This is where I'm stuck and I'm not sure how to proceed with this proof. Any guidance is greatly appreciated!","['proof-writing', 'ordinary-differential-equations']"
4007824,Is the the function $f(k) = \frac{k\ln 2}{2\ln k}$ strictly increasing at $k \ge 10$,"Is the the function $f(k) = \frac{k\ln 2}{2\ln k}$ strictly increasing at $k \ge 10$ where $\ln$ is the natural log . I believe that the answer is yes. Here's my thinking: $\dfrac{d}{dk}\left(\frac{k\ln 2}{2\ln k}\right) = \dfrac{\ln 2(\ln k - 1)}{2\ln^2(k)}$ The conclusion follows since for $k\ge 10$ , $\dfrac{\ln 2(\ln k - 1)}{2\ln^2(k)} > 0$ Would I also be right in concluding that since $\dfrac{\ln 2(\ln k - 1)}{2\ln^2(k)} < 1$ , it follows that the rate of increase decreases as $k$ increases?","['functions', 'derivatives']"
4007831,Solving differential equations with trigonometric functions using laplace,"Can this DE be solved using Laplace transform? $$
L\;\frac{d^2\theta}{dt^2} + A\cos(\theta) +g\sin(\theta) = 0
$$ where g , A , L are constants","['laplace-transform', 'ordinary-differential-equations']"
4007833,$A$ is representable as a difference of two closed sets if and only if $\overline A \setminus A$ is closed.,"Show that the set $A$ is representable as a difference of two closed sets if and only if $\overline A \setminus A$ is closed. My try: $(\Leftarrow)$ Suppose $\overline A \setminus A$ is closed. Since $\overline A$ is closed and $A = \overline A \setminus (\overline A \setminus A)$ , we see that $A$ is represented as a difference of two closed sets. $\square$ $(\Rightarrow)$ Suppose $A = B\setminus C$ where $B$ and $C$ are closed sets. We need to show that $\overline A \setminus A$ is closed. Since $\overline A = \overline {B\setminus C}$ , we have $$\overline A \setminus A = (\overline {B\setminus C}) \setminus (B \setminus C) = \partial (B\setminus C)$$ Since the boundary is closed (?), $\overline A \setminus A$ is closed $\square$ Last arguments of mine seem to be vague not clear. How to solve the problem rigorously?","['elementary-set-theory', 'general-topology']"
4007855,Some inequalities involving binomial coefficients in Erdös' Graph Theory and Probability,"Let $n$ be a (sufficiently large) positive integer, and $k$ be a fixed positive integer. Let $0 < \epsilon < \frac{1}{k}$ and $0 < \eta < \epsilon / 2$ be arbitrary. Define $m = \lfloor n^{1 + \epsilon} \rfloor$ and $p = \lfloor n^{1 - \eta} \rfloor$ . I am working on the result from Erdös' Graph Theory and Probability that for any $k$ and $r$ there exists a graph with no cycles of length $\leq k$ and chromatic number $> r$ using the probabilistic method. It seems many modern treatments are more explicitly probabilistic, but I would like to understand a bit more of the classic techniques used. In particular, I would like some help in understanding the following two inequalities from (p35), which I cannot get: $$
(n + 1) \binom{\binom{p}{2}}{n} \binom{\binom{n}{2} - \binom{p}{2}}{m} < p^{2n} \binom{\binom{n}{2} - \binom{m}{2}}{m} < \binom{\binom{n}{2}}{m} p^{2n} \left( 1 - \frac{\binom{p}{2}}{\binom{n}{2}} \right)^{m} .
$$ If anyone might be able to share some hints or tricks for dealing with these binomial coefficients, that would be really helpful. Attempt: A basic inequality that I believe might be useful is $\frac{n^k}{k^k} \leq \binom{n}{k} \leq \frac{n^k}{k!}$ . This seems to get some promising results, but I can't seem to pushit through to get the whole desired result, so I am probably missing some key steps. For the first inequality, $\binom{p}{2} \leq \frac{p^2}{2}$ , so we have $\binom{\binom{p}{2}}{n} \leq \frac{p^{2n}}{2^n n!} \leq p^{2n}$ . So this gives one part of it. But I am unsure how the $(n+1)$ (and perhaps the $\frac{1}{2^n n!}$ part) can be used to change the upper index of the binomial coefficient. Note that $\binom{n}{2} - \binom{p}{2} > \binom{n}{2} - \binom{m}{2}$ . For the second inequality, I have tried to use $\binom{\binom{n}{2} - \binom{m}{2}}{m} \leq \frac{\left[\binom{n}{2} - \binom{m}{2}\right]^m}{m!} \leq \frac{\left[\binom{n}{2} - \binom{p}{2}\right]^m}{m!}$ . If I use the $1/m!$ term to create the first binomial coefficient, I can write $\frac{1}{m!} = \frac{\binom{n}{2}!}{m! \left(\binom{n}{2} - m\right)!} \frac{\left(\binom{n}{2} - m\right)!}{\binom{n}{2}!} = \binom{\binom{n}{2}}{m} \frac{\left(\binom{n}{2} - m\right)!}{\binom{n}{2}!}$ . So far so good, but then I can only get $\frac{\left(\binom{n}{2} - m\right)!}{\binom{n}{2}!} \leq \frac{1}{\left[\binom{n}{2} - m\right]^m}$ , whereas I want the upper bound to be $\frac{1}{\binom{n}{2}^m}$ .","['graph-theory', 'inequality', 'binomial-coefficients', 'discrete-mathematics']"
4007875,Diagonalizing a matrix where the pairwise difference of eigenvalues are units,"Let $R$ be a commutative ring (with $1$ ), and $M$ be an $n\times n$ matrix over $R$ whose characteristic polynomial is $$\det(tI - M) = (t-\alpha_1)\cdots(t-\alpha_n)$$ with $\alpha_i \in R$ for all $i$ . Assume that $\alpha_i - \alpha_j \in R^\times$ whenever $i\ne j$ . Is it true that there is some invertible $P \in GL_n(R)$ with $$M = P\begin{pmatrix}\alpha_1 & & & \\ & \alpha_2 & & \\ & & \ddots & \\ & & & \alpha_n\end{pmatrix}P^{-1}?$$ This is true if $R$ is a field. The proof here shows that we must have $R^n = \oplus_{i=1}^n \ker(M - \alpha_i I_n)$ , at least in the case when $R$ is a local ring (but also it seems to work for general $R$ ). But would it follow that we can write $M$ in the form above? It is not clear to me that each $\ker(M - \alpha_i I_n)$ is free (if $R$ is not local), so I am not sure if we can necessarily find a basis of $R^n$ consisting of eigenvectors of $M$ . If the above is false, might there be some conditions on $R$ that would make it true, e.g. if we assume $R$ is an algebra over a field?","['matrices', 'diagonalization', 'linear-algebra', 'commutative-algebra']"
4007910,Prove that the algebraic expression is greater than zero,"Prove that $x^8 - x^5 + x^2 -x + 1 >0$ for $x \in \mathbb{R}$ . It's from the (junior) high-school competition and the idea is that not everyone there knows calculus, so that I'm looking for more ""basic"" justification. My idea was to use AM-GM: $x^8 + x^2 \geq 2\sqrt{x^{10}} = 2x^5$ . Thus, $$x^8 - x^5 + x^2 -x + 1 \geq  x^5-x + 1 $$ So that we can now focus on proving that $x^5 - x + 1 > 0 $ but I don't really see how to do so without calculus...","['contest-math', 'algebra-precalculus']"
4007911,Envelope of oscillator signal,"How do we find envelope ODE of a modulated oscillator obeying $$y^{''}(t)+y (t)\left(\dfrac{2 \pi}{t-c}\right)^2 = 0 $$ after obtaining solution say for initial conditions $y(0) = 1, y'(0) = 0?$ . Does it oscillate indefinitely? Could not readily apply $\; c-, p-$ discriminant methods. Please help. Numerical solution with $ c=t _{max} =6$ Envelope sketched by hand.","['signal-processing', 'ordinary-differential-equations']"
4007940,How to find the partial derivatives of the following nested expression?,"I want to find the partial derivatives of the expression for $v_3(\boldsymbol{u})$ with respect to $u_1$ , $u_2$ and $u_3$ from the expressions below. Here $\Phi$ denotes the cumulative distribution function of the standard normal probability distribution. I think it should be possible to solve it analytically by employing the chain rule. However, I have a feeling that the expressions quickly will become quite ugly. Any suggestions on how this can be done? $$h(\boldsymbol{u}) = F_{H_s}^{-1}(\boldsymbol{\Phi}(u_1)) = \alpha[-\ln(1-\Phi(u_1))]^{1/\beta}$$ $$t(\boldsymbol{u}) = F_{T_z|H_s}^{-1}(\boldsymbol{\Phi}(u_2)|h(\boldsymbol{u})) = \exp({\mu(h(\boldsymbol{u})) + \sigma(h(\boldsymbol{u})) u_2})$$ $$v_3(\boldsymbol{u}) = F_{V_3|Tz,H_s}^{-1}(\boldsymbol{\Phi}(u_3)|h(\boldsymbol{u}),t(\boldsymbol{u})) = \sqrt{-2m_0(h(\boldsymbol{u}),t(\boldsymbol{u})) \ln\left(-\frac{2\pi}{\widetilde{T}}\sqrt{\frac{m_0(h(\boldsymbol{u}),t(\boldsymbol{u}))}{m_2(h(\boldsymbol{u}),t(\boldsymbol{u}))}}\ln\boldsymbol{\Phi}(u_3)\right)}$$ Here $\mu(h(\boldsymbol{u}))$ and $\sigma(h(\boldsymbol{u}))$ denotes the h-dependent mean and standard deviation of the lognormal distribution, respectively. These are given by: $\mu(h(\boldsymbol{u})) = a_0 + a_1 h ^ {a_2}$ $\sigma(h(\boldsymbol{u})) = b_0 + b_1 \exp(b_2 h)$ where $a_0 = 0.70, a_1 = 0.282, a_2 = 0.167, b_0 = 0.07, b_1 = 0.3449, b_2 = -0.2073$ . Furthermore, $\alpha = 1.76$ and $\beta = 1.59$ .","['nested-radicals', 'probability-distributions', 'reliability', 'partial-derivative', 'derivatives']"
4007942,"If you know why something happened, and why something didn't happen...","I'm not a mathematician, so go easy. I dropped out of high school. But I'm a programmer / logician / writer of algorithms. And I'm currently engaged in one of my most complex projects to date, which involves building up something like Markov chains within one another to lead people to find unexpected, complex results out of their own psychological preferences. I'm raising this question not because I need help with my project, but because I stumbled on an unexpected feature of my data, and then had a corresponding dream about it. The feature I stumbled on was that it's quite easy to record all the events and conditions leading up to a happening, but it's quite another thing to record all the ones that didn't lead to it, let alone all the ones that didn't lead to something not happening . And let's not forget all the ones that didn't lead to something not happening which caused a whole chain of other things not to happen. The dream In the dream, K[0] is a set of things that had never been imagined happening. K[1] is a set of things that you could imagine, because they diverged from the chain of events at some point where you could still conceive of their results. But they didn't actually happen. K[2] is the much smaller set of things that actually did happen. From K[2] you can begin to infer K[1]. As soon as you imagine something from K[0], it becomes part of K[1]. For all intents and purposes, K[0] is infinite, even after you imagine parts out of it. K[1] is only limited by your imagination, and K[2] is the reality upon which your imagination is based. So in this dream, K[1] acts as a kind of thicker or thinner membrane around reality, describing the contour of K[0] which most closely match K[2]. Depending on how much of K[0] you can imagine and reference to something happening in K[2]. What I'm interested in is, is what is the relationship between these sets? For example, how can you prove that K[1] doesn't exist until you imagine it, and that K[0] is still unknown even though you can pull an element out randomly, by imagining it, and insert it into K[1]? Apologies if this makes no sense, just a human brain trying to make order out of chaos.","['chaos-theory', 'statistics']"
4007957,Irregularity of $a^ib^jc^k∣\text{ if }i=1\text{ then }j=k$ using pumping lemma,"This question has been asked here several times. However none of the examples I saw actually tried to prove it's irregularity using the standard pumping lemma. I know how to prove irregularity using the specific case of $a^1b^pc^p$ however I'm struggling to build the pumping lemma for the whole language $a^ib^jc^k$ I know this won't prove the language to be regular, but I'm more interested in how to deal with lemmas with multiple variables on the exponents.
Let's suppose I've divided the string into the following: $ x = \epsilon$ $ y = b^\beta$ $ z = b^{p-\beta}c^m$ Let $n = 2$ . I get $xy^2z= b^{p-\beta}c^n$ But this doesn't seem like I can find a pumping length for this language as it has too many variables. Is there a way to make this pumping lemma work? (I know it can't be used to prove the language regular, but I'm trying to find at least one pumping length which works for this language)","['pumping-lemma', 'discrete-mathematics']"
4007983,Is the operator norm of the canonical surjection $X\to X/U$ equal to $1$?,"Let $X$ be a normed space, $U$ be a closed subspace of $X$ and $\pi:X\to X/U$ denote the canonical projection. By definition, $\pi$ is surjective and it is easy to show that $\pi\left(B^X_1(0)\right)=B^{X/U}_1(0)$ , where $B^X_1(0)$ and $B^{X/U}_1(0)$ denote the open unit balls around $0$ in $X$ and $X/U$ , respectively. It should immediately follow that $\pi$ is an open map and the operator norm of $\pi$ is at most $1$ . But can we show that the operator norm is precisely equal to $1$ (unless $X=U$ , of course)?","['operator-theory', 'functional-analysis', 'quotient-spaces']"
4008006,Module of differentials of an extension of Dedekind domains,"Let $A$ be a Dedekind domain with fraction field $K$ , $L|K$ a finite separable field extension and $B$ the integral closure of $A$ in $L$ . Assume that al the residue field extensions are separable. In the proof of Serre's ""Local Fields"", chapter III, Proposition 14 (page 59), it is stated that in order to show that the module of differentials $\Omega_{B|A}$ is cyclic we can assume that $A$ is local and complete. Why? I understand the reduction to the local case of the other part of the theorem (the annihilator of the module of differentials equals the Dedekind different), since clearly two ideals are equal if they are locally equal, but being cyclic is not a local property in general, and I am not able to understand that reduction to the local case. For convenience the above Proposition is the following:","['algebraic-number-theory', 'algebraic-geometry', 'commutative-algebra']"
4008016,Divisors on Riemann Surface form a group under pointwise addition(doubt),"In (Rick Miranda, page 129) Divisor on a Riemann Surface is defined as : A divisor on Riemann surface $X$ is a function $D: X \rightarrow \mathbb{Z}$ whose support is a discrete subset of $X$ . Author states that The divisors on $X$ form a group under pointwise addition. I'm having difficulty in verifying that divisors form a group under pointwise addition. I tried to check the above fact by taking $X = \mathbb{C}$ as Riemann Surface. Let $f, g$ be two divisors on $X$ with supports $\{\frac{1}{n}\}_{i=1}^\infty$ and $\{0\}$ respectively. f and g are defined as follows $$f(x) = \begin{cases} n \text{ ,if } x = 1/n\\ 0 \text{ ,otherwise}\\
\end{cases}
$$ $$g(x) = \begin{cases} 1 \text{ , if } x = 0 \\ 0 \text{ ,otherwise}\end{cases}$$ Consider $f+g:X \rightarrow \mathbb{C}$ , clearly $(f+g)(x) \ne 0 $ when $x \in \{\frac{1}{n}\}_{i=1}^\infty$ or $x = 0$ , Hence support of $f+g$ has a limit. So, by definition $f+g$ is not a divisor. Is there something that I don't understand?","['riemann-surfaces', 'algebraic-geometry']"
4008038,Cosine of complex variable,"Show that $|\cos z|\leq2$ for all $z \in B(0,r)\subset C$ for some $r>0$ . Can we have $|\cos z|\leq 1$ for all $z \in B(0,r)\subset C$ for some $r>0$ ? I have found the answer for the first part but can't think of a solution for the second question. For the first part $$|\cos z|=\biggl|\frac{e^{iz}+e^{-iz}}{2}\biggr|$$ $$ =\biggl|\frac{e^{ix}*e^{-y}+e^{-ix}*e^{y}}{2}\biggr|$$ $$ \leq\biggl|\frac{e^{ix}*e^{-y}}{2}\biggr|+ \biggl|\frac{e^{-ix}*e^{y}}{2}\biggr| $$ $$ \text{But }\:|e^{-ix}|=|e^{ix}|=1$$ $$ =\biggl|\frac{e^{-y}}{2}\biggr|+ \biggl|\frac{e^{y}}{2}\biggr|$$ $$= \cosh y$$ $$\text{So }\: |\cos z|\leq \cosh  y$$ and since $\cosh 0=1$ we can find a neighborhood around the point $0$ such that $|\cos z|\leq 2$ . Since $\cosh x$ is a strictly increasing function I can't use it to prove that $|\cos z|\leq 1 $ for some neighborhood. Another method I can think of is taking partial derivative of $|\cos z|$ along $x$ and $y$ -axes to check the direction in which it increases or decreases. But is there a simpler way for checking whether such a neighborhood exists ?","['complex-analysis', 'trigonometry', 'inequality']"
4008046,Help to know what kind of differential equation is this,"I've to solve this differential equation: $
(2y^3-2y^2+3x)dx+(3xy^2-2xy)dy=0
$ But I even don't know what kind of differential equation is it. Please, any help? Thanks in advance.",['ordinary-differential-equations']
4008059,Construction of the Universal Covering Space via Compact-Open Topology,"Recently I've been self-studying the theory of covering spaces from ""Introduction to Topological Manifolds"", by John M. Lee. At the end of Chapter 11, there is an explicit construction of the universal covering space for a connected, locally path connected and semilocally simply connected topological space $X$ . Very briefly, the idea is as follows: take $x_{0}\in X$ , define $P(X,x_{0})$ to be the set of all paths in $X$ which start at $x_{0}$ , and let $\tilde{X}$ be the quotient set of $P(X,x_{0})$ by the relation: $\alpha \sim \beta$ if and only if $\alpha(1)=\beta(1)$ and $\alpha\simeq \beta$ are path-homotopic. We define $q\colon \tilde{X}\to X$ to be the map $q([\alpha]):=\alpha(1)$ . We later define a topology on $\tilde{X}$ by means of a basis, which turns $\tilde{X}$ into a simply connected, locally path connected space and $q$ into a covering map. However, some authors suggest that an alternative way to construct $\tilde{X}$ is to give $P(X,x_{0})$ the compact-open topology (that is, the subspace topology it inherits as a subset of $\mathcal{C}([0,1],X)$ ), and $\tilde{X}$ the quotient topology induced by the canonical map $\pi \colon P(X,x_{0})\to \tilde{X}$ . Nevertheless, I haven't been able to find a clear proof that $q\colon \tilde{X}\to X$ is the universal cover of $X$ . What I'm trying to do is imitate the proof in Lee's book, but using this alternative topology: most of the details of the proof are rather set-theoretic, so I've managed to reduce the problem of rewriting the proof to just having to prove these 4 facts: $\tilde{X}$ is a path connected topological space. $q\colon \tilde{X}\to X$ is continuous. $q\colon \tilde{X}\to X$ is open. For every $\alpha \in P(X,x_{0})$ and every open set $U\subseteq X$ such that $\alpha(1)\in U$ , the subset $$
[\alpha \cdot U]=\{ [\alpha \cdot \beta]\colon \beta \text{ is a path in } U \text{ such that } \beta(0)=\alpha(1) \}
$$ is open in $\tilde{X}$ . Here are my ideas so far: $P(X,x_{0})$ is path connected (and hence $\tilde{X}$ is too): let $\tilde{x}_{0}=[c_{x_{0}}]$ be the class of the constant path at $x_{0}$ and $\alpha\in P(X,x_{0})$ be arbitrary. Define $F\colon [0,1]\times [0,1]\to X$ by $F(t,s)=\alpha(ts)$ . This is a continuous map, so by properties of the CO-topology, the map $f\colon [0,1]\to \mathcal{C}([0,1],X)$ given by $f(t)(s)=F(t,s)$ is continuous. Since $f(0)(s)=x_{0}$ , $f(1)(s)=\alpha(s)$ and $f(t)(0)=x_{0}$ , $f$ is a path in $P(X,x_{0})$ from $c_{x_{0}}$ to $\alpha$ . Therefore, $P(X,x_{0})$ is path-connected. Let $\operatorname{ev}\colon P(X,x_{0})\to X$ be the map defined by $\operatorname{ev}(\alpha)=\alpha(1)$ . This map is continuous (again, this is a general property of the CO-topology) and passes continuously to the quotient, inducing precisely the map $q$ , so $q$ is continuous. As of openness of $q$ , I'm not sure how to proceed: what I'm sure of is that, if $\operatorname{ev}$ is an open map (which I think it is), then $q$ is too. I believe that it should be possible to prove that basic open subsets of $P(X,x_{0})$ are mapped into open sets of $X$ . Let $[\alpha \cdot U]$ defined as above, we need to see that $\pi^{-1}([\alpha \cdot U])$ is open in $P(X,x_{0})$ . Take any $\gamma \in \pi^{-1}([\alpha \cdot U])$ , so that $\gamma \simeq \alpha \cdot \beta$ , where $\beta$ is a path in $U$ starting at $\alpha(1)$ . Let $V$ be the path component of $U$ which contains $\gamma(1)$ (and therefore, it contains $\alpha(1)$ ). Then $\gamma\in [\{1\},V]$ , where $[\{1\},V]$ is the basic open subset of $P(X,x_{0})$ given by all paths which end at some point of $V$ . From here I don't know how to continue: I think this open set is contained in $\pi^{-1}([\alpha \cdot U])$ , but I haven't got an idea to prove it (certainly, since we know ""a posteriori"" that $\tilde{X}$ is simply connected, every element of $[\{1\},V]$ is homotopic to $\alpha\cdot \eta$ , where $\eta$ is a path in $V$ from $\alpha(1)$ to the endpoint of such element). So far, are my ideas on the right track? Can someone help me especially with the last two statements? Thank you in advance! EDIT 1: I wanted to add some new insights on the proof of the last two statements: I think this could be a valid proof for openness of $\operatorname{ev}$ : let $A=[K_{1},U_{1}]\cap \dots \cap[K_{n},U_{n}]$ be a basic open set of $\tilde{X}$ , we need to prove that $\operatorname{ev}(A)$ is an open subset of $X$ . Take $x\in \operatorname{ev}(A)$ , so that there exists some $\alpha \in A$ such that $x=\alpha(1)$ . Let $B\subseteq X$ be the intersection of all $U_{i}$ 's such that $1\in K_{i}$ (if none of the $K_{i}$ contains $1$ , then $B:=X$ ), so $x\in B$ , and let $V$ be the path component of $B$ that contains $x$ (so $V$ is open in $X$ ). I claim that $V\subseteq \operatorname{ev}(A)$ . To see this, let $y\in V$ . For every $j$ such that $1\notin K_{j}$ , let $a_{j}=\max \{t\colon t\in K_{j}\}<1$ , and let $a=\max a_{j}$ . By continuity, one can choose some $a<b<1$ such that $\alpha([b,1])\subseteq V$ . Take any path $\gamma$ in $V$ from $\alpha(b)$ to $y$ and define $$
\beta(t)=
\begin{cases}
\alpha(t), & 0\leq t \leq b \\
\gamma\left( \dfrac{t-b}{1-b} \right), & b\leq t \leq 1.
\end{cases}
$$ Then $\beta$ is continuous, and since $\gamma([0,1])\subseteq B$ and $\beta = \alpha$ up to $t=b$ , we have that $\gamma \in A$ and $y=\operatorname{ev}(\beta)\in \operatorname{ev}(A)$ , which proves that $V\subseteq \operatorname{ev}(A)$ . Hence, $\operatorname{ev}$ is open, and so is $q$ . After further inspecting Lee's proof, it is only neccessary to prove that $[\alpha \cdot U]$ is open when $U$ is a relatively simply connected neighborhood of $\alpha(a)$ , but adding that hypothesis hasn't helped me as of now. EDIT 2: I think I've come up with a proof of the last statement. The main idea is to prove that ""translations by a path"" reduce the study of such sets to just seeing that $[c_{x_{0}}\cdot U]$ is open in $\tilde{X}$ . For any $x\in X$ , let $P(X,x)$ be the space of all paths in $X$ starting at $x$ (equipped with the compact-open topology), and let $Q(X,x)$ be the quotient of $P(X,x)$ by path homotopy, and denote by $\phi_{x}\colon P(X,x)\to Q(X,x)$ the natural map. Notice that $\tilde{X}=Q(X,x_{0})$ . Given $x,y\in X$ , and any path $\gamma$ from $x$ to $y$ , one can define a mapping $\Lambda\colon P(X,y)\to P(X,x)$ given by $\Lambda_{\gamma}(\alpha)=\gamma\cdot \alpha$ . We prove that $\Lambda_{\gamma}$ is a continuous map. Let $\alpha \in P(X,y)$ , and suppose $[K,U]$ is a subbasic set of $P(X,x)$ such that $\Lambda_{\gamma}(\alpha)=\gamma \cdot \alpha \in [K,U]$ . Divide $K$ into $K_{1}=K\cap [0,1/2]$ and $K_{2}=K\cap [1/2,1]$ . Given any $t\in K_{2}$ , we have $\gamma \cdot \alpha(t)=\alpha(2 t -1)\in U$ , so $K_{2}'=\{ 2s-1 \colon s\in K_{2} \}$ is a compact subset of $[0,1]$ such that $\alpha \in [K_{2}',U]$ . Now, given any $\beta\in [K_{2}',U]\subseteq P(X,y)$ , it is clear that $\gamma \cdot \beta (K_{1})=\gamma(K_{1})=\gamma \cdot \alpha(K_{1})\subseteq U$ , and $\gamma \cdot \beta (K_{2})=\beta(K_{2}')\subseteq U$ , so $\Lambda_{\gamma}(\beta)\in [K,U]$ . Therefore, $\Lambda_{\gamma}$ is continuous. Now, since $\Lambda_{\gamma}$ is compatible with both $\phi_{x}$ and $\phi_{y}$ , it passes to the quotient into a continuous map $\Omega_{\gamma}\colon Q(X,y)\to Q(X,x)$ , whose inverse is $\Omega_{\overline{\gamma}}$ , so $\Omega_{\gamma}$ is a homeomorphism. Returning to the question at hand: consider a path $\gamma\in P(X,x_{0})$ , and a relatively simply connected open set $U\subseteq X$ containing $\gamma(1)=x$ . Then: $$
[\gamma \cdot U]=\{[\gamma\cdot \alpha]\colon \alpha \text{ is a path in } U \text{ such that } \alpha(0)=\gamma(1)=x\} \\
=\{\Omega_{\gamma}([\alpha])\colon \alpha \text{ is a path in } U \text{ such that } \alpha(0)=\gamma(1)=x\}=\Omega_{\gamma}(\phi_{x}([[0,1],U])),
$$ So it suffices to prove that $\phi_{x}([[0,1],U])$ is open in $Q(X,x)$ , that is, $\phi^{-1}_{x}(\phi_{x}([[0,1],U]))$ is open in $P(X,x)$ .I have yet to prove this last bit, but I think it should be possible to conclude from here.","['general-topology', 'algebraic-topology', 'covering-spaces']"
4008083,Is this definition of the gradient using the exterior derivative consistent with calculus 1?,"I'm trying to get a better grasp on what the exterior derivative means on my own and I'm trying to connect the language of forms to my pre-existing knowledge. I came along the following formula for the gradient on wikipedia : $$\text{grad}f=\nabla f=(df)^\sharp$$ where $d$ is the exterior derivative and $^\sharp$ is a musical isomorphism. Since $(\omega_ie^i)^\sharp=\omega^ie_i$ this gives the following definition in component form $$\nabla f=e_i\partial^if=(\partial^if)\frac{\partial}{\partial  x^i}.$$ From my calculus classes I remember the gradient being defined as a vector which is consistent with this formula. But what confuses me is that the vector component have raised indices . In Cartesian coordinates you wouldn't notice this but in polar coordinates, or any other coordinates for that matter, you would notice a difference. But again when I recall my calculus classes I remember always calculating the ordinary partial derivatives which correspond to lower indices $\partial_i f$ . So is this definition consistent with elementary calculus intuition? So my elementary calculus definition would perhaps be $(\partial_i f)e_i$ even though I know that wouldn't make sense.","['differential', 'differential-forms', 'multivariable-calculus', 'vector-analysis']"
4008084,The equivalence of Lindeberg with CLT & Feller for a given example,"I consider Gabriel's example "" Showing that Lindeberg condition does not hold "" where we deal with a sequence of random variables $(X_n)_n$ with $X_k = Y_k + Z_k$ and $P(Y_k = \pm 1) = \frac{1}{2}$ and $$
P(Z_k = \pm k) = \frac{1}{2k^2} = \frac{1 - P(Z_k = 0)}{2}.
$$ As in the solution there, it can be shown, that the CLT for $S_n = \sum_{k=1}^{n} X_n$ holds, that is $$
\frac{S_n}{\sqrt{n}} {\stackrel{d}{\longrightarrow}} \eta \sim \mathcal{N}(0,1) \quad \text{for } {n \rightarrow \infty}
$$ but the Lindeberg condition is not fullfilled (even for the little more genereal Case where $Y_k$ is iid with expectation 0 and variance 1). But I struggle with the Feller condition. As fare as I know this is (if I use the triangular array with $X_{n_k}:=(\frac{X_k}{\sqrt{n}})$ ): $$
	\max_{1 \leqslant k \leqslant n} \sigma_{n_k} = \max_{1 \leqslant k \leqslant n} \mathbb{E}\left[\left(\frac{X_k}{\sqrt{n}}\right)^2\right] = \max_{1 \leqslant k \leqslant n} \frac{\mathbb{E}(X_k^2)}{n} = \frac{2}{n} \stackrel{n \to \infty}{\longrightarrow} 0,
$$ as it may be found in mathworld .
However, if the Feller condition is fulfilled, the Lindeberg condition is necessary and sufficient for the CLT. Do I have a mistake with the Feller condition or is there another assumption for the equivalence Lindeberg $\Leftrightarrow$ Feller & CLT I do not considere/know? And maybe another but minor important question: the example shows that the second moment of $\frac{S_n}{\sqrt{n}}$ does not converge. What do I need that $\mathbb{V}\left(\frac{S_n}{\sqrt{n}}\right) \stackrel{n \to \infty}{\longrightarrow} \mathbb{V}(\eta)$ ?","['probability-limit-theorems', 'central-limit-theorem', 'probability-theory', 'probability']"
4008106,How to show that the full faithfulness of a functor preserved under an action of finite flat algebra?,"Let $R, S,T$ be three commutative rings  with $R \subset S \subset T$ and the map $ S \to T$ is faithfully flat. Assumme a functor $F: \mathscr{C} \to \mathscr{D}$ between two categories, where $\mathscr{C}$ is the category of $S$ -modules and $\mathscr{D}$ is the category of $T$ -modules. Now consider a finite flat $R$ -alebra $A$ . Question: How to show the functor $ \mathscr{C} \otimes A \to \mathscr{D} \otimes A$ is fully faithful provided the functor $F: \mathscr{C} \to \mathscr{D}$ is fully faithful. Note: Here by notation $\mathscr{C} \otimes A$ ,  I want to mean we are taking action of the finite flat $R$ -algebra $A$ or just scalar extension by $A$ . $$------------------------------------$$ My efforts: Given that $F: \mathscr{C} \to \mathscr{D}$ is fully faithful. So for any $S$ -modules $M,N \in \mathscr{C}$ , the functor $F$ induces the map $$F_{M,N}: \text{Hom}_{\mathscr{C}}(M,N) \to \text{Hom}_{\mathscr{D}}(F(M),F(N)),$$ which is bijective. So for any $S$ -module homomorphism $f: M\to N$ in category $\mathscr{C}$ , we get a unique $T$ -module homomorphism $F_{M,N}(f): F(M) \to F(N)$ in category $\mathscr{D}$ by the injectiveness property. Also by the surjective property, for every $T$ -module homomorphism $F_{M,N}(g): F(M) \to F(N)$ in category $\mathscr{D}$ there exists a $S$ -module homomorphism $f: M \to N$ in category $\mathscr{C}$ which corresponds to each other. Now we consider the action of the finite flat $R$ -algebra $A$ on every modules of $\mathscr{C}$ and $\mathscr{D}$ such as $ M \otimes_R A$ or $N \otimes_R A$ or $F(M) \otimes_R A$ or $F(N) \otimes_R A$ etc. We can then think of the   functor $F: M\to N$ and the $S$ -module homomorphism $f:M \to N$ as follows: $$ {\color{red}{F \otimes 1}}: \mathscr{C} \otimes A \to \mathscr{D} \otimes A, \ \text{and} \ f \otimes 1: M \otimes_R A \to N \otimes_R A,$$ (where $A$ can be thought of as a category of single object (a $R$ -module) along identity map $1$ ). Thus it seems, by the property of product categories, $${\color{red}{(F \otimes 1)}}_{M,N} (f \otimes 1)=F_{M,N}(f) \otimes F_{M,N}(1),$$ where $1$ denotes the identity map. So it seems to me that the flatness property of $A$ and the map $S \to T$ being faithfully flat, the functor $F \otimes A$ induces the bijective map \begin{align}
{\color{red}{(F \otimes 1)}}_{M,N}: &\text{Hom}_{\mathscr{C} \otimes A}(M \otimes_R A,N \otimes_R A) \\ & \to  \text{Hom}_{\mathscr{D} \otimes A}({\color{red}{(F \otimes 1)}}(M \otimes_R A), {\color{red}{(F \otimes 1)}}(N \otimes_RA)), \end{align} which answers question $(1)$ , I think. Perhaps we can consider the following diagram for better understanding: \begin{align}
\matrix{
\mathscr{C} & \overset{F}{ \longrightarrow} & \mathscr{D} 
\cr  \downarrow  && \downarrow 
\cr \mathscr{C} \otimes A & \overset{{\color{red}{F \otimes 1}}}{\longrightarrow} & \mathscr{D} \otimes A}
\end{align} Any comment please","['number-theory', 'category-theory', 'tensor-products', 'commutative-algebra']"
4008152,"Throw a coin one million times. What is the expected number of sequences of six tails, if we do not allow overlap?","Question itself: Throw a coin one million times. What is the expected number of sequences of six tails, if we do not allow overlap ? I know when overlap is allowed, the answer is (1,000,000-5)/(2^6). Not sure if we can just do (1,000,000-5)/(2^6) divided by 6 if overlap is not allowed? Some clarifications: For example, if part of the sequence is ""one H, nine T, then one H"", we would count 1 sequence of six tails. (When overlap is allowed, we can count three times because each of the first 3 T can start a sequence of six tails; However, this question does not allow overlap, so 9T can only be counted as containing one sequence of six tails) If part of the sequence is ""one H, thirteen T, then one H"", we would count 2 sequences of six tails.",['probability']
